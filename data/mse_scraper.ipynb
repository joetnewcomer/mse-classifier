{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28515af2-0775-4bc8-9455-8ce9c86a83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe8208-2f65-4697-a04a-25b793db4178",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad3e2b6-03db-4652-9ae0-a8edb8c87c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_links(tag, num_pages=10):\n",
    "    '''\n",
    "    Gets links to questions that belong to a certain tag.\n",
    "\n",
    "    Parameters:\n",
    "    tag (str): A tag for which to get questions.\n",
    "    num_pages (int): Number of pages of the tag to scrape. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    question_links (list[str]): A list of URLs to Math Stack Exchange questions.\n",
    "    '''\n",
    "    question_links = []\n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = f'https://math.stackexchange.com/questions/tagged/{tag}?tab=votes&page={page}&pagesize=50'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for question in soup.select('.s-post-summary'):\n",
    "            link = question.select_one('.s-link')['href']\n",
    "            question_links.append(link)\n",
    "        time.sleep(random.uniform(0,2)) # Random to mimic human behavior and hopefully not get banned...\n",
    "        \n",
    "    return question_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8555ad88-dcb8-43c0-adcf-3b0a3b36cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title(title_str):\n",
    "    '''\n",
    "    Separates title into text portions and LaTeX portions.\n",
    "\n",
    "    Parameters:\n",
    "    title_str (str): The raw title.\n",
    "\n",
    "    Returns:\n",
    "    text_content (str): The text portion of the title.\n",
    "    latex_content (str): The LaTeX portion of the title. \n",
    "    '''\n",
    "    latex_parts = re.findall(r'\\$(.*?)\\$', title_str)\n",
    "    text_content = re.sub(r'\\$.*?\\$', '', title_str).strip()\n",
    "    latex_content = ' '.join(latex_parts)\n",
    "    return text_content, latex_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a033d97-b26b-406e-aee5-9ab606ce3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_body(content_soup):\n",
    "    '''\n",
    "    Separates body into text portions and LaTeX portions. Takes into account more sophisiticated LaTeX than just \"$\" delimiters.\n",
    "\n",
    "    Parameters:\n",
    "    content_soup (soup): The soup object obtained from the contents of the question.\n",
    "\n",
    "    Returns:\n",
    "    text_content (str): The text portion of the body.\n",
    "    latex_content (str): The LaTeX portion of the body. \n",
    "    '''\n",
    "    latex_elements = content_soup.find_all('span', class_='math-container')\n",
    "    for element in latex_elements:\n",
    "        element.extract()\n",
    "    text_content = content_soup.get_text(separator=\" \", strip=True).replace('\\n', ' ')\n",
    "    latex_content = ' '.join([element.get_text(separator=\" \", strip=True) for element in latex_elements]).replace('$', '')\n",
    "    return text_content, latex_content       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2a29e1-c2d9-42d8-8bf2-cfd2cce4ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines_outside_dollar(text):\n",
    "    '''\n",
    "    Removes all \"\\n\" characters outside of LaTeX (i.e. outside of \"$\" delimiters).\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Raw text.\n",
    "\n",
    "    Returns:\n",
    "    cleaned (str): Cleaned text.\n",
    "    '''\n",
    "    # Split text by LaTeX parts\n",
    "    parts = re.split(r'(\\$.*?\\$)', text)  \n",
    "    cleaned_parts = []\n",
    "    \n",
    "    for part in parts:\n",
    "        # Keep LaTeX parts as they are, strip out newlines from all other parts. \n",
    "        if part.startswith('$') and part.endswith('$'):\n",
    "            cleaned_parts.append(part)\n",
    "        else:\n",
    "            cleaned_parts.append(part.replace('\\n', ' '))  # Remove newlines from non-LaTeX parts\n",
    "    cleaned = ''.join(cleaned_parts)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176b2bf5-3501-4a04-9bc6-ef421f7daedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_content(link):\n",
    "    '''\n",
    "    Gets title, body, and tags for a question. Also separates all text into text portions and LaTeX portions. \n",
    "\n",
    "    Parameters:\n",
    "    link (str): URL for the question.\n",
    "\n",
    "    Returns:\n",
    "    data_dict (dict): A dictionary containing all the data for the question.\n",
    "    '''\n",
    "    url = f'https://math.stackexchange.com{link}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    title = soup.select_one('.question-hyperlink').get_text(separator=\" \", strip=True)\n",
    "    title_text, title_latex = parse_title(title)\n",
    "    body = soup.select_one('.js-post-body')\n",
    "    body_raw = remove_newlines_outside_dollar(body.get_text(separator=\" \", strip=True))\n",
    "    body_text, body_latex = parse_body(body)\n",
    "    tags = []\n",
    "    tag_data = soup.find_all('li', class_='d-inline mr4 js-post-tag-list-item')\n",
    "    for tag in tag_data:\n",
    "        tags.append(tag.get_text())\n",
    "    data_dict = {'title_raw':title, 'title_text': title_text, 'title_latex': title_latex, \n",
    "            'body_raw': body_raw, 'body_text': body_text, 'body_latex': body_latex, \n",
    "            'tags':tags[:len(tags) // 2]} # Tags get repeated at bottom of every page\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f6b51-da3f-4464-8450-319a3758a285",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e503e9f-08d6-43ea-ade3-97bea1244696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 30 tags on Math Stack Exchange\n",
    "tags = [\n",
    "    'real-analysis',\n",
    "    'calculus',\n",
    "    'linear-algebra',\n",
    "    'probability',\n",
    "    'abstract-algebra',\n",
    "    'integration',\n",
    "    'sequences-and-series',\n",
    "    'combinatorics',\n",
    "    'general-topology',\n",
    "    'matrices',\n",
    "    'functional-analysis',\n",
    "    'complex-analysis',\n",
    "    'geometry',\n",
    "    'group-theory',\n",
    "    'algebra-precalculus',\n",
    "    'probability-theory',\n",
    "    'ordinary-differential-equations',\n",
    "    'limits',\n",
    "    'analysis',\n",
    "    'number-theory',\n",
    "    'measure-theory',\n",
    "    'statistics',\n",
    "    'multivariable-calculus',\n",
    "    'functions',\n",
    "    'derivatives',\n",
    "    'differential-geometry',\n",
    "    'discrete-mathematics',\n",
    "    'trigonometry',\n",
    "    'algebraic-geometry',\n",
    "    'elementary-set-theory'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824aa2f7-7993-483e-ab23-9cafeba75366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get 10,000 questions for each tag. Should take around two hours to run based on the average 1 second time.sleep() between calls.\n",
    "all_links = []\n",
    "for tag in tags:\n",
    "    curr_links = get_question_links(tag, num_pages=200)\n",
    "    all_links.extend(curr_links)\n",
    "    with open('links.txt', 'w') as f:\n",
    "        for link in all_links:\n",
    "            f.write(f'{link}\\n')\n",
    "    print(f'Gotten {len(curr_links)} questions for tag: {tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a80ab18-ceb6-4d0c-9dd6-f847bf92b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all links from file\n",
    "with open('links.txt') as f:\n",
    "    all_links = f.read().splitlines()\n",
    "all_links = list(dict.fromkeys(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d5f964-bb57-452b-921e-b275854fd751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gotten 234300 questions.\n",
      "Gotten 234400 questions.\n",
      "Gotten 234500 questions.\n",
      "Gotten 234600 questions.\n",
      "Gotten 234700 questions.\n",
      "Gotten 234800 questions.\n",
      "Gotten 234900 questions.\n",
      "Gotten 235000 questions.\n",
      "Gotten 235100 questions.\n",
      "Gotten 235200 questions.\n",
      "Gotten 235300 questions.\n",
      "Gotten 235400 questions.\n",
      "Gotten 235500 questions.\n",
      "Gotten 235600 questions.\n",
      "Gotten 235700 questions.\n"
     ]
    }
   ],
   "source": [
    "# Get question data for each link\n",
    "counter = 234200 # Has been reset each time I've restarted the program, hence why it isn't set to 0. \n",
    "curr_data = []\n",
    "for link in all_links[234200:]:\n",
    "    next_data = get_question_content(link)\n",
    "    time.sleep(random.uniform(0,1)) # Once again, used to hopefully not get banned. \n",
    "    curr_data.append(next_data)\n",
    "    counter += 1\n",
    "    if counter % 100 == 0: # Save data incrementally due to running this process on my local machine (sometimes have to restart). \n",
    "        print(f'Gotten {counter} questions.')\n",
    "        question_data = pd.DataFrame(curr_data)\n",
    "        question_data.to_csv(f'question_data/{counter-99}-{counter}.csv')\n",
    "        curr_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96849b6-92a7-47e3-8ac6-b68bfdcce8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
