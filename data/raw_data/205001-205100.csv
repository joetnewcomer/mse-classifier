question_id,title,body,tags
4069810,"How many 4-element DNA sequences containg exactly three of four bases A,T,C,G?","How many 4-element DNA sequences containg exactly three of four bases A,T,C,G?

Hello, my answer is c(4,3)*c(3,1)*(4!/2!) because

by saying c(4,3), I choose three of four bases, e.g. ATC_
by saying c(3,1), I choose extra one of chosen three bases, e.g. ATCT
by saying 4!/2!, I permutated them, i.e., there is 4!/2! possible permutations of ATCT. So, I found the answer as 144, but there is a solution on the internet like this: The objective is to find the 4 element DNA sequence that contain exactly three of the four bases A, C, G, and T.
Three of the four bases, but not with base A.
There are 3 ways for first base as it cannot be A.
There are 3 ways for second base as it cannot be A.
There are 2 ways for third base as it cannot be A and nor first or second base.
There are 1 way for fourth base as it cannot be A and nor first or second or third base.
By product rule, 3.3.2.1 =18.
Exactly three of four bases.
As there are 4 possible bases that are excluded and there are 18 DNA sequences without corresponding base but with three of the four bases.
By product rule, 4.18 = 72.
Therefore, there are 72 possible way for 4 DNA bases. I wonder which answer is correct 144 or 72? and if my solution with the answer 144 is correct, then why is the solution on the internet with answer 72 incorrect? or if my solution is incorrect, then why?","['combinatorics-on-words', 'discrete-mathematics']"
4069839,Relationship between law of large numbers and regression to the mean,"I hear both of these terms often explained independently of one another but to me it seems that the are very related. I know the law of large numbers deals with the cumulative average of successive observations while regression to the mean is about the next observation. But my thinking is as follows: If the proportion of heads in a 100 coin flips is .75, regression to the mean says that it is more likely that the proportion of heads in the next 100 coin flips would be less extreme. Wether that is as extreme in the opposite direction(say .25) or less extreme in the same direction(say .6), both cases ultimately lower the total proportion of heads over the 200 flips. This, at least when repeated many times, leads the the result of the law of large numbers. Or more generally each successive group of an arbitrary amount of flips is more likely to be less extreme then the previous so the cumulative average  of all of the groups, as the number a groups approach’s infinity, approaches the theoretical average. Is this a correct understanding of these two concepts?","['statistics', 'law-of-large-numbers', 'probability']"
4069898,Help with continuity of a multivariable piecewise function,"I need help finding if the limit of $g(x,y)$ at $(0,0)$ and at $(2,0)$ to see if it is continuous on these points. I get confused, because normally these piecewise functions are defined such that $(x,y)$ different than some $(a,b)$ but here I have no idea how to do it because I can approach $(0,0)$ or $(2,0)$ from both pieces of the function... And if I wanted to see the differentiability as well, what should I do? I would really appreciate if you could explain this to me. Thank you !","['multivariable-calculus', 'calculus', 'functions', 'limits', 'piecewise-continuity']"
4069929,Greatest number of occurrences of the pattern 4213 in a permutation.,"Statistic St000750 in the FindStat database is a map $\operatorname{St000750} \colon S_n \rightarrow \mathbb N_{\geq 0}$ given by The number of occurrences of the pattern $4213$ in a permutation. This is the number of length-4 substrings such that the first number is largest, the second is third-largest, the third is smallest, and the fourth is second-largest. For example, the permutation $\pi = 563214$ has $\operatorname{St000750}(\pi) = 6$ occurrences of this pattern: $$5324, 5314, 5214, 6324, 6314, \text{and}\ 6214.$$ I'm interested in computing $$
   a(n) = \max \{ \operatorname{St000750}(\pi) : \pi \in S_n\}
$$ By brute-forcing $0 \leq n \leq 9$ , I get that $a(0) = a(1) = a(2) = a(3) = 0$ , $a(4) = 1$ , $a(5) = 3$ , $a(6) = 6$ , $a(7) = 13$ , $a(8) = 24$ , and $a(9) = 40$ . Moreover, this sequence does not appear in the On-Line Encyclopedia of Integer Sequences . However, an analogous sequence for the pattern $132$ is A061061 , with a simple formula: $A061061(n) = \max\{A061061(k) + k\binom{n-k}{2} : 1 \leq k < n\}$ . Is there a way to compute this sequence which is better than brute force? If not, how can you construct a better upper bound than $a(n) \leq \binom{n}{4}$ ?","['permutations', 'oeis', 'combinatorics', 'discrete-optimization', 'pattern-recognition']"
4069948,Proof verification: $\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}=\ln(2)$,"Motivated by the beautiful identity $$\int_{0}^{\frac{\pi}{4}}\tan^{2n}(x)\text{ }dx=(-1)^n\left(\frac{\pi}{4}-\sum_{k=0}^{n-1}\frac{(-1)^k}{2k+1}\right)$$ and the equally beautiful proof of $$\sum_{n=0}^{\infty}\frac{(-1)^n}{2n+1}=\frac{\pi}{4}$$ that it implies, I decided to try and find a closed-form expression for $\int_{0}^{\pi/4}\tan^{2n+1}(x)dx$ . Following the method I used to establish the integral above (reduction formulae), I discovered this stunning identity, true for all $n\geq 1$ (also true for $n=0$ if you accept the empty sum convention). $$\int_{0}^{\frac{\pi}{4}}\tan^{2n+1}(x)\text{ }dx=(-1)^n\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right)$$ As you can probably see, this is very suggestive of the fact that $\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}=\ln(2)$ , so I naturally tried to leverage it in a proof. Here's my attempt: Proof : We'll begin by proving that $\int_{0}^{\pi/4}\tan^{2n+1}(x)\text{ }dx=(-1)^n\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right)$ . We do this with mathematical induction. The base case $n=1$ can be established as follows: \begin{align*}
\int_{0}^{\frac{\pi}{4}}\tan^{2(1)+1}(x)dx &= \int_{0}^{\frac{\pi}{4}}\tan^{3}(x)\text{ }dx\\
&= \int_{0}^{\frac{\pi}{4}}\tan(x)\left[\sec^2(x)-1\right]dx\\
&= \int_{0}^{\frac{\pi}{4}}\tan(x)\sec^2(x)\text{ }dx-\int_{0}^{\frac{\pi}{4}}\tan(x)\text{ }dx
\end{align*} Making the substitution $u=\tan(x)$ in the first integral gives \begin{align*}
\int_{0}^{\frac{\pi}{4}}\tan(x)\sec^2(x)\text{ }dx-\int_{0}^{\frac{\pi}{4}}\tan(x)\text{ }dx &= \int_{0}^{1}u\text{ }du-\left[\ln\left(\sec\frac{\pi}{4}\right)-\ln(\sec 0)\right]\\
&= \frac{1}{2}-\ln(\sqrt{2})\\
&= -\left(\frac{1}{2}\ln(2)-\frac{1}{2}\cdot 1\right)\\
&= (-1)^1\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{1}\frac{(-1)^{k-1}}{k}\right)
\end{align*} This proves the base case. If we assume that the identity is true for some $m\in\mathbb{N}$ , then \begin{align*}
\int_{0}^{\frac{\pi}{4}}\tan^{2(m+1)+1}(x)dx &= \int_{0}^{\frac{\pi}{4}}\tan^{2m+1+2}(x)\text{ }dx\\
&= \int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\tan^{2}(x)\text{ }dx\\
&= \int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\left[\sec^2(x)-1\right]dx\\
&= \int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\sec^2(x)\text{ }dx-\int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\text{ }dx
\end{align*} Like before we make the substitution $u=\tan(x)$ in the first integral. Leveraging our assumption, we get \begin{align*}
\int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\sec^2(x)\text{ }dx-\int_{0}^{\frac{\pi}{4}}\tan^{2m+1}(x)\text{ }dx &= \int_{0}^{1}u^{2m+1}\text{ }du-(-1)^m\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\\
&= \frac{1}{2m+2}-(-1)^m\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\\
&= \frac{(-1)^m(-1)^m}{2(m+1)}-(-1)^m\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\\
&= (-1)^m\left[\frac{(-1)^m}{2(m+1)}-\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\right]\\
&= (-1)^m\cdot -\left(-\frac{(-1)^{m}}{2(m+1)}+\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\\
&= (-1)^{m+1}\left(\frac{1}{2}\ln(2)-\frac{(-1)^{(m+1)-1}}{2(m+1)}-\frac{1}{2}\sum_{k=1}^{m}\frac{(-1)^{k-1}}{k}\right)\\
&= (-1)^{m+1}\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{m+1}\frac{(-1)^{k-1}}{k}\right)
\end{align*} This shows that it must be true for $m+1$ . Thus, mathematical induction implies that the identity is true for all natural numbers. We are now in a position to prove that $\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}=\ln(2)$ . Notice that \begin{align*}
\left|\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right| &= \left|(-1)^n\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right)\right|\\
&= \left|\int_{0}^{\frac{\pi}{4}}\tan^{2n+1}(x)\text{ }dx\right|\\
&= \int_{0}^{\frac{\pi}{4}}\tan^{2n+1}(x)\text{ }dx
\end{align*} since $\tan^{2n+1}(x)\geq 0$ for $0\leq x <\pi/2$ . We can bound the quantity $$\left|\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right|$$ by making the substitution $x=\tan^{-1}(t)$ on the last integral and proceeding as follows \begin{align*}
\int_{0}^{\frac{\pi}{4}}\tan^{2n+1}(x)\text{ }dx &= \int_{0}^{1}\frac{t^{2n+1}}{1+t^2}dt\\
&< \int_{0}^{1}t^{2n+1}\text{ }dt\\
&= \frac{1}{2n+2}\\
&= \frac{1}{2(n+1)}
\end{align*} This gives the upper bound $\left|\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right|<\frac{1}{2(n+1)}$ , or $$\left|\ln(2)-\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right|<\frac{1}{n+1}$$ Letting $n\to\infty$ and applying the squeeze theorem immediately gives the desired result. $$\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}=\ln(2)$$ Q.E.D. If correct, this argument is absolutely beautiful! Not only does it prove the equality $$\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}=\ln(2)$$ in a completely elementary fashion, it also establishes this absolutely astounding result: $$\int_{0}^{\frac{\pi}{4}}\tan^{2n+1}(x)\text{ }dx=(-1)^n\left(\frac{1}{2}\ln(2)-\frac{1}{2}\sum_{k=1}^{n}\frac{(-1)^{k-1}}{k}\right)$$ In particular, combining this with $\int_{0}^{\pi/4}\tan^{2n}(x)\text{ }dx=(-1)^n\left(\frac{\pi}{4}-\sum_{k=0}^{n-1}\frac{(-1)^k}{2k+1}\right)$ , we now have a recipe for evaluating $$\int_{0}^{\frac{\pi}{4}}\tan^{n}(x)\text{ }dx$$ for any natural number $n$ . How awesome it that?! Let me know what you think! If you have any suggestions for optimizing the proof or identify some logical errors, please don't hesitate to share them with me!","['solution-verification', 'sequences-and-series']"
4069974,What's the $\int_0^T (T - s) dW_s$?,"Let $W_{t}$ be a Wiener process on a standard filtered probability space $(\Omega ,{\mathcal {F}},{\mathcal {F}}_{t},P)$ and let ${\mathcal {G}}_{t}$ be the augmented filtration generated by $B$ . If $X$ is a square integrable random variable measurable with respect to ${\mathcal {G}}_{\infty }$ , then there exists a predictable process $\Theta$ which is adapted with respect to ${\displaystyle {\mathcal {G}}_{t}}$ , such that $$X = EX + \int_0^T\Theta_s dW_s$$ where $W$ is a Wiener process I want to prove that Ito representation of $X = \int_0^T W(s) ds$ is in form for $\Theta_s = (T-s)$ . My work so far Let's calculate the integral $$\int_0^T (T-s)dW_s = \int_0^T TdW_s - \int_0^TsdW_s = T\int_0^TdW_s - \int_0^TsdW_s=$$ $$= TW_T - \int_0^TsdW_s$$ And now I have two problems: $(1)$ Why $EX = E[\int_0^T W(s)ds] = 0 $ ? $(2)$ I'm not exactly sure how to calculate this integral $\int_0^TsdW_s$ . I read that partial integration should be used but I don't see how. Could you please give me a hand in justifying $(1)$ and $(2)$ ?","['stochastic-processes', 'martingales', 'probability-theory', 'probability']"
4069985,Last step in proof of comparison theorem of etale and singular cohomology,"I am trying to understand the argument in the very last sentence in the proof of Lemma 4.5 in SGA 4 Exposé XI, page 47 here: https://www.normalesup.org/~forgogozo/SGA4/tomes/tome3.pdf The argument that I am trying to understand is the following (english translation) ""since $H^1(X_{ét}, \mathbb{Z}/n\mathbb{Z})\to H^1(X_{cl}, \mathbb{Z}/n\mathbb{Z})$ is bijective, we immediately obtain the vanishing in 4.5 for $q=1$ "". Lemma 4.5 basically states the vanishing of $R^q \varepsilon_*\mathbb Z/n \mathbb Z$ for $q>0$ , so what we are trying to deduce is $R^1 \varepsilon_*\mathbb Z/n \mathbb Z=0$ . My idea was to use the exact sequence of low degree of the Leray spectral sequence \begin{align*}
 	H^p(X_{ét},R^q\epsilon_{*}\mathbb Z/n \mathbb Z) \Longrightarrow H^{p+q}(X_{cl},\mathbb Z/n \mathbb Z)
 \end{align*} induced by the morphism of sites $\epsilon \colon X_{cl} \to X_{ét}$ . This yields \begin{align}
0 \to H^1(X_{ét}, \epsilon_*\mathbb Z/n \mathbb Z) \to H^1(X_{cl}, \mathbb Z/n \mathbb Z) \to H^0(X_{ét}, R^1 \varepsilon_*\mathbb Z/n \mathbb Z) \to H^2(X_{ét}, \epsilon_*\mathbb Z/n \mathbb Z) \to H^2(X_{cl}, \mathbb Z/n \mathbb Z) 
\end{align} Now, knowing that the first map is an isomorphism doesn't seem to be enough to conclude that $H^0(X_{ét},R^1 \varepsilon_*\mathbb Z/n \mathbb Z)$ vanishes, so I am stuck here. Help with this argument, or an alternative argument, would be much appreciated.","['etale-cohomology', 'algebraic-geometry', 'abstract-algebra', 'proof-explanation']"
4069997,How does a 0-ball have volume 1?,"I've been reading about n-balls and I found in the Wikipedia article that in dimension 0, the volume of a 0-ball is 1. I have searched for more information but I can't find any resource explaining this. So, how does a 0-ball have volume 1?","['spheres', 'geometry', 'volume']"
4070114,Coin Distribution Problem- Combinations,"In how many ways can we distribute a single quarter, a single dime, a single nickel and 25 separate cents between $5$ children if a) we have no restrictions?
b) such that the oldest kid gets either $20$ cents or $25$ cents. a) $$\;\binom{1+5-1}{1}\times \binom{1+5-1}{1}\times \binom{1+5-1}{1}\times  \binom{25+5-1}{5} = 14,844,375$$ b) My textbook is a spanish translation of the original and the exercise is badly worded and I cannot find it in the english version, so I am confused. Please help me out.","['combinations', 'combinatorics', 'discrete-mathematics']"
4070115,Show $ \int_0^{\frac\pi2} \frac{(1+\sec^2t)\sqrt{\sec t}}{ (1+\sec t)^2-2}dt= \frac\pi{\sqrt2}$,"I try to figure out how to deal with the trigonometric integral $$ \int_0^{\frac\pi2} \frac{(1+\sec^2t)\sqrt{\sec t}}{ (1+\sec t)^2-2}dt
$$ which is supposed to be equal to $\frac\pi{\sqrt2}$ . Despite the simplicity of the result, it does not seem easy. What is troublesome is the square-root part in the integrand, which renders known techniques, such as half-angle substitution, ineffective. I also threw it into WA, which churns out a complicated antiderivative expression in elliptical functions not all that helpful.","['integration', 'trigonometric-integrals']"
4070182,Sections on locally ringed space as functions,"Notation/Introduction: Let $(X, \mathcal{O}_X)$ be a locally ringed space, $U \subseteq X$ an open and $p \in U$ . Denote by $\mathfrak{m}_p \lhd \mathcal{O}_{X,p}$ the unique maximal ideal and $k_p=\mathcal{O}_{X,p}/\mathfrak{m}_p$ the residual field at $p$ . Let $$
ev_p : \mathcal{O}_X(U) \to \mathcal{O}_{X,p} \to k_p \quad , \quad \quad p \in U
$$ and denote $f(p) = ev_p(f) \in k_p$ . Taking the product we define $$
ev = \mathcal{O}_X(U) \to \prod_{p \in U} \mathcal{O}_{X,p} \to \prod_{p \in U} k_{p} \quad, \quad \quad ev(f) = (f(p))_{p \in U}
$$ The question is: when $ev$ is injective? Well, let $f \in \mathcal{O}_X(U)$ such that $f(p) = 0$ , $\forall p \in U$ , then $f_p = \mathrm{stalk}_p(f) \in \mathfrak{m}_p = \mathcal{O}_{p, X} \setminus \mathcal{O}_{p, X}^{\times}$ . So $f|_V \notin \mathcal{O}_X(V)^{\times}$ for all open $V \subseteq U$ . Then what? If all stalks $\mathcal{O}_{X,p}$ are fields then $ev$ is injective (because $\mathcal{O}_X$ is a separated presheaf), but it is too restrictive if $X$ is not discrete. For schemes I know that $X$ be reduced is a sufficient condition, but what about the general case of locally ringed spaces? The case of schemes is reduced to affine schemes and the proof relies on commutative algebra (the intersection of all primes is the nil radical), so I can't use those ideas now (I guess). In some sense, this condition of $ev$ being injective is about understanding the abstract sheaf $\mathcal{O}_X$ as a sheaf of rings of functions (what sounds like a reasonable question to me).","['ringed-spaces', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
4070201,Suppose $X$ be the random variable that denotes the number of heads minus the number of tails when $10$ unbiased coins are tossed. Find the variance.,"Suppose an unbiased coin is tossed $10$ times. Let $X$ be the random variable that denotes the number of heads minus the number of tails. What is the variance of $X$ ? This seems to have the solution but I do not understand what it says. I am looking for an explanation of the link I shared. I am still sharing my solution so as to show I am not posting it without trying it at all. $\text{E}[X] = \displaystyle\sum_{h=0}^{10} \left(\frac{{10 \choose h}}{2^{10}} (h - (10-h))\right) = \frac{1}{2^{9}} \displaystyle\sum_{h=0}^{10} {10 \choose h} (h-5) = 0$ $\text{E}[X^2] = \displaystyle\sum_{h=0}^{10} \left(\frac{{10 \choose h}}{2^{10}} (h - (10-h))^2\right) = \frac{1}{2^{8}} \displaystyle\sum_{h=0}^{10} {10 \choose h} (h-5)^2 = 10$ This gives $\text{Var}[X] = \text{E}[X^2] - \text{E}[X]^2 = 10 - 0^2 = 10$ . This is how I did, considering the PMFs.","['statistics', 'probability-theory', 'probability']"
4070231,"Limit of $\int_0^1\left(\frac {2}{\sqrt {(1-t^2)(1-xt^2)}}-\frac{x}{1-xt}\right)\,dt$ as $x\to 1^{-}$","While going through this question I was reminded of one of my earlier questions and I found that there is some unfinished business which needs some further exploration. Let $$F(x) =\int_0^1\left(\frac{2}{\sqrt{(1-t^2)(1-xt^2)}} -\frac{x}{1-xt}\right)\, dt=\int_0^1 f(x, t) \, dt\tag{1}$$ for $x\in[0,1]$ . Let's observe that $$\lim_{x\to 1^-}f(x,t)=\frac{1}{1+t}\tag{2}$$ and hence it is natural to expect that $\lim_{x\to 1^-}F(x)$ should equal $\int_0^1 dt/(1+t)=\log 2$ but numerical evidence as well as some amount of elliptic function theory tells (see one of my questions linked earlier for details) us that this particular limit is $4\log 2$ . This suggests that there is some weird behavior of integrand as $x\to 1^{-}$ (in particular the convergence is not uniform). I would like to have this limit evaluated using some analysis related to convergence of integrand as $x\to 1^-$ . Any help in this direction would be appreciated. Note : I have asked a new question instead of bumping an old one. The old question is more about solution verification and is related to elliptic integrals. I wanted to have a different perspective which involves general issues of uniform convergence to handle the limit of this integral.","['integration', 'limits', 'real-analysis']"
4070280,Can anyone tell me if my proof is right?,"Let $0<a<b,$ compute $\lim_{n\to \infty}{\frac{a^{n+1}{+}b^{n+1}}{a^n+b^n}}$ My proof are followings : Assuming that $r=b-a>0,$ so $b=a+r.$ So the original formula equals to $\frac{a\cdot a^{n}{+}{(a+r)\cdot}b^{n}}{a^n+b^n}=a+\frac{r\cdot b^n}{a^n+b^n}=a+\frac{r}{1+(a/b)^n},$ so it can limit to $a+r=b.$ From my point of view, I think that the results should contain $a,$ however my result contains no $a.$ I am a self learner, I don't know wheather my result is right. Hope that someone can help me out.","['calculus', 'sequences-and-series']"
4070302,"Evaluating $\int_0^{\pi/2} \log(1 - x \cot x) \, dx\;$ (Is there a closed form?)","I am interested in knowing if it is possible to find a closed-form solution to the following challenging log-cotangent integral $$\int_0^{\frac{\pi}{2}} \log(1 - x \cot x) \, dx$$ I very much doubt a closed form in terms of known mathematical constants can be found and have no reason to suspect one exists. In the absence of a simple closed-form value being found, maybe the integral can be evaluated in terms of an infinite series. In this direction, since $0 < x \cot x < 1$ for all $x \in (0,\frac{\pi}{2})$ the log term appearing in the integrand can be expanded. Doing so produces $$\int_0^{\frac{\pi}{2}} \log(1 - x \cot x) \, dx = -\sum_{n = 1}^\infty \frac{1}{n} \int_0^{\frac{\pi}{2}} (x \cot x)^n \, dx = -\sum_{n = 1}^\infty \frac{a_n}{n},$$ where $$a_n = \int_0^{\frac{\pi}{2}} (x \cot x)^n \, dx. \tag1$$ Noting that \begin{align*}
a_1 &= \int_0^{\frac{\pi}{2}} x \cot x \, dx = \frac{\pi}{2} \log (2)\\
a_2 &= \int_0^{\frac{\pi}{2}} (x \cot x)^2 \, dx = \pi \log (2) - \frac{\pi^3}{24}\\
a_3 &= \int_0^{\frac{\pi}{2}} (x \cot x)^3 \, dx = \frac{9\pi}{16} \zeta (3) - \frac{\pi^3}{16} + \frac{3\pi}{2} \log (2) - \frac{\pi^3}{8} \log (2),
\end{align*} perhaps it is possible to find a general expression for $a_n$ . Indeed, an attempt at finding (1) can be found here . Any other approaches or suggestions to this challenging integral would be welcome.","['integration', 'improper-integrals', 'definite-integrals']"
4070306,Is $\mathbb{Q} \times \mathbb{Q}$ a $G_\delta$ set?,"I can prove that $\mathbb{Q}$ is not a $G_\delta$ set in $\mathbb{R}$ . I was applying the same Baire space argument to show that $\mathbb{Q} \times \mathbb{Q}$ is not a $G_\delta$ set. I was thinking like this: We can write $(\mathbb{Q} \times \mathbb{Q})^c= \displaystyle{\bigcap_{(p,q)\in \mathbb{Q} \times \mathbb{Q}}\{(p,q)\}^c}= \displaystyle{\bigcap_{n=1}^{\infty}V_n}$ where each $V_n$ is open in $\mathbb{R}^2$ . If we can write $\mathbb{Q} \times \mathbb{Q}= \displaystyle{\bigcap_{n=1}^{\infty}U_n}$ where each $U_n$ is open in $\mathbb{R}^2$ . Then $\displaystyle{\bigcap_{n=1}^{\infty}(U_n \cap V_n)}= \phi$ is dense in $\mathbb{R}^2$ -----which is a contradiction.! Am I thinking correctly ? Please help. Thanks in advance.","['multivariable-calculus', 'general-topology', 'the-baire-space', 'functional-analysis']"
4070316,Why are there repeated patterns in Ulam spiral for multiples?,"I had recently, just about a year ago, “discovered” that there are easy to see, clear patterns if you look at the Ulam spiral and just highlight the multiples for numbers. By Ulam spiral I just mean the layout of spiralling out natural numbers. These patterns are repeated in x and y direction. Here are some examples, for multiples of n=22 and n=31 Note that these patterns appear for any scalar and its multipliers. There are no exceptions. Needless to say, “prime numbers” live in points where some of these patterns appear for the first time, and never again. I have considered that this may be the reason why prime numbers seem to favour “diagonals”, because the multiplier patterns repeat clearly in x/y direction and not chaotically at all - but have not clearly been able to formulate this. Since the Ulam spiral is based on tracing back the squares of all odd numbers (every bottom-right point - in some orientations this may be the bottom left, - is the next square of an odd number), this means that there are some “formula” F in $(2x+1)^2$ that all resolve to multipliers of a scalar, and these formula are dependent on some constants and $x$ only. So far, I can only explain this for the pattern that appears at $n = 4$ , where I can indeed see a formula in $(2n+1)^2-1$ which resolves to $4n^2+4n$ which obviously generates multipliers of 4. I have not dared to “do the math” on the other patterns, which are more complex. Now, a year has gone by and I have been thinking about this a lot, and it is driving me mad. Could someone help me clear this up so I can let this matter rest?
I wrote a little more about it here - I might have gone into too much assumption in my initial enthusiasm on describing this “discovery” which may ultimately be only a trivial fact in arithmetics. My question, what could be an explanation for the appearance of these repeated patterns? https://github.com/buddhabrot/UlamAnalysis/blob/main/README.md","['number-theory', 'prime-numbers']"
4070325,How to use the trace of matrix to prove this problem?,"Let $A,B$ be a square matrix of order $n$ and $$A B - B A = A^m$$ where $m \geqslant 1$ . Prove that $|A|=0$ . I got that $$\mathrm{tr}(A^m)=\mathrm{tr}(AB-BA)=\mathrm{tr}(AB)-\mathrm{tr}(BA)=0$$ but I don't know the next steps.","['matrices', 'linear-algebra']"
4070342,Find a value of $\;\lim\limits_{n\rightarrow\infty}n\left ( 1- a_{n} \right )$,"I'm going to give you an extremal problem. Given $a_{n}:=\left ( \text{the solution for the equation}\,x^{n}= \cos x,\quad x> 0 \right ),$ find a value of $$\lim_{n\rightarrow\infty}n\left ( 1- a_{n} \right )$$ Source: Fujino_Yusui If you imagine the graph of $x^{n},$ it should intersect at the point where it increases rapidly by $1,$ which is about where $x^{n}= \cos 1\,(y$ is increasing rapidly, so if you look at $y,$ you should be able to approximate $x$ well enough $).\,n\left ( 1- \cos^{\frac{1}{n}}1 \right )$ looks good, and $\frac{1}{n}= h$ is the derivative of $h\rightarrow 0^{+}.$ I guess $-\ln\cos 1$ by definition.","['limits', 'trigonometry', 'derivatives']"
4070391,If a function is not defined at a point then will its inverse be defined at that point?,"I have a function $y=\frac{x-2}{x-3}$ clearly the function is not defined at $x= 3$ But for its inverse $ \frac{3x-2}{x-1},$ can we say that it is defined at $x= 3$ ?",['functions']
4070428,Find a value of $\;\lim\limits_{n\rightarrow\infty}\frac{a_{n}}{n}$,"(If you're good at it, you can do it by heart.) Let $a_n$ be the average value of lengths of all the diagonal lines of regular n-gon whose side is 1. Find a value of $$\lim_{n\rightarrow\infty}\frac{a_{n}}{n}$$ Source: Fujino_Yusui After messing around with the cosine theorem and doing some calculations, I found the exact formula of $a_{n},$ so I did the rest of the calculations and the answer is $$\lim_{n\rightarrow\infty}\frac{a_{n}}{n}= \lim_{n\rightarrow\infty}\frac{2\cos\frac{\pi}{n}- 1}{\left ( \left ( 1- \cos\frac{\pi}{n} \right )n \right )\left ( n- 3 \right )}= \frac{2}{\pi^{2}}$$ But I want to see a shortcut that leads $a_{n}\sim\frac{n}{2\pi}\cdot\frac{4}{\pi}\,{\rm as}\,n\rightarrow\infty$ without cosine theorem, I need to the help.","['limits', 'trigonometry']"
4070430,Probability of some dice rolls,"Question A fair six-sided die is rolled $12$ times. Find the probability that each of the six possible outcomes ( $1$ , $2$ , $3$ , $4$ , $5$ and $6$ ) come up at least once. My working Let $X_n$ be the random variable denoting the number of times $n$ appears, out of $12$ rolls. For example, $X_1$ will be the random variable denoting the number of times $1$ appears, out of $12$ rolls. Then, $$X_n \sim B(12, \frac 1 6)$$ and the required probability is \begin{align}
P(X_1 \geq 1)P(X_2 \geq 1)P(X_3 \geq 1)P(X_4 \geq 1)P(X_5 \geq 1)P(X_6 \geq 1) & = [P(X \geq 1)]^6
\\[5 mm] & =
[1 - P(X = 0)]^6
\\[5 mm] & =
\left[1 - \left(\frac 5 6\right)^{12}\right]^6
\\[5 mm] & \approx
0.490
\end{align} Answer The solution by my professor gives the required probability as $$1 - 
\left[\binom 6 1 \left(\frac 5 6\right)^{12} - \binom 6 2 \left(\frac 4 6\right)^{12} + \binom 6 3 \left(\frac 3 6\right)^{12} - \binom 6 4 \left(\frac 2 6\right)^{12} + \binom 6 5 \left(\frac 1 6\right)^{12}\right] \approx 0.438.$$ The solution does come with an explanation, but I am very confused by it, so I am hoping to find more intuitive suggestions on why my working is wrong as well as how to go about approaching the problem.","['dice', 'probability-theory', 'probability']"
4070437,Show that $\frac{\arctan(x^2)}{\ln(1+x^2)}$ is bounded by $\frac{1+\sqrt{2}}{2}$,"Given $F(x) = \frac{\arctan(x^2)}{\ln(1+x^2)},$ which is defined for $x>0.$ I would like to show that it is bounded above by $\frac{1+\sqrt{2}}{2}$ . I tried to differentiate the function in order to find maximal points however I've reached an equation which I don't know how to solve : $$F'(x) = \frac{\frac{2x}{1+x^4}\ln(1+x^2)-\arctan(x^2)\frac{2x}{1+x^2}}{\ln^2(1+x^2)}\overset{{\rm ?}}{=}0$$ Any help would be appreciated.","['maxima-minima', 'calculus', 'functions', 'derivatives']"
4070495,Counting interpretation of $\sum^{n}_{i=0}\binom{n}{i}i^n$,"$$\sum^{n}_{i=0}\binom{n}{i}i^n$$ I can't find a counting interpretation of this formula. I thought of using the binomial theorem but I don't think it applies here. So, I am not sure how to begin.","['summation', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
4070497,Why $\frac{y’}{y}$ is equivalent to $(\ln|y|)’$?,"I just read a proof process from a textbook about differential equations, it has following content : $$y’= ay\implies\frac{y’}{y}= a\implies (\ln|y|)’= a$$ I want to know why $\frac{y’}{y}$ is equivalent to $(\ln|y|)’$ ?","['calculus', 'ordinary-differential-equations']"
4070537,An entire function which is onto,"Prove that $\sin z - z$ is surjective, z $\in \mathbb C$ $\sin z - z$ is an entire function and hence by Little Picard its image can omit at most one complex number. I am unable to arrive at a contradiction from here on. Is there a way out! Please help.",['complex-analysis']
4070687,Formula for number of surjective functions in case where codomain is greater than domain,"We were deriving the formula for number of surjective functions from f: $X \to Y$ , where $|X| = n$ and $|Y| = m$ . The formula that we have is: $$\sum_{k=0}^m(-1)^k (m-k)^n {m \choose k}$$ Now, if $m>n$ we have no surjective functions, as codomain is greater than domain and the answer should be zero. The formula gives the right answer, but I cannot figure out why does it work algebraically. Any hints on why does this sum equals to zero when $m > n$ ?","['functions', 'combinatorics', 'discrete-mathematics']"
4070703,Prove Positivity of a Function Involving $\log$.,"I want to prove The function $f:(0,\infty)^2 \to \mathbb{R}$ defined by \begin{equation}\label{key}
			f(x,y) =  \ln \left( \dfrac{1+y}{1+ x}\right) + \dfrac{x}{1+ x} \ln \left( \dfrac{x}{y}\right)
		\end{equation} is non-negative. My attempt was to compute $\dfrac{\partial f}{\partial y}$ and then see where the zeros of the function are. I think that works fine, but I was wondering if there was a slicker way to do it.","['logarithms', 'real-analysis', 'calculus', 'functions', 'inequality']"
4070706,Circle group not a simple group,"In the theory of Lie groups, a simple Lie group is defined as a connected non-abelian Lie group $G$ which does not have nontrivial connected normal subgroups. Only the non-abelian condition excludes the circle group $\mathbb{T}$ from the list of simple groups. In categorical terms, a simple object is defined as an object which has exactly two quotient objects: the $0$ object and itself. Hence in the category of Lie groups this gives the definition of simple Lie group above except for the non-abelian condition. Is there a way to arrive to this definition from the categorical definition? Restricting to the category of non-abelian Lie groups does not seem like a suitable idea since one would ultimately want to talk about the circle or torus groups in one way or another. In any case, why should one exclude the circle group from the definition?","['lie-groups', 'category-theory', 'differential-geometry']"
4070749,A particular relation between two matrices,"I'd like to consider the consequences of the following relation between two symmetric square matrices $A$ and $B$ $$SA^{-1}S^T=B$$ $$S^TB^{-1}S=A$$ There are no inversion conditions on the matrix $S$ . Now, say we have the eigenvalues/vectors of $A$ , can we say anything about the eigenvalues/vectors of $B$ ? Edit: I might also add the conditions on $S$ $$S^TS=aA^2$$ $$SS^T=bB^2$$ where $a$ and $b$ are real numbers.","['matrices', 'linear-algebra']"
4070780,Set theory self taught (check if my logic is okay),"I am a beginner in set theory and I really do not feel confident writing proofs so a help would be much appreciated. I am not a mathematician by any stretch but I always felt like math is an essential tool and so I am setting myself into this adventure of learning it.
Here's where I am struggling: Problem: let $R$ be a binary relation Proof that $R^{-1}[R[A]]\supseteq A\cap domR$ with $domR$ being the domain of $R$ and $ranR$ being its range My proof :) ""Don't laugh"" $R^{-1}[R[A]]=\{x:x \; \in  dom R \; and \; \exists y\;(y \in R[A] \; and \; xRy)\}$ which mean $R^{-1}[R[A]]=\{x:x \; \in  dom R \; and \; \exists y \; \exists x' \; (y \in ran R \; and \; x' \in A  \; and \; \; x'Ry\; and \; \; xRy)\}$ Now let $x \in A \cap domR $ then $x \in domR \; and \; \exists y \exists x'(y \in ran R\; and \;x'=x \in A\; and \;xRy) $ Thus $x \in R^{-1}[R[A]]$ Should I give up and do something more productive with my life?","['elementary-set-theory', 'solution-verification']"
4070783,Manageable project to learn some arithmetic geometry,"OK, this may be an unusual question, since I'm asking you for advice, the way I would ask a supervisor were I a grad student. I am a thirty-something maths teacher with an unresolved attraction to arithmetic geometry, and would like to know more about themes I find fascinating when I read texts about arithmetic geometry, such as: the local-global principle the way geometry influences the arithmetic behaviour of Diophantine equations, like in Faltings's theorem the way scheme theory helps number theory by making a lot of geometric constructions possible, starting from base change One of the reasons this attraction is unresolved is that I never managed to seriously learn enough algebraic number theory, algebraic geometry, etc. in a ""bottom-to-top"" way: I have often started to read for instance R. Vakil's The rising sea , D. Eisenbud & J. Harris The geometry of schemes or Q. Liu's Algebraic geometry and arithmetic curves and find them to be very good texts, but I don't have the stamina to ingest hundreds of pages without a more specific goal. Because of this there are a number of subjects I'm vaguely familiar with, but don't know in any depth. For instance, I know what a scheme is, I even think I understand in part their raison d'être, but am probably unable to pass an scheme theory exam (and the same goes for elliptic curves, derived categories, class field theory...). To change this, I would like to try and understand a specific result and working my way from the top down to acquire the needed skills. The result has to be interesting enough to preserve my motivation in the long run, but ""small"" enough so that I could realistically understand it in a few months. I would love it to really mix number theory and geometry. So the question is: what theorem would constitute a reasonable-size project? Personal facts that might be relevant: my PhD is in low-dimensional topology, so I'm quite comfortable with things like cohomology and Riemann surfaces, and I like it when geometric intuition is useful. Large doses of homological algebra or category theory don't frighten me.","['algebraic-geometry', 'soft-question', 'arithmetic-geometry', 'reference-request']"
4070786,"Prove that $\lim_{(x, y) \to (0, 0)} \frac{xy}{\sin(x^2+y^2)}$ does not exist.","I'm trying to prove that $$\lim_{(x, y) \to (0, 0)} \frac{xy}{\sin(x^2+y^2)}$$ does not exists. To do so, I'm trying to find two different sequences $\{\bar{a_n}\}$ , $\{\bar{b_n}\}$ such that $\{\bar{a_n}\} \to (0, 0), \{\bar{b_n}\} \to (0, 0)$ and $$\lim_{n\to\infty} f(\bar{a_n}) = L_1 \not = L_2 = \lim_{n\to\infty} f(\bar{b_n})$$ Def. Let $f: A\subseteq \mathbb{R^2} \to \mathbb{R}, (x_0, y_0) \in \mathbb{R^2}$ accumulation point of $A.$ We say that $$\lim_{(x, y) \to (x_0, x_0)} f(x, y) = L \Longleftrightarrow$$ if $\forall \{\bar{a_n}\}$ such that $\forall n\in\mathbb{N}, \bar{a_n} \in A, \bar{a_n}\not = (x_0, y_0)$ and $\lim_{n \to \infty} \bar{a_n} = (x_0, y_0),$ then $$\lim_{n \to \infty} f(\bar{a_n}) = L$$","['limits', 'multivariable-calculus']"
4070788,"Given a coin that produces the probability $\lambda$, what is a constructive way to produce $f(\lambda)$, where $f$ is continuous non-Hölder?","Given a coin of ""bias"" $\lambda$ , sample the probability $f(\lambda)$ . This is the Bernoulli factory problem , and it can be solved only for certain functions $f$ . (For example, flipping the coin twice and taking heads only if exactly one coin shows heads, we can simulate the probability $\lambda(1-\lambda)$ .) Usually, the Bernoulli factory problem can be solved for $f$ if and only if— $f$ is continuous in $[0, 1]$ , and $f$ is identically $0$ , identically $1$ , or polynomially bounded away from $0$ and $1$ (roughly speaking, the function takes on only values in $ [0, 1]$ and its graph doesn't touch $0$ or $1$ except at the points $0$ and/or $1$ ) (Keane and O'Brien 1994). This question is a continuation of another question of mine , but this time we focus on the case when $f(\lambda)$ is a continuous non-Hölder function , which roughly means a continuous function with an exponentially steep slope (steeper than any $n$ th-root). The question just linked to seeks ways to compute polynomials that converge from above and below to $f$ in a manner that solves the Bernoulli factory problem for $f$ . These polynomials form an approximation scheme for $f$ . See that question for a formal statement of such approximation schemes. There are two algorithms (one by Thomas and Blanchet $2012$ , another by Łatuszyński et al.) to simulate a function $f$ via an approximation scheme. Roughly speaking, the algorithms work as follows: Generate U, a uniform random number in $[0, 1]$ . Flip the input coin (with ""bias"" $\lambda$ ), then build an upper and lower bound for $f(\lambda)$ , based on the outcomes of the flips so far. In this case, these bounds come from two degree- $n$ polynomials that approach $f$ as $n$ gets large, where $n$ is the number of coin flips so far in the algorithm. If U is less than or equal to the lower bound, return 1. If U is greater than the upper bound, return $0$ . Otherwise, go to step $2$ . The result of the algorithm is $1$ with probability exactly equal to $f(\lambda)$ , or $0$ otherwise. In general, the rate at which a function can be simulated by these algorithms depends on the smoothness of $f$ . It roughly corresponds to the rate of convergence of an approximation scheme for $f$ . I list approximation schemes for different kinds of functions $f$ , which work with the two algorithms described above. For example, roughly speaking, a $C^0$ continuous function $f$ can be simulated at the rate $O(n^{\alpha})$ only if $f$ is $\alpha$ -Hölder continuous (Holtz et al. 2011). This seems to imply that a function not meeting a Hölder condition (a non-Hölder function) can achieve, at best, a simulation rate of $O(1)$ , so that the polynomials won't necessarily converge uniformly for all $\lambda \in [0, 1]$ and for all non-Hölder functions, so that the algorithms above won't terminate in all cases. And this suggests to me that we need to add the following extra condition to the Bernoulli factory problem, since it appears that no approximation scheme exists for non-Hölder functions: $f$ is $\alpha$ -Hölder continuous in its domain for some $\alpha > 0$ . Is this true? Is there really no algorithm to sample the probability $f(\lambda)$ for a non-Hölder function $f$ , given sample access to the probability $\lambda$ ? This suggests that a different approach may be needed for Hölder functions. Thus: Is there a constructive method to approximate non-Hölder functions with polynomials for the Bernoulli factory problem (in the form of a formula to compute their coefficients), so that we can sample the probability $f(\lambda)$ for a non-Hölder function $f$ , given sample access to the probability $\lambda$ ? Note: An example of a non-Hölder function is the following, with a ""cusp"" at $0$ : $1/10$ if $\lambda = 0$ , and $-1/(2*\ln(\lambda/2))+1/10$ otherwise. Another example is the following, where the cusp is at $3/10$ : $1/10$ if $\lambda = 3/10$ , and $-1/(2*\ln(\frac{|\lambda-3/10|}{2}))+1/10$ otherwise. A third example is the following monotone function: $3/10$ if $\lambda = 3/10$ , $1/(2*\ln(\frac{3/10-\lambda}{2}))+3/10$ if $\lambda < 3/10$ , and $-1/(2*\ln(\frac{\lambda-3/10}{2}))+3/10$ otherwise. Roughly speaking: A non-Hölder function is continuous but has an exponentially steep slope. If a continuous function has no vertical slope, the function is 1-Hölder continuous. REFERENCES: Thomas, A.C., Blanchet, J., "" A Practical Implementation of the Bernoulli Factory "", arXiv:1106.2508v3 [stat.AP], 2012. Łatuszyński, K., Kosmidis, I., Papaspiliopoulos, O., Roberts, G.O., ""Simulating events of unknown probabilities via reverse time martingales"", arXiv:0907.4018v2 [stat.CO], $2009/2011$ . Keane, M. S., and O'Brien, G. L., ""A Bernoulli factory"", ACM Transactions on Modeling and Computer Simulation 4(2), 1994. Holtz, O., Nazarov, F., Peres, Y., "" New Coins from Old, Smoothly "", Constructive Approximation $33$ ( $2011$ ). Update: I have become aware of so-called Dini-continuous functions , which are a superset of Hölder continuous functions. Essentially, a Dini-continuous function has a slope no ""steeper"" than that of $\phi(\lambda)$ for some increasing non-negative function $\phi$ with a finite integral of $\phi(\lambda)/\lambda$ over $[0, 1]$ . However, I haven't found any paper yet on the rate at which polynomials can approximate a Dini-continuous (but not Hölder-continuous) function (let alone in a manner that solves the Bernoulli factory problem). Moreover, the following function, adapted from this question , is apparently not even Dini continuous: $1/10 + (1/(1+|\ln(\lambda)|))/2$ if $\lambda>0$ , and $1/10$ otherwise.","['simulation', 'approximation-theory', 'polynomials', 'holder-spaces', 'probability']"
4070808,Solve $\left\lfloor x - 1/2 \right\rfloor^2 = 25$,"I would just like to confirm my approach to this equation: $$\lfloor x - 1/2 \rfloor^2 = 25$$ Now square root both sides $$\lfloor x - 1/2\rfloor = \pm5.$$ By the definition of floored value we have $$\lfloor x - 1/2 \rfloor \leqslant x - 1/2 < \lfloor x - 1/2 \rfloor + 1.$$ Now, when the the floor expression is equal to $5$ we find that \begin{align*}
    5 &\leqslant x - 1/2 < 5+1 \\
    11/2 &\leqslant x < 13/2
\end{align*} Similarly, if the expression is equal to $-5$ we find that \begin{align*}
    -5 &\leqslant x - 1/2 < -5 + 1 \\  
    -9/2 &\leqslant x < 7/2  
\end{align*} Now, can I say that the solution groups are: $[-9/2,-7/2)\cup[11/2,13/2)$ ? Or is there something I'm missing, thank you.","['algebra-precalculus', 'solution-verification', 'ceiling-and-floor-functions']"
4070818,Prove that $\tan(x)\tan(x+r) = \frac{\tan(x+r) - \tan(x)}{\tan r} -1$,"$\tan(x)\cdot \tan(x+r) = \dfrac{\tan(x+r) - \tan(x)}{\tan r} -1$ I tried L.H.S = $\dfrac{\sin(x)\cdot \sin(x+r)}{\cos(x)\cdot \cos(x+r)}$ = $\dfrac{\sin(x+r- x)}{\sin(r)}\dfrac{\sin(x)\cdot\sin(x+r)}{\cos(x)\cdot \cos(x+r)}$ = $\dfrac{\sin(x+r- x)}{\sin(r)}\dfrac{\sin(x)\cdot\sin(x+r)}{\cos(x)\cdot\cos(x+r)}$ = $\dfrac{\sin(x)\cdot\sin(x+r)}{\sin(r)}\dfrac{\sin(x+r)\cos(x) - \cos(x+r)\cos(x)}{\cos(x)\cdot \cos(x+r)}$ = $\dfrac{\sin(x)\cdot\sin(x+r)}{\sin(r)}\left(\tan(x+r) -\tan(x)\right)$ I get stuck here; what else is there to do? Edit: using Tavish's hint , we can get it directly. $$\tan(x+r -x) = \dfrac{\tan(x+r) - \tan(x)}{1 + \tan(x+r)\tan(x)}$$ $$1 + \tan(x+r)\tan(x)= \dfrac{\tan(x+r) - \tan(x)}{\tan(r)}$$ $$\tan(x+r)\tan(x) = \dfrac{\tan(x+r) - \tan(x)}{\tan(r)} -1$$","['algebra-precalculus', 'trigonometry']"
4070820,Lie bracket of tangent vectors in a submanifold is tangent to the submanifold,"Let $M$ be a smooth manifold and $N$ a submanifold of $M$ . Let $X$ and $Y$ be vector field of $N$ . We know that the differentials on $M$ of those vector fields $d_XY$ and $d_YX$ are not necessarily tangent to $N$ , and so we need to project them on to $TN$ to define a connection on $N$ . However, looking at the proof in my course that the projected connection is torsion free (for $M=\mathbb R^n$ ), it seems like the same is not true for the Lie bracket on $M$ defined by $[X,Y]=d_XY-d_YX$ which is tangent to $N$ without needing to be projected. Why is this true?","['submanifold', 'connections', 'lie-derivative', 'smooth-manifolds', 'differential-geometry']"
4070890,Finding extremum of quadratic function using factorisation as symmetry operation.,"In this book in Section 3.2.3, the author shows how to find extremum of a quadratic function using an invariant quality and symmetry operation, which preserves it. E.g. to find the extremum of $f(x)=6x-x^2$ we can notice that $f(x)=6x-x^2 = x(6-x) = (6-x)x$ . This operation maps every value $x$ to $6-x$ through the axis of symmetry and vice-versa (e.g. 0 is mapped to 6 and 6 mapped to 0). This operation preserves symmetry for $x=3$ - the axis of symmetry and hence the extremum of the function. What about the function $f(x)=6x+x^2 = x(6+x) = (6+x)x$ ?
We know that the minimum of this function is at $x=-3$ but $6+(-3)=3$ .
Also this operation maps e.g $4$ to $10$ , but $10$ to $16$ ! Hence, this approach fails with this example (symmetry is not preserved). Why is that so? Why is this approach not working for all the quadratic functions?","['algebra-precalculus', 'functions', 'quadratics', 'symmetry']"
4070917,"Show that there exist $n, m \in \mathbb{Z}\setminus\{0\}$ such that $\alpha^n = \beta^m$, without computing $n, m$. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $K = \mathbb{Q}(\sqrt{13})$ , $ \alpha = (3+\sqrt{13})/2$ and $\beta = 23382 + 6485\sqrt{13}$ . Show that there exist $n, m \in\mathbb{Z}\setminus\{0\}$ such that $\alpha^n = \beta^m$ , without computing $n, m$ . How would I show this? The norms I believe are both -1, so they must differ by a unit, but I do not know how to proceed, can I use Dirichlet's theorem or not? Any hints would be welcome","['number-theory', 'measure-theory', 'algebraic-number-theory', 'algebraic-groups']"
4070922,"Sum=Integral? Find $m$ so that $\sum _{n=1}^{\infty } \frac{n^m}{e^{2 \pi n}-1}=\int_0^{\infty } \frac{x^m}{e^{2 \pi x}-1} \, dx$","This question asked for a derivation of the interesting relation $$\sum_{n=1}^{\infty}  \frac{n^{13}}{e^{2 \pi n}-1} = \frac{1}{24}$$ In an attempt to answer this problem I played around a bit and was surprised that the related integral $$\int_{0}^{\infty}  \frac{n^{13}}{e^{2 \pi n}-1} \,dn= \frac{1}{24}$$ has the same nice result. Notice that the sum starts at $n=1$ and the integral starts at its ""natural"" boundary $0$ . Defining more generally $$S(m) = \sum_{n=1}^{\infty}  \frac{n^m}{e^{2 \pi n}-1}\tag{1a}$$ $$i(m) = \int_{0}^{\infty}  \frac{n^m}{e^{2 \pi n}-1} \,dn\tag{1b}$$ We can ask for which $m$ sum and integral lead to equal values, i.e. $$S(m) = i(m)\tag{2}$$ It turns out that equality seems to happen if and only if $m=4k+1, k=1,2,3...$ . This picture shows a discrete plot of the quotient $\frac{S(m)}{i(m)}$ of sum and integral. Questions: (1) Find all natural solutions $m$ of equation $(2)$ (2) Find an analytic continuation of $S(m)$ to real $m$ and study if the quotient $S(m)/i(m)$ is unity for other values Hints (for derivations see ): a) the integral has a closed expression which is not restricted to natural values of $m$ $$i(m)= \frac{1}{(2 \pi )^{m+1} } \zeta (m+1) \Gamma (m+1)\tag{3}$$ Here $\zeta(x)$ is the Riemann zeta function. b) the sum has a closed expression for $m=1,2,3,...$ as well $$S(m)=\frac{(-1)^{m+1} \psi _{e^{-2 \pi }}^{(m)}(1)}{(2 \pi )^{m+1}}\tag{4}$$ Here $\psi _{q}^{(m)}(x)$ is the $m$ -th derivative of the $q$ -digamma function with respect to x. EDIT: after a comment of @Jean Marie I saw that Marko Riedel has derived as a special case of $(4)$ for $m=4k+1$ the simplified formula $$S(4 k+1)=\frac{B_{4 k+2}}{2 (4 k+2)}, k=1,2,3,...\tag{4a}$$ Here $B_{n}$ is the Bernoulli number.","['definite-integrals', 'special-functions', 'sequences-and-series']"
4070935,Solve $(\cos^2{x}+y \sin{2x})\frac{{\rm d}y}{{\rm d}x}+y^2=0$,"Solve $$(\cos^2{x}+y \sin{2x}) \frac{{\rm d}y}{{\rm d}x}+y^2=0$$ Please help me to solve this. It is not possible for me to separate. Attempt : If $M=\cos^2{x}+y \sin{2x}, N=y^2$ then $M_y=\sin{2x}, N_x=0$ are not equal.",['ordinary-differential-equations']
4070946,Integration with respect to a finitely-additive measure.,"I found an explanation of how to integrate with respect to a finitely-additive measure (taken from a book) : If $M$ is an algebra (not necessarely a $\sigma$ -algebra!) on $X$ and $\mu : M → [0, ∞]$ is a finitely additive (not necesseraly countabley
additive!) measure on $X$ , we can still define a notion of integral as
follows: we say that a measurable function $u : X → [−∞, ∞]$ is
integrable if there exists a sequence ${s_n }$ of measurable simple
functions, each of them bounded and vanishing outside a set of finite
measure (depending on $n$ ), such that $$\lim\limits_{n\to\infty} \mu
({x ∈ X : |u (x) − s_n (x)| > \epsilon}) = 0$$ for each $\epsilon >0$ ,
and $$\lim\limits_{n,l\to\infty}\int_X|s_n − s_l | d\mu = 0.(*)$$ It may be shown that for
every $E \in M$ the limit $\lim\limits_{n\to\infty}\int_E s_n d\mu$ exists in $\mathbb{R}$ and does not depend on the particular sequence ${s_n}$ . The integral of $u$ over the measurable set E is defined by $$\int_E u d\mu := \lim\limits_{n\to\infty}\int_E s_n d\mu.$$ Now I think the fact that $\lim\limits_{n\to\infty}\int_E s_n d\mu$ exists is because by $(*)$ $\{\int_X s_nd\mu\}_{n\ge 1}$ is a Cauchy sequence and $\mathbb{R}$ is complete (is that correct?). However I am not sure how to show that the limit does not depend on the particular sequence. If I take two sequences $s_n$ and $\hat{s}_n$ ,  then $$\int_E (s_n-\hat{s}_n)d\mu = \sum\limits_{i=1}^I c_i \mu(E_i)-\sum\limits_{j=1}^J \hat{c}_j\mu(\hat{E}_j)$$ and then I don't know how to conclude.","['integration', 'measure-theory']"
4070996,"Indefinite integral $\int \frac{1}{1+\sin^4(x)} \, \mathrm dx$","I'm a bit lost in this integral: $$\int \frac{1}{1+\sin^4(x)} \, \mathrm dx$$ I have tried solving with Wolfram, but I was getting a cosecant solution which doesn't seem as the correct method. Do you have any ideas? :) EDIT:
Do you please have step-by-step solution, because I am now somewhat lost. Using the substitution $t=\tan(x)$ , I got to $$\int \left(\frac{t^2}{2t^4+2t^2+1}+\frac{1}{2t^4+2t^2+1}\right)\mathrm dt$$ By expanding with 1: $$\int \frac{1}{1+\sin^4x}\cdot \frac{\frac{1}{\cos^4x}}{\frac{1}{\cos^4x}}\mathrm dx$$ $$\int \:\frac{1}{\frac{1}{\cos^4x}\cdot \frac{\sin^4x}{\cos^4x}}\cdot \frac{1}{\cos^4x} \mathrm dx$$ $$\int \:\frac{1}{\left(\frac{1}{\cos^2x}\right)^2\cdot \tan^4x}\cdot \frac{1}{\cos^2x}\cdot \frac{1}{\cos^2x}\mathrm dx$$ And using the substitution: $t=\tan\left(x\right)$ $$\mathrm dt=\frac{1}{\cos^2x}\mathrm dx$$ $$t^2=\tan^2\left(x\right)$$ $$t^2=\frac{\sin^2x}{\cos^2x}$$ $$t^2=\frac{1-\cos^2x}{\cos^2x}$$ $$t^2=\frac{1}{\cos^2x}-\frac{\cos^2x}{\cos^2x}=\frac{1}{\cos^2x}-1$$ $$t^2+1=\frac{1}{\cos^2x}$$ Using it: $$\int \:\frac{t^2+1}{2t^4+2t^2+1}\mathrm dt$$ I don't think I got to the expected result but I can't seem to be able to find why…","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
4071015,Evaluate $\int_{0}^{\pi} \frac{x\coth x-1}{x^2}dx$,"I've been trying to evaluate certain series recently, and I found that $$\sum_{r=1}^{\infty}\frac{1}{r}\arctan\frac{1}{r}=\frac{\pi}{2}\int_{0}^{\pi} \frac{x\coth x-1}{x^2} \, dx$$ Therefore, I would like to know how to evaluate $$\int_{0}^{\pi} \frac{x\coth x-1}{x^2} \, dx$$ The integral is approximately equal to $0.895004...$ but even Wolfram Alpha gives no closed form solution. Any ideas? Part of the problem is that the indefinite integral has no elementary antiderivative. I've tried using 'Feynman's trick' on this integral too but without success. Thank you for your help.","['integration', 'summation', 'improper-integrals', 'definite-integrals', 'calculus']"
4071031,"Is $\langle \nabla \omega, \eta \rangle \mathrm{dVol}_g=\nabla \omega \wedge \star \eta$ meaningful? How?","I know that $ \omega\wedge \star \eta=\langle \omega, \eta \rangle\mathrm{dVol}_g$ . I want to know Q1: why the following make sense? $$\langle \nabla \omega, \eta \rangle  \mathrm{dVol}_g=\nabla \omega \wedge \star \eta,\qquad\omega,\eta\in\Omega^k(M).$$ I am asking this because $\nabla \omega$ is not a differential form in general. It is a $(0,k+1)$ -tensor that has been wedge producted with a $(n-k)$ -form $\star\eta$ . Q2: I know that $\langle \nabla \omega, \eta \rangle$ is a $(0,1)$ -tensor, so what is the product between thatand $\mathrm{dVol}_g$ in the above displayed relation? Also Q3: Does $\star\nabla\omega$ make sense? i.e. Hodge star acting on tensors!! (because in general $\star\nabla=\nabla\star$ then it must make sense I think but how it works in practice?) p.s. Motivating MO post.","['tensors', 'riemannian-geometry', 'differential-geometry']"
4071057,What does it mean for an inner product to induce a norm?,"I'm working on a problem set and am trying to understand the concept of ""induced norms"": Let's say I have a space of $M \times N$ matrices (I'm interpreting this as the collection of all real-valued $M \times N$ matrices). Let's say I want to convert this space into an inner-product space using some inner product $\langle A, B\rangle$ . I now have some inner-product vector space where each matrix pair has an associated value produced by the inner product. For those interested, the provided inner product is $\operatorname{trace}(A^{T}B)$ . The problem then goes on to state that the provided inner product induces a norm. What does it mean to induce a norm? And is this an induced norm on the original $M \times N$ matrix space? Or the inner-product space?","['matrices', 'inner-products', 'linear-algebra', 'matrix-norms']"
4071071,SARIMA: Fitted values of the time series [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I'm trying to forecast future sales via SARIMA model.
Since I have multiple time series, I have used a grid search technique to find the best parameters for the SARIMA model.
But when looking at the fitted values the fit shows a huge dip at September.
Details:
Model fitted on $2$ years of weekly sales.
SARIMA: $(0, 1, 0) \times (1, 1, 0, 52)$ AIC= $4.000$ Can someone explain why is the SARIMA model fit shows such dips. Ideally it show consider it as an outlier.","['time-series', 'statistics']"
4071073,How to prove that $\Gamma(x) \leq x^x$ for $x \geq 1$,"Where can I find a (simple?) proof that $\Gamma(x) \leq x^x \,\,\,\, \forall x \geq 1$ ? $\Gamma(x)$ is the Gamma function defined as $$ \Gamma(x) = \int_0^\infty t^{x-1} e^{-t} \, \mathrm{d}t
$$","['calculus', 'reference-request', 'analysis', 'inequality']"
4071078,Find the asymptotic distribution of δ,"Let $X_1, \ldots, X_n$ i.i.d. from the $\mathrm{Bernoulli}(p)$ distribution. Then $X = X_1 +\ldots+X_n$ follows the $\mathrm{Binomial}(n,p)$ distribution.
We wish to estimate $g(p)=p(1-p)$ whose UMVUE is $$\delta=\frac{X(n−X)}{n(n−1)}
$$ Find the asymptotic distribution of $\delta$ . I tried: let $$
\delta^*=\frac{X(n-X))}{n^2}=\frac{X}{n}-\left(\frac{X}{n}\right)^2=\frac{\sum_{i=0}^n X_i}{n}-\left(\frac{\sum_{i=0}^n X_i}{n}\right)^2=\bar X-(\bar X)^2
$$ so, $$
\delta=\frac{X(n-X)}{n(n-1)}=\frac{n}{n-1}\big(\bar X - (\bar X)^2\big)
$$ Let, $$h(\mu) = \left(\frac{n}{n-1}\right)\big(\mu-(\mu)^2\big) $$ So, $$h^\prime(\mu)=\frac{n}{n-1}-2\mu\left(\frac{n}{n-1}\right)$$ hence, the asymptotic distribution of $\delta$ is $$
\sqrt n {\big(h(\bar x) - h(\mu)\big)}\xrightarrow{L} N\big(0, (h^\prime(\mu))^2\sigma^2\big)=N\big(0, \big(\frac{n}{n-1}-2\mu(\frac{n}{n-1})\big)^2\big(np(1-p)\big)^2\big)
$$ By the Delta method. But, to use the Delta method, I must prove $\delta$ and $g(p)$ are consistent. How do I prove it? Thank you very much!",['statistics']
4071109,Show that two $R$-algebras are not isomorphic.,"Consider the $\mathbb{R}$ -algebras $A := \mathbb{R}\left[a,b,c,d\right]\left[\frac{1}{a^2+b^2+c^2+d^2}\right]$ and $B := \mathbb{R}\left[a,b,c,d\right]\left[\frac{1}{ad-bc}\right]$ (so we are adjoining the inverses of $a^2 + b^2 + c^2 + d^2$ and $ad-bc$ , respectively).
I claim that these are not isomorphic as $\mathbb{R}$ -algebras, but I'm not sure how to formalize this. My intuition says that this is because $$a^2 + b^2 + c^2 + d^2 = 0 \iff a=b=c=d=0,$$ while $ad-bc=0$ has nonzero solutions. I tried to formalize this using evaluation homomorphisms, but to no avail. I also tried assuming they were isomorphic and obtaining a contradiction, but haven't been able to. Does anyone have any pointers on how to approach this?","['algebraic-geometry', 'ring-theory', 'abstract-algebra']"
4071185,Can we get quantitative information from the Dominated (resp. Monotone) Convergence Theorem?,"It's a common exercise in measure theory courses to solve problems like the following: Compute $$\lim_{n \to \infty} \int_0^\infty (1+ (x/n))^{-n} \sin(x/n)\,\mathrm{d}x.$$ (cf. Folland Ch 2.4, exercise 28a). The dominated convergence theorem makes short work of things like this, since (for large $n$ ) we get roughly exponential decay. A little bit of work turns this intuition into a pointwise bound, and then we swap $\lim \int = \int \lim$ to solve the problem. Often in computer science, combinatorics, etc. this is not enough. We're interested in the rate of convergence. That is, it's not enough to know $$
\lim_{n \to \infty} \int_0^\infty (1+ (x/n))^{-n} \sin(x/n)\ dx 
= \int_0^\infty 0\  dx
= 0
$$ We want to say that $$\int_0^\infty (1+ (x/n))^{-n} \sin(x/n)\ dx = O(1/n),$$ or something similar. I'm not well versed with computing integrals while using estimates of this kind, but I'm sure that people have thought about this. Is there a way to get these kinds of error estimates from the dominated (resp. monotone) convergence theorem? I would be happy to use this problem (or any others that you may feel are more emblematic of the technique) as a case study. I suspect one could argue by integrating some error bounds between $f_n$ and $f$ , and it may be helpful to look at, say $f_n \cdot \chi_{[0,n]}$ in order to make the error bounds more useful. This feels like it is kind of sidestepping the convergence theorems entirely, though, and I'm curious if there's a more elegant approach. Thanks in advance! ^_^","['integration', 'measure-theory', 'asymptotics', 'reference-request', 'real-analysis']"
4071219,"Given the octagon $ABCDEFGH$, with $\angle GHA=\angle ABC=\angle CDE=\angle EFG=120^o$, $AE\perp GC$ and $AO=OE=OG=OC$, find the area of the octagon","Given the octagon $ABCDEFGH$ ,  with $\angle GHA=\angle ABC=\angle CDE=\angle EFG=120^o$ , $AE\perp GC$ and $AO=OE=OG=OC$ find the area of the octagon. We have that $\triangle AGH, \triangle GFE, \triangle DEC, \triangle CBA$ isosceles. $ACEG$ is a square with side $2$ . $\angle HGA=\angle HAG=\angle BAC=\angle BCA=\angle DCE=\angle DEC=\angle GEF=\angle EGF$ . Also we have that $HBDF$ is a square. Basically all you need to work out is $GH$ , but I can't work it out. Could you please explain to me how to solve the question?","['contest-math', 'euclidean-geometry', 'area', 'geometry', 'trigonometry']"
4071256,Deriving the centripetal acceleration in circular motion,"I tried to make sure I understand uniform circular motion by deriving the formula for centripetal acceleration, $a_c = v^2/r$ , rigorously from first principles. I think I did it correctly, but it seems quite complicated - can you show me better ways? Given a particle moving uniformly in a circule of radius $r$ around $O$ with period $T$ , I take it as given that it has tangential velocity at each point with the same constant magnitude. So let's say its velocity at the topmost point, broken down into Cartesian components, is $v_0=(v,0)$ . Now some small amount of time $\Delta t$ passes, and the particle rotates by the angle $\alpha = \frac{2\pi}{T} \Delta t$ . The magnitude of velocity remains $v$ , and it's now pointed in the new tangential direction, so it's easy to see its components as $v_1=(v\cos\alpha, v\sin\alpha)$ . Now acceleration is the limit of $\frac{v_1-v_0}{\Delta t}$ when $\Delta t \to 0$ . I just want the magnitude of acceleration which will be $$\lim_{\Delta t \to 0}\frac{\sqrt{(v\cos\alpha - v)^2 + (v\sin\alpha)^2}}{\Delta t}$$ I can simplify this, by passing to $\alpha$ as the dependent variable ( $\Delta t=\frac{T}{2\pi}\alpha$ ), to $$v \frac{2\pi}{T} \lim_{\alpha \to 0}\frac{\sqrt{2-2\cos\alpha}}{\alpha}        $$ To evaluate the limit, I bring the denominator under the square sign and break down $\cos\alpha$ by its Taylor series: $$\lim_{\alpha \to 0}\sqrt{\frac{2-2\cos\alpha}{\alpha^2}} = \lim_{\alpha \to 0}\sqrt{\frac{2-2(1-\frac{\alpha^2}{2} + \frac{\alpha^4}{24} - \cdots}{\alpha^2}} =  \lim_{\alpha \to 0}\sqrt{1 - \frac{\alpha^2}{12} + \cdots} = 1$$ So in the end the magnitude of acceleration is $v\frac{2\pi}{T}$ . But since the particle traces the circumference of the circle, of length $2\pi r$ , under constant speed $v$ in time $T$ , we have $vT = 2\pi r$ , so $\frac{2\pi}{T} = \frac{v}{r}$ , and finally the acceleration is the familiar formula $$a_c=\frac{v^2}{r}$$ Did I do this right? And even if I did, was it necessary to do the Taylor series stuff to obtain the trigonometric limit? What are some ways to make this derivation easier, but still rigorous under the formal definition of acceleration in Cartesian coordinates?","['classical-mechanics', 'trigonometry', 'vectors']"
4071273,Ways to number a row of trees,"On the median strip of an infinite road there are n trees in a row. We want to mark all of them with the three numbers 1, 2 and 3, in such a way that all trees have one number and no two adjacent trees can have the same number. In how many ways is this possible, if one of the numbers (say, 3) must be used at least twice? I tried to find a recursive relation by starting from the small numbers:
For $n=4$ I found that only 4 numberings are possible.
For $n=5$ , I got 34 and for $n=6$ , 88. I think the general formula for all possible numberings without the exclusion of the ones which have only 1 or 2 3's, is $3*2 ^{n-1}$ but I don't know how to calculate the invalid numberings. Any help?",['combinatorics']
4071295,Function of class $C^1$ implies locally Lipschitz,"Let $A$ be open in $\mathbf{R}^{m} ;$ let $g: A \rightarrow \mathbf{R}^{n} .$ If $S$ is a subset of $A,$ we say that $g$ satisfies the Lipschitz condition on $S$ if the function $$
\lambda(\mathbf{x}, \mathbf{y})=|g(\mathbf{x})-g(\mathbf{y})| /|\mathbf{x}-\mathbf{y}|
$$ is bounded for $\mathbf{x}, \mathbf{y}$ in $S$ and $\mathbf{x} \neq \mathbf{y}$ . We say that $g$ is locally Lipschitz if each point of $A$ has a neighborhood on which $g$ satisfies the Lipschitz condition. How do I go about showing that if $g$ is of class $C^{1}$ , then $g$ is locally Lipschitz? I know that the derivatives of $g$ are locally bounded and then I can apply the MVT, but am not sure how to formulate this. The $1-D$ case is easy, but I am struggling with the multidimensional case given.","['proof-writing', 'lipschitz-functions', 'analysis', 'real-analysis', 'multivariable-calculus']"
4071357,Asymptotic of series,Let $x_n$ be a sequence of positive numbers with the property that $$\sum_n \frac{x_n}{n \log(n)^3}< \infty.$$ Can we show that $$\limsup_{\varepsilon \downarrow 0}\frac{\sum_{i=1}^{\infty} \exp(-\varepsilon x_n)}{\sum_{i=1}^{\infty} \exp(-\varepsilon \log(i)^2)}>0?$$,"['convergence-divergence', 'sequences-and-series']"
4071364,The meaning of $dx$ in an indefinite integral,"This semester I'm taking integral calculus for the first time. We started with the differential (i.e. $dy=f'(x)\,dx$ ) and right after that with the indefinite integral. Since then, I've been trying to make sense of the $dx$ when it's part of an indefinite integral (i.e. $\int f(x) \, \boldsymbol{dx}$ ). I know there are already a bazillion answers regarding this question, but all of them refer to the definite integral and the ones that do touch on indefinite integrals only say things like "" it's just a syntactical device to tell you the variable to differentiate with respect to or the integration variable "" (Ihf, 2012, web). I don't like this answer, especially because I was taught that given two functions $f(x)$ , $g(x)$ and the antiderivative of their product $\int f(x)g(x)\,dx$ , if I were to assign $f(x)$ to $u$ and $g(x)\,dx$ to $dv$ in order to integrate by parts, then I would have to integrate $dv$ to find $v$ . This only makes sense if $dx$ means something by itself and is not just a quirk of the notation, otherwise we would end up with something like the following: $$\int g(x)\,dx\space dx$$ After thinking about it a lot, I believe I finally found a way to make sense of the $dx$ as something that isn't purely and simply a notation device. My reasoning is as follows: Given a function $f(x)$ , let $y=f(x)$ . Then $$\frac{dy}{dx}=f'(x)$$ Then from the fundamental theorem of calculus, we know that $$\int\frac{dy}{dx}\,dx=y$$ Let $dy=f'(x)\,dx$ . Then the equation $$dy=\frac{dy}{dx}\,dx$$ holds and $$\int\frac{dy}{dx}\,dx=\int dy=y$$ Finally, integrate both sides of the equation $dy=f'(x)\,dx$ in order that $$\int dy=\int f'(x)\,dx\implies y=f(x)$$ From this I conclude that, by integrating a function, what we are really doing is integrating the differential of that function. This makes perfect sense to me, although I'm aware that seemingly logical things aren't necessarily logical. That's why I would appreciate it if someone could tell me whether the above is mathematically correct or pure gibberish. PS, I had never written a mathematical proof before and I have taken no proofs courses yet, so any suggestions are welcome. Reference: lhf . (2012, May 9). What does $dx$ mean? . Mathematics Stack Exchange. https://math.stackexchange.com/q/143262","['integration', 'differential', 'notation', 'calculus', 'indefinite-integrals']"
4071409,Find the value of $T=\mathop {\lim }\limits_{n \to \infty } {\left( {1+ \frac{{1+\frac{1}{2}+ \frac{1}{3}+ . +\frac{1}{n}}}{{{n^2}}}} \right)^n}$,I am trying to evaluate $$T = \mathop {\lim }\limits_{n \to \infty } {\left( {1 + \frac{{1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{n}}}{{{n^2}}}} \right)^n}.$$ My solution is as follow $$T = \mathop {\lim }\limits_{n \to \infty } {\left( {1 + \frac{{1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{n}}}{{{n^2}}}} \right)^n} \Rightarrow T = {e^{\mathop {\lim }\limits_{n \to \infty } n\left( {1 + \frac{{1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{n}}}{{{n^2}}} - 1} \right)}} = {e^{\mathop {\lim }\limits_{n \to \infty } \left( {\frac{{1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{n}}}{n}} \right)}}$$ $$T = {e^{\mathop {\lim }\limits_{n \to \infty } \left( {\frac{1}{n} + \frac{1}{{2n}} + \frac{1}{{3n}} + \cdots + \frac{1}{{{n^2}}}} \right)}} = {e^{\left( {0 + 0 + \cdots + 0} \right)}} = {e^0} = 1$$ The solution is correct  but I presume my approach $\mathop {\lim }\limits_{n \to \infty } \left( {\frac{{1 + \frac{1}{2} + \frac{1}{3} + \cdot + \frac{1}{n}}}{n}} \right) \Rightarrow \mathop {\lim }\limits_{n \to \infty } \left( {\frac{1}{n} + \frac{1}{{2n}} + \frac{1}{{3n}} + \cdot + \frac{1}{{{n^2}}}} \right) = 0$ is wrong. Is there any generalized method,['limits']
4071438,Gettings bounds for seminorms from bound of absolute value,"On a compact domain $\Omega \subseteq \mathbb{R}^d$ , we have a function $u(x) \in C^{\infty}(\Omega)$ with an approximation $u_h(x)$ with the following properties: $$
|u(x) - u_h (x)| \leq C h^{m+1} |u(x)|_{C^{m+1}(\Omega)},
$$ where the seminorm on the right is defined as $
|u(x)|_{C^{m+1}(\Omega)} = \text{max}_{|\alpha|=m+1} \|D^{\alpha} u\|_{L^{\infty}}
$ , with the derivative being defined using the multi-index notation: $$
D^{\alpha} f = \frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1} \cdots\partial x_n^{\alpha_n}}, \quad \alpha = (\alpha_1, \cdots, \alpha_n),
$$ for $|\alpha| = \alpha_1 + \alpha_2 + \cdots \alpha_n| \leq k$ , $x \in \mathbb{R}^d$ , $f \in C^k (\Omega)$ . I want to use that approximation to derive similar bound for the seminorm $|v|^2_{k, \Omega}$ defined as the sum of all the squares of the $L^2$ norms of all the derivatives of order $k$ . So in 2D, this seminorm would look like: $$
\|v\|^2_{0, \Omega} = |v|^2_{0, \Omega} = \int_{\Omega} v^2 d\Omega \\
|v|^2_{1, \Omega} = \left| \frac{\partial v}{\partial x_1} \right|^2_{0, \Omega} + \left| \frac{\partial v}{\partial x_2} \right|^2_{0, \Omega}  \\
|v|^2_{2, \Omega} = \left| \frac{\partial^2 v}{\partial x_1^2} \right|^2_{0, \Omega} + \left| \frac{\partial^2 v}{\partial x_1 \partial x_2} \right|^2_{0, \Omega} + \left| \frac{\partial^2 v}{\partial^2 x_2} \right|^2_{0, \Omega}
$$ To be more precise, I'm trying to arrive at some bound for $|u(x) - u_h(x)|_{s, \Omega}$ , with $0 \leq s < m$ . Any suggestions how I could achieve that?","['normed-spaces', 'analysis', 'upper-lower-bounds']"
4071492,"$\{(x,f(x)): x\in E\}$ is compact in $\mathbb R^2 \implies f:E\to\mathbb R$ is continuous","Given $f: E\to\mathbb R$ , define $G: E\to\mathbb R^2$ by $G(x) = (x,f(x))$ for all $x\in E$ . $E$ is a compact subset of $\mathbb R$ . The following are equivalent: $f$ is continuous. $G$ is continuous. The graph of $f$ is a compact subset of $\mathbb R^2$ . First, let $E = [a,b]$ . I have shown $1\implies 2$ and $2\implies 3$ . Proving $3\implies 1$ would help me complete the argument full circle. Please let me know if the following makes sense (point out errors if any), and help me complete the proof. $[1\implies 2]$ : If $x_n\to x$ and $f$ is continuous, then $f(x_n)\to f(x)$ , and hence $G(x_n)\to G(x)$ meaning $G$ is continuous. Does this need more argument? $[2\implies 3]:$ The continuous image of a compact set is compact. Hence, $G([a,b])$ , i.e. the graph of $f$ is compact in $\mathbb R^2$ . I found the following for $[3\implies 1]$ : Let $G([a,b])$ be compact and $x_n\rightarrow x$ be a convergent sequence in $[a,b]$ . We show that $f(x_n)$ converges to $f(x)$ . Since the graph is compact, $f(x_n)$ has a convergent subsequence, Q1. $G([a,b])$ is compact, so $(x_n,f(x_n))$ has a convergent subsequence. How does this tell us that $f(x_n)$ has a convergent subsequence? I feel we need to add some details here. i.e. $f(x_{n_j})\rightarrow y$ . That is $(x_{n_j}, f(x_{n_j}))\rightarrow (x, y)$ . The graph is closed. That is, the limit of every convergent sequence in $G([a,b])$ is again in $G([a,b])$ . Therefore $(x,y)\in G([a,b])$ , i.e. $y=f(x)$ . Since this is true for every convergent subsequence, we showed that $f(x)$ is the only limit point of $f(x_n)$ , i.e. $f(x_n)$ converges to $f(x)$ . Q2. How is the last sentence concluded? We choose an arbitrary convergent subsequence $f(x_{n_j}) \to y$ , and found $y = f(x)$ . What now? My attempt for $[3\implies 1]$ : Suppose $G_f = \{(x,f(x)): x\in [a,b]\}$ is compact in $\mathbb R^2$ . Define $\phi_1(x,y) = x, \phi_2(x,y) = y$ . Suppose $S\subset\mathbb R$ is an arbitrary closed set in $\mathbb R$ . $$f^{-1}(S) = \{x\in [a,b]: f(x) \in S\}$$ We can write $$f^{-1}(S) = \phi_1(G_f \cap \phi_2^{-1}(S))$$ The above expression seems good intuitively but I need help establishing it by showing $\subseteq$ and $\supseteq$ inclusions. Next, $S\subset \mathbb R$ is closed tells us that $\phi_2^{-1}(S) \subset \mathbb R^2$ is closed - since $\phi_1,\phi_2$ are continuous. $G_f \cap \phi_2^{-1}(S)\subset G_f$ , and $G_f \cap \phi_2^{-1}(S)$ is closed. So, $G_f \cap \phi_2^{-1}(S)$ is compact. $\phi_1$ is continuous, which means $f^{-1}(S)$ is compact. Hence, $f^{-1}(S)$ is closed. Done! Please help me fill in the gaps in my attempt , and let me know if you've any other ideas to solve the problem, such as $[3\implies 2]$ and $[2\implies 1]$ . I'd also like to understand the proof posted above my attempt. Thank you!","['proof-explanation', 'solution-verification', 'analysis', 'real-analysis']"
4071521,"Why can we think the divergence and the curl as some kind of ""derivative""?",My question arises from think about why the divergence theorem and the stoke's theorem are considered generalizations of the fundamental theorem of calculus.,"['multivariable-calculus', 'calculus', 'vector-analysis']"
4071533,"Is the set of points ${i/n},\,n=1,2,3\ldots$ in the complex plane a closed set?","A set is said to be closed if it contains all of its boundary points, where a boundary point of a set in the complex plane is any point such that every neighborhood of the boundary point contains at least one point in the set and at least one point not in the set. At first glance, I assumed that the set $S$ defined by $S=\{ i/n\,\vert \,n\in\mathbb{Z}^+\}$ is closed, since each point $i/n$ is a boundary point of the set and is an element of the set. However, the more I think about it, the more I feel that the complex number $z=0$ is also a boundary point of the set, since any neighborhood of $0$ must contain a complex number that is arbitrarily close to $0$ on the positive imaginary axis (and therefore in $S$ ) and $0$ itself (which is not in $S$ ). Since this boundary point $z=0$ is not contained in the set, $S$ does not contain all of its boundary points, and is therefore not closed. I know that this is not a rigorous proof of my claim, but is this reasoning correct?","['complex-analysis', 'general-topology', 'elementary-set-theory', 'complex-numbers']"
4071616,Two mysterious missing angles in the sine values of acute angle list?,"There is a well known list of 5 for  trig values of special angles between 0 $^o$ to $90^o$ : $\sin 0^o =\frac{\sqrt {\color{blue}{0}}}{2}$ , $\sin 30^o =\frac{\sqrt {\color{blue}{1}}}{2}$ , $\sin 45^o =\frac{\sqrt {\color{blue}{2}}}{2}$ , $\sin 60^o =\frac{\sqrt {\color{blue}{3}}}{2}$ , $\sin 90^o =\frac{\sqrt {\color{blue}{4}}}{2}$ If wee add 15 $^o$ and 75 $^o$ , we can  make the angles evenly spaced by 15 $^o$ and expand the list of 5 to a list of 7: $\sin 0^o =\frac{\sqrt {\color{blue}{0}}}{2}$ , $\sin 15^o =\frac{\sqrt {\color{red}{2-\sqrt3}}}{2}$ , $\sin 30^o =\frac{\sqrt {\color{blue}{1}}}{2}$ , $\sin 45^o =\frac{\sqrt {\color{blue}{2}}}{2}$ , $\sin 60^o =\frac{\sqrt {\color{blue}{3}}}{2}$ , $\sin 75^o =\frac{\sqrt {\color{red}{2+\sqrt 3}}}{2}$ , $\sin 90^o =\frac{\sqrt {\color{blue}{4}}}{2}$ Reformat the list : $\sin 0^o =\frac{\sqrt {\color{green}{2-\sqrt {4}}}}{2}$ , $\sin 15^o =\frac{\sqrt {\color{green}{2-\sqrt3}}}{2}$ , $\sin 30^o =\frac{\sqrt {\color{green}{2-\sqrt{1}}}}{2}$ , $\sin 45^o =\frac{\sqrt {\color{green}{2-\sqrt{0}}}}{2}$ , $\sin 60^o =\frac{\sqrt {\color{green}{2+\sqrt{1}}}}{2}$ , $\sin 75^o =\frac{\sqrt {\color{green}{2+\sqrt 3}}}{2}$ , $\sin 90^o =\frac{\sqrt {\color{green}{2+\sqrt{4}}}}{2}$ Now, we see a nice pattern of $\frac{\sqrt {{2\color{red}{\pm}\sqrt i}}}{2}$ with i=0,1,3,4. But wait, why is 2 missing from this i list?  Seems like we have two special angles lost. With them, we can expand this to list of 9. Where are these two mysterious angles?  Can you find them and prove they  fit into the pattern? Or, do you find ways to expand this list even further to a list of 11,13,...and find something amazing?","['algebra-precalculus', 'trigonometry']"
4071682,Elementary proofs about $f(t)=\lim_{n\to\infty}(1+\frac tn)^n$,"Please read carefully what I mean by elementary before marking the question as duplicate. I'm starting calculus lessons in High School; that is: no series, no derivatives, no limits of functions, no continuity... I have just stated the axiom of supreme and defined sequence and limit of sequence. I have proved that a monotone, bounded sequence has limit. Just that. Under so 'elementary' conditions, I'd like to prove: For each real $t$ , the sequence $\left(1+\dfrac tn\right)^n$ converges. (I have problems for $t<0$ ). Then I'll define $e^t$ as the limit of this sequence. For every pair $t,s$ , $e^{t+s}=e^te^s$ . Any ideas or bibliography?","['calculus', 'exponential-function']"
4071705,Convergence of sequence of sets is empty set iff limit of symmetric difference of sets exists.,"I'am trying to solve one of the exercises of Halmos's measure theory book, but I can't figure it out. Exercises goes as follows:
Let $(E_n)_{n\in\mathbb{N}}$ sequence of sets. Define the sequence $(D_n)_{n\in\mathbb{N}}$ as follows: $$D_1=E_1,D_2=D_1\triangle E_2,~~~D_n=D_{n-1}\triangle E_n,~~\forall n\in\mathbb{N}_{\geq 3}.$$ Prove that the sequence $(D_n)$ converge to some set, say $A$ , if and only if $\lim_{n}E_n=\emptyset$ . I try to solve it with definitions of limes superior and limes inferior for sequences of sets but I'm struggling with understand what is the role of symmetric difference in limits of sequences of sets. My attempt:
For sufficiency part, let $\lim_{n}D_n=A$ this implies that $\limsup_nD_n-\liminf_nD_n=\emptyset$ . So? What is this means? I also try to derive a contradiction with assuming that $\lim_nE_n\neq\emptyset$ but the sequence $(E_n)$ converge to some set, say U. How can I proceed from here? Can I derive a contradiction or is there any proof directly?","['measure-theory', 'convergence-divergence']"
4071719,"If $A$ and $B$ are subgroups of $G$ such that $[[A, B], B] = 1$, then $[A, B]$ is abelian.","I am stuck on the following question: If $A$ and $B$ are subgroups of $G$ such that $[[A, B], B] = 1$ , then $[A, B]$ is abelian, where $[X, Y]$ denotes the commutator subgroup of $X$ and $Y$ as usual. I have seen that $[A, B]$ is in the intersection of all the centralizer of each $b\in B$ . And I am trying to show that $B$ is a normal subgroup of $G$ , then it follows that $[A, B] \subseteq Z(B)$ , where $Z(B)$ denotes for the centre of $B$ . Then the result follows. But I have no idea how to show that $B$ is normal in $G$ or maybe I am completely on the wrong way. Anyone can help?","['normal-subgroups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
4071728,Second normal derivative on a curved boundary,"The motivation is that I am trying to understand the equation $$\tag{1}\label{eq:1}u_{nn} - \Delta u = -(\kappa u_n + u_{tt})$$ on the boundary $\partial\Omega$ of some bounded open set $\Omega\subset\mathbb R^2$ ( $\kappa$ is the signed curvature of the boundary). Basically, if $\partial \Omega$ is piecewise straight, then $\kappa=0$ and the tangential $t$ and normal $n$ simply form a local coordinate system by rotating the standard coordinates and hence \eqref{eq:1} is clear since the Laplacian $\Delta u := D^2u(x_1,x_1) + D^2u(x_2,x_2) = D^2u(t,t) + D^2u(n,n)$ is invariant under such rotation. In the case of arbitrary, say piecewise $C^2$ , boundary I am a bit confused. What does $u_{tt}$ and $u_{nn}$ even stand for, it cannot simply be $D^2u(t,t)$ and $D^2u(n,n)$ since then there would be no curvature term in \eqref{eq:1}. My intuition for $u_{tt}$ : The tangential derivative $u_t=\frac{\partial}{\partial t} u=\nabla u\cdot t$ can be written as $\frac{d}{ds}u(\gamma(s))$ for some arc-length parametrisation $\gamma$ of the boundary. Hence $u_{tt} = \frac{d^2}{ds^2}u(\gamma(s)) = D^2u(\gamma'(s), \gamma'(s)) + \nabla u\cdot \gamma''(s)= D^2u(t(s), t(s)) - \kappa u_n$ since $\gamma'(s)= t(s), \gamma''(s) = -\kappa n(s)$ . For $u_{nn}$ : The normal derivative $\frac{\partial}{\partial n} u_n$ as a directional derivative is the limit when approaching the boundary normally, but $u_n$ is only defined on the boundary. So does this mean that for any extension $n^*$ of the normal field $n$ , that $\frac{\partial}{\partial n} u_n = \frac{\partial}{\partial n} u_{n^*}$ is equal? And how to see this? Is there a better way of interpreting $u_{nn}$ in the first place? I guess I am making this way to complicated - thanks for your help!","['plane-curves', 'laplacian', 'partial-derivative', 'derivatives', 'differential-geometry']"
4071838,"For a bounded operator $A$, show that $(fg)(A)=f(A)g(A)$","Let $f$ be an analytic function in the neighbourhood of the spectrum $\sigma(A)$ of a bounded operator $A$ . Let $C$ be a contour, counterclockwise around $\sigma(A)$ within the domain of $f$ . Finally let $f(A)$ be defined by $$f(A)=\dfrac{1}{2\pi i}\oint_C f(z) (z-A)^{-1}dz.$$ Now I have to prove that $(fg)(A)=f(A)g(A)$ but I don't know how to start. I do recognize Cauchy's integral and since $f$ is analytic on a neighbourhood of $\sigma(A)$ one could use Cauchy's integral formula but I don't see how this would help.","['spectral-theory', 'operator-theory', 'contour-integration', 'functional-analysis']"
4071843,Multiple choice questions in exam,"In a country-level placement exam, there are 10 multiple-choice questions, each with 4 equivalent possible replies.
What is the minimum number of students taking this exam, so that it is always possible to find at least 2 sets with at least 9 same replies? All questions must be answered (and we assume that they are answered at random, that is, without any previous knowledge of the subjects). My thoughts:
All possible different sets of replies are $4^{10}$ .
If we get $4^{9}+1$ , do we ensure we will have at least 9 same sets?","['coding-theory', 'combinatorics']"
4071921,Is it true that any set which contains elements with contradictory properties is the empty set?,"Here's what I've ""discovered"" but can't verify. Let's take a set $A$ defined as ""the set of all $x$ which don't belong to $A$ "". Obviously this definition wouldn't hold in particular axiomatic systems, but it would in others. Let's analyze this in NST. $X\in A$ iff $X\not\in A$ . This is a logical contradiction, but it still doesn't prove that $A$ doesn't exist. In fact, I would argue that $A$ is the empty set. If put all of the elements of $A$ into the empty set, we get $(X∈A \text { iff } X∉A) \text { iff } X\in \emptyset$ . This is a tautology for whatever $X$ and $A$ . Now, if we switch two of the atomic sentences, we get $X\not\in A \text { iff } (X\in A \text { iff } X\in\emptyset$ ). We know this to also always be true, which means that either $A$ doesn't exist or $A$ is the empty set. Therefore, the empty set does contain every element belonging to any set it doesn't belong to. Is there some error in my proof?","['elementary-set-theory', 'solution-verification', 'logic']"
4071956,Exercise about CW Complexes,"I've just started studying algebraic topology this semester and I've been given some homework to do. Right now I'm struggling with the following exercise (which has already taken me too much time): Given integers k and l, let $X(k,l)$ be the CW complex with a single 0-cell, a single 1-cell and two 2-cells attached by maps $f, g : S^1 \to S^1$ which, respectively, wrap the circle around itself k and l times. I've managed to prove that $X(k,1)$ is homotopy equivalent to $X(k',1)$ for $k \neq k'$ . Moreover, I believe I've showed that $X(2,2)$ is Not homotopy equivalent to $X(2,1)$ . My question now is: Is $X(2,2)$ homotopy equivalent to $X(2,0)$ ??? If I'm not mistaken both have the same fundamental group, so I can't use that. Also, I haven't learned homology, so that's not allowed too. The complex $X(2,0)$ is a wedge between the projective plane and $S^2$ (I believe), and $X(2,2)$ are two projective planes glued...(?) Any hints or suggestions will be much appreciated!","['general-topology', 'cw-complexes', 'algebraic-topology']"
4072030,Construct a (conditional) independent strong approximation,"It is well known that for the sum of independent r.v., the strong approximation can be achieved using Yurinskii's coupling: Theorem (Yurinskii, 1978). Let $\xi_{1},\ldots,\xi_{n}$ be independent random variables with $\mathbb{E}\left[\xi_{i}\right]=0$ for each $i$ and $\beta\equiv\sum_{i}^{n}\mathbb{E}\left[\left|\xi_{i}\right|^{3}\right]$ finite. Let $S=\xi_{1}+\ldots+\xi_{n}.$ For each $\delta>0$ there exists a random variable $T$ with a $\mathcal{N}\left(0,\mathrm{Var}\left(S\right)\right)$ distribution such that $$\mathbb{P}\left(\left|S-T\right|>3\delta\right)\leq C_{0}B\left(1+\left|\log\left(1/B\right)\right|\right)\quad \text{where }B=\beta\delta^{-3},$$ for some universal constant $C_{0}$ . In above theorem, $\xi_{i}$ are independent and are assumed in $\left(\Omega,\mathcal{F},\mathbb{P}\right)$ . I wonder if it still holds when the independent condition is replaced by conditional independence. That is, suppose now $\xi_{i}$ are defined in the probability space $\left(\Omega,\mathcal{F},\mathbb{P}\right)$ , where the probability space have the following structure: $\Omega=\Omega^{\left(0\right)}\times\Omega^{\left(1\right)}$ , $\mathcal{F}=\mathcal{F}^{\left(0\right)}\otimes\mathcal{F}^{\left(1\right)}$ . The only difference is that $\xi_{i}$ are not naturally independent, instead, we have $\xi_{i}$ are independent conditional on $\mathcal{F}^{\left(0\right)}$ . Does the above Gaussian coupling variable still exist? If so, will the variable be independent of $\mathcal{F}^{\left(0\right)}$ ? Any comments / counter examples / hints on proof are welcome. Thanks!","['weak-convergence', 'statistics', 'coupling', 'probability']"
4072036,Dominated convergence theorem for stochastic processes integrated with respect to Lebesgue measure,"I consider a filtered probability space $(\Omega, \mathcal{F}, P)$ with filtration $(\mathcal{F}_t)$ on which $(X_t)$ is an $(\mathcal{F}_t)$ -adapted stochastic process. In addition to this, $(X^n_t)$ is a sequence of stochastic processes where for each $n$ , $(X_t^n)$ is $(\mathcal{F}_t)$ -adapted. I want to show that for every fixed $t \geq 0$ $$
\lim_{n \to \infty} \int_0^t \vert X_s^n -X_s \vert^2 ds = 0, \quad \text{P-a.s}
$$ My questions is, does their exist a dominated convergence result which can be used in this context? More precisely, is it enough if I can show that for every fixed $t \geq 0$ $$
 \lim_{n \to \infty} \vert X_t^n - X_t \vert^2  = 0, \quad \text{P-a.s}
$$ and for every $t \geq 0$ there exist a stochastic variable $Y_t$ with $E[\vert Y_t \vert ]< \infty$ such that for every $n$ $$
\vert X_t^n - X_t \vert^2 \leq Y_t \quad \text{P-a.s}
$$ I'm looking for a reference.","['stochastic-integrals', 'stochastic-processes', 'stochastic-analysis', 'probability-theory']"
4072050,"Validity of $\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$","Definitions For the definitions of $\operatorname{AGP}$ and $\operatorname{AGO}$ , see here or here . $\theta_2(z)$ and $\theta_3(z)$ are defined as follows: $$\theta_2(z)=\sum_{n=-\infty}^\infty z^{(n+1/2)^2},$$ $$\theta_3(z)=\sum_{n=-\infty}^\infty z^{n^2}$$ where $z\in\mathbb{C}$ and $|z|\lt 1$ . Problem Due to Brent (pages 38 and 48), we have the following ""formula"": $$\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$$ where $z\in\mathbb{C}\setminus (-\infty ,0]$ and $|z|\gt 1$ . It is based on Sasaki and Kanada's formula which is essentially the same, but less general: $$\ln x=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/x),\theta_3^2(1/x))}$$ where $x\in\mathbb{R}$ and $x\gt 1$ . Sasaki and Kanada's formula is fine, but Brent's formula turns out to be very problematic. For example, it works for $z=-1-2i$ , but doesn't seem to work for $z=-0.4+i$ and $z=0.4+i$ . All these complex numbers are greater than $1$ in absolute value and they don't lie on $(-\infty ,0]$ . To be specific, on page 48 Brent writes The theory that we outlined for the $\operatorname{AGM}$ iteration and $\operatorname{AGM}$ algorithms for $\log (z)$ can be extended without problems to complex $z\setminus (-\infty ,0]$ provided we always choose the square root with positive real part. Note that he is describing the $\operatorname{AGP}$ . Apparently there are some problems, though. It is not clear what he means: can it be extended to some complex $z\setminus (-\infty ,0]$ or all complex $z\setminus (-\infty ,0]$ ? Nevertheless, on page 28, he is referencing Borwein & Borwein: Given $(a_0,b_0)$ , the $\operatorname{AGM}$ iteration is defined by $$(a_{n+1},b_{n+1})=\left(\frac{a_n+b_n}{2},\sqrt{a_nb_n}\right).$$ For simplicity we'll only consider real, positive starting values $(a_0,b_0)$ for the moment, but the results can be extended to complex starting values (see Borwein & Borwein, Pi and the AGM , pp. 15–16) and we'll use that later. However, in their book on page 15 and 16, Borwein & Borwein write: All of the algorithms and functional relations extend naturally to the complex domain. In fact, all the algorithms and functional equations of this section hold at least for $k\in\{\operatorname{re}(z)\gt 0\}-[1,\infty )$ . The interested reader may readily establish the exact domains of validity for the various relations. The analysis of the $\operatorname{AGM}$ iteration for complex starting values is reasonably complicated (See Cox [85].) The problem is to decide which root is appropriate in the computation of $b_{n+1}=\sqrt{a_nb_n}$ . The right choice is made to ensure $|a_{n+1}-b_{n+1}|\le |a_{n+1}+b_{n+1}|$ [with $\operatorname{im}(b_{n+1}/a_{n+1})\gt 0$ in the case of equality]. As you can see, Borwein & Borwein are describing $\operatorname{AGO}$ , not $\operatorname{AGP}$ . I was thinking that Brent just erroneously assumed $\operatorname{AGP}$ instead of $\operatorname{AGO}$ , but even if we replace $\operatorname{AGP}$ with $\operatorname{AGO}$ in Brent's formula, the computation of $\ln z$ for both $z=-0.4+i$ and $z=0.4+i$ still gives wrong results. Quite curiously, $$\operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right)\ne \operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right),$$ but $$\operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right)=\operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right).$$ Question Brent's formula is apparently wrong, but what is the largest subset of $\mathbb{C}$ such that his formula holds true? Motivation Sasaki and Kanada's formula provides one of the fastest algorithms for the computation of the real natural logarithm and the real inverse hyperbolic functions. Newton's method can be used to compute the real exponential function and the real hyperbolic functions by means of a fast inversion. However, it is harder to compute the real trigonometric and the real inverse trigonometric functions this way. Namely, one has to extend Sasaki and Kanada's formula to the complex plane. But still, according to Brent, the convergence in the complex plane should be very fast and the algorithm should be even faster than the one based on Landen's transformations . An empirical result $$\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$$ should be valid everywhere outside the square with vertices at $-2.1-1.6i$ , $1.1-1.6i$ , $1.1+1.6i$ , $-2.1+1.6i$ . Complex plots The horizontal axis represents $\operatorname{Re}z$ and the vertical axis represents $\operatorname{Im}z$ . Note $\ln$ denotes the principal branch of the complex natural logarithm. This question was also asked on MathOverflow .","['special-functions', 'complex-analysis', 'algorithms', 'theta-functions', 'sequences-and-series']"
4072062,Does the matrix product $X^T X$ have a special meaning?,"I have come across this specific matrix product several times, lately in the context of stochastic linear models where it is an integral part of the Least Squares Estimator (LSE). Often times in linear algebra there is some beautiful intuition hidden behind recurring formulae and since I don't see the one behind this one I'm asking for help. Is there a geometric interpretation or special meaning for the matrix product $$X^T X$$ for a matrix $X \in \mathbb{R}^{n \times p}$ with $p \leq n$ ?","['matrices', 'statistics', 'linear-algebra']"
4072081,Solving linear differential equation with variable coefficients.,"I have faced this task, when preparing to my university's ""mathematical methods"" exam, and I do not really understand how to solve it. The task content is as follows: Given : $$(1-x^2)\cdot y''_{xx} -x\cdot y'_x +y = \frac{\sqrt{1-x^2}}{x}$$ Solve the equation by substituion of the independent variable: $x(t) = \cos(t), x\in(0,1).$ My attempt : I have performed the suggested substitution: $(1-\cos^{2}(t))\cdot \large\frac{\partial^2y}{\partial x(t)^2}\normalsize-\cos(t)\cdot\large\frac{\partial y}{\partial x(t)} \normalsize+ y = \large\frac{\sqrt{1-\cos^2(t)}}{cos(t)}.$ $\sin^2(t)\cdot \large\frac{\partial^2y}{\partial x(t)^2}\normalsize-\cos(t)\cdot\large\frac{\partial y / \partial t}{\partial x / \partial t} \normalsize+ y = \tan(t).$ $\sin^2(t)\cdot\frac{\large\partial\left(\frac{\dot{y}}{-\sin(t)}\right) / \partial t}{\large\partial x / \partial t} + \large\frac{\cos(t)}{\sin(t)}\normalsize\dot{y} + y = \tan(t).$ $-\ddot{y} + 2\dot{y}\cot(t) +y = \tan(t).$ That is now I have to solve: $-\ddot{y} + 2\dot{y}\cot(t) +y = \tan(t).$ And that is the point, where I am stuck, I have no idea how to proceed from here, and I did not manage to find the way to solve such a linear D.E. in my course book. I would appreciate any help, hints or book references, thank you in advance! Post Scriptum : As correctly mentioned by @Aryadeva, I have made a mistake, when calculating $\large\frac{\partial^2 y}{\partial x^2}$ , I simply lost ""minus"". That is, after recalculating I had to solve: $$\ddot{y} + y = \tan(t), \text{ s.t. } x\in(0,1) \text{ and } x = \cos(t) \Leftrightarrow \forall x\in \mathbb{D}_x: \text{ }t = \arccos{x}.\tag{1}$$ My solution has involved appying vatiation of parameters method: $\underline{\text{Step I}}$ : find characteristic polynomial over $y(t)$ to get a general solution $(\large y_{\small G})$ for $(1)$ : $\lambda^2 + 1 = 0. \Rightarrow \lambda = \pm i.$ $\begin{bmatrix}
\lambda_1\\
\lambda_2\\
\end{bmatrix} = \begin{bmatrix}
i\\
-i\\
\end{bmatrix} \Rightarrow \large y_{\small G} \normalsize = C_1 e^{it}+C_2 e^{-it} = \dot{\tilde {C}}_1\cos(t) + \dot{\tilde{C}}_2 \sin(t).$ $\underline{\text{Step II}}$ : Finding particular solution $(\large y_{\small P})$ for $(1)$ , using Wronskian matrices: I would omit my calculations here, would just note that for the given D.E.: $\mathbb{W} = \begin{pmatrix}\cos(t) & \sin(t) \\ -\sin(t) & \cos(t) \end{pmatrix}, \mathbb{W}_{\small \Delta} = \begin{vmatrix}\cos(t) & \sin(t) \\ -\sin(t) & \cos(t) \end{vmatrix} = 1.$ $\mathbb{W}_{\small \Delta,\normalsize 1} = \begin{vmatrix}0 & \sin(t) \\ 1 & \cos(t) \end{vmatrix} = -\sin(t), \mathbb{W}_{\small \Delta,\normalsize 2} = \begin{vmatrix}\cos(t) & 0 \\ -\sin(t) & 1 \end{vmatrix} = \cos(t).$ Thus: $$\dot{\tilde{C}}_1(t) = \int\frac{\tan(t)\cdot \mathbb{W}_{\small \Delta,\normalsize 1}}{\mathbb{W}_{\small \Delta}} \partial t = \sin(t) +\frac{1}{2}\ln\left(\frac{\sin(t)-1}{\sin(t)+1}\right) +\bar{C}_1,$$ $$\dot{\tilde{C}}_2(t) = \int\frac{\tan(t)\cdot \mathbb{W}_{\small \Delta,\normalsize 2}}{\mathbb{W}_{\small \Delta}} \partial t = -\cos(t) + \bar{C}_2.$$ Thereof: $$\large y_{\small P} \normalsize = \left(\sin(t)+\frac{1}{2}\ln\left(\frac{\sin(t)-1}{\sin(t)+1}\right) +\bar{C}_1\right)\cos(t) +\left(-\cos(t) +\bar{C}_2\right)\sin(t).$$ $\underline{\text{Step III}}$ : Now it just suffices to write down the whole solution and transfer from $t$ to $x$ : $\large y \normalsize (t) = \large y_{\small G} + y_{\small P} \normalsize = \left(\sin(t)+\frac{1}{2}\ln\left(\frac{\sin(t)-1}{\sin(t)+1}\right) +\tilde{C}_1\right)\cos(t) +\left(-\cos(t) +\tilde{C}_2\right)\sin(t).$ Now, as $x \in (0, 1): \cos(\arccos{x}) = x, \text{ }\sin(\arccos{x}) = \sqrt{1-x^2}:$ $$\text{Answer: } \begin{array}{|c|}
\hline
y(x) = \left(\sqrt{1-x^2} + \frac{1}{2}\ln\left(\frac{\sqrt{1-x^2} - 1}{\sqrt{1-x^2} +1}\right)+\tilde{C}_1 \right)x +\left(-x+\tilde{C}_2\right)\sqrt{1-x^2}.\\
\hline
\end{array}$$","['substitution', 'book-recommendation', 'ordinary-differential-equations']"
4072119,Is the limit function continuous?,Is this function continuous or not? $$y\ =\ \lim _{a\to +\infty }\bigg[\frac{\ln \left(1+e^{\alpha \cdot x}\right)}{\ln \left(1+e^{\alpha }\right)}\bigg]$$ I computed that limit of function as $a\to+\infty$ is $x$ . How I proceed from here for proving the continuous part?,"['analysis', 'real-analysis', 'continuity', 'calculus', 'functions']"
4072133,Geometric view of isomorphism between sets,"My studying of Commutative Algebra lead me to the following question (though not a strictly Commutative Algebra question) : What is a (or the) geometric intuition of the isomorphism $$\mathbb{R}[x,y]/(x^2-y,x-x^3+xy)\simeq\mathbb{R}$$ So $\mathbb{R}[x,y]$ is the ring of polynomials with variables $x,y$ and $(x^2-y,x-x^3+xy)$ is an ideal of $\mathbb{R}[x,y]$ . I would like to see an awnser for the spesific question for I have searched for 'geometric approaches' of isomorphisms in classics like the Atiyah MacDonald 'Introduction to Commutative Algebra' and in Algebraic Geometry material and I cannot figure out the idea. Really tough, I would like to know your mind considering geometric approaches of isomorphisms 'in general' (perhaps by giving an example that you have in mind, like the one above and of course, the more examples, the better). Also, any sources for further studying or links to previously related posts are welcome.","['algebraic-geometry', 'abstract-algebra', 'ring-isomorphism', 'commutative-algebra']"
4072190,If $a_{n_k}$ denotes a subsequence of $a_n$. Why is $n_k \geq k$ for all $k$.?,"I am trying to prove that If a sequence converges, then every subsequence converges to the same limit. Now going in the backwards direction, I know it is true because the sequence is a subsequence of itself. But what about proving if a sequence converges then every subsequence converges to the same limit. I do not understand the notation $a_{n_k}$ , $a_n$ , $n_k$ and $k$ I know that subsequence need to be in order just like in the original sequence. Can someone please clarify the notation and explain why $n_k \geq k$ for all $k$ .?","['limits', 'solution-verification', 'sequences-and-series']"
4072217,Hypothesis testing in elections,"The following is a problem I am working on for my stats class regarding hypothesis testing: I have a random sample $X_1,...,X_n$ of voters who either voted for Candidate A ( $X_1=1$ ) or for Candidate B ( $X_i=0$ ), with probability of voting for A denoted as $p$ . I want to test the hypothesis that A will not lose the election: $H_0:p\geq 0.5$ vs. $H_1:p<0.5$ . I set the null parameter space $\Theta_0=[0.5,1]$ and the power test to $\beta_\psi(p)=\mathbb{P}_p(T\leq c)=\sum_{k=0}^c{n\choose k}p^k(1-p)^{n-k}$ , observing that for $c\in\{0,...,n-1\}$ , the power test is strictly decreasing in $p$ and that size of $\psi$ is thus $\beta_\psi(0.5)$ . Now, I want to find $c$ so that the power test is at level 5% with the largest possible power, at sample size $n=100$ . Is it correct for me to assume that I must find the largest $c$ such that $\beta_\psi(0.5)\leq 0.05$ ? I do intuit that this is because of the null hypothesis $H_0:p\geq 0.5$ and $c$ being in the ""same direction"" as $p$ (number of A voters in the sample is used to ""estimate"" the probability of voting A, which we want to increase to the minimal degree to satisfy the level- $\alpha$ test; the ""increasing"" being to control type I error and the ""to the minimal degree"" being to minimize type II error). Could somebody please verify this? If there are any mistakes or a more rigorous explanation in what I said, please let me know.","['statistical-inference', 'statistics', 'log-likelihood', 'hypothesis-testing']"
4072219,topology generated by a metric,"What is the procedure to prove that a particular given metric generates a particular given topology? Actually, I am given with a topology $\rho$ and a distance expression $d$ in my homework. Question is Show that the topology $\rho$ is metrizable by showing that the distance $d$ defines a metric on $\mathcal T$ that generates the topology $\rho$ . I proved that the given expression $d$ is metric on space. But how to proceed next? How to show that the metric generates the topology?","['general-topology', 'functional-analysis', 'metric-spaces']"
4072244,"Prob. 48, Chap. 1, in Royden's REAL ANALYSIS: At what points is this function continuous?","Here is Prob. 48, Chap. 1, in the book Real Analysis by H.L. Royden and P.M. Fitzpatrick, 4th edition: Define the real-valued function $f$ on $\mathbb{R}$ by setting $$
f(x) = \begin{cases} x & \mbox{ if $x$ is irrational} \\ p \sin \frac{1}{q} & \mbox{ if $x = \frac{p}{q}$ is in lowest terms}. \end{cases}
$$ At what points is $f$ continuous? I think the sequential criterion for continuity is what we will have to apply here. The function is not continuous at $x = 0 = \frac{0}{1}$ , because $f(0) = 0$ , but if we consider the sequence $\left( \frac{1}{2^n} \right)_{n \in \mathbb{N}}$ converging to $0$ , then the image sequence $\left( \sin \frac{1}{2^n} \right)_{n \in \mathbb{N} }$ does not converge to $f(0)$ . Am I right? How to check if $f$ is or is not continuous at a point $a \neq 0$ ?","['continuity', 'analysis', 'real-analysis']"
4072251,Find a third degree polynomial $p(x)$ such that the function $f$ is continuously differentiable,"Function $f$ is defined piecewise as follows: $$
f = \left\{
        \begin{array}{ll}
            1 & \quad x<-1 \\
            p(x) & \quad -1\le x\le1 \\
            e^{-4(x-1)} & \quad x>1 \\
        \end{array}
    \right.
$$ Find a third degree polynomial $p(x)$ such that the function $f$ is continuously differentiable. $$ p(x)=a_3x^3+a_2x^2+a_1x+a_0 $$ This is what I have tried this far. Lets call the functions: $$ h(x)=1 , x<-1$$ $$ g(x)=e^{-4(x-1)},x>1$$ I calculated the limits: $$\lim_{x \to -1^-} h(x)= 1$$ $$\lim_{x \to 1^+} g(x)=\lim_{x \to 1^+} e^{-4(x-1)}=1$$ Next I calculate $p(1)=1$ and $p(−1)=1$ $$p(1)=a_3+a_2+a_1+a_0 = 1$$ $$p(-1)=-a_3+a_2-a_1+a_0 = 1$$ I get: $$a_3+a_2x+a_1+a_0 + (-a_3+a_2-a_1+a_0) \Rightarrow 2a_2+2a_0=2 $$ Next I calculate the derivatives: $$ p'(x)=3a_3x^2+2a_2x+a_1 $$ $$ h'(x)=0 $$ $$ g'(x)=-4e^{-4(x-1)}$$ Next the I calculate $p'(-1) = h'(-1)$ and $p'(1) = g'(1)$ : $$3a_3-2a_2+a_1 = 0$$ $$3a_3+2a_2+a_1 = -4$$ I get: $$6a_3+2a_1=-4$$ Next I calculate the second order derivatives: $$ p''(x)=6a_3x+2a_2$$ $$ h''(x)=0 $$ $$ g''(x)=16e^{-4(x-1)}$$ Next the I calculate $p''(-1) = h''(-1)$ and $p''(1) = g''(1)$ : $$ -6a_3+2a_2=0$$ $$6a_3+2a_2=16$$ $$ \Rightarrow 4a_2=16\Rightarrow a_2=4$$ Next the I calculate $p'''(-1) = h'''(-1)$ and $p'''(1) = g'''(1)$ : $$ 6a_3=0$$ $$6a_3=-64$$ $$ \Rightarrow 12a_3=-64\Rightarrow a_3=-\frac{16}{3}$$ Now I can solve $a_0$ from the previous result $2a_2+2a_0=2$ : $$2(4)+2a_0=2\Rightarrow a_0=-3$$ I can solve $a_1$ from the previous result $6a_3+2a_1=-4$ : $$6(-\frac{16}{3})+2a_1=-4\Rightarrow a_1=14$$ Hence: $a_3 = -\frac{16}{3}\\a_2 =4\\a_1 =14\\a_0 =-3$ Edit: I found the answer. I will post it later today. In short, it was a matrix multiplication.","['continuity', 'derivatives', 'polynomials']"
4072272,Torus Killing vectors,"I'm trying to calculate the Killing vectors associated to a 2D torus, parametrised as $ds^2=a^2d\theta^2+(b+a\sin\theta)^2d\phi^2$ . From here I got the metric and found out that the only connection coefficients that don't vanish are: $$ \Gamma^\theta{}_{\phi\phi}=-\frac{(b+a\sin\theta)\cos\theta}{a} \hspace{1cm}\Gamma^\phi{}_{\theta\phi}=\Gamma^\phi{}_{\phi\theta}=\frac{a\cos\theta}{b+a\sin{\theta}}$$ From here, and given the Killing condition: $\nabla_\alpha \xi_\beta + \nabla_\beta \xi_\alpha =\partial_\alpha \xi_\beta + \partial_\beta \xi_\alpha-2\Gamma^{\lambda}_{\beta\alpha}\xi_\lambda=0$ , one can get the three following equations for the killing vectors: $$\partial_\phi \xi_\phi = \Gamma^\theta{}_{\phi\phi}\xi_\theta=-\frac{(b+a\sin\theta)\cos\theta}{a}\xi_\theta \hspace{2cm} (1)$$ $$\partial_\phi \xi_\theta + \partial_\theta \xi_\phi = \frac{2a\cos\theta}{b+a\sin{\theta}}\xi_\phi \hspace{2cm} (2)$$ $$ 2\partial_\theta \xi_\theta=0 \hspace{2cm} (3)$$ From (3) it's easy to see that $\xi_\theta=f(\phi)$ , so that (1) can be solved as: $$\xi_\phi = -\frac{(b+a\sin\theta)\cos\theta}{a}F(\phi)+g(\theta),$$ with $F'(\phi)=f(\phi)$ . This way, one can substitute in (2) and get the following differential equation: $$f'(\phi)+[-\cos(2\theta) + \frac{b}{a}\sin\theta]F(\phi)=- \frac{2a\cos\theta}{b+a\sin\theta}g(\theta)-g'(\theta)$$ But I can't see how to solve this (could be that my differential equation solving skills aren't pretty much on point though... If only I could separate variables), and wouldn't like to spend too much time on it since it could also be that I made some mistake in the previous calculations, so if anyone sees something wrong (or that I'm on the good way), any feedback will be much appreciated!","['differential-topology', 'metric-spaces', 'ordinary-differential-equations', 'differential-geometry']"
4072309,"A question regarding least norm element of a closed, convex subset of a Hilbert space","Suppose $(V, (\cdot, \cdot))$ is a Hilbert space, $U$ is a nonempty closed convex subset of $V$ , and $g \in U$ is the unique element of $U$ with smallest norm. Prove that $\Re(g, h)\ge \|g\|^2 \ \forall h\in U$ . I was thinking about considering $f=\frac{1}{2}(g+h)\in U$ . So $\|f\|^2 \ge \|g\|^2$ . Unable to get the desired inequality. Any help?","['projection', 'normed-spaces', 'hilbert-spaces', 'functional-analysis', 'convex-analysis']"
4072345,Limit of Newton's Method on polynomial $Ax^4 + Bx^3+ Cx^2 + Dx + E$?,"So if you took the function $f(x) = Ax^4 + Bx^3+ Cx^2 + Dx + E$ and did Newton's Method repeatedly, you would get a sequence that converges to at most $4$ roots. I was wondering what would happen if you took the limit of that sequence, would you get the formula for the roots of a quartic equation? And what if you do it for a polynomial of nth degree. I know it's been proven that there can't be an explicit formula for polynomials of degree higher than $4$ so I'm not sure what would happen if you tried to find it through Newton's Method. Would it not diverge because there are multiple roots and the initial term (the guess) determines which root you find? But shouldn't that just get you a formula for the root in terms of the initial guess? I tried looking at the first few terms for Newton's Method but they became too much to work with so I was wondering if there was a program that could do Newton's Method for functions with unknown coefficients. I think I could do it with Python but it would be a lot of work to do it from scratch so if there's a python library that can support operations with variables, I would then just have to write a program for Newton's Method.","['roots', 'polynomials', 'sequences-and-series', 'limits', 'quartics']"
4072354,Is there any other approach available without trig substitution?,"Let $f\colon [0, 1] \to \mathbb{R}$ be a continuous function such that for any $x, y \in [0, 1]$ , $xf(y) + yf(x) \le  1$ . Find
maximum value of $\int_0^1f(x)\,dx$ . Method given was using $x= \sin\theta$ , we get $$\int_0^1 f(x)\, dx = \int_0^{\pi/2} f(\sin\theta)\cos\theta\, d\theta \tag{I}$$ and similarly by $x= \cos\theta$ , we would get $$\int_0^1 f(x)\,dx = \int_0^{\pi/2} f(\cos\theta)\sin\theta \,d\theta \tag{II},$$ adding $(\text{I})$ and $(\text{II})$ we get max value of the required integral to be $\pi/4$ . Any other approach because the idea is very tricky and one may not realize for this type of substitution.","['calculus', 'definite-integrals']"
4072382,Help with arcsin integral,"I have the following integral: $$ I =\int x^2\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) dx$$ Where $a$ and $b$ are non-zero positive integers, and $x<a$ . I have started by integration by parts: $$ I = uv - \int vu'$$ $$u = \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right )$$ $$u' =  \left [ \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) \right ]'$$ We substitute the inside content of the arcsin by $z=\frac{\sqrt{a^2-x^2}}{b}$ : $$u' =  \left [ \sin^{-1}(z) \right ]' = \frac{1}{\sqrt{1-z^2}} \cdot  z'$$ $$z' = - \frac{x}{b} (a^2-x^2)^{- \frac{1}{2}}$$ Hence we obtain: $$u' =  -\frac{x}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}} $$ On the other hand of the integration by parts we have $v'$ : $$v' = x^2$$ $$v = \frac{1}{3}x^3$$ Hence we end up with: $$I = \frac{1}{3}x^3\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) + \frac{1}{3}\int \frac{x^4}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}} $$ I cant really figure out how to solve this final integral . Any help would be appreciated","['integration', 'indefinite-integrals', 'calculus']"
4072432,Pair graphs map maps vertices into vertices and edges on edges (or single vertex),"Definitions : Let $(X,X^0),(Y,Y^0)$ be a pair of graphs (here $X^0,Y^0$ denote the subsets of vertices) and $f : X \longmapsto Y$ be continuos map.
The definition of graph I'm using is the following : $X$ Hausdorff topological space  with $\lvert X^0 \rvert < \infty$ such that $X\backslash X^0 = \sqcup_i e_i$ , with $e_i$ open in $X$ homeomorphic to open intervals and $\overline{e}_i-e_i = \{1,2\}$ (one can think of $(\overline{e}_i,e_i) \sim ([0,1],(0,1))$ . Purpose : Calculate $f_* : H_1(X) \longmapsto H_1(Y)$ . In order to investigate and solve the problem, the following assumptions are useful : $f(X^0) \subset Y^0$ and $\forall \hspace{0.1cm} i, \hspace{0.1cm} \overline{e}_i$ is mapped homeomorphically on $\overline{e}_j$ or collapsed on a vertex in $Y^0$ . Problem : In general a maps between graphs don't satisfy the above requirements. What it should be true is that those are satisfied if we allow homotopy maps or splitting (i.e adding vertices to $(X,X^0)$ ) operations. Is this fact true? If so, how can be proved ? Any help or reference would be appreciated.","['graph-theory', 'homotopy-theory', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
4072520,Find the area of an equilateral triangle inscribed in a unit square,"If inside the square $ABCD$ there is an equilateral triangle $CMN$ inscribed, as shown in the figure. If the area of the square is 1, find the area of the triangle. I attempted to say, I state that $x=MD$ then $MC^2=1+x^2$ . $AM=1-x$ and I thought that something might come from Pythagoras, but it didn't. $\triangle AMN$ looks isosceles, but I can't prove that it is, although if it is proved to be isosceles, then the question can easily be solved by use of the pythagorean theorem. We also have that $\angle CNB+\angle CMD=150^o$ . I got stuck here, could you please explain to me how to solve the question?","['contest-math', 'euclidean-geometry', 'trigonometry', 'geometry']"
4072602,Integral being zero implies measure of set is zero.,"Let $E$ be a Lebesgue measurable set. How does $$\int_{E}e^{-x^2/2}dx=0.\tag{1}$$ imply that the $m(E)=0$ , where $m$ is the Lebesgue measure over $\mathbb{R}$ . This is a smaller part of a larger question, but I can't seem to see how it holds. Any help is appreciated. I know that $(1)$ implies $f(x):=e^{-x^2/2}=0$ Lebesgue almost everywhere on $E$ , since $f$ is a non-negative measurable function and $(1)$ holds.","['measure-theory', 'real-analysis']"
4072604,Twists of elliptic curves over finite fields with characteristic 2 and 3,"Let $E$ be an elliptic curve over a finite field $K$ . In Silverman's The Arithmetic of Elliptic Curves , it is shown in Proposition 5.4. on page 343 that if the characteristic of $K$ is not equal to $2$ or $3$ , then the equations of all twists of $E$ can be described explicitly: Question : Is there a general description of the equations of an elliptic curve in Weierstrass form if $char(K)$ is $2$ or $3$ ? In this paper by Kronberg, Soomro, Top , I can see how many twists an elliptic curve over a finite field with characteristic $2$ or $3$ has but I did not see (yet?) how these equations would look like.","['algebraic-number-theory', 'elliptic-curves', 'finite-fields', 'algebraic-geometry', 'abstract-algebra']"
4072618,Why $X\times\emptyset=\emptyset?$,"If is true that $X\times\emptyset=\emptyset$ , so take $A\times B$ with $U,V\subset A$ and $R,S\subset B$ . We know that $(U\cup V)\times(R\cup S)=(U\times R)\cup (V\times S)$ . So, take $X$ with $|X|\ge2$ , then $X\times X=(X\setminus\{x\}\cup\{x\})\times(X\cup\emptyset)=(X\setminus\{x\}\times X)\cup(\{x\}\times\emptyset)=X\setminus\{x\}\times X?$ . It's a paradox or I miss anything?",['elementary-set-theory']
4072647,Does every $L^1_{\text{loc}}$-function have a signed measure as a distributional derivative?,"Edit. To clear up the confusion that I caused, I will define a signed measure here. The literature sometimes calls it ""extended signed measure"": Definition. A signed measure $\mu$ on $(\mathbb R, \text{Borel sets})$ is a function $$\mu:\text{Borel sets}\to\mathbb R\cup\{\infty\}$$ or a function $$\mu:\text{Borel sets}\to\mathbb R\cup\{-\infty\}$$ such that $\mu(\emptyset)=0$ , for any disjoint Borel sets $A_1, A_2, A_3, \dots$ , we have $$\mu\left(\bigcup_{n\in\mathbb N} A_n\right)=\sum_{n\in\mathbb N} \mu(A_n),$$ with the convention that $\infty+\text{anything}=\infty$ and $-\infty+\text{anything}=-\infty$ . Note that $\infty-\infty$ can never occur, since $\{-\infty, \infty\}\subset\operatorname{Image}\mu$ is impossible by definition. Back to the question. Let $f\in L^1_{\text{loc}}(\mathbb R)$ , i.e. $f$ is a locally absolutely integrable function. It is well-known that the distributional derivative of $f$ doesn't have to be expressible as a $L_{\text{loc}}^1$ function again. For example, if $f$ is the characteristic function of $[0,\infty[$ (or the characteristic function of $]0,\infty[$ , for that matter), then its distributional derivative corresponds to the Dirac measure $\delta_0$ , which has no $L^1_{\text{loc}}$ -density with respect to the Lebesgue measure. Similarly, if we have a measure on $\mathbb R$ , its distributional derivative need not be a measure again. Continuing the above example, the distributional derivative of $\delta_0$ is given by the bounded linear operator \begin{split}\delta_0': \mathcal C_{\text c}^\infty(\mathbb R) &\to \mathbb R \\ \phi&\mapsto-\phi'(0),\end{split} which is not expressible as a measure on $\mathbb R$ . My question: Does every $L_{\text{loc}}^1$ -function have a distributional derivative that can be expressed as a signed measure ? More explicitly, if $f\in L_{\text{loc}}^1(\mathbb R)$ , does there always exist a signed measure $\mu$ on $(\mathbb R, \text{Borel sets})$ such that \begin{equation}\tag{*}\label{*}\bbox[15px,border:1px groove navy]{\int_{\mathbb R}\phi\,\mathrm d\mu = -\int_{\mathbb R}\phi'(t)\cdot f(t)\,\mathrm dt}\end{equation} for every $\phi\in\mathcal C_{\text c}^\infty(\mathbb R)$ ? Note: In particular, I demand that $\int_{\mathbb R}\phi\,\mathrm d\mu$ is well-defined for every $\mathcal C_{\text c}^\infty(\mathbb R)$ (which, since $\mu$ is signed, can be actually quite a messy affair.)","['measure-theory', 'weak-derivatives', 'distribution-theory']"
4072670,"Given $z, w\in\mathbb{C}$ prove that $|z| = 1$ implies $|(z + w)/(1 + \overline{z}w)| = 1$","I know I am supposed to write my process, but the thing is I have no clue. I tried to rewrite $z$ as $a + bi$ and $w$ as $x + yi$ and try to rearrange the left side in a way I can get to the other, but no success. Then I tried to solve like $|(z + w)/(1 +  \overline{z}w)| = 1$ iff $|z| = 1$ because i thought it would be easier to make $w$ ""disapear"" and end up with $|z| = 1$ , but no success as well. (i am not putting what i did, because it's all wrong and useless) I hope you know and help me :(","['complex-analysis', 'solution-verification', 'complex-numbers']"
4072724,Conditional Expectation: $E(X|Y) \geq Y$ and $E(Y|X) \geq X$ implies $X=Y$ a.e.,Suppose for random variables $X$ and $Y$ with finite expectation we he have $E(X|Y) \geq Y$ and $E(Y|X) \geq X$ .  We want to show that $X=Y$ almost everywhere. My attempt: Let $A \in \sigma(X)$ and $B \in \sigma(Y)$ .  Then we have $\int_B X = \int_B E(X | Y) \geq \int_B Y$ and $\int_A Y = \int_B E(Y | X) \geq \int_A X$ . My idea now is to consider sets of the form $\{X>a>Y\}$ for $a$ rational but I'm having trouble with getting the other variable involved.  The issue seems to be that $\{X>a\}$ is in $\sigma(X)$ but not necessarily in $\sigma(Y)$ and it seems like we cannot get the other inequality working.  Any help would be appreciated.,"['measure-theory', 'statistics', 'real-analysis', 'probability-theory', 'probability']"
4072766,"Is there a relationship between the multiplicity of an index and the ""algebraic"" multiplicity of a zero of a section from a (complex) vector bundle?","I'm a physicist who is trying to make sense of the relationship between the number of zeros of a section from an associated vector bundle and the Euler characteristic. My interest lies in applications to gauge theories in which finite energy solutions can be classified according to a topological charge (which is a Chern number/topological degree in the cases I know, and can be related to the Euler characteristic). More precisely, let us consider theorem 11.17 in the book Differential forms ins algebraic Topology from Bott-Tu: Let $\pi:E\to M$ be an oriented rank k vector bundle over a
compact oriented manifold of dimension k. Let s be a section of E with a finite
number of zeros. The Euler class of E is Poincare dual to the zeros of s,
counted with the appropriate multiplicities. I have sometimes found it stated that the topological degree counts the number of zeros of a section, with multiplicity. I believe the above theorem is the mathematical justification for this (do correct me if I am wrong, please). But the multiplicity this theorem is talking about is ""the local degree of x as a singularity of the section $s/||s||$ of the unit sphere bundle of E relative to some Riemannian structure on E"", according to the authors. I wanna know when (if ever) there exists a relationship between this meaning of multiplicity and that found in, say, complex analysis (that's what I called algebraic multiplicity in the title). I will assume the zeros are isolated. My question was motivated by the behavior of axially symmetric magnetic vortices in the static case of the Nielsen-Olesen/Ginzburg-Landau theory. Here we have a scalar field $\varphi:\mathbb{R^2}\to\mathbb{C}$ , seen as a section of the line bundle. Axially symmetric solutions can be taken in the form $\varphi=f(r)e^{in\theta}$ , where $n$ is the (integer) topological degree. This field is coupled to a connection $A_{\theta}=A_{\theta}(r)$ . The boundary conditions ensure those fields are nonsingular and that the magnetic flux is proportional to $n$ . $\varphi$ must have a zero at the origin (and nowhere else). The multiplicity of this zero, in the sense described by Bott-Tu, is indeed $n$ , and it may be verified that $f(r)\propto r^n$ to leading order in its power series expansion, so $f(r)$ has a zero of multiplicity $n$ . This sounds a lot like the Argument Principle, with the difference that $\varphi$ does not have a complex domain. If $r$ and $\theta$ could be seen as polar coordinates in the complex plane, then this would be a zero of multiplicity $n$ in $\mathbb{C}$ . The exact same $r^n$ behavior appears in all vortex theories I know, like [Maxwell or pure] Chern-Simons and many other generalized models, some very different from Nielsen-Olesen. I'm interested in developing models in gauge theories such as the aforementioned ones (with the exact same topology, bundle and covariant derivative, but different equations of motion), and would like to know if I should expect such a behavior to occur in the solutions to such theories. Could I find a solution where, for example, $f(r)\propto r^m$ , where $m\neq n$ or would that somehow lead to a problem in my theory? Can the degree be used to predict anything about the multiplicity of the zeros of $f(r)$ ? Edit (because I accidentally pressed enter before finishing the current bounty description, and didn't find a way to edit that description): While a very good answer has been provided, I still haven't been able to figure out (even after reading some of the references) if something like $f(r)\propto r^m$ could be obtained as a leading order approximation near the origin, with $m\neq n$ . The answer to that might be implicit from the current answer, but I can't see it. A definite answer to the last paragraph preceding this edit is sufficient for the reward (although any information concerning sections with a form more general than the proposed $f(r) e^{in\theta}$ will be greatly appreciated as well).","['fiber-bundles', 'mathematical-physics', 'differential-topology', 'characteristic-classes', 'differential-geometry']"
4072769,Evaluating $\prod_{k=1}^m \tan \frac{k\pi}{2m+1}$ [duplicate],"This question already has answers here : Simplify $\prod_{k=1}^5\tan\frac{k\pi}{11}$ and $\sum_{k=1}^5\tan^2\frac{k\pi}{11}$ (2 answers) Proving that $\prod_{k=1}^{n}\tan\left(\frac{\pi k}{2n+1}\right)=\sqrt{2n+1}$ using geometry (3 answers) Closed 3 years ago . How to evaluate this? $$\prod_{k=1}^m \tan \frac{k\pi}{2m+1}$$ My work I couldn't figure out a method to solve this product.
I thought that this identity could help. $$\frac{e^{i\theta}-1}{e^{i\theta}+1}=i\tan \frac{\theta}{2}$$ By supposing $z=e^{\frac{2k\pi}{2m+1}i}$ , then, $$i\tan \frac{k\pi}{2m+1}=\frac{z-1}{z+1}$$ So, the product $$\displaystyle\prod_{k=1}^m \tan\frac{k\pi}{2m+1}=\displaystyle\prod_{k=1}^m \frac{z-1}{i(z+1)}=\displaystyle\prod_{k=1}^m \frac{e^{\frac{2k\pi}{2m+1}i}-1}{i(e^{\frac{2k\pi}{2m+1}i}+1)}$$ which is getting more complicated. Answer is $\sqrt{2m+1}$ . Any help is appreciated.","['trigonometry', 'complex-numbers', 'products']"
4072802,What is the partial derivative (w.r.t. a vector) of this integral over a matrix vector product?,"Question With two vectors $r(x(t), y(x(t), u(t)))$ and $u(t)$ , what is the matrix of partial derivatives $$\frac{\partial r}{\partial u}\ =\ ?$$ when the total derivative is known as $$\frac{dr}{dt} = F(x(t)) (u^\ast - u(t))$$ where the RHS is a matrix vector product? By integration I obtain the vector function $r$ such that $r(t_1) = r(t_0) + \int_{t_0}^{t_1} F(x(t)) (u^\ast - u(t)) dt$ . For context, this is from a control problem. I want to feed $u(t)$ to the system using $$\frac{du}{dt} = - \left(\frac{\partial r}{\partial u}\right)^T Q r,$$ which is why I try to determine $\frac{\partial r}{\partial u}$ . Update: With $r \in \mathbb{R}^{n' \times 1}, u \in \mathbb{R}^{m \times 1}$ and a matrix function $F: \mathbb{R}^{n' \times 1} \rightarrow \mathbb{R}^{n' \times m}$ , I will most likely have to form the derivative $\frac{\partial F}{\partial u}$ of a matrix w.r.t. a vector to answer this question. That would intermediately introduce tensors of higher order. Potentially, my question is related to the question asked here . The accepted answer suggests working with differentials to avoid higher order tensors, but I don’t know how to apply differentials to my question given the integral in the expression for $r$ . Details Let me add more information on this question, which emerges from a control problem. Background I have a dynamical system $$\frac{d}{dt} \begin{bmatrix}x\\y\end{bmatrix} = \begin{bmatrix}F(x(t)) \ u^\ast\\F(x(t))\ u(t)\end{bmatrix}$$ with a state of size $\mathbb{R}^{n}$ , an input vector $u(t)$ and unknown constant vector $u^\ast$ ( $u, u^\ast \in \mathbb{R}^m$ ) and a function matrix $F(x(t)) \in \mathbb{R}^{(n/2) \times m}$ . Starting from an initial guess $u(t_0) = u_0$ I want to improve $u(t)$ such that the vector $$r(t) = x(t) - y(t)$$ converges to zero for $t \rightarrow \infty$ ( $r, x, y \in \mathbb{R}^{n/2}$ ). Aim: The input $u(t)$ is supposed to be an estimate of the unknown $u^\ast$ . I try to find a control law $u(t)$ in the form of an ODE $\frac{du}{dt} = \dots$ that ensures the convergence of $r(t) \rightarrow 0$ starting with an initial guess $u(t_0) = u_0$ for $u^\ast$ . I am looking for a representation $\frac{du}{dt} = \dots$ such that I can feed $u(t) = u_0 + \int_{t_0}^t \frac{du}{d\tau} d\tau$ into the system. My attempt In order to minimize $r(t)$ I define a loss function $$\mathcal{L}(r(t)) = \frac{1}{2} r(t)^T Q r(t)$$ with constant symmetric positive definite $Q > 0$ and $r, x, y \in \mathbb{R}^{n/2}$ . From the system dynamics I know that $r$ evolves over time: $$\frac{dr}{dt} = F(x(t)) (u^\ast - u(t))$$ with $u^\ast, u(t) \in \mathbb{R}^m$ , unknown constant $u^\ast$ and a function matrix $F(x(t)): \mathbb{R}^{n/2} \rightarrow \mathbb{R}^{(n/2) \times m}$ . In order to get convergence of $r(t) \rightarrow 0$ over time, I want to update $u(t)$ using the gradient flow of the loss function: $$\frac{du}{dt} = - \nabla_u \mathcal{L}.$$ When trying to calculate the (transposed) gradient of $\mathcal{L}$ w.r.t. $u$ $$\left(\nabla_u \mathcal{L}\right)^T = \frac{\partial \mathcal{L}}{\partial u} = r^T Q \frac{\partial r}{\partial u},$$ I encounter as a problem that I only know $\frac{dr}{dt}$ and not $r$ as a function $r(u)$ itself . So I am not sure how to calculate the partial derivatives $\frac{\partial r}{\partial u}$ : $$\frac{\partial r}{\partial u} \stackrel{?}{=} \frac{\partial}{\partial u} \int_{t_0}^{t_1} F(x(t)) (u^\ast - u(t)) dt \stackrel{?}{=} - \int_{t_0}^{t_1} F(x(t)) \frac{\partial}{\partial u} u(t) dt \stackrel{?}{=} - \int_{t_0}^{t_1} F(x(t)) dt\ =\ ?$$ I am not sure what the last integral evaluate to. Maybe $F(x(t))$ ? If so, how? Maybe there are more intelligent ways to obtain $\frac{\partial r}{\partial u}$ or even to achieve $r(t) \rightarrow 0$ ? I would be very happy if anyone could help me, please? The final step is then to get the control law $$\frac{du}{dt} = - \nabla_u \mathcal{L} = - \left(\frac{\partial r}{\partial u}\right)^T Q r,$$ for which I need to know $\frac{\partial r}{\partial u}$ . Last remarks Unfortunately in CS we often use mathematics quite sloppy, but I now try to teach myself to be mathematically rigorous. Is there anything I can change to make my approach more mathematically precise? All suggestions are welcome!","['ordinary-differential-equations', 'control-theory', 'multivariable-calculus', 'matrix-calculus', 'dynamical-systems']"
4072823,"Evaluating $\int_{0}^{1} \frac{x^{2n+2}}{x^2-2x+2}\,{\rm d}x$","$$\int_{0}^{1} \frac{x^{2n+2}}{x^2-2x+2} \,{\rm d}x \tag{1}$$ This integral came up as a result of another integral I was trying to evaluate. Just for recreational purposes. Is there some closed form for this, even in terms of special functions? In general, is it possible to evaluate integrals of the form: $$\int_{0}^{1} \frac{P(x,x^n)}{Q(x)} \,{\rm d}x \tag{2}$$ with $\text{deg}(P) > \deg(Q)$ ? For example: $$\int_{0}^{1} \frac{x^n}{1+x^2} \,{\rm d}x \tag{3}$$ can be written in terms of the digamma function. If I'm not mistaken, $(1)$ does not follow from $(3)$ , because if you try to complete the square in the denominator of $(1)$ , you'd end up having to perform a $u$ -sub with $u = x-1$ and then a $(u+1)^{2n+2}$ in the numerator. This ruins things. Can someone give some help?","['integration', 'definite-integrals']"
