question_id,title,body,tags
2269802,Why is the structure sheaf (sheaf of rings) $\mathcal{O}$ on $\mathrm{Spec}\ A$ a sheaf?,"Let $X = \mathrm{Spec}\ A$, and for each prime ideal $\mathfrak{p} \subseteq A$, let $A_{\mathfrak{p}}$ be the localization of $A$ at $\mathfrak{p}$. Now, for  each open set $U \subseteq X$, define $\mathcal{O}(U)$ to be the set of functions
$$s: U \rightarrow \coprod_{\mathfrak{p} \in U} A_{\mathfrak{p}}$$
such that $s(\mathfrak{p}) \in A_{\mathfrak{p}}$ for each $\mathfrak{p}$, and such that $s$ is locally a quotient of elements of $A$, that is, for each $\mathfrak{p} \in U$, there is some neighborhood $V_{\mathfrak{p}}$ of $\mathfrak{p}$ with $V_{\mathfrak{p}} \subseteq U$ and elements $a,f \in A$ such that for each $\mathfrak{q} \in V$ and $f \notin \mathfrak{q}$, $s(\mathfrak{q} )= a/f$ in $A_{\mathfrak{q}}$. My question is Why is the sheaf of rings $\mathcal{O}$ defined above a sheaf of rings? While it seems clear that $\mathcal{O}$ is a presheaf, I fail to see why it satisfies the extra axioms that make it a sheaf. Hartshorne says ""it is clear from the local nature of the definition that $\mathcal{O}$ is a sheaf"", but while trying to prove it formally, I couldn't show that it is actually a sheaf. Also, I've just been fiddling around with the definitions for the moment trying to gain some insight about why this ""provides a systematic way of keeping track of local algebraic data on $\mathrm{Spec}\ A$"", but for now, it's just as mysterious as it was at the beginning. So if anyone could provide me some insight about why this is what we want to be our definition of structure sheaf, I'd be very grateful for that. Thank you in advance!","['sheaf-theory', 'algebraic-geometry', 'commutative-algebra']"
2269855,Polynomials with same image on the rationals?,"I am struggling with this problem: If $P_1$ and $P_2$ are two polynomials such that $P_1(\mathbb{Q})=P_2(\mathbb{Q})$, show that $P_1(x)=P_2(ax+b)$ for some constants $a,b$. Here is what I have done. First, taking a linearly independent basis over $\mathbb{Q}$ and expressing the coefficients with it, you can reduce the problem to that of rational polynomials $P_1,P_2$. If both are of odd degree , you can translate both polynomials so that near $x=0$, they are asymptotic to $kx$ for some $k$. Make them integer polynomials too (by multiplying them by a large enough number). Then evaluate $P_1(\frac{1}{q})$ for large primes $q$; then $P_2$ has to ""catch up"" with the denominator, so that $P_1(\frac{1}{q})=P_2(\frac{p}{kq})$. Constraints on $k$ quickly show that $P_1=P_2$. (I will not write all the details.) I have, however, a technical difficulty with polynomials of even degree . They tend to positive infinity in both directions, and I cannot be sure that ""these"" large values of $x$ correspond to those, which would allow me to equate neighbourhoods and run the above argument. Or have I missed the best strategy by miles?","['number-theory', 'abstract-algebra', 'polynomials']"
2269874,What is the significance of a Divisibility Sequence?,"I have been learning about the Fibonacci Sequence in school and came across the interesting property: $$\gcd(F_m, F_n) = F_{gcd(m, n)}$$ where $F_m$ and $F_n$ are the $mth$ and $nth$ number from the Fibonacci sequence. Apparently, this is the defining property of a Strong Divisibility Sequence. I've been searching online for quite some time for what a divisibility sequence really means but there are only complex research papers :( Are there any interesting or real life applications of them? Can anyone help explain the concept to me please?","['number-theory', 'fibonacci-numbers', 'sequences-and-series', 'elementary-number-theory']"
2269960,Finding the value of the determinant $|M^2+MN^2|$ and determining whether $U$ is a zero matrix or not,"Let $M$ and $N$ be two $3\times 3$ matrices such that $MN=NM$. Further
  if $M\neq N^2$ and $M^2=N^4$ then what is/are the possible value(s) of
  the determinant $|M^2+MN^2|$? Also if there is a $3\times 3$ matrix
  $U$ such that $(M^2+MN^2)U=O$ can we say whether $U$ is a zero matrix or
  a non-zero matrix ? My Attempt: $|M|=\pm|N|^2$ (from $M^2=N^4$) $(M-N)(N-M)=M^2-N^2$ (as $MN=NM$) $M^2=N^4$ $\implies MMN=N^5$ $\implies NMMN=N^6$ $\implies MNMN=N^6$ $\implies (MN)^2=N^6$ Similarly, $M^6=(MN)^4$ These are what I could deduce from the given information. How should I proceed from here to solve the question?","['matrices', 'linear-algebra', 'determinant']"
2269975,Is this inequality on Schatten p-norm and diagonal elements true?,"Let $A=[a_{ij}]\in\mathbb R^{m\times n}$ be a matrix with $m\ge n$, and $\Vert A\Vert_p$ be the Schatten p-norm of $A$. It is known that $\Vert A\Vert_1\ge \sum_i \vert a_{ii}\vert$ and $\Vert A\Vert_2^2=\Vert A\Vert_F^2\ge \sum_i \vert a_{ii}\vert^2$. Can we show that $\Vert A\Vert_p^p\ge \sum_i \vert a_{ii}\vert^p$ for general $p\ge 1$? Thanks!","['matrices', 'normed-spaces', 'linear-algebra']"
2269977,"For a piecewise function $g_n(t)$, find $g(t)=\lim\limits_{n\rightarrow \infty}g_n(t)$.","I think that I have found a somewhat unorthodox way of doing this question. I have written the question and my solution and finger-crossed it will be okay! Consider the space $C=[0,1]$ of continuous functions equipped with a supremum norm $\left\|\cdot\right\|_{\infty}$. For each $n=1,2,...$ let the function $g_n \in C[0,1]$ be defined by the rule: $$   
g_n(t) = 
     \begin{cases}
       2nt &\quad\text{if } 0\le t \le \frac{1}{2n};\\
       2 -2nt,  &\quad\text{if } \frac{1}{2n}\le t \le \frac{1}{n};\\
       0, &\quad\text{if } \frac{1}{n} \le t \le 1.\\
     \end{cases}
$$ (i) Find $g(t) =\lim\limits_{n\rightarrow \infty}g_n(t)$ for all $t\in [0,1]$. Briefly explain how you arrived at your answer. (ii) Find $g(t) =\lim\limits_{n\rightarrow \infty}\|g_n(t)\|_{\infty}$. Briefly explain how you arrived at your answer. (iii) Is it true that $\lim\limits_{n\rightarrow \infty}\|g_n - g\|_{\infty}=0$? Justify your answer. My answer: I rewrote the rule as 
$$   
f(x) = 
     \begin{cases}
       2x &\quad\text{if } 0\le x \le \frac{1}{2};\\
       2 -2x,  &\quad\text{if } \frac{1}{2}\le x \le 1;\\
       0, &\quad\text{if } 1 \le x \le n,\\
     \end{cases}
$$ where I have redefined $x=nt$. (i) Therefore, for the first question I get $g(t)=0$ as $f(x)\rightarrow 0$. (ii)  $g(t) =\lim\limits_{n\rightarrow \infty}\|g_n(t)\|_{\infty} =\lim\limits_{n\rightarrow \infty}\|f(x)\|_{\infty}= \lim\limits_{n\rightarrow \infty}1 = 1$ (iii)  $\lim\limits_{n\rightarrow \infty}\|g_n - g\|_{\infty}= \lim\limits_{n\rightarrow \infty}\|g_n - 0\|_{\infty}=\lim\limits_{n\rightarrow \infty}\|g_n\|_{\infty}= \lim\limits_{n\rightarrow \infty}1=1$, by the above.","['functional-analysis', 'measure-theory', 'supremum-and-infimum']"
2269992,Rate of convergence in the central limit theorem (Lindeberg–Lévy),"There are similar posts to this one on stackexchange but none of those seem to actually answer my questions. So consider the CLT in the most common form. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $X_1 \in L^2(P)$ and $\mathbb{E}[X_i]= \mu$ and $\mathbb{V}ar[X_i] = \sigma^2>0$. Denote with $\widehat{X}:= \frac{(X_1+\dots+X_n)}{n}$. Then it holds that 
$$\sqrt{n} (\widehat{X} - \mu) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,{\sigma}^2)$$ 
or, equivalently, 
$$\sqrt{n} \left( \frac{\widehat{X} - \mu}{\sigma} \right) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,1).$$ I often see statements like the rate of convergence is of order $\frac{1}{\sqrt{n}}$. Trying to interpret this, this is what I have understood (informally) so far: According to the strong law of large numbers, given the above
  conditions, $$\widehat{X} - \mu\overset{a.s.}{\longrightarrow} 0.$$
  However $\widehat{X} - \mu$ stops converging to zero when multiplied
  by $\sqrt{n}$. So one says that the rate of convergence is of order
  $\frac{1}{\sqrt{n}}$. So here are my questions: How does one define the order of convergence in this case using formal notation? Why does one say of order $\frac{1}{\sqrt{n}}$ and not of order $\sqrt{n}$? How do we know that if multiplied, for example, by a factor of lower or higher order, like $\sqrt[3]{n}$ or $n$, one would not get a random variable converging in distribution to some a.s. non-zero random variable (as opposed to the argument: ""However $\widehat{X} - \mu$ stops converging to zero when multiplied by $\sqrt{n}$."" ? And, most importantly, can someone actually show rigorously that the rate of convergence is exactly of order $\frac{1}{\sqrt{n}}$?","['probability-limit-theorems', 'probability-theory', 'statistics', 'central-limit-theorem', 'probability']"
2270028,Uniform convergence and sequences of minima,"Let $\Omega \subset \mathbb{R}^n$,  $f \in C(\Omega)$ and $g \in C^1(\Omega)$ and assume that $f - g$ has a strict global minimum at $x \in \Omega$. Is the following true? there exists a sequence of functions $\{f_n\}$ such that $f_n \to f$ uniformly $\implies$ there is a sequence of points $x_n \to x$ such that $f_n(x_n) \to f(x)$ and  $f_n - g$ has a global minimum at $x_n$?","['functional-analysis', 'real-analysis']"
2270031,Differentiation -,Finding derivatives of this function - $h(y)= (y^{-3}+2y)(2+3y^3)^{-1/2} $ I tried and weren't sure on how to simplify it to get the answer $\frac{8-27y^{-1} - 12y^4-6y^3}{2(2+3y^3)^{3/2}} $ This is my try - $ (y^{-3} + 2y) (\frac{-1}{2} (2+3y^3)^{-3/2} (0+9y^2)) + (2+3y^3)(-3y^{-4} + 2) $ I simplified it till - $ (2+3y^3)^{-3/2}(-9/2 (y^{-3} + 2y) + (2+3y^3)^{5/2}(-3y^{-4} +2) $ $ \frac{(-9/2 (y^{-3} + 2y) + (2+3y^3)^{5/2}(-3y^{-4} +2)}{ (2+3y^3)^{3/2}}$ I'm not too sure how to simplify this further .. thanks !,"['derivatives', 'calculus']"
2270039,Monic polynomial of degree 5,"Consider a monic polynomial $f(x)$ of degree $5$. The graphs of $f(|x|)$ and $|f(x)|$ are same. If $4$ is a root of $f(x)$, find $f(1)$. I had some problems while drawing the graph of the function. Can anyone explain the solution?","['algebra-precalculus', 'polynomials', 'graphing-functions']"
2270040,Any quaternion Kählerian manifold of dimension $\geq 8$ is an Einstein space?,"I wan't to understand the proof this theorem: Any quaternion Kählerian manifold of dimension $\geq 8$ is an Einstein space. In the book ""Structures on manifolds"" by Kentaro Yano and Masahiro Kon is said that this fact is a corollary of these $2$ lemmas. Lemma $1.$ For any quaternion Kählerian manifold $M$ of dimension
  $n \geq 8$, the Ricci tensor $S$ of $M$ is parallel. Lemma $2.$ Let $(M,g,V)$ be a quaternion Kählerian manifold of
  dimension $\geq 8$. Then the Riemannian manifold $(M,g)$ is irreducible if
  $(M,g)$ has non-vanishing Ricci tensor. However I can't see directly how to use them to prove the theorem using the lemmas, neither is it written in the book. Can someone please help me with that. Or tell me where can I read more detailed proof of the theorem? Thanks in advance!","['quaternions', 'kahler-manifolds', 'riemannian-geometry', 'differential-geometry']"
2270058,How to prove that every real number is the limit of a convergent sequence of rational numbers?,"Here is my procedure:
so we want to prove $\forall r\in \mathbb{R},$ there exists a sequence $q_n$ of rationals such that $\forall\epsilon\gt 0,$ there exists a $N$ such that $n\gt N\implies |q_n-r|\lt\epsilon$. I believe we can apply Denseness of $\mathbb{Q}$, which states that if $a,b\in \mathbb{R}$ and $a\lt b$, then $\exists q\in\mathbb{Q}$ such that $a\lt q \lt b$. By density theorem, we can claim: let $r\in\mathbb{R}$, since $r-\epsilon\lt r+\epsilon$ for any $\epsilon\gt 0$, $\exists q_n\in\mathbb{Q} $ (this is for any $n\in \mathbb{N}$) such that $r-\epsilon\lt q_n\lt r+\epsilon$. Then we can pick and ideal $N$  such that $|q_n-r|\lt \epsilon$. First, I am not quite confident about the proof as I felt I skipped or missed lots of elements. Second, my process doesn't seem to follow the ""let $r$ be..., let $q_n$ be..., let $\epsilon$ be..., ..."". Could someone help me fix the proof?","['real-numbers', 'calculus', 'proof-verification', 'proof-writing', 'proof-explanation']"
2270113,unit sphere simply connected,"I want to prove that the unit sphere $S^2$ is simply connected. In order to do this I am given the following steps: 1. Let $x_1,x_2 \in S^2$ and $\gamma \in P(S^2;x_1,x_2)$ be a path. Let $p \in S^2 \setminus \{x_1,x_2\}$. Assume $\gamma$ is not surjective. Prove that $\gamma$ is path homotopic to a path $\gamma'$ that doesn't cross $p$. (You may assume that $S^2 \setminus \{p\}$ is contractible) 2. Let $x_1,x_2 \in S^2$ en $\gamma \in P(S^2;x_1,x_2)$ again be a path. Prove that $\gamma$ is path homotopic to a non-surjective path $\gamma'$. (Has something to do with a covering space of $S^2$) 3. Prove that every loop in $S^2$ with basepoint $x_0$ is path homotopic to the constant loop with image $x_0$. 4. Conclude that $S^2$ is simply connected. In the first step I suppose you just have to choose a point $x_3 \in S^2$, which is not on the shortest path from $x_1$ to $p$ or $p$ to $x_2$ in order to construct a path that doesn't cross $p$ and is path homotopic to $\gamma$. But the rest of the steps I don't really get. Could you please give me some hints/information to give me something to work with as I am stuck? Thanks in advance!","['spheres', 'general-topology', 'homotopy-theory']"
2270144,Question on why Hilbert-Schmidt operator definition is independent of the choice of basis,"We have just covered Hilbert-Schmidt operators in class (which I missed) and I am having a hard time understanding them. I know the definition: If $\;H,F\;$ are Hilbert spaces and $\;T \in \mathcal B(H,F)\;$ then
  $\;T\;$ is Hilbert-Schmidt if there is some orthonormal basis of
  $\;H\;$ such that: $\; \sum_{n=1}^{\infty} {\vert \vert T(e_n)\vert
 \vert}^2 <∞\;$ An easy calculation shows that this definition does not depend on the choice of basis. I understand why $\sum_{n=1}^{\infty} {\vert \vert T(e_n)\vert
 \vert}^2 \;=\;\sum_{k=1}^{\infty} {\vert \vert T^*(f_k)\vert
 \vert}^2 \;$ where $\; \{ e_n \} \;,\;  \{ f_k \}\;$ are orthonormal basis on $\;H,F\;$ respectively. But I have trouble understanding why this shows that the operator is well defined. I believe I should have $\sum_{n=1}^{\infty} {\vert \vert T(e_n)\vert
 \vert}^2 \;=\;\sum_{n=1}^{\infty} {\vert \vert T(e_n)'\vert
 \vert}^2 \;$ where $\; \{ e_n \} \;,\;  \{ e_n \}'\;$ are orthonormal basis on $\;H\;$ in order to claim the independence of the choice of basis. Is this equal to the above statement somehow? I would appreciate any help! Thanks in advance","['functional-analysis', 'compact-operators', 'operator-theory', 'hilbert-spaces']"
2270151,"What is the Fourier transform of $ f=\chi_{[-1,1]} $?","I am totally new to Fourier transforms, so I would be very thankful for a feedback on my calculation. I want to calculate the Fourier transform of $ f=\chi_{[-1,1]} $, that is, $f(x)=1$ for $-1\le x\le 1$ and $0$ otherwise. My answer:
\begin{align*}
\widehat{f}(\omega)&=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}f(x)e^{-i\omega x}dx\\
&=\frac{1}{\sqrt{2\pi}}\int_{-1}^{1}e^{-i\omega x}dx\\
&=\frac{1}{\sqrt{2\pi}}\left[\frac{1}{-i\omega}e^{-i\omega x}\right]_{-1}^1\\
&=\frac{1}{\sqrt{2\pi}}\frac{1}{-i\omega}\left(e^{-i\omega}-e^{i\omega}\right)\\
&=\frac{1}{\sqrt{2\pi}}\frac{1}{-i\omega}(-2i\sin \omega)\\
&=\sqrt{\frac{2}{\pi}}\frac{1}{\omega} \sin \omega
\end{align*}
where I have used the relation
$$ \sin \omega = \frac{1}{2i} \left( e^{i\omega} - e^{-i\omega}\right). $$
Is this correct?","['fourier-analysis', 'trigonometry', 'functional-analysis', 'integration', 'fourier-transform']"
2270154,How many group homomorphisms $\phi: S_5\to C_5$ are there?,"Denote by $S_5$ and $C_5$ the fifth symmetric and cyclic group respectively. How many homomorphisms $\phi: S_5\to C_5$ are there? I think that there is only one, but I'm not too confident in my attempted proof! My attempted proof: for $i= 1,...,4$, denote the transposition $\sigma_{i,i+1}:=(i\;\; i+1)$. Since $\sigma_i$ generate $S_5$, all homomorphisms, $\phi$, are determined by their behaviour on $\sigma_i$. Observe that $\sigma_i^2 = \mathrm{Id}\implies \phi(\sigma_i)^2=\mathrm{Id}$ and that $\phi(\sigma_i)^5 = \mathrm{Id}$, since the target group is $C_5$. Therefore, the order of $\phi(\sigma_i)$ must be 1 for all $i$. Hence there is only one homomorphism, namely $\phi\equiv \mathrm{Id}$.","['finite-groups', 'permutations', 'group-theory']"
2270167,Mistake with using residue theory for calculating $\int_{-\infty}^{\infty}\frac{\sin(x)}{x}dx$,"In physics, we do contour integrals in a not so rigorous way most of the times. Now, I want to use a trick to compute $$\int_{-\infty}^{\infty}\frac{\sin(x)}{x}dx$$ using residue theory. I find: $$\int_{-\infty}^{\infty}\frac{\sin(x)}{x}dx=2\pi$$which is clearly wrong since the correct value is $\pi$. I don't know what I am doing wrong here but I think it might have to do with using the residue theorem in a clumsy way. Any help in finding the mistake will be much appreciated. My solutions is the following(sorry if my notation(arguments) is too awkward(or not rigorous enough)): $$\int_{-\infty}^{\infty}\frac{\sin(x)}{x}dx=Im\left[\int_{-\infty}^{\infty}\frac{e^{ix}}{x}dx\right]=Im\left[\lim_{ε\to0}\int_{-\infty}^{\infty}\frac{e^{ix}}{x-iε}dx\right]$$ which has a residue just above $x=0$ on the complex plane. Now, consider the following integration paths: So, I can write the above integral as: $$Im\left[\lim_{ε\to0}\int_{-\infty}^{\infty}\frac{e^{ix}}{x-iε}dx\right]=Im\left[\lim_{ε\to0}\int_{C2}\frac{e^{ix}}{x-iε}dx\right]$$(of course $R\to \infty$) Now, if we integrated the same integrand but the path was $C1$, it would give zero since the integrand tends to zero for large $Im[x]$ on the upper plane(this argument was used by a professor of our for a scattering problem in quantum mechanics). So, we can now write: $$Im\left[\lim_{ε\to0}\int_{C2}\frac{e^{ix}}{x-iε}dx\right]=Im\left[\lim_{ε\to0}\int_{C1+C2}\frac{e^{ix}}{x-iε}dx\right]$$which is an integral along a closed path that encloses the pole(residue) at $x=iε$. So, I can use the residue theorem to find that the integral is equal to: $$Im[\lim_{ε\to0}2\pi i Res(e^{i(iε)})]=2\pi $$ which is clearly off by a factor of 2 . So, which of the above arguments is wrong?","['complex-analysis', 'integration', 'residue-calculus', 'complex-integration']"
2270189,Select three people out of 10 sitting in a circle such that no two of them are consecutive?,"10 persons are sitting in a circle. In how many ways can you select any three of them such that no two of them are consecutive? My attempt: To get the required number, we subtract the unfavourable cases from the total number of cases. The total number of cases will be the number of ways to select three people out of 10 people - 10C3 = 120 Out of these cases, unfavourable cases are those in which (1) two of our selected people sit together while the third is sitting apart. First we select any one of those people in 10C1 ways. To select a person sitting next to this person, we have 2C1 ways. Now, there are only 6 ways to select the third person. Therefore, the total number of ways is $10*2*6=120$ . (2) All three of them are sitting together : There are 10 ways to do that. The total number of unfavourable cases = 10+ 120 = 130 My unfavourable cases are exceeding the total number of cases. 
What am I missing?","['combinations', 'combinatorics']"
2270193,Limit of 1/x as x approaches infinity [duplicate],"This question already has answers here : limit as $x$ approaches infinity of $\frac{1}{x}$ (3 answers) Closed 7 years ago . Why is $\lim_{x\to\infty} \frac{1}{x}$ equal to $0$ , when really the limit appears to be an infinitesimal quantity? I am trying to understand why there is no distinction between 0 and an infinitesimal quantity in the context of limits.","['infinity', 'limits']"
2270208,Exercise on infinite series: pointwise product between convergent serie and unbounded sequence,"I am not able to solve this exercise. I've tried everything. Exercise Let be $a_n > 0$ a sequence and suppose that $\sum a_n$ converges. Prove that exists a sequence $c_n > 0$ such that $\lim c_n = \infty$ and $\sum c_na_n < \infty$ I don't even know if I have to find an ""always-valid"" closed form for $c_n$ (maybe in function of $a_n$?) or prove its existence in another way. Thanks in advance.","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2270228,$\cos\gamma+\sin\gamma$ in a 3-5-7 triangle ($\gamma$ is the greatest angle),"Clearly $\gamma$ has to be the angle oposite to the side of lenght 7. The law of cosines gives me $$7^2 = 5^2+3^2 - 2\cdot 5\cdot3\cos{\gamma}\Longleftrightarrow\cos{\gamma}=-\frac{7^2-5^2-3^2}{2\cdot5\cdot 3}=-\frac{1}{2}.$$ This value of $\cos{\gamma}$ means there can be two values of $\gamma$ satisfying it in $0\leq\gamma \leq 2\pi$. So $\sin{\gamma}$ can be either negative or positive. Using the trigonometric identity $\sin^2{\theta}+\cos^2{\theta}=1$, I obtain $$\sin{\gamma}=\pm\sqrt{1-\cos{\gamma}}=\pm\sqrt{1-\left(-\frac{1}{2}\right)^2}=\pm\frac{\sqrt{3}}{2}.$$ Using the positive value I get the correct answer of $$\cos{\gamma} + \sin{\gamma}=-\frac{1}{2}+\frac{\sqrt{3}}{2}=\frac{\sqrt{3}-1}{2}.$$ Why is it incorrect to use the negative value of $\sin{\gamma}$ ?","['trigonometry', 'geometry']"
2270237,"Does every Borel set with a positive Lebesgue measure contain a closed interval $[a,b]$ with $a<b$?","The question is simple: Does every Borel set with a positive Lebesgue measure contain a closed interval $[a,b]$ with $a<b$? If not than I need a counterexample; if so some kind of proof would be nice. I have no idea how to get closed intervals into a Borel set.","['borel-sets', 'measure-theory']"
2270242,Deriving the weak form for linear elasticity equation,"Consider the BVP from linear elasticity:
\begin{align*}
-\mu \Delta\textbf{u} - (\lambda + \mu) \nabla(\nabla \cdot \textbf{u})) &= \textbf{f}, \text{ in } \Omega \subset\mathbb{R}^2, \\
\textbf{u} &= \textbf{g}_D, \text{ on } \partial \Omega.
\end{align*}
First, we multiply by a test function and integrate both sides,
\begin{align*}
\int_{\Omega}( -\mu \textbf{v} \Delta \textbf{u} - (\lambda + \mu) \textbf{v} \nabla (\nabla\cdot \textbf{u})))dX = \int_{\Omega} \textbf{v}\textbf{f} dX.
\end{align*}
Now I am not sure what the best way to proceed is. I think I should break everything up into components, but I am not confident. I think I will end up using the divergence theorem (twice?). Would anyone be able to help me work out the details? I think the $\Delta \textbf{u}$ term should be simple, but I have no clue what identities to use for $\nabla (\nabla \cdot \textbf{u})$. I appreciate any help.","['multivariable-calculus', 'calculus-of-variations', 'finite-element-method', 'partial-differential-equations']"
2270266,Model of Mathematics,"Although my question isn't congruent with the technical nature of this forum, I felt it necessary. Is anyone aware of a written model with visual examples that maps out the structure of mathematics? Not the MOST specific information but the basics of each concept from Algebra, Geometry and Trigonometry all the way down the line to Calculus (and how they relate)? Such a model may be helpful for visual learners to build a better view of math as a whole.","['trigonometry', 'calculus', 'geometry', 'linear-algebra', 'elementary-number-theory']"
2270268,Integration of 1 to n...,"Anybody can explain how, summation of $1$ to $N$, can be replaced with integration and result leads to $(1/2)N^2$:
$$
\sum_{i=1}^N i \sim \int_1^N x \ \mathrm{d}x \sim \frac{1}{2}N^2 
$$ Note: Image is attached.","['summation', 'integration', 'calculus', 'discrete-mathematics']"
2270285,Finding the dimension of the space of symmetric $r-$tensors,"Let $T^r(V^*)$ denote the space of $r-$tensors on $V$ a vector space of dimension $n$. Basis of $V$ is denoted $\{u_1, \dots u_n $} and basis of $T^r(V^*)$ is $\{\tilde{u}^{i_1} \otimes \dots \otimes \tilde{u}^{i_r}  : 1\leq i_1 \leq n, \dots , 1\leq i_r \leq n\}$ Let $\Sigma^r(V^*)$ be the (sub)space of symmetric $r-$tensors where if $\sigma \in S_r$ is a permutation in the symmetric group and $\alpha \in \Sigma^r(V^*)$, then: 
$$\alpha^\sigma (v_1, \dots , v_r) = \alpha (v_{\sigma(1)}, \dots , v_{\sigma(r)}) $$ What I am trying to do is determine the dimension of  $\Sigma^k(V^*)$. I know that there is a projection mapping $\mathcal{S}$ called the symmetrizer from $T^r(V^*)$ onto  $\Sigma^r(V^*)$ defined by: $$\mathcal{S}(\alpha) = \dfrac{1}{r!}\sum_{\sigma \in S_r} \alpha^\sigma$$. I also (from some searching) already know what the desired answer is: $$\text{dim}\Sigma^k(V^*) = \binom{n + r -1}{r} = \dfrac{(n + r -1)!}{r! (n-1)!}$$ However, I am unable to derive the general expression myself. My current approach, which has worked for $V = \mathbb{R}^4$ and $r =2, 3$ has been to consider the basis of $T^r(V^*)$ and see which elements give the same element of $\Sigma^k(V^*)$ upon symmetrization. For example for the $r=2$ case, I notice that $\mathcal{S}(\tilde{e}^1 \otimes \tilde{e}^2) = \mathcal{S}(\tilde{e}^2 \otimes \tilde{e}^1)$ ; $\mathcal{S}(\tilde{e}^1 \otimes \tilde{e}^3) = \mathcal{S}(\tilde{e}^3 \otimes \tilde{e}^1)$ ; $\mathcal{S}(\tilde{e}^1 \otimes \tilde{e}^4) = \mathcal{S}(\tilde{e}^4 \otimes \tilde{e}^1)$ ; $\mathcal{S}(\tilde{e}^3 \otimes \tilde{e}^2) = \mathcal{S}(\tilde{e}^2 \otimes \tilde{e}^3)$; $\mathcal{S}(\tilde{e}^4 \otimes \tilde{e}^2) = \mathcal{S}(\tilde{e}^2 \otimes \tilde{e}^4)$ ;  and $\mathcal{S}(\tilde{e}^3 \otimes \tilde{e}^4) = \mathcal{S}(\tilde{e}^4 \otimes \tilde{e}^3)$. To these $6$ terms, I add the symmertrizations of $\tilde{e}^i \otimes \tilde{e}^i$ for $i \in \{1,2,3,4\}$ to get dimension 10, as required.","['tensor-products', 'tensors', 'differential-forms', 'combinatorics', 'linear-algebra']"
2270294,"Quantify how small are the integrals $\int_0^N e^{-Nx}\binom{x}{N}dx $, as $N\to\infty$","While I was reading the Wikipedia entry for Gregory coefficients I've thought that should be very nice and fun calculate definite integrals involving binomial coefficients. This is a simple exercise that I've thought after I did some experiments using Wolfram Alpha online calculator with codes like these: integrate   e^(-35 x) Binomial[x,35] dx, from x=0 to x=35 integrate   e^(-200 x) Binomial[x,200] dx, from x=0 to x=200 I believe that the absolute value of integrals is small . Question. (Being $N\geq 1$ integer) I would like to know how to quantify how small are these integrals. Does exist 
  $$\lim_{N\to\infty}\int_0^N e^{-Nx}\binom{x}{N}dx?$$ Alternatively, quantify $$ \left| \int_0^N e^{-Nx}\binom{x}{N}dx \right|$$ as $N$ tends to infinite. Thanks in advance.","['real-analysis', 'binomial-coefficients', 'asymptotics', 'integration', 'definite-integrals']"
2270332,Vector calculus identities and theorems to move derivatives over,"Let $\Omega \subset \mathbb{R}^2$. Then we have
\begin{align*}
\int_{\Omega} \textbf{v} \cdot \nabla (\nabla\cdot \textbf{u})dX &= \int_{\Omega} \begin{bmatrix} v_1 \\ v_2\end{bmatrix} \cdot \nabla (u_{1,x} + u_{2,y}) dX, \\
&= \int_{\Omega} \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} \cdot \begin{bmatrix} u_{1,xx} + u_{2,yx} \\ u_{1,xy} + u_{2,yy}\end{bmatrix} dX, \\
&= \int_{\Omega} v_1 (u_{1,xx} + u_{2,xy}) + v_2 (u_{1,xy} + u_{2,yy}) dX.
\end{align*}
Is there an easy way to ""move the derivatives"" over to the components of $\textbf{v}$ (by using the Divergence theorem or Integration by parts, perhaps)? I want to rewrite my starting integral as the sum of an integral over $\Omega$ and an integral over the boundary $\partial \Omega$. The motivation for this is in deriving the weak form a BVP involving linear elasticity. Are there any vector calculus identities that give me what I want immediately? See here: Deriving the weak form for linear elasticity equation","['multivariable-calculus', 'calculus-of-variations', 'partial-differential-equations']"
2270334,How do I show that the limit of the quotient of $n^{th}$ and $(n+1)^{th}$ norm of a function equals its infinity norm?,"This is an exercise from Rudin's Real and Complex analysis, which I'm solving. The question asks me to show that if $a_n=\int_{X}|f|^n d\mu$, then the limit of $\frac{a_{n+1}}{a_n}$ goes to $||f||_{\infty}$ as $n\rightarrow\infty$. I've easily shown the direction that the limit is $\le$ the infinity norm. I can't quite show the other direction, and would appreciate some help. I've tried splitting the integral in $a_n$ into two pieces, one over the set when $|f|\leq c$ for any $0<c<||f||_\infty$ and another over its complement. This is basically trying to imitate the proof of the fact that the infinity norm is the limit of $p$ norms. However, I can't manipulate this to show that the $lim $ $inf$ of the quotient is $\geq$ the infinity norm. I would really appreciate some help on this. Thank you.","['lp-spaces', 'integration', 'measure-theory']"
2270337,An Element in a C$^{*}$-algebra that is Almost a Projection is Close to a Projection,"Let $A$ be a C$^{*}$-algebra and let $\epsilon>0$ be given. I am trying to solve the following problem (Exercise 2.7. in Rordam's little blue book): Show that there exists a $\delta>0$ with the following property: If $a\in A$ and $\|a-a^{*}\|\leq\delta$ and $\|a-a^{2}\|\leq \delta$, then there is a projection $p$ such that $\|a-p\|\leq \epsilon$. Following the hint, we assume that $\epsilon <1/2$ and set $b=\frac{a+a^{*}}{2}$. Then, it is not hard to see that $\sigma(b)\subset[-\epsilon,\epsilon]\cup[1-\epsilon,1+\epsilon]$ provided that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$. The hint suggests to put $p:= f(b)$ for some continuous function $f$. Since we are assuming $\epsilon<1/2$, $\sigma(b)$ is disconnected, so I was thinking to make $f$ identically $0$ on $[-\epsilon,\epsilon]$ and identically $1$ on $[1-\epsilon,1+\epsilon]$ or vice-versa. Then, by the Spectral Mapping Theorem, $p$ would be a projection. However, I'm not sure how to conclude that $\|a-p\|\leq \epsilon$, or if this is even the correct choice of $p$. Also, presumably the fact that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$, which we make use of follows from our choice of $\delta$ and the definition of $b$. However, in proving this, I came up with a $\delta$ in terms of $a$, but the way the question is asked suggests that the same $\delta$ should hold for all $a$ satisfying $\|a-a^{*}\|,\|a-a^{2}\|\leq\delta$. Is it possible to choose the $\delta$ independent of $a$? Thank you very much!","['c-star-algebras', 'operator-theory', 'functional-analysis', 'spectral-theory', 'operator-algebras']"
2270340,Continuous and preserves measurability $\implies$ preserves null sets.,"Let $X$ be a (Lebesgue-)measurable set of $\mathbb{R}^n$ and $f:X \to \mathbb{R}^n$ continuous function that preserves measurability ($A$ meausurable $\implies f(A)$ measurable). Prove: for all $A \subset X$,$\space$$\lambda(A)=0 \implies \lambda(f(A)) = 0$ . I'm totally stuck. Initially I made some progress but now I'm at a point where it feels like the statement shouldn't be true at all. Additionally i'd like to know if the statement works for general topological measure spaces (or even just metric measure spaces). That is: Let $X$ be a (Lebesgue-)measurable set of $Y$, Topological (or metric) measure space and $f:X \to Y$ continuous function that preserves measurability etc...","['real-analysis', 'metric-spaces', 'measure-theory']"
2270350,Problems in finding an integral basis in a ring of algebraic ntegers,"I have some problems with this paper . Firstly, with theorem 3.4: I don't know if this is the original formulation in the literature, but the statement seems rather trivial to me if one considers $0$ to be an algebraic integer. Moreover there are cases where a non trivial integer doesn't even exist as in the classical example of the ring of integers of  $\Bbb Q(\sqrt{d})$ where $d \in  \Bbb Z$ and $d \neq 1 \mod 4$. Secondly, in the algorithm that is based on this theorem. As an example I consider the polynomial $x^4+5x+5$. The Galois group of this polynomial over $\Bbb Q$ is the cyclic group of order $4$ abd its splitting field can be represented by its companion matrix $M = \left(\begin{smallmatrix}0 & 0 & 0 & -5\\1 & 0 & 0 & -5\\0 & 1 & 0 & 0\\0 & 0 & 1 & 0\end{smallmatrix}\right)$. Since $M$ is an algebraic integer one can take as a basis of integers for the splitting field the set $B = \{M^0,M,M^2,M^3\}$.The discriminant of this basis using $\Delta = \det(\operatorname{Tr}(B_iB_j))$ equals $5^3\dot 11^2$ (as does the discriminant of the polynomial). If I apply the algorithm I find an algebraic integer with coefficients $\frac{1}{11}\left [ 1, 3, 6,1\right ]$ (the minimal polynomial is $x^4+x^3+6x^2-4x+1$). If I replace in B the second element by this element I obtain a basis whose discriminant now is $5^33^2$, so we are nowhere nearer to an integral basis, on the contrary, one bastard goes out and another comes in. Conclusion: We know that the discriminant of an intergral basis divides that of a basis of integers so in out case it divides both discriminants so also their $\gcd, 5^3$. If only there was a way to calculate the $\gcd$ of two bases of integers.","['matrices', 'number-theory', 'algebraic-number-theory']"
2270440,Proof that the convolution of a tempered distribution with some $\varphi\in\scr{S}$ is a $C^\infty$ function,"Let $u\in\mathscr{S}'(\mathbb{R}^n)$ be a tempered distribution, and let $\varphi\in\mathscr{S}(\mathbb{R}^n)$ be Schwartz class, then we consider $\varphi*u\in\scr{S}'$ by setting 
$$(\varphi*u)(\psi)=u(\tilde{\varphi}*\psi)$$
where $\tilde{\varphi}(x)=\varphi(-x)$, for all $\varphi\in\scr{S}$, and now it is not too hard to check that this is itself a tempered distribution. However, I'm struggling with the following proof that $\varphi*u$ is actually $C^\infty$. Let $\psi\in\scr{S}(\mathbb{R}^n)$, so we have that
  \begin{align}
(\varphi*u)(\psi)=u(\tilde{\varphi}*\psi) 
&= u\left(\int_{\mathbb{R}^n}\tilde{\varphi}(\cdot-y)\psi(y)\,\mathrm{d}y \right) \\
&= u\left(\int_{\mathbb{R}^n}\tau^y(\tilde{\varphi})(\cdot)\psi(y)\,\mathrm{d}y \right)
\\
&= \int_{\mathbb{R}^n}u(\tau^y(\tilde{\varphi}))\psi(y)\,\mathrm{d}y
\end{align} and I'm told that the last step is justified by the continuity of $u$ and the fact that the Riemann sums converge in the $\mathscr{S}$ topology, though this isn't proven. I suspect that the proof of that last statement will be very long and tedious, so I'm more curious about the general techniques that are necessary to prove it. Is there any specific sequence of test sets in $\mathbb{R}^n$ over which we can conveniently integrate, such that we have convergence w.r.t. $x$? My first naive attempt was to define $\Lambda_k=[-k,k]^n\cap\frac{1}{k}\mathbb{Z}^n$ but I was unable to prove that this would give us the necessary convergence.","['functional-analysis', 'partial-differential-equations']"
2270475,Group scheme endomorphisms of $G_a$ and $G_m$,"I am working through some exercises on group schemes and had a few questions.  $k$ is a ring (commutative with identity, always), $G_a = \textrm{Spec }k[T], G_m = \textrm{Spec } k[T,T^{-1}] = D(T)$, where $D(T)$ is the principal open set in $G_a$ consisting of all primes not containing $T$. (i): I think I have everything here except the end.  If $\phi: k[T,T^{-1}] \rightarrow k[T,T^{-1}]$ is any $k$-algebra homomorphism, it is completely determined by its effect on $T$.  Since $k[T,T^{-1}]$ is the localization of $k[T]$ at $S  \{1,T,T^2, ... \}$, $\phi$ is well defined if and only if $\phi(T)$ is a unit in $k[T,T^{-1}]$. So the end of (i) should involve a characterization of the units of $k[T,T^{-1}]$ as those elements $f$ ""with no zeroes on any geometric fiber over $\textrm{Spec } k$."" I'm not exactly sure what this means.  My guess would be: for the composition $k \rightarrow k[T] \rightarrow k[T,T^{-1}]$, let $\mathfrak p$ be a prime of $k$.  We say that $f \in k[T,T^{-1}]$ vanishes on the fiber of $\mathfrak p$ if there exists a prime $P$ of $k[T,T^{-1}]$ which contains $f$ and for which $P \cap k= \mathfrak p$. If that is the correct interpretation, then the assertion that $f$ is a unit if and only if it does not vanish on any fiber is obvious, because the union of the fibers is $\textrm{Spec } k[T,T^{-1}]$, and $f$ is a unit if and only if it does not lie in any prime ideal. Is there something significant I'm missing?  I didn't really use any properties of the ring extension $k \rightarrow k[T,T^{-1}]$.","['group-schemes', 'algebraic-geometry', 'commutative-algebra']"
2270517,Easy way to find the eigenvalues of this matrix,"I have a $n \times n$ matrix A that we can write as $A = I + x(B - I) = (1-x)I + xB$, where $I$ is the identity matrix and $B$ is a $n \times n$ matrix with $b_{ij} =1$ for $0 \leq i,j \leq n$. Furthermore $x \in [-1,1]$. The eigenvalues of $A$ are given by $(1-x)$ with multiplicity n-1 and $(1-x) +nx$ with multiplicity 1. I checked this for $n=3$, by writing the determinant out. My question is, is there a more convenient way to see that the eigenvalues are indeed given by $(1-x)$ with multiplicity n-1 and $(1-x) +nx$ with multiplicity 1 for general $n$?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'determinant']"
2270528,"$a+b\phi$ and $a+b-b\phi$ are associates in $\mathbb{Z}+\phi \mathbb{Z}$, with $\phi=(1+\sqrt{5})/2$.","Let $a,b \in \mathbb{Z}$ such that $a^2+ab-b^2=a+b$. Show that $a+b\phi$ and $a+b-b\phi$ are associates in $\mathbb{Z}+\phi \mathbb{Z}$,  with $\phi=(1+\sqrt{5})/2$. I have to find an unit $u$ such that $a+b\phi = u(a+b-b\phi)$. I've no idea how to begin, any hints? (I know that they both have the same norm, but that's just a necessary condition)","['number-theory', 'algebraic-number-theory']"
2270622,Critical Curves of the Energy Functional are Geodesics,"I'd like to prove that E-critical curves of the energy functional: $$ E(\eta) = \frac 12 \int_I g(\eta'(t), \eta'(t))dt$$ satisfy the geodesic equation: $$\nabla_{\eta'} \eta' = 0$$ So the geodesic equation is as follows: $$\nabla_{v} u = \nabla_{v^{i}e_{i}} u^{j}e_{j} = v^{i}\nabla_{e_{i}} u^{j}e_{j} = v^{i}u^{j}\nabla_{e_{i}} e_{j} + v^{i}e_{j}\nabla_{e_{i}} u^{j} = v^{i}u^{j}\Gamma^{k}_{ij}e_{k} + v^{i}\frac{du^{j}}{dx^{i}}e_{j}$$ Which I've also seen as: $$\frac{d^{2}x^{k}}{ds^{2}} + \Gamma^{k}_{ij} \frac{dx^{i}}{ds} \frac{dx^{j}}{ds^{2}}$$ with: $\Gamma^{k}_{ij} = \frac 12 g^{kl}(\frac{dg_{jl}}{dx^{i}} + \frac{dg_{il}}{dx^{j}} - \frac{dg_{ij}}{dx^{l}})$ My intuition tells me that... I. First we need to show the curves, $\eta$ , satisfy the Euler-Lagrange equation and thus are critical curves II. Then we show that those curves satisfy the geodesic equation. Correct? If this is correct then I just need some help with... i.) When we say $\eta$ is a critical curve what does that tell us about $\eta$ that is useful in solving the geodesic equation? I mean we can just say $\eta$ is an arbitrary function that solves the EL equations but since we're doing this in general we need not give an explicit form for $\eta$ . I'm just confused on how to proceed. ii. I actually solving the geodesic equation I could use a little assistance too. Since we are on an arbitrary (wrt dimension specifically) manifold we can't say how many components of $\eta$ there are or how many basis vectors there are so there must be other properties endowed to $\eta$ (perhaps based on being a critical curve of the energy functional) which suggest to us that say it's 2nd deriv is equal to zero for all components or the connection on the manifold (cristoffel symbols) are always zero for this reason or that reason. Any help is greatly appreciated.","['riemannian-geometry', 'manifolds', 'calculus-of-variations', 'differential-geometry', 'geodesic']"
2270628,Help understanding the inclusion map,"I'm sure this is a simple question but I just can't wrap my head around the inclusion map. In an example it says that $i_1: A \rightarrow A \times B$ and $i_2: B \rightarrow A\times B$ are the inclusions of the first and second factors respectively. So I'm assuming an element $a \in A$ gets sent to $(a,*)$ and an element $b \in B$ gets sent to $(*,b)$ but I'm not sure what $*$ will be in these 2 cases. Is it just the basepoints $b_0$ and $a_0$ respectively or to every element of $B$ and $A$ respectively to make up the whole set $A \times B$? Or am I just completely misunderstanding this concept?","['homology-cohomology', 'general-topology', 'homotopy-theory']"
2270642,What is the intuition behind the definition of a Markov Chain being $\pi$-invariant?,"In Markov Chain literature, one definition is that a chain admits $\pi$ as an invariant distribution if: $$
\forall \ \theta^t \in \mathcal{H} \ \ \int_{\mathcal{H}}\pi(\theta^{t-1})K(\theta^t|\theta^{t-1})d\theta^{t-1} = \pi(\theta^t)
$$ where $\theta^1, \theta_2, \ldots$ are sequences of a Markov Chain and $K(\theta^t|\theta^{t-1})$ is a transition or Markov Kernel. In this case, we say that the chain is $\pi$-invariant. I am wondering if anyone has any intuition here as to why this is the case. My understanding from Stochastic Processes is that if $\lambda P = \lambda$, then $\lambda$ is an invariant distribution for $P$ a transition matrix. However, the above definition confuses me. Does anyone have any ideas how to interpret it?","['stochastic-processes', 'probability-theory', 'statistics']"
2270671,How may we show that $\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}?$,Consider $(1)$ $$\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}\tag1$$ My try: $x=-\ln(t)$ then $(1)$ becomes $$\int_{0}^{1}{t^2-3t+1\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag2$$ Split $(2):$ $$\color{blue}{\int_{0}^{1}{\ln(-\ln t)}\mathrm dt}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag3$$ $$\color{blue}{\gamma}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag4$$ Where $\gamma$ is Euler-Mascheroni Constant . How may we prove $(1)?$,"['integration', 'definite-integrals', 'calculus']"
2270675,"Find all primes $p,q$ such that $p^3+p=q^7+q$","The following has been unanswered in art of problem solving and other forums for months. Find all primes $p,q$ such that $p^3+p=q^7+q$ One solution is $(5,2)$ and it has been computer checked that there is no other solution till $10^7$. I am really curious to see a complete solution.","['number-theory', 'prime-numbers']"
2270722,Finding the Fixed points of a Möbius Transformation,Is there a method or algorithm that can be used to find the Fixed points of a Möbius transformation on $\mathbb{C}$?,"['fixed-points', 'complex-analysis', 'mobius-transformation']"
2270729,integrate $\int_D e^{x^2+3y^2}$,"Evaluate $\int_D e^{x^2+3y^2}$, where $D$ is the region bounded in the first quadrant by the lines $y=0, y=x, x^2+3y^2=1$. My method is as follows, and I am not sure if it is correct. Let $u=x, v=\sqrt{3}y$. Then $D$ becomes bounded by $v=0, \frac{\sqrt{3}}{3}v=u, u^2+v^2=1$. $u=r\cos\theta, v=r\sin\theta$, so $\int_D e^{x^2+3y^2} = \int_D e^{r^2}r = \int^{\pi/6}_0e^{r^2}r$ Is this correct? If not, can you tell me where I got this wrong? Thank you.","['multivariable-calculus', 'multiple-integral', 'calculus']"
2270730,What's the limit of $\sqrt{2 + \sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2 + ...}}}}}} $?,"Let's look at the continued radical $ R = \sqrt{2 + \sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2 + ...}}}}}} $ whose signs are defined as $ (+, -, +, -, -, + ,-, -, -,...)$, similar to the sequence $101001000100001...$, where $1 = +$ $0 = - $ This radical seems to converge to a constant approximately equal to $1.567883...$. The question is: Is it possible to find this limit $R$ in closed form? Remark: In the article ""On the periodic continued radicals of 2 and generalization for Vieta’s product"", it is proved that a periodic sequence of signs composed of nested square roots of two converges to $2\sin(q\pi)$ for some rational number $q$. I have tried with non periodic sequences of plus and minus, and they also converge to numbers between $0$ and $2$. if this radical has a closed form, It can be the sine of an irrational multiple of $\pi$, since both are transcendental numbers.","['real-analysis', 'limits', 'calculus', 'closed-form', 'nested-radicals']"
2270739,"Help solving the differential equation $y''+y'+y=0$ with initial conditions $y(0)=4,y'(0)=-3$ using Laplace transform.","UPDATED WTH ANSWER: Please help me solve the following differential equation using Laplace transform:
$$y''+y'+y=0;y(0)=4,y'(0)=-3$$ My answer so far:
$$\mathcal{L}\{y''\} + \mathcal{L}\{y'\} + \mathcal{L}\{y\}=0$$
We know that $\mathcal{L}\{y'\} = s\mathcal{L}\{y\}-y(o)$ and $\mathcal{L}\{y''\}=s\mathcal{L}\{y'\}-y'(0)$. Upon substituting this to the equation,  it becomes
$$s\mathcal{L}\{y'\}-y'(0)+s\mathcal{L}\{y\}-y(0)+\mathcal{L}\{y\}=0$$
$$s(s\mathcal{L}\{y\}-y(0))-y'(0)+s\mathcal{L}\{y\}-y(0)+\mathcal{L}\{y\}=0$$
$$s^2\mathcal{L}\{y\}-sy(0)-y'(0)+s\mathcal{L}\{y\}-y(0)+\mathcal{L}\{y\}=0$$
Upon substituting the values of initial conditions the equation becomes
$$s^2\mathcal{L}\{y\}-4s+3+s\mathcal{L}\{y\}-4+\mathcal{L}\{y\}=0$$
Solving for $\mathcal{L}\{y\}$:
$$\mathcal{L}\{y\}(s^2+s+1)-4s+3-4=0$$
$$\mathcal{L}\{y\}(s^2+s+1)=4s+1$$
$$\mathcal{L}\{y\}=\frac{4s+1}{s^2+s+1}$$
Modifying the numerator and denominator to obtain the form similar to one of the them in the Laplace transform table . 
First applying the method of completing the square to the denominator:
$$\frac{4s+1}{s^2+s+1} = \frac{4s+1}{(s^2+s+\frac{1}{4})+(1-\frac{1}{4})}=\frac{4s+1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}$$
Then modifying the numerator:
$$\frac{4s+1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}=\frac{4s+2-1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}=\frac{4(s+\frac{1}{2})-1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}$$
Divide the fractions:
$$\mathcal{L}\{y\}=\frac{4(s+\frac{1}{2})}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}-\frac{1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}$$ Taking the inverse of Laplace transform of $\mathcal{L}\{y\}$ and let it be $y$. Then the equation becomes
$$y=4\mathcal{L}^{-1}[\frac{(s+\frac{1}{2})}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2)}] - \mathcal{L}^{-1}[\frac{1}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}]$$ The inverse of the first fraction is:
$$4e^{\frac{-1x}{2}}\cos(\frac{\sqrt3x}{2})$$ To match the second fraction to one of the forms from the Laplace Transform table, we need to multiply the numerator and denominator by $\frac{\sqrt3}{2}$. Then it becomes: 
$$\frac{2}{\sqrt3}\mathcal{L}^{-1}[\frac{\frac{\sqrt3}{2}}{(s+\frac{1}{2})^2+(\frac{\sqrt{3}}{2})^2}]$$
Therefore the inverse of the second fraction is:
$$\frac{2}{\sqrt3}e^{\frac{-1x}{2}}\sin(\frac{\sqrt3x}{2})$$
FINAL ANSWER:
$$y=4e^{\frac{-1x}{2}}\cos(\frac{\sqrt3x}{2})+\frac{2}{\sqrt3}e^{\frac{-1x}{2}}\sin(\frac{\sqrt3x}{2})$$
                      //","['real-analysis', 'laplace-transform', 'calculus', 'proof-verification', 'ordinary-differential-equations']"
2270740,Expected time for the flower snark graph,"I know that the expected time for a random walk to visit all vertices of a complete graph is, $$\mathrm E(G)= (n-1)(1+(1/2)+(1/3)+...+(1/n-1).$$ But what would be the expected time for a random walk to visit all vertices in a flower snark graph which is a cubic regular graph?","['stochastic-processes', 'graph-theory', 'expectation', 'probability']"
2270756,Even degree rational polynomials must attain some rational values twice?,"If $P$ is a polynomial, with rational coefficients and of even degree, do there exist arbitrarily large rational $y$ such that $P(x)=y$ has two roots in the rationals? The tricky bit, I suppose, is to show that polynomials without an axis of symmetry, which cannot be described as $Q(ax^2+bx+c)$, fit this criterion. But I have no idea if it is true at all.","['number-theory', 'polynomials']"
2270787,Calculating stability and order of implicit midpoint scheme,"Consider solving $y'(t) = f(t,y(t))$ by the implicit midpoint method:
$$
y_{n+1} = y_n + h \cdot f \left(t_n + \frac{h}{2},\frac{y(t_n) + y(t_{n+1})}{2} \right).
$$
I want to determine the order and regions of stability for this method. Order. My first idea was to do the following: Substitute the exact solution.
\begin{align*}
&y(t_{n+1}) - \left[ y(t_n) + h \cdot f \left(t_n + \frac{h}{2},\frac{y(t_n) + y(t_{n+1})}{2} \right) \right] \\
=& [ y(t_n) + hy '(t_n) + \frac{1}{2} h^2 y''(t_n) + O(h^3) ] \\
- & [ y(t_n) + h \left[ y'(t_n) + \frac{1}{2} h y''(t_n) + O(h^2) \right]
\end{align*}
which is $O(h^3)$. But I don't think I can substitute in for the last part $f(t,y(t)) = y'(t)$ since $\frac{y(t_n) + y(t_{n+1})}{2} \neq y \left( t_n +  \frac{h}{2} \right)$ . . . It's only an approximation. Stability. Apply to the test problem $y'(t) = f(t,y(t)) = \lambda y(t)$. This is done here ( Determine a stability region? ), but again $f(\cdot, y(\cdot))$ is not of the form $f(t, y(t))$, so I don't know why the solution is valid. In particular, why is the test problem $y' =f(t,y(t)) =  \lambda y(t)$ applied to $f(t_{n+1/2} , (y_n + y_{n+1})/2)$ equal to $\lambda (y_n + y_{n+1})/2$? The questions are similar and I probably have some misconception on numerics that is (hopefully) easy to clarify. EDIT: Should I just think about $f \left(t_n + \frac{h}{2},\frac{y(t_n) + y(t_{n+1})}{2} \right)$ as $f(t_{n+1/2} , y_{n+1/2})$? If so I think my question is answered, but I would appreciate someone wiser in the field taking a look.","['numerical-methods', 'ordinary-differential-equations']"
2270827,Show that $|A|$ is an integer multiple of 125,"Let A=$(a_{ij})\in M_{4\times4}(\mathbb Q)$ be a matrix each entry of which is either -2 or 3. Show that $|A|$ is an integer multiple of 125. Would it be best to look at the $2\times 2$, minor determinants, or is there some better way?",['linear-algebra']
2270928,What is $\sup\limits_{n \in \mathbb{N}} \sum\limits_{k=0}^n \cos(k)$?,"For the sake of curiosity, does anyone know what $\sup\limits_{n \in \mathbb{N}} \sum\limits_{k=0}^n \cos(k)$ or $\sup\limits_{n \in \mathbb{N}} \sum\limits_{k=0}^n \sin(k)$ are? It is pretty easy to see that both partial sums are bounded, but I don't even have a clue as to what their respective supremums should be. Definitely something not too large.","['number-theory', 'real-analysis']"
2270977,Recovering a partition of 50,"The sum of 10 numbers, not necessarily distinct, is 50. When placed appropriately in the circles of this diagram, any two numbers will be joined by a line if, and only if, they have a common divisor greater than 1. What are those ten numbers? How many other partitions of 50 (or, in general, of N ) can be uniquely recovered from its corresponding graph of common divisors, that is, the simple graph whose vertex set is the set of parts, two of of which are joined by an edge if, and only if, they have a common factor greater than 1?","['number-theory', 'combinatorics', 'graph-theory', 'integer-partitions']"
2270996,Questions relating differentiability to continuity and integrability,"These questions are from Stephen Abbott's ""Understanding Analysis"", 7.5.2, following a brief explanation of the Fundamental Theorem of Calculus. I have ideas but I feel like I need help still. Decide whether each statement is true or false, providing a short justification for each conclusion. (a). If $h'=g$ on $[a,b]$, then $g$ is continuous on $[a,b]$ If I understand the question correctly, it's asking that if a function is differentiable on $[a,b]$ then the derivative has to be continuous on that interval. I have seen a counter example to this from previous questions, which is $f(x)=\{x^2 sin(1/x),  x \neq 0$,and $0, x=0 \}$ (b) If $g$ is continuous on $[a,b]$, then $g=h'$ for some $h$ on $[a,b]$ Is this asking if a function is continuous does that mean it's differentiable? Then the answer is no because $f(x)=|x|$ is not differentiable at $x=0$. But I'm not sure if I'm even reading the problem correctly. (c) If $H(x) = \int_{a}^{x}h$ is differentiable at $c \in [a,b], $ then $h$ is continuous at $c$. Intuition tells me yes. I can integrate a step function, for example. The result is continuous but not differentiable. Any input or hints would be appreciated.","['derivatives', 'real-analysis', 'integration', 'continuity']"
2271011,How can we tackle this integral $\int_{0}^{1}{2x^2-2x+\ln[(1-x)(1+x)^3]\over x^3\sqrt{1-x^2}}\mathrm dx=-1?$,"Something is wrong with this integral (in terms of splitting  them out) $$\int_{0}^{1}{2x^2-2x+\ln[(1-x)(1+x)^3]\over x^3\sqrt{1-x^2}}\mathrm dx=\color{blue}{-1}\tag1$$ My try: Splitting the integral $$\int_{0}^{1}{2x^2-2x\over x^3\sqrt{1-x^2}}\mathrm dx+\int_{0}^{1}{\ln[(1-x)(1+x)^3]\over x^3\sqrt{1-x^2}}\mathrm dx=I_1+I_2\tag2$$ Note that $I_1$ and $I_2$ diverge, so how can we tackle it as a whole?","['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2271044,Integrate functions from point 'a' to point 'a' proof,"I understand that the integral of any function from and to the same point must equal zero, such;
$$\int_a^a f(x) \,dx= 0$$
It makes sense, area from one point to the same point should be zero. But, how is this shown in a mathematical sense, proving it fully, without just saying 'it makes sense'?","['real-analysis', 'integration', 'calculus']"
2271045,Complex analysis question.,"Which of the following are not true? $(a)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that for all $z\in \mathbb{C}$ , $Re(f(z))=e^x$. $(b)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that $f(0)=1$ and for all $z\in \mathbb{C}$ such that $|z|\geq1$ such that $|f(z)|\leq e^{-|z|}$. could you please give me some hints? I have applied liouville thorem for $(b)$ and got $f(z)$ is constant but not necessarily $f(z)=1$. Am I correct?","['analyticity', 'complex-analysis', 'analytic-functions', 'complex-numbers']"
2271058,"Fractional part of $1+\frac{1}{2}+\dots+\frac{1}{n}$ dense in $(0,1)$","Is the sequence $(x_n)_{n=1}^\infty$, where $x_n$ is the fractional part of $1+\frac{1}{2}+\dots+\frac1n$, dense in $(0,1)$? The fractional part of a number $y$ is defined as $y-\lfloor y\rfloor$. For a sequence like $a,2a,3a,\dots$ where $a$ is an irrational number, it is known that the fractional part sequence is dense. (I think there's even a name for this result, but I can't recall.) The proof uses a pigeonhole-style argument to show that the sequence must fall into any small interval of $(0,1)$ and relies on the linearity of the sequence, which we don't have in our sequence.","['real-analysis', 'sequences-and-series']"
2271066,How to determine the probability that two variables are related?,"I have a set of observations. Each observation has two variables: # | VarA  | VarB
--|-------|-------
1 | True  | False
2 | False | False
3 | True  | True
4 | True  | False
...
(143,804 rows) From this, I've got the following table: | VarB true | VarB false
VarA true |   729     |    1296
VarA false|   1753    |   140026 I want to know the chance that VarA and VarB are related, in the sense that their likelihood of occurring together is significantly higher than suggested by chance. It's rare that an observation contains VarA or VarB (1.98% and 1.41% respectively); if the variables were randomly distributed I'd expect to see (0.0198*0.0141)*143804 = 40 co-occurrences, but instead I see 729. My question is: for this and other observations, what test(s) can I run to check whether the results are independent or related? I've looked at chi-squared, but I can't work out whether it's valid.","['statistics', 'probability']"
2271088,what does it mean to get the cdf of a constant variable,"I saw this theorem If $X_n \ \xrightarrow{d}\ c$, where $c$ is a constant, then $X_n \ \xrightarrow{p}\ c$ In order to get $X_n \ \xrightarrow{d}\ c$, I need to prove $\begin{align}%\label{eq:union-bound}
   \lim_{n \rightarrow \infty} F_{X_n}(x)=F_X(x),
\end{align}$ which means I'm trying to get $F_c(x)$, my question is what does it mean to get the cdf of a constant variable and what would the density function for $c$ be? Is it just 0? If it is what is the intuition behind this?","['statistics', 'probability', 'convergence-divergence']"
2271130,"$\mathbb C^2\setminus\{p_1,p_2\}$ is not a homogeneous space","Why the complex manifold $\mathbb C^2\setminus\{p_1,p_2\}$ is not homogeneous  where $p_1,p_2\in \mathbb C^2$ are distinct? I mean who to show that there is no complex Lie group acts holomorphically and transitively on  $\mathbb C^2\setminus\{p_1,p_2\}$?","['several-complex-variables', 'differential-geometry', 'algebraic-geometry', 'lie-groups']"
2271152,When is a *-derivation inner (in matrix- or C*-algebra)?,"Let $A$ be a C*-algebra (actually, the finite dimensional case of $A=Mat(n\times n,\mathbb{C})$ is my main interest at the moment) and $\delta\colon A\to A$ a *-derivation, i.e. a linear map with $\delta(ab)=\delta(a)b+a\delta(b)$ and $\delta(a^*)=\delta(a)^*$. Clearly, the commutator with a self-adjoint element is an example, that is $\delta(a)= i[h,a] = i(ha-ah)$. My question is: What are the conditions on $\delta$ such that such an $h$ exists (and how can I obtain it)? A bit of background: This is like a non-commutative version of Noether's theorem: If $A$ arises from the algebra of functions on a symplectic space then derivations are vector fields and Hamiltonian ones are those that arise from taking Poisson brackets with the ""Noether charge"". There is a differential condition (making sure the Lie derivative of the symplectic structure vanishes) plus a topological one making sure the closed 1-form obtained from contracting the vector field with the symplectic form is in fact exact. The case of 2x2 matrices, I can figure out myself, but that makes use of Pauli matrices and the fact that traceless 2x2 matrices can be represented by 3-vectors with the vector product (i.e. this might be very special due to low dimensionality).","['matrices', 'c-star-algebras', 'noncommutative-algebra']"
2271176,"Choosing $101$ numbers from $\{1, 2, \dots , 200\}$.","I want to prove that if you choose $101$ numbers from the set $\{1,2,3,4,\dots ,200\}$ , there are always two numbers such that one divides the other with no remainder. The proof should involve the ""pigeonhole principle"". I am not sure how to define the pigeonholes and how to define the pigeons. Any assistance with the proof will be most appreciated. Thank you.","['number-theory', 'pigeonhole-principle']"
2271218,Example of Connected but Not-Path Connected Set,"$ L:= \{(1,0)\}\;\cup\; \bigcup_{n=1}^\infty L_n$ where $L_n:= \{(x,{x\over n})\in \Bbb R^2\mid \; x\in [0,1]\},\; n\in \Bbb N$. I've been provided that the set L as an example of Connected but not Path-connecte set . I would like to prove that the given L is connected but not-path-connected? Below is my proof for connectedness, please check whether it's correct. Proof of Connected-ness>> If we choose two open sets $u,v$ in $\Bbb R^2 $ which are $ u = (1,0)$ and $ v = L \setminus \{(1,0)\} $ then A is connected. Proof of Path-Connected >> How to do this?","['general-topology', 'path-connected', 'connectedness']"
2271326,Implicit Euler method for linear first order ODE's,"We have the linear first order ODE $y'(t) = m(t) y(t) + n(t)$ where $m(t), n(t)$ are given functions. We need to show that after applying the implicit Euler method we receive a linear system of equations for the variable $y_{k+1}$. Let $h>0$ be the step size, $t_0 \in \mathbb{R}$ such that the ODE suffices the initial value condition $y(t_0) = y^0$.
The implicit Euler method in our case is given by $y_0 = y^0$ and $y_{k+1} = y_k + h (a(t_{k+1}) y_{k+1} + b(t_{k+1}))$. This leads to $y_{k+1} = \frac{y_k+h n(t_{k+1})}{1-h m(t_{k+1})}$. My questions: How does this make a linear system of equations or what do we mean with that? Here we have only one equation and in what sense is this equation linear? Usually I would associate a system of linear equations with something like $Ax = b$. We use the implicit Euler method. But is it correct if the result is an explicit equation? That confuses me a bit. Any help is very appreciated.","['numerical-methods', 'eulers-method', 'ordinary-differential-equations']"
2271333,Half-full cone of water,"I have been battling with this for a little while now, but can't really get my head around it. The question goes: how high must you pour water into a cone before it is half-full (by volume)? No numbers specified, so I guess what I am looking for is a generalised formula for finding the height at which the volume is halved. Edit: I was wrong in the last paragraph, what I was looking for was not half the volume, but the height at which the value of the volume was halved. Sorry.",['geometry']
2271343,How to prove that the product of eight consecutive numbers can't be a number raised to exponent 4?,"How to prove this? I tried something like $$P(n,8)=\frac{n!}{(n-8)!} = b^4$$ but I can't proceed to a solution.","['number-theory', 'contest-math', 'integers', 'discrete-mathematics']"
2271357,"Bijection from $[0,1]^3$ to $[0,1]$? [duplicate]","This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Closed 7 years ago . Is there any bijection from $[0,1]^3$ to $[0,1]$? How can I construct it?","['elementary-set-theory', 'functions']"
2271380,How to show that $\gamma=\lim\limits_{n \to \infty}\left(\sum\limits_{k=1}^{n}{\zeta(2k)\over k}\right)-\ln(2n)$,"Proposed: $$\gamma=\lim_{n \to \infty}\left\{\left[\,\sum_{k=1}^{n}{\zeta\left(\,2k\,\right)\over k}\,\right] -\ln\left(\,2n\,\right)\right\}\tag1$$ Where $\gamma$ is Euler-Mascheroni Constant My try Well-known $$\gamma=\lim_{n\to \infty}\left(\sum_{k=1}^{n}{1\over k}\right)-\ln(n)\tag2$$ How do we prove $(1)?$","['zeta-functions', 'sequences-and-series', 'euler-mascheroni-constant', 'limits']"
2271387,Prove these two conditional probabilities are equivalent,"I saw people using such equivalence $$P(X|\mu) P(\mu | D) = P(X,\mu|D)$$
how to prove it is valid? My attempt:
\begin{align}
P(X|\mu) P(\mu | D) &= P(X|\mu) \frac{P(\mu,D)}{P(D)}\\
&= P(X|\mu) \frac{P(D|\mu) P(\mu)}{P(D)}\\
&=\frac{P(X,\mu) P(D|\mu)}{P(D)}
\end{align}
where $P(X,\mu|D) = \frac{P(X,\mu,D)}{P(D)}$. I have stuck here, couldn't figure out why $P(X,\mu,D) = P(X,\mu) P(D|\mu)$. Edited Additional: If instead we have $P(X|\mu,D) P(\mu | D)$, then
\begin{align}
P(X|\mu,D) P(\mu | D) = \frac{P(X,\mu,D)}{P(\mu,D)} \frac{P(\mu,D)}{P(D)}=P(X,\mu|D)
\end{align}
seems like in order to obtain such equivalence it implicitly assumes $P(X|\mu,D)=P(X|\mu)$, correct me if I am wrong.","['bayesian', 'probability']"
2271395,Finding a parametric representation for a boundary of $S$,"the question is:
Let $\Omega$ denote the conical region $\sqrt{x^2 + y^2} \leq z \leq 2$. Find a parametric representation $x(u,v)$ for $S = \partial \Omega$, the boundary of $\Omega$. (You'll need to split it into two parts). I have no clue how to do this. What does it mean by boundary? Does it mean $z=2$ and $z = \sqrt{x^2 + y^2}$?How would I approach finding a parametric for this?","['multivariable-calculus', 'parametrization']"
2271426,"If $f\in L^2([0,1]^2)$, what can we say about $g(x)=f(x,x)$?","Suppose that $L^2([0,1]^2)$ is the space of equivalence classes of square integrable functions $f:[0,1]^2\to\mathbb R$ with the usual norm given by
$$
\|f\|_2=\biggl(\int_0^1\int_0^1|f(x,y)|^2dxdy\biggr)^{1/2}.
$$
With an abuse of notation, the function and the equivalence class is denoted by the same symbol $f$ (instead of using $f$ for the function and $[f]$ for its equivalence class). Suppose that $f\in L^2([0,1]^2)$ and set $g(x)=f(x,x)$ for each $x\in[0,1]$. What can we say about $g$? Can we say that $g\in L^2([0,1])$? Suppose that $f,f_1,f_2,\ldots\in L^2([0,1]^2)$ such that $f_n\to f$  as $n\to\infty$ in $L^2([0,1]^2)$. Set $g(x)=f(x,x)$, $g_1=f_1(x,x),g_2=f_2(x,x),\ldots$ for each $x\in[0,1]$. Can we say that $g_n\to g$ as $n\to\infty$ in $L^2([0,1])$? Any help is much appreciated!","['functional-analysis', 'lp-spaces', 'measure-theory']"
2271440,Show that $x^x$ grows faster than $b^x$ as $x \to \infty$ for $b > 1$,"I have been searching for this for a while, but I can't understand it from my textbook. I am supposed to: ""Show that $x^x$ grows faster than $b^x$ as $x \to \infty$ for $b > 1$"" I can't figure out why the value of $b$ really matters when they have the same limit and exponent.",['limits']
2271453,Characterisation of $\left(-\frac{d^2}{dx^2}\right)^{1/2}$,"Let $T:=-\frac{d^2}{dx^2}$ on $L^2([0,1])$ (let's say with Dirichlet boundary conditions). This is a positive operator and therefore has a positive square-root $\left(-\frac{d^2}{dx^2}\right)^{1/2}$ My question: Is there a nice characterisation of this square-root? I know that in $n$ dimensions the operator $(-\Delta)^{1/2}$ is quite nasty, but I suspected that it might be better in one dimension. It would be particularly nice to have some relation between $i\frac{d}{dx}$ and $\left(-\frac{d^2}{dx^2}\right)^{1/2}$. Does anyone know whether such a thing exists? Maybe a more precise way to pose this question is the following: By the polar decomposition, there is a unitary operator $U$ such that 
$$i\frac{d}{dx} = U\left(-\frac{d^2}{dx^2}\right)^{1/2}.$$
What's $U$?","['functional-analysis', 'spectral-theory', 'ordinary-differential-equations', 'analysis']"
2271454,Isomorphism between two modules which have an inner product and a $\mathbb{Z}_p[G]$ action,"Let $G$ be a finite group (not necessarily abelian), let $\mathbb{Z}_p$ denote the p-adic integers and let $M$ and $N$ be two finitely generated $\mathbb{Z}_p$-modules, which are also $G$-modules. Assume in addition that there is a perfect bilinear pairing
 $$\langle \cdot, \cdot \rangle : M\times N \to \mathbb{Z}_p$$
which for all $m \in M$, $n \in N$ and $g\in G$ satisfies
$$\langle m^g,n^g\rangle=\langle m,n\rangle^g$$
and
$$\langle m^g,n\rangle=\langle m,n^{g^{\ast}} \rangle,$$
where $*:\mathbb{Z}_p[G] \to \mathbb{Z}_p[G]$ is a certain involution. I have two questions: Is it possible to show (maybe under some additional hypotheses, such as $M$ and $N$ are both free and finitely generated) that $M$ and $N$ are isomorphic as $\mathbb{Z}_p[G]$-modules? For example, when $N$ is free and finitely generated, from the above we have that
$$ M \cong \mathrm{Hom}_{\mathbb{Z}_p}(N,\mathbb{Z}_p)$$
as $\mathbb{Z}_p[G]$-modules and 
$$\mathrm{Hom}_{\mathbb{Z}_p}(N,\mathbb{Z}_p) \cong N$$
as $\mathbb{Z}_p$ modules. Furthermore, a Corollary from Maschke's theorem asserts that if $L$ is a module defined over a field $K$ with characteristic not dividing $|G|$, then 
$$\mathrm{Hom}_{K}(L,K) \cong L$$
as $K[G]$-modules. So it seems that the result would be true if we worked over $\mathbb{Q}_p[G]$. If the result in part 1) is true, can one extend it to infinite groups $G$?","['finite-groups', 'representation-theory', 'modules', 'group-theory']"
2271504,Proof of Fundamental Theorem of Finite Abelian Groups,"Statement: Let G be an Abelian group of prime-power order and let a be an element of maximum order in G. Then G can be written in the form $a \times K$. Proof: We denote |G| by p^n and induct on n. If n = 1, then G = $\langle a \rangle \times \langle e \rangle$. Now assume that the statement is true for all Abelian groups of order $p^k$, where $k < n$. 
Among all elements of G, choose $a$ of maximum order $p^m$. [Question: Why are we picking any random m for the order of a? For Abelian groups, isn't the converse of Lagrange always true? So shouldn't the element a have order $p^{k-1}$?] Then $x^{p^m} = e$ for all $x$ in G. [Question: How, if |G| = p^k?]
We assume that $G \neq \langle a \rangle$, as there would be nothing left to prove then. 
Now among all elements of G, choose $b$ of smallest order such does $b \not\in \langle a \rangle$. 
We claim that $\langle b \rangle \cap \langle a \rangle = e$
Since $|b^p| = |b|/p$, we know that $b^p \in \langle a \rangle$ by the manner in which b is chosen. [Question: What does he mean by the manner in which b is chosen? Why does b^p lie in the set generated by a? Is it because the group with the minimum order has to have order p according to Lagrange and this straightaway implies b^p = e?] Say $b^p = a^i$. Notice that $e=b^{p^m}=(b^p)^{p^{m-1}} = (a^i)^{p^{m-1}}$, so $|a^i| \leq p^{m-1}$. 
Thus, $a^i$ is not a generator of . Therefore, $gcd(p^m,i) \neq 1$. This proves that $p$ divides $i$. Let $i = pj$. Then $b^p = a^i = a^{pj}$. Consider the element $c = a^{-j}b$. $c$ is not in . 
$c^p = a^{-jp}b^p$. Thus $c$ is an element of order p such that c is not in . Since b was chosen to have minimal order, we can finally say that b has an order of p. 
It now follows that $\langle a \rangle \cap \langle b \rangle = {e}$, because any non-identity element of the intersection would generate $\langle b \rangle$ and thus contradict that b lies in . Consider the factor group $\overline{G} = G/\langle b \rangle$. Let $\overline{x}=x\langle b \rangle$ in G. 
If $|\overline{a}| < |a| = p^m$, then $\overline{a}^{p^{m-1}} = \overline{e}$. [Question: here we have picked $p^{m-1}$ just as any arbitrary number less than $p^m$, but still a power of $p$, right?] This means that $(a\langle b \rangle)^{p^{m-1}} = a^{p^{m-1}}\langle b \rangle = \langle b \rangle$. This implies that the order of a is $p^{m-1}$, which is absurd. So order of a-bar is equal to order of a which is $p^m$. 
Therefore $\overline{a}$ is an element of maximum order in $\overline{G}$. By induction, we know that $\overline{G} = \langle a \rangle \times \overline{K}$. [Question: ??? What induction? What is the basis of this step? What even is K? How are we even defining K in the steps below?] Let K be the pullback of $\overline{K}$ under the natural homomorphism from G to G-bar. We claim that $\langle a \rangle \cap K = {e}$. For if $x \in \langle \overline{a} \rangle \cap \overline{K} = {e} = \langle b \rangle$ and $x \in \langle a \rangle \cap \langle b \rangle = {e}$. It now follows from an order argument (???) that $G = <a>K$, and therefore $G = \langle a \rangle \times K$. I am currently teaching myself abstract algebra and real analysis and this proof has be confused for a while now. I apologize for the length of the post, but I could not think of any other way to convey my doubts in any concise manner.","['abelian-groups', 'abstract-algebra']"
2271510,The number of reduced expressions for the longest element of $B_n$?,"Let $W=W_{\Phi}$ be a reflection group, with root system $\Phi$, and $\Delta=\{\alpha_1, ...,\alpha_n\}\subseteq \Phi$ a simple system. So $W$ is generated by the $s_{\alpha_i}=s_i$ for $i=1,2,...n. $ We know the fact that the length of the longest element $w_0$ of $W$ is $\mid\Phi^+\mid$. For example, in the type $A_3$, $w_0=s_2s_1s_3s_2s_1s_3$ is a longest element and its length is $6=\mid\Phi^+\mid$. You can see also What are the length of the longest element in a Coexter group for every type? We know the fact that the number of reduced expressions for $w_0$ in type $A_n$ is given by 
\begin{align}
\frac{(\frac{1}{2}n(n+1))!}{r}
\end{align}
where $r$ is the product of the lengths of the hooks in the Young diagram corresponding to the partition $(n,n-1,n-2,...,2,1)$ of $\frac{1}{2}n(n+1)$. My question is what is the number of reduced expressions for the longest element of $B_n$? Maybe this question is still an open question?","['finite-groups', 'coxeter-groups', 'group-theory', 'lie-groups']"
2271536,condition by which a vector function $f : \mathbb{R}^2 \rightarrow \mathbb{R}^2$ produces area zero,"I have what seems (to me, although I'm a nonmathematician) an interesting condition to try to describe; it's sort of the nonlinear analogue of singular two-dimensional matrices. Suppose I have a function $f : \mathbb{R}^2 \rightarrow \mathbb{R}^2$ that is continuous but maps coordinates $\mathbf{r}_{xy} = (x,y) \rightarrow \mathbf{r}_{uv} = (u,v)$ subject to some condition I am trying to understand. This condition ensures that for any closed curve $C_{xy}$ defined parametrically as the continuous function $\mathbf{r}_{xy}(t)$ for $t \in [0,1]$ where $\mathbf{r}_{xy}(0) = \mathbf{r}_{xy}(1)$, if the area enclosed by the curve $$ \iint \limits_{C_{xy}} dx \,dy \neq 0$$ then the area enclosed by the corresponding curve $C_{uv}$ defined by $\mathbf{r}_{uv}(t) = f(\mathbf{r}_{xy}(t))$ produces an area 0: $$ \iint \limits_{C_{uv}} du \,dv = 0$$ Some trivial examples of this sort of function are: $$ (x,y) \rightarrow (u=apx+aqy+b, v=cpx+cqy+d) $$ in other words, squashing down $(x,y)$ to a single dimension $w=px+qy$ and then mapping $w$ into the $uv$-plane, with simple trivial cases $$ (x,y) \rightarrow (u=x, v=0) $$ $$ (x,y) \rightarrow (u=0, v=y) $$ $$ (x,y) \rightarrow (u=0, v=0) $$ I am guessing (but not 100% sure) that $f(\mathbf{r}) = g(h(\mathbf{r}))$ where $g : \mathbb{R} \rightarrow \mathbb{R}^2$ and  $h : \mathbb{R}^2 \rightarrow \mathbb{R}$ are both continuous, also satisfies this condition. I am also not sure what kind of $f(\mathbf{r})$ satisfies this condition but is not expressible as $f(\mathbf{r}) = g(h(\mathbf{r}))$. Is there a more concise way to characterize this condition on $f$ ?","['functions', 'vector-spaces']"
2271585,Use $\widehat{f*f}(x)=2\sqrt{2/\pi}\left( \sin x/x \right)^2$ to show that $\int_{-\infty}^{+\infty}\left( \frac{\sin x}{x} \right)^2 dx=\pi. $,"I have already showen that the Fourier transform of $ f=\chi_{[-1,1]} $ is 
$$ \widehat{f}(\omega)=\sqrt{\frac{2}{\pi}}\frac{\sin \omega}{\omega}  $$
Then I showed that 
$$ \widehat{f*f}(x)=2\sqrt{\frac{2}{\pi}}\left( \frac{\sin x}{x} \right)^2  .$$
I would now like to use the above to show that 
$$\int_{-\infty}^{+\infty}\left( \frac{\sin x}{x} \right)^2 dx=\pi. $$
I was thinking maybe I can use the inverse Fourier transform 
$$ f(\omega)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}\widehat{f}(x)e^{i\omega x}dx\\ $$
(do I have the definition right?) or maybe the relation $ \widehat{\widehat{f}}(x)=f(-x) $, but I don't see how neither of these does the trick. Can anyone help me out?","['functional-analysis', 'integration', 'trigonometry', 'fourier-transform']"
2271632,Why is the sample space called a 'space'? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 7 months ago . Improve this question Originally, the word 'space' reffered to the ""boundless three-dimensional extent"", as Wikipedia tells us. In modern mathematics, 'space' is used in a more general sense , referring to a set with some added structure, so that besides $\mathbb R^3$, we can also consider $\mathbb R^n$ for every other natural number $n$ to be a space, can consider the set of functions $A\to B$ between any two sets together with additional structure (such as addition $(f+g)(x)=f(x) + g(x)$) as a space, and so on. In some sense, spaces are the same as structures, but in my understanding the difference between structures and spaces is that we consider the latter to be a special case of the former that have a 'geometric' nature (of course, 'geometric' here doesn't have a formal definition, and is just used informally). Now, vector spaces, metric spaces, projective spaces, measurable spaces, ... clearly are geometric in its nature, and thus deserve to be called 'spaces'. But why the hell do we, in probablity theory, call the set of all outcomes the 'sample space '? It's just defined to be the set of all possible outcomes/results of (random) experiment—without additional structure! I can sort of understand why we say 'probability space ', I think it's because it's a special case of a measure space. But the sample space alone ... why is it called a 'space'? It hasn't additional structure and isn't geometric in nature.","['terminology', 'probability-theory', 'geometric-probability', 'soft-question']"
2271634,About topological group and a connected component,"If $G$ is a toplogical group and $H$ is a connected component of $G$ containing the identity $e$ of $G$, then how can we show that $H$ is a normal subgroup of $G$? I get that $xHx^{-1}$ is a connected component of $G$. Now I need to know how to show that $H \subseteq xHx^{-1}$.  Because then $H= xHx^{-1}$ due to the fact that $H$ is maximal connected. So $H$ is normal...
So how can I show that $H \subseteq xHx^{-1}$?","['abstract-algebra', 'general-topology', 'topological-groups', 'lie-groups']"
2271649,Modification of Dini's theorem,"Classical Dini's theorem states that if $(f_n)$ is a monotone sequence of continuous functions on a compact space converges pointwise to a continuous function $f$, then the convergence is uniform. It is shown that all conditions are needed for the conclusion to hold. If one examines carefully, the proof can be modified to obtain the following statement: If $(f_n)$ is a monotone sequence of upper semicontinuous functions converges on a compact space converges pointwise to a lower semicontinuous function $f$, then the convergence us uniform. Question: Suppose for each natural number, $f_n = g_n - h_n$ where $g_n,h_n$ are upper semicontinuous functions. If $(f_n)$ is a decreasing sequence of functions defined above on a compact space converges pointwise to $0$, then is it true that the convergence us uniform?",['real-analysis']
2271651,How to find range of a rational function?,How to find range of $$f(x) = x^2 + \frac{1}{x^2+1} \quad ?$$ Its domain is all real numbers. If I use calculus it is very lengthy but if I put RHS of equation equal to y I get a quadratic equation in $x^2$ but I cannot find range of y by imposing condition on discriminant as even if let us say $x$ was complex or imaginary but there is the  possibility that when it is raised to power 2 or 4 it becomes purely real?,['functions']
2271674,Matrix equation including diagonal and orthogonal matrices,"I want to prove the following estimate (I'm not really sure if it really holds, but I'm interested in proving it): $$(1,...,1)UDU^T\left(\begin{array}{c} 1 \\ \vdots\\1 \end{array}\right) < n$$ where $U\in\mathbb{R}^{n\times n}$ is an orthogonal matrix and $D\in\mathbb{R}^{n\times n}$ is a diagonal matrix whose diagonal elements $d_i$ are all in the interval $\lbrack 0, 1) $. 
I began the following way:
Let $w:=U^T\left(\begin{array}{c} 1 \\ \vdots\\1 \end{array}\right)$ then we have
$$(1,...,1)UDU^T\left(\begin{array}{c} 1 \\ \vdots\\1 \end{array}\right) = \langle w, Dw\rangle = \sum_{i=1}^n d_iw_i^2.$$
Further we have $w_i = \sum_{k=1}^nu_{k,i}$ where $U = (u_{i,j})_{i,j=1,...,n}$. I now want to exploit that the the columns of $U$ are orthonormal. Unfortunately I didn't find the right way to do so.","['matrices', 'estimation', 'orthogonality', 'inner-products', 'orthogonal-matrices']"
2271683,Series expansion of $\sum_{k=1}^{n} \frac{\ln(k+1)}{k}$ to order $o(1)$,"I am interested in the asymptotic development of $a_n\stackrel{\rm def}{=} \sum_{k=1}^{n} \frac{\ln(k+1)}{k}$, when $n\to \infty$. Via a standard comparison series/integral, I got that
$$
\int_1^{n+1} dx\,\frac{\ln(x+1)}{x} \leq a_n \leq \int_0^{n} dx\,\frac{\ln(x+1)}{x}
$$
which, conditioning on my not messing up the computations, leads to
$$a_n = \frac{1}{2}{\ln^2 n} + O(1)
$$
where the $O(1)$ term is, ignoring lower-order terms, between $\frac{\pi^2}{6}$ and $\frac{\pi^2}{12}$. For my application, however, it is crucial that I get $a_n$ to order $o(1)$ (and the higher the better: $o(\frac{1}{n})$, for instance, would be great) . I tried a bit this morning, but couldn't figure out out to do so: by starting the comparison at a higher indice, I can reduce the range of uncertainty about the constant term, but didn't get to completely get it.","['taylor-expansion', 'asymptotics', 'sequences-and-series']"
2271725,Multivariate Calculus: Differentiating the following problem,"Suppose $\mu$ is $m \times 1 $, $A$ is $m \times m$, $B$ is always $m \times n$ and $\Sigma$ is $n \times n$. Note that $\Sigma$ is symmetric. I need to differentiate the follow form: $$\ell = -\log( \det[B \Sigma B^T]) - \operatorname{tr}([B \Sigma B^T]^{-1} [\mu\mu^T - \mu\mu^T A^T - A(\mu\mu^T)^T + A \mu\mu^T A^T])$$ Now I would like to know how can I obtain the following: $$\frac{\partial \ell }{\partial A} = \text{?}$$
$$\frac{\partial \ell }{\partial \Sigma} = \text{?}$$
$$\frac{\partial \ell }{\partial B} = \text{?}$$ And What would the optimal $A$ , $\Sigma$ and $B$ be after differentiating and rearranging the terms to one side ? Update: Through its differential, I have taken an attempt and obtained the following: 
Let $Z = [\mu\mu^T - \mu\mu^T A^T - A(\mu\mu^T)^T + A \mu\mu^T A^T]$ $$d \ell = -tr\Big(\big[2 B^T \Sigma(B\Sigma B^T)^{-1})\big]dB + \big[ B^T(B\Sigma B^T)^{-1}B\big] d\Sigma + \big[ (B\Sigma B^T)^{-1}Z(B\Sigma B^T)^{-1} B\Sigma +\big((B\Sigma B^T)^{-1}Z(B \Sigma B^T)^{-1}B \Sigma\big)^T \big]dB + \big[ B^T(B\Sigma B^T)^{-1}Z^T (B\Sigma B^T)^{-1}B\big]d \Sigma\Big) - tr\Big(\Big(\big[B\Sigma B^T\big]^{-1}\big[ 2\mu^T\mu - 2\mu\mu^TA^T\big]\Big)dA\Big)$$ Please kindly verify if it is correct. The problem that remains is how to rearrange the terms such that the optimal $A, B, \Sigma$ will be on one side.",['multivariable-calculus']
2271749,Covariant derivatives for bundle maps,"Suppose that $M$ is a smooth manifold and $\nabla$ is an affine connection on it (in my case it is the Levi-Civita connection of a Riemannian metric, but probably this is not relevant). If $E$ and $F$ are linear bundles over $M$, I call a bundle map a smooth map $E \to F$ that covers the identity map on $M$. Also, $M$ can be seen as a trivial bundle over itself. A vector field $X$ can be interpreted as a bundle map $M \to T^1M$. Then $\nabla X$ is a bundle map $M \to T^1_1M$, and the same construction can be repeated for tensors of any order. What I would like to do is to use $\nabla$ to differentiate bundle maps between tensor spaces, i.e., maps of the type $G \colon T^k_hM \to T^p_qM$. Is there some reference that lays the theoretical foundations for this operation and the basic properties? In particular, I would like to have a chain-rule-like formula: if $X \colon M \to T^1M$ and $G \colon T^1M \to T^1M$, what is $\nabla(G \circ X)$ in terms of $\nabla X$ and the derivatives of $G$?","['reference-request', 'differential-geometry']"
2271822,"For an action of a compact Lie group in a manifold, does the complement of the non-expansive maps set have positive Haar measure?","Let $(M,g)$ be a riemannian manifold, it is smoothly acted by a compact Lie group $G$. Consider $\mu$ the Haar measure on $G$. Set $A=\{h\in G\, | \, |h_{*}v|_{g}\geq |v|_{g}, \, \forall\, v\in TM\}$. Is true that $\mu(A)>0$? I know that the set $\{h\in G\, | \, |h_{*}v|_{g}>|v|_{g}, \, \forall\, v\in TM\}$ is open, because the expansive maps set forms a open set in $Diff^{\infty}(M)$. But, it can be empty, for example while $G$ is a finite group. Otherwise for finite groups $\mu(A)>0$. I have tried to proof it looking to what happens in a neighborhood of the identity, concretely I tried to proof that interior of $A$ is not empty.","['ergodic-theory', 'measure-theory', 'haar-measure', 'differential-geometry', 'lie-groups']"
2271845,Linear transformation of a random vector with pseudo-inverse,"I have already asked this question in cross-validated, but nobody answered, so I thought I may have more luck here. If $$ \mathbf{X} = (X_1,\ldots,X_n)^t$$ is a random variable drawn according to a probability density function (pdf) $$ f_{X_1,\ldots,X_n}(x_1,\ldots,x_n) $$ then $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_n)^t$$ with $A$ a square non-singular matrix, has a pdf given by:
$$ f_{Y_1,\ldots,Y_n}(y_1,\ldots,y_n)=\frac{f_\mathbf{X}(A^{-1} \mathbf{y})}{|A|} $$
I have heard that this can be generalised to the case of a non-square matrix with the Moore–Penrose pseudo-inverse concept, where now $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_m)^t \qquad m<n $$
and 
$$ f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)=\frac{f_\mathbf{X}(A^{+} \mathbf{y})}{|A|_{+}} $$ 
with $A^+$ the pseudo-inverse of $A$ and $|A|_{+}$ the pseudo-determinant. If this is right, how can it be proved? and more important, what is the intuition behind this generalisation?
I've only found this related question, but I can't understand how the OP finds the general expression for $f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)$.","['statistics', 'linear-transformations', 'probability-distributions']"
2271887,How to solve the matrix minimization for BFGS update in Quasi-Newton optimization,"I am interested in deriving the unique solution to the following Quasi-Newton minimization problem
$$
 \min_{H}||  H-H_k||\\   
H=H^\top,\quad Hy_k =s_k
$$ The norm is the weighted Frobenius norm 
$$
||A||_W \equiv ||W^{1/2}A W^{1/2}||_F
$$where the weight matrix $W$ is any positive definite matrix that satisfies $Ws_k=y_k$, and $||\cdot||_F$ is defined by $||C||^2_F= \sum_{i,j}^n c^2_{ij}$. The quantity $H$ is the inverse hessian which is symmetric, positive definite and satisfies the secant equation above, $Hy_k=s_k$.  We can assume that $W=G^{-1}_k $ where $G_k$ the average hessian is given by
$$
G_k= \int_0^1 \nabla^2 f(x_k+\tau \alpha_k p_k)d\tau
$$
The unique solution is given by
$$
H_{k+1} = (1-\rho_k s_k y^\top_k)H_k (1-\rho_k y_k s^\top_k)+ \rho_k s_k s^\top_k
$$ where $\rho_k = (y^\top_k s_k)^{-1}$.  Note, this is an iterative scheme where $k$ represents the current iteration and $H_{k+1}$ is an approximation to the inverse hessian. The notation I am using is directly from the book Nocedal & Wright - Numerical Optimization.  I am not able to find a full derivation of this anywhere, everything written above is all that Nocedal/Wright has in regards to this topic. For a reference, this is in chapter 6 - Quasi Newton Methods, of their newest/2nd edition. All links I have tried to google and other books also have no full derivation.  I am not able to find anything more thorough than Nocedal & Wright however they still don't have a derivation.  Thanks","['real-analysis', 'optimization', 'calculus', 'algorithms', 'numerical-methods']"
2271903,Use Fourier series of odd function to evaluate $1-\frac15+\frac17-\frac1{11}+\cdots$,"Show that the Fourier series expansion for $f(x)$ is
  $$\frac2{\sqrt3}\left(\cos x-\frac{\cos5x}5+\frac{\cos7x}7-\frac{\cos11x}{11}+\cdots\right)$$
  where
  $$f(x)=\begin{cases}\dfrac\pi3&\text{for }x\in\left[0,\dfrac\pi3\right)\\[1ex]0&\text{for }x\in\left[\dfrac\pi3,\dfrac{2\pi}3\right)\\[1ex]-\dfrac\pi3&\text{for }x\in\left[\dfrac{2\pi}3,\pi\right)\end{cases}$$
  and $f(x)=f(x+\pi)$ for all $x\in\mathbb R$. Attempt : $$f(x)=\frac{a_0}2+\sum_{n\ge1}(a_n\cos2nx+b_n\sin2nx)$$ where $$a_0=\frac2\pi\int_0^\pi f(x)\,\mathrm dx$$
$$a_n=\frac2\pi\int_0^\pi f(x)\cos2nx\,\mathrm dx$$
$$b_n=\frac2\pi\int_0^\pi f(x)\sin2nx\,\mathrm dx$$ I know that $f(x)$ is odd, so $a_0=0$ and $a_n=0$ for all $n\in\mathbb N$. For the sine series, I end up with, among several equivalent expressions, $$b_n=\frac1{3n}\left(2-\cos\frac{2n\pi}3-\cos\frac{4n\pi}3\right)$$
$$b_n=\frac2{3n}\left(\sin^2\frac{2n\pi}3+\sin^2\frac{4n\pi}3\right)$$ which gives me (using $g$ to distinguish my result from the expected $f$) $$g(x)=\sum_{n\ge1}\frac{c_n\sin2nx}n=\sin2x+\frac{\sin4x}2+\frac{\sin8x}4+\frac{\sin10x}5+\frac{\sin14x}7+\cdots$$ where $c_n=1$ if $n$ is not a multiple of $3$, and $0$ otherwise. Plotting the first few partial sums suggests that this answer is just as valid as the suggested one. Is there some manipulation I can do to my result in order to get the solution to match? Or is there another way of finding the series expansion to arrive at the cosine series directly? There is also a second part to the problem, which is to Show that
  $$\frac\pi{2\sqrt3}=1-\frac15+\frac17-\frac1{11}+\cdots$$ which I can easily get from evaluating $f(x)$ and the given expansion at $x=0$: $$\frac\pi3=\frac2{\sqrt3}\left(1-\frac15+\frac17-\frac1{11}+\frac1{13}-\frac1{17}+\frac1{19}-\frac1{23}+\cdots\right)$$ but I don't immediately see a way to use $g(x)$. At first glance, choosing $x=\dfrac\pi4$ seems to be the right thing to do, but this yields $$\frac\pi3=1+\frac15-\frac17-\frac1{11}+\frac1{13}+\frac1{17}-\frac1{19}-\frac1{23}+\cdots$$","['fourier-series', 'sequences-and-series']"
2271945,Can skew lines be perpendicular?,"In a math textbook for primary school, there's a picture like the one below. They explain which of the line segments are perpendicular and which are parallel to AD. There's also a note stating that A1B1, D1C1, BB1 and CC1 are neither parallel nor perpendicular to AD. I was wondering about that statement, because I learned that those four are perpendicular to AD. So I wrote to the book publisher asking about that. They replied that actually there are two conventions for this situation and they choose ""not perpendicular"" which, according to them, is more popular. Is there really no consensus on that? Edit: I found another question here, related to a mathematical consensus: Is $0$ a natural number? and I'd accept an answer referring to some resources and clarifying whether the consensus exists or not.","['definition', 'online-resources', 'geometry']"
2271959,Mazur's Weak Basis Theorem,"It is the Exercise 1.1 in Topics in Banach Space Theory by Albiac and Kalton to prove Mazur's Weak Basis Theorem, which states that every weak basis in a Banach space $X$ is a Schauder basis, where weak basis is defined as follows: A sequence $(e_n)_n$ in a Banach space $X$ is called a weak basis for $X$ if for every $x\in X$ there is an unique sequence of scalars $(a_n)$ such that $x=\sum_{k=1}^\infty a_ke_k$ in the weak topology. I tried to show, to no avail, that $\lVert\sum^n a_kx_k\rVert\rightarrow\lVert x\rVert$ so that it would immediately follow that $\sum^n a_ne_n\overset{\lVert\cdot\rVert}{\rightarrow}x$. I'd like suggestions on how to proceed.","['functional-analysis', 'schauder-basis', 'linear-algebra']"
2271970,Twists and half-twists on ribbons in $\mathbb{R}^4$,"I've heard that in a manifold of dimension four or higher, if one takes a two-dimensional ribbon and gives it two half-twists (ie. two $180$-degree twists), it is the same as if the ribbon has no twists. Thus in $\mathbb{R}^3$, a ribbon can have $z$ half-twists where $z \in \mathbb{Z}$ because it can have any number of half-twists in either direction, whereas in $\mathbb{R}^4$, it can only have $z$ half-twists where $z \in \mathbb{Z} / 2\mathbb{Z}$. I don't know the theory behind this, and it doesn't seem obvious. Can anyone offer a proof or some intuition for this fact?","['algebraic-topology', 'general-topology']"
2272073,Find $\int_0^\infty (A x +I)^{-1} B (A x +I)^{-1} dx$ where $A$ and $B$ are positive definite matrices,"Let $A$ and $B$ be two positive definite matrices. I would like to find the following integral $$\int_0^\infty  (A x +I)^{-1} B (A x +I)^{-1} dx$$ where $x$ is a scalar and integration is done cell-wise. Solution when $A$ and $B$ commute \begin{align}
\int_0^\infty  (A x +I)^{-1} B (A x +I)^{-1} dx &=\int_0^\infty  (A  B^{-1}x +B^{-1})^{-1}  (A x +I)^{-1} dx \\
&=\int_0^\infty  ( B^{-1} A x +B^{-1})^{-1}  (A x +I)^{-1} dx\\
&=B \int_0^\infty  (  A x +I )^{-1}  (A x +I)^{-1} dx\\
&=B A^{-1}
\end{align} The last expression can be inferred from this question . Now, how to do this for the general case?","['matrices', 'improper-integrals', 'integration', 'matrix-calculus']"
2272145,Prove that $(n - 1)^2 \mid n^k -1$ if and only if $(n - 1) \mid k$ [duplicate],"This question already has answers here : For what powers $k$ is the polynomial $n^k-1$ divisible by $(n-1)^2$? [closed] (3 answers) Closed 6 years ago . I need help! I need to prove that for any $2 \le n,k$ positive integers
$(n - 1)^2 \mid n^k -1$ if and only if $(n - 1) \mid k$ Thanks!",['number-theory']
2272154,Direct computation of continuous spectrum for differential operator,"I have trouble to directly obtain the continuous spectrums of differential operators such as $\pm\frac{d}{dx}, \pm i\frac{d}{dx}, \pm \frac{d^2}{dx^2} \pm \frac{d}{dx}$, etc. I find it easier to calculate directly what the point spectrum is via finding eigenvalues, and the residual spectrum via finding the point spectrum of the adjoint. But there seems to be no equivalent method to do that for the continuous spectrum. One way that I rely on to find the continuous spectrum is to first obtain the inverse of the operator, then shows that it is bounded. Secondly, sometimes the domain is nice enough that I can obtain the result without actually trying. Is there some method to directly obtain the continuous spectrum without relying on fancy theorems or special cases? For a specific example, take any of the above operator and use the domain $C^1_0[0,1]$, or $C^1[0,1]$.","['functional-analysis', 'spectral-theory', 'operator-theory', 'analysis']"
2272182,Proving the trig identity $\sin(20^\circ)\cos(65^\circ)-\cos( 20^\circ)\sin(65^\circ)$,"Using the trigonometric identities I have to prove that: $$
\sin(20^\circ)\cos(65^\circ)-\cos(20^\circ)\sin(65^\circ)=-\frac{1}{\sqrt{2}}
$$ I solved $$
\sin(20^\circ)\cos(65^\circ) = \frac{\sin(-45^\circ)+\sin(85^\circ)}{2}$$ and $$
-\cos(20^\circ)\sin(65^\circ)=\frac{\sin(45^\circ)+\sin(85^\circ)}{2}
$$ How do I continue from here to prove that it is equal $-\dfrac{1}{\sqrt{2}}$",['trigonometry']
2272186,Analytical approximation of the ODE: $\alpha y y'' = - y+1$,"I would like to achieve an approximate solution to the following 2nd-order non-linear ODE of y(t): $\alpha y y'' = - y +1$ Where $\alpha>0$ is a constant, and the initial conditions are as follows: $y(0) = \beta>0$ $y'(0) = 0$ Solving it numerically with MATLAB yields a solution which reminds a cosinusoidal wave with an increasing amplitude. That is except for the case $\beta=1$, then the solution is simply $y(t) = 1$. From the numerical solution, it seems that the approximation will have the form: $y = 1 + A cos(\omega t)$ Where the amplitude is $A = A(\beta,t)$ and $\omega = \omega(\beta)$. Any help would be appreciated!","['ordinary-differential-equations', 'initial-value-problems']"
2272225,Solving $\int_0^1 \sqrt{x^2+1}$ with Euler substitution,"So I was trying to solve this integral $$\int_0^1 \sqrt{x^2+1} \, dx$$ in two different ways with Euler substitution. So: $(x^2+1)=x+t$, so that $x=(1-t^2)/(2t)$, $(x^2+1)=x*t+1$, $x=2t/(1-t^2)$. But I am not sure how to proceed, and how do the integral and the limits change... Any tips? Thanks :)","['definite-integrals', 'analysis']"
2272238,Example of Basic Theorem of field extensions,"I'm studying the proof of Basic Theorem of field extensions from Pinter's A Book Of Abstract Algebra. Theorem: Let $F$ be a field and $a(x)$ a nonconstant polynomial in $F[x]$.
There exists an extension field $E$ of $F$ and an element $c$ in $E$ such that $c$ is a root of $a(x)$. Proof: To begin with, $a(x)$ can be factored into irreducible polynomials in $F[x]$. If $p(x)$ is any non-constant irreducible factor of $a(x)$, it is clearly sufficient to find an extension of $F$ containing a root of $p(x)$, since such a root will also be a root of $a(x)$. If $p(x)$ is irreducible in $F[x]$, then $〈p(x)〉$ is a maximal ideal of $F[x]$. Furthermore, if $〈p(x)〉$ is a maximal ideal of $F[x]$, then the quotient ring $F[x]/〈p(x)〉$ is a field. It remains only to prove that $F[x]/〈p(x)〉$ is the desired field extension of $F$. When we write $J = 〈p(x)〉$, let us remember that every element of $F[x]/J$ is a coset of $J$. We will prove that $F[x]/J$ is an extension of $F$ by identifying each element a in $F$ with its coset $J + a$. To be precise, define $h: F → F[x]/J$ by $h(a) = J + a$. Note that $h$ is the function which matches every $a$ in $F$ with its coset $J + a$ in $F[x]/J$. We will now show that $h$ is an isomorphism. I'm trying to have a better understanding of the proof and the concept. Wonder if someone could give me a SIMPLE specific example of the following so I have better grasp of the proof: 1) $a(x)$ 2) $p(x)$ 3) $c$ 4) $F[x]/〈p(x)〉$ 5) $〈p(x)〉 + a$ Thank you!","['irreducible-polynomials', 'abstract-algebra', 'extension-field', 'polynomials']"
2272242,How is the Gastner-Newman equation implemented to create value-by-area cartograms?,"There is a paper called ""Density-equalizing map projections: Diffusion-based algorithm and applications"" by Michael T. Gastner and M. E. J. Newman, which explains their algorithm for generating value-by-area cartograms. While it explains the theoretical side of the mathematics involved with their algorithm, it doesn't explain how they actually implemented it. I tried to piece it together by looking at the source code from cart , but I don't have the programming knowledge (it's written in c, which I don't know) required to understand it. If anyone has at least a decent understanding of it and can explain the steps needed to create a cartogram using their algorithm, that would be greatly appreciated. Otherwise, if you have other helpful resources on the topic, those would be good too.","['physics', 'linear-transformations', 'ordinary-differential-equations', 'cartography', 'linear-algebra']"
