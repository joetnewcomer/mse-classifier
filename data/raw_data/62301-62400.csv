question_id,title,body,tags
707217,Double Angle Formula?,I am just trying to figure out what formula I would use to solve this equation. The problem is solve $\cos(3\theta)=1/2$; for all $0\leq \theta\leq 360^\circ$. I want to say I would use the double angle formula but I am not positive.,['trigonometry']
707256,How to show $\sum_{i=1}^{n} \binom{i}{2}=\binom{n+1}{3}$?,"Show that $\,\displaystyle\sum_{i=1}^{n} \binom{i}{2}=\binom{n+1}{3}$. I'm thinking right now (though not getting anywhere with it) that I want to expand out the summation portion to $i!/2!(i-2)!$ and simplify from there? Not sure if that will help, not to mention if I put $1$ in for $i$ I get $1/-2$ which I don't think is right. Anyone care to shed some light on the subject? Thanks.","['discrete-mathematics', 'factorial', 'summation', 'binomial-coefficients', 'combinatorics']"
707272,"Why do statisticians like ""$n-1$"" instead of ""$n$""?","Does anyone have an intuitive explanation (no formulas, just words! :D) about the ""$n-1$"" instead of ""$n$"" in the unbiased variance estimator
$$S_n^2 = \dfrac{\sum\limits_{i = 1}^n \left(X_i-\bar{X}\right)^2}{n-1}?$$","['statistics', 'standard-deviation', 'intuition', 'notation']"
707294,"If $\,x>1$, then $\lim\limits_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x$. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I prove that
$$
\lim_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x,
$$
whenever $x>1$. Here $\left\lfloor \cdot\right\rfloor$ denotes the floor function,
or the integer part function. The integer part $\lfloor z\rfloor$ of $z$ is the largest integer, which does not exceed $z$. Thanks for your answer.","['sequences-and-series', 'convergence-divergence', 'calculus', 'ceiling-and-floor-functions', 'limits']"
707306,Why is this proof incorrect? - $f(b) - f(a) = [Df(c)](b-a) = \nabla f(c) \cdot (b-a)$,"I'm currently a student in a Vector Calculus class, and received my exam back today. I plan to go to the professor's office hours, but I'd like to ask here (in case there's some blatantly obvious fault I'm missing). Not only do I not understand why I received no partial credit in this problem, but I don't understand why it's not completely correct. I'd really appreciate any insight. The problem statement is: Let $a,b \in \mathbb{R^n}$ with $a \neq b$ . The segment $(a,b)$ in $\mathbb{R^n}$ is defined by: $$(a,b) := \{x \in \mathbb{R^n} | ~x = (1 - t)a + tb,~ t \in (0,1) \} $$ Let $f: \mathbb{R^n} \rightarrow \mathbb{R}$ be differentiable on $\mathbb{R^n}$ . Use the Mean Value Theorem from single-variable calculus to show that there exists $c \in (a,b) \subset \mathbb{R^n}$ such that: $$f(b) - f(a) = [Df(c)](b-a) = \nabla f(c) \cdot (b-a)$$ Here's my proof: We know $f$ is differentiable on $\mathbb{R^n}$ (including on the interval $(a,b)$ ). Fix all elements in $x$ but one, call this element $x_i$ (that is, the $i^{th}$ element of $x$ . Let $a_i < c_i < b_i$ . By the mean value theorem, we know there is at least one $c_i$ such that the tangent at $c_i$ is parallel to the secant between $a_i$ and $b_i$ . That is, there exists a $c_i$ such that: $$\frac{f(b_i) - f(a_i)}{b_i - a_i} = \frac{\partial f(x_i)}{\partial c_i}$$ Multiplying by $(b_i - a_i)$ on both sides, we have: $$f(b_i) - f(a_i) = \frac{\partial f(x_i)}{\partial c_i}(b_i - a_i)$$ We now fix all other elements in $x$ and, by the same process, arrive at the same result for every component of $x$ . This gives us: $$f(b) - f(a) = \left(\frac{\partial f(x_1)}{\partial c_1} + \frac{\partial f(x_2)}{\partial c_2}  + ... + \frac{\partial f(x_n)}{\partial c_n} \right)(b-a)$$ Note that the term on the right side of the equality is just $\nabla f(c) \cdot (b-a)$ , so we know that there exists some $c$ such that: $$f(b) - f(a) = \nabla f(c) \cdot (b-a)$$ I have pretty much zero idea where I went wrong (but it's, apparently, all wrong). I'm very confused.","['multivariable-calculus', 'proof-verification', 'partial-derivative']"
707355,Irreducible representations (over $\mathbb{C}$) of dihedral groups,"Find  number of complex irreps of the group $D_n$. Find dimension of the irreps. I know that The number of complex irreps of a finite group is equal to the number of conjugacy classes of the group. All the reflections are conjugate to each other in case $n$ is odd, but they fall into two conjugacy classes if $n$ is even. But there are $n$ rotations in $D_n$. I can't find the number of conjugacy classes for these. The number of 1-dimensonal complex irreps is equal to $[D_n:D_n^\prime]$. I don't know anything about the commutator subgroup of $D_n$. The matrices for elements of $D_n$ have the following form:
$$R_k=\pmatrix{\cos{\frac{2 \pi k}{n}}&-\sin{\frac{2 \pi k}{n}}\\
               \sin{\frac{2 \pi k}{n}}& \cos{\frac{2 \pi k}{n}}}$$
$$S_k=\pmatrix{\cos{\frac{2 \pi k}{n}}& \sin{\frac{2 \pi k}{n}}\\
               \sin{\frac{2 \pi k}{n}}& -\cos{\frac{2 \pi k}{n}}}$$ $R_k$ is a rotation matrix, expressing a counterclockwise rotation through an angle of $2\pi k/n$. $S_k$ is a reflection across a line that makes an angle of $2\pi k/n$ with the $x$-axis. This helps me to find all $2$-dimensional real irreps, but what about the complex ones? Answer in my book: ""If $n=2k$, then there are $4$ 1-dimensional  complex irreps and $(k-1)$ 2-dimensional complex irreps; If $n=2k+1$, then there are $2$ 1-dimensional  complex irreps and $(k+1)$ 2-dimensional complex irreps.""","['finite-groups', 'group-theory', 'representation-theory']"
707400,Characterizing certain real functions,"After reading this question , I became curious about these functions, $f: \mathbb{R} \to \mathbb{R}$, with the property that $f(a+b) = f(a) + f(b)$ and $f(ab) = f(a)f(b)$. Clearly the only constant function with this property is $f(x) \equiv 0$. The non-constant ones are precisely the ring endomorphisms of $\mathbb{R}$, and you can easily show that they must satisfy $f(q) = q$ for $q \in \mathbb{Q}$. I want to understand what happens to these $f$ in $\mathbb{Q}^*$ (the irrational numbers), clearly if $f$ is continuous then $f(p) = p$ for $p \in \mathbb{Q}^*$. My question is, what values can $f$ take for $p \in \mathbb{Q}^*$ when $f$ is not continuous? I am thinking that for algebraic numbers the same thing happens (e.g $f(x) = x$), at least I am able to see that the possible values of $f$ for an algebraic number is finite, but I don't what else to say. Thanks,","['functions', 'abstract-algebra', 'real-analysis']"
707406,"Showing that if $f,g \in k[x,y]$ are irreducible and not associates then $(f,g) \cap k[x] \ne 0$","There is a part of example 10.25.3 at http://stacks.math.columbia.edu/tag/00EX that I'm having trouble understanding.  Here, $k$ is a field and $f,g \in k[x,y]$ are irreducible and are not associates.  I am confused where they show that $f$ and $g$ are relatively prime when viewed as elements of $k(x)[y]$. Specifically, why does the following shorter argument not work: $f$ and $g$ are irreducible in $k[x,y] = k[x][y]$ so by Gauss's lemma each $f$ and $g$ are irreducible in $k(x)[y]$.  Since $f$ and $g$ are both irreducible, they are, in particular, relatively prime in $k(x)[y]$.","['commutative-algebra', 'algebraic-geometry', 'irreducible-polynomials', 'polynomials']"
707431,Normal bundle of a line in a blow-up,Let $x\in X=\mathbb{P}^3$. Consider the blow-up $\widetilde{X}\to X$ of $x$ in $X$. Let $l\ni x$ be a line in $X$ and $\widetilde{l}$ is its strict transform in $\widetilde{X}$. How to prove that the normal bundle $N_{\widetilde{l}/\widetilde{X}}$ is $\mathcal{O}\oplus \mathcal{O}$? Upd. Let us blow two points on $l$. How to prove that the normal bundle of strict transform would be $\mathcal{O}(-1)\oplus \mathcal{O}(-1)$?,['algebraic-geometry']
707441,Are there nonisomorphic fields with isomorphic multiplicative groups?,"This is false for finite fields as the multiplicative groups of finite fields are cyclic, and different cardinalities yield cyclic groups of different cardinalities. But I'm unsure how to proceed for infinite fields.","['group-theory', 'abstract-algebra', 'field-theory']"
707443,Endomorphisms of the projective line,"Let $f:\mathbb{P}^1 \to \mathbb{P}^1$ be a degree 1 endomorphism of the the projective line over $\mathbb{C}$.  It is well known that $f$ is an automorphism, and moreover it is determined by its value at three points. Is there an analogous statement for endomorphisms $f:\mathbb{P}^1 \to \mathbb{P}^1$ of higher degree? (I would like for $f$ to be determined by its value on a few points and some information about its ramification.)","['algebraic-geometry', 'algebraic-curves']"
707468,"Is $d(x,y) = \sqrt{|x-y|}$ a metric on R?","For $x,y \in \mathbb{R}$, define $d(x,y) = \sqrt{|x-y|}$. Is this a metric on $\mathbb{R}$? It's clear that $d(x,x) = 0$ and $d(x,y) = d(y,x)$ for all $x,y \in \mathbb{R}$.  The triangle inequality seems to hold for all values I have tested, but I have not found this function anywhere online as an example of a metric on $\mathbb{R}$.","['general-topology', 'metric-spaces', 'real-analysis']"
707469,How to prove that $d \sin(x)/dx = \cos(x)$ without circular logic such as L'Hôpital's rule?,"How do I prove that the derivative of $\sin$ is $\cos$ without resorting to L'Hôpital's rule (circular logic) ? This part is easy: $$
\begin{align*}
\sin'(x) &= \lim_{\Delta x \to 0} \frac{\sin(x + \Delta x) - \sin(x)}{\Delta x}  \\
\sin'(x) &= \lim_{\Delta x \to 0} \frac{\cos(x)\sin(\Delta x) + \sin(x) \cos(\Delta x) - \sin(x)}{\Delta x}  \\
\sin'(x) &= \lim_{\Delta x \to 0} \left(\cos(x)\frac{\sin(\Delta x)}{\Delta x} + \sin(x)\frac{\cos(\Delta x) - 1}{\Delta x}\right)  \\
\end{align*}
$$ but where do I go from here?",['derivatives']
707485,What does it mean for a solution to a Linear DE to be homogeneous?,"I'm a physics student and I've just being going over some definitions for differential equations. I don't think I fully understand what a homogeneous equation is and the Wikipedia article says that a Linear DE has homogeneous solutions which add to form other homogeneous solutions. What does it mean for a solution to be homogeneous? Usually, a DE is said to be homogeneous if it is equal to zero. eg: $$u'' + u' -4u = 0$$ But that's not the full story is it? This definition of ""homogeneous"" is making me think that a homogeneous solution is equal to zero. Alas, mathematicians, please enlighten me.","['ordinary-differential-equations', 'homogeneous-equation']"
707537,Show $p(X)$ (over a field) is irreducible iff $p(X+a)$ is irreducible,"Let $A$ be a field and let $p(X)$ be a polynomial over $A$. Let $a\in A$. Want to show: $p(X)$ is irreducible if and only if $p(X+a)$ is irreducible. I suspect that I should use the substitution principle somehow , but that's as far as I've come. Completely stumped.","['irreducible-polynomials', 'abstract-algebra']"
707543,Partitions of a set into three parts,"How many partitions of the set $\{1,2,3, \ldots , 100\}$ are there such that both a) there are exactly three parts and b) elements $1,2,3$ are in different parts. Any help on this question would be fine. Hints are welcomed","['discrete-mathematics', 'set-partition']"
707604,"Prove that $\bigcup_{n=2}^{\infty} [1/n, 1 - 1/n] = (0, 1)$","This is an exercise for a set theory class. I already managed to prove $\bigcup_{n=2}^{\infty} [\frac{1}{n}, 1 - \frac{1}{n}] \subseteq (0, 1)$ : Let $x \in \bigcup_{n=2}^{\infty} [\frac{1}{n}, 1 - \frac{1}{n}]$ . Then, there exists an $n \in \mathbb N, n > 2$ such that $x \in [\frac{1}{n}, 1 - \frac{1}{n}]$ . That is, $\frac{1}{n} \leq x \leq 1 - \frac{1}{n}$ for some $n$ . We also have $n > 0$ , and thus $\frac{1}{n} = \frac{n}{n^2} > \frac{0}{n^2}$ . Then $0 \lt \frac{1}{n} \leq x \leq 1 - \frac{1}{n}$ . Since $\frac{1}{n} > 0$ , $-\frac{1}{n} < 0$ and $1 - \frac{1}{n} \lt 1 - 0$ . Putting all the inequalities together, $0 \lt \frac{1}{n} \leq x \leq 1 - \frac{1}{n} \lt 1$ . This implies $0 \lt x \lt 1$ . Therefore, $x \in (0, 1)$ . Though I don't know what to do about the other inclusion. I tried looking for a specific $n$ such that $x \in [\frac{1}{n}, 1 - \frac{1}{n}]$ , but I can't really do that only knowing that $0 \lt x \lt 1$ .",['elementary-set-theory']
707635,Are there any other functions that behave the same as $ce^x$ with respect to differentiation,"$$\frac{d}{dx} ce^x = ce^x$$
Are there any other functions $f$ such that
$$\frac{d}{dx} f(x) = f(x)$$
or is $ f(x) = ce^x $ the only one?",['calculus']
707647,About Example 1.8.2 in Durrett: Probability Theory and Examples,"The example is about tail $\sigma$-field. Given i.i.d. r.v. $ X_1, X_2, \dots $ and the partial sum $ S_n = X_1 + \dots + X_n $. The example says that $\{ \limsup_{n\rightarrow\infty} S_n > 0 \} \notin \mathcal{T}$ and $\{ \limsup_{n\rightarrow\infty} S_n/c_n > x \} \in \mathcal{T}$ if $c_n \rightarrow \infty$, where $\mathcal{T} = \cap_n \mathcal{F}'_n = \cap_n \sigma(X_n,X_{n+1},\dots)$ is the tail $\sigma$-field. I am always getting in trouble with the $\limsup$ stuff. Can anyone provide some explainations about the above example. Many thanks in advance.",['probability-theory']
707648,Algebraic Proof that a Disk is Convex,"After searching on Google for a while, I cannot seem to find an algebraic proof that a disk is a convex set. Intuitively, this seems obvious: if you take any two points $x, y$ in a disk, then the line from $x$ to $y$ is clearly contained in the disk. More specifically, let $D \subset \mathbb{R}^2$ be an origin-centered disk of radius $r$. Let $x = (x_1, x_2), y = (y_1, y_2) \in C$. We wish to show that for any $\lambda \in [0, 1]$, the point $z$ given by
$$
    z = \lambda x + (1 - \lambda) y = (\lambda x_1 + (1 - \lambda y_1), \lambda x_2 + (1 - \lambda) y_2)
$$
also lies in $D$. By definition, we have $\|x\|_2^2 \leq r^2$ and $\|y\|_2^2 \leq r^2$. Using this information, I tried to show that $\|z\|_2^2 \leq r^2$ as follows:
\begin{align*}
    (\lambda x_1 + (1 - \lambda y_1))^2 + (\lambda x_2 + (1 - \lambda) y_2)^2
    &= \lambda^2 x_1^2 + 2 \lambda (1 - \lambda) x_1 y_1 + (1 - \lambda)^2 y_1^2 + \\
    &\phantom{50} \lambda_2 x_2^2 + 2 \lambda (1 - \lambda) x_2 y_2 + (1 - \lambda)^2 y_2^2 \\
    &= \lambda^2 (x_1^2 + x_2^2) + 2 \lambda (1 - \lambda) (x_1 y_1 + x_2 y_2) + (1 - \lambda)^2 (y_1^2 + y_2^2).
\end{align*}
Unfortunately, I'm stuck at this point -- I can't see a clean way to factor this expression and bound it above by $r^2$. I feel like I am missing obvious, but at this time I cannot determine what that is. Is there a clean proof of this fact that follows from this reasoning? Edit: Solution using Cauchy-Schwarz Inequality Even though I used the notation for norms, it didn't occur to me to just use the triangle inequality, as Dustan Levenstein suggested. The solution would then proceed as follows:
\begin{align*}
    \| \lambda x + (1 - \lambda) y \|_2
    &\leq \lambda \| x \|_2 + (1 - \lambda) \| y \|_2 \\
    &\leq \lambda r + (1 - \lambda) r = r.
\end{align*}
It follows that $\| z \|_2^2 \leq r^2$, as desired. I'm still going to leave the question up, in case there's a solution that does not rely on the Cauchy-Schwarz inequality.","['geometry', 'convex-analysis', 'circles']"
707649,Why is the projection of a closed polytope closed?,"In general, projection of a closed set into a subspace does not result in a closed set. However, I was able to prove that in $\mathbb{R}^n$, the projection of a closed polytope (intersection of finitely many closed half spaces) onto a 1 dimensional subspace is closed. However the proof involved induction on dimension and using the theory of linear optimization. Is there a short topological proof of this fact? And perhaps a generalization that projection onto an m-dimensional subspace preserves closure? Intuitively imagining the shadow of a polytope, I feel it's true.","['general-topology', 'convex-analysis']"
707655,Showing independence of random variables,"When proving $\bar x$ and $S^2$ are independent in my noted it says that ""functions of independent quantities are independent "". Can someone tell me how functions of independent quantities are independent happen? Also let $X_1,X_2,X_3,\dots,X_n$ be a random sample.And suppose we want to estimate parameter $\theta$ using $T(x)$ as an estimator. In this I have a expression as $E\{ [  T(X)-E(T(X))][E(T(x)-\theta)]\}$. I want to know if I can say that in $[T(X)-E(T(X))]$ since $E(T(X)$ (expected value is a one particular fixed value) and $T(X)$ are independent of one another . Also the expression $[E(T(x)-\theta)]$ is independent of $X$. Hence the two expressions $[T(X)-E(T(X))]$ and $[E(T(x)-\theta)]$  are independent of one another. So that I can use if $a,b$ are independent $E(ab)=E(a)E(b)$ form","['statistics', 'statistical-inference']"
707666,Prove the set of sequences $c_0$ which converge to zero in $l_{\infty}$ is closed.,"Prove the set of sequences which converge to zero in $l_{\infty}$ is closed. Let $x_n(k)\rightarrow x(k)$ as $n\rightarrow\infty$ .  With $x_n(k)\in c_0$ and $x(k)\in l_{\infty}$ . Let $\varepsilon>0$ .  Then there exists an $N>0$ such that $$\parallel x_N-x\parallel_{\infty}:=\sup_{k\in\mathbb{N}}|x_N(k)-x(k)|\leq\varepsilon.$$ Then we have, \begin{align}
|x(k)| &= |x(k) - x_N(k) + x_N(k)| \\\\
&\leq |x_N(k) - x(k)| + |x_N(k)| \\\\
&\leq \varepsilon + |x_N(k)|\rightarrow \varepsilon\;\; \text{as}\;\; k\rightarrow\infty. 
\end{align} Therefore since $\varepsilon$ was chosen arbitrarily we can conclude that $x(k)\rightarrow0$ and thus that $x(k)\in c_0$ Can someone check my work on this?  It seems too slick and painless to be correct.","['functional-analysis', 'lp-spaces']"
707673,Find angle in degrees from one point to another in 2D space?,"Given Point A and Point B in 2D space, how can I find the angle Point B is from Point A? 0° can be any direction; it doesn't matter. For example, Point A is at (0, 10) and Point B is at (10, 20) . The angle is 45° in this example (assuming 0° is up).",['geometry']
707678,Spectral Mapping Theorem,Spectral mapping theorem is as follows: https://math.uc.edu/~halpern/Matrix.methods/Homatrixmethods/Spectralmappingthm.pdf Is Spectral mapping theorem true for point spectrum ?,"['operator-theory', 'spectral-theory', 'functional-analysis', 'analysis']"
707683,Coordinate transformation on del operator,"If there are two sets of orthogonal bases, $\hat{x}_1, ...,\hat{x_n}$ and $\hat{u}_1, ...,\hat{u_n}$, and a point in space can be expressed as $$\vec{r}=x_1\hat{x}_1+...+x_n\hat{x}_n$$ and $$\vec{r}=u_1\hat{u}_1+...+u_n\hat{u}_n$$ with the coordinate transformation $$x_i=f_i(u_1,...,u_n), i=1,2,...,n$$ So the volume element transformation shall be $$dx_1dx_2...dx_n=||A||du_1du_2...du_2$$ where $A$ is a $n\times n$ matrix with $$A_{ij}=\partial{f_i}/\partial{u_j}$$ Is there a similar relationship with the del operator $\nabla$? Given all $f_i$ and the del operator for the first set of bases, and all the projections $\hat{x}_i \cdot \hat{u}_i$, how do I get the del operator for the second set?","['multivariable-calculus', 'calculus']"
707690,How can you calculate the derivative of this Wronskian?,"If $W(y_1,y_2,y_3)=\left| \begin{array}{ccc} y_1 & y_2 & y_3 \\ y_1' & y_2' &  y_3'  \\ y_1'' & y_2'' & y_3'' \end{array}\right|$, how can I show that $W'(y_1,y_2,y_3)=\left| \begin{array}{ccc} y_1 & y_2 & y_3 \\ y_1' & y_2' &  y_3'  \\ y_1''' & y_2''' & y_3''' \end{array}\right|$? I am not sure how to go about computing the derivative of a determinant. Any input would be greatly appreciated.","['ordinary-differential-equations', 'wronskian']"
707705,What is the cardinality of the set of all infinite sequences?,"The set is defined as {$(n_1, n_2,...n_k ..) | n_k \in \mathbb{N}$}. What are some approaches to finding and proving the cardinality of this set?",['elementary-set-theory']
707706,Show the Volterra Operator is compact using only the definition of compact,"The Volterra operator $V:L^{2}[0,1]\rightarrow L^{2}[0,1]$ is defined by $(Vf)(x)=\int_0^xf(t)dt$. I am wondering if it can be shown that $V$ is compact by definition - that is, either that $V$ maps bounded sets to precompact sets, or equivalently, that for any bounded sequence $(f_n)$ in the domain, $\{Vf_n\}$ has a convergent subsequence. I have seen an elegant proof of the compactness of $V$ using the Arzela-Ascoli theorem.  Also, I have come across proofs using the notion of Hilbert-Schmidt operators.  However, both of these notions were foreign to me when I was assigned this problem, and I am curious if I can show $V$ is compact without using these ideas; unfortunately, I am not sure how to proceed directly. Thank you.","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'compact-operators']"
707772,How to prove that we cannot see more than 3 faces of an opaque solid cube simultaneously?,"Is there an elegant mathematical proof to assert that we cannot see more than 3 faces of an opaque solid cube simultaneously (of course without mirrors or any optical tools such as camera, etc)?",['geometry']
707778,Characterization of Volumes of Lattice Cubes,"Here is a problem that came up in a conversation with a professor. I do not know if he knew the answer (and told me none of it) and has since passed so I can no longer ask him about it. Let $C$ be a lattice cube in $\mathbb{R}^n$. Characterize all possible volumes for $C$. A cube is called a lattice cube if and only if every vertex has integer coordinates. I broke this proof into three cases, the last of which I am having trouble with in one direction. We will let $V(n)$ be the set of all numbers $V$ for which there exists a lattice cube of volume $V$ in dimension $n$. We will break into three cases based on the value mod 4. \begin{align*}
V(2k+1)&=\{a^n:a\in\mathbb{N}\} \\
V(4k)&=\{a^\frac{n}{2}:a\in\mathbb{N}\} \\
V(4k+2)&\supseteq\{(a^2+b^2)^\frac{n}{2}:a,b\in\mathbb{N}\}
\end{align*} These statements I have proven, and conjecture that the last one is an equality. I've been trying to use a collapsing dimension argument to show if I can make a cube of side length $s$ in $\mathbb{R}^{4k+2}$ then I can in $\mathbb{R}^{4k-2}$, at which point the theorem follows since I have proven the special case of $n=2$ (which is quite trivial - there is no way to write down a square whose volume is not of the specified form in $2$D. The above assertions (sans my conjecture) are proven here","['matrices', 'geometry', 'number-theory']"
707784,Prove the curvature of a level set equals divergence of the normalized gradient,"Suppose we have a function $\phi : \mathbb{R}^2 \to \mathbb{R}$, and a curve $\gamma:\mathbb{R}\to\mathbb{R}^2$ defined by a level set of $\phi$, ie. the codomain of $\gamma$ is $\{(x,y)\mid\phi(x,y)=C\}$ for a given constant $C$. Edit: assume that $\gamma$ is parameterized by arc length, so $\left\|\gamma'(s)\right\|=1.$ The curvature of $\gamma$ is defined as $$\kappa(s)\equiv\left\|T'(s)\right\|=\left\|\gamma''(s)\right\|\,\,.$$ Show that it can also be written as
$$\kappa(s) = \left|\nabla\cdot\left(\frac{\nabla \phi}{\left|\nabla\phi\right|}\right)\right|$$
where $\phi=\phi\left(\gamma(s)\right)$. (Note: not a homework problem.  I came across this while watching a youtube video on Level Set Methods )",['differential-geometry']
707799,How to find the sum of $i(i+1)\cdots(i+k)$ for fixed $k$ between $i = 1$ and $n$? [duplicate],"This question already has answers here : Finding a closed formula for $1\cdot2\cdot3\cdots k +\dots + n(n+1)(n+2)\cdots(k+n-1)$ (5 answers) Closed 8 years ago . I learned that $$\sum \limits_{i=1}^n i(i+1) = \frac{n(n+1)(n+2)}{3}$$ or in general $$\sum \limits_{i = 1}^n i(i+1)(i+2) \dots (i + k) = \frac{n(n+1)\dots (n+k+1)}{k+2}$$ From a mathematical standpoint why is this true? I'm not asking for inductive proof. I am asking if you only given the left hand side, how would you go about writing a closed form expression for the sum?","['summation', 'sequences-and-series']"
707806,Algebraic numbers and their closure,"Are all of the roots/zeroes of a polynomial of finite degree with algebraic coefficients algebraic? How about for a generalization of a polynomial wherein the indefinite is exponentiated to an algebraic power and then multiplied by an algebraic coefficient, where the number of terms is finite, provided that such a zero/root/value exists? In other words, must the values $z$ for which sums of summands of the form $az^b$ , where $a$ and $b$ are algebraic, evaluate to zero be algebraic (if such $z$ exists)?","['algebraic-number-theory', 'abstract-algebra']"
707807,Strange closed forms for hypergeometric functions,"So in the process of trying to find a derivation for this answer, the following interesting equalities arose (one can check with Wolfram Alpha/Mathematica): $$\frac{8\sqrt{2}G^4}{5\pi^2} \left(\left(7 \sqrt{2}-10\right) \beta +5 \left(\sqrt{2}-2\right)\right) = -\pi/2,\tag1$$ $$-\frac{4}{3} \left(\alpha\left(\sqrt{2}-1\right)^2 +6 \ln \left(\sqrt{2}-1\right)\right) = 7\ln 2 - \ln(17-12\sqrt{2})-\pi/2,\tag2$$ where $G = \Gamma\left(\frac{3}{4}\right)$, $\alpha = {}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right)$ and $\beta = {}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right)$. Doing some simplification and solving will tell you: $${}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right) = \frac{3}{4}\cdot\frac{\pi/2-7\ln{2}-4\ln(\sqrt{2}-1)}{(\sqrt{2}-1)^2},\tag4$$ $${}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right) = \frac{5}{4}\cdot\frac{(\pi/2)^3-4(\sqrt{2}-1)G^4}{G^4(\sqrt{2}-1)^3}.\tag5$$ It's very bizarre that aside from the Gamma function valued at 3/4, these come out to (relatively) nice closed forms. My guess is that they are a result of integrals, but I have no idea what those integrals could be. Mathematica doesn't get anywhere with the hypergeometric functions, so I'm a bit stuck. Note: $(\sqrt{2}-1)^2 = 3 - 2\sqrt{2}$. That last number seems to come out, sort of, in the result of the hypergeometric functions' closed form, but I can't place why. EDIT: Here are some ways of describing both functions simultaneously, which may help in some way: ${}_3F_2\left(a,b,c;c+\frac{1}{2},b+1;z\right)$, ${}_3F_2\left(a,b,c;c+\frac{1}{2},a+b;z\right)$, ${}_3F_2\left(a,b,b+\frac{1}{4};a+b-\frac{1}{4},a+b;z\right)$, ${}_3F_2\left(1,a,a+\frac{1}{4};a+\frac{3}{4},a+1;z\right)$","['closed-form', 'special-functions', 'calculus', 'gamma-function', 'hypergeometric-function']"
707867,Find set with maximal cardinality given constraints,"We are given a set $A = \{1,2,3 \:...\:256 \}$. I'm obliged to find such A', so: $A' \subset A$ A' has the maximal possible cardinality A' contains no elements x,y which satisfy the following equality: $x = 2y$ I came up with some thoughts, but I'm not sure that my answer is correct, and I'm sure that the task could be solved in a more mathematically beautiful style. My reasoning was the following: 1. First, pick up all odd numbers from set A. It makes 128 elements.
 2. Then, pick all even numbers, which are large enough to not comply with the equation $x = 2y$. They are $\{130, 132\:...\: 256\}$. It adds 64 elements. 3. Then we note, that half of those 64 elements could be divided by 2 and some odd number from set A'. So we should only use those elements from previous step, which comply x div 4 = 0. 4. Also, we can include some even numbers, which are small enough to not have and greater match. They are $\{2, 4\:...\: 64\}$. We have to skip every second of them, to not create new matches. It gives us another 16: $\{4,8,12\:...\: 64\}$. Though, we have skip every second of them again, since they build pairs with themselves. It's 8 now: $\{4,12\:...\: 32\}$ 5. Thus, we have 128 + 32 + 8 = 168, which is the maximal cardinality of A'. I believe this solution lacks proof of maximality. So I would appreciate if you guys could prove my solution correct or erroneous or suggest more mathematically advanced way of approaching this problem (for example, I tried to look at elements of A as sequences of 8 bits, but it didn't help me much).","['elementary-number-theory', 'elementary-set-theory']"
707870,Convergence or divergence of $\sum\limits_n(-1)^{\pi(n)}\frac1n$ where $\pi(n)$ is the number of primes less than or equal to $n$,Consider $$\sum_{n=1}^{\infty}\frac{(-1)^{\pi(n)}}{n}$$ where $\pi(n)$ is the number of primes less than or equal to $n$. Does this sum converge or does it diverge? Are there any results related to this?,"['prime-numbers', 'sequences-and-series', 'number-theory']"
707876,Showing that $f$ has exactly one fixed point,"Let $\gamma$ be the circle $\{z \in \mathbb{C}: \lvert z\rvert=1  \}$. Suppose $f$ is a function analytic on an open set containing $\gamma$ and its interior and that $\lvert\, f(z)\rvert<1$ for each $z$ on $\gamma$. Show that $f$ has exactly one fixed point inside $\gamma$ That is, there is exactly one $z$ in the open unit disk with $f(z)=z$. Is this a result of Louville's theorem? I don't know how to approach it.","['fixed-point-theorems', 'complex-analysis', 'analysis']"
707877,Noetherian schemes and varieties,"What types of varieties (e.g. projective, affine,...) over a field $k$ (char = $0$) are Noetherian schemes?","['algebraic-geometry', 'schemes']"
707934,Three questions about ucp convergence,"We say that a sequence of processes $X^n$ converges to a process $X$ uniformly on compacts in probability if for all $\epsilon >0, t>0$
$$P[\sup_{s\le t}|X^n_s-X_s|>\epsilon]\to 0 $$
for $n\to\infty$. We suppose that the processes $X^n$, $X$ are nice such that the supremum is measurable, e.g. left or right continuous. To get a feeling for the definition I wanted to prove several things. I stuck on three of these and it would be appreciated if someone could help me. I will first state the three questions and then explain my attempts so far. I want to prove that $X^n\to X$ in ucp if and only $d(X^n,X)\to 0$, where
$$d(X,Y):=\sum_{m=1}^\infty 2^{-m}E[1\wedge \sup_{s\le m}|X_s-Y_s|] $$ If $X^n\to X$ then we can pass to a subsequence which converges a.s. uniformly on compacts. For a left-continuous process with right limits $Y$ we define $T_n:=\inf\{t:|Y_t|> n\}$. By the Début theorem $T_n$ is a stopping time (we assume the usual assumption on the filtration). Let $Y^n:=Y^{T_n}\mathbf1_{T_n>0}$, where $X^T:=(X)_{t\wedge T}$. Why does $Y^n \to Y$ in ucp? My thoughts: Suppose $X^n\to X$ in ucp. Let $\delta>0$, we have to prove that there is a $N\in\mathbb{N}$ such that for all $n\ge N$ we have 
$$d(X^n,X)<\delta $$
i.e. $$\big(\sum_{m=1}^\infty 2^{-m}E[1\wedge \sup_{s\le m}|X^n_s-X_s|] \big)<\delta$$ Of course we want to manipulate the expectation in such a way to apply ucp convergence. Let $A:=\{\sup_{s\le m}|X^n_s-X_s|\le 1\}$, I started $$E[1\wedge \sup_{s\le m}|X^n_s-X_s|]=E[(1\wedge \sup_{s\le m}|X^n_s-X_s|)\mathbf1_A]+E[(1\wedge \sup_{s\le m}|X^n_s-X_s|)\mathbf1_{A^c}]$$ The first term can be bounded by $$E[(1\wedge \sup_{s\le m}|X^n_s-X_s|)\mathbf1_A]\le P[A]=P[\sup_{s\le m}|X^n_s-X_s|\le 1] $$ The second one is equal
$$E[(1\wedge \sup_{s\le m}|X^n_s-X_s|)\mathbf1_{A^c}]=P[\sup_{s\le m}|X^n_s-X_s|> 1]$$
The second one is nice, since it is of the form to apply ucp convergence. However, I can make this probability as small as I want but it will still depend on $m$. Moreover it is unclear how I get rid of the first term. For the converse direction I have no idea so far. By convergence in ucp we can pass to a subsequence again denoted by $X^n$ such that $d(X^n,X)<2^{-n}$. To apply Borel-Cantelli and establish the result we must prove for every $\epsilon >0,t>0$ that $$\sum_{n=1}^\infty P[\sup_{s\le t}|X^n_s-X_s|>\epsilon]<\infty $$
Of course the idea is to bound $P[\sup_{s\le t}|X^n_s-X_s|>\epsilon]<D(X^n,X)$. By $1.$ there is a $m$ such that $P[\sup_{s\le t}|X^n_s-X_s|>1]\le P[\sup_{s\le m}|X^n_s-X_s|>1]$. in fact ever $m>t$ does the job. For $\epsilon >1 $ I also have $$P[\sup_{s\le t}|X^n_s-X_s|>1]\ge P[\sup_{s\le t}|X^n_s-X_s|>\epsilon]$$. But how should I deal the case $\epsilon <1$? Moreover I have still to think about the $2^{-m}$. Intuitively this is clear but I have trouble to write it down
formally. I tried to apply Markov's inequality without success. What
I need to prove is that for every $\epsilon,t,\delta>0$ there is a
$N\in\mathbb{N}$ such that for all $n\ge N$ we have $$ P[\sup_{s\le
    t}|Y^n_s-Y_s|>\epsilon]\le \delta$$","['probability-theory', 'stochastic-processes', 'convergence-divergence']"
707935,Dini derivatives and fundamental theorem of calculus,"I have been looking for some references concerning the fundamental theorem of calculus and Dini derivatives and I did not find it. I would like to know if given a locally Lipschitz function $f:\mathbb{R}\to\mathbb{R}$, then it is related to its Dini derivative by \begin{equation*}
 f(t)=f(0)+\int_0^tD^+f(s)\,ds.
\end{equation*} Does someone knows a reference on that?","['integration', 'definite-integrals', 'real-analysis', 'analysis', 'derivatives']"
707942,Borel cantelli lemma application.,"For each fixed $C>0$ write 
$$A_{c}=\{x\in [0,1]:\mid x-\frac{p}{q}\mid >\frac{c}{q^3} \text{for every relatively prime pair} (p,q)\in \mathbb{N}\}$$
Prove that each $A_{c}$ is measurable and there exists $c>0$ such that $\lambda(A_{c})=\frac{1}{2}$, whre $\lambda$ is Lebesgue measure. For the $A_{c}$ is measurable we can use Borel cantelli lemma. I need help how to construct second assertion.","['measure-theory', 'real-analysis']"
707945,How to find the absolute value of a vector?,"In my linear algebra course I keep seeing something like this: a = {1, 3, 5} Then in formulas I see this: |a| What does this mean, what is the absolute value of a vector? Wouldn't just be {1,3,5}?","['linear-algebra', 'vectors']"
707957,Isometry group of a compact manifold,Is an isometry group of a compact manifold always a compact group?,"['riemannian-geometry', 'lie-groups', 'differential-geometry']"
707996,Number of ways to distribute indistinguishable balls into distinguishable boxes of given size,"I need to find a formula for the total number of ways to distribute $N$ indistinguishable balls into $k$ distinguishable boxes of size $S\leq N$ (the cases with empty boxes are allowed). So I mean that the maximum number of balls that we can put in each box is $S$, while the minimum number is zero. In the case $S=N$ the result should be: \begin{equation}
\binom{N+k-1}{N}
\end{equation} Do you know the formula for the general case? Thanks in advance! P.S.: something similar can be found here .","['binomial-coefficients', 'combinatorics']"
708091,Find the maximum angle possible,"$P$ is a point on the $Y-axis$ . Find the maximum possible value of $\angle APB$ where $A=(1,0)$ and $B=(3,0)$. Here is how I solved the problem. Suppose $P=(0,k)$ .  Then using the cosine formula we get  $\cos\angle APB$ as a $f(k)$ . Then differentiating the function for finding maxima and minima, I got the answer. But this is a very lengthy process because $f(k)$ is a little complicated and then differentiating it makes it a lot more worse. Can anyone tell me a simpler way to solve the problem?","['geometry', 'calculus', 'differential-geometry', 'triangles', 'trigonometry']"
708097,Name for multiples of orthogonal matrices,"Is there a name for a matrix which is a multiple of an orthogonal matrix? I.e. a square matrix $A$ which satisfies the condition $$A^TA = AA^T = \lambda I$$ where $\lambda$ is some scalar (which should perhaps be required to be non-zero) and $I$ is the identity matrix. Or in other words, a matrix whose rows and columns are orthogonal vectors of equal length $\sqrt\lambda$, but not neccessarily unit length, so not orthonormal. I've thought about these objects twice in different contexts recently, and it feels like a concept that should have a name. So far I haven't been able to find such a name, though. Do you know an established name for these matrices?","['orthogonal-matrices', 'matrices', 'linear-algebra', 'terminology']"
708109,find a chance that all N points lie on the half circle. [duplicate],"This question already has answers here : Probability that n points on a circle are in one semicircle (6 answers) Closed 10 years ago . We are given a circle with N randomly allocated points on it. Task is to find a chance that all N points lie on the one half of circle. I have drafted some solution: 1. Since there are no way to put two points on circle, so that they were not on the same half-circle, $P_1$ and $P_2$ picked randomly and didn't affect the chance. So, required probability is: $P(P_3) \cdot P(P_4)\: \cdot ... \cdot P(P_n)$, where $P(P_i)$ is the chance that i-th point lays on the proper half of circle. 2. Let's visualize what's $P(P_3)$, $P(P_4)$ look like: Grey sector highlights forbidden part of circle. It's obvious from pictures, that $P(P_i)$ approaching 0.5 as point amount increases For this specific example, we could write:
$P(P_3) = 1 - \frac {\Delta(\theta_2,\theta_1)} {2\pi}$ $P(P_4) = 1 - \frac {\Delta(\theta_3,\theta_1)} {2\pi}$. 3. Then if we generalize, $P(P_i) = 1 - \frac {\Delta_i} {2\pi}$, where $\Delta_i$ is a difference of angles of the most distant points. And I'm understand that here I should introduce some generalized formula but I don't see it and don't want to make guesses. So I would appreciate any help.","['geometry', 'probability', 'geometric-probability']"
708113,A module over an algebra. Is it a vector space?,"Let $A$ be an algebra over a field $k$. I would like to know if my understanding of the following correct or not. What I want to clarify is the definition of a module $M$ over $A$. I know the definition of a module over a ring. Is the definition of a module over an algebra $A$ the same as the
ring theoretic definition replacing a ring by an algebra? Or, a module is a $k$-module, plus $A$ action? Or, are they the same? If it is the definition 2 above, then $M$ is a vector space over $k$. Is $M$ a vector space in the case of 1?","['modules', 'abstract-algebra']"
708164,Uncertainty in parallel resistors.,I need help with one of my study guide questions. We learned about uncertainty in class but am not sure how to attack this problem: Could someone walk me through this example? Any help will be appreciated!,['statistics']
708219,Zeta function for nonpositive integers,"I already proved that $\zeta(z)=\frac{1}{\Gamma(z)}\int_0^\infty\frac{t^{z-1}}{e^t-1}dt=\frac{\Gamma(z-1)}{2\pi i}\int_{-\infty}^0\frac{t^{z-1}}{e^{-t}-1}dt$ Now the Benoulli numbers are defined by $\frac{1}{e^t-1}=\sum_{m=0}^{\infty}B_m\frac{t^{m-1}}{m!}$ where $B_0=1, B_1=1/2, B_{2m+1}=0$ How can I use these things to get an expression for $\zeta(-n), n=0,1,2,3...$ in terms of $B_n$","['riemann-zeta', 'special-functions', 'integration', 'zeta-functions']"
708261,Find out minimize volume (V) of tetrahedral,"I have this problem: On space $ (Oxyz)$ given point $M(1,2,3)$. Plane ($\alpha$) contain point $M$ and ($\alpha$) cross $Ox$ at $A(a,0,0)$; $Oy$ at $B(0,b,0)$; $C(0,0,c)$. Where a,b,c>0 Write the equation of plane ($\alpha$) such that  It makes $V_{OABC}$ reach minimum. I don't know which inequality should use in here to find out $\min_{V_{OAB}}$ . Please help me. P\s: We have formula: $V_{OABC} = \frac{1}{6}a.b.c$","['optimization', 'geometry']"
708287,Inequality of Frobenius norm for skew matrices,"Let $A$ be a complex skew- symmetric $n \times n$ matrix, that is, $A^T = -A$. Denote by $\|\cdot\|_F$ the Frobenius norm, that is, $\|B\|_F^2 = \text{trace}(B^*B)$. I would like to prove that
$$
\big\|A^*A\big\|_F^2 \leq \frac{1}{2}\big\|A\big\|_F^4.
$$
Even better would be to prove a strict inequality, that is, to replace $\frac{1}{2}$ by a strictly smaller constant (possibly depending on $n$, possibly tending to $\frac{1}{2}$ as $n$ grows). The strange condition of $A$ being complex but skew-symmetric is unfortunately unavoidable, since this $A$ comes essentially from the Lie algebra of $SO(n, \mathbb{C})$. For reasons connected to this other point of view, I deduced from some ""too-well-known-to-give-a-reference"" facts in the literature that the inequality must hold, but I have never seen a proof of that. For arbitrary matrices $A$ a weaker inequality holds with $\frac{1}{2}$ replaced by $1$, by sub-multiplicativity. However, the equality is reached for a matrix made only of 1, which is as far from being skew-symmetric as possible. Motivated by this, I tried the computation for a skew matrix having 1 everywhere above the diagonal, but the ratio that one obtains in that case is
$$
\frac{\|A^*A\|_F^2}{\|A\|_F^4} = \frac{1}{3} \frac{n^2+n-3}{n^2-n},
$$
which tends to $\frac{1}{3}$ and does not look great for proving a general bound. If this were a general bound, however, I would be happy! But I have no reason to believe that, other than I have no better guesses... Thanks in advance for any help! EDIT: I still do not know how to prove the inequality in general, but at least I can now prove that the inequality is optimal, since if one takes any (nonzero...) matrix of the form
$$
A = \begin{pmatrix}
0 & \dots & 0 & v_1\\
\vdots & \ddots & \vdots & \vdots\\
0 & \dots & 0 & v_{n-1}\\
-v_1 & \dots & -v_{n-1} & 0
\end{pmatrix}
$$
then $\text{trace}(A^*A) = -2\|v\|^2$ and $\text{trace}\big((A^*A)^2\big) = 2\|v\|^4$, realizing the equality. Thus restricting to real-valued matrices does not seem to make you lose anything.","['matrices', 'normed-spaces', 'inequality', 'lie-algebras']"
708294,Cardinality of the set of all straight lines in $\mathbb R^2$,"Find the cardinality of the set of all straight lines in  $\mathbb R^2$. Here's what I did: Let $M$ be the given set. $$M \sim\{y=ax+b, \ a,b\in \mathbb R \}\cup\{x=c, \ c\in\mathbb R \}$$ So: $$|M|=|\{(a,b) \ a,b\in \mathbb R\}|+|\{c, \ c\in\mathbb R\}| = \frak c\cdot\frak c +\frak c =\frak c$$",['elementary-set-theory']
708298,How many way can we obtain $0$?,"You are walking in road and you have only two directions,forward and back.Your $n$th step has length $n$. How many way can you return your starting point after $n$ steps ? It is equivalent to say that we have integers from $1$ to $n$.We want to get $0$ by adding or substructing these numbers. Let say $a_n$ is the answer.We can say that $a_1=0$ and $a_2=0$ as it is impossible to get $0$ and $a_3=2$ since $$1+2-3=0$$ $$-1-2+3=0$$ I can show that $a_n$ is nonzero if $n\equiv0 mod(4)$,but I am not even near to find $a_n$. Any result about $a_n$ would be appriciated.","['discrete-mathematics', 'combinatorics']"
708299,Invariance of Brownian motion under orthogonal transformations,"Let $\left(B_t\right)_{t \in [0,\infty)}$ be an $n$-dimensional Brownian motion with start at $x \in \mathbb{R}^n$, and let $A$ be an orthogonal $n \times n$ real matrix. I'm trying to show that $AB$ is again an $n$-dimensional Brownian motion. I've succeeded in showing that each component is a one-dimensional Brownian motion, but I'm having a hard time showing that the components are independent. Any help would be appreciated.","['probability-theory', 'stochastic-processes', 'brownian-motion']"
708307,Center of Mass with two functions,I am having trouble trying to figure out how to go about this problem. I can do problems with single variables but I can not solve this one. I think I would need to subtract the functions from one another but I am not sure which should be subtracted from which. If anyone can help with tips or solutions it would be greatly appreciated. Thank you.,"['calculus', 'integration']"
708310,Exponentiation in terms of Summation,"For positive integers, $a \times b=\sum\limits^{b}{a}$, correct? So therefore exponentiation where n is also a positive integer should be something like $a^n=\sum\limits^n{\sum\limits^a{a}}$ This is for a proof by induction, and I just want to see if I can simplify the proof enormously by doing this. Is this correct, or am I missing something?","['summation', 'discrete-mathematics']"
708354,"Let $a_n$ be a convergent sequence wit limit $L$. With out using the Heine-Borel theorem, prove that the set $\{L,a_1,a_2,...\}$ is compact.","Let $a_n$ be a convergent sequence wit limit $L$. With out using the Heine-Borel theorem, prove that the set $\{L,a_1,a_2,...\}$ is compact. I know that $a_n$ is convergent to $L$, meaning for all $\epsilon >0$, there exists an $N>0$ such that $n>N$   implies $|a_n -L|< \epsilon $ I also know that $a_n$ is convergent, so it's bounded, so is $\{L,a_1,a_2,...\}$ . I can prove this set is both bounded and closed, so it's sequentially compact, hence compact. But I'm not allowed to use this theorem. How can I use the above info to prove that set is compact?","['general-topology', 'calculus']"
708359,Limits of Topological Vector Spaces,"Let $X, Y_1, Y_2, \cdots$ be a sequence of topological vector spaces, and let $f_n : X \to Y_n$ be a sequence of continuous linear maps. Define the product space $\mathcal Y_N := Y_1 \times \cdots \times Y_N$, and let $\mathcal Y_\infty := \prod_n Y_n$ denote the cartesian product (equipped with the product topology). Let $\pi_N : \mathcal Y_\infty \to \mathcal Y_N$ denote the projection maps. Let $F_N : X \to \mathcal Y_N$ denote the product function, defined by $F_N(x) := \big( f_1(x), \cdots, f_N(x) \big)$. Does there exist a continuous linear function $F_\infty : X \to \mathcal Y_\infty$ so that $$F_N = \pi_N \circ F_\infty$$ for all $N$? The answer seems ""obviously yes"", but there could be a topological issue that I'm missing. Assume that the spaces are infinite-dimensional. The more general question: ""Does the category $\operatorname{TopVectSp}$ of topological vector spaces have limits?""","['infinite-product', 'general-topology', 'category-theory', 'limits-colimits', 'functional-analysis']"
708373,"For every rational number, does there exist a sequence of irrationals which converges to it?",I can think of of examples where a sequence of irrationals converges to $0$. But if we pick any rational will there always exist a sequence of irrationals which converges to it? I cannot find a straight answer to this question.,['real-analysis']
708429,Values of the limit $\lim\limits_{x\to+\infty}\left(\sqrt{(x+a)(x+b)}-x\right)$,"Hi I have a question regarding finding the values of limit for the following question. Let $a, b \in \mathbb R$ . Find the limit $$\lim_{x\to+\infty}\left(\sqrt{(x+a)(x+b)}-x\right)$$","['radicals', 'limits']"
708439,An open cover $\{U_\alpha\}$ of $X$ is locally finite iff each $U\alpha$ intersects $U_\beta$ for only finitely many $\beta$,"I am trying to prove: Lee, Smooth Manifolds, Exercise 2.9. Show that an open cover $\{U_\alpha\}$ of $X$ is locally finite if and only if each $U\alpha$ intersects $U_\beta$ for only finitely many $\beta$. However, on my way I found what I believe to be the counterexample:
Let $X=\mathbb{R}$ and $\{U_\alpha\}=\{(k,k+2):k \in \mathbb{Z}\} \cup \{\mathbb{R}\}$. Then clearly $\{U_\alpha\}$ is locally finite since each point $p=k+\delta \in \mathbb{R}, k \in \mathbb{Z}, \delta \in [0,1)$ has a neighbourhood $(p-1,p+1)$ that intersects finitely many (3) sets from $\{U_\alpha\}$, notably $(k-1,k+1),(k,k+2),\mathbb{R}$. However, take $U_\alpha=\mathbb{R}$, then it intersects with $U_\beta=(k,k+2)$ for each $k \in \mathbb{Z}$, therefore for infinitely many $\beta$ which is a contradiction. Is the cover by definition minimal? I.e. no proper subset of the cover of $X$ is the cover for $X$? That we have to remove $\mathbb{R}$ from $\{U_\alpha\}$?","['general-topology', 'manifolds']"
708490,Generating a stochastic matrix with a given second dominant eigenvalue,"I need a procedure (iterative or otherwise) that, given a positive integer $N$ and a (possibly complex) number $\lambda$ such that $0 < \vert \lambda \vert < 1$, will be able to generate an $N \times N$ stochastic matrix $\mathbf{M}$ (in which every column sums to $1$) whose second-largest (in absolute value) eigenvalue is $\lambda$. The constraint is only on $\vert \lambda \vert$ and it does not matter if $\lambda$ is complex. The first (largest-magnitude) eigenvalue is always $1$. The rest of the eigenvalues are arbitrary. I need the procedure (if one exists) to always converge with a correct answer with probability $1$ (if it is iterative). I need this in Markov chain simulations and I want to control the convergence rate from the initial distributions to the equilibrium one. EDIT : It is also important to know that randomly generating a stochastic matrix in Matlab (shown in the figure below) yields a relatively small second-largest eigenvalue, indicating that the probability of having large second-largest eigenvalue is small and it needs to be crafted. You can also see the eigenvalue $1$ that always exists in isolation on the far right. The figure below is the spectra of $10000$ randomly generated $16 \times 16$ stochastic matrices. As pointed out in the comments, I found a paper that constructs a doubly stochastic matrix explicitly from a given positive spectrum. However, the constructed matrices are, in fact, very concentrated around the diagonal (these can be called lazy Markov chains since they tend to stay where they are). This result explains why it is extremely unlikely that a randomly generated stochastic matrix would have eigenvalues closer to $1$ than shown in the above figure. This means there is only local transitions between Markov chain states with very weak global transitions. Is that indeed implied by asking for large eigenvalues of the transition matrix ? Here is a surface plot of a $100 \times 100$ stochastic matrix constructed from a randomly generated positive spectrum as explained in this paper . I also found a result here saying that lazy, reversible Markov chains have positive spectra, which is in line with the above result.","['stochastic-processes', 'markov-chains', 'algorithms', 'linear-algebra', 'spectral-graph-theory']"
708498,Integral $\int_{-\infty}^\infty J^3_0(x) e^{i\omega x}\mathrm dx $,"Hi I am trying to evaluate the integral
$$
\mathcal{I}(\omega)=\int_{-\infty}^\infty J^3_0(x) e^{i\omega x}\mathrm dx
$$
analytically.  We can also write
$$
\mathcal{I}(\omega)=\mathcal{FT}\big(J^3_0(x)\big)
$$ which is the Fourier Transform of the cube of Bessel function.  The Bessel function $J_0$ is given by
$$
J_0(x)=\frac{1}{2\pi}\int_{-\pi}^\pi e^{-ix\sin t} \mathrm dt.
$$
If it helps, we can represent the cube of the Bessel function by
$$
J^3_0(x)=-3\int J^2_0(x) J_1(x) \mathrm dx, \ \ \ \ \ J_1(x)=\frac{1}{2\pi}\int_{-\pi}^\pi e^{i(t-x\sin t)} \mathrm dt.
$$
In general
$$
J_n(x)=\frac{1}{2\pi}\int_{-\pi}^\pi e^{i(nt-x\sin t)}\mathrm  dt.
$$
The Fourier Transforms of the Bessel function and its square is given by
$$
\mathcal{FT}\big(J_0(x)\big)=\sqrt{\frac{2}{\pi}}\frac{\theta(\omega+1)-\theta(\omega-1)}{\sqrt{1-\omega^2}}
$$ 
and 
$$
\mathcal{FT}\big(J^2_0(x)\big)=\frac{\sqrt{2}K\big(1-\frac{\omega^2}{4}\big)\big(\theta(-\omega-2)-1\big)\big(\theta(\omega-2)-1\big)}{\pi^{3/2}}         
$$
where K is the elliptic-K function and $\theta$ is the heaviside step function.  However I need the cube...","['calculus', 'integration', 'special-functions', 'definite-integrals', 'real-analysis']"
708522,"Prove $X=(y^{2}z-x^{3}+xz^{2})\backslash\{(1,0,-1)\}$ is irreducible.","Let $X=Z(y^{2}z-x^{3}+xz^{2})\subset\mathbb{P}^{2}$ and $P=(1,0,-1)$. Prove that $X\backslash P$ is irreducible in the Zariski topology. When char$(k)\neq 2$, I've answered this problem by showing that $y^{2}z-x^{3}+xz^{2}$ is irreducible because $X$ is a nonsingular variety in $\mathbb{P}^{2}$. $X\backslash P$ is an an open set of an irreducible set. Whence irreducible. When char$(k)=2$, I have a problem because $X$ has a singularity at $(1,0,-1)$ and nowhere else. So I am unable to show that the polynomial $y^{2}z-x^{3}+xz^{2}$ is irreducible. I have no idea how to proceed from here. Any direction or hints would be great. Thanks.","['algebraic-geometry', 'abstract-algebra']"
708523,Number of ways to place $k$ non-attacking rooks on an $m\times n$ chessboard,"I need to calculate the number of ways to place $k$ non-attacking rooks on an $m \times n$ table where $k \leq n$ and $k \leq m$.  (""Non-attacking"" means that no two rooks may share a row or column.)  My attempt: 
Calculate the number of ways to place $k$ rooks on a $k \times k$ board ($k!$), then multiply by the number of ways to select a $k \times k$ board from an $m \times n$ board. (This is the part I can't calculate, if it is correct at all.) 
My question: 
Is my approach good and if so, how to calculate the second part?",['combinatorics']
708531,"How to determine if a relation is a partial order, an equivalence relation, or none.","My understanding of relations is fair enough for now, however I am unsure how to determine the answer and provide a brief explanation. I can't say I am a fan (yet) of the notation used either. Here is an example taken from the homework: $$xRy \Leftrightarrow y|x \mbox{ is an integer}$$ Any hints, tips, and pointers into the right direction would be greatly appreciated! =) Also, if it is not too much to ask, may you go easy on using formal notation to explain? I am not the most confident reader of it, yet.",['discrete-mathematics']
708542,$\lim_{x\rightarrow 0^+} \frac {\ln(x)}{\ln( \sin x)}$ without l'Hôpital's rule,"How to calculate $\displaystyle
\lim_{x\rightarrow 0^{+}}\frac{\ln x}{\ln (\sin x)}$ without l'Hôpital's rule please?
If anybody knows please help
I don´t have any idea :-( 
I´m looking forward your helps","['calculus', 'limits']"
708543,Prove $ \left |\sin(x) - x + \frac{x^3}{3!} \right | < \frac{4}{15}$,"Prove $ \left |\sin(x) - x + \dfrac{x^3}{3!} \right | < \dfrac{4}{15}$ $\forall x \in [-2,2]$ By Maclaurin's formula and Lagrange's remainder we have $\sin(x)  = x - \dfrac{x^3}{3!} + \dfrac{\sin(\xi)}{5!}x^5$ for some $0<\xi<2$ subbing this in we get $\left|\dfrac{\sin(\xi)}{5!}x^5 \right| \leq \left |\dfrac{x^5}{5!} \right| \leq \dfrac{2^5}{5!} = \dfrac{4}{15}$, but the question has $<$ rather than $\leq$ - where have I done wrong? edit: thinking the $\cos(\xi)$ should be there rather than $\sin(\xi)$",['analysis']
708568,"The image of a Banach space under a continuous, linear, open map is a Banach space.","This is an exercise from Royden's Real Analysis . Suppose $X$ is a Banach space, there is a continuous, linear, open map from $X$ onto a normed linear space $Y$. Show that $Y$ is Banach.",['analysis']
708571,Is there a shape with infinite volume but finite surface area?,"Is there any pathological shape that has a finite surface area but an infinite volume, sort of like the opposite of a Gabriel's horn ?","['geometry', '3d', 'calculus', 'volume', 'area']"
708620,"Same mean, different standard deviation in data sets","How would a data set containing the values of a variable with a mean of 50 and a standard deviation of 3 compare with another data set containing the same variable, but a mean of 50 and a standard deviation of 12?",['statistics']
708634,Is an infinite line the same thing as an infinite circle?,"Imagine that you are sitting next to a line that extends infinitely in both directions.  Is it possible to distinguish it from an infinite circle? From my poor understanding of topology, I would guess that it makes a difference if it's a line or a circle: The second is closed, the first isn't. What they both do to a plane is, that they split it into two parts, left and right or in and out. But is this enough to say that they are obviously the same thing? EDIT $\lim_{R\to \infty}$ $\hskip1in$","['general-topology', 'geometry', 'infinity']"
708645,What is larger: The inside or the outside of the infinite circle? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Assume a circle with radius $R$ in a plane. Let $R$ go to infinity. What is larger: The inside or the outside of the circle? EDIT My naive way of thinking about ""largeness"" was just to compare $\displaystyle\lim_{R \to\infty} \pi R^2$ with the rest of the plane. I didn't think of where the origin of circle would be or any other things like theories. If this is wrong, don't blame a layman...","['geometry', 'infinity']"
708661,"Russian roulette, how many people left","I have a questian about a game similar to russian roulette. Suppose that we have n people in a room. Every round, everyone shoots a random person. So it can happen that everbody dies, or if everyone shoots the same person only two people die(the unlucky person and the person that hè shot). 
I want to know what the expected number of surviving persons is after one round. I have no clue how to approach this problem.",['probability']
708665,How do I get an exact value for the trigonometric expression?,"I'm trying find an exact value for $$\cos\left(\frac{1}{3}\arctan\left(\frac{-10}{9\sqrt{3}}\right)\right)$$ Evaluating $\cos(\arctan(\frac{-10}{9\sqrt{3}}))$ is straighforward, but I'm having trouble with the above expression. I plugged it into Wolfram Alpha and it returned $3/2 \sqrt{\frac{3}{7}}$. Any help would be appreciated.","['trigonometry', 'algebra-precalculus']"
708681,Every dense $G_\delta$ subset of $\Bbb R$ is uncountable,Every dense $G_\delta$ subset of $\Bbb R$ is uncountable. I know that I have to use Baire's Theorem but I don't know how. Thanks!,['real-analysis']
708686,Are the $L^p$ norms ordered by $p$?,A question left over from this post is: Are the $L^p$ norms ordered by $p$ like the power means are?,"['average', 'integration', 'lp-spaces']"
708693,How to prove $n^3 < 4^n$ using induction? [duplicate],"This question already has answers here : How to prove that for all natural numbers, $4^n > n^3$? (5 answers) Closed 10 years ago . It's true for all Natural numbers. What I've got so far: 
Prove $P(0) \to $ base case: Let $n = 0$ $(0)^3 < 4^0 = 0 < 1$ Then $P(0)$ is true. Part Two: Prove $P(n) \Rightarrow P(n + 1) $ Assume $P(n)$ $= n^3 < 4^n $ $= 4(n + 1)^3 < 4^{(n + 1)}$ im not sure if the last step is right. Where can I go from here?","['induction', 'discrete-mathematics']"
708696,Differentiate vector norm by matrix,"I've been trying to perform the following differentiation of a neural network: $$\frac{\delta||h(XW)\alpha-y||^2}{\delta W} = \frac{\delta}{\delta W}\sum_i(h(XW)_i\alpha-y_i)^2$$ Where $X$ and $W$ and matrices, $\alpha$ and $y$ are vectors, and $h$ is a point wise applied function. I've been reading the Wikipedia article on Matrix calculus and ""The Matrix Cookbook"" all day, but I can't seem to get things to work. I think it should probably be $$2(h(XW)\alpha-y)\frac{\delta}{\delta W}(h(XW)\alpha)$$ But I certainly get stuck at the $h$ function, which I guess you could say is from matrix to matrix. Any hints would be appreciated. Update: I think this derivation is correct: $$\frac{\delta||h(XW)\alpha-y||^2}{\delta W} = \frac{\delta}{\delta W}(h(XW)\alpha-y)^T(h(XW)\alpha-y) = 2(h(XW)\alpha-y)^T\frac{\delta}{\delta W}(h(XW)\alpha) = 2(h(XW)\alpha-y)^TX^Th'(XW)\alpha$$ This was derived by derivating over each element of $W$ using traces. Update 2: I found this great presentation of the topic: Schonemann_Trace_Derivatives_Presentation.pdf which I recommend very much. I've reformulated by defining $H=h(XW)$, $H'=h'(XW)$, $E = HA-Y$. Hence the problem has the pretty solution $$\frac{\delta}{\delta W}||E||_F^2 = \frac{\delta}{\delta W}Tr(EE^T) = 2X^T(H' \odot EA^T)$$ Where $\odot$ is the point wise product. By working more with the trace manipulations you can also get a formula for the generalized problem $h(h(...)W_2)W_1)W_0$.","['matrices', 'matrix-calculus', 'calculus', 'multivariable-calculus']"
708718,Two curvature formulas when equal arc-length,"all. So with a parametric curve $\vec{r}=\langle x(t),y(t)\rangle$, curvature is given by 
$$\kappa=\frac{|x'y''-x''y'|}{(x'^2+y'^2)^{3/2}}.$$
When we have constant arc-length, an alternate expression is
$$\kappa=|\vec{r}''(t)|=\sqrt{x''^2+y''^2}.$$
So I see why these are both valid expressions (I can derive them both), but when we have constant arc-length, I don't see why, when we have constant arc-length
$$|x'y''-x''y'|=x''^2+y''^2$$
is true.  Care to enlighten me?","['geometry', 'calculus', 'differential-geometry', 'curvature', 'parametric']"
708739,"If $G=\langle{a}\rangle$ is a cyclic group of order 4, what would the permutations in $S_4$ that would form a subgroup of $S_4 \cong G$ be?",I know Cayley's Theorem states that every group $G$ is isomorphic to a subgroup of the symmetric group acting on $G$. The proof of his theorem seems to hint at finding the 4 permutations,"['group-theory', 'abstract-algebra']"
708762,"When is $x^{\alpha}\sin(x^{\beta})$ uniformly continuous for $\alpha, \beta > 0$?","Consider a function $f_{\alpha, \beta}\colon (0, \infty) \longrightarrow \mathbb{R}$ defined in the following way: $$f_{\alpha, \beta} = x^{\alpha}\sin(x^{\beta}) \quad \alpha, \beta > 0$$ Then we can pose the questions: For which pairs $\alpha, \beta$ is this function uniformly continuous? For which sets $(\alpha, \beta)$ in $(0, \infty)^2$ is the family equicontinuous? I am baffled as to how to go about answering these questions in a clear and concise way. I think that it is possible to produce an answer by considering many cases and lots of tedious estimates. Is there a better way to approach the problem? Any help will be appreciated.","['uniform-continuity', 'continuity', 'real-analysis', 'analysis']"
708775,Does there exist some $k$ such that $2^n+k$ is never prime?,"Does there exist some odd positive integer $k$ such that, for all integers $n>0$, $2^n+k$ is never prime? Extension: If yes, for any $a$, does there always exist some $b$ such that $a^n+b$ is never prime? If no, do there exist some coprime positive integers $a,b>1$, such that $a^n+b$ is never prime?","['prime-numbers', 'number-theory']"
708779,Is a non-negative random variable with zero mean almost surely zero?,We have proven the following in class: If $X$ is a finite random variable with $X\geq 0$ then $$E(X)=0  \iff  P(X=0)=1$$ (By finite I meant that the range has finitely many elements). Does it hold for any non-negative random variable $X:\Omega\to\mathbb R_{\geq0}$? (I've tried proving it with the indicator function yet it didn't help.),"['probability-theory', 'random-variables']"
708793,Dimension of $SO_n(\mathbb{R})$,"Is there a simple proof that the dimension of $SO_n(\mathbb{R})$,
  a.k.a the group of rotations in $n$-dimensional space is $(n-1)n/2$? It would be great to see some proofs based only on the algebraic definition:
$$R \mid \left\{ R^T=R^{-1} \land \det(R)=1 \right\}$$
or alternatively proofs invoking geometrical arguments (though I'd like to stay away from proofs using Lie Algebra methods). Any takers?","['lie-groups', 'linear-algebra', 'group-theory', 'rotations']"
708816,A monic polynomial with integer coefficients has irrational or integer roots,"This is a tut question, where beforehand I had to prove that if $p$ is prime and $a$ is an integer and if $p|a^n$ then $p|a$. And from this I am supposed to prove that if $\alpha$ is a zero of the monic polynomial $T(x) = x^n + c_{n-1}x^{n-1} + ... + c_1x + c_0$ then $\alpha$ is irrational or an integer. I honestly have no idea where to start with this, any help would be greatly appreciated.","['elementary-number-theory', 'number-theory']"
708846,How to take derivative of sums of absolute values,Take the derivative of $f(m) = \sum_i | x_i - m |$. I've been told that derivative of each term is +1 or -1. How do you show that?,"['absolute-value', 'derivatives']"
708858,Closed orbits of complete flags in $\mathbb{C}^n$,Let $B$ be a symmetric (or antisymmetric) non-degenerate bilinear form on $\mathbb{C}^n$ and let $G$ be the associated group of automorphisms $O(n)$ (resp. $Sp(n)$). What can we say about the Zariski-closed $G$-orbits on the variety of complete flags in $\mathbb{C}^n$ for these two cases?,"['bilinear-form', 'algebraic-geometry', 'representation-theory', 'lie-groups']"
708922,Reducing a fraction by dividing top and bottom,"I am trying to cancel out to reduce this: $$\frac{ 6xh + 3h^2 + 5h }{ h }$$ Is it possible to cancel out the h's to become this;
$$\frac{ 6x + 3 + 5 }{ h }$$ While the $3$ goes into the $6x$? So the final answer is 
$2x + 5$?",['algebra-precalculus']
708947,Finding the derivative of $f(x) = 2x^2 + x - 3$ at $x = 4$.,"I am learning about derivatives and differentiating and I came across this; $f(x) = 2x^2 + x - 3$ at $x = 4$ This is as far as I get;
$$\frac{2(x + h)^2 + (x + h) - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2(x^2 + 2xh + h^2) + x + h - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2x^2 + 4xh + 2h^2 + x + h - 3 - 2x^2 - x + 3}{ h }$$ The answer I get is $$\frac{4xh + 2h^2 + h}{ h }$$ How can I reduce that further, and am I doing this correctly? Because the answers they show are $f'(x) = 4x+3$ $f '(x) = 2x-3$ $f '(x) = 4x+1$ $f '(x) = 4x-a$ I think I am doing something wrong or not reducing it correctly. I would really appreciate some guidance asap. Thanks!","['calculus', 'derivatives']"
708962,Simple combinatorics question - caught off guard!,"Prove that ${{2n}\choose{n}}$ is even for $n \in \mathbb{N}$. This one caught me off-guard when answering (or attempting to answer!) this for a student today. I tried this approach: $${{2n}\choose{n}}=\frac{(2n)!}{n!n!}=\frac{(2n)(2n-1)(2n-2)\dots (n+1)}{n!}$$ and recognized that rearranging the numerator as $$(2n)(2(n-1))(2(n-2)) \ldots (2n-1)(2n-3) \ldots(n+1)$$ can help, but I don't know, roughly speaking, how far the chain on the left of the dots above goes.",['combinatorics']
708973,question of some invertible sheaves,"Let $C$ be a nonsingular curve and $\mathcal{F}$ be a locally free sheaf with rank $2$.
suppose that $H^0(\mathcal{F})\neq 0$ and let $s \in H^0(\mathcal{F})$ be a nonzero section. Then $s$ determines an injective map $\mathcal{O}_C \rightarrow \mathcal{F}$
( I think that since $\mathcal{F}_U=\mathcal{O}_U \oplus \mathcal{O}_U$ for any open subset $U$, it determines injection). Put $\mathcal{L}=\mathcal{F}/\mathcal{O}_C$. I easily think that since $\mathcal{L}_p \cong (\mathcal{F}/\mathcal{O}_C)_p \cong \mathcal{F}_p/\mathcal{O}_{C,p} \cong \mathcal{O}_{C,p} \oplus \mathcal{O}_{C,p}/\mathcal{O}_{C,p} \cong \mathcal{O}_{C,p}$ for any point $p\in C$, $\mathcal{L}$ is invertible.
But In Hartshorne book(p.372), to show $\mathcal{L}$ is invertible, it must be check that $\mathcal{L}$ is torsion free since $C$ is nonsingular and $\mathcal{L}$ has rank $1$ in any case. My first question is why we check that $\mathcal{L}$ is torsion free?? So, suppose $\mathcal{L}$ is not torsion free and let $\mathcal{G}\subset \mathcal{F}$ be the inverse image of the torsion subsheaf of $\mathcal{L}$ by the map $\mathcal{F} \rightarrow \mathcal{L}$. Then, My last question is why $\mathcal{G}$ is torsion free of rank $1$ on $C$??",['algebraic-geometry']
708994,Proof of the Inverse of a Scalar times a Matrix,How would I prove that given a square matrix $A$ and non-zero scalar $c$ that $$(cA)^{-1}=c^{-1}A^{-1}$$,"['matrices', 'linear-algebra', 'inverse']"
709040,Solving $x^{\left\lfloor x \right\rfloor}\; =\; 2014$,"$x^{\left\lfloor x \right\rfloor}\; =\; 2014$ Mathematica gives that there are no solutions, but how do you actually come to the conclusion that there exists no solution to this equation?","['algebra-precalculus', 'discrete-mathematics']"
709047,Show that $\nabla [f(r)]=f'(r)\frac {\mathbf{r}}{r}$,"Let $\mathbf{r} = xi+yj+zk$, write $r= \|\mathbf{r}\|$ and let $f:\mathbb{R}\to\mathbb{R}$ be a function of class $C^1$ So from what I know, we can derive the function at least once and we know gradients are just the derivative of the function with respect to each variable . Anyways
$$r=\sqrt{x^2+y^2+z^2}$$
now replacing
$$\nabla f\left(\sqrt{x^2+y^2+z^2}\right)$$ where do I go from here to get the proof? I feel like I'm overthinking this. The follow up is to use the answer from the above to calculate $\nabla \left(\frac{r}{\sin r}\right)$. I am guessing $$\nabla f(r)=\nabla f\left(\frac{r}{\sin r}\right)=f'\left(\frac{r}{\sin r}\right) \frac{\|\frac{r}{\sin r}\|}{\frac{r}{\sin r}}$$",['multivariable-calculus']
709049,why is $\sqrt[3]{31}$ so close to $\pi$?,$\sqrt[3]{31}$ is about $3.14138$.  Why is this so close to $\pi$?,"['pi', 'radicals', 'algebra-precalculus']"
709114,How to prove $e^{A \oplus B} = e^A \otimes e^B$ where $A$ and $B$ are matrices? (Kronecker operations),"How to prove that $e^{A \oplus B} = $$e^A \otimes e^B$? Here $A$ and $B$ are $n\times n$ and $m \times m$ matrices, $\otimes$ is the Kronecker product and $\oplus$ is the Kronecker sum:
$$
A \oplus B = A\otimes I_m + I_n\otimes B,
$$
where $I_m$ and $I_n$ are the identity matrices of size $m\times m$ and $n\times n$, respectively. EDIT: Actually if you go to the page http://mathworld.wolfram.com/KroneckerSum.html it tells us this property is true. http://digitalcommons.unf.edu/cgi/viewcontent.cgi?article=1025&context=etd","['ring-theory', 'abstract-algebra', 'linear-algebra', 'quantum-mechanics', 'group-theory']"
709125,R is countable using Zorn's Lemma?,"I used Zorn's Lemma to cook up a proof that $\mathbb{R}$ is countable, and now I can't find a flaw in it. Can anyone help? Here it is... Denote by $\mathcal{A}$ the set of countable subsets of $\mathbb{R}$, partially ordered under inclusion, and consider any chain in $\mathcal{A}$:
$$A_0 \subseteq A_1 \subseteq A_2 \subseteq \dots$$
Now let $A = \cup_{k \ge 0} A_k$. Then $A \in \mathcal{A}$, the countable union of countable sets. It follows that every chain in $\mathcal{A}$ has an upper bound. So by Zorn's Lemma, $\mathcal{A}$ contains an element $X$ maximal under inclusion. Suppose now that there is $a \in \mathbb{R}$ not in $X$. Then $X' = X \cup \{ a \}$ is countable, for if $f: X \to \mathbb{Z}^{+}$ is a bijection, then $f': X' \to \mathbb{Z}^{+}$, $$f'(a) = 1 \quad \text{and} \quad f'(x) = f(x) + 1,$$
is a bijection. But then $X' \in \mathcal{A}$ strictly contains the maximal element $X$, a contradiction. So $a \in X$, and hence $X = \mathbb{R} \in \mathcal{A}$.","['set-theory', 'combinatorics']"
