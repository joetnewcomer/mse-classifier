question_id,title,body,tags
3837506,Values of k such that $f(x)=x^k|x|$ is 3 times differentiable at the origin,"We must find values of k such that $f(x)=x^k|x|$ is 3 times differentiable at the origin. Firstly we can view the question as a product of two functions $g(x)=x^k$ and $h(x)=|x|$ You may obtain the result of triple product rule as a function in terms of $f'$ s and $h'$ s It is clear to me that $h'$ nor $h''$ is not differentiable at the origin since the denominator of both contains a x, however I was unable to obtain a third derivative of h Thus all terms containing a h prime terms must be cancelled out by the f components, which clearly have zeros at $k=0,1,2$ respectively of their times differentiated This leads to the only solution being $k=0$ which cancels out all of the absolute value terms, but I suspect that this cannot be correct, is my intuition correct or is there some piece I am missing to solve this? EDIT : should be product of functions not composition","['calculus', 'derivatives', 'absolute-value', 'real-analysis']"
3837561,Constructing a convex polyhedron from a spherical polyhedron,"Suppose I am given an arbitrary 3-dimensional convex polyhedron $P\subset\Bbb R^3$ that contains the origin.
I can ""blow it up"" to a spherical polyhedron by projecting all edges and vertices (away from the origin) to the unit sphere (centered at the origin): What about the other direction? Question: Given a spherical polyhedron, is there a ""convex polyhedron"" whose projection is exactly the given spherical polyhedron? And how to construct it explicitly? For me, a spherical polyedron is a tiling of the 2-sphere where the edges are great circle arcs.
And I know that there is always a convex polyhedron with the same combinatorics as the given spherical polyhedron, but I ask specifically about a convex polyhedron that projects to the given spherical polyhedron.","['polyhedra', 'discrete-geometry', 'projection', 'polytopes', 'geometry']"
3837598,Prove that $x \in {\rm Jac}(R)$ if and only if $1-xy \in R^{\times}$ for all $y$.,"I know the definition of Jacobson radical $J(R)=\cap m$ over maximal ideals. I want to prove the following property, but I can prove just one side of it. Fact: $x \in {\rm Jac}(R) \Longleftrightarrow \forall y, 1-xy \in R^{\times}$ Proof: $\Leftarrow$ : suppose on contrary that $x \notin {\rm Jac}(R)$ , then there exists a maximal ideal $m$ such that $x \notin m$ , so $\langle x\rangle+m=R$ , so there exist $y \in R$ and $m_0 \in m$ such that $xy+m_0=1$ . By assumption $m_0=1-xy \in m$ is a unit, and thus $m=R$ , which contradicts the maximality of $m$ . $\Longrightarrow$ : I don't have any idea for this side. Edit :
I think I did something, but I can not complete it! $x \in {\rm Jac}(R)$ , and let $y$ be arbitrary and let $m$ be an arbitrary maximal ideal. We claim that $1-xy \notin m$ . suppose on contrary that $1-xy \in m$ , then $1=(1-xy)+xy \in m$ , so $m=R$ which contradicts the maximality of $m$ . so I proved that $1-xy$ is not included in no maximal ideal. but I can not go further. Considering both of the answers, I guess that $R^{\times}=R\setminus \cup m_{{\rm maximal}}$ , am I correct?","['abstract-algebra', 'solution-verification', 'commutative-algebra']"
3837600,Find maximum of $|\sqrt{x^4-7x^2-4x+20}-\sqrt{x^4+9x^2+16}|$ without using calculus,"Find maximum of $|\sqrt{x^4-7x^2-4x+20}-\sqrt{x^4+9x^2+16}|$ without using any calculus I believe I have made most of the progress but am stuck on the last step I rewrote the expression as- $$\left|\sqrt{(x^2-4)^2+(x-2)^2}-\sqrt{(x^2+4)^2+(x-0)^2}\right|$$ We notice that this is written in the format of the distance formula. In particular, this is the expression for the difference of distances from an arbitrary point $(x^2,x)$ and $(4,2)$ , $(-4,0)$ respectively. In this figure we have to find maximum of $|PA-PB|$ I could not think of how this could be maximised. Usually in questions like these $P$ somehow is collinear or lies on the reflection of some given point but nothing of that sort can happen here. I tried a few special points as well like $(4,-2),(0,0)$ etc. Can someone help me with this?","['maxima-minima', 'algebra-precalculus', 'quadratics']"
3837602,Chern character of ideal sheaf of non-smooth conic,"$\newcommand{\oh}{\mathcal{O}} \newcommand{\ch}{\mathrm{ch}} \newcommand{\Hom}{\mathrm{Hom}} \newcommand{\Ext}{\mathrm{Ext}}$ Let $i : C \hookrightarrow X$ be a non-smooth conic in a smooth projective threefold $X$ . I'm trying to find the Chern character $\ch(I_C)$ where $I_C$ is the ideal of $C$ . I know that for a smooth conic, we have $\ch(I_C)=(1,0,-2L,0)$ where $L$ is the class of a line, essentially by Hirzebruch-Riemann-Roch and being able to compute the cohomology groups $H^i(X, I_C)$ because $C \cong \mathbb{P}^1$ . For a non-smooth conic (either reducible, i.e. union of two transversal lines; or non-reduced, i.e. $C_{\mathrm{red}} = L$ a line) however, I'm not entirely sure what the cohomology groups $H^i(X, I_C)$ are. I've taken cohomology of the short exact sequence $0 \to I_C \to \oh_X \to i_* \oh_C \to 0$ which gives the long exact sequence $$ \begin{align} 0 & \to H^0(X, I_C) \to \mathbb{C} \to H^0(X, i_* \oh_C) \\
&\to H^1(X, I_C) \to 0 \to H^1(X, i_* \oh_C) \\
&\to H^2(X, I_C) \to 0 \to 0 \to \cdots \end{align} $$ Here I've used $H^i(X, i_* \oh_C) \cong H^i(C, \oh_C)$ and that this cohomology vanishes for $i > \dim(C)=1$ (Grothendieck). I've also used that $H^i(X, \oh_X)$ is $\mathbb{C}$ for $i=0$ and $0$ else. So my question essentially becomes: how does one compute the cohomologies $H^i(X, i_* \oh_C)$ for $i=0,1$ in the non-smooth case, and how to interpret the resulting sequence $ 0 \to H^0(X, I_C) \to \mathbb{C} \to H^0(X, i_* \oh_C) \to H^1(X, I_C) \to 0$ ? Thanks. Edit: I think I recall reading somewhere that for any conic, $H^1(C, \oh_C)=0$ (but I still don't know how to prove this?). If this is the case, then regardless of what $H^i(X, I_C)$ are for $i=0,1$ (I'd still be interested to know though), they'd have to be of equal dimension (by dimension counting the long exact sequence in cohomology). Then if $\ch(I_C)=(1,0,-2L, w)$ , we have $\chi(I_C)  = w = h^0(X,I_C)-h^1(X,I_C) = 0$ which would mean that for any conic $C$ , $\ch(I_C)=(1,0,-2L,0)$ . Is this correct?","['sheaf-cohomology', 'complex-geometry', 'algebraic-geometry', 'sheaf-theory', 'schemes']"
3837651,How can I find the value of the derivative at a certain value given the graph?,"I need to find the values of $$\lim_{h\rightarrow 0^+} \frac{f(2+h)-f(2)}{h}$$ I know that the value of $f(2)=-1$ I think I need to come up with an equation for the graph, which I can't come up with. I thought it was $|x-2|-1$ but that isn't it. How can I solve this?","['calculus', 'derivatives']"
3837726,"How prove this $x^3<\sin^2{x}\tan{x},x\in\left(0,\dfrac{\pi}{2}\right)$","show that $$x^3<\sin^2{x}\tan{x},x\in\left(0,\dfrac{\pi}{2}\right)$$ have nice methods? Thank you my try:
$$\Longleftrightarrow \cos{x}\cdot x^3<(\sin{x})^3$$ let
$$f(x)=\cos{x}\cdot x^3-(\sin{x})^3$$
$$\Longrightarrow f'(x)=-\sin{x}\cdot x^3+3\cos{x}\cdot x^2-3(\sin{x})^2\cos{x}$$",['inequality']
3837727,What is the theoretical mathematical justification for differential arithmetic?,"Throughout undergraduate physics textbooks, you will see informal math with differentials where elements like $dx$ and $dy$ are multiplied around like scalar constants, and differentiation in terms of a variable is treated as analogous to division. What is the theoretical justification for this? I have never seen a formal mathematical argument to say why this can be done, especially not in the textbooks that use it. When I mean formal, I mean an argument from the point of view of rigorous mathematics, not just saying that $\Delta x/\Delta y$ approximates $dx/dy$ so we can treat $dx$ like we would $\Delta x$ . Are there any formal proofs available? An example of the type of differential mathematics I am talking about is used in thermodynamics. https://en.wikipedia.org/wiki/Fundamental_thermodynamic_relation I have never seen the formal justification that undergirds this way of talking about infinitesimal changes and using the differentials like constants.",['derivatives']
3837744,Does the unit generate the additive group in a unital ring with cyclic additive group?,"Let $R$ be a unital ring with cyclic additve group $(R, +,0)$ . Is it the case that $1$ generates the additive group $(R,+,0)$ ? Thoughts: Maybe classifying the unital rings with cyclic subgroups is possible.","['ring-theory', 'group-theory', 'abstract-algebra']"
3837909,Prove $\mu(\varliminf _{n \rightarrow \infty} A_{n}) \leq \varliminf_{n \rightarrow \infty} \mu(A_{n})$,"If $(\Omega, \mathcal{A}, \mu)$ is a measure space, and $A_{n} \in \mathcal{A},$ then $\mu(\varliminf _{n \rightarrow \infty} A_{n}) \leq \varliminf_{n \rightarrow \infty} \mu(A_{n})$ I tried to prove the statement  by going back to the definition of liminf of a set: $$\mu(\varliminf A_n)=\mu(\bigcup^\infty_{n=1}\bigcap^\infty_{n=k}A_n)$$ As I know $\bigcap^\infty_{n=k}A_n$ is increasing when $k$ increases, I get $$\mu(\bigcup^\infty_{n=1}\bigcap^\infty_{n=k}A_n)=\lim\mu(\bigcap^\infty_{n=k}A_n)$$ but I am stucked from here. Intuitively, $\bigcap^N_{n=k}A_n$ is decreasing when $N\rightarrow\infty$ but as $n$ starts from $k$ , therefore it seems $\mu(\bigcap^N_{n=k}A_n)$ is bounded above but how do I connect  it to the $\inf \mu(A_n)$ ? On the other hand, it seems $\bigcap^\infty_{n=k}A_n$ is a decreasing sequence that is bounded below by $n\geq k$ . I am so confused with the bounded above and bounded below and the infimum in this case. I hope my question make sense. Could someone please explain to me how should I look at this question and reason the statement rigorously?","['measure-theory', 'supremum-and-infimum', 'set-theory', 'sequences-and-series']"
3837943,What is the function $f(x)$ which is differentiable everywhere and $f(x-1)f(x-2)+1=f(x)$?,"What is the function $f(x)$ which is differentiable everywhere and $f(x-1)f(x-2)+1=f(x)$ and $f(1)=f(2)=1$ ? I've been wondering about this problem for about $1 \frac{1}{2}$ years. I don't know the tools to solve this problem. So, if you could show me how to find a solution, I would like that. I found the values of $f(x)$ from $0$ to $10$ : $$0,1,1,2,3,7,22,155,3411,528706,1803416167,\dots,f(n)$$ I realized that at $f(-1)$ can't be found just using $f(x-1)f(x-2)+1=f(x)$ because $n\times f(0)=f(1)$ has infinite solutions. $f(-1)$ can't be zero because then $f(-2)$ wouldn't be defined because $n\times 0=-1$ . So maybe if I add $f(x)$ must differentiable everywhere I could get an answer.","['functional-equations', 'calculus', 'real-analysis']"
3837967,Primitive Pythagorean Triple: show a and b are coprime,"Show $a$ and $b$ must be relatively prime where $a= m^2 - n^2$ and $ b = 2mn$ . From this show that $r$ and $s$ are relatively prime. Show this
implies that $r$ and $s$ must be perfect squares as well. $r = n^2$ and $s = m^2$ . I don't really know where to start here. I'm new with proofs. My first inclination is to plug $r$ and $n$ into $a$ and $b$ , but this doesn't get me anywhere. Suggestions?","['pythagorean-triples', 'proof-writing', 'discrete-mathematics']"
3837974,How to group people so everyone meets?,"I have sort of a stupid maths problem which I was thinking about recently, given the UK's covid rules about only being able to meet with 6 people max. If I have a group of $N$ friends (e.g. 15) and everyone wants to hang out with everyone else, what's the fewest number of meet-ups we would need to accomplish this (with max 6 people in each)? This seems similar to the social golfer problem. Is it possible to come up with a general solution? (obviously not planning to go and do this in person, but I was thinking about this and couldn't come up with a solution)","['combinations', 'combinatorics', 'probability']"
3838068,"Find $f(t,w)$ such that $\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|$","Problem As part of a 2d Stokes flow fluid simulation I'm working on I'm trying to find a $f(t, w)$ such that $$\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|, \forall \theta \in [0, 2\pi)$$ where $w \in \mathbb{C}, |w| < 1$ and $\delta(t)$ is just a complex finite fourier series: $$\delta(t) = \sum_{n=-N}^N c_n e^{int}, c_n \in \mathbb{C}$$ Partial solutution If $\delta(t) = e^{it}$ I have that $$f(t, w) = \frac{1}{\pi} Re\Big(\frac{1}{1 - w e^{-it}}\Big)$$ to give some flavor of what $f(t,w)$ might look like (this value for $f(t,w)$ is not unique).  I'm trying to generalize this result to a wider class of $\delta(t)$ , ideally all finite Fourier series but maybe it's only possible for a certain class, I'm not sure. Possible approach? I thought maybe I could factor $\delta(t) - \delta(\theta)$ as $a e^{-iNt} \prod_{n=-N}^N (e^{it} - \alpha_n)$ .  Then the log term is linearly seperable: $$ \ln|a e^{iNt} \prod_{n=-N}^N (e^{it} - \alpha_n) | = \ln|a| + \sum_{n=-N}^N \ln|e^{it} - \alpha_n| $$ I can then split the integral into smaller, solvable pieces: $$\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = $$ $$\ln|a| \int_0^{2 \pi} f(t, w) dt + \sum_{n=-N}^N \int_0^{2 \pi} f(t, w) \ln|e^{it} - \alpha_n| dt$$ Assuming $|\alpha_n| = 1$ , (which is a big assumption!), I think I can use my solution for $\delta(t) = e^{it}$ and a little bit of linear algebra to build up a more complex solution.  But the $\theta$ term disappears in the factorization (I have to pick some arbitrary value of $\theta$ to even do the factorization).  Maybe that's okay?  My solution when $\delta(t) = e^{it}$ should hold for all $\theta$ so maybe picking a value for $\theta$ arbitrarily is okay?  It's unclear to me and I'm not sure how to justify or refute the idea. Any help would be appreciated.  Mostly I'm out of tools in my toolbox and I'm not sure if I'm on the right track or if this is even possible in principle.","['integration', 'complex-analysis', 'contour-integration', 'fluid-dynamics']"
3838096,How to find range of a function $f : \mathbb{R}^2\to \mathbb{R}^2 $,"How to find range of a function $f : \mathbb{R}^2\to \mathbb{R}^2 $ defined by $f(x,y)=(x^2-y^2, 2xy)$ I am new to calculus of several variables and I have no idea on how to solve such questions. I tried the following way: We set $f(x,y) = (x^2-y^2, 2xy) = (h,k)$ but it is getting very dirty solving for $x$ and $y$ from this. However, is this the correct method?","['multivariable-calculus', 'inverse-function-theorem', 'implicit-function-theorem']"
3838183,"Alternative approach for proving that for any $x\in\mathbb R^+$, $x^2+3x+\frac{1}{x} \ge \frac{15}{4}$.","Let $x \in \mathbb{R^+}$ . Prove that: $$x^2+3x+\frac{1}{x} \ge \frac{15}{4}.$$ While this is indeed easily proven using derivatives, where the minimum is obtained when $x=\frac{1}{2}$ , is it possible to prove it through other means, say by AM-GM? Any hints would be much appreciated.","['algebra-precalculus', 'a.m.-g.m.-inequality', 'inequality']"
3838188,Inner automorphism group as the kernel of a homomorphism,"Is there a homomorphism $\psi : \text{Aut}(G) \to \mathcal G$ with $\ker \psi = \text{Inn}(G)$ ? (Besides mapping each automorphism to its corresponding coset in $\text{Aut}(G) / \text{Inn}(G)$ .) Any group $G$ acts on itself via conjugation: $g * h = ghg^{-1}$ . So there is a corresponding homomorphism $\varphi : G \to \text{Sym}(G)$ defined by $\varphi(g) = (h \mapsto g*h)$ . The kernel of this action is clearly $Z(G)$ , so $Z(G) \trianglelefteq G$ . The image of $\varphi$ is clearly $\text{Inn}(G)$ , the set of all conjugation automorphisms of $G$ , so $\text{Inn}(G) \leq \text{Sym}(G)$ . By the first isomorphism theorem, $G / Z(G) \cong \text{Inn}(G)$ . It follows that $\text{Inn}(G) \leq \text{Aut}(G)$ . What we DON'T get from this argument is that $\text{Inn}(G)$ is normal in $\text{Aut}(G)$ . So far I've only seen proofs that analyze what happens when you conjugate an inner automorphism by an automorphism: Inner automorphisms form a normal subgroup of $\operatorname{Aut}(G)$ , Set of all inner automorphisms is a normal subgroup . But is there a homomorphism $\psi : \text{Aut}(G) \to \mathcal G$ (for some other group $\mathcal G$ ) with $\ker \psi = \text{Inn}(G)$ ? An obvious choice is the canonical map $\pi : \text{Aut}(G) \to \text{Aut}(G)/\text{Inn}(G) = \text{Out}(G)$ that maps each element to its corresponding coset. But its codomain will not be a group unless we first prove that $\text{Inn}(G) \trianglelefteq \text{Aut}(G)$ . EDIT: To be clear, I am not asking for any arbitrary proof that $\text{Inn}(G)$ is normal. I am looking for a homomorphism with kernel $\text{Inn}(G)$ besides the obvious one.","['group-homomorphism', 'group-theory', 'abstract-algebra', 'automorphism-group']"
3838201,Number of images formed by two plane mirrors formulae derivation.,"Derive: Number of images formed by two plane mirrors inclined at an angle of $\theta$ is given by $$\frac{360}{\theta} -1 $$ What I think: Inclined mirror forms images in the circle and one image lies in one sector. No of images = Number of sectors= $\frac{360}{\theta}$ And $1$ is subtracted from $\frac{360}{\theta}$ because a sector is occupied by the object. I think this is not a proper derivation. How to prove that
Inclined mirror forms images in the circle? I saw an answer but I didn't understand it. How to derive it formally? What's correct: Let $$n=\dfrac{360}{\theta}$$ where $\theta$ is the angle between the two mirrors If $n$ is even: $$\mathrm{Number\ of\ images}=n-1$$ If $n$ is odd and the object is placed symmetrically: $$\mathrm{Number\ of\ images}=n-1$$ If $n$ is odd and the object is not placed symmetrically: $$\mathrm{Number\ of\ images}=n$$ If $n$ is in decimal then only integral part is taken and above rules are followed. It should be noted that above the 'number of images' means the number of images formed. Experiment work: $\color{red}{\theta=30^\circ}$ Simulator: Plus corner: I don't think there exists a derivation to the above formulae. Maybe it was found by experiments. Note: A very tiny change in the angle can spilt the farthest image.","['physics', 'geometry']"
3838205,Finding the range of $f(x)=x+\frac{1}{x}$. How to take into account the discontinuity at $x=0$?,"The task is: Determine the range of values ​​of the function $$f(x)=x+\frac{1}{x}$$ I did this: $   y=f(x)=x+\frac{1}{x}\\y=\frac{x^2+1}{x}\;/\cdot x\\x^2-xy+1=0\\D=b^2-4ac\ge0\\y^2-4\ge0\Longrightarrow y\le -2\; \vee \; y\ge 2
   $ Question : It is not clear to me how nowhere did we take into account that for $x = 0$ the function is not defined, ie. how are we sure that the codomain of a given function will be equal to those values ​​of $y$ − a for which the solutions of the quadratic equation $x^2−xy+1 = 0 $ are real? Is there any reason why this is so? No other approach to the task (other than this template) is known to me. I would really like to know another way (which is not based on a template) of approaching this type of task. Thanks in advance !","['algebra-precalculus', 'functions']"
3838237,Find the interval of monotonicity for $f(x)=\frac{1}{4x^3-9x^2+6x}$,"Let $g(x)=4x^3-9x^2+6x$ $$g’(x)=6(2x-1)(x-1)$$ So $g(x)$ is strictly increasing in $(-\infty, -\frac 12)\cup (1,\infty)$ and strictly decreasing in $(\frac 12 , 1)$ So $f(x)$ is decreasing where $g(x)$ is increasing and vice versa. But the answer says $f(x)$ is decreasing in $(0,\frac 12)\cup (1,\infty)$ instead of $(-\infty, \frac 12)\cup (1,\infty)$ I realise that $f(x)$ is discontinuous at $x=0$ , but technically the function is still decreasing. What is the right answer?","['proof-explanation', 'proof-writing', 'analysis', 'functions', 'derivatives']"
3838280,Finding a summation form of this sum - and its value,"I was just thinking about this sequence: $$ 1, 2^{-1}, 3^{ - (1 + 2^{-1})}, 4^{-(1 + 2^{-1}+3^{ - (1 + 2^{-1})})} , \dots$$ The previous element in the sum is of the form $$n^{- \sum \text{previous elements}}$$ Because of this, I think this is the right way of writing it: $$a_1 = 1, ~~ a_2 = 2^{-1}, ~~ $$ $$ a_n = n^{-\sum_{k=1}^{n-1}a_k}$$ I was wondering - is there a way of finding the sum itself? $$\sum_{n=1}^{\infty} a_n$$ it seems very difficult and even impossible! On the other hand, my knowledge on sums is very minor, I don't know even how to begin with calculating this! My Python program showed this converges to about: $$ \approx 2.045290822396635$$","['calculus', 'recurrence-relations', 'sequences-and-series']"
3838311,Incompatible charts on a complex manifold,"Consider the following subset of $\mathbb{R}^2$ . $$U=\{(x,y):x,y \in \mathbb{R}, x>0\}$$ We can make this into a 1-dimensional complex manifold by giving it a global chart on to the open set of complex numbers with positive real part. $$V=\{z \in \mathbb{C}:Re(z)>0\}$$ Consider the following two identifications, $\phi,\phi^{\prime}$ : $$1)\phi(x,y)=x+iy$$ $$2)\phi^{\prime}(x,y)=x+i\frac{y}{a}$$ where $a$ is any non-zero number. In general these two charts aren't holomorphically compatible, so they define two different complex manifolds. I have a hard time wrapping my head around this, what exactly is the difference between the two complex manifolds. I am thinking that they should be very similar since the charts are compatible when you consider them as smooth manifolds. Is there any good example where two incompatible charts give bizarrely different complex manifolds?","['complex-geometry', 'smooth-manifolds', 'complex-analysis', 'complex-manifolds', 'differential-geometry']"
3838343,On a reversed Cauchy-Schwarz inequality for an indefinite quadratic form,"Let $f$ be a quadratic form over $\mathbb{R}$ and write $$f(x)=xAx^t,$$ where $A\in M_n(\mathbb{R_{+}})$ is symmetric with positive entries and $x=(x_1,x_2,\ldots,x_n)$ . Suppose that $A$ has exactly one positive eigenvalue and $n-1$ negative eigenvalues. IS IT TRUE that for any $0\neq u\in \mathbb{R}_{\geq 0}^n$ and $v\in \mathbb{R}^n$ that is not parallel to $u$ , $$(u^tAv)^2>(u^tAu)(v^tAv).$$ I tried to find proof of this result but failed. Anyone can help me or provide some references?
Thanks a lot!","['matrices', 'linear-algebra', 'symmetric-matrices', 'quadratic-forms']"
3838348,Expectation of Reciprocal of Average of Variables.,"I'm considering such a question: Suppose that there are $n$ i.i.d. variables denoted as $X_1,\cdots,X_n$ , and a sequence is defined as: $a_n=\mathbb{E}\left (\frac{n}{\sum_{i=1}^NX_i}\right)$ . It's easy to know that $a_n=\mathbb{E}\left(\frac{n}{\sum_{i=1}^NX_i}\right){\geq}\frac{1}{\mathbb{E}\left (\sum_{i=1}^nX_i/n\right)}=\frac{1}{\mathbb{E}(X)}$ , and the limitation of $a_n$ may be $\lim_{n\to\infty}a_n=\mathbb{E}\left (\lim_{n\to\infty}\frac{1}{\frac{\sum_{i=1}^nX_i}{n}}\right)=\mathbb{E}\left(\frac{1}{\mathbb{E}(X)}\right)=\frac{1}{\mathbb{E}(X)}$ . The question is: what is the convergence speed of $a_n\to\frac{1}{\mathbb{E}(X)}$ ? According to simulation, the convergence speed seems like $\mathscr{O}(\frac{1}{n})$ , but I wonder why. Notes: May be here means I'm not sure whether the order of expectation and limitation can be exchanged here. It seems like correct through simulation results.","['expected-value', 'limits', 'law-of-large-numbers', 'probability-theory']"
3838364,What kinds of spaces can be made with CW complexes?,"Coming from a background of mostly algebra and geometry, I am curious to learn what kinds of spaces one can build using CW complexes. To put it bluntly, my question is: Which ""geometric"" category is the largest one can build (all/some/most of) the topological spaces of using CW complexes? The Wikipedia page lists several examples here , however a wider perspective on the landscape of possibilities would be nice. It seems clear that not all topological spaces are CW complexes: requiring that the space be Hausdorff eliminates many ""pathological"" examples (e.g. the Hawaiian earring ), but also many spaces of interest (e.g. spaces with Zariski topology). On the positive side, polyhedra are , and most nice manifolds are (homotopy equivalent to) CW complexes ( see  here ). Moreover, as per the Wikipedia page, real and complex algebraic varieties (using their Euclidean topologies I suppose) are CW complexes. I am also suspecting that the kinds of stratified spaces studied in Intersection Homology ( topological pseudomanifolds? ) are good candidates. Perhaps my geometric view is also too constrained, any kinds of CW spaces that arise in analysis are also welcome.","['geometry', 'cw-complexes', 'general-topology', 'soft-question', 'algebraic-topology']"
3838431,Why the pdf always exists in statistics textbooks?,"I just jumped into statistics, but what confuses me is that all textbooks seem to assume existence of the probability densify function (pdf) of a R.V.? For instance, at the beginning, they say there is a dominating measure (Lebesgue measure or counting measure, depending on continuous or discrete cases), and a probability measure. Then they implicitly use the Radon-Nikodym theorem to write the pdf as the R-N derivative. From real analysis, I know the condition that R-N theorem holds is that the probability measure must be absolutely continuous w.r.t. the dominating measure. But those textbooks do not discuss it. So my question is why we can use the R-N theorem while no discussion of absolute continuity between the two measures? Is there some point I missed? Thanks!","['statistics', 'real-analysis', 'probability-theory', 'probability', 'random-variables']"
3838494,$\sum_{i=0}^k \lfloor\sqrt{ip} \rfloor = \frac{(p^2-1)}{12}$ where p is a prime and $p=4k+1$,Question: Let p be a prime number of the form 4k+1. Show that $\sum_{i=0}^k \lfloor\sqrt{ip} \rfloor = \frac{(p^2-1)}{12}$ Source: I came across this question while solving An Introduction to the Theory of Numbers by Niven et al as a part of my reading project. Question number 24 from section 3.2 (Quadratic Reciprocity) My attempt: I converted the problem into an equivalent problem of proving that the following identity holds: $\sum_{i=0}^{2k} \lfloor \frac{i^2}{p} \rfloor = \frac{(p-1)^2}{8}-\frac{(p^2-1)}{12}$ The motivation for this was that it is easier to evaluate a sum that involves square as compared to the one involving square root. Now I am stuck and don't know how to proceed. Thanks in advance.,"['ceiling-and-floor-functions', 'number-theory', 'elementary-number-theory', 'quadratic-residues', 'prime-numbers']"
3838501,How prove this limit via epsilon delta?,"$$\lim_{(x,y) \to (4,1)}{\frac{y}{2x-y}}=\frac{1}{7}$$ I know so far that $|x-4|<\delta\quad \&\quad |y-1|<\delta$ , and that I can use $$\bigg|\frac{y-1}{2x-y} + \frac{1}{2x-y} - \frac{1}{7}\bigg|$$ and I get one delta, but how to continue from here, or is it even correct?",['multivariable-calculus']
3838503,Proving a criterion for recognizing when a group $G$ is a semidirect product of 2 groups,"Here is the question I want to prove: For groups $G,H,K,$ show that the following conditions are equivalent. $G \cong K \rtimes_{\varphi} H.$ where $\varphi : H \rightarrow Aut(K).$ There exists a right-split short exact sequence: $1 \rightarrow K \rightarrow G \rightarrow H \rightarrow 1.$ $H \subset G, K \triangleleft G, G = HK $ and $H \cap K = \{1\}.$ My questions are: 1-Is there any textbooks contains the proof of $1 \Leftrightarrow 3.$ ? 2- Can anyone help me in proving $1 \Rightarrow 2$ ? 3- Can anyone help me in proving $2 \Rightarrow 3$ ?","['group-theory', 'semidirect-product', 'exact-sequence', 'reference-request']"
3838555,Non-homogeneous linear differential equation with all coefficients equal to $1$,"Consider continous function $f: X \rightarrow \mathbb{R}$ , where $X$ is an open subset of $\mathbb{R}$ Solve the following equation: $$y+y^{(r)}+y^{(2r)}+...+y^{(r(k-1))}=f(x)$$ Where $y=y(x)$ , $k,r$ are some natural numbers and $y^{(r)}$ denotes $r$ -th derivative of $y$ Here is my attempt: Firstly i consider homogeneous version of this equation: $$y+y^{(r)}+y^{(2r)}+...+y^{(r(k-1))}=0$$ Secondly i associate a characteristic polynomial: $$P(T):=1+T^{r}+T^{2r}+...+T^{(k-1)r}$$ (I notice that this polynomial has exactly $(k-1)r$ distinct roots) Then the general solution to my original equation schould be in the form $$y(x)=\sum_{\alpha_: P(\alpha)=0}C(\alpha, x)e^{\alpha x}$$ Now it is sufficient to calculate all the $C(\alpha, x)$ by substituting $y(x)$ into my equation. However i find this difficult. Thank you in advance",['ordinary-differential-equations']
3838602,"Show that if $\langle Tx,x\rangle \geq 2\left\| x \right\|^2$, then $T$ has dense image","Exercise: Let $H$ be an inner product space and $T:H \to H$ be a linear operator, such that: $$\langle Tx,x\rangle \geq 2\left\| x \right\|^2, \quad \forall x \in H.$$ Show that $T$ has dense image. Discussion: My initial thought was working with the given condition in order to construct an expression, such as for all $x \in H$ and $\varepsilon >0$ , $y \in H$ it holds: $\left\| Tx - Ty \right\| < \varepsilon$ . Then the image space spanned by the operator would be dense. I tried working around with Cauchy Scwarz, yielding: $$\left\| Tx\right\|\left\|x\right\| \geq \left| \langle Tx, x\rangle \right| \geq 2\left\|x\right\|^2 \implies \left\|Tx\right\| \geq 2\left\|x\right\|, \quad \forall x \in H.$$ Then, since $T$ is linear, let $x:= x-y \in H$ and: $$\left\|Tx - Ty\right\| \geq 2 \left\|x-y\right\|$$ By the Triangle Inequality, we can write: $$\left\|Tx \right\| + \left\|Ty\right\| \geq\left\| Tx - Ty\right\| \geq 2\left\|x-y\right\|$$ I don't know if that helps though. I know that by the condition given, we can easily show that the operator is $""1-1""$ - not sure if that can help though. Any hints or help will be appreciated!","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
3838652,"An inner product on $\mathcal{C}[a,b]$","I've to prove that the functional $$\langle f,g\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{g(t)}dsdt$$ is an inner product on $\mathcal{C}[a,b]$ (complex continuous functions). I've already made a similar exercise where I shown that $$\int_{a}^{b} f(t) \overline{g(t)} dt$$ is an inner product. And most of the properties follow the same reason. But I can't see how $$\langle f,f\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{f(t)}dsdt = 0 \iff f \equiv 0.$$ The implication $f=0 \Longrightarrow \langle f,f\rangle=0$ is clear from of the definition of the functional, but since $\frac{\sin(\pi(t-s))}{\pi (t-s)} = 0$ for $\pi(t-s) = n\pi$ I can't get the other implication. Same with $\langle f,f\rangle \geq 0.$","['inner-products', 'functional-analysis']"
3838666,A group $G$ has a finite number of subgroups if and only if $G$ is finite.,"I found this as an exercise, and wrote my own solution but am interested in a shorter/easier one. So here it goes: Statement: $G$ is a group $G$ has a finite number of subgroups <=> $G$ is finite. Proof: Suppose $G$ has an infinite number of elements but a finite number of subgroups. Let's look at the cyclic subgroups of $x$ where $x \in G$ . $A_G=\{\langle x\rangle : x \in G\}$ Since the elements of $A_g$ are subgroups of $G$ => $A_G$ has a finite number of elements. Obviously $\cup_{A \in A_G}{A} = G$ .(since every $x \in G$ would belong to $\langle x\rangle$ which is in $A_G$ . So it's a given that for some $x \in G$ , $\langle x\rangle$ must have an infinite number of elements. But then we can make infinitely many subgroups of $\langle x\rangle$ like: $\langle x^2\rangle$ , $\langle x^3\rangle$ , $\langle x^4\rangle$ ,etc.(which are all different, but to convince oneself, we can only look at $\langle x^p\rangle$ where p is prime.) Hence G has an infinite amount of subgroups which is a contradiction,
so G has to be finite. Now in the opposite direction: Suppose G is finite. Let $|G|=n$ . $P(G)$ (the powerset of G) will have only $2^n$ elements.
But the set of subgroups of G is a subset of $P(G)$ . Hence G has a finite number of subgroups.","['group-theory', 'abstract-algebra', 'finite-groups', 'solution-verification']"
3838707,Subset of a set of sets,"This may be a silly question to ask, but I am a bit confused on this.
Say we have a set $A=\{a,b,\{\{c,d\},e\}\}$ . Then, is $\{c,d\}$ a subset of $A$ ? Thank you,",['elementary-set-theory']
3838845,"If $a^2x^4+b^2y^4=c^6$, then the maximum value of $xy$","Simply subsisting the value of $y$ in $xy$ will not work, but I don’t know any other method to solve it. Can I get a hint?","['maxima-minima', 'derivatives', 'absolute-value', 'a.m.-g.m.-inequality']"
3838939,Motivation for the standard symplectic space,"I'm aware that for the vector space $V\oplus V^*$ that the product between $(v,\phi)$ and $(w,\psi)$ is given by $\psi(v)-\phi(v)$ . What I'm struggling to see is why a person might want to define a product this way, other than to give an example of a symplectic product. Is there a particularly nice geometric or physics interpretation?","['symplectic-geometry', 'symplectic-linear-algebra', 'differential-geometry']"
3838943,Derivative of Blaschke product,"Let $z_n$ be a Blaschke sequence in $\mathbb{D}$ and let $B$ be the Blaschke product defined by $$B(z)=z^m\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz}$$ I'm trying to show the following relationship is true for any $n$ . $$(1-|z_n|^2)|B'(z_n)|=\prod_{m=1,m\neq n}^{\infty}\left|\frac{z_n-z_m}{1-\bar{z}_n z_m}\right|$$ By simply taking the derivative of the product, we have $$B'(z)	=mz^{m-1}\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz}+z^m\prod_{n=1}^{\infty}\frac{|z_{n}|}{z_{n}}\frac{(\bar{z}_{n}z-1)+(z_{n}-z)\bar{z}_{n}}{(1-\bar{z}_{n}z)^{2}}$$ But I'm having trouble seeing how the right hand side of the equation can be derived from here.","['complex-analysis', 'blaschke-products']"
3838951,A Strange but seemingly easy functional equation problem,I was solving a much larger problem and hence reduced it to a functional equation which looks a little strange but also seems easy to solve. Question : Find all differentiable functions f defined on entire reals and differentiable on reals such that is satisfies the following $$ f(2n) -f(-2n) = f'(2n) - f'(-2n) +4n^2 $$ for natural numbers n. I need some help to solve this out so if anyone can help it will be appreciated and helpful.,"['functional-equations', 'derivatives', 'real-analysis']"
3838974,Is there meaning in the minimal instances of a variable you need to write a rational expression?,"This is something I've never thought about before. Given a rational function $f \in \mathbf{k}(x)$ , the minimum number of $x$ you need to write down a formula for $f$ on its domain is well-defined. My cute example is that the rational function $$f(x) = \frac{x}{x+1} \;\;=\;\;1-\frac{1}{x+1}$$ only needs one $x$ to be expressed, which means here that $f$ is invertible on its domain: there exists an $f^{-1}$ with range equal to the entire domain of $f$ . But is this interesting? Like, can we say something general relating the minimal number of $x$ s needed to express $f$ and the number of sections of $f$ ?","['algebra-precalculus', 'algebraic-geometry', 'rational-functions']"
3838976,Is it possible to solve exponential equation analytically?,"I'm trying to solve the following equation: $$e^{3x}-e^{2x}\left(e^2-\frac{1}{e^4}\right)-1=0$$ I know the solution is 2, as the equation above is simply a rearranged version of this initial statement: $$e^{x}-\frac{1}{e^{2x}}=e^2-\frac{1}{e^4}$$ I assumed I could forge a cubic by letting $x=e^b$ and then using the cubic formula to do so, but I get into a hideous mess with terms being ""trapped"" inside cube roots and nothing really falls together nicely. My question is, how would one go about solving this equation analytically (if it's at all possible)?","['cubics', 'algebra-precalculus', 'exponential-function']"
3839006,Solution differential equation $\frac{d^2x}{dt^2}=ax+bx^3$,"I'm trying to solve the following differential equation: $$\frac{d^2x}{dt^2}=ax+bx^3$$ I tried the following: $$\frac{d^2x}{ax+bx^3}=dt^2$$ But I'm not sure how to continue. Can I use $d^2x$ the same as $dx^2$ and use partial fraction decomposition to work out the left side of the equation? Like this: $$
\begin{split}
\iint{\frac{1}{ax+bx^3}d^2x}&=\iint{dt^2}\\
\frac{1}{b}\iint{\frac{A}{x}+\frac{B}{x+\sqrt{\frac{a}{b}}}+\frac{C}{x-\sqrt{\frac{a}{b}}}d^2x} &= \frac{t^2}{2}+c_1t+c_2
\end{split}
$$ But am I using $d^2x$ correctly here? If not, how can I solve this equation?",['ordinary-differential-equations']
3839074,What is the opposite of a null set?,"In probability theory (and in measure theory), a null set is a set with measure $0$ . Is there a term for the opposite of this, ie. a set whose complement is a null set, or (equivalently, if we restrict ourselves to a probability space) a set with measure $1$ ? Events with probability $1$ can be described as ""almost certain,"" ""almost sure,"" etc., but I'm looking for a word to describe the set itself. Would something like ""full set"" be a suitable phrasing? Or is there already a convention for this?","['measure-theory', 'probability-theory', 'probability', 'terminology']"
3839080,How do these two solutions of $\frac{dn}{dt}=rn(t)+m$ correspond/relate to each other?,"I attempted to solve the following first-order linear ODE: $$ \frac{dn}{dt} = rn(t)+m $$ This is what I managed to come up with: \begin{align}
\int \frac{1}{rn(t)+m}dn & = \int 1dt \\
\frac{\ln(rn(t)+m)}{r} & = t+C \\
rn(t)+m & = e^{r(t+C)}\\
rn(t)+m & = e^{rt}e^{rC}
\end{align} $$ rn(0)+m = e^{rC} $$ \begin{align}
rn(t)+m & = e^{rt}(rn(0)+m) \\
n(t) & = \frac{e^{rt}rn(0)+e^{rt}m-m}{r} \\
n(t) & = \frac{e^{rt}rn(0)+(e^{rt}-1)m}{r} \\
n(t) & = e^{rt}n(0)-\frac{m}{r}(1-e^{rt})
\end{align} This solution should be correct based on the book where I got the ODE from. (Otto, S.P.; Day, T., 2007. A Biologist's Guide to Mathematical Modeling in Ecology and Evolution. Princeton University Press. (p. 200.: Recipe 6.3)) My purpose was to work the solution out by a separation of variables by myself. But when I give $\frac{dn}{dt}=rn(t)+m$ to WolframAlpha, its solution is the following: $$ n(t) = c_1e^{rt}-\frac{m}{r} $$ Where does this come from? And how do these two solutions correspond/relate to each other? I've tried but could not work it out.",['ordinary-differential-equations']
3839082,Taylor expansion of a function defined by a sum.,"I'm looking at a complex function defined as $$f(z) = \sum\limits_{r=1}^\infty (-1)^{r+1}\sin\left(\frac{pz}{r}\right)$$ and am looking to find its Taylor expansion about $z=0$ . Presumably $p$ is some real number. My instinct is to Taylor expand $\sin$ about $z=0$ , then combine the sums. The only issue is that I have no idea how to combine sums nicely. Is this a decent approach, or is there a better way?","['complex-analysis', 'taylor-expansion', 'laurent-series', 'real-analysis']"
3839128,Using Fermat's Little Theorem with a complicated polynomial exponent,"I am to prove that if: $p$ and $q$ , two distinct odd primes $N = pq$ $a$ is an integer such that $gcd(a,N)=1$ Then... $a^{(p-1)(q-1)+1} ≡ a(mod N) $ My idea was to use Fermat's little theorem to somehow break down the exponent but I was at a roadblock because how do we use Fermat with something like $a^{N - p - q +2} ≡ a(mod N) $ My second idea was to say that b/c of what we're given we can say that $(p-1)(q-1)+1≡ 1(mod (p-1)(q-1))$ but I wasn't sure what to do with that either. Would appreciate a hint or two!","['chinese-remainder-theorem', 'discrete-mathematics']"
3839170,Check Whether a 2D Plane Intersects a Hypercube,"I'd like to quickly check whether a 2D plane intersects a $N$ -dimensional hypercube. In my case, the hypercube is $[0,1]^N$ , and the plane is described by an offset point $\mathbf r$ and two vectors $\mathbf u$ and $\mathbf v$ . $$\mathbf r = \mathbf r_0 + s \mathbf u + t \mathbf v$$ I'm not interested in constructing the intersection or identifying any of its properties, only determining whether it exists. I didn't find an answer in these related questions: This question concerns the intersection of a random subspace centered on the origin with a hypercube. My application involves a specified plane that may not intersect the origin. These questions 1 , 2 concern properties of the intersection, but do not touch upon fast methods for testing whether the intersection is nonempty. This question concerns checking if a line intersects a hypercube, but I wasn't quite sure how to generalize it for checking if a plane intersects a hypercube. Edit: I've removed a more extended example discussing a possible answer which has since been deleted. The current answer rightly suggests to use Linear Programming. However, I'd hoped that there was a more direct solution based on the geometry of the problem, something vaguely akin to this approach for testing whether a point lies inside a triangle.",['geometry']
3839219,Maximal Ergodic Theorem for flows?,"This is Petersen 2.2.1. Let $\{T(t,x)\}_{t \in \mathbb{R}}$ be a family of one-parameter invertible measure preserving transformations on $(X, \mathcal{M}, \mu)$ a measure space. Let $f : X \rightarrow \mathbb{R}$ be an $L^1(\mu)$ function. The goal is to formulate and prove the Maximal Ergodic Theorem for flows. My idea is that this looks like the Hardy-Littlewood theorem, so try to just shove it into that. That is, let $$A_r(f)(x) = \frac{1}{|B(r,0)|} \int_{B(r,0)} f(T(s,x)) d\lambda(s),$$ and let $$f^*(x) = \sup_{r > 0} A_r(f)(x).$$ Then the formulation would be $$ \int_{\{f^* > 0\}} f d\mu \geq 0,$$ and the proof would be something like the Hardy-Littlewood theorem (except now you're going to have to use the invertible measure preserving transformation to move between $\mathbb{R}$ and $X$ so that you can use the Vitali covering lemma). Is this a reasonable formulation/idea? It also asks for the Pointwise Ergodic theorem, but if my hunch is correct for the above then I'm pretty sure this is going to be something like the Lebesgue differentiation theorem. Based on the discussion in Ergodic Theorem and flow I have a feeling this might not be the correct approach, but I am still curious.","['measure-theory', 'ergodic-theory', 'dynamical-systems']"
3839222,How to check if a distribution is subgaussian using a finite sample?,"Let $X_1, X_2... X_n$ be a iid sample of size $n$ from some distribution. How can I check if the distribution of these $X_i$ is subgaussian? Is there some statistical test I can apply? My thought is that a distribution is subgaussian if it's tails are bounded by some gaussian, but in practice I can always find some gaussian distribution whose tails dominate those of my finite sample of size $n$ .","['statistics', 'probability', 'hypothesis-testing']"
3839276,Solving first order ODE: $(4x+3y^2)+(2xy)\frac{dy}{dx}=0$,"Solve this ODE: $$(4x+3y^2)+(2xy)\frac{dy}{dx}=0.$$ I am having trouble doing this ODE.
I tried using separable of variables and integrating factor and I am having no luck. $$\frac{dy}{dx}= -\frac{2}{y}-\frac{3y}{2x}$$",['ordinary-differential-equations']
3839311,"Convergence of $\sum_{n}\frac{q_n}{n}$, where $(q_n)$ enumerates $\mathbb{Q}\cap[0,1]$?","This problem is from a book reviewed Sep. 2020 Notices of AMS. Rational numbers in $[0,1]$ are countable.  Can they be ordered as $(q_n)_n$ so that $\sum_{n=1}^\infty \frac{q_n}{n}$ converges? My belief is no, since half the rationals are in the upper half of the interval, the tail of the sum will always have half of its terms $\gt \frac{1}{2n}$ implying divergence.  I am having difficulty in making this rigorous.","['rational-numbers', 'sequences-and-series']"
3839323,Does finding an inverse function prove it's bijective?,Let's assume we have a function $f: \mathbb{R} \rightarrow \mathbb{R}$ given by $f(x) = x^5$ . Then the inverse function would be $f^{-1}=\sqrt[5]{x}$ and $f^{-1} \circ f = f \circ f^{-1} = e$ is the identity  function. Does finding this inverse function suffice to prove that $f$ is bijective or do we need to prove injectivity and surjectivity for $f$ seperately?,"['elementary-set-theory', 'functions', 'inverse-function']"
3839329,"Let $X,Y\not=\emptyset$ and $\phi : X\mapsto Y$ an injective function. Find a function $\Phi: 2^X\mapsto 2^Y$ injective","Let $X,Y\not=\emptyset$ and $\phi : X\mapsto Y$ an injective function. Find a function $\Phi: 2^X\mapsto 2^Y$ injective I'm lost in this proof. I know that if $\phi$ is injective then $|X|\leq |Y|$ , so that we can give the $\Phi$ injective function. But I don't see how to build that function",['elementary-set-theory']
3839330,Geometric probability: line segment intersecting a circle?,"I'm interested in formulating a $2\text{D}$ geometric probability. Given: $(1)$ a circle of radius $r < \frac{1}{2}$ with origin $O$ at the center of a unit square $(2)$ two points $\{A,B\}$ chosen at random on the perimeter of the square* (*To avoid falling prey to the Bertrand paradox, here's the exact way the points are picked . Importantly, this process does not avoid segments on the perimeter, itself.) What is the probability that the line segment connecting the points also intersects the circle? From what I've considered so far the perpendicular bisector of $\angle AOB$ provides a good test of intersection... but the task of integrating binarized results is daunting. I've also considered trying to solve this problem by some kind of polar projection, after which the circle would form a bounding line.","['geometric-probability', 'circles', 'geometry', 'probability']"
3839334,$10$ people and $2$ of them are traitors,"Let's suppose you are playing a game similiar to “Among Us”. There are $10$ players and $2$ of them are impostor/traitors. Normally, they would kill people secretly stab people, convince, manipulate, lie and etc. to win the game but lets spice things up and suppose that all players decide to eliminite one person at a time and no one leaves the election room! These are the rules. $-$ No killing between rounds other than elections. $-$ They can't vote two people at the same round, one at a time! $-$ Vote priority is determined by number of persons seat. They vote by the numbers $(1,2,3,\dots).$ $-$ Seats are given randomly. Normally, this would be a fairly simple question if there was just one impostor/traitor. For a impostor to win the game, he must either be the last man standing or there must be just one innocent. That means he must sit on one of the green seats like this: Probability of an impostor/traitor win is $\frac{2}{10} = \frac{1}{5}$ (in percentage, $20\%$ ). But what if there were two impostors/traitors? By the way, for an impostor win, innocent players must be at least $n$ where $n$ is the number of impostors in the game. You may have noticed that I said this for a one impostor/traitor situation too. For example, if the $2$ impostors/traitors are in the $7$ and $8$ seats, game is over when the $6$ is out of the election because the only innocent players that are alive are $9$ and $10$ and we have $2$ impostors/traitors. So $n=2$ and voila! Impostor/traitors won. Question is: What is the probabilty for an impostor/traitor win where there are $2$ of them? Side note: I am new to this site so if there is something wrong with the question please let me know.",['probability']
3839362,The directional derivative is the Jacobian,"Let $ f:\mathbb{R}^m \rightarrow \mathbb{R}^n$ differentiable at $x$ and $v$ an unit vector in $\mathbb{R}^m$ . I've always used the formula that the directional derivative in $x$ by $v$ is simply the Jacobian times the $v$ . However, I could never figure it out how to prove it. $$\frac{\partial f}{\partial v}(x) = Df(x) v$$ In this question , the answer simply assumes that $$\lim_{t\to0}\frac{\bigl\lVert f(a+tv)-f(a)-Df(a)(tv)\bigr\rVert}{\lVert tv\rVert}=\lim_{t\to0}\frac{f(a+tv)-f(a)-tDf(a)(v)}t$$ But it apparently ignores the triangular inequality in the given norm. What am I not seeing here? How can I prove it?","['partial-derivative', 'jacobian', 'multivariable-calculus']"
3839364,"Corollary (1.6.2)(b) in ""Champs algébriques""","I believe this hasn't been asked on this platform, so here goes. Part (b) of Corollary (1.6.2) in Gérard Laumon and Laurent Moret-Bailly's text `Champs algébriques' states the following: Let $S$ be a scheme. Let $X \xrightarrow{f} Y \xrightarrow{g} Z$ be two morphisms of $S$ -spaces (i.e. sheaves of sets on the category of $S$ -schemes endowed with the étale topology). If $g \circ f$ is representable, then $f$ is representable in each of the following cases: the natural morphism $Y \times_Z Y \to Y \times_S Y$ is representable; the diagonal morphism $Z \to Z \times_S Z$ is representable; $g$ is a monomorphism. Its proof for case (1) proceeds as follows: Pick a $S$ -scheme $U$ and $y \in Y(U)$ : to show $X \times_Y U$ is representable, it suffices to consider the following cartesian diagram (reader will explicate the arrows): $\require{AMScd}$ \begin{CD}
X \times_Y U @>{}>> X \times_Z U\\
@VVV @VVV\\
Y \times_Z Y @>{}>> Y \times_S Y
\end{CD} The proof then deduces case (2) (resp. (3)) from case (1) as follows: Note $Y \times_Z Y \to Y \times_S Y$ is deduced by base change from the diagonal morphism $Z \to Z \times_S Z$ (resp. is an isomorphism). I have two main concerns: The above diagram does not look cartesian to me --- I only know the diagram is certainly cartesian if we replace the bottom row by the diagonal morphism $Y \xrightarrow{\Delta_g} Y \times_Z Y$ , and this other case (i.e. $\Delta_g$ is representable) is the only case in which I know the corollary to be true. Also, it seems like case (3) is true, but I don't understand the explanation: if $g$ is a monomorphism, I can only deduce that the diagonal morphism $Y \xrightarrow{\Delta_g} Y \times_Z Y$ is an isomorphism (whence representable, which implies case (3)), but I cannot see why $Y \times_Z Y \to Y \times_S Y$ is an isomorphism. Therefore, I'm asking if case (1) is true? If not, is case (2) true? Is the proof for case (3) correct? [Edit: I'm working on my own private translation of the text, so I would appreciate if someone can confirm/deny this for me.]","['algebraic-stacks', 'algebraic-geometry', 'schemes', 'category-theory']"
3839424,Derivative of inverse of matrix wrt itself in Einstein notation,"I'm struggling to work with Einstein notation to derive $\frac{dA^{-1}}{dA}$ . I.e. I understand given $A^{-1}A=I$ I can differentiate both sides to  get $\frac{d}{dA}A^{-1}A=0$ and apply product rule then rearrange to get $\frac{dA^{-1}}{dA} = -A^{-2}$ . The problem is deriving this in Einstein notation.  My indices end up all over the place. I.e. $\frac{d}{dA_{ij}}(A^{-1}_{kl}A_{lm}) = (\frac{d}{dA_{ij}}A^{-1}_{kl})A_{lm} + A^{-1}_{kl}(\frac{d}{dA_{ij}}A_{lm})= (\frac{d}{dA_{ij}}A^{-1}_{kl})A_{lm} + A^{-1}_{kl}(\delta_{il}\delta_{jm})$ $\iff \frac{d}{dA_{ij}}A^{-1}_{kl} = -A^{-1}_{ki}\delta_{jm}A^{-1}_{lm} = -A^{-1}_{ki}A^{-1}_{lj}$ ... a fourth-order tensor?!  Obviously I'm doing something wrong, any hints much appreciated.","['tensors', 'matrices', 'multivariable-calculus', 'calculus', 'index-notation']"
3839466,"Prove that $\frac{AB}{AE} + \frac{AD}{AG} = \frac{AC}{AF}$ in parallelogram $ABCD$, where $E$, $F$, $G$ are points on a line intersecting the sides","Let $ABCD$ be a parallelogram. A line meets segments $AB$ , $AC$ , $AD$ at points $E$ , $F$ , $G$ , respectively. Prove that $\frac{AB}{AE} + \frac{AD}{AG} = \frac{AC}{AF}$ . So recently I've been assigned a few problems, and this is one of them. So far, I've thought of extending line $EG$ and diagonal $BD$ to meet at a point, which we can call point $X$ and making point $O$ as the intersection of the diagonals in the paralellogram. And from here, I thought that maybe using Menelaus's theorem on triangle $BEX$ with line $AC$ , which gets us $\frac{BA}{AE} \cdot \frac{EF}{FX} \cdot \frac{XO}{OB} = 1$ . And similarly on triangle $DGX$ with line $AC$ , we would get $\frac{DA}{AG} \cdot \frac{GF}{FX} \cdot \frac{XD}{OD} = 1$ . But I'm not sure how to proceed from here and to relate these back to the original problems. Does anyone have any ideas on how I could do so?","['quadrilateral', 'euclidean-geometry', 'geometry', 'ratio']"
3839480,"Is my understanding of ""subshifts of finite type"" correct?","I am reading some lecture notes on Dynamical Systems, and I arrived at subshifts of finite type (ssft). The professor defines $\sum_n^+$ as the set of all one-sided sequences $.s_0s_1s_2...$ where for each $i$ , $s_i \in \{0, 1, 2, ..., n-1\}.$ Then, let $A$ be any $n \times n$ matrix whose entries are in $\{0, 1\}$ . Then the notes define the subshift of finite type corresponding to A as $$\{\underline{s} = s_0 s_1 s_2...|\forall i: A_{s_i, s_{i+1}} = 1\}$$ I would like to show an example to make sure I understood the definition clearly. Let $A$ be the matrix $$A = \begin{bmatrix}
1 & 1 & 0\\
0 & 1 & 1\\
1 & 1 & 0
\end{bmatrix}$$ I think we are supposed to label the rows as row 0, row 1, row 2, and the columns as col 0, col 1, col 2. N. We have $$1 = A_{00} = A_{01} = A_{11} = A_{12} = A_{20} = A_{21}$$ $$0 = A_{02} = A_{10} = A_{22}$$ Therefore the sequences in $\sum_A^+$ are exactly those whose size-2 blocks are on this list: $00, 01, 11, 12, 20, 21$ . So for example, an element of $\sum_A^+$ is $$.00011120000000...$$ But an element not in $\sum_A^+$ is $$.000020000.....$$ Is my understanding of ssft correct? Thank you so much!","['graph-theory', 'group-theory', 'dynamical-systems']"
3839581,Logical Equivalence for $p \lor q$,"I have to prove that $$p \vee q \equiv (p\wedge q) \vee (\neg p\wedge q) \vee (p\wedge \neg q)$$ Based on the truth table, they are equivalent, but I couldn't figure out how to use logic statements to prove they are equivalent. I have tried many ways but they all go weird. $(p\wedge q) \vee (\neg p\wedge q) \vee (p\wedge \neg q)$ $\equiv (p\wedge q) \vee ((\neg p\wedge q)\vee p) \wedge ((\neg p\wedge q)\vee \neg q)$ $\equiv (p\wedge q) \vee ((T \wedge (q\vee p)) \wedge (T\wedge \neg(p \wedge q))$ $\equiv (p\wedge q) \vee (q\vee p) \wedge \neg(p \wedge q)$ I couldn't figure out what I'm supposed to from this point. Did I do anything wrong?
Thanks","['boolean-algebra', 'propositional-calculus', 'logic', 'discrete-mathematics']"
3839619,"Proof that transpositions generate $S_n$, and proof that $\#(S_n) = n!$ (Lang's Algebra p. 13)","I am trying to unpack Lang's proofs and verify that I'm correctly filling in the details. Excerpt: My attempt: To prove that the transpositions generate $S_n$ , we proceed by induction on $n$ . When $n = 1$ we can use the identity map to generate $S_1$ . Assume the result is true for $S_{n - 1}$ . Consider $\sigma \in S_n$ and assume that $\sigma(n) = k \neq n$ , otherwise we could think of $\sigma$ as a product of transpositions in $S_{n - 1}$ and tack on $\tau (n) = n$ for all the transpositions. Take transposition $\tau \in S_n$ that interchanges $k$ and $n$ . Then $\tau \sigma$ leaves $n$ fixed and can therefore be written as $\tau \sigma = \tau_m \tau_{m - 1} \dots \tau_1$ where all the transpositions on the right-hand side are extensions of transpositions in $S_{n - 1}$ that leave $n$ fixed. Multiply by $\tau$ on the left to see that $\sigma = \tau \tau_m \tau_{m - 1} \dots \tau_1$ as desired. To prove that $\#(S_n) = n!$ we again use induction on $n$ . The base case is clear. Assume that $\# (S_{n - 1}) = (n - 1)!$ . The subgroup $H$ of $S_n$ that leaves $n$ fixed is isomorphic to $S_{n - 1}$ because the elements of $S_{n - 1}$ are the same as those of $H$ , except that they are restricted to $\{ 1, \dots n - 1 \}$ . The elements $\sigma_1, \dots, \sigma_n$ as described are coset representatives (of distinct cosets) of $H$ in $S_n$ . The argument $\sigma_i h_1 = \sigma_j h_2 \Rightarrow \sigma_i = \sigma_j h_2 h_1^{-1} \Rightarrow \sigma_i H = \sigma_j h_2 h_1^{-1} H \Rightarrow \sigma_i H = \sigma_j H$ shows that two such cosets are either disjoint or equal. Question: Unfortunately I cannot quite put my finger on why $\bigcup_{i = 1}^n \sigma_i H = S_n$ . If I consider $\sigma \in S_n$ such that $\sigma (n) = k$ , then I feel like I need to show that $\sigma \in \sigma_k H$ , but I don't see how to do this. Why is this ""immediately verified""? Once I've shown this, I see that Lagrange's theorem gets us $(S_n : 1) = n(n - 1)!$ as desired. I appreciate any help.","['permutations', 'group-theory', 'abstract-algebra', 'symmetric-groups']"
3839639,Suppose an abelian group has an element m of order 4 and an element n of order 3. Show that it must also have elements of order 2 and 6.,"I am trying to manipulate $m^4$ and $n^3$ by setting them both equal to the identity e. I thought that squaring both sides of n^3=e would result in n^6=e. Thus the element n has order 6. I made a similar argument with m^4=e, but instead square rooted both side to get m^2=e. Thus showing the element m has order of 2. As both elements are in G and both orders required 2 and 6 are shown, I thought that would show it. Outside of my current thought process I don't know where to go with the problem though. If someone could lead me in the right direction I would appreciate it.","['group-theory', 'abstract-algebra', 'abelian-groups']"
3839640,Putnam 2018 - Exercise A.5 - proof check,"The problem statement is as follows. Let $f:\Bbb R \to \Bbb R$ be an infinitely differentiable function satisfying $f(0) = 0$ and $f(1) = 1$ , and $f(x) \geq 0$ for all $x \in \Bbb R$ . Show that there exist a positive integer $n$ and a real number $x$ such that $f^{(n)}(x)< 0$ . My proof. Suppose $f^{(n)}(x) \geq 0$ for all $x\in \Bbb R$ , for all $n \in \Bbb Z^+$ . If there exists a $c < 0$ such that $f(c)>0$ , then the Mean Value Theorem would give a negative derivative at some point between $c$ and $0$ . So $f(x) = 0$ for $x \leq 0$ , and thus, since for all $n$ $$\lim_{x\to 0^-}f^{(n)}(x) = 0.$$ we must have $f^{(n)}(0) = 0$ . (So far it is all like in some of the ""official"" proofs.) By Taylor's Theorem (with ""starting point"" $0$ ) we have $$f(x) = \frac{f^{(n)}(\eta_n(x))}{n!}x^n,$$ for some $\eta_n(x) \in (0,x)$ . In particular $$f(1) = \frac{f^{(n)}(\eta_n(1))}{n!} = 1,$$ which implies that there is a point $\eta_n(1)\in (0,1)$ such that $f^{(n)}(\eta_n(1)) = n!$ . By monotonicity of $f^{(n)}(x)$ , therefore, we must have $$f^{(n)}(1) \geq n!.$$ Using again Taylor's Theorem (starting at $1$ , this time) yields $$f(x) = \sum_{k=0}^n \frac{f^{(k)}(1)}{k!}(x-1)^k+ \frac{f^{(n+1)}(\xi_n(x))}{(n+1)!}(x-1)^{n+1},$$ for some $\xi_n(x) \in (1,x)$ , and where $f^{(0)}(x) = f(x)$ .
This gives $$f(2) \geq n$$ for all $n\in \Bbb Z^+$ , a contradiction. Is my proof correct?","['solution-verification', 'taylor-expansion', 'real-analysis']"
3839657,Why is the flow generated by a smooth vector field smooth?,"Suppose $X$ is a smooth vector field on a smooth manifold $M$ . For any $p \in M$ , the theorems of existence and uniqueness to solutions of ODEs show that there is a unique differentiable function $\theta ^ {(p)} :J \to M$ , where $J$ is an open interval containing $0$ , such that $\theta ^ {(p)} (0) = p$ and $\frac{d}{dt}\theta ^ {(p)} (s)=X_{\theta^{(p)}(s)}$ . Then we can define a function $\theta$ on an appropriate subset of $M \times \mathbb{R}$ by $\theta(p,s)=\theta^{(p)}(s)$ . $\theta$ is the flow generated by $X$ . I am trying to understand why $\theta$ is smooth, and I don't even see why it has to be continuous. I thought of using the explicit construction from the proof of the existence theorem, but it seems to be quite involved so I wonder if there is a simpler way.","['vector-fields', 'smooth-manifolds', 'ordinary-differential-equations', 'differential-geometry']"
3839661,Is there a specific symbol for denoting a linear subspace like $\subseteq$ for denoting a subset?,"I was under the impression that this was a proper notation, but I was just corrected on this but did not get a proper explanation of what it should be. I get that it is definitely not the same, but what is the right symbol then? So I am specifically asking for a linear subspace. Or does this not make any difference?","['notation', 'linear-algebra']"
3839683,The escape radius of a polynomial and its filled Julia set,"I'm studying complex dynamics and I am struggling to verify the following facts. Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a complex-valued polynomial of degree $d\geq 2$ . That is, define $f(z)=a_dz^d+...+a_0$ . Take $R=\sup(1,\frac{1+|a_{d-1}+...+|a_0|}{|a_d|})$ . Show that $|f(z)|\geq |z|^d/R$ whenever $|z|>R$ ( $\star$ ). [I guess I need the reverse triangle inequality but I'm still lost] Now, we define the filled Julia set of $f$ to be the set $K_f$ such that under the iterations of $f^n(z)$ do not tend to $\infty$ as $n$ tends to $\infty$ . Thus the statement $(\star)$ shows that $K_f$ is compact. Now, we want to prove that $K_f$ is in fact $\bigcap_{n\in\mathbb{N}} f^{-n}(\overline{D}_R)$ (where $R$ is defined as above).","['complex-analysis', 'dynamical-systems']"
3839696,Van der Pol's identity for the sum of divisors and a quartic polynomial equation for odd perfect numbers,"In Touchard (1953) it is mentioned that the sum of divisors $\sigma(n)$ satisfies the following recurrence relation ( $n>1$ ): $$n^2(n-1) = \frac{6}{\sigma(n)} \sum_{k=1}^{n-1}(3n^2-10k^2)\sigma(k)\sigma(n-k)$$ Substituting in this equation an odd perfect number $n = \sigma(n)/2$ we find that it is a root of the quartic polynomial: $$
\begin{align}
f(x) &= x^4-x^3+12a_0x^2-60a_1x+60a_2 \\
&= (x^3+(n-1)x^2+(12a_0+n^2-n)x+12a_0n+n^3-n^2-60a_1)(x-n)
\end{align}
$$ where $$a_i = \sum_{k=1}^{\frac{n-1}{2}}k^i \sigma(k)\sigma(n-k),\text{ } i=0,1,2$$ We have: $$n^3(n-1) = 3 \sum_{k=1}^{n-1} (3n^2-10k^2)\sigma(k) \sigma(n-k)$$ and by symmetry of $\sigma(k)\sigma(n-k)$ in $k,n-k$ we get: $$= 3 \sum_{k=1}^{(n-1)/2} (6n^2-10k^2-10(n-k)^2)\sigma(k) \sigma(n-k)$$ which might be simplified to: $$=-12n^2a_0 -60a_2+60na_1$$ which proves that the odd perfect number $n$ is a root of the polynomial $f(x)$ above. However, computations with Sagemath (it takes a few seconds to do the computation) seem to suggest, that for an odd number $m$ , we have $$f(m) > 0, \text{for } m>1 \text{ odd}$$ This observation would maybe prove, that there are no odd perfect numbers. I am aware that $\sigma(k)\sigma(n-k)$ is kind of like a black box to handle, but it would be nice, if maybe for some special cases where $m$ is odd the last inequality could be proven. It might be noticed that it seems like for $n>1$ , odd the polynomial $f(x)$ is irreducible over the rational numbers. Here are the first polynomials: n, f(n,t), f(n,n)>0?
3 t^4 - t^3 + 36*t^2 - 180*t + 180 f(n,n)>0 ? True
5 t^4 - t^3 + 228*t^2 - 1860*t + 3300 f(n,n)>0 ? True
7 t^4 - t^3 + 696*t^2 - 7920*t + 20160 f(n,n)>0 ? True
9 t^4 - t^3 + 1548*t^2 - 22500*t + 72900 f(n,n)>0 ? True
11 t^4 - t^3 + 2940*t^2 - 51600*t + 204600 f(n,n)>0 ? True
13 t^4 - t^3 + 4956*t^2 - 102360*t + 478920 f(n,n)>0 ? True
15 t^4 - t^3 + 7752*t^2 - 185760*t + 1004400 f(n,n)>0 ? True
17 t^4 - t^3 + 11376*t^2 - 307620*t + 1900260 f(n,n)>0 ? True
19 t^4 - t^3 + 16020*t^2 - 481980*t + 3309420 f(n,n)>0 ? True
21 t^4 - t^3 + 22080*t^2 - 735120*t + 5559120 f(n,n)>0 ? True Is there a irreducibility criterion which might be applied to all ( $n=3,\ldots,21$ ) of these example polynomials? Thanks for your help! (Originally asked on MO: https://mathoverflow.net/questions/372476/van-der-pols-identity-for-the-sum-of-divisors-and-a-quartic-polynomial-equation ) Edit :
The odd perfect number is also a root of the polynomial: $$g(x) = x^4-x^3-9A_0x^2+30A_2$$ where $$A_i = \sum_{k=1}^{n-1}k^i \sigma(k)\sigma(n-k),i=0,2$$ But numerical computations suggest, that: $$\gcd(f(x),g(x))=1$$ which would lead to a contradiction. Can this last claim about the $\gcd$ be proven? An answer to the question :
It would be nice if someone can spot the error in this answer, otherwise it would follow that there are no odd perfect numbers...: Let $$A_i = \sum_{k=1}^{n-1} k^i \sigma(k)\sigma(n-k),\text{ } i=0,1,2,3$$ . Using the symmetry of $\sigma(k)\sigma(n-k)$ in $n,k$ for $A_i$ we get: $$A_0 = 2a_0$$ $$A_1 = na_0$$ $$A_2 = a_0n^2-2a_1n+2a_2$$ $$A_3 = n^3a_0-3n^2a_1+3na_2$$ On the other hand we can evaluate $A_i$ with Eisenstein series ( https://mathoverflow.net/questions/372766/is-there-a-similar-formula-like-ramanunjans-eisenstein-series-identity-for-su ): $$A_0 = \tfrac5{12}\sigma_3(n)-\tfrac12n\sigma(n)+\tfrac{\sigma(n)}{12} = \tfrac5{12}\sigma_3(n)-\tfrac12n \cdot 2n +\tfrac{2n}{12}$$ $$A_1 = \frac{5n}{24}\sigma_3(n) - \frac{6n^2-n}{24}\sigma(n) = \frac{5n}{24}\sigma_3(n) - \frac{6n^2-n}{24}2n$$ $$A_2 = \frac{n^2}{8}\sigma_3(n) - \frac{4n^3-n^2}{24}\sigma(n) = \frac{n^2}{8}\sigma_3(n) - \frac{4n^3-n^2}{24}2n$$ $$A_3 = \frac{n^3}{12}\sigma_3(n) - \frac{3n^4-n^3}{24}\sigma(n) = \frac{n^3}{12}\sigma_3(n) - \frac{3n^4-n^3}{24}2n$$ We can solve the set of equations in $a_i,A_i$ for $a_i$ and get: $$a_0 = 1/2 A_0$$ $$a_2=\frac{A_{2}-nA_1}{2} +na_1$$ We can further substitute for $A_i$ the last equations in $\sigma_3(n)$ and then substitute these $a_i$ in $f(x)$ . We get (here are the calculations done with Sagemath , I hope there is no bug in this): $$0 = f(n) = n^4 + 6A_0n^2 - n^3 + 30A_1n + 30A_2 $$ $$ = -5/2(12n^2 - 5\sigma_3(n) - 2n)n^2$$ Hence: $$0 = 12 \, n^{2} - 2 \, n - 5 \,  \sigma_{3}(n)$$ But $\sigma_3(n)>n^3+1$ and we get the contradiction for $n>1$ : $$5(n^3+1) < 5 \sigma_3(n)= 12n^2-2n < 5(n^3+1) $$","['conjectures', 'perfect-numbers', 'number-theory', 'solution-verification', 'inequality']"
3839732,elementary proof that sum of algebraic numbers is algebraic(Real Analysis and Foundations),"How can one prove that the sum of two algebraic numbers is an algebraic number without using theories of algebra? I don't know about (abstract) algebra. Actually, this is an exercise of an analysis book(Real Analysis and Foundations, 4th edition, Steven G.Krantz, p67 exercise 6), so there must be a way of solving this in a relatively simple manner. (Proof Verification) Prove that the sum of two algebraic numbers is algebraic. and Elementary proof for the theorem that field of algebraic numbers is closed use theories of algebra, How to prove that the sum and product of two algebraic numbers is algebraic? uses algebra and tensor product(which I don't know). What I know is calculus, linear algebra, and a little set theory and analysis.","['roots', 'polynomials', 'analysis', 'real-analysis']"
3839756,Holomorphic subbundle and second fundamental form,"Setup: Let $E\rightarrow X$ be a holomorphic Hermitian vector bundle and $S\hookrightarrow E$ a holomorphic subbundle. In Kobayashi's DIFFERENTIAL GEOMETRY OF COMPLEX VECTOR BUNDLES, in proposition 1.6.14 it says that the second fundamental form vanish if the complementary $S^{\perp}$ is holomorphic and the isomorphism $$E=S\oplus S^{\perp}$$ holomorphic. Now my question is, why is not it enough that $S^{\perp}$ is holomorphic? Is it possible that both $S$ and $S^{\perp}$ are holomorphic but the splitting is not? What can go wrong? In other words is there a situation where we cannot find a holomorphic retract to the map $S\rightarrow E$ ?","['complex-geometry', 'vector-bundles', 'holomorphic-bundles', 'differential-geometry']"
3839770,How to calculate 1 in _______ chance from a percentage?,"I am wondering, how do I ago about calculating 1 in chances from a percentage? Example: A 1 in 2 chance is 50% and 0.5 as a decimal. What I want to do: I have the value 0.1431 (14.3%) and want to convert that into a 1 in chance - any help is much appreciated, thanks.","['statistics', 'percentages', 'probability']"
3839814,Probability that $\text{det}(A)$ is an even number.,"I'm struggling to solve the following problem: If a matrix $A$ is chosen randomly in the set of all $2\times 2$ matrices with coefficients in $\mathbb{Z}$ , i.e. $A\in\text{Mat}_2(\mathbb{Z})$ , what is the probability that $\text{det}(A)$ is an even number? How can I solve this problem, why is the probability a finite number, even thought I'm dealing with an infinite set. Any help is appreciated.","['linear-algebra', 'probability']"
3839837,Cauchy sequence is not a topological notion,"Let $(E,d)$ be a metric space. A sequence $(u_n)_n\in E^\mathbb{N}$ converges to $l\in E$ if for all $\varepsilon >0$ , there exists $N\in \mathbb{N}$ such that $d(u_n,l)<\varepsilon$ .
I could also say that for any open subset $U$ , $l\in U \Rightarrow \exists N, u_n\in U, \forall n\ge N$ . I understand that this notion of convergence is topological in the sense it depends only on the topology of $E$ . A sequence $(u_n)_n\in E^\mathbb{N}$ is said to be a Cauchy sequence if for all $\varepsilon >0$ , there exists $N\in \mathbb{N}$ such that for all $p,q\ge N$ , $d(u_p,u_q)<\varepsilon$ .
Here I could say for any open subset $U$ , $0\in U \Rightarrow \exists N, u_n-u_p \in U, \forall n,p\ge N$ . Yet I do not understand why this notion of Cauchy sequence is not topological, that is we cannot define it onyl from the open sets of $E$ ? I am trying to understand this with the fact that a convergent Cauchy sequence may not be converging in $E$ . In that case, the limit could not be characterized with open sets of $E$ . That would be the reason ?","['cauchy-sequences', 'general-topology', 'convergence-divergence', 'metric-spaces']"
3839873,Determining whether a subset is a subspace,"The problems are as follows: Determine whether the following subsets of $\mathbb{R}^3$ are subspaces of $\mathbb{R}^3$ . $A = \{(u^2, v^2, w^2) \,|\, u, v, w \in \mathbb{R} \}$ , $B = \left\{(a, b, c) \,|\,
\begin{pmatrix}
a & b & c\\
1 & 2 & 0\\
0 & 1 & 2
\end{pmatrix} \text{is not invertible}\right\}$ , $C = \left\{(x, y, z) \,|\, \begin{pmatrix}
1 & 2 & 3\\
4 & 5 & 6\\
7 & 8 & 9
\end{pmatrix}
\begin{pmatrix}
x\\
y\\
z
\end{pmatrix} =
\begin{pmatrix}
2x\\
2y\\
2z
\end{pmatrix}\right\}$ . Here's what I've tried so far: $A$ is a subspace of $\mathbb{R}^3$ as it contains the $0$ vector (?). The matrix is not invertible, meaning that the determinant is equal to $0$ . With this in mind, computing the determinant of the matrix yields $4a - 2b + c = 0$ . The original subset can thus be represented as $B = \left\{\left(\frac{2s - t}{4}, s, t\right) \,|\, s, t \in \mathbb{R}\right\}$ ; i.e. $B = \text{span}\left\{(\frac{1}{2}, 1, 0), (-\frac{1}{4}, 0, 1)\right\}$ , a plane in $\mathbb{R}^3$ . Solving for the linear system, $$
\begin{aligned}
\begin{pmatrix}
1 & 2 & 3\\
4 & 5 & 6\\
7 & 8 & 9
\end{pmatrix}
\begin{pmatrix}
x\\
y\\
z
\end{pmatrix} &=
\begin{pmatrix}
2x\\
2y\\
2z
\end{pmatrix}\\
x
\begin{pmatrix}
1\\
4\\
7
\end{pmatrix}
+ y
\begin{pmatrix}
2\\
5\\
8
\end{pmatrix}
+ z
\begin{pmatrix}
3\\
6\\
9
\end{pmatrix}
&= 
\begin{pmatrix}
2x\\
2y\\
2z
\end{pmatrix}\\
x
\begin{pmatrix}
-1\\
4\\
7
\end{pmatrix}
+ y
\begin{pmatrix}
2\\
3\\
8
\end{pmatrix}
+ z
\begin{pmatrix}
3\\
6\\
7
\end{pmatrix}
&= 
\begin{pmatrix}
0\\
0\\
0
\end{pmatrix}
\end{aligned}$$ Converting to row echelon form gives the trivial solution $x = 0, y = 0, \text{ and } z = 0$ ; $C$ only contains the $0$ vector. Is my reasoning correct? Also, quite a bit of the computations have been omitted in this post for brevity. Regardless of this, are my answers well justified? Thank you.","['matrices', 'linear-algebra']"
3839956,Evaluating $\lim_{n\to\infty}\prod_{i=2}^{n}{\frac{i^k-1}{i^k+1}}$ for various values of $k$,"Let's consider the following function: $$
f(n, k) = \prod_{i = 2}^{n}{\frac{i^k - 1}{i^k + 1}}
$$ I'm interested in the limit of $f$ as $n$ approaches infinity for various values of $k$ . I managed to calculate the limit for $k = 1$ (it's $2$ ) and $k = 3$ (it's $2/3$ ). For other values of $k$ the limit seems to be irrational, but I only managed to approximate it with direct calculations. My question: How to find the limit analytically for other $k$ ? What's so special about $3$ and $1$ being rational limits?","['limits', 'products']"
3840013,Calculating length of circular arc,"I'm currently working through a step-by-step example which calculates the length of a circular arc $\gamma$ of radius $r$ subtended by angles $\theta_1$ and $\theta_2$ . The circular arc is parametrised as $\gamma (t) = c + re^{it}$ for $\theta_1 \leq t \leq \theta_2$ . To calculate the length, we need to work out the derivative, $\gamma'$ , which is $\gamma'(t)=rie^{it}$ . Then by the definition of length, we get $$L(\gamma) = \int_{\theta_2}^{\theta_1}|rie^{it}| dt$$ I understand everything up until this point, but then the solution goes onto simplifying the integral further, and I do not understand why this can be done. $$L(\gamma) = \int_{\theta_2}^{\theta_1}|rie^{it}| dt = r\int_{\theta_2}^{\theta_1}dt = r(\theta_2 - \theta_1)$$ Surely by integrating, you would get the following instead? $$L(\gamma) = \int_{\theta_2}^{\theta_1}|rie^{it}| dt = r\int_{\theta_2}^{\theta_1}|ie^{it}| dt = r(e^{i\theta_2} - e^{i\theta_1})$$ Any help showing where I've gone wrong would be much appreciated!","['complex-analysis', 'multivariable-calculus', 'arc-length']"
3840023,Minimizing the energy in a ruler,"I'm trying to find the shape a metal ruler takes when it is forced into certain specific boundary conditions. Introduction Imagine a long thin metal ruler, that is forced to bend around a number of nails that are nailed into a sheet of wood. The ruler will take on a certain shape to minimize its internal deformation energy. The smaller the radius of curvature along the length $l$ of the ruler, the more energy is needed to force it into that shape. If $\theta$ is the angle that the ruler makes with the horizontal, we want to minimize its change, i.e., we want to minimize $$E = \int_0^L \left|\frac{d\theta}{dl}\right| dl = \int_0^X \left|\frac{d\theta}{dx}\right| dx.$$ Using $g(x)$ to describe the path of the ruler, we see that $\theta(x) = \arctan(g'(x))$ . The change in the angle is therefore $$ \frac{d\theta}{dx} = \frac{1}{1+g'(x)^2} g''(x). $$ So: whatever the boundary conditions, we want to find the function $g(x)$ , so that $$E = \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx$$ is minimal. Now, without boundary conditions, this is trivial: due to the absolute value signs, the absolute minimum is $E=0$ , which is obtained when $g''(x)=0 \forall x\in[0,X]$ , i.e., when $g(x)$ is a straight line. Which is what's expected: the ruler is straight if there are no additional conditions it needs to fulfil. It becomes more interesting with boundary conditions. Boundary conditions The most natural boundary conditions, in line with how I initially presented the problem, is that there are several points $(a_i, y_i)$ , and the condition is that, for all $i$ , $$g(a_i) = y_i$$ This is an interesting problem, and already one I couldn't solve. For reasons I won't go into here (see this question if you're interested), the problem I'm actually trying to solve is one where there is a boundary condition on the integral of $g$ . There are several tuples $(a_i, b_i, y_i)$ , and the condition is that, for all $i$ , we have $$\int_{a_i}^{b_i} g(x) dx = y_i \cdot (b_i-a_i)$$ I have no idea how to go about this, and would be grateful for any tips. Many thanks! EDIT: Now, I'm not sure if it's actually helpful, but, solving the integral for E, we get $$ \begin{align} E &= \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx \\ 
&= \int_{I_+} \frac{1}{1+g'(x)^2} g''(x) dx + \int_{I_-} \frac{1}{1+g'(x)^2} (- g''(x)) dx \\
&= \left. \arctan(g'(x)) \right\vert_{I_+} - \left. \arctan(g'(x)) \right\vert_{I_-} \end{align} $$ With $I_+$ and $I_-$ the $x$ -intervals where $g''(x)$ is positive and negative, respectively. Because $I_+$ and $I_-$ form a continuous interval from $0$ to $X$ , we can also write this as $$
E = \arctan(g'(X)) - \arctan(g'(0)) - \left. 2 \arctan(g'(x)) \right\vert_{I_-}  
$$ Our goal is to find the function $g(x)$ that minimizes this expression while conforming to the boundary conditions.","['optimization', 'functional-analysis', 'mathematical-physics', 'calculus-of-variations']"
3840038,"Starting with $1,9,9,3$ the sequence continues as the last digit of the sum of preceding 4 terms. Will subsequence $7, 3, 6, 7$ ever appear in it?","Formally, $a_n = (a_{n-1} + a_{n-2} + a_{n-3} + a_{n-4})$ mod $10$ .
Is there a mathematical way of knowing whether $7, 3, 6, 7$ will ever occur in the sequence? One idea I was delving upon was to prove the sequence is analogous to a decimal expansion of an irrational number, that way any arbitrary four numbers would appear.","['elementary-number-theory', 'modular-arithmetic', 'sequences-and-series']"
3840042,Smoothly extending a metric from a manifold with boundary to an attached cylinder,"Let $M$ be a manifold with boundary $\partial M$ . Form the manifold $M'$ by attaching a half-infinite cylinder $\partial M\times[0,\infty)$ to $M$ along its boundary. In other words, $$M'=M\cup_{\partial M}\partial M\times[0,\infty),$$ where we identify $\partial M\sim\partial M\times\{0\}$ . Let $g$ be a Riemannian metric on $M$ . Question: Does there always exist a Riemannian metric $g'$ on $M'$ such that the restriction of $g'$ to $M$ is equal to $g$ ? Comment added later: Now that I think about it, perhaps the required property is built into the definition of smoothness of $g$ at the boundary, namely that it's extendible slightly beyond the boundary of the chart into some open neighborhood; one then uses a partition of unity to get a metric on all of $M'$ .","['riemannian-geometry', 'manifolds-with-boundary', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
3840084,Can there be maximal proper subcontinua?,"Let X be a compact connected Hausdorff space (a continuum). Say $C$ is a proper subcontinuum: a proper compact connected subspace of $X$ . Can $C$ be maximal? That is: is it possible that for all proper subcontinua $C \subset C' \subset X$ , we have that $C = C'$ ? What about under the stronger condition that $C \subset \text{int}(C')$ ? I can prove that if $C$ is maximal then every point outside of $C$ is a non-cut-point. And in every example I can think of there cannot be maximal proper subcontinua, so I think they don't exist. If there isn't an example and I should be able to prove this a hint will suffice. If there is an example I would like to see it though. I am not so good at coming up with examples yet.","['connectedness', 'general-topology', 'continuum-theory', 'compactness']"
3840117,"Show $\int_0^\infty \frac{\ln^2x}{(x+1)^2+1} \, dx=\frac{5\pi^3}{64}+\frac\pi{16}\ln^22$","Tried to evaluate the integral $$I=\int_0^\infty \frac{\ln^2x}{(x+1)^2+1} \, dx$$ and managed to show that \begin{align}
I &= \int_0^1 \frac{\ln^2x}{(x+1)^2+1} \, dx + \int_0^1 \frac{\ln^2x}{(x+1)^2+x^2} \, dx\\
&= \int_0^1 \frac{\ln^2x}{(x+1+i)(x+1-i)} \, dx 
 + \int_0^1 \frac{\ln^2x}{(x+1+ix )(x+1-ix )} \, dx\\ 
 &= -2\operatorname{Im}\operatorname{Li}_3\left(-\frac{1+i}2\right)
 -2\operatorname{Im} \operatorname{Li}_3(-1-i)
\end{align} which is equal to $ \frac{5\pi^3}{64}+\frac\pi{16}\ln^22$ . It is perhaps unnecessary, though, to resort to evaluation in complex space. I would like to work out an elementary derivation of this integral result.","['integration', 'improper-integrals']"
3840119,A problem about the connectivity of vertices that must have the same color for any proper minimal $4$-coloring of a graph.,"Two vertices $u, v$ of a finite graph $G(V, E)$ are said to be entangled if for any proper coloring $c:V(G)\rightarrow\mathbb{N}$ with $\chi(G)$ colors we have $c(u) = c(v)$ , that is, they must have the same color. In that question I made a false conjecture about the connectivity of entangled vertices. There I ask if ""Given a graph $G$ and two entangled vertices $u, v\in V(G)$ , is there $w\in V(G)$ (possibly equal to $v$ ) also entangled with $u$ so that there are $\chi(G)-1$ disjoint paths from $u$ to $w$ ?"" It turns out that the conjecture is false for $\chi(G) \ge 5$ , as shown by a counter example in that post. I would like to know now if the conjecture is true for the case $\chi(G) = 4$ , i.e., if ""Given a $4$ -chromatic graph $G$ and two entangled vertices $u, v\in V(G)$ , is there $w\in V(G)$ (possibly equal to $v$ ) also entangled with $u$ so that there are $3$ disjoint paths from $u$ to $w$ ?"" In fact, it was this particular case that inspired me to come up with this conjecture. Any help would be greatly apreciated.","['coloring', 'graph-theory', 'graph-connectivity', 'combinatorics', 'problem-solving']"
3840121,Find the area bounded by the curve $x^4+y^4=x^2+y^2$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I am stuck with this problem which deals with evaluating an Area
The problem reads : Find the area bounded by the curve $x^4+y^4=x^2+y^2$ . I tried factorizing the expression and expressing $y$ in terms of $x$ , not able to proceed with that idea. Someone please help me out.","['multivariable-calculus', 'area', 'definite-integrals']"
3840150,Is $\ln (x/y) = \ln |x| - \ln |y|$?,"If I am to find the $y$ of the following equation $$\ln(x/y) = x + y,$$ you would first try to split the left-hand side by doing $\ln x - \ln y$ . My question is, do you need to put the absolute function over both $x$ and $y$ ? I think although you know that $x/y > 0$ , you don't know if both are bigger or smaller than zero. In my opinion I don't think it's mathematically correct since both $x$ and $y$ could be negative. So I'm wondering if it's more correct to write like this instead: $$\ln |x| - \ln |y| = x + y.$$ Could anyone let me know if this is indeed the correct way to split the log? Thanks!","['calculus', 'algebra-precalculus', 'logarithms']"
3840159,Limit of ratio of a combinatorial expression?,"The following function takes as arguments $n$ and $\left\{n_{i}\right\} = \left\{n_{0}, n_{1}, n_{2}\right\}$ : $$
\operatorname{f}\left(n,\left\{n_i\right\}\right) =
\sum_{j = 0}^{n}\binom{n}{j}n_{0}^{\,\,\left(n - j\right)\left(n - j - 1\right)/2}\,\,\,\,\,\,
n_{1}^{\left(n - j\right)\,j}\,\,
n_{2}^{\,\,j\,\left(j - 1\right)/2} 
$$ Is there any hope of calculating the following limit $$
\lim_{n \to \infty}\frac{\operatorname{f}\left(n,\left\{n_{i}\right\}\right)}
{\operatorname{f}\left(n,\left\{m_{i}\right\}\right)}
$$ in terms of $n_{0}, n_{1}, n_{2}$ and $m_{0},m_{1},m_{2}\ ?$ . The limit needs to be calculated for a given $n_{0}, n_{1}, n_{2}$ and $m_{0},m_{1},m_{2}$ i.e. they are constant.","['limits', 'summation', 'combinatorics']"
3840192,"identifying the measure $\lambda f^{-1}$ on the interval $[0,1]$","Let $X_i=\{0,1\}$ be the space equipped with the measure $\mu$ s.t. $\mu(\{0\})=\mu(\{1\})=\frac{1}{2}$ . Now define $\Omega$ to be the product space of $X_i$ 's with the product $\sigma$ -field and the product measure $\lambda$ . Consider the map $$f:\Omega\to[0,1]$$ $$\omega=(x_1,\ldots,x_n,...)\mapsto\sum_{j=1}^{\infty}\frac{x_j}{2^j}\in[0,1]$$ My aim is to identify the measure $\lambda f^{-1}$ on the interval $[0,1]$ . First, I take an example. I take $E=(\frac{3}{4},\frac{7}{8})$ , which is a dyadic interval. With the binary expansion defined, we see that $f^{-1}(E)=\{1\}\times\{1\}\times\{0\}\times\ldots$ , a cylinder with volume $\frac{1}{8}$ . Hence, $(\lambda f^{-1})(E)=\lambda(f^{-1}(E))=\frac{1}{8}$ . We can say $\lambda f^{-1}(E)=m(E)$ , where $m$ is the Lebesgue/Borel measure, for every dyadic interval. We can conclude that $\lambda f^{-1}$ is just the standard Borel measure on $[0,1]$ . Details added: Let $E=\left(\frac{k}{2^j},\frac{k+1}{2^j}\right)$ with $n\in\mathbb{N}$ and $0\leq k<2^j$ . Let $x=x_1\ldots x_j$ be the binary expansion, with two exceptions $x=\frac{k}{j}$ and $x=\frac{k+1}{j}$ . Hence $f^{-1}(E)=F\setminus\{p,q\}$ , where $F$ consists of all sequences that start with $x$ and $p=(x,0,0,\ldots)$ and $q=(x,1,1,\ldots)$ . It is clear that $\lambda(F)=2^{-j}$ by definition of the product measure, and $\lambda(\{p\})=\lambda(\{q\})=0$ . Hence $\lambda\left(f^{-1}(E)\right)=2^{-j}$ , which is the Borel measure of $E$ . Since the dyadic intervals generate $\mathcal{B}$ , $\lambda\left(f^{-1}(E)\right)=m(E)$ for any measurable $E$ , and $m$ is the Borel measure on $[0,1]$ . Does this complete the proof for dyadic intervals? I think my statement is correct, but I need a proof to generalize it, instead of just taking dyadic intervals. Here is a post regarding a similar problem as mine: identify the interval $[0, 1]$ with the Lebesgue measure to the probability space for tossing a fair coin . The result is that $f(\omega)$ is almost bijective, meaning that $f(\omega)$ is a bijection except at countably many points $x\in[0,1]$ that have two inverse images; $f(\omega)$ is measure-preserving. Are these two results from this post helpful for writing a rigorous proof regarding my statement? And how can I do that? Thank you.","['measure-theory', 'real-analysis']"
3840236,Limit of sum of exponential functions under root,How to solve this limit? $$\underset{x\to \infty }{\text{lim}}\left(4*6^x-3*10^x+8*15^x\right)^{1/x}$$ It is equal $15$ and it seems obvious that it is so. I just can not write it mathematically. I tried to get rid of $1/x$ in exponent: $$\underset{x\to \infty }{\text{lim}}\left(4*6^x-3*10^x+8*15^x\right)^{1/x}=\exp \left(\underset{x\to \infty }{\text{lim}}\frac{\log \left(4*6^x-3*10^x+8*15^x\right)}{x}\right)$$ Then applied L'Hôpital's rule: $$\frac{\partial \log \left(4*6^x-3*10^x+8*15^x\right)}{\partial x}=\frac{4*6^x (\log 6)+8*15^x (\log 15)-3*10^x (\log 10)}{4*6^x-3*10^x+8*15^x}$$ So we have: $$\underset{x\to \infty }{\text{lim}}\left(4*6^x-3*10^x+8*15^x\right)^{1/x}=\\\exp \left(\underset{x\to \infty }{\text{lim}}\frac{4*6^x \log (6)-3*10^x \log (10)+8*15^x \log (15)}{4*6^x-3*10^x+8*15^x}\right)$$ I can apply the rule again but it only gets more complicated. I was thinking also about some substitution but can not figure out what substitution to use.,['limits']
3840334,The series $\sum_{n=1}^{\infty} \sin(n^4) \sin(4^n)$ converges or not?,Does the series $$ \sum_{n=1}^{\infty} \sin(n^4) \sin(4^n) $$ converges or diverges? I've been stuck with this problem for a long while and I can't figure out anything. Even I tried to break the $\sin$ into its expansion and still no sign of progress. Really need some help.,"['convergence-divergence', 'sequences-and-series', 'real-analysis']"
3840347,When is the $\lim\sup(a_n+b_n)$ strictly less than $\lim \sup (a_n)+\lim\sup(b_n)$,"So I recently proved this inequality in my real analysis class: $$\lim\sup(a_n+b_n)\leq \lim\sup(a_n) + \lim\sup(b_n)$$ However I am wondering when this inequality is strictly less than. I've tried out a bunch of sequences and here is my thought process so far: $$$$ To get a view of when this inequality is unequal look at the two sequences: $$a_n=(0,1,0,1,0,....)$$ $$b_n=(1,0,1,0,1,....)$$ Clearly: $$\lim \sup (a_n+b_n)=1$$ However: $$\lim \sup (a_n)+\lim\sup(b_n)=2$$ This seems to imply that if the limit of a sequence does not exist then we have an inequality. Furthermore what if: $$a_n=(1,1,1,1,....)$$ $$b_n=(0,1,0,1,....)$$ Well then clearly: $$\lim \sup (a_n+b_n)=2$$ $$\lim \sup(a_n)+\lim \sup (b_n)=2$$ And we have equality, which contradicts our earlier hypothesis. Perhaps then it is if both limits do not exist, well let $b_n$ be defined as previously and $a_n=cb_n$ , for some $c\in\mathbb{R}$ both these limits of the sequence do not exist however we obtain: $$\lim \sup (a_n+b_n)=c+1$$ $$\lim\sup(a_n)+\lim\sup(b_n)=c+1$$ And we have equality again. Well then perhaps it must be that both limits do not exist, and that the sequences cannot be scalar multiples of each other. Well then define: $$a_n=(0,1,0,1,0,....)$$ $$b_n-(0,0,0,1,0,0,0,1...)$$ Clearly: $$\lim \sup (a_n+b_n)=2$$ $$\lim \sup(a_n)+\lim \sup (b_n)=2$$ From here I tried testing some cases where $\sup(a_n)\neq \lim\sup(a_n)$ but I still continued to get equalities. So I really can't figure out for what conditions inequality holds. I guess if $a_n$ and $b_n$ look period but are shifted by a non even $n$ then that would make sense but I feel like there's more to it than that.","['limsup-and-liminf', 'sequences-and-series', 'real-analysis']"
3840404,"Simplify $\mathbb{E}\left[ -\log c(u,v)\right] $, the expected logarithm of the copula density","2020 11.26: I finished the derivation but haven't posted it here. I leave this open so that those willing to try their own version can if they want Question How can we derive a closed-form analytical solution for $\mathbb{E}\left[ -\log c(u,v)\right] $ ? $c(u,v)$ is the bivariate copula density for Student's $t$ -copula, whose degrees of freedom is $\nu$ and dependence parameter is $\rho\in (-1,1)$ : \begin{aligned}
c(u,v) &= \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \Bigg(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \Bigg)^{-\frac{\nu +2}{2}}
\end{aligned} where $$dt(x_i; \nu) = \frac{\Gamma \bigg(\frac{\nu+1}{2}\bigg) }{\Gamma (\frac{\nu}{2}) \sqrt{\pi\nu}} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} } \enspace, i=1,2 $$ or equivalently, $$\displaystyle dt(x_i;\nu) = \frac{1}{\sqrt{\nu}B \left(\frac{1}{2}, \frac{\nu}{2} \right)} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} }, i=1,2 $$ where $\Gamma(\cdot)$ is the gamma function, and $B(\cdot)$ is the beta function. First Attempt \begin{align}
h(c(u,v)) &= -\int_{[0,1]^2} c(u,v) \ln c(u,v) \hspace{1mm} du \hspace{1mm} dv \\
&= \mathbb{E}\left[ -\log c(u,v)\right] \\
&= \mathbb{E}\left[ -\log \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\
&=  -\mathbb{E}\left[\log \frac{1}{2\pi \sqrt{1-\rho^2}} + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} +\log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\
&=  -\mathbb{E}\left[-\log \left(2\pi \sqrt{1-\rho^2}\right) + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\
&=  \log \left(2\pi \sqrt{1-\rho^2}\right) -\mathbb{E}\left[\log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\
& = \dots ?
\end{align} Hint Why do I think an analytical solution of copula entropy can be found? Because there is one for the entropy of the Normal distribution's pdf , which I copy and paste now from its derivation here : \begin{align}\label{equation:hN}
h(X_\mathrm{Gauss}) = &-\int_{-\infty}^{\infty} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \ln\left[ \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \right] \mathrm{d} x\\
= &\frac{1}{2} \ln(2\pi \sigma^2) \int_{-\infty}^{\infty} (2\pi \sigma^2)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\
&+ \frac{1}{2\sigma^2} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} (x-\mu)^2 e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\
=& \frac{1}{2} \ln (2\pi\sigma^2) + \frac{1}{2}\\
=& \frac12\ln(2\pi\sigma^2) + \frac12\ln e\\
=& \frac12\left(\ln(2\pi\sigma^2) + \ln e\right)\\
=& \frac{1}{2} \ln (2\pi e \sigma^2)
\end{align} Link to someone's attempt at the Clayton copula entropy","['integration', 'statistics', 'entropy', 'information-theory', 'copula']"
3840411,Error bounds on the Expansion of Square Root of Matrix,"Wikipedia gives the expansion of the square root matrix as follows: $$\frac{A^{1/2}}{\|A\|^{1/2}} = I - \sum_{n = 1}^{\infty}\left\lvert {1/2 \choose n}\right\rvert  \left(I-\frac{A}{\|A\|}\right)^n = I - \frac 1 2\left(I-\frac{A}{\|A\|}\right) - \frac 1 8 \left(I-\frac{A}{\|A\|}\right)^2 \,...$$ In this post, I'm taking the matrix norm to be the max of the absolute values of the column-sums of matrix $A$ . I thought I might be able to get an estimate of square root matrix by taking the first two terms and using the third term as an error bound. But a simple numerical example appears to not work. I'm not sure if I'm using the expansion incorrectly, or there's some hypothesis I'm missing. In particular for $A = \begin{pmatrix}
4 & 0 \\
0 & 16 
\end{pmatrix}, \|A\| = 16$ I get an error: $$\|A^{1/2}/\|A\|^{1/2} - I + (I-A/\|A\|)/2 \| = 1/8$$ Error bound using the third term: $$\|(I-A/\|A\|)^2/8 \| = 9/128$$","['matrices', 'operator-theory', 'linear-algebra', 'functional-analysis']"
3840446,Complex analysis integral residuum,"I am asked to evaluate, principal value of $$\int_{-\infty}^\infty\frac{\cos(x)}{a^2-x^2} \, dx=\pi \frac{\sin (a)}{a},a>0$$ If we start from $$\oint\limits_{C}\frac{e^{iz}}{a^2-z^2}dz,a>0$$ the line $C$ is composed of the half circle $\Gamma$ , pole circles at $-a,a, \gamma_1,\gamma_2$ whose circumferences are ( $r,r_1,r_2$ ),  and a portion of the $x$ -axis. If we use the Cauchy remainder theorem, we get $$
\begin{split}
\int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}
                {a^2-r^2e^{2-\theta}}
                ire^{i\theta} \, d\theta
&+ \int_{-r}^{-a-r_2} f(x) \, dx
 + J_2 \\
&+ \int_{-a+r_2}^{a-r_1} f(x) \, dx
 + J_1
 + \int_{a+r_1}^r f(x) \, dx
 = 0
\end{split}
$$ Since $\left|\int_0^\pi \frac{e^{ir\cos \theta -rsin \theta}}{a^2-r^2 e^{2-\theta}}ire^{i\theta} \, d\theta\right|\leq{\frac{\pi r}{r^2-a^2},(r>a)}$ We get $$\lim_{n \to \infty}\int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}{a^2-r^2e^{2-\theta}}ire^{i\theta} \, d\theta=0$$ Evaluating residuum at $J_{1}$ and $J_{2}$ we get $$J_1=\operatorname{Res}f(a)=\lim_{x \to a}(a-x)\frac{e^{ix}}{(a-x)(a+x)} =\frac{e^{ia}}{2a}$$ and $$J_2= \operatorname{Res}f(-a)=\lim_{x \to -a}(a+x)\frac{e^{ix}}{(a-x)(a+x)}=\frac{e^{-ia}}{2a}$$ In my book the author got $J_{1}=\frac{\pi i}{2a}e^{ia}\land J_2=-\frac{\pi i}{2a} e^{-ia}$ Where does the $\pi i$ come from ? also, why - in the second one? Is it because the residuum is at $-a$ ?  Then, adding those two gives us the result, but still, where does $\pi$ come from?","['complex-analysis', 'cauchy-principal-value']"
3840476,Prove that the relation $\subseteq$ over $℘(\mathbb{N})$ is not well-founded.,"I want to prove the following theorem: Prove that the relation $\subseteq$ over $℘(\mathbb{N})$ is not well-founded. I understand that to prove this we need to find a nonempty set $S \subseteq p(\mathbb{N})$ , where for each $x \in S$ , we can find $y \in S$ , where $y \subseteq x$ . I think that the main thing why I have difficulties with proving the theorem is that I don't have an intuition of why this is true. Like my brain doesn't believe the theorem is true, therefore I can't even know how to proceed. These are my thoughts which lead me to doubt about the theorem: Let $S \subseteq p(\mathbb{N})$ be set, which has a minimal element $x$ . Then we can find a set, where $x$ is not a minimal any more by creating $S_n$ = $S \cup \{ x_n \}$ , where $x_n$ is the set $x$ without any one element. So like it seems that $x_n$ is a minimal in $S_n$ . And I feel that we can do this forever until $x_n$ is empty set, which is definitely minimal. I know this can't be proof that the original theorem is false and I don't try to do this. I just want to build an intuition around the theorem, just to allow my brain to be comfortable with it and don't think that this is impossible. Could you please provide any hints, any thoughts so that I understand why this can be possible and will be able to go to the right direction in my proof.","['elementary-set-theory', 'intuition', 'order-theory', 'relations']"
3840490,$8$ distinct balls are randomly distributed among $4$ boxes. What is the probability that each box has exactly two balls?,"I made up an question in my head as to probability but i am not sure about the solution. Question: There are $8$ distict balls and $4$ distinct boxes.An individual distributes the balls into boxes randomly.What is the probability that each boxes have exactly two balls? My solution: The sample space is ${4}^{8}$ and the number of ways distributing exactly two balls into each four boxes : $ C(8,2).C(6,2).C(4,2).C(2,2).P(4,4)$ $\therefore \frac {C(8,2).C(6,2).C(4,2).C(2,2).P(4,4)}{{4}^{8}} $ Is my solution correct? I feel that i am wrong in somewhere.If it is not correct ,can you give hints or the solution. Thanks for your helps..","['solution-verification', 'discrete-mathematics', 'balls-in-bins', 'probability']"
3840520,Number of $3\times3$-matrices with integer coefficients satisfying $\operatorname{Tr}(A^{\top}A)=6$.,"We are asked to find the number of $3$ x $3$ matrices $A$ with all integer entries satisfying $\operatorname{Tr}(A^{\top}A)=6$ . My approach Assuming $A=\begin{bmatrix}
 a_{11}&a_{12}  & a_{13}\\ 
a_{21} & a_{22} &a_{23} \\ 
a_{31} &a_{32}  & a_{33}
\end{bmatrix}$ and hence $A^{\top}=\begin{bmatrix}
 a_{11}&a_{21}  & a_{31}\\ 
a_{12} & a_{22} &a_{32} \\ 
a_{13} &a_{23}  & a_{33}
\end{bmatrix}$ We have $A^{\top}A=\begin{bmatrix}
 a_{11}^{2}+ a_{21}^{2}+ a_{31}^{2}&\lambda_{1} & \lambda_{2}\\ 
 \lambda_{3}&   a_{12}^{2}+ a_{22}^{2}+ a_{32}^{2}& \lambda_{4}\\ 
 \lambda_{5}&   \lambda_{6}&  a_{13}^{2}+ a_{23}^{2}+ a_{33}^{2}
\end{bmatrix}$ So the problem reduces to finding integers $a_{ij}$ ; $i,j=1,2,3$ such that $\sum_{i=1}^{3}\sum_{j=1}^{3}a_{ij}^{2}=6$ which can be thought of as $\sum_{i=1}^{9}t_{i}=6$ where each $t_{i}$ is an integer and perfect square. Hence we must partition 6 into 9 portions each of which is a perfect square, Case 1; 9 $t_{i}s$ = 6( $t_{i}s$ have value $1$ )+3( $t_{i}s$ have value $0$ ) number of matrices here would be $n_{1}=\frac{9 !}{6!3!}2^{6}$ , since each permutation of the string of 6 1’s and 3 0’s corresponds to a value of $t_{i}$ and hence $a_{ij}^{2}$ and because for each value of $a_{ij}^{2}$ =1, we can have $a_{ij}=\pm1$ , hence the number of permutations is scaled up by $2^{6}$ Case 2 9 $t_{i}s$ = 1( $t_{i}$ has value $4$ )+2( $t_{i}s$ have value $1$ )+6( $t_{i}s$ have value $0$ ) number of matrices here would be $n_{2}=\frac{9 !}{1!2!6!}2^{3}$ , since each permutation of the string of 1 2’s and 2 1’s and 6 0’s corresponds to a value of $t_{i}$ and hence $a_{ij}^{2}$ and because for each value of $a_{ij}^{2}$ =1, we can have $a_{ij}=\pm1$ and similarly for $a_{ij}^{2}$ =4, hence the number of permutations is scaled up by $2^{3}$ No further partitions into perfect squares are possible Thus the total number of matrices should be $N=n_{1}+n_{2}=\frac{7\cdot8\cdot9\cdot64}{6}+7\cdot8\cdot9\cdot4=7392$ Is the above reasoning correct for the number of such matrices ? Please help me if anything is missing in above since I don’t have the answer for this in the exercise.","['permutations', 'sums-of-squares', 'matrices', 'linear-algebra', 'combinatorics']"
3840576,What is a good geometric reason to care about the Jacobson radical of a ring?,"Let $R$ be an arbitrary commutative ring with unit. The nilradical $\mathfrak N = \mathfrak N(R)$ is the intersection of $R$ 's prime ideals, hence the closed subset $V(\mathfrak N)$ contains every point of $\operatorname{Spec}(R)$ , so, in a sense, $\operatorname{Spec}(R/\mathfrak N)$ is the smallest closed subscheme of $\operatorname{Spec}(R)$ that the raw topology sees as being the whole of $\operatorname{Spec}(R)$ , i.e., any distinctions can only be seen in the structure sheaf. I see the inclusion $\operatorname{Spec}(R/\mathfrak N) \to \operatorname{Spec}(R)$ as adding an infinitesimal layer of fat on top of $\operatorname{Spec}(R/\mathfrak N)$ , which is just meat and bones. The elements of $R$ and $R/\mathfrak R$ induce the same functions on the same underlying topological space, because we cannot see any nilpotent distinctions by evaluating them at points. Is there any similar intuition that I could develop for the Jacobson radical? Of course, I can adapt the sentence in the preceding paragraph as follows: $\mathfrak J = \mathfrak J(R)$ is the intersection of $R$ 's maximal ideals, hence the closed subset $V(\mathfrak J)$ contains every closed point of $\operatorname{Spec}(R)$ , so, in a sense, $\operatorname{Spec}(R/\mathfrak J)$ is the smallest closed subscheme of $\operatorname{Spec}(R)$ that the raw topology sees as containing every closed point of $\operatorname{Spec}(R)$ . However, what is a good reason to care about this definition? Evidently, I am failing to see Nakayama's lemma as a geometric statement.","['algebraic-geometry', 'commutative-algebra']"
3840578,References for learning real analysis background for understanding the Atiyah--Singer index theorem,"I am interested in learning the Atiyah--Singer theorem, and its version for families of operators. For this purpose, I have tried to read the recent book by D.Bleecker et.al. . However I have difficulty understanding some proofs due to my weak analysis background. I have learnt the related differential geometric notions (principal bundles, connections, Chern--Weil theory) and the algebraic topological notions (K-theory, characteristic classes) and feel comfortable with Clifford Algebras. However, my analysis background is very weak. In real analysis, my knowledge is limited to what is covered in baby Rudin. I have not studied any Fourier analysis or measure theory. As regards functional analysis, I know basic notions about Hilbert spaces, but no spectral theory. As a result when concepts such as distributions and test functions convergence issues with Fourier transforms L^p spaces etc. pop-up or the author proceeds to discuss Sobolev spaces and pseudo-differential operators, I find myself to be very confused and puzzled. My question is : Given my background described above, which analysis books should I study in order to properly understand the analysis background required for the Atiyah--Singer index theorem? For the time being, I wish to learn only the minimum analysis required for this purpose. Also I prefer to first read up the required pre-requisites rather than learning-on-the-go. Also : Given that I am not strong at analysis, should I consider studying a different book (e.g. Spin Geometry by Lawson--Michelsohn) rather than the book by D.Bleecker et. al. ? I am aware of a related question on MO which is partially helpful, but most answers there suggest books for learning Index theory rather than its pre-requisites. Thanks so much !","['spin-geometry', 'book-recommendation', 'reference-request', 'partial-differential-equations', 'differential-geometry']"
3840627,Expected number of games so that every player has been an Imposter in Among Us [duplicate],"This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed 3 years ago . Imagine you have $n$ players. In each game, $k$ $(k\leq n)$ players are chosen randomly to do whatever. By game $G$ , what is the probability that every player has been chosen at least once? What is the expected number of games that have to be played so that every player was chosen at least once? Of course, when $G < n/k$ the probability is zero. This idea came from the game Among Us, where there are $n$ players ( $n\leq10$ ) and in each game you have $k$ imposters (usually $1$ , $2$ or $3$ ).","['combinations', 'expected-value', 'combinatorics', 'coupon-collector', 'probability']"
3840658,Does the restriction of $\mathcal{O}(1)$ to a quadric have a square root?,"Let $Q^n$ be a smooth $n$ -dimensional quadric in $P^{n+1}(\mathbb{C})$ . Does the restriction of $\mathcal{O}(1)$ to $Q^n$ have a square root, for any $n \geq 1$ ? If $n = 1$ , then $Q^1$ is biholomorphic to $P^1(\mathbb{C})$ , and the restriction of $\mathcal{O}(1)$ to $P^1(\mathbb{C})$ is $\mathcal{O}(2)$ (that is, $\mathcal{O}(2)$ with respect to $P^1(\mathbb{C})$ ) and thus has a square root, namely $\mathcal{O}(1)$ (with respect to $P^1(\mathbb{C})$ ). My question is whether this also holds for $n > 1$ . Edit: I don't think so, but could someone please confirm? If $n = 2$ , I think that the restriction of $\mathcal{O}(1)$ to $Q^2$ , itself biholomorphic to $P^1(\mathbb{C}) \times P^1(\mathbb{C})$ , is the line bundle $\mathcal{O}(1,1)$ , which does not have a square root. Am I right?","['algebraic-geometry', 'line-bundles']"
3840660,"For all Lebesgue-Integrable function $f$, there exists two upper and lower semi-continuous functions $g,h$, such that $g\le f\le h$.","This is one exercise from functional-analysis. The full problem is : Let $f:X\to\mathbb{R}$ a Lebesgue-integrable function. Then $\forall s>0$ , there is upper-semi-continuous function $g$ and lower-semi-continuous function $h$ , such that $g\le f\le h$ , and $$\int_X (h(x)-g(x))m(dx)<s$$ At first, I think of simple functions. BUT, as $f$ is not bounded and $m(X)$ could be infinite, so there is no step function could do that (Counter example: $f(x) = \frac{1}{x^2}$ , $x\ge 1$ there doesn't exist simple function $\phi(x) \ge f$ meet the requirement.) And I wonder if I can find two continuous functions. However the only theorem I can think of is Lusin'theorem. But it couldn't guarantee that continuous $g\le f$ or $g\ge f$ . So, I get stuck. Pls let me know where should I go. Thanks!","['functional-analysis', 'real-analysis']"
3840661,Proof of 42 | $n^7-n$ [duplicate],"This question already has answers here : How can I prove that $n^7 - n$ is divisible by $42$ for any integer $n$? (8 answers) Closed 3 years ago . I saw a proof of why 42 | $n^7-n$ here But I was a little confused. By Fermat's Little Theorem for any prime $p$ and any $a \in {(1,2,..., p−1)}$ , we have $a^{p−1}$ ≡ $1$ $($ mod p $)$ . So, don't we need to split into two cases, where $n \geq 7$ and $n < 7$ ? Because we don't know what $n$ is, and the def of Fermat only applies if $n$ is within the set $(1,2,3,4,5,6,7)$ ?","['elementary-number-theory', 'discrete-mathematics']"
