question_id,title,body,tags
2179926,A certain kind of non-linear mapping from $\mathbb{R}^2$ to $\mathbb{R}^2$,"Give an example of a map $T:\mathbb{R}^2\rightarrow\mathbb{R}^2$ with both of the following properties: a. $T(kx)=kT(x)$ for all $x\in \mathbb{R}^2, k\in \mathbb{R}$ b. $T$ fails to be a linear transformation I am really stuck on this. I can only find matrices that are not linear transformations and don't fulfill the first condition, or they are linear transformations and they do fulfill the first condition. I am not sure how to go about doing this.","['examples-counterexamples', 'linear-algebra']"
2179931,"Topology: if for every $A,B \in T$, either $A \subset B$ or $B \subset A$, then the arbitrary union of elements of T is an element of T","I'm trying to prove that if $T$ is a collection of subsets of $X$, such that for  every $A,B\in T$, either $B \subset A$ or $A \subset B$, then $\bigcup_{i\in I}A_i \in T$ I know that $B\cup A=A$ if   $B \subset A$ and $B\cup A=B$  if $A \subset B$
but I don't know how to prove the above statement and I can't find a counterexample.","['general-topology', 'elementary-set-theory']"
2179953,How do I find the area of the inscribed triangle within the ellipse without analytic geometry?,"I have the following problem where I need to solve for the inradius of a particular inscribed triangle in an ellipse: ∆ABC is situated within an ellipse whose major axis is of length 10 and whose minor axis is of length 8. Point A is a focus of the ellipse, point B is an endpoint of the minor axis and point C is on the ellipse such that the other focus lies on BC. Compute the inradius of ∆ABC. Hint: recall the area formula for a triangle involving the inradius. At the end I'm given a hint to use the area formula for a triangle $K = rs$  in solving for the inradius. I divided both sides by $s$ to get $K/s = r$, and then tried to solve for both $K$ and $s$. It was easy to solve for $s$, because if we let $A'$ be the other focus then $$
\begin{equation}
\begin{split}
\begin{gathered}
P = AB + BC + AC = AB + BA' + A'C + CA\\
AB = a\\
BA' = a\\
A'C + CA = 2a\\
P/2 = 2a
\end{gathered}
\end{split}
\end{equation}
$$ However, I'm having trouble solving for $K$. I realize it's easy to just write up an analytic equation for the ellipse and find the equation of the line $BA'$ then solve for $C$, but I'm interested if there's a better way to do this. I noticed that since B connects line segments passing through both foci the question may have something to do with the reflective property of the ellipse, but I'm not sure. How do I find the area of the triangle non-analytically?","['algebra-precalculus', 'conic-sections']"
2179976,"Identity for the divisor function: $\tau(mn)=\sum\limits_{d\mid(m,n)}\mu(d) \tau(m/d)\tau(n/d)$","Let $\tau$ denote the classical divisor function and $\mu$ be the 
Möbius function. Then for each pair of integers $n,m$ we have $$\tau(mn)=\sum_{d\mid(m,n)}\mu(d) \tau(m/d)\tau(n/d),$$ where the sum is taken over all positive integer common divisors of $m$ and $n$ . I can verify this by using multiplicativity and checking via brute force that it is true when $m,n$ are powers of the same prime. My question is whether there is a different proof and whether it is part of a bigger family of similar identities.","['analytic-number-theory', 'divisor-counting-function', 'number-theory', 'summation', 'elementary-number-theory']"
2179977,Sparse basis orthogonal to the ones vector,"Let $v\in \mathbb{R}^{n}$ be the vector of ones, $v=(1,1,1,\cdots,1).$ I need an orthogonal basis for the orthogonal complement $v^{\perp}$, the space of all vectors orthogonal to $v$. Of course, one can solve for such a basis using Gram-Schmidt, but I have an extra requirement: that the basis vectors are sparse . Is there a standard such basis? I can start writing down basis vectors in an ad-hoc way, e.g. \begin{align*}
b_1 &= (1, -1, 0, 0, \cdots)\\
b_2 &= (0, 0, 1, -1, \cdots)
\end{align*} but obviously this pattern runs out after $n/2$ vectors.",['linear-algebra']
2179995,"Does $\lim\limits_{n\rightarrow \infty}E[X|F_n]$ exists a.s if $F_n$ is the $\sigma-$field generated by $Y_0,...,Y_n$ where $Y_n=X+W_n$.","Let $X$ be a random variable such that $|X|<K$ a.s for some $K>0$. Let $Y_n=X+W_n$ for $n\in \mathbb{N}$ where $(W_n)$ is some process. If we define $F_n$ be the $\sigma-$field generated by $Y_0,Y_1,...,Y_n$. Does $\lim\limits_{n\rightarrow \infty}E[X|F_n]$ exists a.s? My answer is ""Yes"". I proved it by using Martingale convergence Theorem, but I am not pretty sure whether I did it correct or not. If there is any problems of my proof, please let me know. Thanks! The detail is as follows: Let $Z_n=E[X|F_n]$, and note that $E|Z_n|=E|E[X|F_n]|\leq E(E[|X| | F_n])\leq K$ for all $n\in\mathbb{N}.$ This implies that $Z_n$ is $L^1$; moreover, $\sup\limits_{n\in\mathbb{N}} E|Z_n|<\infty.$ On the other hand, for $m<n,$ we have $E[Z_n|F_m]=E[E[X|F_n]|F_m]=E[X|F_m]=Z_m$. Thus, we obtain $(Z_n)$ is a $(F_n)-$martingale, and $\{Z_n\}$ is bounded in $L^1$, by Martingale convergence theorem, $Z_n=E[X|F_n]$ converges almost surely.",['probability-theory']
2180004,Using Functions to Reach Every Positive Integer,"Consider the functions $f(x)=2x+1$ and $g(x)=3x+1$, as well as their inverses f'(x) and g'(x). Starting with the number 1, is it possible to reach every positive integer through some finite sequence of these $4$ functions? For example, we could have the following sequence: $$1\,\,\overbrace {\longrightarrow}^{f(x)}  \,\, 3\,\,\overbrace {\longrightarrow}^{f(x)}  \,\,7\,\,\overbrace {\longrightarrow}^{g'(x)} \,\,2\,\,\overbrace {\longrightarrow}^{f(x)} \, \,5$$ Edit: I've tried a few things like taking base 6 and simply bashing a lot, and it seems like that it is possible, though I have no idea how to rigorously prove that.","['functions', 'elementary-number-theory']"
2180009,Line integral with vector field in polar coordinates,"I have the following problem: Given a vector field in polar coordinates $$ \mathbf{F}(r,\theta) = -4 \sin \theta\ \mathbf{i}\ +\ 4 \sin \theta\ \mathbf{j},$$ calculate the work done when a particle is moved from point $(1,0)$ to the origin, following the spiral whose polar equation is $r = e^{-\theta}.$ My attempt was to write the equation of the spiral like so $$\mathbf{\alpha}(t) = e^{-\theta} \cos \theta\ \mathbf{i} + e^{-\theta} \sin \theta\ \mathbf{j} \\ \mathbf{\alpha}'(t) = -e^{-\theta}(\cos \theta + \sin \theta\ \mathbf{i}\ + \sin \theta - \cos \theta\ \mathbf{j}),$$ so the line integral would become $$\int_C \mathbf{F}\cdot\mathbf{\alpha'}(t) = \int_C 8 e^{-\theta}\sin\theta\cos\theta\ d\theta.$$ But this doesn't give me the right answer, what am I doing wrong? NOTE: I know this question was asked before, but it doesn't have an accepted answer, and what I read from there wasn't very helpful.",['multivariable-calculus']
2180012,Betti numbers for the isotropic grassmannian,"I want to know if there is some type of combinatorial formula for computing the Betti numbers of the isotropic grassmannian $IG(r,2n)$ for $r\leq n$. I'm thinking of this as the homogenous space $G/P$ where $G=Sp(2n)$, and $P$ is the maximal parabolic generated by the subset of simple roots $S-{\alpha_r}$, where $S={\alpha_1,...,\alpha_n}$ are the simple roots for $Sp(2n)$. I know in the case of the Grassmannian $Gr(r,n)$ the $i^{th}$ Betti number is the number of partitons of the integer $i$ which can for inside a $r\times (n-r)$ box. These are the coefficients of the Poicare series of the Grassmanian which happens to be the Gaussian polynomial or q-binomial coefficient http://mathworld.wolfram.com/q-BinomialCoefficient.html So I wonder if there is a similar combinatorial description for the betti numbers of the isotropic grassmannian or it the Poincare Series has a known form. I can write down the Poincare series for the isotrpic Grassmannian, but its not clear to me if this has some more well-known form. In particular I'd like to know whether $dim(H^i(IG,r,2n))$ is still bound by the number of partitions of the integer $i$ ?","['algebraic-geometry', 'representation-theory', 'algebraic-topology', 'combinatorics', 'schubert-calculus']"
2180024,How do I prove the divisibility of 2 numbers?,"Let $N$ be any $6$-digit positive integer in base 10. Let $N^*$ be obtained from $N$ by swapping the positions of the first $3$ digits with the last $3$ digits. (eg. if $N = 123456$, then $N^* = 456123$). Prove that for any choice of $N$, $N + N^*$ is divisible by 7. I'm confused as to where to begin this question. Am I supposed to create variables that represent each digit for both $N$ and $N^*$ before starting the proof? We're also learning about congruence so I'm assuming that might be used somewhere within the solution.","['congruences', 'divisibility', 'discrete-mathematics']"
2180052,Solve $\int_{0}^{\infty}\frac{\ln(2x)}{4+x^2}dx$ by contour integration,"I'm a little stuck with this one. I've found the singularities to be at $\pm 2i$ and $0$ (branch point). So far, using a branch cut at $2\pi$ I've found that
$$\int_{0}^{\infty}\frac{\ln(2r)}{4+r^2}dr+\int_{0}^{\infty}\frac{\ln(2r)+2\pi i}{4+r^2}dr = 2I+\int_{0}^{\infty}\frac{2\pi i}{4+r^2}dr$$
And 
$$\int_{0}^{\infty}\frac{2\pi i}{4+r^2}dr = \text{Res}(r=2i) \\ = -2\pi^2\lim_{r\to2i}\frac{r-2i}{(r-2i)(r+2i)} = \frac{i}{2}\pi^2$$
My problem is that the answer I found is completely imaginary, and I'm not sure how that's possible given that the original function is real. Any help is appreciated.","['complex-analysis', 'contour-integration', 'branch-cuts']"
2180059,A power even smaller than Fermat's Little Theorem suggests?,"So I know that Fermat's little theorem states: let $p$ be a prime number, let $a$ be an integer where $p \nmid a$. So $a^{p-1} \equiv 1 $ (mod $p$). But is it possible to prove that there is some smaller power of $a$ that is congruent to $1$ as well? If I can find some integer $k$ where it is the smallest positive integer so that $a^k \equiv 1$ (mod $p$) then how can I prove that $k \mid (p-1) $ as that would complete the proof in stating that there IS some smaller power than $p-1$.","['congruences', 'discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2180089,Prove or disprove the logic statement about subsets,"Prove or disprove: If $ A \nsubseteq  B \cap C$, then $A \nsubseteq B$ and $A \nsubseteq C$. I think it is false statement, shown by this counterexample: let $A=\{1,2,3\} , B=\{1,2,3\}$, and $C=\{4,5\}$, so $ B \cap C=\emptyset$, but $ A \subseteq B$. Is my counterexample correct?",['elementary-set-theory']
2180091,Average number of inversions in an involution,"I'm working through some exercises in Sedgewick's Analysis of Algorithms, but I'm stuck on 7.45: Find the CGF for the total number of inversions in all involutions of length $N$ . Use this to find the average number of inversions in an involution. I understand that the construction for $\mathrm{inversions}(i)$ will look different than say the construction of $\mathrm{inversions}(p)$ for a random permutation, since we create fewer than $|i|+1$ involutions upon adding the next element. That next element cannot be put in a place where it will cause a 2-cycle to become a 3-cycle. As such, the number of inversions caused by $|i|+1$ will be fewer than the construction for inversions in a random permutation. This depends on how many 2-cycles exist within the $|i|$ involution. I have no idea how it should look.","['generating-functions', 'algorithms', 'permutations', 'combinatorics', 'involutions']"
2180102,How to calculate 3d rotation from 3 points?,"If you have 3 labeled points on a surface of a paper. Like 1


2       3 This makes a perfect equilateral triangle. From this perspective I can say that the camera is on top of the paper looking down. We can say the camera is at coordinate $(0,0,100)$. Which is 0 degree rotation in Z axis and 90 degree rotation in Y axis. Then, I move the camera to some arbitrary spot. Now, the points are like 1

2                 3 This looks like the camera is farther back from the paper and was lowered, say at location $(0, -100, 50)$. Which is about -90 degree rotation in Z-axis, and 45 degree rotation in Y axis. So my question is basically, given the $(x_1,y_1), (x_2,y_2), (x_3,y_3)$. Is there some formula that can take these arbitrary points, compare it with the original 3, to know how much of a X,Y,Z rotation it is of the camera? I can also rotate on angles like this. For example, I can take the second example from above, then I can rotate my head clockwise, making the numbers flip like 2
    1
3 I think getting a normal vector from the center might be better to find.","['rotations', 'linear-algebra', 'geometry']"
2180115,Why is $\int \frac{f'(x)}{f(x)}=\ln |f(x)|$ ignored in differential equations?,"I've noticed that whenever $\int \frac{f'(x)}{f(x)}$ comes up in a differential equation the answer is always given as $\ln f(x)$ rather than $\ln |f(x)|$ as I was taught it should be. Is it because of the arbitrary constant? In other words, since $$\int \frac{f'(x)}{f(x)}=\ln |f(x)|+\ln A$$ for some constant $A$, then the answer is $\ln A|f(x)|$ and because $A$ can be positive or negative it follows that there is no point including the absolute signs? Hence the answer is given as $\ln f(x)+C$ for some constant $C$ rather than $\ln |f(x)|+C$. Is this why?","['indefinite-integrals', 'integration', 'ordinary-differential-equations']"
2180118,"Tiling with 1 x k tiles; if you can tile n x m rectangle, k|n or k|m","Tiling with 1 x k tiles;prove that if you can tile n x m rectangle, k|n or k|m (assuming k, n, m integers). It is obvious that you get down to the remainders of n and m divided by k. Experience and logic say we can shift all the tiles to line up in blocks parallel to one side and if there are non-zero remainders less than k, the tiling fails. But how do I demonstrate that formally and  mathematically?","['number-theory', 'tiling', 'elementary-number-theory']"
2180181,Find the value of $\sum_{k=1}^{n}k\binom{n}{k}$?,"Find the value of $\sum_{k=1}^{n}k\binom{n}{k}$ ? I know that $\sum_{k=0}^{n}\binom{n}{k}= 2^{n}$ and so, $\sum_{k=1}^{n}\binom{n}{k}= 2^{n}-1$ but how to deal with $k$ ?","['binomial-coefficients', 'combinatorics', 'summation', 'sequences-and-series', 'discrete-mathematics']"
2180205,Two proofs regarding open and closed sets,"[Question] 1) Let $M=\{\frac{1}{n}:n\in\mathbb{N}\}$. How do I show $M$ is not open in $\mathbb{R}$? 2) Let $K=\{\frac{1}{n}:n\in\mathbb{N}\} \cup \{0\}$. How do i show $K$ is closed in $\mathbb{R}$? [Solution] 1) 
I've taken the point $1 \in M$ and placed an open ball around it such that $B_r(1)$. I want to prove that I can find an $x \in B_r(1)$ such that $x \not\in M$ because then, by definition, $M$ is not open. I understand that it isnt open, by drawing and looking at the interval. But how do i prove it mathematically? Could i simply write something like this: Let $r>0$ and $x=1+\frac{1}{2}r$ then $x \in B_r(1)$ while $x \not\in M$ therefore $B_r(1) \not\subset M$ and therefore $M$ is not open. I'm not sure how to argue how/why I defined x as such. Is the above an okay proof and how could I proof/argue how x is defined? 2) To show that $K$ is closed, I will show that $K^c$ is open. I know $K^c$ is an open union of sets but I'm not certain how to make a proper proof. Here is what I've tried $K$ will never be negative and will be greater than 1, therefore it will never be within $(-∞;0)$ & $(1;∞)$. Now I'm not certain what to do.","['real-analysis', 'sequences-and-series', 'proof-verification']"
2180212,Why does the homology of noncompact manifolds often vanish below the dimension?,"So I was watching this talk by Peter Scholze , where at around 9:50 he says that the homology of the quotient $X := H^3/SL_2(\mathbb{Z}[i])$ only has homology in degrees 0, 1, and 2, because it's noncompact. Here $H^3$ is hyperbolic upper 3-space. (I understand that homology must vanish beyond degree 3, so the question is why the top dimensional homology vanishes) I'm trying to understand why the noncompactness makes the 3-dimensional homology vanish. In particular I'd be interested in the relevant facts/theorems, and if possible, references would be awesome. Other simpler but enlightening examples would be appreciated as well. As a side question - this space $X$ is triangularizable right?","['homology-cohomology', 'manifolds', 'algebraic-geometry', 'algebraic-topology', 'general-topology']"
2180231,$L^2$ decay of solutions of heat equation,"Consider heat equation: in $\Omega \subset \mathbb R^n:$ \begin{equation*}
\begin{cases}
\begin{aligned}
u_t - \Delta u &=0 \\
u(0,x) &= u_0 \\
u &= 0\quad\text{on }\partial \Omega
\end{aligned}
\end{cases}
\end{equation*} I want to show $\|u(t)\|_{L^2}\rightarrow 0$ as $t \rightarrow \infty$ . So far, we know $$\frac{d}{dt} \int_\Omega u^2 = 2\int uu_t = 2\int u\Delta u = -2\int|\nabla u|^2 \leq 0.$$ I doubt we can conclude from here that $\|u(t)\|_{L^2}\rightarrow 0$ as $t \rightarrow \infty$ . The derivative of the function is negative and the function $\int_\Omega u^2$ is non-negative.","['real-analysis', 'partial-differential-equations', 'heat-equation', 'ordinary-differential-equations', 'analysis']"
2180306,Does $h \circ f = I = f \circ g \implies h = g$?,"Suppose that the identity function $I$ is defined as $I:X \to X$ such that $\forall x \in X$, $I(x) = x$.
I was hoping that $f(g(x)) = h(f(x)) = x \implies g(x) = h(x)$ for a proof I am constructing. I am stuck as to where to begin. Any help would be greatly appreciated. Cheers.","['real-analysis', 'functions']"
2180352,When is the direct image functor exact?,"Consider a morphism of topological spaces $f:X\to Y$ . The direct image functor takes a sheaf $\mathcal{F}$ on $X$ to the sheaf defined by $f_*\mathcal{F}(U)=\mathcal{F}(f^{-1}(U))$ . It's a right adjoint to the inverse image functor, which means it is automatically left-exact (but usually not right exact). Here are some general situations I know when $f_*$ is exact: 1) $f$ is a closed immersion (true for any mapping of topological spaces, not just schemes) 2) $f$ is affine and we consider quasicoherent sheaves (a generalization of 1, but this time requiring $X,Y$ be schemes and the sheaves quasicoherent) and then my knowledge of this situation kind of teeters off in to the distance. Question : What are some more scenarios where we know that $f_*$ is exact (are there any)? I'm curious about what adjectives one can stick on $X,Y,f$ which would let me know without extra calculation that $f_*$ is exact. I'm mostly concerned with $X,Y$ schemes, I'm somewhat interested in the case where $X,Y$ are analytic spaces over any of $\mathbb{Q}_p,\mathbb{R},\mathbb{C}$ , and I'd definitely take other interesting scenarios if any of you want to tell me about them.","['sheaf-theory', 'algebraic-geometry']"
2180369,Absolute convergence implies convergence in complete spaces,"Let $V$ be a normed space with norm $\|\|$. $\sum_{n=1}^\infty a_n$ is an absolutely convergent series if $\sum_{n=1}^\infty \|a_n\|$ converges. Could you please explain why in complete normed spaces the absolute convergence implies convergence, but it doesn't hold for incomplete normed spaces?",['functional-analysis']
2180384,Show $f(x)=1-\frac{1}{x\left(\lvert x\rvert_2\right)}$ converges on $0$ in finite steps,"Let $$ f(x)=1-\frac{1}{x\lvert x\rvert_2}. $$ Show that $f^m(x)$ converges to $0$ for all $x\in\mathbb{N_{>0}}$, for
  sufficiently high $m\in\mathbb{N}$. In a nutshell, $x\lvert x\rvert_2$ boils down to the odd factors of $x$.
$\lvert x\rvert_2$ is the $2$-adic metric of $x$, defined by $\lvert x\rvert_2=\frac{1}{2^p}$, where $x=2^p\cdot\frac{r}{q}$ and $r,q$ are odd numbers. Note that the question is, whether for an initial integer input $x$, $f^m(x)$ converges, however $f(x)$ must be defined over rationals so we have $$f(x)=1-\frac{1}{x\lvert x\rvert_2}\quad \mathbb{Q}\mapsto\mathbb{Q}.$$ Let $x_{m+1}=f(x_m)$. Show that $\forall x_0\in\mathbb{N_{>0}}\exists
> n\mid (f^m(x)=0\forall m\geq n)$ UPDATE I'm currently investigating whether Mahler's theorem and Newton's forward difference formula have something to say. Forward difference formula looks promising on the face of it but I haven't studied that in depth.","['p-adic-number-theory', 'abstract-algebra', 'number-theory', 'continued-fractions', 'convergence-divergence']"
2180401,Can any real function be expressed as sum of increasing and decreasing functions,"I want to know if any real function can be expressed as:
$f(x)=g(x)+h(x)$ such as $g(x)$ is an increasing function and $h(x)$ is a decreasing function?
thanks","['real-analysis', 'monotone-functions', 'functions']"
2180404,Proving the product rule for the formal derivative over $F[X]$,"I am trying to prove that the formal derivative of a polynomial in $F[X]$, defined by: $$P'(X) := \sum_{i \in \mathbb N}(i+1)a_{i+1}X^i$$
satisfies the product rule such that for the derivation operator $D$: 
$$D(P(X)*Q(X)) = D(P(X))* Q(X) + P(X)*D(Q(X))$$ I tried doing the proof, by using the definition of products of polynomials over $F[X]$ (Cauchy - Product) and started with: $$D(\sum_{j \in \mathbb N} (\sum_{i=0}^k a_ib_{k-i})X^j) = \sum_{j \in \mathbb N}(j+1)(\sum_{i=0}^{k+1} a_ib_{k-i})X^j$$ when I try simplifying further, I get lost at some point and I am not even sure whether or not this is the right approach to prove this, since it is pretty messy. Is there another easy way of proving this, and would this approach that I took work as well?","['derivatives', 'abstract-algebra']"
2180406,Area of the intersection of two cones,"I would like to find an expression for the area of the intersection of the two cones shown in the following figure: The axes of both cones are situated on the plane YZ, and the angles are respectively $\alpha_1$ and $\alpha_2$, while the angle of the intersection is $\theta$, as indicated in the picture. Obviously, I'm interested in the case when $\alpha_1+\alpha_2<\theta$, since otherwise there would be no intersection between the cones. My idea is to do it by integration on the sphere, but how can I find the limits I need for the integral?","['integration', 'geometry']"
2180424,On $\int_0^1\frac{\log^2(x)}{1+x^3}dx$ and $\zeta(3)$,"When I was playing with Wolfram Alpha about the integral $$\int_0^1\frac{x^{s-1}}{1+x^2}dx$$ and its derivatives, since I know the relationship between the Apéry's constant and particular values of the polygamma function, and since I  presume that this way will be known, I found playing with the code a closed-form for  this $$\int_0^1\frac{\log^2(x)}{1+x^3}dx$$
see this code integrate 1/(1+x^3)(log^2(x))dx, from x=0 to x=1 in the online calculator . I am not able to get easily the calculations for $$\int\frac{\log^2(x)}{1+x^3}dx$$ and after evaluate it as a definite integral. And you? Question. This can be a good integral for this friday. Can you prove the closed-form for $$\int_0^1\frac{\log^2(x)}{1+x^3}dx?$$ Thanks in advance.","['integration', 'definite-integrals', 'closed-form']"
2180428,Integral equation,"For any $f:\mathbb{R}\rightarrow \mathbb{R}$ is a continuous function, prove that $\int_0^4f(x(x-3)^2)dx=2\int_1^3f(x(x-3)^2)dx$. I tried many things, but nothing worked out. I observed that $g(x)+g(4-x)=4$ where $g(x)=x(x-3)^2$. Hence this action $x \rightarrow 4-x$ acts in some peculiar way. Please, any help would be great.","['real-analysis', 'definite-integrals', 'calculus']"
2180437,Why Cauchy's definition of infinitesimal is not widely used?,"Cauchy defined infinitesimal as a variable or a function tending to zero, or as a null sequence. While I found the definition is not so popular and nearly discarded in math according to the following statement. (1). Infinitesimal entry in  Wikipedia : Some older textbooks use the term ""infinitesimal"" to refer to a
variable or a function tending to zero Why textbooks involved with the definition is said to be old ? (2). Robert Goldblatt, Lectures on the Hyperreals: An Introduction to Nonstandard Analysis, P15
(His = Cauchy's) Why says 'Even'? (3). Abraham Robinson, Non-standard analysis, P276 why Cauchy's definition of infinitesimal, along with his 'basic approach' was superseded? Besides, I found most of the Real analysis or Calculus textbooks, such as Principles of mathematical analysis(Rudin) and Introduction to Calculus and Analysis(Richard Courant , Fritz John), don't introduce Cauchy's definition of infinitesimal, Why ?
Why Cauchy's definition of infinitesimal was unpopular and not widely used, and nearly discarded? P.S. I refered some papers still cannot find the answer.","['real-analysis', 'math-history', 'nonstandard-analysis', 'calculus', 'infinitesimals']"
2180456,Lie algebra of vector fields,"I have some conceptual confusion when thinking about the Lie algebra of a set of vector fields. Below, there are two questions which refer to the same problem, but from different viewpoints. Any comments/suggestions are greatly appreciated. Sorry if my questions appear silly. Let $V=\{V_i\}$, $i=1,\dots,m$ be a set of vector fields on a smooth manifold $M$, $dim(M)=n\ge m$. Let $L(V)$ be a non-involutive Lie algebra of vector fields $V$. For any $p\in M$, $L(V)$ is an infinite-dimensional group acting locally on some neighborhood $U(p)\subset M$ of $p$. Any group action can be seen as $\exp(t\cdot v):U(p)\rightarrow U(p)$, where $v\in L(V)$. Here comes my first problem. 
When we look at elements of $L(V)$, these are all vector fields. If we consider them is being elements of a vector space, these form an infinite dimensional set. However, vector fields belong to a more general object: a module over $C^\infty(M)$. As such, they form a finite-dimensional set. Thant is, we can always find a set of basis vector fields and express the remaining ones as linear combinations (over $C^\infty$) of the basis v.f.'s. I wonder, how infinite-dimensionality enters the picture? Is there something that cannot be expressed using a finite-dim. basis? When we think about the Lie algebra of a Lie group $G$, it is basically the same at each point $g\in G$. This is not true for the Lie algebra of vector fields. Would it make sense to speak about rank of the Lie algebra $L(V)$ at some point $p\in M$, to say that $p$ is a critical point of the Lie algebra etc? If so, how should we consider the rank of $L(V)$ at $p$? As the rank of vector fields $v\in L(V)$ at $p$? Obviously, it cannot be higher than $n$. So, again, we have an inf-dim set whose rank does not exceed $n$ locally.","['vector-bundles', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2180459,$p^{p+1}+(p+1)^p-1$ a perfect square,"For which primes $p$ is $$p^{p+1}+(p+1)^p-1$$ a perfect square? Context: Once again a modified problem, this time from $p^{p+1}+(p+1)^p$ a perfect square, for which the answer is no such $p$ exist.  For the modified form above, however, $p=2,3$ work, the main trouble I've had being that one can't easily find prime divisors of the above number that aren't already divisors of $p$ or $p+1$. Edit: I forgot to say that I have already tested this statement up to $p=19$ or as far as the calculators on a computer will go without finding any other examples apart from $2$ and $3$","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2180560,Functional equation $4f(x^2+y^2)=(f(x)+f(y))^2$,"Consider the following problem: Determine all functions $f:\mathbb{N}\rightarrow \mathbb{N}$ that satisfy the functional equation $$4f(x^2+y^2)=(f(x)+f(y))^2.$$ So first of all plugging in $x=0=y$, we get that $4f(0)=4f(0)^2$. Hence $f(0)=0$ or $f(0)=1$. Now using $x=1$ and $y=0$, we get that $f(1)^2+(2f(0)-4)f(1)+f(0)^2=0$. Thus $f(1)=2-f(0)+2\sqrt{1-f(0)}$. Hence if $f(0)=0$, then $f(1)=4$ and if $f(0)=1$, then $f(1)=1$. (Obviously we implicitly assumed that $f(1)\neq 0$.) Now notice that plugging in $x=y$ yields $f(2x^2)=f(x)^2$. Let's assume that $f(0)=0$ and $f(1)=4$ . Then also $4f(x^2)=f(x)^2$. From these equations we easily get that $f(2)=16, f(4)=\frac{f(2)^2}{4}=64, f(8)=f(2)^2=256$, and so on. So we can find $f(2^n)$ using these techniques. We see that $f(2^n)=4^{n+1}$. From this one could guess that $f(x)=4x^2$ is a solution. Corr-blimey, $f(x)=4x^2$ is a solution! Now notice that $f(x)=0$ is a solution, $f(x)=1$ is also a solution and $f(x)=4x^2$ is a solution. I guess that these solutions are actually determined by there values on $0$ and $1$ for which we already found all possibilities. But how to proceed? Again assume that $f(0)=0$ and $f(1)=4$ . We already know $f(2^n)$. How do we find $f(3)$? Well, notice that $4f(5)=4f(2^2+1^2)=(f(2)+f(1))^2=(16+4)^2=400$. Hence $f(5)=100=4\cdot 5^2$. Now using the Pythagorean triple $(3,4,5)$ we find that $10000=f(5)^2=4f(5)^2=4f(3^2+4^2)=(f(3)+f(4))^2=f(3)^2+128f(3)+64^2$. Solving this equation yields $f(3)=36=4\cdot 3^2$. Using the above procedure I can find the value of $f(n)$ for a lot of $n$, but I'm not sure whether I can find it for all $n$. There is probably some extra piece of information I'm missing, but I cannot find it. Suggestions are wellcome.","['algebra-precalculus', 'recreational-mathematics', 'functional-equations']"
2180608,Walking on a torus minimum distance,"I was imagining a problem, about a torus (in general a well behaved 3D object). Let us pick two arbitrary non-identical points $A$ and $B$ on the surface of the torus. How would I calculate the shortest path connecting both points? I don't know how to start this problem. I think I need to calculate the length of a path in 3D parametrized by $\boldsymbol{c}(t)$ ($\boldsymbol{c}(t=0)=A$,$\boldsymbol{c}(t=1)=B$) and then add the surface of the torus via Lagrange Multipliers. $$L=\int_{t=0}^{t=1}||\boldsymbol{c}(t)||dt+\lambda F,$$ in which $F$ would be the equation describing the surface of the Torus. Would that be an appropriate approach? I think that it would be necessary to pick a different coordinate system (e.g. torus coordinates). I know that the solution is not always unique.","['optimization', 'differential-geometry', 'calculus']"
2180630,"How to evaluate $\int_0^{\pi}\ln(2+\cos^6x)\,\mathrm dx$","How to evaluate
$$\int_0^{\pi}\ln(2+\cos^6x)\,\mathrm dx$$
I tried to let
$$I(a)=\int_0^{\pi}\ln(a+\cos^6x)\,\mathrm dx$$
so
$$I'(a)=\int_0^{\pi}\frac{1}{a+\cos^6x}\,\mathrm dx=2\int_0^{\pi/2}\frac{1}{a+\cos^6x}\,\mathrm dx$$
and let $\cos^2x=t$ we get
$$I'(a)=\int_0^1\frac{\mathrm dt}{(a+t^3)\sqrt{t}\sqrt{1-t}}$$
But I don't know how to go further. Any help will be nice!","['integration', 'definite-integrals', 'trigonometric-integrals', 'calculus']"
2180644,Find minimum of $y=\sqrt{-x^2+4x+12}-\sqrt{-x^2+2x+3}$,Find minimum of $y=\sqrt{-x^2+4x+12}-\sqrt{-x^2+2x+3}$ My work so far: 1) $$y =\frac{2x+9}{\sqrt{-x^2+4x+12}+\sqrt{-x^2+2x+3}} $$ 2) I used a derivative and found the answer ($y=\sqrt3$ at $x=0$). Is there any other way?,"['real-analysis', 'inequality', 'optimization', 'functions', 'maxima-minima']"
2180666,rupee and paise coins probability question,"Initially a bag was known to contain some one rupee ('0' or more) and some fifty paisa ('0' or more) coins. In all bag was known to have 4 coins. Two coins were randomly drawn from the bag and both found to be one rupee coin. If these coins are replaced, what is the probability that next drawn coin is fifty paisa coin ? (Assumption : Initially all number of rupee coins in the bag are equiprobable) My try : Let $P$ denotes $50 $ paise coin and $R$ represent $1$ rupee coin. So cases would be as follows $PPPP$ $PPPR$ $PPRR$ $PRRR$ $RRRR$ But as the question says there were $2$ $R$ coins so case $1.$ and $2$. get rejected.So remaining cases are $3$.
So getting paise coin probabillity can be written as $\frac{1}{3}$.$\frac{2}{4}$ (case 3) + $\frac{1}{3}$.$\frac{1}{4}$ (case 4). i.e $\frac{1}{4}$ but answer is $\frac{1}{8}$ I think my method is wrong. Please help.",['probability']
2180685,Find matrix $P$ such that $P^{-1}AP=B$,"Given $$A = \begin{bmatrix}
1 & 0 & 0 \\
0 & 2 & -3 \\
1 & 3 & 2 \end{bmatrix}$$ $$B= \begin{bmatrix}
1 & 0 & 0 \\
0 & 2 & -3 \\
0 & 3 & 2 \end{bmatrix}$$ find $P$ such that $P^{-1} A P = B$. Firstly I said that $AP=PB$ Solved the 9 equations in 9 unknowns. and got that: $$P= \left( \begin{array}{ccc}
-10x & 0 & 0 \\
3x & y & z \\
x & -z & y \end{array} \right)$$ Then I used computer to find $P^{-1}$ in terms of those unknowns and plugged it back in to $P^{-1}AP=B$ Compared the coefficients and i end up with 
$B= \left( \begin{array}{ccc}
1 & 0 & 0 \\
-z/10x & 2 & -3 \\
1-y/10x & 3 & 2 \end{array} \right) $ Set $x=1$, $y=10$, $z=0$ and indeed $P^{-1}AP=B$ The doubts I am having is the fact that P is not unique. I could set x,y,z to different numbers. Can anyone explain this? Thank you.","['matrices', 'matrix-equations', 'linear-algebra']"
2180688,"Find all pairs of prime numbers $p$ and $q$ such that $\,p^2-p-1=q^3.$","I'm preparing a mathematical olympiad and our group is stuck in this problem. Here is all we've done: First, let's rewrite the equation
$$p^2-p-1=q^3\Rightarrow p(p-1)=(q+1)(q^2-q+1)$$
It's obvious that $q$ must be less than $p$. Then, $p|(q^2-q+1)$ and then equation is of the form
$$p-1=k(q+1)$$
For some integer $k$. Putting that onto the first equation
$$\left(\frac{p-1}{k}-1\right)^3=q^3=p^2-p-1$$
Which is the same as
$$p^2-(2+3k+k^3)p+(3k^2+3k+1)=0$$
Since $p$ is prime $p|3k^2+3k+1$, a possible solution is $p=3k^2+3k+1$. Substituting
\begin{align*}
(3k^2+3k+1)^2-(2+3k+k^3)(3k^2+3k+1)+3k^2+3k+1=-k^2(k-3)(3k^2+3k+1)=0
\end{align*}
$k$ cannot be 0, so it's unique possible integer value is $3$ and $p=37$. Solving, $q=11$ which is a valid solution but we don't know if there are more or how to prove there aren't more, please help us continue.","['number-theory', 'contest-math']"
2180737,A hard integral,"Looking for a solution for an integral:
$$I(k)=\int_0^{\infty } \frac{e^{-\frac{(\log (u)-k)^2}{2 s^2}}}{\sqrt{2 \pi } s \left(1+u\right)} \, du .$$
So far I tried substitutions and by parts to no avail.","['normal-distribution', 'calculus', 'probability-distributions', 'definite-integrals', 'gamma-function']"
2180755,"Is there a way to ""proof"" the Wirtinger derivates?","I'm a bit confused about the wirtinger derivates, as I understand they define: $$df/dz := 1/2 (df/dx - idf/dy)$$ and $$df/d\bar z := 1/2 (df/dx +idf/dy)$$ Is there actually a way to derive a holomorph function with $d/d\bar z$, as of the limes definition of the derivate?
Or is it just that there are there some benefits if we introduce the operater $d/d\bar z$ defined like that? If so what does this enable us to do?","['derivatives', 'complex-analysis', 'proof-explanation']"
2180759,Scale dependence of Voronoi path length,"Consider a square of fixed size in Euclidean space. Assume the square has been decomposed into Voronoi blocks of a certain average area. Now assume you can only move along the edges of the Voronoi diagram, and you want to cover a certain distance in the embedding space. Is there a result on how your minimum path length along teh Vornoi edges depends of the fineness of the Voronoi decomposition (i.e. on the average size of the blocks)? Update: 
To make this more specific, consider the following example: I have three Voronoi decompositions of average edeg length 0.3, 0.1 and 0.02, and I'm interested in the lengths of the red paths, i.e. the expected minimum path length. In the example, the paths are about the same length, but I don't know whether there is a more general statement known. I have a feeling the the larger cells have fewer longer detours, while the smaller cells have more shorter ones, and the effects cancels out, to some extent. I assume a ""reasonably uniform"" point distribution, and the Voronoi cells are much smaller that the surrounding square, so the sides of the square should not have a major influence.","['voronoi-diagram', 'geometry']"
2180782,Open subset with non-acyclic structure sheaf,"Let $X$ be a projective algebraic variety with acyclic structure sheaf, can we find an open set $U\subset X$, which is the complement of a divisor, such that $\mathcal{O}_U$ is not an acyclic sheaf?","['sheaf-theory', 'algebraic-geometry']"
2180831,How to characterize functions that map convex sets to convex sets?,"Let $f: \mathbb{R}^n \to \mathbb{R}^n$. What is a necessary and sufficient condition for the following? If $C$ is a convex subset of $\mathbb{R}^n$, then so is $f(C)$. It's easy to find various sufficient conditions (I won't attempt an exhaustive list here), but I've been unable to find interesting necessary conditions. If it helps, I'm happy to assume that $C$ is closed and/or bounded. If a necessary and sufficient condition is known for $\mathbb{R}^n$, can it be extended to general vector spaces? Alternatively, if such a condition is unknown, could someone explain why the problem is difficult?","['reference-request', 'real-analysis', 'convex-analysis']"
2180850,Combinatorics tennis match,"The prompt says, a tennis club has to select 2 mixed double pairs from a group of 5 men and 4 women. In how many ways can this be done? There's total of 9 people and we need to choose of 8 people, that's what I think ""2 mixed double pairs"" means since one pair is 2 people and 2 double pairs would mean 2 * 4 = 8 people so I simply did 9 choose 8","['combinatorics', 'discrete-mathematics']"
2180851,evans book pde estimate question,"I'm reading Evans' book on PDE and I'm having troubles understanding one estimate. He defines the fundamental solution to Laplace' equation as $$
\Phi(x) = \begin{cases} -\frac{1}{2\pi} \, \log(|x|), \, & n=2, \\ \frac{1}{n \, (n-2) \, \omega_n} \, \frac{1}{|x|^{n-2}}, \, & n\geq 3, \end{cases} $$ where $\omega_n$ is the volume of the $n$-ball. For the solution of Poisson's equation $ -\Delta u = f$ he computes the Laplace acting on the convolution of $f$ and $\Phi$, involving this estimate: $$ \bigg|\int_{B(0,\varepsilon)} \Phi(y) \, \Delta_y f(x-y) \, dy \bigg| \leq C \, \lVert D^2f \rVert_{L^\infty} \int_{B(0,\varepsilon)} |\Phi(y)| \, dy \leq \begin{cases} C \, \varepsilon^2 \, |\log(\varepsilon)|, & n=2, \\ C \, \varepsilon^2, & n\geq 3. \end{cases} $$ How do you obtain the last inequality?","['multivariable-calculus', 'calculus', 'partial-differential-equations']"
2180913,How to concretely find the characters and pure states of $L^\infty$?,"Let $(X, \mathcal X, \mu)$ be a space with measure. Out of curiosity I was trying to understand what the Gelfand-Naimark theorem and Glimm's abstract Stone-Weierstrass theorem give when applied to the $\Bbb C$ $*$-algebra $L^\infty(X,\mu)$. Sadly, I had to give up: given that its elements are not functions with pointwise values, how can I find the pure states and characters of $L^\infty$ (i.e see how they look like concretely)?","['c-star-algebras', 'banach-spaces', 'banach-algebras', 'functional-analysis', 'lp-spaces']"
2180914,Necessary and sufficient condition for real analyticity,"I am trying to prove the following result: Let $f:\mathbb{R}\to\mathbb{R}$ be infinitely differentiable. If $f$ is analytic at $a$ , then there is a ball $B_r(a)$ for which: $$\lim_{n\to\infty} M_n\frac{r^n}{n!}<\infty$$ where $M_n:=\sup\{|f^{(n)}(x)|:x\in B_r(a)\}$ . I know that the converse is true. I have the feeling that it is too good to be true, but I really don't know how to prove it. Any ideas? Thanks!","['real-analysis', 'taylor-expansion', 'power-series']"
2180929,"Orthogonal Trajectories Using Polar Coordinates. Correct Calculations, Two Different Answers?","My textbook, George F. Simmons' Differential Equations with Applications and Historical Notes, asks to find the orthogonal trajectory of the family of curves $r = 2Ccos(\theta)$ where C is a parameter. The original equation of the family of curves was $x^2 + y^2 = 2Cx$ , but it led to an equation that was as yet unsolvable using the methods taught by the textbook up to that moment. $^*$ To compensate, the textbook switched to polar coordinates and started solving it that way, which was what I have shown in the calculations below. $*$ For further elaboration, the authors got $\dfrac{dy}{dx} = \dfrac{2xy}{x^2 - y^2}$ from $x^2 + y^2 = 2Cx$ . They then said, ""Unfortunately, the variables cannot be separated, so without additional techniques for solving differential equations we can go no further in this direction. However, if we use polar coordinates, the equation of the family can be written as $r = 2Ccos(\theta)$ "". And then they continue with their calculations, as stated below. The solution that I am getting is different from that of the textbook. All of the (similar) previous problems that I have completed have been correct, so if there are errors in my understanding of this concept, I cannot detect them. My Solution $r = 2Ccos(\theta)$ $\dfrac{dr}{d\theta} = -2Csin(\theta)$ We need to eliminate the arbitrary constant $C$ because we don't just want the orthogonal trajectory for a single curve -- we want the orthogonal trajectories for the entire family of curves; therefore, we want $\dfrac{dr}{d\theta}$ in terms of $r$ and $\theta$ . $\dfrac{r}{2\cos(\theta)} = C$ $\therefore \dfrac{dr}{d\theta} = -2\left( \dfrac{r}{2cos(\theta)} \right) sin(\theta)$ $= \dfrac{-rsin(\theta)}{cos(\theta)}$ The orthogonal trajectories will have a slope which is the negative reciprocal of the slopes of the family of curves: $\therefore \dfrac{-d\theta}{dr} = \dfrac{-rsin(\theta)}{cos(\theta)}$ $\implies \dfrac{d\theta}{dr} = \dfrac{rsin(\theta)}{cos(\theta)}$ $\implies \dfrac{dr}{d\theta} = \dfrac{cos(\theta)}{rsin(\theta)}$ $\implies dr(r) = \dfrac{cos(\theta)}{sin(\theta)} (d\theta)$ And we can now proceed with separation of variables... Textbook's Solution $r = 2Ccos(\theta)$ $\dfrac{dr}{d\theta} = -2Csin(\theta)$ After eliminating C we arrive at $\dfrac{rd\theta}{dr} = \dfrac{-cos(\theta)}{sin(\theta)}$ as the differential equation of the given family. Accordingly, $\dfrac{rd\theta}{dr} = \dfrac{sin(\theta)}{cos(\theta)}$ is the differential equation of the orthogonal trajectories. In this case, the variables can be separated, yielding $\dfrac{dr}{r} = \dfrac{cos(\theta) d\theta}{sin(\theta)}$ And it then proceeds with integration ... I'm wondering if both solutions (mine and the textbook) are correct? Or have I made an error? If I've made an error, I would appreciate it if people could please take the time to carefully explain the reasoning behind it. I have only just begun studying differential equations (chapter 1), so any explanation would have to be very elementary.","['ordinary-differential-equations', 'polar-coordinates']"
2180932,"How many ways can a slate of 4 (distinct) officers from 20 people, etc.","In how many ways can a slate of 4 officers (president, vice-president, secretary, treasurer) be selected from among 20 people? $$4! {20 \choose 4}$$ In how many ways can a committee of three be selected from among 10 people? $$3! {10 \choose 3}$$ I wanna make sure I'm doing the questions above correctly, any feedback is greatly appreciated","['statistics', 'probability']"
2181021,A non-Hausdorff space with a Hausdorff subspace [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Can anyone give an example of a non-Hausdorff space that contains a Hausdorff subspace?","['general-topology', 'examples-counterexamples', 'separation-axioms']"
2181026,Set Theory Contradiction Proof Verification,"Let A, B and C be subsets of a universal set U. Prove by contradiction that $$A\cap B \subseteq C \to (A-C)\cap B = \emptyset$$ Suppose otherwise, $A\cap B\subseteq C \land (A-C)\cap B \neq \emptyset$. 
Let $n\in A$, then by definition of the subset, $n\in C$. Since $n\in A \land n\in C, n\not \in (A-C)$, by definition of the set difference, this means $(A-C)= \emptyset$. Therefor, $n\not \in (A-C)\cap B$, by definition of the intersection. Thus, by definition of the empty set, $(A-C)\cap B = \emptyset$. This is a contradiction. Thus, $A\cap B \subseteq C \to (A-C)\cap B = \emptyset$ must be true. Can someone tell me whether I did this right. I think it makes sense, but it also seems like I made a mistake somewhere because it seems too easy and short. Thank you.","['proof-writing', 'elementary-set-theory', 'proof-verification']"
2181032,Interpretation of the second continous group cohomology,"In regular group cohomology theory, it is well known that $\mathrm{H^2(G,A)} \cong \mathrm{Ext(G,A)}$, where $\mathrm{Ext(G,A)}$ denotes the class of all groups $\mathrm{U}$ which make the following sequence exact: $$\mathrm{0 \rightarrow A \rightarrow U \rightarrow G \rightarrow 1}$$
and the action of $\mathrm{G}$ on $\mathrm{A}$, is the same as the conjugation by the corresponding element from $\mathrm{U}$. What about the case when $\mathrm{G}$ is a pro-finite group and one considers $\mathrm{H_{cont}^2(G,A)}$ instead of the regular cohomology? Is there a similiar interpretation to the above isomorphism, say, for example, the class of groups $\mathrm{U}$ with the same property but with continous arrows? In other words, may one writes something like that $\mathrm{H_{cont}^2(G,A)} \cong \mathrm{Ext_{cont}(G,A)}$ (If the right object really exist)? I am familiar with the relation to Brauer groups, but I like to work with group extensions. Thank you!","['group-cohomology', 'profinite-groups', 'group-theory', 'galois-cohomology']"
2181062,"Composition of linear functions, but backwards?","Is it true that if a composition of functions is linear, then the two functions it is composed of are also linear? ie. $f_i(x) = g_i(T(x))$, where $f_i$ is linear. Does this imply $T$ is linear? 
For this specific question, we also have $g_i$ is linear.",['linear-algebra']
2181092,Re-sample a sparse matrix - keeping row- and column-sums constant,"Lets say I have a square matrix $A_{n\times n}$. It is a sparse matrix and let's assume that it only holds 0's and 1's. I wish to generate another matrix $B_{n\times n}$ with the following properties: All the row-sums and column-sums (or equivalently, the norms) are kept constant, i.e equal between $A$ & $B$. None of the 1's are in the same location in $B$ as they were in $A$. The diagonal elements of $B$ are all zero (this is also true of $A$). So basically, I want to re-sample a matrix (or a set of matrices $B_{i}$) that keeps that above resemblance and difference with $A$. Of course there are no guarantees that this actually have a solution, but given a high level of sparsity and favorable distribution of the 1's, It should be possible. The matrix correspond to a social network with unidirectional connections between the $n$ users ($a_{ij}$ 'likes' $a_{kl}$), and I need to sample a new network over the $n$ users that keeps the distribution of 'likes' and 'is liked by' constant over the users. Anyone with an idea of how to systematically generate this? I guess I could brute force it, moving the connections around and test for validity. But there might be some theoretical framework to formalize the process a bit.","['combinatorics', 'statistics', 'linear-algebra', 'graph-theory']"
2181101,Why do Markov chains converge exponentially quick?,"Let $G$ be a finite group, $q$ a probability mass function (pmf) on $G$ and $u$ the uniform pmf on $G$. We use the convolution product
$$
q^{(k)}(\sigma) = \sum_{\alpha \beta =\sigma} q^{(k-1)}(\alpha)q(\beta)
$$
and the $L^1$ distance between $q^k$ and $u$
$$
d(k) := || q^{(k)}-u || = \sum_{\sigma \in G} |q^{(k)}(\sigma) - u(\sigma)|.
$$
Thus (see note below) $q^{(k)}$ is the distribution of the Markov chain on $G$ associated to $q$ at the $kth$ step and $d(k)$ is its rate of convergence. Question: It is stated, as an observation here (Diaconis and Saloff-Coste, 1995, page 3), that $d$ is submultiplicative. This means that $d(n+m) \le d(n)d(m)$. Why is it true? The observation is quite interesting: it implies an at least exponential rate of convergence (we can assume $q^{(k)}$ converges to $u$). Notes. The Markov chain on $G$ associated to $q$ is defined as follows. Given a current state $x_n\in G$, the transition probability to $x_{n+1}$ is $q(x_n^{-1}x_{n+1})$. It can be checked that $q^{(k)}$ is the distribution of this chain at the $k$th step when starting at the identity. The problem could be formulated for general Markov chains, but I wanted to stick with the notations of the technical report.","['random-walk', 'markov-chains', 'probability-theory']"
2181105,poincaré inequality direct proof,"I don't understand an estimate in my textbook, maybe you can help me out! Lemma (Poincaré's inequality). Let $Ω ⊂ (0,L) × \mathbb R^{n−1}$. For $u ∈ C^\infty_c(Ω)$ we have the estimate $$
\int_Ω |u|^2\, dx ≤ L^2 \int_Ω |∇u|^2 \, dx.$$ Proof. Extend $u$ with $u(x) = 0$ for $x \not \in Ω$. For $x = (x^1,x′) ∈ Ω$ estimate $$ |u(x^1,x')|^2 = \bigg|\int_0^{x_1} \frac{\partial u}{\partial x_1} (s,x') \, ds \bigg|^2 \leq \bigg(\int_0^L \bigg|\frac{\partial u}{\partial x_1}(s,x')\bigg| \, ds \bigg)^2 \leq L \int_0^L |\nabla u(s,x')|^2 \, ds.$$ Then it follows $$ \int_\Omega |u|^2 \, dx \leq \int_{\mathbb R^{n-1}} \int_0^L |u(x_1,x')|^2 \, dx_1 \, dx' \leq \int_{\mathbb R^{n-1}} L^2 \int_0^L |\nabla u(s,x')|^2 \, ds \, dx' \leq  L^2 \int_\Omega |\nabla u|^2 \, dx.$$
$\Box$ I very well understand the first inequalities, via Hölder's inequality. But in the second line i don't understand where the second $L$ comes from. And shouldn't the last inequality be an equality?","['functional-analysis', 'inequality', 'multivariable-calculus']"
2181108,Mechanical Surface Integrator,"In an episode of ""Dirty Jobs"" Mike Rowe visited a tannery where they used an old mechanical device to calculate the surface area. Video shown [here] How is it calculating the surface area? Is it doing Riemann sum as it passes through with the width being the distances between the wheel, or is doing an operation similar to a planimeter [ link ] with an application of Green's Theorem? (Or some other mechanism?)",['integration']
2181120,"Fibonacci Numbers proof, circular reasoning?","I got this from "" Number Theory "" by George E. Andrews (1971), at the end of the first chapter, he asks for proofs by mathematical induction about Fibonacci Numbers as exercices. In one of them I am asked to show that $$(\forall \, n \in \Bbb Z^+)((F_{n+1})^2-F_nF_{n+2}=(-1)^n)$$ which has already has been asked on Math S.E.: "" Fibonacci numbers and proof by induction "" but I am not looking for a complete solution here; rather, since I am learning the subject on my own I would appreciate it if someone could simply tell me if my reasoning is correct, it does not ""feel"" concrete to me. Going through the usual steps I first check  that the base case $F_2^2-F_1F_3=1-2=(-1)^1$ is true such that the inductive step can be taken. Then, assuming $(F_{k+1})^2-F_kF_{k+2}=(-1)^k$ is true, I try to show that it implies that $(F_{k+2})^2-F_{k+1}F_{k+3}=(-1)^{k+1}$ is also true. Then, doing a bit of algebra I get, $$\begin{align}
(F_{k+2})^2-F_{k+1}F_{k+3} & = (-1)^{k+1}=(-1)^k(-1)\\
& = ((F_{k+1})^2-F_kF_{k+2})(-1)\\
& = F_kF_{k+2}-(F_{k+1})^2\\
(F_{k+2})^2-F_{k+1}F_{k+3} + (F_{k+1})^2-F_kF_{k+2} & = 0\\
(F_{k+2})^2-F_{k+1}F_{k+3} + (-1)^k & = 0\\
(F_{k+2})^2-F_{k+1}F_{k+3} & = -(-1)^k = (-1)(-1)^k\\
& = (-1)^{k+1}\\
\end{align}$$
$$\tag*{$\blacksquare$}$$ I am not sure about this, it feels like circular reasoning, is it? Thanks a lot for the valuable input!","['number-theory', 'induction', 'fibonacci-numbers', 'proof-verification']"
2181146,"Computing a double integral by method of change of variables. I am having trouble determining a valid diffeomorphism that ""works"".","I am trying to compute the integral $$\iint_{R} sin(9x^2 + 4y^2) dA$$ where R is bounded by the region $9x^2 + 4y^2 = 36$, by the change of variables method. I am having trouble determining the proper transformation $G: \mathbb{R^2} \to R$ so that I can perform my change of variables. I have tried expressing the ellipsoid by transforming it into a circle (with radius 1) but that did not get me anywhere and hence I am really stuck. I'd appreciate any hints or ideas on how to approach these problems. More so, any general advice that you may have for finding a good transformation/diffeomorphism that works for the change of variables. Thanks!",['multivariable-calculus']
2181155,Intuition for shape operator in local coordinates in terms of first and second fundamental forms,"In section 3-3 of do Carmo's Differential Geometry of Curves and Surfaces the author proves the following (formula (3) on page 155). Let $\bf x$ be a parametrization of a surface embedded in $\mathbb R ^3$. Let $N=\frac{\mathbf x_u \wedge \mathbf x_v}{\|\mathbf x_u \wedge \mathbf x_v\|}$ and let $A$ be the matrix representing the shape operator endomorphism $\mathrm d_pN$ w.r.t the basis provided by $\bf x$. Furthermore, let $\mathrm I,\mathrm I\!\mathrm I$ respectively denote the matrices representing the first and second fundamental forms w.r.t the same basis. Then $-\mathrm I\!\mathrm I=\mathrm I A$. The proof seems to just be about rearrangement, but I feel I'm missing geometric content. Is there a conceptual explanation for this formula? Is there a conceptual proof for a general embedded oriented hypersurface in Euclidean space? Added. Just to be clear, the rigorous conceptual definition of the Gauss map of an embedded oriented hypersurface $\iota:H\rightarrowtail V$ in an inner product space $V$ that I have in mind is the composite 
$$H\overset{\mathbf n}{\longrightarrow}(\mathrm TH)^\perp \longrightarrow\iota^\ast (\mathrm TV)\overset{\iota ^\ast \jmath}{\longrightarrow} H\times V\overset{\pi _2}{\longrightarrow}V$$
where $\bf n$ is the normal vector field and $\jmath$ is the canonical trivialization of the tangent bundle of $V$ itself.","['intuition', 'smooth-manifolds', 'differential-geometry', 'surfaces']"
2181156,"Prove that $\lim_{t\rightarrow\infty}\int\limits_1^2\frac{\sin(tx)}{x^2\sqrt{x-1}}\,dx=0$","Prove that $$\lim_{t\rightarrow\infty}\int\limits_1^2\frac{\sin(tx)}{x^2\sqrt{x-1}}\,dx=0$$ I'm hoping there's some better way to go about this other than bounding the integral by $\int\frac{1}{x^2\sqrt{x-1}}\,dx$, because that integral seems to require two substitutions. Is there?","['real-analysis', 'integration', 'limits']"
2181158,Determining stability of ODE,"I'm working on a prey-predator model. I'm using the following system of differential equations for it:
\begin{align} x'&=-a_1x+a_2xy+a_3xz\\
y'&=b_1y-b_2xy\\
z'&=c_1z-c_2xz
\end{align}
Where $a_i, b_i, c_i >0$. One of the stationary points is $P=(\frac{b_1}{b_2},\frac{a_1}{a_2},0)$. Question : 
How can I determine the stability of this point $P$? Attempt : First I wrote the equation as:
\begin{align} \frac{\mathrm d \underline{v}}{\mathrm d t}=\underline{F}(\underline{v}), \hspace{10pt} \underline{v}=(x,y,z)\end{align}
I looked at the linearized ODE, and I found:
\begin{align} \frac{\mathrm d \underline{\hat{v}}}{\mathrm t}=
\begin{pmatrix} 
0 & \dfrac{a_2b_1}{b_2} & \dfrac{a_3b_1}{b_2}\\
-\dfrac{a_1b_2}{a_2} & 0 & 0 \\
0 & 0 &c_1-\dfrac{c_2b_1}{b_2}\\
\end{pmatrix}
\underline{\hat{v}}
\end{align}
The eigenvalues are $c_1-\dfrac{c_2b_1}{b_2}, \pm i \sqrt[]{a_1b_1}$. My problem is the pair with zero real part. I have learned a theorem that only says something when all eigenvalues have negative real part (then it's stable) or at least one has positive eigenvalue (then it's unstable). My other approach was Lyapunov's theorem. I found (with a little bit puzzling) the following Lyapunov function:
\begin{align}V(x,y,z) = a_2y+ b_2x  -a_1\left(1+\ln (y)-\ln\left(\frac{a_1}{a_2}\right)\right)-b_1\left(1+\ln(x)-\ln\left(\frac{b_1}{b_2}\right)\right)  \end{align}
Differentiating it brought me eventually to this:
\begin{align} V'=a_3b_2xz-a_3b_1z\end{align}
Now the only thing that I can say is that $V'$ is both positive and negative in every neighborhood of $P$, so the theorem doesn't say something about that case. What I also thought about is to Taylor approximate the function $F$ till the second order term, like it can be done with one-dimensional ODE if the first derivative is equal to zero. But then here I get a matrix in a matrix (a tensor?) which is pretty vague. I can not visualise what is going on there, but if someone can explain how to do it that way, then you are welcome. I have read many articles about this problem on internet. I couldn't find something useful/understandable. Some are talking about manifolds, but I have not learned that yet. What I understand is that it is something like a solution curve. I really couldn't sleep well because of this problem. Your help is appreciated! Thanks in advance. Update I have realised that the function $V$ that I have used missed an imortant requirment, it was $0$ in all points $(\frac{b_1}{b_2},\frac{a_1}{a_2},z)$, so that was not a Lyapunov function. My new approach was to pick:
\begin{align} V(x,y,z)=\left(x-\frac{b_1}{b_2}\right)^2+\left( y-\frac{a_1}{a_2}\right)^2+z^2\end{align}
Okay, this one is Lyapunov for sure. I differentiate w.r.t. $t$ and get:
\begin{align} V'=(-a_1x+a_2xy+a_3xz)\left(x-\frac{b_1}{b_2}\right) + (b_1y-b_2xy)\left( y-\frac{a_1}{a_2}\right) +z(c_1z-c_2xz)
\end{align}
This is zero in $(x,y,z)=P$ but that is also a saddle point, which means that is both negative and positive in every neighborhood of $P$. I also tried some Lyapunov functions of the form:
\begin{align} V(x,y,z)=f(x-\frac{b_1}{b_2})+g(y-\frac{a_1}{a_2})+h(z)\end{align} 
where $f,g,z$ are all even functions that has minimum in zero. Examples that I have tried are: $-\cos(x), -e^{-x^2}$ and they also made $V'$ have a saddle point in $P$. I also transformed everything to cilindar coordinates, but the equation that I have got was not so beautiful. I believe there is a way to prove the stability of this point. Can you guys help me? I really don't know what to do after this.","['stability-in-odes', 'ordinary-differential-equations', 'nonlinear-system', 'systems-of-equations']"
2181180,"Exercise solutions for ""3264 and all that""","Please excuse, that this is not exactly a math question, but I do not know of a better forum to ask publicly and I do not want to contact the authors of the abovementioned book before having asked the public: In the book ""3264 and all that"" by Eisenbud and Harris, in Chapter 0, page 8, it is said that Francesco Cavazzini prepared solutions for the exercises in the book, which appear on a web site associated to the book. Unfortunately I was not able to locate this website or another place in the web, where these solutions are given. Does anyone know, where they can be found?","['reference-request', 'algebraic-geometry']"
2181186,Are all finite dimensional algebras over the real numbers `Banach algebra'-able,"Suppose that $A$ is a finite dimensional algebra over the real or complex numbers. Then $A$ has a natural topology induced from it being a finite dimensional vector space. Is it always true that there is a norm on $A$ satisfying $\| MN \| \leq \| M \| \| N \|$, or are there some finite dimensional algebras which aren't `Banachable'? If we weaken the norm to not being complete, do we obtain stronger results?","['functional-analysis', 'banach-spaces', 'banach-algebras']"
2181205,Help understanding AM-GM use.,"So I was reading the solution of the following problem. A $100X100$ array is filled with numbers from ${1,2,...,100}$ ,such that each number appears exactly 100 times.Prove that there is some row or column which contains atleast 10 different numbers. In the solution it says that we can prove through AM-GM that each number appears in at least 20 rows-columns.I have proved this another way but i can't find how to apply AM-GM.
Any help will be appreciated.","['combinatorics', 'a.m.-g.m.-inequality', 'discrete-mathematics']"
2181219,How do I get rid of the radical in the denominator of $\lim\limits_{x \to -9} \frac{x+9}{\sqrt{x+9}}$?,$\lim\limits_{x \to -9} \frac{x+9}{\sqrt{x+9}}$ I know the answer is $0$ from looking at the graph but I want to know how to solve this algebraically. I tried to use L'hopital's rule but that doesn't get rid of the radical in the denominator. Then I tried to multiply the top and bottom by $\sqrt{x+9}$ and after trying to cancel stuff out I still ended up with an $x+9$ in the denominator. The I tried to split up the limit by taking the limit of the numerator and putting that over the limit of the denominator and then put the limit in the denominator inside the radical but I would still get $0$ in the denominator. What method am I suppose to use to solve this?,"['calculus', 'limits']"
2181245,Limit of $2^x\log{(1+2^{-x})}$,"With l'hopital's rule I can show that $f(x)=2^x\log{(1+2^{-x})}$ goes to $1$ as $x$ goes to $\infty$. What I intuitively don't get though is why apparently $2^x$ and $\log{(1+2^{-x})}$ exactly balance each other such that the limit to $\infty$ is $1$. For example, if the base of the first term would be slightly higher, then the limit would go to $\infty$. Any hints for the intuition of this result?",['limits']
2181304,An alternative formula for computing curvature of a curve,"Didn't mean to bother you, but I don't know exactly what is going on here, I'm trying to have a grasp on proving the following formula: $\displaystyle \kappa = \frac{\Vert\dot \gamma \times \ddot \gamma\Vert}{\Vert\dot \gamma\Vert^3}\quad$ where $\kappa$ stands for curvature, and $\gamma$ is a parameterised curve of time $t$. Here I upload an extract of what I'm attending atm. In line $4$, the third identity what has exactly been done by author? Are we allowed to do such things in elemantary calculus? I mean sending $ds$ of $d/ds$ into the numerator of $\displaystyle \frac{d\gamma/dt}{ds/dt}$ and pulling its $dt$ back where $ds$ was, without even touching the denominator?! And the funny thing is after applying this substituting, $d/dt$ became the operator operating only on the numerator, and not the denominator. Am I missing something?! Another proof of this would also be much obliged ;-)","['multivariable-calculus', 'curves', 'differential-geometry', 'curvature']"
2181327,Eigenvalues of the Frobenius-Perron Operator,"Say I have a map ${\bf X}_n = {\bf F}({\bf X}_{n-1})$, ${\bf X_n} \in \mathbb{R}^N$.
The Frobenius-Perron operator $L$ transfers the probability measure in phase space according to the dynamics defined by the map, ${\bf F}$. That is, 
$L \mu_n = \mu_{n+1}$, where $\mu_n$ is the probability distribution in phase space at time $n$. $\mu_0$ is the initial distribution. We know that the map has an invariant measure $\mu$. In other words, $L$ has an eigenvalue 1 with eigenfunction $\mu$. My question is: under what conditions,
(on ${\bf F}$ and $L$) will $L$ have an at most countably infinite set of eigenvalues?  I know that compact operators on separable Hilbert spaces can be shown to have at most countably infinite set of eigenvalues but I have never studied the space of measures formally and am not sure how to think about this. Thank you very much for your time!","['dynamical-systems', 'chaos-theory', 'measure-theory']"
2181336,What's the intuition behind sub gaussian's moment?,"In Vershynin's book about high dimensional probability: http://www-personal.umich.edu/~romanv/teaching/2015-16/626/HDP-book.pdf , Proposition 2.5.2 states that $X$ is a sub gaussian r.v. iff, for some $K_1$, the tail of $X$ satisfies $\mathbb{P}\{|X|>t\}\leq2\exp(-t^2/K_1),~\forall t\geq0$ or equivalently, for some $K_2$, the moment of $X$ satisfies $||X||_p=(\mathbb{E}|X|^p)^{1/p}\leq K_2\sqrt{p}$ The first property is evident from the pdf of gaussian, but the second property is not really clear. Though it can be shown that the moment of the standard gaussian is $O(\sqrt{p})$, it does not really tell why it is $\sqrt{p}$.","['probability-theory', 'probability', 'concentration-of-measure', 'statistics']"
2181367,Rank of the $n \times n$ matrix with ones on the main diagonal and $a$ off the main diagonal,"I want to find the rank of this $n\times n$ matrix
\begin{pmatrix}
1 & a & a & \cdots & \cdots & a \\
a & 1 & a & \cdots & \cdots & a \\
a & a & 1 & a & \cdots & a \\
\vdots & \vdots & a& \ddots & & \vdots\\
\vdots & \vdots & \vdots & & \ddots & \vdots \\
a & a & a & \cdots  &\cdots & 1
\end{pmatrix} that is, the matrix whose diagonals are $1's$ and $a$ otherwise, where $a$ is any real number. My first observation is when $a=0$ the rank is $n$ and when $a=1$ the rank is $1.$ Then I can assume $a\neq 0, 1$ and proceed row reduction to find its pivot rows. I obtain \begin{pmatrix}
1 & a & a & \cdots  & a \\
0 & 1+a & a & \cdots & a \\
0 & a & 1+a & \cdots & a \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & a & a & \cdots  & 1+a
\end{pmatrix}
by subtracting the first row multiplied $a$ for each row below the first, and then divides the factor $(1-a)$, 
and stuck there. Any hints/helps?","['matrices', 'symmetric-matrices', 'matrix-rank', 'linear-algebra']"
2181402,Prove $\partial (A \cup B)\subset \partial A\cup\partial B$,"How to use this definition of boundary: ""any open ball centered at a boundary point of a set $A$ intersects both $A$ and $A^C$"" to prove $\partial (A \cup B)\subset \partial A\cup\partial B$? I tried by arguing that it is equivalent to: $\partial (A \cup B)\subset \partial A$ or  $\partial (A \cup B)\subset \partial B$. And assume  $\partial (A \cup B)\not\subset \partial A$ then we need to show $\partial (A \cup B)\subset \partial B$ must hold. I don't know how to use the definition to prove this.","['general-topology', 'real-analysis', 'analysis']"
2181427,Quotient of plane set embeds in $\mathbb R ^3$?,"Let $X\subseteq \mathbb R ^2$ be a compact subspace of the plane.  Let $A\subseteq X$ be closed.  It is well-known that the quotient $X/A$ is metric and separable, and therefore embeds into the Hilbert space $\mathbb R^\omega$. Does it embed into $\mathbb R ^3$?  It seems like the answer should be yes. EDIT: The Menger-Nöbeling theorem (1932) states that if X is compact metric separable and of dimension n, then it embeds as a subspace of Euclidean space of dimension 2n + 1.  So the answer to my question is yes if $X$ is a 1-dimensional.  But of course $X$ could have dimension $2$...",['general-topology']
2181446,Does the series $\sum_{n=1}^{\infty}\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n+x}}$ represent a well-known function?,"Consider the function series 
$$f(x)=\sum_{n=1}^{\infty}\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n+x}}$$
According to some theorems, I found that the above series is convergent point wise on $(-1, +\infty)$. 
Does the series represent a well-known function?","['real-analysis', 'riemann-zeta', 'sequences-and-series', 'closed-form']"
2181479,"If differentials aren't supposed to be treated like fractions, how come we do just that in Differential Equations?","For years I've heard that differentials aren't fractions and multiplying $\frac {d y}{d x} $ with $d x$ to ""cancel out the denominator"" isn't the right view, yet I've never been shown this ""right view"" and in my ODE class we always do exactly what we were told was wrong. What exactly are the properties and proper usages of differentials? How come we're told they don't technically ""cancel out"" in fractions, yet nearly everything we've been exposed to counters that?","['ordinary-differential-equations', 'calculus']"
2181496,Complete and incomplete norm in a vector space,"Let $X$ be a plain vector space . Since we can always equip $X$ with a norm, Can we always equip $X$ with a complete norm? Can we always equip $X$ with an incomplete norm?","['functional-analysis', 'linear-algebra', 'analysis']"
2181540,Solving differential equation $y''-y'^2/y+y'/x=0$,What approach we have to solve the following differential equation? $$y''(x)- \frac{y'(x)^2}{y} + \frac{y'(x)}{x}=0$$ The known solution is $y(x) = c_2 * x^{c_1}$,"['derivatives', 'numerical-methods', 'ordinary-differential-equations', 'calculus']"
2181582,Noob question about $\int \frac{1}{\sin(x)}dx$,"I manually integrate $\int \frac{1}{\sin(x)}dx$ as $$\int \frac{\sin(x)}{\sin^{2}(x)}dx = -\int \frac{1}{\sin^{2}(x)}d\cos(x) = \int \frac{1}{\cos^{2}(x) - 1}d\cos(x).$$ After replacing $u = \cos(x)$, $$\int \frac{1}{u^{2} - 1}du = \int \frac{1}{u^{2} - 1}du = \frac {1} {2} \int \left(\frac {1} {u - 1} - \frac {1} {u+1}\right) du = \frac {1} {2} \ln\left(\frac {u-1} {u+1}\right) + C.$$ Substitute back to obtain $$\frac {1} {2} \ln\left(\frac {\cos(x)-1}{\cos(x)+1}\right) + C.$$ The problem is that this solution is incorrect (I guess) because for example http://www.integral-calculator.com/ gives another solution $$\frac {1} {2} \ln\left(\frac {1 - \cos(x)}{1 + \cos(x)}\right) + C.$$ And all other online solvers gives equivalent solution to 
$$\frac {1} {2} \ln\left(\frac {1 - \cos(x)}{1 + \cos(x)}\right) + C.$$ The question is there I made a mistake? Update : some of you may say that in complex space my answer is right but not so fast: Take wolfram solver: integrate 1/sinx The we get: $-ln(cot(x) + csc(x)) + C$ It is easy to see that it is equvalent to $$\frac {1} {2} \ln\left(\frac {1 - \cos(x)}{1 + \cos(x)}\right) + C.$$ $-\ln(\cot(x) + \csc(x)) + C = -\ln(\frac {\cos(x)} {\sin(x)} + \frac {1} {\sin(x)})$ then $-\ln(\frac {\cos(x)} {\sin(x)} + \frac {1} {\sin(x)}) = -\frac {1}{2} \ln(\frac {(1+\cos(x))^{2}} {\sin^{2}x}) = -\frac {1}{2} \ln(\frac{1+\cos(x)+\cos(x)+\cos^{2}(x)} {1-\cos^{2}x}) = -\frac {1}{2} \ln(\frac {(1+\cos(x))(\cos(x)+\cos^{2})(x)} {1-\cos^{2}x}) = -\frac {1}{2} \ln(\frac {1+\cos(x)} {1-\cos(x)}) = \frac {1}{2} \ln(\frac {1-\cos(x)} {1+\cos(x)})$","['integration', 'complex-numbers']"
2181640,Partial sums of $nx^n$,"WolframAlpha claims:
$$\sum_{n=0}^m n x^n = \frac{(m x - m - 1) x^{m + 1} + x}{(1 - x)^2} \tag{1}$$
I know that one can differentiate the geometric series to compute $(1)$ when it is a series, i.e. $m=\infty$. However, I'm wondering how the closed form for the partial sum is obtained. Actually, WolframAlpha gives an explicit formula for
$$\sum_{n=0}^m n(n-1)(n-2)\cdots (n-k)x^n \tag{2}$$
where $k$ is an integer between $0$ and $n-1$, so it seems that there are some differentiation involved. But already for $k=5$, the formula becomes very messy . My question: How to prove $(1)$ and how to build a similar formula for $(2)$ assuming $k$ is given?","['real-analysis', 'summation', 'calculus', 'analysis']"
2181734,How many barcodes are there?,"A barcode is made of white and black lines. A barcode always begins and ends width a black line. Each line has is of thickness 1 or 2, and the whole barcode is of thickness 12. How many different barcodes are there (we read a barcode from left to right). I know that I'm required to show some effort, yet I really don't have a clue about this problem. Can you give me any hints?","['combinations', 'combinatorics']"
2181754,Evaluate the sum of series $\sum_{k=1}^{+\infty}(-1)^{k-1}\frac{1}{k(4k^2-1)}$,"Evaluate the sum of series
$$\sum_{k=1}^{+\infty}(-1)^{k-1}\frac{1}{k(4k^2-1)}$$ I have tried two methods: 1) using power series 2) using partial sums but I can't find the sum. 1) Using power series: $$\sum_{k=1}^{+\infty}(-1)^{k-1}\frac{1}{k(4k^2-1)}x^{k(4k^2-1)}$$ $$f(x)=\sum_{k=1}^{+\infty}(-1)^{k-1}\frac{1}{k(4k^2-1)}x^{k(4k^2-1)}$$ After derivation: $$f'(x)=\sum_{k=1}^{+\infty}(-1)^{k-1}x^{4k^3-k-1}$$ The problem here is that:
$$\sum_{k=1}^{+\infty}(-1)^{k-1}x^{4k^3-k-1}=x^2-x^{29}+x^{104}-...$$ Is it possible to find the closed form for the last series? 2) Using partial sums: $$S_n=\sum_{k=0}^{n}(-1)^{k}\frac{1}{(k+1)(4(k+1)^2-1)}$$ Now, using the formula: $$S_n+a_{n+1}=a_0+\sum_{k=1}^{n+1}(-1)^{k}\frac{1}{(k+1)(4(k+1)^2-1)}\Rightarrow$$ $$S_n+(-1)^{n+1}\frac{1}{(k+2)(4(k+2)^2-1)}=\frac{1}{3}+\sum_{k=1}^{n+1}(-1)^{k}\frac{1}{(k+1)(4(k+1)^2-1)}$$ $$S_n=\frac{1}{3}-\frac{1}{30}+...+(-1)^{n}\frac{1}{(n+1)(4(n+1)^2-1)}$$ 
$$\sum_{k=1}^{n+1}(-1)^{k}\frac{1}{(k+1)(4(k+1)^2-1)}=T_n=-\frac{1}{30}+...+(-1)^{n+1}\frac{1}{(n+2)(4(n+2)^2-1)}$$
$$T_n=S_n-\frac{1}{3}+(-1)^{n+1}\frac{1}{(n+2)(4(n+2)^2-1)}$$ Going back to the formula $$S_n+a_{n+1}=a_0+\sum_{k=1}^{n+1}(-1)^{k}\frac{1}{(k+1)(4(k+1)^2-1)}$$ we have that $S_n$ cancels, so we can't determine partial sums using this method? $$S_n+(-1)^{n+1}\frac{1}{(k+2)(4(k+2)^2-1)}=\frac{1}{3}+T_n$$
$$S_n+(-1)^{n+1}\frac{1}{(k+2)(4(k+2)^2-1)}=\frac{1}{3}+S_n-\frac{1}{3}+(-1)^{n+1}\frac{1}{(n+2)(4(n+2)^2-1)}$$ Question: How to find the sum of this series?",['sequences-and-series']
2181757,Four primes together in an equality. How often does it happen?,"I am almost a complete number theory newbie so pardon me if this is stupid. $$128 - 125 = 3$$
$$2^7 - 5^3 = 3$$ Are there an infinite number of these, four primes $p_1,p_2,p_3,p_4$ so that: $${p_1}^{p_2} - {p_3}^{p_4} = p_4$$","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2181800,What is the variance of a constant? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given a constant $c$, I know that $\text{E}(c)=c$, but what about the variance of $c$?","['statistics', 'variance', 'probability-distributions']"
2181824,How do I find a matrix $B\neq 0$ so $AB = BA = 0$,"Sorry if it's relatively easy, I just have no idea what to do here: $A = \begin{pmatrix}
1 & 2 &3 \\ 
4 & 5 & 6\\ 
7 & 8 & 9
\end{pmatrix}$ how to find  $B\neq 0$ so $AB = BA = 0$ I only know if I need to find it, then A is linear dependant if that is useful for it somehow.
I probably can build a $3x3$ matrix with variables and solve a huge equation system but I don't think it's what I'm supposed to do here and there must be a smarter solution.","['matrices', 'linear-algebra']"
2181888,Vakil Exercise 6.6.T,"I'm having trouble with the following exercise from Professor Vakil's book. EXERCISE. As $A^1_\mathbb{Z}$ is a group scheme, $\mathbb{Z}[t]$ has a Hopf algebra structure.
  Describe the comultiplication map $\mathbb{Z}[t] \to \mathbb{Z}[t]\otimes_\mathbb{Z}\mathbb{Z}[t]$. My only guess was the map that sends $t$ to $t \otimes t$ (and the rest is determined by linearity). I want to describe the map $A^1_\mathbb{Z} \times A^1_\mathbb{Z} \to A^1_\mathbb{Z}$ which behaves like ""multiplication"" on points, so that was my guess. How do I check it though? I think the ""addition of points"" map would send $t$ to $t \otimes 1 + 1 \otimes t$, but I'm not sure about this one either. EDIT: Can you please transfer this question to mathoverflow.net? Thank you","['algebraic-geometry', 'commutative-algebra']"
2181901,Why does Euler's formula have to be $e^{ix} = \cos(x) + i\sin(x)$,"In part one of this youtube video the uploader goes on to explain the calculus proof for Euler's Formula. The Formula
$$e^{ix} = \cos(x) + i\sin(x)$$
Differentiate
$$ie^{ix} = f'(x) + i g'(x)$$
Multiply original formula by $i$
$$ie^{ix} = if(x) - g(x)$$
Equate the differentiation and the multiplied version
$$f'(x) + ig'(x) = if(x) - g(x)$$
Equate real and imaginary (and cancel the i)
$$f'(x) = -g(x) \qquad g'(x) = f(x)$$ Then he goes on to explain $f(x) = \cos(x)$ and $g(x) = \sin(x)$. My question is why can't $f(x) = \sin(x)$ and $g(x) = -\cos(x)$? Can further proof be added to this proof to eliminate $f(x) = \sin(x)$ and $g(x) = -\cos(x)$?","['complex-numbers', 'calculus', 'proof-verification', 'complex-analysis', 'proof-explanation']"
2181942,"Is there a set $A \subset [0,1]$ such that both $A$ and $[0,1] \setminus A$ intersect every positive-measure set?","Is there a set $A \subset [0,1]$ such that for every Borel set $B \subset [0,1]$ of positive Lebesgue measure, both $B \cap A$ and $B \setminus A$ are non-empty? This is, in a sense, the ""measure-theoretic analogue"" of the more obvious topological question: is there a set $A$ such that for every non-empty open $U \subset [0,1]$ , both $U \cap A$ and $U \setminus A$ are non-empty? (For which the answer is obviously $A:=\mathbb{Q}$ .) Now it is clear that $A$ cannot itself be a Borel set of non-trivial Lebesgue measure (just take $B=A$ ). My intuition is that $A$ cannot be any Lebesgue-measurable set. I thought about taking $A$ to be a set consisting of one point from every orbit of $x \mapsto x+\sqrt{2} \; \mathrm{mod} \; 1$ , or at least a union of such sets. But I'm not sure if this gets anywhere.","['descriptive-set-theory', 'borel-sets', 'measure-theory']"
2181994,Find the sum of series $\displaystyle \sum_{n=0}^{+\infty}\frac{(-1)^n}{2(n+1)(2n+1)}$,"Find the sum of series $$\sum_{n=0}^{+\infty}\frac{(-1)^n}{2(n+1)(2n+1)}$$
I have tried to use the telescoping method, but it seems that it can't reduce the problem. $$\sum_{n=0}^{+\infty}\frac{(-1)^n}{2(n+1)(2n+1)}=\lim_{N\rightarrow+\infty}\sum_{n=0}^{N}\frac{(-1)^n}{(2n+2)(2n+1)}$$
$$=\lim_{N\rightarrow+\infty}\sum_{n=0}^{N}(-1)^n\left(\frac{1}{2n+1}-\frac{1}{2n+2}\right)$$
$$=\lim_{N\rightarrow+\infty}\left[\left(1-\frac{1}{2}\right)-\left(\frac{1}{3}-\frac{1}{4}\right)+\left(\frac{1}{5}-\frac{1}{6}\right)+...+(-1)^N\left(\frac{1}{2N+1}-\frac{1}{2N+2}\right)\right]$$ Is it possible to find the sum of the last expanded series?",['sequences-and-series']
2182009,Slope of the Orthogonal Trajectory in Polar Coordinates (Versus the Slope of the Orthogonal Trajectory in the $xy$-plane),"When finding the orthogonal trajectories of a family of curves in the $xy$ plane, we do the following: Differentiate the equation of the family of curves with respect to the independent variables, which gives us the slope of the family of curves; Eliminate the parameter (if it didn't already get eliminated during differentiation); Rearrange to get the form $\dfrac{dy}{dx} = f(x, y)$; Take the negative reciprocal of $\dfrac{dy}{dx} \implies \dfrac{-dx}{dy} = f(x, y)$, which gives us the slope of the orthogonal trajectories; Solve the differential equation using separation of variables or some other method. This gives us the equation of the orthogonal trajectories. In my previous (related) question , I mentioned a peculiar problem in my textbook, "" Differential Equations with Applications and Historical Notes, 3rd edition "", by Simmons and Finlay, where the authors used polar coordinates to solve the orthogonal trajectories problem. In the aforementioned question, I discovered that the reason for my confusion was because the slope of the orthogonal trajectories in polar form is different to the slope of the orthogonal trajectories in the xy plane : The slope of the orthogonal trajectories in the xy plane , as previously mentioned, is the negative reciprocal of $\dfrac{dy}{dx} \implies \dfrac{-dx}{dy} = f(x, y)$, whilst the slope of the orthogonal trajectories in polar form is the negative reciprocal of $\dfrac{1}{r}\dfrac{\mathrm dr}{\mathrm d\theta} \implies -r\dfrac{\mathrm d\theta}{\mathrm dr} = f(r, \theta)$. In other words, and more generally, we can see that the way in which we get the slope of the orthogonal (normal) trajectories (vectors) in polar form is different from that in the $xy$-plane. My original confusion stemmed from this fact that, with polar coordinates, we do not only take the negative reciprocal of the operator $\dfrac{\mathrm dr}{\mathrm d\theta}$, but also the negative reciprocal of $\dfrac{1}{r}$ along with it. This difference was not mentioned in the textbook; the only case that was mentioned was that of dealing with the operator $\dfrac{dy}{dx} = f(x, y)$ -- coordinates of the xy-plane. I would greatly appreciate it if people could please take the time to post a step-by-step proof that clearly shows that, unlike the orthogonal trajectory in the $xy$-plane, the orthogonal trajectory in polar form is found by taking the negative reciprocal of $\dfrac{dr}{rd\theta} \implies -r\dfrac{\mathrm d\theta}{\mathrm dr} = f(r, \theta)$. My goal is to convince myself that this is true -- that the way we get the slope for the orthogonal trajectories is different between equations using coordinates in the xy-plane $\left( \dfrac{dy}{dx} \implies \dfrac{-dx}{dy} = f(x, y) \right)$ and those using coordinates in polar form $\left( \dfrac{1}{r}\dfrac{\mathrm dr}{\mathrm d\theta}\ \implies -r\dfrac{\mathrm d\theta}{\mathrm dr} = f(r, \theta) \right)$.","['ordinary-differential-equations', 'polar-coordinates']"
2182014,Proving specific unital rings have maximal ideals without Zorn's Lemma,"In Dummit & Foote's Abstract Algebra , they make the comment on the fact that unital rings have maximal ideals: $\dots$ the proof relies on Zorn's Lemma (see Appendix I). In many specific rings, however, the presence of maximal ideals is often obvious, independent of Zorn's Lemma. Are there specific rings that require use of Zorn's Lemma to show they have maximal ideals?","['abstract-algebra', 'ring-theory', 'axiom-of-choice']"
2182032,"When solving for angles using law of sines, how do you know if the angle is obtuse or acute?","Consider the problem on khanacademy . I set up the equation and solve using the Law of Sines as follows. $$\frac{\sin 40^{\circ}}{30} = \frac{\sin x}{40}$$
$$ \sin^{-1}\left(40\cdot\frac{\sin 40^{\circ}}{30}\right) = x$$
$$x = 58.99^{\circ}$$
From what I understand, arcsin restricts outputs from $-180$ to $180$ degrees, which is why i get $58.99$. My question is what stops $(180-58.99) = 121.01$ from being a valid answer as well.",['trigonometry']
2182077,Explanation Of Cauchy's Integral Theorem,"When we integrate in terms of  real variables over a closed loop  then we get a positive area enclosed by that loop( in 2D). I don't understand why integration of a complex analytic function comes out to be zero. 
Please explain this to me.
Pardon me if you find this question silly.",['complex-analysis']
2182084,Discriminant of $\Bbb Q(\sqrt[3]{2})$,"I want to understand a way of computing the discriminant of the number field $K=\mathbb{Q}(\sqrt[3]{2})$. The degree of $K|\mathbb{Q}$ is $n=3$ and we have $3=1+2\cdot 1$, so there are one real and two complex embeddings. Now my teacher concludes that the absolute value of the discriminant is equal to $2^2\cdot 3^3$. Why that?","['abstract-algebra', 'algebraic-number-theory']"
2182143,"Original and interesting problems about the theorems of Green, Stokes and Gauss","Problems about these three classical theorems that we find in Calculus textbooks are usually in a low level. So, in this post, I'd like examples of original and  interesting problems involving such theorems that can be solved with a typical Calculus 3 course background.","['multivariable-calculus', 'big-list', 'vector-analysis']"
2182172,How to solve this limit? $ \lim_{x \to +\infty} \frac{(\int^x_0e^{x^2}dx)^2}{\int_0^xe^{2x^2}dx}$ [duplicate],This question already has answers here : Compute $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^{2}} dy]^2}{\int^x_0 e^{2y^{2}}dy}$ (3 answers) Closed 7 years ago . There's  a limit which confuses me: $$ \lim_{x \to +\infty} \dfrac{(\int^x_0e^{x^2}dx)^2}{\int_0^xe^{2x^2}dx}$$ Is it possible to use L'Hôpital's rule here?,"['real-analysis', 'limits']"
2182174,how to set values in a conjugate prior,"Say I'm trying to set a bayesian prior for a Bernoulli trial of coin flips. The equation I'm interested in is the $p(x|I)$ from the Bayesian numerator:
$$P(x|data)\propto x^{N_H}(1-x)^{N_t}p(x|I)$$
where $I$ is the background information. NOTE: The Bayes denominator takes the form (for a uniform prior $p(x|I)$):
$$\int_0^1{x^{N_H}(1-x)^{N_t}p(x|I)} = \frac{\Gamma(N_H+1)\Gamma(N-N_H-1)}{\Gamma(N+2)}$$
Alternative, if I choose the conjugate prior $p(x|i)=x^{\alpha}(1-x)^\beta$, the form of the Bayes denominator stays the same:
$$\int_0^1{x^{N_H}(1-x)^{N_t}p(x|I)} = \frac{\Gamma(N_H+\beta+1)\Gamma(N-N_H+\alpha+1)}{\Gamma(N+\alpha+\beta+2)}$$ Now, say I'm interested in using this conjugate prior with the following data: HTHTTHTTTHHTHTHTTTTHHTHTTTHTHTHHTTH
  $$N=35, N_H=15, N_T=20$$ I feel like the way I choose the $\alpha$ and $\beta$ parameters for $p(x|I)=x^{\alpha}(1-x)^\beta$ is to calculate the mean and stdev for the given data and then somehow ""fit"" those values to the prior. But I can't seem to figure out the mechanics of doing so. Hoping someone can put me on the right track","['bayesian', 'statistics', 'probability']"
2182182,Calculate the integral $\int_{C_1} e^{X(z+iz-z^2/2)} dz$ as $X \rightarrow \infty$,"I need help calculating the following integral as $X \rightarrow \infty$ $$\int_{C_1} e^{X(z+iz-z^2/2)} dz$$
along the path
$$z=x+i\frac{x+1}{x-1},$$
for $x\in (-\infty,-1]$. It seems very difficult. $C_2: z=x+i,x\in\mathbb{R}$, $C_3: z=\infty+iy, y\in [0,1]$, and $C: z=x, \in [-1,\infty)$. So the closed contour is $C=-C_1+C_2-C_3$. The integral along the path $C_2$ I calculated as $$e^{iX}\sqrt{\frac{2\pi }{X}}$$ as $X\rightarrow \infty$.","['complex-analysis', 'asymptotics', 'contour-integration', 'complex-integration']"
2182186,How to solve $\frac{y''}{y} = -\frac{2}{9x^2}$ without guessing?,"I want to solve the second-order differential equation 
$$ \frac{y''}{y} = -\frac{2}{9x^2} $$ By trial and error, I found that $y=x^{1/3}$ and $y=x^{2/3}$ satisfy the equation. So, all solutions are of the form $y = ax^{1/3} + bx^{2/3}$ as long as $y\not= 0$. How could I go about solving a differential equation like this analytically?","['ordinary-differential-equations', 'calculus']"
