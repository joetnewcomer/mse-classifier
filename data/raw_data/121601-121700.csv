question_id,title,body,tags
1826109,Inclusion–exclusion: Matrices,"Let $A$ be an $n\times n$ matrix that contains all the numbers $1,2,\ldots,n^2$ (each one appears one time). Count the number of $n \times n$ matrices $B$ that contain all the numbers $1,2,\ldots,n^2$ and don't have any row identical to some row in $A$, and don't have any column identical to some column in $A$. I marked $R_i=\{\text{all the matrices with row }i\text{ identical to some row in }A\}$,
$C_i=\{\text{all the matrices with column }i\text{ identical to some column in }A\}$, and said that $$\left|\bigcap_{i\in I} R_i\right|=\left|\bigcap_{i\in I} C_i\right|={n \choose |I|}\big(n^2-|I|n\big)!|I|!$$ and $$\left|\bigcap_{i\in I} R_i\cap\bigcap_{j\in J} C_j\right|=\left(n^2-(|I|+|J|)n+|I||J|\right)!\;.$$ By the Inclusion–exclusion principle, I got  this answer: $$(n^2)!+\sum_{k=1}^{2n}(-1)^k\left[2{n \choose k}^2k!(n^2-kn)!+ \sum_{i=1}^{k-1}{n \choose i}{n \choose k-i}\big(n^2-kn+i(k-i)\big)!\right]\;.$$ Is this correct? Is there another way? Thanks","['inclusion-exclusion', 'combinatorics']"
1826138,How to find the coordinates where the altitude of a triangle intersects the base in 3 dimensions?,"Assuming I know three completely random coordinates in 3d space that correspond with vertices of a triangle, how can I then find the point at which the altitude intersects the base? I know how to calculate the side lengths of the triangle and have an idea of how to solve my problem, but I become stuck when challenged with finding the height of the altitude.","['trigonometry', 'geometry']"
1826188,Is my understanding of quotient rings correct?,"Amidst all the rigorous constructions of quotient rings involving equivalence relations and ideals, I feel that I have finally grasped what a quotient ring is. I have applied this intuition to a few examples and they have served me well, but I would just like to verify that this actually the case. If $R$ is a ring and $I$ an ideal, then $R/I$ is just what you have leftover if you map all of the elements of $I$ to zero. So going by that $$\mathbb{Z}/n\mathbb{Z} = \{0, 1,2,3,...,n-1\}=\mathbb{Z}_n$$ Also $$\mathbb{R}[x]/x = \text{Constant polynomials}=\mathbb{R}$$ It seems to me that the quotient ring is always 'hiding' inside the original ring. So for example $\mathbb{Z}_n \subset \mathbb{Z}$ or $\mathbb{R} \subset \mathbb{R}[x]$. But if we consider this isomorphism $$\mathbb{R}[x]/(x^2+1) \cong \mathbb{C}$$ Then it doesn't seem to work anymore. I cannot see how $\mathbb{C}$ is 'hiding' inside $\mathbb{R}[x]$. Was my initial observation just a coincidence and hence cannot be applied here? Or am I totally misunderstanding everything?","['abstract-algebra', 'ring-theory']"
1826197,Floor sum of reciprocal of square root of first $50$ numbers,"Find Sum of $$\bigg\lfloor 1+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+\frac{1}{\sqrt{4}}+\cdots+\frac{1}{\sqrt{50}}\bigg\rfloor$$ $\bf{My\; Try::}$ Let $\displaystyle y=f(x) = \frac{1}{\sqrt{x}}\;,$ Then draw that graph in coordinate axis, We get $$\displaystyle \int_{1}^{51}\frac{1}{\sqrt{x}}dx<\sum^{50}_{k=1}\frac{1}{\sqrt{k}}<1+\int_{1}^{50}\frac{1}{\sqrt{x}}dx$$ So we get $$\displaystyle 2\left(\sqrt{51}-1\right)<\sum^{50}_{k=1}\frac{1}{\sqrt{k}}<1+2(\sqrt{50}-1)$$ So we get $$12.28<\sum^{50}_{k=1}\frac{1}{\sqrt{k}}<13.14$$ But answer given is $12,$ How cai i solve avobe question, Help Required, Thanks",['calculus']
1826205,"$\int\frac{\sqrt{9x^2-25}}{x}dx$. Using Trigonometric substitution, how to solve an integral when leading coefficient under radical isn't Unity?","Problem $$\int\frac{\sqrt{9x^2-25}}{x}dx$$ My Approach I identify this (perhaps incorrectly) as a secant problem, where: $$3x=5\sec\theta$$ and $$dx=\frac{5}{3}\sec\theta\tan\theta\; d\theta$$ Then, substituting back, we get: $$\int\frac{5\tan\theta\;\frac{5}{3}\sec\theta\tan\theta}{\frac{5}{3}\sec\theta}\;d\theta$$ Reducing I get (Maybe incorrectly) $$\int5\tan^2\theta\;d\theta$$ And finally, using $\tan^2\theta = \sec^2\theta-1$ , I get: $$5\int(\sec^2\theta-1)\;d\theta= 5\tan\theta-5\theta + C$$ Now, substituting back in for $\theta$ , where $\tan\theta = \frac{\sqrt{9x^2\;-\;25}}{5}$ , I get $$ \boxed{\sqrt{9x^2-25} - 5arcsec(x) + C}$$ However, this is not the answer my professor has listed in the answer key. He gives the solution as $$\boxed{-\frac{3\sqrt{9x^2-25}}{x^2}+\frac{27}{50}arcsec(x) + C}$$ Now, his answers have been wrong before but I think I just made a major error along the way. The $arcsec$ at the end tells me I was kind of on the right track, but the fraction in front of it tells me I messed up big somewhere. Did I make a mistake converting the radical for trigonometric substitution, make a reducing error, or both? Should I have tackled this problem using a different technique?","['integration', 'trigonometry', 'trigonometric-integrals', 'calculus']"
1826212,Find the value of k when $f(x) = x^3 -4x^2 + 6x + k$,"If $ \ \ a ,b \ \  $and $\  \ c \ \ $  are roots of $ \ \ f(x) = x^3  -4x^2 + 6x + k \ \   $ and  $ \frac{1}{a^2 + b^2} + \frac{1}{b^2 + c^2} + \frac{1}{a^2 + c^2} = 1 \ \ \ \ $then   find the value of $ \ k $ I have to tell you honestly that I cannot solve this question or find the way to get   value of $ \ k$ I started with   $(a + b +c)^2 = a^2 + b^2 + c^2 + 2(ab+bc+ac) \ \ $   $\Rightarrow a^2 + b^2 + c^2 = 4$ then $a^3 +b^3 + c^3 = (a+b+c)(a^2 + b^2 +c^2) - (ab+bc+ac)(a+b+c) + 3abc$ $ \ \ \ \ \ \  \ \ a^3 +b^3 + c^3 =  -8 + 3k$ apply to   $(a+b+c)^3 = a^3 + b^3 + c^3 + 3(a+b)(b+c)(a+c)$ $ \ \ \ \ \ \  \ \ \ \ \  \ \ 72 -3k =  3(a+b)(b+c)(a+c)$ finally , I don't know how relation between $ \frac{1}{a^2 + b^2} + \frac{1}{b^2 + c^2} + \frac{1}{a^2 + c^2} = 1 \ \   $  and $(a+b)(b+c)(a+c)$ Please tell me the way to solve this question correctly. thank you in advance.",['algebra-precalculus']
1826238,Are all bijective functions continuous?,"I'm teaching my self topology with a book, and I'm trying to understand continuity better. Using the following definition, If X and Y are topological spaces, a map $f$: $X \rightarrow Y$ is said to be continuous if for every open subset $U \subseteq Y$, its preimage $f^{-1}(U)$ is open in $X$. I know the following function is not continuous: $f: \mathbb{R} \rightarrow \mathbb{R} $ $$
f(x) = \left\{
        \begin{array}{ll}
            2x + \frac{|x|}{x} & \quad x \neq 0 \\
            0 & \quad x = 0
        \end{array}
    \right.
$$ If we set $U=(-1/2,+\infty)$. Then $U$ are open in $\mathbb R$. But $f^{-1}(U)=[0,+\infty)$, which is not open. Thus, $f$ is not continuous. However, this function is not a bijection. If I redefine the range to make it a bijection as follows: $f: \mathbb{R} \rightarrow (-\infty, 1)\cap\{0\}\cap(1,\infty) $ Now $U$ cannot be defined the same way. Is the bijective version of $f$ now continuous? If it is, can someone please give an example of a simple 1-dimensional bijective function that is not continuous?","['general-topology', 'real-analysis']"
1826253,Functions validity.,"Why does writing a function differently make it valid for a originally invalid input? $e.g:$ $$f(x) = \frac{1} {(\frac1x+2)(\frac1x-3)} \implies x≠0$$ Which  may alternatively be written as: $$f(x) =\frac{x^2}{(1+2x)(1-3x)}$$ Which is valid for $x=0$? Both graphically represent the same function. 
Thanks.","['generating-functions', 'functions', 'functional-equations']"
1826264,Reference request: product Borel $\sigma$-algebra of non-separable metric spaces,"The following is a proposition in Folland's Real Analysis about product sigma algebra: Here $\mathcal{B}_X$ denotes the Borel $\sigma$-algebra on $X$. Could anyone come up with an example that 
  $$
\mathcal{B}_X\setminus\otimes_{1}^n\mathcal{B}_{X_j}
$$
  is nonempty?","['reference-request', 'real-analysis', 'examples-counterexamples', 'measure-theory']"
1826314,"The sequence $(a_n)$ is given as $a_1=1, a_{2n} = a_n - 1, a_{2n+1} = a_n + 1$. $a_{2015}=$?","The sequence $(a_n)$ is given as  $a_1=1, a_{2n} = a_n - 1, a_{2n+1} = a_n + 1$.
What's the value of $a_{2015}$ Correct answer should be $a_{2015} = 9$. How? thing that came to mind was to see what $a_{2015}$ is composed of. So $a_{2015} = a_{(2*1007 + 1)} = a_{1007} + 1$ because $a_{2n+1} = a_n + 1$ and
than to work that way down? My teacher said that I am complicating too much, and I agree, but
what am I missing to solve this?","['algebra-precalculus', 'recurrence-relations', 'binary', 'sequences-and-series']"
1826319,Trigonometric solution to solvable equations,"The algebraic equations in one variable, in the general case, cannot be solved by radicals. While the basic operations and root extraction applied to the coefficients of the equations of degree $2, 3, 4 $  are sufficient to express the general solution, for arbitrary degree equations, the general solution can be expressed only in terms of much more complicated functions than the root function. And even more: trigonometric and logarithmic functions are not enough to express the general solution of an algebraic equation of any degree (cf. Beyond the Quartic Equation , Bruce King, p. 57). However, it is possible to express the general solution of certain equations using trigonometric functions. The quintessential example is the trigonometric solution to the cubic equation in the case of three real roots. In the case of a real root and two complex roots, the general solution is expressed by means of hyperbolic functions. Another example equally interesting, but less known, is the trigonometric solution to the quadratic equation . The De Moivre's quintic can also be solved by means of trigonometric functions.  The change of variable $ x = y - \frac{a}{y}$ will reduce the equation $ x^5+5ax^3+5a^2x+2b = 0$ to $y^{10}+2by^5-a^5$, and consequently $$x = \sqrt[5]{-b+\sqrt{b^2+a^5}}+\sqrt[5]{-b-\sqrt{b^2+a^5}}$$ If $b^2+a^5 < 0$, then the roots are trigonometrical functions of the coefficients; the change of variable $ x = -2\phi\sqrt{-a}$ reduces the given equation to $$ 16\phi^5-20\phi^3+5\phi = \frac{b}{a^2\sqrt{-a}}$$ which coincides with $\sin5\theta$. By taking $\phi = \sin \theta$ and $\frac{b}{a^2\sqrt{-a}} = \sin5\theta$, we get $$ x = -2\sqrt{-a}\sin\Big(\tfrac{1}{5}\arcsin\tfrac{b}{\sqrt{-a^5}}+\tfrac{2\pi k}{5}\Big)$$ for $ k = 0, 1... 4$. There is a similar approach to solve this quintic by means of hyperbolic functions when $b^2+a^5 > 0$. This leads to me to the following question: Let $P(x) = a_1x^n+a_2x^{n-1}+\dotsb + a_{n-1}x+a_n = 0$ be a solvable equation with real coefficients. Is always possible to express the roots of $P(x)$ by means of the four elementary operations, extraction of roots and trigonometrical and hyperbolics functions applied to the coefficients $a_1... a_n$? In fact, this is possible for some solvable equations as shown in the above examples, the case of quadratic, cubic, and a certain quintic equation. But is this a property of all solvable equations? If the answer is yes, how can be expressed the roots of each solvable equation in terms of trigonometric and hyperbolic functions applied to their coefficients?","['real-analysis', 'galois-theory', 'polynomials', 'abstract-algebra', 'trigonometry']"
1826335,If $x$ and $y$ are non-negative integers for which $(xy-7)^2=x^2+y^2$. Find the sum of all possible values of $x$.,I am not able to reach to the answer. I have used discriminant as $x$ and $y$ are both integers but it didn't give any hint to reach to answer. I am not able to understand how should I deal with these type of question.,"['number-theory', 'diophantine-equations']"
1826356,How to show that the following function is bijective?,"If we have the function $c : \mathbb{N}^2 \rightarrow \mathbb{N} : (x,y) \rightarrow 2^x \cdot (2y+1) -1 $ how to show that this function is bijective? So I thought the easiest way is to show that is injective and surjective, but this leads me to the next problem, how to show those sides. So how to show that every $n \in \mathbb{N}$ from the target set gets hit and every $(x,y)$ hits another $ n \in \mathbb{N} $ from the target set? Hope somebody can help.","['elementary-set-theory', 'functions']"
1826381,Evaluate $\int_0^{\infty} \frac{\log(x)dx}{x^2+a^2}$ using contour integration,"This question is Exercise 10 of Chapter 3 of Stein and Shakarchi's Complex Analysis. Show that if $a>0$ , then $$\int_0^{\infty}  \frac{\log(x)dx}{x^2+a^2}=\frac{\pi \log(a)}{2a}.$$ The hint is to integrate over the boundary of the domain $\{z: \epsilon<|z|<R, \Im(z)>0\}.$ I'm not sure what to do with the integral over the outer arc.","['complex-analysis', 'contour-integration', 'complex-integration']"
1826412,Another question about proving Lebesgue Decomposition,"Note: This is my original question.  I have been kindly helped to turn this into a correct proof, which I have posted as an answer so this question won't show up as ""unanswered"". As an exercise, I am trying to provide a rigorous proof of uniqueness in the Lebesgue Decomposition Thm, assuming we already have existence.  I am following the outline provided here . Below is what I have so far Step 1 : Assume $\lambda$ is a finite measure ($\mu$ only needs to be $\sigma$-finite). Let $$\lambda=\lambda_1+\lambda_2 = \lambda_3 + \lambda_4, \text{where } \lambda_1, \lambda_3 \perp \mu \text{ and } \lambda_2,\lambda_4 \ll \mu \tag1$$ Let $\alpha:=\lambda_3 -\lambda_1 =\lambda_2-\lambda_4$ Extend defns of singular & abs cont to signed measures: (I just do the most intuitive thing here) $\alpha \perp \mu $ means $\exists$ a partition A,B of X s.t. $\alpha(A)= \mu(B)=0$.  $\alpha \ll \mu$ means $\mu(E)$=0 implies $\alpha(E)$=0. Show $\alpha \perp \mu$ and $\alpha \ll \mu$.  This is just checking defns. Conclude $\alpha$=0.  I'm stuck here.  By the previous pt, $\exists$ a partition A,B of X s.t. $\alpha(A)=\mu(B)$=0.  Further, $\mu(B)$=0 implies $\alpha(B)=0$.  So $\alpha(X)=\alpha(A)+\alpha(B)$=0.  But we may have a partition $X_1,X_2$ of X s.t. 0 $< \alpha(X_1)=-\alpha(X_2)$. Step 2 : (General case) $\lambda$ is $\sigma$-finite. Let $X_1 \subseteq X_2 \subseteq$..., $X=\cup_{n=1}^{\infty} X_n$, each $\lambda(X_n)< \infty$. $\forall n$, $E \in \textbf{X}$, put $\lambda_n(E):=\lambda(E \cap X_n)$, which is a finite measure, so $\exists$ a unique Lebesgue decomp $\lambda_n=\lambda_{1n}+\lambda_{2n}$ Assume (1) again.  Now I don't know how to show $\lambda_1=\lambda_3$.  I’m trying to use the previous bullet pt.  I think I can show $\lambda=(\lim_{n \to \infty} \lambda_{1n})+ (\lim_{n \to \infty} \lambda_{2n})$ is a Lebesgue Decomp, but how do I know there aren’t others?","['real-analysis', 'measure-theory']"
1826414,What is the probability that a person wearing a blue t-shirt will sit next to one wearing red?,"9 people sit in a row linearly. 2 dressed in Red, 3 blue and 4 in yellow. What is the probability that a person in blue will sit next to a person in red? Why? RRBBBYYYY this sequence from what I gather can be arranged in 9! ways. Attempt There are 2 groups R and Y we want to seat together. The Y(people wearing yellow) can be arranged in 4! ways and people wearing red in 2! ways. 
Therefore 2 x 3! x 2! should be the right answer. Times 2 because we only want to consider two groups. (I think this is where I am going wrong because there are 3) If there were two groups of people the. i am guessing it would be right. However there are 3 groups and I have no idea how to show it. Attempt There is a total lf 9!/2!x3!x4 = 1260 ways they can be seated. These however will be in random order and I can't figure out how to put them in an order that R sits next to Y.","['combinatorics', 'statistics', 'probability']"
1826420,Change of Variable Proof in Folland,"I am reviewing Folland's proof of the following standard result and I have a question on one part. Suppose $\Omega$ is an open set in $\mathbb R^{n}$; $G:\Omega \to \mathbb R^{n}$ is a diffeomorphism on $\Omega$; $f\in \mathcal L^{1}(G(\Omega))$. Then, $$\int _{G(\Omega)}f(x)dx=\int _{\Omega}f\circ G(x)\cdot\vert\det G'(x)\vert dx.$$ The main idea is to establish the inequality $$\tag1 m(G(Q))\leq \int _{Q}\vert\det G'(x)\vert dx$$ where $Q$ is a cube in $\Omega$. Folland does this by observing that for any $\epsilon>0$ we may choose $\delta>0$ so that, as soon as $Q$ is subdivided into $\left \{ Q_k \right \}^{n}_{k=1}$, where the $Q_k$ are cubes with disjoint interiors, of side length $<\delta$, with centers $x_k$, then the following holds: $$\tag 2m(G(Q))\leq (1+\epsilon)\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k).$$ He then claims that $(1)$ follows from this, upon letting $\epsilon ,\delta\to 0$ and appealing to the uniform continuity of $\vert \det G'\vert $. This seems like a bit of handwaving to me. Or at least the claim deserves more rigor. Or am I missing something simple here? In any case, it seems easier just to note that $\vert \det G'\vert $ is Riemann integrable on $Q$, so we may write, with $P_k$ the partition of $Q$ determined by $Q_k$: $$\tag3 m(G(Q))\leq (1+\epsilon )\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k)\leq (1+\epsilon )U(\vert \det G'\vert , P_k).$$ Then, given an an arbitrary partition of $Q$, there is a refinement to a partition determined by some $\left \{ Q_k \right \}^{N}_{k=1}$ where the side length of each $Q_k<\delta$, from which it follows immediately from $(3)$ that $$\tag4 m(G(Q))\leq (1+\epsilon )\overline \int _{Q}\vert\det G'(x)\vert dx=(1+\epsilon )\int _{Q}\vert\det G'(x)\vert dx,$$ which is what we want.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1826426,"Is $\{\{\emptyset\}\} \subseteq \mathcal P(\{\emptyset,\{\emptyset\}\})$?","For my homework I have to determine whether $\{\{\emptyset\}\} \subseteq \mathcal P(\{\emptyset,\{\emptyset\}\})$ is true or false. I believe the answer would be true because $\{\emptyset\} \in \mathcal P(\{\emptyset,\{\emptyset\}\})$ , but I am not sure. I have been reading previous questions but am still confused about this problem. I know that $\{\{\emptyset\}\} \in  \mathcal P(\{\emptyset,\{\emptyset\}\})$, but have been unable to determine the relationship between the two. Any help would be greatly appreciated",['elementary-set-theory']
1826452,"Why isn't f(x^2) a horizontal stretch of f(x) by a factor of ""1/x""?","I know this question seems silly, but it came to mind while reading about transforming functions. Is the statement ""y=f(kx) results from scaling the graph of y=f(x) horizontally by a factor of 1/k"" not applicable when k=x? A thorough explanation would be appreciated.","['functions', 'graphing-functions']"
1826552,"Repeating/""Periodic"" Derivatives? [duplicate]","This question already has answers here : Functions that are their Own nth Derivatives for Real $n$ (5 answers) Closed 8 years ago . We know that $Ce^x$ and $0$ are the two functions whose first derivative is equal to itself, but what about derivatives of a higher order? For example, the second derivative of $e^{-x}$ is equal to itself, but not the first, and the fourth derivative of $sin(x)$ is equal to itself. In short, are there other examples of functions whose nth derivative is equal to itself, where $n>1$? Thank you kindly!","['derivatives', 'calculus', 'functions']"
1826556,Conjecture about Cal 1 derivatives?,"Conjecture: Let $F\left(\vec{x}\right) : \Bbb{R}^n \to \Bbb{R}$ Define $g(t) = F(t, t, \dots, t)$ Then $$g^{\prime} (t) = \left(\sum_{i=1}^n \ { \partial F \over \partial
 x_i}\right)\Big( \ \{ \ \vec{x} = \langle t,t,\dots,t\rangle \Big)$$ This theorem, if true, could greatly simplify finding the derivatives of most cal 1 functions, and functions in general. My first observation of this pattern was in finding the derivative of $x^x$ Informally, this function has two parts - a part which behaves like $x^a$, and a part which behaves like $a^x$. Treating $a$ as a constant and deriving these two functions with respect to $x$ yields $ax^{a-1}$ and $a^x \ln x$. Plugging $x$ back in for $a$ in these yields $x^x$ and $x^x \ln x$. Separately, these derivatives are incorrect, but their sum, $x^x + x^x \ln x$, is the correct derivative. This pattern held for several examples that I verified by hand, including $x^2 = x \cdot x $, $2x = x + x$, and even the function $\log_x (x)$, which is identical to $1$, yields the correct derivative $0$ when derived this method. And yet I don't know how to prove the conjecture in general. However, contained within this method are several other basic derivative rules. For example, the product rule and quotient rule can be proven with this method. Product rule proof: let $g(t) = a(t)b(t)$. Define $F(x,y) = a(x)b(y)$ Then ${\partial F \over \partial x} = a^{\prime}(x) \cdot b(y)\\ {\partial F \over \partial y} = b^{\prime}(y) \cdot a(x)$ So $g^{\prime}(t)= {\partial F \over \partial x} (t,t) + {\partial F \over \partial y} (t,t) = a^{\prime}(t)  \cdot b(t) + b^{\prime}(t) \cdot a(t)$ Similar proof for the quotient rule. This conjecture also must be true for all $F$ which are linear combinations of smaller, univariate functions,  $F = \sum_i \ a_i \ f_i (x_i)$, because then this method demonstrates the linearity of the derivative operation. This conjecture can also prove the power rule, ${d \over dx} x^n = nx^{n-1}$ Proof: Define $F(\vec{x}) = \prod_{i=1}^n \ x_i$, and thus $g(t) := F(t,t,\dots,t) = t^n$ Then $${\partial F \over \partial x_i} =\prod_{1 \ \le \ r \ \le \ n, \ \ r \ \ne \ i} \ \ x_r$$  Thus $${\partial F \over \partial x_i}(t,\dots,t) = t^{n-1} $$
So $$g^{\prime}(t) = \sum_i { \partial F \over \partial x_i} (t,\dots,t)  = \sum_{i=1}^n t^{n-1} = n \ t^{n-1}$$ I am very confident that this theorem could be true in general, but I can't think of a way to prove it in general. My professor was unconvinced when I showed him, and neither of us could think of any prior theorem this conjecture might be calling to. Is this conjecture true in general, or does there exist a counterexample function?","['derivatives', 'partial-derivative', 'proof-verification', 'calculus', 'multivariable-calculus']"
1826580,"If $f(f(x)) = f(x^2)$, then must there be some constant $c$ such that $f(x)=c$ for all values of $x$ in the domain of $f$?","Here is a problem from Rusczyk-Crawford's Art of Problems Solving: Intermediate Algebra textbook (Chapter 2 Review, problem 2.30). If $f(f(x)) = f(x^2)$, then must there be some constant $c$ such that $f(x)=c$ for all values of $x$ in the domain of $f$?","['algebra-precalculus', 'functions']"
1826594,Mathematical description on the interface of two adjacent bodies.,"I am recently studying about a problem related to shortest path. I can briefly describe my idea but I am not sure if there is some ""professional"" mathematical description about it. In the following figure, two 3-D bodies are adjacent. I need the interface between them be somehow simple, like the upper case In the figure. To be more specific, form point A in body 1 to point B in body 2, the straight line shall intersects with the interface once at most. Not intersecting with the interface is allowed, but intersecting more than once is not allowed (as shown in the underneath case). So, any one tell me about if there is some research on this? I can not even search for this without knowing a ""professional"" mathematical description. ------ Update 2016-06-19 ---------------- Supplement following the discussion happened in comments: The intersection being a isolated segment is allowed. Segment AB can intersect with the interface at a point or a segment. In other words, let $I_s$ be the point set that $ I_s = \{ \vec{x} | \vec{x} \in {Interface \cap {AB}} \} $, $I_s$ shall be a closed interval.","['analytic-geometry', 'geometry']"
1826607,$\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx $,$$\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx$$ where $a>b>0$ What shall I do? I have diffucty when I meet multi value function.,"['complex-analysis', 'improper-integrals']"
1826609,basic concepts of limits,"Suppose I have a function: $ f(x)=x$ Now I want to calculate the limits:
$\lim\limits_{x\rightarrow1}f(x)=f(1)$ As wiki_limits said, the limit of $f$ of $x$, as $x$ approaches 1, is $f(1)$. So my question here is 1 Does it mean the limit calculation are actually is a approximated kind of calculation? It is not normal precise calculation such as $1+1=2$ 2 If all limit calculation are approximated results, does it mean that Caculus are about approximated calculation? (Based on my current knowledge, just begin to learn single calculus)","['calculus', 'limits']"
1826638,"Rigorous justification for ""complex"" change of variable in integration","Suppose that I have $X_1,\ldots,X_n$ i.i.d. $\sim $ $X$ and $Y_1,\ldots,Y_n$ i.i.d. $\sim$ $Y$ for some continuous $X$ and $Y$. Consider the r.v.'s $\bar{X}=\frac{1}{n}\sum_jX_j$ and $\bar{Y}=\frac{1}{n}\sum_jY_j$. First, the joint MGF for $(X,Y)$ can be written as
$$
M(t,u)=\exp{K(t,u)}=E[\exp(tX+uY)].
$$
Here $K$ denotes the joint CGF (the joint cumulant generating function). Then, I know enough to write the density $f_n$ of $(\bar{X},\bar{Y})$ as
$$
f_n(\bar{x},\bar{y})=\frac{n^2}{(2\pi)^2}\int_{-\infty}^\infty\int_{-\infty}^\infty\exp[n(K(it,iu)-it\bar{x}-iu\bar{y})] \, dt \, du.\tag{$*$}
$$
My reading (source available if requested) says that I can write ($*$) as
$$
f_n(\bar{x},\bar{y})=\frac{n^2}{(2\pi i)^2}\int\int\exp[n(K(t,u)-t\bar{x}-u\bar{y})] \, dt \, du.\tag{$**$}
$$
with ""integration being along admissible paths in the $t$ and $u$ planes."" Heuristically, I can see how to go from ($*$) to ($**$) by two changes of variables: $it\to t$ and $iu\to u$, but how do I justify ($**$) rigorously? Can you please recommend (self-learning-friendly) references? My background: undergrad real and complex analysis. For complex analysis, I'm familiar with the Cauchy Integral Formula, Cauchy Theorem, Residue Theorem, McLauren series, contour integrals.","['fourier-analysis', 'reference-request', 'probability-theory', 'complex-analysis', 'integration']"
1826653,"Without calculating $A^4$ prove that $A^4\in Span\{A,I\}.$","Let 
$$A=
        \begin{bmatrix}
        -1 & 6 & -9 \\
        -11 & 24 & -33 \\
        -6 & 12 & -16 \\
        \end{bmatrix}
$$
a) Without calculating $A^4$ prove that $A^4\in Span\{A,I\}.$ b) Write $A^n$ in a form of $a_nA+b_nI$ If matrix $A^4\in Span\{A,I\}$ then $A^4=\alpha A+ \beta B$.
I had an idea to find eigenvalues and eigenvectors of $A$, so I can diagonalize the matrix and say that $A^4=SD^4S^{-1}$. However, I am not sure is that done without calculating $A^4$. Thank you all in advance.","['matrices', 'linear-algebra']"
1826655,Necessary and sufficient condition for a normal group to be kernel of a homomorphism from the group to itself,I am looking for a necessary and sufficient condition for a subgroup $K$ of a group $G$ to be kernel of a homomorphism $\phi$ from $G$ to $G$. The tools that come into my mind is first isomorphism theorem (that $\frac{G}{\operatorname{kernel} \phi}$ is isomorphic to $\operatorname{Im}(\phi)$) and also that $\operatorname{kernel} \phi$ is normal subgroup of $G$. I don't know how to combine these two to get a necessary and sufficient condition?,['group-theory']
1826662,Kernels of powers of linear transformation,"Suppose $T:V\to V$ is a linear transformation and $dim(V)=n$. It is well known that there is an integer $m$, where $0\le m\le n$ such that
$$\{\textbf{0}\}=K(T^0)\subsetneq K(T^1)\subsetneq K(T^2) \subsetneq \cdots \subsetneq K(T^m)=K(T^{m+1})=K(T^{m+2})=\cdots$$ Here $K$ denotes kernel.
Let the nullity of $T^i$ be $n_i$. Then we have a sequence
$$0, n_1, n_2, \cdots,n_{m-1},n_m,n_m,n_m,\cdots$$ Denote $s_i=n_i-n_{i-1}$, which can be thought of as how much ""bigger"" $K(T^i)$ is larger than $K(T^{i-1})$. It is clear that $s_i>0$ for $0 \le i \le m$. I am reading a proof of some theorem and I think the author has implicitly assumed $s_{i-1} \ge s_i$. I come up with a proof of this but am not sure about its correctness. Consider $K(T^i)$. Since $K(T^{i-1})\subsetneq K(T^i)$, we can choose $s_i$ vectors, called $z_{i,1}, z_{i,2},\cdots,z_{i,s_i}$, all not in $K(T^{i-1})$ so that
$$K(T^i)=K(T^{i-1})\oplus \langle z_{i,1},z_{i,2},\cdots, z_{i,s_i}\rangle$$ Now consider the $s_i$ vectors $T(z_{i,1}),T(z_{i,2}), \cdots, T(z_{i,s_i})$. First let us shown that they are linearly independent. Suppose
$$\textbf{0}=a_1T(z_{i,1})+a_2T(z_{i,2})+\dots+a_{s_i}T(z_{i,s_i})$$
Then
$$\textbf{0}=T(a_1 z_{i,1}+a_2z_{i,2}+\dots+a_{s_i} z_{i,s_i})$$
$$\implies a_1 z_{i,1}+a_2z_{i,2}+\dots+a_{s_i} z_{i,s_i}\in K(T)\subsetneq K(T^{i-1})$$ Then by definition of $z_{i,1},z_{i,2},\cdots,z_{i,s_i}$, we must have
$$a_1 z_{i,1}+a_2z_{i,2}+\dots+a_{s_i} z_{i,s_i}=\textbf{0}$$
and hence
$$a_1=a_2 = \dots =a_{s_i}=0.$$ Now because
$$T^{i-1}(T(z_{i,j}))=T^i(z_{i,j})=\textbf{0}$$
we have 
$$T(z_{i,j})\in K(T^{i-1}).$$ Next, by the way $z_{i,j}$ are chosen, we have
$$T^{i-1}(z_{i,j})\ne\textbf{0}$$
$$T^{i-2}(T(z_{i,j}))\ne\textbf{0}$$
$$z_{i,j}\notin K(T^{i-2})$$ In conclusion, the $s_i$ vectors
$$T(z_{i,1}), T(z_{i,2}), \cdots, T(z_{i,s_i})$$
are linearly independent, $\in K(T^{i-1})$ but $\notin K(T^{i-2})$. Hence,
$$s_{i-1} \ge s_i$$ Is the above proof correct?","['linear-algebra', 'linear-transformations']"
1826670,Does this pattern have anything to do with derivatives?,"In 6th grade I was first introduced to the idea of a function in the form of tables. The input would be ""n"" and the output ""$f_n$"" would be some modification of the input. I remember finding a pattern in the function ""f(n)=n^2"". Here is what the table looked like: \begin{array}{|c|c|}
\hline
n& f_n\\ \hline
1&1 \\ \hline
2&4\\ \hline
3&9\\ \hline
4&16\\ \hline
5&25\\ \hline
...&...\\ \hline
n&n^2\\ \hline
\end{array} I would then take the outputs $f_n$ and find the differences between each one: $f_n-f_{n-1}$. This would produce: \begin{array}{|c|c|}
\hline
n& f(n)-f(n-1)\\ \hline
1&1 \\ \hline
2&3\\ \hline
3&5\\ \hline
4&7\\ \hline
5&9\\ \hline
...&...\\ \hline
\end{array} Repeating this process (of finding the differences) for the outputs of  $f_n-f_{n-1}$ would yield a continuous string of $2$s. As a 6th grader I called this process 'breaking down the function' and at the time it was just another pattern I had found. Looking back at my work as a freshman in high school, I realize that the end result of 'breaking down a function' corresponds to the penultimate derivative (before the derivative equals zero). For example: breaking down $y=x^3$ gives a continuous string of $6$s, and the third derivative of $x^3$ is 6 (while the 2nd derivative is 6x). Is there any significance to this pattern found by finding the differences between each output of a function over-and-over again? Does it have anything to do with derivatives? I know my question is naive, but I'm only a high school freshman in algebra II. A non-calculus (or intuitively explained calculus concepts) answer would be very helpful [note that I used an online derivative calculator to find the derivatives of these functions and I apologize for any incorrect calculus terminology].","['derivatives', 'functions']"
1826692,Cartan decomposition of SO(2n),"I am trying to understand the Cartan decomposition theory, on the following example : $G=SO(2n)$, and $K=U(n)$, and I'm interested in the manifold $G/K$ (an hermitian symmetric space). 1) How do we see $U(n)$ as a subgroup of $SO(2n)$ ? 2) Do we have a Cartan decomposition to $G$ ? More precisely do we have for the Lie algebra of $G$ that
$\mathfrak{g} = \mathfrak{k} + \mathfrak{p}$, where $\mathfrak{k}$ is the Lie algebra of $K$, and also the +1 eigenspace of an involution $\theta$ on $\mathfrak{g}$, and $\mathfrak{p}$ is the -1 eigenspace of $\theta$ ? 3) If so, what is $\theta$ is that case? And what is $\mathfrak{p}$ explicitly ?","['differential-geometry', 'lie-algebras', 'lie-groups']"
1826743,Why are there two versions of a polar equation for a circle from geometric form,"In class today we learned that a rectangular/geometric equation for a circle such as $x^2+(y-5)^2 = 9$ can be converted into a polar equation by reducing it to the quadratic equation $r^2-10r\sin \theta+16=0$ applying the quadratic formula to this equation yields two equations 
$$
r=5\sin\theta + \sqrt {25\sin^2\theta-16}
$$ 
and
$$
r=5\sin\theta - \sqrt {25\sin^2\theta-16}
$$
However when these equations are graphed in polar mode on a calculator they are the exact same circle. How is this possible?","['polar-coordinates', 'trigonometry', 'analytic-geometry', 'algebra-precalculus', 'geometry']"
1826794,the proof of variational principal for the principal eigenvalue (checking orthonormal subset),"Hi I am looking at part 3 of the proof in Evans Chapter 6. 
I have difficulty understanding 
""Furthermore from (6) and (7) we see that $(\lambda_k^{-1/2} w_k)$ is an orthonormal subset of $H_0^1(U)$. It is known, from the previous results of the chapter, $(w_k)_{k=1}^{\infty}$ is an orthonormal basis of $L^2(U)$, $w_k\in H_0^1(U)$ is an eigenfunction corresponding to $\lambda_k.$ The bilinear form is defined as 
$$ B[u,v]:=\int_{U} a^{ij} D^j u D^i v+b^i D^i u v+cuv .$$ Given $u$ is a weak solution, the following also holds for the eigenvalue problem
$$ B[u,v]=(\lambda u,v)\,\,\,\forall\,\,\,v\in H_0^1(U)$$
I understand this is really a matter of checking definition. My confusions two-fold. I do not see, by diving $w_k$ by $\lambda_k^{1/2},$ 1) Why we get an orthonormal subset? This means??
2) Why this orthonormal subset is in $H_0^1(U)?$ Now the most important questions of mine. A . It is true that $(w_k)_{k=1}^{\infty}$ forms an orthogonal basis of $H_0^1(U)$, in view of the Galerkin approximation of weak solutions in Chapt 7. How to verify this? B . In view of the proof below, $(w_k)_{k=1}^{\infty}$ cannot be orthonormal basis of $H_0^1(U).$ (Though the scaled version does.) Can someone give a proof, perhaps a contradictory argument? I am looking for a proof that make use of the definition of $H_0^1$ inner product and integration by parts, rather than inferring from (6) and (7).","['orthonormal', 'partial-differential-equations', 'regularity-theory-of-pdes', 'functional-analysis', 'linear-algebra']"
1826803,"In $\triangle ABC$, if $\tan A$, $\tan B$, $\tan C$ are in harmonic progression, then what is the minimum value of $\cot \frac{B}{2}$?","In a $\triangle ABC$, if $\tan A$, $\tan B$, $\tan C$ are in harmonic progression, then what is the minimum value of $\cot(B/2)$? $\bf{My\; Try::}$ Here $A+B+C=\pi\;,$ Then $\tan A+\tan B+\tan C=\tan A\cdot \tan B\cdot \tan C$ and given  $\tan A,\tan B\;,\tan C$ are in harmonic progression, So we get $$\frac{2}{\tan B} = \frac{1}{\tan A}+\frac{1}{\tan C} = \frac{\tan A+\tan C}{\tan A\tan C}=\frac{\tan A\tan B\tan C-\tan B}{\tan A\tan C}$$ So $$\tan B -\frac{\tan B}{\tan A\tan C} = \frac{2}{\tan B}\Rightarrow \tan^2 B = \frac{2\tan A\tan C}{\tan A\tan C-1}$$ Now how can i solve after that, Help required, Thanks","['trigonometry', 'geometry']"
1826821,"Real Analysis, Folland Theorem 1.21 Borel Measures","Background information: $L$ is the class of Lebesgue measurable sets. $m$ is the Lebesgue measure which is a complete measure $\mu_F$ associated to the function $F(x) = x$, for which the measure of an interval is simply its length. $\mu_F$ is the Lebesgue-Stieltjes measure associated with $F$. Theorem 1.21 - If $E\in L$ then $E+s\in L$ and $rE\in L$ for all $s,r\in\mathbb{R}$. Moreover, $m(E + s) = m(E)$ and $m(rE) = |r|m(E)$. Proof - Let $E\subset\mathbb{R}$. If $E\in L$ and $r,s\in\mathbb{R}$ define $$E + s = \{x + s: x\in E\}$$ and define $$rE = \{rx:x\in E\}$$  We need to show that if $E\in L$, then $E + s\in L$ and $rE\in L$. For all $Y\subset \mathbb{R}$ $$m^*(E) = m^*(E\cap Y) + m^*(E\cap Y^c)$$ Let $E = E - s$ then $$m^*(E) = m^*(E-s) = m^*((E-s)\cap Y) + m^*((E-s)\cap Y^c)$$ I am not really sure if this is on the right track and I do not understand how to show the Moreover part. Any suggestions is greatly appreciated.","['real-analysis', 'measure-theory']"
1826827,"Topology: Show restriction of continuous function is continuous, and restriction of a homeomorphism is a homeomorphism","I need to prove two trivial results but I don't know how to work with restricted function and its inverse Consider the topological spaces $(X, \mathcal{T}), (Y, \mathcal{J})$ Claim 1 : Let $f:X \to Y$ be continuous function, $A \subset X$ equipped with subspace topology, then
  $f|_{A}:A \to Y$ is continuous Proof: Take some $V \in \mathcal{J}$, then $f^{-1}|_A(V) = f^{-1}(V) \cap A$, where $f^{-1}(V)$ is open, therefore $f^{-1}(V) \cap A$ is open in the subspace topology. Claim 2 : Let $f:X \to Y$ be homeomorphism, $A \subset X$ equipped with subspace topology, then $f(A)$ is a subspace of $Y$ and $f|_{A}:A \to f(A)$ is continuous Proof: We proceed by showing $f|_A$ is continuous and open. First show $f|_A$ is continuous, take some open set $W$ in the subspace topology on $f(A)$, $W = f(A) \cap V, V \in \mathcal{J}$  then $f^{-1}|_A(V \cap f(A) ) = f^{-1}|_A(V) \cap f^{-1}|_A(f(A)) = $$(f^{-1}(V) \cap A) \cap  (f^{-1}(f(A)) \cap A) = f^{-1}(V) \cap A$ is open. Next show $f|_A$ is open. Take some open set $M$ in the subspace topology on $A$, then $M = A \cap U, U \in \mathcal{T}$. Then $f|_A(A \cap U) = f|_A(A) \cap f|_A(U) = f(A) \cap f|_A(U) = f(A) \cap f(U \cap A) = $$ f(A) \cap f(U) \cap f(A) = f(A) \cap f(U)$. Note $f(U)$ is open since $f$ is open, therefore $f(A) \cap f(U)$ is open in the subspace topology of $f(A)$ This shows all homeomorphisms are local homeomorphism Can someone check the two proofs? The second one is a bit messy.","['functions', 'proof-verification', 'proof-writing', 'proof-explanation', 'general-topology']"
1826878,Show that every local homeomorphism is continuous and open therefore bijective local homeomorphism is a homeomorphism,"Follow up on another question I asked recently: Topology: Show restriction of continuous function is continuous, and restriction of a homeomorphism is a homeomorphism Definition : Let $(X, \mathcal{T})$ and $(Y, \mathcal{J})$ be topological spaces. A
  function ${\displaystyle f:X\to Y\,}$  is a local homeomorphism if for
  every point $x \in X$ there exists an open set $U \subseteq X$
  containing $x$ and an open set $V \subseteq Y$ such that the restriction ${\displaystyle f|_{U}:U\to V\,}$  is a  homeomorphism. This definition is a bit alarming because it starts with ""...if for
 every point $x \in X$ there exists an open set $U \in \mathcal{T}$..."", makes it seem like a property of the underlying space. Can we always find an open $U$? But anyways. Objective : Show that every local homeomorphism is continuous and open
  therefore bijective local homeomorphism is a homeomorphism Proof : 
(Honestly not sure what I am doing but proceed regardless) Let $(X, \mathcal{T})$ and $(Y, \mathcal{J})$ be topological spaces and 
 function ${\displaystyle f:X\to Y\,}$  is a local homeomorphism. We will show that $f$ is continuous and open. First show $f$ is continuous. $f$ is continuous if for all $V \in \mathcal{J}, f^{-1}(V) \in \mathcal{T}$. Take some $V \in \mathcal{J}$, then $V$ is a subspace equipped with subspace topology $\mathcal{J}_V = \{V \cap W| W \in \mathcal{J}\}$. Consider the inverse of the  restriction $f^{-1}|_U$ on an open set in $\mathcal{J}_V$, then $f^{-1}|_U(V \cap W) = f^{-1}|_U(V) \cap f^{-1}|_U(W) $$= f^{-1}(V) \cap U \cap f^{-1}(W) \cap U =  f^{-1}(V) \cap  f^{-1}(W) \cap U$. Then $f^{-1}(V) = f^{-1}(W) \cup U \cup f^{-1}|_U(V \cap W)$. We note all the sets on the right hand side are open. In particular, $U$ is open,  $f^{-1}|_U(V \cap W)$ is open by definition of homeomorphism (??  $f^{-1}(W)$ ??), hence $f$ is continuous. ($\leftarrow$ something wrong here!) Next show $f$ is open. $f$ is open if $\forall U \in \mathcal{T}, f(U) \in \mathcal{J}$. Consider the restriction $f|_U$ on the subspace topology on $U$, $\mathcal{T}_U = \{U \cap M | M \in \mathcal{T}\}$.  $f|_U(U \cap M) = f|_U(U) \cap f|_U(M) = V \cap f(M) \cap f(U)$ Then $f$ is open since $f(U) = f|_U(U \cap M) \cup V \cup f(M)$ and $f|_U(U \cap M)$ is open by definition of homeomorphism, $V$ is open in $\mathcal{T}$ (?? $\cup f(M)$ ??) ($\Leftarrow$ another mistake here) I'm not quite sure how to proceed with showing bijective + continuous + open + local = homeomorphism part. Can someone help me fix those two problems and give me some ideas how
  to conclude that bijective local homeomorphisms are homeomorphisms?","['functions', 'proof-verification', 'proof-writing', 'proof-explanation', 'general-topology']"
1826885,"Find $2^k$ elements from the set ${0,1,\cdots,3^k-1}$ such that none of these element is the average of two other elements of $T$.","The problem is:
Consider the set $S = \{0, 1, 2, \ldots, 3^k-1\}$. Prove that one can choose $T$ to be a $2^k$-element subset of $S$ such that none of the elements of $T$ can be represented as the arithmetic mean of two distinct elements of $T$. I have represented the numbers in base $3$,then I have tried on small cases and I think all the numbers(in base $3$) with $k$ number of positive digits satisfy the problem. But I don't know how I can prove. Can someone help me out to prove it?","['combinatorics', 'elementary-number-theory']"
1826967,Question on Inequality from Bartle's Elements of Integration: Riesz Fischer Theorem,"I am puzzled how did Bartle get $$|g_k|\leq\sum_{j=k}^\infty |g_{j+1}-g_j|$$ (second last line)? I tried using Triangle Inequality and ended up with one extra term: $$\begin{align*}
|g_k|&=|g_k-g_{k+1}+g_{k+1}-g_{k+2}\dots+g_{k+N-1}-g_{k+N}+g_{k+N}|\\
&\leq\sum_{j=k}^{N-1}|g_{j+1}-g_j|+|g_{k+N}|
\end{align*}$$ Even after taking limits $N\to\infty$, the extra term $|g_{k+N}|$ does not necessarily go to zero. Thanks for any help!","['functional-analysis', 'real-analysis', 'lp-spaces', 'analysis']"
1826992,Limit of the sequence $a_{n+1}=\frac{1}{2} (a_n+\sqrt{\frac{a_n^2+b_n^2}{2}})$ - can't recognize the pattern,"Consider the sequence: $$a_0=x,~~~b_0=y$$ $$a_{n+1}=\frac{1}{2} \left(a_n+\sqrt{\frac{a_n^2+b_n^2}{2}} \right),~b_{n+1}=\frac{1}{2} \left(b_n+\sqrt{\frac{a_n^2+b_n^2}{2}}\right)$$ $$\lim_{n \to \infty} a_n=\lim_{n \to \infty} b_n=l(x,y)$$ I can't pin down the pattern for the limit. Numerically, I've got the following result: $$\frac{1}{l(x,y)}=\arctan (f(x,y))$$ What is the explicit expression for $f(x,y)$? Numerical examples: $$\begin{array}( x & y & \frac{1}{l(x,y)} \\ 1 & 2 & \arctan \left( \frac{3}{4} \right) \\ 1 & 3 & \arctan \left( \frac{1}{2} \right) \\ 2 & 3 & \arctan \left( \frac{5}{12} \right) \\ 3 & 5 & \arctan \left( \frac{1}{4} \right) \\ 1 & 5 & \arctan \left( \frac{\sqrt{13}-3}{2} \right) \\ 4 & 5 & \arctan \left( \frac{9}{40} \right) \\ 3 & 4 & \arctan \left( \frac{7}{24} \right) \\ 3 & 7 & \arctan \left( \frac{\sqrt{29}-5}{2} \right) \end{array}$$ Edit To summarize @IvanNeretin's comment (and adding my own numerical results), so far we have: $$l(x,0)=\frac{2x}{\pi}$$ $$f(x,x+1)=\frac{2x+1}{2x(x+1)}$$ $$f(x,x+2)=\frac{1}{x+1}$$ $f(x,x+3)$ - see my answer below $$f(x,x+4)=\frac{\sqrt{x^2+4x+8}-(x+2)}{2}$$ Here $x \in \mathbb{R}^{+}$, $x \neq 0$ Also by symmetry we have of course: $$f(x,y)=f(y,x)$$ At this point it's obvious that no ordinary function works here. My hope is to connect $f(x,y)$ to some special function or an integral.","['recurrence-relations', 'limits', 'pattern-recognition', 'trigonometry', 'sequences-and-series']"
1827003,"Is the group $G_{n,\phi} = \langle x_1 , \dots, x_n \mid x_i^2, (x_i x_j)^4, x_i x_{\phi(i)} x_{i+1} x_{\phi(i)} \rangle$ abelian?","I am working on a family of finitely presented groups and I asking me the following question. Let $\phi$ be an application from $\left\{1,\dots,n\right\}$ to $\left\{1,\dots,n\right\}$ (not necessary bijective), we consider the group defined by:
$$G_{n,\phi} = \langle x_1 , \dots, x_n \mid x_i^2, (x_i x_j)^4, x_i x_{\phi(i)} x_{i+1} x_{\phi(i)} \rangle. $$
Is $G_{n,\phi}$ isomorphic to $\mathbb{Z}/2\mathbb{Z}$? It is clear that the abelianisation of $G_{n,\phi}$ is $\mathbb{Z}/2\mathbb{Z}$, so the question is equivalent to prove that $G_{n,\phi}$ a monogenous group or an abelian group. Futhermore, we have that $x_i$ and $x_{i+1}$ commute. I have tested on GAP the first cases, and it seems to be true when $n\leq 7$. But I don't found a method to simplify this presentation for all $n$ and $\phi$. If you have any idea, it is welcome. Edit I: The question is equivalent to prove that the group $K_{n,\phi}$ is trivial, where:
$$
K_{n,\phi} = \langle y_1,\dots,y_n \mid y_1, (y_i y_j^{-1})^4, y_i y_{\phi(i)}^{-1} y_{i+1} y_{\phi(i)}^{-1} \rangle.
$$
In this group we have the properties $(y_i y_{i+1}^{-1})^2=1$, which implies that the order of $y_2$ and $y_n$ is 2. Edit II: I have tried to simplify the set of relations of $K_{n,\phi}$, and it seems that the groups:
$$
S_{n,\phi}=\langle y_1,\dots,y_n \mid y_1, y_i^4, y_i y_{\phi(i)}^{-1} y_{i+1} y_{\phi(i)}^{-1} \rangle,
$$
is always trivial. I have tested it on GAP for all $\phi$, and all $n\leq7$.
In fact, I have also remarked that the groups:
$$
T_{n,m,\phi}=\langle y_1,\dots,y_n \mid y_1, y_i^{2^m}, y_i y_{\phi(i)}^{-1} y_{i+1} y_{\phi(i)}^{-1} \rangle,
$$
seems to be trivial. Once again, I have checked on GAP for all $\phi$ and all $n\neq 6$ and $m\leq 6$. It is clear that $T_{n,1,\phi}$ is always trivial and that we have a natural morphism $\psi_m:T_{n,m,\phi}\to T_{n,m-1,\phi}$. For the moment, I do not see how use these last properties.","['gap', 'finite-groups', 'computational-algebra', 'group-presentation', 'group-theory']"
1827007,Fourier Transform of $\frac{1}{\sqrt{|x|}}$ [duplicate],"This question already has answers here : Fourier transform of $ |x|^{s} $ and $\log|x| $ (5 answers) Closed last month . I want to find the fourier transform of $\frac{1}{\sqrt{|x|}}$. I checked the table of common fourier transforms in Wikipedia, and I know the answer should be $$\sqrt{\frac{2\pi}{|\omega|}}$$ What I can't find out, however, is why that is the answer. I tried 
$$ \hat{f}(\omega) = \int_{-\infty}^{\infty} \frac{1}{\sqrt{|x|}} e^{-i\omega x} dx$$
$$ = \int_{0}^{\infty} \frac{1}{\sqrt{x}} e^{-i\omega x} dx + \int_{0}^{\infty} \frac{1}{\sqrt{x}} e^{i\omega x} dx$$ but that just gives me two unsolvable exponential integrals. I also tried finding the answer through residue calculus, as the function has a single singularity at 0, which yields $$ \hat{f}(\omega) = 2\pi i \ Res_{z = 0} \frac{e^{-i \omega z}}{\sqrt{|z|}} = 2\pi i \lim_{z \to 0} (e^{-i \omega z}) = 2\pi i$$ What am I doing wrong? Or am I thinking completely in the wrong direction?
Thanks in advance!","['complex-analysis', 'fourier-analysis', 'fourier-transform']"
1827086,Does there exist $A$ of infinite order in $\{ A \in GL_2(\mathbb{R}) : A^T = A^{-1} \}$? [duplicate],"This question already has an answer here : Matrix Group induction proof and order of elements question (1 answer) Closed 7 years ago . Does there or does there not exist $A$ of infinite order in $\{ A \in GL_2(\mathbb{R}) : A^T = A^{-1} \}$? I know that elements of the form
$$A=\begin{bmatrix}\cos(\theta) & \sin(\theta)\\\pm\sin(\theta) & \pm\cos(\theta)\end{bmatrix}$$
are in this group, but do not know how to calculate their order.","['matrices', 'infinite-groups', 'group-theory']"
1827092,Doubt in Baby Rudin Theorem 6.17 (Riemann-Stieltjes integral),"I have a doubt in one step of the proof of the following theorem in Rudin's Principles of Mathematical Analysis Rudin proceeds to prove this as follows: Given $\epsilon>0, \exists$ a partition P such that $$U(P,\alpha')-L(P,\alpha') < \epsilon$$
Let $M=sup|f(x)|$ He then proves that
$$ |U(P,f,\alpha)-U(P,f\alpha')| \leq M\epsilon$$ Also, he has shown that the above is true for any refinement of $P$ as well. It is clear to me till here. But then he 'concludes' that I fail to understand how this follows from the the fact that the inequality for $P$ is also true for any refinement of $P$. Please help!","['real-analysis', 'integration']"
1827127,Did I pick the error? Mathematical Logic,"Given these propositions: $$\begin{align}
x&=y \\
x^2&=xy \\
x^2-y^2&=xy-y^2\\
x+y&=y\\
y+y&=y\\
2y&=y\\
2&=1
\end{align}
$$
I've found out that the error is ""$x+y=y$"". Am I correct? I'm just a beginner in Discrete Math.","['logic', 'discrete-mathematics']"
1827141,Find $\lim_{x\to0}\sum_{n=1}^{\infty}\frac{\sin x}{4+n^2x^2}$,"I have a problem with finding the following limit. I suspect that it should be easy, but really I don't have a clue.
$$
\lim_{x\to0}\sum_{n=1}^{\infty}\frac{\sin x}{4+n^2x^2}
$$","['real-analysis', 'uniform-convergence', 'limits', 'convergence-divergence', 'sequences-and-series']"
1827147,Proofs related to chi-squared distribution for k degrees of freedom,I was reading a proof related to chi-squared distribution for k degrees of freedom from wiki. https://en.wikipedia.org/wiki/Proofs_related_to_chi-squared_distribution I think I might understand the general idea behind the proof. But there are some subtle details which I am confused about. 1) What is the meaning of the notation $P(Q)dQ$? Shouldn't it just be $P(Q)$? 2)The integral $\int_vdx_1dx_2...dx_k$ is equal to the surface area of the (k − 1)-sphere times the infinitesimal thickness of the sphere which is $dR = dQ/2Q^{1/2}$. Why we need to times $dR$? Could someone please help me with the questions?,"['probability-theory', 'probability-distributions', 'statistics', 'integration', 'lebesgue-integral']"
1827183,How to integrate $\cos^2x$? [duplicate],"This question already has answers here : Evaluating $\int P(\sin x, \cos x) \text{d}x$ (3 answers) Closed 8 years ago . It seems like I am stuck on such a simple problem: How to I find the antiderivative of $\cos^2x$?
I have tried partial integration, it doesn't seem to work (for me). Some help on how to integrate it would be nice.","['indefinite-integrals', 'integration', 'trigonometry', 'calculus']"
1827190,Prove that $\lim\limits_{x\to \infty} a\sqrt{x+1}+b\sqrt{x+2}+c\sqrt{x+3}=0$ if and only if $ a+b+c=0$,"Prove that $$ \displaystyle \lim_{x\to\infty } \left({a\sqrt{x+1}+b\sqrt{x+2}+c\sqrt{x+3}}\right)=0$$ $$\text{if and only if}$$
$$ a+b+c=0.$$. I tried to prove that if $a+b+c=0$, the limit is $0$ first, but after getting here i got stuck 
$$\lim_{x\to\infty } \left({\sqrt{x+1}\left(a+b\sqrt{1+\frac{1}{x+1}}+c\sqrt{1+\frac{2}{x+1}}\right)}\right)$$
Got here by substituting $\sqrt{x+2}$ with $\sqrt{(x+1)(1+\dfrac{1}{x+1})}$ Edit: x tends to infinity, not to 0. I transcribed wrongly.",['limits']
1827226,Proving that the exponential function is continuous,"We aren't allowed to use many tricks such as difference quotient / integral calculus... Prove that $\exp$ is continuous at $x_{0}=0$ ............................................................................................................................... Given: $$\exp: \mathbb{R} \ni  x \mapsto \sum_{k=0}^{\infty } \frac{1}{k!} x^{k} \in \mathbb{R}$$ also $e = \exp(1)$. For all $x \in \mathbb{R}$ with $\left | x \right | \leq 1$: 
$$\left | \exp(x) - 1 \right | \leq \left | x \right | \cdot (e-1)$$ and $\exp(0) = 1$ ............................................................................................................................... If I remember correctly, we said that if $|f(x) - f(x_0)| < \varepsilon$ is true then it's continuous. So I think it would be good to start with: $$e^x = \lim_{n \to \infty}\left(1 + \frac{x}{n}\right)^n$$
then show this is convergent:
$$\lim_{x \to x_0} \lim_{n \to \infty} \left(1 + \frac{x}{n}\right)^n = \lim_{x \to x_0} e^x = e^{x_0} = \lim_{n \to \infty} \left(1 + \frac{x_0}{n}\right)^n = \lim_{n \to \infty} \lim_{x \to x_0} \left(1 + \frac{x}{n}\right)^n$$ and in the end put it somehow in $|f(x) - f(x_0)| < \varepsilon$ to show $\exp$ continuous? I don't know exactly how to do that but the way is correct so far?","['exponential-function', 'analysis']"
1827241,Tychonoff's theorem for completely regular spaces and the axiom of choice,"It is well-known that Tychonoff's theorem, i.e., that the product of any set-indexed family of compact spaces is compact, is equivalent to the axiom of choice. It is also the case that if the spaces are Hausdorff, then the full axiom of choice is no longer needed (I believe the claim becomes equivalent to the ultrafilter axiom). What if the spaces have even more structure? In particular, what sort of equivalency holds for completely regular spaces? In other words, if the product of a set-indexed family of compact completely regular spaces is always compact, which choice-like axiom is implied.","['general-topology', 'compactness', 'axiom-of-choice']"
1827249,"Let $\lVert\cdot\rVert_1,\lVert\cdot\rVert_2$ be norms on vector space $X$. Prove that they generate the same topology iff they are equivalent. [duplicate]","This question already has answers here : Are two norms equivalent if they induce the same topology on a vector space? (2 answers) Closed 8 years ago . Note that by ""generate the same topology"" we mean that any set that is open with respect to $\lVert\cdot\rVert_1$ is also open with respect to $\lVert\cdot\rVert_2$ and vice versa. By ""equivalent"" we mean that $\exists m,M>0$ such that $m\lVert x \rVert_2\leq \lVert x \rVert_1 \leq M\lVert x \rVert_2$. This is part of an old preliminary exam in Analysis I'm using to prep for my own prelim. I have already proven that equivalent $\implies$ same topology, but the other direction is causing me trouble. I've been attempting a reductio, supposing that for some open $A$ we have $\inf_{x\in A} \{m>0: m\lVert x \rVert_2 \leq \lVert x \rVert_1\}=0$. I don't see any contradiction here, though.","['normed-spaces', 'real-analysis', 'analysis']"
1827271,Find $I$ in $\frac{\overline{SIX}}{\overline{NINE}}=\frac23$,"In $\frac{\overline{SIX}}{\overline{NINE}}=\frac23$ every letter denotes a  UNIQUE digit,find $I$. Expanding the fraction in base $10$ we have: $300S+30I+3X=2020N+200I+2E$ , but this doesn't help much.We may deduce that since $\overline{SIX}\lt1000$ so $\overline{NINE}\lt1500$ , now we know $N=1$.How to find other digits specially $I$?","['algebra-precalculus', 'puzzle']"
1827301,Proof of Leibniz $\pi$ formula,"I found the following proof online for Leibniz's formula for $\pi$: $$\frac{1}{1-y}=1+y+y^2+y^3+\ldots$$
Substitute $y=-x^2$: $$\frac{1}{1+x^2}=1-x^2+x^4-x^6+\ldots$$ Integrate both sides: $$\arctan(x)=x-\frac{x^3}{3}+\frac{x^5}{5}-\frac{x^7}{7}+\ldots$$ Now plug in $1$ for $x$: $$\frac{\pi}{4}=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\ldots$$ The thing I am confused about is that the Taylor expansion for $\frac{1}{1-y}$ only works for $-1<y<1$. Why is this still a legitimate proof? At the end, we compute the integral of both sides to $y=-1$.","['taylor-expansion', 'sequences-and-series', 'calculus', 'pi', 'convergence-divergence']"
1827309,Does the repeated integral of $\ln x$ have a pattern?,"I was reminiscing with a friend and we remembered a question asked to us in our high school calculus class. Find an expression for the $n^{\text{th}}$ derivative and the $n^{\text{th}}$ integral of $\ln x$ ( ignoring integration constants$^1$ ). The first part is easy: $$f(x) = \ln x$$
$$f'(x) = \frac{1}{x}$$
$$f''(x) = -\frac{1}{x^2}$$
$$f'''(x) = \frac{2}{x^3}$$
$$\vdots$$
$$f^{(n)}(x) = \frac{(-1)^{n-1}\cdot(n-1)!}{x^n}$$ The second part seems to have no pattern: $$f(x) = \ln x$$
$$\int f(x)\ dx = x\ln x - x$$
$$\iint f(x) \ dx^2 = \frac12x^2\ln x - \frac34x^2$$
$$\iiint f(x) \ dx^3 = \frac16x^3\ln x - \frac{11}{36}x^3$$
$$\vdots$$ It looks like the answer is something like: $$f^{(-n)}(x) = \frac{1}{n!}x^n\ln x - \ ?x^n$$ From the looks of it, I think the question boils down to finding a general term for: $$\int x^n \ln x \ dx$$ And then also trying to figure out what pattern the coefficients $?$ take. $^1$As user Semiclassical points out, this is just equivalent to computing successive antiderivatives of: $$\int_0^x f(t) \ dt$$","['integration', 'calculus']"
1827312,How to show bound ${\rm Tr} ( {\bf A} ({\bf I}+ b {\bf A})^{-1}) \le \frac{n {\rm Tr}(A)}{n +b {\rm Tr}(A) }$,"Let ${\bf A} \in \mathbb{R}^{n \times n}$ be symmetric positive definite. Can one prove the following inequality for some positive constant $b$?
\begin{align}
{\rm Tr} ( {\bf A} ({\bf I}+ b {\bf A})^{-1}) \le \frac{n {\rm Tr}({\bf A})}{n +b {\rm Tr}({\bf A}) }
\end{align} Edit: Based on one of the answers below the question boils down to showing the following inequality
\begin{align}
\sum_{i=1}^n \frac{d_i}{1+b d_i } \le \frac{ n \sum_{i=1}^n d_i}{\sum_{i=1}^n  (1+b d_i) }
\end{align}
where $d_i \ge 0$.","['matrices', 'linear-algebra']"
1827337,Proofing that the exponential function is continuous in every $x_{0}$,"Given: $$\exp: \mathbb{R} \ni  x \mapsto \sum_{k=0}^{\infty } \frac{1}{k!} x^{k} \in \mathbb{R}$$ also $e = \exp(1)$. For all $x \in \mathbb{R}$ with $\left | x \right | \leq 1$: 
$$\left | \exp(x) - 1 \right | \leq \left | x \right | \cdot (e-1)$$ and $\exp(0) = 1$ ........................................................................................................................... In order to proof that the exponential function is continuous for every $x_{0}$,
it needs to be shown that it's continuous at all.
This was shown here (it's continuous at $x_{0}$ = 0): Proving that the exponential function is continuous But I prefer this proof: $$
\exp(x) = \sum_{n=0}^\infty \frac{x^n}{n!}
$$
apply some little changes
$$
\exp(x) = 1 + x \sum_{n=1}^\infty \frac{x^{n-1}}{n!}
$$
whence for $x\to 0$
$$
|\exp(x) - 1| \le |x| \sum_{n=1}^\infty{|x|^{n-1}} \le |x| \frac{1}{1-|x|} \to 0
$$ I would say in order to show that the exponential function is continuous for all $x_{0} = 0$, I just need to show it is continuous at $x_{0}$ = 0 (done) and then I can just conclude it is continuous everywhere, so at $x=x_{0}$?
Not sure about this, is it really possible?","['exponential-function', 'analysis']"
1827340,How do I find the domain/range of functions algebraically?,"I've been having trouble when trying to find the domain/range of functions algebraically. Here is an example: $P(x)=\frac{1}{3+\sqrt{x+1}}$ Finding the domain: $x+1\ge0$ $x\ge-1$ Therefore, $x \in [-1,+\infty)$ Finding the range: Let $y=P(x)=\frac{1}{3+\sqrt{x+1}}$
From isolating x we find: $x=(\frac{1}{y} -3)^2-1$ Therefore: $(\frac{1}{y} -3)^2-1\ge-1$ $(\frac{1}{y} -3)^2\ge0$ $\frac{1}{y} -3\ge0$ or $\frac{1}{y} -3\le0$ $y\le \frac{1}{3}$ or $y\ge \frac{1}{3}$ This doesn't make any sense! Intuitively I can see that when $x=-1$ then $f(x)=\frac{1}{3}$ and as x approaches $+\infty$ then $f(x)$ approaches zero (without ever reaching it). How do I find this solution algebraically? What are the ""rules"" for working with inequalities w/ exponents and radicals (both positive and negative)? How do I find the range for other functions such as $g(x)=3+\sqrt{16-(x-3)^2}$ and $h(x)=\frac{12x-9}{6-9x}$ algebraically? A thorough explanation would be appreciated (also, feel free to point out errors in my work- there are obviously many).","['inequality', 'functions']"
1827355,A sum of squared binomial coefficients,"I've been wondering how to work out the compact form of the following.
$$\sum^{50}_{k=1}\binom{101}{2k+1}^{2}$$","['summation', 'binomial-coefficients', 'discrete-mathematics']"
1827361,Minimizing $\cot^2 A +\cot^2 B + \cot^2 C$ for $A+B+C=\pi$,"If $A + B + C = \pi$, then find the minimum value of $\cot^2 A +\cot^2 B + \cot^2 C$. I don't know how to solve it. And can you please mention the used formulas first. What I can see is that if one of the angles $A$, $B$, $C$ is small, then the value $\cot^2A$ or $\cot^2B$ or $\cot^2C$ will be big. So I want to make angles big (more precisely, close to $\pi/2$, where cotangent is zero), but the condition $A+B+C=\pi$ prevents me from making all three of them very big . I can see that if $A=B=C=\frac\pi3$, then I get $\cot A=\cot B=\cot C=\frac1{\sqrt3}$ and $\cot^2A+\cot^2B+\cot^2C=1$. But I do not know whether this is indeed minimum. (According to WolframAlpha this is the minimum . However, I would like to see some proof of this fact.)","['triangles', 'inequality', 'trigonometry', 'optimization']"
1827390,Cutting an equilateral triangle into $n$ equal pieces,"We have an equilateral triangle and we want to cut it into $n$ equal triangular pieces. For which $n$ is it possible? My Attempt : I found these possible numbers: $2,3,4,6$ . I also proved every $n$ of the form $4^n$ . Note : I don't mean equal areas, I mean equal triangles.","['dissection', 'geometry']"
1827411,Evaluate $ \int_{0}^{1} \log\left(\frac{x^2-2x-4}{x^2+2x-4}\right) \frac{\mathrm{d}x}{\sqrt{1-x^2}} $,"Evaluate : $$ \int_{0}^{1} \log\left(\dfrac{x^2-2x-4}{x^2+2x-4}\right) \dfrac{\mathrm{d}x}{\sqrt{1-x^2}} $$ Introduction : I have a friend on another math platform who proposed a summation question and he has a good reputation of posting legitimate questions. I worked it out to another equivalent form i.e, the above integral. Here's my work :- We start with  $\displaystyle \sum_{n=0}^\infty L_{2n+1} x^n = \dfrac{x+1}{x^2-3x + 1}  $. Replacing $x$ with $x^2$ , we get $$ \sum_{n=0}^\infty L_{2n+1} x^{2n} = \dfrac{x^2+1}{x^4-3x^2+1} $$ Integrate: $$ \sum_{n=0}^\infty \dfrac{L_{2n+1} x^{2n+1}}{2n+1} = \underbrace{\int \dfrac{x^2+1}{x^4-3x^2+1} \,\mathrm{d}x}_{:= I} $$ Then, $\displaystyle I = \int \dfrac{ 1+(1/x^2)}{x^2 + 1/x^2 - 3} \, \mathrm{d}x $. Let $t = x - \dfrac1x  \Rightarrow \left( 1 + \dfrac1{x^2} \right) \, \mathrm{d}x = \mathrm{d}t $. Then $\displaystyle I = \int \dfrac{\mathrm{d}t}{t^2-1} = \dfrac12 \log \left | \dfrac{t-1}{t+1} \right | = \dfrac12 \log \left | \dfrac{x^2-x-1}{x^2+x-1} \right | $. $$ \begin{eqnarray}
S & := & \sum_{n=0}^\infty \dfrac{ L_{2n+1}}{(2n+1)^2 \binom{2n}n } = \int_0^1 \sum_{n=0}^\infty \dfrac{ L_{2n+1}}{2n+1} (x-x^2)^n \, \mathrm{d}x  \qquad \left(\text{ Because }\dfrac1{(2n+1) \binom{2n}n} = \operatorname{B}(n+1,n+1) = \int_{0}^{1}  x^n(1-x)^n \mathrm{d}x\right) \\
&=& \int_0^1 \dfrac1{2\sqrt{x-x^2} } \log \left | \dfrac{x -x^2 - \sqrt{x-x^2} - 1}{x -x^2 + \sqrt{x-x^2} - 1} \right | \, \mathrm{d}x \\
&=& \int_0^1 f(x)\, \mathrm{d}x 
\end{eqnarray} $$ Note that $f(1-x) = f(x) $, so $\displaystyle S =2  \int_0^{1/2} f(x) \, \mathrm{d}x = 2 \int_0^{1/2} f\left( \dfrac12 - x\right) \, \mathrm{d}x $, and so $$ S = \int_0^{1/2} \dfrac1{\sqrt{\frac14 - x^2}} \log \left |\dfrac{a^2-a-1}{a^2+a-1} \right| \, \mathrm{d}x $$ where $a = \sqrt{\dfrac14 - x^2} $. Substitute $x = \dfrac12 \cos (\theta) $ and simplify: $$ S = \int_0^{\pi/2} \log \left | \dfrac{ \cos^2 -2 \cos \theta - 4}{\cos^2 + 2\cos\theta - 4} \right | \, \mathrm{d}x = \int_0^1 \log \left ( \dfrac{x^2-2x-4}{x^2+2x-4} \right) \dfrac{\mathrm{d}x}{\sqrt{1-x^2}} \\ \vdots $$ Closed Form : Recently, the same question was posted on M.S.E. albeit in a different form by another friend of mine here . That integral is obtained from this by applying Integration By Parts. Mr. Jack D'Aurizio also gave a closed form in terms of Imaginary part of Dilogarithms, specifically, $$I = -2 \ \Im \left[\text{Li}_2\left[i\left(1-\sqrt{5}+\sqrt{5-2 \sqrt{5}}\right)\right]+\text{Li}_2\left[i\left(1+\sqrt{5}-\sqrt{5+2 \sqrt{5}}\right)\right] \right]$$ However, there is a more elementary closed form that exists for the question (as evident from the original question) in terms of natural logarithm and Catalan's constant. All solutions are greatly appreciated.","['real-analysis', 'integration', 'definite-integrals', 'polylogarithm', 'sequences-and-series']"
1827436,Iterating a multiple of sine function makes a square wave,"So, I found something curious playing around with a graphing calculator. Say we start with a function, $f_1(x) = 2\sin(x)$ and we define a constant, $C$,to be the positive fixed point for $f_1(x)$. Then we talk about the recurrence relation: $f_{n}(x) = f_1 \circ f_{n-1}(x)$. It seems to be the case that: $$\lim_{n \to \infty} \frac{1}{C}f_n(x) = \begin{cases}
  \phantom{-}1 & \text{if}\ \sin(x)>0 \\
  -1           & \text{if}\ \sin(x)<0
\end{cases} $$ I toyed with using numbers other than $2$ in this nesting procedure and they all either limit towards horrendous and strange shapes or tend towards being identically zero. Does anyone have any idea as to why this composition creates a square wave, and whether or not other ""Fourier-Series"" results like this can be found this way?","['recurrence-relations', 'trigonometry', 'dynamical-systems']"
1827444,Non-negative Linear Span of Vectors,"I would like to understand if there is a common concept of a `linear span' of a set of vectors which are combined with non-negative multipliers. I know that usual definition of the span of a set of vectors as follows [wiki] : $\operatorname{span}(S) =  \left \{ {\sum_{i=1}^k \lambda_i v_i \Big| k \in \mathbb{N}, v_i  \in S, \lambda _i  \in \mathbf{K}} \right \}.$ Is there a commonly used name for a span when $\lambda _i  \in R^+$ (positive real numbers) so that I can study this further? I cannot find much material in this area. Ultimately, I am interested if there is a way to distinguish between matrices (or collections of vectors) that have full rank even if only positive multipliers are permitted. Thanks for any guidance.","['matrix-rank', 'linear-algebra', 'vector-spaces']"
1827452,"Finding the volume of Torus, Jacobian of spherical substitution.","I thought to find the volume of a Torus, like I would a sphere, where the spherical substitution was: $$x=r\cos\varphi\sin \theta , y= r\sin\varphi \sin \theta, z=r\cos \theta \\ g(r,\varphi,\theta)\mapsto(x,y,z);J_g=r^2\sin\theta.\implies V=\int_{0}^{2\pi}d\varphi \int_{0}^{\pi}\sin\theta d\theta \int_{0}^{r}r^2dr$$
Can I do something similar with a torus? Like this?Since the large Radius is fixed? $$x=(R+r\cos\theta)\cos \varphi , y=(R+r\cos\theta)\sin \varphi, z=r\sin \theta \\ g(r,\varphi,\theta)\mapsto(x,y,z);J_g=R+r\cos\theta\implies V=\int_{0}^{2\pi}d\varphi \int_{0}^{2\pi} d\theta \int_{0}^{r}(R+r\cos\theta) dr\ \ ??$$","['real-analysis', 'volume', 'calculus', 'multivariable-calculus', 'spherical-coordinates']"
1827466,$S_n$ is an integer for all integers $n$,"Let $a$ be a non-zero real number. For each integer $n$, we define $S_n = a^n + a^{-n}$. Prove that if for some integer $k$, the sums $S_k$ and $S_{k+1}$ are integers, then the sums $S_n$ are integers for all integers $n$. We have $S_{k} = a^k+\frac{1}{a^k} = m_1$ and $S_{k+1} = a^{k+1}+\frac{1}{a^{k+1}} = m_2$ where $m_1,m_2 \in \mathbb{Z}$.  Thus raising $S_k$ and $S_{k+1}$ to any positive power results in an integer. Is there a way I can prove the statement from this?",['number-theory']
1827469,Are real numbers generated uniformly at random guaranteed to be unique?,"Suppose I can generate numbers uniformly at random from an infinite set, such as: $$r \in \mathbb{R} :  0 < r < 1$$ Each number has an infinitely small probability of being generated. Does that mean any two randomly generated $r$ are guaranteed to be unique? I think this is a weaker version of the same question: Suppose an algorithm generates two bits uniformly at random. If the two bits are different, it starts over. Otherwise, it halts. Is the algorithm guaranteed to halt? (Assuming the universe can provide infinite entropy/has an infinite lifespan.)","['probability-theory', 'probability']"
1827475,Finding primes so that $x^p+y^p=z^p$ is unsolvable in the $p$-adic units,"On my number theory exam yesterday, we had the following interesting problem related to Fermat's last theorem: Suppose $p>2$ is a prime. Show that $x^p+y^p=z^p$ has a solution in $\mathbb{Z}_p^{\times}$ if and only if there exists an integer $a$ such that $p\not\mid a(a+1)$ and $$(a+1)^p=a^p+1\pmod{p^2}.$$ (I wil not show this here, it's a good exercise in Hensel's lemma) Now I'm interested for which primes this last property holds true.
This is what I found so far: Proposition: for every prime $p\equiv 1\pmod{3}$ there exists an $a\in\mathbb{Z}$ such that $p\not\mid a(a+1)$ and $p^2\mid(a+1)^p-a^p-1$ . Sketch of proof: We will often use the fact that if $p\mid a-b$ then $p^2\mid a^p-b^p$ for $a,b,p\in\mathbb{Z}$ . There exists some $n\in\mathbb{Z}$ such that $p \mid n^2+n+1$ . We will show that we can take $a=n$ (it is clear that $p\not \mid n(n+1)$ ). If $n\equiv 1\pmod{p}$ , we are done because $(n+1)^p\equiv 2\equiv n^p+1\pmod{p^2}$ . So we may assume that the order of $n$ mod $p$ is 3. We see that $n^{3p}\equiv 1\pmod{p^2}$ , hence $p^2\mid \frac{n^{3p}-1}{n^p-1}=n^{2p}+n^p+1$ and therefore $(n+1)^p\equiv -n^{2p}\equiv n^p+1\pmod{p^2}$ . $\blacksquare$ What can we say about primes $p\equiv 2\pmod{3}$ ? Say a prime is bad if it satisfies the above property. It is easy to see that for $p$ to be good we only have to check that for all $1\le a \le (p-1)/2$ we have $p^2\not\mid (a+1)^p-a^p-1$ . Numerical data suggests that infinitely many primes $p\equiv 2\pmod{3}$ are good and infinitely many are bad. I'd like to find a proof of this. My numerical data furthermore suggests that there is no easy divisibility criterion to judge badness for primes, and that that there are a lot more good primes than bad ones, in terms of asymptotics. I welcome all comments/ideas/references. Edit: Here are some observations. I've listed the first bad primes, together with the set of $a\in\mathbb{Z}$ such that $1\le a \le (p-1)/2$ and $(a+1)^p\equiv a^p+1\pmod{p^2}$ : $59\qquad [3, 4, 11, 14, 15, 20]  \\
83\qquad [8, 30, 36]  \\
179\qquad [2, 59, 88]  \\
227\qquad [36, 82, 92]  \\
419\qquad[80, 110, 150]  \\
443\qquad [108, 125, 201]  \\
701\qquad [23, 61, 132, 146, 153, 252]  \\
857\qquad [6, 143, 244]  \\
887\qquad [20, 132, 168]  \\
911\qquad [14, 64, 242]  \\
929 \qquad[234, 253, 266]  \\
971 \qquad[9, 97, 108]  \\
977 \qquad[102, 182, 331] \\ 
1091\qquad [64, 234, 358]  \\
1109 \qquad[176, 400, 523]  \\
1193\qquad [224, 227, 473]  \\
1217\qquad [186, 228, 410]  \\
1223\qquad [304, 349, 409]  \\
1259\qquad [19, 62, 264]  \\
1283\qquad [19, 134, 449]  \\
1289\qquad [412, 535, 593]  \\
1439\qquad [93, 199, 294]  \\
1487\qquad [167, 416, 649]  \\
1493 \qquad[141, 179, 367]  \\
1613 \qquad[227, 473, 739]  \\
1637 \qquad[76, 279, 574]  \\
1811 \qquad[39, 123, 498, 628, 691, 743]  \\
1847\qquad [172, 362, 698]  \\
1901\qquad [3, 475, 634]  \\
1997\qquad [125, 671, 840]  \\
2003 \qquad[31, 312, 840]  \\
2087 \qquad[31, 202, 586]  \\
2243 \qquad[252, 593, 1077]  \\
2423\qquad [353, 704, 857]  \\
2477\qquad [17, 688, 1020]  \\
2579 \qquad[294, 576, 693]  \\
2591 \qquad[322, 345, 368]  \\
2729\qquad [1024, 1049, 1089] \\ 
2777\qquad [488, 1078, 1269]  \\
2969\qquad [341, 789, 1158]  \\
3089\qquad [677, 1015, 1053]\\
3137\qquad [1227, 1308, 1427]\\
3191\qquad [776, 916, 1383]\\
3203\qquad [1214, 1305, 1587]\\
3251\qquad [164, 337, 1260]$ I also found this sequence on OEIS , along with more numerical data , where it is claimed (but not proved) that the density of bad primes is roughly $\frac 16$ . My numerical data also suggests that the number of $a\in\mathbb{Z}$ satisfying $1\le a \le (p-1)/2$ and $p^2\mid (a+1)^p-a^p-1$ is always either $3$ or $6$ , but I think that's rather a bold statement. (edit: indeed, 20123 is a counterexample with $9$ solutions, found by Michael Stocker. The weaker statement that the number of such solutions is divisible by $3$ is true, however: see here .) Edit: Someone showed me these slides, where the above criterion for solvability of $x^p+y^p=z^p$ in the $p$ -adic units is stated.    (There is a remark that it can be proven with eisenstein reciprocity that for all non-Wieferich primes the first case of FLT holds true - maybe there is some way to use this for some (partial) result on our problem? I'm really curious.)","['diophantine-equations', 'p-adic-number-theory', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
1827476,Failure of an elementary 'proof' of Fermat's Last Theorem?,"Can someone explain to me why this does not constitute a proof of Fermat's Last Theorem, please? Basically, using something I've read online, it appears you can write an equation for $(a, b, c)$ to find solutions for equations $a^n + b^n = c^n$ in the form of
$$a = (u^2 - v^2)^{2/n}, \: b = (2uv)^{2/n},\: c = (u^2 + v^2)^{2/n}$$ which won't produce integer solutions for $n > 2$. Could someone explain to me the mistake in this "" proof "" please? The full work is here (there's no downloading required because it's just a PDF). Thanks in advance","['number-theory', 'fake-proofs', 'diophantine-equations', 'proof-verification']"
1827486,Why does Van Kampen Theorem fail for the Hawaiian earring space?,"The Hawaiian earring space has notoriously complicated fundamental group, and is essentially not as simple as the wedge sum of countably many circles whose fundamental group is straightforwardly given by Van Kampen Theorem. However, I'm still struggle to understand why Van Kampen fails in this case. I can, however, largely grasp the topological difference between the two. For instance, the wedge point of countably many unit circles is locally contractible while that of the Hawaiian earring is not. But, when checking the Van Kampen Theorem given by Allen Hatcher, I really can't find anything wrong with the earring: Path-connectedness is trivial. It really suffices to check the red-boxed condition. Of course, for each circle, say $C_n:=\{(x-1/n)^2+y^2=1/n^2\}$ , in the earring space, we can always find an open subarc $L_n$ that deformation retracts onto $(0,0)$ , the wedge point. So why isn't the theorem applicable?","['algebraic-topology', 'general-topology', 'fundamental-groups']"
1827541,Showing that the omega and the alpha limits are disjoint or have just one common point,"Let $f:\mathbb R^2\rightarrow \mathbb R^2$ be a $C^1$ function and $x'=f(x)$. Suppose that there are finites points $x_i\in \mathbb R^2$, such that $f(x_i)=0$. Given $y$, such that $f(y)\neq 0$, and the flux through $y$ is not periodic, then the $\omega$-limit and the $\alpha$-limit are disjoint, or both are equal to $\{x_0\}$, and moreover $f(x_0)=0$. I'm trying to show that if they are not disjoint, then there is one point, by supposing that there is another point in one of them, and then getting an absurd. But I can't get it done, hope that you have some tips to me. Thanks in advance.","['ordinary-differential-equations', 'analysis']"
1827550,Stirling number equality,"How to prove that $\left\{{n}\atop{k}\right\} = \sum_{i_1,\ldots,i_{n-k}}i_1\cdot i_2\dots i_{n-k} \cdot [1\le i_1\le i_2 \le \ldots \le i_{n-k}\le k]\ $ and $\left[{n}\atop{k}\right] = \sum_{i_1,\ldots,i_{n-k}}i_1\cdot i_2\dots i_{n-k} \cdot [0< i_1 < i_2 < \ldots < i_{n-k} < n]$? Sorry but I don't know even how to begin...","['combinatorics', 'discrete-mathematics']"
1827557,Why are there no finitely additive measures on $\ell_\infty$ for which the measure of every ball is positive and finite?,"As the question title suggests, why are there no finitely additive measures on $\ell_\infty$ for which the measure of every ball is positive and finite? Here, we do not assume that the measure is translation invariant.","['functional-analysis', 'real-analysis', 'lp-spaces', 'measure-theory']"
1827570,What is the probability that they have no common prime factor?,"I am seeking a simple way to solve the following problem. It is an easy problem, but I don't like the way I solve the problem. I listed two sets of numbers and counted one by one first and then find the probability. It works for this problem. But if the problem changes a little, such as change 9 to 1000, my method will not work. Two different integers are randomly selected from the set of integers greater than 2 and less than 9. What is the probability that they have no common prime factor?",['probability']
1827587,If $a$ and $b$ be the roots of the quadratic equation $x^2-6x+4=0$ then find the value of given expression.,Let $a$ and $b$ be the roots of the quadratic equation $x^2-6x+4=0$ and $P_n = a^n + b^n$ then the value of $$\frac{P_{50}(P_{48}+P_{49})-6P_{49}^2+4P_{48}^2}{P_{48}.P_{49}}$$ Options are $(A)$ $2$ $(B)$ $1$ $(C)$ $4$ $(D)$ $10$ Here roots are $x=3\pm \sqrt5$ but how are we going to calculate such big powers. Roots are real so we don't have advantage of De-Movier's theorm. Could someone suggest something?,"['algebra-precalculus', 'quadratics']"
1827600,Understanding the solutions to questions concerning cardinalities and power sets.,"Let $A = \{1, 2, 3, ... , n\}$ . Find the cardinalities of the following sets: $\{(a, S) \mid a \in S, S \in P(A)\} $ $\{(S, T) \mid S \in P(A), T \in P(A), S\cap T = \emptyset \}$ Please note that I have only recently (a week ago) started to study some basic, introductory set theory, and will probably need a detailed explanation. Prior to this exercise, my book only offered a brief definition of a power set and of the cartesian product. $\{(a, S) \mid a \in S, S \in P(A)\}$ What confuses me here is the fact that when considering the cartesian product, we normally multiply the cardinalities of the sets, but in this case, the cardinality of $S$ seems to vary, as it is an element of the power set. The book mentioned that I should start with choosing $n$ elements from $A$ and that there are $2^{n-1}$ choices for $S$ . From where does the latter come from? $\{(S, T) | S \in P(A), T \in P(A), S\cap T = \emptyset \}$ The solution to this one, $3^n$ , I don't understand at all.",['elementary-set-theory']
1827686,Circle packing – How to get the minimum length?,"In an a past admission paper from a local university, I came across a problem I couldn't solve. Given $n$ circles with their respective radii $r_1, r_2, \dotsc , r_n,$ we are to find the minimum width of a rectangle to encapsulate all the given circles. The placement of the circles, along with an example case may be found here: The problem, as I see it, is identifying the overlapping portion of the segments determined by the radii of adjacent circles of different diameters, and deduct the length of any such overlapping segment from the total sum of the radii. It may be because I have no training in geometry, or I'm simply missing something trivial, but I can't see a solution. How would you solve this?","['algorithms', 'packing-problem', 'geometry']"
1827734,How can I solve this hard system of equations?,"Solve the system below \begin{align}
&\sqrt {3x} \left( 1+\frac {1}{x+y}  \right) =2\\
&\sqrt {7y} \left( 1-\frac{1}{x+y}  \right) =4\sqrt{2}
\end{align} Frankly I am disappointed, because I spent around 2 hours in solving this equation, but, finally I didn't do it so, I hope you can help me in approaching this problem.","['algebra-precalculus', 'radicals', 'systems-of-equations']"
1827740,Convergence of the integral $\int_0^\infty f(x)\frac{xf'(x/(1-1/N))}{f(x/(1-1/N))}\ \mathsf dx$ as $N\to\infty$,"How can calculate this integral $$\lim_{N \to \infty} \int_{x=0}^{\infty}f(x) \frac{x f'\left(\frac{x}{1-1/N}\right)}{f\left(\frac{x}{1-1/N}\right)} dx$$ where $f(x)$ is a probability density function? If there exist a function $g(x)$ such that $$\Bigg|f(x) \frac{x f'\left(\frac{x}{1-1/N}\right)}{f\left(\frac{x}{1-1/N}\right)}\Bigg|< g(x)$$ for all $N$, then 
 I can use the Dominated Convergence Theorem. But can I calculate the integral without such an assumption? I am thinking maybe the probability function $f(x)$ has some characteristics that could help. Any idea?","['probability-theory', 'improper-integrals', 'integration', 'probability', 'convergence-divergence']"
1827764,Prove that $\int_{0}^{\infty}\left(2\cdot{1-e^x\over 1-e^{3x}}+{1+e^x\over 1+e^{3x}}\right)dx=\ln{3}$,"We wish to prove that $$I=\int_{0}^{\infty}\left(2\cdot{1-e^x\over 1-e^{3x}}+{1+e^x\over 1+e^{3x}}\right)dx=\ln{3}\tag1$$ $$1-e^{3x}=(1-e^x)(1+e^x+e^{2x})\tag2$$ $$1+e^{3x}=(1+e^x)(1-e^x+e^{2x})\tag3$$ Sub $(2)$ and $(3)$ into $(1)\rightarrow (4)$ $$I=\int_{0}^{\infty}\left(2\cdot{1\over 1+e^x+e^{2x}}+{1\over 1-e^x+e^{2x}}\right)dx\tag5$$ Any hint, please, I am unable to continue. $$I=\int_{0}^{1}\left({2u\over u^2+u+1}+{u\over u^2-u+1}\right)du=I_1+I_2\tag6$$ Respectively. Apply formula (17) to $(6)$ Hence $$I_1=\ln{3}-{2\sqrt3\over 3}\tan^{-1}\left({3\over \sqrt3}\right)$$ $$I_2={2\over \sqrt3}\tan^{-1}\left({\sqrt3 \over 3}\right)$$ Hence $I=\ln{3}$","['integration', 'definite-integrals', 'calculus']"
1827836,Finding partial fractions expansions mentally,"On a problem on a test, my students were asked to find $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^3-2x^2} dx$, and one student began by writing $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^2(x-2)} dx=\int\left(\frac{3}{x^2}+6x+\frac{2}{x-2}+\frac{8}{x}+5\right)dx$. My question is how someone can get this result without doing any division or partial fraction decomposition -- what techniques can be used to get this?","['integration', 'calculus']"
1827859,Splitting Line Segments and Finding Expected Value,"Consider a line segment which has a length of $2n-3$. It is split into $n$ segments at random. It is guaranteed that $n\ge 3$ and $n\in \mathbb{Z}$. These smaller lines are then used as the sides of a convex $n$-polygon. However, the lines are arranged in a way that the area is maximum. Additionally, there are ${2n-4}\choose {n-1}$ total ways to split the original line and occur with same probability. How can we find the expected value of the area? If we work out the case for $n=3$, there will have to be $2$ splits. All three smaller lines have to be of the same size if we look at the above conditions. So now, we have a triangle whose sides are all $1$ and so the area is $\frac{1}{4}\sqrt{3}$. $n=3$ seems to be a simple case. What about for larger $n$? Can we derive a formula for general $n$, or is each case independent of one another?","['expectation', 'statistics', 'probability', 'geometry', 'combinatorics']"
1827862,"Let $a,b,x,y\in \mathbb{Z}$, with $ax-by=1$. How to prove that $gcd(a+b,x+y)=1$?","My guess is that if i start with this  $ax-by=1$, by transforming that into a $gcd()$ form, like $gcd(ax,-by)$, or $gcd(a,-b)$ and this way i could be able to reach the end result. However, i can't reach anywhere useful and i'm very unsure about a lot of things. I'm new in number theory. If anyone could help, i would be very grateful. Thanks in advance!","['number-theory', 'elementary-number-theory']"
1827873,Uniqueness of the uniform spherical distribution,"Suppose that $X,Y$ are random vectors on some (possibly different) probability spaces mapping to $\mathbb R^n$ for some $n\in\mathbb N$. Suppose furthermore that $\|X\|=r>0$ for all realizations of the sample space on which $X$ is defined, $\|Y\|=r$, if $U$ is an orthogonal matrix, then $U X$ and $X$ have the same distribution, and if $U$ is an orthogonal matrix, then $U Y$ and $Y$ have the same distribution. I want to show that $X$ and $Y$ must generate the same Borel probability distribution on $\mathbb R^n$. That is, there is a unique uniform distribution on the surface of the $n$-dimensional sphere of radius $r$. I tried showing that the characteristic functions corresponding to $X$ and $Y$ must coincide. In doing so, I managed to derive that if the characteristic function of $X$ is, say, $\varphi:\mathbb R^n\to\mathbb C$, then the following must hold for any $t\in\mathbb R^n$ and any orthogonal matrix $U\in\mathbb R^{n\times n}$: $$\varphi(t)=\varphi(U^{\mathsf T}t).$$ Any further hints would be appreciated.","['probability-theory', 'probability', 'measure-theory']"
1827886,Open vs Closed Immersions of Locally Ringed Spaces,"I'm reading Qing Liu's book at the moment and I'm trying to figure out why open immersions of locally ringed spaces are required to be isomorphisms on stalks, but closed immersions are only required to be surjective on stalks. I searched the site, googled a bit, and doodled around with the nature of sheaves not being ""nice"" with respect to images (i.e. needing sheafification in general), but no luck. Any good explanations?","['ringed-spaces', 'algebraic-geometry', 'definition']"
1827938,"Let $R$ be a commutative ring, $\phi :R\to S^{-1}R, \phi(r)=\frac{r}{1}$ then $\phi(r)$ is invertible iff $r\in S$","$R$ is an arbitrary commutative ring with identity, and $S\subset R$ is multiplicative. I read that the map $\phi :R\to S^{-1}R, \phi(r)=\frac{r}{1}$ is characterized by the set $S'=\{s:\phi(s)\text{ is invertible}\}$, but I can't seem to prove that $S'=S$ necessarily. The best I can do is prove $S\subset S'$.","['localization', 'abstract-algebra', 'ring-theory', 'commutative-algebra']"
1827939,"supremum, infimum, max and min - assistance understanding the difference","I think I understand the very basic concepts of these terms, but wanted to check my understanding here. The max is the largest number in the set. The supremum is the least upper bound number in the set. The min is the smallest number in the set. The infimum is the greatest lower bound in the set. In a way these all seem like they are saying the same thing, which I know they are not.  Can you all help me to understand it via the following examples? $\{2.9, e, \pi, 2\sqrt{3}, 10/3\}$ If I were to guess I'd say the max is $2\sqrt{3}$ , min $e$ , and that there is no supremum or infimum. $\{x \in \mathbb R : x \gt -5\}$ For this one I'd say there is no max, supremum or infimum, but the min is -5. Any assistance in understanding how to find these is greatly appreciated.","['real-analysis', 'supremum-and-infimum', 'elementary-set-theory']"
1827941,Square root confusion: Why am I getting an answer if it doesn't work?,"Alright, so I have $\sqrt{x-15} = 3-\sqrt{x}$.
I first square both sides to get $x-15 = (3-\sqrt{x})(3-\sqrt{x})$ which simplifies to $x-15 = 9 -6\sqrt{x} + x$. I solved for $x$ and got $x = 16$, however, when I plug it in, the equation doesn't work. Why does this happen?","['algebra-precalculus', 'radicals', 'proof-verification']"
1827949,"Complex function $f$ is either constant or unbounded, but maximum value still does exist even if $f$ is not constant?","In Complex Variables and Applications , Brown & Churchill (9th edition), I stumbled upon a chapter which got me somewhat confused. On page 175 of the book, there is the theorem, which states the following: If a function $f$ is analytic and not constant in a given domain $D$, then $\left| f(z) \right|$ has no maximum value in $D$. That is, there is no point $z_0$ in the domain such that $\left|f(z) \right|\le \left|f(z_0) \right|$ for all points $z$ in it. To me, this means that $f$ is unbounded on $D$ if it's not constant. But now there is a Corollary on page 176 which seems to contradict this theorem, and which goes as follows: Suppose that a function $f$ is continuous on a closed bounded region $R$ and that it is analytic and not constant in the interior of $R$. Then the maximum value of $\left|f(z) \right|$ in $R$, which is always reached, occurs somewhere on the boundary of $R$ and never in the interior. And also there's this theorem: Suppose that $\left| f(z) \right| \le \left| f(z_0) \right|$ at each point $z$ in some neighborhood $\left| z - z_0\right|<\varepsilon$ in which $f$ is analytic. Then $f(z)$ has the constant value $f(z_0)$ throughout that neighborhood. So, we have three theorems, where one says that $f(z)$ is either constant or unbounded. Another theorem says that there actually does exist a maximum value of $f$ if it's not constant. While the third theorem says that, nevertheless, $f$ must be constant if it's bounded. I would really appreciate if someone could please clear this confusion of mine.","['complex-analysis', 'functions']"
1827969,Restricted equality involving prime numbers,"Given three real numbers such that $a + b + c = 0$, it can be proved that
\begin{align*}
\frac{a^{5} + b^{5} + c^{5}}{5} & = \frac{a^{3} + b^{3} + c^{3}}{3}\cdot \frac{a^{2} + b^{2} + c^{2}}{2}\\
\frac{a^{7} + b^{7} + c^{7}}{7} & = \frac{a^{5} + b^{5} + c^{5}}{5}\cdot \frac{a^{2} + b^{2} + c^{2}}{2}
\end{align*}
Thence I would like to ask: given three real numbers under the same restriction as above and prime numbers $p_{2} = p_{1} + 2$, for which of them does the following equation hold:
\begin{align*}
\frac{a^{p_{2}} + b^{p_{2}} + c^{p_{2}}}{p_{2}} & = \frac{a^{p_{1}} + b^{p_{1}} + c^{p_{1}}}{p_{1}}\cdot \frac{a^{2} + b^{2} + c^{2}}{2}
\end{align*}
Thank you in advance.","['algebra-precalculus', 'number-theory', 'polynomials', 'prime-numbers']"
1827971,"Expected value of $x^t\Sigma x$ for multivariate normal distribution $N(0,\Sigma)$","For standard normal distribution, the expected value of $x^2$ is $1$. A natural question is that in the multivariate case, what is the expected value of $x^t\Sigma x$ for multivariate normal distribution $x \sim N(0,\Sigma)$? I have difficulty to carry out the integral, but would guess the result is related to the norm of $\Sigma$.","['gaussian-integral', 'statistics', 'probability', 'normal-distribution']"
1827973,"Improper integral complex analysis $\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$","I tried the following problem but I don't think I got the right answer. I checked it by substituting $a=\frac{1}{2}$ into the integral and putting that through Wolfram Alpha but it didn't match the answer I found when I substituted $a=\frac{1}{2}$ into my final answer. So I would be so grateful if someone could tell me where I went wrong. I'm not sure if there's an easier contour than a rectangle but if there is please don't suggest any because I was required to solve this problem using a rectangular contour. Thank you in advance! :) Problem: Evaluate $$\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ where $-1<\operatorname{Re}(a)<1$ using a rectangular contour integral and residue calculus. My attempt: $$\cosh(z)=\cos(iz)=0$$
$$z=\frac{i\pi}{2}-k\pi i,k\in Z$$ Let $L>0$ be a real number, and $C_1, C_2, C_3, C_4$ be the line segments that go from $-L$ to $L$, from $L$ to $L+\pi i$, from $L + \pi i$ to $-L+\pi i$ and from $-L+\pi i$ to $-L$, respectively.  Let $C = C_1 + C_2 + C_3 + C_4$, a  rectangular contour surrounding the singularity $z=\frac{i\pi}{2}$. $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=\int_{-L}^L \frac{e^{ax}dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Now, $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=2\pi i \operatorname{Res} \left(\frac{e^{az}}{\cosh(z)};\frac{i\pi}{2}\right) =2\pi i \lim_{z \rightarrow \frac{i\pi}{2}}\frac{e^{az}(z-\frac{i\pi}{2})}{\cosh(z)}=-ie^{\frac{ai\pi}{2}}$$ and $$\int_{-L}^L \frac{e^{ax} \,dx}{\cosh(x)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)}$$ using the fact that $\cosh(x+\pi i)=-\cosh(x)$. $$\Rightarrow -ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Then after showing that $\int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}$, $\int_\pi^0 \frac{e^{a(-L+iy)}i\,dy}{\cosh(-L+iy)} \rightarrow 0$ as $L\rightarrow \infty$ we find that $$-ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ $$\Rightarrow \int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)} = \frac{-i e^{\frac{ai\pi}{2}}}{(1+e^{a\pi i})}$$","['complex-analysis', 'improper-integrals', 'residue-calculus']"
1827981,Existence of rotations between two points,"Let $x,y\in\mathbb R^n$ ($n\in\mathbb N$) be two given points with the same Euclidean norm: $\|x\|=\|y\|$. Does there, in this case, exist an orthogonal matrix $U\in\mathbb R^{n\times n}$ such that $$Ux=y\quad\text{ and }\quad U^{\mathsf T}U=I?$$ I don’t need an explicit construction, just mere existence. Would the Gram–Schmidt procedure help construct an appropriate orthonormal basis as the columns of $U$?","['functional-analysis', 'linear-algebra', 'hilbert-spaces']"
1827985,Show that the unit sphere is connected [duplicate],"This question already has an answer here : Is the unit sphere in $\Bbb R^4$ path connected? (1 answer) Closed 8 years ago . I need to show that $\{(x,y,z)\in\mathbb{R}^{3}:x^2+y^2+z^2 = 1\}$ is connected. Intuitively I understand that it is path connected and, therefore, connected. However, I don't understand how I would define such a path mathematically. For example, if I wish to show that every point on the unit sphere connected to the north pole and, therefore, to every other point, how would I show this?","['path-connected', 'connectedness', 'elementary-set-theory', 'geometry', 'linear-algebra']"
1828029,Proving that $3 + 3 \times 5 + 3 \times 5^2 + \cdots+ 3 \times 5^n = [3(5^{n+1} - 1)] / 4$ whenever $n \geq 0$,"Use induction to show that $$3 + 3 \times 5 + 3 \times 5^2 + \cdots+ 3 \times 5^n= \frac{3(5^{n+1} - 1)}{4} $$whenever $n$ is a non-negative integer. I know I need a base-case where $n = 0$:
$$3 \times 5^0 = \frac{3(5^{0+1} - 1)}{4}\\LHS = 3  = \frac{12}{4} = RHS$$ Next I need to show that this is true for the $n + 1$ (next) term through a proof using induction. This is really where I could use a concrete example of a proof; I have yet to find one that I could really understand.","['induction', 'discrete-mathematics']"
1828051,Dihedral groups: Relationship between symmetries and rigid motions,"In Dummit & Foote, $D_{2n},\ n \geqslant 3$ is the set of symmetries of a regular $n$-gon, where a symmetry is a rigid motion of the $n$-gon which can be effected by taking a copy of the  $n$-gon, moving this copy in any fashion in $3$-space and then placing the copy back on the original $n$-gon so it exactly covers it. Question 1 : What does it mean by moving this copy in any fashion? How can I find the inverse of every rigid motion? Using this definition, the book calculates the order of $D_{2n}$, it reasons as follows: Given any vertex $i$, there is a symmetry which sends vertex 1 into position $i$. Since vertex 2 is adjacent to vertex $1$, vertex 2 must end up in position $i+1$ or $i-1$ by some symmetry. Thus there are $2n$ positions the ordered pair of vertices 1,2 may be sent to upon applying symmetries. Question 2 : It is clear that in this case I can achieve those symmetries by rotating the $n$-gon or first reflecting then rotating the $n$-gon. But when I consider the group of the rigid motion of a tetrahedron using the same reasoning, how can I justify that every symmetry can actually be achieved by some sort of rigid motion?","['abstract-algebra', 'symmetry', 'dihedral-groups', 'group-theory']"
1828057,Prove that an infinite chain of proper containments of compact sets is non empty [duplicate],"This question already has an answer here : Let $\{K_i\}_{i=1}^{\infty}$ a decreasing sequence of compact and non-empty sets on $\mathbb{R}^n.$ Then $\cap_{i = 1}^{\infty} K_i \neq \emptyset.$ (1 answer) Closed 8 years ago . I need to prove that if $K_1\supset K_2 \supset K_3 \supset K_4 \supset \ldots$ is a chain of proper containments and each $K_{i}\subseteq \mathbb{R}^{n}$ is compact, then $\bigcap_{i=1}^{\infty} K_{i} \neq \emptyset$. I understand that $K_i \neq \emptyset, \forall i$ because of the proper subset condition and since the empty set has no proper subsets. I also understand that the compact condition is necessary in order to prevent sets that limit, at infinity, to an empty set but for no $i$ are empty themselves (example: $K_i=(0, 1/i)$). However, I'm not sure how to complete.","['compactness', 'elementary-set-theory']"
1828126,Show that $x^2 + y^2 + z^2 \ge 35$ if $x+3y+5z \ge 35.$,"Show that $x^2 + y^2 + z^2 \ge 35$ if $x+3y+5z \ge 35.$ I have tried everything (proof by contradiction, etc.) but I can't seem to get it. The book didn't give any constraints whatsoever. Any hints would be appreciated. Thank you.","['algebra-precalculus', 'inequality']"
1828152,"How do I find $\lim_{n\to \infty}\left [\left (1+\frac{2}{n^a}\right )^{-n^b}n^c\right ]$ for real $a,b,c$ and $n\geq 1$?","Evaluate $\displaystyle\lim_{n\to \infty}\left [\left (1+\frac{2}{n^a}\right )^{-n^b}n^c\right ]$ for real $a,b,c$ and $n\geq 1$. I am not sure how to do this but the hint given is to consider various cases of $a>b$, $a<b$, $a=b$ and $c>0$, $c<0$.","['sequences-and-series', 'calculus', 'limits']"
1828194,Radon-Nikodym with respect to Stochastic Measure?,"Question This question is now concerning stochastic processes.
Let $(X_t)_{t\geq0}$ be defined on the probability space $(\Omega,\mathcal{F},P)$ with $\mathcal{F}_t=\sigma(X_s:s\leq t)$.
Assume that for the restircted measures it holds $P_{|\mathcal{F}_t}\ll Q_{|\mathcal{F}_t}$. Then $$f(\mathcal{F}_t)=\frac{dP_{|\mathcal{F_t}}}{dQ_{|\mathcal{F}_t}} \tag1$$
  is $\mathcal{F}_t$ measurable by radon-nikodym and thus is a.s. a function of $(X_s)_{s\leq t}$, say $g((X_s)_{s\leq t})$. Can we conclude that the following holds, considering the push forward measures $P^{(/X_s)(\omega))_{s\leq t}}$? $$f(\mathcal{F}_t)(\omega)=\frac{dP_{|\mathcal{F_t}}}{dQ_{|\mathcal{F}_t}}(\omega)=\frac{dP^{(X_s(\omega))_{s\leq t}}}{dQ^{(X_s(\omega))_{s\leq t}}}=g((X_s(\omega)_{s\leq t}) \tag2$$ What can we say about this situation? 
What does this mean? Are the pushforward measures  induced by the sample path $(X_s)_{s\leq t}$? And can we think of the Radon-Nikodym-Density of $P\ll Q$ on $\mathcal{F}_t$ as the Likelihood-function of the joint-density of $(X_s)_{s\leq t}$? Or do we say that (1) can be expressed almost surely as a function of the sample path $(X_s)_{s\leq t}$? What I know from more elementary probability theory Let $X$ be a random variable mapping to $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ and $\mathcal{F}^{X}=X^{-1}(\mathcal{B}(\mathbb{R}))$.
Assume there is a measure $Q$, such that 
$P_{|\mathcal{F}^{X}}\ll Q_{|\mathcal{F}^{X}}$.
We define the Radon-Nikodym density as $$f(\mathcal{F}^{X})=\frac{dP_{|\mathcal{F}^{X}}}{dQ_{|\mathcal{F}^{X}}}$$ If this is case  for the pushforward measures it holds $P^{X}\ll Q^{X}$, where $Q^{X}(B)=Q(A)$ and $A:=X^{-1}(B)\in \mathcal{F}^{X}$.
We can define a Radon-Nikodym density as $$g(X)=\frac{dP^{X}}{dQ^{X}}$$ Now the transformation theorem states, that $$f(\mathcal{F}^{X})(\omega)=g(X(\omega))\quad Q-a.s.$$","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-calculus']"
