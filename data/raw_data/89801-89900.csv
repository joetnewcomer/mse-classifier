question_id,title,body,tags
1204714,How do I find equivalence classes?,"Let A = {a, b, c, d, e} Suppose R is an equivalence relation on A. Suppose R has three equivalence classes. Also aRd and bRc. Write out R as a set. From my understanding an equivalence relation is reflexive, symmetric & transitive. I understand that but what is it saying when aRd and bRc? How can I form equivalence classes from this information?",['discrete-mathematics']
1204739,"proving that for every integer $x$, if $x$ is odd, then $x + 1$ is even (induction)","So I have to write a proof that ""for every integer $x$, if $x$ is odd, then $x + 1$ is even"". I understand what I have to do but I always get stuck at the last step which is prove that it's true for $k + 1$. Here's what I wrote down as my reasons as part of the proof: The theorem above is true for the base case (when $n=1$). Now lets assume the theorem is true for $n = k$. Now it's time to prove that the theorem is true for $n = k + 1$. If k is odd, then $(k + 1) + 1$ is even. Is my rational/jump from $3$ to $4$ correct? I feel like I'm missing a step where I have to factor and algebraically solve the problem but I don't know how to go about that. Can someone please help me? Thanks!","['induction', 'logic', 'proof-verification', 'discrete-mathematics']"
1204741,Complete intersections with respect to different sections,"Let us consider the Whitney sum $E$ of holomorphic line bundles $L_1,\dots, L_k$ on a smooth (projective) variety $X$. For a generic global section $s$ of $E$, the zero locus $Z_s := s^{-1}(0_E)$ forms a (smooth) subvariety of $X$. I would like to know how ""similar"" the subvarieties $X_s$ and $X_t$ for different generic sections $s$ and $t$ are. I think that they are connected by a deformation family (i.e. we have a smooth proper map $f:Y \to B$ with connected $B$ such that $X_s \simeq f^{-1}(b)$ and $X_t \simeq f^{-1}(b')$), because some papers say so an implicit way. But I can not find any relevant information about my question in books/lecture notes on deformation theory. Can you tell me any relevant resources mentioning a precise statement about my question?","['complex-geometry', 'algebraic-geometry', 'reference-request', 'deformation-theory']"
1204794,"Find the five different equivalence relations on the set {a,b,c}","What is the best way and easiest way to approach this problem? My first relation is going to be defined as such R = {(a,a), (b,b), (c,c)} which is reflexive, symmetric, and vacuously transitive. My second relation will be defined as such R = {(a,a), (b,b), (c,c), (a,c), (c,a)} Am I on the right track here? It seems to me that I can make more than 5 equivalence relations.. ie. R = {(a,a), (b,b), (c,c)} R = {(a,a), (b,b), (c,c), (a,c), (c,a)} R = {(a, a), (b,b), (c, c), (a,b), (b,a)} R = {(a, a), (b,b), (c, c), (b,c), (c,b)} R = {(a, a), (b,b), (c, c), (a,c), (c,a), (b,a), (a,b)} R = {(a, a), (b,b), (c, c), (a,c), (c,a), (b,a), (a,b) (b,c), (c,b)}",['discrete-mathematics']
1204829,"""Indexes the sequence"" meaning in the definition of a subsequence","Let $(a_n)$ be a sequence of real numbers, and let $n_1<n_2< n_3 <n_4 <n_5 <···$ be an increasing sequence of natural numbers. Then the sequence $a_{n_1},a_{n_2},a_{n_3},a_{n_4} ,···$ is called a subsequence of $(a_n)$ and is denoted by $(a_{n_j} )$, where $j ∈\mathbb{N}$ indexes the subsequence. What exactly is the meaning of ""indexes the subsequence"" ?",['sequences-and-series']
1204904,permutations confusion!,"Hello this is my first post , 
I am reading a book called (probability for dummies) the answer in the book for the question below has confused me ... Suppose you have four friends named Jim , Arun , Soma , and Eric. How many ways can you rearrange the individuals in a row so that Soma and Eric don't sit next to each other ? The answer in the book is 18 of the scenarios involved the two not sitting next to each other I know there are 4! = 24 ways to seat the four people But I don't understand how the author got to 18 when 2 of them cant sit next to each other would really appreciate any help thank you","['probability', 'statistics', 'permutations']"
1204926,Very Tricky Double Integral Problem,"Evaluate the Integral: \begin{align}
\int_{0}^{4}\int_{\sqrt{x}}^{2}{\mathrm{d} y\,\mathrm{d}x \over 1 + y^{3}}
\end{align} I can't understand how this would be possible. There IS a formula for evaluating $1/\left(1+y^{3}\right)$ , but it becomes an extremely complicated mess that I can't imagine could be re-integrated. Is there a simplification technique that I'm missing here $?$ .","['multivariable-calculus', 'definite-integrals', 'integration']"
1204949,Why Laplace transform equals zero if and only if $f(x)=0$?,"The question is how to show the Laplace transform of $L(f(x))=\int_0^{ + \infty } {f(x){e^{ - sx}}dx}  = 0$ if and only if $f(x)=0$? The question arises when I watch this video https://www.youtube.com/watch?v=Z1cmSOaEak8&index=14&list=PLbMVogVj5nJRkNUH5v9qNEJvW7r2A7rEY at 57:00, when the professor tries to prove normal distribution $N(\mu,1)$ is complete by stating $\int_{ - \infty }^{ + \infty } {g(x){e^{ - \frac{{{x^2}}}{2}}}{e^{\mu x}}dx}  = 0$ if and only if $g(x)=0$. The following is a scree capture. Thank you!","['statistics', 'calculus']"
1204969,Nilpotent and solvable groups,"If $G$ is a finitley generated group say by $x_1,\ldots,x_n$, then $G$ is abelian if 
$x_i$ and $x_j$ commute for every $i,j$. This measn we can check if $G$ is abelian by just looking at the generators. Is there a similar condition which enables to check that the group is solvable or nilpotent
by looking at the generators only?",['group-theory']
1204974,Principle of mathematical induction,"In his book “Introduction to Mathematical Philosophy” Bertrand Russell seems to reach the conclusion that mathematical induction is a definition and not a principle. In essence he states that mathematical induction works because of its definition. The use of mathematical induction in demonstrations was, in the past, something of a mystery. There seemed no reasonable doubt that it was a valid method of proof, but no one quite knew why it was valid. Some believed it to be really a case of induction, in the sense in which that word is used in logic. Poincaré considered it to be a principle of the utmost importance, by means of which an infinite number of syllogisms could be condensed into one argument. We now know that all such views are mistaken, and that mathematical induction is a definition, not a principle … (*) This is perplexing to me (perhaps because I am just beginning to study higher math). If we assume no knowledge of the principle of induction, it still works. In other words, changing the definition does not change the fact that it works. To use his example: If quadrupeds are defined as animals having four legs, it will follow that animals that have four legs are quadrupeds; However, calling them bipeds does not change the fact that they have four legs. It seems that induction works as a consequence works of the properties of the natural numbers not because of the definition of induction itself. Is this correct? (*) Introduction to Mathematical Philosophy , 33","['philosophy', 'induction', 'discrete-mathematics']"
1204986,Constructing a recursive definition.,"I know a recursive definition is a function or procedure that is defined in terms of itself, for instance $f(n) = f(n - 1) + n$ or $f(n + 1) = f(n) + n + 1$. This makes sense to me in terms of numerical expressions, but with strings it starts to get a little confusing for me. The problem I have is this: Construct a recursive definition for $f(x) = xy$, where $y$ is the reverse of $x$ for strings over the alphabet $\{ a, b \}$. I guess I start getting confused when it says y is the reverse of x. So what I am thinking is that we have this: $f(\Lambda) = \Lambda$, $f(xa) = af(x)$, $f(xb) = bf(x)$. But them I am confused on where $y$ goes. Any ideas on what I am doing wrong?","['computer-science', 'discrete-mathematics', 'functions']"
1204991,Why is $\operatorname{Spec} \ k$ final in category of $k$ schemes?,"I am working on an exercise trying to show that $Spec \ k$ is final in category of $k$ schemes.
I am stuck and I would appreciate any assistance. Thank you! PS The definition I have for $k$ scheme is that it is a morphism of the form $X \rightarrow \operatorname{Spec} \ k$ . And then I know from the exercise I did that $X \rightarrow \operatorname{Spec} \ A$ are in natural bijection with ring morphisms $A \rightarrow \Gamma (X, O_X)$ . So I figured if I have a $k$ scheme, then it follows that
there exists a corresponding ring morphism $k \rightarrow \Gamma (X, O_X)$ .
I guess I was wondering how this is unique.",['algebraic-geometry']
1205013,How do you prove the almost sure convergence is not (in general) metrizable?,How do you prove the almost sure convergence is not (in general) metrizable? Many thanks for your help.,"['probability-theory', 'probability', 'convergence-divergence']"
1205039,Proving Any connected subset of R is an Interval,"Common Proof: Suppose $S$ is not an interval of $R$. Then by Interval Defined by Betweenness, $∃x,y∈S$ and $z\in R∖S$ such that $x<z<y$. Consider the sets $A_1=S∩(−∞,z)$ and $A_2=S∩(z,+∞)$. Then $A_1,A_2$ are open by definition of the subspace topology on S. Neither is empty because they contain x and y respectively. They are disjoint, and their union is S, since z∉S. Therefore $A_1∣A_2$ is a separation of S. It follows by definition that S is disconnected. But why are $A_1,A_2$ open sets?","['metric-spaces', 'general-topology']"
1205049,Function with an $x$ not in simple form,"I've stumbled upon a practice example in an old textbook which I find confusing. Maybe it's because I haven't reached part of an explanation yet (went through pages, haven't found anything of help). Also, task doesn't have a solution offered. Some do, some don't - it's a weird textbook of ye old age (and country). Here's what it states (sorry for possible rough translation): For a given function: $$f(x)=\sqrt{x^2-6x+9}-\sqrt{x^2+6x+9}$$ a) How much is $f(x)$, for $-2 < x < 2$? b) Calculate $f(\sqrt{2}-\sqrt{3})$ I admit I haven't seen this before, so I would really appreciate if someone would guide me through this, step by step preferable since I have no one to ask. I struggle with the meaning here of how much is $-2 < x < 2$. I understand this can't be an $x$ value itself. I guess it's supposed to be a range of a given function? So what is it then? A range of values I should put into a function or something? What I did is I have ""simplified"" the function first (don't know if there's a term for it?). 
here's what I did so far: 1: $f(x)=\sqrt{x^2-6x+9}-\sqrt{x^2+6x+9}$ 2: $f(x)=\sqrt{{(x-3)}^2}-\sqrt{{(x+3)}^2}$ <- factored quadratics basically 3: $f(x)=\lvert(x-3)\rvert-\lvert(x+3)\rvert$ <- cancelled out sqrts with ^2 exponents but how would I proceed now with given tasks? PS
Sorry I couldn't think of a better title.","['terminology', 'functions']"
1205086,$\mathrm{Aut}(D_4)$ is isomorphic to $D_4$,"Problem statement : I need to find out if $\mathrm{Aut}(D_4)$ is isomorphic to $D_4$ and explain my answer. I already know that it is isomorphic, so now all I need to do is to prove it. I assume that first we need to look where it sends $s$ and $t$ and it must send them to elements that satisfy the same relations()
And then need to show that those two are conjugation by some element in $D_4$(?) Any help is appreciated.
I was hoping for a duplicate post, but couldn't find it. Thank you!","['abstract-algebra', 'dihedral-groups', 'group-theory', 'group-isomorphism']"
1205096,Gamblers ruin formula,"Hello , I have been reading about gamblers ruin and I found this formula can anyone confirm its accuracy ?   I assume they only bet one chip a time","['gambling', 'probability', 'statistics', 'game-theory']"
1205103,Laplace Transform of an Piecewise Function,"Write $f(t) = \begin{cases}
5,& \mbox{if} \quad 0 \leq t \lt 3 \\
-4,& \mbox{if} \quad 3 \leq t \lt 7 \\
0,& \mbox{if} \quad t \geq 7   
\end{cases}$ as a unit step function and find the Laplace transform. Workings: The unit step function is $f(t) = 5 + u(t-3)(-9) + u(t-7)(4)$ $f(t) = 5 - 9u(t-3) + 4u(t-7)$ The Laplace transform would then be: $\mathcal L \{f(t)\} = \mathcal L \{5\} - 9 \mathcal L \{u(t-3)\} + 4 \mathcal L \{u(t-4)\}$ $\mathcal L \{f(t)\} = \frac{5}{s} - \frac{9e^{-3s}}{s} - \frac{e^{-4s}}{s}$ I'm not sure if this is correct. Any help will be appreciated.","['laplace-transform', 'ordinary-differential-equations']"
1205109,Is $\sum_{n = 1}^{\infty} v_p(n) 2^{-n+1}$ a rational number?,"Fix $p \in \Bbb{Z}$ a prime number and let $v_p$ be the usual $p$-adic valuation on $\Bbb{Q}$. I would like to know if
$$
\sum_{n = 1}^{\infty} \frac{v_p(n)}{2^{n-1}}
$$
is a rational number. I think it should be, based on the following assumption (it seems reasonable to me, but I couldn't find a reference): Claim: If $(\alpha_n)$ is a sequence of algebraic integers, then
$$
\prod_{n = 1}^{\infty} \alpha_n
$$
converges in $\Bbb{C}_p$ with respect to $\left|\cdot\right|_p$ if and only if $\left| \alpha_n \right|_p \to 1$ for $n \to \infty$. (Here $\left|\cdot\right|_p$ is the unique normalised extension to $\Bbb{C}_p$ of the usual $p$-adic absolute value on $\Bbb{Q}$.) Then consider the sequence of algebraic integers $(\alpha_n) = (n^{1/2^{n-1}})$. Since
$$
\left| \alpha_n \right|_p = p^{-v_p(n)/2^{n-1}} \to 1
$$
then by the claim (if it is true) it follows that
$$
\prod_{n = 1}^{\infty} n^{1/2^{n-1}}
$$
converges to some $\alpha \in \Bbb{C}_p$. Finally, by the definition of the extension of $\left|\cdot\right|_p$ from the algebraic closure of $\Bbb{Q}_p$ to $\Bbb{C}_p$, we know that $\left| \alpha \right|_p$ is the limit of the absolute values of the partial products, i.e.
$$
\left| \alpha \right|_p = \lim_{k \to \infty} \left| \prod_{n = 1}^{k} n^{1/2^{n-1}} \right|_p = p^{-\sum_{n = 1}^{\infty} v_p(n) 2^{-n+1}}
$$
and by Proposition 1.3 and Proposition 2.1.1 of [1], chapter 3, we know that $\left|\cdot\right|_p : \Bbb{C}_p \to p^{\Bbb{Q}}$, so
$$
-\sum_{n = 1}^{\infty} \frac{v_p(n)}{2^{n-1}}
$$ Note: I'm asking because I come from algebraic number theory and this is the first time I have to do with $p$-adic analysis, plus I have never been much good at classical analysis: so please understand any blunder I may have made in this regard (and point them out, with a thorough explanation if possible or with some references)! [1] Alain Robert, A Course in $p$-adic analysis ( Google Books )","['p-adic-number-theory', 'number-theory', 'limits']"
1205121,Orthogonal Level Sets and a generalization of harmonic functions,"Forgive my ignorance of differential equations and analysis.  I was playing around with orthogonal level curves of real valued functions in the plane, and realized this is one way a person could be led to harmonic functions: The function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ has gradient
$$ \nabla f(x,y) = <f_x,f_y> $$ If we wanted a function $g$ so that the level sets of $g$ are orthogonal to those of $f$ then we can just take their gradients to be orthogonal.  The easiest way to do that is to find a $g$ so that
$$\nabla g = <-f_y,f_x> $$
But, any conservative vector field $<P,Q>$ must satisfy $P_y = Q_x$, which leads to the condition that
$$-f_{yy} = f_{xx}$$
i.e. that $\Delta f$, the Laplacian, must be zero. Now, suppose that we didn't assume that $\nabla g$ were not exactly $<-f_y,f_x>$, but instead some arbitrary multiple at each point, so that the level sets are still orthogonal.  Does this give you a more general class of functions? Then the condition becomes
$$\nabla g = \lambda(x,y) <-f_y,f_x>$$
for some positive function $\lambda$.  Then, by the product rule, and using the same $P_y = Q_x$ condition above, we get that 
$$-\lambda_y f_y -\lambda f_{yy} = \lambda_x f_x + \lambda f_{xx}$$ 
Or in another form
$$\lambda \Delta f +\nabla \lambda \cdot \nabla f = 0$$
Dividing through by $\lambda$ and subtracting over, one could also write this as
$$\Delta f = \nabla (-log(\lambda)) \cdot \nabla f$$ So the question becomes, for a function $f$, does there exist some function $h$ so that 
$$\Delta f = \nabla(f) \cdot \nabla(h)?$$
Clearly, harmonic functions satisfy this with $\lambda = 1$ and $h = 0$.  Are there functions that satisfy this that aren't harmonic? Is this a well studied class of functions?  Again, forgive me as this might be a stupid question.","['multivariable-calculus', 'partial-differential-equations']"
1205127,operation to get a diagonal matrix from a vector,"In many programs you can create diagonal matrix from a vector, like diag function in Matlab and DiagonalMatrix function in Mathematica. I'm wondering whether we can use matrix product (or hadamard product, kronecker product, etc) of a vector and identity matrices to create a diagonal matrix.
Thank you!",['linear-algebra']
1205138,Stochastic Calculus Question,"I'm new here and was hoping someone could help me answer this question. I'm reading a paper and I'm a bit confused on how they go from 1 equation to the next. They say: Let
\begin{align}
x(t) = {} & \exp\left\lbrace \int_0^t \left[\frac{\alpha(s)^2}{2} - a(s) \right] \, ds - \alpha(s) \, dB(s)\right\rbrace \\
& \times \left[ x_0 + \int_{0}^{t} b(s)\exp\left\lbrace \int_0^s \left[ a(\tau)-\frac{\alpha(\tau)^2}{2}\right] \, d\tau + \alpha(\tau) \, dB(\tau) \right\rbrace \, ds \right]
\end{align} Then $x(t)$ satisfies the equation: $$dx(t) = [(\alpha(t)^2 - a(t))\, dt - \alpha(t)\,dB(t)]x(t) + b(t)\,dt$$ Now I worked through this, but when I use their $x(t)$ and calculate $dx(t)$, I get the following: $$dx(t) = \left[\left(\frac{\alpha(t)^2}{2} - a(t)\right) \,  dt - \alpha(t)\,dB(t)\right]x(t) + b(t)\,dt$$ Here, $a(t), b(t),$ and $\alpha(t)$ are all T-periodic functions. The only difference is that extra $\frac{1}{2}$ I have where they don't. Likewise, if I start with their $dx$ and integrate, I get: \begin{align}
x(t) = {} & \exp\left\lbrace \int_0^t \left[\alpha(s)^2 - a(s) \right] \, ds - \alpha(s) \, dB(s)\right\rbrace \\
& \times \left[ x_0 + \int_0^t b(s)\exp\left\lbrace \int_0^s \left[ a(\tau)-\alpha(\tau)^2\right] \, d\tau + \alpha(\tau)\,dB(\tau)\right\rbrace \, ds \right]
\end{align} And now that extra $\frac{1}{2}$ is missing. That $\frac{1}{2}$ is very important for the rest of the paper, and I can't figure out where it goes. Can anyone please help?","['stochastic-calculus', 'ordinary-differential-equations']"
1205148,Fisher Expected Information for a Gaussian Process model,"Suppose I have a two dimensional Gaussian process model (GP), defined by a squared exponential correlation function s.t: 
$$R(x_{i},x_{j}) = \exp\left(-\frac{|x_{i} - x_{j}|^2}{2}\right).$$
I am trying to evaluate Fisher Expected Information for the GP model, defined by:
$$I(\theta) = E\left[\left(\frac{\partial \log f(x;\theta)}{d \theta}\right)^2\right].$$","['information-theory', 'statistical-inference', 'statistics', 'machine-learning', 'parameter-estimation']"
1205151,"Writing circles as $|z-a| = \lambda |z-b|$ for the same $a,b$","My problem is in the context of the complex plane. I want to know if given two disjoint, not concentric circles $C_1,C_2\subset \mathbb{C}$, can you find $a,b\in \mathbb{C}$ such that $$C_1=\{z\in \mathbb{C} : |z-a| = \lambda_1|z-b|\}$$ $$C_2 = \{z\in \mathbb{C}:|z-a| =\lambda_2|z-b|\}$$
If the problem is true, how can you find them or how can you prove the existence. If it's false, is there a counterexample?","['geometry', 'circles', 'complex-numbers']"
1205177,monoids of injections and surjections,"Let $X$ be an infinite set, and let $I(X)$ and $S(X)$ denote the monoids of injective and surjective maps from $X$ to itself, respectively.  How do $I(X)$ and $S(X)$ relate algebraically?  Is there any reason to suspect that they may be isomorphic aside from optimism?","['abstract-algebra', 'elementary-set-theory', 'monoid']"
1205189,Conditional distribution of order statistics,"Let $X_{(1)},...,X_{(n)}$ be the order statistics of a set of $n$ independent uniform $(0,1)$ random variables. Find the conditional distribution of $X_{(n)}$ given that $X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}$ I need to find: $P[X_{(n)}\le x_n| X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]$ which is equal to: $${P[X_{(n)}\le x_n, X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]\over P[X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]}$$ but I have no idea how to compute the above probability and also I don´t know how to use the fact that the variables are uniform and independent. I would really appreciate if you can help me with this problem","['probability-theory', 'probability-distributions', 'random-variables', 'uniform-distribution', 'probability']"
1205244,What are the irreducible curves on the blow up of $\mathbb{P}^{2}$?,"On the blow-up of $2$-dimensional complex projective space, $\mathbb{P}^2$, I know that
$$Pic(\mathbb{\tilde{P}^2})=\mathbb{Z}[\tilde{H}]+\mathbb{Z}[E]$$
where $\tilde{H}$ is the blow-up of the hyperplane bundle of $\mathbb{P}^2$, and $E$ is the exceptional divisor on $\tilde{\mathbb{P}}^2$. Note that $[\cdot]$ denotes numerical equivalence class. I already know that the set $\{[\tilde{H}], [E]\}$ form a basis for $\tilde{\mathbb{P}}^2$. but how do the irreducible curves on the blow-up look like?","['complex-geometry', 'algebraic-geometry']"
1205246,Find $y'$ for $\ln(x+y)=\arctan(xy)$,Find $y'$ for $\ln(x+y)=\arctan(xy)$ Here is my attempt at a solution. Is this correct? Any hints or advice would be appreciated.,"['solution-verification', 'implicit-differentiation', 'calculus', 'derivatives']"
1205257,"Differential equation Laguerre $xy''+(1-x)y'+ay=0, a \in \mathbb{R}$","The differential equation Laguerre $xy''+(1-x)y'+ay=0, a \in \mathbb{R}$ is given. Show that the equation has $0$ as its singular regular point . Find a solution of the differential equation of the form $x^m \sum_{n=0}^{\infty} a_n x^n (x>0) (m \in \mathbb{R})$ Show that if $a=n$, where $n \in \mathbb{N}$ then there is a polynomial solution of degree $n$. Let $L_n$ the polynomial $L_n(x)=e^x \frac{d^n}{dx^n} (x^n \cdot e^{-x})$ (show that it is a polynomial), $n=1,2,3, \dots$. Show that $L_n$ satisfies the equation Laguerre if $a=n(n=1,2, \dots)$. That's what I have tried: For $x \neq 0$ the differential equation can be written as: $y''+ \frac{1-x}{x}y'+ \frac{a}{x}y=0$.
$p(x)= \frac{1-x}{x}, q(x)= \frac{a}{x}$
The functions $x \cdot p(x)= 1-x, \ x^2q(x)=ax$ can be written as power series in a region of $0$.
Thus, $0$ is a singular regular point. We suppose that there is a solution of the form $y(x)=x^m \sum_{n=0}^{\infty} a_n x^n= \sum_{n=0}^{\infty} a_n x^{n+m}$.
Then $y'(x)= \sum_{n=0}^{\infty} a_n(n+m) x^{n+m-1} \Rightarrow -xy'(x)= \sum_{n=0}^{\infty} -a_n(n+m) x^{n+m}$ and $y''(x)= \sum_{n=0}^{\infty} a_n(n+m)(n+m-1) x^{n+m-2} \Rightarrow xy''(x)= \sum_{n=0}^{\infty} a_n(n+m)(n+m-1) x^{n+m-1}$ So we have 
$$\sum_{n=0}^{\infty} a_n (n+m)(n+m-1) x^{n+m-1}+ \sum_{n=0}^{\infty} a_n (n+m) x^{n+m-1} + \sum_{n=1}^{\infty} -a_{n-1} (n+m-1) x^{n+m-1}+ \sum_{n=1}^{\infty} a a_{n-1} x^{n+m-1}=0 \\ \Rightarrow a_0 m (m-1) x^{m-1}+ a_0 m x^{m-1}+ \sum_{n=1}^{\infty} \left[ a_n (n+m) (n+m-1)+ a_n(n+m)-a_{n-1}(n+m-1)+ a a_{n-1} \right] x^{n+m-1}=0$$ It has to hold: $$a_0 m^2=0 \overset{a_0 \neq 0}{ \Rightarrow } m=0$$ $$a_n (n+m) (n+m-1)+ a_n (n+m)- a_{n-1} (n+m-1)+ a a_{n-1}=0$$ For $m=0$: $a_{n} n (n-1)+ a_n n-a_{n-1} (n-1)+ a a_{n-1}=0 \Rightarrow a_n n^2+ a_{n-1} (a-n+1)=0 \Rightarrow a_n=- \frac{a_{n-1}(a-n+1)}{n^2}$ For $n=1: \ a_1=-aa_0$ For $n=2: \ a_2= \frac{aa_0(a-1)}{2^2} $ For $n=3: \ a_3=- \frac{aa_0(a-1) (a-2)}{2^2 3^2} $ For $n=4: \ a_4= \frac{aa_0(a-1)(a-2)(a-3)}{2^2 3^2 4^2} $ For $n=5: \ a_5= -\frac{aa_0(a-1)(a-2)(a-3)(a-4)}{2^2 3^2 4^2 5^2} $ We see that $a_n=(-1)^n a_0 \frac{\prod_{i=0}^{n-1} (a-i)}{\prod_{i=2}^n i^2}$ $$\frac{a_{n+1}}{a_n}=(-1) \frac{a-n}{(n+1)^2} \to 0$$ So the series $\sum_{n=0}^{\infty} a_n x^n$ converges and its radius of convergence is equal to $+\infty$. Is it right so far? Could you give me a hint what we could do in order to answer the other two questions? EDIT : Do we differentiate the Leguerre polynomial as follows?
$$$$
$$\frac{d}{dx} L_n(x)=e^x \frac{d^n}{dx^n} (x^n e^{-x})+\frac{d^{n+1}}{dx^{n+1}}(x^n e^{-x})$$ $$\frac{d^2}{dx^2} L_n(x)=e^x \frac{d^n}{dx^n} (x^n e^{-x})+ e^{x} \frac{d^{n+1}}{dx^{n+1}}(x^n e^{-x})+\frac{d^{n+2}}{dx^{n+2}}(x^n e^{-x})$$ EDIT : Substituting the above, we cannot show that $L_n$ satisfies the equation Laguerre if $a=n$. Do you maybe know how else we could show this?",['ordinary-differential-equations']
1205269,Integrating over the two form,"Let $A=(0,1)^2$. Let $\alpha:A\to\Bbb R^3$ be given by the equation $$\alpha(u,v)=(u,v,u^2+v^2+1)$$ Let $Y$ be the image set of $\alpha$. Evaluate the integral over $Y_\alpha$ of the 2-form 
$x_2dx_2\land dx_3+x_1 x_3 dx_1\land dx_3$. Can someone please give me a useful hint for solving this? Thanks in advance!","['smooth-manifolds', 'real-analysis', 'manifolds', 'differential-geometry', 'multivariable-calculus']"
1205291,Uniformly convergent implies equicontinuous,"I'm trying to prove that if I have a sequence of continuously differentiable functions $f_n$ that converge uniformly on $[a,b]$ , then $\{f_n\}$ is equicontinuous for all $x_0 \in [a, b]$ . My idea is to use uniform convergence to deal with the ""tail"" and then use continuity to deal with the finitely many $f_n$ 's left. But I'm having trouble writing it down.","['equicontinuity', 'sequence-of-function', 'real-analysis', 'uniform-convergence']"
1205304,Proving Composition of Uniformly Continuous/Convergent Function Sequences,"I'm not very good at this analysis stuff, it turns out. Introduction to Analysis went great, but this intermediate real analysis thing is kicking me in the rear. So, the problem: $f_{n}: D \rightarrow [c,d]$ converges uniformly to $F: D \rightarrow [c,d].$ The function $g$ is continuous on $[c,d].$ Prove that $g(f_{n})$ converges uniformly to $g(F)$ on $D$. Hint: Start with the continuity of $g$. I have no idea where to start with this problem. I feel like I'm missing an important fact to get started, and though there are similar problems on this site, I've not found one close enough to help :( Thanks!","['analysis', 'real-analysis']"
1205310,"UMVUE for pdf $f_{\theta}(x) = \theta e^{-\theta x}, x>0$","Let $X_1,\ldots,X_n$ be a random sample from a pdf  $f_{\theta}(x) =
\begin{cases}
\theta e^{-\theta x},  & x>0 \\
0, & \text{otherwise}
\end{cases}$, where $\theta>0$ is an unknown parameter. Then, the uniform minimum variance unbiased estimator for $\dfrac{1}{\theta}$ is (A)$\dfrac{1}{\bar{X_n}}$ (B) $\displaystyle\sum_{i=1}^{n}X_i$ (C) $\bar{X_n}$ (D) $\dfrac{1}{\displaystyle\sum_{i=1}^{n}X_i}$ MY STEPS: Taking the Expectation, $E_\theta(X)=\displaystyle\int_{0}^{\infty}xf(x)\;dx$ $$E_\theta(X)=\theta\int_0^\infty x e^{-\theta x}\;dx=\dfrac{1}{\theta}=\bar{X_n}$$ Hence, option (C) should be correct. Did I solve this correctly ? Please help me confirm my solution.","['statistics', 'statistical-inference', 'parameter-estimation']"
1205323,"Evaluating $\sum_{\gcd\left(m,n\right)=1}\frac{1}{m^2n^2}$","I was wondering how one would evaluate the sum $$\sum_{\gcd\left(m,n\right)=1}\frac{1}{m^2n^2}.$$ The first thought that came to mind to to try something like this: $$\sum_{\gcd\left(m,n\right)=1}\frac{1}{m^2n^2}=2\sum_{\substack{\gcd\left(m,n\right)=1,\\m<n}}\frac{1}{m^2n^2}=2\sum_{k=1}^{\infty}\frac{f\left(k\right)}{k^2},$$ where $f\left(k\right)$ counts the number of ways that $k=mn$ for $m<n$ relatively prime. However, I can't see how I would proceed. Is this even the right way to be thinking about this? In general, what techniques should I look into when looking at problems like this, and which books should I read to learn about these and similar techniques? Also, if this function $f$ has been studied before (and if it has a more standard notation/name), what should I search for to learn more?","['number-theory', 'riemann-zeta', 'analytic-number-theory', 'sequences-and-series', 'reference-request']"
1205333,Why is boundedness of the ball multiplier equivalent to the convergence of Fourier transform in Lp?,"Let $\mathcal{F}$ be the fourier transform operator and let $T_R$ =  $\mathcal{F}^* \chi_R\mathcal{F}$ where $\chi_R$ is the indicator function on the ball of radius $R$. Hence $T_R$ is the fourier multiplier operator with the indicator function on ball of radius R. I am interested in understanding the question for what $p$ with $1\leq p\leq \infty$ does $T_R(f) \to f$ in $L^p$ as $R\to \infty$ for all $f\in L^p(\mathbb{R}^n)$ ? I am only interested in $n\geq2$. Now first I am a little confused about how to make the question precise. Now $T_R(f) = f*\hat{\chi_R}$ and by stationary phase arguments I know that the exact asymptotics of $\hat{\chi_R}(\xi)$ is like $|\xi|^{-(n+1)/2}$ as $\xi \to \infty$ and hence $\hat{\chi_R} \in L^p(\mathbb{R}^n)$ iff $p> \frac{2n}{n+1}$. Hence the problem definitely doesn't make sense (i.e. there is trivial schwartz function for which the statement fails) for $1\leq p \leq \frac{2n}{n+1}$. By using Young's inequality, we know that $T_R(f)$ is in $L^1_{loc}$ for $ f \in L^p$ for the range $ \frac{2n}{n+1}<p < \frac{2n}{n-1}$ hence the problem is potentially meaningful/interesting in this range. But what about $p \geq \frac{2n}{n-1}$? Is there a clear counterexample or an argument which rules out this range of $p$? I am not even sure whether $T_R(f)$ is in $L^1_{loc}$ for $p$ in this range. In a lot of places I have read that the original problem is equivalent to the problem of boundedness of the operator $T_R$ from $L^p \to L^p$ (Stein mensions this in his book Harmonic Analysis page 389). I understand that if $T_R$ is bounded, then the original problem is solved for that $p$ by a simple density argument. However I do not see why we really need to have boundedness of the operators $T_R$. Grafakos in his book Modern Fourier Analysis ""proves"" that we really need boundedness of $T_R$ in the exercise 10.2.1 page 366 and the proof is via uniform boundedness principle. However I do not see how we can apply uniform boundedness principle as the principle only applies if we apriori know that the individual operators are bounded. For example consider an infinite dimensional Banach space $X$. By axiom of choice, let us chose a hamel basis and collect an countable infinite among them $x_1, x_2,..$. We define the unbounded operators $T_n:X \to X$ by defining them on the chosen basis vectors and extending linearly. Define $T_n(x_i) = i*x_i$ for $i\geq n$ and zero for $i<n$, and zero on all other basis vectors. We clearly see that $T_n$ are unbounded operators, for every $f\in X, sup\|T_n(f)\| < \infty$ and $T_n(f) \to 0$ for every $f\in X$. So to summarize I have 2 questions: 1) Whether the question $T_R(f) \to f$ in $L^p$ for all $f\in L^p$ makes sense (or does not makes sense) for $p \geq \frac{2n}{n-1}$ 2) How does $T_R(f) \to f$ in $L^p$ for all $f\in L^p$ imply the boundedness of the opertors $T_R$ I am sorry for the long post. Any help would be appreciated!","['analysis', 'fourier-analysis', 'harmonic-analysis']"
1205376,"Functions $\mathbb{N} \to \mathbb{N}$ that are injective but not surjective, and vice versa",Suppose that $A$ and $B$ are sets each containing the same finite number of elements and $f: A \to B$ . a. Prove that $f$ is injective if and only if it is surjective. b. Give an example of an injective function from $\Bbb N \to \Bbb N$ that is not surjective. Does this contradict (a)? c. Give an example of a surjective function from $\Bbb N \to \Bbb N$ that is not injective. Does this contradict (a)? My attempts b. $f(x)= \frac{x}{2}$ c. $f(x) = x -1$ I don't get if it contradict part a.,"['elementary-set-theory', 'examples-counterexamples', 'functions']"
1205385,Prove Laurent Series Expansion is Unique,"Suppose that $f$ is holomorphic on $A=\{r<|z|<R\}$, where $0\le r<R\le \infty$. Suppose that there are two series of complex numbers $(a_n)_{n\in{\mathbb Z}}$ and $(b_n)_{n\in\mathbb Z}$ such that $f(z)=\sum_{n=-\infty}^\infty a_n z^n=\sum_{n=-\infty}^\infty b_n z^n$ for $z\in A$. Show that $a_n=b_n$ for all $n\in\mathbb Z$. This means that the Laurent series expansion is unique. Hint: It suffices to show that if $f\equiv 0$, then $a_n=0$ for all $n$. Use $\sum_{n=0}^\infty a_n z^n=\sum_{n=-\infty}^{-1} -a_n z^n$ to construct a bounded entire function. Hi everyone, I've set out to prove that the Laurent series expansion of a function is unique. I found a very short and nice proof of uniqueness here , however my problem's hint goes a different direction. Is there any reason not to favor the simple proof I linked to? I'd like to figure out what to do with the hint given and what bounded entire function to construct. Once I find a bounded entire function, I have a feeling I will need to cite Liouville's Theorem to help me somehow, which says every bounded entire function on $\mathbb{C}$ is constant. Thanks for your help!","['sequences-and-series', 'laurent-series', 'complex-analysis']"
1205392,"To calculate variance, given conditional distribution","Let Y be an exponential random variable with mean $\frac{1}{\theta}$, where $\theta>0$. The conditional distribution of X given Y has Poisson distribution with mean Y. Then, the variance of X is (A)$\dfrac{1}{\theta^2}$ (B) $\dfrac{\theta+1}{\theta}$  (C) $\dfrac{\theta^2+1}{\theta^2}$ (D) $\dfrac{\theta+1}{\theta^2}$ My Attempt: $\!f(x; \lambda|Y)= \Pr(X{=}x)= \frac{\lambda^x e^{-\lambda}}{x!}$ $E(X|Y)=\displaystyle\sum xf(x; \lambda|Y)=\lambda=\frac{1}{\theta}$ Variance(X)=$E[X^2]-(E[X])^2$ Now, $E(X^2)=\displaystyle\sum x^2\frac{\lambda^x e^{-\lambda}}{x!}=(1+\lambda)=1+\frac{1}{\theta}$ Because $(1+x)e^x= \sum^\infty_{n=0}{n+1\over n!}x^n$ Hence, Var(X)=$1+\frac{1}{\theta}-\frac{1}{\theta^2}$ Where did I go wrong ? Please advise.","['conditional-expectation', 'statistics', 'statistical-inference']"
1205397,"Given $¥frac{dy}{dx}=x^2+y^2$ and initial condition $¥varphi (0)=1$, find the first 6 terms in the Taylor expansion solution $y=¥varphi (x)$","Given $¥frac{dy}{dx}=x^2+y^2$ and initial condition $¥varphi (0)=1$, use the method of reduction to an integral equation and successive approximation to find the first 6 terms in the Taylor expansion solution $y=¥varphi (x)$. We have that if $f:D ¥rightarrow ¥mathbb{R}$ is continuous, $¥varphi$ is defined and continuous on $I=¥{x|x_0-h<x<x_0+h¥}$ to $¥mathbb{R}$, and $(x_0,y_0) ¥in D$ with $¥varphi (x_0)=y_0$, then $¥varphi$ is a solution of $¥frac{d¥varphi}{dx}=f[x,¥varphi (x)]$ on $I$ only if $¥varphi (x)=y_0+¥int_{x_0}^{x} f[t,¥varphi (t)] dt$ for $x ¥in I$. This is what I mean by reduction to an integral equation. EDIT: In case it helps anyone refine their answer, the answer should be $1+x+x^2+¥frac{4}{3}x^3+¥frac{7}{6}x^4+¥frac{6}{5}x^5$. This comes out of the back of my book. Of course, my problem is that I cannot get to this answer.","['fixed-point-theorems', 'real-analysis', 'ordinary-differential-equations']"
1205401,Proof for spherical polar law of cosine,"I'm reading my textbook and for some reason, it does not present the proof for the spherical polar law of cosine which is: $$ \cos(a)=\frac{\cos(A)+\cos(B)\cos(C)}{\sin(B) \sin(C)}$$ It does present the proof for spherical law of cosine which is:
$$ \cos(A)=\frac{\cos(a)-\cos(b)\cos(c)}{\sin(b) \sin(c)}$$ where $A$ is the angle and $a,b,c$ are the sides. in which they use cross product and dot product where for example $|b\times c|=\sin a$ and $(b,c)=\cos a$. So i'm not sure but I believe that for the proof for the spherical polar law of cosine, it can use a similar method. However, like i said, i'm not sure. For example, does $|B\times C|=\sin A$ ? If anyone can help start this proof or show me, either way that would be great.","['spherical-geometry', 'geometry']"
1205411,On the importance of the Riesz–Markov–Kakutani representation theorem.,"I am following big Rudin and I have arrived at the representation theorem.
Before doing the full long proof I would like to know what results are based on this theorem that for completeness I state below: Let $X$ be a locally compact Hausdorff space. For any positive linear functional $\psi$ on $C_c(X)$, there is a unique regular Borel measure $μ$ on $X $such that: $$
    \psi(f) = \int_X f(x) \, d \mu(x) \quad 
$$ for all f in Cc(X). (Rudin proves it in a more general setting ). I apologize if I should already understand why this is important and what results are based on this but in my defence I am fairly new to measure theory.","['riesz-representation-theorem', 'self-learning', 'complex-analysis', 'measure-theory']"
1205419,Status of $\tau(n)$ before Deligne,Ramanujan's $\tau$ conjecture states that $$\tau(n)\sim O(n^{\frac{11}2+\epsilon})$$ which is a consequence of Deligne's proof of Weil conjectures. My question is what is best that could be proved possibly without etale cohomology regarding $\tau(n)$?,['number-theory']
1205425,Can we halve the real number,"Intuitive formulation:Can we halve the real numbers in a way that changes its density by half and does not alter its analytic properties. Formal statement:Is there a subset $A$ of $\mathbb{R}$ such that $A$ is dense and $$|A\cap[a,b]|=|(\mathbb{R}-A)\cap[a,b]|=|\mathbb{R}\cap[a,b]|$$ for all $a,b\in\mathbb{R}$","['real-numbers', 'elementary-set-theory']"
1205489,Flows of $f$-related vector fields,"If we have a smooth map between manifolds $f : M \rightarrow N$ and (say, complete) vector fields $X$ in $M$ and $Y$ in $N$, we say they are $f$-related when $Y(f(x)) = d_x f(X(x))$ for all $x \in M$. I've heard it then claimed that, if $X$ is $f$-related to $Y$, their flows will satisfy the relationship: $f(\phi_{X}^{t}(x)) = \phi_{Y}^{t}(f(x))$. Can anyone indicate an argument or reference for this? I was told to simply differentiate that relationship, but then it seems we get $df(X(\phi_{X}^{t}(x))) = Y(\phi_{Y}^{t}(f(x)))$; we don't know if those are equal, and even if they were I'm not sure how that implies anything.",['differential-geometry']
1205512,Convexity of Conjugate Function on Determinant,"If $f: \mathbb R^n \to \mathbb R$ then $conj(f) : \mathbb R^n\to \mathbb R$ is defined as
$conj(f)(y) = \sup_{x \in dom_f} (y^Tx - f(x))$
and it is called the conjugate function of $f$. if $f(X) = -\log(\det X)$ where $X$ is a symmetric positive definite matrix, what is the domain of $conj(f)$ and how can we show that it is convex? ($Y^TX$ is defined as $trace(YX)$).","['convex-optimization', 'functions', 'matrices']"
1205540,"If $x^2 +px +1$ is a factor of $ ax^3 +bx+c$ then relate $a,b,c$","Suppose If $x^2 +px +1$ is a factor of $ax^3 +bx+c$ then relate $a,b,c$ such that $a,b,c \in R$ I can write $$ax^3 +bx+c=(x^2 +px +1)(\lambda x +D)$$ $$\implies ax^3 +bx+c =\lambda x^3 + x^2.p\lambda + x(\lambda+pD)+D $$ and then compare coefficient to find out relation but that will be long and tedious process , I want shorter approach to this problem . Btw I was given following options for this question A) $a^2+c^2+ab=0$ B) $a^2-c^2+ab=0$ C) $a^2-c^2-ab=0$ D) $ap^2+bp+c=0$ Maybe we can relate something by looking at options?","['number-theory', 'linear-algebra', 'algebra-precalculus']"
1205543,How to solve $\int_0^{\infty} \frac{\log(x+\frac{1}{x})}{1+x^2}dx$?,Here is my question $$\int_0^{\infty} \frac{\log(x+\frac{1}{x})}{1+x^2}dx$$ I have tried it by substituting $x$ = $\frac{1}{t}$. I got the answer $0$ but the correct answer is $\pi log(2)$. Any suggestion would be appreciated.,"['calculus', 'closed-form', 'definite-integrals', 'logarithms', 'integration']"
1205611,Lipschitz constant of the convex function $f(x) - \frac{a}{2} |x|^2$,"I was going through this blog post https://blogs.princeton.edu/imabandit/2013/04/04/orf523-strong-convexity/ It has been mentioned without proof that for a function $f:\mathbb{R}^n\rightarrow\mathbb{R}$ that is Lipschitz continuous with Lipschitz constant $\beta$ and strongly convex with coefficient $\alpha$, the function $g:\mathbb{R}^n\rightarrow\mathbb{R}$ defined as
\begin{equation}g(\mathbf{x})\triangleq f(\mathbf{x}) - \frac{\alpha}{2}\|\mathbf{x}\|^2\end{equation}
is Lipschitz continuous with coefficient $\beta-\alpha$. I tried proving this as follows
\begin{align}
\nabla g(\mathbf{x}) =& \nabla f(\mathbf{x}) - \alpha \mathbf{x} \\
\|\nabla g(\mathbf{x}) - \nabla g(\mathbf{y})\|^2 = & \|\nabla f(\mathbf{x}) - \nabla f(\mathbf{y})\|^2 + \alpha^2 \|\mathbf{x} -\mathbf{y}\|^2 - 2 \alpha (\nabla f(\mathbf{x}) - \nabla f(\mathbf{y}))^T(\mathbf{x}-\mathbf{y}) \\
\leq & \beta^2 \|\mathbf{x} -\mathbf{y}\|^2 + \alpha^2 \|\mathbf{x} -\mathbf{y}\|^2 - 2 \alpha (\nabla f(\mathbf{x}) - \nabla f(\mathbf{y}))^T(\mathbf{x}-\mathbf{y})
\end{align}
where the last inequality was from the definition of Lipschitz continuity of $f$. I am stuck at the last inequality and am not sure on how to proceed. My hunch is that the last term should become $2\alpha\beta\|\mathbf{x} - \mathbf{y}\|^2$ but am not able to prove that. The problem seems fairly straightforward though. Any help would be greatly appreciated.","['convex-analysis', 'multivariable-calculus']"
1205721,Inequality $|A+B|_m\leq|A|_m+|B|_m$ on square matrices,"Consider $n\times n$ real matrices $A$ and $B$. If $|A|_m$ denotes the modulus matrix of $A=[a_{i,j}]_{n\times n}$, and is defined as $|A|_m := [|a_{i,j}|]_{n\times n}$, prove that $|A+B|_m\leq|A|_m+|B|_m$. (We mean by $N\leq M$ that matrix $(N-M) $ is a negative semi-definite matix) I have seen this inequality in a paper, where no proof is provided.","['matrix-equations', 'linear-algebra', 'matrices']"
1205733,How to convert (or transform) from one range to another? [duplicate],"This question already has answers here : Shift numbers into a different range (3 answers) Closed 3 years ago . I have score ranges min score = 40 and max score = 60 . I have same gpa ranges too 1.00 - 1.99 . Which formula I can use to calculate the gpa.  Like If I entered 45 then it should print 1.25 . Range of score and grade can be different. P.S. I am a web developer, and I am a little poor in Math. I need to apply this formula in my coding.",['multivariable-calculus']
1205740,Two times differentiable function,"We know that the two times differentiable function  $g : \mathbb{R} \rightarrow \mathbb{R}$ is such that $g(0) = 999$, $g'(0) = 1000$ and $|g''(x)| \le 10000$ for every $x \in \mathbb{R}$. Let $K := g(\frac{1}{1000})$. How to prove that $K$'s second digit after the decimal point equals to $9$ or $0$? What are its other digits?",['derivatives']
1205774,BMO1 2009/10 Q5 functional equation: $f(x)f(y) = f(x + y) + xy$,"Find all functions $f$ , defined on the real numbers and taking real values, which satisfy the equation $f(x)f(y) = f(x + y) + xy$ for all real numbers $x$ and $y$ . I worked out $f(0)=1$ , and $f(-1)f(1)=0$ , but then I hit a wall.","['contest-math', 'functional-equations', 'functions']"
1205778,Showing the set with a $\sup$ has a convergent sequence,"Let $A$ be a set in $\mathbb{R}$, non-empty and bounded above. Prove that $s = \sup A$ if and only if $s$ is an upper bound of $A$ and there exists a sequence $(s_n)$ in $A$ which converges to $s$. I am a little uncertain, given the fact there is no statement suggesting sequences in $A$ are monotone in anyway, so how can we say they are bounded? Next, I realised it says ""there exists a sequence"". So this would mean we need only show that there is at least one sequence in the set $A$ that converges? I started as: $\Longrightarrow$
Assume $ s = \sup A$ Then let $\epsilon> 0 $ be arbitrary, meaning $|s - \epsilon| < s$ is no longer an upper-bound for the set $A$ since, there exists some $s_N \in A$ such that $|s - \epsilon| < s_N \leq s$ Now here is where I run into trouble , since I can't make the statement
""For some $n \geq N, s_n \geq s_N$ such that
$s - \epsilon< s_N < s_n \leq s < s+\epsilon$""
I can't make a statement about convergence, since there is no condition that we have an increasing sequence in this set. But since the question says ""there exists a sequence which converges"", am I allowed to simply say ""take some increasing sequence in $A$ that...""? Or am I missing some sort of idea here, and my method/approach is entirely wrong?","['proof-verification', 'real-analysis']"
1205788,Explicitly construct a field with 729 elements,"I would like to construct a field with 729 elements. I know that $729 = 3^6$, and that I have to find an irreducible monic polynomial of degree 6 over $GF(3)$. I chose the polynomial $x^6 + 2x^2 + 1$, which I have verified (computationally) that it is irreducible over this field. However, I do not know how to proceed with the construction. Any hints? Suppose I hadn't found this polynomial computationally. Is there an algebraic method of finding such polynomials when the degree is quite large? Or, at least testing for irreducibility in such cases?","['abstract-algebra', 'galois-theory', 'irreducible-polynomials', 'finite-fields']"
1205808,"On an $h \times h$ square lattice, count all the paths from $(0,a)$ to $(h-1,b)$, $a,b \in [0,h-1]$, with diagonal moves allowed","Consider an $h \times h$ upright square lattice , where a point is defined by $(x,y)$, $x,y \in [0,h-1]$. A valid path starts from the left boundary, $(0,a)$, $ a \in [0,h-1]$ and ends to the right boundary $(h-1,b)$, $ b \in [0,h-1]$. Allowed moves are: Diagonal, such as $(0,0) \rightarrow (1,1)$, or To the right, such as $(0,0) \rightarrow (1,0)$. Vertical movement or any movement to the left is not valid. What is the total number of all these paths? Its possible to calculate the paths programmatically up to a certain $h$ (after $h=8$ it becomes really slow). I'm looking for a closed form expression. Here are the number of paths for $h=2,\ldots,7$ Table 1: h=2, 4 paths h=3, 17 paths h=4, 68 paths h=5, 259 paths h=6, 950 paths h=7, 3387 paths A more general problem: Now consider we can move on all the diagonal axes. For example consider an $4\times 4$ lattice. From $(0,0)$ we can go to $(1,0)$, $(1,1)$, $(1,2)$ or $(1,3)$. Lets denote these diagonal moves with $a$-diagonal . Therefore, $(0,0) \rightarrow (1,0)$ is a $0$-diagonal move, $(0,0) \rightarrow (1,1)$ is a $1$-diagonal move, $(0,0) \rightarrow (1,2)$ is a $2$-diagonal move, $(0,0) \rightarrow (1,3)$ is a $3$-diagonal move, etc. Denote the set of all paths that start from the left boundary $(0,a)$ and end to the right boundary $(h-1,b)$, $ b \in [0,h-1]$, and have at least one $a$-diagonal move but not an $(a+1)$-diagonal move with $\mathcal{B}_a$. The problem statement is: Calculate the number  of paths in each  $\mathcal{B}_0, \mathcal{B}_1,\ldots,\mathcal{B}_{h-1}$ . 
(Note that the numbers in Table 1 give $\mathcal{B}_0 + \mathcal{B}_1$). The following table shows the values for $h=2$ to $h=7$: Any hint on how to approach this would be greatly appreciated. Edit : The movitation for this problem is to calculate the number of piecewise linear functions $f:[0,1]\rightarrow [0,1]$ that have a maximum derivative of 0 (given by $\mathcal{B}_0$), 1 (given by $\mathcal{B}_1$), $\ldots$, $h-1$ (given by $\mathcal{B}_{h-1}$).","['discrete-mathematics', 'graph-theory', 'combinatorics']"
1205811,How to determine a function?,"I have two relations: $R_1:=\{(x,y)| x^2=y\} \subseteq \mathbb{N} \times \mathbb{R}$ $R_2:=\{(y,x)| x^2=y\} \subseteq \mathbb{R} \times \mathbb{N}$ $R_1$ is a total function $R_2$ is a partial function I´m trying really hard to understand but just struggle to get it. Could someone correct my understanding of it. So for $R_1$: I take a $x$ from $\mathbb{N}$, for example $4$ $\subseteq$ $\mathbb{N}$ the corresponding $y=2$. That seems to apply. Generally,$ y=x^2 \subseteq \mathbb{N}$ and thus $\mathbb{N}\subseteq \mathbb{R}$. For $R_2$ I mean I just dont see the difference, the $y$ are still coming from $\mathbb{R}$ and $x$ from $\mathbb{N}$. 
So taking a negative $y$ still results in positive $x$.
Could someone explain me that?",['functions']
1205822,Riemann integral confusion 2,"I evaluate the following limit with Riemann integral $\displaystyle u_n=\frac{1}{n}\sum_{k=1}^n \log(1+\frac{k^2-2k+2}{n^2}),\:\
$$\lim _{n\to \infty } u_n=lim _{n\to \infty\ }\frac{1}{n}\sum_{k=1}^n \log(1+\frac{k^2-2k+2}{n^2})=lim _{n\to \infty\ }\frac{1}{n}\sum _{k=1}^nf\left(\frac{k}{n}\right)$$=\int _0^1\:f\left(x\right)dx$ I know what it is about but at the final I always have problem because I don't know to get the function... and if I put a function how verify if that is correct? I'm total confused 
Please make me to understand that, I apreciate! For example, I get this function: f:[0,1]-->R, f(x)= ln(1+x), how I verify if that is correct, because if I put k/n instead x we obtain ln(1+k/n) but we have $$log(1+\frac{k^2-2k+2}{n^2})$$ we must have same value? In general how we find the function ? how we understand which is function?","['limits', 'riemann-sum']"
1205836,How could we show that $u=0$?,"In my notes there is the following example about the energy method. We want to show that the problem $$w_{tt}(x, t)-w_{xxtt}(x, t)-w_{xx}(x, t)=f(x, t), 0<x<1, t>0$$ 
$$w(x, 0)=\phi(x) \\ w_t(x, 0)=\psi(x) \\ w_x(0, t)=h(t), t>0 \\ w_x(1, t)=g(t)$$ 
has an unique solution. We suppose that $w_1, w_2$ are two distinct solutions. Then $u=w_1-w_2$ solves the problem : 
$$u_{tt}(x, t)-u_{xxtt}(x, t)-u_{xx}(x, t)=0, \, 0<x<1, \, t>0$$
$$u(x, 0)=0 \\ u_t(x, 0)=0 \\ u_x(0, t)=0 \\ u_x(1, t)=0$$ $$$$ To find the energy we do the following: $$\int_0^1(u_tu_{tt}-u_tu_{xxtt}-u_tu_{xx})dx=0 \tag 1$$ $$\int_0^1 u_tu_{tt}dx=\int_0^1\frac{1}{2}(u_t^2)_tdx=\frac{d}{dt}\int_0^1 \frac{1}{2}u_t^2dx$$ $$\int_0^1 u_t u_{xxtt}dx=-\int_0^1 u_{tx}u_{xtt}dx+[u_t u_{xtt}]_0^1=-\int_0^1\frac{1}{2}(u_{tx}^2)_tdx$$ $$\int_0^1 u_t u_{xx}dx=-\int_0^1 u_{tx}u_x dx+[u_t u_x]_0^1=-\frac{1}{2} \frac{d}{dt} \int_0^1 u_x^2dx$$ $$(1) \Rightarrow \frac{d}{dt}\int_0^1 \frac{1}{2}u_t^2dx+\frac{d}{dt}\frac{1}{2}\int_0^1 u_{tx}^2dx+\frac{d}{dt} \frac{1}{2} \int_0^1 u_x^2dx=0$$ The energy of the system is $$E(t)=\frac{1}{2}\int_0^1 (u_t^2(x, t)+u_{tx}^2(x, t)+u_{x}^2(x, t))dx$$ $$\Rightarrow E'(t)=\int_0^1 (u_t u_{tt}+u_{tx}u_{xtt}+u_xu_{xy})dx= \dots =0$$ (The energy is always positive.) $$\Rightarrow 0 \leq E(t) = E(0)=0 \Rightarrow u_t=0 \Rightarrow u(x, t)=u(x, 0)=0 \text{ Contradiction}$$ So,  the initial problem has an inuque solution. $$$$ $$$$
I wanted to apply this at the following : $$v_{tt}(x, t)-v_{xt}(x, t)=f(x, t), x \in \mathbb{R}, t>0 \\ v(x, 0)=g(x), x \in \mathbb{R} \\ v_t(x, 0)=h(x), x \in \mathbb{R}$$ and I have done the following: We suppose that $v_1, v_2$ are two distinct solutions. Then $u=v_1-v_2$ solve the problem: 
$$u_{tt}-u_{xt}=0, x \in \mathbb{R}, t>0 \\ v(x, 0)=0, x \in \mathbb{R} \\ v_t=0, x \in \mathbb{R}$$ 
In this case since $x\in \mathbb{R}$ we are looking for the characteristic curves to use them as the limits of the integral. $$u_{tt}-u_{xt}=f $$ The characteristic curves are $$x=x_0 \text{ AND } x+t=x_0+t_0$$ $$\int_{x_0}^{x_0+t_0-t}(u_tu_{tt}-u_tu_{xt})dx=0 \tag 2$$ $$\int_{x_0}^{x_0+t_0-t}u_tu_{tt}dx=\int_{x_0}^{x_0+t_0-t}\frac{\partial}{\partial{t}}\left (\frac{1}{2}u_t^2\right )dx=\frac{d}{dt}\int_{x_0}^{x_0+t_0-t}\frac{1}{2}u_t^2dx$$ \begin{align} 
\int_{x_0}^{x_0+t_0-t}u_tu_{xt}dx &= \int_{x_0}^{x_0+t_0-t}u_t\left [\frac{\partial}{\partial{x}}u_t\right ]dx=[u_t^2]_{x=x_0}^{x_0+t_0-t}-\int_{x_0}^{x_0+t_0-t}u_{xt}u_tdx \\ &\Rightarrow \int_{x_0}^{x_0+t_0-t}u_tu_{xt}dx=\frac{1}{2}\left (u_t^2(x_0+t_0-t, t)-u_t^2(x_0, t)\right )
\end{align} $$(2) \Rightarrow \frac{d}{dt}\int_{x_0}^{x_0+t_0-t}\frac{1}{2}u_t^2dx-\frac{1}{2}\left (u_t^2(x_0+t_0-t, t)-u_t^2(x_0, t)\right )=0 \Rightarrow \frac{d}{dt}\int_{x_0}^{x_0+t_0-t}\frac{1}{2}u_t^2dx=\frac{1}{2}\left (u_t^2(x_0+t_0-t, t)-u_t^2(x_0, t)\right )$$ The energy of the system is $$E(t)=\int_{x_0}^{x_0+t_0-t}\frac{1}{2}u_t^2dx$$ $$E'(t)=\frac{d}{dt}\int_{x_0}^{x_0+t_0-t}\frac{1}{2}u_t^2dx \Rightarrow E'(t)=\frac{1}{2}\left (u_t^2(x_0+t_0-t, t)-u_t^2(x_0, t)\right )$$ We have also that $E(0)=0, E'(0)=0$, right?? How could we continue to show that $u=0$ ?? We could show that if we would know that $E'(t) \leq 0$, but how could we get this inequality??","['ordinary-differential-equations', 'partial-differential-equations']"
1205840,"$f(A \cap B)\subset f(A)\cap f(B)$, and otherwise?","I got a serious doubt ahead the question Be $f:X\longrightarrow Y$ a function. If $A,B\subset X$, show that $f(A \cap  B)\subset f(A)\cap f(B)$ I did as follows $$\forall\;y\in f(A\cap B)\Longrightarrow \exists x\in A\cap B, \text{ such that } f(x)=y\\ \Longrightarrow x \in A\text{ and }x\in B\Longrightarrow f(x)\in f(A)\text{ and }f(x)\in f(B)\\ \Longrightarrow f(x)\in f(A)\cap f(B)\Longrightarrow y\in f(A)\cap f(B)$$ This ensures that $\forall y \in f(A\cap B)$ then $y\in f(A)\cap f(B)$, therefore $f(A\cap B)\subset f(A)\cap f(B)$. Okay, we have the full demonstration. We know that for equality to be valid, then $ f $ must be injective. But my question is when should I see that equality is not worth, not by counter example, but finding an error in the following demonstration $$\forall\;y\in f(A)\cap f(B)\Longrightarrow y\in f(A)\text{ and }y\in f(B) \Longrightarrow \\ \exists x\in A \text{ and } B, \text{ such that } f(x)=y\\ \Longrightarrow x \in A\cap B\ \Longrightarrow f(x)\in f(A\cap B)\Longrightarrow y\in f(A\cap B)$$ Where is the error in the statement? Which of these steps can not do and why?","['elementary-set-theory', 'functions']"
1205843,Does the totient function reach all its values when restricted to odd numbers?,"This question might be a duplicate, if so, I apologise in advance. It is simple, but answering it is probably harder :) Is it true, that the $\phi(n)$ function(Euler's totient function) takes on all of it's values, when $n$ is an odd integer? I obviously tried it for the first some $n$: $\phi(1) = 1,
\phi(3) = 2, \phi(5) = 4, $ and so on. It is obvious, that if $n$ is a prime, than $\phi(n) = n-1$, so we cover all the $p-1$ numbers, where $p$ is a prime. I just can't really prove if any number is missing on this list. The question can be asked in this way too: Is it true, that if we use the totient function with only odd integers, we get all the values from it. I hope you can understand it, if not, just comment below, and I try to answer. :) Thanks for any comments!","['number-theory', 'totient-function']"
1205883,Understanding an exercise about gradients and vector fields,"In John M. Lee's Introduction to Smooth Manifolds, exercise 11.17 goes as follows: Let $f(x,y)=x^2$ on $\mathbb R^2$, and let $X$ be the vector field $$X=\operatorname{grad} f=2x\frac\partial{\partial x}.$$ Compute the coordinate expression for $X$ in polar coordinates (on some open subset on which they are defined) and show that it is not equal to $$\frac{\partial f}{\partial r}\frac{\partial }{\partial r}+\frac{\partial f}{\partial \theta}\frac{\partial}{\partial\theta}.\tag{*}$$ I am not sure, what I am supposed to do here, but this is what I thought: Considering the change of coordinates $(x,y)=(r\cos\theta,r\sin\theta)$ we can compute the change of bases of tangent spaces:
$$
\begin{align}
\frac{\partial}{\partial r}
&=\cos\theta\frac{\partial}{\partial x}+\sin\theta\frac{\partial}{\partial y}\\
\frac{\partial}{\partial\theta}
&=-r\sin\theta\frac{\partial}{\partial x}+r\cos\theta\frac{\partial}{\partial y}
\end{align}
$$
and then since $f(r,\theta)=r^2\cos^2\theta$ we have
$$
\begin{align}
\frac{\partial f}{\partial r}&=2r\cos^2\theta\\
\frac{\partial f}{\partial\theta}&=-2r^2\cos\theta\sin\theta
\end{align}
$$
we see that the coefficient of $\dfrac{\partial}{\partial y}$ in $(*)$ becomes
$$
2r\cos^2\theta\sin\theta-2r^3\cos^2\theta\sin\theta\neq 0
$$
but to equal $X$, this coefficient should have been identical zero. I chose to use $(x,y)=(r\cos\theta,r\sin\theta)$ instead of $(r,\theta)=(\sqrt{x^2+y^2},\tan^{-1}(y/x))$ which is limited to $x>0$ and more heavy to work with. But I would like to know, if what I write here even makes sense, or if I am way off.","['vector-fields', 'differential-geometry']"
1205902,Counting total number of monic irreducible polynomials of all degrees $k$ that divide $m$.,"Why is the following relation counting monic irreducible polynomials of all degrees $d$ that divide $m$ true? \begin{equation}
\sum_{d\ |\ m}\left(\frac{1}{d} \sum_{c\ |\ d} \mu(d/c)\ p^{c}\right) = \frac{1}{m} \sum_{d\ |\ m} \phi\!\left(\frac{m}{d}\right)\ p^{d},
\end{equation} where $\mu(n)$ is the Möbius function and $\phi(n)$ is Euler's totient function. Background: one can express the degree of the polynomial $x^{p^m}-x$ over $\mathbb{F}_{p}$ ($p$ = prime) as the sum of the degrees of the monic irreducible factors of $x^{p^m}-x$ as
$$
\begin{equation}
	p^m = \sum_{d\ |\ m} d\ I_d,
\end{equation}
$$
where the sum runs over all divisors $d$ of $m$, and $I_d$ is the number of minimal polynomials of degree $d$ which are factors of $x^{p^m}-x$. By Möbius inversion on gets the number of monic irreducible polynomials of degree $m$ as,
\begin{equation}
I_m =\frac{1}{m} \sum_{d\ |\ m} \mu(d)\ p^{m/d}= \frac{1}{m} \sum_{d\ |\ m} \mu\!\left(\frac{m}{d}\right)\ p^{d}.
\end{equation} Now, if I sums up the monic irreducible polynomials of all degrees $d$ that divide $m$ one has,
\begin{equation}
\sum_{d\ |\ m} I_d =\sum_{d\ |\ m}\left(\frac{1}{d} \sum_{c\ |\ d} \mu(d/c)\ p^{c}\right) = \frac{1}{m} \sum_{d\ |\ m} \phi\!\left(\frac{m}{d}\right)\ p^{d},
\end{equation}
where $\phi(n)$ is Euler's totient function counting the number of integers less than $n$ that are relatively prime to $n$ given by,
\begin{equation}
\phi(n) = |{\{0 \leq i < n\ | \gcd(i, n) = 1\}}|.
\end{equation} I verified the above relation in Matlab. I initially thought that $\sum_{d\ |\ n} \phi(d) = n$ would be of help, but could not come up with a decent proof. Any suggestions are greatly appreciated. Thanks.","['abstract-algebra', 'irreducible-polynomials', 'combinatorics', 'finite-fields']"
1205912,$f(\alpha x) = f(x)^{\beta}$ under different constraints,"With $\alpha > 0,\, \beta \in \Bbb R^*,\, \alpha, \beta \neq 1$ and $f : \Bbb R \to \Bbb R_+^*$, let's consider the functional equation 
$$ f(\alpha x) = f(x)^{\beta} \tag{$\Xi$}$$ 
or equivalently $g(\alpha x) = \beta g(x)$ for $g = \ln f$. The case where $\alpha = \sqrt2$, $\beta = 2$ and $f \in \mathcal C^2$ has already been solved here : Solving $(f(x))^2 = f(\sqrt{2}x)$ (the answer is $\exists \lambda\mid f(x) = e^{\lambda x^2}$). What if we relax/change some of the constraints, for instance: Keeping $f$ regular (say $\mathcal C^{\infty}$) but setting $\alpha, \beta$ generic $f \in \mathcal C^0$ $f \in L^1$ (other ideas?)","['real-analysis', 'functional-equations']"
1205918,Can someone show the equivalence of the following relationship $\dfrac{\partial{v}^Tv}{\partial v}=2v^T$,"Let $v$ be an n dimensional vector Then how can one show that $$\dfrac{\partial{v}^Tv}{\partial v}=2v^T$$ Specifically, I am not quite understanding the difference between taking the derivative against a quantity $v$ versus its transposed quantity $v^T$?","['partial-derivative', 'vectors', 'calculus', 'derivatives']"
1205927,How to calculate the area covered by any spherical rectangle?,"Is there any analytic or generalized formula to calculate area covered by any rectangle having length $l$ & width $b$ each as a great circle arc on a spherical surface with a radius $R$ ? i.e. How to find the area $A$ of rectangle in terms of length $l$ , width $b$ and radius $R$ ( $A=f(l, b,R)$ )? Note: Spherical rectangle is a quadrilateral having equal opposite sides but non-parallel & all the interior angles are equal in magnitude & each one is greater than $90^\circ$ .","['area', 'spherical-geometry', 'geometry', 'triangles', 'trigonometry']"
1205928,Probability of three events occurring given correlation?,"I am facing a problem that I cannot find the answer to. I have three variables, A, B and C. There are only two possibilities for each of these, A either happens or it does not, B happens or it does not and C happens or it does not. I know that if these events are independent that the probability of them all occurring is simply $P(A)\cdot P(B)\cdot P(C)$. So if the probability of each happening is 10% then all three have a $10\%·10\%·10\% = 0.1\%$ probability of occurring. But how would this formula change if the events were not independent but were instead positively correlated. I can solve this for just two variables with the formula:
$P(A \cap B) = P(A)\cdot P(B) + \rho_{AB}\cdot \sqrt{P(A)\cdot (1-P(A))\cdot P(B)\cdot (1-P(B))} $, where $\rho_{AB}$ is the correlation coefficient between A and B. How would I change this formula to calculate the probability that A, B and C all occur? I.e. calculating $P(A \cap B \cap C)$ knowing $P(A)$, $P(B)$, $P(C)$, $\rho_{AB}$, $\rho_{AC}$, $\rho_{BC}$. Thanks in advance for the help!","['probability', 'correlation']"
1205998,Simplying linear recurrence sum with binomials,Is there a way to simplify $$\sum_{k=1}^{n} \binom{n}{k}f(k)$$ Where $f(k)$ is a large linear recurrence?,"['recurrence-relations', 'number-theory', 'binomial-coefficients', 'combinatorics']"
1206001,"How to compute the integral $\int_{-\infty}^\infty e^{-x^2/2}\,dx$?","Yes, I know that this is very similar to  $\int_{-\infty}^\infty e^{-x^2}\,dx$, which has been answered a million times, but I still don't know how to apply the technique from that integration to mine. I don't want to do this using polar coordinates, or ""erf"". I'd like to use the Gamma function (which I assume is possible..). Is this correct? : $$\int_{-\infty}^\infty e^{-x^2/2}\,dx=2\int_{0}^\infty e^{-x^2/2}\,dx$$ Let $u = x^2/2  \implies x = \sqrt{2u}$, $du = x \, dx \implies dx = (2u)^{-1/2}$ So, $$=2\int_{0}^\infty (2u)^{-1/2}e^{-u}\,dx=\sqrt{2}\int_0^\infty (u)^{-1/2}e^{-u}\,dx=\sqrt{2} \Gamma(1/2)= \sqrt{2\pi}$$","['calculus', 'gaussian-integral', 'proof-verification', 'algebra-precalculus', 'integration']"
1206004,Why is Linearity of Expectation so important?,"I understand what linearity of expectation is. In short: $E[\sum X_i] = \sum E[X_i] $ However I don't quite see its significance. That is, in what scenario does applying $E[\sum X_i]$ over $\sum E[X_i]$ (or vice versa) make a difference?","['probability-theory', 'probability']"
1206085,Pattern in Digits in Powers of 2,"Along a similar line to this question, ( pattern in decimal representation of powers of 5 ), I was playing around in a mathematics program called GAP. I was entering powers of two, when I noticed an odd pattern in the amount of digits produced, I'm sorry if this is not the right place to ask this question. My first guess is that the number pattern is to do with the ratio of digits when converting from the base two representation to the base ten representation. 2^1 = 1 digit 2^12 = 4 digits 2^123 = 37 digits 2^1234 = 372 digits 2^12345 = 3717 digits 2^123456 = 37164 digits 2^1234567 = 371642 digits 2^12345678 = 3716420 digits 2^123456789 = 37164197 digits 2^1234567890 = 371641967 digits If you could couch your answer in both technically (for other mathematicians) and layman's terms (for myself) it would be most appreciated. Thankyou.","['number-theory', 'exponentiation']"
1206094,Why/How does this sqrt term work? The inverse of a fraction in a sqrt,"Why does this term work? $$
\frac{1}{\sqrt{\frac{g}{l}}} = \sqrt{\frac{l}{g}}
$$",['algebra-precalculus']
1206149,Blow-up of $\mathbb P^2$ in 2 points is isomorphic to blowup of quadric in 1 point,"How to show that blow-up of $\mathbb P^2$  in 2 points is isomorphic to blowup of quadric in 1 point? I think it is a standard fact, but Google can not help me with it. Update : I found an answer here: J. Harris "" Algebraic Geometry: A First Course "", example 7.22 .","['blowup', 'algebraic-geometry', 'birational-geometry']"
1206159,About the construction of resolvents in Galois theory (over $\mathbb{Q}$ in $\mathbb{C}$),"I have to say that my question is quite long and I apologize for this. The  main idea is that I would like to show how to construct resolvents for any transitive
subgroup of the permutation group to some students. I present here the whole construction but I think there is a problem at the end and I would be happy if someone could help me to fix it. I am looking for a way to compute the Galois group of an irreducible monic polynomial. That is, given an integer $n$ and a transitive subgroup of $\mathfrak{S}_n$. Find a way to answer (with a little computation) for each $P\in\mathbb{Q}[X]$ do we have $Gal(P,\mathbb{Q})\subseteq $ some conjugate of the group $G$. A resolvent $R_G$ for $G$ is then a polynomial in $n+1$ variables : $$R_G\in\mathbb{Q}[A_1,...,A_n,X] $$ Such that if : $$P(Y)=Y^n+\sum_{k=1}^na_kY^{n-k} $$ We have $Gal(P,\mathbb{Q})\subseteq $ some conjugate of the group $G$ if and only if $R_G(a_1,...,a_n,X)$ has a root in $\mathbb{Q}$. I claim that we all know such an example of resolvent for $G=\mathfrak{A}_n$ : $$R_{\mathfrak{A}_n}(X)=X^2-Discr(P) $$ Now, imitating the idea for $G=\mathfrak{A}_n$ would go as follows : Given some $G$ a transitive subgroup of $\mathfrak{S}_n$, first find : $$U\in\mathbb{Z}[Y_1,...,Y_n]\text{ such that } Stab_{\mathfrak{S}_n}(U)=G  $$ Then using a system $(g_i)$ of representative for $\mathfrak{S}_n/G$ (its cardinal being $d$) : $$S_G(Y_1,...,Y_n,X):=\prod_{i=1}^d(X-[g_i.U](Y_1,...,Y_n)) $$ Finally : $$S_G(Y_1,...,Y_n,X)=X^d+\sum_{r=1}^dV_r(Y_1,...,Y_n)X^{d-r} $$ From the first expression of $S_G$ we actually see that it is fixed by every permutation of $Y_1,..,Y_n$ so that each of the $V_r$ is a symmetric polynomial in the variables $Y_1,...,Y_n$.  If we set : $$A_k=(-1)^k\sum_{1\leq l_1<...<l_k\leq n}Y_{l_1}...Y_{l_k} $$ By the Newton's theorem about symmetric polynomials we finally get that there exists $R_G$ : $$S_G(Y_1,...,Y_n,X)=R_G(A_1,...,A_n,X) $$ Now I would like to proove that such a $R_G$ is a resolvent for $G$. Take : $$P(Y)=(Y-y_1)...(Y-y_n)=Y^n+\sum_{k=1}^na_kY^{n-k}$$ Suppose that $Gal(P,\mathbb{Q})\subseteq $ some conjugate of $G$, let's say $g_kGg_k^{-1}$ then  we have that for all $\sigma\in Gal(P,\mathbb{Q})$ $g_k^{-1}\sigma g_k$ is in $Stab(U)$ (here I identify the decomposition field of $P$automorphism with the permutation induced on the roots of my polynomial $P$) then we have : $$\sigma([g_k.U](y_1,...,y_n))=g_k(g_k^{-1}\sigma g_k).U(y_1,...,y_n)=g_k.U(y_1,...,y_n) $$ So we see that the complex number $[g_k.U](y_1,...,y_n)$ is fixed by any automorphism of the decomposition field so it must be rational. This gives the first part. Now, here comes my problem when you reverse the process you want to  do the following implication (recalling that an automorphism of the decomposition field is at the same time a permutation of the roots and the correspondence is faithfull) because a root of $R_G(a_1,...,a_n,X)$ is supposed to be rational we get for some $k$ : $$[g_k.U](y_1,...,y_n)\in \mathbb{Q} $$ We see that this means, in particular that $\sigma\in Stab([g_k.U](y_1,...,y_n))$ and I would like to deduce from that $\sigma\in Stab(g_k.U(Y_1,...,Y_n))$. I cannot figure if this works or not in my setting (that is the $(y_1,...,y_n)$ must be the roots of an irreducible polynomial).","['field-theory', 'galois-theory', 'polynomials', 'group-theory', 'finite-groups']"
1206172,"if we change the norm, is it possible to make it complete ?","There are many examples about $C^1[0,1]$ that is not complete under supremum norm. if we change the norm, is it possible to make it complete ? Are there any examples about this ? 
Thank you for your help .","['functional-analysis', 'real-analysis', 'general-topology']"
1206181,Evaluation of Painful Integral:,"I'm trying to find a way to unit test a numerical evaluation of:
\begin{align}
I(y) := \int_{0}^{y} \frac{\sin(x)}{x} \frac{1}{\sqrt{1+ax}} \, \mathrm{d}x, \qquad a \in \mathbb{R}
\end{align}
Is there a nice representation of this function in terms of special functions? (Hopefully special functions that can be evaluated in Boost.Math, though any other representation not using numerical quadrature would be convenient.) I should add that the limit $y\to \infty$, though aesthetically pleasing, is not the goal.",['integration']
1206234,Are all convergent sequences bounded and monotone?,"I know of the monotone convergence theorem, but does this mean that sequences converge only if they are bounded and monotone?","['sequences-and-series', 'real-analysis']"
1206280,"A set $A \subset l_1$ is compact if and only if closed, bounded, and one other condition","A set $A \subset \ell_1$ is compact if and only if $A$ is closed and bounded and given any $\epsilon >0$, there exists $n_0$ such that $\sum_{k=n}^{\infty} |x_k| < \epsilon$ for all $n> n_0$ and $x \in A$. It's easy to prove the part assuming that $A \subset l_1$ is compact, but I am finding difficulty to prove the other part.","['metric-spaces', 'general-topology', 'compactness']"
1206284,Solve $(y')^2=(y/c)^2-1$,"Can someone help me solve $(y')^2=(y/c)^2-1$?  WolframAlpha is giving me $\frac 12(c^2 e^{(x/c)-k}+e^{k-(x/c)})$.  One book I have is giving me $y=c\cdot \cosh(\frac {x+b}c)$ -- but that one won't work for the HW problem I'm solving because with the conditions $y(0)=y(D)=0$ it gives $y$ as identically $0$ -- so it must not be the most general form (though it does clearly solve this).  I'm also seeing elsewhere that the answer should be $y_0 + A\cosh(k(x-x_0))$, which would work for these boundary conditions, but I'm having trouble verifying that it actually solves this ODE. I'm just not at all good at solving nonlinear ODEs.","['solution-verification', 'ordinary-differential-equations']"
1206292,$S^2=SO(3)/SO(2)$. Does this mean that $S^2 = SU(2)/U(1) $?,"$S^2=SO(3)/SO(2)$. Does this mean that $S^2 = SU(2)/U(1) $ since $SO(3) \approx SU(2)$ and $SO(2) \approx U(1)$? Is there some more generic rule on how to relate 
$S^{n-1} = SO(n)/SO(n-1)$ to the corresponding (special) unitary groups? Also, is there a way to write $S^{n-1}$ as a quotient or so of $Sp(n)$ and $Spin(n)$ (e.g. in specific dimensions)?","['lie-groups', 'differential-geometry', 'algebraic-topology']"
1206303,Prove that f'=f iff f is an exponential funtion,"Written more formally, prove that $f' = f \iff \exists c \in \mathbb{R} : f = c * \exp$ In other words, I guess, it's enough to prove that $\exp$ and $f(x) = 0$ are the only functions that are equal to its derivatives. How can I do that? I'll be grateful for a hint instead of a full proof. Thanks!","['calculus', 'proof-writing', 'derivatives']"
1206357,What is the norm of the pre-multiplication by a fixed matrix operator?,"Let $A \colon= \left(\alpha_{ij} \right)_{m\times n}$ be a given $m \times n$ matrix of complex numbers, and let the operator $T \colon \mathbb{C}^n \to \mathbb{C}^m$ be defined by 
$$T(x) \colon= Ax \ \ \ \mbox{ for all } \  x \in \mathbb{C}^n,$$
where $\mathbb{C}$ denotes the set of all complex numbers, all vectors are to be understood as column vectors, and $Ax$ denotes the usual matrix product. Then $T$ is of course a linear operator. Let $r$ and $k$ be given real numbers such that $1 \leq r < +\infty$ and $1 \leq k < +\infty$. Then what is the norm of $T$ (i) if the norm on $\mathbb{C}^n$ is given by 
$$\Vert x \Vert_k \colon= \left( \vert \xi_1\vert^k+ \cdots + \vert \xi_n \vert^k \right)^{\frac{1}{k}} \ \ \ \mbox{ for all }  \ x \colon= (\xi_1, \ldots, \xi_n) \in \mathbb{C}^n$$ 
and the norm on $\mathbb{C}^m$ is given by 
$$\Vert y \Vert_r \colon= \left( \vert \eta_1 \vert^r + \cdots + \vert \eta_m \vert^r \right)^{\frac{1}{r}} \ \ \ \mbox{ for all } \ y \colon= (\eta_1, \ldots, \eta_m) \in \mathbb{C}^m?$$ (ii) if $\mathbb{C}^n$ is given the same norm as in (i) above  but $\mathbb{C}^m$ is given the maximum norm 
$$\Vert y \Vert_{\infty} \colon= \max \left( \vert \eta_1 \vert, \ldots, \vert \eta_m \vert \right) \ \ \ \mbox{ for all } \ y \colon = (\eta_1, \ldots, \eta_m ) \in \mathbb{C}^m?$$ (iii) if $\mathbb{C}^n$ is given the maximum norm 
$$\Vert x \Vert_{\infty} \colon= \max \left( \vert \xi_1 \vert, \ldots, \vert \xi_n \vert \right) \ \ \ \mbox{ for all } \ x \colon= (\xi_1, \ldots, \xi_n ) \in \mathbb{C}^n,$$
but $\mathbb{C}^m$ is given the same norm as in (i) above? (iv) if both $\mathbb{C}^n$ and $\mathbb{C}^m$ are given their respective  maximum norms, as in (ii) and (iii) above? Definition: Let $X$ and $Y$ be normed spaces both real or both complex, and let $T \colon X \to Y$ be a linear operator. Then $T$ is said to be bounded if there is a non-negative real number $c$ such that 
$$\Vert T(x) \Vert_{Y} \leq c \ \Vert x \Vert_{X}  \ \ \ \mbox{ for all } x \in X,$$
and then the norm $\Vert T \Vert$ of $T$ is given by  the formula 
$$\Vert T \Vert \colon= \sup \left\{ \ \frac{\Vert T(x) \Vert_Y}{\Vert x \Vert_X} \ \colon \ x \in X,  \ x \neq \theta_X \ \right\},$$
where $\theta_X$ denotes the zero vector in $X$. Or, equivalently, 
$$\Vert T \Vert = \sup \left\{ \ \Vert T(x) \Vert_Y \ \colon \ x \in X, \ \Vert x \Vert_X = 1 \ \right\}.$$ It can be shown that if $X$ is finite-dimensional, then $T$ is bounded.","['analysis', 'real-analysis', 'functional-analysis', 'normed-spaces']"
1206376,Number theory: $a\in A\iff \frac{1}{2}-a\in A$.,"Let $A$ be the set of all $a\in \mathbb{Q}$ for which there exist $x,y,z\in \mathbb{Z}$ not all $=0$ such that $$a=\frac{xy+yz+zx}{x^2+y^2+z^2}.$$ Prove that $$a\in A\iff \frac{1}{2}-a\in A.$$ Note: This is a special case of a more general result I discovered while investigating Diophantines of the form $a(x^2+y^2+z^2)=b(xy+yz+zx)$ and already have a solution using methods I invented for that purpose, but this is indirect/unmotivated. I am looking for a more direct solution. It might help to know the ""more general result:"" Proposition. If $b\in A$ then $a\in A\iff \frac{b-a}{1+a-2ab}\in A.$ However, none of these look as nice as the case where $b=\frac{1}{2}=\frac{1\cdot 1+1\cdot 4+4\cdot 1}{1^2+1^2+4^2}$, which gives rise to the above problem: $a\in A\iff \frac{\frac{1}{2}-a}{1+a-a}=\frac{1}{2}-a\in A.$","['number-theory', 'elementary-number-theory']"
1206401,The limit of sums of the form $ \frac{1}{\sqrt{2n}}- \frac{1}{\sqrt{2n+1}}+\frac{1}{\sqrt{2n+2}}-\dotsb-\frac{1}{\sqrt{4n}}$,"I need to calculate limit: $$
\lim\limits_{n \to \infty} \left ( \frac{1}{\sqrt{2n}}- \frac{1}{\sqrt{2n+1}}+\frac{1}{\sqrt{2n+2}}-\dotsb+\frac{1}{\sqrt{4n}}\right )
$$ Any hints how to do that would be appreciated.","['sequences-and-series', 'calculus', 'limits']"
1206402,Can someone clarify something in Fubini's theorem please?,"In my notes I have a version of Fubini's theorem which differs from the other forms of it I've seen which seem to all be like the one found on wiki here . Here is the version I have in my notes; Let $(X,\mathcal{A},\mu),\;(Y,\mathcal{B},\nu)$ be complete $\sigma$-finite measure spaces and $f$ a function on $X \times Y$ whose integral with respect to $\mu \widehat{\otimes} \nu$ exists (completion of the product measure $\mu \otimes \nu$). Then; $\displaystyle\int_{X\times Y} f(x,y)\; d(\mu \widehat{\otimes} \nu)(x,y) = \displaystyle\int_X \bigg(\displaystyle\int_Y f(x,y)\;d\nu(y)\bigg)d\mu(x)= \displaystyle\int_Y \bigg(\displaystyle\int_X f(x,y)\;d\mu(x)\bigg)d\nu(y)$ The subtle difference here is our function is no longer required to be integrable, all that is needed is for the integral to exist. Can someone explain why switching to the completion of the product measure removes the requirement for our function to be integrable? Note integral exists means it is well defined but possibly infinite. Integrable means the integral is finite. As you can see on the wiki page (counterexamples at the bottom) under their conditions if the integral is infinite the theorem does not hold. But here we seem to have removed that issue. Thanks.","['real-analysis', 'measure-theory']"
1206460,proving that the set of all english words is countble. [duplicate],"This question already has answers here : Is the set of all finite sequences of letters of Latin alphabet countable/uncountable? How to prove either? (2 answers) Closed 9 years ago . This is the question :
Prove that the set of all the words in the English language is countble (the set's cardinality is אo)
A word is defined as a finite sequence of letters in the English language. I'm not really sure how to start this. I know that a finite union of countble sets is countble and i think this is the way to start. Thanks in advance !","['infinity', 'elementary-set-theory']"
1206464,Need help interpreting weird result for seemingly simple problem.,"I am solving a problem and just can't wrap my had around the result I'm getting...
Here it is: So my next step would be setting derivative equal to zero and solving for Theta...
Are my calculations wrong?...
I would appreciate any constructive advice.",['statistics']
1206528,Find Matrix $A^{50}$?,Find the matrix $A^{50}$ given $$A = \begin{bmatrix} 2 & -1 \\ 0 & 1 \end{bmatrix}$$ as well as for $$A=\begin{bmatrix} 2 & 0 \\ 2 & 1\end{bmatrix}$$ I was practicing some questions for my exam and I found questions of this form in a previous year's paper. I don't know how to do such questions. Please assist over this question. Thank You,"['education', 'matrices']"
1206532,Math Puzzle: Largest number which cannot be written as the sum of distinct fourth powers,"I've come across this question which I can't seem to solve. Write the largest number that cannot be written as the sum of distinct fourth powers. First I'm stuck with the interpretation: I was thinking it meant base-4, but you can certainly find a base-4 representative of any base-10 number, right? Any help appreciated.","['number-theory', 'puzzle']"
1206591,Almost everywhere differentiable definition,"I dont understand what is the almost everwhere differentiable, can you give an example and definition please?","['calculus', 'real-analysis']"
1206617,"Weakly convergence in $W^{1,p}_0$ and strong convergence in $L^p$","I have a bounded sequence $(u_n)$ from $W^{1,p}_0(\Omega)$ that converges weakly to $u\in W^{1,p}_0(\Omega)$ and converges strongly to $u$ in $L^p(\Omega)$. We define a function $f:\Omega\times \mathbb{R}\rightarrow \mathbb{R}$ a bounded Carathéodory function such that $\lim_{s\rightarrow+\infty} f(x,s)=f^{+\infty}(x)$ My question is why $$\lim_{n\rightarrow +\infty} \int_{\Omega}f(x,u_n)(u_n-u) dx=0$$ and $$\lim_{n\rightarrow +\infty}\int_{\Omega} |u_n|^{p-2} u_n(u_n-u) dx=0$$ for the first integral, I'm trying to apply Lebesgue dominated convergence, but I have no idea. For the second integral, when $p=2$ I have no problems, because in this case we have not $|u_n|^{p-2}$ it is equal to 1 and then I just have to do $u_n(u_n-u)=(u_n-u+u)(u_n-u)$ and I use the Cauchy-Schwarz inequality, but when $p$ is not equal to 2, I have no idea. Thank you","['lebesgue-integral', 'analysis', 'weak-convergence', 'functional-analysis']"
1206628,Mathematics of password cracking,"Background : This is for a $6^{th}$ grade science project. I am doing a project on password cracking and I have created a program to predict how long your password would take to crack and then try to crack it. I have come up with an equation for how to predict how long it would take to crack your password but it always predicts way longer than it actually is. (Passwords can only be lowercase letters and digits, so therefore Total Possible Combination is $36$ ). Password length for example will be $8$ , and calculations per second will be $\boxed{cps=4\times10^9}$ ( $4$ billion calculation per second)
My algorithm is $\boxed{comb =36^8}\\\boxed{seconds=comb\div cps}$ What is wrong with my math here? EDIT: I have realized that for where you enter calculations per second I was just using the default, which I had put in a variable to be "" $4,000,000,000$ "" which isn't supported in the language I was using (You have to put "" $4000000000$ "" without the commas)","['computer-science', 'combinatorics']"
1206631,Proving the series of partial sums of $\sin (in)$ is bounded?,"So I'm trying to prove some series converges, and I'm trying to show it by using the Drichlet test. So I need to prove that the series of partial sums $\Sigma_{k=1}^\infty \sin(ki)$ is bounded. I tried proving it by dividing and multiplying with $2\cos(\frac{i}{2})$ and then using the trigonometric identity $2\cos(\beta)\sin(\alpha)=sin(\alpha+\beta)-sin(\alpha-\beta)$, which creates a telescopic series - but I didn't manage to bound the result. Any assistance would be great! Thanks in advance!","['calculus', 'complex-analysis']"
1206633,What function can produce a perfect saddleback plot and fulfil the following requirement?,"I need to find a function that produce a good saddleback plot. The function has the following requirements: Having 2 arguments: x and y Both x and y are natural numbers The result of the function is natural number The function is increasing in each argument In order to plot a saddleback (in 3D), I tried $ x^2 - y^2 $, which gives such plot : It looks like a saddleback, but it doesn't fit to the requirements . I then tried $ 3x+27y+y^2 $, it gives plot like this: It is not that saddleback , right? So can anyone supply me a good one on this?","['3d', 'functions']"
1206670,"Set A = {1,2,3,4,5} Pick randomly one digit and remove it. What is the prob. that we pick an odd digit the 2nd time.","The probability that we pick any number for the first time is $\dfrac{1}{5}$ the sample space of sample spaces after the first event is then {2,3,4,5} {1,3,4,5} {1,2,4,5} {1,2,3,5} {1,2,3,4} prob. to pick an odd from the 1st sample space is $\dfrac{1}{2}$ prob. to pick an odd from the 2nd sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 3rd sample  space is $\dfrac{1}{2}$ prob. to pick an odd from the 4th sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 5th sample  space is $\dfrac{1}{2}$ The final result is: $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ = $\dfrac{3}{5}$ Is this reasoning correct? Are there any simpler ways to solve this problem?",['probability']
1206694,"On a canonical morphism from $\operatorname{Spec} \mathcal{O}_{X,p} \rightarrow X$","Let $X$ be a scheme. I am doing an exercise: Let $p \in X$ .
Describe a canonical (choice-free) morphism from \operatorname{Spec} \mathcal{O} \rightarrow X$, with
hint that says to make sure that the morphism is independent of choice. This is what I thought:
Given any $y \in \Gamma (X, \mathcal{O}_X)$ , we have image of $y$ in $\mathcal{O}_{X,p}$ , $y_p = [(y, X)]_p$ , and this defines a ring homomorphism from $\Gamma (X, \mathcal{O}_X)$ to $\mathcal{O}_{X,p}$ . By the correspondence, this gives a morphism of schemes $\operatorname{Spec} \mathcal{O}_{X,p} \rightarrow X$ . I thought this was right, but I haven't done anything to make sure it is independent of choice. I just don't see what I am missing... I would appreciate any assistance! PS I denoted $[(f, U)]_p \in \mathcal{O}_{X,p}$ to denote the element of stalk at $p$ , given by $f \in \Gamma(U, \mathcal{O}_X)$ .","['algebraic-geometry', 'schemes']"
1206722,A textbook for a rigorous introduction to Stochastic Analysis with emphasis on stochastic differential equations,"I'm looking for a good textbook for an introduction to Stochastic Analysis,  preferably one that focuses on rigour. I am familiar with measure theory and basic probability theory. The direction I am mostly interested in is stochastic differential equations.","['probability-theory', 'soft-question', 'stochastic-processes', 'reference-request', 'stochastic-analysis']"
1206723,Intuitive explanation of Four Lemma,"In the Short Five Lemma where the rows are exact, it is a fact that 
$$\alpha \text{ and }\gamma \text{ injective (surjective) }\implies \beta \text{ injective (surjective)}.$$
I've heard this fact summarized as ""if $\beta\left.\right|_A$ is injective (surjective) and $\tilde{\beta}:B/A \to B'/\beta(A)$ is injective (surjective), then $\beta$ is injective (surjective)"". This explanation makes a good deal of sense to me, and I'm looking for a similar explanation for the four lemma , and also for questions like this: In these cases, we could talk about $B$ containing $A / \ker \psi$, and induced maps on this. Is this the way to go? Would it be advantageous to consider this from a categorical perspective? I'm trying to have exercises like the above be not a collection of random facts, but a picture of what's really going on, and explanations like the one above are very helpful.","['homological-algebra', 'abstract-algebra', 'modules', 'category-theory']"
1206772,Lie derivative and simultaneous diagonalizability,"I just arrived at this theorem: Let $M$ be an $n$-manifold and let  $\{X_j\}_{j\le k}$ be a collecion of $k$ vector fields 
  and $p \in V \subset M$ satisfying: 1) $\{X_j(p)\}_{j\le k}$ is linearly independent 2) $[X_j,X_i]_a = 0$ for all $a$ in $V$. $\implies$ There exists a chart $(x,U)$ with $U \subset V$ that satisfies
  $X_i=\frac{\partial}{\partial x^i}$ for all $i \le k$ The analogy with simultaneously diagonalizable operators (iff commuting) seems very strong.
Is there a deep algebraic result behind this?","['abstract-algebra', 'differential-geometry', 'linear-algebra']"
1206794,"Prove that $ f:(a,b)\to\mathbb{R}$ is integrable iff $\lim_{\epsilon\to0} \int_{[a+\epsilon,b-\epsilon]}f$ exists","I want to solve the following: Let $ f:(a,b)\to\mathbb{R}$ continous such that $f(x)\ge 0 $ for all $x\in(a,b)$ . Show that $f$ is integrable iff $\displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f$ exists. My attempt: $\Leftarrow]$ I want invoke the following proposition: If $A$ is open and bounded, and $f:A\to\mathbb{R}$ is bounded and its set of discontinuities is measure zero, then $f$ is integrable. And we have that $(a,b)$ is bounded by the one dimensional rectangle $[a,b]$ and since $f$ is continous we have that it is bounded in $(a,b)$ , but the thing is that this argument does not need the limit. Can you help me fix this please? If $f$ is integrable then we have that: $$\sum_{\phi \in F} \phi f \to \int_{(a,b)} f = \displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f$$ But I think this is a little bit trivial and I think I am wrong. Can you help me verify this, and if it is wrong, can you help me fix the mistakes please? Thanks a lot in advance :)","['real-analysis', 'improper-integrals', 'integration']"
1206812,Conditional Expectations Given Sum of I.I.D.,"Given that $X_1,...Xn$ are all identical independent random variables. $\mathbb{E}(X_1|\sum_{k=1}^{n}X_k)$ = ? I am unsure how to proceed on this one. I know the default relation: $\mathbb{E}(X|Y)$ = $\mathbb{E}(X*I_{[Y=y]})\over\mathbb{P}(Y=y))$, where I is an indicator function. Intuitively, I believe the answer should be the sum of the random variables divided by how many random variables or the average of the sum.","['probability', 'statistics']"
