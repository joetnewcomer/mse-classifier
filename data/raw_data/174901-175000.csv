question_id,title,body,tags
3126304,How is the log-likelihood for a multinomial logistic regression calculated?,"In a multinomial logistic regression, the predicted probability $\pi$ of each outcome $j$ (in a total of $J$ possible outcomes) is given by: $
\pi_j = \frac{e^{A_j}}{1+\sum_{g \neq j}^Je^{A_j}}
$ where the value $A_j$ is predicted by a series of predictor variables. For instance, here it is predicted by two covariates ( $x_1$ and $x_2$ ), with their associated regression slopes $\beta_1$ and $\beta_2$ , and the interaction between the two covariates (with associated regression slope $\beta_{12}$ ): $
A_j = e^{(\alpha_j+\beta_{1,j}x_1+\beta_{2,j}x_2+\beta_{12,j}x_1x_2)}
$ The model needs to be fitted to real data, and we will want to know how well it fits. For instance, perhaps out of a draw of 10 balls from a sack, 5 were red, 2 were green, and 3 were yellow. We are interested in whether the variables $x_1$ and $x_2$ associated with the sack allow us to predict this result if we plug in the values for $\beta_1$ , $\beta_2$ , and $\beta_{12}$ from the fitted model. To obtain a measure of the goodness-of-fit of the model, we need to calculate the log-likelihood formula for a multinomial logistic regression. I am unsure how to go about this. What is the formula for log-likelihood in a multinomial logistic regression of the kind described above?","['regression', 'statistics', 'log-likelihood', 'logistic-regression']"
3126328,Question about the sum of xi minus x bar square?,"Im looking through my notes in class and see that it is written that $$S = \sqrt{\frac{1}{n-1}\sum(X_i - \bar{X})^2} $$ which is then equal to $$S = \sqrt{\frac{1}{n-1}\left(\sum X_i ^2 - n*\bar{X}^2\right)} $$ how is this possible? 
I tried expanding but don't see how it works","['calculus', 'statistics']"
3126341,"Evaluate the integral $\int_{0}^{\frac{\pi}{3}}\sin(x)\ln(\cos(x))\,dx$","$$\int_0^{\frac{\pi}{3}}\sin(x)\ln(\cos(x))\,dx $$ $$
\begin{align}
u &= \ln(\cos(x)) & dv &= \sin(x)\,dx \\
du &= \frac{-\sin(x)}{\cos(x)}\,dx & v &= -\cos(x)
\end{align}
$$ $$
\begin{align}
\int_0^{\frac{\pi}{3}}\sin(x)\ln(\cos(x))\,dx &= 
-\cos(x)\ln(\cos(x)) - \int  \frac{-\cos(x)-\sin(x)}{\cos(x)}\,dx \\\\
&= -\cos(x)\ln(\cos(x)) - \int \sin(x)\,dx \\\\
&= -\cos(x)\ln(\cos(x)) + \cos(x) \\\\
F(g) &= -\cos(\pi/3)\ln(\cos(\pi/3)) + \cos(\pi/3) + \cos(0)\ln(\cos(0)) - \cos(0) \\\\
&= -\frac{1}{2}\ln\left(\frac{1}{2}\right) - \frac{1}{2} \\\\
\end{align}
$$ However, my textbook says that the answer is actually $$\frac{1}{2}\ln(2) - \frac{1}{2}$$ Where does the $\ln(2)$ come from in the answer?",['integration']
3126373,Is this multiplication operator bounded for this special norm?,"Consider $L_2[0,1]$ with the usual inner product $\langle f, g \rangle = \int_{0}^1 f(t)g(t) \, dt$ and define a new norm $$ \| f \|^2_{\star} = \sum_{i=1}^\infty \langle f, \phi_i\rangle^2 \lambda_i $$ where $\phi_1, \phi_2, \ldots$ are an orthonormal basis for $L_2[0,1]$ and $\lambda_n$ is a sequence of non increasing postitive numbers such that $\sum_{i=1}^\infty \lambda_i < \infty$ . For some $0<c<1$ the indicator function $I_{[0,c]}(t)$ and define the operator $T : L_2 \to L_2$ such that $T(f) = f I_{[0,c]}$ Is T a bounded operator under $\| \|_{\star}$ ?  (Does there exists $M >0$ such that $ \| T(f) \|_{\star} \leq M \|f\|_{\star}$ . I have tried bounding $\langle f I_{[0,c]} , \phi_i \rangle^2 = (\int_{0}^c f(t) \phi_i(t) \, dt )^2$ for each $i$ but failed.","['hilbert-spaces', 'functional-analysis', 'linear-transformations']"
3126396,$x^{1682}+22x≡1652 (\bmod3599)$.,"Hello I'm trying to learn the Chinese Remainder Theorem and now I have the problem from an old exam: $x^{1682}+22x≡1652 (\bmod3599)$ . Ok, so what makes this problem difficult for me is the combination of $x^{1682}$ and $22x$ . My start to a solution is: The primefactorization of $3599=59\cdot 61$ , and according to the CRT have $f: Z_{3599} \to (Z_{59}\times Z_{61})$ but after this it basically stops. I know how to handle the terms individually but not combined. Can someone please help me.","['chinese-remainder-theorem', 'modular-arithmetic', 'discrete-mathematics']"
3126424,"Prove $|y''(x)| \leq 40$ for all $x \in [1,3]$.","$$y' = 2 - \sin(xy), \qquad\quad 1 \leq x \leq 3, \qquad\quad y(1) = -\frac{1}{2}$$ Attempt:= $$|y''(x)| = |-\cos(xy)(y + xy')| \leq |y + xy'|$$ Not sure what to do next.","['initial-value-problems', 'ordinary-differential-equations', 'upper-lower-bounds']"
3126444,Find all natural numbers $n \geq 3 $ such that if matrix $A$ has certain properties (e.g. $A^n = I$) then $A = CBC^{-1}$,"Find all natural numbers $n \geq 3 $ such that: if: $A$ is a $2 \times 2$ matrix with real coefficients $\land \space A^n = I \land \space A^j \neq I$ for $ 0 <j <n$ , then: there are such invertible matrices $B$ and $C$ that $A = CBC^{-1}$ and \begin{equation}
  B =
      \begin{bmatrix}\cos\space t & \sin \space t \\-\sin \space t & \cos \space t \end{bmatrix}
\end{equation} for certain $t \in \Bbb R $ I'm not really sure how to approach such problem. I guess one is supposed to use the properties of the determinant and the fact that $detB = $ cos $^2(t)+$ sin $^2(t)=1 $","['matrices', 'determinant', 'linear-algebra']"
3126452,Axiom of Countable Choice - Consequences,"There are some strange consequences if one rejects the axiom of choice [e.g. $\mathbb{R}$ can be a countable union of countable sets, not every commutative ring with unit has a maximal ideal, not every vector space has a (Hamel) basis,...]. Also, there are some strange consequences if you assume the axiom of choice (like the Banach-Tarski paradox). I was wondering: What consequences might occur if one assumes the axiom of countable choice? It is obvious, that $\mathbb{R}$ is not a countable union of countable sets since this must be countable then. But are there any other similar results as in the case of the axiom of choice (or maybe the same results but with stricter assumptions)? EDIT: Let me ask more particularly: Can you prove the existence of a Schauder basis for every separable Hilbert space just using ACC?","['elementary-set-theory', 'axiom-of-choice']"
3126490,Topology on the real numbers such that all polynomials are continuous but cosine is not continuous,"So the question asks to find a topology on $\mathbb{R}$ so that all the polynomials are continuous functions from $\mathbb{R}$ to $\mathbb{R}$ but $\cos(x)$ is not continuous as a function from $\mathbb{R}$ to $\mathbb{R}$ . I looked at another similar question in stack exchange: A Topology such that the continuous functions are exactly the polynomials I think this is a special case of my question since it requires all other functions to not be continuous. Other than that I thought maybe the solution could be based on how cosine is a periodic function unlike the polynomials, so maybe I should take out some infinite sets from the topology but that still wouldn't be enough since the topology would be closed under unions. So I am not even sure if there exists such topology.","['continuity', 'general-topology']"
3126558,"Find the smallest value of $f(x) := \left({1\over9}+{32\over \sin(x)}\right)\left({1\over32}+{9\over \cos(x)}\right)$ on the interval $(0,\pi/2)$","There's a function defined as: $$f(x) := \left({1\over9}+{32\over \sin(x)}\right)\left({1\over32}+{9\over \cos(x)}\right)$$ In interval $$\left(0,\frac{\pi}{2}\right)$$ Find the smallest value (Save only its integer value) I've managed to come to this $${1\over288}+{{2(\sin(x)+\cos(x))+576}\over(\sin(x)+\cos(x))^2-1}$$ How can I find the smallest value now?","['inequality', 'cauchy-schwarz-inequality', 'trigonometric-integrals', 'optimization', 'trigonometry']"
3126568,"Prove that $2018^{2019}> 2019^{2018}$ without induction, without Newton's binomial formula and without Calculus.","Prove that $2018^{2019}> 2019^{2018}$ without induction, without Newton's binomial formula and without Calculus. This inequality is equivalent to $$
2018^{1/2018}>2019^{1/2019}
$$ One of my 'High school' student asked why the inequality is true. The whole class became interested in the problem.The demonstration that such inequality is true, using calculus, can be found here . But my students are not familiar with calculus. I can also show by induction and Newton's binomial formula that $ n^{(n + 1)}> (n + 1)^n $ , to $ n> 3$ , but my students are not familiar with mathematical induction. 
Another limitation of my students is that they have not yet learned the  Newton's binomial formula. How to prove the inequality $2018^{2019}> 2019^{2018}$ without induction, without Newton's binomial formula and without calculus? That is how to prove this inequality for High school students without using Newton's binomial formula?","['alternative-proof', 'number-theory', 'inequality']"
3126571,"Proof verification : If $S$ and $T$ are subsets of $B$ with $S \subset T$, prove $f^{-1}(S)\subset f^{-1}(T)$","EDT. Clarification: $f:A\rightarrow B$ EDT. Changed the first line in the proof according to responses / comments. Proof . Let $a \in f^{-1}(S)$ . Then, $f(a)\in S$ . Because $S\subset T$ , if $f(a)\in S$ then also $f(a)\in T$ and therefore $a \in f^{-1}(T)$ . For all $a \in f^{-1}(S)$ we then have $a \in f^{-1}(T)$ and therefore $f^{-1}(S)\subset f^{-1}(T)$ QED","['elementary-set-theory', 'proof-explanation', 'functions', 'proof-verification']"
3126576,Complex structures on $TM$ and $T^*M$,"There we go. I'm asking this question to know the different complex structures can be defined on $TM$ and $T^*M$ (I don't mind because my manifold will be Kähler). I know there are related questions, for example those ones in MO (the former cites the latter ) and also others in M.SE, although I can't find them. However, none of them clarify my doubts. Suppose $M$ is a manifold. It is well known that $T^*M$ is a symplectic manifold in a natural way. It seems that doesn't happen if we are interested in complex structures, i.e., $T^*M$ isn't a (an almost) complex manifold in a natural way. Now, suppose that $M$ is a Riemannian manifold. Róbert Szöke, in his paper Complex structures on tangent bundles of Riemannian manifolds (you should be able to find the paper here ) says that there are a natural complex structure on $TM$ . Namely, that the metric gives rise to a direct sum decomposition of the bundle $T(TM)$ into the vertical and the horizontal subbsendles, so for any $p\in TM$ we have the isomorphism $T_p(TM)\cong T_{\pi(p)}M\oplus T_{\pi(p)}M$ . Question 1. Im' not sure the metric give you that split. I guess that the split is actually given by the Levi-Civita connection associated with the Riemannian metric of $M$ . Am I right? Furthermore,  imagine that $M$ is also complex (in my case it will be Kähler). If $J$ is the complex structure on $M$ , I have checked that $TJ$ (the differential map of $J$ ) is an almost complex structure on $TM$ . I don't know if it will be integrable, it should be though (call it poetic justice). Question 2. I can't find the question here in M.SE, but there, there was a comment saying that if $M$ is complex, then $T^*M$ is too. Is $TJ$ the complex structure that person referred to? Or can we define (in a more or less natural way) other complex structures using $J$ ? In that case, does it matter if I consider $TM$ or $T*M$ , suposseing $M$ is still Riemannian? Let me add some context for my question. I want to reproduce Hitchin's result about the c-Map but defining all the structures globally. Because he points that it is possible, but he doesn't prove the result and works only locally. Here is the paper I say and here you can find another paper studying the c-map globally in the lagange of principal bundles, which I want to avoid.","['complex-geometry', 'vector-bundles', 'differential-geometry']"
3126593,Groups of derangements: what is known about subgroups of a symmetric group $S_{n}$ that contain only derangements (plus the identity)?,"A derangement is a permutation that has no fixed points. My question is . . . What is known about subgroups of a symmetric group $S_{n}$ that contain only derangements (plus the identity)? It is clear that elements of such groups would need to be a product of $\frac{n}{k}$ disjoint $k$ -cycles. It would be simple to see cyclic groups, but this is certainly not all possible. For example, if $n=6$ , I can generate in GAP a subgroup generated by $(163)(245)$ and $(15)(23)(46)$ which contains only derangements plus the identity. Is any more known?","['permutations', 'gap', 'group-theory', 'finite-groups']"
3126610,$n\geq 2 $ such that the equation $x^2-x+\hat2=\hat0$ has an unique solution in $\mathbb Z_n$,"Find $n\geq 2 $ such that the equation $x^2-x+\hat2=\hat0$ has an unique solution in $\mathbb Z_n$ . I've tried to solve it this way: Let $a$ be its only solution. We see that $1-a$ is a solution too, so $a=\hat1-a \Rightarrow \hat2a=\hat1$ . Now I did a thing which I'm not sure if that's true, writing $a=\hat2^{-1}$ . ( $\hat2$ is not invertible in $\mathbb Z_4$ for example) $\hat2^{-2}-\hat2^{-1}+\hat2=\hat0 \ , \ \hat1-\hat2+\hat2^3=\hat0$ so $n=7.$ Can somebody tell me if this is correct?","['ring-theory', 'abstract-algebra', 'modular-arithmetic']"
3126642,"All permutations of $1,2,...,n$ such that each element is larger than all previous elements or smaller than all previous elements","We have a sequence $a_1,a_2,...,a_n$ and $\forall i\in N;~~~ a_i\in\{1,2,3,...,n\}$ . A sequence is $GOOD$ if we have that: For Every $k \in N$ , we have $a_k≥a_i$ for every $i<k$ , or $a_k≤a_i$ for every $i<k$ . it means that every element is larger than all previous elements or smaller than all previous elements. We want to find how many permutations of $1,2,3,...n$ are $GOOD$ ? It was a question in an old exam and the answer was $2^{n-1}$ it said that in every choice, we can put the biggest or the smallest element from the remaining numbers, except that for the last one we have one choice so the answer is $2^{n-1}$ . I don't completely understand this answer. (eg. if we follow this algorithm it could easily get to the point where we can't choose any other number: $1\to 1, \  n \to ?$ Can anyone explain this answer or give another answer for this question? Is this answer correct? PS. Changed the condition so it is better understandable.","['permutations', 'combinations', 'combinatorics']"
3126660,Which books to use for self-studying calculus and linear algebra? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question After years of divorce with mathematics I decided to come back to it. I studied computer science, so had quite a lot of maths in university, but though passing the exams, I didn't feel I fully grasped it. Now I'd like to come back to this material and go through it in detail to really understand it. My reasons are: For fun I plan to also study some university physics It'll surely sharpen some of the skills used at my work as a programmer I was recommended to start with linear algebra and calculus. I'm planning to study both of them more or less concurrently. I want to self-study and am deciding what books to use for that. I like to dig deep into things and relly understand theory behind them, so probably I'd like books with more theoretical approach. But I wouldn't like to totally skip any real-world applications of those things, so ideally the book would also cover some of that. I'd also like something challenging and rigorous. Recommended positions I've done some research and see people recommending those positions: Calculus: ""Calculus"" by Michael Spivak ""Calculus"" by Tom Apostol (2 volumes) Linear algebra: ""Linear Algebra"" by by Stephen H. Friedberg, Lawrence E. Spence,, Arnold J. Insel ""Linear Algebra"" by Kenneth Hoffman ""Linear Algebra Done Right"" by Sheldon Axler ""Linear Algebra"" by Georgi E. Shilov Questions I've read Tom Apostol's book covers some linear algebra. Does it mean that I would be able to skip linear algebra book at all and learn both just doing his ""Calculus""? Spivak's ""Calculus"" covers only single-variable. If I choose to follow his book, what would be good choice of a book for multi-variable calculus? Which of those books on linear algebra cover both theory and applications? Or maybe it'd be wise to complete one more theoretical and then read about applications alone in another text?","['self-learning', 'book-recommendation', 'reference-request', 'calculus', 'linear-algebra']"
3126670,Can the domain of $f(x)/g(x)$ be larger than that of $f(x)$ or $g(x)$?,"Consider the following two functions: $f(x) = \sqrt {4 - x^2};\;\{x : x \in \mathbb{R}, x \ge -2 \,\ \text{and} \ \, x \le 2\}$ $g(x) = \sqrt {1 + x};\;\{x : x \in \mathbb{R}, x \ge -1\}$ Given that: $$\frac{f(x)}{g(x)} = \frac{\sqrt{4-x^2}}{\sqrt{1+x}} = \sqrt{\frac{4-x^2}{1+x}}$$ Is the domain of $\frac{f(x)}{g(x)}$ determined by the first step or only the last? For instance, does the domain include $-3$ ? If the domain is determined by the first step, then the answer would be NO, because both $\sqrt{4-(-3)^2}$ and $\sqrt{1+(-3)}$ are imaginary. However, if the domain is determined by the second step, then the answer would be YES, because $\sqrt{\frac{4-(-3)^2}{1+(-3)}} = \sqrt{\frac{-5}{-2}} = \sqrt{\frac{5}{2}}$ Any help appreciated.",['algebra-precalculus']
3126779,Showing an alternating sum is positive,"I am trying to prove the following for $n > 1$ . $$\sum_{k=0}^n (-1)^k \binom{n}{k} \max\{0,n-2k\}^{n-1} > 0.$$ From numerical computations, this seems to be true, but I am struggling to find a simple proof. Attempt:
I noticed that by an inclusion-exclusion argument, one can show that the following similar expression is exactly zero. $$\sum_{k=0}^n (-1)^k \binom{n}{k} (n-k)^{n-1} = 0.$$ Since the addends of the latter sum are larger in magnitude than those of the former sum, and both sums begin with the same term $n^{n-1}$ , I was hoping this would help, but it seems this is not quite enough. (Take for example $5 - 10 + 5 = 0$ vs $5 - 8 + 2 = -1$ .) I tried to interpret the original sum as an inclusion-exclusion argument itself, but the $\max\{0, n-2k\}$ is difficult to interpret in a combinatorial situation. As noted in the comments, I could rewrite the first sum as $$\sum_{k=0}^{\lfloor n/2 \rfloor} (-1)^k \binom{n}{k} (n-2k)^{n-1},$$ but this does not help me too much in either of my above approaches. The desired inequality would hold if the addends were decreasing in magnitude. But unfortunately this is not true either: see @saulspatz's answer  below along with my comments there.","['summation', 'combinatorics', 'inclusion-exclusion']"
3126805,A 'Kinda' Normal Distribution Over the Unit Interval? (the ladybug won't die),"Update: I added the stochastic-processes tag. For my non-theoretical computer model/application, I'm trying to approximate a Bernoulli random variable. So we are 'watching the ladybug' to get a real-time estimate of the probability as each observation is processed. The application uses an $\alpha$ of $\text{1%}$ . This is a filtering parameter - we allow for the fact that the Bernoulli distribution itself can change over time. If things (strategic adaptions) changed quickly, an $\alpha = \text{10%}$ might work better - we 'open up the filter' to place more value in the current reading. Let $\alpha = 0.01$ . A ladybug is walking on the open unit interval $(0,1)$ . She starts at the midpoint $\frac{1}{2}$ . Every minute she makes a move to either the right (a larger number) or to the left (a smaller number). The ladybug makes the move by flipping a coin. If the coin comes up heads and she is at position $x$ , she move to the right to the number $\tag 1 x  + \alpha \, (1 - x) = (1 - \alpha)\,x + \alpha$ If the coin comes up tails and she is at position $x$ , she move to the left to the number $\tag 2 (1  - \alpha) \, x$ If the ladybug does this for many weeks, is there a continuous random
  variable that statisticians use to estimate probabilities that the
  ladybug is in some sub-interval? Note: I am just curious about this and would expect any answer to be a bit esoteric from my perspective. For example, it might involve Beta distributions , something that I've never studied.","['stochastic-processes', 'statistics', 'probability', 'maximum-likelihood']"
3126811,Integral using group theory,"I am taking a first course on representation theory and trying to solve a problem where I'm asked to use group theory to integrate something. Given the polynomial: $$
P(x,y) = ax^2 +bxy +cy^2
$$ consider the integral $$
\int_\Delta P(x,y)dxdy
$$ where $\Delta$ is an equilateral triangle with its centroid at the origin and one of the vertices lying on the $y$ -axis. The question asks to ""decompose $P(x,y)$ into irreducible representations of the symmetry group of the triangle and identify which vanish under the integral and which do not"". The idea of this question is to integrate the polynomial using symmetry, this is fine, but what is not clear to me is what is meant by ""decomposing $P$ into irreducible representations"" since I don't see how $P$ is a representation. What I have done is breaking $P$ into parts which are symmetric or anti-symmetric with respect to some symmetry of the domain and using invariance of the integral under change of variable. My question is: What do they mean by that decomposition of the polynomial? PS: please don't give solutions to the problem itself!","['integration', 'group-theory', 'representation-theory']"
3126835,How Gaussian curvature is affected by a conformal map (using forms),"This is an exercise from Tu's book Differential Geometry. Let us say we have a two Riemannian manifolds $M$ and $M'$ of dimension 2 with a diffeomorphism $T:M\to M'$ between them. Say $T$ is conformal, i.e., for every point $p\in M$ , there is a positive number $a(p)$ such that $$\langle T_*(u),T_*(v)\rangle_{M',F(p)} = a(p)\langle u,v\rangle_{M,p}$$ for all $u,v\in T_pM$ . We must determine the relationship between the Gaussian curvatures between the two manifolds. In this section of the book Tu gives a version of Theorem Egregium in terms of forms, where for an orthonormal frame $e_1,e_2$ we have the Gaussian curvature is given by $$K = \Omega^1_2(e_1,e_2)$$ where $\Omega^1_2$ is a curvature form. We also have that the Gaussian curvature at a point is given by $$K_p = \langle R_p(u,v)v,u\rangle$$ for any orthonormal basis $u,v$ for $T_pM$ . Further, we know that $$\langle R(e_1,e_2)e_2, e_1\rangle = \Omega^1_2(e_1,e_2).$$ At the moment it is fairly unclear to me how to work with these notions of curvature and the conformal map property to get a relationship. Any help would be much appreciated!","['curvature', 'differential-geometry']"
3126856,"There is a bag of 8 candies, and 3 are chocolates. You eat candy until the chocolates are gone. What is the probability you will have eaten 7 candies? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question You buy a bag of $8$ candies, of which $3$ are chocolates, but all candies look alike. You eat candies from the bag until you have eaten all three chocolates. What is the probability you will have eaten exactly $7$ of the candies in the bag?","['statistics', 'probability']"
3126858,Prove that $C^{\infty}_b(\mathbb{R}^{n})$ is dense in $C_{b}(\mathbb{R}^{n})$ using generic functions.,"Let $$C^{\infty}_b(\mathbb{R}^{n}) = \{f:\mathbb{R}^{n} \to \mathbb{R} \mid f\text{ is smooth and } \Vert f \Vert_{\infty} < \infty\},$$ $$C_{b}(\mathbb{R}^{n}) = \{f:\mathbb{R}^{n} \to \mathbb{R}\mid f\text{ is continuous and bounded}\}.$$ I want to prove that $C^{\infty}_b(\mathbb{R}^{n})$ is dense in $C_{b}(\mathbb{R}^{n})$ . The proofs that I know are totally constructive, I mean: the proofs use explicit function defined by parts. I want to know if is possible to prove this result using generic functions (such a generic step function) or, at least, a strong theorem.","['continuity', 'general-topology', 'real-analysis']"
3126890,What is the $n^{th}$ term derivative of $f(x) = (x^2-x-1)(\ln(1-x))$?,I have the first three terms but am struggling with finding the $n^{th}$ term derivative of the function. Here is my work: $$\\$$ $$f(x) = (x^2-x-1)(\ln(1-x)) $$ $$f'(x) = (2x-1)(\ln(1-x))-\left(\dfrac{x^2-x-1}{1-x}\right)$$ $$f''(x) = \dfrac{3x^2-5x+2(x-1)^2 \ln(1-x)+3}{(1-x)^2}$$ $$f'''(x) = \dfrac{2x^2-5x+1}{(x-1)^3}$$ $$f^{(n)}(x) = \ ?$$,"['calculus', 'derivatives']"
3126909,Is $\Bbb Z_3$ a subset of $\Bbb Z$?,"I was told that this is not true. Based on my understanding of a subset it would seem that this is true. If every element of $\Bbb Z_3$ is in $\Bbb Z$ then it is a subset. $0,1,2$ are in $\Bbb Z$ , so is it not a subset?","['elementary-set-theory', 'elementary-number-theory']"
3126948,How many equivalence classes of squares are there?,"Let's say we have a $3×3$ square where $3$ of the cells are labeled $a$ , $b$ , $c$ and the rest are blank. Two such squares are considered ""equivalent"" if one square can be obtained from another square by 1) rotation on 90, 180, and 270 degrees, 2) reflection (through the horizontal, vertical, or either diagonal axis). I need to find equivalence classes of squares (maybe groups or patterns?). My attempt is : 
1) put the $a$ , $b$ and $c$ in the 1-st row: $A=\left(%
\begin{array}{ccc}
  a & b & c \\
  .. & .. & .. \\
  .. & .. & .. \\
\end{array}
\right)$ , then we can rotate the square $A$ on 90, 180 and 270 degrees: $A_{90}=\left(%
\begin{array}{ccc}
  .. & .. & a \\
  .. & .. & b\\
  .. & .. & c \\
\end{array}
\right)$ , $A_{180}=\left(%
\begin{array}{ccc}
  .. & .. & .. \\
  .. & .. & ..\\
  c & b & a \\
\end{array}
\right)$ , $A_{270}=\left(%
\begin{array}{ccc}
  c & .. & .. \\
  b & .. & ..\\
  a & .. & .. \\
\end{array}.
\right)$ . Four square $A$ , $A_{90}$ , $A_{180}$ and $A_{270}$ are equvalent. This is the first equivalence class. 2) put the $a$ , $b$ and $c$ in the main diagonal: $$A=\left(%
\begin{array}{ccc}
  a & .. & .. \\
  .. & b & .. \\
  .. & .. & c \\
\end{array}%
\right)
$$ and rotate on 90 degree $$A_{90}=\left(%
\begin{array}{ccc}
  .. & .. & a \\
  .. & b & .. \\
  c & .. & .. \\
\end{array}%
\right)
$$ Two square $A$ and $A_{90}$ are equvalent. This is the second equivalence class. Edit 2. Here I have found the 16 patterns. Question. How many equivalence classes for three elements in a square are there?","['class-field-theory', 'abstract-algebra', 'combinatorics', 'symmetric-groups', 'group-theory']"
3126969,Proving limit does not exist (multivariable caculus),"How do I prove that the limit: $$\lim_{(x,y)\to(0,1)} y\sin(1/x)$$ does not exist. I am absolutely lost. I am not sure if I can substitute $(x,y)$ for another function such as $y=x-1,$ leading to the limit being: $$\lim_{(x-1)\to(1)} (x-1)\sin(1/x)$$ but I think this just complicates things more. Any help is appreciated.","['multivariable-calculus', 'limits', 'calculus']"
3126970,Weird Answer involving Minimum,"Given the isosceles triangle $ABC$ , in which $AB$ is 12 inches and the altitude $CD$ is 3 inches, find the point $P$ on CD such that the sum of the distances of P from the vertices is a minimum. This problem seemed fairly simple.
Here's the equation that I set up: $$2\sqrt{x^2+36} + 3 - x = d$$ Then, I took the derivative, set it to zero, and hoped to find the minimum: $$2 \cdot 2x \cdot \frac{1}{2} \cdot \frac{1}{\sqrt{x^2+36}} -1 = d'$$ $$\frac{2x}{\sqrt{x^2+36}} = 1$$ $$4x^2 = x^2 + 36$$ $$x = 2\sqrt{3}$$ Firstly, my book says the answer should be where the point C lies (i.e, the length $x = 3$ inches). Secondly, $2\sqrt{3} > 3$ . If I'm right, I would like to know how to interpret this result (as I had obtained similar answers for previous questions). If I'm not right, I would like to know how I screwed up something so basic so I can then proceed to bash my head on the wall for the next few hours (not really). Thanks. Edit: Here's a better picture.","['word-problem', 'calculus', 'geometry']"
3127041,finding the mean and variance descriptive statistics,"Suppose the following data are obtained by recording $X$ , the number of customers that arrive at an automatic banking machine during $15$ successive one-minute
time intervals. Q) Record the mean and variance. mean is $u_{X} = \sum_{x=1}^{15} x f_{X}(x) = 1.67$ using the data from below: $f_{X}(0) = 4/15, f_{X}(1) = 3/15, f_{X}(2) = 4/15, f_{X}(3) = 2/15, f_{X}(4) = 2/15$ variance is $\sigma^2_{X} = \sum_{x=1}^{15} x f_{X}(x) - 1.67^2 = 1.88$ the mean is the same as the solution, but the variance they got was $1.952$ . What am I doing wrong?","['descriptive-statistics', 'statistics', 'probability']"
3127047,When is a quotient of a principal bundle is a principal bundle?,"Suppose $\pi:P\rightarrow M$ is a principal $G$ bundle. Let $H$ be a Lie group acting freely and properly on $P$ and on $M$ so that $P/H$ and $M/H$ are manifolds. Further assume this action is such that it defines a map $P/H\rightarrow M/H$ . Is it always true that the induced map $P/H\rightarrow M/H$ is also a principal $G$ bundle? I think it is true, may be with some extra conditions. Can some one please say what extra conditions (if at all) I need to confirm $P/H\rightarrow M/H$ is a principal $G$ bundle?","['principal-bundles', 'smooth-manifolds', 'lie-groups', 'differential-geometry']"
3127101,Proving the set $\{x ∈ \Bbb Z|x ≥ 3\}$ is countable,"Show that the set $\{x ∈ \Bbb Z|x ≥ 3\}$ is countable. I'm really stuck on this problem, I have an exam really soon and I'm trying to solve it. So far I know that I have to show that it's onto and one-to-one. Would I start by saying that $f(n)= 3 + n$ and then showing that it's onto and one-to-one?","['elementary-set-theory', 'discrete-mathematics']"
3127157,"Show that the set $𝐴 × ℤ^+$ is countable, where $𝐴=\{2,3\}$.","Show that the set $A  $ × $  \Bbb Z^+$ where $A=\{2,3\}$ is countable. I checked the answer and it says that the set is infinitely countable, could someone explain why? I don't understand how this set contains an unlimited amount of integers for it to be infinite. I also don't understand how to read this set, could someone explain what $\{2,3\}$ actually means? If that makes sense.","['logic', 'discrete-mathematics']"
3127188,Reference of the ergodic theorem in continuous time,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space and $\tau_t:\Omega\to\Omega$ for $t\ge0$ such that $\tau_0=\operatorname{id}_\Omega$ $\tau_{s+t}=\tau_s\tau_t$ for all $s,t\ge0$ $\tau:\Omega\times[0,\infty)\to\Omega$ is $\left(\mathcal A\otimes\mathcal B\left([0,\infty)\right),\mathcal A\right)$ -measurable $\operatorname P\circ\:\tau_t^{-1}=\operatorname P$ for all $t\ge0$ Now, let $$\mathcal I:=\left\{A\in\mathcal A:\tau_t^{-1}(A)=A\text{ for all }t\ge0\right\}.$$ I'm searching for a reference (with proof) of the ergodic theorem of the following form: If $p\in[1,\infty)$ and $F\in\mathcal L^1(\operatorname P)$ , then $$\frac1t\int_0^tF\circ\tau_t\:{\rm d}t\xrightarrow{t\to\infty}\operatorname E\left[F\mid\mathcal I\right]\tag1$$ almost surely and in $L^p(\operatorname P)$ . I was only able to find either the discrete-time analogue or the special where $\tau$ is the time-shift on the canonical probability space of a stochastic process.","['measure-theory', 'ergodic-theory', 'reference-request', 'stochastic-processes', 'dynamical-systems']"
3127310,Integration by substitution in different dimensions,"I want to solve a specific integral, by using substitution. As it is too specific to describe my situation and probably also not of general interest, let me give a toy example. Let $\overline{\Omega} \subseteq \mathbb{R}^3$ and $\Omega \subseteq \mathbb{R}^2$ be two domains of different dimension. Note that the intrinsic dimension of $\overline{\Omega}$ is two, although the ambient space is three dimensional.
Furthermore, I know a bijective map $\varphi: \overline{\Omega} \rightarrow \Omega$ . We may assume that all partial derivatives of $\varphi$ exist.
I want to solve the following integral as follows: $$\int_{x\in \Omega} f(x)dx = \int_{x\in \varphi(\overline{\Omega})} f(x)dx = \int_{y\in \overline{\Omega}} f(\varphi(y)) \ ? ? ? \ dy.$$ Where I have written the three question marks, there should be a dependence on $\varphi$ . According to Wikipedia, if $\varphi$ would be a function from $\mathbb{R}^n$ to $\mathbb{R}^n$ , I should take the absolute value of the determinant of the Jacobian. 
( https://en.wikipedia.org/wiki/Integration_by_substitution ) But $\varphi'$ is not a square matrix. So something else needs to be done.
I feel there should be a general theorem that one can look up if one knows integrals better. Question 1: What should be at the three question marks? Question 2: Can someone give me a citeable source? many thanks
Till","['integration', 'determinant', 'matrices', 'substitution', 'derivatives']"
3127321,How much rigour is this proof of multivariable chain rule?,"I have seen some statements and proofs of multivariable chain rule in various sites. I ""somewhat"" grasp them but seems too complicated for me to fully understand them. To make my life easy, I have come up with a simple statement and a simple ""rigorous"" proof of multivariable chain rule . Please explain to what extent it is plausible. PLEASE NOTE: In my statement of multivariable chain rule "" $f[x(t),y(t)]$ is differentiable at $t=a$ "" is a condition rather than a provable result. I think it is the only way in which my statement differs from the usual statement. I am a graduate Physics student and everywhere in my text (Electricity and Magnetism, Thermodynamics, etc) there is no mention of differentiability even though multivariable chain rule is used quite often. It seems to me the book just assumes that all functions used in the book are differentiable everywhere. So with this little change in the statement, I do not think it will have any affect on my rigorous Physics study. Am I right? $\text{}$ Statement: If $f[x(t),y(t)]$ , $x(t)$ and $y(t)$ are differentiable at $t=a$ ; and $f(x,y)$ is differentiable at $x(t)=x(a)$ and $y(t)=y(a)$ ; then at $t=a$ $$\dfrac{df[x(t),y(t)]}{dt}=\dfrac{\partial f[x(t),y(t)]}{\partial x(t)}\ \dfrac{dx(t)}{dt}+\dfrac{\partial f[x(t),y(t)]}{\partial y(t)}\ \dfrac{dy(t)}{dt}$$ $\text{}$ Proof: \begin{align}
\Delta f[x,y]&=f[x+\Delta x, y+\Delta y]-f[x,y]\\
&=f[x+\Delta x, y+\Delta y]-f[x,y+\Delta y]+f[x,y+\Delta y]-f[x,y]\\
&=\delta f_x[x,y]+\delta f_y[x,y]\\
\Rightarrow\ \Delta f[x(t),y(t)]&=\delta f_x[x(t),y(t)]+\delta f_y[x(t),y(t)]\\
\Rightarrow \dfrac{\Delta f[x(t),y(t)]}{\Delta t}&=\dfrac{\delta f_x[x(t),y(t)]}{\delta x(t)}\dfrac{\Delta x(t)}{\Delta t}+...\\
\Rightarrow \lim\limits_{\Delta t \to 0} \dfrac{\Delta f[x(t),y(t)]}{\Delta t}&= \lim\limits_{\Delta t \to 0} \left( \dfrac{\delta f_x[x(t),y(t)]}{\delta x(t)}\dfrac{\Delta x(t)}{\Delta t}   \right)+...\\
\Rightarrow \lim\limits_{\Delta t \to 0} \dfrac{\Delta f[x(t),y(t)]}{\Delta t}&=
\lim\limits_{\Delta t \to 0} \left( \dfrac{\delta f_x[x(t),y(t)]}{\delta x(t)} \right)
\lim\limits_{\Delta t \to 0} \left(    \dfrac{\Delta x(t)}{\Delta t}   \right)+...\\
&\text{}\\
&\text{It is given that $x(t)$ is differentiable at $t=a$.}\\
&\text{Therefore $\lim\limits_{\Delta t \to 0} \dfrac{\Delta x(t)}{\Delta t}$ exists.}\\
&\text{Therefore when $\Delta t \to 0$, $\Delta x(t) \to 0$.}\\
&\text{}\\
\Rightarrow \lim\limits_{\Delta t \to 0} \dfrac{\Delta f[x(t),y(t)]}{\Delta t}&=
\lim\limits_{\Delta x(t) \to 0} \left( \dfrac{\delta f_x[x(t),y(t)]}{\delta x(t)} \right)
\lim\limits_{\Delta t \to 0} \left(    \dfrac{\Delta x(t)}{\Delta t}   \right)+...\\
&\text{}\\
&\text{It is given that $f[x(t),y(t)]$, $x(t)$ and $y(t)$ are differentiable at $t=a$;} \\
&\text{and $f(x,y)$ is differentiable at $x(t)=x(a)$ and $y(t)=y(a)$}\\
&\text{}\\
&\text{Therefore we can replace the limits with derivatives.}\\
&\text{}\\
\Rightarrow \dfrac{df[x(t),y(t)]}{dt} &=
\dfrac{\partial f_x[x(t),y(t)]}{\partial x(t)}\
\dfrac{dx(t)}{dt}  +...\\
\end{align} So this is the statement and proof I have come up with. Again, please explain to what extent is it plausible (whether it is completely or partially rigour).","['proof-verification', 'multivariable-calculus', 'partial-derivative', 'limits', 'chain-rule']"
3127364,Convergence of ergodic averages,"Let $(X_n)_{n\in\mathbb N_0}$ be a time-homogeneous Markov chain on a probability space $(\Omega,\mathcal A,\operatorname P)$ with transition kernel $\pi$ , invariant measure $\mu$ and initial distribution $\nu$ . Let $f\in\mathcal L^1(\mu)$ and $$A_{b,\:n}f:=\frac1n\sum_{i=b}^{b+n-1}f(X_i).$$ Assuming that the total variation distance $|\mu-\nu\pi^n|$ tends to $0$ as $n\to\infty$ , it is claimed here in Theorem 3.18 that $$A_{b,\:n}f\xrightarrow{n\to\infty}\int f\:{\rm d}\mu.$$ In the proof, the author is basically reducing the problem to the case $\nu=\mu$ (i.e. the chain is started in stationarity). However, even in that case, we should need that $\operatorname P_\nu:=\nu\pi$ ( composition of transition kernels ) is ergodic with respect to the shift $$\tau:\mathbb R^{\mathbb N_0}\to\mathbb R^{\mathbb N_0}\;,\;\;\;(x_n)_{n\in\mathbb N_0}\mapsto(x_{n+1})_{n\in\mathbb N_0}.$$ What am I missing?","['ergodic-theory', 'markov-chains', 'stochastic-processes', 'probability-theory', 'dynamical-systems']"
3127381,What is meant by interval notation in $\mathbb{R}^n$?,"I am reading a version of the mean-value theorem and it goes as follows: What is meant by, 'the interval $[x,x+s]$ '?","['multivariable-calculus', 'calculus']"
3127408,Checking my proof for the following question,"I wanted to check my proof if it is correct. Using these field axioms: (i)Trichotomy Property:  Exactly one of $x<y$ , $y<x$ , or $x=y$ hold. (ii)Transitivity: if $x<y$ and $y<z$ (which we could write in shorthand as $x<y<z$ ), then $x<z$ . (iii)If $x<y$ then $x+z < y+z$ . (iv) If $x<y$ and $z>0$ then $xz<yz$ . (A1) Addition is commutative (A2) Addition is associative (A3) Addition has a neutral element $0$ (A4) Any element has an additive inverse (A5) Multiplication is commutative (A6) Multiplication is associative (A7) Multiplication has a neutral element $1$ (A8) Any non-zero element has a multiplicative inverse (A9) Multiplication distributes over addition Prove that for all $a,\, b,\, c\in\mathbb{R}$ , if $0<a<b$ and $0<c<d$ then $ac<bd$ . Since $a<b$ and $0<c$ , then by (iv), $ac<bc$ . Moreover, as $c<d$ and $0<b,$ $bc<bc,$ also by (iv). Therefore we can conclude, by (ii) $ac<bd$ .","['abstract-algebra', 'proof-verification', 'discrete-mathematics', 'real-analysis']"
3127431,How to prove that total number of non-isomorphic labelled trees of order $n$ is $n^{n-2}$?,"I predicted the formula by finding total number of non-isomorphic labelled trees of order 1 is 1 , order 2 is 1,order 3 is 3,order 4 is 16,order 5 is 125.But how do i prove it ?
I am beginner in graph theory so i will be very thankful if i get some simple approach to solve the problem(Not by using some difficult theorems).","['graph-theory', 'trees', 'data-structure', 'discrete-mathematics']"
3127454,Boundedness of high order derivatives,"Let $f:\mathbb{R}\to\mathbb{R}$ a function differentiable $p$ times in $\mathbb{R}$ , such that $f$ and $f^{(p)}$ bounded. Consequently, I would show that all intermediate derivatives $f^{(1)},...,f^{(p-1)}$ are also bounded on $\mathbb{R}$ . By myself, I succedeed in the case $p=2$ in this way: $$f(x_0+h)=f(x_0)+f^{(1)}(x_0)h+f^{(2)}(\xi _1)\frac{h^2}{2}$$ $$f(x_0-h)=f(x_0)-f^{(1)}(x_0)h+f^{(2)}(\xi _2)\frac{h^2}{2}$$ that are true $\forall x_0\in\mathbb{R}$ and $\forall h>0$ with $\xi_1\in (x_0, x_0+h)$ and $\xi_2\in (x_0-h, x_0)$ . So subtracting the first equation and the second: $$f(x_0+h)-f(x_0-h)=2hf^{(1)}(x_0)+\frac{h^2}{2}\left( f^{(2)}(\xi _1)-f^{(2)}(\xi _2) \right)$$ and so: $$f^{(1)}(x_0)=\frac{f(x_0+h)-f(x_0-h)}{2h}-\frac{h}{4}\left( f^{(2)}(\xi _1)-f^{(2)}(\xi _2) \right)$$ taking the absolute value of both members and using the triangular inequality at right member: $$|f^{(1)}(x_0)|\leq \frac{|f(x_0+h)|+|f(x_0-h)|}{2h}+\frac{h}{4}\left( |f^{(2)}(\xi _1)|+|f^{(2)}(\xi _2)| \right)$$ from which: $$|f^{(1)}(x_0)|\leq \frac{M_{0}}{h}+\frac{h}{2}M_{2}$$ where $M_{0}:=\sup_{x\in\mathbb{R}}|f(x)|$ and $M_{2}:=\sup_{x\in\mathbb{R}}|f^{(2)}(x)|$ . Consequently: $$\sup_{x\in\mathbb{R}}|f^{(1)}(x)|=:M_1\leq \frac{M_{0}}{h}+\frac{h}{2}M_{2}$$ . In a similar way I also proved the claim in the case $p=3$ , but I can't start the induction chain. Can you help me? Thanks.","['derivatives', 'upper-lower-bounds', 'real-analysis']"
3127547,Average of maximum among order statistic,"We have G groups. Each group has $M$ (i.i.d) variables $X_{g,1}$ ,..., $X_{g,M}$ following the exponential distribution exp(- $\mu$ ) ( $\mu$ is a constant). Focus on each group g (g=1,...,G), we take the $k$ th ( $k\leq M$ and fixed) order statistic $X_{g,sta}$ , i.e., $X_{g,sta}$ is the $k$ th-smallest value of each group. By taking the maximum of the G order statistics, we get a new varaible $X_{max}$ =max{ $X_{1,sta}, X_{2,sta},..., X_{G,sta}$ }. The question is: how to get the expectation E[ $X_{max}$ ] of $X_{max}$ ?","['expected-value', 'statistics', 'order-statistics']"
3127559,Riemann integral of two same functions except at finitely many points.,"Here is my proof. Theorem: If $f$ is Riemann integrable on $[a,b],c\in[a,b]$ , and $g(x)=f(x)$ except for finitely many points $c_1,\cdots,c_k$ in $[a,b]$ , then $g$ is Riemann integrable on $[a,b]$ , and $\int_{a}^{b}f(x)dx=\int_{a}^{b}g(x)dx.$ Suppose another function $g$ such that $g(x)=f(x)$ except for finitely many points $c_1,\cdots,c_k$ . Since $f$ is Riemann integrable, for any $\epsilon>0$ , there exists $\delta=\frac{\epsilon}{4n\sum_{i=1}^{k}|g(c_i)-f(c_i)|}$ such that for any partition $P=(a=x_0,\cdots,x_n=b)$ with $\left\lVert P\right\rVert<\delta$ , we have $\left|R(f,P)-\int_{a}^{b}f\right|<\frac{\epsilon}{2}.$ Now, \begin{align*}
\left|R(g,P)-\int_{a}^{b}f\right|&=\left|R(g,P)-R(f,P)+R(f,P)-\int_{a}^{b}f\right|\\
&\leq\left|R(g,P)-R(f,P)\right|+\left|R(f,P)-\int_{a}^{b}f\right|\\
&<\left|R(g,P)-R(f,P)\right|+\frac{\epsilon}{2}\\
&<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon.\\
\end{align*} where \begin{align*}
|R(g,P)-R(f,P)|&=\left|\sum_{i=1}^{n}g(x_i*)(x_i-x_{i-1})-\sum_{i=1}^{n}f(x_i*)(x_i-x_{i-1})\right|\\
&=\left|\sum_{i=1}^{n}(g(x_i^*)-f(x_i^*))(x_i-x_{i-1})\right|\\
&<\sum_{i=1}^{k}|g(c_i)-f(c_i)|(2n\delta)\\
&=2n\sum_{i=1}^{k}|g(c_i)-f(c_i)|\left(\frac{\epsilon}{4n\sum_{i=1}^{k}|g(c_i)-f(c_i)|}\right)\\
&<\frac{\epsilon}{2}
\end{align*} Is my proof of this theorem correct?","['proof-verification', 'riemann-integration', 'analysis', 'real-analysis']"
3127597,"How to spread probability in a ""gradient"", i.e. so that it decreases with distance from a point on a dimension?","I have data tasks which involve a little bit of math - which is really not my strong suit - hope you can help. Background Respondent has been given a question that they answer with options on a discrete 0:10 scale. One of the answers is ""the true"" response, so if each of the (11) options is assigned a (subjective) probability the sum of these probabilities must be 100%. So... Options on the scale: 0, 1 , 2 , 3, 4, 5, 6, 7, 8, 9, 10. $p(o_0)+p(o_1)+...p(o_i)...+p(o_9)+p(o_{10})$ = 1.0 = 100% What I plan to do is the following: First. If a respondent answers some option $o_i$ . I want to assign, to the respondent's option, a subjective probability, let's call it $p(o_k)$ . Then. Spread the remaining $1-p(o_k)$ probability over the other options; with the probability of each option declining as the distance from $o_k$ increase. All options must be assigned a non-zero probability. Problem What I can't solve is what function would give me the probability of an option on the scale, given: The probability of the respondent's option. The distance, on the scale, of an option from the respondent's option. That the sum of the probabilities of all options, on the scale, is 1. Example The respondent has answered option 4. I assign to option 4 a 25% chance of being true. Then there's a 75% probability of one of the other options is the true option. But what probability to assign each individual option if it is to decline with the distance (absolute difference) from 4? I hope this was sufficiently clear. Have a great day.","['statistics', 'bayesian', 'functions', 'exponential-function', 'probability']"
3127614,Proving $\frac{d}{dx}a^x=a^x\ln a$ from the integral definition of the natural logarithm,"Using the definition of the natural logarithm as $\displaystyle\ln x=\int_1^x\frac{dt}{t}$ , is there a way to prove that $\frac{d}{dx}a^x=a^x\ln a$ ? Proofs that I have generally seen have used the definition of the natural logarithm as the inverse of the exponential function $e^x$ : $$\frac{d}{dx}a^x=\frac{d}{dx}e^{x\ln a}=e^{x\ln a}\ln a=a^x\ln a$$ using the chain rule and the fact that $f(x)=e^x$ satisfies $f'(x)=f(x)$ . But is there a way to go about finding this derivative without using the definition of the natural logarithm as the inverse of the exponential function?","['calculus', 'derivatives', 'logarithms']"
3127635,Tilted sum of independent random variables,Let $(X_i)_i$ be a sequence of centered i.i.d. random variables with finite variance. Is it true that $$\frac{\sum_{i=1}^{\lfloor n^{0.6} \rfloor}X_i}{\sqrt{n}}\stackrel{\mbox{a.s.}}{\longrightarrow} 0\quad ?$$ Should be a sort of corollary of the central limit theorem but I don't know how to prove the a.s. convergence. Any help?,"['probability-limit-theorems', 'central-limit-theorem', 'convergence-divergence', 'probability-theory', 'random-variables']"
3127644,"$G$ group, $H \unlhd G$; prove/disprove $gC_G(h) \cap H \ne \emptyset, \forall h \in H, g \in G$.","Let $G$ be a (possibly infinite) group and $H \unlhd G$ . For a given $h \in H$ , $G$ is partitioned into the set of (e.g. left) cosets of $C_G(h)$ in $G$ . I would like to prove/disprove the following Claim: $gC_G(h) \cap H  \ne \emptyset, \forall h \in H, g \in G$ . It holds for $g \in H$ , since then $gh \in H \cap gC_G(h), \forall h \in H$ . If $g \notin H$ , we can say that $\exists g' \in G \setminus H$ such that $g \in Hg'$ , but I can't go farther than that.","['group-theory', 'normal-subgroups']"
3127675,How to find the total number of pages which a book has when the clues given indicate a range?,"This problem doesn't seem very complicated but I got stuck at trying to understand what is the meaning of the last clue involving an integer and a range. Can somebody help me? The problem is as follows: Marina is reading a novel. The first day she read a third of the book,
  the second day she read the fourth parts of what it was left, the
  third day she read half of what it was left to read, the fourth day
  she read the fifth parts of what it was still left to read, the fifth
  day she decided to end the novel and found that it was left less than $70$ pages. If she always read an integer number of pages and never
  read less than $14$ pages. How many pages did the novel had? The alternatives given in my book were as follows: $\begin{array}{ll}
1.&\textrm{360 pages}\\
2.&\textrm{240 pages}\\
3.&\textrm{180 pages}\\
4.&\textrm{300 pages}\\
5.&\textrm{210 pages}\\
\end{array}$ I'm lost with this problem. What would be the correct way to go?. So far what I attempted to do was the following: I thought that the number of pages that the book has to be $x$ . Since it said that the first day she read a third of the book I defined it as: $\frac{1}{3}x$ On the second day it is said that she read the fourth parts of what it was left so that would account for: $\frac{1}{4}\left(x-\frac{1}{3}x\right)=\frac{1}{4}\left(\frac{2x}{3}\right)=\frac{x}{6}$ The third day: $\frac{1}{2}\left(x-\frac{x}{6}\right)=\frac{1}{2}\left(\frac{5x}{6}\right)=\frac{5x}{12}$ The fourth day: $\frac{1}{5}\left(x-\frac{5x}{12}\right)=\frac{1}{5}\left(\frac{7x}{12}\right)=\frac{7x}{60}$ The fifth day: She decides to end reading the novel but, what it was left was less than $70$ pages. So this would translate as: $x-\frac{7x}{60}<70$ This would become into: $\frac{53x}{60}<70$ Therefore: $53x<4200$ $x<\frac{4200}{53}$ However this fraction is not an integer. There is also another piece of information which mentioned that she always read no less than $14$ pages. If during the first day she read a third of the novel then this would be: $\frac{1}{3}x>14$ So $x>42$ But, on the fourth day she read: $\frac{7x}{60}>14$ Therefore: $x>120$ How come x can be greatest than $42$ and at the same time $120$ ?. Am I understanding this correctly?. If I were to select the greatest value and put it in the range which I found earlier: $120<x<\frac{4200}{53}$ and round to the nearest integer: $120<x<79$ Which doesn't make sense. If it were $\frac{5x}{12}>14$ $x>33$ (rounded to the nearest integer) Which would be: $33<x<79$ But again this doesn't produce an reasonable answer within the specified range in the answers. Did I overlooked something or perhaps didn't understood something right?. Can somebody help me with this inequation problem?.","['algebra-precalculus', 'inequality']"
3127690,Simple example on uniformly convex spaces,"In the lectures we showed the following result: Theorem: Let $(E,\|\cdot\|_E)$ be a uniformly convex space. Consider a sequence $\{x_n \}\rvert_{n\in\mathbb{N}} \subset E$ and $x \in E$ such that it converges weakly to $x\in E$ $$ x_n\rightharpoonup x ,$$ and the sequence of the norms converges to the norm of $x\in E$ , i.e. $$\|x_n\|_E \longrightarrow \|x\|_E.$$ Then the sequence $\{x_n \}\rvert_{n\in\mathbb{N}} \subset E$ is strongly convergent $$x_n \longrightarrow x.$$ This means that weak convergence, together with the convergence of the norms imply strong converge in uniformly convex spaces. Question: Could you please provide a counterexample on a non uniformly convex space (maybe sequence space of bounded sequences $\ell^\infty$ ?) where this result does not hold? Concretely: A sequence on a non uniformly convex space such that it is weak convergent, and the sequence of the norms converges, but the sequence itself is not strongly convergent. I would be grateful to read any possible counterexample. Thanks!","['weak-convergence', 'analysis', 'functional-analysis', 'sequences-and-series', 'convergence-divergence']"
3127720,Simplify $\frac{4^{-2}x^3y^{-3}}{2x^0}$ to $\frac{x^3}{32y^3}$,"I am to simplify $\frac{4^{-2}x^3y^{-3}}{2x^0}$ and I know that the solution is $\frac{x^3}{32y^3}$ I understand how to apply rules of exponents to individual components of this expression but not as a whole. For example, I know that $4^{-2}$ = $\frac{1}{4^2}$ = $1/16$ But how can I integrate this 1/16 to the expression? Do I remove the original $4^{-2}$ and replace with 1 to the numerator and a 16 to the denominator like this? $\frac{1x^3y^{-3}}{16*2x^0}$ How can I simplify the above expression to $\frac{x^3}{32y^3}$ ? Would be grateful for a granular set of in between steps, even if they are most basic to others.",['algebra-precalculus']
3127764,Term by term integration of $\int_0^1 \sum_{n=0}^{\infty}a_nx^n g(x)dx$,"If $\displaystyle \sum_{n=0}^{\infty}a_nx^n$ converges uniformly to $f(x)$ on $[0,1]$ and $g(x)$ is any integrable function. Can we perform term by term integration, in other words, is the following true $$\displaystyle\int_0^1f(x)g(x)dx=\displaystyle\int_0^1 \sum_{n=0}^{\infty}a_nx^n g(x)dx=\displaystyle  \sum_{n=0}^{\infty}a_n\int_0^1x^n g(x)dx$$ I don't have series representation of $g(x)$ . What are the conditions on $f$ and $g$ that ensure such a term by term integration?","['calculus', 'sequences-and-series', 'functional-analysis', 'real-analysis']"
3127771,Total differential equation with an integrating factor depending on the product $xy$,"Description Show that if the quantity $$\frac{\frac{\partial P(x,y)}{\partial y}-\frac{\partial Q(x,y)}{\partial x}}{yQ(x,y)-xP(x,y)}$$ is a function $g(z)$ of the product $z=xy$ , then the quantity: $$\mu=e^{\int g(z)dz}$$ is an integrating factor for the equation: $$P(x,y)dx+Q(x,y)dy=0$$ I am certain this is a problem about total differential equations but I am not sure how to translate the first quantity into the function $g(z)$ .
The equation that requires the integrating factor could be a differential of another function, which is constant. How do I pick up from there? Thanks in advance.","['ordinary-differential-equations', 'differential', 'integrating-factor', 'partial-differential-equations', 'partial-derivative']"
3127833,An example of a submartingale $X=\{X_n\}$ such that $\{X_n^2\}$ is a supermartingale.,"A submartingale is a real-valued stochastic process $X=\{X_n\}$ adapted to a filtration $\{\mathcal{F}_n\}$ such that $$E[X_{n+1}\mid \mathcal{F}_n] \geq X_n.$$ For a supermartingale just reverse the inequality. So I don't want someone to just give me the answer, but I'm having trouble just coming up with a submartingale at all. I've been using Durrett's book and there is a lack of examples for sure. Could someone point me in the right direction? Thank you so much!","['stochastic-processes', 'martingales', 'probability-theory', 'probability']"
3127874,Morphing Hypercubes and Odd Permutations,"Let $Q_n$ denote the $n$ -dimensional hypercube graph and let $H$ denote a subgraph of $Q_n$ that is isomorphic to $Q_{n'}$ , for some input parameter $n' \leq n$ (i.e. $H$ is an $n'$ -dimensional subcube of $Q_n$ ). Next, I would like to partition $H$ into $2^{n' - d}$ vertex disjoint subgraphs $H_1, \ldots, H_{2^{n'-d}}$ each isomorphic to $Q_d$ where $d \leq n'$ . We can think of each $H_i$ as a ternary string $s_i \in \{0, 1, *\}^n$ such that $s_i$ has exactly $d$ $*$ 's. These represent free coordinates. For each $s_i$ , we define a mapping $f_i : \{0, 1, *\}^n \to \{0, 1, *\}^n$ such that the $j$ -th coordinate of $f_i(s_i)$ is a $*$ if and only if the $j$ -th coordinate of $s_i$ is a $*$ . So intuitively, each $f_i$ maps a $d$ -dimensional subcube to another $d$ -dimensional subcube on the same axes. Let $H'$ denote the subgraph obtained by decomposing $H$ as described above and applying the $f_i$ 's on its $2^{n'-d}$ pieces. If $H'$ is also isomorphic to $Q_{n'}$ , then I call $H'$ a ""morph"" of $H$ . So my question is the following. Given $H$ , I would like to apply a sequence of ""morph"" operations to obtain a graph $H''$ that ""finishes where $H$ started"". By this, I mean that the ternary string that represents $H$ must be the same as $H''$ . However, if we look at the placement of the vertices in $H$ and $H''$ , I want them to induce an odd permutation. To make things clearer, let's look at a small example. Let $H$ denote a subgraph isomorphic to $Q_2$ in $Q_3$ . In my example, I will take $H$ to be the graph induced by the vertices with labels $\{A=000, B=001, C=010, D=011\}$ (i.e. the $0**$ face of $Q_3$ ). Now, consider the following 3 morph operations when $d=1$ : 1) Partition $\{A,B,C,D\}$ into pairs $\{A,B\}$ and $\{C, D\}$ . These can be represented by ternary strings $00*$ and $01*$ respectively.We morph $00* \to 11*$ and leave $01*$ unchanged. This gives us a new graph isomorphic to $Q_2$ with vertices $\{A = 110, B = 111, C = 010, D = 011\}$ . Note that $C$ and $D$ are unchaged from before. This new square doesn't have the same ""orientation"" as the first, since it has ternary string $*1*$ . 2) Next, partition the newly obtained $*1*$ into $*10$ and $*11$ and we morph $*10 \to *01$ to obtain the square $**1$ with labels $\{A = 101, B = 111, C = 001, D = 011\}$ . This also doesn't have the same ""orientation"" as $H$ . 3) Finally, we partition the obtained $**1$ into $1*1$ and $0*1$ and morph $1*1 \to 0*0$ . This gives us our graph $H''$ induced by the square $0**$ (just as it was with $H$ ). However, if we look at the new label placements, we see that we have $\{A = 000, B = 010, C = 001, D=011\}$ . And if we look at the permutation induced by $A,B,C,D$ , we see that: $A$ went from $000$ to $000$ , $B$ from $001$ to $010$ , $C$ went from $010$ to $001$ and $D$ went from $011$ to $011$ . This permutation is an odd permutation as needed. So now I am interested in the case when $d=2$ . Does there exists an $n'$ and $n$ such that there is a sequence of such ""morph"" operations that induce an odd permutation? I can try to add additional details if the question is still unclear. I also apologize for using possibly faulty terminology... I don't know the best way to frame/word this problem. Is there a better way to frame this problem? Edit: I've updated the labels for the vertices from a,b,c,d to A,B,C,D to avoid confusion with the other parameter d.","['permutations', 'graph-theory', 'reference-request', 'combinatorics', 'group-theory']"
3127895,A question about the central limit theorem,"The question is: $g:R\rightarrow R$ has at least three bounded continuous derivatives and let $X_i$ be $iid$ and in $L^2$ . Prove that: i) $\sqrt{n}[g(\overline{X_n}) - g(\mu)]\xrightarrow{w} N(0,g^{'}(\mu)^{2} \sigma ^2)$ and that ii) $E[g(\overline{X_n})-g(\mu)] = \frac{\sigma^2g''(\mu)}{2n} + o(n^{-1})$ as $n\rightarrow \infty$ where $\overline{X_n} = \frac{\sum X_n}{n}$ , $\mu = EX_1$ , $\sigma^2=Var(X_1)$ I have proved i) using CLT but for ii) $g(\overline{X_n}) - g(\mu)\approx N(0,g^{'}(\mu)^{2} \sigma ^2/n)$ as $n\rightarrow \infty$ . Since $RHS$ has $g''(\mu)$ , I was thinking of expanding $e^{\frac{-x^2}{2g'(\mu)\sigma^2/n}}$ using Taylor's series at $\mu$ but it already has $g'(\mu)$ in it which is a constant. If it had a $g'(x)$ , I would get a $2^{nd}$ derivative, so not sure how to approach the problem. Thanks and appreciate a hint.","['statistics', 'central-limit-theorem', 'probability-theory']"
3127898,Limit of permuted numbers when each of them is approaching $0$,"Let $\sigma:N_n \rightarrow N_n$ be arbitrary permutation of $n$ numbers. Does the following limit exist? $$\lim_{x_i \to 0} \frac{x_1+x_2^2+ \cdots x_n^n}{x_{\sigma(1)}+x_{\sigma(2)}^2+ \cdots {x_{\sigma(n)}^n}}$$ I've considered the case where $\sigma(n) = n$ for some $n \in N$ and concluded that then the limit doesn't exist but I'm having trouble figuring out when $\sigma(n) \neq n \ (\forall \ n \in N)$ . I was given a hint to consider that $\sigma (1) >1$ and $\sigma(n) <n.$ The set $N_n$ I believe to be arbitrary set with $n$ elements, not necessarily natural numbers. Don't have much much more context than that but I don't think this matters for the problem.","['limits', 'multivariable-calculus']"
3127902,Write $\cos^2(x)$ as linear combination of $x \mapsto \sin(x)$ and $x \mapsto \cos(x)$,"Can we write $\cos^2(x)$ as linear combination of $x \mapsto \sin(x)$ and $x \mapsto \cos(x)$ ? I know $$
\cos^2(x)
= \frac{\cos(2x) + 1}{2}
= 1 - \sin^2(x)
= \cos(2x) + \sin^2(x)
$$ but none of these helped.
Then, I tried to solve $$
\cos^2(x) = \alpha \sin(x) + \beta \cos(x)
$$ for the coefficients $\alpha, \beta \in \mathbb{R}$ .
But when plugging in $x = 0$ I get $\beta = 1$ and for $x = \frac{\pi}{2}$ I get $\alpha = 0$ . Plugging those values back in I obtain a false statement, and WolframAlpha can't do better! This is from a numerical analysis exam and the second function is $x \mapsto \sqrt{2}\cos\left(\frac{\pi}{4} - x \right)$ , which can easily be expressed in terms of $x \mapsto \sin(x)$ and $x \mapsto \cos(x)$ by the corresponding addition formula.","['algebra-precalculus', 'linear-algebra', 'trigonometry']"
3127948,Under what conditions does $E[f(X)] \approx f(E[X])$?,"Intuitively, when a random variable $X$ has a low variance, a sufficiently smooth function of that random variable will have an expected value which is close to that same function applied to $E[X]$ . That is, $$
f(E[X]) \approx E[f(X)]
$$ This is obviously true when $X$ takes on only one value, and appears in a few special cases I have worked out. Is this a well-known theorem? If not, how could this intuition be formalized?",['probability']
3127980,Vector valued function derivative with matrix,"Given a function $f: \mathbb{R}^n \rightarrow \mathbb{R}^n$ and a matrix $A \in \mathbb{R}^{n \times n}$ . Is there a general formula for calculating the following derivative: $$
\frac{\partial}{\partial x} f(x)^T A f(x) \tag{1} = ?
$$ I know that $$
\frac{\partial}{\partial x} x^T A x = x^T(A + A^T)  \overset{A = A^T}{=} 2 x^T A \tag{2}
$$ and the solution to $(1)$ will probably look similar to $(2)$ , but I am stuck here since I am not sure how to apply the chain rule in the matrix case. Edit: Regarding notation, we have $$
\frac{\partial }{\partial x}f(x) = \begin{bmatrix} \frac{\partial}{\partial x_1} f_1(x) & \frac{\partial}{\partial x_2} f_1(x) & \cdots & \frac{\partial}{\partial x_n} f_1(x) \\
\frac{\partial}{\partial x_1} f_2(x) & \frac{\partial}{\partial x_2} f_2(x) & \cdots & \frac{\partial}{\partial x_n} f_2(x) \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial}{\partial x_1} f_n(x) & \frac{\partial}{\partial x_2} f_n(x) & \cdots & \frac{\partial}{\partial x_n} f_n(x)  \end{bmatrix}
$$ and $$
x = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix} ,
f(x) = \begin{bmatrix}
f_1(x) \\
f_2(x) \\
\vdots \\
f_n(x)
\end{bmatrix}
$$","['matrices', 'calculus', 'matrix-calculus', 'derivatives']"
3128022,Why is $\sum_{i=1}^6 2^i = 2^7-2$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Why is $$\sum_{i=1}^6 2^i = 2^7-2$$","['algebra-precalculus', 'statistics', 'summation', 'probability']"
3128043,"Find the integral $\int \frac{(\ln(x))^2}{x^3} \, dx$","$$\int \frac{(\ln(x))^2}{x^3} \, dx $$ Starting off with Integration by Parts $$
\begin{align}
u = \ln(x)^2 &~~~ dv = x^{-3} \\\\
du = 2\ln(x)dx &~~~ v = \frac{x^{-2}}{-2}
\end{align}
$$ $$
\begin{align}
\int \frac{(\ln(x))^2}{x^3} &= (\ln(x))^2 \left( \frac{-x^{-2}}{2} \right) -\frac{2}{2} \int \frac{\ln(x)}{x^2}
\end{align}
$$ Integration by parts again... $$
\begin{align}
u = \ln(x)  &\hspace{10mm} dv = \frac{1}{x^2} \\\\
du = \frac{1}{x}dx &\hspace{10mm} v = -\frac{1}{x} \\\\
-\frac{2}{2} \int \frac{\ln(x)}{x^2} &= -\ln(x) \left(\frac{1}{x} \right) + \int \frac{1}{x^2}dx \\\\ 
\end{align}
$$ Integration by parts several times $\int \frac{1}{x^2}dx \rightarrow \int \frac{1}{x} \rightarrow \ln(x) + C$ Combining everything together, I get $$
\int \frac{(\ln(x))^2}{x^3} = (\ln(x))^2 \left( \frac{-x^{-2}}{2} \right) -\ln(x) \left(\frac{1}{x} \right) - \ln(x) + C\\\\
= -\frac{(\ln(x))^2}{2x^2} - \frac{\ln(x)}{x} - \ln(x) + C
$$ Is there a shorter way I could have done this? I think I got the right answer, but I am not really sure either. Checking my answer via differentiate doesn't seem like a feasible test strategy and even without time constraints still seems too complex for my level right now (but then maybe this is why I need the practice)",['integration']
3128053,Explanation of a regular pattern only occuring for prime numbers,"Consider multiplication group tables modulo $n$ with entries $k_{ij} = (i\cdot j)\ \%\ n$ visualized according to these principles: Colors are assigned to numbers $0 \leq k \leq n$ from $\color{black}{\textsf{black}}$ for $k=0$ over $\color{red}{\textsf{red}}$ for $k=\lfloor n/4\rfloor$ and $\color{silver}{\textsf{white}}$ for $k=\lfloor n/2\rfloor$ and $\color{blue}{\textsf{blue}}$ for $k=\lfloor 3n/4\rfloor$ back to $\color{black}{\textsf{black}}$ for $k = n$ Sizes are assigned to numbers $0 \leq k \leq n$ by $\textsf{1.5}$ if $k=\lfloor n/4\rfloor$ or $\lfloor 3n/4\rfloor$ $\textsf{1.0}$ otherwise Positions are shifted by $(n/2,n/2)$ modulo $n$ to bring $(0,0)$ to the center of the table. Visualized this way, you will occasionally find (for some $n$ ) highly regular multiplication group tables like these (with $n=12,20,28,44,52,68$ ): My question is: Why do these patterns occur exactly when $n = 4p$ with a prime number $p$ ? Find here some examples for $n \neq 4p$ , e.g. $n=61, 62, 63, 64$ : Here for some other prime numbers: $n = 4\cdot 31 = 124$ and $n = 4\cdot 37 = 148$ : One may observe that for $n = 4m$ and $x,y = m$ or $x,y = 3m$ the ""size 1.5"" dots are systematically separated by $0$ (= black) and $n/2$ (= white) dots, i.e. that there are only and exactly $4$ values along these lines. For the sake of completeness: the multiplication group table modulo $8 = 4\cdot 2$ (which also qualifies, but not so obviously):","['number-theory', 'group-theory', 'visualization']"
3128090,Can a holomorphic function be globally represented by a power series on an open connected set?,"I have a theorem in my book (Stein) which says: Suppose $f$ is holomorphic in an open set $\Omega$ . If $D$ is a disc centered at $z_0$ and whose closure is contained in $\Omega$ , then $f$ has a power series expansion at $z_0$ $$f(z) = \sum_{n=0}^{\infty} a_n(z-z_0)^n$$ for all $z \in D$ . Let's say our open set $\Omega$ contains $0$ ; let $P(z)$ be the power series of $f$ centered at $0$ . Obviously, if $\Omega$ is not connected, $P(z)$ does not have to represent $f$ at all points of $\Omega$ . However, what about the case where $\Omega$ is connected? Are there any counterexamples?","['complex-analysis', 'analysis']"
3128117,Questions on proving the lower bound for $P\left(\limsup\limits_{n\rightarrow \infty} A_n\right) \geq \frac{1}{C}$,"This is Lyapunov's inequality for moments of a random variable (the paper can be accessed here ): Let $\{F_{k}\}, k = 1, 2, ..., N$ be an arbitrary sequence of events in $(\Omega, F, P)$ . We have, if $P\left(\bigcup\limits_{k=1}^{n} F_k \right) > 0$ , (1) $$2 \sum_{1\leq j < k \leq N} P(F_{j}F_k) \geq \Bigg[P\bigg(\bigcup_{k=1}^N F_k\bigg)\Bigg]^{-1}\Bigg(\sum_{k=1}^N P(F_k)\Bigg)^{2} - \sum_{k=1}^N P(F_k)$$ Proof: Define r.v. $ X_k(\omega)=
\begin{cases}
0,  & \text{if $\omega \notin F_k$} \\[2ex]
1, & \text{if $\omega \in F_k$}
\end{cases}$ The following identity is evident: (2) $2 \sum\limits_{1\leq j < k \leq N} P(F_j F_k) = E\left[\left(X_1+...+X_N\right)^{2}\right] - E\left(X_{1}^{2} +...+ X_{N}^{2}\right)$ Now by the Schwarz inequality we have (3) $[E(X_1+...+X_N)]^2 \leq P(X_1+...+X_{N}>0)E[(X_{1}+...+X_N)]^2$ Since $E(X_k) = E(X_{k}^{2}) = P(F_k), $ $P(X_1+...+X_N>0) = P\left(\bigcup\limits_{k=1}^{N} F_k\right)$ by definition, (1) follows from (2) and (3) How can I strengthen Lyapunov's inequality for moments of a random variable so that this new inequality: $$P\bigg(\bigcup_{k=n}^{N} A_k\bigg) \geq \frac{\big(\sum_{k=n}^{N} P(A_k)\big)^{2}}{\sum_{k,j=n}^{N} P(A_k A_j)}$$ holds?","['measure-theory', 'probability-theory']"
3128143,A counterexample to show that the following set does not form a semigroup,"Let $A = $ { $f:\mathbb Z$ $\to \mathbb Z$ | the cardinality of set { $x \in \mathbb Z$ | $f(x) = x$ } is finite}. I have to prove or disprove that the set $A$ forms a semigroup/monoid under function composition. I can easily see that $A$ does not form monoid because the identity function does not exist in $A$ . I am trying to look for an example to disprove that $A$ forms a semigroup. Does the following work? Let $f(x) = x +1 $ and $h(x) = x-1 \in A\ \forall x \in \mathbb Z$ . Then, we can see that { $x$ $\in$ $\mathbb Z$ | $f(x) = x$ } is finite because no element gets mapped to itself, hence it is an empty set, and similar for { $x$ $\in$ $\mathbb Z$ | $h(x) = x$ }, which is also an empty set. But, $f(g(x)) = x$ $\forall$ $x \in \mathbb Z$ . Hence, the set { $x$ $\in$ $\mathbb Z$ | $h(f(x)) = x$ } is infinite and hence, closure is not satisfied. Can anyone check my work, please?","['monoid', 'proof-verification', 'abstract-algebra', 'semigroups', 'group-theory']"
3128156,Formulation of Bioche's rules in familiar notation,"I was trying to find an interesting problem for my physics students involving a nontrivial flux integral, and I came up with one that produced the integral $$\int \frac{dx}{1+\beta\cos x}$$ ( $\beta^2<1$ ). I resorted to the computer algebra system Maxima in order to integrate it, and that worked, but I wanted to understand what it had done. Playing around and searching on the web showed that this is an example that can naturally be approached using Bioche's rules, but the only description of those I could find was a French language wikipedia article . I'm finding the article hard to understand, I think not so much because of my weak French as what seems to be some archaic notation or old-fashioned ways of thinking about what we would today call a function. The WP article seems to say this (my attempted translation): In the following $f(t)$ is a rational expression in $\sin t$ and $\cos t$ . Then in order to calculate $\int f(t)dt$ , one forms the integrand $\omega(t)=f(t)dt$ . Then: If $\omega(-t)=\omega(t)$ , a good change of variables is $u=\cos t$ . If $\omega(\pi-t)=\omega(t)$ , a good change of variables is $u=\sin t$ . If $\omega(\pi+t)=\omega(t)$ , a good change of variables is $u=\tan t$ . If two of the preceding relations both hold, a good change of variables is $u=\cos 2t$ . In all other cases, use $u=\tan(t/2)$ . I'm having a hard time interpreting the distinction between $f$ and $\omega$ . Presumably rule 1 is equivalent to saying that $f$ is even. In 2, is the idea to do the substitution $t\rightarrow \pi-t$ , which also implies $dt\rightarrow-dt$ ? This would seem equivalent to $f(\pi-t)=-f(t)$ ...? Is there a reason not to just express the rules in terms of $f$ ? My faith in my own translation/understanding is not reinforced when I try to apply the rules to my own example. It seems that 1 holds, because $f$ is even. Then the substitution $u=\cos x$ transforms my integral into $$-\int\frac{du}{\sqrt{1-u^2}(1+\beta u)},$$ but this doesn't actually seem any better. It seems like the most general substitution $u=\tan(x/2)$ is required. What is wrong with my analysis/translation/understanding?","['integration', 'indefinite-integrals']"
3128164,Relationship between $(n - 1)$ forms and flux of a vector field across a hypersurface,"I am currently studying about differential forms and want to deduce the Divergence Theorem (the one in $\mathbb{R}^n$ ) from the general Stokes' Theorem, which is obtained by taking $$\omega = \sum_{i=1}^n (-1)^{i+1}F_idx_1\wedge\dots\widehat{dx_i}\dots,\wedge dx_n$$ However, I also want to find the relation between $\omega$ and the flux of $F$ through a surface $\Sigma$ . Note we defined flux using the integral $$\text{flux} = \int_\Sigma F\cdot \hat{n} $$ It seems to me that if $g$ is a parameterization of $\Sigma$ , then $g^* \omega=F\cdot \hat{n}\ \text{dvol}_\Sigma$ , but I cannot prove this. I tried writing the normal explicitly as a cross product $$ N=\det \begin{bmatrix}
e_1 & | & |& |\\ 
 |& \frac{\partial g}{\partial u_1} & \cdots & \frac{\partial g}{\partial u_{n-1}}\\ 
e_n & | & | & |
\end{bmatrix},\ \hat{n}=\frac{N}{||N||}$$ Then if we dot product with $F$ , we do get by opening the determinant a sum of the form $$F\cdot \hat{n} = \sum_{i=1}^n (-1)^{i+1}F_i\circ g \cdot \text{det of a weird minor}$$ I couldn't get any further though. EDIT: I should point out that my knowledge volume forms is basic and stems from the definition $$\text{vol}_M(x)(v_1,\dots,v_k) = \varepsilon \text{vol}_k (v_1,\dots,v_k) ,\ \forall v_i \in T_xM$$ where $\varepsilon$ is chosen such that $(v_1,\dots,v_k ; \varepsilon)$ is a positivly oriented frame. I also know that if I pull back a volume form I get $\sqrt{\det Dg^T Dg} du_1 \wedge \dots \wedge du_k$","['surface-integrals', 'calculus', 'vector-analysis', 'differential-forms', 'differential-geometry']"
3128231,Construct a Holder continuous compactly supported function,"I want to construct a function $f$ satisfying the following properties: 1) Holder continuous with exponent $\alpha \in (0,1)$ so that there exists $C > 0$ such that $$
|f(x+t) - f(x)| \le C|t|^{\alpha}, \forall x, t \in \mathrm{supp}(f)
$$ The exponent should be tight. 2) $f$ has compact support (say) in $[-1,1]$ , with $f(0) \ne 0$ . Life is better for me if $f(0) = \left\|f \right\|_{\infty}$ , but this is not a showstopper. 3) $f$ can be rapidly evaluated via arithmetic operations present in hardware, like adds/subtracts/multiplies/divides. Is such a function possible? (Note: Daubechies wavelets come close to satisfying this criteria, but fast evaluation is currently not available. Also, the Holder exponent cannot be tuned.)","['holder-spaces', 'functional-analysis']"
3128234,Convex Combination Generalized to Infinite Sums,"I'm independently studying Boyd & Vandenberghe's Convex Optimization and came across the following statement discussing convex combinations of infinite terms. The idea of a convex combination can be generalized to include
  infinite sums, integrals, and, in the most general form, probability
  distributions. Suppose $\theta_1, \theta_2, \dots$ satisfy $$\begin{align} \theta_i &\geq 0 \\ i &= 1, 2, \dots \\
\sum_{i=1}^{\infty} \theta_i &= 1 \end{align}$$ and $x_1, x_2, \dots \in C$ , where $C \subseteq \mathbb{R}^n$ is convex. Then $$\sum_{i=1}^{\infty} \theta_i x_i \in C$$ if the series converges. My first question is $\dots$ what mathematical concept or proof enables us to generalize the definition of convex combination from a finite $k$ to $k = \infty$ ? Previously in the book, the definition of convex combination was simply introduced as A point of the form $\theta_1 x_1 + \dots + \theta_k x_k$ , where $\theta_1 + \dots + \theta_k = 1$ and $\theta_i \geq 0$ , $i = 1, \dots, k$ is a convex combination of the points $x_1, \dots, x_k$ . My second question is $\dots$ why is it necessary that the series converge? Shouldn't the fact that $C$ is convex guarantee that the infinite sum $\sum_{i=1}^{\infty} \theta_i x_i \in C$ since $C$ is a convex set and convex sets are closed under convex combination? Thank you for taking the time to read this lengthy question!","['convex-optimization', 'convex-analysis', 'sequences-and-series']"
3128260,"If $f \in C[a,b]$ has $\int_{a}^{b}f(x)x^{n}dx=0$ for all $n\in \mathbb{N}$, then $f=0$.","Let $f \in C[a,b]$ with $$\int_{a}^{b}f(x)x^{n}dx=0$$ for all $n\in \mathbb{N}$ . Prove $f=0$ . I got the intuition to prove this with induction over $n \in \mathbb{N}$ , for $n=0$ , 
 I have $\int_{a}^{b}f(x)dx=0$ . So how I got that $f=0$ ? Also, how I end up the proof?
Any help will be appreciated. Thanks","['integration', 'calculus', 'functional-analysis', 'real-analysis']"
3128271,What is the integral of a cumulative distribution function?,"I cannot find what is the integral of a cumulative distribution function $$\int G(\xi)d\xi$$ I think it should be simple, but I have no idea where else to look for it.","['integration', 'statistics', 'probability-distributions']"
3128276,How many primes does this sequence find?,"The sequence in question is: $$S=\left\{\int_0^1\pi(x)\pi(1-x)dx,\int_0^2\pi(x)\pi(2-x)dx,...\right\},$$ where $\pi(x)$ is the prime counting function. I don't know how to check this for an infinite sequence but I've tried computing many values. Here's the first prime number in the sequence: $$\int_0^{13}\pi(x)\pi(13-x)dx=73.$$ and the second in the sequence: $$\int_0^{57}\pi(x)\pi(57-x)dx=3803.$$ This is what I know: The primes thin out as higher numbers are reached. My conclusion is that this sequence will continue to find fewer primes compared to all values computed.","['number-theory', 'prime-numbers', 'sequences-and-series']"
3128310,Tail event example,"In Durrett's Probability (4th edition), an example of a tail event (an event in the tail sigma-field $\bigcap_n \sigma(X_n, X_{n+1}, \dots)$ ) is the following: given independent random variables $X_1, X_2, \dots,$ and
their partial sums $S_n = \sum_{i=1}^n X_i$ , the following event is a tail event ( Example 2.5.2 ): $$
\{ \limsup_n S_n > x c_n \}, \; c_n \to \infty.
$$ I understand the high level idea of a tail event (i.e. only depends in the asymptotic behavior of the sum since $c_n$ go to infinity) but I cannot articulate a rigorous explanation. Is there a concrete way to show this?","['measure-theory', 'probability-limit-theorems', 'probability-theory', 'probability']"
3128330,Product of distributions satisfying log-sobolev inequality,"Let $f,g\in C^\infty(\mathbb{R})$ be two smooth positive functions satisfying $\int f = \int g = 1$ .  Suppose that both $f$ and $g$ satisfy the log-Sobolev inequality (LSI) with constant $C$ , so that $$
\int \phi^2 \log(\phi^2) f(x)\,dx \leq C \int |\phi'|^2 f(x)\,dx
$$ for every $\phi$ satisfying $\int \phi^2(x)f(x)\,dx = 1$ , and the same holds with $f$ replaces by $g$ . If $\int f(x)g(x)\,dx = Z > 0$ , does it follow that the density $h(x) = Z^{-1} f(x)g(x)$ also satisfies LSI with the same constant $C$ ? I would be equally interested in a counterexample.","['concentration-of-measure', 'functional-inequalities', 'probability']"
3128367,A curious equality of integrals involving the prime counting function?,"This post discusses the integral, $$I(k)=\int_0^k\pi(x)\pi(k-x)dx$$ where $\pi(x)$ is the prime-counting function . For example, $$I(13)=\int_0^{13}\pi(x)\pi(13-x)dx = 73$$ Using WolframAlpha, the first 50 values for $k=1,2,3,\dots$ are, $$I(k) = 0, 0, 0, 0, 1, 4, 8, 14, 22, 32, 45, 58, 73, 90, 110, 132, 158, 184, 214, 246, 282, 320, 363, 406, 455, 506, 562, 618, 678, 738, 804, 872, 944, 1018, 1099, 1180, 1269, 1358, 1450, 1544, 1644, 1744, 1852, 1962, 2078, 2196, 2321, 2446, 2581, 2718,\dots$$ While trying to find if the above sequence obeyed a pattern, I noticed a rather unexpected relationship: Q: For all $n>0$ , is it true, $$I(6n+4) - 2\,I(6n+5) + I(6n+6) \overset{\color{red}?}= 0$$ Example, for $n=1,2$ , then $$I(10)-2I(11)+I(12)=32-2*45+58 = 0$$ $$I(16)-2I(17)+I(18)=132-2*158+184= 0$$ and so on.","['integration', 'definite-integrals', 'prime-numbers']"
3128409,Does the following limit exist $\lim_{x \to 0} \frac{\cos x^{-2}}{ \cos x^{-2}}$,"$$\lim_{x \to 0} \frac{\cos x^{-2}}{ \cos x^{-2}}$$ I had nothing better to do than come up with a pathological function. 
The cos(x) function has an infinite number of zeroes which are constantly spaced.
cos(x^2) likewise has an infinity of zeroes, but the spacing between them decreases as one goes out to either infinity.
cos(x^-2) maps that infinity of zeroes into a finite interval, namely [-1,1].
I understand my quest for a pathological function might end here, but I felt the fact that its limit at zero didn't exist was more intuitive, since it had an infinite number of waves within any interval around x=0. So anyway, to generate a flat line with a infinite number of gaps on a finite interval around zero, I simply divided cos(x^-2) by itself to get cos(x^-2)/cos(x^-2) Clearly $${cos(x^{-2})\over{cos(x^{-2})}}=1;x \neq \sqrt[\scriptstyle-2]{{\pi\over2}+2\pi k} \enspace or \enspace \sqrt[\scriptstyle-2]{{3\pi\over2}+2\pi k}, \enspace k \in \mathbb{N} $$ I asked my classmates about this limit, and they thought little of it, even when I warned them about its odd neighborhood behavior. They were all convinced it was 1, since the function is 1 ""almost everywhere"" near x=0. I'll be honest, I'm not even sure if it exists. This pathology prevents one from defining f for an interval of any sort around 0, which I thought might preclude the existence of a limit because you lose some oppurtunities to find a delta within for every epsilon within an interval, since an infinity of epsilons is missing. I looked at wikipedia's (ε, δ)-definition of a limit line by line (I've never taken a real analysis course). Let ${\displaystyle f}$ be a real-valued function defined on a subset ${\displaystyle D}$ of the real numbers. Let ${\displaystyle c}$ be a limit point of ${\displaystyle D}$ and let ${\displaystyle L}$ be a real number. So f is defined on a subset of the real numbers, though an odd subset at that. When I speak of D, it can be the interval [-1,1] or any subinterval including x=0, since they all are pesky. I have a feeling that the issue here is the condition that c, here 0, has to be a limit point of the subset D of $\mathbb{R}$ . To be honest, I only have an intuitive grasp of what a limit point is. I know that the ends of an open interval are its limit points for example, but I have no Idea what it is in general. For a normal space, I know you can just show that a point is a limit point if it is the limit of some sequence of points in the subset at hand. So back to this example, I think you can come up with any other sequence that approaches zero as long as you dodge the gaps. So, straight to the chase... $${\displaystyle \lim _{x\to c}f(x)=L\iff (\forall \varepsilon >0,\,\exists \ \delta >0,\,\forall x\in D,\,0<|x-c|<\delta \ \Rightarrow \ |f(x)-L|<\varepsilon )}$$ I'll be honest, I don't fully understand this definition. In fact I've never done an epsilon delta proof before. If you can respond to some of my reasonings, that'd be great, but any airtight proof/disproof of the existence of the limit is appreciated.","['limits', 'epsilon-delta']"
3128424,Confused about the splitting of 2 in $\mathbb{Q}(i).$,"How do we split 2 in the cyclotomic ring $S = \mathbb{Z}[\sqrt{-1}]?$ Clearly the field $\mathbb{Q}(i)$ is a degree 2 normal extension. However, $(2)$ in $S$ is equal to $(2) = (1 - i)^2.$ Thus, the ideal cannot split anymore so we can deduce that $(1 - i)$ is in fact a prime ideal. But $S$ is a Dedekind domain and $(1 - i)$ is not a maximal ideal...I say this because $S/(1 - i) \cong \mathbb{Z}.$ Did I mistakenly assume that $\mathbb{Z}[i]/(1 - i) \cong \mathbb{Z}?$","['algebraic-number-theory', 'abstract-algebra']"
3128498,Is it possible to construct modulo classes that cover the integers?,"I am trying to construct (or disprove the existence of) some finite
  set, $S=\left\{(y,k)\mid y,k\in\mathbb{Z},y\ge2\right\}$ , where no two $y$ are the same, and every integer $x\in\mathbb{Z}$ may be written as $x=n\cdot y_i + k_i$ , where $(y_i,k_i)\in S$ . In other words, I am wondering if it might be possible to perhaps construct something like: $$x+k_1\equiv r_1\pmod2$$ $$x+k_2\equiv r_2\pmod3$$ $$x+k_3\equiv r_3\pmod4$$ $$\vdots$$ $$x+k_i\equiv r_i\pmod {i+1}$$ where, for all $x\in\mathbb{Z}$ , there is at least one $0 < j\le i$ where $r_j=0$ . So far I have written a greedy algorithm in python to try and find an example, with no luck. For example, the best case I have found for $i=4$ gives a covering of $\frac{56}{60}=\frac{14}{15}$ of the integers. I have a feeling it is not possible.","['elementary-set-theory', 'elementary-number-theory']"
3128507,Clues on how to solve these types of problems within 2-3 minutes for competitive exams,"$$\int_0^{102}\left(\prod_{k=1}^{100}(x-k)\right)\left(\sum_{k=1}^{100}\frac1{x-k}\right)\,dx$$ I've tried solving this problem but only thing that comes to my mind is the manual integration by multiplication of the expressions which will literally take much longer than the allotted time for competitive exams  Now this is a homework and exercises problem but I'd be glad if I could get some clues on how to solve this problem.","['integration', 'definite-integrals', 'derivatives']"
3128565,Representability of primes by quadratic forms and congruence conditions,"Let $$Q(x,y) = ax^2 + bxy + cy^2, \quad a,b,c \in \mathbb{Z}$$ be a binary quadratic form. We say an integer $n$ is representable by $Q$ if $n = Q(x,y)$ for some $x,y \in \mathbb{Z}$ . A theorem due to Fermat shows that a prime $p$ is representable by $x^2 + y^2$ if and only if $p = 2$ or $p \equiv 1 \pmod 4$ . Fermat also proved similar theorems about the quadratic forms $x^2 + 2y^2$ and $x^2 + 3y^2$ . Given a quadratic form $Q$ , one might ask if there exists an theorem analogous to those of Fermat. More precisely, does there exist a modulus $M \in \mathbb{N}$ and congruence classes $a_1,\ldots,a_k$ such that for all but finitely many primes $p$ , we have that $p$ is representable by $Q$ if and only if $$p \equiv a_1,\ldots,a_k \pmod M.$$ We say a natural number $N \in \mathbb{N}$ is convenient if the above holds for the quadratic form $Q_N(x,y) = x^2 + Ny^2$ . Gauss proved that the $65$ numbers $$1,2,3,4,7,5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 22, 25, 28, 37, 58, 21, 24, 30, 33, 40, 42, 45, 48, 57, 60, 70, 72, 78, 85, 88, 93, 4
102, 112, 130, 133, 177, 190, 232, 253
105, 120, 165, 168, 210, 240, 273, 280, 312, 330, 345, 357, 8
385, 408, 462, 520, 760
840, 1320, 1365, 1848$$ are convenient, and Weinberger showed that there are at most two additional convenient numbers. My question is what is known about the general case? For instance, is there a finite list of quadratic forms for which a Fermat-type theorem holds?","['number-theory', 'quadratic-forms']"
3128583,Flow of vector field on semi-Riemannian manifold,"Consider $\mathbb{R}^{n+1}$ with the metric given by $$ g(x,x) = 2x_1x_2 + \sum_{i=3}^{n+1}x_i^2 $$ and $M$ the set of $x$ such that $g(x,x)=1$ . Further, take a basis $e_1,...,e_n$ for $\mathbb{R}^{n+1}$ such that $g(e_1,e_1) = -1$ let $Y$ be the vector field on $M$ given by $Y(z) = e_2 - g(z,e_2)z$ . I want to prove that $t \mapsto \alpha_z(t)$ defines the flow of $Y$ with $$\alpha_z(t) = \frac{1}{1+g(z,e_2)t} (z + \frac{t}{2} (2 + g(z,e_2)t )e_2 ).$$ So far, I have showed that $$ \dot{\alpha}_z(t) = e_2 - \frac{1}{(1+g(z,e_2)t)^2}g(z,e_2)z $$ which looks somewhat familiar. I proceeded to compute $Y(\alpha_z(t))$ but the resulting term is quite large and does not look very helpfull. As of now, all I have is $\dot{\alpha}_z(0) = Y(\alpha_z(0))$ but I do not know how to prove it for arbitrary $t$ .","['semi-riemannian-geometry', 'differential-geometry']"
3128592,How to prove/show this actually defines a homomoprhism,"We define the  homomorphism $f: \text{SL}_2(\mathbb Z / 2 \mathbb Z) \to \text{SL}_2(\mathbb Z / 2 \mathbb Z)$ that maps the generators to: $ \begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix} \to \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$ $ \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \to \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$ How do we know this is a homorphism? In a previous exercise I explored that these two elements generate the group, the first has order 3, the second has order 2. Essentially this maps any power of the first matrix to the identity, and any power of the second to a power of the matrix $\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$ is it as simple as: $$f\left(\begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix}^{m \bmod 3}\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}^{n \bmod 2}\right)=\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}^{n \bmod 2}$$ But since the matrices don't commute I find it hard to prove this is a homomorphism ( $f(AB)=f(A) f(B))$ . Essentially I want to prove that: $f$ defined by: $$\begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix},\begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix}^2= \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix}^3 =\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \to \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$$ $$\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix},\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}, \begin{pmatrix} 1 & 0 \\ 1 & 1 \end{pmatrix}    \to \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} $$ is a homomorphism.","['group-homomorphism', 'finite-groups', 'matrices', 'abstract-algebra', 'group-theory']"
3128609,A $5\times 5$ Matrix with No Eigenvalues.,"It can be observed that a matrix of order $5$ over $\mathbb{R}$ has at least one eigenvalue in $\mathbb{R}$ . What if we consider a finite field? For example, over $\mathbb{Z}_2$ , a matrix having characteristic polynomial $x^4(x-1)+1$ cannot have an eigenvalue from $\mathbb{Z}_2$ . Can such a matrix exist?","['eigenvalues-eigenvectors', 'finite-fields', 'matrices', 'abstract-algebra', 'linear-algebra']"
3128611,"Why is a flat, asymptotically flat 3-manifold isometric to $\mathbb{R}^3$?","I'm currently reading Schoen & Yau's 1979 proof of the positive-mass theorem and arrived at the very last sentence on the very last page (modulo the appendix) where they say: Hence we conclude that $\mathop{Ric} = 0$ and because we are working in dimension three, $ds²$ is flat. This completes the proof of Theorem 2. Theorem 2, however, made the claim that the manifold-with-boundary $N$ is (globally) isometric to $\mathbb{R}^3$ and I haven't been able to figure out in detail why local isometry to $\mathbb{R}^3$ (away from the boundary, of course) implies global isometry in this case. (My gut tells me that I'm missing something very elementary about what 3-manifolds of the given kind must look like, so I hope you'll excuse if this is a very simple question.) For definiteness, let me restate the situation and the claim in detail: Let $N$ be a connected¹, complete², asymptotically flat Riemannian manifold-with-boundary. Here, asymptotic flatness means that (1) there is a compact set $K \subset N$ such that the open set $N \setminus K$ consists of finitely many connected components (""ends"") $N_k$ each of which is diffeomorphic to some $\mathbb{R^3} \setminus (\text{closed ball})$ , and (2) the boundary of $N$ has mean curvature $H < 0$ with respect to the outward-pointing normal $n$ . (Here, $H$ is defined as $H := \mathop{tr}_g II$ and $II(v, w) := \langle \nabla_v w, n \rangle$ is the 2nd fundamental form.) Claim: Suppose $N$ is flat and only has one end (called $N_k$ in the theorem). Then $N$ is isometrically isomorphic to $\mathbb{R}^3$ . ¹, ²: These requirements are not explicitly mentioned by Schoen & Yau but seem natural and, in fact, are necessary for some of the proofs in the paper to work. In particular, without them the claim would be false right away. I hope I'm not missing any further implicit assumptions on $N$ . My intuition is that the requirement on the boundary's mean curvature prevents it from bounding any ""holes"" in $N$ . (In particular, K cannot merely be the boundary of $N_k \subset \mathbb{R}^3$ , i.e. a sphere.) Moreover, the completeness of $N$ prevents us from choosing $K$ to be e.g. the empty set. Finally, the fact that $N = K \cup N_k$ and that $N$ is flat everywhere should prevent $K$ from including something like a flat 3-torus. After all, topologically, there would be nothing preventing me from e.g. gluing $N_k$ to $T^3$ . So I suspect that it must be the flatness forbidding this, in the sense that I cannot actually choose the throat between $N_k$ and $T^3$ to be flat. But I'm having trouble making this precise and, in particular, generalizing this argument to any other $K$ that is not a ball.","['manifolds', 'differential-geometry']"
3128617,"$G$ group, $H \unlhd G$; $gC_G(h) \cap H \ne \emptyset,\forall h \in H,g \in G$ iff $G$ fixes the conjugacy classes of $H$ under conjugation.","I have learnt here that, given a group $G$ and $H \unlhd G$ , it is $gC_G(h) \cap H \ne \emptyset,\forall h \in H,g \in G$ , if and only if $G$ fixes the conjugacy classes of $H$ under conjugation. Then, it seems that the following holds: Corollary. $K$ a group; put $G:=\operatorname{Aut}(K)$ and $H:=\operatorname{Inn}(K)$ ; $G$ fixes the conjugacy classes of $H$ under conjugation, and then the above claim holds. Proof. $\operatorname{Inn}(K)=im_\varphi$ , where $\varphi \colon K \rightarrow \operatorname{Aut}(K)$ is defined by $a \mapsto \varphi_a$ , being $\varphi_a(g):=a^{-1}ga, \forall g \in K$ . Now, $\forall \sigma \in \operatorname{Aut}(K)$ , $\sigma^{-1}\varphi_a\sigma=\varphi_{\sigma^{-1}(a)}$ ; but also, $\forall \sigma \in \operatorname{Aut}(K)$ , $\exists b \in K \mid \sigma^{-1}(a)=\varphi_b^{-1}(a)$ . Therefore, $\forall \sigma \in \operatorname{Aut}(K)$ , $\sigma^{-1}\varphi_a\sigma=\varphi_{\sigma^{-1}(a)}=\varphi_{\varphi_b^{-1}(a)}=\varphi_b^{-1}\varphi_a\varphi_b$ , for some $b \in K$ . $\blacksquare$ Does this corollary really hold? Is the proof correct?","['group-theory', 'normal-subgroups']"
3128618,Counting Necklaces,"Suppose we have a necklace with $n$ beads. Each bead is either red or blue. I'd like to ask how to count the number of necklaces $f(n,m,k)$ satisfying the following requirements: 1) There are exactly $m$ red beads; $(0 \leq m \leq n)$ . 2) No two adjacent red beads; 3) The number of blue beads with two adjacent red beads is $k$ exactly. Note that rotation of necklace is counted differently. For example, ""blue blue blue red"" is different from ""red blue blue blue"". Some test cases: $f(4,2,2)=2: \color{red}{1}0\color{red}{1}0, 0\color{red}{1}0\color{red}{1}$ $f(5,2,1)=5: 0\color{red}{1}011, 10\color{red}{1}01, 110\color{red}{1}0, 0110\color{red}{1}, \color{red}{1}0110$ , where $0$ represents a red bead and $1$ represents a blue one. I've colored the blue beads satisfying the third requirement. Note that $a_n=\sum_{m,k}f(n,m,k)$ are Lucas numbers .
I've also noticed that for fixed $m$ and $k$ , the series $f(n,m,k)$ seems to have a generating function which looks like $\frac{a-bx}{(1-x)^c}$ where $a$ , $b$ and $c$ are constants related to $m$ and $k$ .","['combinatorics', 'necklace-and-bracelets', 'generating-functions']"
3128621,Does $\lim_{x \to - \infty} \left(\frac{\pi}{2} + \arctan{x} \right) \cdot x = - \infty$?,"Does $$\lim_{x \to - \infty} \left(\frac{\pi}{2} + \arctan{x} \right) \cdot x = - \infty$$ ? My logic is that “something“ times ""negative infinity"" equals negative infinity. Am I right?","['limits', 'calculus', 'infinity']"
3128640,Algebraic Geometry Proof Explanation,"In the last paragraph of the proof given in this SE question ( $I(V \times W ) =I(V) + I(W)$ ), the OP alludes to an inductive / infinite descent argument, saying, ""Continuing this process, we finally get an expression with zero terms... etc."" Whilst the proof seems to make perfect sense up to this point, I do not understand the inductive step. Also, I just want to get some verification of the fact that the target identity, $I(V \times W ) =I(V) + I(W)$ , holds for arbitrary sets $V$ , $W$ , not just algebraic sets. Any help would go a long way!","['algebraic-geometry', 'proof-verification', 'proof-explanation']"
3128643,Find closed form of $f(x)=x^2 \cdot \lfloor {\frac{1}{x^2}}\rfloor$,"Yesterday I asked a question about the continuity of $f(x)=x^2 \cdot \lfloor {\frac{1}{x^2}}\rfloor$ and we found out that $f(x)=0$ , $\forall x>1$ . Now I want to find its closed form over the reals. Now, since $f$ is even, suffice it to find its closed form on $(0,1)$ and we are done. How to do this?",['functions']
3128652,Request for help with solving a tricky Riccati Differential Equation.,"Long story short, I'm working through a model derivation right now and have arrived at a tricky Riccati Differential Equation that I am afraid has pushed me beyond the limits of my talent. The equation is as follows: $$\frac{dE}{dt}=c\left(\frac{1-\exp(ht)}{1-g\exp(ht)}\right)+bE+aE^{2}.$$ It seems to me that this can't really be reduced down to an auxiliary equation form as would be the case if the $c$ term was constant, and I don't see any tricks with substitution that would help my cause. I have a strong feeling that I am missing something here. I would greatly appreciate if someone would please help me with this; and additionally if you can point me in the right direction,  please provide a further reference that I may investigate in case I have a case like this in the future. Thank you! Edit: I have substituted $h$ for $d$ inside the exponentials, in order to avoid confusion with the differential. Also, $a$ , $b$ , $c$ , $g$ , and $h$ are all constants.",['ordinary-differential-equations']
3128677,Is This a New Property I Have Found Pertaining to Mersenne Primes?,"While playing with Mersenne numbers, I found the following property distinguishing Mersenne prime numbers from Mersenne composite numbers. A Mersenne number, $\text{M}p$ , is a number of the form $2^p - 1$ , where $p$ is prime. Property For $p > 2$ , Mersenne primes can be expressed as \begin{align*}
	\text{M}p = \frac{a^3 + b^3}{a + b}\text{,}
\end{align*} where $a$ and $b$ are integers, $a \neq -b$ ,
with exactly $12$ different solutions.
So far, also $\operatorname{gcd}(a,b)=1$ holds for Mersenne primes. Mersenne composites have either no integer solution or more than $12$ solutions ( $24$ so far).
Also $\operatorname{gcd}(a,b)=1$ does not hold if the integer solutions exist so far. Examples \begin{align*}
\text{M}5 &= \frac{6^3 + 5^3}{11} = 31 \\
\text{M}7 &= 7^3 - 6^3 = 127
\end{align*} The M11 has no integer solution for $(a,b)$ . The M37 has 24 solutions and also $\operatorname{gcd}(a,b)=1$ does not hold. Remarks Except the M2, twelve solutions exist for each Mersenne prime.
If $(a,b)$ is a solution, then also $(-a,-b)$ , $(b,a)$ , and $(-b,-a)$ are. Since \begin{align*}
	\frac{a^3 + b^3}{a + b} = a^2 -ab + b^2 \text{,}
\end{align*} each Mersenne prime has an ellipse intersecting integer grid associated with it.
For example, $-a^2 + ab - b^2 + 127 = 0$ is the ellipse for M7. Results Solutions for the first few Mersenne numbers: $$\begin{matrix}
p & \text{M}p & (a,b) \\
\hline
2 &          3 & (1,2) \\
	 3 &          7 & (1,-2), (1,3), (2,3) \\
	 5 &         31 & (1,-5), (1,6), (5,6) \\
	 7 &        127 & (6,-7), (6,13), (7,13) \\
	11 &       2047 & \text{no solution} \\
	13 &       8191 & (1,-90), (1,91), (90,91) \\
	17 &     131071 & (6,-359), (6,365), (359,365) \\
	19 &     524287 & (83,-679), (83, 762), (679, 762) \\
	23 &    8388607 & \text{no solution} \\
	29 &  536870911 & \text{no solution} \\
	31 & 2147483647 & (4698, 43813), (4698,48511), (43813, 48511) \\
	37 & 137438953471 & \text{24 solutions} \\
	41 & 2199023255551 & \text{no solution} \\
	43 & 8796093022207 & \text{no solution} \\
   ... & ... & ... \\
\end{matrix}$$ I have verified the conjecture using WolframAlpha for all $p$ below 100. Question Can you confirm this result?
Is this known?
Any feedback is welcome.","['conjectures', 'number-theory', 'mersenne-numbers', 'primality-test', 'prime-numbers']"
3128718,An equation concerning perfect numbers,"Find all positive primes $p_1,p_2,p_3, \cdots p_n$ such that $$\left(1+\frac{1}{p_1}\right)\left(1+\frac{1}{p_2}\right) \cdots \left(1+\frac{1}{p_n}\right) =2$$ I found this question while finding all squarefree perfect
numbers.I denoted the primes as $p_1,p_2, \ldots, p_n$ thus the sum of all the factors is $$1+p_1+p_2+ \cdots p_1 p_2+\cdots +p_1 p_2 \cdots p_n$$ which we can notice to be $$\alpha =(1+p_1)(1+p_2) \cdots (1+p_n)$$ Thus, $$\alpha=2 p_1 p_2 \cdots p_n$$ Now dividing(transposing) each $(1+p_k)$ by $p_k$ we get the proposed question. I think there must be some cancellation in the fractions thus we assume WLOG they are in ascending order but still we don't know which factors cancelled where :(","['number-theory', 'elementary-number-theory', 'abstract-algebra', 'products', 'prime-numbers']"
3128722,"Coefficients of $1,x,x^2$ in $((\cdots (x-2)^2-2)^2-2)^2\cdots )-2)^2$","Finding coefficients of $x^0,x^1,x^2$ in $((\cdots (x-2)^2-2)^2-2)^2\cdots )-2)^2$ where there are $k$ parenthesis in the left side Try: Let $P(x)=((\cdots (x-2)^2-2)^2-2)^2\cdots )-2)^2$ Let we assume $P(x)=a_{k}+b_{k}x+c_{k}x^2+d_{k}x^3+\cdots\cdots $ For constant term put $x=0$ , we have $$((\cdots (0-2)^2-2)^2-2)^2\cdots )-2)^2=a_{k}$$ Now i did not know how to find coeff. of $1,x,x^2$ in $P(x)$ . Thanks",['algebra-precalculus']
3128749,"$28222149$, a semiprime with amazing properties","The semiprime $28222149$ is a semiprime $S=A*B$ (with $A=3$ and $B=9407383$ ) such that - $A.B$ - $B.A$ - $S.A$ - $S.B$ - $A.S$ - $S.A.B$ - $S.B.A$ - $A.S.B$ - $A.B.S$ - $B.S.A$ - $B.A.S$ are all semiprime. (Dots here means concatenation.) It would be a 'perfect' result if $B.S$ were also a semiprime. Unfortunately, $B.S$ is not semiprime. I've checked semiprimes up to $10^{10}$ , and I didn't find a semiprime which gives a 'perfect' result. Could you find a semiprime with 'perfect' result?","['number-theory', 'prime-numbers', 'semiprimes']"
3128756,Calculate the derivative $f(x)=\lfloor x\rfloor(\sin(\pi x))^{2}$,"I have a problem with this task because answer which I have does not match the right answer and I don't know where is a mistake. My try: For $x\in \mathbb Z$ $f'_{+}(x)=f'_{-}(x)=0$ so $f'(x)$ exist For $x \in (n,n+1), n \in \mathbb Z, f(x)=n(\sin(\pi x))^{2}$ So \begin{align}f'(x)&=1\cdot n^{0}(\sin(\pi x))^{2}+n((\sin(\pi x))^{2})'\\&=(\sin(\pi x))^{2}+n2\sin(\pi x)\cos(\pi x)\\&=(\sin(\pi x))^{2}+\sin(2\pi x)n\end{align} In the answer is: $f'(x)=n \pi\sin(2\pi x)$ and then $f'(x)=\lfloor x\rfloor\pi\sin(2\pi x)$ because for $x \in \mathbb Z$ $f'(x)$ also exist. Why?","['ceiling-and-floor-functions', 'derivatives', 'real-analysis']"
3128771,Showing that there exists a positive integer $t$ such that $5^t\equiv -3\pmod {2^{n+4}}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question When I deal with number theory, I encounter a problem that seems to be easy but I can't prove. let $n$ be a positive integer, there exists a positive integer $t$ such that $$5^t\equiv -3\pmod {2^{n+4}}$$","['real-numbers', 'number-theory', 'modular-arithmetic']"
3128869,Every real matrix $A$ is the linear combination of $4$ orthogonal matrices,"Question: Prove that every matrix $A\in M_n(\mathbb R)$ is the linear combination of $4$ orthogonal matrices $X, Y, Z, W$ , i.e. $A=aX+bY+cZ+dW$ for some $a,b,c,d\in\mathbb R$ . This problem is taken from a forum and this is my paraphrase. It is not obviously true. But I think the proof must invoke the singular-value decomposition (SVD) of a real matrix, but it's unclear to me what the next step is. Any idea is appreciated. Many thanks.","['orthogonal-matrices', 'linear-algebra', 'svd']"
3128870,Another way to compute $\lim\limits_{x\to+\infty}x^2\log\left(\frac{x^2+1}{x^2+3}\right)$,"I need to compute as a title a limit with $x\to+\infty$ . The only way I found to obtain a result is to use the L'Hôpital's rule: $$\lim\limits_{x\to+\infty}x^2\log\bigg(\frac{x^2+1}{x^2+3}\bigg)=\lim\limits_{t\to 0}\frac{1}{t^2}\log\bigg(\frac{1+t^2}{1+3t^2}\bigg)\stackrel{H}{=}\lim\limits_{t\to 0}\frac{1}{2t}\bigg(\frac{2t}{1+t^2}-\frac{6t}{1+3t^2}\bigg)=\lim\limits_{t\to 0}\bigg(\frac{1}{1+t^2}-\frac{3}{1+3t^2}\bigg)=-2$$ It seems the result is the difference between the two functions inside the log, but how this can be possible? Is there another way to compute these type of limits? I mean a calculus way without using theorems.","['limits', 'limits-without-lhopital', 'real-analysis']"
3129007,Problem with transformation of functions and simple logarithm,"I am tackling a problem as below: $F(x)=\ln x$ . The graph is transformed into a function $g$ by a translation
  of $(3 , -2)$ , followed by a reflection in the $x$ -axis. Find an
  expression for $g$ , giving your answer as a single logarithm. My thoughts are here: After the transformation: $$g(x)=-\ln(x+3)-2$$ Then I tried to make it into a single logarithm: $$g(x)=-(\ln x+\ln 3)-2=-\ln3x-2$$ How can I change the digit 2 also into a logarithm form?? Help!","['functions', 'logarithms']"
3129012,Please explain the authors' reasoning in a proof about stationary set,"My textbook Introduction to Set Theory 3rd by Hrbacek and Jech defines some concepts as follows: A set $C \subseteq \omega_1$ is closed unbounded if $C$ is unbounded in $\omega_1$ , i.e., $\sup C=\omega_1$ . $C$ is closed , i.e., every increasing sequence $$\alpha_0 < \alpha_1 < \cdots < \alpha_n < \cdots \quad (n \in \omega)$$ of ordinals in $C$ has its supremum $\sup \{\alpha_n \mid n \in \omega\} \in C$ . A set $S \subseteq \omega_1$ is stationary if $S \cap C \neq \emptyset$ for every closed unbounded set $C$ . A function $f$ with domain $S \subseteq \omega_1$ is regressive if $f(\alpha)<\alpha$ for all $\alpha \neq 0$ . Then they go on to prove this theorem: 3.6 Theorem A set $S \subseteq \omega_1$ is stationary if and only if every regressive function $f:S \to \omega_1$ is constant on an unbounded set. In fact, $f$ has a constant value on a stationary set. My question lie in the proof of the following example: In the proof, I am unable to understand how the authors go from For each $n$ , because $f_n(\alpha)<\alpha$ on $C$ to There exists $\gamma_n$ such that the set $S_n = \{\alpha \in C \mid _n(\alpha) = \gamma_n\}$ is stationary. Please helps me understand the authors' reasoning! Thank you for your help!","['elementary-set-theory', 'proof-explanation']"
