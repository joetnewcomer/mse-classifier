question_id,title,body,tags
1275437,Dividing an angle into $n$ equal parts,"My question is simply: for which values of $n$ is it possible to divide any given angle into $n$ equal parts using only a compass and a straight edge? I know that it is possible for $2$ and not possible for $3$, but is it possible for any integers that are not of the form $2^k$?","['geometric-construction', 'geometry']"
1275443,How to compute this multivariable limit?,"How do I evaluate $$\lim_{x \to 0 ,\, y \to 0} \frac{x^3y-xy^3}{(x^2+y^2)^{3/2}}$$ 
I tried using squeeze theorem and writing it in polar coordinates, but I got stuck. Can anyone give me a hint?","['limits', 'real-analysis']"
1275471,Showing that a function is surjective (onto)?,"For example : $F:\Bbb R\rightarrow\Bbb R$ defined by $F(x) = \frac{2x+1}{3}$ I let $F(x)=Y$ which gives $Y=\frac{2x+1}{3}$ then simplify and solve for $x$ , what I have at the end is $x=\frac{3Y-1}{2}$ , now I don't get how does this prove that the function is onto ?","['discrete-mathematics', 'functions']"
1275521,The Leibniz rule for the curl of the product of a scalar field and a vector field,I have some scalar field $u:D \rightarrow\mathbb R; \space \space D\subset \mathbb R^3$ and a vector field $\vec{v}: D\rightarrow \mathbb R^3$ and I want to show that: curl$(u\vec{v)}=$grad$(u)\times \vec{v}+u\space$rot$(\vec{v})$ My question is: How do I multiply a vector field by a scalar field? Can I write curl$(u\vec{v})$ like this: curl$(\vec{v})=$curl$\begin{pmatrix}uv_1\\uv_2\\uv_3\end{pmatrix}=$ $\begin{vmatrix}\hat{i}&\hat{j}&\hat{k}\\\frac{d}{dx}&\frac{d}{dy}&\frac{d}{dz}\\uv_1&uv_2&uv_3\end{vmatrix}=\hat{i}(\frac{d}{dy}(uv_3)-\frac{d}{dz}(uv_2))-\hat{j}(\frac{d}{dx}(uv_3)-\frac{d}{dz}(uv_1))+\hat{k}(\frac{d}{dx}(uv_2)-\frac{d}{dy}(uv_1))$ or am I doing something wrong? Edit: grad$(u)\times\vec{v}+u\space $curl$(\vec{v})=(\frac{du}{dx}\hat{i}+\frac{du}{dy}\hat{j}+\frac{du}{dz}\hat{k}) \times (v_1 \hat{i}+v_2\hat{j}+v_3\hat{k})+u\space $curl$(\vec{v})$ $=\hat{i}(\frac{du}{dy}(v_3)-\frac{du}{dz}(v_2))-\hat{j}(\frac{du}{dx}(v_3)-\frac{du}{dz}(v_1))+\hat{k}(\frac{du}{dx}(v_2)-\frac{du}{dy}(v_1))+u[\hat{i}(\frac{d}{dy}(v_3)-\frac{d}{dz}(v_2))-\hat{j}(\frac{d}{dx}(v_3)-\frac{d}{dz}(v_1))+\hat{k}(\frac{d}{dx}(v_2)-\frac{d}{dy}(v_1)]$ $\not=\hat{i}(\frac{d}{dy}(uv_3)-\frac{d}{dz}(uv_2))-\hat{j}(\frac{d}{dx}(uv_3)-\frac{d}{dz}(uv_1))+\hat{k}(\frac{d}{dx}(uv_2)-\frac{d}{dy}(uv_1))$ I guess I am making a mistake somewhere but I can't find it. Edit 2: grad$\space u \times \vec{v}=(\frac{du}{dx}\hat{i}+\frac{du}{dy}\hat{j}+\frac{du}{dz}\hat{k}) \times (v_1 \hat{i}+v_2\hat{j}+v_3\hat{k})$ $=\begin{vmatrix}\hat{i}&\hat{j}&\hat{k}\\\frac{du}{dx}&\frac{du}{dy}&\frac{du}{dz}\\v_1&v_2&v_3\end{vmatrix}=\hat{i}(\frac{du}{dy}(v_3)-\frac{du}{dz}(v_2))-\hat{j}(\frac{du}{dx}(v_3)-\frac{du}{dz}(v_1))+\hat{k}(\frac{du}{dx}(v_2)-\frac{du}{dy}(v_1))$,"['vector-fields', 'multivariable-calculus']"
1275574,What does it mean that we can diagonalize the metric tensor,"On a Riemannian manifold $M$, the matrix representation is diagonalisable, cause the tensor is symmetric. What is the physical meaning behind this? I mean, in Riemannian geometry, we always get a coordinate system defined by the charts(for simplicity I only use one) $\phi : M \rightarrow \mathbb{R}^k $ which we express here by $x_i := \pi_i \circ \phi,$ where $\pi_i $ is the projection on the $i-$th component in $\mathbb{R}^k.$ Now, by diagonalising the metric tensor, we can apparently make the transition to a basis of the tangent space $\partial_1,....,\partial_k$ at each point so that  the metric tensor is the identity matrix. I am not sure how to interpret this? Does this mean that the manifold looks locally euclidean? If so, does this mean that we can define locally a chart so that this chart would actually induce this locally euclidean coordinate system on the manifold? Probably, this chart would, if it exists, not be in general compatible with the atlas of the manifold $M$, is this correct? If my attemt to interpret this is wrong, I would love to here an explanation of this fact.","['differential-geometry', 'riemannian-geometry']"
1275575,Subgame perfect Nash equilibrium & perfect Bayesian Nash equilibrium - Game theory,"For a week or so I have been struggling with the topics around the concept of subgame perfect Nash equilibrium (SPNE) and the perfect Bayesian Nash equilibrium (BNE). Namely: Is it possible to apply backward induction (to obtain SPNEs) in dynamic games of complete but imperfect information? According to $\textit{Game Theory for Applied Economists}$ by $\textit{Robert Gibbons}$ it is possible. Or atleast, that what I understand from the text on page 128-129. But, then the SPNE would be implausible, since the player at the nonsingleton information set has no knowledge at which decision node he is. How is it then possible to apply backward induction to games of imperfect information? On page 129 of the book of $\textit{Gibbons}$ it is mentioned that there is a second method to obtain an optimal solution/strategy profile by specifying a probability to each node in the nonsingleton information set. And (this is what confuses me) this yields a perfect Bayesian equilibrium. But wait a minute... the perfect Bayesian equilibrium occurs in games of incomplete information, so how would we solve games of imperfect information by regarding games of incomplete information? I thought that we could solve games of incomplete information with the help of solution concepts applicable in games of imperfect information, but the above tells the reverse (right?). Hopefully one can help me out! 
Have a nice day.","['nash-equilibrium', 'probability', 'statistics', 'game-theory']"
1275594,"Determine whether the relations are symmetric, antisymmetric, or reflexive.","This exercise is given in my textbook and I am trying to solve it. Determine whether they are symmetric, antisymmetric or reflexive. $R_1=\{(2,2), (2,3), (2,4), (3,2), (3,3), (3,4)\}$ $R_2=\{(1,1), (1,2), (2,1), (2,2), (3,3), (4,4)\}$ $R_3=\{(2,4), (4,2)\}$ $R_4=\{(1,2), (2,3), (3,4)\}$ $R_5=\{(1,1), (2,2), (3,3), (4,4)\}$ $R_6=\{(1,3), (1,4), (2,3), (2,4), (3,1), (3,4)\}$ My answers: 1- $R_1$ is symmetric. 2- $R_2$ is reflexive, symmetric. 3- $R_3$ is symmetric. 4- $R_4$ is antisymmetric. 5- $R_5$ is reflexive, antisymmetric. 6- $R_6$ is symmetric, Book's answers: 1-None of the these properties. 2- $R_2$ is reflexive and symmetric. 3- $R_3$ is symmetric. 4- $R_4$ is antisymmetric. 5- $R_5$ is reflexive, symmetric and antisymmetric. 6-None of these properties. You can see that some of my answers don't match the answers given in book. Is that probably a misprint or I am wrong somewhere?","['relations', 'discrete-mathematics']"
1275612,Coffee Shop Meeting,"$A$ and $B$ decide to meet at a cafe between $5$ p.m. and $6$ p.m. They agree that the person who arrives first at the cafe would wait for exactly $15$ minutes for the other. If each of them arrives at a random time between $5$ p.m. and $6$ p.m., what is the probability that the meeting takes place? I figured that if one of them arrive at the first minute then the probability of the two meeting each other would be $15/60$, because the second person could arrive from the $1^{st}$ minute till the $15^{th}$ minute and meet with him. Similarly if the first person arrives at the second minute the probability would be $16/60$. This will go on till the $14^{th}$ minute and the probability would be $29/60$. The probability will remain $29/60$ till the $45^{th}$ minute, after which it will gradually decrease in the order $28/60, 27/60,... , 15/60.$ I am not sure if my approach is correct. Also I am stuck after a point with my approach. Please explain elaborately how to solve such questions.",['probability']
1275631,"A possible inequality related to binomial theorem (or, convex/concave functions)","Let $x, \ y, \ p$ be any real numbers with $x>0$, $y>0$, and $p>1$. The question is about (most probably) an elementary inequality: Is it always true that  $x^p+y^p\leq (x+y)^p$ ? Note that if $p$ is any positive integer, then the above inequality is obviously correct. What about if the number $p \ (\text{with} \ p>1)$ is any non-integer real number? I guess that (by my intuition) the answer should be positive. But how can we proceed to prove this inequality?","['analysis', 'real-analysis', 'inequality']"
1275692,The set of all critical points of a smooth map is closed,"Let $f : \mathbb{R}^m \to \mathbb{R}^n$ be a smooth map. How do I show that the set of all critical points of $f$ is closed in $\mathbb{R}^m$? (Here, a critical point is a point $x \in \mathbb{R}^m$ for which the derivative $Df_x : \mathbb{R}^m \to \mathbb{R}^n$ is not onto.) I can prove this by the inverse function theorem when $m = n$ but cannot see any easy way of going about it when $m > n$. Thanks.",['differential-geometry']
1275724,When should matrices have units of measurement?,"As a mathematician I think of matrices as $\mathbb{F}^{m\times n}$, where $\mathbb{F}$ is a field and usually $\mathbb{F} = \mathbb{R}$ or $\mathbb{F} = \mathbb{C}$. Units are not necessary. However, some engineers have told me that they prefer matrices to have units such as metres, kg, pounds, dollars, etc. Assigning a unit of measurement to each entry to me seems restrictive (for instance if working with dollars then is $A^2$ allowed?). Here are a few things that I would like to understand more deeply: Are there examples where it is more appropriate to work with matrices that have units? If units can only restrict the algebra, why should one assign units at all? Is there anything exciting here, or is it just engineers trying to put physical interpretations on to matrix algebra? Also, see: https://stackoverflow.com/questions/11975658/how-do-units-flow-through-matrix-operations","['unit-of-measure', 'matrices']"
1275759,Solve $\int \limits_{0}^{\infty} \frac{\cos(x)}{\cosh(x)} dx$ without complex integration.,"Solve $$\int \limits_{0}^{\infty} \frac{\cos(x)}{\cosh(x)} dx$$ without complex integration. This integral can be very easily solved with contour integration, but how can you solve it without taking a tour in the complex plane?","['improper-integrals', 'calculus', 'definite-integrals', 'integration']"
1275781,"Sufficient statistics and UMVUE for joint poisson, bernoulli","Given a pair $(X,Y)$ of r.v.s such that: $$X \sim
 \text{Poisson}(\lambda)\quad \text{and}\quad Y \sim
 B(\frac{\lambda}{1+\lambda})$$ with $X,Y$ independent, determine a
  one-dimensional sufficient statistic for $\lambda$ and the UMVUE
  (uniformly minimum variance unbiased estimator) for $\lambda$ . Attempt: $$P(X,Y\mid(x_1,x_2,\dots, x_n, y_1,y_2,\dots y_n)) =  P(X\mid(x_1,x_2, \dots x_n))\times P(Y|(y_1,y_2, \dots y_n)) = \prod_{i=1}^n\frac{\lambda^{x_i}e^{-\lambda}}{x_i!} \times \frac{\lambda^{y_i}}{1+\lambda} = \frac{\lambda^{\sum (x_i+y_i)} e^{-n\lambda}}{(1+\lambda)^n \prod x_i!}
$$ Using the factorisation theorem, $\sum(x_i+y_i)$ is a sufficient statistic. It is however not an unbiased estimator of $\lambda$ because: $$E\left(\sum(x_i+y_i)\right) = n\left(\lambda + \frac{\lambda}{1+\lambda}\right)$$ A trivial unbiased estimator would be $\frac{\sum x_i}{n}$ , but then it is not sufficient. To utilise Rao-Blackwell Theorem, $\sum x_i$ should be conditioned on $\sum x_i + y_i$ . I am not able to proceed further.","['estimation', 'probability', 'statistics', 'probability-distributions']"
1275803,Number of ways to express a number as the sum of different integers,"Given a number $n$, then  $P_k(n)$ is the number of ways to express $n$ as the sum of $k$ integers. For example $P_2(6)=7$ $0+6=6$ $1+5=6$ $2+4=6$ $3+3=6$ $4+2=6$ $5+1=6$ $6+0=6$ Now I worked out that $P_2(n)=n+1$ and $P_3(n)$ may be $P_3(n)=\sum^n _{k=0} P_2(n-k)$ but the question is: Given $k$ and $n$ is there a formula to always find $P_k(n)$?","['summation', 'elementary-number-theory', 'combinatorics']"
1275810,Show that $c_0$ is a Banach space with the norm $\rVert \cdot \lVert_\infty$,"Let $ c_0 = \{ x = (x_n)_{n \in \mathbb N} \in l^\infty : \lim_{n \to \infty} x_n = 0\}$ . Show that $c_0$ is a Banach space with the norm $\rVert \cdot \lVert_\infty$ I am capable of showing the space where the limit of $x_n$ exists is normed linear space but am having trouble with showing that the limit of Cauchy sequences must converge to 0. Let $(x^{(n)})_{n \in \mathbb N}$ be a Cauchy sequence in $c_0$ such that $x^{n} = (x^n_1, x^n_2,...)$ .
Fix $k \in \mathbb N$ consider the sequence $(x^n_k)_{n \in \mathbb N}$ in $\mathbb F$ . For any $n,m \in \mathbb N$ $\lvert x^n_k - x^m_k \rvert \le \sup_{k \in \mathbb N} \lvert x^n_k - x^m_k \rvert = \lVert x^n - x^m \rVert_\infty \lt \epsilon $ (1) Thus $x^n_k$ is Cauchy in $\mathbb F$ and so has limit $y_k$ such that $y = (y_1,y_2,...)$ and y is the limit of $x^n$ To show that such a y exists we look at the value of $\lvert y_n - y_m \rvert \le \lvert y_n - x^N_n \rvert + \lvert x^N_n - x^N_m \rvert + \lvert x^N_m - y_m \rvert \lt \epsilon$ for all $n,m \ge N$ (2) The middle expression on RHS of (2)  is $\lt \epsilon/3$ by (1) The other two are also $\lt \epsilon/3$ follow from $x^N_k$ being Cauchy and converging to $y_k$ This shows that $\lim_{n \to \infty} y_n$ exists but we still have not shown that $y \in c_0$ . I know that to show y tends to 0 i should show that $\lvert y_k \rvert \lt \epsilon$ for $k \ge N$ This is where I am stuck. Perhaps $\lvert y_k \rvert = \lvert \lim_{n \to \infty} x^n_k \rvert$ and then we can take the limit function outside the absolute value sign by continuity?
Then we might say due to it being a Cauchy sequence $x^n_k \lt \epsilon$ . I know this last bit isn't at all convincing so I could do with some help.","['cauchy-sequences', 'banach-spaces', 'functional-analysis']"
1275832,Linear Regression quadratic terms,"I have a hard time understanding the term 'linear regression'. For what I know, linear means polynomial of degree 1. But then, I found that in one of my lectures, the lecturers are saying that this regression is a linear regression: $$Y_i=\alpha_0+\alpha_1 x_i +\alpha_2 x_i^2$$ How is this a linear regression when it has quadratic terms in it? Does it not make it a non-linear regression? However when there is a quadratic curve as the regression, it is called a non-linear regression. Which is right?","['linear-regression', 'terminology', 'statistics', 'regression']"
1275848,One number divisible by all prime factors of another?,"Given two numbers $x$ and $y$, how to check whether $x$ is divisible by all prime factors of $y$ or not?, is there a way to do this without factoring $y$?.","['prime-numbers', 'number-theory', 'algorithms']"
1275856,Finding a nullspace of a matrix.,"I am given the following matrix $A$ and I need to find a nullspace of this matrix. $$A =
 \begin{pmatrix}
  2&1&4&-1 \\
  1&1&1&1 \\
  1&0&3&-2  \\
  -3&-2&-5&0
 \end{pmatrix}$$ I have found a row reduced form of this matrix, which is:
$$A' =
 \begin{pmatrix}
  1&0&3&-2 \\
  0&1&-2&3 \\
  0&0&0&0  \\
  0&0&0&0
 \end{pmatrix}$$
And then I used the formula $A'x=0$, which gave me:
$$A'x =
 \begin{pmatrix}
  1&0&3&-2 \\
  0&1&-2&3 \\
  0&0&0&0  \\
  0&0&0&0
 \end{pmatrix}
\begin{pmatrix}
  x_1 \\
  x_2 \\
  x_3  \\
  x_4
 \end{pmatrix}=
\begin{pmatrix}
  0 \\
  0 \\
  0  \\
  0
 \end{pmatrix}$$
Hence I obtained the following system of linear equations:
$$\begin{cases} x_1+3x_3-2x_4=0 \\ x_2-2x_3+3x_4=0 \end{cases}$$
So I just said that $x_3=\alpha$, $x_4=\beta$ and the nullspace is:
$$nullspace(A)=\{2\beta-3\alpha,2\alpha-3\beta,\alpha,\beta) \ | \ \alpha,\beta \in \mathbb{R}\}$$ Is my thinking correct? Thank you guys!","['solution-verification', 'linear-algebra', 'matrices']"
1275878,Does Tambara-Yamagami category admit a braiding when G is a non-abelian group?,"Tambara-Yamagami category is a fusion category which its simple objects are elements of a group and one element out of group. i.e : 
$$simple\;objects = G \cup \{m\}$$ 
The fusion rule of this category is :
$$m\times m=\sum_{i \in G} g_i, \hspace{0.5cm} g_i\times g_j=g_i*g_j(*:group\;action),\hspace{0.5cm}
m\times g_i=g_i\times m =m $$
As far as I know, according to [1],[2] there is a complete classification for braided Tambara-Yamagami category if we put G an abelian (2-)group. My question is about this category if G is a non-abelian group. 1-Tambara, Daisuke, and Shigeru Yamagami. ""Tensor categories with fusion rules of self-duality for finite abelian groups."" Journal of Algebra 209.2 (1998): 692-707. 2-Siehler, Jacob A. ""Braided near-group categories."" arXiv preprint math/0011037 (2000).","['abstract-algebra', 'fusion-categories', 'category-theory']"
1275881,How do I find this limit? $\lim_{n\to\infty}\frac{(n+1)^2}{4^n}$,"$$\lim_{n\to\infty}\frac{(n+1)^2}{4^n}$$ The answer says zero is the limit, how this is I do not understand, I've tried H'opitals rule , didn;t work out for me, anyone have any suggestions on how to solve this limit ?","['sequences-and-series', 'calculus', 'limits']"
1275899,Solutions of the equation $X^n-1\equiv 0$ (mod $m$)?,"How many solutions does the equation $X^n-1\equiv 0$ (mod $m$) have? It is obvious that if $m$ and $n$ are primes with $n|m-1$ then there exist $n$ solutions, otherwise there is only one ($X=1$). Is there any similar result for arbitrary $m,n\in\mathbb{Z}$? In order to solve this, I think it would be useful to know a result which is an inmediate consequence of the CRT, i.e.: If $m=p_1^{\alpha_1}\cdots p_r^{\alpha_r}$, then $X^n-1\equiv 0$ (mod $m$) iff $X^n-1\equiv 0$ (mod $p_i^{\alpha_i}$) for each $i=1\cdots r$.",['number-theory']
1275936,"How many strings of $\{0,1,2,3\}$ of length $n$ are there such that $0$ appears exactly once and $1$ appears an even number of times?","How many strings of length $n$ of the digits $\{0,1,2,3\}$ are there such that $0$ appears exactly once and $1$ appears an even number of times? My attempt: define $a_n$ to be a sequence of such string. If I had only the even number of appearances constraint, then it would be: $a_n =\\\begin{cases}0(\text{no constraint})= a_{n-1}\\ 
1 (\text{even number of ones}) = 1 (\text {general sequence}) - 1(\text{even number of ones}) = 4^{n-1}-a_{n-1} \\
2 (\text{ no constraint})= a_{n-1}\\
3 (\text{ no constraint})= a_{n-1}\\\end{cases}$ So: $a_n=4^{n-1}+2a_{n-1}$ If I had only the other constraint then I get stuck pretty quickly: $b_n =\\\begin{cases}0& (\text{ no more zeros})= 3^{n-1}\\ 
1& (\text{no constraint}) = \begin{cases} 10(\text{ no more zeros})= 3^{n-2} \\
11= ? \\12=? \\13=? \end{cases}\\
2& (\text{ no constraint})= ?\\
3& (\text{ no constraint})= ?\\\end{cases}$ Combining the two constraints makes it too complex to turn into a recurrence... Note that it should probably be solved with a recurrence formula.","['recurrence-relations', 'combinatorics']"
1275946,"Verify that the set $\Omega = \lbrace (u,v) \in \mathbb{R}^2 \mid |u| + |v| \leq 1 \rbrace$ is Jordan measurable","Motivation : I am currently in a rather uncomfortable spot in my Analysis studies. In class we introduced the Jordan measure in a very vague way, meaning no proofs, no examples. (Because next Semester we study the better Lebesgue-Measure theory) I do understand the concepts of it as a generalization of the 1 Dimensional case. That is, approximating a given bounded set $\Omega\subset \mathbb{R}^n$ from above and below by rectangles (boxes, simple sets) and if it happens that the smallest of all the approximations from above is equal to the largest of all the approximations from below, we say by definition that $\Omega$ is Jordan measurable. However when it comes to applying said intuitive idea I run into troubles Problem : Show that the set $\Omega := \lbrace (u,v) \in \mathbb{R}^2 \mid |u| + |v| \leq 1 \rbrace \subset \mathbb{R}^2$ is Jordan measurable. My approach : Clearly the set is bounded, from below by $0$ and from above $1$ . I don't know how to work with the definition as explained above in the motivation to show that said set is Jordan measurable. The best thing I could do was to cheat my way around by computing the following picture: The red line shows the boundary $\partial \Omega$ of the set. Since it is only a line segment in $\mathbb{R}^2$ it has Jordan measure zero respective to the topology in $\mathbb{R}^2$ . According to How to prove $E\subset R^n$ Jordan measurable is equivalent to $\bar{E}-E$ is Jordan measured null this would 'show' that $\Omega$ is Jordan measurable. My question is if I can formalize this idea into an actual proof rather than my hand wavy  explanation above. Or even better, is it possible to show that $\Omega$ is Jordan measurable by just relying on the definition of above/below approximations and check the equality of the infimum and supremum? Because said definition is so far what I understand best, the iff statement linked is only covered in the $\implies$ direction in my course.","['analysis', 'multivariable-calculus', 'measure-theory']"
1275968,Codifferential and corresponding homology theory,"This is the kind of a natural question which can come to mind after completing the standard course in differential geometry and homology theory: lety us start with a smooth manifold $M$. One can construct the differential $d$ on differential forms which satisfies $d^2=0$. With the help of this differnetial one can consider de Rham (cochain) complex and one naturally arrives to the de Rham cohomology. However, it is also possible to consider the codifferential $\delta$ defined as $\pm \star d \star$ where $\star$ is the Hodge star operator. However, as far as I understood, the Hodge star depends on the choice of metric (Riemannian) structure on $M$. This codifferential satisfies $\delta^2=0$ so also gives rise to some (chain) complex and therefore to some homology theory. Question : what is the connection of homology corresponding to this codifferential with (for instance) singular homology? In patricular, is it true that this homology does not depend from the choice of metric structure?","['homology-cohomology', 'differential-geometry', 'manifolds']"
1275978,Non-monic polynomial with roots on the unit circle,"When setting up to prove Dirichlet's Unit Theorem, we show that all roots of unity in a number field K are algebraic integers. Further, if all conjugates of $x \in \mathcal{O}_K$ have modulus 1 then $x$ is a root of unity. (Here $\mathcal{O}_K$ is the ring of algebraic integers in K). So the first question is can we find $x \in K\setminus\mathcal{O}_K$ such that $x$ and all of its conjugates have modulus 1 (and therefore cannot be roots of unity). This is equivalent to finding a non-monic irreducible polynomial $p(x)\in \mathbb{Z}[X]$ such that all of its roots are on the unit circle. Now I have found an example of this $5-6x^2+5x^4$ from a question on math overflow . So the real question is how might you come up with such an example (is it just trial and error?) The only other observation I have made is that in such a polynomial with coefficients $a_i \in \mathbb{Z}$ then $a_{n-k}=a_k$ for all $k \in  \{0, 1, 2, ..., n\}$. This is due to the fact that $\overline{z}=1/z$ for $z \in \mathbb{C}, |z|=1$.","['number-theory', 'algebraic-number-theory']"
1276003,Using induction prove $n^3-n$ is divisible by 3 whenever n is a positive number.,"I am not sure if I am doing this right, but I have this: There exists an integer $k$.
$2k =$ positive number $(2k)^3 - 2k$ [*And this is where I get lost. How does one prove this?]","['discrete-mathematics', 'induction', 'elementary-number-theory']"
1276009,Why are the fundamental theorems of calculus usually associated to the Riemann Integral?,"I am writing a ""textbook"" on Analysis, and I've reached the time I must talk about integrals. I prefer to approach directly the Lebesgue Integral theory. This question is not about the status of this opinion: it has been already extensively discussed in this website and in mathoverflow. My question is rather: why do we associate ""calculations"" with the riemann integral? Specifically, why is it common sense that the Fundamental Theorems of Calculus we see when we first study calculus are best understood in the riemann-integral framework? I give an example of this opinion: From a conceptual standpoint, I think that there are three things one asks of an approach to integration 1) An easily accessible geometric interpretation 2) A readily available computational toolbox (e.g. the fundamental theorem of calculus) 3) A flexible theory The Lebesgue integral is absolutely unrivaled in (3), but it is actually quite obtuse from the other two points of view. Basic results like the Lebesgue differentiation theorem and the change of variables formula are not at all transparent from the Lebesgue point of view, and geometrically it is no better than the Riemann integral. The Cauchy integral is great if you only care about (2), but it is abysmal at (1) and (3). The Riemann integral, for all its faults, strikes a pretty good balance between (1) and (2). It is even known to enjoy an occasional technical advantage over the Lebesgue theory; for instance, one must invent the theory of distributions to make sense of the Cauchy principal value of an improper integral in the Lebesgue theory if I recall correctly. this can be seen here. My point is: the fundamental theorems of calculus (as stated in calculus) can be demonstrated without ever touching the concept of riemann-integration. We, thus, have the so-asked tool of calculation without ever having to appeal to the riemann-integral theory. I illustrate my claim: [First Fundamental Theorem of Calculus] Let $f:[a,b]\rightarrow \mathbb{R}$ be an integrable function. Then: $$F(x):= \int_{[a,x]} f d\mu $$ is continuous in $[a,b]$. Furthermore, if $f$ is continuous at $x_0 \in (a,b)$, then $F$ is differentiable at $x_0$, and $$F'(x_0)=f(x_0)$$ Proof: To prove continuity, fix $x_0 \in [a,b]$. Take a sequence $x_n$ that converges to $x_0$. We will prove $F(x_n) \rightarrow F(x_0)$ $F(x_n)=\int_{[a,x_n]} f d\mu=\int_{[a,b]}f \chi_{[a,x_n]} d\mu$ It is easy to see that $f \chi_{[a,x_n]} \rightarrow  f \chi_{[a,x_0]}$ pointwise. Therefore, since the sequence $f \chi_{[a,x_n]}$ is dominated by $|f|$, it follows by Lebesgue's Dominated Convergence Theorem that: $\lim F(x_n)=F(x_0)$ This proves continuity. For the second part, we must prove that $\lim_{x \rightarrow x_0}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. We will prove that the right-handed limit is $f(x_0)$, and the left-handed limit is analogous. Suppose $f$ is continuous at $x_0$. Take an arbitrary $\epsilon >0$. There exists a $\delta>0$ such that $|x-x_0| < \delta \implies f(x_0)-\epsilon<f(x)<f(x_0)+\epsilon$. Therefore, if $0<x-x_0 <\delta$, since $$\frac{F(x)-F(x_0)}{x-x_0}=\frac{\int_{[x_0,x]}f(x)}{x-x_0}$$ we have: $$ \frac{\int_{[x_0,x]}(f(x_0)-\epsilon)}{x-x_0}\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq \frac{\int_{[x_0,x]}(f(x_0)+\epsilon)}{x-x_0} \implies$$ $$ f(x_0)-\epsilon\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq f(x_0)+\epsilon$$ Therefore, taking any sequence $x_n \rightarrow x_0$ from the right. We have: $$ f(x_0)-\epsilon\leq \limsup \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ $$ f(x_0)-\epsilon\leq \liminf \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ Since $\epsilon >0$ is arbitrary: $\lim \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0}=f(x_0)$ This holds for every sequence $x_n \rightarrow x_0$ from the right. Then, $\lim_{x \rightarrow x_0^+}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. As said before, the left-handed limit is analogous. $\blacksquare$ [Second Fundamental Theorem of Calculus] If $f$ is a continuous function on $[a,b]$ and there exists a differentiable function $F$ on $[a,b]$ such that $F'=f$, then: $$\int_{[a,b]}f d\mu=F(b)-F(a)$$ Proof: Fix $n \in \mathbb{N}$ and divide $[a,b]$ in $2^n$ parts: $[a,a+\frac{b-a}{2^n}],...,[a+\frac{(2^n-1)(b-a)}{2^n} ,b]$. Call $x_k:=a+\frac{k(b-a)}{2^n}$, and $[x_{k-1},x_k]$ the $k$-th part. By the mean value theorem there exists, for each part $k$-th part, a number $t_k$ such that: $F(x_k)-F(x_{k-1})=f(t_k)(x-x_{k-1})$ Choose such a $t_k$ for every $k$-th part. Therefore: $$\displaystyle F(b)-F(a)=\sum_{k=1}^{2^n}F(x_k)-F(x_{k-1})=\sum_{k=1}^{2^n}f(t_k)(x-x_{k-1})$$ Now, define: $$\displaystyle f_n:=\sum_{k=1}^{2^n}f(t_k)\chi_{[x_{k-1},x_k]}$$ Doing this for every $n \in \mathbb{N}$, we arrive at a sequence $f_n$ of functions which converge pointwise to $f$, as is easily verified (Here we use continuity of $f$). By construction, for every $n \in \mathbb{N}$, we will have: $$\displaystyle F(b)-F(a)=\int_{[a,b]}f_n d\mu$$ Now, note that $f_n \leq M$ for some $M \in \mathbb{R}$, since $f$ is bounded and $f_n$ is defined piecewisely with values of $f$. Therefore, by Lebesgue's Dominated Convergence Theorem, we have: $$\displaystyle F(b)-F(a)=\lim \int_{[a,b]}f_n d\mu= \int_{[a,b]}f d\mu$$ $\blacksquare$ Therefore, I end with two questions: Are there flaws in the proofs above? If not (or if they are easily repaired), why is the opinion I asked so mainstream?","['analysis', 'soft-question', 'integration']"
1276030,Sigma algebra generated by a homeomorphic random variable,"Let $\Omega = [0,1]$ be our probability space with sigma algebra of borel sets on $[0,1]$ and Lebesgue measure on $[0,1]$. Let Y be a random variable such that $Y(\omega) = Y(1-\omega)$ for every $\omega$ in $\Omega$. Assume that $Y_{[0, \frac{1}{2}]}$ is a homeomorphism on $Y([0, \frac{1}{2}])$. What does $\sigma-$algebra generated by $Y$ look like? The information that $Y_{[0, \frac{1}{2}]}$ is a homeomorphism tells us that the image of every borel set in $[0, \frac{1}{2}]$ is a borel set. Is that correct? What does that tell us about $\sigma(Y)?$ I need this in order to prove that for any random variable $X$ and for random variable $Y$ described above we have $$\mathbb{E}(X|Y)(\omega) = \frac{X(\omega) + X(1- \omega)}{2}$$ When I integrate $\mathbb{E}(X|Y)$ over a $\sigma(Y)-$measurable set $B$ I get $$\int_B\mathbb{E}(X|Y) dP = \frac{1}{2}\int_B X(\omega) dP(\omega) + \frac{1}{2}\int_B X(1-\omega) dP(\omega)$$ Now we know that $Y(\omega) = Y(1-\omega)$ but we do not know that about $X$. Anyway, shouldn't $\mathbb{E}(X|Y)$ be a measurable function of $Y$?","['probability-theory', 'conditional-expectation', 'random-variables', 'measure-theory']"
1276072,Degree of a splitting field over $ \mathbb{Q}$,"I'm trying to solve the following problem:
 Let \begin{equation*}
f(x) = x^4 - 2x^2 - 2 \in \mathbb{Q}[x] 
\end{equation*} and $ E $ be its splitting field. What is the degree $ [E: \mathbb{Q}] $? First of all, the roots of this polynomial are $ \pm \sqrt{1 + \sqrt{3}}, \pm \sqrt{1 - \sqrt{3}} $. The first two are real and the other two are complex. It looks as if $ E $ was equal to $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}, \sqrt{1 - \sqrt{3}}) $. The degree of these elements over $ \mathbb{Q} $ is $ 4 $ since $ f(x) $ is irreducible by Eistenstein's criterion. However, I can't tell what the degree of $ \sqrt{1 - \sqrt{3}} $ over $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}) $ is, since I don't know how to check whether $ f $ is irreducible over this field. I'd appreciate any ideas on how to get to that","['abstract-algebra', 'field-theory']"
1276090,"Find an example where the random variables $X_1,X_2,X_3$ are pairwise independent, but not all together.","Find an example where the random variables $X_1,X_2,X_3$ are pairwise independent, but not all together. 
I can't really understand how I am to do so. How is it done? There cannot be any multiplication. Is it a sum? I searched for it but didn't understand how it is interpreted mathematically. I could really use your help.",['probability']
1276114,Continuity of sin x over rationals,"I need a little help on the following question:
 For the function $f\colon[0, 2\pi]\to\mathbb R$ defined below, explain with proof, at which points of $c \in [0,2 \pi]$ $f$ is continuous or discontinuous $$f(x)=\begin{cases} 0 &\text{if $x\in\mathbb Q$}\\
     \sin x&\text{if $x\notin\mathbb  Q$}\end{cases}$$ I've thought that $f$ might be continuous at the points where $\sin x= 0$, i.e., $f(x)$ is continuous at $c = 0, \pi,2\pi$, since any sequence $x_n$ with $\lim_{n\to\infty} x_n=c$, will result in $f(x_n)\to 0$ as $n\to\infty$. $f$ will be discontinuous everywhere else. I'm having trouble in proving this statement. I've been trying to use  the epsilon-delta definition to prove discontinuity but in vain. Any help will be appreciated.","['continuity', 'trigonometry']"
1276119,"Looking for a ""job description"" for Hölder's inequality","Here's an example of what I mean by ""job description"" in the post's title: triangle inequality : to be used, whenever the (unsigned) distances between adjacent points in a sequence $x_0, x_1, x_2, \dots, x_{n>1}$ are given, to derive an upper bound on the (unsigned) distance between the endpoints $x_0$ and $x_n$. 1 Is it possible to give a similarly high-level characterization of the kind of problem that Hölder's inequality is useful for? BTW, the generality of the theorem's statement, which always involves exponents $s, t \in [1, \infty]$ satisfying $s^{-1}+t^{-1} = 1$, greatly exceeds the modest needs of every application area I ever come across, where only the case $s = t = 2$ ever matters.  This may have something to do with my inability to formulate a job description for this inequality. 1 This is the basic idea, though there are several variations of it.  Also, I don't claim that this is, even ""in essence"", the only way to interpret the triangle inequality's utility.  This ""job description"" is only meant to make concrete the difference between knowledge that is somehow ""in active use"", and that, like my present ""knowledge"" of the Hölder's inequality, which is passive at best.","['inequality', 'functional-analysis', 'measure-theory']"
1276136,Exercise in measure theory/probability,"This is an exercise in chapter 2 of Probability with Martingales by David Williams. Question: Let $\mathcal{A}$ be the set of all maps $\alpha : \mathbb{N} \rightarrow \mathbb{N}$ such that $\alpha(1) < \alpha(2) < \dots  $,. For $\alpha \in \mathcal{A}$, let $$F_\alpha = \{ \omega : \frac{\# (k \le n : \omega_{\alpha_{(k)}} = H)}{n} \rightarrow 0.5  \} .$$ Prove that $$\bigcap_{\alpha \in \mathcal{A}} F_\alpha = \emptyset.$$ It is not too clear to me what can be done. Would appreciate some hints.","['probability-theory', 'filtrations', 'measure-theory']"
1276146,Why are equivariant morphisms of $G$-torsors necessarily isomorphisms?,"This was something I read on the Stacks project, but whose proof was omitted. Simply stated, if $f\colon E\to F$ is a $G$-equivariant morphism of $G$-torsors over a scheme $X$, why is $f$ necessarily an isomorphism?","['abstract-algebra', 'algebraic-geometry', 'schemes']"
1276156,Having bit of trouble with simple simplification,"Hi there I am having a stump onto how in my book an equation goes from $$\frac{y}{1-(y/K)}=Ce^{rt}$$ with $$C=\frac{y_{o}}{1-(y_{o}/K)}$$ to solving for y to be $$y= \frac{y_{o}K}{y_{o}+(K-y_{o})e^{-rt}}$$ I know this is a very trivial question for most, but I am just wondering the best way to do this, because when I tried to derive it I kept getting different terms and such and it was hard to get a nice formula like this. Thanks",['algebra-precalculus']
1276169,Proving $f$ is continuous using the $\epsilon-\delta$ definition,"Prove that $f(x,y) = x^2 + xy$ is continuous using the $\epsilon-\delta$ definition, at $(1,-1).$ I encountered this question in a test and I fumbled through it quite shamelessly. Here is my latest attempt. We want to find a $\epsilon > 0$ such that when $ \rho ((x,y),(1,-1)) < \delta$ and $N \in \mathbb{N}$, we have $$|f(x,y) - f(1,-1)|< \epsilon$$ $\forall n \le N$. $$\sqrt{(x-1)^2 + (y+1)^2} < \delta$$
$$|x-1|^2 + |y+1|^2 < \delta^2$$
So,
$$|x-1| < \delta$$ and 
$$|y+1| < \delta$$
Here is where I get reach-y.
\begin{align}
|f(x,y)-f(1,-1)| &\le& |x-1|^2 + 2 |x-1||y+1|\\
&<& \delta^2 + 2 \delta^2\\
\end{align} In the end I take $\epsilon$ as $3\delta^2$ which seems strange to me. Is this as wrong as I think it is? I've never been able to follow this specific method in class.","['calculus', 'real-analysis', 'multivariable-calculus']"
1276179,What is the maximal path of a tree?,Could anyone explain obviously what the maximal path is ? Is it necessary for a tree that has two maximal paths that share no common vertex ?,"['graph-theory', 'discrete-mathematics', 'trees']"
1276203,Notation for replacing a matrix column with a vector,"Let $A$ be an $n\times n$ matrix. Let $v$ be an $n\times 1$ matrix. Is there a notation to signify replacing the $j$-th column of $A$ with $v$? If not, what is the accepted way to denote this?","['notation', 'matrices']"
1276206,Method of generating random numbers that sum to 100 - is this truly random?,"I am writing a computer program that involves generating 4 random numbers, a, b, c, and d, the sum of which should equal 100. Here is the method I first came up with to achieve that goal, in pseudocode: Generate a random number out of 100. (Let's say it generates 16).
Assign this value as the first number, so a = 16.
Take away a from 100, which gives 84.

Generate a random number out of 84. (Let's say it generates 21).
Assign this value as the second number, so b = 21.
Take away b from 84, which gives 63.

Generate a random number out of 63. (Let's say it generates 40).
Assign this value as the third number, so c = 40.
Take away c from 63, which gives 23.

Assign the remainder as the fourth number, so d = 23. However, for some reason I have a funny feeling about this method. Am I truly generating four random numbers that sum to 100 here? Would this be equivalent to me generating four random numbers out of 100 over and over again, and only accepting when the sum is 100? Or am I creating some sort of bias by picking a random number out of 100, and then a random number out of the remainder, and so on? Thanks.","['probability', 'random']"
1276207,Number of moves necessary to solve Rubik's cube by pure chance,"Suppose, random moves are made to solve Rubik's cube. A move consists of
a $90$-degree-rotation of some side. The starting position is also random. What is $E(X)$, where $X$ is the number of moves until the cube is solved ? How many moves must be made, that the probability that the cube is solved, exceeds $99$% ?","['rubiks-cube', 'probability', 'expectation']"
1276227,Density of $C^\infty(\mathbb{R}^n)$ in $C^0(\mathbb{R}^n)$,"This could be well-known, but I cannot come up with a rigorous proof. I want to prove density of $C^\infty(\mathbb{R}^n)$ in the continuous functions $C^0(\mathbb{R}^n)$ in the following sense: given a continuous function $f$, I want to select a smooth function $g$ such that $\sup |f - g|$ is as small as we want. All the tricks I can think of either deal with a compact setting, or continuous functions vanishing at infinity. Thanks!","['real-analysis', 'functional-analysis']"
1276237,Perfect matching problem,"We have a graph $G = (V,E)$. Two players are playing a game in which they are alternately selecting edges of $G$ such that in every moment all the selected edges are forming a simple path (path without cycles). Prove that if $G$ contains a perfect matching, then the first player can win. A player wins when the other player is left with edges that would cause a cycle. I tried with saying that $M$ is a set of edges from perfect matching and then dividing the main problem on two sub problems where $M$ contains an odd or even number of edges, but it lead me nowhere. Please help.","['discrete-mathematics', 'matching-theory', 'combinatorial-game-theory', 'graph-theory', 'discrete-optimization']"
1276238,Find equation of tangent line using differential equation: dy/dx = x(y^1/3),"The expression $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = x\sqrt[3]{y}$ gives the slope at any point on the graph of the function $f(x)$ where $f(2) = 8$. a. Write the equation of the tangent line to $f(x)$ at point $(2,8)$. Since $\frac{\mathrm{d}y}{\mathrm{d}x}$ gives the slope of the tangent line at any point, can I just plug and chug $(2,8)$ into the differential equation, and then use that slope in the point-slope formula? This would give: $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = (2)(\sqrt[3]{8})$ $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 4$ $y - 8 = 4(x - 2)\\
y = 4(x - 2) + 8$ ... could anyone verify that? b. Write an expression for $f(x)$ in terms of $x$. I got: $x = \sqrt{3y^\frac 23 + C}$, where $C$ is a constant of integration. Not quite sure whether this is correct or not. c. What is the domain of $f(x)$? I have no idea how to begin answering this question. Could it be all real numbers, since the domain of the differential equation seems to be all real numbers? d. What is the minimum value of $f(x)$? I think I have to set $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 1$, but then what? Is it $x = 0, y = 0$?","['derivatives', 'calculus', 'ordinary-differential-equations', 'integration']"
1276247,"Bayes' theorem to find $P(A\cap B), \,P(B\mid A),\,P(A\cup B)$","Given, $P(A)=0.4, P(B)=0.5,P(A\mid B)=0.3 $ . Need to find $$P(A\cap B), \,P(B\mid A),\,P(A\cup B).$$ So far I did $$P(A\cap B) = P(A\mid B) P(B) = 0.15.$$ And I have the formula $$P(B\mid A)= \frac{P(A\mid B)P(B)}{P(A\mid B)P(B) + P(A\mid\bar B)P(\bar B)}$$ How do I find $P(A|\bar B)$ ? And what is the formula for $P(A\cup B)$ ? Please help.","['probability', 'discrete-mathematics', 'bayes-theorem']"
1276258,Inverse of $f(x) = 3x + \cos(x)$,"Was hoping someone could help me find the inverse of $f(x) = 3x + \cos(x)$ The steps I took were: $y = 3x + \cos(x)$ $x = 3y + \cos(y)$ $x - 3y = \cos(y)$ $\arccos(x-3y) = y $ But I still have a $y$ in the $\arccos$ , and I don't know how to isolate it.","['inverse', 'calculus', 'functions']"
1276264,Solve for $n$ in $2^n=8$,"So, I was wondering if it is possible to solve for $n$ in $2^n=8$ (or any other question where $n$ is a power) using $9^{th}$ grade math. Please excuse my naïveté if this is extremely stupid/simple. Thanks so much in advance! –– come to think of it: Is it possible at all?","['exponentiation', 'algebra-precalculus', 'functions']"
1276274,Help with Calculus Newton's Method,"Alright So I have kind of an interesting question involving Newton's method and have been at this for quite some time, and have come up with that it is not possible. I would like some input to if this is correct or not. Here is the question: Find an approximate solution, accurate to the nearest $0.0001$, using
  Newton’s method, to the equation $$e^{-x^2}=x$$ Use an initial guess of  and submit your solution with the following
  format – completing each cell until you stop. Any insight is appreciated. I have been using excel to obtain my answer. Thanks","['derivatives', 'calculus', 'integration']"
1276283,Does a matrix with negative eigenvalues have singular values?,What if the eigenvalues of a matrix $A$ are all negative? Does that simply mean there is no singular value for this particular matrix? I can't calculate the conditional number or matrix $2$ -norm for this matrix. Please clarify.,"['definition', 'matrices', 'eigenvalues-eigenvectors', 'singular-values', 'linear-algebra']"
1276304,Not understanding solution to $\large \int_{|z-2|=2} \frac {5z+7}{z^2+2z-3}dz$ computation,Not understanding solution to $\large \int_{|z-2|=2} \frac {5z+7}{z^2+2z-3}dz$ computation. What was  shown in class:  $\large \int_{|z-2|=2} \frac {5z+7}{z^2+2z-3}dz=\large \int_{|z-2|=2} \frac {5z+7}{(z+3)(z-1)}=\cdots= \int_{|z-2|=2} \frac {2}{z+3}dz+\int_{|z-2|=2} \frac {3}{z-1}dz $ And then it is said that $\large \int_{|z-2|=2} \frac {2}{z+3}dz=0$ while $\large \int_{|z-2|=2} \frac {3}{z-1}dz=3 \cdot 2 \cdot \pi \cdot i$. Can you please help me understand the last step? What's the difference bewteen the integrals?,"['complex-analysis', 'integration']"
1276307,Find the Laurent series about $z=i$,"Let $g(z)=\cfrac{3z+1}{(z-i)^3}$. Find the Laurent expansion of $g$ about $z=i$. My idea is first to find the Laurent series of $\cfrac{1}{z-i}$ about $z=i$, and then diferenciate, but I have problem with that. I
want to use
$$\displaystyle\sum_{n=0}^{+\infty}z^n=\cfrac{1}{1-z},\quad \|z\|<1$$
How can I do that with $\cfrac{1}{z-i}$ about $z=i$? Thank you,","['laurent-series', 'complex-analysis']"
1276314,The set of all the rotations of a plane around multiple points contained in it doesn't form a group.,"I'm reading the book ""An introduction to the theory of Groups"" by P.S. Alexandroff and in one of his examples he says that the group of all the rotations of a plane around a given (fixed) point forms a group that is isomorphic to the rotations of a circle over a plane, around it's center.
 This is quite easy to visualize. However, a later exercise asks the reader to prove that the set of rotations of a plane around multiple points (contained in it) doesn't form a group. I couldn't come up with any counter-examples and I'd really appreciate hints and insights about this.",['group-theory']
1276318,Why do the dimensions not line up when I calculate this (directional) derivative using the chain rule?,"an arbitrary, differentiable function $f : \mathbb{R}^n \to \mathbb{R}$ and the function $\gamma: \mathbb{R} \to \mathbb{R}^n$ defined as $\gamma(t) = u + tv$, where $u, v$ are fixed vectors in $\mathbb{R}^n$, I'm trying to find the derivative with respect to $t$ of $(f \circ \gamma)(t)$ at $t = 0$. From the chain rule, I know that $D(f \circ \gamma)(t) = Df(\gamma(t)) \cdot D \gamma(t)$. I'm confused, though, because I thought that $D(f \circ \gamma)(t)$ (the left-hand side) would give me a function from $\mathbb{R}$ to $\mathbb{R}$, but $Df(\gamma(t))$ gives me a function from $\mathbb{R}^n$ to $\mathbb{R}$ and $D \gamma(t) = v$, which is a constant function from $\mathbb{R}$ to $\mathbb{R}^n$, so the right-hand side gives me a function from $\mathbb{R}$ to $\mathbb{R}^n$. It's a simple directional derivative that I've done a million times, and I'm probably missing something easy because it's late, but why don't these dimensions line up? What am I missing?","['analysis', 'calculus', 'derivatives']"
1276335,"Show that if $a, b$ and $m$ are integers such that $m \geq 2$ and $a \equiv b \pmod{m}$, then $\gcd(a, m) = \gcd(b, m)$","Problem 1 (#3.5.32). Show that if $a, b$, and $m$ are integers such that $m \geq 2$ and
$a \equiv b \pmod {m}$, then $\gcd(a, m) = gcd(b, m)$. Proof. 
Let $d = \gcd(a, m)$ Then $d \mid a$ and $d \mid m$
, 
so for some $k,l \in \mathbb{Z}$, $a = kd$ and $m = ld$ 
Since $a \equiv b \pmod {m}$, for some $r \in \mathbb{Z}$, $a − b = rm$. Substituting in, $kd − b = rld$, so $b = d(k − rl)$. Thus $d \mid b$. Since the gcd of $a$ and $m$ divides $b$, it’s a common divisor of $b$ and $m$, so $\gcd(a, m) \leq \gcd(b, m)$. By an analogous argument, the greatest common divisor of $b$ and $m$ is a common divisor of $a$ and $m$, so $\gcd(a, m) \geq gcd(b, m)$. Thus $\gcd(a, m) = gcd(b, m)$  as desired. Can someone explain this proof to me? I was okay with it until the ""substituting in, $kd -b$... "" step. How did they get rid of the mod operator between those steps? The next steps might click after that one, but an explanation on them would be much appreciated (just in case!). Edit: Thank you so much!!","['proof-verification', 'modular-arithmetic', 'discrete-mathematics']"
1276338,How can horizontal asymptote of $\frac{x^{}}{x^{2}+4}$ allow the origin to be plotted?,"So, horizontal asymptote of this rational function $\frac{x^{}}{x^{2}+4}$  is y = 0. But this function's graph goes through the origin which is (0, 0). I don't understand this. If horizontal asymptote doesn't allow any y value to be 0, how can the origin be plotted, which has the y value of 0? Is there an exception for origin? I thought the graph was never supposed to cross the asymptotes.",['algebra-precalculus']
1276343,Why are two planes parallel to the same line not necessarily parallel?,"What is a case in which the statement, ""Two planes parallel to the same line are parallel"" be false?",['geometry']
1276358,All possible total orderings of a finite set are isomorphic. What are some other examples of this phenomenon?,"All possible total orderings of a finite set are isomorphic. I find these kinds of results remarkable. Here's a few more. Assume that $S$ is a finite set. Then: All possible field structures on $S$ are isomorphic (and there exists a field structure on $S$ iff the cardinality of $S$ is $p^n$ for some prime $p$ and positive integer $n$.) All possible Boolean algebra structures on $S$ are isomorphic (and there exists a Boolean algebra structure on $S$ iff the cardinality of $S$ is $2^n$ for some natural number $n$.) All possible cyclic group structures on $S$ are isomorphic. If the cardinality of $S$ is prime, then all possible ways of making $S$ into a group yield isomorphic groups. All possible ways of making $S$ into a cycle (in the sense of graph theory) are isomorphic. Question. Not necessarily assuming that $S$ is a set (e.g. it can be an abelian group, or a ring, or whatever) what are some other
  examples of this phenomenon? We can make things a little more precise using the language of categories. Given a functor $U : \mathbf{S} \leftarrow \mathbf{C}$ and an object $S$ of $\mathbf{S}$, define that: $U^{-1}(S)$ is the full subcategory of $\mathbf{C}$ consisting of precisely those objects whose image under $U$ is $S$. $U^{-1}(\mathrm{id}_S)$ is the wide subcategory of $U^{-1}(S)$ consisting of precisely those morphisms of $U^{-1}(S)$ whose image under $U$ is $\mathrm{id}_S$. We're interested in results of the form: the category $U^{-1}(\mathrm{id}_S)$ has multiple non-isomorphic objects; nonetheless, all objects of $U^{-1}(S)$ are isomorphic.","['graph-theory', 'big-list', 'abstract-algebra', 'combinatorics', 'examples-counterexamples']"
1276382,j-invariants for an elliptic curve over the Artin ring $k[t]/(t^n)$.,"Let $k$ be an algebraically closed field, let $\lambda \in k - \{0,1\}$ and let $C = k[t]/(t^n)$. Hartshorne's ""Deformation Theory"" chapter 1 exercise 4.9(c) asserts that the family $$y^2 = x(x-1)(x-(\lambda +t))$$
is a nontrivial family over $C$. The hint given is ""the computation of $j$-invariant can be carried out over the ring $C$."" After a bit of searching online, it looks like the moduli space of elliptic curves over a ring becomes much more complicated than over a field (as in beyond the knowledge one acquires in a first course of algebraic geometry, which is what I currently have roughly). My hope is that over $k[t]/(t^n)$, the problem would be only slightly more complicated than over $k$. But I have no idea where to even begin. If you could provide a reference, or a more detailed ""hint"" on how to define the $j$-invariant and use it to classify elliptic curves over $C$, that would be greatly appreciated.",['algebraic-geometry']
1276390,Curvature tensors and bivectors,"At the beginning of the paper ""The curvature of 4-dimensional Einstein spaces"", by Singer and Thorpe, the authors define the space $\mathcal{R}$ of curvature tensors of the vector space $V$ as the set of symmetric bilinear transformations on the space of bivectors $\Lambda^{2}(V).$ Few lines after this, they define the ''Bianchi map'' $b$ as an operator $b : \mathcal{R} \rightarrow \mathcal{R}$ in the following way:
$$[b(R)](u_{1},u_{2})u_{3}=\sum_{\sigma \in S_{n}} R(u_{\sigma(1)},u_{\sigma(2)})u_{\sigma(3)},$$
but they do not explain the notation. If $R$ is a transformation
$$R: \Lambda^{2}(V) \rightarrow \Lambda^{2}(V),$$
and $u_{1},u_{2}$ and $u_{3}$ are, I presume,vectors of $V,$ what is the meaning of $R(u_{\sigma(1)},u_{\sigma(2)})u_{\sigma(3)}$? Also, they define immediately after this the ''Ricci contraction'' $r$ as an operator from $\mathcal{R}$ to the space of symmetric linear transformations of $V$ by means of:
$$\langle r(R)(v),w \rangle=\mathrm{Tr}\{u \rightarrow R(v,u)w  \}.$$ I see that this strongly resembles to the Ricci tensor that one usually meets in riemannian geometry, but I have a similar notational problem with this last definition. If someone could possible clarify the notation and explain a little this way to look at the curvature tensor (or give me some references) I would be really grateful.","['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
1276404,How does $\ln(x)$ blow up at $0$ and $\infty$.,"In general: How do I figure out how fast a function blows up at a certain point or infinity? How fast does $\ln x$ blow up at $0$? Does it blow up as fast as $1/x$, $1/x^2$, or maybe faster than any $1/x^n$? How do I answer such a question about other types of functions? How do I answer such a question for infinity? I know that $\ln x$ blows up very slowly at infinity, slower than any $x^n, n>0$. How do I justify this information? Edit: After some thinking I realized that lnx is e^x flipped about y=x. This means lnx is asymptotic to the -y axis as e^-x is asymptotic to +x axis. This is an intuitive justification of lnx blowing up slower than any x^-n, n>0","['infinity', 'limits', 'logarithms']"
1276419,What does actually probability mean?,"I am a beginner in quantum information. Reading about it has made me question the definition of probability. If the probability of an outcome $m$ in an experiment is $p(m)$ then it means that if I perform the experiment $n$ times ( $n \to \infty$ ) then $p(m)*n$ times I will get the outcome as $m$ . But probability of an outcome by intuition also means how certain we are that we
will get that outcome as a result when we perform the experiment. But according to the first definition  probability of an outcome makes sense when we perform the same experiment a very large number of times. Whereas according to the second definition we are just performing the experiment once and rather express probability as a measure of certainty. sorry for asking  a trivial question like this.","['probability-theory', 'probability']"
1276422,Show that $\limsup$ of $\sin n$ is 1 [duplicate],This question already has answers here : Showing $\sup \{ \sin n \mid n\in \mathbb N \} =1$ [closed] (3 answers) Closed 6 years ago . I want to prove that the $\limsup\limits_{n\rightarrow \infty} \sin n=1$. I know that $1$ is an upper bound for $\sin n$ but I cannot find a subsequence of $\sin n$ that converges to $1$. Can somebody help me construct such a subsequence?,"['analysis', 'numerical-methods', 'real-analysis']"
1276430,Expectation of CDF of normal random variable.,"Let $\Phi$ be the CDF of the standard normal distribution $N(0,1)$.
Then can we analytically compute $E(\Phi(y-c))$, where $y$ follows $N(0,1)$ and $c>0$? I need this for my research in social science. I know it is 1/2 if $c=0$, but I would like to obtain it for $c>0$.","['statistics', 'integration']"
1276449,"$\cos^2(\theta)-\sin^2(\theta)=1+\sin(\theta)$ over the interval $(0,2\pi)$ [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question $\cos^2(\theta)-\sin^2(\theta)=1+\sin(\theta)$ over the interval $0<\theta<2\pi$ Find the trigonometric identity. Apologize for the confusion, first time using this resource didnt read the instructions. i have tried manipulating the equation by substituting x^2 and y^2 in for the cos^2 and sin^2 and subtracting and adding the one but i could not find out what identities to use to make both side equal. Sorry again for the mistake.",['trigonometry']
1276454,Measure theory problem to show a set contains positive interval [duplicate],"This question already has answers here : Steinhaus theorem (sums version) (2 answers) Closed 9 years ago . Let $E\subset \mathbb{R}$ be a Lebesgue measurable subset of reals such that $\mu(E)>0.$ Consider the set $E+E=\{x+y: x,y\in E\},$ prove that $E+E$ contains an interval of length greater than $0$. Is this problem even true? Let's say the set $E$ is our set of irrational numbers, then $E+E$ doesn't contain positive length interval. If this is indeed true, how can we go about proving this statement?","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1276455,Find the smallest $n$ such that $\mathbb Z_2\times \mathbb Z_2\times \mathbb Z_2$ is isomorphic to a subgroup of $S_n$,"Let us consider the group $A=\mathbb Z_2\times \mathbb Z_2\times \mathbb Z_2$. Find the smallest positive integer $n$ such that $A$ is isomorphic to a subgroup of $S_n$. My thought. Since $o(A)=8$ then $n\geq 4$. If $n=4$, then $8$ will divide $24$, but how to make sure whether it has an abelian subgroup of order $8$ or not since $A$ is abelian. Any help.","['abelian-groups', 'abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
1276470,Proving $\ell^p$ is complete,"Let be $1\leq p\in\mathbb{R}$, denote:
  $$\ell^p(\mathbb {R})=\left\{(x_n)\subset \mathbb{R}: (x_n) \mbox{ is a sequence with } \displaystyle\sum_{n=1}^{\infty}|x_n|^p<\infty \right\}$$ 
  Prove that: The function: $d_p:\ell^p(\mathbb{R})\times\ell^p(\mathbb{R})\to \mathbb{R}$ is a metric for $\ell^p(\mathbb{R})$  where $d_p(x_n,y_n)= \left| \displaystyle\sum_{n=1}^\infty |x_n-y_n|^p \right|^\frac{1}{p}$ (Only triangular inequality, I work in $\mathbb{R}$, should I assume Minkowski inequality and its done?) $\ell^p(\mathbb{R})$ is a complete metric space. it is right? I mean $p\in\mathbb{R}$? I've never work with $\ell^p$ spaces, this is a question from introduction to topology.","['metric-spaces', 'functional-analysis']"
1276480,Cardinality of order topology?,"Just out of interest: The cardinality of the Euclidean topology on the real line is $c$. In general, if $X$ is totally ordered of cardinality $\alpha$, the order topology on $X$ must have cardinality $\geq\alpha$. When is it precisely $\alpha$?","['order-topology', 'infinitary-combinatorics', 'general-topology', 'cardinals']"
1276499,Algebraically closed fields of characteristic $0$ and $\mathbb{C}$,"Let $k$ be an algebraically closed field of characteristic $0$ . Then I have heard that if $k$ has cardinality no greater than that of $\mathbb{C}$ , then there is an embedding $k\hookrightarrow\mathbb{C}$ . Firstly, does anyone have a reference of this statement? Secondly, suppose $k$ is larger than $\mathbb{C}$ (cardinality-wise). Must there exist an embedding $\mathbb{C}\hookrightarrow k$ ? Lastly, suppose again $k$ is larger than $\mathbb{C}$ , and let $x\in k$ . Must there exist an embedding $\mathbb{C}\hookrightarrow k$ with $x$ in its image? Does anyone have any references for these facts?","['abstract-algebra', 'algebraic-geometry', 'field-theory']"
1276506,Genus of $k(T)$?,"Let $F$ be a function field in one variable with total constant field $k$, let $X$ be the set of all places $F$, and let $S$ be a nonempty finite subset of $X$. Then the genus of $F$ is equal to the dimension over $k$ of the cokernel of $O_S \to \bigoplus_{v \in S} F_v/O_v$. My question is, what is the genus of $k(T)$?","['field-theory', 'number-theory', 'abstract-algebra', 'algebraic-geometry', 'algebraic-number-theory']"
1276515,Analysis Constructing a Sequence,"I'm looking for a sequence of functions that is continuous and absolutely integrable, but pointwise divergent for every $z$ $\in [0,1]$. In other words, $ \int_0^1 |f_n(z)| dz \rightarrow 0$ as $n \rightarrow \infty$, but $(f_n(z))_n$ pointwise diverges for every $z$ $\in [0,1]$. I'm having no luck coming up with an example, and would appreciate any sort of insight on how to go about constructing such a sequence.",['analysis']
1276537,Measure of intersection of set and its translation,"I came across an old qualifying exam question: Let $A\subset [0,1)$ be a Lebesgue measurable subset of unit intreval such that $0<\mu(A)<1$. For every $x\in [0,1)$ let $A+x=\{x+y$ mod 1$:y\in A\}$. Prove that there exists $x_0=x_0(A)\in[0,1)$ such that $\mu(A\cap(A+x_0))<\mu(A)$ Intuitively, it seems that if $A$ is a measurable interval then there exist an interval $I$ such that they overlap by more than half. Moreover the intersection $(A\cap(A+x_0))$ would need less intervals to ""cover up"" than $A$. Hence we have the inequality. But I am having a hard time making this rigorous.","['analysis', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
1276559,Cholesky of matrix plus identity,I have a positive definite matrix $A$ ( $n \times n$ dimension) for which I have the Cholesky decomposition $A=LL^{'}$ . I want to use this to compute a) The Cholesky decomposition of $A+c^2\times I $ where $c$ is a constant and $I$ is the identity matrix b) The Cholesky decomposition of $A+BB^{'}$ where $B$ is a $n \times n$ sparse matrix with each row having at most $k$ elements for some fixed $k << n$ . Is there any analytical/ computational method/ R-package that can use the already available Cholesky decomposition of $A$ and perform (a) and (b) in a computationally scalable way i.e. ( $O(n)$ complexity). Note that (a) is a special case of (b) with $B=cI$ . Any references will be appreciated. Thanks,"['cholesky-decomposition', 'computational-complexity', 'matrix-decomposition', 'matrices']"
1276590,"(combinatorics) prove that on average, n-permutations have Hn cycles without mathematical induction.","Prove that on average, n-permutations have $H_n$  cycles, where $H_n=1+1/2+1/3+...+1/n$  without mathematical induction. I think that on average, the number of cycles of length i (1≤i≤n) should be 1/i to prove but, I don't know how to show this. Some books proved this using an indicator function. Do I have to use that?","['harmonic-numbers', 'combinatorics', 'permutations']"
1276599,Solving an exponential equation involving e: $e^x-e^{-x}=\frac{3}{2}$,"In a previous exam, my professor had the question \begin{equation*}
e^x-e^{-x}=\frac{3}{2}.
\end{equation*} I attempted to take the natural log of both side to solve it, but evidently that was incorrect... how does one start to go about solving this type of problem? Any help or advice would be greatly appreciated. Thanks!","['quadratics', 'algebra-precalculus', 'exponential-function']"
1276630,Top degree de Rham cohomology determines an orientation,"Let $M^n$ be a smooth, compact, orientable, connected manifold. We know then that $H^n_{dR}(M^n)\simeq \mathbb{R}$ by the map $[\omega]\mapsto \int_{M^n} \omega$. I was wondering if, given an orientation on $H^n_{dR}(M^n)$, there was a way to get an orientation on $M^n$? Essentially, given a basis element $[\omega]\in H^n_{dR}(M^n)$ (so essentially a nonzero element of the cohomology), are we able to find a representative of this class which is an orientation form (everywhere nonvanishing)? Any ideas? Edit: The basic idea I had was a proof by contradiction: if for every $p\in M$, there is a representative of $[\omega]$ which vanishes at $p$. I would want to show that $\int_{M^n}\omega=0$. To do this, we would want to choose, in every coordinate neighborhood, a clever representative of $[\omega]$ which is zero on that neighborhood and sum up. Here's where I'm stuck. Edit 2: Bott and Tu may have a sort of proof involving Poincare Duality (on pg. 87) which is a bit above my level. See also theorem 3 here (the reference is to Bott and Tu).","['homology-cohomology', 'differential-geometry', 'smooth-manifolds']"
1276639,"Explaining problem in Gadea's ""Analysis and Algebra on Differentiable Manifolds""","I have a lot of trouble trying to explain to myself what the author did in problem 1.102 (the answer is in the link): Let $TM$ be the tangent bundle over a differentiable manifold $M$. Let $\varphi: \mathbb R\times TM \to TM$ defined by $\varphi(t, X)=e^tX$. (i) Prove that $\varphi$ is a $1$-parameter group of transformations of $TM$. (ii) Calculate the vector field $Y$ on $TM$ associated to $\varphi$. (iii) Prove that $Y$ is invariant under $\varphi$. I'm interested in the first point since maybe the rest continues from in. The definition of $1$-parameter group (or flow) is given for maps that go from $M\times \mathbb R$ to $M$, where $M$ is a smooth manifold. Althought we know that the tangent bundle $TM$ gives a manifold structure to tangent vectors, applying straight the definition of flow doesn't seem like the way  the author took. $(1)$ I don't uderstand why does he prove that $\varphi_t \circ \varphi_s=\varphi_{t+s}$, I saw that he used that too in the problem before. $(2)$ Later when he is defining the chart in $TM$, I don't quite get the definition of $\Psi$. I thought the charts in $TM$ where given like this: if you take a chart of $M$, say $(U,\phi)$ then it induces the chart of the tangent bundle  like $(\pi^{-1}(U),\tilde \phi)$, with $\tilde\phi(X_p)=(\phi(p),\omega)$ and $\omega\in T_pM$. I don't know if my diagram is correct, but that's what I understand, and I don't see how did he got the so called $\Psi$ and $\tau$.","['smooth-manifolds', 'differential-geometry', 'manifolds']"
1276643,What is the next prime number?,"Given an integer \begin{equation*}
N~\text{such that}~N\leq 10^{18}, 
\end{equation*} what is the next prime number after this number? What approach should I use to solve this problem? (Problem link: http://www.spoj.com/problems/NAJPLNP/cstart=10 )","['prime-numbers', 'discrete-mathematics']"
1276646,limit as $x$ approaches infinity of $\frac{1}{x}$,"How can I show $\lim_{x \to \infty} \frac{1}{x} = 0$ using epsilon delta proof. Its pretty obvious that the limit is zero, but I am still new at epsilon proofs.","['infinity', 'limits', 'epsilon-delta']"
1276656,"Does there exist a continuous onto function $f:[0,1] \to (0,1)$?","If there is, what's an example. If not, how do I prove none exists?","['real-analysis', 'functions']"
1276665,If $A$ is an antisymmetric matrix then $A+I$ is invertible [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $A$ be an antisymmetric matrix with real entries. How can I show that $A+I$ is invertible?","['linear-algebra', 'matrices']"
1276690,"$y^5 =(x+2)^4+(e^x)(ln y)−15$ finding $\frac{dy}{dx}$ at $(0,1)$","Unsure what to do regarding the $y^5$. 
Should I convert it to a $y$= function and take the $5$ root of the other side. Then differentiate? Any help would be great thanks.","['implicit-differentiation', 'calculus', 'derivatives']"
1276701,Calculating the shortest route around cylinder,"If I have the following situation, what would the path look like? Where would the path go and how would I calculate it? Cylinder with diameter $10\,\hbox{cm}$ and height $5\,\hbox{cm}$.
Use the shortest route from a point on the top edge ($A$) to a point on the 
bottom edge ($B$) diametrically opposite $A$. I understand the following might help but how? $\mathbf{r}(t) = a\cos(t)\mathbf{i}+ a\sin(t)\mathbf{j}+ ct\mathbf{k}$. With the resultant formulae as follows:
\begin{cases}
x = r\cos t		\\
y = r \sin t\\
z = \frac{h\cdot t}{2\cdot \pi\cdot n},&         (0 ≤ z ≤ h)
\end{cases} Where: $h$ = height $r$ = radius $n$ = the number of complete revolutions Note: I know 2 methods of calculating this, but I don't know how to provide a value (or an approximation). Could a value and the process be provided?","['euclidean-geometry', 'geometry', 'vectors']"
1276709,Coincidence points on compact Hausdorff spaces.,"I am really stuck on this exercise in my course notes. Let $X$ and $Y$ be compact Hausdorff spaces and $f, g : X \to Y$ be continuous functions. Show that: There is an $x \in X$ with $f(x) = g(x)$ if and only if for each open cover $C$ of $Y$, there is $x \in X$ and a $U \in C$ with $f(x), g(x) \in U$. Proving the forwards direction is very easy but the reverse is not so easy. I have tried to prove the contrapositive. If $f(x) \neq g(x)$ for all $x \in X$, then there exists an open cover $C$ of $Y$ such that for all $x \in X$ and $U \in C$, $f(x) \notin U$ or $g(x) \notin U$. If $f(x) \neq g(x)$ then we could use that $Y$ is Hausdorff so for each $x\in X$ there exists open $U_{x}, V_{x}\subset X$ with $U_{x}\cap V_{x}=\emptyset$ and $f(x)\in U_{x}$, $g(x)\in V_x$. This would give an open cover of $f(X)$ and another open cover of $g(X)$. After this I have no ideas. Any ideas of where I could go from here? (or where would be a better place to start?)","['general-topology', 'compactness']"
1276712,"How do I find $\int_{0}^{\infty} \frac{\sin^4 x}{x^2}\,dx$?","I need help evaluating the following integral
$$\int_{0}^{\infty} \frac{\sin^4 x}{x^2}\,dx$$
which should probably be equal to $\frac{\pi}{4}$ Using some trigonometric manipulations I got $\frac{3}{8} - \frac{\cos{2x}}{2} + \frac{\cos{4x}}{8}$ which using integration by parts doesn't lead me to anything pretty. Update : Not sure if I should post this as a separate question but getting explanation why $\int_{0}^{\infty} \frac{\sin{ax}}{x} = \frac{\pi}{2}$ for a positive integer $a$ could help me solve this question.","['calculus', 'integration']"
1276760,Homomorphisms Groups Kernel,Given G: group  of units in Z mod 14 under multiplication.  A function sends the integers under addition to G. $f(n)$ = $[3]^n$ I am just checking whether I am correct in stating that the kernel is simply the order which would be 6 and this would represented as  <6>.,"['group-homomorphism', 'group-theory', 'functions']"
1276768,Application of Egorov's theorem,"Problem Let $(E,\Sigma, \mu)$ be a $\sigma$-finite measurable space (i.e., $E=\bigcup_{k \in \mathbb N} A_k$ where $\mu(A_k) < \infty$ for each $k$). Let $(f_n)_{n \geq 1},f:E \to \overline{R}$ be a sequence of measurable, a.e. finite functions such that $f_n \to f$ a.e. on $E$. Show that there exists a sequence $(E_i)_{i \geq 1}$ of measurable sets on $E$ such that $$\mu(E \setminus \bigcup_{i \geq 1} E_i)=0, f_n \rightrightarrows f \space \text{on} \space E_i \space \text{for each i}$$ I've tried to show this result but I got stuck at one part, I'll write what I could do: In each $A_k$ I can apply Egorov's theorem, so for each $j \in \mathbb N$, there exists $B_{k,j}$ measurable subset of $A_k$ with $\mu(A_k \setminus B_{k,j})<\dfrac{1}{j}$ and $f_n \rightrightarrows f$ on $B_{k,j}$. Then $(B_{k,j})_{j}$ is a sequence of measurable subsets of $A_k$ with $$\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})<\mu(A_k\setminus B_{k,j})<\dfrac{1}{j} \space \text{for each} j \in \mathbb N$$ But then $\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})=0$ and $f_n$ converges uniformly to $f$ on each $B_{k,j}$. I defined $E_k=\bigcup_{j \geq 1} B_k,j$, then $$\mu(E \setminus \bigcup_{k \geq 1} E_k) \leq \mu(\bigcup_{k \geq 1} (A_k \setminus E_k)) \leq \sum_{k \geq 1} \mu(A_k \setminus E_k)=0$$ The problem here is that I cannot affirm $f_n \rightrightarrows f$ on $E_k$. Any suggestions to complete the solution would be greatly appreciated.","['real-analysis', 'measure-theory']"
1276789,"How many 1's can a regular 0,1-matrix contain?","A matrix of order $n$ has all of its entries in $\{0,1\}$. What is the maximum number of $1$ in the matrix for which the matrix is non singular.","['linear-algebra', 'matrices']"
1276809,Lebesgue measure. Find $\mu(A)$,"If $I_0 = [a,b]$ and $b>a$, let $A \subset I_0$ be a measurable set such that
$$\forall p,q \in \mathbb{Q} , p \neq q \rightarrow (\{p\}+A)\cap(\{q\}+A) = \emptyset$$ Then what is $\mu(A)$? Intuitively $\emptyset$ should imply $0$(?) Please help!","['lebesgue-measure', 'measure-theory']"
1276816,The probability of maximum of two independent Poisson-distributed variables,"I have two Poisson distributions with parameters $\lambda_1$ and $\lambda_2$ and two independent variables $A$ and $B$ from these two distributions. I know that $$\begin{equation*}
\mathsf P(\min(A,B)>K)=\mathsf P(A>K) \ast \mathsf P(B>K)  
\end{equation*}$$ I'm just wondering what $\mathsf P(\max(A,B)>K)$ is. Thanks.","['probability', 'poisson-distribution']"
1276819,What should be number of integral values of n?,"If the period of the function $\cos(nx)\sin(5x/n)$ is $3\pi$ then what should be number of integral values of $n$ ? My approach :
I tried like period of $\cos(nx)$ is $2\pi$/n and $\sin(5x/n)$ is $2\pi n/5$ 
So the period should be L.C.M of $2\pi$/n and $2\pi n/5$.Which is equal to $2\pi n/\gcd(n,5)$. However after this I'm not being able to proceed. Help please!",['functions']
1276820,What is the significance of Gaitsgory and Lurie's proof of Weil's conjecture for function fields?,Can anyone place this result in context (including historical context) and explain its significance?  Is this considered to be a major result?,['algebraic-geometry']
1276828,Finding the intersection of a line and hyperplane,"Taking the hyperplane
P = $\{ $x$ :3x^1-3x^2-3x^3-x^4=0\}$
and the line $t(e_1-e_2)+(1-t)e_4$ I do not know how to solve for t, where t is the intersection of the two. This is problem 2b from Fleming's Functions of Several Variables. I am self-studying. There isn't any point within the book that prepares one for this problem. The method I know for solving this type of problem isn't useful for this version see Lang's (Intro)/Linear Algebra. e.g., (X-Q) $\cdot$ N = O
where N is the normal and Q is some point in the plane and we have the parametric line X=P+tA for some point on the line P, and the line is in the direction of the vector A, for all t. When trying to use this method of solution I run into the issue of the parametric line and its original counterpart and failure during conversion. Could you please offer hints as to where to start because I do not think I am doing this the most effective way.","['linear-algebra', 'multivariable-calculus']"
1276843,Showing that $Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4})$,"Let $Q(x)$ denote the number of square-free numbers not exceeding $x$. How can we show that $Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4})$, i.e. $$\liminf_{x\to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} < 0 \qquad\text{and}\qquad \limsup_{x \to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} > 0\,?$$ The computation \begin{align}
Q(x) &= \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lfloor \frac{x}{k^2}\biggr\rfloor \\
&= \sum_{k \leqslant \sqrt{x}} \mu(k)\,\frac{x}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace \\
&= \frac{6x}{\pi} - x\sum_{k > \sqrt{x}} \frac{\mu(k)}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace
\end{align} yields $Q(x) - \frac{6x}{\pi^2} = O(\sqrt{x})$ easily, but it is not at all obvious if we can obtain a lower bound on the magnitude of $Q(x) - \frac{6x}{\pi^2}$ from this. How does one go about proving these?","['complex-analysis', 'analytic-number-theory']"
1276865,Name of an element of an element of a set,"Is there some way of notating that an object can be related to a set through element relations, even if it is not an element of the set? e.g. $a\not\in\{\{a,b\},\{c,d\}\}$, but $a\in\{a,b\}\in\{\{a,b\},\{c,d\}\}$.",['elementary-set-theory']
1276866,Probability of picking at least one of each of $x$ items in $y$ tries from possible $z$ options,"As stated in title, there are $z$ things to pick from, and you get $y$ picks, with replacement. What's the probability of picking such that you get at least one of each of $x$ things? Assume $x \leq y$ and $x \leq z$, and order doesn't matter. It seems like it should just be an extension of stars and stripes or balls in boxes but I'm having trouble getting it right. Stars and stripes seems like it would be choosing types for $y-x$ things, since $x$ are set, which means distributing $z-1$ bars in those $y-x$ things for $\binom{y-x+z-1}{z-1}$ for an overall probability of that of $z^y$, which I reduced to $\frac{(y-x+z-1)!}{(z-1)! (y-x)! z^y}$. However as $y$ goes to infinity that seems to go to $\frac{y^z}{z^y}$, when intuitively it should go to 1. For boxes I'm not sure of how to represent ""at least 1 of each,"" and the inverse is not really that simple either. Thanks!",['combinatorics']
1276895,"Precise meaning of ""extension""?","Halmos's Naive Set Theory explains the ""extensionality"" in ""axiom of extensionality"" as: Every set is determined by its extension. and that's it. What is a set's extension, then? Intuitively it seems to me that an (or maybe ""the"", who knows?) extension of $X$ is a set that contains all of $X$'s elements, and possibly some other ones too. Am I right? If not, could you please explain what an extension of a set is?",['elementary-set-theory']
1276914,Does the wedge product of bundle-valued forms induce a universal object?,"Given a smooth manifold $M$ and a vector bundle $E$ over $M$, the $C^\infty(M)$-module of $E$-valued $p$-forms on $M$ is defined to be
$$\Omega^p(M; E) := \Gamma_M\left( \bigwedge^p T^*M \otimes E \right).$$ The wedge product of a $E_1$-valued $p$-form $\omega_1 \in \Omega^p(M; E_1)$ with a $E_2$-valued $q$-form $\omega_2 \in \Omega^q(M;E_2)$ is defined in R. W. Sharpe's Cartan geometry text to be the $E_1 \otimes E_2$-valued $p+q$-form $\omega_1 \wedge \omega_2 \in \Omega^{p+q}(M; E_1 \otimes E_2)$ given by
$$(\omega_1 \wedge \omega_2) (v_1, \ldots v_{p+q})=\sum_{\text{$(p,q)$ shuffles $\sigma$}} (-1)^{\text{sgn}(\sigma)} \omega_1(v_{\sigma(1)}, \ldots, v_{\sigma(p)})\otimes \omega_2(v_{\sigma(p+1)}, \ldots, v_{\sigma(p+q)}).$$ I am wondering if this multiplication induces a universal object of some sort? For example, the wedge product of $\mathbb{R}$-valued forms gives you the exterior algebra $\Omega^{\bullet}(M)$, which is the free graded-commutative algebra on $\Omega^1(M)$. This is more generally true for the exterior algebra $\bigwedge^\bullet V$ for any module $V$ over a commutative ring. Likewise, the tensor algebra $\bigotimes^\bullet V$ is the free algebra on $V$, and the symmetric algebra $\bigodot^\bullet V$ is the free commutative algebra on $V$. Does the wedge product of bundle-valued forms induce a universal object of some sort as well? Also, I would really appreciate a reference on bundle-valued forms, especially one from a categorical viewpoint. I haven't been able to find a comprehensive treatment yet.","['differential-forms', 'exterior-algebra', 'abstract-algebra', 'differential-geometry', 'category-theory']"
1276921,"Given a fixed path connected topological space $X$, is ""$Y$ is homotopy equivalent with $X$"" always strictly weaker than ""$Y \approx X$""?","$\simeq$ will denote homotopy equivalence, and $\approx$ will denote homeomorphism. Given many spaces, it is easy to show this property, for example using the fact that $X \times I \simeq X$, where $I$ denotes the unit interval $[0,1]$.  But it is not as clear (in fact I'm not sure it's true) that homotopy equivalence with a given space is strictly weaker than homeomorphism.  For example $I^{\mathbb{Z}}$ taken as a product is homeomorphic to $I^{\mathbb{Z}} \times I$, so the method I gave doesn't work in general.  Of course, $I^{\mathbb{Z}}$ is also homotopy equivalent to a point, so this is far from a counterexample. Any kind of proof, proof sketch, or reference would be appreciated.  Thank you.",['general-topology']
1276954,How to divide a pizza between friends equally without using centre,"Here's a really fun question a friend told me abut. He claims to know the correct answer, and told me the answer, but left proving the answer as an exercise to me. Now, It's been ages since he asked me the question, and he himself seems to have forgotten the solution, so here's the question for the community(I tried searching, but useless): Two friends go to a pizza shop and purchase one. They decide to make 8 slices of the pizza. Then the waiter comes and challenges them to cut the pizza such that the point where all cutting lines meet is NOT the centre of the pizza, but another point. The friends are jolts of each other and think that one of them will get a bigger area f pizza is this method is used. To satisfy both of them, the waiter himself cuts it in such a way that both get 4 slices, and there cumulative area is equal. How did the waiter do this ? So, basically, you have to draw chords across the circle such that all of them intersect at a certain point(thats not the center) and then choose 4 pieces equal in area to the other 4. My friend claims that if we divide the circle as in the image below: IN this way, or basically any way, the following property holds: ar(1) + ar(3) + ar(5) + ar(7) = ar(2) + ar(4) + ar(6) + ar(8) Hence, the two friends can distribute the pizza amongst themselves.
But now, he doesn't remember how to prove this mathematically. He does say that the proof is very easy and was childish and obvious once you've read it, but he is unable to trace the book this was part of now... So, I turn to you, friends, help me to solve this. Thanks in advance, Nib","['geometry', 'circles']"
1276957,Why does my solutions manual take away or add 180 when finding $\theta$?,"These are the provided notes: These are the provided questions: I do not understand when I should subtract, add or leave the answer as is (The notes do not make sense to me very much). I do not, clearly, have an intuitive understanding of this. I hope someone can please please please show me thank you :)",['algebra-precalculus']
