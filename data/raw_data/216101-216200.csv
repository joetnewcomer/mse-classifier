question_id,title,body,tags
4390550,How is this differential equation solved?,"I have a differential equation as follows: $$ y \cdot y'' +(y')^2 +1=0.$$ I'm interested in how to solve it. So far I have found a few solutions like $y=\sqrt{r^2-(x-k)^2}$ and $y=x+k.$ [In these, $r$ and $k$ are real constants.] It came up while looking at a property of surface area of revolutions which held for spheres and certain cones. I am wondering if a general soution can be found, and in particular whether only circles and certain lines are solutions. Note: As user RadialArmSaw noted, $y=x+k$ is not a solution.",['ordinary-differential-equations']
4390557,derivative of norm of two matrix.,"I am a bit rusty on math. I need to take derivate of this form: $$\frac{d||AW||_2^2}{dW}$$ where $A, W$ are matrices. I recall that $|AW|^2 = (AW)(AW)^T$ . However, I don't know how to solve the derivative in matrix form. Any help? Attempt: Is the solution: $2(W^TWA)$ ?","['matrices', 'derivatives', 'linear-algebra']"
4390675,The pullback orientation on $M$ induced by a local diffeomorphism $F:M\to N$,"I'd like to understand the proof of the following proposition, cited from Lee's Introduction to Smooth Manifolds . Proposition 15.15 (The Pullback Orientation). Suppose $M$ and $N$ are smooth manifolds with or without boundary. If $F:M\to N$ is a local diffeomorphism and $N$ is oriented, then $M$ has a unique orientation, called the pullback orientation induced by $F$ , such that $F$ is orientation-preserving. Proof. For each $p\in M$ , there is a unique orientation on $T_p M$ that makes the isomorphism $dF_p:T_p M\to T_{F(p)}N$ orientation-preserving. This defines a pointwise orientation on $M$ ... Why does there exist a unique orientation on $T_p M$ that makes the isomorphism $dF_p:T_p M\to T_{F(p)}N$ orientation-preserving? Since $dF_p$ is an isomorphism, it must carry a basis for $T_p M$ to a basis for $T_{F(p)}N$ . But, this is not enough. To show $dF_p$ is orientation-preserving, one must equip $T_p M$ with a choice of orientations (keep in mind that $T_p M$ is not oriented initially) and prove that $dF_p$ carries a positively-oriented basis to a positively-oriented basis, where I have been stuck. I think the question can be taken care of properly by appealing to linear algebra, but somehow I don't know how to start it. Can anyone give me a piece of advice? If possible, please do not refer to any differential forms. Thank you. Note. Two bases for a vector space are said to be consistently oriented if the change-of-coordinate matrix between them has positive determinant. Being consistently oriented characterizes an equivalence relation on bases, and we define an orientation on a vector space to be an equivalence class of bases.","['smooth-manifolds', 'differential-geometry']"
4390698,Vanishing Cohomology of Cubic Surface,"I recently read somewhere that for a cubic surface $S$ in $\mathbb{P}^3$ , the classes $[\Delta] - [\Delta']$ generate the vanishing cohomology $H^2(S,\mathbb{Q})_{van}$ , taken over all pairs of lines $\Delta$ and $\Delta'$ on $S$ . Recall that $H^2(S_0,\mathbb{Q})_{van}= \ker (j_*:H^{n-1}(S_0,\mathbb{Q}) \rightarrow H^{n+1}(S,\mathbb{Q})$ , where $S_0 \xrightarrow{j} S$ is a smooth hyperplane section. Note that the vanishing cohomology is generated by the vanishing cycles. Could someone please explain this to me? I'm very new to intersection theory and would like to understand this. I should add some context. This is part of an exercise in Chapter 3 of Voisin's Hodge Theory and Complex Algebraic Geometry Volume II. The hint recommends the use of Theorem 3.27. This chapter also provides all of the relevant notation. Aside from doing it this way, I would be interested in seeing any other way we can compute the vanishing cycles.","['complex-geometry', 'algebraic-geometry', 'intersection-theory']"
4390706,Kähler manifold which is not a torus or a curve and has every Hodge number nonzero,"Basically title. What is an example of a compact Kähler manifold $X$ satisfying (1) $X$ is not isomorphic to a compact complex torus and (2) $h^{p,q}(X) \neq 0$ for every Hodge number of $X$ (3) the dimension of $X$ is $\ge 2$ ? For a compact complex torus of dimension $n$ , $ h^{p, q} = \binom{n}{p} \binom{n}{q} \neq 0 $ . Edit: For curves, the Hodge diamond is obvious and I missed it. Thank you to Tabes Bridges for catching it.","['complex-geometry', 'algebraic-geometry']"
4390744,Why is a complete measure space called “complete”?,"Things in mathematics are usually called “complete” for an obvious reason. A metric space is complete when you run out of Cauchy sequences without limits. A field is complete when you run out of polynomials without solutions. It is not clear what, if anything, you run out of in a complete measure space. The most obvious contender is that a complete measure space $(\Omega,\mathcal{F},\mu)$ can’t be extended, in the sense that there exist no $\sigma$ -algebra $\mathcal{G}\supset\mathcal{F}$ (containment is strict) and measure $\nu$ on $\mathcal{G}$ such that $\nu|_{\mathcal{F}}=\mu$ . But the measurable space $(\{a,b\},\{\emptyset,\{a,b\}\})$ equipped with any measure provides an easy counterexample. However, my trick here is cheap. My space is not, to abuse terminology, $T_0$ . We could introduce an equivalence relation on $\Omega$ of being members of precisely the same sets of $\mathcal{F}$ , and require that the equivalence classes be singletons. So would this result apply to “ $T_0$ ” complete measure spaces. If not, why are they called complete?","['measure-theory', 'terminology']"
4390792,When is it necessary to define a new function?,"For example: Lambert $W$ is a non-elementary function that can be defined as a solution for $x$ to $x\cdot e^x$ , but $\int{\frac{1}{\ln(t)}dt}$ is also supposed to be nonelementary. How do we know that those are not related by known operations? When is it necessary to define a new second or third etc. function?","['logarithms', 'real-analysis', 'lambert-w', 'elementary-functions', 'closed-form']"
4390816,What is the minimal order of a “sigmoid-like” entire function?,"The following question is motivated by Is there a complex analytic function that acts like sigmoid on the reals? : What is the minimal order of an entire function $f$ which is real-valued, increasing, and bounded on the real axis? In the above-referenced Q&A an additional condition is imposed on the second derivative, which I have omitted here for simplicity. The order of an entire function $f$ is defined as $$
\rho(f) = \limsup_{r \to \infty} \frac{\log \log M(r, f)}{\log r}
$$ where $ M(r, f) = \max \{ |f(z)| : |z| = r \}$ is the maximum of $|f|$ on the circle with radius $r$ . The order of an entire function is equal to the order of its derivative (see, e.g., here ), therefore an equivalent question is What is the minimal order of an entire function $h$ which is real-valued, positive, and integrable on the real axis? The answer must be a value between $1$ and $2$ : The function $h(z) = \exp(-z^2)$ satisfies these conditions and has order $2$ , so that is an upper bound for the minimal order. The corresponding function $f(z) = \int_0^z f(t) \, dt$ is – apart from a constant factor – the Gauss error function . On the other hand, the Phragmén–Lindelöf principle shows that $\rho(f) \ge 1$ for any entire function which is bounded on the real axis. Some thoughts: The easiest way to construct admissible function $h$ of finite order would be to set $h(z) = \exp(p(z))$ with a polynomial $p$ with real coefficients. But in order to make $\int_{-\infty}^\infty h(x) \, dx$ finite, the degree of $p$ must be at least $2$ , so that does not lead to a better upper bound. $f(z) = \sin(z)$ has order one, is real-valued and bounded on the real axis, but is not increasing on the real axis. The question is whether the monotony condition enforces a larger order or not. Any examples or results which improve the lower or upper bound are welcome.","['complex-analysis', 'entire-functions']"
4390822,"Checking whether $\int_{B(0,r)} \int_{B(0,r)} \ln(\|x-y\|)dxdy > 0$?","Today I was discussing with a classmate about the sign of the integral $$\int_{B(0,r)} \int_{B(0,r)} \ln(\|x-y\|)dxdy,$$ where $B(0,r)$ denotes the ball of center $0$ and radius $r$ in $\mathbb{R^2}$ . My friend said that this integral is negative for every $r>0$ because the function $\ln |x-y|$ is ""very negative"" at $x=y$ . I don't agree and I told him that I think there exists a critical $r$ from which the integral is positive. However, I don't know how to prove it. I rewrite it by using polar coordinates as $$\int_0^r\int_0^r\int_0^{2\pi}\int_0^{2\pi} \ln(\sqrt{r_1^2+r_2^2-2r_1r_2\cos(t_1-t_2)})r_1r_2dt_1dt_2dr_1dr_2.$$ I computed this integral with the software Mathematica and I obtained positive values with, for example, $r=2$ . However, this proof is not valid for my friend. Does anyone know how to prove it rigorously?","['integration', 'definite-integrals', 'real-analysis', 'multivariable-calculus', 'inequality']"
4390855,What's the area of the shaded regions in the triangle below?,"For reference: In triangle ABC, $S_1$ and $S_2$ are areas of the shaded regions. If $S_1 \cdot{S}_2=16 cm^4$ , calculate $MN$ . My progress: $\frac{AM.DM}{2}.\frac{CN.FN}{2}=16 \implies AM.DM.CN.FN=64\\
\frac{S1}{S2} = \frac{AM.MD}{CN.FN}\\
\frac{S1}{\frac{MI.DM}{2}}=\frac{AM}{MI}\implies S1 = \frac{AM.DM}{2}\\
\frac{S2}{\frac{NI.FN}{2}}=\frac{CN}{NI}\implies S2 = \frac{CN.FN}{2}$ .....????","['euclidean-geometry', 'geometry', 'plane-geometry']"
4390954,Metric space on which every function is uniformly continuous,"I would like to ask your thoughts on the following problem: “Characterise the metric spaces in which every function is uniformly continuous” The first thing I observed is that every subset of such metric spaces (let us call them X for the sake of semplicity) must be open for otherwise there would be some metric spaces Y and some function $f:X \rightarrow Y$ which may not be continuous (hence, also not uniformly continuous). Then, I conjectured that X must be compact, in fact, by the Heine-Cantor theorem this is a sufficient condition; however I can not manage to find a counter-example for when X is not compact in order to conclude that it is also necessary. Any help or hint is much appreciated!","['metric-spaces', 'real-analysis', 'continuity', 'functions', 'general-topology']"
4391014,Can I always get the generators of a subgroup?,"Let's say I have a group with a presentation in generators and relations: $$G = \langle g_1, g_2, ...\mid r_1, r_2, ...\rangle$$ And I have $H$ a subgroup of $G$ . If I take $h_1, h_2, ...$ the generators that are elements of $H$ and $q_1, q_2, ...$ the relations which relate only to the $h_i$ . Can I say that: $$H = \langle h_1, h_2, ... \mid q_1, q_2, ... \rangle$$ If that's not true, can I go in the other direction? In other words, can I say that if: $$H = \langle h_1, h_2, ... \mid q_1, q_2, ... \rangle$$ then I can ""extend"" this to a presentation for $G$ : $$G = \langle g_1, g_2, ...\mid r_1, r_2, ...\rangle$$ such that each $h_i$ is one of the $g_i$ and each $q_i$ is one of the $r_i$ ?","['group-theory', 'abstract-algebra']"
4391025,Challenge: a Bit-flipping Game,"I was just thinking about brain teasers the other day and came up with this one that turned out to be more difficult than I was anticipating. Suppose we play a game where we start with a bit string of $l$ zeroes (in my example $l=8$ ), 00000000 At each step of the game, we choose a bit at random from the bit string and flip it, like 01000000 The game terminates whenever we return back to our initial state of all zeroes. My question is this: What is the (closed-form) expected value of the length of the game as a function of $l$ ? My (incomplete) approach: First, I found the answer for verification purposes by programming the game with a couple different values of $l$ in python, which gave me the hypothesis that the expected value should be $2^l$ . My formal proof for how this is the case is what I'm seeking. I started by conceptualizing the bit string differently, as a string of integers from $0$ to $l-1$ with a dividing line between them. On the LHS of the line would be the indices of 1 in the bit string and the RHS would be indices of 0 in the bit string. This would encode a state like this: $$
\texttt{10111000}\qquad \Longrightarrow \qquad \texttt{0234 | 1567}
$$ Then, each iteration of the game is simply choosing one of these numbers at random, and putting it on the other side of the dividing line. If we call the set of integers on the LHS $L$ and those on the RHS $R$ , then the probability that the line moves left is $|L|\;/\;l$ and the probability that it moves right is $|R|\;/\;l$ . In this sense, we can sort of model the bit-flipping process as a one-dimensional random walk, terminating whenever the walker reaches the LHS, or $|L| = 0$ . This is why I consider the process to be a Martingale, even though the probability that the walker moves one direction or the other actually changes depending on where it is. That said, I don't actually know anything about Martingales other than that they are essentially random walks with a terminating condition (like gambling or w/e). I'm just not sure how to continue from here, can anyone solve this problem?","['game-theory', 'martingales', 'probability', 'algorithms']"
4391048,What is adjoint bundle for trivial bundle?,"Let $P =M\times G\to M$ be a principal $G$ -bundle on $M$ (first coordinate projection) What is $ad(P)$ ? Here $ad(E) = E\times_{Ad}g$ is a vector bundle on $M$ [where $g$ = Lie $(G)$ , $E$ is any principal $G$ -bundle on $M$ ] . My expectation is that it is the trivial bundle on $M$ . Any element in $ad(P)$ is $[(m,g),v] \sim [(m,e).g,v] \sim [(m,e), Ad_{g}v]$ . I need an isomorphism from $ad(P) \to M\times g$ . Here $e$ is the identity element in $G$ . All spaces are smooth manifolds and groups are Lie groups. Edit : I am adding the wiki link for adjoint bundle to avoid any confusion. https://en.wikipedia.org/wiki/Adjoint_bundle","['principal-bundles', 'vector-bundles', 'lie-groups', 'differential-geometry']"
4391140,Property of a connected graph with $\text{deg(all nodes)}=\text{even}$,"In my lecture nodes it is proposed that for a connected graph $G$ with the degree of all nodes being even, there exist two paths between any two nodes $x,y\in G$ with no common edges. From the very definition of a connected graph, there must exist one path between $x$ and $y$ ; the reason why there must exist two paths is then because we can simply ""walk in the opposite direction"" to get a new path? Also, how can it be shown that the two paths considered contain no common edges?","['graph-theory', 'elementary-number-theory', 'eulerian-path', 'combinatorics', 'discrete-mathematics']"
4391210,On a lemma for planar graphs,"Throughout, let $G$ be a planar graph with $n$ vertices, $e$ edges and $f$ faces. Additionally, let $n_k$ be the number of vertices of degree $k$ and $f_k$ be the number of faces with $k$ edges.
I have come across a simple lemma that would make a nice exercise. Has anyone seen this before? Lemma: Let $G$ be a planar graph with every vertex of degree at least 3 so that no triangles share an edge (equivalently, $G$ does not contain a diamond as a subgraph). Then $f_3 < 2f/3$ . Lemma: (Dual version) Let $G = (V,E)$ be a graph with $f_1=f_2=0$ such that no two degree 3 vertices are incident. Then $n_3 < 2n/3$ . Proof: Let $e_3$ be the number of edges contained in a triangle and $e'$ be the number of edges that are not. Since no edge is contained in two triangles, we see $e_3 + e' = e$ and $3f_3 = e_3$ . Since every vertex has degree at least three, $$
2e = \sum_{v \in V} deg(v) = \sum_{k \geq 3} k \cdot n_k \geq 3 n_3 + 4(n-n_3).
$$ Rearranging, we have $n_3 \geq 4n - 2e$ . Let $v$ be a vertex of degree $3$ . Since no edge is contained in two triangles, at least of the edges containing $v$ is not part of a triangle, so contributes to $e'$ . That edge may contain two vertices of degree $3$ , so we have $n_3 \leq 2e'$ . Combining these observations, we have $$
f_3 = \frac{e_3}{3} = \frac{e - e'}{3} \leq \frac{e - n_3/2}{3} \leq \frac{2e - 2n}{3} = \frac{2f-4}{3} < 2f/3
$$ where the final equality is Euler's formula. I would be interested in an explicit reference or better proof of this lemma. In particular, I don't understand why I should have to analyze degree three vertices -- it seems like a direct argument that does not reference degrees at all should be possible.","['graph-theory', 'combinatorics', 'planar-graphs']"
4391223,Solve $\int_{0}^\infty \frac{1}{(x^2 +b^2)^4}\ dx$,"I ran into this integral in the context of Quantum Mechanics, and I don't really know how to tackle it. Here, $b$ is simply a real constant, which we can assume is positive. $$\int\limits_0 ^\infty\frac{1}{(x^2+b^2)^4}\ dx$$ It doesn't look like I can use ""traditional"" methods to solve it, so I was thinking to maybe try to transform it to complex integral somehow and apply Cauchy's theorem or something, but I'm unsure if that would even work. Any nudge in the right direction would be appreciated!","['integration', 'definite-integrals']"
4391225,"$H\le G$ and $|H|=10$, $a^6\in H$, what could $|a|$ be? Without using Lagrange's theorem.","This is exercise 43 in chapter 4 of Gallian's Contemporary Abstract Algebra , 9th edition: Suppose that $H$ is a subgroup of a group $G$ and $|H|=10$ .  If $a$ belongs to $G$ and $a^6$ belongs to $H$ , what are the possibilities for $|a|$ ? The answer in the back of the book is ""all divisors of 60"".  It's easy to reach this conclusion using Lagrange's theorem: since $a^6\in H$ , $|a^6|$ is a divisor of $|H|=10$ , so $|a|$ is a divisor of $6\cdot 10 = 60$ .  The problem is that Lagrange's theorem isn't proven until chapter 7.  Chapter 4 contains the special case of Lagrange's theorem when the ambient group is cyclic (Corollary 1 on p79: ""In a finite cyclic group, the order of an element divides the order of the group""), but I don't see how to deduce this result using only that case, since neither $G$ nor $H$ is assumed cyclic. Is there a way to do this exercise using only the facts introduced in the book up until this point?","['group-theory', 'abstract-algebra']"
4391233,Hyperboloid of one sheet has only one closed geodesic,"Let $S : x^2+y^2-z^2 = 1 $ be the hyperboloid of one sheet. We know that there exists a closed geodesic, namely the unit circle $\{(\cos\theta, \sin\theta,0) , \theta \in [0,2\pi]\}$ , since it is the locus of fixed points of the reflection along the $xy$ plane . The claim of uniqueness should follow from Clairaut's relation, however I can't see why that is.
In fact, the problem can be solved in a more general case; A surface of revolution with negative gaussian curvature has at most one simple closed geodesic. Can anyone enlighten me on how this follows from Clairaut's relation?",['differential-geometry']
4391243,For what reason are data sets with no repeating values defined as no mode whilst sets with n/2 is part of the set of integers is defined?,"This question is in regards to the reasoning underpinning the definition of a set with no repeating values as having no mode.  I am interested in the analytical philosophy behind this. A set with no repeating values is defined as having no mode. But a set that has an even number of elements is described as having a median = [(n/2)th term + (n/2)+1 term)]/2 rather than “no median”. So, in cases where there is no repeating element, for what reason did mathematicians not define such sets as mode = mean?",['statistics']
4391302,Question about the definition of differentiability of a map between surfaces,"In his book on Curves and Surfaces, Do Carmo defines what a differentiable map between surfaces means as follows: A continuous map $\varphi:V_1 \subset S_1 \to S_2$ of an open set $V_1$ of a regular surface $S_1$ to a regular surface $S_2$ is said to be differentiable at $p \in V_1$ if, given parametrizations $$\mathbf{x}_1: U_1 \subset \mathbb{R}^2 \to S_1, \quad \mathbf{x}_2: U_2\subset \mathbb{R}^2 \to S_2$$ with $p \in \mathbf{x}_1(U_1)$ and $\varphi(\mathbf{x}_1(U_1))\subset \mathbf{x}_2(U_2),$ the map $$\mathbf{x}_2^{-1}\circ \varphi \circ \mathbf{x}_1:U_1 \to U_2$$ is differentiable at $q=\mathbf{x}_1^{-1}(p).$ My question is the following: Why do we need to assume that $\varphi$ is a continuous map? If we remove that word from the definition, is there an example of a map $\varphi: S_1 \to S_2$ between surfaces $S_1$ and $S_2$ that satisfies this new definition but that is not continuous? Thanks in advance.","['surfaces', 'differential-geometry']"
4391411,A 2-connected graph example,"$\textbf{Question:}$ In a $k$ -connected graph $(k\ge2)$ , any $k$ vertices lie on a common cycle. $\textbf{Proof:}$ Let $S$ be a given set of $k$ vertices and consider a cycle $C$ with the maximum
number of vertices from $S$ . Suppose that some $v \in S - C$ . Then by Menger theorem, there are $kv - C$ paths. Partition $C$ into at most $k - 1$ paths $P_j$ , where the $i$ th path begins from the $i$ th vertex of $S$ on $C$ (in clockwise order say), and ends just before the $i + 1st$ vertex. Since $|S| = k$ , by pigeonhole, two of the $v - C$ paths have their endpoints in the same $P_i$ . Detouring along these two paths yields a cycle with more vertices of $S$ , contradiction. $\textbf{A follow-up question:}$ Show that if a graph is 2-connected, then every two cycles of maximum length have at least two common vertices. Helpful comments are needed to prove this follow up.","['graph-theory', 'graph-connectivity', 'discrete-mathematics']"
4391436,Separation of finite sets in homogeneous spaces by homeomorphisms,"Call a topological space $X$ flexible , if for each finite set $A \subset X$ there exists a homeomorphism $f: X \rightarrow X$ such that $A \cap f(A) = \emptyset$ .
(Certainly not a good name, and by far not standard, but for the purpose of this question it might suffice.) Let $X$ be an infinite, T2, homogeneous topological space (i.e., for all $x, y \in X$ there is a homeomorphism $f: X \rightarrow X$ such that $f(x) = y$ ). Is $X$ flexible? Notes Of course, a flexible, non-empty space is infinite and must provide a certain amount of homeomorphisms.
For instance, if it is rigid (i.e, the identity is the only homeomorphism), it can't be flexible. Therefore, it makes sense to restrict to homogeneous spaces. Considering ""typical"" homogeneous spaces as $\mathbb{R}^n$ , the answer seems so obviously to be ""yes"". However, I couldn't prove the above in general, not even for two-element sets $A$ . It is not difficult to prove that $X$ is flexible, if $X$ is infinite and at least one of the following conditions holds: a) $X$ is the underlying space of a topological group b) $X$ is a product with (at least) one factor flexible (this might indicate how weak flexible is) c) $X$ is n-homogeneous for all $n \in \mathbb{N}$ d) $X$ is strongly locally homogeneous, T2 and contains no isolated points (in particular, if $X$ is a manifold) e) $X$ is uniquely homogeneous (The notations in c), d) and e) are the standard ones, see for instance here .) My assumption is that the answer is ""yes"". Perhaps, the proof is more combinatorial (eg. Ramsey theory) rather than topological?
Or even with some trivial argument, which I just didn't notice? The pseudo-arc is a standard example of a homogeneous, not strongly locally homogeneous, space. I'm not very familiar with it. Embarrassingly, I don't know, whether it is flexible or not. Perhaps, it provides a counter-example? [edit: I just deleted 6. (and my two related comments below), since after some further consideration it no longer make sense.] Perhaps the T2 requirement in the prerequisite is superfluous? I also don't know of a non-T2 counterexample.","['general-topology', 'group-actions', 'combinatorics']"
4391442,"Prove that there are no real numbers $a,b,c,d$ such that this system of equations holds.","Prove that there are no real numbers $a,b,c,d$ such that this system of equations holds. $$a^3+c^3=2$$ $$a^2b+c^2d=0$$ $$b^3+d^3=1$$ $$ab^2+cd^2=-6$$ I think that we have to use the fact that $x^2-xy+y^2\ge0$ as this is a two part question with the a) part being to prove that $x^2-xy+y^2\ge0$ which is a simple $AG$ equation. Here's some of what I tried. I think it's important to figure out $d^3-cd^2+c^2d=d(d^2-cd+c^2)$ $c^3-c^2d+cd^2=c(c^2-cd+d^2)$ $b^3-ab^2+a^2b=b(b^2-ab+a^2)$ $a^3-a^2b+ab^2=a(a^2-ab+b^2)$ but I'm not sure how to effectively use this as summing these four terms together we get $a^3+b^3+c^3+d^3$ which equals $3$ which I don't see a use for. But I'm 99% sure we do have to use them in some way. I've been stuck at this problem for the past hour or so with no significant progression so any help's appreciated! Thanks in advance.","['algebra-precalculus', 'systems-of-equations']"
4391449,How do I find the x value of an undefined tangent function,"Apologies in advance if the formatting for the equations isn't great (first time doing this), hopefully it worked correctly though. The problem: Given the function $f(x)=-2*\tan(1.7*x-8.8)-7.7$ find the x value which is (a) undefined and (b) a x value at which $f(x)=0$ I have already found the undefined value by calculating $1.7*x-8.8$ = $\frac{(\pi)}{2}$ which gave me $6.1005$ To find an x value at which $f(x)=0$ , I tried entering the equation as: $0=-2*tan(1.7*(6.1005)-8.8)-7.7$ $\ln(0)=\ln(-2*tan(1.7*(6.1005)-8.8)-7.7)$ and carrying it through from there however my answer kept coming back as either false or undefined.
Can someone help me with this? Its probably really simple but I cant think of any other way aside from the natural log method","['trigonometry', 'functions', 'special-functions']"
4391451,Confusion in finding derivative of $\sqrt{\frac{1-\cos(2x)}{1 + \cos(2x)}}$,"Find $f'(x)$ where $f(x) = \sqrt{\dfrac{1-\cos(2x)}{1 + \cos(2x)}}$ . This question is given in my textbook but I don't agree with the solution given in my book and various sites on the internet. The book shows the following method: $$f(x) = \sqrt{\dfrac{1-\cos(2x)}{1 + \cos(2x)}} =\sqrt{\dfrac{2\sin^2(x)}{2\cos^2(x)}}=\sqrt{\tan^2x}= \tan(x)$$ So the derivative of $\tan(x)$ is $\sec^2(x).$ But my confusion is that, $\sqrt{\tan^2(x)}$ should be $|\tan(x)|$ and so, it's derivative cannot be equal to $\sec^2x$ . Derivative of $|x|$ is $\dfrac{x}{|x|}$ . So, the derivative of $|\tan(x)|$ should be $\dfrac{\tan(x) \cdot \sec^2(x)}{|\tan(x)|}.\bf\qquad\qquad\qquad\qquad....(1)$ Or we can also say that derivative of $|\tan(x)|= \begin{cases}\sec^2{x},\rm If\, tan(x)\ge0\\-\sec^2x, \rm If \tan(x) < 0 \end{cases}.\bf\qquad....(2)$ Am, I right in (1) and (2) ?","['calculus', 'solution-verification', 'derivatives', 'trigonometry']"
4391456,Continuous extension of a stochastic process,"I'm actually following a Brownian motion course, unfortunately I'm stuck with the following. Consider a probability space $(\Omega, \mathcal{F},\mathbb{P})$ and stochastic process $(X_t)_{t \in \mathbb{R}^+}$ on this probability space. We are interested in the property $(*)$ which is, Property ( $*$ ): It is possible to find some probability space $(\tilde{\Omega}, \mathcal{L},\mathbb{Q})$ , and some random process $(Y_t)_{t \in \mathbb{R}^+}$ on this probability space with $(Y)_{t\in \mathbb R^+}\stackrel{\text{fdd}}=(X)_{t\in \mathbb R^+}$ and such that there exists a measurable set with probability 1, such that for all $\omega$ in this set, $t\mapsto Y_t(\omega)$ is continuous on $\mathbb{R}^+$ . Here, $(Y)_{t\in \mathbb R^+}\stackrel{\text{fdd}}=(X)_{t\in \mathbb R^+}$ means that the two processes have the same finite dimensional distributions. Now suppose that our $(X_t)_{t \in \mathbb{R}^+}$ have the $(*)$ property. The statement is the following: suppose $J$ is a countable dense subset of $\mathbb{R}^+$ (for instance $\mathbb{Q}^+$ ) and one has a collection of random variables $(Z_q)_{q\in J}$ with the same fdds as $(X_q)_{q \in J}$ (this is really a property about the law in particular we do not suppose anything about the probability space of $(Z_q)_{q\in J}$ ), then $(Z_q)_{q\in J}$ almost surely has a continuous extension. In addition this extension $(\tilde{Z_t})_{t \in \mathbb{R}^+}$ is such that $(\tilde{Z}_t)_{t\in \mathbb R^+}\stackrel{\text{fdd}}=(X_t)_{t\in \mathbb R^+}$ . I've tried to prove the above without success for a long time thus I will greatly appreciate if any of you can help me with that :) Have a great day.","['stochastic-processes', 'brownian-motion', 'probability-theory']"
4391457,Is the hypothesis $\mu \ge 0$ redundant in Brezis's Ex 3.15?,"I'm doing Ex 3.15 in Brezis's book of Functional Analysis. Let $(E, |\cdot|)$ be a reflexive Banach space. In the following, the convex subset $K$ of $E$ is equipped with the weak topology $\sigma (E, E')$ such that $K$ is compact. Let $F = \mathcal C(K)$ with its usual norm $| \cdot |_\infty$ . Fix some $\mu \in F'$ with $\|\mu\|_{F'}=1$ and assume that $\mu \geq 0$ in the sense that $$
\langle\mu, u\rangle \geq 0 \quad \forall u \in \mathcal C(K) \text{ such that } u \geq 0 \text { on } K .
$$ Prove that there exists a unique element $x_{0} \in K$ such that $$
\langle \mu, f_{\mid K} \rangle = \langle f, x_{0} \rangle \quad \forall f \in E'.
$$ In below proof, I do not use the assumption that $\mu \ge 0$ . I think I made some mistake but could not recognize. Could you have a check on my attempt? Consider the map $\varphi:E' \to \mathbb R, f \mapsto \langle \mu, f_{\mid K} \rangle$ . It's clear that $f$ is linear. Let $B_E$ be the closed unit ball of $E$ . Because $K$ is weakly compact, $K$ is bounded. There is $r>0$ such that $rK \subset B_E$ . We have $$
|f_{\mid K}-g_{\mid K}|_{\infty} = \sup_{x\in K} |\langle f-g, x\rangle| = \frac{1}{r} \sup_{x\in rK} |\langle f-g, x\rangle| \le  \frac{1}{r} \sup_{x\in B_E} |\langle f-g, x\rangle| = \frac{1}{r} \|f-g\|_{E'}.
$$ It follows that $\varphi$ is continuous and thus $\varphi\in E''$ . Because $E$ is reflexive, we can identify $\varphi$ with a unique $x_0 \in E$ , i.e., $$
\langle f, x_0 \rangle = \langle \varphi, f \rangle = \langle \mu, f_{\mid K} \rangle \quad \forall f \in E'.
$$ Assume the contrary that $x_0 \notin K$ . Then  we can strictly separate $\{x_0\}$ and $K$ by Hahn-Banach theorem. This means there are $a,b \in \mathbb R$ and $f \in E'$ such that $$
\langle f,x \rangle <a <b< \langle f,x_0 \rangle =  \langle \mu, f_{\mid K} \rangle \le \|\mu\|_{F'} \cdot |f_{\mid K} |_\infty = |f_{\mid K} |_\infty \quad \forall x\in K.
$$ Notice that $\langle f,x \rangle < |f_{\mid K} |_\infty$ for all $x\in K$ is a contradiction because $f \in E'$ and $K$ is weakly compact. Update: @MaoWao showed that I made a mistake at the end. Hopefully, I have found a fix :v Let $\lambda := \langle \mu, 1 \rangle$ . By positivity condition, we get $$
\|\mu\|_{F'} = \sup_{\substack{u\in \mathcal C(K) \\ |u|_\infty = 1}}  \langle \mu, u \rangle \le \sup_{\substack{u\in \mathcal C(K) \\ |u|_\infty = 1}}  \langle \mu, 1 \rangle = \lambda.
$$ It follows that $\|\mu\|_{F'} = \lambda$ and thus $\lambda = 1$ . It follows from $f_{\mid K} <a<b$ that $f(x_0) = \langle \mu, f_{\mid K} \rangle \le \langle \mu, a \rangle < \langle \mu, b \rangle$ . This implies $a < b < \langle \mu, a \rangle < \langle \mu, b \rangle$ and thus $a<b<\lambda a<\lambda b$ . This in turn implies $\lambda \neq 1$ which is a contradiction. This completes the proof. We can see that the positivity constraint and the fact that $\|\mu\|_{F'} = 1$ are essential.","['banach-spaces', 'functional-analysis', 'weak-topology']"
4391474,$\pi$ estimation with a coin,"I have a topic in which I have to estimate the value of $\pi$ by throwing coins and write the calculations in excel. I found this article but I can't figure out how $N_0$ was determined. Here in the example where $M=100$ and $N=1000$ , $N_0$ is $80$ but why? And also in the second picture there is $M=100$ , $N=1000000$ , and $N_0= 78929$ . Thank you !","['statistics', 'probability']"
4391491,Why isn't this closed loop curve integral $0$?,"I had to solve a problem where I had to calculate the work done by the force field given by: $$ \vec{F} = \frac{(-y,x)}{x^2+4y^2}, (x,y) \neq (0,0)$$ where we travel along the whole unit circle in a positive orientation. I managed to find the potential function given by: $\phi = \frac{-1}{2}\arctan(\frac{x}{2y})$ . Since there exists a potential function for which $\vec{F} = \nabla(\phi)$ , we have that the force field is conservative. We also note that the potential function isn't defined at $y = 0$ . This means I can't use the fundamental theorem of line integrals directly. Maybe I should extend my $\phi$ in so that I get a continous function by computing the limit as we tend to $0$ from the left and the right. Then I'm also thinking that our curve we are walking along is a closed loop, and then indeed, for a conservative force field, this has to become $0$ . Instead, my answer sheet tells me it's $\pi$ . I'd be thankful if you could describe to me what went wrong in my solution, and why that's the case.","['integration', 'vector-fields', 'multivariable-calculus']"
4391520,"If proposition $\text{I}, 17$ in Euclid's Elements does not depend on the parallel postulate, how can elliptic geometry be consistent?","I'm from Italy, so I was reading an Italian translation of Euclid's Elements ; and while I was doing just that, something about the introduction—written by Attilio Frajese—really caught my attention. Frajese explains how Euclid, not feeling confident about his own parallel postulate, tried to delay its usage as much as he could, wanting to see how far he could push geometry forward before he was forced to make use of it. In particular, he focuses on the very existence of proposition $\text{I}, 17$ , which states that the sum of any two angles within any triangle is always less than $180^°$ (in modern notation, of course). This proposition is apparently useless and redundant, seeing how it's just a consequence of $\text{I}, 32$ —the much more well-known theorem according to which the sum of the internal angles of a triangle is precisely $180^°$ . This apparent redundancy is easily explained by Frajese as he points out that between these two theorems is $\text{I},29$ , the first proposition that Euclid cannot prove without his postulate parallel. Therefore, $\text{I}, 17$ exists as a separate proposition simply because Euclid wanted to write down as many results as he could that didn't depend on that postulate, even if they're mere corollaries of results he will later prove in a more general way. But then, this leads me to a question. If $\text{I}, 17$ is indeed independent from the parallel postulate, how can elliptic geometry be consistent? The independence of the fifth postulate from the other ones is usually shown by exhibiting geometries like this, which make use of the first four postulates while replacing the fifth one with something else, and then pointing out that the resulting system is still consistent. But in elliptic geometry a triangle will look like this thing here—see image below; and surely the angles in this triangle add up to more than $180^°$ (indeed, it's one of the most peculiar traits of elliptic geometry that everyone knows). So how is this not in violation of the (parallel-postulate-free) proposition $\text{I}, 17$ ?","['noneuclidean-geometry', 'geometry']"
4391525,moment inequality of martingales,"Let $M_t$ be a martingale whose quadratic variation is finite (and also any higher moments). Then for any $s<t$ and $k > 1$ , is it true that \begin{align*}
 \mathbb{E}|M_s|^k \le \mathbb{E}|M_t|^k?
\end{align*} My intuition says that due to the quadratic variation of any martingale is increasing, so $\mathbb{E}|M_s|^2 \le \mathbb{E}|M_t|^k$ is quite trivial due to the Ito's isometry.
But is this still hold for any arbitrary $k>1$ ? Thanks,","['martingales', 'inequality', 'probability-theory', 'probability']"
4391615,number of ways of choosing sets of integers,"Let $k$ be a nonnegative integer. Determine the number of ways to choose $(k+1)^2$ sets $S_{i,j}\subseteq [2k] := \{1,2,\cdots ,2k\}$ for integers $i,j$ with $0\leq i, j \leq k$ so that for all $0\leq i\leq c\leq k, 0\leq j\leq d \leq k, S_{i,j}\subseteq S_{c,d}.$ The number of subsets of $\{1,2,\cdots, 2k\}$ is $2^{2k}$ . There are thus $2^{2k}$ ways to choose the subset $S_{0,0}$ . Suppose it has $a_0$ elements. Then the set $S_{1,0}$ must contain these $a_0$ elements and a subset of the complement of these $a$ elements in $\{1,2,\cdots, 2k\}$ . In general, if $S_{i,0}$ has $a_i$ elements then $S_{i+1, 0}$ must have at least $a_i$ elements and the set of elements in $S_{i+1,0}\backslash S_{i,0}$ is a subset of $[2k]\backslash S_{i,0}$ . This chain of reasoning does not seem very useful however, because it's largely dependent on what the sizes of the sets $S_{i,j}$ are. Would generating functions be useful and if so, how? Obviously one can't just choose $(k+1)^2$ subsets from the set of all subsets of $[2k]$ and order them because subsets only form a partial order under inclusion; some aren't even comparable.","['elementary-set-theory', 'combinatorics', 'contest-math']"
4391646,General means of obtention of regular tetrahedra inscribed into a regular tetrahedron,"This is a follow-up of a recent question that I will name $(Q)$ . Reformulating question $(Q)$ : being given a regular tetrahedron $(T)=(ABCD)$ , how is it possible to inscribe (slanted) smaller regular tetrahedra $A'B'C'D'$ inside $(T)$ (i.e., with $A' \in BCD, B' \in ACD...$ . An elegant solution is given there (with alas few details) using an adequate rotation combined with a shrinking factor $1/3<f<1$ . This solution did not fully satisfied me because I want to know if there other means to get inscribed tetrahedra. I have taken the vetices of the regular tetrahedron $(T)$ as the columns of this matrix: $$T=\left(\begin{array}{rrrr}1 &-1& 1& -1\\1& 1 &-1 &-1\\1 &-1 &-1 &1\end{array}\right)\tag{1}$$ (obtained by taking a system of 4 non-neighbor vertices of a cube). Here are the equations of the planes containing the faces of tetrahedron $(T)$ : $$\begin{cases}x+y+z+1&=&0\\-x+y+z-1&=&0\\x-y+z-1&=&0\\x+y-z-1&=&0\end{cases}\tag{2}$$ I decided to use a CAS (Computer Algebra System).
After a certain number of failures, I have finaly obtained a satisfying way to get particular solutions. Here is the central part of the corresponding (Matlab CAS) program on which I am going to make some comments: syms x1 x2 x3 x4 y1 y2 y3 y4 z1 z2 z3 z4
d12=(x1-x2)^2+(y1-y2)^2+(z1-z2)^2;
d13=(x1-x3)^2+(y1-y3)^2+(z1-z3)^2;
d14=(x1-x4)^2+(y1-y4)^2+(z1-z4)^2;
d23=(x2-x3)^2+(y2-y3)^2+(z2-z3)^2;
d24=(x2-x4)^2+(y2-y4)^2+(z2-z4)^2;
d34=(x3-x4)^2+(y3-y4)^2+(z3-z4)^2;
    [X1,X2,X3,X4,Y1,Y2,Y3,Y4,Z1,Z2,Z3,Z4]=...
    solve(...
      x1+y1+z1+1==0,x2-y2+z2-1==0,x3-y3-z3+1==0,x4+y4-z4-1==0,...
      x1+x2+x3+x4==0,y1+y2+y3+y4==0,z1+z2+z3+z4==0,...
      d12==d13,d12==d14,d14==d23,d23==d24,...
      z1==-1/3,...
    x1,x2,x3,x4,y1,y2,y3,y4,z1,z2,z3,z4) Let me explain the different lines following the ""solve"" instruction, being understood that the vertices of the looked for tetrahedra are $(x_k,y_k,z_k)$ : first line: the vertices of tetrahedra $(T')$ must belong to the faces (see (2)), second line: the center of $(T')$ must be the origin, third line: $(T')$ must be regular, fourth line: one of the coordinates of the first vertex of $(T')$ is fixed arbitrarily. In the case at hand, we obtain almost instantly different solutions. Among them, in blue, we obtain the very particular ""central"" tetrahedron whose vertices are the centroids of the faces of $(T)$ (this is why we had taken the particular value $z_1=-1/3$ ...). The two other solutions (in red and green) are spurious, but fulfill all the conditions... Fig. 1: Results of the program given above. Fig. 2: With a different value of $z_1$ , four different solutions for $T'$ . Fig. 3: The  vertices of many different inscribed tetrahedra $(T')$ for many different values of $z_1$ , making apparent the fact that they belong to hyperbolic arcs as shown in the answer by @Intelligenci Pauca. Remark: when a solution $(T')$ has been found (as before, we assimilate a tetrahedron with the matrix $3 \times 4$ of the coordinates of its vertices), we can retrieve the scaling factor $s$ by computing the ratio of norms of the columns of matrices $(T)$ and $(T')$ , and the rotation $R$ such that $T'=sRT$ by computing: $$R=\frac1s T'T^+$$ where $T^+$ is the $4 \times 3$ pseudo-inverse of $T$ . My question is twofold: With my method based on vertices of $(T')$ , are we able to retrieve a larger set of combinations ""rotation + shrinking"" than in question $(Q)$ ? Are there general formulas that avoid to consider particular cases ? Same question as in $(Q)$ , to which no answer has been given: is there some interesting papers about the issue of tetrahedra inscribed in a tetrahedron ? Edit: This question has found a new direction with the answer by Intelligenci Pauca that I have attempted to explain in a simple way (see my answer).","['geometry', 'linear-transformations']"
4391682,How to reconcile Jech's different definitions of cardinal numbers?,"Thomas Jech begins the chapter 3 of his Set Theory (p. 27), titled Cardinal Numbers , as follows (in all excerpts below, the emphasis in bold letters is mine): Two sets $X$ , $Y$ have the same cardinality ( cardinal number , cardinal ), $$\tag{3.1} |X| = |Y|,$$ if there exists a one-to-one mapping of $X$ onto $Y$ . This looks to me like a complete definition of cardinal numbers.  (I will call it Definition 1.)  But immediately after the paragraph above, Jech writes: The relation (3.1) is an equivalence relation.  We assume that we can assign to each set $X$ its cardinal number $|X|$ so that two sets are assigned the same cardinal number just in case they satisfy condition (3.1).  Cardinal numbers can be defined either using the Axiom of Regularity (via equivalence classes of (3.1)), or using the Axiom of Choice. In this chapter we define cardinal numbers of well-orderable sets; as it follows from the Axiom of Choice that every set can be well-ordered, this defines cardinals in ZFC. I don't know what to make of the sentence in bold.  Does it mean that the real definition of cardinals is still coming, and therefore that Definition 1 does not count somehow?  Or does it mean that Definition 1 is what the statement ""In this chapter we define cardinal numbers of well-orderable sets"" is referring to?  If the latter is the case, which of the two alternative approaches (via Axiom of Regularity or via Axiom of Choice) is being used in Definition 1? The confusion does not end there.  After Jech has already been using terms like ""cardinal numbers"" and ""cardinals"" quite extensively, including (on p. 28) a complete definition of the ""arithmetic operations on cardinals"", on p. 29 he writes An ordinal $\alpha$ is called a cardinal number (a cardinal) if $|\alpha| \neq |\beta|$ for all $\beta < \alpha$ . I will call this definition of cardinal numbers Definition 2. I have the same questions about Definition 2 as I had about Definition 1.  I.e. is Definition 2 what the sentence ""In this chapter we define cardinal numbers of well-orderable sets"" is referring to?  If yes, which of the two alternative approaches (via Axiom of Regularity or via Axiom of Choice) is being used in Definition 2? Finally, how can these two different definitions of cardinal numbers be reconciled?  How is one supposed to know which one is being referred to whenever Jech uses terms like ""cardinal numbers"" and ""cardinals"" in the rest of the book?  Is this as appalling as it looks, as a piece of mathematical exposition, or am I missing something?",['elementary-set-theory']
4391714,Equivalence between connecting $n\times n$ grid and the gossip problem,"In this thread , the problem about connecting a $n\times n$ grid without lifting your pen was discussed. A user mentioned the relation between this problem and the gossip problem. Apparently this is equivalent to the gossip problem. (see A058992 .) – Vepir I find such equivalence not-so-obvious. Wonder if anyone can provide some insights (or complete proof, if possible) about the equivalence between the connect $n\times n$ grid problem and the gossip problem. P/s. It would have been easier for me if I have more than 50 reputations to ask the user directly about the relationship instead of posting this question.","['graph-theory', 'combinatorics']"
4391731,A functional equation $(f(x)+1)f(f(x))=x(x+1)$,"I am trying to find all solutions for the following functional equation: $$f:\mathbb{N}\to\mathbb{R}, \ \ s.t. \ \ (f(x)+1)f(f(x))=x(x+1)$$ It is clear that $f(x)=x$ is a solution for this equation. However, I'd like to prove that this is the only solution (or find a general formula for all the solutions). My attempt was to first find $f(0)$ : For $x=0$ , $(1+f(0))f(f(0)) = 0$ so either $f(0)=-1$ or $f(f(0))=0$ .
For the second case, let $x=f(0)$ , so $(1+f(f(0)))f(f(f(0))) = f(0)(f(0)+1)$ , therefore $f(0)=f(0)(f(0)+1)$ , where we find that $f(0)=0$ . As such, I have proven that either $f(0)=-1$ or $f(0)=0$ . Being inspired by the technique for finding $f(0)$ , I wrote the functional equations for $x=n$ and $x=f(n)$ . $$(1+f(n))f(f(n)) = n(n+1)$$ $$(1+f(f(n)))f(f(f(n))) = f(n)(f(n)+1)$$ and by dividing we obtain: $$f(n)  \cdot f(f(n)) = n(n+1) \cdot (1+f(f(n)))f(f(f(n)))$$ Or, by plugging in $x=n$ and $x=n-1$ , we get the two equations $$(1+f(n))f(f(n)) = n(n+1)$$ $$(1+f(n-1))f(f(n-1))=n(n-1)$$ an idea is to find a formula for $f(n)$ in terms of $f(n-1)$ , but I am stuck how I could find such an equation without including $f(f(n))$ . Is there any way we can find all solutions, or find a relationship involving only $f(n)$ and $f(n-1)$ ?","['functional-equations', 'functions', 'linear-algebra']"
4391754,Number of plates that can be placed on the table so that they neither overlap each other nor the edge of the table?,"Table in my room is round in shape and its radius is 15 times the radius of our plates, which are also round in shape. Find the number of plates that can be placed on the table so that they neither overlap each other nor the edge of the table ? MY Solution :-
let the radius of plates be $r$ Then radius of table is $15 r$ Number of plates = $225πr^2/πr^2$ = $225$ I have doubt that is my solution is correct or not ?","['puzzle', 'logic', 'geometry', 'packing-problem']"
4391765,Changing the signs in the metric and the curvature,"Suppose we have two Riemannian manifolds $(B,g_B)$ and $(F,g_F)$ and consider their product $C:=B\times F$ endowed with the metric tensor $g_C:=-\pi_B^*(g_B)+\pi_F^*(g_F)$ , where $\pi_B$ and $\pi_F$ denote the projections on $B$ and $F$ respectively and $^*$ is the pullback. If I want to write the Ricci tensor of $C$ , if $g$ was the usual product metric then that tensor would be just the sum of the two Ricci's on $B$ and $F$ , but in this case the sign $-$ in front of $\pi_B^*(g_B)$ should change the sign of the Ricci of $B$ : if $\xi:=x+v$ , where $x\in T_bB$ and $v\in T_fF$ for $b\in B$ and $f\in F$ , I would have $$\textrm{Ric}_{(b,f)}^C(\xi,\xi)=-\textrm{Ric}^B_b(x,x)+\textrm{Ric}^F_f(v,v).$$ What confuses me is the fact that if I change the sign in a metric of a Riemannian manifold the curvature tensors do not change (since the Riemann tensor is made of Christoffel symbols in coordinates which are products of the matrices of the metric) but here the Ricci does. Does this come from the fact that the metric contraction wrt the $g_C$ ? If I have a smooth function $f:X\rightarrow\mathbb{R}$ than the Hessian of $f$ would be the same of $B$ but with the same sign? P.s. I did everything not in coordinates, using, given a frame $\{E_i\}_i$ on $C$ , $$\textrm{Ric}^C(X,Y)=\sum_ig_C(E_i,E_i)\,g_C(\textrm{R}^C_{XE_i}Y,E_i),$$ following O'Neill computations in chapter $7$ of his book ""Semi-Riemannian geometry"".","['riemannian-geometry', 'semi-riemannian-geometry', 'curvature', 'calculus', 'differential-geometry']"
4391773,Which of these reasonings is correct?,"If $K(x)=-\ln\|x\|$ , we know that $\Delta K=\delta_0$ in $\mathbb{R^2}.$ Furthermore, we consider $f$ as the characteristic function of the ball $B(0,1)$ .  I have obtained two different results when I use divergence theorem, but I am not able to find which way is correct. Any help would be welcome because I am really stuck with this question. On the one hand \begin{align}
\int_{\mathbb{R}^2}(K*f)(x)f(x)dx&=\int_{\mathbb{R}^2}(K*f)(x)(\delta_0*f)(x)dx=\int_{\mathbb{R}^2}(K*f)(x)\Delta K*f(x)dx\\&=\int_{\mathbb{R}^2}(K*f)(x)div (\nabla K*f(x))dx
\\&=\lim_{r\to\infty}\Big[ \int_{C(0,r)}(K*f)(x)(\nabla K*f)(x)\cdot n(x)dx   \Big]-\int_{\mathbb{R}^2}(\nabla K*f)(x)\cdot(\nabla K*f)(x)dx.
\end{align} On the other hand \begin{align}
\int_{\mathbb{R}^2}(K*f)(x)f(x)dx&=\int_{B(0,1)}(K*f)(x)f(x)dx=\int_{B(0,1)}(K*f)(x)(\delta_0*f(x))dx\\&=\int_{B(0,1)}(K*f)(x)(\Delta K*f(x))dx=\int_{B(0,1)}(K*f)(x)div (\nabla K*f(x))dx
\\&= \int_{C(0,1)}(K*f)(x)(\nabla K*f(x))\cdot n(x)dx-\int_{B(0,1)}(\nabla K*f(x))\cdot(\nabla K*f(x))dx.
\end{align}","['integration', 'real-analysis', 'multivariable-calculus', 'functional-analysis', 'partial-differential-equations']"
4391783,Maximizing the volume of a cuboid with constraints (lagrange) fails?,"Given is the following (translated) problem: You have $12$ meters of wire.
Try to build a wireframe model of a cuboid with sidelengths $x, y, z$ and maximize volume $V(x,y,z)=xyz$ . Show that this is the case iff all sidelengths are equal. My attempt: Using Lagrange with the constraint $g(x,y,z)=x+y+z-3$ leads to: $$\nabla L(x,y,z,\lambda)=\begin{pmatrix}
           yz+\lambda \\
           xz+\lambda \\
           xy +\lambda \\
           x+y+z-3
         \end{pmatrix} \stackrel{!}{=}0$$ After solving I get: $$x=y=z=1$$ $$\lambda = -1$$ I calculate the Hessian matrix afterwards and get: $$H_L=\begin{pmatrix}
           0 & z & y & 1\\
           z & 0 & x & 1 \\
           y & x & 0 & 1  \\
           1 & 1 & 1 & 0
         \end{pmatrix}$$ Inserting previous values produces this matrix: $$H_L=\begin{pmatrix}
           0 & 1 & 1& 1\\
           1 & 0 & 1 & 1 \\
           1 & 1 & 0 & 1  \\
           1 & 1 & 1 & 0
         \end{pmatrix}$$ Now the problem : This matrix has eigenvalues $3$ and $-1$ , which should mean it's indefinite and therefore has as saddle point/ no minimum or maximum. Did I do something wrong or is it not possible to solve this problem with lagrange?","['lagrange-multiplier', 'matrices', 'multivariable-calculus', 'calculus', 'optimization']"
4391792,Alternative way of writing the stars and bars formula where each bar is associated with at least one star.,"I was looking for a different way of writing the formula of the number of different $k$ -tuples of non-negative integers whose sum is equal to $n$ and I thought of this formula followed by this combinatorial proof : $$
\sum_{i = 1}^k \binom{n + 1}{i}\binom{k - 1}{i - 1}
$$ The first combination is the number of positions that we can choose from to place the bars. There are $n+1$ positions to choose from, since now we can also place the bars before and after the stars. The next combination is the number of different ways of splitting the stars between the positions that were chosen for the bars to be placed. Lastly, we'll have to add all the different ways of combinations of bar positions and number of bars in each position. I haven't found a flaw in my proof yet but I can't seem to conclude that the above formula is equal to $$\binom{n + k - 1}{k - 1}$$ Could someone more experienced verify my proof or show me where the flaw is?","['integer-partitions', 'combinatorics', 'combinatorial-proofs', 'discrete-mathematics']"
4391795,An unbroken path of straight lines passing through $3\times 3\times 3$ lattice grid,"It's well known that it requires an unbroken path of $4$ straight lines to cover all $9$ dots in a $3$ by $3$ lattice grid (see here ). By making use of the $4$ -line path in $3\times 3$ grid, it only needs $14$ lines to cover the three-dimensional $3\times 3\times 3$ grid ( $4$ lines for each layer and $2$ lines for layer connection, which yields $4\times 3 + 2 = 14$ lines). Is it the optimal number of lines needed for this problem? What about general results for $N\times N\times N$ grid?","['graph-theory', 'combinatorics']"
4391817,Jensen's inequality for composition of functions,"I want to prove (or find a counterexample for) the following variant of Jensen's inequality. Let $f$ and $g$ be convex functions (then $f(g(x))$ and $g(f(x))$ are convex functions). From the standard Jensen's inequality, we have $$
\mathbb{E_{\sim i}}[f(g(x_i))] \geq f(g(\mathbb{E_{\sim i}}[x_i]))
$$ or alternatively $$
\mathbb{E_{\sim i}}[f(g(x_i))] \geq f(\mathbb{E_{\sim i}}[g(x_i)])
$$ where in the second case we are only ""extracting"" the first function, but we can take the first as well since the composition of $f,g$ is convex. I would like to know what necessary assumptions on $f,g$ are required such that the following holds: $$
\mathbb{E_{\sim i}}[f(g(x_i))] \geq g(\mathbb{E_{\sim i}}[f(x_i)])
$$ A sufficient condition, of course is that $f\circ g \geq g \circ f$ : $$
\mathbb{E_{\sim i}}[f(g(x_i))] \geq \mathbb{E_{\sim i}}[g(f(x_i))]  \geq g(\mathbb{E_{\sim i}}[f(x_i)])
$$ but this is not very interesting and I was hoping for something more general. Edit: Some additional constraints of interest to consider: $f$ is monotonic, $g$ is sublinear.","['jensen-inequality', 'functions', 'convex-analysis']"
4391818,Pullback of a set is its preimage,"(posting this as a question-answer combo, as figuring out this relation helped me understand the terms, and I hope it might for others) I have heard that the preimage of a function is sometimes referred to the pullback. Specifically, given a map $f:A\to B$ and a subset $E\subseteq B$ , that the preimage of $E$ under $f$ , $f^{-1}(E)$ , may also be called the pullback of $E$ under the map $f$ , $f^*E$ . I have encountered the notion of a pullback several times in geometry where, for example, the pullback of a map $g:B\to C$ under a map $f:A\to B$ may be given as $f^*(g) = g\circ f$ . Is there a relationship between these two concepts?","['pullback', 'functions']"
4391833,The meaning of the indefinite integral symbol the definition of an antiderivative,"I have been thinking that the symbol $$\int f(x) dx$$ is a variable as a whole, referring to $F(x)$ , where $F$ is some antiderivative of $f$ . It can refer to any function that is an antiderivative of $f$ , evaluated at $x$ . So $A =$ the symbol means $A$ is equal to some function evaluated at $x$ , and that function is some unknown antiderivative of $f$ . Does this symbol mean above? Am I correct? Also, What is the precise definition of an antiderivative of a function? What is the definition that is most commonly accepted? What is the one that I write, others will know what I am referring to? Is there one? I need to know it because the symbol is based on an “antiderivative”. According to Wikipedia, an antiderivative of $f$ is $F$ such that $F' = f$ . And two functions are equal iff their domains are the same and outputs are the same for each input from the domain. By that definition, $F: \mathbb{R} \rightarrow \mathbb{R}$ , $F(x) = C$ is not an antiderivative of $f: (0,1) \rightarrow \mathbb{R}$ , $f(x) = 0.$ Is this also correct? Is it the commonly accepted definition of an antiderivative?","['calculus', 'analysis']"
4391995,Ratio of Poisson Distributions (Possible mistake on exams by instructor),"I found the following on a practice final of one of my students and it does not seem to add up. Let $X_1, X_2, \dots, X_n$ be a random sample from a Poisson distribution $f(k\vert \theta) = \frac{e^{-\theta}\theta^k}{k!}$ where $k \in \mathbb{N}$ . Show that $S(X)= \frac{X_1}{\sum_{i=1}^n X_i}$ is an ancillary statistic (i.e. its distribution does not depend on $\theta$ ). I think what they have in mind is that the above expression is scale invariant which it is. The issue is however twofold: $S$ is not well defined when $X_1 = X_2 = \dots = X_n = 0$ which happens with non-zero probability. The scale invariant property of the expression is not sufficient. One also needs to show that the $X_i$ 's follow what is known as the scale model, namely there are Random Variables $W_i$ which do NOT depend on $\theta$ and a constant $c$ such that: $X_i = cW_i$ . To my knowledge this is not the case for Poisson. Is this a case of a simple oversight or am I missing something obvious? (Note: This is a standard graduate course in statistics where students are expected to identify various kinds of statistics (sufficient, complete, ancillary etc) and apply these ideas to relevant theorems such as Basu's theorem.)","['statistics', 'poisson-distribution']"
4392007,"Examples of non-elementary integrals, but whose definite integral IS solvable with power series.","In a high-school level calculus course you learn about Taylor series and some basic integration techniques. In my experience, most definite-integration exercises boiled down to finding an antiderivative and then evaluating at the endpoints using the F.T.C. Sometime after this, I learned that non-elementary integrals existed. This meant that the finding-antiverivative technique wasn't going to work on these types of integrals. However, I was surprised to find out some of these non-elementary integrals had definite integrals with concise closed forms! Most of these integrals are usually solved using more advanced techniques like multivariable calculus and complex analysis, but not all of them. This got me thinking... How many examples of non-elementary integrals, but whose definite integral is solvable with power series, can I find? I believe these types of integrals would be great examples in a high-school course, since they break away from the monotony of the ""Find antiderivative and plug-in values"" recipe used in most exercises, with the added bonus of sometimes giving very insightful solutions in the process. One example of this type of integral is $\int_0^1 \frac{\ln(x)}{x-1} \mathrm{d}x = \frac{\pi^2}{6}$ . Since the antiderivative of $\frac{\ln(x)}{x-1}$ is given in terms of a polylogarithm function, it isn't elementary. However, using the power series for $\frac{1}{x-1}$ and interchanging the sum and integral we can achieve the result given in the answer above. Besides the example above, I haven't managed to find many other examples like this. Does anyone know of some other definite integrals like the above? Any and all suggestions are welcome. Thank you very much!","['integration', 'definite-integrals', 'big-list', 'elementary-functions', 'sequences-and-series']"
4392069,Prove a quotient space and a subspace are isomorphic,"Let $V_1$ and $V_2$ be subspaces of a vector space $V$ such that $V=V_1+V_2$ . Let $\alpha$ be a basic for $V_1 \cap V_2$ . Extend $\alpha$ to a basic $\alpha \cup \alpha_1$ for $V_1$ and $\alpha \cup \alpha_2$ for $V_2$ . (where $\alpha$ , $\alpha_1$ and $\alpha_2$ are pairwise disjoint). Define $V'=span\,\alpha_2$ . I need to prove that $V/V_1$ is isomorphic to $V'$ . I tried to prove that $V=V_1 \oplus V'$ but failed. Also I tried to construct an isomorphism but found out that it isn't well-defined. Any thoughts about this question?","['linear-algebra', 'vector-spaces', 'linear-transformations']"
4392101,"How many method to evaluate the integral $\int_{0}^{1} \frac{\ln ^{n}(1-x)}{x} d x , \textrm{ where }n\in N?$","$$
\begin{aligned}
\int_{0}^{1} \frac{\ln (1-x)}{x} d x &\stackrel{x \rightarrow 1-x}{=} \int_{0}^{1} \frac{\ln x}{1-x} d x \\
&=\sum_{k=0}^{\infty} \int_{0}^{1} x^{k} \ln x d x \\
&=\sum_{k=0}^{\infty} \int_{0}^{1} \ln x d\left(\frac{x^{k+1}}{k+1}\right) \\
& \stackrel{I B P}{=} \sum_{k=0}^{\infty}\left(\left[\frac{x^{k+1} \ln x}{k+1}\right]_{0}^{1}-\int_{0}^1{\frac{x^{k}}{k+1}} d x\right) \\
&=-\sum_{k=0}^{\infty} \frac{1}{(k+1)^{2}} \\
&=-\zeta(2)
\end{aligned}
$$ Similarly, $$
\begin{aligned}
\int_{0}^{1} \frac{\ln ^{2}(1-x)}{x} d x 
\stackrel{x\mapsto 1-x}{=}  & \int_{0}^{1} \frac{\ln ^{2} x}{1-x} d x \\
=& \sum_{k=0}^{\infty} \int_{0}^{1} x^{k} \ln ^{2} x d x \\
\stackrel{IBP}{=} & \sum_{k=0}^{\infty} \frac{1}{k+1}\left(\left[x^{k+1} \ln ^{2} x\right]_{0}^{1}-\int_{0}^{1} 2 x^{k} \ln x d x\right) \\
\stackrel{IBP}{=}&-2 \sum_{k=0}^{\infty} \frac{1}{k+1}\left(\left[\frac{x^{k+1}\ln x}{k+1}\right]_{0}^{1}-\int_{0}^{1} \frac{x^{k}}{k+1} d x\right) \\
=& 2 \sum_{k=0}^{\infty} \frac{1}{(k+1)^{3}} \\
=& 2 \zeta(3)
\end{aligned}
$$ Replacing the power of $\ln x$ by $n$ and performing integration by parts by $n$ times yields $$
\begin{aligned}\int_{0}^{1} \frac{\ln ^{n}(1-x)}{x} d x &\stackrel{x\mapsto 1-x}{=} \int_{0}^{1} \frac{\ln ^{n} x}{1-x} d x\\ &\qquad\qquad \vdots \\&= (-1)(-2)(-3) \cdots(-n) \sum_{k=0}^{\infty} \frac{1}{(k+1)^{n+1}}\\&= (-1)^{n} n ! \zeta (n+1)\end{aligned}
$$ My Question Is there an alternative method to evaluate the integral?","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
4392159,Optional process,"I'm interested in proving that any optional process is adapted.
Here optional and adapted are used in the conventional sense but the precise definitions can be found here . In the proof I'm actually using I'm confuse with two statements: If $X$ is optional then $X^n:=X 1_{|X|<n}$ is also optional Noting $\mathcal{O}_b$ for the set of all the optional bounded process and $\mathcal{M}:=\{$ all  bounded RCLL process $\}$ we have $\mathcal{O}_b=\sigma(\mathcal{M})$ or at least $\mathcal{O}_b \subset \sigma(\mathcal{M})$ Of course all the objects are defined on the same probability space $(\Omega,\mathcal{F},\mathbb{P} )$ I'm stuck in proving that both this statements are valid and I will greatly appreciate any help :) Thanks by advance, Arthur","['stochastic-processes', 'brownian-motion', 'probability-theory']"
4392229,Evaluate $\lim_{n\to\infty} \sqrt{n}\int_{0}^{\pi/2} \sin^{n} x dx$,"Question: Compute $I_n=\lim\limits_{n\to\infty} \sqrt{n}\int_{0}^{\frac{\pi}{2}} \sin^{n} x dx$ . Attempt: We know the famous result that $\lim\limits_{n\to\infty}\int_{0}^{\frac{\pi}{2}} \sin^{n} x dx=0$ , and by dividing it into two parts $\int_{0}^{\frac{\pi}{2}-n^{-\alpha}}+\int_{\frac{\pi}{2}-n^{-\alpha}}^{\frac{\pi}{2}}(0<\alpha<\frac{1}{2})$ , we can show that $\int_{0}^{\frac{\pi}{2}} \sin^{n} x dx=O(\frac{1}{n^{\alpha}})$ . There is a hint which says by substitution we can rewrite the limits with $\Gamma$ , and eventually get $I_n\sim c\frac{1}{\sqrt{n}},c>0$ . Is there any method without using the $\Gamma$ function? (Answers using Gamma function are also appreciated.)","['limits', 'asymptotics', 'real-analysis']"
4392349,State the likelihood function,"Im learning something about likelihood function and there is a task in my book. But I'm not sure if I did it correctly could you help with some tips? Following task: Clients are lining up in a post office. We record the time $t_1, \ldots, t_N$ in minutes required to serve the $N$ consecutive
clients. We distinguish between two types of clients, those that are coming to send a packet, and those that are
coming to send a letter (and whose service is typically twice faster). Service times for all clients are independent,
and drawn from an exponential distributions with rate dependent on whether the client sends a packet or a letter: $$p(t_i\mid\theta) = \theta \exp(-\theta t_i) \tag{packet}$$ $$q(t_i\mid\theta) = 2\theta \exp(-2\theta t_i) \tag{letter}$$ and where $\theta$ is a parameter between $0$ and $\infty$ to be learned. Consider six clients, the first two wanted to send a packet, and stayed at the post office for $2$ and $5$ minutes
respectively. The last four clients wanted to send a letter and were served in $1$ minute each. State the likelihood function measuring the joint probability of observing all these events. My problem here is, that I have the Data $D$ and the information about six Clients. How do I combine this informations? My solution(s): 1: $$P(t_1, \ldots, t_ND\mid\theta) = \prod_{i=1}^N (\theta \exp(-\theta t_i))^2 \cdot (2\theta \exp(-2\theta t_i))^4$$ 2: Just consider the six given clients. $$P(2,5,1,1,1,1\mid\theta) = \theta \exp(-2\theta ) \cdot \theta \exp(-5\theta) \cdot (2\theta \exp(-2\theta))^4  $$","['machine-learning', 'probability-theory', 'probability', 'maximum-likelihood']"
4392353,Chain rule multivariable calculus.,"I have problem understanding the chain rule. For example consider a function $w = f(x,y)$ and $y=x^2$ . By the chain rule: \begin{equation}
\frac{\partial w}{\partial x} = \frac{\partial w}{\partial x}\frac{\partial x}{\partial x}+\frac{\partial w}{\partial y}\frac{\partial y}{\partial x} = \frac{\partial w}{\partial x}+2x\frac{\partial w}{\partial y}
\end{equation} so $\frac{\partial w}{\partial y} = 0$ . What is wrong with this reasoning? Can you give some example to show that this is not true?","['multivariable-calculus', 'calculus', 'chain-rule']"
4392386,Total number of subsets in a set,"I was reading about subsets, in that, the article suggests the total number of subsets in a set is $2^n$ , where $n$ is the number of elements in the set. For example - $\{1, 2, 3, 4, 5\}$ the total number of subsets is $32$ because $n$ is $5$ and $2^5$ is 32 by multiplicative principle. But the multiplicative principle is that if m events can happen in n ways then the possible outcomes are $m \times n$ . So in the subsets problem if every element has $2$ possibilities of it being in set or not being in set why is it not $2 \times 5$ and $2 ^ 5$ ? I know that the $2 ^ 5$ is correct but not able to visualize it.","['elementary-set-theory', 'discrete-mathematics']"
4392414,Doubt in the proof of Blichfeldt's Theorem given in Wiki,"Suppose we are drawing some patches in a paper of size $1\times 1$ . In the end, we discover that the sum of the area of all the patches is $>n$ . Prove that there must exist at-least one point such that it lies in at-least $n+1$ of the patches. This was a part in the proof of Blitchfeldt Theorem . The proof given in the link does not really seem convincing to me. The idea of contributions of points towards the area doesn't seem rigorous or at-least needs more justification in my opinion. So I was trying a ""set-theoretic"" approach, but could not get far. Progress: When $n=1$ , if no two patches have a area in common, then they all lie inside a square of area 1 and are disjoint, hence their total area can not exceed $1$ . I could also show it for the case $n=2$ . But could not for $n>2$ . Any help would be appreciated.","['combinatorics', 'discrete-mathematics']"
4392416,How to interpret $dx$ on its own in differential equations?,"I have come across some variations in the notation of differential equations that seem to be so obvious to everybody that nobody cares to explain the meaning properly. There is a notation version that I understand like e.g. this one representing angular change in a pendulum $$\ddot{x}(t) = - \mu \dot{x}(t) -\frac{g}{L} \sin(x(t))$$ which should be the same as $$\frac{d^2x}{{dt}^2}(t) = - \mu \frac{dx}{dt}(t) -\frac{g}{L} \sin(x(t))$$ where I understand $\frac{dx}{dt}(t)$ as in the rigorous analysis definition $$\frac{dx}{dt}(t) := \lim_{h \to 0}\frac{x(t+h)- x(t)}{h}$$ To me $\frac{dx}{dt}$ was until now a kind of mnemonic representation for the idea that we look at the tiny changes in the function output given a tiny change in function input and see what happens when that tiny input change goes to $0$ . Now I see differential equations like this one defining the Ornstein-Uhlenbeck process: $$dX_t =  \theta \cdot ( \mu - X_t) dt + \sigma dW_t$$ Of course this is different in a variety of ways but my question is with regards to the use of $dX_t$ or $dt$ . In the first equation the $dx$ 's and $dt$ 's seemed to occur only together, representing the rigorous definition of the derivative via a limit. Here they seem to have a life of their own and a separate meaning. How can one (1) interpret and (2) handle terms like $dX_t$ or $dt$ arithmetically when they stand alone like this?","['derivatives', 'stochastic-differential-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
4392429,The commutator map,"I am trying to study the commutator map of a given Lie group $G$ : $$\mu : G\times G\to G,\ \mu(x,y)=[x,y]=xyx^{-1}y^{-1}$$ I am interested in: Its singular points (where the  the differential is not onto). Its fibers, are connected or not? After some long computations, I get: $$D_{(x,y)}\mu(u,v)=D_xR_{yx^{-1}y^{-1}}(u)-D_x\left(L_{xyx^{-1}}\circ R_{x^{-1}y^{-1}}\right)(u)+D_y\left(L_x\circ R_{x^{-1}y^{-1}}\right)(v)-D_y\left(L_{xyx^{-1}y^{-1}}\circ R_{y^{-1}}\right)(v)$$ Where $L_x$ and $R_x$ are the left and right translations of $G$ . Apart from the obvious singular point $(e,e)$ , I don't see how to find the singular points in the cases: $G=SL(2), SU(2), GL(2)$ ? Is there a nice reference where this map is studied in detail? Same question for the map: $$c(x_1,...x_{2g})=[x_1,x_2]...[x_{2g-1},x_{2g}]$$","['multivariable-calculus', 'singularity-theory', 'lie-groups']"
4392446,Weird Problem on Polynomial Roots,"The polynomial $f(x)=x^3-3x^2-4x+4$ has three real roots $r_1$ , $r_2$ , and $r_3$ . Let $g(x)=x^3+ax^2+bx+c$ be the polynomial which has roots $s_1$ , $s_2$ , and $s_3$ , where \begin{align*}
s_1 &= r_1+r_2z+r_3z^2, \\
s_2 &= r_1z+r_2z^2+r_3, \\
s_3 &= r_1z^2+r_2+r_3z,
\end{align*} and $z=\dfrac{-1+i\sqrt3}2$ . Find the real part of the sum of the coefficients of $g(x)$ . I know the sum of the coefficients is $g(1)$ , $g(x)=(x-s_1)(x-s_2)(x-s_3)$ , and $z^3=1$ . This means $s_1z=s_2$ , and $s_2z=s_3$ . Since $s_1^3=s_2^3=s_3^3$ , I have $g(x)=x^3-s_1^3$ . Since the answer is $g(1)$ , I need to calculate $$1-s_1^3.$$ I expanded $s_1^3$ to get $$s_1^3=r_1^3+r_1^2r_2z+3r_1^2r_3z+3r_1r_2^2z^2+6r_1r_2r_3+3r_1r_3^2z+r_2^3+3r_2^2r_3z+3r_2^2r_3z+3r_2r_3^2z^2+r_3^3.$$ I'm pretty sure using Vieta's can finish this, but I'm not sure where else to apply Vieta's other than $r_1r_2r_3$ . I also tried substituting $z^2=-z-1$ , but it didn't do much. I also tried using $(r_1+r_2+r_3)^2$ , but this also failed. Could someone give me some guidance? Thanks in advance!","['algebra-precalculus', 'roots', 'polynomials']"
4392486,Solving a differential equation related to quasihomogeneous polynomials,"I have these equations: $$\frac{dx}{dt}=ax^3+by^2 \quad \text{and} \quad \frac{dy}{dt}=x^2y$$ I need to somehow find an expression for $y(x)$ , and I have been given a hint that I can use the fact that these correspond to ""quasihomogeneous"" polynomials. I understand that this means that the degree of the polynomials $P(x,y):=ax^3+by^2$ and $Q(x,y):=x^2y$ have some special relaltion. Once checked this relation,  to obtain an expression is straightforward, but again I am not sure how to do this. Sorry for the vagueness of this explanation but I am confused and I can not find any references or examples. If you have some other method to deal with the system I will be glad to learn them as well. Thank you!",['ordinary-differential-equations']
4392496,Does $|A\times \mathbb{Q}|=|\mathbb{R}|$ imply $|A|=|\mathbb{R}|$?,"For any sets $A$ and $B$ let $|A|=|B|$ , if there is bijection from $A$ to $B$ . My question is: Does $|A\times \mathbb{Q}|=|\mathbb{R}|$ imply $|A|=|\mathbb{R}|$ ? I began solving this problem by noticing that: $|A \times \mathbb{Q}|=|A \times \mathbb{Z}|$ , since $|\mathbb{Q}|=|\mathbb{Z}|$ . Now we see that there is example of set $A$ satisfying the condition above - When ${A}=[0,1)$ it is clearly true that $|{A} \times \mathbb{Z}|=|\mathbb{R}|$ as we can find the following bijection: $f(x,n)=x+n, x \in {A} ~ n \in \mathbb{Z}$ and we also know that $|{A}|=|\mathbb{R}|$ I thought that maybe $|A \times \mathbb{Z}|=|B \times \mathbb{Z}|$ implies $|A|=|B|$ which would allow to solve the problem easily, but this unfortunately isn't true (For example when $A=\{1\}~ B=\{1,2\}$ ) Now I'm thinking about using some contradiction, but really I have no idea how to solve this problem.",['elementary-set-theory']
4392567,Is there a math theorem by which a contour integral is equal to a double integral?,"I was reading Maxwell's relations and came across: $$\oint pdV=\oint TdS\Rightarrow \iint dpdV=\iint dTdS.$$ I know this is straightforward to see since they both represent the surface area, but I've never seen a math theorem on textbooks that indicates $$\oint ydx=\iint dxdy.$$ Is this just a trivial corollary?",['integration']
4392596,"Differentiability of the functions $\mathbf{f}:\mathbb{M}_{n\times n}\to \mathbb{M}_{n\times n},\ \mathbf{f}(A)=A^2,\ \mathbf{f}(A)=A^T A$","I am trying to prove that the functions $\mathbf{f}:\mathbb{M}_{n\times n}\to \mathbb{M}_{n\times n},\ \mathbf{f}(A)=A^2,\ \mathbf{f}(A)=A^T A$ are differentiable. What I have done: We consider $\mathbf{D}(f_1)(A):H\mapsto AH+HA$ and $\mathbf{D}(f_2)(A):H\mapsto A^TH+H^TA$ . These are linear transformations (*) from $\mathbb{M}_{n\times n}$ to $\mathbb{M}_{n\times n}$ and we want to prove that $$\lim\limits_{H\to [0]}\frac{1}{|H|}\left( (f_1(A+H)-f_1(A)) - (AH+HA) \right)=[0]$$ and $$\lim\limits_{H\to [0]}\frac{1}{|H|}\left( (f_2(A+H)-f_2(A)) - (A^TH+H^TA) \right)=[0].$$ Since $f_1(A)=A^2,$ we have $$|f_1(A+H)-f_1(A) - (AH+HA)|=|A^2+AH+HA+H^2-A^2-AH-HA|=|H^2|;$$ this gives $$\lim\limits_{H\to [0]}\frac{|H^2|}{|H|}\leq\lim\limits_{H\to [0]}\frac{|H||H|}{|H|}=0$$ so $f_1$ is differentiable with derivative $AH+HA$ .\ Similarly, since $f_2(A)=A^TH+H^TA,$ we have $|f_2(A+H)-f_2(A)-(A^TH+H^TA)|=|(A+H)^T(A+H)-A^TA-A^TH-H^TA|=|(A^T+H^T)(A+H)-A^TA-A^TH-H^TA|=|A^TA+A^TH+H^TA+H^TH-A^TA-A^TH-H^TA|=|H^TH|$ ;
this gives $$\lim\limits_{H\to [0]}\frac{|H^TH|}{|H|}\leq\lim\limits_{H\to [0]}\frac{|H^T||H|}{|H|}=\lim\limits_{H\to [0]} |H^T|=0$$ so $f_2$ is differentiable with derivative $A^TH+H^TA.$ $f_1(H_1+H_2)=A(H_1+H_2)+(H_1+H_2)A=AH_1+AH_2+H_1A+H_2A=(AH_1+H_1A)+(AH_2+H_2A)=f_1(H_1)+f_2(H_2),$ $f_1(cH))=A(cH)+(cH)A=cAH+cHA=c(AH+HA)=cf_1(H),$ $f_2(H_1+H_2)=A^T(H_1+H_2)+(H_1+H_2)^TA=A^TH_1+A^TH_2+H_1^TA+H_2^TA=(A^TH_1+H_1^TA)+(A^TH_2+H_2^TA)=f_2(H_1)+f_2(H_2),$ $f_2(cH)=A^T(cH)+(cH)^TA=cA^TH+cH^TA=c(A^TH+H^TA)=cf_2(H)$ for all $H,H_1,H_2\in\mathbb{M}_{n\times n},\ c\in\mathbb{R}$ Is this correct? Thanks for the feedback.","['differential', 'multivariable-calculus', 'derivatives']"
4392597,Derivative of matrices involving transpose and inverse,"I have an equation which looks like this: $$Z = [{A(A^TA + \lambda I)^{-1}A^TB - B}]^T[{A(A^TA + \lambda I)^{-1}A^TB - B}]$$ Here, $\lambda$ is scalar ( $\lambda > 0$ ) and $I$ indenty matrix such that $$\mathbf{\lambda I}=\begin{bmatrix}
\lambda & 0\\
0 & \lambda\\
\end{bmatrix}$$ I want to find $\frac{\partial Z}{\partial \lambda}$ in order to prove that if $\lambda_1 \geq \lambda_2$ then $Z_1 \geq Z_2$ . Here, is what I tried $\frac{\partial Z}{\partial \lambda} = \frac{\partial}{\partial \lambda} [{A(A^TA + \lambda I)^{-1}A^TB - B}]^T[{A(A^TA + \lambda I)^{-1}A^TB - B}]$ $\frac{\partial Z}{\partial \lambda} = 2\frac{\partial}{\partial \lambda} [{A(A^TA + \lambda I)^{-1}A^TB - B}]$ ...( $\frac{\partial X^TX}{\partial X}$ = 2X) $\frac{\partial Z}{\partial \lambda} = 2[\frac{\partial}{\partial \lambda} (A) * [(A^TA + \lambda I)^{-1}A^TB] + A[\frac{\partial}{\partial \lambda} (A^TA + \lambda I)^{-1} * (A^TB) + (A^TA + \lambda I)^{-1} * \frac{\partial}{\partial \lambda}A^TB]
 - \frac{\partial}{\partial \lambda}B]$ ...( $\frac{\partial MN}{\partial X}$ = MN' + M'N) $\frac{\partial Z}{\partial \lambda} = 2[0 * [(A^TA + \lambda I)^{-1}A^TB] + A[\frac{\partial}{\partial \lambda} (A^TA + \lambda I)^{-1} * (A^TB) + (A^TA + \lambda I)^{-1} * 0]- 0]$ ...( $\frac{\partial A}{\partial \lambda}$ = 0, $\frac{\partial B}{\partial \lambda}$ = 0, $\frac{\partial A^TB}{\partial \lambda}$ = 0) $\frac{\partial Z}{\partial \lambda} = 2A\frac{\partial}{\partial \lambda} (A^TA + \lambda I)^{-1} * (A^TB)$ $\frac{\partial Z}{\partial \lambda} = -2A(A^TA + \lambda I)^{-1}\frac{\partial}{\partial \lambda} (A^TA + \lambda I) * (A^TA + \lambda I)^{-1}*(A^TB)$ ...( $\frac{\partial M^{-1}}{\partial X} = -M^{-1}M'M^{-1}$ ) $\frac{\partial Z}{\partial \lambda} = -2A(A^TA + \lambda I)^{-1}I(A^TA + \lambda I)^{-1}(A^TB)$ ...( $\frac{\partial (A^TA + \lambda I)}{\partial \lambda} = I$ ) I am unsure of this answer since I expected the derivative to be positive so that the above statement/proof can be proved.","['matrices', 'calculus', 'matrix-calculus', 'derivatives']"
4392630,Show that $\quad \vec{x}^TA\vec{x}=\frac{1}{2}\vec{x}^T(A^T+A)\vec{x}$,Let $A\in\mathbb{R}^{n\times n}$ and $\vec{x}\in\mathbb{R}^{n\times 1}$ Show that $\quad \vec{x}^TA\vec{x}=\frac{1}{2}\vec{x}^T(A^T+A)\vec{x}$ My try: We know that $$A=\frac{1}{2}(A+A^T)+\frac{1}{2}(A-A^T)$$ Then $$\vec{x}^TA\vec{x}=\vec{x}^T(\frac{1}{2}(A+A^T)+\frac{1}{2}(A-A^T))\vec{x}$$ $$=\frac{1}{2}\vec{x}^T((A+A^T)+(A-A^T))\vec{x}$$ $$=\frac{1}{2}\vec{x}^T((A+A)\vec{x}$$ Which is not quite what I want. Any suggestions of how to keep going would be great!,"['matrices', 'linear-algebra', 'symmetric-matrices']"
4392643,Measure preserving transformation that makes two partitions independent,"I am looking for a reference for the following result.  I think it is pretty well known but I haven't found it written down anywhere. Let $(X, \mathcal{B}, \mu)$ be a standard nonatomic measure space and let $\mathcal{P}, \mathcal{P'}$ be two finite measurable partitions of $X$ .  Then there is a map $\varphi: X \to X$ which preserves the measure $\mu$ and such that the partitions $\mathcal{P}$ and $\varphi^{-1}\mathcal{P'}$ are independent with respect to $\mu$ . (Two partitions $\mathcal{P}$ and $\mathcal{Q}$ are independent with respect to $\mu$ if for any two cells $A \in \mathcal{P}$ , $B \in \mathcal{Q}$ , $\mu(A \cap B) = \mu(A)\mu(B)$ .)","['measure-theory', 'ergodic-theory', 'reference-request']"
4392679,Motion in plane,"A particle moves in the plane with an acceleration that is parallel to the y-axis and proportional to the distance from the x-axis. If the acceleration is attractive (that is, directed toward the x-axis), then show that the equation of the path may be written in the form $y = A\cos(mx + B)$ . If the acceleration is repulsive (directed away from the x-axis), on the other hand, then show that the path will be given by an equation of the form $ y = Ae^{mx} + Be^{-mx}$ .","['integration', 'definite-integrals', 'analysis', 'calculus', 'derivatives']"
4392774,Example of a Chief series [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Can you give an example of a non solvable group whose at least one Chief factor is a product of more than one simple group (i.e. it should not be a simple group). Edit: Thanks @HallaSurvivor for suggestion. I am a Research scholar in mathematics. I have enough background in group theory. The reason why I am asking this questions is that I have not study this concept of Chief series before. Almost all the example I have seen has the chief factors which are simple. But by definition it can be product of simple. So I just wanted to see such examples.
Thank you!","['group-theory', 'normal-subgroups', 'examples-counterexamples']"
4392844,Tracing a circle by a sliding triangle,"An isosceles triangle with a unit length base is sliding on two lines which make an angle of $60^\circ$ between them.  The third vertex traces a circle centered at the intersection of the two lines.  What is the altitude of the triangle, and what is the radius of the circle ? What I have tried: I found the coordinates of points $X$ and $Y$ as shown above on the two lines in terms of the angle $\theta$ , then found the coordinates of the tip of the triangle (the third vertex) as a function of $\theta$ , and finally found the altitude $h$ that results in the distance of this tip from the origin being constant.  And that constant is the radius of the circle.","['analytic-geometry', 'triangles', 'vectors', 'geometry']"
4392854,Polar of a circle.,"So, I was doing some analytical geometry, circles to be precise. There, the concept of polar was introduced as: ""If through a point P (within or without the circle) there be drawn any straight line to meet the circle in Q and R, the locus of the point of intersection of tangents at  Q and R is called the polar of P; also P is called the pole of the polar.""
Now, this locus comes out to be of the form of a straight line which passes through the circle if P lies outside the circumference of the given circle. My doubt is, if the polar is a locus of points of intersection of tangents of a circle, how can it pass through the inside of the circle since that would mean that there are intersection points of two tangents of circle lying inside it, which is downright impossible. Are there ""imaginary"" points of contact to be considered.
P.S.: The book I refer to is The Elements of Coordinate Geometry by S.L. Loney, it hasn't left me in doubts yet.","['analytic-geometry', 'circles', 'geometry']"
4392997,"Let $A=\{1,2,...,10\}$ and $B=\{41,42,...,50\}$. Find number of subsets of $S$, which have non-empty intersection with both $A$ and $B$.","Let $S=\{1,2,...,100\}$ and let $A=\{1,2,...,10\}$ and $B=\{41,42,...,50\}$ . What is the total number of subsets of $S$ , which have non-empty intersection with both $A$ and $B$ . My Attempt: Let $C$ be the desired subset. Number of ways to select atleast one element from $A$ is $2^{10}-1$ and from $B$ is also $2^{10}-1$ . And the remaining $80$ elements have $2$ choices each i.e. they may be in C or they may not be in $C$ . So total number of possible subsets is $2^{80}\left(2^{10}-1\right)^2$ Is it correct? Can the problem be solved by some other method","['combinations', 'combinatorics']"
4393072,How to solve thisrecurrence relation? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question $f(n)=\frac{1+f(n-1)}{f(n-2)}$ $f(0)=a$ $f(1)=b$ I can't figure out how to solve this. If you multiply both parts by $f(n-2)$ , you get $f(n)f(n-2)-f(n-1)-1=0$ , and I don’t understand how to make a characteristic equation from this (I don’t understand, what to do with $f(n)f(n-2)$ ).","['recurrence-relations', 'discrete-mathematics']"
4393084,`Conformal class' in Riemannian geometry vs Complex Analysis,"Recently I found myself a bit confused about the definition of conformality. In Riemannian geometry, we say that two metrics on a manifold $M$ , $g$ and $h$ are in the same conformal class if there exists a function $\mu:M\rightarrow\mathbb{R}$ such that, \begin{equation}
g = e^\mu h \tag{$\ast$}.
\end{equation} The point of confusion for me was this: the uniformization theorem says that there is only one conformal class on the sphere $\mathbb{S}^2$ . This, however, does not mean that two Riemannian metrics on a sphere can be related like ( $\ast$ ), but that there is a diffeomorphism $\varphi:\mathbb{S}^2\rightarrow\mathbb{S}^2$ such that $\varphi^*g=e^\mu h$ . Why is there a difference between the definitions of conformality in complex analysis (as in the Uniformization theorem) and Riemannian geometry? What does conformal class mean in complex analysis (is it different from the definition for Riemannian metrics)?","['complex-analysis', 'conformal-geometry', 'riemannian-geometry', 'differential-geometry']"
4393159,"Variable or constant, and Dependence among variables","I've been working with symbolic Mathematics for a very long time, but I still have many small questions relating to the idea of a 'constant' and the idea of change with respect to variables, and their co-dependence. I will warn that this may be slightly difficult to express to you. Primarily it is the following: When we are using a symbolic relationship with variables (I'm going to use the most simple definition of the idea as a variable representing an unspecified number) that change, such as the following: $$y=2x+1$$ Or (ignoring the binding operation of function definition): $4f(x)=x^2+\sin(x)$ (function $f$ at the point $x$ ) Such equations are designed to specify varying quantities, and here we have a relationship that holds for pairs of values $(y,x)$ and $(f(x),x)$ and in the context of this problem, we have a relation that holds for various values. It is possible to discuss the situations where two independent values can have the same value, but we cannot draw a distinction between something like $a=b$ for two independent varying quantities $a$ and $b$ and a relation that holds for multiple pairs of values (such as $y=2x+1$ ) where the variables are dependent, however how do we deal with the fact that $a$ and $b$ are able to change, but in this context we're only discussing a relation between values that they are equal, which they do not need to be, but it is still misleading due to this relation, and almost seems to imply they are not independent. This raises a point another common thing we do is having a formula such as $y=2x+1$ we might want to solve for a value, but when doing this we still use the original variable, almost like we are saying, 'in the context where $x$ is...' and then we solve the equation using the original variable $x$ , this seems somewhat misleading, as the relation e.g. $2x+1=3$ is not a relation that can hold for the varying quantity $x$ as it can only be existentially quantified, this brings questions about how to represent the idea of change and context once again. We also use the idea of a 'constant' and we might represent it with $a$ , which brings the first question, how can it be 'constant' if we literally express it as a variable, any number can go into this expression, again, we can use the idea of context, in a given context we can say similarly have a value ' $a$ ' that is 'constant' and talk about the 'point' $x=a$ and the limit 'at the point $x=a$ , once again this idea causes an issue, if we want to talk about many 'contexts' defining $x=a$ is misleading as $x$ and $a$ are 'changing' and again that could imply that $x$ and $a$ are not independent, which is required if $a$ is to be 'constant'. Can we talk about scenarios for different values of a constant, analyzing and replacing the value? Do we need to change the way we talk about them? How should I approach clearing up this confusing situation regarding notation, and dependence between variables, as a result of the use of 'constants'?","['notation', 'functions', 'soft-question', 'terminology']"
4393199,$\operatorname {Spec}$ versus $\operatorname {MaxSpec}$,"If $R$ is a ring, it  is known that $\operatorname {MaxSpec}R$ can be equipped  with a topology: the one induced by $\operatorname{Spec}R$ . Furthermore, if $A\to B$ is a morphism of finitely generated algebras over an algebraically closed field $k$ ,  the map $f:\operatorname {Spec}B\to \operatorname {Spec}A$ induces a map $\operatorname {MaxSpec}B\to \operatorname {MaxSpec}A$ , by restriction. As usual denote with $V(I)\subseteq \operatorname {Spec}R$ the vanishing set of the ideal $I\subseteq R$ , and write $Z(I)$ for $V(I)\cap \operatorname {MaxSpec}R$ . It makes sense to think if, for ideals $I,J$ in respectively $A,B$ , the following equalities hold: $$fZ(J)=fV(J)\cap \operatorname{MaxSpec} B;$$ $$f^{-1}Z(I)\cap \operatorname{MaxSpec} A=f^{-1}V(I)\cap \operatorname{MaxSpec} A.$$ Observe also that the radical of an ideal in a $k$ -algebra is the intersection of the maximal ideal over it, so in this setting the max spectrum is a dense set in the spectrum. Therefore the problem can be reduced as it follows. Let $X'\subseteq X,Y'\subseteq Y$ be dense subsets of two topological space, and let $g:X\to Y$ be a map such that $gX'\subseteq Y'$ . So $(g^{-1}(S^r))^r=(g^{-1}S)^r$ , where $S\subseteq Y$ and $-^r$ denotes the restriction to $X'$ ; this is clear even without the hypothesis that $X',Y'$ are dense, and shows the second equality. Instead the first equality becomes $g(S^r)=(gS)^r$ , where $S\subseteq X$ and $-^r$ denotes the restriction to $Y'$ ; this is true if $S$ is closed, because if a prime $\mathfrak p$ contracts to a maximal ideal $\mathfrak m$ , also the contraction of any maximal containing $\mathfrak p$ is $\mathfrak m$ . I don't know precisely what topological result I used, I know very little of that branch, I'd say something similar to: if every point of $V$ is closed and $U$ is a space with a dense subset $U'$ , whose points are all closed, for any closed $S\subset U$ and $S\cap U'$ has the same image. What do you think about this argument, does it hold? The motivation for my answer is that I often don't know how the results that I see for the spectrum can be used when working with the max spectrum, for the $k$ -algebras. Thank you in advance","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
4393203,Showing that the derivative of a vector-valued function is the the derivative of it's components using linear operators,"Recently in class we had shown the following to be true using a proof that's equivalent to this ProofWiki article : Let $\vec{r}(t) = x(t)\vec{i} + y(t)\vec{j} + z(t)\vec{k}$ be a
vector-valued function on $\left(a,b\right) \rightarrow \mathbb{V}^3$ whose components $x(t), y(t), z(t)$ are differentiable real functions.
Then $\vec{r}$ is differentiable and: $$\vec{r}'(t) = x'(t)\vec{i} + y'(t)\vec{j} + z'(t)\vec{k}$$ Now while the linked proof is straightforward enough, I was thinking about differentiation in the context of a linear operator. My argument was: since differentiable real functions form a vector space and differentiation was a linear operator, then the theorem above immediately follows from the linearity property. Like this: Let $x(t), y(t), z(t)$ be vectors from the vector space of real differentiable functions and let $$\vec{r}(t) = x(t)\vec{i} + y(t)\vec{j} + z(t)\vec{k}$$ Apply linear operator of differenitation and use linearity: $$\vec{r}'(t) = \left(x(t)\vec{i} + y(t)\vec{j} + z(t)\vec{k}\right)' = x'(t)\vec{i} + y'(t)\vec{j} + z'(t)\vec{k}$$ When I asked my professor about this, he said that this cannot be done because I've applied linearity incorrectly, but upon further questioning he was unable to answer why. It seems valid to me, so I want to ask, is this a valid way to show the theorem? It seems much more elegant than using parametric limits. The only possible problem I can see is the multiplication of vectors $x(t), y(t), z(t)$ with $\vec{i}, \vec{j}, \vec{k}$ since they are from different vector spaces. But since $x,y,z$ are real valued, it is, in a way, equivalent to scalar-vector multiplication.","['multivariable-calculus', 'linear-algebra']"
4393209,A problem with two shuffled decks of cards and the expectation value,"I found this problem while preparing for interviews. The same problem is asked here . You have two decks of (52) distinct cards. You shuffle each deck. Now you keep drawing the top card from each of the two decks and you compare the two top cards. If they are the same card, you get one point. Otherwise, you get zero points. You then throw the two cards away (so there is no repetition). You keep drawing cards until both decks are exhausted (so 52 times in total). What is the expected number of points you receive? I have an idea on how to approach this and it would be great to get some feedback and/or alternative ideas. I draw one card for the left deck and I ask what's the probability that the card drawn from the right deck matches. I define $X_i$ the random variable that for the $i$ -th draw is equal to 1 if the cards are the same and 0 otherwise. The total number of points is therefore $N=\sum_{i=1}^{52} X_i$ , with $E[N]=\sum_{i=1}^{52} E[X_i]$ . Now I could use the fact that for the expectation value $E[X_i]$ it holds that $E[X_i]=\sum P(Y_i)E[X_i|Y_i]$ , where $Y_i$ is the random variable associated to the event that the matching card is present in the right deck at the $i$ -th draw. The probability $P(Y_i)$ is $\frac{53-i}{52}$ and we have that $E[X_i|Y_i]=\frac{1}{53-i}\cdot 1$ , being $\frac{1}{53-i}$ the probability to draw the same card from the right deck at the $i$ -th draw. Therefore $E[X_i]=\frac{53-i}{52}\cdot \frac{1}{53-i}=\frac{1}{52}$ . The requested expected number of points is then $E[N]=\sum_{i=1}^{52}\frac{1}{52}=1$ . Many thanks for any comments.","['solution-verification', 'probability']"
4393223,How do I compute the probability in this exercise?,"I need to define the probability space $\Omega$ and it's probability function $\Bbb{P}$ for the following exercise: For a fair die which we toss two times, compute the probability that the parity of the two numbers that show up matches. My Idea was the following. We define $\Omega=\{1,...,6\}^2$ , then $|\Omega|=36$ . We have the following partition into even and odd numbers: $$\Omega=\{1,3,5\}~\dot\cup~\{2,4,6\}=:A~\dot \cup ~B$$ Now let us define $\Lambda\subset \Omega$ such that it contains all pairs $(u,v)$ where $u,v\in A$ or $u,v\in B$ . Case $1$ : $u,v\in A$ . Then we have $3^2=9$ possibilities. Case $2$ : $u,v\in B$ . Then we have $3^2=9$ possibilities. Thus we have $18$ possibilities and $$\Bbb{P}(\Lambda)=\frac{|\Lambda|}{|\Omega|}=\frac{18}{36}=\frac{1}{2}$$ Is this correct so?","['probability-theory', 'probability', 'stochastic-calculus']"
4393225,Spectrum of sum of bounded and compact map,"Assume $X$ is a Banach space and that $T$ is a bounded linear map and $K$ is a compact linear map from $X$ to itself. I need to prove that that if $\lambda$ is in the spectrum of $T$ but is not an eigenvalue of finite multiplicity then $\lambda$ is in the spectrum of $T+K$ . I know some properties of the spectrum of a compact operator, but I am not sure what to say about the sum of a bounded and a compact one. For instance, for a compact operator we know that every $\lambda \neq 0$ in the spectrum has finite multiplicity and is an eigenvalue. But since the sum $T+K$ is not compact in general we can not say much about them at first sight. Also, I know that $T+K$ is Fredholm, but how could this be useful? I would appreciate any hints on the problem. Thanks!","['spectral-theory', 'compact-operators', 'functional-analysis']"
4393228,Shuffled order: A food delivery person is out to delivers 6 dishes to 4 different households,"A food delivery person is out to delivers 6 dishes to 4 different households:
household 1 get dish 1
household 2 get dish 2
household 3 get dish 3,4
household 4 get dish 5,6 A computer malfunction randomly reshuffled the order of the dishes a) what is the sample space of the reordered dishes b) what is the probability that household 1,2,3 did not get all their order? For this problem I assume that the sample space is the possible permutations of the sequence of dishes as for the second question since we get 6! possible reshuffled sequence, and of these possible outcomes there are 4 outcomes where 1,2,3 still get all their orders $$\{(1,2,3,4,5,6), (1,2,3,4,6,5), (1,2,4,3,5,6), (1,2,4,3,6,5)\},$$ so I reasoned that the probability should be $1-\dfrac 4{6!}$ . However, I am not sure if it is the right result, or I should approach problem differently?","['permutations', 'combinatorics', 'probability-theory', 'probability']"
4393280,Why can't I use trig substitution for this integral?,"$
\int \frac x {\sqrt {1-x^2}}dx
$ I was attempting to solve this integral, and it would appear the solution to it is $-\sqrt{1 -x^2}+C$ . When I attempted to solve it, however, I attempted to let $x = \sin\theta$ , making $dx=\cos{\theta}d{\theta}$ $
\int \frac {\sin\theta} {\cos^2\theta}\cos\theta{d\theta} = \int \tan \theta d\theta = \ln|\sec\theta| + C = \ln{\frac 1 {\sqrt {1 - x^2}}}+C = -{\frac 1 2}\ln|1-x^2|+C
$ I don't quite understand why this is incorrect. Now, I do understand that what I had to do to get the correct solution is to let $u=\sqrt {1-x^2}$ , and everything else works out. But can someone explain where I went wrong with my attempt?","['integration', 'trigonometric-integrals']"
4393290,What's the difference between a dense set and an uncountable set?,"I once called a dense set an uncountable set. I was told this was wrong, as the set was dense , and not uncountable . I didn't have the mathematical knowledge to find this confusing, and instead thought I was just mistaken. I still reckon I'm mistaken, but now I don't understand why. A set $X$ is dense iff $\forall x,z \in X$ where $x <z, \ \exists y \in X$ s.t. $x < y <z$ . A set is uncountable if you can't ever count the members in any subset of it. So, let's take the set of naturals. I of course can't count all of the members within the naturals, but I can count all the members in any finite subset of the naturals (of course, since the subset is finite). The problem with an uncountable set, like the set of real numbers, is that finite subsets (that include all members between the lower and upper limits) don't exist. $|[x,z]| = \infty \ \forall x,z \in \Bbb R$ There's an infinite number of members between any two members, and thus all subsets are infinite, which makes counting impossible (hence, uncountable ). Now, maybe there's  way to achieve this uncountability without the set being dense. I just don't see how. Surely, a dense set is an uncountable set and vice versa? EDIT: I took user Pilcrow's adivce, and looked at a proof of the countability of the rationals. If I understand correctly, a set being countable means that there is a formula or algorithm for the next member in line. So, for the rationals, that algorithm could be expressed like this: $\frac ab$ is a rational. $n(\frac ab)$ is the next rational ( next defined by an ordering not of the greatness kind). $$n(\frac ab) = \begin{cases} \frac{a+1}{b} & a+1 < b \\ \frac{1}{b+1} & a +1 = b \end{cases}$$ This would create a countable, ordered multiset, of which the rationals would be a subset. Thus, the rationals are countable (I assume it's impossible to have uncountable subsets of countable sets). From this, I gather that if a poset is dense, it just means that there is no formula/algorithm for the next member, if one is enumerating using the ordering of which the density arises from. To be concrete, $n(\frac ab)$ is undefined if its ordering is so that it is the next number greater than $\frac ab$ . There is no such number, because the rationals are dense when using the greatness ordering. So, now my question is, is this new understanding correct?","['elementary-set-theory', 'real-numbers', 'infinity', 'terminology']"
4393339,Am I wrong or is my professor wrong? (Basic measure theory/set theory),"Edit: Here is an image of the question: Edit 2: In my professor's e-mail reply to me, my professor wrote that, among other things, ""The polynomials of degree $N$ certainly include all the monomials of degree $N$ or less."" Isn't this totally wrong? A polynomial of degree 5 must have nonzero coeffcient $a_5$ , so the set of all polynomials of degree 5 cannot include $x^4$ because $x^4$ has coefficent zero for the $x^5$ term. Is this Twilight Zone stuff or am I missing something totally obvious? In a measure theory course I was given the following problem. Question: Define $A_i = \{ a_i x^i \colon a_i \in \mathbb R\}$ for $i = 0, 1, 2, \dots$ . Construct an increasing sequence of sets that produces $\bigcup_{i = 0}^{\infty} A_i$ . My Answer: To construct the desired sequence of sets, make the definitions \begin{align*}
B_k &:= \bigcup_{j = 0}^k A_j \text{ for } k = 0, 1, 2, \dots \ .
\end{align*} This is an increasing sequence of sets because $\bigcup_{j = 0}^k A_j \subseteq \bigcup_{j = 0}^l A_j$ if $k <  l$ . I assume that the word ``produces"" means that we are expected to prove that $\bigcup_{j = 0}^{\infty} B_j = \bigcup_{j = 0}^{\infty} A_j$ . First consider $x \in \bigcup_{j = 0}^{\infty} B_j$ . Then there is some $k \in \{ 0, 1, 2, \dots \}$ such that $x \in B_k$ , which by definition means that there is some $l \in \{ 0, 1, 2, \dots, k \}$ such that $x \in A_l$ . Therefore $\bigcup_{j = 0}^{\infty} B_j \subseteq \bigcup_{j = 0}^{\infty} A_j$ . Conversely, consider $x \in \bigcup_{j = 0}^{\infty} A_j$ . There is some $k \in \{ 0, 1, 2, \dots \}$ such that $x \in A_k$ , which certainly implies that $x \in B_k$ . Therefore $\bigcup_{j = 0}^{\infty} A_j \subseteq \bigcup_{j = 0}^{\infty} B_j$ . The two paragraphs above prove that \begin{align*}
\bigcup_{j = 0}^{\infty} B_j &= \bigcup_{j = 0}^{\infty} A_j.
\end{align*} Commentary: I was given zero marks for this answer. My professor's feedback was as shown below (this is verbatim; he didn't use LaTeX). what does this formal setting mean. think of a0 a0 + a1x a0 + a1x + a2x^2 ... I don't get this at all. He defines $A_i$ to be the set of all monomials of degree $i$ , unioned with zero. Therefore the union of all $A_i$ is all monomials of any degree. I defined $B_k$ to be the set of all monomials of degree at most $k$ . Clearly the $B_k$ form an increasing sequence and their union is the set of all monomials of any degree. Why is he referring to polynomials in his feedback? I don't get it. Nothing in his definition of $A_i$ permits general polynomials (addition of monomials). For example, $3x + 1 \notin \bigcup_{i = 0}^{\infty} A_i$ , although $1 \in A_0$ and $3x \in A_1$ . I appreciate any feedback because I'm stumped.","['elementary-set-theory', 'measure-theory']"
4393377,Dudley's Inequality can be Loose (Vershynin 8.1.12),"Let $e_1,...,e_n$ denote the canonical basis vectors in $\mathbb{R}^n$ . Consider the set $$T = \left \{ \frac{e_k}{\sqrt{1 + \log k}}, k =1,...,n\right \}$$ Show that $$\int_{0}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)} d\epsilon \rightarrow\infty$$ as $n \rightarrow \infty$ . Here $\mathcal{N}(T,d,\epsilon)$ is the size of the smallest $\epsilon$ -net of $T$ with respect to the metric $d$ . An $\epsilon$ -net in this context is a set $N \subset T$ such that for all $t \in T$ there is an $s \in N$ such that $d(s,t) \leq \epsilon$ . I assume that $d(x,y) = ||x-y||_2$ , although this isn't explicitly stated. Also note,that $\epsilon$ -nets must be  subsets of $T$ I also write $\log$ when really I mean $\ln$ . I've spent quite a bit of time working on this exercise and from what I can tell, unless I've missed the trick completely, is that this example actually does not work. Here is my argument. For convenience, let $v_k = \frac{e_k}{\sqrt{1+\log k}}$ . Let $f_n(k):\{1,...,n-1\} \rightarrow \mathbb{R}_+$ be defined as $$f_n(k) = \sqrt{\frac{1}{1+\log k} + \frac{1}{1+\log n}}$$ It is easy to see that for $1 \leq j < k \leq n$ we have $$||v_j -v_k||_2 = \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log k}} \geq \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log n}} = ||v_j - v_n||_2 =f_n(j)$$ Now let $1 \leq k \leq n-2$ and let $\epsilon \in [f_n(k+1),f_n(k))$ . Let $N$ be an $\epsilon$ -net of $T$ . It must be that for all $j \leq k$ that $v_j \in N$ since the nearest point $$\min_{i \neq j} ||v_j - v_i||_2 = ||v_j - v_n|| = f_n(j) \geq f_n(k) > \epsilon.$$ Therefore $|N| \geq k+1$ since $\{v_1,...,v_k\} \subset N$ and we need at least one more point for $v_n$ .
Also note that $N = \{v_1,...,v_k,v_n\}$ is an $\epsilon$ -net since for all $j \geq k+1$ we have $$||v_j - v_n||_2 = f_n(j) \leq f_n(k+1) \leq \epsilon.$$ This and the lower bound shows that $N$ is best possible and therefore that $\mathcal{N}(T,d,\epsilon) = k+1$ . Also note that for $\epsilon < f_n(n-1)$ the only possible $\epsilon$ -net is $T$ and therefore $\mathcal{N}(T,d,\epsilon) = |T| = n$ for $\epsilon < f_n(n-1)$ . Similarly for $\epsilon \geq f_n(1)$ the set $N = v_n$ is an $\epsilon$ -net. We next put these bounds on $\mathcal{N}(T,d,\epsilon)$ together. First we can use what happens when $\epsilon \geq f_n(1)$ . \begin{align}
\int_0^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\
&= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log 1}d\epsilon \\
&= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon
\end{align} Next we split the integral up \begin{align}
\int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(n-1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\
&= \int_0^{f_n(n-1)} \sqrt{\log(n)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log(i+1)}d\epsilon \\
&= f_n(n-1)\sqrt{\log n} + \sum_{i=1}^{n-2} [f_n(i) - f_n(i+1)]\sqrt{\log(i+1)}
\end{align} So far this is all an exact equality. If we substitute in the definition of $f_n$ into this expression we get $$\sqrt{\frac{\log n}{1+\log (n-1)} + \frac{\log n}{1+\log n}} + \sum_{i=1}^{n-2}\sqrt{\frac{\log(i+1)}{1+\log i } + \frac{\log(i+1)}{1+\log n}}-\sqrt{\frac{\log(i+1)}{1+\log(i+1)} + \frac{\log(i+1)}{1+\log n}}$$ Numerically however this seems to converge to less than 3. So either the series grows incredibly slowly or it is failing to grow to infinity. Any help would be greatly appreciated! Also, if you try replacing $||\cdot||_2$ with $||\cdot||_1$ it doesn't appear to help","['inequality', 'concentration-of-measure', 'probability-theory', 'probability']"
4393390,"$G$ acts transitively on a space $X$. If a function on $X$ is $G$-invariant up to measure zero, is it necessarily a constant (up to measure zero)?","Consider a locally compact Hausdorff $σ$ -compact topological space $X$ and a locally compact Hausdorff $σ$ -compact topological group $G$ acting continuously and transitively on $X$ such that there exists a $G$ -invariant Radon measure $\mu$ on $X$ . Now suppose $f: X \to [0, 1]$ is a Borel-measurable function on $X$ that is a.e. $G$ -invariant. That means for every $g \in G$ we have $f(g x) = f(x)$ for $\mu$ -almost every $x \in X$ . How do you show (if true) that such an $f$ will be constant outside of a set of measure zero? I'm trying to use this to show that any $G$ -invariant measure on $X$ would be unique up to scale using the approach outlined in this answer .","['measure-theory', 'locally-compact-groups', 'haar-measure', 'radon-nikodym']"
4393403,Limit of expectation of a function of sufficient statistics,"Let $h$ be abounded differentiable function on $[0, \infty)$ , vanishing at zero, $h(0)=0$ . If $Z$ has a standard normal distribution, $Z\sim\mathcal{N}(0, 1)$ , find $$\lim_{n\rightarrow \infty}n \mathbb{E}[h(1/(n^2Z^2))].$$ Noticing that $h(1/x^2)$ is absolutely integrable, and that $Z^2$ is the sufficient statistics for exponential family $Z\sim \mathcal{N}(0, \sigma^2)$ , I was trying to relate this problem to calculating the cumulants of $Z^2$ by differential identities of the exponential family. However, I was stuck and not sure whether this is the intended way to solve this problem. Any hints would be greatly appreciated. Solutions using properties of exponential family are preferable, as this is an exercise on this topic.","['statistics', 'probability']"
4393458,Average rate of water dripping from a cylindrical bucket,"Water drips out of the bottom of a cylindrical bucket that is initially full. The rate of dripping is proportional to the height of water column in the bucket. If the rate of dripping at half height is R, then the average rate of dripping until the bucket becomes almost empty is: 1.greater than R 2.R 3. Between R/2 and R 4. Less than R/2 How to find the average rate of dripping, please help. Thanks in advance. My attempt (Modified as per my trivial understanding of the comments) Let $$V=\pi r^2 h$$ The rate of water dripping from the bucket is: $$-\frac{dV}{dt}=\pi r^2 \frac{dh}{dt}$$ Now we have $-\frac{dV}{dt}=kh$ for some constant of proportional $k$ . Also for half height we have $R=kH/2$ which gives $k=2R/H$ . Substituting back we get: $-\frac{dV}{dt}= 2Rh/H$ When the bucket becomes almost empty, the instantaneous rate is: $-\frac{dV}{dt}= 2R$ But I need to find the average rate of dripping. Is it the right way to do it?
What should I do next, please suggest.","['related-rates', 'calculus', 'derivatives', 'volume']"
4393533,Understanding properties of sequential orthogonalization methods like Gram-Schmidt.,"We all know the Gram-Schmidt orthogonalization is done recursively and takes the linearly independent set of vectors one-by-one. And it can be distinguished from democratic orthogonalization like Löwdin and Wigner, which handles all the given vectors simultaneously and treat them on equal footing 1 2 . I want to understand a particular property of sequential orthogonalization methods like Gram-Schmidt. Suppose we have a linearly independent set of vectors $A:=\{v_,\cdots,v_i,\cdots,v_n\}$ and we apply the Gram-Schmidt orthogonalization method to get the orthonormal set of vectors $B:=\{w_1,\cdots,w_i,\cdots,w_n\}$ . Now suppose we replace $v_i$ to $\tilde{v}_i$ $(\tilde{v}_i \neq v_i)$ such that the new initial set $\tilde{A}$ is still linearly independent. Then after applying the Gram-Schmidt orthogonalization we get $\tilde{B}:=\{w_1,\cdots,\tilde{w}_i,\cdots,\tilde{w}_n\}$ . Can we show that $w_j \neq \tilde{w}_j$ for some $i \leq j \leq n$ . Or may be there are some special conditions for which the equality holds. Can we mathematically explore such conditions. A similar condition is when we exchange positions of $v_i$ and $v_k$ $(1\leq k<i\leq n)$ , then again can we answer the above question. I know that the Gram-Schmidt orthogonalization is not one-one. So most probably the inequality doesn't hold always. But what conditions will result in equality and what conditions to inequality. It would be helpful even if you could point me to some references or explanations.","['orthogonality', 'gram-schmidt', 'linear-algebra']"
4393558,"If $\underbrace{f*f*\ldots*f}_{n\text{ times}}\to f$ uniformly, then the continuous $2\pi$-periodic function $f$ is a trigonometric polynomial","Let $f$ be a $2 \pi$ -periodic continuous function. Given $$g_1 = f, \qquad g_2 = f * f, \quad \cdots \quad g_{n} = \underbrace{f * f * \cdots * f}_{n \text{ times}} $$ where $*$ denotes convolution, and assume $ g_{n} \xrightarrow{n\to\infty} f $ uniformly.
Prove that $f $ is a trigonometric polynomial. Im not sure where to start, I have proved in previous parts that if $f$ is Dirichlet kernel $$\sum_{n=-N}^{N}e^{i n x}$$ then for any $n\in \mathbb{N} $ we have $g_n=f$ , but I am not sure how to use it, if it is relevant at all. Any help would be appreciated. Thanks in advance.","['calculus', 'fourier-analysis', 'real-analysis']"
4393673,On simplicial complexes and their geometric realization,"Simplicial complexes can be defined in two different way, i.e. either abstractly as purely combinatorial objects, or embedded in Euclidean space. Let me briefly mention which definitions I use exactly: Definition 1: Let $\mathcal{V}$ be a finite set. An "" abstract simplicial complex "" is
a collection of non-empty subsets $\Delta$ of $\mathcal{V}$ such that
it contains all the singelton sets and such that for any non-empty $\tau\subset\sigma$ for $\sigma\in\Delta$ it holds that $\tau\in\Delta$ Definition 2: A Euclidean simplicial complex is a collection $\Delta$ of Euclidean
simplices (=the convex hull of a bunch of affinely-independent vectors
in $\mathbb{R}^{n}$ ) such that every face of a simplex is again
contained in $\Delta$ , such that the intersection of any two simplices
is either empty or the face of both simplices and such that $\Delta$ is locally finite. Obviously, to every Euclidean simplicial complex we can associate an abstract one by defining the abstract simplices to be the sets containing all the vertices of the corresponding Euclidean simplices. The abstract simplicial complex corresponding to a Euclidean one is usually called "" vertex scheme "". Last but not least, we need a notion of equivalence: Let $(\mathcal{V}_{1},\Delta_{1})$ and $(\mathcal{V}_{2},\Delta_{2})$ be two abstract simplicial complexes. A pair of maps $(\varphi:\Delta_{1}\to\Delta_{2},\varphi_{0}:\mathcal{V}_{1}\to\mathcal{V}_{2})$ is called "" simplicial isomorphism "", if it is of the form $\varphi(\{v_{0},\dots,v_{k}\})=\{\varphi_{0}(v_{0}),\dots,\varphi_{0}(v_{k})\}$ and if both $\varphi$ and $\varphi_{0}$ are bijective. In other words, two simplicial isomorphic abstract simplicial complexes admit the same number and the same gluing pattern of simplices. Now, it is a well-known fact that every finite abstract simplicial complex admits a "" geometric realization "", which is a Euclidean simplicial complex whose vertx scheme is simplicial isomorphic to our given complex. This is exactly the point which I do not quite understand. Why does there always exists an isomorphic simplicial complex which has the property that the intersection of two simplices is either a face or empty? It seems that this property in the definition of Euclidean simplicial complexes is much more restrictive, since for an abstract simplicial complex, the intersection of two simplices must not necessarily be again a simplex. For example, consider the following ""triangulation"" of the 2-torus: where we glue together the top and bottom as well as the right and left. Now, this is a well-defined abstract simplicial complex , since the non-empty subset of any simplex is again a simplex. However, it is certainly not an Euclidean simplicial complex, since the intersection of the two triangles is the union of two edges and not again a simplex. So, how does this triangulation, viewed as an abstract simplicial complex, has a geometric realization? Obviously, I just have a thinking error and misunderstand some of the definitions above, but I can't figure out which part I miss exactly... Thank you all!","['geometry', 'simplex', 'combinatorics', 'algebraic-topology', 'simplicial-complex']"
4393704,How to calculate $\nabla_{\mathbf{x}}(\mathbf{c}\mathbf{x}-A)\mathbf{x}^t$?,"How to calculate $\nabla_{\mathbf{x}}(\mathbf{c}\mathbf{x}-A)\mathbf{x}^t$ directly? $\mathbf{x}\in\mathbb{R}^{1\times n}$ , $\mathbf{c}\in\mathbb{R}^{m\times 1}$ , $A\in\mathbb{R}^{m\times n}$ . My attempt: Denote the expression $(\mathbb{c}\mathbf{x}-A)\mathbf{x}^t$ by $f$ . Then, find $\frac{\partial f_i}{\partial x_j}$ $f_i = ((\mathbf{c}\mathbf{x}-A)\mathbf{x}^t)_i = \sum_j c_ix_j^2-\sum_jA_{ij}x_j$ $\frac{\partial f_i}{\partial x_j} = 2c_ix_j - A_{ij}$ So, $\nabla_\mathbf{x}(\mathbb{c}\mathbf{x}-A)\mathbf{x}^t = 2\mathbf{c}\mathbf{x}-A.$ Instead of calculating the $ij$ -th component, how to compute the gradient directly?","['multivariable-calculus', 'matrix-calculus', 'derivatives', 'vector-analysis']"
4393882,Is double integration an easier way to find volume of rotation?,"AP Calculus BC student here, One of the most hated topics from Calculus 1 & 2 is often the disk method, washer method, and the shell method. Disk Method = $\pi \int [f(x)^2]dx$ (rotate x-axis) Washer Method = $\pi \int [R(x)^2-r(x)^2]dx$ (rotate x-axis) Shell Method = $2\pi \int xf(x)dx$ (rotate y-axis) Is there a method from multivariable calculus that uses double integration to calculate the volume of rotation?","['multivariable-calculus', 'calculus', 'multiple-integral', 'volume']"
4393917,Finding the volume with triple integrals,"I want to find the volume of a function described by: $$ G= \{(x,y,z)|\sqrt{x^2+y^2} \le z \le 1, (x-1)^2+y^2 \le 1\}$$ This question can be best solved in cylindrical coordinates. So if I follow that process, I get the following limits: $$ r \le z \le 1$$ $$ 0 \le r \le 2\cos(\theta)$$ $$ -\frac{\pi}{2} \le \theta \le \frac{\pi}{2}$$ I am fairly certain that these limits are correct. So continuing, to find the volume of G: $$\begin{align}
\iiint r \ dz\ dr\ d\theta
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} \int^{1}_{r} r \ dz \ dr \ d\theta\\
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} r-r^2  \ dr \ d\theta\\
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \frac{(2\cos(\theta))^2}{2}-\frac{(2\cos(\theta))^3}{3}   \ d\theta\\
&= \pi - \frac{32}{9}
\end{align}$$ Solving the above integral I get a negative answer which does not make sense considering the physical quantity is volume, which has to be positive. Where am I going wrong?","['integration', 'multivariable-calculus', 'cylindrical-coordinates', 'multiple-integral']"
4393921,Find the value of $\displaystyle \int \limits_{0}^{1}\frac{\ln^2{x}+2\ln{x}-2x+2}{\ln^2{x}-x\ln^2{x}} \mathrm dx$,"I have a question which askes us to find the value of the integral: $\displaystyle \tag*{} \int \limits_{0}^{1}\frac{\ln^2{x}+2\ln{x}-2x+2}{\ln^2{x}-x\ln^2{x}} \mathrm dx$ I tried using differentiation under integral using some variable, I couldn't go any further, I even tried the substitution $\ln x=t$ , it just reduces the size of integral. I divided the integral with the denominator to get $3$ separate integrals but each of them diverges. Any help would be appreciated. Thanks.","['integration', 'definite-integrals', 'logarithms', 'real-analysis', 'complex-analysis']"
4393970,Showing that series of random variables doesn't converge,"Let $S_1,S_2,\dots$ be series of independent variables with exponential distributions with parameters $\lambda_i>0$ . Show that $$ \sum_{i=0}^\infty \frac{1}{\lambda_i}  =\infty \Rightarrow P\left(\sum_{i=0}^\infty S_i = \infty\right)=1.$$ I know that $E(S_i)=\frac{1}{\lambda_i}$ , so it feels kind of intuitive that this is right. My idea was to look at $\lim_{n\rightarrow \infty}\{\sum_{i=1}^{n} S_i>M\}$ for any $M>0$ and show that it converges to 1, but the distribution of $S_1+\dots+S_n$ is hard to find. Is there a better way to approach this problem?","['probability-theory', 'probability']"
4393976,"Abuse of notation when we denote $\mathcal{F}_n $-measurability of $X_n$ by ""$X_n \in \mathcal{F}_n$""?","I am confused about a notation that I am seeing in many probability texts when authors write $X_n \in \mathcal{F}_n$ to express that $X_n$ is $\mathcal{F}_n$ -measurable. The elements in $\mathcal{F}_n$ are subsets of $\Omega$ , our probability space, so it does not make any sense for $X_n$ to be an element of $\mathcal{F}_n$ ... If anything, what we should write is $X^{-1}_n(\omega) \in \mathcal{F}_n$ for every $\omega \in \Omega$ to denote $\mathcal{F}_n$ -measurability. So my question is, do authors just write $X_n \in \mathcal{F}_n$ as some sort of shorthand convenience/abuse of notation, or am I missing something deeper here? Thanks in advance!","['measure-theory', 'probability-theory', 'probability']"
4394002,Why is this projection of rank 1?,"I'm reading the following proof excerpt from a textbook that state the following: Let $E$ be an orthonormal basis of a Hilbert space $H$ .  For $e \in E$ , define $p_e = e \otimes e$ for $e \otimes e: H \longrightarrow H$ given by $(e \otimes e)(z) = \langle z,e \rangle e$ .  Then $p_e$ is a projection of rank $1$ with $p_eK(H)p_e = \mathbb{C}p_e$ with $K(H)$ the collection of compact operators on $H$ . Let $H'$ be another Hilbert space, and suppose that $\varphi: K(H) \longrightarrow K(H')$ is a $*$ isomorphism.  Then $q_e = \varphi(p_e)$ is a projection satisfying $q_eK(H')q_e= \mathbb{C}q_e$ .  It's clear also that $q_e$ is of rank $1$ too. Why is $q_e$ of rank one?  I know that $q_e=q_e\varphi(v)q_e$ for $v$ the rank $1$ operator that sends $x \mapsto \beta e$ .  I.e, $v$ takes an $x \in H$ (which is represented in terms of the orthonormal basis $E$ on $H$ ), to $\beta e$ , where $\beta$ is the coefficient in front of $e$ in the basis representation of $x$ (as then the range of $v$ is $\text{Span}(e)$ and $\langle v(e),e \rangle =1$ , so $p_e=p_evp_e$ ). However, I don't see why this arbitrary $*$ isomorphism sends the rank $1$ operator $v$ to another rank $1$ operator.","['proof-explanation', 'operator-theory', 'analysis', 'hilbert-spaces', 'functional-analysis']"
4394071,How to show that $\sup_n E(X_n^2) < \infty$ for a certain martingale?,"Let $X_n$ , $n\geq 0$ , be a martingale and let $\xi_n = X_n - X_{n-1}$ for $n \geq 1$ . If $E(X_0^2)$ and $\sum_{m=1}^{\infty}E(\xi_m^2) < \infty$ , then $X_n \rightarrow X_\infty$ a.s. and in $L^2$ . My attempt: I used $L^p$ convergence theorem to proved this question. This theorem is stated as If $X_n$ is martingale with $\sup E(|X_n|^p) < \infty$ where $p>1$ then $X_n \rightarrow X$ a.s. and in $L^p$ . The only thing I need to show $\sup E(|X_n|^2) < \infty$ . For. this I proved that If $X_n$ and $Y_n$ are martingale with $E(X_n^2)<\infty$ and $E(Y_n^2)<\infty$ , then \begin{equation*}
 E(X_nY_n) - E(X_0Y_0) = \sum_{m=1}^n (X_m - X_{m-1})(Y_m - Y_{m-1})
\end{equation*} My question is how do I show that $E(X_n^2)<\infty$ ?","['expected-value', 'stochastic-processes', 'probability-theory', 'martingales']"
4394091,"How to tackle the integral $\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}}dx, \textrm{ where } n \in N $","Inspired by an integral in my post , I want to generalize the result by replacing the power 2 in the denominator by $n.$ Letting $x \mapsto\pi-x$ yields $$
I_n:=\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}} d x=\int_{0}^{\pi} \frac{2 x^{3}-3 \pi x^{2}+\pi^{3}}{(1+\sin x)^{n}} d x=-I+\pi^{3} \int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}}
$$ Rearranging gives $$
I_{n}=\frac{\pi^{3}}{2} \underbrace{\int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}}}_{K_n}
$$ $$
\begin{aligned}
K_{n} & \stackrel{2 y=\frac{\pi}{2}- x}{=} 2 \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{(1+\cos 2 y)^{n}} \\
&=2\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{\left(2 \cos ^{2} y\right)^{n}}\\&= \frac{1}{2^{n-2}} \underbrace{\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y}_{J_n} 
\end{aligned}
$$ Now we need a reduction formula for $J_n$ , for any natural number $n$ , $$
\begin{aligned}
J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y\\
&=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n-2} y  d(\tan y) \\
&=\left[\sec ^{2 n-2} y \tan y\right]_{0}^{\frac{\pi}{4}}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \tan ^{2} y \sec ^{2 n-3} y \sec y dy\\
&=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}}\left(\sec ^{2} y-1\right) \sec ^{2 n-2} y d y \\
&=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y+(2 n-2) J_{n-1}
\end{aligned}
$$ Rearranging yields the reduction formula $$
J_{n}=\frac{1}{2 n-1}\left[2^{n-1}+(2 n-2) J_{n-1}\right] \tag*{(1)} 
$$ Hence $$
I_{n}=\frac{\pi^{3}}{2} K_{n}=\frac{\pi^{3}}{2} \cdot \frac{1}{2^{n-2}} J_{n}=\frac{\pi^{3}}{2^{n-1}} J n\tag*{(2)}
$$ Back to the reduction formula for our integral $I_n$ , combining (1) and (2) gives $$
\boxed{I_{n}=\frac{1}{2 n-1}\left[\pi^{3}+(n-1) I_{n-1}\right]}
$$ For examples, $$
\displaystyle \begin{array}{l}
I_{1}=\frac{1}{1}\left(\pi^{3}+0\cdot I_{0}\right)=\pi^{3} \\
I_{2}=\frac{1}{3}\left(\pi^{3}+1 \cdot I_{1}\right)=\frac{2 \pi^{3}}{3} \\
I_{3}=\frac{1}{5}\left(\pi^{3}+2 \cdot I_{2}\right)=\frac{7 \pi^{3}}{15} \\
I_{4}=\frac{1}{7}\left(\pi^{3}+3 \cdot I_{3}\right)=\frac{12 \pi^{3}}{35}\\ \qquad\qquad \vdots 
\end{array}
$$ My Question Although we can find our integral one by one by the reduction formula, it is tedious and unsatisfactory.  Is there any closed form for it? Latest Edit Helped by Mr Quanto, we got a closed form for the integral $$
\boxed{I_{n}=\frac{\pi^{3}}{2^{n-1}} \sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \frac{1}{2 k+1}}
$$ which is obtained by letting $t=\tan y$ \begin{aligned}
J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y \\
&=\int_{0}^{1}\left(1+t^{2}\right)^{n-1} d t \\
&=\sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \int_{0}^{1} t^{2 k} d t \\
&=\sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \frac{1}{2 k+1}
\end{aligned} For example $$
\begin{aligned}
I_{5} &=\frac{\pi^{3}}{2^{4}}\left[\left(\begin{array}{l}
4 \\
0
\end{array}\right)+\left(\begin{array}{l}
4 \\
1
\end{array}\right) \frac{1}{3}+\left(\begin{array}{l}
4 \\
2
\end{array}\right) \frac{1}{5}+\left(\begin{array}{l}
4 \\
3
\end{array}\right) \frac{1}{7}+\left(\begin{array}{l}
4 \\
4
\end{array}\right) \frac{1}{9}\right] =\frac{83 \pi^{3}}{315}\approx{8.16991},
\end{aligned}
$$ which is checked by Wolframalpha","['integration', 'definite-integrals', 'reduction-formula', 'calculus', 'trigonometry']"
4394100,Level curves and critical points,How can I find critical points with level curves? Well I saw this video about a method for find critical points with level curves video but he don´t proof nothing and really I don't understand what is the essential method for find maxima or minima point. I'm interested in that because I'm reading a article that use this method for find global maxima ref theorem 2 Also if you can give me an explanation of theorem 2 I appreciate,"['optimization', 'multivariable-calculus', 'proof-explanation', 'real-analysis']"
