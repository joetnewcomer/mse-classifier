question_id,title,body,tags
1611153,Compute $\lim_{x\to 0}\frac{x}{[x]}$,"When I take left hand limit of the function $\lim\limits_{x\to 0}\frac{x}{[x]}$ , then $\lim\limits_{h\to 0^{-}}\frac{-h}{[-h]}=\lim_{h\to 0^{-}}\frac{-h}{-1}=0$ where $0<h<1$ and $[\cdot ]$ is greatest integer function. But when I take right hand limit, then the function $\frac{h}{[h]}$ does not exists. so I do not understand what about $\lim\limits_{h\to 0^{+}}\frac{h}{[h]}$ and the limit of original function. Does the limit exists? please someone help me Thanks in advance.","['real-analysis', 'limits', 'functions', 'sequences-and-series', 'ceiling-and-floor-functions']"
1611211,Partition of plane into disjoint circumferences,"1) Euclidian plane $\mathbb{R}^2$ is not a union of disjoint circumferences (assuming point is not a circumference of radius $0$). 2) If we exclude 1 point from plane, concentric circumferences with center at this point form a desired partition. 3) Choose $n \geq 2$ distinct points $p_1, \dots, p_n$. Is $\mathbb{R}^2 \setminus \{p_1, \dots, p_n\}$ a union of disjoint circumferences? I believe 3) is not, but I don't know how to prove it. Here's my proof of (1). Suppose such partition exist. Let's construct a sequence of compact circles $A_1 \supset A_2 \supset \dots$, such that $r_n \to 0$, where $r_n$ denotes the radius of $A_n$. Let $A_1$ be any circumference with its interior. Having chosen $A_n$, choose circumference passing through its center. Let $A_{n+1}$ be a union of this circumference with its interior. Obviously, $r_{n+1} < r_n/2$. Thus, $r_n \to 0$. By Cantor's intersection theorem
$$\bigcap_{n=1}^{\infty} A_n \neq \varnothing.$$
Choose $p \in \bigcap_{n=1}^{\infty} A_n$. If $p$ is a boundary point of some $A_n$ then $p \notin A_{n+1}$. Hence, $p$ is an interior point of all $A_n$ and boundary point of some other circle. This circle should be contained in all $A_n$ (otherwise circumferences would intersect), which is impossible because $r_n \to 0$. Any ideas on (3)? Thanks in advance. (1) and (2) are included for completeness.","['proof-verification', 'general-topology', 'elementary-set-theory', 'geometry']"
1611280,How many times should I roll a die to get 4 different results?,"What is the expected value of the number $X$ of rolling a die until we obtain 4 different results (for example, $X=6$ in case of the event $(1,4,4,1,5,2)$)? I'm not only interested in technical details of a solution---I can solve it to some extent, see below---but even more in the following: Is it a known problem, does it have a name? Does there exist a closed-form expression? (See below for a series expansion) Does there exist a feasible algorithm/formula to compute it if the die is not ""fair"" and each face has possibly a different probability? My attempt:
$EX=\sum_{j=4}^\infty j\, P(X=j)$. Clearly, $P(X=j)$ is $1/6^j$ multiplied by the number of ways to obtain $X=j$. The number of ways is $6\choose 3$ (the choice of 3 elements that occur within the first $j-1$ rolls) multiplied by $3$ (the last roll) multiplied by the number of surjective functions from $j-1$ to 3 (the number of ways what can happen in the first $j-1$ rolls, if the three outputs are given). Further, the number of surjective functions can be expressed via Stirling numbers of the second kind : so in this way, I can get a series expression, although not a very nice one.","['combinatorics', 'probability', 'reference-request']"
1611288,Problem with differential equation RLC circuit series,"I am trying solve the differential equation of RLC's circuit in series, I have: $C=4\ F, L= 1\ H$, $R=5\ \Omega$, and $V_e=20\ V$. $1)$ first I got the equation, it is: $i''+5i'+\frac{1}{4}i=0$, what I have to calculate is $v_c$, and I know that $i(0)=-2\ A$ and $v_c(0)=10\ V$ I have calculated the characteristic polynomial and I got that a fundamental system is $\{ e^{-0.051t}; e^{-4.950t}\}$, so $$i=Ae^{-0.051t}+Be^{-4.950t}$$
And now I could calculate $v_c=\int_{0}^{t}idt$ Ok, first problem !... I got $$v_c=-4.950A(e^{-0.051t}-1)-0.051B(e^{-4.950t}-1),$$ SO... when I said that $v_c(0)=10=0-0 $ what happen here? Ok, now I dont said $\int_0^t$, no. I consider $\int$ only, so I got $$v_c=-4.950A(e^{-0.051t})-0.051B(e^{-4.950t})$$ And when I said that $v_c(0)=0$ I got that $$A=-2.020\ B=0.021,$$ in that, $$ v_c\approx10e^{-0.051t}$$ but in my but said that $v_c=20+0.102e^{-4.950t}-10.102e^{-0.051t}\ [V]$, so what happen, I need help please... please... PD; To solve can not use the formula that we all know , the problem is solved by mathematical methods. I need help...","['physics', 'ordinary-differential-equations']"
1611308,Best Fit Line with 3d Points,"Okay, I need to develop an alorithm to take a collection of 3d points with x,y,and z components and find a line of best fit.  I found a commonly referenced item from Geometric Tools but there doesn't seem to be a lot of information to get someone not already familiar with the method going.  Does anyone know of an alorithm to accomplish this?  Or can someone help me work the Geometric Tools approach out through an example so that I can figure it out from there?  Any help would be greatly appreciated.","['differential-geometry', 'linear-regression', 'linear-algebra', 'geometry']"
1611309,Is $[p \land (p \to q)] \to q$ a tautology?,"I am new to discrete mathematics, and I am trying to simplify this statement.  I'm using a chart of logical equivalences, but I can't seem to find anything that really helps reduce this. Which of these would help me to solve this problem?  I realize I can covert $p \to q$ into $\lnot p \lor q$, but I'm stuck after that step.  Any push in the right direction would be awesome.","['logic', 'discrete-mathematics']"
1611385,Definite Integral of Polynomial of Sine and Cosines,"I was wondering if there is a way to compute definite integral 
\begin{align}
I(m,n) :=\int_{0}^{\pi} \sin^m (\theta) \cdot \cos^{n}(\theta) \ \mathrm{d} \theta
\end{align}
in general for integer-valued $m$ and $n$. This problem arises when I try to compute integrals of trigonometric functions over a high dimensional sphere. In fact I am more interested in the asymptotic order of this integral. I was wondering how $I(m,n)$ behaves when $n$ goes to infinity. For example, what is the limit of $\lim _{n\rightarrow \infty} I(2, n)$?","['real-analysis', 'trigonometry', 'integration', 'definite-integrals', 'analysis']"
1611415,Bounds on the eigenvalues of a covariance matrix,"Consider the (symmetric) covariance matrix $\Sigma_{22}(k,k)=
\begin{bmatrix}
    b(0)       & b(1)& b(2) & \cdots & b(k-1) \\
    b(1)      & b(0) & b(1) & \cdots & b(k-2) \\
    \vdots  && \vdots \\
    b(k-1)      & b(k-2)& b(k-3)& \cdots & b(0)
\end{bmatrix},
$ where $\sum_{i=1}^n\sum_{j=1}^nb(|i-j|)=O(n^{2H})$ and $0<H<1$.  Can we give an estimate of the bounds of the eigenvalues, $\min \lambda_i$ and $\max \lambda_i$? I know that $\sum \lambda_i=trace(\Sigma_{22})=kb(0)$, so $b(0)\leq\max \lambda_i\leq kb(0)$, but can we give a better estimate? Thank you in advance.","['statistics', 'probability', 'linear-algebra']"
1611417,Elliptical Integral that diverges at one point,"I have to solve the following integral $$I=\int_{\lambda_1}^yd\lambda\frac{1}{1-\lambda}\sqrt{\frac{(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_4)}{\lambda-\lambda_3}}$$ where $y>1>\lambda_1>\lambda_2>\lambda_3>\lambda_4>0$. The problem, as you can see, is that the integral $I$ has non-integrable contribution at $\lambda=1$. So what I do basically to avoid the problem is to rewrite $I$ as $$I=\lim_{r\to1}\int_{\lambda_1}^rd\lambda\frac{1}{1-\lambda}\sqrt{\frac{(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_4)}{\lambda-\lambda_3}}-\lim_{r\to1}\int_{r}^yd\lambda\frac{1}{\lambda-1}\sqrt{\frac{(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_4)}{\lambda-\lambda_3}}$$ I already could solve $$I_1=\lim_{r\to1}\int_{\lambda_1}^rd\lambda\frac{1}{1-\lambda}\sqrt{\frac{(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_4)}{\lambda-\lambda_3}}$$ using ""P. F. Byrd and D. F. Morris, Handbook of elliptic integrals for engineers and scientists, Vol 67,
Berlin Springer (1971)"". I only need to solve $$I_2=\int_{r}^yd\lambda\frac{1}{\lambda-1}\sqrt{\frac{(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_4)}{\lambda-\lambda_3}}$$ for $y>r>1$. The problem is that in this case I can not use ""P. F. Byrd and D. F. Morris, Handbook of elliptic integrals for engineers and scientists, Vol 67, Berlin Springer (1971)"" because in order to do it I will have to rewrite $I_2$ like a sum of two integrals with one of the limits of integration being $\lambda_i$ for $i\in\{1,\dots,4\}$ and if I do that I return to the case when there is no integrable contribution at $1$. Could you please help me to solve $I_2$?","['improper-integrals', 'integration', 'definite-integrals', 'elliptic-integrals', 'special-functions']"
1611426,Why does this double infinite sum $\sum_{n=1}^\infty \sum_{k=n}^\infty\frac{1}{k!}$ converge to $e$?,"I can't seem to come to grips with the result below:
$$S=\sum_{n=1}^\infty \sum_{k=n}^\infty\frac{1}{k!}=e$$
which is given by Mathematica (code below) and (numerically) verified by WolframAlpha . In[65]:= Sum[1/k!, {n, 1, Infinity}, {k, n, Infinity}]

Out[65]= E I've attempted to work it out in the following way:
$$\begin{align*}S&=\sum_{n=1}^\infty\sum_{k=n}^\infty \frac{1}{k!}\\[1ex]
&=\sum_{n=1}^\infty\left(\frac{1}{n!}+\frac{1}{(n+1)!}+\frac{1}{(n+2)!}+\cdots\right)\\[1ex]
&=\sum_{n=1}^\infty\frac{1}{n!}+\sum_{n=1}^\infty\frac{1}{(n+1)!}+\sum_{n=1}^\infty\frac{1}{(n+2)!}+\cdots\\[1ex]
&=\sum_{n=1}^\infty\frac{1}{n!}+\sum_{n=2}^\infty\frac{1}{n!}+\sum_{n=3}^\infty\frac{1}{n!}+\cdots\\[1ex]
&=(e-1)+\left(e-1-\frac{1}{2}\right)+\left(e-1-\frac{1}{2}-\frac{1}{6}\right)+\cdots\end{align*}$$
which doesn't appear to me to follow a telescoping pattern, but I might be wrong about that. It's not obvious to me if this actually does telescope. Edit: Changing the order of summation does wonders, as shown in the accepted answer, but I'm currently wondering if there is any possibility that the last line admits any neat telescoping argument?","['gamma-function', 'exponential-function', 'sequences-and-series', 'convergence-divergence']"
1611443,"Show that $f$ does not change sign on some interval $(\beta,+\infty)$.","Let $a,b,f$ are continuous functions on some interval $(\alpha,+\infty)$ such that $a,b$ have constant sign on $(\alpha,+\infty)$ and $f$ is differentiable on $(\alpha,+\infty)$. Suppose $f'=af+b$. Show that $f$ does not change sign on some interval $(\beta,+\infty)$. So I consider this as cases: Case I: $a>0,b>0$ So I can rewrite $f=(f'-b)/a$. To the contrary assume that given $\beta \in \mathbb{R}$ there is $c_1,c_2>\beta $ such that $f(c_1)>0$ and $f(c_2)<0$. Then by intermediate value theorem there is $c\in(c_1,c_2)$ such that $f(c)=0$. So,$f'(c)=b(c)>0$. But after that I was stuck. Even a periodic function like sin function does have the property I got. So how do I prove the result?","['real-analysis', 'calculus']"
1611450,Closed points of $Spec(A)$ are dense,"This is exercise 3.6.J from the most recent Vakil's notes. Suppose that k is a field, and A is a finitely generated k-algebra. Show that closed points of Spec A are dense, by showing that if f ∈ A, and D(f) is a nonempty (distinguished) open subset of Spec A, then D(f) contains a closed point of Spec A. Hint: note that $A_f$ is also a finitely generated k-algebra. Use the Nullstellensatz 3.2.5 to recognize closed points of Spec of a finitely generated k-algebra B as those for which the residue field is a finite extension of k. Apply this to both B = A and B = $A_f$. I know we have $A_f/pA_f=(A/p)_f$, then if p is a prime ideal of $A_f$, then the left side is a field and is a finite extension of k. Then how should I get the conclusion that $A/p$ is also a field?",['algebraic-geometry']
1611465,What's domain of $\sqrt{\sin\pi(x^2-x)}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Find the domain of 
  $$\sqrt{\sin\pi(x^2-x)}$$ I'm confused about this function. I've been trying to figure out what's the domain but can't get a right answer.","['trigonometry', 'functions']"
1611480,Simplify $\int_0^\infty \frac{\text{d}{x}}{e^x+x^n}$,I seem to have seen quite a lot of integrals in the form: $$\int_0^\infty \frac{\text{d}x}{e^x+(1+x^n)}$$ But none of those hold a closed forms (at least to my knowledge) $$\Large\color\red{\int_0^\infty \frac{\text{d}x}{e^x+x^n}}$$ Does a closed form exist of this integral? (in terms of $n$),"['integration', 'closed-form']"
1611507,Divergent function of ratio must be logarithm,"Given. Consider two functions $F(t)$ and $r(t,x)$ such that $\lim_{t\to\infty} F(t) = \infty$ and $\lim_{t\to\infty} r(t,x)$ is finite for any $x$.  ($x$ and $t$ are always positive in what follows.)  Suppose they sum to a function only of the ratio $x/t$:
\begin{align}
F(t) + r(t,x) = f (x/t) \qquad (1)
\end{align} Claim. $f(x/t)$ must diverge logarithmically at large $t$.  That is,
\begin{align}
\lim_{t\to\infty} \frac{f(x/t)}{\ln t} = const\ (\text{independent of } x) \qquad (2)
\end{align} Flawed proof. The paper cited below does the following.  Define $r(x)= \lim_{t\to\infty} r(t,x)$.  Then we can write:
\begin{align}
f(x/t) = F(t) + r(x) + \phi(t,x) \qquad (3)
\end{align}
where $\phi(t,x) = r(t,x) - r(x)$ goes to zero as $t\to\infty$. Now it seems reasonable ( this is the incorrect step! ) that $F(t)+r(x)$ and $\phi(t,x)$ should separately be functions only of the ratio $x/t$, since they have different behavior at large $t$.  In particular,
\begin{align}
F(t) + r(x) = W(x/t) \qquad (4)
\end{align}
It is then straightforward to show that $W$ is a logarithm, which completes the proof.  We differentiate both sides of $(4)$ with $x$:
\begin{align}
r'(x) = \frac{1}{t}W'(x/t)    \qquad (5)
\end{align}
Then set $x=1, t=\frac{1}{y}$:
\begin{align}
r'(1) = y\ W'(y)    \qquad (6)
\end{align}
so $W(y) = r'(1) \ln y + $ const. Counterexample to (4). Consider $F(t) = \ln t + \frac{1}{t}, r(t,x) = -\ln x - \frac{1}{t}.$  Then $r(x) = -\ln x$ and $F(t) + r(x) = \ln \frac{t}{x} + \frac{1}{t}$, so $(4)$ fails. Can this proof be saved?  If not, how else can it be done? Reference. ""A hint of renormalization"" (American Journal of Physics, hep-th/0212049).  See equation (30) and Appendix C.  My $t$ is his $\Lambda$.","['logarithms', 'asymptotics', 'limits']"
1611534,How to find $\lim_{x \to a}\frac{ a^nf(x)-x^nf(a)}{x-a}$,"f:$\mathbb {R} \to \mathbb{R}$ which is differentiable at $x=a$ the we are to evaluate the following:-
$$\lim_{x\to a}\frac{a^nf(x)-x^nf(a)}{x-a}$$
My approach:-
$$\frac{a^nf(x)-x^nf(a)}{x-a}=x^na^n\frac{\frac{f(x)}{x^n}-\frac{f(a)}{a^n}}{x-a}$$
Let
$g(x)=\frac{f(x)}{x^n}$
then$$x^na^n\frac{\frac{f(x)}{x^n}-\frac{f(a)}{a^n}}{x-a}=x^na^n\frac{g(x)-g(a)}{x-a}$$
so that $$\lim_{x \to a}x^na^n\frac{g(x)-g(a)}{x-a}=(\lim_{x \to a}x^na^n)g'(a)=a^{2n} \frac{d}{dx}(f(x)/x^n)$$
$$=a^{2n}\left(\frac{x^nf'(x)-nx^{n-1}f(x)}{x^{2n}}\right)_{x=a}=a^nf'(a)-na^{n-1}f(a)$$
Is my attemplt correct?","['derivatives', 'limits']"
1611536,Standard Basis of $SU(2)$--where does the 1/2 come from?,"The most common matrix representation of $SU(2)$ is given by 
$$
\begin{pmatrix}
a & b\\
b^* & -a^*\\
\end{pmatrix}
$$
where $a,b\in\mathbb{C}$. If we denote real components by the subscript $r$, imaginary by $i$, one can clearly write this as $$
\begin{pmatrix}
a & b\\
-b^* & a^*\\
\end{pmatrix}
 =
a_r\begin{pmatrix}
1 & 0\\
0 & 1\\
\end{pmatrix}
+b_r\begin{pmatrix}
0 & 1 \\
-1 & 0 \\
\end{pmatrix}
+b_i\begin{pmatrix}
0 & i \\
i & 0 \\
\end{pmatrix}
+a_i\begin{pmatrix}
i & 0 \\
0 & -i \\
\end{pmatrix},
$$
so the Lie algebra should be obtained by discarding the coefficient of the identity matrix and identifying the remaining traceless matrices as the generators of $\mathfrak{su}(2)$. We quickly realize these are $i\sigma_a$, where $a = 1,2,3$ denote the Pauli spin matrices. Many books however define the standard basis of $\mathfrak{su}(2)$ as $(i/2)\sigma_a$. While this would normally be simply a trivial convention, R. Gilmore, on page 107 of ""Lie Groups, Physics, and Geometry"", seems to use this to show the $SU(2)\rightarrow SO(3)$ cover is 2:1 by splitting $\mathfrak{su}(2)$ into the form $\mathfrak{su}(2)\ni X = S_1 + (ia_i/2)\sigma_3$ where $S_1 =  (ib_i/2)\sigma_1 + (ib_r/2)\sigma_2$ and exponentiating $S_1$ and $(ia_i/2)\sigma_3$ individually to give $$SU(2) \ni U = \exp(S_1)\times\begin{pmatrix}
e^{ia_i/2} & 0\\
0 & e^{-ia_i/2}\\
\end{pmatrix}.$$ Using a similar splitting of $\mathfrak{so}(3)$ into two components (an $SO(3)/SO(2)$ quotient and $SO(2)$) which are individually exponentiated, he concludes the quotients $SO(3)/SO(2)$ and $SU(2)/U(1)$ are both topologically $S^2$, thus bijective, and the thus the cover must be 2:1 because putting $\theta \mapsto \theta + 2\pi$ is a complete rotation in $SO(2)$, while $a_i \mapsto a_i + 4\pi$ is a complete rotation in the given representation of $U(1)$. I've been wanting to emulate this argument but can't do so without the factor of $1/2$. My questions are thus as follows: (1) where does the $1/2$ come from? Is it just convention or something else? (2) Is there any easy way to argue the cover is $2:1$ without using the $1/2$? (3) I thought that generally the whole Lie algebra had to be exponentiated to map back onto the Lie group. How does separating the Lie algebra and exponentiating the terms individually make sense in the context of the BCH formula? Does this have to do with irreducible representations?","['rotations', 'linear-algebra', 'lie-algebras', 'lie-groups']"
1611558,What is the most efficient way to find a penny in an empty field?,"Let's say that I'm in a rectangular field,2 miles in width and 3 in length, with a metal detector. I know that somewhere within this field lies a penny, which is equally likely to be at any point. My metal detector will detect any penny within a 30-ft radius of my location. Furthermore, this penny is the only metallic object in the field (at least as far as my metal detector is concerned). I want to minimize my metal detector's battery usage. Of course, I'll turn off my metal detector when I walk back to a place I've already been to.","['algorithms', 'geometry']"
1611560,Why are all k-cells convex?,"Reading through the first half of Baby Rudin again before taking an Analysis class, I came across the assertion that ""it is also easy to show that k-cells are convex"". Previously it gave the example of open/closed balls being convex, and the proof is obvious and easy to understand.  That being said, and it's probably very easy, but I can't for the life of me produce something that shows that all k-cells are convex as well. I understand convex to sort of say ""all points 'between' two points in a given set are also in the set"" in Layman's terms, but I'm not sure where to proceed from there.  I either got this on my first read and can't remember for the life of me, or I took it for granted and went with it. Any help leading me in the right direction?","['general-topology', 'real-analysis', 'analysis']"
1611616,Dirichlet problem to the ball with boundary data $1-2y^2$.,"Let $\omega=\{(x,y):x^2+y^2<1\}$ be the open unit disk in $\mathbb R^2$ with the boundary $\delta\omega$.If $u(x,y)$ be the solution of Dirichlet problem $$\begin{cases} u_{xx}+ u_{yy}=0 & \text{in} \ \omega \\ u(x,y)=1-2y^2 & \text{on the boundary.} \end{cases} $$ Then $u(1/2,0)=?$ $-1$ $-1/4$ $1$ $1/4$ I have no idea how to find the solution. Does there exist a simple way to find solution? please someone help. Thanks.","['harmonic-functions', 'ordinary-differential-equations']"
1611681,Lack of rigour in Spivak's Calculus book?,"I logged on today with this exact question: Ellipse definition I found it disconcerting for him to say that it was clear that $a > c$ when $a$ could be equal to $c$ (a straight line) or maybe even less than $c$ (if complex numbers are allowed). So he is assuming that we don't want a straight line, and also that complex numbers aren't allowed. Neither of those assumptions were stated or explained. I don't even know whether complex numbers would work, whether any sum at all could be arrived at. It's also not stated that the formula wouldn't work for a straight line; it's just glossed over by saying it 'clearly' couldn't be a straight line. I picked up Spivak's book because I had heard it was extremely rigourous, but now I'm wondering a) whether the unstated assumption and lack of addressing conceivable possibilities is common in his book, and b) whether there were any other book recommendations to learn calculus with the requirement of rigour in mind. I'm a bit hesitant to continue, as I may be unable to tell whether something 'clear' to him is not clear to me due to me not understanding it properly, or due to not being aware of his assumptions. As I'm trying to learn this on my own, that's not a favourable position for me to be in.","['reference-request', 'book-recommendation', 'calculus']"
1611699,"If $\frac{\sec^8 \theta}{a}+\frac{\tan^8 \theta}{b} = \frac{1}{a+b}\;,$ Then prove that $ab\leq 0$","If $\displaystyle \frac{\sec^8 \theta}{a}+\frac{\tan^8 \theta}{b} = \frac{1}{a+b}\;,$  Prove that $ab\leq 0$ $\bf{My\; Try::}$ I am Trying To solve it Using Inequality. Using $\bf{Cauchy\; Schwartz\; Inequality::}$ $$\frac{(\sec^4 \theta)^2}{a}+\frac{(\tan^4 \theta)^2}{b}\geq \frac{(\sec^4 \theta+\tan^4\theta)^2}{a+b}$$ and equality hold when $$\frac{\sec^4 \theta}{a}=\frac{\tan^4 \theta}{b}$$ Now I did not understand How can I solve after that Help me Thanks","['algebra-precalculus', 'trigonometry']"
1611713,What is that thing that keeps showing in papers on different fields?,"A few months ago, when I was studying strategies for the evaluation of functional programs, I found that the optimal algorithm uses something called Interaction Combinators, a graph system based on a few nodes and rewrite rules . I've implemented and got some surprising results with it. I tried learning more, only to realize there are very few papers and almost nobody talking about it. Another day, by sheer luck, I stumble with this paper about chemical computers that would be ""the future of computation"". Midway through my read, I see this: The similarity to Interaction Nets in striking. The nodes, the rules, the principal ports - on its core, the system is mostly the same. I tried looking at references to find more about ""it"", but didn't find anything very relevant, so I gave up. Another day, by sheer luck once again, I sumble with this blog post about some kind of graphical linear algebra that ""can divide by zero"". Midway through the read, I see this: Once again, the same ""thing"" can be seen. There are some minor differences but, on its core, it is the same. What is that thing in common with those systems? How is it called, what is its importance, where is it studied and, most importantly, why it keeps showing in completely different fields?","['graph-theory', 'linear-algebra', 'functions']"
1611730,Predicting the number of unique elements in the Cartesian product of a set with itself,"I am a linguist, not a mathematician, so I apologize if there's something wrong with my terminology and/or notation. I have two structures that I want to merge (partially or completely). To generate a list of all possible combinations, I compute the Cartesian product of the two sets of objects, which gives me a set of pairs, and then I compute the [1, ..., n ]-fold Cartesian product of my set of pairs with itself where n is the highest cardinality out of the two structures (here, 5). A = (a1, a2, a3, a4, a5) and B = (b1, b2, b3, b4, b5) Basically, I'm generating 1-tuples like ((a1, b1)), ((a1, b2)), ..., ((a5, b5)) that merge one pair of objects, 2-tuples that merge two pairs of objects, etc. up to n -tuples. I end up with $\sum\limits_{i=1}^{n} (\bar{\bar{A}}\times \bar{\bar{B}})^i$ tuples, where $\bar{\bar{A}}$ and $\bar{\bar{B}}$ represent the cardinalities of the two structures. In this case, I get 10172525 tuples, which is way too high for my needs. I filter my list to only keep tuples if the pairs they contain are all different and cannot be found in another tuple with the same length. This removes up to 99% of the original tuples. For example: ((a1, b1), (a2, b2), (a3, b3)) ((a1, b1), (a3, b3), (a2, b2)) has the same pairs as the preceding tuple, but in a different order ((a1, b1), (a1, b1), (a3, b3)) has the pair (a1, b1) more than once I'm looking for an equation that will help me predict the number of unique tuples. For 1-tuples, there's $\bar{\bar{P}}$ unique tuples where $\bar{\bar{P}}$ is the number of pairs. For 2-tuples, I do $\frac{\bar{\bar{P}}\times (\bar{\bar{P}}-1)}{2}$. I'm sure there's an equation that works for any tuple length, but I can't figure it out. Here are the numbers of tuples generated vs. unique tuples for two structures with 4 objects each: +--------+-----------+--------+
| Length | generated | unique |
+--------+-----------+--------+
| 1      |        16 |     16 |
| 2      |       256 |    120 |
| 3      |      4096 |    560 |
| 4      |     65536 |   1820 |
| Total  |     69904 |   2516 |
+--------+-----------+--------+",['elementary-set-theory']
1611732,Example of non-noetherian ring whose spectrum is noetherian [duplicate],"This question already has answers here : A non-noetherian ring with noetherian spectrum (6 answers) Closed 7 years ago . Since spectrum of noetherian ring is a noetherian topological space, I am finding an example s.t. a non-noetherian ring whose spectrum is noetherian. Since most nice rings are noetherian, actually I do not have many examples to start, does any one can help? Thanks!",['algebraic-geometry']
1611793,A combinatorial expression is equal to a binomial coefficient squared,"Problem : Prove for all natural numbers the following identity: $$\sum_{r=0}^{n}\frac{(2n)!}{(r!)^2((n-r)!)^2}=\dbinom{2n}{n}^2$$ I have just been successful in interpreting the LHS of the above as sum of the coefficients of those terms in the expansion of $(a+b+c+d)^{2n}$ which are of $(ab)^r(cd)^{n-r}$ form. I also tried wrote the LHS in terms of binomial coefficients as follows $$\sum_{r=0}^{n} \dbinom{2n}{r}\dbinom{2n-r}{r}\dbinom{2n-2r}{n-r}$$ But since $r+r+n-r$ is not a constant so the above sum cannot be interpreted as the coefficient of $x^{t}$ in some expression where t is some constant. So, please help me with this problem. Even hints would be appreciated. Also, I failed to find any combinatorial interpretation for this problem, though I am used to using double counting in combinatorial indentities.","['generating-functions', 'combinatorics', 'binomial-coefficients']"
1611797,How many trees on N vertices have exactly k leaves?,"I need help on the topic of counting labeled trees (with its nodes numbered from 1 to N) with exactly k leaves. I have thought about surjective functions that return the father of a node, but I'm not sure how to count all of them that give me correct trees. Here is the source of the question: http://www-math.mit.edu/~djk/18.310/Lecture-Notes/counting_trees.html and it's not explained in this paper. I would be very greatful if anyone could help me with a formula and, even more important, an explanation. Thank you!","['combinatorics', 'graph-theory', 'trees']"
1611814,Examples of fallacies in arithmetic and/or algebra [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 8 years ago . Improve this question I'm currently preparing for a talk to be delivered to a general audience, consisting primarily of undergraduate students from diverse majors.  My proposed topic would be Examples of fallacies in arithmetic and/or algebra . So my question would be: What are some examples of arithmetic/algebraic fallacies that you know of? One example per answer please. Let me give my own example, which is one of my personal favorites: Let $$a = b.$$
  Multiplying both sides by $a$, we get $$a^2 = ab.$$
  Subtracting $b^2$ from both sides, we obtain $$a^2 - b^2 = ab - b^2.$$
  Factoring both sides, we have $$(a + b)(a - b) = b(a - b).$$
  Dividing both sides by $(a - b)$, $$a + b = b.$$
  Substituting $a = b$ and simplifying, $$b + b = b,$$ and $$2b = b.$$
  Dividing both sides by $b$, $$2 = 1.$$ Of course, this fallacious argument breaks down because we divided by $a - b = 0$, since $a = b$ by assumption, and division by zero is not allowed.","['algebra-precalculus', 'big-list']"
1611816,A bounded linear operator between Banach spaces that cannot be compact,"Let $K: X \to Y$ be a bounded linear operator, where $X$ and $Y$ are two Banach spaces. Further assume that the image $imK$ is a $\infty$-dim closed subspace of Y. In my script they claim that in such a setting $K$ can never be compact because by the closed image theorem we have that $K(B)$ ($B$ closed unit ball in $X$) contains an open ball and hence has no compact closure because the dimension is $\infty$. My questions: I understand that the dimension of the closed unit ball $B$ characterizes the dimension of the underlying Banach space but I don't understand how this argument is used here. Also I don't quite get the thing with the open ball due to the closed image theorem and the thing that follows with the compact closure. How does one mash these things together the right way? EDIT: Ok I might have found another way to proof the above: Define $K_1: X \to im(K)$ by $x \mapsto K(x)$. Then $K_1$ is surjective, hence $K_1(B_{open})$ ($B_{open}$ denotes the open unit ball in x) contains a small $\delta$-ball $B_{\delta}$ centered at the origin of $Y$ by the open mapping theorem. If we assume $cl(K_1(B_{open}))$ to be compact in $im(K)$ we get that $cl(B_{\delta})=\{y \in Y | \Vert y \Vert_Y \leq \delta\} \subset cl(K_1(B_{open}))$ and since Y is Banach it's also Hausdorff therefore it follows that $cl(B_{\delta})$  is compact and hence by scaling the unit ball in $Y$ is also compact which contradicts the $\infty$-dimensional property of $im(K)$. Is this right?",['functional-analysis']
1611858,Vakil FOAG 11.3.B,"I am thinking about how to use Krull's PIT to prove this statement (11.3.B on Vakil's notes): If $(A,m,k)$ is a Noetherian local ring with maximal ideal $m$, and $f \in m$, then $\dim  A/(f) \geq \dim A-1$. What puzzles me is that Krull's PIT only gives us information about the codimension of $V(f)$. How can I know its dimension from its codimension?","['algebraic-geometry', 'commutative-algebra']"
1611863,"Zariski topology on $\mathbb{C}[X, Y]$","For a commutative ring $A$, let Spec$(A)$ be the set of prime ideals. A topology on Spec$(A)$ is defined by the closed sets
$$
\mathcal{V}(T) = \lbrace \mathbb{p} \in \text{Spec}(A) \vert T \subseteq \mathbb{p} \rbrace
$$
for some $T \subseteq A$, called the Zariski topology. We studied some basic properties of this topology in class (e.g. it is $\mathtt{T}_0$ and sober ) and worked out the rather trivial examples where $A$ is a field or a principal ideal domain. More complicated examples, like $\mathbb{Z}[T]$ or $\mathbb{C}[X, Y]$, were left as an exercise. I have no idea how to begin to answer the question 'describe the Zariski topology on Spec$(A)$' for these more complicated rings. I understand the theory, but what can be said about this topology in these cases? As a more general question: how to analyse the Zariski topology of a given ring? This is not a homework assignment, I'm just trying to get a better grip on what I have to study. I have gotten no further than a few remarks: Both rings are domains, hence $\lbrace 0 \rbrace$ is the minimum of Spec$(A)$ in both cases. By the Nullstellensatz, we know that the maximal ideals of $\mathbb{C}[X, Y]$ are of the form $(X - a, Y - b)$. Also the prime ideals of height one must be principal ideals, generated by an irreducible polynomial. In $\mathbb{Z}[T]$, the prime ideals of height one are principal ideals, generated by an irreducible polynomial or a prime in $\mathbb{Z}$.","['maximal-and-prime-ideals', 'general-topology', 'zariski-topology', 'commutative-algebra']"
1611906,"Proof that ""symmetrized"" sequence of random variables is independent.","While studying the following theorem from Loeve's book on probability: Let $X_n$ be uniformly bounded random variables. If $\sum X_n$
  converges a.s. then $\sum \sigma^{2}X_n$ and $\sum E X_n$ converges He writes the proof as follows: To the random variables $X_n$ we associate random variables $X_n'$
  such that $x_n$ and $X_n'$ are identically distributed for every n and
  $X_1,X_1',X_2,X_2'...$ is a sequence of independent random variables.
  We form the ""symmetrized"" sequence $X_{n}^{s} = X_n - X_n' $ of
  independent random variables. So I checked the section on symmetrization but I cannot figure out the following: -How can such a $X_n'$ be built in general? (they need to be independent and identically distributed)
-How can I proof that the ""symmetrized"" sequence is made up with independent random variables?","['independence', 'probability-theory']"
1611924,Change of variables from multiple to single,"Consider the following limit calculation: $$ \lim_{(x,y)\to (0,0)} \frac{\sin(x^2+y^2)}{x^2+y^2} = \lim_{t\to 0} \frac{\sin t}{t} = 1$$ How can one justify this change of variables from multiple to single? When can we do it (and when can't we?) Thanks.","['multivariable-calculus', 'calculus', 'limits']"
1611949,Fibonacci sequence digits,"We define the Fibonacci sequence by $F_{n+2}=F_{n+1}+F_{n}$, with $F_0=0$ and $F_1=1$. How to compute the last $30$ digits of $F_{2^{200}}$ for instance? 
can we use Python?how?","['number-theory', 'fibonacci-numbers', 'math-software', 'arithmetic']"
1611955,Eigenvalues of inverse matrix to a given matrix,How to calculate the eigenvalue of the inverse of a matrix given matrix is $A= \begin{bmatrix} 0&1&0\\ 0&0&1 \\4&-17&8\end{bmatrix}$ Is there any fast method?,"['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1611980,Description of Levi factors and unipotent radicals of parabolic subgroups in classical groups,"For an algebraic group $G$ over an algebraically closed field $k$, a parabolic subgroup $P$ has factorization $P = Q \rtimes L$, where $Q$ is the unipotent radical of $P$ and $L$ is some Levi factor of $P$. If $G = GL(V)$ with $\dim V = n$, then $$P = \{ \pmatrix{A_{n_1} &  & & * \\  & A_{n_2} & & \\  &  & \ddots & \\ 0 &  & & A_{n_t} } \}$$ for some $n = n_1 + \cdots + n_t$ and $$Q = \{ \pmatrix{I_{n_1} &  & & * \\  & I_{n_2} & & \\  &  & \ddots & \\ 0 &  & & I_{n_t} } \}$$ and for example $$L = \{ \pmatrix{A_{n_1} &  & & 0 \\  & A_{n_2} & & \\  &  & \ddots & \\ 0 &  & & A_{n_t} } \}$$ So $L \cong GL_{n_1} \times GL_{n_2} \times \cdots \times GL_{n_t}$. What about when $G = Sp(V)$ or $G = SO(V)$ in characteristic $p \neq 2$? Then $P$ is a stabilizer of a flag of totally singular subspaces, how does one describe $Q$ and $L$? Is there a good reference for this?","['group-theory', 'algebraic-groups', 'linear-algebra', 'lie-algebras']"
1611988,"What does Halmos mean when he says ""to get something for nothing"" (in the context of the axiom of specification)","I was reading Halmos Naive Set Theory, Chapter 2 The Axiom of Specification, in which after stating the Russel Paradox, he goes on to say ""The moral is that it is impossible, especially in mathematics, TO GET SOMETHING FOR NOTHING. To specify a set it is not only enough to pronounce some magic words; it is also necessary also to have at hand a set to whose elements the magic words apply."" This is after he shows that a universal set cannot exist ( in the naive perspective of set theory of which this book is about). What is bothering me, is the statement GET SOMETHING FOR NOTHING. I cannot seem to understand what he means there. If anyone has read the book and could explain it it would be a great help .",['elementary-set-theory']
1612012,"How should I understand the probability space $(\Omega, \mathcal{F}, P)$? What does ""hidden"" mean?","I thought I understood the measure theoretic concept of a probability space, but yesterday I realized that I really don't.  Here's what I mean: I thought we could think of $\Omega$ as the set of outcomes of a certain experiment.  So before we can even define the triple $(\Omega, \mathcal{F}, P)$, we would need to think about an experiment.  Now, each $\omega \in \Omega$ was supposed to be a possible outcome of the experiment, and the randomness thus comes from the fact that different outcomes can occur with different frequencies over time.  These long term frequencies define $P$ for us. So, if we consider the experiment of flipping a coin once, then $\Omega = \{ H, T\}$, since we only have those possible outcomes. Ok, but in the discussion of Brownian motion (or the diffusion of a particle across some environment like dye in water), we are told to think of each $\omega \in \Omega$ as a particle.  For example, each $\omega$ is a particle of pollen.  And the stochastic process $X_{t}(\omega)$ gives us, for each fixed $\omega$, the path that that particle $\omega$ follows.  But then what is the experiment we started with in order to get the set $\Omega$?  How are the particles that each $\omega$ represents the outcomes of some experiment?  And where does the randomness come from?  It seems like the randomness comes from the path the particle takes after we've already chosen it, so how can each particle be considered the outcome of some experiment?  Which experiment? Finally, after reading the above (and in addition to the above questions), I'd really like to understand why in many times, the probability space $(\Omega, \mathcal{F}, P)$ is often ""hidden"" or not explicit.  Can anyone explain this intuitively or give me some useful examples where the probability space is hidden?  Shouldn't it always be explicitly defined (since math is always explicit)?","['stochastic-processes', 'probability-theory', 'measure-theory']"
1612014,Is it possible to work entirely with Axioms and Isomorphisms?,"I've been thinking a lot about foundations, again, and specifically how to make isomorphism invariance clearer - which seems to be one of the main purposes of alternative foundations such as Homotopy Type Theory. The problem seems to be that we often have different models of the same object which we would really like to identify with each other (as a simple example,  $\mathbb{N} = \{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is an entirely different set from the $X \subseteq \mathbb{Z}$ we tend to call $\mathbb{N}$) and  in ZFC, under the current definitions, we cannot formally do so. What we tend to do if we ever point this out at all is simply call it an abuse of notation, and justify it by claiming that the clear isomorphisms existing between the two models will preserve any theorems we want to invoke. Homotopy type theory claims to make this easier by making it so that if we have two isomorphic objects we can say they are equal (in some sense I'm not entirely clear on) and so carry across any theorems we like. The problem is that it seems we really need to leave our comfort zone to be able to do this. My question is...could this all be fixed by changing our point of view on some definitions? For instance, rather than saying ""The set of natural numbers is [some specific set]"", we could have the definition be phrased something like ""$(X, Succ, 0)$ is a natural numbers set if and only if [Peano Axioms]"", and then have as a theorem that $\{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is a natural numbers set. What I'm effectively suggesting is that we relegate the phrase ""set of natural numbers"" to the same level as ""group"", so that rather than proving that some statement is true of a particular set which we have called the set of natural numbers, we prove that the statement is true for any set of natural numbers. When we want to work with natural numbers, we simply say ""Let $\mathbb{N}$ be a set of natural numbers"" in the same way that we often say ""Let $G$ be a group"". What kind of problems arise from working in this way? If I'm not being clear enough please let me know, because I do have a few specific definitions in my head that I could give as examples which might clarify what I mean. EDIT: While structural set theory is effectively what I want, my question is whether or not this type of definition change would give us the benefits of structural set theory without leaving ZFC.","['foundations', 'elementary-set-theory']"
1612017,Gradient of the TV norm of an image,"Context: I am trying to implement an algorithm for X-ray image reconstruction called ADS-POCS that minimizes the TV norm as well as reconstructs the image. After separating the reconstruction into 2 steps, namely data reconstruction and TV norm minimization, the second part is solved by a steepest descend. The image is a 3D image (relevant for the TV-norm). Problem: The paper defines $\vec{f}$ as a $1\times N_i$ vector of voxels. Later, defines the operator $\nabla_{\vec{f}}$ as $\nabla_{\vec{f}} Q(\vec f)=\sum_{i} \frac{\partial}{\partial f_i} Q(\vec f) \vec \delta_i$, being $\delta_i$ 1 in the $i$ voxel and  0 elsewhere. eventually, the algorithm to minimize the TV norm of the image is defined as a gradient descend loop where the update is defined as: $\vec f   =\vec f  -\alpha \cdot \nabla_{\vec{f}} ||\vec f ||_{TV}$ My problem is that I dont know how to compute the $\nabla_{\vec{f}} ||\vec f ||_{TV}$ term. I know how would I compute $||\vec f ||_{TV}$, but I feel like the $\nabla_{\vec{f}}$ is actually derivation the norm itself. If this were the 2-norm , for example,  I'd know how to derive it (e.g. see here ), but the TV-norm has the absolute value function, and its also dependent in neighboring voxels, while the 2-norm isn't. The TV norm can be written as (if I'm not wrong with my maths notation) $||\vec f||_{TV} =\sum_i ||\nabla \vec f_i||_{2}$ Being my mayor in ElecEng, I feel like there are some maths here that I'm missing in order to understand and code this""gradient of the TV-norm"" operator. So, how can I compute that term? How can I get the gradient of the TV-norm? Disclaimer: due to my little math knowledge, I am unaware if this is a too specific problem or it has a more generic mathematical explanation. If the question is too specific to help anyone else, please inform me and Ill delete/edit my question. The paper: Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization Emil Y Sidky and Xiaochuan Pan","['normed-spaces', 'linear-algebra']"
1612022,Counting duplicates,"I have been doodling around and have stumbled across the following problem: Say I have a set $p = \{p_1, p_2, p_3, ..., p_n\}$ where $p_i \in \mathbb{N}$ $p_i$ could represent the amount of a distinct object i.e $p_1 =$ amount of red balls and $p_2 =$ amount of blue balls and so on. Now to calculate how many distinct possible ways I could choose a new set of balls would be: $\prod\limits_{i=1}^n (p_i + 1) $ Yet I thought to myself it should also be possible to represent this in terms of combinations: $\sum\limits_{i=1}^n\binom {\sum\limits_{i=1}^n p_i} i $ This would work perfectly fine if all the elements are equal to 1 yet when $p_i > 1$ then the above would count duplicate sets. So I need to determine a way to get rid of all the duplicate sets. I tried counting all the different combinations of an element and multiplying it through with all the different combinations of the other elements, but things get messy and I am not sure if this is the right approach. Any ideas?","['combinatorics', 'recreational-mathematics', 'discrete-mathematics']"
1612054,Using a truth table to show that an argument form $(p\rightarrow q) \land q \rightarrow p$ is invalid.,"Use a truth table to show that the following argument form is invalid. p$\rightarrow$q q ∴p My attempt:
I made a truth table as below, but in what column and row can I find the argument form is invalid? $$\begin{array}{c|c|c|c} 
\space\space\space\space(p \rightarrow q)&\land &q& \rightarrow& p
 \\\hline
T\space T\space T&\space T&\space T&T&T
\\TFF&F&F&T&T\\F\color {red} {T}T&T&\color {red} {T}&F&\color {red} {F}\\FTF&F&F&T&F
 \\\hline
 step 1\space2\space 1&\space3&\space1&\space4&\space1
\end{array}$$ [EDIT] I think it's found invalid in the row where I wrote in red since it shows the conclusion p is false when all the premises (p$\rightarrow$q) and $q$ are true. FYI
""""A row of the truth table in which all the premises are true is called a critical row. ...You can show that an argument is invalid by constructing a truth table for the argument form and finding at least one critical row in which all the premises are true but the conclusion is false."" Source: Discrete Mathematics with Applications by Susanna Epp","['logic', 'discrete-mathematics']"
1612106,Why is $\lim_\limits{x\to 0}\frac{\sin(6x)}{\sin(2x)} = \frac{6}{2}=3$?,"Why is $\lim_\limits{x\to 0}\frac{\sin(6x)}{\sin(2x)} = \frac{6}{2}=3$? The justification is that $\lim_\limits{x\to 0}\frac{\sin(x)}{x} = 1$ But, I am not seeing the connection. L'Hospital's rule? Is there a double angle substitution happening?","['calculus', 'limits']"
1612202,The $n$th prime number is $85489307341$. How to find $n$?,"Say you are given the $n$th prime number $p_n$, like $p_n = 85489307341$, but not $n$. Questions: What's a quick, simple, and approximate formula for $n$? By adding more terms, can this formula be made more precise? Edit : In reference to the answer below, how can we tweak $n = \pi(x) \approx \frac{x}{\log(x)}$ to make it more accurate?","['number-theory', 'prime-numbers']"
1612232,"In $\triangle ABC,a,b,c$ are the sides of triangle satisfying $a^4+b^4+c^4-4abc+1=0$.Find $\frac{a^2+b^2+c^2}{S}$","In $\triangle ABC,a,b,c$ are the sides of triangle satisfying $a^4+b^4+c^4-4abc+1=0$ Find the value of $\frac{a^2+b^2+c^2}{S}$,where $S$ is area of the triangle $ABC$and find the value of $1+\frac{R}{r}$ where $R$ is the circumradius and $r$ is the inradius of the triangle $ABC$ My attempt:$a^4+b^4+c^4-4abc+1=0$ I expanded $(a+b+c)^4=a^4+4a^3b+4a^3c+6a^2b^2+6a^2c^2+12a^2bc+4ab^3+4ac^3+12ab^2c+12abc^2+4bc^3+4b^3c+6b^2c^2+b^4+c^4$ But this expression has got complicated and not seeming helpful and i do not know any other method to solve this question.",['trigonometry']
1612257,Intersection condition for a Grothendieck topology,"I am a bit confused about constructing a Grothendieck topology from a Grothendieck pretopology, largely because I have a discrepancy in definitions of the former. According to all of the questions I've seen on this site (and Wikipedia), there are three conditions for an assignment of sieves on an object to each object in a category to be a Grothendieck topology, namely stability under pullbacks, transitivity, and containing the maximal sieve. nLab, however, also has the requirement that two sieves are covering if and only if their intersection covers, and mentions that 'here the saturation condition is important'.
One direction of this hypothesis follows straight away if we are trying to show that we can construct a topology from a pretopology, but I don't see how, if we have two sieves $S,T$ which both contain a covering family, the intersection $S\cap T$ has to contain a covering family. Could anybody please explain why the nLab has this condition, what it means by its comment, and what I'm missing? Edit: Apparently (from the comments) the intersection condition is redundant.
Does anybody know where I could find a proof of this to cite?
I'm working on a tight word limit and would quite like to avoid having to state a proof myself if it's not just a quick one-liner...","['category-theory', 'grothendieck-topologies', 'algebraic-geometry']"
1612267,Probability space induced by a random variable,"Consider three random variables $Y$, $X$, $Z$ all defined on the same probability space $(\Omega, \mathcal{F}, \mathbb{P})$ such that $Y:  \Omega \rightarrow \mathcal{Y} \subseteq \mathbb{R}$, $X:  \Omega \rightarrow \mathcal{X} \subseteq \mathbb{R}$, $Z:  \Omega \rightarrow \mathcal{Z} \subseteq \mathbb{R}$. These random variables induce the following probability spaces: $(\mathbb{R}, \mathcal{B}(\mathbb{R}), P_Y)$, $(\mathbb{R}, \mathcal{B}(\mathbb{R}), P_X)$, $(\mathbb{R}, \mathcal{B}(\mathbb{R}), P_Z)$, where $\mathcal{B}(\mathbb{R})$ is the Borel $\sigma$-algebra on $\mathbb{R}$, $P_Y(B):=\mathbb{P}(\{\omega \in \Omega \text{ s.t. }Y(\omega)\in B\})$, $P_X(B):=\mathbb{P}(\{\omega \in \Omega \text{ s.t. }X(\omega)\in B\})$, $P_Z(B):=\mathbb{P}(\{\omega \in \Omega \text{ s.t. }Z(\omega)\in B\})$ for any $B \in \mathcal{B}(\mathbb{R})^k$. My question is related to the notation: is it correct in terms of notation to write the
  probability spaces induced by the three random variables with
  different probability measures $P_Y$, $P_X$, $P_Z$ despite the fact
  that all the three random variables are defined on the same
  probability space? If your answer is :""correct"", then I have another question: consider the sequence of real valued random variables $\{X_n\}_n$ and the random variable $X$, all defined on $(\Omega, \mathcal{F}, \mathbb{P})$. The definition with PRECISE notation of the statement ""$X_n$ converges in distribution to $X$"" is (a) $\lim_{n \rightarrow \infty} \mathbb{P}(\{\omega \in \Omega \text{ s.t. } X_n(\omega)\leq x\})=\mathbb{P}(\{\omega \in \Omega \text{ s.t. } X(\omega)\leq x\})$ $\forall x \in \mathbb{R}$ where the map $x\rightarrow \mathbb{P}(\{\omega \in \Omega \text{ s.t. } X(\omega)\leq x\})$ is continuous or (b) $\lim_{n \rightarrow \infty} P_{X_n}((-\infty, x])=P_X((-\infty, x])$ $\forall x \in \mathbb{R}$ where the map $x\rightarrow P_X((-\infty, x])$ is continuous, $(\mathbb{R}, \mathcal{B}(\mathbb{R}), P_{X_n})$ is the probability space induced by $X_n$, $(\mathbb{R}, \mathcal{B}(\mathbb{R}), P_X)$ is the probability space induced by $X$. Correct?","['probability-theory', 'random-variables', 'probability-distributions']"
1612297,Draw the graph of $\sin(\pi/​2-​2x)$,"I tried to draw the graph of this function $\sin\left(​\frac{\pi}{2}​ - ​2​x\right).$ If I understand correctly, this means that we have to shrink the graph by $2$, shift the curve by $\frac{\pi}{2}$ to the left, and invert it, because we multiplied $x$ by a negative number ($-2$ in this case). The curve I got this way is the same as the curve of $\sin(2x)$ function. Where did I make a mistake? What kind of transformations, and in which order we need to make, to transform $\sin(x)$ to $\sin\left(​\frac{\pi}{2}​ - ​2​x\right)?$","['trigonometry', 'functions', 'graphing-functions']"
1612308,"if $\ f(f(x))= x^2 + 1$ , then $\ f(6)= $?","I want to know how to solve this type of questions.  How can I find $\ f(x)$ from $\ f(f(x))$ Suppose, $\ f(f(x)) = x$   , then $\ f(x)=x$ or $\ f(x)=\dfrac{(x+1)}{(x-1)}$ how to find these solutions.. I have found one.. $\ f(6) = \sqrt{222} $ Is this correct?","['functions', 'functional-equations']"
1612382,Calculus function to determine points on the graph,"I am learning calculus and I just could not find the way to reach the answers of two cases Case 1 If $f(−5)=−2$ and $g(x)= −2⋅f(x)$, what point can you determine on the graph of $g$? Answer: $(-5,4)$ Case 2 If $f(−4)=1$ and $g(x)=f(x/−3)$, what point can you determine on the graph of $g$? answer: $(12,1)$ What is the process to find these two points?
Thanks a lot, Sonia Ardila.","['calculus', 'functions']"
1612411,Making an infinite generating function a finite one,"If we have some generating function $G(x)$ that generates terms indefinitely, is there a way to translate it to be a finite generating function? For example if I only want to generate the first $k$ terms of a sequence, can I do $G(x) - x^kG(x)$ or something similar? This isn't the right answer but it's where my thought process is. Trying to find some way to ""start"" the recurrence at a later point so that when I subtract one infinite generating function from the other, all the terms past $k$ drop out.","['number-theory', 'recurrence-relations', 'generating-functions']"
1612431,Book for studying Linear Algebra,"So I'm taking Linear Algebra in college. However, I'm not getting the grades I want and I have sort of difficulties using my teacher's book: it has very formal explanations and a strong lack of examples. I'm looking for a book that has a good explanation of the content and also solved exercises (which is a very important thing that I'm missing). So here is a list of books my college has: Calculus: T. M. Apostol 1994 Vol. I. and Vol.II Reverté Linear Algebra and Its Applications: G. Strang 1988 3rd ed. Academic Press Linear Algebra: S. Lipschutz 1994 Schaum's Outline Series. McGraw-Hill What is in your opinion the best book for self-study? (I'm going to repeat the examinations next semester but I'll be studying on my own.) If there is a better book than the ones on this list please tell me. Thanks!! EDIT: 
I study in a Portuguese-speaking country and we use a Portuguese book. The contents of the course are: Systems of linear equations. Gaussian elimination. Vectors and matrices. Inverse matrices. Linear spaces and linear transformations. Linear independence, bases and dimension. Kernel and range of a linear transformation. Applications to linear differential equations. Inner products and norms, orthogonal bases and Gram-Schmidt orthogonalization, orthogonal complements and projection onto subspaces. Applications to equations of straight lines and planes. Least squares approximations. Determinants and their applications. Eigenvalues and eigenvectors. Invariant subspaces. Diagonalization of matrices. Jordan forms. Hermitian, skew Hermitian, and unitary transformations. Quadratic forms.","['reference-request', 'book-recommendation', 'linear-algebra']"
1612437,Notation of the second derivative - Where does the $d$ go? [duplicate],"This question already has answers here : Why is the 2nd derivative written as $\frac{\mathrm d^2y}{\mathrm dx^2}$? (6 answers) Closed 5 months ago . In school, I was taught that we use $\dfrac{du}{dx}$ as a notation for the first derivative of a function $u(x)$ . I was also told that we could use the $d$ just like any variable. After some time we were given the notation for the second derivative and it was explained as follows: $$
\frac{d\left(\frac{du}{dx}\right)}{dx} = \frac{d^2 u}{dx^2}
$$ What I do not get here is, if we can use the $d$ as any variable, I would get the following result: $$
\frac{d\left(\frac{du}{dx}\right)}{dx} =\frac{ddu}{dx\,dx} = \frac{d^2 u}{d^2 x^2}
$$ Apparently, it is not the same as the notation we were given. A $d$ is missing. I have done some research on this and found some vague comments about ""There are reasons for that, but you do not need to know..."" or ""That is mainly a  notation issue, but you do not need to know further."" So what I am asking for is: Is this really just a notation thing?
If so, does this mean we can actually NOT use d like a variable?
If not, where does the $d$ go? I found this related question, but it does not really answer my specific question. So I would not see it as a duplicate, but correct me if my search has not been sufficient and there indeed is a similar question out there already.","['derivatives', 'notation']"
1612478,Importance of the compactness of idele group,"Si $k$ is a number field and $J_k$ is the group of $V_k^*$ of invertible elements of the adele ring $V_k$ with the induced topology given by the morphism 
$V_k\to V_k\times V_K,\  x\mapsto(x,x^{-1})$. In addition, $k^*$ is a topological subgroup of $J_k$. Now, let $d:J_k\to \mathbb R, \ \alpha=\{\alpha_v\}\mapsto \displaystyle d(\alpha)=\prod_{all v}\vert \alpha_v\vert_v$ We denote $Ker d=J_k^1$. By the product formula $k^*\subseteq J_k^1$. A relevant result is the compactness of the topological group $J_k^1/k^*$ in the quotient topology. I don't know of this topic, but in some books say's that the compacteness is importante on Class Field Theory, for example in Cassels-Frohlich A.N.T. I know a little of C.F.T but  not enough for see the importance of the compactness. They could give me some important results on C.F.T. involving the compactness of this group. Thanks for all.","['number-theory', 'adeles', 'class-field-theory', 'algebraic-number-theory']"
1612515,"y'''+4y""+4y'=2 solution of non-homogenous differential equation","This is non-homogenous differential equation :
$$y'''+4y''+4y'=2.$$ Of course, I started with characteristic polynomial of homogenous case: $$t^3+4t^2+4t=0$$ then $$t(t^2+4t+4)=0$$ we have:
$$t_1=0; t_{2,3}=-2.$$ So, solution of homogenous case is: $$y_s(x)=c_1 + c_2e^{-2x}+c_3xe^{-2x}$$ Now, I want to continue from this point to solution of non-homogenous differential equation. Please give any hint or general solution!! Thanks in advance.",['ordinary-differential-equations']
1612526,Riesz potential of a set and its complement,"Let $F\subset [0,1]$ be a closed set, $G = [0,1]\setminus F$, $\alpha \in(1,2)$. Is there a simple condition on $F$ under which the integral
$$
\int_F\int_G \frac{dx\,dy}{|x-y|^{\alpha}}
$$
is finite? I suspect that if the fractal dimension of $\partial F$ is small, then this is the case.","['fractional-calculus', 'integration', 'potential-theory']"
1612571,Second derivative of $x^3+y^3=1$ using implicit differentiation,"I need to find the $D_x^2y$ of     $x^3+y^3=1$ using implicit differentiation So, $$
x^3 + y^3 =1 \\
3x^2+3y^2 \cdot D_xy = 0 \\
3y^2 \cdot D_xy= -3x^2 \\
D_xy = - {x^2 \over y^2}
$$ Now I need to find the $D_x^2y$. I am pretty sure that means the second derivative. How would I do it to find the second derivative? apparently, it is supposed to be$$-{2x \over y^5}$$","['algebra-precalculus', 'implicit-differentiation', 'calculus', 'derivatives']"
1612587,Spivak's Limit Example,"Consider the function $f: (0, 1) \to \mathbb{Q}$ defined by
$$f(x) = \begin{cases}
0, & x\text{ irrational} \\
1/q, & x = p/q\text{ in lowest terms.}
\end{cases}$$
The problem is to show that $\lim\limits_{x \to a}f(x) = 0$, using $\delta$-$\epsilon$, for all $a \in (0, 1)$. That is, for all $\epsilon >0$ there is a $\delta > 0$ such that for all $x$ satisfying $0 < |x - a| < \delta$, $|f(x)-0| <\epsilon$. If $x$ is irrational, this is trivial . Edit : as discussed in the comments, this isn't as trivial as I thought it was. But what if $x$ is rational? Then $f(x) = 1/q$ as shown above, so
$$\left|\dfrac{1}{q}\right| < \epsilon\text{.}$$
I'm used to $\delta$-$\epsilon$ problems where I can ""work backwards"" to find $\delta$, but obviously $1/q$ isn't a function of $x$, and I'm lost as to what to do here. I sort of understand the discussion in Spivak, but I'm not quite getting how the discussion helps me find $\delta$, so I thought someone here could enlighten me. As mentioned in the comments, I don't agree that this is a duplicate.","['epsilon-delta', 'calculus', 'limits']"
1612616,how to find null space basis directly by matrix calculation,"The problem of finding the basis for the null space of an $m \times n$ matrix $A$ is a well-known problem of linear algebra. We solve $Ax=0$ by Gaussian elimination. Either the solution is unique and $x=0$ is the only solution, or, there are infinitely many solutions which can be parametrized by the non-pivotal variables. Traditionally, my advice has been to calculate $\text{rref}(A)$ then read from that the dependence of pivotal on non-pivotal variables. Next, I put those linear dependencies into $x = (x_1, \dots , x_n)$ and if $x_{i_1}, \dots , x_{i_k}$ are the non-pivotal variables we can write:
$$ x = x_{i_1}v_1+ \cdots + x_{i_k}v_k \qquad \star$$
where $v_1, \dots, v_k$ are linearly independent solutions of $Ax=0$. In fact, $\text{Null}(A) = \text{span}\{ v_1, \dots, v_k \}$ and $k = \text{nullity}(A) = \text{dim}(\text{Null}(a))$. In contrast, to read off the basis of the column space I need only calculate $\text{rref}(A)$ to identify the pivot columns ( I suppose $\text{ref}(A)$ or less might suffice for this task). Then by the column correspondence property it follows that the pivot columns of $A$ serve as a basis for the column space of $A$. My question is this: What is the nice way to calculate the basis for the null space of $A$ without need for non-matrix calculation? In particular, I'd like an algorithm where the basis for $\text{Null}(A)$ appears explicitly. I'd like avoid the step I outline at $\star$. When I took graduate linear algebra the professor gave a handout which explained how to do this, but, I'd like a more standard reference. I'm primarily interested in the characteristic zero case, but, I would be delighted by a more general answer. Thanks in advance for your insight. The ideal answer outlines the method and points to a standard reference on this calculation.","['matrices', 'reference-request', 'gaussian-elimination', 'linear-algebra']"
1612648,Simplify $\sum\limits_{a_1=0}^{p_1}\sum\limits_{a_2=0}^{p_2}\sum\limits_{a_3=0}^{p_3}...\sum\limits_{a_n=0}^{p_n}\frac{p!}{a_1!a_2!a_3!.... a_n!}$,I am currently doodling around with some mathematics and stumbled across the following expression: $$\sum\limits_{a_1=0}^{p_1}\sum\limits_{a_2=0}^{p_2}\sum\limits_{a_3=0}^{p_3}\cdots\sum\limits_{a_n=0}^{p_n}\frac{p!}{a_1!a_2!a_3!\cdots a_n!}$$ where $p=p_1+p_2+p_3+\cdots+p_n$ and $p_i \in \mathbb{N}$ This is a tedious expression to calculate and thus I was wondering whether it is possible to simplify it?,"['combinatorics', 'discrete-mathematics']"
1612649,Why must $A_n$ be generated by the 3-cycles,"For my course in Group Theory, I have seen various proofs that show why the alternating group $A_n$, which consists of the elements of $S_n$ that can be expressed as an even number of transpositions (i.e. 2-cycles), is generated by the 3-cycles. All of these proofs, and sometimes also the question, seem to guide you to showing that any element in $A_n$ can be expressed as a product of 3-cycles. Now I get the proofs up to this point. What I do not understand, and I hope you can help me with, is why the fact that any element in $A_n$ can be expressed as a product of 3-cycles means that $A_n$ is generated by the 3-cycles. Could it not be that, even though any element of $A_n$ can be expressed as a product of 3-cycles, that if we let the 3-cycles generate a group there will be elements in that group that are not in $A_n$? I do not see why our proof (for instance given here ) would exclude that possibility. If any of you could shed some light on this, your help is very much appreciated!","['permutations', 'group-theory']"
1612691,"Question about notation, language, and meaning in the context of combinatorics","In my math class today, my teacher defined a function as follows: A string on alphabet $[m]$ of length $n$ is a function: $$
s: [n] \rightarrow [m]
$$ To seque back to math from programming, what exactly is this function?  It reads like it is taking an $n$-length input and outputting an $m$-length output. I think some other specifications might be necessary: for instance, that the function is 1:1: for a number, $n$, there is one output, $s_n$. Is this specification implied in the arrow notation?  Or is it missing, where the arrow notation could just as easily imply that $s$ in fact, takes the whole of $[n]$ and produces a vector of length $[m]$...and I should fill in the gaps... Also, in terms of programming, a string can be defined as the physical sequence after the mapping occurs... Finally (and here is where all of my trouble stems from), the intent of this definition is that $s$ produce a tuple, or indexed item (indexed by $n$)...but the function signature indicates that it produces a $[m]$... Honestly, I hate it when I wind up answering myself by rewriting the question. $$
\begin{align}
f(n) &= x, x \text{ is a valid index of m}\\
s(n) &= (m_{f(n)})_n\\
s(1) &= (m_{f(1)})_1\\
\end{align}
$$ Where the tuple of information, $(n,m)$ is baked into the ordered list, $[m]$. It's funny, but I have no idea why I was confused anymore... Anyhow, the rule I've got is that with $s: [n] \rightarrow [m]$, 1:1ness is implied by default...for every 1 $n$, there is a single index number from $m$ placed next to $n$ by virtue of it being output in order with $n$...so the type signature of the output is actually the map, $\lbrace \lbrace 1,f(1) \rbrace, ... \rbrace$...","['combinatorics', 'functions', 'graphing-functions']"
1612708,Computing one-sided inverse of a matrix over some finite field,"Let $M$ be a $k\times n$ matrix with $k < n$, and assume that $\text{rank}(M)=k$. Over $\mathbb{R}$, one can compute a right inverse of $M$ as follows: $$M_\text{right}^{-1} = M^T(MM^T)^{-1}$$ However, the above relation does not necessarily hold over finite fields. For instance, let $M=\begin{bmatrix}1&2\end{bmatrix}$ be defined over $GF(5)$. Then, $MM^T=\begin{bmatrix}0\end{bmatrix}$, which is not invertible, so $(MM^T)^{-1}$ is not defined over this field. The right inverse can basically be computed by solving a linear system over the finite field. In the example above, let $M_\text{right}^{-1}=\begin{bmatrix}a\\b\end{bmatrix}$. Then: $$M M_\text{right}^{-1} = I \qquad\Rightarrow\qquad a+2b=1 \qquad\Rightarrow\qquad a=1-2b$$ Therefore, we can enumerate all right inverses over $GF(5)$: $\begin{bmatrix}1\\0\end{bmatrix}, \begin{bmatrix}4\\1\end{bmatrix},\begin{bmatrix}2\\2\end{bmatrix},\begin{bmatrix}0\\3\end{bmatrix},\begin{bmatrix}3\\4\end{bmatrix}$ Is there a better way to compute the right inverse of a matrix over finite fields, such as the closed formula $M_\text{right}^{-1} = M^T(MM^T)^{-1}$ over $\mathbb{R}$? and Can we build something similar to the Moore–Penrose pseudoinverse for finite fields? Edit: This paper by John D. Fulton discusses generalized inverses of matrices over a finite field , which seems to be relevant to my second question.","['matrices', 'pseudoinverse', 'linear-algebra', 'inverse']"
1612721,Triangularization of matrices over algebraically closed field,"A friend of mine is studying physics in first semester and for his next assignment, he has to prove the following theorem: Let $V$ be a finite dimensional vector space over an algebraically closed field $K$ . Further, let $f: V \to V$ be an endomorphism. Then there exists a basis $B$ of $V$ , such that $\mbox{Mat}_{B,B}(f)$ is an upper triangular matrix. Now this theorem really stumbles me, because I know two proofs of it but they are way beyond first semester. They have only introduced elementary matrix/basis manipulation, basis change theorems and they know theorems about the existence of eigenvectors and eigenvalues ( $K$ is algebraically closed so there has to exist an eigenvector). Is there a way to prove this theorem just with the mentioned work tools? Thanks for your help!","['matrices', 'abstract-algebra', 'matrix-decomposition', 'triangularization', 'linear-algebra']"
1612723,how to calculate $\int_{0}^{\infty}\frac{x}{\sqrt{e^x-1}}\mathrm{d}x$,"I was trying to solve another integral when then I reached this, I've no idea of how to select the contour for the integration.","['residue-calculus', 'complex-analysis', 'integration', 'definite-integrals', 'contour-integration']"
1612726,What's wrong with this equal probability solution for Monty Hall Problem?,"I'm confused about why we should change door in the Monty Hall Problem, when thinking from a different perspective  gives me equal probability. Think about this first: if we have two doors, and one car behind one of them, then we have a 50/50 chance of choosing the right door. Back to Monty Hall: after we pick a door, one door is opened and shows a goat, and the other door remains closed. Let's call the door we picked A and the  other closed door B. Now since 1 door has already been opened, our knowledge has changed such that the car can only be behind A or B. Therefore, the problem is equivalent to: given two closed doors (A and B) and one car, which door should be chosen (we know it's a 50/50 thing)? Then, not switching door = choosing A, and switching door = choosing B. Therefore, it seems that switching should be equally likely, instead of more likely. Another way to think: no matter which door we choose from the three, we know BEFOREHAND that we can definitely open a door with a goat in the remaining two. Therefore, showing an open door with a goat reveals nothing new about which door has the car. What's wrong with this thinking process? (Note that I know the argument why switching gives advantage, and I know experiments have been done to prove that. My question is why the above thinking, which seems legit, is actually wrong.) Thanks.","['monty-hall', 'probability']"
1612810,If $\mu(A)<\delta$ then $\sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon$,"Let $(X,\Sigma,\mu)$ be a finite measure space. Let $\mathcal{F}$ be a family of measurable functions $f:X\to\mathbb{R}$ . Prove that if $$\lim_{t\to\infty}\left(\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu \right)=0,$$ then $$\sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty,$$ and for all $\epsilon >0$ there exists $\delta >0$ such that: $$A\in\Sigma,\mu(A)<\delta\Longrightarrow \sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon.$$ For the first part. Let $t>0$ such that: $\displaystyle\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu<1$ . Fix $f\in\mathcal{F}$ . Then $$\displaystyle\int_X|f|d\mu=\int_{\{|f|\ge t\}}|f|d\mu+\int_{\{|f|<t\}}|f|d\mu\le 1+t\mu(X)<\infty.$$ And $1+t\mu(X)$ does not depend of $f$ , so we get $\sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty$ . Is that correct? I don't know how to do the second part. Could it be true that $v(A):=\sup_{f\in\mathcal{F}}\int_A|f|d\mu$ is a finite measure? I wanted to try something similar to that known result when $\mathcal{F}$ is just one function (some call it absolutely continuous of the measure $v$ , I think). Any hint? Thank you.",['measure-theory']
1612811,Are all rationally parametrized plane curves algebraic? How does one find their degree?,"Suppose a plane curve is given parametrically by $x=p(t),y=q(t)$, where $p,q$ are rational functions. I originally assumed that this means that the parametrized curve is algebraic, i.e. that it is the zero set of a polynomial in $x$ and $y$, but now I have doubts. Take for starters the case where $p,q$ are polynomials of degrees $m$ and $n$ respectively. In simple examples like $x=t^2+2,y=t^3-1$ the algebraic equation is easy to obtain, $(x-2)^3=(y+1)^2$, and the degree of the curve appears to be $\text{max}(m,n)$ generically (of course one can make up degenerate examples like $x=t^3,y=t^3$, where it drops). But what about $x=t^5+t^2+1, y=t^6-t+1$? It's not like we can solve for $t$ in radicals, plug in, and take powers to eliminate the radicals to get an algebraic equation in terms of $x$ and $y$. And even when that's possible it is not clear what the degree will come out to be after taking all the powers. So my questions are: when are polynomially (or more generally rationally) parametrized plane curves algebraic? Is there an algorithm for finding the algebraic equation when there is one? Is there a way to find the algebraic degree without finding the equation? Is the degree generically $\text{max}(m,n)$ when the parametrizing polynomials have degrees $m,n$? I looked in Gibson's Elementary Geometry of Algebraic Curves, and Reid's Undergraduate Algebraic Geometry, but they only deal with converse questions, from equation to parametrization. EDIT: After searching I found out that converting parametric equations into implicit ones is called implicitization (the opposite of parametrization), and apparently it is a big thing in computational geometry and applications because it provides an efficient way of determining if a given point lies on a given curve (or surface). Sederberg, Anderson and Goldman give an overview of elimination theory that in particular implicitizes rationally parametrized plane curves, and explain why the degree does not increase under implicitization (p.78).","['algebraic-curves', 'polynomials', 'plane-curves', 'algebraic-geometry']"
1612812,Is parallelizability equivalent to the set of vector fields being free?,"We have the $C^{\infty}(M)$-module $\mathcal{D}^1(M)$ of vector fields over a $C^{\infty}$ manifold $M$. Is being parallelizable equivalent to this module being free, of dimension $n$? I have the impression it is, since we can take as a basis the $n$ vector fields given by the assumption that $M$ is parallelizable and decompose every vector field in their components in each tangent space, and reciprocally the basis of the module would give the vector fields needed to parallelizability. Am I overlooking something? If this is true, is it ever possible for $\mathcal{D}^1(M)$ to be a free module of a different dimension, other than $n$?","['differential-geometry', 'differential-topology']"
1612825,Equation used to represent a disc galaxy,"I'm trying to create a solid which looks something like a disc galaxy: Key features are: Bulge in the middle Tapered ""width"" as it extends to a disc shape The end goal would be to use Python to generate a bunch of ""points"" (ie, stars) within this galaxy shape randomly and use that to create a galactic model for a game. I've tried describing the galaxy using spherical coordinates broken up into sections but am failing pretty hard. That's driven to try and find a single equation for the whole solid and then give random values to one of the free variables to find points within the solid. Any ideas?","['spherical-coordinates', 'functions', 'solid-geometry']"
1612915,Continuous and discontinuous function problem,"The following problem can be true? Problem: For every positive integer $n>1$ there exists a function $ f\left( x \right)$ on $\mathbb{R}$ which satisfies both following conditions: (i) $f\left( x \right),{\rm{ }}f\left( {f\left( x \right)} \right), \ldots ,{\rm{ }}f\left( { \ldots f\left( x \right) \ldots } \right)$ ( $ (n-1)$ times $ f $) discontinuous at every $x$ belong to $\mathbb{R}$. (ii) $ f\left( { \ldots \left( {f\left( x \right) \ldots } \right)} \right)$ ( $n$ times $f$ ) continuous in $ \mathbb{R}$.","['calculus', 'analysis']"
1612919,On what sets other than $\mathbb{N}$ might we use proof by induction?,"Suppose we have a set $S$ with $s_1\in S$ and $f: S\to S$ and $n\subset S$ such that  $n=\{s_1, f(s_1), f(f(s_1)), \cdots \}$ ($n$ not necessarily infinite). To establish properties of $n$, can we use proof by induction on $n$ itself using $f$ as the successor function? EDIT: Suppose $f:S\to S$. For what it is worth, here is my own formal proof that for every $s_1\in S$ there exists a set $n\subset S$ on which induction holds, with $f$ being the successor function and $s_1$ being the ""first element"" in $n$. The key to the proof is the construction of the subset $n$: $\forall a:[a\in n \iff a\in S\land \forall b\subset S:[s_1\in b\land \forall c\in b : [f(c)\in b]]\implies a\in b]$ We can show that: (1) $s_1\in n$ (2) $\forall a\in n: f(a)\in n$ (3) $\forall P\subset n:[s_1\in P \land \forall a\in P: [f(a)\in P] \implies \forall a\in n : [a\in P]]$ These are the equivalent of 3 of the 5 Peano axioms for the natural numbers (the modern set-theoretic version). Missing are only that $f$ would be injective, and that $s_1$ would have no pre-image in $n$ under $f$.","['induction', 'logic', 'elementary-set-theory', 'peano-axioms']"
1612954,"Can I use ""$\iff$"" symbol when I ""transform"" an expression to another form?","I am writing a solution to prove that $\sqrt5$ is not rational. Here is my first half proof: Assume $\sqrt{5}$ is a rational number. By the definition of rational number, $\sqrt{5} = \frac{p}{q}$, where $p,q\in\mathbb{Z^+}, q\neq0$, and $gcd(p,q)=1$. We have $5=\frac{p^2}{q^2} \iff 5q^2=p^2$. Can I use ""$\iff$"" symbol like this? How about if a question is asking me to work backward from the desired conclusion and then prove: If x and y are nonnegative integer, then $\frac{x+y}{2}\geq \sqrt{xy}$. Can I do like something like: (first half proof) $\frac{x+y}{2}\geq \sqrt{xy} \iff x+y\geq 2\sqrt{xy} \iff (x+y)^2 \geq 4xy 
\iff x^2+2xy+y^2 \geq 4xy \iff x^2-2xy+y^2 \geq 0 \iff (x-y)^2 \geq 0$. Should I use $\iff$, $\Leftarrow$ or $\Rightarrow$?","['number-theory', 'proof-writing', 'discrete-mathematics']"
1612963,Evaluate $ \lim_{x \rightarrow - \infty} \frac{\sqrt{9x^6-x}}{x^3+1} $,"I have started learning limits in calculus and I came across this question: Evaluate $ \displaystyle \lim_{x \rightarrow \infty} \dfrac{\sqrt{9x^6-x}}{x^3+1} $ . I rewrite the above as $ \displaystyle \lim_{x \rightarrow \infty} \dfrac{\sqrt{9-\dfrac{1}{x^5}}}{1+\dfrac{1}{x^3}} = \lim_{x \rightarrow \infty} \dfrac{\sqrt{9}}{1} = \boxed{3}  $ But now I am asked to compute $ \displaystyle \lim_{x \rightarrow -\infty} \dfrac{\sqrt{9x^6-x}}{x^3+1} $ How to solve for minus infinity? Where to put minus sign , I am getting confused , please help. Thanks.","['calculus', 'limits']"
1612989,"The number of maps $f$ from the set $\{1,2,3\}$ into the set $\{1,2,3,4,5\}$ such that $f(i)\le f(j)$, whenever $i<j$","The number of maps $f$ from the set $\{1,2,3\}$ into the set $\{1,2,3,4,5\}$ such that $f(i)\le f(j)$, whenever $i<j$.","['combinatorics', 'functions']"
1613039,An inequality about the dimension of fiber,"I am working on Problem 11.4.A of Vakil's notes: Let $X$ and $Y$ be two locally noetherian schemes, $\pi:X \to Y$ is a morphism, and $\pi(p)=q$. Then prove:
  $$\operatorname{codim}_Xp \leq \operatorname{codim}_Yq+\operatorname{codim}_{\pi^{-1}(q)}p.$$ There are morphisms of stalks: $O_{Y,q} \to O_{X,p}$ and $O_{X,p} \to O_{\pi^{-1}(q),p}$ How can I use a set of parameters which cut out the maximal ideal in $O_{Y,q}$ and a set of parameters which cut out the maximal ideal in $O_{\pi^{-1}(q),p}$ to get a set of equations that cut out the maximal ideal in $O_{X,p}$? There is no problem to go from $O_{Y,q}$ to $O_{X,p}$, but how can I lift elements from $O_{\pi^{-1}(q),p}$ to $O_{X,p}$?","['algebraic-geometry', 'commutative-algebra']"
1613093,Calculate complex determinant,"$$\left| {\begin{array}{*{20}{c}}{{a^2}}&{{{(a + 1)}^2}}&{{{(a + 2)}^2}}&{{{(a + 3)}^2}}\\{{b^2}}&{{{(b + 1)}^2}}&{{{(b + 2)}^2}}&{{{(b + 3)}^2}}\\{{c^2}}&{{{(c + 1)}^2}}&{{{(c + 2)}^2}}&{{{(c + 3)}^2}}\\{{d^2}}&{{{(d + 1)}^2}}&{{{(d + 2)}^2}}&{{{(d + 3)}^2}}\end{array}} \right|
$$ It's very stupid desicion for me to expand it by row or column. Any suggestions?",['linear-algebra']
1613119,"A diophantine equation with only ""titanic"" solutions","I made a note some time ago that I had read in some book that the equation $$313(x^3+y^3)=t^3$$ has positive integer solutions, but that these are so large that it would be absolutely hopeless to search for them with computers.  Unfortunately, I didn't write down where I read this and if you only have the equation, the results Google gives you aren't very helpful.  I could only find this so far. Can someone point me to an article or book where I can read more about this equation?  (Preferably something with a proof of the claim above which is accessible even if you're not an expert in number theory.)","['number-theory', 'reference-request', 'diophantine-equations']"
1613131,Is is possible to obtain exactly 16 black cells?,"We are given an $18*18$ table, all of whose cells may be black or white. Initially all the cells are colored white. We may perform the following operation:
Choose one column or one row and change the colour of all cells in this column or row. Is it possible by repeating the operation to obtain a table with exactly $16$ black cells? I know that this question is based on invariant principle but I am not getting the invariant.",['combinatorics']
1613144,Number of common chords of the two parabolas,How can we find common chords to the parabolas  $$ (y-2)=(x-3)^2$$ and $$(x-2)=(y-3)^2$$ without drawing graphs. What i have done is i have subtracted both of them and i got $$(y-x)=(x-y)(x+y-6)$$ $\implies$ $$(x-y)(x+y-5)=0$$ Hence $x=y$ and $x+y=5$ are the two common chords. How can find whether there are any other chords,"['conic-sections', 'geometry']"
1613147,Factore $(x+1)(x+2)(x+3)(x+4)-35$,"I need to factor
$$(x+1)(x+2)(x+3)(x+4)-35$$
I know that the answer will be 
$$(x^2+5x+11)(x^2+5x-1)$$
I go out only
$$(x^2+5x)(x^2+5x+10)-11$$
Help me.",['algebra-precalculus']
1613158,Polynomials with some roots whose product is 1,"Consider the complex coefficient polynomial equation
\begin{eqnarray}
x^n-\left(a_1+\binom{n}{1}\right)x^{n-1}+\cdots+(-1)^k\left(a_k+\binom{n}{k}\right)x^{n-k}+\cdots+(-1)^{n-1}\left(a_{n-1}+\binom{n}{n-1}\right)x+(-1)^n=0
\end{eqnarray}
By Vieta Theorem, the product of its roots is 1. If we impose the condition that, among the $n$ roots, there exist $k$ roots (counted with multiplicity) whose product is 1, then $a_1, \cdots, a_{n-1}$ have to satisfy a polynomial equation $P(a_1, \cdots, a_{n-1})=0$, where $P\in\mathbb{C}[a_1, \cdots, a_{n-1}]$ has 0 as the constant term. Question: Under what condition does $P$ has nonzero linear term? The following are some easy examples I have worked out. If $k=1$, then that means one of the roots is 1. Plugging $x=1$ to the original polynomial equation yields that $P$ can be 
\begin{eqnarray}
\sum_{i=1}^{n-1} (-1)^ia_i
\end{eqnarray}
whose linear term is nonzero. For $k=2$, $n=3$ or $4$, $P$ also has nonzero linear term. If $k=2$ and $n=5$, then the original polynomial equation can be factored as \begin{eqnarray}
(x^3+px^2+qx-1)(x^2+rx+1)=0
\end{eqnarray}
Comparing coefficients, we have
\begin{align*}
a_1&=-p-r-5\\
a_2&=pr+q-9\\
a_3&=-p-qr-9\\
a_4&=q-r-5
\end{align*}
According to Mathematica, $P$ is, up to a constant multiple, 
\begin{eqnarray}
-a_1^3+a_3 a_1^2+a_4 a_1^2+a_1^2+a_4^2 a_1-2 a_2 a_1+2 a_3 a_1-a_2 a_4 a_1-a_3 a_4 a_1-2 a_4 a_1-a_4^3+a_2^2+a_3^2+a_2 a_4^2+a_4^2-2 a_2 a_3+2 a_2 a_4-2 a_3 a_4\end{eqnarray}
which does not have nonzero linear terms. For $k=3$, $n=6$, $P$ is
\begin{eqnarray}
a_1^3-a_4 a_1^2+3 a_1^2-4 a_2 a_1+6 a_3 a_1-12 a_4 a_1+a_3 a_5 a_1+22 a_5 a_1+a_5^3-a_3^2-a_2 a_5^2+3 a_5^2+4 a_2 a_4-12 a_2 a_5+6 a_3 a_5-4 a_4 a_5\end{eqnarray}
which again does not have nonzero linear terms. My guess is that, if $k\geq 2$ and $n-k\geq$ 2, then $P$ does not have nonzero linear term, except the case $k=2$, $n=4$.","['abstract-algebra', 'polynomials']"
1613172,"Knowing $|A| \leq |B|$, how do I prove $|C^A| \leq |C^B|$?","Given three (nonempty) sets $A, B$ and $C$, and knowing that $|A| \leq |B|$, how can I prove that $|C^A| \leq |C^B|$? This problem is trivial if we want to prove that the sets are equipotent, because it is very easy to create a bijective function. Here, we know that there exists an injective function $\phi: A \rightarrow B$, and we have to construct another injection, $\psi: C^A \rightarrow C^B$. I came up with this: let $f: A \rightarrow C$ and $b \in B$; then $(\psi(f))(b) = 
\begin{cases}
f(a)  & \exists \,a \in A \;\; \phi(a) = b\\
??? & \text{otherwise}
\end{cases}
$ But I couldn't figure out what to do in the second case (which is very possible because we know that $A \subseteq B$). Intuitively, it is rather obvious that if we have less elements in $A$ than in $B$, then less functions transforming $A$ into $C$ exist, but of course some sort of formal proof is needed. Since I don't know how standard that notation is, I'd like to clarify that $A^B$ denotes the set of all possible functions transforming elements of $B$ into elements of $A$.",['elementary-set-theory']
1613198,Comparison between Shannon's and Blackwell's measure of informativeness,"I want to compare the concept of ``precision of information'' between signals $x \in X$ and states $\omega \in \Omega$ defined by Blackwell and Shannon. Denote the conditional probability distribution over signals given states by $\mathcal{P}_{X|\Omega}$ and the unconditional probability distribution over states and signals by $\mathcal{P}_\Omega$ and $\mathcal{P}_X$ respectively. Let the number of states and signals be finite. Blackwell says that the conditional probability distribution $\mathcal{P}_{X|\Omega}$ is more informative than another distribution $\mathcal{\tilde{P}}_{X|\Omega}$, $\mathcal{P}_{X|\Omega} \supset \mathcal{\tilde{P}}_{X|\Omega} $, if and only if there exist a Markov matrix $M$:
\begin{equation}
\mathcal{P}_{X|\Omega} M =  \mathcal{\tilde{P}}_{X|\Omega}
\end{equation} For example, suppose the conditional probability distribution $\mathcal{P}_{X|\Omega} $ is given by the following Markov matrix:
\begin{equation} 
\begin{bmatrix}
1 & 0 \\
0 & 1 
\end{bmatrix}
\end{equation}
Such a matrix is fully informative: The signal reveals that state with perfect accuracy. Suppose the matrix $M$ is written as:
 \begin{equation} 
M = 
\begin{bmatrix}
1/2 & 1/2 \\
1/2 & 1/2 
\end{bmatrix}
\end{equation}
The distribution $\mathcal{\tilde{P}}_{X|\Omega}$ is then very diffuse in the sense that the signals do not favour any state. Shannon uses a different notion of ``informativeness''. Let entropy be given by function $H$. For the unconditional distribution over states, the entropy is: \begin{equation}
H(\mathcal{P}_\Omega)  = - \sum_\Omega \mathcal{P}_\Omega(\omega) \log_2 (\mathcal{P}_\Omega(\omega))
\end{equation}
Informativeness between signals and states is quantified by the mutual information of the unconditional probability distribution between signals and states:
\begin{equation}
I(\mathcal{P}_{X,\Omega}) =  H(\mathcal{P}_\Omega) - \sum_X \mathcal{P}_X (x) H(\mathcal{P}_{\Omega|X} ( \ |x))
\end{equation}
In Shannon's notion of informativeness, $\mathcal{P}_{X,\Omega} $ is more informative than  $\mathcal{\tilde{P}}_{X,\Omega} $ if $I(\mathcal{P}_{X,\Omega}) > I(\mathcal{\tilde{P}}_{X,\Omega}) $. What is the relationship between the two concepts of informativeness is? Can one proof that an information structure which is more informative in the sense of one author is more informative in the sense of another author?","['information-theory', 'probability-theory', 'entropy']"
1613210,Proof that $\sum_{i=0}^n {n\choose i}2^{i}=3^{n}$ [duplicate],"This question already has answers here : How to prove that $\sum_{r=0}^n\binom{n}{r}2^r=3^n$ (4 answers) Closed 8 years ago . The following sum came up in a combinatorial argument. I know what it equals thanks to Wolfram Alpha, but I'm not sure how to show it $$\sum_{i=0}^n {n\choose i}2^{i}=3^{n}$$","['combinatorics', 'summation', 'binomial-coefficients']"
1613214,Proof $\int \limits_{0}^{\infty}\left(\frac{\sin x}{x}\right)^2dx=\frac{\pi}{2}$ by definition,"Let $f(x)=\mathbb{I}_{[-t,t]}$ where $t\in (0,\pi)$. Using Parseval's theorem to this function we get: $$\sum \limits_{n=1}^{\infty}\dfrac{\sin ^2(nt)}{n^2t}=\dfrac{\pi-t}{2}.$$ Prove that $$\int \limits_{0}^{\infty}\left(\frac{\sin x}{x}\right)^2dx=\lim \limits_{t\to 0}\sum \limits_{n=1}^{\infty}\dfrac{\sin ^2(nt)}{n^2t}=\frac{\pi}{2}.$$
How to prove the first equality strictly using $\varepsilon-\delta$? Unfortunately I have not any ideas. I know that this sum is a Riemann-integral sum but I can't prove it rigorously. I would be very grateful to anyone who'll post full solution because I can't find it's proof.",['real-analysis']
1613220,The function integrated over the two-sphere is smooth in the radial parameter,"Let $f: \mathbb{R}^3 \rightarrow \mathbb{R}$ be a smooth function. Define the function $h: \mathbb{R} \rightarrow \mathbb{R}$
$$ h(w) = \int_{S^2} d\Omega(\hat{n})\,f(\sqrt{|w|}\, \hat{n}) $$
where $d\Omega(\hat{n})$ is the standard measure on two-dimensional sphere. That is, in $\theta$, $\phi$ coordinates $\sin\theta d\theta d\phi$, $\hat{n}(\theta,\phi)=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)$) and
$$ h(w) = \int_{0}^\pi d \theta\int_0^{2\pi} d \phi~~ f(\sqrt{|w|}(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)). $$ Is it true that $h$ is smooth everywhere? 
This statement is certainly true if $f$ is polynomial (terms containing odd powers of $\sqrt{|w|}$ vanish after integration).","['derivatives', 'real-analysis', 'integration']"
1613228,Is every compact subset of $\mathbb{R}^n$ a deformation retract of some open neighborhood?,"Suppose $A \subset X=\mathbb{R}^n $ is compact. Is it necessary that $ \exists$ an open set $U \supset A$ such that $A$ is a deformation retract of $U$? If yes, is there a concrete construction of the retraction homotopy? I am unable to come up with a proof or a counter example. The statement above holds in all examples that I can think of.","['algebraic-topology', 'general-topology']"
1613281,What is an exact differential equation?,"During A levels, we discussed a type of differential equation which we called exact . By this, we meant a differential equation that had its LHS obtainable by differentiating a product. For example the DE $$x^2\cos y\frac{\text{d} y}{\text{d} x}+2x\sin y=\frac{1}{x^2}$$ is exact because we can look at it this way: $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ thus obtaining $$\frac{\text{d}}{\text{d}x}\left(x^2\sin y\right)=\frac{1}{x^2}$$ which can easily be solved by integrating. However now, in university, we discuss exact equations in the form $$M(x,y)dx+N(x,y)dy=0$$ which are said to be exact if and only if $\forall (x,y)\in\mathbb R^2$ : $$\frac{\partial M}{\partial y}(x,y)=\frac{\partial N}{\partial x}(x,y)$$ Is there a correlation between the two? Are they the same thing but I'm not realising it?",['ordinary-differential-equations']
1613304,"If $f(n)= \binom{n}{0}a^{n-1}-..+(-1)^{n-1}\binom{n}{n-1}a^{0}$ ,Then $f(2007)+f(2008) $","If $\displaystyle a= \frac{1}{3^{223}}+1$ and $\displaystyle f(n)= \binom{n}{0}a^{n-1}-\binom{n}{1}a^{n-2}+...........+(-1)^{n-1}\binom{n}{n-1}a^{0}$ Then value of $f(2007)+f(2008) = $ $\bf{My\; Try::}$ Multiply both side by $a\;,$ We get $$af(n) = \underbrace{\binom{n}{0}a^{n}-\binom{n}{1}a^{n-1}+...........+(-1)^{n-1}\binom{n}{n-1}a+(-1)^n}_{\bf{(a-1)^n}}+(-1)^{n+1}$$ So we get $$af(n)=(a-1)^n+(-1)^{n+1}\Rightarrow f(n) = \frac{(a-1)^n+(-1)^{n+1}}{a}$$ So $$f(2007)+f(2008) = \frac{1}{a}\left[(a-1)^{2007}+1+(a-1)^{2008}-1\right]$$ So we get $$f(2007)+f(2008) = \frac{(a-1)^{2007}\cdot a}{a} = (a-1)^{2007}=3^{-223\times 2007}$$ My Solution did not match here. Where i have done Wrong, Help me Thanks",['algebra-precalculus']
1613328,How to show that $\int_0^{\infty} dx \frac{\log{x}}{1+x^2}$ is zero using complex analysis,"I want to show this using contour integration, the appropriate contour is a keyhole I think.","['residue-calculus', 'complex-integration', 'complex-analysis', 'integration', 'contour-integration']"
1613357,Who has revealed more about a secret password?,"Today, Bob, a colleague of mine, accidentally revealed that his password contains a . Alice laughed, but then also inadvertently said her password does not contain any a . Who has given away more about his/her password? In other words, whose password is now easier to guess? EDIT: I have purposedly not provided information about the length of any password, or even maximum length. One can assume the maximum length to be unbounded. I.e. let the variable m representing the maximum password length in any formulae, tend towards infiny. EDIT2: I picked ""Alice"" and ""Bob"" as a homage/reference to the homework problems in my undergraduate course's books. But this really happened. A colleague of mine has a defective a in his keyboard. EDIT3: Here's my stab at the question that I arrived at with my colleagues over lunch yesterday: Let's write the formulae for the number of possible passwords given an alphabet of integer size $\alpha$ and a maximum password length of $m$ $\sum_{n=1}^m \alpha^n$ This I arrived at by summing ""$\alpha$ passwords of length 1"" + ""$\alpha^2$ passwords of length 2"" + ... + ""$\alpha^m$ passwords of length $m$"". Now, Alice has revealed she doesn't have an a anywhere in her password. She has reduced the alphabet size to the attacker by 1. So the total number of passwords for her is: $N_{Alice}=\sum_{n=1}^m (\alpha-1)^n$ Bob's total number of possible passwords has also decreased: $N_{Bob}=\sum_{n=1}^m \alpha^n -\sum_{n=1}^m (\alpha-1)^n$ In other words, $N_B$ has decreased exactly the same amount as the number of possible passwords for Alice, which have the letter a . Now, if $m$ is [the totally unrealistic value of] 1, Alice has clearly given away her password completely, while Bob still has $\alpha - 1$ total passwords. But, as an intuition as $m$ increases towards infinity, I think $N_{Alice} << N_{Bob}$, so I think it is Alice who is now more likely to have his password brute forced!! My calculus is a bit shaky :-) so I do not know yet if it is true that $N_{Alice} << N_{Bob}$ as $m$ tends towards infinity. If this question is reopened, perhaps someone can help me. EDIT4: Trial-and-error in a simple program seems to confirm my intuition. For an alphabet size of 26, if the maximum password length is 17, Bob has given away more. If it is 18, he wins (Alice has given away more).","['combinatorics', 'cryptography', 'probability']"
1613379,Global generation of vector bundles by an exact sequence,"Let $X$ be a smooth projective complex surface and $V$ a globally generated vector bundle on $X$. Suppose we have a vector bundle $E$ sitting in an exact sequence
$$0\to V\to E\to O_X(C)\otimes A \to 0$$
where $C$ is a smooth curve, and $A$ a torsion sheaf on $X$ supported on $C$, whose restriction to $C$ is a line bundle. In particular $V$ and $E$ have the same rank and the map $V\to E$ is an isomorphism away from $C$. In particular, $E$ too is globally generated, away from $C$. The question is: what about the points of $C$? Can we deduce from the sequence above that $E$ can fail to be globally generated only at the base points of $A$ ?
(we may also assume that $O_C( C )$ is globally generated) Edit As Mohan suggests this is not true if the sections of $C$ can't be lifted. So my question is: what precisely means that ""the sections of $C$ can be lifted"" and how to conclude for the base points of $E$ under this assumption?","['vector-bundles', 'algebraic-geometry', 'holomorphic-bundles']"
1613380,Counting surjective functions,"We have $r$ objects and $n$ boxes. I have to count all the combinations possible if the objects and boxes could be both different. If that happens I can count the number of variations from $n$ to $r$ (number of functions between objects and boxes). I mean, $n^r$. But if I have to count all the combinations possible if anyone of the boxes is empty ($r\ge n$). Now I have to count the surjective functions. For example if I have $r$ objects and 1 box. The number of surjective functions is 1. Then, if I have $r$ objects and 2 boxes, the number of surjective functions is $2^r-2$. And finally if I have $r$ objects and 3 boxes, I will count $3^r-2\cdot[3\cdot2^r-3]$. How do I get the formula for $r$ objects and $n$ boxes?",['functions']
1613392,Why $\zeta (1/2)=-1.4603545088...$?,I saw $\zeta (1/2)=-1.4603545088...$ in this link . But how can that be? Isn't $\zeta (1/2)$ divergent since $\frac{1}{\sqrt{1}}+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+..>\frac{1}{1}+\frac{1}{2}+\frac{1}{3}+..$ ?,"['number-theory', 'divergent-series', 'riemann-zeta']"
1613433,Is a general smooth rescaling of a complete vector field itself complete?,"$\newcommand{\Ga}{\Gamma}$
$\newcommand{\R}{\mathbb{R}}$
$\newcommand{\til}{\tilde}$
$\newcommand{\M}{M}$
$\newcommand{\ep}{\epsilon}$
$\newcommand{\brk}[1]{\left(#1\right)} $
$\newcommand{\R}{\mathbb{R}}$
$\renewcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}$ Let $M$ be a smooth manifold, $X \in \Ga(TM) $.
Assume $X$ is complete , i.e, the flow of $X$ is defined on whole $\mathbb{R} \times M$. I wonder what happens to the flow when $X$ is multiplied by some real positive function  $f \in C^{\infty}(M)$. My guess is that the flow will still be defined for any time, and that it will be a reparametrization of the original flow. (i.e only the speed may change). In particular $fX$ will be complete. Question: Is this guess correct? Does it hold for non-compact manifolds? (Note I assume anyway $X$ is complete) Update: As shown by Travis, when $M$ is non-compact, the scaled field need not be complete. Of course, when $M$ is compact, than any vector field is complete. For the compact case, I am still interested to know if there is
a global smoothly changing reparametrization $h:\mathbb{R} \times M \to \mathbb{R} $ such that $\psi(t,p)=\phi(h(t,p),p) \forall t \in \mathbb{R} , p \in M$? My analysis (below) shows that if there is such a reparametrization than it's unique (since it's enough to prove uniqueness locally), but I do not know how to show there exists such a global $h$. (See my analysis for details about where my ""procedure"" gets stuck). My analysis so far: Let $\phi_p(t)=\phi(t,p)$ denote the $t$-time flow of $X$ from $p \in M$, i.e $(1)\,\, \phi: \R \times M \to M \, , \, \dot \phi_p(t)=X(\phi_p(t))$ Take $Y = fX$. Denote the flow of $Y$ by $\psi_p(t)$. Assume there exists a real function $h_p:\R \to \R$ such that $\psi_p(t)=\phi_p(h_p(t))$. Then $\dot \psi_p(t)=Y(\psi_p(t)) \Rightarrow \dot \phi_p(h_p(t))\cdot h_p'(t)=f(\psi_p(t)) \cdot X(\psi_p(t))$ So by $(1)$ we get: $$X(\psi_p(t)) \cdot h_p'(t)=X\Big(\phi_p\big(h_p(t)\big)\Big)\cdot h_p'(t)=f(\psi_p(t)) \cdot X(\psi_p(t))$$ So if $ X(\psi_p(t)) \neq 0$, this forces $h_p'(t)=f(\psi_p(t))=f\Big(\phi_p\big(h_p(t)\big)\Big)$ This motivates we try to analyze the following equation, $\forall p \in M$: $$(2) \,\, h_p(0)=0,h_p'(t)=f\Big(\phi_p\big(h_p(t)\big)\Big)$$ We now change notations: Define $h:\R \times M \to \R$ via: $h(t,p)=h_p(t)$.
Denote $\til M = \R \times M$, and consider the hypersurface $S = \{0\} \times M \subseteq \til M$.
 then $(2)$ becomes: $$(3) \, \, h|_S=0, \pd{}{t} h = (f \circ \phi) \big(h(t,p),p\big)$$ The vector field $\pd{}{t} \in \Ga\brk{T \til \M}$ is nowhere tangent to $S$ (since $T_{\brk{0,p}}S=0 \oplus T_p\M$ and $\pd{}{t}(t,p)=(1,0)$). Denote $C^\infty\brk{\til M \times \R} \ni \til f: \til M \times \R \to \R$ via the formula: $$\til f((t,p),s) = (f \circ \phi)(s,p) $$, then $(3)$ becomes: $$ (4) \, \,  h|_S=0, \pd{}{t} h = \til f \big((t,p),h(t,p)\big)$$ The above equation is an instance of a Quasilinear Cauchy problem (on the manifold $\til M$), so we know $\forall \til p=(0,p) \in S$ there exists a unique solution in some neighbourhood $U$ of $\til p$. (See for instance Theorem 9.53, page 242 in John M.Lee's book ""Introduction to smooth manifolds"") In the case $M$ is compact, we can proceed in the following way: $\forall p \in \M , (0,p) \in S \Rightarrow  (0,p) \in U \Rightarrow$ there exists an open set $\til U_p \subseteq U$ which contains $(0,p)$. Hence, there exists $\ep_p \in \R \, , \, U_p \subseteq \M$ ($U_p$ open in $\M$)  such that $(-\ep_p,\ep_p) \times U_p \subseteq \til U_p$. $\{U_p|p \in \M\}$ form an open cover of $\M$, hence ( by compactness of $M$ ) there is a finite subcover $U_{p_1},\dots ,  U_{p_n}$. Define $\ep = min\{\ep_{p_i}|i=1,\dots,n \}$. It follows immediately that $(-\ep,\ep) \times \M \subseteq U$. So, we have stablished exsitence of a unique solution on $(-\ep,\ep) \times \M$. The problem is how to continue from here. A naive approach is to define
 $X = \{t \in I| \text{there exists a unique solution for $(4)$ in  } (-t,t) \times \M \}$. Look at $s= \text{sup} X$. We claim $\text{sup} X \in X$. Since $X$ is closed downward , i.e :  $x \in X \Rightarrow \brk{0 \le x' < x \Rightarrow x' \in X}$ it follows that $[0,s) \subseteq X$. It's easy to see there must be a unique solution for $(4)$ on $(-s,s) \times \M$. (If there were two different solutions, they would differ already at some $s'<s$ which contradicts $[0,s) \subseteq X$). Hence, by continuity, there is at most one solution on $[-s,s] \times \M$. So, if we knew it's possibe to extend the unique solution on $(-s,s) \times \M$ to $[-s,s] \times \M$, then we could advance the (existence and) uniqueness further, via the same argument, thus obtaining a contradiction. (In that case our initial hypersurfaces would have been $\{s\} \times M$,$\{-s\} \times M$). I am not sure how to show the solution can be extended that way. In principle, we can also start the equation from $t=s$ by requiring $h(s,p)$ to satisfy $\psi(s,p)=\phi(h(s,p),p)$. Since non-constant integral curves are injective or periodic, we this might  determine $h_{\{s\} \times M}$ uniquely and perhaps we can continue from there.
(Although then the issue of smoothness arise).","['vector-fields', 'differential-topology', 'partial-differential-equations', 'smooth-manifolds', 'differential-geometry']"
1613444,How to calculate $\int_{-\infty}^{\infty}\frac{x^2}{\cosh(x)}\mathrm{d}x$ [duplicate],"This question already has answers here : Integral $ \int_{-\infty}^{\infty}\frac{x^{2}}{\cosh\left(x\right)}\,{\rm d}x $ (6 answers) Closed 8 years ago . I know the poles are $z=i\pi/2+i n\pi$ and therefor I got an rectangular contour for the integration which wasn't so useful. I also know with change of variables I can get to $\int_{0}^{\infty}\frac{\log(x)^2}{1+x^2}\mathrm{d}x$ but I don't want to use this I want to evaluate the original integral.","['residue-calculus', 'complex-integration', 'complex-analysis', 'integration', 'contour-integration']"
1613456,What is a homogeneous Differential Equation?,"In first-order ODEs, we say that a differential equation in the form $$\frac{\mathrm d y}{\mathrm d x}=f(x,y)$$
is said to be homogeneous if the function $f(x,y)$ can be expressed in the form $f\left(\displaystyle\frac{y}{x}\right)$, and then solved by the substitution $z=\displaystyle\frac{y}{x}$. In second-order ODEs, we say that a differential equation in the form 
$$a\frac{\mathrm d^2 y}{\mathrm d x^2}+b\frac{\mathrm d y}{\mathrm d x}+cy=f(x)$$
is said to be homogeneous if $f(x)=0$. Is there a relation between these two? What does homogeneous mean? I thought it's when something $=0$, because in linear algebra, a system of $n$ equations is homogeneous if it is in the form $\boldsymbol{\mathrm{Ax}}=\boldsymbol 0_{n\times 1}$; but this doesn't seem to be the case for first-order ODEs.",['ordinary-differential-equations']
1613461,Find the number of bicycles and tricycles [duplicate],"This question already has answers here : Is there another simpler method to solve this elementary school math problem? (19 answers) Closed 8 years ago . Help for my son.  My math is a bit rusty and I'm trying to remember how to go about answering this question:  ""There are 3 times as many bicycles in the playground as there are tricycles.  There is a total of 81 wheels.  What is the total number of bicycles and tricycles in the playground?""","['algebra-precalculus', 'word-problem']"
1613463,How to prove this inequality (already verified by numerical simulation)?,"I have a conjecture which has been verified extensively by simulation. The conjecture is as follows: $\forall t \in [0, 1], \alpha \in [0,1]$, and positive real sequences $\{p\}_{i:1,\dots,n}, $, $\{q\}_{i:1,\dots,n}, $, it holds that
$$\sum_{i,j} (t p_i p_j + \bar{t} q_i q_j)^{1+\alpha} \geq \sum_{i,j} (t p_i + \bar{t} q_i)^{1+\alpha} (t p_j + \bar{t} q_j)^{1+\alpha},$$
where $\bar{t} = 1-t$. For the case $\alpha = 0$ and $\alpha = 1$, it's easy to prove the conjecture, by expanding the terms and using convexity and Jensen's inequality. For example, when $\alpha = 0$, one can use the fact that $(\sum_i x_i)^2$ is convex. However, I don't have any clue of how to prove it for the more general case where $\alpha \in (0,1)$. Does anyone have any idea of how to prove the general case (possibly by leveraging the convexity of the terms)? Thanks in advance!","['information-theory', 'inequality', 'probability', 'convex-analysis']"
