question_id,title,body,tags
179800,$C(X)$ with the pointwise convergence topology is not metrizable,"I need to show that if $X$ is an uncountable Tychonoff space, then $C(X)$ is not metrizable. All I've been able to show so far is that that $F(X)$, the space of all functions with pointwise topology, is homeomorphic to $\mathbb{R}^X$ (the product) which is not metrizable, but I can't seem to get much further. Thanks.","['general-topology', 'convergence-divergence']"
179819,side length of trapezoid after cut,"Given a symetrical trapezoid with a bottom length (a) and a top lenght (b) and a height (h)  that I would like to cut off at a certain height (h'), how do I calculate the new top lenght (b')?",['geometry']
179832,Can an eigenvalue (of an $n$ by $n$ matrix A) with algebraic multiplicity $n$ have an eigenspace with fewer than $n$ dimensions?,"Is it possible for a matrix with characteristic polynomial $(λ−a)^3$ to have an eigenline (one-dimensional eigenspace)? I know that geometric multiplicity can generally be smaller than algebraic multiplicity. But I was wondering if algebraic multiplicity $n$ might be a special case. This question is motivated by my earlier one The greatest possible geometric multiplicity of an eigenvalue , where I learnt that $A$ has an $n$-dimensional eigenspace iff. $A=\lambda I$.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
179842,Ring homomorphism with $\phi(1_R) \neq1_S$,"Let $R$ and $S$ be rings with unity $1_R$ and $1_S$ respectively. Let $\phi\colon R\to S$ be a ring homomorphism. Give an example of a non-zero $\phi$ such that $\phi(1_R)\neq 1_S$ In trying to find a non-zero $\phi$ I've done the following observation: Since for $\forall r\in R$
$\phi(r) = \phi(r\times1_R) = \phi(r)\times\phi(1_R)$ we must have that $\phi(1_R)$ is an identity of $\phi(R)$ but not an identity of $S$. We must therefor construct a $\phi$ that is not onto and which have this property. I can't come up with any explicit example though, please help me.","['ring-theory', 'abstract-algebra']"
179851,Irreducible polynomial over an algebraically closed field,"Suppose $k$ is an algebraically closed field and $p(x,y)\in k[x,y]$ is an irreducible polynomial. Prove that there are only finite many $a\in k$ such that $p(x,y)+a$ is reducible, i.e. the set $\{a\mid p(x,y)+a $ is reducible over $k, a\in k\}$ is finite. More generally, suppose $p\in k[x_1,\ldots,x_n]$ is irreducible, is it true that there are only finite many $a\in k$ such that $p+a$ is reducible? Thanks!","['commutative-algebra', 'algebraic-geometry', 'irreducible-polynomials', 'polynomials']"
179855,Two sums with Fibonacci numbers,Find closed form formula for sum: $\displaystyle\sum_{n=0}^{+\infty}\sum_{k=0}^{n} \frac{F_{2k}F_{n-k}}{10^n}$ Find closed form formula for sum: $\displaystyle\sum_{k=0}^{n}\frac{F_k}{2^k}$ and its limit with $n\to +\infty$. First association with both problems: generating functions and convolution. But I have been thinking about solution for over a week and still can't manage. Can you help me?,"['fibonacci-numbers', 'sequences-and-series', 'discrete-mathematics']"
179875,What is a metric for $\mathbb Q$ in the lower limit topology?,"A useful source of counterexamples in topology is $\mathbb R_\ell$, the set $\mathbb R$ together with the lower limit topology generated by half-open intervals of the form $[a,b)$. For example this space is separable, Lindelöf and first countable, but not second countable. So in particular, this implies that $\mathbb R_\ell$ is not metrizable. Now Urysohn's metrization theorem says that any regular, second countable space is metrizable. Applying this to $\mathbb Q_\ell\subset \mathbb R_\ell$ gives the (for me rather counterintuitive) fact that there must exist a metric on $\mathbb Q$ inducing the lower limit topology. Which leads to the question: What is a concrete example of a metric inducing the lower limit topology on $\mathbb Q_\ell$? It certainly should be possible to go through the steps of the Urysohn metrization theorem to give a (semi-)concrete embedding of $\mathbb Q_\ell$ in $\mathbb R^\omega$ (for instance picking an enumeration of the rationals and constructing functions which separate points from closed sets, then look at the cartesian product of these maps) and then give the metric on $\mathbb Q_\ell$ in terms of this embedding. But this is really not what I'm looking for, here. I'd be much more interested in a simple metric for $\mathbb Q_\ell$. Because ""simple"" is not well-defined, I will definitely also welcome answers which exhibit a metric, but which I would not consider to be simple. On the other hand, if you see a reason for why there may just be no ""simple"" metrics, please feel free to point this out as well. Thanks!","['general-topology', 'metric-spaces', 'examples-counterexamples']"
179881,"Best way to denote some trigonometric functions (""tg"" vs ""tan"", ""ctg"" vs ""cot"")","What is the best way to denote tangent and other trigonometric functions: tg or tan , ctg or cot . What notation is commonly used and standardized?","['notation', 'trigonometry']"
179893,How to invert this symmetric tridiagonal Toeplitz matrix?,"What's the best way to invert a simple symmetric tridiagonal Toeplitz matrix of the following form? $$
A = \begin{bmatrix} 1 & a & 0 & \ldots & \ldots & 0 \\\ 
a & 1 & a & \ddots & & \vdots \\\
0 & a & 1 & \ddots & \ddots& \vdots \\\
\vdots & \ddots & \ddots & \ddots & a & 0\\\
\vdots & & \ddots & a & 1 & a\\\ 
0 & \ldots & \ldots & 0 & a & 1 \end{bmatrix} 
$$","['tridiagonal-matrices', 'matrices', 'linear-algebra', 'inverse', 'toeplitz-matrices']"
179894,"Corollary 11.13 in Harris' Algebraic Geometry, a first course","I'm confused about corollary 11.13 (see e.g. google books) in the afforementioned book, namely its second half (the dimension formula).
If we take $X$ to be the disjoint union of a point and a line, $\pi$ any constant map on $X$, wouldn't $X_0=point$ give a counterexample? The statement reads:
Let $X$ be a projective variety and $\pi:X \rightarrow P^n$ any regular map; let $Y$ be its image. For any $q\in Y$, define $\lambda(q)= dim (\pi^{-1}(q))$. Then $\lambda$ is an upper semicontinuous function of $q$. Moreover, if $X_0 \subset X$ is any irreducible component, $Y_0$ its image under $\pi$, and $\lambda$ the minimal value of $\lambda(q)$ on $Y_0$, we have $$dim(X_0)=dim(Y_0)+\lambda$$",['algebraic-geometry']
179895,Goldbach's conjecture and number of ways in which an even number can be expressed as a sum of two primes,Is there a functon that counts the number of ways in which an even number can be expressed as a sum of two primes?,['number-theory']
179897,Puzzle: Guessing the bigger number!,"Consider the following interesting puzzle: ""Alice writes two distinct real numbers between 0 and  1 on two sheets of paper. Bob selects one of the sheets randomly to inspect it. He then  has to declare  whether the  number he sees is the  bigger or smaller of the two.  Is there any way he can expect to be correct more than half the times Alice plays this game with him?"" SPOILER ALERT: In the linked site below, the solution to this puzzle is right below the posed question. The puzzle is lifted from here . In the following questions, I have just given my hunch. My calculations could be wrong as I am not very strong at probability. Questions: 1) Is there an assumption here that Bob can play the game many times with Alice (from the last statement)? Are the real numbers assumed to be fixed?
My hunch: If it is played in time, then fixed real numbers dont make sense. So perhaps we have to think over different realizations. Is this right? 2)[Variant] If Bob knows that Alice samples the two real numbers uniformly and independently from [0,1] every time she plays then can he design a strategy that works more than half of the times?
My opinion: I have a strategy that works two-thirds of the time. However I am not sure if that is the best! Is there a strategy that works better? 3) Is there a distribution from which if Alice samples her numbers independently, then she can ensure that Bob can never do better than getting right half the time?
My opinion: No! Although I am not sure. I guess the independence assumption is what allows Bob to get a good strategy. 4) If Alice can sample two real numbers in a correlated fashion every time she plays, can she ensure that Bob can never do better than getting right half the time?
My opinion: Yes! I think I have an answer. P.S: I will post my version of the answers after a few days, if nobody comes up with the same idea. Thanks! :) P.P.S: This is not a homework problem, but just a musing :)","['puzzle', 'probability']"
179919,Condensation points and derived sets,"Let $(X,d)$ be compact metric space and $C$ be the set of condensation points of $X$. Following the notations here , is the equality $\bigcap\limits_{n \geq 1} X^{(n)}=C$ true ? I succeeded in showing the inclusion $C \subset \bigcap\limits_{n \geq 1} X^{(n)}$ but the other inclusion seems to be more difficult. Have you an idea?","['general-topology', 'metric-spaces']"
179923,"What do the $+,-$ mean in limit notation, like$\lim\limits_{t \to 0^+}$ and $\lim\limits_{t \to 0^-}$?",I'm working on Laplace Transforms and have got to a section where they are talking about zero to the power plus or minus and that they are different. I can't remember what this means though. It's generally used in limits. $\lim\limits_{t\to 0^-}$ or $\lim\limits_{t\to 0^+}$ Any help would be much appreciated.,"['notation', 'calculus', 'limits']"
179935,"How to integrate $\sec^3 x \, dx$? [duplicate]","This question already has answers here : Closed 11 years ago . Possible Duplicate: Indefinite integral of secant cubed How to integrate $\sec^3 x \, dx$?
Can someone please give a method, I tried separating $\sec^3 x$ as $\sec x(\sec^2 x)$ then applying by-parts method but it didn't yield anything useful","['definite-integrals', 'calculus']"
179940,How to convert any non-negative matrix into a doubly stochastic matrix?,"Given a non-negative real matrix $A \in \Bbb R_+^{m \times n}$ , how do I convert it to a doubly stochastic matrix (each row and column sums to $1$ ) $$\sum_{j=1}^n A_{ij}= 1, \qquad \forall i = 1, \dots, m \tag{row sum}$$ $$\sum_{i=1}^m A_{ij}= 1, \qquad \forall j = 1, \dots, n \tag{column sum}$$ Is the conversion possible? If not, can we find a nearest matrix that is doubly stochastic matrix?","['matrices', 'nonnegative-matrices', 'stochastic-matrices']"
179950,What are the points of discontinuity of $\tan x$?,"$f(x) = \tan x$ is defined from $\mathbb R - \{\frac{\pi}{2} (2n+1) \mid n \in \mathbb Z\}$ to $\mathbb R$. For every $x$ in its domain,
$$f(x) = \frac{\sin x}{\cos x}$$ where $\cos x$ is never 0. Thus, (in short) $\tan x$ is defined for all points in its domain.
Now the question remains, is $\tan x$ discontinuous at $x = \pi/2$ (which is outside its domain)? The question arises because the test for continuity in a textbook mentions that $f(x)$ is continuous at $x = c$ when: $f(c)$ exists. $\lim_{x \to c} f(x)$ exists. $f(c) = \lim_{x \to c} f(x)$. And my teacher says failure of any of the above results in $x = c$ being a point of discontinuity. Yet, according to me, first test above merely tests the point for its domain and should be the criteria for any point of discontinuity too.","['calculus', 'continuity']"
179961,Intuition behind the concept of indicator random variables.,"I am studying Randomized Algorithms chapter in the book ""Introduction to Algorithms"" by Cormen et al. In this chapter the book introduces the concept of an indicator random variable and state that the expected value of an indicator random variable as : I am having difficulty understanding why this is called an indicator random variable , specifically why indicator and random and how this concept is useful in analyzing algorithm timings . It has been some time since I studied probability in school . However , I am aware of the concept behind probability. So you can base your answer on this premise. As you can see from the diagram all it is saying is that the expected value of an indicator random variable of an event  is equal to the probability of that event . We already have the concept of probability , why should we know about this new concept which happens to be the same value as the probability ?","['probability-theory', 'probability', 'algorithms']"
179973,Are there any secure ciphers you can use without a computer?,"I have some kids that like encryption schemes such as the Caesar cipher and the Vigenère cipher. I would like to teach them something that's not easily breakable by todays maths and computers, but I want them to be able to use it just using pen and paper. RSA probably isn't the way to go, since specially the prime finding part is quite intensive. A symetric cipher like AES would also be fine, but the current AES standard requires lots of rounds of calculations to be effective. One-time pads are nice, but not really a proper cipher. Are there any cute modern schemes that are really cheap, but still have a reasonable amount of security?","['big-numbers', 'cryptography', 'algorithms', 'number-theory']"
179981,How can one express $\sqrt{2+\sqrt{2}}$ without using the square root of a square root?,"I was trying to review some analysis, and came across problem 3 from page 78 of Walter Rudin's Principles of Mathematical Analysis .  As part of the problem, I wanted to try to write $\sqrt{2+\sqrt{2}}$ without using the square root of a square root.  In other words, I wanted to express the number in the form $q_1+q_2{q_3}^s$, where $q_1, q_2, q_3, s \in \mathbb{Q}$ (or perhaps something similar).  I'm aware that this is probably a duplicate of another question, but I wasn't able to find it (I wasn't sure what to search for)...  Many thanks in advance! Edit (my work so far): I tried expressing it as the solution to the quartic $x^4-4x^2+2=0$, but this seemed futile... Edit 2 (the original problem): The original problem from the text states: If $s_1=\sqrt{2}$, and $$S_{n+1}=\sqrt{2+\sqrt{s_n}} (n=1,2,3,\ldots),$$
  prove that $\{s_n\}$ converges, and that $s_n<2$ for $n=1,2,3,\ldots$. The problem is from the 3rd chapter of the book, which talks about sequences and series. Rudin provides numerous theorems on this topic, such as the comparison, ratio, and root tests for convergence.","['abstract-algebra', 'algebraic-number-theory', 'real-analysis', 'field-theory']"
179984,Map bounded if composition is bounded,"Let $X,Y,Z$ Banach spaces and $A:X\rightarrow Y$ and $B:Y\rightarrow Z$ linear maps with $B$ bounded and injective and $BA$ bounded. Prove that $A$ is bounded as well. If I knew that $B(Y)$ is closed I'd have a bounded linear map $B^{-1}:B(Y)\rightarrow Y$ by the bounded inverse theorem. Therefore $A=B^{-1}BA$ is bounded. How to prove the claim if $B(Y)$ is not closed.","['functional-analysis', 'real-analysis', 'banach-spaces']"
179997,"Pythagorean Triplets with ""Bounds""","I am interested in the algebraic/geometric way of finding the pythagorean triplets such that $$a^2 + b^2 = c^2$$ $$a + b + c = 1000$$ I do the obvious $$a + b = 1000 - (a^2 + b^2)^{1/2}$$ $$a^2 + b^2 = 1000^2 -2(1000)a - 2(1000)b +2ab + a^2 +b^2$$ $$2a + 2b - \frac{2ab}{1000} = 1000$$ $$a + b -\frac{ab}{1000} = 500$$ I have no idea what to do at this point. I can't separate the variables, and any geometric solution is beyond my reach. The only other thing I can think of is writing $$a + b = 500 + \frac{ab}{1000} = 1000 - c$$ But this is going backwards",['algebra-precalculus']
180002,"Legendre symbol, second supplementary law","$$\left(\frac{2}{p}\right) = (-1)^{(p^2-1)/8}$$
how did they get the exponent. May be from Gauss lemma, but how. Suppose we have a = 2 and p = 11. Then n = 3 (6,8,10), but not 
$$15 = (11^2-1)/8$$ n is a way to compute Legendre symbols from Gauss lemma:
$$\left(\frac{a}{p}\right) = (-1)^n$$","['legendre-symbol', 'quadratic-residues', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
180023,Klenke's construction of Brownian motion,"Why does Klenke 's concise construction of Brownian motion via probability transition kernels satisfy the motion's characterizing properties, equations (14.17) and (14.18)? ( results referenced in the construction )","['probability-theory', 'brownian-motion']"
180024,Simplify the difference quotient $\frac{f(x+h)-f(x)}{h}$.,"Simplify the difference quotient $\frac{f(x+h)-f(x)}{h}$ where a) $f(x)=2x+3,$ b) $f(x)=\frac{1}{x+1},$ c) $f(x)=x^2.$ I believe that if anyone can help me out with the first one, the other two might come clearer to me. But I started out this problem by plugging in $f(x)$ and got: 
$$\dfrac{(2x+3)+f(h)-(2x+3)}{h}$$
I have no idea what to do after this. Because the $2x+3$'s can cancel out and leave me with just $\frac{f(h)}{h}$ but that doesn't make sense to me. Please help. EDIT: The first one is solved and now for the second one, this is what I got:
$$\dfrac{\frac{1}{(x+h)+1}-\frac{1}{x+1}}{h}$$ Now, to subtract fractions the denominator has to be the same and they are the exact same except for the first fraction has an $h$ while the other one does not. How would I go about this? For the third problem, this is all of my work: 
$$\begin{align*}\dfrac{(x+h)^2-x^2}{h}&=
\dfrac{x^2+2hx+h^2-x^2}{h}\\
&= \dfrac{2hx+h^2}{h}\\
&= \dfrac{h(2x+h)}{h}\\
&= 2x+h\end{align*}$$
Is this all correct?",['algebra-precalculus']
180029,An exercise about convergence of series [duplicate],This question already has answers here : Closed 11 years ago . Possible Duplicate: Convergence/divergence of $\sum\frac{a_n}{1+na_n}$ when $\sum a_n$ diverges. Let $a_n$ be a non-negative sequence such that the series $\sum a_n$ does not converge. Could the series $\sum a_n/(1+na_n)$ be convergent?,['sequences-and-series']
180049,Kernel of Group Action,"this is my first post here. I have a question regarding a proof in Algebra by Hungerford: Let $G$ be a group and $H$ a subgroup of $G$. Let $S$ be the set of all cosets of $H$, where $G$ acts on $S$. Chapter II Collorary 4.9: ""$\dots$ the kernel of $G \rightarrow A(S)$ is a normal subgroup of $G\dots$"" Question: Why is the kernel normal? I looked through the chapter but there were no references, so I figure this is probably ""obvious"" and hence not included. I came up with an attempt at the proof: Let $K$ be the kernel of the action. $ex = x \implies e\in K \implies K$ contains identity. Let $a,b\in K$. $(ab)x=a(bx) = ax=x \implies ab\in K \implies K$ is closed. $a\in K \implies ax=x\implies x=a^{-1}x\implies a^{-1}\in K\implies$ all elements in $K$ has an inverse. Hence $K$ is a group. Let $g\in G$. $(gKg^{-1})x=(gK)(g^{-1}x)=g(K(g^{-1}x))=g(g^{-1}x)=x\implies gKg^{-1}\subset K$ Substitute $g$ for $g^{-1}$ and we get $K\subset gKg^{-1}$. Hence $gKg^{-1}=K$ and $K$ is normal. Is this approach correct? Also, suppose we were to consider the isotropy group of an element $x\in G$ instead. i.e. $G_x=\lbrace g\in G\mid gx=x\rbrace$ $G_x$ will be a subgroup of $G$ using a similar argument, but now it is not guaranteed to be a normal subgroup because in $(gG_xg^{-1})x=g(G_x(g^{-1}x))$, $G_x(g^{-1}x)=g^{-1}x$ is not necessary true. Is this argument right? Thanks for your time!","['group-theory', 'group-actions']"
180060,Difficulty calculating with rational functions,"I'm having trouble calculating the image of a point $P=[0:0:1]$ under a polynomial map:$$f:V \to \mathbb{P}^1 : [x:y:z] \mapsto [y:x]$$ where $$V = \left\{ [x:y:z] \in \mathbb{P}^2 ~\mid~ zy^2 = zx^2 + x^3 \right\}.$$ What is $f([0:0:1])$? Dead end Notice that the given polynomials don't work at this point (but they do at every other point of $V$) since $[0:0]$ is not a valid expression for a point in $\mathbb{P}^1$. I found a different expression, $$f([x:y:z]) = [zx+x^2:zy],$$ but this expression is not defined at $[0:0:1]$, $[0:1:0]$, or $[-1:0:1]$, so it is an objectively worse expression. How do I find a third expression? Similar problem where things work: Let $\mathbb{P}^n$ be projective space over an algebraically closed field $k$, so that $\mathbb{P}^n$ consists of all $(n+1)$-tuples $[x_0 : x_1 : \cdots  : x_n ]$ with $(x_0,x_1,\ldots,x_n) \neq (0,0,\ldots,0)$ with two tuples $[x_0 : x_1 : \cdots  : x_n ] = [y_0 : y_1 : \cdots  : y_n ]$  considered equivalent if there is some nonzero $\lambda$ in $k$ with $\lambda x_i = y_i$ for $i=0,1,\ldots,n$. Let $$V = \left\{ [x:y:z] \in \mathbb{P}^2 ~\mid~ x^2 + y^2 = z^2, (x,y,z) \neq(0,0,0) \right\}$$ be the (projective) circle, and let $$W = \left\{ [ x:y ] \in \mathbb{P}^1 ~\mid~ (x,y) \neq 0 \right\}$$ be the projective line, and let 
$$f : V \to W : [x:y:z] \mapsto \begin{cases} 
[ y-z : x ] & \text{ unless } [x:y:z] = [0:1:1] \\\
[ x : y+z ] & \text{ unless } [x:y:z] = [0:-1:1] \\
\end{cases}.$$ Note that this rule for $f$ is globally valid and the function is well-defined. In other words, the two definitions agree on their overlap, and every point of $V$ is covered by one of the definitions.",['algebraic-geometry']
180061,I don' t understand why the ratio of two meromorphic functions is meromorphic,"Let $D\subseteq\mathbb C $ be  a connected set and consider $f,g\in\mathcal M(D)$.The ratio $r=\frac{f}{g}$ has the pole set $P(r)\subseteq P(f)\cup Z(g)$ (where $Z()$ is the set of all zeros). Why is $P(r) $ discrete in $D$ ? I think that disjoint union of discrete sets isn't discrete, consider for example $$\{0\}\cup\big\{\frac{1}{n} : n\in\mathbb N\big\}$$",['complex-analysis']
180067,Number Theoretic Game,"2 players A and B play a game.
At the start of the game, $n$ positive integers (not necessarily distinct) are written on a notebook.
First, player A chooses a number from the notebook and declares it the ""current number"".
After that, they play alternately starting with B.
At each turn, they do the following: if the current number is $x$, then the player erases $x$ from the notebook (if multiplicity > 1, leaves the rest unerased), chooses some other number $y$ from the notebook, and declares it the ""current number"". $y$ can be chosen provided either 1) $x|y$ and $y/x$ is prime, or
2) $y|x$ and $x/y$ is prime. The first player who is unable to make a move loses. When does A have a winning strategy?","['combinatorial-game-theory', 'number-theory']"
180069,proof of l'Hôpital's rule [duplicate],"This question already has answers here : Understanding the Proof of L'Hopital's Rule (2 answers) Closed 4 years ago . I've never worked out the general proof of l'Hôpital before, and am taking the opportunity to do so before I return to the soul-crushing grind of college life. I looked in Spivak and found a fine proof of the $(x \rightarrow a$ and $f(x), g(x) \rightarrow 0)$ case; but when he went to prove the $(x \rightarrow \infty, f(x), g(x) \rightarrow 0)$ case, he made a suggestion which actually does not work. (He proposed applying l'Hôpital for the first case above to $f(1/x) / g(1/x)$ as $x \rightarrow 0$, but since he used the fact that $f(0)$ and $g(0)$ could be defined to prove the first case, his version doesn't seem to apply. Correct me if I'm wrong!) I adapted this proof of the second case. Theorem : Suppose that $\lim_{x \to \infty} f(x), \lim_{x \to \infty} g(x) = 0$, and $\lim_{x \to \infty} \frac{f'(x)}{g'(x)} = l$. Then $ \lim_{x \to \infty} \frac{f(x)}{g(x)} = l.$ Proof : Note as a lemma that there exists an interval $I = (c, \infty)$ on which $g'(x) \neq 0$ $g(x) \neq 0$ (The hypothesis implies (1); to prove (2), note that every interval $(\eta, \infty)$ would otherwise have $g(\xi) = 0$, so taking any $\eta ' > \eta$, there would be $g'(x) = 0$ on $(\xi, \xi ')$, and thus on $(\eta, \infty)$, against (1).) Fix $\epsilon > 0$. By hypothesis, $\exists M: x > M \implies |\frac{f'(x)}{g'(x)} - l| <  \frac{\epsilon}{2}$. If $M < c$, choose $M = c$ so $M \in I$. Now pick any $y > M$. By Cauchy, $\forall x > y$ we get $($for $\mu \in (y, x))$ $$\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f'(\mu)}{g'(\mu)}.$$ But if we take $\lim_{x \to \infty}$ of both sides, we find $$\lim_{x \to \infty}\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f(y)}{g(y)} = \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)}. $$ We know that the RHS limit is determinate; we also know that $$ l - \frac{\epsilon}{2} < \frac{f'(\mu)}{g'(\mu)} < l + \frac{\epsilon}{2} \implies l - \frac{\epsilon}{2} \leq \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)} \leq l + \frac{\epsilon}{2}$$ $$\therefore l - \epsilon < \frac{f(y)}{g(y)} < l + \epsilon .$$ We have therefore furnished $M : |\frac{f(x)}{g(x)} - l| < \epsilon$ if $x > M$. This proves the theorem. I now feel a sudden urge to begin overusing l'Hôpital! Someone, please tell me if this is correct, so I can go at it.","['calculus', 'analysis']"
180072,Is there more than one way to express a derivative as a limit of a quotient?,"Let $r(t)$ be a real-valued function of $t$.  Let $v(t)$ be the derivative of $r(t)$.  Then $$v(t) = \frac{dr(t)}{dt} = \lim_{\Delta t \to 0} \frac{r(t + \Delta t) - r(t)}{\Delta t}$$ so $$v(t) = \frac{dr(t)}{dt} \approx \frac{r(t + \Delta t) - r(t)}{\Delta t} \text{ for small }\Delta t$$ My question is, is there another way to approximate $v(t) = \dfrac{dr(t)}{dt}$? For example, I am reading the book Understanding Molecular Simulation by Frenkel and Smit (Second Edition) .  On page 71 (some pages are available on Google Books here ), the authors write $$v(t) = \frac{r(t + \Delta t) - r(t - \Delta t)}{2 \Delta t} + \mathcal{O}(\Delta t^2)$$ or, in other words, $$v(t) \approx \frac{r(t + \Delta t) - r(t - \Delta t)}{2 \Delta t}$$ Basically, then, it seems that there are two ways to express $v(t) = \dfrac{dr(t)}{dt}$: $$v(t) = \frac{dr(t)}{dt} = \lim_{\Delta t \to 0} \frac{r(t + \Delta t) - r(t)}{\Delta t} \textbf{ (1)}$$ $$v(t) = \frac{dr(t)}{dt} = \lim_{\Delta t \to 0} \frac{r(t + \Delta t) - r(t - \Delta t)}{2 \Delta t} \textbf{ (2)}$$ Are equations (1) and (2) equivalent?  Equation (1) Is the definition of derivative that I remember from high school calculus; I do not remember (2) .  Is (2) an alternative definition of the derivative?  Or, what is the relationship between (1) and (2) ?","['calculus', 'derivatives', 'limits']"
180082,Lie algebra of a Lie subgroup,"Let $G$ be a Lie group and $H$ a Lie subgroup of $G$, i.e. a subgroup in the group theoretic sense and an immersive submanifold. Let $\mathfrak{g}$ and $\mathfrak{h}$ be the associated Lie algebras. Now, the Lie algebra $\mathfrak{h}$ is given by: $$ \mathfrak{h} = \{ X\in \mathfrak{g} : \exp_G(tX)\in H, \text{ for } \vert t \vert < \varepsilon \text{ for one } \varepsilon > 0 \} $$ Thus, this definition varies from the usual one, $$ \mathfrak{h} = \{ X\in \mathfrak{g} : \exp_G(tX)\in H \quad \forall t\in \mathbb{R}\} $$ by restricting the values for $t$ to a small interval. The only thing that we know, is that $H$ is a Lie subgroup of $G$, but how does this property allow for the restriction of the $t$ values?","['lie-algebras', 'lie-groups', 'differential-geometry']"
180092,Log likehood functions - Expected value,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a Bernoulli($θ$) distribution with probility function
$$P(X=x)= (θ^x)(1-θ)^{1-x},\qquad x=0,1;\ 0 < θ < 1.$$ $dl/dθ = [n \overline{x}/θ] \cdot (n-n\overline{x})/(1-θ)$ <-- Is it this that's wrong? :/ Got help with this too (Perhaps you can tell stats isn't my best subject) Show that $E[(dl(θ)/dθ)] = 0$ Apologies, exam in a couple of days in a mad scattered panic! When I first did this I integrated by accident, then I diffentiated and got a very strange answer and wasn't sure how to bring it to zero.",['statistics']
180122,Zero sections of any smooth vector bundle is smooth?,Could any one give me hint how to show that the zero section of any smooth vector bundle is smooth? Zero section is a map $\xi:M\rightarrow E$ defined by $$\xi(p)=0\qquad\forall p\in M.$$,['differential-geometry']
180147,Counting the number of matrices which cause collision,"Let $m,n \in \mathbb{N}$, and $q$ be a prime number. Let $\mathbf{A} \in \mathbb{Z}^{m \times n}_q$ be a matrix. In the following, assume that all additions and multiplications are performed modulo $q$. We call $\mathbf{A}$ a ""bad"" matrix if there exist two distinct binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^{n \times 1}$ such that $\mathbf{Ax} \equiv \mathbf{Ay} \pmod q$. In other words, a matrix for which there exists a collision is bad. Otherwise, $\mathbf{A}$ is called a ""good"" matrix. Example: For $m=n=2$ and $q=11$, the matrices 
  $\mathbf{A_1} = \left[\begin{smallmatrix}
0&0\\ 0&0
\end{smallmatrix} \right]$ and
  $\mathbf{A_2} = \left[\begin{smallmatrix}
1&2\\ 3&4
\end{smallmatrix} \right]$ are bad and good, respectively. There are a total of $q^{mn}$ possible matrices $\mathbf{A}  \in \mathbb{Z}^{m \times n}_q$. The question is to count the number of bad matrices. Question: How many matrices $\mathbf{A}  \in \mathbb{Z}^{m \times n}_q$ are bad? A tight upper-bound will do as well. PS: Programming experiments with $2 \times 2$ matrices show that about $4q^2$ of the matrices are bad. Edit (8/9/2012): In my problem, I have the following requirement on the parameters $n \ge 3m \lceil \lg q \rceil$. For a practical implementation, one can take $m=100$ and $q=257$, resulting in $n=2700$.","['number-theory', 'modular-arithmetic', 'inclusion-exclusion', 'matrices', 'combinatorics']"
180150,Alternating sum of squares of binomial coefficients,I know that the sum of squares of binomial coefficients is just ${2n}\choose{n}$ but what is the closed expression for the sum ${n\choose 0}^2 - {n\choose 1}^2 + {n\choose 2}^2 + \cdots + (-1)^n {n\choose n}^2$ ?,"['sequences-and-series', 'binomial-coefficients', 'combinatorics']"
180156,Tate conjecture for Fermat varieties,"I've been looking at Tate's Algebraic Cycles and Poles of Zeta Functions (hard to find online... Google books outline here ) and have a question about his work on (conjecturing!) the Tate conjecture for the Fermat variety $X_m^r$, defined by the equation
$$ X_0^m + X_1^m + \cdots + X_r^m = 0$$
over a field $\mathbb{F}_q$ of characteristic $p$. Fix some $i$, $0\leq i\leq m$. He starts by saying there is only one non-trivial dimension to consider, namely $r = 2i+1$. This is because, combining the Veronese embedding with the Lefschetz hyperplane theorem, we have that every non-middle cohomology is 0 or 1-dimensional, and so the cycle class map is surjective (i.e., the Tate conjecture holds) trivially. Now, if some power of $p$ is congruent to -1 modulo $m$, then because the map $X_m^r \to X_{q+1}^r$ given by $X_j \to X_j^{(q+1)/m}$ is dominant, we can (without loss of generality) assume $m = q+1$. The benefit to doing this is because we now have a large group of automorphisms: the maps induced by the maps in the group $U$ of projective transformations
$$ X_j \to \sum a_{ij}X_i $$
where $(a_{ij})$ is a matrix over $\mathbb{F}_{q^2}$ which is unitary with respect to the map $a\to a^q$. Now he writes that he and John Thompson proved the representation of $U$ on $H^{2i}(\overline{X})$ (where $\overline{X} = X\times_{\mathbb{F}_q} \overline{\mathbb{F}_q}$) decomposes as (the direct sum of) the trivial representation and an irreducible representation, and the desired result follows easily from this. There is a natural action, applying the automorphisms of $U$ to $\overline{X}$, but I'm not entirely sure how to get a hold of $U$. I'm guessing once I have an idea of how to get my hands on the representation, the rest should follow without too much trouble. Edit: Some potential progress! We can decompose the representation of $U$ on $H^{2i}(\overline{X})$ without actually computing it (though I'd still like to hear about how!). Indeed, the action of $U$ on $H^{2i}(\overline{X})$ is transitive, so there are only two conjugacy classes and hence the representation decomposes as the trivial representation and a non-trivial (irreducible) representation. From here, we may find the eigenvalues of the $q^2$ Frobenius. From the Weil conjectures, we know they are of the form $\zeta q^w$ for some $\zeta$ with aboslute value 1, and integer $w$. Further, Weil computed the Zeta function of the Fermat variety $X_m^r$ (see Number of Solutions of Equations in Finite Fields ), and showed the eigenvalues are all Jacobi sums, and combined with the Weil conjectures, we can find (since the characters are nice) that each of these must be $\pm q^i$ (recall, we only need to consider the middle cohomology). Thus, the classes of the (appropriately twisted) middle cohomology are all algebraic, i.e., if there are ""enough"" cycles, every class in the appropriate cohomology could be the image of a cycle. On the other hand, to see there are (enough) cycles, one can simply show the cycles don't only map into the trivial part of the representation of $U$. This is done in the answer here . I would still be happy to have input on approaches that work more closely with $U$. Or corrections to the above, if I've missed something.","['arithmetic-geometry', 'algebraic-geometry', 'representation-theory', 'etale-cohomology']"
180173,Prove: symmetric positive definite matrix,"I'm studying for my exam of linear algebra.. I want to prove the following corollary: If $A$ is a symmetric positive definite matrix then each entry $a_{ii}> 0$, ie all the elements of the diagonal of the matrix are positive. My teacher gave a suggestion to consider the unit vector ""$e_i$"", but I see that is using it. $a_{ii} >0$ for each $i = 1, 2, \ldots, n$. For any $i$, define $x = (x_j)$ by $x_i =1$ and by $x_j =0$, if $j\neq i$, since $x \neq 0$, then: $0< x^TAx = a_{ii}$ But my teacher says my proof is ambiguous. How I can use the unit vector $e_1$ for the demonstration?","['matrices', 'linear-algebra']"
180191,Simplifying $|a+b|^2 + |a-b|^2$,"I want to simplify $|a+b|^2 + |a-b|^2$ where $a, b \in \mathbb{C}$. I've used Wolfram Alpha to get 
$$
|a+b|^2 + |a-b|^2 = 2\left(|a|^2 + |b|^2\right)
$$
I'm trying to understand the steps involved in arriving at this result:
$$\begin{eqnarray*}
|a+b|^2 + |a-b|^2 
&=& |(a+b)^2| + |(a-b)^2| \\
&=& | a^2 + 2ab + b^2 | + | a^2 - 2ab + b^2 |
\end{eqnarray*}
$$
But I'm at a loss as to how to continue from here; I find it hard to work symbolically with absolute values.","['complex-numbers', 'absolute-value', 'algebra-precalculus']"
180198,What is the sum of $\sum\limits_{i=1}^{n}ip^i$?,"What is the sum of $\sum\limits_{i=1}^{n}ip^i$ and does it matter, for finite n, if $|p|>1$ or $|p|<1$ ? Edition : Why can I integrate take sum and then take the derivative ? I think that kind of trick is not always allowed. ps. I've tried this approach but I made mistake when taking derivative, so I've asked, mayby I should use some program (or on-line app) for symbolic computation.","['sequences-and-series', 'summation', 'calculus']"
180201,Isomorphic embedding of $L^{p}(\Omega)$ into $L^{p}(\Omega \times \Omega)$?,"Let $(\Omega,\mu)$ be a finite measure space such that $\mu(\Omega)=1$. Suppose $1\leq p \leq \infty$. Let $\psi \colon L^p(\Omega) \to L^p(\Omega \times \Omega)$ be the map which maps $f$ onto the function $(x,y)\mapsto \frac{1}{2}\big(f(x)+f(y)\big)$. The map $\psi$ is contractive. 1) Is it an isomorphic embedding? The answer is positive (see below). Follow-up questions: 2) What is the best constant $c$ in $\|\psi(f)\|_p\ge c\|f\|_p$? 3) Does there exist a bounded projection from $L^p(\Omega \times \Omega)$ onto the range of $\psi$?
Remark: the answer to Question 1 imply that the range of $\psi$ is a closed subspace of $L^p(\Omega \times \Omega)$.","['functional-analysis', 'integration', 'measure-theory', 'functions', 'banach-spaces']"
180213,Periodic solution of differential equation,"let be the ODE $ -y''(x)+f(x)y(x)=0 $ if the function $ f(x+T)=f(x) $ is PERIODIC does it mean that the ODE has only periodic solutions ? if all the solutions are periodic , then can all be determined by Fourier series ??","['ordinary-differential-equations', 'periodic-functions']"
180216,Chain rule for multivariable functions confusion,"Suppose $f=f(x,y(x))$. Then applying the chain rule we get $\frac{\partial f}{\partial x}=\frac{\partial f}{\partial x}\frac{\partial x}{\partial x}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial x}=\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial x}$. From this it seems that it always holds that $\frac{\partial f}{\partial y}\frac{\partial y}{\partial x}=0$. Where's the mistake?","['multivariable-calculus', 'derivatives']"
180232,Regular value: intuition about surjectivity condition,"Let $f:M\rightarrow N$ be a smooth function between two smooth manifolds. A $\textit{regular point}$ is a point $p\in M$ for which the differential $df_p$ is surjective. What does the surjectivity condition for the differential mean intuitively? What is then so ""regular"" about this point?","['manifolds', 'differential-geometry']"
180238,"If every infinite subset has a limit point in a metric space $X$, then $X$ is separable (in ZF)","I can prove this in ZFC, but don't know how to prove this in ZF. Following is the argument of this in ZFC. Fix $0<r\in \mathbb{R}$ and $x_0\in X$.
Let $A_i = \{x\in X\mid d(x,x_j)\ge r,\, j<i\}$.
Suppose $A_i≠\emptyset$ for every $i\in \omega$.
Then by AC, we can choose $x_i$ for each $A_i$ to derive contradiction. I want to prove this in ZF. Help. Additional Question: Does infinite set have a countable subset in ZF? I guess it's true, but I only know the proof in ZFC. (If it is true, I think it would be really useful in many proofs in ZF.)","['general-topology', 'set-theory', 'axiom-of-choice']"
180239,Why isn't an odd improper integral equal to zero,"My calculus book says that the integral of $\frac1x$ cannot cross zero. Now it seems obvious that because of symmetry, there will always be an interval whose integrals are equal in magnitude and opposite insign, so cancel, even though they do not converge. Now typing into wolframalpha I got ""does not converge"" and only at the bottom did the expected result appeared ($\ln|b|-\ln|a|$) as ""Cauchy principal value"" (CPV, which I looked up on wikipedia). Why that fancyness? Does this has some implications in some application area? And also, when I ask wolframalpha about ""integral of cos/sin from $0$ to $\frac\pi2$"", I get infinity (intuitive, looking at the plot, although $\ln|sin(\frac\pi2)|-\ln|sin(0)|$ is admittedly wrong ) as ""CPV"", but when I ask for ""integral of cos/sin from $0$ to $\pi$"" which I expect to be zero, because the plot is symmetric/odd I get ""does not converge"" and there is no CPV result either. Why?","['improper-integrals', 'calculus', 'integration', 'symmetry']"
180248,How to calculate $f(x)$ in $f(f(x)) = e^x$?,How would I calculate the power series of $f(x)$ if $f(f(x)) = e^x$?  Is there a faster-converging method than power series for fractional iteration/functional square roots?,"['power-series', 'tetration', 'functional-equations']"
180259,How can I get matrices for practicing Jordan normal form?,"I would like to practice the algorithm for the transformation from a matrix to its jordan normal form (with change of basis). To do so, I wrote this script that generates random $n \times n$ matrices, with $n \in \{2,3,4,5\}$ import random, numpy

n = random.randint(2,5)

matrix = []

for i in xrange(n):
    line = []
    for j in xrange(n):
        line.append(random.randint(-10, 10))
    matrix.append(line)

A = numpy.matrix(matrix)

print(""Here is your %i x %i Matrix"" % (n, n))
print(A) This way of generating random matrices isn't very good for the following reasons: The numbers can get really ugly ( example ) Sometimes it is not possible to calculate the decomposition of the matrix ( example ) Do you know either pages with many examples of ""good"" matrices up to $5 \times 5$ or do you know how to change my script?","['matrices', 'linear-algebra']"
180283,Why is the probability that a continuous random variable takes a specific value zero?,"My understanding is that a random variable is actually a function $X: \Omega \to T$, where $\Omega$ is the sample space of some random experiment and $T$ is the set from which the possible values of the random variable are taken. Regarding the set of values that the random variable can actually take, it is the image of the function $X$. If the image is finite, then $X$ must be a discrete random variable. However, if it is an infinite set, then $X$ may or may not be a continuous random variable.
Whether it is depends on whether the image is countable or not. If it is countable, then $X$ is a discrete random variable; whereas if it is not, then $X$ is  continuous. Assuming that my understanding is correct, why does the fact that the image is uncountable imply that $Pr(X = x) = 0$. I would have thought that the fact that the image is infinite, regardless of whether it is countable or not, would already imply that $Pr(X = x) = 0$ since if it is infinite, then the domain $\Omega$ must also be infinite, and therefore $$Pr(X = x) = \frac{\text{# favorable outcomes}}{\text{# possible outcomes}} = \frac{\text{# outcomes of the experiment where X = x}}{|\Omega|} = \frac{\text{# outcomes of the experiment where X = x}}{\infty} = 0$$ What is wrong with my argument? Why does the probability that a continuous random variable takes on a specific value actually equal zero?",['probability']
180296,Prime Identification easier than Prime Factorization?,"I need an algorithm to decide quickly in the worst case if a 20 digit integer is prime or composite. I do not need the factors. Is the fastest way still a prime factorization algorithm?  Or is there a faster way given the above relaxation? In any case which algorithm gives the best worst case performance for a 20 digit prime? Update: Here is the simple method I started with: int64 x = 981168724994134051LL; // prime
    int64 sq = int64(ceil(sqrt(x)));

    for(int64 j = 2; j <= sq; j++)
    {
        if (x % j == 0)
            cout << ""fail"" << endl;
    } It takes 9 seconds on my 3.8Ghz i7 3930K.  I need to get it down by a factor of about 1000.  Going to try a low end ""primorial"" sieve and see what that does. Update 2: I created a prime sieve using $2.3.5.7.11.13.17 = 510510 = c$ entries.  And then searched for factors in blocks of 510510, disregarding factors that are divisible by one of the 7 mentioned primes by a lookup table.  It actually made running time worst (11 seconds), I suspect because the memory access time is not worth it compared to the density of numbers cooprime to $(2,3,5,..,17)$","['prime-numbers', 'algorithms', 'number-theory']"
180299,About sheaf cohomology in algebraic geometry,"In algebraic geometry, why is much more interesting to work with injective resolutions? Why is the main functor of global sections of a sheaf? I am reading Hartshorne's book Algebraic Geometry, and it seems to treat only injective resolutions and global sections functor? Why are we motivated to work with them? Thank you!","['homology-cohomology', 'algebraic-geometry']"
180304,Holomorphic function in an annulus,"I'm trying to do a question but I have a doubt on holomorphic functions, here is the problem. Let $A = \{z ∈ \mathbb{C} : \frac{1}{R}< |z| < R\}$. Suppose that $f : A → \mathbb{C}$ is holomorphic and
  that $|f(z)| = 1 $ if $|z| = 1$. 
  Show that $f(z) = {\left(\overline{f(\bar{z}^{−1})}\right)}^{-1}$ when $ |z| = 1 $ and deduce that this holds for all $z ∈ A$. Now, my problem is with the final deduction... I think I need something about the zeroes of f as the right-hand side of the equality could not be defined at some point. 
Am I right or is there a way to prove that a function with these properties can never be zero in A? Thank you all.",['complex-analysis']
180307,A geometry problem - measure of an $\angle$,"We have a square and the following information: 1) $E \in [AB]$, $E$ an arbitrary point 2) $[AC] \cap [DE]= \{P\}$ and 3)$FP \perp ED$, where $F \in BC$ . We have to prove that the measure of the angle $\angle EDF = 45^{\circ}$. Thanks a lot !",['geometry']
180313,"Verifying $\int_0^\pi  \sin(x) /2(\sin(x/(2n+1)) \,dx \leq \pi$","I'm having trouble verifying this inequality.  It goes like this (appears in Giaquinta, Mathematical analysis, linear and metric structures, page 445):
$$
\int_{0}^{\pi} \cfrac{\sin(x)}{\sin\left(\frac{x}{2n+1}\right)} dx \leq\frac{ 2(n+1)\pi}{2n+1} \leq 2\pi
$$
Of course, the last inequality is obvious.  The first one, however, I can't show.  I've tried bounding $\sin(x)$ by $1$, and then calculating the integral with mathematica, but it comes out unbounded.  When I put $n=1,2,3...$ or any finite number in mathematica, the result is numerically true, but I want to show this for any ""$n$"", and mathematica gives me a very complicated function (depending on $n$) with imaginary units and hypergeometric functions.  I guess I'm missing out a very simple argument here.  Any ideas? Edit: I have edited so that the formula is identical to the one of the book.","['trigonometry', 'inequality', 'integration']"
180314,Boundary Question in $\mathbb{R}^{2}$ (Manifolds),"Given a subset $A$ of $\mathbb{R}^{n}$, a point $x \in \mathbb{R}^{n}$ is said to be in the boundary of A if and only if for every open rectangle $B\subseteq\mathbb{R}^{n}$ with $x\in B$, $B$ contains both a point of $A$ and a point of $\mathbb{R}^{n}\setminus A$. My question is from Spivak's Calculus on Manifolds:
Construct a set $A \subseteq [0,1]\times [0,1]$ such that $A$ contains at most one point on each horizontal and vertical line but has boundary equal to $[0,1]\times[0,1]$.","['manifolds', 'real-analysis']"
180321,Two hard number partition problems,"For every positive integer $n$, let $p(n)$ denote the number of ways to express $n$ as a sum of positive integers. For instance, $p(4)=5$. Also define $p(0)=1.$ Problem 1. Prove that $p(n)-p(n-1)$ is the number of ways to express $n$ as a sum of integers each of which is strictly greater than $1$. Problem 2. Prove that the total number of components in all partitions of $n$ is equal to $\displaystyle\sum_{k=0}^{n-1}p(k)\cdot \tau(n-k)$, where $\tau(m)=\sum_{d|m} 1$ is the number of positive divisors of $m$. I came up with a solution for first problem, but I'm not sure if everything is OK with it, so I would be very grateful if you tell me what I should correct here: Let $p_k(n)$ denote number of ways to express $n$ as a sum of exactly $k$ positive integers. So $p_k(n)=\left|\left\{ \langle a_1,...,a_k \rangle : \sum_{i=1}^k a_i=n \wedge 1\le a_i\le a_{i+1} \text{ for } 1\le i\le k-1 \right\}\right|$. It's quite easy to observe that $p_k(n)=p_{k-1}(n-1)+p_k(n-k)$ by dividing above set into two disjoint sets: -set of tuples $\langle 1,...,a_k \rangle$ -set of tuples $\langle a_1,...,a_k \rangle$, where $a_1>1$ So let's count $p(n)-p(n-1)$ knowing that $p(n)=\sum_{k=1}^n p_k(n)$. $$p(n)-p(n-1)=p_n(n)+\sum_{k=1}^{n-1}p_k(n)-p_k(n-1)=\\=1+\sum_{k=1}^{n-1}p_{k-1}(n-1)+p_k(n-k)-p_k(n-1)=\\=1+ p_0(n-1)+p_1(n-1)-p_1(n-1)+p_1(n-1)+p_2(n-2)-p_2(n-1)+\dots+p_{n-3}(n-1)+p_{n-2}(2)-p_{n-2}(n-1)+p_{n-2}(n-1)+p_{n-1}(1)-p_{n-1}(n-1)=\\=1+0-p_{n-1}(n-1)+\sum_{k=1}^{n-1}p_k(n-k)=\sum_{k=1}^{n-1}p_k(n-k)$$ On the other hand, let $r(n)$ be number of partitions that we are looking for:
$r(n)=\left| \left\{ \langle a_1,...,a_k \rangle : 1\le k\le n-1, \ \sum_{i=1}^k a_i=n \wedge 2\le a_i\le a_{i+1} \text{ for } 1\le i\le k-1 \right\} \right|$ and for a given $k$: $r_k(n)=\left| \left\{ \langle a_1,...,a_k \rangle : \sum_{i=1}^k a_i=n \wedge 2\le a_i\le a_{i+1} \text{ for } 1\le i\le k-1 \right\} \right|$ is a number of partitions that we are looking for but consisting only of $k$ integers. Since there is a simple bijection between tuples $\langle a_1,...,a_k \rangle \leftrightarrow \langle a_1-1,...,a_k-1 \rangle $, where $2\le a_i\le a_{i+1}$ for $1\le i\le k-1$ and still $1\le a_i-1$, then $\sum_{i=1}^k(a_i-1)=n-k$ and tuple $\langle a_1-1,...,a_k-1 \rangle$ is some partition of $n-k$. So $r_k(n)=p_k(n-k)$. Hence cases $r_k(n)$ are pairwise disjoint for $1\le k\le n-1$, it follows that: $\displaystyle r(n)=\sum_{k=1}^{n-1}r_k(n)=\sum_{k=1}^{n-1}p_k(n-k)=p(n)-p(n-1)$ as desired. Is that correct? I don't know how to approach second problem. Too hard it seems to be.","['integer-partitions', 'discrete-mathematics', 'combinatorics']"
180325,Prove that a flat shape minimizes a functional,"The following functional arises in an information theoretic problem that I work on currently. $$I(G(\omega)) = \int_{-\kappa\pi}^{\kappa\pi} \frac{A}{G(\omega)+A}d\omega-\frac{\left| \int_{-\kappa\pi}^{\kappa\pi} \frac{A}{G(\omega)+A}\exp(-i\omega)d\omega\right|^2}{ \int_{-\kappa\pi}^{\kappa\pi} \frac{A}{G(\omega)+A}d\omega},$$ where $\kappa<1$, $A>0$, and $G(\omega)\geq 0$. Now I would like to minimize $I(G(\omega))$ under the constraint of unit area of $G(\omega)$, i.e.,
$$\int_{-\kappa \pi}^{\kappa \pi} G(\omega)d\omega=1.$$ My hypothesis is that a flat $G(\omega)=1/2\kappa\pi$ is optimal, but I cannot prove that (Matlab hints towards it). I can take the functional derivative and then apply the Lagrange multiplier method. But then I get stuck. A flat shape appears to be a stationary point (the functional derivative is zero), but how to prove global optimality? Is $I$ perhaps convex...?","['functional-analysis', 'calculus-of-variations']"
180328,Existence of solutions to stochastic differential equations by the Banach contraction principle?,"I've read a proof for existence of solutions to stochastic differential equation from a book of Ikeda and Watanabe and have a question. Is it possible to prove existence (and uniquness) by means of the Banach contraction principle, similarly like in case of ordinary differential equations? It so, could you give a reference? Thank you for help and hints, Almost sure .","['probability-theory', 'stochastic-calculus', 'stochastic-integrals']"
180331,Prove that $\frac{x^5-x^2}{x^5+y^2+z^2}+\frac{y^5-y^2}{x^2+y^5+z^2}+\frac{z^5-z^2}{x^2+y^2+z^5}≥0 $.,"Given $x, y, z $ are 3 positive reals such that $xyz≥1$. Prove that
$$\frac{x^5-x^2}{x^5+y^2+z^2}+\frac{y^5-y^2}{x^2+y^5+z^2}+\frac{z^5-z^2}{x^2+y^2+z^5}≥0.$$
This question is so complicated. I failed many times to get the proof. Can anyone help me please? Thank you.","['inequality', 'algebra-precalculus']"
180341,No closed form for the partial sum of ${n\choose k}$ for $k \le K$?,"In Concrete Mathematics , the authors state that there is no closed form for
$$\sum_{k\le K}{n\choose k}.$$
This is stated shortly after the statement of (5.17) in section 5.1 (2nd edition of the book). How do they know this is true?","['closed-form', 'binomial-coefficients', 'combinatorics']"
180347,Question on smoothness of the projective closure of a smooth variety,"I was taught in the previous thread "" Is the projective closure of a smooth variety still smooth? "", that the projective closure $\bar X\subseteq \mathbb{P}^n$ of a smooth closed subscheme $X\subseteq \mathbb{A}^n$ (over a basefield) needs not to be smooth again. (-1-) I wonder, if one can test the smoothness of $\bar X$ on the closed ''complement'' $\mathbb{P}^{n-1}$ of $\mathbb{A}^n$ in $\mathbb{P^n}$: Is $\bar X$ smooth if $X$ and $\bar X\cap \mathbb{P}^{n-1}$ are smooth? If there is a counterexample, it would be nice to have an irreducible and reduced one, a  good old variety. In the thread '' Example of a non-smooth intersection '', I was taught that the converse is not true: If $\bar X$ is smooth, $\bar X\cap \mathbb{P}^{n-1}$ does not have to be, even if $\bar X\cap \mathbb{P}^{n-1}$ is reduced. (-2-) Let $\bar X$ be smooth and suppose that $\bar X\cap \mathbb{P}^{n-1}$ is reduced. Is it true that in this case all the irreducible components of $\bar X\cap \mathbb{P}^{n-1}$ are smooth?",['algebraic-geometry']
180348,Expressing $\sin^4x-\sin^6x$ in another way,"I am slightly confused on how one would subtract $\sin^4x-\sin^6x$. I know that $\sin^2x=(1/2)(1-\cos2x)$, so $\sin^4x$ would logically be $[(1/2)(1-\cos2x)]^2=(1/4)(1-2\cos(2x)+\cos^2(2x)$ However the value of $\sin^6x$ eludes me. Would it be $(1-\cos2x)^3$? I did that and got $1-\cos2x-2\cos2x-2\cos^2(2x)+\cos^2(2x)-\cos^3(2x)$ I am not sure if that is correct.",['trigonometry']
180349,How many circles are needed to cover a rectangle?,"TRUE OR FALSE Suppose that a rectangle in $R^{2}$ can be covered by (allowing overlaps) $25$ discs of radius $1$, then it can also be covered by $101$ discs of radius $0.5$. Of course, though it is a true or false question, I would like the logic on it and possible a general proof. The answer is true but I don't see any specific logic. P.S. The question is from the entrance exam 2012 to graduate program at TIFR, Mumbai.",['geometry']
180353,Kernel of adjoint of Lie algebra,"Let $G$ be a Lie group and $\mathfrak{g}$ its Lie algebra. The adjoint representation of the Lie algebra $\mathfrak{g}$ is defined as: $$ \text{ad: } \mathfrak{g} \rightarrow \text{End}(\mathfrak{g}), X \mapsto [X,\cdot] $$ Now, it holds true that $$ \text{ker ad} = \mathfrak{z}(\mathfrak{g}) = \{X \in \mathfrak{g} : [X,Y] = 0 \quad\forall\; Y \in \mathfrak{g}\}.$$ On the other hand, the definition of the kernel of this homomorphism is (at least in my mind) $$ \text{ker ad} = \{ X \in \mathfrak{g} : [X,\cdot] = \text{id}, \text{ i.e. } [X,Y] = Y \quad \forall \;Y \in \mathfrak{g} \}, $$ since the group identity in the endomorphism group is the identity-map. Evidently, the two sets are not the same, but where is my mistake?","['lie-algebras', 'lie-groups', 'differential-geometry']"
180363,Exponentiation and Set of Functions Notation.,"Given arbitrary sets $A$ and $B$, the notation $A^{B}$ is mostly clear from context to mean $A^{B} = \{f : f : B \rightarrow A\}$. However, when these sets are ordinal or cardinals, especially $\omega$, the notation is not consistent even among subfields of logic. For example $2^\omega$ in one sense can denote ordinal exponentiation. Hence $2^\omega = \lim_{n < \omega} 2^n = \omega$. However, you can also consider $2^{\aleph_0}$. By using the cardinal $\aleph_0$, some people may consider it clear that $2^{\aleph_0}$ denotes the cardinal of the set $\{f : \aleph_0 = \omega_0 = \omega \rightarrow 2\}$. In the above paragraph $2^{\aleph_0}$ is a cardinal, (in ZFC) it is a special ordinal. However, it descriptive set theory, you may want to consider not the cardinal but Cantor Space (or Baire Space), i.e. the set of functions from $\omega \rightarrow 2$. When you want the set of functions as oppose to the ordinal, is there a notation for that. In recursion theory, I have found that $2^\omega$ or $\omega^\omega$ most frequently refers to Cantor or Baire space, and not the ordinal or cardinal. In Mostovachis book, he uses $\text{}^\omega2$ to denote Cantor Space. Does anyone know of any establish custom to distiguish between ordinal exponentiation, cardinality of the set of functions between ordinals, and the actual set of functions between ordinals. I was thinking perhaps the left right exponent like $\text{}^\omega2$ and $2^\omega$ could be used as distinction, but from reference to recursion theory and Moschivakis's book, it seems that this is not the case. Thanks for any help you can provide.","['notation', 'logic', 'elementary-set-theory']"
180371,Confused about which Hölder spaces are Banach,"If $\Omega$ is an open set in $\mathbb{R}^n$, is the Hölder space $C^{k, \alpha}(\Omega)$ Banach? Or is it only that $C^{k, \alpha}(\overline{\Omega})$ is Banach, like with ordinary continuous functions? If not, why is that???
Norms are
$$|f|_{C^{0,\alpha}} = \sup_{x,y \in \Omega ,\ x \neq y} \frac{| f(x) - f(y) |}{|x-y|^\alpha},$$
$$|f|_{C^{k, \alpha}} = \|f\|_{C^k}+\max_{| \beta | = k} | D^\beta f |_{C^{0,\alpha}}$$
where
$$|f|_{C^k} = \max_{| \beta | \leq k} \, \sup_{x\in\Omega}  |D^\beta f (x)|$$ Thanks for any help","['holder-spaces', 'functional-analysis', 'banach-spaces']"
180374,A closed-form expression for a sequence of integers,"Let $(a_n)$ be the sequence of minimum values of the expression (depending on $\ell$): \begin{equation*}
a_n=\arg\min \bigg\lbrace ((\ell+1)j-n)!\,(n-\ell j)!\quad \text{for}\; \,\bigg\lceil\frac{n}{\ell+1}\bigg\rceil\le j\le  \bigg\lfloor\frac{n}{\ell}\bigg\rfloor \bigg\rbrace
%  \min \big\lbrace (2j-n)!\,(n- j)!,\;  \mathrm{ceil}\,\frac{n}{2}\le j\le n \big\rbrace, 
.\end{equation*} My questions is two fold: Is there a closed-form expression for $(a_n)_{n\ge \ell}$ (for a fixed $\ell$), or a  way to characterize its entries?
Why?","['discrete-mathematics', 'combinatorics']"
180378,How likely is it for a randomly picked number to be larger than all previously chosen numbers?,"Suppose we pick a uniformly distributed number on the range [a,b]. Then we continue to pick more numbers on the same range. Let n(t) be the number of times we have found a number bigger than any previously found, after sampling t total numbers. The initial number picked is not counted. Solve:
$$\lim_{t\to\infty}\sqrt[n(t)]{t}$$ For reference, the problem I'm trying to solve is the geometric mean of the amount of time it takes to find the next bigger number, relative to the amount of time it took for the previous bigger number. So say it finds a new best value at the 4th try, 11th try, and 29th try, I get:
$$\sqrt[3]{4*\dfrac{11}{4}*\dfrac{29}{11}}$$
which simplifies into the top equation. Experiments seem to indicate the amount of time it takes to find the next number multiples by about 3 for each number found, but I'm curious if there might be tools to solve this analytically. Interestingly, the value seems to be the same even if I take the randomly chosen number and plug it into a function (i.e. I'm checking to see if f(x) is greater than any previously seen f(x) for random values of x). Related questions: Is there any way to guess at the probability of finding a new biggest number? Can the geometric mean be shown to be a constant across all (or some) functions? Intuitively I feel like it should be. I don't have too extensive a background in math, so I'm hoping this isn't an unsolved problem.",['probability']
180388,"Calculating $\lim_{n \to +\infty}\int_0^1 (n + 1)x^{n}(1 - x^3)^{1/5}\,dx$","This question is from a bank of past master's exams. I have been asked to evaluate $$\lim_{n \to +\infty}\int_0^1 (n + 1)x^{n}(1 - x^3)^{1/5}\,dx.$$ I did this problem in a hurried manner, but here's what I think. Since $x^n$ is decreasing in $n$ for fixed $x$ in the closed unit interval, it seems like the integrand, which we may denote by $f_n$, converges pointwise to zero. If I can show that the integrand in fact converges uniformly to zero, by showing $$M_n = \sup_{x\in[0,1]}|f_n(x)|\rightarrow 0,$$ then the question is simply a matter of commuting the limit with the integral. Now, $f_n(x)$ is continuous and differentiable on $[0 , 1]$, so it achieves its supremum, which can be found by differentiating and finding the critical points. I found this critical point to be $x=(\frac{5n}{5n+3})^{1/3}$. The denominator exceeds the numerator in this expression for all $n$, so the critical point is between 0 and 1. It also seems clear to me that this is a local maximum. At this point, $f_n$ achieves the value $$M_n =  (n+1)(\frac{5n}{5n+3})^{n/3}(1 - \frac{5n}{5n+3})^{1/5}$$ which goes to infinity. So, my intuition failed me at some point. What is the proper solution to this limit? More importantly, is there a better approach to this type of problem?","['limits', 'calculus', 'analysis']"
180390,Integration of a differential form,"Let $\omega$ be a $2$-form on $\mathbb{R}^3-\{(1,0,0),(-1,0,0)\}$,
$$\omega=((x-1)^2+y^2+z^2)^{-3/2}((x-1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)+
  ((x+1)^2+y^2+z^2)^{-3/2}((x+1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)$$ 
and $S=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2=5 \}$. In this condition, we calculate $\int_{S}\omega$, where the orientation of $S$ is the natural orientation induced by $D=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2 \leq 5 \}$. I can't calculate this, so if you  solve this, please teach me the answer for this.","['manifolds', 'differential-geometry']"
180392,"What kind of ""mathematical object"" are limits?","When learning mathematics I tend to try to reduce all the concepts I come across to some matter of interaction between sets and functions (or if necessary the more general Relation) on them. Possibly with some extra axioms thrown in here and there if needed, but the fundamental idea is that of adding additional structure on sets and relations between them. I've recently tried applying this view to calculus and have been running into some confusions. Most importantly I'm not sure how to interpret Limits. I've considered viewing them as a function that takes 3 arguments, a function, the function's domain and some value (the ""approaches value"") then outputs a single value. However this ""limit function"" view requires defining the limit function over something other then the Reals or Complexes due to the notion of certain inputs and outputs being ""infinity"". This makes me uncomfortable and question whether my current approach to mathematics is really as elegant as I'd thought. Is this a reasonable approach to answering the question of what limits actually ""are"" in a general mathematical sense? How do mathematicians tend to categorize limits with the rest of mathematics?","['calculus', 'functions', 'real-analysis', 'analysis', 'limits']"
180401,Uniform continuity of a function transforming Cauchy sequences into Cauchy sequences,"Problem: $f:(0,\infty )\rightarrow \mathbb{R}$ defined as: $f(x)=x^{2}$ Can anyone show me how to prove that $f$ transforms Cauchy sequences of elements of $(0,\infty )$ into Cauchy sequences, but $f$ is not uniformly continuous? The purpose of this problem is to show how essential the boundedness of the set on which $f$ is defined is. $f$ is definitely not uniformly continuous because for the two sequences: $\left \{ x_{n} \right \},\left \{ y_{n} \right \}$ defined by: $x_{n}=n+\frac{1}{n}$ and $y_{n}=n$. We have: $\left | x_{n}-y_{n} \right | \to 0$ as $n \to \infty $, but $\left | f(x_{n})-f(y_{n}) \right | \to 2$ as $(n \to \infty )$. Can anyone, please, show me how to prove that $f$ transforms Cauchy sequences of elements of $(0,\infty )$ into Cauchy sequences? Thanks","['calculus', 'continuity', 'real-analysis', 'analysis']"
180408,Topology on the set of partitions,"Let $X$ be the set of all partitions of $[0,1]$ such that each element of the partition is Lebesgue-measurable. Let $Y$ be the set of all partitions of $[0,1]$ such that each element of the partition is a Borel set. Is there a standard topology for a set like $X$ or $Y$? If so, is $X$ (or $Y$) compact in this topology? I thought that the set of all partitions of $[0,1]$ (including those with Vitali sets as elements) is a more complicated object, but as @JDH points out in the proposed answer, this may not be the case. The broader context for this question is my interest in convergence of measures on such a set (hence the focus on Borel or measurable partitions).  If $Y$ is compact and metrizable, then the set of measures on $Y$ is itself a compact metric space in the weak topology, which opens the door to standard results on convergence of such measures.","['general-topology', 'measure-theory', 'equivalence-relations', 'set-partition', 'compactness']"
180414,Fourier transform of a measure,I'm a bit confused - How is the Fourier transform of a measure on a compact abelian group defined? specifically the Fourier transform of a measure on $\mathbb{T}$ the unit circle in the complex plain.,"['topological-groups', 'measure-theory']"
180416,Lie derivative: concrete example for linear Lie group,"I am trying to understand the notion (and notation) of the Lie derivative on a general manifold by trying to convert the notation the concrete example of the Lie group O(n). Let $X,Y$ be smooth vector fields on a smooth manifold $M$, $p \in M$ and the local flow $\psi_t: U \rightarrow M$ of X in a neighborhood $U$ of $p$. Then the $\textit{Lie derivative}$ and thus the Lie bracket is defined as: $$ [X,Y]_p := \mathcal{L}_X(Y_p) = \lim_{t\rightarrow 0} \frac{(d\psi)_{-t}\; Y_{\psi_t(p)} - Y_p}{t}$$ In words: one uses the pullback of the vector field $Y$ along the flow of $X$ to define this derivative. Now, for $M=O(n)$, with associated Lie algebra $\mathfrak{o}(n)=\{ X \in M(n,\mathbb{R}) : X = -X^T \}$, the Lie bracket for $A,B \in \mathfrak{o}(n)$ can be written as: $$[A,B] = \lim_{t\rightarrow 0} \frac{\gamma(t) - B}{t}, $$ where the curve $\gamma$ is given by $$ \gamma(t) = \exp(tA)B\exp(-tA). $$ Unfortunately, I got stuck in defining the abstract notation appropriately to arrive at the latter expression. Does someone has an idea how to define $\psi$ and the vector fields in this situation? Or, does someone know a better $\textit{concrete}$ example where one can well understand the Lie derivative?","['lie-algebras', 'lie-groups', 'differential-geometry']"
180418,Calculate Rotation Matrix to align Vector $A$ to Vector $B$ in $3D$?,"I have one triangle in $3D$ space that I am tracking in a simulation. Between time steps I have the previous normal of the triangle and the current normal of the triangle along with both the current and previous $3D$ vertex positions of the triangles. Using the normals of the triangular plane I would like to determine a rotation matrix that would align the normals of the triangles thereby setting the two triangles parallel to each other. I would then like to use a translation matrix to map the previous onto the current, however this is not my main concern right now. I have found this website that says I must determine the cross product of these two vectors (to determine a rotation axis) determine the dot product ( to find rotation angle) build quaternion (not sure what this means) the transformation matrix is the quaternion as a $3 \times 3$ (not sure) Any help on how I can solve this problem would be appreciated.","['vector-spaces', '3d', 'rotations', 'matrices', 'linear-algebra']"
180430,Greatest common denominator of measurements,"In a couple months, I'll do the Millikan experiment. Then, I'll end up with a number of charge measurements and their errors $$((q_i, \Delta q_i))_{i \in \mathbb N}.$$ The idea is that all those $q_i$ can be represented as a multiple of a fixed elementary charge $e$ like $$q_i = n_i e.$$ Now I do not know $e$ in advance. Is there some method to get $(e, \Delta e)$ out of the sequence of measurements? I found this question on StackOverflow , but it does not have any answers that solve the problem in a stable way.",['statistics']
180431,Finite modules over finite local rings,Let $R$ be a finite commutative local ring with identity. If $M$ is a finite $R$-module it is necessarily projective?,"['ring-theory', 'finite-rings', 'projective-module', 'abstract-algebra', 'modules']"
180441,Product of right cosets equals right coset implies normality of subgroup,"I cannot see how to find a way to prove that if $H$ is a subgroup of $G$ such that the product of two right cosets of $H$ is also a right coset of $H,$ then $H$ is normal in $G.$ (This is from Herstein by the way.) Thank you.","['group-theory', 'abstract-algebra']"
180447,Can I only apply the Gauss-Hermite routine with an infinite interval or can I transform the interval?,"Short version of my question Can I only apply the Gauss-Hermite routine with an infinite interval or can I transform the interval? Long version (reason I'm asking) I am interested in solving integral equations numerically and one part of this, if I understood it correctly, is the usage of numerical integration routines. So I ventured into this field and implemented the midpoint, the Simpson, and the Gauss-Legendre routine successfully. Here is my implementation of  the Gauss-Legendre routine in R (depending on the package statmod ): gauss_legendre <- function(f, upper, lower, nr_int, ...) {

  #1. Compute the nodes; those are the roots of the legendre-polynom
  leg_poly <- gauss.quad(nr_int)
  x <- leg_poly$nodes

  #2. Compute the weights as follows: 2/((1-x^2)Ableitung(P(x))^2)
  w <- leg_poly$weights

  #3. Compute the integral
  x_transformed <- ((x+1)*(upper - lower)/2 + lower)
  (upper - lower)/2*sum(w * mapply(f, x_transformed, ...))

} So basically, the first two parts give me the numbers tabulated here and the third part just computes: $$\int_a^b f(x)dx = \frac{b-a}{2}\sum\limits_{i=1}^n \omega_i f\left( \frac{b-a}{2}x_i + \frac{a + b}{2} \right)$$ Let's check that it works (note that integrate is just the built-in function in R): gauss_legendre(function(x) {x^3 + log(x) + sqrt(x)}, 10, 2, 10)
[1] 2528.836
> integrate(function(x) {x^3 + log(x) + sqrt(x)}, 2, 10)
2528.836 with absolute error < 2.8e-11 As you can see, this works with an interval ranging from 2 to 10 by transforming the $x$ values. Given that the interval is well defined, I don't see any problem using that for any interval. Next, I implemented the Gauss-Hermite routine: gauss_hermite <- function(f, upper, lower, nr_int, ...) {

  #1. Compute the nodes; those are the roots of the Hermite-polynom
  her_poly <- gauss.quad(nr_int, ""hermite"")
  x <- her_poly$nodes

  #2. Compute the weights according to the function; attention: this already includes the term exp(x^2)
  w <- her_poly$weights * exp(x^2)

  #3. Compute the integral
  sum(w * mapply(f, x))

} This works for instance when computing the integral of the density function of the standard normal distribution: gauss_hermite(dnorm, -Inf, Inf, 100)
1 However, I don't get any useful results when the interval doesn't go from $[-\infty; \infty]$. On the other side, in none of the material I read was it mentioned that the Gauss-Hermite approach is limited to that case (I read that it's useful in connection with Normal random variables though). So my question (sorry for the long prolog): can I only apply the Gauss-Hermite routine with an infinite interval or can I transform the interval? As you probably guessed from the question, I'm not a mathematician, so any help with this would be great.","['orthogonal-polynomials', 'integration', 'numerical-methods']"
180465,Is there a hyperbolic geometry equivalent to Möbius transformations in spherical geometry?,"There is a sense in which all ""interesting"" properties of functions in spherical geometry are invariant under conjugation by a Möbius transformation.  The reason is that the Möbius transformations correspond to ""uninteresting"" manipulations of the whole sphere, as illustrated in this video . Is there an equivalent notion in hyperbolic geometry?  In other words, is there a valid statement of the form ""All interesting properties of functions in hyperbolic geometry are invariant under conjugation by a $\text{Foo}$ because the $\text{Foo}$s correspond to uninteresting manipulations of the {upper half plane, unit disk, hyperboloid, etc}.""?","['hyperbolic-geometry', 'geometry']"
180477,Abstract nonsense proof of the cocompleteness of the category of groups,"There is a well-known way to conclude the cocompleteness of a category from its completeness. Namely, if a category is complete, well-powered and has a cogenerating set, then it is cocomplete (easy corollary of the special adjoint functor theorem). I was hoping I could use this to prove that the category $\mathbf{Grp}$ of groups is cocomplete. I would find it interesting, for completeness of $\mathbf{Grp}$ is easy to prove (the forgetful functor to the category of sets creates limits), while cocompletenes is not so easy (constructing free product is quite tedious). But alas, a quick google search revealed that $\mathbf{Grp}$ doesn't have a cogenerator (it can be read off the only freely available page of this article ). I suspect it doesn't have a cogenerating set , either. Is there a categorical proof of the cocompleteness of $\mathbf{Grp}$? Edit: I'd like to point out that I found out afterwards the following exercise 1 in section IX.1 of Mac Lane's CWM (I didn't expect to find this exercise in the chapter on ""Special Limits""!) Use the adjoint functor theorem to prove in one step that Grp has all small colimits.","['category-theory', 'abstract-algebra']"
180479,How do I proceed with these quadratic equations?,"The question is $$ax^2 + bx + c=0 $$ and $$cx^2+bx+a=0$$ have a common root, if $b≠ a+c$, then what is $$a^3+b^3+c^3$$","['quadratics', 'algebra-precalculus', 'polynomials']"
180488,Probability for brownian motion,"How can I prove it? For $b>a>0$, show that 
  $$
\operatorname{Pr}\left({\sup_{t\geqslant 0}\left(\frac{b+X(t)}{1+t}\right)\geqslant a}\right)=e^{-2a(a-b)}
$$
  where $X(t)$ is a Brownian motion.","['probability-theory', 'stochastic-processes', 'brownian-motion']"
180495,Hellinger-Toeplitz theorem use principle of uniform boundedness [duplicate],"This question already has an answer here : Hellinger-Toeplitz Theorem and Uniform Boundedness Principle [closed] (1 answer) Closed 4 years ago . Suppose $T$ is an everywhere defined linear map from a Hilbert space $\mathcal{H}$ to itself. Suppose $T$ is also symmetric so that $\langle Tx,y\rangle=\langle x,Ty\rangle$ for all $x,y\in\mathcal{H}$. Prove that $T$ is a bounded directly from the uniform boundedness principle and not the closed graph theorem. This is problem III.13 in the Reed-Simon volume 1. Hints are welcome.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
180507,How to resize an image?,"I am not sure about the title of this question, so if someone knows an appropriate one, please rename it. It's a programming related question (but doesn't involve any programming). I posted it on stack overflow but didn't get any responses so I am trying here. I need to map a piece of rectangle (x, y, width, height) of an (original)image onto a canvas by resizing the original image. Here's a picture that explain it better. Here's another one, bit different, so you get a better idea: I can scale and move the image however I want. How do i figure out the scale at which to resize the original image. I had an idea, which was to figure the bigger dimension of the given rectangle, and use that to figure out the scale, so: Given: imageWidth , imageHeight , rectWidth , rectHeight , canvasWidth , canvasHeight (let's ignore the offsets for now) But that doesn't work in some cases. So I wondering what's the best way to do this.
,","['algebra-precalculus', 'image-processing']"
180525,Area in an equilateral triangle that is closer to the centroid than to any edge,What percent of the area of an equilateral triangle is closer to the centroid of the triangle than to any edge of the triangle?,['geometry']
180554,IVP Perturbation With Small Non-Linear Term,"EDIT:  Sorry to bump this without having anything extra to add, but I still cannot reconcile my solution with what was asked (in (2)).  Could someone with expertise in this subject take a look?  I would definitely appreciate it.  In particular, either my approximation derived in the majority of my solution is incorrect, or, in the last paragraph or so, my methodology for determining the center of oscillation is flawed.  I've triple checked everything though, and I'm not sure what the issue is.  Perhaps it was a typo in the original problem statement from the text? (BACKGROUND) I'm asked to do two things with the IVP $\ddot{x}+x+\epsilon x^{2}=0$ where $0<\epsilon\ll 1$ and $x(0)=a>0$ and $\dot{x}(0)=0$. (1) Find an approximate solution of accuracy $O(\epsilon)$, valid for all time. (2) Show the center of oscillation is approximately $\epsilon\frac{a^2}{2}$. I first observe that if a simple $O(\epsilon)$ approximation is to be valid for all time, then the only real possibility for this to happen is if the solution to be approximated is periodic.  To that end, I use the Poincaré-Leindstedt perturbation method, since if the system has very strict requirements on initial conditions for periodic solutions, the two parameters given by this method (as opposed to one given by regular perturbations) will allow me to obtain them (i.e. when it comes time to eliminate resonance terms). EDIT: It turns out that there is no restriction on $a$ for periodic solutions, but this is only discoverable after proceeding with the method. (ACTUAL QUESTION) I am pretty confident that my approximation is correct (i.e. that I correctly applied the method).  But I have doubts, primarily because in (2) I get a different (though similar) answer for the center of oscillation.  So either my methodology for determining it is wrong, or my approximation is wrong.  So I included both stages here. (SOLUTION ATTEMPT) Our equation is $\ddot{x}+x+\epsilon x^{2}=0$ subject to initial conditions $x(0)=a$ and $\dot{x}(0)=0$.  Note that because the system is autonomous, the initial condition on $x'(t)$ is completely general assuming the solution oscillates indefinitely (which are the solution(s) we obtain by letting $a$ be yet undertermined), for in this case $\dot{x}(t)=0$ for infinitely many $t$, and being autonomous, the solution is unchanged by the translation $t\mapsto t-t_{0}$.  Introduce a yet to be determined time dilation (or equivalently, frequency)
$$
\tau=\omega t.
$$
Expanding $x$ and $\omega$ asymptotically gives
\begin{eqnarray*}
x(\tau)=x_{0}+\epsilon x_{1}+O(\epsilon^{2})\\
\omega=\omega_{0}+\epsilon\omega_{1}+O(\epsilon^{2}).
\end{eqnarray*}
Substituting the asymptotic expansion for $x$ into the equation and immediately discarding $O(\epsilon^{2})$ and higher order terms yields
$$
\omega^{2}x_{0}''+\epsilon\omega^{2}x_{1}''+x_{0}+\epsilon x_{1}+\epsilon x_{0}^{2}=0,
$$
where $'$ denotes differentiation with respect to $\tau$.  Substituting the asymptotic expansion for $\omega$ into this expression and ignoring $O(\epsilon^{2})$ and smaller terms then gives
$$
\omega_{0}^{2}x_{0}''+2\omega_{0}\omega_{1}\epsilon x_{0}''+\epsilon\omega_{0}^{2}x_{1}''+x_{0}+\epsilon x_{1}+\epsilon x_{0}^{2}=0.
$$ Collecting like-order terms forms the system of equations
\begin{eqnarray*}
(1)\;\;\omega_{0}^{2}x_{0}''+x_{0}=0,\\
(2)\;\;\omega_{0}^{2}x_{1}''+2\omega_{0}\omega_{1}x_{0}''+x_{0}^{2}+x_{1}=0.
\end{eqnarray*}
(1) implies $\omega_{0}=1$ and $x_{0}=A\cos\tau+B\sin\tau$.  The initial conditions on $x$ imply $x_{0}(0)=a$ and $x_{k}(0)=x_{k}'(0)=0$.  Hence,
$$
x_{0}=a\cos\tau.
$$
Substituting $\omega_{0}$ and $x_{0}$ into (2) and rearranging gives
$$
x_{1}''+x_{1}=2\omega_{1}a\cos\tau-a^{2}\cos^{2}\tau=2\omega_{1}a\cos\tau-\frac{a^{2}}{2}-\frac{a^{2}}{2}\cos2\tau=f(\tau).
$$
To eliminate resonance terms and obtain a periodic solution, we only require
$$
2\omega_{1}a=0,
$$
and this implies $\omega_{1}=0$.  This means that $a$ may be regarded as a free parameter for the system, and so there are infinitely many initial conditions which lead to periodic solutions (note that we have only computed up to $O(\epsilon)$ order terms; presumably, eliminating resonance terms from $x_{k}$ ($k>1$) would require some dependence on $a$ for $w_{k}$).  At any rate, our equation for $x_{1}$ then becomes
$$
x_{1}''+x_{1}=-a^{2}\cos2\tau.
$$
Solving this equation (using variation of parameters or some other method to obtain a particular solution) with homogeneous initial conditions gives
$$
x_{1}(\tau)=-\frac{2}{3}a^{2}\sin^{2}\left(\frac{\tau}{2}\right)\left(2+\cos\tau\right).
$$
We then form our first order approximation to $x(t)$ by substituting these solutions into our asymptotic expansion for $x$:
\begin{eqnarray*}
x(t)&=&a\cos\omega t-\epsilon\frac{2}{3}a^{2}\sin^{2}\left(\frac{\omega t}{2}\right)\left(2+\cos\omega t\right)+O(\epsilon^{2})\\
&=&a\cos\omega t +\epsilon\frac{a^{2}}{6}(3-2\cos\omega t-\cos2\omega t)+O(\epsilon^{2}),
\end{eqnarray*}
where $\omega=1+O(\epsilon^{2})$ and the simplifying identity $\sin^{2}(\frac{\tau}{2})=\frac{1}{2}(1-\cos\tau)$ was used.  As for the center of oscillation, we expect it to occur at approximately $\frac{T}{4}$, where $T$ is the period of oscillation, since the oscillation begins at maximal amplitude for $t=0$ (see initial conditions).  The period of oscillation is
$$
T=\frac{2\pi}{\omega}
$$
so that evaluating our asymptotic expansion at $\frac{T}{4}=\frac{\pi}{2\omega}$ gives
\begin{eqnarray*}
x\left(\frac{\pi}{2\omega}\right)
&=&a\cos\frac{\pi}{2}+\epsilon\frac{a^{2}}{6}\left(3-2\cos\frac{\pi}{2}-\cos\pi\right)\\
&=& 0+\epsilon\frac{a^2}{6}\left(3-0-(-1)\right)\\
&=& \epsilon\frac{2a^{2}}{3}
\end{eqnarray*}
which is accurate up to $O(\epsilon^{2})$.","['ordinary-differential-equations', 'perturbation-theory']"
180559,Why does gradient descent work?,"On Wikipedia, this is the following description of gradient descent: Gradient descent is based on the observation that if the multivariable function $F(\mathbf{x})$ is defined and differentiable in a neighborhood of a point $\mathbf{a}$, then $F(\mathbf{x})$ decreases fastest if one goes from $\mathbf{a}$ in the direction of the negative gradient of $F$ at $\mathbf{a}$. Now I have several doubts in this description. First of all I have an example of $f(x)=x^2$ in my mind and my starting point is, say, $x=5$. What is the meaning of ""decreases fastest""? I mean, I can go straight from $x=5$ to $x=0$ (which is minimum point), then what's the point of fastest decrease? What is the notion of fast here? Where did this observation come from? I didn't see the proof of this observation.","['optimization', 'gradient-descent', 'calculus', 'numerical-optimization', 'intuition']"
180560,Why does $\sum\limits_{n=2}^{\infty} \frac{ 1}{  n^2  \log (n) }$ converge?,The way I see it you can compare $$\sum_{n=2}^{\infty} \frac{ 1}{  n^2  \log (n) } < 1/n$$ $1/n$ is a $p$-series in which $p = 1 \leq 1 $ So $1/n$ diverges. Thus $\sum\limits_{n=2}^{\infty} \frac{ 1}{  n^2  \log (n) }$ diverges.,"['sequences-and-series', 'calculus']"
180566,Permutation groups as symmetry groups of polynomials,"I recently saw a question in a Text book, which asks to prove that ""The group of symmetries of the polynomial $x_1x_2 + x_3x_4 + x_5x_6$ is a subgroup of $S_6$ of order $48$"". (By the group of Symmetries of this polynomial, we mean the stabilizer of the polynomial $x_1x_2+x_3x_4+x_5x_6$ in the action of the group $S_6$ on $\mathbb{Z}[x_1,x_2,\cdots,x_6]$ given by $\sigma.f(x_1,x_2,\cdots,x_6)=f(x_{\sigma(1)},x_{\sigma(1)},\cdots,x_{\sigma(6)})$.) In view of this exercise, I would like to ask the following question: Is every finite group realizable as the full stabilizer of a polynomial over $\mathbb{Z}$ in a certain number of indeterminates? If yes, then how can we construct that polynomial?",['group-theory']
180575,How many small cancellation groups are there?,It is known that there are uncountably many groups with two generators. But what about the restriction to small cancellation groups? Are there countably or uncountably many small cancellation groups?,"['geometric-group-theory', 'group-theory']"
180581,What is the algebraic structure of functions with fixed points?,"So I just noticed that the set of functions with a fixed point 
$$f(x_0)=x_0,$$ 
are closed under composition 
$$(f\circ g)(x):=g(f(x)),$$
and with $e(x)=x$, the inverible functions even seem to form a (non-commutative) group. Then if one chooses another point $x_1$ and restricts the set to the functions which also have $x_1$ as a fixed point, then it is again closed and so on. If I have one parameterized point (i.e. a curve, or even a couple of those), then solving $f_t(x(t))=x(t)$ for the families $f_t$ should give me morphisms between the functions for different values of $t$. Are there general considerations regarding this? And is this somehow related to the characterization of points of a manifold via the ideal of functions which evaluate to $0$ that point? Edit 1: Might be just a general property of homeomorphisms or something, although I don't associating picking out isolated fixed points with these kind of things. Edit 2: I now see that this might relate a translation/transformation of points in the manifold to a transformation of the function algebra over that manifold. This has some features: If you take two points $y_1$ and $y_2$ and transformations along the curves $Y_1(t),Y_2(t)$ with $Y_1(0)=y_1, Y_1(1)=y_2$ and $Y_2(0): =y_2, Y_2(1)=y_1$ (they move into each other), then the fuction set with both fixed points $Y_1(t),Y_2(t)$ makes a loop as $\{Y_1(0),Y_2(0)\}=\{Y_1(1),Y_2(1)\}=\{y_1,y_2\}$. The particular form of the curves have an impact on how the function set looks in between.","['fixed-point-theorems', 'manifolds', 'functions', 'ideals', 'group-theory']"
180605,Uniform distribution with probability density function. Find the value of $k$.,"For a random sample $X_1,X_2,...X_n$ from a uniform $[0,\Theta]$ distribution, with probability density function $$f(x;\Theta) = \left\{ \begin{array} \ \frac{1}{\Theta} & 0\le x \le\Theta,\\ 0 & \text{otherwise}.\end{array}\right.$$ What is the value of $k$ such that $\hat{\Theta}=k\bar{X}$ is an unbiased estimator of $\Theta$? I've done some questions similar to this but I'm not sure how to go about this one. I have a test in 3 hours so help is really appreciated!","['statistics', 'probability-distributions']"
180615,The graph of xy = 1 is connected or not,"The graph of $xy = 1$ in $\Bbb C^2$ is connected. True or false? I know that it is not connected in $\Bbb R^2$, but what is the case of $\Bbb C^2$?",['general-topology']
180616,Is the limit of uniformly integrable functions integrable?,"If $\left\{f_n\right\}$ are uniformly integrable and $f_n\overset{a.e.}{\rightarrow}f$ ($f$ measurable), is $f$ integrable? Can ""uniformly integrable"" be weakened to ""integrable""?","['measure-theory', 'convergence-divergence']"
180617,How to prove that the $L^p$ spaces are infinite dimensional,"It is well-known that (given a measure space $(S,\mathcal A,\mu)$ and $1\le p\le\infty$) the Banach space $L^p(S,\mathcal A,\mu)$ has infinite dimension. Is there an easy way to proof this statement (or a suitable reference (preferably a book) where I can find this result)?","['functional-analysis', 'banach-spaces', 'measure-theory', 'reference-request', 'lp-spaces']"
180630,Subtract matrix from scalar,Is this even possible? Since you can subtract on the right-hand side I think there must be a way to do it from left-hand side too. I would like to calculate this: 3 - [2 1] = ??,['matrices']
180640,Solving for specific entries in a Lyapunov Equation,"Let $A$ be a $2n\times 2n$ real matrix with the following structure 
\begin{equation}
A = \left(\begin{matrix}
0 & -I \\
K & S
\end{matrix}\right)
\end{equation}
with all sub-matrices of size $n\times n$: $I$ is the identity matrix, $K$ is symmetric positive definite and $S$ is diagonal but singular. I am interested in the (numerical) solution of the  continuous time Lyapunov equation for the $2n\times 2n$ matrix R:
\begin{equation} 
R A^\text{T} + A R = \left(\begin{matrix}
0 & 0 \\
0 & \Gamma
\end{matrix}\right)
\end{equation}
where $\Gamma$ is a diagonal and singular $n\times n$ real matrix. However, I only need a few elements of $R$. More specifically, writing \begin{equation}
R = \left(\begin{matrix}
X & C \\
C^\text{T} & V
\end{matrix}\right)
\end{equation}
all I really want are the diagonal entries of $V$ (also $n\times n$). Is there anyway I could reduce this problem to some other (probably Sylvester) equation for $V$ or, better yet, only it's diagonal? I don't really know how to approach this problem.","['control-theory', 'numerical-linear-algebra', 'linear-algebra']"
