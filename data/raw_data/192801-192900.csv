question_id,title,body,tags
3680880,What is the maximum number of pieces of pizza possible when it is cut with 5 straight line cuts (the lines don't go through the center of the pizza.)?,"What is the maximum number of pieces of pizza possible when cut with 5 straight lines, none of which pass through the center of the pizza?",['combinatorics']
3680988,Calculating $\lim_n e^{-inz}$,"In an exercise I have to prove that $f_n(z)=e^{-inz}$ converges uniformly for $\Re(z)>3$ . So I have to prove that: $$\forall \varepsilon>0, \exists p \in \mathbb{N}:|e^{-inz}-f(z)|<\varepsilon\ \ \ \text{if } n\geq p$$ My question is, how can I find that $f(z)$ ? I've tried calculating the $\lim_n e^{-inz}$ by doing the following: if $z=x+iy$ then: $\lim_n e^{-inz}=\lim_n \frac{1}{e^{inz}}=\lim_n \frac{e^{ny}}{e^{inx}}$ but I could not continue from now on. How can I evaluate this limit?","['complex-analysis', 'limits']"
3681065,Prove $\lim_{n \to \infty}\int_0^1 \dots \int_0^1 f(\sqrt[n]{x_1\dots x_n})dx_1\dots dx_n = f(\frac{1}{e}).$ $f$ is continuous on $[0;1].$,"$f$ is continuous on $[0;1].$ Prove $$\lim_{n \to \infty} \underbrace{\int_0^1 \cdots \int_0^1}_{n} f(\sqrt[n]{x_1\cdots x_n})\mathrm \, dx_1\cdots \mathrm dx_n = f(\frac{1}{e}).$$ At first, I thought that we should get inside the function with the limit, but it's probably restricted due to $dx_1\dots dx_n$ . I feel like I'm missing an important Theorem here. And yet it seems like the problem should be easy. Can somebody smart help me out here (at least with a hint) ? Perhaps, it's an induction method problem.","['integration', 'limits', 'calculus', 'real-analysis']"
3681089,Suppose $f \circ g(x) = \frac{x^2-6x+2}{x+1}$ and $g(x) = 1 - x$. Then $f(-1)$ is equal to...,"I tried to substitute the value of $g(x)$ to every $x$ in $f \circ g(x) = \frac{x^2-6x+2}{x+1}$ and ended up with $\frac{x^2+4x-3}{-x+2}$ .
Although honestly I do not know if that helps, or what I could do next. I thought maybe this question just requires me to substitute $-1$ to every $x$ in $f\circ g(x) = \frac{x^2-6x+2}{x+1}$ ?","['functions', 'discrete-mathematics']"
3681192,The game of taking an even number of stones,"Consider the following game: Two players alternately take one or two stones from a pile of stones. The objective of each player is to take, in total, an even number of stones. Suppose that in the beginning the pile has an odd number of stones $n$ , so that one of the players wins and another loses. I would like to know, what player has the winning strategy here. If $n = 1$ the second player is the one, who wins, as the first player takes the only stone and loses immediately. If $n = 3$ the first player wins by taking two stones and reducing the game $n = 1$ on second player's turn. However, I have no idea how to get the solution for an arbitrary odd $n$ . This question (not all of it, however, but only the quoted ""rules of the game"") was initially posted by @kris , but got deleted as a PSQ. However, this question seemed too interesting to ignore so I reposted it (with added context).","['game-theory', 'combinatorics', 'discrete-mathematics', 'combinatorial-game-theory']"
3681239,How to prove that $\lim_{y \rightarrow \infty} \frac{\sin^2(xy)}{yx^2}=\pi \delta(x)$,"I want to understand how to prove that $$\lim_{y \rightarrow \infty} \frac{\sin^2(xy)}{yx^2}=\pi \delta(x)$$ The proof I am studying relies on doing the following Fourier Transform $$\int dx \frac{\sin^2(xy)}{yx^2} \exp(-ipx) = \frac{\pi}{2} \Theta(2y - |p|) \Big(2-\frac{|p|}{y}\Big)$$ Which is shown by using the inverse of this formula. Then for $y \rightarrow \infty$ the right hand side goes to $\pi$ which gets you the limit proven. However, I do not understand this proof. Could you please shed more details on it? If you have another kind of proof in mind please feel free to share it. Thank you.","['limits', 'fourier-transform']"
3681241,What is the inverse relation of R,"Determine the inverse relation $R^{−1}$ for the relation $R = \{(x,y) : x + 4y \text{ is odd}\}$ defined on $\mathbb{N}$ . does this mean that $R^{-1} = \{(y,x):y+4x \text{ is odd}\}$ ?","['elementary-set-theory', 'relations', 'inverse', 'discrete-mathematics']"
3681297,Prove or disprove that R is an equivalence relation,"A relation $ R $ is defined on $ \mathbb{Z} $ by $ xRy $ if $ x \cdot y \geq 0 $ . Prove or disprove the following: (a) $ R $ is reflexive (b) $ R $ is symmetric (c) $ R $ is transitive (a) If $ xRx $ then $ x \cdot x \geq 0 $ for all $ x $ in $ \mathbb{Z} $ . This is true because $ (-a)(-a) = a $ , for all $ a $ in $ \mathbb{Z} $ . (b) If $ xRy $ then we want $ yRx $ for all $ x, y $ in $ \mathbb{Z} $ . This is true because $ ab = ba $ for all $ a, b $ in $ \mathbb{Z} $ . (c) Now I am stuck because I know that ""If $ xRy $ and $ yRz $ we want that $ xRz $ . This is true because ..."" but how do I say that multiplication is transitive.","['elementary-set-theory', 'equivalence-relations', 'solution-verification', 'discrete-mathematics']"
3681349,"Absolute minimum and maximum of $f(x,y,z)=x^4+y^4+z^4-4xyz$","I have to find the absolute maximum and minimum of the function $f(x,y,z)=x^4+y^4+z^4-4xyz$ over $x^2+y^2+z^2\leq 9$ , $x,y,z\geq 0$ . I'm having problems to find the constrained extremas in $x^2+y^2+z^2=9$ . I have tried by using the Lagrange's Multipliers theorem, by parametrizing the sphere and by algebraic manipulating the function but I haven't been able to come up with the solution. Could anybody help me? Thank you in advance.","['optimization', 'multivariable-calculus', 'maxima-minima', 'lagrange-multiplier']"
3681418,$\mathcal{M}(X)$ compact in Weak* Topology,"If $\mathcal{M}(X)$ is the space of all Borel probability measures on $X$ with Weak $^{∗}$ topology. Is there an example where $\mathcal{M}(X)$ is compact, but $X$ is not metric or not compact?","['probability-theory', 'ergodic-theory', 'functional-analysis', 'measure-theory']"
3681499,Graph theory analysis,"Hi! I need help with verifying this exercise and clarifying a doubt. I might tell you the definition I have since I'm translating and I don't know if with the translation I get the same terms in English. The exercise says: a. Find all the proper paths (paths) that go from vertex A to vertex F. Proper path - is when all vertices are different. Every proper path is a simple path. So this is what I got: ${(A,B,C,F), (A,B,C,E,F), (A,B,E,F), (A,B,E,C,F), 	(A,D,E,F), (A,D,E,C,F), (A,D,E,B,C,F)}$ b. Find all the simple paths (trails) that go from A to F. Simple path (trail) - is when all the arcs are different. ${(A,B,C,F), (A,B,C,E,F), (A,B,E,F), (A,B,E,C,F), (A,D,E,F), (A,D,E,C,F), (A,D,E,B,C,F), (A,D,E,B,C,E,F)}$ c. Find the distance from A to F. Distance - the shortest length between two vertices. So the distance is 3. d. The diameter of the graph. Diameter - the maximum of the distance between the vertices of the graph. So diameter is 5. e. Find the subgraphs obtained by removing each of its vertices. Are there cut points in that graph (a cut point in a connected graph is that one that when eliminated, together with all its incident edges, gives rise to a not connected graph)? EDITED: Are these all? Thanks for the help.","['graph-theory', 'discrete-mathematics']"
3681515,$m$-$n$ Theorem of triangles,"Consider the following theorem For the given triangle and the mentioned attributes of it, $$ (m+n)\cot\theta = m\cot\alpha - n\cot\beta$$ I am looking for the symmetric intuition behind this theorem. What is the hidden symmetry that underlies it","['triangles', 'trigonometry', 'geometry']"
3681519,Can one nontrivially bound intersection size with a union of sets given only pairwise intersection sizes?,"Say you have some finite, non-empty sets $S_1 \ldots S_n$ . You are not able to inspect the contents of these sets directly, or even produce their unions or intersections; the only way you can learn about them is through the function $P$ , defined as: $$
P(S_i, S_j)=\frac{|S_i \cap S_j|}{|S_i|}
$$ In other words, $P$ tells you what fraction of $S_i$ is also contained in $S_j$ —i.e., it captures precision . What I'd ideally like to be able to do is compute $$1 - P\left(S_n, \bigcup_{i=1}^{n-1} S_i\right),$$ AKA how much of $S_n$ is novel with respect to $S_1 \ldots S_{n-1}$ . Of course, this is impossible given only the pairwise $P$ function; an exact result would also need to account for $k$ -way intersections between the various sets. The question, though, is whether it's possible to compute some nontrivial bounds on this value. Intuitively, it seems like all these pairwise intersection sizes should give you a decent amount of information about size of the union of $S_1 \ldots S_{n-1}$ . What are the tightest bounds available on the expression above? Relatedly, does it change anything if we are able to access $|S_i|$ ? For example, I've worked out (tentatively) that in the case of $n=3$ , $$
P(S_3, S_1 \cup S_2) \geq \frac{|S_3 \cap S_1| + |S_3 \cap S_2| - \min(|S_1 \cap S_2|, \max(|S_1 \cap S_3|, |S_2 \cap S_3|))}{|S_3|}
$$ And given the $|S_i|$ s, all of these values should be computable from the $P(S_i, S_j)$ . But I'm still not sure how to generalize this to larger $n$ , and in particular whether the bound would become tighter or looser as $n$ grows.","['elementary-set-theory', 'upper-lower-bounds']"
3681594,Expected number of rolls until all numbers have been rolled an odd number of times (at the same time),"The title is a reformulation of a game that is played as follows: Before you are six light bulbs (all start turned off). You repeatedly roll a fair six-sided die and each time you roll a number you flip the switch of the corresponding switch, turning it on if it's off, and off if it's on. What is the expected number of rolls it will take until every light bulb is turned on? Note: I am not just asking ""What is the expected number of rolls until each number has been rolled?"", as this question has already been asked and answered many times here.","['expected-value', 'dice', 'probability']"
3681612,Elementary Complex Differential Forms,"I learned that an elementary differential form was one like $dx^{i_1}\wedge\cdots\wedge dx^{i_n}$ where $1\leq i_1<\cdots < i_n\leq n$ if we are on an real $n$ -dimensional manifold. I'm trying to learn about complex differential forms, but I am getting confused about the introduction of $d\overline{z}$ . The crux of my question is if I want to take a complex contour integral on a complex analytic $n$ -dimensional (with respect to $\mathbb{C}$ basis) manifold what does it look like? I had imagined that if I had a complex function, $f$ , defined on my complex analytic $n$ -dimensional manifold, then the integral would look like $\int_C fdz^1\wedge\cdots\wedge dz^n$ . But I keep seeing use of $d\overline{z}$ , and I don't know how this fits in. I've also seen a few complexification arguments in my reading, but if this can be done without considering the real space, I would prefer to do it that way. Any advice is much appreciated!","['integration', 'complex-analysis', 'differential-forms', 'differential-geometry']"
3681631,Prove that there are an infinite number of discontinuities on this function.,"Show the  function $f:[0,1]\rightarrow\mathbb{R}$ given by $$
f(x)=
\begin{cases}
1,&x=\frac{1}{n}\text{ for any positive integer $n$}\\
0,&\text{otherwise}
\end{cases}
$$ has an infinite number of discontinuities. I have completed the proof, however I'm not sure if it is completely rigorous.
I first showed that there is an infinite number of point that satisfy $$x=\frac{1}{n}$$ in the interval $[0,1]$ . I then defined $k_n$ as follows $$k_n \in \left(\frac{1}{n+1},\frac{1}{n}\right)\;\forall n\in \mathbb{N}$$ I then fixed $n$ and used the following interval for the function $$\left[\frac{1}{n+1},\frac{1}{n}\right)$$ rather than $[0,1]$ since it is a subinterval of $[0,1]$ . My logic was that if it is discontinuous on the subinterval then it must be discontinuous on $[0,1]$ but I am not quite sure how to say this rigorously so I simply stated it.
I then negated the definition of continuity and took $$\epsilon=\frac{1}{2}$$ I then substituted $$f\left(k_n\right) = 0\text{ and }f\left(\frac{1}{n}\right) = 1$$ so, if $$\left|k_n-\frac{1}{n}\right|<\delta$$ then, $$\left|0-1\right|=1\geq\frac{1}{2}$$ This was the gist of my proof, I didn't write out everything explicitly for you but, can it be improved? have i missed anything? got a better method? any help is appreciated.","['continuity', 'real-analysis']"
3681632,Does comparing a function against $x^N$ ensure $N$ times differentiable?,"If $$\lim_{x \to 0} \frac{f(x)}{x^N} = 0,$$ does that automatically ensure that $f$ has an $N^\text{th}$ derivative at $0$ ? Noting that that would require an $(N-1)^\text{st}$ derivative in an interval around $0$ , it seems unlikely to me that this implication is true, but I also can't find a counterexample. Note that the corresponding question for a more general Taylor polynomial would be: does $$\lim_{\Delta x \to 0} \frac{f(x_0+\Delta x)-g(x_0 + \Delta x)}{(\Delta x)^N} = 0,$$ with $g$ a degree $N$ polynomial, force $f$ to be $N$ times differentiable at $x_0$ with Taylor polynomial $g(x)$ ? This question is equivalent by an appropriate substitution. Note that the statement is true for $N=1$ , and can be considered true for $N=0$ if you define $0$ times differentiable at a point as continuous at that point. So a counterexample would have to be constructed for $N \ge 2$ .","['calculus', 'derivatives', 'taylor-expansion']"
3681639,Show that: $ \sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e $,"Let $(\Omega,\mathcal{A},\mu)$ be a finite mesure space, and $\{f_n\}$ and $\{g_n\}$ are two $L^1$ -bounded sequence, such that : $$
\sum_{n\geq 1}{\frac{1}{n}(F_n(f_n)(\omega)-g_n(\omega))}<\infty\qquad a.e
$$ with: $F_n(f_n)=f_n1_{|f_n|\leq n}$ Show that: $$
\sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e
$$ My effort: according to $\sup_n\|f_n\|_1<\infty$ , there exists $n_0\geq 1$ , such that: for all $n\geq 1$ we have $$|f_n|\leq n_0~~  a.e.$$ Then for all $n\geq n_0$ : $$F_n(f_n)=f_n$$ hence, we have the desired result. Is what I wrote correct?","['measure-theory', 'lebesgue-measure', 'probability']"
3681640,"Prove that $\exists a, b\in(0,1)$ such that $\int_0^{a} xf(x)dx=0\text{ and }\int_0^bxf(x)dx=\frac{b^2f(b)}{2}.$","Question: Let $f:[0,1]\to\mathbb{R}$ be a continuous function such that $f(0)=0$ and $$\int_0^1f(x)dx=0.$$ Prove that $\exists a, b\in(0,1)$ such that $$\int_0^{a} xf(x)dx=0\text{ and }\int_0^bxf(x)dx=\frac{b^2f(b)}{2}.$$ My approach: Let $g:[0,1]\to\mathbb{R}$ be such that $$g(x)=x\int_0^xf(t)dt-\int_0^xtf(t)dt, \forall x\in[0,1].$$ By the first fundamental theorem of calculus we can conclude that $g$ is differentiable on $[0,1]$ and $$g'(x)=\int_0^xf(t)dt, \forall x\in[0,1].$$ Also, observe that $g(0)=0$ and $g(1)=-\int_0^1tf(t)dt$ . Thus, by applying MVT to the function $g$ on the interval $[0,1]$ , we can conclude that, $\exists c\in(0,1)$ such that $$g'(c)=\int_0^cf(t)dt=-\int_0^1tf(t)dt.$$ Observe that clearly three cases are possible, i.e, either $$\int_0^cf(t)dt<0\text{ or }\int_0^cf(t)dt=0\text{ or }\int_0^cf(t)dt>0.$$ Now let $h:[0,1]\to\mathbb{R}$ be such that $$h(x)=\int_0^xtf(t)dt, \forall x\in[0,1].$$ Please note that the part highlighted below is wrong, but still I have included it to just demonstrate my thinking process, as it might be of some help to others trying out this problem. Observe that if $\int_0^cf(t)dt<0$ , then, $h(1)>0$ . This also implies that $\exists$ an open interval $(d,e)\in[0,c]$ , such that $f(t)<0, \forall t\in(d,e)$ . Now select any point $c_1\in(d,e)$ . Applying MVT to the function $h$ on the interval $[0,c_1]$ , we can conclude that $\exists c_2\in(0,c_1)$ such that $$h'(c_2).c_1=f(c_2).c_2.c_1=h(c_1)-h(0)=h(c_1)<0.$$ Now $h(c_1)<0$ and $h(1)>0$ . Thus, by IVT we can conclude that $\exists a\in(c_1,1)\subseteq(0,1)$ , such that $$h(a)=\int_0^af(t)dt=0.$$ A similar reasoning for the case when $\int_0^cf(t)dt>0,$ shows that $\exists a\in(0,1)$ , such that $$h(a)=\int_0^af(t)dt=0.$$ Now finally if $\int_0^cf(t)dt=0$ , then we will have $h(1)=0$ . Now if $f$ is identically equal to $0$ on $[0,c]$ , then clearly $tf(t)=0, \forall t\in[0,c]\implies h(x)=0, \forall x\in[0,c].$ Thus choosing any point $x\in(0,c]$ and setting it as $a$ , we will have $h(a)=0$ and we will be done in that case. Now if $f$ acquires both positive and negative values on $[0,c]$ , then we can conclude that $\exists c_1,c_2\in(0,c)$ , such that $f(c_1)>0$ and $f(c_2)<0$ . Also, let us assume WLOG that $c_2>c_1$ . I have not been able to make any significant approach other than this. Can someone help me out with this problem? Please note that a solution using integration by parts might not be possible, since $f$ is not a differentiable function.","['integration', 'real-analysis']"
3681781,Quadrilateral with two congruent legs of diagonals,"I've come across a geometry proof which seems like it should be easy, but I'm struggling with it: Suppose you have a convex quadrilateral $ABCD$ whose diagonals intersect at $E$ .  Given that angles $ABC$ and $BCD$ are congruent, and the two ""legs"" of the diagonals $EA$ and $ED$ are congruent, show that the sides $BC$ and $AD$ are parallel (that is, show that this quadrilateral is an isosceles trapezoid).
(If this cannot be proven, please explain why or give a counterexample.) I know that we can use the isosceles triangle theorem on triangle $AED$ to show that angles $EAD$ and $EDA$ are congruent, and I know that the angles $BEA$ and $CED$ are congruent, as well as $BEC$ and $DEA$ .  I'm trying to get a pair of congruent triangles that will show that the sides $AB$ and $CD$ are congruent, but I'm always missing one constraint. For example, if I try to show that triangles $ABC$ and $DCB$ are congruent, I have a side $BC$ congruent to itself, and two angles $ABC$ and $DCB$ congruent, but I can't show that the diagonals are congruent because I only know that $AE$ is congruent to $DE$ , and I don't know that $EB$ is congruent to $EC$ . If I try to show that triangles $AEB$ and $DEC$ are congruent, I have side $AE$ congruent to side $DE$ , and angles $AEB$ and $DEC$ congruent, but I can't show that any other pair of angles is congruent, since I only know angles $EAD$ and $EDA$ are congruent and angles $ABC$ and $DCB$ are congruent, but I can't show that angles $EBA$ and $ECD$ are congruent. I have a strong intuition that this proposition is true, but I can't prove it.  I'm hoping someone here can either give a sound proof or give a counterexample that explains why this proposition is false.","['euclidean-geometry', 'proof-writing', 'geometry']"
3681787,Planar graphs and homomorphism graphs?,"I'm working with graphs. I would like to please be verified with this one. Draw, if possible, a planar representation of each graph: I got the planar representation of the 2nd graph. This is what I got. I think the third is not possible. Is that right? Also, do you know how to show that the two graphs are homeomorphic? I understood how to show that graphs are isomorphic, but I'm not really getting homeomorphism. I know that graphs are said to be homeomorphic if both can be obtained from the same graph by subdivisions of edges. But how can I show that they are homeomorphic? The vertices don't have labels.","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
3681799,2 out of 3 property for faithfully flat ring maps,"Proposition 1: Let $f : A\to B$ and $g : B\to C$ be ring maps such that $g$ is faithfully flat. Then the composition $gf$ is flat (resp. faithfully flat) if and only if $f$ is flat (resp. faithfully flat). Proof: Certainly flatness (resp. faithful flatness) of $f$ implies flatness (resp. faithful flatness) of $gf.$ Conversely, suppose that $gf$ is flat, and let $M'\to M\to M''$ be an exact sequence of $A$ -modules. Then flatness of $gf$ implies that $M'\otimes_A C\to M\otimes_A C\to M''\otimes_A C$ is exact as well, whence by faithful flatness of $g$ we have that $M'\otimes_A B\to M\otimes_A B\to M''\otimes_A B$ is exact. If $gf$ is faithfully flat, and $M'\to M\to M''$ is a sequence of $A$ -modules such that the composition $M'\to M''$ is $0,$ then faithful flatness of $gf$ implies that $M'\to M\to M''$ is exact if and only if $M'\otimes_A C\to M\otimes_A C\to M''\otimes_A C$ is. Faithful flatness of $g$ implies that this is exact if and only if $M'\otimes_A B\to M\otimes_A B\to M''\otimes_A B$ is. $\square$ This result has been surprisingly hard to track down in the literature, despite the simplicity of the proof. (The proof and statement of proposition 1 in the flat case can be found here ; I do not know of anywhere that the version of proposition 1 for faithful flatness exists, although I'm sure I just haven't searched carefully enough.) Note that this proposition is not true only assuming flatness of $g,$ as evidenced by the composition $k[t^2, t^3]\to k[t]\to k(t).$ I was originally interested in the situation where we assume that the composition is flat, and use that to deduce that $f$ is flat. However, I was wondering whether the following stronger proposition is true. Proposition 2: Let $f : A\to B$ and $g : B\to C$ be ring maps such that the composition $gf : A\to C$ is faithfully flat. Then $f$ is faithfully flat. Disclosure: I asked this question in the hopes that this 2 out of 3 property for faithfully flat morphisms will more easily searchable for anyone trying to find a result of this type in the future.","['algebraic-geometry', 'commutative-algebra']"
3681810,Derivative of L1 norm of Hadamard product,"I am trying to find the derivative of $f(B)=\lambda\Vert W \bigodot B \Vert_1 + \frac{\rho}{2}\Vert A-B \Vert_F^2 + tr(\Delta^T(A-B))$ with respect to B. where B is (n×n）matrix, W is (n×n）constant matrix, A is (n×n）constant matrix. $\lambda$ and $\rho$ are scalars. $tr$ is the trace of the matrix. $W \bigodot B$ is the Hadamard product of W and B. I am troubled in finding the derivative involving Hadamard product and L-1 norm. Therefore, I first replaced $W \bigodot B$ with T. $$T=W \bigodot B$$ $$B=W^{-1} \bigodot T$$ where $W^{-1}$ is the element-wise inverse. $W \bigodot W^{-1}=I$ . $$f(T)=\lambda\Vert T \Vert_1 + \frac{\rho}{2}\Vert A-W^{-1} \bigodot T  \Vert_F^2 + tr(\Delta^T(A-W^{-1} \bigodot T))$$ I do not konw what to do next.
Thank you in advance for any help you can provide.","['hadamard-product', 'matrices', 'matrix-calculus', 'derivatives', 'regularization']"
3681813,Can gradient of a function be Lipschitz continuous but the function is not Lipschitz?,"Can gradient of a function be Lipschitz continuous but the function is not Lipschitz? Any figurative example where gradient is Lipschitz but the function is not Lipschitz possible would be really intuitive, can someone illuminate me? Thank you so much in advance for your help.","['functional-analysis', 'lipschitz-functions', 'real-analysis']"
3681814,Using Law of Iterated Logarithm to calculate limits,"Suppose $X_i$ are i.i.d., $\mathbb{E}X_1 = 0$ , $\mathbb{E}X^2_1<\infty$ and $S_n = \sum_{i=1}^n X_i$ I am to calculate three following limits: $\liminf_{n \to \infty} \frac{S_n}{ \sqrt{n \ln ( \ln(n))}}$ $\lim_{n \to \infty} \frac{S_n}{n^{\alpha}}$ where $\alpha > \frac{1}{2}$ $\lim_{n \to \infty} \frac{-S_n}{\sqrt{n}lnn}$ The first one was relatively easy, and I got $-\sqrt{2 \mathbb{E}X^2_1}$ as result (using symmetry and LIL Hartman's-Winter). I got stuck on the next two however. What can be done here?","['random-walk', 'probability-theory', 'probability']"
3681841,Finding the remainder of a 6 degree polynomial and polynomial itself. Using some algebraic or graphical techniques. [duplicate],"This question already has an answer here : Solving a six-degree polynomial of the form $ax^6+bx^3+g$. (1 answer) Closed 4 years ago . In a six-degree polynomial, say $f(x)$ we have, $$f(1)=1, f(2)=1/2, f(3)=1/3, f(4)=1/4, f(5)=1/5, f(6)=1/6, f(7)=1/7$$ Find $f(8)$ and the polynomial $f(x)$ . This problem comes all the way from the book of an Indian Author. I tried solving the problem using algebra (definitely not by substituting values in the polynomial and solving for SIX variables). According to me, this question is definitely having a more rational approach. I tried using algebraic techniques by manipulating $f(x)$ writing it in terms of a new polynomial say $h(x)$ but in vain. So can anyone of the bright minds out there could help me in attempting the question. It would be a great help.","['functions', 'polynomials']"
3681872,Problem with Infinite number of iterated integrals,"I have been working on a problem from a past high school Math Competition and I have been stumped. I am asked to compute $$\lim_{n\rightarrow\infty} \int_{0}^{1}\int_{0}^{1}\cdot\cdot\cdot\int_{0}^{1}\frac{x_{1}^{505}+x_{2}^{505}+...+x_{n}^{505}}{x_{1}^{2020}+x_{2}^{2020}+...+x_{n}^{2020}}\,dx_{1}\,dx_{2}\,...\,dx_{n}$$ At first I tried a lot of direct evaluations of the integral to find a simplification i.e. solving the general integrals $$\int_{0}^{1}\frac{x^{505}+a}{x^{2020}+b}\,dx$$ but this really only complicated the matter, so I began to look for more clever manipulations. I noticed for $x_i \in [0,1]$ that we would have the integrand $$ f(x_1,x_2,...,x_n) = \frac{\frac{1}{n}}{\frac{1}{n}}\cdot\frac{\sum_{i=1}^{n}x_{i}^{505}}{\sum_{i=1}^{n}x_{i}^{2020}}$$ which can be seen as a Riemann sum so at infinity, $$\lim_{n\rightarrow\infty}f(x_1,x_2,...,x_n)=\frac{\int_{0}^{1}x^{505}\,dx}{\int_{0}^{1}x^{2020}\,dx}=\frac{2021}{506}$$ My thought process was that the region in $\mathbb{R}^n$ being integrated over is the unit cube, so I could try to view the integral as the product of the volume of the region by some average value of the function in the region, which would maybe approach a constant value because of the Riemann sum? I was just unsure if any of this can be justified, especially when the number of integrals approaches infinity. Any help or advice is appreciated.","['integration', 'iterated-integrals', 'calculus', 'multiple-integral']"
3681879,"How do I understand ""odd parity""","In my Calc 2 course, we're in the u-sub section at the moment. One of my homework problems was $$\int_{-\pi/2}^{\pi/2}{(\cfrac{x^6\sin(3x)}{1+x^{10}})dx}$$ I realized substitution nor integration by parts will work. It turns out the answer is 0 because If $f(x)$ is an odd function and is continuous on the interval [-a, a], then $\int_{-a}^af(x)dx=0$ Can somebody explain the logic behind this; especially why $f$ has to be odd? Is there a simple illustration showing why I should trust the theory?","['integration', 'calculus', 'definite-integrals']"
3682003,Find minimal value of $\left(2-x\right)\left(2-y\right)\left(2-z\right)$,"Let $x,y,z>0$ such that $x^2+y^2+z^2=3$ . Find minimal value of $$\left(2-x\right)\left(2-y\right)\left(2-z\right)$$ I thought the equality occurs at $x = y = z = 1$ (then it is easy), but the fact is $x = y = \frac{1}{3}; z = \frac{5}{3}$ . So I just thought of using $uvw$ , but I am not allowed to use it during my exam. Because of the equality I cannot use AMGM, Cauchy-Schwarz, etc. I tried to use Mixing-Variables, but I failed. Please help.","['roots', 'multivariable-calculus', 'symmetric-polynomials', 'optimization', 'inequality']"
3682028,Geometric visualization of tangent bundles/sheaves and normal cones/bundles,"In algebraic geometry it is customary to identify locally free sheaves on say a scheme $X$ and vector bundles over the same scheme. So say I have a nice scheme $X$ (you can assume it to be a variety, over an algebraically closed field $k$ ), and an exact sequence of locally free sheaves $0\to V'\to V \to V''\to 0$ , this exact sequence is exact on the level of stalks, almost by definition, if $x$ is a (closed) point of $X$ , $0\to j^*V'\to j^*V \to j^*V''\to 0$ is also exact because $V''$ is locally free, hence flat (here $j$ is the closed immersion $x\to X$ ). My question comes to how to practically apply this in the case of normal cones to regular immersion. Let's look at a simple example, $Z=\{xy=0\}$ regularly embedded in $X=\mathbb{A}^2$ .
Concerning $Z$ we have the cotangent sheaf. It is not locally free but the normal cone of $Z$ is locally free. At the origin, we have a geometric tangent cone given by the union the two axis lines. How is this related to the fiber of the tangent sheaf at 0, or to the fiber of the (co)normal cone at 0? We have an exact sequence $0\to N_{Z/X}^{*}\to j^* \Omega^1_X \to \Omega^1_Z\to 0$ .
Away form the origin, it is easy to understand what's going on, at a point of the form say $(a,0)$ the stalk of the cotangent sheaf is given by $f(x)dx$ , the fiber is simply $f(a)dx$ , the conormal sheaf has fiber $k.dy$ (where k is the base field or the residue field of the point). At the origin it becomes blurry to me, the normal bundle should have a line as a fiber, but which line?
The stalk of the tangent sheaf at the point consists of forms of the form $f(x)dx+g(y)dy$ and the fiber is a vector space of dimension 2. Which is also the case for the fiber of $j^{*}\Omega^1_X$ , but as the sheafs are not (locally) free I cannot deduce that the fiber of the normal bundle is zero, which is good as it should be a line. Most importantly, how does this relate to the tangent cone, which is $xy=0$ .
What is the normal cone? In particular how do i deduce the normal cone from the tangent cone (and not the (co)tangent sheaf and the exact sequence). I was hoping that the normal cone should be related (orthgonal) to something like the vector space generated by the tangent cone, but obviously this is not the case. I hope my question is somewhat clear, I can clarify it if needed. Addendum: Algebraically I seem to understand what's going on, it is indeed easy to write down an explicit version of the exact sequence mentionnenned but it is absolutely not clear to me how to interpret the arrow $ N_{Z/X}^* \to\Omega^1_X$ , in particular if I understand things correctly, over $(0,0)$ the map on the fiber will fail to be injective (but will be on the stalks of course), as $\Omega^1_Z$ is not free over $\mathcal{O}_{Z,(0,0)}$ this is not problematic but it makes the geometric interpretention of the (co)normal bundle fiber at that point extremely tedious (to me at least). In particular its fiber is not a subthing of $j_{(0,0)}^*\Omega^1_X$ . Is there a way to have a geometric interpretation of that normal line at the origin. By that I mean, on a picture, how would you draw that line and why?","['vector-bundles', 'algebraic-geometry']"
3682036,The volume of the image of a map with vanishing Jacobian is zero,"Let $\Omega \subseteq \mathbb{R}^n$ be a nice domain with smooth boundary (say a ball), and let $f:\Omega \to \mathbb{R}^n$ be smooth. Set $\Omega_0=\{ x \in \Omega \, | \, \det df_x =0 \} $ Is there an elementary way to prove that $m(f(\Omega_0))=0$ ? ( $m$ is the Lebesgue measure). I know that this follows from the (co)area formula or Sard's theorem*, but is there a way that avoids them? Edit: In this answer , zhw proves that if $x \in \Omega_0$ , and $B(r)$ is an Euclidean ball of radius $r$ centered at $x$ , then $\frac{m(f(B(r))}{m(B(r))} \to 0$ . Since $\Omega_0$ is compact, we can proceed as follows: Cover $\Omega_0$ by finitely many balls $B_i$ with radius $r$ , centered around points that belong $\Omega_0$ . ( The centers depend on $r$ )Then, $$ m(f(\Omega_0)) \le \sum_i m(f(B_i))=\sum_i \frac{m(f(B_i))}{m(B_i)}m(B_i).$$ If we could prove that $\frac{m(f(B_i))}{m(B_i)} \to 0$ when $r \to 0$ uniformly in $i$ , then we could get $$
m(f(\Omega_0)) \le o(1) \sum_i m(B_i)=o(1) \sum_i m(B(r)).
$$ Since we can cover $\Omega_0$ by $N(r)$ balls of radius $r$ with centers in $\Omega_0$ , where $N(r) \le c \frac{1}{m(B(r))}$ , we could conclude that $m(f(\Omega_0)) \le o(1)$ , so it must be zero. The problem is that I am not sure if $\frac{m(f(B_{x_i(r)}(r)))}{m(B_{x_i(r)}(r))} $ converges to zero independently of $i$ . I asked about this separately here . *If I am not mistaken, then Sard's theorem implies that almost every $y \in \mathbb R^n$ is a regular value of $f$ - so it doesn't have a preimage in $\Omega_0$ . **I don't know an elementary proof even in the case where $\Omega_0=\Omega$ . That is, even if we assume the the domain where the Jacobian vanishes is ""open and nice"" I don't know if its trivial. In general, $\Omega_0$ is an arbitrary closed set, which might be pretty complicated.","['measure-theory', 'geometric-measure-theory', 'real-analysis', 'multivariable-calculus', 'change-of-variable']"
3682082,"Intuition behind , and understanding the definition of convexity in the real projective space","I have been studying the Real projective space, which we denote by $\mathbb{RP}^n$ , is obtained by identifying any two points $\mathbb{R}^{n+1} \setminus \{0\}$ that are proportional. I have also understood how in $\mathbb{RP}^2$ , projective points are lines through the origin, and projective lines are planes containing the origin. I am reading the book Complex Convexity and Analytic Functionals by Andersson .
Here definition 1.3.2 says A subset $E$ of $\mathbb{RP}^n$ is said to be convex if it does not contain any projective line and its intersection with any projective line is connected . A convex set is called non-degenerate if it is not contained in any hyperplane and does not contain any affine line. Can anyone tell me first as to how I can relate this definition to convexity in the Euclidean space? This way I can get an intuition behind the above definition. Why is a convex set not supposed to contain a projective line? Why do we consider and define non-degenerate convex set?","['general-topology', 'projective-geometry', 'convex-analysis', 'projective-space']"
3682091,Question about boundary of super-level sets of a continuous function,"I want to prove the following statement. Let $\Omega$ be an open subset of $\mathbb{R}^n$ and let $f \in C^0
 (\Omega;\mathbb{R})$ . Then, for every $r \in \mathbb{R}$ $$\partial
 \left\{ f > r \right\} \subseteq \left\{ f =r \right\},$$ where $\partial$ denotes the topological boundary and $\left\{ f > r
 \right\}=\left\{ x \in \Omega : f(x) > r \right\}$ . My attempt : Suppose by absurd that there exists $\bar{x} \in \partial \left\{ f > r \right\}$ such that $f (\bar{x}) > r$ . By continuity, there exists an open neighborhood $U_{\bar{x}}$ of $\bar{x}$ such that: $$f (y) > r \quad \forall \; y \in U_{\bar{x}},$$ i.e. $U_{\bar{x}} \subseteq \left\{ f > r \right\}$ and then $$U_{\bar{x}} \cap \left\{ f > r \right\}^c=\emptyset,$$ and this is an absurd with the definition of $\partial \left\{ f > r \right\}$ . Similarly for the case $f(\bar{x}) < r$ and then $$\bar{x} \in \partial \left\{ f > r \right\}  \quad \Rightarrow f(\bar{x})=r.$$ Is it correct?
Thanks","['geometry', 'real-analysis', 'functions', 'general-topology', 'differential-geometry']"
3682111,Evaluating $\lim_{n \to \infty} \int_{0}^{\pi} \frac{\sin x}{1+\cos ^2(nx)} dx$,"Evaluate the limit $$\displaystyle\lim_{n \to \infty} \int_{0}^{\pi} \frac{\sin x}{1+\cos ^2(nx)} dx$$ Using property of definite integral $\int_{0}^{2a} f(x).dx=2\int_{0}^{a} f(x)dx$ ,when $f(2a-x)=f(x)$ I got $$\displaystyle\lim_{n \to \infty} \int_{o}^{\pi} \frac{\sin x}{1+\cos ^2(nx)} dx=2\displaystyle\lim_{n \to \infty} \int_{o}^{\pi/2} \frac{\sin x}{1+\cos ^2(nx)} dx$$ but I cannot proceed after that. Could someone provide me with some hint? Till now I have only done integration in terms of elementary functions. Any hint would be appreciated.","['limits', 'calculus', 'definite-integrals']"
3682155,how to solve apollonius problem( $CCC$ case) with compass and straight edge,"Given three circles, how to construct another circle that is tangent to the three circles with compass and straight edge? Well, this problem can be reduced to ( $\rm\color{purple
} {PCC} $ case) by shrinking the smallest circle into a point. But I also don't know how to solve ( $PCC$ case). The problem has $8$ solutions in general. Any hint?","['geometric-construction', 'geometry', 'plane-geometry']"
3682184,"Morphism $\Gamma :\mathbb{A}^n\rightarrow \mathbb{A}^d$ coresp. to $\gamma: k[y_1,\ldots,y_d]\rightarrow k[x_1,\ldots,x_n]$ is a projection","Let $X\subset \mathbb{A}^n$ be an affine variety with $A(X)=k[x_1,\ldots,x_n]/I(X)$ . Write $A=k[a_1,\ldots,a_n]$ for $A(X)$ (where $a_i$ is the image of $x_i$ ). Let $B=k[y_1,\ldots,y_d]$ be a Noether normalization of $A$ . I've previously shown that for $i=1,\ldots,d$ there exists linear polynomials $l_i=l_i(x_1,\ldots,x_n)$ and $k$ -algebra homomorphism $\gamma: B\rightarrow k[x_1,\ldots,x_n]$ mapping $y_i\mapsto l_i$ , st. $B\subset A$ factors as $\gamma$ composed with a surjection $k[x_1,\ldots,x_n]\rightarrow A$ . Let $\Gamma :\mathbb{A}^n\rightarrow \mathbb{A}^d$ be the morphism corresponding to $\gamma$ . I want to show, that after a suitable linear change of coordinates on $\mathbb{A}^n$ , then we may see $\Gamma$ as the projection onto the first $d$ coordinates. From the correspondance, the I know that $\gamma(f)=f(\Gamma)$ for $f\in B$ . So in fact $l_i=\gamma(y_i)=y_i(\Gamma)$ . I've tried played around with this, but it doens't get me much further. I'm kinda stuck now, and don't see how I should make a linear change of the coordinates on $\mathbb{A}^n$ (as far as I understand, then I want to make variable change to the $x_i$ 's st. that $\Gamma$ becomes the projection).",['algebraic-geometry']
3682207,Relation between local ring of regular variety and local ring of regular subvariety,"Let $X$ be a regular affine variety and $Y \subseteq X$ be a regular subvariety such that $\dim(X)-\dim(Y)=1$ . If $y \in Y,$ can we say $\frac{\mathcal{O}_{X,y}}{<c>} \cong \mathcal{O}_{Y,y} $ for some $c \in (\mathfrak{m}_{X,y}\setminus \mathfrak{m}^2_{X,y})$ , where $\mathfrak{m}_{X,y}$ is the unique maximal ideal of $\mathcal{O}_{X,y}$ ? I proved that $\frac{\mathcal{O}_{X,y}}{<c>}$ is regular ring and it's dimension is $dim(X)−1$ when $c$ is in $\mathfrak{m}_{X,y}\setminus \mathfrak{m}^2_{X,y}$ . I don't know how to proceed from this part. I appreciate any help.",['algebraic-geometry']
3682322,Unitarily equivalent multiplication operators,"Let $A$ be the operator given by $Ax(t)=\sin(t)\,x(t)$ in $L_2[0,2\pi]$ , and $B$ the operator given by $Bx(t)=\sin(t)\,x(t)$ in $L_2[-2\pi,2\pi]$ . Are these operators unitarily equivalent?","['operator-theory', 'spectral-theory', 'functional-analysis']"
3682353,Topology on power set such that union is continuous,"Let $C$ be a set and let $2^C$ be its power set. Consider the union function $\cup: 2^C\times 2^C\rightarrow 2^C$ such that $\cup (X,Y)=X\cup Y$ . For a fixed $Y\in 2^C$ , let $\cup_Y$ be the evaluation map $\cup_Y(X)=X\cup Y$ . Are there natural topologies in $2^C$ such that: the union function $\cup$ is continuous; for every singleton ${y_0}$ the evaluation map $\cup_{y_0}$ has dense image? Any help is welcome. P.S: I have no concrete problem involving the question above in mind. I'm pursuing a motivation for a nomenclature that I'm using in a not related work.",['general-topology']
3682418,What is the meaning of set in Theorem3.1 of ALGEBRA by Thomas W. Hungerford?,"What happens if I choose class instead of set in part (ii) of this theorem?
AND  essentially what is the difference between a set and a class?","['elementary-set-theory', 'abstract-algebra']"
3682518,"A tweak to an integral for $(s-1)\,\Gamma(s)\,\zeta(s)$. What is its value at $s=0$?","The following integral: $$(s-1)\,\Gamma(s)\,\zeta(s)={\int_{0}^{\infty}\!{u}^{s-1} \left( {\frac {u-1}{{{\rm e}^{u}}-1}}+{\frac {u}{ \left( {{\rm e}^{u}}-1 \right) ^{2}}} \right) \,{\rm d}u}\ \qquad \Re(s)>0$$ could be tweaked into: $$f(s)={\int_{0}^{\infty}\!{u}^{s-1} \left( {\frac {u-1}{{({\rm e}^{u}}-1)^\frac12}}+{\frac {u}{ \left( {{\rm e}^{u}}-1 \right) ^{\frac32}}} \right) \,{\rm d}u}\ \qquad \Re(s)\ge0$$ and yields closed forms expressions for certain values: \begin{align}
f\left(\frac12\right)&=2 \\
f(1)&= \pi \\
f(2)&= 6\,\pi\,\ln(2) \\
f(3)&= 10\,\pi\,\zeta(2)+20\,\pi\,\ln(2)^2 \\
f(4)&= 84\,\pi\,\zeta(3) +84\,\pi\,\ln(2)\,\zeta(2) +56\,\pi\,\ln(2)^3 \\
f(5)&=...
\end{align} so, at integer values of $f$ , the function can be expressed as a finite series of weighted $\zeta$ -values. Question: f(0) also converges for this integral to: 1.869957636881892752... Curious whether this value could be expressed into other constants? (checked Plouffe's inverter and Mathematica, but no results from those). Added: Made one step forward on $f(0)$ , by splitting the associated integral: $$\int_{0}^{\infty}\! \left( {\frac {1-\frac{1}{u}}{{({\rm e}^{u}}-1)^{\frac12}}}+{\frac {1}{ \left( {{\rm e}^{u}}-1 \right) ^{\frac32}}} \right) \,{\rm d}u$$ into: $$\overbrace{\int_{0}^{\infty}\! \left( {\frac {1}{{({\rm e}^{u}}-1)^{\frac12}}} \right) \,{\rm d}u}^{\pi} \,\, + \,\, \overbrace{\int_{0}^{\infty}\! \left( {\frac {-\frac{1}{u}}{{({\rm e}^{u}}-1)^{\frac12}}}+{\frac {1}{ \left( {{\rm e}^{u}}-1 \right) ^{\frac32}}} \right) \,{\rm d}u}^{-1.2716350167...}$$ So, the question now boils down to whether a closed form for $-1.2716350167...$ exists.","['riemann-zeta', 'number-theory', 'definite-integrals']"
3682585,Tangent space definition,"I am slightly confused by the algebraic definition of tangent spaces on a differentiable manifold. The book I am following defines the tangent space at a point p in a manifold M to be the set of all linear derivations on the algebra of germs of locally defined functions at p. What I do not understand is why we look at derivations on 'germs', i.e equivalence classes of functions whose restrictions agree on some open neighbourhood of p (explicated for my own edification), rather than just looking at derivations on the locally defined functions themselves. As I understand it, a derivation on the algebra of germs is the same as a derivation acting on representative members of the equivalence classes, so I do not understand why the object of consideration is the set of equivalence classes of functions rather than the functions themselves. The wikipedia article on tangent spaces briefly justifies this by asserting that this is necessary for some applications in Algebraic Geometry, but I did not follow any of this.","['tangent-spaces', 'differential-geometry']"
3682596,How to verify if $\cos(x)+\sin(\sqrt{3} x)$ is periodic with elementary methods?,"I've been given this exercise (among others) and am trying to verify if it is periodic. For the other problems, I did some graph sketching and solved it but this one is a bit more complicated. At the moment, I just thought about using: $$\sin(x)=\cos\left(\frac{\pi}{2}-x \right)$$ Yielding: $$\cos(x)+\sin(\sqrt{3}x)=\cos(x)+\cos \left(\frac{\pi}{2} - \sqrt{3}x \right)$$ And I also tried to use identities such as the ones for $\sin(x) + \cos (y)$ and $\cos(x)+\cos(y)$ without success. I've managed to find a strategy that could work: We assume that $f(x)=\cos(x)+\sin(\sqrt{3} x)$ , if $f$ is periodic, then there is a unique smallest positive number $t$ such that for all $x$ , we have: $$f(x)=f(x+t)$$ All we need to do now is pick $x,x'$ such that finding solutions for $t$ in $$f(x)=f(x+t)\\f(x')=f(x'+t)$$ yield different results. One of the ""strategic"" values is $x=0$ , we then have: $$1=\cos(t)+\sin(\sqrt{3}t)$$ Now if we come up with a certain $x'$ such that $$\cos(x')+\sin(\sqrt{3}x')=\cos(x'+t)+\sin(\sqrt{3}(x'+t))$$ implies that $t$ needs to be different in both equations, I guess this shows it is non-periodic. The trouble is that finding such an $x'$ doesn't seem easy.",['trigonometry']
3682610,Every separable Banach space is isometrically isomorphic to a quotient of $\ell^1$,"I am currently trying to prove the statement above. So let $X$ be a Banach space and choose a dense sequence $(x_n)_n$ in the closed unit ball of $X$ . Then it is easy to see that $$T: \ell^1 \to X, \quad Ta = \sum_{n = 1}^\infty a_n x_n$$ is well-defined and $\lVert T \rVert \leq 1$ . To prove surjectivity of the map pick $x \in X$ with $\lVert x \rVert \leq 1$ . Then by density of the sequence $(x_n)_n$ I can find some $n_1 \in \mathbb N$ such that $\lVert 2x - x_{n_1} \rVert \leq 1$ . For the same reason I can find $n_2 \in \mathbb N$ such that $\lVert 2(2x - x_{n_1}) - x_{n_2}\rVert \leq 1$ . So inductively I obtain a sequence $(n_k)_k$ such that $$ \bigg \lVert x - \sum_{k = 1}^N \frac{1}{2^k} x_{n_k} \bigg \rVert < \frac{1}{2^N}$$ for all $N \in \mathbb N$ . Now set $a := \sum_{k = 1}^\infty \frac{1}{2^k} e_{n_k}$ (where $e_n$ denotes the $n$ -th unit vector) and obtain that $a \in \ell_1$ and $\lVert a \rVert_{\ell^1} \leq 1$ . Moreover, one easily calculates that $Ta = x$ . Hence $T$ maps the closed unit ball of $\ell^1$ onto the closed unit ball of $X$ . In particular, $T$ is surjective and by the isomorphism theorem $$ S: \ell^1/ \ker T \to X,\quad a + \ker T \mapsto Ta $$ is an isomorphism. Hence, $\ell^1/ \ker T \cong X$ as vector spaces. So it is just left to show that $S$ is an isometry. So let $a \in \ell^1$ . Then one has clearly that $$ \lVert S(a + \ker T) \rVert = \lVert T(a + b) \rVert \leq \lVert a + b \rVert_{\ell^1}$$ for each $b \in \ker T$ and therefore $$ \lVert S(a + \ker T) \rVert \leq \inf \{\lVert a + b \rVert_{\ell^1} : b \in \ker T\} = \lVert a + \ker T \rVert,$$ i.e. $\lVert S \rVert \leq 1$ . This means by the inverse theorem that $\ell^1/ \ker T \cong X$ as Banach spaces. But I have no idea how to show that $\lVert S(a + \ker T) \rVert \geq \lVert a + \ker T \rVert$ for all $a \in \ell^1$ . I think I have to come up with some fancy representative $\tilde a \in \ell^1$ but I do not see how to get that. What am I missing? Please tell me anyone :-)","['banach-spaces', 'operator-theory', 'functional-analysis', 'real-analysis']"
3682691,Are two Poisson random variables independent if their sum is also Poisson?,"Suppose $X\sim \text{Poisson}(\lambda)$ , $Y\sim \text{Poisson}(\mu)$ . If $X+Y\sim \text{Poisson}(\lambda+\mu),$ can we conclude that $X$ and $Y$ are independent? I know that, if we assume that the conditional distribution of $X$ given $W=X+Y$ is a Binomial distribution, then $X, Y$ can be shown to be independent. I wonder whether the independence holds in absence of any such assumption.","['poisson-distribution', 'independence', 'probability-distributions', 'probability-theory', 'probability']"
3682722,"How to tell whether a vector of random variables has a single variable as input, and when it has a vector of variables as input?","Let $X_1,...,X_n$ be random variables. Then the formula $$\mathbb{P}(\pmatrix{X_1\\...\\X_n} = A)$$ can have two meanings, dependent on how $\mathbb P $ is defined: It can mean either $\mathbb{P}\left(\left\{w\in\Omega\mid \pmatrix{X_1(w)\\...\\X_n(w)} = z\right\}\right)$ , if we define our probability space as $(\Omega,\mathcal{F},\mathbb{P})$ or $\mathbb{P}\left(\left\{\pmatrix{w_1\\...\\w_n} \in \times_{i=1}^n \Omega_i \mid \pmatrix{X_1\\...\\X_n}\pmatrix{w_1\\...\\w_n}  = z\right\}\right)$ , if we define our probability space as $(\Omega^n,\mathcal{F},\mathbb{P})$ . However, defining the probability space is often skipped, and the domain of the $X_i$ isn't always denoted either. If I happen to stumble upon such a case where I can't somehow deduce which is correct, is there a difference between the two cases, and which should I assume it is, then?","['probability-theory', 'random-variables']"
3682728,Tiling a rectangle with both rational and irrational sided squares,"We define a 'tiling of rectangle with squares' as the process of dividing the rectangle into finitely many squares so that they do not overlap and cover up the whole rectangle. Here is my question: Is there a rectangle with such a square tiling that contains squares of both rational and irrational side lengths? The following statement is well-known: A rectangle can be tiled with squares if and only if the ratio of its side lengths is a rational number. The proof of this statement can be found in Proofs from THE BOOK . From this we can assume the sides of such a rectangle, if it exists, to be 1 and p/q , p and q being integers. However, I really have no idea how to move further from this point. Hope you could help me with this problem. Thanks!","['number-theory', 'geometry', 'combinatorial-geometry', 'combinatorics', 'tiling']"
3682739,"Does a strictly increasing, differentiable function that converges to 0 with an unbounded slope necessarily behave as a power function?","Suppose $f:\mathbb{R}_+\rightarrow \mathbb{R}_+$ satisfies: $f$ is continuous, $f(0)=0$ , $f$ is differentiable on $\mathbb{R}_{++}$ with $f'(x)>0$ , and $f'(0)=\infty$ . A canonical example of such a function would be $ax^b$ for $a>0$ , $b\in(0,1)$ . My question is, do all functions satisfying the above conditions also satisfy $f\sim ax^b$ as $x\rightarrow 0$ for some $a>0$ , $b\in(0,1)$ ? Here, I use $\sim$ in the sense of $\lim_{x\rightarrow0}ax^b/f(x) = 1$ . My gut says the answer should be no, but I've been unable to prove it/find any counter-examples.","['limits', 'real-analysis']"
3682803,Pigeonhole principle of 81 numbers [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Please someone can help me to prove this. We have a 9x9 square panel with some arrangement of the numbers 1... to 81 in it.
Prove that there are at least two neighboring numbers the differnce between them bigger than 6 (horizontally or vertically) prove that???","['pigeonhole-principle', 'complex-numbers', 'discrete-mathematics']"
3682831,How is $\mathbb{F}_2^4$ related to an $8$ element set?,"I am trying to understand the part of this answer explaining why $A_8\cong\mathrm{PSL}_4(\mathbb{F}_2)$ . Let $|X|=8$ . We can form the free vector space $\mathbb{F}_2X=\mathbb{F}_2^8$ with the usual dot product and consider the subquotient $v^{\perp}/v$ where $v=(1,\cdots,1)$ . Or equivalently, the vector space $(\mathcal{P}(X),\Delta)$ where $\mathcal{P}(X)$ is the power set and $\Delta$ is symmetric difference with bilinear form $|A\cap B|\bmod 2$ , then consider $X^{\perp}/X$ . This is a $6$ -dim vector space with subset $Q=\binom{X}{4}$ of unordered quadruples (mod complement) with $\frac{1}{2}\binom{8}{4}=35$ elements. The action of $S_8$ on $X$ induces one on $Q$ . On the other hand, the set of $2$ -subspaces of $\mathbb{F}_2^4$ , i.e. the Grassmanian $\mathrm{Gr}_2(\mathbb{F}_2^4)$ , also has $35$ elements, it presumably has some kind of embedding in $\Lambda^2\mathbb{F}_2^4$ (which mods by $x\wedge x=0$ , so is $6$ -dim spanned by $e_i\wedge e_j$ ), the projectivized form is called the Klein quadric (which is presumably the same because $\mathbb{F}_2$ ), and carries an action of $\mathrm{PGL}_2(\mathbb{F}_2)$ (which is the same thing as $\mathrm{PSL}_2(\mathbb{F}_2$ ) and $\mathrm{GL}_4(\mathbb{F}_2)$ and $\mathrm{SL}_4(\mathbb{F}_4)$ because again, $\mathbb{F}_2$ ). Supposedly there is a bijection $Q\leftrightarrow\mathrm{Gr}_2(\mathbb{F}_2^4)$ which makes the action of $A_8$ and $\mathrm{PSL}_4(\mathbb{F}_2)$ match, but I'm not seeing what it's supposed to be. What is this bijection, or in other words how is $\mathbb{F}_2^4$ related to $X$ ? Presumably there is some kind of functorial construction of $\mathbb{F}_2^4$ out of $X$ or vice-versa. Or are some arbitrary choices necessary? From there, maybe I can see how $X=\mathbb{P}(\mathbb{F}_7)$ makes $\mathrm{PSL}_2(\mathbb{F}_7)$ relevant, and what the planes and lines business is in the so-called Klein correspondence. Also - why $\mathrm{PSL}_2(\mathbb{F}_7)$ not $\mathrm{PGL}_2(\mathbb{F}_7)$ ? Why $A_8$ not $S_8$ ? Also curious if $\mathrm{Aff}_3(\mathbb{F}_2)=\mathbb{F}_2^3\rtimes\mathrm{GL}_3(\mathbb{F}_2)$ fits in somewhere, since it is a subgroup of both $S_8$ (with $X=\mathbb{F}_2^3$ ) and $\mathrm{PGL}_4(\mathbb{F}_2)$ . Edit. Some further thoughts. Given a six-element set $Y$ , we can take $Y^{\perp}/Y$ from $(\mathcal{P}(Y),\Delta)$ to get $S_6\to\mathrm{Sp}_4(\mathbb{F}_2)$ (with some set-theoretic skew form I can't remember), which is an isomorphism. We can embed $S_6$ in $A_8$ (multiply the odd elements of $S_6$ by $(78)$ ) and try to extend the action to $X^{\perp}/X$ , but it doesn't seem like $Y^{\perp}/Y$ embeds naturally into it in the first place. The sum $1+28+35$ seems to show up in places. First off, in the sizes of the $S_8$ -orbits of $X^{\perp}/X$ , in which case the sum is $\binom{8}{0}+\binom{8}{2}+\frac{1}{2}\binom{8}{2}$ . Secondly, it appears in the $\mathrm{GL}_4(\mathbb{F}_2)$ -orbits of $\Lambda^2\mathbb{F}_2^4$ , comprised of elements of the form $a\wedge b+c\wedge d$ and $a\wedge b$ . Thirdly for some reason it seems to show up in $\mathfrak{h}_3(\mathbb{F}_2)$ , the $3\times 3$ Hermitian matrices over $\mathbb{F}_2$ , as those nonzero elements with determinant $0$ or $1$ (so, presumably as the $\mathrm{GL}_3(\mathbb{F}_2)$ -orbits). I can detail how I calculated the sizes of all these orbits if someone wants. Is there some relationship between $\mathfrak{h}_3(\mathbb{F}_2)$ and $\Lambda^2\mathbb{F}_2^4$ ? Note $\Lambda^2\mathbb{F}_2^4$ naturally coincides with the diagonal-free $4\times4$ Hermitian matrices, say $\mathfrak{h}_4'(\mathbb{F}_2)$ ; is there a relationship between $\mathfrak{h}_3(\mathbb{F}_2)$ and $\mathfrak{h}_4'(\mathbb{F}_2)$ ? I imagine if there is, it has something to do with the exceptional homomorphism $\mathrm{SO}_4\to\mathrm{SO}_3$ . (Note Hermitian and skew-Hermitian are equivalent over $\mathbb{F}_2$ ). There is a Hodge-star operator $\ast$ on $\Lambda^2\mathbb{F}_2^4$ ; on $\mathrm{Gr}_2(\mathbb{F}_2^4)$ it replaces a $2$ -subspace with its orthogonal complement. There are three $2$ -subspaces which are fixed points, $\mathrm{span}\{e_i+e_j,e_k+e_\ell\}$ for the three partitions $\{\{i,j\},\{k,\ell\}\}$ of $\{1,2,3,4\}$ . The 3D invariant subspace $(\Lambda^2)^{\ast}$ is spanned by the three linearly independent elements $e_i\wedge e_j+e_k\wedge e_\ell$ , and $\ast$ acts trivially on $\Lambda^2/(\Lambda^2)^{\ast}$ . Is there some corresponding involution $\ast$ on $X$ or $\mathfrak{h}_3(\mathbb{F}_2)$ ? I'm aware there's some way to set up a vector space $\mathbb{F}_2^4$ using ""even"" and ""odd"" subgroups of $A_8$ , but while this seems like a useful general trick to know I was hoping for something a bit less ""pull-up-by-bootstraps"" than looking at subgroups.","['exceptional-isomorphisms', 'grassmannian', 'abstract-algebra', 'group-theory', 'group-actions']"
3682892,Spectral description of the Kronecker factor,"$\newcommand{\set}[1]{\{#1\}}$ $\newcommand{\mc}{\mathcal}$ $\newcommand{\Z}{\mathbb Z}$ $\newcommand{\C}{\mathbb C}$ $\newcommand{\R}{\mathbb R}$ Definitions Let $(X, \mc X, \mu)$ be probability space and $T:X\to X$ be an invertible measure preserving transformation.
Let us write $L^2$ to mean $L^2(X, \mc X, \mu)$ .
Let $U_T$ be the associated Koopman operator on $L^2$ .
We may write $Tf$ in place of $U_Tf$ . We say that $\lambda\in \C$ is an eigenvalue of the measure preserving system $(X, T)$ if there is a nonzero function $f\in L^2$ such that $Tf=\lambda f$ .
Given an eigenvalue $\lambda$ , we say that $f\in L^2$ is an eigenfunction corresponding to $\lambda$ if $Tf=\lambda f$ .
Let $\mc X_1$ denote the $\sigma$ -algebra generated by the set of all the eigenfunctions.
Let $H_{pp}$ be the closure of the span of all the eigenfunctions. We say that $f\in L^2$ is almost periodic if the closure of $\set{T^nf:\ n\in \Z}$ is compact in $L^2$ .
It is shows in Proposition 2 of this blog post of Tao , assuming ergodicity of $T$ , that $f$ is almost periodic if and only if $f$ is measurable with respect to $\mc X_1$ .
In other words, $f$ is almost periodic if and only if $f\in L^2(X, \mc X_1, \mu)$ . Question Exercise 5 in this blog post of Tao asks to show the following. Exercise. Assume $T$ is $\mu$ -ergodic and $f\in L^2$ be given. Then $f\in L^2(X, \mc X_1, \mu)$ if and only if $f$ is in $H_{pp}$ . (I do not think ergodicty is required but right now I am content with the ergodic case.) The hint given is that first one may use the fact that $f\in L^2(X, \mc X_1, \mu)$ if and only if $f$ if almost periodic and also use the fact that the product of two eigenfunctions is also an eigenfunction.
I am unable to see how this hint helps solve the question at hand.
Independent of the hint, I thought of using the spectral theorem to push the information to $\mathbb T=\R/\Z$ .
The almost periodicity of $f$ in $L^2$ gives that the constant function $1$ is almost periodic in $L^2(\mathbb T, \nu)$ , where $\nu$ is the spectral measure corresponding to $f$ .
However, I couldn't make any progress using this.","['measure-theory', 'ergodic-theory', 'functional-analysis']"
3683108,Why does $\sum \frac{1}{n^{1 + \epsilon}}$ converge?,"The proof that the infinite sum of $\frac{1}{n}$ diverges seems to have a fair amount of breathing room.  We group successive terms in quantities of increasing powers, starting with $\frac{1}{2}$ , then $\frac{1}{3} + \frac{1}{4}$ , then the next four terms, then the next eight terms, etc., and note that each of the groups is greater than or equal to $\frac{1}{2}$ , and adding $\frac{1}{2}$ forever approaches $\infty$ . As extra credit for this proof, each group after the first is strictly greater than $\frac{1}{2}$ , so the divergence actually occurs faster.  Furthermore, we didn't even need the terms to be that large; adding $\frac{1}{1,000,000}$ forever would also approach $\infty$ .  Why then, given this generous cushion in the proof, is it the case that $\frac{1}{n^{1 + ε}}$ for some tiny ε converges?  Why is the power of $n$ so fragile to nudges in the positive direction given how firmly $\frac{1}{n}$ seemed to diverge?","['summation', 'infinity', 'sequences-and-series', 'limits', 'convergence-divergence']"
3683136,"Examples of non-continuous, non-piecewise-constant, idempotent map?","So a projection $P$ is a linear map such that $P^2 = P$ . If we don't require linearity, then there are other examples of functions $f$ such that $f^2 = f$ . For example, the floor and ceiling functions. If $f: \mathbb{R} \to \mathbb{R}$ and we require continuity, it seems that the image is a closed interval and $f(x)=x$ for all $x$ in the image. I'm wondering if there are any examples of idempotent maps that are not continuous but also not piecewise constant?","['functions', 'real-analysis']"
3683224,Problem about $F_\sigma$ and $G_\delta$ sets,"Define a set to be bivalent iff it's both $F_\sigma$ and $G_\delta$ . Let $X$ be a $G_\delta$ -space (i.e. all closed sets are $G_\delta$ sets). Let $G$ and $H$ be disjoint $G_\delta$ sets. Prove that there exists a bivalent set $B$ disjoint from $H$ , such that $G\subset B$ . Note : if the exercise just asked for $B$ to be an $F_\sigma$ , the proof would be immediate (just take the complement of $H$ , which is $F_\sigma$ .","['general-topology', 'descriptive-set-theory']"
3683256,"When converting a Riemann sum to an integral, how does one decide the bounds of the converted Riemann sum?","Context problem: $$ \lim_{n\to \infty} \frac{1}{n} \sum_{r=1}^{r=2n} \frac{r}{\sqrt{r^2+n^2}}$$ So the thing messing me up is the '2n' in the upper of sum, I've already figured out that the function which this rienman integral is ( $ \int \frac{x}{\sqrt{1+x^2}}$ )","['integration', 'calculus']"
3683283,"Show that the tangent plane of the cone $z^2=x^2+y^2$ at (a,b,c)$\ne$0 intersects the cone in a line","My attempt: Let $f(x,y,z)=x^2+y^2-z^2$ and calculate the total derivative $Df(a,b,c)=(2a,2b,-2c)$ . The tangent plane is $$g(x,y,z)=f(a,b,c)+Df(a,b,c)(x-a,y-b,z-c)=2ax+2by-2cz-a^2-b^2+c^2$$ Then let $g(x,y,z)=f(x,y,z)$ to find the intersction got $$(x-a)^2+(y-b)^2-(z-c)^2=0$$ Does this equation means the tangent plane intersects the cone in a line?",['multivariable-calculus']
3683338,Show that the tangent plane of the saddle surface $z=xy$ at any point intersects the surface in a pair of lines.,"My attempt: Let $f(x,y,z)=xy-z$ , (a,b,c) $\in$ the saddle surface, and calculate the total derivative $Df(a,b,c)=(b,a,-1)$ Then the tangent plane is $$g(x,y,z)=f(a,b,c)+Df(a,b,c)(x-a,y-b,c-z)=bx+ay-z+ab$$ Set $g(x,y,z)=f(x,y,z)$ to get the intersection got $bx+ay-xy+ab=0$ . 
I know that the equation can be written as $$bx+ay-xy+ab=bx-ay-z-c=0$$ But I have no idea to get a pair of lines which intersects the saddle surface.",['multivariable-calculus']
3683360,Basic question on automatic differentiation. Why we compute jacobian-vector product,"I am struggling a bit with automatic differentiation. Let us focus on the forward mode. There are two components of the method I can't put together: The ""seeds"" and the vector $v$ that multiplies the jacobian. Let's say we have a function $f(x): \mathbb{R}^n \rightarrow \mathbb{R}^m$ which is a composite function like $$
f = f^L \circ f^{L-1} \circ \dots \circ f^{1}
$$ we want to find the Jacobian matrix $J$ of $f$ with respect to $x$ . Then with the chain rule we can write $$
J = J^L J^{L-1} \dots J^{1} 
$$ now in practice I read that the AD algorithm does not actually computes $J$ but the product $Jv$ where $v$ is a vector. (I don't get why at the moment). From this blog post I understand that one has to provide the ""seeds"" of the derivatives. So I thought that $v$ are the seeds. Is that correct? If yes, to me it makes sense to always use seeds that are equal to $1$ . Is there a reason why sometimes it makes sense to use seeds not equal to $1$ ?","['derivatives', 'algorithms']"
3683364,Segre map is an embedding,"I'd like to show that there exists an embedding $P^m \times P^n \to P^{(m+1)(n+1)-1}$ , where $P^i$ denotes the real projective space. I found the Segre map $$\Sigma_{m,n}:P^m \times P^n \to P^{(m+1)(n+1)-1}$$ $$[x_0:\cdots: x_m] \times [y_0:\cdots:y_n] \to [x_0y_0: x_0y_1: \cdots: x_iy_j:\cdots: x_my_n].$$ We define $[z_{00}:z_{01}:\cdots:z_{ij}:\cdots:z_{mn}]:= [x_0y_0: x_0y_1: \cdots: x_iy_j:\cdots: x_my_n]$ for $[x_0:\cdots: x_m] \times [y_0:\cdots:y_n]\in P^m \times P^n$ . It is easy to see the image in matrix form \begin{equation*}
    \begin{bmatrix}
    z_{00} & \cdots & z_{0n} \\
    \vdots & \vdots & \vdots \\
    z_{m0} & \cdots & z_{mn} 
    \end {bmatrix}
    =
    \begin{bmatrix}
    x_{0} \\
    \vdots \\
    x_{m}  
    \end {bmatrix}
    \begin{bmatrix}
    y_{0}: \cdots : y_{n} 
    \end {bmatrix}.
\end{equation*} Let $z=[z_{00}:z_{01}:\cdots:z_{ij}:\cdots:z_{mn}]$ be an element of the image of $\Sigma_{m,n}$ and let $(a,b)\in P^m \times P^n$ such that $\Sigma_{m,n}(a,b)=z$ . WLOG we can assume $a_0=b_0=z_{00}=1$ . then $b_j=z_{0j}$ for all $0\leq j \leq n$ and $a_i=z_{i0}$ so $a,b$ are uniquely determined and this map is bijective onto the image. Is this enough to conclude that we have an embedding? Is $(m+1)(n+1)-1$ the smallest number for which we can have an embedding of $P^m\times P^n$ ?","['algebraic-geometry', 'projective-geometry', 'projective-space']"
3683396,Information/references/examples on fields $\mathbb R^3 \to \mathbb C^3$ with divergence and curl free real and imaginary parts,"In the course of some physical considerations I came across a complex vector field $$ \mathbf u = \mathbf v + i \mathbf w,  $$ with \begin{align}
\mathbf v:& \mathbb R^3\to \mathbb R^3\\
\mathbf w:& \mathbb R^3\to \mathbb R^3
\end{align} and the special propert, that it has a divergence-free imaginary and
curl free real components, that means \begin{align}
 \vec{\nabla}\times \mathbf v & = \mathbf 0 \tag{1}\\
 \vec{\nabla}\cdot\mathbf w & = 0 \tag{2}
\end{align} In my attempts to better understand and interpret the quantitiy described by this field, I started to wonder if: Question 1: This property has a special name/term in complex vector analysis. Question 2: If there are any important prominent examples of such fields. Question 3: If there are other properties that follow as a consequence of  (1) and (2). Question 4: If anyone can hint me at literature where such fields are investigated. I would be very grateful for any hints at this. I would hope for answers like those to this question .","['differential-geometry', 'vector-fields', 'complex-analysis', 'vector-analysis', 'terminology']"
3683445,Distributing values into a histogram,"Let $b_1(n), b_2(n), \ldots, b_k(n)$ be the height of the $k$ bars of a fixed-width histogram with $n$ data points.  Assume $k$ is constant, and $n\geq k$ is an integer which is increasing as we collect new data. Let $d_n$ be the value received at time $n$ .  I would like to calculate the height of $b_i(n)$ for each $i = 1, 2, \ldots, k$ , with the data uniformly scaled to fit the width. For example in case $k = 3$ and $n=6$ , then each bar $b_i(6)$ will consist of an average of two data values: $$b_1(6) = \frac{1}{2}(d_1 + d_2), \ \ \ b_2(6) = \frac{1}{2}(d_3 + d_4),\ \ \text{and }\  b_3(6) = \frac{1}{2}(d_5 + d_6).$$ Continuing the example with $k=3$ , if $n=7$ , I think we should set: $$b_1(7) = \frac{3}{7}d_1+\frac{3}{7}d_2 + \frac{1}{7}d_3 $$ $$b_2(7) = \frac{2}{7}d_3+\frac{3}{7}d_4 + \frac{2}{7}d_5 $$ $$b_3(7) = \frac{1}{7}d_5+\frac{3}{7}d_6 + \frac{3}{7}d_7 $$ The problem is to find a general formula to calculate $b_i(n+1)$ as a function of the constant $k$ and the values $n, d_1, \ldots d_{n+1}$ .","['combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3683465,Evaluating $\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)}$,"I'm in a little struggle with this limit, can anyone help me, please? $$\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)}$$ I tried to use the logarithm to then use L'Hospital's rule but I got stuck here: $\ln(L)=\lim_{x \to \frac{\pi}{6}}{[\tan(\frac{\pi}{6}-x)\ln(1-2\sin(x))]}$ Thank you!","['limits', 'calculus']"
3683543,Evaluating $\int _0^{\infty }\frac{e^{-ax^m}-e^{-bx^n}}{x^p}\:dx$,"I was able to evaluate this using Feynman's trick and managed to find a closed form though it has strict conditions that make this integral converge but the main thing is how can one evaluate this using other techniques? i find it very hard to come up with anything else, this time ill checkmark the best approach in my opinion. My attempt. To find the closed form of the integral i heavily relied on the following identity, $$\int _0^{\infty }x^ne^{-ax^b}\:dx=\frac{\Gamma \left(\frac{n+1}{b}\right)}{b\:a^{\frac{n+1}{b}}}$$ Now resuming on the integral. $$I\left(a\right)=\int _0^{\infty }\frac{e^{-ax^m}-e^{-bx^n}}{x^p}\:dx$$ $$I'\left(a\right)=-\int _0^{\infty }x^{m-p}\:e^{-ax^m}\:dx$$ $$I'\left(a\right)=-\frac{\Gamma \left(\frac{1-p}{m}+1\right)}{m\:a^{\frac{1-p}{m}+1}}$$ $$\int _{\infty }^aI'\left(a\right)\:da=-\frac{\Gamma \left(\frac{1-p}{m}+1\right)}{m}\int _{\infty }^aa^{\frac{p-1}{m}-1}\:da$$ We can also use the same identity we used earlier to calculate $I\left(\infty \right)$ so, $$I\left(\infty \right)=-\int _0^{\infty }x^{-p}e^{-bx^n}dx=-\frac{\Gamma \left(\frac{1-p}{n}\right)}{n\:b^{\frac{1-p}{n}}}$$ Resuming on the original expression we now have: $$I\left(a\right)+\frac{\Gamma \left(\frac{1-p}{n}\right)}{n\:b^{\frac{1-p}{n}}}=-\left(\frac{1-p}{m}\right)\frac{\Gamma \left(\frac{1-p}{m}\right)}{m}\left(\frac{m}{p-1}\:a^{\frac{p-1}{m}}\right)$$ $$I\left(a\right)=\frac{\Gamma \left(\frac{1-p}{m}\right)}{m}\:a^{\frac{p-1}{m}}-\frac{\Gamma \left(\frac{1-p}{n}\right)}{n}\:b^{\frac{p-1}{n}}$$ Meaning that: $$\boxed{I\left(a\right)=\int _0^{\infty }\frac{e^{-ax^m}-e^{-bx^n}}{x^p}\:dx=\frac{\Gamma \left(\frac{1-p}{m}\right)}{m}\:a^{\frac{p-1}{m}}-\frac{\Gamma \left(\frac{1-p}{n}\right)}{n}\:b^{\frac{p-1}{n}}}$$ I tried using this to calculate for some values and in all cases it agrees with mathematica even when the integral diverges. Noticed immediately after posting that i couldve bring the $x^p$ up and use the same identity not having to go through all of Feynman's trick, -.- at least its more fancy.","['integration', 'improper-integrals', 'definite-integrals', 'real-analysis', 'calculus']"
3683647,Conditions for a vector field to be a gradient,"Consider a vector field $F : \mathbf{R}^d \to \mathbf{R}^d$ . I want to know standard conditions on $F$ which guarantee that $F$ is a gradient, i.e. that $F = \nabla V$ for some function $V$ . I know that gradient fields (sufficiently smooth, etc. etc.) all satisfy $$\frac{ \partial F_i }{ \partial x_j} = \frac{ \partial F_j }{ \partial x_i} \quad \text{for all } i, j$$ and I have it in my mind that this is also a sufficient condition (or pretty close to it), but I don't really trust myself on this, and have no reference to this effect. Is this the case? Is there another sufficient condition? What is a good reference for this sort of thing?","['vector-fields', 'calculus', 'reference-request', 'differential-geometry']"
3683668,The angle between two subspaces of $\mathbb R^n$ can not be too small,"Notations. Let $A$ and $B$ be two subspaces of $\mathbb R^{2k}$ of dimensions $k$ . Let's call $p_A^\perp$ the orthogonal projection onto $A$ . Let's define two quantities: $$\psi_1(A,B)=\inf_{b\in B\setminus\{0\}} \vert\sin\widehat{(b,p_A^\perp(b))}\vert$$ and $$\psi_\infty(A,B)=\sup_{b\in B\setminus\{0\}} \vert\sin\widehat{(b,p_A^\perp(b))}\vert.$$ The question. Assume that it exists a constant $c$ such that $\psi_\infty(A,B)\geqslant c$ ; There exist $b_1,\ldots,b_k\in B$ linearly independent such that $\widehat{(b_i,b_j)}\geqslant \pi/4$ if $i\ne j$ , and $$\forall j\in\{1,\ldots,k\},\quad \vert\sin\widehat{(b_j,p_A^\perp(b_j))}\vert \geqslant c.$$ Let's also assume that $A\cap B=\{0\}$ . Can we prove that for all $c$ sufficiently small, $$\psi_1(A,B)\geqslant c'$$ where $c'$ is a constant depending on $c$ ? Remarks. This question is kind of linked to this other question . Any hints or references would be much appreciated.","['angle', 'linear-algebra', 'geometry', 'vector-spaces']"
3683731,Solving $\arctan(x)+\arctan(2x)=\frac{\pi}{3}$. Why do I get an extra root?,"I have this equation $$\arctan(x)+\arctan(2x)=\frac{\pi}{3}$$ that ends up with two roots but when I graph the equation online the graph only intercepts the x-axis once. So where is my problem? $$\begin{align}
\arctan(x)+\arctan(2x) &=\frac{\pi}{3} \tag{1}\\
\tan(\arctan(x)+\arctan(2x)) &=\tan\left(\frac{\pi}{3}\right) \tag{2} \\
\tan(\arctan(x)+\arctan(2x)) &=\sqrt3 \tag{3} \\
\frac{\tan(\arctan(x))+\tan(\arctan(2x))}{1-\tan(\arctan(x)\cdot\arctan(2x))} &=\sqrt3 \tag{4} \\
\frac{3x}{1-2x^2}&=\sqrt3 \tag{5} \\
3x &=\sqrt3\cdot(1-2x^2) \tag{6} \\
3x &=\sqrt3-2\sqrt3x^2 \tag{7} \\
2\sqrt3x^2+3x-\sqrt3 &=0 \tag{8}
\end{align}$$ Now I look for the roots using $$b^2-4ac=9-(-4\cdot2\sqrt3\cdot\sqrt3)=33 \tag{9}$$ $$x_1= \frac{-3+\sqrt{33}}{4\sqrt3} \tag{10}$$ $$x_2= \frac{-3-\sqrt{33}}{4\sqrt3} \tag{11}$$ I hope this is right (not sure). But If it is, I don't understand why graphing this function online gives me only one root, which corresponds to $x_1$ . I also used a website allowing to solve trigonometric equations on the fly in order to check my answer and same result there: their answer is unique and corresponds to my $x_1$ only.
Can someone explain this to me please? Thanks for your help.","['trigonometry', 'graphing-functions', 'roots']"
3683831,Meaning of bold capital D,"I would like to know the (asymptotic) properties of a Kernel Density Estimation. As a result, I was reading an article from Nadaraya (1964) . In this article, a bold capital D ( $\textbf{D}$ ) is used and apparently, it is assumed that the reader knows what this means. However, I am a bit puzzled. From reading on the internet, it usually refers to the derivative, but that seems odd to me in this particular case. To me, it seems more likely that is refers to the variance. (so maybe it comes from [standard] Deviation?) What is meant by the $\textbf{D}$ ? Is this a common notation? Here is the important passage of the article, with the capital D highlighted by the red rectangle:","['statistics', 'probability-distributions', 'probability-theory']"
3683848,"Could you suggest basic mathematics textbooks (calculus, linear algebra) that are written in an intuitive manner?","For instance, I really loved reading the book "" Div, Grad, Curl, and All That"" by H.M.Schey. I would like texts closely written in that particular style.","['reference-request', 'calculus', 'linear-algebra', 'education', 'soft-question']"
3683851,Grimm's Weak Conjecture,"On Wikipedia it says that the following weaker version of Grimm's conjecture is also still open: ""A product of $k$ consecutive composite numbers has $k$ pairwise distinct prime factors."" Is it true, that this is still open or is there already a proof for it? Motivation My motivation to this question comes from factorization theory: Let $H$ be a monoid, i.e. a commutative cancellative semigroup with identity element. An element $a \in H$ is called a strong atom , if it is an atom (i.e. irreducible) and for every $k \in \mathbb{N}$ the only facorization of $a^k \in H$ into atoms is $a\cdot...\cdot a$ (where $a$ appears $k$ times). Let $\text{Int}(\mathbb{Z}) = \{ f \in \mathbb{Q}[x] \mid f(\mathbb{Z}) \subseteq \mathbb{Z} \}$ be the ring of integer-valued polynomials and consider the multiplicative monoid $H = \text{Int}(\mathbb{Z}) \setminus \{0 \}$ of non-zero elements. It is known that the factorization behaviour of this monoid is very rich. For instance, for every list of integers $n_1,...,n_k \geq 2$ there exists $f \in H$ such that $f$ has exactly $k$ different (up to order and multiplication by units) factorizations into atoms and the lengths of these factorizations are exactly $n_1,...,n_k$ . The construction for the result in the preceeding paragraph only uses a very restricted pool of polynomials and does not give much information about atoms, though. That is why one is interested in a better understanding of these smallest multiplicative bricks and considers examples: It is well-known since a long time that for $n \in \mathbb{N}$ the polynomial $\binom{x}{n} = \frac{x(x-1)...(x-n+1)}{n!} \in H$ is an atom. These so-called binomial polynomials are of particular interest, because taken together the form a $\mathbb{Z}$ -module basis of $\text{Int}(\mathbb{Z})$ . It is conjectured that the binomial polynomials are strong atoms. This is already known for several special cases. A particularly easy case is when $n$ is prime.
More generally, it turns out that the distribution of prime numbers between $\max \{p \in \mathbb{P} \mid p \leq n \}$ and $n$ is crucial for the proof of the conjecture. It should be not too hard to see that it follows from Grimm's conjecture. I also have the suspicion that it implies Grimm's weak conjecture as stated above. Thank you very much for your help!","['number-theory', 'conjectures', 'elementary-number-theory']"
3683883,How to get the derivative based on the function?,"Based on $f(x) = x^2$ , we know $f'(x) = 2x$ . If $x = y^2$ Then $f(y) = (y^2)^2 = y^4$ , and $f'(y) = 4y^3$ . My question is if we only know $f'(x) = 2x$ $x = y^2$ How to get $f'(y) = 4y^3$ ? Any hint or formula will be helpful. Thanks",['derivatives']
3683886,"basic trig: How to find angle of a parallelogram inside a box, when box dimensions and 1 dimension of parallelogram is known?","First-time poster. Essentially, I am building an angled leg for a desk, and I need to know the angles and lengths for cutting. I am using wood that is 9"" wide, and with the help of software, I have built a construction model based on my project requirements.  There are two critical points of intersection between the box and the rectangle - the pivot on the bottom left of the box (as seen correctly in the photo) and the top right corner of the box (NOT DISPLAYED CORRECTLY IN THE PHOTO.  I have not yet figured out how to merge line:point in fusion 360 while maintaining the 9"" parallel relationship of my workpiece).  These are my known variables. Unknown variables:  Once the rectangle is cut to fit in the box, I will have a parallelogram.  How do I find the angles of the parallelogram and the length of all sides?  I am asking in this forum so that I can learn another (i.e. fail-proof) approach to solving...  and just in case I cannot find an answer in the fusion 360 forum.  Thanks!",['trigonometry']
3683921,Is the function $(1+x)^{\frac{1}{x}}$ differentiable at $x=0$?,Is the function $(1+x)^{\frac{1}{x}}$ differentiable at $x=0$ ? Would the expression below denote its derivative? $$  \lim_{x \to 0}  \lim_{h \to 0 } \frac{ (1+x+h)^{\frac{1}{x+h}} - e}{h}$$,"['calculus', 'derivatives']"
3683957,Normal subgroups from generators,"I am reading Coxeters ""Generators and Relations for discrete goups"". There is something in the very begin where I am struggling: A group $G$ shall be defined by a set of $s$ relations $g_k$ between its $m$ generator elements $\{S_1,\cdots,S_m\}$ and the identity element $E$ \begin{align}
 g_1(S_1,\dots,S_m) & = E \\
 g_1(S_2,\dots,S_m) & = E \\
 \cdots \tag{1}\\
 g_s(S_2,\dots,S_m) & = E \\ 
\end{align} and the group $G'$ shall be defined by the set of generators $\{R_1,\cdots,R_m\}$ which fulfill the same relations (1) and another $r$ relations: \begin{align}
 g_1(R_1,\dots,R_m) & = E \\
 g_1(R_1,\dots,R_m) & = E \\
 \cdots \tag{2}\\
 g_s(R_1,\dots,R_m) & = E \\
\cdots \\ 
 g_{s+r}(R_1,\dots,R_m) & = E \\
\end{align} Now obviously the map $$ S_i \mapsto R_i \;\;\; (i=1,...,m)$$ defines a group homomorphism from $G\to G'$ and all group elements $$ g_k(R_1,\dots,R_m)  \;\;\; (k=s+1,...,s+r)\tag{3}$$ correspond to the identity element $E$ in $G'$ . To me it seems that these elements form the kernel of the group homomorphism. So I don't understand the next step in the argument in the book, it says ""the kernel of the homomorphism is the normal subgroup $$ N \simeq \{W^{-1}g_k(S_1,\dots,S_m) W\} \;\;\; (k=s+1,...,s+r) \tag{4}$$ where $W$ runs through all the elements of $G$ . In fact, $N$ is the smallest normal subgroup of $G$ that contains the elelemts (3), and it follows that $$ G'\simeq G/N.""$$ I somehow can't wrap my head around that conjugation loop over all elements how does it generate the normal subgroup. I expect that it must be connected with the circumstance that iff $N$ is normal then \begin{align} 
WN & = NW\\
W^{-1}NW & = N = WNW^{-1}
\end{align} must hold for all $W\in G$ . But I still can't see clearly how it connects to construction (4). Possibly its very simple but I am just hanging here. Would be grateful for any hints.","['finite-groups', 'combinatorial-group-theory', 'normal-subgroups', 'discrete-mathematics', 'group-theory']"
3684035,"What axioms can be added to $S,K$ combinator algebra without making it collapse into triviality?","My understanding is that if you start with the free magma on two generators (call them $S$ and $K$ ) and then take a quotient with respect to the usual $S$ and $K$ equivalence rules ( $Sfgx = fx(gx)$ and $Kxy = x$ ), you get the usual $S,K$ combinator algebra. (I think there may be something I don't get about $\eta$ equivalence and incompleteness with respect to $\lambda$ -calculus, but that's another story.) What happens when you add other axioms that don't ordinarily belong, such as commutativity, associativity (perhaps limited), right inverse, things like $K^n = I = SKK$ or $S^n = I$ for large $n$ , and so on?  Are there any interesting systems like this on two generators, especially finite ones, that have nontrivial models? I can't visualize this and I'm not sure I even know how to think about the question.","['combinatory-logic', 'lambda-calculus', 'abstract-algebra']"
3684050,Is it possible to evaluate $\iiint \frac{2x^2+z^2}{x^2+z^2} dxdydz$ using cylindrical coordinates instead of spherical?,"I know that this integral is way easier with spherical coordinates, but I would like to understand my mistakes; evaluate $$\iiint_D \frac{2x^2+z^2}{x^2+z^2} dxdydz$$ Where $D=\{(x,y,z)\in\mathbb{R}^3 \ \text{s.t.} \ 1 \leq x^2+y^2+z^2 \leq 4, \ x^2-y^2+z^2 \leq 0\}$ . Letting $x=\rho \cos \theta$ , $y=y$ and $z=\rho \sin \theta$ it follows that $$\iiint_E (2\cos^2 \theta+\sin^2 \theta)\rho d\rho dyd\theta=\iiint_E (1+\cos^2 \theta)\rho d\rho dyd\theta$$ Where $E=\{(\rho,y,\theta)\in\mathbb{R}^3 \ \text{s.t.} \ 1 \leq \rho^2+y^2 \leq 4, \rho^2 \leq y^2\, \rho \geq 0, 0 \leq \theta < 2\pi\}$ . The point is that now I have a lot of conditions on $y$ , because $\sqrt{1-y^2} \leq \rho \leq \sqrt{4-y^2}$ , $-y\leq\rho\leq y$ and $\rho \geq 0$ . From the existence conditions of the roots we get $-1 \leq y \leq 1$ and $-2 \leq y \leq 2$ , so it follows that $-1 \leq y \leq 1$ . So it remains to discuss the cases of $\max\left\{\sqrt{1-y^2},-y\right\} \leq \rho$ and $\rho \leq \min\left\{y,\sqrt{4-y^2}\right\}$ ; it is $y \leq \sqrt{4-y^2}$ for $-1 \leq y \leq 1$ and it is always $\sqrt{1-y^2} \leq \sqrt{4-y^2}$ , we have that $$\max\left\{\sqrt{1-y^2},-y\right\}=\begin{cases} -y, \ \text{if} -1 \leq y \leq -\frac{1}{\sqrt2} \\ \sqrt{4-y^2}, \ \text{if} \ -\frac{1}{\sqrt2} \leq y \leq 1  \end{cases}$$ So I end up with $$\iiint_E (1+\cos^2 \theta)\rho d\rho dyd\theta=\int_0^{2\pi} \left(\int_{-1}^{-\frac{1}{\sqrt2}} \left(\int_{-y}^{\sqrt{4-y^2}} (1+\cos^2 \theta)\rho d\rho\right)dy \right)d\theta+$$ $$+\int_0^{2\pi} \left(\int_{-\frac{1}{\sqrt2}}^{1} \left(\int_{\sqrt{1-y^2}}^{\sqrt{4-y^2}} (1+\cos^2 \theta)\rho d\rho\right)dy \right)d\theta$$ But I get the wrong answer, am I missing some more conditions (maybe the discussion of $\rho \geq 0$ too) or am I making other mistakes? Thanks.","['integration', 'multivariable-calculus', 'solution-verification']"
3684066,"Has anyone invented a computationally simple method to calculate the probability of at least n1-consecutive die rolls, for n2-sided die, n3-rolls?","I think I have invented a formula that allows a computer to very easily calculate the probability of at least n1-consecutive die rolls, on an n2-sided die, rolling it n3-times. For example, for a 3-sided die being rolled 4 times, the probability of at least 3 consecutive rolls being the same is: $$\frac{5}{27} \sim 0.185185$$ A 10-sided die being rolled 20 times with at least 4 consecutive rolls: $$\frac{153252438815221561}{10000000000000000000} \sim 0.0153252$$ A 20-sided die being rolled 100 times with at least 5 consecutive rolls: $$\frac{36138486362801675395834082841530471263391618236217471764311872542282160082804618163213
   4714483039586709049484138205953646876021}{63382530011411470074835160268800000000000000000
   0000000000000000000000000000000000000000000000000000000000000000000000000000000000} \sim 0.000570165$$ A 150-sided die being rolled 250 times with at least 10 consecutive rolls: $$\frac{43754862099840059340989164536890668843600275210242353790609200399332108157129005621344
   12966072844123998821529817954285993344643635690087672932957210052124849484632371945364241
   27895214917314522967829996314996884843354909465711479333655125328467972639354192054002381
   80358736161798175079981214320161396998878382245814510025222948918658240716181935621089269
   06271521762936897812401688121481273594338138312959838934408957524646299446591373165468391
   26633170992252043228387167654509762247790434963321680468677569650750302475087706401}{7026
   24848833633473725832814569816725466578833488064526319504046334823913293570611014402352480
   20759777065059629450925139424048788112889589987529495486017499085597652471999291372698929
   85667366792663663798677273390781336908763915319543616880317198383190582106072596957346831
   91403746604919433593750000000000000000000000000000000000000000000000000000000000000000000
   00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
   00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
   0000} \sim \text{6.2273433927754916$\grave{ }$*${}^{\wedge}$-18}$$ What I want to know, is there a method out there that already exists which is finding what I am already able to find?  I am really scared that I have wasted my time 'inventing' something that someone has already done before as my literature review has come up empty.  I am also a bit weary to share my method at the moment because I would ideally want to write a paper on this if this has not been done before. Edit:  You can generate tables with this easily too.  For a 6-sided die for up to 15-rolls and -consecutive: $$
\left(
\begin{array}{ccccccccccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{1}{6} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{11}{36} & \frac{1}{36} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{91}{216} & \frac{11}{216} & \frac{1}{216} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{671}{1296} & \frac{2}{27} & \frac{11}{1296} & \frac{1}{1296} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{4651}{7776} & \frac{751}{7776} & \frac{1}{81} & \frac{11}{7776} & \frac{1}{7776} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{31031}{46656} & \frac{5531}{46656} & \frac{7}{432} & \frac{1}{486} & \frac{11}{46656} & \frac{1}{46656} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{201811}{279936} & \frac{2177}{15552} & \frac{5611}{279936} & \frac{7}{2592} & \frac{1}{2916} & \frac{11}{279936} & \frac{1}{279936} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{1288991}{1679616} & \frac{270241}{1679616} & \frac{40091}{1679616} & \frac{13}{3888} & \frac{7}{15552} & \frac{1}{17496} & \frac{11}{1679616} & \frac{1}{1679616} & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{8124571}{10077696} & \frac{1827071}{10077696} & \frac{15497}{559872} & \frac{40171}{10077696} & \frac{13}{23328} & \frac{7}{93312} & \frac{1}{104976} & \frac{11}{10077696} & \frac{1}{10077696} & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{50700551}{60466176} & \frac{126731}{629856} & \frac{979}{31104} & \frac{279851}{60466176} & \frac{31}{46656} & \frac{13}{139968} & \frac{7}{559872} & \frac{1}{629856} & \frac{11}{60466176} & \frac{1}{60466176} & 0 & 0 & 0 & 0 \\
 1 & \frac{313968931}{362797056} & \frac{80043931}{362797056} & \frac{12790681}{362797056} & \frac{106217}{20155392} & \frac{279931}{362797056} & \frac{31}{279936} & \frac{13}{839808} & \frac{7}{3359232} & \frac{1}{3779136} & \frac{11}{362797056} &
   \frac{1}{362797056} & 0 & 0 & 0 \\
 1 & \frac{1932641711}{2176782336} & \frac{521516711}{2176782336} & \frac{84941711}{2176782336} & \frac{6619}{1119744} & \frac{1912811}{2176782336} & \frac{1}{7776} & \frac{31}{1679616} & \frac{13}{5038848} & \frac{7}{20155392} & \frac{1}{22674816} &
   \frac{11}{2176782336} & \frac{1}{2176782336} & 0 & 0 \\
 1 & \frac{11839990891}{13060694016} & \frac{561766711}{2176782336} & \frac{11638417}{272097792} & \frac{24761}{3779136} & \frac{715337}{725594112} & \frac{1912891}{13060694016} & \frac{1}{46656} & \frac{31}{10077696} & \frac{13}{30233088} &
   \frac{7}{120932352} & \frac{1}{136048896} & \frac{11}{13060694016} & \frac{1}{13060694016} & 0 \\
 1 & \frac{72260648471}{78364164096} & \frac{21637367221}{78364164096} & \frac{50620543}{1088391168} & \frac{563631721}{78364164096} & \frac{44059}{40310784} & \frac{12876971}{78364164096} & \frac{41}{1679616} & \frac{1}{279936} & \frac{31}{60466176} &
   \frac{13}{181398528} & \frac{7}{725594112} & \frac{1}{816293376} & \frac{11}{78364164096} & \frac{1}{78364164096} \\
\end{array}
\right)
$$","['statistics', 'fibonacci-numbers', 'probability']"
3684067,"Weak Convergence in the Space $L_1$, Why So Special?","For $1< p< \infty$ and $U\subset \mathbb{R}^d$ , and let $p'$ be the conjugate of $p$ . We say that a sequence $\{f_n\}\in L^p(U)$ converges weakly to $f\in L^p(U)$ if $$ \lim_{n\to \infty}\int_U f_n(u) g(u) d(u)=\int_U f(u)g(u) d(u) \ \ \ \  \forall g\in L^{p'}(U).  $$ Knowing a small amount of probability I think of weak-convergence as convergence in average (mentioned in these notes https://www.uio.no/studier/emner/matnat/math/MAT4380/v06/Weakconvergence.pdf Remark 1.2). My question is what is so special about $L^1-$ convergence? What are the usual ways to guarantee a sequence converges weakly somewhere in $L^1$ ?","['lp-spaces', 'functions', 'functional-analysis', 'weak-convergence']"
3684093,Dimension of kernel of Fredholm operator,"Let $X$ be a vector space and let $T\colon X\to X$ be a Fredholm operator. Fix $V$ a finite dimensional subspace of $X$ such that $T(X)+V=X$ . Define $S\colon X\oplus V\to X$ by the formula $S(x,v) = Tx+v$ . It is clear that $S$ is surjective and that $\ker S = \{(x,v) : Tx=-v\}$ . I was told that $S$ is a Fredholm operator and that $\mbox{ind}(S)=\mbox{ind}(T)$ , so of course we must have $$\dim\ker S = \mbox{ind}(T) \ \dot{=} \ \dim\ker T - \dim X/T(X)$$ but I am not able to prove it by calculating the dimension of $\ker S$ . Is there a way to do this? Thanks in advance! PS. You can assume that $X$ is Banach, or even Hilbert, and that $T$ is a bounded Fredholm operator (therefore $T(X)$ is closed).","['linear-algebra', 'functional-analysis', 'linear-transformations']"
3684104,Formal proof: induced outer measure defined via infimum of measure.,"Let $(\Omega, \mathscr{S}, \mu)$ be a measure space and $\nu$ the outer measure induced by $\mu$ . Then for any $A \subseteq \Omega$ we have $$\nu(A)=\inf(\mu(B):B\in\mathscr{S}, A\subseteq B)$$ I just don't see how this statement is equivalent to the definition for the induced outer measure that we have: $$\mu^*(A) = \inf\{\sum_n \mu(A_n): A_n\in \mathscr{S}, A\subseteq \bigcup_nA_n\}$$ Intuitively I understand that we are looking for the minimal cover of $A$ using sets from the $\sigma$ -Algebra. But I don't see a path to formally prove that the statements are in fact equivalent. How can we formally show the equivalence of these statements? Edit : Because $A \subseteq B$ it is clear that $\nu(A)\le\mu^*(A)$ as $\mu(B)$ is in the sum. Is it possible to show the reverse inequality, to complete the proof?","['elementary-set-theory', 'measure-theory', 'outer-measure']"
3684142,Solutions pairs for the equation $(4a - b) (4b - a) = 1770n$,"How many solution pairs $(a, b)$ of positive integers exist for the equation $(4a - b) (4b - a) = 1770n$ ,
  when $n$ is a positive integer? This one seemed to be pretty tough, it's from Sweden's national contest. How should one approach this?","['contest-math', 'algebra-precalculus']"
3684143,Prove that linear operator A has a nonzero kernel.,"H is a separable Hilbert space, E is an inseparable Hilbert space, A is a continuous linear operator from E to the space L (H) of continuous operators on H with an operator norm. $A:E\to L(H).$ Prove that A has a nonzero kernel. Please help","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
3684149,Notation: what's the difference between $2dvdr$(old style notation) and $dv\otimes dr +dr\otimes dv$(new style notation)?,"Gravitation by Charles Misner, Kip Throne, John Wheeler where on chapter 13 page 312 Exercise 13.2 it stated that $$ds^2 =-(1-2M/r) dv^2 + 2dvdr+r(d\theta^2 +\sin^2\theta d\phi^2)$$ (the usual First fundamental form) was an old style notation where the metric had new style notation $$ds^2 =-(1-2M/r) dv\otimes dv + dv\otimes dr +dr\otimes dv +r(d\theta\otimes d\theta +\sin^2\theta d\phi \otimes d\phi)$$ What's the difference between those two notation? Especially was $2dvdr \Rightarrow dv\otimes dr +dr\otimes dv$ instead of $2 dv\otimes dr$ purely for the symmetry of the metric, or does it has some more founding reasons, i.e. the value of $[dv,dr]$ and the corrections?","['notation', 'metric-spaces', 'differential-geometry']"
3684177,local extremum of $x\mapsto \sum_{j=1}^{\mu}g(x-x_j)^2$,"Let $x_1,x_2,\ldots,x_{\mu}\in\mathbb{R}^n$ and let $\phi:\mathbb{R}^n\to\mathbb{R}$ be defined by $x\mapsto \sum_{j=1}^{\mu}g(x-x_j)^2$ , where $g$ denotes the euclidean norm on $\mathbb{R}^n$ . Problem: Find all local extrema of $\phi$ on $\mathbb{R}^n$ , if there are any. My problem is that $\phi$ doesn't seem to be differentiable (at least I haven't been able to find a derivative) and so we have to manually find local extrema or show that there aren't any.        In order to show the latter, I've been trying different approaches for a while now but the problem seems to be that if we let $x$ be ""further away"" from one of the $x_j$ 's, we can't really take into account the effect this has on the ""distance"" from $x$ to the others. I would very much appreciate help with this.","['multivariable-calculus', 'calculus', 'analysis', 'real-analysis']"
3684195,"$\mathbb P(\sup_{t\in[0,1]}|W_t|\le1)$ for Brownian motion","What is $\mathbb P(\sup_{t\in[0,1]}|W_t|\le1)$ for $W_t$ a Brownian motion? Without the absolute value, we have $\mathbb P(\sup_{t\in[0,1]}W_t\le c)=1-\sqrt{2/\pi}\int_c^\infty e^{-x^2/2}dx$ for all $c\ge0.$ (The proof I know of uses the strong Markov property.) However, I have no idea how to proceed when we have the absolute value.","['stochastic-processes', 'markov-process', 'brownian-motion', 'probability-theory']"
3684196,Help with the proof that $E\subset \mathbb{R}$ with finite perimeter and area has to be equal to the finite union of bounded intervals,"I'm preparing for an exams and I've problems solving this exercise from an old exam, any help will be welcomed Let $E\subset \mathbb{R}$ be a measurable set with $\mathfrak{L}^1(E)<\infty$ and $$P(E) = \sup\biggl\{\int_E\varphi'(x)\,dx:\varphi \in C_c^1(\mathbb{R})\wedge |\varphi|_{\infty}\le 1\biggr\}<\infty.$$ Prove that $E$ is (equivalent to, up to a set of measure $0$ ) the union of a finite number of bounded
  intervals. In here $P(E)$ is just a formal way to define the perimeter, so the problem is proving that, if a subset of the real line $\mathbb{R}$ has finite length and finite perimeter then it is the union of a finite number on bounded intervals . My problem is how to put together the two datas we have on $E$ (the finite perimeter and finite length). I actually found a proof of this fact but it seems quite convoluted so I was hoping to find some help in understanding it or even better state it in a simpler way This come from the book ""Sets of finite perimeter and geometric variational problems"" from Francesco Maggi EDIT: My idea is to pass to the closure and then argue with connected components of the former, also using the fact that for balls $P(E)=H^{n-1}(E)$ the $(n-1)$ -dimensional Hausdorff measure, this ball will need to be bounded and each of them giving a finite contribution to the perimeter therefore in a finite number.
However to do so I need $\overline{E}\setminus E$ to have measure 0 and even if I'm quite sure about this in the comments of this own post it doesn't seem like so.","['geometry', 'geometric-measure-theory', 'functional-analysis', 'analysis']"
3684239,When is the integral of a function well defined with respect to a signed measure?,"When is the integral of a function well defined with respect to a signed measure? Hello friends, I have a question. I appreciate who can guide me a little. Is the next: Let $ (\Omega, \Sigma, \mu) $ be a measure space, where $ \mu $ is a signed measure. If $f $ is measurable in $ (\Omega, \Sigma) $ when does it make sense to talk about the integral of $f $ with respect to $\mu$ ?
The natural thing is to think of defining it in the following way: $$\int_{\Omega} fd\mu: = \int_{\Omega}fd\mu_{+}-\int_{\Omega}fd\mu_ {-},$$ where $\mu = \mu_ {+}-\mu_{-},$ but something like $ \infty- \infty $ can happen, right? Are there other conditions to define the integral in signed measures?","['integration', 'measure-theory']"
3684266,Wald meets Weitzman/Gittins,"Suppose a searcher is faced with $n$ objects. Each object's quality is an i.i.d. Bernoulli random variable $\Theta_{i}$ , $i = 1, \dots, n$ , where $\mathbb{P}\left(\Theta_{i} = 1\right) = \mu_{0}$ . Time is continuous, and each instant the searcher may sample from an object: she chooses object $i$ and observes a process $(Z^{i}_{t})_{t\geq 0}$ . For all $i$ , when object $i$ is being sampled, the change in the process $Z^{i}_{t}$ is the sum of the state and a noise term, which is the increment of a Brownian motion $(W_{t})_{t \geq 0}$ : $$dZ^{i}_{t} = \theta_{i} dt + \sigma dW^{i}_t$$ For simplicity, I've assumed the volatility for each object $i$ is identical, $\sigma$ (more generally, each would have volatility $\sigma^{i}$ ). Let $\mu^{i}_{s}$ denote the agent's posterior belief that object $i$ has quality $1$ : $$\mu_{i}^{s} := \mathbb{P}\left(\Theta_{i} = 1|\left(Z^{i}_{s}\right)_{s \leq t}\right)$$ If object $i$ is not sampled in the interval $[s,s']$ , $\mu^{i}_{s} = \mu^{i}_{s'}$ i.e. she does not learn about its quality. Thus, she can only learn about one object per instant. Each instant the agent must decide whether to sample some object $i$ or to stop and select one of the objects. Selecting an object ends the scenario. When sampling an object $i$ the agent incurs a bounded (positive) flow cost $c\left(\cdot\right)$ , which depends on her posterior belief i.e. if she samples from box $i$ between times $s$ and $s'$ , she pays cost $$\int_{s}^{s'}c\left(\mu^{i}_{t}\right)dt$$ More generally, each object could have a different flow cost, $c^{i}\left(\cdot\right)$ , but for now I suppose that they're all the same. The agent's payoff from stopping and selecting object $i$ at time $\tau$ is $$\mu^{i}_{\tau} - \sum_{j=1}^{n}\int_{0}^{\tau}c\left(\mu_{t}^{j}\right)dt$$ The classic Wald (1945) problem has just one object and a constant flow cost. This set-up is also clearly related to the multi-arm bandit problem, in which each instant/period an arm is selected and a flow payoff is received. Here, each instant and arm is selected and ""flow learning"" occurs. Also closely related is the sequential search problem of Weitzman (1979). Here are my questions: Has this problem been studied? This seems likely, since it seems like a natural question and it is closely related to two rich literatures: the multi-arm bandit literature, and the literature on Wald problems. Is an index policy optimal? I'd appreciate any references or suggestions.","['reference-request', 'stochastic-processes', 'stopping-times', 'brownian-motion', 'probability']"
3684292,Proving that the Kernel of an Integral Equation is Weakly Singular,"I have a simple problem of deducing whether the kernel $$k(x,t) := \log |x-t|$$ is weakly singular or not. I have seen many basic examples of how to do this but I can't make the link to this. I know that the kernel is weakly singular if $$|k(x,t)| \leq C|x-t|^{- \alpha}$$ Does it have something to do with $\log 0$ being undefined and $|x-t| \rightarrow 0$ ? Any help would be appreicated.","['integration', 'continuity', 'improper-integrals']"
3684302,"Prove that there are no nontrivial cycles in any transitive, antisymmetric relation R.","A cycle in a relation R is a sequence of k distinct elements a_0, a_1, ..., a_(k-1) of A where (a_i, a_((i+1) mod k)) ∈ R for each i ∈ {0, 1, ..., k-1}. A cycle is nontrivial if k ≥ 2. Prove that there are no nontrivial cycles in any transitive, antisymmetric relation R. I understand that a cycle in graph theory is a path of length >= 2 from vertex u, back to vertex u that doesn't traverse the same edge twice. What I don't understand is how can I represent a cycle as a set of relations, and then prove that it holds the following properties? Thanks for your help. I will prove by contrapositive and say that if R is transitive and has a non-trivial cycle, then R is not anti-symmetric. To do this I will show that if (a_i, a_i+1) ∈ R for i = 0, 1, ..., k-2; then (a_0, a_k-1) ∈ R using induction on i. Let i = j for some j ∈ Natural Numbers. The base case will be j=0 and thus we have, (a_0, a_0) = (a_0, a_(0 (mod 1))) == (a_0, a_0) Our inductions hypothesis will be to assume that (a_k-1, a_0) ∈ R.
Next we will assume that (a_0, a_j) is in the relation R, for some j ∈ {1,2,...,k-2} Thus, (a_0, a_j+1) == (a_0, a_k-1) Therefore, since (a_0, a_k-1) ∈ R, and (a_k-1, a_0) ∈ R by the I.H.; and since every node is different, a_0 =/= a_k-1, hence R cannot be anti-symmetric, hence proved. Q.E.D.","['graph-theory', 'proof-explanation', 'proof-writing', 'discrete-mathematics']"
3684315,$x-\sin(x) \geq \dfrac{x^3}{(x+\pi)^2}$,"Let $x \geq 0.$ I need to prove that $x-\sin(x)\geq\dfrac{x^3}{(\pi+x)^2}.$ I tried the derivative, of $f(x)=x-\sin(x)-\dfrac{x^3}{(\pi+x)^2}$ which is $1-\cos(x)-\dfrac{x^2(x+3\pi)}{(\pi+x)^3},$ but it has a complicated formula. Any ideas, hints? Edit: sorry, there was a mistake in the derivative, I corrected it.","['inequality', 'functions', 'analysis', 'real-analysis']"
3684361,Unitary operator as an exponent of self-adjoint,I'm trying to proof that set of unitary operators on infinite Hilbert space is path-connected. That's why i need to show that for each unitary $U$ there is a self-adjoint $B$ such that $U=e^{iB}$ . Any ideas on how to show that? Maybe by using the fact that every unitary operator is unitary equivalent to operator of multiplication by $f$ in some $L_{2}(\mu)$ ?,"['operator-theory', 'functional-analysis', 'self-adjoint-operators']"
3684379,Can a function $f$ have an antiderivative even though its indefinite integral $F(x) = \int_{a}^{x} f(t)\ dt$ is not one?,"The fundamental theorem of calculus states that if $f:[a,b] \to \mathbb{R}$ is integrable and $F(x) = \int_{a}^{x} f(t)\ dt$ , then $F'(x) = f(x)$ at every point $x$ at which $f$ is continuous. This means that if $f$ is integrable, $F'(x) = f(x)$ almost everywhere. If $f$ is continuous on $[a,b]$ , then $F$ is an antiderivative of $f$ , since $F'(x) = f(x)$ holds for all $x \in [a,b]$ . But what if $f$ has a discontinuity at some $x \in [a,b]$ ? In this case, it is not necessarily true that $F'(x) = f(x)$ , and so we cannot necessarily conclude that $F$ is an antiderivative of $f$ . Does this mean that there is no antiderivative of $f$ ? Is it possible for $f$ to have an antiderivative but the indefinite integral $F$ is not an antiderivative of $f$ ? I know that if $f$ has a jump discontinuity, then $f$ can have no antiderivative (since the derivative of a function must satisfy the intermediate value property), but what if we have some other type of discontinuity?","['integration', 'calculus', 'real-analysis']"
3684390,When do differential equations induce maps between algebraic varieties and how to find these varieties,"The intuition: Consider a single variable polynomial differential equation with integer-polynomial coefficients, for example $$ y '' = -y $$ Then consider a pair of algebraic varieties (that is solutions to systems of polynomial equations with integer coefficients) on $\mathbb{R}^2$ for example $\lbrace (x,y) | x^2+y^2 =1 \rbrace$ and $\lbrace (x,y) | x = 0\rbrace $ Now observe that our algebraic varities in $\mathbb{R}^2$ can also be viewed as sets in $\mathbb{C}^2$ , as the unit circle and real-line respectively. Now recall the famous fact that curiously enough ONE of the solutions to that differential equation $y = e^{ix}$ happens to map the real-line to the unit circle This is is a pretty surprising result. But theres a family of such results The curves $re^{ix}$ and $re^{-ix}$ both map the real line to the circle of radius r. And in general the solution $ae^{ix} + be^{-ix}$ maps the real line to an ellipse given by $(x(t),y(t) = ((a+b)\cos(t), (a-b)\sin(t))$ (introducing complex numbers for $a,b$ allows us to tilt our ellipses around). So generally speaking the maps between ${x=0}$ to any ellipse centered at 0, are induced by the solutions of $y'' = -y$ . The Question: Given a polynomial differential equation $D$ , with integer-polynomial coefficients, how can one find the set of all [if any] pairs of algebraic varieties $U,V$ that get mapped to each other under solutions of $D$ viewed as complex functions. For example given $y'' = -y$ one could could generate the pair $\lbrace (x,y), x = 0 \rbrace, \lbrace (x,y) |  x^2 + y^2 = 1 \rbrace$ But if we just consider some arbitrarily harder equation such as: $$ 2yy'' + 3y' - 5x^2 y = 0$$ It becomes extremely hard to figure how to do algorithmically do this. Your best luck is to solve the equation, and hope that you recognize some nice properties about the functions used in the general solution. Note that since the definition of variety is quite general, I want cut straight to the interesting stuff by insisting the two varieties should have covering dimension $1$ (that is they are line-like). Some Results: Going the other way from algebraic variety to differential equation is surprisingly easier. You can always parametrize algebraic curves and once you have a parametric function of 2 variables that can be transformed into a complex function of 2 variables and from here there is a lot more hope at being able to find a differential equation [although insisting the differential equation has integral/polynomial coefficients or polynomial form might make matters much harder] Some stray thoughts: Instead of asking about algebraic varieties you could ask about topological manifolds [forgetting the algebraic part] and as the original intuition suggests, a more natural question is to ask for infinite families of varieties and/or families of manifolds (often indexed by real or complex parameters) You could also restrict the form of the differential equations [linear, constant coefficient, etc...] So you end up with very large space of similar questions. But for the purposes of this site I decided to pick one such specific question feel free to answer any of the forms if one of them appears to be more well known/promising. Some potentially related questions/ideas: Algebraic Curves and Second Order Differential Equations","['complex-analysis', 'algebraic-geometry', 'ordinary-differential-equations']"
3684391,Computing a limit of a piece-wise function.,"I'm a student studying maths, I'm taking a real analysis course and I'm looking through some old exams questions. I've arrived at a number of questions that ask me to take the limit of a number of piece-wise functions as $x \rightarrow 2$ . Here is the first one. $$f(x)= \begin{cases} 
      \frac{x^2-4}{x-2} & \text{if }x \neq 2  \\
      6 & \text{if }x = 2 \\ 
   \end{cases}
$$ I know if I do some algebra we get... $$\frac{x^2-4}{x-2} = \frac{(x+2)(x-2)}{x-2}= x+2$$ So we get. $$f(x)= \begin{cases} 
      x+2 & \text{if }x \neq 2  \\
      6 & \text{if }x = 2 \\ 
   \end{cases}
$$ so if we take the limit $$\lim_{x\to2}f(x) = ???$$ I'm not sure weather the answer is 4 or 6. They both seem intuitively correct so perhaps the answer might even be neither. I'm very interested to know! Thanks for your time!","['limits', 'piecewise-continuity', 'real-analysis']"
3684397,Prove that following set is Gröbner system [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Can you help me with this task, please?
Prove that set $F \subseteq K[x] \setminus \{0\}$ is Gröbner system if and only if such polynomial $f \in F$ exists, that $f$ divides any polynomial in F. This task is from our previous year algebra exam and one of the hardest one I suppose.. I expect something similar this year, can you please help me solving this one to be prepared for the current exam? Will appreciate any help :)","['minimal-polynomials', 'ring-theory', 'abstract-algebra', 'polynomials', 'group-theory']"
3684420,Lower bound on the variance of the maximum of random variables.,"I'm trying to figure out a lower bound on the variance of the follow: $\max_i(x_1,x_2,...x_m)$ . Where $x_i, i \in m$ are independent random variables that shares the same variance $\sigma_x$ . I know we can upper bound the above quantity to be: $\text{Var}[max_i(x_1,x_2,...x_m)] \leq \sum^m_i \text{Var}[x_i] $ , but what about a lower bound? Also, is there a guarantee that this is the tightest lower bound? Also, can we find a bound for $\text{Var}[max_i(a_1,a_2,...a_m),max_i(b_1,b_2,...b_m),...,max_i(z_1,z_2,...z_m)] $","['concentration-of-measure', 'variance', 'upper-lower-bounds', 'probability-theory', 'random-variables']"
3684449,Relation/Difference between moduli spaces and classifying spaces.,"From what I have read so far, a classifying space is a  representing object of some (co)representable functor. For example, the $n^\text{th}$ Eilenberg–MacLane space is the classifying space for the $n^\text{th}$ singular cohomology functor since $$H^n_{\text{sing}}(X;G)\cong[X, K(G,n)]_{\text{Hotop}}.$$ Also principal $G$ -bundles over a manifold $X$ are classified by the classifying space $BG,$ where $G$ is a Lie group. This is written as $$G\text{Bun}(X)\cong[X, BG]_{\text{Hotop}}.$$ So, maps in to (or from) the classifying space classify some data over associates to our object $X$ up to isomorphisms. On the other hand, in my mind, a moduli space is a space whose points are (isomorphism classes of)
geometric structures/objects associated to $X.$ This is very intuitive as many sources say the term ""modulus"" is used synonymously with ""parameter"" and so a moduli space parametrizes the associated geometric structures/objects. The easiest example being the real projective plane $G(1,\mathbb{R}^3,\mathbb{R})=\mathbb{R}P^2$ whose each point represent a $1$ -dimensional vector subspace of $\mathbb{R}^3.$ Next, moduli spaces on this line are general Grassmannians $G(k, V,\mathbb{F}).$ Another example is the moduli space $\mathcal{M}_g$ whose points are Riemann surfaces of genus $g$ up to biholomorphisms. Please correct me if I am wrong at some point so far. However it seems like in literature people use the words moduli space and classifying space as synonyms. I would like to clarify this confusion, and know the precise difference and relationship between them.","['moduli-space', 'classifying-spaces', 'algebraic-geometry', 'differential-topology', 'algebraic-topology']"
3684453,Compute the integral of $e^{-x}$,"I am working on a problem in my past Qual. ""Prove that $e^{-x}$ is Lebesgue integrable on $[0,\infty)$ and compute the integral."" Here is my solution: $e^{-x}$ is continuous, hence measurable. We can use the monotone convergence theorem $$\int_0^\infty e^{-x} = \int_0^n \lim(e^{-x}\chi_{[0,n]})=\lim \int_0^n(e^{-x})=1<\infty$$ So it is Lebesgue integrable. This solution seems too short and direct. So I doubt that it is wrong.","['measure-theory', 'solution-verification', 'lebesgue-integral', 'real-analysis']"
3684538,Is my logic textbook incorrect?,"I am reading ""Mathematical Methods in Linguistics,"" corrected first edition, by Barbara H. Partee, Alice ter Meulen, and Robert E. Wall. The textbook is brilliant, though I believe there is an error in it. Given: $$A = \{b,c\} \text{ and } B = \{2,3\},$$ the textbook holds the following to be true (Chapter two, question 2a) : $$(A \times B) ∪ (B \times A) = \emptyset.$$ I can see this being the case for an intersect, though not for a union.","['elementary-set-theory', 'logic']"
3684559,Number of edges of a random connected undirected graph created by a random walk,"Consider the following algorithm that generates a random connected undirected graph with $n$ vertices. Choose a random starting vertex and perform a random walk as follows. At each step $i$ of the walk, let $v_i$ be the vertex we are currently at. Choose a random vertex $v_{i+1}$ and walk to $v_{i+1}$ at the next step. If $ v_i \neq v_{i+1} $ and $ \{v_i, v_{i+1}\} $ has not been walked, add $ \{v_i, v_{i+1}\} $ to the set of (undirected) edges. (Even if $ v_i = v_{i+1} $ , we still perform the walk. We just 'wasted' one step). Stop when all $n$ vertices have been visited. The graph $G_n$ obtained this way is guaranteed to be connected. Now the problem is: What is the probability distribution of the number $M_n$ of edges of $G_n$ ? If this is too hard to find, what about the expected number $\text{E}[M_n]$ ? I know $ \text{E}[M_n] = O(n\log n) $ , because the expected number of the steps $N_n$ needed is exactly $$ \text{E}[N_n] = n \sum_{i=1}^n \frac{1}{i} = O(n\log n) $$ But is there an exact formula for $ \text{E}[M_n] $ ? Better yet, can we find the probability distribution of $M_n$ ?","['random-graphs', 'graph-theory', 'stochastic-processes', 'probability-theory', 'probability']"
