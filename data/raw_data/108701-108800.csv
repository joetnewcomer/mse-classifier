question_id,title,body,tags
1563224,Do the singular matrices form a topological manifold,"So the definition of manifold I'm using is that of a topological manifold (a topological space with an atlas of homeomorphisms to $\mathbb{R}^n$). I have two related questions: Is the set of singular matrices (over $\mathbb{R}$) of dimension $n$ a manifold?  My understanding is that it cannot be if it has the subspace topology inherited from $\mathbb{R}^{n^2}$, since in this case it's given by the surface $\det(A)=0$, which has a singularity at $0$.  I'm aware of the similar questions here and here , but the answers given seem to be for smooth manifolds and not topological manifolds. My second question is what exactly is the topological definition of a singularity?  Since a topological space being a manifold is a property of the topology itself, there should be a purely topological definition of a singularity.  The best I can come up with is that a singular point in a topological space is a point such that no open set which contains it can be homeomorphic to $\mathbb{R}^n$, however this definition seems like a bit of a cop out. Update So as far as I can tell my definition of a topological singularity is correct.  However as to whether the surface $\det(A)=0$ is a topological manifold or not, I still couldn't say. Considering the determinant as a potential submersion of manifolds $\mathbb{R}^{n^2}\rightarrow\mathbb{R}$, we see by looking at its derivative that it fails to be a submersion whenever the adjoint (or equivalently the cofactor) matrix is identically zero.  And since the adjoint of a matrix being zero implies the matrix is singular, this will be some subset of the singular matrices.  So it is these matrices which prevent us from using the regular level set theorem to conclude that the singular matrices form a smooth manifold, however it doesn't mean they aren't a topological manifold. The set of points in $\mathbb{R}^{n^2}$ which are singularities is thus given by the polynomial surface 
$$\{\det(A_{ij})=0\; :\; 1\leq i,j\leq n\}$$ 
where $A_{ij}$ is the sub-matrix of $A$ obtained by deleting the $i^{th}$ row and $j^{th}$ column. An example of a singular curve which does admit a $C^0$ structure is $y^2-x^3=0$, via the parametrization $t\mapsto (t^2,t^3)$. An example of a singular curve which doesn't admit a $C^0$ structure is $xy=0$, since any open set containing the origin has 4 disconnected components when the origin is removed, while removing a point in $\mathbb{R}^k$ results in at most 2 disconnected components.","['manifolds', 'singularity-theory', 'general-topology', 'algebraic-geometry']"
1563256,Counterexample to two-sided limit must equal one sided limits if they exist and are equal,"We learned that the two sided limit must equal the one-sided limits if they both exist and are the same. And I don't seem to get it, because I think I found a counterexample (I hate when this happens!). Consider $f(x) = (1 \text{ if } x=0)(0 \text{ otherwise})$.
If we have a sequence $x_n$ with $x_n <0$ for all $n \in \mathbb{N}$ and $\lim_{n\to \infty} x_n= 0$, then we have $\lim_{n\to\infty} f(x_n) = 0$. Therefore $\lim_{x\to 0^-} f(x) = 0$. Likewise $\lim_{x\to 0^+} f(x) = 0$. Hence, it should be true that $\lim_{x\to 0} f(x) = 0$ But $(x_n) = (0,0,0,0,\ldots)$ is a sequence with $\lim_{n\to\infty} x_n= 0$ and $\lim_{n\to\infty}= f(x_n) = 1$. Therefore the limit does not exist! Thank you in advance.","['calculus', 'limits']"
1563257,Prove: if $a \equiv b \pmod 5$ then $2a \equiv 2b \pmod{5}$?,"Prove only using of the definition of congruence: if $a \equiv b \pmod 5$ then $2a \equiv 2b \pmod{5}$? I have thought about the solution as follows: $2a \equiv 10k+2r \equiv 5 (2k) +2r$ ......(1) $2b \equiv 10l+2r \equiv 5 (2l) + 2r$ .....(2) both of (1) and (2) have the same remainder, therefore $2a \equiv 2b \pmod{5}$?",['discrete-mathematics']
1563267,Cardinality of the Mandelbrot set,"Is the Mandelbrot set countable or of the cardinality $2^{\aleph_0}$? My intuition says the latter, but I couldn't find a bijection.",['elementary-set-theory']
1563279,Lagrange Multipliers: find points farthest/closest to a point,"Find the points of the ellipse: $$\frac{x^2}{9}+\frac{y^2}{4}=1$$ which are closest to and farthest from the point $(1,1)$. I use the method of the Lagrange Multipliers by setting: $$f(x,y)=(x-1)^2+(y-1)^2$$ (no need for the root since maximizing one maximizes the other) And $$g(x,y)=\frac{x^2}{9}+\frac{y^2}{4}-1=0$$ the constraint. We get: $$x-1=λx/9$$           and           $$2y-2=λy/2$$ I don't know where to go from there. I tried finding $x$ and $y$ alone and then plugging their values in the constraint $g(x,y)=0$ but I get a really complicated equation.","['multivariable-calculus', 'lagrange-multiplier']"
1563281,Don't understand this proof of $(A \triangle B)\cup C = (A\cup C)\triangle (B\setminus C)$,"In this question , the most upvoted explanation of the identity in my title is this reply . I don't have the reputation to comment on the existing thread, so I'm asking here, because I am having a hard time following the explanation. I can prove this identity via Venn decomposition as in the checked reply , or simply verbalizing the ideas, but I can't seem to follow it via straight logical equivalencies. This explanation just confuses me further, such as here: $x \in (A \triangle B)\setminus C$ or $x \in C$. In the first case, $x \in A$ and $x \notin B$ (so $x \in A \cup C $ and $x \notin B\setminus C$) or $x \notin A$ and $x \in B$ and $x \notin C$ Why is it being phrased this way? I can see how individual assertions are technically true, but I can't seem to follow how they're being arrived at, and the treatment of the set $C$ seems arbitrary to me. Why is its exclusion not mentioned in the first possibility, but is in the second? I know what these statements mean taken by themselves, but I can't seem to make sense of how the respondent relates them. Here's as far as I get with the algebraic logic approach: $((A \lor B)\land(\lnot A \lor \lnot B))\lor C \equiv ((A \lor C) \lor (B \land \lnot C)) \land ((\lnot A \land \lnot C) \lor (\lnot B \lor C))$ But it's at this point that I run into a wall.","['logic', 'elementary-set-theory', 'proof-explanation']"
1563305,Set of finite outer measure is contained in an open set of finite measure?,"In a proof I'm reading, the author remarks in the first line of the proof, with no justification whatsoever, that a set of finite outer measure is contained in an open set of finite measure. I have spent some time thinking about this and it is not obvious to me that this is the case. Can someone please explain why this should be obvious? Thank you.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1563330,Cohomologies of anticanonical sheaf of blow-up of $\mathbb{P}^2$ in 9 points,"Let $\pi:X\to\mathbb{P}^2$ be a blow-up of $\mathbb{P}^2$ in 9 points (in general position for example, but it doesn't matter). Then the canonical divisor of $X$ is equal $K_X=-3\pi^*H+\sum\limits_{k=1}^9E_k$, where $E_k$, $k=1,...,9$ are exceptional divisors. It is known and not hard to compute that $-K_X\sim C$, where $C$ is a proper transform cubic curve on $\mathbb{P}^2$, which passes through that 9 points. I want to compute $H^i(X, \mathcal{O}_X(-K_X))$. By Riemann-Roch, $\chi(\mathcal{O}_X(-K_X))=1$. From the identification of $-K_X$ we need to compute $H^i(X, \mathcal{O}_X(C))$. Let us write the exact sequence $$0\to\mathcal{O}_{X}\to\mathcal{O}_{X}(C)\to\mathcal{O}_{C}(C)\to0.$$ But $C\cdot C=K_X\cdot K_X=0$, so the third term is actually $\mathcal{O}_{C}$. Taking the long exact sequence of cohomologies we obtain $$0\to H^0(X,\mathcal{O}_{X})\to H^0(X,\mathcal{O}_{X}(C))\to H^0(C,\mathcal{O}_{C})\to0.$$
Thus $\text{dim}\,H^0(X, \mathcal{O}_X(-K_X))=2$. But this result doesn't coincide with the result from Sándor Kovács's answer for the following question: https://mathoverflow.net/questions/107345/blowing-up-general-k-points-on-the-plane Where is my mistake?","['algebraic-geometry', 'proof-verification']"
1563383,Moving special lines on cubic threefold,"Let $X$ be a cubic hypersurfaces in $\mathbb{P}^4$. $F(X)$ variety of lines on $X$. In this survey on page 3 Debarre claims that $F(X)$ is connected. Moreover he says that there are two type of lines (points in $F(X)$). I construct an explicit family of lines of the second type. $$X = \{ (x_0 : x_1 : x_2 : x_3: x_4) | x_0^3 + x_1^3 + x_2^3 + x_3^3 + x_4^3= 0 \} $$ My lines are parametrized by elliptic curve $E = \{ (a_1: a_2 : a_3) | a_1^3 +a_2^3 +a_3^3 = 0 \}$ My family of lines is defined as follows $$ l_a  = \{ ( \mu : -\mu : a_1 \nu : a_2 \nu : a_3 \nu ) \ \  \text{for all} \ \ (\mu : \nu) \in \mathbb{P}^1 \} $$ All curves from from this family intersect at one point. Then normal bundle has subsheaf $\mathcal{O} (1)$. Then all these curves are of second type (because $\mathcal{O} \oplus \mathcal{O} $ does not have $\mathcal{O}(1)$ as a subsheaf ). Question How can one move line from my family to get a general line? Such movement must be possible from connectedness of $F(X)$, must not it?",['algebraic-geometry']
1563403,Cardinality of set difference of finite sets,"Is $|A \setminus B| = |A| - |A \cap B|$, where $A$ and $B$ are finite sets, true? I have been unable to prove this or find a good reference on cardinality of set differences. The only reference I found was ProofWiki , and the only case they consider is when $A \subseteq B$, which is not necessarily the case here.","['proof-writing', 'elementary-set-theory']"
1563531,Is the set $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)$ exist$\}$ measurable?,"Let $f$ be a Lebesgue Measurable Function on $\mathbb{R}$. 
  Is the set $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)$ exist$\}$ always measurable? I can prove if $a\in \mathbb{R}$ is given $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)=a\}$ is measurable by showing the $\epsilon-\delta$ definition of limit only requires $\frac{1}{n}$ values($n\in \mathbb{N}$) for $\epsilon$ and $\delta$ and write the set as countable union/intersection of measurable sets. However I don't think we can do the same thing for $a$ becuase it has uncountably many possibilities.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'functions']"
1563558,"Find all irreducible polynomials of degrees 1,2 and 4 over $\mathbb{F_2}$.","Find all irreducible polynomials of degrees 1,2 and 4 over $\mathbb{F_2}$. Attempt: Suppose $f(x) = x^4 + a_3x^3 + a_2x^2 + a_1x + a_0 \in \mathbb{F_2}[x]$. Then since  $\mathbb{F_2} =${$0,1$}, then we have either $0$ or $1$ for each $a_i$. Then we have two choices for the $4$ coefficients, hence there are 16 polynomials of degree $4$ in $\mathbb{F_2}[x]$. Recall $f(x)$ is irreducible if and only if it has not roots. Then $f_1 = x$ is irreducible because it has not roots $f_2 = x + 1$ is also another irreducible polynomial. $f_3 = x^4 + x^2 + x = x ( x^3 + x + 1) $ is reducible. $f_4 = x^4 = x^3* x$ is reducible $f_5 = x^4 + x + 1$ Can someone please help me? Is there a way I can save time in finding the irreducible polynomials, other than just trying to come up with polynomials. Any better approach or hint would really help! Thank you !","['abstract-algebra', 'ring-theory', 'field-theory']"
1563567,"In $S_{4}$, find a Sylow 2-subgroup and a Sylow 3-subgroup.","In $S_{4}$ , find a Sylow 2-subgroup and a Sylow 3-subgroup. With everyone's comments and inputs, I have outlined the following answer: We have $|S_{4}|= 24 = 2^{3}3$ . If $P$ is a Sylow $2$ -subgroup then $|P| = 2^3$ , and if $K$ is a Sylow $3$ -subgroup then $|K|=3$ . So we need to find subgroups of $S_4$ of order $8$ and order $3$ . For the subgroup of order $3$ , since it is of prime order, it is cyclic, thus we need to find an element of $S_4$ of order $3$ .  So any $3$ -cycle of $S_4$ will suffice.  As a concrete example, we will call $K = \langle(1\ 2\ 3)\rangle$ . Now we must find $P$ . Since $|P| = 8$ , every element in $P$ must have order $1$ , $2$ or $4$ .  We can choose a dihedral subgroup $D_4$ to be $P$ . For example $$P= \lbrace e, (1234), (13)(24), (1432),(24) ,(14)(23), (13), (12)(34)\rbrace.$$","['finite-groups', 'abstract-algebra', 'sylow-theory', 'group-theory', 'symmetric-groups']"
1563607,What property does this binomial probability calculation use?,I have an equation $$\sum_{k=2}^7{7\choose k}{0.01^k}(1-0.01)^{7-k} = 1-(0.99)^7 - 7(0.01)(0.99)^6 \approx 0.002031$$ I don't know what property the teacher used to quickly transform the summation to two simple equations. Can someone please give me a hint? P.S. This formula is used to calculate binomial probability.,"['summation-method', 'binomial-distribution', 'probability']"
1563609,Team Fortress 2: Choosing Between Two Weapons,"Background : In Team Fortress 2, there are two secondary weapons that the 'Heavy' class can choose between. I am trying to figure out what the best way to compare the two weapons mathematically is. The first weapon is the default Shotgun . It shoots $1.6$ times per second, and has a clip size of $6$. For simplicity, let's assume that it does $60$ damage every time it hits. The second weapon is called the Family Business . It shoots $15\%$ faster than the regular shotgun, so it shoots $1.84$ times per second. It has a clip size of $8$, and it does $15\%$ less damage than the regular shotgun, so that means it does $51$ damage every time it hits. Finally, both weapons must be reloaded after their clips are emptied. It takes $3.5$ seconds for the regular shotgun to reload completely, and it takes $4.5$ seconds for the family business to reload completely. My Calculations (so far): The family business shoots $15\%$ faster and does $15\%$ less damage per shot. $$1.15\cdot0.85 = 0.9775$$ So, ignoring clip sizes, the family business should intuitively do about $2.25\%$ less damage than the regular shotgun while both weapons are continuously firing (ignoring reloading times). The shotgun takes $6/1.6=3.75$ seconds to empty its clip. The family business takes $8/1.84 \approx 4.35$ seconds to empty its clip. That means that if both weapons are shooting for less than or equal to $3.75$ seconds, then the family business should do $2.25\%$ less damage. My Question : Which of these two weapons has a greater average damage per second in an indefinitely prolonged battle? In other words, if $D_s(t)$ and $D_{fb}(t)$ are the damage done after $t$ seconds of continuous shooting by the shotgun and family business, respectively, then what is the value of this limit? $$\lim_{t\to\infty} \frac{D_{fb}(t)}{D_{s}(t)}$$ The answer should represent ratio of the average damage per second of the family business to that of the regular shotgun, over an indefinitely long shootout. I know the value for $t=3.75$. $$\frac{D_{fb}(3.75)}{D_{s}(3.75)}=0.9775$$ Any help is appreciated, thank you!","['arithmetic', 'optimization', 'limits']"
1563626,Critical Homogeneous Sobolev Embedding,"For $s\in\mathbb{R}$, $1<p<\infty$, define the homogeneous Sobolev space $\dot{W}^{s,p}(\mathbb{R}^{n})$ as follows: For $f\in\mathcal{S}_{0}(\mathbb{R}^{n})$ (Schwartz functions with Fourier transforms supported away from origin), we define the homogeneous Sobolev norm $\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$ by
    $$\|(2\pi|\xi|^{s}\widehat{f})^{\vee}\|_{L^{p}(\mathbb{R}^{n})}=\||\nabla|^{s}f\|_{L^{p}(\mathbb{R}^{n})}$$
We define $\dot{W}^{s,p}(\mathbb{R}^{n})$ as the closure of all $f$ under this norm. I am interested in the following critical Sobolev embedding: For $1<p<\infty$ and $s=n/p$, if $f\in\dot{W}^{s,p}(\mathbb{R}^{n})$,
  then $f\in BMO(\mathbb{R}^{n})$ with    $$\|f\|_{BMO(\mathbb{R}^{n})}\lesssim_{n,p}\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$$ One proof of this result is via Riesz potentials and goes something as follows. Using the fact that for $0<s<n$, the Fourier transform of the distribution $|x|^{-n+s}$ is a scalar multiple of $(2\pi|\xi|)^{-s}=\widehat{|\nabla|^{-s}}$, it suffices to show that the Riesz potential satisfies the inequality
    $$\|I_{s}f\|_{BMO}\leq\|f\|_{L^{n/s}},\quad\forall f\in\mathcal{S}_{0}(\mathbb{R}^{n})$$
Indeed, if $f\in\mathcal{S}_{0}$, then $|\nabla|^{s}f\in\mathcal{S}_{0}$, whence
    $$\|f\|_{BMO}=\|I_{s}|\nabla|^{s}f\|_{BMO}\lesssim_{n,s}\||\nabla|^{s}f\|_{L^{n/s}}=\|f\|_{\dot{W}^{s,n/s}}$$ By translation invariance, it suffices to show that there exists a constant $A>0$ such that for all cubes $Q$ centered at the origin, there exists a constant $c_{Q}\in\mathbb{C}$
    $$\int_{Q}|I_{s}(f)(y)-c_{q}|dy\leq A|Q|$$
We then have that the infimum of all such $A$ is comparable to $\|I_{s}f\|_{BMO}$. To do this, we let $Q^{*}$ denote the enlargement of a cube $Q$ by a factor of $2\sqrt{n}$ (i.e. $l(Q^{*})=2\sqrt{n}l(Q)$). We write $f=f_{1}+f_{2}$, where $f_{1}=f\chi_{Q^{**}}$. Choose $1<p_{0}<p$ and let $q_{0}$ be such that $q_{0}^{-1}=p_{0}^{-1}-(s/n)$. By the Hardy-Littlewood-Sobolev inequality together with Holder's inequality, we have the estimate
\begin{align*}
\dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|dx\leq\left(\dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}&\leq|Q|^{-1/q_{0}}\left(\int_{\mathbb{R}^{n}}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}\\
&\lesssim_{n,p_{0},s}|Q|^{-1/q_{0}}\left(\int_{Q^{*}}|f_{1}(x)|^{p_{0}}dx\right)^{1/p_{0}}\\
	&\lesssim_{n,p,s}|Q^{*}|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}}\left(\dfrac{1}{|Q^{**}|}\int_{Q^{*}}|f(x)|^{p}dx\right)^{1/p}\\
	&\lesssim_{n,p,s}|Q|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}}\|f\|_{L^{p}}
\end{align*}
where we make use of Holder's inequality. Since $\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}=\frac{s}{n}-\frac{1}{p}=0$, we obtain the desired estimate. Now take
$$c_{Q}:=I_{s}(f_{2})(0)=\int_{(Q^{*})^{c}}f(y)|y|^{-s}dy$$
Since for $x\in Q$ and $y\in (Q^{*})^{c}$, we have that $|x-y|\geq $, we obtain from the mean value theorem that
\begin{align*}
|I_{s}(f_{2})(x)-c_{Q}|&\leq\int_{(Q^{*})^{c}}|f(y)|\left|\dfrac{1}{|x-y|^{s}}-\dfrac{1}{|y|^{s}}\right|dy\\
&\lesssim_{s}\int_{(Q^{*})^{c}}|f(y)|\cdot\dfrac{|x|}{|y|^{n-s+1}}dy\\
&\leq l(Q)\left(\int_{(Q^{*})^{c}}|f(y)|^{\frac{n}{s}}dy\right)^{s/n}\left(\int_{(Q^{*})^{c}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\
&\leq l(Q)\|f\|_{L^{n/s}}\cdot l(Q)^{\frac{n}{p'}}\cdot l(Q)^{-n+s-1}\left(\int_{|y|\geq 2\sqrt{n}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\
&=C_{n,s}\|f\|_{L^{n/s}}
\end{align*}
where we use Holder's inequality and dilation invariance above. By the triangle inequality, we conclude that
$$\dfrac{1}{|Q|}\int_{Q}|I_{s}(f)(x)-c_{Q}|dx\lesssim_{n,s}\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{1})(x)|dx+\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{2})(x)-c_{Q}|dx\lesssim_{n,s}\|f\|_{L^{n/s}},$$
which completes the proof. In some comments which can be found here , Terence Tao says that it's possible to prove this critical Sobolev embedding via Littlewood-Paley theory and references some notes of his which may be helpful. I took a look at them, and the only result which seemed to be useful was that if a Schwartz function has compactly supported Fourier transform, then $\|f\|_{L^{\infty}}\approx\|f\|_{BMO}$. One can apply this result to individual Littlewood-Paley projections $P_{k}f$, but I don't right now how to put this individual estimates together to obtain an estimate for $\|f\|_{BMO}$ in terms of $\|f\|_{L^{n/s}}$.","['fourier-analysis', 'harmonic-analysis', 'functional-analysis', 'littlewood-paley-theory', 'sobolev-spaces']"
1563627,"Prove that $f$ on $[a,b]$ has only a finite number of zeros.","Let $f:[a,b]\to\mathbb{R}$ be differentiable. Assume that there exists no $x\in[a,b]$ such  that $f(x)=0=f'(x).$ Prove that the set {$t\in[a,b]:f(t)=0$} of zeros of $f$ is finite. What I have done is, let the set contain infinite number of points. Then by the Bolzano Weierstrass theorem there exists a sequence $<x_n>$ which has a convergent subsequence $<{x_n}_k>$ convergent to $c$. Then $f(c)=0$. But I got stuck in proving $f'(c)=0$.","['real-analysis', 'calculus']"
1563659,Is this true that $\mathrm{Tr}(ABC)=\mathrm{Tr}(ACB)$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $A,B,C\in M_n$. Is this true that $\mathrm{Tr}(ABC)=\mathrm{Tr}(ACB)$?","['matrices', 'linear-algebra']"
1563665,Hidden Markov Models and Viterbi Algorithm: Fair and Biased Die,"So following is the problem that I am trying to solve using Viterbi algorithm and HMM: Before attempting to write a program, I want to do this problem by hand for the first 3 observations($651$). Based on the question, I understand that: $P(i | Fair) = \frac1{6} , 1\leq i \leq 6 $ $P( 6 | Biased ) = \frac5{10} = \frac1{2} $ $P( i | Biased ) = \frac1{10} , 1\leq i \leq 5 $ and the transition matrix is $Fair$ $Biased$ $\begin{bmatrix}
    0.95 & 0.05  \\
    0.1 & 0.9  \\
\end{bmatrix}$ but where should I go from here ? EDIT: Assume that initially either fair or biased is equally likely($\frac1{2}$) from a ""fictitious"" state $O$. I managed to compute the first 4 highest probabilities:  $1 , 0.25 , \frac9{400}, \frac{81}{40000}$ corresponding to $O , B,  B,  B$ Is this right ?","['stochastic-processes', 'markov-chains', 'statistics', 'bayesian-network', 'probability']"
1563666,To evaluate limit $\lim_{n \to \infty} (n+1)\int_0^1x^{n}f(x)dx$,"Let $f:\Bbb{R} \rightarrow \Bbb{R}$ be a differentiable function whose derivative is continuous, then $$\lim_{n \to \infty} \left((n+1)\int_0^1x^{n}f(x)dx\right).$$ I think I have to use L'Hop rule, but I don't see how.","['real-analysis', 'limits', 'calculus', 'integration', 'definite-integrals']"
1563699,Show that the angle with x-axis which the tangent to a circle is -x/y,"everyone this question is from Hogben's Mathematics for the Million . I'm not sure if I'm even interpreting it correctly, but I'm not making any headway. Any help would be appreciated for either the first or second parts (or both). I'm interpreting the question as asking for the angle alpha in blue here , is this incorrect? Thanks","['algebra-precalculus', 'trigonometry']"
1563720,Measurability criterion of Caratheodory,"Let $E=[0,1]$. 
Here are the definitions I am using: Let $A\subset E$, then we define the outer measure of $A$ as
$$\mu^*(A)=\inf \left\{\sum_k m(I_k): A\subset \cup_k I_k \right\}$$
where the infimum is taken over all any countable collection $\{I_k\}$ of intervals (open, closed or half open) whose union contains $A$, and we define the inner measure of $A$ as,
$$\mu_*(A)=1-\mu^*(E\setminus A)$$
and finally $A$ is said to be measurable if $\mu^*(A)=\mu_*(A)$. As a note, 
I have shown that
$$\mu^*(A)=\inf\{\mu(G): A\subset G, G \text{ is open relative to } E\}$$
so that we may use this characterization of the outer measure of a set or the one originally given above. We can also reformulate the definition of a measurable set: a set $A\subset E$ is measurable if and only if $\mu^*(E)=\mu^*(E\cap A)+\mu^*(E\setminus A)$ and this follows immediately from the fact that if $A$ is measurable according to the definition above, then $\mu^*(A)+\mu^*(E\setminus A)=1$ and since $A\subset E$, we have $A\cap E=A$. Now, I want to show yet another equivalent characterization of measurability in the following, $\textbf{Problem:}$
I am trying to prove if $A \subset E$ is measurable then for any $F\subset E$, we have
$$\mu^*(F)=\mu^*(F\cap A)+\mu^*(F\setminus A).$$ The hint in my book says to use $B\subset E$ is measurable if and only if for any $\epsilon >0$, $\exists G_1, G_2 \subset E$ and open relative to $E$ such that $B\subset G_1$, $E\setminus B\subset G_2$, and $\mu(G_1\cap G_2)<\epsilon$, so I also proved this (using the second characterization of $\mu^*$ provided here). For the current problem, this is my work so far: Clearly,
$$\mu^*(F)\leq \mu^*(F\cap A)+\mu^*(F\setminus A)$$
by sub-additivity. For the other inequality, let $\epsilon >0$, then
by the above condition for measurability, we have (for some $G_1, G_2 \subset E$, etc),
$$F\cap A\subset A \subset G_1 \text{ and } F\setminus A\subset E\setminus A\subset G_2$$
and
$$\mu^*(F)+\mu^*(F\setminus A)\leq \mu(G_1)+\mu(G_2)=\mu(G_1 \cup G_2) + \mu(G_1\cap G_2)$$
but $G_1\cup G_2=E$, so the right hand side above is less than $1+\epsilon$. But I don't really see how this helps. We can conclude the left hand side is less than or equal to $1$ then since $\epsilon$ was arbitrary but I don't think I'm approaching this correctly. Any suggestions would be greatly appreciated, thanks.","['real-analysis', 'measurable-sets', 'measure-theory']"
1563742,Cofactor multiplied with another row [duplicate],"This question already has answers here : Taking product of cofactor with different row (2 answers) Closed 5 years ago . Why is it that when I add up the product of cofactors for one row and a corresponding element of any other row , the answer is 0?
For example: This seems to work for all matrices but I'm unable to figure out why.","['matrices', 'determinant']"
1563756,Let $f$ be analytic function defined on the open unit disc in $\mathbb{C}$. Then which are of the following true?,"Let $f$ be analytic function defined on the open unit disc in $\mathbb{C}$ . Then $f$ is constant if $1.~~f\left(\frac{1}{n}\right)=0$ for all $n\geq1.$ $ 2. ~~f(z)=0$ for all $|z|=1/2$ $ 3. ~~f\left(\frac{1}{n^2}\right)=0$ for all $n\geq1.$ $ 4. ~~f(z)=0$ for all $z\in (-1,1)$ I used Identity theorem and conclude that $1$ , $3$ and $4$ are true. But I am confused with $2$ . Please help me with some hints or ideas.",['complex-analysis']
1563760,Convergence in distribution and characteristic function,"Convergence in distribution ( Two equivalent definitions) I am referring to the above problem. There was one thing in the proof that I was not clear. Once we have the $\textbf{existence of a}$ weakly convergent subsequence.  The distribution, call it $\mu$, this subsequence converges weakly to, must have characteristic function $\phi$
. Moreover, $\textbf{every subsequence has a further subsequence}$ that converges weakly to $\mu$. Using again the Portmanteau Theorem characterization mentioned above (and a general topological fact: if every subsequence has a further subsequence that converges to some point, then the whole sequence converges to that point) one can show that the whole sequence of distributions. But we only find one subsequence that converges weakly, how can we get the conclusion that this is for $\textbf{every}$ subsequence converges weakly. I mean, we may just have one such subsequence.","['weak-convergence', 'probability-theory', 'convergence-divergence']"
1563862,"Evaluate the indefinite integral $\int\sin2x(\cos2x+1)^{1/2}\, dx$.","Evaluate the indefinite integral $$\int \sin 2x \sqrt{\cos2x+1}\ dx$$ Hello, I am a Calc I student currently working on substitution, and cannot find a solution to this particular problem. Thank you for your time!","['indefinite-integrals', 'substitution', 'integration', 'trigonometry']"
1563866,"Understanding proof by infinite descent, Fermat's Last Theorem.","See here . The question is as follows. How do we see that there do not exist nonconstant, relatively prime, polynomials $a(t)$, $b(t)$, and $c(t) \in \mathbb{C}[t]$ such that$$a(t)^3 + b(t)^3 = c(t)^3?$$ There is the following answer, purportedly elementary. We give a completely elementary proof simply working in the ring $\mathbb{C}[t]$ and using that it is a UFD. Suppose there are some solutions of$$a(t)^3 + b(t)^3 = c(t)^3$$in $\mathbb{C}[t]$. Choose a solution $(a(t), b(t), c(t))$ such that the maximum $m > 0$ of the degrees of $a$, $b$, $c$ is minimal possible among all solutions. Clearly, this choice ensures that $a(t)$, $b(t)$, $c(t)$ are coprime. Then we have$$a(t)^3 = c(t)^3 - b(t)^3 = (c(t) - b(t))(c(t) - \omega b(t)) (c(t) - \omega^2 b(t)),$$where $\omega$ is a third primitive root of unity. Now, we look at the factors $c(t) - b(t)$, $c(t) - \omega b(t)$. Suppose that they have a common factor $q(t)$. Considering their sum and difference, we conclude that $c(t)$ and $b(t)$ have a common factor too. Moreover, $q(t)$ is a factor of $a(t)$. Thus, $a$, $b$, $c$ are not relatively prime, which is a contradiction. Repeating the same game with other pairs of factors, we see that all three factors $c(t) - b(t)$, $c(t) - \omega b(t)$, $c(t) - \omega^2 b(t)$ are pairwise coprime. Therefore,$$c(t) - b(t) = d_1(t)^3,\text{ }c(t) - \omega b(t) = d_2(t)^3,\text{ }c(t) - \omega^2b(t) = d_3(t)^3,\text{ where }d_1,\,d_2,\,d_3 \in \mathbb{C}[t].$$Note that$$\omega^2 + \omega + 1 = 0.$$Multiplying the second equation by $\omega$ and the third equation by $\omega^2$ and adding all three, we arrive at $$d_1(t)^3 + \omega d_2(t)^3 + \omega^2d_3(t)^3 = 0.$$Choosing $\eta_1$ and $\eta_2$ as any third roots of $-\omega$ and $-\omega^2$, respectively, and letting$$a_1 = d_1^3,\text{ }b_1 = \eta_1d_2^3,\text{ }c_1 = \eta_2d_2^3,$$we get$$a_1^3 = b_1^3 + c_1^3.$$By construction, at least one of $a_1$, $b_1$, $c_1$ is a nonconstant polynomial, and the maximum of their degrees is smaller than that of $a$, $b$, $c$. This is a contradiction to the choice of $a$, $b$, $c$. Unfortunately, I have never seen any abstract algebra before (I am only a student who has taken calculus), and therefore, do not really understand what is going on, aside from the fact infinite descent is being invoked. Can anyone explain the motivation/what is going on/the key steps/help me understand the proof? Thanks.","['polynomials', 'abstract-algebra', 'algebraic-number-theory', 'number-theory', 'ring-theory']"
1563896,"Given 100 coin tosses, the largest string of same results in a row is...?","My question is, if someone tossed a fair coin 100 times, what is the most number of times that a result will likely present itself in a row. Alternatively put, what is the largest string of consecutive flips of the same result that has a probability of occurring >50% in 100 coin flips. Conversely, I think this question can be answered by giving the equation for the expected number of flips of a fair coin before X number of consecutive flips  are the same results (without constraining that the results be heads or tails).","['statistics', 'probability']"
1563905,"Roots of unity filter, identity involving $\sum_{k \ge 0} \binom{n}{3k}$","How do I see that$$\sum_{k \ge 0} \binom{n}{3k} = (1 + 1)^n + (\omega + 1)^n + (\omega^2 + 1)^n,$$where $\omega = \text{exp}\left({2\over3}\pi i\right)$? What is the underlying intuition behind this equality?","['algebra-precalculus', 'generating-functions', 'combinatorics', 'contest-math', 'summation']"
1563907,Is the inverse of an invertible circulant matrix also circulant?,"The circulant matrices in $M_n(F)$ ($F$ field) form a subspace $\mathcal C_n$ spanned by $I,J,J^2,\cdots,J^{n-1}$ where
$$J=\begin{bmatrix} O & I_{n-1}\\1 &  O\end{bmatrix}$$
This subspace $\mathcal C_n$ is also closed under multiplication, which makes it a subring of $M_n(F)$. Now my question is, if $A\in \mathcal C_n$ and $A$ is non-singular, can we assert that $A^{-1}\in\mathcal C_n$ too? I'm in particular encouraged to make this guess by observing  these examples: $$\begin{bmatrix}0 & 1 & 1 & \cdots & 1\\ 1 & 0 & 1 & \cdots & 1 \\ 1 & 1 & 0 & \cdots & 1\\ \vdots & \vdots & \vdots & & \vdots \\ 1 & 1 & 1 & \cdots & 0 \end{bmatrix}^{-1}=\frac{1}{n-1}\begin{bmatrix} 2-n & 1 & 1 & \cdots & 1\\ 1 & 2-n & 1 & \cdots & 1 \\ 1 & 1 & 2-n & \cdots & 1\\ \vdots & \vdots & \vdots & & \vdots \\ 1 & 1 & 1 & \cdots & 2-n \end{bmatrix}$$
and
$$
\begin{bmatrix}
   1 & 2 & 3 & \cdots & n-1 & n \\
   n & 1 & 2 & \cdots & n-2 & n-1\\
   n-1 & n & 1 & \cdots & n-3 & n-2 \\
   \vdots & \vdots & \vdots & & \vdots & \vdots \\
   2 & 3 & 4 & \cdots & n & 1
\end{bmatrix}^{-1}=
\frac1{ns}
\begin{bmatrix}
  1-s & 1+s & 1 & \cdots & 1 & 1\\
  1 & 1-s & 1+s & \cdots & 1 & 1 \\
  1 & 1 & 1-s & \cdots & 1 & 1\\
  \vdots & \vdots & \vdots & & \vdots & \vdots \\
  1+s & 1 & 1 & \cdots & 1 & 1-s
\end{bmatrix}
$$
in which $s:=1+2+\cdots+n$.","['matrices', 'linear-algebra']"
1563930,Functional equation $f\left(\frac{1}{x}\right)+(x+1)f(x)=1$,"Find all functions $f$ such that $f\left(\frac{1}{x}\right)+(x+1)f(x)=1,\space x\neq0$.","['functions', 'functional-equations']"
1563986,Factorials in different base,"Got an interesting problem from a friend. How many zeroes does $n!$ end in when written in base $n$? For every factor of $n$ in $n!$, I know that there will be $1$ $0$ added. However, I'm not really sure how to proceed from here. EDIT: A question I'm curious about: what would the value of $\frac{\#\{\text{number of zeros in $n!$ in base $n$}\}}{n}$ be?","['number-theory', 'factorial']"
1564018,Limits using L'Hopital's rule $\lim_{x\to0^+} (x^{x^x-1})$,"Could you help me with this one? Thanks. The answer should be 1, somehow. I tried everything I know, but I couldn't solve it. $$\lim_{x\to0^+} (x^{x^x-1})$$","['exponentiation', 'calculus', 'limits']"
1564024,Ideal of affine algebraic variety is radical,"In remark 1.15(c) of these notes by Gathman, it is said that for a ring $R$, an ideal of an affine variety is radical, for if $f\in \sqrt I$ then $f^k|_X=0$ and hence $f|_X=0$ meaning $f\in I$. I'm confused. If ""ideal of an affine algebraic variety $X$"" just means an ideal of $R$ which is a subset of $X$, then why would it be radical if $R$ is not reduced?","['algebraic-geometry', 'commutative-algebra']"
1564045,Projective Resolution of $C^{\infty}(V)$ by Connes,"In his article Noncommutative differential geometry (Inst. Hautes Études Sci. Publ. Math. No. 62 (1985), 257–360) A. Connes gives in Lemma 44 (p. 343f) a projective topological resolution of the module $C^{\infty}(V)$ over $C^{\infty}(V \times V)$ for a smooth compact manifold $V$. The basic construction is as follows: One considers the complex bundles $E_k$ on $V \times V$ given by the pull back of the projection $\mathrm{pr}_2\colon V \times V \to V$ onto the second coordinate of the exterior power $\bigwedge^k T_{\mathbb{C}}^* V$ of the complexified cotangent bundle of $V$.  Now, if the Euler characteristic of $V$ vanishes, one finds a section $X$ of $E_1^*$ which does not vanish outside the diagonal. Connes then states that a resolution is given by $$C^{\infty}(V) \xleftarrow{\Delta^*} C^{\infty}(V \times V) \xleftarrow{\iota_X} C^{\infty}(V^2, E_1) \xleftarrow{\iota_X} \cdots \leftarrow C^{\infty}(V^2, E_n) \leftarrow 0,$$ where $n$ is the dimension of $V$. For the proof Connes chooses smooth cut-offs $\chi$ and $\chi'$ in $C^{\infty}(V \times V)$ such that $X(a,b) = \exp_b^{-1}(a)$ for $(a,b)$ in the support of $\chi'$ and $\chi' = 1$ on the support of $\chi$ which itsself satisfies $\chi = 1$ in a neighbourhood of the diagonal $\Delta$. We do not understand a conclusion at the very end of the proof. Connes defines the section
$$s(\omega) = \chi' \int_0^1 \varphi_t^*(d_b(\chi \omega)) \frac{dt}{t} + (1-\chi) \omega' \wedge \omega.$$
Then he proves that for every form $\omega_1 \in E_k$ vanishing off the support of $\chi$ and statisfying $\omega_1(a,a) = 0$ (i.e. $\omega_1$ vanishes on the diagonal) one has
$$\int_0^1 \phi_t^* d(\iota_X \omega_1) + \iota_X \int_0^1 \varphi_t^* d\omega_1 \frac{dt}{t} = \omega_1.$$
Finally, he applies the above identiy to the form $\omega_1 = \chi \omega$, a smooth cut-off of an arbitray given form $\omega \in E_k$. But why does $\omega_1$ vanish on the diagonal and one can therefore apply the above identity? Can anyone clarify this step? Searching through the web, everyone seems to give more or less this proof due to Connes and therefore further literature was no help.","['differential-geometry', 'noncommutative-geometry', 'commutative-algebra']"
1564052,"Positively invariant $(S,I)$-triangle for SIS dynamical system","Consider the following differential equations $${dS \over dt} = \lambda-\beta SI-\mu S+\theta I$$ $${dI \over dt} =\beta SI-(\mu +d)I-\theta I$$ In all papers that I have read it is only mentioned that $$\Omega = \left\{ (S,I) : I\geq 0, S \geq 0, S+I \leq {\lambda \over \mu} \right\}$$ is positively invariant. How can I explicitly show that the set $\Omega $ is positively invariant?","['set-invariance', 'ordinary-differential-equations', 'dynamical-systems']"
1564065,Dominated convergence with $g$ depending on $n$,"I have a question about dominated convergence. Suppose I have a functions $f_n(x)$ which converge pointwise to $f(x)$. Furthermore, I know that $|f_n(x)|\leq g_n(x)$ for all $n$ and $x$, where $g_n(x)$ has limit $g(x)$.  If I also know that 
$$\lim_{n\to\infty}\int g_n(x)dx=\int g(x)dx,$$ can I conclude that 
$$\lim_{n\to\infty}\int f_n(x)dx=\int f(x)dx?$$ (This is basically the dominated convergence theorem, with $g$ replaced by $g_n$.)","['integration', 'measure-theory', 'convergence-divergence']"
1564079,Residue of $\frac{g(z)}{\cos^{2}z}$,"I would like to show that the residue of the function $$\text{Res}\left(\frac{g(z)}{\cos^{2}z}\right) = g'(z_n)$$ at $z_{n}=(n+\frac{1}{2})\pi$, where $g$ is analytic. I tried the Limit formula for higher order poles and it fails. What other method can  I use?",['complex-analysis']
1564087,Prove ln(n) diverges as quickly as the harmonic series.,"Question: Find a (simple) $f(n)$ so that $\lim\limits_{n \rightarrow \infty} \frac{n \sum\limits_{k=1}^{n} \frac{1}{k}}{f(n)} = 1$ My Attempt: I know the answer, by using Mathematica, is $f(n) = n \cdot ln(n)$. I, however, can't find a way to prove this. I've only tried $$\lim\limits_{n \rightarrow \infty} ln(n) = \int\limits_{1}^{\infty} \frac{1}{x} \ dx \approx \sum\limits_{k=1}^{\infty} \frac{1}{k} = \lim\limits_{n \rightarrow \infty} \sum\limits_{k=1}^{n} \frac{1}{k}$$
But that doesn't seem entirely correct. Does anybody know a way to prove this limit? Thanks in advance!","['harmonic-functions', 'proof-verification', 'limits']"
1564153,Recurrence relation $T(n+1)=T(n)+⌊\sqrt{n+1}⌋$?,"Consider the following recurrence relation $T(1)=1$ $T(n+1)=T(n)+⌊\sqrt{n+1}⌋$ for all $n≥1$ The value of $T(m^2)$ for $m≥1$ is $(m/6) (21m – 39) + 4$ $(m/6) (4m^2 – 3m + 5)$ $(m/2) (m^{2.5} – 11m + 20) – 5$ $(m/6) (5m^3 – 34m^2 + 137m – 104) + (5/6)$ My attempt : I've used counter example to choose correct option. $m = 3$ $T(9) = T(4) + 2*5 + 1 = 5 + 10 + 1 = 16$ Both options $(1)$ & $(2)$ produces $16$. $m = 4$ $T(16) = T(9) + 3*7 + 1 = 16 + 21 + 1 = 38$
Only option $(2)$ produces $38$, $(1)$ produces $34$ which doesn't match. Can you explain in formal way, please?","['recurrence-relations', 'algorithms', 'recursive-algorithms', 'discrete-mathematics']"
1564168,Divergence operator of higher order and intrinsic point of view,"Let $\underline{u}$ be a $1$ - order tensor (say a column vector) I want to prove that : $\underline{\operatorname{div}}  \left( (\underline{\underline{\operatorname{grad}}} \, \underline{u})^T\right)= \underline{\operatorname{grad}} \, (\operatorname{div} \underline{u})$ where $\underline{\operatorname{grad}}$ is the one order gradient (the usual one) and $\underline{\underline{\operatorname{grad}}}$ is the second order gradient (it is the jacobian matrix) I want a proof that those not involve any coordinates. Because it is easy to find a proof using for example cartesian coordinates. Here is what I've done so far : Since for any volume $V$ we have : $$\iiint _V \underline{\operatorname{div}}  \left( (\underline{\underline{\operatorname{grad}}} \, \underline{u})^T\right) \; \mathrm{d}V = \iint_{S} (\underline{\underline{\operatorname{grad}}} \, \underline{u})^T \cdot \underline{n}  \; \mathrm{d}S$$ (it it the definition of $\underline{\operatorname{div}}$)  where $\underline{n}$ is the normal vector to the surface $S$ at the limit of the volume $V$. And we can write : $$\iiint_V \underline{\operatorname{grad}} \, (\operatorname{div} \underline{u}) \; \mathrm{d}V = \iint_S (\operatorname{div} \underline{u} )\underline{n} \; \mathrm{d}S$$ Thus it is sufficient to prove that : $$\iint_{S} (\underline{\underline{\operatorname{grad}}} \, \underline{u})^T \cdot \underline{n}  \; \mathrm{d}S =\iint_S (\operatorname{div} \underline{u} )\underline{n} \; \mathrm{d} S$$ The problem is that we don't have $ (\underline{\underline{\operatorname{grad}}} \, \underline{u})^T \cdot \underline{n} = (\operatorname{div} \underline{u} )\underline{n} $ So how can I finish the proof ? If you need details, please tell me. Thank you.","['real-analysis', 'tensors', 'analysis', 'vector-analysis']"
1564178,Maximum of martingales,"I need to show whether or not the maximum of two martingales is also a martingale. Originally, I thought yes. But supposedly the answer is no. So as a counter-example, let $U_i$ be $iid$ $unif(0,1)$, $X_0 = 1$, and
$$X_n = 2^n\prod_{k=1}^n U_k.\tag{1}$$ 
I already know that $X_n$ is a martingale. For my second martingale, let $\xi_i$ be $iid$ $Bern(p),0<p<1$, $Y_0 = 1$,
and
$$Y_n = p^{-n}\prod_{k=1}^n \xi_i.\tag{2}$$
I already know that $Y_n$ is a martingale. So let $W_n = \max(X_n,Y_n)$.
What I did was I tried to get the distribution of $W_n$ using the CDF and I ended up with
$$F_W(w) = \left(\frac{w}{2}\right)^n(1-p)^n$$ But then I got stuck. I'm not sure what to do with this. I'm not even actually sure if I am on there right track. How can I proceed to show that $W_n$ is not a martingale? Any help is appreciated. Thanks. EDIT: I forgot to mention that $X_n,Y_n$ are martingales with respect to the same filtration. However , in my class, we had a rudimentary treatment of martingales. The main definition I know/we use is: A stochastic process $\{X_n;n = 0,1,\dotsc\}$ is a martingale if for $n = 0,1,2,\dotsc,$ $E[|X_n|] <\infty$, and $E[X_{n+1}|X_0,\dotsc,X_n] = X_n$. This is the level of detail I need. This is what did to ""show"" that the sum of martingales is also a martingale: Given that $(X_n)$ and $(Y_n)$ are martingales with respect to the same filtration, $E[|X_n|]<\infty$ and $E[|Y_n|]<\infty$. Then
$$E[|Z_n|] = E[|X_n+Y_n|] \leq E[|X_n|] + E[|Y_n|] <\infty,$$
and
\begin{align*}
E[Z_{n+1}|\mathcal F_n] &= E[X_{n+1}+Y_{n+1}|\mathcal F_n] \\
&= E[X_{n+1}|\mathcal F_n]+E[Y_{n+1}|\mathcal F_n] \\
&= X_n + Y_n = Z_n.
					\end{align*}
Therefore $(Z_n)$ is a martingale. So, this is the level of detail I'm expected to know. So I'm stuck showing that the maximum of two martingales is not (necessarily) a martingale.","['stochastic-processes', 'independence', 'probability-theory', 'martingales', 'uniform-distribution']"
1564204,Finding the sum of n terms $S_n$ starting from sigma $k=0$,"$$\sum_{k=0}^{n} ((4k-3)\cdot 2^k)+4=(2^{n+3}+4)n-7\cdot2^{n+1}+15$$ How? I've tried everything but i don't see it. Any equivalent solutions are also welcome, thanks.","['recurrence-relations', 'recursion', 'discrete-mathematics']"
1564230,Integral of the principal value of a hypergeometric function,"I am looking to write the hypergeometric function $${}_2F_1\left(1,1,2+\epsilon, -\frac{\alpha}{\beta}\right) = \int_0^1\,dt\,\frac{(1-t)^{\epsilon}}{1-tz + i\delta},$$ where $z=-\alpha/\beta$ and $0< \beta < - \alpha$, in terms of its real and imaginary part.  The $i\delta$ prescription is to shift the denominator away from the pole at $t=1/z$. I know that $$\frac{1}{1-tz+i\delta} = \text{P.V} \frac{1}{1-tz} -i\pi \delta(1-tz)$$ so to compute the real part I am left with the problem with finding $$\text{P.V}\int_0^1\,dt\,\frac{(1-t)^{\epsilon}}{1-tz}$$ I tried writing this as $$\lim_{\tau \rightarrow 0} \left(\int_0^{1/z-\tau} + \int_{1/z+\tau}^1\right)\frac{(1-t)^{\epsilon}}{1-tz} dt$$ but I am not sure how to progress. I tried using the residue theorem and coming up with a closed contour but the limits do not extend to $\pm \infty$. Any help would be great,  thanks! Edit: I thought maybe I could change variables in the last equation such that the resulting transformation puts the limits on the integration to be $0$ and $1$ and maybe then identify the real part as other (different) hypergeometrics, but I can't see such a transformation yet.","['complex-analysis', 'hypergeometric-function', 'residue-calculus', 'cauchy-principal-value']"
1564309,Do torsion and curvature have higher order analogues?,"Consider the usual formulas for the Torsion and Curvature of an affine connection: $$T(X,Y)=\nabla_X Y -\nabla_Y X-[X,Y]$$
$$R(X,Y)=\nabla_X\nabla_Y-\nabla_Y\nabla_X-\nabla_{[X,Y]} $$ These formulas are clearly formally alike; can one still obtain tensors (i.e. geometric quantities) by wisely applying ""higher-order"" derivatives?","['riemannian-geometry', 'differential-geometry', 'curvature']"
1564322,Length of a side of a triangle given the angles and the area,"We have $\triangle ABC$ with the following measures: $A = 65^\circ$,
$B= 75^\circ$, 
$\text{area}= 88\,m^2$. How can I determine the longest side?","['trigonometry', 'geometry']"
1564333,Maximum Baire class of a Riemann integrable function,"In this answer (see example 1), Andrés Caicedo gives an example of a function $f : [0,1] \to \mathbb{R}$ which is Riemann integrable and is (strictly) of second Baire class. Are there Riemann integrable functions of higher Baire class?  Arbitrarily high?  Are there Riemann integrable functions which are not in any Baire class? To be precise, recall that for an ordinal $\alpha$, the Baire class $B_{\alpha}$ is defined inductively as follows.  $B_0$ is the set of all continuous functions $f : [0,1] \to \mathbb{R}$.  Then, once $B_\beta$ are constructed for all $\beta < \alpha$, we say $f \in B_\alpha$ if there exists a sequence $f_n \in \bigcup_{\beta < \alpha} B_\beta$ with $f_n \to f$ pointwise.  Note that this stabilizes at $\alpha = \omega_1$. If $\mathcal{R}$ is the set of all Riemann integrable functions, my question is: do we have $\mathcal{R} \subset B_\alpha$ for some $\alpha$?  If so, what is the least such $\alpha$?  If not, what is the least $\alpha$ such that $\mathcal{R} \cap B_{\omega_1} \subset B_\alpha$? Of course, it may be helpful to recall that $f$ is Riemann integrable iff the set of discontinuities of $f$ has Lebesgue measure zero.","['descriptive-set-theory', 'real-analysis', 'measure-theory', 'riemann-integration']"
1564354,Series' convergence - making my ideas formal,"Find the collection of all $x \in \mathbb{R}$ for which the series $\displaystyle \sum_{n=1}^\infty (3^n + n)\cdot x^n$ converges. My first step was the use the ratio test: $$ \lim_{n \to \infty} \dfrac{(3^{n+1}+n+1) \cdot |x|^{n+1}}{(3n+n) \cdot |x|^n} = \lim_{n \to \infty} \dfrac{3^{n+1}|x|+n|x|+|x| }{3^n+n} = \lim_{n \to \infty} ( \dfrac{3^{n+1}|x|}{3^n+n} + \dfrac{n|x|}{3^n+n} + \dfrac{|x|}{3^n+n}) $$ $$ = \lim_{n \to \infty} (\dfrac{3|x|}{1+\dfrac{n}{3^n}} + \dfrac{|x|}{\dfrac{3^n}{n} + 1} + \dfrac{|x|}{3^n + n}) = 3|x| + 0 + 0 = 3|x| $$ So we want $3|x| < 1$, i.e. $|x| < \dfrac{1}{3}$. But we have to also check the points $x=\dfrac{1}{3}, -\dfrac{1}{3}$, where the limit equals $1$. For $x=\dfrac{1}{3}$ we have $\displaystyle \sum_{n=1}^\infty (3^n + n)\cdot (\dfrac{1}{3})^n = \displaystyle \sum_{n=1}^\infty (1 + n \cdot \dfrac{1}{3}^n)  $ which obviously diverges. For $x=-\dfrac{1}{3}$ we have $\displaystyle \sum_{n=1}^\infty (3^n + n)\cdot (-\dfrac{1}{3})^n = \displaystyle \sum_{n=1}^\infty ((-1)^{n} + n \cdot (-\dfrac{1}{3})^n)$. Now I know this diverges because $(-1)^n$ and $(-\dfrac{1}{3})^n$ have alternating coefficients. But is there a theorem that I can use here? So we conclude that $|x| < \dfrac{1}{3}$, but is the above work enough to show it conclusively?","['convergence-divergence', 'limits']"
1564360,Sum of the supremum and supremum of a sum,"Consider two real-valued functions of $\theta$, $f(\cdot): \Theta \subset\mathbb{R}\rightarrow \mathbb{R}$ and $g(\cdot):\Theta \subset \mathbb{R}\rightarrow \mathbb{R}$. Is there any relation between (1) $\sup_{\theta \in \Theta} (f(\theta)+g(\theta))$ and (2) $\sup_{\theta \in \Theta} f(\theta)+\sup_{\theta \in \Theta} g(\theta)$ ? Could you provide some informal proof or intuition behind your answer?","['supremum-and-infimum', 'calculus']"
1564365,Find the maximun of the sum $\sum_{k=1}^{n}(f(f(k))-f(k))$,"Let $f:\{1,2,3,\cdots,n\}\to \{1,2,3,\cdots,n\}$ such that $$f(1)\le f(2)\le\cdots\le f(n)$$ Let $g(n)$ $$g(n)=max\left(\sum_{k=1}^{n}(f(f(k))-f(k))\right)$$ Find $$g(n)$$","['summation', 'optimization', 'functions']"
1564377,Derivative of dot product,"Let $\frac{dy}{dt}=Ay+g(y)$ and consider $\lVert y(t)\rVert^2=\langle y,y\rangle$. I would like to prove that
$$
\frac{d}{dt}\langle y,y\rangle= 2\langle\frac{dy}{dt},y\rangle.
$$ To do so, I made the following start: $$
\langle y+\Delta y,y+\Delta y\rangle=\langle y,y\rangle+2\langle\Delta y,y\rangle+o(\lVert \Delta y\rVert)\text{ as }\Delta y\to 0.
$$ So the derivative seems to arise from the summand
$$
2\langle\Delta y,y\rangle.
$$
But how? It seems to be
$$
2\langle\Delta y,y\rangle=2\langle\dot{y},y\rangle\Delta y?
$$",['derivatives']
1564393,What to do with this,"Prove that
$$
\int^{1}_{0} \frac{\ln \left(\cos \left(\frac{\pi x}{2} \right)\right)}{x(x+1)}dx=\frac{1}{2} (\ln 2)^2-\ln \pi \ln2   
$$ I separated them 
$$
\int^{1}_{0} \frac{\ln \left(\cos \left(\frac{\pi x}{2} \right)\right)}{x}dx-\int^{1}_{0} \frac{\ln \left(\cos \left(\frac{\pi x}{2} \right)\right)}{x+1}dx
$$ For the former integral i tried to use differentiation under integration but got stuck and i have no idea about the latter one. Plz help!","['integration', 'definite-integrals']"
1564397,proof that $x/c^x$ goes to 0,"Im trying to show that $\lim_{x\to\infty}\frac{x}{c^x}$ where $c>1$ is a constant goes to zero.  To show this i know i need to take some $\epsilon$ and find some $m$ such that $\forall x>m$, $|\frac{x}{c^x}|<\epsilon$.  However, im having trouble finding $m$. What is the usual way people go to find $m$?","['real-analysis', 'limits']"
1564426,Examples for the Kuratowski–Fréchet theorem,I was wondering what kind of applications or basic exercises we can create with this powerful result https://en.wikipedia.org/wiki/Kuratowski_embedding Thanks in advance!,"['functional-analysis', 'banach-spaces']"
1564439,Interpretation of Hellinger distance,"Given to discrete probability distribution $\mathbf{p}:=(p_1,p_2,\dots,p_n)$ and $\mathbf{q}:=(q_1,q_2,\dots,q_n)$, the Hellinger distance between $\mathbf{p}$ and $\mathbf{q}$ is defined as:
$$
d_H(\mathbf{p},\mathbf{q}):=\frac{1}{\sqrt{2}}\left\|\mathbf{p}^{1/2}-\mathbf{q}^{1/2}\right\|_2=\frac{1}{\sqrt{2}}\left(\sum_{i=1}^n \left(\sqrt{p_i}-\sqrt{q_i}\right)^2\right)^{1/2},
$$ Why is this distance extensively exploited in statistics and probability? What is the geometrical/statistical interpretation of this distance? Assuming that $\mathbf{p},\mathbf{q}$ represent vectors and not probability distributions, has this distance been studied in other areas different from statistics? My questions are not technical, but I was not able to find references which clearly address them. Thank you for your help.","['reference-request', 'statistics', 'probability']"
1564464,How to find the period of periodic solutions of the van der Pol equation?,The equation $$y''+1.115(y^2-1)y'+y=0$$  has solutions that tend towards periodic solutions and I am asked to enter the period of the periodic solutions. How can I find the period without any boundary conditions? And what is the period?,"['ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
1564495,Asymptotic analysis of non-linear ODE,"I'm looking for references on the topic of asymptotic analysis of non linear ODE's of the sort
$$
x'' + x'x = 0
$$
This specific case has an analytic solution (with some $\tanh(\cdots)$ involved) and quickly converges to a real value; in my case, I'm dealing with ""similar"" equations, with some form of $x'x$ involved.","['reference-request', 'asymptotics', 'ordinary-differential-equations', 'dynamical-systems']"
1564507,How do I find the matrix with respect to a different basis?,"I tried to solve this question but the answer is totally different, can you explain how to solve it","['matrices', 'linear-algebra', 'transformation']"
1564516,How to determine if an equation is algebraically solvable?,"Problem I was given the following equation to solve for $x$: $$35x^{9 / 5} + 180x^{7 / 5} + 252x = 50400 / \pi$$ But don't get hung up on it. It's only an example. My solution ...was simply to use a calculator, which gave me a seemingly irrational number, which is understandable given the presence of pi. But at the same time, I was wondering if this equation was solvable by typical algebraic methods, like substitutions yielding a quadratic equation for example. But more generally, I started wondering how I could determine whether or not it is solvable algebraically. Question Do we have any ""if such-and-such is not satisfied, go numerical"" rules of thumb? Or do we just make a judgment call?","['algebra-precalculus', 'numerical-methods']"
1564554,"Is there an analytic function $f$ on $B(0,1)$ the open ball with radius 1 such that $f(1/n)=e^{-n}$ for $n=2,3,4,...$?","Is there an analytic function $f$ on $B(0,1)\subset\mathbb{C}$ such that $f(1/n)=e^{-n}$ for $n=2,3,4,...$? I know the following doesn't work: Let $g(z)=\exp(-1/z)$. Then, $f=g$ on a sequence with a limit point in $B(0,1)$ and so $f=g$ on $B(0,1)$. Since $g$ is not $\mathbb{C}$-differentiable at $0$, neither is $f$ and so such a function cannot exist. This is not the solution because you cannot use the identity principle with a non analytic function like $\exp(-1/z)$ is not analytic at $z=0$. Any help using the identity principle another way?",['complex-analysis']
1564571,Double integral - Change of Variables,"I am trying to evaluate this double integral, but I don't see any good change of variables (I tried polar, but it got really hairy): $$
\iint_D \sqrt{(x-1)^2+y^2} \, dx \, dy
$$
given $D = \{(x,y):x^2+y^2 \le 1, y>0\}$","['multivariable-calculus', 'integration']"
1564584,Prove uniform distribution,"For any random variable $X$, there exists a $U(0,1)$ random variable $U_X$ such that $X=F_X^{-1}(U_X)$ almost surely. Proof:
In the case that $F_X$ is continuous, using $U_X=F_X(X)$ would suffice.
In the general case, the statement is proven by using $U_X=F_X(X^-)+V(F_X(X)-F_X(X^-))$, where $V$ is a $U(0,1)$ random variable independent of $X$ and $F_X(x^-)$ denotes the left limit of $F_X$ for $x\in\mathbb{R}$. How does one easily see/show that $U_X$ in the general case is a $U(0,1)$ random variable?","['statistics', 'probability', 'order-statistics', 'probability-distributions']"
1564587,$\frac{\Gamma(\frac{n_T + n_C - 2}{2})}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1}$,"In this answer to a question I asked (which derives the variance of Cohen's $d$), the approximation $$\frac{\Gamma\left(\frac{n_T + n_C - 2}{2}\right)}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1}$$
is used. We can reasonably assume that $n_T, n_C> 0$ are integers. How is this approximation derived? The answerer states: I pulled it from the Hedges paper -- don't know its derivation at the moment but will think about it some more. I wish I had more to contribute to this question than that, but the removal of the $\Gamma$ function I find completely baffling, and I wouldn't even know where to start. Edit : Currently trying out Stirling's approximation, seeing if that leads me anywhere. And so far, I'm quite lost as to how to deal with the division by $2$ in the $\Gamma$ functions.","['statistics', 'gamma-function']"
1564598,There are 31 houses on north street numbered from 1 to 57. Show at least two of them have consecutive numbers.,I thought to use the pigeon hole principle but besides that not sure how to solve.,"['pigeonhole-principle', 'discrete-mathematics']"
1564609,Evaulate $\cosh(1-i\sqrt{3})$,Going through some exercises in complex functions and I get $\frac{1}{2}(ee^{-i\sqrt{3}} + e^{-1}e^{i\sqrt{3}})$ but not sure if I can simplify this further? Thanks,['complex-analysis']
1564628,Change of scale of periodic function,Could someone show how to prove the following: If $f(x)$ has a period of $p$ show that $f(kx)$ has period of $p/k$.,"['periodic-functions', 'fourier-series', 'functions']"
1564666,Calculate $f(3)$ such that $f(f(x))=x^2-5x+9$,"How can one calculate $f(3)$ when $f(f(x))=x^2-5x+9$ I tried this:
$f(f(3))=3$ I'm stuck here.",['functions']
1564691,Evaluate $\space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt$,"Find the limit $$ \large
\space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt
$$","['integration', 'calculus', 'limits']"
1564704,"How do $P( A | B , C) < P(A| B^c,C)$ and $P( A | B , C^c ) < P(A| B^c,C^c) \Longrightarrow P( A|B) > P(A|B^c)$?","In general, Simpson's Paradox occurs because situation such as following occurs for some arbitrary events $A,B,$ and $C$: $P( A | B , C) < P(A| B^c,C) \tag{1}$ $P( A | B , C^c ) < P(A| B^c,C^c) \tag{2}$ Can someone show me a step-by-step way to arrive at $P( A|B) > P(A|B^c)$ from (1), (2)? The Law of Total Probability $P( A | B ) = P( A | B , C ) P( C | B) + P( A | B, C^c) P(C^c | B)$ appears  somehow involved but I don't see how. Any help would be appreciated.","['simpsons-rule', 'inequality', 'statistics', 'probability', 'paradoxes']"
1564729,Find $\lim_{x\to0}\frac{\sin\left(1-\frac{\sin(x)}{x}\right)}{x^2}$. Is my approach correct?,"Find:
$$
L = \lim_{x\to0}\frac{\sin\left(1-\frac{\sin(x)}{x}\right)}{x^2}
$$ My approach: Because of the fact that the above limit is evaluated as $\frac{0}{0}$, we might want to try the De L' Hospital rule, but that would lead to a more complex limit which is also of the form $\frac{0}{0}$. What I tried is:
$$
L = \lim_{x\to0}\frac{\sin\left(1-\frac{\sin(x)}{x}\right)}{1-\frac{\sin(x)}{x}}\frac{1}{x^2}\left(1-\frac{\sin(x)}{x}\right)
$$
Then, if the limits
$$
L_1 = \lim_{x\to0}\frac{\sin\left(1-\frac{\sin(x)}{x}\right)}{1-\frac{\sin(x)}{x}},
$$ $$
L_2 = \lim_{x\to0}\frac{1}{x^2}\left(1-\frac{\sin(x)}{x}\right)
$$
exist, then $L=L_1L_2$. For the first one, by making the substitution $u=1-\frac{\sin(x)}{x}$, we have
$$
L_1 = \lim_{u\to u_0}\frac{\sin(u)}{u},
$$
where
$$
u_0 = \lim_{x\to0}\left(1-\frac{\sin(x)}{x}\right)=0.
$$
Consequently,
$$
L_1 = \lim_{u\to0}\frac{\sin(u)}{u}=1.
$$ Moreover, for the second limit, we apply the De L' Hospital rule twice and we find $L_2=\frac{1}{6}$. Finally, $L=1\frac{1}{6}=\frac{1}{6}$. Is this correct?","['trigonometry', 'limits']"
1564750,n-cents stamp (Strong induction),"Imagine that your country's postal system only issues 2 cent and 5 cent stamps. Prove that it possible to pay for postage using only these stamps for any amount n cents, where n is at least 4. My attempt (using Strong induction, I know we can use induction but since they say you can can apply strong induction for generalized/weak induction cases): Base case: 
$$n=4: 2 \times2cents$$
$$n=5: 0 \times 5cents$$
$$n=6: 3 \times 2cents$$
$$n=7: 1 \times 2 cents + 1 \times 5 cents$$ You might ask why I have so many base cases, this is my reason why: The question states that we can pay for postage using 2 and 5 cents only. Hence, we have 3 general cases: 1: ONLY 2-cents stamps are used 2: ONLY 5-cents stamps are used 3: 2-cents and 5-cents stamps are used. (Till now, are my base cases valid?) Assume that for n=k, P(k) is true and that we need to show P(k+1) $\textbf{Induction hypothesis:}$ P(k) is true when $4\le i \le k$ and $k \ge 7$ Since $4\le (k-3) \le k$ , P(k-3) or i is true by Induction hypothesis. Now, k-3 cents can be formed using 2 and 5-cent stamps. To get k+1 stamps, we can just replace it with $\textbf{four}$ 2-cent stamps? Thank you! Is my proof valid or no? Any alternatives for this question using strong induction? Also, if I have used strong mathematical induction wrong or any of the steps are incorrect, please explain why.","['proof-explanation', 'alternative-proof', 'proof-verification', 'discrete-mathematics']"
1564757,"(Proof) If $f$ and $g$ are continuous, then $\max\{f(x),g(x)\}$ is continuous","Consider the continuous functions $f,g:\mathbb{R}\rightarrow\mathbb{R}$. Show that $F:\mathbb{R}\rightarrow\mathbb{R}$ with $x\mapsto \max\{f(x),g(x)\}$ is continuous using the $\epsilon - \delta$ definition of continuity. I know there must be four cases. If $f(x)\leq g(x)$ and $f(x_0)\leq g(x_0)$ or if $g(x)\leq f(x)$ and $g(x_0)\leq f(x_0)$ it is easy. However , assuming $f(x_0)\neq g(x_0)$, what if $g(x)\leq f(x)$ and $f(x_0)\leq g(x_0)$ or $f(x)\leq g(x)$ and $g(x_0)\leq f(x_0)$? For example: $|f(x)-g(x_0)|$... how do I get from here to $|x-x_0|$?","['continuity', 'epsilon-delta', 'real-analysis', 'proof-writing']"
1564900,Compute $\lim_{n\to\infty }\int_E \sin^n(x)dx$,"Let $E$ Lebesgue measurable of finite measure. Compute $$\lim_{n\to\infty }\int_E\sin^n(x)dx.$$ I already have the solution, but I did differently, and I would like to know if it's correct or not. We can see that $\sin^n(x)\longrightarrow 0$ pointwise. Let $\varepsilon>0$. By Egoroff theorem there is a closed set $F\subset E$ s.t. $m(E\backslash F)<\varepsilon$ and $\sin^n(x)\to 0$ uniformly. Therefore, $$\int_E|\sin^n(x)|dx\leq \int_{F}|\sin^n(x)|dx+\int_{E\backslash F}dx=m(E\backslash F)+\int_{F}|\sin^n(x)|dx\underset{n\to\infty }{\longrightarrow} m(E\backslash F)<\varepsilon$$
Therefore $$\lim_{n\to\infty }\int_E\sin^n(x)dx=0.$$ Do you think it work ?","['lebesgue-integral', 'measure-theory']"
1564919,Left Inverse and Surjectivness,"I just needed to clarify something. I read the following proposition and something didn't make sense: ""The map $f$ is injective if and only if $f$ has a left inverse"" Now $f$ having a left inverse implies there is a function $g$ whose domain is the codomain of $f$. Every element of the domain of $g$ must have a specified value (by definition), then surely $f$ is also surjective since the codomain of $f$ is its range. My question is, does $f$ having a left inverse imply that $f$  is bijective?",['functions']
1564942,"Let $f(x,y)$ be a continuous function from $R^2$ to $R$. If $f(x,y)=0$, does $y$ vary continuously as $x$ varies?","Let $f(x,y)$ be a continuous function from $R^2$ to $R$. Suppose further that for every $x$, there exists a unique $y$ such that $f(x,y)=0$. Thus we can define the function $g(x)=y$ such that $f(x,y)=0$. Is $g$ is continuous? Hello all, I am working on a project and I have found myself stuck on the question in the title. I am trying to find out if the roots of a continuous function $f(x,y)$ vary continuously as the argument $x$ is allowed to vary. I have a particular function $f$ in my project, but I cannot solve it for $x$ or $y$ so I am trying to do things in the abstract. We can suppose further that there exists a unique $y$ for every $x$ such that $f(x,y)=0$. Thus we can define the function $g(x)=y$ such that $f(x,y)=0$. I want to know if $g$ is continuous. From my attempts to solve this, it seems like the implicit function theorem might point the way, but I am not familiar with that result and it seems like it only gives a continuous function in a subset of the domain. I was hoping to find an elementary answer but having gone though my old topology and analysis textbooks I was not able to find anything helpful.","['general-topology', 'real-analysis']"
1564944,"Over $SET$ category, a relation R there is a contractible pair of morphisms $f,g$ if and only if $[x]$ has one element $x_{*}$ such...","If I am over $SET$ category , I want to prove that given a relation R there is a contractible pair of morphisms $(f,g)$ if and only if every equivalence class $[x]$ has one element $x_{*}$ such  $xRx´$ if and only if $xRx_{*}$ and $x_{*}Rx´$ Definition.- A parallel pair of morphism $f,g:A$ $\rightarrow$ $B$ is contractible if there is a morphism $t:B$  $\rightarrow$ $A$ such  $ft$ = $1_{B}$ and $gtf=gtg$ Can anyone help me out by sketching a proof of the statement since im still new in categories? I was thinking in  think the elements of the equivalnce class $[x]$ as morphisms between objects  $A,B$ of $SET$ so this way the morphism $t$ can be viewed as the element $x_{*}$ but this seems to be a very particular case of the statement. Thanks, I really need to understand the proof of these as statement as soon as possible.","['category-theory', 'elementary-set-theory']"
1564971,Number Theory: Find $m\equiv 1\pmod4$ so that $x^2\equiv -1\pmod{m}$ has no solution.,"I have this problem that I'm a bit stuck on: Find $m\equiv 1\pmod4$ so that $x^2\equiv -1\pmod{m}$ has no solution in $\mathbb{Z}$. So far, I know that $m$ can't be prime because $(\frac{-1}{p})=1$, $p$ prime, whenever $p\equiv 1\pmod4$, where $(\frac{}{})$ is the legendre symbol. Also, I've considered the following: $m=4k+1$, so $(\frac{-1}{m})=(\frac{4k}{m})=(\frac{4}{m})(\frac{k}{m})=(\frac{k}{m})$, but again I get stuck here since $m$ is composite. I think that there is no such $m$, but I'm unsure how to prove it. My Proof So Far Note that if $m=p_1^{k_1}p_2^{k_2}\cdots p_r^{k_r}$, $p_i$ prime, $k_i\geq 1$ then by the Chinese Remainder Theorem, $x^2\equiv -1\pmod{m}$ has a solution $\iff x^2\equiv -1\pmod{p_i^{k_i}}$ for all $1\leq i\leq r$. So, let us take $m=p^k$, $p$ prime, $k\geq 1$. Note that we must have $k>1$ since $k=1\implies m=p\implies (\frac{-1}{m})=1$ since $m\equiv1\pmod4$. ... Now, I know that $m=3^2=9$ works, but I'm not sure how to prove that $({-1\over9})=-1$ since $9$ is composite. I'm also not allowed to use the fact that $x^2\equiv a\pmod{p^n}$ has a solution $\iff ({a\over p})=1$ since we haven't covered this theorem in class.","['number-theory', 'elementary-number-theory', 'prime-numbers', 'modular-arithmetic', 'legendre-symbol']"
1564984,"Number Theory: Reordering $c_1,\dotsc,c_{10}$ so that $(2k-1)\mid(a_k-b_k)$","I have this homework problem that I'm confused on how to do: Given any distinct $z_1,\dotsc,z_{10}\in\mathbb{Z}$, show that one can reorder these as $s_5,s_4,\dots,s_1,t_5,\dotsc,t_1$ so that $(2k-1)\mid(s_k-t_k)$; thus $9\mid(s_5-t_5),7\mid(s_4-t_4),$ etc. I've tried writing $z_i=q_i(2i-1)+r_i$ and comparing the remainders of $s_i$ and $t_i$ modulo $2i-1$, but I haven't been able to solve the problem this way.","['number-theory', 'divisibility', 'modular-arithmetic', 'elementary-number-theory']"
1565043,Using Green's Theorem to find area enclosed by curve,"Use Green's theorem to calculate the area enclosed by the curve: $x^{2/3}+y^{2/3}=4$ Knowing that $A=\frac{1}{2}\int_c xdy-ydx$ I know that there are already some questions and answers on this site regarding Green's theorem, and I've read many of them. I still really do not know how to proceed, though. Any help or direction would be appreciated. Thanks.","['multivariable-calculus', 'parametrization', 'greens-theorem']"
1565067,A Chi-Squared fit of a general quadratic polynomial is done to ten data points. What is the number of degrees of freedom of this fit?,"I think the correct answer is $7$ because the general quadratic is $$y_i=ax_i^2 + bx_i + c$$ Using the formula $$\color{red}{\fbox{Number of degrees of freedom = Number of data points - Number of Parameters}}$$ The $3$ parameters are $y_i,x_i^2,x_i$ So $10-3=7$ degrees of freedom. The correct answer is indeed $7$; But is this because $x_i^2$ 'counts' as $2$ parameters as it's squared (adding the other $x_i$ to make $3$)? I am somewhat new to this idea of degrees of freedom; so I'm not really sure which method is valid, if any?","['statistics', 'proof-verification']"
1565075,Gradient of vector field notation,"Working in 3D. I know that the gradient is a vector operator defined as $\nabla = [\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}]$. The gradient of a scalar scalar-valued function $f(\vec{x})\in\mathbb{R}$ is $\nabla f(\vec{x}) = [\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}]f(\vec{x}) = [\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}]$. This makes sense to me. But if we take the gradient of a vector field, say $\vec{f} = [f_1,f_2,f_3]$, I know that this is $\displaystyle
\nabla \vec{f} =
\begin{bmatrix}
\frac{\partial f_1}{\partial x} &
\frac{\partial f_1}{\partial y} &
\frac{\partial f_1}{\partial z} \\
\frac{\partial f_2}{\partial x} &
\frac{\partial f_2}{\partial y} &
\frac{\partial f_2}{\partial z} \\
\frac{\partial f_3}{\partial x} &
\frac{\partial f_3}{\partial y} &
\frac{\partial f_3}{\partial z} \\
\end{bmatrix}
$. But how did we get to this? Since both $\nabla$ and $\vec{f}$ are vectors, this seems a bit like an outer product, but writing $\nabla \otimes\vec{f}$ turns out to be the transpose of what I want i.e. $\displaystyle
\nabla \otimes\vec{f}=\nabla\vec{f}^T
= 
\begin{bmatrix}
\frac{\partial}{\partial x}\\
\frac{\partial}{\partial y}\\
\frac{\partial}{\partial z}
\end{bmatrix}
\begin{bmatrix}
f_1 & f_2 & f_3
\end{bmatrix}
=
\begin{bmatrix}
\frac{\partial f_1}{\partial x} &
\frac{\partial f_2}{\partial x} &
\frac{\partial f_3}{\partial x} \\
\frac{\partial f_1}{\partial y} &
\frac{\partial f_2}{\partial y} &
\frac{\partial f_3}{\partial y} \\
\frac{\partial f_1}{\partial z} &
\frac{\partial f_2}{\partial z} &
\frac{\partial f_3}{\partial z} \\
\end{bmatrix}
$
Am I not understanding something correctly? What am I doing wrong?","['tensor-products', 'tensors', 'calculus', 'multivariable-calculus', 'vectors']"
1565088,Almost sure convergence of sum implies bounded sumands a.s./Proof of Kolmogorov's continuity theorem,"Yesterday I asked a question about Kallenberg's proof of Kolmogorov's continuity theorem for stochastic processes . I understood that part of the proof, but now i face another problem:
After showing that $\sum_{n=1}^\infty (2^{nc}\xi_n)^a<\infty$ a.s., he then states that $\xi_{n}{<\atop\frown} 2^{-cn}$ a.s. (Where given two nonnegative functions $f$ and $g$, $f{<\atop\frown}g$ means that there exists a constant $c>0$ such that $f\leq cg$). I can't see why this is true since we don't necessarily have this, since we don't have some kind of ""uniform"" convergence, only punctually.
I also thought that the constant would depend on the argument of $\xi_n$, but then all the previous stuff would be unnecessary since we could simply take $c_n(\omega)=2^{cn}\xi_n(\omega)$. I'll post again the parte of the proof for easier reference: Any help is appreciated. Thanks in advance.","['stochastic-processes', 'probability-theory']"
1565089,bounded operator whose image is contained in the image of a compact operator,"Let $A,K$ be 2 linear operators from $X$ to $Y$ (Banach spaces). $A$ is bounded and $K$ is compact. If $A(X)\subset K(X)$, is it true that $A$ is alse compact? I know that if the rank of $K$ is finite, then $A$ must be compact. But I have no idea about the infinite rank case. Any hint would help.","['functional-analysis', 'compact-operators']"
1565119,Is a single point a closed interval?,"For example, is $\{0\}$ considered a closed interval? Why or why not? Doesn't it contain all (it's only) limit point of $0$ ?","['terminology', 'real-analysis']"
1565192,Simplicial Homology Does Not Depend on the Orientation,"Let $K$ be a simplicial complex and denote by $K_1$ and $K_2$ the complexes obteined from $K$ with two different orientations. I want to prove that the simplicial homology groups of $K_1$ and $K_2$ are isomorphic, that is, for each $n$ we have $$ H_n(K_1) \cong H_n(K_2)$$ I have thought about an explicit isomorphism given by sending a simplex to itself but changing the orientation. But I do not know how to explicitly prove that this function induces a ismorphisms in simplicial homology.","['homology-cohomology', 'simplex', 'simplicial-complex', 'algebraic-topology', 'general-topology']"
1565208,Finding $\int_{-\infty}^\infty \frac{x^2}{x^4+1}\;dx$,"$$\int_{-\infty}^\infty \frac{x^2}{x^4+1}\;dx$$ I'm trying to understand trigonometric substitution better, because I never could get a good handle on it.  All I know is that this integral is supposed to reduce to the integral of some power of cosine.  I tried $x^2=\tan\theta$, but I ended up with $\sin\theta\cos^3\theta$ as my integrand.  Can someone explain how to compute this?","['improper-integrals', 'integration', 'trigonometry', 'calculus']"
1565209,Understanding mathematical notation for coding problems.,"The majority of my questions revolve around code (thus my activity on stackoverflow), but I've been going over interview question that assume a good understanding of  mathematical notation. I don't have a great mathematical background, so I am having trouble understanding what the question is actually asking. I am trying to decipher the following question (image because I couldn't figure out formatting): I believe I understand every sentence except the last. Could someone help work through this? I believe with this example decoded, I can work through the majority of the others with some help from here .","['computer-science', 'notation', 'discrete-mathematics']"
1565239,How can I calculate a non-integer power of a number?,"Integer powers are easy to calculate by repeated application of multiplication. However if a power is not an integer then I always need to use my calculator. How can I calculate a non-integer power without a calculator? For example, how does one compute 10 raised to 0.90 without a calculator? The closest I've come to solving the problem is doing fractional power approximations for upper and lower bounds.  For example 10 raised to the .31 is greater than 10 raised to the 1/2 but less than 10 raised to the one third 10 raised to the 1/2 is 1/100.  10 raised to the 1/3 is 1/1000.  But there is no where near to a good answer................. I think",['algebra-precalculus']
1565253,Why does $\frac{d^2y}{dx^2}$ represent the second derivative? [duplicate],"This question already has answers here : Why is $\frac{d^n}{dx^n}(y(x))$ the notation for the $n$th derivative of $y(x)$, instead of $\frac{d^n}{d^nx}(y(x))$? (5 answers) Closed 8 years ago . I know the second derivative of y wrt x: $\frac{d^2y}{dx^2}$ means  $\frac{d}{dx}(\frac{dy}{dx})$, but is there a mathematical reason you square the $d$ in the numerator but the $x$ in the denominator? I've wondered if it's because the $d$ in the denominator represents some arbitrary infinitely tiny amount, and the $d$ in the numerator is that same $d$, only squared to account for the second derivative. Does that make sense, and/or am I missing something significant about derivatives?","['derivatives', 'calculus']"
1565285,"Modes of Convergence, Real Analysis ch 2 problem 36","If $\mu(E_n) < \infty$ for $n\in\mathbb{N}$ and $1_{E_n}\rightarrow f$ in $L^{1}$, then $f$ is (a.e. equal to) the characteristic function of a measurable set. I am not sure how to define $E_n$ in order to prove this, any suggestions is greatly appreciated.","['real-analysis', 'lp-spaces', 'measure-theory', 'elementary-set-theory']"
1565301,How many solutions to $x^2-4x-\cos x=-8$?,"$$x^2-4x-\cos x=-8$$ 
  We want the number of solutions. Now I tried taking $\cos x$ as constant but by formula for root we get a trig equation which can't be solved. Any help? Thanks!","['trigonometry', 'quadratics']"
1565336,How to solve differential equation $y'+\frac xy=x^2y^3$,"I've tried to let $u=y^2$, and got
$$u'+2x=2x^2u^2,$$
but I still can't solve it.",['ordinary-differential-equations']
1565339,Notational Definition: $A \subset B$,"Suppose $A$ and $B$ are two sets and suppose $A \subset B$, then from the definition of subset, it implicitly follows that $A$ might also be equal to $B$. Then why do we need $A \subseteq B$ where we explicitly declare that $A$ might also be equal to $B$? Does $A \subset B$ means $A$ is a proper subset of $B$?","['notation', 'elementary-set-theory']"
1565350,Why is Completeness not a Topological Property?,"I am trying to answer the question: Show why completeness is not a topological property. My answer:  $\mathbb{R}$ and the set $(0,1)$ are homeomorphic, but $\mathbb{R}$ is complete while $(0,1)$ is not. My question to you all:  Does this answer the question?  I feel like I am not quite seeing what is going on with completeness and why it is not a topological property. Can someone give me another example?",['general-topology']
1565374,Question regarding Odd and Even function $g(x)=f(x)(f(x)+f(-x))$,Let $f\colon\mathbb{R} \to \mathbb{R}$. Define $g: \mathbb{R}\to \mathbb{R}$ by $g(x)=f(x)(f(x)+f(-x))$ Then which of following is/are correct? A. $g$ is even for all $f$ B. $g$ is odd for all $f$ C. $g$ is even if $f$ is even D. $g$ is even if $f$ is odd Taking $f(x)=\sin x$ eliminated option B. What if I take $f$ to be odd function then my $g=0$. Is $0$ a even function or odd function? Thanks,['functions']
1565375,Anything wrong with following analysis on $y=\tan(x+y)$?,"Given $y=\tan(x+y)$, we want to discuss the derivative of $y$ of $x$, says $y'_x$. Assume that $y$ is a function of $x$, then by $y(x)=\tan(x+y(x))$, the derivative of both sides remains equal,
$$y'_x=y'_x\sec^2(x+y),\tag{1}$$ then we get $y'_x=-\csc^2(x+y)$. But if we analysis equation (1), we finds
$$y'_x\tan^2(x+y)=0,$$
so for any $x$, either $y'_x=0$ or $\tan(x+y)=0$. We can easily deduce that neither $y'_x=0$ nor $\tan(x+y)=0$ can be hold on any open interval $(a,b)$: 1) If for any $x\in(a,b)$, $y'_x=0$, then $y=C$, where $C\in\mathbb{R}$ is a constant. From the original equation $y=\tan(x+y)$, we get
$$C=\tan(x+C),\;(x\in(a,b)).$$
It's obviously false. 2) If for any $x\in(a,b)$, $\tan(x+y)=0$, then we get $x+y=k\pi,\;k\in\mathbb{Z}$. From $y=\tan(x+y)$, we get $y=0$, that means $x=k\pi,\;k\in\mathbb{Z}$, and $\tan(x+y)=0$ can only holds with some isolated $x$ values. In conclusion, equation (1) can only holds on some isolated point $x$, is there anything wrong? From the graph above, we can find $y'_x$ could never be $0$!","['derivatives', 'functions']"
1565378,Elliptic Curve as Sphere with 4 Punctures?,"I saw an informal comment somewhere about taking a Riemann sphere with four punctures and generating all possible elliptic curves.  I was hoping someone could describe for me how this construction goes?  Or possibly point me to online literature? If I had to guess, I feel like given four points on the sphere, you could connect them pairwise with branch cuts, and glue these two cuts together to get the torus/elliptic curve.  I know that any two Riemann spheres with three punctures are biholomorphic, so is the idea that the fourth puncture treated as a moduli which turns into the modular parameter $\tau$ of the elliptic curve?  Kind of like a change of variables, or so?","['number-theory', 'complex-analysis', 'algebraic-geometry']"
1565405,Bourbaki's definition of semidirect product,"This recess I'm off to learn about group extensions and the cohomological methods to characterize those extensions, but I'm a bit stuck on wraping my head around all the new concepts (I just finished a beginners course covering material on elementary number theory, algebraic structures of the integers, some basic abstract algebra - concerning only finite and abelian groups -, with hints on analytic number theory and deeper abstract algebra). I read the start of Serre's 1978 lectures Groupes Finis as a motivation, then moved on to Bourbaki's Algebra . Bourbaki's encyclopedia was not hard to follow up to chapter 6, where extensions began popping up. The characterization of a extension was comprehensible, along with his demonstration that the direct product and the external direct product were extensions and their characterizations. But when he moved on to the ( omissed term internal) semidirect product, I felt unsure on my understanding of the subject. Here's what I've got: Bourbaki's definition, external semidirect product : If $G$ and $F$ are two groups and there exists a homomorphism $\pi$ of $G$ into $\text{Aut}(F)$ - (the automorphism group of F, which in my understanding clearly defines a action of $G$ on $F$, through the map $\phi :G\times F \rightarrow F$ where $\phi(g, f) \mapsto \pi(g)(f)$) - then the set $F \times G$ with the composition:
$$((f, g), (f',g')) \mapsto (f\pi(g)(f'), gg')$$
is a extension of G by F (written $F \times_\pi G$). With that proposition, we can describe all external semidirect product extensions of two groups $F$ and $G$ by looking at the possible homomorphisms of the automorphism group. Now to the real question. Bourbaki's definition, semidirect product : $G$ is a semidirect product of the subgroups $H$ and $K$ if $H$ is a normal subgroup, if $K\cap H = \{e\}$ and $H.K = G$. First off, from my understanding the statement $H.K = G$ is referring to the property of complement subgroups, i.e., every element $g$ of $G$ can be uniquely written as $hk$ for some $h \in H$ and $k \in K$. That means $K$ has one and only one representative of each orbit of the equivalence relation defined by $H$, and that means $K$ is isomorphic to $G/H$. Now, Bourbaki proceeds: ""Let $\pi$ be the operation of $K$ on $H$ by inner automorphisms of $G$. The mapping $(h, k) \mapsto hk$ is a isomorphism of $H \times_\pi K$ onto $G$"". I'm not sure I actually understand that last $\pi$ operation. If it defines a external semidirect product, it must be a homomorphism from $K$ to the automorphism group of $H$, so it must define a action of $K$ on $H$. When he mentions inner automorphisms of $G$, because $H$ is normal every inner automorphism of $G$ is a automorphism of $H$, and I guess the converse is also valid, so why couldn't $\pi$ be defined in terms of the group of automorphisms of $H$? Would it make it different? Does the set of inner automorphisms of $G$ and automorphisms of $H$ differ?","['abstract-algebra', 'group-extensions', 'group-cohomology', 'group-theory']"
1565428,DeMorgan's Law and Differences of Sets,"I'm currently trying to prove the following identity: $(A \cup B)\triangle C \equiv (A \triangle C)\triangle(B \setminus A)$ I can easily figure that the left side reduces down to $(x \in A \land x \notin C) \lor (x \in B \land x \notin C) \lor (x \in C \land x \notin A \land x \notin B)$ But when I start working on the right side, I end up with something a bit confusing on my hands: Let $x \in(A \triangle C)\triangle(B \setminus A) \rightarrow (x \in(A\triangle C)\setminus(B\setminus A)) \lor (x \in (B\setminus A)\setminus(A\triangle C))$ The first of those two possibilities is where it starts to break down for me, particularly when treating the second possibility in $(A \triangle C)$, which is $(C \setminus A)$. In that case, I end up with the following: $x \in (C \setminus A)\setminus(B\setminus A)$ The logical equivalent of the difference of sets is 'and not,' so it could be rewritten $(C \land \lnot A)\land \lnot (B \land \lnot A)$ But according to DeMorgan's Law, the negation of an end statement would be an or statement with both elements negated, meaning it becomes $(C \land \lnot A) \land (\lnot B \lor A)$ If you distribute this, you'd end up with $(C \land \lnot A \land \lnot B) \lor (C \land \lnot A \land A)$ That first one is fine, but if you let the contradiction cancel out, you're still now left with $x \in C$ in a way that does not exclude elements in A or B, which would mean it doesn't match up to the left side. What am I missing here?","['logic', 'elementary-set-theory']"
1565450,What is the spherical law of cosines in high dimensions?,"If I have 3 points on an N-D sphere, does there exist a law of cosines which holds, regardless of the number of dimensions that the sphere occupies? If so - what is the N-D law of cosines? EDIT for reference I provide links to wiki pages: 2D Plane Triangle law of cosines: https://en.wikipedia.org/wiki/Law_of_cosines 3D Sphere Triangle law of cosines: https://en.wikipedia.org/wiki/Spherical_law_of_cosines 4D+ Sphere Triangle law of cosines: WANTED","['euclidean-geometry', 'trigonometry']"
