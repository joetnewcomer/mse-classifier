question_id,title,body,tags
2382245,What is the most efficient shape for tiling curved spaces?,"In a great video by PBS Infinite Series, the mathematician Kelsey Houston-Edwards argues that bees build their honeycombs into hexagonal shapes because that's the most efficient way of tiling two-dimensional euclidean space that ""minimizes the length of lines relative to [the] number of regions"" . She goes on in that video to generalize the question and explore possible honeycomb shapes that 4-dimensional bees might produce. My question is, what is the most efficient shape for tiling non-euclidean 2-dimensional space? Or, in other words, what shape honeycomb would a 3-dimensional bee make in a highly hyperbolic or elliptical space? How much does the curvature of the space effect the tiling? I'd also like to know how this idea generalizes to higher-dimensional curved spaces, if possible.","['tiling', 'noneuclidean-geometry', 'geometry']"
2382296,Binomial Transform and Ordinary Generating Functions,"I had a couple of simple doubts about the following Theorem from Wikipedia's Binomial Transform page, which I have not been able to solve by searching for information over the Internet: Let $$f(x)=\sum_{n=0}^\infty a_n x^n$$ And $$g(x)=\sum_{n=0}^\infty s_n x^n$$ Where $s_n$ is the binomial transform of $a_n$. Then, $$g(x)=\frac{1}{1-x} f \left ( \frac{-x}{1-x} \right )$$ 1st Question (already solved) : After some time looking for information about it on the Internet, I have not found any proof for this Theorem, and I do not have access to all of Wikipedia's suggested bibliography. Where can I find this proof? 2nd Question: Does that formula still hold for: $$g(1)=\lim_{x \to 1^-} \frac{1}{1-x} f \left ( \frac{-x}{1-x} \right )$$ As we are working with Ordinary Generating Functions, I do not know wether the original formula is valid for $|x| \le 1$ or only for $|x| <1$. 3rd Question: I am having some trouble when working with this specific series: Let $$a_n= \frac{B_{n+1}}{8^n (n+1)!}$$ So that $$s_n= \sum_{k=0}^n (-1)^k {n \choose k} \frac{B_{k+1}}{8^k (k+1)!}$$ And let both $h(x)$ and $i(x)$ be defined as $f(x)$ and $g(x)$ but for these specific sequences  above. Then, $$h(x)=\sum_{n=0}^\infty \frac{B_{n+1}}{ (n+1)!}{\left ( \frac{x}{8} \right )}^n = \frac{8}{x} \sum_{n=1}^\infty \frac{B_{n}}{ (n)!}{\left ( \frac{x}{8} \right )}^n = \frac{8}{x} \left ( \sum_{n=0}^\infty \frac{B_{n}}{ (n)!}{\left ( \frac{x}{8} \right )}^n -1 \right )$$ By the generating function of Bernoulli Numbers (and taking $B_1=\frac{1}{2}$), $$ h(x)= \frac{8}{x} \left ( \frac{\frac{x}{8}}{1-e^{-\frac{x}{8}}}-1 \right ) =\frac{1}{1-e^{-\frac{x}{8}}} - \frac{8}{x}$$ Then, as $$i(x)=\frac{1}{1-x} f \left ( \frac{-x}{1-x} \right )$$ We have that: $$i(x)=\frac{1}{1-x} \left ( \frac{1}{1-e^{-\frac{\frac{-x}{1-x}}{8}}} - \frac{8}{\frac{-x}{1-x}} \right )$$ $$i(x)= \frac{1}{(1-x)(1-e^{\frac{x}{8(1-x)}})} + \frac{8}{x}$$ However, the original series for $i(1)$ diverges but $$\lim_{x \to 1^-} \frac{1}{(1-x)(1-e^{\frac{x}{8(1-x)}})} + \frac{8}{x} = 8$$ I also have some trouble when choosing some values for $x$ close to $1$. Assuming that the answer to the 2nd question is yes, is there any flaw in my work? Is there any concept that I am missunderstanding? Thank you. Edit: to clarify a bit what I want here. Intuition tells me that, for some $x<1$ very close to $1$, the formula above should be valid (while on the other hand, some small computations give numerical evidence that it isn't). Moreover, the following limit should exist: $$\lim_{x \to 1^-} i(x)-\frac{1}{1-x} h \left ( \frac{-x}{1-x} \right ) = 0 $$ While, substituting $\frac{1}{1-x} h \left ( \frac{-x}{1-x} \right )$ with $\frac{1}{(1-x)(1-e^{\frac{x}{8(1-x)}})} + \frac{8}{x}$ as obtained before, we gent that the limit does not exist, since $i(1)$ diverges and the subtrahend equals 8.","['generating-functions', 'binomial-coefficients', 'sequences-and-series', 'transformation']"
2382304,Solution of a linear differential equation,"Find the general solution of the equation $$ \frac{dy}{dx}=1+xy $$ My attempt: Arranging it in standard linear equation form $\frac{dy}{dx}+Py=Q$, we get
$$\frac{dy}{dx}+(-x)y=1$$
Hence, the integrating factor(I.F.) = $e^{\int-xdx}=e^{-x^2/2}$
Hence, the solution is $$y(e^{-x^2/2})=\int{e^{-x^2/2}dx}+c$$ How do I solve this integral now?",['ordinary-differential-equations']
2382318,Square root of $2$ is irrational,"I am studying the proof that $\sqrt 2$ is an irrational number. Now I understand most of the proof, but I lack an understanding of the main idea  which is: We assume $\frac{m^2}{n^2} = 2$ . Then both $m$ and $n$ can't be even. I do not understand, why can't both $m$ and $n$ be even?","['substitution', 'roots', 'algebra-precalculus', 'integers', 'elementary-number-theory']"
2382342,Proof checking: subsequential convergence implies compactness,"I attempt to solve this problem: If $A$ is a subset of $\Bbb R^n$ and every sequence $\{p_n\}_{n=1}^{\infty}$ of points in $A$ has a subsequence converging to a point in $A$ , then $A$ is compact. An important theorem (Heine–Borel theorem) to support my proof: $A$ is a closed and bounded subset of $\Bbb R^n$ , $A$ is compact. I was thinking that since if $A$ is closed and bounded, $A$ would be compact so I am trying to prove that $A$ is closed and $A$ is bounded. Here is my proof: $1)$ Suppose $A$ is not bounded, satisfying the condition. Since $A$ is unbounded, there exists a sequence $\{p_i\}_{i=1}^{\infty}$ such that $|p_n|>n$ . Its subsequence does not converge on $\Bbb R^n.$ It contradicts to the condition given by the problem so $A$ is bounded. $2)$ Suppose $A$ is not closed, there exists a limit point $x$ of $A$ , $x \not \in A.$ Since $x$ is a limit point, $\forall n>0, \exists x_n \text{ s.t. } |x_n-x|<\frac{1}{n},x_n \in A, x_n \neq x$ . Then $\{x_n\}_{n=1}^{\infty}$ is a sequence of points. Since the subsequence of $\{x_n\}_{n=1}^{\infty}$ always converges to $x$ . $x \in A$ , which brings out an contradiction. So $A$ is closed. Since $A$ is closed and bounded, by Heine–Borel theorem, $A$ is compact. I am not sure my proof is right or not? Because my proof is different from the proof given by the link . If anything wrong, what is it? Is there any link between the proof given by the hyperlink and the one given by me?","['real-analysis', 'sequences-and-series', 'proof-verification', 'general-topology', 'convergence-divergence']"
2382372,"If $\tan(\alpha)=2-\sqrt{3},$ find the value of the acute angle $\alpha$","I rewrote it as $$\tan\left(2\cdot\frac{\alpha}{2}\right)=\frac{2\tan(\frac{\alpha}{2})}{1-\tan^2(\frac{\alpha}{2})}=2-\sqrt{3} \ \Rightarrow \ 2(1-\tan^2(\frac{\alpha}{2})-\sqrt{3}(2\tan(\frac{\alpha}{2}).$$ Obviously, it didn't bring the answer. My other attempts also were untrue. I would like somebody to hint at other method(s).",['trigonometry']
2382387,How to solve $y''+y=\cos x$?,"Solve $y''+y=\cos x$. After first solving the homogeneous equation we know that the solution to it is $y=c_1\cos x+c_2\sin x$. We can guess that the private solution to non-homogeneous equation will be of form: $y_p=x(A_1\cos x+A_2\sin x)$. Then:
$$
y_p'=A_1\cos x-A_1x\sin x+A_2\sin x+A_2x\cos x\\
y_p''=-2A_1\sin x-A_1x\cos x+2A_2\cos x-A_2x\sin x
$$
If we plug these into the original equation we get:
$$
\cos x(A_1+A_2x-A_1x+2A_2)+\sin x(A_2-A_1-2A_2-A_2x)=\cos x \quad\ast
$$
We can try to solve the system:
$$
\begin{cases}
x(A_2-A_1)+A_1+2A_2=1\\
x(-A_1-A_2)+A_2-2A_1=0
\end{cases}
$$
But there're 3 unknowns in the system so I don't see how to find out the values of $A_1$ and $A_2$. The solution says that we get $2(A_2\cos x-A_1\sin x)=\cos x$ from which is follows that $A_1=0$ and $A_2=0.5$. But how do we get to this conclusion? Is there some trick I missed? I checked my calculations in Wolfram Alpha and they match .","['multivariable-calculus', 'ordinary-differential-equations']"
2382392,"is $\int_1^x \sin(\sin(t)+\cos(t\sqrt{2}))\,dt$ a bounded function?","The function $f(x)=\int_1^x \sin(\sin(t)+\cos(t\sqrt{2})) \, dt$ seems bounded, so I plot it in maple and I deduce that $f$ is always between $-1$ and $1$. I tried to prove it by searching the max and min of this function, but this doesn't help me at all. Do you any idea why $f$ is bounded?","['real-analysis', 'calculus', 'analysis']"
2382417,"How to compare $a^b $and $ b^a $ ( for Eg. $ (\sqrt 2 )^{e} $ and $ e^{\sqrt2}$ ) such that $a \leq e \leq b$ and $a,b\geq 0 $","I have seen answer to similar question but it was about $ 3^{\pi}$ & $ { \pi }^3 $. And they have done that through defining a function $f(x)=x^{\frac{1}{x}} $ also this function attains maximum at $'e'$ That can be shown easily . My question is about How to compare two numbers $ a , b $ such that $a \leq e \leq b$ , what will we do there? Any Help to overcome this problem is appreciable..!!","['real-analysis', 'functions']"
2382436,"Prob. 9, Chap. 6, in Baby Rudin: Integration by parts for improper integrals","Here is Prob. 9, Chap. 6, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Show that integration by parts can sometimes be applied to the ""improper"" integrals defined in Exercises 7 and 8. (State appropriate hypotheses, formulate a theorem, and prove it.) For instance show that 
  $$ \int_0^\infty \frac{\cos x}{1+x} \ \mathrm{d} x =  \int_0^\infty \frac{\sin x}{(1+x)^2} \ \mathrm{d} x. $$ 
  Show that one of these integrals converges absolutely , but that the other does not. Here are the links to my Math SE posts on Probs. 7 and 8, Chap. 6 in Baby Rudin, 3rd edition: Prob. 7 (a), Chap. 6, in Baby Rudin: If $f$ is integrable on $[c, 1]$ for every $c>0$, then $\int_0^1 f(x) \ \mathrm{d}x = $ . . . Prob. 7 (b), Chap. 6, in Baby Rudin: Example of a function such that $\lim_{c \to 0+} \int_c^1 f(x) \ \mathrm{d}x$ exists but . . . Prob. 8, Chap. 6, in Baby Rudin: The Integral Test for Convergence of Series And, here is Theorem 6.22 (integration by parts) in Baby Rudin: Suppose $F$ and $G$ are differentiable functions on $[a, b]$, $F^\prime = f \in \mathscr{R}$, and $G^\prime = g \in \mathscr{R}$. Then 
  $$ \int_a^b F(x) g(x) \ \mathrm{d} x = F(b)G(b) - F(a) G(a) - \int_a^b f(x) G(x) \ \mathrm{d} x. $$ My Attempt: Here I will only be formulating the analog of the result in Prob. 7 (a). Suppose $F$ and $G$ are  real differentiable functions on $(0, 1]$ such that $F^\prime = f \in \mathscr{R}$ and $G^\prime = g \in \mathscr{R}$ on $[c, 1]$ for every $c > 0$. Suppose that $\lim_{x \to 0+} \left[ F(x) G(x) \right]$ exists and is finite. If $f \in \mathscr{R}$ and $g \in \mathscr{R}$ on $[0, 1]$, then we have 
  $$ \int_0^1 F(x) g(x) \ \mathrm{d} x =  F(1) G(1) - \lim_{c \to 0+} F(c) G(c) \ - \  \int_0^1 f(x) G(x) \ \mathrm{d} x. $$ Is this result correct? If so, is this the result required by Rudin? Now here is my proof: By Theorem 6.22 in Baby Rudin, we see that for any $c$ such that $0 < c < 1$, we have 
  $$ \int_c^1 F(x) g(x) \ \mathrm{d} x = F(1)G(1) - F(c) G(c) - \int_c^1 f(x) G(x) \ \mathrm{d} x.  $$
  Now applying the conclusion of Prob. 7 (a) to this identity we obtain 
  $$
\begin{align}
\int_0^1 F(x) g(x) \ \mathrm{d} x &= \lim_{c \to 0+} \int_c^1 F(x) g(x) \ \mathrm{d} x \\
&= \lim_{c \to 0+} \left( F(1)G(1) - F(c) G(c) - \int_c^1 f(x) G(x) \ \mathrm{d} x \right) \\
&= F(1) G(1) - \lim_{c \to 0+} F(c) G(c) - \lim_{c \to 0+} \int_c^1 f(x) G(x) \ \mathrm{d} x \\
&= F(1) G(1) - \lim_{c \to 0+} F(c) G(c) \  - \  \int_0^1 f(x) G(x) \ \mathrm{d} x, 
\end{align}
$$
  as required. Is my proof correct and rigorous enough for Rudin?","['real-analysis', 'calculus', 'integration', 'definite-integrals', 'analysis']"
2382512,"""All but finitely many..."" in the finite case","Maybe this is a stupid question, but I can't figure it out, since the wording makes it very confusing to me. I've been mulling over the meaning of ""all but finitely many"" and its negation. There are plenty of answers to what that means. But what does this mean if some property $P$ is defined on a finite set $X$? To say that ""$P(x)$ holds for all but finitely many $x\in X$"" means what? Thank you in advance.","['elementary-set-theory', 'definition']"
2382552,"What is the general term formula of this recurrence relation, if it exists?","$$a_n=-\frac{(a_{n-1} + 1)^2}{a_{n-1}+2}\quad \quad a_1 = -\frac 12$$ I transformed to: $$a_n = -a_{n-1} - \frac{1}{a_{n-1} + 2}$$ $$a_{n-1} = -a_{n-2} - \frac{1}{a_{n-2} + 2}$$ ... And then $$a_n - a_{n-1} + a_{n-2} -\cdots  + \cdots - a_1$$ $$=$$ $$- a_{n-1} + a_{n-2} - ... + ... - \frac{1}{a_{n-1} + 2} + \frac{1}{a_{n-2} + 2} - ... + ... $$ Many terms cancel each other and: $$a_n = - \frac{1}{a_{n-1} + 2} + \frac{1}{a_{n-2} + 2} - ... + ... + \frac{1}{a_{1} + 2} + a_1$$ (Here need to divide cases odd vs even) And then I'm forever stuck. I can't find analytical form of the sum above I try to get the value of the first few dozen terms to observe. I find nothing other than the terms are negative fractions that satisfy the recurrence relation. Question is, is there a general term formula? How to find it?","['recurrence-relations', 'sequences-and-series']"
2382572,Relationship between second derivative of a function on a manifold and its covariant Hessian,"I'm interested in how the covariant Hessian $\nabla^2 f :TM \oplus TM \to \mathbb{R}$ of $f$ and the second derivative of $f$, $d(df):TTM \to \mathbb{R}$ are related once we view $TTM = TM \oplus TM$ by the splitting induced by $\nabla$ I describe below. I became interested in this after looking into $C^2(M)$ as a Banach space. The definition of the norm always uses the covariant Hessian $\nabla^2f$ in place for the second derivative. This make sense in that it's easier to define the norm, but it seems strange to me that we need a connection to define the space whereas $C^1(M)$ can be defined with just $f$ and $df$ (which just needs the smooth structure of M). I suppose you need a metric to then define the norm of $df$, which would then give a connection, but still I'm still interested in the question on its own now. Here are the details: Let $f:M \to \mathbb{R}$ be a smooth function on a manifold $M$. We can consider the derivative of $f$, $df:TM \to \mathbb{R}$ by $df(p,v) = df_p(v)$. Now, considering $df$ as a map between the smooth manifolds $TM$ and $\mathbb{R}$ we can take the derivative again to get a function $d^2f: TTM \to \mathbb{R}$ by $d^2f((p,v),w) = d(df)_{(p,v)}(w)$. Note that $d^2f$ is not the exterior derivative of the one form $df$, which would be zero. Now, we can split the double tangent bundle $TTM$ as follows: For $\pi:TM \to M$ we have $d\pi : TTM \to TM$ and we can define $VTM = \ker d\pi$. A choice of complementary subspace $HTM$ such that $TTM = VTM \oplus HTM$ is equivalent(kind of) to a connection on $M$. This is because $VTM \cong TM$ by the regular value theorem, for example. So if $\nu: VTM \oplus HTM \to VTM \cong TM$ is the projection then we can define a connection by $\nabla X = \nu \circ dX$ considering $X$ as a funtion $X : M \to TM$. So, for example, $\nabla_Y X = \nu(dX(Y))$. We get a connection on $M$. Getting to the point, we have $HTM \cong TM$ and the restriction of $d\pi$ to $HTM$ gives an isomorphism $HTM \cong TM$. Consequently $TTM \cong TM \oplus TM$. So we can think of $d^2f$ as $d^2f : TM \oplus TM \to \mathbb{R}$. I want to know the relationship between this $d^2f:TM \oplus TM \to \mathbb{R}$ and the covariant Hessian $\nabla^2 f: TM \oplus TM \to \mathbb{R}$. I imagine the differ somehow by something to do with the curvature of $\nabla$. All of my attemps at this have been long calulations that lead nowhere so I'm ommiting what I've tried. Thanks.","['connections', 'differential-geometry']"
2382584,"Need a formula for $\frac{d}{dx}f(g(x), h(x))$","I know the derivative chain rule $\frac{d}{dx}f(g(x))= f^{\prime}(g(x))\cdot g^{\prime}(x)$. What is the formula if $f$ is a function of two variables, i.e. what is $\frac{d}{dx}f(g(x), h(x))$? Thanks for help.","['multivariable-calculus', 'calculus', 'derivatives']"
2382589,Vetting a random number generator -- Chi Square Tests throws varying p-value results,"Suppose I have a random number generator and I want to check with a Chi Square Test whether its pdf is uniform or no. I can write a script that does that and I will run it several times. To my surprise, I get completely different results each times. Sometimes I will get a p-value of 0.3, sometimes 0.987 and other times 0.003. Which is the number I should take? Should I try to get an average of the p-values I get? How do I decide if this generator passes the test or not? So what I try next is using a random number generator that I already ""know"" to be uniform and I run the test on that. And I keep getting absolutely varying results. Even if I increase the number of samples, it keeps varying a lot! From what I understad, the probability if seeing a very low p-value when drawing random samples from a uniform distribution should be low, and the probability of seeing a high p-value should be high. But this doesn't seem to happen. How should I interpret the results I get from this test? This is the Python script I am using: import numpy as np
from scipy.stats import chisquare

bins=256
x = np.random.randint(bins, size=bins*100)

h = [];
for i in range(bins):
  h.append(0);

for n in range(0, len(x)):
  h[x[n]] += 1;

print(chisquare(h)) and this are the results I get: Power_divergenceResult(statistic=303.19999999999999, pvalue=0.020572599306529871)
Power_divergenceResult(statistic=211.06, pvalue=0.97933788750272888)
Power_divergenceResult(statistic=289.66000000000003, pvalue=0.066874498546635575)
Power_divergenceResult(statistic=275.63999999999999, pvalue=0.17885688588645363)
Power_divergenceResult(statistic=257.86000000000001, pvalue=0.43814613213884313)
Power_divergenceResult(statistic=217.07999999999998, pvalue=0.95911527563656596) Even more, I did a histogram of the p-values I got and it looks pretty uniform. If I know the samples I have are drawn from a uniform distribution, shouldn't I get most of the times a high p-value?","['statistics', 'simulation', 'chi-squared']"
2382590,sum of rational terms in $\left(\sqrt{2}+\sqrt{27}+\sqrt{180}\right)^{10}$,"Find a sum of the rational terms in the following expression after full expanding. $$\left(\sqrt{2}+\sqrt{27}+\sqrt{180}\right)^{10}$$ Since the term should be rational, each power should be even. Number of non negative even integers $m,n,q$ satisfying $$m+n+q=10$$ gives number of triplets as $21$..but its very tedious to find sum of $21$ terms...any other approach?","['binomial-coefficients', 'polynomials', 'irrational-numbers', 'rational-numbers', 'combinatorics']"
2382621,Ergodicity and Simple Eigenvalue,"It is a fact that a measure-preserving system $(X,\mathcal{B},\mu,T)$ is ergodic if and only if $1$ is a simple eigenvalue for the associated unitary operator $U_T: L^2(\mu) \to L^2(\mu)$ given by $U_Tf = f\circ T$ . I'm curious as to what a simple eigenvalue means here. I know $T$ is ergodic if and only if the only $T$ -invariant $L^2$ functions are the constants. So it is clear to me that $T$ is ergodic if and only if the eigenspace associated with the eigenvalue $1$ has dimension $1$ . However, for finite-dimensional transformations, a simple eigenvalue is an eigenvalue $\lambda$ for which if we completely factor the characteristic polynomial, then the exponent of the term with $\lambda$ is $1$ . Wikipedia seems to indicate that this is not necessarily the same as the dimension of the eigenspace corresponding to $\lambda$ . So what is a simple eigenvalue for a linear operator on infinite-dimensional space, and why does it coincide with the dimension for the eigenspace corresponding to the eigenvalue?","['real-analysis', 'ergodic-theory', 'linear-algebra']"
2382627,"Most Probable Sum by rolling $2$ dice in $[100,111]$.","Given two dices, we roll them and add the result to a sum (initialised to 0) till sum is $\ge 100.$ The resultant sum can be any number in [100 111]. Which among them have the highest probability of being the resultant sum.","['probability', 'dice']"
2382654,Riesz representation for bounded function and continuous functional,"I have found the following version of Riesz-Representation theorem: Let X be local compact hausdorff space. For any continuous functional $\psi $ on $C_0(X)$ (continuous function vanishing at infinity), there is a unique regular countably additive complex Borel measure $\mu$ on $X$ such that $$\psi(f)=\int_Xf(x)d\mu(x)$$ for all f in $C_0(X)$. My question is how about the space of continuous bounded function class $C_b(X)$? Does there exist a similar version?","['functional-analysis', 'riesz-representation-theorem']"
2382662,Surjective polynomial map from $M_n(F)$ to $M_n(F)$,"Assume that $F$ is a field, and that $f \in F[x]$ is a polynomial. If $f$ is surjective for every sufficient large $n$ when we regard $f$ as a map from $M_n(F)$ to $M_n(F)$, must $f$ be linear?","['abstract-algebra', 'linear-algebra']"
2382670,Prove that a complete metric space contains a non-empty open set,"In the proof of Baire's Category Theorem in the book by Kreyszig, it is mentioned that a complete metric space will contain a non-empty open set. I like to know the proof of this.","['functional-analysis', 'complete-spaces', 'metric-spaces']"
2382672,Given $a+b+c=0$ find the value of $\big(\frac{b-c}{a}+\frac{c-a}{b}+\frac{a-b}{c}\big)\big(\frac{a}{b-c}+\frac{b}{c-a}+\frac{c}{a-b}\big)$,"I already have a solution, which is correct, it is $9$. I'm just wondering if there is a simpler method. First we just expand and find $3+\frac{b-c}{a}\big(\frac{b}{c-a}+\frac{c}{a-b}\big)+\frac{c-a}{b}\big(\frac{a}{b-c}+\frac{c}{a-b}\big)+\frac{a-b}{c}\big(\frac{a}{b-c}+\frac{b}{c-a}\big)$ Each of these ""not yet a number"" terms can be expanded to give $\frac{b-c}{a}\big(\frac{b}{c-a}+\frac{c}{a-b}\big) = \frac{2(c-b)^2}{(c-a)(a-b)}$ $\frac{c-a}{b}\big(\frac{a}{b-c}\big)= \frac{2(a-c)^2}{(c-a)(a-b)}$ $\frac{a-b}{c}\big(\frac{a}{b-c}+\frac{b}{c-a}\big) = \frac{2(b-a)^2}{(b-c)(c-a)}$ Adding each of these terms together and factoring out the two we find that they equal $2\frac{3(a-b)(b-c)(c-a)}{(a-b)(b-c)(c-a)}=6$ So our total is $9$. This is problem 160 of The USSR olympiad problem book by Shklarsky, Chentzov and Yaglom, they give the answer and $9$ is correct. Obviously they don't give the method.","['algebra-precalculus', 'contest-math', 'polynomials', 'fractions']"
2382673,"How to compute $\int_0^\infty e^{-a(s^2+1/s^2)}\, ds$","How do I integrate $$\int_0^\infty e^{-a(\frac{1}{s^2} + s^2)}\, ds \tag{*}$$ Context: At page 602 of the paper ""Reaction-Diffusion equations for Interacting Particle Systems"" from De Masi Ferrari and Lebowitz one reads: $$\tilde{c}_0(q-q';t)=8\gamma\int_0^tds(4\pi s)^{-1/2}\exp[-(q-q')^2/4s]\cdot\exp[-4(1-\gamma/\gamma_c)s]\tag{2.32a}$$ For $\gamma<\gamma_c$, $$\tilde{c}_0(q-q';t)\underset{t\to\infty}{\xrightarrow{\quad\!\!\!\!\qquad}}\dfrac{\gamma}{(\gamma_c-\gamma)^{1/2}}\exp[-2|q-q'|(\gamma_c-\gamma)^{1/2}]\tag{2.32b}$$ So using $C$, $\Delta$ and $A$ to denote constants that are in our way, we rewrite more neatly: $$C \int_0^t \frac{1}{\sqrt s} e^{\frac{-\Delta}{s}} e^{-A s}\, ds $$ Now consider a series of change of variables: 1) $ s = \Delta y$ ( $ds = \Delta dy$) yields
$$ C(\Delta)^{1/2}\int_0^t \frac{1}{\sqrt y} e^{\frac{-1}{y}} e^{-A\Delta y}\, dy $$ 2) $y = x^2$ $dy = 2x dx$ yields $$2C(\Delta)^{1/2}\int_0^{\sqrt{t}}  e^{\frac{-1}{x^2}} e^{-A\Delta x^2}\, dx  $$ 3) Finally $x = \lambda z$ yields $$2C(\Delta)^{1/2}\lambda\int_0^{\frac{\sqrt{t}}{\lambda}}  e^{\frac{-1}{\lambda^2x^2}} e^{-A\Delta\lambda^2 x^2}\, dx  $$ Choose $\lambda$ such that $$\frac{1}{\lambda^2} = A\Delta\lambda^2$$ That is, choose $\lambda = \frac{1}{(A\Delta)^{1/4}}$ So we arrive at $$2C(\Delta)^{1/2}\frac{1}{(A\Delta)^{1/4}}\int_0^{\frac{\sqrt{t}}{\lambda}}  e^{\frac{-(A\Delta)^{1/2}}{x^2}} e^{-(A\Delta)^{1/2} x^2}\, dx  $$ Therefore, to conclude this integral, need to compute $(*)$ with $a =(A\Delta)^{1/2}$. but I am stuck.",['integration']
2382685,Algebraic topology on function spaces,"I study algebraic topology using hatchers book. So far, most of the encountered examples are (low dimensional) manifolds. Therefore I was wondering, if the introduced concepts are of any use for investigating continuous maps between infinite dimensional spaces (other than $\mathbb R P^\infty$, etc), like the standard $L^p$ and $\ell^p$ spaces? I guess that the theory is not suitable when dealing wiht spaces with infinite (diferent) path components. But I have no clue, how many path components these spaces have. Are there any books about this subject I could study?","['functional-analysis', 'reference-request', 'homology-cohomology', 'algebraic-topology']"
2382687,Do we really need axioms to define order in $\mathbb R?$,"I apologize if this question appears to be a dumb one. However given my preliminary knowledge in real analysis, I am unable to resolve the issue; it’s about the order axiom (of reals). It can be shown that algebraic properties of reals follows from field axioms that work as a premise for further reasoning. Since order properties of reals cannot (?) be shown from algebraic properties, we assume the existence of a positive set based on which we can define order of reals. That’s the way Bartle-Sherbert text introduced the concepts of order (of reals). Image: Bartle-Sherbert Introduction to Order But why do we just assume the existence of a positive set the way we assume an axiom? Can’t we really define a positive set $P$ based on algebraic properties as: $P=\{y^2:y\in\mathbb R, y\ne 0\}$. For then we could define order relation $<$ as: $x<y$ iff $y – x\in P$. Based on this observation, do we really need extra (order) axioms, whereas we could define order based on algebraic properties?",['real-analysis']
2382710,Free abelian groups clarification,"I'm having troubles understanding the following definition of a free abelian group:
 $$\mathbb{Z}^{(A)} := \{f: A\rightarrow \mathbb{Z} \ |\ f(a)\ne 0\ \ \text{for finitely many elements}\  a \in A\}$$ I don't get how to write an element of this set as a formal sum. On the internet I could find such a representation:
$$f = \sum_{a \in A}{n_a\phi_a}$$
Where $\phi_a(x) = \begin{cases}
                      \text{1,}  &\quad\text{if x}\ = \text{a} \\
                      \text{0,}  &\quad\text{if x}\ \ne \text{a}\\
                   \end{cases}$ The problem is, I don't udnerstand what $n_a$ is here, many resources don't mention what this is. For example, on Wikipedia it's writtten as a function, but this doesn't feel natural to me. Is $n_a\phi_a$  a function composition then? An integer value seems to fit here more. I am totally fine with less general definition of a free group $\mathbb{Z}^{\oplus n} = \underbrace{\mathbb{Z}\oplus\ .\ .\ .\ \oplus\mathbb{Z}}_\text{n-times}$. With an element of $\mathbb{Z}^{\oplus n}$ being a tuple $(m_1, ..., m_n)$ that can be written in a unique way as a sum:
$$\sum_{i = 1}^n{m_i\phi(i)}$$
With $\phi(i) := \underset{\text{i-th place}}{(0,\ .\ .\ .,\ 0,\ 1,\ 0,\ .\ .\ .\ ,\ 0)} \in \mathbb{Z}^{\oplus n}$ and $m_i$ being some integer coefficient. I understand that $\mathbb{Z}^{(A)}\cong \mathbb{Z}^{\oplus n}$ if, for example, 
if  $A =\{1,\ .\ .\ .\ , n\}$, then $(m_1, ..., m_n)$ may be identified with a function $A\rightarrow \mathbb{Z}$ taking $i$ to $m_i$. But I don't understand how to put this information together and define an element of $\mathbb{Z}^{(A)}$ via sum. Moreover, should group homomorphism $\psi:\mathbb{Z}^{(A)} \rightarrow G$  ($G$ is an arbitrary abelian group) be defined as 
    $$\psi(\sum_{a \in A}{n_a\phi_a}):= \sum_{a \in A}{n_af(a)}$$
where $f:A\rightarrow G$ is a set function (a forgetful functor, in fact). Again, only integer value $n_a$ feels ok for me. Another point of confusion is the fact that only finite sums are used, $\mathbb{Z}^{(A)}$ is defined to have function with only finitely many non-zero values. Why is that? I don't have an intuitive understanding in what way infinities could 'break' free groups as I was only given a definition but no explanation why. Thanks in advance","['abelian-groups', 'group-theory', 'free-abelian-group']"
2382723,Definition of a branch of a complex function?,"I have been looking at the definition of a 'branch' of a complex function. The typical definition I am getting is as follows: ...branches $f_1(z)$, $f_2(z)$, $...$ of $f(z)$ each defined as a single-valued continuous function throughout its range of definition. Each branch assumes one set of the function values of $f(z)$. (Korn & Korn, 2013; pg 193) (a similar definition is given here ) The problem with these definition is that there is an ambiguity of what we call a branch, and by these definitions we should have an infinite number. e.g. we could have a branch defined for $0\le \theta \lt 2\pi$ and another for $0.001\le \theta \lt 2\pi+0.001$. My question is; is their a name for the set of branches $f_i$ such that they don't overlap in this way?","['complex-analysis', 'definition']"
2382775,Find the point which is furthest away from existing points while remaining within the convex hull,"I have a set of x,y coordinates and wish to find a new coordinate pair which is as far away from any point in the initial set, while also being within the convex hull of the original points. The current process I have to determine the new point is as follows: Generate every possible midpoint between the original coordinate pairs. Compute the distance between the midpoints and every original point. Find the smallest distance calculated in Step 2 for each midpoint. Find the midpoint with the largest distance from Step 3. If multiple points have the same maximum distance to the nearest original set of points, only one of those points is needed (for my purpose) and can be selected arbitrarily. Is there a better method for finding these coordinates?","['computational-geometry', 'discrete-mathematics']"
2382816,Summation series ($\Sigma$) is to Integral ($\int$)... as Product series ($\Pi$) is to ??,"If a Summation series ($\Sigma$) is to an Integral ($\int$)... is there a corresponding concept for a Product series ($\Pi$)? Summation series ($\Sigma$) is to Integral ($\int$)... as Product series ($\Pi$) is to ?? This would be multiplying all the points of a function together to arrive at a result. If there were any points where the function was zero, then the equation would equal zero. The idea being to follow along the curve similar to an Integral. This question is related to another question I am asking regarding a plane wave intersecting with a curve: Intersection of plane wave surface and a curve","['products', 'summation', 'sequences-and-series']"
2382820,$\mathbb{R}$ and $\mathbb{R}^2$ isomorphic as groups?,"Using the axiom of choice, $\mathbb{R}$ and $\mathbb{R}^2$ are equal-dimensional vector spaces over $\mathbb{Q}$ and so are isomorphic as $\mathbb{Q}$-vector spaces thus as groups. This is obvious, however I recently began reading Godement's Introduction à la théorie des groupes de Lie and in particular I was reading the chapter on topological groups when I came across this statement: Given a group $G$, there is at most one topology that makes it into a topological group that is at the same time locally compact and countable to infinity. (I don't know how to translate ""dénombrable à l'infini"" better, it means $G$ is a union of countably many compact sets) Here's my reasoning: let $\phi: \mathbb{R}\to \mathbb{R}^2$ be a group isomorphism. In particular, it is a bijection, and so one can define a topology $\mathcal{T}$ such that $\phi$ is a homeomorphism from $(\mathbb{R}, \mathcal{T})$ to $\mathbb{R}^2$ with the usual topology. Obviously, $(\mathbb{R}, \mathcal{T})$ is locally compact and countable to infinity. Moreover, $+: \mathbb{R}\times \mathbb{R}\to \mathbb{R}$, and letting $add$ denote the addition in $\mathbb{R}^2$, because $\phi$ is an isomorphism, we get $+= \phi^{-1}\circ add \circ (\phi\times\phi)$. Therefore, since all these maps are continuous (wrt the usual topology on $\mathbb{R}^2$ and $\mathcal{T}$ on $\mathbb{R}$), so is $+$, and similarly one gets that $x\mapsto -x$ is continuous on $\mathbb{R}$ wrt $\mathcal{T}$. But then $(\mathbb{R}, \mathcal{T})$ is a locally compact topological group that's countable to infinity: according to Godement's claim $\mathcal{T}$ is the usual topology ! This leads to the absurdity that $\mathbb{R}$ and $\mathbb{R}^2$ are homeomorphic, which is trivially false. I'm really stuck on this and I don't know where I went wrong. Could anybody please solve my problem? EDIT : as suggested in the comments, here's a link to a dropbox file with the proof in Godement's book : https://www.dropbox.com/sh/2gxg1jpbdmmcg23/AACP__txcn3o26cw-JR5W5Oea?dl=0 Sorry for the quality of the pictures. And it's in french !","['topological-groups', 'proof-verification', 'general-topology', 'group-theory', 'vector-spaces']"
2382836,Hyperplane sections of curves in $\mathbb{P}^n$.,"Let $K$ be an algebraically close field, and let $X\subset \mathbb{P}^2(k)$ be an irreducible  curve of degree $d$. We know that a general  line in $\mathbb{P}^2$ intersects $X$ in 
$d$ distinct points. Actually, if $X$ is not strange, we also know something stronger: For any $P \in \mathbb{P}^2$, the general  line in the $\mathbb{P}^1$
of lines contaning $P$  intersects $X$ in 
$d$ distinct points. I was wondering if  something analogous for  curves in higher dimensional spaces holds. More precisely, I asked myself the following question: Consider a  curve (say,irreducible, smooth)  $X\subset \mathbb{P}^n$ of degree $d>n$. What is the largest number $r$ such that for any   set of points  $\{P_1,\cdots,P_r\}$ in $\mathbb{P}^n$ with the property that a general  hyperplane in the family of all hyperplanes containing the points $P_1,\cdots,P_r$ intersects $X$ in  $d$ distinct points? My (naive) guess is $r=n-1$, but I'm not sure this is correct.","['algebraic-curves', 'curves', 'algebraic-geometry']"
2382881,"If $f,g$ each have property p then $f \circ g$ also has property $p$","What type of characteristics should properties have for the following to hold true? If $f,g$ each have property $p$ then $f  \circ g$ also has property $p$ Examples: If $f,g$ continuous then $f  \circ g$ is continuous If $f,g$ entire then $f  \circ g$ is entire If $f,g$ differentiable then $f  \circ g$ is differentiable If $f,g$ one to one then $f  \circ g$ is one to one If $f,g$ Contractible then $f  \circ g$ is Contractible If $f,g$ polynomial then $f  \circ g$ is polynomial If $f,g$ lineaer then $f  \circ g$ is linear Counter Examples: If $f,g$ integrable then $f  \circ g$ is integrable (false) see Robert Israel's answer If $f,g$ measureable then $f  \circ g$ is measureable Update Edit:
The motivation for the question was to use the statement as a filter to specify properties p, I had seen too often question being asked for a specific property, was wondering if there is a way to devise a test for p rather than test each p individually to see if it satisfies the statement. (This is as good as I can explain my intent for asking the question, making a list seems to be a beneficial side effect). If anyone can elucidate the motivation with better mathematical terminology please edit.",['analysis']
2382885,Counting the number of distinct weighted subsets,"Suppose you have a finite set of items $X$ . You want to assign a positive number $\mu(S)$ to each subset $S\subseteq X$ in such a way that you respect subset ordering: $$S \subsetneq T \Rightarrow \mu(S) \lneq \mu(T).$$ In other words, you want the assignment to be monotonic. There are infinitely many possible assignments of this form, but it seems that many are equivalent. Here, I consider two assignments $\mu_1$ and $\mu_2$ to be equivalent if for all subsets $S, T$ , $$\mu_1(S)< \mu_1(T) \iff \mu_2(S) < \mu_2(T).$$ My first question is how many possible assignments there are, modulo this equivalence?  Is there a way to parameterize or enumerate them, e.g. characterizing them by just a few of the relationships $\mu(S)\leq\mu(T)$ ? There is a special kind of assignment which assigns a consistent weight to each element of $X$ . These are the additive assignments, where $$\mu(S \sqcup T) = \mu(S) + \mu(T)$$ whenever $S$ and $T$ are disjoint subsets of $X$ .  My second question is how many of these there are, modulo equivalence? How can we describe them? There is another wider kind of equivalence, where two assignments are equivalent if there is a permutation $\pi:X\rightarrow X$ such that $\mu_1$ on $\pi(X)$ is equivalent to $\mu_2$ on $X$ in the earlier sense. For this, it seems like there are even fewer possibilities— how can we count them? In this second case, it seems like you need to know at least how the doubleton sets $\{x,y\}$ relate to the singleton sets, but beyond this, I'm not sure.","['combinatorics', 'equivalence-relations', 'lattice-orders', 'measure-theory']"
2382979,Existence and uniqueness of the differential equation $\frac{dy}{dx}=\sqrt{xy} $,"I am trying to find the regions for the differential equation $\frac{dy}{dx}=\sqrt{xy} $ for which the solution is unique, with graph passing through
the point $(x_0, y_0)$ in these regions. I tried to applied Picard theorem for existence and uniqueness. The function $\frac{\partial f}{\partial y}(x,y) = \frac{\sqrt x}{2 \sqrt y}$ is defined when $xy\geq 0$ and $y \neq 0$ thus we have existence and uniqueness in the
regions $R = [0, \infty)\times (0, \infty)$ and $R = (-\infty, 0]\times (-\infty, 0)$ for any $(x_0, y_0)  \in R$. However, answer is $R = (0, \infty)\times (0, \infty)$  and $R = (-\infty, 0)\times (-\infty, 0)$. My question is why not $x=0$ is included in the region of existence and uniquness? Thank you",['ordinary-differential-equations']
2382997,Cosine Sum of Odd Prime Numbers,I noticed the following unusual sum of the number of odd primes up to the even number 32. $$\cos(2\pi\cdot3/32) + \cos(2\pi\cdot5/32) + \cos(2\pi\cdot7/32) + \cos(2\pi\cdot11/32) + \cos(2\pi\cdot13/32) + \cos(2\pi\cdot17/32) + \cos(2\pi\cdot19/32) + \cos(2\pi\cdot23/32) +\cos(2\pi\cdot29/32)+ \cos(2\pi\cdot31/32)=0$$ Does anyone know of any other similar sums for odd primes for other even numbers?,['number-theory']
2383015,First and Fourth derivative tests giving different result,"Consider the function $$f(x)=2x^5-5x^4-10x^3$$ we have to find Local maxima and minima So $$f'(x)=10x^4-20x^3-30x^2=0$$ critical points are $x=0$,$x=3$ and $x=-1$ $$f''(x)=40x^3-60x^2-60x$$ Now at $x=0$ $f''(0)=0$ so second derivative test fails. Using First derivative test we have $$f'(0^-)<0$$ and$$f'(0^+) \lt 0$$  so no change of sign in $f'(x)$  hence $x=0$ is neither point of Local max nor Min But $$f''''(x)=240x-120$$ $$f''''(0) \lt 0$$ so $x=0$ should be point of Local Max right? what is going wrong here?","['algebra-precalculus', 'ordinary-differential-equations', 'maxima-minima', 'functions']"
2383019,Proof of $1+x\leq e^x$ for all x? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Does anyone provide proof  of $1+x\leq e^x$ for all $x$? What is the minimum $a(>0)$  such that $1+x\leq a^x$ for all x?","['inequality', 'calculus']"
2383020,Is $f:\emptyset \to X$ injective,"My book uses 2 equivalent definitions of injectivity, the first being 
$$x\neq y \Rightarrow g(x)\neq g(y)$$
and the second being
$$g(x)=g(y) \Rightarrow x=y$$ Now as $f$ has $\emptyset$ as its domain I cannot make sense of  either of these definitions as i cannot put in a variable to actually test either of these.",['functions']
2383023,Index of a subgroup,"Let $G$ be a finite group and $H$ be a  subgroup of $G$. Let $q$ be a fixed prime. Suppose that for every Sylow subgroup $P$ of $G$, the index of $H$ in $H^P$ is a power of $q$. What can we say about $|H^G:H|$? $H^X=\langle x^{-1} Hx |x\in X\rangle$ I guess that $|H^G:H|$ is also a power of $q$. I can easily prove $|H^G: H|$ is a power of $q$ when $H$ is a subnormal subgroup of $G$.","['finite-groups', 'group-theory']"
2383067,Ecclid's Lemma (Prime Divisor Property) proved by descent (as Gauss did),"I'm going through Elements of Number Theory by Stillwell.
One of the exercises is confusing me a bit. Finding a different proof from the normal $b = mab + npb$. It says it's attributed to Gauss:
Show a prime $p$ cannot divide $a_1b_1$ when $a_1$,$b_1 \lt p$ 
Suppose $p$ divides $a_1b_1$ and show $p$ divides $a_1b_2$ $b_2$ = remainder when $p$ is divided by $b_1$
which gives infinite descent, which I'm not as familar with. Then from that show if $p$ divides neither $a$ or $b$ then $p$ divides $a_1b_1$ where $a,b \lt p$ I've been trying to maybe factorise $a_1b_1 = np$ Maybe $n$ or $p = \frac{n(pq+(a_1b_1-pq)}{n}$
so $b_2 = (a_1b_1-pq)$ I'm getting lost though and going in the wrong direction I think any advice/solutions?","['number-theory', 'elementary-number-theory']"
2383069,Sequence defined recursively: $\sum_{k=1}^n x_k = \frac{1}{\sqrt{x_{n+1}}}$,"Let $(x_n)_{n \ge 1}$ defined as follows:
$$x_1 \gt 0, x_1+x_2+\dots+x_n=\frac {1}{\sqrt {x_{n+1}}}.$$ Compute the limit $\lim _ {n \to \infty} n^2x_n^3.$ MY TRY: I thought about using Stolz-Cesaro lemma, but I couldn't get to an appropriate form that leads to an easier limit.","['recurrence-relations', 'sequences-and-series', 'convergence-divergence', 'limits']"
2383090,"Define a function $ \ f: [1,3] \to [3,7] \ $ by $ \ f(x)=2x+1 \ $.","Define a function $ \ f: [1,3] \to [3,7] \ $ by $ \ f(x)=2x+1 \ $. If $ f \ $ be a injective function , does the following condition confirm that the function is bijective ? (a) Here clearly ,  $ \ f \ $ is continuous. Since $ f(1)=3 \  \ and \ \ f(3)=7 \ $ , every  $ \ y \ $ value between $ \ 3 \ \ and \ \ 7 \ $ is the output of some $ x \in (1,3) $ by Intermediate value theorem. Hence f is surjective and so f is bijective. . Answer I think this is true. But not sure . Is there any help ? To show",['functions']
2383126,Evaluate $\lim_{n \to \infty} \frac{1}{1^2+n^2}+\frac{2}{2^2+n^2}+\frac{3}{3^2+n^2}+\cdots+\frac{n}{n^2+n^2}$,Evaluate $$  \lim_{n \to \infty} \frac{1}{1^2+n^2}+\frac{2}{2^2+n^2}+\frac{3}{3^2+n^2}+\cdots+\frac{n}{n^2+n^2}$$ I used definite integral as a limit of a sum as: $$S= \lim_{ n \to \infty}\frac{1}{n} \sum_{r=1}^{n} \frac{\left(\frac{r}{n}\right)}{1+\left(\frac{r}{n}\right)^2}$$ So $$S=\int_{0}^{1}\frac{ x \:dx}{1+x^2}=\frac{1}{2} \log 2$$ Is there any other approach?,"['algebra-precalculus', 'integration', 'limits']"
2383142,trace embedding in fractional sobolev space,"I asked about the compact trace embedding ( trace embedding ). In the answer, embeddings are used to answer my question as follows: 
For $N \ge 3,$ trace map $W^{1,2}(\Omega) \to W^{1/2,2}(\partial \Omega)$ is bounded, inclusion $W^{1/2,2}(\partial \Omega) \to L^1(\partial \Omega)$ is compact, inclusion $W^{1/2,2}(\partial \Omega) \to L^{q^*}(\partial \Omega)$ with $q^* = \frac{2(N-1)}{N-2}$ is bounded. By interpolation, the inclusion $W^{1/2,2}(\partial \Omega) \to L^{q}(\partial \Omega)$ is compact for all $q \in [1,q^*)$, and the claim follows. The only modification needed in the case $N=2$ is that this time $W^{1/2,2}(\partial \Omega) \to L^{q}(\partial \Omega)$ is bounded for all $q<q^*=\infty$, but not for $q=q^*$. This is because the Sobolev embedding doesn't work if $\textrm{order of derivatives} \times \textrm{exponent} = \textrm{dimension}$. The claim follows in the same fashion. He/she said ""If you need a reference, you can find these embeddings in Hitchhiker's guide to the fractional Sobolev spaces( https://arxiv.org/abs/1104.4345 )."" However, I couldn't find the above embeddings in [ https://arxiv.org/abs/1104.4345] exactly. Are there anything I miss? If so, would you explain it in detail? I would be grateful for any comment about it or my original question ( trace embedding )","['functional-analysis', 'sobolev-spaces']"
2383144,"Does Collatz Rule $3x+5$ have a bias for certain loops, or are my results faulty?","Not too long ago, I studied a modified Collatz rule where $$f(x)=
\begin{cases}
3x+5,  & \text{if $x$ is odd} \\
x/2, & \text{if $x$ is even}
\end{cases}$$ by observing the trajectories of $n$ with some code I wrote. The code would calculate the trajectory of each seed or starting number $n$ beginning with $1$ until the trajectory reached a loop. The code will then dump the loop into a spreadsheet and then repeat the process for $n+1$ until some defined limit for $n$ was reached. The resulting spreadsheet contains every starting number and the loops each of those numbers ended up in. I did not record the original trajectories in the spreadsheet. In this Google Document, I created pie charts for the sample sizes 100, 1,000, 10,000, 100,000, and 1,000,000. The results were made by defining some sample size up to some number, sorting all of the numbers based on what loop their trajectories entered, and then creating ratios for those relationships. Here is a link to the raw data my code generated: https://drive.google.com/drive/folders/0BzfYa_--3heeNkVpd1NPd090aDA?usp=sharing (note: Viewing the 10,000 sample size worked just fine for me, however you would need to download the sample sizes 100,000 and 1,000,000 to view them) The results show the percentages vary quite a bit from sample to sample, however in the general scheme of things the data seems to be somewhat consistent. For example, my data shows the 19 loop is the end of roughly half the trajectories of the numbers in the samples. Only one percentage never changed from sample to sample; unsurprisingly, the 20-10-5 loop consisted of 1/5 of all tested values. I am unsure if this “loop bias” I observed is a consequence for relying on a sample size to begin with, human/code error, or if there is a mathematical explanation for what makes certain loops more popular than others. I have a few ideas for why some bias occurs, however I am not confident in them, mostly because my ideas heavily rely on speculation I do not know how to prove formally. EDIT: Here are the loops in order of appearance: [1, 8, 4, 2, 1] [19, 62, 31, 98, 49, 152, 76, 38, 19] [5, 20, 10, 5] [23, 74, 37, 116, 58, 29, 92, 46, 23] [187, 566, 283, 854, 427, 1286, 643, 1934, 967, 2906, 1453, 4364, 2182, 1091, 3278, 1639, 4922, 2461, 7388, 3694, 1847, 5546, 2773, 8324, 4162, 2081, 6248, 3124, 1562, 781, 2348, 1174, 587, 1766, 883, 2654, 1327, 3986, 1993, 5984, 2992, 1496, 748, 374, 187] [347, 1046, 523, 1574, 787, 2366, 1183, 3554, 1777, 5336, 2668, 1334, 667, 2006, 1003, 3014, 1507, 4526, 2263, 6794, 3397, 10196, 5098, 2549, 7652, 3826, 1913, 5744, 2872, 1436, 718, 359, 1082, 541, 1628, 814, 407, 1226, 613, 1844, 922, 461, 1388, 694, 347] EDIT 2: I agree that smaller numbers may be responsible for skewing the data. Therefore, I picked the sample size 100,000 to 1,000,000 to test this theory. I uploaded the results to the original Google Doc with the other pie charts. I was surprised to find, well the same chart. The ratios were slightly different as usual, but aside from that I am unsure to conclude if this test debunks the hypothesis or iterates the small number problem. I could try different sample sizes, however I do not know if that is a good idea or not. To provide some insight on what I think is going on, I will show you a digital version of some notes I sketched and explain where my speculations came from. In May, I drew some sketches of trees and made some speculations about what I observed. I assumed if a loop had a branch or a tail coming from the original even numbers in the loop, then the loop would connect to more numbers. I also assumed smaller even multiples (if $n$ is odd, then an even multiple is $n*2^a$, where $a$ is any value) branching to multiples of three ""restricted"" the size of the loops. Of course, none of these statements are objective, much less provable. I wanted to share them in case there were any interesting mathematical patterns occurring or if this information shed light on anything... Here is a digital version of my sketches. Note: the trees are built using the ""reverse Collatz method"" or ""${(n-1)}/{3}$, or in this case, an adapted version of that method. To divide $n$ by 2, go one number left. To multiply $n$ by 3 and add 5, find the bottom of the ""T"", which points to the next even number. Warning: I showed this to a friend and the tree sketch confused them. If you find this sketch confusing, let me know and I will re-draw the entire thing with arrows instead. Key: If an even number branches, It will have a ""T"" above it. The first odd number on the ""T"" is the resulting odd number after applying ${(n-5)}/{3}$. The following even numbers are the even multiples of the odd number. (ex. In the 19 loop, 38 will have a ""T"" over it. 11 is the resulting odd number, and the even numbers after 11 are $11*2^1$, $11*2^2$, $11*2^3$, ... Blue numbers are members of a loop. Red numbers followed by a ""no"" sign are multiples of 3. Purple ""T""s connect the loop. Green ""T""s emphasize the extra ""tail"" or branch. Orange ""T""s emphasize where a tail could have been, but the number branched to a multiple of 3 instead. Arrows connect the separated ends of the loop. ""..."" are used to convey numbers not shown. I color-coded the sketch to draw attention to certain properties. I figured it would make it easier to understand.","['number-theory', 'combinatorics', 'collatz-conjecture']"
2383169,Finding the value of a given trigonometric series.,"Find the value of $\tan^2\dfrac{\pi}{16}+\tan^2\dfrac{2\pi}{16}+\tan^2\dfrac{3\pi}{16}+\tan^2\dfrac{4\pi}{16}+\tan^2\dfrac{5\pi}{16}+\tan^2\dfrac{6\pi}{16}+\tan^2\dfrac{7\pi}{16}.$ My attempts: I converted the given series to a simpler form: $\tan^2\dfrac{\pi}{16}+\cot^2\dfrac{\pi}{16}+\tan^2\dfrac{2\pi}{16}+\cot^2\dfrac{2\pi}{16}+\tan^2\dfrac{3\pi}{16}+\cot^2\dfrac{3\pi}{16}+1.$ Then I found the following values because I already knew the values of $\sin22.5^{\circ}$ and $\cos22.5^{\circ}$: $\cos^2(\frac{\pi}{16})= \dfrac{2+\sqrt{2+\sqrt2}}{4}$ $\sin^2(\frac{\pi}{16})= \dfrac{2-\sqrt{2+\sqrt2}}{4}$ $\sin^2(\frac{\pi}{8})= \dfrac{2-\sqrt2}{4}$ $\cos^2(\frac{\pi}{8})= \dfrac{2+\sqrt2}{4}$ However, at this stage I feel that my method of solving this problem is unnecessarily long and complicated. Could you guide me with a simpler approach to this question?","['algebra-precalculus', 'trigonometry', 'trigonometric-series']"
2383207,Partitioning the irrational numbers in a special way,"Can the set of  irrational numbers be partitioned into two nonempty subsets , each of which is closed under addition ? I can show that if $A \subseteq \mathbb R$ has the property that $A$ is closed under addition and there is at least two elements in $A$ that can be extended to a Hamel basis of $\mathbb R$ over $\mathbb Q$ then $A$ can be partitioned into two nonempty subsets , each of which is closed under addition . Unfortunately for me , the set of  irrational numbers is not closed under addition . Please help . Thanks in advance","['real-analysis', 'set-theory', 'irrational-numbers']"
2383214,Proof verification: $\int_{\Omega} \left(cf\right) d\mu = c\int_{\Omega} f d\mu$,"This is a proof verification post. I'm attaching the problem and my solution to it. I believe that my solution is too long. Please check it it is correct  and also let me know if there are methods by which I can shorten the proof a bit. Thank you. The Problem : Let $\left(\Omega,\mathcal{F},\mu\right)$ be a measure space and $f,g:\Omega \to \mathbb{R}$ be Borel functions, i.e. $f^{-1}\left(\mathcal{B}\right) \subset \mathcal{F},~g^{-1}\left(\mathcal{B}\right) \subset \mathcal{F},$ where $\mathcal{B}$ denotes the Borel-$\sigma$-field of $\mathbb{R}$. Show that, if $\int_{\Omega} f d\mu$ exists and $c \in \mathbb{R},$ then $\int_{\Omega} \left(cf\right) d\mu$ exists and
$$\int_{\Omega} \left(cf\right) d\mu=c\int_{\Omega} f d\mu$$ My Solution : To show existence, it is enough to show that $cf$ is Borel. We have to show that $\left(cf\right)^{-1}\left(\mathcal{B}\right) \subset \mathcal{F}$. Let us choose (arbitrarily) $B \in \mathcal{B}$. We want to show that $\left(cf\right)^{-1}\left(B\right) \in \mathcal{F}$. Note that, $\left(cf\right)^{-1}\left(B\right)=\left\{\omega \in \Omega : \left(cf\right)\left(\omega\right) \in B\right\}=\left\{\omega \in \Omega : cf\left(\omega\right) \in B\right\}$ Suppose $c=0$. Either we have $0 \in B,$ or $0 \notin B$. Thus, $\left\{\omega \in \Omega : cf\left(\omega\right) \in B\right\}=\left\{\omega \in \Omega : 0 \in B\right\}=\phi \text{ or } \Omega,$ and hence, $\left(cf\right)^{-1}\left(B\right) \in \mathcal{F}$. Now suppose $c \neq 0$. Define, $\frac{B}{c}:=\left\{\frac{b}{c} : b \in B\right\}$. Then,
\begin{align*}
\left(cf\right)^{-1}\left(B\right)&=\left\{\omega \in \Omega : cf\left(\omega\right) \in B\right\}\\
&=\left\{\omega \in \Omega :\exists b \in B, \text{ such that } cf\left(\omega\right)=b\right\}\\
&=\left\{\omega \in \Omega :\exists b \in B, \text{ such that } f\left(\omega\right)=\frac{b}{c}\right\}\\
&=\left\{\omega \in \Omega : f\left(\omega\right) \in \frac{B}{c}\right\}\\
&=f^{-1}\left(\frac{B}{c}\right)
\end{align*}
If we can show that $\frac{B}{c} \in \mathcal{B}$, we are done. Now, $B \in \mathcal{B} \implies \exists \text{ a sequence } \left(A_n\right)_{n=1}^{\infty} \text{ of open intervals in } \mathbb{R} \text{ such that } B=\bigcup_{n=1}^{\infty}A_n$ Claim : $\frac{B}{c}=\bigcup_{n=1}^{\infty}\frac{A_n}{c}$. Now, \begin{align*}
a \in \frac{B}{c} &\implies \exists b \in B, \text{ such that } a=\frac{b}{c}\\
&\implies \exists n \in \mathbb{N} \setminus \left\{0\right\}, \text{ and } b \in A_n, \text{ such that } a=\frac{b}{c}\\
&\implies \exists n \in \mathbb{N} \setminus \left\{0\right\}, \text{ such that } a=\frac{A_n}{c}\\
&\implies a \in \bigcup_{n=1}^{\infty} \frac{A_n}{c}
\end{align*} Thus, $$\frac{B}{c} \subset \bigcup_{n=1}^{\infty} \frac{A_n}{c}$$
To show the other side, \begin{align*}
a \in \bigcup_{n=1}^{\infty} \frac{A_n}{c} &\implies \exists n \in \mathbb{N} \setminus \left\{0\right\}, \text{ such that } a=\frac{A_n}{c}\\
&\implies \exists n \in \mathbb{N} \setminus \left\{0\right\}, \text{ and } b \in A_n, \text{ such that } a=\frac{b}{c}\\
&\implies \exists b \in B, \text{ such that } a=\frac{b}{c}\\
&\implies a \in \frac{B}{c}
\end{align*}
Thus, $$\bigcup_{n=1}^{\infty} \frac{A_n}{c} \subset \frac{B}{c}$$
Hence we have, $$\frac{B}{c}=\bigcup_{n=1}^{\infty} \frac{A_n}{c}$$ The crucial (although trivial) thing is that for all $n \in \mathbb{N} \setminus \left\{0\right\}, A_n \text{ is an open interval in } \mathbb{R} \implies \frac{A_n}{c} \text{ is an open interval in } \mathbb{R}$. And hence, $\frac{B}{c} \in \mathcal{B}$. This completes the existence part. Now to show that,
$$\int_{\Omega} \left(cf\right) d\mu=c\int_{\Omega} f d\mu \tag{1}$$ If $c=0,$ $(1)$ holds trivially. $$\text{By definition, }L.H.S.=\int_{\Omega} \left(cf\right) d\mu=\int_{\Omega} \left(cf\right)^+ d\mu-\int_{\Omega} \left(cf\right)^- d\mu$$
$$\int_{\Omega} \left(cf\right)^+ d\mu=\sup\left\{\int_{\Omega}\psi d\mu : \psi \text{ is a simple function}, 0 \leq \psi \leq \left(cf\right)^+\right\}$$
Suppose, $c>0$. Then, $\left(cf\right)^+ = \max\left\{cf,0\right\} = c \max\left\{f,0\right\} = cf^+$ \begin{align*}
\int_{\Omega} \left(cf\right)^+ d\mu&=\sup\left\{\int_{\Omega}\psi d\mu : \psi \text{ is a simple function}, 0 \leq \psi \leq cf^+\right\}\\
&=\sup\left\{\int_{\Omega}\psi d\mu : \psi \text{ is a simple function}, 0 \leq \frac{\psi}{c} \leq f^+\right\}\\
&=\sup\left\{\int_{\Omega}c\cdot\frac{\psi}{c} d\mu : \frac{\psi}{c} \text{ is a simple function}, 0 \leq \frac{\psi}{c} \leq f^+\right\}\\
&\left[\psi \text{ is a simple function } \implies \frac{\psi}{c} \text{ is a simple function } \right]\\
&=\sup\left\{\int_{\Omega}c\psi^* d\mu : \psi^* \text{ is a simple function}, 0 \leq \psi^* \leq f^+\right\}\\
&=\sup\left\{c\int_{\Omega}\psi^* d\mu : \psi^* \text{ is a simple function}, 0 \leq \psi^* \leq f^+\right\}\\
&=c\sup\left\{\int_{\Omega}\psi^* d\mu : \psi^* \text{ is a simple function}, 0 \leq \psi^* \leq f^+\right\}\\
&=c\int_{\Omega} f^+ d\mu
\end{align*} In the same way, $\int_{\Omega} \left(cf\right)^- d\mu = c\int_{\Omega} f^- d\mu,$ and hence, $$\int_{\Omega} \left(cf\right) d\mu=\int_{\Omega} \left(cf\right)^+ d\mu-\int_{\Omega} \left(cf\right)^- d\mu=c\int_{\Omega} f^+ d\mu-c\int_{\Omega} f^- d\mu=c\int_{\Omega} f d\mu$$ Similarly, if $c<0,$ we have $\left(cf\right)^+ = \max\left\{cf,0\right\} = c\min\left\{f,0\right\} = -c\max\left\{-f,0\right\} = -cf^-,$ and hence, $\int_{\Omega} \left(cf\right)^+ d\mu = -c\int_{\Omega} f^- d\mu$. Also in this case, $\left(cf\right)^- = \max\left\{-cf,0\right\} = -c\max\left\{f,0\right\} = -cf^+,$ and hence,
$\int_{\Omega} \left(cf\right)^- d\mu = -c\int_{\Omega} f^+ d\mu$. Thus we have
$$\int_{\Omega} \left(cf\right) d\mu=\int_{\Omega} \left(cf\right)^+ d\mu-\int_{\Omega} \left(cf\right)^- d\mu=-c\int_{\Omega} f^- d\mu+c\int_{\Omega} f^+ d\mu=c\int_{\Omega} f d\mu$$ Hence, in all the cases, $(1)$ holds. Hence the proof.","['real-analysis', 'integration', 'measure-theory', 'proof-verification']"
2383227,How can I know the number of asymptotes of a function?,"I want to know that given function has how many asymptotes, I am trying this one asymptotes y = x^3 giving me answer x^3 not the numbers of asymptotes Here my function is y=x^3 . Any suggestion please.","['calculus', 'functions']"
2383242,Is a product of two modulus functions the modulus of the product of the functions?,I would just like to ask a simple question: Is the following statement true? And is there a simple proof for it? $$|f(x)| \cdot|g(x)| = |f(x)\cdot g(x)| $$,"['algebra-precalculus', 'functions']"
2383248,A conjecture inspired by the abc-conjecture,"This conjecture is obviously inspired by the abc-conjecture: Let $\gcd(a,b)=1$ then $\operatorname{rad}((a+b)ab(ab+a+b))> ab+a+b$ I am not asking for a proof, just for possible counterexamples, if they exist.
I checked this with the computer for some numbers, and didn't find any counterexample. What I checked so far $(\gcd(a,b)=1)$ : $1 \le a,b \le 1000$ $a=1$ , $1 \le b \le 10^6$ $1 \le m \le 10^6$ , $a=m,b=m+1$ Heuristic that this is true for infinetly many $b$ :
If $p\neq 2$ is a prime, then set $b = \frac{p-1}{2}, a = 1$ .
Then $\operatorname{rad}((a+b)ab(ab+a+b)) = \operatorname{rad}(\frac{p-1}{2}\frac{p+1}{2}p) > p = ab+a+b$ Another way to prove that there are infinitely many $(a,b)$ which fulfill the conjecture:
Choose some $a \in \mathbb{N}$ . Since $\gcd(a,a+1)=1$ , by the ( https://en.wikipedia.org/wiki/Dirichlet%27s_theorem_on_arithmetic_progressions ) Dirichlet theorem on arithmetic progression there are infinitely many primes of the form $p = b(a+1)+a = ab + a +b$ . Then necessarily $\gcd(a,b)=1$ , otherwise if $g=\gcd(a,b)$ $a = g a_1$ and $b=g b_1$ then $g | p$ and hence $g=p$ , which is impossible since $p = g ( a_1 b_1+a_1+b_1)$ and we must have $3 \le a_1b_1+a_1+b_1=1$ , which can not work. Then $\operatorname{rad}((a+b)ab(ab+a+b)) = \operatorname{rad}((a+b)ab \cdot p) > p = ab + a +b$ Edit :
If someone finds another way to produce infinitely many tuples $(a,b)$ which fulfill the conjecture, that would also be interesting. Second Edit :
Related question: https://mathoverflow.net/questions/343245/other-examples-of-irreducible-similarities-over-the-natural-numbers","['number-theory', 'computational-mathematics', 'conjectures', 'abc-conjecture']"
2383269,"What do we need Sobolev-spaces $W^{k, p}$ with $p \neq 2$ for?","In the course on PDE's I took this semester we talked a lot about the theory of Sobolev-spaces $W^{k, p}(\Omega)$ for $\Omega \subset \mathbf{R}^n$ an open set, $k \in \mathbf{N}$ and $1 \leq p \leq \infty$. But then we only used the Sobolev-spaces with $p = 2$ to deal with PDE's, since we can use the Riesz-Representation theorem on a suitable subspace of $W^{k, 2}(\Omega)$ (which is a Hilbert-space). For $p \neq 2$, we can't use the Riesz-Representation theorem, so we don't get weak solutions for $W^{k, p}(\Omega)$. My question now is: Why do we introduce general Sobolev-spaces, instead of just limiting ourselves to $W^{k, 2}(\Omega)$? Are there any applications to the theory of PDE's (or other parts of mathematics) of Sobolev-spaces with $p \neq 2$? Thanks!","['functional-analysis', 'real-analysis', 'sobolev-spaces', 'partial-differential-equations']"
2383397,Differentiability of the sum of $\sum_{n=1}^{\infty}\frac{\sin(nx)}{n^2}$,"Consider the series $$\sum_{n=1}^{\infty}\frac{\sin(nx)}{n^2}$$
This series converges uniformly to a continuous function, by Weierstrass's test, and it is the Fourier series of its sum, I'll call $f(x)$. Is $f$ continuously differentiable in $[-\pi, \pi]$? The common criterion to determine differentiability of the sum of uniformly convergent series is by testing uniform convergence of the series of derivatives. But I don't see how it's applicable here. This question: The Fourier series $\sum_{n=1}^\infty (1/n)\cos nx$ calculates the sum of the derivatives. But is there an argument to say that $f$ is not differentiable (based on the answer there), without calculating the explicit sum?","['real-analysis', 'fourier-series']"
2383440,Fundamental Theorem of Algebra - an elementary complex analysis proof?,"We begin by assuming that a non-constant complex polynomial $$p(z)=a_n z^n+a_{n-1}z^{n-1}+...+a_1 z+a_0,$$ where $a_0 \neq 0$, doesn't vanish in $\mathbb{C}$. Therefore $1/p$ is also an analytical function everywhere. Note that $(p(z)-a_0)/z$ is a polynomial and therefore, due to Cauchy's theorem, the following integral must be zero. $$\int_{S_r^1}\frac{(p(z)-a_0)/z}{p(z)}dz=\int_{S_r^1}\frac{a_nz^{n-1}+a_{n-1}z^{n-2}+...+a_1}{a_nz^n+a_{n-1}z^{n-1}+...+a_1 z+a_0}dz=0.$$ On the other hand $$\int_{S_r^1}\frac{a_nz^{n-1}+a_{n-1}z^{n-2}+...+a_1}{a_nz^n+a_{n-1}z^{n-1}+...+a_1 z+a_0}dz$$ $$=\int_{0}^{2\pi}\frac{a_n(re^{i\theta})^{n-1}+a_{n-1}(re^{i\theta})^{n-2}+...+a_1}{a_n(re^{\theta})^n+a_{n-1}(re^{i\theta})^{n-1}+...+a_1 (re^{i\theta})+a_0}(ire^{i\theta})d\theta$$ $$=\int_{0}^{2\pi}i d\theta - \int_{0}^{2\pi}\frac{a_0 i}{a_n(re^{i\theta})^n+a_{n-1}(re^{i\theta})^{n-1}+...+a_1 (re^{i\theta})+a_0}d\theta$$ $$=2\pi i -\int_{0}^{2\pi}\frac{a_0i}{p(re^{i\theta})}d\theta.$$ Let $r \rightarrow \infty$ and the integral approaches value $2\pi i$ - a contradiction. Therefore $1/p$ can't be entire and $p$ must vanish somewhere in the complex plane. EDIT: I have changed this post and deleted the idea that the integral $\int_{\partial D_r}\frac{(p(z)-a_0)/z}{p(z)}dz=0$ could be evaluated with the fundamental theorem of calculus. Now, as it stands, this proof is essentially the same as the one that Mr. José Carlos Santos points out in his comment.","['complex-analysis', 'alternative-proof', 'analysis', 'complex-integration']"
2383461,Find the general solution of $3\csc^2 x - 4=0$.,"Find the general solution of $3\csc^2 x - 4 =0$. My Attempt: $$3\csc^2 x - 4=0$$
$$\csc^2 x =\dfrac {4}{3}$$
$$\csc x = \pm \dfrac {2}{\sqrt {3}}$$",['trigonometry']
2383476,On the solution of the functional equation $(x(t))^{p}u(t)=(x\circ f)(t)$,"I am given a real number $p$ and two real valued functions $f(t),u(t)$ on $\mathbb{R}$ You can assume $u(t)$ and $f(t)$ are as nice as they need to be, including that they're invertible. I am trying to find a function $x(t)$ that solves the equation $$(x(t))^{p}u(t)=(x\circ f)(t).$$ Ideally, the solution for $x(t)$ is some expression involving $u(t)$ and $f(t).$ Also, observe if $t^{*}$ is a fixed point of $f$ and $p\neq1,$ then $$x(t^{*})=(u(t^{*}))^{\frac{1}{1-p}}.$$","['functional-analysis', 'analysis', 'functional-equations']"
2383477,"Find $a,b$ for $f(x) = \frac{x^2-x+a}{x^2-4x+b}$ when $f(x)\le-\frac{7}{2}$ or $f(x) \ge \frac{1}{2}$","I'm self-studying and have attempted the following question. I don't have access to a worked solution. Find $a,b$ for real $x$: $$f(x) = \frac{x^2-x+a}{x^2-4x+b}\quad when\quad f(x)\le-\frac{7}{2}\space or\space f(x) \ge \frac{1}{2}$$ I however keep getting stuck and find myself always facing division by $0$. I have a feeling I'm missing some intuition here. I don't think there are operation or arithmetic errors. I am not confident that I have setup the equations correctly either. My questions are: 1) What is the correct approach here / key idea I'm missing? 2) What is the solution? A sample of my working is as follows: $$\frac{x^2-x+a}{x^2-4x+b} = -\frac{7}{2}\Rightarrow 9x^2-30x = b - 2a\qquad [1]$$
$$\frac{x^2-x+a}{x^2-4x+b} = \frac{1}{2}\Rightarrow x^2+2x = b-2a \qquad [2]$$
$$[2]-[1]:\qquad 8x^2 - 32x = 0 \Rightarrow x(x-4) = 0\Rightarrow x=0,x=4$$ $x = 0$ leads to $b=0$ which leads to division by $0$ so I discarded it. Subbing $x=4$ gives: $$\frac{12 + a}{b} = -\frac{7}{2} \Rightarrow 24 + 2a = -7b \qquad [3]$$
$$\frac{12+1}{b} = \frac{1}{2} \Rightarrow 24 + 2a = b \qquad [4]$$ $[3] + 7[4]$ gives: $$192 + 16a = 0 \Rightarrow a = -\frac{192}{16} \Rightarrow a = -12$$ Subbing $a=-12$ into $[4] \Rightarrow b = 0$ So for $x=4,a=-12,b=0$ the denominator becomes $0$.","['algebra-precalculus', 'problem-solving', 'functions']"
2383480,Synthetic proof of Euclidean geometry problem,"Problem: $\triangle{ABC}$ is such that $\angle B=\angle C=50°$. $D$ and $E$ lie on $BC$ and $AC$ respectively such that 
$\angle ABE = 30^{\circ}$ and $\angle BAD = 50°$.
Let $F$ be the intersection point  of $AD$ and $BE$.  Find $\angle BED=x$. I am able to do this using trigonometry. But I want a synthetic proof of this which I have failed to find. I did find a couple of congruent triangles and a few tangent circles.There is even the famous $80-80-20$ triangle in the figure. Please help. My solution: I apply the sine rule to $\triangle FED$ and $\triangle AFE$ $$\frac{\sin x}{FD}=\frac{\sin(100°+x)}{FE}=\frac{\sin (x+100°) \sin70°}
{AF\sin 30° }.$$ Now, using 
$$\frac{FD}{AF}=\frac{DB  \sin20°}{AB \sin 30° }$$ and 
$$\frac{DB}{AB}=\frac{\sin 50}{\sin 80}$$ I get 
$$\sin x \sin80 =\sin(x+100)\sin70\sin20 \sin 50, $$ 
and $40^{\circ}$ solves this as can be easily guessed once the above is reduced to the following: 
$$\sin(x)=8\sin(x+100)\cos(20)\cos(40)\cos(80).$$","['contest-math', 'euclidean-geometry', 'trigonometry']"
2383502,"How does Rudin's rank theorem apply to the map $F(x,y)=x^2+y^2$?","Intuition regarding the ""rank theorem"" in Rudin's Principle of Mathematical Analysis has been asked several times in this site: I'm trying to understand how this theorem applies to the following example. Consider $F:{\bf R}^2\to{\bf R}$ with
$$
F(x,y)=x^2+y^2
$$
So here we have $n=2$ and $m=r=1$. Take $a=(1,0)$. Then $A=[2,0]$ and thus $Y_1={\bf R}$ and $Y_2=\{0\}$. Here are my questions : What should be $V$, $H$ and $\varphi$ for this example? What does the rank theorem really say about this example?","['multivariable-calculus', 'real-analysis']"
2383534,A map without fixed points homotopic to $-x$,"Let $ f: S^2 \to S^2 $ be a map without fixed points, then it's 
  homotopic to $ g(x) = -x $ . (Hint: look at a great circle that contains $ x $ and $ f(x)$ ). I don't understand the hint. What I tried to do is to do someting like Borsuk-Ulam and take $ g(x) = \frac{f(x) - x}{||f(x)-x||} $ , and I don't know how to continue. The only insight I found is that $ f(x) $ isn't nullhomotopic, but that's not seems useful. So how can I prove that statement?","['algebraic-topology', 'general-topology']"
2383585,What's the difference/connection between PCA and inverse Fourier transform?,"Principle Component Analysis (PCA) finds the component with the highest contribution, which is very similar to the idea of inverse Fourier transform, which finds the frequency with the highest weight. Could someone help clarify their difference/connection. It seems that they are connected in some mathematical forms.","['wavelets', 'fourier-analysis', 'signal-processing', 'svd', 'analysis']"
2383589,"How can i prove that linear function does not form a vector space basis of $\mathcal{C}\bigl([0,1]\bigr)$ over $\mathbb R$?","Prove that the linear function does not form a vector space  basis  of $\mathcal{C}\bigl([0,1]\bigr)$ over $\mathbb R$? i was trying this question many times but i could not get it.
i was taking   the  scalar  multiplication and  addition property
it was showing that this vector  form  vector space
ie  it contain the zero vector i dont know from where i have to start
if anybody help me , i would be very thankful to him","['functional-analysis', 'linear-algebra', 'linear-transformations', 'vector-spaces']"
2383625,About Generalized Hypergeometric Function,"I have a definition of Generalized hypergeometric function as $$_1F_2(a_1;b_1,b_2;z) = \sum_{n=0}^\infty \frac{(a_1)_n}{(b_1)_n (b_2)_n} \frac{z^n}{n!}$$ 
My question is, what will be the result if $a_1$ equals to zero? I couldn't come across any definition defining this special case. Thanks.","['hypergeometric-function', 'sequences-and-series', 'functions']"
2383675,On inequalities for norms of matrices,"I have a matrix $A \in \mathbb{R}^{n \times n}$ and would like to know about the relationship between the $\| A \|_\infty$ (i.e., the maximum element of the matrix) and the operator-induced norm $\| A \|$. I know that the following upper-bound holds (from Matrix Norm Inequality ): $ \| A \|_\infty \leq \sqrt{n} \| A \| $? But, I am trying to find a lower-bound? (Would the lower-bound possibly be comprised of the minimum singular value times some factor of $n$?) Also, I need this lower bound to have a norm that has the sub-multiplicative property: given square matrices $A,B \Rightarrow \| A B \|_{\infty} \geq \| A \|_p \| B \|_p $ But, is there an appropriate norm/$p$ that suits this?","['matrices', 'normed-spaces']"
2383680,Help defining a topological property,"After an introductory course in General Topology I started to look up many examples of topologies (mainly on $\mathbb{R}$) just to get a feel for how different they can be and it seems to me that they all can be fit in one of the following classes: Topologies with ""special points"" like the $K$-topology or the collapse $\mathbb{R}/\mathbb{Z}$ where the neighborhoods of the point $0$ are substantially different from those of the other points. Topologies in which all points are ""alike"" such as the standard topology on $\mathbb{R}$ or the cofinite topology. I attempted to formalize this property for topologies of type (2): if $U$ is a neighborhood of any point $x$ then every other point $y$ have a neighborhood $V_y$ homeomorphic to $U$ . My question is: is this intuition justified?",['general-topology']
2383695,Why should we have $\sin^2(x) = \frac{1-\cos(2x)}{2}$ knowing that $\sin^2(x) = 1 - \cos^2(x)$?,"Why should we have $\sin^2(x) = \frac{1-\cos(2x)}{2}$ knowing that $\sin^2(x) = 1 - \cos^2(x)$? Logically, can you not subtract $\cos^2(x)$ to the other side from this Pythagorean identity $\sin^2(x)+\cos^2(x)=1?$ When I look up trig identities, however, it says $\sin^2(x) = \frac{1-\cos(2x)}{2}$. Why is this?",['trigonometry']
2383696,When is a quotient group abelian?,"Every subgroup of an abelian group is normal, and every quotient of an abelian group is abelian. Also, a subgroup of a nonabelian group need not be normal, and a quotient of a nonabelian group need not be abelian. Is there a simple set of (sufficient, necessary) conditions for a quotient of a nonabelian group to be abelian? I found one here . Let $G$ be a group with commutator subgroup $G'$, let $N$ be a normal subgroup of $G$. Now $G/N$ is a abelian iff $G'$ is a subset of $N$. Are there others? Bonus question . A nonabelian group where every proper subgroup is normal is called Hamiltonian. What do you call a nonabelian group where every proper subgroup is abelian? What do you call a nonabelian group where every quotient group is abelian? (Then the commutator subgroup is a subset of every normal subgroup.)","['abelian-groups', 'abstract-algebra', 'group-theory', 'quotient-group']"
2383710,A sufficient condition for a sequence to converge if arithmetic mean of the sequence converges?,"We have a well-known conclusion: If a sequence $\{a_n\}_{n\in\mathbb{N}}$ converges, then the arithmetic mean $\frac{S_n}{n}$ (where $S_n=\sum\limits_{k=1}^na_k$ is the nth partial sum)  converges to the same limit. $\lim\limits_{n\to\infty}a_n=a\implies\lim\limits_{n\to\infty}\frac{S_n}{n}=a$ I hope the inverse process also works, so I add a condition: Sequence $\{n(a_n-a_{n-1})\}_{n\in\mathbb{N}}$ is bounded, i.e, $\exists M>0,\forall n\in\mathbb{N},|n(a_n-a_{n-1})|<M$ With such condition, can $\frac{S_n}{n}$ converges implies $a_n$ converges? I want to prove that $\lim\limits_{n\to\infty}\frac{S_n}{n}=a,\ |n(a_n-a_{n-1})|<M\implies \lim\limits_{n\to\infty}a_n=a$ I see that $|a_n-\frac{S_n}{n}|=\frac{1}{n}|\sum\limits_{k=2}^n (k-1)(a_{k}-a_{k-1})|  \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \leq\frac{1}{n}\sum\limits_{k=2}^n |(k-1)(a_{k} - a_{k-1})|\\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \leq\frac{1}{n}\sum\limits_{k=2}^n |k(a_{k} - a_{k-1})|\\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ < \frac{(n-1)M}{n}<M$ then $|a_n|\leq |\frac{S_n}{n}|+M$ means that $\{a_n\}$ is bounded. Now I can't continue the proof (Maybe consider a convergent subsequence of$\{a_n\}$? I failed..). Does the added condition works? Could you prove that? Sincerely looking forward to your help. Thanks!","['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
2383718,Linear Algebra - basis question,"I am revising for a Linear Algebra exam by going through some previous quiz questions, that I have True/False answers to, but not the reasoning or counterexamples. I am stuck on the following: If $v_1,v_2,v_3,v_4$ is a basis for $V$, and $U$ is a subspace of $V$ such that $v_1,v_2\in U$ but $v_3,v_4\notin U$, then $v_1,v_2$ is a basis of U. The answer is listed as False, which intuitively seems right, but I can't seem to find a counterexample.",['linear-algebra']
2383721,Relations between two versions of the rank theorem in Rudin and Lee,"This a follow-up question to a previous one of mine regarding Rudin's rank theorem: @ Jack Lee gives the following theorem in his Introduction to Smooth Manifolds : As I understand, Theorem 4.12 should be a generalization of 9.32. But I don't completely understand how one can be translated into another. Here is my question : How is (66) related to (4.1)? One can see that $(H,V)$ (or $(H^{-1},V)$ according to different convention) in Theorem 9.32 plays the role of the chart $(U,\varphi)$ in Theorem 4.12. What really puzzles me is that how one can translate the R.H.S of (66) to that of (4.12).","['multivariable-calculus', 'real-analysis', 'differential-topology']"
2383729,Arithmetic Sequences in Finite Set,"Consider a finite set $S\subset \mathbb{N}_{\geq 1}$ which contains no arithmetic sequences of length greater than $l$. For each arithmetic sequence of length $l$ contained in $S$, place the greatest element of this arithmetic sequence in a new set, which we call $\overline{S}$. For what values of $l$ is it possible for $$|S\setminus \overline{S}|<|\overline{S}|$$ For $l=3$, the set $A=\{1, 17, 41, 52, 69, 79, 81, 86, 87, 89, 92, 93, 94\}$ (which has no arithmetic sequences of length $4$) has $\overline{A}=\{81, 86, 87, 89, 92, 93, 94\}$, so the inequality can be satisfied. However, it seems like finding such a set should not be possible for $l\geq4$, but I can't find a nice proof.","['number-theory', 'arithmetic-progressions', 'elementary-set-theory']"
2383739,I need to figure out Why wouldn't a limit exist if we got the SAME value on each path?,"When talking about limits for functions of several variables, why isn’t it sufficient to say,
$$\lim_{(x,y)\to(0,0)} f(x,y)=L$$ if $f(x,y)$ gets close to $L$ as we approach $(0,0)$ along the $x$-axis ($y = 0$) and along the $y$-axis ($x = 0$)?","['multivariable-calculus', 'calculus', 'limits']"
2383751,How is a doubly twisted cylinder different from a cylinder?,"Imagine bending a square sheet of paper and gluing two opposite edges together. The most natural way to do this results in a cylinder with open ends. Call this object $C_0$. If one twists the sheet one half turn ($180^{\circ}$) and glues the edges, one obtains a Mobius band. Call that object $C_1$. It's easy to imagine object $C_n$ with $n$ twists. Notice that $C_n$ is homeomorphic to $C_m$ whenever $m-n$ is even, since the gluing identifications are the same. In particular, $C_0$ and $C_2$ are homeomorphic. Thus, topologically, $C_0$ and $C_2$ are equivalent. But intuitively, they strike me as different: one cannot continuously deform $C_0$ into $C_2$ without ripping the paper or some such thing. My (soft) question: what's the best way to understand this difference between $C_0$ and $C_2$? I'm clearly thinking of $C_0$ and $C_2$ as embeddings of $S^1\times[0,1]$ into $\mathbb{R}^3$. I think one can describe the difference between $C_0$ and $C_2$ as a difference between their embedding maps -- they're not homotopic in some way. (I'm not sure exactly how to formulate the non-equivalence of the embeddings.) But does one even need to refer to embeddings to capture the difference between $C_0$ and $C_2$?
 Intuitively, it seems to me the difference is largely, if not completely, independent of the space in which they're embedded. I'm inspired by the beautiful way manifold theory is built up without ever needing to describe the manifold as embedded in a higher dimensional space. Can one distinguish between $C_0$ and $C_2$ without embedding them, or at least showing that the distinction is independent of the space in which they're embedded?","['algebraic-topology', 'general-topology', 'homotopy-theory', 'manifolds']"
2383775,What is $\frac{x^2}{|x|}$ at $x=0$,"Why $\frac{x^2}{|x|}$ is not defined on $x=0$. It should be $0$, since $\frac{x^2}{|x|}=|x|$, isn't?","['calculus', 'functions']"
2383782,About the zeroes of an almost-periodic function,"Recently, when providing an answer to a question asking to prove the boundedness of an integral function, I invoked the following Lemma: Lemma. Let $\varphi(t)=\sin(t)+\cos(t\sqrt{2})$. Such function is not periodic, but it is bounded, Lipshitz-continuous and with mean zero, i.e. $\lim_{b\to +\infty}\frac{1}{b-a}\int_{a}^{b}\varphi(t)\,dt = 0$. Its real zeroes are simple, hence by denoting as $\zeta_0<\zeta_1<\zeta_2<\zeta_3<\ldots$ the real positive zeroes we have that
  $$ E = \sup_{n\in\mathbb{N}}\left(\zeta_{n+1}-\zeta_n\right) < +\infty. $$ Now my actual question : Q: How can we improve the previous inequality and show, for instance, that $E\leq 2\pi$? My thoughts: If one is able to produce accurate bounds for $\frac{1}{2\pi i}\oint_{\gamma}\frac{\varphi'(t)}{\varphi(t)}\,dt$, with $\gamma$ being the boundary of a thin rectangle in the complex plane enclosing the real interval $[a,b]$, is also able to estimate the density of real zeroes; If for some non-negative function $\psi(t)$ over the interval $[a,b]$ the integrals $\int_{a}^{\frac{a+b}{2}}\varphi(t)\psi(t)\,dt $ and $\int_{\frac{a+b}{2}}^{b}\varphi(t)\psi(t)\,dt $ have opposite signs, $\varphi(t)$ has a zero in $[a,b]$. But what is an efficient way for constructing such weigth functions $\psi$? Can we exploit the convergents of the continued fraction of $\sqrt{2}$? It might by practical to consider the winding number of the curve $\gamma:[0,T]\to \mathbb{C}$ given by $\gamma(t) = e^{it}+e^{it\sqrt{2}}$.","['real-analysis', 'inequality', 'trigonometry', 'integral-inequality']"
2383838,"The understanding of random variables and their arithmetic, can't wrap my head around it.",Recently started studying probability and statistics. What I first learned is that random variables are like functions taking outcomes from an experiment and plotting them to a number on the real-axis. I feel that my interpretation can't be applied to for example the definition of the central limit theorem where we are asked to sum independent identically distributed random variables. Should I think of the addition like the addition of two arbitrary results of the random variables?,"['probability-theory', 'central-limit-theorem', 'random-variables']"
2383844,"About the (non-trivial, this time) zeroes of an almost-periodic function","This is a follow-up on my previous question that turned out to be almost-trivial. Let $\varphi(t)=\sin(t)+\sin(t\sqrt{2})+\sin(t\sqrt{3})$. Such function is not periodic, but it is bounded, Lipshitz-continuous and with mean zero, i.e. $\lim_{b\to +\infty}\frac{1}{b-a}\int_{a}^{b}\varphi(t)\,dt = 0$. Its real zeroes are simple, hence by denoting as $\zeta_0<\zeta_1<\zeta_2<\zeta_3<\ldots$ the real positive zeroes we have that
$$ E = \sup_{n\in\mathbb{N}}\left(\zeta_{n+1}-\zeta_n\right) < +\infty. $$ Now my actual question : Q: How can we improve the previous inequality and show, for instance, that $E\leq 2\pi$? My thoughts: If one is able to produce accurate bounds for $\frac{1}{2\pi i}\oint_{\gamma}\frac{\varphi'(t)}{\varphi(t)}\,dt$, with $\gamma$ being the boundary of a thin rectangle in the complex plane enclosing the real interval $[a,b]$, is also able to estimate the density of real zeroes; If for some non-negative function $\psi(t)$ over the interval $[a,b]$ the integrals $\int_{a}^{\frac{a+b}{2}}\varphi(t)\psi(t)\,dt $ and $\int_{\frac{a+b}{2}}^{b}\varphi(t)\psi(t)\,dt $ have opposite signs, $\varphi(t)$ has a zero in $[a,b]$. But what is an efficient way for constructing such weigth functions $\psi$? Can we exploit the convergents of the continued fractions of $\sqrt{2}$ and/or $\sqrt{3}$? It might by practical to consider the winding number of the curve $\gamma:[0,T]\to \mathbb{C}$ given by $\gamma(t) = e^{it}+e^{it\sqrt{2}}+e^{it\sqrt{3}}$. Addendum: an explicit proof of $E<+\infty$ through Diophantine Approximation. Let $R\subset\mathbb{R}^+$ the set of real numbers such that $r,r\sqrt{2},r\sqrt{3}$ are simultaneously close to integer multiples of $\pi$. For any $r\in R$ we have that $\varphi(r)$ is close to zero: since $\varphi$ is bounded and Lipschitz-continuous, it is enough to show that $R$ is syndetic to have that $E$ is finite. If we consider a cube with side length $\varepsilon>0$ centered at $\frac{m}{\pi}\left(1,\sqrt{2},\sqrt{3}\right)\pmod{1}$ we easily get than for some integer $m\leq\frac{1}{\varepsilon^3}$ the numbers $m,m\sqrt{2},m\sqrt{3}$ are simultaneously at most $\pi\varepsilon$-apart from an integer multiple of $\pi$. By choosing $\varepsilon=\frac{1}{3\pi}$ the ridiculous bound $E\leq 6+27\pi^3$ can be easily derived. The inequality $E\leq 12$ can be deduced from my approach below, however the optimal bound for $E$ seems to be around $4.5$, so there still is some work to be done.","['real-analysis', 'inequality', 'trigonometry', 'integral-inequality']"
2383859,"Prove that there is a unique real number $x$ such that for every real number $y$, $xy + x -17 = 17y$.","My attempt is as follows. I factored $xy + x - 17 - 17y$ into $(x-17)(y+1)$ and got solutions: $x=17,y=-1$.
So in this case; Is my unique value for $x$, $x=17$.
I tried using $y=-1$ but it just reduced $xy + x - 17 = 17y$ to $0=0$.
Am I approaching this problem correctly?","['algebra-precalculus', 'elementary-number-theory']"
2383877,How many total orders consistent with a partial order?,"I have a finite set of objects $X$, whose power set is partially ordered by $\subseteq$. Consider all possible total orderings of the power set $\mathscr{P}(X)$ which are compatible with the partial order $\subseteq$ in the sense that $A \subsetneq B \Rightarrow A \prec B$. How many compatible total orders are there? Some orders $\prec$ have the special property that they can be concretely quantified by assigning numerical weights to each element in the set; then a subset has a smaller total weight than another subset if and only if the subsets are related by $\prec$. Specifically, this means that you can find a weight assignment function $f:\mathscr{P}(X)\rightarrow \mathbb{R}^+$ such that every subset's weight is the sum of its elements' weights: $$\forall S\subseteq X,\quad f(S) = \sum_{x\in S} f(\{x\})$$
and the weight respects order in that $f(S) < f(T) \iff S \prec T.$ How many quantifiable total orders are there?  (For my applications, I'm interested in weight assignments where $f(S) = 0 \iff S = \varnothing$.)","['combinatorics', 'measure-theory', 'order-theory']"
2383956,Algebraic dependence of polynomials in several variables,"Let $a_1,a_2 \in k[x_1,x_2]$, $k$ is a field of characteristic zero.
There is a result (that can be found in a paper of Nagata , Corollary 1.3) saying that if $a_1$ and $a_2$ are algebraically dependent over $k$, then there exists a polynomial $h \in k[x_1,x_2]$ such that $a_1=u_1(h)$ and $a_2=u_2(h)$, where $u_1(t), u_2(t) \in k[t]$. My question is what happens in higher dimensions, namely: Let $a_1,\ldots,a_n \in k[x_1,\ldots,x_n]$, $k$ is a field of characteristic zero.
  Is it true that if $a_1,\ldots,a_n$ are algebraically dependent over $k$, then there exist $n-1$ polynomials $h_1,\ldots,h_{n-1} \in k[x_1,\ldots,x_n]$ such that $a_i=u_i(h_1,\ldots,h_{n-1})$, where $u_i(t_1,\ldots,t_{n-1}) \in k[t_1,\ldots,t_{n-1}]$,
  $1 \leq i \leq n$. For example, $n=3$, $a_1=a_2=xyz$, $a_3=z$, so in this case $h_1=xyz$ and $h_2=z$. Remarks: (1) In $k[x_1,\ldots,x_n]$, $n$ polynomials are algebraically dependent iff their Jacobian is zero.
(2) Perhaps there is a connection between my above question and the kernel conjecture? Thank you very much for any help!","['polynomials', 'field-theory', 'algebraic-geometry', 'commutative-algebra']"
2383989,Proof of the identity $\sin(x+y) =\sin(x)\cos(y) + \cos(x)\sin(y)$ for all $x$ and $y$ [duplicate],"This question already has answers here : Proof of the angle sum identity for $\sin$ (5 answers) Closed 6 years ago . I don't know if I'm asking for too much, but the proofs I've seen of the statement $$\sin(x+y) =\sin(x)\cos(y) + \cos(x)\sin(y)$$ consist of drawing a couple of triangles, one on top of each other and then figuring out some angles and lengths until they arrive at the identity. And I agree with the proof, is just that, even by flipping the triangle around, it only proves the identity for the case $x+y<\pi/2$, or if it does prove it for all values of $x$ and $y$, I wouldn't understand why. As to construing a proof by using Euler's identity or the derivatives of sin and cos, I would ask the writer to first prove his/her already accepted formulas without using the addition identity. So that is my humble question. How could one prove that for all the values of $x$ and $y$, the identity $\sin(x+y) = \sin(x)\cos(y) + \cos(x)\sin(y)$ holds. Any thoughts/ideas would be really appreciated.","['trigonometry', 'triangles', 'proof-explanation']"
2383990,Is there any solution except integration by parts for $\int_0^\infty x^2 e^{-x} \sin(\alpha x) dx$?,"I want to calculate the Fourier sine integral and the Fourier cosine integral of the function $f(x)=x^2e^{-x}$. So I have to calculate:
$$
\int_0^\infty x^2e^{-x}\sin(\alpha x)dx \qquad , \qquad \int_0^\infty x^2e^{-x}\cos(\alpha x)dx
$$ The integration by parts method is really complex for these two integrals! Is there any better solution to calculate them?!","['self-learning', 'integration', 'calculus', 'partial-differential-equations']"
2383991,Is it always possible to split a complex function into the sum of its real + imaginary parts? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm looking for any kind of proof or at least an intuitive explanation. I am curious because I want to know: if I have an unknown complex function that I want to manipulate, can I assume it has the structure a(x) + ib(x) . It seems to me this should definitely be possible. I'm hoping someone can provide a lucid argument that makes the answer seem stupidly obvious","['complex-analysis', 'complex-numbers']"
2384056,Show that $(AB-BA)^2=O_2$,"Let $A,B$ be two $2 \times 2 $ matrices with real elements and $a,b \in \Bbb R$ such that $a^2 \ne b^2$ and $A(A-aB)+B(B-bA)=O_2$. Show that $(AB-BA)^2=O_2.$ MY TRY: Using Hamilton-Cayley Theorem, the problem reduces to showing that $\det (AB-BA)=0$ because the trace of $AB-BA=0$. This is where I am stuck.","['matrices', 'determinant']"
2384071,What is the probability of having a cycle in an directed Erdős-Rényi graph?,"In a Erdős-Rényi graph $G_{n,1/n}$, i.e., $n$ nodes and each arc is formed independently with probability $1/n$, what is the probability that it has at least one cycle? I did refer to Erdős and Rényi's ON THE EVOLUTION OF RANDOM GRAPHS ( https://www.renyi.hu/~p_erdos/1960-10.pdf ). Although it talks about a non-directed graph, I believe the means should be the same. However, I don't really follow the proof of theorem 5b, in which they mention ""an obvious sieve"". I can show that the number of $k$ cycles follows a Poisson distribution with expectation asymptotically $1/k$. Of course, here two cycles are not independent so that the Poisson distributions do not add. And all the literature I found stops with finding the expectation of the total number of cycles, which I know is $\sum 1/k$. A simulation reveals that the probability is asymptotically 1, which I think is obvious since the dependence between cycles should be small. But I fail to find a way to give a precise proof. Can anyone give some hint?? Thanks!","['graph-theory', 'random-graphs', 'probability']"
2384088,Poisson equation as a limit of Helmholtz equation,"Assuming I can solve Helmholtz equation: $$ \nabla^2 \phi(\textbf r) - \kappa^2 \phi(\textbf r) = f(\textbf r), $$ with some given boundary conditions, where $f(\textbf r)$ is some given source. 
If I take a limit of the solution when $\kappa \to 0$ am I always guaranteed to obtain the correct solution of the corresponding Poisson equation $$ \nabla^2 \phi(\textbf r) = f(\textbf r), $$ assuming the same boundary conditions? 
Are there some contra examples where this would not be the case, e.g. $f$ is constant and we have an infinite volume or something. In other words, is there an example where for some setup we would not have $$ \phi_{P}(\textbf r) = \lim_{\kappa \to 0}  \phi_{H}(\textbf r)? $$","['functional-analysis', 'ordinary-differential-equations']"
2384113,"Find the number of rearrangements of the string 12345 in which none of the sequences 12, 23, 34, 45, and 51 occur.","So I posted a similar problem before, so please don't try to close this problem. Anyway I think I did this problem correctly, but I just want to make sure if I'm understanding what this question is asking me solve. So below I have my attempt at this problem: Let $A_{12}$ denote where 12 occurs, $A_{23}$ denote where 23 occurs, $A_{34}$ denote where 34 occurs, $A_{45}$ denote where 45 occurs, $A_{51}$ denote where 51 occurs. Also let $|U|=5!$ where there are no restrictions to the string. By gluing numbers together (i.e. 1245, 5123) and using inclusion/exclusion we get $$\begin{aligned}
|A_{12}&\cup A_{23}\cup A_{34}\cup A_{45}\cup A_{51}|\\
&= |A_{12}|+|A_{23}|+|A_{34}|+|A_{45}|+|A_{51}|\\
&\qquad-(A_{12}A_{23}+A_{12}A_{34}+A_{12}A_{45}+A_{12}A_{51}+A_{23}A_{34}\\
&\qquad\qquad+A_{23}A_{45}+A_{23}A_{51}+A_{34}A_{45}+A_{34}A_{51}+A_{45}A_{51})\\
&\qquad+(A_{12}A_{23}A_{34}+\cdots+A_{34}A_{45}A_{51})\\
&\qquad-(A_{12}A_{23}A_{34}A_{45}+\cdots+A_{23}A_{34}A_{45}A_{51})\\
&\qquad+A_{12}A_{23}A_{34}A_{45}A_{51}\\
&=\ 5(4!)-10(3!)+10(2!)-5(1!)+0\\
&=\ 75 \end{aligned}$$ Then $|U|-|A_{12}\cup A_{23}\cup A_{34}\cup A_{45}\cup A_{51}|=120-75=45$ Please help me. Thank you!","['combinations', 'combinatorics', 'inclusion-exclusion', 'discrete-mathematics']"
2384152,"Rank of a matrix with entries $1, \dots, n^2$","Given $n\geq 2$ , let $M$ be a matrix with entries $1, \dots, n^2$ , e.g., $$\begin{alignat*}{1}
A_3 = \begin{pmatrix}
      1 & 2 & 3 \\
      4 & 5 & 6 \\
      7 & 8 & 9
      \end{pmatrix} & \qquad
A_4 = \begin{pmatrix}
      1  &  2 &  3 & 4 \\
      5  &  6 &  7 & 8 \\
      9  & 10 & 11 & 12\\
      13 & 14 & 15 & 16
      \end{pmatrix}
\end{alignat*}$$ How do I prove that $\operatorname{rank}(M)=2$ ? I am supposed to use only the elementary row operations. For me, the definition of $\operatorname{rank}$ is number of non-zero rows in a row-echelon form . For a specific $n$ , I can actually perform the row operations and obtain the row-echelon form . However, I don't know how to prove it in general. Should I prove it using induction? How do I proceed with the induction step? The matrices $A_n$ and $A_{n+1}$ are completely different! By the way, is there any specific name for this type of matrices?","['matrices', 'matrix-rank', 'linear-algebra', 'terminology']"
2384178,Are elements of a ring actual functions or sections on the spectrum?,"An element of the coordinate ring of a variety $k[X]/I$ may be viewed as a function mapping points of the variety $V=V(I)$ to $k$. Similarly, an element of a ring $a\in R$ may be viewed as a function on $\operatorname{Spec} R$, which maps each $\mathfrak{p}\in\operatorname{Spec}R$ to the residue of $a$ in the fraction field $R_{\mathfrak{p}}/\mathfrak{p}R_{\mathfrak{p}}$. In the latter case, $a$ isn't actually a function in the strict sense, because its codomain varies from point to point. For example, $x\in\mathbb{R}[x]$ is takes a value in $\mathbb{R}$ at the prime ideal $(x),$ but a value in $\mathbb{C}$ at $(x^2+1)$. Is there some standard construction that corrects this defect? Do the residue fields all include into a larger field which can be viewed as the single codomain for the function $a$? Or can we assemble the residue fields into a bundle over $\operatorname{Spec}R$ of which $a$ is a section?","['schemes', 'affine-schemes', 'algebraic-geometry']"
2384247,First order ODE - Solve $dy/dx=\sin(x+2y)+\cos(x+2y)$,"I am taking an online course on IIT's MOOC site https://onlinecourses.nptel.ac.in/noc17_ma11/ on Ordinary Differential equations. One of the questions in the assignment is the following : Solve the differential equation $$\frac{dy}{dx}=\sin(x+2y)+\cos(x+2y)$$ I am having some trouble attempting this question. Here are my quick thoughts: This is not in the separable form. Substituting $y=ux$ or $x=vy$ does not yield a homogenous function. The coefficient of $dx$ is not linear. This is not an exact differential equation. $\partial{P}/\partial(y)=2\cos(x+2y)-2\sin(x+2y)$ and $\partial{Q}/\partial(x)=0$ Obviously, this must have an integrating factor then. Are my initial thoughts correct? Is that the correct way to proceed? I tried googling, but didn't find much luck. Any hints in the right direction would be great.",['ordinary-differential-equations']
2384298,Find the limit if it exists of $S_{n+1} = \frac{1}{2}(S_n +\frac{A}{S_n})$ [duplicate],"This question already has answers here : Proof of Convergence: Babylonian Method $x_{n+1}=\frac{1}{2}(x_n + \frac{a}{x_n})$ (9 answers) Closed 3 years ago . Suppose that $S_0$ and A are positive numbers, let $$S_{n+1} = \frac{1}{2}\left(S_n +\frac{A}{S_n}\right)$$ with $n \geq 0 $. (a)Show that $S_{n+1} \geq \sqrt{A} $ if $n \geq 0$ (b)Show that $S_{n+1} \leq S_n $ , if $n \geq 1$ (c) Show that $s= \lim\limits_{n \rightarrow \infty} S_n$ exists (d) find s (a) Show that $S_{n+1} \geq \sqrt{A} $ if $n \geq 0$ Given $$P_n:  S_{n+1} = \frac{1}{2}\left(S_n +\frac{A}{S_n}\right) \geq \sqrt{A}$$ $$P_0: S_{1} = \frac{1}{2}\left(S_0 +\frac{A}{S_0}\right) \geq \sqrt{A}  $$ We assume that $P_n$ is true $$P_{n+1}: S_{n+2}= \frac{1}{2}\left(S_{n+1} +\frac{A}{S_{n+1}}\right)$$
by assumption
$$S_{n+2}= \frac{1}{2}\left(S_{n+1}\left(1 +\frac{A}{(S_{n+1})^2}\right)\right) \geq \frac{1}{2}\left(\sqrt{A}\left(1 +\frac{A}{(\sqrt{A})^2}\right)\right)$$
$$ S_{n+2}= \frac{1}{2}\left(S_{n+1} +\frac{A}{S_{n+1}}\right) \geq \sqrt{A}  $$ It follows that $S_{n+1} \geq \sqrt{A} $ (b) Show that $S_{n+1} \leq S_n $ , if $n \geq 1$ $$S_{n+1} \leq S_n$$
$$\frac{1}{2}\left(S_n +\frac{A}{S_n}\right) \leq S_n $$
Dividing by $S_n$
$$\frac{1}{2}\left(1 +\frac{A}{S_n^2}\right) \leq 1 $$
$$\frac{A}{2S_n^2} \leq \frac{1}{2}$$
$$A \leq S_n^2$$
$$S_n \geq \sqrt{A}$$
As  $S_{n+1} \leq S_n$ yields a true statement, it follows $S_{n+1} \leq S_n$ is true. (c) Show that $s= \lim\limits_{n \rightarrow \infty} S_n$ exists Since $S_{n+1} \leq S_n$, the sequence is non-increasing, using the non-increasing theorem stating that if $\{S_n\}$ is non-increasing then $$\lim\limits_{n \rightarrow
> \infty} S_n = \inf\{S_n\} $$ (d) find s Is the argumentation in (a) and (b) appropriate? Also, I have to admit I m getting less confident in my argumentation (c) and (d). How to proceed in (c) and (d)? 
Much appreciated for your input or help.","['real-analysis', 'sequences-and-series', 'proof-verification']"
2384342,Does a function change when you multiply both the denominator and numerator by the same function?,"For example: $ 1) \, f(x): 3x+3$ $2) \, f(x)= \frac{(3x^2-3)}{(x-1)}$ If you simplify the second function it becomes the first, but isn't the function, in its present form, undefined for $x = 1$?",['functions']
2384359,counting all possible realizations of k subsets of a set $U$ such that no one is a subset of another and the union of these $k$ subsets is $U$,"Consider a set $U=\{1,2,...,N\}$, and $k$ non-empty subsets $U_i\subset U$, such that: i) none of these k subsets is a subset of another; ii) $\bigcup_{i=1}^k U_i=U$. Given any $k$, what is the total number of possible realizations of such $k$ subsets? When $k = 1$ or $2$, it appears easy to calculate the total number of possible realizations. How about $k\geq 3$? Does anyone have any idea? Note that the $k$ is upper bounded by ($N$ choose $floor(N/2)$), as given by this relevant post: Find maximal number of subsets of the set $U$ such that no one is a subset of another Thanks.","['combinatorics', 'elementary-set-theory']"
2384386,Diophantine equation considering primes,"I want to find the prime solutions for the equation $2^p=q^q+q+2$. So far I came up with solutions $(p,q)=(3,2),(5,3)$. I don't think there are any other solutions, but I'm struggling to prove this fact.",['number-theory']
2384391,Prove that $\lim\limits_{n\to\infty} \frac{S_n - s}{S_n+s} = 0$ implies $\lim\limits_{n \rightarrow \infty} S_n = s$,"Prove that if 
  $$ \lim\limits_{n \rightarrow \infty} \frac{S_n-s}{S_n+s} = 0$$ then $$\lim\limits_{n \rightarrow \infty} S_n = s$$ Hint: Define $t_n = \frac{S_n -s}{S_n + s}$ and solve for $S_n$ By the hint:
$$t_n = \frac{S_n -s}{S_n + s}$$
$$(S_n + s)t_n = S_n -s$$
$$S_n(t_n-1)= - s -st_n$$
$$S_n= -s \cdot \frac{1+t_n}{t_n-1}$$ $$\lim\limits_{n \rightarrow \infty} S_n= -s \cdot \frac{1+\lim\limits_{n \rightarrow \infty} t_n}{\lim\limits_{n \rightarrow \infty} t_n-1}$$ As $ \lim\limits_{n \rightarrow \infty} \frac{S_n-s}{S_n+s} = \lim\limits_{n \rightarrow \infty} t_n = 0$, it follows: $$\lim\limits_{n \rightarrow \infty} S_n= s$$ Is my argumentation correct/appropriate?Anything needs to be added? Much appreciated for your input.","['real-analysis', 'sequences-and-series', 'proof-verification', 'limits']"
2384405,Time reversal in Robertson's chemical reaction,"I am studying the behavior of the Robertson chemical reaction, $$\begin{array}{rl} \dot{x} &= -0.04 x + 10^4 y z\\ \dot{y} &= 0.04 x - 10^4 y z - 3 \times 10^7 y^2\\ \dot{z} &= 3 \times 10^7 y^2\end{array}$$ (source: Wikipedia on stiff equations ). I have noticed that numerical schemes can integrate this equation forwards in time but not backwards; that is, for a given initial condition $(x_0, y_0, z_0)$, integrating forward to $t = t_1$ and then reversing the integration back to $t = t_0$ yields a solution not equal to the initial condition. I am wondering about the mathematical reason for this, and if there is any remedy. Is this a feature of all stiff equations? Have I missed something obvious? Thanks in advance. More detail: I chose the initial condition $(3, 1, 2)$ as an example, but I have observed this effect with other initial conditions as well. Let $t_0 = 0$ and $t_1 = 1$. For the first integration: $t = 1$, $(x, y, z) = (3.00609, 4.00023 \times 10^{-6}, 2.99391)$ And for the reverse integration: $t = 0$, $(x, y, z) = ( 3.00657, 4.00151 \times 10^{-6}, 2.99343 )$ I use the BDF integration method and have tried multiple implementations; all of the results are consistent with each other.","['applications', 'numerical-methods', 'ordinary-differential-equations', 'chemistry']"
2384420,How to prove this $A$ has full rank and the number of positive eigenvalues of $A$ is one?,"Suppose $A$ is a $3\times 3$ symmetric matrix such that $$\begin{bmatrix}x & y &1\end{bmatrix} A \begin{bmatrix}x \\y & \\1 \end{bmatrix}=xy-1$$ How to prove $A$ has full rank and the number of positive eigenvalues of $A$ is one? My try: $$\begin{bmatrix}x & y &1\end{bmatrix} \begin{bmatrix}a & b &c \\b & d & e \\c & e & f \end{bmatrix} \begin{bmatrix}x \\y  \\1 \end{bmatrix}=xy-1$$ $$\Rightarrow \begin{bmatrix}x & y &1\end{bmatrix} \begin{bmatrix}ax+by+c \\bx+dy+e  \\cx+ey+f \end{bmatrix}=xy-1$$ $$\Rightarrow ax^2+2bxy+2cx+dy^2+2ey+f=xy-1 $$ $$\Rightarrow a=c=d=e=0\; \text{and} \;b=1/2, f=-1$$ So the matrix becomes $$\begin{bmatrix}0 & 1/2 &0 \\1/2 & 0 & 0 \\0 & 0 & -1 \end{bmatrix}$$ which has only one positive eigenvalue, namely, $\frac 12$ . Also this matrix is invertible and, hence, full rank. Is this way correct or anything I'm doing wrong? What is the general idea?","['eigenvalues-eigenvectors', 'matrices', 'symmetric-matrices', 'quadratic-forms', 'linear-algebra']"
2384422,How to find the general solution for this ODE?,"I'm really stuck on how to go about solving the following first order ODE; I've got little idea on how to approach it, and I'd really appreciate if someone could give me some hints and/or working for a solution so I can have a reference point on how to approach these sorts of problems. The following is one of many ODE's I've gotten off a problem set I found in a textbook at a library: $$y' = xe^{-\sin(x)} - y\cos(x)$$ Can anyone help?","['stability-in-odes', 'integration', 'ordinary-differential-equations', 'calculus']"
2384423,Calculating median (second quartile) using formula for quartiles in an interval,"I have the following formula in my lecture notes for calculating the $j^{th}$ quartile in an interval: $$Q_j=L_l+I\frac{N \frac{j}{4}-F_l}{f_l}, j=1,2,3$$ Where $L_l$ is the left side of the interval in which the quartile is. The interval in which the quartile is, is defined as the interval before the sum of the frequencies is bellow $N\frac{j}{4}$. $F_l$ is the sum of the frequencies in the intervals before $L_l$ $f_l$ is the frequency in the interval of the median I is the length of the interval which contains the median My question is: If this formula is correct, how do I calculate the second quartile which is the median, when the formula is actually using information about the median ($f_l$ is the frequency in the interval of the median)? Also, what is the intuition behind this formula (if it's correct of course)?","['descriptive-statistics', 'statistics']"
2384464,Does the series $\sum\limits_{n=2}^\infty(-1)^n\ln\left(1+\frac{\sin n}{\ln n}\right)$ converge?,"I want to know the nature of the following series : $$\sum_{n=2}^{\infty}(-1)^n\ln\left(1+\frac{\sin(n)}{\ln(n)}\right)$$ So, I make an asymptotic expansion to $$(-1)^n\ln\left(1+\frac{\sin(n)}{\ln(n)}\right)=\frac{(-1)^n\sin(n)}{\ln(n)}+\frac{(-1)^{n+1}\sin^2(n)}{\ln^2(n)}+O\left(\frac{1}{\ln^2(n)}\right)$$ but $\sum_{n=2}^{\infty}O\left(\frac{1}{\ln^2(n)}\right)$ doesn't converge absolutely, and I can't group it with $\frac{(-1)^{n+1}\sin^2(n)}{\ln^2(n)}$ to search an equivalent because $\frac{(-1)^{n+1}\sin^2(n)}{\ln^2(n)}$ doesn't conserve the same sign. what should I do to know its nature?","['sequences-and-series', 'convergence-divergence']"
