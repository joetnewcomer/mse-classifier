question_id,title,body,tags
1067936,Number of ways to choose 6 books out of 20 books such that no 2 are adjacent books,"I was trying to do the following question: Describe a bijection between ways of choosing 6 books out of 20 books
  so that no two adjacent books are selected and a 15-bit sequence with
  exactly 6 ones. I attached a useful picture from the solutions: The solutions actually nearly make sense to me, except one detail. It seems to me that it has a small mistake (or a maybe I have a misunderstanding) because not all the ones can actually be adjacent to each other. For example, if it happens that the last 1 and the first 1 are actually together then it could mean that we are selection first a book and then a pair (book, empty), but what would correspond to selecting two books that are adjacent. For me intuitively it would make more sense if we would have described the sequence they suggested by: 100110001001002 where the digit 2 corresponds to the special case indicating that its not a pair, (book, no book) but in fact it corresponds to the singleton selection (book). However, with that set up it makes it hard for me to count things cuz the 2 cannot be next 1's.... am i wrong or do the solutions have a small typo? Also, why is it not undercounting? This is why I believe it is undercounting: It seems to be undercounting (I think), cuz I could have choose a single book at the beginning and the reverse the pairs thereafter. i.e. (book),(no book, book), ..., (no book, book). How is the given solution not missing that sequence?","['discrete-mathematics', 'combinatorics']"
1067951,Positive component of a submartingale is a submartingale,"I am trying to prove the Doob's Upcrossing Lemma and the first step requires to prove that:
If $X$ is a submartingale, then $(X-a)_+$ is a submartingale.  I found it intuitive but i failed to prove.  Here is my attempt: $\mathbb{E}[(X_{n+1}-a)_+|\mathscr{F_n}]\\=\mathbb{E}[(X_{n+1}-a)|\mathscr{F_n}]+\mathbb{E}[(X_{n+1}-a)_-|\mathscr{F_n}]\\>(X_{n}-a)+\mathbb{E}[(X_{n+1}-a)_-|\mathscr{F_n}]\\=(X_{n}-a)_+-(X_{n}-a)_-+\mathbb{E}[(X_{n+1}-a)_-|\mathscr{F_n}]\\=(X_{n}-a)_++(\mathbb{E}[(X_{n+1}-a)_-|\mathscr{F_n}]-(X_{n}-a)_-)$ If $(X_{n}-a)_-$ is a martingale or submartingale this is fine.  What if supermartingale?","['probability-theory', 'martingales', 'random-variables']"
1067961,Problem 3.14(e) in Baby Rudin,"If $\{s_n\}$ be a sequence of complex numbers, define its arithmetic mean $\sigma_n$ by 
$$\sigma_n \colon= \frac{s_0 + s_1 \cdots + s_n}{n+1} \, \, (n = 0, 1, 2, \ldots). $$ Put $a_n = s_n - s_{n-1}$ for $n \geq 1$. Assume $M < +\infty$, $\vert n a_n \vert \leq M$ for all $n$, and $\lim \sigma_n = \sigma$. Prove that $\lim s_n = \sigma$. I haven't been able to fill in the proofs in the steps of the outline suggested by Rudin. Can anyone please help me out with coming up with a solution to this problem?","['sequences-and-series', 'convergence-divergence', 'real-analysis', 'analysis', 'limits']"
1067977,Relationship between functional analysis and differential geometry,"I am taking courses on functional analysis (through Coursera.com) and differential geometry (textbook author : O'neil) on my university. I made the following table on my own. Are the similar concepts linear form and 1-form? Also I want to know more relationships deeply. Or any recommendation (book or whatever) (Modified and added)
I feel that the weak topology is generated by pulling back in dual space so that we get small open sets.
I wonder whether it is the same story as pulling forms back.","['functional-analysis', 'differential-geometry']"
1068010,Why Is $y^{-1}$ = $\frac{1}{y^1}$?,"Basically, I'm asking 'Is there any place where I can access a compendium of formal mathematical proofs'? I need to know what processes mathematicians went through to declare $(-1)(-1)=1$ and so on. I believe this will actually help me understand topics a lot better. Also, why is $y^{-1}$ = $\dfrac{1}{y^1}$?","['fractions', 'algebra-precalculus']"
1068015,The Computation of a special kind of Laurent Series,"Let $a\in\mathbb{C}$ and $k\in\mathbb{N}$, we wish to compute the Laurent Series for the function
$$
f(z)=\frac{1}{(z-a)^k}
$$
about $z=0$ (NOT $z=a$). So there should be two Laurent Series which are valid for $|z|<|a|$ and $|z|>|a|$. Clearly if $a=0$ then this is already a Laurent Series. But what about $a\ne 0$? I can do 
$$
\frac{1}{z-a},
$$
but not quite sure how to do $(z-a)^{-k}$. Could somebody give me some clue about how to do this or give me some general methods to do this kind of question? First for the case $|z|<|a|$, $f(z)$ is holomorphic, then it has a Taylor Series
$$
f(z)=\frac{1}{(z-a)^k}=\sum^{\infty}_{n=0}a_nz^n.
$$
Then
$$
a_n=\frac{f^{(n)}(0)}{n!}=\frac{(-1)^n(k+n-1)!}{n!(k-1)!(0-a)^{k+n}}=\frac{(-1)^k}{a^{k+n}}\binom{n+k-1}{k-1}.
$$
In particular, if $a=1$, then for $|z|<1$
$$
\frac{1}{(z-1)^k}=(-1)^k\sum^{\infty}_{n=0}\binom{n+k-1}{k-1}z^n.
$$ Now if $|z|>|a|$, then $\left|\frac{1}{z}\right|<|a|$, we write
$$
f(z)=\frac{1}{(z-a)^k}=\frac{1}{(-1)^k(a-z)^k}=\frac{1}{(-1)^kz^k(\frac{a}{z}-1)^k}.
$$
From above, we know that $\left|\frac{a}{z}\right|<1$, then
$$
\frac{1}{(\frac{a}{z}-1)^k}=(-1)^k\sum^{\infty}_{n=0}\binom{n+k-1}{k-1}\left(\frac{a}{z}\right)^n.
$$
Then for $|z|>|a|$, we have
$$
f(z)=\sum^{\infty}_{n=0}\binom{n+k-1}{k-1}\frac{a^n}{z^{n+k}}=\sum^{\infty}_{n=k}\binom{n-1}{k-1}a^{n-k}z^{-n}.
$$","['laurent-series', 'complex-analysis']"
1068027,Finding the Area of a Torus-like surface,"I'm trying to find out the Area of the following surface: Let $C$ be the curve associated  to a regular, simple path $\theta:[0,l]\rightarrow  \Bbb  R^2  $; also assume that $((x'(s))^2+((y'(s))^2=b^2$ and let $S$ be the surface generated by the circles of radius $b$, orthogonal to, and centered in points of the curve $\rho(s)=(\theta(s),0) $. With help from this source . I concluded that a convenient parametrization for $S$ is given by: $$
H(s, t) = ( x(s), y(s), 0) + \sin(t) (0, 0, b) + \cos(t) (b\ y'(s), -b\ x'(s), 0).
$$ I intended to use the fact that the area of $S$ is given by the surface integral: $$
\int_S ||T_s \times T_t|| \ dv
$$ However,by this approach, the terms of $||T_s \times T_t||$ become really awful. Am I doing something wrong here? What would you recommend? I found this approach , wich uses the Divergence Theorem. However in this case I´m not sure I can use that since I don´t have a vector field.","['multivariable-calculus', 'parametric', 'integration', 'real-analysis']"
1068031,Riemann Integrability in $\Bbb R^2$,"Define the General Subdivision $S$ of a rectangle $R$ in $\Bbb R^2$ as a collection $E_1,...,E_k$ of Jordan regions such that none of them has interior points in common, and: $$R \subset \bigcup_{i=1}^k E_i$$ The norm of $S$ is defined as: $$d(S)=\max \left[\operatorname{diam}(E_i:1<i<k)\right]$$ Where $diam$ denotes denotes the diameter of each rectangle. Also, if $f$ is a continuous in $R$ and for each $i$, $(x_i, y_i)$ is in $E_i$ then the sum $$S(f,S,(x_i,y_i))= \sum_{i=i}^k f(x_i,y_i)  \operatorname{vol}(E_i)
$$ is named the Riemann sum of $f$ in S . I need to show that for every $\epsilon >0$ there is a $\delta >0$ such that if $d(S)<\delta$ then: $$\left| \iint_R f \ dA -S(f,S,(x_i,y_i)) \right| < \epsilon $$ The definition of integral I've been studying is given by the superior and inferior sums: $$\iint_R f \ dA= \sup \{L(f,P) \mid \text {P is a partition of } \mathbb{R}\}= \inf \{ U(f,P) \mid \text {P is a partition of } \mathbb{R} \}$$ I tried using the Cauchy Criterion but i couldn't prove what I need. Any help will be great, thanks in advance.","['riemann-sum', 'multivariable-calculus', 'integration', 'real-analysis']"
1068043,Measure Spaces: Uniform & Integral Convergence,"Given a measure space $\Omega$. Consider a sequence of measurable functions $f_n$ Suppose it converges pointwise: $f_n\to f$ Can one find increasing subsets with uniform convergence:
$$A_N\uparrow\Omega:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0$$
Or at least with convergence in integral norm:
$$A_N\uparrow\Omega:\quad\int_{A_N}|f-f_n|\mathrm{d}\mu\stackrel{n\to\infty}{\to}0$$ (Not passing over to subsequences!) Some first basic examples allow that:
$$f_n:=\chi_{(n,n+1]}:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0\quad(A_N:=(0,N])$$
$$g_n:=x^n:\quad\|g-g_n\|_{B_N}\stackrel{n\to\infty}{\to}0\quad(B_N:=(0,1-\frac{1}{N}])$$
$$h_n:=x^{1/n}:\quad\|h-h_n\|_{C_N}\stackrel{n\to\infty}{\to}0\quad(C_N:=(\frac{1}{N},1])$$ So I wonder: Are there are examples where both can't hold?","['convergence-divergence', 'examples-counterexamples', 'integration', 'measure-theory', 'lebesgue-integral']"
1068044,"Proving that for all complex $z$, $\lim_{x\to0}\frac{1-\cos^{z}x}{x^2}=\frac{z}{2}.$","What do I need to study beforehand in order to prove it (not necessarily in only one way)? I found this sperimentally, at the moment we're beginning derivatives at school. By induction, I succeeded in proving $$\lim_{x\to0}\frac{1-\cos^{n}x}{x^2}=\frac{n}{2}.\tag{P(n)}$$ Basis : $P(0)$: $\displaystyle\lim_{x\to0}\frac{1-\cos^{0}x}{x^2}=0$ is true. Inductive step : Assume $P(k)$ holds. This indeed implies $P(k+1)$ holds too: $$\lim_{x\to0}\frac{1-\cos^{k+1}x}{x^2}=\lim_{x\to0}\frac{\left(1-\cos^kx\right)\cos x-\cos x+1}{x^2}=\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \lim_{x\to0}\frac{\left(1-\cos^kx\right)\cos x}{x^2}+\lim_{x\to0}\frac{1-\cos x}{x^2}=\frac{k}{2}+\frac{1}{2}=\frac{k+1}{2}.\ \ \ \ \ \ \ \ \ \ \ \ \ \blacksquare$$ I want to show it is true for all complex $z$ on my own.","['complex-numbers', 'complex-analysis', 'limits']"
1068047,Best book for self-study on the foundations of probability,"After some selection, I have three ""candidates"" books to purchase in order to study by myself the foundations of the theory of probability, at a level that I can define as ""high undergraduate""/""low graduate"". These are my candidates: 1) Probability. A.N.Shiryaev. GTM Springer-Verlag. 2) Probability and Stochastics. Erhan Çinlar. GTM Springer-Verlag. 3) Probability Theory. A. Borovkov. UT Springer-Verlag. I have very good references from all of them.
Which one do you recommend me ? Thank you for your answers.","['book-recommendation', 'probability']"
1068049,Converting a polar equation to a rectangular one,$$r=\frac { 4 }{ 1+2\sin\theta  } $$ Steps I took: $$(1+2\sin\theta )r=\frac { 4 }{ 1+2\sin\theta  } (1+2\sin\theta )$$ $$r+2r\sin\theta =4$$ $$r+2y=4$$ $$(r+2y)^2=16$$ $$(r+2y)(r+2y)=r^2+4yr+4y^2$$ $$r^2+4yr+4y^2-16=0$$ My outcome doesn't seem to match the correct answer. Where did I go wrong?,['algebra-precalculus']
1068063,$n_p(GL_2(\mathbb{F}_p))=p+1$,"I'm interested in the following problem from Dummit & Foote's Abstract Algebra text (Exercise 40 of Section 4.5): Prove that the number of Sylow p-subgroups of $GL_2(\mathbb{F}_p)$ is $p+1$. [Exhibit two distinct Sylow p-subgroups.] I've managed to solve the exercise in the following way: Exercise 39 tells us that $UT_2(\mathbb{F_p})$, the subgroup of upper triangular matrices with ones on the diagonal is a p-Sylow subgroup. It can be verified that the normalizer $N_{GL_2(\mathbb{F}_p)}(UT_2(\mathbb{F}_p)$ is a supergroup of the larger subgroup of upper triangular matrices, where the diagonal entries are allowed to be any nonzero element of the field $\mathbb{F}_p$ (this subgroup has size $p(p-1)^2$). Since $$n_p=|GL_2(\mathbb{F}_p):N_{GL_2(\mathbb{F}_p)}(UT_2(\mathbb{F}_p))|,$$ the above gives $$n_p=\frac{p+1}{m}$$ for some integer $m$. Part (iii) of Sylow's Theorem then forces $n_p=p+1$. (The case $n_p=1$ is impossible, as the subgroup of lower triangular matrices is a Sylow p-subgroup as well.) I think my solution is correct (isn't it?), however, I wonder, do simpler solutions exist? Thank you!","['sylow-theory', 'group-theory', 'abstract-algebra']"
1068084,A little more on $\sqrt[3]{\cos\bigl(\tfrac{2\pi}7\bigr)}+\sqrt[3]{\cos\bigl(\tfrac{4\pi}7\bigr)}+\sqrt[3]{\cos\bigl(\tfrac{8\pi}7\bigr)}$,"Using a special case of an identity by Ramanujan , we find that given the roots $x_i$ of $$x^3 + x^2 - (3 n^2 + n)x + n^3=0\tag1$$ which, since its discriminant is negative, always has three real roots, then, $$F_p = x_1^{1/3}+x_2^{1/3}+x_3^{1/3} = \sqrt[3]{-(6n+1)+3\sqrt[3]{np}}\tag2$$ where $p = 9n^2+3n+1$. Question: Is it true that if $p$ is prime, then a root of $(1)$ is alway s a sum of the $p$th root of unity of form, $$x = \sum_{m=1}^{(p-1)/3}\,\exp\Bigl(\frac{2\pi\, i\, k^m}{p}\Bigr)\tag3$$ for some integer $k$? We have, $$\begin{array}{|c|c|c|}
n&p&k\\
-1&7&6\\
1&13&5\\
-2&31&15\\
2&43&2\\
3&73&7\\
\end{array}$$ and so on. ( P.S. If indeed true, this implies that $x$ is also a sum of cosines and would generalize, $$F_7=\sqrt[3]{\cos\bigl(\tfrac{2\pi}7\bigr)}+\sqrt[3]{\cos\bigl(\tfrac{4\pi}7\bigr)}+\sqrt[3]{\cos\bigl(\tfrac{8\pi}7\bigr)}=-\sqrt[3]{\tfrac{-5+3\sqrt[3]7}2}$$ $$F_{13} = \sqrt[3]{\cos\bigl(\tfrac{2\pi}{13}\bigr)+\cos\bigl(\tfrac{10\pi}{13}\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{4\pi}{13}\bigr)+\cos\bigl(\tfrac{6\pi}{13}\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{8\pi}{13}\bigr)+\cos\bigl(\tfrac{12\pi}{13}\bigr)}=\\
\sqrt[3]{\tfrac{-7+3\sqrt[3]{13}}2}$$ which are just the cases $n=-1,\,1$, with the second one discussed by GrigoryM in the related question in the link above.)","['prime-numbers', 'trigonometry', 'radicals', 'roots-of-unity']"
1068095,Ways of getting three of a kind in a 52 card deck,"This question has probably been asked before, but just to be clear here, I am NOT asking for the answer, I know the answer.  What i want to know is why my solution is not equivalent to the actual solution. Three of a kind in a deck means you draw 3 cards of the same rank, and 2 other cards each of different ranks. So. The solution in my book is the following: (13 C 1)(4 C 3) * (12 C 2)(4 C 1)(4 C 1) The logic is the following: 1) Choose 1 out of the 13 ranks, then for the 4 cards in the chosen rank, pick 3. 2) Choose a combination of 2 ranks from the remaining 12, then for the 4 cards in each rank, choose 1. Total combinations: 54912 My solution is the following: ((13 C 1)(4 C 3)) * ((12 C 1)(4 C 1)) * ((11 C 1)(4 C 1)) 1) My logic for the 3 of a kind is the same as the solution. 2) Choose 1 of the remaining 12 ranks, and 1 card from the 4 cards in the rank. 3) Choose 1 of the remaining 11 ranks, and 1 card from the 4 cards in the rank. Total combinations: 109824 My solution says that the combinations are exactly double of the book's solution.  I'm just very confused as to why this is. If anyone could explain this to me I would be very appreciative, thank you.","['discrete-mathematics', 'poker', 'combinatorics']"
1068124,Why sometimes we get only one root of quadratic equations?,What is logic behind getting (sometimes) only one root of a quadratic equation which satisfies the equation?,"['quadratics', 'algebra-precalculus']"
1068129,What are some practical applications of measure theory apart from providing theoretically rigourous foundations?,"It seems that measure theory has a very good theoretical purpose, in that it provides a rigorous framework to define a lot of what we do in analysis. However, I have a hard time thinking of a situation where you need to invoke a purely measure-theoretic concept that is not serving as a ""shoring up"" lemma/theorem to the ""main idea"", which will often be some integral or limit. Are there instances where the measure theoretic idea is the crux of a result that isn't related to probability theory? At the broader level, where are non-probabilistic measureable spaces even used?",['measure-theory']
1068150,How to find $\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx$,Evaluate $$\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx$$ where $a$ is a real parameter $a\geq1$. I can easily find the definite integral for $a=1$. It is $\sin(1)$. In wolframalpha.com when I put $\displaystyle\int_{-1}^1 \frac{\cos x}{a^x+1}\text{d}x$ it shows me a very complicated formula with complex numbers and functions I didn't study but it says that definite integral is $= 0.841471\ldots$. How can I find that integral?,"['definite-integrals', 'calculus', 'integration']"
1068183,How to solve $y^2=3x^4+3x^2+1$ for integers.,"If $x,y \in \mathbb Z$ , then find all the solutions of $$y^2=3x^4+3x^2+1$$ I was asked this question by my friend who said that he encountered this while solving another problem. I have tried several things but am unable to solve this question. Moreover, this has to be done using elementary methods only. So far, I have tried to factorize and use Pell's equation. At the end, I'm getting $$2y_{n} + (2x^2_{n}+1)\sqrt{3}=(2+\sqrt{3})^{n}$$ where $n \in \mathbb Z^{+}$ But I'm not able to figure out how to show a contradiction from here. Can anyone please help me out? Thanks.","['polynomials', 'diophantine-equations', 'number-theory']"
1068239,Calculate the distance between intersection points of tangents to a parabola,"Question Tangent lines $T_1$ and $T_2$ are drawn at two points $P_1$ and $P_2$ on the parabola $y=x^2$ and they intersect at a point $P$. Another tangent line $T$ is drawn at a point between $P_1$ and $P_2$; it intersects $T_1$ at $Q_1$ and $T_2$ at $Q_2$. Show that
$$\frac{|PQ_1|}{|PP_1|} + \frac{|PQ_2|}{|PP_2|} = 1$$ My attempt at the question I include a possible scenario of the graph for convenience'(I hope) sake: The outer two tangents are tangents $T_1$ and $T_2$, and the inner tangent is tangent $T$. Since points $P_1$ and $P_2$ are points on the parabola, I can give them coordinates as follows, $$\tag 1 P_1(P_{1x}, P^2_{1x})$$ and  $$\tag 2 P_2(P_{2x}, P^2_{2x})$$ Using $y\prime = 2x$, I calculate the equations for the tangents $T_1$ and $T_2$ respectively, they are, $$T_1 = y = 2P_{1x}(x - P_{1x}) + P^2_{1x}$$ and $$T_2 = y = 2P_{2x}(x - P_{2x}) + P^2_{2x}$$ By setting $T_1 = T_2$ and then solving for $x$ I show that the two tangents intersect at a point $x = \frac{P_{1x} + P_{2x}}{2}$, which in words is the two tangents to the parabola is halfway between points $P_1$ and $P_2$. Then substituting $x = \frac{P_{1x} + P_{2x}}{2}$ into any of the tangent line equations I get the $y$ coordinate of the tangent lines' intersection, which is $y = P_{1x}\cdot P_{2x}$ Now I have the coordinates for point $P$, that is $$\tag 3 P\Big(\frac{P_{1x} + P_{2x}}{2}, P_{1x}\cdot P_{2x}\Big)$$ To get coordinates for points $Q_1$ and $Q_2$ I will substitute $Q_{1x}$ in to the equation of tangent $T_1$ and substitute $Q_{2x}$ in to the equation of tangent $T_2$. That yields the following for coordinates: $$\tag 4 Q_1(Q_{1x}, \,\,2P_{1x}Q_{1x} - P_{1x}^2)$$
$$\tag 5 Q_2(Q_{2x}, \,\,2P_{2x}Q_{2x} - P_{2x}^2)$$ Since I have all the points necessary to calculate $\frac{|PQ_1|}{|PP_1|} + \frac{|PQ_2|}{|PP_2|}$, I feel inclined to apply the distance formula. Doing so yielded the following: $$\tag 6 |PQ_1| = \frac{\sqrt{(4P_{1x}^2 + 1)(P_{1x} + P_{2x} - 2Q_{1x})^2}}{2}$$ $$\tag 7 |PP_1| = \frac{\sqrt{(4P_{1x}^2 + 1)(P_{1x} - P_{2x})^2}}{2}$$ $$\tag 8 |PQ_2| = \frac{\sqrt{(4P_{2x}^2 + 1)(P_{1x} + P_{2x} - 2Q_{2x})^2}}{2}$$ $$\tag 9 |PP_2| = \frac{\sqrt{(4P_{1x}^2 + 1)(P_{1x} - P_{2x})^2}}{2}$$ Now I calculate $\frac{|PQ_1|}{|PP_1|} + \frac{|PQ_2|}{|PP_2|}$ using the above: 
$$\frac{|PQ_1|}{|PP_1|} + \frac{|PQ_2|}{|PP_2|} = \frac{\frac{\sqrt{(4P_{1x}^2 + 1)(P_{1x} + P_{2x} - 2Q_{1x})^2}}{2}}{\frac{\sqrt{(4P_{1x}^2 + 1)(P_{1x} - P_{2x})^2}}{2}} + \frac{\frac{\sqrt{(4P_{2x}^2 + 1)(P_{1x} + P_{2x} - 2Q_{2x})^2}}{2}}{\frac{\sqrt{(4P_{2x}^2 + 1)(P_{1x} - P_{2x})^2}}{2}}$$ $$\tag {10} =\frac{\sqrt{(P_{1x} + P_{2x} - 2Q_{1x})^2} + \sqrt{(P_{1x} + P_{2x} - 2Q_{2x})^2}}{\sqrt{(P_{1x} - P_{2x})^2}}$$ I can't seem to find a way to show that $(10)$ is equal to $1$. I have, however tested a few instances and it held up, for what it's worth. But for now, I'm at a loss as to how to proceed. Any hints, suggestions, or alternative approaches?","['analytic-geometry', 'calculus', 'derivatives']"
1068254,"Let $z_1$, $z_2$ and $z_3$ be complex vertices of an equilateral triangle. Show $z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1$.","Prompt: Let $z_1$, $z_2$ and $z_3$ represent vertices of an equilateral triangle in the complex plane. Show $z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1$. Question: I hope the following question isn't too soft. I know a solution to the above question by taking the sides of the triangle and equating them by rotations in the complex plane of $e^{i\pi/3}$. What, if anything, is the significance of the result other than showing some clever algebraic manipulation? Does it tell us something unique about equilateral triangles defined by vertices in the complex plane? Is there any intuition to be gained here?","['intuition', 'complex-analysis']"
1068291,"recursive sub-sequences of sequence , one is increasing and one is decreasing to same limit -> the sequence converge?","Let $b_1=\:0$, $b_{n+1}\:=\:\frac{1}{1+b_n}$. I need to show that $\left(b_n\right)_{n\:=1}^{\infty }$ converge. I thought about dived $b_n$ to 2 sub_sequence : $b_{2n}$, $b_{2n+1}$. (i thought about it  because intuition: it is very clear if you start to put values to n, you see that $b_{2n-1}$ increasing and $b_{2n}\:$ decreasing) So, its true to say that ? : $b_{2n}\:=\:\begin{pmatrix}1 & n=1 \\b_{2\left(n+1\right)}\:=\:\frac{1}{1+b_{2n}} & \forall n\end{pmatrix}$, $b_{2n-1}\:=\:\begin{pmatrix}0 & n=1 \\b_{2\left(n+1\right)-1}\:=\:\frac{1}{1+b_{2n-1}} & \forall n\end{pmatrix}$ If its correct, how can i prove that these two are bounded? tnx for any help!","['sequences-and-series', 'calculus', 'limits']"
1068300,Partial Derivatives versus Proper Derivatives,"I'm having some difficulty understanding exactly what a partial derivative is. I had been content with the definition $$\frac{\partial F}{\partial x_i } = \lim_{\Delta x \rightarrow 0} \frac{F(x_0, x_2 ... x_{i-1}, x_i + \Delta x, x_{i+1} ... x_n ) - F(x_0 ... x_n )}{\Delta x} $$ However now I am beginning to realize that there is a bit more going on here than originally intended. Consider in the definition of the Euler Lagrange Equations where given an operator $$L (x,y(x), y'(x)) $$ We are seeking to find the optimal y for this operator. We are required to solve $$\frac{\partial L}{\partial y} -\frac{d}{dx}[\frac{\partial L}{\partial y'}] = 0 $$ To find such L. But here's my issue. Where we treat all other variables constant except what we are deriving w.r.t, How can you treat y constant and derive w.r.t. y' Because if either varies, then so does its complement. For example consider expression $L = y^2$. If y = $e^x$ then $$ \frac{\partial L}{\partial y'} = \frac{\partial e^{2x}}{\partial e^x} = 2e^x = 2y$$ But if $y = x^3$ then $$ \frac{\partial L}{\partial y'} = \frac{\partial x^6}{\partial (3x^2)} = x^4 = y^{\frac{4}{3}}$$ In other words... what the hell? What does the partial derivative REALLY mean?","['calculus', 'partial-differential-equations', 'partial-derivative', 'euler-lagrange-equation', 'derivatives']"
1068309,Solve the recurrence relation: $2a_n = 7a_{n-1} - 3a_{n-2}; a_0 = a_1 = 1$,"$2a_n = 7a_{n-1} - 3a_{n-2}\\
a_0 = a_1 = 1$ My attempt: $2t^2 - 7t + 3 = 0\\
t = -\frac{1}{2}, -3\\
\\
U_n = b(-\frac{1}{2})^n + d(-3)^n\\
b+d = 1 = -\frac{1}{2}b-3d\\
b = \frac{8}{5}, d = -\frac{3}{5}\\
a_n = \frac{8}{5}(-\frac{1}{2})^n - \frac{3}{5}(-3)^n\\
a_2 = -5 \neq 2 =\frac{1}{2}(7-3)$ Where did I go wrong? Update: changing the t values to positive, new solution: $a_n = \frac{4}{7}(\frac{1}{2})^n+\frac{3}{7}(3)^n\\
a_2 = 4$ But following the initial equation given, $2a_2 = 4$, so shouldn't $a_2$ be 2? $a_2$ according to Wolfram Alpha is indeed 2.","['recurrence-relations', 'discrete-mathematics']"
1068324,logic and set theory proof : $|A \cap B| <|A^C|$,"Prove that if $A$ and $B$ are sets then $|A \cap B| <|A^C|$. I'm not sure how I should start this proof. Normally I would turn the proof into set theory notation, but I'm not sure if that works or if I an represent cardinality in set theory notation. If someone could show me how to get started that would be nice.",['elementary-set-theory']
1068325,power series for $\int_0^x e^{-t^2}dt$,"Use a known power series expansion to find the power series
  representation of the integral function $g(x) =\int_0^x e^{-t^2}dt$
  centered at $a=0$ My approach Note that $g'(x) = e^{-x^2}$. We also know the Maclaurin Series for
  $e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}$. Then, $$g'(x)=e^{-x^2} = \sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}$$
   $$g(x) = \int  \bigg[\sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}\bigg]
 dx$$ $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{n!} \int x^{2n}dx $$
   $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)} +K,
 \text{  where $K$ is unknown}$$ Consider $x=0$, we figured out that $g(0) = 0 +K = 0$, hence $K=0$. Hence
  $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)}$$ Is this right? I cannot differentiate between power series and Maclaurin series or stuffs like that. Can anybody clarify on this too?","['power-series', 'sequences-and-series', 'integration']"
1068339,Prove that $\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0$ in the $\epsilon$-$\delta$ way [duplicate],This question already exists : Proving a limit of a trigonometric function: $\lim_{x \to 2/\pi}\lfloor \sin \frac{1}{x} \rfloor=0$ Closed 9 years ago . Given: $$\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0$$ How to prove this limit using the $\epsilon$-$\delta$ way? (the biggest problem is to find $\delta$),"['epsilon-delta', 'calculus', 'trigonometry', 'ceiling-and-floor-functions', 'limits']"
1068349,How to smooth a list of angles.,"I'm not a math guy so maybe there is a super simple thing that my eyes cannot see. And sorry if my math terminology is not good at all. Please address me the right math terminology to use because probably this is one of the reason I'm not finding a good solution: I'm not finding the right question. I'm in the realm of programming a 3D box that changes its orientation (roll, pitch, yawn) in respect to an accelerometer. Everything goes well, I'm receiving a list of numbers that represents angles in degree from the accelerometer along axis x,y,z and the box rotates in the middle of the screen. But I'd like to post-process this signal - for example to take the direction of the movement (for instance: rotating clockwise or anti-clockwise?). But the signal is a little bit noisy so.. the first post-process operation I'd like to do is smoothing. What to say, simple average, running average, kalman filter.. with those techniques I'm facing a big problem: I'm always talking about angles. And angles are periodic. So, in every way I try to resampling the angles ([0-360], [-180,180], etc) if I'm doing a complete round I'm going from 0 to 360 or vice versa. This let the smoothing filter (let's say I'm using a running average) to get crazy. Normal angle values cannot be smoothed/interpolated.
How to do it?","['interpolation', 'trigonometry', 'euclidean-geometry']"
1068356,"How to integrate $\ln \big( b + \sqrt{b^2 + c^2 + x^2}\,\big)$?","I am looking to demonstrate the following result. Any ideas are much appreciated. 
$$
\begin{align}\int \ln \left( b + \sqrt{b^2 + c^2 + x^2}\right) dx  = &\;x \ln \left( b + \sqrt{b^2 +c^2 +x^2}\right) +b \ln \left(2x + 2\sqrt{ b^2 +c^2 +x^2} \right)\\&\;  - c \arctan \left(\frac{ b x} { c  \sqrt{b^2 +c^2 +x^2}}\right) + c \arctan  \left(\frac{x}{c}\right) -x  \end{align}$$","['logarithms', 'calculus', 'integration', 'indefinite-integrals']"
1068359,Function in $L^\infty$ is element of $L^2$?,Let $\mu$ positive measure and $f\in L^\infty(\mu)$. My question is: $f\in L^2(\mu)$? Thank you all.,"['measure-theory', 'real-analysis']"
1068367,Finding a closed-form formula for a sequence that is defined recursively,"$$a_0 = 0, a_1 = 1 \quad \text{ and } \quad a_n = a_{n-1} + 2a_{n-2}\quad \text{ for }n\geq 2$$ a) Find $a_2,a_3,a_4,a_5$ b) Find a closed form-formula for $a_n$ I found the value to be $(a_n)_{n\in \Bbb N} = \{0, 1, 1, 3 , 5, 11, ...\}$ I have not the slightest clue how to find a closed form formula, so if anyone could help me out with this I would be greatly appreciated. I've seen similar questions with answers talking about finding a geometric series, but I can assure that this question should not require knowledge of such since we have not done anything of the sort in class. Is it just trial and error to find such a formula? Or is there a set method to follow?
I noticed that the formula is very similar to the Fibonacci sequence:
$$F(n) = F(n-1) + F(n-2)$$ Thanks.","['closed-form', 'recurrence-relations', 'sequences-and-series', 'discrete-mathematics', 'exponential-function']"
1068395,Can a matrix have the same range and nullspace?,"If you can pick any $3\times 3$ matrix, is there a matrix that its $R(A) = N(A)$?
If you can pick any $4\times 4$ matrix, is $R(A) = N(A)$ possible? Here, $R(A)$ is the range of matrix A, and $N(A)$ is the nullspace of matrix A I thought the answers to both questions would be ""no"" because
$R(A)$ is obtained from $Ax=b$, where $b \not= 0$
$N(A)$ is obtained from $Ax=0$. The vectors in both spaces will never be the same. I wonder why the question would be structured in such a way.",['linear-algebra']
1068411,"Proving analytic continuation, choosing suitable branch cuts,","Consider the function $$f(z)=\log[(z^2+1)^{1/2}],\quad z>0$$ where the branch is chosen so that $(z^2+1)^{1/2}>0$ for $z>0$ and the log denotes the principal branch.  Let $R$ be the union of the negative real axis and the vertical interval $\{i\gamma:-1\le \gamma \le 1\}$. Show that $f(z)$ has an analytic continuation to the complement of R and compute $$\lim f(\epsilon), \lim f(\epsilon e^{(i3\pi)/4}), \lim f(\epsilon e^{(-i3\pi)/4})$$ as $\epsilon\to 0$. Any help would be greatly appreciated.  This problem is a little beyond me, so I don't even know how to get started, other than writing down some obvious things from the problem such as: $$(z^2+1)^{1/2}=(z+i)^{1/2} (z-i)^{1/2},$$
where $z^2$ is defined as $e^{2\log(z)}$ and that the principal branch of $\log(z)$ is analytic away from the negative real axis, when we restrict the argument of $\log(z)$ to ($-\pi \le \theta \ <\pi$). Edit:  A more specific question that I have is: Why is an analytic extension even necessary for $f(z)$?  Isn't the function already analytic away from the negative real axis, and thus should be analytic to the complement of R, which is just the whole plane minus the negative real axis and the interval of the imaginary axis from $-i$ to $i$. Is it because, in addition to the principal branch of $\log(z)$, which is already chosen for us, we need to also choose two more branches of $\log(z)$ - one branch for $(z+i)^{1/2}$, and one branch for $(z+i)^{1/2}$?","['branch-cuts', 'logarithms', 'analyticity', 'complex-analysis']"
1068448,"What conditions are necessary on $a,b,c,d$ so that the Möbius transformation $w=\frac{az-b}{cz-d}$ has only one fixed point?","Question: What conditions are necessary on $a,b,c,d$ so that the Möbius transformation $w=\frac{az-b}{cz-d}$ has only one fixed point? Attempt: We examine
$$ z=\frac{az-b}{cz-d}$$
to find that any fixed point of a Möbius transformation must satisfy
$$cz^2 + (d-a)z - b =0.$$
Hence, there are either one or two fixed points in $\mathbb{R}$ OR two fixed points in $\mathbb{C}$ which are all characterized by
$$z = \frac{(a-d) \pm \sqrt{(d-a)^2+4bc}}{2c}.$$
Hence, there can only be a fixed point when the discriminant $(d-a)^2+4bc$ is zero. Further, if there is only one fixed point, it must be in $\mathbb{R}$. Can someone with more knowledge than me comment on if my approach is right? Is there a better way to solve this question?","['mobius-transformation', 'complex-analysis']"
1068473,How to solve a linear system in matrix form using Laplace transform?,"How to solve this linear system using Laplace transform?
$$\mathbf X'(t)=\left[\begin{array}{r,r,r}-3&0&2\\1&-1&0\\-2&-1&0\end{array}\right]\mathbf X(t); ~~~~~~~~\mathbf X(0)=\left[\begin{array}{r}4\\-1\\2\end{array}\right]$$
I am struggling with this problem. I tried by write it as $$\begin{cases}x_1' &= -3x_1+2x_3,\quad   x_1(0)=4\\
x_2'&= -1x_1+1x_2, \quad   x_2(0)=-1\\
x_3'&= -2x_1 -1x_2,    \quad x_3(0)=2 \end{cases}$$ Then Laplace transform both sides but I have hit a dead end. Is there any better way to solving this problem? I would be grateful for help. I did only simple problems so far. This is very complicated for me.","['ordinary-differential-equations', 'laplace-transform', 'eigenvalues-eigenvectors', 'matrices', 'systems-of-equations']"
1068484,"Expressing ""formally"" $f(x)=\frac {1}{\sqrt {1-2x}}$ as a power series","I have to express $f(x)=\frac {1}{\sqrt {1-2x}}$ as a power series and give its interval of convergence. Knowing the binomial series is as follows this should be fairly easy: $$(1+x)^{\alpha}=\sum _{n=0}^{\infty}\binom{\alpha}{n}x^n$$ which converges when $-1<x<1$ (it must be verified if $-1,1$ belong to the interval or not). Then $$f(x)=\frac {1}{\sqrt {1-2x}}=\ (1-2x)^{-1/2}=\sum _{n=0}^{\infty}\binom{-1/2}{n}(-2x)^n=\sum _{n=0}^{\infty}\binom{-1/2}{n}(2)^n (-1)^n x^n$$ which converges when $-1<-2x<1\iff -1/2 < x < 1/2$. I verified that the series diverges when $x=-1/2$ and given that the function is not defined in $x=1/2$, it can't converge. Hence the interval of convergence is $(-1/2,1/2)$ (it would be greatly appreciated if this can be checked, just to be sure). All of this is thanks to one knowing the binomial series represents functions of the form $(1+x)^{\alpha}$ but I can't prove this. Firstly I tried to find an $M>0$ such that $|f^n(x)|<M^n$. Because $f$ is infinitely differentiable and bounded, then the Taylor series generated by $f(x)$ would represent $f(x)$. I couldn't find such $M$ in the specific case for the function I'm working with nor the general case $(1+x)^\alpha$. I then tried to show that the Lagrange remainder converges pointwise to the $0$ function. Then the Taylor Series would represent the function. Again I was not able to in my specific case nor the general case. How can I prove the result in the general case of the binomial series or how can I formally prove in the function I'm given that it is represented by it's Taylor Series? Thank you in advance.","['power-series', 'sequences-and-series', 'calculus', 'binomial-theorem', 'real-analysis']"
1068492,"Show that if $f \in \mathbb{C} \left[x_1, \dots, x_n \right]$ vanishes at every point of $\mathbb{Z}^n$, then $f$ is the zero polynomial.","I am working on a problem from Ideas, Varieties, and Algorithms: Show that if $f \in \mathbb{C} \left[x_1, \dots, x_n \right]$ vanishes at every point of $\mathbb{Z}^n$, then $f$ is the zero polynomial. My attempt so far: This proof is by induction on $n$. Let $f \in \mathbb{C}\left[x\right]$ vanish at every point in $\mathbb{Z}$. Then, it must be identically the zero polynomial, as a polynomial of degree $d$ has at most $d$ roots. Hence, $f$ vanishes at every point at $\mathbb{C}$. Now, assume that $g \in \mathbb{C} \left[x_1, \dots, x_{n-1} \right]$ vanishes at every point in $\mathbb{Z}$. We may collect terms and rewrite $f$ as $$
f(x_1, \dots, x_n) = \sum_{i=0}^m x^i_n g(x_1, \dots, x_{n-1}),
$$
for some functions $g_1,\dots,g_n\in \Bbb C[x_1,\dots,x_{n-1}]$. How do I proceed from here? I was trying to adapt an earlier proof with no success.",['algebraic-geometry']
1068494,Prove that $\binom n2 + \binom {n-1}2$ is always a perfect square,"Prove that if $n$ is a positive integer and $n >1$:
$$\binom n2  + \binom {n-1}2$$
 is always a perfect square. I know we need to turn that into a binomial, but I can't follow how.
Please note I'm pretty new to discrete math.
Thanks in advance.","['binomial-theorem', 'binomial-coefficients', 'combinatorics']"
1068513,Using Stokes' Theorem to evaluate $\int_{C}{(xyz)dx+(xy)dy+(x)dz}$,"Let $C$ be the closed, piecewise smooth curve formed by traveling in straight lines between the points $(0,0,0),(2,1,5),(1,1,3)$ and back to the origin, in that order. Use Stokes' theorem to evaluate the integral: $$\displaystyle\int_{C}{(xyz)dx+(xy)dy+(x)dz}$$ First, Stokes' theorem is: $$\displaystyle\int_{∂S}{F \cdot dS} = \displaystyle\iint_{S}{(\nabla \times F)\cdot dS} = \displaystyle\iint_{D}{((\nabla \times F)\cdot n)\,dx\,dy}$$ I started by creating two vectors by subtracting the vertex points of the triangle. The I took the cross product of those two vectors to get $n = (-2,-1,1)$. Which is the normal vector to the surface. Taking $n \cdot (x,y,z) = 0$ will give me the tangent plane. Which will be:
$$-2x - y + z = 0$$ so, $$z = 2x + y$$ I also can deduce from the question that (correct me if I'm wrong)
$$F = (xyz,xy,x)$$ So, $$\nabla \times F = (0,xy-1,y-xz)$$ so now the integral is: $$\displaystyle\iint_{D}{((1-xy+y-xz)\,dx\,dy}$$ However, I'm not sure what to do for the boundaries of the integral. In the xy-plane, I believe D would be the triangle with the vertices (0,0), (2,1), (1,1). But that doesn't really do me much good. Would I need to do some sort of transformation to make D into something easier to work with and then just include the Jacobian determinant of that transformation? Or is there a better way to go about this? Thanks!","['surface-integrals', 'multivariable-calculus', 'multiple-integral']"
1068514,Hierarchy of Mathematics Breakdown,"Can you provide me with a hierarchical breakdown on Discrete Math as it applies to computer science? By this I mean a breakdown on topics that fall under the study of discrete numbers, specifically those that apply to computer science. I understand that discrete math focuses on noncontinuous numbers such as integers, statements of logic, and graphs. But I don't really understand any practical examples of how these apply... Well statements of logic make sense in programming with if/then/and/or etc, but i'm not sure about the rest. I really just need someone smart to talk too... any takers? Background: I am starting on a course in computer science that involves programming, networking, etc. The problem is this course has a very high attrition rate, specifically in its mathematics portion and I only have a few weeks to study before starting the course, which I'll be tested on throughout. I am taking this course for work and all I've been told is to focus on ""Discrete Math, Logic, Knights and Knaves""? As for my own background I feel strong on the actual computer science portion, however I finished highschool with a GED and did terrible in math when I was there... I know this post was extremely vague, terribly worded and will likely be crucified. But I honestly don't know how to ask this question any better and I truly am limited on my knowledge of the upcoming course. I would greatly appreciate any resources or help that you can Offer...",['discrete-mathematics']
1068517,Standard deviation of $Z = 9 - 3Y^3$,"If Y is a random variable with probability mass function: Y | Pr(Y = y)
-1 | 0.4
 0 | 0.5
 1 | 0.1 I need to find the standard deviation of $Z = 9 - 3Y^3$. Approach: since it's the variance I know that 9 should not affect it and I essentially have $3^2 Var(Y^3)$ using one of the identities.  My understanding is that I should be able to use the delta method to find $Var(Y^3)$ but I am not sure how.  I don't think I can directly use the identity $Var(X) = E[X^2] - E[X]^2$ can I?","['statistics', 'standard-deviation']"
1068566,Help with difficult telescoping series question: $\frac3{1!+2!+3!}+\frac4{2!+3!+4!}+\ldots+\frac{2012}{2010!+2011!+2012!}$ [duplicate],"This question already exists : Finding $\frac{3}{1!+2!+3!}+\frac{4}{2!+3!+4!} +\frac{5}{3!+4!+5!}+\cdots+\frac{2008}{2006!+2007!+2008!}$ [duplicate] Closed 6 years ago . Evaluate $$\frac3{1!+2!+3!}+\frac4{2!+3!+4!}+\ldots+\frac{2012}{2010!+2011!+2012!}\;.$$ I see that the question is telescoping, but I don't know how to break it down into a form similar to that of the most basic telescoping series.
What would be the best method to simplify this question?","['factorial', 'sequences-and-series']"
1068576,"Finding General Solutions to 2nd Order Differential Equations, Am I on the right track?","I'm studying Differential Equations, and I'm working on figuring out how to solve using Undetermined Coefficients.  We've been assured that on the test we will only have to solve equations with a 2nd order at most.  That being said, I'm trying to figure out what my general solutions should look like for each possible combination of roots. I've read through a lot of very verbose generalized general solutions, that I'm having a lot of trouble really comprehending.  Here's what I've taken from them. Two Real Roots (non-repeating) $$
Y_c = c_1e^{m_1x}+c_2e^{m_2x}
$$ Repeated Real Roots $$
Y_c = c_1e^{x}+c_2xe^{x}
$$ Imaginary Roots (I'm really lost on this one) $$
Y_c = c_1\cos+c_2\sin
$$ My Questions is this: Am I on the right track with the first two? What am I doing wrong with the last one? *[We're using Dennis G Zill's A First Course in Differential Equations ]*",['ordinary-differential-equations']
1068614,Understanding the proof of an Ergodic theorem for Markov chains,"An ergodic theorem for Markov chains is as follows. If a Markov chain $(X_n)_{n \ge 0}$ is irreducible and has an invariant distribution $\pi$, then
  $$\frac{1}{n} \sum_{k=0}^{n-1} f(X_k) \to \overline{f}:=\sum_{i \in I} \pi_i f(i)$$
  almost surely as $n \to \infty$, for any bounded function $f:I \to \mathbb{R}$. I have attached the proof that appears in Norris's text below. Here, $V_i(n):= \sum_{k=0}^{n-1} \mathbf{1}_{\{X_k=i\}}$ denotes the number of visits to state $i$ before time $n$. I do not understand the step $$\sum_{i \in J} \left|\frac{V_i(n)}{n}-\pi_i\right| + \sum_{i \notin J} \left(\frac{V_i(n)}{n}+\pi_i\right)\le 2\sum_{i \in J}\left|\frac{V_i(n)}{n}-\pi_i\right| + 2 \sum_{i \notin J} \pi_i.$$ After rearranging, I see that this is equivalent to showing that
$$\sum_{i \in J} \left|\frac{V_i(n)}{n}-\pi_i\right| \ge \sum_{i \notin J} \left(\frac{V_i(n)}{n}-\pi_i\right),$$
but I don't see why this is true either. Why was it necessary to examine a subset $J \subset I$? What is wrong with the following?
$$\left|\frac{1}{n}\sum_{k=0}^{n-1} f(X_k)-\overline{f}\right| \le \sum_{i \in I} \left|\frac{V_i(n)}{n}-\pi_i\right|<\epsilon,$$
for $n$ large enough? Norris's proof.","['ergodic-theory', 'markov-chains', 'markov-process', 'real-analysis', 'probability']"
1068616,Evaluating inverse of trigonometric function,"I have this function, $$\sin\left[{\arctan\left({\frac{x}{\sqrt{1-x^2}}}\right)}\right]$$ I drew a right angled triangle putting $x$ on the opposite side and the square root on the adjacent which makes the hypotheses being $1$, and since that $\sin = \frac{\text{opposite }(x)}{\text{hypotenuse (1)}}$ the result is equal to $x$, now my question is the result doesn't respect the domain as the original function am I supposed to add one and am I supposed to reverse the denominator and nominator in the case of an arc function? because when I do that I get $\sqrt{1-x^2}$ which isn't correct","['trigonometry', 'calculus']"
1068637,Kloosterman sum and multiples of 16,"A Kloosterman sum is defined as $$K(a,b;m)=\sum_{\substack{ 0\leq x \leq m-1\\\gcd(x,m)=1}} e^{2\pi \mathcal{i} (ax+bx^*)/m}$$ where $a,b,m \in \mathbb{N}$ and $x^*$ is the inverse of $x$ modulo $m$. How can I show that $$K(1,1;16n)\neq 0$$ for odd $n$?","['analytic-number-theory', 'number-theory']"
1068649,Evaluating $\int_{0}^{\pi/2}\frac{x\sin x\cos x\;dx}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}}$,"How to evaluate the following integral
$$\int_{0}^{\pi/2}\frac{x\sin x\cos x}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}}dx$$ For integrating I took $\cos^{2}x$ outside and applied integration by parts. Given answer is $\dfrac{\pi}{4ab^{2}(a+b)}$.
But I am not getting the answer.","['closed-form', 'calculus', 'integration', 'definite-integrals', 'trigonometry']"
1068663,Topology generated by Functions.,"Fix a set $X$. Let $\mathcal{F}_0$ be a set of functions $g:X\to\mathbb{R}$. Let $\mathcal{T}_0$ be the smallest topology on $X$ in which all $g\in\mathcal{F}_0$ are continuous. Next, we say that a function $f:X\to\mathbb{R}$ is locally generated by $\mathcal{F}_0$, if for every $x\in X$, there exists an open neighborhood $U\in\mathcal{T}_0$ of $x$, $k\in\mathbb{N}$, $g_1,...,g_k\in\mathcal{F}_0$, and a continuous map $F:\mathbb{R}^k\to\mathbb{R}$ such that forall $y\in U$, we have $f(x)=F(g_1(x),...,g_k(x))$. Let $\mathcal{F}$ be the set of all functions $f:X\to\mathbb{R}$ locally generated by $\mathcal{F}_0$, and $\mathcal{T}$ the smallest topology in which all $f\in\mathcal{F}$ are continuous. Note that one can prove $\mathcal{T}_0=\mathcal{T}$. Now assuming that $\mathcal{T}$ is $T_0$ topology, prove directly that it is $T_3$ (regular), and then prove that it is $T_{3\frac{1}{2}}$ (completely regular). Can somebody help me with proving this?? I can't even start... Also, if anybody have any reference related to this problem, let me know then I will appreciate it. Thank you in advance... New things On the other hand, I tried to disprove the above problem by giving a counter-example... If any one interested in the following claim, you may check and verify. Furthermore, if you can find any mistake or wrongness on the claim, and if you let me know, I will appreciate so much... Thank you. Now, I thought the following example was a counter example, but I got $0$ score on this.. (It was a homework whether to prove or disprove (by giving a counter example).) Let $X=\mathbb{R}$ with $\mathcal{F}_0=\{f,g\}$ where $f$ is defined by $f(x)=x$ for $x\geq 0$, and $f(x)=-\frac{1}{2}x$ for $x<0$, and $g(x)=-\frac{1}{2}x$ for $x\geq 0$ and $g(x)=x$ for $x<0$. Then, by drawing a graph, you can easily see that the smallest topology generated by this functions is $T_0$ space (You can choose arbitrary small open interval on $Y$-axis to separte a point (in $X$) from another point (in $X$)). Now consider a point $-\frac{1}{2}$ and a closed subset $[0,1]$. Since for every $(a,b)\subset\mathbb{R}$ such that $\frac{1}{2},\frac{1}{4}\in(a,b)$, either $f^{-1}(a,b)$ or $g^{-1}(a,b)$ intersects $[0,1]$ while the $f^{-1}(a,b)$ or $g^{-1}(a,b)$ are basic open sets in $\mathcal{T}_0$, that containing $-\frac{1}{2}\in\mathbb{R}$, I claim that it is not regular, and hence not completely regular.","['general-topology', 'separation-axioms']"
1068665,"How can I test if an element g is a generator of a group G with a known number of elements, N?","Let's say $G$ has $1000$ elements. Without looping through each $g^m$, how can I show that $g$ is a generator? I've deduced that I must prove that the order of $g = N$, or in this case $1000$, but I'm not sure how to go about that. Any help is appreciated. Thanks!","['modular-arithmetic', 'finite-groups', 'group-theory']"
1068726,When does a formula for the roots of a polynomial exist?,"My question is straightforward to pose: given a polynomial $f$ over a subfield of $\mathbb{C}$, are there conditions which guarantee the existence of a closed formula for the roots of $f$ in terms of its coefficients? $\textit{Edit:}$ By ""closed formula"", I am referring to a formula using addition, subtraction, multiplication, division, and extraction of roots, such as the quadratic formula. In case my background in mathematics is relevant to anyone who may wish to answer my question, I just finished my first undergraduate course in Galois theory, in which I was introduced to the following theorem: If $f$ is a polynomial over a subfield $F$ of $\mathbb{C}$ and $f$ is solvable by radicals, then the Galois group of $f$ over $F$ is solvable. This theorem offers us a method to demonstrate, for example, that the general quintic polynomial is not solvable by radicals. However, I did not encounter any theorems that address the question I stated above. Any answers or comments pertaining to my question will be much appreciated. Thanks.","['galois-theory', 'solvable-groups', 'abstract-algebra', 'polynomials']"
1068730,Number of samples needed to get a given expected distance,"Suppose I have a surface in $\mathbb{R}^3$ with surface area $A$. How many points do I need to (uniformly at random) sample so that the expected distance from each point to its nearest neighbor is $d$? Dimensional analysis suggests the number of samples should be proportional to $\frac{A}{d^2}$. Can anything be said about the proportionality constant, if we don't know anything about the geometry of the surface?","['statistics', 'geometry']"
1068748,Uniformly integrable martingale in a finite time horizon,"Let $\{ M (t) \mid t \in [0,T] \}$ be a martingale and $\{ \tau_n \mid n = 1, 2, \ldots\}$ be an increasing sequence of stopping times such that $\tau_n \rightarrow \infty$ as $n \rightarrow \infty$. Without additional assumptions, is the family of stopped processes 
$\{ M (T \wedge \tau_n ) \mid n = 1, 2, \ldots \}$ always uniformly integrable? It seems to me that by Doob's stopping theorem $M (T \wedge \tau_n) = \mathrm{E} [ M (T) \mid {\cal F}_{T \wedge \tau_n} ]$. So the uniform integrability holds. Is this argument true or not? Any hints are really appreciated.","['stochastic-processes', 'martingales', 'uniform-integrability', 'probability-theory', 'stopping-times']"
1068757,Any finite set is compact; what exactly is a finite set?,"Any compact set is finite. Assume the sets are in $\mathbb{R}$ Since $A = [0, 1]$ is compact, it is also finite. As for $B = (0, 1)$, it is not compact, so it is infinite. However, how is it infinite? There are infinitely many points between 0 and 1? But aren't there infinitely many points between 0 and 1 in set $A$ as well? Also, for the set $C = \left \{ 1 + \frac{1}{n}, n \in \mathbb{N} \right \}\cup \left \{ 0 \right \}$. It is bounded and closed, thus compact. However, how is it finite? The natural numbers are infinite, so wouldn't the set contain infinitely many elements?",['general-topology']
1068811,Power set of Set differences,"Assume that $\mathcal P(A-B)= \mathcal P(A)$. Prove that $A\cap B = \varnothing$. What I did:
I tried proving this directly and I got stuck. Let $X$ represent a nonempty set, and let $X\in\mathcal P(A-B)$. By definition of power set and set difference: $X\subseteq A$ and $X\nsubseteq B$. By definition of a subset and subset negation: Let $y$ be an arbitrary element of $X$ such that:
$(\forall y)(y \in X \rightarrow y \in A)\land (\exists y)(y \in X \land y \nsubseteq B)$ This is where I get stuck, how do I confirm I have no common elements with the fact that there is at least one element they don't share? I also tried proving the contrapositive by assuming that the intersection is not disjoint, where I let $X$ be a subset in the intersection then $X$ must belong to both $A$ and $B$ and that's where I got stuck. I apologize for bad formatting first time poster",['elementary-set-theory']
1068823,Every metric space is a D-space.,"I think it is correct, but I would like another pair of eyes to verify. Definition. An open neighborhood assignment is a function $f:X\to \tau$ such that $x\in f(x)$. Definition. A space is said to be D, or a D-space, if for every open neighborhood assignment $f:X\to \tau$ there exists a closed discrete set such that $f[D]$ is a cover of $X$. Theorem. Every metric space is a D-space Proof. Let $f:X\to\tau$ be an open neighborhood assignment in a metric space. Then define the function $\textit{d}:X \to \mathbb{N}$ by $\textit{d}(x) = \min\lbrace n\in\mathbb{N} | B_{1/n}(x)\subset f(x)\rbrace$. Since this is possible, we will actually just replace our open neighborhood assignment with the smaller assignment given by $\lbrace B_{1 / \mathit{d}(x)}(x)\in \tau | x\in X \rbrace$. If it is possible to show that there is a one such closed discrete set using this smaller assignment, then it is then possible to use the original assignment. For all $n\in\mathbb{N}$, define $L_n = \lbrace x\in X|\textit{d}(x) = n\rbrace$. Enumerate $X=\lbrace x_\alpha | \alpha<\lambda\rbrace$ such that if $\alpha<\beta$ then either $x_\alpha,x_\beta\in L_i$ for some $i$ or $x_\alpha\in L_i$ and $x_\beta\in L_j$ for some $i<j$. Without loss of generality, suppose that $L_1$ is non-empty. Define $D_1 = \lbrace x_1 \rbrace$. If $x_\alpha$ is not in $f[\cup_{\beta < \alpha}D_{\beta}]$, then let $D_\alpha = \cup_{\beta < \alpha}D_{\beta}\cup \lbrace x_\alpha \rbrace$. If $x_\alpha$ is in $f[\cup_{\beta < \alpha}D_{\beta}]$ then we let $D_\alpha = \cup_{\beta < \alpha}D_{\beta}$. Let $D=\bigcup_{\alpha\in\lambda}D_\alpha$. Claim. D is discrete. Argument. (no one is in another person's bubble) Let $x_\alpha,x_\beta\in D$. Since $X$ is well ordered, let $\alpha<\beta$. Then $x_\beta \notin f(x_\alpha)$ by construction. Hence, $\rho(x_\alpha,x_\beta)\geq 1/ \textit{d}(x_\alpha)$. But also, since $\alpha<\beta$, $1/ \textit{d}(x_\alpha)\geq 1/ \textit{d}(x_\beta)$. Thus we have $\rho(x_\alpha,x_\beta)\geq 1/ \textit{d}(x_\alpha)\geq 1/ \textit{d}(x_\beta)\Rightarrow x_\alpha\notin f(x_\beta)$.\ Claim. D has no accumulation points Argument. If $D$ were to have an accumulation point, it surely won't be an element of $D$ by our previous result. Hence let $x_\alpha\in X\setminus D$. Since $x_\alpha$ was not chosen to be in $D$, it follows that there exists $\beta<\alpha$ such that $x_\alpha\in f(x_\beta)$. Let $\epsilon>0$ such that $B_\epsilon(x_\alpha)\subset f(x_\beta)$. By our previous result, there is no $y\in D$ such that $y\in f(x_\beta)$. Hence, no $y\in D$ such that $y\in B_\epsilon(x_\alpha)$.","['general-topology', 'metric-spaces']"
1068830,Find Minimum value of $P=\frac{1}{1+2x}+\frac{1}{1+2y}+\frac{3-2xy}{5-x^2-y^2}$,"Given: $x,y\in (-\sqrt2;\sqrt2)$ and $x^4+y^4+4=\dfrac{6}{xy}$ Find Minimum value Of $$P=\frac{1}{1+2x}+\frac{1}{1+2y}+\frac{3-2xy}{5-x^2-y^2}$$ Could someone help me ?","['inequality', 'calculus']"
1068838,Conditions for Taylor formula,"I know that, if $F:X\to Y$, where $X,Y$ are Banach spaces, is a map whose $n$-th Fréchet derivative $x\mapsto F^{(n)}(x)$ is continuous as a function of $x$ in a neighbourhood of $x_0\in X$, then the Taylor formula of $F$ in $x_0$ holds:$$F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)+...+\frac{1}{n!}F^{(n)}(x_0)(h,...,h)+\omega(x,h)$$where $\|\omega(x,h)\|=o(\|h\|^n),h\to 0$ and $F^{(n)}(x_0)$ is the $n$-linear form corresponding to the $n$-th derivative. I have never see the condition of continuity of $F^{(n)}$ in $x_0$ relaxed either in the general case or when $X=\mathbb{R}^n$, $Y=\mathbb{R}$ (contrarily tom what happens when $X=\mathbb{R}=Y$, when De l'Hôpital's rule can be used and the assumption of the continuity of $F^{(n)}$ avoided). Can that assumption be relaxed? I am asking that because Kolmogorov-Fomin's Элементы теории функций и функционального анализа proves the Taylor expansion under the continuity assumption (p. 491 here ), but then proves the following theorem, which has the Hessian matrix test as a particular case, without saying that $F''$ must be continuous by using the Taylor expansion $F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)$ $+o(\|h\|^2)$: if functional $F:X\to\mathbb{R}$ where $X$ is a Banach space and (1) $F'(x_0)=0$ and (2) $F''(x_0)$ is strongly positive, i.e. $\exists c>0:\forall h\in X\quad F''(x_0)(h,h)\ge c\|h\|^2$, then $F$ has a minimum in $x_0$.","['multivariable-calculus', 'banach-spaces', 'real-analysis', 'functional-analysis', 'taylor-expansion']"
1068849,Calculate $\int_{|z|=1}\frac{dz}{\sin z}$,I have to evaluate $\int_{|z|=1}\frac{dz}{\sin z}$. Any tips?,"['definite-integrals', 'complex-analysis']"
1068862,covariant and contravariant components and change of basis,"I encountered the following in reading about covariant and contravariant: In those discussions, you may see words to the effect that covariant 
  components transform in the same way as basis vectors (“co” ≈ “with”),
  and contravariant components transform in the opposite way to basis 
  vectors (“contra” ≈ “against”). As you’ll see later in this chapter,
  there’s plenty of truth in that description, but there’s also a major
  pitfall. That’s because the “transformation” of basis vectors usually
  refers to the conversion of the basis vectors in the original
  (non-rotated) coordinate system to the different basis vectors which
  point along the coordinate axes in the new (rotated) system, whereas
  the “transformation” of vector components refers to the change in the
  components of the same vector referred to two different sets of
  coordinate axes. Later on it shows the following: $$\begin{pmatrix} \text{Components of}  \\
                  \text{same vector} \\
                  \text{in new system} \end{pmatrix} = 
\begin{pmatrix} \text{Inverse}  \\
                  \text{transformation} \\
                  \text{matrix} \end{pmatrix}
\begin{pmatrix} \text{Components of}  \\
                  \text{vector in} \\
                  \text{original system} \end{pmatrix}$$ $$\begin{pmatrix} \text{New basis}  \\
                  \text{vectors} \end{pmatrix} = 
\begin{pmatrix} \text{Direct}  \\
                  \text{transformation} \\
                  \text{matrix} \end{pmatrix}
\begin{pmatrix} \text{Original basis}  \\
                  \text{vectors}\end{pmatrix}$$ These confuse me because from change of basis we have $B'= BP$ and $[v]_{B'}=P[v]_B$.
The $[v]_{B'}=P[v]_B$ is the first of the aforementioned equations. But the second of them I don't understand since the book as shown above has the direct transformation matrix on the left side and not the right side. We could write $B'= BP = (BPB^{-1})B$ but if $BPB^{-1}$ is the direct transformation matrix then the $P$ in $[v]_{B'}=P[v]_B$ does not make sense as the inverse transformation matrix as the inverse of $BPB^{-1}$ is not $P$. So then later on when I read the following: you can combine superscripted (contravariant) components with
  subscripted (covariant) basis vectors I don't know how to reconcile it with what I already know about change of basis.","['tensor-products', 'linear-algebra', 'multilinear-algebra', 'vectors']"
1068879,How to derive this interesting identity for $\log(\sin(x))$ [duplicate],"This question already has answers here : Fourier series of Log sine and Log cos (2 answers) Closed 9 years ago . I saw on SE that: $$\log(\sin x)=-\log(2)-\sum_{n=1}^{\infty}\frac{\cos(2nx)}{n} \phantom{a} (0<x<\pi)$$ This is an extremely useful identity, as it helps solve: $$\int_{0}^{\pi} \log(\sin(x)) dx$$ But how is it derived? From Taylor series, power series? How do I get this? Even if someone can start me off that would be great.","['power-series', 'sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
1068914,Showing that $f(x)=x^2$ for $x \in \mathbb{Q}$ and $f(x)=0$ for $x \not\in \mathbb{Q}$ is differentiable in $x=0$,"I am supposed to show that $f(x) = x^2$ for $x$ in the rationals and $f(x) = 0$ for $x$ in the irrationals is differentiable at $x = 0$ and I am supposed to find the derivative of $f(x)$ at $x = 0$.
Is my proof correct or not?
My proof: consider limit as $h\rightarrow0$ of $\frac{f(0 + h) - f(0)}h$ 
then we have limit as $h\rightarrow0$ of $\frac{h^2 - 0^2}h$
and then we get limit as $h\rightarrow0$ of $\frac{h^2}h
=$ limit as $h\rightarrow0$ of $h= 0 = $ the derivative of $f(x)$ at $0$","['derivatives', 'real-analysis']"
1068915,interior of union of two sets,"I have been reading about some properties of interior and closure operator. I came across the fact that For any topological space $X$ and $A$ and $B$ $\subseteq X$.It is not true in general $i(A \cup B )=i(A) \cup i(B)$
.We have the counter example as the set $A=[0,1] \cup (1,2) \subseteq \mathbb{R}$. But I would be interseted in knowing that can we impose any condition on $A$ and $B$ in general topological space so that equality holds.Will it hold if the two sets are disjoint??",['general-topology']
1068918,How many such functions are possible?,"Let $f$ be a function from $\{1,2,3,\dots,10\}$ to $\Bbb{R}$ such that $$\left(\sum\limits_{i=1}^{10}{\frac{|f(i)|}{2^i}}\right)^2=\left(\sum\limits_{i=1}^{10}{|f(i)|^2}\right)\left(\sum\limits_{i=1}^{10}{\frac{1}{4^i}}\right)$$ How many such $f$ are possible? I used the Cauchy-Schwarz inequality to conclude that this condition would imply $2|f(1)|=2^2|f(2)|=\dots=2^{10}|f(10)|$, and hence there are uncountably many such functions possible. However, I am not sure of this. Any help solving this question would be great.",['functions']
1068948,"How to prove that $\int_{0}^{\infty}\sin{x}\arctan{\frac{1}{x}}\,\mathrm dx=\frac{\pi }{2} \big(\frac{e-1}e\big)$","I found this nice result. Prove that $$\int_{0}^{\infty}\sin{x}\arctan\left({\frac{1}{x}}\right)\,\mathrm dx=\frac{\pi }{2} \left(\frac{e-1}e\right)$$ I tried some methods but I can't evaluate it.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
1068949,Find a bijection from $\mathbb R$ to $\mathbb R-\mathbb N$,Find a bijection from $\mathbb R \to  \mathbb R-\mathbb N$. I want to set my function up such that all natural numbers get mapped to $n+.1$ and reals of the form $n+.1$ to $2n+.1$ is this correct?,['elementary-set-theory']
1068953,Evaluate $\lim_{x\rightarrow 0^{+}}(3^{x}-2^{x})^{{1}/{x}} $,"Evaluate 
$$\lim_{x\rightarrow 0^{+}}(3^{x}-2^{x})^{{1}/{x}}  $$ I tried to use $\ln$ and $e$ with no success.","['limits-without-lhopital', 'calculus', 'limits']"
1068966,trace inequality of positive definite matrices.,"Assume $A,B \in M_n(\Bbb{R})$ are positive definite matrices, show that $$\text{Tr}(AB)\leq \text{Tr}(A)\text{Tr}(B) $$ I only prove it for $n=2$, it is straightforward calculate.but when $n \geq 3$. I have no idea to use the condition positive definite. I know it is equal to its principal minors are positive. when $n=2$, is very useful .but when $n \geq 3$. it seems useless : ( please help me ,thanks","['matrices', 'linear-algebra', 'inequality']"
1068993,Set up integral in spherical coordinates outside cylinder but inside sphere,"I have the equation of a cylinder and the equation of a sphere given: Cylinder: $x^2+y^2=4$ Sphere: $x^2+y^2+z^2=25$ I'm asked to set this up in cylindrical and spherical coordinates. Cylindrical was easy enough, but I'm having some trouble figuring out the limits for spherical. My first thought:
$\int\limits_0^{2\pi}\int\limits_0^\pi\int\limits_2^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ I thought that in spherical $\rho$ is basically the radius so setting it from 2 to 5 would exclude the area of the cylinder but apparently it is not that simple.  Below is the answer my teacher gave and I'm not exactly sure what she did. Correct integral in spherical:
$2\int\limits_0^{2\pi}\int\limits_{cos^{-1}(\frac{\sqrt{21}}{5})}^{\pi/2}\int\limits_{2\csc(\phi)}^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ The picture when graphed is just a sphere with radius 5 and a cylinder that cuts through the middle.  I'm not sure how my teacher got limits like $cos^{-1}(\frac{\sqrt{21}}{5})$ or $2\csc(\phi)$","['multivariable-calculus', 'integration', 'spherical-coordinates']"
1069000,How many $f(x)$ are possible satisfying $f(x)=f'(x)$ and $f(0)=f(1)=0$.,"Let $f:[0,1]\to\Bbb{R}$ be a fixed continuous function such that $f$ is differentiable on $(0,1)$ and $f(0)=f(1)=0$ . Then the equation $f(x)=f'(x)$ admits how many solutions? The only solution that I am getting is $y=0$ . This is because $y=y'$ implies $y=Ae^x$ , and $A=0$ when accounting for boundary conditions. However, I am not sure if this is the right answer. Most other examinees were saying that multiple such functions are possible. An explanation of this would be great. EDIT: The options were A. No solution $x\in (0,1)$ B. More than one solution $x\in (0,1)$ C. Exactly one solution $x\in (0,1)$ D. At least one solution $x\in (0,1)$ I feel that if C is right, then so is D!","['ordinary-differential-equations', 'calculus', 'functions']"
1069017,Counterexample to an implication,"Denote $\bar{A}$ a complement of $A$ in a set $\Omega$ and $A \Delta B = A/B \cup B/A$ the symmetric difference of $A, B$. It is claimed that for a map $\phi := \Omega \rightarrow \lbrace 0, 1 \rbrace, \; \phi(\emptyset) = 0$: $$
\begin{array}{|c|c|}
\hline
\phi(A) & \phi(\bar{A}) \\
\hline
0 & 1 \\
1 & 0 \\
\hline
\end{array}, \, A \in \Omega  \implies \phi(A \Delta B) = \phi(A) + \phi(B),  \text{  and } \phi(\Omega) = 1
$$ I know of a counterexample to this. Let $\mathcal{P}(\alpha)$ be a set of all subsets (a power set) of set $\alpha$. Consider $\phi: \Omega \rightarrow \lbrace 0,1 \rbrace$, $\Omega = \mathcal{P}({\lbrace a, b, c \rbrace})$: $$
\begin{align*}
\phi(a) &= 0 &
\phi(b) &= 1 &
\phi(c) &= 1 & 
\phi(\emptyset) &= 0 \\
\phi(b \cup c ) &= 1 &
\phi(a \cup c) &= 0 &
\phi(a \cup b) &= 0 &
\phi(a \cup b \cup c) &= 1
\end{align*}
$$ which satisfies the truth table, but breaks linearity ($\phi(a \Delta c) = \phi(a \cup b) = 0 \neq \phi(a) + \phi(c) = 1$). I am interested if the following could be also implied by the LHS and also lead to a valid counter: $$
\phi(A \Delta B) = \phi(A) + \phi(B) + \phi(A)\phi(B), \, \text{ and } \phi(\Omega)  =1
$$ Choosing $\phi(A) = 0$ implies that:
$$
\phi(A \Delta \bar{A}) = \phi(\Omega) = 1 = \phi(A) + \phi(\bar{A})(1 + \phi(A)) = \phi(\bar{A})$$
and hence: $\phi(A) = 0 \implies\phi(\bar{A}) = 1$ and $\phi(\bar{A}) = 0 \implies \phi(A) = 1$. Choosing $\phi(A) = 1$ however leads to:
$$
1 = 1 + \phi(\bar{A})\cdot 0 = 1
$$
no matter what $\phi(\bar{A})$ is, so the opposite implication is not simply shown to hold. Is there any way out of this to finish the counter? Note: If you can think of a better title for the question, please let me know.","['examples-counterexamples', 'elementary-set-theory']"
1069046,Linear systems of differential equations,I would like to see an example of a real physical situation where one can find a set of variables evolving according to a system of linear differential equations. I wasn't able to find any such example so I'm asking here.,"['motivation', 'ordinary-differential-equations']"
1069060,Master equation of chemical reaction,"I have about the construction of master equation for chemical reaction i.e. I have to construct differential equations for the probability mass function for the number of particles A, B and C. When I have this following reaction 
$$\emptyset\rightarrow^{k_A}{A}$$
$$\emptyset\rightarrow^{k_B}{B}$$
$$A\rightarrow^{k_A}{B}$$
$$B\rightarrow^{\gamma}{\emptyset}$$
I have no problem to construct the master equation because if i consider P(n,m,t), P(n,t), P(m,t) where n is the number of particles A and m the number of particles B at time t I should have the following equations with respect to each reaction (if I'm right):
$$
P'(n,t)=P(n-1,t)k_{A}-P(n,t)k_A
$$
$$
P'(m,t)=P(m-1,t)k_{B}-P(m,t)k_B
$$
$$
P'(m,t)=P(m-1,t)nk_{A}-P(m,t)nk_A
$$
$$
P'(m,t)=P(m+1,t)(m+1)\gamma-P(m,t)\gamma
$$
But for example, when I have to consider more complicated reaction, in which way should I have to procede? 
For example, for the following reaction
$$
A+B\rightarrow^{\gamma}\emptyset
$$
is the following reaction correct?
$$
P'(n,m,t)=P(n+1,m+1,t)(n+1)(m+1)\gamma-P(n,m,t)nm\gamma
$$
And for other kind of reaction like these:
$$
A+B\rightarrow^{\gamma_B}A
$$
$$
A+A\rightarrow^{\gamma_{AA}}\emptyset
$$
$$
A+B\rightarrow^{k_C}C
$$
In which way should I procede? 
I will be very happy if someone could help me! Thank you very much in advance!","['stochastic-processes', 'ordinary-differential-equations', 'probability']"
1069061,"Find a function that maximizes $\int_{0}^{1}f(x)\,\rm dx$ with given constraints","Find a function $f(x)$ that maximizes the following integral $$\max\int_{0}^{1}f(x)\,\rm dx\quad \text{s.t.}\quad \frac{d}{dx}ln(f(x))<0$$ $f(x)$ also continues, $f:[0,1]\rightarrow R$ and we know that $f(0)=a$, $f(1)=b$ and $a>b>0$. I think that the function f(x) that maximizes this integral in the interval $[0,1]$ with the given constraints is a linear function: $f(x)=(b-a)x+a$ and this integral would be: $$\frac{a}{2}+\frac{b}{2}$$ Am I right?","['optimization', 'integration', 'definite-integrals']"
1069068,Almost surely convergence of the sequence,"Let ${X_n}$ be a sequence of independent and identically distributed, square integrable random variables.
  Write $ u = E(X_n)$. Study the almost sure convergence, as $n \rightarrow \infty$, $$S_n = (X_1X_2 + X_2X_3 + ... + X_{n-1}X_{n})/n$$ Since $X_iX_{i+1}$ are not independent, it seems we cannot directly use law of large number for that, so anyone can give me some idea?","['central-limit-theorem', 'law-of-large-numbers', 'probability']"
1069087,A question about matrices such that the elements in each row add up to $1$.,"Let $A$ be an invertible $10\times 10$ matrix with real entries such that the sum of each row is $1$. Then is the sum of the entries of each row of the inverse of $A$ also $1$? I created some examples, and found the proposition to be true. I also proved that if two matrices with the property that the sum of the elements in each row is $1$ are multiplied, then the product also has the same property. Clearly, $I$ has this property. I think I have a proof running along the following lines: $$A^{-1}A=I$$ where $A$ and $I$ satisfy the aforementioned property. Also, if $A^{-1}$ did not satisfy this property, then neither would the product of $A$ and $A^{-1}$, which is a contradiction. Is the proposition true, and if so, is my proof correct?",['matrices']
1069089,"notation (ab)use for random variables, distributions, pdfs/pmfs","This question is about notation for random variables (RVs), distributions and pdfs/pmfs and their common (ab)use as I recently got confused. Let $X,Y$ denote random variables. First, notations I usually encounter. Please correct me: values a RV takes on are usually denoted by small caps so that $P(X=x) \in [0,1]$ denotes the probability of the RV $X$ taking on the value $x$ $X_1,...,X_n \sim X$ means ""let X_1,...,X_n be RV with same distribution as $X$"" (often $\overset{\text{iid}}{\sim}$) if $X$ is discrete it's pmf is usually denoted by $p(x) = p_X(x) = P(X=x) \in [0,1]$ if $X$ is non-discrete it's pdf is usually denoted by $f(x) = f_X(x) \in [0,\infty)$ or $p(x) = p_X(x)$ to easily talk about discrete and non-discrete RVs at the same time the cdf is usually written as $F(x) = F_X(x) = P(X \leq x)$ which is a sum/integral using the pdf/pmf The following notations I've usually understood in an ""intuitive"" way or assumed to just be sloppy but caused some confusion: ""Let $X$ be a RV with distribution $X \sim P(X)$"" -- What exactly is meant? Should I think of $P$-robability here or is it a symbol which reads ""this denotes/represents the distribution of $X$""? ""$p(X,Y), p(X), p(X|Y)$ denote the joint, marginal, conditional probability density functions"" -- How should I understand this? I mean, they should be functions of values the RVs can take on but here they take the RVs itself as argument? "" Let $P(x,y)$ be an (unknown) joint probability distribution on instances and labels $X × Y$. Given a training sample ${(x_i, y_i)}_{i=1}^n \overset{\text{iid}}{\sim} P(x,y)$ ..."" -- How to read this? Could someone help me out and shed some light upon above mentioned points? Sorry, if my questions are stupid. I just feel the notation gets far more sloppy when reading applied stuff and it would help me to pin down what actually is meant or to know that one needs to relax and learn how to sloppily-correctly read this.","['probability-theory', 'probability-distributions', 'probability', 'notation']"
1069122,Is the function $y = a^x + b$ exponential?,"What exactly is an exponential function? Some of the sources at which I looked said that it's a function where the rate of change at $x$ $(f'(x))$ is proportional to the value at that point $(f(x))$, and others wrote that it is simply a function with $a^x$ in it, where $a$ is a fixed base. So, my question is: if $f(x) = a^x + b$, is $f(x)$ exponential? This function is exponential by the 2nd definition, but not by the first.","['exponential-function', 'derivatives', 'functions']"
1069141,Solving a circular permutation problem with recursion,"N people are invited to a dinner party, and they are sitting at a round table. Each person is sitting on a chair; there are exactly N chairs. So each person has exactly two neighboring chairs, one on the left and the other on the right. The host decides to shuffle the sitting arrangements. A person will be happy with the new arrangement if he can sit on his initial chair or either of his initial neighboring chairs. We have to find the number of different arrangements such that no people are happy. Two arrangements are considered different if there is at least one person sitting on a different chair in the arrangements. How can I solve this problem with a recursive relation? Since I'm novice in counting, a clear explanation is needed.",['combinatorics']
1069152,A faster way of calculating this determinant?,"I'm doing a problem involving Cramer's rule, and one of the determinants I have to work with is as follows: \begin{vmatrix}
1&1&1\\
a&b&c\\
a^3&b^3&c^3
\end{vmatrix} So I started off by getting the matrix to a triangular matrix so I can just take the product of the diagonal cells by doing this: \begin{equation}
R_1 \times-c + R_2
\end{equation} \begin{equation}
R_3 \times -\frac{1}{c^3} + R_1
\end{equation} \begin{equation}
R_2 \times(\frac{1-\frac{b^3}{c^3}}{b-c})+R_1
\end{equation} I then got this matrix \begin{vmatrix}
((1-\frac{a^3}{c^3})-(a-c)(\frac{1-\frac{b^3}{c^3}}{b-c}))&0&0\\
a-c&b-c&0\\
a^3&b^3&c^3\\
\end{vmatrix} By summing the diagonal cells, I got this as a final answer: \begin{equation}
(c-a)(a-b)(b-c)(a+b+c)
\end{equation} However, it was a lengthy process, and I can't help but thinking this is not the type of calculations I can afford the time in a written exam, especially if I have to repeat this four times solving three linear equations with Cramer's rule. I'd really appreciate it if you have any thoughts as to speed this process up. Just as an added detail, the original question was (translated from Chinese): With regards to the following set of equations \begin{equation}
x + y + z = 1\\
ax + by + cz = d\\
a^3x + b^3y + c^3z = d^3
\end{equation} Under what conditions can Cramer's rule be used? Please solve the set of equations with Cramer's rule. For the first question, the immediate thought that pops up is that \begin{equation}
det(A) ≠ 0
\end{equation} For the second question, it's simply \begin{equation}
\frac{\begin{vmatrix}A_1\end{vmatrix}}{\begin{vmatrix}A\end{vmatrix}},
\frac{\begin{vmatrix}A_2\end{vmatrix}}{\begin{vmatrix}A\end{vmatrix}},
\frac{\begin{vmatrix}A_3\end{vmatrix}}{\begin{vmatrix}A\end{vmatrix}} 
\end{equation} which is the part I'm having trouble solving quickly. Again, appreciate any hints or thoughts on this. Thanks.","['linear-algebra', 'determinant']"
1069157,"If $p\equiv 1,9 \pmod{20}$ is a prime number, then there exist $a,b\in\mathbb{Z}$ such that $p=a^{2}+5b^{2}$.","I have to prove that if $p\equiv 1,9 \pmod{20}$ is a prime number then there exist $a,b\in\mathbb{Z}$ such that $p=a^{2}+5b^{2}$. I consider the quadratic field $\mathbb{Q}(\sqrt{-5})$, with ring of integers $A=\mathbb{Z}[\sqrt{-5}]$. It is easy to check that $\left (- \dfrac{5}{p} \right)=1$ if $p\equiv 1,9 \pmod {20}$. According to this, $t^{2}+5$ has two different roots in $\mathbb{F}_{p}$. In consequence, $pA=P_{1}P_{2}$ for certain prime ideals $P_{1}, P_{2}$ with norm $p$. A is not a PID, but if I prove that $P_{1}$ or $P_{2}$ are principal, then I had there exist $\gamma=a+b\sqrt{-5}\in A$ such that: $p=N(P_{i})=N(\gamma A)=|N_{\mathbb{Q}(\sqrt{-5})|\mathbb{Q}}(\gamma)|=a^{2}+5b^{2}$, and I would have finished. The problem is that I do not know how to prove this. If there is an easier way, please, let me know.","['algebraic-number-theory', 'number-theory']"
1069158,Defining median for discrete distribution,"In probability theory, a median of a probability distribution is a number $M$ such that the CDF of this distribution $F_\xi(x)$ satisfies $F_\xi(M)=\frac{1}{2} \tag1$ This works for continuous distributions, but for discrete distributions median would almost always be undefined if we were using this definition. How is it defined in the discrete case? Does it have similarity with $(1)$? To stress the difference from median of a set and illustrate my thoughts, the CDF looks something like this .","['definition', 'statistics', 'median', 'probability-distributions', 'probability']"
1069165,Probability coupon collection question - nth coupon is a new type?,"I'm just solving some probability problems in preparation for my exam, and I stumbled upon this one which I cannot tackle: Suppose that you continually collect coupons and
that there are $m$ different types. Suppose also that
each time a new coupon is obtained, it is a type
$i$ coupon with probability $p_i, i = 1, \ldots ,m$. Suppose
that you have just collected your $n$-th coupon. What
is the probability that it is a new type? Hint: Condition on the type of this coupon. Any help would be appreciated, thank you.","['probability', 'conditional-probability']"
1069187,Intersection of two circles.,"Let $C_1$ and $C_2$ be the circles: $\rho=a\sin\theta, \rho=a(\cos\theta + \sin\theta)$ respectively. The graphs of these two circles are From the graphs, we see that the intersection points are $(0,0)$, $(\pi/2, a)$. But when we solve the system of equations: $\rho=a\sin\theta, \rho=a(\cos\theta + \sin\theta)$, we obtain $(\theta, \rho)=(\pi/2, a)$ or $(-\pi/2, -a)$. $(\pi/2, a)$, $(-\pi/2, -a)$ are different from $(0,0)$, $(\pi/2, a)$. I am confused. Thank you very much.","['calculus', 'algebra-precalculus']"
1069189,bilinear maps with respect to noncommutative rings,"Consider a noncommutative ring with unity $R$, three left $R$-modules $M,N,P$ and a map $f\colon\;M\times N\to P$ such that: $
f(m+m',n)=f(m,n)+f(m',n)\\
f(m,n+n')=f(m,n)+f(m,n')\\
f(rm,n)=rf(m,n)=f(m,rn)
$ A map like this does exist: the null one. What about others? Can exist a non-null map satisfying those axioms? From the third point, given two scalars $r,s\in R$, it is evident that $(rs-sr)f(m,n)=0$ for all $m,n$ and this could be a problem given that $R$ is non-commutative.","['modules', 'noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
1069212,Inequality between $L^2$- and $L^1$-norms for functions,"In the vector space $\mathbb{R}^n$, we have the inequality
$$
||x||_2 \leq ||x||_1
$$
where $x$ is a vector. I am wondering that we have similar inequality for function's norm. The $L^1$-norm of function $f$ is given by
$$
||f||_1=\int |f| d\mu, 
$$
the $L^2$-norm is 
$$
||f||_2=\left( \int |f|^2 d\mu \right)^{1/2}
$$
then, is this right?
$$
||f||_2\leq ||f||_1
$$
If so, how to prove it? And tell me what I should study. e.g. real analysis or Lebesgue integral.","['functional-inequalities', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
1069233,Determinant bundle of a tensor product,"Let $X$ be a ringed space (for example, a scheme or a manifold). If $V$ is a locally free $\mathcal{O}_X$-module of rank $n$, then $\mathrm{det}(V) := \Lambda^n V$ is a locally free $\mathcal{O}_X$-module of rank $1$, called the determinant of $V$. Actually $\mathrm{det}$ is a functor. Now I wonder how to give a slick proof of the well-known (?) fact that there is a natural isomorphism
$$\mathrm{det}(V \otimes W) \cong \mathrm{det}(V)^{\otimes m} \otimes \mathrm{det}(W)^{\otimes n},$$
where $V$ is locally free of rank $n$ and $W$ is locally free of rank $m$. For this I would like to construct a map globally and basis-free and then show that it is an isomorphism locally, hence an isomorphism. A typical local generator of $\mathrm{det}(V \otimes W)= \Lambda^{n \times m}(V \otimes W)$ is
$$(v_{11} \otimes w_{11}) \wedge \dotsc \wedge (v_{1m} \otimes w_{1m}) \wedge \dotsc \wedge (v_{n1} \otimes w_{n1}) \wedge \dotsc \wedge (v_{nm} \otimes w_{nm}).$$
To which element of $\Lambda^n(V)^{\otimes m}  \otimes \Lambda^m(W)^{\otimes n}$ should we map this? Note that SE/571839 is a very similar question, but I would like to have an abstract proof like indicated in the last paragraph of the accepted answer.  (In fact, I want to prove a similar formula in an arbitrary cocomplete symmetric monoidal $\mathbb{Q}$-linear category, where $V$ is called locally free of rank $n$ if $\Lambda^n V$ is invertible and $\Lambda^{n+1} V = 0$. Here, no local bases are available.)","['vector-bundles', 'algebraic-geometry', 'commutative-algebra', 'exterior-algebra', 'determinant']"
1069278,Taylor approximation for $\ln(1.3)$,"I have to calculate an approximation for $\ln(1.3)$ using degree $2$ expansion for Taylor polynomial: $$P_2(x) = f(x_0) + f'(x_0)(x-x_0) + f''(x_0)(x-x_0)^2$$ So I can take $x_0 = 1$ and $x = 1.3$ right? Then I get $$P_2(1.3) = \ln(1) + \frac{1}{1}(1.3-1) - \frac{1}{1^2}(1.3-1)^2$$ which gives me $0.21$, but my book says $2.55$. What am I doing wrong?","['calculus', 'derivatives', 'taylor-expansion']"
1069284,Method for Counting the Divisors of a number,"I need to find the number of divisors of 600. Is there any other way to solve the problem, apart from writing them down and counting??","['elementary-number-theory', 'divisor-counting-function', 'combinatorics']"
1069320,If the dual unit ball of a normed space $X$ is metrizable in the weak-$*$ topology then $X$ is separable,"Let $X$ be a normed space and $(B_{X^*},w^*)$ be the unit ball of the dual space $X^*$ endowed with the weak-$*$ topology. Here is a proof a the fact that if $(B_{X^*},w^*)$ is metrizable then $X$ is separable : Set $K :=(B_{X^*},w^*)$. Since $K$ is metrizable we have that $C(K)$ -
  the space of continuous functions over $K$  - is separable (proved as
  a lemma). Consider the function $\Lambda : X \rightarrow C(K)$ defined
  by $x \mapsto \widehat{x}\big|_K$ where $\widehat{x}\big|_K(x^*) =
 x^*(x)$ for all $x \in X$. This function is well-defined and $$
 \big\|\widehat{x}\big|_K\big\|_\infty = \sup\big\{|x^*(x)| : x^* \in
> B_{X^*}\big\} = \|x\|$$ by Hahn-Banach. Hence $X$ is separable. I don't get why it should be obvious that $X$ is separable. Is the function $\Lambda$ onto ?","['general-topology', 'normed-spaces', 'functional-analysis']"
1069345,$A$ be a $10*10$ matrix with complex entries s.t. all eigenvalues are non negative real and at least one eigenvalue is positive.,"Let $A$ be a $10 \times 10$ matrix with complex entries s.t. all eigenvalues are non negative real and at least one eigenvalue is positive. Then which of the following statements is always false? A. there is  a matrix $B$ s.t. $AB-BA=B$ B.there is  a matrix $B$ s.t. $AB-BA=A$ C.there is  a matrix $B$ s.t. $AB+BA=A$ D.there is  a matrix $B$ s.t. $AB+BA=B$ I am new comer in Liner algebra. I have studied finite dimensional vector space, eigen value eigen vector from a book of G. Strang. I have found this in a competitive exam. I have no idea how to tackle this question. Can anybody help to solve this problem.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
1069347,"Stats probability addition rule, multination rule",The directions are to calculate the following probability based on drawing cards without replacement from a standard deck of 52. What is the probability of drawing a 2 or a king on the first draw and drawing a queen on the second draw?,"['statistics', 'probability']"
1069368,defining a topology by its compact sets,"The goal. Let $X$ be a set endowed with Hausdorff topologies $\tau_w$ and $\tau_n$, such that $\tau_w\subseteq\tau_n$.  Let $\mathscr{C}$ denote a family of subsets $A\subseteq X$, which satisfies the following properties. (i)  $\mathscr{C}$ is closed under arbitrary intersections and finite unions; (ii)  every $\tau_n$-compact set belongs to $\mathscr{C}$; and (iii)  every $A\in\mathscr{C}$ is $\tau_w$-compact. I would like to define a new topology $\tau_\mathscr{C}$ on $X$ which satisfies the following properties. (1)  $\tau_w\subseteq\tau_\mathscr{C}\subseteq\tau_n$; (2)  every $\tau_\mathscr{C}$ compact set belongs to $\mathscr{C}$; and (3)  every $A\in\mathscr{C}$ is $\tau_\mathscr{C}$-compact. Discussion. The obvious thing to try is to take the intersection $\tau_\cap$ of all topologies $\tau$ satisfying $\tau_w\subseteq\tau\subseteq\tau_n$ and for which every $\tau$-compact set belongs to $\mathscr{C}$.  However, it is far from obvious that $\tau_\cap$ would satisfy (2) or (3). Probably this is not possible in general.  However, we could assume that $X$ is a Banach space, $\tau_n$ is the norm topology, and $\tau_w$ is the weak topology.  We could also, if necessary, impose some additional assumptions on $\mathscr{C}$.","['general-topology', 'compactness', 'functional-analysis', 'banach-spaces']"
1069372,Show that $A \subseteq B$ if and only if every subset of A is a subset of B.,"Let $A$ and $B$ be sets. Show that $A \subseteq B$ if and only if every subset
of $A$ is a subset of $B$. So I know I have to prove this in both directions but this is what I got so far: If if every subset
of $A$ is a subset of $B$ then, $A \subseteq B$ . Let $U=$ be the union of all the subsets of $A$ Assume that $A\not\subseteq B$ by definition $U\not\subseteq B$ Then there exists an arbitrary subset of $U$ that is not a subset to $B$ by definition of subset negation Now we have shown that not every subset of $A$ is a subset of $B$ Similar the other way?",['elementary-set-theory']
1069376,Closed form of $\int_0^\infty \ln \left( \frac{x^2+2kx\cos b+k^2}{x^2+2kx\cos a+k^2}\right) \;\frac{\mathrm dx}{x}$,"Today I discussed the following integral in the chat room $$\int_0^\infty  \ln \left( \frac{x^2+2kx\cos b+k^2}{x^2+2kx\cos a+k^2}\right) \;\frac{\mathrm dx}{x}$$
  where $0\leq a, b\leq \pi$ and $k>0$. Some users suggested me that I can use Frullani's theorem: $$\int_0^\infty \frac{f(ax) - f(bx)}{x} = \big[f(0) - f(\infty)\big]\ln \left(\frac ab\right)$$
So I tried to work with that way.
\begin{align}   I&=\int_0^\infty  \ln \left( \frac{x^2+2kx\cos b+k^2}{x^2+2kx\cos a+k^2}\right) \;\frac{\mathrm dx}{x}\\   &=\int_0^\infty \frac{\ln \left( x^2+2kx\cos b+k^2\right)-\ln \left( x^2+2kx\cos a+k^2\right)}{x}\mathrm dx\tag{1}\\   &=\int_0^\infty \frac{\ln \left( 1+\dfrac{2k\cos b}{x}+\dfrac{k^2}{x^2}\right)-\ln \left( 1+\dfrac{2k\cos a}{x}+\dfrac{k^2}{x^2}\right)}{x}\mathrm dx\tag{2}\\   \end{align}
The issue arose from $(1)$ because $f(\infty)$ diverges and the same issue arose from $(2)$ because $f(0)$ diverges. I then tried to use D.U.I.S. by differentiating w.r.t. $k$, but it seemed no hope because WolframAlpha gave me this horrible form . Any idea? Any help would be appreciated. Thanks in advance.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
1069447,Extending a uniformly continous function to the closure of its domain,"Suppose $X$ is a normal space and $f:X \rightarrow X$ is continous on X, and also uniformly continuous on a subset $A \subseteq X$. In this setting, can one conclude that f is uniformly continuous on the  closure of $A$? If not, what about a metric space? Other families of spaces? I ask this question for the following case: Montel's Theorem in complex analysis states that a bounded sequence of holomorphic functions on an open set has a converging subsequence  (i.e, the set of bounded holomorphic functions is sequentially compact and thus compact). In the proof, one first shows that there is a subsequence that is uniformly continous on a dense subset, and than you extend it to the whole set. The proof of the last assertion heavily uses properties of holomorphic functions (cauchy's theorems and so on). However, it seems to me that it can be proved in a (much) more general case. Any ideas?","['general-topology', 'uniform-continuity']"
1069453,Reference request for studying on Fiber bundles,"I am looking for some material (e.g. references, books, notes) to get started with Fiber bundles and vector bundles. Can someone help me? 
Thanks.","['fiber-bundles', 'reference-request', 'differential-geometry']"
1069460,How many distinct values of floor(N/i) exists for i=1 to N.,"Say we have a function $F(i)=\text{floor}(N/i)$. Then how many distinct values of $F(i)$ will exist for all $0 \leq i \leq N$ e.g. We have $N=25$ then. $F(1)=25$ $F(2)=12$ $F(3)=8$ $F(4)=6$ $F(5)=5$ ... ... ... $F(24)=1$ $F(25)=1$ So total distinct values of $F(i)$ are $(N=25)$ :- $25, 12, 8, 6, 5, 4, 3, 2, 1$ total distinct values are $9$: $(2 \times 5-1)$ Can anyone please help in that total number of distinct values are $O(\sqrt{N})$?","['elementary-number-theory', 'functions', 'periodic-functions']"
1069467,How to sum up this series and simplify yet another one?,"Primarily, I would like to know what could be done with this series: $$    \sum_{n=2}^{\infty}\frac{n^3}{(n^2-1)^3}\left(\frac{n-1}{n+1}\right)^{2n}$$ As hardmath says in his comment, the series converges. I tried with Mathematica which gives for the sum 0.00526589. Is it possible to obtain some analytical result/approximation for the sum of the series? Moreover, I would like to simplify the following sum: $$ \sum_{n=2}^{\infty}\frac{(n-1)^{2n-3}}{n(n+1)^{2n+1}}\left[ \sum_{m=0}^{n-1}\left(\frac{n+1}{n-1}\right)^m\right]^2$$ Such sums appear in quantum mechanics when dealing with second order perturbation theory (the first mentioned case comes out when dealing with the Coulomb potential 1/r perturturbed by a k^2/r term). Any hints appreciated. Update:
As hardmath says in his comment, in the 
""second series the finite inner sum (over m) is geometric, so it can be replaced by an explicit expression in terms of n"". This means that we can simplify the double sum into a single one: $$ \frac1{4}\sum_{n=2}^{\infty}\frac1{n(n^2-1)}\left[1-2\left(\frac{n+1}{n-1}\right)^n+\left(\frac{n+1}{n-1}\right)^{2n}\right] $$ which is closer in form to the first mentioned.","['quantum-mechanics', 'summation', 'sequences-and-series']"
1069506,A problem with equality in a inequality for convex function,"Let $f:\rightarrow \mathbb R$ be a convex function on a convex subset $D$ of linear space $X$. Assume that for some pairwise disjoit $x_1,x_2,x_3\in D$  and some $t_1,t_2,t_3\in (0,1)$ such that $t_1+t_2+t_3=1$ the following equality holds:
$$
f(t_1x_1+t_2x_2+t_3x_3)=t_1f(x_1)+t_2f(x_2)+t_3f(x_3).
$$
Is it true that 
$$
f(s_1x_1+s_2x_2+s_3x_3)=s_1f(x_1)+s_2f(x_2)+s_3f(x_3)
$$
for all $s_1,s_2,s_3\in (0,1)$ such that $s_1+s_2+s_3=1$?
What does the last condition geometrically mean?","['convex-analysis', 'analysis']"
1069516,"How to solve linear, second order ODE with Frobenius method with a difficult recurrence relation?","The ODE in question is:
$$4xy''+2y'+y=0$$ Shifting the power series of each term so that they are all raised to the power $(n+r)$ will yield this recurrence relation:
$$a_{n+1}={a_n\over (n+r+1)(-2-4(n+r))}$$ with $$r=1/2, 0$$ If you plug values of $n$ into this recurrence relation it is nearly impossible to find a pattern for $a_n$, unless I'm missing something. Is there a way to continue to solve this ODE with the Frobenius method using this difficult recurrence relation, or any tricks to use earlier in the problem to avoid difficult recurrence relations?","['power-series', 'ordinary-differential-equations', 'pattern-recognition', 'recurrence-relations']"
