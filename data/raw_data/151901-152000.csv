question_id,title,body,tags
2540294,Geometric interpretations of the quotient rule and reciprocal rule.,"I have been reviewing basic calculus by working through Gilbert Strang's book ""Calculus"". My full time job is as a programmer, but I tutor calculus on the side. Professor Strang has kindly made the pdfs of the book, solutions manual, and study guide available for free . I understand his 'regular' proofs of the reciprocal rule, $$\frac{d}{{dx}}\left( {\frac{1}{{v\left( x \right)}}} \right) = \frac{{ - dv/dx}}{{{v^2}}}$$ and the quotient rule, $$\frac{d}{{dx}}\left( {\frac{{u\left( x \right)}}{{v\left( x \right)}}} \right) = \frac{{v\frac{{du}}{{dx}} - u\frac{{dv}}{{dx}}}}{{{v^2}}}$$ however... I'm struggling to understand what appears to be his informal geometric derivation of both of these rules from figure 2.14, pg  74: I know how to derive that $\frac{1}{{v + \Delta v}} - \frac{1}{v}$ is equal to $\frac{{ - \Delta v}}{{v\left( {v + \Delta v} \right)}}$ , and that $\frac{{u + \Delta u}}{{v + \Delta v}} - \frac{u}{v} = \frac{{v\Delta u - u\Delta v}}{{v\left( {v + \Delta v} \right)}}$ . I also know how to get from those equalities to the reciprocal rule and quotient rule. I just have not been able to figure out an intuitive way to understand the reciprocal rule and quotient rule geometrically from figure 2.14. I found a way to use figure 2.14 and geometry to derive $\frac{1}{{v + \Delta v}} - \frac{1}{v} = \frac{{ - \Delta v}}{{v\left( {v + \Delta v} \right)}}$ and $\frac{{ - \Delta v}}{{v\left( {v + \Delta v} \right)}}$ . I couldn't think of a geometric way to derive $\frac{{u + \Delta u}}{{v + \Delta v}} - \frac{u}{v} = \frac{{v\Delta u - u\Delta v}}{{v\left( {v + \Delta v} \right)}}$ . Basically, the best I was able to do for the numerator of the difference quotient for the reciprocal rule from figure 2.14 was show that a geometric derivation of that equation is consistent with the algebraic definition. Here's the best I could come up with, using a modified version of figure 2.14 that I made in paint: For the reciprocal rule (left side of the and its top equation). $$\text{Area}_{red - triangle} = \frac{{\Delta v}}{2}$$ $$\text{Area}_{blue - triangle} = \frac{v}{2}$$ $$\text{Area}_{red - triangle} + \text{Area}_{blue - triangle} = \frac{{v + \Delta v}}{2}$$ $$v + \Delta v = 2\left( {\text{Area}_{red - triangle}} + \text{Area}_{blue - triangle} \right)$$ $$v = 2\text{Area}_{blue - triangle}$$ $$\frac{1}{{v + \Delta v}} = \frac{1}{{2\left( {Are{a_{red - triangle}} + Are{a_{blue - triangle}}} \right)}}$$ $$\frac{1}{v} = \frac{1}{{2\text{Area}_{blue - triangle}}}$$ $$\frac{1}{{v + \Delta v}} = \frac{1}{{2\left( {Are{a_{red - triangle}} + Are{a_{blue - triangle}}} \right)}}$$ $$\frac{1}{{v + \Delta v}} - \frac{1}{v} = \frac{1}{2}\left( {\frac{{ - Are{a_{red - triangle}}}}{{\left( {Are{a_{red - triangle}} + Are{a_{blue - triangle}}} \right)Are{a_{blue - triangle}}}}} \right)$$ $$\frac{1}{{v + \Delta v}} - \frac{1}{v} = \frac{1}{2}\left[ {\frac{{ - \frac{{\Delta v}}{2}}}{{\left( {\frac{{v + \Delta v}}{2}} \right)\frac{v}{2}}}} \right] = \frac{{ - \Delta v}}{{\left( {v + \Delta v} \right)\frac{v}{2}}}$$ From there... I know how to derive the reciprocal rule... taking the limit of the difference quotient as $\Delta x \rightarrow 0$ Basically seems like circular reasoning... I assume that Professor Strang included the figure to give students an intuitive, geometric feel of the quotient rule and reciprocal rule, considering that Professor Strang's informal geometric derivation of the product rule is intuitive (also... why include figure 2.14 at all if it isn't meant to help readers gain an intuitive grasp of the reciprocal and quotient rules). The pdf of his textbook is in black and white, which makes figure 2.13 on page 72 difficult to read. Here is a re-creation of figure 2.13 that I put together using paint: And the product rule plus an informal proof of it:
If $u = u(x)$ and $v = v(x)$ (assuming u and v are differentiable functions of x): $$\frac{d}{{dx}}\left( {uv} \right) = u\frac{{dv}}{{dx}} + v\frac{{du}}{{dx}}$$ Informal 'proof': $$\frac{d}{{dx}}\left( {uv} \right) = \mathop {\lim }\limits_{h \to 0} \frac{{u\left( {x + h} \right)v\left( {x + h} \right) - u\left( x \right)v(x)}}{h}$$ As $h \to 0$ , $\Delta u \to 0{\text{ and }}\Delta v \to h$ From 'Calculus' by Gilbert Strang: The important change in area are the two strips $u \Delta v$ and $v \Delta u$ . The corner area $\Delta u \Delta v$ is much smaller. When we divide by $\Delta x$ (h), the strips give $u \frac{\Delta v}{\Delta x}$ and $v \frac{\Delta u}{\Delta x}$ . The corner gives $\Delta u \frac{Delta v}{\Delta x}$ , which approaches zero. The extra area comes from the whole side strip. I would greatly appreciate it if someone could help me figure out a better way to interpret figure 2.14. I know it isn't really essential for me to have an intuitive feel of the quotient rule or the reciprocal rule, however it drives me pretty crazy if I can't figure something out.","['derivatives', 'calculus']"
2540341,"If $f(x)$ is maximised, then when $x=1/2$ when is $g(x)=\frac{1}{1-x}f(x)$ maximised?","I have a function $f(x)$ that has a strict global maximum $x=1/2$ and $f(x)\rightarrow0$ as $x\rightarrow0, \infty^+$. Define $g(x)$ as follows: $$g(x)=\frac{1}{1-x}f(x)$$ Does $g(x)$ have a maximum at $x=0.5$? Hint: Given that $f(x)\rightarrow0$ as $x\rightarrow0, \infty^+$, $g(x)$ will have a maximum when $0<x<1$. Moreover,
$$\frac{dg(x)}{dx}=f'(x)\frac{1}{1-x}+f(x)\frac{1}{(1-x)^2}$$ Hence, 
$$g'(x)=0 \iff f'(x)\frac{1}{1-x}=-f(x)\frac{1}{(1-x)^2} \iff \frac{f'(x)}{f(x)}=-\frac{1}{(1-x)}$$ We also know that $f'(x)=0 \iff x=1/2$. I think this question cannot be answered since $f(0.4)$ may be $0.5-\epsilon$ and $g(0.4)$ may therefore be bigger than $g(0.5)$, it depends on $f'(x)$, which we do not know. Is this correct?","['derivatives', 'optimization', 'limits', 'functions', 'calculus']"
2540438,Non local functor covered by affine opens,"I've been reading Demazure and Gabriel to learn the functor of points approach to algebraic geometry.  They define a functor $X$ from commutative rings to sets as local if the standard sequence
$$X(R) \to \prod_{i \in I}X(R_{f_i}) \overset{\to}{\to} \prod_{\substack{i, j \in I \\ i \neq j}}X(R_{f_if_j})$$
is exact for each commutative ring $R$ and sequence $f_i$ generating the unit ideal.  My understanding is that this is the same as the sequence
$$\mathrm{Mor}(Y, X) \to \prod_{i \in I}\mathrm{Mor}(Y_i, X) \overset{\to}{\to} \prod_{\substack{i, j \in I \\ i \neq j}}\mathrm{Mor}(Y_i \cap Y_i, X)$$
being exact, where $Y$ is any functor with an open covering $Y_i$.  I'm happy using either definition. A scheme is a local functor that has a covering by affine open subfunctors.  As an example that the above condition is not trivial they suggest looking at the subfunctor $X \subseteq \mathrm{Gr}_{n, r}$ of the Grassmannian.  Where $\mathrm{Gr}_{n, r}(R)$ is the set of rank $n$ summands of $R^{n + r}$ they define $X(R)$ to be the set of free rank $n$ summands of $R^{n + r}$.  It's easy to see that the affine opens that cover $\mathrm{Gr}_{n, r}$ are actually subfunctors of $X$ and cover $X$, but Demazure and Gabriel claim that $X$ is not local whereas $\mathrm{Gr}_{n, r}$ is. I can't figure out why $X$ is not local.  Can anyone explain this to me, or alternatively give an example of a functor $X$ that is covered by affine open subfunctors but which is not local?","['category-theory', 'schemes', 'algebraic-geometry']"
2540447,Find the angles of the triangle if $∠BAC = 60°$ and $AB + BA' = AB' + BB'$.,"Let $AA′$ and $BB′$ be the bisectors of the angles $∠BAC$ and $∠ABC$ of the triangle $ABC$. Find the angles of the triangle if $∠BAC = 60°$ and $AB + BA' = AB' + BB'$. Hi, can anybody solve this problem for me? Thanks","['triangles', 'geometry']"
2540452,Understanding an equality in complex analysis,"Let C denote the segment from $z=i$ to $z=1$. I want to show that $|\int_C \dfrac{dz}{z^4}|≤4\sqrt(2)$ my attempt: I want to use the following theorem: Let $C$ denote a contour of length $L$, and suppose a function $f(z)$ is piecewise continuous on $C$. If $M$ is a constant s.t. $|f(z)|≤M$, then $\forall z$ in the interior of $C$ s.t. $f(z)$ is defined, then : $$|\int_C f(z)dz|≤ML$$ In our case,
$z=i+t(1-i) =t+i(1-t), 0≤t≤1$ therefore we cant quite minimize $|1/z^4|$ but we can minimize $|z^4|$. $|z^4| = \sqrt{\Big(t^2+(1-t)^2 \Big)^4} = \Big(t^2+(1-t)^2 \Big)^2 = (2t^2-2t+1)^2 = (*)$ $**$ This should be easy to minimize but I can't figure out how to do it $**$ Let's say $|z^4| ≤ N$,  $N$ some constant Once I've minimized (*), I can use the fact that $|{\Big(\dfrac{z_1}{z_2}\Big)|} = \dfrac{|{z_1}|}{|{z_2}|}$ to get that $|1/z^4| ≤ 1/N = M$ It's also easy to find $L=\sqrt{2}$ The question tells us that $N ≤ 1/4$ but I don't know how to prove that.",['complex-analysis']
2540453,Finding invariant measures (to solve recurrences),"INTRO: If you don't feel like reading the justification for my question, just skip down to the question. Some recurrence relations can be solved by finding invariants , or quantities that remain unchanged. For example, consider the sequences defined by
$$a_{n+1}=\frac{a_nb_n}{a_n+b_n+1}$$
$$b_{n+1}=a_n+b_n$$
$$a_0=b_0=-1$$
If one defines the function $\mu$ as
$$\mu (x,y)=x+xy+y$$
then it is easily proven that
$$\mu (x,y)=\mu\bigg(\frac{xy}{x+y+1}, x+y\bigg)$$
From this, it follows that
$$\mu (a_{n+1}, b_{n+1})=\mu (a_n,b_n)$$
and
$$\mu (a_n,b_n)=\mu(a_0,b_0)$$
$$\mu (a_n,b_n)=-1$$
$$a_n+a_nb_n+b_n=-1$$
$$a_n=\frac{-1-b_n}{1+b_n}$$
$$a_n=-1$$
and so
$$b_{n+1}=-1+b_n$$
$$b_{n+1}=b_n-1$$
...yielding explicit formulas for $a_n$ and $b_n$:
$$a_n=-1,\space\space\space b_n=-1-n$$ This was perhaps a trivial (and manufactured) example, but it demonstrates how invariants are used to solve recursions. QUESTION: I would like to know the following: what are some methods used to find invariants? That is, what methods might one use to find a particular nontrivial solution $\mu$ to the functional equation
$$\mu(x,y)=\mu(f(x,y),g(x,y))$$
where $f,g$ are given?","['invariance', 'recurrence-relations', 'sequences-and-series']"
2540465,Finding the angle between two functions,"I know that $\cos(\theta) = \frac{\langle f,g \rangle}{\|f\| \|g\|}$ for two functions $f$ and $g$. So, for two functions $x^n$ and $x^m$, $n \neq m$, on the interval $[-1,1]$ I want to find the angle between the two functions. Setting this up, I believe it would be $$\cos(\theta) = \frac{\int_{-1}^1x^nx^m\,dx}{(\int_{-1}^1|x^n|\,dx)(\int_{-1}^1|x^m|\,dx)}$$ Evaluating this, I seem to get a mess of $$\cos(\theta) = \frac{(1 + (-1)^{n+m})(n+1)(m+1)}{4n+4m+4}$$ which doesn't feel right. Am I overlooking something simple about this?","['real-analysis', 'integration', 'functions', 'inner-products']"
2540471,Volterra Operator Property,"It can be shown that if $V(f) = \int_0^x f(t)\,dt$ denotes the Volterra operator on $C([0,1])$, then the closed subspace $A_b = \{f : f|_{[0,b]} =0\}$ satisfies $ V(A_b) \subset A_b$, that is, $A_b$ is invariant under the Volterra operator. Is it true that $A(A_b) \subset A_b$ whenever $A$ is a bounded operator satisfying $AV=VA$? Edit: Here's a potential solution, however, I'm not sure how to bring it full circle. Any comments would be helpful! : ) Inductively we can show the following three properties:
$$
(i) \quad V x^m = \frac{x^{m+1}}{m+1}
$$
$$
(ii) \quad V^m e = \frac{x^m}{m!}
$$
$$
(iii) \quad V^m f(x) = (x^{m-1} \star f)(x),
$$
where $e \equiv 1$ on $[0,1]$.
Applying these observations to $A$, we see that $Ax^m = (x^m \star A e)'$, the derivative of the convolution. Given $f \in C[0,1]$ and $\epsilon>0$, we can find a polynomial $p(x) = \sum_{k=0}^ma_k x^k$ such that $||f-p|| < \epsilon/ \lambda$, where $\lambda > 0$ is a constant to be determined later. Then, by the triangle inequality, we must have 
$$
||Vf-Af|| \leq ||Vf-Vp|| + ||Af-Ap|| + ||Vp-Ap|| \leq (M_1+M_2) \epsilon + ||Vp-Ap||.
$$
The using linearity and a rule for differentiating a convolution, we get
$$
||Vp-Ap|| \leq m \max |a_k| ||Vx^k - Ax^k|| \leq M_3 ||V x^k - (kx^{k-1} \star Ae)||.
$$ My fight is with getting this very last estimate arbitrarily small.","['functional-analysis', 'compact-operators', 'operator-theory', 'analysis']"
2540475,definition of meromorphic function : it may have removable singularities,"I'd like to know about the definition of meromorphic function. Usually I see the definition of meromorphic function as follows:
Let $D\subset\mathbb C$ be a connected open set,  a function $f$ defined on a subset $U$ of $D$ and with value in $\mathbb C$ is meromorphic on $D$ if the following conditions are satisfied: $P(f)=D\setminus U$ is a set of poles $P(f)$ is discrete in $D$ $f$ is holomorphic on $U$. However, in the book "" Complex anlysis for mathematics and engineering"" by John H. Mathews and Russel W. Howeell, $P(f)=D\setminus U$ is a set of poles and removable singularities. I think removable singularities are not real singularities, since we can extend the function to the holomorphic function. Thus, two definitions may be almost same. I'd like to know how other people think about this question. Would you give any comments about this question? Thanks in advance!","['complex-analysis', 'meromorphic-functions']"
2540483,How to teach a kid geometry,"I found my kid more interested in shapes than numbers, adding 14 and 7 to get 21 is boring, while triangle, rectangle and heart shape is fun. But what could I introduce, besides the basic shapes, e.g. triangle, rectangle, parallelogram, diamond, circle, line, and angle? I couldn't really go on to Elements ; that will kill the interest. Any suggestion on how to keep the introduction basic and fun and still encourage some thinking?","['education', 'geometry']"
2540488,$\frac{(2n − 1)!!}{(2n)!!} \leq \frac{1}{\sqrt{2n+1}}$ by induction? [duplicate],"This question already has answers here : Induction and convergence of an inequality: $\frac{1\cdot3\cdot5\cdots(2n-1)}{2\cdot4\cdot6\cdots(2n)}\leq \frac{1}{\sqrt{2n+1}}$ (7 answers) Proving the inequality $\frac12\frac34....\frac{2n-1}{2n}<\frac1{\sqrt{2n+1}}$ (4 answers) Closed 6 years ago . Let $(2n)!!$ be the product of all positive even integers less than or equal to $2n$. Let $(2n − 1)!!$ be the product of all odd positive integers less than or equal to $(2n − 1)$. Prove that 
$$\frac{(2n − 1)!!}{(2n)!!} \leq \frac{1}{\sqrt{2n+1}}.$$
I am up to the inductive step, where am I stuck. I can't find a way to substitute in from the assumption because of the square root.","['algebra-precalculus', 'induction', 'factorial', 'products']"
2540520,Interior Product and Pullback Properties,"Let $f:M\rightarrow N$ a diffeomorfism between differentiable manifolds. $X$ is a $C^{\infty}$ vector field over N. If $\omega \in \Omega^{k}(N)$.    (i.e. $\omega$ is a $k$ - form), prove that $$f^{\ast}(i_X \;\omega)=i_{f^{\ast} X}f^{\ast}\omega $$
where $f^{\ast} $ denotes the pullback, and $i_X$ denotes interior derivative (or interior product). My attempt is to use the fact with exterior derivative $d$; because I know that $d(f^{\ast} \omega)= f^{\ast}(d\omega)$. I don't know if there is a relationship between interior and exterior derivative that helps me prove my proposition.","['smooth-manifolds', 'differential-forms', 'pullback', 'manifolds', 'differential-geometry']"
2540528,Finding defining polynomial of a relative number field extension,"Say I have some number field $K_1/\mathbb{Q}$ defined as:
$$K_1 \cong \mathbb{Q}[x]/\langle f(x)\rangle$$
for some irreducible (monic, if this makes things easier) polynomial $f(x)$.
Now, let $g(x)\in K_1[x]$ be an irreducible (monic) polynomial over $K_1$.  I can then define the relative field extension $K_2$ as:
$$K_2\cong K_1[x]/\langle g(x)\rangle$$ Now, $K_2/K_1/\mathbb{Q}$ is a tower of field extensions, but we can view $K_2/\mathbb{Q}$ directly as a number field. How can I go about finding the defining polynomial of $K_2$ over $\mathbb{Q}$?
By this, I mean the irreducible (monic) polynomial $h(x)\in\mathbb{Q}[x]$ such that:
$$K_2\cong \mathbb{Q}[x]/\langle h(x)\rangle$$","['number-theory', 'extension-field', 'algebraic-number-theory']"
2540552,Need a hint for an expected value problem,"You are allowed to write positive integers from 1 to 100 on 100 cards, you the show the 100 cards to a friend who will pick a number. You then shuffle the deck and flip off the top card. If the top card was the number your friend selected you pay him that number. Assuming your friend picks the number to maximize his expected value what numbers do you place on each of the 100 cards to minimize his expected value My strategy was to start from the highest number we can place in the deck and go down. For example we can't place a hundred in the deck because this would give an expected value of 1 if the friend picked 100, but this isn't giving me much progress. Any suggestions are appreciated","['expectation', 'probability']"
2540555,What functions can be characteristic functions of real-valued random variables?,"For a real-valued random variable $X$, the characteristic function $\phi \colon \mathbb{R} \to \mathbb{C}$ is defined as
$$\phi(t) = \mathbb{E}[e^{itX}].$$
One can check that $\phi$ satisfies $\phi(0) = 1$, $\phi$ is uniformly continuous, $\phi(t) \to 0$ as $|t| \to \infty$. Conversely, if we have a $\phi$ satisfying these three properties, is there a distribution with characteristic functions $\phi$? In my specific case, I have a $\phi \in C^\infty \cap L^1 \cap L^\infty$.",['probability-theory']
2540617,Birthday problem with at least 3 people,"Question: whats the probability that at least 3 out of a group of n people have the same birthday. I am confused as to where to start. I know that it would be complementary probability, but even then I dont know exactly. 
Would it be; P(at least 3 have the same bday) = 1 - (|all 3 have different| + (2 have the same|)?
Any directions and suggestions?","['birthday', 'discrete-mathematics']"
2540625,is taking the transpose of a matrix a continuous operation [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Suppose $\{A_i\}_{i=1}^{\infty}$ is a sequence of matrices with $\lim_{i\to\infty}A_i= B$. Then does  $\lim_{i\to \infty}A_i^\top= B^\top$ if we measure distances between matrices with a 2-norm?,"['matrices', 'continuity', 'linear-algebra']"
2540629,How to find critical points when you get constant value,"To find these critical points you must first take the derivative of the function. Second, set that derivative equal to 0 and solve for x. Each x value you find is known as a critical number. But what happens if you take derivative and you get a constant value like -1?","['derivatives', 'calculus']"
2540653,Describing equivalence classes and finding the quotient for a relation.,"The set $A = \mathbb{R} \times \mathbb{R}. (x_1,y_1) \sim (x_2,y_2)$ if $x^2_1+y^2_1 = x^2_2+y^2_2$. I need some help describing the equivalence classes and describing all elements in $A/{\sim}$. Any help in describing how to figure out this would be really helpful. Thanks :)","['equivalence-relations', 'relations', 'discrete-mathematics']"
2540677,Finding value of $c+d$,"At a point $A(1,1)$ on the ellipse , equation of tangent is $y=x.$ If one of the foci of the ellipse is $(0,-2)$ and coordinate of center of ellipse is $(c,d)$ . Then find value of $c+d$ (given length of major axis is $4\sqrt{10} unit$ ) Attempt : assuming one foci is at $S_{1}(0,-2)$ and other is at $S_{2}(\alpha,\beta)$ and $A(1,1)$ be a point on ellipse. then $AS_{1}+AS_{2} = 4\sqrt{2}$ $\sqrt{10}+\sqrt{(1-\alpha)^2+(1-\beta)^2} = 4\sqrt{2}$ could some help me to solve it , thanks","['conic-sections', 'geometry']"
2540758,An example of a non-commutative ring with multiplicative identity 1 in which the only (two sided) ideals are 0 and the whole ring,"Is there any example of a non-commutative ring with 1 in which the only ideals are (0) and the whole ring, yet the elements do not have multiplicative inverses? I thought an example of all 2x2 matrices with entries from any fields (like R, the real number), and it is clearly that not all of them are invertible, thus do not have multiplicative inverses, but how do I show the ideals are only (0) and the whole ring? Thank you so much!","['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'ideals']"
2540771,A finite group is nilpotent iff two elements with relatively prime order commute,"(Question 9 in chapter 6.1 of Dummit and Foote). Prove that a finite group G is nilpotent if and only if whenever $a, b \in G$ with $(|a|, |b|) = 1$ then $ab = ba$. It says to use the following theorem: Let G be a finite group, $p_1$, $p_2$, ... $p_s$ be the distinct primes dividing its order, and $P_i \in Syl_{p_i}(G)$. Then G is nilpotent iff $G \cong P_1 \times P_2 \times ... P_s$. I believe I know the if direction: an element $a \in G$ corresponds to an element $(g_1, g_2, ... g_s) \in P_1 \times P_2 \times ... P_s$ and $|a| = lcm(|g_1|, |g_2|, ... |g_s|)$. If $b$ corresponds to $(h_1, h_2, ... h_s)$ then $(|a|, |b|) = 1$ implies each $(|g_i|, |h_i|) = 1$. Since the order of the elements divides $|P_i|$ a prime power, $|g_i|$ or $|h_i|$ has to be 1 or their gcd would not be 1. So one of every pair $g_i$ and $h_i$ has to be 1, so they commute, so $a$ and $b$ commute. I'm not sure how to do the only if direction. Any pointers? Thank you","['finite-groups', 'sylow-theory', 'group-theory']"
2540791,Isn't the Martingale betting system completely rational?,"https://en.wikipedia.org/wiki/Martingale_(betting_system) I don't think it's based on gambler's fallacy. Suppose I have $1+2+4+8+.....+2^{9}=1023$ Dollars. I'm about to bet on heads in the tosses of a fair coin. If the coin lands heads, I receive an amount double my bet (my original bet + profit equal to my original bet) My strategy will be: 1.Bet 1 Dollar on the first toss. 2.Double my bet on each successive toss. 3.Walk away on my first win. So, all the possible outcomes are:
$$H, TH, TTH, TTTH, TTTTH, TTTTTH, TTTTTTH, TTTTTTTH, TTTTTTTTH, TTTTTTTTTH, TTTTTTTTTT$$ I end up making a 1 dollar profit in the first 10 of these outcomes. Only in the last case I lose 1023 dollars. But it would take a miracle for $TTTTTTTTTT$ to happen with a fair coin. I know that the expected value is negative but the expected value comes into play only when I keep on betting till the end of time. My strategy is to walk away on the first win. So, before I begin to bet, isn't it reasonable for me to believe that I'll most likely make a profit?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2540806,$\mathbb{R}^n$ not homeomorphic to open subset of $\mathbb{R}^m$,"I am a little confused on this topic, I have managed to prove that if $n < m$ then this is true, but the proof does not seem to work if $m < n$. Indeed, if $n < m$ and $f :\mathbb{R}^n \to U$ is a homeomorphism  with $U$ being an open subset of $\mathbb{R}^m$, then $\mathbb{R}^n$ will also be homeomorphic to the subset of $\mathbb{R}^m$ consisting of tuples where the last $m-n$ entries are zero, this set $A$ is closed, and so we have an homeomorphism $F: U \to A$, but since $U$ is open so must $A$ be by the invariance of domain theorem, but $A$ can't be both close and open since the only such sets in $\mathbb{R}^m$ is the empty set and $\mathbb{R}^m$ itself, contradiction. But what if $m < n$? This proof does not seem to work then?","['algebraic-topology', 'general-topology']"
2540827,"What makes a Riemannian manifold ""directionally homogeneous""?","Consider the three Riemannian 2-manifolds: Euclidean plane, 2-sphere and Poincaré disk. Each of them has the following property (D): For any point $p$ on the surface $S$ and any two unit tangent vectors $v,w\in T_pS$, there exists an isometry $f:S\to S$ such that $f(p)=p$ and the pushforward $(f_*)_p:T_pS\to T_pS$ sends $v$ to $w$. This property is not seen in arbitrary smooth Riemannian 2-manifolds. For instance, consider the infinite cylinder $S=\{(x,y,z)\in\Bbb R^3:x^2+y^2=1\}$ with metric inherited from $\Bbb R^3$. Even though the space is homogeneous in the sense that for any two points $p_1,p_2\in S$, there exists an isometry $f:S\to S$ sending $p_1$ to $p_2$, there is no isometry whose pushfoward sends a unit tangent vector that goes horizontally (along the direction of $xy$-plane) to a unit tangent vector that goes vertically (parallel the direction of $z$-axis). If there is, such an isometry would send a horizontal circle on $S$ (which is a geodesic generated by a horizontal tangent vector) to a vertical line on $S$ (which is a geodesic generated by a vertical tangent vector), and this is absurd. On the cylinder, directions at a point are not ""equal"" to each other, and I say the cylinder is not ""directionally homogeneous"". So what are some necessary and/or sufficient conditions for a smooth Riemannian manifold to have property (D)? Please note that I have only taken a course on differential geometry at the level of do Carmo's Differential Geometry of Curves and Surfaces .","['riemannian-geometry', 'differential-geometry']"
2540914,A pure algebraic proof for: Any unirational surface over $\mathbb{C}$ is rational.,"Let $k$ be an algebraically closed field of characteristic zero (for example, $k=\mathbb{C}$).
Let $L$ be a field such that $k \subset L \subset k(x,y)$ 
and $L$ is of transcendence degree two over $k$. 
Then there exist $h_1,h_2 \in k(x,y)$ such that $L=k(h_1,h_2)$. This seems a known result in algebraic geometry, according to the comments in this question (especially the last one). Please: (1) Is there a pure algebraic proof for this result? (2) Is it possible to find $h_1,h_2 \in k[x,y]$? The motivation is the following result: If $k \subset L \subset k(x,y)$ is of transcendence
  degree one over $k$, then $L=k(h)$, where $h \in k[x,y]$; see the answer to this question . Thank you very much! Edit: (1) Wikipedia only brings the algebraic geometry terminology. 
Also, this notes talk in algebraic geometry terminology (except for the first chapter). (2) This question is relevant.","['abstract-algebra', 'field-theory', 'algebraic-geometry', 'commutative-algebra']"
2540947,Can this definite integral involving series be solved without a calculator?,"I got this question today but I can't see if there is any good way to solve it by hand. Evaluate the definite integral $$\int_2^{12}\frac{\sqrt{x+\sqrt{x+\sqrt{x+...}}}}{\sqrt{x\sqrt{x\sqrt{x}...}}}\,\mathrm{d}x$$ where the series in the numerator and denominator continue infinitely. If you let $y=\sqrt{x+\sqrt{x+\sqrt{x+...}}}=\sqrt{x+y}$ , solving for $y$ we get $y=\frac{1\pm\sqrt{1+4x}}{2}$ . And similarly for the denominator we have $z=\sqrt{xz}$ . So $z=x$ . So the integral simplifies to $$\int_2^{12}\frac{1\pm\sqrt{1+4x}}{2x}\,\mathrm{d}x\,.$$ Now my problems are I don't know what to with the $\pm$ . I tried to solve the integral by separating it as a sum of two fractions. But I can't solve $$\int_2^{12}\frac{\sqrt{1+4x}}{2x}\,\mathrm{d}x\,.$$","['integration', 'definite-integrals', 'calculus']"
2540965,No simple group of order 4400,"Burnside proved, by use of character theory, that if a finite group $G$ has a conjugacy class $C$ such that $\vert C \vert$ is a prime power $> 1$, then $G$ is not simple. Let us call this statement ""Burnside's non-simplicity theorem"". Let $G$ be a group of order $4400$. Let $n_{5}(G)$ denote the number of Sylow $5$-subgroups of $G$. In a proof that G is not simple, W.R. Scott (12.3.5, p. 335) uses  Burnside's non-simplicity theorem, and thus character theory (since Scott proves Burnside's non-simplicity theorem by use of character theory), in the case where $n_{5}(G) = 11$. He settles the other cases without character theory. In fact, if I'm not wrong, it is not very difficult to avoid character theory, by use of the following lemma: (Edit : the following lemma is the result of an improvement made by j.p. to my initial formulation.) Lemma. Let $H$ be a finite group, let $p$ be a prime divisor of  $\vert H \vert$. Let $n_{p}(H)$ denote the number of Sylow $p$-subgroups of $H$. Assume that 1° $n_{p}(H)$ is the least divisor $d$ of $\vert H \vert$ such that $d > 1$ and $d \equiv 1 \pmod{p}$; 2°  $n_{p}(H) \not\equiv 1 \pmod{p^{r}}$, where $p^{r}$ denotes the greatest power of $p$ that divides $\vert H \vert$ (in other words, $p^{r}$ is the order of the Sylow $p$-subgroups of $H$). Then $H$ is not simple. Proof. In view of a strong form of the Sylow congruence theorem, we conclude from hypothesis 2° that we can choose two distinct Sylow $p$-subgroups of $H$, say $P$ and $Q$, such that $P \cap Q > 1$.
We may additionally assume that $P\cap Q$ is maximal among the intersection of two Sylow $p$-subgroups. Let $N:=N_H(P\cap Q)$ be the normalizer of this intersection in $H$. As $P$ and $Q$ are (finite) $p$-groups, $N\cap P$ and $N\cap Q$ both properly contain $P\cap Q$. $N\cap P$ and $N\cap Q$ are contained in Sylow $p$-subgroups $P'$ rsp. $Q'$ of $N$, which in turn are contained in Sylow $p$-subgroups $P''$ rsp. $Q''$ of $H$.
By maximality of $P\cap Q$ we get $P=P''$ and $Q=Q''$ and hence that $N\cap P = P'$ and $N\cap Q = Q'$ are (different) Sylow $p$-subgroups of $N$,
thus $N$ has more than one Sylow $p$-subgroup. On the other hand, by Sylow theorems, the number of Sylow $p$-subgroups of $N$ is $\equiv 1 \pmod{p}$ and divides $\vert N\vert$, which divides $\vert H \vert$. Thus the number of Sylow $p$-subgroups of $N$ is $> 1$, is $\equiv 1 \pmod{p}$ and divides  $\vert H \vert$. By minimality of $n_{p}(H)$ (hypothesis 1°), (*) the number of Sylow $p$-subgroups of $N$ is $\geq n_{p}(H)$. As $P\cap Q$ is normal in $N$, every Sylow $p$-subgroup of $N$ contains $P\cap Q$. But, as by the maximality of $P\cap Q$ every Sylow $p$-subgroup of $N$ is contained in a unique different Sylow $p$-subgroup of $H$, by (*) every Sylow $p$-subgroup of $H$ contains some Sylow $p$-subgroup of $N$, and hence $P\cap Q$. Thus the intersection of all Sylow $p$-subgroups of $H$, which is a normal subgroup, is non-trivial, and thus $H$ is not simple. Applying this lemma with $H = G$ (where $\vert G \vert = 4400$) and $p = 5$, we find that if $n_{5}(G) = 11$, then $G$ is not simple. Thus, in each case, it can be proved without character theory that a group of order $4400$ is not simple. In exerc. 12.3.10, p. 337, W.R. Scott asks for a proof that there are no simple groups of order $1200$, $2240$ or $2800$. I presume that use of Burnside's non-simplicity theorem is expected, but here again, if I'm not wrong, character theory can be skipped. My question is : do you know a nonzero natural number $n$ with at least $3$ distinct prime factors such that (i) it is relatively easy to prove that there is no simple group of order $n$ with use of  Burnside's non-simplicity theorem; (ii) it is not easy to prove it without Burnside's non-simplicity theorem and without character theory ? Thanks in advance for the answers.","['finite-groups', 'group-theory']"
2540992,Sequence of positive integers.,An infinite sequence of increasing positive integers is given with bounded first differences. Prove that there are elements $a$ and $b$ in the sequence such that $\dfrac{a}{b}$ is a positive integer. I think maybe computing the Natural Density of the sequence would lead to some contradiction. But don't know if it exists. Any help will be appreciated. Thanks.,"['analytic-number-theory', 'sequences-and-series', 'elementary-number-theory']"
2541044,Sleeping beauty problem and Monty Hall paradox,"I read this argument on the internet about how the solution to the sleeping beauty problem is $\frac{1}{3}$: All these events are equally likely in the experiment : Coin landed Heads, it's Monday and Beauty is awake Coin landed Heads, it's Tuesday and Beauty is asleep Coin landed Tails, it's Monday and Beauty is awake Coin landed Tails, it's Tuesday and Beauty is awake All these are mutually exclusive and exhaustive and also equally likely. So, all four of these events have a probability $\frac{1}{4}$. But when Beauty is awakened, she knows that she isn't asleep. So, the second possibility can be ruled out. The rest three are still equally likely with a probability $\frac{1}{3}$. Hence the probability that the coin landed Heads is $\frac{1}{3}$. But I remember something from the Monty Hall problem and this situation looks somewhat similar. The solution assumes that when possibility no. 2 is ruled out, the remaining three remain equally likely. This doesn't happen in the Monty Hall problem. For example, there are 100 doors. A prize is behind one of them. Clearly, all the doors are equally likely to have the prize. We pick one random door. The probability that it has the prize is $\frac{1}{100}$. The probability that the prize is in one of the remaining doors is $\frac{99}{100}$. When doors from the set of remaining 99 doors are ruled out one by one, all the doors no longer remain equally likely. Our door still has the probability $\frac{1}{100}$ while the group of remaining doors still hold a  probability of $\frac{99}{100}$. Could this be true for the Sleeping Beauty Problem too? I mean the possibilities 1. and 2. that I've listed collectively hold a probability of $\frac{1}{2}$ and even when possibility no.2 is ruled out, it's probability gets transferred to possibility no.1, so that it still has a probability of $\frac{1}{2}$. EDIT: Suppose Beauty is the contestant on the Monty Hall Show. She is presented four doors in front of her, A, B, C, D. Clearly, all the door currently have a winning probability of $\frac{1}{4}$. But she knows that before the prize was put behind one of the doors, a coin was tossed. If it landed heads, the prize was placed in one of the doors A or B and in case it was tails, the prize was put in C or D. Beauty knows this. Now, the host rules out door B as a possibility (which is equivalent to Beauty ruling out possibility 2). Do the doors A, C and D remain equally likely to have the prize or is it safer to choose A? I think it's safer to choose A because either you can assume the coin landed tails and further burden yourself in choosing between C and D or you can assume the coin landed heads and then choose A, the only remaining Heads door.","['probability-theory', 'monty-hall', 'probability']"
2541078,Evaluate $\lim_{x \to 0} \frac{1-(x^2/2) -\cos (x/(1-x^2))}{x^4}$,find the limits with Using : $\lim_{x \to 0} \frac{1-\cos x}{x^2}=\frac12$ $$\lim_{x \to 0} \frac{1-\dfrac{x^2}2-\cos (\dfrac{x}{1-x^2})}{x^4}$$ My Try : $$\lim_{x \to 0} \frac{1-\dfrac{x^2}2-\cos (\dfrac{x}{1-x^2})}{x^4}=\lim_{x \to 0} \frac{(1-\cos (\dfrac{x}{1-x^2}))+(-\dfrac{x^2}2)}{x^4}$$ $$\lim_{x \to 0} \frac{(\dfrac{(1-\cos (\dfrac{x}{1-x^2}))}{(\dfrac{x}{1-x^2})^2})(\dfrac{x}{1-x^2})^2+(-\dfrac{x^2}2)}{x^4}$$ now what ?,"['limits-without-lhopital', 'limits']"
2541093,"Bags, probability and recurrence","I need help on this one: There are two bags, each of them contain $n$ balls. The first bag contains only white balls. The second bag contains only black balls. Pick one black ball and input it to first bag. Then choose one ball from first bag randomly and and throw out it. Repeat this process while second bag is not empty. Question: What is probability that last selected ball from first bag is white? I guess there are some recurrence formula for this probability...","['combinatorics', 'recurrence-relations', 'probability']"
2541094,$\lim_{x \to x_0}{\frac{\arcsin x-\arcsin x_0}{x-x_0}}=?$ [duplicate],"This question already has answers here : question about the limit $\lim_{h\to0}\frac{\arcsin(x+h)-\arcsin(x)}{h}$ (4 answers) Closed 6 years ago . I have the following problem: $$
\lim_{x \to x_0}{\frac{\arcsin x-\arcsin x_0}{x-x_0}}=\text{?}
$$ What I have: Let $x=\sin t$. Then the problem becomes: $$
\lim_{t \to t_0}{\frac{t-t_0}{\sin t-\sin t_0}} = \lim_{t \to t_0}{\frac{\frac{t-t_0}{2}}{\sin (\frac{t-t_0}{2}) \cos{\frac{t+t_0}{2}}}}=\lim_{t \to t_0}{\frac{1}{\cos(\frac{t+t_0}{2})}}=\frac{1}{\sqrt{1-\sin^2(t_0)}}
$$ So I'm kind of stuck here. I'm not very good with trigonometric formulas. Assuming so far the solution is correct, how do I continue from here? Thanks in advance!","['real-analysis', 'trigonometry', 'limits']"
2541101,"A strange norm in the polynomial space $\mathbb{P}[0,1]$. A contradiction?","Let us define a norm $\|f\|=\sup_{k\geq 0}\sup_{t\in [0,1]}|f^{(k)}(t)|$. It is easy to see that in the polynomial space $\mathbb{P}[0,1]$ space, the norm $\|\|$ is well-defined. What is the dimension of the completion of $(\mathbb{P}[0,1],\|\|)$ under this norm ? It seems to be finite dimensional, because one can show that the unit ball in this new Banach space $X$ is compact as follows: We only need to show that every bounded sequence $\{f_n\}$ in $X$ has a convergent subsequence. That is a repeated application of the Ascoli-Arzelà theorem and Cantor's diagonal argument; the boundedness of $\{f^{(k+1)}_n\}$ implies the equicontinuity of $\{ f^{(k)}_n\}$. For details of this argument, we can refer to Is there no norm in $C^\infty ([a,b])$? Since it is a normed space with Montel-Heine-Borel property, it has to be finite dimensional. On the other hand,  $\mathbb{P}[0,1]$ is already infinite dimensional. Then $X$ has to be at least infinite dimensional. Something must be wrong. references: Every normed space has a completion?","['functional-analysis', 'fake-proofs']"
2541131,Closed form of $ S = \sum_{n=1}^{99} \frac{(5)^{100}}{(25)^{n} + (5)^{100}}$,"$$ S =  \sum_{n=1}^{99} \frac{(5)^{100}}{(25)^{n} + (5)^{100}}$$ I tried writing first and end terms to make a similar face in the denominator, but in vain. The denominators are getting same in alternate terms.
I tried adding and subtracting by 1 to look after a v(n) and v(n-1) pair of terms also, but that just isn't anywhere near.","['summation', 'sequences-and-series']"
2541155,Bounded variation of $\frac1f$ when $\inf(|f|)>0$ & $f$ bounded variation,"I want to show if  $\frac{1}{f}\in BV[a,b]$ when $\inf(|f|)>0 \land  f\in BV[a,b]$. I tried to find a partition that $V(\frac{1}{f},P)$ is upper-bounded using the partition that makes $V(f,P)$ upper-bounded in which I failed. (in case $f$ is not continuous which is countable..) Showing by subtraction of two increasing functions also seems hard. Hope if someone can help me or give me a hint. Thank you.","['real-analysis', 'partitions-for-integration', 'analysis', 'bounded-variation']"
2541202,Show that $\tan^{-1} (\tfrac{1}{8} ) \geq \frac{1}{\sqrt{65}} $,"Here I'd like to check that: $$ \frac{1}{8} \geq \tan^{-1} (\tfrac{1}{8} ) \geq \frac{1}{\sqrt{65}} $$ The numbers do check out if one uses a calculator.  They were using the Taylor series: $\frac{1}{\sqrt{65}} \;\;\;\;\;= 0.12403 $ $\tan^{-1} \frac{1}{8} = 0.12435 $ $\frac{1}{8} = 0.125$ The Taylor series for tangent could lead to an approximation. If $0 < x < \frac{\pi}{4}$ I believe we have:
$$ x - \frac{x^3}{3} < \tan^{-1} x <  x  $$
I do not recommend either of these, as a first recourse, but it came up in discussion last time. These numbers might be somewhat mysterious (and they are). I got these using complex numbers.  I said that:
\begin{eqnarray*}
5 &=& 1^2 + 2^2 \\
13 &=& 2^2 + 3^2
\end{eqnarray*}
And there are angles associated to these sum of squares $\theta_5 = \tan^{-1} \frac{1}{2}$ and $\theta_{13} = \tan^{-1} \frac{2}{3} $
then, using the difference of arctangents formula:
$$ \tan^{-1} \frac{2}{3} - \tan^{-1} \frac{1}{2} = \tan^{-1} \left[
\frac{ \frac{2}{3} - \frac{1}{2}}{1 + \frac{2}{3} \times \frac{1}{2}} \right] = \tan^{-1} \tfrac{1}{8}$$
and this leads to the left side inequalty above.","['trigonometry', 'complex-numbers']"
2541217,Fourier Transform of the product between a L1 function and a distribution,"Let us define the real functions $f_a(t)=\begin{cases}
				1 & \text{ if } t \in \left[-a;a\right] \\
				0 & \text{ else}
			\end{cases}$
and 
$g_{a;b}(t)=\begin{cases}
				\cos\left(2\pi bt\right) & \text{ if } t \in \left[-a;a\right] \\
				0 & \text{ else}
			\end{cases}$. Since $g_{a;b}\in L^1(\mathbb{R})$, we can compute the Fourier Transform of $g_{a;b}$, and we obtain $\mathcal{F}(g)=2a.\operatorname{sinc}(2\pi a(x-b) ) + 2a.\operatorname{sinc}(2\pi a(x+b))$. We can notice that this transformation is also the convolution product between a distribution and a function in $\mathcal{C}^\infty(\mathbb{R})$:
$2a.\operatorname{sinc}(2\pi a(x-b) ) + 2a.\operatorname{sinc}(2\pi a(x+b))= 
<\delta_b+\delta_{-b};y\mapsto2a.\operatorname{sinc}(2\pi a(x-y) )>_y= (\delta_b+\delta_{-b}) \ast 2a.\operatorname{sinc}(2\pi a\ \cdot) = (\delta_b+\delta_{-b}) \ast \mathcal(F)(f_{a;b}) $ We also, know that the Dirac distribution is linked to the regular distibution associated to the cosine function by $\mathcal{F}T_{\cos(2\pi b\ \cdot)}=\delta_b+\delta_{-b}$. Therefore, I wander if there is a proper way to obtain the Fourier Transform of $g_{a;b}$ by using the distribution theory? Maybe there is a theorem for a the product of a function in $L^1(\mathbb{R})$ (I mean $f_{a;b}$) and a distribution. I know one between a Schwartz's function and a tempered distribution, but $f_{a;b}\notin\mathcal{S}(\mathbb{R})$.","['functional-analysis', 'distribution-theory', 'fourier-transform']"
2541222,Compute integral $\int_{-\infty}^{\infty}\frac{e^{-ixt}}{\sqrt{1+x^2}} dx$,"How to compute integral $\int_{-\infty}^{\infty}\frac{e^{-ixt}}{\sqrt{1+x^2}}dx$, which is the Fourier transform of $f(x)= \frac{1}{\sqrt{1+x^2}}$?
We already know that we can get the Fourier transform of $\frac{1}{(1+x^2)^2}$ by using the convolution theorem linked-to result .\
Now the question is that can we apply the same for  $f(x)= \frac{1}{\sqrt{1+x^2}}$? And how?
Thanks!","['complex-analysis', 'real-analysis', 'integration', 'fourier-analysis']"
2541249,Showing quotient group operations are well defined,"The book I am reading has the proves the following theorem: Let $G$ be a group and let $H$ be a normal subgroup of $G$. The set $G/H= (aH | a \in G)$ is a group under the operation $(aH)(bH) = abH$. The first step they show is that: $$f: G/H \times G/H \rightarrow G/H \\ aH * bH \mapsto abH$$
is well defined. I tried this verification myself, but its a little different from the one in my book. I wanted to know if it was correct: To check if $f$ is well defined, we consider the following two mappings:
  $$aH * bH \mapsto abH \\ a'H * b'H \mapsto a'b'H$$
  If $aH=a'H$ and $bH=b'H$ then we want $abH=ab'H$. So suppose $aH=a'H$ and $bH=b'H$. Then $aH * bH = a'H * b'H = a'b'H$. We also know $aH * bH=abH$. Thus when $aH=a'H$ and $bH=b'H$, it follows $abH=a'b'H$. Is this correct?","['group-theory', 'functions', 'quotient-group']"
2541293,Calculating Probability of Die Rolls with a single reroll,"I am trying to figure out the odds of success for this problem, but keep running into issues around the ability to reroll one die. Scenario:  I am making two rolls of special dice.  I am allowed to reroll one die in the first set, and in total I need 3 ""successes"" Set 1, where I am allowed to reroll one die, has the following dice:
A Die with success on 1 of 6 faces
A Die with success on 2 of 6 faces
A Die with success on 3 of 6 faces Set 2, where no reroll is allowed, has the following dice:
A Die with sucess on 1 of 6 faces
Two Dice with successes on 2 of 6 faces I need a total of 3 successes among all of the dice rolled (with the reroll replacing the result of the rolled die). Calculating the odds of each group succeeding is easy (disregarding reroll 6/216 or 2.8% and 4/216 or 1.85% respectively).  I am at a total loss for how to figure in that reroll for the larger problem. EDIT FOR CLARITY:  Three success must happen among all six dice, the sets are just defining where a reroll can happen.  You can choose which die in the first set to reroll (but obviously if it rolled a success and you reroll, the success is ignored and the new result is used).","['statistics', 'dice']"
2541296,Prove that the greatest prime divisor $ q$ of $ 2^p-1$ satisfies the inequality $ 2^q>(6p)^{2p}$,"Let $ p$ be a prime of the form  $ 4k+1$ such that
  $$ p^2|2^p-2$$. Prove that the greatest prime divisor  $ q$ of $ 2^p-1$
  satisfies the inequality $$ 2^q>(6p)^{2p}$$ my attemp: let $2^p-1=\prod q_{i}$,where $q_{i}$ are primes (not necessarily distinct).we have $q_{i}=k_{i}p+1$ for some postive integer $k_{i}$,then I can't",['number-theory']
2541325,Characterization of $A_5$ by the Centralizer of an Involution,"In his thesis, Fowler had shown that $A_5$ is the only finite simple group $G$ affording an involution $u$ such that $C_G(u) \cong C_2 \times C_2$. Is there a proof of that result that relies on elementary methods of group theory and representation theory? For comparison: If a finite simple group $G$ affords an involution $u$ such that $C_G(u) \cong D_4$ is the dihedral group of order 8, then $|G| \in \{ 168, 360 \}$. This is proven in some standard textbooks such as the book of James and Liebeck. The proof relies on the Sylow theorems, the orthogonality relations for characters, and some standard facts about induced characters. Can the above statement be proven by similar methods? Here are some thoughts: Let $C = C_G(u)$ be the Klein four group, and let $P \leq G$ be a 2-Sylow subgroup containing $C$. Then $1 \lneq Z(P) \leq C$. Suppose $u \in Z(P)$. Then we have $P=C$. In particular, $P$ has a subgroup of index two containing a unique involution. By a lemma of Thompson [Isaacs - Character Theory of Finite Groups, Lemma 7.11], all involutions of $G$ must be conjugated, whence $P = C_G(x)$ for all $x \in P \setminus \{1\}$. So we are in the situation mentioned by Orat in the comments, and we know how to proceed. So it remains to consider the case, where $u \notin Z(P)$. Then $Z(P) = \langle z \rangle$ is of order two, and $C = \langle u,z \rangle$. There is a subgroup $D$ between $C$ and $N_P(C)$ isomorphic to the dihedral group of order 8. Of course this situation has to be impossible since it does not match with the $A_5$. Any ideas how to derive a contradiction from here? I don't know if it helps, but by Brauer-Fowler, $G$ can be embedded into the alternating group $A_{15}$. In particular, the order of $P$ is bounded by $2^{10}$. I think the remaining case can be handled by exactly the same methods as in the book of Collins: We have $\sum_i \chi_i(u)^2 = 4$, where $\chi_i$ runs over the irreducible characters of $G$, $\chi_1$ being the trivial character. Because of that equation, there are exactly four of those characters not vanishing on $u$, say $\chi_1, \dots, \chi_4$. Due to orthogonality relations, we may assume $\chi_2(u) = 1$, $\chi_3(u) = -1$ and $\chi_4(u) = \pm 1$. Now, in contrast to the case handled in the book, we have more than one conjugacy class of involutions in $G$. More precisely, $u$ and $z$ cannot be conjugated, since they have centralizers of different orders. Moreover, we also use (as in the book) that the product of two involutions is an involution if and only if they commute. So any two involutions $x,y \in G$ with $xy = u$ must be in $C_G(u)$. It follows that $u$ is not the product of any two elements of its conjugacy class $u^G$. The class algebra constants formula (applied to the conjugacy class $u^G$) yields
$$ \frac{|G|}{16} \left( 1+ \frac{1}{\chi_2(1)} - \frac{1}{\chi_3(1)} \pm \frac{1}{\chi_4(1)} \right) = 0. $$
Now, since $G$ is perfect, we have $\chi_i(1) \geq 2$ for $i \geq 2$. But then the left hand side is strictly positive. So we arrived at a contradiction here. I would be happy if anyone can confirm my proof, or point out some mistake.","['finite-groups', 'abstract-algebra', 'simple-groups', 'representation-theory', 'group-theory']"
2541381,Variance of normal cdf?,"Suppose $Z \sim N(0,1)$, how to calculate $Var(\Phi(\frac{a - bZ}{c}))$ with $a,b,c >0$? I know how to solve $E[\Phi(\frac{a - bZ}{c})]$, but how to find $E[\Phi^2(\frac{a- bZ}{c})]$? Thanks! Here is my attempt to solve $E[\Phi(\frac{a-bZ}{c})]$: $E[\Phi(\frac{a-bZ}{c})] = \int_{-\infty}^{\infty} P(X \le \frac{a-bz}{c})\phi(z)dz \\
= \int_{-\infty}^{\infty}P(X \le \frac{a- bZ}{c}| Z = z) \phi(z)dz \\
= P(X \le \frac{a-bZ}{c}) \\
= P(bZ + cX \le a) \\
= P(N(0,c^2+b^2) \le a) \\
= \Phi(\frac{a}{\sqrt{c^2 + b^2}})$","['statistics', 'probability']"
2541382,Measuring degrees with time?,I am curious as to know why we can convert degrees into measurements of time (i.e. minutes and seconds). I know that 1 degree is equal to 60 minutes but I do not understand why? Any help is greatly appreciated.,['trigonometry']
2541401,"Three ""commutative"" functions","Is there possible to have three functions $f,g,h$ such that $$f(g(h(x))) = f(h(g(x))) = g(f(h(x))) = g(h(f(x))) = h(f(g(x))) = h(g(f(x)))$$ where the functions can be defined anywhere ? The requirement: $f,g,h$ are not constants. I think functions must not be polynomials (I can hardly believe that there exist 3 polynomials $f,g,h$ with the above property).","['algebra-precalculus', 'calculus', 'functions']"
2541403,Lie Derivative of a Metric in Coordinate Expression.,"I apologize in advance if this question is too vague, but I have no idea where to start. I am trying to find the Killing vector fields of a certain manifold with respect to a metric which is written as $ds^2 = ...$ where the right hand side of the equation is a combination of certain one-forms. I have two questions: I have only ever seen ""metrics"" written as tensors. I know how to the compute the Lie derivative of tensors, but this time the metric is written as ""ds"" which is like an infinitessimal line segment so I'm confused how to go about finding the Killing vector fields since I need to compute the Lie derivative of the metric. Is there a book or website that has some good examples of problems like this? I am reading Lee's smooth manifolds and nothing really looks quite like this. The closest thing I have seen is his section on Riemannian metrics.","['riemannian-geometry', 'general-relativity', 'smooth-manifolds', 'mathematical-physics', 'differential-geometry']"
2541412,"What is the difference between ""almost surely"" property of a measurable function and the property which holds ""on the support of a random variable""?","Consider a random variable $X: \Omega \to \mathbb{R}$ on $(\Omega, \mathcal{F}, P)$ and a measurable function $g:\mathbb{R} \to \mathbb{R}$. And let's choose some function property, for example continuity. Does the sentence ""function $g$ is continuous almost surely"" (i.e. $g$ is continuous at every point of $B \subset \mathbb{R}, \, P(X \in B) = 1$) mean the same as ""function $g$ is continuous on the support of $X$""? This looks like to be true when $X$ is a discrete random variable but what about other possible cases (continuous r.v.)? And what if we choose another function property (monotonicity, differentiability, etc.)?","['probability-theory', 'random-variables']"
2541445,Number of components of Levi Civita Connection $\Gamma^a_{bc}$.,"How follows on page $1$ of this paper, in the second last paragraph, the three formulas containing $n$ , namely $n^2(n+1)/2$ $n+n(n+1)/2$ and $n(n^2-3)/2$ Maybe it will suffice for me to understand the first number $n^2(n+1)/2$ to get the rest: This is the number of independent components in $\Gamma^a_{bc}=\Gamma^a_{cb} $ , but I do not understand the combinatorics behind it.","['smooth-manifolds', 'projective-geometry', 'differential-geometry', 'manifolds', 'connections']"
2541463,Computing $\int\limits_0^{\pi/2} {1 \over 1+8\sin^2(\tan x)}\ dx$,"I’m trying to evaluate$$\int\limits_0^{\pi/2}dx\,\frac 1{1+8\sin^2(\tan x)}$$And made the substitution $u=\tan x$. Therefore$$I=\int\limits_0^{\infty}dx\,\frac 1{(1+x^2)(1+8\sin^2x)}$$Through some manipulations, you arrive at$$I=\int\limits_0^{\infty}dx\,\frac 1{(1+x^2)(5-4\cos 2x)}$$However, I’m confused what to do after that. The answer key started with$$\int\limits_0^{\infty} dx\,\frac 1{(1+x^2)(5-4\cos 2x)}=\int\limits_0^{\infty}dx\,\frac 1{1+x^2}\left(\frac 13+\frac 23\sum\limits_{k\geq1}\frac {\cos 2kx}{2^k}\right)$$However, I’m confused where they got the infinite sum from. Any ideas?",['integration']
2541471,Minimal Surface and Mean Curvature,"In the frame of a course on instabilities, I am trying to prove that the soap film between two rings has the form of a catenoid. Since pressure is equal on either side of the film, we expect to have a surface that has zero mean curvature everywhere, i.e.: $$\frac 1 {r_1}+\frac 1 {r_2}=0 \tag1 
$$ where $r_1$ and $r_2$ are the two principal radii. (Assume we have two perpendicular planes, the $(x,r)$ plane and the $(r,\theta)$ plane). In the $(x,r)$ plane, the radius is: $$r_1=\frac{r''(x)}{\left(1+r'(x)^2\right)^{3/2}} \tag2$$ while the radius is ""constant"" at each section in $(r,\theta)$ with  $r_2=-r(x) \tag3 $ so that the first relation becomes: $$r(x)r''(x)=\left(1+r'(x)^2\right)^{3/2} \tag4 $$ which is not the relation given by finding the minimal surface $$ rr''=1+r'^2 \tag 5$$ that leads to the correct catenoid form. Where did I go wrong? I feel I'm using the wrong formula for $r_1$ but can't seem to find an alternative. Can someone throw a hint my way?","['euler-lagrange-equation', 'variational-analysis', 'curvature', 'calculus', 'differential-geometry']"
2541485,"Turán's graph $T_{k, n}$ has more edges than any other $k$-partite graph with $n$ vertices.","In Bondy and Murty's Graph Theory , exercise $1.1.11$ defines something called Turán's graph $T_{k, n}$ , as a complete, $k$-partite graph where all parts are of size $\lceil \frac{n}{k} \rceil$, or $\lfloor \frac{n}{k} \rfloor$. I want to show the following: $T_{k, n}$ has more edges than any other complete $k$-partite graph with $n$ vertices. I know from part $a)$ that in this case, the number of edges of a complete, $k$-partite graph is $\frac{1}{2} \sum_{i=1}^{k} a_{i}(n-a_{i})$, where $a_{i}$ are the sizes of the parts $A_{i}$. So I want to prove that if $n=kq+r$, $0 \leq r < n$, $q = \lfloor \frac{n}{k} \rfloor$, $a_{1}= \space ... \space =a_{r}=q+1$, $a_{r+1}= \space ... \space =a_{k} = q$, and $b_{i}$ any other sequence of $k$ positive numbers such that $\sum_{i=1}^{k} b_{i} = n$, that $$\sum_{i=1}^{k} a_{i}(n-a_{i}) \geq \sum_{i=1}^{k} b_{i}(n-b_{i}).$$ Is there an elementary-inequality way of proving this? I've tried Lagrange multipliers, but it seems like overkill, and it'd require further discussion since $a_{i}$ can only be positive integers, not real numbers.","['graph-theory', 'inequality', 'discrete-mathematics']"
2541529,Exercises to help a student become accustomed to Sweedler notation,"For a coassociative coalgebra $A$, we have a comultiplication map $\Delta \colon A \to A \otimes A$. An element $c \in A$ is sent to a sum of simple tensors, which can be a mess of indices, so we can use Sweedler's notation to try to write down the comultiplication more cleanly:
$$
  \Delta(c) = \sum_i c_{{(1)}_i} \otimes c_{{(2)}_i} 
  = \sum_{(c)} c_{{(1)}} \otimes c_{{(2)}}
$$ Sometimes even the sigma is omitted in the notation, and we simply write $\Delta(c) = c_{(1)} \otimes c_{(2)}$. Working with this sumless Sweedler notation takes some getting used to. What are some good introductory exercises to give a student practice working with Sweedler notation? I assume that there must be some canonical exercises like this one that only use the very basic properties of bialgebras or Hopf algebras.","['tensor-products', 'notation', 'abstract-algebra', 'hopf-algebras', 'coalgebras']"
2541549,How to intersect a line with a point off the page using a straight edge and compass (see description),"Its very common in illustration to want to draw a line towards a vanishing point that is off of the page. The specific problem is this: lets say we draw two line segments on a piece of paper lying on a flat surface. The line segments are drawn such that, if extended beyond the edge of the page, they intersect at a point $A$. Next, we draw a point $B$ anywhere on the page. Without actually extending the two line segments to find $A$, is there a way to draw a line segment such that, if extended to a line, would intersect both $A$ and $B$ using only a straight edge and compass construction? Looking for an answer with the fewest number of steps.","['plane-geometry', 'geometric-construction', 'projective-geometry', 'euclidean-geometry', 'geometry']"
2541579,Proving Peano's Existence Theorem by approximating with $C^{\infty}$ functions using Weierstrass' Theorem.,"Let $f:B_r(x_0)\to\mathbb{R}^n$ be continuous. Prove there always exists a local solution $x:[0,\delta)\to\mathbb{R}^n$  satisfying
  $$x(0)=x_0, \hspace{1cm} x'(t)=f(x(t)), \quad \forall t \in (0,\delta),$$ by approximating $f$ uniformly by $C^{\infty}$ functions. I am looking for proof verification of the following and any suggestions for improvement. I do not feel confident with this proof because I did not use Ascoli-Arzela, which is used in the typical proof of Peano's Existence Theorem. Consider, instead of the open ball $B_r(x_0)$, a closed ball contained in it (since we're showing a local solution, this makes no difference), say $\overline{B_r(x_0)}$. Consider polynomials $P_n(x)$ which converge uniformly to $f$ on the closed ball. These exist because of the Weierstrass' theorem.
Now the problems $$\begin{cases} x_n'(t)=P_n(x_n(t))\\
x_n(0)=x_0\end{cases}$$ have a unique local solution in $B_r(x_0)$, since $P_n$ is a polynomial, hence locally Lipschitz on the open ball. Call this solution $x_n$. Moreover, we may extract a convergent subsequence of $x_n$ such that the function $P_n$ has a uniform limit $f$, and therefore the functions $t \mapsto x_n'(t)$ have a uniform limit, which we shall denote by $g(t)$. Now we have a sequence of functions $x_n$ which take the same value at $0$, which are $C^1(B_r(x_0))$ and whose derivatives converge uniformly to a function $g$. Therefore $\exists \lim x_n$ and it is differentiable in a neighborhood of $0$ and its derivative is $g$ because: If $\exists a.f_n(a)\to L$ and $f'_n\to g$ uniformly then $f_n$
  has a limit $f$ satisfying $f(a)=L$, $f'=g$. In other words, there is some local solution $x:[0,\delta)\to\mathbb{R}^n$ satisfying $x(0)=x_0$ where $x'(t) = f(x(t))$ for all $t\in[0,\delta)$.","['real-analysis', 'ordinary-differential-equations', 'weierstrass-approximation', 'proof-verification']"
2541613,Generalization of Dirichlet integral,"Is it correct that
$$\lim_{L\to\infty} \int_0^L d x \int_0^L dy \int_0^L d z \frac{\sin(x+y)}{x+y}\frac{\sin(y+z)}{y+z}\frac{\sin(z+x)}{z+x} =\frac {\pi^3}{16}. $$
or does anybody has a reference for this? The value $\frac{\pi^3}{16}$ comes from numerics. 
The identity
$$ \lim_{L\to\infty}\int_0^L \frac{\sin(x)}{x} = \frac \pi 2 $$
(which is sometimes also called Dirichlet integral) is well known and there are many ways to prove it. However, I need the slight generalization of this above.","['real-analysis', 'integration']"
2541634,"If $A$ and $B$ are invertible matrices, is $A+B$ invertible too?","Assume that $A$ and $B$ are invertible matrices, is $A+B$ (given that $A+B\neq0$) an invertible matrix too? And if so how do I prove it?","['matrices', 'linear-algebra']"
2541651,Jacobian Transformation to find joint pdf of $Y_1$ and $Y_2$,"Let $X_1$ and $X_2$ have the following joint density: $$f_{X_{1},X_{2}}(x_1,x_2) = \begin{cases}
 {\frac{4}{\pi}e^{-(x_1^2+x_2^2)}}  & \text{$x_1 \gt 0$, $x_2 \gt 0$}
 \\{0} & \text{otherwise}\end{cases}$$ Letting $Y_1=X_1^2$ and $Y_2 =X_1^2 + X_2^2$, give the joint pdf of
  $Y_1$ and $Y_2$. I have avoided using Jacobian Transformations in the past because it seemed complicated, but I think using it would be much easier than alternative methods in this case. I wanted to make sure I'm doing this correctly. $$\begin{align*}
J(x_1,x_2)
&= \begin{vmatrix}\frac{\partial x_1^2}{\partial x_1}&&\frac{\partial x_1^2}{\partial x_2}\\\frac{\partial x_1^2+x_2^2}{\partial x_1}&&\frac{\partial x_1^2+x_2^2}{\partial x_2}\end{vmatrix}\\\\
&= \begin{vmatrix}2x_1&&0\\2x_1&&2x_2\end{vmatrix}\\\\
&= 4x_1x_2
\end{align*}$$ For $x_1$ and $x_2$ we have $x_1=\sqrt{y_1}$ and $x_2=\sqrt{y_2-y_1}$ Thus I have, $$\begin{align*}
f_{Y_1,Y_2}(y_1,y_2)
&= f_{X_1,X_2}\left(\sqrt{y_1},\sqrt{y_2-y_1}\right) \cdot \left |J(x_1,x_2)\right|^{-1}\\\\
&= \frac{4}{\pi}\cdot e^{-(\sqrt{y_1}^2+\sqrt{y_2-y_1}^2)}\cdot\frac{1}{4x_1x_2}\\\\
&= \frac{1}{\pi\sqrt{y_1}\sqrt{y_2-y_1}}\cdot{e^{-y_2}} \\\\
\end{align*}$$ So the pdf I obtained is $$f_{Y_{1},Y_{2}}(y_1,y_2) = \begin{cases}
 \frac{e^{-y_2}}{\pi\sqrt{y_1}\sqrt{y_2-y_1}}  & \text{$y_1 \gt 0$, $y_2 \gt 0$}
 \\{0} & \text{otherwise}\end{cases}$$ Is this correct? Edit: If $Y_1 = X_1^2$ and $Y_2=X_1^2+X_2^2$ then $Y_2 \gt Y_1$ so $$f_{Y_{1},Y_{2}}(y_1,y_2) = \begin{cases}
 \frac{e^{-y_2}}{\pi\sqrt{y_1}\sqrt{y_2-y_1}}  & \text{$y_1 \gt 0$, $y_2 \gt y_1$}
 \\{0} & \text{otherwise}\end{cases}$$ Checking, I get that $$\int_0^\infty \int_x^\infty \frac{e^{-y_2}}{\pi\sqrt{y_1}\sqrt{y_2-y_1}} = 1$$","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2541873,Why do we assume Taylor series to be polynomials?,"Consider the Taylor series of a function $f(x)$
we usually assume $f(x)$ to be a polynomial:
$$f(x)=a_0+a_1x+a_2x^2+a_3x^3...$$ But why not assume $$f(x)=a_0+a_{0.5}x^{0.5}+a_1x+a_{1.5}x^{1.5}+...$$ or $$f(x)=a_0+a_{0.1}x^{0.1}+a_{0.2}x^{0.2}+a_{0.3}x^{0.3}+...$$ what are the advantages of polynomials?","['complex-analysis', 'real-analysis']"
2541888,ODE solver giving unexpected result,"I have the following coupled ODEs:
$$
\begin{cases}
F'(s) & = \lambda F(s) - \lambda (1 - (1 - F(s))^2) + \lambda H'(s)\\
H'(s) & = 1 - H(s) - (1 - F(s))^2,
\end{cases}
$$
with boundary condition $F(0) = 1-\lambda, H(0) = 0$, here $\lambda \in ]0,1[$. The solution for $F$ I am looking for is a Cummulative Distribution Function (CDF), but when I solve these coupled ODEs with these boundary conditions, I get a result which is not a CDF at all. The question is: how to find the correct solution OR did I make a mistake in deriving these ODEs and do these ODEs indeed not give a CDF as a possible solution? I am using the Python solve odeint","['numerical-methods', 'ordinary-differential-equations', 'calculus', 'probability-distributions']"
2541921,Getting x in terms of y,I have this equation: $$\dfrac{x}{y} = \dfrac{y-x}{x}$$ How would I separate $x$ and $y$ in $x^2+xy-y^2=0$ ?,['algebra-precalculus']
2541937,"Are metrics that determine the same topology, equivalent?","I've just completed an exercise where I had to prove that two equivalent metrics induce the same topology. Now, I was wondering if it's true that two metrics that induce the same topology, are equivalent? If it's not the case, what are some counterexamples?","['general-topology', 'metric-spaces']"
2541991,Dependant random variables with covariance equal to $0$,"I need to find a pair of dependent random variables $(X, Y)$ with covariance equal to $0.$ From this I gather: $$0 = E((X-EX)(Y-EY)) = E \left(\left(X - \int_{-\infty}^\infty xf_X(x)\,dx\right) \left(Y - \int_{-\infty}^\infty xf_Y(x)\,dx \right)\right)$$ but what can I do now? How can I use the fact that they are dependent in the equation? Do you know of two such variables?",['statistics']
2542004,Computing the state transition matrix,"Let $$\pmatrix{\dot x_1\\ \dot x_2\\ \dot x_3} = \underbrace{\pmatrix{0 & 3 & 2\cos(7t)\\-3 & 0 & -2\sin(7t)\\-2\cos(7t) & 2\sin(7t) & 0}}_{A(t)}\underbrace{\pmatrix{x_1(t)\\x_2(t)\\x_3(t)}}_{X(t)}.$$ Find the state transition matrix $\phi(t,0)$ for the system. I know how to work with this if the matrix $A$ is actually time-invariant. It is as simple as computing $\phi(t,0) = e^{At}$, which can be decided by the eigenvalues of $A$ or even putting the matrix $A$ into real-Jordan form. However, we have a time-variant matrix $A(t)$. Initially I thought that maybe I could try and use the $e^{At}$ formula again, but my first hint that this probably won't work was the fact that MATLAB and Mathematica spit out a gigantic mess. Can anyone provide a hint on what might need to be done in order to compute the state transition matrix for a time-varying system such as this? More specifically, is there a more intuitive method to finding the state transition matrix for a system like this than the Peano-Baker series?","['matrix-calculus', 'control-theory', 'linear-control', 'ordinary-differential-equations', 'linear-algebra']"
2542011,An application of the Inclusion Principle to Chemistry? (Proof Verification),"Background I’m taking chemistry and one thing they have us do is draw Lewis structures for molecules. Guessing if there are going to be double or triple bonds is kind of annoying. I’d like to be able to come up with a formula to predict the total number of bonds a molecule will form. I count a double bond as $2$ bonds, and a triple bond as $3$. What I’d like to prove Count a single bond as $1$ bond, a double as $2$ bonds, and a triple as $3$. Scrolling through YouTube one video seems to suggest that when octets (or a duet for hydrogen) are formed, the number of bonds a molecule will form is, $$B=\frac{N-H}{2}$$ Where $N$ is the sum of the electrons needed on each atom. Ex: In $H_2O$, we have $N=2+2+8=12$. And $H$ is the number of electrons we have to distribute. In our case $1+1+6=8$ hence, $B=\frac{12-8}{2}=2$ and water forms $2$ bonds as expected (two single bonds). I’d like to be sure this holds in general for the conditions mentioned to be sure I’m not using some nonsense. I think I came up with a proof: My proof Suppose we have $n$ atoms $X_1,X_2,\dotsc,X_n$ part of a molecule. Think of each atom $X_i$ as a set consisting of it’s electrons (in the molecule form). $X_1 \cup X_2 \cup \dotsb \cup X_n$ is what you get when you combine these elements/electrons and overlapping may occur. $X_1 \cup \dotsb \cup X_n$ is the molecule, which has a cardinality of $H$ electrons by definition. By inclusion exclusion, $$
    H
  = \left| \bigcup_{k=1}^{n} X_k \right|
  =   \sum_{k=1}^{n} |X_k|
    - \sum_{1 \leq i < j \leq n} |X_i \cap X_j|
    + \dotsb
    + (-1)^{n-1} \left| \bigcap_{k=1}^{n} X_k \right|
$$ On the right most part of the equation above, everything vanishes except $|\sum_{k=1}^{n} |X_k|-\sum_{1 \leq i < j \leq n} |X_i \cap X_j|$ since each electron can only share $2$ atoms at most. Finally, $\sum_{k=1}^{n} |X_k|=N$ since the cardinality of each atom is exactly how many electrons it needs, if we give it what it needs. And $\sum_{1 \leq i < j \leq n} |X_i \cap X_j|$ is the some of the bonding electrons (no double counting), between each element. That is $\sum_{1 \leq i < j \leq n} |X_i \cap X_j|=2B$. So, $H=N-2B$ and $\frac{N-H}{2}=B$. Question Is the above proof correct.","['inclusion-exclusion', 'combinatorics', 'chemistry', 'proof-verification']"
2542027,Riemannian metrics on vector bundles according to Jeffrey. M. Lee's book,"According to Manifolds and differential Geometry (J. M. Lee, 2009), a Riemannian metric on a vector bundle $\pi:E\rightarrow M$ is a smooth assignment to each point $p\in M$ a scalar product $g_p$ on the fibre $\pi^{-1}(p)$ , so this is the standard definition. However, he wants to show that a choice of Riemannian metric for $E$ is a reduction of structure group from $GL(V)$ to $(O(V)$ . And he will do it using charts. Let's go. First, he says: If the vector bundle has such a structure, it is convenient to assume that a fixed inner product has is chosen on the typical fibre and that a distinguished orthonormal basis $(e_1,\dots,e_k)$ has been chosen. (Here $k$ is the rank). Now he continues: If $(U,\Psi)$ is a local trivialization, then define a local frame field $(X_1,\dots,X_k)$ simply as $$
X_a(p) = \Psi^{-1}(p,e_i) \qquad \forall p\in U,
$$ for all $a=1,\dots,k$ . This is also good because he has already proven the relation between local frame fields and vector bundle charts, so it is okay. But now, he says: One can perform a Gram-Schmidt proccess in the basis $\{X_1(p),\dots,X_k(p)\}$ simultaneously for all $p\in U$ so that we have a new orthonormal basis $\{E_1(p),\dots,E_k(p)\}$ (...). Thus, $\{E_1(p),\dots,E_k(p)\}$ is a local frame called orthonormal frame. HERE the point is. Some comments: First, yo haven't a metric on $\pi^{-1}(p)$ , but in $V$ , so you must to import it. I mean, Gram-Schmidt process does not make sense at this moment. Second, since you really haven't such a metric, I think Gram-Schimdt process would look like $$
E_a(P) = \Psi^{-1}(p,W_a),
$$ where $W_a$ is defined as $$
W_p = \frac{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)}{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)}
$$ (here $\Psi$ is supposed to be $\Psi=(\pi,\psi)$ . If the above process is right, Lee's words don't not make sense, since $\Psi(X_a(p))=e_a$ exactly, and then it is already orthonormal. So, what is happening here? Lee's book is wrong? Is all that a mistake? Or what is he actually thinking in? Thanks EDIT Reading Riemannian Geometry and Geometric Analysis (Jürgen Jost, 2011) I realize that I am wrong: Each (real) rank $k$ vector bundle $\pi:E\rightarrow M$ with a bundle metric $g$ has structure group $(On)$ . In particular, there exists bundle charts $(U,F)$ , $F:\pi^{-1}\rightarrow U\times\mathbb{R}^k$ , for which for each point $p\in U$ , $F^{-1}(p,(e_1,\dots,e_k))$ is an orthonormal basis of $\pi^{-1}(p)$ . Since my bundle charts was arbitrary, $\{X_1,(p),\dots,X_k(p)$ cannot be an orthonormal frame, but I don't know why. I'm missing something.","['vector-bundles', 'riemannian-geometry', 'differential-geometry']"
2542039,Solving a system of generic quadratic forms,"Suppose we have a system of $n$ quadratic forms, 
$$x^T A_1 x = 0 \\ x^T A_2 x = 0 \\ ... \\ x^T A_n x = 0$$
where $x\in \mathbb{R}^d$ and $A_i \in \mathbb{R}^{d \times d}$ symmetric, $d > n$. What is the best way to solve this system without any assumptions on the $A_i$? Can this even be done in general? What kind of assumptions on the $A_i$ would make this problem feasible/easier?","['linear-algebra', 'algebraic-geometry', 'systems-of-equations']"
2542068,"Asymptotic behavior of $x_{n+1}=x_n+\frac{1}{x_n}, \space\space\space x_0=1$ [duplicate]","This question already has answers here : Closed form for the sequence defined by $a_0=1$ and $a_{n+1} = a_n + a_n^{-1}$ (6 answers) Closed 3 years ago . I have defined a sequence $x_n$ as follows:
$$x_{n+1}=x_n+\frac{1}{x_n}, \space\space\space x_0=1$$
After convincing myself that there is no nice closed-form formula for $x_n$, I decided to try and find an asymptotic formula for $x_n$ (unfortunately, I have very little experience with asymptotic formulae). I noticed that the recurrence is equivalent to
$$\Delta x_{n}=\frac{1}{x_n}$$
and so a solution can be approximated by solving the corresponding differential equation for $y(t)$:
$$y'=\frac{1}{y}$$
This differential equation (with initial value $y(0)=1$) yielded
$$y=\sqrt{2t+1}$$
which led me to believe that
$$x_n\approx \sqrt{2t+1}$$
When I plotted $x_n$ and $y(n)$ side by side, it did indeed appear that they were very close to each other. However, this isn't enough for me... I would like to prove that $y(n)$ is a good approximation for $x_n$, either by proving that
$$\lim_{n\to\infty}(x_n-\sqrt{2n+1})=0$$
...or, even better, by finding a zero-approaching function $f$ satisfying
$$x_n=\sqrt{2n+1}+O(f(x))$$
This is where I got stuck. How do can I prove (or disprove?) the statement in the first equality, and find $f$ satisfying the second? NOTE: There may be a closed-form that I wasn't able to find. In fact, the similar sequence
$$y_{n+1}=\frac{y_n}{2}-\frac{1}{2y_n}$$
has closed form formula
$$y_n=\frac{1}{\tan(2^n\arctan(y_0^{-1}))}$$
...but even if you do find a closed form, I would still like to know how to prove the above statements, since the techniques would be useful to know for future problems.","['recurrence-relations', 'asymptotics', 'sequences-and-series', 'approximation']"
2542084,"Radical ideal in $k[X_{1},...,X_{n}]$","Let $k$ be an field with $\mathrm{char}(k) = 0$ and $f_{1},...,f_{n} \in k[X_{1},...,X_{n}]$. Consider the jacobian matrix $A := (\frac{\partial f_{j}}{\partial X_{l}})$ and suppose that $\det(A) = 1$. Is it true that $\sqrt{(f_{1},...,f_{n})} = (f_{1},...,f_{n})$? Note that if $n = 1$, then $\det(A) = 1 \Longrightarrow f_{1} = X+b$ with $b \in k$. So, $\sqrt{(f_{1})} = (f_{1})$.","['abstract-algebra', 'commutative-algebra']"
2542113,"""chain rule"" for Laplace-Beltrami operator on spheres","Let $\Delta_{S^{n-1}(R)}$ be the Laplace-Beltrami operator $\Delta_{S^{n-1}(R)}$ on the $(n-1)$-dimensional sphere $S^{n-1}(R)\subset \mathbb{R}^{n}$ with radius $R$. Define $i_R\colon S^{n-1}(1)\to S^{n-1}(R)$ by $i_R(\xi):=R\xi$. I think for smooth $f\colon{S^{n-1}(R)}\to \mathbb{R}$ we have
$$
\Delta_{S^{n-1}(1)}(i_R^* f)(\xi)=R^2 \Delta_{S^{n-1}(R)}f(x)|_{x=R\xi},\tag{$\star$}
$$
where $(i_R^* f)(\xi):=f(i_R(\xi))$ is the pullback of $f$ by $i_R$. This seems to be a natural extension of the chain rule in the one dimensional case $\frac{d^2f}{dx^2}(ax)|_{x=x^*}=a^2f''(ax^*)$, but it does not seem to be consistent with Expression for Laplace-Beltrami on sphere? Question: Is ($\star$) correct?","['manifolds', 'differential-geometry', 'analysis', 'geometry']"
2542176,Relax Egoroff's Theorem to pointwise convergence a.e. and bounded a.e. pointwise limit,"The following question is taken from Royden's Real Analysis $4$th edition, Chapter $3,$ question $28,$ page $67:$ Question: Show that Egoroff's Theorem continues to hold if the convergence is pointwise a.e. and $f$ is finite a.e., that is. Assume $E$ has finite measure. Let $\{f_n\}$ be a sequence of measurable functions on $E$ that converges pointwise almost everywhere on $E$ to the real-valued function $f$ which is finite almost everywhere. Then for each $\varepsilon>0,$ there is a closed set $F$ contained in $E$ for which 
  $$\{f_n\}\to f \text{ uniformly on }F \text{ and }m(E\setminus F)<\varepsilon.$$ My attempt: Let $A = \{ x\in E: f_n\not\to f \text{ pointwise} \}$ and $B=\{ x\in E: |f|=\infty \}.$ 
By assumption, 
$$m(A)=m(B)=0.$$
So $A$ and $B$ are measurable. 
Note that 
$$m[E\setminus (A\cup B)] = m(E) - m(A\cup B) = m(E).$$
Fix $\varepsilon>0.$
Since $\{f_n\}$ converges to $f$ pointwise on $E\setminus (A\cup B)$ to the real-valued function $f,$ by Egoroff's Theorem, there exists a closed set $F$ contained in $(E\setminus (A\cup B))\subseteq E$ for which 
$$f_n\to f \text{ uniformly on } F \text{ and }m[(E\setminus(A\cup B)) \setminus F] < \varepsilon.$$
Since $E$ has finite measure and $F\subseteq E,$ by monotonicity,  $F$ has finite measure.
As $F$ is closed, it is also measurable. 
Therefore, by Excision property, we have $$m(E\setminus F) = m(E) - m(F) = m[E\setminus(A\cup B)] - m(F) = m[(E\setminus(A\cup B)) \setminus F]<\varepsilon.$$ Is my proof correct? I ask for verification because in this post Kenny's comment about countable union of null sets. I do not use this anywhere in my proof. So I wonder whether my proof miss out something.","['real-analysis', 'measure-theory', 'proof-verification']"
2542179,How many ways can you put: a) two bishops b) two knights c) two queens on a chessboard in such a way that one piece does not attack the other?,"How many ways can you put:
a) two bishops
b) two knights
c) two queens
on a chessboard in such a way that one piece does not attack the other?",['combinatorics']
2542193,The Product of Two Sequences Converging in Distribution?,"Suppose there are two i.i.d. sequences $\left\{X_n\right\}$ and $\left\{Y_t\right\}$ that
\begin{align*}
\sqrt{N}\left(\bar{X}_N-\mathrm{E}\left[X_n\right]\right)\overset{d}{\rightarrow}&\mathcal{N}\left(0,\mathrm{Var}\left[X_n\right]\right)\\
\sqrt{T}\bar{Y}_T\overset{d}{\rightarrow}&\mathcal{N}\left(0,\mathrm{E}\left[Y_t^2\right]\right)
\end{align*}
and they are independent. Can I infer anything about
\begin{align*}
\frac{1}{\sqrt{NT}}\sum_{i=1}^{N}{\sum_{t=1}^{T}{X_nY_t}},
\end{align*}
i.e. the product of two sequences that converge in distribution? I think I cannot apply Slutsky's Theorem since both converge not in probability, but in distribution. Here I am assuming the existence of the moments $\mathrm{E}\left[X_n\right]$, $\mathrm{E}\left[X_n^2\right]$, $\mathrm{E}\left[Y_t\right]$ and $\mathrm{E}\left[Y_t^2\right]$, but, if it is necessary, then I can add the assumption that both $X$ and $Y$ are normally distributed. By the way, I tried Monte Carlo Simulation and it seems the product follows a leptokurtic distribution that is similar to Laplace Distribution.","['weak-convergence', 'probability-theory', 'asymptotics']"
2542195,Question regarding exponentiation of cardinal numbers,Let $2\leq \kappa\leq \gamma$ where $\gamma$ is an infinite cardinal number and $\kappa$ is any cardinal. Prove that $2^\gamma = \kappa^\gamma$. One direction is obvious but I'm stuck with the other. i.e. showing $\kappa^\gamma\leq 2^\gamma$. Any hints or solutions will be appreciated.,"['cardinals', 'set-theory', 'functions']"
2542202,Functor from Order Category to Top Category,"Let Order be the category whose objects are totally ordered sets and whose morphisms are monotone functions, and let Top be the category whose objects are topological spaces and whose morphism are continuous functions. Then given an ordered sets $A$ with relation $\leq_A$, we can construct a topology $\mathcal{T}_{\leq_A}$ on $A$ with a basis consisting of the following types of sets: $$(a,b) = \{x|a<_A x <_A b\},$$
$$ (-\infty,b) = \{x|x <_A b\},$$
$$ (a,\infty) = \{x|a<_A x\}.$$ where $a<_A b$ means $a\leq_A b$ but $a\neq b$. I am supposed to show that there is a functor $F:$ Order $ \to$ Top that maps $(A,\leq_A)$ to $(A,\mathcal{T}_{\leq_A})$ and takes a monotone function $f:A\to B$ to the same function. Now in order for this actually to be a functor, it must hold that the monotone functions $f:A\to B$ are continuous functions in order for them to be morphisms in Top , but I don't see why this must necessarily be true. For instance, $\Bbb{R}$ is an ordered set. So let us say that $A=B=\Bbb{R}$. Then the topology induced by the order is just the usual topology on $\Bbb{R}$. Then consider the floor function $f:\Bbb{R} \to \Bbb{R}$ given by $f(x) = \lfloor x \rfloor$. This is not a continuous function because $f^{-1}(0.5,1.5) = [1,2)$ which is not an open set in this topology. So it seems to me that the above is a counterexample to the claim that a monotone function between two ordered sets is necessarily continuous in the topology induced by that order. Is this the case? If this is not a counterexample, I don't see how to prove that the monotone functions are continuous.","['category-theory', 'general-topology']"
2542220,"What's the derivative wrt. $x$ of $\int_0^x f(x-s)\,ds$?","I know how to compute the derivative of $f(x-s)$ and by the fundamental theorem of calculus the derivative of $\int_0^x f(s)\,ds$ is $f(x)$. But I can't figure out how to do it when they're mashed together as in $\int_0^x f(x-s)\,ds$. The presence of the $s$ inside $f(x-s)$ prevents me from factoring out $f$ and using the product rule.",['derivatives']
2542263,Simple upper bound on the probability that the sum of $n$ dices rolls is equal to the most likely total,"Suppose $n$ $s$-sided (and fair) dice and are rolled, and consider the most likely value their total will take. Is there a simple / easy to state upper-bound on the probability that this total is rolled? I know you can bound this accurately using generating functions, but to use in the proof I'm working on requires summing over this probability for a range of (large) $n$ values,  which gets too complicated. I imagine it can also be approximated it using some distribution, but it's for a crypto proof so I really need an upper bound. I'm crudely upper bounding this with $1/s$ at the moment for all $n$. This follows by induction on n. Letting $X_i$ denote the distribution of the $i$th dice roll For $n = 1, Prob[X_1 = z] = 1/s$ for all $z \in [1, s]$, so the base case holds. Assume true for $n=k$, so $max_{z \in [k, ks]} Prob[\sum_{i = 1}^k {X_i} = z] \leq  1/s$. Then for $n = k+1$, and each $z \in [k+1, (k+1)s]$: $Prob[\sum_{i = 1}^{k+1} {X_i}=z$]
                     $ = \sum_{h \in [k, ks]} Prob[X_{k+1} = z - \sum_{i = 1}^k X_i | \sum_{i = 1}^k X_i = h]Prob[\sum_{i = 1}^k X_i = h]$ $\leq \sum_{h \in [z - s, z-1]}1/s^2 = 1/s$, where the final inequality follows since by the induction hypothesis $Prob[\sum_{i = 1}^k X_i = h]\leq 1/s$ and $Prob[X_{k+1} = z - h] = 1/s$ if $h \in[z - s, z-1]$ and $0$ otherwise. I was wondering if there is any tighter (for large $n$) but still simple upper bound?","['combinatorics', 'statistics', 'probability', 'cryptography']"
2542269,The difference of two order statistics of exponential distribution,"If we have a random sample $X_1,X_2, \ldots, X_n \stackrel{\text{iid}}\sim f(x\mid\theta)=e^{-(x-\theta)}I(x >\theta)$. We want to prove 
$$2\sum X_i-2n X_{(1)} \sim \chi^2_{n-2}$$
where $X_{(1)}$ is the smallest order statistic. I tried: 
$$2\sum X_i-2n X_{(1)} =2\left[\sum X_i-n X_{(1)}\right]=2\left[\sum X_{(i)}-n X_{(1)}\right]=2\left[\sum \left(X_{(i)}- X_{(1)}\right)\right]$$ 
And I was trying to find the distribution of 
$$X_{(i)}- X_{(1)}$$ And I searched that
$$X_{(i)}-X_{(i-1)} \sim \operatorname{Exp}\left(\frac{1}{n+1-i}\right) \text{ if } X_i \stackrel{\text{iid}}\sim \operatorname{Exp}(1)$$
Any ideas? Thank you~","['statistics', 'probability', 'probability-distributions']"
2542316,Prove/Show that Limit is equal to 0.,"I'm really struggling on this question.  I've been thinking about it for awhile now but this is one of those where I don't really have much intuition on what to do. Problem 3. Prove that if the limit $\lim_{x\to +\infty}f(x) =: L$ exists (finite or infinity) and the improper integral. $$\int_a^{+\infty}f(x) dx$$ is convergent, then $L = 0$ . Here is some facts that I know that I think I should perhaps use. Facts/Knowledge I know:
The above integral can be rewritten as: $$\int_a^{\infty}f(x)dx = \lim_{A\to \infty}\int_a^{A}f(x)dx$$ We know that limit as x goest to infinity of $f(x)=L$ .  I need to somehow show that limit L is equal to 0.
If I take the integral I get $\lim_{A \to \infty} F(A)-f(a)$ and I know this does not equal infinity as the integral converges.  I'm not sure if this is on the right track or what to do next. I was thinking maybe perhaps instead I could use the Cauchy Criterion to come up with a proof.  Note: I'm not used to doing proofs with Improper integrals. Theorem 1 (Cauchy Criterion). The improper integral (1) converges if and only if for every $\epsilon > 0$ there is an $M\geqslant a$ so that for all $A, B \geqslant M$ we have $$\Bigg|\int_A^B f(x) dx\Bigg| < \epsilon$$","['real-analysis', 'limits', 'improper-integrals', 'integration', 'analysis']"
2542351,Is $\frac{\partial}{\partial x} f(x-y) = - \frac{\partial}{\partial y} f(x-y)$?,This seems intuitively plausible to me. But the notation sort of gets in the way when trying to prove this exactly. In particular when using the chain rule to write $\frac{\partial}{\partial y} f(x-y) = - f'(x-y)$ the $'$ looses the information that the chain rule has already been applied.,['derivatives']
2542369,"In constructive mathematics, can the algebraic numbers be constructed directly from the rationals?","Is it possible in constructive mathematics (no excluded middle or Axiom of Choice) to construct the algebraic numbers directly from the rationals (in say HoTT), without first constructing a real line and then augmenting it with the imaginary unit? In classical mathematics one could do this by appealing to the (obviously nonconstructive) principle that every field admits an algebraic closure. One reason that I ask is that in constructive mathematics the real line seems a bit messy: the various constructions of the real line (Cauchy vs. Dedekind) are in general inequivalent without at least assuming countable choice, and in particular the usual construction of the Cauchy reals may not even be sequentially complete without countable choice (though the new higher-inductive type definition given in HoTT avoids this problem). I'm relatively new to constructive mathematics, so I apologize if this construction is obvious (or obviously not possible). Edit: I'm also curious about the constructive properties of the algebraic numbers, such as if they inherit decidable equality from the rationals?","['constructive-mathematics', 'abstract-algebra', 'extension-field', 'field-theory']"
2542378,Some new graph operations in graph theory.,I was just going through following link on wiki about the graph operations: https://en.wikipedia.org/wiki/Graph_operations . Just curious to know if there any other graph operations that are not defined in the above link. It would be kind of you to help me. Thanks a lot for helping me.,"['combinatorics', 'graph-theory', 'spectral-graph-theory', 'discrete-mathematics']"
2542406,Proof that Lukaszyk-Karmowski metric upper bound Wasserstein metric,"I was reading Introduction to Uncertainty Quantification and there was an exercise for the reader, that I haven't been able to solve (Exercise 5.11). Given $(X,d)$ is a metric space equipped with a Borel $\sigma$-algebra. $\mu$ and $v$ are both probability measures. Let $$d_W(\mu, v) = \inf_{\gamma \in \Gamma(\mu,v)} \int_{X\times X} d(x,x')d\gamma(x,x')$$
where ""the infimum is taken over the set $\Gamma(\mu,v)$ of all measures $\gamma$ on $X \times X$ such that the push-forward of $\gamma$ onto the first copy of $X$ is $\mu$"" Also let 
$$d_{LK}(\mu,v)=\int_X \int_X d(x, x')d\mu(x)dv(x')$$ I am able to show that $d_W$ is an actual metric. But how do I show that $$d_W(\mu,v)\leq d_{LK}(\mu,v)$$","['probability-theory', 'metric-spaces', 'measure-theory']"
2542411,"Given $f(0)=f(1)=0$ and $\int_{0}^{1} f^2(x)dx=1$, evaluate $\int_{0}^{1} xf(x)f'(x)dx$","Q.Suppose $f$ is a real valued continuously differentiable function on $[0,1]$ with $f(0)=f(1)=0$ and $$\int_{0}^{1} f^2(x)dx=1.$$ Find the value of $\int_{0}^{1} xf(x)f'(x)dx$? My approach : Let $I(x)$ be the antiderivative of $xf(x)f'(x)$ and $G(x)$ be the antiderivative of $f^2(x)$, here $f^2(x) = (f(x))^2$. We want to calculate $I(1)-I(0)$ and we know that $G(1)-G(0)=1.$ Then using integration by parts, 
$$\begin{align}
I(x)&=xf(x)\int f'(x)dx-\int \left(\int f'(x)dx\right)\left(\frac {d}{dx} xf(x)\right)dx \\
&=xf^2(x)-\int f(x)(xf'(x)+f(x))dx\\
&=xf^2(x)-I(x)-\int f^2(x)dx \\
\Rightarrow 2I(x)&=xf^2(x)-\int f^2(x)dx \\
\Rightarrow I(x)&=\frac {xf^2(x)-\int f^2(x)dx}2\\
&=\frac {xf^2(x)-G(x)}2.
\end{align}$$ $\displaystyle \therefore I(1)-I(0)=\frac {1f^2(1)-G(1)}2 - \frac {0f^2(0)-G(0)}2=-\frac {G(1)-G(0)}2=-\frac 12.$ In my approach above, I didn't apply hypothesis $f(0)=0$ anywhere. I didn't understand where I used the given fact that $f$ is a continuously differentiable function on $[0,1]$. So I feel that my solution is ambiguous. What are errors in my proof? Can the two hypotheses which I mentioned be dropped safely?","['real-analysis', 'proof-verification', 'integration', 'definite-integrals', 'contest-math']"
2542416,How to prove this integral inequality $ \int_0^{2\pi} p(x)[p(x)+p''(x)] dx \int_0^{2\pi}\frac{1}{p(x)+p''(x)} dx\geq 2\pi \int _0^{2\pi} p(x) dx $?,"Let $p\in C^2(\mathbb{R})$ be a $2\pi$-periodic function such that $p(x)>0$ and $p(x)+p''(x)>0$ for all $x\in \mathbb{R}$. Then it holds $$
\int_0^{2\pi} p(x)[p(x)+p''(x)] dx \int_0^{2\pi}\frac{1}{p(x)+p''(x)} dx\geq 2\pi \int _0^{2\pi} p(x) dx 
$$
The identity holds when $p+p''$ is a constant.","['real-analysis', 'inequality', 'integral-inequality']"
2542468,A basic question about upper and lower densities in Geometric Measure Theory [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question Let $\mathcal{E}$ be a $n$-dimensional Euclidean space with full dimensional Lebesgue measure $\mathcal{L}$. For $(X,x) \in 2^{\mathcal{E}} \times \mathcal{E}$, upper and lower densities of $x$ in $X$ are:
\begin{eqnarray}
d^{+}(X,x) := \limsup_{r \downarrow 0} \frac{\mathcal{L}(X \cap B(x,r)))}{\mathcal{L}(B(x,r))} \\
d^{-}(X,x) := \liminf_{r \downarrow 0} \frac{\mathcal{L}(X \cap B(x,r)))}{\mathcal{L}(B(x,r))}
\end{eqnarray}
where $B(x,r)$ are closed balls. Since $X \cap B(x,r) \subseteq B(x,r)$ then $\mathcal{L}(X \cap B(x,r)) \leq \mathcal{L}(B(x,r))$ it is reasonable to say that $d(X,x)\leq 1$ is always true. However, Mattila ""Geometry of sets and measures in Euclidean spaces"" at p. 90 does not exclude the existence of pairs $(X,x)$ for which density can be bigger than $1$. Specifically, in the proof of Thm. 6.2 he proves that the set of points with density bigger than $1$ has measure zero without proving that it is empty. Whereas for ""nice"" sets upper and lower densities exist, coincide and cannot be bigger than $1$, an arbitrary set may have points for which upper and lower densities do not agree, are bigger than $1$  or are not defined. Of course, the existence of such sets and points should be of a rather ""pathological"" nature but I would be interested to know if and to what extent it is possible to characterize the sets $X$ for which there are special points in the above sense.","['geometric-measure-theory', 'real-analysis', 'measure-theory']"
2542476,Random walk over a cube:Probability of returning back,"There is a cube and an ant is performing a random walk on the edges where it can select any of the 3 adjoining vertices with equal probability. What is the probability that ant is in the vertex it started with after N steps? What I tried-> Breaking problem to simpler one where we see distance from start vertex. So out of 8 vertices, we have 1 with distance 0(our start), 3 with distance 1, 3 with distance 2 and 1 with distance 3. Also, ant can only return back if N is even. So probability is 0 when N is odd.","['markov-chains', 'probability']"
2542508,Probability of choosing value of variable in equation - 4 tuple ($x_1 +x_2+x_3+x_4=10$),"It may be the wording in this problem that is throwing me off but I can't seem to figure out the number of possible successful outcomes to calculate the probabiliy: Suppose a non-negative integer solution to the equation $w+x+y+z=10$ is chosen at random (each one being equally likely to be chosen). What is the probability that in this particular solution that $w$ is less than or equal to 2? Let $A = w \leq 2 $ To find P(A) I need: \begin{align}
P(A)=\frac{|E|}{|S|}
\end{align} Where |E| = Successful outcomes and |S| = Size of sample space. I start by finding the sample space of possible solutions, since this is a 4 tuple: ${\{w,x,y,z\}}$ --  order does not matter and repeats are allowed,  I would say the size of sample space is \begin{align}
|S| = C(10+4-1,4) =C(13,4)
\end{align} So this gives me: \begin{align}
P(A)=\frac{|E|}{C(13,4)}
\end{align} However, I can't seem to figure out $|E|$ as I don't know how to account for all cases... I am guessing since there are 4 variables: $\{w,x,y,z\}$ and we assume $w$ is aleady chosen from the following: $\{0,1,2\}$ (since $w\leq 2$) this leaves us with 3 variables left to determine. The number of outcomes for this would look like: $$
\begin{array}{c|lcr}
case & \text{Number of outcomes} \\
\hline
0+x+y+z= 10  & C(10+3-1,3) = C(12,3) \\
1+x+y+z= 10  & C(10+3-1,3) = C(12,3)\\
2+x+y+z= 10  & C(10+3-1,3) = C(12,3) 
\end{array}
$$ This feels wrong.. or maybe I am overthinking it. But would the solution be: \begin{align}
P(A)=\frac{3 \cdot C(12,3)}{C(13,4)}
\end{align}","['combinatorics', 'probability', 'discrete-mathematics']"
2542518,Show that for a convex polyhedron the faces lighted by a point light source are entirely connected,"In $\Bbb R^3$ we have a closed convex polyhedron $P$ with triangularised faces (you may assume it's symmetric about the origin for simplicity.), and a point light source $s\notin P$. Let $F_{1,\cdots, m}$ be all of $P$'s faces, and $\pi_i$ be the plane that passes through $F_i$ respectively. Each $\pi_i$ cuts $\Bbb R^3$ into two open regions one of which contains the interior of $P$ while the other doesn't intersect $P$. For each $i$, we call the open region that doesn't intersect $P$ as $R_i$. Then we know that a face $F_i$ is lighted by $s$ if and only if $s\in R_i$. Now consider the collection $\mathcal F_s$ of all faces that are lighted by $s$. An illustration made in Matlab where the yellow point indicates the light source and faces coloured red are lighted faces (viewed from two different angles): I have to show that $\mathcal F_s$ is entirely connected , in the sense that any face in $\mathcal F_s$ must share an edge with at least one another face in $\mathcal F_s$ (which is slightly stronger than path connectedness, because in this case two faces connected only by a single point are not considered as connected), and that the union of all faces in $\mathcal F_s$ is simply connected. This is geometrically intuitive, but the proof turns out extremely hard for me. Having been working on it for a whole week, I still get virtually nothing of value. Could anybody help? PS: for what it's worth, it's 2D analog is very easy to prove, because edges of a convex polygon form a loop and we can make sense of a ""direction"" on it. But in 3D, the connectivity between faces is much more complicated. So I don't think there is an easy extension from 2D to 3D.","['convex-geometry', 'computational-geometry', 'convex-analysis', 'analytic-geometry', 'geometry']"
2542579,How to solve a functional equation $f(x+y)=f(x)+f(y)-f(0)$.,"I encountered in my research a functional equation that I'm not sure how to solve in general. It is similar to Cauchy's functional equation but includes an extra constant term of $-f(0)$. I'm not an expert in functional equations, so any help would be appreciated. The functional equation is $f(x+y)=f(x)+f(y)-f(0)$ This is actually a part of a pair of functional equations that $f$ has to satisfy, but I'm at first interested in just solving this first functional equation. The other equation is $f(-x)=-f(x)+2f(0)$, and $f$ has to satisfy both the above one and this other one. Clearly $f(x) = x$ solves the functional equations, as does any function of the form $f(x)=ax+b$, but are there any other solutions? Any help is much appreciated.","['functions', 'functional-equations']"
2542617,Domain of a solution of differential equation,"Given the following system of differential equations
\begin{equation}
\begin{cases}
\frac{dx}{dt}=-x+xy
\\\frac{dy}{dt}=-2y-x^2
\end{cases}
\end{equation}
I want to prove that the maximal solutions of the system are defined on all $\mathbb{R}$ and that
$$\lim_{t\rightarrow +\infty } {(x(t),y(t))}=0$$ As shown here I tried proceeding same way but I don't have any information about $t=0$.
$$x′x+y′y=-x^2-2y^2\leq 0$$
$$x′x+y′y= x'+y'\cdot x+y =\frac{1}{2}\frac{d}{dt}|| x+y ||^2$$
$$\frac{1}{2}\frac{d}{dt}|| x+y ||^2\leq 0$$
Hence I have information about the monotony, but I don't know how to show that, for example, the solution is limited on a subset of $\mathbb{R}$ (I could use this hypothesis to prolong the solution on all $\mathbb{R}$).","['real-analysis', 'ordinary-differential-equations', 'dynamical-systems', 'limits']"
2542634,Is the mean distance to a body's surface times its area always proportional to its volume?,"This question came up because the ideal gas law says that for, say, a gas enclosed in a bottle the pressure is: $ P \propto \frac{N \cdot T}{V}$ Where P: Pressure, N: Number of Gas particles in the bottle, T: Temperature and V: Volume of the bottle. I am only investigating the dependence on volume: The Pressure does not depend on the shape of the volume. I find it intuitive that the pressure would be inversely proportional to the bottle's surface area. I also find it plausible that the pressure would be inversely proportional to the average distance of a point inside the volume to the volume's surface, as the particles inside the volume will take more time to impinge on the surface (and cause a momentum transfer that causes pressure) the farther the particles are away from the bottle's surface. The average distance to the surface should be understood as the average over all points inside the volume and all solid angles subtending each point to the surface, and not averaged over the surface itself. This is because the average distance needed here should be a sum of the contributing distances weighed by the likelihood this distance will be traversed by a particle: This likelihood is identical for all directions. If one were to calculate the average by weighing the distances proportionally to the (infinitesimal) surface areas that are connected to the point whose average distance is being calculated, one would weigh those directions more that make a very small or large angle with the surface, as the solid angle cones intersect a larger piece of the surface there. I checked the conjecture for a sphere, and it seems to work, but I do not see how to extend this result to all ""well behaved"" volumes. Also, the proportionality factor between (Average Distance multiplied by Surface Area) and Volume would have to be identical for all body shapes....","['physics', 'geometry']"
2542639,What is the logic behind the digit sum formula?,"The digit sum of a number is the sum of the digits in the number. Let $n$ be a natural number. Then the digit sum of $n$ is $S(n)=\displaystyle\sum_{k=0}^{\lfloor{\log_{10} n}\rfloor}\frac{1}{10^k}\left(n\mod10^{k+1}-n\mod10^k\right)$, as is seen in this wiki page (I am interested in the base $10$ case only). I am aware that the number of digits in $n$ equals $\lfloor{\log_{10} n}\rfloor+1$ in base $10$. Numerous posts are there regarding how to write a computer code for finding the sum of digits in a given positive number. However, I haven't found any source of the digit sum formula and I want to know how it is derived. I just need the basic idea. Any link to a source would be great too.","['algebra-precalculus', 'elementary-number-theory']"
2542782,"Differentiability of $f(x)=\frac{x|y|}{\sqrt{x^2+y^2}}$ at $(0,0)$","Prove that $$\begin{array}\\&f(x)&=\begin{cases}\frac{x|y|}{\sqrt{x^2+y^2}}&\text{ if }(x,y) \ne (0,0)\\0&\text{ otherwise }\end{cases}\end{array}$$ is differentiable in $(0,0)$ . Proof: We know that $f$ is differentiable in $(0,0)$ , if all partial derivatives exist and are continuous in $(0,0)$ . We have $$\frac{\partial f}{\partial x}=\lim_{h\to\ 0}\frac{f(h,0)}{h}=0$$ $$\frac{\partial f}{\partial y}=\lim_{h\to\ 0}\frac{f(0,h)}{h}=0$$ So the partial derivatives exist. I am now stuck at proving the continuity of the partial derivatives in $(0,0)$ . Can anyone help me with that?","['multivariable-calculus', 'partial-derivative']"
2542821,What is the name for the shape formed by removing a square from the corner of a larger square?,"Squares of consecutive numbers differ by the sum of those numbers, so $6^2 = 5^2 + 5 + 6$.  Geometrically, this is because the difference between the two squares is a pair of strips, $5$ and $6$ units long, that together form L-shaped polygon. Is there a name for this L-shaped polygon?  I vaguely recall that the ancient Greeks had a name for this shape, but I can't find it anywhere.",['geometry']
2542976,Solve the eigenvalue problem $y''=\lambda y$ numerically,"I am trying to solve the eigenvalue problem 
$$\begin{cases} y''=\lambda y \\y(0)=y(1)=0\end{cases}$$
I use the finite difference to discretize the ODE with BVs. I get the following equation
$$\frac{y_{i-1}+2y_i+y_{i+1}}{(\Delta x)^2}=\lambda_{\Delta x}y_i,$$
where $\Delta x =1/{(n+1)}.$ Then I get the following $n \times n$ tridiagonal matrix formulation $\frac{1}{(\Delta x)^2}\begin{bmatrix}-2&1&~&~\\1&-2&1&~&~ \\~&~&\ddots\\ 
~&~&1&-2&1\\~&~&~&1&-2\end{bmatrix}\begin{bmatrix}y_1 \\y_2\\\vdots\\
y_{n-1}\\y_n\end{bmatrix}=\lambda_{\Delta x}\begin{bmatrix}y_1 \\y_2\\\vdots\\
y_{n-1}\\y_n\end{bmatrix}$ I know that the ODE has infinitely many eigenvalue values and eigenfunction. We can compute the eigenvalue numerically by computing the eigenvalues of the matrix on the LHS. I have two questions. Why can I only get the approximation of the first $n$th eigenvalue ($n\times n $ matrix) instead of the kth to $(k+n-1)$th eigenvalues? If I want to compute the $m$th eigenvalue, do I have to compute the eigenvalues of the $m\times m$ matrix ? When $m$ becomes very large, it needs a lot of computations. Do we have numerical method to compute the $m$th eigenvalue directively?","['numerical-methods', 'computational-mathematics', 'ordinary-differential-equations']"
2543090,Solve the Differential Equation : $y'' + \frac{L(x)}{2}y = 0 $,"Solve the $2$nd order differential equation :
  $$y'' + \frac{L(x)}{2}y = 0  $$ I have been looking at different methods as known integral , variation of parameters etc, but I don't know how to go about this equation. Please help.",['ordinary-differential-equations']
2543107,What is wrong in my solution attempt to the $80^\circ$-$80^\circ$-$20^\circ$ problem?,"I'm trying to solve the following famous problem: Here's my attempt, for some reason it leads to a contradiction, where have I gone wrong? Please do not give me any hints on how to solve the problem on a whole, as I want to solve it on my own. If I'm wrong I'll try another approach, but I'd like to know where I have went wrong.","['angle', 'geometry']"
2543125,How can I calculate the limit $\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2}$ without L'Hospital's rule?,I have a problem with calculation of the limit: $$\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2}$$ Is there a way to calculate it? How can I do it?,"['real-analysis', 'limits-without-lhopital', 'limits']"
2543135,Parametrising the surface enclosed by a parametric curve,"I have a curve given by $(\cos t, \sin t, \sin 2t)$ with $0 \leq t \leq 2\pi$: I need to integrate a function over any of the infinitely many surfaces to which this curve is a boundary. How would I find a parametrised form of such a surface?","['multivariable-calculus', 'parametric', 'surface-integrals', 'surfaces']"
