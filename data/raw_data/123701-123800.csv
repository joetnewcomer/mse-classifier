question_id,title,body,tags
1866160,Find the value of $\mathbb{E}(X_1+X_2+\ldots+X_N)$ of i.i.d random variables $X_i$s.,"Let $ X_1,X_2,X_3 ,\ldots$ be a sequence of i.i.d. random variables with mean $1$. If $N$ is a
  geometric random variable with the probability mass function $\mathbb{P}(N=k)=\dfrac{1}{2^k}$; $k=1,2,3,\ldots$ and it is independent of the $X_i$'s, then $\mathbb{E}(X_1+X_2+\ldots+X_N)=$? My work: Since mean of $X_i$s are $1$, so $\frac{X_1+X_2+\ldots+X_N}{N}=1$. Hence $\mathbb{E}(X_1+X_2+\ldots+X_N)=\mathbb{E}(N)=\sum_{k=1}^{\infty}k\mathbb{P}(N=k) = \sum_{k=1}^\infty \dfrac{k}{2^k}=2$. Is my solution correct? Is this the right process to do it? Help please. Thanks.","['probability-theory', 'expected-value']"
1866211,Do I have the right idea about affine connections?,"On a smooth manifold $M$, a vector field is a smooth map $X : M \to TM$, where $TM$ is the tangent bundle of $M$. If $\chi(M)$ denotes the space of vector fields on $M$, an affine connection $\nabla$ on $M$ is a mapping $\nabla : \chi(M) \times \chi(M) \to \chi(M)$ which (intuitively) creates a new vector field $\nabla_{X}Y$ given two vector fields $X$,$Y$. If I am correct, given $p \in M$, $\nabla_{X}Y(p)$ can be understood as the derivative of $X$ in the direction of $Y(p)$. 1) Consider that $M \subset \mathbb{R}^n$ to make things ""easier. Now, a vector field on $M$ is a smooth map $X : M \to \mathbb{R}^n$ (such that, for all $p$, $X(p) \in T_{p}M$). Given another vector field $Y$ and $p \in M$, the derivative of $X$ in the direction of $Y(p)$ could be (naively) $D_{p}X\big( Y(p) \big)$, where $D_{p}X : T_{p}M \to \mathbb{R}^n$ denotes the differential of $X$ at $p$. But this might not define an affine connection since $D_{p}X\big( Y(p) \big)$ is not necessarily a tangent vector, right ? 2) If $\gamma : I \subset \mathbb{R} \to M$ is a smooth curve and $X$ a vector field along $\gamma$, the covariant derivative $\frac{DX}{dt}$ of $X$ (namely $\nabla_{\frac{d\gamma}{dt}}X$) is defined to be the orthogonal projection on the linear space $T_{\gamma(t)}M$. However, this definition holds only because we implicitly assume that $M$ is equipped with the metric induced by $\mathbb{R}^n$, right ? In other words, if I'm correct and if $g$ is a Riemannian metric (which is not the metric induced by $\mathbb{R}^n$) on $M$, this definition of covariant derivative no longer makes sense.","['manifolds', 'riemannian-geometry', 'differential-geometry']"
1866295,Division of a square and value of a disk,"I cam across this problem and I really don't know how to solve it. So you start with a square that has value 1. You divide this square in 4 so that each new square has a new value, as given by the following picture : Then you divide again each square in 4 new squares by the same process, so that you obtain the following picture and data : Now put a circle inside the square : If you repeat the process of dividing each square in 4, each new square having a new value, what is the value of the disk ? I wrote a program allowing me to compute the value of the region outside the disk : I started with a square divided by $8 \times 8$ new squares and stopped at $2^{27} \times 2^{27}$. Here is the output of the algorithm giving the approximation of the value of the disk (it is 1- approximation of the region outside the disk) 9.000000000e-01 8.144000000e-01 7.626000000e-01 7.292020000e-01 7.088800000e-01 6.973523000e-01 6.918611000e-01 6.885892690e-01 6.869197714e-01 6.859950674e-01 6.855135614e-01 6.852518648e-01 6.851172864e-01 6.850433926e-01 6.850051560e-01 6.849844363e-01 6.849737746e-01 6.849678775e-01 6.849649240e-01 6.849632929e-01 6.849624579e-01 6.849620047e-01 6.849617754e-01 6.849616479e-01 6.849615847e-01 I was not able to find an explicit formula for the limit (does it exist ?). I also tried an exponential regression on the data but I was not really satisfied. Any hint ?","['problem-solving', 'recreational-mathematics', 'sequences-and-series', 'geometry']"
1866304,Find $\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx$,"Find: $$\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx$$ This is one of the problems i have to solve so that i could join college. I tried using integration by parts, i tried using notations but nothing works. If someone could please help me i would deeply appreciate it. ! thanks in advance ! I know the answer to the limit is 1. But i need help proving it.","['integration', 'calculus']"
1866313,OLS under Mean Independence,"Assume mean independence of the error term. Show that the OLS estimator is unbiased. Hint: use the Law of Iterated Expectations I am not quite sure if I understood the concept of 'mean independence'. So we have that $\mathbb{E}[\varepsilon \mid X]=0$. My proof would be as follows: $$\hat{\beta}=(X^TX)^{-1}X^Ty$$$$=(X^TX)^{-1}X^T(X\beta+\varepsilon )$$
$$=(X^TX)^{-1}X^TX\beta+(X^TX)^{-1}X^T\varepsilon $$
$$=\beta+(X^TX)^{-1}X^T\varepsilon$$ $$\implies\mathbb{E}[\hat{\beta}]=\beta+\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]$$
$$=\beta+\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$$
$$=\beta$$ My problem is whether I can write $\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]=\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$. My intuition says yes, because mean independence implies zero covariance and hence we can write the expectation as a product. However, I haven't used the LIE. Could anyone help me here?","['statistics', 'probability']"
1866394,Trying to understand $\mathbb E[X\mid \mathcal F]$ and Martingale concept,"Q1) Let $X$ a r.v. on a probability space $(\Omega ,\mathcal F,P)$ and $\mathcal G\subset \mathcal F$ a sub $\sigma -$algebra. What does $$\mathbb E[X\mid \mathcal G]\ \ ?$$
I understand what is $\mathbb E[X\mid Y]$ when $Y$ is an r.v., but not when it's a $\sigma -$algebra. Q2) Let $(M_t)$ a stochastic process adapted to the filtration $\{\mathcal F_t\}_t$. I know that $(M_t)$ is a martingale if $\mathbb E[|M_t|]<\infty $ and $$\mathbb E[M_t\mid \mathcal F_s]=M_s,\quad s\leq t.$$
Could you explain me what does mean the last condition ? I would interpret is that when $t>s$, it's enough to know $M_s$ to now $M_t$ given $\mathcal F_s$, but I have no intuition neither any idea of what it can mean.","['conditional-expectation', 'probability', 'martingales']"
1866395,How to derive Lobachevsky's formula for the angle of parallelism,I'm lightly studying some non-Euclidean Geometry and in the book I am reading there is no proof or derivation from where the Lobachevsky formula for angle of parallelism comes from: $$\Pi(x)=2\tan^{-1}\left(e^{-x}\right)$$ Any help? Thanks P.S. I couldn't find anything by google search either.,"['hyperbolic-geometry', 'noneuclidean-geometry', 'differential-geometry']"
1866414,"Finding ""the"" Marchenko-Pastur distribution in the original article of 1967","I am looking at distribution properties of eigenvalues of sample covariance matrices. Following the Wikipedia article on the Marchenko-Pastur distribution : Let $X$ denote a $M \times N$ random matrix whose entries are i.i.d. random variables with mean $0$ and variance $\sigma^2 < \infty$. Let
  $$
Y_ N = N^{-1}XX^T,
$$
  (which in a statistical context I can view as a sample covariance matrix) and let $\lambda_1, \lambda_2, \ldots, \lambda_M$ be the eigenvalues of $Y_N$ (viewed as random variables). Finally consider the random measure
  $$
\mu_M(A) = \frac{1}{M}\#\{\lambda_j \in A\},\, \, A \subset \mathbb{R}.
$$ Theorem. Assume that $M, N \rightarrow \infty$ so that the ratio $M/N \rightarrow \lambda \in (0,+\infty)$. Then $\mu_M \rightarrow \mu$ (in distribution), where
  $$
\mu(A) =\begin{cases} (1-\frac{1}{\lambda}) \mathbf{1}_{0\in A} + \nu(A),& \text{if } \lambda >1\\
\nu(A),& \text{if } 0\leq \lambda \leq 1,
\end{cases}
$$
  and
  $$d\nu(x) = \frac{1}{2\pi \sigma^2 } \frac{\sqrt{(\lambda_{+} - x)(x - \lambda_{-})}}{\lambda x} \,\mathbf{1}_{[\lambda_{-}, \lambda_{+}]}\, dx$$
  with
  $$ \lambda_{\pm} = \sigma^2(1 \pm \sqrt{\lambda})^2. \, $$ I then tried to align this statement with the original paper of Marchenko and Pastur (1967) . However, the setting there is far less clear to me (i.e., I do not immediately see the connection to the setting of sample covariance matrices): We shall consider as acting in $N$-dimensional unitary space $H_N$ a self-adjoint operator $B_N(n)$ of the form
  $$
B(n) = A_N + \sum_{i=1}^n \tau_i q^{(i)}(\cdot, q^{(i)}).
$$
  Here, $A_N$ is a nonrandom self-adjoint operator; $n$ is a nonrandom number; the $\tau_i$ are i.i.d. real random variables and the $q^i$ are mutually independent random vectors in $H_N$, independent also of the $\tau_i$. $(x, q^{(i)})$ denotes the inner product in $H_N$. ($\ldots$) We shall be interested in the function $\nu(\lambda; B_N(n))$ giving the ratio of the number of eigenvalues of $B_N(n)$ lying to the left of $\lambda$ to the dimension of space. $\nu(\lambda; B_N(n))$ is called the normalized spectral function of the operator $B_N(n)$. In the paper, on p. 458, there follow four assumptions I-IV, among them: I. The limit $\lim_{N\rightarrow \infty} n/N = c$, which for brevity we call the concentration exists. One now is interested in cases of very large $N$ and $n$ and the properties of the operator that ensure convergence in probability of $\nu(\lambda; B_N(n))$ to a nonrandom number $\nu(\lambda; c)$. The main result is then contained in Theorem 1 on p. 460, where the normalized spectral function is given in terms of its Stieltjes transform. This is followed by three examples on p. 461, where the function can even be given explicitely and of which I assume the first one applies in my case: 1) The sum of random independent and equally probable projections . Let $B_N(n) = \tau\sum_{i=1}^n P_i$, where each $P_i$ is a projection operator on the random vector $q^{(i)}$, independent and uniformly distributed on the unit sphere and $\tau$ is a nonrandom number. ($\ldots$) We find that $\nu(\lambda; c) = \nu_1(\lambda; c) + \nu_2(\lambda; c)$, where
  $$
\frac{d\nu_1(\lambda; c)}{d\lambda} =\begin{cases} (1-c)\delta(\lambda) & \text{for } 0 \leq c \leq 1,\\
0 & \text{for } c > 1,
\end{cases}
$$
  $$
\frac{d\nu_2(\lambda; c)}{d\lambda} =\begin{cases} \frac{\sqrt{4c\tau^2 - (\lambda -c\tau -\tau)^2}}{2\pi\tau\lambda} & \text{for } (\lambda-c\tau-\tau)^2 \leq 4c\tau^2,\\
0 & \text{for } (\lambda-c\tau-\tau)^2 > 4c\tau^2,
\end{cases}
$$ My question now is how to relate this to the example in the Wikipedia article, i.e. how to view the sample covariance matrix in the form $B_N(n) = \tau\sum_{i=1}^n P_i$ and how the two distributions agree. Moreover, the concentration $\lambda$ in Wikipedia seems to be the reciprocal value of the $c$ in the paper? Any help is appreciated! Many thanks,
P. Diaz","['functional-analysis', 'statistics', 'random-matrices']"
1866433,Two well orders on an uncountable set,"We have two well orders $\preceq_1, \preceq_2$ on an uncountable set $X$. Why would there be a set $Y\subseteq X$ such that $Y\restriction_{\preceq_1} = Y\restriction_{\preceq_2}$ and Y is uncountable? I'm trying and trying to come up with a proof but I don't see why that would be true at all. Say, I want to do it by induction. Then sure, I can choose two elements of $X$ such that they are in the same relation both with respect to $\preceq_1$ and $\preceq_2$. But why can I find a third element like this? Or $n$-th? Or $\gamma$-th... Perhaps there are no such.",['elementary-set-theory']
1866474,Prove the following trigonometric result,"If $\theta_1,\theta_2(0\leq\theta_1,\theta_2<2\pi)$  are two solutions of $\sin(\theta+\phi)=\frac{1}{2}\sin(2\phi)$, prove that $$\frac{\sin(\theta_1)+ \sin(\theta_2) }{ \cos(\theta_1)+ \cos(\theta_2)} =\cot\phi$$ I have tried with the following process: Since 
$\theta_1,\theta_2(0\leq\theta_1,\theta_2<2\pi)$  are two solutions of $\sin(\theta+\phi)=\frac{1}{2}\sin(2\phi)$, we have
 $\sin(\theta_i+\phi)=\frac{1}{2}\sin(2\phi)$, I=1,2. This gives
  $\sin\theta_i\cos\phi+ \cos\theta_i \sin\phi= \frac{1}{2}\sin(2\phi)$, I=1,2. I don't know what will be the next process.",['trigonometry']
1866488,Find conjugate prior of an exponential family distribution,"I read on Wikipedia that all exponential family distributions have conjugate priors. I have not, however, been able to find a reference that describes how to find it. So given $$f_X(x\mid\theta) = h(x) \exp \left (\theta^T \cdot T(x) -A(\theta)\right )$$ how do I find its conjugate prior? (In particular, I am trying to find the conjugate prior for a distribution that is the product of many binomials, which is also in the exponential family:
\begin{align}
P(\Phi=\{\phi_1, \cdots, \phi_k\}|X=\{(d_1, v_1), \cdots, ... (d_k, v_k)\}) =\prod\limits_{j=1}^k\binom{d_{j}}{v_{j}} \left(\phi_{j}\right)^{v_{j}} \left(1 - {\phi}_{j}\right)^{{d}_{j} -{v}_{j}}
\end{align}
).","['probability-theory', 'probability-distributions', 'bayesian', 'statistics', 'probability']"
1866502,Closed form for $\sum_{n=1}^{\infty}\frac{1}{\sinh^2\!\pi n}$ conjectured,By trial and error I have found numerically $$\sum_{n=1}^{\infty}\frac{1}{\sinh^2\!\pi n}=\frac{1}{6}-\frac{1}{2\pi}$$ How can this result be derived analytically?,"['summation', 'sequences-and-series', 'calculus', 'closed-form']"
1866538,Intuition for Fredholm operators?,"Alot of the material I'm reading lately seems to mention Fredholm operators and the 'Fredholm alternative' and operators being 'Fredholm of index $0$'. Can someone give me a high level overview of what's the reason for caring whether an operator is Fredholm or not? What does it enable us to do with the operator? Is being Fredholm of index $0$ a good thing or a bad thing? Would be prefer an operator to be, say, Fredholm of index $2$ for example?","['functional-analysis', 'integral-equations', 'operator-theory', 'partial-differential-equations']"
1866546,Extreme points of the unit ball of the space $c_0 = \{ \{x_n\}_{n=1}^\infty \in \ell^\infty : \lim_{n\to\infty} x_n = 0\}$,"I want to prove that all ""closed unit ball"" of
$$
c_0 = \{ \{x_n\}_{n=1}^\infty \in \ell^\infty : \lim_{n\to\infty} x_n = 0\}
$$
do not have any extreme point. Would you please help me? (Extreme Point) Let $X$ be a vector space and $A \subset X$ be convex. We say $x\in A$ is an extreme point if for $x = (1-t)y + tz,\; y,z,\in A, \;t\in(0,1)$ then $y = z = x$. What I tried is as follows: Let $B$ be a closed unit ball of $c_0$, that is, $$B = \{\{x_n\}_{n=1}^\infty \in \ell^\infty : \lim_{n\to \infty} x_n = 0 \text{ and } \|x\|_{\ell^\infty}\le 1\}.$$
If there is a extreme point $b = \{b_n\}_{n=1}^\infty\in B$, then we have for
$$
b = (1-t)y + tz, \quad y,z\in B,\quad t\in (0,1)
$$
implies
$$
y = z = b.
$$
But I cannot do anymore here. Would you please help me?","['functional-analysis', 'real-analysis', 'convex-analysis']"
1866591,"Show that if $H$ is a subgroup of $S_n$, then either every member of $H$ is even or half of them are even","Show that if $H$ is a subgroup of $S_n$ the symmetric group of order $n$, then either every member of $H$
is an even permutation or exactly half of the members are even. I can see that if $a,b$ are arbitrary even elements in $H$, then their product and any combination of their products will be even, which implies $H$ is full of even permutations, but I'm not sure how to show the half-even half-odd part.","['abstract-algebra', 'group-theory']"
1866621,How to solve $y''+y=x^2$?,"I need to solve: $$y''+y=x^2$$ Taking the Laplace transform  (and using the fact that it is a linear operator) on both sides I get: $$\mathscr{L}(y)=\frac{2}{s^3(s^2+1)}+y(0)\frac{s}{s^2+1}+y'(0)\frac{1}{s^2+1}$$ And hence: $$y=2G(x)+y(0)\cos x +y'(0)\sin x$$ Where $G(x)$ is the inverse Laplace transform of: $$\frac{1}{s^3(s^2+1)}$$ My question is how do I find this inverse Laplace transform, I'm used to splitting the fraction into partial fractions but I don't think I'm used to doing a partial fraction like in the above.","['ordinary-differential-equations', 'laplace-transform']"
1866625,Characterization of compact operators by their spectra,In any functional analysis book there is usually a section devoted to the study of the properties of the spectrum of compact operators. Is there any spectral characterization of compact (self-adjoint) operators? Here is an example of what I have in mind Suppose $T$ is a bounded self-adjoint operator whose eigenvalues have finite multiplicity and $0$ is the only limit point of its spectrum. Then (perhaps with some more spectral conditions) $T$ is a compact operator. Thanks!,"['functional-analysis', 'compact-operators', 'spectral-theory', 'operator-theory']"
1866630,For which values of $n$ the sum $\sum_{k=1}^n k^2$ is a perfect square?,"Question. For which values of $n$ the sum $\sum_{k=1}^n k^2$ is a perfect square ? Clearly, $n=24$ is one such value, and I was wondering whether this is the only value for which the above holds. The question is equivalent to finding the positive integer solutions of the Diophantine equation
$$
n(n+1)(2n+1)=6N^2.
$$
The first thing to observe is that the numbers $n,n+1$ and $2n+1$ are pairwise relatively prime, and one we divide one of the them by 2 and one of the them by 3, the resulting three numbers should all be perfect squares. This leads to a combination of Pell's equations. It seems to me that there should be a simpler way to solve it.","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1866643,"Limits of $a_n, b_n, c_n$","Three given positive $a_1, b_1, c_1$, such that $a_1+b_1+c_1=1, \forall\ n,$
    $$a_{n+1}=a_n^2+2b_nc_n, b_{n+1}=b_n^2+2a_nc_n, c_{n+1}=c_n^2+2a_nb_n$$
    Prove $\{a_n\},\{b_n\}$ and $ \{c_n\} $ are convergent. I have noticed that if I add three equalities together, then get 
$$a_{n+1}+b_{n+1}+c_{n+1}=(a_n+b_n+c_n)^2$$
This means $\forall \ n, a_n+b_n+c_n=1$.
Also, I get 
$$a_{n+1}-b_{n+1}=(a_1-b_1)\prod_{i=1}^n(1-3c_i).$$
But I don't know how to continue proving they are convergent? Sincerely thanks for our help.","['sequences-and-series', 'limits-without-lhopital', 'limits']"
1866647,Another way to evaluate $\int\frac{\cos5x+\cos4x}{1-2\cos3x}{dx}$?,"What I've done is this:$$\int\dfrac{\cos5x+\cos4x}{1-2\cos3x}{dx}$$
$$\int \dfrac{\sin 3x}{\sin 3x}\left[\dfrac{\cos5x+\cos4x}{1-2\cos3x}\right]{dx}$$
$$\dfrac {1}{2}\int\dfrac{\sin 8x -\sin 2x +\sin 7x -\sin x}{\sin 3x - \sin 6x}$$
$$-\dfrac {1}{2}\int\dfrac{ \sin \frac{7x}{2} +\sin \frac{5x}{2} } {\sin \frac{3x}{2} }$$
$$-\int\dfrac{ \sin {3x}\cos \frac{x}{2} } {\sin \frac{3x}{2} }$$
$$-\int\dfrac{2\sin \frac{3x}{2} \cos \frac{3x}{2}\cos \frac{x}{2} } {\sin \frac{3x}{2} }$$
$$-\int {2\cos \frac{3x}{2}\cos \frac{x}{2} }$$
$$ -\left(\frac{\sin 2x}{2} +\sin x \right) +c $$
Is there any other way to do so ? Is it possible to do it by substitution ?","['indefinite-integrals', 'integration', 'closed-form']"
1866656,Is it possible to endow $\text{GL}_2(\Bbb R)$ with a ring structure?,"My question is the following: Is it possible to find a binary operation $*$, seen as an addition, such that $(\text{GL}_2(\Bbb R),*,\cdot)$ has a ring structure (not necessarily with a unit)? [We are given the multiplication of the ring, and we are searching for the addition.] I remember that these questions are pretty similar: (1) , (2) , but in that case we are asked whether an abelian group $(A,+)$ admits a ring structure. This question asked whether the abelian group $(\text{GL}_1(\Bbb Q),\cdot)$ admitted a ring structure $(\text{GL}_1(\Bbb Q),\cdot, \star)$, which is a bit different from my question. I tried to think what the characteristic of such a ring could be (in the case it has a unit). I also tried to find what $(\text{GL}_2(\Bbb R),\cdot)$ was isomorphic to, in order to eventually transport the structure of another ring... without any success. Thank you for your help!","['matrices', 'abstract-algebra', 'ring-theory']"
1866663,What is the problem in my computation of $\sin 18^{\circ}$?,"I needed to compute $\sin 18^{\circ}$. Now, these two relations hold for every $x$: $\cos 5x=16\cos^5x-20\cos^3x+5\cos x$ $\sin5x=16\sin^5x-20\sin^3x+5\sin x$, which can be easily proved using the multiple angle formulae. Now, one thing to observe is : $\sin5(18^{\circ})=1$ and $\cos5(18^{\circ})=0$ So, $$\begin{align}16\cos^518^{\circ}-20\cos^318^{\circ}+5\cos18^{\circ}&=0 \\\implies16\cos^418^{\circ}-20\cos^218^{\circ}+5&=0 \tag{1}
\end{align}$$
And, 
$$\begin{align}16\sin^518^{\circ}-20\sin^3+5\sin18^{\circ}&=1\\
\implies16\sin^418^{\circ}-20\sin^218^{\circ}+5&=\dfrac{1}{\sin18^{\circ}} \tag{2}
\end{align}$$ So, before moving forward with my computation, I would like to ask: Is there any problem in these two equations? Now, equation (1) consists of squares of cosines, which clearly means that (1) can be represented consisting of sines like this: $$\begin{align}16\cos^418^{\circ}-20\cos^218^{\circ}+5 &=0\\
\implies16(1-\sin^218^{\circ})^2 -20(1-\sin^218^{\circ})+5&=0 \\
\implies 16\sin^418^{\circ}-12\sin^218+1&=0
\end{align}$$ Now, using the above equation, we can easily deduce that $\sin^218=\dfrac{12\pm4\sqrt5}{32}=\dfrac{3\pm\sqrt5}{8}$. Now, if I put this value in equation (2), I get something like this: $\dfrac{1}{\sin18^{\circ}}=16\dfrac{(3\pm\sqrt5)^2}{64}-20\dfrac{(3\pm\sqrt5)}{8}+5$, which reduces to $1\mp\sqrt5$, which upon solving does not give me the correct value for $\sin18^{\circ}$. So, what mistake am I doing here? Edit: By solving, I mean that the actual value of $\sin18^{\circ}=\dfrac{\sqrt5-1}{4}$, but in my computation, the negative $1$ and the denominator $4$ is missing.",['trigonometry']
1866677,Proving that $\sin(1/x)$ is not continuous at 0,"Let $f(x) = \begin{cases}
0 &\text{ if $x=0$}\\
\sin(1/x) &\text{ otherwise}
\end{cases}$ . Prove that $f$ is discontinuous at $0$ My proof goes like this: for the function to be continuous at 0, the following limit: $\lim_{x\to 0}(\sin(1/x))$ needs to exist and be equal to 0. Let $1/x=k$ , I rewrite the limit expression as: $\lim_{k\to\infty}(\sin(k))$ . And since this limit oscillates, the limit does not exist. Therefore f(x) is not continuous at 0. Am I correct?","['continuity', 'real-numbers', 'solution-verification', 'limits']"
1866709,Integral of solid angle of closed surface from the exterior,"Jackson derives Gauss's Law for electrostatics by transforming the surface integral of the electric field due to a single point charge over a closed surface into the integral of the solid angle, demonstrating that the integral depends only on the charge enclosed by the surface. $$\mathbf{E}\cdot\mathbf{n}\, da = q\frac{cos\theta}{r^2}\,da$$ $$\mathbf{E}\cdot\mathbf{n}\, da = q\, d\Omega$$ And, apparently, it is ""easy to see"" that $$\oint_S \mathbf{E}\cdot\mathbf{n}\,da=\begin{cases}\begin{align}&4\pi q & ~~~~~~~~~~~~~~~~~~~~&\text{if q lies inside S} \\&0 & ~~~~~~~~~~~~~~~~~~~~~& \text{if q lies outside S}\\\end{align}\end{cases}$$ Now, intuitively, this is pretty obvious, but I have no idea how to demonstrate that the integral of the solid angle of some closed surface at a point outside the surface is equal to zero. Even inside the surface, I wouldn't know how to show that the integral is equal to $4\pi$  for an implicit function $f(r,\theta,\phi)=c$ where I can't just use the spherical Jacobian transformation. I'd like to be able to somehow generically parameterize a closed surface, or find a generic Jacobian for the surface area element, but it's just really not clear where to begin. I'd like to be able to show that $$\frac{\hat{r}\cdot\hat{n}\,da}{r^2} = \nabla\times A$$ when the point P is outside the surface, but no approach is presenting itself. Thanks","['solid-angle', 'physics', 'differential-geometry', 'vector-analysis']"
1866749,"If $5\sqrt [ x ]{ 125 } =\sqrt [ x ]{ { 5 }^{ -1 } } $, then $x$ equals $-4$","For the equation $$5\sqrt [ x ]{ 125 } =\sqrt [ x ]{ { 5 }^{ -1 } } $$ $x$ is equal to $-4$, but I'm not sure why. I've taken the right side of the equation ${ \left( \frac { 1 }{ 5 }  \right)  }^{ \frac { 1 }{ x }  }$ and converted it to $5^{-(1/x)}$, but haven't been able to perform the mathematical gymnastics to prove this.",['algebra-precalculus']
1866757,Not understanding derivative of a matrix-matrix product.,"I am trying to figure out a the derivative of a matrix-matrix multiplication, but to no avail. This document seems to show me the answer, but I am having a hard time parsing it and understanding it. Here is my problem: We have $\mathbf{D} \in \Re^{m n}$ , $\mathbf{W} \in \Re^{m q}$ , and $\mathbf{X} \in \Re^{q n}$ . Furthermore, $\mathbf{D} = \mathbf{W}\mathbf{X}$ . (NOT an element wise multiplication - a normal matrix-matrix multiply). I am trying to derive the derivative of $\mathbf{D}$ , w.r.t $\mathbf{W}$ , and the derivative of $\mathbf{D}$ , w.r.t $\mathbf{X}$ . My class note this is taken from seems to indicate that $$
\frac{\delta \mathbf{D}}{\delta \mathbf{W}} = \mathbf{X}^{T} \text{ and that } \frac{\delta \mathbf{D}}{\delta \mathbf{X}} = \mathbf{W}^{T}, 
$$ but I am floored as to how he derived this. Furthermore, in taking the derivatives, we are asking ourselves how every element in $\mathbf{D}$ changes with perturbations by every element in, say, $\mathbf{X}$ , - so wouldn't the resulting combinations blow up to be a-lot more than what $\mathbf{W}^{T}$ has? I cant even see how the dimensionality is right here. EDIT: Id like to add the context of this question. It's coming from here , and here is my marked screen-shot of my problem. How are they deriving those terms? (Note: I understand the chain-rule aspect, and I am not wondering about that. I am asking about the simpler intermediate step). Thanks.","['matrices', 'matrix-calculus', 'calculus', 'derivatives']"
1866771,"A limit in a Feynman ""proof"" about Fermat's Theorem.","As perhaps some of you already know, Richard P. Feynman, the famous physicist tried a non-orthodox (in his usual way, I suppose) proof of the Fermat's Last Theorem. He tried a probabilistic ""proof"" that no rigurous mathematician in the world would have accepted, but that shows his enormous creativity and insights. It is very well explained here: http://www.lbatalha.com/blog/feynman-on-fermats-last-theorem I have followed the derivation of Mr. Luis Batalha, but at some point he challenges the reader to prove that the value: $$c_{n} = \int_{1}^{\infty}\int_{1}^{\infty}(u^{n} + v^{n})^{-1 + \frac{1}{n}} \, du\,dv $$ when $n \to \infty $ is approximately $1/n$ ($c_{n} \approx 1/n$). Well, Mr. Batalha says that for big $n$ tends to $1/n$, and I think we can say for $n \to \infty$. I'm afraid I have tried to solve the limit but I am clueless. Thank you and congratulations to Mr. Batalha for such an interesting post. EDIT: Typo in the definition of $c_{n}$, the low limit of the integral is 1, not 0 as it was before. I'm afraid the typo is also present in the link. EDIT 2: When I asked this question a few days ago, I couldn't imagine so many rich and fruitful comments and answers. Thank you to all. I am going to let the question open for a few days more if someone wants to continue adding solutions. I think all the comments have been superb. I think I am goingo to choose the answer by @tired. Thank you all.","['physics', 'integration', 'mathematical-physics', 'limits']"
1866778,clarity on empirical probability,"My definition of empirical probability: Let $(X_1,\ldots,X_n)$ be a random sample of i.i.d random variables. Then, the empirical probability for a subset A contained in the sample space $\Omega$ is $P_n(A)=\frac{1}{n}\sum_{i=1}^n \mathbb{1}(X_i \in A).$ Fine. What I don't get is that $P_n(A)$ is a random variable for a fixed event A. Therefore, won't it have it's own (theoretical) probability distribution? My understanding of empirical probability with an example: Say you roll a 6 sided die and you introduce the random variable X, where X=1 if you roll a $1$, $X=2$ if you roll a $2$ etc. You don't know anything about how $X$ is distributed (it may or may not be a fair die for example). Roll the same die $n$ times, producing the random sample $(X_1,\ldots,X_n)$ Let $A=\{1\}$ and $P(X \in A)=p$. By defintion, $P_n(A) = \{\text{counting the number of times 1 appears}\}/n$. Since the indicator function in this case is a random variable that has a Bernoulli distribution with parameter $p$, $nP_n(A)$ is just a random variable that has a binomial distribution with parameters $p$ and $n$. Why then is the empirical probability called ""empirical"" as if to suggest its distribution would be generated by experiment? I kind of just view this as related to (if not a generalization of) the sampling distribution of sample proportions, where $X_i$ are not necessarily Bernoulli.","['statistics', 'probability-distributions']"
1866779,Sum of roots rational but product irrational,"Suppose that $x_1,x_2,x_3,x_4$ are the real roots of a polynomial with integer coefficients of degree $4$, and $x_1+x_2$ is rational while $x_1x_2$ is irrational. Is it necessary that $x_1+x_2=x_3+x_4$? For example, the polynomial $x^4-8x^3+18x^2-8x-7$ has roots $$x_1=1-\sqrt{2},x_2=3+\sqrt{2},x_3=1+\sqrt{2},x_4=3-\sqrt{2}.$$
It holds that $x_1+x_2$ is rational while $x_1x_2$ is irrational, and we have $x_1+x_2=x_3+x_4$.","['algebra-precalculus', 'polynomials']"
1866783,What is the probability that $7$ cards are chosen and no suit is missing?,"Cards are drawn one by one from a regular deck ($13$ cards for each of the
  $4$ suits). If $7$ cards are drawn, what is the probability that no suit will be
  missing? Ok, so I tried the approach where I choose the $1$ suit out of $4$ and then I don't know what do next. I dont know how am I supposed to arrange the cards in such a random manner, and I found the total which is obvious, $52$ choose $7$.",['probability']
1866796,"If $\sin x + \sin y = 1$ and $\cos x + \cos y = 0$, solve for $x$ and $y$","$\sin x + \sin y = 1$ $\cos x + \cos y = 0$ Any valid pair of $(x, y)$ is fine, as the restrictions on the board in the image below are obscured. I got the question from chapter 26 of a comic called Yamada-kun. How can I solve this equation?",['trigonometry']
1866832,Categorical Interpretation of Strongest/Weakest Topology,"One way to define the product topology is as the weakest topology for which all projection maps are continuous. Strongest/weakest topologies satisfying a given property are ubiquitous in topology and functional analysis: for example, the subspace topology can also defined as the weakest topology making all inclusion maps continuous. If we define a partial order under inclusion on the collection of all possible topologies for a given set, then the strongest/finest topology satisfying a given property is the least upper bound of the subset of topologies satisfying that property, and the weakest/coarsest topology satisfying a given property is the greatest lower bound of the subset of topologies satisfying that property. I know that a binary join (least upper bound) is a category theoretic binary coproduct, and that a binary meet (greatest lower bound) is a category theoretic binary product. And category theoretic products/coproducts are defined via a universal mapping property, thus they are a type of generalization of terminal/initial objects, respectively. In fact, when the condition the topologies need to satisfy is the continuity of a family of functions $f$, then the strongest topology satisfying that property is called the final topology, which would correspond nicely to it being a join/coproduct/terminal object. Likewise, weak topologies are also called initial topologies. Question: So are strongest/weakest topologies just a special case of initial/terminal objects, respectively? I believe this is a generalization of the following questions: Request for gentle explanation of defining a topology with its universal property Proof: Categorical Product = Topological Product Is my understanding of product sigma algebra (or topology) correct?","['category-theory', 'general-topology', 'order-theory']"
1866843,I want to prove that $C_0(X)$ is Banach,"Let $X$ be locally compact Hausdorff space. I'm trying to prove that
$$
C_0(X)=\{ f:X\to \mathbb{C} \; | \; f \text{ is continuous and }\forall \epsilon>0 \; \exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K\}
$$
is complete space with $\sup$ norm.
I tried as follows: Let $f_n$ be a Cauchy sequence in $C_0(X)$. Then for all $x\in X$,
$$
|f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty \to 0
$$
as $n,m\to \infty$. So $\{f_n\}$ is Cauchy in $\mathbb C$ and therefore the limit $f(x) := \lim_{n\to \infty} f_n(x)$ exsits. Now I'm trying to show that this $f(x)$ satisfies $f\in C_0(X)$ and $\|f - f_n\|_\infty \to 0$ as $n\to \infty$. (1) Continuity: Since $\forall \epsilon>0$, $\exists N$: $\forall n,m\ge N$, $\forall x \in X, $ $|f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty < \epsilon$,
taking $m\to \infty$, we have $|f_n(x) - f(x)| \le \epsilon$ so that $\{f_n\}$ converges uniformly to $f$ on $\mathbb C$, therefore $f$ is continuous. (2) $\forall \epsilon>0 $ $\exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K$ Since $f_N \in C_0(X)$, $\exists K$(compact) $\subset X$ s.t. $|f_N|< \epsilon$ on $X\setminus K$. So $$
|f| \le |f-f_N| + |f_N| \le \epsilon + \epsilon = 2\epsilon.
$$ (3) From (1), we have $|f_n(x) - f(x)| \le \epsilon $ for $n \ge N$. So $\| f_n - f\|_\infty \le \epsilon$. I'm wondering that my proof is correct or not. Would you please confirm my solution? In fact, I'm wondering that $2\epsilon$ argument works or not in (2). Also I think I did not use the property that $X$ is locally compact and Hausdorff in my solution.","['functional-analysis', 'real-analysis']"
1866848,"Integrating $e^{a\cos(\phi_1-\phi_2)+b\cos(\phi_1-\phi_3)+c\cos(\phi_2-\phi_3)}$ over $[0,2\pi]^3$","I am trying to integrate the following function. (it arises in channel modeling in wireless communications, Rayleigh random variables)..Any help is appreciated.Thanks $$\int_0^{2\pi}\int_0^{2\pi}\int_0^{2\pi}e^{a\cos(\phi_1-\phi_2)+b\cos(\phi_1-\phi_3)+c\cos(\phi_2-\phi_3)}d\phi_1d\phi_2d\phi_3$$","['multivariable-calculus', 'integration', 'definite-integrals']"
1866861,"Is there a topology such that $(\Bbb R, +, \mathcal T)$ is a compact Hausdorff topological group?","I already know that this is impossible for $(\Bbb Q, +, \mathcal T)$ to be a compact Hausdorff topological group (notice that the trivial topology does not work because it is not Hausdorff). Indeed, this follows from Baire theorem: for if $(\Bbb Q, +, \mathcal T)$ were a compact Hausdorff topological group, then $\Bbb Q$ would be the union of the countable collection of closed sets $\{r\}$ (with $r \in \Bbb Q$).
As we have a locally compact Hausdorff space, Baire theorem tells us that at least one of the closed set has non empty interior, i.e. some $\{r\}$ is open.
Since we have a topological group, it follows that $(\Bbb Q, +, \mathcal T)$ is discrete and hence non compact. But what about $(\Bbb R, +, \mathcal T)$ ? My first idea was to use the group (and even vector spaces) isomorphism $\Bbb R \cong \Bbb Q^{(\Bbb N)}$. Transporting the topology $\mathcal T$ on $\Bbb Q^{(\Bbb N)}$ preserves compactness, and we could try to use the projection $\Bbb Q^{(\Bbb N)} \to \Bbb Q$. But I was not sure what to do then. Any comment would be appreciated!","['general-topology', 'topological-groups']"
1866910,"Real Analysis, Folland Theorem 3.27 Properties of functions of Bounded Variation","Background Information: Taking $a = -\infty$ and considering the total variation as a function of $b$ . To with $F:\mathbb{R}\rightarrow \mathbb{C}$ and $x\in\mathbb{R}$ , we define $$T_F(x) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},-\infty < x_0 < \ldots < x_n = x\}$$ $T_F$ is called the total variation of $F$ . We observe that the sums in the definition of $T_F$ are made bigger if the additional subdivision points $x_j$ are added. Hence, if $a < b$ , the deinition of $T_F(b)$ is unaffected if we assume that $a$ is always one of the subdivision points. It follows that $$T_F(b) - T_F(a) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},a = x_0 < \ldots < x_n = b\}$$ Thus $T_F$ is an increasing function with values in $[0,\infty]$ . If $T_F(\infty) = \lim_{x\rightarrow \infty}T_F(x)$ is finite, we say that $F$ is of bounded variation on $\mathbb{R}$ , and we denote the space of all such $F$ by $BV$ . More generally, the supremum on the right side is called the total variation of $F$ on $[a,b]$ . It depends only on the values of $F$ on $[a,b]$ , so we may define $BV([a,b])$ to be the set of all functions on $[a,b]$ whose total variation on $[a,b]$ is finite. Theorem 3.23 - Let $F:\mathbb{R}\rightarrow \mathbb{R}$ be increasing, and let $G(x) = F(x^+)$ . a.) The set of points at which $F$ is discontinuous is countable. b.) $F$ and $G$ are differentiable a.e., and $F' = G'$ . 3.25 Examples: a.) If $F:\mathbb{R}\rightarrow \mathbb{R}$ is bounded and increasing, then $F\in BV$ (in fact, $T_F(x) = F(x) - F(-\infty)$ ). b.) If $F,G\in BV$ and $a,b\in\mathbb{C}$ , then $aF + bG\in BV$ . Lemma 3.26 - If $F\in BV$ is real-valued, then $T_F + F$ and $T_F - F$ are increasing. Question: Theorem 3.27 a.) If $F\in BV$ if and only if $Re F \in BV$ and $Im F \in BV$ . b.) If $F:\mathbb{R}\rightarrow \mathbb{R}$ , then $F\in BV$ if and only if $F$ is the difference of two bounded increasing functions; for $F\in BV$ these functions may be taken to be $(\frac{1}{2}(T_F + F)$ and $\frac{1}{2}(T_F - F)$ . c.) If $F\in BV$ , then $F(x^+) = \lim_{y\searrow x}F(y)$ and $F(x^-) = \lim_{y\nearrow x}F(y)$ exists for all $x\in\mathbb{R}$ , as do $F(\pm\infty) = \lim_{y\rightarrow \pm\infty}F(y)$ . d.) If $F\in BV$ , the set of points at which $F$ is discontinuous is countable. e.) If $F\in BV$ and $G(x) = F(x^+)$ , then $F'$ and $G'$ exist and are equal a.e. Proof a.) I am sort of confused how I should show that $Re F \in BV$ and $Im F \in BV$ from just supposing $F\in BV$ . I know that if $F\in BV$ then $\lim_{x\rightarrow \infty}T_F(x) = T_F(\infty) < +\infty$ . But I am not sure how to add the real and imaginary parts of $F$ to show that they are also of bounded variation. Proof b.) Suppose $F\in BV$ then $\lim_{x\rightarrow \infty}T_F(x) = T_F(\infty) < +\infty$ and from Example 3.25 we can write $$F = \frac{1}{2}(T_F + F) - \frac{1}{2}(T_F - F)$$ For the converse, I don't understand how if $F$ is taken to be the difference of these two increasing functions would should that $F\in BV$ . What Folland does is refer back to the proof of Lemma 3.26 and states the inequalities for $x < y$ $$T_F(y) \pm F(y) \geq T_F(x) \pm F(x)$$ implies that $$|F(y) - F(x)| \leq T_F(y) - T_F(x) \leq T_F(\infty) - T_F(-\infty) < \infty$$ ok... so this shows that $F$ and $T_F\pm F$ is bounded. But how is Folland using the difference of $F$ to show that $F\in BV$ ? For c,d,e Folland states that the result follows from a,b and Theorem 3.23. I can see how d and e may follow from Theorem 3.23 (not sure how to prove it though) but I don't see how the above results follow to prove c. I am pretty lost with this theorem any suggestions is greatly appreciated.","['real-analysis', 'measure-theory']"
1866974,Rank of a lower triangular block matrix,"For $$A= \begin{bmatrix}B&0\\C&D\end{bmatrix}$$
where $B, C, D$ are matrices that may be rectangular, is it true or false that $$\text{rank}(A)=\text{rank}(B)+\text{rank}(D)$$ I think that if $C=0$ this is true since the rank of A is the number of linear independent columns, which is the number of linear independent columns of B and of D, but does C affect this relationship? Or is it still true that $\text{rank}(A)=\text{rank}(B)+\text{rank}(D)$ when C is nonzero?","['matrices', 'matrix-rank']"
1867012,What Stochastic Calculi Other Than Ito And Stratonovich Exist?,"When learning about stochastic calculus, you typically encounter Ito and Stratonovich calculi, usually in that order. There are many differences between the two (Ito processes have better martingale and Markov properties, while Stratonovich processes obey the chain rule from ordinary calculus), but at the fundamental level, these differences stem from how the integrals of each calculus is defined: The Ito calculus is just integration using the forward Euler scheme: $$dX_t=a(t,X_t)dt + b(t,X_t)dW_t \Rightarrow$$ $$ X_t-X_0=\lim_{\Delta t\to 0}\Big(\sum_{n} a(t_n,X_{t_n}) (t_{n+1}-t_n) + \sum_{n} b(t_n,X_{t_n}) (W_{t_{n+1}}-W_{t_n}) \Big)$$ The Stratonovich calculus is just integration using the Trapezoidal rule: $$dX_t=a(t,X_t)dt + b(t,X_t)\circ dW_t \Rightarrow$$ $$ X_t-X_0=\lim_{\Delta t\to 0}\Big(\sum_{n} \frac{a(t_{n+1},X_{t_{n+1}})+a(t_{n},X_{t_{n}})}{2} (t_{n+1}-t_n) + \sum_{n} \frac{b(t_{n+1},X_{t_{n+1}})+ b(t_n,X_{t_n})}{2} (W_{t_{n+1}}-W_{t_n}) \Big)$$ (The above are just rough sketches, especially the sum bounds. I denote Brownian motion by $W_t$, and $\Delta t=t_{n+1}-t_n$ is assumed constant above even though the actual time mesh is unimportant) So...what happens if I choose another integration method, like Simpson's rule? Runge-Kutta? (I remember from Kloeden and Platen that R-K is not possible for some reason) Backward Euler? Et cetera? Is it even possible to do so? Will I end up with something reducible to Ito or Stratonovich, does it lead to ""garbage"" calculi (i.e. nothing of interest), or is there some other useful calculus out there?","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'numerical-methods', 'stochastic-calculus']"
1867020,How to prove that a sum of $\cosh(kx)$ is equal to a formula? [duplicate],This question already has answers here : Sum of $\cos(k x)$ [duplicate] (2 answers) Closed 7 years ago . I need to prove that $$\sum_{k=0}^{n}\cosh(kx) = \frac{\sinh((n+1/2)x) + \sinh(x/2)}{2\sinh(x/2)}$$ Can you help me out? How do I even start?,"['spherical-trigonometry', 'summation', 'trigonometry']"
1867062,Find the common divisors of $a_{1986}$ and $a_{6891}$,"Let $(a_n)_{n \in \mathbb{N}}$ be the sequence of integers defined recursively by $a_0 = 0$, $a_1 = 1, a_{n+2} = 4a_{n+1}+a_{n}$ for $n \geq 0$. Find the common divisors of $a_{1986}$ and $a_{6891}$. I think it is true that $\gcd(a_m,a_n) = a_{\gcd(m,n)}$, but I am not sure how to prove it. From this the answer follows since $\gcd(1986,6891) = 3$ and so $\gcd(a_{1986,6891}) = a_3 = 17$.",['number-theory']
1867068,P(P(N)) is equinumerous to the set of real functions,"I need to show that (the power set of power set of N) P(P(N)) is equinumerous to the set of real functions. I know that P(N) is equinumerous to R, thus it is equivalent to show that $\{0,1\}^R $ is equinumerous to $R^R$.  But I can't convince myself of this claim, let alone showing it. Any hints are welcome.","['real-numbers', 'elementary-set-theory']"
1867074,The completeness relation from QM in terms of inner products,"I remember from QM that the completeness relation says $$ \sum_{n=1}^\infty |e_n\rangle \langle e_n | = I$$ so that $\langle x\mid y\rangle =\sum_{n=1}^\infty \langle x\mid e_n\rangle \langle e_n \mid y\rangle$. I was recently trying to prove a result on Trace operators and one calculation was $$\sum_{k=1}^n \langle A g_k ,  h_k \rangle = \sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k))$$
Where apparently if $f\in X^*$ and $y\in Y$ we define $y\otimes f:X\to Y$ by $(y\otimes f)(x) = f(x)y$;
my attempt at this: $$\sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k)) = \sum_{k=1}^n\sum_{i=1}^\infty \langle A(g_k \otimes h_k) e_i, e_i\rangle$$
$$= \sum_{k=1}^n\sum_{i=1}^\infty \langle A(\langle e_i,h_k\rangle g_k), e_i\rangle = \sum_{k=1}^n\sum_{i=1}^\infty \langle Ag_k,e_i\rangle\langle e_i,h_k\rangle$$ So using my naive approach from quantum mechanics I just conclude that the last term is $\sum_{k=1}^n \langle A g_k ,  h_k \rangle $. However, I feel uneasy about this because $\langle \cdot , \cdot \rangle$ is an inner product, while $\langle \cdot \mid \cdot \rangle$ is the bra-ket notation... whatever that means. 1) Can I apply the completeness relation to make my conclusion? 2) Is there a canonical relation between $\langle \cdot, \cdot \rangle$ and $\langle \cdot \mid \cdot \rangle$? 3) How can I prove the completeness relation (I believe it's an axiom in QM, but I reckon its equivalence (in functional analysis (if it exists)) is a theorem).","['functional-analysis', 'trace', 'quantum-mechanics', 'operator-theory']"
1867078,Geometric interpretation of primitive element theorem?,"The primitive element theorem is a basic result about field extensions. I was wondering whether there are nice geometric ways to visualize it or think about it. Since field spectra are singletons, it has to be about the non-trivial automorphisms of points (I think), and I don't know how to think about it.","['intuition', 'galois-theory', 'extension-field', 'algebraic-geometry']"
1867082,Information matrix for a Student's T distribution,"I'm reading a paper from Creal, Koopman, Lucas ""Univariate Generalized Autoregressive Score Volatility Models"" and I'm stuck with this computation. $$
-\operatorname{E}_{t-1} \left[ \frac{\partial^2\ln p(y_t\mid f_t;\theta)}{\partial\sigma_t^2\,\partial\sigma_t^2} \right]^{-1} = \frac{2\sigma_t^4 (\nu+3)} \nu.
$$ After considering the log likelihood, the score is obtained by differentiation. I'm having troubles in two points: 1) Showing that the expectation of the score equals zero, in this specific case; 2) How do I get the negative of the inverse of the information Matrix as it is presented? I tried to differentiate another time the score w.r.t. $\sigma^2$ and then taking the expectation, but I don't know how to get the given result... Obviously I think that this problem is related to my inability to show the zero expectation of the score. Thanks to anybody that wants to help!","['fisher-information', 'probability-theory', 'probability-distributions']"
1867093,Geodesics in geodesic balls,"It is well-known that in a geodesic ball centered at $p$, the radial geodesic between $p$ and $q$ is the unique minimizing curve. I'm trying to follow the proof of this given in Cheeger & Ebin (AMS Chelsea edition, page 8). They seem to take a slightly different approach than usual. Let $B_r(p)$ be a geodesic ball, and let $c:[0,1]\to M$ be a piecewise smooth curve from $p$ to $\exp_pv\in B_r(p)$. Let $r$ be the radial distance function on the ball. Suppose $r(c(t))\le r$ $\forall t\le t_0$, that is, $c$ is inside the ball for $t\le t_0$. The authors show that 
$$\tag{1}L(c)\ge r(c(t_0))+\int_{t_0}^1||c'||\,dt,$$
with equality holding iff $c'=\lambda\partial_r$, for $\lambda$ some nonnegative function. They then define $t_1$ as the first $t$ for which $r(c(t_1))=||v||$. This follows from the Intermediate Value Theorem, and I understand this. They then say
$$\tag{2}L(c)=||v||+\int_{t_1}^1||c'||\,dt.$$
However, this would imply that 
$$||v||=\int_0^{t_1}||c'||\,dt=r(c(t_1)),$$
which seems incorrect for general curves. Is (2) correct? I suspect there should really be a $\ge$ instead of $=$, so it is consistent with (1). In particular, the rest of the proof makes sense with $\ge$, but it is then not clear why (1) needed to be derived.","['riemannian-geometry', 'differential-geometry']"
1867113,Commutative Banach algebra and its Gelfand spectrum,"Let $A$ be the set of all functions on $\mathbb{R}^2$ of the form $$
f(t,s):=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}},
$$ with the following norm: $$
\|f\|:=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}.
$$ I want to show that $A$ is a commutative Banach algebra. And, I am curious whether it is possible to show that the Gelfand spectrum of $A$ can be identified with the two-dimensional torus, i.e. $\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. Firstly, it is easy to show that: $A$ is commutative, since for all $f,g\in A$:  $(fg)(t,s)=f(t,s)g(t,s)=g(t,s)f(t,s)=(gf)(t,s)$; $A$ is associative, since for all $f,g,h\in A$:  $((fg)h)(t,s)=(fg)(t,s)h(t,s)=g(t,s)f(t,s)h(t,s)=f(t,s)(gh)(t,s)=(f(gh))(t,s)$; $A$ is distributive, since for all $f,g,h\in A$: $(f(g+h))(t,s)=f(t,s)(g+h)(t,s)=f(t,s)(g(t,s)+h(t,s))=f(t,s)g(t,s)+f(t,s)h(t,s)=(fg)(x)+ (fh)(t,s)=(fg+fh)(t,s)$, therefore $(g+h)f=gf+hf$; $A$ has the following property: for all $f,g\in A,\alpha\in \mathbb{R}$: $(\alpha(fg))(t,s)=\alpha(fg)(t,s)=\alpha f(t,s)g(t,s)=(\alpha f)(t,s)g(t,s)=((\alpha f)g)(t,s)= f(t,s) \alpha g(t,s)=(f(\alpha g))(t,s)$; Secondly, I want to show that the norm of the product is less than or equal to the product of the norms, i.e.
$$
\|fg\|\leq\|f\|\|g\|.
$$
So, let,
$$
f(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}
$$
and
$$
g(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}}
$$
We observe that
\begin{align}
(fg)(t,s)&=f(t,s)g(t,s)\\
         &=\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}\right)\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}}\right)
\end{align} Now, I want to conclude somehow that $f(t,s)g(t,s)$ has the following form: $$
\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{C_{mn}e^{i(mt+ns)}},
$$ such that $$
\|fg\|\leq \sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|b_{mn}|}.
$$ However, I dont know how to finish this proof. How can I conclude that $\|fg\|\leq\|f\|\|g\|.$ Now, let $M$ denote the set of all multiplicative linear functionals on $A$. Then, we can define the Gelfand transform $\hat{x}$ of $x$ as
$$
\hat{x}(\varphi):=\varphi(x),\qquad\quad\varphi\in M
$$ We can easily see that $A(M)$ with the following norm is a Banach space
$$
\|\hat{x}\|=\sup_{\varphi\in M}{|\hat{x}(\varphi)|}.
$$ Now, there exists a topology on $M$ such that $M$ is compact and $\hat{x}\in C(M)$ (Gelfand topology). Finally, we call set $M$ on $A$ with the Gelfand topology the Gelfand spectrum of $A$. My question: Is it possible to identify  the Gelfand spectrum of $A$ with the two dimensional torus: $T^2:=\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. If so, how? Any hints are appreciated.","['functional-analysis', 'operator-algebras', 'operator-theory', 'banach-algebras']"
1867132,Prove that up-to isomorphism there are two integral domains of order $p^2$.,Prove that up-to isomorphism there is exactly one  integral domain of order $p^2$ . Does there exist only two non-commutative rings of order $p^2$ upto isomorphism? We know that any group of order $p^2$ is abelian and also any abelian group of order $p^2$ is either isomorphic to $\Bbb Z_p\times \Bbb Z_p$ or $\Bbb Z_{p^2}$ . In order for the rings to be isomorphic the corresponding groups should be isomorphic.But I am unable to extend the result for the rings. Please give some tips.,"['abstract-algebra', 'ring-theory', 'group-theory']"
1867147,"Prove $f$ is identically zero in $\Omega = \{ z \in \Bbb C:|{\mathop{\rm Re}\nolimits} (z)| < 1,|{\mathop{\rm Im}\nolimits} (z)| < 1\} $","Let $\Omega  = \{ z \in \Bbb C:|{\mathop{\rm Re}\nolimits} z| < 1,|{\mathop{\rm Im}\nolimits} z| < 1\} $ and consider the function $f:\bar\Omega\to\Bbb C$ continuous on $\bar\Omega$, analytic in $\Omega$, and with the property that $f(z)=0$ when $\rm{Re}(z) =1$. Prove that $f$ is identically zero in $\Omega$. The following is a solution I copied from my prof's lecture note. I don't understand why $\text{Im}(F)=0$. Thank you! Let $F=f^2$ then $|F|=(\text{Re}f)^2-(\text{Im} f)^2+2(\text{Re}f)(\text{Im}f)$. $\text{Im} F =0$ for any $z\in \Omega$.
  $|e^{-iF}|=e^{\text{Im} F}=1$, $e^{-iF}$ analytic on $\Omega$, then for any $z\in \overline\Omega$, $|e^{-iF}|=1$, then $\text{Im} f=0$ on $\Omega$, so $F$ is constant on $Omega$, then $f$ is constant on $\Omega$, then $f$ is identically zero. P.S.",['complex-analysis']
1867150,Estimate $\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x$ without spherical coordinates.,"Is it possible to estimate the following Lebesgue integral ($\|\cdot\|$ is the 2-norm)
$$\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x, \, x\in\Bbb R^d$$
in terms of $\delta$ when $\delta\to 0$? That is to say, to bound it by $O(\frac1{\delta^\alpha})$. I know spherical coordinate transform may be a way to do it or even better yet - to give the exact value. But coordinate transform itself is quite troublesome to justify. What's more, I'm not interested in the exact value anyway, all I want is a best big O bound. So is there any good alternative, without spherical coordinate system? What I tried, the integral is equivalent to a slightly modified one interms of the big O asymptotic of $\delta$:
$$\int_{\|x\|_\infty\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x,$$
since 
$$\|x\|_2\ge\delta\implies \|x\|_\infty\ge \frac{\delta}{d^\frac12}\implies \|x\|_2\ge \frac{\delta}{d^\frac12}. $$
So the original integral over the space minus a ball is replaced by one over the space minus a cube - the sum of several rectangles. In dimension as low as $d=1,2$ the integral can be easily carried out over each of the rectangle to be summed up, since there are not many rectangles, but as the dimension goes higher there are as many as $3^d-1$ ones, impossible to be listed one by one. So I couldn't get any further following this seemingly hopeful thread of thought.","['multivariable-calculus', 'multiple-integral', 'real-analysis', 'lebesgue-integral']"
1867206,Derivative of Exponential map on manifolds,"I'm trying to compute the derivative of the map $f:\Sigma\times [0,\delta)\to M$ given by
$$f(p,t)=\exp_p tN(p),$$
in $X\in T_p\Sigma$, where $(M^n,g)$ is a Riemannian manifold, $\Sigma\subset M$ a immersed hypersurface and $N$ is a unit normal vector field along to $\Sigma$. If $X\in T_p \Sigma$ then I think something like that \begin{align}
df_{(p,t)}X &=\frac{d}{ds}\bigg|_{s=0}f\circ c(s)
\end{align} where $c$ is a differentiable curve in $\Sigma\times [0,\delta)$ with $c(0)=(p,t)$ and $c'(0)=X$. Taking $c(s)=(\exp_p sX,t)=(c_1(s),t)$, we have \begin{align}
df_{(p,t)}X &=\frac{d}{ds}\bigg|_{s=0}\exp_{c_1(s)}tN(c_1(s))\\
&\overset{*}{=}d(\exp_{c_1(s)})_{tN(c_1(s))}\nabla_{c'(s)}N(c(s))\bigg|_{s=0}\\
&= d(\exp_p)_{tN(p)}\nabla_X N(p).
\end{align} In fact, I would like know if the equality (*) make sense because in this calculation when I derive $\exp_{c_1(s)}tN(c_1(s))$ the curve $c_1$ is varying. NOTE: The original problem is decompose the pullback metric. I posted here but I don't understand the solution suggested. So, I tried to do something different.","['proof-writing', 'riemannian-geometry', 'differential-geometry', 'proof-verification']"
1867257,Books for maths olympiad,"I want to prepare for the maths olympiad and I was wondering if you can recommend me some books about combinatorics, number theory and geometry at a beginner and intermediate level. I would appreciate your help.","['number-theory', 'book-recommendation', 'geometry', 'combinatorics', 'contest-math']"
1867263,I was trying to find out the intervals where $\sin ^{-1}x > \cos ^{-1}x$,"I was trying to find out the intervals where $\sin ^{-1}x > \cos ^{-1}x$ The easiest way was to just look at the graph and I found out that the region is $x \in ({1\over \sqrt{2}} , 1]$ But I tried to prove the statement algebraically also but couldn't get it correctly. For $$\sin ^{-1}x > \cos ^{-1}x$$
$$\Rightarrow \sin ^{-1}x -\cos ^{-1}x>0$$
$$\Rightarrow \sin ^{-1}x - \sin ^{-1} \sqrt{1-x^2}>0 \tag1$$ Using the identity $$\sin ^{-1}x -\sin ^{-1}y=\sin ^{-1} \left (x\sqrt{1-y^2}-y\sqrt{1-x^2}\right)$$ Equation $(1)$ can be written as $$\Rightarrow \sin ^{-1}(2x^2-1)>0$$ For this to be true $0<2x^2-1<1$ and also for the equation to be valid $-1<2x^2-1<1$ Hence we can take 
$0<2x^2-1<1$ as the intersection of both the conditions
$$\Rightarrow 0\le  2x^2-1\le 1$$
$$\Rightarrow 1\le 2x^2\le 2$$
$$\Rightarrow 1/2\le x^2\le 1$$ The solution set of the inequality would be $x \in ({1\over \sqrt{2}} , 1] \cup [-1,{-1\over \sqrt{2}}),$ Can anybody tell me why I am getting the wrong answer.",['trigonometry']
1867269,Use $\delta-\epsilon$ to show that $\lim_{n\to\infty} a^{\frac{1}{n}} = 1$?,"Hope this is a meaningful question, but I'm curious if is possible to show that $$\lim_{n\to\infty} a^{\frac{1}{n}}=1, \text{where  }a>0$$ using $\delta-\epsilon$ directly or other methods. One method that I am aware of is to use the following: If $\{s_n\}$ is a nonzero sequence, then $\liminf\bigl|\frac{s_{n+1}}{s_n}\bigr|\le \liminf |s_n|^{\frac{1}{n}}\le \limsup |s_n|^{\frac{1}{n}}\le\limsup\bigl|\frac{s_{n+1}}{s_n}\bigr|$","['epsilon-delta', 'real-analysis', 'alternative-proof', 'limits']"
1867390,Algebra $A$ and its Gelfand spectrum,"Let $A$ be the set of all function $f$ on $\mathbb{R}$ of the form
$$
f(x)=d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt,\qquad\quad x\in\mathbb{R},
$$
where $d\in\mathbb{C}$ and $k\in L_1([0,\infty])$. The norm on $A$ is defined by $$
\|f\|:=|d|+\int\limits_0^\infty |k(t)|dt.
$$ I want to show that $A$ is a commutative Banach algebra and find its Gelfand spectrum We need the following properties in order to show that $A$ is a commutative Banach algebra: commutativity associativity distributivity scalar multiplication property the norm of the product is less than or equal to the product of the norms, The first four properties are easy to prove: Let $f,g\in A$, then
\begin{align}
f(x)g(x)&=\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\\
&=\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\\
&=g(x)f(x).
\end{align} Let $f,g,h\in A$, then
\begin{align}
(f(x)g(x))h(x)&=\left(\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\right)\left(d_2+\int\limits_{0}^{\infty}e^{ixt}k_2(t)dt\right)\\
&=\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\left(d_2+\int\limits_{0}^{\infty}e^{ixt}k_2(t)dt\right)\right)\\
&=f(x)(g(x)h(x))
\end{align} Let $f,g,h\in A$, then
\begin{align}
f(x)(g(x)+h(x))&=\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)+\left(d_2+\int\limits_{0}^{\infty}e^{ixt}k_2(t)dt\right)\right)\\
&=f(x)g(x)+f(x)h(x)
\end{align}
This implies that $(g(x)+h(x))f(x)=g(x)f(x)+h(x)f(x)$ Let $f,g\in A$ and $\alpha\in\mathbb{R}$, then
\begin{align}
\alpha (f(x)g(x))&=\alpha\left(\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\right)\\
&=(\alpha f(x))g(x)=f(x)(\alpha g(x)).
\end{align} Let $f,g\in A$, then
\begin{align}
f(x)g(x)&=\left(d+\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(d_1+\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)\\
&=dd_1+d\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt+d_1\int\limits_{0}^{\infty}e^{ixt}k(t)dt+\left(\int\limits_{0}^{\infty}e^{ixt}k(t)dt\right)\left(\int\limits_{0}^{\infty}e^{ixt}k_1(t)dt\right)
\end{align} Here I get stuck, I cannot show that $\|fg\|\leq\|f\|\|g\|$, any hints? Secondly, I have some difficulties mastering the Gelfand spectrum concept. How can I find Gelfand spectrum of $A$? Any hints are appreciated.","['banach-algebras', 'operator-theory', 'functional-analysis', 'integration', 'operator-algebras']"
1867392,Intuitive way to understand Polar Coordinate Gradient,"I am looking for an intuitive way to explain the ""$1/r$"" factor in the gradient in polar coordinates. For instance, if $g(x,y)=f(r,\theta)$, $$\nabla g=f_r\hat{e_r}+\frac 1rf_\theta\hat{e_\theta}$$ Is there a way to explain the $\frac 1r$ factor? By dimension matching? Or any other way to see that the answer is not $$\nabla g=f_r\hat{e_r}+f_\theta\hat{e_\theta}$$ Thanks for any help.",['multivariable-calculus']
1867403,A paradox in differential calculus,"Say I have a function $f=f(x,y)$ where $x,y$ are independent variables. Now, it is given that $p=x+y$. It can be shown that, since $x,y$ are independent, we get
$$\frac{\partial p}{\partial x}=\frac{\partial x}{\partial x}+\frac{\partial y}{\partial x} \implies \frac{\partial p}{\partial x}=1+0 \implies \frac{\partial x}{\partial p}=1$$ and similarly $$\frac{\partial p}{\partial y}=\frac{\partial x}{\partial y}+\frac{\partial y}{\partial y} \implies \frac{\partial p}{\partial y}=0+1 \implies \frac{\partial y}{\partial p}=1$$ Now I can write that $$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot\frac{\partial x}{\partial p}+\frac{\partial f}{\partial y}\cdot\frac{\partial y}{\partial p}$$
And using the above values, we get that
$$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot1+\frac{\partial f}{\partial y}\cdot1=\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}  \tag1$$ So if I replace $f$ by $p$ in $(1)$, which is quite valid since, like $f$, $p$ is also a function in $x,y$, we get that 
$$\frac{\partial p}{\partial p}=\frac{\partial p}{\partial x}+\frac{\partial p}{\partial y} \implies \large\color{red}{1=2}$$ How is this possible? Where is the error? Can someone point it out for me? Addendum as per Surb's answer and comments : If, as Surb concludes, for $x,y$ being independent, $\frac{\partial x}{\partial p}=\frac{\partial y}{\partial p}=0$, so I will get $\frac{\partial f}{\partial p}=0$ for all $f=f(x,y)$. But this is not true at all. How about $f=p^2=(x+y)^2$? So where is the mistake?","['differential', 'fake-proofs', 'calculus', 'multivariable-calculus', 'paradoxes']"
1867467,Is the set of aleph numbers countable?,"If I write the set of aleph numbers in this way $\{\aleph_0, \aleph_1, \aleph_2, \aleph_3, \dots\}$ it seems obvious to me that this set is countable, because aleph numbers have integer coefficients. However, maybe we are using the wrong notation for aleph numbers: how do we know that aleph numbers are really countable? I think my question can be rephrased like this: what is the cardinality of the set $\{\mathbb{N}, \mathscr{P}(\mathbb{N}), \mathscr{P}(\mathscr{P}(\mathbb{N})), \mathscr{P}(\mathscr{P}(\mathscr{P}(\mathbb{N}))), \dots\}$, where $\mathscr{P}(\mathbb{N})$ represents the power set of $\mathbb{N}$? How do I prove it?","['cardinals', 'elementary-set-theory']"
1867469,"Number of integer triplets $(a,b,c)$ such that $a<b<c$ and $a+b+c=n$","What is an equivalent combinatorial presentation for the problem? Can I use the stars and bars approach to find the number of integral solutions of $a+b+c=n$ where $a,b,c\geq 0$? If in addition $a+b>c$, $b+c>a$, $a+c>b$ hold, then the problem can be seen as $a,b,c$ being the sides of a triangle with perimeter $n$. I would like a hint on how to do that as well.","['combinatorics', 'integers', 'elementary-number-theory']"
1867484,Why isn't $\ell^p$ locally convex for $0<p<1$?,"I believe we have to distinguish the finite-dimensional from the infinite dimensional case. Regardless, if $0<p<1$, $\|x\|_p := (\sum |x_i|^p)^{\frac 1 p}$ is not a norm as it fails to satisfy the triangle inequality. That's why we use instead the metric $d(0,x) = \sum |x_i|^p = \|x\|_p^p$ to define the topology and remark that this is also not a norm since it is homogeneous of degree $p$. I do not know how the balls defined by this metric look like, but they ought to be convex because the metric satisfies the triangle inequality, right? In other words, they can't be the corresponding astroid-shaped superellipses for $0<p<1$. So why is $\ell^p$ said to not be locally convex (at least in the infinite dimensional case)?","['normed-spaces', 'convex-analysis', 'functional-analysis', 'lp-spaces', 'topological-vector-spaces']"
1867502,Integration by parts: is this legitimate way of using?,"Is it legitimate to write 
$$\int_0^a\mathrm{d}x\,f(x)g(x)=\left[f(x)\int_0^x\mathrm{d}x\,g(x)\right]_0^a-\int_0^a\mathrm{d}x\,\frac{\mathrm{d}f(x)}{\mathrm{d}x}\int_0^x\mathrm{d}x\,g(x)$$ Thanks.","['integration', 'definite-integrals', 'calculus']"
1867503,Without AC is there a relationship between $\beth$ and $\aleph$ numbers?,Assuming AC we know that all $\beth_\alpha$'s will be $\aleph_\beta$ for some $\beta$ since they can be well ordered. Can anything interesting be said about their relationship without AC? Is it possibly consistent that with the exception of $\beth_0$ none of the $\beth$'s can be well-ordered?,"['cardinals', 'elementary-set-theory', 'axiom-of-choice']"
1867561,Compute $1 \cdot \frac {1}{2} + 2 \cdot \frac {1}{4} + 3 \cdot \frac {1}{8} + \cdots + n \cdot \frac {1}{2^n} + \cdots $ [duplicate],"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 7 years ago . I have tried to compute the first few terms to try to find a pattern but I got $$\frac{1}{2}+\frac{1}{2}+\frac{3}{8}+\frac{4}{16}+\frac{5}{32}+\frac{6}{64}$$ but I still don't see any obvious pattern(s). I also tried to look for a pattern in the question, but I cannot see any pattern (possibly because I'm overthinking it?) Please help me with this problem.",['sequences-and-series']
1867568,Maximum and minimum of $f(x)=\cos(\sin(x))-\sin(\cos(x))$,"Given the function:
$$f(x)=\cos(\sin(x))-\sin(\cos(x))$$
it has absolute maxima at $x=(2k+1)\pi$ with $k=0,1,..N$ and relative maxima at $x=2k\pi$. It is not clear where are the minima. Putting the derivative to zero doesn't help. Any suggestion on how to find the minimum value and where is it? Thanks.","['algebra-precalculus', 'trigonometry']"
1867573,"When evaluating a limit by making a change of variable, how does the sign (+/-) change?","Say I have $$\lim_{x \rightarrow 4} f(x)=\frac{\sqrt{x}-2}{\sqrt{x^3}-8}.$$ My homework paper says to do a change of variable for $u=\sqrt{x}.$ If I do that, I get $$\lim_{u^2 \rightarrow 4} f(x)=\frac{u-2}{\sqrt{u^6}-8},$$ and from there we simplify like the following: $$\lim_{u^2 \rightarrow 4} f(x)=\frac{u-2}{u^3-8}$$ $$\lim_{u^2 \rightarrow 4} f(x)=\frac{u-2}{(u-2)(u^2+2u+4)}$$ $$\lim_{u^2 \rightarrow 4} f(x)=\frac{1}{u^2+2u+4}$$ My question is, when I square root the $u^2$ as in $u^2\rightarrow4$, does it become $u\rightarrow2$ or $u\rightarrow-2$, and why? It's apparent that in the from the first equation that it ""makes sense"" or at least ""follows some pattern"" for $u$ to equal positive $2$ because it would make the numerator $0,$ but this isn't really valid reasoning. So, should $u$ approach $2$ or $-2,$ and how do we know?",['limits']
1867590,Gradient of a maximum,"How do you compute the gradient of a function that involves a maximum? For example, I have the function:
$$ f(\vec{t}) = v(1-\exp(-\lambda\cdot \max(t_0,t_1)))$$
With $v$ and $\lambda$ constant, for which values of $t$ is this funciton at a maximum. I know I can use the chain rule to compute the partial derivatives, but I'm not sure how to deal with something like $\nabla_t \max(\vec{t}) $ If analytical solutions are difficult, is there a numerical way to approximate this?","['multivariable-calculus', 'optimization', 'calculus', 'vector-analysis']"
1867644,Finding a tricky composition of two piecewise functions,"I have a question about finding the formula for a composition of two piecewise functions. The functions are defined as follows: $$f(x) =
\begin{cases}
2x+1,  & \text{if $x \le 0$} \\
x^2, & \text{if $x > 0$}
\end{cases}$$ $$g(x) =
\begin{cases}
-x,  & \text{if $x < 2$} \\
5, & \text{if $x \ge 2$}
\end{cases}$$ My main question lies in how to approach finding the formula for the composition $g(f(x))$. I have seen a couple of other examples of questions like this online, but the domains of each piecewise function were the same, so the compositions weren't difficult to determine. In this case, I have assumed that, in finding $g(f(x))$, one must consider only the domain of $f(x)$. Thus, I think it would make sense to test for individual cases: for example, I would try to find $g(f(x))$ when $x <= 0$. $g(f(x))$ when $x <= 0$ would thus be $-2x-1$, right? However, I feel like I'm missing something critical, because I'm just assuming that the condition $x < 2$ for $g(x)$ can just be treated as $x <= 0$ in this case. Sorry for my rambling, and many thanks for anyone who can help lead me to the solution.","['algebra-precalculus', 'piecewise-continuity', 'functions']"
1867647,Partial and total derivative of a multivariable function,"Given a function $f(x,y,t)$, is it correct to say $$\frac{d f}{d x} = \frac{\partial f}{\partial x} \text{ ?}$$",['multivariable-calculus']
1867695,"Limit of the sequence $\lim_{n\rightarrow \infty}n\left ( 1-\sqrt{1-\frac{5}{n}} \right )$, strange result","$\lim_{n\rightarrow \infty}n\left ( 1-\sqrt{1-\frac{5}{n}} \right )$ $\lim_{n\rightarrow \infty} n *\lim_{n\rightarrow \infty}\left ( 1-\sqrt{1-\frac{5}{n}} \right ) = \infty * \left ( 1-\sqrt{1-0} \right ) = \infty * 0 = 0$ Did I do it correctly? Problem is when I use my calculator and put big values for $n$, I get $2,5$ as result (if I take very very big values, it's $0$ :D). Anyway, this made me feel a bit insecure and that's why I'm asking if I did it right.","['functions', 'calculus', 'analysis']"
1867713,Find an explicit map with certain combinatorial properties,"The following combinatorial problem popped up in a totally uncombinatorial context: Let $\mathcal{P}$ denote the power set of a set and let $k \in \mathbb{N}$.
Is there a map $c: \mathcal{P}(\{1,2,\dots,k\}) \to \mathbb{Q}$ with the following properties:
\begin{align*}
&c(\emptyset)=1 \ , \\
&c(\{i,i+1,\dots,j\}) = \sum_{\nu=i}^{j} (c(\{i,i+1,\dots,\nu-1\}) + c(\{\nu+1,\dots,j\} ) \quad \forall i \leq j \in \{1,2,\dots,k\} \ .
\end{align*} I am searching for an explicit description of a map with these properties. I have tried to define such a map using factorials and binomial coefficients. (This is a more special version of a map I was searching for in this earlier question: Find a map on a power set with certain combinatorial properties )","['combinatorics', 'factorial', 'binomial-coefficients']"
1867714,"Calculating the number of ""birthday days"" in the birthday problem","Given 's' students in a room and 'd' days in the calendar year, what is the probability 'P' that there will be 'k' ""birthday days""? i.e., 'k = 1' means that everybody's birthday falls on the same day, 'k = 5' means that exactly 5 days of the year coincide with the birthday of at least one student, and 'k = s' means that everyone's birthday is unique. Assume d ≥ s. 'k' will range from 1 to 's', and ∑P from k = 1 to k = s will be 1 (in other words, P(k) is a probability mass function). What I Know So Far: • The total number of ways for the students to have birthdays is d^s. • P(1) = d/d^(s) (because there are 'd' days on which all students could all share the exact same birthday). • P(s) = d!/(d^(s)(d-s)!) (because this is compliment of the solution to the standard birthday problem) Any help/resources that get me closer to a formula for P(k) are greatly appreciated. Thanks!","['birthday', 'combinatorics', 'probability']"
1867716,Why is holomorphic function with non-zero derivative a conformal map?,"I am new to complex analysis, interested to know why non-zero derivative implies a conformal map. Intuitively, I would think that non-zero derivative means the function is non-constant. Why would that be related to preserving angles? Any intuitive reasons? I understand that this may be a standard result in complex analysis. If so, please point out a good source where I can read more about it. (Suitable text for undergraduate level student) Thanks!",['complex-analysis']
1867729,Circles in complex plane.,"Find the real value of a for which there is at least one complex number satisfying $|z+4i|=\sqrt{a^2-12a+28}$ and $|z-4\sqrt{3}|\lt a$. My solutions:- Graphical solution:- $|z+4i|=\sqrt{a^2-12a+28}$ represents a circle with center at $A\equiv(0,-4)$ and radius $r_1=\sqrt{a^2-12a+28}$ and similarly, $|z-4\sqrt{3}|\lt a$ represents all the points inside the circle with center at $B\equiv(4\sqrt{3},0)$ and radius $r_2=a$. So, the distance between the centers of the circle is $\sqrt{(4\sqrt{3})^2+(4^2)}=8$ Now consider the graphs of $\sqrt{a^2-12a+28}$ and $a$. The graph of $\sqrt{a^2-12a+28}$ which is a hyperbola with its centre at $(6,0)$ and vertexes being $(6\pm 2\sqrt2,0)$ It is clear from the plot that $a\in (0,6-2\sqrt2]\cup [6+2\sqrt2,\infty)$ for $\sqrt{a^2-12a+28}\ge0$ and $a\gt 0$ Now, lets do some case study. Case 1:- When $a \ge 6+2\sqrt2$ In this case the radius of the circle represented by $|z-4\sqrt3|=a$ is greater than the distance between the centers of the circles, i.e $r_2\gt AB$ as $r_2\gt 8$. So, the circle $|z-4\sqrt3|=a$ either encloses the circle $|z+4i|=\sqrt{a^2-12a+28}$(or the point $-4i$, which is the case when $a=6+2\sqrt2$) fully or encloses a portion of it and in both the cases we find that we obtain a number common to both the regions. So, $a\in(6+2\sqrt2,\infty)$ Case 2:- $0\le a\le 6-2\sqrt2$ In this case we see that due to the bounding of $a$, we see that $(r_1+r_2)\lt 8$, so there is no intersection of the wanted regions, so there is no solution in this region. So the required interval of $a$ is $\boxed{a \in [6+2\sqrt2, \infty)}$ Algebraic Solution (or whatever you wanna call it) :- Lets consider all the possible circles that can be drawn for the given circles, they are as given in the figure:- From the above drawn circles we can consider the following cases. Case 1:- From Figure-3 (I have not numbered it so consider it in the left to right manner) we can get the following condition $$AB\lt r_1+r_2 \implies 8 \lt \sqrt{a^2-12a+28} + a \implies a\gt 9$$ This case deals with the limiting condition of both the circles touching. Case 2:- Now to not let the Figure-5 take place we have to consider the case $$AB\gt r_1-r_2 \implies 8 \gt \sqrt{a^2-12a+28} -a \implies a\gt -\frac{9}{7}$$ Now, I don't know what to conclude from this, so please do tell me that Case 3:- Consider Figure-4(don't know why I drew the last figure as it IMO represents the same case as Figure 4), the case we get is 
$$AB\lt r_2-r_1 \implies 8\lt a-\sqrt{a^2-12a+28} \implies a\gt 9$$ My deal with the question:- $a\gt 9$, $a\gt 9$ everywhere not a single $a\ge 6+2\sqrt2$ to see.(It's a joke) So as you can see that from the Algebraic solution I got $a\gt 9$ and from the Graphical approach to the question I get $a\ge 6+2\sqrt2$. And the book I am solving also gives the answer interval as $a\in (9,\infty)$. So what is wrong with the solutions and do point out the errors. As, always more elegant solutions are welcome. In my opinion the answer should be $a\in [6+2\sqrt2, \infty)$, which is evident from the graph figure below.","['complex-analysis', 'inequality', 'complex-numbers']"
1867733,About the Fermi charts,"In the book Topics in Differential geometry , Peter W. Michor defines the Fermi charts for a Riemannian manifold as follows. Let $(M,g)$ be a Riemannian manifold. For simplicity, I assume that $M$ is geodesically complete. Let $c : 0 \in I \subset \mathbb{R} \to M$ a geodesic. Let $\lbrace \dot{c}(0) \rbrace^{\perp}$ denote linear space of tangent vectors in $T_{c(0)}M$ which are orthogonal to $\dot{c}(0)$ (for the metric $g_{c(0)}$). Define the mapping $\Theta : (t,v) \in I \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto \mathrm{Exp}_{c(t)}\big( \mathrm{Pt}(c,t)v \big)$, where $\mathrm{Pt}(c,t)v$ denotes the parallel transport of $v$ from $T_{c(0)}M$ to $T_{c(t)}M$ along the curve $c$. The following result is given in the book : The tangent map of $\Theta$ along $I \times \lbrace 0 \rbrace$ is given by : $$ T_{(t,0)}\Theta : (s,Y) \in \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto s\dot{c}(t) + \mathrm{Pt}(c,t)Y $$ I tried to compute this tangent map myself but I couldn't. I considered a curve $\varphi : ]-\varepsilon,\varepsilon[ \to \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp}$ such that : $\varphi(0) = (t,0)$ and $\dot{\varphi}(0) = (s,Y)$. But I do not see how to compute the derivative at $u=0$ of $(\Theta \circ \varphi)(u)$ (because $u$ appears in the base point of the Exponential and in the parallel transport). What would be the right way to compute this tangent map ?","['riemannian-geometry', 'differential-geometry', 'geodesic']"
1867735,Value of this convergent series: $\frac{1}{3!}+\frac2{5!}+\frac3{7!}+\frac{4}{9!}+\cdots$,What is the value of- $$\frac{1}{3!}+\frac2{5!}+\frac3{7!}+\frac{4}{9!}+\cdots$$  I  wrote it as general term $\sum\frac{n}{(2n+1)!}$. As the series converges it should be telescopic (my thought). But i dont know how to proceed. I also know $\sum\frac{1}{n!}=e$ Any help /hints appreciated. Thanks!,"['sequences-and-series', 'convergence-divergence', 'closed-form']"
1867741,Why must a function be independent of coordinates?,"What is the motivation for why a function should be independent of coordinates? In the case of a general manifold I kind of get why, since one (usually) defines a function $f$ as a map from the manifold to the reals, i.e. $f:M\rightarrow\mathbb{R}$, and so in this sense it is manifestly coordinate independent (since $f$ has been defined without introducing any particular coordinate system). However, is there a reason in general (both heuristically and technically) why a function should be coordinate independent? In physics, the standard argument seems to be that a function is a scalar and so has no directional dependence, thus it should be invariant under rotations of coordinate systems. However, I'm unsure how this extends in generality (for example, why should it be true for a coordinate translation. Is it simply that coordinates are an artefact of the observer and so the value of the scalar function should not depend on the coordinates chosen, much like a vector is coordinate independent and this requires that its individual components should transform under coordinate transformations)? I'm fairly new to the concept of differential geometry so I apologise for such a basic question, but hopefully someone can help me out.","['coordinate-systems', 'differential-geometry', 'linear-algebra']"
1867746,What is the cardinality of a non-measurable set?,We know that $|P( \Bbb{R} )|=|L (\Bbb{R} )|$ ( $L (\Bbb{R} )$ is the set of all Lebesgue-measurable sets). Note that $L (\Bbb{R} ) \subsetneq P( \Bbb{R} )$ . What is the cardinality of non-measurable set? Is this set countable?,"['real-analysis', 'lebesgue-measure', 'measure-theory', 'elementary-set-theory']"
1867779,"Geometric meaning of interior,exterior derivatives, and, Hodge Duality","I've been tinkering with differential forms for a while now, and I've had a few questions all rolled into one trying to understand them. The exterior derivative is quite natural to me - it looks just like a regular old derivative, and so I believe I have a good intuition about how it works. The first question that struck me was that I did not have a similar intuition about the interior derivative. I wanted to know in what sense it was a derivative, if any, and either way I wanted to get an idea of what this guy really does. A geometric interpretation would have been ideal. At one point I was thinking about tensor contractions and how that's kind of like a trace, but that's not really what the interior derivative is anyway, so I ended up putting that aside for a while. But I noticed something interesting that has given me renewed interest in the question when I learned about Hodge duality. We will work in $\mathbb R^3$ with the usual coordinates. Consider an arbitrary $1-$ form which we'll write down as $F_x dx + F_y dy + F_z dz$ . We'll compute the exterior derivative of this, and we end up with $$ \bigg ( \frac{\partial F_x}{\partial y} - \frac{\partial F_y}{\partial x} \bigg ) dx \wedge dy + \bigg ( \frac{\partial F_x}{\partial z} - \frac{\partial F_z}{\partial x} \bigg ) dz \wedge dx + \bigg ( \frac{\partial F_y}{\partial z} - \frac{\partial F_z}{\partial y} \bigg ) dy \wedge dz $$ Amazingly (at least to me), this is the Hodge dual of the curl! Now, we can do a similar computation using $d(i_X)$ . If we let $X = \alpha \frac{\partial }{\partial x} + \beta \frac{\partial}{\partial y} + \gamma \frac{\partial}{\partial z}$ . $X$ is a vector field so these could be functions of $x,y,z$ , it doesn't really matter. Now if we let $\omega$ denote the $3-$ form, $dx \wedge dy \wedge dz$ . We can now compute. The computation is a little laborious to do directly from the definition, but there's a nice little formula which we can use to shortcut the computation. What we end up with is $$ \alpha dy \wedge dz + \beta dz\wedge dx + \gamma dy \wedge dz$$ after a few little rearrangements. Now we take the exterior derivative of this, and we have $$\bigg (\frac{\partial \alpha}{\partial x} + \frac{\partial \beta}{\partial y} + \frac{\partial \gamma}{\partial z} \bigg ) (dx \wedge dy \wedge dz) $$ And again in a way that totally amazes me, this is Hodge dual of the divergence of $X$ ! Now this motivates the question: What is the geometric significance Hodge duality? If there was some nice way to think about what the Hodge dual of something is, it would help me to understand the interior derivative, maybe. There is a problem though, which makes me worry that all of this is just coincedence of some sort - the above analysis depends on the fact that the Hodge dual on a 3-manifold takes 1-forms to 2-forms, which is how we able to see what's going on with the curl. In particular, curl is not even defined in dimensions different from 3. Divergence is defined in general though, so that much is a welcome sign. So somehow, I want to say that what I have learned will give me an avenue to understanding interior derivatives, and exterior derivatives better, but I don't know how to interpret Hodge duality, and I have these concerns. In Summary: How is the interior derivative a derivative, geometrically? What is the geometric content of Hodge duality? Can I put these together to understand interior and exterior derivatives?","['exterior-algebra', 'tensors', 'differential-forms', 'multivariable-calculus', 'vector-analysis']"
1867807,Simplifying trig expression $\frac{1}{1-\cos \theta}$,"I need help with the following trig problem, I'm getting the first part, but can't seem to complete it. $$\frac{\cos \theta}{1-\cos^2 \theta}- \frac{1}{1-\cos \theta}$$ The first part is going to equal $\csc^2 \theta \cos \theta$ minus the second part. Please help me solve the second part or the complete problem in general","['algebra-precalculus', 'trigonometry']"
1867821,Find all solutions to $f\left(x^2+xf(y)\right)=xf(x+y)$,"Find all functions $f:\mathbb{R}\to\mathbb{R}$ such that $$f\left(x^2+xf(y)\right)=xf(x+y)$$ for all $x,y\in\mathbb{R}$. This is somewhat related to this question , but with an $xf(y)$ term instead of $yf(x)$. I've managed to get $f(0)=0$, $f\left(x^2\right)=xf(x)$ and $f$ is odd, but not much more. I think that $f(x)=x$ and $f(x)=0$ are the only solutions, but I'm not sure.","['algebra-precalculus', 'functions', 'functional-equations']"
1867864,Help with conditional expectation of a convolution of exponential random variables,"I'm working through this paper , with lots of help from all the great people on this site. Obviously my statistics/probability is a lacking to follow all the mathematical steps. Currently, I'm trying to figure out how equation $(12)$ was derived from equation $(8)$: given the pdf 
  $$f_n(t) = \frac{\binom{n+1}{2}}{2N}\exp\left(-\frac{\binom{n+1}{2}}{2N}
t\right)\;\;\; (5) $$
  The convolution of $f_{n-1}(t),f_{n-2}(t),\ldots,f_m(t)$ has the expectation and variance:
  $$E(t) = 2N\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}}} = 2N \sum_{i=m+1}^{n}{\left(\frac{2}{i-l} - \frac{2}{i}\right)} = 4N\left(\frac{1}{m}-\frac{1}{n}\right) \;\;\; (8)\\
V(t) = 4N^2\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}^2}} \;\;\; (9)
$$
  given that the starting frequency of a mutant is $\frac{k}{2N}$, show the expectation of $E\left(t\mid\frac{k}{2N}\right)$ (mean time for $k$ alleles to go to $2N$ alleles, also known as the fixation time (since there are $2N$ alleles in the population)) is:
  $$
E\left(t\mid\frac{k}{2N}\right)=4N\left(1-\frac{1}{2N} - \sum_{i=1}^{k-1}{\frac{1}{i(i+1)}}\prod_{j=1}^{i}\frac{k-j}{2N-j} \right) \;\;\; (12)
$$ so basically the exponential distribution listed above (equation $(5)$) is the probability that $N+1$ randomly sampled alleles come from $N$ ancestors. I don't understand why the conditional expectation is different when you start with a known number of alleles, you just be able to plug $k$ and $2N$ into equation $(8)$:
$$
E(t) = 4N\left(\frac{1}{k}-\frac{1}{2N}\right)\;?
$$ I know this is a bit ambiguous, especially without knowing the details of the paper, but I'm sure someone more knowledgeable of statistics/probability can probably identify what the authors are using to derive the last equation. Also, bonus points if you can derive the following from  equation $(12)$ as $N\to\infty$:
$$E(t\mid p) = -4N(1/p - 1)\ln(1-p)\;,$$
where $p=\frac{k}{2N}$. Any help would be amazing!","['biology', 'probability-theory', 'convolution', 'statistics', 'probability']"
1867925,$\text{ Proving }\; A \subseteq \Bbb R \text{ A is bounded above} \Rightarrow A^c \text{ is not?} $,"Prove: Let $A \subseteq \Bbb R$. Prove that if $A$ is bounded above, then $A^c$, the complement of $A$ is not bounded above. $ A^c = $ those element of the universe that are not in A. $ \Bbb R =$ real numbers. Proof: (direct proof) Suppose that $A^c$ is bounded above and $ s= \text{supremum}(A), t = \text{supremum}(A^c)  $ $\Rightarrow$ $a\le s, ∀ a \in A; b \le t,  ∀ b \in B.$ . How does one finish this proof? Any hints would be appreciated.","['real-numbers', 'analysis', 'proof-verification']"
1867939,How unique is $e$?,"Is the property of a function being its own derivative unique to $e^x$, or are there other functions with this property? My working for $e$ is that for any $y=a^x$, $ln(y)=x\ln a$, so $\frac{dy}{dx}=\ln(a)a^x$, which equals $a^x$ if and only if $a=e$. Considering equations of different forms, for example $y=mx+c$ we get $\frac{dy}{dx}=m$ and $mx+c=m$ only when $m=0$ and $c=0$, so there is not solution other than $y=0$. For $y=x^a$, $\frac{dy}{dx}=ax^{a-1}$, which I think equals $x^a$ only when $a=x$ and therefore no solutions for a constant a exist other than the trivial $y=0$. Is this property unique to equations of the form $y=a^x$, or do there exist other cases where it is true? I think this is possibly a question that could be answered through differential equations, although I am unfortunately not familiar with them yet!","['derivatives', 'exponential-function', 'ordinary-differential-equations', 'calculus']"
1867972,Proving that ${x +y+n- 1 \choose n}= \sum_{k=0}^n{x+n-k-1 \choose n-k}{y+k-1 \choose k} $,"How can I prove that $${x +y+n- 1 \choose n}= \sum_{k=0}^n{x+n-k-1 \choose n-k}{y+k-1 \choose k} $$ I tried the following: We use the falling factorial power : 
$$y^{\underline k}=\underbrace{y(y-1)(y-2)\ldots(y-k+1)}_{k\text{ factors}},$$
so that $\binom{y}k=\frac{y^{\underline k}}{k!} .$ Then $${x +y+n- 1 \choose n} = \frac{(x +y+n- 1)!}{n! ((x +y+n- 1) - n)!} = 
\frac{1}{n!}. (x +y+n \color{#f00}{-1})^{\underline n} $$ And $$ {x+n-k-1 \choose n-k}{y+k-1 \choose k}$$
$$\frac{1}{(n-k)!}.(x+n-k-1)^{\underline{n-k}}.\frac{1}{k!}.(y+k-1)^{\underline{k}}$$
$$\frac{1}{k!.(n-k)!}.(x+n-k-1)^{\underline{n-k}}.(y+k-1)^{\underline{k}}$$
$$\sum_{k=0}^n{n \choose k}(x+n-k-1)^{\underline{n-k}}.(y+k-1)^{\underline{k}}$$ According to the Binomial-coefficients: $$ ((x+n-k-1) + (y+k-1))^{\underline{n}}$$
$$ (x+y+n\color{#f00}{- 2})^{\underline{n}}$$ What is wrong ? und How can I continue?  :/","['combinatorics', 'binomial-coefficients', 'analysis', 'proof-verification']"
1867983,Are the extremas of $h(x)$ global?,"It is well known that $li(x)$, the integral logarithm is a very good approximation of $\pi(x)$, the nunmber of primes not exceeding $x$. So, a very good approximation for the probability, that a random number with $x$ digits is prime, is given by $$f(x)=\frac{li(10^x)-li(10^{x-1})}{10^x-10^{x-1}}$$ I figured out that the function $$g(x)=\frac{2000x}{(2000x^2-646x-141)\ln(10)}$$ is a superb approximation to $f(x)$ , using an interpolating tool at a very nice math-site from Arndt Brünner. Let us define $h(x):=f(x)-g(x)$ It seems that for $x\ge 11$, the function $h(x)$ has minimum about $-4.334\cdot 10^{-8}\ $ and maximum about $2.1749\cdot 10^{-8}\ $. Are these extremas global extremas ? Can we rigorously prove that $|h(x)|<4.335\cdot 10^{-8}\ $ for all $x\ge 11$ ? I tried to verify this with Wolfram Alpha, but the function seems to be too complicated. Any ideas ? The limit of $h(x)$, $x$ tending to $\infty$, should be $0$.","['number-theory', 'prime-numbers', 'calculus']"
1867990,Deriving sum of powers formula using generating functions,"Just for fun I wanted to try to derive a formula for the sum of $p$ -powers using generating functions, but without using any literature or websites for help. However I do need a small push or hint. Let $p$ be some positive integer constant. Define $f(n) = \sum_{k=0}^{n} k^p = 0^p + 1^p + 2^p + 3^p + \cdots + n^p$ I can also state it as a recurrence: $f(n) = f(n-1) + n^p$ where $f(0) = 0$ . Define $G(x) = \sum_{n=0}^{\infty} f(n) x^n$ Then $$
\begin{aligned}
G(x) &= f(0)x^0 + \sum_{n=1}^{\infty} f(n) x^n\\
G(x) &= 0 + \sum_{n=1}^{\infty} f(n-1) x^n + \sum_{n=1}^{\infty} n^p x^n\\
G\left( x \right) &=x\sum_{n=1}^{\infty}{f}\left( n-1 \right) x^{n-1}+\left( -0^px^0+\sum_{n=0}^{\infty}{n}^px^n \right) 
\\
G(x) &= x\sum_{n=0}^{\infty} f(n) x^{n} + \sum_{n=0}^{\infty} n^p x^n\\
G(x) &= xG(x) + \sum_{n=0}^{\infty} n^p x^n\\
G(x) - xG(x) &= \sum_{n=0}^{\infty} n^p x^n\\
G(x) &= \frac{\sum_{n=0}^{\infty} n^p x^n}{1-x}
\end{aligned}$$ So now it is all about finding the generating function for $H(x,p) = \sum_{n=0}^{\infty} n^p x^n$ I need some way to get from $H(x,p-1) = \sum_{n=0}^{\infty} n^{p-1} x^n$ to $H(x,p) = \sum_{n=0}^{\infty} n^p x^n$ because the base case is $H(x,0) = \sum_{n=0}^{\infty} n^0 x^n = \sum_{n=0}^{\infty} x^n = \frac{1}{1-x}$ At this point I feel a little stuck and could use a push in the right direction. Am I onto a solution here or am I just spinning my wheels? Where can I go from here? I know one usual approach is to keep taking the derivative of both sides but I'd prefer to avoid that method (no real reason, just want to see if it can be done without noticing that trick). How can I relate $H(x,p-1)$ to $H(x,p)$ ?","['recurrence-relations', 'number-theory', 'generating-functions', 'summation', 'sequences-and-series']"
1868003,What is the limit of the sequence: $n$-th root of the $n$-th Fibonacci number?,"My computer can not calculate numbers large enough for this. If you take the $n$-th Fibonacci number $F_n$ and raise it to the $1/n$-th term, where does the sequence $F_n^{1/n}$ tend to? Examples: $13^{1/7}$ $21^{1/8}$","['fibonacci-numbers', 'sequences-and-series']"
1868025,How to represent polynomial rings in multiple variables.,"If $R$ is a ring, we can form the polynomial ring in $x$ as $$R[x]=\{\sum_{i=1}^nax^i|a \in R  \wedge n\in \mathbb{N} \cup\{0\}\} $$ where the $\sum_{i=1}^nax^i$ are formal sums. Every source I look at deals with polynomials with just one variable, and only a select few go as far as mentioning $R([x])[y] \cong R([y])[x]$ and just call it $R[x,y]$. None mention explicitly $R[x_1, ... ,x_n]$. How could one explicitly and rigorously define it in the manner above with $R[x]$? What do elements of $R[x_1, ... ,x_n]$ look like explicitly? What do their operations formally look like?",['abstract-algebra']
1868055,"Explanation of Aumann's ""agreeing to disagree"" in modern notation","I'm attempting to understand Aumann's classic 1976 paper Agreeing to Disagree , which claims, under certain assumptions, that if two Bayesian agents share knowledge of each others' posteriors then they must always eventually agree on the same posterior. Unfortunately, this paper has a tendency to make up its own notation as it goes along rather than using standard probability theory notation. This bad habit seems to have infected all the papers that reference it as well, with the result that I'm finding it really hard to work out what's going on. My question is whether an explanation exists in more modern notation, i.e. where the result is described in terms of random variables and the relationships between them, rather than constantly reinventing the notion of a random variable using set theory notation. As an example of what I mean, the original paper contains the sentence Let $A$ be an event, and let $\mathbf{q}_i(.)$ denote the posterior probability $p(A \mid \mathscr{P}_i)$
  of $A$ given $i$’s information: i.e., if $\omega \in \Omega$, then $\mathbf{q}_i(\omega) =p(A \cap P_i(\omega))/p(P_i(\omega)).$ Well firstly, if it's a conditional probability then why wouldn't you just always write it as $p(A\mid \mathscr{P}_i)$ rather than defining a new notation for no apparent reason, and secondly, if it's equal to $p(A\mid \mathscr{P}_i)$ then why is $\mathbf{q}_i$ a function of $\omega$ and not a function of $A$? The paper is full of this sort of thing, and while I can slowly work through it and convert these set theory level definitions into a more familiar probability theory notation, I'm hoping that someone else has already done this and presented a more readable explanation.","['bayesian', 'probability-theory']"
1868121,How to precisely define a function that chooses randomly from a finite set?,"Let $A = \{1, 2, \ldots, n\}$. I want to define a function that picks with uniform probability an element in $A$, so that $$f(A) = i \in A.$$ I don't know how to precisely define this mathematical operation. Sure, I can say: Let $f: A \to A$, $f(A) = i \in A$. But this does not characterize the randomness at all. Is there a common function that do this work for us?","['real-analysis', 'probability', 'functions']"
1868128,probability of rank of a number,"Suppose I have 10 sample means. I want to find the probability of rank of the population means using sample means. Therefore, I want to perform two experiments. First experiment: I pick one of the sample means and compute the probability of being rank from 1 to 10 of the population mean correspond to the sample mean, i.e, what is the probability that this population mean's rank is 1 or 2 or 3....or 10. Note that I used only one sample mean here. Second experiment:I sort all 10 sample means in the descending order so that the maximum number is in the first and the minimum number is in the last. Then compute the probability of the corresponding population means to be rank 1 if the sample mean's rank is 1, to be rank 2 if the sample mean's rank is 2, and so on. Here I used all sample means. My question is, are these two experiments equivalent? Note that I assume that I have the tools to compute the probability of the rank. I am are trying to find the ranking probabilities of the population means using sample means. In practice, we estimate population mean by sample mean but we never know the actual population mean. Thank you","['statistics', 'probability', 'statistical-inference', 'discrete-mathematics']"
1868143,A pair of sequences defined by mutual addition/multiplication,"Define sequences $\{a_n\},\,\{b_n\}$ by mutual recurrence relations: $$a_0=b_0=1,\quad a_{n+1}=a_n+b_n,\quad b_{n+1}=a_n\cdot b_n.\tag1$$ The sequence $\{a_n\}$ begins: $$1,\,2,\,3,\,5,\,11,\,41,\,371,\,13901,\,5033531,\,69782910161,\,...\tag2$$ It appears in OEIS as $A003686$ under the name ""Number of genealogical $1$ - $2$ rooted trees of height $n$ ."" (note that indexing starts with $1$ rather than $0$ in OEIS). It seems that for $n\to\infty$ , $$\ln\ln a_n=n\cdot\ln\phi+c+o(1),\tag3$$ where $\phi=\frac{1+\sqrt5}2$ is the golden ratio, the last term $o(1)$ exponentially decays in absolute value (and seems to have alternating signs for $n\ge8$ ), and the constant $$c\approx-1.11328370529375397170010672464407271138948509227239...\tag4$$ (see more digits here ) The equivalent asymptotics is given in OEIS without proof. How can we prove $(3)$ ? Is there a closed form or some alternative representation (integral, series, product, continued fraction, etc) for the constant $c$ ? Is it irrational? Is there an efficient way to numerically calculate $c$ to a higher precision?","['recurrence-relations', 'golden-ratio', 'limits', 'asymptotics', 'number-theory']"
1868163,Baby Rudin Problem 2.16,"Regard $Q$, the set of all rational numbers, as a metric space, with $d(p,q) = |p-q|$. Let $E$ be the set of all $p\in Q $ such that $2<p^2<3$. Show that $E$ is closed and bounded in $Q$, but $E$ is not compact. Is $E$ open in $Q$? To show $E$ is closed I thought I would should that $E^c$ is open.
We will look at three regions. 1) Let $A$ be the set of all $p\in Q $ such that $p<-\sqrt{3}$ 2) Let $B$ be the set of all $p\in Q $ such that $-\sqrt{2}<p<\sqrt{2}$ 3) Let $C$ be the set of all $p\in Q $ such that $p>\sqrt{3}$ Let $a \in A$, pick a neighborhood $N_r(a)$ such that $r<|a+\sqrt{3}|$ then surely
$N_r(a)\subset A$, hence A is open. A similar argument follows for (2) and (3)
and by the theorem, the union of open sets is open, $E^c$ is open. Hence $E$ is closed. Clearly $E$ is bounded do to the strict inequalities. To show $E$ is not compact I will provide one infinite open cover of $E$. Let $G_a$ be an open cover of $E$. Place each rational number in a segment with irrational endpoints less than the surrounding rational numbers. Because the rational numbers obey the archimedean axiom this will go on forever and hence a infinite open cover exists. Using the same argument to show $E^c$ is open we can show $E$ is open. I know my argument is not very rigorous, I'm still learning how to write a solid proof, but am I on the right track?","['general-topology', 'real-analysis']"
1868205,On real part of the complex number $(1+i)z^2$,"Find the set of points belonging to the coordinate plane $xy$, for which the real part of the complex number $(1+i)z^2$ is positive. My solution:- Lets start with letting $z=r\cdot e^{i\theta}$. Then the expression $(1+i)z^2$ becomes $$\large\sqrt2\cdot|z|^2\cdot e^{{i}\left(2\theta+\dfrac{\pi}{4}\right)}$$ Now, as $\sqrt2\cdot|z|^2\gt0$, so $\Re{((1+i)z^2)}\gt 0 \implies\cos{\left(2\theta+\dfrac{\pi}{4}\right)}\gt 0$. So, we get 
$$-\dfrac{\pi}{2}\lt\left(2\theta+\dfrac{\pi}{4}\right)\lt\dfrac{\pi}{2}
\implies-\dfrac{3\pi}{4}\lt2\theta\lt\dfrac{\pi}{4}
\implies-\dfrac{3\pi}{8}\lt\theta\lt\dfrac{\pi}{8}$$ Now, lets find the equation of the lines which would help us show these inequalities in the coordinate plane. The inequality can be represented by 
$$\begin{equation}
y\lt \tan{\dfrac{\pi}{8}}x\implies y\lt(\sqrt2-1)x \tag{1}
\end{equation}$$
$$\begin{equation}
y\gt \tan{(-\dfrac{3\pi}{8})}x \implies y\gt-(\sqrt2+1)x \tag{2}
\end{equation}$$ So, the inequality can be represented in the coordinate plane as in the following portion of the graph with the cross-hatched part. My deal with the question:- The book I am solving gives the answer as the (cross-hatched part + un-hatched part) , so what am I missing in my solution. And, as always more elegant solutions are welcome.","['complex-analysis', 'inequality', 'complex-numbers']"
1868219,addition of two differential forms with different degrees,"Does it make sense to add two differential forms with different degrees like $dx+dx\bigwedge dy$? If yes, what's the arguments of it? I ask this because in text book, the vector space, $\Omega^*(M)$, of $C^\infty$ differential forms on a manifold $M$ is defined as $\Omega^*(M)=\bigoplus_{k=0}^n\Omega^k(M)$, where $\Omega^k(M)$ is the vector space of k-forms. It means each element in $\Omega^*(M)$ is uniquely a sum $\sum_{k=0}^n \omega_k$, $\omega_k\in \Omega^k(M)$.","['manifolds', 'differential-geometry']"
1868228,"Let $S=\{0,2,4,6,8\}$, $T=\{1,3,5,7\}$. Determine whether each of the following sets of ordered pairs is a function with domain $S$ and co-domain $T$.","Let $S=\{0,2,4,6,8\}$ and $T=\{1,3,5,7\}$. Determine whether each of the following sets of ordered pairs is a function with
  domain $S$ and co-domain $T$. $\{(6,3),(2,1),(0,3),(8,7),(4,5)\}$ TRUE This is a function $\{(2,1),(4,5),(6,3)\}$ FALSE Not all domain values used $\{(0,2),(2,4),(4,6),(6,0),(8,2)\}$ FALSE Domain values mapped to values outside of co-domain $\{(2,3),(4,7),(0,1),(6,5),(8,7)\}$ TRUE This is a function $\{(6,1),(0,3),(4,1),(0,7),(2,5),(8,5)\}$ FALSE $0$ is mapped twice Currently, I am unsure about number 3, can the domain values be mapped to itself as shown or does that invalidate it as a function in this situation since the co-domain has specified values? Thanks!",['functions']
1868262,"$Im(K)\subset Y$ closed, infinite-dimensional: $K:X\to Y$ is not a compact operator","Proposition: If $K:X\to Y$ is a bounded linear operator between two Banach spaces $X$ and $Y$ such that $\operatorname{Im}(K)\subset Y$ is an infinite-dimensional closed subspace, then $K$ is NOT compact. Proof: I have to prove it, but the only think I know is that from the Closed Image theorem: $\operatorname{Im}(K)\subset Y$ is closed if and only if  $\exists C>0 \quad \forall x\in X$ s.t. \begin{equation}
\inf_{Ky=0}\Vert x+y \Vert_Y\leq \Vert Kx\Vert_Y. \end{equation} Also I know a Theorem that says: $dim(Z)<\infty$ is equivalent to $B$ compact. Where $B$ is the closed unit ball on Z. But I have no idea how to do the proof formally, and also how to conclude. Can someone help me?","['functional-analysis', 'compact-operators', 'banach-spaces', 'operator-theory']"
1868277,A strong version of the Dominated Convergence Theorem,"Let $(X, \Sigma, \mu)$  be a measure space, and let $f, f_n:X\rightarrow \mathbb{C}$ be measurable functions with $f_n\rightarrow f$ pointwise.
Assume that there are integrable functions $G, g_n:X\rightarrow[0, \infty]$ with finite integrals
such that $|f_n|\leq G+g_n$ for every $n$. Also assume that $\int g_n \rightarrow 0$. We need to show that $\int |f-f_n|\rightarrow 0$. I've tried using the dominated convergence theorem but couldn't find the dominating function. I have 2 main ""problems"" with the statement: $\underset{n}{\sup}  g_n$ doesn't necessarily have a finite intgeral; $g_n$ doesn't have to converge pointwise to anything. That's what makes this statement different from all the others in this site I've checked.","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1868313,"what does ""a set of sets that are not members of themselves"" of Russell’s Paradox mean","Russell’s Paradox begins with a statement of ""Let $R$ be the set of sets that are not members of themselves"", i.e. $R=\{S\mid S\notin S\}$. I'm a little bit confused  with the statement, for example, let  $S=\{1,\{2,3\}\}$, of course $S\notin S$ since $S$ doesn't have an element $\{1,\{2,3\}\}$, $S$ only have two elements which are $1$ and $\{2,3\}$, So $R$ only have one element i.e. $R=\{\{1,\{2,3\}\}\}$, and again, of course $R\notin R$, I must have something wrong here but I don't know where I go wrong.","['elementary-set-theory', 'discrete-mathematics']"
1868322,Canonical bundle of the Lagrangian Grassmannian,"I'd like to compute the canonical bundle of the Lagrangian Grassmannian $\mathbb{LG}_n$, the set of Lagrangian subspaces  of dimension $n$ of a complex vector space together with fixed symplectic bilinear form. I already know, that this is $K_{\mathbb{LG}_n} = \mathcal{O}_{\mathbb{LG}_n}(-n-1)$. So far I know, that the tangent space in one point $L$ (that is a Lagrangian subspace) of $\mathbb{LG}_n$ can be identified with the set of symmetric bilinear forms $B_{symm}(L,L)$, see Piccione, Tausk - A Student's Guide to Symplectic Spaces . For some references or help for the proof I'd be grateful.","['symplectic-geometry', 'grassmannian', 'algebraic-geometry', 'multilinear-algebra']"
1868323,Eigenvalue perturbation of singular matrix,"Consider a Hermitian matrix $\mathbf{A_0} \in \mathbb{C}^{N \times N}$ with one singularity, i.e. its eigenvalues in increasing order are:
\begin{equation}
0 < \lambda_2 \leq \lambda_3 \leq \cdots \leq \lambda_N
\end{equation}
The eigenvector corresponding to $\lambda_k$ is $\mathbf{v_k}$.
Now consider a matrix with small entries $\mathbf{\delta A}$ and $\mathbf{A} = \mathbf{A_0} + \mathbf{\delta A}$, let the eigenvalues of $\mathbf{A}$ be 
\begin{equation}
\gamma_1 \leq \gamma_2 \leq  \cdots \leq \gamma_N
\end{equation}
The eigenvector corresponding to $\gamma_k$ is $\mathbf{u_k}$.
It is well-known that a $1^{st}$ order perturbation of eigenvalues is
\begin{equation}
\gamma_k = \lambda_k +\mathbf{v_k^H} \mathbf{\delta A} \mathbf{v_k} + O(\delta^2)
\end{equation}
There is also a similar expression of $\mathbf{u_k}$ as a function of $\mathbf{v_1} \ldots \mathbf{v_k}$. The questions are: 1) Is this true for $k = 1$, i.e. can we say $\gamma_1 =  \mathbf{v_1^H} \mathbf{\delta A} \mathbf{v_1} + O(\delta^2)$ ? The reason i'm asking this is that i see repeatedly that the matrix $\mathbf{A_0}$ should be positive definite so that the perturbation on eigenvalues hold true. 2) If (1) is true, can we approximate $\mathbf{A}^{-1}$ by $\frac{1}{\gamma_1}\mathbf{u_1}\mathbf{u_1^H} $ ? Is there any formal theory behind this apprxoimation ? Thank you very much in advance.","['eigenvalues-eigenvectors', 'quantum-mechanics', 'perturbation-theory', 'linear-algebra', 'discrete-mathematics']"
