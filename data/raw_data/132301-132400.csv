question_id,title,body,tags
2072199,The sum of all integers from $1$ to $p$ is divisible by $p$ and all prime numbers before $p$. What can $p$ be?,"The summation of all integers from $1$ to $p$ is divisible by $p$ and all prime numbers before $p$. Find all possible solutions for $p$, with proof. Here $p$ is a prime number. This is a preparation problem for the upcoming BdMO. I can't find a way to start. Any hint will be helpful.","['number-theory', 'contest-math', 'prime-numbers']"
2072204,"Operator topologies on $L^{\infty}(X,\mu )$","Let $(X,\mu )$ be a measure space.  Then, $L^2(X):=L^2(X,\mu )$ is a Hilbert space in the usual way and we may view $L^{\infty}(X):=L^{\infty}(X,\mu )$ as a subalgebra of bounded operators on $L^2(X)$ via $L^{\infty}(X)\ni f\mapsto M_f$, where $M_f\colon L^2(X)\rightarrow L^2(X)$ is the multiplication operator defined by $[M_f(g)](x):=f(x)g(x)$. Regarding $L^{\infty}(X)$ as an algebra of bounded operators in this way, the question can be stated as How can we describe explicitly convergence in the various operator topologies on $L^{\infty}(X)$? At least one is relatively easy.  For example, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the operator norm topology iff $\lambda \mapsto f_{\lambda}$ converges to $f$ in the $L^{\infty}$ norm.  It seems that convergence in measure corresponds to ultra-weak convergence .  Furthermore, pointwise almost-everywhere convergence can't correspond to any topology .  These are perhaps the three most obvious notions of convergence in $L^{\infty}(X)$, but that leaves many operator topologies unaccounted for.  Perhaps most of them just don't have a very nice description? Update #1 :  It seems as if the weak operator topology corresponds to the weak-$^*$ topology:  $\lambda \mapsto f_{\lambda}\in L^{\infty}(X)$ converges to $f\in L^{\infty}(X)$ in the weak-$^*$ topology iff $\lambda \mapsto \int _Xgf_{\lambda}$ converges to $\int _Xgf$ for all $g\in L^1(X)$, and on the other hand, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the weak operator topology iff $\lambda \mapsto \int _Xgf_{\lambda}h$ converges to $\int  _Xgfh$ for all $g,h\in L^2(X)$.  As $gh\in L^1(X)$ for $g,h\in L^2(X)$, we obtain the $(\Rightarrow )$ direction immediately.  For the $(\Leftarrow )$ write $g=u|g|$ for some Borel function $u$ with $|u|=1$, so that we have $\lambda \mapsto \int _Xgf_{\lambda}=\int _X(u|g|^{1/2})f_{\lambda}|g|^{1/2}$ converges to $\int _X(u|g|^{1/2})f|g|^{1/2}=\int _Xgf$. Update #2 :  I have decided to ask this on mathoverflow .","['functional-analysis', 'operator-algebras', 'measure-theory', 'operator-theory']"
2072225,"Condition for $f+g$ to be periodic given that $f,g$ are periodic functions.","Is the following statement true? If $f,g$ are two periodic functions with period length $P_1,P_2$, respectively. Then $f+g$ is a periodic function with length of period $T$ if and only if $T/P_1,T/P_2$ are integers. One example supports this statement: $f(x)=\sin 2x, g(x)=\cos 3x$ and $f+g$ is periodic with period length $2\pi= 2 \cdot \pi= 3 \cdot 2\pi/3$ where $\pi,2\pi/3$ are length of periods of $f,g$, respectively.","['periodic-functions', 'functions']"
2072228,Prove that:$\sum_{n=0}^{\infty}{2^{n+3}(n^2+n+\phi)\over (n+1)(2n+1)(2n+3){2n\choose n}}=\phi\pi^2+8\phi^2\pi-8\phi^3\sqrt{5}$,"$\phi$ is the golden ratio $$\sum_{n=0}^{\infty}{2^{n+3}(n^2+n+\phi)\over (n+1)(2n+1)(2n+3){2n\choose n}}=\phi\pi^2+8\phi^2\pi-8\phi^3\sqrt{5}$$ I try: $$S=\sum_{n=0}^{\infty}{2^{n+3}\over {2n\choose n}}\left[{A\over n+1}+{B\over 2n+1}+{C\over 2n+3}\right]$$ $n^2+n+\phi=A(2n+1)(2n+3)+B(n+1)(2n+3)+C(n+1)(2n+1)$ $A=-\phi$, $B=\phi-0.25$ and $C=\phi+0.75$ $$S=\sum_{n=0}^{\infty}{2^{n+3}\over {2n\choose n}}\left[{-\phi\over n+1}+{\phi-0.25\over 2n+1}+{\phi+0.75\over 2n+3}\right]$$ If we know the closed form $$\sum_{n=0}^{\infty}{2^n\over {2n\choose n}(an+b)}=F(a,b)$$ Then it is easy to prove the above series. I manage to find $$\sum_{n=0}^{\infty}{2^n\over {2n\choose n}(2n+1)}={\pi\over 2}$$ Any help? Thank you.","['power-series', 'binomial-coefficients', 'sequences-and-series']"
2072252,"Algebraic fundamental group of $\mathbb{P}^1(\mathbb{Q})\setminus\{P_1,\ldots,P_n\}$","Define the algebraic fundamental group as follows: Let $k$ be a perfect field, $X$ an integral proper normal $k$-curve with function field $K$ and $U\subset X$ a nonempty open subset. Denote by $K_s$ a fixed separable closure of $K$.Let $K_U$ be the composite of all finite subextensions $L:K_s/L/K$ such that the corresponding finite morphism of proper normal curves is Ã©tale over $U$. Then $K_U$ is Galois over $K$ and the algebraic fundamental group of $U$ is $\operatorname{Gal}(K_U/K)$, denoted as $\pi_1(U)$. (Cf. Tamas Szamuely, Galois Group and Fundamental Groups, Section 4.6) Now let $\Pi(n)$ be $\pi_1(\mathbb{P}^1(\mathbb{Q})\setminus\{P_1,\ldots,P_n\})$. Then why is $\Pi(n)$ a quotient of $\operatorname{Gal}\bigl(\overline{\mathbb{Q}(t)}/\mathbb{Q}(t)\bigr)$? (Section 4.8 of the book I mentioned above)","['galois-theory', 'fundamental-groups', 'algebraic-geometry']"
2072253,Why do I first need to bring $-4x$ into the numerator in $\lim_{x\to \infty} 4x^2/(x-2) - 4x$,"I tried solving the question in the title as follows: $$\lim_{x\to \infty} \frac{4x^2}{x-2} - 4x \to 4x - 4x \to 0$$ However, apparently that first step ($\to 4x - 4x$) was wrong, and I should first have brought the second $4x$ into the numerator. My question is not how I need to solve the question, as I know that now. My question is why what I did was wrong, as I lack any intuition for it, and it seems a mystery to me.",['limits']
2072270,A partition problem,"I want to enumerate the partitions of $\{1,2,\ldots,n\}$ into disjoint sets $A$ and $B$ such that no subset of $B$ has a sum that is a member of $A$. For example, when $n=3$ there are $7$ such partitions: \begin{align*}
A&=\emptyset,B=\{1,2,3\}\\
A&=\{1\},B=\{2,3\},\\
A&=\{2\},B=\{1,3\},\\
A&=\{1,2\},B=\{3\},\\
A&=\{1,3\},B=\{2\},\\
A&=\{2,3\},B=\{1\},\\
A&=\{1,2,3\},B=\emptyset,
\end{align*} Note that $A=\{3\},B=\{1,2\}$ is not a valid since there is a subset of $B$ whose sum is a member of $A$, namely $B$ itself. That is, $1+2=3\in A$. I can do this numerically (by building the subsets recursively) but is there a way of theoretically determining this number?","['combinatorics', 'set-partition']"
2072275,"For the distribution $f_\theta (x) = \theta x^{\theta-1}$, what is the sufficient statistic corresponding to the Monotone Likelihood Ratio?","Suppose I have a sequence of iid random variables $X_1, \ldots, X_n$ following the pdf: $$
f_\theta (x) = \theta x^{\theta-1}
$$ for $\theta >0$ and $0 <x<1$. I would like to find a sufficient statistic $T(X)$, such that the family $f_\theta (x)$ has a monotone
likelihood ratio (MLR) in $T(X)$. I do this by having: $$
\frac{f(x|\theta_1)}{f(x|\theta_2)} = \frac{\prod_{i=1}^{n}\theta_1x_i^{\theta_1-1}}{\prod_{i=1}^{n}\theta_2x_i^{\theta_2-1}} = \left(\frac{\theta_1}{\theta_2}\right)^n \prod_{i=1}^n\left(x_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2}
$$ At this point, is the sufficient statistic corresponding to the MLR, $T(X) = \prod_{i=1}^nx_i$? Or would it be: $$
\frac{f(x|\theta_1)}{f(x|\theta_2)}  = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(e^{\sum_{i=1}^n \log(x_i)}\right)^{\theta_1-\theta_2}
$$ and hence the sufficient statistic is $\sum_{i=1}^n \log(x_i)$? I understand that sufficient statistics are not unique, but which one of the above is the right answer? Is it $T(X) = \prod_{i=1}^nx_i$ or $T(X) =\sum_{i=1}^n \log(x_i)$ ?","['statistics', 'probability', 'statistical-inference']"
2072293,How to evaluate $\int_0^{2\pi}\frac{1-\alpha\cos{\theta}}{r'^3}d\theta$,"Let $P$ be a fixed point inside a circle with radius $r$ and $Q$ a non-fixed point on its perimeter as shown below, and let $\alpha=\frac xr$ Is there any closed-form solution for the following integral?
$$\int_0^{2\pi}\frac{1-\alpha\cos{\theta}}{{r'}^{3}}d\theta$$
I tried Wolfram-Alpha without any luck. It doesn't look similar to any form of the integrals I have ever seen before. I appreciate if anybody gives it a try.","['definite-integrals', 'integration', 'trigonometry', 'contour-integration']"
2072337,Prove that $\lim_{x\rightarrow 0}\frac{1}{x^{4}}=\infty $,"Please check my proof :) We suppose that we are given $M\gt0$ we must find $\delta $ that $0<|x-0|<\delta \rightarrow \frac{1}{x^{4}}>M$ $$\frac{1}{x^{4}}>M$$ $$\frac{1}{M}>x^{4}$$ $$\frac{1}{\sqrt[4]{M}}>x$$ Choose $\delta =\frac{1}{\sqrt[4]{M}}$ Then $\frac{1}{\sqrt[4]{M}}>x\leftrightarrow \frac{1}{x}>\sqrt[4]{M}$ Then, limit is $\infty $","['real-analysis', 'proof-verification', 'limits']"
2072347,Limit of $\lim \limits_{x \to 0} \frac{\sin(5x)}{\sin(4x)}$,"I was trying to solve this problem, but couldn't figure it out. The solution goes like this: I don't understand the first step. Why is the limit multiplied by $\frac{4x}{5x}$? and $\frac{5}{4}$ ?","['trigonometry', 'limits']"
2072355,Show that :$\sum_{j=0}^{n}j{n\choose j}^2H_{n-j}={1\over 4}{2n\choose n}(4nH_{n}-2nH_{2n}-1)$,Where $H_0=0$ and $H_n$ is the n-th harmonic number. Show that this sum has a closed form $$\sum_{j=0}^{n}j{n\choose j}^2H_{n-j}={1\over 4}{2n\choose n}(4nH_{n}-2nH_{2n}-1)$$ I try: $j{2n\choose n}={(2n)!\over (j-1)!(2n-j)!}$ look more messier! I found two sum on Wikipedia site but it doesn't see more helpful at all! $$\sum_{j=1}^{n}H_j=(n+1)(H_{n+1}-1)$$ $$\sum_{j=0}^{n}{n\choose j}^2=2^n$$ Any help? Thank you!,"['harmonic-numbers', 'binomial-coefficients', 'sequences-and-series']"
2072359,Find the normal to the function,"Good day everyone, I think my teacher had made a mistake in a answer. She claims that this function cannot have normal that is parallel to $y=2x+7$ $f(x)=\ln(x+1)$ In my calculations it has : $y=-\frac{1}{2}x -\frac{1}{4} + \ln\frac{1}{2} $ Can you ansure me that it has ?",['functions']
2072371,$x^2+y^2=z^n$: Find solutions without Pythagoras!,"I was presented with the following problem: Prove that there exist solutions to $x^2+y^2=z^n$ for all $n$, with $x,y,z, n \in \mathbb{N}$ I showed that by taking any Pythagorean triple $x^2+y^2=z^2$ and multiplying by $z^{2(n-1)}$ we get $(z^{n-1}x)^2+(z^{n-1}y)^2=(z^2)^n$, which allows me to generate solutions easily for any value of $n$. I managed to find several similar questions on this site, such as this one concerning the specific case $n=3$. I notice that all of these questions take a similar approach and start with a Pythagorean triple and use it to generate general solutions. Is there a way to prove the statement (or better yet provide solutions to the equation) without first relying on Pythagoras?","['number-theory', 'diophantine-equations', 'pythagorean-triples']"
2072388,A relation between open and closed sets in Zariski tolopogy,"For a commutative ring $R$  with 1, if $\mathrm{Spec} (R)$ is the set of all 
prime ideals of $R$, we can define the Zariski Topology on $\mathrm{Spec} (R)$ 
as follows: 1) The sets of the form $$V(E)=\{P \in \mathrm{Spec}(R)|E \subseteq P\}$$ are closed subsets. 2)  The sets of the form $$D(E)=\{P \in \mathrm{Spec}(R) | E \not\subseteq P \},$$ are open subsets. Let $rad(I)$ denote the radical of an ideal $I$ of $R$; if $I$ and $J$ are two ideals 
of $R$, the relation $V(I) \subseteq V(J)$ is equivalent to 
$rad(J)\subseteq rad(I)$. Is there any equivalence conditions for $V(I) \subseteq D(J)$? \
And is there any equivalence conditions for $D(I) \subseteq V(J)$?","['zariski-topology', 'algebraic-geometry', 'commutative-algebra']"
2072415,Proof that the limit of the normal distribution for a standard deviation approximating 0 is the dirac delta function.,"so basically I want a proof for $\lim_{\epsilon\rightarrow 0}\frac{1}{\sqrt{2\pi\epsilon}}e^{\frac{-x^2}{2\epsilon}}=\delta(x)$ I don't yet care about proving $\int_{-\infty}^{\infty}dx\cdot\delta(x)=1$ I just want to prove that $\delta(x)=\lim_{\epsilon\rightarrow 0}\frac{1}{\sqrt{2\pi\epsilon}}e^{\frac{-x^2}{2\epsilon}}=0$ $\forall x\neq 0$ I don't have a clue how to solve the limit. I tried using L'Hospitals rule but it doesn't work and I'm completely clueless how I should be going about this. I mean, it makes sense that the limit is zero when I look at a graph of the normal distribution, but how can I prove that with equations? Thanks in advance!","['real-analysis', 'distribution-theory', 'limits']"
2072442,Does $\mathbb{E}\left[X\right]=\infty$ imply $\mathbb{E}\left[X^{2}\right]=\infty$?,I'm trying to prove that if $\mathbb{E}\left[X\right]=\infty$ then $\mathbb{E}\left[X^{2}\right]=\infty$ for every random variable $X$. I know that if $X(w)>1$ I'll get that $X^2(w)>X(w)$ so $\mathbb{E}\left[X^{2}\right]\ge\mathbb{E}\left[X\right]$ and if $X(w)\le1$ then $X^2(w)\le X(w)$  so $\mathbb{E}\left[X^{2}\right]=\sum\nolimits _{w\in\Omega}X^{2}\left(w\right)\cdot p(w)\le\sum\nolimits _{w\in\Omega}1\cdot p(w)=1$ But how do I prove it when some of the $w\in \Omega$ are larger than 1 and some are less ? Is this even the right way to prove this ?,"['expectation', 'probability', 'random-variables']"
2072444,"Prob 33, Ch. 3 - Two proofreaders reading a book with n typos - Discrete probability distributions, Blitzstein and Hwang","I would like someone to verify my result to parts (a) and (b) of this problem. A book has $n$ typos. Two proofreaders Prue and Frida independently read the book. Prue catches each typo with probability $p_{1}$ and misses it with probability $q_{1}=1-p_{1}$, and likewise for Frida, who has probabilities $p_{2}$ if catching and $q_{2}=1-p_{2}$ of missing each typo. Let $X_{1}$ be the number of typos caught by Prue, $X_{2}$ be the number of typos caught by Frida and $X$, be the number of typos caught by atleast one of the proofreaders. (a) Find the distribution of $X$. Solution. Define an r.v. $I_{p}$. $$\begin{align}
I_{p}&=1 \text{, if Prue catches an error}\\
&=0 \text{, if Prue misses to catch an error}
\end{align}$$ We have, $$\begin{align}
P(I_{p}=1)&=p_{1}\\
P(I_{p}=0)&=1-p_{1}
\end{align}$$ On similar lines, $$\begin{align}
P(I_{f}=1)&=p_{2}\\
P(I_{f}=0)&=1-p_{2}
\end{align}$$ We have, $\begin{align}
P(I_{p}=1\cup{I_{f}}=1)&=P(I_{p}=1)+P(I_{f}=1)-P(I_{p}=1,I_{f}=1)\\
&= p_{1}+p_{2}-p_{1}p_{2}
\end{align}$ Thus, define success as, a typo is caught by atleast one of the proof-readers. Each of the $n$ typos can be caught or missed by atleast one proofreader. These can be conceived as $n$ independent Bernoulli trials. Therefore, $X\sim{Binomial(n,p_{1}+p_{2}-p_{1}p_{2})}$. $\displaystyle{P(X=x)={{n}\choose{x}}(p_{1}+p_{2}-p_{1}p_{2})^{x}(1-p_{1}-p_{2}+p_{1}p_{2})^{n-x}}$ (b) For this part only, assume $p_{1}=p_{2}$. Find the conditional distribution of $X_{1}$, given that $X_{1}+X_{2}=t$. Solution. $\begin{align}
P(X_{1}=x|X_{1}+X_{2}=t)&=\frac{P(X_{1}=x,X_{1}+X_{2}=t)}{P(X_{1}+X_{2}=t)}\\
&=\frac{{{n}\choose{x}}p^{x}(1-p)^{n-x}{{n}\choose{t-x}}p^{t-x}(1-p)^{n-(t-x)}}{{{2n}\choose{t}}p^{t}(1-p)^{2n-t}}\\
&=\frac{{{n}\choose{x}}{{n}\choose{t-x}}}{{{2n}\choose{t}}}
\end{align}$","['independence', 'probability-theory', 'probability-distributions', 'binomial-distribution', 'probability']"
2072468,"How to prove $_2F_1\big(\tfrac16,\tfrac16;\tfrac23;-2^7\phi^9\big)=\large \frac{3}{5^{5/6}}\,\phi^{-1}\,$ with golden ratio $\phi$?","( Note : This is the case $a=\frac16$ of ${_2F_1\left(a ,a ;a +\tfrac12;-u\right)}=2^{a}\frac{\Gamma\big(a+\tfrac12\big)}{\sqrt\pi\,\Gamma(a)}\int_0^\infty\frac{dx}{(1+2u+\cosh x)^a}.\,$ There is also $a=\frac13$ and $a=\frac14$ .) After investigating $a=\frac13$ and $a=\frac14$ , I wondered if there was for $a=\frac16$ . And happily there was, $$\frac{1}{\color{red}{432}^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[6]{x^5+\color{blue}{\tfrac{125}3}x^6}}=\,_2F_1\big(\tfrac16,\tfrac16;\tfrac23;-\color{blue}{\tfrac{125}{3}})=\frac{2}{3^{5/6}}$$ $$\frac{1}{\color{red}{432}^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[6]{x^5+\color{blue}{2^7\phi^9}\, x^6}}=\,_2F_1\big(\tfrac16,\tfrac16;\tfrac23;-\color{blue}{2^7\phi^9})=\frac{3}{5^{5/6}}\phi^{-1}$$ The first was found by computer search and, from previous posts, the denominator with $K(k_3)$ was enough to give me a clue that $\tau=\frac{1+3\sqrt{-3}}2$ was involved. After fiddling around with some equations, a third conjecture can be made, that there is an infinite family of algebraic numbers $\alpha$ and $\beta$ such that, $$_2F_1\left(\frac16,\frac16;\frac23;-\alpha\right)=\beta$$ Conjecture: ""Let $\tau = \frac{1+p\sqrt{-3}}{2}$ with integer $p>1$ . Then $\alpha$ is the root of an analogous quadratic, $$16\cdot\color{red}{432}\,\alpha(1+\alpha)=-j(\tau)$$ with j-function $j(\tau)$ .
And if odd $p=3k\pm1$ is a prime, then $\alpha$ and $\beta^6$ are algebraic numbers of degree $k$ ."" $$\begin{array}{|c|c|c|c|c|}
\hline
p&\tau&\alpha(\tau)&\beta(\tau)&\text{Deg}\\
\hline
3&\frac{1+3\sqrt{-3}}2&\frac{125}3& \large\frac2{3^{5/6}}  &1\\
5&\frac{1+5\sqrt{-3}}2&2^7\phi^9& \large\frac3{5^{5/6}}\phi^{-1}  &2\\
7&\frac{1+7\sqrt{-3}}2&\Big(\frac{129 + 29\sqrt{21}}2\Big)^3& \large\frac47 \frac1{U_{21}^{1/2}} &2\\
11&\frac{1+11\sqrt{-3}}2& x_1 & \large\frac6{11} x_2 &4 \\
13&\frac{1+13\sqrt{-3}}2& y_1 & \large\frac7{13} y_2 &4 \\
\hline
\end{array}$$ $U_{21}=\frac{5+\sqrt{21}}2$ is a fundamental unit , while $x_i,y_i$ are roots of quartics which are rather tedious to write down. And so on. Q: How do we prove this conjecture? (And the other two?)","['conjectures', 'golden-ratio', 'calculus', 'hypergeometric-function', 'definite-integrals']"
2072469,What is the probability that each book does not have a neighbour of the same color?,"There are $13$ identical books which differ only in color: $2$ red, $5$ black and $6$ blue. They were randomly placed in a row. What is the probability of the event that there are no books of same color standing $2$ in a row? At first, I tried to put $6$ blue books in a row so there will be at least one space between them, and I found out that there are ${7 \choose 1}^2$ combinations to do so. But I do not know what to do next.","['combinatorics', 'probability']"
2072486,Continuous extension of Euclidean spaces?,"I am wondering if it is possible to ""continuously"" increase the dimension of Euclidean spaces â in other words, would it be possible to define Euclidean spaces of non-integer dimensions with nice topological properties? I have thought about the way to generalize Euclidean space with nonnegative real dimension, and here are some axioms that I have set. A sequence $\mathcal{R}$ of generalized topological spaces is given by the following data and properties: For each nonnegative real $d \geqslant 0$, there corresponds a topological space $\mathcal{R}(d)$. If $d \geqslant 0$ is an integer, then $\mathcal{R}(d)$ is homeomorphic to $\mathbb{R}^d$. If $d, e \geqslant 0$ satisfies $d \neq e$, then $\mathcal{R}(d)$ and $\mathcal{R}(e)$ are not homeomorphic to each other. For each pair of nonnegative reals $d \geqslant e \geqslant 0$, there corresponds an embedding (i.e. a continuous injection) $\rho_{ed} : \mathcal{R}(e) \rightarrow \mathcal{R}(d)$. If $d \geqslant 0$, then $\rho_{dd}$ is an identity function on $\mathcal{R}(D)$. If $d \geqslant e \geqslant f \geqslant 0$, then $\rho_{ed} \circ \rho_{fe} = \rho_{fd}$. Sequences of generalized Euclidean spaces, however, might not be set-theoretically unique, so we can define isomorphisms between such sequences. Two sequences $\mathcal{R}_1$ and $\mathcal{R}_2$ of generalized Euclidean spaces are said to isomorphic if: There exists a proper mapping $\varphi : \mathbb{R}_{\geqslant 0} \rightarrow \mathbb{R}_{\geqslant 0}$. For all $d \geqslant 0$, $\mathcal{R}_1(d)$ and $\mathcal{R}_2(\varphi(d))$ are homeomorphic to each other. Now I wonder if such sequence of generalized Euclidean spaces exists, and if it is unique up to isomorphism provided that it exists. Any feedback on either existence/uniqueness problem or general background of the question would be highly appreciated.",['general-topology']
2072624,"Find rational numbers $(x,y)$ such that $ (x^2 + y^2 - 2x)^2 = x^2 + y^2$","The general limaÃ§on has both a polar equation: $r = b + a \cos \theta  $ and an algebraic equation:
$$ (x^2 + y^2 - ax)^2 = b^2 (x^2 + y^2)$$
Can we find all the rational points on a curve like this? I want to consider the case $a = 2b$ and $b = 1$:
$$ (x^2 + y^2 - 2x)^2 = x^2 + y^2$$
One solution is $(x,y) = (0,1)$ and another is $(x,y) = (1,0)$. How can I generate the other solutions over $\mathbb{Q}$ ?","['algebra-precalculus', 'algebraic-curves', 'diophantine-equations', 'algebraic-geometry']"
2072637,A Problem from BdMO 2016 Regionals,"Fifty natural numbers are written in such a way so that sum of any four consecutive numbers is $53$. The first number is $3$, the $19^\text{th}$ number is eight times the $13^\text{th}$ number, and the $28^\text{th}$ number is five times the $37^\text{th}$ number. Find the $44^\text{th}$ number. I have nothing to say on this problem. How to solve this problem?","['algebra-precalculus', 'contest-math']"
2072668,"A generalization of the ""Four vertex theorem""",Assume that  $S$  is a  compact surface  in $\mathbb{R}^3$. Its  Gaussian curvature is  denoted  by $\kappa$. Is it true to say that $\kappa$  has  more than two critical points?,"['riemannian-geometry', 'differential-geometry', 'curvature']"
2072688,Is indefinite integration largely a heuristic or it can be mechanical too?,"I am sorry for putting multiple questions in the same post, but I think providing answers here will be better. As far as I know, there is no 'product formula' for integrals, like we have for the derivative. Also, I can be wrong, but I think a general class of functions, differing by a constant, have the same derivative. So, ignoring the constant, one might think that such a product formula might exist. So, my first question: Can it be proved that there is no 'product formula' for integrals, or
  is it just that it has not been discovered yet? Let us reduce our case to just rational functions. Partial fractions for integration is a pretty good technique, but I think it can't be used for all rational functions, because not all polynomials have all real roots. So: Is there a technique/algorithm to integrate all rational functions? Another open-ended question, that I think of, is that are there any techniques/formulas for integrals not discovered yet, or are the existence of these techniques/formulas been proven false by some theorem? Answer to any question is suffice. EDIT FROM HERE After reading some of the answers, I felt I need to be more precise. The integration by parts formula, as far as I know, is again a heuristic, and not mechanical. So, there is no scope for integration by parts theorem to be such a product formula. Another user answered that I thought of a formula combining functions in an elementary way, and proposed that it is well known that the sinc function does not have a closed form integral, and so such a formula doesn't exist. But, to add to this, there is also a possibility that such a formula may produce an undefined result, or some weird result, which we can relate to the absence of such a closed-form solution. What I am looking for is a theorem or result which clearly proves the non-existence of such a formula, taking into account all possibilities.","['integration', 'soft-question', 'calculus']"
2072693,"Matrix function converges, how about the eigenvalues?","Suppose I have a matrix function $A(t)$ with $$\lVert A(t) - B\rVert \le ct^\alpha$$ in some matrix norm (this will work for any norm, I guess). So, in a sense $A(t)\rightarrow B$ for $t\rightarrow 0$ in $\mathcal{O}(t^\alpha)$. Plus, we have $A(0) = B$. I happen to know the eigenvalues of $B$, but I don't know a thing about the eigenvalues of $A(t)$. Plus, $A(t)$ does not have any favorable structure, in particular, no symmetry. So, what can you say about the eigenvalues of $A(t)$? In particular: What about the spectral radius of $\lambda_{A(t)}$? Does it converge to the spectral radius of $B$? Do we have $\lambda_{A(t)}\rightarrow\lambda_B$ for $t\rightarrow 0$ for all eigenvalues $\lambda_{A(t)}$ of $A(t)$? And finally: is the speed of convergence $\mathcal{O}(t^\alpha)$ the same for the eigenvalues/spectral radius as for the matrix function? The last question is actually the most important one. If the eigenvalues of $B$ are all zero, the eigenvalues as well as the spectral radius of $A(t)$ would go to zero as $\mathcal{O}(t^\alpha)$... Any help would be appreciated, incl. references to (standard?) textbooks or papers on this matter. Maybe there is a counterexample? So far, in all numerical examples I have seen/done, all properties above do hold. Edit : To provide a bit more background: The matrices $A(t)$ are iteration matrices which depend on a time-step size $t$. They are not this  ugly, but showing convergence of this iteration has proven to be rather difficult. In the simplest case, they look like
$$A(t) = (I-tQ_1)^{-1}(t(Q_2-Q_1)+B)$$
with identity matrix $I$ and some matrices $Q_1,Q_2$, which do not have any particular structure we were able to exploit so far.
Now, if I can make that conclusion about the spectral radius as described above, I can state that the spectral radius is smaller than 1, i.e. the iteration converges, if the time-step size $t$ is small enough. Edit: Does this answer help? Also, this question might be related to perturbation theory for eigenvalue problems (with non-symmetric matrices, though, and $B$ is not diagonalizable).","['eigenvalues-eigenvectors', 'matrices', 'perturbation-theory', 'convergence-divergence', 'linear-algebra']"
2072706,Matrix determinant lemma derivation,"While reading this wikipedia article on the determinant lemma, I stumbled upon this expression (in a proof section):
\begin{equation}
\begin{pmatrix} \mathbf{I} & 0 \\ \mathbf{v}^\mathrm{T} & 1 \end{pmatrix}
\begin{pmatrix} \mathbf{I}+\mathbf{uv}^\mathrm{T} & \mathbf{u} \\ 0 & 1 \end{pmatrix}
\begin{pmatrix} \mathbf{I} & 0 \\ -\mathbf{v}^\mathrm{T} & 1 \end{pmatrix} =
\begin{pmatrix} \mathbf{I} & \mathbf{u} \\ 0 & 1 + \mathbf{v}^\mathrm{T}\mathbf{u} \end{pmatrix}.
\end{equation} Although I see that this equation ""works"", I'm interested in HOW this thing was invented. For example, why we have $u$ term in a central block matrix of the left side? UPD A little clarification of the question above. Let
\begin{equation}L = \begin{pmatrix} \mathbf{I} & 0 \\ \mathbf{v}^\mathrm{T} & 1 \end{pmatrix} \end{equation} I see that
\begin{equation}
L^{-1}=
\begin{pmatrix} \mathbf{I} & 0 \\ -\mathbf{v}^\mathrm{T} & 1 \end{pmatrix} 
\end{equation} and hence the first equation looks like 
\begin{equation}
L\begin{pmatrix}\mathbf{I + uv^T} & \mathbf{u} \\ 0 & 1\end{pmatrix}L^{-1} = 
\begin{pmatrix} \mathbf{I} & \mathbf{u} \\ 0 & 1 + \mathbf{v}^\mathrm{T}\mathbf{u} \end{pmatrix}.
\end{equation} I see that $\det(L) = \det(L^{-1}) = 1 $. Hence determinants of RHS and LHS are equal as well. What I do not understand is how we jumped from simple $\begin{pmatrix}\mathbf{I + uv^T} & \mathbf{0} \\ 0 & 1\end{pmatrix}$ or $\begin{pmatrix}\mathbf{I} & \mathbf{u} \\ \mathbf{-v}^T & 1\end{pmatrix}$ to $\begin{pmatrix}\mathbf{I + uv^T} & \mathbf{u} \\ 0 & 1\end{pmatrix}$ for a central part of LHS. Thank you.","['matrices', 'linear-algebra', 'determinant']"
2072755,"Prove that for each $n \in \mathbb N$, $\gamma_n=1+\frac{1}{2}+\dots+\frac{1}{n}-\int_1^n \frac{1}{x}dx$ is convergent [duplicate]","This question already has answers here : Is there another proof for EulerâMascheroni Constant? (4 answers) Closed 3 years ago . Question : For each $n \in \mathbb N$, Define : $\gamma_n=1+\frac{1}{2}+\dots+\frac{1}{n}-\int_1^n \frac{1}{x}dx$ Prove that $\{\gamma_n\}$ is convergent. Note 1 :  I know that $\sum_1^\infty \frac{1}{k}$ diverges. I can guess that this sequence is convergent to $0$ because of the similar terms inside the integration and outside of it.  The problem is that the integration is continuous. I mean that $x$ is not just integers.  What can we do with the values left?! ( For example, $\frac{1}{2.5}$ ) Also, Notice that this problem should be solved with some elementary tools.  ( It's from a part of my book which is even before any discussion about the Fundamental theorem of calculus. ) Note 2 : I'm not good at integration and i'm learning it. Any good details can help me. Thanks in advance.","['real-analysis', 'integration', 'harmonic-numbers', 'euler-mascheroni-constant']"
2072813,"What is the relationship between classical algebraic geometry, modern algebraic geometry, and actual curves?","I was interested the other day by a professor's research on using algebraic varieties to characterize certain sparse estimation problems. I then looked a little bit of Vakil's notes and went through a couple chapters of An Invitation to Algebraic Geometry . I can follow at a fine level, but I don't really understand the broader ideas. How exactly does commutative algebra elucidate geometric notions of the roots of polynomials (what even are they?)? Also, I understand the basic idea of a sheaf, but what do local rings and such have to do with actual curves in some space?","['sheaf-theory', 'algebraic-geometry']"
2072846,volume of a truncated cone that is not a frustum,I know the formula for a conical frustum is $$\frac{\pi h}{3}\left( r^2+rR+R^2 \right) $$ What would the formula be for the area of a truncated right circular cone be where the top is not parallel to the base. With the plane truncating the cone at an angle $\theta$ from parallel and $\theta <.5 \pi$.,"['volume', 'geometry']"
2072866,If $F$ is conservative.... does $\mathrm{curl}(F)$ really equal zero?,"My notes say that if $F$ is conservative (i.e. $F=\nabla f$) then $\text{curl }(F)=0$.  But I feel this is not quite right. There is a theorem that says that if $f(x,y,z)$ has continuous second order partial derivatives then $\text{curl }(\nabla f)=0$. (I'm fine with this theorem, it makes sense.) Obviously the 'proof' for my question is 
$$\text{curl }(F)=\text{curl }(\nabla f)=0$$ But I don't see why it is necessarily true that $f$ has continuous second order partial derivatives.  Is there something I am missing?","['multivariable-calculus', 'proof-explanation']"
2072897,Curious relation between $e$ and $\pi$ that produces almost integers,"I have seen in an article, without proof, that the following expression involving $e$ and $\pi$ is an almost integer very close to 1: $ e^{-\frac{\pi}{9}} + e^{-4\frac{\pi}{9}} + e^{-9\frac{\pi}{9}} + e^{-16\frac{\pi}{9}} + e^{-25\frac{\pi}{9}} + e^{-36\frac{\pi}{9}} + e^{-49\frac{\pi}{9}} + e^{-64\frac{\pi}{9}} = 1.0000000000010504... $ Furthermore, I have read that the following ""approximate theorem"" holds If $n$ is an odd square, then $\sum\limits_{k = 1}^{n-1} e^{-k^2\frac{\pi}{n}}$ is an almost integer. By some experiments I see easily that the integer being approximated is ($\sqrt{n} - 1)/2$ How to prove that this curious relation holds?","['real-analysis', 'taylor-expansion', 'exponential-function', 'pi', 'approximation']"
2072906,"If $\mathcal{A}$ is a basis for a topology, on $X$, show the topology generated by it equals the intersection of all topologies on $X$ containing $A$","Show that if $\mathcal{A}$  is a basis for a topology on $X$, then the topology generated by $\mathcal{A}$ equals the intersection of all topologies on $X$ that contain $A$ This what what I did before getting stuck Proof : The topology $\mathcal{T}$ on $X$ generated by the basis $\mathcal{A}$ is defined as follows: $$\mathcal{T} = \{ U \subset X \ | \  \forall x \in U, \exists A \in \mathcal{A} \ \text{ such that } x \in A \ \text{ and } A \subset U \}$$ Lemma : If $\mathcal{B}$ is a basis and $\mathcal{K}$ is the topology generated by $\mathcal{B}$, then $\mathcal{B} \subset \mathcal{K}$ Therefore we have $\mathcal{A} \subset \mathcal{T}$. Now let $\mathcal{F} = \{T_{\alpha}\}$ be the family of topologies on $X$ such that $\mathcal{A} \subset \mathcal{T_{\alpha}}$. Put $\mathcal{D} = \bigcap_{\alpha} \mathcal{T_{\alpha}}$, where $\mathcal{T_{\alpha}} \in \{\mathcal{T_{\alpha}}\}$. By a well known theorem $\mathcal{D}$ is a topology on $X$ (this can be easily proven but I've left it out here to keep the proof as short as possible) , and since $\mathcal{A} \subset \mathcal{T_{\alpha}}$ for every $\mathcal{T_{\alpha}} \in \{\mathcal{T_{\alpha}} \}$,we have $\mathcal{A} \subset \mathcal{D}$. But that is as far as I've got before getting stuck. To show that $\mathcal{T} = \mathcal{D}$, I can do one of two things Show that $\mathcal{T} \subset \mathcal{D}$ and $\mathcal{D} \subset \mathcal{T}$, and thus that $\mathcal{T} = \mathcal{D}$, by showing that each $U \in \mathcal{T} = U \in \mathcal{D}$ Show that $\mathcal{T}$ and $\mathcal{D}$ both have the same basis $\mathcal{A}$ and thus must be the same topology as every basis generates a unique topology. But in either case I'm not sure how to proceed. For 2, I could assume that $\mathcal{D}$ has some underlying basis $\mathcal{O} \neq \mathcal{A}$, and then  attempt to arrive at some contradiction, but I don't see how I would reach a contradiction here. For 1, I can show that $U \in \mathcal{T}$ can be expressed as the union of basis elements, but for $U \in \mathcal{D}$ all I know is that $U \in \mathcal{T_{\alpha}}$ for every $\alpha$, and that for one $\alpha$ we have $\mathcal{T_{\alpha}} = \mathcal{T}$. How could I complete this proof using approach 1, or 2? Or is there a shorter easier way to complete this proof?","['general-topology', 'proof-writing', 'elementary-set-theory', 'proof-verification']"
2072971,"Is rational equivalence of algebraic cycles ""transitive""?","Let $X$ be a $k$-scheme, and let $A$ and $B$ be algebraic cycles on $X$ (i.e., irreducible subvarieties). Recall that $A$ is rationally equivalent to $B$ if there is a finite sequence of cycles $A_1, \dots, A_n$ on $X$ with $A_1 = A$ and $A_n = B$ such that for each $i$, there exists a flat family over $\mathbb{P}_k^1$ of cycles on $X$ interpolating between $A_i$ and $A_{i+1}$. It follows immediately from the above definition that rational equivalence is transitive. However, I'm looking for something a bit stronger: if $A$ and $B$ are rationally equivalent cycles on $X$, does there exist a flat family over $\mathbb{P}_k^1$ of cycles on $X$ interpolating between $A$ and $B$? This is equivalent to asking whether the existence of such an interpolating family is a transitive condition.","['intersection-theory', 'algebraic-geometry']"
2072989,Antiderivative of CDF,"Let $F(x)$ be the CDF of a random variable. Does its antiderivative $$
\int_{-\infty}^x F(x') dx'
$$ have an interpretation?","['probability-theory', 'probability', 'probability-distributions']"
2072991,What affine line are we considering when defining a geometric vector bundle over a scheme $X$?,"I recently began studying algebraic geometry, and in an attempt to learn about Abelian Varieties, I needed to learn the definition of a geometric vector bundle. I began reading this book , and in the notation section, it states: By a geometric vector bundle of rank $d$ on $X$ we mean a group scheme $Ï: \mathbb V \to X$ over $X$ for which there exists an affine open covering $X = \bigcup U_\alpha$ such that the restriction of $\mathbb V$ to each $U_\alpha$ is isomorphic to $\mathbb G^d_a$ over $U_\alpha$. I assume the $\mathbb G_a$ is the additive group of $\mathbb A^1$, but I am not sure what field $\mathbb A^1$ comes from. Could someone enlighten me? Thanks ever so much! :)","['schemes', 'vector-bundles', 'algebraic-geometry']"
2073028,"Lebesgue integration on $[0,1]$ of $x^\alpha$","This question has been asked before here , but no one really dealt with the problem, and just critiqued the user's method, which seems to have been what the poster wanted. I'm looking for the full solution. In other words, is my full answer correct? If not, what should the changes be? I can find small details all over the place on Math.SE but for my own confidence (and reference), I would be very happy to have the full solution here. Perhaps others will benefit, too. My answer seems too easy to be correct, and I am suspicious that the Monotone and/or Dominated convergence theorems don't make an appearance in my solution. We are in Royden's ""Real Analysis"", page 84, question 19. The question states: ""For a number $\alpha$, define $f(x)=x^\alpha$ for $0<x\leq 1$ and $f(0)=0$. Compute $\int\limits_{0}^{1}f.$"" Now, for $\alpha\geq0$, the problem is easy, as the function is Riemann integrable, and we obtain $\frac{1}{\alpha+1}$. But what about $\alpha<0$? It seems that the three cases are then $-1<\alpha<0$, $\alpha=-1$, and $\alpha<-1$. In the second, we obtain: $$-\lim\limits_{\varepsilon\to0^+}\ln\varepsilon=\infty.$$ In the last, we obtain: $$\frac{1}{\alpha+1}+\lim\limits_{\varepsilon\to0^+}\frac{\varepsilon^{\alpha+1}}{\alpha+1}=\infty,$$
since $\alpha+1<0$. In the first, we obtain:
$$\frac{1}{\alpha+1}+\lim\limits_{\varepsilon\to0^+}\frac{\varepsilon^{\alpha+1}}{\alpha+1}=\frac{1}{\alpha+1},$$
since $\alpha+1>0$. So, is my answer correct when I say $\int\limits_{0}^{1}f=\frac{1}{1+\alpha}$ for $\alpha>-1$ and $\int\limits_{0}^{1}f=\infty$ otherwise? Is the whole point of the problem that $x^\alpha$ is not Lebesgue integrable for $\alpha<-1$?","['real-analysis', 'integration', 'lebesgue-integral', 'calculus']"
2073046,How to differentiate $y=\ln(x+\sqrt{1+x^2})$?,"I'm trying to differentiate the equation below but I fear there must have been an error made. I can't seem to reconcile to the correct answer. The problem comes from James Stewart's Calculus Early Transcendentals, 7th Ed., Page 223, Exercise 25. Please differentiate $y=\ln(x+\sqrt{1+x^2})$ My Answer: Differentiate using the natural log rule:
$$y'=\left(\frac{1}{x+(1+x^2)^{1/2}}\right)\cdot\left(x+(1+x^2)^{1/2}\right)'$$ Now to differentiate the second term, note the chain rule applied and then simplification: $$\left(x+(1+x^2)^{1/2}\right)'=1+\frac{1}{2}\cdot(1+x^2)^{-1/2}\cdot(2x)$$ $$1+\frac{1}{2}\cdot(1+x^2)^{-1/2}\cdot(2x)=1+\frac{x}{(1+x^2)^{1/2}}$$ Our expression is now: $$y'=\left(\frac{1}{x+(1+x^2)^{1/2}}\right)\cdot\left(1+\frac{x}{(1+x^2)^{1/2}}\right)$$ Distribute the left term across the two right terms for my result: $$y'=\left(\frac{1}{x+(1+x^2)^{1/2}}\right)+\left(\frac{x}{\left(x+(1+x^2)^{1/2}\right)\left(1+x^2\right)^{1/2}}\right)$$
$$y'=\left(\frac{1}{x+(1+x^2)^{1/2}}\right)+\left(\frac{x}{\left(x(1+x^2)^{1/2}\right)+(1+x^2)^{1}}\right)$$ At this point I can see that if I simplify further by adding the fractions I'll still have too many terms, and it will get awfully messy. The answer per the book (below) has far fewer terms than mine. I'd just like to know where I've gone wrong in my algebra. Thank you for your help. Here's the correct answer: $$y'=\frac{1}{\sqrt{1+x^2}}$$","['derivatives', 'calculus']"
2073057,Examples of closed sets with empty interior,"Could I please have an example of closed sets with empty interior? Any topological space. Everything goes. Remark: 
This is not homework. 
I'm in the middle of proving the space of $n$-degree polynomials in $(C[0,1], \lVert \cdot \rVert_\infty)$  is meager. Empty interior of this set (if I'm at all correct...) is the punchline and I just want to understand a bit more the nature of closed sets with empty interior.","['general-topology', 'real-analysis', 'examples-counterexamples', 'baire-category']"
2073088,Determine the stability of a system,"For the system
  $$x'=y(1+r^2),~~y'=-x(1+r^2),$$
  where $r=x^2+y^2,$ determine whether this is asymptotically stable or not. My approach: Writing in terms of Polar coordinates, $x=r \cos \theta,~y=r \sin \theta$ and simplifying, I got 
$$r'=0,~~\theta'=-1-r^2.$$
By integrating, 
$$r=r_0,~~\theta=\theta_0 -(r_0^2 + 1)t.$$
From this it's clear these form a family of periodic orbits with each being a circle in the phase plane. So they are orbitally stable. But what can I say about the asymptotic stability ?","['stability-in-odes', 'ordinary-differential-equations']"
2073089,Tricky integral,"I am trying to do the following integral for a few days now, but getting nowhere. \begin{align}
\int_0^x \mathrm dy\,y^2 \cos(y^2) C^2 \!\!\left(\!\dfrac{\sqrt{2}\,y}{\sqrt\pi}\!\right)\!
\end{align} In reality only the first one is causing me troubles, however I have pasted the entire expression as it might lead to some cancellations. Any help would be welcome. $C()$ is the Fresnel integral.","['indefinite-integrals', 'fresnel-integrals', 'integration', 'definite-integrals']"
2073092,Eigenstructure of a matrix polynomial,"Given a square matrix A and a polynomial p(x), what is the eigenstructure of p(A)? I can show that if $\{ \lambda_i \}_{i=1,2,...n}$ is the spectrum of $A$,
then $\{ p(\lambda_i \}_{i=1,2,...n}$ is the spectrum of $p(A)$. the geometric multiplicity of an eigenvalue $\lambda$ of $A$ is
less than or equal to the geometric multiplicity of $p(\lambda)$
of $p(A)$. What I do not know is what happens to the algebraic multiplicites.
Any pointers?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2073097,Characteristic Function of Geometric Brownian motion - PDE with terminal condition approach,"I want to compute the characteristic function of the standard geometric brownian motion. Note that I know that it is easy when you exploit the distributional properties of the process, but I'm trying to come up with some exercises by myself in order to apply the same approach to broader classes of stochastic processes.
Consider the usual equation of the GBM:
$$
dX_t = \mu X_t dt + \sigma X_t dW_t
$$ Then, by Feynman-Kac, we have to solve the PDE:
$$
\frac{\partial f}{\partial t} + \mu x \frac{\partial f}{\partial x} + \frac{1}{2}\sigma^2 x \frac{\partial^2 f}{\partial x^2} = 0
$$
In order to find the characteristic function, we have to take into account the terminal condition
$$
f(x,T) = \exp(i \omega x)
$$
Substituting $f(x,T)$ inside the PDE yields
$$
\mu x i \omega \exp(i \omega x) - \frac{1}{2}\sigma^2 x \omega^2 \exp(i \omega x)=0
$$
But then, how do I proceed? The above doesn't look at all like the characteristic function of a random variable with lognormal distribution ).
Obviously considering the logarithm of $\frac{dX_t}{X_t}$ simplifies things a lot, however I really want to came up with the characteristic function of $X_t$, not its logarithm (see p. 41-42 in Pricing Bermudan and American Options Using the FFT Method ). I hope that somebody can help me, or even discuss things a little bit. By the way, excuse me for my poor way of handling PDEs. :)","['stochastic-processes', 'partial-differential-equations', 'characteristic-functions', 'probability-theory', 'brownian-motion']"
2073101,Factorial-like function that behaves like $ 1\times \sqrt{2} \times \sqrt[3]{3} \times \dots \times \sqrt[n-1]{n-1} \times \sqrt[n]{n} $?,"The Barnes G-function is a generalization of the factorial funcion which grows a lot faster.  The factorial: $$ n! = 1 \times 2 \times 3 \times \dots \times (n-1) \times  n  $$ Then it is possible to write a super-factorial : $$ n!! = 1! \times 2! \times 3! \times \dots \times (n-1)! \times  n!
= 1^n \times 2^{n-1} \times \dots \times (n-1)^2 \times n^1  $$ For a given combinatorics function $f(n)$ we can try to extend to $f(x)$ with $n < x < n+1$.  The super-factorial can be continued to the Barnes G-function . How can I get a function that behaves like the product of successive $n$-th roots? $$ f(n) =  1\times \sqrt{2} \times \sqrt[3]{3} \times \dots \times \sqrt[n-1]{n-1} \times \sqrt[n]{n} $$ I tried looking amongst the multiple gamma functions but there is no negative multiple Gamma functions... now what?","['algebra-precalculus', 'combinatorics', 'permutations', 'interpolation']"
2073120,Natural line bundle over $\mathbb{P}^n$,"What follows is from the book ""Mirror Symmetry"" by Hori et. al. From the definition of $\mathbb{P}^n$ we see there is a natural line bundle over $\mathbb{P}^n$ whose fiber over a point $l$ in $\mathbb{P}^n$ is the line it represents in $\mathbb{C}^{n+1}$. Define $J â \mathbb{P}^n  \times \mathbb{C}^{n+1}$ to be $\{(l,v) : v \in l \}$. $J$ is called the âtautological line bundle.â Suppose we have coordinates $X_k$ on $\mathbb{C}^{n+1}$ with which to describe the point $v$. Then $X_k$ is a linear map from the fiber $J_l$ to $\mathbb{C}$. In other words, $X_k$ is a section of $\text{Hom}(J, \mathbb{C})$, the line bundle dual to $J$. Let us call this $H$. Note that the equation $X_k = 0$ makes sense on $\mathbb{P}^n$, and its solution defines a hyperplane (hence the â$H$â). So here is my confusion : First of all in a local neighbourhood $U \in \mathbb{P}^n$ the bundle should look as $U \times \mathbb{C}^{*}$, since it is a line bundle the rank of the fiber should be $1$ and not $n+1$. Is this correct? Then the line bundle $J$ should look for some trivialisation $i$ as $J = U_i \times \mathbb{C}^{*}$. Is there some mistake in the first two lines of the quoted text? According to the text the tautological line bundle is the one given by $J â \mathbb{P}^n  \times \mathbb{C}^{n+1}$ to be $\{(l,v) : v \in l \}$. Another thing is that the tautological line bundle $\mathcal{O}(-1)$ has sections which are inverses of polynomials of degree $1$. How does one see this from the definition given above? For example if $\{ x_i \}$ are coordinates in $\mathbb{P}^n$ for $i=0,\ldots,n$ then $1/x_i$ is a section and of course when multiplying with a section of the dual bundle gives back a c-number. Therefore, I conclude that their $X_k$ is a coordinate on $\mathbb{C}^{n+1}$ as they say and as a section of the tautological bundle it is just $1/X_k$. Is this a correct way to think about it at least for projective spaces (and their blow ups possibly?) A follow up : Sections of the hyperplane bundle $\mathcal{O}(1)$ at $U_i$ look like $X_i$. Then, how exactly do we obtain the hyperplane divisor and the canonical divisor?","['sheaf-theory', 'projective-geometry', 'algebraic-geometry', 'holomorphic-bundles']"
2073128,sum of the power of fermat point,"conjectureï¼ Let $ O, $ $ F_1, $ $ F_2 $ be the circumcenter, 1st Fermat point , 2nd Fermat point of $ \triangle ABC, $ respectively. Prove that $$ \text{Power of } F_1 \text{ WRT } \odot (O) \text{ + Power of } F_2 \text{ WRT } \odot (O) \text{ = } -{F_1F_2}^2. $$(the power of WRT see: Power WRT ) I have use GeoGebra test this conjecture are right:see this following But How to prove this",['geometry']
2073137,Applications of Switching Sums and Integrals,"Under some nice conditions, we can perform the following 'trick' of switching sums and integrals: $$\sum \int f_n(x) dx = \int \sum f_n(x) dx.$$
(We will ignore issues of convergence.) This trick can be used to prove a lot of interesting limits such as 
$$\sum_{n = 1}^{\infty} \frac{1}{\binom{2n}n} = \frac{1}3 + \frac{2\sqrt{3} \pi}{27}$$ or $$\sum_{n = 0}^{\infty} \frac{1}{C_n} = 1 + \frac{4 \pi}{9 \sqrt{3}}$$ where $C_n$ is the $n$th Catalan numbers. 
Are there any other interesting or surprising examples that this community is aware of?","['summation', 'integration', 'limits']"
2073148,Fully invariant subgroups,The following proposition is a well-known theorem but I don't know where I can find its proof. Let $G$ be a finite group. Then every subgroup of $G$ is a fully invariant subgroup if and only if $G$ is cyclic group. Thank you in advance,['group-theory']
2073149,What are the good books or lecture notes for learning field extension and Galois theory?,I am a undergraduate student with some knowledge of group theory and ring theory. May I ask how should I do to  get start to field theory? Could someone tell me what are good to read? Thanks in advance!,"['galois-theory', 'big-list', 'abstract-algebra', 'extension-field', 'field-theory']"
2073155,Convergence to $\pi$,"Assume a square inscribed in a circle. Rotate it by $45^\circ$ and superimpose on the original square. Rotate by $22.5^\circ$ the resulting star like shape and superimpose on the previous shape. Continue this way, each time the rotation is half the previous one and superimpose on the last created shape. The area of the resulting shapes is converging to the area of the circle.
Assuming the circle with radius of 1 (area is $\pi$), the sequence for computing the area of the resulting shape may be derived as follows:
$$2^{n-1}[1-\tan(\pi /4-\pi /2^n)]$$
This converges to $\pi$, as $n \to \infty$, ""based"" on the geometrical process described.
How is this proven by analytical means?
A side note - you may start with any regular polygon and develop a a similar equation that converges to $\pi$ in a slightly different way.
It is also interesting that the perimeter of the shapes is not converting to the expected $2\pi$.","['sequences-and-series', 'geometry']"
2073196,"Suppose X and Y are i.i.d and $\frac{X+Y}{\sqrt{2}}\overset{d}=X\overset{d}=Y$, show that X has a normal distribution.","Suppose $X$ and $Y$ are independent with mean zero and variance 1, and
$\frac{X+Y}{\sqrt{2}}\overset{d}=X\overset{d}=Y$. Use the CLT to show that $X\sim \mathcal N(0,1)$. I saw in many places that set $\frac{S_{2^n}}{\sqrt{2^n}}$ to prove the problem. Is it feasible to go through the proof by using $\frac{S_{2n}}{\sqrt{2n}}$? I see, we need to set $\frac{S_{2^n}}{\sqrt{2^n}}$. Thus $X\overset{d}=\frac{S_{2^n}}{\sqrt{2^n}}\overset{d}\to \mathcal N(0,1)$.","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2073198,Noncontractible space with zero homology groups?,"If we define $X\subset\ell^2$ to be the unit sphere, i.e. $$X=\left\{(x_i)_{i=1}^\infty\ \Bigg|\ \sum_{i=1}^\infty x_i^2 = 1\right\}$$ then since $X$ is path connected and not compact, and since $X\setminus\{x\}$ is contractible for all $x\in X$, then a simple calculation shows that $\tilde{H}_n(X)=0$ for all $n$. Now, I wish to show that $X$ is not contractible. Assuming we have a contraction to a point $x$, we can use a change of orthonormal basis to obtain a contraction to the point $e_1=(1,0,0,\ldots)$, i.e. a continuous map $h:X\times I\to X$ such that $h(\bullet,0)=\mathrm{id}_X$ and $h(\bullet,1)\equiv e_1$. However, I'm struggling to get a contradiction here, since I know of no stronger invariant than homology/homotopy groups, and by compactness arguments, these are all trivial.","['algebraic-topology', 'general-topology']"
2073230,How could I show $(\frac{n+0.06}{n})^n$ is an increasing function for $\forall n\in \mathbb{N}$?,"I thought I'd might use induction, but that seems too hard, then I tried to take the derivative and show that that's positive $\forall$n. But I can't figure out how to do that either, I've tried induction there too.","['functional-analysis', 'number-theory', 'discrete-mathematics']"
2073244,"The digits of a positive integer, having three digits, are in A.P and their sum is $15$. The number ..","The digits of a positive integer, having three digits, are in A.P and their sum is $15$. The number obtained by reversing the digits is $594$ less than the original number. Find the original number. My Attempt: Let the three digits number be $100x+10y+z$ where $x$, $y$ and $z$ are in A.P. Then, $y=\frac {x+z}{2}$ $2y=x+z$. Then, what should I do??",['sequences-and-series']
2073251,minimum value of $f(t) = 10t^6-24t^5+15t^4+40t^2+108$ without derivative,"minimum value of $f(t) = 10t^6-24t^5+15t^4+40t^2+108$ without derivative for $t\leq 0$ value of function $f(t)\geq 108$ i wan,t be able to proceed after that ,could some help me with this",['algebra-precalculus']
2073257,To prove $\omega_1 \cup \{\omega_1\} $ is not first countable but $\omega_1$ is,"The topological space $X=\omega_1\cup \{\omega_1\}$ is not first countable but $\omega_1$ is. Here $\omega_1$ denotes the set of all countable ordinals and $\{\omega_1\}$ is the first uncountable ordinal. Cardinality of $\omega_1$ is $\aleph_1.$And also $\omega_1$ is called the limit ordinal meaning it is the limit point of the set $\omega_1.$ Here I want to prove two things. $1)$ $\omega_1$ is first countable. and $2)$ $\{\omega_1\}$ is the limit point of $\omega_1$. But since no sequence converges to $\{\omega_1\}$, using this I could say that our space $X$ is not first countable. $1)$ The proof of this I got from here with just one question: it says we need to prove that such an $S(y)$ exists,and I'm thinking $S(y)=\cap\{u\in \omega_1:u\gt y\}.$ This is correct$?$ But here is a chance that the countable base around $y$ may be finite and not countably infinite. $2)$ If possible let us assume that $\omega_1$ is not a limit point of the set $\omega_1.$ $U$ be a nbd of $\omega_1$ that does not intersect $\omega_1.$ Then what are the elements of $U$ like? The ones coming before $\omega_1$  cannot be uncountable because $\omega_1$  is the first. Then they must be countable. This is absurd so no such $U$ exists. Thus $\{\omega_1\}$ is a limit point. Are my proofs correct? Thank you.","['general-topology', 'first-countable', 'proof-verification', 'ordinals']"
2073264,"Do directional derivatives require direction vectors to have unit length? If so, why?","I have just started studying directional derivative from the book Mathematical Analysis by T.M. Apostol. The directional derivative is the generalization of partial derivative. The partial derivative represents the rate of change of a function due to small change of one of the independent variables involved, whereas the directional derivative represents the rate of change of the function due to the small change of a point in it's domain along any arbitrary direction. The concept of directional derivative is as follows : Let $\mathbf{f} : S \longrightarrow \mathbb R^{m}$ be a vector valued function defined over $S \subset \mathbb R^{n}$ . Suppose we are to find out the rate of change of $\mathbf{f}$ when we move from a point $\mathbf{c}$ of $S$ to a nearby point $\mathbf{c} + \mathbf{u}$ along a line segment. Since each point of the line can be taken as $\mathbf{c} + h\mathbf{u}$ for some $h \in \mathbb R$ , we can take $h$ sufficiently small so that $\mathbf{c} + h\mathbf{u}$ is in $S$ . Then the quantity $$\lim_{h \rightarrow 0} \frac {\mathbf{f}(\mathbf{c} + h\mathbf{u}) - \mathbf{f}(\mathbf{c})} {h}$$ if it exists is called the directional derivative of $\mathbf{f}$ at $\mathbf{c} \in S$ in the direction of $\mathbf{u}$ . I am having some difficulty here. According to my teacher's lecture notes, $||\mathbf{u}|| = 1$ . For this reason the directional derivative of a given function $\mathbf{f}$ at a point along some certain direction may differ. Is there any significance of considering $||\mathbf{u}|| = 1$ ? If the answer to my question is affirmative, then why?","['multivariable-calculus', 'derivatives']"
2073272,Probability of Choosing an Item in Weighted Random Sampling Without Replacement,"Consider the problem of randomly sampling $k$ distinct items from a population of $n$ items without replacement. If all items have the
same weight, then the probability that a specific item is among the $k$ selected items is $\binom{n-1}{k-1} / \binom{n}{k}$. Now suppose that items are weighted and the probability of each item
being selected is determined by its relative weight: Input: Set $N=\{1,\dots,n\}$ items with weights $W=\{w_1,\dots,w_n\}$ Output: Set $S$ of $k$ randomly selected items without replacement Repeat k times probability of $i \in N \setminus S$ being selected = $\frac{w_i}{\sum_{j\in N \setminus S}w_j}$ randomly select an item from $N \setminus S$ and add it to $S$. What is the probability that a specific item is among the $k$ selected items in weighted random sampling without replacement?","['statistics', 'sampling', 'probability']"
2073283,software for Nullstellensatz certificate of infeasibility,"I was wondering if anyone could recommend software to construct a real Nullstellensatz certificate that a system of polynomial equations has no real solution.  The system of about 20 polynomials equations is cubic at most.  I was interested in something that applied, or is similar to, (Nullstellensatz Linear Algebra (NulLA) Algorithm) as described here https://www.usna.edu/Users/math/margulies/papers/nulla_issac.pdf My understanding is that if the certificate is of degree 1 then I'll have about 400 linear equations, but that if its of degree 2 then this explodes to 8000 or so.  Hence the need for some purpose built software. Any suggestions or approaches much appreciated (I have a science not math background). thanks","['computational-mathematics', 'algebraic-geometry']"
2073284,Finding the $k^{th}$ root modulo m,"We know that method of finding $k^{th}$ root modulo $m$ , i.e. if $$x^k\equiv b\pmod m,\tag {$\clubsuit$}$$ with $\gcd (b,m)=1$ , and $\gcd(k,\varphi(m))=1$ , then $x\equiv b^u\pmod m$ is a solution to $(\clubsuit)$ , where $ku-v\varphi(m)=1$ .  Because $$\begin{array}
{}x^k &\equiv \left(b^u\right)^k\pmod m\\
&\equiv b^{uk}\pmod m\\
&\equiv b^{1+v\varphi (m)}\pmod m\\
&\equiv b\cdot b^{v\varphi(m)}\pmod m\\
&\equiv b\cdot \left(b^{\varphi (m)}\right)^v\pmod m\\
&\equiv b\pmod m
\end{array}$$ Thus $x\equiv b^u\pmod m$ is a solution to $(\clubsuit)$ . Here we use $\gcd(b,m)=1$ , since we used Euler's theorem that $b^{\varphi(m)}\equiv1\pmod m$ . But I am asked to prove that if $m$ is the product of distinct primes, then $x\equiv b^u \pmod m$ is always a solution, even if $\gcd (b,m)\gt1.$ What I did, is say $m=p_1p_2$ . Then $\varphi(m)=(p_1-1)(p_2-1)$ $$\begin{array}
{}b^{uk}&\equiv b\cdot b^{\varphi (m)}\pmod m\\
&\equiv b\cdot b^{(p_1-1)(p_2-1)}\pmod m
\end{array}$$ Now, we just have to compute $b^{(p_1-1)(p_2-1)}\pmod {p_i}$ . Here I got stuck, because I really can't use the little theorem for every $p_i$ 's, since some $p_i$ can exist in $b$ . Can someone help me?","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
2073292,Sum of two sets,"Let $P$ and $Q$ be two non-empty subsets of a normed linear space $X$ and let $$P+Q=\{x+y\in X: x\in P\mbox{ and }y\in Q\}.$$ 
Then which of the following is FALSE? If $P$ or $Q$ are convex, then $P+Q$ is convex. If $P$ or $Q$ is open, then $P+Q$ is open. P+Q must be closed if P and Q are closed. If $P$ is closed and $Q$ is compact, then $P+Q$ is closed. I think 1st is false, because if one set is not convex, then on addiction with a convex set, the resultant might not be convex. But in one answer key, the answer is given as 3rd. In another, the answer is given as 4th. But I am not able to think of counter examples for either 3rd or 4th.",['general-topology']
2073351,Can you get a basis for an infinite direct product of vector spaces from a basis for each factor?,"If $\{V_i\}_{i\in I}$ is a family of vector spaces over $F$ with basis $B_i$ for each $V_i$, then there is a vector space $\prod_i V_i$ over $F$, called the direct product of $V_i$'s; its definition involves a certain universal property in terms from projections from it onto $V_i$'s (see this wiki ) Since every vector space has a basis, $\prod_i V_i$ has so. Q. Can we obtain basis a of $\prod_i V_i$ from given basis $B_i$ of each $V_i$? I am not too familiar with Category theory; please explain in as elementary fashion as you can, so that this will be also accessible to undergraduates; I want to explain this in my Linear Algebra course to undergraduates, and my aim is to introduce maximum number of advanced concepts of other areas of mathematics from starting point in Linear Algebra.","['direct-product', 'linear-algebra', 'vector-spaces']"
2073354,Intuition behind a probability measure,"These are some related questions to the question posed here . I don't think it's a duplicate. What is a probability measure? How do they differ from measure spaces? And could anyone elaborate on the ""physical"" interpretation of a probability measure? For any measurable subset here, what is its interpretation of its measure? Can anybody answer these questions by providing some enlightening examples along the way?","['probability-theory', 'probability', 'measure-theory']"
2073372,Hopf bifurcation in a simple system,"Given the system: $$ 
\dot{r} = -\mu r + r^3, \\
\dot{\theta} = r
$$ There is clearly one single node at $r=0$. The Jacobian is then: $$  \begin{pmatrix}
        -\mu + 3r^2 & 0 \\
        1 & 0
        \end{pmatrix}$$
Setting $r=0$ and finding the eigenvalues I get:
$\lambda = 0 , \lambda = -\mu $.
The problem statement says ""show that a subcritical Hopf bifurcation occurs at the parameter value $\mu = 0$ "".
I don't see how a Hopf bifurcation appears here when all my eigenvalues are all real and I am failing to interpret $\lambda = 0$","['eigenvalues-eigenvectors', 'ordinary-differential-equations', 'dynamical-systems']"
2073400,Equivalent definitions of Fano variety,"Given a projective variety $X\subseteq\mathbb{P}^n$, Harris defines the Fano variety of $k$-planes contained in $X$ as:
$$
F_k(X)=\{\Lambda:\Lambda\subseteq X\}\subseteq Gr(k,n).
$$
On the other hand, a lot of sources (like Wikipedia ) define a Fano variety to be a complete (let's say projective) variety whose anticanonical bundle is ample. I'd like to know the exact relation between these definitions, either in an answer or references. I'd imagine any variety of the first kind satisfies the second condition (can this be shown in an answer?), but I'm not sure if it's reasonable to expect a variety with ample anticanonical bundle to be necessarily of the first kind for some $X$ and $k$, or even to be a subvariety of a Grassmannian.",['algebraic-geometry']
2073427,Must every subset of $\mathbb R$ contain $2$ homeomorphic distinct open sets?,"Take $X\subseteq\mathbb R$ containing at least $2$ points, I want to prove or construct a counterexample to the statement ""$X$ contains $2$ distinct open sets which are homeomorphic"" (where $X$ is equipped with the induced topology and $\mathbb R$ with the standard one). I'm asking this question because it was posted as a comment to another question on MSE but the comment was deleted shortly afterward and I'm curious about the answer, if you are the person who wrote that comment and figured it out let me know. Some thoughts: suppose that $X$ is a counterexample to this statement, clearly it can contain at most a single isolated point and no intervals, so $X$ is totally disconnected. If $X$ contains no isolated points it can't be closed (or better perfect) because it'll either be homeomorphic to the Cantor set if it's also compact or $X\cap[a,b]$ will be homeomorphic to the Cantor set for some closed interval such that the intersection isn't empty. A similar approach works if $X$ is closed and has a single isolated point. So $X$ must be neither closed nor open, but I don't know how to conclude, what do totally disconnected, (almost) everywhere dense subset of $\mathbb R$ which are neither open nor closed look like? Or is there an entirely different (and maybe more straightforward) approach to this question?",['general-topology']
2073447,When regularity implies normality,"Let $X$ be a hausdorff topological space. It is well known that if $X$ is  regular and lindelof then it is normal. Is the any other topological property $*$ for $X$ such that ""regular+$*\rightarrow$ normal""?",['general-topology']
2073455,Theorem of Cauchy,"Let $f:[a,b] \to \mathbb{R}$ be continuous and differentiable in $(a,b)$. Prove that there exists $ \alpha\in (a,b)$ such that $$\frac{b f(a) -a f(b)}{b-a} = f(\alpha) - \alpha f'(\alpha).$$","['derivatives', 'real-analysis']"
2073466,"Exists $a < c < b$ where $\int_a^b (b - x)^n f^{(n + 1)}(x)\,dx = {{f^{(n + 1)}(c)}\over{n + 1}}(b - a)^{n + 1}$?","Let $\tilde{a} < a < b < \tilde{b}$ and let $n$ be a nonnegative integer. Suppose $f(x)$ is a real-valued function on $(\tilde{a}, \tilde{b})$ which is $(n + 1)$-times continuously differentiable on $(\tilde{a}, \tilde{b})$. My question is this. Does there necessarily exist some $a < c < b$ such that$$\int_a^b (b - x)^n f^{(n + 1)}(x)\,dx = {{f^{(n + 1)}(c)}\over{n + 1}}(b - a)^{n + 1}?$$","['derivatives', 'real-analysis', 'calculus', 'integration', 'analysis']"
2073478,Finding $\lim_{n\to\infty}\binom{2n}{n}$,"I found a limit problem which is
$\lim_{n\to\infty}{2n \choose n}$
as we know that $\sum_{i=0}^{n}{n \choose i}^2={2n \choose n}$
now we could transform the given problem as $\lim_{n\to\infty} \sum_{i=0}^{n}{n \choose i}^2$
and as $\sum_{i=0}^{n}{n \choose i}^2$ is a polynomial in $n$,
therefore, $\lim_{n\to\infty}\sum_{i=0}^{n}{n \choose i}^2=\infty$
Please tell me if my solution is correct or not,and if it is incorrect then please provide me a solution. Thanks","['sequences-and-series', 'calculus', 'limits']"
2073480,Name for the $\otimes$ operator,"I'm teaching 3D vector stuff to engineers. When we write $\mathbf{u} \cdot \mathbf{v}$, we say ""u dot v"". When we write $\mathbf{u} \times \mathbf{v}$, we say ""u cross v"". When we write $\mathbf{u} \otimes \mathbf{v}$, we say what?? Here $\mathbf{u} \otimes \mathbf{v}$ is the so-called "" outer product "", defined by $\mathbf{u} \otimes \mathbf{v} = \mathbf{u}\mathbf{v}^T$. It's clumsy and verbose to say ""the outer product of u and v"" and it feels odd to say ""u outer v"". Any ideas?","['terminology', 'linear-algebra', 'vectors']"
2073513,non-capable groups and their direct products,"A group $H$ is said to be capable if there is a group $G$ such that $G/Z(G)\cong H$. It is well known that $G/Z(G)$ can never be cyclic of order $>1$; so cyclic groups are not capable. More interesting: quaternion group $Q_8$ is not capable: there is no $G$ with 
$G/Z(G)\cong Q_8$. Now $Z_p$ (cyclic of order $p$) is not capable; but $Z_p\times Z_p$ is capable. This raises question, is $Q_8\times Q_8$ capable? In general, Q. Given any group $H$, is $H\times H$ capable? Edit: Is there a known example of a finite group $H$ such that $H\times H$ is not capable?","['finite-groups', 'abstract-algebra', 'group-theory']"
2073526,Is a family of disjoints atoms in $\sigma$-finite neasurable space at most countable?,"Let   $\mu$ be a positive measure on a $\sigma$-algebra $S$ in $X$. A subset $A\subset X$ is called an atom if $\mu(A)>0$ and  for each $E\subset A$ is $\mu(E)=0$ or $\mu(E)=\mu(A)$. Let's assume that $\mu$ is $\sigma$-finite and consider a family 
$\cal F$ of pairwise disjoint atoms in $(X, S, \mu)$. Is $\cal F$ at most countable? Remarks. Is it not true without $\sigma$-finitness of a measure, for example if $X$ is uncountable, $S=2^X$, $\mu(A)=+\infty$ if $A\neq \emptyset$, $\mu(\emptyset)=0$ and ${\cal F}= \{ \{x\}: x\in X \} $. It is true if $\mu $ is finite; in this case for each $c>0$ the family ${\cal F}_c=\{A\in {\cal F}: \mu(A)>c \}$ is finite and consequently $\cal F=\bigcup_{n\in \mathbb N} {\cal F}_{\frac{1}{n}}$ is at most countable.",['measure-theory']
2073531,Is curl of a given vector always perpendicular to the given vector field?,As we know cross product of any two vectors yields a vector perpendicular to plane containing both the vectors so is it same for the vector operator del crossed with a vector  â Ã F (curl of vector field F). if not why?,"['multivariable-calculus', 'vectors', 'vector-analysis']"
2073559,Calculating the sum of $\sum\frac{n^2-2}{n!}$ [duplicate],"This question already has answers here : What's the value of $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$? (8 answers) Closed 7 years ago . Calculating the sum of $\sum\frac{n^2-2}{n!}$ I want to calculate the sum of $\sum_{n=0}^{+\infty}\frac{n^2-2}{n!}$. This is what I have done so far: $$ \sum_{n=0}^{+\infty}\frac{n^2-2}{n!}=\sum_{n=0}^{+\infty}\frac{n^2}{n!}-2\sum_{n=0}^{+\infty}\frac{1}{n!}=\sum_{n=0}^{+\infty}\frac{n}{(n-1)!}-2e$$ And here I don't know how to deal with the $\frac{n}{(n-1)!} $. Any tips? EDIT:
One of the answers recommends to write down the sum as follows: $$\sum_{n=0}^{+\infty}\frac{n^2-2}{n!}=\sum_{n=0}^{+\infty}\frac{n(n-1)}{n!} + \sum_{n=0}^{+\infty}\frac{n}{n!}-2\sum_{n=0}^{+\infty}\frac{1}{n!}$$ Which equals to: $$\sum_{n=0}^{+\infty}\frac{n(n-1)}{n!} + \sum_{n=0}^{+\infty}\frac{n}{n!}-2\sum_{n=0}^{+\infty}\frac{1}{n!}=\sum_{n=0}^{+\infty}\frac{(n-1)}{(n-1)!}+\sum_{n=0}^{+\infty}\frac{1}{(n-1)!} -2e$$ But here I have negative factorials. What should I do next? Or can I just say that $\sum_{n=0}^{+\infty}\frac{1}{(n-1)!}=e$?","['real-analysis', 'summation', 'sequences-and-series']"
2073621,Number of graphs without any isolated vertices,"How many labeled graphs there are of order $n$ without any isolated vertices? By the inclusion-exclusion principle, we have: $$\sum_{i=0}^n (-1)^i{n\choose i}2^{n-i \choose 2} $$ But is there any closed form for it? Or is there any better solution?","['inclusion-exclusion', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
2073623,wildly ramified extensions and $p$-power roots of unity,Let $K$ be a finite extension of $\mathbf{Q}_p$. I have this vague intuition that $K$ having a lot of wild ramification is closely related to $K$ being close to containing high degree $p$-power roots of unity. I was wondering if this intuition is true and if maybe the following result (which would formalise it) is true : Let $e_K$ be the ramification degree of $K$ over $\mathbf{Q}_p$ then $p^n$ divides $e_K$ if and only if $K(\zeta_p)$ contains $p^n$ roots of unity where $\zeta_p$ is a $p$-root of unity. If this is false is there a way to salvage the result/my intuition ?,"['number-theory', 'ramification', 'algebraic-number-theory', 'local-field']"
2073669,How can I solve this recursive relation? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question If  $T(1)=1 $ and $nT(n)=2nT(n/2)+n^2,n>1$ find $ T(n)$. I have tried both changing the variable $n$ to $2x$ or something similar, but I get to a dead end, since I can not deal with odd values of n this way. How could I proceed? Thanks in advance.","['recursion', 'discrete-mathematics']"
2073713,How much variance does the random Mersenne twister algorithm allow,"I'm sorry if I don't know how to phrase this question properly, but I would like to know when using a random number generator like the Mersenne twister, and I generate  numbers which fall into a range [1..5] for example. I understand that I should then get an even distribution of those numbers (20% of each) but generally there is always a ""variance"" of that count (for example the number ""1"" would come out 18% of the time while ""5"" 22%). How much of this variance is allowed and expected? Is there a proper term for this value? Is this dependent on different random number generator algorithms, and if so which ones are better at giving even distributions?","['statistics', 'random']"
2073714,Bartle's Theorem 6.14 Completeness of $L^p$ (Riesz Representation)- need explanation,"Note: There are 4 parts to my questions, I have labelled (and colored them, sorry if that is irritating) with (1), (2), (3) and (4) of the proof. Any answer to parts is great. Thanks! Completeness Theorem. If $1 \le p < \infty$, then the space $L_p$ is a complete normed linear space under the norm 
  $$ ||f ||_p = \Big \{ \int |f|^p \, d \mu \Big \} ^{1/p}. $$ Proof: Let $(f_n)$ be a Cauchy sequence relative to the norm $|| \, \, || _p$. There exists a sub-sequence $(g_k)$ of $(f_n)$ such that $||g_{k+1} - g_k || _p < 2^{-k}$ for $k \in \mathbb{N}$. Define $g$ by 
  $$ g(x) = |g_1(x) | + \sum_{k=1}^{\infty} |g_{k+1}(x) - g_k(x) |$$
  so $g : X \rightarrow \bar{ \mathbb{R}}^{+}$ is measurable. By Fatou's Lemma, we have 
  $$ \color{blue}{ \int |g|^p \, d \mu \le \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \quad \quad (1) } $$
  Taking the $p^{th}$ root of both sides and apply Minkowski's Inequality to obtain, 
  $$ \color{blue} { \Big \{ \int |g|^p \, d \mu \Big \} ^{1/p } \le \lim \inf_{n \rightarrow \infty} \Big \{ ||g_1||_p + \sum_{k=1}^n ||g_{k+1} - g_k||_p \Big \} \quad (2) } $$
  $$ \le ||g_1||_p + 1. $$ 
  Hence, if $E = \{x \in X:g(x) < + \infty \},$ then $\color{blue}{ \text{  $E$ is a measurable set and $\mu(X \setminus E) = 0$. } \quad (3) } $ Therefore, $\color{blue}{ \text{ the series in $g(x)$ converges almost everywhere and $g\, \chi_E$ belongs to $L_p$. } \quad (4) } $ My questions regarding (1) : By construction $$g(x) = |g_1(x)| + \lim \sum_{k=1}^n |g_{k+1}(x) -  g_k(x)| $$ $$ =  |g_1(x) | + \lim \inf \sum_{k=1}^n |g_{k+1}(x) - g_k(x) |. $$ Is this right? (2) : If we take the $p^{th}$ root we would obtain, an exponent of $1/p$ outside of the $\lim \inf $. That is, from (1) we should obtain
$$ \Big( \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \Big) ^{1/p} $$ 
so we could not directly apply Minkowski's. Does this mean it's true, for a sequence $a_n$ and continuous function $f$ that $f ( \lim \inf a_n) \le \lim \inf f(a_n)$? (3) & (4) : It is unclear why these statements are true. Thanks in advance. Minkowski's Inequality. If $f$ and $h$ belong to $L_p$, $p \ge 1 $ then $f+h$ belongs to $L_p$ and 
  $$ ||f+h||_p \le ||f||_p + ||h||_p $$","['inequality', 'lebesgue-measure', 'proof-verification', 'measure-theory', 'proof-explanation']"
2073717,How can a linear operator represents the total derivative?,"I am now studying total derivative of a function. The defination of the differentiability of the vector-valued function $\mathbf{f}$  is given in my book as follows : Let $\mathbf{f} : S \longrightarrow \mathbb R^{m}$ be a function defined on a set $S \subset \mathbb R^{n}$ with values in $\mathbb R^{m}$.Let $\mathbf{c}$ be an interior point of $S$, and let $B(\mathbf{c}; r)$ be an $n$-ball lying in $S$. Let $\mathbf{v}$ be a point in $\mathbb R^{n}$ with $||\mathbf{v}|| < r$, so that $\mathbf{c} + \mathbf{v} \in B(\mathbf{c}; r)$.Then the function $\mathbf{f}$ is said to be differentiable at $\mathbf{c}$ if there exists a linear operator $T_{\mathbf{c}} : \mathbb R^{n} \longrightarrow \mathbb R^{m}$ such that $\mathbf{f}(\mathbf{c} + \mathbf{v}) = \mathbf{f}(\mathbf{c}) + T_{\mathbf{c}}(\mathbf{v}) + ||\mathbf{v}|| E_{\mathbf{c}}(\mathbf{v})$ , where $E_{\mathbf{c}}(\mathbf{v}) \rightarrow \mathbf{0}$ as $\mathbf{v} \rightarrow \mathbf{0}$.The linear function $T_{\mathbf{c}}$ is called the total derivative of $\mathbf{f}$ at $\mathbf{c}$. But my question is ''how can the total derivative be linear operator?''In particular if $f$ be a real valued function of real variable then if $f$ is differentiable at $c$ then I have a question. Is $f'(c)$ the total derivative of $f$ at $c$? If the answer is affirmative then how is the real number $f'(c)$ considered to be linear operator i.e. to be function.Please help me in understanding this concept. Thank you in advance.","['multivariable-calculus', 'derivatives']"
2073721,If $ax^2+bx+c=0$ has rational roots then $(a+1)x^2+bx+c=0$ cannot have rational roots,"I was working on quadratic equations and found the following fact that: ""If $ax^2+bx+c=0$ has rational roots then $(a+1)x^2+bx+c=0$ cannot have rational roots where $a,b,c\in\mathbb N$"" And now I have to prove or disprove it And I know the first comment will be ""show your efforts"" So I have assumed if a quadratic equation have rational roots, then $b^2-4ac$ should be a perfect square. Applying to both equation I got $k^2-4c=l^2$ for some integer $k$ & $l$. How to proceed now?? Please help!!","['algebra-precalculus', 'quadratics']"
2073768,Is a mixture of two uniform distributions more complex than a single distribution?,"I'm a psychologist studying perception of visual ensembles (e.g., lots of lines with different orientations drawn on a screen) that have different underlying probability distributions. One of the reviewer's for our paper has asked us to justify a statement that seems intuitively correct to me but I wasn't able to find a proper reference. The statement in question says that a mixture of two uniform distributions is more complex than a normal or a uniform one. The mixture distribution here consists of two non-intersecting uniform distributions with equal ranges but different means. Intuitively it seems to me that it should be more complex as its probability density function has more parameters than the functions of a single uniform or a normal distribution hence it could be said that it has lower ""description length"". Am I correct in saying that this mixture distribution is more complex? And if so, could you please provide any reference supporting this?","['probability', 'probability-distributions']"
2073867,Find the value of the infinite product: $\prod\limits_{n=1}^{\infty}\left(1+\frac{1}{3^n}\right)$,"I am Anay, here is a problem I am stuck with: $$x = \prod\limits_{n=1}^{\infty }\left ( 1 + \frac{1}{3^n} \right )$$ The task is to find the value of $x$. (obviously, we aren't supposed to have infinite products or sums, etc. in the answer) This is what I have done: We define the sequence $a_{k}$ as, $$a_{k} = \prod\limits_{n=1}^{k }\left ( 1 + \frac{1}{3^n} \right )$$ First, we put some bounds on $a_{k}$, as it is a increasing sequence, we already have the lower bound as $\frac{4}{3}$. Now to get the higher bound, we have the following inequality for all integers $x$ (easily proved through binomial expansion): $$\left(1 + \frac{1}{x}\right)^{x} < e$$ So, $$(1+x) < e^{\frac{1}{x}}$$ Using this inequality many times, we have, (using the formula for sum of a geometric progression) $$a_{k} < e^2$$ Thus, $$\frac{4}{3}\leq a_{k}< e^2$$ Then, to prove that this sequence is converging we show that it has the Cauchy Property. This can be done as follows: First, we have, $$a_{k} = a_{k-1} + \frac{a_{k-1}}{3^k}$$ So adding such equations for $a_{1}$, $a_{2}$ ..... $a_{k}$, we see that all terms cancel out and the following remains: $$a_{k} = a_{1} + \sum\limits_{i = 1}^{k-1}\frac{a_{i}}{3^{i+1}}$$ So, if $m < n$, $$a_{n} - a_{m} = \sum\limits_{i=m}^{n-1} \frac{a_{i}}{3^{i+1}} < a_{n-1}\left(\frac{3^{n} - 3^{m}}{3^{m+n}\times2 }\right)$$ As $a_{k}$ is a increasing sequence, we have used $a_{n-1} > a_{n-2}>....>a_{m} $. And then we use the formula for sum of a geometric progression to get the result. Now we can see that when $m$ and $n$ are large enough, we can have the RHS arbitrarily small as $a_{n-1}$ has a upper bound ($e^2$), thus the sequence has the Cauchy property and it is converging. After this I thought may be the sequence converges to the bound which I established ($e^2$), but it is not so as I checked it through a computer program, it approaches around $1.56$, which is far below $e^2$. So, after this I try many other methods to find where the sequence converges to but I found no luck. Also, I couldn't find any results on Google, so I have come to your help. How do I solve this? Thanks in advance.","['infinite-product', 'cauchy-sequences', 'convergence-divergence', 'sequences-and-series', 'exponentiation']"
2073883,Extension of divisible fields,"Assume that $F$ is an infinite subfield of a field $K$ such that its multiplicative group, $F^\times$, is divisible. Also, $a\in K$ and $[F(a):F]<\infty$. Can we conclude that the  multiplicative group of $F(a)$ is a divisible group? For example the root closure of $\mathbb Q$ in $\mathbb C$, is a divisible field.
Can we obtain that any finite extension of this field is a divisible field?","['abstract-algebra', 'field-theory', 'divisible-groups', 'group-theory']"
2073906,$R^2$ of two regressed lines divided by each other. [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question In this situation I have two lines. For the sake of the question I will simplify the two lines to simple linear equations. $$f(x) = x + 1$$ $$g(x) = x + 2$$ $f(x)$  and $g(x)$ were linearly regressed using least sum of squares. If the R$^2$ value of $f(x)$ is $0.5$ and the R$^2$ value of $g(x)$ is $0.7$, what is the R$^2$ value of the result of $\frac{f(x)}{g(x)}$?","['regression', 'statistics']"
2073920,Explicit solution of the recursion $x_n = x_{n-1}^2 - 2$ with $x_0>2$,"Let $m>2$ be an integer, $x_0 = m$ and $x_n = {(x_{n-1})}^2 - 2$ for $n > 0.$ Prove that $x_n=\lceil\tau(n) \rceil$, where $\tau(n) = Î±^{2^n}$ and $\alpha >1$ satisfies $\alpha + \frac{1}{\alpha} = m$. This is the problem.  The only thing I can think of is that it could have something to do with $\varphi$, since for $m=3$ we have $x(n)=\lceil\left(\varphi^2\right)^n\cdot \varphi) \rceil$, $\alpha = \varphi^2$. Other than that I have no idea how to move on. Thanks in advance","['recursion', 'ceiling-and-floor-functions', 'sequences-and-series', 'discrete-mathematics']"
2073927,"probability theory, conditional probability","This is exercise 13.4.1 from ""A First Look at Rigorous Probability"". The question statement is below. Let $A$ and $B$ be events, with $0 < P(B) < 1$ . Let $\mathcal{G} = \sigma(B)$ be the $\sigma$ -algebra generated by $B$ . (a) Describe $\mathcal{G}$ explicitly. (b) Compute $P(A \mid \mathcal{G})$ explicitly. (c) Relate $P(A \mid \mathcal{G})$ to the earlier notion of $P(A \mid B) = \frac{P(A \cap B)}{P(B)}$ . (d) Similarly, for a random variable $Y$ with finite mean, compute $E(Y \mid \mathcal{G})$ , and relate it to the earlier notion of $E(Y \mid B) = \frac{E(Y 1_B)}{P(B)}$ . For part (a), the sigma algebra generated by $B$ is just $\mathcal{G} = \{\varnothing, \Omega, B, B^c\}$ . For part (b), we are looking for a $\mathcal{G}$ measurable function $P(A \mid \mathcal{G})$ with the property that $E[P(A\mid \mathcal{G}) 1_S] = P(A \cap S)$ for $S \in \mathcal{G}$ . I'm having trouble guessing this function. The only functions I could think of which are $\mathcal{G}$ measurable are $1_B$ or $P(A)1_B$ but neither of these satisfy the expectation property. The problem with the function $1_A$ is even though it satisfies the expectation property, it is not $\mathcal{G}$ measurable. Earlier in the reading, Rosenthal defines this $\mathcal{G}$ measurable function to be the Radon Nikodym derivative $\frac{d\nu}{dP_0}$ of $\nu(E) \doteq P(A \cap E)$ with respect to $P_0 = P$ restricted to $\mathcal{G}$ . But again I'm not sure how to compute this derivative. Any hints would be helpful!","['probability-theory', 'conditional-expectation', 'probability', 'measure-theory']"
2073950,What is the least positive integer that is divisorous?,"We say that a positive integer $N$ is divisorous if the ones digits of the positive divisors of $N$ include all of the base-ten digits from $0$ to $9$. What is the least positive integer that is divisorous? I didn't see an easy way of finding the least such $N$. We know that $N$ must contain a factor of $2$ and $5$, but how do we find the least such $N$?",['number-theory']
2073994,Probability that my roll on a die will be higher than yours: Why divide by 6?,"I have to work out a question where on two fair, $6$ sided dice, what is the probability that the second die gives me a higher number than the first die. So I broke the question down the long way and said ""If you roll a $1$, I have a $\frac{5}{6}$ chance of beating you, if you roll a $2$, I have a $\frac{4}{6}$ chance of beating you, etc."" Then I added all these up but got the answer to be $\frac{5}{2}$. More research showed that I was actually supposed to divide this number by $6$ to get my probability to be $\frac{15}{36} = \frac{5}{12}$, but I can't see why you divide it by $6$. Can someone explain this to me please? EDIT: The bit I am struggling with is the fact that why do we take the draw into consideration. Thank you to everyone who has commented and answered, I now get that the division by 6 is because we include the probability of drawing. But in my specific question, there was nothing about a tie, I simply have to beat you, or I lose. So why do we still include the possibility of a draw, when that's not part of the game?","['algebra-precalculus', 'statistics', 'probability', 'dice']"
2074020,Condition for Self-Adjoint Sturm-Liouville Operator,"Consider the Sturm-Liouville operator $$L(u) = -(pu')' + qu$$ where, $p \in C^1[a,b]$ and $q \in C[a,b]$ with $p(t) \neq 0$ for $t \in [a,b]$ are complex valued functions, with boundary conditions: \begin{align*}\alpha u(a) + \beta u'(a) = 0 \\ \gamma u(b) + \delta u'(b) = 0\end{align*} where, $\alpha, \beta, \gamma, \delta \in \mathbb{C}$. Prove that the operator is self-adjoint iff $p,q$ are real valued and $\alpha \overline{\beta} = \overline{\alpha} \beta$, $\gamma \overline{\delta} = \overline{\gamma} \delta$ (i.e., requiring $\alpha, \beta, \gamma, \delta$ to be real valued.) If the boundary conditions and $p,q$ are real valued then clearly $L$ is self-adjoint, i.e., $\displaystyle \int_a^b L(u) \overline{v} = \int_a^b u\overline{L(v)}, \quad \forall u,v \in C^2[a,b]$ satisfying the boundary conditions, which can be verified by simply integration by parts. It's proving the converse that I'm having trouble with. (This is Exercise 1 of Chapter 7 in Coddington-Levinson).","['sturm-liouville', 'ordinary-differential-equations']"
2074029,Why do we divide by the expected value in the chi squared test?,"Chi squared, $\chi ^{2}$, is calculated using the formula: $$ \chi ^{2} = \sum \frac{{(O_i - E_i)}^{2}}{E_i}$$ $\chi ^{2}$ is used to determine how well a particular model fits some observed data.  The way I justify this formula is that we want a model that resembles the data very closely.  Hence, we will need to check how different the model is to the observed data. We can check how different individual data points are from the expected values by $(O_i - E_i)$.  Thus, $(O_i - E_i)$ is justified. To determine how well the model fits the data as a whole we can sum $(O_i - E_i)$ for all data points.  $(O_i - E_i)$ will need to be squared to remove negative terms in the summation.  Negative terms will lower $\chi ^{2}$ and give a flawed goodness of fit.  Thus, $\sum {(O_i - E_i)}^{2}$ is justified. My question is why do we normalize ${(O_i - E_i)}^{2}$ by $E_i$?  This seems unnecessary to me.","['statistics', 'chi-squared']"
2074061,Prove that: $\zeta(3)=\lim_{N\to \infty}{1\over N}\sum_{k=1}^{N}{1\over k^{\phi^2}\ln{\left(1+{k^{\phi^{-2}}\over N}\right)}}$,"Show that:
  $$\zeta(3)=\lim_{N\to \infty}{1\over N}\sum_{k=1}^{N}{1\over k^{\phi^2}\ln{\left(1+{k^{\phi^{-2}}\over N}\right)}}$$
  where $\phi$ is the golden ratio and $\zeta(3)$ is the Apery constant. My try: It converges very slowly when I tested it a sum calculator. Let summed out $$\zeta(3)=\lim_{N\to\infty}{1\over \ln{\left(1+{1\over N}\right)}}+{1\over 2^{\phi^{2}}\ln{\left(1+{2^{\phi^{-2}}\over N}\right)}}+{1\over 3^{\phi^{2}}\ln{\left(1+{3^{\phi^{-2}}\over N}\right)}}\cdots\tag1$$ $$\zeta(3)=1+{1\over2^3}+{1\over3^3}+\cdots$$ $$\zeta(\phi^2)=1+{1\over2^{\phi^2}}+{1\over3^{\phi^2}}+\cdots$$
I wonder is there a sum of this form $$S={1\over \ln{A_1}}+{1\over \ln{A_2}^2}+{1\over \ln{A_3}^3}+\cdots$$ May be this sum could be useful $$\ln{\left(n^s\over n^s-1\right)}=\sum_{r=1}^{\infty}{1\over n^{sr}\cdot{r}}$$ I wonder if we could apply geometric sum[sum to $\infty$] to $(1)$ $$S_{\infty}={a\over 1-r}$$ $$=1+{1\over r}+{1\over r^2}+{1\over r^3}+\cdots$$ I need help on how prove (1)","['power-series', 'riemann-zeta', 'sequences-and-series', 'limits']"
2074067,Algebra problem - traces and norms,"This question: Assume $F$ has $p$ distinct $p$th roots of $1$, $p$ a prime, and $E|F$ is cyclic of dimension $p^f$. Let $z$ be a primitie $p$th root of $1$. Show that if $E|F$ can be imbedded in a cyclic field $K|F$ of dimension $p^{f+1}$, then $z = N_{E|F}(u)$ for some u $\in E$. is in the book Basic Algebra, Jacobson. $N_{E|F}(u)$ is the norm of u (If $E|F$ is Galois then the norm of $u$ is $\prod_{\phi \in Gal(E|F)} \phi_i (u) $). Can anyone give a hint on how to solve it? For example, what would be a good way to show that an element of $E$ is norm of some other element?","['abstract-algebra', 'galois-theory', 'field-theory']"
2074092,How many ways can 8 teachers be distributed among $4 $ schools?,"There are several ways that the teachers can be divided amongst $4$ schools, namely here are the possible choices I came up with: $1) 1 1 1 5$ $2) 1 1 2 4$ $3) 1 1 3 3$ $4) 1 2 2 3$ $5) 2 2 2 2$ now given the fact that say $2213$ is the same as $1 2 2 3$ it was omitted. With out repeats I believe these 5 are the only possibilities. 1) ${8 \choose 5} \times {3 \choose 1} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{5!3!} \times \frac{3!}{1!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 3 \times 2 \times 1 = 336$ 2) ${8 \choose 4} \times {4 \choose 2} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{4!4!} \times \frac{4!}{2!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $70 \times 6 \times 2 \times 1= 840$ 3) ${8 \choose 3} \times {5 \choose 3} \times {2 \choose 1} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{3!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 10 \times \times 2 = 1,120$ 4) ${8 \choose 3} \times {5 \choose 2} \times {3 \choose 2} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{2!3!} \times \frac{3!}{2!1!} \times \frac{1!}{1!0!}$ Which comes out to: If 8 new teachers are to be divided amongst 4 new schools how many divisions are possible? $56 \times 10 \times 3 \times 1= 1,680$ 5) ${8 \choose 2} \times {6 \choose 2} \times {4 \choose 2} \times {2 \choose 2}$ $\frac{8!}{2!6!} \times \frac{6!}{2!4!} \times \frac{4!}{2!2!} \times \frac{2!}{2!0!}$ Which comes out to: $28 \times 15 \times 6 \times 1 = 2,520$ What am I missing?","['combinatorics', 'probability']"
2074097,"Calculating $\int_{0}^{\frac{\pi}{2}}\sin(\sec x)\,dx$","I want to calculate
$$\int_{0}^{\frac{\pi}{2}}\sin(\sec x)\,dx.$$ I couldn't really figure out. Should I do integration by parts? I can't calculate the integral this way.","['integration', 'definite-integrals', 'calculus']"
2074131,Can a large number of small matrices be multiplied quickly?,"I know two large matrices can be multiplied faster than one would naively expect.  A large number of the same matrix can be multiplied quickly using repeated squaring.  But what about a large number of small matrices?  Specifically, can I find the product of one million two by two matrices all the entries of which are positive integers less than five quickly (or faster than expected)?","['matrices', 'algorithms']"
2074149,The valid interval of the maclaurin series for $\frac{1}{1+x^2}$,"The Maclaurin series for $\frac{1}{1-x}$ is $1 + x + x^2 + \ldots$ for $-1 < x < 1$. To find the Maclaurin series for $\frac{1}{1+x^2}$, I replace $x$ by $-x^2$.
The Maclaurin series for $\frac{1}{1+x^2} = 1 - x^2 + x^4 - \ldots$. This is valid for $-1 < -x^2 < 1$ if I replace $x$ by $-x^2$. So if I multiply each side by $-1$, I get $-1 < x^2 < 1$. If I take the square roots, I get $i < |x| < 1$. And I am stuck. And my book says that this Maclaurin series is valid for $-1 < x < 1$ anyway. There is no further explanation. How can I derive $-1 < x < 1$ from $i < |x| < 1$? Please help.","['taylor-expansion', 'calculus']"
2074154,Can one tell based on the moments of the random variable if it is continuos or not,"Suppose we are given moments of a random variable $X$. 
Can we determine based on this if the random variable is continuous or not? We also assume that the moments of $X$ completely determine the distribution of $X$. In other words, do moments of continuous random variable behave fundamentally differently than moments of say discrete random variable? Thanks, looking forward to your ideas. Edit: It seems like there was some confusion with the questions. Let me demonstrate with an example what I have in mind. Suppose, we are given moments of some random variable $X$
\begin{align}
E[ X^n]=\frac{1}{1+n},
\end{align}
for $n \ge 0$. Can we determine if the distribution of $X$ is continuous or not? In this example, I took $X$ to be continuous uniform on $(0,1)$. Some Thoughts: Since we know the moments we can reconstruct the  characteristic function of $X$  (I think this can be done, right? If not let as assume this)
\begin{align}
\phi_X(t) =\sum_{n=0}^\infty \frac{i^n E[X^n]}{n!} t^n
\end{align} We also know that $X$ has a pdf iff $\phi_X(t)  \in L_1$. So it seems it is enough to show that
\begin{align}
\int_{-\infty}^\infty \left| \sum_{n=0}^\infty \frac{i^n E[X^n]}{n!} t^n \right| dt
\end{align}
is finite or not. However, I don't think the above approach would work, as we can not switch the integration and summation.","['moment-problem', 'probability-theory', 'expectation']"
2074159,Approximation of Riemann integrable function with a continuous function,"I have proved that if $f \in R[a,b]$ and given $\epsilon > 0$ there exists a continuous function $g$ such that $$\int_a^b |f-g| < \epsilon$$
I was wondering if using this fact there is some way to show that there is also some continuous function $h$ such that $$\int_a^b |f-h|^2 < \epsilon$$
Any help will be appreciated, thanks :)",['real-analysis']
