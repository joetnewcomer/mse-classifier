question_id,title,body,tags
1483273,Dot product with which polynomial gives evaluation at $x_0$?,"I thought of following situation/problem, and was surprised that the solution did not jump out at me. Fix a positive integer $n$ and let $V_n$ be the finite-dimensional vector space of all polynomials of degree $\leq n$ with real coefficents. Make $V_n$ into a inner product space with respect to
$$ \langle p,q \rangle = \int_{-1}^1 p(x) q(x) \ dx.$$
Now, fix some point $x_0 \in \mathbb{R}$ and consider the linear functional 
\begin{align*}
\varphi_{x_0} : V_n \to \mathbb{R} && \varphi_{x_0}(p) = p(x_0).
\end{align*}
Because we are in an inner product space, there is a unique polynomial $p_{x_0,n}$ such that
\begin{align*}
\varphi_{x_0}(p) = \langle p_{x_0,n},p \rangle =\int_{-1}^1 p_{x_0,n}(x) p(x) \ dx &&
\forall p \in V_n.
\end{align*} Question: What is this polynomial!? One approach would be to apply the Gramm-Schmidt procedure to $1,x,\ldots,x^n$ to get an orthonormal basis $p_0,p_1,\ldots,p_n$ for $V_n$ and then calculate $\varphi_{x_0}$ on this basis. The required vector should be then $\sum_{i=0}^n \varphi_{x_0}(p_i) p_i$, but I am hoping for a more enlightening representation.","['polynomials', 'linear-algebra', 'inner-products']"
1483281,Mistake in proof of transitivity,"This is a problem from Velleman's How to prove it . Suppose $A$ is a set, and $\mathcal{F} \subseteq \mathcal{P}(A)$. Let $R = \{ (a,b) \in A \times A \text{ } | \text{ } \text{for every } X \subseteq A \backslash \{a,b \}, \text{if } X \cup \{a\} \in \mathcal{F} \text{ then } X \cup \{b\} \in \mathcal{F} \}$. Show that $R$ is transitive. My proof seems to be similar and yet somewhat shorter than the hint given at the back. I'm sure I have a mistake somewhere since the hint suggests considering the two cases $b \in X$ and $b \notin X$, but I really can't seem why. Let $a,b$ and $c$ be arbitrary. Suppose that $a,b,c \in A$ and that $a R b$ and that $b R c$. Let $X$ be an arbitrary set and suppose $X \subseteq A \backslash \{a,c\}$ and $X \cup \{a\} \in \mathcal{F}$. Since $a R b$  and $X \cup \{a\} \in \mathcal{F}$ then $X \cup \{b\} \in \mathcal{F}$. But since $b R c$ and $X \cup \{b\} \in \mathcal{F}$ then $X \cup \{c\} \in \mathcal{F}$. This shows that if $a R b$ and $b R c$ it follows that $a R c$, hence $R$ is transitive.",['elementary-set-theory']
1483289,Linking regularity of ideal sheaf with Fitting ideals sheaf,"I'm reading Eisenbud's book The geometry of syzygies and I'm quite struck undestanding the argument proposed in Chapter 5, in the section named ""Fitting ideals"". Remember that a coherent sheaf $\mathscr{F}$ over a scheme $X$ is called $m$*-regular* if
$$H^p(X,\mathscr{F}(m-p))=0$$ 
for every $p>0$. The minimum $m$ among integers, if it exists, such that $\mathscr{}$ is $m$-regolar is the Castelnuovo-Mumford regularity $\mathrm{reg}(\mathscr{F})$. There is an algebraic definition for module that involves (among other things) local cohomology. Let be $X$ an irreducible and smooth projective curve over an algebraically closed field $k$. If we call $I(X)$ the homogeneous saturated ideal of $X$, id est $$ I(X):=\bigoplus_{n\geq 0} \mathscr{I}_X(n) $$ where $\mathscr{I}_X$ is the ideal sheaf of $X$, we know thath $\mathrm{reg}(I(X))=\mathrm{reg}(\mathscr{I}_X)$. Now, let suppose that $X$ comes with a very ample line bundle, i.e. lets assume that $X\subseteq \mathbf{P}^r_k$ for some $r\geq 2$; in this case we have $I(X)\subseteq k[x_0,\ldots,x_r]=:S$ as homogeneous ideal. Let be $\mathscr{L}\in\mathrm{Pic}(X)$, i.e. an invertibile sheaf over $X$ and let be 
$$F:=\bigoplus_{n\geq 0} H^0(X,\mathscr{L}(n))$$
the generated cone; it's well known that $F$ is a graded $S$-module and has a free minimal presentation
$$L_1\overset{\psi}{\longrightarrow} L_0\longrightarrow F\longrightarrow 0$$ Sheafifying this sequence, we obtain a sequence $$\bigoplus_{j=1}^s \mathscr{O}_{\mathbf{P}^r_k}(-h_j)\overset{\Psi}{\longrightarrow} 
\bigoplus_{l=1}^t \mathscr{O}_{\mathbf{P}^r_k}(-l_i)\longrightarrow
\mathscr{L}\longrightarrow 0$$ In both cases we can define the 0-th Fitting ideal $I(\psi)$ of $\psi$, that is the ideal generated by $\psi$'s maximal minors; the sheaf $\mathscr{I}(\Psi)$ of Fitting ideals of $\Psi$. The problems that arise are the following: how can we relate the sheaf $\widetilde{I(\psi)}$ to the sheaf $\mathscr{I}(\psi)$? Since Fitting ideals commute with localizations, I find quite reasonable that the two sheafs are isomorphic, but Eisenbud don't even give an hint of a formal way to prove it; What can we say about $\mathrm{reg}(\mathscr{I}(\Psi))$ and $\mathrm{reg}(\mathscr{I}_X)=\mathrm{reg}(I(X))$? Following Eisenbud considerations (which don't assume $X$ smooth), there should be inequality $\mathrm{reg}(\mathscr{I}_X)\leq\mathrm{reg}(\mathscr{I}(\Psi))$, but following the cumbersome proof of this fact it seems that, if $X$ is smooth, then we have $\mathscr{I}_X=\mathscr{I}(\Psi)$. Anyone can help me finding the way to cleat out these facts?","['algebraic-geometry', 'algebraic-curves', 'sheaf-theory', 'commutative-algebra']"
1483297,Proof that the following sum is bounded above.,"Let  $i_1,  i_2 , ... , i_n, ...$ be a sequence of positive integers such that, a) No $i_n$ is a prime. b) For all pairs of distinct positive integers, $m$ and $n$, the pair of integers $i_m$ and $i_n$ are relatively prime. Show that $\frac{1}{i_1}  + \frac{1}{i_2}+ ... + \frac{1}{i_n} + ...$ is bounded above by some
  finite real number. I know that all $i_k$ are $> 1$ for every $k$, and $q_k$ the smallest prime that divides $i_k$(Thanks Andre for this hint). I try several ways (more calculus related, infinite series) but all my attempts end in a failure. Therefore I can't find such a finite real number that its bounded the sum of my problem. For me is a very hard problem, and I would really appreciate if I receive help solving this exercise, and then been able to understand the path of thinking of how to solve such a kind of problem. 
Thanks again community.","['sequences-and-series', 'number-theory', 'calculus', 'real-analysis']"
1483325,A function $f$ that is not in any $L^p$ but the measure of $\{|f|>t\}$ is bounded by $C/t$,"How can I find a function $f$ such that $f \notin L^{p} (\mathbb{R})$ for all $p$ but you can find a constant $c>0$ for it with $m(x \in \mathbb{R} \,  s.t.  |f(x)|>t) \leq \frac{c}{t}$  for $\forall t$ I tried $f(x)={1 \over x^2}$ since $f \notin L^{p} (\mathbb{R})$ for all $p$, but it looks like this is not the right answer. I guess we could use the Chevyshev's inequality on $f(x)$ , the measure theoretic one (see Section Measure-theoretic statement in https://en.wikipedia.org/wiki/Chebyshev%27s_inequality )","['lp-spaces', 'real-analysis', 'measure-theory']"
1483359,Stacking circles with $r=\frac{1}{p}$ inside a circle with $r = 1$,"Let's start with a circle with radius $1$. Now suppose we would continuously insert circles from above with radii $\frac{1}{p}$ (first a circle with $r = \frac{1}{2}$, then a circle with $r = \frac{1}{3}$, etc...) so that they would rest at the lowest possible position, meaning that the circles can't cross or overlap each other. To illustrate what I mean, here's an image: My question is if we can keep doing this infinitely without ever exceeding the outer circle. Now it is known that the sum of squared prime reciprocals converges to approximately $0.452247$, so we know that the total area of all the inner circles is less than half of the area of the outer circle. Looking at the picture then leads me to believe that we can easily fill the circle infinitely from above, but I'm not entirely sure and I'd like to find out if this can be proven mathematically.","['prime-numbers', 'geometry', 'packing-problem']"
1483381,What is the smallest prime of the form $n^n+5$?,"This question asks about the smallest prime of the form $n^n+8$. However, I haven't be able to find a prime of the form $n^n+5$ where $n$ is natural, assuming we take $0^0=1$. If $n$ is odd, then $n^n+5$ is even. If $n \equiv 2 \mod 6$ or $n \equiv 4 \mod 6$ then $n$ is even and $\gcd(n,3)=1$ and hence by the Euler-Fermat theorem $n^n \equiv 1 \mod 3$, and hence $n^n+5 \equiv 0 \mod 3$. So only numbers in the form $n=6m$ can qualify. Of course, one also needs that $n$ is not divisible by 5. I also checked $n \leq 71$, they are not prime. So I wonder whether there exists a prime in the form $n^n+5$, and if so, what is the smallest?","['prime-numbers', 'number-theory']"
1483394,Any set of $d$ points in projective space is the zero locus of polynomials of degree $d - 1$,"Show that if $\Gamma \subseteq \mathbb{P}^n$ consists of d points and is not contained in a line, then $\Gamma$ may be described as the zero locus of polynomials of degree $d - 1$ and less. This problem is exercise 1.3 from Joe Harris's Algebraic Geometry: A First Course . I don't so much want an answer to the original question as some help understanding it. My issue is a general unfamiliarity with projective geometry, and I think some concrete examples might help me better make sense of the situation. More specifically, just above this problem the book states that for a line $L \subset \mathbb{P}^n$, ...it's not hard to see that a polynomial $F(Z)$ of degree $d - 1$ or less that vanishes on $d$ points $p_i \in L$ will vanish identically on L. But I'm not sure what it means in any useful, algebraic sense for points in projective space to be collinear. I can't even seem to put together for my own use three collinear points in $\mathbb{P^3}$ to see why (in a simple numeric sense) every quadratic equation that is zero at all three of them will also be zero everywhere else on the line.","['projective-space', 'algebraic-geometry']"
1483395,Factoring a polynomial (multivariable),"Factor $ (a - b)^3 + (b - c)^3 + (c-a)^3$ by SYMMETRY. Okay, this is the problem. Let $f(a) = (a - b)^3 + (b-c)^3 + (c-a)^3$ obviously, if you let $a = b$ then, $f(b) = 0$, thus $(a - b)$ is a factor of $f(a)$. Then someone said : If $(a - b)$ is a factor then $(b - c)$ and $(a-c)$ must be factors as well by symmetry. But $f(a, b, c)$ is not symmetric, actually, $f(b, a, c) = -f(a, b, c)$ it is an alternating polynomial, so what is up with the solution?","['contest-math', 'polynomials', 'linear-algebra', 'algebra-precalculus']"
1483419,Proving non compactness of a space,"I'm trying to show that the space $\mathbb R^p$, endowed with a metric $d'(x,y) = \frac{d_2(x,y)}{1 + d_2(x,y)}$, where $d_2(x,y)$ is the Euclidean distance, is closed and bounded but not compact. I've had no problem with the first two proof, but I cannot go ahead with the proof of non compactness. I only know that I have to use the Bolzano-Weierstrass property about subsequences and to proceed by contradiction, assuming that the space is compact.","['metric-spaces', 'general-topology', 'compactness']"
1483438,"$Q=A\times B$. if $\int_Q f$ exists, then $\int_{y\in B}f(x,y)$ exists for $x\in A-D$, where $D$ is a set of measure zero in $\mathbb{R^k}$.","Let $A$ be a rectangle in $\mathbb{R^k}$; let $B$ be a rectangle in $\mathbb{R^n}$; let $Q=A\times B$. Let $f: Q\to \mathbb{R}$ be a bounded function. Show that if $\int_Q f$ exists, then $$\int_{y\in B}f(x,y)$$ exists for $x\in A-D$, where $D$ is a set of measure zero in $\mathbb{R^k}$. I'm having difficulty proving this. I think I might have to use these theorems in the proof. My work: Let $D$ be a set of measure zero in $\mathbb{R^k}$, and $x\in A-D$. Since $f$ is integrable on $Q$, $f$ is continuous except in a measure zero set, say $E$. Claim: Let $B$ be a rectangle in $\mathbb{R^n}$. If $D$ is a set of measure zero in $\mathbb{R^k}$, then $D\times B$ is a set of measure zero in $\mathbb{R^{k+n}}$. Proof of Claim: Let $\epsilon\gt 0$ be given.Since $D$ is a set of measure zero in $\mathbb{R^k}$, there exists a countable set of rectangles $\{Q_i\}$ whose union covers $D$ and the sum of the volumes is less than $\epsilon/v(B)$, where $v(B)$ is the volume of $B$. Now consider the countable set of rectangles $Q_i \times B$. Then the union of all of these rectangles cover $D\times B$, and $\sum v(Q_i\times B)=\sum v(Q_i)\times v(B)\lt \epsilon$. QED. Hence by the claim above, $E \cup (D\times B)$ is a set of measure zero in $\mathbb{R^{k+n}}$. Hence, $f$ is continuous almost everywhere when $x\in A-D$. Now for a fixed $x\in A-D$, $f$ is continuous almost everywhere in $\mathbb{R^{k+n}}$. However, to complete the proof of this problem, I need to show that $f(x,y)$, for a fixed $x\in A-D$ is continuous almost everywhere in $\mathbb{R^n}$, but I don't know how to show this part. I would greatly appreciate any hints, suggestions or solutions.","['calculus', 'real-analysis', 'integration', 'analysis', 'multivariable-calculus']"
1483444,Find solutions of $2^m\cdot p^2+1=q^5$,"$2^m\cdot p^2+1=q^5$ $p$ and $q$ are prime numbers find $p$ and $q$ I think it will be useful to transfer $1$ to the other side of the equation $2^m\cdot p^2=(q-1)(q^4+q^3+q^2+q+1)$
 and we know $gcd(q-1,q^4+q^3+q^2+q+1)=1$ or $5$ we know if I)$q-1|2^m \implies p^2|q^4+q^3+q^2+q+1$ or II)$2^m|q-1 \implies q^4+q^3+q^2+q+1|p^2$ if $gcd(q-1,q^4+q^3+q^2+q+1)=5 \implies$ I)$5|2^m \implies$ 
Inconsistency II)$5|p^2 \implies p=5$ $\implies gcd(q-1,q^4+q^3+q^2+q+1)=1$ But I went to this part of the problem and more of this I could not continue","['prime-numbers', 'number-theory', 'diophantine-equations', 'elementary-number-theory']"
1483455,Example of complete orthonormal set in an inner product space whose span is not dense,"Let $X$ an inner product space and $A$ be an orthonormal set and $\overline{Span(A)}$ = $X$ then $A$ is Complete. But the converse is not true until we consider $X$ as a Hilbert space. I am searching of an example for that. Here, I call a system/set $Z \subset X$ of vectors complete if $Z^\perp = \{0\}$. My Attempt : Lets take the polynomial vector space $P[x]$ over $\mathbb{R}$. Certainly it is not a Hilbert space. I choose the standard basis $\left \{1,x^2,x^3,... \right \}$ of $P[x]$. Using Gram–Schmidt process we can find an orthonormal basis. But i am stuck with the density part. Please let me know how do i prove it. Thank You.","['fourier-analysis', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
1483469,Faulty Argument: Chern number of U(1)-bundle over $T^2$ is zero?,"Consider a $U(1)$-bundle $P$ over the two-dimensional torus $T^2$. Given a local curvature $F$, We can compute the first Chern number $c_1(P)$ by considering a rectangle $R_{\epsilon}$ in the center of the torus whose edges are a distance $2\epsilon$ from touching each other: Then we may also define a restricted bundle $P|_{R_{\epsilon}}:=\pi^{-1}(R_{\epsilon})$. Note that this is a principal $U(1)$-bundle in its own right, over a manifold with non-trivial boundary. The Calculation :
Since the first chern-form is non-singular (by virtue of being a characteristic class), its integral over the complement of $R_{\epsilon}$ vanishes as $\epsilon$ goes to zero and we can write the first chern number of $P$ as the limit
$$c_1(P)=\int_{T^2}C_1(F)=\lim_{\epsilon\to 0}\int_{R_{\epsilon}}C_1(F)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})$$
However, since $R_{\epsilon}$ is contractible, $P|_{R_{\epsilon}}$ is a trivial bundle, and so $c_1(P|_{R_{\epsilon}})=0$ for all values of $\epsilon$ greater than zero. So 
$$c_1(P)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})=\lim_{\epsilon\to 0}0=0.$$
So the first chern number of any $U(1)$ bundle over the two-torus must vanish. What am I misunderstanding?","['differential-topology', 'homology-cohomology', 'differential-geometry', 'characteristic-classes']"
1483528,Multivariable Factor Theorem,"By my previous questions here and here I have been inspired to ask about the factor theorem; the multivariable case of it. So take $f(a, b, c) = (a-b)^3 + (b-c)^3 + (c-a)^3$ $f(a, a, c) = f(b, b, c) = f(a, c, c) = f(a, b, a) = f(a, b, b)$ these give factors: $(b - a), (a - b), (b - c), (c - a), (c - b)$, so which ones am I supposed to use?","['contest-math', 'polynomials', 'algebra-precalculus']"
1483531,Can I use greek letters such as alpha to denote a set? [duplicate],"This question already has answers here : If capital letters are supposed to be sets, why is $N$ used as a number? (3 answers) Closed 8 years ago . Can we have a set which is called by a small greek letter, e.g. a set $\alpha$?","['elementary-set-theory', 'terminology', 'notation']"
1483600,Product of metric outer measures,"The problem below has been asked recently already but, as a naive user, I got burned (well singed perhaps) because I asked the question in the wrong place.  So if this looks like a redundant question ... excuse me (as Steve Martin would say)! Problem:  Show that the product of two metric outer measures (also known as Borel measures on a metric space) is again a metric outer measure. Does anyone know if the problem is valid? The hints given already on this forum work only for the separable case, but I don't have a solution to the general case. I found the problem originally in the text by Munroe ( Measure and Integration 1953). It seemed that the obvious approach would work so I added it without further thought to our book ( Real Analysis , Bruckner/Bruckner/Thomson 1996). We received some valuable feedback from many sources, mostly from R. B. Burckel who pointed out among many other things that this problem was not straightforward and may be wrong. For the second 2008 edition I left the problem (since it is interesting) but included a footnote to indicate that there was some doubt. Anybody have a definitive answer? The problem appears as Exercise 6:1.5. in our 2nd edition. You can get a free PDF from the website classicalrealanalysis.com. Hope to hear from someone (not, I hope, from someone assigned this problem because it appeared in our first edition--if so blame Munroe -- please). Brian","['real-analysis', 'set-theory', 'measure-theory']"
1483616,Does $c\cdot\sum\limits_{n=k}^{\infty}a_{n}= \sum\limits_{n=k}^{\infty}c\cdot a_{n}$ provided that the series converge?,"I am struggling to find what is wrong about this reasoning when calculating a series that does not start at $n=0$. For instance, let $S = \sum\limits_{n=2}^{\infty}\left(\frac{1}{2}\right)^n$. Then $\left(\frac{1}{2}\right)^2S=\left(\frac{1}{2}\right)^2\sum\limits_{n=2}^{\infty}\left(\frac{1}{2}\right)^n$ (I) And:
$$\left(\frac{1}{2}\right)^2S=\left(\frac{1}{2}\right)^2\sum\limits_{n=2}^{\infty}\left(\frac{1}{2}\right)^n=\sum\limits_{n=2}^{\infty}\left(\left(\frac{1}{2}\right)^n\cdot\left(\frac{1}{2}\right)^2\right)=\sum\limits_{k=0}^{\infty}\left(\frac{1}{2}\right)^k=2$$
But that means (from I): 
$$\left(\frac{1}{2}\right)^2S = 2 \Rightarrow \dfrac{\frac{1}{4}}{\frac{1}{4}}S=\dfrac{2}{\frac{1}{4}}\Rightarrow S = 8$$
Which is clearly wrong since: $$\sum\limits_{n=2}^{\infty}\left(\frac{1}{2}\right)^n=\sum\limits_{n=0}^{\infty}\left(\frac{1}{2}\right)^n-\sum\limits_{n=0}^{1}\left(\frac{1}{2}\right)^n=\sum\limits_{n=0}^{\infty}\left(\frac{1}{2}\right)^n - 1 -\frac{1}{2}=\frac{1}{2}$$ I suspect that there is something behind this step $\left(\frac{1}{2}\right)^2\sum\limits_{n=2}^{\infty}\left(\frac{1}{2}\right)^n=\sum\limits_{n=2}^{\infty}\left(\left(\frac{1}{2}\right)^n\cdot\left(\frac{1}{2}\right)^2\right)$ that I am missing. So my question is: Considering that $\sum\limits_{n=k}^{\infty}a_{n}$ is well defined (converges?), does:
$$c\cdot\sum\limits_{n=k}^{\infty}a_{n}= \sum\limits_{n=k}^{\infty}c\cdot a_{n}$$ And if it does, why does the reasoning presented above is wrong?","['sequences-and-series', 'calculus', 'limits', 'convergence-divergence']"
1483637,About rational Hodge conjecture.,"What progress has been made to date on the rational Hodge conjecture ? Can anyone tell us if there is some new books related to Hodge conjecture which explain in detail, the latest development in the field of rational Hodge conjecture ? Thank you in advance for your answers.","['algebraic-geometry', 'homology-cohomology', 'hodge-theory']"
1483685,Measurable function in $L^2$-norm,"Let $f$ be a measurable function. Assume you know that $$\sup_{||g||_2=1} \left|\int fg\,\right|$$ exists. Does this mean that $$\sup_{||g||_2=1} \left|\int fg\,\right| = ||f||_2?$$","['measure-theory', 'real-analysis', 'functional-analysis', 'integration']"
1483697,Expressing an element in a number field as a ratio of two coprime integers,"Let $K$ be a number field and $O_K$ be its ring of integers. 
Take $\alpha \in K$ and consider the principal fractional ideal $(\alpha)$. 
I am sure the following is true, but I couldn't quite prove it.
I was wondering if someone could give me a hint on how I can find $\beta, \gamma \in O_K$ so that $\alpha = \beta/ \gamma$ and $(\beta) + (\gamma) = 1$.
Thank you very much!","['number-theory', 'algebraic-number-theory']"
1483700,Arithmetic Derivative,"In Calculus, whenever we see a constant and want to take the derivative of it, it always is $0$. However in Number Theory, we have something called the arithmetic derivative in which we can differentiate to get some nonzero term.  So we can denote the arithmetic derivative the same way as in calculus, say for some $x$, we can say $x'$ to be the arithmetic derivative. Some properties of arithmetic derivatives are that: For all primes, the arithmetic derivative is $1$. Product Rule: $(xy)'=x'y+xy'$ $0'=1'=0$ Now, there is also some lesser-known sub-part to the arithmetic derivative called the Arithmetic Product Derivative, $P(n)$. In this case, if $$\ n= p_1^{x_1} \cdot p_2^{x_2} \cdot ... \cdot  p_k^{x_k}  ,$$ then  $$ P(n) =  x_1 \cdot p_1^{x_1 - 1} \cdot x_2 \cdot p_2^{x_2 - 1} \cdot ... \cdot  x_k \cdot p_k^{x_k-1} .$$ Are there are infinitely values of $a$ such that $P(a)=P(a-5)+5$?","['arithmetic', 'number-theory', 'analytic-number-theory', 'arithmetic-functions', 'algebraic-number-theory']"
1483707,"Singular covariance matrix, understanding the beginning of a proof","Let $\left\{X_t,t\in T\right\}$ be a stationary process such that $\text{Var}(X_t)<\infty$ for each $t\in T$. The autocovariance function $\gamma_X(\cdot)=\gamma(\cdot)$ of $\left\{X_t\right\}$ is defined to be
$$
\gamma(h)=\text{Cov}(X_{h+t},X_t)~\forall h,t\in\mathbb{Z}.
$$
Moreover, assume that $EX_t=0$ for each $t\in T$. There is the following statement: If $\gamma(0)>0$ and $\gamma(h)\to 0$ as $h\to\infty$, then the covariance matrix $\Gamma_n=[\gamma(i-j)]_{i,j=1,\ldots,n}$ of the column vector $(X_1,\ldots,X_n)'$ is non-singular for every $n$. The proof of this starts as follows: Suppose that $\Gamma_n$ is singular for some $n$. Then since $EX_t=0$ there exists an integer $r\geq 1$ and real constants $a_1,\ldots,a_r$ such that $\Gamma_r$ is non-singular and
$$
X_{r+1}=\sum_{j=1}^r a_j X_j.~~~~~(*)
$$ I do not completely see this argument. In particular, there are two inaccuricies to my opinion. Here's how I do understand it: Suppose $\Gamma_n$ is singular. This means, its determinant is zero. So there is at least one column (one row) that is a linear combinations of the other columns (rows). If we delete this column (row), we get $\Gamma_{n-1}$, if its determinant is again zero, we repeat this. Eventually, we get $\Gamma_r$, for some $r\geq 1$, such that all columns (rows) are independent, meaning that $\Gamma_r$ has positive determinant, i.e. is non-singular. So far so good. It remains to argue, how to get $(*)$. In the proof, there is said to look at the following statement that one probably should use for my problem: If $X=(X_1,\ldots,X_n)'$ is a random vector with covariance matrix $\Sigma$, then $\Sigma$ is singular if and only if there exists a non-zero vector $b=(b_1,\ldots,b_n)'\in\mathbb{R}^n$ such that $\text{Var}(b'X)=0$. So, I apply this as follows: As done above, let $\Gamma_r$ be non-singular. Since $r$ was the smallest $r\geq 1$ such that all columns are linear independent, the covariance matrix $\Gamma_{r+1}$ of $X=(X_1,X_2,\ldots,X_{r+1})'$ is singular. By the cited statement, there is some $b=(b_1,b_2,\ldots,b_{r+1})'\in\mathbb{R}^{r+1}$ such that
$$
\text{Var}(b'X)=0.
$$
But this means that
$$
b'X=\sum_{i=1}^{r+1}b_iX_i=E(b'X)=0\text{ almost surely },
$$
implying that
$$
b_{r+1}X_{r+1}=-\sum_{i=1}^r b_iX_i.
$$
Imho, we can suppose that $b_{r+1}\neq 0$ since if $b_{r+1}=0$, we have that $0=\text{Var}(b_1X_1+b_2X_2+\ldots + b_rX_r+b_{r+1}X_{r+1})=\text{Var}(b_1X_1+b_2X_2+\ldots + b_rX_r)$, meaning by the cited statement that $\Gamma_r$ is singular. But $\Gamma_r$ is non-singular. Hence
$$
X_{r+1}=\sum_{i=1}^r a_iX_i,~~~a_i:=-\frac{b_i}{b_{r+1}}
$$ or, more precisely, this identity holds almost surely. I don't know why the ""almost surely"" is omitted in the proof. Is this okay?","['probability-theory', 'time-series', 'stochastic-processes', 'covariance', 'statistics']"
1483711,Find the limit of $(1+\frac{1}{n})^{n^2}/e^n$ without using derivatives,Try to use just basic operations with limits to find this one: $$\lim_{n\to\infty}\frac{(1+\frac{1}{n})^{n^2}}{e^n}$$ I have some ideas. Is it possible that they are right? $$\lim_{n\to\infty}\frac{(1+\frac{1}{n})^{n^2}}{e^n}=\lim_{n\to\infty}\frac{((1+\frac{1}{n})^{n})^n}{e^n}=\lim_{n\to\infty}\frac{e^{n}}{e^n} = 1$$,"['calculus', 'limits']"
1483715,"How many ways can 10 identical buttons, 10 identical bows, and 10 identical beads be distributed to 4 different people?","Question: How many ways can 10 identical buttons, 10 identical bows, and 10 identical beads be distributed to 4 different people? My thoughts: I decided to use the bars and stars method. With the knowledge that there are 4 unique groups of people, each person has the possibility of getting 1 of the 10 buttons, 1 of the 10 bows, and 10 of the 10 bows. I'm having trouble deciding whether the items are the elements or the actual people are the elements (the stars in this case). Your thoughts?","['discrete-mathematics', 'permutations', 'combinations', 'combinatorics', 'probability']"
1483716,"In a ring, how do we prove that a * 0 = 0?","In a ring, I was trying to prove that for all $a$, $a0 = 0$. But I found that this depended on a lemma, that is, for all $a$ and $b$, $a(-b) = -ab = (-a)b$. I am wondering how to prove these directly from the definition of a ring. Many thanks!","['abstract-algebra', 'rngs', 'ring-theory']"
1483741,Write $0.2154154\overline{154}$ as a fraction,"Let $x = 0.2154154\overline{154}$ , I have to prove that it is a rational number just by writing it as a fraction with the proper steps. I note that the repeating part, $154$, is composed by 3 digits. Thus, using a trick that I have learnt, I can write an equation of this type: $$1000x = ?$$ I am not sure about what goes on the right side of the equation because of this $0.2$
I mean, if, for instance, the number was $x = 0.154$ periodic, I would write the equation as: $1000x = 154 + x$    and solve for $x$ I have tried various attempts, re-writing $0$, $2$ as $\frac{1}{5}$, but I don't get the number which equals our $x$.","['rational-numbers', 'number-theory', 'decimal-expansion']"
1483797,Inverse Laplace transform of one complicated function,"I want to ask the inverse Laplace transform of the following function: $$F(s) = \frac{1}{s \cdot (1 + a \cdot s)^{m} \cdot (1 + b \cdot s)^{m-k}} \cdot \Bigl[\exp{(\frac{- c \cdot s}{ 1 + b \cdot s } )}\Bigr]^{m-k}$$ where $a,b,c,m,k$ are all positive constants. $m$ and $k$ are integers with $m\ge k$. It is possible to get an approximate solution using the Euler summation-based technique. But I want to have an exact solution for the inverse transform. Some similar questions but in a much less simple form are also found on Stackexchane, i.e., Inverse Laplace Transform of e$^{-c \sqrt{s}}/(\sqrt{s}(a - s))$ or find the inverse Laplace transform of complex function . Especially I am wondering how to deal with the point $s = \frac{1}{b}$ since it is a pole of order $(m-k)$ but also appears in the exponential function and also I am not sure about the contour integral considering that $s$ exists in both the nominator and denominator of the argument of the exponential function. Thanks a lot.","['inverse', 'calculus', 'contour-integration', 'laplace-transform', 'complex-analysis']"
1483816,Proof of chain rule for entropy of random variables,"I have the following proof for the chain rule for entropy of random variables:
We write: \begin{eqnarray*}
H(X_1,X_2,...,X_n)&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)logp(x_1,x_2,...,x_n)
\\&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)log\prod\limits_{i=1}^{n}p(x_i|x_{i-1},...,x_1)
\\&=&-\sum\limits_{x_1,x_2,...,x_n}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1)
\\&=&-\sum\limits_{x_1,x_2,...,x_i}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1)
\\&=&\sum\limits_{i=1}^n H(X_i|X_{i-1},...,X_1)
\end{eqnarray*} Basically, I have 2 questions: first how we get from line 1 to line 2. Is it some kind of Markov property? And second, why the summation lower boundary changes in line 4?","['summation', 'entropy', 'probability', 'random-variables']"
1483882,Showing that choice of point on a curve is irrelevant to finding $f(z_0)$ in the curve,"Before I start I apologize for the horrible title but I have no idea how to title this. So the problem is as follows: Let $f(z)$ be analytic in and on a simple closed curve $\Gamma$, and let $f(z)$ have no zeros in or on $\Gamma$.
Now let $z_0$ be a point in $\Gamma$, and $z_1$, $z_2$ be two points on $\Gamma$. Let $\gamma_1$ & $\gamma_2$ be the two curves connecting $z_1$ & $z_2$ to $z_0$ respectively.  Where the integraion is towards $z_0$ both times show that $$f(z_1)e^{\int_{\gamma_1}\frac{f'(x)}{f(x)}dx}=f(z_2)e^{\int_{\gamma_2}\frac{f'(x)}{f(x)}dx}$$ And then show that both sides are equal to $f(z_0)$. I'm given a hint to represent $f(z_2)/f(z_1)$ as an integral along the part of $\Gamma$ connecting these two points. This is where the problem begins and thats where I would start, but I'm struggling with that. One idea I had is that since $f(z_0)$ doesn't equal $0$, I could use that I could make a disk large enough centered at $z_0$ such that $e^{w(z)}=f(z)$, where $w(z)$ is essentially the two integral above, just flip the sign. Another idea I think is better.  If I solve the hint, then I could make a new curve $\gamma_3$ using the arc connecting $z_1$ and $z_2$ and $\gamma_1$ and $\gamma_2$, and then use Cauchy's theorem, so that $\int_{\gamma_3}f(z)=0$, and I would split this integral up into the three parts forming this curve if I could figure it out. Any help is appreciated, thanks in advance.",['complex-analysis']
1483891,Show that the sum of two consecutive primes is never twice a prime.,"Show that the sum of two consecutive primes is never twice a prime. My first language is not English, and would just like to understand the problem. Does someone could give me a concrete example? P.S. I can remove the question later if you find that the question is not relevant to the website.",['number-theory']
1483897,Coefficients of connection under diffeomorphism and metric change.,"Let $\varphi_t :M\rightarrow M $ is a family of diffeomorphism. $\widehat{g}_{ij}(x,t)$ is a solution of $$\frac{\partial}{\partial t}g_{ij}=-2R_{ij} ,\ 
y(x,t)=\varphi_t(x)=\{y^1(x,t),...,y^n(x,t)\},\ g_{ij}(x,t)=\varphi_t^*\widehat{g}_{ij}(x,t)$$ How to show that :
$$
\Gamma_{jl}^k(x,t)=
\frac{\partial y^a}{\partial x^j}  \frac{\partial y^b}{\partial x^l}
\frac{\partial x^k}{\partial y^r}\widehat{\Gamma}_{ab}^r(y,t)
+\frac{\partial x^k}{\partial y^a}
\frac{\partial^2y^a}{\partial x^j\partial x^l}
$$ I really can't compute it out , so I really need a detail answer ,so thanks.","['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
1483997,Compactness of a family of closed subsets in a compact space.,"Gamelin and Greene's ""Introduction to Topology"", Second Edition, Dover, pg25, Exercise 8, states that if $X$ is a compact space, then the family of non-empty, closed subsets, $C$, with the metric 
$$\rho(E,F) = \max \left( \sup_{x\in E} d(x,F) ,\ \sup_{y\in F} d(y,E) \right),$$ 
is compact. The $d(u,v)$ is the metric for the given compact space $X$. $E$ and $F$ are members of the family $C$. On page 200, the authors supply a proof which I find too terse to follow, though I must admit - with some embarrassment - I have spent much time.  On the internet, I have found proofs of the well known theorem about a subset of a compact set, but not another proof of the above.  I am seeking a more expansive proof of Gamelin and Greene's exercise.","['general-topology', 'compactness']"
1484077,Solving for the radius of the Earth based on distance to horizon problem,"Lets say you are standing on the top of hill with height $d$ and from the top of this hill you can see the very top of radio tower on the horizon. Your goal is to determine the radius of the Earth, so you drive from the base of the hill, in a straight line (along an arc) to the base of the radio tower. Your odometer measures an arc length, $s$ and you can measure the height of the radio tower, $a$. So, what is $R$? I may have just forgotten my basic algebra but I am trying to solve this by using three equations and three unknowns: $$s = R(\phi_1+\phi_2) $$
where
$$ \cos(\phi_1) = \frac{R}{R+a} $$
and 
$$\cos(\phi_2) = \frac{R}{R+d}.$$
Here, $a$, $d$ and $s$ are all known. So we have three equations and three unknowns where $R$ is the radius of the Earth to be determined, $\phi_1$ and $\phi_2$ are the angles of their respective arc lengths. How does one solve this? As a note, this is not a homework problem. I actually want to go perform this experiment to see how accurate my determined radius is.","['nonlinear-system', 'algebra-precalculus', 'trigonometry']"
1484097,"How to prove that both f(x) and its derivative decay to zero, as x grows to infinity, [duplicate]","This question already has answers here : If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist? (2 answers) Closed 8 years ago . The problem statement is: Prove: If $f(x)$ is differentiable for x>0 and $$\lim_{x \to \infty}  (f(x)+\frac {df}{dx}(x)) =0$$ and if $$\lim_{x \to \infty} f(x)$$ exists, then $$\lim_{x \to \infty} f(x) = \lim_{x \to \infty} \frac{df}{dx}(x)=0$$ My work: I don't see how the differentiability assumption on f can be used (or is even needed?), but I have that, for every $\epsilon$>0, there exists M = $max(M_1,M_2)$, such that x>M implies that $$|f(x)+ \frac{df}{dx}(x)| < \epsilon$$
$$\implies-\epsilon < f(x) +  \frac{df}{dx}(x)  < \epsilon$$
$$\implies -\frac{df}{dx}(x) -\epsilon < f(x)   < -\frac{df}{dx}(x) +\epsilon$$ and since by assumption we know that the limit at infinity for f(x) exists, then the limit must be $-\frac{df}{dx}$, by the last inequality above. Now I think the goal is to just show that the limit at infinity of $|\frac{df}{dx}|=0.$  Then we would have the desired equality, by the Squeeze Theorem. But what can I say about the limit of $|\frac{df}{dx}|$? Thanks,","['derivatives', 'limits', 'real-analysis', 'integration']"
1484099,Cramer-Rao lower bound and efficiency vs biased estimator efficiency,"I am a bit confused on the Cramer-Rao (CR) lower bound. If an estimator achieves the CR lower bound, then it is UMVUE, right? And for any given set of unbiased estimators, the one with the lowest variance is the most efficient. So for any set of unbiased estimators, the one that achieves the CR lower bound is the most efficient of the group since it is uniformly min-var., but is it possible to find a biased estimator that could be more efficient? If I did find one, is comparing the two really worth while, or should I just stick with the CR lower bound estimator. Thanks for looking","['probability-theory', 'probability']"
1484122,Is total variation a continuous map from complex measures to positive measures?,"The following question arises naturally in my current research. It seems to be a basic problem in measure theory, and therefore I guess that answers to it can be found in some textbooks. However, I looked in a few books and found nothing. Since measure theory is not really my field of interest (I do symplectic geometry), I would appreciate any relevant observations and/or references to a text handling this issue. Let $\Omega$ be a bounded domain in $\mathbb{R}^n$, let $M_\mathbb{C}(\Omega)$ denote the space of complex Borel measures on $\Omega$, and let $M_+(\Omega)$ denote the space of positive Borel measures on $\Omega$. For every complex measure $\lambda\in M_\mathbb{C}(\Omega)$, the total variation of $\lambda$, denoted by $|\lambda|$, is a positive measure. In other words, we have$$|\cdot|:M_\mathbb{C}(\Omega)\to M_+(\Omega).$$We define weak convergence of measures in the usual manner, when thinking of a measure as a linear functional on the space of continuous functions. Namely, we say the sequence $\lambda_1,\lambda_2,\ldots$ of measures converges weakly to the measure $\lambda$, if we have$$\int_\Omega\varphi\lambda_n\to\int_\Omega\varphi\lambda$$for every continuous compactly supported $\varphi:\Omega\to\mathbb{R}$. Question: Is $|\cdot|$ continuous with respect to weak convergence? That is, if the sequence $(\lambda_n)$ converges weakly to $\lambda$, does it follow that the sequence $(|\lambda_n|)$ converges weakly to $|\lambda|$? If the answer is no, can we add some assumptions on the measures in question to change the picture? My intuition tells me that the answer should be positive without any further assumptions, but then again, I don't really know... As written above, any observations are welcome.","['real-analysis', 'functional-analysis', 'measure-theory']"
1484142,"Will Riemann Hypothesis, if true, give us the exact value of number of primes less than a given number?","As we know that RH is the most popular unsolved problem in all of maths. If this hypothesis is true, then will it give us the power to predict the exact number of primes less then a given number? And how it will effect the e-commerce system?","['riemann-hypothesis', 'prime-numbers', 'number-theory']"
1484175,$f \in L^p \cap L^q$ implies $f \in L^r$ for $p\leq r \leq q$.,"Let $(X, \mathfrak{M}, \mu)$ is a measure space. Let $f:X \rightarrow \mathbb{C}$ be a measurable function. Prove that the set $\{1 \le p \le \infty \, | \, f \in L^p(X)\}$ is connected. In other words prove that if $f \in L^p(X) \cap L^q(X)$ with$ 1\le p < q \le \infty$ and if $p\le r \le q$, then $f \in L^r(X)$. I've tried to prove this using Holder's Inequality, here's my attempt: Since $r \in [p,q]$, let $\lambda$ be such that $(1-\lambda)p+\lambda q = r.$ We use the fact that $f \in L^r(X)$ iff $|f|^r \in L^1(X)$. Let $m = \frac{1}{1-\lambda}$ and $n=\frac{1}{\lambda}$ so that $m$ and $n$ are conjugates. Then, \begin{eqnarray*}
\int_{X} |f|^r \, d\mu &=& \int_{X} |f|^{(1-\lambda)p+\lambda q} \, d\mu \\
&=& \int_X |f|^{(1-\lambda)p}|f|^{\lambda q} d\mu \\
&\stackrel{\text{H$\ddot{o}$lder}}{\leq}& \left(\int_X |f|^p \, d\mu\right)^{(1-\lambda)}\left(\int_X |f|^q \, d\mu \right)^\lambda \, \\
&<& \infty
\end{eqnarray*} Since surely the RHS is finite since $f \in L^p(X) \cap L^q(X)$. Is this correct? Is this the intended method of proof?","['proof-verification', 'real-analysis', 'lp-spaces', 'integration', 'analysis']"
1484208,Proof: Need help with Rodrigues's formula for finding coefficent of $x^n$,I’m having problems with proving Rodrigues’s formula. I’m stuck on expanding $$u=D^n((x^2-1)^n)$$ (where D is the differential operator) to “show that the coefficient of x^n in u is $$(2n)!/(n!)$$”. I’ve used Leibniz’s formula to differentiate it n times via difference of squares and got to this:$$\sum_{k=0}^n ((x+1)^{n-k}(x-1)^k\frac{(n!)^3}{(k!)^2((n-k)!)^2})$$but I’m still no closer to proving it. Can someone please give me a hint with this.,"['ordinary-differential-equations', 'derivatives']"
1484272,Distance between two hyperplanes,"I have two parallel hyper planes $$a^Tx=b_1,a^Tx=b_2$$ where $a \in \mathbb{R}^n, x \in \mathbb{R}^n ,b \in \mathbb{R}$ and I want to find the distance between the two.
I have read that the distance between the two hyperplanes is also the distance between the two points $x_1$ and $x_2$ where the hyperplane intersects the line through the origin and parallel to the normal vector $\vec a$. These points are given by $$x_1=\frac{b_1}{\|a\|^2_2}a$$ and $$x_2=\frac{b_2}{\|a\|^2_2}a$$
Then the distance is $|x_1-x_2|$ but I don't really understand how we got $x_1$ and $x_2$.",['linear-algebra']
1484305,Prove distinct right cosets of $H$ in $G$ form a partition in $G$.,"Let $H$ be a subgroup of the group $G$. Prove that if two right cosets $Ha$ and $Hb$ are not disjoint, that is $$Ha~\cap~ Hb \neq \emptyset$$ then we have $$Ha=Hb$$ that is, the distinct right cosets of $H$ in $G$ form a partition in $G$. My attempt: Let $H$ be a subgroup of the group $G$. Let $a\neq b \in G$ be arbitrtary. Suppose now that $$Ha~\cap~ Hb \neq \emptyset$$ thus, there exists some $x \in Ha~\cap~ Hb$. Therefore we must have that $x \in Ha$ and $x\in Hb$. From this we can deduce that $$x=h_1 a ~~ \text{and}~~ x=h_2b,$$ for some $h_1, h_2 \in H$. Equality thus yields that \begin{align}h_1a &= h_2b \\ h_1^{-1}h_1a &=h_1^{-1}h_2b \\ a &= (h_1^{-1}h_2)b\end{align} This is where I am stuck. Can anyone please show me how to continue from here? Or am I on the wrong track completely?","['abstract-algebra', 'group-theory']"
1484330,Finding all positive integer solutions for $x+y=xyz-1$,"How do I manually solve $x+y=xyz-1$ assuming that $x, y$ and $z$ are positive integers? I was able to guess all possible solutions, but I do not know how to show that these are the only ones: $x=1, y=1, z=3$ $x=1, y=2, z=2$ $x=2, y=1, z=2$ $x=2, y=3, z=1$ $x=3, y=2, z=1$ Any hints would be appreciated.","['number-theory', 'diophantine-equations', 'integers']"
1484332,Prove that $[(p \to q) ∧ (q \to r)] \to (p \to r)$ is a tautology without truth tables,"Prove that this tautology is always true without truth table.
 $\begin{align}
[(p \to q) ∧ (q \to r)] \to (p \to r)
\end{align}$ What mistake did I make? It doesn't seem to be true. $\begin{align}
[(p \to q) ∧ (q \to r)] \to (p \to r)
\\ [ (\neg p \vee q) ∧ (\neg q \vee r)] \to (\neg p \vee r)
\\ [(p ∧ \neg q) \vee (q∧\neg r)] \vee (\neg p \vee r)]
\\ [\neg p \vee(p∧ \neg q)] \vee [ r \vee (q ∧ \neg r)]
\\ [(\neg p \vee p) ∧(\neg p \vee \neg q)] \vee [(r \vee q) ∧ ( r \vee \neg r)]
\\ [1 ∧ (\neg p \vee \neg q)] \vee [1 ∧(r \vee q)]
\\ (\neg p \vee \neg q) \vee (r \vee q)
\end{align}$","['logic', 'discrete-mathematics']"
1484334,Can someone explain the ABC conjecture to me?,"I am an undergrad and I know that the conjecture may have been proven recently. But in reading about it, I am entirely confused as to what it means and why it is important. I was hoping some of you kind people could help me. I know there are several formulations of the conjecture. Wolfram says: for any infinitesimal $\epsilon > 0$, there exists a constant $C_\epsilon$ such that for any three relatively prime integers $a$, $b$, $c$ satisfying $a+b=c$ the inequality $$\max (|a|, |b|, |c|) \leq C_{\epsilon}\displaystyle\prod_{p|abc} p^{1+\epsilon}$$
holds, where $p|abc$ indicates that the product is over primes $p$ which divide the product $abc$. Then Wikipedia says: For a positive integer $n$, the radical of $n$, denoted $\text{rad}(n)$, is the product of the distinct prime factors of $n$. If $a$, $b$, and $c$ are coprime positive integers such that $a + b = c$, it turns out that ""usually"" $c < \text{rad}(abc)$. The abc conjecture deals with the exceptions. Specifically, it states that for every $\epsilon>0$ there exist only finitely many triples $(a,b,c)$ of positive coprime integers with $a + b = c$ such that $$c>\text{rad}(abc)^{1+\epsilon}$$ An equivalent formulation states that for any $\epsilon > 0$, there exists a constant $K$ such that, for all triples of coprime positive integers $(a, b, c)$ satisfying $a + b = c$, the inequality $$c<K\cdot\text{rad}(abc)^{1+\epsilon}$$ holds. A third formulation of the conjecture involves the quality $q(a, b, c)$ of the triple $(a, b, c)$, defined by: $$q(a,b,c)=\frac{\log(c)}{\log(\text{rad}(abc)}$$ I am particularly interested in the first definition, but any help with any of it would be greatly appreciated.","['open-problem', 'number-theory']"
1484403,What is the function for a 'fractal sine wave'?,"Maybe I abused the word fractal here. I was wondering what's the function ( if not functions ) for this wave: My attempt was this function, It looks the same, but It's not.
The second sine wave is following the envelope of the first, somewhat following the 90-degree angle of the first sine wave. $y=\frac{sin(200*x)}{10}+sin(x)$","['approximation', 'functions']"
1484409,Limit of Expected values,"Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $\{X_n : n \geq 1 \}$ be a sequence of Independent random variables. $$E(X_n) = 0 \; , \; Var(X_n) = 1 \; \; \forall n $$ Show that for any $Y \in L^2$ it is neccesarily true that $$E(X_nY) \xrightarrow{n \rightarrow \infty} 0 $$ Stuck on this problem. I tryed to use dominated convergence but I could neither prove the pointwise limit nor find a dominating function. Is this the wrong approach?",['probability-theory']
1484427,Inverse Laplace transform of $\frac{\exp(\frac{\lambda s}{1 - 2s})}{(1 - 2s)^{k/2}}$ (MGF of noncentral chi-squared distribution),"I am trying to use the countour integral to calculate the inverse Laplace transform of the function
$$F(s) = \frac{\exp(\frac{\lambda s}{1 - 2s})}{(1 - 2s)^{k/2}} \hspace{1cm}\mathrm{for} \hspace{1cm} s<\frac{1}{2}$$ The above function is the MGF of the noncentral chi-squared function Wikipedia: noncentral chi-squared distribution . From Bromwich's integral, we have \begin{align}
f(x) = & \frac{1}{2\pi i}\int_{c - \infty i}^{c + \infty i} F(s)e^{sx}\,ds \\
     = & \frac{1}{2\pi i}\int_{c - \infty i}^{c + \infty i} \frac{\exp(\frac{(\lambda + x -2xs) s}{1 - 2s})}{(1 - 2s)^{k/2}} \, ds \\
     = & \frac{1}{2\pi i}\oint_{C} \frac{\exp(\frac{(\lambda + x -2xs) s}{1 - 2s})}{(1 - 2s)^{k/2}} \, ds - \frac{1}{2\pi i}\int_{C_{R}} \frac{\exp(\frac{(\lambda + x -2xs) s}{1 - 2s})}{(1 - 2s)^{k/2}} \, ds
\end{align} The difficult part for me is how to choose the contour since $s$ exists in both the nominator and denominator of the exponential function. I have no idea about how to choose a contour such that the integral along $C_{R}$ vanishes. The answer to the question is 
\begin{align}
f(x) = & 1 - Q_{k/2}(\sqrt{\lambda}, \sqrt{x}) \\
     = & e^{-\frac{\lambda}{2}} {}_{0}F_{1}(;\frac{k}{2};\frac{\lambda x}{4}) \frac{e^{-\frac{x}{2}} x^{\frac{k}{2}-1}}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})}
\end{align}
with $Q_{m}(a, b)$ denoting the Marcum Q-function. That's the PDF of the noncentral Chi-square distribution. But how to get this answer from its MGF $F(s)$???","['inverse', 'calculus', 'contour-integration', 'laplace-transform', 'complex-analysis']"
1484451,Density of a Normal RV whose mean is drawn from a Normal Distribution (Compound Distribution),"I am trying to compute the density of a random variable that is normal distributed, where the mean of the distribution is itself drawn from a normal distribution. I would like to find the best estimate of $\mu$ given $c$, where $\mu, c$ are defined: \begin{align*} c \sim N(\lambda, 1)\\
 \lambda \sim N(\mu,1) \end{align*} Given that we have no prior on $\mu$ I assume the maximum likelihood is the best approach to this question. Wikipedia says 
""Compounding a Gaussian distribution with mean distributed according to another Gaussian distribution yields a Gaussian distribution."" but offers no reference for this. I cannot work this out myself and have no clue where to look for lecture notes or textbooks on this.","['probability', 'probability-distributions']"
1484473,Problem related to maximum and minimum value of a trigonometric function,I have used the following technique to calculate the maximum value of the function... but I couldn't proceed with next step.. can anyone guide me please? Find the maximum and minimum value of the function $$f(x) = \sin^2(\cos x)+\cos^2(\sin x)$$ I have written the following function as $$1+\sin^2(\cos x)-\sin^2(\sin x) = 1+\sin(\cos x+\sin x)\cdot \sin(\cos x-\sin x)$$,"['calculus', 'trigonometry']"
1484562,The Scorza-Dragoni theorem as a consequence of Egorov's theorem?,"Scorza-Dragoni theorem (at least the version I have used) says that if you have a function $f : \Omega \times \mathbb{R}^{N} \longrightarrow \overline{\mathbb{R}}$ which satisfies: i) $x \rightarrow f(x,v)$ is measurable for all $v \in \mathbb{R}^{N}$ ii) $v \rightarrow f(x,v)$ is continuous for  almost every $x \in \Omega$ iii) $f$ is locally integrable Then for any positive $\epsilon$ there exists a compact subset of $\Omega,$ say $K,$ such that $f$ restricted to $K \times \mathbb{R}^{N}$ is a continuous function and $\vert K^{c} \vert < \epsilon$ I tried to prove this before looking for it somewhere and came up with a stupidly simple proof, which confuses me, because if this were right, the theorem wouldn't have its own name :S My reasoning is: As we have a measurable function, we can approximate it pointwise by step functionts which, in turn, can be approximated pointwise by continuous functions almost everywhere . Theorefore, by Egorov's theorem we can find $K$ such that $\vert K^{c} \vert < \epsilon$ and such that those continuous functions converge uniformly. The limit on $K$ is then continuous and clearly coincides with the restriction of $f.$ There must be some subtle technical point I am omiting, because I guess the proof of a named theorem cannot be this silly. Where is my mistake? Thanks for your help EDIT: Added the almost everywhere that was missing","['proof-verification', 'measure-theory']"
1484565,Maps of discs into surfaces,"Let $f:D \to S $ be a continuous map from the closed unit disc in $R^2$ into a closed surface of genus $g \geq 1$ such that $f|_{\partial D}$ is an embedding (homeomorphism onto its image) with Image $\gamma$ a simple closed curve. Then, $\gamma$ bounds an embedded disc $D* \subset S$ and I wonder if it is true that $D* \subset f(D)$.","['general-topology', 'geometric-topology']"
1484612,How many tosses for 95% centainty that coin is not fair,"Given a bag of 10 coins, 9 are ordinary coins and one is a double headed coin. You select one coin at random and toss it three times. It comes up heads each time what is the probability its the double header? This can be solved using bayes rule the answer is $\frac{8}{17}$. However the follow up question asks how many tosses would you need to be 95% sure that the coin is double headed? Based on Mark Galek's answer here If I flip a coin 1000 times in a row and it lands on heads all 1000 times, what is the probability that it's an unfair coin? The probability of getting a head n times is: $(\frac{1}{2})^n$ and I need to find the value of n that gives us 95% confidence that the coin is not fair. $(\frac{1}{2})^n=0.05$ $n=ln(0.05)/ln(\frac{1}{2})$ n=5 Is this correct my gut instinct is that it is a little low? Here I have used the CI for the fair coin to try and find how many heads would be required for us to be 95% sure that it isn't fair. Given that the only other choice here is for the coin to be double headed I believe this is correct. Is there any other way this calculation could be done without using the CI for the fair coin?",['probability']
1484675,"How to find the base, given a number and its representation in the base?","If 211 in base $x$ is 152 base 8, how to find $x$? With trial and error or there's a method?","['elementary-number-theory', 'algebra-precalculus']"
1484678,"Let A be a square matrix of order n. Prove that if $A^2 = A$, then $\operatorname{rank}(A) + \operatorname{rank}(I - A) = n$. [duplicate]",This question already has answers here : $\mathrm{rank}(A)+\mathrm{rank}(I-A)=n$ for $A$ idempotent matrix (2 answers) Closed 8 years ago . $A(I-A) = 0\implies\operatorname{rank}(A) + \operatorname{rank}(I-A)\le n$. I managed to get this but wasn't able to go further. Any help would be appreciated.,"['matrix-rank', 'linear-algebra', 'idempotents', 'matrices']"
1484802,Find the last three digits of $17^{102}$.,"Find the last three digits of $17^{102}$. That is we have to find out $17^{102}\equiv ?\pmod{1000}$. Now if we solve it through general congruence relation , then the process becomes very difficult , computational and laborious. Again from Euler's theorem , $$17^{\phi(1000)}\equiv 1 \pmod{1000}.$$ But $\phi(1000)=400(>102)$. So it can't help me. Does there any simplest way to solve this congruence relation easily ?","['congruences', 'algebra-precalculus', 'congruence-relations']"
1484812,How to prove that if the one sided limits are equal the general limit is that value?,"My teacher proposed this question as a challenge proof to do on our own and I can't seem to get it. Was Wondering if anyone could give me a hint or help me on the process to completing it. Let $a \in \mathbb{R}$. Let $f$ be a function defined, at least, on an interval 
centred at $a$, except possibly at $a$. Let $L \in \mathbb{R}$. If $\lim\limits_{ x→a-} f(x) = \lim\limits_{ x→a+} f(x) = L$
  then $\lim\limits_{ x→a} f(x) $ = $L$. We are supposed to prove this using the ""delta-epsilon"" proof style. Thanks in advance!!","['analysis', 'calculus', 'limits']"
1484835,"Find the distribution of $|X-Y|$ if $X$ and $Y$ are i.i.d. uniform on $[0,1]$","$X$ and $Y$ are independent random variables uniformly distributed over $[0,1]$. I want to find the CDF of $|X-Y|$. I could use convolution but I wan't to calculate this more ""directly"". Here is my set-up so far: Let $Z = |X-Y|$. Then, $F_Z(z) = P(Z \leq z) = P(|X-Y| \leq z)$. We can split up this last inequality into two cases because of the absolute value: $P(|X-Y| \leq z) = P(X-Y \leq z, X \geq Y) + P(Y-X \leq z, Y > X)$ We now compute the two terms separately with integration. Let's start with the first term: To integrate this we need to find the correct limits of integration. The constraints we must satisfy are: $0 \leq x,y \leq 1$ $x \geq y$ $x - z \leq y$ All of this implies $\max\{x-z,0\} \leq y \leq \min\{1,x\}$. But, $x =1$ at most so we can replace $\min\{1,x\}$ with just $x$: $\implies \max\{x-z, 0\} \leq y \leq x$ We use these boundaries to set up the integral of the first term: $P(X-Y \leq z , X \geq Y) = \int_0^1{\mathrm{d}x \int_{\max\{x-z,0\}}^x{\mathrm{d}y}}$ Should I continue proceeding this way? Is my set up correct? Thank you!","['probability-theory', 'uniform-distribution', 'probability-distributions']"
1484842,Show that $\frac{1}{2}(0.5)+\frac{(1+\frac{1}{2})}{3}(0.5)^2+\frac{(1+\frac{1}{2}+\frac{1}{3})}{4}(0.5)^3+\cdots=(\log 2)^2$,"Show that $$\frac{1}{2}(0.5)+\frac{(1+\frac{1}{2})}{3}(0.5)^2+\frac{(1+\frac{1}{2}+\frac{1}{3})}{4}(0.5)^3+\cdots=(\log 2)^2$$
I tried to prove it by using the Taylor series, But I've found it not useful as shown below any help, thanks","['sequences-and-series', 'calculus']"
1484863,Can I always decompose a random variable in sum of iid random variables?,"Let $Z$ be a random variable. Can I always find a number $n \in \mathbb N > 1$, weights $w_i \neq 0$, and iid random variables $X_i$ such that $$Z = w_1X_1 + \dots + w_n X_n$$? Conversely, if I have a certain combination of $w_i$ and $X_i$, can I always choose the distribution that the $X_i$ follow so to make $Z$ follow whatever distribution I like? Thanks! (Maybe I should ask the converse in another question?)","['probability-theory', 'characteristic-functions', 'probability', 'random-variables']"
1484870,"Prove that the product $NK$ of two normal subgroups $N$ and $K$ of a group $G$ is a normal subgroup of $G$, and $NK=KN$.","This seemed a bit too simple, so I just wanted to get it verified. The Statement of the Problem: Prove that the product $NK$ of two normal subgroups $N$ and $K$ of a group $G$ is a normal subgroup of $G$, and $NK=KN$. My Approach: For the first part: (WTS that $gNK = NKg)$ \begin{align}
   gNK & = (gN)K & &\text{(because of associativity)} \\
   & = (Ng)K & & \text{(because $N$ is normal)} \\
   & = N(gK) & & \text{(because of associativity)} \\
   & = N(Kg) & & \text{(because $K$ is normal)} \\
   & = NKg & & \text{(because of associativity)} \\
\end{align} Therefore $gNK = NKg$, as desired. Now, for $NK = KN:$ Well, since $NK$ is a (normal) subgroup of $G$, it is closed under inverses, so $$ NK = (NK)^{-1}=K^{-1}N^{-1}=KN. $$ And, that's what it's all about! ...right?","['abstract-algebra', 'group-theory', 'proof-verification']"
1484895,"True or False Questions about Open , Closed, and Closure Set.","For any set A, complement of closure A is open => True since closure A is closed and complement must be open. If a set A has an isolated point, it cannot be an open set.  => I think it is true, but can not think of proof. 3.Set A is closed if and only if A= closure of A => True by following definition. If A is a bounded set, then s=supA is a limit point of A => False Let A={1,2,3} then supA is 3 but 3 is not a limit point. Every finite set is closed => true, singleton element is closed and finite union of closed sets is closed. An open set that contains every rational number must necessarily be all of R
I think it is true, but anyone can explain? If there are any wrong answers, please point out and show me some counterexmaples. Thanks","['elementary-set-theory', 'real-analysis']"
1484904,Why are periodic solutions impossible for a differential equation on $\mathbb{R}$?,"I am trying to understand a simple property of odes defined on a real line (or a subset of the real line). Consider an ordinary autonomous differential equation where the dependent variable $x$ is defined on the real line, i.e. $$\dot{x} = f(x),$$ where $x \in \mathbb{R}$, and the dot is differentiation with respect to time $t$. It is known that the corresponding phase portrait has solutions that are equilibria, and all other solutions either move towards $\pm \infty$, or towards / away from the equilibria. Geometrically, if we draw the phase portrait, we only can have equilibria and all other trajectories move right or left. No periodic solutions exist. So what about nonautonomous ode like $$\dot{x}=\cos t.$$ The general solution is $x(t)=\sin t - \sin t_{0} +x_{0}$.  It is clear that all solutions are periodic. Does that contradict the above theory? How would the corresponding phase portrait look like?","['dynamical-systems', 'calculus', 'real-analysis', 'ordinary-differential-equations']"
1484968,An asymptotic behavior of $\operatorname{Li}_{-n}(a)$ for $n\to\infty$,"Suppose $a,b\in(0,1)$ . I'm interested in comparison of an asymptotic behavior of $\operatorname{Li}_{-n}(a)$ and $\operatorname{Li}_{-n}(b)$ for $n\to\infty$ . Such functions exhibit approximately factorial-like (faster than exponential) growth rate. The particular case $\operatorname{Li}_{-n}\!\left(\tfrac12\right)$ for $n\ge1$ gives (up to a coefficient) a combinatorial sequence called Fubini numbers or ordered Bell numbers $^{[1]}$ $\!^{[2]}$ $\!^{[3]}$ (number of outcomes of a horse race provided that ties are possible). This sequence is known to have the following asymptotic behavior: $$\operatorname{Li}_{-n}\!\left(\tfrac12\right)\sim\frac{n!}{\ln^{n+1}2}.\tag1$$ After some numerical experimentation I conjectured the following behavior: $$\ln\!\left(\frac{\operatorname{Li}_{-n}(a)}{\operatorname{Li}_{-n}(b)}\right)=(n+1)\cdot\ln\!\left(\frac{\ln b}{\ln a}\right)+o\!\left(n^{-N}\right)\tag2$$ for arbitrarily large $N$ (so, the remainder term decays faster than any negative power of $n$ ). It looks like the remainder term is oscillating with exponentially decreasing amplitude, but I haven't yet found the exact exponent base or asymptotic oscillation frequency. Could you suggest a proof of $(2)$ or further refinements of this formula?","['conjectures', 'analytic-number-theory', 'combinatorics', 'asymptotics', 'polylogarithm']"
1484974,How many non-isomorphic simple graphs are there on n vertices when n is...,"How many non-isomorphic simple graphs are there on n vertices when n is 2? 3?
4? and 5? So I got... $2$ when $n=2$ $4$ when $n=3$ $13$? (so far) when $n = 4$ But I have a feeling it will be closer to 16. I was wondering if there is any sort of formula that would make finding the answer easier than just drawing them all out. And if not, if anyone could confirm my findings so far.","['graph-theory', 'discrete-mathematics']"
1484981,Joint Distribution function and joint density function,"I am really confused with what the question is asking and where to start. Thanks in advance for help. Suppose $(a,b) $~uniform$([0,1]\times[0,1])$  (Does that mean we are given the join density function?) Determine the cdf $F: R^2 \to [0,1]$ Determine the density $f$ from $F$.","['probability', 'statistics', 'probability-distributions']"
1484993,"Let $A \unlhd G$ and $o(x) = 3$ for each $x \notin A$, then $[B, B^x] = 1$ for abelian subgoups $B \le A$.","Let $A$ be a normal subgroup of $G$. If each element from $G \setminus A$ has order $3$, then $[B, B^x] = 1$ for every abelian subgroup $B \le A$ and $x \in G \setminus A$. Any hints for this exercise? I have totally no idea how to exploit the fact that $x$ has order three (guess this might be crucial here...). All I see is that $B^x \le A$ by normality of $A$ and that we must show $[b, \hat b^x] = 1$ for $b, \hat b \in B$.","['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
1485018,How to evaluate the line integral?,"I've solved part (a) and (b), but I'm unsure about part (c). My attempt is: $\int_C f(x,y,z)ds$ = $\int_0^4 ((2t*\frac{4}{3}t^{3/2}*\frac{1}{2}t^2$)(t+2) = $\frac{2}{13}4^{3/2} + \frac{8}{33} 4^{11/2}$ But I'm not sure I'm on the right track at all.","['calculus', 'multivariable-calculus', 'integration']"
1485023,In which algebraic theories do 'free' and 'projective' coincide?,"Free models of algebraic theories are always projective objects in the category of models, but the converse is not always true. For instance, some (actually, all) projective modules are direct summands of free modules, and these need not be free. On the other hand, the two notions do coincide for abelian groups. Hence I'm left wondering: for which kinds of algebraic theories do free and projective coincide?","['abstract-algebra', 'projective-module', 'universal-algebra', 'category-theory']"
1485036,"$2^\text{nd}$ Derivative of normal distribution, evaluated at one standard deviation","What is the $2^{nd}$ derivative of the normal distribution at one standard deviation? The normal distribution is given by $N(x,\mu ,\sigma)=\frac{1}{\sigma\sqrt{2\pi }}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$. To make this problem easier, lets say I have a standard normal distribution($\mu =0,\sigma =1$). So $N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$. $$\frac{d}{dx}N(x,0,1)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}\frac{d}{dx}\left(e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{\left(x\:\right)^2}{2}\cdot \frac{d}{dx}\left(-\frac{x^2}{2}\right)}$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot -x}$$ So, $$\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}$$ is the first derivative. To get the second, I took the derivative of the first. $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot \:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\:\sqrt{2\pi }}\frac{d}{dx}\left(e^{-\frac{x^2}{2}\cdot\:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N(x,0,1)\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}\cdot \frac{d}{dx\:}\left(-\frac{x^2}{2}\cdot \:-x\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(x^2}{2}\cdot \:-x}\right)\cdot \left(3\frac{x^2}{2}\right)$$ So now I evaluate $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{x^2}{2}\cdot -x}\right)\cdot \left(3\cdot \frac{x^2}{2}\right),$$ at the standard deviation which I set to $\sigma =1$ So, $$\frac{1}{\sqrt{2\cdot :\pi}}\left(e^{-\frac{1^2}{2}\cdot -1}\right)\cdot \left(3\cdot\frac{1^2}{2}\right)$$ $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(1)^2}{2}\cdot\,-1}\right)\cdot \left(3\cdot \frac{1^2}{2}\right)=\frac{3\sqrt{e}}{2\sqrt{2\cdot\pi}}$$ But my teacher says the answer is suppose to be $0$? What am I doing wrong? Side Note: I am new to Calculus. So an elaborate explanation will be appreciated.","['statistics', 'normal-distribution', 'calculus', 'derivatives']"
1485057,What is the purpose of showing some numbers exist?,For example in my Analysis class the professor showed $\sqrt{2}$ exists using Archimedean properties of $\mathbb{R}$ and we showed $e$ exists. I want to know why it's important to show their existence?,"['motivation', 'real-numbers', 'real-analysis', 'soft-question']"
1485069,How do you find the derivative of the integral $\sin(\ln x)$,"$$\frac{d}{dx} \;\left[ \int_{a}^{x^2}\sin(\ln(z))\;dz\right]$$ I'm not sure if I'd have to do the chain rule on the natural logarithm and them $x^2$, or if there is no chain rule at all. Any help would be appreciated, thank you!","['derivatives', 'logarithms', 'definite-integrals', 'integration']"
1485189,Show that a group of order 7 has no subgroups of order 4.,I can do this with the use of Lagrange's theorem but my professor says its possible without it. I can't find how to go about solving it. Any hints would be appreciated.,"['abstract-algebra', 'group-theory']"
1485195,Problems in Theorem 2.43 of baby Rudin,"Theorem 2.43 Let $P$ be a nonempty perfect set in $\mathbb{R}^k$ . Then $P$ is uncountable. Proof Since $P$ has limit points, $P$ must be infinite. Suppose $P$ is countable, and denote the points of $P$ by $\mathbf{x_1}, \mathbf{x_2}, \mathbf{x_3}, \ldots$ . We shall construct a sequence $\{V_{n}\}$ of neighborhoods as follows. Let $V_1$ be any neighborhood of $\mathbf{x_1}$ . If $V_1$ consists of all $y\in \mathbb{R}^k$ such that $|y−x_1|<r$ , the closure $\overline{V_1}$ of $V_1$ is the set of all $y\in \mathbb{R}^k$ such that $|y−x_1|≤r$ . Suppose $V_n$ has been constructed, so that $V_n\cap P$ is not empty. Since every point of $P$ is a limit point of $P$ , there is a neighborhood $V_{n+1}$ such that (i) $\overline{V_{n+1}} \subset V_n$ , (ii) $x_n\notin \overline{V_{n+1}}$ , (iii) $V_{n+1}\cap P$ is not empty. By (iii), $V_{n+1}$ satisfies our induction hypothesis, and the construction can proceed. Put $K_n=\overline{V_n}\cap P$ . Since $\overline{V_n}$ is closed and bounded, $\overline{V_n}$ is compact. Since $\mathbf{x_{n}}\notin K_{n+1}$ , no point of $P$ lies in $\cap_1^\infty K_n$ . Since $K_{n}\subset P$ , this implies that $\cap_1^\infty K_n$ is empty. But each $K_n$ is nonempty, by (iii), and $K_n\supset K_{n+1}$ , by (i); this contradicts the Corollary to Theorem 2.36. I have not been able to understand third paragraph of Walter's proof. I would like to understand why the neighborhood $V_{n+1}$ exists with properties (i),(ii) and (iii), using only the previous definitions and theorems of the Book.","['metric-spaces', 'vector-spaces', 'general-topology']"
1485199,Associativity of extension of scalar (tensor product),"I am trying to prove the following basic property
$$(M \otimes_A B) \otimes_B C \cong M \otimes_A (B \otimes_B C) \cong M \otimes_A C$$
where $M$ is $A$-module, $B$ is an $A$-algebra and $C$ is $B$-algebra. (All rings are commutative.)  Note that this is isomorphism of $C$-modules. Intuitively, I understand the isomorphism as ""transitivity of extension of scalars"": to extend scalars of $M$ from $A$ to $C$ i.e. $M \otimes_A C$, we can extend scalars of $M$ from $A$ to $B$ to get a $B$-module $M \otimes_A B$ and then extend its scalar from $B$ to $C$. I want to do it using universal (adjunction) property of tensor product; namely $P \otimes_A N$ is the module such that for any $A$-module $Q$, one has
$$Hom_A(P \otimes_A N, Q) \cong Hom_A(P, Hom_A(N, Q)).$$
Unfortunately, I can only prove associativity
$$(M \otimes_A B) \otimes_A C \cong M \otimes_A (B \otimes_A C)$$
as $A$-modules. Is there a universal property for the case of tensoring $M \otimes_A B$ where $B$ is $A$-algebra?","['abstract-algebra', 'tensor-products', 'universal-property']"
1485226,Integration by substitution not working?,"I've been working on a set of problems for the past 6 hours and I'm about to explode from frustration! Either my book has errors, Wolfram Alpha is broken or integration by substitution does not work! I'm trying to solve the following ODE:
$$
\frac{\mathrm dh}{\mathrm dt}=\frac{1-20kh+kh^2}{20h-h^2},\text{ where }k=0.01
$$ Here is what I have (the first line is the ODE I'm trying to solve, if it's unclear): $$\begin{align}
\frac{\mathrm dh}{\mathrm dt}&=\frac{1-20kh+kh^2}{20h-h^2}\\
\frac{20h-h^2}{1-20kh+kh^2}\,\mathrm dh&=\mathrm dt\\[5pt]
\frac{20h-h^2}{1-0.2+0.01h^2}\,\mathrm dh&=\mathrm dt,\text{ since }k=0.01\\[5pt]
\frac{100\left(20h-h^2\right)}{100-20h+h^2}\,\mathrm dh=\mathrm dt\\[5pt]
\int\frac{2000h-100h^2}{(h-10)^2}\,\mathrm dh&=\int\mathrm dt
\end{align}$$ Let $u=h-10$ So, $h=u+10$ And, $\mathrm dh=\mathrm du$ $$\begin{align}\require{cancel}
\int\left(\frac{2000(u+10)}{u^2}-\frac{100(u+10)^2}{u^2}\right)\,\mathrm du&=t+c\\[5pt]
\int\left(\frac{2000u}{u^2}+\frac{20000}{u^2}-\frac{100(u^2+20u+100)}{u^2}\right)\,\mathrm du&=t+c\\[5pt]
\int\left(\cancel{\frac{2000}u}+\frac{20000}{u^2}-100-\cancel{\frac{2000}u}-\frac{10000}{u^2}\right)\,\mathrm du&=t+c\\[5pt]
\int\left(\frac{10000}{u^2}-100\right)\,\mathrm du&=t+c\\[5pt]
-\frac{10000}u-100u&=t+c\\[5pt]
-\frac{10000}{h-10}-100(h-10)&=t+c\\[5pt]
-\frac{10000-100(h-10)^2}{h-10}&=t+c\\[5pt]
-\frac{100\left(100+(h-10)^2\right)}{h-10}&=t+c\\[5pt]
-\frac{100\left(100+\left(h^2-20h+100\right)\right)}{h-10}&=t+c\\[5pt]
\frac{100\left(h^2-20h+200\right)}{10-h}&=t+c
\end{align}$$ But according to Wolfram Alpha, that isn't the correct answer. http://wolframalpha.com/input/?i=integrate+%28100x%2820-x%29%2F%28x-10%29%5E2%29+with+respect+to+x And according to my book's solution manual, this is the answer (same as Wolfram Alpha's answer): (b) Letting $k=1/100$, separating variables and integrating (with the help of a CAS), we get $$\frac{100h(h-20)}{(h-10)^2}\,\mathrm dh=\mathrm dt\;\text{and}\;\frac{100\left(h^2-10h+100\right)}{10-h}=t+c$$ The equation on the right in the solutions manual is the same as what Wolfram Alpha outputs. However, it seems that there's a typo in the equation on the left. It should be $\frac{100h(20-h)}{(h-10)^2}$ instead of $\frac{100h(h-20)}{(h-10)^2}$. If we input that left equation in Wofram Alpha, we don't get the solution on the right: http://www.wolframalpha.com/input/?i=integrate+%28100x%28x-20%29%2F%28x-10%29%5E2%29+with+respect+to+x (see comments in the graydad's answer) What's going on? Why isn't my method giving me the right answer? For reference: question a solution to question a my solution to question a (which is correct)",['ordinary-differential-equations']
1485230,How to convert from a power of base two to a power of base 10?,"I might have an extremely silly question:
If I have a number, say $2^{32}$ and I need to convert to base 10, how should I do it? I know it should be $4 * 10^9$, but I do not know how did we get it. I understand that $10$ is $2^3 + 2$, but I cannot understand how to proceed further in my reasoning... Thanks!",['algebra-precalculus']
1485231,"If $X$ is independent of $Y$, is it true that $E(f(X)|Y) = E(f(X))$ for any function $f$?","If $X$ is independent of $Y$, is it true that $E(f(X)|Y) = E(f(X))$ for any function $f$? I cannot think of a specific example but am not able to prove it either. The best I have been able to do so far is to recognize that it suffices to show that $f(X)$ is independent of $Y$. From a measure theoretic standpoint, since $X$ and $Y$ are independent, $P(X \in A, Y \in B)= P(X \in A) P(Y \in B)$ for Borel sets $A,B$. Then, I have that $P(f(X) \in C, Y \in B) = P(X \in f^{-1}(C), Y \in B)$, but don't know what to do from here. Thanks.","['probability-theory', 'conditional-expectation']"
1485242,Cycle index of a symmetric group defined by recurrence relation,"It is claimed in a text I am reading that the cycle index of the symmetric group satisfies the recurrence relation $$Z(S_n)=n^{-1} \sum_{k=1}^n{s_kZ(S_{n-k})}$$ This is presented without explanation, much less proof. The standard presentation in terms of the partitions of n is presented earlier and makes sense to me, but this isn't as clear.","['group-theory', 'combinatorics', 'permutations']"
1485257,Example of Saddle-Point method,"I am trying to solve using the saddle point method (large a>0):
$$I(\alpha)= \int_{-i\pi/2}^{\pi/2}dz\, (1+z^2)e^{-a\cos(z)}$$
So I find that the point I want to expand about is z=0, because $\partial_z\cos(z)=0\implies z=0,n\pi$  So at $z_0=0$, I get
$$I(\alpha)=1\int_{-\epsilon}^\epsilon e^{-a(1-z^2/2+...)}\approx e^{-a}\int_{-\infty}^\infty e^{az^2/2}\, dz\approx i\frac{\sqrt{2\pi}}{\sqrt{a}}e^{-a}$$ My question is if this is a valid approach.  Mostly, did I correctly choose to expand about z=0.  I get confused on which saddle point to select, because I can deform the integral in many ways. And then if I want $a<0$, would I approach it the same way?","['asymptotics', 'complex-analysis']"
1485280,Solve symmetric equations with 4 variables,"Is there a method to find or count the number of unique integer solutions $(n, H, L, W)$ to symmetric equations such as, $$x = 4n^2 + 2 + 4n(H + L + W) + 2HL + 2HW + 2LW$$ given $x$? All variables are positive integers. I don't even know where to begin. Isolating one variable gives an ugly equation. For each solution $(H, L, W)$ the quadratic equation (and thus Pell's equation) can be used to see if $n$ is an integer, but that still involves brute forcing every possibility.","['geometry', 'diophantine-equations']"
1485281,Very fascinating probability game about maximising greed?,"Two people play a mathematical game. Each person chooses a number between 1 and 100 inclusive, with both numbers revealed at the same time. The person who has a smaller number will keep their number value while the person who has a larger number will halve their number value. Disregard any draws. For example, if the two players play 50 and 70, the first player will retain 50 points while the second will only get 35. There are five turns in total and each person receives a score equal to the sum of their five values. What is the optimum winning strategy? Obviously playing 100 each turn is a bad strategy since if the other player plays 70 then they gain 20 points more than you. Similarly, playing 1 is also a bad move since you are guaranteed to receive less points than your opponent. If we assume that our opponent is a computer that picks numbers from 1 to 100 with equal probability, we can work out the expected value which will maximise our score relative to the computer's. (I have worked out this to be 60 something - I think) But, if this is true then the computer will realise that it is pointless to play anything less than 30 something so we can further assume the computer will not play such low numbers. This gives a different optimal number to play each time. Repeating this method will give different values of the 'best' number to play. I'm just wondering what this number is. Also, the 'five turns' thing is of course irrelevant, but with a human it is interesting to predict the other player's strategy and moves. So does there exist a number, which will maximise the total expected value? (We can assume our opponent has the same amount of knowledge as us)","['average', 'puzzle', 'recreational-mathematics', 'probability', 'game-theory']"
1485296,Operator $T \colon L^p \to L^p$ is a conditional expectation,"I'm trying to solve this problem: Let $(X,\mathcal{B},\mu)$ a probability space and $T \colon L^p(\mu) \to L^p(\mu)$ a continuous linear operator ($1 \leq p < \infty$ ) with the following properties: 1) $||T||=1$. 2) $T(1) = 1$. 3) $\forall g \in L^\infty(\mu), f \in L^p(\mu) \colon \, T(gT(f))=T(f)T(g)$. Then exists a sub $\sigma$-algebra $\mathcal{G} \subseteq \mathcal{B}$ such that $$ \forall f \in L^p(\mu) \colon \, T(f) = \mathbb{E}(f | \mathcal{G})$$ My attempt: We can define $$\mathcal{C}= \{g \in L^\infty \colon T(g) = g\}, \ \mathcal{G} = \sigma(\mathcal{C})$$ 
By the monotone class theorem is not to difficult to see that if $g \in L^\infty$ is $\mathcal{G}$-measurable then $T(g) = g$. Then I want to prove that for every $f \in L^\infty$ $T(f) = \mathbb{E}(f|\mathcal{G})$. $T(f) \in \mathcal{C}$ by property 2) then $T(f)$ is $\sigma(\mathcal{C})=\mathcal{G}$-measurable. Let $g \in L^\infty$ and $\mathcal{G}$-measurable. Then $$\int_X T(f)g d\mu = \int_X T(fg) d\mu =\cdots $$ I don't know how to procede from here. Any help will be appreciated.","['probability', 'measure-theory']"
1485325,"Find an equation of the sphere with center $(3,−2,1)$ and that goes through the point $(4,2,5)$","Find an equation of the sphere with center $(3,−2,1)$ and that goes through the point $(4,2,5)$ I did the following: $r^2=(x-h)^2+(y-k)^2+(z-l)^2$ Since that is the equation of a sphere I simply plugged in the center and the points supplied to get: $r^2=(4-3)^2+(2+2)^2+(5-1)^2 \Rightarrow r=\sqrt{33}$ This solution just provides the radius, so how do I represent this as an equation?","['geometry', 'calculus', 'multivariable-calculus']"
1485327,"Show that $f(x,y)$ is differentiable at $(0,0)$","Show that $f(x,y)$ defined by: $$f(x,y) = \begin{cases}\dfrac{x^2y^2}{\sqrt{x^2+y^2}}&\text{ if }(x,y)\not =(0,0)\\0 &\text{ if }(x,y)=(0,0)\end{cases}$$ is differentiable at $(x,y) = (0,0)$ I tried to solve this problem by applying the theorem that if partial derivatives are continuous then the function is differentiable. Therefore, I calculated partial derivated but not I am stuck in showing they are indeed continuous. Help me!","['partial-derivative', 'derivatives']"
1485372,How to show density of 2^a 3^b,"Sounds like a nice homework problem, but this actually came up in preparing a lecture for a Music class; I want to show that if you try to build a set of notes where you can go up and down octaves and perfect fifths from any note (that is, the set of notes is closed over multiplication and division by 2 & 3, essentially), you wind up with an infinite number of keys on your piano. Thinking about this, it seems ""obvious"" that this set--also describable as the rationals of the form $2^a 3^b$ where $a$ & $b$ can be positive or negative or zero--is dense in the reals. Proving it, though, is giving me fits. I feel like this should be easy. The best I've got is to think about multiplication & division by 3 as addition & subtraction in the log realm, and then to argue that if there was a neighborhood of a point that contained no other point in the set, then there would have to be a nonzero greatest common divisor of $\log2$ and $\log3$, but that no such thing can exist, because then it would be the case that $\exists$ (nonzero) $y,z . 2^y = 3^z$, which is impossible. Is there a simpler way to show this?",['measure-theory']
1485415,Connected components of a given subspace of $M_{n \times n}(\mathbb{R})$.,"This question is motivated by this question, which gave me quite a headache today. Context: I posted originally what I thought was a quick proof using the derivative of the given function. It was intended to be a straightforward answer using a well-known strategy of proving something is constant and equal to some other thing by proving its derivative is zero and you are in a connected set. But I came across an issue: I didn't realize that I was not in a connected set, as the domain of definition of my function had to take into account the inverses I was considering (see here ). I managed to go around this issue (although at the cost of simplicity), but one of my initial attempts to solve my blunder was to try to pinpoint the connected components of the set $\mathcal{D}$ I was considering. I wasn't able to solve this issue (trying to show it was path-connected got me troubled in a lot of possible cases for the matrices). Hence, this present question arose What are the connected components of the space $\mathcal{D}=\mathcal{A} \cap \mathcal{B}$, where $\mathcal{A}=\{A \mid \exists A^{-1}\}$ and $\mathcal{B}= \{B \mid \exists (I+B)^{-1}\}$?","['linear-algebra', 'general-topology', 'matrices']"
1485426,"Closed form for ${\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx$","Let $\operatorname{li}(x)$ denote the logarithmic integral :
$$\operatorname{li}(x)=\int_0^x\frac{dt}{\ln t}.$$
How can we prove the following conjectured closed form?
$${\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx\stackrel{\color{gray}?}=\left(\frac12-\frac{\operatorname{arctan}\left(\sqrt[4]2\right)+\operatorname{arcoth}\left(\sqrt[4]2\right)}{4\sqrt[4]2}\right)\cdot\Gamma\!\left(\frac14\right)$$ Related questions: [1] [2] .","['special-functions', 'closed-form', 'definite-integrals', 'logarithms', 'integration']"
1485459,"If $f(x) >0$ for all $x$, then $\lim_{x\to a} f(x) \ge 0$","I met a problem like this: Suppose $f(x) > 0$ for all $x$ , and also that $\lim_{x\to a} f(x)$ exists. a) Show that $\lim_{x\to a} f(x) \ge 0$. b) Give an example where $\lim_{x\to a} f(x) = 0$. I am not sure how to solve it.. in fact I have no idea.
Could anyone give me a hint？
Thanks!!!","['limits', 'real-analysis']"
1485482,"A limit about $a_1=1,a_{n+1}=a_n+[\sqrt{a_n}]$","Let the sequence $\{a_n\}$ satisfy $$a_1=1,a_{n+1}=a_n+[\sqrt{a_n}]\quad(n\geq1),$$ where $[x]$ is the integer part of $x$. Find the limit $$\lim\limits_{n\to\infty}\frac{a_n}{n^2}$$. Add: By the Stolz formula, we have 
\begin{align*}
&\mathop {\lim }\limits_{n \to \infty } \frac{{{a_n}}}{{{n^2}}} = \mathop {\lim }\limits_{n \to \infty } \frac{{{a_{n + 1}} - {a_n}}}{{2n + 1}} = \mathop {\lim }\limits_{n \to \infty } \frac{{\left[ {\sqrt {{a_n}} } \right]}}{{2n + 1}} = \frac{1}{2}\mathop {\lim }\limits_{n \to \infty } \left( {\left[ {\sqrt {{a_{n + 1}}} } \right] - \left[ {\sqrt {{a_n}} } \right]} \right)\\
 = &\frac{1}{2}\mathop {\lim }\limits_{n \to \infty } \left( {\left[ {\sqrt {{a_n} + \left[ {\sqrt {{a_n}} } \right]} } \right] - \left[ {\sqrt {{a_n}} } \right]} \right) = \frac{1}{2}\mathop {\lim }\limits_{x \to \infty } \left( {\left[ {\sqrt {x + \left[ x \right]} } \right] - \left[ {\sqrt x } \right]} \right).\end{align*}
But it seems no use!","['analysis', 'calculus', 'real-analysis', 'limits']"
1485506,Why there is no general equation to denote polygons?,"We have algebraic equations for conic sections, like circle, ellipses and parabolas, but why there is no such result for polygons like triangle or square or hexagon? Is it impossible to represent polygons as algebraic identities?",['geometry']
1485509,Show that two planes are parallel and find the distance between them,"Given planes $Ax + By + Cz - D = 0$ and $Ax + By + Cz - F = 0$ show that they are parallel and the distance between them is given by 
$$\frac{D-F}{\sqrt{A^2 + B^2 + C^2}}.$$ I am afraid I don't know how to start to prove this, previously when finding the distance between two planes I had used the orthogonal projection formula, which is similar to the one given, but not the same. I also don't know how to prove they are parallel without real numbers, because those variables could represent any plane (right?). Thanks in advance.",['geometry']
1485546,How many tickets should I buy to win a prize in lottery? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Each ticket in a lottery contain a single ""hidden"" number according to the following scheme: 55% of the tickets contain a 1, 35% contain a 2, and 10% contain a 3. A participant in the lottery wins a prize by obtaining all three numbers 1,2 and 3. Can you please help me to describe an experiment that could be used to determine how many tickets you would expect to buy to win a prize? Thank you!!","['probability', 'statistics']"
1485569,Understanding Carmichael Number,"A Carmichael number is a composite number $n$ which satisfies the modular arithmetic congruence relation
$$a^{n-1} \equiv 1 \pmod n$$ $\forall a \in \mathbb Z_n$ such that $\gcd(a, n) = 1$ Wiki says Carmichael numbers are important because they pass the Fermat primality test but are not actually prime. Since Carmichael numbers exist, this primality test cannot be relied upon to prove the primality of a number, although it can still be used to prove a number is composite. This makes tests based on Fermat's Little Theorem risky. Suppose we are using Fermat's Test to check the primality of the number n . Does the above paragraphs signifies that Cardinality of the Fermat's liar set $|L(n)|$ would be more in case of Carmichael numbers as compared to other composite numbers. As more number of random a's will be selected which will pass the Fermat's Test as compared to other composite numbers. Please explain.. Am I assuming something wrong.","['primality-test', 'cryptography', 'number-theory']"
1485580,Solution interval for $\dot x(t)=x(t)^2$?,"In my course notes, the professors introduces the example ODE: $$
\dot x(t)=x(t)^2
$$ The solution is: $$
x(t)=\frac{c}{1-tc}
$$ However, this is undefined (division by zero) for $t=1/c$. The professors says no solution is defined for $t\ge 1/c$ . While I agree that no solution exists for $t=1/c$, help me understand why we cannot also have the solution for $t>1/c$, where $x(t)$ by the above formula is perfectly well defined (no division by zero)?","['analysis', 'real-analysis', 'ordinary-differential-equations']"
1485592,Number of cubes from sphere,"Reference : 2nd question - 
 . From a spherical ball of 10cm radius, how many complete cubes of 5cm
  side can be extracted out, if sphere cannot be molten What I have tried. Volume of sphere = $\frac43 \pi 10^3$ volume of cube = $5^3$ So find how many $5^3$ can appear in $\frac43 \pi 10^3$. But I guess this is wrong and the statement sphere cannot be molten . makes this answer different. How this statement affect the answer. Please give pointers on what is the approach of solving this.",['geometry']
1485611,Why $B_3 \subset B_1 \cap B_2$ in the definition of a basis for a Topology in Munkres' Book?,"I'm learning Topology by Munkres' book and I am a bit confused about the definition he gives (in p.78) of a basis of a topology: Definition . If $X$ is a set, a basis for a topology on $X$ is a collection $\mathfrak{B}$ of subsets of $X$ (called basis elements ) such that For each $x \in X$ , there is at least one basis element $B$ containing $x$ . If $x$ belongs to the intersection of two basis element $B_1$ and $B_2$ , then there is a basis element $B_3$ containing $x$ such that $B_3 \subset B_1 \cap B_2$ . My question is: shouldn’t Munkres mean $B_3 \subseteq B_1 \cap B_2$ ? I mean, subset instead of proper subset? For instance, in Example 2 (Figure 4) below, isn’t the rectangle $B_3$ encountered, the very intersection of the rectangles $B_1$ and $B_2$ ? Any help would be highly appreciated.",['general-topology']
1485639,"Finding an example of ""A reparametrization of a closed curve need not be closed""$\text{}$","I look at the following exercise of the book ""Elementary Differential Geometry"" of Andrew Pressley: ""Give an example to show that a reparametrization of a closed curve need not be closed."" Any hints how we could do that? I don't have any idea how to find such an example.","['differential-geometry', 'curves']"
1485640,Lyapunov invariant set for affine systems,"Given a linear system $\dot{x}=Ax$ such that the real part of every eigenvalue of $A$ is less than $0$, Lyapunov's equation $A^T P + P A = -Q$ with $Q$ being any suitably sized positive definite matrix gives us an invariant ellipsoid $x^T P x \leq 1$, i.e. for any initial state $x_0$ such that $x_0^T P x_0 \leq 1$ we know that the states $x$ or rather $x(t)$ (making dependency to $t$ explicit) reachable from $x_0$ remain inside the invariant ellipsoid, i.e. $x(t)^T P x(t) \leq 1 ~\forall t \geq t_0$. How can this be generalized to affine systems $\dot{x}=Ax + b$ where the real part of every eigenvalue of $A$ is less than $0$? Clearly, transforming the affine system into a linear system by extending state vector by $b$ with $\dot{b}=0$ does not help since we will have eigenvalue(s) $0$ which violates our assumption.","['invariance', 'invariant-theory', 'control-theory', 'ordinary-differential-equations', 'derivatives']"
1485675,Second derivative of $\int_\mathbb{R}\cos(tx)dp(x)$,"Let $p$ be a probability on $\mathbb{R}$ and 
$$f(t):=\int_\mathbb{R}\cos(tx)dp(x).$$
I want to show that if $f''(0)$ exists then $$f''(0)=\lim_{t\to 0}2\frac{f(t)-1}{t^2} \: \:(\star).$$ By differentiation under the integral sign, I obtain
$$f''(t)=\int_\mathbb{R}-x^2\cos(tx)dp(x).$$
Now, it seems that I need a sort of ""integration by parts for probabilities"", but I don't know if something similar exists. So what's the fastest way to deduce $(\star)$?","['derivatives', 'probability', 'measure-theory', 'integration']"
