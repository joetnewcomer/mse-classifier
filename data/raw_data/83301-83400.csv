question_id,title,body,tags
1087547,tensor product of trivial line bundles,"In Hatcher's book on Vector Bundles , the tensor product of two vector bundles is defined through the gluing functions. But I need an example to understand it. So I think of the simplest case, the tensor product of two trivial line bundles. Let $V_1$ and $V_2$ be two copies of $\mathbb R\times \mathbb R$, and $B = \mathbb R$. Let $\pi_i: V_i \rightarrow B, (x,y) \mapsto x$ for $i=1,2$. Are the gluing functions all identity maps? What is the tensor product of $(V_1,\pi_1)$ and $(V_2,\pi_2)$ as $B$-bundles and why? I guess that up to isomorphism, the result line bundle is still the trivial one, but I think what I need is something concrete. Thanks.","['algebraic-geometry', 'algebraic-topology']"
1087565,Subsets of the rationals order isomorphic to transfinite ordinals,"Let $\langle\mathbb Q,\lt\rangle$ be the set of rational numbers with the usual $\lt$ ordering. Find subsets $A$ and $B$ of $\mathbb Q$ which, with the usual ordering, are order isomorphic to the following ordinal arthimetic expressions: (i) $\omega^2+\omega$ (ii) $2.\omega^3$ Idea: So I think I need to find order preserving bijections between the expressions and subsets of Q. I can see that $Z=\{\frac1n:n \in \mathbb N\}$ is order isomorphic to $\omega$, but I don't see how to deal with isomorphism to powers of $\omega$. I'm aware that a way of thinking of $\omega^2$ is as $\omega$ copies of $\omega$ Solution: (i) So I'm looking for $\omega$ many increasing sequences following on the idea in the comments. Let $F:[0,\infty) \rightarrow [0,1)$ be a linearly piecewise map such that $F:[0,1] \rightarrow [0,\frac 12)$ $F:[1,2] \rightarrow [\frac 12,\frac 23)$ and $F:[n,n+1] \rightarrow [{n \over n+1},{n+1 \over n+2})$ Now let $A^i$={$i- \frac 1n: n \in \mathbb N$} for $i \ge 1$ So each $A^i$ is an increasing sequence of order type $\omega$ Let $Z= \bigcup_{i \in \mathbb N}F""(A^i)$ Then Z has order tupe $ \omega^2$ where $F""(A^i)$ is the range of $F$ on $A^i$. So $A = Z \cup$ {$k:k \ge 1 \land k \in \mathbb N$} is order isomorphic to $\omega^{2}+\omega$ (ii) Let $C^l$ = {$k+l:k \in B,l \in$ {odds}}, then $\bigcup_{k \in {odds}}C^k$ has order type $\omega^3$ and $\bigcup_{k \in {odds}}C^k \cup \bigcup_{k \in {evens}}C^k$ is order isomorphic to $2.\omega^3$","['ordinals', 'elementary-set-theory', 'order-theory']"
1087586,"Inequality for $C^1$ function: $|f(x)|^2 \le \frac{1}{2}\tanh \frac{1}{2}\int_0^1 (|f(x)|^2+|f'(x)|^2)\,dx$","Prove for $f\in C^{1}[0,1]$ such that $f(0) = f(1) = 0$, the following inequality: $$|f(x)|^2 \le \left(\frac{1}{2}\tanh \frac{1}{2}\right)\left(\int_0^1 (|f(x)|^2+|f'(x)|^2)\,dx\right)$$ This is Problem $4.157$ from Problems in Mathematical Analysis .","['inequality', 'calculus', 'integration']"
1087591,Measure theory - lebesgue's density theorem and changing order of limit,"First of all I'll say that I did see many questions in this site that try to answer a similar question like mine, but I didn't find them usefull enough. As a part of a proof of mine I would like to claim: $$\lim_{r\rightarrow 0^+} \frac{m(\bigcup_{i\in\mathbb N}E_i\bigcap(x-r,x+r))}{2r}\leq \sum_{i\in\mathbb N}\lim_{r\rightarrow 0^+}\frac{m(E_i\bigcap(x-r,x+r))}{2r}$$ ($x\in\mathbb R$, $m$ is lebesgue measure, $r>0$, $E_i\subset \mathbb R$).
Assume That each RHS limit exists.","['measure-theory', 'lebesgue-measure', 'real-analysis', 'limits']"
1087593,density on smooth boundary in several variables complex analysis,"Assume bounded domain (open and connected) $\Omega\subset \mathbb{C}^n$, and a smooth function $\rho:\mathbb{C}^n\longrightarrow \mathbb{R}$ such that $\rho(x) = 0$ for all $x\in \partial \Omega$, $\rho (x) < 0$ for all $x\in \Omega$ and $\rho(x) > 0$ for all $x\in \mathbb{C}^n\backslash \overline{\Omega}$. And $\nabla \rho \neq 0$ on $\partial \Omega$. We say $\partial \Omega$ is smooth.
Now let $z\in \partial \Omega$, we denote by $\tau(z)$ the expression
$$ \tau(z) = \lim_{\varepsilon \longrightarrow  0^+}  \frac{vol(S(z,\varepsilon)\cap \Omega)}{vol(S(z,\varepsilon))}$$
where $S(z,\varepsilon) = \{x\in \mathbb{C}^n: |x - z| = \varepsilon\}$ -- the boundary of ball $B(z,\varepsilon)$ in $\mathbb{C}^n$ as usual. And $vol$ denote the usual measure on $\partial \Omega$. Show that when $\rho$ is smooth as above, we always have $\tau(z) = \frac{1}{2}$ for all $z\in \partial \Omega$. Furthermore, if $\partial \Omega$ is piece-wise smooth, then $\tau(z)$ is defined on 
$\partial \Omega$ and not zero. I read this result in the book "" The Bochner--Martinelli Intergral and It's application "" but I don't understand why this fact is trivial - as the author said.","['several-complex-variables', 'complex-analysis']"
1087601,Can a function be continuous but not Hölder on a compact set?,"Is it possible to construct a function $f: K \to \mathbb{R}$, where $K \subset \mathbb{R}$ is compact, such that  $f$ is continuous but not Hölder continuous of any order?  It seems like there should be such a function--it would probably oscillate wildly, like the Weierstrass-Mandlebrot function.  However, the W-M function itself doesn't work, since it is Hölder. Edit: I guess I did have in mind for the function to not be Hölder anywhere, even though I didn't explicitly say so.","['calculus', 'continuity', 'real-analysis', 'uniform-continuity']"
1087616,New Year Maths 2015,"In the spirit of the festive period and in appreciation of the encouraging response to my Xmas Combinatorics 2014 problem posted recently, here's one for the New Year! Express the following as a product of four binomial coefficients:
  $$\color{red}{\sum_{r=1}^{M-1}r}\color{orange}{\sqrt{\int_0^X 2x dx}}
\color{green}{\left(\prod_{i=1}^{120}(V!-i+1) \right)}
\color{indigo}{\left(\prod_{h=1}^Mh\right)}
\left[\color{maroon}{\left(\prod_{n=1}^{120}n\right)}\color{blue}{\left(\prod_{y=1}^M y\right)}\right]^{-1} $$","['products', 'summation', 'recreational-mathematics', 'binomial-coefficients', 'combinatorics']"
1087623,Is function $f:\mathbb C-\{0\}\rightarrow\mathbb C$ prescribed by $z\rightarrow \large \frac{1}{z}$ by definition discontinuous at $0$?,"Is function $f:\mathbb C-\{0\}\rightarrow\mathbb C$ prescribed by  $z\rightarrow \large{\frac{1}{z}}$ by definition discontinuous at $0$? Personally I would say: ""no"". In my view a function can only be (dis)continuous at $z$ if $z$ belongs to its domain. But I have heard other sounds, that made me curious. This question was inspired by comments/answers on this question.","['soft-question', 'functions', 'definition']"
1087631,If Banach space is algebraic sum of its two linear subspaces with mutually separated unit spheres then these subspaces are closed.,"Let $X$ be a Banach space, $Y$ and $Z$ be its linear subspaces such that $X = Y+Z$, $\ Y\cap Z = \{0\}$ and the unit spheres in $Y$ and $Z$ are separated, i.e. $$
\exists r>0 \ \ \lVert y-z\rVert \geq r \quad \forall y\in Y \ \ \forall z\in Z \ \text{ s.t. } \lVert y\rVert = \lVert z\rVert = 1
$$ The problem is to prove that $Y$ and $Z$ is closed in $X$. My idea was to estimate norms of $y\in Y$ and $z\in Z$ with norm of their sum, because by Banach's isomorphism theorem it is enough to show that
$$
\exists C>0 \ \ \ \lVert y\rVert + \lVert z\rVert \leq C\lVert y+z\rVert \quad \forall y\in Y \ \forall z\in Z
$$
what implies $X \cong Y\oplus Z$. Could anybody help me?","['functional-analysis', 'banach-spaces']"
1087669,Does $\sum_{n\ge0} \sin (\pi \sqrt{n^2+n+1}) $ converge/diverge?,"How would you prove convergence/divergence of the following series? $$\sum_{n\ge0} \sin (\pi \sqrt{n^2+n+1}) $$ I'm interested in more ways of proving convergence/divergence for this series. My thoughts Let
$$u_{n}= \sin (\pi \sqrt{n^2+n+1})$$
trying to bound $$|u_n|\leq |\sin(\pi(n+1) )| $$ since $n^2+n+1\leq n^2+2n+1$ and $\sin$ is decreasing in $(0,\dfrac{\pi}{2} )$ $$\sum_{n\ge0}|u_n|\leq \sum_{n\ge0}|\sin(\pi(n+1) )|$$
or $|\sin(\pi(n+1) )|=0\quad  \forall n\in \mathbb{N}$ then $\sum_{n\ge0}|\sin(\pi(n+1) )|=0$
thus $\sum_{n\ge0} u_n$ is converge absolutely then is converget any help would be appreciated","['sequences-and-series', 'calculus', 'convergence-divergence', 'trigonometry', 'real-analysis']"
1087674,Why do we have two definitions of Cartier divisor?,"Why do we have several definitions of Cartier divisor? For example, I found in two books the following definitions: Let $X$ be a scheme. We denote the group $H^0(X,\mathcal K_X^*/\mathcal O_X^*)$ by $\operatorname{Div}(X)$. The elements of $\operatorname{Div}(X)$ are called as Cartier divisors on $X$. and Let $X$ be a scheme. An invertible sheaf on $X$ is an $\mathcal{O}_X$-module that is isomorphic to $\mathcal O_X$ locally on $X$. A closed subscheme $D$ of $X$ is called a Cartier divisor if its defining ideal sheaf $\mathcal I_D$ is an invertible sheaf on $X$. How can one prove that the definitions are equivalent?",['algebraic-geometry']
1087678,Let $a_n=2\sqrt n-\sum_{k=1}^n\frac{1}{\sqrt{k}}$. Show $a_n$ converges and $1<\lim_{n\to\infty}a_n<2$.,"I am able to show that $\lim_{n\to\infty}a_n\le 2$, but I can't think of a way to show strict inequality. Here's my work so far: By Riemann sums, $$\int_1^{n+1}\frac{1}{\sqrt x}\,dx<\sum_{k=1}^n\frac{1}{\sqrt k}<\int_0^n\frac{1}{\sqrt x}\,dx.$$ $$2\sqrt{n+1}-2<\sum_{k=1}^n\frac{1}{\sqrt k}<2\sqrt n$$ So, $$0<2\sqrt n-\sum_{k=1}^n\frac{1}{\sqrt k}<2\sqrt n+2-2\sqrt{n+1},$$ which implies, $$0<2\sqrt n-\sum_{k=1}^n\frac{1}{\sqrt k}<2\quad\forall\,n\ge1.$$ $$\begin{align}
a_{n+1}-a_n & =\left(2\sqrt{n+1}-\sum_{k=1}^{n+1}\frac{1}{\sqrt k}\right)-\left(2\sqrt n-\sum_{k=1}^n\frac{1}{\sqrt k}\right)\\
& =2(\sqrt{n+1}-\sqrt n)-\frac{1}{\sqrt{n+1}}\\
&=\frac{2}{\sqrt{n+1}+\sqrt n}-\frac{1}{\sqrt{n+1}}\\
&=\frac{\sqrt{n+1}-\sqrt n}{\sqrt{n+1}(\sqrt{n+1}+\sqrt n)}>0.
\end{align}$$ Since, $a_1=1$, $\{a_n\}$ is a monotonically increasing sequence, 
and $$1<a_n<2,\quad\forall\,n\ge1.$$ So, $\{a_n\}$ converges, and $$1<\lim_{n\to\infty}a_n\le2.$$","['sequences-and-series', 'real-analysis']"
1087683,"Green Theorem in 3 dimensions, calculating the volume with a vector integral identity","Let $E$ be a region in $\mathbb{R}^2$ with a smooth and non self-intersecting boundary $\partial E$ oriented in the counterclockwise direction, then from green theorem, we know that $$Area(E)=\frac{1}{2}\int_{\partial E} x\ dy-y\ dx$$
What is the analogue for Green theorem for volume of $E$ in 3 dimension? Also, a proof will be  nice?","['multivariable-calculus', 'vector-analysis', 'real-analysis']"
1087698,"Limit of the Derivative of an Increasing, Bounded-Above Function","Let $f:(0,\infty) \to \mathbb{R}$ be a differentiable function, which is increasing and bounded above.  Then does $\lim_{x \to \infty} f'(x)=0$? If we assume that $\lim_{x \to \infty} f'(x)$ exists, then this is true by an argument using the mean value theorem: By assumption $L=\lim_{x \to \infty} f(x)$ exists and is finite, and then $0=L-L=\lim_{n \to \infty} f(n+1)-f(n)=\lim_{n \to \infty} f'(x_n)$ for some $x_n \in (n,n+1)$ by the mean value theorem.  But this doesn't work if we don't assume $\lim_{x \to \infty} f'(x)$ exists because $x_n$ isn't an arbitrary sequence with $x_n \to \infty$. Intuitively it seems that it should be true without this assumption, but of course that doesn't mean that it's true.",['real-analysis']
1087702,Is $T(X)$ a Banach space?,"Let $X$ be a Banach space and $Y$ be a normed space and $T \colon X\to Y$ be a linear transformation. Then is $T(X)$ a Banach space? How do I prove this? I'm asking this since I saw a post saying this is true some hours ago (I don't remember the reference though, maybe it was on some forum and I believe the statement is false). EDIT: Let $T:V\to W$ is a bounded bijective operator where $V$ is a Banach space and $W$ is a normed space. Then, is $T(V)$ a Banach space?","['linear-algebra', 'functional-analysis', 'banach-spaces']"
1087712,"Questions about continuity in the function $f(x+y)= f(x)+f(y)$ for each $x,y \in \Bbb{R}$.","$f: \Bbb{R}\rightarrow\Bbb{R}$ is continuous in zero, s.t $f(x+y)= f(x)+f(y)$ for each $x,y \in \Bbb{R}$. A. calculate $f(0)$ and prove that $f(-x)=-f(x)$ B. prove that $f$ is continuous in $\Bbb{R}$ for A, I reached that the limit when $x$ goes to zero must be equal to the value $f(0)$, by the definition of continuity, which means that $x+y$ must go to zero, and that way x can go to $-y$ which is the same thing, then I put $-y$ in the function and see what value I get, at the end i got: $\lim \limits_{x \to -y}$$f(x+y) = f(-y)+f(y)$. and I know from the information I have about the function $f(x+y)= f(x)+f(y)$ that $f(y)+f(-y) = f(0)$, but didn't know how to continue from here. and I don't have any direction for B. any kind of help would be appreciated.","['calculus', 'functions']"
1087713,Clarification of an example.,"I am currently learning about measure theory and I am a bit behind. I came across an example over the holiday and I didn't understand one of the equalities. It's probably just because I'm a bit behind on some of the stuff and have a memory like an 2 year old, so I hope someone can help me. So let $X$ be a stochastic variable on $(\Omega,\mathbb{F},P)$ with values in $(X,\mathbb{E})$. Now equip $(X,\mathbb{E})$ with the basic measure $\mu$, and assume that the distribution of $X$ has density $f$ with respect to $\mu$. Furthermore let $t:(X,\mathbb{E})\rightarrow (\mathbb{R},\mathbb{B})$ be a measurable map, and consider the real-valued stochastic variable $t(X)$. If we try to calculate the expectation to $|t(X)|$ we see that: $$E|t(X)|=\int|t(X)|\:\mathrm{d}P=\int|t|\:\mathrm{d}X(P)=\int|t|f\:\mathrm{d}\mu$$ Now... the first equality is just the definition of expectation. The second equality is due to the abstract change-of-variable formula: ( http://mathworld.wolfram.com/ChangeofVariablesTheorem.html ) And the last one is the one puzzling me. Now.. I understand that since the distribution of $X$ has density $f$ with respect to $\mu$, we know that: $$X(P)(A)=\int_A f\:\mathrm{d}\mu$$ But I'm not sure if that is even used. Thanks for any help.","['probability-theory', 'measure-theory']"
1087733,Plotting a function (by hand) if the second derivative is hard to find,"In plotting graphics we use the first derivative to find critical points and in which intervals the function grows and becomes smaller. We can insert the critical points in the second derivative to see if it is convex or concave at these points. But sometimes the second derivative is really hard to find. It is important because it gives us additional information, like inflex points, which help us make our graph more precise. Is there any approach if the second derivative is hard to find?","['graphing-functions', 'calculus', 'derivatives']"
1087737,"Let $G$ to be abelian group and $|G|=mn$ when $(m,n)=1$. $G_m=\{g\mid g^m=e\}$,$G_n=\{g\mid g^n=e\}$, prove isomorphism","I want to prove   $ f:G_n\times G_m\rightarrow G$ when $f(g,h)=gh $ is an isomorphism . First of all I showed that $G_m,G_n$ are subgroups of $G$ (easy). Now I want to show that for every  $  a,b, \in G$, $f(ab)=f(a)f(b) $. Let  $a=(g_1,h_1)$ and $b=(g_2,h_2)$ $\implies f(g_1,h_1)=g_1h_1$ , $f(g_2,h_2)=g_2h_2$ $\therefore f(g_1,h_1) f(g_2,h_2)=g_1h_1g_2h_2=g_1g_2h_1h_2$ (because G is abelian) $=f\bigl((g_1g_2),(h_1h_2)\bigr)$ Then, I need to show that only $f(e)=e$. Because $(m,n)=1$, only $f(e,e) = e e = e$. Am I right? If not how can I prove this? Is $f$ an isomorphism even if $G$ is not abelian?","['group-isomorphism', 'group-theory', 'abstract-algebra', 'abelian-groups']"
1087770,Dirac delta function as a limit of sinc function,"I'm looking for a rigorous proof of the statement:
$\delta(x) = \lim_{\epsilon->0} \frac{\sin(x/\epsilon)}{\pi x}$
(see (37) ). For any non-zero value of x, LHS of the above is by definition zero. But, for any non-zero value of x, the limit in RHS simply does not exist. So, how is this statement proved?","['dirac-delta', 'distribution-theory', 'limits']"
1087774,Proving $ C = D $ from $ A \triangle C = A \triangle D$ [duplicate],This question already has answers here : $A \oplus B = A \oplus C$ imply $B = C$? (5 answers) Closed 9 years ago . I have been working on one part of the proof where my aim is to show that $C =  D$. I have been able to prove that $ A \triangle C = A \triangle D$. Is it reasonable to conclude $ C = D $ from $ A \triangle C = A \triangle D$ ?,"['logic', 'elementary-set-theory']"
1087798,Integrating certain functions over the unit sphere $\mathbb{S}^2$,"Let $ \mathbb{S}^2$ the unit sphere, and $  \vec a$, $  \vec b$ two constant vectors. I have to prove that: 
 $$  \iint\limits_{\mathbb{S}^2}  \langle \vec x , \vec a \rangle \langle \vec x , \vec b \rangle \, d \sigma= \frac43 π \langle \vec a , \vec b \rangle $$ and by using this to prove that: $$  \iint\limits_{\mathbb{S}^2}  \langle A\vec x , \vec x \rangle \, d \sigma = \frac{4}{3}  π  \operatorname{tr}(A) $$ where $A$ is a matrix with order $3 \times 3$.
Can anyone give me an idea about the solution?","['surface-integrals', 'multivariable-calculus', 'vector-analysis']"
1087805,Solve $\sin \frac{\alpha - \beta}2 + \sin \frac{\alpha - \gamma}2 + \sin \frac{3\alpha}2 =\frac 3 2$,"Solve the following trigonometric eqation where $\alpha, \beta, \gamma$ are angles in a triangle ($\alpha + \beta + \gamma = 180$): $$\sin \frac{\alpha - \beta}2 + \sin \frac{\alpha - \gamma}2 + \sin \frac{3\alpha}2 =\frac 3 2$$ Transforming it into $2 \sin \frac{3\alpha-180}4 \cos \frac{\beta - \gamma}4 + \sin \frac{3\alpha}2 =\frac{3}2$ 
and
$\cos \frac{\beta - \gamma}4 =\cos \frac{180- \alpha}4 + 2 \sin \frac{\beta}4 \sin \frac{\gamma}4$ is as far as I came.","['trigonometry', 'functional-equations']"
1087814,Let $C$ be the curve of intersection of the plane $x+y-z=0$ with ellipsoid $\frac{x^2}4+\frac{y^2}5+\frac{z^2}{25}=1$.,"Let $C$ be the curve of intersection of the plane $x+y-z=0$ and the ellipsoid $$\frac{x^2}4+\frac{y^2}5+\frac{z^2}{25}=1$$ Find the points on $C$ which are farthest and nearest from the origin When dealing with constraints I tried to consider the function $$F(x,y,z)=x^2+y^2+z^2-\lambda(x+y-z)-\mu\left(\frac{x^2}4+\frac{y^2}5+\frac{z^2}{25}-1\right)$$ However, I cannot solve this equation after differentiating respect to $x,y,z$ because it yields three equations with no common solution. The system of equations are $$2x=\lambda+\frac{\mu x}{2}$$ $$2y=\lambda+\frac{2\mu y}{5}$$ $$2z=-\lambda+\frac{2\mu z}{25}$$ How would I approach this problem, thanks.","['multivariable-calculus', 'real-analysis', 'lagrange-multiplier']"
1087837,Approximating a piecewise continuous function with a function in $\mathcal{C}^{\infty}_{0}(\mathbb{R})$,"Let $\eta \in \mathcal{C}^{\infty}_{0}(\mathbb{R})$, where $\mathcal{C}^{\infty}_{0}(\mathbb{R})$ is the set of compactly supported infinitely differentiable function, be a function which is non-negative, non-vanishing and constant in a neighborhood of $x=0$, symmetric about $x=0$, supported in $[-1,1]$, bounded between $0$ and $\eta(0)$, and normalized so that $\int \eta d\mu =1$. Let $\varphi$ be a compactly supported absolutely continuous function with a piecewise continuous derivative $\varphi'$. I have been told (by a user of MSE whom I thank very much again) the following, which I think to be interesting enough to be the object of a specifical question: Then one defines$$\eta_{n}(x) = n\eta(x/n)$$so that
  $\int_{\mathbb{R}}\eta_{n}\,d\mu =1$ for all $n$. For any compactly
  supported absolutely continuous function $\varphi$,
  define$$\varphi_{n}=\int_{\mathbb{R}}\eta_{n}(x-y)\varphi(y)\,d\mu(y).$$The function
  $\varphi_{n}$ is in $\mathcal{C}^{\infty}_{0}(\mathbb{R})$. Because
  $\eta_{n}$ is supported in $[-1/n,1/n]$, and $\varphi$ is continuous,
  then $\varphi_{n}$ converges uniformly to $\varphi$ as
  $n\rightarrow\infty$. And, because $\varphi$ is absolutely continuous,
  then$$\varphi_{n}'=\int_{\mathbb{R}}\eta_{n}'(x-y)\varphi(y)\,d\mu(y)=-\int_{\mathbb{R}}\eta_{n}(x-y)\varphi'(y)\,d\mu(y).$$
  For my case $\varphi'$ is piecewise continuous, and the right
  side then converges pointwise everywhere to mean of the left- and
  right-hand limits of $\varphi'$, and it remains uniformly bounded by
  any bound for $\varphi'$. I must say that I have no knowledge of the theory of mollification until now. I would like to understand why the fact that $\eta_{n}$ is supported in $[-1/n,1/n]$, and $\varphi$ is continuous, implies that $\varphi_{n}$ converges uniformly to $\varphi$ as $n\rightarrow\infty$; the absolute continuity of $\varphi$ implies $\varphi_{n}'=\int_{\mathbb{R}}\eta_{n}'(x-y)\varphi(y)\,d\mu(y)=-\int_{\mathbb{R}}\eta_{n}(x-y)\varphi'(y)\,d\mu(y)$; the piecewise continuity of $\varphi'$ implies the facts that $-\int_{\mathbb{R}}\eta_{n}(x-y)\varphi'(y)\,d\mu(y)$ converges to $(\lim_{t\to x^+}\varphi'(t)+\lim_{t\to x^-}\varphi'(t))/2$ and $|\int_{\mathbb{R}}\eta_{n}(x-y)\varphi'(y)\,d\mu(y)|\le |\varphi'(x)|$. I heartily thank both who told me these interesting facts and whoever will help me to understand the reason of the quoted facts.","['functional-analysis', 'integration', 'real-analysis']"
1087841,"Existence of $x$ such that $2^x =a,3^x=b,5^x=c$ for some integers $a,b,c$","Conjecture: There does not exist a non-integer $x$ such that $$2^x=a$$ $$3^x=b$$ $$5^x=c$$ where $a,b,c$ are all integers. I'm aware that the similar question There does not exist a non-integer $y$ such that $$2^y=A$$ $$3^y=B$$ where $A,B$ are all integers. is a famous unsolved problem. (evidence in the corrolaries here or here ) My idea was that the addition of the condition $5^x$ made the problem easier and therefore solvable.","['exponentiation', 'transcendence-theory', 'number-theory']"
1087844,(Geometric algebra) Acceleration of a particle with constant speed as a bivector-vector inner product,"I've been working on (self-studying) Geometric Algebra for Physicists which, sadly, has no solutions manual. This is not a problem in general, but I feel like one of my solutions for a question asked in the textbook is incomplete. The question is: A particle in three dimensions moves along a curve $x(t)$ such that $|v|$ is constant. Show that there exists a bivector $Ω$ such that
  $$
\dot v = Ω\cdot v
$$
  and give an explicit formula for $Ω$. Is this bivector unique? My solution: Since we're in three dimensions, we can construct a vector $\dot v$ with the following property:
  $$
v^2=v_0^2 \implies \dot v v+v \dot v = 0 \implies v\cdot \dot v = 0
$$
  (This is obvious from elementary multivariable calculus) As $\dot v$ must always be perpendicular to $v$, we can always come up with such a vector by forming a plane with it and some arbitrary vector and then take this resulting bivector's dual. That is,
  $$
\dot v = I(v\wedge b)
$$
  Where $I=e_1e_2e_3$ is the unit pseudoscalar. We can re-write this in the following form:
  $$
I(v\wedge b) = v\cdot (Ib)=-(Ib)\cdot v
$$If we allow $b$ to absorb the constant, then we can claim:
  $$
\Omega = Ib(t)
$$
  Where $b(t)$ is any vector-valued function of $t$. Clearly, then, the bivector is not unique. Is this all? It seems like the question implies there should be a more restrictive condition on $\Omega$, but I haven't been able to find any (and, intuitively, it doesn't seem like it could be made more restrictive). Thank you.","['multivariable-calculus', 'calculus', 'self-learning', 'geometric-algebras', 'clifford-algebras']"
1087849,Matrix equation $aX^{3} + bX^{2} = I$.,"I want to solve the matrix equation for $X$ $$aX^{3} + bX^{2} = I,$$ where $a,b \in \mathbb{R}$ and $X \in \mathbb{R}^{n\times n}$. My thoughts: If $a = 0$ or $b = 0$, the solution is easy. If $a, b \neq 0$ I have tried to find matrices $U$ and $V$ such that $X^3 =UD_3V$ and  $X^2 =UD_2V$, where $D_2$ and $D_3$ are diagonal matrices, but I did not have success until now. Maybe this is not possible. Do you have any idea? Thanks in advance!","['matrix-equations', 'matrices']"
1087867,Convex function property,"Let $ f_{1}, f_{2},..., f_{n} $ convex functions in the interval $[0,1]$ such that $ max(f_{1},f_{2},...,f_{n}) \geq 0 $ show that there exist positive real numbers $a_{1}, a_{2},...,a_{n} $ not all equal to 0 such that $ a_1 \times f_1 + a_2 \times f_2 + ... + \ a_n \times f_n \geq 0 $ This problem seems to be not easy, I tried many ways but no results
please help","['convex-analysis', 'inequality', 'calculus', 'functions', 'functional-analysis']"
1087868,"Hodge star operator and volume form, basic properties","let $(M,g)$ be an oriented Riemannian manifold. Let $*$ be the hodge operator,
I want to prove that $$*\mathrm{vol}_g =1$$ where $\mathrm{vol}_g$ is the associate volume form $\sqrt{g} e^1\wedge \cdots \wedge e^n$ In these notes it's given as a fact, but when I started to prove it, I got confused by the underlying scalar product and how the pairing works, hence can someone show me some hints on how to prove that? I don't want a full solution, only a clarification. In fact using the definition of hodge star I think that it's enough to prove that $g(\mathrm{vol}_g,\mathrm{vol}_g)=1$ but I don't know how to prove it. Given this, then is it true that, for a given top-form ($n$-dim differential form), $w=(*w)\mathrm{vol}_g$? Because I'd argue in this way: $w=\tilde{w}(x)\mathrm{vol}_g$ because we are working in a one dimensional vector space, then $*w={*\tilde{w}}(x)\mathrm{vol}_g=\tilde{w}(x)\,{*\mathrm{vol}}_g=\tilde{w}(x)$. Is it correct? ADDENDUM In this setting, given $\eta \in \Omega^p(M)$, we define $*\eta$ as the unique element such that, for every $w \in \Omega^{p}(M)$ we have $$ w \wedge *\eta = (\bigwedge^p g)(w,\eta) \mathrm{vol}_g$$","['global-analysis', 'differential-geometry']"
1087878,Find the general solution for the differential equation $(D^2+4D+4)y=5xe^{-2x}$,"Find the general solution for the differential equation $(D^2+4D+4)y=5xe^{-2x}$ Attempt: $y_c(x)=c_1e^{-2x}+c_2xe^{-2x}$ and  $y_p(x)=Ax^2e^{-2x}$. Moreover $y'_p(x)=2Axe^{-2x}-2Ax^2e^{-2x}$ and $y_p''(x)=2Ae^{-2x}-8Axe^{-2x}+4Ax^2e^{-2x}$
So $A=5x/2$. So the general solution is $y(x)=c_1e^{-2x}+c_2xe^{-2x}+(5/2)x^3e^{-2x}$. 
But the answer says that the genral solution is $y(x)=c_1e^{-2x}+c_2xe^{-2x}+(5/6)x^3e^{-2x}$. I am very new in differential equations. Did I mistake somewhere?Thanks!",['ordinary-differential-equations']
1087905,Automorphism group of a tournament is solvable,"$(a)$ Let $X$ be a tournament, i.e. $X$ is a directed complete graph. Denote $V(X)$ the vertex set of $X$ . An automorphism of $X$ is a bijection $V(X) \to V(X)$ preserving orientation. Prove that the automorphism group $\text{Aut}(X)$ is solvable. $(b)$ Prove, in fact, that the following statements are equivalent: Every group of odd order is solvable. $\iff$ $\text{Aut}(X)$ is solvable for every tournament $X$ . I am having trouble getting started, in particular how could I compute the automorphism group of a given tournament? This seems very hard if the number of vertices is large.","['graph-theory', 'group-theory']"
1087908,Can't find adequate change of variables $y=u^{\alpha}x^{\beta}$ for this equation.,"I'm studying for a test on ODEs by running through a bunch of exercises, and this one has me stuck. I'd like to find the general solution to $$xy^{\prime} = \sqrt{y^2+x^6}$$ The hint they give me is to use a substitution $y = u^{\alpha}x^{\beta}$. The first thing I did was (and in this removing $0$ from the domain of $y(x)$, at least for the time being) divide out to get $$y^{\prime} = \sqrt{\frac{y^2+x^6}{x^2}}$$
After some playing around I figured that, for the substitution to be useful, it should change the equation into a separable one, which could happen if, for instance, $y^2/x^2 = u^{2\alpha}x^{2\beta-2}$ were equal to $x^3u^{\gamma}$, so I could take a common factor of $x^{3/2}$, and the other factor would only have terms in $u$. So I tried $y = ux^{5/2}$. This got me to the expression $$u' = \frac{1}{x^{5/2}}\left(\sqrt{u^3 + x^3}-5x^{3/2}u\right) \Rightarrow \frac{u'}{\sqrt{u^2+1} - 5u} = \frac1x$$
Which in theory can be integrated quite easily. However the LHS is clearly not a simple integral (for humans; a CAS solves it in no time). It can be done with some hyperbolic trig. substitutions, but on the whole it becomes quite ugly. What's more, I'd end up having [complicated expression in u] = $\ln x + k$, and that won't help me find $u$ explicitly, let alone $y$. Then I tried doing the same without a determined value for $\alpha$, to see if a certain value would make the LHS have an easy primitive. This is to say, I let $y=u^{\alpha}x^{5/2}$ and I got: $$\frac{\alpha u'u^{\alpha-1}}{\sqrt{u^{2\alpha}+1} - 5u} = \frac1x$$ However I can't see which value of $\alpha$ will help here. A couple of things occur to me as ""the problem"": a) I'm not calculating right and things actually turn out much simpler. b) I'm too set on the idea of achieving a separable equation, when maybe I could get linear, Bernoulli, etc. c) I'm missing something extremely obvious and the only problem is in my head. Can someone help me solve this?",['ordinary-differential-equations']
1087910,A result of Erdős on increasing multiplicative functions,"Erdős proved that if $f(n)$ is a monotone increasing function from the natural numbers to the positive reals, and $f(n)$ is completely multiplicative, then there exists some constant $C$ such that $f(n)=n^C$ for all $n$. I have not been able to find a nice proof of this online and was hoping someone could provide a proof.","['reference-request', 'number-theory']"
1087934,Why is $\mathbb N$ a closed set?,"I know that we can prove that $\mathbb N$ is a closed set through the use of the compliment of $\mathbb N$. Since $\mathbb R$\ $\mathbb N$ is open, $\mathbb N$ must be closed. However, the question arises: If that is so, then $\mathbb N$ must contain its limit points. Then what are the limit points of $\mathbb N$ ? I believe they are every element of $\mathbb N$: 1,2,3,4,5,6,... are all limit points of $\mathbb N$. But remember the definition of a limit point: x is a limit point of $A$ if $\forall \epsilon \gt 0$, $V_{\epsilon}(x) \cap A =$ points that are different from $x$. Now take $\epsilon = 0.5$ Then we see that $V_{\epsilon =0,5}(1) \cap \mathbb N = {1}$. Hence, EVERY points in $\mathbb N$ is an isolated point, and there is no limit point: A contradiction. So, please point out what is wrong with my thoughts ? I thank you very much for your help. I am just an introductory real analysis learner, so please help me. I thank you.","['general-topology', 'calculus', 'real-analysis']"
1087943,"Real analysis ""theory book"" similar to Andreescu's Problems in Real Analysis: Advanced Calculus on the Real Axis","I am going through Andreescu et al. , Problems in Real Analysis: Advanced Calculus on the Real Axis and I am very impressed: the style of the book seems really modern and the material covered includes many theorems, examples, etc. that are rarely or not at all seen in other books (both theory books and problem books) and that are often taken from not well-known sources or from recent issues of math journals. I was wondering if there is a "" theory book "" that resembles the one I
  mentioned (and roughly covers the same material)?","['book-recommendation', 'calculus', 'reference-request', 'soft-question', 'real-analysis']"
1087948,Question 39 in Folland's Real Analysis chapter 3,"The question ""If {$F_j$} is a sequence of nonnegative increasing functions on $[a,b]$ such that $F(x)= \sum_1^\infty F_j(x) < \infty$"" for all $x \in [a,b]$, then $F\prime(x)=\sum_1^\infty F\prime_j(x)$ for a.e. $x \in [a,b]$. (It suffices to assume that $F_j \in NBV$. Consider the measures $\mu_{F_j}$.)"" By the theorem 3.23 page 101 in the same book it makes sense to assume that $F_j \in NBV$ for all $j$. I have very basic questions actually: first of all, how is derivative of F expressed? Are we allowed to write it down as:
$F\prime = lim_{r\rightarrow 0} \frac{\mu_F(E_r)}{m(E_r)}$ where $\mu_F$ is the Borel measure , $\mu((a,b])=F(b)-F(a)$, $m$ is the Lebesgue measure, and $E_r = (x,x+h]$. After that I consider writing $\mu_F$ in terms of $\mu_{F_j}$'s and obtain the equality, but it seems very wrong and there is not any use of the fact that $F_j$'s are nonnegative. So could anyone please give me some hints and clarifications? Thank you.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1087950,Calculating probability of getting $m$ unique numbers when choosing $n$ times from $0\ldots k$,"I'm trying to write a test to verify a reasonable distribution for a function that generates 4-digit pin numbers from 8 digit phone numbers.  I'm not aware of any direct method of calculating this, so my approach is to (1) generate $n$ pin numbers, (2) for each $i \in \{1,\ldots,n\}$ calculate the probability that there would be $i$ unique pin numbers among the generated, and (3) test that the actual number of unique pins in the $n$ generated fall within $\pm2$ stdev of the average of the probabilities calculated in step (2). I'm stuck on step 2. I know that the probability of choosing only 1 distinct number from $0..k$ in $n$ tries is $$\left(1 \over k \right)^{n-1}$$ and that the probability of choosing $n$ distinct numbers from $0..k$ in $n$ tries is $$\prod_{i=0}^n{1-\left(i \over k \right)}$$ How do I calculate the probability when the chosen numbers aren't all the same or all distinct?",['probability']
1087979,Calculating a contour integral,"I want to evaluate the integral $$\int_{\gamma} \sin{(2z)} \ {\rm d}z$$ where $\gamma$ is the line segment joining the point $i+1$ to the point $-i$. Thus $\gamma(t) = -i+t(2i+1)$ for $0\le t\le1$. So I want to calculate \begin{align}\int_{\gamma} \sin{(2z)} \ {\rm d}z
&=\int^{1}_{0} f(\gamma(t))\gamma'(t) \ {\rm d}t\\
&=\int_{0}^{1} \sin{[2(-i+t(1+2i))]}(1+2i) \ {\rm d}t \\ 
&=(1+2i)\int^{1}_{0} \sin{[2t+i(4t-2)]} \ {\rm d}t \\ 
&= (1+2i)\int^{1}_{0} \sin{(2t)}\cosh{(2-4t)}-i\cos{(2t)}\sinh{(2-4t)} \ {\rm d}t \\ 
&=(1+2i)\left[\int^{1}_{0}\sin{(2t)}\cosh{(2-4t)} \ {\rm d}t\, - i\int^{1}_{0}\cos{(2t)\sinh{(2-4t) \ {\rm d}t}}\right]\end{align} Now this seems extremely long winded, is there any other way to calculate this?","['complex-analysis', 'contour-integration']"
1087983,Rectifying Proof,"At the moment I read ""How to Prove It"" by Velleman. I reached & solved the same exercise as in this question: Finding flaw in proof . The exercise was formulated like this and the other asker had problems with finding the flaw (A could be empty). Incorrect Theorem. Suppose F and G are families of sets. If ∪F and ∪G
  are disjoint, then so are F and G. (a) What’s wrong with the following
  proof of the theorem? Proof. Suppose ∪F and ∪G are disjoint. Suppose F and G are not
  disjoint. Then we can choose some set A such that A ∈ F and A ∈ G.
  Since A ∈ F, by exercise 8, A ⊆ ∪F, so every element of A is in ∪F.
  Similarly, since A ∈ G, every element of A is in ∪G. But then every
  element of A is in both ∪F and ∪G, and this is impossible since ∪F and
  ∪G are disjoint. Thus, we have reached a contradiction, so F and G
      must be disjoint. Then I asked myself: Would the theorem hold if you added the premise that $\forall x( (x \in F \wedge x \in G) \implies (x \neq \emptyset)) $? I think yes, but I'm not sure yet. Also, could the premise be weakened?","['elementary-set-theory', 'proof-verification']"
1087986,"Proof of $\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)$","How can we prove that
$\DeclareMathOperator\Hom{Hom}\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)$ without using the fact that $\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \mathbb Z/d \mathbb Z$ and $\Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)\cong \mathbb Z/d \mathbb Z$, where $d=$ GCD$(m,n)$? It's not too hard to prove the two latest isomorphisms but it would be interesting to derive one from another using the first isomorphism.",['abstract-algebra']
1087999,A riddle for 2015,"How can one get $2015$ using $1,2,\dots,9$ in this order and only once, with the operations $+,-,\times,/$ ? Solving this riddle with a computer (using python) turned out to be impossible for me due to the amount of memory needed. Hence, I am looking for a mathematical way to find the/a solution (I am not just looking for the solution, but also for a technique to solve that kind of problems).","['algebra-precalculus', 'recreational-mathematics']"
1088018,Name for Theorem 3.27 from baby Rudin?,"Rudin rarely gives names to the theorems in this book.  Theorem 3.27 states if
$\{a_n\}$ is a monotonically decreasing sequence of  positive reals, then $$\sum_{n=1}^\infty a_n\,\text{ converges}\iff\sum_{k=0}^\infty 2^ka_{2^k} \text{ converges}.$$","['terminology', 'real-analysis']"
1088031,Complex structure on the Jacobian of a Riemann surface,"Let $X$ be a fixed smooth, connected, compact Riemann surface of genus $g$.  The Jacobian variety $\mbox{Jac}(X)$, which parametrises isomorphism classes of holomorphic degree $0$ line bundles on $X$, is the quotient $H^1(X;\mathcal O)/H^1(X;\mathbb Z)$ of cohomology groups, where $\mathcal O$ is the sheaf of holomorphic functions on $X$ and $\mathbb Z$ is the sheaf of locally-constant integer-valued functions on $X$.  This construction of the Jacobian as a $g$-dimensional complex torus comes from the cohomology of the exponential sequence, as explained in most standard references. The surface $X$ may admit more than one complex structure, if $g$ is positive.  Exactly how does the choice of complex structure on $X$ influence the complex structure on $\mbox{Jac}(X)$?  Can this be seen somehow in the quotient $H^1(X;\mathcal O)/H^1(X;\mathbb Z)$?  (Does the embedding of the lattice $H^1(X;\mathbb Z)\cong\mathbb Z^{2g}$ into $H^1(X;\mathcal O)\cong\mathbb C^g$ determine the complex structure on $\mbox{Jac}(X)$, and is this embedding determined by the complex structure on $X$?)","['riemann-surfaces', 'algebraic-geometry', 'holomorphic-bundles', 'complex-geometry']"
1088038,$G$ is characteristically simple $\iff$ there is simple $T$ such that $G \cong T\times T \times \cdots \times T$,"Let $G$ be a characteristically simple finite group, i.e. it has no nontrivial characteristic subgroups. Prove there is some simple group $T$ such that $G \cong T \times T \times \cdots \times T$. No idea how to start this one. I have tried to induct on the size of $G$ to no avail. Any help would be appreciated!","['characteristic-subgroups', 'finite-groups', 'group-theory', 'simple-groups']"
1088050,Is there a faster way to factor $X^{12}-1$ over $\mathbb{F}_5[X]$?,"Problem: Factor $X^{12}-1$ into irreducibles in $\mathbb{F}_5[X]$.  This problem appeared on a past qual and took me awhile to do.  While I solved it, I'll need to be able to do problems like this a lot faster to have a chance of passing.  At the very least, I was wondering whether there was a quick way to tell that $X^4-X^2+1$ is not irreducible in $\mathbb{F}_5[X]$. My solution: I first factored this polynomial over $\mathbb{Z}[X]$, as $$(X-1)(X+1)(X^2+X+1)(X^2+1)(X^2-X+1)(X^4-X^2+1)$$ via the formula $X^n-1 = \prod\limits_{d \mid n} \Phi_d(X)$, where $\Phi_d$ is the $d$th cyclotomic polynomial.  The first $5$ irreducibles can easily be checked to remain irreducible when going modulo $5$ (by checking if they have a root), so the hard part of the problem is checking whether the $12$th cyclotomic polynomial, $X^4-X^2+1$, remains irreducible in $\mathbb{F}_5[X]$. It's easy to see that $\Phi_{12}$ has no roots in $\mathbb{F}_5$, so it would have to be a product of two quadratics.  I supposed it did factor, as $$X^4-X^2+1 = (X^2 + aX+b)(X^2+cX+d)$$ I expanded the right hand side as $X^4 + (a+c)X^3 + (b+ac+d)X^2 + (bc+ad)X + bd$, so I had the relations (i): $a+c = 0$ (ii) $b+ac+d =-1$ (iii) $bc+ad=0$ (iv) $bd = 1$. I began by considering the case where $a \neq 0$ (I had already checked that $\Phi_{12}$ couldn't factor as a product $(X^2 +e)(X^2+f)$), so that also $c \neq 0$.  I multiplied (iii) by $d$ to get $c+ad^2 = 0$, and subtracted (i) from this to get $ad^2-a = 0$, or $d^2 = 1$. So $d = \pm 1$.  First I supposed $d = 1$, so that also $b=1$.  Then $a, c$ were nonzero elements satisfying $a+c = 0$ and $ac + 2 = -1$, or $ac = 2$. For $ac = 2$ we can only have $\{a,c\} = \{3,4\}$ or $\{a,c\} = \{1,2\}$, and in neither of those cases could we have $a+c = 0$. Next I supposed $d = -1$, so that also $b = -1$.  Then $a, c$ were nonzero elements satisfying $ac=1$ and $a+c = 0$.  This relation is satisfied by $a = 2, b = 3$.  So I looked at the product $$(X^2+2x-1)(X^2+3X-1)$$ which expands as $X^4+5X^3+4X^2-5X+1$, which is $X^4-X^2+1$ in $\mathbb{F}_5[X]$.","['irreducible-polynomials', 'abstract-algebra', 'field-theory']"
1088066,Can one always map a given triangle into a triangle with chosen angles by means of a parallel projection?,"This is something that seems to be true from experience by playing with shadows from the sun: If one cuts a paper triangle, he can turn it in a way to make its shadow be a triangle of any given angles (of course, not exceeding internal sum of 180°), for example: If one draws a right triangle with internal angles 90°, 60° and 30°,  one can turn it in a way that the shadow triangle can be of angles 60°, 60°, 60° (equilateral) or 120°, 30° and 30° (isosceles), or any other triangle possibilities. Is it true? How can we prove it? (if possible, showing not only that it's possible, but how to obtain the specific mapping that does it)",['geometry']
1088074,Sum over subsets of a multiset,"I have a sum that looks like the following for some multiset $S$ and some function $f$ of $n$ variables which does not depend on the ordering of its arguments: $$\sum_{\{k_1,\dots, k_n\}\subset S}f(k_1,\dots k_n)$$ However, this is not a form where a computer (or Mathematica) can easily iterate over the set. Therefore, I would like to use the principle of inclusion-exclusion to write this as a sum of the form (where $P(n)$ denotes integer partitions of $n$): $$\sum_{p\in P(n)}c_p\sum_{k_1,\dots,k_{|p|}\in S}f(k_1,\dots,k_n),$$ where $c_p$ is some coefficient that I need to calculate in terms of the partition, and the input into the function $f$ now has multiple copies of some of the variables based on the multiplicities of the integer partition $p$. What is $c_p$ in this formula? As an example consider that when sum is over subsets of size 3 ($n=3$), then the formula is: $$\sum_{\{k_1,k_2,k_3\}\subset S}f(k_1,k_2,k_3)=\frac{1}{6}\sum_{k_1,k_2,k_3\in S}f(k_1,k_2,k_3)-\frac{1}{2}\sum_{k_1,k_2\in S}f(k_1,k_1,k_2)+\frac{1}{3}\sum_{k_1\in S}f(k_1,k_1,k_1)$$ When $n\geq 4$, however, the formula becomes substantially more complicated. For example, when $n=4$:
\begin{align}
\sum_{\{k_1,k_2,k_3,k_4\}\subset S}f(k_1,k_2,k_3,k_4) &=\frac{1}{24}\sum_{k_1,k_2,k_3,k_4\in S}f(k_1,k_2,k_3,k_4)-\frac{1}{4}\sum_{k_1,k_2,k_3\in S}f(k_1,k_1,k_2,k_3) \\
& +\frac{1}{8}\sum_{k_1,k_2\in S}f(k_1,k_1,k_2,k_2)+\frac{1}{3}\sum_{k_1,k_2\in S}f(k_1,k_1,k_1,k_2)-\frac{1}{4}\sum_{k_1\in S}f(k_1,k_1,k_1,k_1)
\end{align} When $n=5$:
\begin{align}
& \sum_{\{k_1,k_2,k_3,k_4,k_5\}\subset S}f(k_1,k_2,k_3,k_4,k_5) \\
& \hspace{5mm} =\frac{1}{120}\sum_{k_1,k_2,k_3,k_4,k_5\in S}f(k_1,k_2,k_3,k_4,k_5)-\frac{1}{12}\sum_{k_1,k_1,k_2,k_3,k_4\in S}f(k_1,k_1,k_2,k_3,k_4) \\
& \hspace{5mm} +\frac{1}{8}\sum_{k_1,k_2,k_3\in S}f(k_1,k_1,k_2,k_2,k_3)+\frac{1}{6}\sum_{k_1,k_2,k_3\in S}f(k_1,k_1,k_1,k_2,k_3) \\
& \hspace{5mm} -\frac{1}{4}\sum_{k_1,k_2\in S}f(k_1,k_1,k_1,k_1,k_2)-\frac{1}{6}\sum_{k_1,k_2\in S}f(k_1,k_1,k_1,k_2,k_2)+\frac{1}{5}\sum_{k_1\in S}f(k_1,k_1,k_1,k_1,k_1)
\end{align} Let me know if anything in this question is unclear.","['integer-partitions', 'combinatorics']"
1088127,Splitting of an exact sequence,"Let $(R,\mathfrak m)$ be a Noetherian local ring. Suppose that $x \in \mathfrak m \setminus \mathfrak m^2$.  Is it true that
  $$
\frac{\mathfrak m}{x\mathfrak m} \cong \frac{\mathfrak m}{(x)} \oplus \frac{(x)}{x\mathfrak m}?$$ There exists an exact sequence $$
0 \rightarrow \frac{(x)}{x\mathfrak m} \rightarrow \frac{\mathfrak m}{x\mathfrak m} \rightarrow \frac{\mathfrak m}{(x)} \rightarrow 0$$ and the question becomes: Does this sequence split? If not, what is a counterexample?","['exact-sequence', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
1088131,What is the edge set of a multigraph?,"An edge set of a graph is a set of doubletons, pairing edges. For example: has an edge set of $\{\{6,4\},\{4,5\},\{4,3\},\{5,2\},\{5,1\},\{3,2\},\{1,2\}\}$. A set, by definition, cannot have duplicate elements, else it is not a set. is a multigraph. All graphs have edge sets, yet the edge set of the multigraph would have to contain duplicate sets in its edge set to properly represent its edges, but then it wouldn't have an edge set, because a set cannot possibly have duplicate elements. I suppose its edge set would be $\{\{1,3\},\{1,2\},\{2,4\},\{2,4\},\{2,4\}\}$, but then it wouldn't be a set, having three instances of the same member. Question How do I represent the edge set of a multigraph, which have multiple edges along the same vertices?","['graph-theory', 'multigraphs', 'elementary-set-theory']"
1088159,"Evaluate $\lim_{n \to \infty}\Bigl[\bigl(\prod_{k=1}^{n}{\frac{2k}{2k-1}}\bigr)\bigl(\int_{-1}^{\infty}\frac{(\cos{x})^{2n}}{2^x}\,dx\bigr)\Bigr]$","The following calculus problem is from the Stanford Math Tournament, 2013 #10. Evaluate $$\lim_{n \to \infty}\left[\left(\prod_{k=1}^{n}{\frac{2k}{2k-1}}\right)\left(\int_{-1}^{\infty}\frac{(\cos{x})^{2n}}{2^x}\,dx\right)\right]$$ I've had immense difficulty with this problem, and I wasn't really able to understand the solutions to this problem provided by Stanford. Hopefully you guys can help me out. Thanks! Edit: Okay, to the person who voted my question to be closed because it was deemed off-topic and did not provide enough context: there's not really much I can say about my own approach to this question since it is beyond my level. I'm pretty much clueless about where to even begin, so sorry about that.","['improper-integrals', 'sequences-and-series', 'calculus', 'contest-math', 'limits']"
1088163,Is there a system of mathematics where everything is a function?,"I was wondering if there is a system of mathematics where everything (except sets) is a function. For example, 3 would be the 3 function $x \mapsto 3$. There would be basic operators, such as $+$, $\times$, and $\circ$. As a concrete example, the derivative $D$ would be defined $$D = \left(f\mapsto \lim_{h\in \mathbb{k},h\to 0} \dfrac{f\circ(x\mapsto x+h)-f}{h}\right)$$ where $\mathbb{k}$ is the set of constant functions $f\in\mathbb{k}\leftrightarrow f\circ x = f\circ y\;\forall x\forall y$","['soft-question', 'functions']"
1088166,"Cardinality of the countably infinite product of a two-point set $\{0,1\}$?","I'm so confused about cardinalities of some sets. What is the countable infinite product of a two points set $\{0,1\}$? Does it have the same cardinality as the real number $\mathbb R$? Or is the infinite product just countable? Could anyone give me the answer?","['cardinals', 'elementary-set-theory']"
1088172,Prove that an infinite sigma algebra contains an infinite sequence of disjoint sets and is uncountable,"The following question is from Folland Real Analysis, chapter 1 problem 3. Let $\mathcal{M}$ be an infinite $\sigma$ -algebra.  Prove that a. $\mathcal{M}$ contains an infinite sequence of disjoint sets. b. $\text{card}(\mathcal{M}) \ge \mathfrak{c}$ . This is the problem I'm totally stuck at. First, I think there is a missing condition in (a). For (a) to be meaningful, (a) should be corrected : ""M contains an infinite collection of disjoint and nonempty sets."" But I can't find a way to construct such a collection of sets. Could anyone show me how to solve it?","['measure-theory', 'real-analysis']"
1088175,Diagonals of a Hexagon,The diagonals of a hexagon each bisect its area. Prove that the difference of the square of the lengths of alternating edges is zero. I tried to use the shoelace theorem but it become a bit too messy???,['geometry']
1088185,Conditions for two straight lines to intersect: is this exam question wrong?,"I am pretty sure this question (from a university admission test exam) is wrong. Two lines: $a_1x+b_1y+c_1=0$, $a_2x+b_2y+c_2=0$, intersect only if (a) $a_1a_2-b_1b_2=0\;\;\;$ (b) $a_1a_2-b_1b_2\ne0\;\;\;$(c) $a_1a_2-b_1b_2=1\;\;\;$ (d) $a_1a_2-b_1b_2\ne1$ Attempted solution: \begin{matrix}
a_1x+b_1y+c_1=0&                    \;\; &a_2x+b_2y+c_2=0 \\
y=-\frac{a_1x}{b_1}-\frac{c_1}{b_1}&\;\; & y=-\frac{a_2x}{b_2}-\frac{c_2}{b_2}\\
\end{matrix} If the lines are not parallel, they will always intersect. In case of non-parallel lines 
$$m_1\ne m_2$$
$$-\frac{a_1}{b_1}\ne-\frac{a_2}{b_2}$$
$$\require{cancel}
\cancel{-}a_1b_2\ne\cancel{-}a_2b_1$$
$$a_1b_2-a_2b_1\ne0.$$","['coordinate-systems', 'algebra-precalculus']"
1088198,Why is the $0$th percentile of the standard normal distribution $-\infty$?,Why is the $0$th percentile of the standard normal distribution $-\infty$? I can't explain the cause except saying there is no area under the curve. So it goes beyond the bell-shaped curve.,"['statistics', 'normal-distribution', 'probability-distributions', 'probability']"
1088203,Why is first fundamental form considered intrinsic,"I am reading Kuhnel's differential geometry book, and in chapter 4, it says that ""intrinsic geometry of a surface"" can be considered to be things that can be determined solely from the first fundamental form. But I am unsure on why the first fundamental form itself can be considered to be something intrinsic to the surface. Kuhnel defines the first fundamental form to be the inner product induced from that of $\mathbb{R}^3$ restricted to $T_pM$. So isn't the larger $\mathbb{R}^3$ used? So my question is: Supposed I have a smooth 2-dimensional manifold (e.g. in the sense defined by Lee's Introduction to Smooth Manifolds), but I didn't put it in any ambient space. Is there a way for me to define the first fundamental form? $T_pM$ is intrinsically defined (as the space of derivations in Lee's book), and so what is the inner product that I should put on $T_pM$?","['surfaces', 'smooth-manifolds', 'differential-geometry']"
1088209,deduce that $\cos 6° \cos42° \cos66° \cos78°= \frac{1}{16}$,Prove that $$4 \cos\theta \cos(\frac{\pi}{3}-\theta) \cos(\frac{\pi}{3}+\theta)= \cos 3\theta$$ and deduce that $$\cos 6° \cos42° \cos66° \cos78°= \frac{1}{16}$$ I have proved by using $2 \cos A \cos B= \cos (A+B)+ \cos (A-B) $ But I cant deduce $1/16$ P.S. we have to use prove that to deduce $1/16$,"['trigonometry', 'self-learning']"
1088216,"Pursuit Curve, Parametric Equation","So its a classic problem: Object $A$ starts at the origin $(0,0)$ and moves straight up the $y$ axis with a speed $v$. Object $B$ starts at point $(1,0)$, always moves towards object $A$ and has a speed of $2v$. There are answers on Stack Exchange to the question of finding $y_b (x) $ where $y_b$ is the $y$ coordinate of object $b$. But I want to find $y_b(t)$ and $x_b(t)$ where $t$ is time These, I think are the two equations you get from the problem have: Since the velocity of object $b$ is always $2v$
$$ \sqrt{x_b'(t)^2 + y_b'(t)^2} = 2v$$
Since the slope of object $B$ is always pointing toward object $A$, whose coordinates are $(0, vt)$
$$ \frac{y_b'(t)}{x_b'(t)} = \frac {y_b(t) - vt}{x_b(t)}$$ So far,  I have had no luck solving this, and I did try mathematica, but that didn't work. I'm not even sure if there is a reasonable solution. If you must, you can let $v = 1$, and bonus points if you can solve this for more generic coordinates. Note: I've only just finished calculus $AB$, so if could keep that in mind with your responses, that would be helpful :)","['ordinary-differential-equations', 'parametric']"
1088222,Show that the roots of the polynomial $x^4 - px^3 + qx^2 - pqx + 1 = 0$ satisfy a certain relationship,"Here is the question: If the roots of the equation
  $$
x^4 - px^3 + qx^2 - pqx + 1 = 0
$$
  are $\alpha, \beta, \gamma,$ and $\delta$, show that
  $$
(\alpha + \beta + \gamma)(\alpha + \beta + \delta)
(\alpha + \gamma + \delta)(\beta + \gamma + \delta)
= 1.
$$ Pretty much exhausted my resources.If there are more than one way of doing it please state and you can state some good books for this particular topic. $$
 1+x^4+\text{qx}^2-\text{px}^3-\text{pqx} \equiv x^4+x^3 (-\alpha -\beta -\gamma -\delta )+x^2
   (\alpha  \beta +\alpha  \gamma +\alpha  \delta +\beta  \gamma +\beta  \delta
   +\gamma  \delta )+x (-\alpha  \beta  \gamma -\alpha  \beta  \delta -\alpha 
   \gamma  \delta -\beta  \gamma  \delta )+\alpha  \beta  \gamma  \delta
$$ So,
$$
\text{p} = \alpha+\beta +\gamma +\delta 
$$
$$
\text{q} = \alpha  \beta +\alpha  \gamma +\alpha  \delta +\beta  \gamma +\beta  \delta
   +\gamma  \delta
$$
$$
\text{p}\text{q}=\alpha  \beta  \gamma +\alpha  \beta  \delta +\alpha 
   \gamma  \delta +\beta  \gamma  \delta
$$
$$
1= \alpha  \beta  \gamma  \delta
$$","['symmetric-polynomials', 'algebra-precalculus', 'polynomials']"
1088251,Probability of some die face being missed N or more times in a row in M rolls? [Clarified],"2015/01/28 Clarification: Question rewritten to remove ambiguity that elicited (interesting) responses to a different problem (use edit should you wish to view). From Markus' feedback on the earlier question: Let's consider a die with $F$ faces. This die is rolled $M$ times. What is the probability, that each window of size $N \leq M$ within this series of $M$ rolls contains always all $F$ faces? Or alternatively, consider an urn with $F$ differently colored balls, where $M$ balls are drawn (with replacement after each draw) and the colors noted. What is the probability given $F$, $M$, and some $N \leq M$ that every consecutive $N$ draws of the $M$ total draws exhibited at least one example each of all $F$ colors? Obviously, if $M<N$ or $N<F$ the probability is 0. I'm stuck for the $F\leq N \leq M$ cases. I can do this using recursive calculation or a Markov chain, but only for the most trivial (small) cases, since the state space obviously explodes quite quickly. I thought of treating it like a runs/streak problem, that is, I thought that if some face/color is seen, followed by $N$ all of differing face/color resulting in a ""failure"", I could just use existing means of calculating a streak of $N$ events with probability $(faces - 1)/(faces)$ for the event of a differing face/color. I was unable to arrive at a solution this way. I then thought of treating it as a coupon collector's problem. I can easily calculate the probability of all faces/colors being seen in the first $N$, so I thought using that, the next ""window"" from 2 to N+1 is a ""failure"" if those $N$ are all different from the 1st element (probability $((faces - 1)/(faces))^N$), continuing this for each step of the ""window"" by 1 to get a net probability. I get stuck here with the dependency between successive ""windows"", and I'm not even sure if it's a valid tack. I attempted to find a generating function by looking at actual example counts of differing cases, and searching OEIS for sequences along with checking for generating/sequence functions in Mathematica . I found no matches, and I'm a neophyte with generating functions, so I hit a dead end there. Bottom line, given $F, M, N$, how might I calculate this? A couple of examples follow to clarify the above problem description. Given an alphabet of two elements ${0,1}$, ($F=2$) the possible words of length 4 ($M=4$) are With a ""window"" of 3 ($N=3$), the only length 4 words that have no missing alphabet elements in all possible length 3 ""windows"" are So, my probability of missing some alphabet element in a 3-windowed 4-length string on a 2-element alphabet is 6/16. For a more involved example, take the length 6 strings on $0,1,2,3$. There are 4096 of them (I'll not list them for obvious reasons). For a ""window"" of 5, only 528 of them have the complete alphabet in all possible length 5 consecutive positions. A few examples: Note that in all of these, positions 1 through 5 and 2 through 6 for each have at least one example of every element in the alphabet. That number (528 in this example, or equivalently 3568 for the complement) is what I'm after. I hope that clarifies the question, apologies to readers for any confusion I caused. 2015/01/30 - I've awarded the current bounty to Markus, even though the answer was for a different problem (my fault, my ambiguously written OP), rather than have it vanish into the ether. His response prompted me to look at the problem in other ways and was most interesting in itself. I shall add another bounty if/when it is allowed, and/or award one manually should a solution present itself.","['dice', 'probability', 'combinatorics']"
1088253,Events $A_n\uparrow A$ meaning. $A_n\downarrow A$ meaning.,i simply do not understand the arrows in this context! :\,"['probability-theory', 'measure-theory', 'probability', 'notation']"
1088266,Finding the limit $\lim\limits_{x\to 2} \frac{x^3-8}{x-2}$ when naive substitution yields a division by 0,I am trying to find the following. $$\lim\limits_{x\to 2} \frac{x^3-8}{x-2}$$ The book I am reading (Spivak's Calculus) provides the following answer: $$\lim\limits_{x\to 2} \frac{x^3-8}{x-2} = \lim\limits_{x\to 2} (x^2+2x+4)=12$$ I don't see how that works. Could you explain what is going on here?,"['calculus', 'limits']"
1088269,A corollary of Arzela-Ascoli Theorem,"I have seen in a paper to claim the fact that due to Arzela-Ascoli theorem pointwise convergence with equicontinuity and uniform boundedness of a sequence of functions implies uniform convergence on compacts. This is not correct. The statement is true, but it is not due to arzela-ascoli as this theorem talks about existence of some subsequence. Am I correct ?","['sequences-and-series', 'functional-analysis', 'real-analysis']"
1088287,Change of variable in integration causes upper and lower unequal limits to be same and makes finite integral zero.,"Let $t=1+\sin x$ in the following integral, then we encounter something weird!! Note: $t(x)=1+\sin x$, so $t(0)=1+\sin0=1+0=1$ and $t(\pi)=1+\sin\pi=1+0=1$ $$2=\int_0^{\pi}\frac{{\rm d}x}{1+\sin x}=\int_{1}^{1}(*){\rm d}t=0??$$
It was actually asked to me by one of my friend(s).",['integration']
1088297,Sections of cones in higher dimensions,"Everybody knows that when a plane intersects a cone at different angles and positions, we get conic sections. But, I wanted to know that if the same was possible in higher dimensions. If we take the 4 dimensional equivalent of a cone, and make it intersect with the 3 dimensional equivalent of a plane (cube or a cuboid) in 4 dimensional space, will we get 3 dimensional shapes like spheres or ellipsoids?","['geometry', '3d', 'conic-sections']"
1088300,Surface Integral without Parametrization,"Let $S$ be the sphere $x^2 + y^2 + z^2 = a^2$. Use symmetry considerations to evaluate $\iint_Sx\,dS$ without resorting to parametrizing the sphere. Let F $= (1, 1, 1)$. Use symmetry to determine the vector surface integral $\iint_S$ F $\cdot \, dS$ without parametrizing
  the sphere. I find it difficult to understand question 1. What does it mean by 'symmetry considerations'? For question 2, without parametrizing the sphere, I find out that the integral should be equal to $$\frac1a \iint_S(x+y+z)dS.$$ Now symmetry comes in - a sphere is symmetric in all axes, thus the answer should be $\frac3a$ times the answer in part a. Am I correct? Any help will be appreciated.","['multivariable-calculus', 'integration']"
1088307,How to prove if something is a function?,"I know two conditions to prove if something is a function: If $f: A \to B$ then the domain of the function should be A. If ($z,x$) , ($z,y$) $\in f$ then $x = y$. Now for example I have two functions: $f:Z \to Z$ $g: Z \to Z$ And I have to show that the following are also functions: $h: Z \to Z$ defined as $h(x) = f(g(x))$. $h: Z \to Z$ defined as $h(x) = f(x) + g(x)$. $h: Z \to Z$ defined as $h(x) = f(x) \times g(x)$. Now in all these cases to I would have to show that the $Dom(h) = Z$. Now I show this by showing $Dom(h) \subset Z$ and then showing $Z \subset Dom(h)$. Hence through this I am able to show $Dom(h) = Z$. Now to show this for the three functions: 1 (a). $Dom(h) \subset Z$: $Dom(h) = Dom(f(g(x))) = Dom (g(x)) = Z$ . (As this is an equality can I use this statement instead showing both sides as subsets of each other?) 1 (b). $Z \subset Dom(h)$: (I don't understand how I would show this side.) 2 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) + Dom(g(x)) = Z + Z = Z$
3 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) * Dom(g(x)) = Z$ (Can I do this instead of showing them subsets for each side. Plus here is it correct to say $Dom(f(x)*g(x)) = Z.$ What if the domains of the two functions were different? Now for each function I have to show that each element in the domain only maps to one element in the co-domain. (How would I show this?) Is this method correct: Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(g(x))$ hence $\exists a,b : (z,a), (z,b) \in g$ AND $(a,x), (b,y) \in f$. So as $g$ is a function $a = b$, and then as $f$ is a function $x=y$ hence $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) + g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a+c$, $y=b+d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) \times g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a*c$, $y=b*d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function.","['functions', 'solution-verification']"
1088326,Don't understand why this generating function needs to be taken to the power $-1$,"I'm given the following recursive formula for a sequence: $u_{n+1}=u_n+\sum_{k=1}^{n-1}u_ku_{n-k}\ (n\ge1),\ u_0=0,\ u_1=1$ Since $u_0=0$ we can rewrite: $u_{n+1}=u_n+\sum_{k=0}^{n}u_ku_{n-k},\ (n\ge1)$ now writing $u(x)=u_1x+u_2x^2+....$ we obtain (by multiplying by $x^{n+1}$ and summing): $u(x)-x=xu(x)+xu(x)^2$ Which I believe we can just solve using $xu(x)^2+(x-1)u(x)+x=0$ So $u(x)=\frac{1-x\pm\sqrt{(x-1)^2-4x^2}}{2x}$ However, my book says the solution should be $u(x)=\frac{2x}{1-x+\sqrt{1-2x-3x^2}}$ Which is my answer to the power $-1$. I don't see why this is necessary, so any hints would be much appreciated.","['generating-functions', 'discrete-mathematics', 'functional-equations']"
1088358,Differentiation operator is closed?,"Got stuck in this problem: Let us denote by $X$ the linear space $C^1([0,1])$ equipped with the norm of $C^0([0,1])$ and consider the following statement: ""The differentiation operator $L:X \rightarrow C^0([0,1]): u \mapsto u'$ is linear and closed. By the Closed Graph Theorem, the operator is then continuous"" Show that the conclusion is wrong and find the mistake in the argument To show that the conclusion is wrong it should be enough to show that the operator is not bounded (as it is obviously linear and, as it is linear, it is continuous iff it is bounded), which is not hard. So I believe the mistake is that $L$ is not closed, but how can I prove it? I was trying to find an example of a closed set in $X$ whose image is not closed but I'm not sure whether this is a good approach...","['general-topology', 'functional-analysis', 'operator-theory']"
1088359,Dominated convergence theorem for finitely additive measures.,"Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $\mu$ a finitely additive, finite signed measure, which is absolutely continuous with respect to the Lebesgue measure in $\Omega$. Let $\phi_n\in L^\infty(\Omega)$, $\phi\in L^\infty(\Omega)$. Assume that $\phi_n(x)\to \phi(x)$ for a.e. (Lebesgue measure) $x\in \overline{\Omega}$, $\|\phi_n\|_\infty <M$. May I conclude that $$\int_\Omega \phi_nd\mu\to\int_\Omega \phi d\mu. \tag{1}$$ Once $\mu$ is only finitely additive, the Dominated Convergence Theorem does not work, however, as we have that $\mu$ is absolutely continuous with respect to the Lebesgue measure in $\Omega$, maybe we can use this fact to prove the result, or maybe there is also a counter example. If we can prove that $\phi_n\to \phi$ in $\mu$-measure, we are done, however I could not prove it also. This problem comes from my answer here . In that answer, I used Dominated Convergence Theorem (which is not immediately true) to prove the limit $$\int_\Omega \frac{\partial (u\gamma_n-u)}{\partial x_i}d\mu_i\to 0.$$ I think that this limit is really zero and that I can save the answer. Remark: If necessary, we can assume that the support of $\phi_n$ is contained in the set $$\{x\in \Omega:\ \operatorname{dist}(x,\partial\Omega)<1/n\}.$$",['measure-theory']
1088411,What's the explicit categorical relation between a linear transformation and its matrix representation?,"There several questions about linear transformations and its respective matrices in some basis, but I'm particularly interested in the explicit definition of this relation in the category $Vect$ (of vector spaces and linear transformations.) Of course, a inevitable question is if there is always an matrix (or tensor, perhaps) representation (representable Functor?) for every morphism in an arbitrary category.
Sorry if it is a silly question, but I'm learning CT by myself and it is difficult for me to understand this relation in categorical terms.","['category-theory', 'linear-algebra', 'abstract-algebra']"
1088422,"Integral $\int_0^\infty \frac{\sqrt[3]{x+1} - \sqrt[3]{x}}{\sqrt{x}} \, \mathrm dx$ [duplicate]","This question already has answers here : Computing $ \int_0^{\infty} \frac{ \sqrt [3] {x+1}-\sqrt [3] {x}}{\sqrt{x}} \mathrm dx$ (2 answers) Closed 9 years ago . I have the following integral to solve: $$\int_0^\infty \frac{\sqrt[3]{x+1} - \sqrt[3]{x}}{\sqrt{x}} \, \mathrm dx$$ I tried substitution $u= x+1$ and $u=\sqrt[3]{x+1}$ then partial integration but that didn't really help because it didn't become any simpler. Thank you.","['definite-integrals', 'integration']"
1088428,How does $\sum_{k=0}^n (pe^t)^k{n\choose k}(1-p)^{n-k} = (pe^t+1-p)^n$?,"How does $\sum_{k=0}^n (pe^t)^k{n\choose k}(1-p)^{n-k} = (pe^t+1-p)^n$? Where $e$ is Euler's number and $p,n$ are constants. ${n\choose k}$ is the binomial coefficient. If context helps, I'm currently trying to show that the moment generating function of a binomial random variable $X$ with parameters $n$ and $p$ is given by $(pe^t+1-p)^n$. I'm stuck on this very last bit. My notes just simply state that $\sum_{k=0}^n (pe^t)^k{n\choose k}(1-p)^{n-k} = (pe^t+1-p)^n$, but I don't understand why this is so. Many thanks in advance.","['probability-theory', 'summation']"
1088447,How to implement a group action in Sage ( for educational purposes )?,"Let S= {""A"",""B"",""C"",""D""} and S4= SymmetricGroup(4). I want to create a table of the action S4 x S -> S which standardly permutes the letters in the set. The table should look like: Permutation.   A.  B.  C.  D
()             A.  B.  C.  D
(1 2 )         B.  A.  C.  D.
etc. How can this be done with Sage? ( The Set and Group in the question are just examples, I want to be able to create a table for any action.","['sagemath', 'group-theory', 'abstract-algebra', 'math-software']"
1088476,On the value of $e^{ix}$ at $\pm \infty$,"Consider the integral $$ \int_{-\infty}^{+\infty} e^{ix} \, dx.$$ Integrating, we have $$\left[-ie^{ix}\vphantom{\frac11}\right]_{-\infty}^{+\infty},$$ and we need to evaluate the limits of $e^{ix}$ at ${-\infty}$ and ${+\infty}$ which, as far as I understand, do not exist since the function is oscillatory. But if we now evaluate the integral using contour integration: $$ \oint_{-\infty}^{+\infty} e^{iz} \, dz.$$ Closing in the upper half plane, so that $e^{iz} = e^{ix}e^{-y} \rightarrow 0 $ as $y\rightarrow 0$, the contribution of the semi-circle to the contour goes to $0$, and we get that the integral is $0$. What is the correct anwer and what is the reason of this inconsistency?","['complex-analysis', 'contour-integration']"
1088483,Not using Jacobi symbol how to prove For all positive integer $n>1$ $2^n - 1 \not | 3^n-1$?,"There is a proof: if $n$ is even,then $3|2^n-1$ but $3\not|\;3^n-1$,It is correct; if $n$ is odd,suppose $2^n-1|3^n-1$,then $3^n \equiv 1(\mod 2^n-1)$,then
$$\left(\frac{3^n}{2^n-1}\right)=\left(\frac{1}{2^n-1}\right)=1.$$
However 
$$\left(\frac{3^n}{2^n-1}\right)=\left(\frac{3}{2^n-1}\right)^n=\left(\frac{3}{2^n-1}\right)=-\left(\frac{2^n-1}{3}\right)=-\left(\frac{1}{3}\right)=-1$$
That is a contradiction. $\left(\frac{m}{n}\right)$ is Jacobi symbol,which is a generalization of Legendre symbol. I want a proof without high technique.
So I transformed the right side for $$3^n-1=(2+1)^n-1=2(2^{n-1}+n\times2^{n-2}+\cdots n),$$
and then have no idea.
Can this way work?","['prime-numbers', 'number-theory']"
1088519,Are the primitive groups linearly primitive?,A transitive permutation group $G \subset S_n$ is primitive if $G_1 \subset G$ is a maximal subgroup. A finite group $G$ is linearly primitive if it has a faithful complex irreducible representation. Question: Are the primitive finite groups linearly primitive? Remark : I've checked by a GAP computation that it's true for $n=[G:G_1] \le 200$ and $\vert G \vert \le 10^4$.,"['permutations', 'representation-theory', 'finite-groups', 'gap', 'group-theory']"
1088529,Justify the solution of $x^2-x+\arctan{x}=0$,"It is obvious that a solution of  $x^2-x+\arctan{x}=0$ is $x=0$, but I would like you to show me how this can be derived more conceptually than by plugging in $0$, and how can one prove that such solution is unique.","['trigonometry', 'calculus', 'algebra-precalculus']"
1088546,Subspace for a matrix representation of a linear transformation,"Can someone help me with this problem? Let $V$ be an $n$-dimensional vector space, and let $T: V \rightarrow V$ be a linear transformation. Suppose that $W$ is a $T$-invariant subspace of $V$ having dimension $k$. Show that there is a basis $\beta$ for $V$ such that $[T]_{\beta}$ has the form $\begin{pmatrix} A & B \\ O & C \end{pmatrix}$, where $A$ is a $k \times k$-matrix and $O$ is the $(n-k) \times k$ zero matrix. Attempt at a solution: Let $(v_1, v_2, \ldots, v_k)$ be a basis for $W$ and extend it to a basis $\beta = (v_1, v_2, \ldots, v_n)$ for $V$. Since $W$ is $T$-invariant, we have $\forall v_j \in W$, $T(v_j) \in W$ for $j= 1, 2, \ldots, k$. Hence $T(v_j) = \sum_{i=1}^{k} a_{ij} v_i$. Don't know where to go from here. How to find A, B, C and $O$?","['linear-transformations', 'matrices', 'linear-algebra']"
1088556,How can Distinguishable objects behave as if they were Indistinguishable?,"I am mentally disabled: I cannot imagine indistinguishable marbles. However, I can imagine that there exist sequences of (random) manipulations on real (distinguishable) marbles causing them to end up in real (distinguishable) boxes according to the Bose-Einstein distribution: For example, in case of $2$ marbles and $3$ boxes the following six arrangements are supposed to be equally likely: $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &.. & & \end{gather}$$
$$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &.. & \end{gather}$$
$$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & & &.. \end{gather}$$
$$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. &. & \end{gather}$$
$$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. & &. \end{gather}$$
$$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &. &. \end{gather}$$ (Arrangements of this type can be listed in the case of $n$ marbles and $m$ boxes. So the Bose-Einstein distribution can be defined in general.) Can one describe manipulations that result in the Bose-Einstein distribution? Restriction on the manipulations: one cannot choose a whole arrangement of marbles. Only individual boxes and individual marbles can be picked.","['statistics', 'probability', 'combinatorics']"
1088560,Does there always exist a lift of a path from $Y$ to $X$ if $f: X\to Y$ is a continuous surjective function?,"If one has a continuous surjective function $f:X \longrightarrow Y$ and let $\gamma$ be a continuous path in $Y$, under what circumstances can one find a (possibly non-unique) lifted path $\gamma'$ in $X$ such that $f\circ\gamma'=\gamma$? Can somebody give a counterexample to this always holding? In particular, does it hold in metric spaces?","['general-topology', 'algebraic-topology']"
1088562,Solutions of $x(\ln x)^2=e$,"The solution of $x(\ln x)^2=e$ is clearly $e$, but how can I show that it is indeed a solution conceptually (that is, without substituting $x=e$ ) and that it is unique?","['trigonometry', 'calculus', 'algebra-precalculus']"
1088587,Find solutions of $\alpha x^n = \ln x$,"How can I find the solutions of $$\alpha x^n = \ln x$$ when $\alpha \in \mathbb{R}$ and $n\in \mathbb{Q}$? Or, if it is not possible to have closed form solutions, how can I prove that there exist one (or there is no solution) and that it is unique? (I'm particularly interested in the cases $n=2$, $n=1$, and $n=1/2$).","['calculus', 'algebra-precalculus']"
1088610,Computation of a indefinite integral: $ \int \frac {dx} {x^n-1}$,"This trouble arose when I earlier played with W|A, I found that it can compute $\int \frac{dx}{x^{11}-1}$, which has a huge messy answer. With great uncertainty, this's my work so far: Let $\displaystyle I=\int \frac 1 {x^n-1} dx$. Let $\alpha=e^{\frac {2i\pi} n}$ be $n$th root of unity, then $\displaystyle x^n-1=\prod_{k=1}^n (x-\alpha^k)$ $$\displaystyle\prod_{k=1}^{n-1} (x-\alpha^k)=\sum_{k=1}^{n-1} x^k...(*)$$ Write $\displaystyle \frac 1 {x^n-1}=\sum_{k=1}^n \frac {A_k}{x-\alpha^k}$. Multiply by $x^n-1$ on both sides, $\displaystyle 1=\sum_{k=1}^n \prod_{1\leq l\leq n,l\neq k}A_k(x-\alpha^l)$ Substitute $x=\alpha^k$, then $\displaystyle \prod_{1\leq l\leq n,l\neq k}A_k(\alpha^k-\alpha^l)=1$ $$\displaystyle \prod_{1\leq l\leq n,l\neq k}A_k \alpha^l(\alpha^{k-l}-1)=1$$ $$\displaystyle A_k\alpha^{\frac{n(n-1)} 2-k}\prod_{l=1}^{n-1}(\alpha^l-1)=1$$ $$\displaystyle A_k\alpha^{\frac{n(n-1)} 2-k}(-1)^{n-1}n=1[(*),x=1]$$ $$\displaystyle A_k=\frac{\alpha^k}n$$ Therefore, $\displaystyle I=\int \sum_{k=1}^n \frac 1 n\frac {\alpha^k}{x-\alpha^k}=\frac 1 n \sum_{k=1}^n \alpha^k \log(x-\alpha^k)$. I know that, in the last line, the logarithm of a complex number is a set of value, but since $I$ is real, all the imaginary branches should cancel out each other, right? Is there any conceptual or other kind of error in above? And could the answer be further simplified? Thanks.","['calculus', 'integration', 'indefinite-integrals']"
1088618,Convergence on the boudary,"Consider this power series $$\sum_{n=0}^{\infty}\frac{(3n)! (2n)!}{(n)!(4n)!}z^n $$
The radius of convergence is $\displaystyle \frac{64}{27}$. But how do we know where it's convergent on the boundary $|z|=\displaystyle \frac{64}{27}$, $z \in \mathbb{C}$? Abel's theorem seems to not work here.",['complex-analysis']
1088623,Proving that linear functionals are linearly independent if and only if their kernels are different,"Here is a problem I'm trying to solve: Let's assume that $\dim X < \infty$. Show that 2 non-zero linear functionals $a^*, b^* \in X^*$ are linearly independent if and only if $\ker a^* \neq \ker b^*$. I think I managed to do the implication from left side to right side: ($\rightarrow$) $a^*, b^*$ are linearly independent if and only if for all $x \in X$ we have $\alpha a^*(x) + \beta b^*(x) = 0$ if and only if $\alpha=\beta=0$ where $\alpha, \beta$ are scalars. But if $\ker a^* = \ker b^*$, then for some $x' \in \ker a^*$ we have $a^*(x') = b^*(x')=0$ so for $\alpha=\beta=1$ we get $a^*(x') + b^*(x') = 0$ which is a contradition. So $\ker a^* \neq \ker b^*$ But I really don't know where to start when trying to prove the implication in the other way. The information that $\ker a^* \neq \ker b^*$ seems like it's not enough to say whether $a^*,b^*$ are linearly independent. So, is there a way to prove that using only that information?","['linear-algebra', 'functional-analysis']"
1088627,Inverse of a tridiagonal Toeplitz matrix,"Let 
$${A_{n \times n}} = \left[ {\begin{array}{*{20}{c}}
{-2}&{1}&{}&{}&{}\\
{1}&{-2}&{1}&{}&{}\\
{}&{1}&{\ddots}&{\ddots}&{}\\
{}&{}&{\ddots}&{\ddots}&{1}\\
{}&{}&{}&{1}&{-2}
\end{array}} \right]$$
be a tridiagonal matrix. How we can prove that its inverse is the matrix $B=(b_{ij})$ where
$$b_{ij}=-\frac{i(n+1-j)}{n+1} \; ,\quad i\leq j.$$","['tridiagonal-matrices', 'matrices', 'linear-algebra', 'inverse', 'toeplitz-matrices']"
1088643,Do regular partitions suffice for Riemann integrability of a real-valued function on a closed interval?,"Does the following condition for a bounded function $f: [a, b] \to \mathbb R$ suffice that it be Riemann integrable on $[a,b]$, with Riemann integral $I$? For every $\epsilon > 0$, there exists a positive integer $N$ such that, for every positive integer $n \geq N$:  for each $i = 1, 2, \dots, n$, for each number $c_{i} \in [x_{i-1}, x_{i}]$ — the $i$th subinterval in the $n$th regular partition of $[a, b]$ whose subintervals have length $\Delta x = (b-a)/n$ — we have
$\left| \sum_{i=1}^{n} f\bigl(c_{i})\,\Delta x - I \right| < \epsilon$. The condition may be stated equivalently as:
For every $\epsilon > 0$, there exists a $\delta > 0$ such that, for every positive integer $n$ with $\Delta x = (b - a)/n < \delta$:  for each $i = 1, 2, \dots, n$, for each number $c_{i} \in [x_{i-1}, x_{i}]$ — the $i$th subinterval in the $n$th regular partition of $[a, b]$ — we have
$\left| \sum_{i=1}^{n} f\bigl(c_{i})\,\Delta x - I \right| < \epsilon$. In short, do regular partitions suffice for Riemann integrability? Notes: The usual condition for Riemann integrability involves arbitrary partitions, not just those that are regular, and then of course it involves the mesh of partitions being $< \delta$. Of course for a regular partition with $n$ subintervals, that mesh is $\Delta x = (b-a)/n$. The only thing I intend to change in the usual condition is to restrict partitions just to those that are regular. Note that the condition as stated allows the sample points to be chosen arbitrarily in the subintervals. It's well known that it is not enough to allow just endpoints.",['integration']
1088648,Focal length of an ellipse and related results,"There are 2 questions(part of same question but I divided it into two): Q1. Prove that the length of the focal chord of the ellipse $¥frac {x^2}{a^2}+¥frac {y^2}{b^2}=1$ which is inclined to the major axis at an angle $¥theta$ is $$¥frac {2ab^2}{a^2¥sin^2¥theta+b^2¥cos^2¥theta}$$ I tried to solve this using the parametric form of a line, i.e., $(x,y)=(ae+r¥cos¥theta,r¥sin¥theta)$, plugging this into the given equation to find $r_1-r_2$ which is giving a different solution. Q2. If $PSQ$ and $PS'R$ are two chords of an ellipse through its two focii S and S', then prove that $$¥frac {PS}{SQ}+¥frac {PS'}{S'R}=2¥left(¥frac {1+e^2}{1-e^2}¥right)$$ Here I fixed $P ¥equiv (a¥cos¥theta,b¥sin¥theta)$ and found out the parametric angles of $Q$ and $R$ using the result $$¥tan¥theta_1/2*¥tan¥theta_2/2=¥left(¥frac {e-1}{e+1}¥right)^{¥pm1}$$, $+$ when chord passes through $S$ and $-$ when chord passes through $S'$. But it gives a very ugly expression. So how do I do it  in an easy way? Hints are welcome.","['analytic-geometry', 'trigonometry']"
1088654,"Moduli spaces, stacks and homotopy theory","For my final-year project (not this academic year but next) I'm hoping to write a relatively complete account of the basic theory of schemes used in modern algebraic geometry. My supervisor thinks that as long as I work hard I should have enough time to study some simple moduli spaces as well. It's quite an ambitious undergrad project but I'm hoping to use it as a stepping stone towards a PhD working with moduli, stacks and other ""very general"" geometric objects. However I'm also quite fond of topology and a lot of the homotopy theory that I've glanced over has really interested me, particularly that which uses higher categories and other very abstract machinery, and I'd like to work in an area which combines both geometry and topology with a lot of category theory thrown in. I've still got more than a year to think about which subfield to go into with the PhD but I'd like to get some ideas now so I can aim this project in the right direction. Can anyone suggest some particular ideas or general areas in the intersection of algebraic geometry and topology which would be relevant to look into? I'm happy to accept answers which might be way too advanced for my knowledge at the moment - I'm just trying to get some ideas. Thanks in advance!","['algebraic-geometry', 'algebraic-topology', 'moduli-space', 'soft-question', 'homotopy-theory']"
1088658,When is a continuous function also a bijective function?,"To begin with, I would like to  set forth a property of continuous functions: There doesn't exist a continuous function $f$ on $\mathbb{R}$ such that $f|_{\mathbb{R}\setminus \mathbb{Q}} : \mathbb{R}\setminus \mathbb{Q} \rightarrow f\left( \mathbb{R}\setminus \mathbb{Q} \right)$ is a bijection and $f|_{\mathbb{Q}} : \mathbb{Q} \rightarrow f\left(  \mathbb{Q}\right)$ is not a bijection. Hence, if $f$ is a continuous function on $\mathbb{R}$ and $f|_{\mathbb{R} \setminus \mathbb{Q}}$ is a bijection, then $f|_{\mathbb{Q}}$ must be a bijection too. Motivated by this, My question is in the following: Suppose that $f \in C(\mathbb{R})$ and $f|_{\mathbb{R}\setminus \mathbb{Q}}$ is a bijection from $\mathbb{R}\setminus \mathbb{Q}$ onto $f\left( \mathbb{R}\setminus \mathbb{Q} \right)$. Then, can we come to a conclusion that $f$ is a bijection from $\mathbb{R}$ onto $f\left( \mathbb{R} \right)$ ?","['functions', 'continuity', 'real-analysis']"
1088660,integration of a complex function,"i want to solve this integral  $\displaystyle \int_{-2}^{+2}\sin{ (π|x|/2)e^{-i2πkx}}\,dx$  in order to find the fourier transform of a function 
 g(x)  that is $0$  outside $(-2;2)$; i have already tried to solve the integral by  splitting  it in 2 and using the complex definition of sin. i also use the fact that sin is  odd :
$$
  - \int_{-2}^{0}\sin{ (πx/2)e^{-i2πkx}}dx\ + \int_{0}^{2}\sin{ (πx/2)e^{-i2πkx}}dx
$$
then i use 
 $  \sin (z ) = \frac{e^{iz}- e^{-iz}}{2i\ } $
but the process is very long. i would like to know if there is a shorter way to handle this integral. thank you update : $k$ is a real number","['complex-integration', 'complex-analysis']"
1088661,"reduction order method $(2-x)y'''+(2x-3)y''-xy'+y=0$, $y_1=e^x$","$(2-x)y'''+(2x-3)y''-xy'+y=0$, $x<2$ being $y_1=e^x$ a solution for the homogeneous equation.
making $y=ue^x$
i came to $u''+u'''=0$
making $u''=w$
,  $w'+w=0$ this way $w=e^{-x}*c_1$ and $y=c_1+c_2xe^x+c_3e^x$. However the right solution is $y=c_1x+c_2xe^x+c_3e^x$. Where have i made the mistake? Thanks","['ordinary-differential-equations', 'calculus', 'integration', 'derivatives']"
1088674,Compactly supported infinitely differentiable function constant on an interval,"I know a typical example of compactly supported infinitely differentiable function to be defined by $$f(x) = \begin{cases} e^{\frac{1}{(\beta-x)(\alpha-x)}}, & \alpha<x<\beta \\ 0, &x\notin (\alpha,\beta) \end{cases}$$Can a compactly supported infinitely differentiable function be explicitly defined to be constant on a certain interval? I have not been able to get anything by using piecewise defined functions with exponentials. Thank you very much for any answer!","['functional-analysis', 'real-analysis']"
1088685,Showing an open connected subset of $\mathbb{R}^n$ is path-connected,In the above proof the following equivalence is used at the last step: A space $M$ is connected if and only if the only open and closed subsets of $M$ are $\emptyset$ and $M$ (ie. there are no proper open and closed subsets). However I do not understand the claim that $X$ is the completment of the open union and feel like it is non-trivial. Can someone please elaborate?,['complex-analysis']
1088688,Trace class operator is an ideal,"To show that trace class operators space is an ideal, we need to show that $\|uv\|_1\leq \|u\|\|v\|_1$ where $u,v \in B(H)$ and $\|u\|_1 = tr(|u|)$. Murphy in his book (C*-algebras and operator theory) prove it as below: Let $u=w|u|$ and $vu = w'|vu|$ be the polar decomposition of $u$ and $vu$ respectively and $w''=w'vw$ . Then $|vu| = w'^*vu=w''|u|$. Hence, $|vu|^2=|u| w''^*w''|u| \leq |u|^2\|w''\|^2 \leq |u|^2\|v\|^2$, so $|vu|\leq |u|\|v\|$. and he continues his proof to get the desired inequality. But I can not understand how he concludes $|u| w''^*w''|u| \leq |u|^2\|w''\|^2$. Please help me. Thanks.","['operator-theory', 'compact-operators', 'functional-analysis', 'c-star-algebras']"
1088715,Proving this set is an algebra.,"Let $J = \{$all intervals contained in $[0,1]\}$  and $B_0 = \{$all finite unions of elements of $J\}$. Prove that $B_o$ contains $[0,1], \emptyset$, and is closed under formation of complements and of finite unions and intersections, i.e., prove that $B_0$ is an algebra. How do I prove that $B_0$ is closed under complements?","['self-learning', 'elementary-set-theory']"
1088720,A property of a solution of a differential problem.,"Let $f \in L^2(0,1)$ such that $f(x)=f(-x)$ a.e. in $(-1,1)$ and let $u$ be the solution of the problem $$ -u''(x)+u(x)=f(x) \,\,\,\, x \in (-1,1)$$
with the condition
$$ u(-1)=u(1)=0 $$ Can I deduce that $u(x)=u(-x)$?","['ordinary-differential-equations', 'analysis']"
