question_id,title,body,tags
625602,Why modern mathematics prefer $\sigma$-algebra to $\sigma$-ring in measure theory?,"Actually, i posted the exact same question before (about a year ago), but now i lost my past account so i couldn't find the past post.. So i googled this, but i couldn't find a satisfying post. I'll illustrate two different situations below ======== First definition Let $X$ be a set and $\sum \subset P(X)$.
  Then, $\sum$ is a sigma algebra on $X$ iff (1)it is closed under countable union, (2)it is closed under complement and (3)$X\in \sum$ If we start measure theory via this definition, just like topology, for a given sigma algebra, we can immediately know that on which set this sigma algebra is defined. Thus, this definition makes it possible to view a sigma-algebra as a measurable space. ======= Second definition Let $X$ be a set and $\sum \subset P(X)$.
  Then $\sum$ is a sigma ring on $X$ Iff (i) it is closed under countable union, (ii)$\forall A,B\in \sum, A-B\in \sum$. If we start measure theory in this way, when we want to talk about a measure space, a set and a sigma-ring on this set should be given together. This is the only disadvantage of sigma ring in my opinion. Let $M=\bigcup \sum$. Then, $\sum$ is a sigma algebra on $M$ iff $M\in \sum$. Thus, the definition of sigma ring is strictly stronger than that of sigma algebra. I cannot understand why mathematicians got rid of this generalized definition and prefer a weaker one. I remember that someone answered me that a lot of interesting spaces are integrable themselves. Which means, lot of interesting $\sigma$- whatsoever contains the whole space, so they are $\sigma$-algebras. But, isn't there any interesting $\sigma$-ring which is not $\sigma$-algebra? I really hate to go back and define something again more generally so that i have to prove every single theorem depending on property of the older definition. For example, i started analysis with Rudin-PMA and he defined Topology as topology induced by metric space in usual sense. It was painful to me to distinguish theorems which hold only in metric space and which hold in topological space, when i learned general-topology later. It's hard to confirm myself why mathematicians prefer this weak definition taking this risk..","['measure-theory', 'analysis']"
625611,"Given every horse's chance of winning a race, what is the probability that a specific horse will finish in nth place?","I have been interested in calculating a specific horse's chance of finishing in nth place given every horse's chance of winning in a particular race. i.e. Given the following: Horse    Chance of winning
A        0.35
B        0.25
C        0.15
D        0.10
E        0.09
F        0.05
G        0.01 Calculate for any horse it's chance of finishing in nth place. For instance, calculate the chance of HorseC finishing in 2nd place, or calculate the chance of HorseB finishing in 3rd place. I thought that this is something I could get help with online. All of the journal articles I found discuss chances of a pair of horses winning, i.e. the chance of horse A winning and horse B coming second, which is obviously different to this question. This: http://forum.sbrforum.com/handicapper-think-tank/526381-win-v-place-odds-value-math-question.html#post5076725 is the closest thing I have found to what I am looking for, but I believe he assumes that given one horse wins, the others have an equal chance of placing second, which is clearly not the case. UPDATE I just had time to have a go at this and I am trying to come up with a formula for P(i, n) as @ThanosDarkadakis suggested. I am unsure of whether the odds of HorseZ finishing 3rd is: sum of HorseXWin * HorseY2nd * (HorseZWin/(1-HorseXWin-HorseY2nd)), for each X/Y or sum of HorseXWin * HorseY2nd * (HorseZWin/(sum of remaining win probabilities)), for each X/Y or sum of HorseXWin * HorseYWin * (HorseZWin/(1-HorseXWin-HorseYWin)), for each X/Y Where HorseX is the winner of the race, HorseY comes 2nd and HorseZ comes 3rd (for each X/Y). I'm sure that with a formula for P(i, 3) it would be trivial to write a formula for P(i, n). Any suggestions are greatly appreciated.","['statistics', 'probability', 'conditional-probability']"
625618,intuition on the projection formula,"For a morphism $f:X\rightarrow Y$, locally free sheaf $\mathcal{G}$ on $Y$, and a quasi-coherent sheaf $\mathcal{G}$ on $X$, we have the projection formula
$$f_*(\mathcal{F}\otimes_{\mathcal{O}_X}f^*\mathcal{G})\simeq f_*\mathcal{F}\otimes_{\mathcal{O}_Y}\mathcal{G}.$$ I don't have a problem proving this, but I have a hard time seeing it as a projection! This looks more like compatibility of pushforward with base change if we take $\mathcal{G}=\mathcal{O}_Y$. What is the  motivation for calling it the projection formula?",['algebraic-geometry']
625623,A finite group with the property that all of its proper subgroups are abelian,Let $G$ be a finite group with the property that all of its proper subgroups are abelian. Let $N$ be a normal subgroup of $G$. Prove that either $N$ is contained in the center of $G$ or else $G$ has a normal abelian subgroup of prime index. I think $G$ is solvable. http://crazyproject.wordpress.com/2010/06/08/every-finite-group-whose-every-proper-subgroup-is-abelian-is-solvable/ . I hope that idea maybe usefull. Help me some hints. Thanks a lot. P/s: This is a question comes from a qualifying exam in Algebra ( Wisconsin August $1979$ ),"['finite-groups', 'group-theory', 'abstract-algebra']"
625628,"Why aren't these two matrices conjugate in SL(2, $\mathbb{R}$)?","Can you please give me a ""good"" reason that the following two matrices are not conjugate in $SL(2, \mathbb{R})$?  I'm sure I could prove it with a computation but I'd like to know why they're not conjugate. For instance, I hope there is some sort of conjugate-invariant property of one that is not a property of the other. Thank you. $$\left(\begin{matrix}
1&1\\
0&1
\end{matrix}\right)$$ $$\left(\begin{matrix}
1&-1\\
0&1\\
\end{matrix}\right)
$$","['linear-algebra', 'abstract-algebra']"
625684,A commutative ring whose all proper ideals are prime is a field. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Let $R$ be a commutative ring with $1$. Suppose that all ideals $I \neq R$ are prime. Prove that $R$ is a field. Help me some hints. Thanks a lot.","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
625703,How many (linear) order types are there on a set of n elements?,"Given number $n$ variables $a_1, a_2, \dots, a_n$. How many way can we place $>$, $=$ between them ? For example, for $n = 3$ (Let's call $a_1 = x, a_2=y, a_3=z$ for convenient). There are 13 way:
 $$x = y = z;\ x = y > z;\ x > y = z;\ x > y > z;\ x > z > y;\ x = z > y;\
y > x = z;\ y > x > z;\ y > z > x;\ y = z > x;\ z > x = y;\ z > x > y;\  z > y > x.$$ For $n$ small enough, I can count it by brute-force, but what about for a large $n$. Is there a formula ? How can I get it ? Thank you.","['problem-solving', 'combinatorics']"
625734,Holomorphic function has at most countably zeros,"Let $f$ be holomorphic in a domain $U$, then $f$ has at most countably zeros. How can I prove this statement? I have seen it in Sheng Gong  explicitly, but without any indications.",['complex-analysis']
625752,orthogonal functions with orthogonal first derivatives,"Is there any set of functions  $\phi_1(x) , \phi_2(x) , \ldots , \phi_n(x) , \ldots $ defined on $[a,b]$ such that 
\begin{eqnarray}
&&\langle\phi_i, \phi_j\rangle = \int_a^b \phi_i(x)\phi_j(x) \, dx = 0   , & \quad i \neq j\\
\text{and} &&\langle\phi'_i, \phi'_j\rangle = \int_a^b \phi_i'(x)\phi_j'(x) \, dx = 0   , & \quad i \neq j\\
\end{eqnarray} In other words is it possible to construct  a set of orthogonal functions with orthogonal first derivatives. thanks for any help in advance. If $\mathbf x_{(n)} = (1,x,...,x^n)^\top$  and $n= 2k$, we can build $k+1$ orthogonal functions as $\{f_1(x) , f_2(x) , \ldots, f_{k+1}(x)\} $  with orthogonal derivatives.
Where $$f_i(x) = \beta_{(i)}^\top \mathbf x_{(n)} $$
for example if $n=4$ we choose $\beta_{(1)} = (1,1,1,1,1) ^\top$, to calculate $\beta_{(2)}$  we obtain a system of $2$ equations with $n+1=5$ unknowns, thus we can choose three of the unknowns arbitrary, in this case we obtained $\beta_{(2)} = (1,1,1, -13863953/737217, 3891559/245739)^\top$ to calculate $\beta_{(3)}$ we obtain a system of $4$ equations with $n+1=5$ unknowns, thus we can choose one of the unknowns arbitrary, i chose $1$ for arbitrary elements and obtained  $\beta_{(3)} = (1,-107258998722634059/7523609370275492, 196455394286418897/3761804685137746, -262795627408036863/3761804685137746, 58289000568303981/1880902342568873)^\top$ (to calculate $\beta_{(i)} $ we have $n+3-2i$ choices) Now I  have a question that is important to me:
can we choose the elements of $\beta_{(i)}$ (those element which are arbitrary)  such  that  the orthogonal  functions $\{f_1(x) , f_2(x) , \ldots, f_{k+1}(x)\} $ generate 
the space $Span\langle 1,x,x^2,\ldots,x^k\rangle$ ?","['ordinary-differential-equations', 'orthogonal-polynomials', 'orthonormal', 'numerical-methods']"
625782,What is the value of Exponential Geometric Sum?,"The sum in question is 
$$\sum_{k=0}^\infty x^{a^k}. $$
This comes from a more difficult summation, but if I can find the value of this one then the other one is solved. Does anyone know the exact value of this? Any help in that direction would be really appreciated. The original problem is in this post: A tricky infinite sum-- solution found numerically, need proof $X Y^{\alpha} + X^2 Y^{\alpha + \alpha^2} +X^3 Y^{\alpha + \alpha^2 + \alpha^3} + ...=\sum\limits_{j = 1}^{\infty}X^j \prod\limits_{k = 1}^{j}Y^{\alpha^k}$
where $0 < \alpha < 1, 0 < X < 1$ and $Y>0$","['sequences-and-series', 'calculus']"
625795,Stone-Čech compactification of discrete space,"Let $X$ be a discrete space and $\beta X$ its Stone-Čech-compactification, given by $\overline{\iota(X)}$ where 
$$
\iota:\ X \to \prod_{f \in C(X,[0,1])} [0,1],\quad x \mapsto (f(x))_{f \in C(X,[0,1])}.
$$
I have already proven that the linear span of idempotent functions in $C_b(X,\mathbb R)$ lies dense in $C_b(X,\mathbb R)$ (in sup-norm). Since $X$ is discrete these are only the bounded functions. How can I use this fact to prove that $\beta X$ is totally disconnected, i.e. the connected components consist of only one point ? It would also be sufficient to prove that $\beta X$ is totally separated, i.e. if $x \neq y$ in $\beta X$ then there is a clopen $C \subset \beta X$ s.t. $y \notin C \ni x$. I would appreciacte some hints, in particular why we need idempotent functions.","['general-topology', 'compactness']"
625842,Product of positive matrices,"I have two positive-definite matrices $A$ and $B$ (not necessarily symmetric), and we have $AB=BA$, is there any theorem that ensures that the product of $A$ and $B$, $AB$ is positive definite? Or semi-positive definite?","['matrices', 'linear-algebra']"
625861,Prove $x^{2 \over 3} \ln(x)$ is uniformly continious,"Prove $x^{2 \over 3} \ln(x)$ is uniformly continuous in $(1,\infty)$ To my understanding I need to show the derivative is bounded. That will prove uniform continuity. The derivative is: $$ {2\ln(x) + 3} \over {3x^{1 \over 3}}$$ Now, I need to test the limit of the derivative at $\infty$ but I'm not sure how to do it.","['functions', 'continuity', 'real-analysis', 'limits']"
625898,Finding the diameter of a n-cube,Is there a general method that can be used find the diameter of a n-cube? In particular what if I want to find the diameter of a 4-cube can someone suggest me a method or hint. I would much appreciate it. Thanks,"['graph-theory', 'discrete-mathematics']"
625909,How to prove that $b_{2008}\neq 0$,"Let the polynomial $f$ be defined as
$$f(x)=a_{m}x^m+a_{m-1}x^{m-1}+\cdots+a_{1}x+a_{0}, \qquad a_{i}\in \Bbb Z \ (i=0,1,2,\cdots,m), \ a_{i}\neq 0.$$
Define the sequence $\{b_{n}\}$ as 
$$b_{1}=0,b_{n+1}=f(b_{n}).$$
Show that
$$b_{2008}\neq 0.$$ My try: let $x_{i},i=1,2,\dots,m$ be the complex roots of the polynomial $f(x)$, then
$$f(x)=a_{m}(x-x_{1})(x-x_{2})\cdots(x-x_{m})$$ Maybe this is Olympic math exam question, this is a problem my frend asked me.","['sequences-and-series', 'polynomials']"
625925,How to compute the similarity transformation matrix,"Stuck on this question: Let $$A=\begin{pmatrix}
2&1\\
-1&-1
\end{pmatrix}$$$$B=\begin{pmatrix}
-2&5\\
-1&3
\end{pmatrix}$$$$C=\begin{pmatrix}
5&2\\
4&1
\end{pmatrix}$$
  Show that A is similar to B, but that A is not similar to C. I can do the second part of the question as $det(A)\neq\det(C)$, therefore as similar matrices have the same determinant $A\nsim C$. I also understand that I need to find $P$ such that $AP=PB$ for the first part but have no idea how I would go about finding it.Would anyone be able to provide an answer and explanation of the method used? Thanks Edit:Had a look at the solution from the textbook, it gives $$P=\begin{pmatrix}
2&3\\
1&1
\end{pmatrix}$$",['linear-algebra']
625929,Laurent expansion of digamma function around $x=0$,"I want to check the validity for such a method Define the digamma function as $$\psi_0(x)=\frac{d}{dx}\left( \log \Gamma(x)\right)$$ $$\tag{1}\psi_0(x)=\frac{\Gamma'(x)}{\Gamma(x)}$$ It has the following series representation $$\tag{2} \psi_0(1+x)=-\gamma +\sum_{n\geq 1}\frac{x}{n(x+n)}$$ we can easily recognize the poles at negative integers using (2). Using the reflection formula  $$\Gamma(x)\Gamma(1-x)=\frac{\pi}{\sin(\pi x)}$$ We can prove $$\tag{3} \psi_0(1-x)-\psi_0(x)=\pi \cot(\pi x)$$
and $$\tag{4} \psi_0(1+x)-\psi_0(x)=\frac{1}{x}$$ plugging (4) in (2) we have $$\psi_0(x)+\frac{1}{x}=-\gamma +\sum_{n\geq 1}\frac{x}{n(x+n)}$$ Now if look at the sum on the left $$\sum_{n\geq 1}\frac{x}{n(x+n)} = \sum_{n\geq 1} \frac{x}{n^2} \frac{1}{1+\frac{x}{n}}$$ Assuming $|\frac{x}{n}| < 1$ and expand using geometric series $$\sum_{n\geq 1} \frac{x}{n^2}\sum_{k\geq 0}\left(\frac{-x}{n} \right)^k=-\sum_{n\geq 1} \sum_{k\geq 1} \frac{(-x)^k}{n^{k+1}}=-\sum_{k\geq 1}\zeta(k+1)(-x)^k$$ Hence we have $$\tag{5}\psi_0(x)=-\frac{1}{x}-\gamma-\sum_{k\geq 1}\zeta(k+1)(-x)^k $$ Which is the Laurent expansion of $\psi_0$ around $x=0$ giving a residue of $-1$. Question My concern was the geometric expansion and the swapping of two series. If $|x|<n$ then $|x|<1$ then the expansion is valid for any compact subset of $(-1,1)$ which justifies the uniform convergence of $\frac{(-x)^k}{n^{k+1}}$ by the $\text{M-test}$, hence swapping the two series. Then the Laurent expansion is valid on any annulus inside $(-1,1)$ avoiding $x=0$. Is that correct ? or am I missing something ?","['laurent-series', 'complex-analysis', 'special-functions', 'real-analysis']"
625939,Compute $\left (1+\frac{1}{2}+\cdots+\frac{1}{n} \right )^2+\cdots+\left (\frac{1}{n-1}+\frac{1}{n} \right )^2+\left (\frac{1}{n} \right )^2$,Compute the value of the following expression $$\left (1+\frac{1}{2}+\cdots+\frac{1}{n}  \right )^2+\left ( \frac{1}{2}+\cdots + \frac{1}{n}\right )^2+\cdots+\left (\frac{1}{n-1}+\frac{1}{n}  \right )^2+\left (\frac{1}{n}  \right )^2$$ The answer is $\boxed{2n-\left (1+\frac{1}{2}+\cdots+\frac{1}{n}  \right )}$. I've been trying to do it but I've been failed. Any ideas ? Wolfram's test,"['power-series', 'harmonic-functions', 'sequences-and-series', 'harmonic-analysis']"
625943,$H^1$ of a constant sheaf,"Let $X$ be an irreducible smooth curve, and $\underline{k(X)}$ the constant sheaf on $X$ with  the function field $k(X)$ as fibers. Reading from Serre's Algebraic groups and class fields I met the claim ($H$ denotes sheaf cohomology)
$$ H^1(X, \underline{k(X)}) = 0 $$
motivated by the sentence: ""the nerve of every open cover of $X$ is a simplex"". I don't know what the nerve of an open cover is, but anyway the above claim seems quite intuitive: an element of $H^1$ is a section of $\underline{k(X)}$ defined only on the intersection of pairs of opens of a cover of $X$. Such a local section, in our case, always comes from the restriction of a globally defined section. After all the sheaf is constant, and a global section consists of a collection of an arbitrary regular function for every point of $X$, with any kind of jumps allowed. Is my reasoning correct? Could you please help me to formalize it?","['sheaf-theory', 'algebraic-geometry', 'algebraic-curves']"
625946,Singular value decomposition of an arbitrary anti-symmetric ($A=-A^{T}$) complex matrix,"I am a physicist and very much used to the fact that any self-adjoint matrix ($H^{\dagger} =H$) in a finite-dimensional complex linear space can be uniquely specified by (a) the set of its (real) eigenvalues, and (b) the unitary matrix built from its (orthonormal) eigenvectors: $$H = U^{\dagger} \cdot \rm{diag}\{ h_1, h_2, \ldots h_n \} \cdot U$$ where $(\cdot)^{\dagger} \equiv (\cdot)^{*T}$ denotes conjugate transpose. I need a generalization of this for the classes of symmetric ($S^{T} =S$) and anti-symmetic  ($A=-A^{T}$) complex matrices. The symmetric case seems easy: $$S = U^{T}\cdot \rm{diag}\{ s_1, s_2, \ldots s_n \} \cdot U$$
where the singular values $s_1, s_2 \dots$ are non-negative reals and $U$  again is a generic the unitary matrix. (Here is a more precise statement , accounting for the extra choice of signs). But I have a difficulty identifying the general singular value decomposition structure for an arbitrary anti-symmetirc matrix . I've observed numerically that the rank of $A$ is at most $n-1$ EDIT: when $n$ is odd ($n$ is the dimensionality of the linear space), so generalization needs to be 'clever'. Can you help?","['matrices', 'linear-algebra', 'spectral-theory']"
625958,Borel subalgebras contain solvable radical,"Let $L$ be a Lie algebra and let $B$ be a Borel subalgebra (a maximal solvable subalgebra) of $L$. I want to understand why $\operatorname{Rad} L \subseteq B$. In his proof, Humphreys (Introduction to Lie Algebras and Representation Theory - pag 83) says that, since $B$ is a solvable subalgebra and $\operatorname{Rad}L$ is a solvable ideal of $L$, then $B+\operatorname{Rad}L$ is a solvable subalgebra. Why should it be true? I know in general that the sum of two solvable ideal is a solvable ideal, but I don't know how to apply this in my situation. Thanks.","['lie-algebras', 'abstract-algebra']"
625974,Taking Seats on a Plane: The General Case,"$n$ men are getting on a plane which contains $n+k$ seats. Each one has a seat number but among them, $m$ men forgot  his seat number. They get on the plane one by one. For person $X$ if he knows his seat number and if the seat is empty then he take it but if the seat if occupied then he chooses randomly a chair and sits. On the other hand if $X$ does not know his seat number them he chooses randomly a chair and sits.  What is the probability that the last $i$ persons sit on their proper seat!? (Those who forgot their seat number are not necessary the first $m$ persons who get on the plane) COMMENT: Some versions of this problem are posted to SE. You can see the following ones: Number 1 , Number 2 , Number 3","['probability', 'combinatorics']"
625988,$x_n$ convergence to $x$ implies $f_n(x_n)$ convergence to $f(x)$. prove that $f$ is continuous,"Let $f$ and $f_n$ be functions from $\mathbb{R} \rightarrow \mathbb{R}$ Assume that $f_n (x_n) \rightarrow f (x)$ as $n\rightarrow \infty$ whenever $x_n \rightarrow x$. Prove that $f$ is
  continuous. (Note: the functions $f_n$ are not assumed to be
  continuous.) Here is my approach to prove it :
Suppose $(x_n)\rightarrow x$. We want to prove $f(x_n)\rightarrow f(x)$ And perhaps we may write : $|f(x_n)- f(x)|\leq|f(x_n)- f_n(x_n)|+|f_n(x_n)-f(x)|$ We can control the second term in RHS, but I don't think there's a way to control the first absolute value. Another intuitive approach is working with diameter of the matrix of $f_n$ values.","['continuity', 'convergence-divergence', 'sequences-and-series', 'functional-analysis']"
626012,Find a probability integral,"For $0 <t<1$  express the integral
$$
\int_0^\pi \int_{\max\left\{-1;\cos x - \frac{t}{\sin x}\right\}}^{\cos x}  \frac{dy}{\sqrt{1-y^2}} \, dx
$$
as a function of $t$ (without any  integrals). I am sorry, but actually I don't know  any attempt  to do it.","['multivariable-calculus', 'calculus', 'probability', 'real-analysis']"
626024,Elementary proof of irreducibility criterion,"From ``Problems from the Book'' by Andreescu and Dospinescu, the following irreducibility criterion is presented: Let $f$ be a monic polynomial with integer coefficients and let $p$ be a prime.  If $f$ is irreducible over the integers, and $\sqrt[p]{(-1)^{\deg(f)} f(0)}$ is irrational, then $f(x^p)$ is also irreducible over the integers. I've reproduced the proof here.  I'd like to see an elementary proof that does not rely on field theory, if possible.","['alternative-proof', 'irreducible-polynomials', 'abstract-algebra', 'polynomials']"
626027,"If $f(x) \lvert f(x^m) (m \gt 1)$, then every root of $f$ must be $0$ or a root of unity.","If $f \in \mathbb{C}[x]$ satisfies $f(x)\ \lvert\ f(x^m)\ (m \gt 1)$, prove that every root of $f$ is either $0$ or a root of unity. My idea: let $\alpha$ be a root of $f$, show that $\alpha^{q} = \alpha$ for some natural number $q$. Let $\alpha$ be a root of $f$, then so is $\alpha^{m}$, because $f(x)\ \lvert\ f(x^m)$. Apply this fact repeatedly, it follows that the sequence
$$\alpha, \alpha^{m},\alpha^{m^2},\dots$$
contains only roots of $f$, therefore must contain a loop. That is, there is some $\beta = \alpha^{m^p}$ and a natural number $q$ such that $\beta^{q} = \beta$, thus either $\beta = 0$ or $\beta^{q-1} = 1$. But how to show that $\alpha$ is also contained in this loop?","['algebra-precalculus', 'polynomials']"
626030,Why the space of skew-symmetric tensors $\Lambda^{n}V$ is a one dimensional if $dim(V)=n$,"While reading Liviu Nicolaescu  Lectures on the geometry of manifolds, I came accross the notion of ""determinant line"": Definition: Lev $V$ be an n-dimensional R-vector space. The one dimensional vector space $\Lambda^{n}V$ is called the determinant line . Here, $\Lambda^{n}V$ is a space of skew-symmetric (a.k.a. antisymmetric) tensors. My question is why $\Lambda^{n}V$ is a one-dimensional vector space? I think that this has something to do with the fact that the degrees of the tensors in that spaces is equal to the dimension of $V$, i.e. $n=dim V$. But I cann't figure this one out. Any guidance would be very appreciated.","['vector-spaces', 'tensors', 'differential-geometry']"
626047,Probability of random functions where domain equals co-domain,"Given random function defined by $f: [n] \rightarrow [n]$, chosen uniformly, what is probability that the function is injective, surjective, or bijective? If $[n]$ is a set of discrete elements, then size of the domain is equal to the size co-domain. Therefore the total number of functions is $n^n$. The number of functions which have no repetition in mapping domain to co-domain is the ways to arrange the $n$ co-domain elements over the $n$ domain elements which is $n!$. These functions with no repetition are also injective, surjective, and bijective, and all others are not. So the probability is $\frac{n!}{n^n}$ for all three possibilities?","['random', 'elementary-set-theory', 'functions']"
626101,A partition of the unit interval into uncountably many dense uncountable subsets,"The title says it all: Is there a partition of $[0,1]$ into uncountably many dense uncountable subsets ?",['real-analysis']
626127,Example of a false proof when a Fourier series is not unique?,"I am attempting to come up with an example to illustrate why one should care that a function has a unique Fourier series expansion.  Inspired by the fact that one can rearrange terms in a conditionally convergent series to obtain any number they want, I'm hoping that if one has a function with a non-unique Fourier series expansion, then one can do something with that series to obtain some kind of false result.  Is anyone aware of such an example? Thank you.","['fourier-series', 'analysis']"
626128,Fabius function and equivalent,"The Fabius function $F$ can be defined on $[0,1]$ by $F(0)=0$ $F(1)=1$ on $[0,\frac{1}{2}]$ $F'(x)=2F(2x)$ on $[\frac{1}{2},1]$ $F'(x)=2F(2(1-x))$ It's a known example of a not analytic $C^\infty$ function. The Fabius function can also be defined as the CDF of the random variable $X$ such that $$X=\sum_{i=1}^\infty 2^{-i}U_i$$ where $U_i$ are independent random variables uniform on $[0,1]$ . Is it possible to find a usual function $f$ such that $$\lim_{x\rightarrow 0}\frac{F(x)}{f(x)}=1$$ Some functions like $f(x)=e^{-\frac{1}{x^2}}$ could be good candidates, but I don't really know how to find such a function, or given a function $f$ , how to compute the limit.","['special-functions', 'ordinary-differential-equations', 'probability-distributions', 'limits']"
626155,Is This Set of Zero Measure?,"Let $(X,\mathscr M,\mu)$ be a measure space and $(Y,\|\cdot\|)$ a separable Banach space with $\{y_n\}_{n=1}^{\infty}$ being a dense subset in it. Suppose that $f:X\to Y$ is a Borel measurable function and $$\int \|f(x)\|\,\mathrm d\mu<+\infty.$$ Suppose also that the sets $(E_{nj})_{n,j=1}^{\infty}$ in $X$ are such that all of them are in $\mathscr M$ and their measures are finite; for any given $j\in\mathbb Z_+$, $(E_{nj})_{n=1}^{\infty}$ are disjoint and their union gives $\{x\in X\,|\,f(x)\neq 0\}$; if $x\in E_{nj}$, then $\|y_n-f(x)\|<1/j\cdot\|y_n\|$. What I want to show is that the set $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$
is of measure zero (the notation $\sqcup$ emphasizes that the union is one of disjoint sets). I'm afraid I cannot use a limiting argument that exploits measures being continuous from above, as the sets
$$\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$
may be of infinite measure for all $\ell\in\mathbb Z_+$. In particular, if $\|f(x)\|>0$ for all $x\in X$ and $\mu(X)=+\infty$, then this fear is justified, as $X=\bigcup_{n=1}^{\infty} E_{nk}$ for all $k\in\mathbb Z_+$ by the second assumption above. If it is of any help, we know also that for any $\varepsilon>0$, the following holds: $$Y\setminus\{0\}\subseteq\bigcup_{n=1}^{\infty}\left\{y\in Y\,\big|\,\|y_n-y\|<\varepsilon\|y_n\|\right\}.$$ More generally (it would be enough for my purposes), is it possible to choose a map from $\mathbb Z_+$ to itself $k\mapsto N_k$ such that $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=N_k+1}^{\infty}E_{nk}$$
is of measure zero? Any suggestion will be dearly appreciated.","['measure-theory', 'functional-analysis']"
626165,Almost sure convergence of harmonic mean,"Let $X_1,...,X_n \sim Uniform(0,1)$. Harmonic mean is defined as: $H_n = \frac {n}{\sum_{i=1}^n\frac{1}{X_i}}$ Find a.s. limit of this as $n \rightarrow \infty$ I already did the problem for both arithmetic and geometric means which relied on SLLN and CMP theorems. In the case of harmonic mean expectation of $1/X_i$ is infinite so I can't use SLLN.
I feel like the limit should be 0 but I'm at a loss.","['convergence-divergence', 'expectation', 'probability-theory', 'law-of-large-numbers', 'almost-everywhere']"
626184,Automorphism group of an L-function,"I define the notion of Galois class of L-functions as follows: $A$ is a Galois class of L-functions if and only if the following conditions simultaneously hold true: 1) $A$ is a subset of the Selberg class containing the constant function equal to $1$ 2) whenever $F$ and $G$ are elements of $A$, then so is $F.G$ 3) every element of $A$ factors in a unique fashion as a product of primitive elements of $A$ Then I denote $M$ the maximal Galois class of L-functions (conjecturally equal to the whole Selberg class) and define its group of automorphisms (under composition) $Aut(M)$ as follows: $\Phi$ is an automorphism of $M$ if and only if the following conditions simultaneously hold true: 1) $\Phi$ is a bijective map from $M$ to itself 2) $\forall F\in M$, $deg(\Phi(F))=deg(F)$, where $deg(F)$ is the degree of $F$ as an element of the Selberg class 3) $\forall (F,G)\in M^{2}$, $\Phi(F.G)=\Phi(F).\Phi(G)$ 4) $\Phi$ maps a primitive element of $M$ to a primitive element of $M$ Given an element $F$ of $M$ of degree $d$, one can write $F=\prod_{i=1}^{n}F_{i}^{e_i}$ where $\forall 1\leqslant i\leqslant n$ $F_{i}$ is a primitive element of $M$ and $e_{i}$ is a positive integer. Let's consider the group $G_{F}$ (under composition) of automorphisms of $M$ preserving $F$. Suppose there exists a Galois extension $\mathbb{K}_{F}$ of $\mathbb{Q}$ of degree $d'$ such that $G_{F}$ is either isomorphic to $Gal(\bar{\mathbb{K}}_{F}/\mathbb{K}_{F})$ or to $Gal(\bar{\mathbb{Q}}/\mathbb{K}_{F})$. Is it true that $d=d'$? Thanks in advance. EDIT January 4th 2014: Suppose it's true that $d=d'$. Is $Gal(\mathbb{K}_{F}/\mathbb{Q})$ a finite simple group if and only if $F$ is primitive? It would be true for $d=d'=1$ since degree $1$ elements of the Selberg class are exactly the Riemann Zeta function and the Dirichlet L-functions which are known to be primitive. More generally is $Gal(\mathbb{K}_{F}/\mathbb{Q})$ the product of $n$ finite simple groups if and only if $F$ is the product of $n$ primitive elements of the Selberg class?","['galois-theory', 'number-theory']"
626185,Almost sure convergence of a product of random variables,"Let $X_1, X_2, ...$ be a sequence of random variables such that: $X_i = \begin{cases} 1 &\mbox{with probability } p = 1-1/n^2 \\ 
2 & \mbox{with probability } p = 1/n^2 \end{cases} $ and let $Y_n=\Pi_{i=1}^n X_i $. Show that $Y_n$ converges almost surely to some random variable $Y$. I already know several methods of proving a.s. convergence to a constant. However, I do not know how to establish convergence to a non-constant random variable except for definition which does not seem to work in this case.","['convergence-divergence', 'random-variables', 'probability-theory', 'almost-everywhere', 'probability']"
626191,"the distribution of distance between two random points from $U(0,1)^3$","Suppose $x_1$ and $x_2$ are two uniformly distributed points from unit cube $(0,1)^3$, what's the distribution of the distance between $x_1$ and $x_2$?
I did a quick simulation and find that this distribution's kurtosis is 2.5, smaller than 3. can anyone help me with a closed form pdf? thanks.","['probability-distributions', 'probability']"
626216,Find the $n^{\rm th}$ digit in the sequence $123456789101112\dots$ [duplicate],"This question already has an answer here : $n$-th digit in the sequence of natural numbers (1 answer) Closed 6 years ago . Basically, the question asks us to find the nth digit in the following sequence: $$12345678910111213\dots9899100101\dots$$ where the 10th digit is $1$, the 11th digit is $0$, etc. EDIT: Here are my workings:
I was thinking about defining intervals in some way, for example, I know that there are 9 digits in this interval $0\dots9$ and $10\dots99$, and later try to find a sum. However, I am stuck on this point.","['elementary-number-theory', 'sequences-and-series']"
626247,Simplified Averages - Always true?,"While working on an ""average rating"" function for a website, I came across an idea for simplified averages, but I want to confirm that it always works.  If it does, I might be able to keep a running average (accurately updating the average as new ratings are submitted) while only storing the current average and the number of ratings (rather than storing every rating individually so you can re-average them later). The question is this: is the average of a given set of numbers always equal to the average of the final number with the average of the rest of the set, included as many times as the rest of the set?  In other words, is this ALWAYS true: AVG(x,y,z) = AVG( AVG(x,y) , AVG(x,y) , z ) or AVG(a,b,c,d) = AVG( AVG(a,b,c) , AVG(a,b,c), AVG(a,b,c) , d ) and so on, with any number of variables? One final note: I'm fairly good with math, but I have basically no experience with proofs and such, and the math here is just complex enough for me not to be quite able to answer it definitively myself.  Any insight will be appreciated, but bonus points will be given for small words and simple explanations.  Thanks!","['average', 'algebra-precalculus']"
626266,Prime ideals in a principal ideal ring,"I know that in a principal ideal DOMAIN every $\neq 0$ prime ideal is maximal. is this also true for just a commutative principal ideal ring? It seems to be true for $\mathbf{Z}/n\mathbf{Z}$ ($>1$, is always a PIR) innit? as every finite integral domain is a field.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
626325,"Calculate the determinant of the $2n \times 2n$ matrix with entries equal to zero on the main diagonal, $1$ below and $-1$ above [duplicate]","This question already has answers here : Determinant of a special skew-symmetric matrix (6 answers) Closed 10 years ago . Calculate the determinant of the $2n \times 2n$ matrix with entries equal to zero on the main diagonal, equal to $1$ below and equal to $-1$ above.
I'll denote this matrix $A_{2n}$. So for example you have $A_{2} = \begin{bmatrix}
        0 & -1  \\
        1 & 0  \\
              \end{bmatrix} 
$ and $A_{4}= \begin{bmatrix}
        0 & -1 & -1  &-1 \\
        1 & 0  & -1  & -1\\
        1 & 1  & 0   & -1 \\
        1 & 1  & 1   & 0\\
        \end{bmatrix}
$ From trying it out by hand I think you have $\det(A_{2n})=1$ for all odd $n$ , or $=-1$ for all even $n$. Can anyone come up with some way to prove this? From doing these two examples my algorithm seems to be something like this: Switch the first and second rows (multiplies det by $-1$) If the matrix is now upper triangular, calculate the  determinant by product of main diagonal. If not, make a new pivot and clear that column below. Swap the third and fourth rows (multiplies det by $-1$). Repeat from 2.","['matrices', 'linear-algebra', 'determinant']"
626334,"""Proof"" that $g(t) = (t,t,t,...)$ is not continuous with uniform topology","Let $g : \mathbb R \to \mathbb R^{\omega}$ be the function
$$
 g(t) := (t, t, t, \ldots).
$$
If $\mathbb R^{\omega}$ is equipped with the uniform topology, and $\mathbb R$ with the standard topology, then is $g$ continuous? According to this post it is. I have a different proof which yields another conclusion, but I cannot see whats wrong with the proof? Let $Y = \prod_{i=1}^{\infty} Y_i \subseteq R^{\omega}$, then
$$
 g^{-1}(Y) = \bigcap_{i=1}^{\infty} Y_i.
$$ Proof: Let $x \in g^{-1}(Y)$, then $g(x) = (x,x,x,\ldots) \in Y$ and so $x \in Y_i$ for all $i$, thus $x \in \bigcap_{i=1}^{\infty} Y_i$. Conversely let $x \in \bigcap_{i=1}^{\infty} Y_i$, then $g(x) = (x,x,x,\ldots) \in \prod Y_i = Y$, and so $x \in g^{-1}(Y)$. $\square$ A basis set $B(x,r)$ in the uniform topoloy on $\mathbb R^{\omega}$ has the form
$$
 B(x,r) = \{ y = (y_i) : |x_i - y_i| < r \mbox{ for all }i \}
        = \prod_{i=1}^{\infty} B(x_i, r) = \prod_{i=1}^{\infty} (x_i - r, x_i + r)
$$
so in particular for $x = (1,1/2,1/3,\ldots)$ the set
$$
 B(x, 1) = \prod_{i=1}^{\infty} \left( \frac{1}{n} - 1, \frac{1}{n} + 1 \right)
$$
is open in the uniform topology. But
$$
 g^{-1}(B(x,1)) = \bigcap_{i=1}^{\infty} \left( \frac{1}{n} - 1, \frac{1}{n} + 1 \right) = (0,1]
$$
is not open, so $g$ is not continuous? What goes wrong here....","['general-topology', 'metric-spaces', 'analysis']"
626340,"Formula for the number of ""addition constructions"" of a positive integer","I was working on a cool maths problem and got inspired from one of the mini lemmas I had to make up in order to solve the problem. From then on, I have been trying to find a formula which for any positive integer, gives the number of ways it can be ""built"" as a sum of smaller positive integers. Example: for 5, you can have: 1+1+3, 2+3, 1+4, 1+1+1+1+1, etc. Finding a formula that regards (example) 1+1+3, 3+1+1 and 1+3+1 as unique ""constructions"" proved to be not too hard (in fact I re-discovered ;P 2 formulas) but finding a formula for my original aim is proving exceedingly difficult for me. Please (I don't wan't to spoil the fun and look the answers up on wikipedia or something), given a high school education in maths, could one potentially attain the formula (as I have been trying for very long now) or am I wasting my time and should I look up the answer (as it is far too advanced???)? Thank you.","['elementary-number-theory', 'combinatorics']"
626342,Are there any known uncountable transfinite increasing sequences of real numbers?,"The real numbers are uncountable, so assuming the axiom of choice there is at least transfinite sequence of real numbers $r_0, r_1, r_2, ..., r_\omega, r_{\omega + 1}, ..., $ up to (and possibly including) $r_{\omega_1}$ that contains an uncountable number of terms. However, it's not guaranteed that $r_0 < r_1 < ..., r_\omega < ...$ Is there a known transfinite sequence of real numbers that is monotonically increasing and which contains uncountably many real numbers? Thanks!","['elementary-set-theory', 'real-analysis', 'order-theory']"
626347,Definition of Banach limit,"In my Bachelor Thesis I have defined a Banach limit as a functional $\operatorname{LIM} : l^\infty (\mathbb{N})\rightarrow \mathbb R$ that has the following properties: B1 If $(x_n)$ is a convergent sequence, then $\operatorname{LIM}(x_n)=\lim_{n\to \infty} x_n$. B2 If $x_n\geq 0$ for all $n\in\mathbb N$, then $\operatorname{LIM}(x_n)\geq 0$. B3 $\forall\alpha,\beta\in\mathbb{R}\forall (x_n),(y_n)\in l^\infty(\mathbb{N})[\operatorname{LIM}(\alpha (x_n)+\beta (y_n)) = \alpha \operatorname{LIM}((x_n)) + \beta \operatorname{LIM}((y_n))]$. B4 If $y_n=x_{n+1}$ for all $n\in\mathbb{N}$, then $\operatorname{LIM}((x_n))=\operatorname{LIM}((y_n))$. My supervisor thought that the condition B2 might not be necessary, because maybe it followed from the other conditions. I've looked up a lot of definitions of Banach limits, but they're all a little different, which makes it hard to compare sometimes. But it looks like most of the time, the conditions are at least as strong as mine. I have not been able to prove that B2 is necessary, nor have I been able to find a counterexample. Can anybody tell me if the other three conditions are sufficient? If not, can you give me a counterexample? I figured that maybe I haven't been able to find a counterexample, because there are only non-constructive counterexamples.","['functional-analysis', 'real-analysis']"
626351,"Express $\int_0^1\frac{dt}{t^{1/3}(1-t)^{2/3}(1+t)}$ as a closed path integral enclosing the interval $(0,1)$","From an old complex analysis qualifier: Define $$I=\int_0^1\frac{dt}{t^{1/3}(1-t)^{2/3}(1+t)}.$$ Express $I$ as a closed path integral enclosing the interval
  $(0,1)$. Evaluate $I$. Ideas: At first I thought this was an exercise in the Schwarz-Christoffel integral, but now I'm not so sure. I'm thinking I'm just not aware of the method they're suggesting, and I was hoping someone could point me to it. Thanks","['integration', 'complex-analysis']"
626355,Inverse of a matrix,"I'm trying to show that 
\begin{equation}
P^H ( I_M + PBP^H) ^{-1} P = \big( (P^H P)^{-1} + B \big)^{-1},
\end{equation}
where $P$ is an $M$-by-$N$ matrix, $I_M$ is the $M$-by-$M$ identity matrix, $B$ is an $N$-by-$N$ matrix, and $(P^H P)$ is invertible. I've used various versions of matrix inversion lemmas, but I'm stuck. How can the above equality be shown?","['matrices', 'linear-algebra']"
626363,Entire $f$ and $g$ constant if $e^{f(z)}+e^{g(z)}=1$,Suppose we have entire functions $f$ and $g$ that satisfy $e^{f(z)} + e^{g(z)} = 1 $ for all complex values $z$.  Show that $f$ and $g$ are constant.,['complex-analysis']
626377,Show that B is measurable,"Let $\mathbf{g}:\Delta \subset \mathbb{R}^n \rightarrow D\subset \mathbb{R}^n $ be univalent, $C^{(1)}$ and with the Jacobian different from zero, $\forall t \in \Delta$. Let $B=\mathbf{g}^{-1}(A)$, where $A$ is a measurable (Lebesgue) subset of $D$. Show that B is measurable. There is hint which is to first consider the case when $A\subset L\subset D$, where $L$ is compact.  And also, from another exercise, we proved that for this g, and for a compact $L$, and a number $C$ (proved in yet another exercise), if $B\subset int(L)$, then $V(A)=V[\mathbf{g}(B)]\leq C^n V(B)$. And the last part of the exercise is to find compact sets $L_1 \subset L_2 \subset \dots$ with union $D$. We know that $\mathbf{g}^{-1}$ will also have the Jacobian different from zero. So, I was thinking of using this last theorem this time to $\mathbf{g}^{-1}$, resulting in a different upper bound number $Q$, we would get $V(B)=V[\mathbf{g}^{-1}(A)]\leq Q^n V(A)$... But this doesn't seem to help at all. I have no idea how to prove that it's measurable. The hints seem only help me prove what would be the measure of B (bounds of the measure) instead of trying to prove that B has a measure. I'm probably not understanding something... Any help would be appreciated. Thanks in advance. P.S.: This is an exercise taken from Wendell Fleming's Functions of several variables, page 216, exercise 8. (It uses exercise 6 and 7) http://en.bookfi.org/book/580162","['multivariable-calculus', 'measure-theory', 'lebesgue-measure']"
626390,clarification about theorem $3.10 $ of Brezis functional analysis book.,"I'm referring to the theorem at page $61$. It shows that for a linear operator $T $ between $E $ and $ F$ Banach space are equivalent
(notation: $S$ means strong topology, the norm ome, $W $ weak topology) $T$ is continuous from $ E, S $ to $F, S$ $T$ is continuous from $E, W$ to $F, W$ $T$ is continuous from $E, S$ to $F, W$ Where by $E, S$ i mean $E$ equipped with the strong topology.
My question is why the same argument is not valid for $T$ between $E, W $ to $F, S$?
I don't know what doesn't work.","['functional-analysis', 'banach-spaces']"
626401,Residue at infinity,This is an old qualifying exam problem: Suppose $f$ is entire and $a < b$.  Show that the residue of $$ f(z) \log \frac{z-b}{z-a} $$ at infinity is $\int_a^b f(x)dx$.,['complex-analysis']
626425,"Given a perturbation of a symmetric matrix, find an expansion for the eigenvalues","Let $A$ be a real, symmetrix $n\times n$ matrix with $n$ distinct,
  non-zero eigenvalues, and let $V$ be a real, symmetric $n\times n$
  matrix. Consider $A_{\varepsilon}=A+\varepsilon V$, a perturbation of $A$, where
  $\varepsilon$ is a small number. Find an expansion as an $\varepsilon$-series for the eigenvalues and
  eigenvectors of $A_{\varepsilon}$ around the eigenvalues and
  eigenvectors of the original matrix, $A$. Assume that $\epsilon$ is sufficiently small that one can neglect
  all terms of order $\varepsilon^2$ and higher in the expansion. How
  close are the eigenvalues of $A_{\varepsilon}$ to those of $A$? What
  about the eigenvectors? What can we say about the eigenvalues and eigenvectors of
  $A_{\varepsilon} $ if $A$ and $V$ are arbitrary $n\times n$ matrices?
  You may assume that $\det A \neq 0$. Ideas : If $A$ and $V$ commute (thus are simultaneously diagonalizable), there are just the linear term $\varepsilon v_{ii}$, when we look with the right basis. I'm getting the feeling I really don't know what they want me to do with this problem. Any ideas?","['matrices', 'power-series', 'linear-algebra']"
626465,The Hairy ball theorem and Möbius transformations,"I  just came across a chapter in Needham's Visual complex analysis ; in particular, these diagrams: ( p. 153 - these happen to be on the cover as well) They represent families of Möbius transformations acting on the Riemann sphere . The pictures reminded me of the famous Hairy ball theorem : one could imaging the combing as being a combined effect of the above transformations. The more striking connection is that they completely agree with the theorem: any such transformation has at least one fixed point. Is there an underlying connection here, either with the theorem itself or perhaps a dumbed-down version of it? PS: I know little about the actual proof of the theorem $-$ please forgive me if the connection (or absence thereof) is obvious.","['vector-spaces', 'complex-analysis']"
626482,Compare the integrals $\int_0^{\frac{\pi}{2}}\sin(\cos x)dx$ and $\int_0^{\frac{\pi}{2}}\cos(\sin x)dx$,"Compare the following two integrals: $$\int_0^{\frac{\pi}{2}}\sin(\cos x)dx,\quad \int_0^{\frac{\pi}{2}}\cos(\sin x)dx$$ First I observe that by making the change of variable $x=\frac{\pi}{2}-x$,we have $$\int_0^{\frac{\pi}{2}}\sin(\cos x)dx=\int_0^{\frac{\pi}{2}}\sin(\sin x)dx$$ Then I consider the function $f(x)=\sin(\sin x)-\cos(\sin x)$,after some simplification we have $$f(x)=\frac{1}{\sqrt{2}}\sin(\sin x-\frac{\pi}{4})$$ Then I tried to determine the sign of $\int_0^{\frac{\pi}{2}}f(x)dx$ and I don't know how to proceed.","['definite-integrals', 'inequality', 'integration', 'real-analysis']"
626484,Show that $\frac{1}{2}-\frac{1}{2e}<\int_0^{+\infty}e^{-x^2}dx<1+\frac{1}{2e}$,"Show that $$\frac{1}{2}-\frac{1}{2e}<\int_0^{+\infty}e^{-x^2}dx<1+\frac{1}{2e}$$ I know that one way to do this is to evaluate the integral in the middle, and then compare these three numbers. I wonder how can we do this without explicitly compute the integral?","['calculus', 'integration', 'real-analysis']"
626488,Find all entire functions $f(z)$ such that $|f(z)|=1$ for $|z|=1$ [duplicate],"This question already has answers here : Characterizing non-constant entire functions with modulus $1$ on the unit circle (5 answers) Closed 4 years ago . Find all entire functions $f(z)$ such that $|f(z)|=1$ for $|z|=1$ Hint: First show that $f(z)$ is a polynomial. Clearly one can not use Cauchy Estimates to prove that $f(z)$ is a polynomial, the other way is to prove that $f(z)$ has a pole at infinity which I am not sure how to prove that, are there any other ways to prove that a given entire function is a polynomial ? Thank you !",['complex-analysis']
626492,Analytic function taking prescribed values,"From Ahlfors, exercise 5.2.3 #1: Suppose that $a_n\to \infty$ and that the $A_n$ are arbitrary complex
  numbers. Show that there exists an entire function $f(z)$ which
  satisfies $f(a_n)=A_n$. Hint: Let $g(z)$ be a function with simple zeros at the $a_n$. Show that $$\sum_{n=1}^\infty g(z)\frac{e^{\gamma_n(z-a_n)}}{z-a_n}\cdot
 \frac{A_n}{g'(a_n)}$$ converges for some choice of the numbers
  $\gamma_n$. I see that $$\lim_{z\to a_i}g(z) \frac{e^{\gamma_n(z-a_n)}}{z-a_n}\cdot \frac{A_n}{g'(a_n)}=\begin{cases} A_n&n=i\\0&n\neq i \end{cases}$$ for any choice of $\gamma_n\in \mathbb{C}$, so the terms do what we want. In trying to choose $\gamma_n$ to ensure convergence, it doesn't seem like just a matter of making $\gamma_n$ be real numbers going to $-\infty$, for instance, since $e^{-z}$ takes every value in a neighborhood of infinity, not just values of small modulus. So we have to figure a way to use some symmetry to get the different $e^{\gamma_n(z-a_n)}$ to cancel, right?","['sequences-and-series', 'complex-analysis']"
626509,"For non-negative iid random variables, show that the max converges ip","From Resnick's A Probability Path , exercise 6.7.11.  (Studying for my comprehensive exam.) Suppose $\{X_n, n \ge1\}$ are iid and non-negative and define $M_n=\bigvee^n_{i=1}X_i$. a) Check that $P[M_n > x] \le nP[X_1 > x].$ b) Show that if $E(X^p_1) < \infty$, then $\frac{M_n}{n^{1/p}} \stackrel{p}{\to} 0.$ I did part a:
\begin{equation}
[M_n > x] \subseteq \bigcup^n_{i=1}[X_i>x] \\
P[M_n > x] \le P\left(\bigcup^n_{i=1}[X_i>x]\right) \le \sum^n_{i=1}P[X_i>x] = nP[X_1>x]
\end{equation} Part b is giving me trouble--I must be missing something!  I assumed that part (a) was meant to be used in part b: \begin{align}
P\left(\left|\frac{M_n}{n^{1/p}}-0\right|>\epsilon\right)&=P[M_n > n^{1/p}\epsilon]\\
&\le nP[X_1>n^{1/p}\epsilon]\\
&=nP[X_1^p > n\epsilon^p]\\
&\le \frac{E(X_1^p)}{\epsilon^p} \nrightarrow0.
\end{align} Now, I recognize that although Markov's inequality does not push the probability to zero doesn't mean that the probability actually fails to converge to zero, but it seems as if the author is implying I should use the inequality from part (a), which naturally seems to lead to Markov.  What am I missing here?","['probability-theory', 'independence']"
626534,probability that two randomly chosen numbers are coprime [duplicate],This question already has answers here : Probability that two random numbers are coprime is $\frac{6}{\pi^2}$ (2 answers) Closed 2 years ago . Is this question well posed? See here for the solution Probability that two random numbers are coprime I have also seen it in some contests. The question asks to compute $p=\lim p_n$ where $p_n$ is the probability that two random chosen integers less than $n$ are coprime. There is no way to associate a uniform distribution to integers; so I would hesitate to call this limit a probability. So is there any rigorous way to understand this limit as a probability of some event? See also this post What's the mean of all real numbers? where it is mentioned (and I agree) that the mean of reals (or integers) is undefined. But one could in the same way define a uniform distribution for reals or integers with absolute value less than $x>0$ and take the limit of the mean as $x$ goes to infinity. Then the mean of reals would be $0$.,"['probability', 'real-analysis']"
626537,Graphs of functions with fractional powers: $x^{p/q}$,"How does changing the value of $\dfrac{p}{q}$ affect the drawing of the graph (domain/range/shape, etc.)
How do you calculate asymptotes? Below is a question dealing with this type of function. Can someone please refer to the explanations on how to go about solving these questions?
I have no idea because I don't understand these graphs","['fractions', 'graphing-functions', 'algebra-precalculus', 'functions']"
626564,Let $R$ be a commutative ring with $1$. Suppose that every nonzero proper ideal of $R$ is maximal. Prove that there are at most two such ideals.,Let $R$ be a commutative ring with $1$ . Suppose that every nonzero proper ideal of $R$ is maximal. Prove that there are at most two such ideals. Help me some hints. I have no idea to start.,"['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
626568,Subspace of Tempered Distributions,"Let ${S_{h}}'(\mathbb{R}^{n})$ be the space of tempered distributions such that if $u\in {S_{h}}'(\mathbb{R}^{n})$, then $\lim_{\lambda\rightarrow \infty}{||\phi(\lambda D)u||_{\infty}} = 0$ for all $\phi$ compactly supported smooth functions. For $\phi \in C_{c}^{\infty}(\mathbb{R}^{n})$, we define $\phi(\lambda D)u$ by the Fourier transform $F[\phi(\lambda D)u] = \phi(\lambda t)F[u](t)$. What do distributions in this subspace behave like? Also, how can I show that any function in $L^{p} + L^{q}$ belongs to this subspace for $p$ and $q$ finite? What happens in the case of $L^{\infty}$?","['functional-analysis', 'fourier-analysis', 'real-analysis', 'analysis', 'lp-spaces']"
626624,Existence of Inverse of a Matrix,"Let $A_{m\times n}$ be an $m\times n$ matrix (over a field $k$). Suppose there exist matrices $B_{n\times m}$ and $C_{n\times m}$ such that $AB=I_{m}$ and $CA=I_{n}$. We should expect first that $m=n$ and then $B=C$. This can be proved by considering the matrices as linear transformations on appropriate vector spaces, and using rank-nullity theorem. But, while studying a book named ""Matrices"", I raised Question: Can we prove $m=n$ by considering ""only matrices"" and not linear transformations and vector spaces? (This question may have been appeared in stackexchange, but I didn't find this question. )","['matrices', 'linear-algebra']"
626627,Series comparisons and logarithms?,"Prove the convergence of $$
\sum_{n = 1}^{\infty}
{\sqrt{\, 2n - 1\,}\,\ln\left(4n + 1\right) \over n\left(n+1\right)}
$$ I've been struggling for hours on this. By the textbook we have the limit test, comparison test, asymptotic test and integral test. When I use the asymptotic test my quotient ends up as $0$ or $\infty$, and I cannot prove anything. Since I am self studying, I have no one to turn to. The rest of the questions were easy, but I cant figure this out. Please help!","['logarithms', 'convergence-divergence', 'sequences-and-series']"
626649,Ideal Generated by the Union of Two Ideals,"Let $I$ and $J$ be ideals of a ring $R$. Prove that $I+J$ is an ideal of $R$ and that $I+J=\langle I\cup J\rangle$, the ideal of $R$ generated by $I\cup J$.","['ideals', 'abstract-algebra']"
626660,Is there an everywhere-defined function that satisfies $f(x+y)=\frac{f(x)+f(y)}{1-f(x)f(y)}$,"Is there a function $f:\mathbb{R}\to\mathbb{R}$ which is differentiable and satisfies the following: (1) $f(x+y)=\frac{f(x)+f(y)}{1-f(x)f(y)}$ (2) $f'(0)=1$ (1) is the functional equation for $\tan$ function, but $\tan x$ is not defined at $\frac{\pi}{2}+n\pi$, so $f$ cannot be the $\tan$ function. Then does such $f$ exist?","['trigonometry', 'real-analysis', 'functional-equations']"
626664,"Why, conceptually, is it that $\binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r}$? [duplicate]","This question already has answers here : why is ${n+1\choose k} = {n\choose k} + {n\choose k-1}$? [duplicate] (3 answers) What's the intuition behind this equality involving combinatorics? [duplicate] (2 answers) Closed 10 years ago . Why, conceptually, is it that $$\binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r}?$$ I know how to prove that this is true, but I don't understand conceptually why it makes sense.","['intuition', 'binomial-coefficients', 'combinatorics']"
626675,Integration of progressively measurable process,"Let $X=\{X_{t},\cal{F}_{t}; 0\leq t<\infty\}$ be a progressively measurable process and $f(t,x):[0,\infty)\times \mathbb{R}^{d}\rightarrow \mathbb{R}$ be a bounded, $\cal{B}([0,\infty))\otimes \cal{B}(\mathbb{R}^{d})$-measurable function. Show that the process $Y_{t} =\int_{0}^{t}f(s,X_{s})ds; t\geq0$ is progressively measurable with respect to $\{\cal{F}_{t}\}$","['stochastic-processes', 'measure-theory', 'integration']"
626693,Disproving $A \subset B \wedge B \cap C \neq \varnothing \Rightarrow A \cap C \neq \varnothing$,"Let $A,B,C$ be any sets. Tell if $A \subset B \wedge B \cap C \neq \varnothing \Rightarrow A \cap C \neq \varnothing$ is true or false. I tried to prove by absurd. Suppose $A \subset B \wedge B \cap C \neq \varnothing$ and $A \cap C = \varnothing$ (absurd). Let $x \in A$, so by the hypothesis $x \notin C$. By the hypothesis one have $A \subset B$, so $x \in B$. Because $x \notin C$, one have $x \notin B \cap C$. But by hypothesis one have, $B \cap C \neq \varnothing$. So there exist a $p$ such that $p \in B \cap C$ and $p \notin A$. I know that this thought doesn't prove/disprove the statement. But can it help to show a counterexample? Let $A=\{1,2,3\}$, $B= \{1,2,3,4 \}$ and $C=\{4\}$. By this counterexample one can say that the statement is false. Can someone give me a hint on how to complete the proof whithout the counterexample? Thanks.","['logic', 'elementary-set-theory', 'proof-verification']"
626732,"Linear regression: degrees of freedom of SST, SSR, and RSS","I'm trying to understand the concept of degrees of freedom in the specific case of the three quantities involved in a linear regression solution, i.e. $SST=SSR+SSE, $ i.e. Total sum of squares = sum of squares due to regression + sum of squared errors, i.e. $\sum(y_i-\bar y)^2=\sum(\hat y_i-\bar y)^2+\sum(y_i-\hat y_i)^2$. I tried Wikipedia and thought I had understood why the first (SST) and the third (SSE) have (n-1) and (n-2) degrees of freedom respectively, but I could not make out why (SSR) has 1 degree of freedom. So maybe I did not understand degrees of freedom after all. Can someone explain? Thank you! Sources: http://en.wikipedia.org/wiki/Degrees_of_freedom_%28statistics%29 http://www.cs.rice.edu/~johnmc/comp528/lecture-notes/Lecture9.pdf","['statistics', 'regression']"
626743,$\lim_{k \to \infty} A^k$ where $A$ is diagonalizable,"I'm reviewing diagonalization and am wondering if the following makes sense. Let $A \in \mathcal{M}_{n \times n}(\mathbb{R})$ be a diagonalizable matrix. That is, there exist matrices $D$ and $P$ such that $$
A = PDP^{-1}
$$ where the columns of $P$ are linearly independent eigenvectors of $A$ and the $D$ is a diagonal matrix whose diagonal entries are the eigenvalues of $A$ (repeated based on their respective multiplicities). Does it follow that $$
\lim_{k \to \infty} A^k = 0
$$ if each eigenvalue of $A$ is in the range $(-1, 1)$? My reasoning is that (from elementary linear algebra) we can show that $$
A = PD^kP^{-1}
$$ if $A$ is diagonalizable. Since $P$ and $P^{-1}$ are finite, the product should approach zero since each (diagonal) entry of $D$ will approach zero since $$
\lim_{k \to \infty} \lambda^k = 0
$$ if $-1 < \lambda < 1$. Does this make sense or is my reasoning flawed?","['diagonalization', 'linear-algebra', 'limits']"
626745,Tangents at singularities,Given an implicit polynomial function $f$ with singularity at the origin. How do I find the tangents to the curve at the point? Wikipedia says that ignore all the terms except the ones with lowest degree. Why is this true? Take for example the curve $x^3+x^4+y^3=0$. What are the tangents at the origin?,"['multivariable-calculus', 'algebraic-geometry', 'differential-geometry']"
626763,Evaluate: $I=\int\limits_{0}^{\frac{\pi}{2}}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx$,Evaluate: $$I=\int\limits_{0}^{\frac\pi2}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx$$,"['definite-integrals', 'calculus', 'integration']"
626781,Question about bisection method,"We have $f(x)=(x-1)^3(x-2)(x-3)$. $a_0<1,b_0>3$. We had to show that if $\frac{a_0+b_0}{2}\ne 1,2,3$, there is one root of $f$ that we can't get it by the bisection method. I guess that this is $2$, I did few tests and I never get $2$, but I didn't understand why... Can you help me please, Thank you!","['calculus', 'roots', 'functions']"
626785,How find this $DF=?$,"In diamond $ABCD$,such $\angle B=\dfrac{\pi}{3}$,and the point $E$ in on $BC$.such
$BE=3CE$,and the point $F$ is on $DE$,such $\angle AFC=\dfrac{2\pi}{3}$ Find $$DF=?$$ My try: since
$$\angle B+\angle AFC=\pi$$
so
$A,B,C,F$  is cyclic and follow I can't",['geometry']
626797,Functional equation with function defined on $\mathbb{N}^{*}$,"Let $ f:\mathbb{N}^{*} \mapsto \mathbb{N}^{*} $ be a function with the following property: $$ \frac{f(x+1)f(x)-2x}{f(x)}=\frac{2f^2(x)}{x+f(x)}-1$$
Determine all functions with this property.
(I'm sure the only function is $f(x)=x$).","['functions', 'functional-equations']"
626817,Morphisms from a proper scheme to the affine line over a field must be constant.,"Let $k$ be a field. Let $X$ be a (non empty) connected proper $k$-scheme. I would like to prove the maximum principle , that is for any $k$-morphism $\varphi \colon X \to \mathbb A_k^1$, the image of $\varphi$ is a closed point. From a previous result, as $\mathbb A_k^1$ is a separated $k$-scheme, I already know that $\varphi(X)$ is closed in the affine line. It remains to show that $\varphi(X)$ is a single point. I have no clue… I tried to exploit the fact that a morphism $\varphi \colon X \to \mathbb A_k^1$ is given by a morphism $k[T] \to \mathscr O_X(X)$ (via the left adjoint of the inclusion of affine schemes into the locally ringed spaces) and it lead me to exhibit $\varphi$ as follow : there is an global section $f \in \mathscr O_X(X)$ such that for all $x \in X$, 
$$\varphi(x) = \ker (k[T] \to \kappa(x) \colon Q \mapsto Q(f)) .$$
But I don't see why this prime ideal of $k[T]$ wouldn't change with respect to $x$.","['algebraic-geometry', 'schemes']"
626833,Proving that $X^6-15X^4-6X^3+75X^2-90X-116$ is irreducible over $\mathbb Q$,"When asked to find the minimal polynomial of  $\sqrt[3]{3}+\sqrt[2]{5}$ over $ \mathbb Q$, I easily found out that $X^6-15X^4-6X^3+75X^2-90X-116$ has $\sqrt[3]{3}+\sqrt[2]{5}$ as a root. It's very likely that it is indeed the minimal polynomial. All I need to prove now is that it is irreducible over $\mathbb Q$ and equivalently that it is irreducible over $\mathbb Z$. The rational root theorem at least proves (computations needed though) that the polynomial has no root in $\mathbb Q$. What to do next ? Eisenstein criterion is of no use here.","['irreducible-polynomials', 'minimal-polynomials', 'abstract-algebra', 'field-theory']"
626845,Prove that $\exp(x)>0$ using only formal definition of exp,"This problem would be easy if I could use the fact that $\exp(x)=e^x$, but I have to use the following definition:
$$\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}$$
I can also use the fact that
$$\exp(x+y)=\exp(x)\exp(y)$$
So how do I prove, using those two equations, that
$$\forall x\in \mathbb{R}:\exp(x)>0 $$
I mean, I can't just use the definition, because if $x<0$ then it isn't so obvious that $\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}>0$. Can someone give me a hint or two? Thanks!",['real-analysis']
626884,How to build a trapezoid,"Build a trapezoid knowing its diagonals, the angle between them, and, also, the sum of $2$ adiacent sides. I appreciate your time and help!","['geometry', 'geometric-construction']"
626927,How a group represents the passage of time?,"I am reading a book on algebraic geometry and I google some keywords, eventually come up with this post in Terry Tao's blog: http://terrytao.wordpress.com/2009/10/19/grothendiecks-definition-of-a-group/ I think I got good intuition on the different thoughts on a group, but not this one: (6) Dynamic: A group represents the passage of time (or of some other
variable(s) of motion or action) on a (reversible) dynamical system. Can anyone explain to me how a group represents the passage of time?
I can only think of Noether's theorem on conservation law when combining the concept of time and algebra.","['dynamical-systems', 'soft-question', 'group-theory', 'abstract-algebra']"
626936,Quasi-coherent sheaves on varieties,"I am reading Kempf's book ""Algebraic varieties"".
On page 55 the author considers a sheaf of rings ${\mathcal{A}}$ (commutative, unital) on a topological space $X$. 
An ${\mathcal{A}}$-module ${\mathcal{M}}$ is said to be quasi-coherent if there is an open cover $X=\bigcup X_i$ such that we have exact sequences of ${\mathcal{A}}|_{X_i}$-modules
$$
 {\mathcal{A}}|_{X_i}^{\oplus J}\to {\mathcal{A}}|_{X_i}^{\oplus I}\to {\mathcal{M}}|_{X_i}\to 0
$$
(where the sets $I$ and $J$ can be infinite). Let $M$ be an ${\mathcal{A}}(X)$-module. Then we can form an ${\mathcal{A}}$-module $M\otimes_{{\mathcal{A}}(X)} {\mathcal{A}}$ by taking it to be the sheaf associated to the presheaf
$$
U\mapsto M\otimes_{{\mathcal{A}}(X)}{\mathcal{A}}(U).
$$
The author notices that if $M$ is the cokernel of a homomorphism
$$
\psi\colon {\mathcal{A}}(X)^{\oplus J}\to {\mathcal{A}}(X)^{\oplus I},
$$ 
then we have an exact sequence
$$
{\mathcal{A}}(X)^{\oplus J}\to {\mathcal{A}}(X)^{\oplus I}\to M\otimes_{{\mathcal{A}}(X)} {\mathcal{A}} \to 0.
$$ Then the author remarks that thus on a Noetherian space $X$, an ${\mathcal{A}}$-module ${\mathcal{M}}$ is quasi-coherent if and only if it locally has the form
$M_i\otimes_{{\mathcal{A}}(X_i)} ({\mathcal{A}}|_{X_i})$. Question . How can one prove the assertion of this last remark? Where does one use the assumption that $X$ is Noetherian?","['quasicoherent-sheaves', 'algebraic-geometry']"
626942,Calculation of $\int \sqrt{\tan x+2}dx$,"Calculation of $\displaystyle \int\sqrt{\tan x+2}\;dx$ $\bf{My\; solution::}$ Let $\displaystyle \tan x+2 = t^2 $, Then $$\displaystyle \sec^2 (x)dx = 2tdt\Rightarrow dx = \frac{2t}{1+\tan^2 x}dt = \frac{2t}{1+(t^2-2)^2}dt$$ So Integral convert into $$\displaystyle \int \frac{2t^2}{(t^2-2)^2+1^2}dt$$ Let $\displaystyle (t^2-2) = u\Rightarrow t^2=u+2\;,$ Then $\displaystyle tdt=\frac{1}{2}du$ Now How can i solve after that please help me Thanks","['calculus', 'integration', 'indefinite-integrals']"
626946,"Proof that $\frac{(x+y)-abs(x-y)}{2}$ equivalent to $\min(x,y)$","I plotted the two functions $\frac{(x+y)-abs(x-y)}{2}$ and $min(x,y)$ in the range $[-1, 1]$ and they look the same. The both $min$ and $abs$ functions are defined as expected. $abs(x)=\begin{cases}&x,&0<x,\\-&x,&\text{else.}\end{cases}$ $\min(x,y)=\begin{cases}x,&x<y,\\y,&\text{else.}\end{cases}$ The $min$ function is quite easy to imagine. For the other function, I think of it as the average of $x$ and $y$ minus their half distance. Anyhow, I haven't an imagination of both functions being equal yet. Could you provide a proof and the idea behind it to me?","['proof-writing', 'functions']"
626958,Conditional mean on uncorrelated stochastic variable,"I know that $E[X|Y]=E[X]$ if $X$ is independent of $Y$. I recently was made aware that it is true if only $\text{Cov}(X,Y)=0$. Would someone kindly either give a hint if it's easy, show me a reference or even a full proof if it's short? Either will work I think :) Thanks. Edit: Thanks for the great answers! I accepted Alecos simply for being first. I've made a followup question here . (When i someday reach 15 reputation I will upvote)",['probability-theory']
626981,How to imagine zeros of an analytic function of several variables,"Let $f(z_1,\cdots, z_n)$ be a holomorphic function of several variables in an open subset of $\mathcal C^n$. Let
$Z(f)=\{ (z_1,\cdots, z_n) \: | \: f=0\}$ be the zero set of $f$. If $n=1$, the zeros set consists of isolated points. How to generalize this to 
$n$ dimensions? I know that $Z(f)$ has zero Lebesgue measure in $2n$ dimensional space. But this does not help: for $n=1$ it includes both isolated points and line segments. Can the concept of limit/isolated/accumulation point be usefully generalized in this context? What's the best way to characterize $Z(f)$?","['several-complex-variables', 'roots', 'complex-analysis', 'analyticity']"
627002,Uniqueness of completion of a measure space,"Let $(X,\Sigma,\mu)$ be a measure space. Define $P=\{S\subset X : \exists N\in \Sigma(\mu(N)=0 \land S\subset N)\}$. And let $\Sigma^*$ be the $\sigma$-algebra generated by $P\cup \Sigma$. I have proved there exists a complete measure $\mu^*$ on the measurable space $(X,\Sigma^*,\mu^*)$, which is an extension of $\mu$. However, it is in wikipedia that such extension is unique for $\Sigma^*$. How do i prove this?","['measure-theory', 'real-analysis']"
627005,convergence of sequence of random variables and cauchy sequences,"Let $(X_n)$ be a sequence of real random variables on $(\Omega,\mathcal A,\mathbb  P)$. Then 1. and 2. are equivalent: There exists a random variable $X$, s.t. $X_n\to X$ $P$-almost sure for $n\to \infty$. $\sup_{m>n} |X_m-X_n|\to 0$ in probability for $n\to\infty$. I tried showing $1.\Rightarrow 2.$: I know that $X_n\to X$ $P$-almost sure means that $$P(\lim_{n\to\infty} X_n=X)=1$$  or equivalently $$(*)\quad \lim_{n\to\infty} P(\sup_{m\geq n} |X_m-X|\geq\varepsilon)=0\quad\forall\varepsilon>0$$ $\sup_{m>n} |X_m-X_n|\to 0$ in probability means \begin{equation}\lim_{n\to\infty} P(\sup_{m>n}|X_m-X_n|\geq\varepsilon)=0\quad\forall\varepsilon>0\end{equation} This looks like a Cauchy-sequence in probability, but I don't know if I can deduce the convergence of this from $(*)$. How can I go on proving this? Thanks for any input!","['probability-theory', 'convergence-divergence', 'random-variables']"
627009,"Prove that $\int_{0}^1 u^{\alpha_1-1} (1-u)^{\alpha_2-1} \, {\rm d}u =\frac{\Gamma(\alpha_1)\Gamma(\alpha_2)} {\Gamma(\alpha_1+\alpha_2)}$","I have the following equality in a textbook of mine $$\frac{y^{\alpha_1+\alpha_2-1} e^{-y/\beta}}{\Gamma(\alpha_1+\alpha_2) \beta^{\alpha_1+\alpha_2}} \cdot \frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)} \int_{0}^1 u^{\alpha_1-1} (1-u)^{\alpha_2-1} \, \mathrm du = \frac{y^{\alpha_1+\alpha_2-1} e^{-y/\beta}}{\Gamma(\alpha_1+\alpha_2) \beta^{\alpha_1+\alpha_2}}$$ and I see that for the equality to be true we must have $$\int_{0}^1 u^{\alpha_1-1} (1-u)^{\alpha_2-1} \, \mathrm du =\frac{\Gamma(\alpha_1)\Gamma(\alpha_2)} {\Gamma(\alpha_1+\alpha_2)}$$ However can someone give me an explanation why this is the case ?","['statistics', 'calculus', 'probability', 'integration']"
627025,Convergence of double series $\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2}$,"I was playing around with some integrals and series convergence and computations and after some ugly transformations the following double series occurred. Title says it all, is the following series convergent or divergent? If its convergent can we get a good estimate? $$\displaystyle{ \sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2}}.$$ An elementary solution is preferred.
Thanks in advance.","['sequences-and-series', 'calculus']"
627026,How to prove $\binom{2n}{n}\frac{1}{n+1} = \prod \limits_{i = 2}^n \frac{2i-1}{i+1} $?,How to prove this closed form involving Catalan numbers ? $$\binom{2n}{n}\frac{1}{n+1} = \prod \limits_{i = 2}^n \frac{2 \times (2i-1)}{i+1} $$ I have seen this being used here . Not sure how to derive it. Any ideas?,"['elementary-number-theory', 'algebra-precalculus', 'contest-math', 'combinatorics']"
627034,Orthogonal Projection onto the $ {L}_{2} $ Unit Ball,"On an article I'm reading, I find that:
if $v$ is a vector, the projection of of $v$ on the unit ball is:
$$p(v)=\frac{v}{\max\{1,\|v\|\}}$$
I know that a projection of a point $v$ into a space is the nearest point to $v$ inside the space..why the expression above?","['optimization', 'geometry', 'linear-algebra', 'convex-optimization', 'matlab']"
627035,Unable to figure out equation involving imaginary numbers,"I have been trying this for a while, but cannot get how to finally solve it. This is what we have: If $x$ and $y$ are real, solve the equation: $(xi) / (1 + iy) = (3x + 4i) / (x + 3y)$ where $i^2 = -1$ I ended up with: $x^2i - 3x - 4i + 4y$. However, I have no idea how to continue, as I always worked with equations in the form $a + bi$, but in this particular case, how should I proceed?","['trigonometry', 'calculus']"
627067,"Why are compact sets called ""compact"" in topology?","Given a topological space $X$ and a subset of it $S$, $S$ is compact iff for every open cover of $S$, there is a finite subcover of $S$. Just curiosity: I've done some search in Internet why compact sets are called compact, but it doesn't contain any good result. For someone with no knowledge of the topology, Facing compactness creates the mentality that a compact set is a compressed set! Does anyone know or have any information on the question?","['general-topology', 'math-history', 'terminology', 'soft-question']"
627092,"Raabe's test, logarithm test, Bertrand test","Raabe's test, logarithm test and  Bertrand test are the  most commonly used criterion in calculus. The relationship between them is quite interesting. Here is how: $\sum\limits_{n=1}^\infty a_n$,  $a_n\gt0$, 1). If $\lim\limits_{n\to\infty}n(\dfrac{a_n}{a_{n+1}}-1)=\alpha$, then $$\lim_{n\to\infty} \frac{\ln\frac1{a_n}}{\ln n}=\alpha $$ 2). If $\lim\limits_{n\to\infty}\ln n\left[n\left(\dfrac{a_n}{a_{n+1}}-1\right)-1\right]=\beta$, then $$\lim_{n\to\infty} \frac{\ln\frac1{na_n}}{\ln\ln n}=\beta $$ I have no clue about it. I don't know how to prove it. Could anyone help me? Thanks a lot","['calculus', 'real-analysis', 'analysis']"
627116,The set consisting of all zero divisors in a commutative ring with unity contains at least one prime ideal [duplicate],"This question already has answers here : Showing the set of zero-divisors is a union of prime ideals (5 answers) Closed last month . I'm asked to prove that the set consisting of all zero divisors in a commutative ring with unity contains at least one prime ideal. I can't even start in the proof, I've just defined my set but cant move on construction the ideal !","['ring-theory', 'ideals', 'abstract-algebra']"
627130,How many elements of order $k$ are in $S_n$?,"I need to find how many elements of order $k$ are in $S_n$ (where $k \leq n$ ). So if $k$ is prime, it's easy: $k$ can't be the $\mathrm{lcm}$ of any integers besides itself and one's (which we're omitting). So the length of the cycle then must be $k$ , and the number of elements with $k$ -length cycle representation in $S_n$ is given by $$\dbinom{n}{k}(k-1)!$$ But it gets really tricky when $k$ is not a prime number... I need to consider every set of integers that can divide $k$ , and then, for every set, I need to find how many elements of that form are there... Or maybe I'm missing something here? I need help figuring that out.","['permutations', 'symmetric-groups', 'abstract-algebra', 'combinatorics']"
627144,Prime chains with large gaps,"It is well known that the gap between consecutive primes is unbounded. Is this 
still true for a chain of consecutive primes ? More Formally : Is the following statement true for all natural numbers m and n ? There are m consecutive primes $a_1,...,a_m$ , such that all the gaps are greater
than n (this means $a_{k+1}-a_k>n$ for all k with 1 <= k <= m-1) ? I also heard about primes in arithmetic progressions, but I always wondered if
the primes must be consecutive in such progressions. Can any of the known properties of the prime-numbers help to answer this question ?","['prime-numbers', 'prime-gaps', 'number-theory']"
627160,999 coins in 3-by-3 piles,"999 coins are organized in a 9 piles in a $3\times 3$ grid. There number of coins in each column is the same (333). We are allowed to take the 3 piles in a single row, but only if we manage to arrange the 6 remaining piles in two rows (without splitting the piles), such that each row contains at least 333 coins. Is this always possible? Some simple cases: ** CASE A **
 22  22  22 
111 111 111
200 200 200 : Here we can just take the top row. The two remaining rows already contain at least 333 coins each. ** CASE B **
100 100 100 
100 100 100
133 133 133 : Here we can take the top row and arrange the remaining piles as follows: 100 100 133
100 133 133 : ** CASE C **
 11 100 211 
 22 200 100 
300  33  22 : Here we can take the top row and arrange the remaining piles as follows: 33 200 100
300 22  22 I tried many cases and it seems to be always possible, but I could not come up with a proof. Is this always possible?","['recreational-mathematics', 'combinatorics']"
627170,Conformal map from unit disk to strip,"I have the following question: Write down the solution $u(x, y)$ to the Dirichlet problem for the following region and boundary conditions:
$U = \{x + iy : 0\le y\le1\}; u(x, 0) = 0, u(x, 1) = 1$. Hence use appropriate conformal maps to find to a solution  in the following region and with the following boundary conditions: $A = \{z : \lvert z \lvert \le 1\}, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)<0, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)>0$. In the region $U$ I have the solution $u(x,y)=y$. Now I need to find a conformal map, but I am struggling to get one that gives the right boundary conditions. Something like $(4i/\pi)arctan(z)$ maps the region correctly but does not give the right conditions for the answer. I think the solution may have something to do with mapping the lower half of the disk to $\{x + iy : -1 \le y\le 0\}$ and the upper half to $\{x + iy : 0 \le y \le 1\}$ and then adjusting appropriately, but I can't see how to do this. Any help would be appreciated.","['conformal-geometry', 'complex-analysis']"
627176,Prove that $f$ is constant almost everywhere.,"Let $f$ be a Lebesgue integrable function on $[0,1]$ such that for any $0 \leq a < b \leq 1$, $$\int^{\frac{a+b}{2}}_a f(x)dx = \int^b_{\frac{a+b}{2}} f(x)dx $$ Prove that $f$ is constant almost everywhere. Hints/ideas are appreciated, thanks","['measure-theory', 'real-analysis']"
