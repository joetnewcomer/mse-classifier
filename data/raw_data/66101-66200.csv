question_id,title,body,tags
780769,Remarkable integral: $\int_0^{\infty} x \left(1 - \frac{\sinh x}{\cosh x-\sqrt 3/2} \right) \mathrm dx= -\frac{13 \pi ^2}{72}$?,"Numerical evidence suggests that $$\int_0^{\infty} x \left(1 - \frac{\sinh x}{\cosh x-\sqrt 3/2} \right) \mathrm dx=  -\frac{13 \pi ^2}{72}$$ How can we prove this? I could not find a nice contour in the complex plane to integrate around. Integration by parts also didn't help.
Mathematica finds a very complicated antiderivative in terms of special functions, but this was a contest problem so there must be a 'human' way to calculate it. As O.L. helpfully pointed out, I had the sign wrong. It is corrected now.","['definite-integrals', 'integration']"
780782,Learning Advanced Mathematics,"I'm a 12th grade student and I've recently developed a passion for mathematics . Currently my knowledge in this particular area is comprised by : single-variable calculus , trigonometry , geometry , basic notions of linear algebra and set theory . I'm particularly interested in calculus and I need some advice as I intend on coupling my future math skills with the study of Quantum Physics . Where should I go from here in order to understand multivariable calculus ?Can anyone recommend an interesting advanced calculus textbook  ? (Hope the prerequisites needed for understanding the textbooks you suggest match my current mathematical skills and knowledge)","['mathematical-physics', 'multivariable-calculus', 'reference-request', 'advice']"
780799,Free group of finite rank: subgroup of finite index,"This is a well-known result, but I can't find a proof of it without using topology. Let $m\geq2$ be an integer. Then the free group of rank $2$ contains a free group of rank $m$ as a finite-index subgroup.","['free-groups', 'group-theory', 'abstract-algebra']"
780802,A non-abelian group such that $G/Z(G)$ is abelian.,"I'm looking for an example of a non-abelian group $G$ such that $G/Z(G)$ is abelian, where $Z(G)$ is the center of the $G$ . In other words, I'm looking for a non-abelian group where $Z(G)$ contains the commutator subgroup $[G,G]$ . Further, what if I request $G/Z(G)$ to be a finitely generated and abelian group?","['group-theory', 'abstract-algebra', 'abelian-groups']"
780824,Equivalent ideas of absolute continuity of measures,"Wikipedia says that $\mu$ is absolutely continuous with respect to $\nu$, if $\nu(A)=0 \Rightarrow \mu(A)=0$. Okay, then I found another notion of absolute continuous measures: Let $||f||_1=1$ and $\mu(A):= \int_A |f| d \nu$, then we also have absolute continuity in the sense that if $\nu(A)  < \delta \Rightarrow \mu(A) < \varepsilon$. My question is: How are these definitions related to each other? It is clear that the second notion implies the first one, but is the converse also true? Where does this $\varepsilon$, $\delta$ comes into play? Edit: Afais is the converse implication the result of a special case of the Radon-Nikodym theorem and a few lines of calculation that the $\varepsilon, \delta$ stuff actually holds, right?","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
780828,Product of Elements in SU(2),"Let $$ V := \frac{x_4+i\vec{x}\cdot{\vec{\sigma}}}{\left|x\right|}$$ where $\left(x_1,x_2,x_3,x_4\right)\in\mathbb{R}^4$, $|x|$ is the Euclidean norm, and $\sigma^j$ are the Pauli matrices. Let $\theta_1,\,\theta_2,\,\theta_3$ be some parametrization of $S^3$. How do you ""see"" that \begin{align} \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\varepsilon^{i j k} tr\left[V\left(\frac{\partial}{\partial \theta_i}V^{-1}\right)V\left(\frac{\partial}{\partial \theta_j}V^{-1}\right)V\left(\frac{\partial}{\partial \theta_k}V^{-1}\right)\right]\end{align} is proportional to $\left[\sin\left(\theta_1\right)\right]^2\sin\left(\theta_2\right)$, where $\varepsilon^{i j k}$ is the totally anti-symmetric tensor? I have tried explicitly calculating this expression but after half a page of tediousness it seems like the wrong way to go. Using Mathematica I get the right result ($-12\times \left[\sin\left(\theta_1\right)\right]^2\sin\left(\theta_2\right)$), but I would like to know how to just ""see"" this result and compute the proportionality constant conveniently.","['multivariable-calculus', 'linear-algebra', 'calculus']"
780879,All roots of polynomial inside the open unit disc,I know from here that for a polynomial $p(z)=a_0+a_1z+...+a_nz^n$ with $0<a_0\leq a_1\leq...\leq a_n$ all roots are in the closed unit disk. What condition do we need to get that all roots are in the open unit disc? I was thinking that maybe some $a_i\neq a_{i+1}$. But I don't know how to prove that?,"['roots', 'complex-analysis']"
780913,How to evaluate $\frac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta $?,How to evaluate the integral given below? $$\dfrac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta $$,"['definite-integrals', 'integration']"
780925,Closed form of $\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx}$,"Does it possibly have a closed form? $$\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x
 \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx}$$ Thank you! I found it. No more need for efforts.","['complex-analysis', 'calculus', 'real-analysis']"
780958,Solving Simplified Hamilton's Equation,"I have a question on a project that I am working on. I have included a large amount of the background information so that all relevant information is included, however the question is as follows (it is also #12 below): Using a simplified version of $H$ given as $H(p,x)=\frac{p^2}{2}+\frac{x^2}{2}$ , consider a particle with initial position $a$ and no initial momentum. Solve Hamilton's equations for this particle. In other words, find the curve $\gamma(t)=(x(t),p(t))$ that solves Hamilton's equations with the initial conditions $x(0)=a$ and $p(0)=0$ . EDIT This is the answer that I have given so far: Using the example of the Harmonic Oscillator, with potential energy is $V(x) = \displaystyle\frac{kx^2}{2}$ for some constant $k$ , and allowing $k$ and $m$ to be equal to $1$ for simplicity, the Hamiltonian is given by: $$H(p,x) = \frac{p^2}{2} + \frac{x^2}{2}.$$ We can solve Hamilton's equations for a particle with initial position $a$ and no initial momentum, to find closed curve $\gamma(t)=(x(t),p(t))$ , with $x(0)=a$ and $p(0)=0$ .
In actuality, we are finding $\dot{x}$ and $\dot{p}$ . Starting with the former, $\dot{x}$ : $$
\frac{\partial x}{\partial t}
=\dot{x}
=\frac{\partial H}{\partial p}
=\frac{\partial}{\partial p}\left(\frac{p^2}{2} + \frac{x^2}{2}\right)
=\frac{\partial}{\partial p}\left(\frac{x^2}{2}\right)
  + \frac{\partial}{\partial p}\left(\frac{p^2}{2}\right)
=0+\frac{2}{2}p
=p.$$ We now integrate $\displaystyle\frac{\partial x}{\partial t}=p$ to get $x(t)$ : $$x(t)=\int{\frac{\partial x}{\partial t} dt} = \int{p dt} = pt + c_1.$$ Since we know $x(0)=a$ , $a$ is the initial condition of $x(t)$ , which implies $c_1=a$ , giving $x(t)=pt+a$ .
Similarly, we can find $p(t)$ : $$
\frac{\partial p}{\partial t}
=\dot{p}
=-\frac{\partial H}{\partial x}
=-\frac{\partial}{\partial x}\left(\frac{p^2}{2} +\frac{x^2}{2 }\right)
=-\frac{\partial}{\partial x}\left(\frac{x^2}{2}\right)
+ \frac{\partial}{\partial x}\left(\frac{p^2}{2}\right)
=-\frac{2}{2}x+0=-x.
$$ We now integrate $\frac{\partial p}{\partial t}=-x$ to get $p(t)$ : $$p(t)=\int{\frac{\partial p}{\partial t} dt} = \int{-x dt} = -xt + c_2.$$ Since we know $p(0)=0$ , $0$ is the initial condition of $p(t)$ , which implies $c_2=0$ , giving $p(t)=-xt$ .
Therefore, $\gamma(t)=(x(t),p(t))$ is given by the closed curve solving Hamilton's equations $\gamma(t)=\big(pt+a,-xt\big)$ . Here is the full information:","['mathematical-physics', 'multivariable-calculus']"
780999,General approach for finding how many group homomorphisms are there,"So I've asked this type of questions for more than once, and still I don't get the method(s) I've been presented with. What's the general recommended method for finding how many homomorphisms are there, and finding them? I would probably understand better through an example: How many homomorphisms are there from $S_3$ to $\mathbb Z_2 \times \mathbb Z_2$. I would gladly appreciate full solutions. You have my full gratitude for any sort of assistance, comment, insight or info you can provide.","['permutations', 'finite-groups', 'group-theory', 'abstract-algebra']"
781017,"How to find PV $\int_0^\infty \frac{\log \cos^2 \alpha x}{\beta^2-x^2} \, \mathrm dx=\alpha \pi$","$$
I:=PV\int_0^\infty \frac{\log\left(\cos^2\left(\alpha x\right)\right)}{\beta^2-x^2} \, \mathrm dx=\alpha \pi,\qquad \alpha>0,\  \beta\in \mathbb{R}.$$
I am trying to solve this integral, I edited and added in Principle value to clarify the convergence issue that the community pointed out.  I tried to use $2\cos^2(\alpha x)=1+\cos 2\alpha x\,$ and obtained
$$
I=-\log 2 \int_0^\infty \frac{\mathrm dx}{\beta^2-x^2}+\int_0^\infty \frac{\log (1+\cos 2 \alpha x)}{\beta^2-x^2}\mathrm dx,
$$
simplifying
$$
I=\frac{ \pi \log 2 }{2\beta}+\int_0^\infty \frac{\log (1+\cos 2 \alpha x)}{\beta^2-x^2}\mathrm dx
$$
but  stuck here. Note the result of the integral is independent of the parameter $\beta$. Thank you Also for $\alpha=1$, is there a geometrical interpretation of this integral and why it is $\pi$? Note this integral 
$$
\int_0^\infty \frac{\log \sin^2 \alpha x}{\beta^2-x^2} \,\mathrm dx=\alpha \pi-\frac{\pi^2}{2\beta},\qquad \alpha>0,\beta>0
$$
is also FASCINATING, note the constraint $\beta>0$ for this one.  I am not looking for a solution to this too obviously on the same post, it is just to interest people with another friendly integral.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
781024,"For $x_{n+1}=x_n^2-2$, show $\lim_{n\to\infty}\frac{x_n}{x_0x_1\cdots x_{n-1}}=2$ [duplicate]","This question already has answers here : If $x_1=5$, $x_{n+1}=x_n^2-2$, find $\lim x_{n+1}/(x_1\cdots x_n)$ (2 answers) Closed 6 years ago . Suppose $x_0:=2\sqrt{2}$ and $x_{n+1}=x_n^2-2$ for $n\ge1$. We have to show $$\lim_{n\to\infty}\frac{x_n}{x_0x_1\cdots x_{n-1}}=2$$ Establishing convergence is pretty direct but I'm having trouble evaluating the limit. I have tried using the relation $\frac{x_{n}}{x_{0}x_{1}\cdots x_{n-1}}=\frac{x_{n-1}^{2}-2}{x_{0}x_{1}\cdots x_{n-1}}=\frac{x_{n-1}}{x_{0}x_{1}\cdots x_{n-2}}-\frac{2}{x_{0}x_{1}\cdots x_{n-1}}=\cdots=\frac{3}{\sqrt{2}}-2\sum_{k=1}^{n}\frac{1}{x_{0}x_{1}\cdots x_{k}}$ but that doesn't really shed light on the exact value of the limit. Any and all help appreciated. Thanks!","['recurrence-relations', 'real-analysis']"
781033,Integrating : $\int_0^1 {\frac {x^a-x^b} {\ln x} dx}$ [duplicate],"This question already has an answer here : Is the integral $\int_1^\infty\frac{x^{-a} - x^{-b}}{\log(x)}\,dx$ convergent? (1 answer) Closed 6 years ago . We are given parameters $a > 0, b > 0$. Task is to integrate that:
$\displaystyle \int_0^1 {\frac {x^a-x^b} {\ln x} dx}$. I have tried approaching problem from different angles with no luck. 
I tried integration by parts(tried all combinations of possible $v$ and $u$), u-substitution with no luck. Also I tried to integrate this two similar terms separately. Tried to get some idea of how to go from answer, got nice answer from MATLAB: $\displaystyle \ln{\frac{a+1}{b+1}}$, but no idea how to reach it. I would appreciate some suggestions.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
781055,Maximize total area of 3 circles inscribed in a triangle,"Given a triangle of sides $a,b,c$ three non concentric and not intersecting circles are to be inscribed in that triangle such that the sum of areas of enclosed circles is maximum..This is an extreme value problem but I am not sure what to begin with...",['geometry']
781099,"Exercise 2.26 Atiyah-Macdonald, flatness","I'm stuck on this exercise. $A$ is a commutative ring with unit. $N$ is an $A$-module. Then $N$ is flat $\Longleftrightarrow $ $\text{Tor}_{1}(A/a, N ) = 0 $ for every finitely generated ideal $a$ of $A$. What I know: every module is isomorphic to the direct limit of its finitely generated submodules, I think I should use this information.","['ring-theory', 'abstract-algebra', 'homological-algebra', 'modules', 'commutative-algebra']"
781105,"Derangements and the ""other"" secretary problem","I just found out that the name ""Secretary problem"" is given to two different problems. The first one talks about a secretary who mixes letters and envelopes, and ask for the probability that no letter will be put into the right envelope: this is an application of derangements, and the limit value for the probability is $1/e$. However, Wikipedia defines the Secretary problem as the task to choose the best candidate, if you see them one at a time and cannot keep anybody on hold. Curiously (at least for me), the best algorithm has the identical chance to find the best candidate, that is $1/e$. Is it really a casual correlation - after all, $e$ pops out everywhere - or derangements are somewhat involved? In the comments at this answer in SO the same question was made, but nobody answered.","['derangements', 'recreational-mathematics', 'combinatorics']"
781108,Prove or disprove inequality $a^2+b^2+c^2\ge a^rb^{2-r}+b^rc^{2-r}+c^ra^{2-r}$.,"If $a$, $b$ and $c$ are real numbers greater than $0$ and $r$ is a real number with $0 \le r \le 2$. Does inequality $$a^2+b^2+c^2\ge  a^rb^{2-r}+b^rc^{2-r}+c^ra^{2-r}$$ hold?","['inequality', 'algebra-precalculus', 'real-analysis']"
781118,"Strength of ""Every finite dimensional subspace of a vector space has a complement""","Does the following choice principle have a name? Every finite dimensional subspace of a vector space has a complement. Equivalently, every line inside a vector space has a complementary hyperplane. How strong/weak is it compared to other choice principles? It certainly follows from the existence of a basis, and as such is a consequence of the axiom of choice. Feel free to edit the Tags, I wasn't sure which tag is appropriate.","['vector-spaces', 'axioms', 'linear-algebra', 'reference-request', 'axiom-of-choice']"
781129,why is $\int_{\pi/2}^{5\pi/2}\frac{e^{\arctan(\sin x)}}{e^{\arctan(\sin x)}+e^{\arctan(\cos x)}}=\pi$?,"I cannot make progress on the definite integral $$\int_{\pi/2}^{5\pi/2}\frac{e^{\arctan(\sin x)}}{e^{\arctan(\sin x)}+e^{\arctan(\cos x)}}\,dx=\pi$$
I know the result is $\pi$ from numerical approximation. Could someone give some hints? Is there a clever substitution I'm missing? I'd prefer hints to a full solution.","['definite-integrals', 'integration', 'problem-solving']"
781141,Diophantine Equations problem 2,"Find all the solutions to the Diophantine equation $x^2+y^2=2z^2$ . I do not have a lot of experience on Diophantine equations and I do not know how to approximate them. I can see that the triples of the form $(x,x,x)$ , example $(0,0,0), (1,1,1),\ldots,$ etc, gives solutions to my equation but that is all, how do I define that is all of them or if they are not how I find the rest?","['elementary-number-theory', 'abstract-algebra', 'number-theory']"
781189,"Let $|G|=p^nm$ where $p$ is a prime and $\gcd(p,m)=1$.Suppose that $H$ is a normal subgroup of $G$ of order $p^n$.","Let $|G|=p^nm$ where $p$ is a prime and $\gcd(p,m)=1$.Suppose that $H$ is a normal subgroup of $G$ of order $p^n$. IF $K$ is a subgroup of $G$ of order $p^k$, show that $K \subseteq H$. Attempt: Given that $|G|=p^nm$ and $gcd(p,m)=1 => \gcd(p^n,m)=1$ $H \triangleleft G =>g^{-1}hg \subseteq H~~ \forall ~~g\in G, h\in H$ $G/H=\{gH ~~\forall~~g \in G \}$ and then $|G/H|=p^nm/p^n=m$ Now, $O(gH)~~|~~O(g)$ and $O(g)~~|~~p^nm$ $=> O(gH)~~|~~p^nm ..........(1)$ $O(gH)~~|~~m ....... (2) $ ( By Lagrange's Theorem, $gH$ is an element in $G/H$ and $O(gH) ~~|~~|G/H|$ and $|G/H|=m$) Since $\gcd(p^n,m)=1 => O(gH)= r $ s.t. $r$ divides $m$.
$=> g^r \in H$ If we show that $\exists h_1,h_2 \in H $ s.t. $k=h_1h_2$ then our result can be proved or if we prove that $K$ is a normal subgroup in $H$ and $|H : K|=1$, then also we can prove the result How should I proceed ahead. Help will be appreciated. Thank you.","['group-theory', 'abstract-algebra']"
781196,Integrating over Branch Cuts,"I'm having problems following the solution for b). The main problem is finding the interval which you integrate over, which for some reason in this case is $(-i,i)$. To be frank I don't really get the rest of the answer either.",['complex-analysis']
781229,Compactly supported Dolbeault Cohomology: is this True?,"nLab states that for $D$ the unit disk in $\mathbb C$, the cohomology of the complex
$$ (\Omega_c^{1,\ast}(D),\overline{\partial})$$ is the continuous dual of the space of holomorphic functions $\mathcal O(D)$. Is it true that any continuous linear form on $\mathcal O(D)$ can be represented by a form $f dz\wedge d\overline{z}$ with $f$ having compact support? This result looks really weird to me. What would be the function representing the Delta distribution?","['homology-cohomology', 'complex-analysis']"
781252,"CDF of $\max(X,X^2)$ for $X$ uniformly distributed on $[-1,1]$","$X$ is uniformly distributed on $[-1,1]$. And $Y=max(X,X^2)$. What is $F_{Y}(t)$ , the CDF of $Y$? My attempt: I tried to graph it, but I think I found wrong. I found the joint pdf $5/6$. Is this correct? And what can I do next?","['probability-theory', 'probability-distributions']"
781287,Missing a necessary power in this proof - please help.,"This question is somewhat related to Gradient Estimate - Question about Inequality vs. Equality sign in one part . That question was related to part (c) of a problem I am working on, and this question is related to part (b). Specifically, I need to show the following: Let $u$ and $v$ be two functions on $\Omega$ related as follows:
  $$ |u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy, \quad x \in \Omega, $$
  for some kernel $K(x,y)$. Show that for any $1 \leq p \leq q \leq \infty$, we have
  $$ ||u||_{L^{q}(\Omega)}\leq A||v||_{L^{p}(\Omega)} $$
  where $A = \max \left( \sup_{x}||K(x,\cdot)||_{L^{\frac{pq}{pq+p-q}}(\Omega)},\sup_{y}||K(\cdot,y)||_{L^{\frac{pq}{pq+p-q}}(\Omega)} \right)$. So, starting with $u$, $v$ on $\Omega$ satisfying $$|u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy \quad (*)$$ I have that $$(*) \leq \int_{\Omega} |K(x,y) |v(y)|| dy \\
= \int_{\Omega}|K(x,y)v(y)| dy \\
= \int_{\Omega}|K(x,y)^{\alpha+1-\alpha}v(y)|dy\\
\leq \int_{\Omega}|K(x,y)|^{\alpha}|K(x,y)|^{1-\alpha}|v(y)|dy \\
= \int_{\Omega} |K(x,y)|^{\alpha} |K(x,y)|^{1-\alpha}|v(y)|^{1-\beta + \beta} dy\\
\leq \int_{\Omega}|K(x,y)|^{\alpha}(|K(x,y)|^{1-\alpha}|v(y)|^{1-\beta})|v(y)|dy \quad (1)$$ Aplying Holder's Inequality to $(1)$, we get that $$(1) \displaystyle \leq \left[ \int_{\Omega} |K(x,y)|^{\alpha a} dy\right]^{1/a} \cdot \left[ \int_{\Omega} |K(x,y)|^{(1-\alpha)c} |v(y)|^{(1-\beta)c}dy \right]^{1/c} \cdot \left[\int_{\Omega}|v(y)|^{\beta b}dy \right]^{1/b}, $$ where $\displaystyle 1 = \frac{1}{a} + \frac{1}{b} + \frac{1}{c}. \quad (1^{\prime})$ Since we want the $L^{p}$ norm of $v$ to appear in the RHS, choose $\beta b = p$. Thus, $\displaystyle b = \frac{p}{\beta}. \quad (2)$ Also, let $(1-\beta)c = p$, which implies that $\displaystyle \beta = 1 - \frac{p}{c}$. Raising (1) to the power of $q$ and taking the integral with respect to x, we obtain that $$ \int |u(x)|^{q} dx \leq \int \left( \left[ \int|K(x,y)|^{\alpha a}dy \right]^{q/a}\left[ \int|K(x,y)|^{(1-\alpha)c}|v(y)|^{(1-\beta)c}dy\right]^{q/c}||v||_{L^{p}}^{\beta q}\right) dx. $$ Now, in order for us to be able to switch the order of integration, we need $\displaystyle \frac{q}{c} = 1$, so $q = c. \quad (4)$ Therefore, $(3)$ becomes $\displaystyle \beta = 1 - \frac{p}{q} \quad (3^{\prime})$, and $(2)$ becomes $\displaystyle b = \frac{p}{\displaystyle \left( 1 - \frac{p}{q}\right)} = \frac{pq}{q-p} \quad (2^{\prime})$. Substituting $(4)$ and $(2^{\prime})$ into $(1^{\prime})$, we obtain an expression for $a$: $\displaystyle a = \frac{p}{p-1} \quad (5)$ Bounding everything, we obtain $$||u||_{L^{q}}^{q} \leq \sup_{x}\left( \int|K(x,y)|^{\alpha a}dy\right)^{q/a} \cdot \left[\sup_{y}\int |K(x,y)|^{(1-\alpha)c}dx \right] ||v||_{L^{p}}^{p+\beta q}. \quad (6)$$ Notice also that $\displaystyle \frac{q}{a} = 1$, so $$ (6) = \left[ \sup_{x}\int|K(x,y)^{\alpha a}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{(1-\alpha)c}dx \right] \cdot ||v||_{L^{p}}^{p+\beta q}. \quad (6^{\prime})$$ Now, we need $\sup_{x}$, $\sup_{y}$, and each of these kernels to be finite, so choose $\alpha$ so that $\alpha a = (1-\alpha)c$, which implies then that $\displaystyle \alpha = \frac{c}{a+c}$. Then, substituting our values for $a$ and $c$ [$(5)$ and $(4)$], respectively, we obtain that $\alpha = \frac{q}{\frac{p}{p-1}+q} = \frac{q(p-1)}{p+pq-q} \quad (7)$ and that $(1-\alpha) = \frac{p}{p+pq-q}. \quad (7^{\prime})$ So, $\alpha a = \frac{pq}{p+pq-q}$, and $(1-\alpha)c = \frac{pq}{p+pq-q}. \quad (7^{\prime\prime})$ Thus, $(6^{\prime})$ becomes $$ = \left[ \sup_{x}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]||v||_{L^{p}}^{p+(1-\frac{p}{q})\cdot q}. \quad (8)$$ But, since $\displaystyle p + \left( 1-\frac{p}{q}\right)q = q$, $(8)$ becomes $$ = \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]\left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}} dx \right] ||v||_{L^{p}}^{q}$$. Which brings me to my question. Taking $q$th roots, you see that we have the following: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{1/q}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{1/q}||v||_{L^{p}}$$, but what I need is: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{\frac{p+pq-q}{pq}}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{\frac{p+pq-q}{pq}}||v||_{L^{p}}$$, so that I will have the $||K(x,y)||_{L^{\frac{pq}{pq+p-q}}}$ norms on the RHS that I need. So, what I am hoping someone will tell me is, where did I go wrong in ""misplacing"" these powers? How do I fix this so that I will get the correct norm in my final answer? Thank you in advance! I really would appreciate your help!!","['normed-spaces', 'functional-analysis', 'partial-differential-equations', 'functional-inequalities']"
781301,Examples of Stone algebras which are not Boolean algebras,"Grätzer, in his Lattice Theory: Foundation , describes a Stone algebra as a distributive lattice with pseudocomplementation $L$ which satisfies the Stone identity: for every $a \in L$, $\neg a \vee \neg\neg a = 1$, where ""$\neg$"" is the pseudocomplementation operation. Unfortunately, he doesn't delve too much into examples of this type of structure; specifically, I'm interested in examples of structures which are not Boolean algebras as well. I tried to find some topological examples, but couldn't come up with any (but then again, I know very little of topology). Any ideas?","['general-topology', 'lattice-orders', 'abstract-algebra', 'universal-algebra']"
781308,Localization in formal power series,"I saw in a textbook the following assertion: Let $R$ be a commutative ring with unity, and $R[[X]]$ be the ring of power series in one indeterminate $X$. If the homomorphism $\phi∶ R[[X]] \to R$ sending $X$ to $0$ takes a maximal ideal $M$ of $R[[X]]$ to a maximal ideal $\mathfrak{m}$ in $R$, then the two localizations $R[[X]]_M$ and $R_{\mathfrak{m}}[[X]]$ are equal. I think this problem is some fishy, and would appreciate anyone helping me solve it. Thanks in advance.","['commutative-algebra', 'algebraic-number-theory', 'abstract-algebra']"
781320,"The curve $(\cos(\sin x),\sin(\cos x))$ as plotted by Wolfram Alpha",I've just gotten this from Wolfram Alpha: It makes no sense to me. $\cos(\sin x)$ is never zero so how can this curve cross the $y$-axis?,"['trigonometry', 'wolfram-alpha', 'curves']"
781322,What is the meaning of this notation?,"I am watching this video on maximum likelyhood estimation. I'm confused by the notation when the presenter says ""assume a set of distributions P-theta."" (the URL links to the relevant part of the video: What is the presenter saying here? I am confused by a bunch of things. I have seen set builder notation, but not this notation with a colon. Are they the same? Also he says that little theta ""ranges over"" big theta. What does it mean to ""range over"" something? Basically there are enough unfamiliar things going on here that I can't totally follow it from context. Is the idea that this statement builds a set of all of the distributions that are possible with all of the different parameters (thetas)? Is this the idea?","['statistics', 'probability', 'notation']"
781351,Ordered stars and bars,"Find the number of ordered $8$-tuples of nonnegative integers $x_0 < x_1 < x_2 < \cdots < x_7$ such that $\sum_{i=0}^{7} x_i = 99$ The above question clearly cannot be answered with the classic stars and bars, and the substitution $y_i = x_i - i$ doesn't seem to help either. I cannot see how to progress.",['combinatorics']
781365,Find the parametric equation to the curve,"Find the parametric equation for the curve. $$x^{2}+y^{2}=10$$ I haven't learned parametric equations fully yet, so I wanted to check with you guys and see if you can confirm if I'm doing this correctly and possibly go more in depth on the problem if you can? Because it's centered at (0,0) the origin, and it has a radius of sqrt(10) then the answer is this, right? $$(x(t),y(t)) = (\sqrt{10}\cos t\,,\, \sqrt{10}\sin t)$$","['multivariable-calculus', 'parametric', 'calculus']"
781372,Are proofs in geometry rigorous?,"What I mean by that is, suppose say I have a circle centered at some point in the Euclidean space for which a certain property $P$ is true. How can I conclude from this, that $P$ is true for all circles centered at any arbitrary  point in the space. Is there some kind of invariance principle in geometry like that in Physics. We measure the speed of light here on earth and from that we conclude that this is the speed of light throughout the universe. How can I check if the property is invariant under translation. Can you give me a concrete example of this ? In case of a circle, we can rotate it and that property might still be true,  I would say then that the property is invariant under rotation for that particular circle.",['geometry']
781382,Showing that a power of an ample sheaf is equivalent to an effective Cartier divisor,"I am trying the following exercise: Let $X$ be a quasi-projective scheme over a Noetherian ring A. Let $\mathcal{L}$ be an ample sheaf on $X$. Show that there exists an $m \geq 1$ such that $\mathcal{L}^{\otimes m} \cong \mathcal{O}_X(D)$ for some effective Cartier divisor $D$. I tried to start by using that on $X$, invertible sheaves and Cartier divisors are in bijective correspondence. Now, the obvious thing would be to take a tensor power $\mathcal{L}^{\otimes m}$ of $\mathcal{L}$ that is very ample, and try to argue that if a Cartier divisor $D$ is such that $\mathcal{O}_X(D)$ is isomorphic to a very ample sheaf, it is effective.For this, I thought maybe one should use something about global generation and show that any divisor $D$ such that $\mathcal{O}_X(D)$ is globally generated is actually effective. I have not been able to show this, so, any hints or solutions?",['algebraic-geometry']
781384,Resource for Stochastic Calculus and Ito processes [duplicate],This question already has answers here : Where to begin in approaching Stochastic Calculus? (5 answers) Closed 6 months ago . May someone please recommend a book or website where one can learn Stochastic Calculus and Ito processes from scratch.,"['stochastic-processes', 'book-recommendation', 'probability-theory', 'stochastic-calculus', 'reference-request']"
781398,Derivative of Integral with variable bounds,"I was testing my calculus knowledge when I found an example final exam from UCIrvine: http://www.math.uci.edu/sites/math.uci.edu/files/2B_final_samp1.pdf Number 2.) a.) asks to evaluate: $$ {d\over dx}\int_{sin(x)}^{x^2}t^3tan(t)dt $$ This is what I did: $\begin{aligned} 
{d\over dx}\int_{\sin(x)}^{x^2}t^3\tan(t)dt 
&={d\over dx}\left(\int_{\sin(x)}^{a}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right) 
\\
&= {d\over dx}\left(-\int_{a}^{\sin(x)}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right) 
\\
&= -{d\over dx}\int_{a}^{\sin(x)}t^3\tan(t)dt+{d\over dx}\int_{a}^{x^2}t^3\tan(t)dt 
\\
&= -\sin^3(x)\tan(\sin(x))\cos(x)+{x^2}^3\tan(x^2)2x \\
&= 2x^7\tan(x^2)-\sin^3(x)\cos(x)\tan(\sin(x)) 
\end{aligned}$ Is this correct?","['integration', 'derivatives']"
781405,Prove or disprove inequality $\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc}$.,"Let $a$, $b$ and $c$ be real numbers greater than $0$. Prove inequality $$\displaystyle{\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc}}.$$","['a.m.-g.m.-inequality', 'inequality', 'algebra-precalculus', 'cauchy-schwarz-inequality', 'real-analysis']"
781421,Show that $E(X)^2 \le E(X^{2/3})E(X^{4/3})$,"Show that $E(X)^2 \le E(X^{2/3})\cdot E(X^{4/3})$ $X$ is a nonnegative r.v. I know the easiest way to prove this is using Cauchy-Schwarz, but I'm not sure how to get around squaring the probabilities in the expectation formula.",['probability-theory']
781431,Solving Cubic Equations Using Origami,"I have to write a research paper on a mathematical topic for my class; I chose the above topic. I understand that a parabola can be formed using a focus and directrix, both created by origami folds, and that Axiom 6 of Origami-Folding (Given two points $P_1$ and $P_2$ and two lines $L_1$ and $L_2$, there is a fold that places $P_1$ onto $L_1$ and $P_2$ onto $L_2$) can be used to solve a cubic equation. But some of this explanation of why confuses me: Now, let's solve the cubic equation $x^3+ax^2+bx+c=0$ with origami. Let two points $P_1$ and $P_2$ have the coordinates $(a,1)$ and $(c,b)$, respectively. Also let two lines $L_1$ and $L_2$ have the equations $y+1=0$ and $x+c=0$, respectively. Fold a line placing $P_1$ onto $L_1$ and placing $P_2$ onto $L_2$, and the slope of the crease is the solution of $x^3+ax^2+bx+c=0$. I will explain why. Let p1 be a parabola having the focus $P_1$ and the directrix $L_1$. Since the crease is not parallel to the $y$-axis, we can let the crease have the equation $y=tx+u$. Let the crease be tangent to $P_1$ at $(x_1,y_1)$, and $(x_1 -a)^2=4y_1$. Because the crease has the equation $(x_1 -a)(x-x_1)=2(y-y_1)$, we get $t=\frac {x_1-a}{2}$ and $u= y_1-\frac {x_1(x_1-a)}{2}$. From these equations, we get $u=-t^2-at$. Specifically, I do not understand where the equation  $(x_1 -a)^2=4y_1$ is coming from. I would greatly appreciate someone helping to explain. [this explanation comes from http://origami.ousaan.com/library/conste.html if you want a look at the entire thing]","['origami', 'geometry', 'cubics', 'polynomials', 'linear-algebra']"
781489,linear ordinary differential equation solution,"How can I solve this linear ode:
$$y''+\dfrac{4x}{x^2-1 }y'+\dfrac{x^2+1}{x^2-1}y=0 $$
I tried few variables changing but I did not get any result.
thanks",['ordinary-differential-equations']
781498,Reduction to standard form.,"I was wondering whether this ODE has been studied yet or whether there is anything we can say about its solutions? $$(1-t^2)u_{tt}-tu_t+4\left[n\beta (2t^2-1)+  \beta^2 (2t^2-1)^2+C\right]u=0$$ $C$ is a free parameter. So if you know a function that would fulfill this equation only for particular $C$, this would be perfectly fine. I am interested in its solutions on $[-1,1]$. I should include the motivation/reference here: The equation is motivated by Physics (Quantum Mechanics) and you might want to see this great answer that gives us (meanwhile complete hints) about the structure of the solution (due to O.L. (thank you!)) The problem is that the approach taken by O.L. does not offer an analytical representation of the solution. He was able to show that some types of polynomials will give you the solution, but still you have to throw this ' guess' into the equation. I suspect that the solutions form a nice orthogonal basis of $L^2[-1,1]$, but was incapable of constructing them by recursion or explicit representation. Now, I also got the hint to consider symmetries in my ODE and separately consider even and odd solutions so that I could reduce my ODE to a confluent Heun's equation . 
If I follow this hint and substitute $s=t^2$ and $u(t)= v(s)$ I get $$v''(s)+\frac{1}{2}\left(\frac{1}{s}+ \frac{1}{s-1}\right) v'(s) + \left(n \beta \frac{(2s-1)}{s(1-s)} + \frac{\beta^2(2s-1)^2}{s(1-s)} + C\right) v(s)=0.$$ This is very close to the confluent Heun's equation but not exactly the form that we are looking for (since $s^2$ is appearing in the nominator of the right term in the parenthesis. So probably we need to substitute even more(anything like $v(s) = exp(\alpha s)w(s)$ might help), but actually I don't see how to go further. So is there anybody who knows how to finish this and who is able to construct the solutions from here?(and how $C$ has to be chosen in order to find a solution) If anything is unclear, please let me know and just to point this out: If you are able to reduce this ODE to the confluent Heun equation, then this answers my question totally.","['dynamical-systems', 'ordinary-differential-equations', 'calculus', 'lie-groups', 'real-analysis']"
781518,Boundary value problem-Is the solution correct?,"Having the following boundary value problem:
$$u_{xx}+u_{yy}=0,\quad 0<x<a,\; 0<y<b, \tag{1}$$
$$u_x(0,y)=u_x(a,y)=0,\quad 0\leq y\leq b,$$
$$u(x,0)= \cos{(\frac{\pi x}{a})},\;\; u(x,b)=\cos^2{(\frac{\pi x}{a})},\;\; 
0\leq x\leq a.$$ I have done the following: Using the method of separation of variables, the solution is of the form $u(x,y)=X(x)Y(y)$ $$(1) \Rightarrow X''Y+XY''=0 \Rightarrow \frac{X''}{X}+\frac{Y''}{Y}=0 \Rightarrow \frac{X''}{X}=- \frac{Y''}{Y}=- \lambda$$ So we get the following problems: $$\left.\begin{matrix}
X''+ \lambda X=0, 0<x<a\\ 
X'(0)=X'(a)=0
\end{matrix}\right\}\tag{*}$$ $(*) \Rightarrow $ The eigenvalues are $\lambda =0$ and the corresponding eigenvalue is $X_0(x)=1$; $\lambda_n =\left(\frac{n \pi}{a}\right)^2$ and the eigenfunctions are $ X_n(x)= \cos\left(\frac{n \pi x}{a}\right)$. $$\left.\begin{matrix}
Y_n''- \lambda_n Y_n=0,\quad 0<y<b\\ 
u(x,0)=\sum_{n=0}^{\infty} X_n(x)Y_n(0)= \cos{(\frac{\pi x}{a})}\\
u(x,b)=\sum_{n=0}^{\infty} X_n(x)Y_n(b)=\cos^2{(\frac{\pi x}{a})}\end{matrix}\right\}
\tag{**}$$ $$(**) \Rightarrow Y_n(y)=\left\{\begin{matrix}
a_0y+b_0, & n=0\\ 
a_n \sinh\left(\frac{n \pi y}{a}\right)+b_n \cosh\left(\frac{n \pi y}{a}\right) & n=1,2,3, \dots\,.
\end{matrix}\right.$$ So $$u(x,y)=a_0y+b_0+ \sum_{n=1}^{\infty}{[a_n \sinh\left(\frac{n \pi y}{a}\right)+b_n \cosh\left(\frac{n \pi y}{a}\right) ] \cos{(\frac{n \pi x}{a})}}$$ By the condition $u(x,0)= \cos{(\frac{\pi x}{a})}$ we get:
$b_0+ \sum_{n=1}^{\infty}{b_n  \cos{(\frac{n \pi x}{a})}}=\cos{(\frac{\pi x}{a})}$ So $$b_0=0, b_1=1, b_n=0(n \neq 1)$$
$$\Rightarrow u(x,y)=a_0y+  \cosh\left(\frac{ \pi y}{a}\right) \cos{(\frac{n \pi x}{a})}  +\sum_{n=1}^{\infty}{a_n \sinh\left(\frac{n \pi y}{a}\right) \cos{(\frac{n \pi x}{a})}}$$ By the condition $u(x,b)=\cos^2{(\frac{\pi x}{a})}$ we get:
$a_0b+  \cosh\left(\frac{ \pi b}{a}\right) \cos{(\frac{n \pi x}{a})}  +\sum_{n=1}^{\infty}{a_n \sinh\left(\frac{n \pi b}{a}\right) \cos{(\frac{n \pi x}{a})}}=\cos^2{(\frac{\pi x}{a})}$ So $$a_0=\frac{1}{2b}, a_1=-\coth{(\frac{\pi b}{a})}, a_2=\frac{1}{2 \sinh{(\frac{2 \pi b}{a})}},\; a_n=0\;(n \geq 3).$$ So the solution is:
$$u(x,y)=\frac{1}{2b}y+[-\coth{(\frac{\pi b}{a})} \sinh{(\frac{\pi y}{a})}+\cosh{(\frac{\pi y}{a})}] \cos{(\frac{\pi x}{a})}+\frac{1}{2 \sinh{(\frac{2 \pi b}{a})}} \sinh{(\frac{2 \pi y}{a})} \cos{(\frac{2 \pi x}{a})}$$ Are the coefficients that I have found correct?? Is the solution of the problem correct??","['ordinary-differential-equations', 'partial-differential-equations']"
781578,Proof of uniform continuity on compact sets,"Show that a function $f:\mathbb{R} \rightarrow \mathbb{R}$ that is continuous on a compact set $K$ is uniformly continuous on $K$. Is the proof below correct? Proof: Let $\epsilon > 0$ and let $x \in K$. Because $f$ is continuous on $K$ there exists a $\delta(x)$ such that whenever $|y - x| < \delta(x)$ it follows that $|f(y) - f(x)| < \epsilon / 3$. Now consider the collection of sets, $$\mathcal{C}_K = \{ V_{\delta(x)}(x) : x \in K \} $$ where $V_{\delta(x)}(x)$ is the open neighborhood $(x - \delta(x), x + \delta(x))$. The collection $\mathcal{C}_k$ form an open cover of $K$ and because we are given that $K$ is compact there exists a finite subcover of $K$: $$\mathcal{C}'_K = \{ V_{\delta(x_n)}(x_n) : n \in \{1, 2, \ldots, N\}\}$$ Before we can find a suitable choice of $\delta$ for the given $\epsilon$ it might be that $K$ is disconnected which can lead to a situation in which there exist $x, y \in K$ such that there exists no open interval contained entirely within $K$ which also contains $x$ and $y$. This will allow the possibility that $x$ and $y$ can be arbitrarily close to each other and yet also allow $|f(x) - f(y)|$ to be larger than our desired maximum value of $\epsilon$. To prevent this situation from occurring define, $$ D = \{ |x_m - x_n| - \delta(x_m) - \delta(x_n) : \forall m, n \in \{1, 2, \ldots, N \} \mathrm{\ such\ that\ } |x_m - x_n| > \delta(x_m) + \delta(x_n)
\} $$ Now take, $$ \delta_{\epsilon} = \min \{ \{ \delta(x_n) : n \in \{1, \ldots, N \}\} \cup D \}$$ Now whenever $|x - y| < \delta_\epsilon$ it must be that $x \in V_{\delta(x_n)}$ and $y \in V_{\delta(x_m)}$ for some $m, n \in \{1, \ldots, N\}$ and there must exist a $l \in \{1, \ldots, N\}$ such that, $$ A = V_{\delta(x_n)}(x_n) \cap V_{\delta(x_l)}(x_l) \neq \emptyset$$ and, $$ B = V_{\delta(x_m)}(x_m) \cap V_{\delta(x_l)}(x_l) \neq \emptyset$$ Let $a$ be a point in $A$ and $b$ be a point in $B$. Then it follows from the way that we have constructed the open cover $\mathcal{C}'_K$ that, $$
\begin{align}
|f(x) - f(y)| &= |f(x) - f(a) + f(a) - f(b) + f(b) - f(y)| \\
              &\leq |f(x) - f(a)| + |f(a) - f(b)| + |f(b) - f(y)| \\
              &< \epsilon / 3 + \epsilon / 3 + \epsilon / 3 \\
              &< \epsilon
\end{align}
$$ Since $\delta_\epsilon$ is independent of $x$ and $y$ we can conclude that $f$ is uniformly continuous on $K$.","['proof-writing', 'proof-verification', 'analysis', 'compactness', 'uniform-continuity']"
781605,Characteristic subgroups $\phi(H) \subseteq H$,"My book uses this definition: Let $G$ be a group. A subgroup $H$ of $G$ is called a characteristic subgroup if $\phi(H) \subseteq H$ for all $\phi \in \operatorname{Aut}(G)$. But after some googling around, it seems that the definition for a characteristic subgroup involves equality $\phi(H) = H$. Does  $\phi(H) \subseteq H$ $\Rightarrow$ $\phi(H) = H$ ??? I tried to multiply by $\phi ^{-1}$ to get $H \subseteq \phi^{-1}(H)$ but I'm not sure if I am allowed to that and I'm even more unsure if $\phi(H) \subseteq H$ and $H\subseteq \phi^{-1}(H)$ $\Rightarrow$ $\phi(H) = H$. Any mathematical wisdom? Thank you.","['group-theory', 'abstract-algebra']"
781658,The proof of $e^x \leq x + e^{x^2}$ [duplicate],This question already has answers here : proof of inequality $e^x\le x+e^{x^2}$ (4 answers) Closed 8 years ago . How can we prove the inequality $e^x \le x + e^{x^2}$ for $x\in\mathbb{R}$?,"['inequality', 'exponential-function', 'calculus']"
781675,"Determine the location of multiple static bodies based on their ""gravitational"" effect upon a dynamic point?","I am writing a SF story, and though I'm sure that I've violated most of science and math to the Andromeda Galaxy and back, I'd like this part at least to be mathematically accurate. Here is a run down of the problem: There's a group of objects known as 'the artifacts'. These artifacts have a mystical attraction to one another. This attraction functions along the same line as gravity, such that the attraction force ( F ) between any two artifacts is equal to $1/r^2$ (where r is the distance between the two artifacts). For this problem, all other forces acting on the artifacts can be ignored. If the protagonists possess one of these artifacts and the means to measure the total force acting upon it, can they determine the position of the other artifacts (which can be considered to be unmoving)? The protagonists can reposition the artifact that they possess in between measurements. How many measurements are needed if there are only 2 artifacts (including the one possessed by the protagonists)? 4 artifacts? 7? 8? Is there a general rule that tells you how many measurements are needed for N artifacts? What I've done so far (which is basically just solving for the simplest system): Variables Known Artifact position -> ($X,Y,Z$) Force on Known Artifact -> $F$ X-Component of Force on Known Artifact -> $F_X$ Y-Component of Force on Known Artifact -> $F_Y$ Z-Component of Force on Known Artifact -> $F_Z$ Unknown Artifact positions represented by ($X_1...X_N, Y_1...Y_N, Z_1...Z_N$) Distance from Known Artifact to Artifact N -> $r_N$ Equations $r_N = \sqrt{(X - X_N)^2 + (Y - Y_N)^2 + (Z - Z_N)^2}$ $F = 1/r^2$ $F_X = (X_N - X)/r_N^3$ $F_Y = (Y_N - Y)/r_N^3$ $F_Z = (Z_N - Z)/r_N^3$ Solution for System of 2 Artifacts $r_1 = \sqrt{1/F}$ $X_1 = X + F_X\cdot r_1^3$ $Y_1 = Y + F_Y\cdot r_1^3$ $Y_1 = Z + F_Z\cdot r_1^3$ The system of 2 artifacts is trivial to solve, but the other solutions are more complex. Thank you in advance for your help. Also, is there a name for this type of math? I've been calling it reverse-trilateration.","['algebraic-geometry', 'physics']"
781734,Proving a metric induces the product topology,"Let $(M,d)$ and $(N,d')$ be metric spaces. Prove that the product topology is induced by the metric $d_1((x,y),(x',y')=d(x,x')+d(y,y')$ and $d_2((x,y),(x',y'))=\operatorname{max}\{d(x,y),d'(x',y')\}$. I have to say, that I truly have no idea how to prove that a metric induces a certain topology, my guess here is to just  consider the topology induced by the metric as well as the product topology and show that they are included in each other. I don't have a complete proof, but I wrote  a couple of things following that idea: $(1)$ Let $T$ be the product topology and $T_i$ be the topology induced by the metric $d_i$. A basis for the product topology of $M\times N$ contains sets of the form $U\times V$ where $U$ is open in $M$ and $V$ is open in $N$; and a basis for the topology induced by $T_1$ would be the sets of open balls according to the metric $d_1$, this is, the set of all open balls where each ball si given by $$B_{1}((x,y),r) = \{(x',y')\in M\times N:d_1((x,y),(x',y'))<r\}$$ In terms of the metric $d,d'$ the balls could be expressed as $$B_{1}((x,y),r) = \{(x',y')\in M\times N:d(x,y)+d'(x',y')<r\}$$ Which means I need to show that for $(x,y)\in U\times V$ open in $M\times N$ there is a ball such that $$(x,y)\in B_1((x,y),r)\subset U\times V$$ Now, what are exactly those open sets $U$ and $V$?. $M$ and $N$ are metric spaces which means that $U$ and $V$ are open balls according to their respective metric, then I could write $$U=B_{U}(x,\delta)=\{y\in M:d(x,y)<\delta\}$$ $$V=B_{V}(x',\epsilon)=\{y'\in N:d'(x',y')<\epsilon\}$$ I would like to pick $r$ in order that $\pi_{1}^{-1}(B_1((x,y),r))\subset U$ and $\pi_{2}^{-1}(B_1((x',y'),r))\subset V$. I have thought two different ways of working this part, but I don't know which of them is right $(1a)$ One of the ideas to solve this problem was to set $r<\displaystyle\frac{1}{2}\operatorname{min}\{\delta,\epsilon\}$. Doing this I believe that from $d(x,y)+d'(x',y')<r$ I can conclude that $d(x,y)<\delta$ and $d'(x',y')<\epsilon$, therefore the ball is included in the set. $(2a)$ On second thoughts, maybe $(1a)$ was excessive and considering that the set $U\times V$ would have a diameter of $\delta+\epsilon$ according to the metric $d_1$, maybe it would be enough just to sed $r<\delta+\epsilon$ so the open ball would lie inside $U\times V$? Now I will assume the open ball is given, how can I pic $\delta$ and $\epsilon$ to have $U\times V$ inside the ball?.Taking $\delta=\epsilon < \frac{1}{2}r$ seems to be enough. Does this prove that $T=T_1$? $(2)$ Now the ball $B_2$ would be given by $$B_2((x,y),r)=\{(x',y'):\operatorname{max}\{d(x,x'),d'(y,y')\}<r\}$$ Here I don't know how to proceed, my problem with this is that I need to find a relation between $r$ and $\delta,\epsilon$ in order to define the inclusions as I did before, but I believe I need to know more about $d(x,x')$ and $d'(y,y')$ if I were to define $r$.","['general-topology', 'metric-spaces', 'proof-verification']"
781750,How prove the constant term of $\left(1+x+\frac{1}{x}\right)^p\equiv1\pmod {p^2}$,"if $p>3$ is odd prime number,show that:
the constant term of $$\left(1+x+\dfrac{1}{x}\right)^p\equiv1\pmod {p^2}$$ My try: since
$$(1+x+\dfrac{1}{x})^p=\sum_{k=0}^{p}\binom{p}{k}\left(x+\dfrac{1}{x}\right)^k=\sum_{k=0}^{p}\binom{p}{k}\sum_{j=0}^{k}\binom{k}{j}x^{k-2j}$$ so when $k=2j$,then the term is constant.
But how prove this constant $\equiv 1\pmod {p^2}$?","['number-theory', 'analysis']"
781753,The issue of treating an inverse Fourier transform in terms of a tempered distribution.,"Consider the wave equation
$$
u_{tt}=\Delta{u} \quad u(x,0)=f(x) \quad u_t(x,0)=g(x) \tag{*}
$$ A solution to this equation is given by
$$
u(.,t)=f*\partial_t\Phi_t+g*\Phi_t \tag{**}
$$
where $\Phi_t$ is the inverse Fourier transform of the function $\Psi_t(\xi)=\frac{\text{sin}2\pi |\xi|t}{2\pi |\xi|}$. Now for $n=3$, how do we show that $\Phi_t$ as a tempered distribution is given by 
$$
\displaystyle  \langle \Phi_t, h \rangle := \frac{t}{4\pi} \int_{S^2} h(t\omega)\ d\omega \tag{***}
$$
That is
$$
\displaystyle  \Phi_t (h) := \frac{t}{4\pi} \int_{S^2} h(t\omega)\ d\omega
$$
for all Schwartz function $h$? Note that, I am using the following definition of Fourier transform: $$
F[f]=\hat{f}(\xi)=\!\int\limits_{\mathbb{R}^3}\!f(x)e^{-2\pi ix\cdot\xi}dx
$$ and the Fourier transform of a tempered distribution is defined as: $$
\bigl\langle F[\lambda],\varphi\bigr\rangle
=\bigl\langle \lambda,\check{\varphi}\bigr\rangle                           
\quad\forall\,\varphi\in \mathcal{S}
$$ OR: How to verify that $(**)$ is a solution to $(*)$ where $\Phi_{t}$ is a tempered distribution given by $(***)$?","['convolution', 'measure-theory', 'partial-differential-equations', 'distribution-theory', 'wave-equation']"
781796,Can we prove that all equations can be solved via complex numbers?,"$x^2+1=0$ cannot be solved via real numbers. Because of this, we extend the real numbers to complex numbers.We can solve $x^2+1=0$  and $x^2+x+1=0$ equations after we define complex numbers. I wonder if we can solve all equations ( includes only the functions that are analytic.) via complex numbers or not?
 If It is yes, how can we prove that claim? For example: Can $z^{100}-5z+2=e^{i.\operatorname{erf}(z)}$  be solved via complex numbers? where 
$\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}}\int_{0}^x e^{-t^2}\,\mathrm dt$ Note: This is just an example, I am not wondering the solution for a special example, I am wondering if a general proof is possible or not. Update: I mention the functions that are analytic. $\bar z$ or $\Re{(z)}$ are not analytic functions. Thanks for answers.",['complex-analysis']
781802,Prove $G$ is abelian if $f(f(x)) = x$?,"Let $G$ be a finite group and $f$ an automorphism such that $f(f(x)) = x$ , and $f(x) = x$ if and only if $x=e$ . Prove that $G$ is abelian and $f(x) = x^{-1}$ . My attempt: Since $f(f(x)) = x$ , we can divide the elements of $G$ (except e) into pairs $(a,b)$ such that $f(a)=b$ and $f(b)=a$ . So $G$ has odd order. What to do next.. Thanks in advance for any hints.","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
781820,How find the maximum value of $|bc|$,"Question: Given complex numbers $a,b,c$, we have that $|az^2 + bz +c| \leq 1$ holds true for any complex number $z, |z| \leq 1$. Find the maximum value of $|bc|$ It is said this is answer is $$|bc|\le \dfrac{3\sqrt{3}}{16}$$ My idea: let $z=1$,then
$$|a+b+c|\le 1$$
let $z=-1$,then $$|a-b+c|\le 1$$
let $z=0$, then
$$|c|\le 1$$ let $|\theta|=1$,then we have
$$|a(z/\theta)^2+b(z/\theta)+c|\le 1\Longrightarrow |az^2+b\theta z+c\theta^2|\le 1$$
and only this can't solve this problem,Thank you","['inequality', 'complex-analysis']"
781848,Minimum Argument Difference to Make the Lower Bound > the Upper Bound,"Assume $g$ is a function that grows asymptotically as 
$$
g(n) \in\frac n {log(n)} + O(\sqrt n),\,n \in \Bbb N\tag1
$$
I wish to find $h(n)$ such that
$$
g(n) \le g(n+h(n)).
$$
i.e. Given the bounds
$$
\begin{align}
u(n)=\frac n {log(n)} + \sqrt{n} \tag 2 \\
l(n)=\frac n {log(n)} - \sqrt{n} \tag 3
\end{align}
$$
what $h(n)$ would give
$$
u(n)\le l(n+h(n)) \tag 4
$$
Since $h(n)$ would simply be the difference of the inverse functions of $(2)$ and $(3)$, my approach so far has been to look for these. The inverse of $f(n)=n/log(n)$ is given by
$$
f^{-1}(n)=e^{-W(-1/n)} \tag 5
$$
which has the multivalued Lambert W function, where the principal branch for reals stops at $e$. The analytic continuation is
$$
f^{-1}(n) = n \log(n \log(n \log(...\,\,,\,\, n>e \tag 6
$$ 
but I haven't found a way to express the inverse of the bounding functions. Maybe I need a taylor series or some integral to approximate these? Proof of $(6)$ The inverse of $y = {x / log(x)}$ is
$$
x = {y / log(y)}.\tag7
$$
Assume $(7)$ can be equated to
$$
y=x\,log(x\,log(x\,log(x\,...\tag8
$$
The expression inside the first log function is $y$, so we have
$$
y=x\,log(y).\tag9
$$
Dividing through by $log (y)$ confirms the original assumption (for $x>e$). $(8)$ returns the upper branch value (the area of interest), whereas $(5)$ returns only the principal value. Addendum Apparently, $(1)$ is weaker than I intended. How could it be made stronger, such that $(2)$ and $(3)$ are strict bounds? My guess is that substituting $O()$ with something like
$$
o(x^{\frac 1 2 - \epsilon})\tag{10}
$$
would eliminate the implied constant of $O()$, and reflect my intention that $$
\forall n \in \Bbb N, l(n) < g(n) < u(n)\tag{11}
$$ and $(4)$ holds such that
$$
\lim_{n\to \infty} \frac {l(n+h(n))}{u(n)} \to 1^+.\tag{12}
$$","['lambert-w', 'functions', 'approximation', 'inverse', 'prime-numbers']"
781879,What's the Jordan canonical form of this matrix?,given is the $6 \times 6$-matrix $A$: $A = \begin{pmatrix} 0 & 1 & 0 & -1 & 0 & 0 \\ 0 &0&1&1&-1&0\\ -1&0&0&0&-1&-1 \\ 1 & 0&0&0&1&0 \\ 0&1&0&0&0&1 \\ 0&0&1&1&0&0 \end{pmatrix}$ With only the information that $A$ has exactly two different eigenvalues one eigenvalue is $t_1 = i$ I have to determine the Jordan-matrix. How can I do this with only the information of $t_1 = i$ ?,"['jordan-normal-form', 'linear-algebra', 'eigenvalues-eigenvectors']"
781885,What is the number of self dual boolean functions?,"The dual of a Boolean function $F(x_1,x_2 \dots x_n,+,\bullet)$, written as $F^D$, is the same expression as that of $F$ with $+$ and $\bullet$ swapped. $F$ is said to be self-dual if $F=F^D$. What is the number of self-dual functions with $n$ Boolean variables? I have no clue where to begin with. Any subtle hint would be great. Thanks !","['boolean-algebra', 'discrete-mathematics']"
781911,Question about function notation,"I'm learning function notation and will soon be doing Calculus - having trouble with this question: Question: Find the x- and y- intercept of each function: $f(x) = x^2 + 3x$ If I set x to 0, I find out that Y would be obviously equal to 0. I'm not sure how to do that for the other value. I try: $f(x) = x^2 + 3x$ $y = x^2 + 3x$ $0 = x^2 + 3x$ $-3x = x^2$ I don't know what to do from there, if I even did anything correct On another topic, is their any easy introductory book for Calculus I?",['functions']
781921,Showing the normal distribution has points of inflections at $x = \mu \pm \sigma$ and a maximum at $x = \mu$,"$X \sim N(\mu, \sigma^2)$ I.e. the density of $X$ is the normal distribution. I am looking to show that $f_X(x)$ has points of inflections at $x = \mu \pm \sigma$. In my notes it says that we should work with $ln(f_X(x))$ instead of $f_X(x)$ directly as the answer will be equivalent as $ln$ is an increasing function. When I get the first derivative of $ln(f_X(x))$ w.r.t. $x$ I get $\frac{-x + u}{\sigma^2}$. This implies a critical point of $x$. Then the second derivative is $\frac{-1}{\sigma^2} < 0$ so $x$ is a maximum. But how do I show the points of inflection are $x = \mu \pm \sigma$?","['statistics', 'normal-distribution', 'probability-distributions', 'probability']"
781931,Caught in the net,"I'm reading through some notes one locally convex spaces (""lcs"" from now on) analysis and there the following version of the Banach-Steinhaus theorem is given Theorem (Banach-Steinhaus) $\quad$ The pointwise limit  of a sequence of continuous, linear mappings from a barrelled lcs $U$ to a lcs $V$ is again a continuous, linear mapping. followed by the remark If we replace ""sequence"" with ""net"" this needn't be the case: For a
  discontinuous functional $f:U\rightarrow \mathbb{K}$ we can construct
  for each subspace $W\subseteq U$ a continuous, linear functional $F_W$
  such that $f\big|_W=F_W\big|_W$. Can someone explain, or give me a hint, how to make this construction from the last sentence above explicit ? I'm also not sure how to use this to obtain a counterexample to the theorem above ? I somehow can't think of a way to make use of a point of discontinuity in $x_0\in U$ of $f$ to show that the net $(F_W)_W$ doesn't converge at all at $x_0$ (at least I intuitively think that this is the case - opposed to that the net indeed converges everywhere, but not to a continuous, linear functional).","['examples-counterexamples', 'locally-convex-spaces', 'functional-analysis', 'nets']"
781935,Elementary proofs of subadditivity of positive index of inertia,"Denote the number of positive eigenvalues of a Hermitian matrix by $P(\cdot)$. If $A,B$ Hermitian, show that $$P(A+B)\leq P(A)+P(B).$$ I know there is an elementary proof: Subadditivity of positive index of inertia But my teacher says that this problem has other elementary proofs. Can anybody help? Thank you.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
782007,"Does $f$ exist such that $f(1)<0 , f(5)>3 $ and $ f'(x)\le e^{-f(x)}$","Does there exist a continuously differentiable function $f:[1,5]\rightarrow\mathbb{R}$ such that $f(1)<0 , f(5)>3$ and $f'(x)\le e^{-f(x)}$ ? My Attempt : If such $f$ exists the mean value theorem states: $\exists c \in(1,5) :$ $$f(5)-f(1)=f'(c)(5-1)$$ Now $$f'(c)(5-1)\le 4e^{-f(c)}\implies f(5)-f(1)\le 4e^{-f(c)}$$ and $$f(5)-f(1)>3$$ Therefore $$3<4e^{-f(c)} \implies -f(c)>\ln(3/4)$$ $$\implies f(c)<-\ln(3/4)$$ This dosen't result in the nice contradiction I was searching for, does such a function exist?",['real-analysis']
782030,Prove that matrices have equal rank.,"If $P$ and $Q$ are $n \times n$ matrices of real numbers such that $P^2=P$ and $Q^2=Q$ and $I-P-Q$ is invertible where $I$ is an $n \times n$ identity matrix, Show that $P$ and $Q$ have the same rank. If $P$ is non-singular, then it can be shown that $P=Q=I$, so they have same rank. But I can't prove it when $P$ is singular.","['matrices', 'linear-algebra']"
782035,When are all ring homomorphisms also algebra homomorphisms?,"Let $k$ be an algebraically closed field, and let $A,B$ be two unitary $k$-algebras. In general, there are more ring homomorphisms $A\to B$ than there are $k$-algebra homomorphisms. More precisely, the forgetful functor from $k$-algebras to rings induces an injective map of sets $$j:\hom_{k\textrm{-Alg}}(A,B)\to \hom_{\textrm{Ring}}(A,B).$$ Question . Under what conditions on $k,A,B$ is $j$ a bijection? There is a particular case I am looking at. I have a finite dimensional $k$-vector space $V$ and the ring $A=k[x,y,z]$. If $B=\textrm{End}_k(V)$ is the ring of $k$-linear endomorphisms of $V$, does $$\hom_{\textrm{Ring}}(A,B)\cong\hom_{k\textrm{-Alg}}(A,B)$$ hold in this case? Thank you!","['vector-spaces', 'ring-theory', 'category-theory', 'abstract-algebra']"
782038,Find a formula for $\sin(5x)$ in terms of $\sin(x)$ and $\cos(x)$.,I was asked to find a formula for $\sin(5x)$ in terms of $\sin(x)$ and $\cos(x)$. I thought about using euler formula which gives: $$\sin(5x) = e^{i\sin(5x)} = \cos(\sin(5x))+i\cdot sin(\sin(5x))$$ Do you think that's was the intention of this excerise? Another solution might be: $$\sin(5x) = \sin(4x + x) = \sin(4x)\cos(x) + \cos(4x)\sin(x)$$,"['trigonometry', 'calculus', 'algebra-precalculus']"
782039,Function compositions that are in $L^p$,"We have $f \in L^p$. The goal is to show that $\exists \psi \in C(\mathbb{R^+}, \mathbb{R^+})$ such that $$ \lim_{s \to +\infty} \frac{\phi(s)}{s}=+ \infty \text{ and } \phi(|f|) \in L^p$$ I neeed some pointer on how to begin. Edit: I went to my professor for a hint and he said that there exists a continous function $\psi$ such that $\lim_{s \to \infty}\psi(s)=+\infty$ with $\sum \psi(n)a_n < \infty$ for a convergent series of poistive terms. Use $\psi$ to construct $\phi$.","['lp-spaces', 'integration', 'real-analysis', 'analysis']"
782059,A sharper bound for $\|\cos(kA)\|_{\infty}$ for symmetric stochastic matrices,"Given $A \in \mathbb{R}^{n \times n}$ that is symmetric, stochastic and diagonalizable, and $k \in \mathbb{N}$, I am interested in bounding $\|\cos(kA)\|_{\infty}$ from above. $\| \|_{\infty}$ is the induced $\ell_{\infty}$ norm, i.e. $\|A\|_{\infty} = \max_{i}\sum_j|A_{i,j}|$, and the cosine of a matrix can be defined, for instance, via its Taylor expansion, $\cos(A) = \sum_t \frac{(-1)^{t}}{(2t)!}A^{2t}$. The trivial bound is of course $\cosh(k)$. However, it seems highly untight for large $k$. For instance, we also have $\|\cos(kA)\|_{\infty} \le \sqrt{n}\|\cos(kA)\|_{2} = \sqrt{n}$ (since $\cos(kA)$ is normal and its largest eigenvalue is at most $1$). Can you see a tighter bound in the special case where $A$ is doubly stochastic? Thank you very much.","['matrices', 'normed-spaces', 'linear-algebra']"
782078,Incremental Calculation of the Sample Covariance,"The formula to calculate the sample covariance given $n$ vector samples $x_{i}$ for $i = 1, \ldots, n$ is as follows: \begin{align*}
S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal
\end{align*} where $m$ is defined as the sample mean:
\begin{align*}
m &= \frac{1}{n}\sum\limits_{i=1}^{n}x_{i}
\end{align*} I have to prove that the formula for $S$ can be rewritten as:
\begin{align*}
S &= \frac{\left(\sum\limits_{i=1}^{n} x_{i} x_{i}^\intercal\right) - n\ mm^\intercal}{n - 1}
\end{align*} I have started my proof off as follows:
\begin{align*}
S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal \\
&= \frac{\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal}{n - 1} \\
&= \frac{\sum\limits_{i=1}^{n}(x_{i}x_{i}^\intercal - x_{i}m^\intercal -mx_{i}^\intercal + mm^\intercal)}{n - 1} \\
\end{align*} This is where I do not know how to proceed further. To me it seems that the only way to proceed would be to show that $x_{i}m^\intercal = mx_{i}^\intercal = mm^\intercal$, but I do not think this equality makes sense..","['statistics', 'linear-algebra', 'probability']"
782093,What are well-defined functions? [duplicate],"This question already has an answer here : ""Well defined"" function - What does it mean? (1 answer) Closed 5 years ago . What exactly makes a function well-defined? I have seen some proofs but they are too hand-wavy and I couldn't understand exactly what a well-defined function is.",['abstract-algebra']
782096,$\left(A\times B\right)^n=A^n\times B^n$?,"Is this property true: For any set $A$ and $B$: $$\left(A\times B\right)^n=A^n\times B^n?$$ Where $A\times B$ is the Cartesian product and $A^n=\underbrace{A\times A\times \cdots\times A}_{n\, \text{times}}$.","['notation', 'elementary-set-theory']"
782119,"how to calculate all numbers of the form $6x-1, 6x+1, 6x+5$ that are not divisible by $5,7$ or $11$?","This is purely a hobbist question, I would simply like to know what methods are currently used to find the answer to this question. (Does modular arithmetic suffice in finding all the ""$x$"" values that when plugged back into all of the 3 functions: $6x-1,6x+1$ and $6x+5$, will give numbers that aren't divisible by 5,7 or 11? And if yes, how so?) Thank you. P.S.: I know that there is exactly 64 functions I would need to plug into the ""$x$"" value to solve this. But I want to know what other methods there are in solving this! :)","['algebra-precalculus', 'number-theory']"
782148,Inner Product Space vs. Vector Space,"I had no trouble understanding what a vector space is: a constraint on the type of vectors you can create, such that certain operations could be performed with them. For example, a vector space of 
$$\left( \begin{array}{ccc}
a  \\
a\\
a\end{array} \right)$$ fulfills all the requirements of vector spaces and is represented by a straight line through the origin. However I cannot understand what an Inner Product Space is. My first thought was that it's a set of vectors that fulfill certain requirements like Symmetry, Positivity, Multiplicity etc, similar to the concept of vector space. However, upon further observation, I realized that all vector spaces have these properties. If it is a vector space, it seems it is already an Inner Product Space. So what exactly does the Inner Product Space do for us? What does it add?
Is there a visual representation of an Inner Product Space?","['linear-algebra', 'inner-products', 'machine-learning']"
782152,Groups past exam question help,"I've been having some trouble with the following type of question: I think I can do part (a) and part (c). (a) The subset is the set of all elements with self-inverses: $E =\lbrace e,rot_{\pi},ref_0,ref_{\pi /4}, ref_{pi /2}, ref_{3\pi /2} \rbrace $ (c) First in the $\rightarrow$ direction. Assume $\varphi \in Hom(G,G)$ and let $x,y \in G$, then $$\varphi(xy)=(xy)^{-1}$$ $$\implies \varphi(x) \varphi(y)=y^{-1} x^{-1}$$ $$\implies x^{-1} y^{-1} =y^{-1} x^{-1},$$ hence abelian. In the $\leftarrow$ direction. Assume $G$ is abelian. Let $x,y \in G$, then $$\varphi(xy)=(xy)^{-1} = y^{-1}x^{-1} = x^{-1}y^{-1} = \varphi(x)\varphi(y).$$ Hence $\varphi \in Hom(G,G)$. For (b) I don't really have a clue what I'm trying to show, or the technique to do it. Many thanks.","['group-theory', 'abstract-algebra']"
782156,Evaluate $\frac{2}{4}\frac{2+\sqrt{2}}{4}\frac{2+\sqrt{2+\sqrt{2}}}{4}\cdots$,"Evaluate 
$$
\frac{2}{4}\frac{2+\sqrt{2}}{4}\frac{2+\sqrt{2+\sqrt{2}}}{4}\frac{2+\sqrt{2+\sqrt{2+\sqrt{2}}}}{4}\cdots .
$$ First, it is clear that terms tend to $1$. It seems that the infinity product is not 0. This is related to the post Sequence $x_{n+1}=\sqrt{x_n+a(a+1)}$ .","['convergence-divergence', 'calculus', 'limits']"
782163,$x'=Ax$ has one periodic solution. Prove that all solutions are periodic.,"I want to prove the following: 1) Suppose $$A_{2,2}=\begin{pmatrix} a_{1,1} & a_{1,2} \\ a_{2,1} & a_{2,2} \end{pmatrix}$$
 real
   and suppose the system of differential equations $$\begin{matrix}
        x'=a_{1,1}x+a_{1,2}y\\
        y'=a_{2,1}x+a_{2,2}y
 \end{matrix}$$ has at least one periodic solution $\begin{pmatrix} x \\ y \end{pmatrix}=\begin{pmatrix} f(t) \\ g(t) \end{pmatrix}$. 
   Show that in this case, all solutions are periodic. 2) Suppose $A \in M_{n,n}(\mathbb{R})$ is invertible with $n$ odd. Show that there exists a solution to the system of equations $x'=Ax$ that is not periodic. I came up to the following. We proved in lecture that an ODE of this kind has a solution of the form $x(t)=\exp(At)\,x(0)$. As our solution is periodic of period $\omega$, we know: $$
\begin{pmatrix} f(t) \\ g(t) \end{pmatrix}
=exp(At)\,\begin{pmatrix} f(0) \\ g(0) \end{pmatrix}=\exp(A(t+\omega))\,\begin{pmatrix} f(0) \\ g(0) \end{pmatrix}=\begin{pmatrix} f(t+\omega) \\ g(t+\omega) \end{pmatrix}$$ My ideas was now to show that $\exp(At)=\exp(A(t+\omega))$ and then deduce that all solutions have to be periodic. But I kinda stuck by how I should prove this.","['ordinary-differential-equations', 'periodic-functions']"
782179,Find the probability distribution for the number of spades.,"Three cards are drawn in succession from a deck without replacement. Find the probability
distribution for the number of spades.","['statistics', 'probability-distributions', 'probability']"
782186,"Proof of ""Japanese Theorem"" -- Triangulation of Cyclic Polygon","On Mathoverflow, I saw this great result on the ""Japanese Theorem"". “Japanese Theorem” on cyclic polygons: Higher-dimensional generalizations? Given triangulation of a cyclic polygon, the sum of the areas inradii of the incircles of the triangles is independent of the triangulation. How do we prove this result that make the independents of the triangulation obvious. The inradius is related to the area by $\boxed{\text{Area} = \text{semiperimeter} \times \text{inradius}}$ .  Perhaps this can be used to re-create the conservation law above? Also, it is sufficient to prove this result for a cyclic quadrilateral and compare the two triangulations. Proof :  Wikipedia says is based on Carnot's Theorem : $OO_A+OO_B+OO_C = R + r$ , where $r$ is the inradius, and $R$ is the circumradius, $OO_A,OO_B,OO_C$ distances to the sides of the triangle. In that case, I am not understanding proof of this Carnot's result, or why - if we sum over the triangles in the triangulation - this sum is independent of the triangulation.","['euclidean-geometry', 'triangulation', 'circles', 'combinatorics']"
782216,Is my induction proof of the handshake lemma correct? (Graph Theory),"I am an high-school senior who loves maths, I decided to taught myself some basic Graph Theory and I tried to prove the handshake lemma using induction. While unable to find any proofs similar to the one I wrote on the Internet, I wonder if mine is incorrect or just presented differently. Any advice, remarks or critic would be warmly welcomed! Let P be the following proposition ""In any graph, the sum of the degrees of all vertices is equal to twice the number of edges:"" $$\textrm{P(n)}:\sum_{V\;\in\;G} deg(|V|) = 2n\;\;\;where\;\;|E| = n\\$$ Base case:  $P(0): 2n = 0 |_{n=0}.$ Since there aren't any edge the number of vertices must be equal to $1$ or $0$. $$\sum_{V\;\in\;G} deg(|V|) = deg(|V|) = 0\;\text{the number degree equal to }0.\\\text{thus, }P(0)\text{ is true}$$ Induction step: Assuming that $P(n)$ is true for a given natural number.Let show that $P(n)\Rightarrow P(n+1).$ $$P(n):\sum_{V\;\in\;G} deg(|V|) = 2n\\
\sum_{V\;\in\;G} deg(|V|) + 2= 2n + 2\\
\sum_{V\;\in\;G} deg(|V|) + 2 = 2(n+1)\\
which\;yield\;by\;adding\;two\;vertices\;of\;degree\;1\\P(n)\Rightarrow P(n+1)$$ $$\forall n \in \mathbb{N}, \sum_{V\;\in\;G} deg(|V|) = 2|E|\\
\textrm{For any given graph G, the sum of the degree of all vertices is equal}\\\textrm{to twice the number of edges.}$$ Thanks all, I really want to understand what is wrong (if anything!) $$PS:\;Sorry\;for\;any\;grammar\;faults\;or\;horrible\;\LaTeX\;formatting$$","['graph-theory', 'induction', 'discrete-mathematics', 'proof-verification']"
782272,sequence of complex polynomials $p_n$ s.t. $p_n(0) = 1$ for every $n \in \mathbb{N}$ and $p_n(z) \to 0$ for each $\mathbb{C}-\{0\}$?,Is there a sequence of complex polynomials $p_n$ s.t. $p_n(0) = 1$ for every $n \in \mathbb{N}$ and $p_n(z) \to 0$ for each $z \in \mathbb{C} \setminus \{0\}$? Any help with this would be great!,"['complex-analysis', 'analysis']"
782284,"How to prove or is there any reference to ""integration-by-parts"" formula for difference quotients?","I found this identity in Lawrence C.Evans' book 'Partial Differential Equations' 2ed edition, page293, where $\phi \in C_{c}^{\infty}(V) \ and\ V\subset \subset U$, then $\int_{V}u(x)\frac{\phi(x+he_i)-\phi(x)}{h}dx=-\int_{V}[\frac{u(x)-u(x-he_i)}{h}]\phi(x)dx$
It says ""this is the 'integration-by-parts' formula for difference quotients."" I'd like to know is there any proof or reference of this  ""integration-by-parts"" formula for difference quotients?","['ordinary-differential-equations', 'partial-differential-equations', 'real-analysis']"
782318,Non-unique prime factorisation,"G is a number system where $(a,b)$ belongs in G where $a$ and $b$ is an element of the integers $\mathbb{Z}$. multiplication is defined as follows: $(a, b) \times (c, d) := (ac-5bd , ad+bc)$ $(6,0)$ is one number that has non-unique prime factorisation. Find two more numbers in G that each have non-unique prime factorisation.  One of your
numbers must of the form $(a, 0)$, and the other one of the
form $(a, b)$ where $b$ does not equal $0$ . Basically I understand how $(6,0)$ has non-unique prime factorisation because $(6,0) = (1,1) \times(1,-1)$ is one prime factorization $(6,0) = (2,0) \times (3,0)$ is another prime factorization But i need to find two more numbers like this but is there a certain method to finding more numbers like $(6,0)$ because I'm sure I'm not just supposed to do trial and improvement.
Can anyone help?",['number-theory']
782334,Interview Question Asked In yahoo,"Can you find the smallest positive number such that if you shuffle the digits of the number in a particular order, the shuffled number becomes twice the original number. Source: http://gpuzzles.com/mind-teasers/very-hard-maths-riddle/ I understand the answer is $125874 => 251748$ $251748$ is twice the $125874$ and have same digits $1,2,4,5,7$ & $8$ but how to solve this non programmatic ?","['puzzle', 'discrete-mathematics']"
782362,Bound of a certain sum of cosines,"Let $N$ be a sufficiently large natural number
and let $k \in \mathbb{N}$ such that $k | N$. Suppose I have
a sequence $\{ \alpha_j \}_{j=1}^N \subseteq [0,1)$, which satisfies
$$
\# \{ j \in \{1, ..., N\} : \alpha_j \in [l/k, (l+1)/k) \} = N/k
$$ 
for $l = 0, ..., k-1$.
What is a bound for 
$$
\sum_{j=1}^N cos(2 \pi \alpha_j) ?
$$ I was guessing that if $k$ is large enough, then perhaps there would be enough cancelation to make the sum small. I would appreciate any help with it. Thank you!","['trigonometry', 'elementary-number-theory', 'number-theory']"
782374,Notation: is it correct to state $3a=a3$?,"If $a$ is a real constant, do you regard $3a$ and $a3$ as equal or different?","['notation', 'algebra-precalculus']"
782386,Is $f(x)=0$ the only function that is both even and odd?,Is $f(x)=0$ the only function that is both even and odd? Thanks to you.,"['algebra-precalculus', 'functions']"
782414,integration of $\int \frac{1}{x+ i\:y}\mathrm{d} x$,"I can't seem to find where this result comes from
$$
\int \frac{1}{x+  i\:y}\mathrm{d} x = \frac{\ln(x^2
+y^2)}{2} - i \: \arctan \left( \frac{x}{y} \right)
$$ by my calculation the result should be
$$
\int \frac{1}{x+  i\:y}\mathrm{d} x = \frac{\ln(x^2
+y^2)}{2} + i \: \arctan \left( \frac{y}{x} \right)
$$ as $$
\frac{\mathrm{d} }{\mathrm{d} x} \ln (x+a) = \frac{1}{x+a}  \Rightarrow \int \frac{1}{x+  a}\mathrm{d} x = \ln (x+a) 
\\
\ln (x+a)  = \ln (|x+a| e^{i \arg{(x+a)}}) = \ln \left( \sqrt{x^2+y^2} \right) + i \underbrace{\arg{(x+a)}}_{\arctan \left( \frac{y}{x} \right)}
$$","['integration', 'complex-analysis']"
782432,Prove that $\nabla_A \mbox{Tr} \left( A A^T \right) = 2A$,"Prove that $$\nabla_A \mbox{Tr} \left( A A^T \right) = 2A$$ where $A$ is any square matrix. I did a simple derivative with product rule, but I don't know where i messed up. I started with $$ \nabla_A \mbox{Tr} \left( A A^T \right) = \mbox{Tr} \left( \frac {\partial A}{\partial A}A^T+A\frac {\partial A^T}{\partial A} \right) $$","['trace', 'matrices', 'matrix-calculus', 'derivatives', 'scalar-fields']"
782436,Can any function be upper bounded by a separable function?,"Given a function $f(x,y)$, can we always find functions $h(x), g(y)$ such that $$f(x,y) \leq h(x) + g(y)$$ for all $x,y, \geq 0$? Note that I have placed no restrictions on the functions $f(x,y), g(x), h(y)$ above. Now perhaps this will fall out automatically from of the answer, but I would also be interested to know if it makes any difference whether $f(x,y)$ is continuous or smooth, and if the answer is yes in that case, whether $h(x)$ and $g(y)$ can then be taken to be continuous/smooth as well.",['analysis']
782449,Why is $\lim_{x\rightarrow 0^{+}} x^{1/x}=0?$,"Why is $\lim_{x\rightarrow 0^{+}} x^{1/x}=0?$ I believe it is from graphing it, but I'm not able to prove it.  Log w/ L'Hospitals isn't working for me since ln(x)/x isn't the right indeterminant form.","['real-analysis', 'limits']"
782461,Galois extension and morphism of curves,"Let $\phi: C \rightarrow \mathbb P^1$ a morphism (over a field of characteristic 0) from a rational curve $C$ to $\mathbb P^1$ of degree 3. By the Riemann-Hurwitz formula the degree of the ramification divisor is 4, hence $\phi$ can ramify in three possible ways:
(a) two points of ramification index 3; (b) one point of ramification index 3 and two point of ramification index 2; (c) four points of ramification index 2. The morphism $\phi$ corresponds to an extension of fields $k(t) \subset k(C)$ of degree 3. This extension can be a Galois extension or not. (1) In which cases (a), (b) or (c) can this extension be Galois? Suppose it is not, and suppose that its Galois closure $k(t) \subset k(C) \subset k(B)$ corresponds to the function field of another curve $B$, so that we have a morphism $\psi: B \rightarrow C$. (1) What is the degree of the extension $k(C) \subset k(B)$ or, in other words, what is the degree of $\psi$? (2) What is the genus of $B$? (3) What are the possible ramification indexes of the composite morphism $\phi \circ \psi$?","['galois-theory', 'riemann-surfaces', 'algebraic-geometry']"
782484,Countable limit ordinal as limit of $\omega$ ordinals,"I've got a most probably silly question, but I can't find the answer to it: If $\alpha$ is a countable limit ordinal, how can we be sure that there exist ordinals $\alpha_n$ such that $\alpha = \bigcup \{\alpha_n\mid n\in\omega\}$ (rather than the usual $\alpha = \bigcup \{\beta\mid \beta<\alpha\}$)? Cheers!","['ordinals', 'elementary-set-theory']"
782492,A question on ergodic theory: topological mixing and invariant measures,"This is a question on dynamical systems. Suppose I have a compact metric space $X$, with $([0,1], B, \mu)$ a probability space, with $B$ a (Borel) sigma algebra, and $\mu$ the probability measure. Suppose also that $\mu(A) > 0$ for any nonempty set $A \subset X$. If we take a measure invariant transformation $T:X\to X$ and assume it is NOT topologically mixing, how do we show it CANNOT be mixing with respect to $\mu$? This is how I would attempt it.  Take two sets nonempty open sets $A$ and $B$ in $X$. Since we know that T is NOT topologically mixing, there are infinitely many natural numbers $n \in \mathbb{N}$ such that $T^{n}(A) \cap B = \emptyset$. The preimage of $T^{n}(A)$ is $T^{n-1}(A)$. By measure preservation, we have $\mu (T^{n-1}(A)) = \mu(T^{n}(A))$. By repeated argument, we eventually have $\mu (T^{-n}(A)) = \mu(A)$. Now we have $T^{-n}(A) \cap B = \emptyset$ for infinitely many $n$. Hence $\mu(T^{-n}(A) \cap B) = 0$. This contradicts the requirement that for mixing, we need $\mu(T^{-n}(A) \cap B) = \mu(A)\mu(B)$ in the limit of $n$ tending to infinity, as the our assumption was that the measure of any nonempty set is bigger than zero. Proof complete. Is this correct, or are there any gaps or errors in my logic? If it is faulty, I'd be grateful to see the correct version. Thanks!","['dynamical-systems', 'ergodic-theory', 'solution-verification', 'measure-theory', 'mixing']"
782507,Chern-Weil: why do we divide by $2\pi$?,"So here's a somewhat incoherent question. To define characteristic classes in the Chern–Weil way, one takes a curvature form $\Omega$ on a vector bundle $E \to M$ and an invariant polynomial $f$ on $\mathrm{GL}(\mathrm{rk }(E),\mathbb R)$, and then forms the cohomology class $c = \Big[f\big(\!\frac 1{2\pi}\Omega\big)\Big]$. Why do we divide by $2\pi$? I understand why in the sense that ""it works"": if we want an integral class, so that $\langle c, [M] \rangle = \int_M f\big(\!\frac 1{2\pi}\Omega\big) \in \mathbb Z$, and agreeing with other standard definitions of these classes, dividing by $2\pi$ works, and not doing it doesn't. But why does it work? ""Morally,"" why is this the right thing to do? I suppose this is analogous to asking why one always divides by $2\pi i$ in complex analysis, but there I feel I have some grasp on the answer: Cauchy's theorem holds, the only power of $z$ whose antiderivative isn't well-defined everywhere a power is $1/z$, and $t \mapsto z_0 + re^{it}$ describes one loop around a point $z_0$ as $t$ ranges from $0$ to $2\pi$. I don't have even that clear an understanding what's going on in the case of the Chern–Weil homomorphism.","['characteristic-classes', 'algebraic-topology', 'differential-geometry']"
782526,How to prove that $A^{-1} + B^{-1}$ is invertible given the conditions,"If $A$ and $B$ be two invertible $n \times n$ real matrices and $A + B$ is invertible, how to prove that $A^{-1} + B^{-1}$ is also invertible?","['matrices', 'linear-algebra']"
782541,Why do we say $n$ distinct points?,""" Let's say we have $n$ distinct points... "" , you see this every time you open a geometry textbook. Why not just $n$ points ? If the points are not distinct, they are not exactly $n$ points, are they ? We don't write a set as $ \{x_1,x_2,x_3\}$ where $x_1 =x_2$, or do we ? Can you give me an example of a case in geometry, where an ambiguity might arise if one does not do so ?","['geometry', 'terminology', 'soft-question']"
782586,"How do you minimize ""hinge-loss""?","A lot of material on the web regarding Loss functions talk about ""minimizing the Hinge Loss"". However, nobody actually explains it, or at least gives some example.
The best material I found is here from Columbia , and I include some snippets from it below. I understand the hinge loss to be an extension of the 0-1 loss. The 0-1 Loss Function gives us a value of 0 or 1 depending on if the current hypothesis being tested gave us the correct answer for a particular item in the training set.
The hinge loss does the same but instead of giving us 0 or 1, it gives us a value that increases the further off the point is. This formula goes over all the points in our training set, and calculates the Hinge Loss $w$ and $b$ causes. It sums up all the losses and divides it by the number of points we fed it. where This much makes sense to me. What's confusing me is as follows: How do you plot a hinge loss function? How do you minimize it? Isn't the minimal always zero? How should I understand the typical hinge loss graph? Are they just gross oversimplifications?
For example, the green line represents the hinge loss function you see in every image in a Google search for ""hinge loss"". **Please, **Can someone provide (for the world) a simple example of hinge loss minimization? Let's say I have four negative points (blue circles) and four positive points (red squares). What would the loss function look like? How do I minimize (mathematically, and with intuition). Knowing this would be a huuuge help for me, and probably for many others, as the resources on this popular topic are scarce. Thanks!","['optimization', 'machine-learning', 'graphing-functions', 'functions', 'quadratic-programming']"
782624,seeing the differential dx/y on an elliptic curve as an element of the sheaf of differentials,"$\newcommand{\CC}{\mathbb{C}}\newcommand{\Spec}{\operatorname{Spec}}$ It's a well known fact that every elliptic curve (say, over a field $k$ ) has a global holomorphic nowhere vanishing differential. If the curve is given by $y^2 = x^3 + ax + b$ , then it's computed in Silverman (p33, example 4.6), that the differential $dx/y$ is holomorphic and nonvanishing. Hence, the line bundle of holomorphic differentials should be trivial, corresponding to a free rank 1 sheaf of relative differentials. On the other hand, let $E$ be some elliptic curve over $k = \CC$ , say given by the equation $y^2 = x^3 - 1$ . Then the existence of a nowhere vanishing holomorphic differential should imply that the sheaf of relative differentials $\Omega_{E/k}$ is free of rank 1. In particular, we can restrict the sheaf $\Omega_{E/k}$ to the affine locus given by the ring $$R := \CC[x,y]/(y^2-x^3+1)$$ The restriction of $\Omega_{E/k}$ to $U := \Spec R$ is then just the sheaf associated to the $R$ module $$\Omega_{R/k} = (Rdx\oplus Rdy)/(2ydy - 3x^2dx)$$ The global sections of $\Omega_{E/k}|_U$ should then just be the elements of $\Omega_{R/k}$ . In particular, $dx/y$ should be an element of the module $\Omega_{R/k}$ . My question is: how do you see $dx/y$ as an element of $\Omega_{R/k}$ ? Am I missing some algebra trick?","['algebraic-geometry', 'elliptic-curves']"
782644,Infinite sum of ideals,"I've been trying to prove that given a ring $R$ and a collection of ideals $\{I_{\beta}\}_{\beta \in B}$ in $R$, the set $$\sum_{\beta \in B} I_{\beta}=\{f_1+\cdots+f_r:f_j \in I_{\beta_j}, \mbox{ for some } I_{\beta_j}\}$$ is an ideal and is the smallest ideal containing $\cup_{\beta \in B} I_{\beta}$. I've already proved when I only have two ideals, and so, using induction, I've seen it for finite sums. But I don't see how to generalise that to an arbitrary family of indexes (maybe infinite) $\beta$. Could someone please give me a hand? Thank you.","['ideals', 'abstract-algebra']"
782678,tangent/normal space to set of symmetric isospectral matrices,"Let $\Lambda = \{\lambda_1, \ldots, \lambda_n\}$ be a set of $n$ distinct real numbers. $M_n(\mathbb{R})$ denotes the set of all $n \times n$ real matrices, and for $B\in M_n(\mathbb{R})$, $B^T$ denotes the transpose of B, and $\sigma(B)$ is the (multi)set of the eigenvalues of $B$. I'm trying to figure out the tangent space and the normal space to the set $$S = \{ B \in M_n(\mathbb{R}) \, : \, B^T = B, \sigma(B) = \Lambda\},$$
at the point $A= \text{diag}(\lambda_1,\ldots,\lambda_n)$, the diagonal matrix with diagonal entries $\lambda_i$'s. Note that $S$ is a manifold in a neighborhood of $A$. This is my thought process: 
Define a path in $S$ as follows: 
$$A(t)= Q(t) \, A \, Q(t)^T,$$ for a family of orthogonal matrices $Q(t)$, such that $Q(0) = I$, the identity matrix. Then $A(0) = A$. \begin{align*}\dot{A}(t) &= \dot{Q}(t) \, A \, Q(t)\\ &+\, {Q}(t) \, \dot{A} \, Q(t)\\ &+ \,  {Q}(t) \, A \, \dot{Q}(t) \end{align*}
But $\dot{A} = O$, hence $$\dot A(0) = \dot Q(0) \, A + A \, \dot Q(0)^T.$$ So, if I know all the tangents/normals to orthogonal matrices at $0$, that is, at $I$, I can describe all the tangents/normals to $S$ at $A$. But it is not too hard to show that the set of all skew-symmetric matrices (i.e. $\{B : B^T = -B\}$) is the tangent space to the orthogonal matrices at $I$. Hence, the tangent space to $S$ at $A$ is $$ T_A(S) = \{ B \, A + A \, B^T : B^T = -B \}.$$ So here are my questions: Question 0: Is my argument above correct? Question 1: Why are these all of the tangent vectors? I think(?) $S$ is an $n(n-1)/2$ dimensional manifold, and $T_A(S)$ is $n(n-1)/2$ dimensional, is that really the reason for $T_A(S)$ begin the whole tangent space? Can you elaborate on it, please? Question 2.1: What is the normal space to the set of orthogonal matrices, at $I$? Question 2.2: How do you find the normal space to $S$ at $A$? Is it the same as the following? 
$$\{B \in M_n(\mathbb{R}) : C\, B = O, \forall C \in T_A\}.$$ Edit: Direct calculations yield that $T_A(S)$ is the set of all symmetric matrices with zero diagonals, as long as $\lambda_i$'s are all distinct.","['matrices', 'linear-algebra', 'lie-groups', 'differential-geometry']"
782684,"What is a ""control point""?","I'm trying to figure out a good definition of control point for use in wikipedia (see https://en.wikipedia.org/wiki/Control_point_(mathematics) ) There seems to be a bias towards ascribing a computer-graphics/CAD basis/usage for the term, but is it really limited to that field?  I was thinking that control point might be a term used more generally in mathematics/geometry/topology to describe sets of points that describe curves/surfaces/manifolds -- is it a mistake to think it a general term?","['geometry', 'general-topology', 'manifolds', 'spline', 'numerical-methods']"
782690,Simple module over matrix rings [duplicate],"This question already has answers here : Simple $M_n(D)$-module with $D$ a division ring (3 answers) Closed 6 years ago . I'm trying to prove that if $M$ is a simple module over $M_n(D)$ where $D$ is a division algebra, then $M\cong D^n$. I know that if $M$ is a simple module over $R$ then it is isomorphic to $Rv=\{rv|r\in R\}$ for all $v\in M$. I'm trying to find a $M_n(D)$ module isomorphism $f:M_n(D)v\rightarrow D^n$. I've been told to try the map that maps $Xv\mapsto Xe_1$, where $e_1$ is the column vector with 1st entry 1 and the rest 0. I can prove that this is a homomorphism but I'm stuck on the injectivity. Any help would be well appreciated!","['modules', 'matrices', 'abstract-algebra']"
782707,Hyperplane not containing a given set of points over a Noetherian scheme,"This is related to the answer in this question: Showing that a power of an ample sheaf is equivalent to an effective Cartier divisor Let $X$ be a quasiprojective scheme over a Noetherian ring A and suppose we have a very ample sheaf $\mathcal{L} \cong i^\ast O(1)$ for $i$ an immersion into projective space. Then, given a finite set of points $F$ (say the associated points of $X$) I want to show that there is a hyperplane $H \in \mathcal{O}(1)$ such that it does not meet any of these points, i.e that $Supp H \cap F = \emptyset.$ I was told that this is really tautologous, and I believe it is, but I am afraid I don't see it. I have seen arguments of the form previously, but never felt completely comfortable with them and thus I would be interested to see a careful proof (or as careful as you have the energy to give) of doing this. In the comments, it seems as if the statement I am making here is not true. Basically, I am interested in this just to get a detailed answer for the previous question, so feel free to reinterpret the question as long as the previous question gets a detailed answer.",['algebraic-geometry']
