question_id,title,body,tags
1334661,Finding the sum of the series $\frac{1}{1!}+\frac{1+2}{2!}+\frac{1+2+3}{3!}+ \ldots$,"Deteremine the sum of the series
$$\frac{1}{1!}+\frac{1+2}{2!}+\frac{1+2+3}{3!}+ \ldots$$ So I first write down the $n^{th}$ term $a_n=\frac{\frac{n(n+1)}{2}}{n!}=\frac{n+1}{2(n-1)!}$. So from there I can write the series as $$1+\frac{3}{2}+\frac{4}{2\times 2!}+\ldots +\frac{n+1}{2(n-1)!}+\ldots $$ I am quite sure I can do some sort of term by term integration or differentiation of some standard power series and crack this. Any leads?","['sequences-and-series', 'real-analysis']"
1334678,Does mathematics become circular at the bottom? What is at the bottom of mathematics? [duplicate],"This question already has answers here : When does the set enter set theory? (7 answers) Closed 9 years ago . I am trying to understand what mathematics is really built up of. I thought mathematical logic was the foundation of everything. But from reading a book in mathematical logic, they use ""=""(equals-sign), functions and relations. Now is the ""="" taken as undefined? I have seen it been defined in terms of the identity relation. But in order to talk about functions and relations you need set theory. 
However, set theory seems to be a part of mathematical logic. Does this mean that (naive) set theory comes before sentential and predicate logic? Is (naive)set-theory at the absolute bottom, where we can define relations and functions and the eqality relation. And then comes sentential logic, and then predicate logic? I am a little confused because when I took an introductory course, we had a little logic before set-theory. But now I see in another book on introduction to proofs that set-theory is in a chapter before logic. So what is at the bottom/start of mathematics, logic or set theory?, or is it circular at the bottom? Can this be how it is at the bottom? naive set-theory $\rightarrow$ sentential logic $\rightarrow $ predicate logic $\rightarrow$ axiomatic set-theory(ZFC) $\rightarrow$ mathematics (But the problem with this explanation is that it seems that some naive-set theory proofs use logic...) (The arrows are of course not ""logical"" arrows.) simple explanation of the problem: a book on logic uses at the start : functions, relations, sets, ordered pairs, ""="" a book on set theory uses at the start: logical deductions like this: ""$B \subseteq A$"", means every element in B is in A, so if $C \subseteq B, B \subseteq A$, a proof can be ""since every element in C is in B, and every element in B is in A, every element of C is in A: $C \subseteq A$"". But this is first order logic? ($(c \rightarrow b \wedge b \rightarrow a)\rightarrow (c\rightarrow a)$). Hence, both started from each other?","['foundations', 'elementary-set-theory', 'logic']"
1334701,$1+\sqrt[3]{e^{2a}}\sqrt[5]{e^{b}}\sqrt[15]{e^{2c}} \leq \sqrt[3]{(1+e^{a})^2}\sqrt[5]{1+e^{b}}\sqrt[15]{(1+e^{c})^2}$,"The inequality $1+\sqrt[3]{e^{2a}}\sqrt[5]{e^{b}}\sqrt[15]{e^{2c}} \leq \sqrt[3]{(1+e^{a})^2}\sqrt[5]{1+e^{b}}\sqrt[15]{(1+e^{c})^2}$ is true for all $a,b,c\in\mathbb{R}$? I've tried to use the Bernoulli inequality $(1+k)^n \geq 1+kn$ but my inequality don't satisfy the conditions. My other apporach was by the binomial theorem $(1+x)^n = \sum_{k=0}^n {n \choose k}x^k$ but with non integer power I don't see a way here to solve it.","['binomial-theorem', 'real-analysis', 'algebra-precalculus', 'inequality']"
1334726,"Can $\text{conv} \{ e_1,e_2,e_3, (1/2, 1/2, 1) , (1/2, 1, 1/2) , (1, 1/2, 1/2) \}$ be reduced to a convex hull of a subset of these?","How do I see whether $$\text{conv} \{ e_1,e_2,e_3, (1/2, 1/2, 1) , (1/2, 1, 1/2) , (1, 1/2, 1/2) \}$$ can be reduced to a convex hull of a subset of these vectors? That is, if $D = \{ e_1,e_2,e_3, (1/2, 1/2, 1) , (1/2, 1, 1/2) , (1, 1/2, 1/2) \}$ does there exist a proper subset $S \subset D$ such that $\text{conv}(D) = \text{conv}(S)$ ? By inspection it seems that I cannot write any of the vectors as a convex combination of the others, does this imply that $D$ is minimal ?","['calculus', 'algebra-precalculus', 'linear-algebra', 'convex-optimization', 'convex-analysis']"
1334740,Totally geodesic hypersurface in compact hyperbolic manifold,"In [Zeghib: Laminations et hypersurfaces géodésiques des variétés hyperboliques, Annales scientifiques de l'ENS, 1991] it is shown, that in a compact manifold of negative curvature, there exists only a finite number of totally geodesic hypersurfaces (codim=1) without self-intersections. Now my question: Is there an example of such a compact manifold M (with dim(M) > 2)  , that allows even one totally geodesique hypersurface? 
Or a result that proofs the existence? In manifolds of variable curvature it is not clear, that there exists even one totally geodesic hypersurface. In the case of constant curvature it is clear in the universal covering (hyperbolic space), bur for a compact manifold?","['differential-geometry', 'hyperbolic-geometry', 'riemannian-geometry', 'gromov-hyperbolic-spaces']"
1334759,Total derivative of inner product.,"Let $$F:\Bbb R^n\times\Bbb R^n\to\Bbb R$$ be the function $F(x,y)=\langle Ax,y\rangle$ where $\langle , \rangle$ denotes the standard inner product on $\Bbb R^n$ and $A$ be an $n\times n$ real matrix. If $D$ denotes the total derivative. which of the fallowing is correct? 1). $(DF(x,y))(u,v)=\langle Au,y\rangle+\langle Ax,v\rangle$ 2). $(DF(x,y))(0,0)=(0,0)$ 3). $DF(x,y)$ may not exist for some $(x,y)\in\Bbb R^n\times\Bbb R^n$ 4). $DF(x,y)$ doesnot exist at $(x,y)=(0,0)$ I don't know, how the total derivative is defined for Inner product. So, tell me the definition for total derivative on inner product space, also tell, How to proceed further to solve this problem? Thank you","['inner-products', 'multivariable-calculus', 'matrix-calculus']"
1334762,"How to show that if $\sum_na_n=\infty$ and $a_n\downarrow 0$ then $\sum\limits_n\min(a_{n},\frac{1}{n})=\infty$? [duplicate]","This question already has an answer here : If $\sum_na_n=\infty$ and $a_n\downarrow 0$ then $\sum\limits_n\min(a_{n},\frac{1}{n})=\infty$ [duplicate] (1 answer) Closed 6 years ago . Suppose $a_n\downarrow 0, \sum\limits_{n=1}^{\infty}a_n=+\infty,   b_n=\min\{a_n,1/n\}$. Prove that $\sum b_n $ diverges. In fact, I have known that two positive divergent series $\sum a_n ~\sum b_n$,  $c_n=\min\{a_n,b_n\}, \sum c_n$ is not always divergent.
But I do not know why this above series is surely divergent. Sincerely thanks.","['sequences-and-series', 'real-analysis']"
1334767,The maximal size of between $\varphi(n)$ divided by $\lambda(n)$.,"I want to find $$f(n) = \max\left\{\frac{\varphi(k)}{\lambda(k)} : 1 \leq k \leq n\right\}$$ In other words, I want to find the maximal value of $\frac{\varphi(k)}{\lambda(k)}$ when $k$ is restricted. $\lambda(n)$ is the Carmichael function, the smallest $k$ such that for all $a$ such that $\gcd(a,n)=1$ the following congruence holds: $a^{k} \equiv 1 \mod n$. $\varphi(n)$ is the Euler-phi function. Note that $\lambda(n) \mid \varphi(n)$. Since I don't expect $f(n)$ to have a nice expression in terms of elementary and number theoretic functions, I started to search for some lower bounds. I found that $$\frac{\varphi(2^k \cdot p_{k+1}\#)}{\lambda(2^k \cdot p_{k+1}\#)} \geq 2^k$$ Here $k\#$ is the primorial function. Therefore I know that the fraction is unbounded, and that $$f(n) \in \Omega(n^{1/ \ln \ln n})$$ However $n^{1/ \ln \ln n}$ is still bounded above by all power functions with a positive power. Does anyone have an asymptotically better bound or a proof that this is the best bound? I looked to OEIS, which has this sequence A034380 . I found that the smallest $n$ such that $f(n)\geq 108$ is $n=3591$, the smallest $n$ such that $f(n)\geq 128$ is $n=5440$. However my method gives $1241560320$ as a number such that it is bigger than 128. Clearly, there is some room for improvement. Conjecture: Will Jagy found strong numerical evidence that $f(n)$ eventually outgrows $n^{1-\varepsilon}$ for every $\varepsilon > 0$. A proof (or disproof) of this would be very welcome.","['asymptotics', 'number-theory', 'carmichael-function', 'special-functions']"
1334795,Is the following function a constant function,Suppose that $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire and bounded on the set $\{z \in \mathbb{C}; Re(z) \leq 0\}$. Is $f$ a constant function. I know by Picards theorem that a non-constant entire function assumes all but one value in the complex plane. Can this result be tweaked and applied here? Any hints?,"['complex-analysis', 'complex-numbers']"
1334848,Is theoretical Linear Algebra still an active field of research?,"Numerical Linear Algebra seems to be a very active area right now, but is there any work still being done on the purely theoretical side? To put it another way...is it possible for someone to write a book titled ""All of Linear Algebra"" and actually create a closed set of concepts that encompass this field? For example, I'm thinking a book like Peter Lax's Linear Algebra and its Applications seems to be close to this, but a lot of reviewers of the book stated it was a select group of topics.","['education', 'linear-algebra', 'soft-question']"
1334857,cycle space in graph theory,"I read the following definition of the cycle space in a set of notes. Definition (Cycle space): Let $G=(V,E)$ . The cycle space of $G$ is an element of $2^{E}$ denoted $\mathcal{C}$ and is the smallest set (of sets) containing the $\emptyset$, all cycles in $G$ and (where each cycle is treated as a set of edges) and all unions of edge disjoint cycles in $G$. Surely they made a mistake when they said $\mathcal{C}$ is an element of $2^{E}$? Surely they actually mean that $\mathcal{C} \subseteq 2^{E}$?","['graph-theory', 'linear-algebra', 'combinatorics', 'algebraic-graph-theory']"
1334863,"Proof about finitely generated torsion-free R-module M is free, where R is a PID","Proof about finitely generated torsion-free $R$-module $M$ is free, where $R$ is a PID. Can I prove by the following way? Proof by induction on $n$, where $M=\langle v_1,...,v_n\rangle$. If $n=1$, then $M$ is cyclic, and it's easy to see $M\cong R$, thus $M$ is free. For the inductive step, let $M=\langle v_1,...,v_{n+1}\rangle$ and define $S=\langle v_{n+1}\rangle$. And as M is torsion free thus its submodule M/S is torsion free. And clearly M/S is generated by n elements. Thus by inductive hypothesis, M/S is free. Thus M/S is a projective module. Thus by the sequence: 0$\to S \to M \to M/S \to 0$, we can get $M\cong S\oplus M/S$. And we know S is free, thus M is free. Is there a mistake in my proof? Thank you!","['abstract-algebra', 'principal-ideal-domains', 'modules']"
1334869,When is the restriction of a normal operator not normal?,"I was proving the spectral theorem for normal operators on finite-dimensional complex vector spaces today during a test, when I arrived at the point in which If $T\in\operatorname{End}(V)$ is normal, then if $W$ is a subspace of $V$ is $T$-invariant ""surely"" the restriction $T|_W\colon W\to W$ must be normal too. But the professor said he could find a counterexample.
Now, the claim above was true in that case, but I'm still curious about that example.
Practically, he said that it can happen that the restriction of the adjoint $T^*$ may not coincide with the adjoint of $T$ in $W$, in other words
$$
(T|_W)^*\ne (T^*)|_W.
$$ When is it true (in finite-dimensional vector spaces)?","['adjoint-operators', 'linear-algebra']"
1334870,How to find sum of the infinite series $\sum_{n=1}^{\infty} \frac{1}{ n(2n+1)}$,$$\frac{1}{1 \times3} + \frac{1}{2\times5}+\frac{1}{3\times7} + \frac{1}{4\times9}+\cdots $$ How to find sum of this series? I tried this: its $n$ th term will be = $\frac{1}{n}-\frac{2}{2n+1}$ ; after that  I am not able to solve this.,"['calculus', 'limits', 'real-analysis', 'logarithms', 'sequences-and-series']"
1334887,Is this a homomorphism? Matrix homomorphism $\phi:\Bbb R\to GL_2(\Bbb R)$,"My book claims that the following is a homomorphism: $$\phi:\Bbb R\to GL_2(\Bbb R),\phi(a)=\begin{bmatrix}1&0\\a&1\end{bmatrix}$$ But it doesn't seem to be: $$\phi(ab)=\begin{bmatrix}1&0\\ab&1\end{bmatrix}$$
$$\phi(a)\phi(b)=\begin{bmatrix}1&0\\a&1\end{bmatrix}\begin{bmatrix}1&0\\b&1\end{bmatrix}=\begin{bmatrix}1&0\\a+b&1\end{bmatrix}$$ Right? What am I missing?","['abstract-algebra', 'group-homomorphism', 'matrices']"
1334890,Show that the sequence $\langle b_n\rangle$ Converges to $1$,"The following question was asked in my Masters entrance examination but unfortunately I was unable to answer this. Please tell me how to approach this problem correctly. Suppose $\langle a_{mn}\rangle$ is a double sequence such that $1$. $ \forall n$, $b_n :=
 $$\lim_{m\to\infty} a_{mn}$ exists. $2$. $ \forall$ increasing sequences $\langle m_k\rangle$ and $\langle n_k\rangle$ of positive integers  $\lim_{k\to\infty} a_{m_k n_k} =1$ Show that sequence $\langle b_n\rangle$ converges to  $1$.","['sequences-and-series', 'convergence-divergence', 'real-analysis']"
1334904,differential inclusions vs differential equations,"Can someone please clarify what the difference (no pun intended) between the two is? I am reading this tutorial and at the very start they state that a differential inclusion is a solution to $
\frac{\mathrm{d}}{\mathrm{d}t}x(t) \in F(t, x(t))
$ So that means that the derivative of $x(t)$ is included in $F$ which is a function the argument $t$ and the $x(t)$ itself. Then a solution is a family of functions, right? But why is this different the just a differential equation? I suppose it's meant to be more general, but right now I'm failing to see where. P.S. no tag for differential inclusions, so differential equations it is.",['ordinary-differential-equations']
1334907,Reversing the Order of Integration and Summation,"I am trying to understand when we can interchange the order of Integration and Summation. I am increasingly encountering Integrals; some of which are being solved by interchanging the order of Summation and  Integration, and some which cannot (for no given reason) be solved using this.
Despite looking at a variety of sites, I was unable to understand when we can do so. $$$$ I came up with the following two requirements here on MSE: $$$$ If $f_n(x)\ge 0$ for all $x,n$ $$\sum \int f_n(x) \, dx = \int \sum f_n(x) \,dx$$ Also if $\sum \int |f_n| < \infty$ or $\int \sum |f_n| < \infty$ , then $$\int \sum f_n = \sum \int f_n$$ I would be grateful if somebody could  please explain this to me. Thanks very much in advance.","['summation', 'calculus', 'integration']"
1334923,What are the differences between $361°$ and $1°$?,"So since my high school algebra tells me that $361°$ is basically rotating the whole axis around and adding $1$ more degree, I would assume that at least in trigs they are the same. But then $1°$ is acute, while $361°$ is not classified as either acute, obtuse or right. I understand this difference. Then just out of curiosity, what other differences (any subtle differences would count) exist between $361°$ and $1°$?",['geometry']
1334969,To find continuous functions on $\mathbb R$ which preserve certain algebraic structures,"Can we determine all non-constant continuous functions $f:\mathbb R \to \mathbb R$ such that for every subgroup $G$ of $(\mathbb R,+)$, $f(G)$ is also a subgroup of $(\mathbb R,+) $ ? And similarly, characterize all continuous functions on $\mathbb R$ which preserves subrings and also those which preserves $\mathbb Q$-vector subspaces of $\mathbb R$ ?","['abstract-algebra', 'continuity', 'linear-algebra', 'real-analysis']"
1334982,"Product of two continuous, non-negative and monotone non-decreasing function is itself..","My question is simple: 
is the product of two continuous, non-negative and monotone non-decreasing function itself a continuous, non-negative and monotone non-decreasing function? I believe the result holds for sequences but I don't know enough advanced math to know if this implies this results also holds for continuous functions.","['calculus', 'functions']"
1334983,Gauss elimination: Difference between partial and complete pivoting,"I have some trouble with understanding the difference between partial and complete pivoting in Gauss elimination. I've found a few sources which are saying different things about what is allowed in each pivoting. From my understanding, in partial pivoting we are only allowed to change the columns (and are looking only at particular row), while in complete pivoting we look for highest value in whole matrix, and move it ""to the top"", by changing columns and rows. Is this correct, or am I wrong?","['gaussian-elimination', 'linear-algebra', 'numerical-methods', 'matrices']"
1334986,Not contradiction of Picard-Lindelöf theorem,"I have this homework problem: Consider the following initial value problem:
  $$\frac{dy}{dt}=6t\sqrt[3]{y^2}$$
  $$y(0)=0$$
  Demonstrate that this I.V.P has a different solution of $y(t)=0$, $\forall t \in \mathbb{R}$. Explain why this doesn't contradict the Picard-Lindelöf problem. So I found a solution for this I.V.P: $$y=t^6$$ Picard-Lindelöf theorem says that: For a differential equation of the form: $\frac{dy}{dt}=f(t,y)$ with the initial condition $y_0=y(t_0)$, if $f(t,y)$ is Lipschitz continuous, then I.V.P solution exists and it's unique on a open interval which contains $t_0$. In this case, $f(t,y)$ is $C^1$, and so, Lipschitz continuous. Then Picard-Lindelöf theorem is applicable. 
Only for $t=0$, this two solutions are equal. So, I can only say that unicity is valid for $t=0$. Can I consider an open interval of the form $]t_0 -\varepsilon, t_0+\varepsilon[=]-\varepsilon,\varepsilon[$, so that Picard-Lindelöf theorem holds?",['ordinary-differential-equations']
1334997,To Reconcile Two Different Descriptions of the Dual Bundle,"$\newcommand{\mc}{\mathcal}$
Let $\pi:E\to M$ be a smooth vector bundle with typical fibre a $k$-dimensional vector space $\mc V$. There are (at least) two ways to construct the dual bundle of $E$. Direct Approach: Define $E^*$ as the disjoint uinon $\bigcup_{p\in M}E^*_p$. Define $\pi^*:E^*\to M$ as $\pi(E^*_p)=\{p\}$.
For each smooth local trivialization $\Phi:\pi^{-1}(U)\to U\times \mc V$ of $E$ over $U\subseteq M$, define $\Phi^*:{\pi^*}^{-1}(U)\to U\times \mc V^*$ as $\Phi^*(v)=(p, \Phi_p^{-t}v)$ for all $v\in E^*_p\cap {\pi^*}^{-1}(U)$. Then using the vector bundle construction theorem, one can establish that there is a unique topology and smooth structure such that $\pi^*:E^*\to M$ is a smooth vector bundle over $M$ with typical fibre $\mc V^*$. Associated Bundle Approach: Consider the frame bundle $F(E)$ which is known to be a principal $GL(\mc V)$-bundle. Define a representation of $GL(\mc V)$ on $\mc V^*$ by defining a map $\rho:GL(\mc V)\to GL(\mc V^*)$ as $\rho(T)=T^{-t}$ (Here $T^{-t}$ means the inverse of the transpose of $T$). Then we can define the dual bundle of $\pi:E\to M$ as the associated bundle of $F(E)$ with respect to the representation $\rho$. These two constructions look quite different. One way to show that they are same is by coming up with a bundle isomorphism between them. Can somebody please try to give some intuition as to why these two constructions are same? Thank you.","['principal-bundles', 'differential-geometry', 'smooth-manifolds', 'vector-bundles']"
1335002,An infinite series in polygamma function,"I'm interested in $2$ things: $1)$ if you're used to such series and when you met before such series and $2)$ the tools you might like to employ $3)$ I don't ask for a solution . Calculating in closed form
$$\sum _{n=1}^{\infty } (24 \psi ^{(-3)}(n)-24 \psi ^{(-3)}(n+1)+24 \psi ^{(-2)}(n+1)-12 \text{log$\Gamma $}(n+1)+4 \psi ^{(0)}(n+1)-\psi ^{(1)}(n+1))$$ EDIT: I conjecture the beautiful closed form 
$$36 \log (A)+3 \gamma+\zeta (2) -6 \log (2 \pi )-\frac{3 \zeta (3)}{2 \zeta (2)}$$ Here is another example with conjuctured closed form $$\sum _{n=1}^{\infty } (90 \text{log$\Gamma $}(n+1)-3628800 \psi ^{(-9)}(n)+3628800 \psi ^{(-9)}(n+1)-3628800 \psi ^{(-8)}(n+1)+1814400 \psi ^{(-7)}(n+1)-604800 \psi ^{(-6)}(n+1)+151200 \psi ^{(-5)}(n+1)-30240 \psi ^{(-4)}(n+1)+5040 \psi ^{(-3)}(n+1)-720 \psi ^{(-2)}(n+1)-10 \psi ^{(0)}(n+1)+\psi ^{(1)}(n+1))$$
$$=-810 \log (A)+3240 \zeta '(-7)+11340 \zeta '(-5)+7560 \zeta '(-3)+\frac{810 \zeta (3)}{\pi ^2}+\frac{42525 \zeta (7)}{\pi ^6}-\frac{8505 \zeta (5)}{\pi ^4}-\frac{127575 \zeta (9)}{2 \pi ^8}-\frac{\pi ^2}{6}+\frac{13371}{280}-9 \gamma +55 \log (2)-2 \log (32)+45 \log (\pi )$$ And again, a last one $$\sum _{n=1}^{\infty }(380 \text{log$\Gamma $}(n+1)-2432902008176640000 \psi ^{(-19)}(n)+2432902008176640000 \psi ^{(-19)}(n+1)-2432902008176640000 \psi ^{(-18)}(n+1)+1216451004088320000 \psi ^{(-17)}(n+1)-405483668029440000 \psi ^{(-16)}(n+1)+101370917007360000 \psi ^{(-15)}(n+1)-20274183401472000 \psi ^{(-14)}(n+1)+3379030566912000 \psi ^{(-13)}(n+1)-482718652416000 \psi ^{(-12)}(n+1)+60339831552000 \psi ^{(-11)}(n+1)-6704425728000 \psi ^{(-10)}(n+1)+670442572800 \psi ^{(-9)}(n+1)-60949324800 \psi ^{(-8)}(n+1)+5079110400 \psi ^{(-7)}(n+1)-390700800 \psi ^{(-6)}(n+1)+27907200 \psi ^{(-5)}(n+1)-1860480 \psi ^{(-4)}(n+1)+116280 \psi ^{(-3)}(n+1)-6840 \psi ^{(-2)}(n+1)-20 \psi ^{(0)}(n+1)+\psi ^{(1)}(n+1))$$ 
$$=-7220 \log (A)+64980 \zeta '(-17)+1472880 \zeta '(-15)+10310160 \zeta '(-13)+28721160 \zeta '(-11)+35103640 \zeta '(-9)+19147440 \zeta '(-7)+4418640 \zeta '(-5)+368220 \zeta '(-3)+\frac{16245 \zeta (3)}{\pi ^2}+\frac{57994650 \zeta (7)}{\pi ^6}+\frac{62199262125 \zeta (11)}{\pi ^{10}}+\frac{11755660541625 \zeta (15)}{\pi ^{14}}+\frac{176334908124375 \zeta (19)}{2 \pi ^{18}}-\frac{1104660 \zeta (5)}{\pi ^4}-\frac{2261791350 \zeta (9)}{\pi ^8}-\frac{1119586718250 \zeta (13)}{\pi ^{12}}-\frac{58778302708125 \zeta (17)}{\pi ^{16}}-\frac{\pi ^2}{6}+\frac{17504273203}{16081065}-19 \gamma +210 \log (2)-2 \log (1024)+190 \log (\pi )$$
I already said the previous is going to be the last one, but this one is the last one
$$\sum_{n=1}^{\infty}(870 \text{log$\Gamma $}(n+1)-265252859812191058636308480000000 \psi ^{(-29)}(n)+265252859812191058636308480000000 \psi ^{(-29)}(n+1)-265252859812191058636308480000000 \psi ^{(-28)}(n+1)+132626429906095529318154240000000 \psi ^{(-27)}(n+1)-44208809968698509772718080000000 \psi ^{(-26)}(n+1)+11052202492174627443179520000000 \psi ^{(-25)}(n+1)-2210440498434925488635904000000 \psi ^{(-24)}(n+1)+368406749739154248105984000000 \psi ^{(-23)}(n+1)-52629535677022035443712000000 \psi ^{(-22)}(n+1)+6578691959627754430464000000 \psi ^{(-21)}(n+1)-730965773291972714496000000 \psi ^{(-20)}(n+1)+73096577329197271449600000 \psi ^{(-19)}(n+1)-6645143393563388313600000 \psi ^{(-18)}(n+1)+553761949463615692800000 \psi ^{(-17)}(n+1)-42597073035662745600000 \psi ^{(-16)}(n+1)+3042648073975910400000 \psi ^{(-15)}(n+1)-202843204931727360000 \psi ^{(-14)}(n+1)+12677700308232960000 \psi ^{(-13)}(n+1)-745747076954880000 \psi ^{(-12)}(n+1)+41430393164160000 \psi ^{(-11)}(n+1)-2180547008640000 \psi ^{(-10)}(n+1)+109027350432000 \psi ^{(-9)}(n+1)-5191778592000 \psi ^{(-8)}(n+1)+235989936000 \psi ^{(-7)}(n+1)-10260432000 \psi ^{(-6)}(n+1)+427518000 \psi ^{(-5)}(n+1)-17100720 \psi ^{(-4)}(n+1)+657720 \psi ^{(-3)}(n+1)-24360 \psi ^{(-2)}(n+1)-30 \psi ^{(0)}(n+1)+\psi ^{(1)}(n+1))$$
$$=-25230 \log (A)+353220 \zeta '(-27)+20663370 \zeta '(-25)+413267400 \zeta '(-23)+3734166150 \zeta '(-21)+17426108700 \zeta '(-19)+45149463450 \zeta '(-17)+67476121200 \zeta '(-15)+59041606050 \zeta '(-13)+30099642300 \zeta '(-11)+8713054350 \zeta '(-9)+1357878600 \zeta '(-7)+103316850 \zeta '(-5)+3178980 \zeta '(-3)+\frac{88305 \zeta (3)}{\pi ^2}+\frac{2324629125 \zeta (7)}{\pi ^6}+\frac{61753772705625 \zeta (11)}{2 \pi ^{10}}+\frac{179518217255251875 \zeta (15)}{\pi ^{14}}+\frac{735127099660256428125 \zeta (19)}{2 \pi ^{18}}+\frac{363887914331826931921875 \zeta (23)}{2 \pi ^{22}}+\frac{38208231004841827851796875 \zeta (27)}{4 \pi ^{26}}-\frac{30995055 \zeta (5)}{2 \pi ^4}-\frac{588131168625 \zeta (9)}{2 \pi ^8}-\frac{10559895132661875 \zeta (13)}{4 \pi ^{12}}-\frac{18849412811801446875 \zeta (17)}{2 \pi ^{16}}-\frac{40431990481314103546875 \zeta (21)}{4 \pi ^{20}}-\frac{7641646200968365570359375 \zeta (25)}{4 \pi ^{24}}-\frac{114624693014525483555390625 \zeta (29)}{8 \pi ^{28}}-\frac{\pi ^2}{6}-\frac{16571275403939220313}{40156716600}-29 \gamma +435 \log (2)+435 \log (\pi )$$","['sequences-and-series', 'calculus', 'real-analysis']"
1335011,"Let $X \subseteq \mathbb R$ and $X$ has same cardinality as $\mathbb R$ , does there always exist a continuous surjection from $\mathbb R$ onto $X$ ?","Let $X \subseteq \mathbb R$ and $X$ has same cardinality as $\mathbb R$ , does there always exist a continuous surjection from $\mathbb R$ onto $X$ ? ( I know that there need not always be a continuous surjection from $X$ onto $\mathbb R$ , for example when $X$ is closed bounded interval )","['continuity', 'real-analysis', 'cardinals']"
1335096,"Proof of strictly increasing nature of $y(x)=x^{x^{x^{\ldots}}}$ on $[1,e^{\frac{1}{e}})$?","The title is fairly self explanatory: I have been trying to rigorously prove that $y(x)=x^{x^{x^{\ldots}}}$ is a strictly increasing function over the interval  $[1,e^{\frac{1}{e}})$ for a while now, primarily by exploring various manipulations using logarithms and polylogarithms but have gotten nowhere. Although it is simple enough to show that $y(\sqrt{2})>y(1)$ and if $y'(x)>0$ for some $x \in [1,e^{\frac{1}{e}})$ then $y'(x)>0$ for all $x \in [1,e^{\frac{1}{e}})$ (since either $y$ must be strictly increasing or strictly decreasing), I am not satisfied by the rigor of this argument, although perhaps this is me being too finicky. This lack of progress has led me to explore the possibility that it is only strictly non-decreasing but this loosening of constraints has not helped at all. When it comes to proving that it is a function I've been at a loss as to where I might even begin. Any and all insights are welcome.","['calculus', 'tetration', 'lambert-w', 'hyperoperation', 'derivatives']"
1335121,Writing product $\prod_{i=1}^m (p_i^{n_i}-1)$ as a sum,"Suppose I have an integer $N$ with prime decomposition $N=\prod_{i=1}^m p_i^{n_i}$. How can I write $$\prod_{i=1}^m (p_i^{n_i}-1)$$ as a sum that only depends on $N$, and not it's prime decomposition? Clearly we have $$\prod_{i=1}^m (p_i^{n_i}-1) = N - \sum_{i=1}^{m} \frac{N}{p_i^{n_i}} + \sum_{\substack{i_1,i_2=1 \\ i_1\leq i_2}}^n \frac{N}{p_{i_1}^{n_{i_1}} p_{i_2}^{n_{i_2}}} \dots$$ So it seems like we could write this as something like $$\prod_{i=1}^m (p_i^{n_i}-1) = \sum_{d|N}\mu(d)\frac{N}{f_{N}(d)}$$ where $f_N(d)$ is a function that looks something like $$f_N(d) = \prod_{p_i|d_i} p_i^{n_i}$$ My questions is, is there already a function like $f_N(d)$ in the literature that will satisfy this? If not, is there some other way to write $\prod_{i=1}^m (p_i^{n_i}-1)$ as a sum that only depends on $N$?","['multiplicative-function', 'number-theory']"
1335143,"Presheaf that do not satisfy: If $\{U_i\}$ is an open cover of $U \subseteq X$ and $s \in \mathcal{F}(U)$, then $s=0$ iff $s|_{U_i}=0$ $\forall i$","Let $X$ be a topological space. Find an example of a presheaf $\mathcal{F}$ that do not satisfy: If $\{U_i\}_{i \in I}$ is an open cover of $U \subseteq X$ and $s \in \mathcal{F}(U)$ , then $s=0$ if and only if $s|_{U_i}=0$ $\forall i \in I$ . Find an example of a presheaf $\mathcal{F}$ that do not satisfy: If $\{U_i\}_{i \in I}$ is an open cover of $U \subseteq X$ and $\{s_i\}_{i \in I}$ is a colection of sections $s_i \in \mathcal{F}(U_i)$ such that $s_i|_{U_i \cap U_j}=s_j|_{U_i \cap U_j}$ , then there exists $s \in \mathcal{F}(U)$ such that $s|_{U_i}=s_i$ $\forall i \in I$ . I know that if $X=\mathbb{R}^n$ , then $\mathcal{F}(U)=\{\varphi:U \rightarrow \mathbb{R} \quad \text{constant function}\}$ is a presheaf but not a sheaf. I think that this example for 2. is the simpliest. However I can't find a simple example for 1. Some help here would be appreciated. Thanks!","['algebraic-geometry', 'sheaf-theory']"
1335146,exponential type of entire function?,"I'm looking at an entire function of the form
$$
f(\lambda):=p(\lambda)e^{-\lambda}+q(\lambda)\;,
$$
where $p$ and $q$ are polynomials and $\lambda\in\mathbb{C}$. I need to establish that $f$ is an entire function of finite exponential type, and to determine its order. This would be helpful in what I'm planning on doing down the road. Any ideas are welcome. This is what I have done so far. Begin by noting that 
$$
e^{-\lambda}=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^n\lambda^n}{n!}\;.
$$
Thus,
$$
\begin{array}{lcl}
|f(\lambda)| &\leq& \displaystyle\sum_{n=0}^{\infty}\left|\frac{\lambda^n p(\lambda)}{n!}\right|+|q(\lambda)|\\
&\leq& e^{|\lambda|+\ln|p(\lambda)|}+e^{\ln|q(\lambda)|}\;.
\end{array}
$$
We say that $f$ is of order $\rho$ if $|f(z)|\leq ce^{{|z|}^{\rho}}$ for $|z|$ large enough, so that $|f(z)|e^{-{|z|}^{\rho}}$ is bounded.","['complex-analysis', 'real-analysis']"
1335161,Proof of Kunneth's formula in Bott & Tu,"Let $M, F$ be smooth manifolds and let's assume all (henceforth, de Rham) cohomologies of $F$ are finite-dimensional. Let $\pi : M \times F \rightarrow M$ and $\rho : M \times F \rightarrow F$ be the projections. There is a pre-sheaf $\mathcal{H}^q$ on $M$, namely $\mathcal{H}^q(U) = H^q(\pi^{-1} U)$. Let's take a good cover $\mathfrak{U}$ of $M$. Then $\mathcal{H}^q$ is locally constant on $\mathfrak{U}$. In fact it is constant; moreso, there are global forms on $M \times F$ which, when restricted to each fiber $F$, freely generate the cohomology. Indeed, we need only take forms $\sigma_1, \ldots, \sigma_n$ in $F$ freely generating $H^q(F)$ and set $\widetilde{\sigma_i} = \rho^{*} \sigma_i$. There is a spectral sequence converging to the cohomology of $M \times F$, and given that the pre-sheaf $\mathcal{H}^q$ is constant (for every $q$) we see that the $E_{2}^{p, q}$ term is $H^{p}(M) \otimes H^{q}(F)$. So far, so good. Now Bott & Tu wish to argue that the $d_2$ on $E_2$ is $0$; they claims that forms on $E_2$ are already global. I don't understand this statement. I'm aware that for any element $\omega \in E_{2}^{p, q} = H^p(\mathfrak{U}, \mathcal{H}^q)$, we will have $\omega(U_{\alpha_0 \ldots \alpha_p}) = \sum_{i = 1}^{n} a^{\alpha_0 \ldots \alpha_p}_{i} [\widetilde{\sigma}_i]$, so that each $\omega(U_{\alpha_0 \ldots \alpha_p})$ is a global form on $M \times F$. But what guarantees that $\omega$ itself is a global form?","['homology-cohomology', 'differential-geometry', 'algebraic-topology']"
1335165,Limit involving Zeta and Gamma function,Can someone help me evaluate this limit? $$\lim_{x\to +\infty}\frac {\zeta(1+\frac 1x)}{\Gamma(x)}$$ I never came across this kind of limit so I don't even know where to start.,"['gamma-function', 'limits', 'riemann-zeta']"
1335169,Prove the relations of the cardinality of sets,"Let us define natural numbers in the following manner (also assume Peano Axioms), 
  $$\varnothing=0\\n^{+}=n\cup\{n\}$$where $n^{+}$ is the successor of $n$. Let $E$ and $F$ be two sets such that there exists a one-to-one correspondence between them. Then we say that $E$ and $F$ are equivalent and write $E\sim F$. A set $E$ is said to be finite if it is equivalent to some natural number. This (unique) natural number is said to be the cardinality of $E$. We will denote this by $|E|$. To be precise, we have $E\sim |E|$. The problems at which I am stuck are (assume $E$ and $F$ to be finite), $|E\cup F|=|E|+|F|-|E\cap F|$ $|E\times F|=|E|\cdot|F|$ I thought to show that the complement of $m$ in $m+n$ is equivalent to $n$ but couldn’t show anything. Any help will be appreciated.",['elementary-set-theory']
1335196,Showing that $f$ is $C^\infty$,"Question: Let $f: U \to \mathbb R$ be a continuous function, with $U \subset \mathbb R^2$ open, such that $$(x^2  +y^4)f(x,y) + f(x,y)^3 = 1,\, \,\, \forall (x,y) \in U$$
  Show that $f$ is of class $C^\infty$. Attempt: Define $F(x,y,z) = (x^2 + y^4)z + z^3 - 1$. Then $$F_z(x,y,z) = (x^2 + y^4) + 3z^2 > 0$$ for any $(x,y,z) \in \mathbb R^3- \{0\}$, and if we fix $(x_0,y_0) \in U$, such that $(x_0,y_0) \neq 0$, then taking $z_0 = f(x_0,y_0) \in \mathbb R$, thus it follows that $F(x_0,y_0,z_0) = 0$. Now by the Implicit Function Theorem we have that $z$ is a defined as a function of $x$ and $y$, such that $$F(x,y,z) = F(x,y,\xi (x,y)) = 0 \tag{1}$$ for every $(x,y,z) \in B \times J$, here $B \subset \mathbb R^2$ and $J \subset \mathbb R$. Clearly $F$ is of class $C^\infty$ then $z = \xi (x,y)$ is of class $C^\infty$. As $f$ is continuous there exists $\delta > 0$ sufficiently small such that $f(B) \subseteq J$, then we may conclude by $(1)$ and by hypothesis $F(x,y,f(x,y)) = 0$, that  $f(x,y) = \xi(x,y)$, for every $x \in B$, it follows then that $f$ is of class $C^\infty$.","['analysis', 'proof-verification', 'implicit-function-theorem']"
1335227,Find the value of a function whose derivative is zero,"The initial function is
$$h(x)=\arcsin  x + \arccos x$$
The derivative of this function is $0$
since $$h'(x)=\frac{1}{\sqrt{1-x^2}}-\frac{1}{\sqrt{1-x^2}}\equiv0$$ This means that $h(x)$ is a constant function; how can I find the value of $h(x)$? Could anyone please explain?","['derivatives', 'calculus', 'trigonometry']"
1335235,Facebook Question (Data Science),"Out of curiosity, here's a question from Glassdoor (Facebook Data Science Interview) You're about to get on a plane to Seattle. You want to know if you
  should bring an umbrella. You call 3 random friends of yours who live
  there and ask each independently if it's raining. Each of your friends
  has a 2/3 chance of telling you the truth and a 1/3 chance of messing
  with you by lying. All 3 friends tell you that ""Yes"" it is raining.
  What is the probability that it's actually raining in Seattle? Using Bayesian analysis, it's pretty clear that you cannot solve this without the prior probability of raining in Seattle. However, here's a different approach which I found interesting in the discussion contained in Glassdoor. Since all three friends said ""Yes"", the question basically boils down to what is the probability that all three friends are telling the truth given that all three friends said ""Yes"". Since you ask all three friends independently, the probability that all three friends are telling the truth is given by (2/3)(2/3)(2/3) = 8/27. Thus, the probability of it raining is 8/27. While this is perhaps a bit compelling, I'm not sure if it's correct. Anyone have any ideas? Thanks!","['probability-theory', 'bayesian']"
1335265,"Is there a ""Coalgebra - Cogeometry"" duality? Good opposite of a category of coalgebras?","So the category of affine schemes is dual to the category of commutative rings, Stone spaces are dual to Boolean algebras, localizable measurable spaces are dual to commutative Von Neumann algebras, and I'm sure there are many more examples. In general, a category of algebraic structures is going to be dual to some related category of geometric structures. My question is, then: is there an analogous story for coalgbraic things? If I take a category of coalgebras for some comonad and flip the arrows around, will I get something interesting? Are there any good examples of this over familiar comonads (say, the costate comonad)?","['coalgebras', 'algebraic-geometry', 'soft-question', 'category-theory']"
1335363,What is the difference between an integral curve and the solution of a differential equation?,"Can you please explain what the difference between an integral curve and the solution of a differential equation is? My book gives an example that $$\frac {dy}{dx}=\frac {y}{x}$$ defines a direction field everywhere except at the origin. the function $y=kx$ is a solution of this equation, and the integral curve is given by $ax+by=0$, where $a,b$ are arbitrary constants. Then the book concludes that y axis is the integral curve of the differential equation, but not the graph of the solution. I know the definition of the integral curve and the solution of an equation. A detailed help would be much appreciated! Thanks in advance!",['ordinary-differential-equations']
1335366,Cosh and Sinh analogs,"We know that 
$$\cosh{x}+\sinh{x}=e^x$$
and that his can be expressed as
$$\frac{e^x+e^{-x}}{2}+\frac{e^x-e^{-x}}{2}=\frac{(e^x+e^x)+(e^{-x}-e^{-x})}{2}=e^x$$
and this works out nicely because the $e^{-x}$ cancel.  Now consider a ""higher order"" cosh equation of the form 
$$C(x)=\frac{e^{\omega^0x}+e^{\omega^1 x}+e^{\omega^2x }}{3}$$
where $\omega^k$ are the 3rd roots of unity; $\omega^k=e^{\frac{2i\pi k}{3}}$.  I would like to devise an analagous expression
$$C(x)+S_1(x)+S_2(x)=e^x$$
with functions of the form $C$.  My first reaction was
$$S_1=\frac{e^{\omega^0x}-2e^{\omega^1 x}+e^{\omega^2x }}{3};  S_2=\frac{e^{\omega^0x}+e^{\omega^1 x}-2e^{\omega^2x }}{3}$$
and indeed
$$(C+S_1+S_2)(x)=\frac1{3}\left[(3e^{\omega^0 x})+(e^{\omega^1 x}-2e^{\omega^1 x}+e^{\omega^1 x})+(e^{\omega^2 x}+e^{\omega^2 x}-2e^{\omega^2 x})\right]=e^x$$
My intuition was that this was correct; since in the case of $\cosh$ and $\sinh$, the 2nd roots of unity correspond to $1$ and $-1$.  But my second thought was that there was no need for subtraction of $2e^{\omega^k x}$ for $k=1,2$.  Perhaps there was a way to keep all the signs positive and find an $a,b$ such that 
$$e^{\omega^1 x}+e^{a\omega^1 x}+e^{b\omega^1 x}=0$$
$$e^{\omega^2 x}+e^{a\omega^2 x}+e^{b\omega^2 x}=0$$
I thought this would keep things a little more ""symmetrical"" and reduce the need for a $-2$ coefficient around the nontrivial roots of unity.  I tried some things to get values for $a,b$ but have been unsuccessful.  Should I just be happy with my original $S_1, S_2$ or are there choices for $a,b$ that would keep the symmetry?","['exponential-function', 'complex-analysis', 'complex-numbers', 'special-functions']"
1335377,"If the weak derivative $\nabla u$ of $u\in L^2(\Omega)$ exists, then $\int_\Omega|\nabla u|^2=\int_\Omega|\nabla u^+|^2+\int_\Omega|\nabla u^-|^2$","Let $\Omega\subseteq\mathbb{R}^n$ be bounded $u\in \mathcal{L}^2(\Omega)$ be weakly differentiable , i.e. $$\int_\Omega u\nabla\psi\;d\lambda^n=-\int\psi\nabla u\;d\lambda^n\;\;\;\text{for all }\psi\in C_0^\infty(\Omega)$$ (where we carefully denote the weak derivative of $u$ by $\nabla u$) $x^+:=\max(x,0)$ and $x^-:=\max(-x,0)$ for $x\in\mathbb{R}$ How can we show, that $$\int_\Omega\left|\nabla u\right|^2\;d\lambda^n=\int_\Omega\left|\nabla u^+\right|^2\;d\lambda^n+\int_\Omega\left|\nabla u^-\right|^2\;d\lambda^n\tag{1}$$ and what can we derive for $\nabla u^\pm$? (e.g. $\nabla u^\pm=\nabla u$ almost everywhere in $\left\{u^\pm >0\right\}$ or even $\nabla u=\nabla u^+-\nabla u^-$ almost everywhere).","['measure-theory', 'sobolev-spaces', 'real-analysis', 'multivariable-calculus', 'partial-differential-equations']"
1335397,"Prove $\{A_1, \cdots ,A_n\}$ is a partition of $A$ given $\{S_1, \cdots, S_n\}$ is a partition of $\Omega$","Let $A \subseteq \Omega$ and $\{S_1,\cdots ,S_n\}$ be a partition of $\Omega$. Let $A_i = A \cap S_i$. Prove $\{A_1, \cdots ,A_n\}$ is a partition of $A$. I'm having trouble formalizing this with mathematical symbols but I think I get the idea behind the problem... To prove something is a partition we must show that is satisfies the conditions: 1) The subsets are mutually disjoint 2) The union of the subsets is equal to the whole sample space We are given that $\{S_1,\cdots ,S_n\}$ is a partition of the sample space $\Omega$ so we know the collection of $S_i$ are mutually disjoint and their union $=\Omega$ We can also view this intuitively by the following example. Let $\Omega$ be a piece of lined paper. Let the lines on this paper represent the partitions $S_i$ with $1\le i \le n$ where $n$ equals the number of lines. Then draw a circle on this piece of paper and no matter what circle you draw (no matter how imperfect the shape) the lines will always divide the circle into mutually disjoint partitions $A_i$ that all together add up to give the full circle. There are two cases for each section separated by lines: Case 1 - No part of the circle is inside the section meaning $A_i\notin S_i$ Case 2 - Some or all of the circle is inside the section meaning $A_i \in S_i$ How do I put all of this logic together in symbols to write it in a concise, mathematical way? Thank you!",['elementary-set-theory']
1335400,Integral of odd function doesn't converge?,"When I look up $$\int_{-1}^1 \dfrac{1}{x} dx$$ on Wolfram Alpha, it says it doesn't converge. While this is a sum of two diverging integrals, the two areas are clearly symmetric, and I'd assume the answer would be zero. How does one usually treat integrals like this?","['convergence-divergence', 'calculus', 'integration']"
1335423,Summation by Parts to Evaluate $\sum_{k=1}^{\infty}(2k+1)x^{2k}$,"I need to evaluate $\sum_{k=1}^{\infty}(2k+1)x^{2k}$ using the Summation by Parts (SBP) method. It is given that $0 < |x| < 1$. The notation our class uses for SBP is as follows:
$$ \sum_{i} u_i\cdot\triangle v_i = u_i\cdot v_i - \sum_{i} \triangle u_i \cdot v_{i+1}$$
where $u_i$ and $v_i$ are both sequences. I have already evaluated the sum using differentiation, but when I attempt SBP I do not get the same result. Here are my steps for differentiation, with the correct result:
$$ \frac{d}{dx} \left(x^{2k+1}\right) = (2k+1)x^{2k} $$
                $$ \sum_{k=1}^{\infty} x^{2k+1} = \boldsymbol{x} + x^3 + x^5 + ... - \boldsymbol{x} = x(1 + x^2 + (x^2)^2 + ...) - x $$ 
$$ = x\left(\frac{1}{1-x^2}\right) - x = \frac{x^3}{1-x^2}$$
                $$ \sum_{k=1}^{\infty} (2k+1)x^{2k} = \frac{d}{dx}\left( \sum_{k=1}^{\infty} x^{2k+1}\right) = \frac{d}{dx}\left( \frac{x^3}{1-x^2}\right) = \boxed{\frac{3x^2-x^4}{(1-x^2)^2}}$$ And here are my steps for SBP, with a different result:
$$\sum_{k=1}^{\infty}(2k+1)x^{2k} $$
                $$ u_k = 2k+1, \triangle u_k = 2(k+1) + 1 - (2k + 1) = 2 $$
                $$ \triangle v_k = v_{k+1} - v_k = \frac{x^{2(k+1)}}{x^2-1} - \frac{x^{2k}}{x^2-1} = \frac{x^{2k}(x^2-1)}{x^2-1} = x^{2k} $$
                $$\sum_{k=1}^{\infty}(2k+1)x^{2k} = (2n+1)\left( \frac{x^{2n}}{x^2-1} \right)\bigg|_{n\rightarrow\infty} - \sum_{k=1}^{\infty} 2\left(\frac{x^{2k+2}}{x^2-1}\right)$$
                $$ = 0 - \sum_{k=1}^{\infty} 2\left(\frac{x^{2k+2}}{x^2-1}\right) \textit{ since } |x| < 1$$
                $$ = -\frac{2x^2}{x^2-1}\sum_{k=1}^{\infty} x^{2k} = -\frac{2x^2}{x^2-1}\left( \frac{x^2}{1-x^2} \right) = \frac{2x^2}{1-x^2}\left( \frac{x^2}{1-x^2} \right) = \boxed{\frac{2x^4}{(1-x^2)^2}}$$ Can anyone point out my mistake(s)?","['summation', 'sequences-and-series', 'discrete-mathematics']"
1335500,Proof of the derivative of $x^n$,"I am proving $(x^n)'=nx^{n-1}$ by the definition of the derivative: \begin{align}
(x^n)'&=\lim_{h \to 0} {(x+h)^n-x^n\over h}\\
&=\lim_{h \to 0} {x^n+nx^{n-1}h+{n(n-1)\over 2}x^{n-2}h^2+\cdots+h^n-x^n\over h} \\
&=\lim_{h \to 0} \left[ nx^{n-1}+{n(n-1)\over 2}x^{n-2}h+\cdots+h^{n-1} \right]
\end{align} Because polynomial is continuous for every $x$, we can conclude that $\lim_{x_0\to 0}(x_0)^n=0$. Therefore 
$$\lim_{h \to 0} \left[ nx^{n-1}+{n(n-1)\over 2}x^{n-2}h+\dots+h^{n-1} \right]= nx^{n-1}$$ Is this proof valid?","['calculus', 'proof-verification']"
1335528,Estimating grader bias/variance and MLE test scores given multiple graders assigned to grade each test,"Suppose we have $m$ graders and $n$ students, and we want to grade a test so that $k$ graders are assigned to grade to each test, and all graders grade the same number of tests. (I realize $m,n,k$ have to satisfy certain properties to make this ""perfect assignment"" possible, but I'd rather just skip this point and assume it's true). Also, to make things interesting, let's assume the assignment of graders to tests is random (so it's not like a group of graders all have the same set of tests to grade). Furthermore, let's assume that each grader $i$ has a mean bias $\mu_i$ and a variance $\sigma_i^2$ for that bias associated with their grading, and the bias they apply to each test they grade is sampled independently from a normal distribution with these parameters. And each test $j$ has a ""true grade"" $c_j$. So then if grader $i$ is assigned to grade test $j$, then the grade they assign will be $c_j + x_{ij}$ where $x_{ij}$ is the sampled bias from the normal distribution with parameters $\mu_i$ and $\sigma_i^2$. If the $\mu_i$ and $\sigma_i^2$ are unknown, how do we find the maximum likelihood values for the true grade scores $c_j$? If using a prior for graders' parameters is required I guess I'm ok with that. I would also like to know the MLE (or MAP if we go Bayesian) values for the grader parameters $\mu_i$ and $\sigma_i^2$. The idea being that graders with lower estimated variance should be preferred to those with higher variance, if we want as accurate of assigned grades as possible in the future. I've phrased this in terms of test grading for clairty, but it's actually for an ""active learning"" problem in machine learning that we are very interested in in our lab, hence insights on this problem could really help.","['statistics', 'statistical-inference']"
1335535,The prerequisites for a change of variables in a double integral,"Given a double integral, I want to find out what should I prove for the equality:
$$
\int \int _\Omega f(x,y) dx dy = \int \int _{\Omega_{new}} f(x(u,v),y(u,v))\cdot J dudv
$$ My dilemma is as follows:
I know that the condition $J\neq 0$ in the domain $\Omega$ implies the validity of the inverse function theorem , and in particular that my mapping $u=u(x,y), v=v(x,y)$ is injective. But, if so, why does all the statements that I find of the theorem of changing variables has the two conditions: $ J\neq 0 $ and our mapping in injective ? In addition, why does for linear mappings $u,v$ it is enough to check the Jacobian does not vanish ?",['multivariable-calculus']
1335541,About two combinatorial counting problems.,"Here are the problems: Suppose $X$ is a set of $n$ elements, and $S_1,...,S_m$ are $m$ subsets of $X$ of average size at least $n/w$. Show that if $m\geq 2kw^k$, then there are $k$ distinct $i_1,...,i_k$ such that $S_{i_1},...,S_{i_k}$ satisfying $|S_{i_1}\cap...\cap S_{i_k}|\geq \frac{n}{2w^k}$. I've thought about the induction on $k$, but I can't understand these tow coefficients 2----The base case $k=1$ doesn't need these 2's. So I'm wondering whether a stonger statement still holds or not. That is, Suppose $X$ is a set of $n$ elements, and $S_1,...,S_m$ are $m$ subsets of $X$ of average size at least $n/w$. Show that if $m\geq kw^k$, then there are $k$ distinct $i_1,...,i_k$ such that $S_{i_1},...,S_{i_k}$ satisfying $|S_{i_1}\cap...\cap S_{i_k}|\geq\frac{n}{w^k}$. Suppose $R_1,...R_m\subset\{1,...,n\}$ satisfying that $|R_i|\neq 0$ mod 6 for every $i$, and $|R_i\cap R_j|=0$ mod 6 for every $i\neq j$. Prove that $m\leq 2n$. I konw the method when the ""mod"" is a number prime $p$----to use rank inequality of the adjacent matrix on the field $\mathrm{F}_p$. But 6 is not prime, so the rank inequality on $\mathrm{F}_6$ doesn't hold. Any discussion will be potentially helpful and appreciated.","['combinations', 'discrete-mathematics', 'combinatorics', 'inequality']"
1335585,$f$ is continuous $\iff f(\bar A) \subset \overline{f(A)}$,"The problem is: $f:X\to Y$: any map. $f$ is continuous $\iff \forall A\subset X, \ f(\bar A) \subset \overline{f(A)}$ My understanding is: Suppose $f$ is continuous. $\forall A\subset X, A \subset f^{-1}(f(A)) \subset f^{-1}(\overline{f(A))}$ so $f^{-1}(\overline{f(A)})$ is a closed set (by continuity) containing $A$. Since $\bar A$ is the smallest closed set containing $A$, $\bar A \subset f^{-1}(\overline{f(A)})$, so that $f(\bar A) \subset f(f^{-1}(\overline{f(A)})) \subset \overline{f(A)}$. Conversely, let $F$ be any closed subset of $Y$. We want to say $f^{-1}(F)$ is closed. $f(\overline{f^{-1}(F)}) \subset \overline{f(f^{-1}(F))} \subset \overline{F}$, so that $\overline{f^{-1}(F)} \subset f^{-1}(f(\overline{f^{-1}(F)})) \subset f^{-1}(\overline{F}) = f^{-1}(F)$. Therefore $f^{-1}(F)$ is closed. My proof is fine? I think this proof is tedious. Thanks.","['elementary-set-theory', 'proof-verification', 'general-topology']"
1335588,What prevents the restriction of a Haar measure to a closed subgroup from being a Haar measure?,"Let $\mu$ be a Haar measure on a locally compact Hausdorff topological group $G$, and let $H$ be a closed subgroup of $G$.  If we restrict $\mu$ to the Borel sets of $G$ which are contained in $H$ (this restriction will include the Borel sets of $H$), it is easy to see that $\mu$ is a Borel measure on $H$.  Let's call this restriction $\lambda$. Sometimes $\lambda$ is a Haar measure on $H$, sometimes it isn't.  If $G$ and $H$ are finite groups, then we can take $\mu$ and its restriction to be the counting measure.  But if, for example, $G = \mathbb{R}$ and $H = \mathbb{Z}$, then the restriction of the Lebesgue measure to the Borel sets of $\mathbb{Z}$ (actually, the power set of $\mathbb{Z}$ since $H$ is discrete) is the zero measure. I believe that if $H$ is a compact subgroup of $G$, then the only way that $\lambda$ can fail to be a Haar measure on $H$ is if it is the zero measure (that is, if $\mu(H) = 0$).  Let me go through the properties of the Haar measure one by one, with the assumption that $H$ is a closed subgroup of $G$. Translation invariance. Obvious since $\mu$ is translation invariant. Finite on compact sets. Also clear, compactness transcends the subspace topology. Inner-regular on open sets. Let $V \cap H$ be open in $H$, for $V$ open in $G$. Actually, Haar measures are inner-regular on $\sigma$-finite Borel sets, so we just need $V \cap H$ to be $\sigma$-finite. This is the case when $H$ is compact. Outer-regular on Borel sets. If $E$ is a Borel subset of $H$, then $E$ is also a Borel subset of $G$.  Let $V$ run through the open sets of $G$ which contain $E$, or equivalently for which $E \subseteq V \cap H$.  We have $$\mu E = \inf_V \mu(V) \geq \inf_V \mu(V \cap H) \geq \mu(E)$$ At a glance, can anyone tell if I've made any mistake here?","['locally-compact-groups', 'topological-groups', 'measure-theory']"
1335592,How do I evaluate this sum :$\sum_{n=0}^{\infty} \frac{\sin(n!)}{\cos(n!)}$?,How do I evaluate this sum :$$\displaystyle\sum_{n=0}^{\infty} \frac{\sin(n!)}{\cos(n!)}$$ Note : I used many criterions of convergence to show if it converges but i didn't up. Thank you for any help . Edit: Also asked at MathOverflow,"['sequences-and-series', 'convergence-divergence']"
1335595,What are the formal terms for the intersection points of the geometric representation of the extended trigonometric functions?,"Mike Pierce's answer to this question , regarding trigonometric functions beyond the common (co)sine, (co)secant, and (co)tangent, points to a figure on the Wikipedia page on trigonometric functions that nicely illustrates the relationships between the magnitudes of some of these various additional functions [(co)versine, ex(co)secant], for a given angle $\theta$: The point $O$ in the figure is the center of the circle . What, if any, are the formal names for the other labeled points, $A$ through $F$?  The names for the various line segments and areas are relatively easy to find on Wikipedia ( radii , chords , tangent , etc .), but I haven't been able to track down any names for these points. A book cited in a comment in the above-linked question, Heavenly Mathematics: The Forgotten Art of Spherical Trigonometry , may contain the answers, but I don't have a copy on hand.","['geometry', 'terminology', 'trigonometry']"
1335619,Symplectic group action,"Let $(M,\omega)$ be a symplectic manifold. We say that a group action $\phi: G \times M \rightarrow M$ is symplectic if each $\phi(g,.)$ is a symplectomorphism. Now, I am going through some lecture notes that are not available online, where I have difficulties to understand some details. So we define the vector field $\psi$ on the Lie Algebra ($\eta \in \mathfrak{g},p \in M$) such that $$\psi(\eta)(p) = \frac{d}{dt}|_{t=0} (\phi(e^{t \eta},p)) \in T_pM$$ So far so good. Now the author says: Assume that for each $\psi(\eta)$ there is a global Hamilton function $H_{\eta}: M \rightarrow \mathbb{R}$ such that $dH_{\eta} = \omega(\psi_{\eta},.).$ (So $\psi_\eta$ is the Hamiltonian vector field to $dH_{\eta}.)$
So far so good: Now the author wants to show that $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ for all $g \in G$ and $\xi \in \mathfrak{g}.$ In order to do this he claims that it is sufficient to prove this for all $1-$parameter subgroups $g(t) = e^{t \eta}, \eta \in \mathfrak{g}.$ I have no idea why this is sufficient cause I don't see that the exponential map is surjective in general (despite, he may refer here to a special case. at least, this is what I suspect, maybe you can help me identifying this one.) Then he writes $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ if and only if $H_{\xi} ( \phi(e^{t \eta},p)) = H_{Ad_{e^{-t\eta}}(\xi)}(p).$ and after that he again claims that it is sufficient (I have not the slightest idea why) to show this for $\frac{d}{dt}|_{t=0}$ so he differentiates both sides and gets for the right hand-side $$\frac{d}{dt}|_{t=0}H_{Ad_{e^{-t\eta}}(\xi)}(p) = H_{ad_{-\eta}(\xi)}(p).$$
Actually, I have even difficulties to understand why you can differentiate this function and leave $H$ as it is (no chain rule). Later on, he claims that any $T_p(orb_G(p))$ can be written as $\psi_{\eta}(p)$ for some $\eta \in \mathfrak{g}$ where $orb_G(p)$ is the orbit of $p$ under the group action $g$. I think this is similar to the previous issues. Either he likes to proof only special cases or I am missing a point here, but I don't see where all his sufficiency arguments come from? Is there anybody who looks through this or could comment on this? I can talk to the author soon, but I don't want to contact him without being sure that there is really something missing here.","['lie-groups', 'differential-geometry', 'lie-algebras']"
1335626,Positive-definite function and Positive-definite matrix,"I am trying to understand Positive-definite function and read the wikipedia link: https://en.wikipedia.org/wiki/Positive-definite_function It has a relation to Positive-definite matrix and I did not understand how clearly. My questions : is the Positive-definite function $f$ mentioned in the wikipedia link is continuous? It is related to to the element of a Positive-definite matrix which
are just numbers what it signifies? Can anyone please clarify?","['definition', 'linear-algebra', 'functional-analysis']"
1335639,Whats is the meaning of the derivative of a vector function?,"Assuming we have a continuous and well behaved vector function 
$$
R(t) = \langle f(t), g(t), h(t) \rangle
$$
then its derivative at an arbitrary point a is $R'(a)$, which can be computed (I'm not using the definition not to clutter the post) as 
$$
R'(x) = \langle f'(a), g'(a), h'(a)\rangle
$$
This gives the vector tangent to the vector function curve, at point a. But what does the function defined by R'(t) describes? I have tried to think about it and search it on the books that I have, but I have found no answer.","['vectors', 'calculus', 'multivariable-calculus']"
1335640,probability application,"1) A disease has hit a city. The percentage of the population infected $t$ days     after the disease arrives is approximated by $$p(t) = 12te^{\frac{-t}{7}} \qquad \mbox{for} \qquad0\leq t \leq 35.$$ After how many days is the percentage of infected people a maximum? What is the maximum percent of the population infected? The maximum percent of  the population  infected    is  ______  % 2) A container contains 12 diesel engines.  The company chooses 5 engines at random and will not ship the container if any of the engines chosen are defective.  Find the probability that a container will be shipped even though it contains 2 defectives if the sample size is 5. For the first problem, the number of days at which the percentage is at maximum is 7. Clearly, if I substitute this to $p(t)$ I will get the maximum percentage. My problem is how did they get the answer of 7 days? How do I deal with this kind of problem? Is there a specific formula? I'm trying to figure it out but can't. Also for the second problem I made use of the hypergeometric formula that is $$p(x) = \frac{\left[C(k,x) \cdot C(N-k, n-x)\right]}{C(N,n)}$$ where $N$ is the size of population, $k$ is the number of successes in the population, $x$ is the number of successes in the sample and $n$ is the sample size. I used this and I got a different answer. The answer should have been 0.318 but I got a different one. Please help.","['probability', 'statistics']"
1335658,Prove that $\exists k\in \mathbb{N}^*$ such that $\|a-a_k\|<\varepsilon$,"Let $E$ be a normed linear space, $C$ compact and $f:C\to C$ a function such that $\|f(x)-f(y)\|\geq \|x-y\|$ for all $x,y\in C$. Then $f$ is an isometry. Note: I'm having trouble trying to prove it! I feel stuck. My approach: Some hint says define: $a_0=a$, $a_n=f\circ ...\circ f(a)=f^{n}(a)$ and similar $b_n=f^{n}(b)$. Added: prove that for all $\varepsilon>0$ there is $k\in \mathbb{N}^*$ such that $\|a-a_k\|<\varepsilon$ and $\|b-b_k\|<\varepsilon$ How can I deduce from this that $\|a_1-b_1\|\leq \|a-b\|+2\varepsilon$? Because in that case I know that $\|f(a)-f(b)\|\leq \|a-b\|$ and since $a,b$ were arbitrary we are done! Please any help in proving this two things!! My attempt: $a_n$ have (by compacity) a subsequence which converges, say $a_{n_k}\to z\in C$. Can I say that $z=a$?? What I know is that for some $x_1,...x_p\in C$ we have that $C\subseteq \bigcup_{i=1}^p B(x_i,\varepsilon)$. Thanks I really feel stuck!",['analysis']
1335674,Matrix on complex field.,"An $n\times n$ complex matrix $A$ satisfies $A^k=I_n$, where $I_n$ is $n\times n$ identity matrix and $k$ is positive integer $\gt1$. Suppose that 1 is not an eigen value of $A$. Then which of the fallowing is necessarily true? 1) $A$ is diagonalizble 2) $A+A^2+...+A^{k-1}=0$ 3) $tr(A)+tr(A^2)+...+tr(A^{k-1})=-n$ 4) $A^{-1}+A^{-2}+...+A^{-(k-1)}=-I_n$ I think 1) and 2) are ture.",['matrices']
1335681,Proof of Sufficiency of Cauchy-Riemann equations,"I understand that the Cauchy-Riemann equations $$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}$$ and $$\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}$$ are necessary for a complex function to be complex-differentiable, but I would like to see a proof that they are also sufficient for this to be true. I am assuming that these partial derivatives exist and are continuous everywhere that they are satisfied.","['calculus', 'complex-analysis']"
1335682,Prove the identity $\frac{1}{\tan (x)(1+\cos( 2x))} = \csc(2x)$,"$$\frac{1}{\tan (x)(1+\cos(2x))} = \csc(2x)$$ I really don't know what to do with denominator. Sure, I can use the double angle formula for cosine, and get: $$\frac{1}{\tan(x)(2 - 2\sin^2(x))} = \csc(2x)$$ But what's next?","['algebra-precalculus', 'trigonometry']"
1335693,Invertible matrix of non-square matrix?,Is a matrix invertible only when it is a square matrix? What about a matrix of the order $m \cdot n$ with $m \gt n$ and such that it is row-equivalent to a row-reduced echelon matrix with more non-zero rows than columns? What is the motivation behind the concepts of left and right inverse? Is it only useful when dealing with non-square matrix?,"['inverse', 'linear-algebra', 'matrices']"
1335700,"Looking for an example of an increasing function $f:[a,b] \to [a,b]$ which is discontinuous at infinitely many points","I am looking for an example of an increasing    function $f:[a,b] \to [a,b]$ which is discontinuous at infinitely many points ; please help , thanks in advance .","['analysis', 'continuity', 'examples-counterexamples', 'real-analysis']"
1335716,How to compute the automorphism group of split metacyclic groups?,"I am trying to calculate the automorphism group of an affine subgroup $$G=\mathbb{Z}_p\rtimes\mathbb{Z}_{k}\leq\text{AGL}(1,p).$$ One might guess $\text{Aut}(G)=\text{AGL}(1,p)$. And this matches what I got in GAP after checking a couple examples. However, it seems proving it through by definition is messy and not particular easy. So I have been pondering a while what will be a better way to approach? Any suggestions?","['group-theory', 'finite-groups']"
1335720,Prove or disprove that $8c+1$ is square number.,"Let $a,b,c$ be positive integers, with $a-b$ prime, and $$3c^2=c(a+b)+ab.$$  Prove or disprove that $8c+1$ is square number.","['number-theory', 'square-numbers']"
1335724,How do I parametrize a circle that's not centered at the origin?,"If the circle were centered at the origin, of radius r, then r(cos$\theta$, sin$\theta$) traverses the circle once counterclockwise, for 0 $\le$$\theta$$\le$2$\pi$. What if the circle were centered at, say, (x,y) = (5,2)?  Also of radius r. It's not r($cos\theta$ - 5, $sin\theta$-2) ... right? I'm thinking of the equation for the circle, which would give $(x-5)^2+(y-2)^2=r^2$. Thanks,","['calculus', 'algebra-precalculus', 'geometry', 'trigonometry', 'multivariable-calculus']"
1335731,Derivative of a lemniscate at the left hand side,How does $${d \over{dx}}(3(x^2+y^2)^2)$$ turn into $$12y(x^2+y^2){{dy} \over{dx}}+12x(x^2+y^2)$$? I'm having a hard time solving it algebraically without it turning into a huge polynomial.,"['calculus', 'derivatives']"
1335737,Question about proving basic results of numbers,"I have just recently started to work with Calculus by Spivak and I am just wondering some things about the first chapter. ( I am doing this as a method to review my calculus which I have done but only using texts such as Stewart). It is  about the basic principals of numbers and such. However, I do not have an answer booklet, so I am unsure if what I am doing is correct or not. (Which is also kinda hard, should I try to find a book that gives answers)? But overall , my question is in regard to all these types of problems. I am looking for someone to motivate why and how important it is to work through all of these problems in the first chapter of spivak or similar , And For an example , One question is, Prove $$\frac{a}{b}=\frac{ac}{bc}$$ if $b,c \neq 0$ So to me , I just thought I will use what had been talked about in the chapter. Ie, $$\frac{ac}{bc}=(ac)(bc)^{-1}=(ac)(b^{-1}c^{-1})=(ab^{-1})(cc^{-1})=(ab^{-1})$$ But I just don't know at all if that is what is expected, I am looking for any other resources to understand exactly what I am supposed to do. Further, it seems like it can't be correct ( or atleast not the way that was supposed to be done) because a few problems after this it asks to prove that $$(ab)^{-1}=a^{-1}b^{-1}$$ So can anyone help provide some insight/advice/ recommendations or anything? I just want to actually make sure I am understanding what is correct and expected for these type of questions. Also, if anyone has any specific insight on how to do the proof without using the property that comes later, or even if possible someone who has Spivak to say a method using only what had been given.","['proof-verification', 'algebra-precalculus']"
1335739,Homework problem about the smallest sigma algebra:,"Let $\mathscr{E} \subset 2^X $ , then there is a unique smallest $\sigma$ -algebra containing $\mathscr{E} $ . Proof(Attempt): Since $\mathscr{E} \subset 2^X $ , $2^X$ is $\sigma$ -algebra containing $\mathscr{E} $ . Let $\{ \mathscr{F}_{\alpha} \}_{\alpha \in A} $ be a collection of $\sigma-$ algebras with $\mathscr{E} \subseteq \mathscr{F}_{\alpha} $ for all $\alpha \in A $ . We have that $$ \mathscr{M} = \bigcap_{\alpha \in A} \mathscr{F}_{\alpha} $$ is a $\sigma$ -algebra and that $\mathscr{E} \subseteq \mathscr{M} $ . Suppose there is a smaller $\sigma$ -algebra $\mathscr{G} $ with $\mathscr{E} \subseteq \mathscr{G} $ . It is evident that $\mathscr{G} \in \mathscr{F}_{\alpha} $ and so we must have $\mathscr{M} \subseteq \mathscr{G}$ showing that $\mathscr{M} $ is the smallest one. Suppose now there is another $\sigma$ -algebra $\mathscr{U}$ with the same characteristics as $\mathscr{M}$ . Since $\mathscr{M}$ is the smallest $\sigma$ -algebra containing $\mathscr{E}$ , then $\mathscr{U} \subseteq \mathscr{M}$ . Similarly, $\mathscr{M} \subseteq \mathscr{M} $ and so we have established uniqueness. Any feedback is much appreciated.","['analysis', 'proof-verification', 'real-analysis', 'measure-theory']"
1335761,Metric on Homogeneous Space $G/H$,"For simplicity, assume $G$ is compact and semi-simple Lie group, and $H$ is a closed subgroup of $G$. Therefore the homogeneous space is reductvie, say $\mathfrak{g}=\mathfrak{h}+\mathfrak{m}$ where $\mathfrak{g}$, $\mathfrak{h}$ and $\mathfrak{m}$ are Lie algebra of $G$, $H$, and complimentary space to $H$. I know there is a fundamental theorem on the metric $\gamma$ of $G/H$ that “there is a one-to-one correspondence between the $G$-invariant metric $\gamma$ on $G/H$ and the ${\rm ad}_\mathfrak{h}$-invariant inner product $\eta$ on $\mathfrak{m}$”. For semi-simple and compact Lie group, one can always find negative definite Killing form $K$ on $\mathfrak{g}$, which is apparently ${\rm ad}_\mathfrak{h}$-invariant. My question is that, given the Killing form $K$, how many $\mathfrak{m}$ compliment to $\mathfrak{h}$ one can choose, so that $\mathfrak{m}$ is ${\rm ad}_\mathfrak{h}$ invariant. I know that for example one can choose the orthogonal $\mathfrak{m}=\mathfrak{h}^\perp$ by Killing form $K$. Is there any options and if so is there any relation among those metric $\gamma$ or $\eta$ induced by the same Killing form $K$ Thanks very much","['vector-bundles', 'metric-spaces', 'riemannian-geometry', 'homogeneous-spaces', 'differential-geometry']"
1335768,Infinite Sample Space,"I came across this line in a textbook I'm reading, When $\Omega$ is infinite, its power set is too large a collection for probabilities to be assigned reasonably to all its members. I'm not quite able to wrap by head around this. Probability is a positive function from a collection of events to $[0,1]$. The disjoint additivity property also holds. Now both $[0,1]$ and $\{0,1\}^\Omega$ are uncountably infinite so why can't there exist a map between the two? An intuitive explanation would help a lot!",['probability-theory']
1335792,An applied problem in ODE leading to Interval of Existence issue,"ODE books have a section on interval of existence of a solution with a standard set of problems, such as what is the interval of existence for $y'+(\tan t) y = t/(t-2), y(3)=5$, or $y'=y^3, y(0)=2$. I am looking for a ""modelling"" problem leading to such an issue. That is, a natural situation where the issue comes up and has a physically meaningful answer.","['education', 'ordinary-differential-equations']"
1335829,Default positive/(non-negative) probability distribution,"So if you have a random variable that corresponds to a natural phenomenon and you don't know how it is distributed, you often assume it is normally distributed. Now I have a random value that I know is strictly positive, what is the ""default"" assumed probability distribution for these kind of variables? My specific case is the volume of air that a human breathes per a random unit of time, which fluctuates from time to time, thus being random if I don't know how it fluctuates. One can easily conclude this number to be strictly positive, since zero means you would be dead, and negative values would be some sort of reverse breathing (photosynthesis maybe? Hehe).","['probability', 'statistics', 'probability-distributions']"
1335832,"Anywhere I integrate $f_n$, the integral approaches $f$. Is $\lim_n f_n = f$ a.e.?","Something tells me this is obvious... I have a bunch of functions: $f,f_n:\mathbb{R}^2\rightarrow \mathbb{R}$, all integrable. Also, $f$ is continuous. I also have a family of sets, $\mathcal{G}$ where $\sigma(\mathcal{G})=\mathcal{B}(\mathbb{R}^2).$ (the Borel sigma-algebra of $\mathbb{R}^2$, perhaps sans some sets of measure 0 wrt Lebesgue) Now the important part: we have that $\int_{S} f_n d\lambda \rightarrow \int_{S} f d\lambda$ for any $S\in \mathcal{G}$. Does $\lim_n f_n = f$ a.e.? Here is my thought: Think of this set: $S:=\{\lim_n f_n \neq f\}.$ What would happen if: $$\lambda(S)>\varepsilon > 0?$$ Then $\lim_n \int_S |f_n-f| = \lim_n \int_S (f_n-f)^+ +\int_S (f_n-f)^- > 0$. But both of these parts must go to 0 by assumption. So we have a contradiction.","['measure-theory', 'continuity', 'proof-verification', 'functional-analysis', 'integration']"
1335856,How do I prove that there doesn't exist a unit norm vector at a unit distance from a closed subspace of an infinite dimensional vector space?,"Let $M$ be a proper closed linear sub space of a normed linear space $X$. If $X$ is finite dimensional, it's a well known result by F.Riesz that there exists a unit vector $x$ such that dist($x,M$)=$inf_{m\in M}\|x-m\|=1$. This need not be true if $X$ is infinite-dimensional. I have to show that the choice of $$
X=\{f\in C[0,1]:f(0)=0\}\\
M=\{f \in X: \int_{0}^1 f=0\}
$$
provides a counter example. Can any one please help me with this ? For every unit norm function $f_0$ in $X$ , I tried designing a function $g_0 \in M$ such that $\|f_0-g_0\| < 1-\epsilon $ or $\|f_0-g_0\|>1+ \epsilon$, but haven't made much progress.",['functional-analysis']
1335879,Infinity indeterminate form that L'Hopital's Rule: $\lim_{x\to0^+}\frac{e^{-\frac{1}{x}}}{x^{2}}$,"When I tried to find the limit of
$$
\lim_{x\to0^+}\frac{e^{-\frac{1}{x}}}{x^{2}}
$$
by applying L'Hopital's Rule the order of denominator would increase. What else can I do for it?","['infinity', 'calculus', 'limits', 'indeterminate-forms']"
1335921,Strong law of large numbers for continuous time martingales?,"Is there a theorem/reference that states if $M(t)$ is a martingale, then under certain mild conditions, $M(t)/t\to 0$ a.s. as $t\to\infty$?","['probability-theory', 'martingales', 'law-of-large-numbers', 'stochastic-processes']"
1335973,Number theory divisibility problem,"For an integer $n > 1$, prove that
$2^n - 1$ does not divide $ 3^n - 1$. I tried doing it for primes first, but got no where. I think we might get it if we assume $k$ to be the smallest integer such that the divisibility holds, and then try to get a contradiction.",['number-theory']
1335985,Inverse function $g^{-1}$,"The function $g$ is defined by $$g(x)= 3-2x-4x^2, x\in \mathbb{R},x\leq -\frac{1}{4} $$ Find the inverse function $g^{-1}$. Calculate the value of $x$ for which $g(x)=g^{-1}x$. My attempt, $g(x)=3-2x-4x^2$ Let $g^{-1}(x)=1$ $x=g(a)$ $=3-2a-4a^2$ $0=3-2a-4a^2-x$ Solving for $a$, I got $\frac{\pm \sqrt{13-4x}-1}{4}$ Since $x\leq -\frac{1}{4}$, so $f^{-1}(x)=\frac{-\sqrt{13-4x}-1}{4}$ Am I correct for my inverse of $g(x)$? How to proceed to find the value of $x$?","['algebra-precalculus', 'functions']"
1335989,How to prove that $a^{\log_cb}=b^{\log_ca}$,"I've met a question whereby it asked me to show that $a^{\log_cb}=b^{\log_ca}$. 
I'm okay with the other logarithm questions. But I don't know how to show this question out. Can anyone give some hints or explanation for me? Thanks in advance.","['algebra-precalculus', 'logarithms']"
1335994,Transitive subgroup of symmetric group $S_n$ containing an $(n-1)$-cycle and a transposition,"Suppose $G$ is a transitive subgroup of $S_n$ such that there exist $\sigma, \tau \in G$ such that $\sigma$ is an $(n-1)$ -cycle and $\tau$ is a transposition. Prove that $G = S_n$ . I just don't understand how to mathematically use the transitive nature of the subgroup.","['group-theory', 'finite-groups', 'symmetric-groups', 'permutations']"
1336017,Median of Poisson Distribution,"I've just taken Probability and Statistics exam and here is the question that becomes a hot debate among my friends in the classroom: What is the median of a random variable that follows a Poisson distribution with parameter $\lambda=5$? $(\text{A})\,\,\,4\quad\quad(\text{B})\,\,\,5\quad\quad(\text{C})\,\,\,6\quad\quad(\text{D})\,\,\,7\quad\quad(\text{E})\,\,\,8$ Here is my attempt: Let $X$ be a random variable that follows a Poisson distribution with parameter $\lambda=5$, then we have $P(X\le4)\approx0.440493$ and $P(X\le5)\approx0.615961$. So, it's clearly the median $(x_{50})$ of $X$ is between $4$ and $5$, more precisely $x_{50}\approx4.32937026824559119408$ obtained by a computer program. Unfortunately, we are only allowed to use a simple scientific calculator so basically it's difficult to obtain that precise value using a simple scientific calculator by trial and error or Newton method due to time limit. I managed to obtain $x_{50}\approx4.33$ by trial and error method, so I answered $4$ because I rounded to the nearest integer. But some of friends argued and they answered $5$ because they used the nearest rank method, $x_{50}=\lceil4.33\rceil=5$. What exactly is the answer? Please explain. Thanks.","['probability', 'statistics', 'probability-distributions', 'percentile']"
1336026,$xy + yz + zx + 2xyz = 1$ implies $4x+y+z\geq 2$,"Let $x,y,z>0$ satisfy $$xy + yz + zx + 2xyz = 1.$$ Prove that $4x+y+z\geq 2$. The condition invites the factoring $(1+x)(1+y)(1+z)+xyz-2=x+y+z$, but having the factor $4$ in the desired inequality makes things more difficult.","['algebra-precalculus', 'inequality']"
1336028,"A lot of confusion in the ""Polynomial Remainder Theorem""?","Lately I've been reading about Polynomial Remainder Theorem from various sources, mainly from the wikipedea article , this post and some high school books. Wikipedea says that if we divide a polynomial $f(x)$ with another polynomial $g(x)$ then $$f(x)=q(x)g(x) + r(x)\quad \text{and}\quad r(x) =0 \; \text{or}\; \deg(r)<\deg(g)\ \tag{1}$$ Why is the expression for $q(x)$ same for all values of $x$ ? E.g. suppose $f(x) = x^3 - 12x^2 - 42$ and $g(x) = x-3$ then $q(x)$ might be of form $q(x)=ax^n+bx^{n-1}+cx^{n-2} \cdots$ . For whatever reason the following relation is true, $$f(x) = x^3 - 12x^2 - 42 = (x-3)(x^2+15x)+3$$ Here why is $a=1$ , $b=15$ , $c=0$ and $n=2$ always true irrespective of the values $x$ take? Why is $\deg(r)$ always less than $\deg(q)$ ? As far as I know things are equivalent to usual Euclid's division, $|r(x)|<|g(x)|$ . Now it might be that for any polynomial $r(x)$ to be less than another polynomial $g(x)$ , $r(x)'s$ degree has to be less than that of $(g(x)'s$ -- but I don't know why is this true or how I can prove it. What is the logic behind long division? Why do we keep on taking the reminder in each step? E.g. while dividing $x^3 - 12x^2 - 42$ with $(x-3)$ why is in first step quotient is $x^2$ , why not just $x$ , why always choose the maximum possible value? This was about the confusions related to the definition. It is said that in equation $1$ if $g(x)=(x-a)$ then $f(a)=r$ , because of $$f(x)=q(x)(x-a) + r \tag{2}$$ But why is equation $2$ true for $x=a$ ? Here $g(a)=0$ so we can't just perform the Euclid division over $f(x)$ . Moreover the expression for equation $2$ with $g(x)$ being $0$ must be something like $$f(x)=0 q(x)+f(x)$$ That is the reminder should be $f(x)$ itself. Most of the answers on the similar question say that we aren't actually dividing by $0$ , we are just figuring out an algebraic identity of sort, $f(x)=(x-a)q(x)+r$ . I agree that if we actually multiply $(x-a)$ with $q(x)$ and then add $r$ to it to observe that the identity holds then $f(a)=r$ , but what we actually do is Euclid division to find out $q(x)$ , which we can't do because we can't divide with $0$ . But then I don't understand why does the value of $q(x)$ found with Euclid division under the condition of $x\neq a$ is same as the value found by trial and error by actually multiplying with guessed values of $q(x)$ with $x-a$ . Another answer says equation $2$ is true for $x=a$ because the following relation holds, $$\begin{eqnarray} f'(a) &=\,& \dfrac{f(x)-f(a)}{x-a}\Bigg|_{\large\, x\,=\,a}\\ \\ {\rm i.e.}\ \ \ f'(a) &=\,& q(a)\ \ {\rm where}\ \ f(x)-f(a) = q(x)(x-a)\end{eqnarray}$$ As far as I know he/she is using the Maan Value Theorem by substituting $x$ for $b$ in the standard equation, $$ f'(c) = \frac{f(b) - f(a)}{b-a}$$ Where $x,c \to a$ , but we can't take $x=c=b$ . So equation (1) might be true for $x \to a$ but not for $x=a$ .","['polynomials', 'definition', 'euclidean-algorithm', 'algebra-precalculus']"
1336036,"Pathologies in ""rng""","There is no general consensus regarding whether a ring should have a unity element or not. Many authors work with unital rings , and other does not essentially require unity. 
If we do not assume unity to be a necessary part of ring, lets call that structure , a "" rng "" (which may or may not have unity i.e. $1$), then many pathologies do occur. I am hoping to get such pathologies (with at least one example) listed together on a page which I can keep as a record for future references. I will post my list as an answer here, to get it started, and hope others will contribute to it, and make this post valuable.","['abstract-algebra', 'rngs', 'ideals', 'ring-theory']"
1336068,How to calculate $\nabla \ln(|\mathbf{u}-\mathbf{v}|)$,"I need to calculate:$$\nabla \ln(|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|)$$where $\mathbf{u}$ and $\mathbf{v}$ are vector valued functions with $\alpha$ and $\gamma$ as independent values and $|\cdot|$ denotes Euclidean norm. Does the $\nabla$ operator represents in this case, $$\nabla = \frac{\partial}{\partial \alpha}\mathbf{e}_1+\frac{\partial}{\partial \gamma}\mathbf{e}_2?$$ If so, are the following calculations correct? NOT CORRECT, SEE EDIT $$\frac{\partial}{\partial\alpha}\ln(|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|) = \frac{1}{|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}\frac{1}{2|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}2(\mathbf{u}(\alpha)-\mathbf{v}(\gamma))=\frac{1}{\mathbf{u}(\alpha)-\mathbf{v}(\gamma)},$$
$$\frac{\partial}{\partial\gamma}\ln(|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|) = \frac{1}{|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}\frac{-1}{2|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}2(\mathbf{u}(\alpha)-\mathbf{v}(\gamma))=\frac{-1}{\mathbf{u}(\alpha)-\mathbf{v}(\gamma)},$$
Then,
$$\nabla \ln(|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|) \stackrel{?}{=} \left[\frac{1}{\mathbf{u}(\alpha)-\mathbf{v}(\gamma)},\frac{-1}{\mathbf{u}(\alpha)-\mathbf{v}(\gamma)}\right].$$ EDIT I do not think is correct because $\frac{1}{|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}\frac{1}{2|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}$ is a scalar but $2(\mathbf{u}(\alpha)-\mathbf{v}(\gamma))$ is a vector. Here is my new attempt:
$$\frac{\partial}{\partial\alpha}\ln(|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|) = \frac{1}{|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}\frac{1}{2|\mathbf{u}(\alpha)-\mathbf{v}(\gamma)|}\left(2(u_1(\alpha)-v_1(\gamma))\frac{\mathrm{d}}{\mathrm{d}\alpha}u_1(\alpha)+2(u_2(\alpha)-v_2(\gamma))\frac{\mathrm{d}}{\mathrm{d}\alpha}u_2(\alpha)\right)$$where $u_1$ denotes the first component of vector $\mathbf{u}(\alpha)$. Thanks for helping!","['solution-verification', 'vector-analysis', 'multivariable-calculus']"
1336093,How many unique numbers can be obtained from multiplying two natural numbers less than $N$?,"The question seems simple, but I cannot wrap my head around how to properly count it, or even give a good estimate. I can't find the answer either. We have two integer numbers $1 < a,b < N$, how many unique products of $a \cdot b$ there are? The possible simplification could be that $N$ is also a prime, as I also interested in a good estimation. My more basic question is it less than $O(N^2)$, but the actual count seems more interesting. This seems related to How many unique combination of $n$ numbers are there when multiplying $x$ numbers? , though answerer there makes one assumption which is a killer IMO, all the products are distinct ("" unless they have to "" which, I believe, meant commutativity of multiplication). In the above the statement is clearly false. E.g. $1 \cdot 4 = 2 \cdot 2$ or $4 \cdot 4 = 2 \cdot 8$. $24$ would also appear quite some times. What have I tried: The obvious upperbound is $N^2$ which is a clear over-estimation (even if we divide it by 2 due to commutitativity) - we cannot obtain any compound involving prime $p_i$ such as $N < p_i < N^2$. My approach was to count prime numbers and assume all the possible numbers are compounds of them, the answer from the cited question could be used then, but this is also not true. E.g. for $N=5$ we need to treat $4$ as a ( pseudo ) prime to get $20$. I can't figure how to count numbers to be excluded from $N^2$, or which to include and when. I had idea that all numbers greater than $\sqrt{N}$ (or maybe $N/2$) can be treated as those pseudo-primes, but I am not sure if this is the correct way.","['prime-numbers', 'elementary-number-theory', 'combinatorics']"
1336103,Algebraic Peter-Weyl theorem in the case of $G=SL_2$.,"The algebraic Peter-Weyl theorem says that for a linear reductive group $G$ we have $\mathbb{C}[G] = \oplus_{V} V \otimes V^* $, where $V$ runs over the set of all non-isomorphic irreducible representations of $G$. I would like to know this result explicitly in the case of $G=SL_2$. We have $\mathbb{C}[SL_2] = \mathbb{C}[a,b,c,d]/(ad-bc-1)$. How to write $\mathbb{C}[SL_2] = \oplus_{V} V \otimes V^* $ explicitly (write the representations $V$ explicitly)? Thank you very much.","['algebraic-groups', 'group-theory', 'representation-theory']"
1336128,Existence of a specific prime,"Reading some background on the Brocard-Ramanujan equation I found a proof which says the following. For a fixed natural number $A$ which is not a square it is always possible to find a prime $p$ such that $p>A$; $x^2\equiv A \pmod{p}$ has no solution (that is, $A$ is a quadratic non-residue modulo $p$). However, the proof does not say anything about how it is possible. I do not find it so evident. Maybe I am missing some very basic fact.","['quadratic-residues', 'number-theory']"
1336135,"In a circle there are $m$ chords and no $3$ are concurrent, $n$ intersections in the interior. Show there are $m+n+1$ regions dividied by the chords.","In a circle there are $m$ chords such that no $3$ are concurrent and
  there are $n$ intersections of these chords in the interior of the
  circle. Prove that the number of regions divided by the chords is
  given by $m+n+1$ For example in the above diagram there are $3$ chords, $3$ points of intersection and $7$ regions. Tried both counting the regions and establishing some sort of a bijection with a set of $m+n+1$ elements but didnt get very far. Any suggestions?",['combinatorics']
1336136,Is this Function differentiable and continuous at x=0? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Is $f(x)$ continuous and differentiable at $x = 0$ ? $$f(x) = x(\sqrt{x} - \sqrt{x+1})$$","['continuity', 'calculus', 'derivatives']"
1336137,"Solve the differential equation. $\frac{dy}{dx} + 2y = f(x),$ where $f(x) = 1,$ if $ 0 \leq x \leq 1;$ $ f(x) = 0, x > 1, y(0) = 0.$","Solve the differential equation. $\frac{dy}{dx} + 2y = f(x),$ where $f(x) = 1,$   if $ 0 \leq x \leq 1;$ $ f(x) = 0, x > 1, y(0) = 0.$ Find $f(\frac{3}{2}).$ I am confused whether to use the concept as follows: An integrating factor is $\mathrm e^{\int 2 dx}.$
Then after multiplication, it makes the original equation exact. Is it okay? Please tell. Thanks in advance...",['ordinary-differential-equations']
1336143,Function and Domain with Deleted Neighbour - Beginner Question,"I have a simple question about functions and domains. Consider the following function: $$f(x) = \frac{ x^2-9}{x-3}$$ I often see in the textbooks mentioning that the domain of this function can be any real number except 3. However, the given function can be reduced to $$ f(x) = \frac{(x+3)(x-3)}{(x-3)} = x+3 $$ Here, the domain now becomes all real number. How this is possible? If both are the same function, how they can have two different domain? Many thanks for helping a beginner. I appreciate your answers in advance.",['functions']
1336145,How do I find $\|T\|$ when given a matrix $T$?,"How do I find the norm $\|T\|$ of T: $\mathbb{R}^3 \rightarrow  \mathbb{R}^3$ is defined by $T(x) := Ax$, where $A:= \begin{pmatrix}
0 & 2 & 0 \\
1 & 0 & 0 \\
0 & 0 & 3 \end{pmatrix} $. I was thinking of writing $T(x_1,x_2,x_3)=(2x_2,x_1,3x_3)$
and then $\|T\|$ =$((2x_2)^2+(x_1)^2+(3x_3)^2))^{1/2}$. Do I find $\|T\|$ like this or not?","['analysis', 'normed-spaces', 'linear-algebra', 'matrices']"
1336149,"The matrix $A-I$ is invertible, suppose $A^2=A$ and show that $A=0$","Let $A_{n\times n}$ over $F$ such that the matrix $A-I$ is invertible. Suppose $A^2=A$, prove that $A=0$. It's easy to see that $A(A-I)=0=(A-I)A$ I also know that there exist a matrix $B$ such that $B(A-I)=(A-I)B=I$ but I can't find a way to use that. Everything I try leads to $A-A=0$ which doesn't help.","['linear-algebra', 'matrices']"
1336169,Differentiating an endomorphism,"Let $(M,\rho)$ be a symplectic $2$-dimensional manifold, and let $J$ be a compatible complex structure on $M$, i.e. the symmetric $(0,2)$-tensor
$$g(*,*) = \rho(*,J*)$$
is a Riemannian metric. Denote by $\nabla$ the Levi-Civita connection. Now let $V\in\Gamma(TM)$ be a vector field (with some further assumptions which are probably not needed). I would like to compute
$$\left.\frac{d}{dt}\right|_{t=0}\left((d\varphi_V^{-t})_{\varphi_V^t(m)}J(\varphi_V^t(m))(d\varphi_V^t)_m\right),$$
where the map in the brackets is a map $T_mM\to T_mM$. Here $\varphi_V^t$ denotes the flow of $V$. If my computations are correct, I get the expression
$$-\nabla_{J*}V + (\nabla_VJ)(*) + J(\nabla_*V)\tag{1},$$
which is again an endomorphism of $TM$. I would like to further simplify this expression. This would be easy if we had
$$\nabla_{J*}V = J(\nabla_*V),$$
but I'm afraid that this is not true (at least without some more assumptions/structure). The only results I have about relations between $\nabla$ and $J$ are
$$J(\nabla_*J) = (\nabla_*J)J\quad\mathrm{and}\quad\nabla_{J*}J = -J(\nabla_*J)$$
(see e.g. lemma 4.1.14 in this book ), but I haven't been able to get anywhere using them. My questions are: Is my computation $(1)$ correct? Is it possible to further simplify the expression $(1)$? If you think that further assumptions are needed to solve the problem, please let me know.","['complex-geometry', 'manifolds', 'symplectic-geometry', 'kahler-manifolds', 'derivatives']"
1336180,Counter exchanging limit and integral,"Background I came across this answer on Math SE which claimed it made a lot of sense to switch limit and integral. In response I came up with the following counter-examples: $\lim_{w \to 0} \int_0^\infty we^{-wt}\ dt = 1$ but $\int_0^\infty \lim_{w \to 0} we^{-wt}\ dt = 0$. $\lim_{n \to \infty} \int_0^\infty \frac{t^{n+1}}{n!} e^{-t}\ dt = \infty$ but $\int_0^\infty \lim_{n \to \infty} \frac{t^{n+1}}{n!} e^{-t}\ dt = 0$. $\lim_{n \to \infty} \int_0^1 n^3 t^n (1-t)\ dt = \infty$ but $\int_0^1 \lim_{n \to \infty} n^3 t^n (1-t)\ dt = 0$. $\lim_{r \to \infty} \int_{-\infty}^\infty \frac{r(rx)^3}{(rx)^4-(rx)^3+1}\ dx = \lim_{r \to \infty} \int_{-\infty}^\infty \frac{y^3}{y^4-y^3+1}\ dy \approx 2$ and $\lim_{r \to \infty} \frac{r(rx)^3}{(rx)^4-(rx)^3+1} = \frac{1}{x}$ for any $x \ne 0$. [Newly added] Unlike the claimed method in that post, the first three counter-examples have continuous limit functions. The third has the advantage of having the integral over a finite interval, to show that interchanging is still not valid without additional assumptions on the function sequence. The fourth uses exactly the same technique as the claimed method (with a discontinuous limit function) and also gives an integral that is constant and independent of the limit! Of course, these examples do not satisfy the dominated convergence theorem in various ways. Question Do you have any good counter-examples that actually show up in real-world problems and have an experimentally measurable implication for the real world? I somehow get the impression that the functions in the real-world might be too nice (wave functions are infinitely differentiable when you really factor everything in; in particular there are no such things as square potential wells because it is impossible to have a discontinuous change in potential!) I would be satisfied with examples in classical mechanics if the effect is measurable.","['physics', 'examples-counterexamples', 'limits', 'integration']"
1336187,What is an integral of operators?,"I am reading the book Semigroups of Linear Operatos and Applications to Partial Differential Equations which studies a uniformly continuous semigroup, this is a family $(T_t)_{t \geq 0}$ of bounded operators $T :X \to X$ on a Banachspace $X$ with $T(0)=Id$ $T_{s+t}=T_s T_t$ $ \lim_{t \to 0^+} || T_t - I || = 0$ They define the infinitesimal generator as
$$ Ax :=\lim_{t \to 0^+} \frac{T_tx -x}{t} $$
for $x \in \mathcal{D}(A) := \{  x \in X \mid \lim_{t \to 0^+} \frac{T_tx -x}{t} \text{ exists} \}.$ Theorem 1.2 states A linear operator A is the infinitesimal generator of a uniformly continuous  semigroup if and only if A is a bounded linear operator I am having difficulties to understand one direction of the proof, namely that for a uniformly continuous semigroup you find a bounded linear operator. The start of the proof goes like this: Let $(T_t)_{t \geq 0}$ be a uniformly continuous semigroup of bounded linear operators on $X$. Fix $\rho >0 $ small enough, such that $$||I - \rho^{-1} \int_0^{\rho}T(s) \, ds|| < 1$$ But how is the integral of operators defined and why can you assure such a $\rho> 0$?","['semigroup-of-operators', 'functional-analysis']"
1336194,Every convex function is locally Lipschitz ($\mathbb{R^n}$),I know that if $f$ is convex function so $f$ is continuous. And I know too that partial derivatives exists. What can I do?,"['lipschitz-functions', 'convex-analysis', 'multivariable-calculus']"
1336197,Asymptotic behavior of many derivatives,"To compute the residue of a pole of very high order $M$ at $z=0$, one needs to compute $\frac{d^M}{dz^M} g(z)$ Suppose that $g(z)$ is a reasonable but not trivial function, that itself may depend on $M$. At the moment I'm interested in $g(z) = \left(\frac{f(z)}{h(z)}\right)^{\gamma-k M}$ where $f(z)$, $h(z)$ are polynomials, and $\gamma$ and $k$ are rational but not integers, but I would like to generalize later. Are there any tricks to get the asymptotic behavior for this quantity? I know the following: (1) I can Laurent expand everything in sight, collect sums and pick out the $M^{th}$ term. This works but then appears to require a lot of Stirling approximations to see the dominant terms. (2) In principle, I could find the Fourier transform of $g$ and look at its large $q$ behavior. This looks intractable, but would at least allow saddle-point methods to be applied.","['asymptotics', 'approximation', 'calculus', 'complex-analysis']"
1336199,Smallest Two-Sided Nearrings,"For those who are unfamilar with nearrings, here is a definition.  Note that there are left-nearrings (where only the left distribution property is assumed), and right-nearrings (where only the right distribution property is assumed) as well.  I only consider two-sided nearings. Definition. A two-sided nearring is a triplet $(N,+,\cdot)$ , where $(N,+)$ is a group and $(N,\cdot)$ is a semigroup such that we have both left and right distributive properties of the multiplication $\cdot$ over the addition $+$ , namely, $$x\cdot(y+z)=(x\cdot y)+(x\cdot z) \text{ and }(x+y)\cdot z=(x\cdot z)+(y\cdot z)$$ for $x,y,z\in N$ .  Of course, every additive group $(G,+)$ with identity $0_G$ can be made a two-sided nearring with the trivial multplication $g\cdot h:=0_G$ for all $g,h\in G$ .  Such a nearring is called a trivial two-sided nearring. My question is about nontrivial two-sided nearrings which are not rings (i.e., the addition $+$ is not commutative).  I know one which has $128$ elements: $N:=(\mathbb{Z}/8\mathbb{Z})\times (2\mathbb{Z}/8\mathbb{Z})\times (2\mathbb{Z}/8\mathbb{Z})$ , where $$\left(a_1,b_1,c_1\right)+\left(a_2,b_2,c_2\right):=\left(a_1+a_2+c_1b_2,b_1+b_2,c_1+c_2\right)$$ and $\left(a_1,b_1,c_1\right)\cdot\left(a_2,b_2,c_2\right)$ is given by $$\left(a_1b_2+a_2b_1+a_1c_2+a_2c_1+b_1b_2+b_2c_1+c_1c_2,b_1b_2+b_1c_2+b_2c_1+c_1c_2,0\right)\,,$$ for all $a_1,a_2\in\mathbb{Z}/8\mathbb{Z}$ , and $b_1,b_2,c_1,c_2\in2\mathbb{Z}/8\mathbb{Z}$ . Old Question. Can you find a nontrivial two-sided nearring which is not a ring with the minimum number
of elements ?  This question has been answered here . The example seen in Eran's answer in the link above is a two-sided nearring which is not a ring with the smallest number of elements.  While the addition of this example is noncommutative, the multiplication is commutative.  Therefore, I am offering a bounty price for anybody who answers the question below. Bounty Question. What is a two-sided nearring
with the minimum number of elements which is not a ring and whose
multiplication is also noncommutative?  Please also prove that your example has the smallest number of elements amongst all two-sided nearing whose multiplication and addition are noncommutative. A Remark (which may or may not be helpful). If $(N,+,\cdot)$ is a two-sided nearing, then the subnearring $N^{\cdot 2}$ of $N$ generated by elements of the form $a\cdot b$ , where $a,b\in N$ , is a ring.  That is, $N^{\cdot 2}$ consists of all integer combinations of $a\cdot b$ , where $a,b\in N$ .  To show this, let $a,b,c,d\in N$ .  Then, we have $$(a+b)\cdot (c+d)= a\cdot(c+d)+b\cdot(c+d)=(a\cdot c+a\cdot d)+(b\cdot c+b\cdot d)$$ and $$(a+b)\cdot(c+d)=(a+b)\cdot c+(a+b)\cdot d=(a\cdot c+b\cdot c)+(a\cdot d+b\cdot d)\,,$$ whence $$a\cdot c+a\cdot d+b\cdot c+b\cdot d=a\cdot c+b\cdot c+a\cdot d+b\cdot d\,,$$ making $$a\cdot d+b\cdot c=b\cdot c+a\cdot d\,.$$ In particular, if $N$ is a two-sided nearring which is not a ring, then $N$ cannot have a multiplicative identity (otherwise, $N^{\cdot 2}=N$ , making $N$ a ring).","['finite-rings', 'ring-theory', 'abstract-algebra', 'group-theory', 'finite-groups']"
1336265,Explanation of the thinness ratio formula?,"I am looking for sliver polygons (term used in geographic information systems for long thin 2D surfaces) and am using the following formula to identify which polygons have a smaller area to circumference ratio (a.k.a. the thinness ratio):
$$
  \frac{4 \cdot \pi \cdot \text{area}}{\text{perimeter}^2}
$$
That much I understand. But what is not fully clear, is the $4 \cdot \pi$ bit and why the length has to be squared. Can someone explain this in simple terms?",['geometry']
