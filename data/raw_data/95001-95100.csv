question_id,title,body,tags
1302369,A question about the vector space spanned by shifts of a given function,"Let $E$ be the space of continuous real functions and $f\in E$ Let $T_t$ denote the shift operator: $T_t(f)(x)=f(t+x)$ Let $T(f)$ be the linear span of the set $\{T_t(f) \;|\; t\in \mathbb R\}$ Suppose $T(f)$ is finite-dimensional. Prove that $f$ is differentiable and that $f'\in T(f)$ I have very few clues about what should be done to solve this problem. Here's my work so far. Let $T_{a_1}(f),\ldots,T_{a_n}(f)$ be a basis of $T(f)$ . Let $x\in \mathbb R$ . There exists $\lambda_1,\ldots,\lambda_n$ such that $T_{x}(f)=\sum_{k=1}^n \lambda_i T_{a_i}(f)$ Since $\displaystyle \frac{f(x+h)-f(x)}{h}=\frac{T_{x}(f)(h)-T_{x}(f)(0)}{h}=\sum_{k=1}^n \lambda_i \frac{T_{a_i}(f)(h)-T_{a_i}(f)(0)}{h}$ , it suffices to prove that $f$ is differentiable at $ a_1,\ldots,a_n$ , but that's still difficult.","['linear-algebra', 'real-analysis', 'functional-analysis', 'derivatives']"
1302370,IVT and fixed point theorem,"Suppose that
$f:[0,1]→[0,2]$
is continuous. Use the Intermediate Value Theorem to
prove that there exists
$c∈[0,1]$
such that
$f(c)=2c^2$ The answer to this goes from the Fixed point theorem. But in that theorem the domain and codomain were the same but in this it is not. Here is what I did: Define $g:[0,1] \rightarrow [0,2]$ by $g(x)=2x^2$. If $g(0)=0$ or $g(1)=2$ then we are done. Otherwise, since $f(0),f(1) \in [0,2]$, $f(0)>0$ and $f(1)<2$ Define $h:[0,1] \rightarrow [0,2]$ by $h(x)= 2x^2 - f(x)$. This is a continuous function. So $h(0)<0<h(1)$. By IVT, there exists $c \in (0,1)$ such that $h(c)=0$ giving the desired result. Does this still work since the dom and codom of each function weren't the same. I know that for IVT, they dont have to be the same but for the ixed point theorem, it says they have to. Is my answer correct?","['analysis', 'real-analysis']"
1302379,A simple way to find $\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}}$,"I was reading an exam paper used to identify gifted high-school students, and I encountered the following problem: 
$$\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}}$$
Using standard calculus techniques, this sum can be easily calculated by treating the sum as a riemann sum, and calculating the corresponding integral. Indeed, if we denote $f(x)=\sqrt{1-x^2}$, we get:
$$
\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}} =  \lim_{n\rightarrow\infty}{\frac{1}{n}\sum_{k=1}^n{f\left(\frac{k}{n}\right)}} = 
\int_0^1{f(x)dx}=\frac{\pi}{4}
$$
Where the integral is calculated by noting that the area under the graph of $f$, between $0$ and $1$, is a quarter of the unit disk. However, in my country, riemann sums are not taught in high-schools, so using this technique is not an option. Is there a simpler method to calculate this limit?","['calculus', 'limits', 'algebra-precalculus']"
1302389,Meaning of n-connected pairs,"A topological space $X$ is $n$-connected if the homotopy groups $\pi_r(X)$ for $0 \leq r \leq n$ are trivial groups. This means (let's say geometrically), $X$ is $0$-connected if it is non-empty and path-connected. It is $1$-connected if it is simply connected. Now, Let X be a topological space and A⊂X a subspace. For x∈A, the homotopy group $\pi_n(X,A,x)$ of the pair $(X,A)$ is by definition the set of homotopy classes of n-cells relative to X modulo A (the usual definition). Now, a pair is $n$-connected if $\pi_r(X,A)$ is trivial for $0 \leq r \leq n$. Is there any interpretation (geometrical) of $0$-connectedness and $1$-connectedness of a pair $(X,A)$? In general what does it mean (geometrically) by an $n$-connected pair?","['homotopy-theory', 'algebraic-topology', 'general-topology']"
1302395,n points can be equidistant from each other only in dimensions $\ge n-1$?,"2 points are from equal distance to each other in dimensions 1,2,3,... 3 points can be equidistant from each other in 2,3,... dimensions 4 points can be equidistant from each other only in dimensions 3,4,... What is the property of number dimensions that relates the number of points that can be equidistant to all other points?","['geometry', 'soft-question']"
1302420,Solve $\cos3x=\cos4x$,"I want to solve the equation $\cos3x=\cos4x$.  The given solutions are $x= 0$, $2\pi/7$, $4\pi/7$ and $6\pi/7$. My first approach was to write the whole thing in terms of $\cos x$ this gave, $0=(\cos x - 1)(8\cos^3x + 4\cos^2x - 4\cos x - 1)$. This gave me the obvious solution of $\cos x = 1$ and therefore $x=0$, however I don't know how to tackle the second set of brackets. 
I've also thought about writing in terms of exponentials, but didn't get to anything simpler. Another way I tried was to say that
$4x = \cos^{-1}(\cos3x)$ $\therefore 4x = 3x + (2n\pi)$. However this just gives that $x$ is $2n\pi$, which ignores the 7 given in the solution! There is no mention of an interval in the question and yet still only the 4 solutions given? I would really appreciate any help, I'm studying for an exam in a few weeks time, and would hate to have an unsolved problem! Thank you in advance.",['trigonometry']
1302424,Is $O(n)$ normal in $GL(n)$?,"Is the orthogonal group $O(n)$ normal in  $GL(n)$? Here is what I did so far: Let $Q\in O(n),S\in GL(n)$  we want to check if $S^{-1}QS\in O(n)$: $(S^{-1}QS)^T=(S^{-1}QS)^{-1}\iff S^TQ^T(S^{-1})^T=S^{-1}Q^{-1}S $ $\iff S^TQ^{-1}(S^T)^{-1}=(S^{-1}Q^{-1}S)\iff SS^TQ^{-1}=Q^{-1}SS^T$ $\iff Q(SS^T)=(SS^T)Q$. So the normality of $O(n)$ in $GL(n)$ is equivalent to the following claim:
$\forall S\in GL(n)$  $SS^T$ commutes with any element of $O(n)$. Update: Here is an easy way to continue (suggested by Alex Fok): Focus upon symmetric matrices $S$. Then if $O(n)$ is normal, for every symmetric $S\in GL(n)$, its square $S^2$ must satisfy: $QS^2=S^2Q $ $\forall Q\in O(n)$. Now take $S=\begin{pmatrix} x & 0 \\\ 0 & y \end{pmatrix}$ for $0\neq x\neq y\neq 0$. Then $S^2=\begin{pmatrix} x^2 & 0 \\\ 0 & y^2 \end{pmatrix}$. Now we can check which matrices commutes with $S^2$: Let
 $Q= \begin{pmatrix} a & b \\\ c & d \end{pmatrix}$. Then: $QS^2=\begin{pmatrix} ax^2 & by^2 \\\ cx^2 & dy^2 \end{pmatrix}$, $S^2Q=\begin{pmatrix} ax^2 & bx^2 \\\ cy^2 & dy^2 \end{pmatrix}$. Hence the two products are equal iff $b=c=0$ that is $Q$ is of the form $\begin{pmatrix} a & 0 \\\ 0 & d \end{pmatrix}$. Since not every orthogonal matrix is of this form, this implies $O(n)$ is not normal.","['orthogonality', 'group-theory', 'normal-subgroups']"
1302433,infinity series of Riemann zeta function at odd integers,"Properties of Riemann zeta function at odd and even integers diverge dramatically, which can be proved by many evidences. I once found an infinity series in wikipedia , it reads
$$
\sum_{n=1}^{\infty}\frac{\zeta(2n)-1}{a^{2n}} = \frac12+\frac{1}{1-a^2}-\frac{\pi\cot(\pi/a)}{2a},~\vert a\vert>1
$$
or equivalently,
$$
\sum_{n=1}^{\infty}\frac{\zeta(2n)}{a^{2n}} = \frac12-\frac{\pi\cot(\pi/a)}{2a},~\vert a\vert>1.
$$ Here, I just wonder that, if there is a closed form for the series
$$
I(a)=\sum_{n=1}^{\infty}\frac{\zeta(2n+1)}{a^{2n+1}} = \mathbf{?},~\vert a\vert>1.
$$
Thanks a lot. Any suggestion or material link will be welcomed. EDIT: As @Lucian's hint in the comment, I arrive at
$$
I(a)=\sum_{n=1}^{\infty}\frac{1}{a^{2n+1}}\Big(\sum_{k=1}^{\infty}\frac{1}{k^{2n+1}}\Big)=\sum_{k=1}^{\infty}\sum_{n=1}^{\infty}\frac{1}{(ka)^{2n+1}}=\sum_{k=1}^{\infty}\frac{1}{(ka)[(ka)^2-1]}
$$
However, the trick 
$$\frac{1}{x(x^2-1)}=\frac{x}{2}\Big(\frac{1}{x-1}-\frac{1}{x+1}\Big)-\frac{1}{x}
$$
doesn't seem to work for the above series. What should I do now?","['sequences-and-series', 'riemann-zeta', 'riemann-sum']"
1302436,$A^2=A^*A$. Why is matrix $A$ Hermitian? [duplicate],"This question already has answers here : $TT^*=T^2$, show that $T$ is self-adjoint (2 answers) Closed 7 years ago . Let $A$ be $n \times n$ matrix and $A^2=A^*A$.  Why is $A$ a Hermitian matrix?","['linear-algebra', 'hermitian-matrices', 'matrices']"
1302440,Integration by parts formula with Lebesgue Integral and distribution function,"I'm struggling to find a solution for the following problem: Let $f$ be an absolutely continuous function on $[a,b]$ , let $\mu$ be a bounded Borel measure on $[a,b]$ , and let $\Phi_\mu(t)=\mu([a,t))$ with $\Phi_\mu(a)=0$ .
Prove $$\int_{[a,b]}f(t)\mu(dt) = f(b)\Phi_\mu(b+)-\int_a^bf'(t)\Phi_\mu(t)dt,$$ where $\Phi_\mu(b+)=\lim_{y\to b^+}\Phi_\mu(y)$ . Obviously, this is some kind of integration by parts formula which per se is not hard to prove, but I have no idea how to use the general distribution function $\Phi_\mu$ . Any help is highly appreciated; thank you very much!","['lebesgue-integral', 'measure-theory']"
1302441,Is the relation $xPy$ iff $ y = x + n\pi$ an equivalence relation on $\Bbb R$?,"I am trying to prove that the relation $P$ on $\mathbb{R}$ given by the rule $$\forall x, y \in \mathbb{R}, xPy \text{ if and only if } \exists n \in \mathbb{Z} \text{ such that }y = x+ n\pi$$ From what I can see, $P$ fails the reflexive test, i.e. when showing xPx: $x \neq x + n\pi$ . But I was told by somebody that $P$ is an equivalence relation. Could someone please confirm whether it is indeed an equivalence relation or not? Thanks heaps
C :)","['elementary-set-theory', 'equivalence-relations', 'relations']"
1302461,Determining a scheme $X$ is affine from $Qcoh(X)$,"My question is a subquestion of this question . I do not want to use full reconstruction theorems. The settings is the following. Let $X$ be a scheme. Assume that the adjunction in TAG01BH of the stacks project is actually an adjoint equivalence. As is the case for every affine scheme.
Is $X$ affine? Or, which is the same, is the canonical map $X\rightarrow \mbox{Spec } O_X(X)$ an iso? What I tried thus far is proving all hypothesis of Serre's vanishing theorem and invoking it. The problem: how to prove that there exist 'enough' acyclic resolutions inside $Qcoh(X)$ as is the case for $Qcoh(\mbox{Spec } O_X(X))$ since $\widetilde{I}$ is flasque for injective modules $I$. Any hints? Any hints in general are also welcome.","['quasicoherent-sheaves', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
1302479,Prove that limit doesn’t exist anywhere? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I'm doing some practice problems and am having trouble answering these problems: Consider the following function $$f(x)=\begin{cases}1, & \text{if } x\in \Bbb Q\\ -1, & \text{if } x\in \Bbb R\backslash \Bbb Q. \end{cases}$$
Prove that limit doesn’t exist anywhere.","['calculus', 'limits']"
1302481,How to prove that the ring of all algebraic integers is a Bézout domain?,"I was told that the ring of all algebraic integers (that is, the complex numbers which are roots of a monic polynomials with integral coefficients) is a Bézout domain. But I have no idea how to prove it. Can anyone help me with this? Thanks in advance.","['ring-theory', 'commutative-algebra', 'number-theory', 'abstract-algebra', 'algebraic-number-theory']"
1302484,Solving $7[x]+23\{x\}=191$,"For every real number $x$, $[x]$ denotes the largest integer less than
  or equal to $x$ and $\{x\}=x-[x]$. The number of real solutions of $$7[x]+23\{x\}=191$$ is (a) 0 $\quad$ (b) 1 $\quad$ (c) 2 $\quad$ (d) 3 I solved it like this: $$7[x]+23\{x\}=191$$ $$7(x-\{x\})+23\{x\}=191$$ $$7x+16\{x\}=191$$ Now, $$0 \leq \{x\} < 1$$ $$0 \leq 16\{x\} < 16$$ $$0 \leq 191-7x < 1$$ $$-16 < 7x-191 \leq 0$$ $$175 < 7x \leq 191$$ $$\frac{175}{7} < x \leq \frac{191}{7}$$ $$25 < x \leq 27.2857$$ But $x=26$ doesn't satisfy given equation. Answer given is $(d)$ $3$. I don't understand where I'm wrong. A hint will be of great help. Please don't provide complete solution. Sorry for poor LaTeX.","['fractional-part', 'ceiling-and-floor-functions', 'algebra-precalculus']"
1302495,Homogeneous metric on a homogeneous space $G/K$ - is this the same as a $G$ - invariant metric?,"I have trouble putting down the notion of a homogeneous Riemannian metric. Suppose we are given a Riemannian manifold $(M,g)$ on which a compact Lie group $G$ acts transitively by isometries (this means that $h^*g = g$ for any $h \in G$, i.e. for any vector fields $X,Y$ on $M$ and any point $p \in M$,
$$
g_{h \cdot p} \big(h_{*,p}(X_p),h_{*,p}(Y_p)\big) = g_p\big(X_p,Y_p) \,.
$$
It also means that if we fix any point $p \in M$ and denote by $K$ the isotropy subgroup associated with $p$ then there is a smooth bijection $\varphi \colon G / K \to M$ given by $\varphi(hK) =  h \cdot p$. Ok, this map then allows us to endow $G / K$ with a metric $\tilde g$ as follows: we decompose the Lie algebra $\mathfrak g$ of $G$ into $\mathfrak m \oplus \mathfrak k$ where $\mathfrak k$ is the Lie subalgebra of $K$ in $\mathfrak g$. Then we have an identification $T_pM \cong \mathfrak m \cong T_K(G/K)$, which allows us to set the value of $\tilde g$ at the point $hK$ on vector fields $X,Y$ over $G/K$ by
$$
	\tilde g_{hK}\big((L_{hK})_{*}(X_{K}),(L_{hK})_{*}(Y_{K})\big) := g_{p}\big(X_{K},Y_{K}\big)
$$
where $L_{hK}$ denotes left translation in $G / K$ by $hK$ and we use the isomorphism $T_pM \cong \mathfrak m \cong T_K(G/K)$  to identify $X_K$ and $Y_K$ with elements in $T_pM$. This metric is manifestly invariant under left translation by $G$ (simply because the right hand side does not see the effect of left translation), i.e. $\tilde g$ is a $G$ - invariant metric on $G / K$. Is this also called a homogeneous metric? I know what homogeneous Riemannian manifolds are, these are precisely of the form given above, where a Lie group acts transitively by isometries, however when it comes to the notion of a homogeneous metric I would have to \emph{guess} that by this is meant the construction above .. is it correct? In other words, do we mean then that $(G/K,\tilde g)$ is a homogeneous Riemannian manifold? Thanks a lot for your feedback and help!!","['differential-geometry', 'riemannian-geometry', 'group-actions']"
1302545,Why is $\int\int f(x)f(y) |x-y|dxdy$ negative?,"The Setup Let $f:\mathbb{R} \to\mathbb{R}$ be a smooth function with support in the 
interval $[-R,R]$ and satisfying $\int f = 0$.  By manipulating some integrals, I found the surprising inequality
$$
\int\int f(x)f(y) |x-y| \,dxdy \leq 0.
$$
My questions are Is this inequality true? Is my derivation below correct? Is there a different reason why this is true? Are there other nontrivial functions $g(x,y)$ for which 
$$
\int \int f(x)f(y)g(x,y)\,dxdy \leq 0?
$$
What properties should I expect of these functions $g(x,y)$? The Derivation Let $H:\mathbb{R}\to\mathbb{R}$ be the Heaviside function, so $H(x) = 1$
for $x>0$, and $H(x) = 0$ for $x\leq 0$.  I was interested in the convolution $H\ast f(x)$ defined by 
$$
H\ast f(x) = \int f(y) H(x-y)\,dy = \int_{-\infty}^x f(y)\,dy.
$$
Notice that since $f$ has support in $[-R,R]$ and $\int f = 0$, 
$H\ast f$ also has support in $[-R,R]$. Now we're prepared to start the derivation of the inequality, beginning
with the simple observation
$$
0 \leq \int |H\ast f(x)|^2\,dx = \int_{-R}^R |H\ast f(x)|^2\,dx.
$$
First expand the square and the convolution, and then
rearrange the order of the integrals:
\begin{align*}
\int_{-R}^R |H\ast f(x)|^2\,dx 
&= \int_{-R}^R \left(\int_{-R}^R f(y)H(x-y)\,dy\right) \left(\int_{-R}^R f(z)H(x-z)\,dz\right) \,dx \\
&= \int_{-R}^R\int_{-R}^R f(y)f(z) \left(\int_{-R}^R H(x-y)H(x-z)\,dx\right)\,dydz
\end{align*}
The integrand $H(x-y)H(x-z)$ is $1$ when both $x>y$ and $x>z$, and $0$ otherwise.  Thus the integral comes out to $\min\{R-y,R-z\}$. We plug this
back into the integral, and use again the fact that $\int f = 0$:
\begin{align*}
\int_{-R}^R\int_{-R}^R f(y)f(z) \min\{R-y,R-z\} \,dydz
&= \int_{-R}^R \int_{-R}^R f(y)f(z)(\min\{-y,-z\} - R)\,dydz
\\&= \int_{-R}^R\int_{-R}^R f(y)f(z)\min\{-y,-z\}\,dydz.
\end{align*}
Now split up the domain according to which of $-y$ or $-z$ is smaller:
\begin{align*}
\int_{-R}^R\int_{-R}^R f(y)f(z)\min\{-y,-z\}\,dydz
&= -\int_{y=-R}^R f(y)\left(y\int_{z=-R}^y f(z)\,dz + \int_{z=y}^R zf(z)\,dz\right)\,dy. 
\end{align*}
Since $\int_{-R}^R f(z)\,dz = 0$, $\int_{-R}^yf(z)\,dz = -\int_y^R f(z)\,dz$, so we can combine the integrals to conclude that 
\begin{align*}
\int |H\ast f(x)|^2\,dx &= \int_{-R}^R f(y) \int_y^R f(z) (y-z)\,dz\,dy\\
&=  - \int_{-R}^R f(y) \int_y^R f(z) |y-z|\,dz\,dy 
\end{align*}
To get to the integral above, swap the names of the dummy variables and
then swap the order of the integrals:
\begin{align*}
\int |H\ast f(x)|^2\,dx &= -\int_{-R}^R f(z) \int_z^R f(y) |z-y|\,dy\,dz\\
&= -\int_{-R}^R f(y) \int_{-R}^y f(z) |z-y|\,dy\,dz.
\end{align*}
In conclusion, adding both of these formulas together, we obtain
$$
0\leq 2\int |H\ast f(x)|^2\,dx = -\int\int f(y)f(z)|y-z|\,dy\,dz.
$$
The derivation is quite long so there's a good chance I've made a mistake.","['inequality', 'real-analysis', 'integration']"
1302562,Proving that the pullback map commutes with the exterior derivative,"I'm trying to prove that the pullback map $\phi^{\ast}$ induced by a map $\phi:M\rightarrow N$ commutes with the exterior derivative. Here is my attempt so far: Let $\omega\;\in\Omega^{r}(N)$ and let $\phi :M\rightarrow N$. Also, let $\mathbf{v}\;\in T_{p}M$. Then, using that $df(\mathbf{v})=\mathbf{v}(f)$ and also, that $(\phi^{\ast}\omega)(\mathbf{v})=\omega (\phi_{\ast}\mathbf{v})$ where $\phi_{\ast}$ is the pushforward map induced by $\phi$, we have that $$\left(\phi^{\ast}df\right)(\mathbf{v})=df(\phi_{\ast}\mathbf{v})=(\phi_{\ast}\mathbf{v})(f)=\mathbf{v}(\phi^{\ast}f)=\left(d(\phi^{\ast}f)\right)(\mathbf{v})$$ Hence, as $\mathbf{v}\;\in T_{p}M$ was chosen arbitrarily, this implies that $$\phi^{\ast}df=d(\phi^{\ast}f).$$ Given this, we now consider an r-form $\omega\;\in\Omega^{r}(N)$ and expand in a coordinate basis $\lbrace dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}}\rbrace$ for $\Omega^{r}(N)$ such that $$\omega = f(x)dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}}$$ It then follows that $$d\omega=df\wedge dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}}$$ and also, $$\phi^{\ast}\omega = \phi^{\ast}(f(x)dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}})=(\phi^{\ast}f)\phi^{\ast}(dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}})$$ Therefore, $$\phi^{\ast}d\omega = \phi^{\ast}(df\wedge dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}})=\phi^{\ast}df\wedge\phi^{\ast}(dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}})\\=d(\phi^{\ast}f)\wedge \phi^{\ast}(dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}})\qquad\qquad\qquad\qquad\quad\,\,\\=d((\phi^{\ast}f)\;\phi^{\ast}(dx^{\mu_{1}}\wedge\cdots\wedge dx^{\mu_{r}}))\qquad\qquad\qquad\qquad\quad\,\,\\=d(\phi^{\ast}\omega)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad\;$$ and so $\phi^{\ast}d\omega=d(\phi^{\ast}\omega)$. Would this be correct at all?","['differential-geometry', 'smooth-manifolds', 'differential-forms']"
1302564,upper bound of a differential equation solution,"Let $A(t)$ be a bounded singular values matrix that is function of time, and $f(t)$ an $L^\infty$ function of time. And consider the ODE
$$
\dot x = A(t) x + f(t)
$$
How we can describe qualitatively  the magnitude that the euclidean norm $\| x \|$ reach in finite time $T$? In other words, I wish to compute the upper bound of the euclidean norm a a time $T$ of the solution of an ODE without solving it. There is some related result from the Qualitative Theory of ODE's??","['inequality', 'ordinary-differential-equations', 'functional-analysis', 'integration']"
1302577,Hitting time is a stopping time,"Can somebody help me proving that the following hitting time is a stopping time?
Let $\{X_t\}_{t\ge 0}$ be a real-valued, right-continuous process, adapted to a filtration $\mathfrak{F}$ which satisfies the usual conditions. Then the hitting time $$\tau(\omega):=\inf\{t\ge 0: X_t(\omega)\ge a\}$$ is a stopping time ($a\in\mathbb{R}$ is fixed in advance). EDIT: @AlexR, you're right, I should be a bit more precise.
The $\textit{usual conditions}$ concerning the filtration $\mathfrak{F}$ imply that it each $\sigma$-algebra in this filtration is complete (i.e. all $\mathbb{P}$-null sets are contained in it). Moreover, the filtration is right-continuous, i.e. for $t\ge 0$, it holds $\mathfrak{F}_t=\bigcap_{s>t}\mathfrak{F}_s$. My thoughts so far: Let $t\ge 0$ and assume $\tau(\omega)\ge t$. This is equivalent to $X_s(\omega)<a$ for all $s\in[0,t)$. By right-continuity of $X$, we know that $X_s=\lim_{u\downarrow s}X_u$ for all $s\ge 0$. Hence, $X_s(\omega)<a$ is equivalent to the existence of some $\varepsilon>0$ such that $X_u(\omega)<a$ for all $u\in[s,s+\varepsilon]$; this holds for all $s\in[0,t)$, as mentioned above. Thus, we conclude:
$$\{\tau<t\}=\bigcup_{s\in[0,t)}\bigcap_{\varepsilon>0}\bigcup_{s\in[t,t+\varepsilon]}\{X_s\ge a\}.$$
Here, I get stuck: Why is this set in $\mathfrak{F}_t$ (this would be sufficient due to the usual conditions)?
Does someone see why this is the case or does someone have another ansatz to this problem?","['probability-theory', 'stochastic-processes']"
1302587,Solving the equation $ f^{-1}(x)=f(x)$,"I attempted to solve the equation given in the title for the function; $$f: \mathbb R_{++} \to\mathbb R_{++}; \quad f(x)=x^2(x+2)$$ I understand that the problem is equivalent to solving $f(f(x))=x$
but since this seemed like too much work, I had a look at the solution and it stated that; $$ f^{-1}(x)=f(x) \Longrightarrow  f(x)=x$$ I don't understand why this is the case. Can someone please explain this? Thanks",['functions']
1302602,First order differential equation: did i solve this equation right,"So i'm trying to solve: $$x^2\frac{dy}{dx} + 2xy = y^3$$ I'm given this differential equation, that Bernoulli equation:
  $$\frac{dy}{dx} + p(x)y = q(x)y^{n} $$ I think i've solved it and got 
$$ u = \frac{2}{5x} +Cx^4$$ I'm just not sure i am right i will show you how i get there but firstly... This was part of another question which i've already solved Show that if $y$ is the solution of the above Bernoulli differential
  equation and $u = y^{1−n}$, then $u$ satisfies the linear differential
  equation: $$\frac{du}{dx} + (n-1)p(x)u = (1-n)q(x)$$ Applying the chain rule to $u = y^{1-n}$ we obtain that 
\begin{align}
\frac{d u}{dx}(x)&= \frac{du}{dy}\cdot\frac{dy}{dx}\\
&= (1-n)y^{-n}\cdot\frac{dy}{dx}
\end{align}
Futhermore using the Bernoulli equation we have 
$$
\frac{dy}{dx}=q(x)y^n-p(x)y
$$
and 
\begin{align}
\frac{d u}{dx}&= (1-n)y^{-n}\cdot\frac{dy}{dx}\\
&=(1-n)y^{-n}\cdot q(x)y^n - (1-n)y^{-n}\cdot p(x) y\\
&=(1-n)q(x) -(1-n)p(x)y^{1-n}\\
&=(1-n)q(x) -(1-n)p(x)u
\end{align} Hence U satisfies the equation
$$
\frac{du}{dx}+(1-n)p(x)u = (1-n)q(x)
$$ $$x^2\frac{dy}{dx} + 2xy = y^3$$
Divide both sides by $x^2$ $$\frac{dy}{dx} + \frac{2}{x}y = x^{-2} y^3$$ Consider
$$\frac{du}{dx} + (n-1)p(x)u = (1-n)q(x)$$ We know that n = 3 1- n = 1-3 = -2 p(x) = $ \frac{2}{x}$ q(x) = $x^{-2}$ u = $y^{1-3} = y^{-2}$ Subbing these in...
$$      
\frac{du}{dx} + (-2)\frac{2}{x}u = (-2)x^{-2}
$$ $$
\frac{du}{dx} + \left(-\frac{4}{x}\right)u = (-2)x^{-2}
$$ So... 
$$ \text{integrating  factor} = e^{\int p(x) \, dx} $$
 - p(x) dx = $-\frac{4}{x}$ $$ -4 \int \frac{1}{x} = -4log(x) = log (x^{-4}) $$
$$ \text{integrating  factor} = e^{log (x^{-4})}= x^{-4} = \frac{1}{x^4}$$ So multiply this to the equation $$\frac{1}{x^4}\frac{du}{dx} + \left(\frac{-4}{x^5} \right)u = \frac{-2}{x^6}$$ So we want to solve $$ \frac{d}{dx}\frac{1}{x^4}u = \frac{-2}{x^6}  $$
$$ \int \frac{d}{dx}\frac{1}{x^4}u = \int \frac{-2}{x^6}  $$
$$ \frac{1}{x^4}u = -2\int \frac{1}{x^6}  $$
$$ \frac{1}{x^4}u = -2\frac{1}{-5x^5} + c  $$
$$ \frac{1}{x^4}u = \frac{2}{5x^5} + c $$
$$ \therefore u= \frac{2}{5x} + cx^{4} $$ is this fine? Or do i need to somehow equate this y or sub $u=y^{1-n}$ As $$u=y^{-2}$$ $$\frac{1}{y^2}= \frac{2}{5x} + cx^{4} $$
$$y^2= \frac{5x}{2} + \frac{1}{cx^{4}} $$
$$y= \sqrt{\frac{5x}{2} + \frac{1}{cx^{4}}} $$","['calculus', 'ordinary-differential-equations']"
1302635,A finite group which has a unique subgroup of order $d$ for each $d\mid n$.,"Problem Suppose G is a finite group of order $n$ which has a unique subgroup of order $d$ for each $d\mid n$. Prove that $G$ must be a cyclic group. My idea:   I try to prove it by induction. Let $p|n$ be a prime. Then by condition, there exists a unique subgroup $H$ of order $n/p$. Since $|gHg^{-1}|=|H|$, we must have $gHg^{-1}=H$ by the uniqueness part of the condition. So, H is a normal subgroup.
Now, $|G/H|=p$ and thus $G/H=\langle x\rangle$ where $x^p \in H$. However, I cannot continue. My another idea is that first consider the case when $|G|$ is a power of some prime $p$. But, it still doesn't work.","['abstract-algebra', 'group-theory', 'finite-groups', 'cyclic-groups']"
1302659,Prove by combinatorial method that $ \frac{(2m)! \cdot (2n)!}{(m)! \cdot (n)! \cdot (m+n)!} $ is an integer [duplicate],"This question already has answers here : Prove that for all non-negative integers $m,n$, $\frac{(2m)!(2n)!}{m!n!(m + n)!}$ is an integer. (2 answers) Closed 9 years ago . Prove that $$ \dfrac{(2m)! \cdot (2n)!}{(m)! \cdot (n)! \cdot (m+n)!} $$ is a positive integer, where $(m,n) \in \mathbb{Z^{+}}$ I have already solved it using Legendre's Formula which states that $$e_{p}(n)=\sum_{i=1}^{\infty} \bigg\lfloor \dfrac{n}{p^{i}} \bigg\rfloor$$ where $e_{p}(n)$ is the exponent of a prime $p$ in $n!$ . For the problem it was sufficient to show that $$ e_{p}(2m) + e_{p}(2n) \ge e_{p}(m) + e_{p}(n) + e_{p}(m+n) $$ which I can show using the properties of floor function. However, I'm seeking a combinatorial approach to this problem. For example, using basic combinatorics, I can show that the number of ways to divide $A$ objects into $k$ persons such that the $i^{th}$ person receives $a_{i}$ objects is $$ \dfrac{A!}{\displaystyle\prod_{i=1}^{k}{(a_{i})!}} = \dfrac{\left(\displaystyle\sum_{i=1}^k (a_{i})\right)!}{\displaystyle\prod_{i=1}^{k}{(a_{i})!}} $$ here, the set $\{a_{i}\}_{i=1}^k$ is exhaustive, i.e, $ A = \displaystyle\sum_{i=1}^k a_{i} $ . Using this, I can show the following numbers to be integer $ \dfrac{(2m)! \cdot (2n)!}{[(m)!]^{2} \cdot [(n)!]^{2} } $ $  \dfrac{(2m)! \cdot (2n)!}{(m-n)! \cdot [(n)!]^2 \cdot (m+n)!} $ ; if $m \geq n$ $  \dfrac{(2m)! \cdot (2n)!}{(n-m)! \cdot [(m)!]^2 \cdot (m+n)!} $ ; if $n \geq m$ However, I can't seem to find a way to tackle this problem using my approach. Edit: I'm specifically asking for an answer using my combinatorics approach as I've already solved it using the answer given in the other question. Any help will be appreciated. Thanks.","['number-theory', 'algebra-precalculus', 'elementary-number-theory', 'combinatorics', 'factorial']"
1302681,Stokes' theorem: Induced orientation on the boundary of a manifold,"The Question Let $K = \{(x,y,z) \in \mathbb{R}^3 : x^2 + y^2 + z^2 \geq 1\}$, where $K$ is oriented via the canonical volume form on $\mathbb{R}^3$: $dx \wedge dy \wedge dz$. Let $\mathbb{S}^2$ be the unit sphere, considered as the boundary of $K$, with the orientation on $\partial K$ given by the induced orientation from $K$. Define the canonical inclusion map $j: \mathbb{S}^2 \rightarrow \mathbb{R}^3$ and the 2-form on $\mathbb{R}^3$ $\omega := (2z -x^2 - xy) dx \wedge dy - dy \wedge dz +dz \wedge dx$ Calculate \begin{align}
\int\limits_{\mathbb{S}^2} j^* \omega
\end{align} where $j^*$ denotes the pullback of $j$ in the usual way. Attempt at a solution Using Stokes' theorem, we have \begin{align}
\int\limits_{\mathbb{S}^2} j^* \omega &= \int\limits_{\mathbb{R}^3 \backslash K} d\omega\\
&= 4 \pi \int\limits_0^1 dr\,2 r^2\\
&= \frac{8\pi}{3}\\
\end{align} The difficulty Is this correct or should the answer be $-8\pi/3$? In class we've said that for manifolds with odd dimension we will adopt the convention that the boundary will have the opposite orientation as the one induced by a volume form on the manifold. To me this means that we pick up a minus sign in this case, because by integrating $r$ from 0 to 1 we are adopting the orientation given by the volume form on $\mathbb{R}^3$. Is this true? It also seems that, using basic calculus reasoning, the result of the integral should differ by a sign change depending on if we view $\mathbb{S}^2$ as the boundary of $K$ or as the boundary of $\mathbb{R}^3 \backslash K$ (because the definition of ""outwards"" would differ for the normal vectors). Is this true? If so, how is it imposed formally? What does this mean for my question in the preceding paragraph? I'm very much interested in the ""why"" for a general case, not just the solution to this particular problem.","['orientation', 'differential-geometry', 'manifolds-with-boundary']"
1302707,For which values of $\theta$ does this equation $x^{\cos\theta} +y^{\sin\theta }=1$ have solutions in integers?,"For which values of $\theta$ does this equation $$x^{\cos\theta} 
+y^{\sin\theta}=1$$ have solutions in integers ? Note : $x, y$ integers, $\theta$ is real number. Thank you for your help.","['integers', 'diophantine-equations', 'elementary-number-theory', 'trigonometry']"
1302721,Is there a finite abelian group $G$ such that $\textrm{Aut}(G)$ is abelian but $G$ is not cyclic?,Is there an example in which $G$ is a finite abelian group and $\textrm{Aut}(G)$ is abelian but $G$ not cyclic?,"['group-theory', 'examples-counterexamples']"
1302774,Expectation of $\mathbb{E}(X^{k+1})$,"I have difficulties with an old exam problem : Let $X$ be a positive random variable defined on a probability space $(\Omega, \mathcal{F}, \mathbf{P})$. 
  Show that $$\int_0^\infty t^k \mathbf{P}(X\geq t) dt = \int_0^\infty \int_{\Omega} t^k\int_{\{X(\omega)\geq t\}}dt d\mathbf{P}(\omega)$$
  Infer from this the integral expression of $\mathbb{E}(X^{k+1})$ (where $\mathbb{E}$ is the expectation) We have Fubini theorem, which we can apply to a $\mathbb{B}(\mathbb{R})\otimes\mathcal{F}$-measurable function because the Lebesgue measure is $\sigma$-finite and $\mathbf{P}$ is also $\sigma$-finite because it is a probability. I think we can write $\mathbf{P}(X\geq t)$ as $\int_{\{ X(w)\geq t\}} d\mathbf{P}(\omega)$ but I don't know how to proceed next. Especially I don't see how to introduce the $\int_{\Omega}$. Edit From the comments, there must be an error in the description of the exam problem. It should have been the following : Let $X$ be a positive random variable defined on a probability space $(\Omega, \mathcal{F}, \mathbf{P})$. 
  Show that $$\int_0^\infty t^k \mathbf{P}(X\geq t) dt = \int_0^\infty \int_{\Omega} t^k\mathbf{1}_{\{X(\omega)\geq t\}}dt d\mathbf{P}(\omega)$$
  Where $\mathbf{1}_{\{X(\omega)\geq t\}}$ is the characteristic function of $\{ X(\omega)\geq t\}$ Infer from this the integral expression of $\mathbb{E}(X^{k+1})$ (where $\mathbb{E}$ is the expectation)","['probability-theory', 'measure-theory', 'integration']"
1302794,Anagram with condition on last letter,"How many ways can ""computer"" be arranged with a vowel as last alphabet?
Isn't it $7! \times 3 $? since there are 3 vowels. $3$ (e,o,u) $ \times 7!$(number of arrangement without one of vowel). Shouldn't it be right?","['discrete-mathematics', 'permutations']"
1302796,Does naturality for characteristic classes imply the classifying space is universal for them?,"Let $G$ be a Lie group, $\mathfrak g$ its Lie algebra, $K$ its maximal compact subgroup. To every flat $G$-bundle $P$ over a smooth manifold $M$ I can associate a homomorphism $w_P: H^*(\mathfrak g, K) \to H^*(M;\Bbb R)$. This is called the characteristic homomorphism of $P$. These are natural under pullbacks in the sense that if we have a smooth map $f: M_1 \to M_2$, then $w_{f^*P_2} = f^*w_{P_2}$. ($H^*(\mathfrak g, K)$ is the Lie algebra cohomology of $\mathfrak g$ relative to the subgroup $K$ - you do the same thing as normal - coefficients in the trivial module $\Bbb R$ - but restrict to cochains that vanish on $\mathfrak k$ and are invariant under the adjoint action of $K$. If $K$ is connected this is just $H^*(\mathfrak g, \mathfrak k)$. The homomorphism is defined as follows: let $P$ be a flat $G$-bundle over $M$; factor the projection as $P \to P/K \to M$. The connection form $\omega \in \Omega^1(P;\mathfrak g)$ defines a chain map $C^*(\mathfrak g) \to \Omega^*(P;\Bbb R)$ (defined for simplicity on 1-chains; extend the same idea in general) $\omega(\alpha)(X) = \alpha(\omega(X))$. Our restrictions on the cochains means this descends to a map $C^*(\mathfrak g,K) \to \Omega^*(P/K;\Bbb R)$. Composing now with the map induced by the homotopy equivalence $H^*(P/K;\Bbb R) \to H^*(M;\Bbb R)$ defines our characteristic homomorphism $w_P$. This process is described in pages 66-69 of Morita's ""Geometry of Characteristic Classes"". Now flat bundles are classified up to isomorphism by the holonomy map $\{\pi_1(M) \to G\}/\text{conjugacy}$ in a very down-to-earth sense: if $P$ has holonomy homomorphism $\rho$, then $P \cong (\tilde M \times G)/\pi_1(M)$, where if we realize the universal cover $\tilde M$ by $$\tilde M = \{[\ell] \mid \ell: [0,1] \to M, \ell(1) = p_0\},$$ $\pi_1(M)$ acts by $\alpha \cdot ([\ell],g) = ([\ell]\alpha, \rho(\alpha)^{-1}g)$. This action preserves the trivial connection on $\tilde M \times G$, so this gives us a flat $G$-bundle over $M$. Because our flat bundles are classified by homomorphisms $\pi_1(M) \to G$, they're classified by (homotopy classes of) maps $M \to BG^\delta = K(G,1)$, where $G^\delta$ is $G$ with the discrete topology. In the usual theory of characteristic classes, we now demonstrate a universal bundle $EG \to BG$ that every other bundle is a pullback of, and thereby universal characteristic classes. But in our new world, $BG^\delta$ is not even close to being a manifold. We're not going to be able to write down any differential forms on it, so it's not going to make sense to talk about a flat $G$-bundle on $BG^\delta$. Is there still a universal characteristic homomorphism $w: H^*(\mathfrak g, K) \to H^*(BG^\delta;\Bbb R)$ that pulls back to the individual characteristic homomorphisms? Do I get it for free somehow because $w$ is natural under smooth maps, and is this/is there a general phenomenon that I can appeal to: I have some sort of universality automatically coming from naturality? (If this is not a general phenomenon, one thing I think might work is to take Sullivan's idea, work with a simplicial model of $BG^\delta$, and define smooth forms on it by doing so cell-by-cell and demanding they agree on restrictions. Maybe one can still make a theory of flat $G$-bundles in this context, perform the same classification as above, and write down a universal bundle on $BG^\delta$. I haven't thought carefully about this. Even if so, it'd be nice if there was something more general than ""I can fiddle and make it work"" going on here.)","['principal-bundles', 'differential-geometry', 'algebraic-topology', 'characteristic-classes']"
1302817,An infinite prime can ramify right? (So what is Neukirch talking about?),"I have been under the impression for several years that if $L/K$ is an extension of number fields, then an infinite place of $K$ is said to ramify in $L$ if it comes from a real embedding of $K$ which extends to complex embeddings of $L$ . I am currently reading Neukirch's magisterial Algebraic Number Theory and he seems to be saying something inconsistent with this on p. 184. He writes: ... This convention suggests that we consider $e$ as being an infinite prime number , and the extension $\mathbb{C}\mid \mathbb{R}$ as being unramified with inertia degree 2... ... If $L\mid K$ is a finite extension of $K$ , then we denote the primes of $L$ by $\mathfrak{P}$ and write $\mathfrak{P}\mid\mathfrak{p}$ to signify that the valuations in the class $\mathfrak{P}$ , when restricted to $K$ , give those of $\mathfrak{p}$ . In the case of an infinite prime $\mathfrak{P}$ , we define the inertia degree , resp. the ramification index , by $$ f_{\mathfrak{P}\mid\mathfrak{p}} = [L_\mathfrak{P}:K_\mathfrak{p}],\text{ resp. } e_{\mathfrak{P}\mid\mathfrak{p} = 1}$$ Isn't he saying that an infinite prime is always unramified then? (And either inert or split?) If this is what he's saying, then was my previous understanding wrong? Or is Neukirch using a different convention than everybody else? If so, what's the thinking behind the different conventions? If on the other hand there is no conflict between Neukirch and my previous understanding, then what am I misunderstanding about what he's saying? Basically, what's going on around here? Thanks in advance for any help you can offer.","['field-theory', 'number-theory', 'valuation-theory', 'algebraic-number-theory']"
1302823,the number of copy of 6-cycles in petersen graph,the number of copy of  6-cycles in petersen graph.I know that Petersen graph has ten copy of 6-cycles but I can't prove it.,"['graph-theory', 'combinatorics']"
1302830,Looking for a non trivial homomorphism I,"Is there a non trivial homomorphism $f: SU(2) \to O(2)$? Is there a concrete description of $Hom(SU(2), O(2))$?","['abstract-algebra', 'lie-groups']"
1302858,"Does this sum converge, is my solution good?","$$ \sum_{n=1}^\infty \frac{\sin(n)^{7}}{(n^{7}+1)^{1/2}} $$ I would say that it doesn't converge, cause I would  write this as:
$$  $$ $$ \frac{\sin(n)^{7}}{(n^{7})^{1/2}} $$ when  $$ \lim_{n\to \infty} $$
then I would write this as: $$ \sum_{n=1}^\infty \frac{\sin(n)^{7}}{(n^{7})*n^{1/2}}$$
and then I would say that 
$$ \sum_{n=1}^\infty \frac{\sin(n)^{7}}{(n^{7})^{1/2}} $$ converges , but that the 
$$ \sum_{n=1}^\infty \frac{1}{n^{1/2}} $$ doesn't converge, so overall sum doesn't converge.","['sequences-and-series', 'divergent-series']"
1302877,Computing the cotangent complex: what's the ring?,"As far as I understand, deformation theory of schemes may be calculated via the cotangent complex. I have read that in general the cotangent complex may be difficult to compute . However, I have a much more naive question about it. Leafing through the basic references about the cotangent complex (by Quillen and Illusie), I only find rings. An affine schemes is the prime spectrum of a ring, so I imagine that the cotangent complex of an affine scheme would use this ring. But then affine schemes don't admit any deformations, so one doesn't need the cotangent complex to calculate deformations of affine schemes. Is there any general method of calculating the cotangent complex of a (quasi-)projective scheme? Does one calculate the cotangent complex by starting from the affine charts and then trying to glue the cotangent complexes?","['algebraic-geometry', 'schemes', 'deformation-theory', 'commutative-algebra']"
1302878,Why is cross product not commutative?,"Why, conceptually, is the cross product not commutative? Obviously I could simply take a look at the formula for computing cross product from vector components to prove this, but I'm interested in why it makes logical sense for the resultant vector to be either going in the negative or positive direction depending on the order of the cross operation. I don't have any formal experience in linear algebra, so I would appreciate if an answer would take that into account (I'm merely learning vectors as part of a 3D game math education).","['vectors', 'linear-algebra', 'cross-product']"
1302885,Hypersphere central angle,"For a sphere, the relationship between steradian of a patch on the surface, and the central angle of the cone subtending that patch, is given by What is the equivalent for an arbitrary sphere of N dimensions?","['geometry', 'differential-geometry']"
1302904,Non trivial homomorphism from $SU(2)$ to the diffeomorphism group of the circle,"Is there a non trivial homomorphism $f: SU(2) \to \operatorname{Diff}(S^1)$? (From the comments) By a previous question , we know that there is no nontrivial homomorphism $SU(2) \to O(2)$. Since $O(2)$ is a subgroup of $\operatorname{Diff}(S^1)$ (rotations are diffeomorphisms), maybe there is a nontrivial map in the larger group.","['abstract-algebra', 'lie-groups', 'geometric-topology']"
1302906,Prove that an increasing and surjective function is continuous.,"If $f:[a,b]\rightarrow [f(a),f(b)]$ is increasing and surjective, prove that it is continuous. Fix $c \in (a,b)$. Take $\epsilon >0$. We then wish to find the set of $x$ such that $|f(x)-f(c)|<\epsilon$ by definition of continuity. That's as far as I got and I don't know how to proceed. Any suggestions/proofs?","['continuity', 'real-analysis']"
1302908,The Intersection of Equivalence Relations which cover a relation,"Exercise A.3 From John Lee( Topological Manifolds) Let $R \subset X \times X$ be any relation on $X$, and define ~ to be the intersecction of all equivalence relations in $X \times X$ that contain $R$. (a) Show that ~ is an equivalence relation.
(b) Show that $x$~$y$ if and only if at least one of the following statements is true: $x=y$, or $x R' y$ or there is a finite sequence of elements $z_1,z_2,\cdots,z_n \in X$ such that $x R' z_1 R' \cdots R' z_n R' y$, where $x R' y$ means  $x R y$ or  $y R x$ I proved most part of the problem but I was stuck on one direction (the third part of $\rightarrow$ ). Is there any good way to prove that if $(x,y) \not\in R'$ $\&$ $(x,y) \in $ ~ then $\exists z_1, z_2, \cdots z_n$ such that  $x R' z_1 R' \cdots R' z_n R' y$?
I don't know how to show that after finite steps, we can 'link' $x$ to $y$.","['elementary-set-theory', 'general-topology']"
1302918,Density Function of Random Variable Related to Brownian Motion,"Above is my question. I've done the first two parts, that's no problem. I'm stuck on finding the density of the rv $R = W_1 / M$. I have got as far as
$$g(x,y) = \frac{\partial^2}{\partial x \partial y} \Bbb P(M \le x, W_1 \le y) = \frac{2(2x-y)}{\sqrt{2\pi}}\exp \left(-\frac{1}{2}(2x - y)^2 \right)$$
for $x \ge y$ and $g(x,y) = 0$ for $x \le y$. I also have
$$ \Bbb P(R \ge r) = \Bbb P (W_1 \ge rM),$$
and so I'm now interested in evaluating a probability of the form ""$\Bbb P(X \ge Y)$"" for rvs $X = W_1$ and $Y = rM$. My attempt is then
$$\Bbb P(W_1 \le rM) = \int_{y < x} \frac{1}{r} g\left(\frac{x}{r},y\right) d(x,y),$$
where the $1/r$ factors come from the fact that $Y = rM$, not just $M$. My issue is that this then gives $1$, for each $r$. So my density function is $1$ everywhere... which is of course not right (eg doesn't integrate to $1$). Of course, I only want to consider $r < 1$ as the probability is $0$ for $r > 1$, by definition of the two rvs. Also, I am concerned with the $1/r$ factors... when $r$ could be $0$. Any advice would be most appreciated. Thanks. PS - This is a probability question - not a finance question - so please don't suggest migrating it to quant.SE - thanks! :)","['probability-theory', 'brownian-motion', 'probability-distributions', 'stochastic-processes']"
1302928,"How to evalute: $\int_0^1 \frac{e^{-ax}}{ax} -\frac{e^{-abx}}{1- e^{-ax}}((1-x)\cos (\pi x) + \frac{3}{\pi} \sin(\pi x)) dx$ and $a, b >0$","How to evalute: $$\int_0^1 \left[ \frac{e^{-ax}}{ax} -\frac{e^{-abx}}{1- e^{-ax}}\left((1-x)\cos (\pi x) + \frac{3}{\pi} \sin(\pi x)\right) \right] dx$$ and $a, b >0$","['analysis', 'calculus']"
1302949,How many ways to select $k$ vertices of an $n$-gon?,"I have a regular $n$-gon, of which I have to select $k$ vertices. The selections must be rotationally distinct; two selections would be considered equivalent if one is a rotation of the other. For example, if I have a square, and I want to select 2 vertices, there are only 2 possible ways to do that according to the constraint. One is ""x - x -"", another is ""x x - -"". If we denote the function by $CR(n,k)$, then these are the trivial cases: $CR(n, 1) = 1$ $CR(n, 2) = \lfloor\frac{n}{2}\rfloor$ $CR(n, k) = CR(n, n - k)$ I am quite short of ideas on how to find the recurrence or closed formula of this problem, or if this problem has any closed form / recurrence solution at all. Any help with a bit detailed walk through would be much appreciated.","['group-theory', 'combinatorics']"
1302984,In-Depth Explanation of How to Do Mathematical Induction Over the Set $\mathbb{R}$ of All Real Numbers?,"I've seen in the answers to a few different questions here on the Mathematics Stack Exchange that one can clearly do mathematical induction over the set $\mathbb{R}$ of all real numbers.  I am, however, having quite a difficult time understanding how the methods described in both those questions' answers and some reference materials to which they link.  In particular,  I can't seem to figure out exactly how the techniques described therein parallel the methods codified in the axiom of induction for use when doing mathematical induction over the set $\mathbb{N}$ of all natural numbers. If somebody would be so kind as to provide me with a more detailed explanation of how to do mathematical induction over the set $\mathbb{R}$ of all real numbers within about the next day or so, then I would be very grateful!  The answer should be understandable by any beginning calculus student who also has a rudimentary understanding of set theory and mathematical logic.  I've provided links to both the relevant questions and whatever reference material mentioned in them that seemed like good leads when I found them no matter how inscrutable they might have been at the time. Questions About Induction Over the Real Numbers: Induction on Real Numbers Is it possible to use mathematical induction to prove a statement concerning all real numbers, not necessarily just the integers? [duplicate] Extending a theorem true over the integers to reals and complex numbers Question-Derived Reference Material: 'The Instructor's Guide to Real Induction' by Pete L. Clark P. S.:  I also have the following follow-up questions: Version of the Axiom of Induction for Real Induction? Real Induction Over Multiple Variables?","['real-numbers', 'real-analysis', 'induction']"
1302987,Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent,can you find a Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent?,"['abstract-algebra', 'group-theory', 'infinite-groups']"
1302989,why $\tan x = \frac{\sin x}{\cos x}$? and not $\tan x$ = opposite/adjacent?,"we know that $\tan x =\left(\frac{\text{opposite}}{\text{adjacent}}\right)$, but sometimes I see that $\tan x = (\frac{\sin x}{\cos x})$, is that the same thing or why it is different sometimes? cause when $\tan x =\left(\frac{\text{opposite}}{\text{adjacent}}\right)$: $\tan x = \frac{1}{2}$ - for example but sometimes is: $\tan x = \frac{1}{5}$ or $ \frac{2}{5}$ - if hypotenuse is $= 5$ why is that?",['trigonometry']
1303017,"On a proof of the fact ""A projective nonsingular curve minus a finite number of points is affine""","In This notse , Vakil gives a proof of the theorem stated in the title. (page 5). In the proof he made use of a section s of $\mathcal{O}_C(kp)$ that has only one zero of order k at p. However such a section doesn't seem to be exist. In fact, any such section s(considered as element of K(x)) must have poles at some other points, and therefor can't be a section of $\mathcal{O}_C(kp)$ since $div(s) + kp \ngtr 0$ . I am correct?",['algebraic-geometry']
1303044,Axiomatic definition of sin and cos?,"I look for possiblity to define sin / cos through algebraic relations without involving power series, integrals, differential equation and geometric intuition. Is it possible to define sin and cos through some axioms? Like: $$\sin 0 = 0, \cos 0 = 1$$ $$\sin \pi/2 = 1, \cos \pi/2 = 0$$ $$\sin^2 x + \cos^2 x = 1$$ $$\sin(x+2\pi n) = \sin x, \cos(x+2\pi n) = \cos x$$ $$\sin(-x)=-\sin x, \cos(-x) = \cos x \text{ for } x \in [-\pi;0]$$ $$\sin(x+y)=\sin x \cos y + \sin y \cos x$$ and be able to prove trigonometric school equations? What additions are required to prove continuity and uniqueness of such functions and analysis properties like: $$\lim_{x \to 0}\frac{\sin x}{x} = 0$$ or $$\sin ' x = \cos x$$ or $$\int \frac{dx}{\sqrt {1-x^2}} = \arcsin x$$ PS In Walter Rudin book ""Principles of Mathematical analysis"" sin and cos introduced through power series. In Solomon Feferman book ""The Number Systems: Foundations of Algebra and Analysis"" I see system derived from integral definition.","['axioms', 'trigonometry']"
1303051,Divergence theorem for a second order tensor,"I want to integrate by part the following integral in cylindrical coordinates
$$\int \vec{r} \times (\nabla \cdot \overline{T}) ~d^3\vec{r} $$
where $\overline{T}$ is a second order symmetric tensor and $\times$ is the vectorial product. Once I integrated by part I want to use the divergence theorem to obtain a surface integral. It works very well in cartesian coordinates but I cannot manage to do it properly in cylindrical. In cylindrical coordinates $\hat{\boldsymbol{\rho}},\hat{\boldsymbol{\theta}},\hat{\mathbf{z}}$, \begin{align}&\nabla \cdot \overline{T}= \left[ \frac{1}{\rho} \frac{\partial}{\partial \rho}(\rho T_{\rho\rho}) + \frac{1}{\rho} \frac{\partial T_{\theta \rho}}{\partial \theta} + \frac{\partial T_{z \rho }}{\partial z} - \frac{T_{\theta \theta}}{\rho} \right]  \hat{\boldsymbol{\rho}} + \\
&\qquad\qquad\left[ \frac{1}{\rho} \frac{\partial}{\partial \rho}(\rho T_{\rho\theta}) + \frac{1}{\rho} \frac{\partial T_{\theta\theta}}{\partial \theta} + \frac{\partial T_{z\theta}}{\partial z} + \frac{T_{\theta \rho }}{\rho} \right] \hat{\boldsymbol{\theta}} + \\
&\qquad\qquad\left[  \frac{1}{\rho} \frac{\partial}{\partial \rho}(\rho T_{\rho z}) + \frac{1}{\rho} \frac{\partial T_{\theta z}}{\partial \theta} + \frac{\partial T_{z z}}{\partial z} \right] \hat{\mathbf{z}}
\end{align} I tried a lot of different ways (5 days I am trying to do it) of doing the integration by part, but by checking numerically I know that my results is wrong. The value I obtain numerically seems to be more like ($\overline{T}$ is symmetric)
\begin{align}
\int \vec{r} \times (\nabla \cdot \overline{T}) ~d^3\vec{r}&= \oint  \vec{r} \times \left(  \hat{\boldsymbol{\rho}} \cdot \overline{T} \right) ~dS + \\
&\left( \int   T_{\rho z}     ~d^3\vec{r}  - \int_0^{\rho_\text{max}} \left[ T_{\theta z}(2\pi) - T_{\theta z}(0) \right]  ~\rho d\rho \right) \hat{\boldsymbol{\theta}} + \\
&\int_0^{\rho_\text{max}} \left[ T_{\theta\theta}(2 \pi) - T_{\theta\theta}(0) \right] \rho d\rho \hat{\mathbf{z}}
\end{align}
First, I am not sure of the result and second, I would like to know how to derive this analytically. Someone can help me? thank you very much","['vector-analysis', 'tensors', 'integration']"
1303059,I call them squares. They called them arrays. What do they mean?,"So I was in C++, and we had third graders come today to play our programs. Whilst the others just drilled them with problems, my game was subtract a square . It was fun watching them discover that numbers like ""9"" were bad positions (I never explicitly referred to squaring, I just had them multiply the number by itself.) I decided to draw something like this on the board, to show the geometric connection: The teacher called their attention that I had drawn ""arrays"" on the board, and they were still used in High School. I didn't bring it up, but I was wondering what they meant by ""arrays"". Is it an another name for square? Is it a multiplication method? Do they mean multidimensional arrays, as in programming? (If so, third grade has sure advanced since I was in school!) Something else? These were USA/Pennsylvania third graders, if that helps. Note: I know various meanings of ""array"", but I am wondering what they could possibly mean in this context, with a third grade teacher explaining to their students.","['education', 'geometry', 'terminology', 'square-numbers']"
1303106,What are the meanings of $\operatorname{trig}(x)^n$ and $\operatorname{trig}^n(x)$?,"When a trigonometric function has an exponent does that mean multiply itself or apply itself to the result recursively? For example, does $\sin(x)^2$ denote $\sin(x)\sin(x)$ or does it denote $\sin(\sin(x))$ ?  What about $\sin^2x$ ?","['notation', 'trigonometry']"
1303181,Show that a field extension $L/K$ is separable iff the trace form is non-degenerate.,Let $L$ be a finite field extension of $K$. I have the following question: Show that $L/K$ is separable if and only if the bilinear trace form $\text{Tr}_{L/K}:L\times L \to K$ is non-degenerate. A proof or reference will be great. Thank you!,"['extension-field', 'bilinear-form', 'linear-algebra']"
1303183,Are the coefficients of a vector according to a basis unique?,"If I have a vector space $V$ ( of dimension $n$ ) over real numbers such that $\{v_1,v_2...v_n\}$ is the basis for the space ( not orthogonal ). Then I can write any vector $l$ in this space as $l=\sum_i\alpha_iv_i$. Here $\alpha_1,\alpha_2...\alpha_n$ are the coefficients that define the vector  $l$ according to this basis. Can another set of coefficients $\beta_1,\beta_2...\beta_n$ give the same vector $l$ ? If the basis was orthogonal the answer would be no, but I can't prove for a non orthogonal basis.","['vector-spaces', 'linear-algebra']"
1303200,Show that $\mathbb{R}^m$ is not homeomorphic to $\mathbb{R}^n$,"Show that $\mathbb{R}^m$ is not homeomorphic to $\mathbb{R}^n$ if $m\ne n$. You may assume that $S^m$ and $S^n$ are different homotopy type if $m\ne n$. My attempt: Suppose $\mathbb{R}^m$ is homeomorphic to $\mathbb{R}^n$. Since $\mathbb{R}^m$ is homeomorphic to $A^m=S^m-\{x\}$, the sphere minus a point, then we would have $A^m$ is homeomorphic to $A^n$. Then $A^m$ and $A^n$ have the same homotopy type. Then by definition, there are functions $f:A^m\to A^n$ and $g:A^n \to A^m$ such that $g\circ f=id_m$ and $g\circ f=id_n$. But then I don't know how to related that to $S^m$ and $S^n$? I know that $S^n$ and $S^n-\{x\}$ are definitely not the same homotopy type though...","['homotopy-theory', 'algebraic-topology', 'general-topology']"
1303306,What does it mean for a prime ideal to split completely?,See here . What does it mean for a prime ideal to split completely?,"['ring-theory', 'commutative-algebra', 'number-theory', 'abstract-algebra', 'algebraic-number-theory']"
1303322,from Carathéodory Derivative definition to the derivative of $\sin(x)$,"A function $f$ is Carathéodory differentiable at $a$ if there exists a function $\phi$ which is continuous at a such that $$f(x)-f(a)=\phi(x)(x-a).$$ For $f(x) = x^n$, $\phi(x)  = x^{n-1} + ax^{n-2} + ... + a^{n-1}$. We can see that $f'(a) = \phi(a) = na^{n-1}$. We get the derivative of $x^n$ directly from this definition. For $\sin(x)$, can we do the same thing to get $\sin'(x) = \cos(x)$ without using limit? My question is raised from the booklet Calculus for Mathematicians by D.J.Bernstein, in which he defined derivative this way before introducing the concept of limits.","['calculus', 'real-analysis', 'measure-theory']"
1303359,Are these two definitions of basis equivalent?,"Lecture note definition Let $(X, \mathcal{T})$ be topological space, A $basis$ of $\mathcal{T}$ is a collection $\mathcal{B}$ of open sets satisfying the following:
For each open set $U$ and for each element $x \in U$ , there exists a set $\beta$ such that $x \in \beta$ and $\beta \subset U$ Most textbook's definition: If $X$ is a set, a basis for a topology on $X$ is a collection $\mathcal{B}$ of subsets of $X$ such that for each $x \in X$ . there is at least one basis element $B$ containing $x$ if $x$ belongs to intersection of two basis element $B_1$ and $B_2$ , then there is a basis element $B_3$ such that $B_3$ containing $x$ and is contained in the intersection of $B_1$ and $B_2$ If so, how do I prove it ?",['general-topology']
1303362,Remembering the definition of the Jacobian: any tips?,"I find it impossible to remember that the Jacobian  of $f: \mathbb R^n \to \mathbb R^m$ is $$ \begin{pmatrix}
{\partial f_1 \over \partial x_1} & {\partial f_1 \over \partial x_2} & \dots & {\partial f_1 \over \partial x_n} \\
\vdots & \dots & \vdots & \vdots\\
{\partial f_m \over \partial x_1} & \dots & \dots & {\partial f_m \over \partial x_n}
\end{pmatrix}$$ and not $$ \begin{pmatrix}
{\partial f_1 \over \partial x_1} & {\partial f_2 \over \partial x_1} & \dots & {\partial f_m \over \partial x_1} \\
\vdots & \dots & \vdots & \vdots\\
{\partial f_1 \over \partial x_n} & \dots & \dots & {\partial f_m \over \partial x_n}
\end{pmatrix}$$ How to memorise this? Is there any reason why it's defined the first
  way and not the other?","['linear-algebra', 'multivariable-calculus']"
1303385,"Analytic continuation of ln(z) counterclockwise about the unit circle,","We write ln(z) as ln(1+z-1) = ln(1+(z-1)) to utilize the familiar expansion that is: (z-1) - (z-1)^2 / 2 + ... which converges for |z-1| < 1, i.e., we get convergence of ln(z) in an open Taylor disk centered at z = 1, with the boundary being a circle of radius 1. Now I want to analytically continue ln(z), along $z=e^{i\theta}$, that is, continue ln(z) along the unit circle |z| = 1, with expansions / Taylor disks centered at $e^{i\theta}$. I am able to write out explicitly the new power series in powers of (z-$e^{i\theta}$), with new coefficients, and noting that we now have convergence for |z-$e^{i\theta}$| < r < 1. My question is:  Say, on my first shift, shifting the center from z = 1 to z = $e^{i(\pi/6)}$, I get a new power series, but here's my confusion:  is this an expansion for the original ln(z), with the original, chosen branch cut, say, the negative real axis?  I'm guessing it can't be, because as I continue analytically around the unit circle, I will eventually get a Taylor disk that covers a part of the negative real axis, which would be nonsense.  If indeed, each shift requires me to specify a new branch cut, how do I do this, so that we still have convergent Taylor disks that satisfy |z-$e^{i\theta}$| < 1? (My task is to do 12 shifts, starting at $\theta = pi/6$ to get back to z = 1 and that I should be able to observe that I get back the original ln(z) plus an additional $2\pi i$.) Edit: But if I chose a different branch cut, as I shift the center and re-expand the power series, then this new series wouldn't even be an analytic continuation of the original ln(z), so I don't know how to proceed. Thanks,","['power-series', 'taylor-expansion', 'analyticity', 'branch-cuts', 'complex-analysis']"
1303400,Why is this map called a fold?,"Consider the map $\varphi : \mathbb R^2 \to \mathbb R^2$ defined by $(x,y) \mapsto (x,y^2)$. Apparently this map is called a fold as the $(x,y)$-plane is folded over and creased along the axis $y=0$. But I really don't see how this is the case: $y^2$ does not ""fold"" or ""crease"" anything it just bends the plane very very slightly. No? Please could someone explain to me how this map folds the plane? I
  obviously misunderstand it completely.","['differential-topology', 'differential-geometry', 'multivariable-calculus']"
1303417,Show that $x^{3}-3$ irreducible over $\mathbb{Q}(\sqrt{-3})$,Is there a slick way to show that $x^{3}-3$ is irreducible over $F= \mathbb{Q}(\sqrt{-3})$? What I did seems kind of convoluted (showing directly that there is no root in F). Thanks,"['abstract-algebra', 'irreducible-polynomials']"
1303433,Characterization of subsets of $\mathbb{R}^n$ of the form $X+Y$,"The following comes from the mathematical tripos exam at Cambridge: Let $X,Y \subset \mathbb{R}^n$, and define $X+Y = \{x+y : x \in X, y \in Y\}$ Prove or disprove each of the following: (i) If each of $X,Y$ is closed and bounded, $X+Y$ is closed and bounded. (ii) If $X$ is bounded and closed, and $Y$ is closed, $X+Y$ is closed. (iii) If $X$ and $Y$ are closed, $X+Y$ is closed. (iv) If $X$ is open and $Y$ is closed, $X+Y$ is open. Attempt: (i) If $X,Y$ are closed and bounded, then $\mathbb{R}^n \setminus X$ and $\mathbb{R}^n \setminus Y$ are open and unbounded. We need show $\mathbb{R}^n \setminus(X+Y)$ is also open and unbounded. Given any element $x+y \in X+Y$ we construct $B_{\tilde{\epsilon}}(x+y)$ in a natural way. Since there exists $\epsilon_1$ and $\epsilon_2$ so that $B_{\epsilon_1}(x) \subset \mathbb{R}^n \setminus X$ and $B_{\epsilon_2} (y) \subset \mathbb{R}^n \setminus Y$, we see that $$B_{\epsilon_1}(x) + B_{\epsilon_2}(y) \subset \mathbb{R}^n \setminus  (X+Y)$$
Let $\tilde{\epsilon}  = \min\{\epsilon_1,\epsilon_2\}$. By the triangle inequality, we have $$B_{\tilde{\epsilon}} (x+y) \subset \mathbb{R}^n \setminus (X+Y)$$ so that this set is open. The fact that both $\mathbb{R}^n \setminus X$ and $\mathbb{R}^n \setminus Y$ are unbounded implies that they are unbounded in at least one coordinate. We have two cases:
Suppose $\mathbb{R}^n \setminus X$ is unbounded in $i$, $(x_1,\ldots x_i, \ldots, x_n)$ and suppose $\mathbb{R}^n \setminus Y$ is unbounded in $j \neq i$. Then, clearly the sum $(x_1+y_1,\ldots, x_i + y_i, \ldots, x_j + y_j, \ldots, x_n+y_n)$ is unbounded. Now, suppose both sets are unbounded in $i$. Then, call the $A$ set of $x_i$ and $B$ the set of $y_i$. Either $A = (a,\infty)$ or $A=(-\infty,a)$ or $A=(-\infty,a) \cup (a,\infty)$ for some $a$. Likewise for $B$ with some $b$. Checking all of these cases, we see that $A+B$ is unbounded and therefore $\mathbb{R}^n \setminus (X+Y)$ is open and unbounded and so $X+Y$ is closed and bounded.  We conclude that, for $\{X_i\}_{i=1}^{n}$ closed and bounded, $$\sum_{i=1}^{n} X_i$$ is also closed and bounded. (ii) Using the same argument as (i) (I think?) we can conclude that $X+Y$ is closed. Is it valid to do this component-wise and use the facts that $\sup(\pi_i(X+Y) = \sup(\pi_i(X)) + \sup(\pi_i(Y))$ and $\inf(\pi_i(X+Y)) = \inf(\pi_i(X)) + \inf(\pi_i(Y))$ and thus the sum is bounded above and below by $[\inf(\pi_i(X+Y)), \sup(\pi_i(X+Y)]$ and since $X$ and $Y$ are closed, we have $$\pi_i(X+Y) = [\inf(\pi_i(X+Y)), \sup(\pi_i(X+Y)]$$ Where $\pi_i: \mathbb{R}^n \to \mathbb{R}$ is the canonical projection onto $i$th coordinate. That is, each $i$th level-cut is closed, if we fix the other coordinates. (iv) Not sure where to begin. Any hints would be wonderful on all four parts. I'm pretty sure Bolzano-Weierstrass would simplify (i) quite a bit, but I wanted to try to use the closed argument in (i) in (ii) and (iii).","['analysis', 'proof-verification', 'real-analysis', 'proof-writing']"
1303436,Motivation for separation axioms,"I have recently been studying different separation and countability axioms in topology. I am looking for a motivation for why such a refined division of different axioms was made and is studied. I am namely talking about the $T_{k}$ and $N_{k}$ hierarchy. I understand the Hausdorff property, i.e. $T_{2}$-property, is important in analysis and limits; and second countability, i.e. $N_{2}$-property, is important for example in integration on smooth manifolds when one constructs partitions of unity. Moreover, a metric space that is $N_{2}$ satisfies automatically most of the separation and all of the countability axioms. So what is the motivation of such a careful examination of all the different levels of separation and countability in general topology? Is it just for the sake of its own interest, or are there other good examples when one really needs to use different levels of this hierarchy? Especially the $T_{k}$ hierarchy. Thanks a lot in advance.","['motivation', 'metric-spaces', 'separation-axioms', 'general-topology']"
1303439,Show that $f: \mathbb{Z} \to n\mathbb{Z}$ defined as $f(m) = mn$ is bijective,"Let $n \in \mathbb{N}$. Show that $f: \mathbb{Z} \to n\mathbb{Z}$ defined as $f(m) = mn$ is bijective such that $f(m_1 + m_2) = f(m_1) + f(m_2)$, $\forall m_1, m_2 \in \mathbb{Z}$ To be bijective, must be injective and surjective. injective: $f(x) = f(y) \implies x = y$ $ xn = yn \implies x = y$ Thus, is injective. surjective Let $y \in n\mathbb{Z}$. We must show that $y=f(x)$. $y=f(x) \implies y=nx$ Since $\forall nx$ follow that $nx \in n\mathbb{Z}$. Thus, is surjective. $f(m_1 + m_2) = f(m_1) + f(m_2) \implies$ $n(m_1 + m_2) = nm_1 + nm_2 \implies$ $nm_1 +nm_2 = nm_1 + nm_2$ Is this answer ok?","['abstract-algebra', 'functions']"
1303441,Integers of the form $x^2+2y^2$.,"I'm stuck in the following problem:
prove an integer $n$ is of the form $x^2+2y^2$ if and only if every prime divisor $p$ of $n$ that is congruent to $5$ or $7\bmod8$ appears with an even exponent. I think we have to do something similar to Fermat’s sum of two squares theorem. So far I have only managed to see that the product of two numbers of this form is a number of this form (this was seen via the Fibonacci Brahmagupta identity).","['number-theory', 'algebraic-number-theory']"
1303459,Example of non-homeomorphic compact spaces $K_1$ and $K_2$ such that $K_1\oplus K_1$ is homeomorphic to $K_2\oplus K_2$,"Once I heard that there exists two compact spaces $K_1$ and $K_2$ which are non-homeomorphic, but with $K_1\oplus K_1$ homeomorphic to $K_2\oplus K_2$ (where $\oplus$ denotes the topological sum). Is it true?","['examples-counterexamples', 'general-topology']"
1303493,"Proof that if $a,b \in G$ and $a^4b = ba$ and $a^3 = e$ then $ab = ba$","I tried to prove one of the examples in my Abstract Algebra book that stated: Prove that if $a,b \in G$ and $a^4b = ba$ and $a^3 = e$ then $ab = ba$ I went about just saying that $a^4b = ba \iff a^3(ab) = ba \iff e(ab) = ba$ and the result follows. However, the book takes a longer route and proves it this way: $a^4b = ba \implies b = a^6b = a^2ba \implies ab = a^3ba = ba$ Are both of our proofs valid and equivalent or am I missing something? Thanks","['abstract-algebra', 'group-theory', 'proof-verification']"
1303497,"What is the algorithm to generate the cards in the game ""Dobble"" ( known as ""Spot it"" in the USA )?h","In the game Dobble ( known in the USA as ""Spot it"" ) , there is a pack of 55 playing cards, each with 8 different symbols on them. What is remarkable ( mathematically ) is that any two cards chosen at random from the pack will have one and only one matching symbol . This spurred me on to investigating the Maths behind generating such a pack of cards, starting with much more basic examples with only 2 symbols on each card and gradually working my way up to 8 . This has been explored extensively in the linked question "" What is the Math behind the game Spot it "". What has been established is that if the number of symbols on each card is N, then the maximum number of different symbols throughout the pack is C , the maximum number of cards in a pack is also C, the number of times any given symbol is repeated throughout the pack is N, and N and C are related as follows : C = N^2 - N + 1    [ N squared minus N plus one ] But I still do not understand the algorithm for generating the cards from a given symbol set . I am trying to follow the matrix generated by Don Simborg , but I just can't quite follow his formula . Even for a simple matrix with N=3 and C=7, I know what the matrix should look like , but can't seem to understand his descriptive syntax . 
For example in column 2, row 4, his formula suggests the symbol is the one numbered 3N-1 in the sequence of 7 symbols, but 3N-1= 8 , so which symbol should I use? Is he making an assumption that we just wrap around (subtract 7) and start counting again from the beginning of the sequence ? But this still generates the wrong symbol . I know from looking at the pattern that it should be either symbol no 4 or symbol no 5, but just can't see how this arises from his formula . 
If we take the 7 symbols as being the letters ""A"", ""B"", ""C"", ""D"", ""E"" and ""F"", then the matrix should be as follows below : A B C A D E A F G B D F B E G C D G C E F Can anyone help me? I've been trying to crack how to generate the symbol arrangements on the ""Dobble"" cards for months, and have succeeded in generating the sequence as far as N=6, C=31  but I am stuck at N=7 . 
I would welcome any assistance or enlightenment with this , thank you ! And if I have misunderstood Don Simborg's formula, then the error lies with me ! Here are the matrices I have found from my own trial and error : For N=4, C=13, with a symbol set being A B C D E F G H I J K L M , the matrix is as follows : A B C D A E F G A H I J A K L M B E H K B F I L B G J M C E J L C F H M C G I K D E I M D F J K D G H L For N= 5, C = 21, with the symbol set : A B C D E F G H I J K L M N O P Q R S T U , the matrix is as follows : A B C D E A F G H I A J K L M A N O P Q A R S T U B F K N R B G J O S B H L P T B I M Q U C F J P U C G K Q T C H M N S C I L O R D F L Q S D G M P R D H K O U D I J N T E F M O T E G L N U E H J Q R E I K P S To state again, both the sets above have the remarkable quality that any two rows chosen at random will have one and only one matching symbol .","['recreational-mathematics', 'combinatorics', 'card-games']"
1303555,"Check if a point is inside a rectangle (not knowing the coordinates, but knowing distances to vertices)","I have to solve  the following problem:
I have 4 points (A, B, C, D) which form a rectangle, but I do not know their coordinates. I have another point (X), I do not know its coordinates either, but I know the distances between point X and all other 4 points (XA, XB, XC, XD). I need to be able to tell if X lies within a rectangle formed by A, B, C, D.
Any help appreciated.","['rectangles', 'geometry', 'coordinate-systems']"
1303633,Multivariable Calculus with Tensors,I'm looking for a book at the undergraduate level on multivariable calculus (for a 2nd course of multivariable calculus) that introduces and makes use of tensors to describe higher order derivatives -- and maybe differential forms for integration.  Does anyone know of a multivariable book that takes this tact?,"['book-recommendation', 'reference-request', 'multivariable-calculus', 'tensors']"
1303653,Basic question on the probability function and the probability distribution function,"I have a question on the probability function. In my book it says that if A and B are mutually exclusive events $P(A∪B)=P(A) + P(B)$. Then when it starts talking about the probability distribution function it says that  $P(a< X)=P(X≤b)-P(X≤a)$.
If I get things right this is because $-P(X≤a)=P(a< X)$ and then  $P(X≤b)-P(X≤a)= P(X≤b)+P(a< X)$. But here comes what confuses me: Is it the fact that $P(A∪B)=P(A) + P(B) ($if $A∩B=Ø)$ that implies that $P(X≤b)+P(a< X)= P(a< X≤b)$ ?
I understand $a< X≤b$ as being the intersection of $X≤b$ and $a< X$ and not the union? In short my question is: Why is $P(a< X≤b)=P(X≤b)-P(X≤a)$? Can someone help me sort this out? Kind regards,","['probability', 'functions']"
1303672,How to prove $\lim \limits_{n\to\infty}(n+1)\int_{0}^{1}x^nf(x)dx=f(1)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I need help to prove this in real analysis. I think it uses IMVT, but not sure how to do it. Let $f(x)$ be a real valued continuous function on $[0,1]$. Show that
  $$
\lim \limits_{n\to\infty}(n+1)\int_{0}^{1}x^nf(x)dx=f(1)
$$","['analysis', 'limits', 'real-analysis', 'integration']"
1303686,Power set of $X$ is not in $X$,"Prove or find a counterexample to: $P(X) \notin X$. I think it's true but I'm having trouble coming up with a proof, clearly if $P(X) \in X$ then $X \in P(X) \in X$ but I'm not sure where the contradiction comes from. Does it require well-foundedness?",['elementary-set-theory']
1303701,"What does ""$x$ divides $y$"" mean?","I need to negate the following sentence:  ""If for the integers $x, y, z$ we know that $x$ divides $y$ and $y$ divides $z$, then $x$ divides $z$."" In this scenario, what does it mean for $x$ to ""divide"" $y$, et cetera?","['discrete-mathematics', 'number-theory', 'divisibility', 'elementary-number-theory']"
1303717,How to prove this sequence converges,"Here is a problem in analysis: Suppose $x_n\geq0$ and for all $n$, there is
  $$ 
x_{n+1}\leq x_n+\dfrac1{n^2}
$$
  Prove that $x_n$ converges. My approach: it is easy to prove $x_m-x_n\leq \epsilon$ using telescope series. But in order to prove it is a Cauchy sequence, it has to be proved that $x_n-x_m\leq \epsilon$ too. I am not sure how to prove the second step.","['analysis', 'cauchy-sequences', 'limits', 'real-analysis']"
1303735,Questions on Kolmogorov Zero-One Law Proof in Williams,"Here is the proof of the Kolmogorov Zero-One Law and the lemmas used to prove it in Williams' Probability book: Here are my questions: Why exactly are $\mathfrak{K}_{\infty}$ and $\mathfrak{T}$ independent? I get that $\mathfrak{K}_{\infty}$ is a countable union of $\sigma$-algebras that each are independent with $\mathfrak{T}$, but I don't see how exactly that means $\mathfrak{K}_{\infty}$ and $\mathfrak{T}$ are independent kind of like here . How exactly does one show that $\mathfrak{T} \subseteq \mathfrak{X}_{\infty}$? That is, how exactly does one show that $\bigcap_{n \geq 0} \sigma(X_{n+1}, X_{n+2}, ...) \subseteq \sigma [\sigma(X_1) \cup \sigma(X_1, X_2) \cup ...]$? Intuitively, I get it. I just wonder how to prove it rigorously. What I tried: Suppose $A \in \mathfrak{T}$. Then A is in the preimage of...I don't know. Help please?","['probability-theory', 'measure-theory', 'real-analysis', 'random-variables', 'independence']"
1303736,Permutations of cards with no adjacent pairs,"We have a standard 52-card deck, and are looking at the possible shuffles/permutations of this deck. However, we have rubbed off the suits
  from the cards, so for every rank (aces, tens, etc.) all 4 cards are indistinguishable. Furthermore, if we can transform one permutation into another just by relabeling ranks, we regard the permutations as equal. For example, looking at the first 6 cards, A52343 and 5234A4 are to be counted as the same permutation. Two cards of the same rank cannot be adjacent to each other, so
  AA2343... is not permissible (adjacent aces). We can assume the first and
  last card are adjacent to make the question easier. How many distinct permutations exist of the 52-card deck? My attempt: Let us assume the first card is an ace of diamonds. We generally have $52!$ permutations for a deck of cards. However, since all suits are equal, we have $\frac{52!}{3!}$. All ranks are symmetrical, so we have $\frac{52!}{3!\times12!}$. I'm not sure how to take into account the adjacent pairs rule. P.S. I have almost no knowledge of combinatorics, I asked because of this answer by @RobWatts.","['combinatorics', 'permutations']"
1303761,Prove that a transformation of the identity functor of a Group $G$ (seen as a category) into itself is just an element of the center of $G$,"I want to prove the follow: Suppose $G$ is a group seen as a category, prove that a transformation of the identity functor of $G$ into itself is just an element of the center of $G$. I'm not sure if I'm doing well this and I think I'm stuck, can you help me checking? Any corrections are welcome! -What I have done: The class of objects of $\mathcal{G}$ (denoted by $\mathcal{A}(G)$) is having only one object: $\{*\}$. So, the transformation of the identity functor of $\mathcal{G}$ into itself is a class of morphisms $\alpha_{*}:*\to *$ $\in\mathcal{G}$ such that $\forall g:*\to*$ the following square commutes: $$\begin{array}{ccc}
* & \stackrel{\alpha_{*}}{\longrightarrow} & * \\
\downarrow{g} & & \downarrow{g} \\
* & \stackrel{\alpha_{*}}{\longrightarrow} & *  
\end{array}$$ i.e. $g\circ\alpha_{*}=\alpha_{*}\circ g$. (Right here I'm stuck!) P.S. The center of a group $G$ is $Z(G)=\{x\in G | gx=xg\quad\forall g\in G\}$.","['abstract-algebra', 'category-theory']"
1303772,How can I show this inequality: $-2 \le \cos \theta (\sin \theta +\sqrt{\sin ^2 \theta +3})\le 2$,"Show that $$-2 \le \cos \theta ~ (\sin \theta +\sqrt{\sin ^2 \theta +3})\le 2$$ for all value of $\theta$. Trial: I know that $0\le \sin^2 \theta \le1 $. So, I have $\sqrt3 \le \sqrt{\sin ^2 \theta +3} \le 2 $. After that I am unable to solve the problem.","['inequality', 'trigonometry']"
1303819,Non Existence of a proper holomorphic map from the unit disc onto the complex plane,It is well known that there is no proper holomorphic map from complex plane onto disc by Liouville's theorem.Does there exist a proper holomorphic map $f$ from the unit disc onto the complex plane?I believe that such map does not exists but I'm unable to prove this.Please Help! Def :A map $f:X \to Y$ is called a proper map if $f^{-1}(K)$ is compact in $X$ for every compact set $K$ in $Y$.,['complex-analysis']
1303822,Wick Rotation technique,"I am trying to get my head around the Wick rotation technique.
I have tried to play around with some elementary examples.
Let us imagine I need to solve on the real line
$$ y’ = \cos (x)$$
the prime denoting differentiation.
I can view the function on the r.h.s as the real part of a complex function and re-formulate the differential equation, now on the imaginary line ( I suppose this is the ""rotation""), as
$$ y’ = e^{ix} $$ 
Whose solution is $$y = \frac{1}{i} e^{ix}$$
Now to get my solution on the real line I have to re-rotate back, by multiplying by $$-i$$, and then take the imaginary part of the ensuing expression to get my solution $ y = - \sin (x)$. Is this a correct,formally rigorous, application of the Wick rotation technique?
I would also be the most grateful if somebody could show me an elementary example of analytical continuation by the Wick rotation.
Thanks",['analysis']
1303825,Independence of the components of a multidimensional Brownian motion,"Let $B = (B^1, \dots, B^n)$ be an $n$-dimensional ($n \in \{1, 2, \dots\}$) Brownian motion (i.e. $B = (B_t)_{t \geq 0} \in \Omega \rightarrow (\mathbb{R}^n)^{[0,\infty)}$ has continuous paths, $B_0 = 0$ almost surely, $B$ has independent increments, and, for every $s, t \geq 0$ with $s < t$, $B_t - B_s \sim N(0, (t - s) E_n)$, where $E_n$ is the identity matrix in $\mathbb{R}_{n, n}$) adapted to the filtration $\mathfrak{F}$ (which is not necessarily the natural filtration). Is it the case that the components $B^k$ are independent? EDIT I have written all my thoughts on the topic in my answer below.","['probability-theory', 'brownian-motion', 'stochastic-processes']"
1303832,How to learn commutative algebra?,"I want to learn commutative algebra from scratch. I was wondering, as you are experts in mathematics, what you think is the best way to learn commutative algebra? Is there any video course available for commutative algebra? Will there be some online course for commutative algebra on some website like Coursera, etc? I know noncommutative algebra up to the Artin-Wedderburn Theorem. Also, I know group theory up to the Sylow theorems and Galois Theory. I also know some basic topology. I'm new to this site so I don't know what tags I should add for this question. Please feel free to edit my question. Edit 1 : I want to learn commutative algebra for learning Algebraic Geometry.","['soft-question', 'commutative-algebra', 'abstract-algebra', 'book-recommendation', 'reference-request']"
1303848,Divisor of a finite group,"Suppose we have a finite group $G$ and $d\in \mathbb N$ is a divisor of $|G|$. We define the set $E_d= \{g\in G : g^d =1\}$. Prove that $d$ is also a divisor of $|E_d|$. So far I proved that $E_d=\displaystyle \bigcup_{g\in G : o(g)\vert d} \langle g \rangle$ but I didn't know how to continue from here and if this equality is helpful or not. 
I will appreciate any help. Thank you.","['abstract-algebra', 'group-theory', 'finite-groups']"
1303854,Need visualization advice for learning partial derivatives and calculus with more than one variable.,"Okay so I just recently started learning calculus with more than one variable and whilst I'm coming to grips with many of the ideas and stuff I'm finding it difficult to visualize certain things for example, what does a directional derivative look like in 3D and stuff like this. Is there a good site or something where I can get a visualization to try and help cement my understanding? Thank you.","['partial-derivative', 'vectors', 'visualization', 'reference-request', 'multivariable-calculus']"
1303891,Question about direct product of two groups.,"Let $G=\mathbb{Z}_n \times \mathbb{Z}_m$ and $d=p^k$ for some prime $p$ such that $d$ divides both $n$ and $m$. Then $G$ has exactly $d\phi(d)+[d-\phi(d)]\phi(d)$. For example consider the group $G=\mathbb{Z}_4 \times \mathbb{Z}_4$ here $d=p^k$ is $4=2^2$ and $4$ divides $n=4$ and $m=4$ so using above formula we have there are $12$ elements of order $4$. If we have a group $G$ such as $G=\mathbb{Z}_{12}\times \mathbb{Z}_2$, then $G$ has $6$ elements of order $6$ and the group $G=\mathbb{Z}_6 \times \mathbb{Z}_6$  has $24$ elements of order $6$. Is there any formula for counting number of elements of a specific order in later two groups?","['abstract-algebra', 'group-theory', 'direct-product']"
1303910,"$A,B$ be Hermitian.Is this true that $tr[(AB)^2]\le tr(A^2B^2)$?","Suppose $A,B \in {M_n}$ be Hermitian.Is this true that $tr[(AB)^2]\le tr(A^2B^2)$?","['linear-algebra', 'inequality', 'trace', 'matrices']"
1303924,The Mountain Pass theorem,"I cam across the Mountain Pass Theorem, mentioned for example at http://en.wikipedia.org/wiki/Mountain_pass_theorem .
In (very) loose terms, it somewhat reminds me of Rolle's theorem. 
Trying to understand it better in the infinte-dimensional setting, I came across a multiple variables Mountain Pass Theorem in finite dimensional spaces, due to Courant. In this case the critical value $c$ is attained for a certain curve $g$ (using Wikipedia's notation). What surprises me is that in the Mountain Pass Theorem proper the critical value $c$ is defined as an $\inf \max$. While I am trying to work out the details, I am sure it would have been defined as a  $\min \max$ if it were possible. I cannot get around this point. The critical value $c$ is never attained by any curve $g$, and yet is a stationary point of the functional. the theorem proves there is a saddle, and yet in general no curve crosses it at the lowest height possible?? This totally defies my understanding. Has anybody got a word of wisdom?
Thanks",['functional-analysis']
1303931,Why is $\operatorname{Int}(A) \cup \operatorname{Int}(B) \neq \operatorname{Int}(A \cup B)$?,"I know that $\operatorname{Int}(A) \cup \operatorname{Int}(B) \subset \operatorname{Int}(A \cup B)$, but that the other direction does not hold, so can anybody please tell me whats wrong with the following proof? Suppose $x \in \operatorname{Int}(A \cup B) \Rightarrow \exists \epsilon > 0 : K(x, \epsilon) \subset A \cup B$. Assume without loss of generatlity that $K(x,\epsilon) \subset A-B \Rightarrow x \in \operatorname{Int}(A) \Rightarrow x \in \operatorname{Int}(A) \cup \operatorname{Int}(B)$.","['real-analysis', 'general-topology']"
1303941,Hidden Markov Model Transition Probability,"I am doing my assignment and I am asked to derive transition probability of a HMM. There are Three states. H, E and T. They initially gave me the information as follow. E is followed by an H 40% of the time and a T 60% of the time. 
H is followed by a E 30% of the time and a T 70% of the time. 
T is equally likely to be followed by a H or an E
At the start of a sequence, any structure is equally likely. Derive the transition probabilities of a state to itself by considering
that if L is geometrically distributed with parameter p then E[L] = $\frac{1}{p}$. Also
remember that $\Sigma_l a_{kl}=1$ for any state $k$. What I did was $H \to E = 0.3,\
H \to T = 0.7$ and
therefore $H \to H = 0 $ $E \to H - 0.4,\ E \to T = 0.6$ and therefore $E \to E = 0$ $T \to H = 0.5,\ T \to T = 0.5$ and therefore $T \to T = 0$ But this seems to be wrong. Is there a specific way to calculate the transition probability of this sort of problem or am I on the right track? If not, can someone please help me?","['probability-theory', 'markov-process', 'markov-chains', 'bayesian-network']"
1303972,Unbiased estimators for binomial distributed variable,"I'm having trouble determining whether the estimator beneath is unbiased or not.
First some info:
$x_i \sim binom(n_i,p)$ I have a sample of $x_1,x_2,x_3,x_4$ so $n=4$ I want to find out if the following $\tilde{p}=\frac{1}{4}\left(\frac{x_{1}}{n_{1}}+\frac{x_{2}}{n_{2}}+\frac{x_{3}}{n_{3}}+\frac{x_{4}}{n_{4}}\right)$ I know that the criteria for an unbiased estimator is that $E(\tilde{p})=p$ This is what I came up with: $E(\tilde{p})=E\left(\frac{1}{4}\left(\frac{x_{1}}{n_{1}}+\frac{x_{2}}{n_{2}}+\frac{x_{3}}{n_{3}}+\frac{x_{4}}{n_{4}}\right)\right)=\frac{1}{4}E\left(\frac{x_{1}}{n_{1}}+\frac{x_{2}}{n_{2}}+\frac{x_{3}}{n_{3}}+\frac{x_{4}}{n_{4}}\right)$ Now, I'm not sure if my next step is valid and how to proceed if it is: $E(\tilde{p})=\frac{1}{4}E\left(\frac{x_{1}}{n_{1}}+\frac{x_{2}}{n_{2}}+\frac{x_{3}}{n_{3}}+\frac{x_{4}}{n_{4}}\right)=\frac{1}{4}\left(\frac{E(x_{1})}{n_{1}}+\frac{E(x_{2})}{n_{2}}+\frac{E(x_{3})}{n_{3}}+\frac{E(x_{4})}{n_{4}}\right)$ I tried to look in other threads but I wasn't able to find any similar calculation.",['statistics']
1303974,Fourier Transform: Understanding change of basis property with ideas from linear algebra,"The notion of Fourier transform was always a little bit mysterious to me and recently I was introduced to functional analysis. I am a beginner in this field but still I am almost seeing that the Fourier transform can be viewed as a change of basis in a space of functions. I read the following article here which tries to build an intuition: https://sites.google.com/site/butwhymath/fourier-analysis/the-fourier-transform Now, I can see that the Fourier and Inverse Fourier tranforms are projecting and projecting back a function $f(x)$ onto and from the basis of complex exponentials, $e^{i2\pi sx}$, respectively: $$
F(s) = \int_{-\infty}^{\infty}f(x)e^{-i2\pi sx}dx$$ $$
f(x) = \int_{-\infty}^{\infty}F(s)e^{i2\pi sx}ds$$ Here are my questions about this view to make it more clear: 1)If I understand correctly, this operation is akin to regular linear algebra change of basis operations $a=Mb$ and $b=M^{-1}a$. Roughly, in this case $M$ is a matrix of uncountable many rows and columns where each row is $e^{-i2\pi sx}$, a function of $x$, and similarly $M^{-1}$ has rows as $e^{i2\pi sx}$, functions of $s$. Is this interpretation correct? 2)I don't have the exact rigour for this but intuitively think, if 1) is a correct interpretation then we should obtain from the ""infinite dimensional"" matrix multiplication $MM^{-1}$ something which resembles an infinite dimensional identity matrix. To test that, I built the inner product where $s$ is held fixed and equal in both terms from two objects $M$ and $M^{-1}$, which should correspond to a ""diagonal"" element of $MM^{-1}$: $\int_{-\infty}^{\infty}e^{i2\pi sx}e^{-i2\pi sx}dx = \int_{-\infty}^{\infty}e^{0}dx=\infty$. So this is not $1$ as expected from an identity matrix. What is the reason of that?","['fourier-analysis', 'linear-algebra', 'functional-analysis']"
1303975,Open embedding of affine toric varieties implies Cone is face of the other,"let $\tau, \sigma \subseteq N_{\mathbb{R}}$ be two rational, strongly convex polyhedral cones with $\tau \subseteq \sigma$. Now we get an inclusion $S_{\sigma} \to S_{\tau}$ inducing an inclusion $\mathbb{C}[S_{\sigma}] \to \mathbb{C}[S_{\tau}]$ and thus a morphism of varieties $U_{\tau} \to U_{\sigma}$. Assume that this is an open embedding. Question: Why is $\tau$ then a face of $\sigma$? This is exercise $3.2.10$ in Cox, Little and Schenck and I don't know how to prove it. Does this have anything to do with torus orbits? How exactly can we use that the induced mapping is an open embedding? In the exercise they say I should prove it like that: If $u, u' \in N \cap \sigma$ and $u + u' \in \tau$ one has to show that $u \in \tau$ and $u' \in \tau$. Now they look at the limit points corresponding to the one-parameter subgroups and I understand, why $\lim_{t \to 0} \lambda^u(t) \cdot \lim_{t \to 0} \lambda^{u'}(t)$ (which lies in $U_{\sigma}$, as $u, u' \in \sigma$) lies in $U_{\tau}$ (which follows since $u + u' \in \tau$). How can i deduce that each of the limits already lies in $U_{\tau}$? Thanks for all answers.","['algebraic-geometry', 'convex-analysis', 'toric-geometry']"
1303977,What is the idea behind a projection operator? What does it do?,"I know what a projection operator is, but I am unable to explain it in words without using mathematical symbols. Can anyone help me? I don't need examples or the definition - I want to know why and how its need arose, and what is the idea behind it?","['intuition', 'linear-algebra', 'functional-analysis']"
1303984,Take the outcome of a draw in ELO formula,Is there any way to get the probability of a draw outcome using ELO formula as it only gives the Win probability ELO formula is given by $E = \frac{1}{1+10^\frac{d}{a}}$ where d is the difference in ELO Rating and a is a constant,"['probability', 'statistics']"
1304012,Why boundary of a locally closed set is nowhere dense?,"Let $X$ is locally closed , i.e. exist open $U$ S.t.  $X=\overline{X}  \cap U $ , and $bd (X) = \overline{X} \setminus \mathring{X} $. How can I show that $ bd(X) $ is nowhere dense? I read topics about closed or open sets, But I can't find about locally closed.",['general-topology']
1304026,Solving differential equation $x''(t)=x^6$.,"Solve the following differential equation
$$x''(t)=x^6(t)$$
If I had $x'(t)$ instead of $x''(t)$ the exercise would have been easier for me. I would appreciate some help with this problem. Thank you very much.",['ordinary-differential-equations']
1304050,What is the name of this paradox?,"What is the name of the mathematical paradox which is arises from the following? If we imagine a point on a two-dimensional coordinate system (line graph), which moves from the positive part of the graph to the negative (if I can say like that), we expect that at one moment this point will cross the coordinates axis (for example axis of ordinates). When the point is approaching the aforementioned axis, the distance to it constantly reduces. The distance may be a 1 unit, then 0.1 unit, then 0.01, then 0.001, 0.0001, 0.00001... It seems that the point will never cross the axis, because the distance between it and axis may reduce infinitely, thus it may be infinitely small. However, anyone can take a pencil, draw coordinates and then draw a line from one part of the graph to the opposite, crossing the axis without any difficulty. Isn't it a mathematical paradox? I am not a mathematician myself, so I beg your pardon if you find my explanation of a problem a bit awkward.","['paradoxes', 'geometry', 'coordinate-systems']"
1304067,Integral depending on a parameter,"Task: find all values of the parameter, such that integral converges. $$\int_0^{+\infty} \frac{dx}{1+x^a \sin^2x}$$
I tried a lot and I used Cauchy and Weierstrass method but it was useless. And now I know that I must use $$\sum_n \int_{\pi n}^{\pi(n+1)}$$",['integration']
1304069,Why $\lim$ of $\cos(f)$ equals to $\cos$ of $\lim(f)$?,"Let
$$\lim_{n\rightarrow \infty}\left(\cos\left(\frac{n\pi}{n+1}\right) \right) = \cos\left(\lim_{n\rightarrow \infty}\left(\frac{n\pi}{n+1} \right)\right)$$ Why the $\cos(x)$ function can be extracted outside of the limit equation? I know it has something to do with $\cos(x)$ being continuous, but not sure of the formal proof for that.","['calculus', 'limits']"
