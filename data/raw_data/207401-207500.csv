question_id,title,body,tags
4148861,"Statistical tests of the form ""is my PDF correct?""","Let's say we observe some data points $x_i$ and we hypothesize they come from some continuous r.v. X which has PDF $f$ . I know that e.g. the Kolmogorov-Smirnov test can be applied to this kind of problems. Do these tests/problems of the form ""is my PDF correct?"" have a specific name? These problems can be viewed as continuous analogues of problems of the kind ""is my PMF correct?"" Example of the latter is the test if a given e.g. 6-sided die is fair. In that test our $H_0$ hypothesis is that $P(X=i) = 1/6$ which is a PMF and we ask: ""Is my PMF correct?"".  Do these also have some name? This question came to me while watching this last lecture of this MIT course. https://youtu.be/rYefUsYuEp0?t=2167",['statistics']
4148911,How to show a function $f$ defined on $\mathbb{R}$ is constant if it satisfies $f(x) + 3f(1-x) = 5$,"Let f be a real valued function on $\mathbb{R}$ . If for all real $x$ ,it satisfies $$ f(x) + 3f(1-x) = 5$$ Then show that f is a constant function. I tried it like this but not sure whether it is true or not. $$ f(x) + 3f(1-x) = 5\tag 1$$ replace $x$ with $1-x$ , $$f(1-x) + 3f(x) = 5\tag 2$$ Then solving (1) and (2) we get $f(x) = \frac{5}{4}$ for all $x\in \mathbb{R}$ .
Hence $f$ is a constant function.",['functions']
4148930,How to prove that the logarithm is a transcendental function,"Let's consider the function $\log x$ ; how can I prove that it is a transcendental function on the function field of rational functions, i.e. that a polynomial in two variables $p(x,y)$ such that $p(x,\log x)=0$ identically does not exist? I have been trying different approaches: seeing the logarithm on the real numbers, like a formal series or like a holomorphic function on an open in the complex plane, but I was not able to do this. I have also tried looking for the differences with $\sqrt{(1+x)}$ which is algebraic on the rational function, and can be defined on a subset of the reals, with a formal series or on an open subset of the complex plane. Could you please help me?","['analysis', 'real-analysis', 'complex-analysis', 'galois-theory', 'functions']"
4148936,Confused about the definitions of cofinite and cocountable topologies,"Note: $cc$ stands for ""cocountable"" and $cf$ stands for ""cofinite"". Statement: (i) Any one-to-one map from $(\mathbb R, \tau_{cc})$ to $(\mathbb R, \tau_{cf})$ is continuous. (ii) Any continuous map from $(\mathbb R, \tau_{cf})$ to $(\mathbb R, \tau_{usual})$ is constant. Proof: (i) Let $F$ be $\tau_{cf}$ closed. $\color{red}{\text{Then either $F = \mathbb R$ or $F$ is finite.}}$ Thus, in the first case, we have $F = \mathbb R \implies f^{-1}(F) = \mathbb R \implies  f^{-1}(F)$ is $\tau_{cc}$ closed and in the latter case, $f$ is $1-1$ and $f$ is finite $\implies f^{-1}(F)$ is finite $\implies f^{-1}(F)$ is countable $\implies \color{green}{\text{$f^{-1}(F)$ is $\tau_{cc}$ closed}}$ . Hence $f$ is continuous. (ii) Suppose $g$ is not constant. Then exist $x, y \in \mathbb R$ s.t. $g(x) > g(y).$ Pick disjoint, open intervals $I, J$ in $\mathbb R$ s.t. $g(x) \in I, g(y) \in J$ . Now $g^{-1}(I) \cap g^{-1}(J) = g^{-1}(I \cap J) = g^{-1}(\emptyset) = \emptyset$ and $x \in g^{1}(I), y \in g^{-1}(J)$ , so $g^{-1}(I), g^{-1}(J)$ are nonempty, disjoint and $\color{blue}{\text{$\tau_{cf}$-open}}$ . But $\mathbb R = \mathbb R \setminus \emptyset =g^{-1}(I) \cup \mathbb R \setminus g^{-1}(J) = $ union of two finite sets. Contradiction. My question: $\color{red}{\text{part in red}}: \ F \in \tau_{cf} \text{ and $F$ is finite $\implies \mathbb R \setminus F$ is finite and $\mathbb (\mathbb R \setminus F) \cup F = \mathbb R =$ finite}$ . Looks like a contradiction to me. $\color{green}{\text{part in green}}:$ The expression in green implies $\mathbb R \setminus f^{-1}(F)$ is countable. How do we know this subset of reals is countable? It's treated as something self-evident, but it's not obvious to me. $\color{blue}{\text{part in blue}}:$ The expression in blue implies $\mathbb R \setminus g^{-1}(I)$ is finite. How do we know this? Again, not at all obvious to me :) Can someone, please, comment on these? Thanks.","['elementary-set-theory', 'general-topology', 'real-analysis']"
4148968,"Solutions to $\Gamma(z,1)^2 + \Gamma(z,1) = 0 $?","Let $\Gamma(z,1) $ be the well-known incomplete gamma function : $\int_1^{\infty} e^{-t} t^{z-1} dt $ Now I am curious to find solutions to $$\Gamma(z,1)^2 + \Gamma(z,1) = 0 $$ We can ofcourse reduce this too all complex solutions of either $$\Gamma(z,1) = 0 $$ or $$\Gamma(z,1) = -1 $$ I heard that this function is an entire function so the equation $\Gamma(z,1)^2 + \Gamma(z,1) = 0 $ must have solutions. I think that $\Gamma(z,1) = 0 $ has no (finite) solutions. I assume most solutions to $\Gamma(z,1) = -1 $ must have $-3 < Re(z) < 3 $ due to the functional equation this function satisfies. ( $\Gamma(z+1,1) = z \Gamma(z,1) + e^{-1} $ ) I know a bit about complex analysis and contour integrals.
But I have no efficient method to find the zero's.
I would like to have the values and some insight into them.
How far are the zero's apart from eachother ? Im aware of another identity for strictly real $z < 1$ : $$ \Gamma(z,1)=\frac{e^{z-1}}{\Gamma(1-z)} \int_0^\infty \frac{e^{-t} t^{-z}}{1+t} dt$$ Not sure if that could help. I was only able to find $t=4.86853..+5.66062..i$ and its complex conjugate as solutions to $\Gamma(t,1) = -1$ edit : Perhaps the following limits might be helpful : $$ \lim_{x \to +\infty} Re(x^2 \Gamma(1+e+x i,1)  ) = -1$$ $$ \lim_{x \to +\infty} Im(x \Gamma(1+e+ x i,1) ) = e^{-1} i $$","['functional-equations', 'special-functions', 'roots', 'complex-analysis', 'gamma-function']"
4148993,What's wrong with my formula?,"I'm learning about rational functions, and encountered this word problem: A helicopter flies from Vancouver to Calgary a distance of 677km with
a tailwind. On the return trip the helicopter was 40km/h slower. The
total flying time for both flights was 6.5 hours. How fast was the
helicopter flying to Calgary? Round the answer to the nearest
hundredth. Without looking, I tried: $$\text{Total distance} / \text{Avg speed} = \text{Total time,}$$ $$\frac{1354}{s-20} = 6.5.$$ Which gives $(228.31 , 0)$ and looks more or less correct. But the given solution is modeled as: $$\text{Time with tailwind} + \text{Time with headwind} = \text{Total time}$$ $$\frac{677}{s} + \frac{677}{s-40} = 6.5.$$ Giving $(230.21,0)$ . I can tell at a glance that the given formulation is more precise and thus more likely to be correct. But as far as I can tell, what I came up with should work too. Where did I go wrong?","['kinematics', 'word-problem', 'average', 'rational-functions', 'algebra-precalculus']"
4149068,Prove $X$ is connected if both $G$ and $X/G$ are connected,"I have a question about an answer written here . For completeness, here is the question and a sketch of the solution: Let $G$ be a topological group acting on a space $X$ . Show that if both $G$ and $X/G$ are connected, then $X$ is connected. Solution sketch : suppose on the contrary $X=U\cup V$ for disjoint, nonempty, open $U,V\subseteq X$ . If $\pi:X\to X/G$ denotes the canonical quotient map, then we have $\pi(U)\cup\pi(V)=X/G$ . The goal is to show that this disconnects $X/G$ . One uses the connectedness of $G$ to show that $\pi(U)\cap\pi(V)=\varnothing$ , and then, as the answer linked states, ""by definition of the quotient topology, both $\pi(U)$ and $\pi(V)$ are open in $X/G$ "", hence $X/G$ is disconnected, a contradiction. My question: I'm pretty sure I'm over thinking this, but why can we say $\pi(U)$ and $\pi(V)$ are open in $X/G$ ? Quotient maps need not be open maps in general. Is this a fact about quotients by group actions?","['general-topology', 'topological-groups']"
4149098,Signal Processing in Functional (Dual) Space of the Schwartz Space,"I am reading a book on signal processing, rigor level of which is lower than a thorough introduction to functional analysis and is higher than an engineering introduction of signals and systems. The biggest difference of the material, from engineering signal processing books, is to explain the space of tempered distributions using Schwartz functions and to explain how $\delta$ is defined a tempered distribution, and to introduce Fourier transforms on the space of tempered distributions. I am half way through the book, and I have some questions to ask. The biggest question I have, is how to view previous engineering writing. For instance, we know that $\delta$ is not a function, but a distribution. We are used to seeing equations of the following style: \begin{equation}
\delta * f = f,
\end{equation} and \begin{equation}
\delta(x-a) * f\left(x\right) = f\left(x - a\right).
\end{equation} My current thought is that, these writings are abbreviations for the following steps: 1. do convolution in functional space 2. convert the result back to function space (if there is a preimage). In this case, there is no need to raise $f$ to a tempered distribution, as a function convolving a distribution is well-defined. In general, my understanding is that, whenever some operation in an engineering signals book is invalid in the function space (no dirac delta, Fourier transform doesn't exist, etc), raise that to the functional space, and use the corresponding operation in the functional space to find a distribution. If the distribution is of a preimage in the function space, convert it back for engineering understanding. Of course, previous conclusions are still valid, but the true theoretical thoughts behind them are more complicated than they look. Is this understanding correct?","['signal-processing', 'functional-analysis']"
4149117,"Proof that $|(0,1)| = |(0,1)^{\mathbb{N}}|$","I'm trying to understand a proof from my professor's lecture notes arguing that $|(0,1)| = |(0,1)^{\mathbb{N}}|$ . Here is my understanding of the proof, with some additional detail added by me. Define the map $(0,1) \to (0,1)^{\mathbb{N}}$ sending $x = 0.a_1 a_2 a_3 \ldots$ , written without terminating in an infinite string of nines, to the sequence $(s_1, s_2, s_3, \ldots)$ , where $s_k$ , by definition, takes the first available digit after the decimal point that hasn't already been enumerated in $s_1, \ldots, s_{k-1}$ and then increments by $2^k$ . For example, \begin{align*}
s_1 & = a_1 a_3 a_5 a_7 a_9 \ldots \\
s_2 & = a_2 a_6 a_{10} a_{14} \ldots \\
s_3 & = a_4 a_{12} a_{20} a_{28} \ldots \\
& \vdots \\
\end{align*} This mapping is well-defined since we use the decimal expansion of $x$ not terminating in an infinite sequence of $9$ 's, which we know to be unique, and it's a bijection because it is invertible. Namely, given a sequence $(s_1, s_2, s_3, \ldots)$ , using the above construction, we can uniquely determination $x = 0.a_1 a_2 a_3 \ldots$ . How does this look?  The proof of bijectivity seems somewhat frail to me, though it does seem simple to me to reconstruct $x$ . The assertion that this decimal expansion is unique, while true, also seems a bit flimsy to me; if anyone can give a hint on how to prove that, this would be helpful.","['elementary-set-theory', 'solution-verification']"
4149132,The equation $\tan x = \tan 2x \tan 4x \tan 8x$,In the question we have the equality $$\tan 6^{\circ} \tan 42^{\circ} = \tan 12^{\circ} \tan 24^{\circ}$$ which is equivalent to $$ \tan 6^{\circ} = \tan 12^{\circ} \tan 24^{\circ} \tan 48^{\circ}$$ This means that the equation $$\tan x = \tan 2x \tan 4x \tan 8x$$ has the solution $x =6^{\circ} = \frac{\pi}{30}$ .  How to find all the solution of this equation?,['trigonometry']
4149162,Divergence of $\sum_{n=1}^\infty\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!}$,"I was solving practice problems for my upcoming calculus 1 final and came across this problem. I'm honestly still a little lost about the series and ratio tests. The problem itself is $$\sum_{n=1}^∞\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!}$$ I identified $$a_n = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)}{n!}$$ but I'm not sure if a $$a_{n+1} = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)^{n+1}}{(n+1)!}$$ or something else?
Please help evaluate the limit using, $$\left|\frac{a_{n+1}}{a_n}\right|.$$ Thank you in advance!","['divergent-series', 'calculus', 'sequences-and-series']"
4149164,How can I calculate $\rho_\alpha(z)$?,"I am trying to design a group of complex functions $\rho_\alpha$ that have a type of symmetry that might look nice if it exists. This is what ""symmetry"" I want to try. $$\alpha=a+bi\space\space,\space\space\bar\alpha=a-bi$$ $$\rho_\alpha(z)=\rho_\alpha(\alpha z+\bar\alpha)\tag{1}$$ $$\rho_\alpha'(0)=\frac{\alpha}{|\alpha|}\tag{2}$$ My questions are does this group of complex functions exist? How can I plot these complex functions using Python, JavaScript, or another programing language? Do they have nice properties? I don't understand a lot about complex analysis only bits and pieces. I'm in high school just going into $11$ th grade. I love math and I love art. I'm not looking for an exact formula for these functions just how I can compute them, but if there is an exact formula that would be good.","['programming', 'art', 'complex-analysis', 'functions', 'complex-numbers']"
4149334,Difference between a vector in $\Bbb{R^1}$ and a scalar,"Many people say that they are the same, even I can't find much difference in them except that a vector/ matrix can be multiplied by any scalar, but to multiply it with a vector in $\Bbb{R^1}$ the vector or matrix should be of the order $1\times n$ . What's and why is there a difference in this case?","['multivariable-calculus', 'vectors', 'linear-algebra', 'vector-spaces']"
4149355,Linear-time sampling of stochastic processes?,"Are there any stochastic processes $(X_t)_{t \in \mathbb{R}^d}$ such that almost surely paths are continuous but nowhere differentiable and sampling of $n$ points $X_{t_n}$ on a path can be done in $O(n)$ time? Most sampling techniques I have in mind require at least $O(n \log n)$ time. On the the other hand, all linear-time samplers I know, create processes such that 1) fails; like Perlin-noise, White noise, Pink noise, etc. Is it even theoretically possible? So this might be a very fundamental question.","['stochastic-processes', 'random', 'random-functions', 'probability']"
4149377,Second order linear non-homogenous ODE - checking my solution,"$$xy'' + 2y' - xy = e^x$$ is the equation. Here's what I did: Divide by x First, solve the homogenous equation. $$y'' + \frac{2}{x}y' - y =0$$ Perform a substitution $y=u(x) \cdot z(x)$ , where $u(x) = e^{-\frac{1}{2}\int{p(x)dx}}$ In this case, $p(x) = \frac{2}{x}$ , and $q(x) = -1$ Find $u', u''$ After plugging in the necessary values, we get an equation: $$z'' - z = 0$$ , the solution of which is $$C_1e^x + C_2e^{-x}$$ We plug this in $y=u\cdot z$ and get: $$y=C_1 \frac{e^x}{x} + C_2 \frac{e^{-x}}{x}$$ I am fairly sure I made no mistakes up until this point. Next, I tried to solve the equation by variation of constants, where I get the Wronskian $-\frac{2}{x^2}$ . Thus, $C_1' = \frac{1}{2}$ , so $C_1 = \frac{x}{2} + C_3$ And $C_2' = -\frac{e^{2x}}{2}$ , so $C_2 = -\frac{e^{2x}}{4} + C_4$ When I plug in these values into $y$ , I get $$y=\frac{e^x}{2} + C_3 \frac{e^x}{x} - \frac{e^x}{4x} + C_4\frac{e^{-x}}{x}$$ Now, when I check the solution on WolframAlpha, the third term in my solution is extra. Can anyone spot my mistake because I am unable to do so? I have been trying for at least several hours. NOTE : It is imperative for this exercise to be done with variation of constants.",['ordinary-differential-equations']
4149383,Finding whether $\int_{0}^{\pi/2}\frac{\rm dt}{\sqrt{1-x\cos^2{t}}}$ is increasing or decreasing,"I'm trying to find if $$f(x)=\int_{0}^{\pi/2}\dfrac{\rm dt}{\sqrt{1-x\cos^2{t}}}\;,\;\text{where}\; x \in (0,1)$$ is increasing or decreasing. My Attempt: Using DUIS to find $f'(x)$ , We get $$f'(x)=\int_{0}^{\pi/2}\dfrac{\cos^2t\;\rm dt}{{2(1-x\cos^2{t})}^{3/2}}$$ How to proceed further?","['calculus', 'definite-integrals', 'derivatives', 'inequality']"
4149409,"A simple graph $G$ with even clique number, find a subset $A$ of the vertices, subgraph induced by $A,V-A$ have equal clique number","Given a simple graph $G=(V,E)$ s.t. $2\mid \omega(G)$ , Show that $\exists S\subseteq V\text{ s.t. } f_G(S)=f_G(V\setminus S)$ where $f_G(A)$ is the clique number of the sub-graph of $G$ induced by vertex set $A$ . I'm have trouble proving this property of clique number. Several approaches have been tried but none leads to a correct proof. IDEA: Firstly, divide a largest clique $C$ of $G$ evenly into to subset $A,B$ . I want to continuously add vertices into $A$ and $B$ keeping the clique number of the sub-graphs induced by $A,B$ unchanged. For every other vertex $v$ , we have $f(A\cup \{v\})=f(A)\lor f(B\cup \{v\})=f(B)$ , otherwise $A\cup B\cup\{v\}$ is a clique bigger than $C$ . After adding the first vertex, I can show that every other vertex $v'$ satisfy $f(A\cup \{v'\})=f(A)\lor f(B\cup \{v'\})=f(B)$ using the pigeonhole principle. However, after adding $|A|$ vertices into $A$ or $|B|$ vertices into $B$ , I can no longer have the property: $f(A+v)=f(A)\lor f(B+v)=f(B)$ IDEA: Continuously find the largest clique $C=\{v_1,\ldots v_k\}$ if $2\mid k$ split it evenly, otherwise split it into $\lfloor k/2\rfloor,\lceil k/2\rceil$ This doesn't work, adding the vertices arbitrarily can cause unpredictable increase in clique number. other naive approaches. I really need some hint to solve it. btw, I don't know why the graph should be simple, I can't see a difference. I have also posted this question on cs stackexchange but only receive 3 unique views after 20minutes. I am assuming that I have posted it at a wrong wibsite. If this is considered inappropriate, please tell me and I will remove this problem.","['graph-theory', 'discrete-mathematics']"
4149428,One sided limit of formula involving the hypergeometric function ${}_2F_1$ at singular point,"I need help finding the following limit (closed form): \begin{align}
&\lim_{x\to1^{-}}\alpha x \ln(1-x) +\frac{(\alpha+1)x^2}{2-\alpha} {_2F_1(1, 2-\alpha; 3-\alpha; x)}
\\
&\hspace{2cm}-\frac{x^2}{2-\alpha} {_2F_1(1, 2-\alpha^2; 3-\alpha^2; x)}
\end{align} where $\alpha = e^\frac{2\pi i}{3}$ and the hypergeometric function is defined as: $$_2F_1(a;b;c;z)=\sum_{n=0}^{\infty} \frac{(a)_n (b)_n}{(c)_n}\frac{z^n}{n!}$$ where: $$(a)_n=\begin{cases}
1,  & n=0 \\
a(a+1)...(a+n-1), & n>0
\end{cases}$$ This is the first time I even hear of a hypergeometric function so I haven't the slightest clue as to how to approach this problem. I tried looking up some identities regarding ${_2F_1}$ but have come up with nothing useful, except the fact that it has a singularity at $1$ which really isn't helpful... any help would be appreciated.","['limits', 'calculus', 'ordinary-differential-equations', 'hypergeometric-function']"
4149478,Is there any way this ODE can be solved with variation of constants?,"$$y'' - y' = \frac{2-x}{x^3}e^x$$ The solution of the homogenous equation is $C_1 + C_2e^x$ . Now, onto the variation of parameters: In this case, the Wronskian would simply be $e^x$ . Therefore, we get $$C_1' = -\frac{e^x(2-x)}{x^3}$$ and $$C_2' = \frac{2-x}{x^3}$$ However, I can't calculate $C_1$ in terms of standard mathematical functions. The integral is too complicated and every integral solver I tried gives me back some of the non-standard functions we haven't learned about. The exercise specifically says to solve this problem with the use of variation of parameters so I think I may have made a mistake, or there's an easier way to solve the integral. Can anyone help?","['integration', 'ordinary-differential-equations']"
4149535,Find units in $\mathbb{Z}[(\sqrt{13}+1)/2]$,"I need to show that the units in the ring $\mathbb{Z}[x] =\{a + bx : a,b \in \mathbb Z\}$ where $x = \frac{1+\sqrt{13}}{2}$ (just considering the positive root of $13$ ), are those which $a^2 +ab -3b^2$ is a unit in $\mathbb{Z}$ , that is, those which $a^2 +ab -3b^2= \pm 1$ . I have tried it by finding the solutions to $(a + bx)(a'+b'x)=1$ , but this leads me to the following equation with 4 variables and many possible restrictions that I am stucked with: $ \displaystyle (a + bx)(a'+b'x)= a a ' +ab'x + a'bx + bb'x^2 =  aa' + \frac{ab'}{2}+ \frac{a'b}{2} +\frac{ab'}{2}\sqrt{13} + \frac{a'b}{2}\sqrt{13} + \frac{bb'}{2}\sqrt{13} + \frac{7}{2}bb'=1$ where the terms with $\sqrt{13}$ are necessarily $0$ , that is $ab'+a'b+bb'=0$ I cannot transform the last condition into anything more easy to handle, and I don't know if there is a more efficient way tho prove this. (I do not know much about Number Theory nor advanced Group or Ring Theory, which I have seen that is often useful in similar problems).","['extension-field', 'ring-theory', 'abstract-algebra', 'roots']"
4149635,"Confidence Interval for Normal$(\theta,\theta^2)$","Let $X_1,X_2,\dots,X_n$ a simple random sample $$X_i\sim N(\theta,\theta^2)$$ I want to find a confidence interval for the mean using a pivotal quantity. I read this answer Confidence Intervals - distribution of a Pivot? and the pivotal quantity should be $$\frac{\bar{x}-\theta}{S/\sqrt{n}}$$ But I'm wondering if for this case I can use $$Y=\sum_{i=1}^nx_i\sim N(n\theta, n\theta^2)$$ Then my pivotal quantity will be $$\frac{Y-n\theta}{\theta\sqrt{n}}\sim N(0,1) $$ So $$P\left(-z_{\alpha/2}<\frac{y-n\theta}{\theta\sqrt{n}}<z_{\alpha/2}\right)=1-\alpha $$ $$P\left(\frac{Y}{n+\sqrt{n}z_{\alpha/2}}<\theta<\frac{Y}{n-\sqrt{n}z_{\alpha/2}}\right)=1-\alpha $$ Is this correct too?","['statistical-inference', 'statistics', 'confidence-interval']"
4149683,Submartingale bounded in $L^2$ converges in $L^2$.,"I have been wondering whether it is possible to extend the $L^2$ -martingale convergence theorem to submartingales that are not necessarily non-negative (the case of non-negative submartingales is treated here ). Thus, if $\{X_n, F_n\}_{n=0}^\infty$ denotes a submartingale with filtration $F_n$ such that $\sup_{n} E(X_n^2)<\infty$ , can we say that $X_n$ converges in $L^2$ ? A good reference suffices. Thank you in advance.","['stochastic-processes', 'probability-theory', 'martingales']"
4149736,Castelnuovo-Mumford regularity - Mumford's proof,"I am studying Mumford's 'Lectures on curves on an algebraic surface', in particular the section on Castelnuovo Mumford regularity. I am stuck in a small point. A coherent sheaf $F$ on $P^n$ is $m$ -regular if $H^i(P^n,F(m-i))=0$ for all $i>0$ . He says the following. If $F$ is a $m$ - regular sheaf on $P^n$ , then $H^0(P^n,F(k))$ is spanned by $H^0(P^n,F(k-1))\otimes H^0(P^n,O(1))$ if $k>m$ . As a consequence of the above statement and Serre's theorem ( $F(k)$ is generated by it's sections if $k$ is large enough), he says for $k$ large, $F(k)$ is generated by $H^0(F(m))\otimes H^0(F(k-m))$ . I am not able to make this jump. Why are we getting this as a consequence. I would be grateful if someone clarifies, even though this might be a silly question.",['algebraic-geometry']
4149739,Euler constant as limit of zeta function,"I want to prove that $ \lim \limits_{s \to 0} (\zeta(1+s)+\zeta(1-s))= 2\gamma$ , I divide it to two limits, $\lim \limits_{s \to 1^{+}} (\zeta(s)-\frac{1}{s-1}) = \gamma$ which I proved using the definition for $\gamma = H(\infty)-\ln (\infty)$ and $\zeta(s) = \sum \limits_{n=1}^{\infty} n^{-s} $ for $s>1$ but the definition of $\zeta(s)$ fails when evaluating $\lim \limits_{s\to 1^{-}} (\zeta(s)-\frac{1}{s-1})$ , so I want to use $\zeta(s) = \frac{1}{1-2^{-s}} \sum \limits_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^s}$ for $s>0$ , the problem for me now is that this new definition does not easily transform to the definition of $\gamma = \lim \limits_{n \to \infty } (H_n -\ln n)$ , I want to see a proof of the case when $s\to 1^{-}$ ? Thanks","['riemann-zeta', 'limits', 'summation', 'euler-mascheroni-constant']"
4149745,find integral $\int_0^{\pi/2}~{\frac{\sin(~40~x)}{\sin(~5~x)}}\mathrm{d}x$,Find integral : $$\int_0^{\frac{\pi}{2}}~{\frac{\sin(~40~x)}{\sin(~5~x)}~dx}$$ My attempt -writing $$\sin~40x= \sin~40x - \sin~30x + \sin~30x - \sin~20x + \sin~20x - \sin~10x +\sin~10x$$ and apply formula $\sin~C - sin~D$ and write $\sin~10x = 2~\sin~5x\cos~5x$ … by this $\sin~5x$ will be eliminated and will be left with only cos terms. Any other approach for this problem.,"['integration', 'definite-integrals', 'complex-analysis', 'calculus', 'trigonometry']"
4149752,The domino curve,"Consider a set of domino tiles with zero thickness evenly spaced apart. Now let them fall but hold the last one upright. The arangement could now look like this: Call the distance between two tiles $d$ and the coordinates of the top of each domino $(p_n,q_n)$ , so the $n$ -th tile is described by $y_n=\frac{q_n(nd-x)}{nd-p_n}$ . However, these equations get complicated fast: $$y_1 = \sqrt{1-d^2}\left(1-\frac{x}{d}\right) \qquad 
y_2 = \frac{ \sqrt{1-d^2} \left( d^2 - \sqrt{d^4-d^2+1} \right) (2d-x)}{d \left( d^2 - \sqrt{d^4-d^2+1} -1 \right)}$$ Is there an easy formula for $(p_n,q_n)$ ? Since they all have the same length and are equally spaced it might be easier to look at it from a point-slope perspective. I obtained $(p_n,q_n)$ by finding the intercept between $y_{n-1}$ and $y=\sqrt{1-(x-nd)}$ . Maybe there is also a nice representation for the angle at the bottom of the $n$ -th tile (depending on $d$ ) but I wasn't able to find it. What curve are all dominoes tangent to? This also depends on $d$ and if it's too hard, consider only the case $\lim_\limits{d \to 0}$ . Such a function would have the following properties: $$\lim_\limits{x \to \infty} f(x) = \lim_\limits{x \to \infty} f'(x) = 0 \qquad 
\lim_\limits{x \to 0^+} f(x) = 1 \qquad \lim_\limits{x \to 0^+} f'(x) = -\infty$$ Thanks in advance.","['limits', 'analytic-geometry', 'geometry', 'real-analysis']"
4149769,"I got the answer as 7/16 , can anyone confirm it?","Box A contains 5 red and 3 white marbles Box b contains 2 red and 6 white marbles if a marble is drawn from each box, what is the prob that they are of same colour. My solution: RR  or WW = (5/8)(2/8)  + (3/8)(6/8) = 10/64 + 18/64 = 28/64 = 7/16 My teacher's solution: Let E1 be the event that marble is from Box A and is Red:
P(E1)=(1/2)(5/8)= 5/16 Let E2 be the event that marble is from Box B and is Red:
P(E2)=(1/2)(2/8)= 1/8 Let E3 be the event that marble is from Box B and is White:
P(E3)=(1/2)(3/8)= 3/16 Let E4 be the event that marble is from Box B and is White:
P(E4)=(1/2)(6/8)= 3/8 Required Probability= P(E1nE2)+P(E3nE4)= (5/16)(1/8)+(3/16)(3/8)= 7/64 can anyone confirm which one is correct?","['combinatorics', 'probability']"
4149778,Contour Integral of $\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx$,"I had this question $\int_{0}^{\infty} \frac{\cos(x)}{(x^2+1)^2}dx$ on a introductory complex analysis final and really had a poor go of it. The poles are $\pm i$ both of order 2, so I replaced $cos(x)$ by $e^{iz}$ and then set $$H(z)=e^{iz}~~ \& ~~G(z)=(z^2+1)^2$$ and so $$G'(z)=4z(z^2+1)=4z((z+i)(z-i))$$ I then attempted to take $Res(\frac{H}{G'};i)$ $$\lim_{z\to i}\left((z-i)\frac{e^{iz}}{4z((z+i)(z-i))}\right)=\frac{e^{-1}}{4i(2i)}=-\frac{1}{8e}$$ But then multiplying by $2\pi i$ gave me an imaginary result which I clearly knew was wrong but due to time constraints I just couldn't afford to fix the problem. I am convinced that since $G'(i)=0$ that I was flawed from the start, could I have taken another derivative or slightly altered this approach? After a week of feeling poor about how I had fumbled this one, I decided to go back and redo it. I defined the same $H(z)=e^{iz}$ and $G(z)=(z^2+1)^2=(z+i)^2(z-i)^2$ . So define $$H_1(z)=\frac{e^{iz}}{(z+i)^2}$$ then $$H_1'(z)=\frac{ie^{iz}(z+i)^2-2(z+i)e^{iz}}{(z+i)^4}$$ To compute the residue I instead used the formula $Res(f;z_0)=\frac{H^{(m-1)}(z_0)}{(m-1)!}$ with $m=2$ , then $$Res(H_1;i)=\frac{H_1'(i)}{1!}=\frac{ie^{i\cdot i}(2i)^2-2(2i)e^{i\cdot i}}{2i^4}=\frac{-4ie^{-1}-4ie^{-1}}{16}=-\frac{i}{2e}$$ Then by the residue theorem; $2\pi i \cdot -\frac{i}{2e}= \frac{\pi}{e}$ . I chose to integrate over the contour of a semicircle in the upper half plane of radius $R$ , of which it can easily be shown that along upper arc $\gamma_R$ the integral will converge to 0 and so we are left with $\gamma_x$ which is the $\mathbb{R}$ -axis. Then $$\lim_{R\to\infty}\int_{-R}^{R}\frac{\cos(x)}{(x^2+1)^2}dx=\int_{-\infty}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx=2\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{e}$$ So $$\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{2e}$$ Could anybody confirm that this is the correct result and please point out any flaws in my method for both my first and second solutions?","['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
4149812,"Determine real numbers a,b and c such that they verify a certain equation",up to this point I've determined c this way: The issue here is that I cannot figure out how to proceed the same way with the other two variables a and b. Is there something I'm missing from the start? Sorry if it's hard to understand I can elaborate if necessary.,"['real-numbers', 'limits', 'problem-solving', 'partial-fractions']"
4149813,Resemblance of the graph of $\ln (ax^2+by^2)=y^{n}$ with ellipse $ax^2+by^2=1$ for large values of $n$.,"Coincidentally using Desmos, I found out that the graph (specifically its curvature) of $\ln (x^2+y^2)=y^{n}$ for large values of $n$ resembles with that of circle $x^2+y^2=1$ . This resemblance increases Further as the value of $n$ increases. Another Fascinating thing I observed is that The Graph of $\ln (ax^2+by^2)=y^{n}$ for large values of $n$ resembles with the graph of ellipse $ax^2+by^2=1$ . So our circle is the special case of the second case, the ellipse. Can we offer any satisfactory explanation for this?","['calculus', 'logarithms']"
4149867,Is it true this formula for $g_f(x)$ is independent of the value of $f\in\mathbb{Z}_{>0}$,"This question is related to analytic formulas for $\sigma_0(x)$ and it's first-order derivative $\sigma_0'(x)$ which are defined and illustrated in this answer I posted to a question on Math Overflow. In particular, $g_f(N)$ defined in formula (1) below represents the evaluation of $\sigma_0'(x)$ at $x=1$ . I suspect the independence of $\sigma_0'(x)$ with respect to $f$ extends to all integer values of $x$ , but hopefully an answer to this question for the specific case $x=1$ will lead to a proof (or disproof) of more general independence. Consider formula (1) below for $g_f(N)$ where $f$ is assumed to be a positive integer. $$g_f(N)=-\frac{(2\pi)}{f}\sum_{n=1}^N\frac{1}{n^2}\sum\limits_{k=1}^{f\ n} k \sin\left(\frac{2 \pi k}{n}\right)\tag{1}$$ I've noticed formula (1) for $g_f(N)$ above seems to evaluate exactly the same independent of the value of $f$ , and $g_1(N)$ is approximated by the linear function $x$ which is illustrated in Figure (1) below. Figure (1) : Illustration of $g_1(N)$ Question : Is it true that $g_m(N)=g_1(N)$ for all positive integer values of $m$ ?","['arithmetic-functions', 'number-theory', 'sequences-and-series']"
4149923,Determine the extrema of this function,"Let $b_i \in \mathbb{R}$ , $f:\mathbb{R} \rightarrow \mathbb{R}$ $f(x) = \sum_{i=1}^{n} (x-b_i)^2$ So i have calculated the first derivative $f’(x) = 2 \sum_{i=1}^{n} (x-b_i)$ and the second $f”(x)=2$ , so the extrema would be a minimum? I have tried to calculate the extrema, $2 \sum_{i=1}^{n} (x-b_i)= 2(nx-\sum_{i=1}^{n} b_i)$ $nx= \sum_{i=1}^{n} b_i$ , so the local minimum would be at $x=\frac{\sum_{i=1}^{n} b_i}{n}$ . Is my approach correct?","['optimization', 'calculus', 'derivatives', 'real-analysis']"
4150005,"Is the sine operator on $L^2[0,1]$ Fréchet differentiable or not and why?","This problem has given me some trouble. Let $F$ be the operator on $L^2[0,1]$ defined by $F(g)(t)=\sin g(t)$ . I'm trying to determine whether or not $F$ is (Fréchet) differentiable in that space. I know that it is in $C[0,1]$ because I have seen this one before. The notion if Fréchet derivative is a direct expansion of the Gâteaux derivative: $f : U \to Y$ where $U\subset X$ and $X, Y$ normed spaces is called (Fréchet) differentiable at $u\in U$ if there exists a bounded linear operator $T$ from $X$ to $Y$ such that for $h\to 0$ we have $$
\frac{f(u+hv)-f(u)}{h} \to Tv
$$ uniformly for all $v\in B_X$ , e.g. in the closed unit ball in $X$ . So this is basically Gâteax differentiabilty with added uniformity of convergence. At first, I couldn't really make sense of the difference, but the example here helped me a great deal with that. I checked for Gâteaux differentiability and after some contortions and the realization that the MVT should be applied I figured out the derivative in $g$ to be $T(f)(t)=\cos(g(t))f(t)$ .
However, I can't come up with an argument as to whether Fréchet differentiability holds true in this case. If the Fréchet derivative exists, it is equal to $T$ . The point in question should be the null function. But how to proceed from here?","['frechet-derivative', 'nonlinear-analysis', 'banach-spaces', 'functional-analysis']"
4150011,Going from trigonometric functions to algebraic functions.,"How do you simplify the function $\arctan(\cos x)$ so that it does not use any trigonometric functions? The closest answer I was able to come up with is $\pi/4\cos x$ , but that was simply a guess from looking at the function. Furthermore, $\cos x$ is obviously a trigonometric function, so this would not work.",['trigonometry']
4150018,Why is this set Lebesgue measurable?,"$K$ : Cantor set $f$ : $[0,1] \to K$ We can write $\displaystyle x=\sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \ (\varepsilon_k = 0,1)$ for all $x \in [0,1]$ by binary expansion. Define $$ f(x)=f \left( \sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \right) = \sum_{k=1}^\infty \dfrac{2\varepsilon_k}{3^k}.$$ Then, prove that $\{f >a \}=\{x\in [0,1] \mid f(x) >a \}$ is Lebesgue measurable for all $a\in \mathbb{R}$ . If $a< 0,$ $\{ f>a \}=[0,1]$ and it is Lebesgue measurable. But what about for $0\leqq a$ ? I don't know how $\{f >a \}$ is expressed for $0\leqq a$ .","['measure-theory', 'lebesgue-measure', 'measurable-functions']"
4150059,"Suppose $u(x,y)$ is a function $C^2$ from $\mathbb{R}^2$ to $\mathbb{R}$. After a change to polar coordinates $u(x,y)=u(r\cos \theta , r\sin \theta)$.","Suppose $u(x,y)$ is a function $C^2$ from $\mathbb{R}^2$ to $\mathbb{R}$ . After a change to polar coordinates $u(x,y)=u(r\cos \theta , r\sin \theta)$ . We have \begin{align*}
u_r=\frac{\partial u}{\partial x} \frac{\partial x}{\partial r} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial r};\ u_\theta = \frac{\partial u}{\partial x} \frac{\partial x}{\partial \theta} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial \theta}
\end{align*} Use the chain rule to show that \begin{align*}
u_{xx}+u_{yy}=u_{rr}+\frac{1}{r}u_\theta
\end{align*} Attempt: \begin{align*}
x&=r\cos \theta \\
y&=r\sin \theta
\end{align*} \begin{align*}
\frac{\partial x}{\partial r}=\cos \theta && \frac{\partial x}{\partial \theta}=-r\sin \theta \\
\frac{\partial y}{\partial r}=\sin \theta && \frac{\partial y}{\partial \theta}=r\cos \theta
\end{align*} \begin{align*}
u_r&=\frac{\partial u}{\partial x} \frac{\partial x}{\partial r} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial r} \\
&=\frac{\partial u}{\partial x} \cos \theta + \frac{\partial u}{\partial y}\sin \theta \\
&=\cos \theta\frac{\partial u}{\partial x} + \sin \theta \frac{\partial u}{\partial y}
\end{align*} \begin{align*}
u_{rr}&=\cos \theta \frac{\partial }{\partial r}\frac{\partial u}{\partial x} + \sin \theta \frac{\partial }{\partial r}\frac{\partial u}{\partial y} \\
&= \cos \theta \left( \frac{\partial }{\partial x}\frac{\partial u}{\partial x}\frac{\partial x}{\partial r}+\frac{\partial }{\partial y}\frac{\partial u}{\partial x}\frac{\partial y}{\partial r} \right) + \sin \theta \left( \frac{\partial }{\partial x}\frac{\partial u}{\partial y}\frac{\partial x}{\partial r}+\frac{\partial }{\partial y}\frac{\partial u}{\partial y}\frac{\partial y}{\partial r} \right) \\
&=u_{xx}\cos ^2 \theta +u_{xy}2\cos \theta \sin \theta +u_{yy}\sin ^2 \theta 
\end{align*} \begin{align*}
u_\theta &= \frac{\partial u}{\partial x}\frac{\partial x}{\partial \theta}+\frac{\partial u}{\partial y}\frac{\partial y}{\partial \theta} \\
&= \frac{\partial u}{\partial x}(-r\sin \theta)+\frac{\partial u}{\partial y}(r\cos \theta) \\
&=r\cos \theta \frac{\partial u}{\partial y}-r\sin \theta \frac{\partial u}{\partial x}
\end{align*} I already have this, but I don't know how to continue.","['multivariable-calculus', 'vector-analysis']"
4150067,Coarse Moduli space of plane cubics,"I am studying Joe Harris' Algebraic Geometry: A First Course, the section
on Moduli Spaces, pg 278. I am stuck in a subtle point.
Harris gives on p 279 an argument why there is no coarse moduli space
of plane cubics and I not understand this argument: Example 21.12. Plane Cubics The fundamental example of a moduli space is one we
encountered before in Example 10.16, that of plane cubics.
Based on our previous discussion, we see that
even a coarse moduli space does not exist for plane cubics.
This is due to the various inclusions among closures of
orbits of the action of $PGL_3 \ K$ ( $K$ field with $char(K) \neq 2,3$ )n on the space $\mathbb{P}^9$ of plane cubics. For example, if $\mathcal{M}$ is the
set of isomorphism classes of plane cubics, $\mathcal{M}$ will have one point $p$ corresponding to irreducible plane
cubics with a node, and another point $q$ corresponding
to cuspidal cubics. But by what we saw in Example
10.16, the point $q$ would have to lie in the closure of
the point $p$ ! Explantions on terminology & references: the coarse moduli space is informally introduced at
pges 278/279 as: Let $\{X_{\alpha}\}$ a collection
of certain varieties (e.g. like genus $g$ curves, etc.).
Then a variety $\mathcal{M}$ is called a coarse moduli space with
respect this collection $\{X_{\alpha}\}$ if as underlying set $\mathcal{M}$ is bijective to
the set of isomorphism classes of $X_{\alpha}$ . for any reduced family $\pi: \mathcal{V} \to B$ (ie a flat surjection such that the general fiber
is reduced) such that
every fiber $\pi^{-1}(b) = X_b $ is a member of the
collection $\{X_{\alpha}\}$ the canonical set-theoretic map $$ \phi_{\pi}: B \to \mathcal{M} $$ given by sending each point $b \in B$ to the point of $\mathcal{M}$ representing the isomorphism
class $[X_b]$ of the fiber $X_b$ over $b$ is a regular map . Above is also refered to Example 10.16. ( How $PGL_3 \ K$ Acts on $\mathbb{P}^9$ ) (page 121). It states that
for base field $K$ with $char(K) \neq 2,3$ there exist
a natural action of $PGL_3 \ K$ on the space
of cubic polynomials on $\mathbb{P}^2$ . The interesting result was that this action has
some interesting closure relationships among diverse orbits under this action. For example
the orbit consisting of smooth cubics with $j$ -invariant $j$ contains in its closure
the locus of cuspidal cubics (i.e., the orbit of cubics
projectively equivalent to $Y^2Z - X^3$ ). This also implies that as stated above
that the closure of the orbit of point $p$ corresponding
to irreducible plane cubics with a node
contains point $q$ corresponding
to cuspidal cubic. Question : Why this observation heuristically
indicates that if $q \in \overline{ \{p \} } \subset 
\mathcal{M}$ then $\mathcal{M}$ cannot be
a coarse moduli space of plane cubics? (and therefore a coarse moduli space of plane cubics not exist)","['algebraic-curves', 'plane-curves', 'algebraic-geometry', 'moduli-space']"
4150075,Show that the function $f$ has pole of order 1,"Problem: Show that the holomorphic function $f$ , $$\frac{z-\pi}{(e^{iz}+1)^2}:D'(\pi;2\pi)\rightarrow \mathbb{C}$$ has a pole of order 1 at the point $\pi$ . This might be really simple but I cannot show that this has pole of order 1 but rather pole order 2, since the denominater is raised to the power of 2? Or am I wrong? When trying to show that it has a pole of order 1 I end with 0/0 but maybe this is sufficient and that 0/0 can be 1 if we compute the limit for $z\rightarrow\pi$ ? I hope someone can clear this up for me. Notice that this is not homework. I'm just trying to get a better understanding of holomorphic functions. Thanks in advance.","['complex-analysis', 'singularity']"
4150078,Question on the distribution of the values of $f(x)=\sum\limits_{n=1}^x a(n)$ where $a(n)=\sum\limits_{d|n}\mu(d)\ \mu\left(\frac{n}{d}\right)$,"Consider the function $a(n)$ defined in formula (1) below and it's summatory function $f(x)$ defined in formula (2) below where $f(x)$ is related to the Riemann zeta function $\zeta(s)$ as illustrated in formula (3) below. $$a(n)=\sum\limits_{d|n}\mu(d)\ \mu\left(\frac{n}{d}\right)\tag{1}$$ $$f(x)=\sum\limits_{n=1}^x a(n)\tag{2}$$ $$F(s)=s\int_0^\infty f(x)\ x^{-s-1}\ ds=\underset{N\to\infty}{\text{lim}}\left(\sum_{n=1}^N a(n)\ n^{-s}\right)=\frac{1}{\zeta(s)^2}\ ,\quad\Re(s)>1\tag{3}$$ The following list illustrates the values taken on by $f(x)$ at the first $100$ positive integer values of $x$ . Note that $f(x)$ jumps around more than Mertens function $M(x)=\sum\limits_{n=1}^x \mu(n)$ which only ever takes a step of $\pm 1$ . $\{1,-1,-3,-2,-4,0,-2,-2,-1,3,1,-1,-3,1,5,5,3,1,-1,-3,1,5,3,3,4,8,8,6,4,-4,-6,-6,-2,2,6,7,5,9,13,13,11,3,1,-1,-3,1,-1,-1,0,-2,2,0,-2,-2,2,2,6,10,8,12,10,14,12,12,16,8,6,4,8,0,-2,-2,-4,0,-2,-4,0,-8,-10,-10,-10,-6,-8,-4,0,4,8,8,6,10,14,12,16,20,24,24,22,20,18,19\}$ Figure (1) below illustrates a discrete plot of the number of times $f(x)=k$ when $x$ is an integer in the range $0<x\le 10000$ . In Figure (1) below, $k$ is the horizontal axis and the number of times $f(x)=k$ is the vertical axis. Figure (1) : Illustration of counts of $f(x)=k$ when $0<x\le 10000$ Assuming $x\in\mathbb{Z}_{>0}$ , I'm wondering if $f(x)=k$ an infinite number of times for every integer $k$ as $x\to\infty$ . I'm particularly interested in whether $f(x)=0$ and $f(x)=4$ an infinite number of times as $x\to\infty$ (for reasons that will become apparent in a question I'm planning on posting in the near future). Question : Is it true that $f(x)=k$ at an infinite number of positive integers $x$ for every integer $k$ ? If this is too hard a question, is it true that $f(x)=0$ and $f(x)=4$ both at an infinite number of positive integers $x$ ?","['riemann-zeta', 'number-theory', 'dirichlet-series', 'arithmetic-functions']"
4150083,What are some applications of projective Fraïssé limits?,"I am looking for some applications of projective Fraïssé limits . For example are they related to a theorem in set theory or topology?
Also is there any modified version for them? (like the version of Hrushovski for Fraïssé limits which led to counterexample to Zilber's conjecture?) Would you please explain some about their importance?","['limits', 'model-theory', 'logic', 'applications']"
4150096,Derivative of a vector field is anti-symmetric $\iff$ $dF_t(p)$ is an isometry,"Let $F$ a complete vector field of class $C^1$ in $\Bbb{R}^n$ . I need to show that $dF(p)$ is an anti-symmetric matrix $\iff dF_t(p)$ is an isometry, that is $$\left<dF_t(p)u,dF_t(p)v\right>=\left<u,v\right>\forall\, t\in\Bbb{R}, p,u,v\in\Bbb{R}^n. $$ Here, $F_t(p)$ is the trajectory of $F$ passing through $p$ . I found some answers, like this one, where $F$ is a linear field. In that case, $F_t(p)$ is just an exponential matrix, and all goes fine. But I couldn't addapt the proof for the non linear case. If someone could give me some hints (not the complete answer) I would appreciate.","['vector-fields', 'isometry', 'ordinary-differential-equations']"
4150119,Show that $A \subset B \implies \overline{A} \subset \overline{B}$,"NOTE: I know that a question asking for help to prove this same property already exists, but I would like an answer specifically based on the definition(s) and / or  remark below, please. Definition 1 : A point $x \in \mathbb{R}$ is a point of closure of a set $E \subset \mathbb{R}$ if $\quad \forall \ \delta>0,\; \ \exists \ y \in E \ \;$ s.t. $ \ |x-y| < \delta$ . Equivalently, $x$ is a point of closure of $E$ if every open interval containing $x$ also contains a point of $E.$ We call the set of all points of E the closure of $E$ and denote it by $\overline{E}.$ Remark: Every point in $E$ belongs to its closure. Particularly, $E \subset \overline{E}$ . Definition 2 : $E$ is closed if $E=\overline{E}$ . Question: Show that $A \subset B \implies \overline{A} \subset \overline{B}$ . Attempt: $A \subset B \implies A \subset B \subset \overline{B} \implies A \subset \overline{B}$ . If $A$ is closed then $A= \overline{A} \implies \overline{A} \subset \overline{B}.$ So I can do this when $A$ is closed but I'm not certain on how to use either of the definitions / remark to show that it holds when $A$ is open.",['real-analysis']
4150138,How to solve this limit related to series [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need just an idea to solve the following limit? I tried everything without success $\lim_{N\rightarrow+\infty}\frac{1}{N}\sum_{k=1}^{N-1} \left(\frac{k}{k+1}\right)^N$ Source https://artofproblemsolving.com/community/c7h495716p2783297","['limits', 'sequences-and-series']"
4150159,Is there a prime of the form 711...117?,"The integers $$77,\,717,\,7117,\,71117,\,711117,\,\ldots$$ appear to all be composite. However, the lack of a small covering set suggests that there might eventually be a prime. Algebraically, these numbers are given by $$a_k=\frac{10^k\cdot64+53}{9}$$ for $k\geq1$ . Here is some partial progress: A computer search confirms that $a_k$ is composite for all $1\leq k\leq5000$ . Even though there isn't a full covering set, you can still narrow down the possibilities for $k$ . For example, looking modulo the primes $\{3,11,13\}$ shows that if $a_k$ is prime then $k\equiv4\pmod{6}$ .","['number-theory', 'elementary-number-theory', 'prime-numbers']"
4150161,How can I solve this differential equation $x(x+1)y' + y = \arctan(x)$?,"I've been trying to solve this differential equation: $x(x+1)y' + y = \arctan(x)$ and that is a linear differential equation after a small reform: $y' + \frac{1}{x(x+1)} y = \frac{\arctan(x)}{x(x+1)}$ . What I did was try using an integrating factor $u(x) = \exp(\int{\frac{1}{x(x+1)}})$ and I found $u(x)=\exp(
−
\ln
(
∣
\frac{1}{x}
+
C|)$ the general solution of the differential equation is expressed as : $y = \frac{{\int {u\left( x \right)f\left( x \right)dx} + C}}{{u\left( x \right)}}$ , where $f(x)=\frac{\arctan(x)}{x(x+1)}$ and $C$ is an arbitrary constant.
But I don't think I can do any more than this, is there a way I can get to find it ?","['calculus', 'ordinary-differential-equations']"
4150187,Gradient of log of norm of a matrix,"I am working on an optimization problem where I need the gradient $\nabla f(X)$ of $f(X) = log(||TX-Y||^2)$ , where X is a vector. My attempt is $\nabla f(X) = 
\frac {\nabla  ||TX-Y||^2}{||TX-Y||^2}  = 
\frac {2(TX-Y)^TT}{||TX-Y||^2}$ . Am I correct ?","['gradient-descent', 'derivatives']"
4150278,Graduate level linear algebra?,"Basically, I have a few related questions. The first one may seem a little naive, so please forgive me. Is there much linear algebra to be taught beyond the level of books like Axler or Friedberg, Insel, and Spence? Is linear algebra typically taught beyond this advanced undergraduate/early graduate level, or would it just start to become abstract algebra and/or functional analysis? If linear algebra is indeed taught at the graduate level, I would love some recommendations for some of the most commonly used textbooks. I hope I phrased my question clearly and correctly, this is my first time posting here.","['linear-algebra', 'book-recommendation']"
4150296,Fairly rigorous multivariable calculus books,"I'm looking for recommendations for a multivariable calculus book at a somewhat sophisticated level; somewhere between Stewart's Calculus and Munkres' Analysis on Manifolds . I'll have a background in single variable calculus and the typical material from a basic ""proofs"" class (set theory, logic, proof techniques, some topics in discrete math). This will be my first formal exposure to multivariable calculus beyond some reading I've done for fun. Note that, although I'll have some mathematical maturity and some background in proof-writing, I'll have learned single variable calculus from Stewart, obviously not a very rigorous book. Let me know if you think it's really necessary that I read a more sophisticated calculus text (like Spivak's Calculus ) before moving on to multivariable calculus at the level that I'm describing. I think a book like Spivak's Calculus on Manifolds or Apostol's Calculus, Vol. 2 would be what I'm looking for. Of these two, I think I'd slightly prefer using Spivak since I'm interested in differential geometry and I like the idea of introducing manifolds in multivariable calculus. I hope this gives some idea of the kind of book I'm looking for. I don't want something crazy rigorous, but definitely something more sophisticated than a typical computational calculus book.","['multivariable-calculus', 'book-recommendation']"
4150325,The integral : $\frac{1}{2}\int_0^\infty x^n \operatorname{sech}(x)\mathrm dx$,"How can I evaluate $$\frac{1}{2}\int_0^\infty x^n \operatorname{sech}(x)\mathrm dx?$$ I was trying integration by parts but it seemed like it is getting more complicated. $$\int_0^\infty x^n \operatorname{sech}(x)\mathrm dx=\left.2x^n\arctan\left(\tanh(x/2)\right)\right|_0^\infty-2n\int_0^\infty x^{n-1}\arctan(\tanh(x/2))\mathrm dx$$ Herein, it seems like we have to apply integration by parts $n$ times but it is not practically possible. This question is a more general problem of the integral $\int_0^\infty \frac{x}{e^x+e^{-x}}\mathrm dx$ , which I was first solving.
Let me know if there's any other method for evaluating this integral. It will be highly appreciated. I have posted my solution employing a method using Geometric series to which this Wikipedia article helped me in finding the solution.
Please see my answer below.","['integration', 'improper-integrals', 'complex-analysis', 'calculus', 'trigonometric-integrals']"
4150349,Prove that $\sum_{n=1}^{\infty}\frac{1}{n^{2}} = \frac{\pi^{2}}{6}$,"The goal is to prove for equality: \begin{equation*}
     \sum_{n = 1}^{\infty} \frac{1}{n^{2}}=\frac{\pi^{2}}{6} \end{equation*} To do this, follow the steps below: Study the poles of the function $\phi(z) = \frac{\pi\cos(\pi z)}{\sin(\pi z)}$ . Find an expression for the integral $$\int_{C_{N}} \frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}$$ , where $C_{N}$ is a curve
that encloses the integer up until $\pm N$ . Considering $C_{N}$ as the rectangle with vertices $\pm(N+1/2)\pm(N+1/2)i$ , prove that $$\lim_{N\to\infty}\int_{C_{N}}\frac{\phi(z)}{z^{2}}dz=0$$ Conclude. What i try is The dist thing is to note that the set of poles on $C_{N}$ is: \begin{equation*}
    \mathcal{P}(N) = \{k : |k|\leq N\}
\end{equation*} then I note that the residue on $k=0$ is: \begin{equation*}
    \begin{split}
        \text{Res}\left(\phi,k=0\right) 
        &=      \lim_{z\to 0}(z-0)\phi(z)\\
        &=      \lim_{z\to0}(z-0)\cdot\frac{\pi\cos(\pi z)}{\sin(\pi z)}\\
        &=      \lim_{z\to0}\cos(\pi z)\cdot\frac{\pi x}{\sin(\pi z)}=1\\
    \end{split}
\end{equation*} To calculate the integral \begin{equation*}
    \int_{C_{N}}\frac{\phi(z)}{z^{2}}dz = \int_{C_{N}}\frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}dz
\end{equation*} whe can see that the pole is of order, meanwhile the other poles are simple, then: \begin{eqnarray*}
    \frac{1}{2\pi i}\int_{C_{N}}\frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}dz
    & = &   \sum_{k=-N}^{N}\text{Res}\left(\frac{\phi(z)}{z^{2}},k\right)\\
    & = &   \text{Res}\left(\frac{\phi(z)}{z^{2}},0\right)+\sum_{k=-N,k\neq0}^{N}\text{Res}\left(\frac{\phi(z)}{z^{2}},k\right)\\
    & = & \lim_{z\to0}\frac{1}{2!}\frac{d^{2}}{dz^{2}}\left[(z-0)^{3}\frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}\right]+\sum_{k=-N,k\neq0}^{N}\text{Res}\left(\frac{\phi(z)}{z^{2}},k\right)
\end{eqnarray*} \begin{eqnarray*}
            \text{Res}\left(\frac{\phi(z)}{z^{2}},k\right)
            & = &   \lim_{z\to k}(z-k)\frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}\\
            & = &   \frac{1}{k^2}\lim_{z\to k}(z-k)\frac{\pi\cos(\pi z)}{\sin(\pi z)}\\
            & = &   \frac{1}{k^2}\lim_{z\to k}\frac{\pi\cos(\pi z) - (z-k)\pi^{2}\sin(\pi z)}{\pi\cos(\pi z)}\\
            & = &   \frac{1}{k^2}\lim_{z\to k}  \left(\frac{\pi\cos(\pi z)}{\pi\cos(\pi z)}-\frac{(z-k)\pi^{2}\sin(\pi z)}{\pi\cos(\pi z)}\right) = \frac{1}{k^{2}}\\
        \end{eqnarray*} Entonces \begin{equation*}
            \frac{1}{2\pi i}\int_{C_{N}}\frac{\pi\cos(\pi z)}{z^{2}\sin(\pi z)}dz = \text{Res}\left(\frac{\phi(z)}{z},0\right) + \sum_{\begin{subarray}{c}k=-N\\k\neq0\end{subarray}}^{N}\frac{1}{k^{2}}
        \end{equation*} and \begin{equation*}
\cot(z) = \frac{1}{z} - \frac{z}{3}-\frac{z^{3}}{45}+o(z^{5})
\end{equation*} with this we calculate $$\text{Res}\left(\frac{\phi(z)}{z^{2}},0\right)=\text{Res}\left(\frac{\pi\cot(z)}{z^{2}},0\right)$$ On the other side: \begin{equation*}
\cot(\pi z) = \frac{\cos(\pi z)}{\sin(\pi z)} = i\frac{e^{\pi i z} + e^{-\pi i z}}{e^{\pi i z} - e^{-\pi i z}} = i\frac{e^{2\pi i z} + 1}{e^{2\pi i z} - 1}
\end{equation*} as $|\cot(\pi z)|<2$ , then \begin{eqnarray*}
\left|\int_{C_{N}}\frac{\phi(z)}{z^{2}}dz\right|
& \leq &   \int_{C_{N}}\left|\frac{\phi(z)}{z^{2}}\right|dz\\
& \leq &   \int_{C_{N}}\left|\frac{2\pi}{z^{2}}\right|dz\\
& \leq &   |2\pi|\int_{C_{N}}\frac{1}{\left|z^{2}\right|}dz\\
& \leq &   2\pi\max_{z\in C_{N}}\left(\frac{1}{z^{2}}\right)\cdot L(C_{N})\\
\end{eqnarray*} Could someone help me with this part (3)?","['complex-analysis', 'complex-integration', 'sequences-and-series']"
4150371,How to find the product distribution of two independent random variable with own distribution,"How to find the distribution function of $G$ given as $f_G(g)$ , where $G = XY$ where $X$ and $Y$ are independent random variable with given pdf as $f_X(x) = \frac{2x^{-\left(\frac{n +4}{n+2}\right)}}{(n + 2) r^2}$ , $x \in [\left(l^2 + r^2\right)^{-\frac{n +2}{2}}, l^{-(n+ 2)}]$ , Assuming $x_{min} = \left(l^2 + r^2\right)^{-\frac{n +2}{2}}$ and $x_{max}= l^{-(n+ 2)}$ . Furhter, $f_Y(y) = \frac{1}{\pi \sqrt{1 - y^2}}$ , $y \in [-1, 1]$ . Here $n, r, l$ are some parameter constant. To find pdf of $G$ I have followed Product distribution As $-1 < y < 1$ and $\frac{z}{x_{max}} < y < \frac{z}{x_{min}}$ . Also, $z \in \left[-x_{max}, x_{max}\right]$ Hence employing Product distribution $f_G(g) = \int_{max\left\{-1,\frac{z}{x_{max}}\right\}}^{min\left\{1,\frac{z}{x_{min}}\right\}} f_Y(y)f_X(\frac{z}{y})\frac{1}{y}\,dy$ . Then after solving I found $f_G(g)$ as $f_G(g) = \frac{2g^{-\left(\frac{n + 4}{n+2}\right)}\left[\beta\left\{\left(1 + \frac{r^2}{l^2}\right)^{(n +2)}, \frac{n+4}{n +2},\frac{1}{2}\right\}-\beta\left\{\frac{n+4}{n +2},\frac{1}{2}\right\}\right]}{\pi(n +2)r^2}$ with $g \in [-l^{-(n+2)}, l^{-(n +2)}]$ . However, problem is when integrating the pdf of $G$ over its range it is not coming as $1$ . Can anyone please provide where I have gone wrong? I guess the limit in the integration of integrant $y$ is wrong can anyone please correct me.","['statistics', 'probability-distributions', 'random-variables']"
4150395,"Show that there exists $\varepsilon >0$ such that for each $x \in X$, the open ball $B(x, \varepsilon)$ is contained in one of the sets in open cover","Let $\{V_\alpha\}_{\alpha \in A}$ be a finite open cover of a compact metric space $X$ . Show that there exists $\varepsilon >0$ such that for each $x \in X$ , the open ball $B(x, \varepsilon)$ is contained in one of the $V_\alpha$ 's Since $\{V_\alpha\}_{\alpha \in A}$ is a cover for $X$ we have that $X= \bigcup_{\alpha} V_\alpha.$ This implies that $x \in X$ is also in the union $\bigcup_{\alpha} V_\alpha$ . So $x$ is in some of the $V_i$ 's. Now for each of $V_i$ 's since they're open there exists $\varepsilon_i$ such that $B(x,\varepsilon_i) \subset V_i.$ If I now let $\varepsilon = \min\{\varepsilon_1, \varepsilon_2, \dots, \varepsilon_i\}$ then I have that at least $x \in \bigcup_i V_i$ . I feel like I'm not in the right direction here. I've seen this done by a contradiction, but I'm trying to find what's the problem with this approach. It seems that I've only showed that $x$ will be in the union of the $V_i$ 's by taking the minimum of the epsilon's, but $x$ was already in the $V_i$ 's by the fact that $x \in\bigcup_{\alpha} V_\alpha$ so of course it would be in the union. What should I do here? Edit: This is the contradiction argument. Assume such $\varepsilon$ doesn't exist. Then for every $\varepsilon >0$ there is an $x \in X$ such that $B(x, \varepsilon)$ is not in any $V_\alpha.$ Now for every $n \in \mathbb{N}$ we can choose $x_n \in X$ such that $B(x_n, \frac1n)$ is not in $V_\alpha$ for any $\alpha$ . But since $X$ is compact there is a limit point $a \in X$ and since the $V_\alpha$ 's for a cover for $X$ , then $a \in V_\alpha$ for some $\alpha$ . And from here looking at $B(a, r)$ we can find a contradiction. I'm confused about the fact that we somehow suddenly jump to sequences here in the part ""Now for every $n \in \mathbb{N}$ we can choose $x_n \in X$ such that $B(x_n, \frac1n)$ is not in $V_\alpha$ for any $\alpha$ "" what's going on there?","['general-topology', 'metric-spaces', 'real-analysis']"
4150474,Quasi-isometric Classification of Free Products of Surface Groups,"Let $S_g$ denote the compact surface with $g$ holes, and denote its fundamental group as \begin{equation}
    \Sigma_g=\pi_1(S_g)=\left<a_1,b_1...,a_g,b_g\Big| \prod_{ i \in \{1,...,g\}} [a_i,b_i]\right>.
\end{equation} In particular, we have that $\Sigma_1 = \mathbb{Z}^2$ . There are two tools I use for the proof. First we have that for $g\geq 2$ , the group $\Sigma_g$ is quasi-isometric to $\Sigma_2$ (this I already understand, see https://math.stackexchange.com/q/2818142 and my following remark about coverings). Secondly, if we can find that two groups are commensurable, then they are quasi-isometric (this means we can pass by finite index subgroups). An equivalent way to use this is by defining finite-degree covering maps between two surfaces. Here I shall mention the equality: $$\pi_1 (S)*\pi_1 (S')=\pi_1 (S\vee S').$$ I try to proof that a free product $$G = \Sigma_{g_1}*\dots \Sigma_{g_n}=\coprod_{i=1}^n \Sigma_{g_i}$$ is quasi-isometric to one of following five groups: $\mathbb{Z}^2 , \Sigma_2,  \mathbb{Z}^2* \mathbb{Z}^2, \mathbb{Z}^2* \Sigma_2, \Sigma_2* \Sigma_2$ . This way we can show that $\mathbb{Z}^2*...* \mathbb{Z}^2$ is quasi-isometric to $ \mathbb{Z}^2* \mathbb{Z}^2$ . $\Sigma_2*...* \Sigma_2$ is quasi-isometric to $ \Sigma_2* \Sigma_2$ . $\Sigma_2*...* \Sigma_2 * \mathbb{Z}^2*...* \mathbb{Z}^2$ is quasi-isometric to $ \Sigma_2* \mathbb{Z}^2$ . This is where I am stuck. These three equivalences should be proven by showing the two groups are finite index subgroups of each other (note that $\Sigma_2$ can be replaced by $\Sigma_g$ at any time). An indirect way to show these are finite index subgroups of each other, is by defining a finite-degree covering map from one to the other. If I remember well this is due to the Seifert–Van Kampen theorem. This question and many insights of for a proof are based on the paper ""Amenability, bilipschitz equivalence, and the von Neumann conjecture"" by Kevin White. Edit: I imagine there are many ways to prove this. I wish to thank Lee Mosher for his solution, but I have the impression that Kevin White uses more elementary arguments. Probably, that is why he adds no reference to the proof. In my opinion, he seems to imply easy subgroups can be found. Here is his proof.","['geometric-group-theory', 'group-theory', 'fundamental-groups']"
4150478,Minimizing $|x-1|+|x-2|+|x-3|+...+ |x-2019|+ |x-2020|$.,"The given expression $$
|x-1|+|x-2|+|x-3|+...+ |x-2019|+ |x-2020|
$$ determine the greatest interval of real numbers $[a,b]$ on which the given expression has a constant value $k$ . What is the value of $k$ ? I found this question in a facebook group's post. I tried a lot to understand the question. But I didn't understand it at all. A user send answer like that $a=1000$ , $b=1001$ and $k=1000000$ . But I don't understand why and how it comes.","['optimization', 'algebra-precalculus', 'problem-solving']"
4150486,Filtering Non-abelian groups of fixed order in GAP [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 3 years ago . Improve this question I was learning GAP commands for operations on groups. I needed to consider non-abelian groups for simplicity in computation. The command Filtered is useful to find out abelian groups in the following way: S:=Filtered(AllSmallGroups(16), G -> IsAbelian(G)); This returns a list of abelian groups of order 16. However, there is no direct replacement of IsAbelian(G) to IsNonAbelian(G) [wrong command]. I tried to write following: S:=Filtered(AllSmallGroups(16), G -> IsAbelian(G)=false); This returned list containing all groups (of order 16). [ Edit :This command works actually as suggested in answer by Alexander Konovalov.] S:=Filtered(AllSmallGroups(16), G -> IsAbelian(G)==false); This returend an error. How do I modify above commands to get list of non-abelian groups of order $16$ using filtered (I have idea of getting it by for loop; but I am getting it by Filtered if possible).","['gap', 'group-theory']"
4150509,Is there a (nice) closed form solution to $\frac{dP(t)}{dt} = AP(t)+P(t)A^T+R$,"The problem : Consider constant matrices $A,R\in\mathbb{R}^{n\times n}$ . I want to solve: $$
\frac{dP(t)}{dt} = AP(t)+P(t)A^T+R
$$ for $P(t)\in\mathbb{R}^{n\times n}$ . My attempt : note that the differential equation is linear, so up to know I have been able to write $P(t)$ as vector $p(t)\in\mathbb{R}^{n^2}$ using the vectorization operator $p(t):=\text{vec}(P(t))$ from wikipedia which comply: $$
\text{vec}(AB) = (I\otimes A)\text{vec}(B) = (B^T\otimes I)\text{vec}(A)
$$ hence, $$
\begin{aligned}
\text{vec}\left(\frac{dP(t)}{dt}\right) &= \frac{dp(t)}{dt}= \text{vec}(AP(t)) + \text{vec}(P(t)A^T) + \text{vec}(R)\\
&=(I\otimes A)p(t) + (A\otimes I)p(t)+r\\
&=\tilde{A}p(t) + r
\end{aligned}
$$ where $\tilde{A} = (I\otimes A) + (A\otimes I)$ and $r=\text{vec}(R)$ . Then, $$
p(t) = \exp(\tilde{A}t)p(0) + \int_0^t\exp(\tilde{A}(t-\tau))rd\tau
$$ However, I still haven't managed to convert $p(t)$ to $P(t)$ without making a total mess with the components of the matrices of the form $ \exp(\tilde{A}t)$ . I have only been able to ""revert"" the vectorization operation ""by hand"", so that I don't see the pattern in the form of $P(t)$ I obtain. Moreover, I have only been able to do this for a particular value of $n$ ( $n=2, n=3$ ) and I don't see the patter for general $n$ . Is there a way to obtain a more compact closed form solution for $P(t)$ (converting $p(t)$ to $P(t)$ for the general case)? Moreover, my procedure may be totally wrong. In that case, can you suggest the correct path? EDIT : I found this paper here where they obtain: $$
P(t) = \exp(At)P(0)\exp(A^Tt) + \int_0^t\exp(A\tau)R\exp(A^T\tau)d\tau
$$ which is easily verified that it complies the differential equation. However, I still have no clue on how one can derive that solution.","['vectorization', 'linear-algebra', 'ordinary-differential-equations']"
4150517,Sobolev space on composite domain,"Let $\Omega_1$ and $\Omega_2$ be two sufficiently smooth domains in $\mathbb R^2$ . Consider the composite domain $\Omega =Ω_1 \cup Ω_2$ . Also, consider the sobolev space $H_0^1 (Ω)$ .  Let $ Y_1 = H_0^1(Ω_1) $ and $ Y_2 = H_0^1(Ω_2)$ . View $Y_1$ and $Y_2$ as closed subspaces of $H_0^1(Ω)$ (by extending functions on $Ω$ to be  zero.) I am looking for a reference to the fact that $Y_1 + Y_2$ is dense in $H_0^1 (Ω)$ . Thanks for any help.","['sobolev-spaces', 'functional-analysis', 'reference-request']"
4150518,Measurability and $\mathbb P$-a.s. or everywhere,"I have two questions that are quite related: The predictable $\sigma$ -algebra $\mathcal P$ is defined as the smallest $\sigma$ -algebra making all adapted left-continuous processes measurable. Does left-continuity need to be everywhere or does $\mathbb P$ -a.s. also work? If a stochastic process $X:\Omega\times [0,\infty)\to\mathbb R$ (thus, $X(\cdot ,t)$ is a random variable for all $t$ ) is $\mathbb P$ -a.s. continuous, is it jointly measurable? I have seen many related questions like this on StackExchange, but often the usual conditions are not stated, hence my questions have not really been adressed. Therefore, assuming the usual conditions, what are the answers to 1. and 2.? Importantly note: I am aware that $X$ is indistinguishable from a jointly measurable map and that $X:\Omega'\times [0,\infty)\to \mathbb R$ , where $\Omega'=\Omega\backslash N$ with $N$ as below, is jointly measurable. A possible rephrasing of 1 and 2 (in more generality): if $X$ is $\mathcal A$ -measurable, and $Y$ is indistinguishable from $X$ , is $Y$ also $\mathcal A$ -measurable? If this does not hold in generality, then let's get back to 2. My try on 2.: I know $X$ is indistinguishable from a process $Y$ with continuous paths everywhere. Hence let $N$ be the $\mathbb P$ -null on which $X$ and $Y$ do not coincide. We can write $$X^{-1}(A)=(X^{-1}(A)\cap (N\times [0,\infty)))\cup (X^{-1}(A)\cap ((\Omega\backslash N)\times [0,\infty))),$$ where the latter is $\mathcal F\times \mathcal B$ -measurable, but the first part I do not know. Edit: Do a.s. right-continuous paths imply product measurability has a useful answer to part 2.  Then why do we even start with $\mathbb P$ -a.s. caglad and caglad processes, for instance. If I want to look at the Lebesgue-Stieltjes integral $$\int _0^tHdA,$$ then $H$ needs to be jointly measurable, so then we take the version of $H$ that is jointly measurable? Seems like an enormous detour. Also, one often shows the inclusions $$\mathcal P\subset \mathcal O\subset \mathcal M\subset \mathcal B\times \mathcal F,$$ the predictably, optional, progressively, and product sigma algebra. But these are the generating $\sigma$ -algebra where the propery then holds everywhere? Clarification regarding question 1.: What is the correct definition of $\mathcal P$ ? a. $\mathcal P=\sigma(X:X$ is an adapted processes with left-continuous paths everywhere); b. $\mathcal P=\sigma(X:X$ is an adapted processes with left-continuous paths a.e.); Or does a. and b. give the same result? (Do not think so by the way. Can you work with b. in the first place?)","['stochastic-processes', 'measure-theory', 'measurable-functions']"
4150546,"Sequence of independent random variables $X_n$ and $Y_n$ with dependent limits $X$, $Y$","Let $X_1, X_2, ...$ and $Y_1, Y_2, ...$ be sequences of random variables such that $$
X_n \stackrel{d}{\rightarrow} X \quad\text{and}\quad Y_n \stackrel{d}{\rightarrow} Y \quad\text{as}\quad n\rightarrow \infty.
$$ Suppose further that $X_n$ and $Y_n$ are independent for all $n$ . Is it possible to find such sequences so that $X$ and $Y$ are dependent? Context: Up to the last sentence, this is Theorem 6.6.6 in Allan Guts ""An Intermediate Course in Probability"". He makes a point of requiring also that $X$ and $Y$ are independent, before the conclusion of the theorem that $X_n + Y_n \stackrel{d}{\rightarrow} X+Y$ as $n\rightarrow\infty$ . So far as I can see, it is not explicitly used in the proof (using characteristic functions). Anyhow, I was mostly curious to see an example where independence is introduced only in the limit.","['independence', 'probability-theory', 'random-variables']"
4150575,Integration of a Function over 7-Sphere,"Suppose we have $x_1^2 + y_1^2 + x_2^2 + y_2^2 + x_3^2 + y_3^2 + x_4^2 + y_4^2 = 1$ and we define $z_j = x_j + iy_j$ ,  where $j = 1,\,2,\,3,\,4$ . The problem is finding or approximating the following integral (The actual problem is more complex than this !) $$I(k) = \int\limits_{\mathbb{S}^7}|(z_1z_4 - z_2z_3)^k|$$ , where $\mathbb{S}^7$ is a $7$ -Sphere, and the integral is over its Surface measure. The ultimate aim is to find or get an estimate of the ratios of the type $\displaystyle \frac{I(k)}{I(k+1)}$ I have never done an Integration over such a surface, the hypersphere and don't know where to begin. Any hint or any pointers would really help me to get started. (I have been suggested to make use of the fact that the points $x_i$ 's and $y_i$ 's lie on a sphere; hence we can use it to reduce one variable and make use of Fubini's Theorem with proper limits for integration to proceed. But I can't see how to make use of this.) What have I done till now? As the problem say, it would be acceptable if we can approximate the ratios or the integral, so $$|z_1z_4 - z_2z_3| \, \leq \, |z_1z_4| + |z_2z_3| \, = \, |z_1||z_4| + |z_2||z_3|$$ This converts everything into real variables and then I have used Mathematica to calculate this. But the problem is Mathematica gives the solution for small values of $k$ , but as I have to find it for the general case, it is not of much use. Also, I have tried using the spherical coordinates to help with the integral but they make it more complicated. Any pointers on this front are also welcome.","['integration', 'lebesgue-measure', 'harmonic-analysis', 'fubini-tonelli-theorems']"
4150631,Showing that swaps of columns does not affect covariance matrix,"Assume I have the following vector $X^*=(X_1,...,X_p,\tilde X_1, ...,\tilde X_p)$ , with a data matrix $\mathbf{X^*}$ of dimension $n \times 2p$ . The corresponding covariance matrix (lets define it with $G$ ), is given by $G = \begin{bmatrix}
\Sigma & \Sigma -  \operatorname{diag}\{s\} \\
\Sigma -  \operatorname{diag}\{s\} & \Sigma
\end{bmatrix},$ with $\Sigma$ being a $p\times p$ symmetric covariance matrix of $(X_1,...,X_p)$ and also the symmetric covariance matrix of $(\tilde X_1, ...,\tilde X_p)$ . The term $\operatorname{diag}\{s\}$ is simply a diagonal matrix with non-negative entries on the diagonals. Hence, $\Sigma -  \operatorname{diag}\{s\}$ defines the covariances between $(X_1,...,X_p)$ and $(\tilde X_1, ...,\tilde X_p)$ . I want to show that for any column-wise permutation of $(X_1,...,X_p,\tilde X_1, ...,\tilde X_p)$ or more specifically the data matrix $\mathbf{X}^*$ encoded by the permutation matrix $P$ , the covariance matrix $G$ does not change. With a column-wise permutation, I mean for example swapping the first and $p+1$ th entry, which would be $(\tilde X_1, X_2 ..., X_p, X_1, \tilde X_2 ,...,\tilde X_p )$ / swapping the first and p+1th column in $\mathbf{X}^*$ . This should have the same covariance matrix $G$ . I know how to encode a column-wise permutation with a multiplication of permutation matrix $P$ from the right $\mathbf{X} P$ but I don't know how to prove such a statement in general.","['permutations', 'covariance', 'statistics', 'linear-algebra']"
4150634,Rate of convergence in probability - log transform,"Let $C>0$ and $(X_n)$ be a sequence of positive random variables. Assume that $$
|X_n - C| = o_p(r_n^{-1}) \iff r_n|X_n-C|=o_p(1)
$$ for some fixed sequence $(r_n)$ with $r_n \to \infty$ . What can we say about the rate of convergence of the log-transform: $$
|\log(X_n)- \log(C)| = o_p(?).
$$ I guess it depends on $C$ and $(r_n)$ but I can't seem to derive anything useful.","['probability-limit-theorems', 'rate-of-convergence', 'probability-theory']"
4150666,Why is $5x+10=2$ not a proposition?,"Why is $5x+10=2$ not a proposition? My textbook says, ""a proposition is any statement that is true or false and its truth value can be known, unknown, true, false, or a matter of opinion"". By that definition, $5x+10=2$ should be a proposition because the truth value is ""unknown"". I'm trying to submit some answers into my online homework software and it's telling me that $5x+10=2$ is not a proposition. Thanks in advance.","['logic', 'discrete-mathematics']"
4150710,Terminology and notation for a zero-padded restriction of a function,"I am a lowly data analyst, but I like to use standard mathematical terms and notation when possible. Here is the setting: given some function $f : \mathbb{R}^2 \rightarrow \mathbb{R}$ , and some subset $S \subset \mathbb{R}^2$ , I define ""zero-extended restrictions"" of $f$ for each of the two disjoint regions into which I have divided the plane: $$ f_1 : \mathbb{R}^2 \rightarrow \mathbb{R}, \quad f_1(x) = \begin{cases} f(x),  &x \in S \\ 0,  &x \notin S \end{cases} $$ and $$ f_2 : \mathbb{R}^2 \rightarrow \mathbb{R}, \quad f_2(x) = \begin{cases}0,  &x \in S \\ f(x),  &x \notin S \end{cases} $$ $f_1$ and $f_2$ are like restrictions , but not exactly, because I don't want to change the domain, which is still all of $\mathbb{R}^2$ . Crucially, I need equations like $f(x) = f_1(x) + f_2(x)$ to still make sense. Therefore it seems like the restriction notation $f|_S$ would be wrong, i.e. $f_1 \neq f|_S$ . Is there some other concise term or notation to describe these functions $f_1$ and $f_2$ ? Or are they sufficiently unusual creations that I won't make a fool of myself if I coin my own description and notation?","['notation', 'convention', 'functions', 'terminology']"
4150764,Calculating $ \int_{0}^{+\infty} \frac{\cos x \sin \sqrt{1+x^{2}}}{\sqrt{1+x^{2}}} \mathrm{~d} x $,"$$
\int_{0}^{+\infty} \frac{\cos x \sin \sqrt{1+x^{2}}}{\sqrt{1+x^{2}}} \mathrm{~d} x
$$ My idea: let $x = \sinh u$ and $\sqrt{1+x^2} = \cosh u$ then the formula simplified as $$
\int_{0}^{+\infty} \cos({\sinh u)\sin(\cosh u)} \mathrm{~d} u
$$ I use wolframalpha to get $$
\begin{align}
 &\int\cos({\sinh u)\sin(\cosh u)} \mathrm{~d} u \\
 &= 1/2 (-Si(\cosh(u) - \sinh(u)) + Si(\cosh(u) + \sinh(u)))
\end{align}
$$ where $Si(z) = \int_{0}^{z} \frac{\sin x}{x}\mathrm{d}x$ Is there any other answer ? Thank you.","['integration', 'calculus']"
4150766,Estimating the total variation distance between two continuous distributions with identical support,"Say I am given two datasets $S_{\mathcal{Q}}$ and $S_{\mathcal{P}}$ sampled from the continuous distributions $\mathcal{Q}$ and $\mathcal{P}$ respectively. Assume that both $\mathcal{Q}$ and $\mathcal{P}$ have the same support, namely some compact set of $\mathcal{C} \in \mathbb{R}^{d}$ . Is there an efficient way to measure the total variation distance between $P$ and $Q$ using the samples $S_{\mathcal{Q}}$ and $S_{\mathcal{P}}$ ? My first thought was just to perform density estimation then numerical integration. I guess histograms would be efficient as the integration would be cheap. But is there a more efficient way with theoretical guarantees that perhaps avoids density estimation all together?","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
4150829,Convergence in probability of conditional second cross-moment for bivariate stationary process,"Let $(X_t,Y_t)_{t\in\mathbb N}$ be a bivariate real stationary process, and let $\mathcal F_t:=\sigma(Y_s :s\leq t)$ be the filtration generated by $Y_t$ . Assuming the following convergence result $$\frac{1}{T}\sum_{t=1}^T X^2_tY_t^2 \overset{p}{\to} E[X_t^2Y_t^2]<\infty \text{ as } T\to \infty,$$ holds, can I show then that $$\frac{1}{T}\sum_{t=1}^T E[X^2_t|\mathcal F_t]Y^2_t \overset{p}{\to} E[X_t^2Y_t^2] \text{ as } T\to \infty $$ ? (Assume $E[X^2_t]<\infty $ and $Y_t$ bounded). EDIT: This lemma can be found in Bauer's book measure and integration. The lemma implies that we have $\frac{1}{T}\sum_{t=1}^T X^2_tY_t^2 \overset{L^1}{\to} E[X_t^2Y_t^2]\text{ as } T\to \infty$ . We can then almost prove the claim: if we replace $\mathcal F_t$ by $\mathcal F_T$ then for any $\epsilon>0$ we have $$P\bigg[\bigg|\frac{1}{T}\sum_{t=1}^T E[X^2_t|\mathcal F_T]Y_t^2 - E[X_t^2Y_t^2]\bigg|\geq \epsilon\bigg ]$$ $$=P\bigg[\bigg|E\bigg[\frac{1}{T}\sum_{t=1}^T X_t^2Y_t^2 - E[X_t^2Y_t^2] \big|\mathcal F_T\bigg]\bigg|\geq \epsilon\bigg ]$$ $$\leq P\bigg[E\bigg[ \bigg|\frac{1}{T}\sum_{t=1}^T X_t^2Y_t^2 - E[X_t^2Y_t^2] \bigg| \big|\mathcal F_T\bigg]\geq \epsilon\bigg ]$$ $$\leq \frac{1}{\epsilon} E\bigg[ \bigg|\frac{1}{T}\sum_{t=1}^T X_t^2Y_t^2 - E[X_t^2Y_t^2] \bigg|\bigg ] \to 0  \text{ as } T\to \infty,$$ where the first inequality is Jensen's inequality for conditional expectations and the second inequality is because $\epsilon1_A\leq 1_AE\bigg[ \bigg|\frac{1}{T}\sum_{t=1}^T X_t^2Y_t^2 - E[X_t^2Y_t^2] \bigg| \big|\mathcal F_T\bigg]$ with $A=\bigg\{E\bigg[ \bigg|\frac{1}{T}\sum_{t=1}^T X_t^2Y_t^2 - E[X_t^2Y_t^2] \bigg| \big|\mathcal F_T\bigg]\geq \epsilon\bigg\}$ .","['stationary-processes', 'conditional-expectation', 'law-of-large-numbers', 'probability-theory', 'probability']"
4150841,Application of Fatou's Lemma to $H^1$ function,"Suppose $D_1$ is a unit disk in $\mathbb{R}^2$ and $u_n \in H^1(D_1;\mathbb{R})$ . We assume further that $\|u_n\|_{H^1} <1$ and $u_n = 0$ on $A:=\big\{(x_1,x_2) : x_1 \in [-1,1] \hspace{2pt} \text{ and } \hspace{2pt} x_2=0 \big\}$ $\mathcal{H}^1$ -almost everywhere (this is possible by trace theorem). Here $\mathcal{H}^1$ is the one-dimensional Hausdroff measure. It is clear that there is a limiting map $u_\infty \in H^1(D_1;\mathbb{R})$ such that $u_n$ converges to $u_\infty$ weakly in $H^1(D_1)$ , up to a subsequence. By Fatou's Lemma, $$ \int_0^1 \liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr
\leq \liminf_{n} \int_0^1 \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr
<1.$$ Therefore, we can find a positive number $R \in (1/2,1)$ such that $$
\begin{split}
\int_0^{2\pi} |\partial_\theta u_\infty(R,\theta)|^2 R^{-1} d\theta
& \leq\liminf_{n} \int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 R^{-1} d\theta \\
& =\liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 \Big|_{r=R} R d\theta <1.
\end{split}
$$ We can obtain that $$
\int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta < 4 \hspace{10pt} \text{for all $n$ large enough.}\label{1}\tag{1}
$$ My question is, can we also find a positive number $\sigma \in (1/2,1)$ such the above inequality \eqref{1} holds and $u_n=0$ at the point $(\sigma,0)$ for all $n$ large? I am trying to use the equi-continuity of $u_n$ . Using \eqref{1} and the fundamental theorem of calculus, we see that $u_n$ is equi-continuous  on $\partial D_{R}$ . Since $$ | u_n(R,\theta_1) - u_n(R,\theta_2)| \leq |\theta_1 - \theta_2|^{1/2} \left(\int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta\right)^{1/2} < 4 |\theta_1 - \theta_2|^{1/2}.$$ But I do know how to get the desired result.","['sobolev-spaces', 'functional-analysis']"
4150847,What are necessary and sufficient conditions for the natural map between a polynomial ring and the set of polynomial functions to be injective?,"If $R$ is a commutative ring (with unity), $R[X]$ is the polynomial ring, and $R^R$ is the set of $R$ -valued functions on $R$ , then there is a natural homomorphism of $R$ -algebras which sends every polynomial $P$ in $R[X]$ to the polynomial function in $R^R$ that maps $r \mapsto P(r)$ . I want to know if there are any necessary and sufficient conditions that $R$ must satisfy in order for this homomorphism to be injective. In other words, for which rings is it true that if one knows all the values of a polynomial function, then one can uniquely determine the polynomial’s coefficients? So far I have been able to determine that: If $R$ is a zero ring, then $R[X]$ and $R^R$ are singletons and the homomorphism is always injective. If $R$ is a finite, nonzero ring, we have $R = \{r_1, \dots, r_n\}$ , where $n \geq 2$ , and $0 \neq 1$ , and $(X - r_1) \cdot \dots \cdot (X - r_n)$ is a nonzero polynomial which is sent to the zero function in $R^R$ . Thus, the homomorphism is never injective. If $R$ is an infinite ring, then $R$ being an integral domain is a sufficient condition for the homomorphism to be injective, since any polynomial with coefficients in an integral domain will have finitely many roots. However, I cannot come up with any condition on $R$ in the case that $R$ is a infinite ring (not necessarily an integral domain) which is equivalent to this $R$ -algebra homomorphism being injective.","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
4150848,Intermediate problem using Chain Rule,"If $y=\frac{d}{dx} [\sin \sqrt{1+\cos (x)}]$ than, differentiate $x$ . $$\frac{d}{dx} [\sin \sqrt{1+\cos (x)}]$$ $$=\frac{d}{dx} [\sin (1+\cos (x))^{\frac{1}{2}}]$$ $$=\frac{1}{2} \cos (1+\cos (x))^{-\frac{1}{2}} (-\sin x)$$ $$=-\frac{\sin (x)}{2\cos (1+\cos (x))^\frac{1}{2}}$$ I found that the answer is wrong. I found the answer which was solved using $$\frac{dx}{dy}=\frac{dx}{du} \frac{du}{dy} $$ But, I want to figure it out using I was trying to solve above question as I did for this $$\frac{d}{dx}[\tan(x^2+1)]=\sec^2 (x^2+1) \cdot 2x$$","['calculus', 'derivatives']"
4150892,Why doesn't an inscribed cube perfectly sample the surface of a sphere?,"I was curious about ways to sample perfectly dispersed points on the surface of the sphere. This question had some interesting info: Is the Fibonacci lattice the very best way to evenly distribute N points on a sphere? So far it seems that it is the best? https://mathworld.wolfram.com/SphericalCode.html For two points, the points should be at opposite ends of a diameter. For four points, they should be placed at the polyhedron vertices of an inscribed regular tetrahedron. There is no unique best solution for five points since the distance cannot be reduced below that for six points. For six points, they should be placed at the polyhedron vertices of an inscribed regular octahedron. For seven points, the best solution is four equilateral spherical triangles with angles of 80 degrees. For eight points, the best dispersal is NOT the polyhedron vertices of the inscribed cube , but of a square antiprism with equal polyhedron edges. The solution for nine points is eight equilateral spherical triangles with angles of $\cos^{-1}(1/4)$ . For $12$ points, the solution is an inscribed regular icosahedron. I can't comprehend how a platonic solid does not perfectly uniformly sample the sphere surface. Is an intuitive explanation of this fact possible?","['platonic-solids', 'spheres', 'geometry', 'packing-problem']"
4150901,Sublevel sets with boundary of Lebesgue measure zero,"so I was wondering if the following is true: consider two smooth convex functions $f,g: \mathbb{R}^n\to \mathbb{R}$ and consider the sublevel sets \begin{equation}
\{f\leq g\}.
\end{equation} I don't mind assuming compactness, if that's neccesary. If $g$ is either constant or linear then these are convex sets, thus their boundary has Lebesgue measure zero. In general this is true for $g$ concaive, but is it true for smooth convex $g$ ? What if we also assume $g$ strongly convex? If not, could you provide a counterexample?","['measure-theory', 'convex-analysis']"
4150922,Infinity norm inequality,"Let $a_1, a_2, \dots, a_n$ given with $a_i = \pm 1$ . Let $f(x) = \sum_{k=1}^n a_k e^{ikx}$ . I need to prove that $\lVert f \rVert_\infty \geq \sqrt{n}$ where $\lVert f \rVert_\infty$ is defined as the maximum value of $|f|$ in the interval $[0,2\pi]$ . Attempt: I tried experimenting with all $a_i$ being $1$ or $-1$ but I couldn't generalize it. Any hint would be appreciated. No need for the full solution.","['complex-analysis', 'fourier-series', 'fourier-analysis', 'real-analysis']"
4150928,Show that $a_n=\frac{\sqrt{n^{2}+2021n+420}}{\sqrt{n^{3}+2022n+420}}$ is decreasing,"I need to show that the sequence $a_n=\frac{\sqrt{n^{2}+2021n+420}}{\sqrt{n^{3}+2022n+420}}$ is decreasing. I tried showing $a_{n+1}\le a_n$ but it was too messy. I did manage to do it by showing that $f'(x)$ will be negative at some point by taking the limit of the nominator of the derivative to infinity,  but this method was pretty exhausting. I wonder if there a simpler method I just didn't see, and i'd be happy to have it in my ""toolbox"". thanks!","['limits', 'calculus', 'sequences-and-series']"
4150932,"Intersection of the Domain of the Logarithm of the Product of a Sequence of Sine Functions and $[0,1]$","Good afternoon.  I have a couple of questions regarding a problem on the 2010 AMC 12A/AHSME.  it's more on the reasoning of something I was using to try and solve the problem (turned out not to be fruitful).  Here's the question. Let $f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right)$ .  The intersection of the domain of $f$ with the interval $[0,1]$ is a union of disjoint open intervals.  What is $n$ ? I already answered the question ( $n=12$ ).  But the strategy for accomplishing this task on my end was very tedious and got me thinking that there was a better.  I literally graphed and highlighted the domains of the individual sine functions above.  Then, since the argument of the logarithm is a product, the intervals in the domain generated would mean that the product would be positive in a particular open interval $(a,b)\in[0,1]$ when there exists an even number of indexed sine functions where, for a particular $c\in[a,b]$ , $\sin{ck\pi}<0$ .  This made it easy to generate the sets, albeit as i mentioned, quite tedious.  But also, what happens if $k$ is large?  It becomes a massive problem. One of the solutions I was thinking of was to look at the derivative of $f$ and see how many maxes or mins occur.  Since there are swathes of sine functions and each of those functions is composite, and that huge product is in itself the inner function of the broader logarithm, this seemed impossible without a CAS like Mathematica (which I haven't tried yet but will).  So then I thought to transform the function based upon rules of logarithms.  So $$f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right)=\sum_{k=1}^{8}\log_{10}\sin{k\pi x}$$ But this approach doesn't seem to work (and it seems that the rules of logarithms doesn't take into account for the product since the domains of both functions appear to be different).  So outside of a CAS, this again seems like a black hole of problems. My questions are this: 1.  Are there any mathematical papers that can handle the analysis of this type of problem or any generalized function similar to this one?  2.  Are there patterns that emerge for increasing $k$ ?  The number of intervals for the problem in question has the following sequence for $k=1...20$ $$1,1,2,4,6,6,9,12,16,16,21,26,30,32,36,44,54,51,60,68,...$$ I checked the OEIS and there was nothing.  I basically plotted the function in desmos and counted intervals where the function existed and went with that.  I am not 100% convinced that this is the sequence, but if it's not, I don't know where i made my error. Any insight, papers, references, etc are welcome and super helpful.  Thank you in advance. Here is a simple PARI/GP program to calculate the number of intervals in $[0, 1]$ where $\prod_{j=2}^n \sin(j \pi x)$ is positive. It collects the zeros of all factors in a list, sorts them in increasing order and then counts the number of non-degenerate intervals on which the product is positive. P(n) = {
    my (zeros = List());
    for (j=2, n, for (k=1,j-1, listput(zeros, k/j)));
    listput(zeros, 1);
    my (xcoords = vecsort(Vec(zeros)), x = 0, sign = -1, count = 0);
    for(i=1, #xcoords,
        sign = -sign;
        if (xcoords[i] > x && sign == 1, count += 1);
        x = xcoords[i];
    );
    count
};

vector(30, n, P(n)) (You can run it in the PARI/GP online calculator ). Output: %2 = [1, 1, 2, 4, 6, 6, 9, 12, 16, 16, 21, 26, 30, 32, 36, 44, 54, 51, 60, 68, 74, 75, 86, 98, 104, 106, 115, 128, 144, 139]","['logarithms', 'interval-arithmetic', 'reference-request', 'calculus', 'sequences-and-series']"
4150995,"Proving $\left(a^2+b^2\right)^2\geqslant(a+b+c)(a+b-c)(b+c-a)(c+a-b)$ for positive reals $a$, $b$, $c$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Question $5$ of BMO1 $2008$ : For positive real numbers $\;a,\;b,\;c,\;$ prove that $$\left(a^2+b^2\right)^2\geqslant(a+b+c)(a+b-c)(b+c-a)(c+a-b)$$ I noticed that the right side can be grouped, but did not get further.","['contest-math', 'algebra-precalculus']"
4151004,Weak convergence of the vector norm a vector field?,"Suppose $\Omega\subset\mathbb{R}^n$ and $\mathbf{v}^k:\Omega\rightarrow \mathbb{R}^m$ is a sequence of vector fields on $\Omega$ that converges weakly in $L^p(\Omega,\mathbb{R}^m)$ to $\mathbf{v}$ . Does the vector (finite-dimensional) norm, i.e. $\left\lvert\mathbf{v}^k\right\rvert:\Omega\rightarrow\mathbb{R}$ converge weakly in $L^p(\Omega)$ to $\left\lvert\mathbf{v}\right\rvert$ ?","['lp-spaces', 'functional-analysis', 'weak-convergence', 'real-analysis']"
4151046,A group orbit/Burnside's lemma question,"Consider a set $X$ of $9$ dots arranged in a $3 \times 3$ grid. Let $H$ be the group generated by the permutations on the rows of $X$ and by the permutations on the columns of $X$ . I am asked: How many elements are in $H$ ? What cycle types appear in $H$ ? How many elements in $H$ belong to each cycle type? If the $9$ elements in $X$ are colored $3$ each red, white and blue, how many ways can we color $X$ , where two colorings are the same if we can move from one coloring to another through operations in $H$ ? I have only a few ideas: The group $H$ will be something like $S_3 \times S_3$ , because we can permute rows and columns, so that should give me 36 elements in $H$ . This clearly looks like I'm supposed to apply Burnside's Lemma. The group acting  will be $H$ . But I'm not too sure about the rest. I need to count the number of fixed points for every element in $H$ . Thanks.","['group-actions', 'group-theory', 'abstract-algebra']"
4151062,How to do statistic test if I know only one changed parameter?,"I have next condition of some study.
We have 15 dogs that passed some test before specific therapy and after one week of therapy its passed it again and 13 pets had positive dynamic and participants with positive effect be the random variable Y. $Y_{obs}$ is 13 First I need establish $H_0$ and alternative hypotheses.
My $H_0$ that nothing changed and alternative that therapy has positive effect to the participants. Can I establish $H_a$ that mean generally changed or in this case only that the therapy has positive effect? Next I should describe distribution. My guess that it is binomial with equal probability. The therapy has positive effect or don't have. Then I should give answer does therapy has effect or not with significant level 1%. And here if it binomial distribution I use mean = np and std $=\sqrt{npq}$ Thank you friends!","['statistics', 'probability']"
4151067,Simplifying $\left({\sqrt{x} + \frac{1}{\sqrt{x}}}\right)^2 - \left({\sqrt{x} - \frac{1}{\sqrt{x}}}\right)^2 $,"Hi can someone help me please simplify the following showing the working out step by step? $$
\left({\sqrt{x} + \frac{1}{\sqrt{x}}}\right)^2 - \left({\sqrt{x} - \frac{1}{\sqrt{x}}}\right)^2 
$$ I can't get the answer matching the text book but I'd also like to get an idea of the most idiomatic way to solve it in terms of steps. What I attempt to do based on what I've learned so far is to: try and simplify the contents of the parens using conjugate and then LCM then square then handle the subtraction. But my answer ends up incorrect. So even steps just to simplify say the left hand term (without the squaring step) would be helpful. My simplifying the left hand looks like: Use Conjugate: $$
\left(\sqrt{x} + \frac{(1)(\sqrt{x})}{(\sqrt{x})(\sqrt{x})}\right)^2
$$ $$
\left(\sqrt{x} + \frac{(\sqrt{x})}{x}\right)^2
$$ Use LCM: $$
\left(\frac{(\sqrt{x})(x)}{x} + \frac{(\sqrt{x})}{x}\right)^2
$$ $$
\left(\frac{(x)(\sqrt{x}) + \sqrt{x}}{x}\right)^2
$$ Then I'm not sure next best step.",['algebra-precalculus']
4151108,Distance between two states in a C$^*$-algebra,"$\def\h{\mathcal H}$ $\def\bh{\mathcal B(\h)}$ $\def\cA{\mathcal A}$ Let $\h$ be a Hilbert space, and $\xi,\eta\in\h$ with $\|\xi\|=\|\eta\|=1$ . Then $$
\phi(A)=\langle A\xi,\xi\rangle,\qquad \psi(A)=\langle A\eta,\eta\rangle
$$ are (pure) states on $\bh$ . We are looking for a proof that $$\tag{$*$}
\|\phi-\psi\|=2\sqrt{1-|\langle\xi,\eta\rangle|^2}.
$$ While $(*)$ is well-known,
I couldn't find a proof in the literature available to me. So I'm posting a proof below.","['von-neumann-algebras', 'c-star-algebras', 'functional-analysis', 'operator-algebras']"
4151110,Existence of a number using Borel-Cantelli,"Let $\{a_n\}_{n=1}^\infty$ be a sequence of real numbers in $[0,1]$ and let $\{b_n\}_{n=1}^\infty$ be a sequence of positive real numbers such that $\sum_{n=1}^\infty b_n<\infty$ . Show that there exists a number $x\in[0,1]$ such that: $$\sum_{n=1}^\infty\frac{b_n^2}{|x-a_n|}<\infty$$ My attempt was to let $X\sim U[0,1]$ be a random variable and define events which will allow me to use Borel-Cantelli lemma. However, those are only ideas and I wasn't able to make a lot of progress. I'll appreciate any help!","['borel-cantelli-lemmas', 'sequences-and-series', 'probability-theory', 'real-analysis']"
4151122,"Prove $f: \mathbb{R}^{2} \to \mathbb{R}$ has directional derivatives in $(0,0)$ but is not differentiable at $(0,0)$.","Let $$f(x,y) = \begin{cases} \frac{2x^2y}{x^{2}+y^{2}}, & \mbox{if } (x,y) \neq (0,0) ,  \\ 0, & \mbox{if } (x,y) =(0,0)\end{cases}$$ be a function from $\mathbb{R}^{2}$ to $\mathbb{R}$ . Prove that in $(0,0)$ the function $f$ has directional derivatives in all directions. But $f$ is not differentiable in $(0,0)$ . For the first question  I try to show that for $v=(x,y)$ and $t \in \mathbb{R}$ : $$D_{v}(f)=lim_{t \to 0} \frac{f(0+tv)-f(0)}{t}$$ . exist. This proves directional derivatives that in $(0,0)$ directional derivatives exist in any direction right? But I cant prove this limit is $0$ . So far: $$\frac{f(0+tv)-f(0)}{t}=\frac{f(tv)}{t}=\frac{f(tx,ty)}{t}=\frac{\frac{2(tx)^{2}(ty)}{(tx)^{2}+(ty)^{2}}}{t}=\frac{2x^{2}y}{x^{2}+y^{2}}.$$ Then $D_{v}(f)=lim_{t \to 0} \frac{f(0+tv)-f(0)}{t}$ exist and is equal to the constant $\frac{2x^{2}y}{x^{2}+y^{2}}$ . This proves directional derivatives exist in $(0,0)$ in all directions. In order to show that $f$ is not differentiable in $(0,0)$ , I attempted to prove $f$ is not continuous at $(0,0)$ . But cant find the path to prove this, for instance $$lim_{t \to 0}f(t,t)=lim_{t \to 0} t=0=f(0,0)$$ also tried $$lim_{t \to 0}f(t^{3},t)=lim_{t \to 0} t^{3}=0=f(0,0)$$ .","['real-analysis', 'continuity', 'multivariable-calculus', 'calculus', 'derivatives']"
4151123,The Jordan Canonical Form of linear operator in two variables polynomial,"I've been trying to solve the following exercise, In the space of bivariate polynomials of the form $f(x,y)=\sum_{n,m=0}^2a_{n,m}x^ny^m$ , the lineal operator $T$ is defined by $Tf(x,y)=f(x+1,y+1)$ . Obtain a Jordan Canonical Form of T I think i've made considerable progress, but I'm concerned i am taking the longest path, and i would like to know if there exist an easy way. Let $V$ be the space of bivariate polynomials of degree at most 4, I've done the following, First, I expressed the operator as $$Tf(x,y)=\sum_{m=0}^2(y+1)^m\left[(a_{0,m}+a_{1,m}+a_{2,m})+ x(a_{1,m}+2a_{2,m})+x^2a_{2,m}\right]$$ Then I observed that whenever $T$ is applied to a function $f$ in $V$ , then the non-zero coefficients of the same degree as the polynomial (non-zero coefficients with maximum $n+m$ ) remain the same. This implies that the only possible eigenvalue is $\lambda=1$ .
To find the eigenvector i tried to found the set of functions $f\in V$ such that $Tf-\lambda f=Tf-f=0$ , using the expressions above it's possible to write the following $$\array{
f(x+1,y+1)-f(x,y)=&\sum_{m=0}^2[(y+1)^m(a_{0,m}+a_{1,m}+a_{2,m})-y^ma_{0,m}]+\\ 
&x\sum_{m=0}^2[(y+1)^m(a_{1,m}+2a_{2,m})-y^ma_{1,m}]+\\
&x^2\sum_{m=0}^2[(y+1)^ma_{2,m}-y^ma_{2,m}]
}
$$ Then if this polynomial is $0$ everywhere then if we treat $y$ as a constant the univariate polynomial is $0$ everywhere and then each coeficient is $0$ , i.e every sum in the expression above is $0$ and because this is true for every $y$ then this is also a $0$ everywhere polynomial for $y$ where every coefficient should be $0$ , after doing this I got a equation system that has a solution only when the following is true $$ 
     \begin{cases}
       a_{2,2}=a_{2,1}=a_{1,2}=0\\
       a_{1,1}+2a_{2_0}=0 \\
       a_{0,1}+a_{1,0}=0\\
       a_{0,2}=a_{0,2}\\ 
     \end{cases}$$ We can refer to $f\in V$ by it's coefficents, this means $f$ can be expressed as a vector in $\mathbb{R}^9$ , in the cannonical basis $f$ can be represented as $f=(a_{0,0},a_{0,1},a_{1,0},a_{0,2},a_{2,0},a_{1,1},a_{2,1},a_{1,2},a_{2,2})$ , then a base of the eigenspace  can be given by $$\array{
v_1=(1,0,0,0,0,0,0,0,0)\\
v_2=(0,1,-1,0,0,0,0,0,0)\\
v_3=(0,0,0,1,1,-2,0,0,0)\\
}$$ I consider that analyzing the powers of $(T-\lambda I)$ , like $(T-\lambda I)^2$ or $(T-\lambda I)^3$ is going to be a struggle, so, how should I construct the Jordan canonical form here?","['jordan-normal-form', 'generalized-eigenvector', 'linear-algebra', 'polynomials']"
4151128,The only strictly stationary random walk in $\mathbb{R}$ is degenerate,"An $\mathbb{R}$ -valued discrete-time stochastic process $\{X_n\}_{n \in \mathbb{Z}}$ is said to be strictly stationary if for all choices of times $t_1, \ldots , t_n \in \mathbb{Z}$ and lags $h \in \mathbb{Z}$ the following holds $$(X_{t_1}, \ldots , X_{t_n}) \stackrel{D}{=} (X_{t_1+h}, \ldots , X_{t_n+h})$$ In particular, no moment assumptions are imposed and all the processes are indexed over the integers. Now, consider the equation $$X_n = X_{n-1} + \epsilon_n \qquad (\star )$$ where $\epsilon_n$ is a strictly stationary white noise (i.e. an iid sequence). I am interested in showing that the only solution to this equation is $X_n = \epsilon_n = 0$ . Here, a solution means expressing each $X_n$ as a function of $\{\epsilon_n\}_{n\in \mathbb{Z}}$ . The case where we assume that $X_n$ and $\epsilon_n$ are also weakly stationary (i.e. constant mean and variance, with covariance only depending on the lag, $\mathrm{Cov}(X_t, X_s) = \gamma (|t-s|) = \gamma (h)$ ) is a trivial consequence of the Cauchy-Schwartz inequality, but of course this relies on the existence of a second moment for each of the processes. It is also tempting to assume that solutions of $(\star )$ must be causal or non-anticipative, and thus argue by assuming the independence of $X_{n-1}$ and $\epsilon_n$ . Arguing like that would be incorrect once one observes that a stationary solution to the equation $X_n = \phi X_{n-1} + \epsilon_n$ for $|\phi| > 1$ is given by $X_n = - \sum_{j=1}^\infty \phi^{-j} \epsilon_{n+j}$ , where we note that $X_n$ is future-dependent. The situation is even worse when one discovers there are stochastic equations whose solutions are of the form $X_t = \sum_{j=-\infty}^\infty \psi_j \epsilon_{t-j}$ , or another (not-necessarily linear) function depending on the entire history of $(\epsilon_n)_{n \in \mathbb{Z}}$ . Indeed, the only restriction to the solution space is that $X_t$ be the measurable image of the entire history of the innovation sequence. An analytically-flavoured approach to this problem is by generalising it to stochastic processes which take values on a locally compact topological group $G$ and the addition in $(\star )$ is treated as the group operation. In this setting, one observes that the problem is solved by considering the idempotent measures, which coincide with the Haar measures on the compact subgroups of $G$ . For instance, the equation is trivially satisfied in the circle group (viewed as a subgroup of $\mathbb{C}^*$ ) where the $\epsilon_n$ are uniformly distributed on the unit circle. But again, this forces us to consider solutions where $X_{n-1}$ and $\epsilon_n$ are independent.","['time-series', 'stochastic-processes', 'statistics', 'probability-theory']"
4151136,Analogy to Legendre's formula for $N!$,"Suppose $A$ is a product of primes $p\le x$ . For any $m$ let $A(m)$ be the largest such $A$ dividing $m$ . Proposition 1. For any $N$ sufficiently large, $$\prod_{i=1}^NA(i) < \prod_{p\le x}p^{\frac{N}{p-1}}.$$ Question. Can someone supply a proof for Proposition 1? Remarks. It may be the case that this holds for all $N$ instead of all $N$ sufficiently large. It seems like it may be possible to prove a uniform bound in $i\le N$ : $$A(i) \le \prod_{p\le x}p^{\frac{1}{p-1}},$$ but I haven't been able to do so (or rule it out). For context, this is the first inequality in Lemma 1 of  Erdős' paper A Generalization of a Theorem of Besicovitch. Erdős mentions this is analogous to Legendre's formula for $N!$ , but I am not sure if that is helpful for considering how to prove Proposition 1. Here is a more precise definition of $A(m)$ that I am using. (Note that Erdős writes "" $A$ is an integer composed entirely of primes not greater than $x$ "", so what follows is the interpretation I gave to this.) Consider the prime factorization of $m$ , $$
m = p_1^{a_1}p_2^{a_2}\dots p_r^{a_r},
$$ where the primes $p_j$ are distinct for $j=1,\dots,r$ , and the exponents $a_j\ge 1$ . Let $$A(m) = \prod_{j : p_j \le x} p_j^{a_j}.$$","['analytic-number-theory', 'number-theory', 'inequality']"
4151145,Question integral,"Assume that $ \lambda $ is the Lebesgue measure on $ \mathbb{R}^N,\ N \geq 1. $ Let $ f \in L^1_\text{loc}( \mathbb{R}^N, d \lambda),\ f \geq 0. $ Assume that there exists $ \alpha > 0 $ such that, for all Borel set $ E $ of $ \mathbb{R}^N $ with $ \lambda(E) = \alpha, $ then $ \int_E f \, d \lambda = \alpha. $ The question is : prove that $ f = 1 \text{ a.e.} $ Any idea?
(I have the idea to set $ D = \{x , f(x) < 1\} $ and to prove by contradiction that $ \lambda (D) = 0 $ and later the set $ D' = \{x , f(x) > 1\} $ )","['measure-theory', 'lebesgue-integral', 'measurable-functions']"
4151169,How is the metric in the complex projective line derived?,"It is mentioned in the Wikipedia page that we can define, in the complex projective line $\mathbb{CP}^1$ , the following metric: $$ds^2 = \left(\frac{2}{1+|\zeta|^2}\right)^2 |d\zeta|^2
= \frac{4}{(1+|\zeta|^2)^2} d\zeta d\bar\zeta.$$ They mention that this metric must be isometric to the sphere of radius $1/\sqrt K$ in $\mathbb R^3$ . How is this metric derived? From the comment I guess it might be derivable from the metric in $S^2$ , but I don't really understand how to go from there to a metric for $\mathbb{CP}^1$ .
Should I somehow derive it via pullback from a metric in $\mathbb C^2$ ? I'm not sure where to start in doing this.","['projective-geometry', 'differential-geometry', 'riemannian-geometry', 'complex-geometry', 'projective-space']"
4151193,"Is ""There exists a circle passing through any three noncollinear points"" really equivalent to Euclid's parallel postulate?","This site https://www.ics.uci.edu/~eppstein/junkyard/parallel-postulate.html lists from the book
""The Foundations of Geometry and the Non-Euclidean Plane"" by George E. Martin 26 propositions which are suppose to be equivalent to the parallel postulate. In particular Proposition I states: There exists a circle passing through any three noncollinear points. However, I would say this is valid in spherical geometry, so it can't be equivalent to the parallel postulate since the parallel postulate is not valid in spherical geometry.","['euclidean-geometry', 'axiomatic-geometry', 'geometry']"
4151212,What is the probability that the best candidate was hired?,"I have encountered some issues with the following question and have also seen the solution to it, but yet don't seem to understand why. An employer is about to hire one new employee from a group of N candidates, whose future potential can be rated on a scale from 1 to N. The employer proceeds according to the following rules: (a) Each candidate is seen in succession (in random order) and a decision is made whether to hire the candidate. (b) Having rejected m-1 candidates (m>1), the employer can hire the mth candidate only if the mth candidate is better than the previous m-1. Suppose a candidate is hired on the ith trial. What is the probability that the best candidate was hired? I am attaching the solution provided in the solutions manual. I will share why I don't understand this solution If we suppose that there are three candidates A, B, and C who are ranked as 1, 2, and 3 respectively. Then there are 6 ways (3!) for them to be interviewed which are: $1. A,B,C$ $2. A,C,B$ $3. B,A,C$ $4. B,C,A$ $5. C,A,B$ $6. C,B,A$ I may be wrong in setting it up this way already, but my thought process was the following. If we assume that the second candidate was hired and we want to find the probability that they were the best of the $3$ (in this example candidate C), then what I did was select the options that were still ""Valid"". For example, we cannot say that options $3, 5$ and $6$ are valid because the second candidate interviewed was worse than the first one. So we only have three valid opitons remaining ( $1, 2$ and $4$ ).
Since they are all equiprobable (if they are not please let me know why not, need to have hope in humanity restored) then the probability of having the selected the best candidate would be $2/3$ . If we were to follow the answer given in the solution it would be $1/2$ . Thanks for any help a good fellow citizen can provide, I believe that my interpretation may be incorrect and don't know what other approach to consider since it seems that there is not much to grab on to. It is in the first chapter of the book, page 41 (exercise 1.32) of Statistical Inference (2nd edition) by Geroge Casella and Roger L. Berger","['permutations', 'statistical-inference', 'statistics', 'combinations', 'combinatorics']"
4151237,"What is a Symbol (as in ""Symbol Calculus"")?","I have been reading through several papers on Deformation Quantization and the terms ""symbol"" and ""symbol calculus"" keep cropping up. I am somewhat well acquainted with most of the basic notions in differential geometry, but I have yet to run into this in any textbook and I'm having a hard time finding a definition for this. Here's an excerpt of the paper ""On representations of star product algebras over cotangent spaces on Hermitian line bundles"" by Bordemann et al. where the term is used: ... Under an operator representation we understand a $\mathbb{C}$ -linear assignment of a pseudo-differential operator $\mathrm{Op}_{\hbar}(a)$ on $\Gamma^\infty(L)$ [smooth sections of a Hermitian line bundle $L$ over $Q$ ] for every $\hbar\in \mathbb{R}^+$ ... and every symbol $a\in S^\infty(Q)\subset C^\infty(T^*Q)$ ... I understand that $S^\infty(Q)$ is the set of smooth symbols on $Q$ , which somehow is a subset of smooth functions on $T^*Q$ , but I am still somewhat confused. What is a ""symbol""?","['differential-geometry', 'vector-bundles', 'pseudo-differential-operators', 'definition', 'terminology']"
4151240,Maximum value of $x+2 x y+4 x y z$,"Given that $x,y,z \in R^+$ such that $x+y+z=1.5$ . Without using calculus find the maximum value of $x+2 x y+4 x y z $ My try:
We can write $S=x+2 x y+4 x y z =x(1+2y+4yz)$ $\implies$ $$S=x((1+2y)(1+2z)-2z)$$ $\implies$ $$S=\frac{1}{2}(1+2 x-1)(1+2 y)(1+2 z)-2 x z$$ $\implies$ $$S=\frac{1}{2}(1+2 x)(1+2 y)(1+2 z)-\frac{1}{2}(1+2 y)(1+2z)-2xz$$ By $AM-G.M$ , we have $$(1+2 x)(1+2 y)(1+2 z) \leq\left(\frac{3+2(x+y+z)}{3}\right)^{3}$$ $\implies$ $$(1+2 x)(1+2 y)(1+2 z) \leq 8$$ Any hint from here?","['contest-math', 'algebra-precalculus', 'inequality']"
4151289,Proving interchangeability of limit and integral for $\lim_{k\to0}\int_0^{\infty}\frac{\sin x}{x(k^2x^2+1)}\mathrm{d}x$,"As the title asks, I would like to ask if $\lim_{k\to0}\int_0^{\infty}\frac{\sin x}{x(k^2x^2+1)}\mathrm{d}x=\int_0^{\infty}\lim_{k\to0}\frac{\sin x}{x(k^2x^2+1)}\mathrm{d}x$ . I'm sure there's some form of convergence theorem that I have to use, and highly likely that it's the DCT, but I can't think of the sequence of functions I should use. Could someone guide me on this please? Thanks!","['integration', 'lebesgue-integral', 'real-analysis']"
4151308,How to use polar coordinate in ODE?,"I don't understand how to use polar coordinate. \begin{cases} \frac{dx(t)}{dt}=2x-y \\ \frac{dy(t)}{dt}=5x-2y  \\ \end{cases} $$ \frac{d}{dt} \left( \begin{array}{c} x \\ y \end{array} \right) = \begin{pmatrix} 2 & -1\\ 5 & -2 \end{pmatrix} \left( \begin{array}{c} x \\ y \end{array} \right)$$ let $A = \begin{bmatrix} 2 & -1\\ 5 & -2 \end{bmatrix}$ , we have $\det(A) = 1, \operatorname{tr}(A) = 0, P(\lambda) = \lambda^2+1 = 0 \Rightarrow \lambda_{1,2}=\pm i $ \begin{cases} 2x-y-ix = 0 \\ 5x-2y-iy = 0  \\ \end{cases} x = 1, y = 0 $\vec v_1 = (x,y) = (x, x(2-i)) = x(1,(2-i)) = \binom{1}{2-i} $ $E_{\lambda1} = \binom{1}{0}+i \binom{0}{-1} = \begin{pmatrix} 1 & 0\\ 2 & -1 \end{pmatrix} = P $ which give us $P^{-1}= \begin{pmatrix} -1 & 0\\ -2 & 1 \end{pmatrix}$ and $J = \begin{pmatrix} 0 & 1\\ -1 & 0 \end{pmatrix}$ $X(t)= e^{0t} \begin{pmatrix} \cos(t) & \sin(t)\\ -\sin(t) & \cos(t) \end{pmatrix}\begin{pmatrix} x_1\\ x_2 \end{pmatrix}$ $Y(t) = \begin{pmatrix} 1 & 0\\ 2 & -1 \end{pmatrix}\begin{pmatrix} \cos(t) & \sin(t)\\ -\sin(t) & \cos(t) \end{pmatrix}\begin{pmatrix} x_1\\ x_2 \end{pmatrix}$ It's a center stable So the solution is pretty simple but i want to try to use the polar coordinate and i can't do it $r^2= x^2 + y^2$ and $x = r\cos(\theta)$ , $y = r \sin(\theta)$ $2rr'= 2xx'+ 2yy' = 2x(2x-y) + 2y(5x-2y) = 4x^2 +8xy -4y^2 $ $\theta ' = \frac{y(2x-y)+x(5x-2y)}{x^2+y^2} = \frac{-y^2+5x^2}{x^2+y^2}$ maybe if the exercise doesnt ask polar coordinate, we don't do it ? i've check this : Polar coordinates differential equation but i still can't do it","['trigonometry', 'ordinary-differential-equations', 'dynamical-systems']"
4151328,can there be a prime ideal between a minimal containment of homogeneous primes?,"If $\mathfrak p_0 \subsetneq \mathfrak p_1\subset k[x_0,...,x_n]$ are homogeneous prime ideals such that there is no homogeneous prime ideal strictly between them, could there be a (non-homogeneous) prime ideal strictly between them? Part of me thinks the answer is probably no, but I couldn't come up with a counterexample. Part of me thinks the answer might be yes since the dimension of a projective variety seems like it should be one less than that of its cone, although idk if that makes any sense or if I'm even using any of those terms correctly. Entertaining the possibility that it's true, my only progress has been to note that if such a prime ideal $\frak q$ exists, then the set $\mathfrak q - \mathfrak p_0$ must not contain any homogeneous elements, since if one such $f$ exists, then $\mathfrak q$ is a minimal prime over $(f)+\mathfrak p_0$ , which implies $\mathfrak q$ must be homogeneous.","['abstract-algebra', 'commutative-algebra']"
4151370,Understanding the $\alpha$-regularity assumption for trees,"In this paper , definition 4 claims that a tree grown by recursive partitioning is $\alpha$ -regular for some $\alpha>0$ if each split leaves at least a fraction $\alpha$ of the
available training examples on each side of the split, and moreover,
the trees are fully grown to depth $k$ for some $k \in \mathbb{N}$ (i.e. there are between $k$ and $2k-1$ observations in each terminal
node of the tree. the first part of the definition makes sense to me, but I am not sure I understand how they conclude that there are between $k$ and $2k-1$ observations in a terminal node. Say you train a tree with $n$ observations, and you choose a depth $k$ , then based on the $\alpha$ -regularity, and assuming $\alpha < 0.5$ the minimum number of observations in a node at depth $k$ is going to be $n\alpha^k$ , and the largest is $n(1-\alpha)^k$ - so I am not sure how they are able to conclude that the size of the node is between $k$ and $2k-1$ . update : my best guess is that they didn't mean a depth of $k$ , but rather they require that the tree is grown fully, and since $\alpha$ is a proportion, it can at most be $0.5$ , and so the number of observations in a terminal leaf will be between $k$ and $2k-1$ for some $k$ . As the number of data points gets larger, this requires that the tree to become deeper since (I assume) $k$ is kept fixed","['statistical-inference', 'statistics', 'trees', 'decision-trees', 'machine-learning']"
4151381,Are ordinal numbers produced by the power set axiom?,"I am a nube just getting into mathematics and set theory. I am learning about how we can produce the list of ordinal numbers by purely using the null set, with 0 standing for Ø, 1 standing for {Ø}, 2 standing for {Ø, {Ø}} and so forth. What I am confused about is the operation at play here to produce the larger sets with more elements. It seems to me to be the power set axiom being applied to create a new larger set. But elsewhere I have seen this called the axiom of subsets. Is this the same thing? Or am I confused? Thanks so much :)
A",['elementary-set-theory']
4151396,Multiplication by an element in semisimple subalgebra of endomorphism,"Serge Lang Algebra, Sec. XVII, Exercise 9: Let $E$ be a finite-dimensional vector space over a field $k$ . Let $R$ be a semisimple sub-algebra of $\operatorname{End}_k(E)$ . Let $a, b \in R$ . Assume that $$\ker b_E \supset \ker a_E$$ where $b_E$ is multiplication by $b$ on $E$ and similarly for $a_E$ . Show that there exists an element $s \in R$ such that $sa = b$ . [ Hint : Reduce to $R$ simple. Then $R = \operatorname{End}_D(E_0)$ and $E = E_0^{(n)}$ ). Let $v_1,\dots, v_r$ be a $D$ -basis for $aE$ . Define $s$ by $s(av_j)= bv_j$ , and extend $s$ by $D$ -linearity. Then $sa_E=b_E$ , so $sa=b$ ]. (Simple rings are assumed to be semisimple, and $E^{(n)}$ means the direct sum of $n$ copies of $E$ .) I'm having troubles understanding the hint here. Specifically in the $E=E_0^{(n)}$ part. I think what they meant is that by Artin-Wedderburn's theorem, we may assume $R=M_m(D)$ where $D$ is a division algebra over $k$ . Then $M_m(D) \cong \operatorname{End}_D(V^{(m)})$ where $V$ is a simple left $D$ -module. But I can't see how $E$ relates to $V^{(n)}$ . Perhaps my interpretation is completely off?","['matrices', 'abstract-algebra', 'semi-simple-rings', 'vector-spaces']"
4151404,Understanding sequences in topological spaces,"Trying to understand what it means for a sequence to be in a topological space. What are the possible sequences in $(\{1, 2, 3, 4\}, \tau_{triv})$ and $(\{1, 2, 3, 4\}, \tau_{disc})$ ? Do the sequences depend on the underlying topology? I am thinking the only possible sequence in the given trivial space above is $\{1, 2, 3, 4\}$ , unless $\{\}$ is also a sequence whereas there are $2^4$ possible sequences in the given discrete space above, among which are $\{1\}, \{1, 4\}, \{2, 3, 4\}$ . Does that make sense? The reason I ask this question is the following two proofs below: In $(X, \tau_{triv})$ , let $l \in X$ and $(x_n)$ be any sequence. If $N$ is ‘any’ neighborhood of $l$ then $N$ must, in fact, be the whole of $X$ . So $n \ge 1 \implies x_n \in N \implies x_n \to l.$ In $(X, \tau_{disc})$ , suppose $(x_n)$ converges to $l$ . Now $\{l\}$ is open and is a neighborhood of $l$ , so $\exists n_0 \in N$ s.t. $n \ge n_0 \implies x_n \in \{l\} \implies  x_n = l$ . So $(x_n)$ is eventually constant (at $l$ ). Why do they choose these particular neighborhoods in the proofs above? Likely because they are convenient for the conclusion. Then, why are these particular $N$ considered appropriately arbitrary? For example, do they choose $N$ to be $X$ in the first proof because there's possibly only one sequence ( $\{1, 2, 3, 4\})$ for a limit to be in? What about $N = \{l\}$ ? Thanks.","['elementary-set-theory', 'general-topology', 'sequences-and-series']"
4151418,How should I prove $\lim_{x \to \infty} \frac{1}{x^3} = 0$,"Use the definition of the limit to prove the following limit. $$\lim_{x \to \infty} \frac{1}{x^3} = 0$$ This is my attempt at solving this question Suppose $\epsilon > 0$ , choose $M = \frac{1}{^3\sqrt{\epsilon}}$ Suppose $x>M$ $$\frac{1}{x}<\frac{1}{M}\ \text{(taking the reciprocal)}$$ $$\frac{1}{x^3}<\frac{1}{M^3}\ \text{(cubing both sides)}$$ Assuming $x > 0$ as the limit is as $x$ approaches $\infty$ : $$\left|\frac{1}{x^3}\right|<\frac{1}{M^3}$$ $$\implies \left|\frac{1}{x^3} - 0\right|<\epsilon$$ I am unsure whether this is the right way to do so. I thought of this method after watching videos and reading up on limit proofs. I am self-learning all these topics purely for interest. Any corrections to my working will be greatly appreciated! Thank you.","['limits', 'epsilon-delta', 'real-analysis']"
