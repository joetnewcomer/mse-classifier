question_id,title,body,tags
1461885,Separating the Variables Solution,"Problem: Solve the initial value problem 
$$y′ = \frac{1+3x^2}{3y^2 −6y},\quad y(0) = 1$$
and determine the interval in which the solution is valid. Hint: To find the interval of definition, look for points where the integral curve has a vertical tangent. Hi! I have this problem from one of my homework's and I am stuck on the part of determining the interval. I have already separated the variables and found C using the initial condition and got: y^3 - 3y^2 = x + x^3 -2. Now I need to determine the interval for the solution. I tried to understand the hint but can't really figure what they mean by looking for points where the integral curve has a vertical tangent. Do I accomplish this by setting: dx/dy = 0 Thanks for the help!",['ordinary-differential-equations']
1461965,"Prove that $\{(x,y,z) \in \mathbb{R}^3 \mid z^2-x^2-y^2-1>0 \}$ is an open set in $3$-space.","Prove that $\{(x,y,z) \in \mathbb{R}^3 \mid z^2-x^2-y^2-1>0 \}$ is an open set in $3$-space.
I'm getting no clue as to how to proceed in order to prove this formally.",['multivariable-calculus']
1461970,Geogebra graphing help,"I'm trying to draw a wave in geogebra, something like the one on a pepsi logo. The wave is a vertical wave and I have no idea how to draw it. I tried drawing a sine graph but I want a 'single' wave, which is 'vertical' Any ideas?","['graphing-functions', 'math-software', 'functions']"
1461972,"Given a function $f(x,y)$ find the limit as $(x,y)\to(0,0)$","If it exists, find $$\lim_{(t,x)\to(0,0)}\frac{t^2\sin^2(x)}{2x^2+t^2}$$ Along the curves $x=mt,t=0,x=at^2,t=ax^2$ the limit approaches 0; the graph also makes $L=0$ seem correct. So assuming that $L=0$, I start the epsilon delta proof:
$$0<\sqrt{x^2+t^2}<\delta$$
$$\left|\frac{t^2\sin^2(x)}{2x^2+t^2}\right|<\epsilon$$ All attempts I did trying to find a $\delta$ for every $\epsilon$ have just end up circling around and accomplishing nothing.
How am I supposed to complete this proof?","['multivariable-calculus', 'limits', 'epsilon-delta']"
1461976,If squared series is convergent then series is convergent absolutely?,"If $\sum_{i=0}^\infty a_n^2$ is convergent, does that imply $\sum_{i=0}^\infty a_n$ is convergent? How can I prove that? Thanks for the help.","['sequences-and-series', 'examples-counterexamples']"
1462006,Confused on applications of solving $\cos \frac x2 - \sin x = 0$,"Why can't $\cos\frac{x}{2} - \sin x = 0 $ be transformed into being $\cos(x) - \sin(2x) = 0$? It works in application to achieve the half angle formulas for $\sin x$, $\cos x$, and $\tan x$, why doesn't it work here?","['algebra-precalculus', 'trigonometry']"
1462034,Plotting $f(x) = \sin(x)+\cos(x)$ by converting it to another form,Are there any trigonometric identity that can make $f(x) = \sin(x)+\cos(x)$ easier to plot? I have no idea how it becomes a sin graph shape in the end.,"['graphing-functions', 'calculus', 'algebra-precalculus', 'trigonometry']"
1462040,A strange question about the subset (of $\Bbb N$) of number $4n + 1$; wrong proof?,"Long introduction (I'm sorry), but very short question You take the proper subset of $\mathbb{N}$ made by all and only numbers 
of the form  $4n + 1$, when $n = 0,1,2,\ldots$ and obtain the set : $A = \{1,5,9,13,17,21,25,29,33,\ldots\}$ $A$ is closed with ordinary product because for any $n$,$m$ of $\mathbb{N}$: 
$(4n+1)(4m+1) = 16nm + 4n + 4m + 1 = 4(4nm+n+m)+1 = 4k + 1 $ Now, in this set $A$, the numbers $9,13,17,21$ (and others) are 
""prime"" because they have no factors in $A$. $9$  and $21$ are not really prime, of course. They are ""prime"" in 
the set $A$, because in $A$ there are actually no factors of those
numbers. I will call a ""prime"" in $A$ A-prime (Ap), and for a prime in $\mathbb{N}$ (so, a real prime) simply prime (p). Obviously if a number is an Ap not necessarily is a p. But if it is a p -and belong to $A$- then it is also an Ap. Then I will say that a number $Aq$ is a square in $A$ ($A$-square) 
if and only if there exists an $Am$ in $A$ such that $Am^2 = Aq$. So (for example) the first $A$-square in $A$ is $25$, not $9$. If $Aq$ is an  $A$-square then  it is also square (in $\mathbb{N}$) but the inverse is false, so the set of the A-square numbers is a proper subset of 
the all squares of $\mathbb{N}$. Here is the question : Are there numbers in $A$ not $A$-square (but eventually square), in other words numbers like $Ay$ such that you can find (in $A$) a pair $An^2$, $Am^2$ that $An^2 = Ay\cdot Am^2$ ? I refer to the proof kindly offered by Mister Sinclair : I think is probably (or may be I should say ""perhaps"") wrong because : It is true that
$k=3 \pmod 4$ and  $k= 3 \pmod 4$ and it is true that $n = 1 \pmod 4$.
But, although it is NOT true that $1 = 3 \pmod 4$, it IS TRUE that
$1^2=3^2 \pmod 4$ ($1 = 9 \pmod 4$). Hence, no contradiction rises up. The problem is (perhaps) a little bit ""sneaky"" and resembles 
to the following one: It is TRUE that $(−6)^2 = 3^2\cdot2^2$, so the three number $−6,3,2$ actually 
satisfy the identity. But it NOT true that $−6=3\cdot2$. So, I think the problem is not resolved yet Thank you a lot for any clarification","['number-theory', 'elementary-number-theory']"
1462072,Is $\emptyset$ in $R^n$ an open set?,"The complement of $\emptyset$ in $R^n$ is $R^n$ itself, which is an open set itself. So, $\emptyset$ should be a closed set, by definition of closed set.
However, Tom M. Apostol's book says it is an open set. Am I going wrong somewhere in my argument? If so, where?",['multivariable-calculus']
1462099,Number of possible combinations of x numbers that sum to y,"I want to find out the number of possible combinations of $x$ numbers that sum to $y$. For example, I want to calculate all combination of 5 numbers, which their sum equals to 10. An asymptotic approixmation is also useful. This question seems to be very close to number partitioning, with the difference that a number can be 0. See: https://en.wikipedia.org/wiki/Partition_%28number_theory%29#Asymptotics All possible partitions for sum 10 and 3 positions that can be zero, are 63 possiblities: (numbers shown as 3 digits) 019
028
037
046
055
064
073
082
091
109
118
127
136
145
154
163
172
181
190
208
217
226
235
244
253
262
271
280
307
316
325
334
343
352
361
370
406
415
424
433
442
451
460
505
514
523
532
541
550
604
613
622
631
640
703
712
721
730
802
811
820
901
910","['summation', 'number-theory', 'integer-partitions']"
1462182,Is it known whether the number of Proth-primes is infinite?,"A prime number of the form $k\times 2^n+1$ with $n\ge 1\ ,\ k<2^n$
is called a Proth-prime. Is it known whether the number of Proth-primes is infinite ? It seems to be almost surely true that there are infinite many proth-primes,
but I do not know a proof.","['prime-numbers', 'number-theory']"
1462224,How can I find the inverse of $h(x)=-x(x^3 +1)$,How can I find the inverse of $h(x)=-x(x^3+1)$? it's asked also to find $h^{-1}(2)$ and $h^{-1}(-2)$. I think it's easy to find a domain where this function is bijective. I've already find $h^{-1}(-2)=1$. My problem is to find $h^{-1}(2)$ and the inverse itself. Thanks,['functions']
1462257,solving for $P=a^{2}+b^{2}$,"Fermat's Two-Square Theorem: Given a prime $ p$, there exist integers $ a, b$ such that $ a^2 + b^2 = p$ iff $ p = 2$ or $ p \equiv 1 \bmod 4$. Consequently, a number $ n$ is expressible in the form $ a^2 + b^2$ iff the primes congruent to $ 3 \bmod 4$ in its prime factorization each divide $ n$ an even number of times. But for example, if we take $49$ whose prime factorisation is $7^2$, all the primes congruent to $3 \bmod 4$ have their power as even, so $49$ should be expressible as sum of squares of two integers, although $49$ can't be expressed as $a^2 + b^2$.","['prime-numbers', 'number-theory']"
1462261,proving a quadratic form is closed,"I'm trying to show that, given a spectral measure $d\mu_\psi(\lambda)$ for a self-adjont operator $A$, for the following quadratic form $$q_\lambda(\psi)=\int_{\mathbb R}\chi_{(-\infty,\lambda]}(\tau) d\mu_\psi (\tau)$$ there exists an operator $P(\lambda)$ such that: $$<\psi|P(\lambda)\psi>= q_\lambda(\psi)$$ In particular, $q_\lambda(\psi)$ is bounded from below and so I have just to prove that it is closed. Well, I know that in order to show closedness I should prove that the domain of the quadratic form $Q$ is complete with respect to the norm form $$||\psi||_q= q_\lambda(\psi)+||\psi||_H$$
where $H$ is our generic Hilbert space. I have some troubles proving this, since chosen a Cauchy sequence on $H$, I can't understand how $q_\lambda(\psi_n-\psi_m)$ behaves. Any help would be greatly apppreciated!","['quantum-mechanics', 'spectral-theory', 'functional-analysis']"
1462269,Proving the closed unit ball of a Hilbert space is weakly sequentially compact,I bumped into this statement in Hofer-Zehnder in the middle of proving a Hamiltonian field always has a periodic orbit over a level set of the hamiltonian if that set is a regular compact and strictly convex energy surface. I looked around the internet but a proof was elusive. How do I prove this?,"['functional-analysis', 'hilbert-spaces', 'weak-convergence', 'general-topology']"
1462276,Is there a function that doesn't have a derivative?,"I was wondering if such a function exist. I'm comfortable with derivatives of polynomial functions, and some other basic functions, but I'm wondering if there could exist a very complicated function that doesn't have a derivative.","['examples-counterexamples', 'calculus', 'derivatives']"
1462383,Is Homeo$(X)$ metrizable?,"If $(X,d)$ is a metric space then is Homeo$(X)$ (the group of homeomorphisms of $X$ with itself) endowed with the compact open topology metrizable? At first I thought I could define a metric on Homeo$(X)$ using the metric $d$ but I can't find a good way to do that. I am not certain how to prove Homeo$(X)$ is regular and has a countable basis either. If this question can't be answered in general then can it be done in the case when $X$ is  connected, locally path connected and locally compact? Thank you.","['metric-spaces', 'general-topology']"
1462400,What is the distribution of an average of independent Poisson random variables?,"If I have random variables $X_1,X_2,\ldots,X_n$ that are Poisson distributed with parameters $λ_1,λ_2,\ldots,λ_n$, what is the distribution of $Y=1/n \sum X_i$? Who knows this can give an answer because I don't know how to do, please.",['statistics']
1462405,Which correlation coefficient indicates the strongest relationship between two variables?,"I'm trying to understand correlation coefficients, and seem to be missing something. For example, Correlation coefficient: Indicates the direction, positively or negatively of the relationship, and how strongly the 2 variables are related. I understand that the strength can vary from 0-1 and I thought I understood that positive or negative simply had to do with the direction of the correlation. This question is part of my review and I don't understand why my answer is incorrect... Which correlation coefficient indicates the strongest relationship between two variables? a) -0.85 - This was my answer which I thought was the closest to one (meaning strongest b)1.94 c)0.58 - This is what the textbook says is the correct answer, but why? d)0.19 Thanks for your help!",['statistics']
1462418,Rational points of finite etale group schemes over $\mathbb{Z}[1/N]$,"Let $N$ be an integer and $G \to \mathrm{Spec}(\mathbf{Z}[1/N])$ be a finite étale group scheme. I read that, for every prime $p$ not diving $N$ we have : $$
G(\overline{\mathbf{Q}}) = G(\overline{\mathbf{F}_p})
$$ Why is this true ?",['algebraic-geometry']
1462443,Set theory possible values,"I'm studying for an upcoming exam and a practice question stumped me. It is asking for possible values A), B), and C) could have. $C^c$ means the complement of $C$. Am I right when I reason that A) would just be any number smaller than 0.7, or is it warranted to be more precise? Family of events → [0, 1] $P(A \cup B \cup C) = 0.7$ A)  $P(A \cup B)$ B)  $P((A \cup B) \cap C^c)$ C)  $P(A^c \cap B^c \cap C^c)$","['probability', 'statistics', 'measure-theory']"
1462506,Relation between determinant of the cofactor matrix and the matrix itself?,"If the cofactor matrix of A is
$$\begin{bmatrix}1 & 2 & 3 \\ 0 & -2 & 4 \\ 0 & 0 & -2\end{bmatrix}$$ How can I find the determinant of $A$?",['matrices']
1462515,Is there a function satisfying the following properties $ f^{n}(x)=(f(x))^{n+1}$??,"Is there a function with the following properties? $$ f(x)=f(x) $$
$$ f'(x)=f(x)^2 $$ $$f^{(n)}(x)=\left(f(x)\right)^{n+1}$$
where $f^{(n)}$ denotes the $n$th derivative, and by convention $f^{(0)}(x) = f(x)$.","['calculus', 'functional-equations']"
1462526,Proving differentiability,"I just had a question on proving differentiability by showing that the difference quotient exists. I understand in the case of a function like $f(x)=x^2$, where you end up with $((x+h)^2 - x^2)/h = 2x + h = 2x$ as h goes to infinity, but in the case of a function such as $1/x^n$, how do you address the ""n"" portion since you cannot expand and divide out the $h$ in the denominator?","['calculus', 'real-analysis', 'derivatives']"
1462539,"Let $T: E \rightarrow E^*$ be a linear operator satisfying $\langle Tx,x \rangle \geq 0 \forall x \in E$. Prove T is bounded.","I'm trying to use the closed graph theorem, i.e, I'm trying to prove that $Graph(T) = \{ (x,Tx) ; ~x \in E \}$ is closed in $E \times $F, but I'm a little bit confused. So, i'd like some help in proving it. Here, given $f$ function, $\langle f,x \rangle = f(x)$. Thanks in advance.",['functional-analysis']
1462573,Repeated application of the gradient on a Riemannian manifold,"While reading about Sobolev spaces on manifolds, I encountered the following notation regarding the norm in $H^k$: $\| \nabla ^k f \|_{L^2}$. There are two questions here: 1) What kind of object id $\nabla ^k f$? Is it a $k$-vector? How is it defined? 2) How is the metric $g$ extended to the space of these objects? I suspect a strong similarity to differential forms and their norms as defined in Hodge theory, yet there must also be some differences, since forms are a purely differential object, whereas the gradient is a Riemannian one.","['hodge-theory', 'sobolev-spaces', 'riemannian-geometry', 'differential-geometry', 'tensors']"
1462584,A question about existence of derivative of function at Zero,"Assume that $f:\mathbb{R}\to\mathbb{R}$ is continuous and differentiable everywhere but at $0$. If $\displaystyle\lim_{x\to0} f'(x) = L$ exists, then does it follow that $f'(0)$ exists? Prove or disprove. I think it has to be true. I know that by definition $\displaystyle f'(0)=\lim_{h\to0}\frac{f(h)-f(0)}{h}$, but I could not able to further steps from here.
 could you please help me out.","['calculus', 'real-analysis', 'limits', 'derivatives']"
1462662,Why does matrix multiplication represent linear transformation compositions?,"I know it's probably a silly question, but I'm trying to figure out why was matrix multiplication (the standard one) defined the way it was defined. I know that it was defined like that so we would gain invariance under change of basis: $PAP^{-1}+PBP^{-1}=P(A+B)P^{-1}$ and $(PAP^{-1})(PBP^{-1})=PABP^{-1}$ and that ofcourse the case. But another explanation that was suggested is: ""We defined matrix multiplication this way so that if $A$ is the matrix of a linear transformation $T_1$ with respect to some basis $s$ and $B$ is the matrix of a linear transformation $T_2$ with respect to the same basis $s$ then $AB$ is the matrix of $T_1$ composition with $T_2$ (I don't know the command for composition operator) with respect to basis $s$. Again, this is a completely legitimate aspiration, but I fail to see why it follows. Why is linear transformation composition equivalent to matrix multiplication?","['linear-transformations', 'linear-algebra', 'matrices']"
1462707,"Find integer a,b > 1 such that $2^a + 3^b = 2^{a+b} +1$","I would like to know if it is possible to find an integer solution to $2^a + 3^b = 2^{a+b} +1$ with $a,b > 1$",['discrete-mathematics']
1462708,Show $f$ is locally invertible if $f = L + g$ and $|g(x)| \le M|x|^2$,"Let $f, g, L: \mathbb{R}^n \to \mathbb{R}^n$ and $L$ is a linear isomorphism, and let $|g(x)| \le M|x|^2$ on $\mathbb{R}^n$ for some $M > 0$. Prove that $f$ is locally invertible at $0$, i.e. $f$ is invertible on some open neighborhood of $0$. I tried to use the inverse function theorem, but I failed because $f$ may be differentiable on no open neighborhood of $0$. How can I solve this?",['analysis']
1462725,Epsilon delta proof; constraining delta.,"I've been trying to do some $\epsilon -\delta$ proofs, but I keep running into problems regarding certain steps. Namely, I can bring the proof to a point that is almost complete, but to complete it I would need to place a constraint on $\delta$ to make the next inequality true (such as $x^2+y^2≤\sqrt{x^2+y^2}$ provided $\sqrt{x^2+y^2}≤1$). If I had
$$\lim_{(x,y)\to(0,0)}f(x,y)$$
Is it fine to constrain my $\delta$ (such as $0<\sqrt{x^2+y^2}<\delta<1$) because my limit is within the disc $\sqrt{x^2+y^2}<1$? If I come to a point where I would need to do that, have I done something wrong? Is there some extra step that I should make that I am missing?","['multivariable-calculus', 'limits', 'epsilon-delta']"
1462752,"What happens to $f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2}$ as $(x,y) \rightarrow (0,0)$.","As in the title I want to study what happens to $f(x,y)$ as $(x,y) \rightarrow (0,0)$. Where $f: R^2 \setminus \{(0,0) \} \rightarrow R$ $$f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2} $$ A useful theorem I have been using is: Let $A \subset R^n, f:A\rightarrow R$ and let $x_0$ be an accumulation point of $A$.
Then the limit $\lim_{x \rightarrow x_0} f(x) = l \in \bar{R}$ if and only if $\forall{B} \subset A$ s.t. $x_0$ is an accumulation point of $B$ we have $\lim_{x \rightarrow x_0} f|_B(x) = l$. So if I restrict the function domain to all $ x = y$ I get $$f(x,y) = \frac{|x|^{\alpha+1}}{x^{4} + x^2} = x^{\alpha -1}(1 + o(1))$$ this is 1 if $\alpha = 1$, $0$ if $\alpha> 1 $ and it goes to infinity if $\alpha <1$. So now I know that for $\alpha <1$ the function does not converge in $R^2$ correct? Then I notice that near $x = 0$ $$0 \le |f(x,y)| \le \frac{||(x,y)||^{1+\alpha}}{x^4+y^4} \le \frac{1}{c} ||(x,y)||^{\alpha -3}$$
by an euclidean distance inequality so the function converges for $\alpha>3$. But what happens for $1 \le \alpha \le 3 $?","['limits', 'real-analysis', 'multivariable-calculus']"
1462778,Area of a right angled hyperbolic triangle as function of side lengths,"I was puzzeling with Area of hyperbolic triangle definition and could not figure it out, but then i thought there should be a (maybe solvable)  simpler problem so here it is: suppose: an hyperbolic plane with a Gaussian curvature of -1 on this surface there is a triangle $\triangle ABC$ $\angle C$ is a right angle Then given the lengths of sides a and b what is the area? Off course we could do: the area $ = \frac{\pi}{2} - \angle A -\angle B$ or $ \frac{\pi}{2} - arctan (\frac{\tanh(a)}{\sinh(b)} )- arctan (\frac{\tanh(b)}{\sinh(a)}) $ (free after http://en.wikipedia.org/wiki/Hyperbolic_triangle ) But is there not a  nicer formula that does not contain any or only one trigonometric function? (I guess the hyperbolic functions are needed) UPDATE 07/10/2015 following https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Arctangent_addition_formula $$ \arctan u + \arctan v = \arctan \left( \frac{u+v}{1-uv} \right) $$ and $$ \frac{\pi}{2} -arctan (\frac{u}{v}) = arctan (\frac{v}{u})$$ (complement tangent = cotangent) I get to $$ Area = arctan(\frac{ \sinh(a)\sinh(b) - \tanh(a)tanh(b)}{\sinh(a)\tanh(a)+ \sinh(b)\tanh(b)} )$$ Can this be simplified any further? 
(Do i overlook the obvious again , or even did i make a mistake on the way somewhere?)","['differential-geometry', 'hyperbolic-geometry']"
1462793,A specific problem on Class field theory,"Let $K$ be a quadratic complex number field. Let $p$ be a prime greater than $5$ unramified in $K/\mathbb{Q}$. Let $M$ be the compositum of all finite $p$- extensions of $K$ which are unramified outside the set of primes of $K$ lying above $p$. Let $M^{ab}$ be the maximal abelian extension of $K$ contained in $M$. Let $\Gamma^{ab}$ be Gal$(M^{ab}/K)$. For a prime $\mathfrak{P}$ of $K$ lying above $p$ let $U_{\mathfrak{P}}$ denote the local units of $K_{\mathfrak{P}}$, which is the completion of $K$ at prime $\mathfrak{P}$. Let $U_{1,\mathfrak{P}}$ denote the units that are congruent to $1$ mod $\mathfrak{P}$. Let $U_1=\prod_{\mathfrak{P}|p}U_{1,\mathfrak{P}}$. Let $H$ be the $p-$ Hilbert class field of $K$. I want to show that (using class field theory)
we have the following exact sequence $1\rightarrow U_1 \xrightarrow{\beta} \Gamma^{ab} \xrightarrow{\alpha} Gal(H/K) \rightarrow 1$ It will be helpful if someone gives me a proof or a reference for this fact. The map $\alpha$ is obvious and it is also surjective but I do not know how to construct the map $\beta$ using class field theory and show that $\beta$ is injective and the sequence is exact. Thank you for help.","['class-field-theory', 'number-theory', 'algebraic-number-theory']"
1462803,Showing $\pi/(2\sqrt3)=1-1/5+1/7-1/11+1/13-1/17+1/19-\cdots$,I am struggling to show that $$\dfrac \pi{2\sqrt3}=1-\dfrac 15+\dfrac 17-\dfrac 1{11}+\dfrac 1{13}-\dfrac 1{17}+\dfrac 1{19}-\cdots$$ by using the Fourier series $$\frac \pi2-\frac x2=\sum_1^\infty \dfrac {\sin(nx)}{n}.$$ Can somebody give me any hint?,"['analysis', 'sequences-and-series', 'pi']"
1462843,Efficient of Newton Polynomial Evaluation,"The polynomial in Newton form having the coefficients $a_{0},a_{1},\ldots,a_{n}$ and centers $x_{1},x_{2},\ldots,x_{n}$ is the polynomial 
$$ p(x) = a_{0} + a_{1} (x-x_{1}) +a_{2} (x-x_{1})(x-x_{2}) + \cdots + a_{n} (x-x_{1})\cdots (x-x_{n}). $$
Let $\alpha \in \mathbb{R}$ and set 
$$\left\{ \begin{array}{ll}
b_{n} &= a_{n}, \\
b_{i} & = a_{i} + b_{i+1} ( \alpha - x_{i+1}), \; \text{for } i=n-1,n-2,\ldots,0.
\end{array} \right.
$$
Then $b_{0} = p(\alpha)$. This is the generalized Horner's rule for evaluating Polynomial in Newton form. This algorithm takes at most 2n additions and n mutiplications. I am trying to prove that in the case $x_{i} \neq x_{j}, i \neq j$ and all the coeficients $a_{i}$ is nonzero and $\alpha \neq x_{i}$ for all $i$, this algorithm is optimal. I think that we may need to generalize the proof of Alexander Ostrowski in 1954 for Horner's rule (he proved that the number of additions required in evaluating arbitrary polynomial must be at least n, the degree of that polynomial), but I am struggling to do it. So my question is: Is this algorithm optimal in the case above?. Any help would be appreciated. Regards.","['analysis', 'numerical-methods', 'real-analysis']"
1462904,How to compute intersection numbers in practice?,"When speaking about plane curves, one of the most fundamental and important results is Bézout's Theorem , which states that over an algebraically closed field $k$, two plane projective curves of respective degrees $d$ and $d'$ with no common component meet in exactly $dd'$ points, counted with multiplicity. One can also compute it in several other ways, see for example this question . However, computing intersection numbers in a more general setting usually gives me a lot of trouble. Say we are working over the field of complex numbers $\mathbb{C}$ and consider a complex manifold $X$ of dimension $n$ and a complex submanifold $Y \subset X$ of dimension $m$. Then, by Poincaré duality, we get the (well-defined) fundamental class of $Y$ defined as $[Y] \colon H^{2m}(X,\mathbb{R}) \to \mathbb{R}$, by sending an $m$-form $\omega$ representing a cohomology class to $\int_Y \omega$. If $Z \subset X$ is another complex submanifold, say of dimension $n-m$, then one has $[Y]\cdot [Z] \in \mathbb{R}$, by wedging the respective representative forms and integrating over $X$. One can then show that if the intersection $Y \cap Z$ is finite, then $[Y]\cdot [Z]$ equals the cardinality of this intersection, counted with multiplicity. One standard example of computing these intersection numbers is considering the blow-up $\pi \colon \hat{X} \to X$ of $X = \mathbb{P}^2$ at a point and the computation of the self-intersection of the exceptional divisor. Then one can go one step further and define the following. $X$ is as above, $Y \subset X$ is now an irreducible analytic set of dimension $m$ and $L$ a line bundle on $X$. Then one can define $L^m.Y := \int_Y \omega^m$, where $\omega$ is a $(1,1)$-form which represents the first Chern class $c_1(L)$ of $L$. (One can also define $L^m.Y$ on singular complex spaces, say reduced. But let's say that this does not play a role in this question.) On manifolds, this is just the the fundamental class $[Y]$ evaluated at $c_1(L)^m$. This intersection number is widely used in algebraic geometry and complex analysis, for instance in nef- and ampleness criteria like Nakai-Moishezon, or in the definition of numerical equivalence and hence also in the definitions of the nef and ample cone. But how can one compute this intersection number in practice? It does not seem very appropriate to use the definitions. A lot of texts that I've been reading use somehow intuitive and not very rigor arguments, not explaining why the intersection number takes the desired value. More generally, if one has a specific variety and a line bundle on it, how can one decide via intersection numbers (i.e., what standard methods come into play) if this line bundle is ample or nef? Can somebody please give a more or less complete overview of standard methods which can be used to compute intersection numbers? It does not have to be detailed, a good reference or a good example would also satisfy me.","['algebraic-geometry', 'complex-analysis', 'intersection-theory']"
1462908,infinite subset of an finite set?,"Is it possible to have a set of infinite cardinality as a subset of a set with a finite cardinality? It sounds counter-intuitive, but there are things in math that just are so. Can one definitely prove this using only basic axioms? The main reason I asked this question is because the book Inverted World says there are infinite planetary bodies in a finite universe, and I wondered if this could be done with sets.","['infinity', 'elementary-set-theory']"
1462952,"Show that if $n+ 1$ integers are chosen from the set $\{1, 2, . . . , 2n\}$, then there always two which differ by $2$.","$n$ is also given to be an even number. So I want to prove this by using the pigeon-hole principle. I would partition the numbers $\{1, 2, . . . , 2n\}$ into $n$ boxes with numbers in each as follows : $$\{1,2\}, \{3,4\},......,\{2n-1,2n \}$$ if $n+1$ numbers are to be chosen from these $n$ boxes, How to show that there will be remaining numbers that differ by 2 ? Let's say we have $n=4$ then we would have 
 $$\{1,2\} ,\{3,4\}, \{5,6\}, \{7,8 \}$$ Now if we $5$ numbers are chosen from the above, then we want to show that there are two of the three numbers remaining that differ by $2$ Here I have $4$ holes and $5$ pigeons, so one of these pairs must be chosen when choosing the $5$ numbers , But still I can't argue that we will be left with 2 numbers that differ by 2. ANy suggestions ?","['discrete-mathematics', 'pigeonhole-principle', 'combinatorics']"
1462977,How to state that a sequence is Cauchy in terms of $\limsup$ and $\liminf$?,"How to state that a sequence is Cauchy in terms of $\limsup$ and $\liminf$? For example, is it true that a sequence $(a_n)_{n=1}^{\infty}$ is Cauchy iff $\displaystyle\limsup_{n\to\infty}|a_{n+k}-a_n|=0$ for all $k\in\mathbb{N}$?","['analysis', 'real-analysis']"
1463010,Differentiating under the (Lebesgue) integral sign.,"There's this guide for proving the theorem about differentiation under integral sign, I took a look around some questions here, but I still have doubts. I know I can probably find this done in a book, but I'm so close that I'd rather ask here instead. Let $(Y, {\scr A},\mu)$ be a measure space with $\mu(Y) < +\infty$ , $U \subseteq \Bbb R^N$ open, and $f\colon U \times Y \to \Bbb R$ such that $f(x, \cdot)$ is $\scr A$ -measurable and bounded, for all $x \in U$ , so we can define $F(x) = \int_Y f(x,y)\,{\rm d}\mu(y)$ . (a) If $f(\cdot, y)$ is continuous for all $y \in Y$ and $|f(x,y)| \leq M$ for all $(x,y) \in U \times Y$ for some $M  \geq 0$ , then $F$ is continuous. Let $x_0 \in U$ and take $(x_n)_{n \geq 1} \subseteq U$ such that $x_n \to x_0$ . Let's prove that $F(x_n) \to F(x_0)$ . By continuity of $f(\cdot, y)$ , we have that $x_n \to x_0$ implies that $f(x_n,y) \to f(x_0, y)$ . Since $|f(x,y)| \leq M$ , we have that $\int_Yf(x_n,y)\,{\rm d}\mu(y) \to \int_Y f(x_0,y)\,{\rm d}\mu(y)$ , but that's what we wanted. (b) Suppose now that $f(\cdot, y)$ is $C^1$ in $U$ for all $y \in Y$ and that $\left|\frac{\partial f}{\partial x_j}(x,y)\right| \leq M_1$ for all $(x,y) \in U \times Y$ for some $M_1 \geq 0$ . Show that $F$ is $C^1$ in $U$ and: $$\frac{\partial F}{\partial x_j}(x,y) = \int_Y \frac{\partial f}{\partial x_j}(x,y)\,{\rm d}\mu(y),$$ for all $x \in U$ , $j=1,2,\ldots, N$ . We can suppose without loss of generality that $N=1$ , so we want to prove that $F'(x) = \int_Y \frac{\partial f}{\partial x}(x,y)\,{\rm d}\mu(y)$ here. I also know that once we prove that $F'$ is given by that formula, the proof from (a) applies with $F' \leftrightarrow F$ and $\frac{\partial f}{\partial x} \leftrightarrow f$ , so that $F'$ being continuous is a given. We have to prove the formula, then. All the versions of this exercise I've seen so far or uses some uniform continuity, which I don't have here, or the integral is over $[0,1]$ , allowing the ${\rm stuff} = \int_0^1 {\rm stuff}\,{\rm d}y$ step. I only know that $\mu(Y) < +\infty$ , not that $\mu(Y) = 1$ . The natural thing to do was to use the MVT: \begin{align}\left|\frac{F(x)-F(x_0)}{x-x_0} - \int_Y \frac{\partial f}{\partial x}(x,y)\,{\rm d}\mu(y)\right| &= \left|\frac{f(x,y)-f(x_0,y)}{x-x_0} - \int_Y \frac{\partial f}{\partial x}(x,y)\,{\rm d}\mu(y)\right| \\ &= \left|\frac{\partial f}{\partial x}(\xi, y) - \int_Y \frac{\partial f}{\partial x}(x_0,y)\,{\rm d}\mu(y)\right|,\end{align} for some $\xi$ between $x$ and $x_0$ , and I can't do anything from here on. Now what?","['lebesgue-integral', 'analysis', 'measure-theory', 'integration']"
1463015,Let $f(z)\ = \frac {z^5} {|z|^4}$ if $z\ \neq 0$ and $f(0) = 0$,"Question : Conclude that the partials of u , v exist and that the Cauchy-Riemann equations hold but that $f'(0)$ does not exist. Does this conclusion contradict the Cauchy-Riemann Theorem? Could some one explain how I can prove this? I was sick and missed an entire week of class, but is this related to the Inverse Function Theorem? For the CR equations, the previous question told me to assume that $ u = Re(f)$ and $v = Im(f)$.",['complex-analysis']
1463017,"Given $v_i∈B^n$, bounding $\sum b_iv_i$ for $b_i= \pm 1$","Let $(v_i)_{i∈ℕ}$ be a vector sequence. Say $(v_i)$ is boundable (under $M$) if there exists a sequence $(b_i)_{i∈ℕ}$ taking values in $\{-1,1\}$ such that $(|\sum^N_i b_iv_i|)_{N∈ℕ}$ is bounded (under $M$). If $(v_i)$ takes values in the unit ball $B^n⊆ℝ^n$, does it follow $(v_i)$ is boundable? With the definition formulated analogously for finite sequences, I see I can utilize the (weak) Konig's lemma to show that a vector sequence is boundable under $M$ if and only if all its finite starting sequences are boundable under $M$. As such, it follows that if every such vector sequence is boundable, then there is a minimal such $α_n$ such that every vector sequence is boundable under $α_n$ (for example, $α_1=1$). Based on some randomized computations of mine it appears the hypothesis holds for $n=2$ and $1.6≤α_2≤1.7$, however I'm not sure how to continue. Edit: It appears actually that should the hypothesis be true, then $α_2 ≥ \sqrt{3}$. This diagram indicates how to construct a finite sequence unboundable under $r$ when $r < \sqrt{3}$: Start with the resultant vector $w_1$ (initial $v_1=(1,0)$) of magnitude $1$ or greater; choose the next vector $w_2$ such that $|w_1+w_2| > r$ yet the angle between $w_1,w_2$ is less than $2π/3$. Then $|w_1-w_2| > |w_1|$ and we can repeat the process with resultant vector $w_1-w_2$ to at least constantly greater effect each time. (Note the mirror situation of $b_1=-1$ is taken care of by symmetry)","['vectors', 'real-analysis', 'inequality']"
1463023,"""$F$-structures can be described in algebraic terms""","Let $(X, \mathcal O_X)$ be an affine variety (ringed space which is isomorphic to a closed subset of $k^n$).  An $F$-structure on $(X, \mathcal O_X)$ is defined (Springer, Linear Algebraic Groups) to be an $F$-structure $F[X]$ on $k[X]$ (which gives us a subtopology on $X$ of $F$-open sets), along with a collection of $F$-subalgebras $\mathcal O_X^F(U)$ of $\mathcal O_X(U)$, for each $U$ $F$-open in $X$, such that the natural $k$-algebra homomorphism $$k \otimes_F \mathcal O_X^F(U) \rightarrow \mathcal O_X(U)$$ is an isomorphism. Springer claims ""The proof of (the proposition that says that the ring of regular functions $\mathcal O_X(X)$ is really just the ring $k[X]$ of polynomial functions $X \rightarrow k$) carries over"" and gives us that $F[X] = O_X^F(X)$.""  That's fine, I'll verify what he claims later.  My question is about what he says next ""We conclude that affine $F$-varieties and their morphisms can be described in algebraic terms.""  What does he mean here?","['algebraic-groups', 'algebraic-geometry']"
1463025,Prove composition of two surjections is surjection,"Suppose $f: A \to B$ and $g: B \to C$ are both surjections. Since $f$ is surjective, then for every $b \in B$ there exists $a \in A$ such that $f(a)= b$.  Since $g$ is surjective, for every $c \in C$, there's  $b \in B$ such that $g(b) = c$. Then $g(f(a)) = g(b) = c$. Would this work? edit; I didn't realize there are similar questions on this site. Don't mind if this post is deleted.","['elementary-set-theory', 'proof-verification']"
1463046,real-valued measurable function under a transformation.,"Here's the question:  ""Let $f \colon \mathbb{R} \to \mathbb{R}$ be measurable. Show that $f(ax)$ is measurable for all real $a$."" I know we can to look at sets of the form $\{f \geq \alpha\}$, where $\alpha$ is any real number. Yet, I'm not sure what this information gives us about the function $f(ax)$. Maybe I'm missing something obvious?  Any hints are very appreciated!","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1463061,Prove $\frac{1\cdot 3\cdot 5\cdots (2n - 1)}{ 2^n(n + 1)!}\cdot 4^n= \frac{1}{n+1} {2n\choose n}$,"Prove: 
$$
 \frac{1\times 3\times 5\times \cdots \times (2n - 1)}{2^n (n + 1)!} \times 4^n = \frac{1}{n+1} \binom{2n}{n}
$$ -Sorry I don't know how to do choose notation in stack exchange. I'm having a bit of trouble proving this, I tried to prove this by induction and would get stuck. Any help is appreciated in advance.","['induction', 'discrete-mathematics']"
1463075,Evaluating a strange sequence [duplicate],"This question already has answers here : Solve $x\sqrt{x\sqrt{x\sqrt{x\dots}}} = 4$ (6 answers) Closed 8 years ago . I'm a first year undergrad maths student and I've come across this particular sequence, which I can't find a limit for. $$\underbrace{\sqrt{10\sqrt{10\sqrt{10\sqrt{10\cdots}}}}}_{n \text{ times}}$$ I know this may be embarrassingly easy, but I can't think of a way to start. Can you share any hints?","['sequences-and-series', 'limits']"
1463102,Generalization of probability,"Suppose I am not only interested in a certain probability of an event $p \in [0,1]$, but have a ""deeper uncertainty"", so to speak, which I would model as a CDF of probabilities $F(p) \in [0,1] \to [0,1]$. Does this extend indefinitely to $F(F(p)) \in ([0,1] \to [0,1]) \to [0,1]$, and so on? How can I deal with the infinite dimensions of the spaces of functions and spaces of sets of functions, etc? For example, imagine I want to bet on the outcome $X$ of a coin, which is $X=0$ if it comes out heads and $X=1$ if it comes out tails. My bet would not be effected if I restrict myself to the probability of heads, which can be obtained by integrating out $f_P(p)$ by taking $$p^*=\Pr(X=1)=\operatorname{E}[P]=\int_0^1 p f_P(p) \, dp.$$ Now if I instead toss the same coin multiple times, I can update my estimate of $p$ using $F(p)$, which may be obtained by integrating over $F(F(p))$ -- but what does this space (of all possible $F(p)$) even look like? Edit: To further clarify, suppose we assign a density $f_{F_P}(F_P)$ to each CDF. We can obtain a cdf of probabilities by integrating out $f_{F_p}(F_P)$ $${f}^*_p(p)=\lim_{\delta \to 0} \frac{1}{\delta} \Pr(p \le P \le p+\delta)=\int f_P(p)f_{F_p}(F_p)dF_P$$ But the space spanning all possible $F_P$ has infinite dimension. How to proceed? (for example, what would an uniform distribution over $F(F_p)$ look like?)",['probability-theory']
1463120,A Question about derivative.,"Suppose that $f:\mathbb{R} \to \mathbb{R}$ is differentiable, $f(0)= 0$, and $f’(x) > f(x)$
for all $x \in \mathbb{R}$. Prove that $f(x) > 0$ for $x >0$. 
Clear, $f'(0)> 0$ and by defintion, $f'(0)> f(0)=0$.
Any hints are welcome.","['calculus', 'real-analysis', 'limits', 'derivatives']"
1463140,Proof for why a matrix multiplied by its transpose is positive semidefinite,"The top answer to this question says Moreover if $A$ is regular, then $AA^T$ is also positive definite,
  since $$x^TAA^Tx=(A^Tx)^T(A^Tx)> 0$$ Suppose $A$ is not regular. It holds that
$$x^TAA^Tx=(A^Tx)^T(A^Tx)= \|A^Tx\|^2_2  \ge 0$$
Therefore $AA^T$ is positive semidefinite.
Is this argument enough, or am I missing something?","['normed-spaces', 'matrices']"
1463142,What do I do next when trying to find the derivative of this fraction?,"I'm trying to find the derivative of this equation: $-\frac{3(x-6)}{2\sqrt{9-x}}$ The quotient rule: $\frac{d}{dx}[\frac{f(x)}{g(x)}]=\frac{g(x)f'(x)-f(x)g'(x)}{(g(x))^2}$ where $g(x)$ and $f(x)$ are functions. So I take out the constants and I'm left with $\frac{-3}{2}\frac{d}{dx}[\frac{(x-6)}{\sqrt{9-x}}]$. $f(x)$ is $(x-6)$ and $g(x)$ is $(9-x)^{1/2}$. This is what it expands to: $$\frac{-3}{2} \left[\frac{(9-x)^{1/2}\frac{d}{dx}[x-6]-(x-6)\frac{d}{dx}[(9-x)^{1/2}]}{((9-x)^{1/2})^2}\right]$$ After simplifying, I get: $$\frac{-3}{2}\left[\frac{(9-x)^{1/2}(1)-(x-6)[(\frac{1}{2})(9-x)^{-1/2}(-1)]}{9-x}\right]$$ $$\frac{-3}{2}\left[\frac{\sqrt{9-x}-(x-6)(-1)}{2(9-x)\sqrt{9-x}}\right]$$ $$\frac{-3}{2}\left[\frac{\sqrt{9-x}+x-6}{2(9-x)\sqrt{9-x}}\right]$$ $$\frac{-3\sqrt{9-x}-3x+18}{4(9-x)\sqrt{9-x}} \text{ ??}$$ What did I do wrong? Wolfram Alpha says the answer is: $\frac{3(x-12)}{4(9-x)^{3/2}}$","['solution-verification', 'calculus', 'derivatives']"
1463180,Finding probability $P(x + y \le 1)$ given the joint pdf,"So in the problem I was given the joint pdf $f(x,y) = x + y$, $0< x <1$, $0< y <1$, $0$ elsewhere. I am tasked to find $P( x+y \le 1 )$. My intuition was to $\int_0^1\int_{1-x}^1 (x+y) \, dy \, dx $ working that out, i got the answer of 50%. Is my intuition correct?",['statistics']
1463196,Question about subset and elements.,"Let $A = \{3,4\}$ be a subset of $S = \{1,2,\ldots,6\}$. Or $A \subseteq S$ and $n \in A$, what is $n \notin A$? Would $n \notin A$ be $\{1,2,5,6\}$? Does that question even makes sense? Help! Trying to solve a proof question but I'm confused with the contrapositive of $n \in A$",['discrete-mathematics']
1463213,Cauchy sequence that satisfies $\|x_{k+2}-x_{k+1}\|\le\theta\|x_{k+1}-x_k\|$,"Suppose the sequence $\{x_k\}_{k=1}^\infty\subset\mathbb{R}^n$ satisfies $\|x_{k+2}-x_{k+1}\|\le\theta\|x_{k+1}-x_k\|$ for all $k\ge1$, with $0<\theta<1$. Show that $\{x_k\}$ is a Cauchy sequence and hence converges. So I did some rearranging to try and get something that worked and got this: For $m,n>1$ such that $m<n$ $$\|x_n-x_m\|=\|x_n+\left(\sum_{i=m+1}^{n-1}(x_i-x_i)\right)-x_m\|$$
$$\le \sum_{i=m+1}^n\|x_i-x_{i-1}\|\text{ (triangle inequality)}$$
$$\le\left(\sum_{i=0}^{n-m}\theta^i\right)\|x_{m+1}-x_m\|$$ Is it sufficient to choose $N$ for any $\epsilon$ such that $\|x_{N+1}-x_N\|<\epsilon$ and since $\left(\sum_{i=0}^{n-m}\theta^i\right)<1$ I can use the above derivation?","['analysis', 'sequences-and-series', 'cauchy-sequences']"
1463216,Asymptotic value of card drawing game,"A deck consisting of $r_0$ red cards and $b_0$ black cards is randomly shuffled. The host turns up the cards one at a time; if it is red, you get $\$1$; otherwise you pay the host $\$1$ (and you're allowed to go into debt).  You can stop the game at any time (even at the beginning of the game). Let $f(r_0,b_0)$ denote the value of the game. Question: What is the asymptotic behavior of $f(n,n)$?  More generally, for fixed $\Delta\in\mathbb{Z}$, what is the asymptotic behavior of $f(n+\Delta,n)$? Partial analysis. The state of the game at any point is a pair $(r,b)$ indicating the number of cards of each color remaining.  Let $f_{r_0,b_0}(r,b)$ denote the current value of the game if the initial state was $(r_0,b_0)$ and the current state is $(r,b)$.  Note that our accumulated balance at $(r,b)$ is $(r_0-r)-(b_0-b)=(b-r)+\Delta$ dollars.  Since we can either stop there or keep playing, we have the recurrence
$$f_{r_0,b_0}(r,b)=\max\left(b-r+\Delta,\frac{r}{r+b}f_{r_0,b_0}(r-1,b)+\frac{b}{r+b}f_{r_0,b_0}(r,b-1)\right).$$ Since the recurrence only depends on $\Delta$, not on $r_0$ or $b_0$ individually, it makes sense to define $f_\Delta(r,b)$ to be the value of the game at state $(r,b)$ if the initial state $(r_0,b_0)$ satisfied $r_0-b_0=\Delta$.  We have
$$f_\Delta(r,b)=\max\left(b-r+\Delta,\frac{r}{r+b}f_\Delta(r-1,b)+\frac{b}{r+b}f_\Delta(r,b-1)\right),$$
with $f(r_0,b_0)=f_\Delta(r_0,b_0)$ where $\Delta=r_0-b_0$. The boundary conditions are $f_\Delta(0,0)=\Delta$, and $f_\Delta(r,b)=0$ if either $r$ or $b$ is negative.  [Thanks to Julian Rosen for catching an error in my original posting here.]  It's now easy to check that $f_\Delta(r,b)=\Delta+f_0(r,b)$, so it suffices to compute $f_0$.  Calculating individual values of $f_0(r,b)$ is easy using the recurrence and dynamic programming.  Here are values of $f_0(r,b)$ for small $r$ and $b$:
$$
\begin{array}{c|ccccccc}
 r\,\backslash\,b & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
 0 & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\
 1 & 0 & \frac{1}{2} & 1 & 2 & 3 & 4 & 5 \\
 2 & 0 & \frac{1}{3} & \frac{2}{3} & \frac{6}{5} & 2 & 3 & 4 \\
 3 & 0 & \frac{1}{4} & \frac{1}{2} & \frac{17}{20} & \frac{47}{35} & 2 & 3 \\
 4 & 0 & \frac{1}{5} & \frac{2}{5} & \frac{23}{35} & 1 & \frac{13}{9} & \frac{31}{15} \\
 5 & 0 & \frac{1}{6} & \frac{1}{3} & \frac{15}{28} & \frac{50}{63} & \frac{47}{42} & \frac{358}{231} \\
 6 & 0 & \frac{1}{7} & \frac{2}{7} & \frac{19}{42} & \frac{23}{35} & \frac{10}{11} & \frac{284}{231} \\
\end{array}
$$ The diagonal entries in the table above lead to OEIS sequences A108883 -A108886, which describe this game (as an urn game), but no asymptotics are given. The value of the game from the starting point $(r_0,b_0)$ is $f_{r_0-b_0}(r_0,b_0)=f_0(r_0,b_0)+r_0-b_0$; numerically, this is:
\begin{array}{c|ccccccc}
 r_0\,\backslash\,b_0 & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
 0 & 0 & 0. & 0. & 0. & 0. & 0. & 0. \\
 1 & 1. & 0.5 & 0. & 0. & 0. & 0. & 0. \\
 2 & 2. & 1.33333 & 0.666667 & 0.2 & 0. & 0. & 0. \\
 3 & 3. & 2.25 & 1.5 & 0.85 & 0.342857 & 0. & 0. \\
 4 & 4. & 3.2 & 2.4 & 1.65714 & 1. & 0.444444 & 0.0666667 \\
 5 & 5. & 4.16667 & 3.33333 & 2.53571 & 1.79365 & 1.11905 & 0.549784 \\
 6 & 6. & 5.14286 & 4.28571 & 3.45238 & 2.65714 & 1.90909 & 1.22944 \\
\end{array} Here are plots of $\ln f(n,n)$ and $\ln f(n,n) / \ln n$ for $n\le 1000$: Remark. This question arose based on my misreading of this question .","['asymptotics', 'recurrence-relations', 'probability', 'card-games']"
1463217,Is $\int |x\rangle \langle x|dx$ Mathematical?,"I am enrolling in a Quantum Mechanics class. As we all know, the formulation of the basic ideas from QM relies heavily on the notion of Hilbert Space. I decide to take the course since it might help me understand the motivation underlying the theory of unbounded operators. However, things started to get confusing when the teacher introduced the inner product of the quantum states. Suppose there are two vectors $|\phi \rangle$,$|\psi \rangle$ represented by two column vectors $v$,$u$ respectively, he then defined their inner product to be
$$
\langle \psi  |\phi \rangle = \bar u^t v
$$
which makes perfect sense to me. He then went on to explain the continuous case by first introducing the thing called ""completeness relation""
$$
1=\sum |i\rangle\langle i|
$$ 
where $|i\rangle$'s are the normalized eigenvectors of an Hermitian Operator. I, as the only math major in the class, recognize the term on the RHS as the projector into the subspace spanned by the orthonormal sequence $(|i\rangle)_{i=1}^\infty$, which is equal to identity since the sequence is complete. He then went on to find a way to calculate $\langle \psi  |\phi \rangle$ in the case where $|\phi \rangle$,$|\psi \rangle\in L^2[-a,a]$, the so-called infinite square well. He said that since the state is continuous (whatever that means) the above summation approach an integration, so we have
$$
1=\int |x\rangle \langle x|dx
$$
instead. Then he demonstrated
$$\begin{align}
\langle \psi|\phi \rangle &= \langle \psi|1|\phi \rangle \\
&= \langle \psi|(\int |x\rangle \langle x|dx)|\phi \rangle \\
&= \int \langle \psi|x\rangle \langle x|\phi \rangle dx \\
&= \int \overline{\langle x|\psi\rangle} \langle x|\phi \rangle dx \\
&= \int \bar\psi(x)\phi(x) dx
\end{align}$$
, which makes very little sense to me. I had always seen the relation as THE definition of inner product in $L^2$ space, not something to be derived. When I asked him questions about the derivation he tried to justify it by saying something about Dirac's delta being an element of the Hilbert space (the irony) and the family of shifted Dirac's delta constitutes a basis (in some vague sense) of $L^2[-a,a]$. While knowing that my teacher's statement makes little sense in the theory of Hilbert space, which is not untypical of a physicist by the way (This is not meant to be an accusation by any mean, I really respect him and he's a good physicist. However the word ""physicist"" and ""rigor"" are usually mutually exclusive), I've learned about existence of Rigged Hilbert space and heard that it partially resolve some foundational issues with using Dirac's delta in QM. Here's my questions: 1.) I wonder if the notation $\int |x\rangle\langle x|dx$
has definite meaning in the Rigged Hilbert space? 2.) Could anyone please explain to me if the derivation is sound in ANY mathematical theory? Note that I'm an undergraduate so I'd really appreciate some not-to-advanced answers :) Thank you in advance. Edit : What does $\langle x|\phi \rangle = \phi(x)$ means anyway? At first I think it looks like the evaluation map but now I'm not quite sure.","['distribution-theory', 'functional-analysis', 'hilbert-spaces', 'mathematical-physics', 'spectral-theory']"
1463269,How to obtain the sum of squared eigenvalues without finding the eigenvalues?,How to obtain sum of square of eigenvalues without finding eigenvalues of a matrix?,"['eigenvalues-eigenvectors', 'matrices']"
1463291,"Formally derive $\displaystyle\int_{x=-\infty}^{x=\infty} f(x) \delta(x) \, \mathrm{d}x = f(0)$","I have been searching for a derivation of the defining property for the Dirac-delta function: $\displaystyle\int_{x=-\infty}^{x=\infty} f(x) \delta(x) \, \mathrm{d}x = f(0)$ and found this derivation on the first 2 pages: Defining the Heaviside (step) function $H(x)$ as $$H(x) = \begin{cases} 0 & \text{for } x \lt 0 \\1& \text{for } x \gt 0 \end{cases} $$ The derivative of the Heaviside function is zero for $x \ne 0$ and undefined for $x=0$ so the $\delta$ function can represent the derivative of the Heaviside function $$\delta(x) = \begin{cases} 0 & \text{for } x \ne 0 \\\infty& \text{for } x = 0 \end{cases} $$ and $$\int_{x=-\infty}^{x=\infty} \delta(x) \, \mathrm{d}x=1$$ Let $f(x)$ be any continuous function that vanishes at $x=\pm\infty$ and integrating by parts \begin{align}
& \int_{x=-\infty}^{x=\infty} f(x)\delta(x) \, \mathrm{d}x = \color{green}{\left.\vphantom{\frac 1 1} f(x)H(x) \right|_{x=-\infty}^{x=\infty}} -
\int_{\color{red}{x=-\infty}}^{x=\infty} f^\prime(x)H(x) \, \mathrm{d}x \\[10pt]
= {} &0-\int_{\color{red}{x=0}}^{x=\infty} f^\prime(x)H(x) \, \mathrm{d}x= \left.\vphantom{\frac 1 1}-f(x) \right|_{x=0}^{x=\infty}=f(0)
\end{align} Could someone please explain how the limits marked $\color{red}{\mathrm{red}}$ were changed? Thank you. (and yes I know from last time , it's an abuse of notation placing the Dirac measure/distribution inside an integral)","['dirac-delta', 'calculus', 'proof-verification', 'integration']"
1463294,Bounded convergence theorem: is the limit function bounded?,"I'm self-studying Durrett (2010). There, he states the Bounded convergence theorem as follows: Let $E$ be a set with $\mu(E)<\infty$. Suppose $f_n$ vanishes on $E^c$, $|f_n(x)|\leq M$, and $f_n\to f$ in measure. Then
  $$
\int f\;d\mu=\lim_{n\to\infty}\int f_n\;d\mu.
$$ The proof appears to employ the fact that $f$ itself vanishes on $E^c$ and $|f(x)|\leq M$. Are these last two facts implied by the premise of the theorem?","['probability-theory', 'limits', 'measure-theory', 'integration']"
1463296,Clarification of proof that a circle is not homeomorphic to a closed interval.,"The motivation for this question comes from a proof I just saw demonstrating that a circle in the plane and $[a,b]$ are not homeomorphic. The argument consists of removing a point from the circle, and also a point from $[a,b]$ which i not an endpoint. Upon removal of this point from both we observe that the circle remains connected while the interval is disconnected. From my understanding, $\mathbb{R}$ is connected and therefore has no proper clopen subsets. But if we can take $[a,b] \in \mathbb{R}$ and disconnect it by removing a point which is neither $a$ or $b$, then this subset of $\mathbb{R}$ has a proper clopen subset, which means that $\mathbb{R}$ has a proper clopen subset. I know that this reasoning is somehow wrong, but I'm not sure where my misunderstanding lies and I would appreciate any help. Also, what would be the proper clopen subset of $[a,b]$ minus a single point that makes it disconnected?",['general-topology']
1463333,Which matrices are conjugate to an integer valued matrix?,"If I have a matrix $A \in M_{n\times n}(\mathbb{C})$, when does there exist a change of basis $B \in Gl_n(\mathbb{C})$ so that $BAB^{-1} \in M_{n\times n}(\mathbb{Z})$? Case $n=1$ is obvious (in this case, $A$ is a number, so $A$ must be an integer). Case $n=2$ already seems impossible to do by brute force. I do know it's not trivial though. Is there a nice characterization of such matrices?",['linear-algebra']
1463388,why this sequence is period $a_{n+5}=a_{n}$,"Let $a_{0}=a>0,a_{1}=b>0$,and such 
$$a_{n+1}a_{n-1}=\max\{(a_{n},1)\},\forall n\in N^{+}$$
show that
$$a_{n+5}=a_{n}$$ Even $a,b$ with the 1 uncertainty,so we can't $$a_{2}=\dfrac{\max{(a_{1},1})}{a_{0}}=\begin{cases}\dfrac{a_{1}}{a_{0}}&a_{1}\ge 1\\
\dfrac{1}{a_{0}},&a_{1}<1
\end{cases}$$, But This sequnece always is period $5$. it looks very interesting.following when I determine$a_{3}$,I can't.Thanks so much for any suggestion.",['sequences-and-series']
1463393,"why $ \rm{lcm}[1,2,3,\cdots,n]\in (2^n,4^n)$","Let $n\ge 7$ be positive integers,show that
$$f(n)=\rm{lcm}[1,2,3,\cdots,n]\in (2^n,4^n)$$ Anyone know this problem background?or maybe have best proof or best result?","['approximation', 'least-common-multiple', 'prime-numbers', 'number-theory', 'inequality']"
1463396,Hipergeometric. Kids and candy.,"Problem There are $15$ identical bags of candy each containing $20$ yellow, $15$ red, $5$ blue and $10$ green
candies. $15$ children are each given their own candy bag and each randomly
picks $12$ candies from their own bags. What is the probability that at least two
of the kids will have at least one green candy? This what I get so far: Each bag contains $N=50$ candies out of which $k=10$ are green. Each child draws $n=12$ times without replacement. Considering the number of ""successes"", drawing a green candy, this is a Hypergeometric distribution with parameters $N,k,n$. Therefore, the probability that a child draws at least one candy is $$1-\frac{40\choose12}{50\choose 12}.$$ Now, I need to calculate the probabilty of two of this 15 kids  will have at least one green candy. I'm stuck here. I show my progress, after the help: I calculate P(X>=)=1-P(X=0) = 0.9539
Then Y=# of kids with green candy. P(y>=2)= 1- 15Cn0 p^0 (1-p0)^15 - 15Cn1 p^1 (1-p)^14
      = 1-[(1)(1)(0.0461)^15 - (15 (0.9539) (0.0461)^14]
      = aprox 1 After all this I'm thinking: Is that true? The probability of at leat two kids have at least one green candy could be 100%? Thanks, for your help community.","['probability', 'statistics']"
1463398,If $S_2$ reaches the semi-final then the probability that $S_1$ wins the tournament is $\frac{1}{20}$,"In  a knockout tournament $2^n$ equally skilled players;$S_1,S_2,...,S_{2^n}$ are participating.In each round players are divided in pair at random and winner from each pair moves in the next round.If $S_2$ reaches the semi-final then the probability that $S_1$ wins the tournament is $\frac{1}{20}$.Find the value of $n.$ There will be $n$ rounds of the tournament because $2^n$ players are there.But i dont know how to solve further.Some help/hints are needed.Thanks.",['probability']
1463409,Length of an interval is its outer measure,"To prove that the Lebesgue outer measure $m^*(I)$ of a closed interval $I$ is less or equal to its length $l(I)$  is easy enough. The converse however starts with a step that seems obvious but that I can not seem to prove: For an arbitrary $\epsilon>0$, and closed cover $\{I_n\}$ of $I$, it is said (Measure integral and probability, P.22) that $$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I) + \frac{\epsilon}{2}$$
What I know from the outer measure being a infimum is that $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)$$ so I could write $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+2[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$$
$$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+\frac{\epsilon}{2}$$ with $\epsilon :=4[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$, but that does not sound like an arbitrary $\epsilon$ to me... Any hints ? thanks. Following hints to exploit the infinum definition for $m^*$, I come to the following argument. Argue the opposite, namely that
$$ m^*(I)+\frac{\epsilon}{2}<\sum_{n=1}^{\infty}l(I_n)
\tag{1}$$ so $m^*(I)+\frac{\epsilon}{2}$ is a lower bound for $\sum_{n=1}^{\infty}l(I_n)$, also $m^*(I)+\frac{\epsilon}{2} > m^*(I)$ another lower bound for the sum. So it remains to find a cover of $I$ with length $m^*(I)+\frac{\epsilon}{2}$, and it would then be the greatest lower bound contradicting the definition of $m^*(I)$ as the g.l.b. Let $\{I_n^*\}$ with endpoints $a_n^*,b_n^*$ be the cover that achieves $m^*$, define the cover $\{I_n^{\epsilon}\}$ $$I_1^{\epsilon}:=(a_1-\frac{\epsilon}{4},b_1+\frac{\epsilon}{4})\\I_i^{\epsilon}=I_i^*,i>1$$ then $\sum_{n=1}^{\infty}l(I_n^{\epsilon})=\sum_{n=1}^{\infty}l(I_n^*)+\frac{\epsilon}{2} = m^*(I)+\frac{\epsilon}{2}$
So we found a cover that acheives l.h.s of $(1)$, contradicting the definition of $m^*(I)$ as the g.l.b. Is that correct ?","['real-analysis', 'measure-theory']"
1463419,What is the probability that the letter came from LONDON?,"A letter has come from exclusively LONDON or CLIFTON, but on the postmark only $2$ consecutive letters ''ON'' are found to be visible. What is the probability that the letter came  from LONDON? This is a question of conditional probability. Let $A$ be the event that the letter has come from LONDON. Let $B$ be the event that consecutive letters ''ON'' are found to be visible. $A\cap B$ is the event that the letter has come from LONDON and consecutive letters ''ON'' are visible. We have to find $P(A\mid B)    
=\frac{P(A\cap B)}{P(B)}$. But then i am stuck. Please help me. Thanks.",['probability']
1463428,Limit of infinity times zero,"I'm trying to evaluate $\displaystyle\lim_{x\to\infty} e^x[e^x\log(1-e^{-x}) - \log(1-e^{-x})+ 1]$. Using L'hopital's rule I know $\displaystyle\lim_{x\to\infty} e^x\log(1-e^{-x}) = -1$ and so I have a $\infty$ times $0$ situation. My problem is that when I use L'hopital's rule on the entire expression $e^x[e^x\log(1-e^{-x}) - \log(1-e^{-x})+ 1]$ I seem to be going in an infinite loop. If I try to evaluate it this way: $\frac{e^x\log(1-e^{-x}) - \log(1-e^{-x})+ 1}{e^{-x}}$ then I always end up with $e^x\log(1-e^{-x})$ on the numerator and $e^{-x}$ on the denominator no matter how many times I take derivatives. These 2 will never simplify to give a nice solution. If I try the other way and evaluate it this way: $\frac{e^x}{\frac{1}{e^x\log(1-e^{-x}) - \log(1-e^{-x})+ 1}}$ then I always end up with $e^x[e^x\log(1-e^{-x}) - \log(1-e^{-x})+ 1]^n$ for some integer $n$, which is basically the same as where I started. Are there any other methods that can be used to evaluate this kind of limit? I don't have anything else in my bag of tricks.","['calculus', 'limits']"
1463437,Find the sum of digits in the product of $A$ and $B$,"My question is If $A$= $9999...........$($77$ times or $77$ digits) and $B$= $7777............$($99$ times or $99$ digits)
Then find the sum of digits in the product of $A$ and $B$.
I have a query that if we have same number of digits then i can easily figure out the sum but in the question it is different. Any help will be appreciated. Note: $$9.7 = 63$$ $$99.77=7623$$
      $$999.777=776223$$ and so on...","['sequences-and-series', 'number-theory']"
1463441,Question about complex analysis in proof in Ingham,"This is a detail from a proof in Ingham's Distribution of Prime Numbers, p. 91-92. He forms a Dirichlet integral and assumes for contradiction that the numerator $c(x)\geq 0.$ Then he bounds $f(s)$ in order to find an inequality for a constant $k$ that is inherently contradictory. My question is about the details of the complex algebra in the penultimate step. Note, $k\neq K.$ Assume RH. $k$ is a positive constant. $$c(x) = \frac{\psi(x)- x + k x^{1/2}}{x},$$ then for $\sigma > 1$ we have $f(s)=\int_1^{\infty}\frac{c(x)}{x^s}dx$ in which $$f(s) = -\frac{1\zeta'}{s\zeta}(s)-\frac{1}{s-1}+\frac{k}{s-1/2}$$ For $\sigma > 1/2$ there are no singularities of $f$ on the real line, and so the abscissa of convergence is $1/2.$ Suppose (for contradiction) $c(x) \geq 0$ for all $x>X (>1).$ Leaving out some detail we get $ | f (\sigma+ t i) | \leq \int_1^X   \frac{ | c(x |)}{x^{\sigma}}dx +\int_X^{\infty} \frac{c(x)}{x^{\sigma}} dx = ...\leq K+ f(\sigma),$ with K independent of $\sigma, t.$ Take $t = \gamma_1,$ where $1/2 + \gamma_1 i$ is the zero with the least positive $\gamma,$ multiply both sides by $(\sigma -1/2),$ and let $\sigma \to (1/2 + 0);$ this gives $$ \frac{m_1}{|1/2 + \gamma_1|}\leq k$$ where $m_1$ is the multiplicity of the zero $1/2 + \gamma_1.$ The part in yellow is verbatim. Can someone explain the details of this step?","['riemann-zeta', 'complex-analysis', 'analytic-number-theory']"
1463456,Meaning of natural homomorphism,"When I reached the homomorphism concept in group theory, I thought that ""natural"" is only an ordinary literal word without mathematical meaning. But I read somewhere that this word has a precise mathematical meaning in the theory of categories. I am not familiar with category theory; only I know it deals with morphisms. Could you explain me the meaning of ""natural"" in the category theory?","['abstract-algebra', 'group-homomorphism', 'group-theory', 'category-theory']"
1463464,How to explain the behaviour of $\int x^n dx$ near $n = -1$ to a layman?,"From both sides, this approaches infinity, but when evaluated exactly at $n = -1$, yields $\ln (x)$. This seems similar to the behaviour of solutions to linear ODEs with characteristic polynomials (as the determinant approaches 0, a factor of $x$ appears next to the repeated root). How can I explain this phenomenon to a layman? Obviously, I could show a proof of both, but that is probably not enough to be satisfactory. How does an infinity turn into a logarithm at the drop of a hat? As an aside, is there a name for this behaviour?","['calculus', 'soft-question', 'functions']"
1463466,A calculation problem about differential equation,"Let $n>2$ and $n\in \mathbb{N}_+$, $\lambda  \ge  - \frac{{{{\left( {n - 1} \right)}^2}}}{4}$.
  For $x>0$, we have $$f\left( x \right) = {\left( {\sinh x} \right)^{2 - n}}\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^\eta }{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} .$$
  Solving the value of $\eta$ such that function $f(x)$ satisfies differential equation $$f''\left( x \right) + \left( {n - 1} \right)\frac{{\cosh x}}{{\sinh x}}f'\left( x \right) - \lambda f\left( x \right) = 0.$$ Adding: This is a difficult problem! I have get 
\begin{align*}&f'\left( x \right) = \left( {2 - n} \right){\left( {\sinh x} \right)^{1 - n}}\cosh x\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^\eta }{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} \\+ &\eta {\left( {\sinh x} \right)^{3 - n}}\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^{\eta  - 1}}{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} .\end{align*}
and 
\begin{align*}&f''\left( x \right) = \left( {2 - n} \right)\left[ {\left( {1 - n} \right){{\left( {\sinh x} \right)}^{ - n}}{{\left( {\cosh x} \right)}^2} + {{\left( {\sinh x} \right)}^{2 - n}}} \right]\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^\eta }{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} \\+ &\left( {5 - 2n} \right)\eta {\left( {\sinh x} \right)^{2 - n}}\cosh x\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^{\eta  - 1}}{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} \\+ &\eta \left( {\eta  - 1} \right){\left( {\sinh x} \right)^{4 - n}}\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^{\eta  - 2}}{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} .\end{align*}
Note that $$f''\left( x \right) + \left( {n - 1} \right)\frac{{\cosh x}}{{\sinh x}}f'\left( x \right) - \lambda f\left( x \right) = 0.$$
So we get \begin{align*}&\left( {2 - n-\lambda} \right)\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^\eta }{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} \\+& \left( {4 - n} \right)\eta \cosh x\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^{\eta  - 1}}{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt} \\+& \eta \left( {\eta  - 1} \right){\left( {\sinh x} \right)^2}\int_0^\pi  {{{\left( {\cosh x + \cos t} \right)}^{\eta  - 2}}{{\left( {\sin t} \right)}^{2\sqrt {\lambda  + \frac{{{{\left( {n - 1} \right)}^2}}}{4}} }}dt}  = 0.\end{align*}
But I have no way to continue, thanks for your help!","['analysis', 'calculus', 'ordinary-differential-equations', 'integration']"
1463496,"Is there a non empty set a such that for every $x∈a$ , $\{x\}∈a$ ? - Axiom of Infinity","Is there any non empty set a such that for every $x∈a$ , $\{x\}∈a$ ? If it is true, how do you deduce the statement from ZFC ( heavy use of the Axiom of Infinity I suspect) & if it false, where does the contradiction appear from ? And, if it is true, does it work as a weaker version of Infinity ? It seems to be the one originally used by Zermelo.","['elementary-set-theory', 'axioms']"
1463537,Do polynomials in two variables always factor in linear terms?,"Consider a polynomial of one variable over $\Bbb C$:
$$p(x)=a_0+a_1x+\cdots+a_nx^n,\quad a_i\in\Bbb C.$$
We know from the Fundamental Theorem of Algebra that there exists $c,\alpha_i\in\Bbb C$ such that
$$p(x)=c(x-\alpha_1)\cdots(x-\alpha_n),$$
i.e. we can factor $p$ in linear terms . Now, what about polynomials $p(x,y)$ in two variables? Is it still true that we can factor $p(x,y)$ in linear terms? I.e. can we always write
  $$p(x,y)=c(\alpha_1x+\beta_1y+\gamma_1)\cdots(\alpha_nx+\beta_ny+\gamma_n)$$
  for some $c,\alpha_i,\beta_i,\gamma_i\in\Bbb C$?","['abstract-algebra', 'polynomials']"
1463559,Action of a finite abelian group on a finite set,"Let $G$ be a finite abelian group acting on a finite set $X$. Let $\mathcal{O}(x)$ be the orbit of $x$:
$$\mathcal{O}(x)=\{g.x\colon g\in G\}.$$
Then obviously $G$ acts transitively on $\mathcal{O}(x)$. Question: Does $G$ contain a subgroup $H$ which acts transitively on $\mathcal{O}(x)$ with $|H|=|\mathcal{O}(x)$?","['group-theory', 'finite-groups']"
1463581,Show that given piecewise function does not have a convergent series from Picard-iteration,"This is a homework question. Given an initial value problem, $\frac{dx}{dt} = f(t,x(t)), \text{ } x(0) = 0$ with the function defined as: $$
f(t,x(t)) =
  \begin{cases} 
      \hfill 0    \hfill & t \leq 0 \\
      \hfill 2t   \hfill & t>0, \text{ } x \leq 0 \\
      \hfill 2t-4\frac{x}{t} \hfill & t>0, \text{ } 0<x<t^2\\
      \hfill -2t  \hfill & t>0, \text{ } x \geq t^2,
  \end{cases}
$$
I have to show that the $x_n$ sequence(acquired by Picard-iteration) is not convergent, nor does it have a convergent subsequence which converges to a solution. I'd like to be provided the least help possible. What I've so far tried is: Showing f is not locally Lipschitz-continuous. This is part of the problem (""Notice that f is continuous, but not locally Lipschitz-continuous!""). As I remember, this is done by evaluating the partial derivatives. The derivative with respect to t is 0 in the first, and 2 in the second interval (with x being x(t), I'm not sure this is the correct method, though), so I did no further evaluation. Calculating the $x_n$ members. This goes as follows ($x_0 := x(0) = 0) $:
$$
x_{n+1} = x(0) + \int_\limits{0}^t f(s, x_n (s))ds.
$$
What I got is 
$$
x_n(t) =
  \begin{cases} 
      \hfill 0    \hfill & t \leq 0 \\
      \hfill \frac{2t^{n+1}}{(n+1)!}   \hfill & t>0, \text{ } x<t^2 \\
      \hfill -\frac{2t^{n+1}}{(n+1)!}   \hfill & t>0, \text{ } x \geq t^2.
  \end{cases}
$$
At this point, I ask the question: are these two steps correct (in showing f is not Lipschitz-continuous locally, and acquiring $x_n(t)$)? My next step would be first to substitute $x_n$ into the initial value problem, getting:
$$
  \begin{cases} 
      \hfill 0 = 0    \hfill & t \leq 0 \\
      \hfill \frac{2t^{n}}{n!}=2t   \hfill & t>0, \text{ } x_n \leq 0 \\
      \hfill \frac{2t^{n}}{n!}=2t-4\frac{\frac{2t^{n+1}}{(n+1)!}}{t} \hfill & t>0, \text{ } 0<x_n<t^2\\
      \hfill -\frac{2t^{n+1}}{(n+1)!}=-2t  \hfill & t>0, \text{ } x_n \geq t^2,
  \end{cases}
$$
$$
  \begin{cases} 
      \hfill 0 = 0    \hfill & t \leq 0 \\
      \hfill \frac{t^{n-1}}{n!}=1   \hfill & t>0, \text{ } x_n \leq 0 \\
      \hfill \frac{(n+5)t^{n-1}}{(n+1)!}=1 \hfill & t>0, \text{ } 0<x_n<t^2\\
      \hfill \frac{t^{n}}{(n+1)!}=1  \hfill & t>0, \text{ } x_n \geq t^2.
  \end{cases}
$$
This leads to quite strange inequalities. Substituting into $x_n$ I could get contradictions on all except the first line, I believe, and thus I could show that for any n, it cannot satisfy the initial value problem. But how do I show that the limit does not satisfy it either (with t remaining as a variable)? Edit: This seems to be an exercise in the book Solving Ordinary Differential Equations I: Nonstiff Problems (I.8 / 5.).","['sequences-and-series', 'ordinary-differential-equations']"
1463588,"[Ask]prove that for all integers 'n', if n is bigger than 2. then there is a prime number 'p' between n and n!","I think using contradiction will be useful. Suppose $p$ exists which divide $n!-1$
and suppose that
 $p \leq n$ leads to a contradiction. But I have no idea how to show contradiction I believe someone can help me.(I'm not English-speaker also)","['prime-numbers', 'discrete-mathematics']"
1463631,"Cauchy sequence in $L^p$, existence of a set with finite measure, and integral is less than epsilon over the complement","The setting is as follows, for each $f\in L^p$, define a set function $\lambda_f$ on $\mathcal{A}$ by $$\lambda_f(E)=\left(\int_E |f|^p d\mu\right)^{1/p}=\|f\cdot I_E\|_p.$$ Let $(f_n)$ be a Cauchy sequence in $L^p$. Show that for all $\epsilon >0$, there exists a set $E\in\mathcal{A}$ (depending on $\epsilon$) with $\mu (E)<\infty$ such that for all $F\in\mathcal{A}$ with $F\subseteq E^c$, we have $\lambda_{f_n} (F)<\epsilon$ for all $n\in\mathbb{N}$. I tried proving by contradiction: Suppose to the contrary for all $E\in\mathcal{A}$ with $\mu(E)<\infty$, $\exists F\in\mathcal{A}$ with $F\subseteq E^c$ but $\lambda_{f_n}(F)\geq\epsilon$ for all $n\in\mathbb{N}$. Intuitively, I see that that may be a problem as $\mu(E)$ gets larger, $\lambda_{f_n}(F)$ should tend towards zero? However I don't know how to prove it rigorously. Thanks for any help. Note: I set a bounty to attract more answers, so that I can choose one that I can understand. Having some problems with understanding this one.","['analysis', 'real-analysis', 'measure-theory']"
1463652,The motivation of weak topology in the definition of CW complex,"Background A CW complex is a Hausdorff space and it is the union of its some of its subsets called cells, and cells are homeomorphic images in $X$ of some closed $k$ -balls. The weak topology of a CW complex X is defined as the topology having the property that a subset of $X$ is closed if and only if it is closed in each cell of $X$ . The question What is the motivation of requiring that the topology is weak? What is, if $X$ has more closed sets then in this definition, and what is if it has less. And why are closed sets are generally used in this definition, why not open sets? (I saw in some places this definition with open sets. Is it an error, or it is an equivalent definition?)","['algebraic-topology', 'general-topology', 'cw-complexes']"
1463660,Is it true that $\sum_{k=1}^n |a_{kk}| \le \sum_{k=1}^n |\lambda_k|$ for any complex square matrix $A$?,"(Note: this is not a duplicate as suggested. I am asking for an inequality.) We know that for any complex square matrix $A$, we have $$\sum_{k=1}^n a_{kk} = \sum_{k=1}^n \lambda_k.$$ I can see this relation in trace property that it is equal sum of diagonal elements. But how to show that the sum of absolute values of the diagonal elements is less than or equal to the sum of absolute values of the eigenvalues? That is, do we have $$\sum_{k=1}^n |a_{kk}| \le \sum_{k=1}^n |\lambda_k|\ ?$$",['matrices']
1463662,if $H$ is a unique subgroup of order $d$ then $H$ is a normal subgroup,"Let $H$ be a subgroup of a group, $G$ such that $H$ is the only subgroup in $G$ with order $d$. Prove that $H\vartriangleleft G$. I have to questions: 1) as you see it is not given that $G$ is finite. is it true that $H\vartriangleleft G$ even if $G$ is not finite? 2) suppose that $G$ is finite. then my try was to take $h\in H$, $g\in G$. now, $(ghg^{-1})^d=gh^dg^{-1}=gg^{-1}=e$ and I tried to show by contradiction that $d$ must be the order of $ghg^{-1}$: if $1\leq k<d$ and $(ghg^{-1})^k=e$ then $(ghg^{-1})^k=gh^kg^{-1}=e$ $\Longrightarrow h^k=e$ so the order of $h$ must divide $k$ which is smaller then $d$ so it seemed reasonable for me that the contradiction should arrise from the fact that the order of $h$ must be $d$ i.e. $H$ is cyclic. I looked up similar questions and found that if $G$ is finite and for every divisor of $|G|$ there is a unique subgroup of the order of that divisor then $G$ is cyclic and in my case it would mean that $H$ is also cyclic and hence the contradiction. but I'm not given that $G$ is finite and that for every divisor of $|G|$ there is a unique subgroup of that order. so I'm kind of stuck here","['abstract-algebra', 'group-theory']"
1463694,Closed Form for $~\lim\limits_{n\to\infty}~\sqrt n\cdot(-e)^{-n}\cdot\sum\limits_{k=0}^n\frac{(-n)^k}{k!}$,"$\qquad\qquad\qquad$ Does $~\displaystyle\lim_{n\to\infty}\frac{\sqrt n}{(-e)^n}\cdot\sum_{k=0}^n\frac{(-n)^k}{k!}~$ possess a closed form expression ? Inspired by this frequently asked question, I wondered what would happen if the sum were allowed to alternate. Numerically, it seems to converge to a value around $~\dfrac15$ . Unfortunately, I wasn't truly able to grasp any of the various approaches used to evaluate the other related limit $($yes, I actually read carefully through all of them$)$, so I haven't been successful in developing a viable method for expressing this one either. $($Perhaps a new, insightful answer will also help me cast some fresh light on older ones ?$)$","['power-series', 'calculus', 'limits', 'closed-form', 'sequences-and-series']"
1463725,Can you calculate confidence intervals for the population mean if the obtained sample is not normally distributed?,"From my knowledge, if the obtained sample is approximately normally distributed, we can use t-tables to calculate the population mean confidence interval without knowing the population standard deviation. However is there a way to calculate the population mean confidence interval if the obtained sample is not normally distributed??","['statistics', 'statistical-inference']"
1463752,definition of a sufficient statistic,"The ""normal"" definition of a sufficient statistics is via independence of the pdf (conditional on the statistic) of the parameter $\theta$. The Fisher-Neyman theorem gives a nice characterization: The statistic $T$ is sufficient iff $f(x;\theta) = h(x)g(T(x);\theta)$ for two nonnegative functions $h, g$. In the book All of statistics by Larry Wasserman the author defines (I quote): ""Write $\vec{x} \iff \vec{y}$ if $f(\vec{x};\theta) = cf(\vec{y};\theta)$ for some constant $c$ that might depend on $\vec{x}$ and $\vec{y}$ but not on $\theta$. A statistic $T(\vec{x})$ is sufficient if $T(\vec{x})\iff T(\vec{y})$ implies that $\vec{x}\iff \vec{y}$ where $\vec{x} = (x_1, \dots, x_n)$ a data sample. The $T(\vec{x})\iff T(\vec{y})$ seems to be like the Fisher-Neyman thoerem with different data samples. How can one show that Wassermans definition is the same as above (or equivalent to the Fisher-Neyman).","['statistics', 'definition']"
1463787,Probability of winning in a die rolling game with six players,"There are 6 players numbered 1 to 6, 1 Player, Player 2, ..., Player 6. Player 1 rolls a die , if he gets a 1 wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die and the player makes a second pitch, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the given passes to the player whose number matches the number rolled, the player rolls the die, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die in this third release, and so on. Calculate the probability that player 1 wins.",['probability']
1463792,"On proving $\{0,1\}^\mathbb{N}\sim\{0,1,2\}^\mathbb{N}$","I'm trying to prove $\{0,1\}^\mathbb{N}\sim\{0,1,2\}^\mathbb{N}$ (the sets are equinumerous). I have already proved that $\{0,1\}^\mathbb{N}\sim\mathbb{N}^\mathbb{N}$, with the following method: For every countable $X\subset\{0,1\}^\mathbb{N}$, $\{0,1\}^\mathbb{N}\sim\{0,1\}^\mathbb{N}\setminus X$. There exists an injective mapping $f:\mathbb{N}^\mathbb{N}\rightarrow \{0,1\}^\mathbb{N}$ for which $\{0,1\}^\mathbb{N}\setminus f\left(\mathbb{N}^\mathbb{N}\right)$ is countable From 1. and 2. it follows directly that $\{0,1\}^\mathbb{N}\sim\mathbb{N}^\mathbb{N}$ Points 1. and 3. should be clear, let me elaborate on 2. a little bit more by constructing this $f$. Let $(n_0,n_1,\ldots)\in\mathbb{N}^\mathbb{N}$. We construct $(a_0,a_1,\ldots)\in\{0,1\}^\mathbb{N}$ by: The sequence starts with $n_0$ zeroes, so $a_0 = \ldots = a_{n_0-1} = 0$ Then a one, so $a_{n_0}=1$ We continue with $n_1$ zeroes, so $a_{n_0+1}=\ldots=a_{n_0+n_1-1}=0$ $a_{n_0+n_1}=1$ $\vdots$ Now the only sequences not reached are the ones that will be zero from some point on. This would namely require an ''$a_n=\infty$'' for some $n$. Thereby we constructed the injective $f$. Now, what I want is a similar proof for $\{0,1,2\}^\mathbb{N}\sim\mathbb{N}^\mathbb{N}$, but I haven't been able to construct a function like in 2. Is this the way to go, or is there a direct way to prove equinumerosity?",['elementary-set-theory']
1463847,what is the difference between well ordered set and totally ordered set?,"I am unable to get the difference between a well ordered set and a totally ordered set ,I have gone through book , it says that if some non-empty subset of a poset has a least element then it is a well-ordered set but this least element can only be found in the relation less than equal to , we can't find it in a relation like ""x divides y "", so then what is the significance of the term least here ?",['discrete-mathematics']
1463856,Find the number of solutions to this equation using combinatorics,"How many solutions are there to the equation $$x_1 +x_2+x_3+x_4+x_5=21$$ where each $x$ is a non negative integer such that $$0\le x_1 \le3 , 1 \le x_2 \lt4\text{ and }x_3\ge15$$ My attempt: So I  first considered the conditions $x_1\ge0 , x_2\ge1$ and $x_3\ge15$ I found out that the total possible combinations with this restriction are $9\choose5$ .
But these include do not include the other restrictions on $x_1$ and $x_2$ . So I found out the combinations for the cases of $x_1\ge4$ and $x_2\ge4$ , with an intention of subtracting these from the total combinations of $9\choose 5$ . However I am not ending up with the right answer of $106$ .Could you please help me out? I used the formula of $n-r+1\choose r$","['combinations', 'combinatorics']"
1463870,Show that $\mathbb{A}^2 \cong \mathbb{A}^1 \times \mathbb{A}^1$ as varieties.,"Show that $\mathbb{A}^2 \cong \mathbb{A}^1 \times \mathbb{A}^1$ as varieties. I know how to do this in the case of affine varieties. Since $\mathbb{A}^1 \times \mathbb{A}^1$ is a product in the category of affine varieties, its coordinate ring $k[\mathbb{A}^1 \times \mathbb{A}^1]$ is isomorphic to $k[x]\otimes_k k[y]$, a co-product in the category of $k$-algebras. Since $k[\mathbb{A}^2]\cong k[x,y] \cong k[x]\otimes_k k[y]$ as $k$-algebras, we are done. How do I generalize this to varieties? Thanks.",['algebraic-geometry']
1463928,Uniqueness for Set in Family of sets,"This is an exercise in How to prove it by Velleman. Suppose $\mathcal{F}$ is a family of sets. Prove that there is a unique set $A$ that has the following two properties: (a) $\mathcal{F} \subseteq \mathcal{P}(A)$ (b) $\forall B(\mathcal{F} \subseteq \mathcal{P}(B) \rightarrow A \subseteq B)$ My approach so far: 
This set is obviously $A = \cup \mathcal{F}$. I have proven the existence part of the proof, but I am struggling with the uniqueness. My approach so far for proving uniqueness: Let $P(X)$ denote $\mathcal{F} \subseteq \mathcal{P}(X) \land \forall B(\mathcal{F} \subseteq \mathcal{P}(B) \rightarrow A \subseteq B)$ My first approach was: $\forall Y \forall Z( (P(Y) \land P(Z)) \rightarrow (Y=Z))$. I tried to somehow prove through $P(Y)$ that $Y = \cup \mathcal{F}$ and through $P(Z)$ that $Z = \cup \mathcal{F}$ and thus that $Y=Z$. My second approach was: Prove that $\forall X (P(X) \rightarrow X = A)$. This has also brought me nowhere so far. I tried proving the contra-positive, but got stuck in the case where I had to prove $\lnot P(X)$ when $X \nsubseteq A$. I would be really grateful for all hints!",['elementary-set-theory']
1463943,"Hamiltonian question, find optimal controller, simple question","An object is moving with accordance to Newton's laws: $\begin{pmatrix} \dot{y} \\ \dot {v} \end{pmatrix} = \begin{pmatrix} v \\ u \end{pmatrix}$ where $y$ is the objects location and $v$ is its speed. Let $x=\begin{pmatrix} y \\ v \end{pmatrix}$ be the state variable. Assume our input controller (the acceleration) $u$ is such that $|u| \leq 1$. Using Jacobi-Hamilton (Hamiltonian) method, find an optimal controller that shifts $y(0),v(0)$ to the origin $(0,0)$ in minimal time $T$. What I did: Our cost function is $J(0)=\int_{0}^{T}1d\tau$ and our state equation is $\dot{x} = \begin{pmatrix} \dot{y} \\ \dot {v} \end{pmatrix} = \begin{pmatrix} v \\ u \end{pmatrix}$ And so our Hamiltonian function is $H(x,u,\lambda) = 1+\lambda^ T\dot{x}$ and if $\lambda = \begin{pmatrix} \lambda _1 \\ \lambda _2 \end{pmatrix}$ then $H=1+\lambda _1 v+\lambda _2 u$ Please note - This is also the result the teacher reached. So I doubt this is incorrect. The method says that $\dot{x} = H_\lambda$, $\dot {\lambda} = -H_x$, and $H_u = 0$. From the first equation we get $\dot{x} =\begin{pmatrix} \dot{y} \\ \dot {v} \end{pmatrix}=\begin{pmatrix} v \\ u \end{pmatrix}$ which we already know and is trivial. From the second equation (I think) we get $\dot {\lambda}  = \begin{pmatrix} \dot{\lambda _1 } \\ \dot {\lambda _2} \end{pmatrix}=-\begin{pmatrix} 0 \\ \lambda _1 \end{pmatrix}$ which is also problematic by itself since this is not solvable, but this isn't my main problem. My main problem is with $H_u=0$. this means that $\lambda _2 =0$. So where does the $u$ part come in? I'm supposed to find an optimal controller $u$, but nothing is dependent on $u$. it does not appear anywhere. Would appreciate any help, I can't understand the teachers solution either.","['dynamical-systems', 'optimization', 'control-theory', 'linear-algebra', 'ordinary-differential-equations']"
1463944,Systematic solution to my soccer ball puzzle,"I once received a puzzle that can be described as follows:
There are $12$ black pentagonal and $20$ white hexagonal pieces. The goal is to form a soccer ball from these (aka. truncated icosahedron ). Similar to a (flat) jigsaw puzzle, each edge of each piece is equipped with either a ""tongue"" or a ""groove"" for interlocking (and there is only one type of these, that is, every tongue fits into every groove of every other piece). The assignment of tongues and grooves follows a highly symmetric pattern: Each piece has at least two tongues and at least two grooves; apart from that all possible shapes occur in equal number, that is: For each of the four ways (up to rotation!) to pick two or three tongue positions for a pentagon, there are three puzzle pieces with that pattern For each of the ten ways to pick two or three or four tongue positions for a hexagon, there are two puzzle pieces with that pattern. It seems highly incidental that the required number of pieces is a multiple of the possible configurations - then again this is just the law of small numbers at work. Anyway, I have spent hours on solving the puzzle manually, but never succeeded. The tricky thing is that it is very easy to just go ahead put together all but one or two pieces, but those last pieces just never fit.
On the other hand, once I sat down and wrote a program to solve the puzzle by backtracking it began spatting out gazillions of solutions faster than the screen could scroll ... which is of course embarrassing for me as a puzzler. My question is: Given the highly symmetric setup of the collection of  puzzle pieces, there should be some ""symmetric"" solution to the puzzle. Can anyone find such a symmetric solution? Of course, the term ""symmetric"" has to be taken a bit loosely here (and that makes this question somewhat opinion-based), after all the threefold repetition of pentagonal pieces and twofold repetition of hexagonal pieces excludes anything that is actually invariant under a symmetry movement of the soccer ball ($\gcd(2,3)=1$). So anything that can be found by contemplating instead of computer power and/or that can be described by a nice pattern instead of a piece-by-piece enumeration would be acceptable.","['geometry', 'puzzle', 'symmetry']"
1463954,"Confusion about Stieltjes integrals: Improper-Riemann, Lebesgue, and Generalized Riemann","I am confused about which, if any, of these integrals is the most general, assuming we allow ""improper"" versions of each (where applicable). The reason I am confused is by this passage in Wikipedia on Riemann-Stieltjes integrals: An important generalization is the Lebesgue–Stieltjes integral which
  generalizes the Riemann–Stieltjes integral in a way analogous to how
  the Lebesgue integral generalizes the Riemann integral. If improper
  Riemann–Stieltjes integrals are allowed, the Lebesgue integral is not
  strictly more general than the Riemann–Stieltjes integral. I am in no way well-versed in measure theory, but I was under the impression that the Lebesgue integral is considered the most general form of the above integrals. However, the above seems to call this into question. Also, I recently had the chance to peruse Abbott's ""Understanding Analysis"", where he introduces the ""Generalized Riemann Integral""...a version I have never heard of before. A really nice exposition of it is given by Bartle , where he argues that we should stop relying on the Lebesgue integral as the ""most general"" and instead switch to this new type of extended Riemann integral (the key element of which is the use of a non-constant gauge over the partitions in the Riemann sum). I was introduced to the Riemann-Stieltjes integral while studying from Ross' ""Elementary Analysis"", where he devotes a considerable amount of real-estate to the, quite useful, generalization of the Riemann integral. In fact, it seems that for the vast majority of probability and statistics applications, the Riemann-Stieltjes integral is sufficient for calculations, without the need for extensive measure-theoretic constructions. It turns out that someone has gone the extra step to generalize the Riemann-Stieltjes integral using a similar construction to the Generalized Riemann integral. Based on Bartle's discussion of the Genearlized Riemann integral, it would appear that this Generalized Riemann-Steiltjes integral can encompass more integrand and domains than any other. However, this is just my impression on reading this. I would appreciate if someone could explain which of the integrals I've discussed is, in fact, the most general in the following, hopefully precise, sense: Let $I_i(f,g)$ be an integral of type $i$, with integrand $f$ and integrator $g$ (e.g., a normal Riemann integral has integrator $g(x)=x$). Finally, let the notation $f \in I_i$ mean that there there exists an integrator such that $f$ is integrable under $I_i$. I will define $I_i$ as being more general than $I_j$ ($I_j \prec I_i$) iff: $$f \in I_i\;\forall f\in I_j\;\textrm{ and}\; \exists h \in I_i: h \notin I_j$$ I would consider $I_j$ equivalent to $I_i$ iff: $$ I_j \nprec I_i \;\textrm{ and } I_i \nprec I_j$$ Question: So, given the above definition for ordering by generality, what is the relationship between the improper Riemann-Stieltjes, Generalized Riemann-Stieltjes, and the most general form of the Lebesgue-Stieltjes integral?","['improper-integrals', 'real-analysis', 'measure-theory', 'integration']"
1463958,"Embedding nowhere dense subsets of $[0,1]$ in the Cantor set","Suppose $A$ is a closed, nowhere dense subset of the unit inteveral $[0,1]$ such that $\{0,1\}\subseteq A$. Let $C\subseteq [0,1]$ be the usual middle third Cantor set. Is there an order-preserving homeomorphism $f:[0,1]\to[0,1]$ such that $f(A)\subseteq C$? Can we also choose $f$ so that it takes each component of $[0,1]\backslash A$ to some component of $[0,1]\backslash C$?",['general-topology']
1463959,Sturm-Liouville Problem for Bessel Functions,"I have been given this recently in PDE class involving the solutions to the Bessel fucntion in Sturm-Liouville form, asking for Eigenvalues and Eigenfunctions: $ (xy')'+\lambda x y = 0 \space \space \space \space 0<a<x<b $ $ y(a)=y(b)=0 $ Here is where my problems start: If I expand the equation I get: $ xy''+y'+\lambda x y = 0 \to x^2y''+xy'+\lambda x^2 y = 0 $ now depending on whether or not the eigenvalues are positive or negative (checking zero is not one is fairly simple) we obtain the general solution to the Bessel equation or modified Bessel equation of order zero: $ y(x) = AJ_0(\sqrt{\lambda}x) + BY_0(\sqrt{\lambda}x) $ or $  y(x) = AI_0(\sqrt{\lambda}x) + BK_0(\sqrt{\lambda}x) $ So there is not the matter of boundedness at zero resulting in eliminating the singular solution from the linear combination so my problem here is basically applying the boundary conditions like this: $ AJ_0(\sqrt{\lambda}a) + BY_0(\sqrt{\lambda}a) = AJ_0(\sqrt{\lambda}b) + BY_0(\sqrt{\lambda}b) = 0 $ so this equation and deriving $ \lambda $ and the actual eigenfunctions from this is beyond my ability, and that's where I am stuck and need the help. Thanks all.","['bessel-functions', 'eigenfunctions', 'ordinary-differential-equations']"
1463978,Find the probability of $P_1$ winning the championship,"Two players $P_1$ and $P_2$ are playing the final of a chess championship,which consists of a series of matches.Probability of $P_1$ winning a match is $\frac{2}{3}$ and that of $P_2$ is $\frac{1}{3}$.The winner will be the one who is ahead by two games as compared to the other player and wins atleast $6$ games.Now if the player $P_2$ wins first 4 matches,prove that the probability of $P_1$ winning the championship is $\frac{1088}{3645}$ I dont have thoughts as to how to tackle this problem.Because a player has to just ahead of 2 games as compared to another player,neither more than 2 nor less than 2.Please help me.",['probability']
1464066,Topologizing the $I$ in $\prod_{i\in I} X_i$,"I know two constructions for producing topologies on a function space: $I$ is a set, $(X_i)_{i\in I}$ is a collection of topological spaces; in this case the initial topology w.r.t the projections $\pi_i:\prod_{k\in I} X_k\to X_i$ is called the (indexed) product topology. $I,X$ are topological spaces; then we can form the set $C(I,X)$ of continuous functions $I\to X$ and topologize it with the compact-open topology. The two definitions agree when $I$ is a set (treated as discrete for the purposes of (2)) and $X_i=X$ is constant, so that $C(I,X)=\prod_{i\in I}X$. Thus we can in some sense understand the index set $I$ as always being discrete in the product topology. Is there a way for us to generalize these two constructions into one where the index set is topologized, but the fibers are not all the same? Fiber bundles seem to be similar, but seem to be more like the binary topological product $X\times Y$. Finally, I have also seen some claims to the effect that HoTT has formalized a topological space with these properties (since all their types act like topological spaces, and they happen to have a dependent type constructor), but I don't know what it would look like in elementary terms.","['homotopy-theory', 'infinite-product', 'general-topology']"
1464107,"Let $f : \mathbb{R} → \mathbb{R}$ be continuous, with $f(x)f(f(x)) = 1$ for all $x ∈ \mathbb{R}$. If $f(1000) = 999$, find $f(500)$.","Let $f : \mathbb{R} → \mathbb{R}$ be continuous, with $f(x)f(f(x)) =
1$ for all $x ∈ \mathbb{R}$. If $f(1000) = 999$, find $f(500)$. I try to solve this problem, but I don't know how to use de continuity on $f$. Is anyone could give me a little hint on the continuity? And please, don't give me the answer to the question.",['real-analysis']
