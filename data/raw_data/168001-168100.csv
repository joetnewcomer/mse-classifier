question_id,title,body,tags
2938622,Does the Shannon Entropy always exist (even for infinite distributions)?,"Let $p : \mathbb{N} \to [0, 1]$ be a probability distribution over the naturals. The Shannon Entropy is: $$H = -\sum_{n=0}^\infty p(n)\log_2 p(n)$$ Does this series always converge? I tried a little to attack this problem but it's been some time since I evaluate series. My attempt: We known that $\sum_{n=0}^\infty p(n) = 1$ , therefore it must be the case that $\lim\limits_{n\to\infty} p(n) = 0$ , and since $\lim\limits_{x\to 0} x\log_2 x = 0$ , for any $\varepsilon > 0$ there exists only a finite amount of terms greater than $\varepsilon$ . The problem is that I can't conclude anything from this, because there are several series in which the terms go to zero but it still diverges.","['divergent-series', 'probability-distributions', 'entropy', 'sequences-and-series']"
2938660,Prove Summation $k=1$ to $n$ $k^3$ with telescoping rule,I know how to do this problem when trying to get sum of squares $$\Sigma k^2  =  n(n+1)(2n+1)/ 6 $$ But I’m having trouble proving for cubes: $$\sum_{k=1}^n k^3 = \frac{n^2(n+1)^2}4$$ I have to prove this by the method of telescopy. Edit $ $ Below is my attempt based on discussion on an answer below I started by  writing $\ \displaystyle \sum_{k=1}^n (k^4-(k-1)^4) = n^4.$ but I don't know where to go once I get here $\ \displaystyle \sum_{k=1}^n  (4k^3-6k^2+4k-1) = n^4 $ I used a table in a book for the others but I don't know how to convert the first  summand $\ 4 \sum_{k=1}^n k^3$ to complete the proof. Update $\ $ If anyone is interested in the exact solution I posted an answer showing what I did.,"['summation', 'telescopic-series', 'discrete-mathematics']"
2938869,Roots of $2x^3-4x+1$,"I'm having difficulty getting the solution to the cubic equation $2x^3-4x+1=0$ and from http://www2.trinity.unimelb.edu.au/~rbroekst/MathX/Cubic%20Formula.pdf it claims that the general solution to $Ax^3+Bx^2+Cx+D=0$ is $$p+q+r=-B/A$$ $$pq+qr+rp=C/A$$ $$pqr=-D/A$$ where $p,q,r$ are the roots. I also tried http://www2.trinity.unimelb.edu.au/~rbroekst/MathX/Cubic%20Formula.pdf and very carefully followed their technique (which looks at first glance different but must obviously be equivalent) however it didn't line up with what I got from Wolframalpha.  So I'm just looking to see where I messed up or how others would solve this. Here's my attempt: $$p+q+r=0$$ $$pq+qr+rp=-2$$ $$pqr=-1/2$$ From the first we get that $$p=-q-r$$ then from the second $$p(q+r) = -2-qr$$ then from the two of these we get $$-p^2 = -2-qr$$ equivalently $$0=p^3 -2p+1/2$$ Wait!  What?!  A cubic to solve a cubic..... cubics all the way down!?  Obviously not.... so if it's possible to solve this apart from numerical techniques, I would be really interested in such an answer.  Thank you","['cubics', 'inverse-function', 'roots', 'multivariable-calculus', 'substitution']"
2938947,"Example to disprove the statement: for all real numbers $x$ and $y$, if $x + \lfloor x \rfloor = y + \lfloor y \rfloor$ then $x = y$","I am supposed to disprove this statement but I can't find an example.
Could anybody give me a hint/guide? For all real numbers $x$ and $y$ , if $x + \lfloor x \rfloor = y + \lfloor y \rfloor$ then $x = y$ . I can't find any example that disproves this yet so I am becoming to believe this is true.. Any insight would be appreciated.. :)","['real-numbers', 'algebra-precalculus']"
2938953,Finite Taylor series of Lagrange Basis functions,"Lagrange basis functions are defined as follows $$L_{j}(x) = \prod_{i\neq j} \frac{x-x_{i}}{x_{j}-x_{i}} $$ then $$\ln\Big(L_{j}(x)\Big) = \ln\Big(\prod_{i\neq j} \frac{x-x_{i}}{x_{j}-x_{i}}  \Big) = \sum_{i \neq j } \ln\Big( \frac{x-x_{i}}{x_{j}-x_{i}} \Big) $$ if we derivate we have: $$ \frac{L'_{j}(x)}{L_{j}(x)} =\sum_{i \neq j} \frac{\frac{1}{x_{j}-x_{i}}}{\frac{x-x_{i}}{x_{j}-x_{i}}} = \sum_{i \neq j} \frac{1}{x-x_{i}}  $$ then $$ L_{j}^{(1)}(x) = L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)  $$ if we use the product rule for  derivatives we have that: $$ L''_{j}(x) = L'_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)+L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)' \\ = 
 L'_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)+L_{j}(x) \Big( \sum_{i \neq j} \frac{-1}{(x-x_{i})^2}  \Big) $$ we know $ L'_{j}(x)  $ so $$ \\ = 
 L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)\Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)-L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{(x-x_{i})^2}  \Big)\\ = 
L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)^2 -L_{j}(x) \Big( \sum_{i \neq j} \frac{1}{(x-x_{i})^2}  \Big) $$ finally $$  L_{j}^{(2)}(x) = 
L_{j}(x) \Big\{\Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)^2 -  \sum_{i \neq j} \frac{1}{(x-x_{i})^2}     \Big\} $$ if we continue this way we get: $$ L_{j}^{(3)}(x) =  L_{j}(x)\Big\{ \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big)^3 -3 \Big( \sum_{i \neq j} \frac{1}{x-x_{i}}  \Big) \Big( \sum_{i \neq j} \frac{1}{(x-x_{i})^2}  \Big) +2\Big( \sum_{i \neq j} \frac{1}{(x-x_{i})^3}  \Big)  \Big\} $$ I want to compute the Taylor Series of $ L_{j}(x) $ and I need to find $ L_{j}^{(n)}(x) $ .  Do you know an expression for $ L_{j}^{(n)}(x) $ or something that could help ? Thank you.","['lagrange-interpolation', 'derivatives', 'taylor-expansion']"
2939000,Sine/Cosine Subtraction Formulas,"The differential equation $\frac{d^2 y}{dt^2}+ \omega^2 y=0$ has the general solution $y = A\cos (\omega t)+ B\sin (\omega t)$ . Also given are the initial values: $y(a) = A, y'(a) = B$ . I tried: $$y(a) = A\cos(\omega a) + B\sin(\omega a )= A$$ $$y'(a) = −\omega A\sin(\omega a) + \omega B\cos(\omega a)= B$$ And then substituted $A$ and $B$ into the general solution: $$y = (A\cos(\omega a) + B\sin(\omega a))\cosωt + \omega (−A\sin(\omega a) + B\cos(\omega a))\sin(\omega t)$$ From here I can't get it to work. I want to simplify and express y with the subtraction formulas. 
The answer is $y = A\cos(\omega (t−a)) + \frac{B}{\omega}\sin(\omega (t−a))$ I know how the formulas work, But I can't figure out how $\frac{B}{\omega}$ got there.
Please help, I'm stuck.","['trigonometry', 'ordinary-differential-equations']"
2939070,Horizontal Subbundles and Connection Maps,"I'm trying to see the equivalence between the Ehresmann connection and the connection map, and having trouble getting the setup to be correct. Suppose $M$ is a smooth manifold.  Let $\pi:TM\to M$ denote tangent bundle, with differential $d\pi:TTM\to TM$ .  Then one has the canonical vertical subbundle $V=\ker{d\pi}$ . A horizontal subbundle $H$ is any subbundle which is complementary to $V$ , that is, $TTM=H\oplus V$ .  Such an $H$ is equivalent to the existence of some $(0,2)$ -tensor $\sigma$ on $TM$ ( $\sigma:TTM\to TTM$ ) such that $\sigma^2=\sigma$ and $\sigma(TTM)=V$ , and then letting $H=\ker{\sigma}$ . However, if $(M,g)$ is Riemannian with Levi-Civita connection $\nabla$ , from what I've found in the literature, one typically defines a connection map $K:TTM\to TM$ by taking some $(\theta,\xi)\in TTM$ , letting $\gamma(t)=(\alpha(t),\beta(t))\in TM$ with $\gamma(0)=\theta$ , $\gamma'(0)=\xi$ and giving $$(\theta,\xi)\mapsto K_\theta(\xi)=\left(\nabla_{\alpha'(t)}\beta(t)\right)_{t=0}.$$ Then you define $H=\ker{K}$ . What's the correlation between $\sigma$ and $K$ ? Also, if anyone has any references on the above that would be helpful.  I seem to have only found a small section Sakai's Riemannian Geometry text, and a bit more in-depth section in Paternain's Geodesic Flows text.  My interest in the topic is geared towards understanding the Sasakian metric on $TM$ better.","['riemannian-geometry', 'connections', 'vector-bundles', 'differential-topology', 'differential-geometry']"
2939080,Sufficient condition for continuity of function of two variables,"For a function of two variables to be continous, a sufficient condition is said to be that one of the partial derivatives exists and is bounded near the required point and the other partial derivative just exists at that point I cant understand how the bounded partial derivative helps in the proof.Please explain this to me
Thanks in advance","['continuity', 'multivariable-calculus']"
2939133,How to solve $ \frac{d^2y}{dx^2} - \left(1/x\frac{dy}{dx}\right) = 0$,I'm trying to solve: $ \frac{d^2y}{dx^2} - \left(1/x\frac{dy}{dx}\right) = 0$ I've been following a tutorial and they say the answer is: $y = \frac{1}{2}Cx^2 + D$ They've used: $\frac{dy}{dx} = Cx$ How did they get that result??,"['integration', 'calculus', 'ordinary-differential-equations']"
2939149,Find smallest possible degree of $f(x)$ from given conditions,"Let $p(x)$ be a polynomial of degree strictly less than 100 and such that it does not have $x^3-x$ as a factor. If $$\frac{d^{100}}  {dx^{100}}  \left(\frac{p(x)}{x^3-x}\right)=\frac{f(x)} {g(x)}$$ for some polynomials $f(x)$ and $g(x)$ . Then, find the smallest possible degree of $f(x)$ . Here $$\frac{d^{100}}{dx^{100}}$$ means taking $100$ th* derivative. My attempt $$\frac{p(x)}{x^3-x}=q(x) +\frac{r(x)} {x^3-x}$$ Then, if $p(x)$ has degree strictly less than 100 then it may be of 99 or 98 or something like that. But if it is like that then its 100th derivative will be zero. As in case of $x^2$ its first derivative is $2x$ , then its second derivative is 2 and then the third derivative is 0. So, if f(x) is nth degree polynomial its n+1 derivative is 0. But then it does not satisfies the given conditions. Edit: The test solution gives another answer of 200 with another solution giving 0 as answer. Now how can two least possible degrees can be the solution","['functional-equations', 'real-analysis', 'calculus', 'algebra-precalculus', 'derivatives']"
2939165,Column space and null space,"Let $A\in M_{5,7}(\mathbb{R})$ be a matrix such that $Ax=b$ has solution for every $b$ . I have to say what this information tells me about column- and null-space and rows of a matrix. The only thing I can think of is that column-space can have dimension $1$ to $5$ and null-space dimension can be deduced using rank-nullity theorem. Is there something more to see here?","['matrices', 'systems-of-equations', 'linear-algebra']"
2939195,Why are integer GCDs positive? [unit normalization of GCDs],"The definition in my text reads, An integer $d$ is said to be the greatest common divisor of two non-zero integers $a$ and $b$ iff, $d|a$ and $d|b$ and if $k$ is any other common divisor of $a$ and $b$ then $k|d$ Now here's the thing, if $d|a$ and $d|b$ then surely $-d|a$ and $-d|b$ as well, also $k|-d$ What I take from this? GCD is not unique! That is if $\mathrm{gcd}(12,8)= 4$ then by the definition, $\mathrm{gcd}(12,8) = -4$ as well. Yet I never ever seen a negative gcd. Someone please explain. Maybe, $4>-4$ , and we want the ""greatest common factor"" so...? But that still doesn't justify the definition.","['elementary-number-theory', 'gcd-and-lcm', 'abstract-algebra']"
2939244,"Prob. 2 (d), Sec. 27, in Munkres' TOPOLOGY, 2nd ed: If $A$ is compact and $U$ is an open set containing $A$, then . . .","Here is Prob. 2, Sec. 27, in the book Topology by James R. Munkres, 2nd edition: Let $X$ be a metric space with metric $d$ ; let $A \subset X$ be nonempty. (a) Show that $d(x, A) = 0$ if and only if $x \in \overline{A}$ . (b) Show that if $A$ is compact, $d(x, A) = d(x, a)$ for some $a \in A$ . (c) Define the $\epsilon$ -neighborhood of $A$ in $X$ to be the set $$ U(A, \epsilon) = \{ \ x \in X \ \vert \ d(x, A) < \epsilon \ \}. $$ Show that $U(A, \epsilon)$ equals the union of the open balls $B_d(a, \epsilon)$ for $a \in A$ . (d) Assume that $A$ is compact; let $U$ be an open set containing $A$ . Show that some $\epsilon$ -neighborhood of $A$ is contained in $U$ . (e) Show the result in (d) need not hold if $A$ is closed but not compact. This and this are two Math SE posts on this problem. And, here is also a solution to this problem. I think I'm clear on parts (a) through (c) of this problem. So here I'll give my attempt at part (d). My Attempt: First, some notation: For any point $x \in X$ , we define $$ d(x, A)  \colon= \inf \{ \ d(x, a) \ \vert \ a \in A \ \}. \tag{Definition A} $$ And, for any point $p \in X$ and for any real number $\delta > 0$ , we define $$ B_d (p, \delta) \colon= \{ \ x \in X \ \vert \ d(x, p) < \delta \ \}. \tag{Definition B} $$ As $U$ is an open set in $X$ with the metric topology determined by the metric $d$ , so, for every element $u \in U$ , there exists a real number $\epsilon_u > 0$ such that $$ B_d \left( u, \epsilon_u \right) \subset U. $$ [Refer to Sec. 20 in Munkres, especially the portion of the section preceding Example 1.] In particular, as $A \subset U$ , so, for every element $a \in A$ , we can find a real number $\epsilon_a > 0$ such that $$ B_d \left( a, \epsilon_a \right) \subset U. \tag{1} $$ For each such $\epsilon_a > 0$ , let us choose a real number $\delta_a$ such that $$ 0 < \delta_a \leq \frac{\epsilon_a}{2}. \tag{2} $$ Now let us consider the collection $$ \left\{ \ B_d \left( a, \delta_a \right) \ \vert \ a \in A \ \right\}. $$ This is a collection of open sets of $X$ whose union contains the set $A$ ; that is, this collection is a covering of $A$ by sets open in $X$ . So, by Lemma 26.1 in Munkres, there is some finite sub-collection of this collection that also covers $A$ . That is, there exist points $a_1, \ldots, a_n \in A$ such that $$ A \subset \bigcup_{j=1}^n B_d \left( a_j, \delta_{a_j} \right). \tag{3} $$ Let us now put $$ \epsilon \colon= \frac{1}{2} \min \left\{ \ \delta_{a_1}, \ldots, \delta_{a_n} \ \right\}. \tag{4} $$ This $\epsilon > 0$ of course, by virtue of (2) above. Now from Part(c)  we have $$ U (A, \epsilon) = \bigcup_{a \in A} B_d(a, \epsilon). $$ Let us pick an arbitrary point $x$ in $U(A, \epsilon)$ . Then as $$ x \in \bigcup_{a \in A} B_d(a, \epsilon), $$ so by the definition of the union of sets there exists a point $a_* \in A$ such that $$ x \in B_d \left( a_*, \epsilon \right), $$ that is such that $$ d \left( x, a_* \right) < \epsilon, \tag{5} $$ by virtue of (Definition B) above. Now as $a_* \in A$ , so by virtue of (3) above, we can conclude that $$ a_* \in B_d \left( a_k, \delta_{a_k} \right) $$ and so $$ d \left( a_*, a_k \right) < \delta_{a_k}, \tag{6} $$ for at least one $k = 1, \ldots, n$ . 
  And for this same $k$ , using (2), (4), (5), and (6) above, we obtain $$ 
d \left( x, a_k \right) \leq d \left(x, a_* \right) + d \left( a_*, a_k \right) < \epsilon + \delta_{a_k} < \delta_{a_k} + \delta_{a_k} = 2 \delta_{a_k} \leq \epsilon_{a_k}.  $$ Thus $$ x \in B_d \left( a_k, \epsilon_{a_k} \right). $$ So from (1) we conclude that $x \in U$ . But by our choice $x$ was an arbitrary element of $U(A, \epsilon)$ . Therefore we have $$ U(A, \epsilon ) \subset U. $$ Is this proof correct? If so, then is each and every step of this proof clear enough too? If not, then where is it lacking?","['proof-verification', 'metric-spaces', 'analysis', 'general-topology', 'compactness']"
2939250,Dungeons and Dragons: Ability Score combinations,"I am trying to figure out how likely it is to roll a certain combination of 6 ability scores in Dungeons and Dragons. edit: Dungeons and Dragons is a tabletop role-playing game. You create a character in a fantasy world which has 6 main statistics, Strength, Dexterity, Constitution, Intelligence, Wisdom, and Charisma. Those ability scores determine the powers that a certain character can use and how strong they are.
The ability scores are rolled using 4 6-sided dice (4d6) and then using the 3 highest scores, giving you values $\in [3, 18]$ for the possible values.
My goal is to compute the likelihood of getting a combination like (8, 8, 8, 8, 8, 8) or (15, 14, 13, 12, 10, 8). /edit I already worked out the probabilities for rolling a single stat and a question on here confirmed that I did the math right: 3: $\frac{1}{1296}$ , 4: $\frac{4}{1296}$ , 5: $\frac{10}{1296}$ , 6: $\frac{21}{1296}$ , 7: $\frac{38}{1296}$ , 8: $\frac{62}{1296}$ , 9: $\frac{91}{1296}$ , 10: $\frac{122}{1296}$ , 11: $\frac{148}{1296}$ , 12: $\frac{167}{1296}$ , 13: $\frac{172}{1296}$ , 14: $\frac{160}{1296}$ , 15: $\frac{131}{1296}$ , 16: $\frac{94}{1296}$ , 17: $\frac{54}{1296}$ , 18: $\frac{21}{1296}$ Now using the same reasoning I managed to work out the probabilities of combinations based on the sum of ability scores, but only if the outcomes are equally likely. I used Python to compute the probabilities like this: def probability_of_outcomes(outcomes, repetitions, subsum=slice(None, None, None)):
    probability_dict = {}
    sum_combinations = 0
    for c in combinations_with_replacement(outcomes, repetitions):
        for p in set(permutations(c, repetitions)):
            s = sum(sorted(p)[subsum])
            if s in probability_dict:
                probability_dict[s] += 1
            else:
                probability_dict[s] = 1
            sum_combinations += 1

return probability_dict, sum_combinations


if __name__ == ""__main__"":
    all_comb, num_combinations_stats = probability_of_outcomes(range(1, 7) 4, subsum=slice(1, None, None)) in the same way I can compute: abilities_comb, num_combinations_ability = probability_of_outcomes(range(3, 19) 6) Now with the first computation I can already see that not every number is equally likely, but I am unsure where to add that probability in. Also the approach is not very elegant, as I simply try out every possible combination. Any ideas?","['dice', 'combinatorics', 'probability']"
2939373,Evaluating $\lim_{n \to \infty}\left(\sqrt{n^2 - n+1}-\left\lfloor\sqrt {n^2 - n+1}\right\rfloor\right)$,"How do I evaluate $$\lim_{n\to\infty}\left(\sqrt{n^2-n+1}-\left\lfloor\sqrt{n^2 - n+1}\right\rfloor\right),n\in\Bbb N$$ Attempt: I thought of using Squeeze theorem but that could not help. Secondly, we know that $x- \lfloor x\rfloor=\{x\}$ where $\{\}$ denotes the fractional part function. But I am not sure how to actually evaluate limits involving the fractional part function.","['limits', 'calculus', 'ceiling-and-floor-functions', 'sequences-and-series']"
2939386,"how to get the equation of a surface equation like $F(x,y,z)=0$ by parallel projecting onto a plane?","taking example 1: we want to project the  standard  ellipsoid  equation: $$
\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1
$$ onto the plane equation $$z=0$$ here we can just substitute $z$ with $0$ and get the projected equations: $$
\begin{cases}
\frac{x^2}{a^2}+\frac{y^2}{b^2}=1 \\
z=0
\end{cases}
$$ taking example 2: there is a non-standard  ellipsoid equation with center shifted: $$
\frac{(x-u)^2}{a^2}+\frac{(y-v)^2}{b^2}+\frac{(z-w)^2}{c^2}=1
$$ too, project it onto  the plane equation $$z=0$$ if we just substitute $z$ with $0$ again. we get the equation 1 : $$
\begin{cases}
\frac{(x-u)^2}{a^2}+\frac{(y-v)^2}{b^2}=1-\frac{(w)^2}{c^2} \\
z=0
\end{cases}
$$ but by geometrical intuition , the equation 1 is not the corrected solution. it is just a slice of the ellisoid cut by $z=0$ instead, by intuition, the projected equation should be the equation 2: $$
\begin{cases}
\frac{(x-u)^2}{a^2}+\frac{(y-v)^2}{b^2}=1 \\
z=0
\end{cases}
$$ equation2 means that we can substitute $\frac{(z-w)^2}{c^2}$ with $0$ and get the projected equation. but why this operating works? I don't know. if we get a non-standard ellipsoid equation that not only center shifted but also center rotated. how to get the corrected projected equation onto $z=0$ ? like example3: $$
2x^2+2y^2+2z^2-2(x+y+z)+2xy+2zy+2zx=0
$$ I don't know. further more, a general surface or plane equation like $F(x,y,z)=0$ , projecting it onto a general plane like $Ax+By+Cz+D=0$ , how to get the corresponding projected equation? do we have the general method to get it?","['euclidean-geometry', 'analytic-geometry', 'coordinate-systems', 'geometry', 'differential-geometry']"
2939445,'flimsy' spaces: removing any $n$ points results in disconnectedness,"Consider the following property: $\mathbb R$ is a connected space, but $\mathbb R\setminus \{p\}$ is disconnected for every $p\in \mathbb R$ . $S^1$ is a connected space and if we remove any point, it is still connected. But if we remove two arbitrary points $p$ and $q$ , the resulting $S^1 \setminus \{p,q\}$ is disconnected. Let $X$ be a topological space. Let's call $X$ to be $n$ -flimsy if removing fewer then $n$ arbitrary points leaves the space connected and removing any $n$ arbitrary (distinct) points disconnects the space. We saw that $\mathbb R$ is $1$ -flimsy and $S^1$ is $2$ -flimsy (as $S^1 \setminus \{*\} \cong \mathbb R$ ). Question: Is there a $3$ -flimsy space? So I'm searching for a space $X$ such that the removal of any $3$ points disconnects the space, but fewer don't. I suspect that there is no such space. I thought  I could show it by showing first, that $1$ - or $2$ -flimsy spaces are in some way unique, but I found many examples of $1$ -flimsy spaces which are significantly different (the long line, a variant of the topological sinus, trees). Alternatively: Is there a standard terminology for this property? (it definitely 'feels' like $n$ -connectivity in graph theory) Addendum 1: A space $X=\{x,y\}$ with two points is a trivial $3$ -flimsy example, since we cannot remove three distinct points. Of course, I'm interested in real examples. Addendum 2: Since Qiaochu Yuan and Paul Frost argued that CW-complexes won't work, here are some thoughts concerning the finite case: Let $(X,T)$ be a topological space with finite $X$ . Then $T$ is automatically an Alexandrov topology and therefore has the Specialization preorder $\prec$ . 
If we have a connected component $Z(x)$ of a point $x$ in a finite space with Alexandrov topology, then $Z(x)$ and its complement are closed and open, so they are downwardly closed. If we visualize $(X,T)$ by the graph $G$ which has $X$ as vertices and two vertices $v,w$ are connected if $v\prec w$ or $w \prec v$ , then connected components in $T$ refer to connected components of the graph.  Deleting a point in $X$ corresponds to deleting the respective vertex. Claim : There is no finite $1$ -flimsy space (disregarding the trivial examples above). Otherwise we have a graph where the removal of any vertex results in a disconnected graph. This graph can't be finite. Corollary : There are no finite $n$ -flimy spaces for $n\in \mathbb N$ (disregarding the trivial examples above). The removal of one point results in a finite $n-1$ -flimsy space, which can't exist (induction). Still open : Are there nontrivial $3$ -flimsy spaces? Those should be infinite and shouldn't be homeomorphic to CW-complexes. Addendum 3: Funfact : Every topological space can be embedded into a $1$ -flimsy space. Just add a real line to each point (as a one-point union). Alternatively, add $1$ -spheres to every point. Then add $1$ -spheres to each new point. Continue like this for eternity. Addendum 4: In the setting of Whyburn's book Analytic topology it is shown, that a compact set cannot be $1$ -flimsy (Chapter 3, Theorem 6.1). Since all my examples for $1$ -flimsy spaces are non-compact: Is there an example of a compact $1$ -flimsy space? Are all $n$ -flimsy spaces non-compact (at least they are infinite)?","['general-topology', 'connectedness']"
2939475,Should one study algebraic geometry if not interested in algebraic curves?,"I'm currently enrolled in a fundamental mathematics program, where a lot of math is covered. In particular, many of the students follow the Algebraic Geometry program, which is almost the core of the masters. While I do enjoy category theory, homological algebra and algebraic topology I can't really understand the thrive for AG, as I'm not curious about algebraic curves (i.e the zeros of a polynomia of several variables on a given field), which is the fundamental object in AG. And I'm not that much filled with enthusiast with say Bezout's theorem. I'm also not much interested in Number Theory However, I'm afraid of missing what is considered probably the most beautiful maths and its connections to fundamental physics, which look very appealing to me. So if I'm not interested in the roots of AG, will I be interested in its further developments (presheaves, sheaves, schemes, topos ...) ? Can I follow courses like ""Introduction to schemes"" without knowing anything in AG ?","['motivation', 'algebraic-geometry', 'soft-question']"
2939481,Conditional Probabilities for a Race? - Sequence of Dependent Events?,"I've been getting stumped by what seems to be a super simple conditional probability question... 3 people run a race: A, B, and C. Based on what we know about about their past races, we estimate the probability of each person coming in $1^{st}$ , $2^{nd}$ , and $3^{rd}$ are... |   |  1st  |  2nd  |  3rd  |
|---|-------|-------|-------|
| A |  0.5  |  0.3  |  0.2  |
| B |  0.3  |  0.2  |  0.5  |
| C |  0.2  |  0.5  |  0.3  | How likely is it that A runs $1^{st}$ and B runs $2^{nd}$ Given that Person A wins the race, what is the probability that person B comes in second? Here's the main part that's confusing me... Shouldn't $P(B=2|A=1) = P(C=3|A=1)$ since the race will be deterministic as soon as we know 2 of the 3 finishers? I just can't seem to find a way to calculate these probabilities that satisfies that criterium. (Note: It's also possible that this is a trick question with impossible probabilities, in which case I'd really appreciate a derivation that can support this.)","['conditional-probability', 'statistics', 'bayesian', 'probability']"
2939517,Pointwise limit of continuous functions is continuous on a dense set,"I'm stuck in understanding the proof of the following theorem given during a course: Let $X$ be a Baire space, and $(Y,d)$ a metric space. Let $f_n:X\to Y$ be a sequence of continuous function, pointwise converging to $f:X\to Y.$ Then $f$ is continuous on a dense set. Proof: Let $N,k\in \mathbb{N}^*.$ Let $A_{N,k}:=\bigcap_{n,m\ge N}\{x\in X\ |\ d(f_n(x),f_m(x))\leq \frac1k\}.$ Then by continuity every $A_{N,k}$ is a closed set and by pointwise convergence $X=\bigcup_{N\in\mathbb{N}^*} A_{N,k}.$ So for every $k\geq 1$ we have that $\Omega_k=\bigcup_{N\in\mathbb{N}^*} A_{N,k}^\mathrm{o}$ is an open dense subset of $X.$ By the Baire property then, we have that $\bigcap_{k\ge 1}\Omega_k$ is a dense set, and that $f$ is continuous right on that set. QED. What I really don't understand is the reason why the set $\Omega_k$ should be dense in the space $X:$ the fact that $X$ is the union of $A_{N,k}$ just implies that one of these sets has non-empty interior (by the Baire property), which is totally different from what I want.","['continuity', 'general-topology', 'proof-explanation', 'pointwise-convergence']"
2939531,Formal completion of modular curves,"Let $N\geq 4$ be an integer coprime with $p$ , where $p$ is a fixed prime number. Then we know that there exists a scheme $Y_N$ over $\text{Spec}(\mathbb{Z}_p)$ whose $\text{Spec}(R)$ -points are elliptic curves over $R$ with a level $N$ -structure, where $R$ is a $\mathbb{Z}_p$ -algebra. $Y_N$ is the non-compactified modular curve of level $\Gamma_1(N)$ . We also know, by representability, that there exists a universal elliptic curve $\mathcal{E}$ over $Y_N$ . My question is the following. What does it happen if we now $p$ -adically complete the picture, i.e. if we consider the formal scheme $\mathcal{Y}_N$ over $\text{Spf}(\mathbb{Z}_p)$ given by completion, does it still have a moduli interpretation? Of course we can complete also $\mathcal{E}$ , but now it's no more an elliptic curve, it's a kind of formal elliptic curve. Is it still true that a morphism $\text{Spf}(R)\rightarrow\mathcal{Y}_N$ gives an elliptic curve (formal or real?) over $R$ with a $N$ -level structure?","['elliptic-curves', 'algebraic-geometry', 'arithmetic-geometry', 'modular-forms', 'schemes']"
2939541,Mandelbrot set reference to get started,"I would like to learn seriously the mandelbrot set.
The idea is to handle it well enough to see why proving its locally connectedness is so difficult.
Can you suggest me some books/PDF online?
I know complex analysis but almost nothing about complex dynamics and fractals. Looking around it seems that this subject arises in many different areas.
I would like to know a reasonable order of the argument to study, to optimize my learning process instead of searching randomly on the web.","['complex-dynamics', 'book-recommendation', 'reference-request', 'complex-analysis', 'fractals']"
2939546,Explain conditional expectations and taking out measurable random variables,"We have the following property of conditional expectations from the point of veiw of measure theory ( $X$ and $Y$ are two random variables): $$\mathbb{E}(XY\mid\mathcal{G})=X\operatorname{\mathbb{E}}(Y\mid\mathcal{G}) $$ when $X$ is $\mathcal{G}$ -measurable. Shreve calls this property: Taking out what is known . Now, I know that how this works in statistics. Also, I know the definition of measurable function in Measure Theory. But I don't get the intuition here. Since when ""measurable"" is the same as ""known""? I always thought that ""measurable"" random variable was one that can be assigned probabilities and events to. This wouldn't make it necessarily known. Can you explain?","['statistics', 'conditional-expectation', 'measure-theory']"
2939576,$\left.\left(\frac{\mathrm d}{\mathrm d x}\right)^n J_0(x)\right|_{x=0}={}$?,"I am interested in determining a closed expression for the n-th derivative of the Bessel function of the first kind $J_0(x)$ , centered in $x=0$ : \begin{equation}
\left.\left(\frac{\mathrm  d}{\mathrm d x} \right)^n J_0(x)\right|_{x=0}
\end{equation} Can I compute it? If yes, how? Thanks in advance!","['special-functions', 'analysis', 'bessel-functions']"
2939605,Proving that $\sqrt{1 + x^2}$ is not a polynomial function,"The given task goes as follows: Show that $ f: \mathbb{R} \longrightarrow \mathbb{R}$ defined by $f(x) = \sqrt{1 + x^2} $ is not a polynomial function. I tried this approach - if $f(x)$ is a $n$ -degree polynomial function, then the $(n+1)$ -st derivative equals to 0 and I was trying to determine the $k$ -th derivative of $f(x)$ (and show it differs from 0 for any $k$ ) but without success. Since $f(x)$ is continuous and defined over whole R domain, I have no idea how to carry on. Any ideas?","['algebra-precalculus', 'polynomials', 'real-analysis']"
2939791,Finding Inverse Laplace Transform,"Calculate the inverse Laplace transform of: $$\frac{1}{s\cdot(\sqrt{s}+1)} \cdot e^{-\sqrt{s} \cdot x}$$ My attempt at the solution was to break down the fraction with partial fraction decomposition as follows: $$\frac{1}{s \cdot (\sqrt{s}+1)} = \frac1s-\frac{1}{\sqrt{s}}+\frac{1}{1+\sqrt{s}}$$ Then the first part can be easily computed from the table or by using some software: $$\mathcal{L}^{-1}( s^{-1} \cdot e^{-\sqrt{s} \cdot x} )= 1-erf(\frac{x}{2\sqrt{t}})$$ However the second part is not at all trivial, as I was unable to find any coherent answer to the problem: $$\mathcal{L}^{-1}( (-\frac{1}{\sqrt{s}}+\frac{1}{1+\sqrt{s}}) \cdot e^{-\sqrt{s} \cdot x} )$$ Could someone, please, guide towards the correct answer?
I have tried using computer algebra systems such Mathematica, but nothing seems to work. ***Treat x as a constant with x>0.","['laplace-transform', 'ordinary-differential-equations']"
2939848,Prove that there is a $m \in \mathbb{R}$ so that $f(f(m)) = m$,"The function $f : \mathbb{R} \to \mathbb{R}$ is continuous . Also $0\lt x_1 \lt x_2 \lt x_3 \lt x_4 \ $ and $f(x_1) = x_2 \ , \ f(x_2) = x_3 \ , \ f(x_3) = x_4 \ , \ f(x_4) = x_1 $ . Prove that there is a $m \in \mathbb{R}$ so that $f(f(m)) = m$ . My Try : Let $g(x) = f(x) - x $ and it is continuous over $\mathbb{R} $ . Furthermore , we have $g(x_1) \ , \ g(x_2) \ , \ g(x_3) \gt 0 $ and $g(x_4) \lt 0$ . The result is $f(c) = c$ for some $c$ between $x_3$ and $x_4$ . Applying $f$ to both sides yields to $f(f(c)) = f(c) = c$ . Is my solution correct ? Also write other solutions . Thanks in advance !","['continuity', 'calculus', 'solution-verification', 'real-analysis']"
2939870,Is $\sin(e)$ rational or irrational?,"We know that $\pi$ and $e$ are transcendental numbers. Here $\sin(x)$ is a real trigonometric function. We know that $\sin(\pi)=0$ which is rational.
Now I am wondering to know that whether $\sin(e)$ is rational or irrational. In addition, if it is irrational then whether $\sin(e)$ is transcendental.","['real-numbers', 'trigonometry', 'transcendental-numbers', 'real-analysis']"
2939884,Right angles in triangles formed in trapezoid,"In the following trapezoid, is angle A in triangle ABC a right angle even though it isn't labeled as such? And if so what property would we use to determine that? I was able to get the correct area for triangle ABC using Heron's formula after finding side AC using the Pythagorean theorem. Therefore, angle A in triangle ABC must be a right angle, but I can't find the property.","['triangles', 'geometry']"
2939898,Show that $Im(f(re^{i\theta})) = r \sin(\theta)(1+O(r))$ for small $r$,"Suppose f is a analytic function such that $f(0) = 1 = f'(0)$ and $/f^{(k)}(0) \in \mathbb{R} \; \forall k$ Show that $v(r,\theta) = Im(f(re^{i\theta})) = r \sin(\theta)(1+O(r))$ for small $r$ . I need to show this, but I don't believe it's true, here's why: I know that $f(re^{i\theta}) = \sum a_kr^k(\cos(k\theta)+i\sin(k\theta)) \implies v(r,\theta) = \sum a_kr^k \sin(k\theta)$ where $a_k = \frac{f^{(k)}(0)}{k!}$ . Now, $v(r,\theta) = 1+r\sin(\theta)+\sum_{k\geq 2}a_kr^ksin(k\theta) = r\sin(\theta)\left(1+\frac{1}{r\sin(\theta)}+\sum_{k\geq 2}a_kr^{k-2}\frac{sin(k\theta)}{sin(\theta)}\right)$ Now, $\frac{1}{r\sin(\theta)}$ is not limited by $Cr$ for any constant $C$ for small r, so, how can $\frac{1}{r\sin(\theta)}+\sum_{k\geq 2}a_kr^{k-2}\frac{sin(k\theta)}{sin(\theta)} = O(r)$ ? I'm sorry, I'm not used to the big Oh notation, regardless I don't know how that statement could be true.","['complex-analysis', 'asymptotics', 'real-analysis']"
2939900,Difference between $⊂$ and $⊆$?,"I was solving the exercises in Discrete Mathematics and its applications book. Determine whether each of these statements is true or
false. {0} ⊂ {0} {∅} ⊆ {∅} I thought both 1 and 2 are true, but when I checked the answers I found that 1 is false and 2 is true. I got confused and distracted because I don't know the difference between them.","['elementary-set-theory', 'notation', 'discrete-mathematics']"
2939911,What's the first non-planar graph of the first $n$ numbers where edges show divisibility?,"Let $G_n$ be a graph with vertices $v_1, v_2, v_3,\dots, v_n$ ,
where there is an edge between $v_i$ and $v_j$ if and only if either $v_i$ divides $v_j$ or vice versa.
Is there a value $n$ such that $G_n$ is non-planar,
ie cannot be drawn in the plane without intersecting edges?
If so, what is the least value of $n$ for which this happens?
By way of example,
the drawing below shows that $G_{12}$ is planar.","['graph-theory', 'elementary-number-theory', 'combinatorics']"
2939935,Probability that there are 5 Heads in the first 6 tosses and 3 Heads in the last 5 tosses.,"Consider 10 independent tosses of a biased coin with the probability of Heads at each toss equal to p , where 0 < p < 1. What is the probability that there are 5 Heads in the first 6 tosses and 3 Heads in the last 5 tosses. Give the exact numerical values of a,b,c,d that would match the answer $ap^{7}*(1-p)^{3}+b p^{c}(1-p)^{d}$ . I don't know how to do this question, especially the overlap part.","['discrete-mathematics', 'problem-solving', 'probability']"
2939958,Definition of measurability of $f:\Bbb R\to \Bbb R$,"Let $\cal B$ be the set of all Borel-measurable subsets of $\Bbb R$ and $\cal L$ be the set of all Lebesgue-measurable subsets of $\Bbb R$ . In measure theory texts, a function $f:\Bbb R\to \Bbb R$ is said to be measurable if for every $B\in \cal B$ , we have $f^{-1}(B)\in \cal L$ . Why is $\cal B$ used for range of the function. Why $\cal L$ is not used on both sides: a function $f:\Bbb R\to \Bbb R$ is said to be measurable if for every $L\in \cal L$ , we have $f^{-1}(L)\in \cal L$ ?","['measure-theory', 'lebesgue-measure']"
2940022,Is a convex function on an infinite dimensional cube bounded?,"Suppose $f : [0, 1]^\alpha \to \mathbb{R}$ is convex. Does it follow that $f$ has a lower bound? I've shown that this holds for finite $α$ . My question is whether it also holds for infinite $α$ . In the finite case, I can prove it by induction. First, we show this for an interval $[0, 1]$ . (For convex $f : [0, 1] \to \mathbb{R}$ , for $x ≥ \frac{1}{2}$ we have $f(x) ≥ 2f(\frac{1}{2}) - f(0)$ , and a similar bound holds for $x ≤ \frac{1}{2}$ .) Next, suppose that $f : [0, 1]^{n + 1} \to \mathbb{R}$ is convex. Then for each $x ∈ [0, 1]$ , let $f_x$ be the function that takes $y ∈ [0, 1]^n$ to $f(x, y_1, …, y_n)$ . Then each function $f_x$ is convex, and thus by the inductive hypothesis it is bounded. Let $b(x)$ be the greatest lower bound of $f_x$ . Then $b : [0, 1] \to \mathbb{R}$ is also convex. (For any $ε > 0$ , there are $y$ and $y'$ such that $f_x(y) < b(x) + \frac{ε}{2}$ and $f_{x'}(y') < b(x') + \frac{ε}{2}$ . So \begin{align}
b(λx + (1-λ)x') 
& ≤ f(λx + (1-λ)x', y) \\
& ≤ λf(x, y) + (1 - λ)f(x', y') \\
& < λb(x) + (1 - λ)b(x') + ε
\end{align} So $b(λx + (1-λ)x') ≤ λb(x) + (1 - λ)b(x')$ .)
So by the first part, $b$ also has a lower bound, and this must be a lower bound for $f$ . It seems like a similar argument using transfinite induction might work in general, but I don't know how the limit step would go.","['convex-analysis', 'linear-algebra', 'real-analysis']"
2940138,Urn Probability Problem containing algebraic variables,"Urn A contains $x$ red marbles and $y$ white marbles, and Urn B contains $z$ red marbles and $v$ white marbles. If a marble is drawn from Urn A and put into Urn B and then a marble is drawn from Urn B, what is the probability that the second marble is red? I get the answer $\frac{2z+1}{z+v+1}$ , but my book gives the answer $\frac{xz+x+yz}{(x+y)(z+v+1)}$ . I cannot understand how the books answer was obtained.",['probability']
2940155,Local factors determine Weil representations - proof of the cyclic case,"I want to understand the proof of the following Theorem from ""Euler Factors determine Weil Representations"" by Tim and Vladimir Dokchitser : Theorem 1 Every Frobenius-semisimple Weil representation $\rho$ is uniquely determined by its local polynomials $P(\rho/F,T)$ over finite separable extensions $F/K$. Before we talk about the cyclic case of the proof, let us recall some definitions first: Let $K$ be a local field and $G_K = \operatorname{Gal}(\bar{K}/K)$ be the absolute Galois group of $K$. An (arithmetic) Frobenius element is any element $\operatorname{Frob}_K \in G_K$ that acts as $x \mapsto x^{|k|}$ on $\bar{k}$, the algebraic closure of the residue field $k$ of $K$. The Weil group $W_K$ is the subgroup of $G_K$ of all automorphisms that act as an integral power of Frobenius on the residue field. A Weil representation is a representation $\rho: W_K \to \operatorname{GL}_n(\mathbb{C})$ such that $\rho(I_K)$ is finite. It is called Frobenius-semisimple if the image of some (equivalently, any) Frobenius element is diagonalizable. The local polynomial $P(\rho,T)$ is the inverse characteristic polynomial of $\operatorname{Frob}_K^{-1}$ on the inertia invariants of $\rho$, i.e. $$P(\rho,T) = \det(1-T \cdot \operatorname{Frob_K^{-1}}).$$
Similarly, for a finite extension $F/K$, we write $P(\rho/F)$ for the local polynomial of the restriction of $\rho$ to $W_F$, i.e. $$P(\rho/F,T) = P(\rho|_{W_F},T).$$ Now I would like to talk about the proof of the cyclic case which is given in the paper: Step 1: Cyclic. Suppose $\rho$ factors through a finite cyclic group $G = \operatorname{Gal}(F/K) \simeq C_n$ and $F/K$ has ramification degree $e$. By Lemma 2 (cf. below), there is a cyclic totally ramified extension $K/K$ of degree $e$ such that $FL/L$ is unramified of degree $n$. The restriction map $\operatorname{Gal}(FL/L) \to \operatorname{Gal}(F/K)$ is an isomorphism, as it is clearly injective and both groups have order $n$. So $\rho/L$ determines $\rho$, and $\rho/L$ can be recovered from its local polynomial $P(\rho/L,T)$. In our proof we used the following Lemma which we shall take for granted in this post: Lemma 2 Let $F/K$ be a cyclic extension of degree $n$ and ramification degree $e$. Then there exists a cyclic totally ramified extension $L/K$ of degree $e$ such that $FL/L$ is unramified of degree $n$. Now I have the following specific questions about the proof above: Could you give me a good argument why the restriction map $\operatorname{Gal}(FL/L) \to \operatorname{Gal}(F/K)$ is injective? Let us say we have $\sigma, \sigma' \in \operatorname{Gal}(FL/L)$ which are not equal. Then there exists an $x \in FL \setminus L$ such that $\sigma(x) \neq \sigma'(x)$. If $x \in F$ then the restrictions $\bar{\sigma}, \bar{\sigma}$ are obviously not equal. But what happens if $x$ is not in $F$? Why does $\rho/L$ determine $\rho$ then? And how can we recover $\rho/L$ from its local polynomial $P(\rho/L,T)$? What do ""determining"" and ""recovering"" even mean in these cases? Additional Remark : I would also like to add a diagram which my professor drew to explain me something relating to this Theorem (or Lemma?): $$\newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex}
\newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex}
\newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}}
\begin{array}{c}
&  &  &  & \operatorname{Gal}(LF/L) & \ra{\chi|_L, \text{ unramified}} & \operatorname{Gal}(K^{ur}/K) & & & & \\
&  &  &  & \da{\simeq} &  & \da{=} & & & & \\
1 & \ra{} & \operatorname{Gal}(F/K^{ur}) & \ra{} & \operatorname{Gal}(F/K) & \ra{} & \operatorname{Gal}(K^{ur}/K) & \ra{} & 1\\
 & &  & & \da{\chi} & &  & &  & &  \\
 &  &  &  & \mathbb{C}^\times & & & & & & \\
\end{array}$$
(Sorry, did not know how to do a long equal for $\operatorname{Gal}(K^{ur}/K)$.) And next to this diagram, he also wrote $P(\chi|_L,T) = 1 - \operatorname{Frob}_L \cdot T$. To this remark, I have the following questions (if it is really related to the proof): What is $\chi$ supposed to mean? Is the diagram commutative? Why all of the sudden does the maximal unramified extension (I think?) $K^{ur}$ of $K$ appear here? If or how is this related to the proof of Theorem 1 (resp. Lemma 2)? Could you please help me answering my questions? I feel like I lack a lot of background knowledge which is required here, so it would be really nice if you could explain them to me carefully. Thank you in advance!","['algebraic-number-theory', 'proof-explanation', 'representation-theory', 'galois-theory', 'abstract-algebra']"
2940216,Question about the chain rule.,"I was doing some practice problems with implicit differentiation and the chain rule.  This is something that I have known how to do, but I do not understand why it works.  Here is a screenshot of the derivative of $y^2$ with respect to $x$ : Where exactly does the $\frac{dy}{dx}\frac{d}{dy}$ come from?  Why exactly does $dy$ stay in the numerator; why is the final term $\frac{dy}{dx}[2y]$ and not $\frac{d}{dx}[2x]$ ?","['calculus', 'implicit-differentiation', 'derivatives']"
2940291,"In general, what information is given by $\nabla^2 f \geq 0$?","Since there are many directions one can take when studying this equation, I am curious: Given a function $f \in C^2$ defined on some open set, what information is given by $\nabla^2 f \geq 0$ ? Please let me know if I am missing something important for the question to make sense. Thanks in advance.","['harmonic-functions', 'real-analysis', 'multivariable-calculus', 'functional-analysis', 'partial-differential-equations']"
2940324,"For a positive function, can the length of gradient get arbitrarily close to 0?","Consider a differentiable function $f:R^d\rightarrow R_+$ . Let $a=\inf\limits_{x\in R^d} f(x)$ . It's evident that $a\ge0$ . Now if there exists $x\in R^d$ such that $f(x)=a$ , then $f'(x)=0$ . If there doesn't exist $x\in R^d$ such that $f(x)=a$ , can we prove that $\forall \epsilon>0, \exists x\in R^d$ such that $|f'(x)|<\epsilon$ ? Is there any relevant theorem?","['multivariable-calculus', 'supremum-and-infimum', 'real-analysis']"
2940339,A Countable Well-ordered (w.r.to usual order) subset of $\Bbb{R}$ which is not of same order type with a subset of $\Bbb{N}$,"Problem. Let $A$ be a countable subset of $\mathbb{R}$ which is well-ordered with respect to the usual ordering on $\mathbb{R}$ . Then A has an order preserving bijection with a subset of $\mathbb{N}$ . ( True/False ) My Attempt. I progressed a little in this problem. I try to construct a counterexample to conclude the statement FALSE . But all the examples I figure out don't work. For example... $\{ 1/n|n \in \Bbb{N} \}\cup \{ 0\}$ , $\{-1/2^n|n\in \Bbb{N} \}$ ..though all of them are well ordered and countable is order isomorphic to $\Bbb{N}$ . Also I can't prove the statement. Can you please help me to conclude the problem? Thank you.","['elementary-set-theory', 'real-analysis']"
2940365,Non-linear (trigonometric) equation having 1 unknown variable,"I want to solve following equation for ""a"". $$ X= \nu \bigg[\frac{\sin{\big(\pi(1+a) \frac{\Delta N}{\lambda}\big)}} {\sin{\big(\pi (1+a)\frac{\Delta N}{\lambda N}\big)}}\bigg] $$ I tried MATLAB 'solve', but unable to find symbolic solution for this in MATLAB. syms X a Delta_N N L
eqn = X==sin(pi*(1+a)*Delta_N/L)/sin(pi*(1+a)*Delta_N/(L*N));
sol_a=solve(eqn, a, 'ReturnConditions', true)
pretty(sol_a.a) The result is 'Warning: Cannot find explicit solution.' The conditions for $X$ is values between $0-1$ . $\lambda$ can take value between $2-8$ , $N=1024$ , $\Delta N=10$ or $\Delta N=20$ and $\nu = 1$ . The value of $a$ is very small. I tried to make changes in the equation using different $N$ in MATLAB. eqn = X==sin(pi*(1+a)*Delta_N/L)/sin(pi*(1+a)*Delta_N/(L*15)); I got this result: (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[1]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[2]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[3]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[4]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[5]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[6]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[7]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[8]))/(Delta_N*pi) - 1
  (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[9]))/(Delta_N*pi) - 1
 (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[10]))/(Delta_N*pi) - 1
 (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[11]))/(Delta_N*pi) - 1
 (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[12]))/(Delta_N*pi) - 1
 (15*L*acos(RootOf(z^14 - (13*z^12)/4 + (33*z^10)/8 - (165*z^8)/64 + (105*z^6)/128 - (63*z^4)/512 + (7*z^2)/1024 - X/16384 - 1/16384, z)[13]))/(Delta_N*pi) - 1","['nonlinear-system', 'trigonometry']"
2940374,"Cardinality of $\{(x, y)\mid x \in y \}$ for Finite Stages of von Neumann Universe","first time posting here, please feel free correct any formatting mistakes, thanks! We are familiar with the definition of the von Neumann universe. Of interests here are the finite stages: $$
V_0 = \emptyset \\ V_{n+1} = \mathcal{P}(V_n)
$$ So my question is the following: for each $V_n$ , what is the cardinality of the membership relation $\{(x, y) \in V_n \times V_n\mid x \in y \}$ ? Thank you very much!","['elementary-set-theory', 'combinatorics']"
2940394,Diffeomorphism between $TM$ and $M\times R^n$,"Let $(M,\mathcal{A})$ be a manifold with smooth structure $\mathcal{A}$ . For any point $x\in M$ , we define a tangent at x by the triplet $(c,x,h)$ , where $c=(U,\phi)$ is a chart at $x$ , $h\in R^n$ ( $n$ is the dimension of the manifold). For two charts $c,c'$ , define the following equivalence relation: $(c_1,x,h_1)\sim (c_2,x,h_2)$ if $D(\psi\circ\phi^{-1})(\phi(x))h_1=h_2$ , where $c_1=(U,\phi), c_2=(V,\psi)$ . Now, the tangent vectors at $x$ is defined by $T_xM=\{[c,x,h]: x\in M, h\in R^n\}$ and $[c,x,h]$ is the equivalence class. Finally, the tangent space is defined as $TM=\cup_{x\in M} T_xM$ . My question is the following: Can we show that $TM$ is diffeomorphic to $M\times R^n$ using this definition of tangent space? In particular, is it true when $M=\mathbb{S}^{n-1}$ ?","['tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
2940412,"Quadratic variation and brackets, whats the difference?","I am using Revous and Yor's book to learn about qudratic variations. For an arbitrary process this is defined via the following pointwise (in t) limit in probability $T^{\Delta _{n}}_{t} =\sum_{i=0}^{k-1}(X_{t_{i+1}}-X_{t_{i}})^2+(X_{t}-X_{t_{k}})^2$ But when when we define a similar concept for a local martingale we instead have that the random variables $\sup_{s\le t}\mid T^{\Delta _{n}}_{s}(M) - <M,M>_{s}\mid$ converging to zero in probablity. The latter looks stronger since it have to be uniform in the sequence of finite partitions. However is still looks like the same sum converges, just in a stronger sense. Yor do not however, call this the quadratic variation but he defines as the ""increasing process of $M$ "". And furthermore for distinct local martingales he calls it the ""bracket"". Is this common pratice not to call this stronger limit the qudratic variation but something else? And if yes is there a particular reason for this? My own guess is that this might have something to do with the fact that this is only considered for martingales and not processes in general, making it a subclass of the more general quadratic varitaion. They do however use citation marks in connection to the following statement ""Brownian motion is not a bounded martingale, nevertheless we have seen it has ""qudratic variation"" $t$ "".","['stochastic-processes', 'quadratic-variation', 'probability-theory', 'martingales']"
2940431,Torsion subgroup of a finitely-generated abelian group is finite?,"The above claim was made at the very beginning of a proof of the structure theorem for finitely-generated abelian groups and brushed off as easy. However, I think the problem is easy if the torsion subgroup is finitely-generated, but this does not seem to necessarily be true, or at least not obviously. Must the torsion subgroup be finitely-generated? And is the claim in the title true?","['finitely-generated', 'group-theory', 'torsion-groups', 'abelian-groups']"
2940476,Indecomposable modules for a finite group,"The following fact is mentioned in the book of Huppert-Blackburn vol. 2. Let $G$ be a finite group and $K$ a field of characteristic $p$ . Then there are only finitely many indecomposable $K[G]$ -module if and only if Sylow- $p$ - subgroups of $G$ are cyclic. So considering this fact, I was in search of examples. For the group $C_3\times C_3$ , what is (natural) infinite family of indecomposible modules with field $\mathbb{F}_3$ ?","['group-theory', 'representation-theory']"
2940529,Holomorphic function that decays faster than any exponential in a half plane?,"I'm getting some trouble with the following question. I will use the common notation $z=x+iy$ . It is well-known that $f(z)=e^{-z}$ tends to zero when $x$ tends to $+\infty$ , since $\vert f(z) \vert =e^{-x}$ . Of course, the same happens for the family of functions $f_{\lambda}(z)=e^{-\lambda z}$ where $\lambda >0$ is a positive parameter. In fact, if $\lambda$ is bigger, the decay is faster. My question is if it is possible to find a (non identically zero) $\textbf{holomorphic}$ function (in the right half plane) that decays faster than any function $f_{\lambda}$ . In mathematical terms, the question is if we can find an $\textbf{holomorphic}$ function $g \neq 0$ (in the right half plane) such that for any sequence $x_n+i y_n$ such that $x_n$ goes to $+\infty$ , we have that the limit $$g(x_n+iy_n) \cdot e^{\lambda (x_n + i  y_n)}$$ tends to zero for any $\lambda >0$ . Informally, when we go to the right in the complex plane (ignoring if $y$ changes or not) we must decay faster than any exponential. Remark: If $g$ is not required to be holomorphic the answer is trivially ""yes"". You just make $g(z)$ a function of its real parts (just depending on $x$ ) in a way that in the interval $[n,n+1]$ $g$ decays as $e^{-n}$ .",['complex-analysis']
2940546,"Prob. 4, Sec. 27, in Munkres' TOPOLOGY, 2nd ed: Any connected metric space having more than one point is uncountable","Here is Prob. 4, Sec. 27, in the book Topology by James R. Munkres, 2nd edition: Show that a connected metric space having more than one point is uncountable. Here is a solution. Although I do understand the proof at this URL [The gist of that proof is the fact that no finite or  countably infinite subset of $[0, +\infty)$ can be connected in the usual space $\mathbb{R}$ .], I'd like to attempt the following. My Attempt: Let $X$ be a set having more than one point. Suppose that $(X, d)$ is a metric space such that the set $X$ is either finite or countable. Case 1. If $X$ is finite, then we can suppose that $X = \left\{ \ x_1, \ldots, x_n \ \right\}$ , where $n > 1$ . Then, for each $j = 1, \ldots, n$ , let us put $$ r_j \colon= \min \left\{ \ d \left( x_i,  x_j \right) \ \colon \ i = 1, \ldots, n, i \neq j \ \right\}. \tag{1} $$ Then the open balls $$ B_d \left( x_j, r_j \right) \colon= \left\{ \ x \in X \ \colon \ d \left( x, x_j \right) < r_j \ \right\},   $$ for $j = 1, \ldots, n$ , are open sets in $X$ . In fact, we also have $$ B_d \left( x_j, r_j \right) = \left\{ \ x_j \ \right\}, \tag{2} $$ because of our choice of $r_j$ in (1) above, for each $j = 1, \ldots, n$ . So a separation (also called disconnection) of $X$ is given by $$ X = C \cup D, $$ where $$ C \colon= B_d \left( x_1, r_1 \right) \ \qquad \ \mbox{ and } \ \qquad \ D \colon= \bigcup_{j=2}^n B_d \left( x_j, r_j \right). $$ Thus $X$ is not connected. Is my logic correct? Case 2. If $X$ is countably infinite, then suppose that $X$ has points $x_1, x_2, x_3, \ldots$ . That is, suppose $$ X = \left\{ \ x_1, x_2, x_3, \ldots \ \right\}. $$ Then, as in Case 1, we can show that every finite subset of $X$ having more than one points is not connected. Am I right? Can we show from here that $X$ is not connected?","['connectedness', 'proof-verification', 'metric-spaces', 'analysis', 'general-topology']"
2940617,Find the limit of $(\frac{1}{2} \frac{3}{4} ...... \frac{2n -1}{2n})$?,"Find the limit of $(\frac{1}{2} \frac{3}{4} ...... \frac{2n -1}{2n})$ ? I have calculated it through calculating the limit of the general term $a_{n} = \frac{2n -1}{2n}$ and it was equal to 1, am I correct?","['limits', 'sequences-and-series']"
2940631,"Show that infinitely many positive integer pairs $(m,n)$ exist s.t $\frac{m+1}{n}+\frac{n+1}{m} \in \mathbb{N}$ [duplicate]","This question already has answers here : $\frac{m+1}{n}+\frac{n+1}{m}$ is a positive integer for infinitely many $(m,n)$ (4 answers) Closed 5 years ago . Show that infinitely many positive integer pairs $(m,n)$ exist such that $\frac{m+1}{n}+\frac{n+1}{m} \in \mathbb{N}$. I couldn't solve it but I did make an observation which might or might not be helpful.
WLOG assume that $m < n$ (since the term is symmetric wrt $m,n$ along with the fact that ignoring the $m=n$ case wouldn't create any trouble). Write $n=mq+r$ for some $r\in \{[0,m-1]\cap \mathbb{N}\}$. Now, the question boils down to showing $\frac{m+1}{n}+\frac{r+1}{m} \in \mathbb{N}$. Note that each of the summand is $\leq 1$. Since the equality case wouldn't be helpful in generating infinitely many pairs of $(m,n)$, we can safely say that the sum is equal to $1$. Now I don't know how to proceed from here.","['number-theory', 'vieta-jumping', 'elementary-number-theory']"
2940656,"Simplifying $\sum_{n=0}^{\infty}\sum_{m=0}^{\infty}\sum_{l=0}^{\min(n,m)}a_{l}b_{m-l}c_{n-l}$","I have come across a sum of the following form; $$\sum_{n=0}^{\infty}\sum_{m=0}^{\infty}\sum_{l=0}^{\min(n,m)}a_{l}b_{m-l}c_{n-l}$$ and want to simplify it (in particular to remove the $min(n,m)$ ). I believe (although am not 100% sure), that it can be reduced simply to; $$\left(\sum_{i=0}^{\infty}a_{i}\right)\left(\sum_{j=0}^{\infty}b_{j}\right)\left(\sum_{k=0}^{\infty}c_{k}\right)$$ I have been trying to get it into the form of the Cauchy product, which for three sums reads; $$
\left(\sum_{i=0}^{\infty}a_{i}\right)\left(\sum_{j=0}^{\infty}b_{j}\right)\left(\sum_{k=0}^{\infty}c_{k}\right)
=
\sum_{k_{1}=0}^{\infty}\sum_{k_{2}=0}^{k_{1}}\sum_{k_{3}=0}^{k_{2}}a_{k_{1}-k_{2}}b_{k_{2}-k_{3}}c_{k_{3}}
$$ but haven't had any luck.
To deal with the $\min(n,m)$ term I have tried splitting up the sum into three parts; $n<m$ , $m<n$ , and $n=m$ , yielding; $$
\sum_{n=0}^{\infty}\sum_{m=0}^{n}\sum_{l=0}^{m-1}a_{l}b_{m-l}c_{n-l}
+
\sum_{m=0}^{\infty}\sum_{n=0}^{m}\sum_{l=0}^{n-1}a_{l}b_{m-l}c_{n-l}
+
\sum_{n=0}^{\infty}\sum_{l=0}^{n}a_{l}b_{m-l}c_{n-l}
$$ Which is close to the Cauchy product form, but unfortunately not close enough. Any help on this would be much appreciated.","['cauchy-product', 'discrete-mathematics', 'sequences-and-series']"
2940671,"Chances of rolling ""Snake Eyes"" at least once in a series of rolls.","So I know that if you roll a standard pair of dice, your chances of getting Snake Eyes (double 1s) is $1$ in $36$ . What I'm not sure of is how to do the math to figure out your chances of rolling Snake Eyes at least once during a series of rolls. I know if I roll the dice $36$ times it won't lead to a $100\%$ chance of rolling Snake Eyes, and while I imagine it's in the upper nineties, I'd like to figure out exactly how unlikely it is.","['dice', 'probability']"
2940843,Does this sequence of polynomials have a name?,"I'm very interested in the function $$f : (0,\infty) \rightarrow (0,\infty)$$ $$x \mapsto - \log(1-e^{-x}).$$ When I use Wolfram alpha to compute the $n$ th derivatives of $f$ , I find that there exists a sequence of polynomials $P_1,P_2,\ldots$ such that for $n \geq 1$ we have $$f^{(n)}(x) = \frac{e^x}{(1-e^x)^n}P_n(e^x).$$ For example: $$\frac{d^6}{dx^6}(-\log(1 - e^{-x})) = \frac{e^x}{(1-e^x)^6} (1+26 e^x + 66 e^{2 x} + 26 e^{3 x} + e^{4 x})$$ Question. Is there a name for this sequence of polynomials? If these polynomials don't have a name, I'd also be satisfied with a name for the variant on Pascal's triangle whose entries are the coefficients of these polynomials.","['calculus', 'polynomials']"
2940875,Find a recursive definition of this sequence,"I always have some difficulty with problems of this type, and I was wondering if there was a typical trick that makes it reasonable. Let $W_n$ be the number of words of length $n$ formed with the letters $A$ and $B$ such that There are no words that contain sequences of $A$ s with length exactly 2 There are no words that contain sequences of $B$ s with length exactly 2 or 3. Examples of words: $AAAB, ABABABA, ABBBBAAABA$ , and of non-words: $AAB, ABBBA$ , etc. These ""recursion with constraints"" type problems always cause me difficulty. I want to write $W_n = f(W_{n-1}, W_{n-2}, \ldots, W_{n-k})$ for some fixed $k$ . I tried to break it into cases based on what the last letter is, so $W_n = A_n + B_n$ where $A_n$ is the number of words of length $n$ that end in $A$ and $B_n$ defined similarly. Then getting recursive definitions for $A_n$ in terms of some $B_{n-k_i}$ and $W_{n-k_j}$ and likewise recursive definitions for $B_n$ produces a whole mess of terms that don't cancel even when you get these $W_{n-11}$ terms showing up. Surely I'm missing the trick?","['combinatorics', 'recurrence-relations']"
2940883,Exact form $\alpha$ and $dg=\alpha$,"Let $\alpha= f_1(x_1,x_2)dx_1 + f_2(x_1,x_2)dx_2$ such that $d\alpha=0$ . Define a function $g$ by $$g(x_1,x_2)= \int_{0}^{x_1} f_1(t,x_2) dt + \int_{0}^{x_2} f_2(0,t)dt$$ Show that $dg=\alpha$ By $d\alpha=0$ we get $\dfrac{\partial{f_2}}{\partial{x_1}}-\dfrac{\partial{f_1}}{\partial{x_2}}=0$ and $$dg= \dfrac{\partial}{\partial{x_1}} ( \int_{0}^{x_1} f_1(t,x_2) dt ) dx_1+\dfrac{\partial}{\partial{x_2}}(\int_{0}^{x_1} f_1(t,x_2) dt) dx_2$$ $$+\dfrac{\partial}{\partial{x_1}}(\int_{0}^{x_2} f_2(0,t) dt) dx_1 +\dfrac{\partial}{\partial{x_2}}(\int_{0}^{x_2} f_2(0,t) dt) dx_2$$ By Leibniz integral rule $\dfrac{\partial}{\partial{x_1}} ( \int_{0}^{x_1} f_1(t,x_2) dt ) =f_1(x_1,x_2) + ( \int_{0}^{x_1}\dfrac{\partial}{\partial{x_1}} f_1(t,x_2) dt ) $ $\dfrac{\partial}{\partial{x_2}}(\int_{0}^{x_1} f_1(t,x_2) dt)=(\int_{0}^{x_1} \dfrac{\partial}{\partial{x_2}}f_1(t,x_2) dt)$ $\dfrac{\partial}{\partial{x_1}}(\int_{0}^{x_2} f_2(0,t) dt)=(\int_{0}^{x_2} \dfrac{\partial}{\partial{x_1}}f_2(0,t) dt)$ $\dfrac{\partial}{\partial{x_2}}(\int_{0}^{x_2} f_2(0,t) dt)=f_2(0,x_2)+(\int_{0}^{x_2}\dfrac{\partial}{\partial{x_2}} f_2(0,t) dt)$ Do i have any mistake? And can you continue to compute those and indicate $dg=\alpha$ ?","['differential', 'differential-forms', 'multivariable-calculus', 'analysis']"
2940950,"What does ""composing"" mean when symmetry reducing a differential equation?","I am reading a set of lecture notes describing the process of symmetry reduction of differential equations via Lie algebra methods ( link ), and I'm stuck at what seems to be a fairly simple point. The specific example is the Korteweg-DeVries equation, $$u_t+uu_x+u_{xxx}=0.$$ The Lie algebra will be realized as a vector field $$\hat{v}=\xi(x,t,u) \partial_x+\tau(x,t,u) \partial_t+\phi(x,t,u)\partial_u.$$ Now I'll directly cut from the notes: (I am excerpting but I don't think I'm missing anything critical - check out pg 5 of that link if you want more background). Anyway, we go through the process of determining the vector field, and end up with $$\xi=1+t+x,\qquad \tau=1+3t,\qquad \phi=-2u+1$$ So now, I should be integrating these equations, subject to the initial conditions $\tilde{x}(0)=x$ , etc. That shouldn't be a problem: $$\frac{d\tilde{x}}{d\lambda}=1+\tilde{t}+\tilde{x}\rightarrow \tilde{x}=e^\lambda(1+\tilde{t}+x)-(1+\tilde{t})$$ $$\frac{d\tilde{t}}{d\lambda}=1+3\tilde {t}\rightarrow \tilde{t}=\frac{1}{3}e^{3\lambda}(1+3t)-\frac{1}{3}$$ $$\frac{d\tilde{u}}{d\lambda}=-2\tilde{u}+1\rightarrow \tilde{u}=\frac{1}{2}e^{-2\lambda}(2u+1)-\frac{1}{2}$$ (we could eliminate $\tilde{t}$ from the first equation, but that won't help what I'm going to say next) The problem is that in the notes (pg 9), the result is given as So for this to match my results I would need to take, for instance, $$t_0=\frac{1}{3}(1-e^{-3\lambda}),$$ certainly not a constant. So what am I doing wrong? I guess I am concerned with not understanding what ""composing the one-dimensional subgroups"" means, but I thought that is describing the process of getting from one solution to another. Like once you get $u(x,t)$ , you can use the results above to get another solution $\tilde{u}(\tilde{x},\tilde{t})$ .","['lie-algebras', 'lie-groups', 'ordinary-differential-equations']"
2941008,"Is there any mistake in my approach for solving $ \int_0^{\pi/2} \frac{ \cos x}{3 \cos x + \sin x} \, dx $ ??","I had to evaluate this integral . $$
\int_0^{\pi/2} \frac{\cos x}{3 \cos x + \sin x} \, dx
$$ Here is how I proceeded Dividing $N^r$ And $D^r$ by $\cos^3 x$ $$
\int_0^{\pi/2} \frac{ \sec^2 x}{3 \sec^2 x + \tan x \sec^2 x}\, dx \\
$$ Substituting $\tan x = t$ $$
\int_0^\infty \frac{ 1 }{(1+t^2)(t+3)} \, dt \\
$$ Then by using Partial Fractions , I got the answer as $$
\frac{1}{10} \log (t+3) - \frac{1}{20} \log (t^2 + 1) + \frac{3}{10} \arctan (t)  \biggr|_{0}^{\infty}
$$ But while substituting the limits , the answer comes out be be infinity which is wrong . Is there any mistake in my approach ??","['integration', 'definite-integrals', 'logarithms', 'calculus', 'partial-fractions']"
2941015,Are there polynomials $p(x)$ such that $p(\sin x)=\sin(2x)$ for all $x$?,"Are there any polynomials $p(x)$ such that $$p(\sin x)= \sin (2x)\;\;\;\;\; \forall x \in \mathbb{R}\,?$$ This is what i did: Anyway, thanks for your hint, I think I've found the solution. Here's my reasoning: we would have $|p(t)|=2t\sqrt{1−t^2}$ , $\forall t\in\mathbb{R}$ , so for the identity principle $|p(t)|=2t\sqrt{1−t^2}$ but this is not a polynomial. Is it right?","['algebra-precalculus', 'polynomials', 'trigonometry']"
2941019,Evaluating $\mathcal{P}\int_0^\infty \frac{dx}{(1 + a^2x^2)(x^2 - b^2)}$,"I am trying to evaluate this integral $$\mathcal{P}\int_0^\infty \frac{dx}{(1 + a^2x^2)(x^2 - b^2)}$$ with $\mathcal{P}$ the principal value and $a,b>0$ . I already know the answer to be $$ - \frac{a\pi}{2(1 + a^2b^2)}$$ after fiddling with Mathematica putting numbers for $a$ and $b$ . The poles of this function are at $x=\pm b, \pm \frac{i}{a^2}$ so I cannot find a proper contour. Any help in getting the answer will be appreciated!","['complex-analysis', 'complex-integration', 'improper-integrals']"
2941035,"$R$ is a unital commutative ring, $M$ and $N$ are $R$-modules. If $f:M \to N$ is $R$-linear, then is it true that $M= \ker(f) \oplus \text{im}(f)$?","Let $R$ be a commutative ring with unity.  Prove or disprove: for $R$ -modules $M$ and $N$ , if $f:M \to N$ is $R$ -linear, then $M= \ker(f) \oplus \operatorname{im}(f)$ . My attempt: Let $f : \Bbb Z/4\Bbb Z \to \Bbb Z/2\Bbb Z$ be defined by $f(\bar{n}) = \overline{2n}$ . Then, $\operatorname{im}(f) = \Bbb Z/2\Bbb Z$ and $\ker(f) = \{\bar{0},\bar{2}\} \cong \Bbb Z/2\Bbb Z$ (as $\Bbb Z$ -modules). But clearly, $\Bbb Z/4\Bbb Z  \not\cong \Bbb Z/2\Bbb Z \oplus \Bbb Z/ 2\Bbb Z$ . Is my answer correct? If there are any mistakes, please point out.","['abstract-algebra', 'proof-verification', 'modules']"
2941072,Compute $\lim_{n\rightarrow\infty}\sqrt[{n+1}]{(n+1)!}-\sqrt[n]{n!}$ [duplicate],This question already has answers here : Computation of a limit involving factorial $\lim_{n \to \infty} \sqrt[n+1] {(n+1)!} - \sqrt[n] {(n)!} = \frac{1}{e}$ (4 answers) Closed 5 years ago . Evaluate $L=\lim_{n\rightarrow\infty}\sqrt[{n+1}]{(n+1)!}-\sqrt[n]{n!}$ How I approached it and where I get stuck: $$\lim_{n\rightarrow\infty}\sqrt[{n+1}]{(n+1)!}-\sqrt[n]{n!}=\lim_{n\rightarrow\infty}\frac{\sqrt[n]{n!}}nn(\frac{\sqrt[{n+1}]{(n+1)!}}{\sqrt[n]{n!}}-1)$$ Now: $$\lim_{n\rightarrow\infty}\frac{\sqrt[n]{n!}}n=\lim_{n\rightarrow\infty}\sqrt[n]{\frac{n!}{n^n}}=\lim_{n\rightarrow\infty}e^{\frac1n\sum_{k=1}^n\ln(\frac kn)}=e^{\int_0^1\ln(x)dx}=e^{-1}=\frac1e$$ So $L=\lim_{n\to\infty}\frac 1e\times n(\frac{\sqrt[{n+1}]{(n+1)!}}{\sqrt[n]{n!}}-1)$ . Now this is where I get stuck. What should I do?,"['limits', 'limits-without-lhopital', 'real-analysis']"
2941153,How evaluate $ \int_0^\infty \frac{\ln^2\;\left|\;\tan\left(\frac{ax}{2}-\frac{\pi}{4}\right)\;\right|}{1+x^2} \;dx$,"How evaluate (without using Complex analysis) $$ \int_0^\infty \frac{\ln^2\;\left|\;\tan\left(\frac{ax}{2}-\frac{\pi}{4}\right)\;\right|}{1+x^2}\; dx\quad (a\gt0)$$ My Attempt: I used the expansion of the following functions: $$ \ln\left|2\sin(x)\right| \text{ and }\ln\left|2\cos(x)\right| $$ To get the following expansion: $$ \ln\;\left|\;\tan\left(\frac{ax}{2}-\frac{\pi}{4}\right)\;\right|=2\sum_{n=1}^\infty (-1)^n \frac{\sin[(2n-1)ax]}{2n-1} $$ Then I expressed the square of the logarithmic function as follows: $$ \ln^2\;\left|\;\tan\left(\frac{ax}{2}-\frac{\pi}{4}\right)\;\right|=4\sum_{m=1}^\infty\sum_{n=1}^\infty (-1)^{m+n} \frac{\sin[(2m-1)ax]\sin[(2n-1)ax]}{(2m-1)(2n-1)} $$ And used the formula of the product of two sines, then integrated the following well known integral under the summation sign: $$ \int_0^\infty \frac{\cos(bx)}{1+x^2} \;dx$$ And expressed the final result in terms of $\; \arctan\;\left(\;e^{-a}\;\right)\; $ but this was not the right answer according to the one evaluated by Complex analysis, which is $$ \frac{{\pi}^3}{8}-2\pi\; \arctan^2\;\left(\;e^{-a}\;\right) $$ Any hint for another method or idea?","['improper-integrals', 'real-analysis']"
2941183,Why is a Itô integral w.r.t. Brownian motion a martingale?,"I'm trying to understand why $M_t(\omega)=\int^t_0 f(s,\omega)dB_s$ is a martingale w.r.t. $\mathcal{F}_t$ . I know that for $I_n(t,\omega)=\int^t_0 \phi_n(a,\omega)dB_a(\omega) $ -- the approximation of $M_t(\omega)$ , using elementary functions (Riemann sums) -- we have $E[I_n(s,\omega)|\mathcal{F}_t]=I_n(t,\omega)$ . To prove that $M_t(\omega)$ is a martingale, I would need to be able to interchange the $\lim$ and $E()$ . Which convergence theorem can I use and how?","['stochastic-integrals', 'stochastic-processes', 'probability-theory']"
2941187,"MLE for Uniform $(0,\theta)$","I am a bit confused about the derivation of MLE of Uniform $(0,\theta)$ . I understand that $L(\theta)={\theta}^{-n}$ is a decreasing function and to find the MLE we want to maximize the likelihood function. What is confusing me is that if a function is decreasing, then wouldn't the function be maximized at the smallest input rather than the largest? Thank you in advance for your help.","['statistics', 'uniform-distribution', 'parameter-estimation', 'maximum-likelihood']"
2941220,Implicit function theorem and fiber,"Let $\pi:X\to T$ be a proper surjective holomorphic mapping of maximal rank from a complex manifold $X$ to a complex manifold $T$ . Let $X_t=\pi^{-1}(t)$ . Then $X_t$ is the fibre over $t$ , or the compact complex submanifold of $X$ corresponding to the parameter $t\in T$ . I can't see clearly why $\psi_p|_{U_p\cap X_t}\cong U'_p\cap C^n\times\{t\}$ by implicit function. I think by implicit function theorem we can only get the case for $t=0$ . However I can't see we can find a general $U_p$ s.t. the $t$ around $0$ can share with $0$ by using the common $U_p$ .","['complex-analysis', 'complex-geometry', 'implicit-function-theorem', 'differential-geometry']"
2941245,How to solve $\frac{dy}{dx}=-\frac{y}{x^2+y^2}$?,"How does one solve the differential equation $$\frac{dy}{dx}=-\frac{y}{x^2+y^2}$$ I've tried to convert to polar coordinates: I let $$x=r(\varphi)\cdot\cos(\varphi)$$ $$y=r(\varphi)\cdot\sin(\varphi)$$ Then, $$\frac{dx}{d\varphi}=r'(\varphi)\cdot\cos(\varphi)+r(\varphi)\cdot\sin(\varphi)$$ $$\frac{dy}{d\varphi}=r'(\varphi)\cdot\sin(\varphi)+r(\varphi)\cdot\cos(\varphi)$$ such that $$\frac{dy}{dx}=\frac{r'(\varphi)\cdot\sin(\varphi)+r(\varphi)\cdot\cos(\varphi)}{r'(\varphi)\cdot\cos(\varphi)+r(\varphi)\cdot\sin(\varphi)}$$ Substitution into the differential equation yields $$\frac{r'(\varphi)\cdot\sin(\varphi)+r(\varphi)\cdot\cos(\varphi)}{r'(\varphi)\cdot\cos(\varphi)+r(\varphi)\cdot\sin(\varphi)}=-\frac{\sin(\varphi)}{r(\varphi)}$$ It does not seem to get any easier now does it.",['ordinary-differential-equations']
2941303,L'Hôpital's rule only applicable if right-hand limit exist?,"In a source I have been reading, this statement was made regarding L'Hôpital's rule: Why is it the case that L'Hôpital's rule is applicable only if the right-hand limit exists?  Why not the left-hand? Why not both?  I have read other sources on L'Hôpital's rule that do not mention it and would like clarification. Here is the text: L'Hôpital's Rule: Suppose that $f$ and $g$ are differentiable functions, and $f(a)=g(a)=0$ , and suppose that $g'(x)$ is nonzero in a neighborhood of $a$ (except maybe at $a$ itself).  Then $$\lim\limits_{x \to a} \ \frac{f(x)}{g(x)}=\lim\limits_{x \to a} \ \frac{f'(x)}{g'(x)}$$ if the limit on the right-hand side exists.","['calculus', 'derivatives']"
2941323,What is the probability that the most common 3 results of 12 equally likely outcomes are selected by at least 11 of a sample of size 22?,"For a illustrative example: 22 people are being sorted into 12 teams. 12 colored balls are placed in a hat. Each player draws a ball from the hat (with replacement) to figure out which team they are on. When the 3 largest teams are counted (random selection among ties for 3rd), the total of these teams is 11 or higher . What are the chances that this is the case? Here's what I've gotten so far. I've established that the maximum number of configurations for the teams is (33 choose 11). I know that I need to select for the largest 3 which can be chosen in (13 choose 2) ways. I'm unsure how to check if the largest 3 teams have 11 or more players. This problem actually relates to a non-mathematical query I had regarding 12 possible outcomes selected by a sample of 22 persons. I have only foundational mathematical knowledge. Source of the question: In Dungeons and Dragons , there are 12 classes players can select. While the chance a player selects them is obviously not random in the real world, a chatizen friend of mine was contemplating a combinatorics question regarding a specific outcome of one of the games he is running. In particular, 11 of the first 22 applicants chose the same 3 classes (Wizard, Fighter, and Paladin). Then, after more applications came in (checking later on during the conversation), 50% of the 28 applications were still these 3. So we wanted a more generalized approach, prompting a question here. This conversation was in a StackExchange chat room, a bookmark of which can be found here .",['combinatorics']
2941327,A Proposition related to Fermat Factorization Method,"The following proposition is so related to Fermat Factorization method. The proposition states the following: Let $n$ be an odd positive integer. If $n$ is composite, then there is an integer $x$ in the interval $[\sqrt{n},\frac{n+1}{2})$ that makes $x^2-n$ a square. How can such proposition be proven?","['number-theory', 'divisibility', 'elementary-number-theory', 'factoring']"
2941359,Understanding partial derivative involving 3 variables,"I am new to partial derivative and I need some help in understanding if what I have done so far is correct. Let $S$ be the surface given by $x^2 + y^2 - 3z^2 = 5$ I want to calculate the partial derivative: $\frac{\partial z}{\partial x}$ at the point $(2,2,1)$ and $(2,2,-1)$ This is what I have done: $x^2 + y^2 - 3z^2 = 5$ $z^2 = \frac{x^2 + y^2 - 5}{3}$ $z = \pm \sqrt\frac{x^2 + y^2 - 5}{3}$ $\frac{\partial z}{\partial x} = \frac{\frac{1}{2}(x^2 + y^2 - 5)^{-\frac12}(2x)}{\sqrt3}$ $\frac{\partial z}{\partial x} = \frac{2x}{2\sqrt{3}\sqrt{x^2 + y^2 - 5}}$ $\frac{\partial z}{\partial x} = \frac{x}{\sqrt{3}\sqrt{x^2 + y^2 - 5}}$ But I am unsure of how to continue after this, and how to use the points (2,2,1) and (2,2,-1).","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
2941368,How to prove that the limit of this sequence is $400/\pi$,"I am new to this forum, so I hope I am proceeding in the correct way. Please excuse any mistakes. I am trying to prove that the limiting factor of a 2D shape's surface area is a circle, and I have managed to find an equation for this from a regular polygon. In my question, I assume that the maximum perimeter/circumference one can form is 40cm (i.e. if someone has 40cm of string). So: For a perimeter of 40: $$
\lim_{n \rightarrow \infty}\frac{200\sin(\frac{2π}{n})}{n\sin^2(\frac{π}{n})}=\frac{400}{π}
$$ I got this value using Wolfram Alpha, which confirmed that the limiting factor for surface area is a circle, since the surface area of a circle with a circumference of 40cm = 400/π. However, I am unable to prove this formula algebraically. I tried using l'hospital's rule after realising that the limit of the original function was 0/0, but I got nowhere. In fact, the result I got was -400π/0, which was very disappointing after so much working out! I was wondering if anyone could help me prove this algebraically or otherwise. I am happy that I found an equation that proves what I wanted to, but I am unable to prove Wolfram Alpha's result, which is frustrating. Again, I am new to this forum, so please let me know if I have made any mistakes so that I can edit my question.","['limits', 'calculus', 'limits-without-lhopital']"
2941386,Find the derivative of an inverse function,"Let $f:\mathbb{R} \to \mathbb{R}$ be a function, $f(x)=\frac{x^3}{3}+\frac{x^2}{2}-6x+4$ . Let $I$ be the longest closed interval such that $0 \in I$ and $f$ is invertible. And let $g$ be the inverse function of $f$ in $I$ . Find $I$ and $g'(4)$ . What I've been doing: I found $f'(x)=x^2+x-6$ and I found the roots which are $-3$ and $2$ , and then I looked where the function decreases and increases. So $f$ is strictly decreasing in $I=[-3, 2]$ so $f$ must be bijective, and then invertible (right?), also $0 \in I$ . Now I have to find $g'(4)$ : I have that $g(x)=f^{-1}(x)$ so $(f^{-1})'(x)=\frac{1}{f'(f^{-1}(x))}$ and now my problem is: How do I find $f^{-1}(x)$ ?","['calculus', 'inverse-function', 'derivatives', 'real-analysis']"
2941404,Which relationship between trace and determinant is established using density?,"I read in some lecture notes that ""as an example for the intersection between linear algebra and calculus, one can establish the relationship between trace and determinant of a matrix using a density-argument"". Which relationship is meant? And what would the argument be?","['determinant', 'trace', 'analysis', 'matrices', 'linear-algebra']"
2941414,Understanding a Proof: Open connected sets and differentiable paths,"I'm reading a book of complex analysis (Jerrold E. Marsden) and I came across a demonstration I can´t understand. I really want to understand it. $\textbf{Proposition}:$ If $C$ is an open connected set and $a$ and $b$ are in $C$ , then there is a differentiable path $\gamma:[0, 1]\rightarrow C$ with $\gamma(0)=a$ and $\gamma(1)=b$ . $\textbf{Proof}:$ Let $a\in C$ . If $z_o\in C$ , then since $C$ is open, there is an $\epsilon>0$ such that the disk $D(z_o; \epsilon)$ is contained in $C$ . $\textit{So far so good}$ By combining a path from $a$ to $z_o$ with one from $z_o$ to $z$ that stays in the disk, we see that: $z_o$ can be connected to $a$ by a differentiable path if and only if the same is true for every point $z\in D(z_o;\epsilon)$ $\textit{I can't see how the above is true}$ This shows that both the sets $A=\{z\in\mathbb C | z\text{ can be connected to }a \text{ by a differentiable path}\}$ $B=\{z\in\mathbb C | z\text{ cannot be so connected to }a\}$ are open. $\textit{Why they are open?}$ Since $C$ is connected, either $A$ or $B$ must be empty. Obviously it must be B. $\text{I dont´have problems with the conclusion.}$ I thank everyone who helps me understand.","['complex-analysis', 'path-connected']"
2941425,UMVUE of $E[X^2]$ where $X_i$ is Poisson $(\lambda)$,"I am working on a problem to find the UMVUE of a function. Let $X_1, X_2, ..., X_n$ be i.i.d. Poison $(\lambda)$ . Find the UMVUE of E[ $X^2$ ]. So far I understand that $$E[X^2]=Var[X]+E[X]^2=\lambda+\lambda^2$$ and thus $$\begin{align}
 E[\hat{\lambda}_{MLE}^2] & = \bar{X}(1+\bar{X})\\
\end{align}$$ Now the goal is to adjust this so that it is unbiased, so I did $$\begin{align}
E[\bar{X}(1+\bar{X})] &= E[\bar{X}]+Var[\bar{X}]+E[\bar{X}]^2\\
&= \lambda +\lambda/n +\lambda^2
\end{align}
$$ And then I could not proceed from there. The notes that I received mentions that we do something from here but it was not explicit and I am not sure how to make this unbiased. Thank you in advance.","['statistical-inference', 'statistics', 'parameter-estimation', 'poisson-distribution']"
2941426,"Subsets of a set, symmetric differences of the form $\{ i , i + 1 \}$","Let $A_i = \{i, i + 1\}$ . Which subsets of $\{1, 2, 3, . . . , n \}$ can be written as the symmetric difference of a number of the
sets $A_1, A_2, . . . A_{n−1}$ ?","['elementary-set-theory', 'combinatorics', 'discrete-mathematics']"
2941442,Fluid dynamics computing streamlines,"I have a question where I have to compute the streamlines given the fluid flow $\vec{u} = (y,x)$ . I must show the streamlines are $x^2 -y^2 = \;$ const. I start of by writing some differential statements: $\frac{dx}{dt} = y \; \; \; \;$ as well as $\; \; \; \; \frac{dy}{dt} = x$ Then I isolate for $dt$ : $\rightarrow dt = \frac{dx}{y}  \; \; \; \;$ as well as $ \; \; \; \; \rightarrow dt = \frac{dy}{x} $ Then I simply eliminate $dt$ altogether by substituting one of the equations into the other and obtaining a simple separable first order ODE: $\rightarrow x\:dx = y \:dy$ eventually leading to: $\rightarrow x^2 - y^2 =\; $ Const as was required in the problem, and I am satisfied with my final answer however I am unsure if my move of eliminating $dt$ through substitution is valid. If not can someone please explain why not. Thanks for all your time!","['integration', 'calculus', 'ordinary-differential-equations', 'fluid-dynamics']"
2941459,"Show that $\mathbb Q\cap [0,1]$ is not Jordan measurable.","I'm trying to show two things: 1. $J^*([0,1])=1$ , where $J^*$ is the Jordan outer measure. 2. $\mathbb Q\cap [0,1]$ is not Jordan measurable - i.e. the Jordan outer and inner measures do not agree. The Jordan measures here are defined on finite union of open intervals. Any hints or proof help would be greatly appreciated.",['measure-theory']
2941468,"Not Following Serre's Argument: Extension/Restriction of a Sheaf, Continuity","I am working through the proof of proposition 5 in Section 5: Extension and restriction of a sheaf in FAC by Serre. FAC can be found in english here , and in particular this question arises on page 11, but I will also include the entire proposition and proof below, and I will also warn that Serre uses the etale space definition of a sheaf (much older), not the modern functor definition. The categories are equivalent. If you have only seen the modern definition this will seem strange. If anyone needs me to include certain definitions if they are unfamiliar with notation Serre uses, just let me know. I feel this should be and easy proof to follow, but I am having trouble in some spots. Definition: Let $X$ be a topological space, $Y$ its closed subspace and $\mathscr{F}$ a sheaf on $X$ . We say $\mathscr{F}$ is concentrated on $Y$ if we have $\mathscr{F}_x = 0$ for all $x \in X-Y$ . Question 1 [answered!]: Why does he say ""Y its closed subspace"" as though it is unique? Was this just a weird bit with translating from french? I am just interpreting it as $Y is a closed subspace"". Proposition 5. If a sheaf $\mathscr{F}$ is concentrated on $Y$ , the homomorphism $\rho_{Y}^{X}: \Gamma(X,\mathscr{F}) \to \Gamma(Y,\mathscr{F}(Y))$ is bijective (thus an isomorphism). Remarks: $\mathscr{F}(Y)$ is the sheaf induced on $Y$ by $\mathscr{F}$ . $\mathscr{F}_x$ is the stalk of $\mathscr{F}$ over the point $x$ . $\Gamma(U,\mathscr{F})$ is the group of sections over $U$ with respect to the sheaf $\mathscr{F}$ . Proof: [copied verbatim] If a section of $\mathscr{F}$ over $X$ is zero over $Y$ , it is zero everywhere else since $\mathscr{F}_{x} = 0$ if $x \notin Y$ , which shows that $\rho_{Y}^{X}$ is injective. Conversely, let $s$ be a section of $\mathscr{F}(Y)$ over $Y$ , and extend $s$ onto $X$ by putting $s(x) = 0$ for $x \notin Y$ ; the mapping $x \mapsto s(x)$ is clearly continuous on $X - Y$ . On the other hand, if $x \in Y$ there exists a section $s'$ of $\mathscr{F}$ over an open neighborhood $U$ of $x$ for which $s'(x) = s(x)$ . Since $s$ is continuous on $Y$ by assumption, there exists an open neighborhood $V$ of $x$ , contained in $U$ and such that $s'(y) = s(y)$ for all $y \in V \cap Y$ . But since $\mathscr{F}_y = 0$ for $y \notin Y$ , we also have that $s'(y) = s(y)$ for $y \in V-(V \cap Y)$ ; hence $s$ and $s'$ coincide on $V$ , which proves that $s$ is continuous in a neighborhood of $Y$ , so it is continuous everywhere. My interpretation / what I do understand: The injectivity part is fine, and on a big picture I understand what we're trying to do in surjectivity - we nominate the only possible candidate for a preimage (the extension of a section over $Y$ by 0). This candidate will easily satisfy the composition requirement with the local homeomorphism to be a section, so we need continuity. This is the interesting part of the result, because extensions of this sort are not always continuous for general topological settings, so this is a sheaf property. So we have this closed subspace $Y$ and some continuous map $s: Y \to \mathscr{F}(Y)$ and we form this new piece wise map (which I call) $s^{*}: X \to \mathscr{F}$ given by $$ s^{*}: x \mapsto \cases{ s(x), &x $\in$ Y\\ 0, &x $\notin$ Y }$$ I understand how Serre says that $s^{*}$ is continuous on $X-Y$ , which is because the trivial global section is always continuous, and this is just a restriction of that. I also understand why it is justified when he says that the section $s'$ exists for some open subset $U$ with the property $s(x) = s'(x)$ for the $x \in Y$ . It is after this that things are semi-familiar, but not entirely clear to me. Uncertainties: 1) First of all why does he start his surjectivity proof by saying
  ""conversely""? I have never thought of surjectivity as the converse of
  injectivity? 2) Picking up from where I left off with what I do understand, in
  Serres next line he asserts the existence of the open set $V$ contained in $U$ with the property that $s$ and $s'$ agree on $V \cap Y$ . It seems like he is invoking the fact that any two
  sections with the property that $s(x) = s'(x)$ must agree on some open
  neighborhood, but the $V$ he invokes seems different than this? Once
  the existence of this $V$ is justified I understand why it follows
  that $s$ and $s'$ agree on $V$ , but then I am again confused how to
  explain why it follows $s$ is continuous everywhere. It makes
  intuitive sense, because our problem spots are really just the
  boundary of $Y$ ? But for every single point of $Y$ , we have an open
  set $V_y$ so that $s$ is continuous on $V_y$ , then $s$ is also
  continuous on $Y^c$ so we can paste together all the $V_y$ 's and $Y^c$ to get one big continuous function? 3) Does the above result actually rely on $Y$ being closed? Does it
  not hold for $Y$ open? Aside from the result, are there reasons that
  we define the concentrated sheaf definition only for closed $Y$ ? I
  know things can get weird with the direct limits when single points
  are closed, are we avoiding stuff like that? Follow up: After some time thinking about this, the only part that is really an issue now is how Serre gets the set $V$ with the property that it is contained in $U$ and $s$ , $s'$ agree on $V \cap Y$ . Edit: I think I am close? We know that for any point $a \in \mathscr{F}$ there is an open neighborhood $W$ of $a$ such that $\pi|_{W} W \to \pi(W)$ is a homeomorphism with $\pi(W)$ open in $X$ . Take $ V = (s')^{-1}(W)$ , then $V \subseteq U$ and $V \subseteq \pi(W)$ . Since $(\pi|_{W})^{-1}$ is a bijection then for each $w \in \pi(W)$ there is exactly one element, say $(f,w)$ of $\mathscr{F}_W$ in $W$ . So if $v \in V = (s')^{-1}(W)$ then $s'(v) \in W$ and say $s'(v)=(g,v)$ but $(\pi|_{W})^{-1}(v) = (g,v)$ so $(\pi|_{W})^{-1}$ and $s'$ agree on $V$ . But then when I intersect with $Y$ , why would $s$ and $s'$ agree?","['coherent-sheaves', 'continuity', 'algebraic-geometry', 'sheaf-theory', 'general-topology']"
2941489,"Computing the UMVUE for Uniform$(0,\theta)$","I am having trouble understanding how to compute $\operatorname E[\bar{X}\mid X_{(n)}]$ related to the following premise. Compute the UMVUE using the Rao–Blackwell Theorem for the following. $X_1,X_2, \ldots ,X_n$ i.i.d. to $\operatorname{Uniform}(0,\theta)$ . I am able to derive that $\hat{\theta}_\text{MM}=2\bar{X}$ and $\hat{\theta}_\text{MLE}=X_{(n)}$ . Since $\hat{\theta}_\text{MM}$ is unbiased and $X_{(n)}$ is a sufficient estimator, I know that $$\operatorname E[2\bar{X}\mid X_{(n)}]$$ must give us the UMVUE. However, I have no idea how to proceed from here.
I appreciate your help.","['statistics', 'probability-theory']"
2941516,"what is meant by ""the integral is interpreted in the weak sense""?","What is meant by the integral is interpreted in the weak sense in following corollary: on page 261 of the book ""An introduction to frame and Riesz bases"", second edition,  by Ole Christenson. There is no an explanation in the book.","['lebesgue-integral', 'real-analysis', 'functional-analysis', 'partial-differential-equations', 'terminology']"
2941546,Why are set operations always showed with a Venn Diagram where both A and B are intersecting?,"So there is this question involving the pictorial representations of set operations (i.e. $A - B$ ). In each Venn Diagram, the A and B circles (sets) are always shown overlapping. For example, $A - B$ : $A - B$ ""> What if the circles $A$ and $B$ were separate? How would defining the set operation be showed? Thanks.","['elementary-set-theory', 'proof-writing', 'proof-verification']"
2941552,Show that $\frac{\sqrt{2}+\sqrt{2+\sqrt{3}}}{\sqrt{2}-\sqrt{2+\sqrt{3}}}=-3-2\sqrt{3}$,"Show that $$\frac{\sqrt{2}+\sqrt{2+\sqrt{3}}}{\sqrt{2}-\sqrt{2+\sqrt{3}}}=-3-2\sqrt{3}.$$ My attempt: I could find a way to develop the LHS by un-nesting the double radical, figuring out that $$\sqrt{2+\sqrt{3}}=\frac{\sqrt{6}+\sqrt{2}}{2}\ \ (1)$$ By substituting (1) in the LHS of the original expression, 
it is straightforward to show that it is equal to the RHS. But my problem is on how to show without the un-nesting, by another approach. I've used a standard approach of
multiplying both terms by $\sqrt{2}+\sqrt{2+\sqrt{3}}$ , leading to $$\frac{4+\sqrt{3}+2\sqrt{4+2\sqrt{3}}}{-\sqrt{3}}\Leftrightarrow \frac{(4+\sqrt{3}+2\sqrt{4+2\sqrt{3}})\sqrt{3}}{-3}.$$ But I was not able to show that this last expression is equal to RHS by this approach. Hints and answers not using my first un-nesting approach (if possible) will be appreciated. Sorry if this is a duplicate.","['algebra-precalculus', 'radicals']"
2941596,Finding eigenvalue based on vector space and linear operator?,"So given that $L$ is a linear operator from a vector space $V$ to itself, with $V=\mathbb R_2[t]$ and $Lf = f'' - f$ I need to show that $\lambda = -1$ is the only eigenvalue. I know how to do this with standard matrices but it has been a couple of years since I've taken differential equations so I'm very rusty and unsure of how to convert this information to a matrix I can use the standard $det(A - \lambda I)$ equation on. Any tips?","['linear-algebra', 'ordinary-differential-equations']"
2941605,Finding the eigenvalues of a linear transformation which takes inputs from the set of all $n\times n$ matrices.,"We define $T(X) = AX - XB$ for fixed $A,B$ . We allow $X$ to be any matrix in $M_n(F)$ . Write down all the eigenvalues of $T$ in terms of the eigenvalues of $A$ and $B$ . I think I saw another question here which said that for $T(X) = AX - XA$ , if $u$ is an eigenvector for $A$ and $v$ an eigenvector for $A^T$ , then $uv^T$ is an eigenvector for $T$ , but I don't know how to prove this nor do I know if it generalizes if we replace one instance of $A$ with $B$ .","['matrices', 'linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
2941635,"Is the sheafication of a ""presheaf of $\mathcal{O}_X$-modules"" an $\mathcal{O}_X$-module?","Let $(X,\mathcal{O}_X$ ) be a ringed space. A presheaf of $\mathcal{O}_X$ -modules is a presheaf $\mathcal{F}$ of abelian groups on $X$ such that $\mathcal{F}(U)$ is an $\mathcal{O}_X(U)$ -module for each open $U\subseteq X$ , and each restriction map of $\mathcal{F}$ is linear with respect to the corresponding restriction map of $\mathcal{O}_X$ . More precisely, the latter condition says: if $V\subseteq U\subseteq X$ are open, then $\alpha(rm)=\beta(r)\alpha(m)$ for all $r\in\mathcal{O}_X(U)$ and $m\in\mathcal{F}(U)$ , where $\alpha:\mathcal{F}(U)\to\mathcal{F}(V)$ and $\beta:\mathcal{O}_X(U)\to\mathcal{O}_X(V)$ are the restriction maps. Is the sheafication of a presheaf of $\mathcal{O}_X$ -modules necessarily an $\mathcal{O}_X$ -module?","['algebraic-geometry', 'sheaf-theory', 'modules']"
2941669,Probability of 2 Dice Throws Equal to Sum,"I'm aware this is a very simple question, I must be missing something obvious. Given that the numbers coming out of two independent dice throws are different, find the probability that the sum of the numbers is 4. Apparently the correct answer is 1/15 . Though my answer is 1/18 : So you can roll either a $(1,3)$ or a $(3,1)$ . So then I do $\left(\frac{1}{6}\cdot\frac{1}{6}\right)$ + $\left(\frac{1}{6}\cdot\frac{1}{6}\right)$ = $\frac{1}{18}$","['dice', 'probability']"
2941677,An happy coincidence for the approximate solution of $x \tan(x)=k $?,"Thinking more about this question where I proposed some approximate solution of the first positive root of equation $\color{blue}{x\tan(x)=k}$ for any $k >0$ , I notice that, for the $[3,4]$ Padé approximant built at $x=0$ $$\tan(x)=\frac{5 x \left(21-2 x^2\right)}{105-45 x^2+x^4} $$ the denominator  cancels at $$x=\pm\sqrt{\frac{1}{2} \left(45-\sqrt{1605}\right)}\approx 1.57123\qquad x=\pm\sqrt{\frac{1}{2} \left(45+\sqrt{1605}\right)}\approx 6.52160$$ that is to say close to $\frac \pi 2$ (which seems ""normal"") and ""rather close"" to $2\pi$ (more surprising). This is the only case for all explored $[2n-1,2n]$ Padé approximants. This gave me the idea of working the series expansion $$(2\pi-x)(2\pi+x)\left(\frac{\pi }{2}-x\right) \left(x+\frac{\pi }{2}\right) x\tan (x)=\pi ^4 x^2+\left(\frac{\pi ^4}{3}-\frac{17 \pi ^2}{4}\right) x^4+O\left(x^6\right)\tag 1$$ reducing the original problem to $$\frac{\pi^2 x^2\left(\left(\frac{\pi ^2}{3}-\frac{17}{4}\right) x^2 +\pi^2\right) }{x^4-\frac{17 \pi ^2 }{4}x^2+\pi ^4 }=k$$ which is just a quadratic equation in $x^2$ the retained solution of which being $$x= \pi\sqrt{\frac{51 k+12 \pi
   ^2-\sqrt{2025 k^2+\pi ^2 \left(192 \pi ^2-1224\right) k+144 \pi ^4}}{2 \left(12 k+\pi ^2 \left(51-4 \pi ^2\right)\right)}}$$ which seems to lead to quite good approximations (in the table below $k=10^n$ ) $$\left(
\begin{array}{ccc}
  n & \text{approximation} & \text{solution} \\
 -3 & 0.03161750711 &  0.03161750711 \\
 -2 & 0.09983363885 &  0.09983363855 \\
 -1 & 0.31105293142 &  0.31105284820 \\
  0 & 0.86034131667 &  0.86033358902 \\
  1 & 1.42887264708 &  1.42887001121 \\
  2 & 1.55524418982 &  1.55524512931 \\
  3 & 1.56922698357 &  1.56922710099 \\
  4 & 1.57063925088 &  1.57063926287
\end{array}
\right)$$ For large values of $k$ , the asymptotics is $$x=\frac{\pi }{2}-\frac{ \pi ^3(4 \pi ^2-3)}{720\,k}+\frac{\pi ^5 \left(4 \pi ^2-3\right)
   \left(436 \pi ^2-3207\right)}{7776000\,
   k^2}+O\left(\frac{1}{k^3}\right)$$ where we can notice that each coefficient is again very close to $\pm\frac \pi 2$ Is there a way to justify the appearance of this value close to $\pm 2\pi$ or is it just an happy coincidence ? By the way, it is possible to improve the coefficients appearing in $(1)$ minimizing $$\Phi(a,b)=\int_0^{\frac \pi 2}\left((2\pi-x)(2\pi+x)\left(\frac{\pi }{2}-x\right) \left(x+\frac{\pi }{2}\right) x\tan (x)-(ax^2+bx^4) \right)^2\,dx$$ and get analytical formulae for $a,b$ in terms of $\zeta (p)$ $(p=3,5,7,9)$ and powers of $\pi$ . Compared to the initial values, the value of $\Phi(a,b)$ is reduced by a factor of $2.22$ .  The expressions for the optimal $a,b$ are not given here but they are available to any one who would like to get them. Edit About he ""coincidence"", consider the $[4,2]$ Padé approximant $$\left(\frac{\pi }{2}-x\right) \left(x+\frac{\pi }{2}\right) x\tan (x)=\frac{\frac{\pi ^2}{4}x^2+\frac{\left(720-60 \pi ^2-\pi ^4\right) }{60 \left(\pi
   ^2-12\right)}x^4 } {1-\frac{2 \left(\pi ^2-10\right) }{5 \left(\pi ^2-12\right)}x^2 }$$ and the roots of the denominator are $\pm\sqrt{\frac{60-5 \pi ^2}{20-2 \pi ^2}}\approx \pm 6.39100$ .","['trigonometry', 'approximation', 'transcendental-equations']"
2941697,"Cardinality, bijections, infinite sets","We know that if there is a bijection from finite set $A$ to finite set $B$ , we can remove one element from both sets and still be able to form a bijection.
Similarly, removing sets of equal cardinalities from finite sets still allows us to form bijections. But this result does not hold for infinite sets. Let the removed infinite sets be $A'$ and $B'$ , such that they are both proper subsets of $A$ and $B$ respectively.
Let $A=B=B'=\mathbb{N}$ .
Let $A'$ be the set of odd numbers.
Then, $A-A'$ is the set of even numbers. The cardinality of $(A-A')$ is $\mathbb{N}$ . $B-B'= \emptyset$ so the cardinality of $(A-A')$ is not equal to $(B-B')$ . Hence, I have proved that the finite set rule I described above does not hold for infinite sets. Is this correct?",['elementary-set-theory']
2941741,HyperGeometric distribution : Inutition for symmetry,"Wikipedia page on HyperGeometric distribution says Swapping the roles of green and drawn marbles: $$ f ( k ; N , K , n ) = f ( k ; N , n , K ) $$ where in LHS, N = Total number of marbles n = number of draws K = number of green marbles(others are red) k = number of green marbles in n draws I understand how the equality holds mathematically, but I can't understand why this equality holds intuitively.","['statistical-inference', 'statistics', 'hypergeometric-function']"
2941764,The operator $T+i Id$,"I have the operator $$T:\mathcal{H}\rightarrow\mathcal{H}$$ the operator $T$ is linear, symmetric and compact, $\mathcal{H}$ is a Hilbert space my problem is Prove that ( $\,T+i\,$ Id) is $\,\bf{surjective}$ . ( $i$ is a imaginary number and Id is the identity operator) I proved that $\,\,\,T+i\bf{Id}$ is injective occupying the above, is there any way to show that $\,\,\,T+i\bf{Id}\,$ is $\,\bf{surjective}$ ? So you can give me some hint, thanks!","['hilbert-spaces', 'compact-operators', 'functional-analysis']"
2941938,Cauchy Hadamard formula and starting index of power series,The radius of convergence $r$ can be calculated for every power series $\sum_{k=0}^\infty a_k z^k$ with $a_k\in \mathbb C$ and $z\in \mathbb C$ by using the Cauchy Hadamard formula: $r = \limsup_{k\to\infty} |\frac{1}{a_k}|^{1/k}$ . In every textbook I find the power series starting from $k=0$ . Can the Cauchy Hadamard formula also be used for a power series $\sum_{k=1}^\infty a_k z^k$ directly (ie. without changing the index of the power series before calculating $r$ )?,['analysis']
2941961,What is the greatest possible number of nonzero terms in a the determinant of a matrix with exactly $N$ zeroes?,"Suppose we have an $n \times n$ matrix and we know there are exactly $N$ zero entries. The determinant is the sum of $n!$ terms, each formed by selecting exactly one entry from each row and column and multiplying them. If a given term comes from selecting one or more zeroes then that term becomes zero. This raises the question of how many of the terms can be nonzero. Intuitively I imagine the maximum numbers are achieved if we take a matrix of all $1$ s and start putting in zeroes, starting with entries $(1,2), (1,3), \ldots, (1,n)$ so the only nonzero entry in that row is at $(1,1)$ , and then moving to the next row and putting zeroes in $(2,1), (2,3), \ldots, (2,n)$ so the only nonzero entry in that row is at $(2,2)$ , and so on until we're filling in zeroes on the last row at $(n,1), (n,2), \ldots, (n,n-1)$ . At this stage we have the identity matrix and there is exactly one nonzero term. I imagine this has already been proved somewhere but cannot find a good reference. Could someone please provide a proof, or better yet, a book where this is proved as part of some wider theory? Ideally by something more elegant than induction?","['matrices', 'determinant', 'reference-request']"
2941967,Log likelihood with exponential function,"I'm trying to find the maximum likelihood of this function.
I have samples in this question as follows: (0.77, 0.82, 0.94, 0.92, 0.98) $$f_Y(y;\theta)=\theta y^{\theta-1} ;, \quad 0 \le y \le 1 ;, 0 \lt \theta$$ $$L(\theta) = \prod\limits_{i=1}^{n} \theta y_i^{\theta-1} \\
= \theta^n\prod\limits_{i=1}^{n}y_i^{\theta-1}$$ From here i'm stuck. I'm not sure if I should take the log now or there is one more move before I take the log. The answer is 8.00. if I put the values it would probably make it easier for me, but it appears to me that I do not know a technique or identity from here to move on.
Any help? Continuing on: $$\text{Let }\; T = \frac{\partial}{\partial \theta}\bigg(n\ln \theta + (\theta -1)\sum_{i=1}^n \ln y_i\bigg) = \frac{n}{\theta} + \sum_\limits{i=1}^{n}ln(y_i) \\
\text{Let } \; T = 0 = \frac{n}{\theta} -0.261 - 0.198 - 0.083 - 0.061 - 0.02 \\
\text{implies } \hat{\theta} = \frac{5}{0.623} = 8$$","['calculus', 'statistics', 'maximum-likelihood']"
2941977,Convert a vector of distances to a normalized vector of similarities,"I'm struggling to find a way to solve this problem. I have derived a $m \times n$ matrix containing in each row the Mahalanobis distance from a certain centroid. So at the end I have $m$ rows each expressing the distance of that variable from $n$ features. Now I want to obtain another matrix such that each row of the new matrix is the measure of similarity ( $\in [0,1]$ ) between the $i$ -th variable and the $j$ -th feature. Also, I want the rows of this matrix to be normalized to 1, since I want to plot each of this variable as a convex combination of a the vertices of a regular polytope. For a very naive example (the numbers are completely off my head): $d_i = [13 \,\, 60 \,\, 4]$ $\rightarrow$ $s_i = [0.15 \,\, 0.05 \,\, 0.8]$ In such a way that I can express $x_i$ and $y_i$ as $\sum_{j=1}^ns_{ij}\,p_{x,y}$ (where $p$ is the $x$ or $y$ coordinate of a vertex). Initially I tried $s_i = \dfrac{\dfrac{1}{d_i}}{\sum_{i=1}^n\dfrac{1}{d_i}} \, \forall i$ , but then I discovered that using the reciprocal I'm loosing some propriety of the distribution. With some research I also found the RBF kernel, but after normalization I just obtain a list of values which are basically identical. Do you have any clue on how I can achieve this? Thanks","['statistics', 'convex-geometry', 'mahalanobis-distance', 'clustering', 'machine-learning']"
2942003,Fourier transform and fourth root,"Given a well-behaved convex function $f(t):\mathbb{R}\to \mathbb{R}$ , its Fourier transform (FT) $\hat{f}(\omega)=\mathcal{F}[f(t)](\omega)$ is positive (and decreasing) proof here . It follows that the fourth square root of the FT $\sqrt[4]{\hat{f}(\omega)}$ is invertible. I was wondering if it is possible to determine the function $g(t)=\mathcal{F}^{-1}\Big[\sqrt[4]{\hat{f}(\omega)}\Big](t)$ directly from $f(t)$ , without making use of the Fourier transform. In other words, knowing $f(t)$ , I would like to determine the function $g(t)$ such that $$\mathcal{F}[g(t)](\omega)=\sqrt[4]{\hat{f}(\omega)}.$$ I had a look at the convolution theorem and at the fractional Fourier transform but I do not see a straightforward application of these tools to solve this problem.","['fourier-analysis', 'fourier-transform', 'convolution', 'functional-analysis', 'fractional-iteration']"
2942011,Correction factor for calculating standard error when drawing sample without replacement - derivation,When drawing a sample of size n from population of size N This relationship holds $$ SE\space when\space  drawing\space  sample\space  without\space  replacement\space  =\space  correction\space  factor\space  *\space  SE\space  when\space  drawing\space  with\space  replacement$$ where $$ correction\space factor = \sqrt{\frac{N-n}{N-1}} $$ N = size of population n = size of sample I would like to know how this relationship was derived.,"['standard-error', 'statistical-inference', 'statistics', 'descriptive-statistics']"
2942031,GCD in arbitrary domain,Is there a domain where computing GCD of two elements is not trivial (i.e. Euclid's algorithm will not work)? AFAIK we can always use the Euclid's algorithm in a Euclidean Domain.,"['euclidean-algorithm', 'gcd-and-lcm', 'euclidean-domain', 'abstract-algebra', 'commutative-algebra']"
2942080,Multiplication that preserves the digits,"I realized that no matter how many times you multiply 25 by 5, the last two digits will always be 25: $125, 625, 3125, ...$ Similarly, no matter how many times you multiply 20 by 6, the last two digits will always be 20: $120, 720, 4320, ...$ The same is true for 2, 4, 5, 10, and 50. So for any divisor $x$ of 100, you can multiply $x$ by a certain number (namely $\frac{100}{x} + 1$ ) any number of times, and the result will still have $x$ as the last two digits. I assume we can generalize to the following: Conjecture. For any $n \geq 1$ , take a number $x$ that divides $10^n$ . Then for all $m \geq 1$ , the last $n$ digits of $x \left( \frac{10^n}{x} + 1 \right)^m$ will be $x$ . Questions: Is it possible to prove this? Does this property hold for any other numbers, besides just divisors of $10^n$ (namely, you can multiply the number by something else any number of times, and the last digits will always be the original number)?",['number-theory']
