question_id,title,body,tags
4370653,General expressions for $\mathcal{L}(n)=\int_{0}^{\infty}\operatorname{Ci}(x)^n\text{d}x$,"Define $$\operatorname{Ci}(x)=-\int_{x}^{
\infty} \frac{\cos(y)}{y}\text{d}y.$$ It is easy to show $$
\mathcal{L}(1)=\int_{0}^{\infty}\operatorname{Ci}(x)\text{d}x=0
$$ and $$\mathcal{L}(2)=\int_{0}^{\infty}\operatorname{Ci}(x)^2\text{d}x
=\frac{\pi}{2}.$$ $\mathcal{L}(3),\mathcal{L}(4)$ is a little bit non-trivial. We have two claims(take a look here to find more details): $$\begin{aligned}
&\mathcal{L}(3)=-\frac{3\pi}{2}\ln2 \\
&\mathcal{L}(4)=3\pi\operatorname{Li}_2
\left ( \frac{2}{3}  \right )+\frac{3\pi}{2}\ln^23
\end{aligned}$$ Where $\operatorname{Li}$ are polylogarithms , they are defined by $\displaystyle{\operatorname{Li}_n(z)
=\sum_{k=1}^{\infty} \frac{z^k}{k^n}}$ for $|z|<1$ . $\mathcal{L}(5)$ is much more non-trivial. We have $$
\mathcal{L}(5)=\int_{0}^{\infty}\operatorname{Ci}(x)^5\text{d}x
=-\frac{15\pi^3}{8}\ln(2)-\frac{15\pi}{2}\ln(2)^3
-\frac{45\pi}{4}\operatorname{Li}_2\left ( \frac{1}{4}  \right )\ln(2)
-\frac{45\pi}{4}\operatorname{Li}_3\left ( \frac{1}{4}  \right ) 
-\frac{15\pi}{16}\zeta(3).
$$ Where $\zeta(n)=\operatorname{Li}_n(1)$ for $\Re(n)>1$ . My question: How can we find alternate generalizations? I believe that $\mathcal{L}(6)$ can be expressed by using ordinary polylogarithms( $\mathcal{L}(7)$ seems impossible). We can also find the closed-forms of following integrals: $$\int_{0}^{\infty}\operatorname{Ci}(x)^4\cos(x)\text{d}x,\int_{0}^{\infty}\operatorname{Ci}(x)^2\frac{\operatorname{Si}(2x)}{x} \cos(x)\text{d}x$$ where $\displaystyle{\operatorname{Si}(x)=\int_{0}^{x} \frac{\sin(t)}{t}\text{d}t}.$ Update 1: Define $\operatorname{si}(x)+\operatorname{Si}(x)=\frac{\pi}{2}$ . Here are some results: $$\begin{aligned}
&\int_{0}^{\infty}\operatorname{si}(x)\text{d}x=1\\
&\int_{0}^{\infty}\operatorname{si}(x)^2\text{d}x=\frac{\pi}{2}\\
&\int_{0}^{\infty}\operatorname{si}(x)^3\text{d}x=\frac{\pi^2}{4} -\frac{3}{2}\ln^22-\frac{3}{4} 
\operatorname{Li}_2\left ( \frac{1}{4}  \right )\\
&\int_{0}^{\infty}\operatorname{si}(x)^4\text{d}x=
\frac{\pi^3}{4} -3\pi\ln^22-\frac{3\pi}{2} 
\operatorname{Li}_2\left ( \frac{1}{4}  \right )
\end{aligned}$$ Update 2: A useful fourier transform $$\int_{0}^{\infty}\operatorname{Ci}(x)^3\cos(a x)\text{d}x
=\begin{cases}
\color{Red}{\frac{\pi  \text{Li}_2\left(\frac{1-a}{3}\right)}{4 a}}+\frac{\pi  \text{Li}_2\left(\frac{a-1}{a-2}\right)}{2 a}+\frac{\pi  \text{Li}_2\left(\frac{a+1}{3 (a-1)}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{a-1}{a+1}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a+1}{a+2}\right)}{2 a}-\frac{\pi  \text{Li}_2\left(\frac{a+1}{3}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a+1}{a-1}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a-1}{3 (a+1)}\right)}{4 a}+\frac{\pi  \log ^2(2-a)}{4 a}-\frac{\pi  \log ^2(a+2)}{4 a}+\frac{\pi  \log (3) \log (a-1)}{4 a}+\frac{\pi  \log (3) \log \left(\frac{a+2}{a+1}\right)}{4 a}-\frac{\pi  \log (3) \log (a-2)}{4 a}-\frac{\pi  \log (3) \tanh ^{-1}\left(\frac{a}{2}\right)}{2 a} &  (0\le a\le1),\\
\color{Red}{\frac{\pi  \text{Li}_2\left(\frac{a^2}{a^2-1}\right)}{4 a}}+\frac{\pi  \log \left(-\frac{a}{a+1}\right) \log \left(\frac{1}{1-a^2}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(-\frac{a}{2}\right)}{2 a}+\frac{\pi  \text{Li}_2(1-a)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{a+2}{2 (1-a)}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(-\frac{3}{a-1}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(-\frac{1}{a}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{a+2}{2 (a+1)}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{a (a+2)}{(a+1)^2}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(-\frac{1}{2}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{1}{1-a}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a}{a-1}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(-\frac{1}{a-1}\right)}{4 a}-\frac{\pi  \text{Li}_2(-a)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{1}{a+1}\right)}{4 a}-\frac{3 \pi  \text{Li}_2\left(\frac{a}{a+1}\right)}{4 a}-\frac{7 \pi ^3}{24 a}+\frac{3 \pi  \log ^2(2)}{8 a}+\frac{\pi  \log ^2(a)}{8 a}-\frac{\pi  \log ^2(a+1)}{2 a}+\frac{\pi  \log (2) \log (a-1)}{4 a}+\frac{\pi  \log (2) \log (a+1)}{4 a}-\frac{\pi  \log (2) \log (a)}{2 a}-\frac{\pi  \log (2) \log (a+2)}{2 a}+\frac{\pi  \log \left(\frac{a+2}{a+1}\right) \log \left(\frac{1}{(a+1)^2}\right)}{4 a}+\frac{\pi  \log \left(-\frac{1}{a+1}\right) \log \left(\frac{a (a+2)}{(a+1)^2}\right)}{4 a}+\frac{\pi  \log (3) \log (a+2)}{4 a}+\frac{\pi  \log (a) \log (a+2)}{2 a}-\frac{\pi  \log (a) \log (a+1)}{2 a}-\frac{i \pi ^2 \log \left(\frac{1}{1-a}\right)}{4 a}-\frac{\pi  \log (3) \log (a-1)}{4 a}-\frac{\pi  \log \left(-\frac{1}{a+1}\right) \log \left(\frac{a+2}{a+1}\right)}{4 a}-\frac{\pi  \log \left(-\frac{1}{a+1}\right) \log \left(-\frac{a}{a+1}\right)}{4 a}-\frac{\pi  \log (a-1) \log (a+2)}{4 a}-\frac{\pi  \log (a+1) \log (a+2)}{4 a}  & (1\le a\le3),  \\
  \color{Red}{-\frac{\pi  \text{Li}_2\left(\frac{a^2}{a^2-1}\right)}{4 a}}-\frac{\pi  \log \left(-\frac{a}{a+1}\right) \log \left(\frac{1}{1-a^2}\right)}{4 a}+\frac{\pi  \text{Li}_2(-2)}{4 a}+\frac{\pi  \text{Li}_2(2)}{4 a}+\frac{\pi  \text{Li}_2\left(-\frac{1}{2}\right)}{2 a}+\frac{\pi  \text{Li}_2\left(\frac{1}{1-a}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{1}{a-1}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{a}{a-1}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(-\frac{1}{a-1}\right)}{4 a}+\frac{\pi  \text{Li}_2\left(\frac{1}{a+1}\right)}{2 a}+\frac{\pi  \text{Li}_2\left(\frac{a}{a+1}\right)}{2 a}-\frac{\pi  \text{Li}_2\left(-\frac{a}{2}\right)}{2 a}-\frac{\pi  \text{Li}_2(1-a)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a+2}{2 (1-a)}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a-2}{a-1}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(-\frac{3}{a-1}\right)}{4 a}-\frac{\pi  \text{Li}_2(a-1)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a+2}{2 (a+1)}\right)}{4 a}-\frac{\pi  \text{Li}_2\left(\frac{a (a+2)}{(a+1)^2}\right)}{4 a}+\frac{\pi ^3}{3 a}-\frac{\pi  \log ^2(2)}{4 a}+\frac{\pi  \log ^2(a+1)}{2 a}+\frac{i \pi ^2 \log (2)}{4 a}+\frac{\pi  \log (2) \log (a)}{2 a}+\frac{\pi  \log (2) \log (a+2)}{2 a}-\frac{\pi  \log (2) \log (a-1)}{4 a}-\frac{\pi  \log (2) \log (a+1)}{4 a}+\frac{i \pi ^2 \log \left(\frac{1}{1-a}\right)}{4 a}+\frac{\pi  \log (3) \log (a-2)}{4 a}+\frac{\pi  \log (a-2) \log (a-1)}{4 a}+\frac{\pi  \log \left(\frac{a+2}{a+1}\right) \log \left(-\frac{1}{a+1}\right)}{4 a}+\frac{\pi  \log \left(-\frac{1}{a+1}\right) \log \left(-\frac{a}{a+1}\right)}{4 a}+\frac{\pi  \log (a-1) \log (a+2)}{4 a}+\frac{\pi  \log (a+1) \log (a+2)}{4 a}-\frac{\pi  \log (a) \log (a+2)}{2 a}-\frac{\pi  \log (a-2) \log \left(\frac{1}{a-1}\right)}{4 a}-\frac{\pi  \log (3) \log \left(\frac{a+2}{a-1}\right)}{4 a}-\frac{\pi  \log (2-a) \log (a-1)}{4 a}-\frac{\pi  \log (a) \log \left(\frac{1}{a+1}\right)}{4 a}-\frac{\pi  \log (3) \log \left(\frac{a-2}{a+1}\right)}{4 a}-\frac{\pi  \log \left(\frac{1}{(a+1)^2}\right) \log \left(\frac{a+2}{a+1}\right)}{4 a}-\frac{\pi  \log (3) \log (a+1)}{4 a}-\frac{\pi  \log \left(-\frac{1}{a+1}\right) \log \left(\frac{a (a+2)}{(a+1)^2}\right)}{4 a}& (a\ge3).
\end{cases}$$ Update 3: Common fourier transforms $$\begin{aligned}
&1.\int_{0}^{\infty}\operatorname{Ci}(x)\cos(\omega x)\text{d}x=
\begin{cases}
  0 &(0\le\omega<1), \\
\displaystyle{ -\frac{\pi}{4}  }&(\omega=1), \\
\displaystyle{ -\frac{\pi}{2\omega}  }&(\omega>1).
\end{cases}\\
&2.\int_{0}^{\infty}\operatorname{Ci}(x)\sin(\omega x)\text{d}x=
\begin{cases}
 \displaystyle{-\frac{\ln(1-\omega^2)}{2\omega}}  &(0\le\omega<1), \\
\displaystyle{ +\infty  }&(\omega=1), \\
\displaystyle{-\frac{\ln(\omega^2-1)}{2\omega} }&(\omega>1).
\end{cases}\\
&3.\int_{0}^{\infty}\operatorname{Ci}(x)^2\cos(\omega x)\text{d}x=
\begin{cases}
\displaystyle{ \frac{\pi\ln(1+\omega)}{2\omega} }&(0\le\omega\le2), \\
\displaystyle{ \frac{\pi\ln(\omega^2-1)}{2\omega} }&(\omega\ge2).
\end{cases}\\
&4.\int_{0}^{\infty}\operatorname{si}(x)\sin(\omega x)\text{d}x=
\begin{cases}
  0 &(0\le\omega<1), \\
\displaystyle{ \frac{\pi}{4}  }&(\omega=1), \\
\displaystyle{ \frac{\pi}{2\omega}  }&(\omega>1).
\end{cases}\\
&5.\int_{0}^{\infty}\operatorname{si}(x)\cos(\omega x)\text{d}x=
\begin{cases}
 \displaystyle{\frac{1}{2\omega}\ln\left ( \frac{1+\omega}{1-\omega}  \right ) }  &(0\le\omega<1), \\
\displaystyle{ +\infty  }&(\omega=1), \\
\displaystyle{\frac{1}{2\omega}\ln\left ( \frac{\omega+1}{\omega-1}  \right ) }&(\omega>1).
\end{cases}\\
&6.\int_{0}^{\infty}\operatorname{si}(x)^2\cos(\omega x)\text{d}x=
\begin{cases}
\displaystyle{ \frac{\pi\ln(1+\omega)}{2\omega} }&(0\le\omega\le2), \\
\displaystyle{ \frac{\pi}{2\omega}\ln\left ( \frac{\omega+1}{\omega-1}  \right ) }&(\omega\ge2).
\end{cases}\\
&7.\int_{0}^{\infty}\frac{\operatorname{Si}(x)}{x}\cos(\omega x)\text{d}x=
\begin{cases}
 \displaystyle{-\frac{\pi}{2}\ln(\omega)}  &(0<\omega\le1), \\
\displaystyle{0 }&(\omega\ge1).
\end{cases}\\
\end{aligned}$$ Definition: Functions $\operatorname{Si}_n(x)$ are defined by $$\operatorname{Si}_0(x)=\sin(x),\operatorname{Si}_n(x)
=\int_{0}^{x} \frac{\operatorname{Si}_{n-1}(t)}{t}\text{d}t.$$ And we are able to get $$
\int_{0}^{\infty}\frac{\operatorname{Si}_2(x)\operatorname{si}(x)^2}{x}
\text{d} x=\frac{7\pi^5}{1440}.
$$","['integration', 'real-analysis', 'calculus', 'polylogarithm', 'trigonometric-integrals']"
4370667,Isometry groups of round three manifolds,"I'm interested in isometry groups of round 3 manifolds, especially Riemannian homogeneous ones. Here are my thoughts so far: The round three sphere $ S^3 $ has isometry group $ O_4 $ . Round projective space is the sphere mod the antipodal isometry (which is a rotation for odd spheres) $$
\mathbb{R}P^3 \cong S^3/-I
$$ Using the normalizer formula for the isometry group of a quotient of a simply connected manifold we have $$
\text{Iso}(\mathbb{R}P^3)\cong N_{\text{Iso}(S^3)}(-I)/-I=O_4/-I 
$$ which further simplifies as $$
 \text{Iso}(\mathbb{R}P^3) \cong (O_1 \ltimes SO_4)/-I \cong O_1 \ltimes (SO_4/-I) \cong O_1 \ltimes (SO_3 \times SO_3)
$$ For a homogeneous lens space $ L_{p,1} \cong SU_2/C_p $ where $ C_p $ is $ p $ element cyclic subgroup the normalizer of $ C_p $ in $ SO_3 $ (or $ SU_2 $ ) is $ O_2 $ and $ O_2/C_p  \cong O_2 $ . So I think the isometry group should be something like $$
O_2 \times O_3
$$ Another reason I'm guessing $ \text{Iso}(L_{p,1}) \cong O_3 \times O_2 $ is that from the Hopf fibration $$
S^1 \to S^3 \to S^2
$$ we can mod out by $ C_p $ $$
S^1/C_p \to S^3/C_p \to S^2
$$ So we have $$
S^1 \to L_{p,1} \to S^2
$$ and then I am just taking the the direct product of the isometry group of the fiber and of the base. (I know you can't generally do that for nontrivial fiber bundles for example no metric on the Klein bottle has isometries $ O_2 \times O_2 $ but just noting here that it sort of agrees with my earlier guess from the normalizer perspective). The normalizers of other groups are $ D_{2n} \trianglelefteq D_{4n} $ for $ n \geq 3 $ , $ D_{4} \cong C_2 \times C_2 \trianglelefteq S_4 $ , $ A_4 \trianglelefteq S_4 $ , $ A_5 \trianglelefteq A_5 $ . The point is that all other discrete subgroups of $ SO_3 $ (and $ SU_2 $ ) have discrete normalizer with finite index. So for the homogeneous prism manifolds and three exceptional manifolds $ SU_2/ \Gamma $ I think roughly the normalizer of $ \Gamma $ is $ \Gamma \times SU_2 $ so the isometry group is roughly $ (SU_2 \times \Gamma) /\Gamma $ or rather $$
\text{Iso}(SU_2/\Gamma) \cong SU_2 \rtimes O_1 
$$ to include orientation reversing isometries For round three manifolds that are not homogeneous I think they probably all have isometry group $ O_2 $ (just a guess)","['riemannian-geometry', 'smooth-manifolds', 'geometric-topology', 'lie-groups', 'differential-geometry']"
4370700,Solve the complex number equation $|z|-\bar{z}=i$,"Solve the complex number equation $|z|-\bar{z}=i$ . The following was my thought process: $$|z|=i+\bar{z}$$ Given that $Im(|z|)=0$ , $Im(\bar{z})=-i$ . Hence, $\bar{z}=a-i$ and $z=a+i$ . $$|z|=i+(a-i)$$ $$|z|=a$$ But since $z=a+i$ , $|z|=\sqrt{a^2+1}$ and hence I've reached a contradiction, as $\sqrt{a^2+1}\neq a$ . Hence, there is no solution for $|z|-\bar{z}=i$ , for $z\in\mathbb{C}$ .","['algebra-precalculus', 'solution-verification', 'complex-numbers']"
4370758,Is the following universal property of holomorphic functions true?,"Suppose that we are given a smooth $f\in C^\infty(\mathbb{\mathbb{R}^2},\mathbb{C})$ and define $\iota$ to be the smooth embedding $$
\begin{aligned}
\iota :\mathbb{R}^2&\to\mathbb{C}^2\\
(x,y)&\mapsto (x+iy,x-iy)=((x,y),(x,-y)).
\end{aligned}
$$ Is it true that there exists a unique holomorphic $\hat{f}\in\mathscr{O}({\mathbb{C}^2},\mathbb{C})$ such that $f=\hat{f}\circ \iota$ ? I suspect this universal property to be true, but my background on holomorphic functions in several variables is a bit weak and I could be wrong since I never saw it mentioned anywhere. Any hints or full answers are much appreciated. This question has occurred to me while studying complex manifolds. The aim is to make sense of the formal expression $f(z,\overline{z})$ used in that context for a smooth $f$ .","['complex-analysis', 'complex-geometry', 'several-complex-variables']"
4370762,"Prove for any function: $f:\:A\rightarrow B$ and any sets $C,D\subseteq A$, $f\left(C\right)$ ∖ $f\left(D\right) \subseteq f(C\backslash D) $","My thinking: Let $x\in f\left(C\right)∖f\left(D\right)$ = $x\in f\left(C\right)$ and $x\notin f\left(D\right)$ If $x\in f\left(C\right)$ , $\exists \:x_1\in C$ such that $f\left(x_1\right)=x$ If $x\notin f\left(D\right)$ , $∄ \:x_2\in D$ such that $ f\left(x_2\right)=x$ I don't know where to go from here, can someone please provide a hint?","['elementary-set-theory', 'proof-writing']"
4370766,"Simplify $\sum_{k = 0}^n\sum_{k_1+\ldots+k_{m}=n-k} \binom{nm}{k_1,\ldots,k_m,n-k_1,\ldots,n-k_m}$","Let $n$ and $m$ be positive integers. I want to find a formula for the following expression: $$\sum_{k = 0}^n\quad \sum_{k_1+...+k_m=n-k} \quad \binom{n-k}{k_1,\ldots,k_m}\binom{nm}{n-k_1,\ldots,n-k_m,n-k}$$ $$= \sum_{k = 0}^n \quad \sum_{k_1+...+k_{m}=n-k} \quad \binom{nm}{k_1,\ldots,k_m,n-k_1,\ldots,n-k_m}$$ I am wondering if there are any special identities I could use to simplify this expression.","['algebra-precalculus', 'binomial-coefficients', 'combinatorics', 'multinomial-coefficients']"
4370781,Show the existence of a sorting function,"Let $(X,\leq)$ be a totally ordered set. A sort for $f\in X^n$ is an element $g\in X^n$ satisfying (i) $g$ is nondecreasing. (ii) $ g=f\circ \sigma$ for some permutation $\sigma:\{1,\dots,n\}\to \{1,\dots,n\}$ . A sorting function for $X^n$ is a function $\Phi:X^n\to X^n$ such that $\Phi(f)$ is a sort for $f$ , for each $f\in X^n$ . Am asked to show that there exists a sorting function for $X^n$ . My attempt: By induction on $n$ . If $n=1$ this is trivial. Suppose there exists a sorting function $\Phi:X^n\to X^n$ for some $n\geq 1$ . Define the functions $\Gamma,\Delta:X^{n+1}\to X^{n+1}$ by $$\Gamma(f)=\bigg(\Phi[f|_{\{1,\dots,n\}}],f(n+1)\bigg)$$ $$\Delta(f)=f\circ \pi$$ where $\pi:\{1,\dots,n+1\}\to \{1,\dots,n+1\}$ is the permutation defined by $$\pi(i)=\begin{cases} 
      i & \text{if } \quad i<i_0 \\
      n+1 & \text{if } \quad i=i_0 \\
     i-1 & \text{if } \quad i>i_0 
   \end{cases}$$ where $i_0$ is the smallest element of the set $\big\{1\leq i\leq n:f(n+1)\leq f(i)\big\}$ if this set is nonempty, and $i_0:=n+1$ otherwise. I claim that $\Phi':=\Delta\circ \Gamma$ is a sorting function for $X^{n+1}$ . Since $\Phi[f|_{\{1,\dots,n\}}]=f|_{\{1,\dots,n\}}\circ \sigma$ for some permutation $\sigma:\{1,\dots,n\}\to \{1,\dots,n\}$ we see that $\Gamma(f)=f\circ \sigma'$ for some permutation $\sigma'$ . Then $$\Phi'(f)=(\Delta\circ \Gamma) (f)=f\circ \sigma'\circ\pi$$ for the permutation $\sigma'\circ\pi$ . By considering the different cases with respect to $i_0$ we also see that $i\leq j$ implies $\Phi'(f)(i)\leq \Phi'(f)(j)$ . Hence $\Phi'(f)$ statisfies (i) and (ii) for all $f\in X^{n+1}$ and so is indeed a sorting function for $ X^{n+1}$ . Is this correct? Thanks a lot for your help","['permutations', 'sorting', 'monotone-functions', 'order-theory', 'elementary-set-theory']"
4370784,How can I use fixed point iteration for $2x^3-4x^2+x+1=0$ to find the negative root?,"How can I use fixed point iteration for $2x^3-4x^2+x+1=0$ to find the negative root? The  worked solution to the question uses the following iterative formula, it apparently finds a solution at -0.3660 (4sf) but I am unable to retrieve this result: $$x_{r+1}=\sqrt{\frac{2x_r^3+x_r+1}{4}}$$ I can find positive roots such as 1 and 1.366(4sf) [link] , but I am unable to find the negative root for the function using fixed point iteration. I have tried $x_0=-0.5$ which eventually finds the root at $1$ . $x_0=-1$ and below seems to result in the square root of a negative number that does not have a real solution.","['fixed-point-theorems', 'sequences-and-series']"
4370786,$\sum \frac{a}{b+c+d}\le \frac{2\sum a^2}{\sum ab}$ if $\sum a =4$,"Let $a, b, c, d$ positive real numbers such that $a+b+c+d=4$ . Prove that $$\frac{a}{b+c+d}+\frac{b}{c+d+a}+\frac{c}{d+a+b}+\frac{d}{a+b+c}\le
\frac{2(a^2+b^2+c^2+d^2)}{ab+ac+ad+bc+bd+cd}.$$ My idea is to cancel the denominators, expand the inequality and use Muirhead, but the calculations are terrible... So I'm looking for a smarter solution.","['contest-math', 'algebra-precalculus', 'muirhead-inequality', 'inequality']"
4370835,Proof that the series $\sum_{n=2}^{\infty}\frac{[\Omega(n)]^\alpha}{n^2}$ converges,"Let's consider the series $$f(\alpha)=\sum_{n\gt1}\frac{[\,\Omega(n)\,]^\alpha}{n^2}$$ where $\Omega(n)$ denotes the number of prime factors of $n$ counted with their multiplicity and $\alpha\ge0$ is a real parameter. It is known that $$f(0)=\frac{\pi^2}{6}-1$$ and by computational experiments results that $$f\Big(\frac 1 2\Big)=0.74587577\dots$$ $$f(1)=0.90748082\dots$$ $$f(2)=1.62036452\dots$$ How to prove that $f(\alpha)$ is finite (that is the given series converges) for any value of $\alpha$ ? The trend of the function $\log f(\alpha)$ is shown in the following graph: One could conjecture that $$f(\alpha)\sim e^{C\alpha}$$ with $C=\frac 5 2$ approximately. How to prove this estimate?","['dirichlet-series', 'number-theory', 'sequences-and-series']"
4370842,Proving a function has a local minimum,"If $f(x)=2x^2+x^2\sin(1/x)$ for $x ≠ 0$ and $f(0)=0$ , how can I prove $f(x)$ has a local minumum when $x= 0$ and (Df)(0)=0? I'm thinking the first step is proving $(Df)(0)=0$ with $$\lim_{x\to 0}(Df)=\lim_{x\to 0}(4x+2x\sin(1/x)-\cos(1/x))=0$$ But here I get stuck because I can't say anything about what happens to $\cos(1/x)$ .","['maxima-minima', 'calculus', 'derivatives']"
4370929,Why does this matrix multiplication converge? [Example of people averaging beliefs],"Converging to average I am pretty new to linear algebra and am working through a problem like this: There is a true value, $\theta=0$ Five people have initial guesses for $\theta$ that are drawn from a uniform distribution $[-1, 1]$ : At each round, people update their guess to an average of the other peoople's guesses I found that eventually all people converge to the average of the initial guesses. Matrix Notation W is a matrix representing the weights that person $i$ puts on person $j$ 's guess. $G_t$ represents the guesses of each individual at time $t$ . $G_t$ = $W^t \times G_0$ $$
W = \begin{pmatrix}
0.00 & 0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.00 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.00 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.00 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 & 0.00 \\
\end{pmatrix}
$$ $$ 
G_o = \begin{pmatrix}
\hat{\theta_1}  \\
\hat{\theta_2} \\
\hat{\theta_3}   \\
\hat{\theta_4}  \\
\hat{\theta_5}  \\
\end{pmatrix}
$$ For large $t$ , $W^t \times G_0$ approaches the average of the values in $G_0$ . Why is that? Simulation import numpy as np 
import random 

# True value 
theta = 0

# Number of guessers
n = 5

# Generate guesses around true value
np.random.seed(seed=100)
guesses = np.matrix(np.random.uniform(-1, 1, size=n))

# Weights
mat = np.matrix([[1/(n-1) for x in range(1,n+1)]]*n)
np.fill_diagonal(mat, 0)

# Update beliefs
temp_guess = guesses.copy()
for i in range(10000):
    temp_guess = (np.matmul(mat, temp_guess.T)).T
    
print(""Final matrix"", temp_guess)
print(""Average of initial guesses"", np.sum(guesses)/n)","['markov-chains', 'linear-algebra', 'probability']"
4370932,Negate a statement and prove the negation,"Consider the following statement.
There exist integers $k$ and $m$ such that for all integers $x$ if $x\geq k$ then $x^2< m \cdot x$ .
Disprove this statement.
(Hint: first write the negation of this statement then prove this negation.) My attempt The statement to disprove is $\exists(k, m) \ \forall x \ x\geq k \implies x^2 < m \cdot x $ $\neg(\exists(k, m) \ \forall x \ x\geq k \implies x^2 < m \cdot x ) = \forall(k, m) \ \exists x \ x\geq k \land \neg(x^2 < m \cdot x)$ $\neg(\exists(k, m) \ \forall x \ x\geq k \implies x^2 < m \cdot x )= \forall(k, m) \ \exists x \ x\geq k \land (x^2 \geq m \cdot x)$ The negation of the statement is $\forall(k, m) \ \exists x \ x\geq k \land (x^2 \geq m \cdot x)$ Question/help: How can I prove the negation of the statement ( $\forall(k, m) \ \exists x \ x\geq k \land (x^2 \geq m \cdot x)$ )?","['proof-explanation', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
4370956,Coefficient of $Y \sim X$ versus coefficient of $X \sim Y$,"Let's consider two variables $X, Y$ such that $EX = EY = 0$ , $VarX = VarY = 1$ Moreover, when considering OLS model without intercept $Y \sim X$ we obtained parameter $\beta$ . Thing that I want to investigate is connection between parameter $\beta$ and parameter $\hat \beta$ obtained from regression $X \sim Y$ . My solution If $\beta$ and $\hat \beta$ are solutions of OLS problems then we have that: $$\beta = (X^TX)^{-1}X^TY$$ $$\hat \beta = (Y^TY)^{-1}Y^TX$$ Then we have that: $$\beta \hat \beta = (X^TX)^{-1}X^TY(Y^TY)^{-1}Y^TX = X^{-1}X^TX^TYY^{-1}Y^TX = 1$$ So we have that $\hat \beta = \frac{1}{\beta}$ . And I'm not sure if my solution is correct since, I check it in R to obtain that: y <- rnorm(1000000)
k <- rnorm(1000000)
lm(y~ 0 + k) $coefficients == 1 / lm(k~0 + y)$ coefficients
FALSE Could you please tell me where do I have an error? EDIT As I understood problem in my calculations is that I'm trying to invert vectors, which are invertible. So my another idea driven by @GoldenRatio is that we know that: $$\beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}X} = E[XY]$$ as well as $$\hat \beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}Y} = E[XY]$$ So out of it we would have that $\beta = \hat \beta$ . Is it right?","['linear-regression', 'statistics', 'probability']"
4371045,"Embarrassing Question about ""Squaring the Circle""","I was reading about this famous problem called ""Squaring the Circle"" ( https://en.wikipedia.org/wiki/Squaring_the_circle ). The goal of this problem is to make a square and a circle with the same surface area. However, it was shown that this is not possible - in particular, it is impossible to make a square with an area of ""pi"". I am having a bit of difficulty understanding why it is not possible to make a square with an area of ""pi"" - for instance, a square of area ""pi"" would have each side measuring ""square root of pi"". If approximations are ""good enough"", it shouldn't be too hard to do this? ggplot() + 
  geom_rect(aes(xmin = 1, 
                xmax = sqrt(pi), 
                ymin = 1, 
                ymax = sqrt(pi))) + 
  coord_qual() I don't think I am correctly understanding this problem - for instance, I can understand that it is impossible to draw a square with each side measuring ""square root of pi"", seeing as ""pi"" is an unending and irrational number. For instance, I could not cut a piece of wood to exactly measure ""pi"" meters: I could curt a piece of wood to measure 3.14159 meters,  because eventually at some decimal position, no cut of wood would exactly measure ""pi"" meters. But wouldn't this concept apply to almost any problem in which measurements are unending decimal numbers? For instance, if I want to build a bridge to sustain some amount of load - I might do some engineering calculations, and it might tell me that that the bridge needs to 42.1256789900031323... meters long. But of course, I would make a cut at 42.125 meters and carry on with the construction. Thus: Is the ""Squaring the Circle"" problem impossible because it is impossible to draw a square having an unending length (i.e. I would spend eternity making sure that the measurement of each side was faithful to ""pi"" over infinite decimal places) - or is there some other reason that the ""Squaring the Circle"" problem is impossible? Thanks!","['irrational-numbers', 'circles', 'geometry']"
4371146,$\mathbf{Q}$ as the countable intersection of open sets?,"$\def\Q{\mathbf{Q}}$ $\def\N{\mathbf{N}}$ $\def\Z{\mathbf{Z}}$ $\def\I{\mathbf{I}}$ $\def\Fs{F_\sigma}$ $\def\Gd{G_\delta}$ Baire's Theorem tells us that $\Q$ is not a $\Gd$ set. However the set of integers $\Z$ is $\Gd$ by the following collection of sets: $$\Z = \bigcap_{n \in \N}\bigcup_{m \in \Z}{{\left(m-\frac{1}{n},m+\frac{1}{n} \right)}}$$ I want to understand why a similar cover for $\Q$ fails to work. Baire's Theorem, although a valid explanation, is somewhat philosophically unsatisfying. $$\Q \overset{?}{=} \bigcap_{n \in \N}\bigcup_{q \in \Q}{{\left(q-\frac{1}{n},q+\frac{1}{n} \right)}}$$ To look at what it would mean if there was an irrational number $x \notin \Q$ in this set: If it is in this set, then it was initially in some interval centred at some rational number $q$ . But as $n$ gets arbitrarily large, eventually the neighbourhood around $q$ will become small enough that it will no longer contain $x$ . This almost feels like it could qualify as a contradiction but I guess it's still possible for $x$ to be in infinitely many intervals. It just looks very counter-intuitive. If there was a direct way to construct an irrational $x \notin \Q$ that is in this set, then that would be philosophically satisfying. Final Remark. To anyone that wants to appeal to the length of the set or Lebesgue measure $\neq 0$ or something related to that, I am not familiar with any of these notions formally, so I'll likely get more confused by it. I could modify the construction like this: $$\Q \overset{?}{=} \bigcap_{n \in \N}\bigcup_{r=1}^{\infty}{{\left(q_r-\frac{1}{n \cdot 2^r},q_r+\frac{1}{n \cdot 2^r} \right)}}$$ where $\left\{q_1,q_2,q_3 \dots \right\}$ is an enumeration of $\Q$ . This set looks to have zero ""length"" (by my informal understanding).","['general-topology', 'real-analysis']"
4371181,Is there an intuition behind the Euler Lagrange equation?,I am taking calculus of variations at the moment and I am curious if there is a visualization of why the EL must be satisfied for all extremals. At first glance it's hard for me to relate: $$\frac{d}{dx}(\frac{\partial L}{\partial y'}) = \frac{\partial L}{\partial y}$$ With a geometric/visual intuition.,"['calculus', 'euler-lagrange-equation', 'ordinary-differential-equations', 'calculus-of-variations']"
4371197,What mistake is the author making (if any) while finding this antiderivative?,"Find the following antiderivative: $\int{\frac{1}{\sqrt{(2-x)(x-1)}}}dx$ My attempt: $$\int{\frac{1}{\sqrt{(2-x)(x-1)}}}dx$$ $$=\int{\frac{1}{\sqrt{2x-2-x^2+x}}}dx$$ $$=\int{\frac{1}{\sqrt{-2+3x-x^2}}}dx$$ $$=\int{\frac{1}{\sqrt{-(2-3x+x^2)}}}dx$$ $$=\int{\frac{1}{\sqrt{-(x^2-3x+2)}}}dx$$ $$=\int{\frac{1}{\sqrt{-(x^2-3x+{(\frac{3}{2})^2)}-2+(\frac{3}{2})^2}}}dx$$ $$=\int{\frac{1}{\sqrt{0.5^2-(x-\frac{3}{2})^2}}}dx$$ $$[\text{Let $x-\frac{3}{2}=u$}\\ \therefore du=dx]$$ $$=\int{\frac{1}{\sqrt{0.5^2-u^2}}}dx$$ $$[\text{Formula:}\int{\frac{1}{\sqrt{a^2-x^2}}}dx=\arcsin\left(\frac{x}{a}\right)+C, |x|<a]$$ $$=\arcsin\left(\frac{u}{0.5}\right)+C$$ $$=\arcsin\left(\frac{x-\frac{3}{2}}{0.5}\right)+C$$ $$=\arcsin(2x-3)+C$$ My work is correct. I know this because integral-calculator agrees with me (after going to the link, click on ""Go!"". For steps, click on ""Show steps""). However, my book did this math in a different way: My book's attempt: $$\int{\frac{1}{\sqrt{(2-x)(x-1)}}}dx$$ $$[\text{Let}\ x-1=u^2,dx=2udu,x=u^2+1,2-x=1-u^2]$$ $$=\int{\frac{1}{\sqrt{(1-u^2)(u^2)}}}2udu$$ $$=\int{\frac{1}{\sqrt{(1-u^2)}u}}2udu$$ $$=2\int{\frac{1}{\sqrt{(1-u^2)}}}du$$ $$[\text{Formula:}\int{\frac{1}{\sqrt{a^2-x^2}}}dx=\arcsin\left(\frac{x}{a}\right)+C, |x|<a]$$ $$=2\arcsin(u)+C$$ $$=2\arcsin(x-1)+C$$ Comments: This is the graph . From the graph, it doesn't look like the book's answer differs only by a constant from my answer. So, is it wrong? If it is wrong, what mistakes did it make?","['integration', 'calculus', 'functions', 'trigonometry']"
4371200,Is Robinson’s non standard analysis accepted by the mathematical community?,"Up until now I had known that calculus had been initially formulated by Leibniz and Newton in terms of infinitesimals, but that approach led to inconsistencies, and so Cauchy and others reformulated calculus rigorously using the epsilon-delta method. Recently I stumbled across “Elementary Calculus : An Infinitesimal Approach” by H. J. Keisler. In his preface Keisler says that the infinitesimal approach to calculus had been placed on rigorous footing in the 1960s by Abraham Robinson. And here is my question : is it universally accepted now that Robinson’s calculus is rigorous/not logically inconsistent? In essence, what’s the common consensus in the math community regarding Robinson’s approach to infinitesimal calculus?","['calculus', 'infinitesimals']"
4371258,An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.,"An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.  What is the probability that the drawn balls have numbers greater than 5? I thought for the first ball, (6,7,8,9,10). The probability is $5/10$ . We took one, and for the second it is $4/9$ . And for the third one it is $3/8$ . Then we multiply these, and it is $1/12$ . But I am not sure for this solution. I am confused.","['discrete-mathematics', 'probability']"
4371274,It is still true that $\dim X \le \dim X^\star$ for infinite-dimensional Banach spaces if $\dim X < 2^{\aleph_0}$?,"Let $X$ be an infinite-dimensional Banach space and $E^\star$ its topological dual. In this answer, @tree detective showed that if $\dim X \ge 2^{\aleph_0}$ , then $\dim X \le \dim X^\star$ . Does the result hold if we remove the assumption $\dim X \ge 2^{\aleph_0}$ ?","['banach-spaces', 'functional-analysis']"
4371276,Why do we use specific probability distributions in certain contexts?,"For instance, in survival analysis and modelling time to failure, one is likely to use a weibull distribution or exponential distribution. I'm struggling to understand the intuition behind this. What makes these distributions more suited to the context than, say, a chi-square distribution or a beta distribution or a log-normal distribution?","['statistics', 'probability-distributions']"
4371280,Can you give me an infinite non abelian group in which every subgroup is normal? [duplicate],"This question already has answers here : Examples for infinite Hamiltonian group having a infinite order 2-group as a subgroup (2 answers) Closed 2 years ago . I know that every subgroup of an abelian group is normal and the converse is not true . For an example $Q_8=\{\pm 1 ,\pm i, \pm j, \pm k \}$ . My question : Can you give me an infinite non abelian group in which every subgroup is normal?","['group-theory', 'normal-subgroups', 'abelian-groups']"
4371283,$A_n\subseteq A: \mu(A_n)\xrightarrow{n}0 \Rightarrow \int_{A_n} f \xrightarrow{n} 0 $ [duplicate],"This question already has an answer here : I must prove that $\lim_{\mu(A)\rightarrow 0}\int_{A}\lvert f \lvert{\rm d}\mu=0$. (1 answer) Closed 2 years ago . Let $f\in L^1(A)$ and $A_n\subseteq A: \mu(A_n)\xrightarrow{n\to\infty}0$ , show that $$\int_{A_n} f \xrightarrow{n\to\infty}0 $$ What i tried: We can write $f$ as following: $$f = f \cdot 1_{\{|f| >M\}} +f \cdot 1_{\{|f| \le M\}}, M>0.  $$ Note: if $f\in L^1(A)$ and $g_n(x) = |f(x)| \cdot 1_{\{|f| \ge n\}}$ then $$\int_A g_n \xrightarrow{n\to\infty}0 \qquad (*)$$ because $|g_n(x)|\le |f(x)|\in L^1(A) $ and $\lim g_n = 0$ hence, from dominated convergence theorem we got $(*)$ $$\int_{A_n}f = \int_{A_n}f \cdot 1_{\{|f| >M\}} +\int_{A_n}f \cdot 1_{\{|f| \le M\}}  $$ $$\int_{A_n}f \cdot 1_{\{|f| \le M\}} \le M\mu(A_n)\xrightarrow{n\to\infty}0$$ let $\epsilon >0$ , we can choose M large enough s.t: $$\int_{A_n}f \cdot 1_{\{|f| >M\}}\le \int_{A}f \cdot 1_{\{|f| >M\}} \le \epsilon.$$ is my approath correct? Thank you!","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4371312,"Let $M$ and $N$ be two $3\times 3$ matrices such that $MN=NM$, Further if $M\neq N^2$ and $M^2=N^4$ then","Let $M$ and $N$ be two $3\times 3$ matrices such that $MN=NM$ , Further if $M\neq N^2$ and $M^2=N^4$ then (A) Determinant of $(M^2+MN^2)$ is $0$ (B) There is a non-zero $3\times 3$ matrix $U$ such that $(M^2+MN^2)U$ is the zero matrix (C) Determinant of $(M^2+MN^2) \geq1$ (D) For a $3\times 3$ Matrix $U$ , if $(M^2+MN^2)U$ equals the zero matrix then $U$ is the zero matrix. My Thinking: $(M-N^2)(M+N^2)=M^2-N^4+MN^2-N^2M$ $\implies$ $(M-N^2)(M+N^2)=MNN-NNM=NMN-NMN=0$ (Here zero denotes Null matrix). Case $(1)$ $M+N^2 \neq0$ and $M-N^2= 0$ (Here zero is Null matrix) But it is given that $M\neq N^2$ So Case $1$ Can't be true. Case $(2)$ $M-N^2\neq 0$ and $M+N^2\neq 0$ But we know that $|M-N^2||M+N^2|=0$ $\implies$ $|M+N^2||M-N^2|= 0$ So Subcase $(1)$ of case $(2)$ $|M+N^2|=0$ and $|M-N^2|\neq 0$ Subcase $(2)$ of case $(2)$ $|M+N^2|\neq 0$ and $|M-N^2|=0$ But when $|M+N^2|\neq0$ then we can take inverse of this. $\implies$ $0=(M+N^2)(M-N^2)$ $\implies$ $0=(M+N^2)^{-1}(M+N^2)(M-N^2)$ $\implies$ $0= M-N^2$ i.e. subcase $(2)$ is false. $\implies$ Result of case $(2)$ is $|M+N^2|=0$ Case $(3)$ $M+N^2=0$ and $M-N^2\neq 0$ Result of case $(3)$ is $|M+N^2|=0$ If above is  true then Matrix $(M+N^2)=0$ From All three cases $|M+N^2|=0$ . So Option $(A)$ is True. My Doubt is option (B) I think this statement should be false because $(M^2+MN^2)U$ need not be zero always. This question was asked in Indian Exam JEE Advanced Paper $1$ of Year $2014$ https://www.jeeadv.ac.in/archive.html Linked Question Finding the value of the determinant $|M^2+MN^2|$ and determining whether $U$ is a zero matrix or not","['matrices', 'jordan-normal-form', 'determinant', 'linear-algebra']"
4371316,Characters of Lie algebra representations,"1.Three definitions Let $\mathfrak g$ be a Lie algebra over a field $k$ . Let $(V, \rho)$ be a $\mathfrak g$ -representation.
In class I was presented with various definitions of characters of $(V, \rho)$ . First case: $(V, \rho)$ a one-dimensional $\mathfrak g$ -representation. By identifying $\mathfrak {gl}(k) \cong k$ and using that $\rho$ is a Lie algebra morphism one obtains (with the universal property of quotients) a bijection between $(\mathfrak g /[\mathfrak g, \mathfrak g])^*$ and one dimensional $\mathfrak g$ -representations. We call the linear form in $(\mathfrak g /[\mathfrak g, \mathfrak g])^*$ corresponding to a $\mathfrak g$ -rep $(V, \rho)$ its character. Second case : $\mathfrak g = \mathfrak sl(2,\mathbb C)$ . Since $\mathfrak g$ is semisimple by Weyl's theorem any $\mathfrak g$ -rep is semisimple. The classification of simple $\mathfrak g$ -reps gives that hence any $\mathfrak g$ -rep decomposes (as a vector space) into integral weight spaces $V_\lambda$ of $\rho(h)$ where $$h = \begin{pmatrix}
    1       & 0 \\
    0 &-1 \\
\end{pmatrix} \in \mathfrak g .$$ We call the Laurent polynomial $\sum_{\lambda \in \mathbb Z} dim(V_\lambda) q^i \in \mathbb Z[q,q^{-1}$ ] the character of the $\mathfrak g$ -rep $(V, \rho)$ . Third case: $\mathfrak g$ a complex semisimple Lie algebra & $(V, \rho)$ a finite-dimensional $\mathfrak g$ -rep. Let $\mathfrak h$ be a Cartan subalgebra of $\mathfrak g$ .  One proves that $V$ is a weight module, i.e. that it has the weight space decomposition $V=\bigoplus _{\lambda \in \mathfrak h^*}V_\lambda$ .
Consider the group algebra $\mathbb Z[\mathfrak h^*]$ of the group $\mathfrak h^*$ with respect to addition. Its elements are formal $\mathbb Z$ -linear combinations of basis elements $e^\lambda$ for $\lambda \in \mathfrak h^*$ . (More formally, the group algebra is the $\mathbb Z$ -algebra of functions $\mathfrak h^* \rightarrow \mathbb Z$ of finite support with $\mathbb Z$ -basis consisting of functions $e^\lambda: \mathfrak h^* \rightarrow \mathbb Z$ with $e^\lambda(\lambda)=1$ and $e^\lambda(\mu)=0$ for $\mu \neq \lambda$ .) We call $\sum _{\lambda \in \mathfrak h ^*} dim(V_\lambda) e^\lambda \in \mathbb Z[\mathfrak h^*]$ the character of $(V, \rho)$ . 2. Question (How) are these notions related?","['lie-algebras', 'characters', 'representation-theory', 'abstract-algebra', 'semisimple-lie-algebras']"
4371326,Why is the Lebesgue integral linear when only one summand is integrable?,"Let $(X, A, \mu)$ be a measure space, $(f_n)_n$ measurable for all $n$ , and $f$ measurable, non-negative and integrable such that $f_n \le f$ for all $n$ . Then $\int _X \limsup_{n\to \infty} f_n d\mu \ge \limsup _{n\to \infty} \int _X f_n d\mu$ .
In the proof I saw for this statement, we define $h_n = f - f_n$ . We have that $$\int _X \liminf _{n\to \infty} h_n d\mu= \int _X \liminf _{n\to \infty} (f - f_n) d\mu = \int _X (f + \liminf _{n\to \infty} (-f_n)) d\mu = \int _X f d\mu + \int _X \liminf _{n\to \infty} (-f_n) d\mu$$ The explanation for the last equality is that $f$ is integrable. However, to use linearity we need all summands to be integrable.
Why can we use it here? Thanks.","['integration', 'measure-theory', 'analysis']"
4371336,Character induced from a faithful character is faithful,"In my last algebra exam, I had this exercise that I wasn't able to solve: Let $H$ be a subgroup of the group $G$ . Let $\chi$ be a character of $H$ . Assuming that $\chi$ is faithful , prove that the induced character $\chi\uparrow G$ is faithful What is the link between $\ker(\chi)$ and $\ker (\chi\uparrow G)$ ? To clarify the notation, this exam is about group representations and in particular about representations of finite groups on a $\mathbb{C}$ vector space. A faithful character is a character of an injective representation. I know that if $\chi$ is the character of a representation $\rho$ then: $$ \ker \rho = \ker \chi := \{g\in G\ |\ \chi(g) = \chi(1)\} $$ . I also know that $$\chi\uparrow G(g) = \frac{1}{|H|}\sum_{x\in G}\dot\chi(xgx^{-1})$$ where $$\dot\chi(g) =
 \begin{cases}
    \chi(g) & \text{if}  & g\in H \\
    0 & \text{if} & g\not\in H
 \end{cases}$$ . Using these formulae is easy to show that: $$\ker \chi\uparrow G = \left\{g\in G\ \middle|\ \frac{1}{|H|}\sum_{x\in G}\dot\chi(xgx^{-1}) = |G:H|\chi(1)\right\}$$ but i don't know how to continue from here.","['characters', 'representation-theory', 'finite-groups', 'abstract-algebra', 'group-theory']"
4371376,"If $M$ is a compact Riemann surface, then $H^1(M,\mathbb R)\cong H^1(M,\mathcal O)$","I am wondering why we have the isomorphism stated in the title. Concretely, we have the following exact sequences of sheaves: $$0\rightarrow\mathbb R\rightarrow\mathcal O\rightarrow\mathcal O/\mathbb R\rightarrow 0$$ Where $\mathbb R$ denotes the constant sheaf over $M$ and the first map is the canonical inclusion. If we pass to the long exact sequence in cohomology, we have that $$\dots\rightarrow H^0(M,\mathcal O/\mathbb R)\rightarrow H^1(M,\mathbb R)\rightarrow H^1(M,\mathcal O)\rightarrow H^1(M,\mathcal O/\mathbb R)\rightarrow\dots$$ is exact, but somehow, the groups at the extremes should be trivial whenever $M$ is a compact Riemann surface. I know this has to do with Hodge theory over compact Kähler manifolds, but although I have been searching for a reference of this fact, I haven't found it. How can we deduce this result from Hodge theory? Thanks in advance for your answers.","['hodge-theory', 'sheaf-cohomology', 'complex-geometry', 'sheaf-theory', 'differential-geometry']"
4371452,"Standard machine and the proof that $\int_Af|_Ad\mu_A = \int_{\Omega}1_Afd\mu$ in a measure space $(\Omega, F, \mu)$.","Preamble: I suppose that the gist of this question is whether I've understood both the steps and what is reasonable to abstract away when using the standard machine to prove anything. In any case, one toy problem for the standard machine is the following: Let $(\Omega, F, \mu)$ be a measure space, $A \in F$ and $F_A = \{A\cap B\mid B \in F\}$ , and define the function $\mu_A[C] = \mu[A\cap B]$ for $C = A\cap B$ for some $B \in F$ . Suppose that it is known that $F_A$ is a sigma-algebra, and that indeed $\mu_A$ is a measure. For any function $f:\Omega \to \mathbb{R}$ let $f|_A:A \to \mathbb{R}$ be its restriction to $A$ . Then, the straightforward way to show that $\int_A f|_Ad\mu_A = \int_\Omega 1_Afd\mu$ is by the standard machine, i.e. showing the equality for 1.) indicator functions, 2.) non-negative simple functions, 3.) non-negative measurable functions, 4.) all measurable functions $f$ s.t. $f|_A \in \mathcal{L}^1(\mu_A)$ . Question: Suppose that the equality has already been proven for indicator functions $f = 1_C, C \in F_A$ , and the linearity $\int_A (af|_A + bg|_Ad)\mu_A = a\int_A f|_A\mu_A + b\int_Ag|_A\mu_A$ of such indicator functions has been confirmed. Then question 1 : is rest of the proof really just 2: invoking the linearity for a non-negative simple function, 3: using the monotone convergence theorem with an approximation sequence of non-negative simple functions to the non-negative measurable function, 4: splitting a general measurable function $f$ into its negative ( $f_-$ ) and positive ( $f_+$ ) component, and then applying to step 3.) and the measurability of $f$ to both $f_-$ and $f_+$ to finish the proof? Question 2 : Is it typical to prove the linearity at each step of the proof, or if the general results for integrals are known (like monotone/bounded convergence theorem) to be true, then do e.g. our restricted integral inherit there properties?","['measure-theory', 'real-analysis']"
4371518,In search of the most symmetric Steiner quadruple systems,"Hanani's original 1960 proof of the existence of Steiner quadruple systems $SQS(n)$ for all $n\equiv2,4\bmod6$ involves explicitly constructing an $SQS(14)$ and an $SQS(38)$ in what is otherwise a purely inductive proof. However, the listed $SQS(14)$ is devoid of any noticeable pattern and would certainly not be memorisable by a human – its automorphism group has order only $6$ . 0125 038D 1236 157C 24AC 3579 479C
013B 039A 1247 1589 24BD 358B 5678
0146 0459 128B 15BD 257B 35AC 569B
0178 047B 129A 1679 258A 367B 56CD
019D 048A 12CD 168D 259C 3689 59AD
01AC 04CD 1345 16BC 267C 36AD 68AC
0234 057D 137D 17AB 269D 3BCD 789A
0268 058C 138A 235D 26AB 457A 78BC
0279 05AB 139C 237A 278D 458D 79BD
02AD 067A 148C 238C 346C 45BC 7ACD
02BC 069C 149B 239B 3478 467D 89CD
0356 06BD 14AD 2456 349D 468B 8ABD
037C 089B 156A 2489 34AB 469A 9ABC Thus I want to find the $SQS(14)$ whose automorphism group is of the highest possible order , just like how two non-isomorphic solutions to Kirkman's schoolgirl problem have the largest possible automorphism group of $\operatorname{PSL}(2,7)$ . The most symmetric $SQS(14)$ I have found so far has $C_7\rtimes C_6$ as its automorphism group, with its blocks falling into five orbits under the actions of $(1234567)(ABCDEFG)$ and $(1A)(2F5G3D)(4B6E7C)$ . The orbit representatives are $$1235,126C,12AB,12DE,12FG$$ and the blocks are 1235 2346 3457 4561 5672 6713 7124
AGFD GFEC FEDB EDCA DCBG CBAF BAGE
126C 237D 341E 452F 563G 674A 715B
AGC6 GFB5 FEA4 EDG3 DCF2 CBE1 BAD7
12AB 23BC 34CD 45DE 56EF 67FG 71GA
15AE 52EB 26BF 63FC 37CG 74GD 41DA
13AC 35CE 57EG 72GB 24BD 46DF 61FA
12DE 23EF 34FG 45GA 56AB 67BC 71CD
15FC 52CG 26GD 63DA 37AE 74EB 41BF
13GB 35BD 57DF 72FA 24AC 46CE 61EG
12FG 23GA 34AB 45BC 56CD 67DE 71EF
15GD 52DA 26AE 63EB 37BF 74FC 41CG
13DF 35FA 57AC 72CE 24EG 46GB 61BD Is there an $SQS(14)$ whose automorphism group has more than $42$ elements, or whose blocks fall into fewer than $5$ orbits?","['automorphism-group', 'combinatorial-designs', 'group-theory', 'combinatorics']"
4371552,showing removable singularity at origin.,"Let $f$ be holomorphic in the punctured disk $\{z:0< \vert z \vert<2\}$ such that $$\vert f(z) \vert \leq \bigg(\log \frac{1}{\vert z \vert}\bigg)^{100}, \space \text{in $\vert z \vert \leq \frac{1}{2}$}$$ and $$\vert f(z) \vert = 1, \space \text{on $\vert z \vert = 1$}$$ I need to show $f$ has a removable singularity at the origin. Does this mean I need to find an analytic function $g$ defined on an $\epsilon$ ball about the origin agrees with $f$ for $0< \vert z \vert < \epsilon$ ? So is this by construction? Am I contracting such an analytic $g$ ?","['complex-analysis', 'singularity', 'analytic-functions']"
4371563,choose the minimum set of elements that uniquely identifies all sets,"I have a total of m elements distributed in N sets, each represented by 1 to k < m elements. My goal is to choose the minimum number of elements needed to uniquely identify all N sets. For example: suppose there are 4 sets (A, B, C, D) containing 6 elements (1, 2, 3, 4, 5, 6) A: {1, 3, 5, 6} B: {2, 4, 5, 6} C: {1, 2, 4, 6} D: {1, 4, 5} checking each set for 3 would yield truth values of 1, 0, 0 ,0 for sets A, B, C, D checking each set for 2 would yield truth values of 0, 1, 1, 0 for sets A, B, C, D checking each set for 1 would yield truth values of 1, 0, 1, 1 for sets A, B, C, D thus after checking 3 elements, each set is represented by a unique truth table (A: {1, 0, 1}; B: {0, 1, 0,} etc.). The minimum number of elements needed is thus 3, and the elements are 1, 2, and 3. How would i generalize this approach to m elements and N sets?","['combinatorics', 'extremal-combinatorics']"
4371588,How to compute Gubinelli Derivatives,"Let $X,Y \in C^{\alpha}([0,1],\mathbb{R})$ be $\alpha$ -Hölder paths in $\mathbb{R}$ with $1/3 < \alpha < 1/2$ . Then a path $Y' \in C^{\alpha}([0,1],\mathbb{R})$ is called a Gubinelli derivative of $Y$ with respect to $X$ if there exists a $C > 0$ s.t. $$ \vert Y_t - Y_s - Y_s' (X_t - X_s) \vert \leq C \vert t - s \vert^{2 \alpha}, ~~~ \forall s,t \in [0,1]. $$ I am fine with the definition of Gubinelli derivatives, but I am struggling to compute it even for very simple functions. For example, let $X_t := t^{\alpha}$ and $Y_t := t^{\beta}$ with $1/3 \leq \alpha \leq \beta \leq 1/2$ . What would be the Gubinelli derivative in this example? Of course if $\alpha = \beta$ , then $Y_s = 1$ for every $s \in [0,1]$ is sufficient. I also know that once a Gubinelli derivative $Y'$ is found, then for a sufficiently regular function (say $\phi \in C^2_b$ ) one can find $(\phi(Y))'$ explicitely.","['stochastic-integrals', 'stochastic-differential-equations', 'rough-path-theory', 'probability-theory']"
4371595,Find all functions $f:\mathbb R \rightarrow \mathbb R$ such that $x^2\cdot f(x)+f(1-x)=2x-x^4$ $\forall\; x\in \mathbb R$,"Find all functions $f:\mathbb R \rightarrow \mathbb R$ such that: $\;x^2\cdot f(x)+f(1-x)=2x-x^4,\;\forall\; x\in \mathbb  R.$ My solution: Replace $x$ by $(1-x)$ and by eliminating $f(1-x)$ . I obtained $f(x)=1-x^2$ as provided in my book. My doubt: How to check that there is no other function satisfying Above property? Also, I think $f(x)=0,\;\forall\;x\in \mathbb R$ can be solution too. Is my thinking correct?","['functional-equations', 'calculus', 'functions', 'solution-verification', 'algebra-precalculus']"
4371614,Why $1_{T=\infty}X_{\infty}$ is $\mathcal{F}_T$-measurable for a martingale?,"For a filtration $\mathcal{F}_0\subset\dots\subset \mathcal{F}_t\subset\dots\subset \mathcal{F}_{\infty}$ . We know that if $X$ is $\mathcal{F}_0$ -measurable, then $X$ is also $\mathcal{F}_t$ -measurable for $t\ge 0$ . I have a question about the martingale $X_t$ (which $\mathcal{F}_t$ measurable) is  that given a stopping time $T$ , why $1_{T=\infty}X_{\infty}$ is $\mathcal{F}_T$ -measurable? It is clear that $1_{T=\infty}$ is $\mathcal{F}_T$ -measurable. But because $X_{\infty}$ is $\mathcal{F}_{\infty}$ -measurable. How can we say $X_{\infty}$ is also $\mathcal{F}_{T}$ -measurable?","['stochastic-processes', 'measure-theory', 'probability']"
4371632,Why does $f$ continuous and its Fourier coefficient converges absolutely implies the Fourier series converges uniformly?,"I've read that if we have a continuous function defined on a circle and its Fourier coefficient converges absolutely, then that implies the Fourier series converges uniformly, but I'm not quite sure why because absolute convergence does not imply uniform convergence for infinite series. I think the reason is due to the Weierstrass $M$ test correct? If the Fourier series converges absolutely, then so do the Fourier coefficients which we use for the $M$ test. Is that correct?","['fourier-analysis', 'harmonic-analysis', 'analysis', 'real-analysis', 'fourier-series']"
4371645,Taylor series expansion of Dirac delta function,"Suppose $f,g : R^N \to R$ and we have an integral of the form $$ I = \int d^N \mathbf{x} \, g(\mathbf{x}) \delta(f(\mathbf{x})), $$ with the Dirac delta function restricting the domain of integration to the submanifold on which $f$ vanishes (assume this manifold is nice and smooth, etc.). Suppose additionally that we can write $$f(\mathbf{x}) = f_0(\mathbf{x}) + \epsilon f_1(\mathbf{x}),$$ where $\epsilon$ is small in some sense and $f_0$ is not a constant. Under what conditions, if any, can we expand the delta function as a formal Taylor series $$\delta(f(\mathbf{x})) \overset{?}{=} f_0(\mathbf{x}) + \epsilon f_1(\mathbf{x}) \delta'(f_0(\mathbf{x})) + \frac{1}{2} \epsilon^2 f_1(\mathbf{x})^2 \delta''(f_0(\mathbf{x})) +\dots,$$ where $\delta'$ is the distributional derivative, and then evaluate $I$ term by term using integration by parts? If this equation doesn't make sense, can it be modified somehow so that it does?","['integration', 'dirac-delta', 'distribution-theory', 'taylor-expansion', 'differential-geometry']"
4371665,Examples of inner product on the space of continous functions.,"Let $C([a,b], \mathbb{R})$ be the space of continous functions $f:[a,b] \to \mathbb{R}$ . I am looking for examples of inner products on this space. I know the inner product $\langle f,g \rangle = \int_a^b fg$ which can be generalized to $\langle f,g \rangle = \int_a^b fgh$ where $h \in C([a,b], \mathbb{R})$ is a non negative function. I haven't been able to find more examples for the space of continuous functions. I'd be especially interested in an inner product that doesn't depend on integration. Does anyone know more examples or a reference? Thanks.","['functions', 'linear-algebra', 'functional-analysis']"
4371698,Maximizing probability of picking the dime,"A money pouch contains a certain number of cents and only one dime. You and your friend are playing a game: They alternate turns and pick one coin at a time, which they put in their pockets. Whoever picks the dime wins. You are trying to decide whether it is better to play first or second: Initially you think that if you pick the dime in your first draw, you immediately win, while if you opt to play second, your probability to pick the dime increases. Which of the two options is more favorable for you? We assume that you can’t see the coins before taking them out of the pouch and also that you can’t tell from the size which coin is which. My thought: Let's say we have $n$ coins in total. If I play first, I have probability of picking the dime: $\frac {1}{n}+\frac {1}{n-2}+\frac {1}{n-4}...$ while if I play second, I have $\frac {1}{n-1}+\frac {1}{n-3}+\frac {1}{n-5}...$ . Clearly the second option gives a larger number.
Is this correct? Thank you.",['probability']
4371707,Finding an injection from $\mathcal{P}(\mathbb{N})$ to $\mathbb{R}$ by using power series of base $2$.,"$
\def\N{\mathbb{N}}
\def\R{\mathbb{R}}
\def\pow{\mathcal{P}}
\def\pown{\pow(\N)}
$ Definitions : $|A| \le |B|$ if there is an injection from $A$ into $B$ ; $|A| = |B|$ if there is a bijection from $A$ onto $B$ ; Proposition 0.12 in Real Analysis by Folland (1999), he showed the existence of an injection from $\pown$ to $\R$ by constructing a function $f: \pown \to \R $ such that $$
\forall A \subseteq \N: f(A)
=
\begin{cases}
S(A), & |\N \setminus A| = |\N|\\
1 + S(A), & |\N \setminus A| < |\N|
\end{cases}
$$ where $S(A) = \sum_{n \in A} 2^{-n}$ . But he did not demonstrate that it is injective. Here is my attempt at a formal proof of it: Attempt :
Let $$
X = \{ A \subseteq \N ~|~ |\N\setminus A| = |\N|\}\\
Y = \{ A \subseteq \N ~|~ |\N\setminus A| < |\N|\}
$$ Since $|\N\setminus A| \le |\N|$ , $X$ and $Y$ partition $\N$ . Moreover, $$
f[X] \subseteq [0, 1)\\
f[Y] \subseteq (1, 2]
$$ Hence, it suffices to show that the two restrictions $ f \restriction_X $ and $ f \restriction_Y $ are both injective. Lemma 1 : For any $A \subseteq \N$ , $$
|\N\setminus A| = |\N| \leftrightarrow \forall n \in \N: \exists m \in \N: (m > n \land m \notin A)
$$ That is, $A$ has infinite holes in $\N$ exactly when $|\N\setminus A| = |\N|$ . Proof : ( $\to$ ) Suppose $\exists n \in \N: \forall m \in \N: [m > n \to m \in A]$ . The contrapositive is $m \notin A \to m \le n$ , i.e., $$
\exists n \in \N: \forall m \in \N \setminus A: m \le n
$$ meaning $\N \setminus A$ is bounded, by which there cannot be a bijection between $\N \setminus A$ and $\N$ . ( $\leftarrow$ ) Let $B = \N\setminus A$ for brevity. Let $(C_n)_{n \in \N}$ be defined by $C_n = \{m \in B ~|~ m > n\} \subseteq \N$ . By the condition, $C_n$ is nonempty for all $n \in \N$ . So we can define a function $g: \N \to B$ such that $$
\forall n \in \N: g(n) = \min C_n
$$ Since $g(n) > n$ , $g$ is injective. Furthurmore, $B \subseteq \N$ implies $|B| \le |\N|$ . By the Schroeder-Bernstein theorem, $|B| = |\N|$ . By Lemma 1, we also have Corollary 1 : $
|\N\setminus A| < |\N| \leftrightarrow \exists n \in \N: \forall m > n: m \in A
$ Lemma 2 : For all $A, B \subseteq \N$ , If $A \neq B$ and $S(A) = S(B)$ , then, there is $n \in \N$ such that $\forall i < n: (i \in A \leftrightarrow i \in B)$ $n \notin A \land \forall i > n: i \in A \land n \in B \land \forall i > n: i \notin B $ WLOG I failed to show Lemma 2, but assume for now it holds. For all $A, B \in X$ , aiming for a contradiction, suppose that $A \neq B$ and $S(A) = S(B)$ . Then, Lemma 1 and 2 yield a contradiction. For all $A, B \in Y$ , suppose that $A \neq B$ and $S(A) = S(B)$ . Then, Corollary 1 and Lemma 2 yield a contradiction. Therefore, $f$ is injective. Questions : We know that two numbers $0.1_2$ and $0.0\bar{1}_2$ have different expansions but the values are identical. I designed Lemma 2 to say that it is the only way that any numbers with distinct binary expansions have the same value. Is Lemma 2 true and how to show it? Given that Lemma 2 is true, is the proof valid?","['elementary-set-theory', 'cardinals', 'solution-verification']"
4371709,Prove that $f( \limsup \limits_{x \to +\infty} x_n)$ = $ \limsup \limits_{x \to +\infty} f(x_n)$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question The problem is divided into two questions: $x_n$ is a real valued sequence. Prove that $f( \limsup \limits_{n \to +\infty} x_n)$ = $ \limsup \limits_{n \to +\infty} f(x_n)$ given that $f$ is continuous and increasing. What can we say when $f$ is decreasing. If it were a regular limit I can just pass the $\lim$ inside the function and we're done. But this is $\limsup$ . Thanks for your help.","['limits', 'functions', 'real-analysis']"
4371734,When would we want to use uneven subintervals in a Riemann integral?,"The formal definition of a Riemann Integral is written such that you can have uneven subintervals and it still works.  Why do we need to generalize to the case of uneven subintervals?  Why not insist our subintervals are always of equal length, and $\Delta x$ is the same for all of them? Here's the full definition from Wiki: The Riemann Integral of $f$ equals $s$ if: For all $\epsilon > 0$ , there exists a $\delta > 0$ such that for any tagged partition $x_0 \dots x_n$ and $t_0 \dots t_{n-1}$ whose mesh is less than $\delta$ we have $$\left|  \left(\sum_{i=0}^{n} f(t_i) (x_{i+1}-x_{i})\right) - s \right| < \epsilon$$ Notice that they have to reference the ""mesh"" in this definition, i.e. the length of the longest subinterval.  Wouldn't we get a simpler definition by just requiring equal subintervals? E.g [my version] The Riemann Integral of $f$ equals $s$ if: For all $\epsilon > 0$ , there exists a $\delta > 0$ such that for any tagged partition $x_0 \dots x_n$ and $t_0 \dots t_{n-1}$ [with equal subintervals] less than $\delta$ we have $$\left|  \left(\sum_{i=0}^{n} f(x_i)\Delta x_i \right) - s \right| < \epsilon$$ Or is there a use for having different subinterval lengths?","['partitions-for-integration', 'riemann-sum', 'calculus', 'riemann-integration']"
4371756,Do both real and imaginary roots of a cubic equation need to continuous?,"I have a cubic equation: $X^3-UX^2-KX-L=0$ (1) with $X=1-E+U$ , $K=4(1-\gamma^2-\lambda^2)$ , $L=4\gamma^2U$ . I solve Eq. (1) for the variable $E$ numerically for $U=2$ and different sets of parameter $\gamma =$ 0.1, 0.25, and 0.45 and plot real and imaginary parts of $E$ against $\lambda$ . The real parts of the solutions for $X$ and $E$ differ by a constant shift for a fixed value of $U$ while the imaginary parts remain identical. See the plots below. The plots plot all the roots or solutions. They are colored with three different colors by looking at the possible continuity of the roots or the solutions (here stressed on the continuity of the imaginary parts). Here we see for the first case $\gamma = 0.1$ , the continuity in the real parts of $E$ (Re $E$ ) break down while the imaginary parts (Im $E$ ) remain continuous for all parameter values of $\gamma$ . Since the solutions are found for discrete values of $\lambda$ , we may think that extreme left and right of the cyan and blue curves of the first plot can be interchanged and hence made Re $E$ continuous all the way. However, that may lead Im $E$ to be discontinuous for other parameter values of $\gamma$ (I can add images if further clarity is needed). How can we interpret or understand this? Or is there something fundamentally wrong? The alternative coloring for the first two plots could be the following (in this sense all the curves appear continuous function of $\lambda$ ). Real part: Imaginary part: Though the above fixes the continuity issue, it appears that all three curves do not smoothly evolve with parameter $\gamma$ . Experts' opinions awaited.","['complex-analysis', 'continuity', 'roots', 'complex-numbers']"
4371811,"$[a,b]$ be a compact interval in $\Bbb R$, $f,g\in C[a,b]$, $f=g$ iff. $\int_a^b x^n f(x)dx=\int_a^b x^ng(x)dx$ for all $n$ - proof assistance","$\newcommand{\d}{\,\mathrm{d}}\newcommand{\c}{\mathcal{C}}$ I need to show the following: Let $[a,b]$ be a compact interval in $\Bbb R$ ; for any two $f,g\in\c[a,b]$ , $f=g$ on $[a,b]$ if and only if: $$\int_a^b x^nf(x)\d x=\int_a^b x^ng(x)\d x$$ For all $n\in\Bbb N$ . This comes as an exercise after a proof of the Stone-Weierstrass and Weierstrass approximation theorems. My strategy: One direction is trivial. For the other, the space of all real polynomials on $[a,b]$ (hereafter denoted by some $p$ ) is dense in $\c[a,b]$ , so by basic integral properties we obtain: $$\int_a^bp(x)f(x)\d x=\int_a^bp(x)g(x)\d x$$ Since $[a,b]$ is a normal space, for all $t\in(a,b)$ I can choose for some small $h\in(0,\frac{1}{2}(b-t))$ so that $[a,t]$ and $[t+h,b]$ are two disjoint closed sets and there is a continuous $\varphi$ which is $1$ on the first set, $0$ on the second. There is some $p$ which can uniformly approximate $\varphi$ by $\epsilon$ for arbitrary positive $\epsilon$ , whence: $$\left|\int_a^b\varphi(x)f(x)\d x-\int_a^b\varphi(x)g(x)\d x\right|\lt\epsilon(b-a)\\\left|\int_a^tf(x)\d x-\int_a^tg(x)\d x\right|\lt\epsilon(b-a)+h(\|f\|+\|g\|)$$ $\epsilon$ and $h$ both may approach $0$ at any rate, and I can conclude then that: $$\int_a^tf(x)\d x=\int_a^tg(x)\d x$$ For all $t\in(a,b)$ . The fundamental theorem of calculus gives immediately then that $f(x)=g(x)$ for all $x\in(a,b)$ , and I believe also for all $x\in[a,b]$ by continuous extension (not sure about this point). Is this right? I feel as if my conclusion from $\epsilon,h$ being arbitrarily small maybe isn't quite right. Can someone elaborate on whether or not the continuous extension idea holds?","['integration', 'weierstrass-approximation', 'real-analysis', 'continuity', 'solution-verification']"
4371819,Prove consistency of MLE,"Let be $(X_1,Y_1),...,(X_n,Y_n)$ n independent couples of random variables where $X_i\sim{Binom(10,\theta)}$ and $Y_i|X_i=x_i\sim{Pois(\lambda{(1+x_i)})}$ . I found the MLE for $\lambda$ , which is: $$
\hat{\lambda}={\sum_{i=1}^n{Y_i}\over{n+\sum_{i=1}^n{X_i}}}.
$$ How can I prove that it is a consistent estimator for $\lambda$ ?","['statistical-inference', 'statistics', 'maximum-likelihood']"
4371883,How to show that $B_{t\land T_a}$ is uniformly integrable?,"For a Brownian motion $B_t$ started from $0$ (it is also a martingale), denote by $T_a=\inf\{t\ge 0: B_t=a\}$ the stopping time. Consider the stopped process $B_{t\land T_a}$ (this is still a martingale), then $|B_{t\land T_a}|$ is bounded by $a$ . (Recall that $T_a<\infty$ a.s.) Why can we say $B_{t\land T_a}$ is uniformly integrable? At first I thought this is because that $E\left[\lvert B_{t\land T_a}\rvert^2\right]\le C$ for some constants $C$ , then $B_{t\land T_a}$ is uniformly integrable. However, I just saw this question: Almost sure bounded imply finite expectation? . I believe the answer means the finite bounded cannot imply the expectation. Thus, we cannot get $E[|B_{t\land T_a}|^2]\le C$ from $|B_{t\land T_a}|\le a$ .","['measure-theory', 'uniform-integrability', 'stochastic-processes', 'brownian-motion', 'probability-theory']"
4371896,"How many $01$ or $10$ substrings are there, on average, in a random $n$-bit string containing $k$ ones.","For example, if $n = 4$ and $k = 2$ , then we have ${4 \choose 2} = 6$ strings: $$
1100 \rightarrow 1\\
0011 \rightarrow 1\\
1001 \rightarrow 2\\
0110 \rightarrow 2\\
1010 \rightarrow 3\\
0101 \rightarrow 3
$$ The number $N$ of $01$ or $10$ substrings is shown beside each string. In this case, the average number is $$\bar{N}(4,2) = \frac{12}{6}$$ So, what's the general formula for $\bar{N}(n,k)$ , the average number of $01$ or $10$ substrings in a random $n$ -bit string containing $k$ ones?","['average', 'combinatorics', 'combinatorial-proofs']"
4371903,Rudin 9.19 Implicit Function Theorem Exercise,"Show that the system of equations $$
\begin{array}{r}
3 x+y-z+u^{2}=0 \\
x-y+2 z+u=0 \\
2 x+2 y-3 z+2 u=0
\end{array}
$$ can be solved for $x, y, u$ in terms of $z$ ; for $x, z, u$ in terms of $y$ ; for $y, z, u$ in terms of $x$ ; but not for $x, y, z$ in terms of $u$ . I am trying to show that this system can be solved for $x,y,u$ in terms of $z$ . Does this need to have a solution set for every single $z\in\mathbb{R}$ ? I am thinking about applying the implicit function theorem however this would require checking that the derivative is non-invertible. If I view this function as $f:\mathbb{R}^3\times \mathbb{R}\to \mathbb{R^3} $ $$f(x,y,z,u)=[3x+y-z+u^2, x-y+2z+u, 2x+2y-3z+2u]$$ I get that the total derivative w.r.t. (x,y,u) is $$\left[\begin{array}{ccc}
3 & 1 & 2 u \\
1 & -1 & 1 \\
2 & 2 & 2
\end{array}\right]$$ Would this need to be invertible for every $u$ for the implicit function theorem to find a function in terms of $z$ that can solve the system of equations?","['complex-analysis', 'calculus', 'analysis', 'real-analysis']"
4371910,Second-order nonlinear ODE $d^{2}y/dx^{2} =y^{-1/2}f(x)$,"Has this second-order nonlinear ODE been studied before or been given a known name that I can look up for further study or investigation? $$ y’’ \sqrt{y}+f(x)=0, $$ in single real variable $x$ , with $y=y(x)$ , an arbitrary function $f(x)$ , and with the double primes indicating second derivative with respect to $x$ ?","['potential-theory', 'mathematical-physics', 'ordinary-differential-equations']"
4371915,"Chebyshev's inequality, how is it applied in this problem?","Data set: Problem: Work attempted: There is no way that .21 % is at least 3.48, especially when 29/30 are between the bounds of (3.48, 3.96). It's not clear to me what I'm doing wrong.","['chebyshev-function', 'statistics', 'probability']"
4371917,"Number of functions $𝑓:\{1,2,3,\ldots,2k+1\}\to \{1,2,3,\ldots,2n+1\}$ satisfying a certain conditions","Let $k<n$ be positive integers. I wish to count the number of function $𝑓:\{1,2,3,\ldots,2k+1\}\to \{1,2,3,\ldots,2n+1\}$ for which $f(k+1)\neq 2n-2$ , $$
f(1)<f(2)<\ldots<f(k)<f(k+1)>f(k+2)>\ldots>f(2 k)>f(2 k+1),
$$ and $f(a)\neq f(b)$ for any $a\neq b$ belong to $\{1,2,3,\ldots,2k+1\}$ . My approach: $S_1$ be the set of all functions for which $f(1)<f(2)<\ldots<f(k)<f(k+1)$ ,  and $f(k+1)\neq 2n-2$ . Then $|S_1|=\binom{2n+1}{k+1}-\binom{2n-3}{k}$ . Similar: $S_2$ be the set of all functions for which $f(k+1)>f(k+2)>\ldots>f(2 k)>f(2 k+1)$ ,  and $f(k+1)\neq 2n-2$ , then $|S_2|=\binom{2n+1}{k+1}-\binom{2n-3}{k}$ . Now I wish to find $|S_1\cap S_2|$ . This seems IE principle could help, but I don't know how to apply it here? Could anyone help me? Thanks.","['functions', 'combinatorics']"
4371950,Proving a formula for the area of a convex quadrilateral with an incircle,"I am preparing for Mathematical Olympiads. I recently stumbled across this Trigonometry Problem and I am unable to solve this after numerous attempts. I couldn't even find  solution to it online. Show that if $ABCD$ is a convex quadrilateral, that has an incircle, and $a$ , $b$ , $c$ , and $d$ are the lengths of the tangents from the vertices to the circle, as shown then; $$[ABCD]^2 = (a + b + c + d)(abc + abd + acd + bcd).$$ I have tried to drop altitudes from the incenter of the quadrilateral to the sides, and see if I can use some identities to prove the result. Dropping those altitudes showed that the quadrilateral was inscribed about a circle with sides tangent to the circle. I tried to use the fact that the area is equal to the semi-perimeter times the inradius. But I couldn't get any far with it because of the $r^2$ term in the R.H.S. I am stuck at it currently. Can someone help me out with this problem? Thank You!","['euclidean-geometry', 'trigonometry', 'geometry']"
4372014,Variance lower bound for discrete random variables,"We know that for a continuous random variable $X$ with density $f$ , $$Var(X) \geq \frac{e^{2h(f)}}{2\pi e},$$ where $h(f)$ is the differential entropy. This follows from Eq (8.80), Theorem 8.6.6 of Thomas & Cover Information Theory book: Can we get a similar lower bound for a discrete random variable? Let's say $X\in\{-N,\cdots,-1,0,1,2,\cdots,N\}$ for finite N with some probability mass function $p(.)$ . We can't apply the argument in eq.(8.80) above since uniform distribution is the maximum entropy for discrete random variables! We know that $Var(X)=0$ if and only if X is degenerate. So I think we can get a lower bound in this case as well, but I am not able to come up with anything. :( Thanks for any help in advance! Edit 1: From here , there doesn't seem to be a closed-form known discrete distribution for the maximum entropy when variance is known.","['variance', 'probability-distributions', 'inequality', 'probability-theory', 'probability']"
4372020,two different version differential Bianchi identity,"There are two different version of differential Bianchi identities,one use the (0,4) curvature tensor: $$\nabla Rm(X,Y,Z,V,W) + \nabla Rm(X,Y,V,W,Z) + \nabla Rm(X,Y,W,Z,V) = 0\tag{1}$$ another use (1,3) curvature endomorphism : $$\left(\nabla_{X} R\right)(Y, Z)W+\left(\nabla_{Y} R\right)(Z, X)W+\left(\nabla_{Z} R\right)(X, Y)W=0\tag{2}$$ I try to show these two are the same.I try to deduce (2) from (1). first since $Rm = R^\flat$ ,hence (1) is equivalent to: $$(\nabla R)^\flat(X,Y,Z,V,W) + (\nabla R)^\flat(X,Y,V,W,Z) + (\nabla R)^\flat(X,Y,W,Z,V) = 0$$ where we use $\nabla$ commute with musical isomorphism. which implies: $$\langle(\nabla_VR)(X,Y)Z,W\rangle+\langle(\nabla_WR)(X,Y)V,Z\rangle+\langle(\nabla_ZR)(X,Y)W,V\rangle = 0$$ at this point I don't know how to preceed,maybe we need to use symmetry of curvature tensor at this step?","['riemannian-geometry', 'differential-geometry']"
4372031,"counting order pairs (A,B)","I am trying to solve the following counting problem and came up till this far. How many ordered pairs (A,B) are there where A and B are subsets of {1, 2, 3, 4, 5} and [1] have $A \cap B = \phi$ [2] have $A \cap B$ = {1} [3] have $|A \cap B|$ = 1 Here is how I progressed for [1]. I assume at any point in time set A consists on m elements. Number of ways I can choose m elements from 5 elements is: ${5 \choose m}$ . Since the intersection of A & B doesn't have any elements in common, so set B has to be built using zero or more from the remaining (5 - m) elements. Number of such set B = |P(B)| = $2^{5 - m}$ Total number of such pairs = $\sum_{m=0}^{5} {5 \choose m}*2^{5 - m}$ = 243 For [2] my thought process is as follows:
Set A & B has 1 in common. A = {1, ...another m - 1 elements} if A has total of m elements. B = {1, another (4 - m) elements disjoint from m elements in A}. Using the logic from [1] Total number such pairs = $\sum_{m=1}^{4} {4 \choose (m - 1)}*2^{5 - m}$ = 81 For [3]: A & B needs to have at least one element each. So if A has m elements then $1 \le m \le 5$ When A has m elements, then B will have (6 - m) elements as they have one element in common. Number of ways to make A = ${5 \choose m}$ For each of them |P(B)| = $2^{6 - m}$ Each of the terms of the product ${5 \choose m} * 2^{6 - m}$ needs to be multiplied by m as there are m choices of the common element between A & B Total count = $\sum_{m=1}^{5} {5 \choose m}*2^{6 - m}*m$ = 810 Is my thought process correct?","['elementary-set-theory', 'combinatorics']"
4372033,What is the distributional limit $\displaystyle\lim_{N\to\infty} \sum_{n=0}^N e^{inx}$?,"What is the distributional limit of $$\lim_{N\to\infty} \sum_{n=0}^N e^{inx} \; ?$$ If the summation is over $-N$ to $N$ , the answer is $\sum_{m\in\mathbb Z}2\pi \delta(x-2\pi m)$ , but what about the above one? Naive guess: If the sum is replaced by an integral, we know $$\lim_{N\to\infty} \int_0^N e^{ikx} dk = \frac{i}{x+i0}.$$ However, since $\sum_{n=0}^N e^{inx}$ should be $2\pi$ -periodic, a plausible answer could be $$\frac{i}{\sin x+ i0}.$$","['limits', 'fourier-analysis', 'poisson-summation-formula', 'distribution-theory']"
4372074,Reason Behind the name for Jungle-River Metric.,"The Metric defined by $d(x,y)=|x_2-y_2|$ if $x_1=y_1$ and  = $|x_2|+|y_2|+|x_1-y_1|$ if $x_1 \neq y_1$ ; where $x=(x_1,x_2)$ and $y=(y_1,y_2)$ is called the Jungle-River Metric. Is there any special reason for calling this Metric by this name?","['terminology', 'metric-spaces', 'analysis', 'real-analysis']"
4372081,Exercise 2.2.12 in Topology and Groupoids,"The following is Exercise 2.2.12 is Ronald Brown’s Topology and Groupoids , which tries to characterize topological spaces using the relation “ $A$ is contained in the interior of $B$ ”. Let $X$ be a non-empty set and $⊲$ a relation on subsets of $X$ such that $∅ ⊲ ∅$ and $X ⊲ X$ $A ⊆ A'$ , $A' ⊲ B'$ , $B' ⊆ B$ imply $A ⊲ B$ . $A ⊲ B$ implies $A ⊆ B$ . $A ⊲ B$ and $A' ⊲ B'$ imply $A ∩ A' ⊲ B ∩ B'$ . $A_i ⊲ B_i$ for all $i ∈ I$ implies $⋃_{i ∈ I} A_i ⊲ ⋃_{i ∈ I} B_i$ . For each $x ∈ X$ , $A ⊆ X$ define $A$ to be a neighbourhood of $x$ if $\{ x \} ⊲ A$ . Prove that these neighbourhoods define a topology on $X$ for which $A ⊲ B$ if and only if $A ⊆ \operatorname{Int}(B)$ . By a topology the book means a neighbourhood topology in the following sense: Let $X$ be a set and let $\mathcal{N}$ be a function assigning to each $x$ in $X$ a set $\mathcal{N}(x)$ of subsets of $X$ .
The elements of $\mathcal{N}(x)$ will be called neighbourhoods of $x$ .
The function $\mathcal{N}$ is a neighbourhood topology if it satisfies the following axioms for each $x$ in $X$ : The set $\mathcal{N}(x)$ is non-empty. If $N$ is a neighbourhood of $x$ , then $x ∈ N$ . If $N$ is a subset of $X$ containing a neighbourhood of $x$ , then $N$ is a neighbourhood of $x$ . The intersection of any two neighbourhoods of $x$ is again a neighbourhood of $x$ . Any neighbourhood $N$ of $x$ contains a neighbourhood $M$ of $x$ such that $N$ is a neighbourhood of each point of $M$ . My attempts so far: It is not hard to see that properties 0–3 of a neighbourhood topology are satisfied, but I’m struggling to show property 4.
Given a neighbourhood $N$ of $x$ we can consider the set $$
  M
  =
  \{
    y ∈ N
  \mid
    \{ y \} ⊲ N
  \}
$$ and this should a posteriori do the job.
But I don’t see why $M$ should be a neighbourhood of $x$ .
I also tried to modify this approach by defining $N^{(0)} ≔ N$ , $N^{(1)} ≔ M$ , etc. and then considering $⋂_{n = 0}^∞ N^{(0)}$ .
But this doesn’t seem to work either. I also tried to solve the exercise the other way around:
It follows from the properties of the relation $⊲$ that the set $$
  \mathcal{U} ≔ \{ A ⊆ X \mid A ⊲ A \}
$$ forms a topology in the usual sense on $X$ (i.e., a collection of “open subsets” satisfying certain conditions).
Is is then not hard to see that $A ⊆ \operatorname{Int}(B)$ implies $A ⊲ B$ , but I don’t see how the reverse implication is supposed to work. I suspect by now that the exercise may be missing some additional requirement on the relation $⊲$ . There seems to be the more general notion of a pretopological space for which axiom 4 of a neighbourhood topology is not required. In such a space $X$ , one can still define the preinterior of a subset $A$ of $X$ as $$
  \operatorname{PreInt}(A)
  =
  \{
    x ∈ X \mid \text{$A$ is a neighbourhood of $x$}
  \}.
$$ It seems to me that the relation $⊲$ given by $A ⊲ B$ iff $A ⊆ \operatorname{PreInt}(B)$ should satisfy all of the given conditions. But the resulting “topology” is just the original pretopology.",['general-topology']
4372094,Triangle with a circle having an altitude as its diameter: proof of a property without using crossratios,"I´ve been thinking about this problem for 3 days: Let $ABC$ be an acute triangle, $D, E,$ and $F$ the feet of the altitudes of $A, B$ and $C$ , respectively. Let; $O$ be the midpoint of segment $AD$ $c$ be the circle with center $O$ passing through $A$ and $D$ $X$ and $Y$ the intersections of $c$ with $AB$ and $AC$ , respectively $P$ the intersection of $XY$ with $AD$ , and $Q$ the intersection of $AD$ and $EF$ . Prove that $P$ is the midpoint of the segment $QD$ . I have proved that $XY$ and $EF$ are parallel lines by using inscribed angles. Someone helped me solve this problem via cross ratios. The following is his solution; It's easy to show that $BCXY$ is cyclic, then $EF\parallel XY$ so if $XY,EF$ intersect $BC$ at $G$ and $S$ respectively and if $T$ is the reflection of $D$ in $G$ then; $$GX\cdot GY=GB\cdot GC=GD^2$$ $$\implies (B,C;D,T)=-1.$$ Thus $S$ and $T$ coincide. Since $G$ is midpoint of $DS,$ we know that $P$ is the midpoint of $QD.$ I don´t understand how he applies cross ratio, and I would be grateful if someone could explain to me how he solves the problem or if someone could solve the problem without using projective geometry. This is my visual proof that EF and XY are parallels","['trigonometry', 'projective-geometry', 'geometry', 'metric-spaces']"
4372096,What's the difference between a higher sheaf on a regular ($1$-) site and a sheaf on a $2$- (or $\infty$-)site?,"A higher site's coverage satisfies If $\left\{f_: U' \rightarrow U\right\}$ is a covering family and $g: V \rightarrow U$ is a morphism, then there exists a covering family $\left\{h: V' \rightarrow V\right\}$ such that the composite $g\circ h$ factors through $f$ up to higher morphisms . instead of the usual condition where strict equality $g\circ h=f$ is involved. Also a higher sheaf takes value in higher categories, for example, $(2,1)$ -sheaf is a stack (category fibered in groupoid). I understand the higher descent when the site is a regular one (the $3$ -cocycle codition involved in the descent for usual stack is nothing but a $2$ -morphism and when the sheaf goes higher the $n$ -cocycle codition gets imposed; see http://nlab-pages.s3.us-east-2.amazonaws.com/nlab/show/descent#AsGluing ). But how exactly is a higher sheaf on a higher site different from that on a regular site?","['algebraic-geometry', 'higher-category-theory', 'category-theory']"
4372124,"The mean curvature of a hypersurface $(M^{(n)},g)$ as $H:=\frac{1}{n}\mathsf{tr}(s)=\frac{1}{n}\mathsf{tr}_g h$","The reference for the following discussion is Lee's Introduction to Riemannian Manifolds . As can be seen in chapter 8 of this book, the mean curvature $H$ of a hypersurface $(M^{(n)},g)$ at $p\in M$ is defined as $H=\frac{1}{n}\mathsf{tr}(s)$ , where $s$ is the shape operator ( Weingarten map ) of $M$ at $p$ in the direction of a smooth unit normal vector field $N$ . Since $s$ is a self-adjoint operator on the tangent space $T_p M$ , linear algebra assures us that  there exists an orthonormal basis $\{E_1,\ldots,E_n\}$ for $T_p M$ consisting of eigenvectors of $s$ . This makes it relatively easy to diagonalize $s$ . If the eigenvalues corresponding to $E_1,\ldots,E_n$ are $\lambda_1,\ldots,\lambda_n$ respectively, then the representation of $s$ in $\{E_1,\ldots,E_n\}$ is simply $\mathsf{diag}(\lambda_1,\ldots,\lambda_n)$ , thereby leading to $$H=\frac{1}{n}(\lambda_1+\ldots+\lambda_n).$$ Now I'd like to know how to start from this expression to get $$H=\frac{1}{n}(\mathsf{tr}_g h)(p)$$ if $\mathsf{tr}_g h$ is the trace of the scalar second fundamental form $h$ with respect to $g$ . The relation between $h$ and $s$ is given by $$\left<s(X),Y\right>_g=h(X,Y)\tag{$*$}$$ for $X,Y\in\mathfrak{X}(M)$ . In the above equation, it is essential to know that $s$ is a map from $\mathfrak{X}(M)$ to $\mathfrak{X}(M)$ . I'm not sure if I gave enough information to begin our discussion. Feel free to ask more if you don't have Lee's IRM. Thank you. Update(2022/2/2): Here is an attempt resulting from my understanding of $\mathsf{tr}_g h$ . Following Lee's convention, we denote the dual basis of $\{E_1,\ldots,E_n\}$ by $\{\epsilon^1,\ldots,\epsilon^n\}$ . Then we write $h_p=h_{ij}\epsilon^i\otimes\epsilon^j$ in order to compute $$(\mathsf{tr}_g h)(p)=g^{ik}(p)h_{ik}.$$ You can see p. 28 of IRM for more information about this formula. Now $$\begin{align}
g^{ik}(p)h_{ik}&=g^{ik}(p)h_p(E_i,E_k)\\
&=g^{ik}(p)\left<s(E_i),E_k\right>_g\tag{bringing ($*$) in}\\
&=g^{ik}(p)\left<\lambda_i E_i,E_k\right>_g\\
&=\sum_{i=1}^n g^{ii}(p)\lambda_i.
\end{align}$$ Look at the last equality. Those redundant $g^{ii}(p)$ 's put me in a very awkward position! How can I get rid of them? Update(2022/2/3): A kind person reminded me that $g^{ij}(p)=\delta_{ij}$ due to the orthonormal basis. The job is done!","['curvature', 'riemannian-geometry', 'differential-geometry']"
4372176,Everyone gets a red card,"The following cards are dealt with $3$ people at random so that every one of them gets the same number of cards: $$R_1, R_2, R_3, B_1, B_2, B_3, Y_1, Y_2, Y_3$$ where $R$ , $B$ and $Y$ denote red, blue and yellow, respectively. Find the probability that everyone gets a red card. A total number of ways we can distribute $9$ cards to $3$ people so that each gets an equal number of cards is equal to $$\binom{9}{3} \times \binom{6}{3}$$ Next, we can give a red card to each of them in $3!$ ways. Then divide the remaining $6$ cards in $\binom{6}{2} \times \binom{4}{2}$ ways. Hence, the required probability is $$ \frac{3! \times \binom{6}{2} \times \binom{4}{2}}{\binom{9}{3} \times \binom{6}{3}} $$ Is my argument correct?","['discrete-mathematics', 'recreational-mathematics', 'combinatorics', 'probability']"
4372178,"Let two subsets $P,Q$ be selected from the set $A=\{1,2,3,4,5\}$. Find the probability... [duplicate]","This question already has an answer here : counting order pairs (A,B) (1 answer) Closed 2 years ago . Let two subsets $P,Q$ be selected from the set $A=\{1,2,3,4,5\}$ . Find the probability that A) $P\cap Q=\phi$ B) $P\cup Q=A$ C) $P\cap Q$ contains exactly one element My Attempt: For part A), each element has $3$ options. It can either go to $P$ or to $Q$ or to neither. So, total cases $=3^5$ Cases involving $P\cap Q$ can be: $^5C_0(^5C_0+...^5C_5)+^5C_1(^4C_0+...^4C_4)+^5C_2(^3C_0+...^3C_3)+^5C_3(^2C_0+...^2C_2)+^5C_4(^1C_0+^1C_1)+^5C_5(^5C_0)=2^5+5(2^4)+10(2^3)+10(2^2)+5(2)+1$ Is this correct? Is there an easier way to solve it? For part $B),$ each element has just two options. So, total cases $=2^5$ So, favorable cases $=^5C_0(^5C_5)+^5C_1(^4C_4+^5C_5)+^5C_2(^3C_3+^4C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5)$ Or, maybe $^5C_0(^5C_5)+^5C_1(^5C_4+^5C_5)+^5C_2(^5C_3+^5C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5)$ Not sure which one to go with. For part $C)$ , maybe we can take $^5C_1$ . This element would be in the intersection and for the remaining $4$ elements, we can approach like in part $A)$ ?","['combinations', 'combinatorics', 'probability']"
4372196,What is the name of the 4d shape that is equivalent to a cylinder except in 4d where 3 dimensions are equidistant from the center line instead of 2..,Sorry if my question is poorly explained. Basically I want the name of the shape that always looks like a sphere in 3 dimensions when fed into 3d space standing up in the 4th dimension; just like how a cylinder always looks like a circle in 2d flatland if you feed it into the 2d plane standing up.,"['geometry', 'terminology']"
4372218,Can infinite $T_0$ space have less open sets than points?,"It is pretty easy to check, that if $X$ is $T_1$ , then it has to have at least as many open sets as points, because every singleton would be closed. On the other hand, if we don't assume anything about $X$ , we could choose indiscrete topology and get positive answer. In the middle, we have $T_0$ . My intuition says, that it shouldn't be possible, but I don't know why.","['general-topology', 'separation-axioms']"
4372219,Prove that $\sum \frac{a^3}{a^2+b^2}\le \frac12 \sum \frac{b^2}{a}$,"Let $a,b,c>0$ . Prove that $$ \frac{a^3}{a^2+b^2}+\frac{b^3}{b^2+c^2}+\frac{c^3}{c^2+a^2}\le \frac12 \left(\frac{b^2}{a}+\frac{c^2}{b}+\frac{a^2}{c}\right).\tag{1}$$ A idea is to cancel the denominators, but in this case Muirhead don't work because the inequality is only cyclic, not symmetric. Another idea would be to apply Cauchy reverse technique: $$(1)\iff\sum \left(a-\frac{a^3}{a^2+b^2}\right)\ge \frac12 \sum (2a-b^2/a)\iff \sum\frac{ab^2}{a^2+b^2}\ge \frac12\sum\frac{2a^2-b^2}{a}$$ $$\iff \sum \frac{(ab)^2}{a^3+ab^2}\ge \frac12\sum \frac{2a^2-b^2}a.$$ Now we can apply Cauchy-Schwarz, and the problem reduces to $$\frac{(\sum ab)^2}{\sum a^3+\sum ab^2}\ge \frac12\sum \frac{2a^2-b^2}{a},$$ and at this point I am stuck. Here the only idea is to cancel the denominators, but as I say above it can't work.","['contest-math', 'algebra-precalculus', 'cauchy-schwarz-inequality', 'inequality']"
4372221,Map from X to $\mathbb P^1_k$ of degree $3$ with $X$ curve of genus $3$.,"Let $X$ be a curve over $k$ algebraically closed field. Here $X$ is a proper, smooth, connected, $\text{dim}(X)=1$ scheme over $k$ .
Suppose that $g(X) = 3$ with $g(X) = \text{dim}_k H^1(X,\mathcal O_X)$ the genus of $X$ .
We say that $X$ is hyperelliptic if $g(X)>1$ and there exists a map $X \rightarrow \mathbb P^1_k$ of degree $2$ .
Prove the following: $X$ is not hyperelliptic $\Longleftrightarrow$ there exists a map $X\rightarrow \mathbb P^1_k$ of degree $3$ . ( $\Rightarrow)$ Take the canonical embedding $X\rightarrow \mathbb P^2_k$ of degree $4$ associated to the canonical divisor. Then $X$ is a quartic in $\mathbb P^2_k$ and we can find a morphism from $X$ to $\mathbb P^1_k$ of degree $3$ using the derivatives of the quartic polynomial that defines $X$ . Any ideas for the other implication?","['algebraic-curves', 'algebraic-geometry', 'schemes']"
4372223,Rolling dice game - who first will roll number 3,"Let's consider very easy game with players A and B - they roll a dice starting with player A. If any of players roll a three, then he wins. I want to calculate probability that player B wins. Intuition Intuition is that $P(\textrm{player B wins}) < P(\textrm{player A wins})$ because they have even chances on winning, and player A starts, so player A has one more roll, therefore bigger chance to win. In other words player A is one roll ahead of player B so what should hold is that: $$P(\textrm{player A wins}) = P(\textrm{player B wins}) + \frac 16$$ Out of this we can already calculate desire probability $P(\textrm{player B wins}) = \frac{5}{12}$ Normal approach I want to calculate this normally (without any tricks) to compare the results. Please see the probability tree that I've created: Out of this tree we can see that: $$P(\textrm{B won}) = \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^2 \cdot \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^4 \cdot \frac 1 6 + ... = \sum_{n = 0}^\infty (\frac 5 6)^{2n}\frac{5}{6}\frac{1}{6} = $$ $$= \sum_{n = 0}^\infty(\frac{25}{36})^n\frac{5}{6}\cdot \frac 1 6 = \frac{1}{1 - \frac{25}{36}} \cdot \frac{5}{36} = \frac{36}{11} \cdot \frac{5}{36} = \frac{5}{11}$$ Question As you can see those two probabilities differ. Second result also matches our intuition that $P(\textrm{player B wins}) < P(\textrm{Player A wins})$ but I want to ask you - which result is correct and where is the mistake with the wrong one?","['dice', 'probability']"
4372270,Why is $L^2$ not a RKHS?,"Let's take $L^2[0,1]$ as an example. Obviously $L^2[0,1]$ is not a Hilbert space because you can have a function $f(0)=1$ but equal to $0$ everywhere else, so you don't have an unique element with norm $0$ , violating the definition of the inner product. So it only makes sense to talk about $L^2[0,1]$ as a Hilbert space in the sense of equivalence classes of functions that differ on at most a (Lebesgue) measure $0$ set. So why is $L^2[0,1]$ not a RKHS, when talking in terms of equivalence classes of functions? Is it because there is no unique representative for each equivalence class so the evaluation functional $\delta_x:f \rightarrow f(x)$ is undefined? If so, is there a way to choose $f$ for each equivalence class of functions in $L^2[0,1]$ such that the evaluation functional becomes well defined and continuous, and thus making $L^2[0,1]$ a RKHS?","['functional-analysis', 'reproducing-kernel-hilbert-spaces']"
4372309,Bayesian fallacy in Binomial example,"There are $50$ students in a course. Suppose that each student independently decides to continue the course or drop out of the course randomly. Let $X$ be the total number of students who continue with the course. Each student continues with a constant probability $p$ , which is drawn randomly with $P(p=0)=0.1,  P(p=0.75) = 0.6, P(p=1) = 0.3$ prior to the decisions being taken. Find $E(X), Var(X)$ . Also, comment on the distribution of $X$ . Now I am having a logical error somewhere in my two approaches : Approach 1 We know that $X|P=p \sim Bin(50,p)$ . So, $E(X) = E(X|P=0)P(P=0) + E(X|P=0.75)P(P=0.75) + E(X|P=1)P(P=1) = 22.5 + 15 = 37.5$ . Now, $V(X) = V(E(X|P))+E(V(X|P)) = V(50P)+E(50P(1-P)) = 50^2 V(P) + 50 E(P-P^2) = K$ which is some value. Approach 2 Let us take $X_i = 1$ with probability $p$ and $0$ otherwise. We try to write $X=X_1+...+X_{50}$ Then $E(X_i |p) = E(E(X_i|P)) = 0.75$ and so, $E(X) = 50*0.75 = 37.5$ . $V(X_i) = V(E(X_i |P)) + E(V(X_i |P)) = V(P)+E(P-P^2) = E(P)-E(P)^2$ , so $V(X) = 50*V(X_i) \neq K$ . Why are the two variances from the two approaches unequal? Is it because in approach 2, $X_i |P$ are not independent and thus we cannot just simply add their variances?","['statistics', 'probability-distributions', 'bayesian', 'expected-value', 'probability']"
4372398,The average time before the first appearance of a sequence of a length 3 of Bernoulli r.v.,"Let $\{X_n,n \geq 1\}$ be i.i.d. random variables of Bernoulli distribution with parameter $p \in (0,1)$ . Let $\tau_{ijk}:=\inf\{n\geq 3: (X_{n-2}, X_{n-1}, X_n) = (i,j,k)\}$ with $i,j,k \in \{0,1\}$ . How can I calculate $\mathbb{E}[\tau_{111}], \mathbb{E}[\tau_{100}]$ or any other? If I wanted to calculate $\mathbb{E}[\tau_{111}|(X_2, X_1, X_0) = (1,1,1)] $ , I would apply the following theorem for the Markov chain $\{Z_n\}_{n\geq 2}:=(X_{n-2}, X_{n-1}, X_n)$ on finite state space (8 states $(0,0,0);(0,0,1)...$ ): ""An irreducible Markov chain ${Z_n}$ has at most one invariant distribution $\pi(z)$ . It certainly has one if it is finite. And $\forall$ $ z $ $\pi(z)=\frac{1}{\mathbb{E}[T_z|Z_0=z]},$ where $T_z:=\inf\{n\geq 1: Z_n=z\} $ ."" The invariant distribution here is $\pi(z)=\frac{1}{8} \forall z$ , so $\mathbb{E}[\tau_{111}|(X_2, X_1, X_0) = (1,1,1)] = \mathbb{E}[\tau_{ijk}|(X_2, X_1, X_0) = (i,j,k)] = 8 $ .
Though it doesn't give any clues on how to calculate $\mathbb{E}[\tau_{111}]$ .","['markov-chains', 'expected-value', 'martingales', 'probability-theory', 'probability']"
4372403,What is the relation between the shift operator for derivatives and Fourier transforms?,"I feel like I am close to piecing together the relation but am not quite fully sure. This is the shift operator I’m talking about from Wikipedia page on shift operator The shift operator $T^{t}$ (where $t \in \mathbf{R}$ ) takes a function $f$ on $\mathbf{R}$ to its translation $f_{t}$ , $T^{t} f(x)=f_{t}(x)=f(x+t)$ .
A practical operational calculus representation of the linear operator $T^{t}$ in terms of the plain derivative $\frac{d}{d x}$ was introduced by Lagrange, $$T^{t}=e^{t\frac{d}{d x}}, $$ which may be interpreted operationally through its formal Taylor expansion in $t ;$ and whose action on the monomial $x^{n}$ is evident by the binomial theorem, and hence on all series in $x$ , and so all functions $f(x)$ as above. $[3]$ This, then, is a
formal encoding of the Taylor expansion in Heaviside's calculus. I also know the properties of Fourier transform time and frequency shifting from the page on the Fourier transform Translation / time shifting For any real number $x_{0}$ , if $h(x)=f\left(x-x_{0}\right)$ , then $\hat{h}(\xi)=e^{-2 \pi i x_{0} \xi} \hat{f}(\xi)$ . Then heuristically because of my slight knowledge of operational calculus , I know that the derivative operator with respect to time can be equated to frequency. Conversely because of the duality of time and frequency, I’m guessing the derivative operator with respect to frequency is the same as the time variable. I feel like there should be some way to interpret all of these things in a unified manner but I haven’t quite figured it out. Mainly the derivative shift operator applied to a function looks like the Fourier transform shifting but there is a slight difference between the two when you do the calculations.","['fourier-analysis', 'harmonic-analysis', 'fourier-transform', 'complex-analysis', 'functional-analysis']"
4372406,Derivative of distance along a smooth curve,"I am struggling to solve the following problem from 'Introduction to Riemannian Manifolds' by John M. Lee $(M,g)$ be a connected Riemannian manifold. $\gamma:(-\epsilon,\epsilon)\to M$ be a smooth curve then $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}=|\dot\gamma(0)|_g$$ I was able to show that $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}\le \lim_{t\to0+}\frac{l(\gamma|_{[0,t]})}{t}=\lim_{t\to0-}\frac{l(\gamma|_{[t,0]})}{t}=|\dot\gamma(0)|_g$$ Here $l(\cdot)$ denotes length of the curve. Then I tried to contradict assuming $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}>|\dot\gamma(0)|_g$$ but failed to complete the argument. Am I doing anything wrong? Please help. Some hints would be highly appreciated.","['metric-geometry', 'arc-length', 'riemannian-geometry', 'differential-geometry']"
4372416,When can a representation of a finite group be defined over certain cyclotomic fields?,"Let $G$ be a finite group and $\rho \colon G \to \mathrm{GL}(n, \overline{\mathbb Q})$ be a representation. A theorem of Frobenius says that $\rho(G)$ is conjugate (in $\mathrm{GL}(n, \overline{\mathbb Q})$ ) to a subgroup of $\mathrm{GL}(n, \mathbb Q(\zeta_e))$ , where $e$ is the exponent of $G$ and $\zeta_e$ is a primitive $e$ th root of unity. We say that $\rho$ is defined over $\mathbb Q(\zeta_e)$ . Considering a cyclic group of prime order shows that Frobenius' field is in general optimal. Sometimes however we are lucky and can do better than this: consider for instance the dihedral group $D_4$ of order $8$ . Its unique irreducible representation of degree $2$ maps the rotation $r$ to $\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$ and the symmetry $s$ to $\begin{pmatrix} 1 & 0 \\ 0 & -1\end{pmatrix}$ , i.e., this representation is real . We can decide whether an irreducible representation can be defined over $\mathbb R$ by calculating the Frobenius-Schur indicator of its character: if the Frobenius-Schur indicator is $1$ , then the given irreducible representation can be defined over the real numbers and if it's different from $1$ , then the representation is not real.
If we calculate the Frobenius-Schur indicator for the irreducible representation of the quaternionic group $Q_8 = \langle a,b \ | \ a^4 = 1, \ a^2 = b^2, \ ab = b^{-1}a\rangle$ given by $$a \mapsto \begin{pmatrix} i & 0 \\ 0 & -i \end{pmatrix}, \qquad b \mapsto \begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix},$$ we end up with $-1$ , showing that this representation cannot be defined over $\mathbb R$ (in fact, it is quaternionic, which is not surprising, since we have a quaternion group). Frobenius' theorem says that we can define it over $\mathbb Q(i)$ , which I already did by giving the matrices. The following has been bothering me for a while: we can define the above representation of $Q_8$ over $\mathbb Q(\omega)$ for a primitive third root $\omega$ ! In fact, it is equivalent to the representation given by $$a \mapsto \begin{pmatrix} 1+2\omega & -1 \\ -2 & -1-2\omega \end{pmatrix}, \qquad b \mapsto \begin{pmatrix}-1 & \omega^2 \\ -2\omega & 1\end{pmatrix}.$$ This seems odd to me. My question is therefore: Given a representation of a finite group and an integer $d \geq 3$ , how can we decide whether it is defined over $\mathbb Q(\zeta_d)$ ? For instance: is the above representation of $Q_8$ definable over $\mathbb Q(\zeta_5)$ ? There is of course the obvious necessary condition that the character must take values in $\mathbb Z[\zeta_d]$ . Also, as explained above, taking $d$ as the exponent of the group works. I appreciate any help!","['representation-theory', 'group-theory', 'linear-algebra', 'cyclotomic-fields']"
4372443,A wavy histogram from a maximum likelihood algorithm,"This question is based on a Puzzling Stack question I answered. Suppose you have a loaded $10$ -sided die that gives one value with probability $\frac7{25}$ and the rest with probability $\frac2{25}$ each, but you do not know the favoured value. A maximum likelihood method to determine this favoured value is as follows: Set probabilities $p_1=\dots=p_{10}=\frac1{10}$ , where $p_i$ is the likelihood of $i$ being the favoured value. Roll the die repeatedly; for each value $c$ that comes up multiply $p_c$ by $3.5$ , the ratio of probabilities of a favoured face to an unfavoured face. Normalise after each update and stop when one $p_i$ becomes dominant enough. This strategy is quite efficient, for simulating it $4121000$ times gave a mean of about $35.47$ rolls until one $p_i$ exceeded $0.99$ and a median of $32$ rolls. The histogram of rolls needed, however, looks very odd with its wavy top: Is there any logical explanation for the histogram's peculiar shape? The number of simulations I made certainly seems high enough to rule out sample size as an explanation. Here is the histogram corresponding to a d3 with one value twice as likely ( $1/2$ ) to come up as the other two ( $1/4$ ): Clearly there is a dependence on the number of possibilities, but what kind?","['dice', 'probability-distributions', 'probability', 'maximum-likelihood']"
4372504,"Find a permutation $x_{\sigma(1)},\ldots,x_{\sigma(n)}$ of $x_1,\ldots,x_n$ that maximises $\sum_{k=1}^{n-1}\vert x_{\sigma(k)}-x_{\sigma(k+1)}\vert.$","Suppose $\ x_1,\ x_2,\ \ldots,\ x_n\ $ are real numbers with $\ x_1 < x_2 <\ldots < x_n.$ Is there an efficient way to find a permutation $\ x_{\sigma(1)},\ x_{\sigma(2)},\ \ldots,\ x_{\sigma(n)}\ $ of $\ x_1,\ x_2,\ \ldots,\ x_n\ $ which maximises $\ f\left(\ \left( x_{\sigma(1)},\ x_{\sigma(2),\ \ldots,\ x_{\sigma(k)} } \right)\ \right) = \displaystyle\sum_{k=1}^{n-1} \left\vert x_{\sigma(k)} - x_{\sigma(k+1)} \right\vert\ ? $ My intuition tells me that either $\ f(\ \left(x_1,\ x_n,\ x_2,\ x_{n-1},\ x_3,\ x_{n-2},\ \ldots)\ \right)\ $ or $\ f(\ \left(x_n,\ x_1,\ x_{n-1},\ x_2,\ x_{n-2},\ x_3,\ \ldots\ \right)\ )\ $ might be a maximum, but I am not sure about this or how to prove if this is true. Edit: my intuition is wrong. For example, take $\ x_1= 1,\ x_2 = 2,\ x_3=3,\ x_4=4.$ Then neither $\ x_1\to x_4\to x_2 \to x_3,\ $ nor $\ x_4\to x_1 \to x_3\to x_2\ $ are the longest route (both have length $6$ ), since $\ x_3\to x_1\to x_4\to x_2\ $ is longer with length $7$ .","['discrete-optimization', 'rearrangement-inequality', 'algorithms', 'real-analysis']"
4372552,Question regarding complex differentiability,"I have been introduced to a new understanding of the differentiability of a complex function, which is: $f$ is $C$ -differentiable at $z_0$ iff we canfind a complex number $\alpha$ and a continuous function $R:\mathbb{D}\to\mathbb{C}$ , where $D\subset C$ is a suitably small neighborhood of $0$ such that $R(0)=0$ and $f(a+h)=f(a)+\alpha h+hR(h)$ . I want to prove this claim. I can prove that if $f$ is differentiable, it will meet the above condition, but I have trouble proving the converse. Any help or guidance you could give would be greatly appreciated.","['complex-analysis', 'derivatives']"
4372571,$\int_0^\infty \frac{x}{(e^{2\pi x}-1)(x^2+1)^2}dx$?,"How to calculate integral $\int_0^\infty \frac{x}{(e^{2\pi x}-1)(x^2+1)^2}dx$ ? I got this integral by using Abel-Plana formula on series $\sum_{n=0}^\infty \frac{1}{(n+1)^2}$ . This integral can be splitted into two integrals with bounds from 0 to 1 and from 1 to infinity and the both integrals converge, so does the sum. I checked with WolframAlpha and the value of the integral is $\frac{-9 + \pi^2}{24}$ , but I don't know how to compute it. Also, I tried to write $\frac{2xdx}{(1+x^2)^2}=d\frac{1}{x^2+1}$ and then tried to use partial integration, but didn't succeded.
Any help is welcome. Thanks in advance.","['integration', 'definite-integrals', 'real-analysis', 'complex-analysis', 'calculus']"
4372582,Drawing 5 paintings with 20 colors problem,"We have 20 different colors. We want to draw 5 pictures (the order of the pictures is not important). 1.) We want to draw every picture with different colors, so that every color is on maximum one picture. How many different combinations do we have if every picture is drawn with exactly 3 colors. 1.)My try: $$\frac{\binom{20}{3}\cdot \binom{17}{3}\cdot \binom{14}{3}\cdot \binom{11}{3} \cdot \binom{8}{3}}{5!}$$ 2.) Again we want to draw every picture with different colors, in how many ways can we draw, that we use all the colors and that on every picture there is at least one color.
2.) My try: I used Stirling numbers $S(20,5)$ 3.)Let's say that we don't differentiate colors(we are colorblind) and we do the same as in 2.), how many combinations are there now? 3.) My try: Natural number partitions: $V(20,5)$ Are the upper correct?","['combinatorics', 'discrete-mathematics']"
4372614,Map between Stiefel manifold and the Grassmannian,"I'm working on problem 2-7 in Lee's introduction to Riemannian Manifolds and am having trouble on part (b): Let $V_k(\mathbb{R}^n)$ be the Stiefel manifold and $G_k(\mathbb{R}^n)$ denote the Grassmannian. I want to show that the map $$ \pi : V_k(\mathbb{R}^n) \rightarrow G_k(\mathbb{R}^n)$$ that sends a k-tuple to its span is a surjective smooth submersion. I have already shown that $\pi$ is surjective and that both $V_k(\mathbb{R}^n)$ and $G_k(\mathbb{R}^n)$ are smooth manifolds. Hence if I can show that $\pi$ is a smooth map of constant rank, the result should follow. I appreciate any help.","['grassmannian', 'differential-topology', 'stiefel-manifolds', 'differential-geometry']"
4372635,Proving that limits at infinity are unique help,"I am trying to prove that the $\displaystyle \lim_{x\rightarrow \infty}f(x)=L$ is unique, if it exists. Definition: Let $f:S\rightarrow\mathbb R$ be a function, where $\infty$ is a cluster point of $S$ . We say that $f(x)$ converges to $L$ as $x$ goes to $\infty$ if  there exists $L\in\mathbb R$ such that for every $\varepsilon>0$ , there is an $M\in \mathbb R$ such that $$|f(x)-L|<\varepsilon$$ whenever $x\in S$ and $x\geq M$ . Here is what I got so far: Proof: Let $L_1$ and $L_2$ be two numbers that both satisfy the above definition. Take $\varepsilon>0$ and find $M_1\in \mathbb R$ such that if $x\in S$ and $x\geq M_1$ then $$|f(x)-L_1|<\varepsilon/2.$$ Also find $M_2\in \mathbb R$ such that if $x\in S$ and $x\geq M_2$ then $$|f(x)-L_2|<\varepsilon/2.$$ Now, put $M=\max\{M_1,M_2\}$ . Suppose $x\in S$ and $x\geq M$ (such $x$ exists since $\infty$ is a cluster point of $S$ ). Then $$|L_1-L_2|=|L_1-f(x)+f(x)-L_2|\leq |L_1-f(x)|+ |f(x)-L_2|<\varepsilon/2 + \varepsilon/2 = \varepsilon.$$ As $|L_1-L_2|<\varepsilon$ for arbitrary $\varepsilon>0$ . Then $L_1=L_2$ . $\blacksquare$ Do you think this argument is correct? Any help will be appreciated! Thanks in advanced.","['limits', 'solution-verification', 'infinity', 'real-analysis']"
4372646,Solution verification. Extension of a series,"I'm trying to follow this argument but with a slight difference: Continuation of series using Cahen-Mellin integral. I start with $\Phi(s)=\sum_{n=1}^\infty e^{-n^s},$ which converges iff $s>0$ is real. Applying the Mellin inversion theorem we have that: $$e^{\frac{1}{\ln(x)}}=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}x^{-z}~dz$$ Where $K$ is a modified Bessel function of the second kind. Then letting $x=e^{-n^{-s}}$ we have: $$\Phi(s)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}\bigg(\sum_{n=1}^\infty e^{zn^{-s}}\bigg)~dz$$ Am I on the right track? How do I get to the solution?","['complex-analysis', 'contour-integration', 'solution-verification', 'sequences-and-series', 'residue-calculus']"
4372669,Why should I only pick the positive number for $C$ in this IVP (separable differential equation)?,"I'm practicing some problems for an upcoming DEs test. I tried the following initial value problem: $\displaystyle\frac{1}{2}\displaystyle\frac{dy}{dx}=\sqrt{y+1}\cos x,y(\pi)=0$ Here's my work: $\begin{align}
\displaystyle\frac{1}{2}\displaystyle\frac{dy}{dx}&=\sqrt{y+1}\cos x \\
\int\displaystyle\frac{dy}{\sqrt{y+1}}&=\int 2\cos x\,dx \\
2\sqrt{y+1}&=2\sin x+c_1 \\
\sqrt{y+1}&=\sin x + C \\
y+1&=(\sin x + C)^2
\end{align}$ Plugging in the initial value I get: $\begin{align}
0+1&=(\sin\pi+C)^2\\
C^2&=1 \\
C&=\pm 1
\end{align}$ So the final answer I got was $y=(\sin x \pm 1)^2-1$ , but the solution in the textbook was $y=(\sin x +1)^2-1$ . Why did they only pick $+1$ as an answer for $C$ ?","['initial-value-problems', 'ordinary-differential-equations']"
4372725,"If $\sec x=\frac{a}{b}$, find the exact value of $\cot x-\frac1{\sin x}$, for positive $a$ and $b$, and for $x\in(\frac{3\pi}{2},2\pi)$","If $\sec(x) = \frac{a}{b}$ , find the exact value of $$\cot(x) - \frac{1}{\sin(x)}$$ and $a$ , $b$ are positive real values and $x\in(\frac{3\pi}{2},2\pi)$ I know that $\sec(x) = \frac{1}{\cos(x)}, $ so: $\cos(x) = \frac{b}{a}$ I used the right angled triangle to find the third side, which is $\sqrt{a^2-b^2}$ I used reciprocal functions of $\tan$ and $\sin$ to obtain the values: $cosec(x) = \frac{a}{(\sqrt{a^2-b^2})}$ and $\cot(x) = \frac{b}{\sqrt{a^2-b^2}}$ and finally getting $\frac{(b-a)}{\sqrt{a^2-b^2}}$ as my answer. But that is not correct.
The correct answer is: $\frac{\sqrt{a^2-b^2}}{a+b}$ . Now I am wondering how.","['algebra-precalculus', 'trigonometry']"
4372755,Central limit theorem with Limits?,"Let $X_1,X_2, . . .$ be an i.i.d. sequence of random variables with $E[X_1] = 1/2$ and $\operatorname{Var}[X_i] = 2$ . I want to Compute: $$P\left(\lim_{n\to\infty} (X_1+X_2+...+X_n)/n > 1\right)$$ My try: $P(\lim_{n->\infty} (X1+X2+...)/n > 1) = 1-P(\lim_{n->\infty} (X1+X2+...)/n \leq 1) = 1-P(\lim_{n->\infty} ((X1+X2+...)/n-1/2)\sqrt{2/n} \leq (1/2)/\sqrt{2/n})$ as I know that: $((X1+X2+...)/n-1/2)\sqrt{2/n}~N(0,1)$ From Central limit theorem. But my problem is the limit inside. My Questions: How can I continue from here Is there a way to solve this exactly without using Central limit theorem?","['probability-distributions', 'functions', 'limits', 'probability-theory', 'probability']"
4372811,"If sequence $a_n>0$ is decreasing to $0$ and $\sum_{k=1}^\infty a_n=\infty$, prove $\sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty$","If sequence $a_n>0$ is decreasing to $0$ for all $n\geq 1$ and $\sum_{n=1}^\infty a_n=\infty$ , is it always true that $\sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty$ , where $S_n=\sum_{k=1}^na_k$ is the partial sum? If yes, how to prove; if no, is there any counterexample? I have tried $a_n=\frac{1}{n}$ , in that case $e^{S_n}\sim n$ when $n$ is large, so $\sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n^2}<\infty$ . I also tried $a_n=\frac{1}{n\ln n}$ , in this case $e^{S_n}\sim \ln n$ when $n$ is large, so $\sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n(\ln n)^2}<\infty$ by Cauchy condensation test.","['sequences-and-series', 'analysis', 'real-analysis']"
4372859,Evaluate $\lim\limits_{n \to \infty}\left(\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)-2n\right)$,"Evaluate $\lim\limits_{n \to \infty}\left(\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)-2n\right)$ . By plugging in large values for $n$ , I noticed that the limit is most likely $\frac{2}{3}$ , but I can't prove it. Update Over a year has passed since I asked this question, but recently it was closed out of the blue because it lacks additional context. So let me explain where this limit comes from. I was studying the following problem: Let's consider a sequence of random numbers. Each number is uniformly distributed between $0$ and $1$ . We add up the terms of this sequence one by one until their sum exceeds a certain number $x \in \mathbb{R}$ . Let $E_x$ be the expected number of terms needed for that. The original question asked for the value of $E_1$ , which turns out to be $e$ . After I solved this by using differential equations, I wanted to find a formula for all $E_x$ . Before I had found one, I thought: ""Well, each term of the sequence increases the sum by an expected value of $\frac{1}{2}$ , so the sum should exceed $x$ after roughly $2x$ "" terms. For large $x$ , this approximation should get better and $E_x$ will get closer and closer to $2x$ ."" In other words, I thought that $\lim\limits_{x \to \infty}\left(E_x-2x\right)=0$ . This turned out to be wrong later. Finding a nice formula for $E_x$ is not easy and the only explicit formula I could come up with was a piecewise-defined function with infinitely many pieces. The first piece ranges from $0$ to $1$ , the second from $1$ to $2$ , the third from $2$ to $3$ , and so on. This makes it really hard to evaluate the limit, so I decided to look at only integer values of $x$ . And indeed, you can find a nice for those, namely: $$E_n=\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)$$ Plugging this into $\lim\limits_{x \to \infty}\left(E_x-2x\right)$ , we get the limit in the title of this question. And apparently, this limit is equal to $\frac{2}{3}$ and not $0$ . So, there you go. Hopefully, this will be enough to open this question again.","['expected-value', 'limits', 'summation']"
4372865,What's the explicit description of the atlas of quotient stack?,Let $U\to[U/G]$ be a quotient stack. How does one associate a $G$ -torsor $P\to S$ and a equivariant map $P\to U$ to each $S\to U$ ?,"['algebraic-stacks', 'algebraic-geometry']"
4372882,Prove that $\displaystyle\int_{0}^{\frac{1}{\sqrt{3}}}\frac{\arctan\left(\frac{1}{\sqrt{1-2x^2}}\right)}{1+x^2} \mathrm{dx}=\frac{13\pi^2}{288}$,"I need to prove that, $\displaystyle \tag*{} \int_{0}^{\frac{1}{\sqrt{3}}}\frac{\arctan\left(\frac{1}{\sqrt{1-2x^2}}\right)}{1+x^2} \mathrm{dx}=\frac{13\pi^2}{288}$ Here is what I tried:
I tried to solve the integral by Integrating by parts.
We have: $\displaystyle \tag{1} \int f(x) g'(x) \mathrm{ dx} = f(x)g(x) - \int f'(x) g(x) \mathrm{ dx}$ I noticed , $\displaystyle \tag*{} \dfrac{1}{1+x^2} = \arctan '(x)$ $\displaystyle \tag*{} g'(x) = \dfrac{1}{1+x^2} \Leftrightarrow g(x) = \arctan(x)$ Now, I defined $f(x)$ $\displaystyle \tag*{} f(x) = \arctan \left( \dfrac{1}{\sqrt{1-2x^2}}\right )$ and $\displaystyle \tag*{} f'(x) = \arctan'\left(\dfrac{1}{\sqrt{1-2x^2}} \right ) = \text{arccot}'(\sqrt{1-2x^2}) = \dfrac{x}{\sqrt{1-2x^2}(1-x^2)}$ Now, using $(1)$ and substituting the values of $f(x)$ and $g(x)$ , My indefinite integral becomes: $\displaystyle \tag*{} \arctan(x) \arctan \left (\dfrac{1}{\sqrt{1-2x^2}} \right ) - \int  \dfrac{x \arctan(x)}{\sqrt{1-2x^2}(1-x^2)} \mathrm{ dx}$ Now, we want to evaluate: $\displaystyle \tag*{} \int \dfrac{x \arctan(x)}{\sqrt{1-2x^2}(1-x^2)} \mathrm{ dx}$ Now this is integral I am having trouble solving. Any hints or different methods would be greatly appreciated. Thank you.","['definite-integrals', 'inverse-function', 'multivariable-calculus', 'calculus', 'trigonometric-integrals']"
4372920,Proving that SO(3) is not isomorphic to another group,"$\newcommand\R{\mathbb R} \newcommand\gl{\mathrm{Gl}} \newcommand\sl{\mathrm{SL}} \newcommand\so{\mathrm{SO}}$ How do you prove that $\gl(2,\R)/\R^*$ is not isomorphic (as abstract groups) to $\so(3,\R)$ ?
Initially I thought that because $\gl(2,\R)/\R^*$ is isomorphic to $\sl(2,\R)/\{-I,I\}$ then it is easier to look at $\sl(2,\R)$ but I am not sure anymore. Anything remarkable to know about centralizers and normalizers that could help me here? Actually I am no event sure anymore if they are not isomorphic.","['group-theory', 'group-isomorphism', 'lie-groups']"
4372945,"An abelian group whose endomorphism group $Hom(G,G)\cong \mathbb{Z}$","Let $C$ be the category of all abelian groups and $G\in ob(C)$ . When the morphism class $Hom(G,G)$ is an infinite cyclic group, I am trying to prove $G\cong \mathbb{Z}$ .  If this is true, every additive and fully faithful functor $F: C\rightarrow C$ maps an infinite cyclic group to an infinite cyclic group. If $G$ is a finitely generated abelian group, then $G$ is a finite diret sum of cyclic groups. Thus $G\cong \mathbb{Z}$ . But I don't know if this is right when $G$ is infinitely generated abelian group.","['group-theory', 'category-theory']"
4372962,How do I solve this stationary Kolmogorov Forward Equation with a Dirac Delta?,"I have the following stationary Kolmogorov Forward Equation $$ 0 = -\dfrac{\partial}{\partial_x}[axg(x)] - \lambda g(x) + \lambda \delta(x-\underline{x}),$$ where $a>0,\underline{x}>0$ and $\lambda>0$ . Basically we have an impulse at a point $\underline{x}$ and then the density flows to the right at a rate $ax$ . At each instant mass is pulled back into $\underline{x}$ at a rate $\lambda$ . If I ignore the Dirac delta I can easily solve for the density $g(x)$ by integrating the Kolomogorov Forward equation. $$g(x) = g(\underline{x})\left(\dfrac{\underline{x}}{x}\right)^{1+\frac{\lambda}{a}} $$ I then impose that all the probability mass must sum to 1 and that pins down what $g(\underline{x})$ is. $$g(\underline{x}) = \dfrac{\lambda}{a}\underline{x}^{-1}  $$ Solving this problem numerically gives me the same result as above. I have three questions. The way I solved for the stationary density completely ignores the Dirac delta term. How is that possible? A colleague mentioned that as I have an impulse at $\underline{x}$ , my density should sum to one with the mass split between $g(x)$ and a mass $m$ , where $m$ captures the Dirac impulse: $1=\int_{\underline{x}}^{\infty} g(x)dx + m$ . Is this correct, and how could the solution be obtained for the stationary density? Is it possible to have a closed form expression linking an initial condition $g(\underline{x},t=0)=\delta$ to the stationary solution $g(x,t=\infty)=\dfrac{\lambda}{\underline{x}a}\left(\dfrac{\underline{x}}{x}\right)^{1+\frac{\lambda}{a}}$ ? How the density looks:","['dirac-delta', 'ordinary-differential-equations', 'probability-distributions', 'stochastic-differential-equations', 'partial-differential-equations']"
4373023,Complex derivative vs two-variable derivative: requiring same limit from different directions,"I am trying to understand how the CR equations encode the field properties present in $\mathbb{C}$ that aren't present in $\mathbb{R^2}$ . Yes, I know their derivation involves multiplying by the inverse of a complex number, which you can't do for a vector, hence the different definition of a multivariable derivative. My question is about approaching along different paths: the crux of the CR derivation seems to involve forcing the limit of the difference quotient of two complex numbers to be the same along both the real and imaginary directions . My question is how this is different from the derivative of a function from $\mathbb{R^2}$ to $\mathbb{R^2}$ : do such function not require limits along different paths to be the same? I get that the complex derivative, as a $2 \times 2$ matrix is a special case of a general $Df$ for $f: \mathbb{R^2} \to \mathbb{R^2}$ that enforces the CR condition amongst the entries of the matrix. I have looked at this question, this question, and a few other questions, and it doesn't seem to answer the heart of my confusion: CR conditions do nothing more than enforce that limits of quotients along two orthogonal axes are the same. Are limits along different (orthogonal) paths allowed to be different in a well defined $Df$ ? Is this why complex derivatives are a stronger condition than multivariate real derivatives? I also understand that complex functions can be thought of as functions in conservative vector fields, in some analogous sense (though they are not totally isomorphic).","['complex-analysis', 'limits', 'multivariable-calculus', 'derivatives']"
4373077,Linear regression with two independent variables,"I want to consider purely theoretical situation that we have two random $\textbf{independent}$ variables $Y$ and $X$ which has $EY = EX = 0$ . Let's also consider regression $Y \sim X$ . I want to say what will be the coefficient $\beta$ in this regression associated with $X$ when we consider model with and without intercept: Model with intercept Since model has intercept we can write $\beta$ as: $$\beta = \frac{\textrm{Cov}(X, Y)}{\textrm{Var}(X)} = 0$$ So the coefficient will be $0$ , because $X, Y$ are independent (I didn't use information that $EY = EX = 0$ ) Model without intercept When we consider model without intercept, then $\beta$ is given as: $$\beta = \frac{\sum_{i = 1}^n x_iy_i}{\sum_{i = 1}^n x_i^2}$$ Which can be rewriten as: $$\beta = \frac{\sum_{i = 1}^n \frac{x_iy_i}{n}}{\sum_{i = 1}^n \frac{x_i^2}{n}} \rightarrow \frac{E[XY]}{E[X^2]} = \frac{EXEY}{E[X^2]} = 0$$ In second case, our $\beta$ will converge to $0$ , when $n$ goes to infinity. Is my justification correct?","['linear-regression', 'statistics', 'mathematical-modeling', 'probability']"
4373082,Find eigenvalues of linear operator $X \mapsto AX^TA$.,"Matrix $A$ has $n$ distinct non-zero eigenvalues, $\lambda_1, \dots, \lambda_n$ . Find the eigenvalues and eigenvectors of the linear operator $$ L : X \mapsto AX^{T}A $$ I tried to use a decomposition: $A = P\Lambda P^{-1}$ , where $\Lambda$ is diagonal matrix with $\lambda_1 \dots \lambda_n$ on its diagonal. Then, I wrote equation $L : (PXP^{-1})^{T} \rightarrow P\Lambda X\Lambda P^{-1} = \lambda (PXP^{-1})^{T}$ . So, I've got $C\Lambda X\Lambda C^{-1} = \lambda X^{T}$ , where $C= P^{T}P$ and stuck there. Edited: $X, A \in \mathbb C^{n \times n}$","['matrices', 'linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
4373093,Similar Right Triangles on Sides of Triangle and Treating BC as a Pascal Line to Obtain a Cyclic Hexagon,"Proposition. Let $ABC$ be an acute triangle. Exterior points $B’$ and $C’$ are such that $\triangle AB’B$ and $\triangle AC’C$ are similar with right angles at $B’$ and $C’$ , respectively. If $M$ is the midpoint of $BC$ and $C’M \cap AB = D$ , then $AB’DC’$ is a cyclic quadrilateral. Furthermore, if $B’M \cap AC = E$ and $B'B \cap C'C = K$ , then the points $A$ , $B'$ , $C'$ , $D$ , $E$ and $K$ are concyclic. How can I prove this? (I’m not sure what I can do to let the condition that M is a midpoint come into play.) I need this to finish off a problem:
(Serbia 2018, Drzavno VI). Let $ABC$ be an acute triangle and let $AX$ and $AY$ be rays, such that the angles $\angle XAB$ and $\angle YAC$ have no common interior point with $\bigtriangleup ABC$ and $\angle XAB = \angle YAC < 90°$ . Let $B'$ and $C'$ be feet of the perpendiculars from $B$ and $C$ to $AX$ and $AY$ , respectively. If $M$ is the midpoint of $BC$ , prove that $\overline{MB'} = \overline{MC'}$ . I wanted to show that the triangles in red are similar by proving two of the interior angles equal. As a consequence, triangles $NC’C’_R$ and $MC’B’$ would be similar as well, thus both isosceles. I’ve done it for the blue one and I need the cyclicity to be true for the other. There is perhaps an easier way to have dealt with the problem but I didn’t want to stop since I’ve reached this point. The cyclicity also seems quite nice. Is it actually well-known?","['contest-math', 'euclidean-geometry', 'geometry', 'plane-geometry']"
4373127,How to calculate the shaded area of this 1/4 circle?,"First I calculate the area of 1/4 circle, that is $\frac{1}{4}\pi.r^2=\frac{1}{4}\pi.4^2=4\pi.$ Then I know the area of each 1/2 circles inside the 1/4 circle is $\frac{1}{2}\pi.2^2=2\pi.$ But I know it's not as simple as 1/4 circle $-$ 1/2 circles inside. I'm having a hard time determining the shaded area that is the intersection of two 1/2 circles inside. Any idea of the steps for this solution? Thanks in advance.","['area', 'circles', 'geometry']"
4373157,Principal connections on $P$ and covariant derivatives on associated vector bundle $E=P\times_\rho V$,"I would like to have a concrete proof or reference to the following fact: Let $P\rightarrow M$ be a principal $G$ -bundle over an $n$ -dimensional manifold $M$ , and let $E=P\times_\rho V$ be an associated vector bundle to $P$ and the representation $\rho:G\rightarrow\text{GL}(V)$ . Then, a principal connection on $P\rightarrow M$ determines a covariant derivative $$\nabla:\Omega^0(M,E)\rightarrow\Omega^1(M,E)$$ on the associated vector bundle $E$ . Moreover, each covariant derivative on $E\rightarrow M$ can be obtained from a unique principal connection on $P\rightarrow M$ . Here by principal connection we understand an Ehresmann connection on $P$ that is $G$ -invariant on the decomposition of $TP$ . For example, in Mathematical Gauge Theory with Applications to the Standard Model of Particle Physics by Mark J. D. Hamilton, only one direction is dicussed throughout sections 8 and 9 of chapter 5, that a principal connection determines a covariant derivative via the notion of parallel transport. However, there is no further discussion on how to construct a principal connection from a covariant derivative. This, being a rather classical question, should be treated extensively somewhere . I would like to have a reference of this result, or the half that is not covered in the aforementioned book of Hamilton. Thanks in advance for your answers.","['principal-bundles', 'connections', 'reference-request', 'gauge-theory', 'differential-geometry']"
4373216,Find power series solution for $y''-xy=0$ close to $x=0$.,"Find power series solution for $y''-xy=0$ close to $x=0$ . $\sum_{n=2}^\infty n(n-1)a_nx^{n-2}-x\sum_{n=0}^\infty a_nx^n=0$ Then, $a_{n+2}(n+2)(n+1)-a_{n-1}=0 \implies a_{n+2}(n^2+3n+2)-a_{n-1}=0 \implies a_{n+3}=a_n\cdot \frac{1}{(n+3)(n+2)}$ I got two problems: $(1)$ The answer is $a_{n+3}=(n+3)(n+2)a_n$ , where am I wrong ? $(2)$ How can I find the general power series solution ?",['ordinary-differential-equations']
