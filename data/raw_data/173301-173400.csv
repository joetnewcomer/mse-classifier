question_id,title,body,tags
3084920,Convergence of gradient flow,"I am interested in a simple property of the gradient flow $$x'(t) = - \nabla f(x)$$ Under what conditions on $f$ does the gradient flow converge to a stationary point? In particular, I am interested in the simple case of $f : \mathbb{R}^n \to \mathbb{R}$ , where we know that $f$ obtains a global minimum somewhere. No assumption of convexity, we allow for arbitrarily many local minima and/or multiple global minima, saddle points, etc. It is fine if part of the conditions on the function require an assumption on the nature of these critical points (e.g. that $f$ has no degenerate saddle points, or something like that). I know that gradient flows are quite general, and PDE's can in many cases be cast as gradient flows on functionals, but I'm not interested in this level of abstraction at the moment — I'm thinking more about nonlinear optimization. I have done some looking around on the internet, but most discussions get into Morse theory, with which I have no experience, and so I've had some difficulty understanding the jargon. In addition to an answer or simple categorization of the relevant functions (if one exists), I would much appreciate a reference where I could read more about this (and in particular cite at some point) - it's okay if the reference is a bit more technical, or is on Morse theory. It's very possible that the tools of Morse theory are necessary to answer this type of question.","['gradient-flows', 'riemannian-geometry', 'ordinary-differential-equations', 'differential-geometry']"
3085038,Cycles of real functions and the derivative operator,"If you start with $\sin(x)$ and take four derivatives, you get three distinct functions and then end up back at $\sin(x)$ . For $e^{-x}$ , you take two. For $e^{x}$ , you only need to take one. Generally, I will call an N-cycle of the derivative operator a sequence of real valued functions of a real variable including $f(x)$ where, $$
\frac{d^Nf}{dx^N}=f(x)
$$ but, $$
\frac{d^mf}{dx^m}\neq f(x)
$$ for every $m$ that is not a multiple of $n$ . Over the complex numbers, these functions are simply $\exp( x\sqrt[N]1)$ . For $N=1,2,4$ there are cycles of real functions, which in the case of $N=4$ may be constructed as a linear combination of the complex functions. Can there be cycles of real functions of length other than 1,2 or 4? If so, how may they be obtained?","['ordinary-differential-equations', 'real-analysis']"
3085078,"Use the Central Limit Theorem to deduce that if $λ$ is large, then $X$ approximately has a normal distribution.","The time instants of incoming requests at a data server can be modelled with a Poisson process. Let $X$ be the number of requests in one hour and let $λ$ be the intensity (requests per hour) of the Poisson process. - Use the Central Limit Theorem to deduce that if $λ$ is large, then $X$ approximately has a normal distribution. Also specify its parameters. Can I assume that, if $X\sim\operatorname{Poisson}(\lambda)$ then: $$
\frac{X-\lambda}{\sqrt\lambda} \overset{\text{distribution}}\longrightarrow N(0,1) \text{ as } \lambda\to\infty \\  $$ It is a correct way to prove it? The parameters for the normal distribution are $\mu=0$ and $\sigma^2=1$ right?",['statistics']
3085104,Compute the Mean Squared Error of $𝑇$,"The famous biologist Henk de Rijn has come up with a skill test for chimpanzees. 
We assume that each chimpanzee has a probability $𝑝$ to pass the test, independent from previous attempts and from other monkeys. 
Let $𝑋_𝑖$ be the number of attempts that chimpanzee $𝑖$ needs to pass. Furthermore, $𝑇 = \overline{X}_𝑛$ is an estimator for $1/𝑝$ . 
Compute the mean squared error of $𝑇$ . So let $T$ be an estimator for a parameter $1∕𝑝$ . The $MSE$ of $T$ is $MSE(T)=\operatorname{Var}(T) + (E[T] − 1∕𝑝)^2$ ,  where $(E[T] − 1∕𝑝)^2$ is the bias. In this case the $E[T]=E[\overline{X}_𝑛]=\mu$ and $\operatorname{Var}(T)=\operatorname{Var}(\overline{X}_𝑛)=\dfrac{\sigma^2}{n}$ . Now my question is: which distribution should I use? I think that I think that is a Binomial but it also make sense to use a Geometric Distribution, so then the estimator $T$ will be unbiased and the $\displaystyle\operatorname{MSE}(T)=\operatorname{Var}(T)=\frac{1-p}{p^2}*\frac{1}{n}$ , is it right?",['statistics']
3085182,Using Rouché's theorem to bound zeroes of partial sums of $e^z$,"I'm having trouble with a question from an exam I'm studying for: ""
Prove that all roots of the polynomial $\sum\limits_{k=0}^n \frac{z^k}{k!}$ (for $n\geq 1$ ) are in the annulus $\{z: \frac{n}{e}<\vert z\vert<2n \}$ .
Hint: use the inequality $n^ne^{-n}<n!$ "" These kind of questions are usually solved by using Rouché's theorem, so I assume that's the case here as well, but I'm having trouble choosing the right functions to use and bounding their norms correctly. I feel like I should be comparing $e^z$ and $\left(e^z - \sum\limits_{k=0}^n \frac{z^k}{k!}\right)$ on the circle with radius $\frac{n}{e}$ since e^z has no roots there, so maybe that will imply the polynomial also has no roots there. And then maybe using some other argument to show that all the polynomial's roots are inside the larger disk of radius $2n$ .","['complex-analysis', 'rouches-theorem']"
3085184,Stapled sequences- set of consecutive positive integers such that no one of them is relatively prime with all of the others,"A stapled sequence is defined as a set of consecutive positive integers such that no one of them is relatively prime with all of the others. When I first came across this definition, I thought it wouldn't be that difficult to find an $n\in \mathbb N$ such that every set $A=\{i\in\mathbb N: j≤i≤j+n-1\}$ for some $j\in \mathbb N$ is a stapled sequence. It turned out, however, that it wasn't that trivial. I first tried to use the ""identity"" $$\text{gdc}(a,b)=\text{gcd}(a-bt,b)\;\;\forall a,b,t\in\mathbb N$$ but it took me nowhere. I then found an article which seemed to help; in the abstract of this article they assert, that there's a very simple proof to show that no stapled sequence containing $N$ consecutive positive intgers exist for any $N < 17$ . Nevertheless, I've tried to read the article and I don't find their proof trivial; I don't even understand it! (It might be worth to tell that I'm a secondary school student interested in maths). Could someone help me understand their proof or provide a own proof?","['contest-math', 'number-theory', 'coprime', 'elementary-number-theory']"
3085186,"Is there a variant of the dot-product operation that returns $\frac{a_1}{b_1} + \frac{a_2}{b_2}$ from vectors $[a_1,a_2]$ and $[b_1, b_2]$?","The dot product of $[a_1,a_2]$ and $[b_1, b_2]$ is $a_1b_1 + a_2b_2$ (and so on for bigger vectors). What I'm wondering is if there's any definition of a function s.t. the ""invdot"" product of $[a_1,a_2]$ and $[b_1, b_2]$ is $$\frac{a_1}{b_1} + \frac{a_2}{b_2}$$ If so, are there any other properties/derivations of this function from the dot product? I can see it's the same as taking the reciprocal of all the components of $b$ and then doing the dot product on that, but I can't understand how I'd do that in my specific use case. For context, I'm trying to solve a problem where I want to algebraically manipulate $a_1b_1 + a_2b_2$ to $\frac{a_1}{b_1} + \frac{a_2}{b_2}$ , and think that this might help if it's a well known operation.","['algebra-precalculus', 'linear-algebra', 'vectors']"
3085187,A coend in the category of vector spaces,"Let $Vect_k$ denote the category of (not necessarily finite-dimensional) $k$ -vector spaces. Clearly, this category is closed symmetric monoidal with internal hom $[X,Y]=Hom_k(X,Y)$ . Is it true that the coend $\int^{X\in Vect_k}\, [X,X]$ doesn't exist? I'm pretty sure that it doesn't, since in general there is no trace $tr_X:[X,X] \to k$ , but I want to be sure. What makes me uncertain is that I read that the category of $k$ -vector spaces is cocomplete..","['limits-colimits', 'monoidal-categories', 'category-theory', 'abstract-algebra', 'linear-algebra']"
3085255,What is the difference between conditional probability and a stochastic kernel?,"I have visited various sites which claim a difference between stochastic kernels and conditional probability. However, I have read a paper which treats them the same, and the Wikipedia page on transition matrices actually lists a matrix full of conditional probabilities. The page linking to it claims that a Markov-kernel ( stochastic-kernel , or probability-kernel) is simply an element of this transition matrix. This is a contradiction in literature, and I would like some clarity on
  the issue. What is the difference between a stochastic kernel and a
  conditional probability statement? It's possible they differ in generality alone, where the stochastic kernel is a specific case of conditional probability, but I haven't found any references on this.","['stochastic-processes', 'probability-theory', 'reference-request']"
3085262,Lebesgue integral of ${x^2}$,"I am having trouble calculating the Lebesgue integral of ${x^2}$ over ${]0,1]}$ . I followed the instructions from my college lessons and constructed a sequence ${f_n}:=\sum_{k=1}^{n*2^n}\frac{k-1}{2^n}*\chi{}_{A_{n,k}}$ with ${A_{n,k}:=\{ \sqrt{\frac{k-1}{2^n}} \leq x < \sqrt{\frac{k}{2^n}} \}}$ . ${\lambda(f)}$ is equal to ${sup_{n\in N}\lambda(f_n)}$ , so I calculated $\lambda(f_n)=\sum_{k=1}^{n*2^n}\frac{k-1}{2^n} * (\sqrt{\frac{k}{2^n}} - \sqrt{\frac{k-1}{2^n}})$ . However, I don't see how this is going to be equal to ${\frac{1}{3}}$ , which would be the result of a Riemann integral. Can anyone spot a mistake or point me in the right direction?","['calculus', 'lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
3085263,Is this estimate true for functionals on Frechet spaces?,"In class the other day my professor made the following claim about the Schwartz class $\mathcal S$ : Let $u: \mathcal S \to \mathbb C$ be linear. $u$ is continuous iff there exist $C,N>0$ such that for all $\varphi \in \mathcal S$ , $$|u(\varphi)| \leq C \sup_{|\alpha|,|\beta| \leq N} ||x^\alpha D^\beta \varphi||_{L^\infty}$$ where $\alpha,\beta$ denote multiindices. (so $||x^\alpha D^\beta \varphi||_{L^\infty}$ is just the $(\alpha,\beta)$ th seminorm of $\mathcal S$ ). He claims this follows immediately from uniform boundedness for Frechet spaces. I'm largely unfamiliar with this area of functional analysis, so it isn't at all clear to me. In particular, I don't see why we'd only need to use finitely many seminorms. So, is the claim Let $F$ be a Frechet space with seminorms $||\cdot||_j$ . A linear map $u: F \to \mathbb C$ is continuous iff there exist $C,N>0$ such that for all $f \in F$ , $$|u(f)| \leq  C\sup_{j \leq N}  ||f||_j$$ valid, or is this just something true for the Schwartz class? Does it follow from Banach-Steinhaus?","['topological-vector-spaces', 'functional-analysis', 'distribution-theory']"
3085293,Closed form expression for the harmonic sum $\sum\limits_{n=1}^{\infty}\frac{H_{2n}}{n^2\cdot4^n}{2n \choose n}$,"I'm wondering if one could derive a closed form expression for the series $$\sum_{n=1}^{\infty}\frac{H_{2n}}{n^2\cdot4^n}{2n \choose n}$$ $$\text{With } \text{ } \text{ } \text{ }H_n=\sum_{k=1}^{n}\frac{1}{k}\text{ } \text{ } \text{} \text{ } \text{ }\text{the } n^{th} \text{ harmonic number.}$$ Now, I know series involving harmonic numbers are well suited for a summation by part (or Abel's transformation) approach, but it doesn't lead anywere here, at least not in this state. Any suggestions ?","['definite-integrals', 'real-analysis', 'harmonic-numbers', 'binomial-coefficients', 'sequences-and-series']"
3085296,Stuck with a possibly impossible trigonometry question,"I need to find the length of the arc between Y1 and Z1 in the image below. If you can even get me to the value of Y, then that will work. I appreciate the drawing may be crude, but imagine that Y and Y1 are directly above each other, as are C, Z, Z1, and the line with A, X, Y is perfectly horizontal (i.e. perpendicular to the Y and Z lines mentioned before) I have no idea if this is even possible, and I've been stuck for over an hour so am throwing it out there to anyone who has better than High School level math than I do! UPDATE: I have been told I should look into using quadratic equations to find the two intersections of a line between a circle, and I think that should be enough to get me there. In case there's another way, I'll add some more info. This is actually based on coords of pixels on a screen. I know the coords of A, C, X, Z and Z1. I also know the lengths of R, AZ and AZ1. The only value that can change is X, although the more I look at it, the more I think it's irrelevant to my situation i.e. finding the length of the arc Y1Z1.","['trigonometry', 'angle', 'geometry']"
3085301,Inverse of a Gram matrix,"If $G$ is the Gram matrix of $n$ vectors of size $d$ that are linearly independent ( $n\leq d$ ), then $G$ is invertible and its inverse is a Gram matrix. Of what? To be more precise, if $G$ is the Gram matrix of $u_1,\ldots,u_n$ , where each $u_i\in\mathbb R^d$ and $u_1,\ldots,u_n$ are linearly independent, then there exists a collection of $n$ linearly independent vectors $v_1,\ldots,v_n$ whose $G^{-1}$ is the Gram matrix. Is there some relationship between the $u$ 's and the $v$ 's?","['matrix-calculus', 'linear-algebra']"
3085303,"""distributive property"" vs. ""ring homomorphism"": comparing definitions","The property of distributivity is defined using expressions like the following, from page one of ""Introduction to Commutative Algebra"" by Atiyah and MacDonald: $$x(y + z) = xy + xz$$ $$(y + z)x = yx + zx.$$ On the other hand, homomorphisms are defined using expressions like the following, from the definition of ring homomorphism on page two of Atiyah-MacDonald: $$f(x + y) = f(x) + f(y)$$ These expressions obviously bear some resemblance to one another, when viewed simply as strings of characters, but does this observation lead to any interesting examples or generalizations? Can the definitions be restated so as to have one subsuming the other?","['notation', 'ring-theory', 'abstract-algebra', 'ring-homomorphism']"
3085355,Why does the circle naturally divide into $6$?,"Draw a circle. Draw a new circle with center on the circumference and the same radius. Draw a new circle with center on the intersecting points and the same radius. How many circles can you fit around the original circle? 6. 6 equiliant triangles fit inside a circle, a hexagon inside the circle has the same lengts as the radius, the way the 60 degree angle is constructed. These are all saying the same thing. Why does the circle divide into 6? But why not 4, 5, 7, 8.",['geometry']
3085382,Weyl curvature of hypersurface in $\mathbb{R}^{n+1}$,"Let $M^n\subset \mathbb{R}^{n+1}$ be an embedded hypersurface and let $g$ be the metric induced on $M$ by the flat metric on $\mathbb{R}^{n+1}$ . Q: What is a formula for the Weyl tensor $W$ of $g$ in terms of the second fundamental form $A$ of $M$ ? More precisely, what is $|W|^2$ ? For example, the scalar curvature $S$ of $g$ can be written as $$
S=H^2-|A|^2=\mathrm{trace}(A)^2-\mathrm{trace}(A^2)=\sum_{1\leq i_1<i_2\leq n}\lambda_{i_1}\lambda_{i_2},
$$ where $H$ is the mean curvature (trace of $A$ ) and $\lambda_1,\dots,\lambda_n\in \mathbb{R}$ are the principal curvatures of $M$ , i.e. the eigenvalues of $A$ . Note that $S$ is thus an elementary symmetric polynomial in $\lambda_1,\dots,\lambda_n$ . Is $|W|^2$ also given by such a polynomial? I guess this is probably not true as $|W|^2$ is zero for any 2-manifold (all surfaces are locally conformally flat).","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3085389,Does $L_1$ convergence of continuous functions imply pointwise convergence?,"Suppose that $(f_n)$ is a sequence in $C[0,1]$ which is convergent with respect to the $L_1$ norm.  Then is $(f_n(x))$ necessarily convergent for all $x\in[0,1]$ ? I'm pretty sure the answer is no, but I'm not aware of a counterexample.","['examples-counterexamples', 'lp-spaces', 'functional-analysis', 'convergence-divergence', 'pointwise-convergence']"
3085442,Challenging probability problem (AMC 12B Problem 18) - Are the AoPS solutions incomplete/wrong?,"The problem A frog makes $3$ jumps, each exactly $1$ meter long. The directions of the jumps are chosen independently at random. What is the probability that the frog's final position is no more than $1$ meter from its starting position? Background This problem comes from the AMC $12$ in the year $2010$ . The contest is an invitational test in the US for secondary school to qualify for the Olympiad. It involves $25$ questions in $75$ minutes and problems can be solved without calculus. I didn't get very far in my attempt, so I ultimately searched and found contributed solutions on the Art of Problem Solving . I don't understand ""solution $1$ "" and I am pretty sure ""solution $2$ "" is incorrect. Possible solution $1$ : random additions/subtractions Let $a$ , $b$ , and $c$ be complex numbers of magnitude one and let the frog start on the origin. Consider the 4 equally likely options of adding or subtracting $b$ and $c$ $$ {|a+b+c|,|a+b-c|,|a-b+c|,|a-b-c|} $$ The AoPS solution states ""it is relatively easy"" to show exactly $1$ of these has magnitude $1$ or less. If so, then out of $4$ possible options, there would be $1$ with magnitude $1$ or less, so the probability would be $1/4$ (the corrrect answer is indeed $1/4$ , but this method does not satisfy me yet). I did not understand this step, and someone asked the same question in a previous thread . It's not obvious to me, and I have no clue how you would go about showing this. Is there an inequality that will help? I don't see how to simplify it. Also the official solution is much more complicated (see sketch below), which makes me think this solution is either elegant and overlooked or it is coincidentally the correct number but not the correct method. (Upon further thought, it seems $a = (1, 0), b = (0, 1), c = (-1, 0)$ would be a counter-example as $|a + b + c| = 1 = |a - b + c|$ so both are within 1.) Possible solution 2: geometric probability The solution goes like this. Suppose the first jump is from the origin. So to be $1$ unit from the starting point, you need to be in the unit circle. The next two jumps can be $2$ units after the first jump, equally likely to be in any angle. So the sample space of ending points is a circle of radius $2$ centered at the point of the first jump. This circle is also tangent to the unit circle. Thus the sample space has an area of $4\pi$ , of which the area of the unit circle is $\pi$ . Hence the probability is $1/4$ . I am pretty sure this method is incorrect because I simulated $2$ jumps numerically. You do get a circle of $2$ , but not all points are equally likely. There is clustering to the center of the circle and the circumference of the circle. Plus if this method was true, it would seem that $3$ jumps should be a circle of radius $3$ , but that would imply a totally different answer of $1/9$ . The official solution I found a pdf on the following website, see problem $18$ : http://web2.slc.qc.ca/sh/Contest/AMC12_2010B-S.pdf Let me try to summarize the method... The idea is to set coordinates so the first jump is $(0, 0)$ and the second jump is $(1, 0)$ . Let the starting point be $(\cos \alpha, \sin \alpha)$ and then the location after the third jump is $(1 + \cos \beta, \sin \beta)$ . It is not too hard to work out the condition for the third point to be within $1$ unit of the first point. Ignoring the measure $0$ cases of $\alpha = 0$ and $\alpha = \pi$ , we need $\alpha \leq \beta \leq \pi$ . We can limit to $0 \leq \alpha \leq \pi$ since the other half works out the same by symmetry. And we have $0 \leq \beta \leq 2\pi$ . (Check out this interactive graph on Desmos to see why $\alpha \leq \beta \leq \pi$ : https://www.desmos.com/calculator/egwegf8utr ) Considering a rectangle $(\alpha, \beta)$ where all angles are equally likely, the sample space is the rectangle of area $2\pi$ . The event to be within 1 is a triangle with area $\pi/2$ , so the desired probability is $1/4$ . Are the AoPS solutions incomplete? I would love if their ""solution $1$ "" is correct as it's much easier to compute and it be more reasonable for an average time allotment of $3$ minutes/problem. (Honestly you could give me unlimited time and I'm not sure I would have produced the official solution.) What do you guys think? Disclosure I run the YouTube channel MindYourDecisions , and am considering this problem. If I make a video I'll credit anyone who offers helpful answers.","['contest-math', 'probability']"
3085480,"From an urn containing a white and b black balls, balls are successively drawn without replacement until only those of the same colour are left.","From an urn containing a white and b black balls, balls are successively drawn without replacement until only those of the same colour are left. What is the probability that balls left are white? This is what I have done.
( https://i.sstatic.net/CZH2x.jpg ) But the answer which is given is : a/(a+b) I can't possibly make out how it's happening.",['probability']
3085483,"Suppose $M_1, \dots M_k$ are smooth manifolds, then each of the projection maps $\pi_i : M_1 \times \dots \times M_k \to M_i$ is a submersion","Suppose $M_1, \dots M_k$ are smooth manifolds of dimensions $n_1, \dots, n_k$ respectively, then each of the projection maps $\pi_i : M_1 \times \dots \times M_k \to M_i$ is a smooth submersion This was my attempted proof: Proof: Let $M = M_1 \times \dots M_k$ and let $p = (p_1, \dots, p_k) \in M$ choose a smooth chart $(U, \phi)$ containing $p$ . Then $U = U_1 \times \dots \times U_k$ and $\phi = \phi_1 \times \dots \times \phi_k$ where each $(U_j, \phi_j)$ is a smooth chart in $M_j$ . Also note that $\phi = \phi_1 \times \dots \times \phi_k$ means that $\phi(p_1, \dots, p_k) = (\phi_1(p_1), \dots, \phi_k(p_k)) = \left(\phi_1 \times \dots \times \phi_k\right)(p_1, \dots, p_k)$ . Let's now compute the local coordinate representation of $\widehat{\pi_i}$ , this is given by $\widehat{\pi_i} = \phi_i \circ \pi_i \circ \phi^{-1} : \phi[U] \to \phi_i[U_i]$ . Observe that $\phi^{-1} = \phi_1^{-1} \times \dots \times \phi_k^{-1}$ . Letting $(x^1, \dots, x^{n_i})$ denote the component functions of $\phi_i$ we have \begin{align*}\widehat{\pi_i}(x^1, \dots, x^{n_1 + \dots + n_k}) &= \phi_i\bigg(\pi_i\big(\phi_1^{-1}(x^1, \dots, x^{n_1 + \dots + n_k}), \dots, \phi_k^{-1}(x^1, \dots, x^{n_1 + \dots + n_k})\big)\bigg) \\
&=\phi_i\bigg( \phi_i^{-1}(x^1, \dots, x^{n_1 + \dots + n_k})\bigg)
\\
&=(x^1, \dots, x^{n_1 + \dots + n_k})
\end{align*} Then $d\widehat{\pi}_{\phi(p)}$ is represented by the Jacobian matrix of $\widehat{\pi_i}$ at $\phi(p)$ and computing the Jacobian matrix for $\widehat{\pi_i}$ we see that $$d\widehat{\pi}_{\phi(p)} =  \begin{bmatrix} 
    I & 0  \\
    0 & 0\\
    \end{bmatrix}$$ with $n_i$ many $1$ 's down the main diagonal. Thus since $d(\pi_i)_p = d(\widehat{\pi_i})_{\phi(p)}$ in the chart $(U, \phi)$ we have $\operatorname{rank}d(\pi_i)_p = \operatorname{rank}d(\widehat{\pi_i})_{\phi(p)} = n_i = \operatorname{dim}T_{p_i} M_i$ hence $d(\pi_i)_p$ is surjective and thus $\pi_i$ is a smooth submersion. $\square$ Is my proof correct? If not where have I gone wrong?","['proof-verification', 'differential-geometry']"
3085491,$\alpha$-Hölder continuous holomorphic function on the unit disk,"Suppose $f \colon \mathbb{D} \to \mathbb{C}$ is a holomorphic function on the unit disk such that for some $C > 0$ and $\alpha \in (0,1)$ we have $$\vert f(z) - f(w) \vert \leq C \vert z - w \vert^{\alpha}$$ for all $z,w \in \mathbb{C}$ . Show that $$\vert f'(z) \vert \leq A\vert 1 - \vert z \vert \vert^{\alpha - 1}$$ for some constant $A > 0$ depending only on $C$ . Dividing both sides of the given inequality by $\vert z - w \vert$ we get $$\frac{\vert f(z) - f(w) \vert}{\vert z - w\vert} \leq C\vert z - w \vert^{\alpha - 1} \leq C \vert \vert z \vert - \vert w \vert \vert^{\alpha - 1}.$$ It seems like we want to replace the $w$ on the right-hand side by $1$ somehow and replace the left-hand side by some constant multiple of $\vert f'(z) \vert$ , but I'm not sure how to do this. I would appreciate hints over full solutions.",['complex-analysis']
3085561,Harnack Inequality for nonnegative subsolutions to uniformly elliptic PDE,"I am trying to prove a Harnack inequality for a nonnegative subsolution $u \in H^1(B_2)$ to the PDE $\text{div}(A Du) \ge 0$ ,where $A = A(x)$ is uniformly elliptic. The proof outline I am following is from a set of notes by a professor at my university, and the key step is the following inductive scheme: Set $x_0$ to be a point such that $$u(x_0) = \sup_{B_{(0,1/2)}} u,$$ and choose $x_k$ inductively such that $x_{k+1}$ is such that $$u(x_{k+1}) = \sup_{B(x_k, r_k)} u$$ for $r_k$ sufficiently small to be chosen in a moment. I have all of the steps except the following: suppose $$\frac{\text{sup}_{B_{0,1/4}} u}{ u(0)}$$ is sufficiently large, then we can choose a sequence $r_k$ such that $\sum r_k <1/2$ and a $\beta>1$ such that $u(x_{k+1}) \ge \beta u(x_k)$ . That this would imply the result is immediate because it would contradict the boundedness of $u$ . The preceding step, which I am led to believe is what implies the claim, is the following: $$u(x_{k+1}) \ge \frac{u(x_k) - cr_k^{-q} u(0)}{1-\theta}$$ where $c$ , $q$ are absolute constants, and $1-\theta \ge \text{osc}_{B_1}u>0$ and $0<\theta \le \inf_{B_1} u$ . Here $c,q>0$ are absolute constants. I basically don't know what to do with this. Even if I assume the ratio in question gets very large, the estimate (from the prior step) becomes useless as $r_k \to 0$ . So it's unclear to me how to use it infinitely many times. I have the Nash-Digiorgi Holder regularity theorem at my disposal. Any hints or references would be much appreciated! I cannot find a similar proof anywhere, and given that I have provided the details for all of the other (numerous) steps, I would like to complete it.","['elliptic-equations', 'analysis', 'real-analysis', 'functional-analysis', 'partial-differential-equations']"
3085568,Is the uniqueness of the additive neutral element sufficient to prove x+z=x implies z=0?,"The following was originally stated for n-tuples of elements from a scalar field, so most of the properties of ""vectors"" are easily established from the properties of the underlying scalar field.  But the authors seem to want their development to be ""self-reliant"".  For this reason I have replaced ""n-tuple"" with ""vector"". The equality relation for vectors has been established, as have the
associative and commutative laws of vector addition. The next property
of vector addition to be introduced is the neutral element: There exists a vector $\mathfrak{0}$ such that $\mathfrak{x}+\mathfrak{0}=\mathfrak{x}$ for every $\mathfrak{x}$ . It follows there can be only one neutral element, for if $\mathfrak{0}$ and $\mathfrak{0}^{\prime}$ were
two such elements we would have $\mathfrak{0}^{\prime}+\mathfrak{0}=\mathfrak{0}^{\prime}$ and $\mathfrak{0}+\mathfrak{0}^{\prime}=\mathfrak{0},$ so that by the commutative law of vector addition and the transitivity of vector equality we would have $\mathfrak{0}=\mathfrak{0}^{\prime}.$ Now suppose that for some $\mathfrak{x}$ we have $\mathfrak{x}+\mathfrak{z}=\mathfrak{x}.$ Do we have enough to prove that $\mathfrak{z}=\mathfrak{0}?$ I note in particular that the proof of the uniqueness of $\mathfrak{0}$ relies on the assumption that $\mathfrak{x}+\mathfrak{0}^{\prime}=\mathfrak{x}$ holds for all vectors, and thereby for $\mathfrak{x}=\mathfrak{0}$ . That assumption comes from the definition of $\mathfrak{0}$ satisfying $\mathfrak{x}+\mathfrak{0}=\mathfrak{x}$ for every vector, and the assumption that $\mathfrak{0}^\prime$ is also 'such an element'. Also note that the additive inverses have not yet been introduced.","['group-theory', 'proof-verification', 'vector-spaces']"
3085628,A power series $\sum_{n = 0}^\infty a_nx^n$ such that $\sum_{n=0}^\infty a_n= +\infty$ but $\lim_{x \to 1} \sum_{n = 0}^\infty a_nx^n \ne \infty$,"Let's consider the power series $\sum_{n = 0}^{\infty} a_nx^n $ with radius of convergence $1$ . Moreover let's suppose that : $\sum_{n = 0}^{\infty} a_n= +\infty$ . Then I would like to find a sequence $(a_n)_{n \in \mathbb{N}} \subseteq \mathbb{R}^{\mathbb{N}}$ that respect the above condition and such that : $$\lim_{x \to 1, x < 1} \sum_{n = 0}^\infty a_nx^n \ne +\infty$$ First I've noticed that $a_n$ can't be a positive sequence, since if it was the case we would have for all $N$ : $$\lim_{x \to 1} \sum_{n = 0}^\infty a_nx^n \geq \sum_{n = 0}^N a_n$$ Hence we need some of the $a_n$ to be negative.
Moreover I need to use the assumption that the sum at $x = 1$ diverges, because if the sum at $x = 1$ converges then Abel's theorem says that the limit at $x \to 1$ and the sum of the power series at $x = 1$ are equal. Thank you.","['power-series', 'calculus', 'summation', 'real-analysis']"
3085699,"Evaluate $\int_0^1 \frac{\ln (1 - x) \ln (1 + x)}{x} \, dx$","I was playing around with trying to prove the following alternating Euler sum: $$\sum_{n = 1}^\infty \frac{(-1)^n H_n}{n^2} = -\frac{5}{8} \zeta (3).$$ Here $H_n$ is the Harmonic number . At least two different proofs for this result that I could find can be seen here and here . Embarking on an alternative proof I did the following. From the integral representation for the Harmonic number of $$H_n = \int_0^1 \frac{1 - x^n}{1 - x} \, dx$$ I rewrote the alternating Euler sum as \begin{align}
\sum_{n = 1}^\infty \frac{(-1)^n H_n}{n^2} &= \int_0^1 \frac{1}{1 - x} \left [\sum_{n = 1}^\infty \frac{(-1)^n}{n^2} - \sum_{n = 1}^\infty \frac{(-1)^n x^n}{n^2} \right ]\\
&= \int_0^1 \frac{-\pi^2/12 - \operatorname{Li}_2 (-x)}{1 - x} \, dx\\
&= \int_0^1 \frac{\ln (1 - x) \ln (1 + x)}{x} \, dx,
\end{align} where integration by parts has been used. I expect this last integral can be knocked over with relative easy but I have been going around in circles now for quite some time without any success. So my question is, how can this last integral be evaluated (a real method is preferred) that does not rely on the alternating Euler sum I started out with?","['integration', 'improper-integrals', 'euler-sums', 'definite-integrals']"
3085709,Constructive proof of the Banach-Alaouglu theorem,"Is there a constructive (i.e., not using Axiom of choice, and at most Axiom of dependent choice) proof of the Banach-Alaoglu theorem in the case of separable Banach spaces? Even if it is needed assume that the dual is separable. Under even more assumptions - is there such a proof for infinite-dimensional Banach spaces. We know such proof exists for Hahn-Banach in the separable case.","['banach-spaces', 'separable-spaces', 'reverse-math', 'functional-analysis', 'axiom-of-choice']"
3085741,Evaluating $\sum_{n=1}^\infty \frac{\sin(nx)}{n}$ without integrating $\sum_{n=1}^\infty e^{nx}$,I am looking for alternative solutions for finding this sum $$\sum_{n=1}^\infty \frac{\sin(nx)}{n} $$ My solution proceeds by integrating $$\sum_{n=1}^\infty e^{nx}=\frac{e^{ix}}{1-e^{ix}}$$ With suitable limits and then taking the imaginary part of it.,"['integration', 'trigonometry', 'summation', 'sequences-and-series']"
3085787,Solve ODE using Fourier series.,"I have that $$f(x)=\frac{4}{3}+\frac{2}{\pi^2}\sum_{n\in\mathbb{Z}}\frac{(-1)^n(1+i\pi
 n)}{n^2}e^{i\pi n x}, \quad n\neq0\tag1$$ and I want to find a 2-periodic function $y(x)$ that solves the
  following diff-equation $$2y''-y'-y=f(x).\tag{2}$$ Since $(1)$ is a linear ODE I know that it's solution is of the form $y(x)=y_h+y_p.$ Finding $y_h$ is trivial and done by solving the characteristic equation. I found it to be $y_h=C_1e^x+C_2e^{-x/2}.$ For $y_p$ , I need to use $f(x)$ somehow, I could not find any good example in the book on how to do this. I only found one video on youtube but it does not really seem to be that similar to my problem. I want to follow the answer in this thread but I can't seem to grasp the mechanics of what he means. Can someone show me how to go about this?","['fourier-series', 'fourier-analysis', 'ordinary-differential-equations']"
3085791,Solution of advanced functional differential equation,"Statement Consider an advanced functional differential equation $$
Lf(x) = f(2x+\pi)+f(2x-\pi),\quad 
L\equiv\frac{d^2}{dx^2}+1. \tag{1}
$$ Let's construct a solution of Eq. $(1)$ with finite support $I\equiv\operatorname{supp}f=\bigl[-\pi,\,\pi\bigr].$ Notation: Denote solution as $\lambda(x),$ i.e. $\lambda(x)\equiv f(x).$ Solution Applying Fourier transform to $(1)$ after some algebra an expression of a spectrum can be obtained $$
\hat{\lambda}(t)=\prod\limits_{k=0}^{\infty}\frac{\cos\Bigl(\frac{\pi}{2}\cdot t\cdot 2^{-k}\bigr)}{1-(t\cdot 2^{-k})^2}. \tag{2}
$$ Expression $(2)$ transforms into a simpler one as well $$
\hat{\lambda}(t) = \operatorname{sinc}(\pi\cdot t)\cdot\prod\limits_{k=0}^{\infty}\frac{1}{1-(t\cdot 2^{-k})^2}. \tag{3}
$$ Solution of $(1)$ is defined by inverse Fourier transform $$
\lambda(x)=\frac{1}{2\pi}\int\limits_{\mathbb{R}}e^{itx}\cdot\hat{\lambda}(t)\,dt. \tag{4}
$$ Computation Consider an approximation of $\lambda(x)$ by lacunary Fourier series $$
\lambda(x) = \frac{a_0}{2} + \sum\limits_{k=0}^{\infty}a_{2^k}\cos(2^kx).
\tag{5}
$$ Note, that $$
a_n = \dfrac{1}{\pi}\int\limits_{I}\lambda(x)\cos(nx)\,dx = \dfrac{1}{\pi}\hat{\lambda}(n).
\tag{6}
$$ Function $\hat{\lambda}(t)$ does not vanish only at points $n=2^k,\,k=0,1,\ldots,$ and $$
a_{2^k} = \dfrac{1}{\pi}\lim_{t\rightarrow 2^k}\hat{\lambda}(t).
\tag{7}
$$ Values of first several coefficients are as follows $$
\mathbf{a}=(a_0,\,a_1,\,a_2,\,a_4,\,a_8)=\biggl(\frac1\pi,\,2.3\cdot10^{-1},\,7.7\cdot10^{-2},\,-5.1\cdot10^{-3},\, 8.1\cdot10^{-5},\,-3.2\cdot10^{-7}\biggr)
$$ Plot of $\lambda(x)$ graph by $(5)$ with $5$ terms approximation $\mathbf{a}$ is a blue line, first derivative $\lambda'(x)$ (orange), and second derivative $\lambda''(x)$ (green) are shown in the figure Questions Does a rectangular function function $\chi_{I}(x)$ , which is also a characteristic function of the interval $I$ satisfy the Eq. $(1)?$ How to construct a fast convergence algorithm to compute values of $f(x)$ , like a proposed one ? Derivation an exact expression of $a_{2^k}$ in (7)? Discussion The problem above is related to the problem of Recursive Integration over Piecewise Polynomials: Closed form? and the form of Eq. (1) close to the Fabius equation . Reference Kolodyazhny, V.M., Rvachov, V.A. Cybern Syst Anal (2007) 43: 893 (page 898). 
DOI: https://doi.org/10.1007/s10559-007-0114-y","['integration', 'functional-equations', 'fourier-analysis', 'recurrence-relations', 'fractals']"
3085853,Infinite series problem,"The sum of $$\frac{2}{4-1}+\frac{2^2}{4^2-1}+\frac{2^4}{4^4-1}+\cdots \cdots $$ Try: write it as $$S = \sum^{\infty}_{r=0}\frac{2^{2^{r}}}{2^{2^{r+1}}-1}=\sum^{\infty}_{r=0}\frac{2^{2^r}-1+1}{(2^{2^r}-1)(2^{2^r}+1)}$$ d not know how to solve from here, could some help me to solve it, Thanks",['sequences-and-series']
3085857,What natural ways of partitioning a group $G$ are there?,"What natural, or at least useful, ways are there to partition a finite group $G$ ? The two examples that come to mind are: Partitioning $G$ into all the left (or right) cosets of a subgroup $H$ of $G$ . Partitioning $G$ into all its conjugacy classes.","['set-partition', 'finite-groups', 'big-list', 'abstract-algebra', 'group-theory']"
3085898,Functional equation involving $f(x^4)+f(x^2)+f(x)$,"Find all increasing functions $f$ from positive reals to positive reals satisfying $f(x^4) + f(x^2) + f(x) = x^4 + x^2 + x$ . It's easy to show that $f(1)=1$ , and I was also able to show that $$f(x)-x = f(x^{(8^k)}) - x^{(8^k)}$$ for all integers $k$ . But where to go from here? Any hints would be much appreciated.","['functional-equations', 'real-analysis']"
3085919,Chern classes of symplectic manifolds,"I have seen that people assign chern classes to the tangent bundle of symplectic manifolds. This confuses me, because to my knowledge chern classes detect differences in the complex structures of vector bundles. I know that there is a canonical way to assign almost complex structures $J$ to symplectic manifolds $(M,\omega)$ . However, this mechnism seems to depend on a choice of metric $g$ . (This is because locally there exists a matrix $A$ such that $\omega(v,w)=g(Av,w)$ and we can define a complex structure $J=Q^{-1} A$ where $Q^2=-A^2$ .) So why is this well defined?","['complex-geometry', 'definition', 'symplectic-geometry', 'differential-geometry']"
3086012,"What's going on when we compute $d(\gamma(z)) = \frac{1}{|cz+d|^2}dz$, where $\gamma \in \operatorname{SL}_2(\mathbb Z)$","Let $\gamma = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \operatorname{SL}_2(\mathbb Z)$ .  Consider the space $\Omega^1(\mathbb H)$ of smooth complex $1$ -forms on $\mathbb H$ .  These consist of all smooth sections of $\mathbb H$ into the complexified tangent bundle of $\mathbb H$ , written formally as $$\omega = f(x,y)dx + g(x,y)dy$$ for $f, g$ smooth complex valued functions on $\mathbb H$ .  In particular, we have the holomorphic differential forms, given by $h(x,y)dz$ , where $dz = dx + i dy$ , and $h$ holomorphic on $\mathbb H$ . Since $\gamma$ induces a diffeomorphism of $\mathbb H$ to itself, it induces a diffeomorphism on the tangent bundle of $\mathbb H$ to itself, and therefore an automorphism of $\Omega^1(\mathbb H)$ . We can compute the effect of $\gamma$ on the form $dz$ .  I have seen the following done: $$\gamma.(dz) = d(\gamma(z)) = d( \frac{az+b}{cz+d}) = (\frac{az+b}{cz+d})'  = \frac{1}{(cz+d)^2}dz \tag{1}$$ I don't really understand what is going on here formally with differential forms.  How do we formally justify what is happening in (1)?  I did compute the action of $\gamma$ on $dz$ and got the same answer in another way: Another way : Let's consider the map $d \gamma$ on the tangent bundle.  With our chart, we can do this by computing the Jacobian of $\gamma$ .  Writing $\gamma(x,y) = u + iv$ , and using the fact that $\gamma$ is holomorphic and $v(z) = v(x+iy) = \frac{y}{|cz+d|^2}$ , we have by the Cauchy-Riemann equations that $$d \gamma = \begin{pmatrix} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} = \begin{pmatrix} \frac{\partial v}{\partial y} & -\frac{\partial v}{\partial x} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix}  $$ The dual map on the contangent bundle is then given by the tranpose: $$\begin{pmatrix} \frac{\partial v}{\partial y} & \frac{\partial v}{\partial x} \\ -\frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} 
 \tag{2} $$ with $$\frac{\partial v}{\partial x} = |cz+d|^{-3}(-4c^2x-4ycd)$$ $$\frac{\partial v}{\partial y} = \frac{|cz+d|^2-2y^2c^2}{|cz+d|^4} $$ Now by (2), $d \gamma$ sends $dx$ to $\frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy$ , and it sends $dy$ to $\frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy$ .  Therefore, $d \gamma$ sends $dz = dx + i dy$ to $$(\frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy) + i(-\frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy) = (\frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x})dz $$ This last expression, $\frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x}$ , is equal to $\frac{\partial v}{\partial x} + i \frac{\partial v}{\partial x} = \frac{\partial}{\partial x}(u+iv) = \frac{\partial}{\partial x}(\gamma(z)) = \gamma'(z)$ . This shows that $\gamma$ induces an automorphism on holomorphic $1$ -forms which sends $dz$ to $$dz \mapsto \gamma'(z)dz = \frac{1}{(cz+d)^2}dz$$ exactly as in (1).  But how can we justify this without going into the Cauchy-Riemann equations and Jacobian calculation?","['riemann-surfaces', 'complex-analysis', 'complex-manifolds', 'differential-forms', 'differential-geometry']"
3086014,Geometry with triangle ABC,My question is... I want to know your another solution. or I want to know if my solution is appropriate. and I’d appreciate some feedback on my work. $E$ is midpoint of $\overline{BC}$ . $\overline{AD} : \overline{DE}$ = 4:3 Find the $\overline{AF} : \overline{FC}$ .,"['euclidean-geometry', 'vectors', 'proof-verification', 'geometry', 'triangles']"
3086029,"Given a differential form $\omega$, is there a differential form $\phi$ such that $\omega\wedge\phi$ is closed?","Let $M$ be a differential manifold and $\Omega^p(M)$ the vector bundle
of $p$ -forms. My question is: Given a differential $p$ -form $\omega$ , is there a differential $q$ -form $\phi$ such that $d(\omega\wedge\phi)=0$ ? I am excluding the trivial cases when $\omega$ is already closed or when $(q+p)$ is larger or equal to the dimension of the cotangent space at a point. My question is a generalization of the integrating factor problem, where $\omega$ is a 1-form, $\phi$ is a function and $d(f\omega)$ should be exact and not only closed as I am requiring. In this question about the existence of integrating factor for 1-forms in two variables the answers say that the problem is difficult and still open, even in this simpler case. I was unable to find any reference who could be of some help in answer my question, then I would really appreciate if someone can give me some directions in the literature and, if possible, discuss some special cases
where a solution is or is not possible.","['exterior-derivative', 'smooth-manifolds', 'vector-bundles', 'closed-form', 'differential-geometry']"
3086103,ideal extension in polynomial ring over quotient field,"This is probably easy, but I can't seem to figure it out.
I have a $K$ -algebra $B$ , which is a domain and an irreducible polynomial $f \in K[x]$ .
Why does $B[x]/f$ embed in $Q(B)[x]/f$ where $Q(B)$ is the quotient field of $B$ as is said in the proof of Lemma~1 in this nice answer here math.stackexchange . I would need to show, that $Q(B)[x] f \cap B[x] = B[x]f$ wouldn't I? Or do I have forgotten a further assumption?","['integral-domain', 'algebraic-geometry', 'polynomials', 'ideals', 'commutative-algebra']"
3086145,Limit of matrix inverse: $\lim_{\lambda \to \infty} (A + \lambda I)^{-1} = \mathbf{0}$?,"Let matrix $A \in \mathbb{R}^{n\times n}$ be positive semidefinite. Is it then true to that $$
(A + \lambda I)^{-1} \to \mathbf{0} \quad (\lambda \to \infty) \quad ?
$$ If so, is the fact that $A$ is positive definite irrelevant here? My thoughts so far: $$
(A + \lambda I)^{-1} = \Big(\lambda( \frac{1}{\lambda}A + I ) \Big)^{-1} = \frac{1}{\lambda} \Big(\frac{1}{\lambda}A + I \Big)^{-1}
$$ I think that $\lim_{\lambda \to \infty} \Big( \frac{1}{\lambda}A + I \Big)^{-1} = I^{-1} = I$ , but I don't know if I can just pass the $\lim$ through the inverse $(\cdot)^{-1}$ like that. If this is the case, then $$
\lim_{\lambda \to \infty} (A + \lambda I)^{-1} = \lim_{\lambda \to \infty} (1/\lambda) \lim_{\lambda \to \infty} (A/\lambda + I)^{-1} = 0 \cdot I = \mathbf{0}
$$ as I'd like to show. Where this comes from: I'm trying to justify a claim made in an econometrics lecture. Namely, $$
\textrm{Var}(\hat{\beta}^{\textrm{ridge}}) = \sigma^2 (X^{T}X + \lambda I)^{-1} X^T X [(X^T X + \lambda I)^{-1}]^T \to \mathbf{0}
$$ where $\hat{\beta}^\textrm{ridge}$ is the ridge estimator in a linear model, $X \in \mathbb{R}^{n \times p}$ is the design matrix, and the equality is known. The limit, however, wasn't justified.","['matrices', 'limits', 'linear-algebra']"
3086162,Compute $\int_0^{\infty} \frac {1}{x^{1/3}(1+x^2)}dx$,"Compute $$I=\int_0^{\infty} \frac {1}{x^{1/3}(1+x^2)}dx$$ My attempt: $$u=x^{1/3}\implies I = 3\int_0^{\infty}\frac {u}{u^6+1}du=\frac 32\int_0^\infty \frac {1}{u^3+1}du=\frac 32 \int_0^\infty \frac {1}{(x+1)(x^2+x+1)}dx\\\implies I=\frac 32 \int_0^{\infty} \frac 1{x+1}-\frac x{x^2+x+1}dx$$ And I'm stuck here, what can I do from here?","['integration', 'improper-integrals', 'definite-integrals']"
3086196,Elementary problems solved with Functional Analysis,"Many times people come and ask me what Functional Analysis is used for and why it's interesting. Of course interest is a matter of taste, and I for one love the subject as it is. There are far reaching applications to Physics, PDE, other areas of analysis and other advanced subjects that I wouldn't be able to demonstrate say to a first or even second year undergraduate student. What about examples that can be stated in very simple terms, and are somehow ""familiar"" to the broader audience? I am not aware of classical or definitive examples, so I wanted to ask: What are some (preferably mathematical) applications of Functional Analysis, that are as elementary as possible?","['reference-request', 'soft-question', 'functional-analysis', 'real-analysis']"
3086218,Homogeneous or non - homogeneous $?$,"The second order differential equation is given by - $ \frac{d^{2}y}{dx^{2}} + \sin (x+y) = \sin x$ Is this a homogeneous differential equation $?$ Well, I guess this is not a homogeneous differential equation since the form of this equation is not $a(x)y'' + b(x)y' +c(x)y = 0$ .
But the answer is given that it's homogeneous. 
How can this equation be homogeneous?",['ordinary-differential-equations']
3086279,Find path length from ODEs,"I am trying to integrate a system of differential equations. Let $p(t)$ be a path in the unit disk in the complex plane with $p(0)=0$ . Write $p(t)=r\exp(i\theta)$ for some $\theta\in[0,2\pi)$ and $r\geq0$ . Suppose $$\frac{d}{dt}p(t)=\exp(i[\theta+\phi(r)])$$ where $r=|p(t)|$ and $\phi(r)=\phi_0(1-r)$ for some constant $\phi_0$ . Also define $\frac{d}{dt}p(0)=1$ . In other words, $p(t)$ is always rotating according to its distance from the origin. I have two questions: Is there an explicit formula for $p(t)$ ? What is path length of $p(t)$ from $t=1$ to $T$ ? Below is a plot of the vector field and $p(t)$ for $\phi_0=-1.197$ .",['ordinary-differential-equations']
3086310,"'Spiky Periodic Things' - Do these objects have a name, and is there a method for finding the boundary curves?","This question was originally about evaluating the sum $\sum_{n=0}^\infty e^{nix}$ , but I figured out the answer about half way through writing it. So instead, I decided to ask a slightly different question. Now, obviously, the sum $\sum_{n=0}^\infty e^{nix}$ does not converge - however, the closure of the set of points $(x,z)$ given by $z=\sum_{n=0}^\omega e^{nix}$ is bounded for arbitrarily large $\omega$ ; the object formed by these points is well defined as $\omega\to\infty$ . This becomes clear when you break the sum into a real and imaginary part: $$\sum_{n=0}^\infty e^{nix}=\sum_{n=0}^\infty \cos{nx}+i\sum_{n=0}^\infty \sin{nx}$$ Both sums form bounded sets, and the boundary is clearly another periodic function with vertical asymptotes at integer multiples of $2\pi$ . The resulting object can be expressed (admittedly awkwardly) as a piece-wise set-valued function of a single real variable $x$ : $$r_1(x)=-\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2}\qquad r_2(x)=\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2}$$ $$m_1(x)=-\frac{1}{2}\tan{\frac{x}{4}}\qquad m_2(x)=\frac{1}{2}\cot{\frac{x}{4}}$$ $$f(x)=\begin{cases}[r_1(x),r_2(x)]+i[m_1(x),m_2(x)]&\cot{\frac{x}{4}}>0\\ \mathbb{C}&\cot{\frac{x}{4}}=0^{\pm1}\\ [r_2(x),r_1(x)]+i[m_2(x),m_1(x)]&\cot{\frac{x}{4}}<0\end{cases}$$ Using $0^{-1}=\pm\infty$ , $\quad Y_1+Y_2=\left\{y_1+y_2\mid y_1\in Y_1\land y_2\in Y_2\right\}$ , and $iY=\left\{iy\mid y\in Y\right\}$ . (If there is a more elegant way to write this, please tell me). Naturally my next question was whether or not other 'spiky summations' exist, so I played around with different periodic functions, trying to get the summation to 'converge' to a bounded shape. After experimenting for a while, it seems that there is an entire class of these objects - which have interesting geometric and statistical properties. Do these objects have a name? And is there a general method for finding the bounding curves given the summation used to generate them?","['curves', 'periodic-functions', 'sequences-and-series']"
3086352,Understand a definition,"Reading Randomized Rounding without Solving the Linear Program paper I came across this definition: Let $P$ be a convex set in $\mathbb{R}^n$ and let $f$ be a linear function (not necessarily homogeneous) from $P$ to $\mathbb{R}^m$ . Correct me if I am wrong, but $f$ is a non-homogenous function that takes a set of points in $\mathbb{R}^n$ and returns a set of points in $\mathbb{R}^m$ ?","['functions', 'linear-algebra', 'discrete-mathematics']"
3086355,Proof $\sum_{k=0}^\infty \binom{k}{n-k} = f_{n+1}$ where $f_n$ is the n-th Fibonacci-number,"In our combinatorics script it is written, that $$\sum_{k=0}^\infty \binom{k}{n-k} = f_{n+1}$$ where $f_n$ is the n-th Fibonacci-number. Apparently this can be proven through the generating function $$A(x) = \sum_{n=0}^\infty x^n \sum_{k=0}^\infty \binom{k}{n-k}$$ I've looked on stackexchange math and on the internet, but I couldn't find a proof. I know that $$\sum_{k\ge0} \binom{n-k}k=f_{n+1}$$ and it can be proven through this $$\sum_{k\ge0} \binom{n+1-k}k=\sum_{k\ge0} \binom{n-k}k + \sum_{k\ge0} \binom{n-k}{k-1}=
\sum_{k\ge0} \binom{n-k}k + \sum_{k\ge0} \binom{n-1-(k-1)}{k-1}=
\sum_{k\ge0} \binom{n-k}k + \sum_{j\ge0} \binom{n-1-j}{j}= f_{n+1}+f_n = f_{n+2}.$$ But I don't know how its done for the first case.","['fibonacci-numbers', 'proof-writing', 'combinatorics', 'binomial-coefficients']"
3086380,Defining a tricky function: $(A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B)$,"How would I define a function of the form: \begin{align*}
\phi: (A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B)
\end{align*} I know what behaviour I want, I'm just struggling to define it. For example,
consider a function \begin{align*}
&f: {0, 1} \rightarrow \mathcal{P}(\{0, 1, 2, 3\}) \\
&f(0) = \{0, 1\} \\
&f(1) = \{2, 3\} \\
\end{align*} I want $\phi(f)$ to be: \begin{align*}
&\phi(f) = \{g_1, g_2, g_3, g_4 \} \\
&g_1(0) = 0 \qquad g_1(1) = 2 \\
&g_2(0) = 0 \qquad g_2(1) = 3 \\
&g_3(0) = 1 \qquad g_3(1) = 2 \\
&g_4(0) = 1 \qquad g_4(2) = 3 \\
\end{align*} That is, I want all possible combinations of $\{0, 1\} \times \{2, 3\}$ as functions .","['elementary-set-theory', 'functions']"
3086387,Applying a function a non-integer amount of times,"Taking the principal log of a real or complex number an infinite number of times converges one of two particular values in the complex plane.  These values are $-W(-1)^*$ given a seed value with $\Im(z) \ge 0$ , and $-W(-1)$ otherwise (with $W$ being the principal branch of the Lambert W function .) While converging these values appear to ""spiral"" around this number in a way reminiscent of certain systems of differential equations. However, function application is a discrete operation, so relating the two might be a bit of a fool's errand.  I'm aware that it is possible to extend the differentiation operator in this manner.  But that may be specific to differentiation, and it might not be possible with general function application. So, is there a method for a general function?  What about the specific function log?  Is there a class of functions for which this works?",['functions']
3086455,Bounded Gradient implies Lipschitz proof with the mean value theorem,"Let $f:\mathbb{R}^n \to \mathbb{R}$ with $|| \nabla f(x)|| \leq M$ (say it is the Euclidean norm), then f is Lipschitz. I have seen proofs that do this for the case where $f:\mathbb{R} \to \mathbb{R}$ by applying the mean value theorem. I am wondering if there is a proof available that shows how the mean value theorem is applied to the problem for a function from $f:\mathbb{R}^n \to \mathbb{R}$ ?","['multivariable-calculus', 'lipschitz-functions']"
3086464,"In the derivative of the product of two functions , why (dx)² is ignored?","I was digging deeply in the fundamentals of calculus, I found that in the famous '3Blue1Brown' channel, when demonstrating the process of finding the derivative of the product of two functions , (dx) ² is ignored because it becomes so tiny when dx is going closer and closer to zero. I think that our calculus can be more precise if we don't ignore it, actually I think we shouldn't ignore it as this is math and not physics or such, the question is how our calculus is still valid and reliable if we give up even a tiny bit of precision. The following image shows the details of the demonstration:","['calculus', 'derivatives', 'products']"
3086483,What precisely does the notation $\frac {\partial h} {\partial z}$ mean in this context?,"I am given the following problem. Let $Ω\subset \mathbb{C} $ and let $h \in C^1(Ω)$ be such that $\frac {\partial h} {\partial z}=0$ . Show that $h(z)=\overline {f(z)}$ for some $f$ analytic in $Ω$ . The $\frac {\partial h} {\partial z}$ notation is mysterious to me. But, after looking at this , I have a guess as to what it means. Write $h(x+iy)=u(x,y)+iv(x,y).$ Then $\frac {\partial h} {\partial z}=\frac {[u_x+iv_x]-i[u_y+iv_y]} 2=\frac {u_x+v_y+iv_x-iu_y} 2$ . Is this interpretation correct?","['complex-analysis', 'notation', 'derivatives', 'partial-derivative']"
3086499,Showing a conditional statement is a tautology without using a truth table.,I wanted to show that [(p→q)∧(q→r)]→(p→r) is a tautology without using a truth table. This is what I got so far: [(p→q)∧(q→r)] → (p→r) => ¬[(¬p v q) ∧ (¬q v r)] v (¬pvr)  (logical equivalence) => [¬(¬p v q) v ¬(¬qvr)] v (¬pvr)  (demorgan's law) => [(p ∧ ¬q) v (q∧¬r)] v (¬pvr)  (demogran's law) I can't seem to figure out what comes after this step. Can someone help me?,"['proof-verification', 'logic', 'discrete-mathematics']"
3086545,Equilateral Triangles In The Taxicab Space,"It's fairly common to represent a unit circle in the Taxicab space ( $1$ -normed metric space) as a diamond in $\mathbb{R}^2$ with extreme points $(1,0), (0,1), (-1,0), (0,-1)$ . What will an equilateral triangle of edge length $1$ 'look like' under this norm? As a followup, how many equilateral triangles (of edge length $1$ ) can be packed in the unit circle?","['packing-problem', 'geometry', 'real-analysis']"
3086554,Show (p ∧ q) → q ≡ T by using table 6 and the first line of table 7,I used the left side to attempt to prove it was T. Chart of Laws (p ∧ q) → q ≡ T (p ∧ q) → q Using the first line in table 7 ¬(p ∧ q) v q D'Morgans Law (¬p  v ¬q) v q Associative Law ¬p     v (¬q  v q) Negation Law ¬p     v T Domination Law T ≡ T I was wondering if this is right since I felt that you can't do that with domination law. If anyone could double check thank you.,"['logic', 'discrete-mathematics']"
3086630,every prime in the form $3k+1$ can be written as the sum of a square and three times a square,i'm having trouble getting started every prime in the form $3k+1$ can be written as the sum of a square and three times a square. verify this for all appropriate primes less than $100$ . hints would be greatly appreciated!,"['elementary-number-theory', 'discrete-mathematics']"
3086655,Calc2 Finding $f'(2)$ from tangent line,"So, I have a Calc 2 problem I am stuck on. The tangent line to $h(x)$ at $x = 2$ is $3x - 2$ . It says to find $f'(2)$ given $f(x) = -3[h(x)]^2 + 2x + 2$ Any ideas on how to go about this? Thank you!","['tangent-line', 'derivatives']"
3086668,Is it possible to parameterize the model by $\Psi = \frac{1-\theta}{\theta}$ ? Prove your answer,"A random sample of $6$ observations $(X_1, X_2, \cdots, X_6)$ is generated from a Geometric( $\theta$ ), where $\theta \in (0, 1)$ unknown, but only $T = \sum_{i=1}^{6} X_i$ is observed by the statistician. (a) Describe the statistical model for the observed data ( $T$ ) (b)-(i) Is it possible to parameterize the model by $\Psi = \frac{1-\theta}{\theta}$ ? Prove your answer (b)-(ii) Is it possible to parameterize the model by $\Psi = \theta(1-\theta)$ ? Prove your answer My attempt: (a) Since geometric is iid with Negative Binomial Each $X_i$ ~ $\mathrm{Geometric}(\theta)$ therefore $T = \sum_{i=1}^{6}$ ~ $\mathrm{NegativeBinomial}(r, \theta)$ where $\theta \in (0, 1)$ unknown. The probability function for T is given by $$f_{\theta}(t) = {t +r-1\choose t}(1-\theta)^t \theta^r$$ for $t = 0,1, \cdots, 6$ parameter is $\theta$ and parameter space is $[0,1]$ (b)-(i) and (b)-(ii) I'm not sure how to do. Would I just show they are one to one by graphing each of them? Not sure","['statistics', 'probability']"
3086688,Conditional expectation of minimum of exponential random variables,"Let $X_1$ and $X_2$ be independent exponentially distributed random variables with parameter $\theta > 0$ . I want to compute $\mathbb E[X_1 \wedge X_2 | X_1]$ , where $X_1 \wedge X_2 := \min(X_1, X_2)$ . I'm really not sure how to do this. I don't want to use any joint distribution formulas (that's a different exercise in this text). Basically all I know about conditional expectations is that $\mathbb E\left[\mathbb E[X | Y] \mathbb 1_A \right] = \mathbb E[X \mathbb 1_A]$ , for any $A \in \sigma(Y)$ . I thought about using this property to calculate $\mathbb E\left[(X_1 \wedge X_2) \mathbb 1_{\{X_1 \leq X_2\}}| X_1\right]$ and $\mathbb E\left[(X_1 \wedge X_2) \mathbb 1_{\{X_1 > X_2\}}| X_1\right]$ separately, but it's not clear to me that either of these sets are necessarily in $\sigma(X_1)$ . Any hints? Edit : I want to avoid using conditional probability over expectations while conditioning over zero-probability events. That's a different section of the book I'm reading out of (Achim Klenke's ""Probability Theory: A Comprehensive Course""). Edit 2 : I eventually found my own solution, which I've posted as an answer below.","['conditional-probability', 'conditional-expectation', 'exponential-distribution', 'probability-theory', 'probability']"
3086741,Transforming integral to polar coordinates,"By transforming to polar coordinates, show that $$\int_{0}^{1} \int_{0}^{x}\frac{1}{(1+x^2)(1+y^2)} \,dy\,dx$$ Is equal to $$ \int_{0}^{\pi/4}\frac{\log(\sqrt{2}\cos(\theta))}{\cos(2\theta)} d\theta$$ I have tried the standard $x=r\cos(\theta)$ etc. And can easily see that the limits for theta is $0,\pi/4$ with a sketch. However, I'm struggling to compute the integral that comes out, which ranges $r$ from $r=0$ to $r=\frac{1}{\cos{\theta}}$ . Also, I can integrate this explicitly using tan substitution but does that help?","['integration', 'definite-integrals', 'integral-transforms']"
3086758,"If the expectation and variance of $X$ are both not affected by $Y$, and vice versa, then must $X$ and $Y$ be independent?","I know that if $\mathbb{E}[X]=\mathbb{E}[X|Y] , \mathbb{E}[Y]=\mathbb{E}[Y|X]$ , $X$ and $Y$ can be dependent, for example a ‘uniform’ distribution in a unit circle.
Now we add the variance, if $$\mathbb{E}[X]=\mathbb{E}[X|Y], \mathbb{E}[Y]=\mathbb{E}[Y|X], $$ $$Var(X)=Var(X|Y), Var(Y)=Var(Y|X).$$ Say the expectation and variance of $X$ are both not affected by $Y$ , and vice versa, then must $X$ and $Y$ be independent?
In this case I can not find a counterexample just like the uniform circle. If they are independent, how to prove it? If not, is there a counterexample? Thanks!","['independence', 'conditional-expectation', 'probability']"
3086862,Characterizing critical points of a complex valued function.,"Consider a function $f : \Bbb R^2 \longrightarrow \Bbb R^2$ . A point $(x_0,y_0) \in \Bbb R^2$ is said to be a regular point of $f$ if $Df\ ((x_0,y_0)) : \Bbb R^2 \longrightarrow \Bbb R^2$ is an invertible linear operator. A point $(x_0,y_0) \in \Bbb R^2$ is said to be a critical point of $f$ if it is not a regular point of $f$ . Since $\Bbb C$ is homeomorphic to $\Bbb R^2$ so I was very eager to know the concept of critical points in the complex plane and I found that the critical points of a complex valued function $f$ over the complex plane are precisely those points $z_0 = x_0 + iy_0 \in \Bbb C$ such that $f'(z_0) = 0$ . How do I relate these two concepts? In fact how do I proof the theorem which states that "" Let $f : \Bbb C \longrightarrow \Bbb C$ be a differentiable function. Then a point $z_0 \in \Bbb C$ is a critical point of $f$ (in the multivariable sense) if and only if $f'(z_0) = 0$ . "" Please help me in proving this theorem. Then it will be really very helpful for me. Thank you very much.","['complex-analysis', 'multivariable-calculus']"
3086874,"A simple question about the proof of theorem 3.42 in Walter Rudin's ""Principles of Mathematical Analysis""","I am reading ""Principles of Mathematical Analysis"" by Walter Rudin. I read the proof of theorem 3.42 on p.71. And I have a simple question about the following calculation: $$|\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|.$$ My calculation is here: $$|\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq \\\sum_{n=p}^{q-1} |A_n| |(b_n - b_{n+1})| + |A_q| |b_q| + |A_{p-1} | |b_p| \leq \\\sum_{n=p}^{q-1} M |(b_n - b_{n+1})| + M |b_q| + M |b_p| = \\\sum_{n=p}^{q-1} M (b_n - b_{n+1}) + M b_q + M b_p = \\ M (\sum_{n=p}^{q-1}  (b_n - b_{n+1}) +  b_q +  b_p).$$ Of course, $$M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p| = M (\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p),$$ but why did Rudin write as follows? $$M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|.$$","['calculus', 'proof-verification', 'sequences-and-series']"
3086947,How to evaluate: $\lim\limits_{n\to\infty} \frac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p}$,"How to evaluate: $$\lim_{n\to\infty} \dfrac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p}$$ when $i)$ $p\in\mathbb R,p\neq0$ $ii)\space p=0$ So for $i)$ I tried using Stolz–Cesàro theorem and Binomial theorem and If I didn't mess up I got $1$ . But I'm unsure about it, but for $ii)$ and I don't have a clue where to begin with.","['limits', 'calculus', 'limits-without-lhopital', 'analysis']"
3086969,Approximate a continuous functions with $C^\infty$ functions in uniform norm.,"I have a question concerning the generator of a backwards SDE. Suppose that $f(\omega,t,y,z):\Omega\times\mathbb{R}^+\times\mathbb{R}\times\mathbb{R}^d\rightarrow\mathbb{R}$ is almost surely jointly continuous in $(t,y,z)$ . Suppose further that $f$ has suitable growth conditions (e.g. linear in $y$ and quadratic in $z$ . In the Kobylanski 2000 paper, it was asserted that there is a sequence $f^{(n)}$ of $C^\infty$ functions such that: $$f+\frac{1}{2^{n+1}}\leq f^{(n)} \leq f+\frac{1}{2^n}$$ I'm at a bit of a loss as to how to prove the existence of such a sequence. In the said paper, it was said that the existence of this sequence is given by a standard argument of regularisation, but I don't quite see how. Any help or reference would be greatly appreciated. Thanks!","['probability', 'real-analysis', 'functional-analysis', 'probability-theory', 'stochastic-calculus']"
3086972,Relation between the order of an element of a group and their character in a simple group,"Let $\chi$ be the representation of a finite group $G$ . Let $g \in G$ be an element of order 2. If $G$ is a simple group but not cyclic of order 2, prove that $\chi(g) \equiv \chi(1) \mod 4$ . 
Proof that $\chi(g) \equiv \chi(1) \mod 2$ in any finite group can be found here: Relation between the order of an element of a group and their character but I'm having trouble connecting the two. Any help would be appreciated.","['group-theory', 'simple-groups', 'representation-theory', 'characters']"
3086979,"Show that when written in terms of $ t$, where $t = \tan(x/2)$, the expression $2(1 + \cos(x))(5\sin(x) + 12\cos(x) + 13)$ is a perfect square.","Attempt:
I've used that $\sin(x) = (2t)/(1+t^2)$ and $\cos(x) = (1-t^2)/(1+t^2)$ .
However I don't seem to get a perfect square, instead I get $$(2/((1+t^2)^2))(14t^2 +20t + 38)$$ . I'm not sure if there error is with my method or my workings. Any help would be greatly appreciated.",['trigonometry']
3086981,Finite Algebras and Grobner Bases,"Background Suppose that $A$ is a finite $\mathbb{R}$ -algebra, that is, it is finite-dimensional as an vector space. By a consequence of the Hilbert-basisatz, since $\mathbb{R}$ is Noetherian, then so is $A$ , hence, in particular, there exists $f_1,\dots,f_n$ generating the ideal $\mathbb{R}[x]/(x^n)=\mathbb{R}(f_1,\dots,f_n)$ .  I assume these can be expressed using a Groebner basis. Question If $f_1,\dots,f_n$ is a Groebner basis of $A\triangleq \frac{\mathbb{R}}{(f_1,\dots,f_n)}$ ; $f_i \in \mathbb{R}$ , and $N_1,\dots,_{N_n}>0$ is such that $$
Deg(f_1)={N_i},
$$ then does the set of all divisors of $f_1,\dots,f_n$ for a basis of $A$ as an $\mathbb{R}$ -module? Example In the special case that $A=\mathbb{R}[x]/(x^n)\cong \mathbb{R}^{n}$ as an vector space over $\mathbb{R}$ .  This is indeed true and $$
\mathcal{B}= \{x^i
\}_{i=0}^{N_n}\qquad
;N_n=n
,
$$ forms a basis of $A$ as a $\mathbb{R}$ -algebra.","['groebner-basis', 'ring-theory', 'algebraic-geometry', 'algebras', 'commutative-algebra']"
3086997,Determine the recurrence formula,"$\int_{-1}^{1}(1-x^2)^ndx$ I have trouble with finding recurrence formula for this integral. $n$ is natural parameter. I've tried to split up $(1-x^2)^n = (1+x)^n(1-x)^n$ and then to integrate partially, but it only makes things more complicate. Maybe substitution $x=sint$ can lead to solution?
When I apply it I get: $\int_{-\pi/2}^{\pi/2}(cost)^{n+1}dt$ What to do next then?","['integration', 'definite-integrals', 'recurrence-relations', 'reduction-formula']"
3087001,Does this infinite primes snake-product converge?,"Form an infinite product of prime ratios as follows.
Start with $$
\frac{2}{3}\cdot\frac{7}{5}=\frac{14}{15} \approx 0.93 \;.
$$ Continue alternating a fraction $< 1$ times the next fraction $>1$ ,
progressively through the primes: $$
\frac{2}{3}\cdot\frac{7}{5}\cdot\frac{11}{13}\cdot\frac{19}{17}
= \frac{2926}{3315} \approx 0.88 \;,
$$ $$
\frac{2}{3}\cdot\frac{7}{5}\cdot\frac{11}{13}\cdot\frac{19}{17}\cdot\frac{23}{29}\cdot\frac{37}{31}
=\frac{2490026}{2980185} \approx 0.83 \;.
$$ Continue this process to $\infty$ . One way to write the product is $$
\xi = \prod_{1,5,9,\ldots}^\infty 
\frac{p_i}{p_{i+1}}\cdot\frac{p_{i+3}}{p_{i+2}}
$$ where $p_i$ is the $i$ -th prime.
I call this the primes snake-product : My questions are: Q1 . Does the product converge? Q2 . If so, to what value $\xi$ does it converge? Up to the $1$ -millionth prime ( $15485863$ ),
the product is about $0.9056$ : Update ( 26Jan2019 ): @Peter has calculated out to $p_i=10^{10}$ when the product is $\approx 0.9048$ .","['number-theory', 'prime-numbers', 'elementary-number-theory', 'sequences-and-series']"
3087004,Show that $\forall n \in\Bbb N: e < \left(1+{1\over n}\right)^n \left(1 + {1\over 2n}\right)$,"Show that: $$
\forall n \in\Bbb N: e < \left(1+{1\over n}\right)^n \left(1 + {1\over 2n}\right)
$$ Till now i've only worked out a couple of proof sketches, and I don't have an idea how to proceed with them. Please note that this question has already been asked here . The answer there uses derivatives and integrals which i'm not allowed to use . First sketch Consider the sequence: $$
x_n = \left(1+{1\over n}\right)^n \left(1 + {1\over 2n}\right)
$$ One of the ways to show what's required is to show that: $$
x_{n+1} \le x_n
$$ namely the sequence is monotonically decreasing. Now given $n\in\Bbb N$ we may calculate $x_1$ : $$
x_1 = \left(1+{1\over 1}\right)^1\left(1+{1\over 2\cdot 1}\right) = 3
$$ Consider the limit: $$
\lim_{n\to\infty}x_n = \lim_{n\to\infty} \left(1+{1\over n}\right)^n \left(1 + {1\over 2n}\right) = e
$$ Now based on the fact that the sequence tends to $e$ and it is monotonically decreasing and $x_1 = 3$ , then it should follow that: $$
\forall n\in\Bbb N: x_n \ge e
$$ Here comes the hard part, I could't prove that $x_n$ is monotonically decreasing. I've considered the fraction: $$
{x_{n+1}\over x_n} = \left(1 - {1\over (n+1)^2}\right)^n \cdot \frac{2n(2n+3)(n+2)}{(2n+2)(2n+1)(n+1)}
$$ Not sure how to show it is less than $1$ . Second sketch This sketch is based on the idea from my previous question . Namely it has been shown there that: $$
e \le \frac{n+2}{(n+1)(n+1)!} + \sum_{k=0}^n {1\over k!}
$$ It looks like : $$
e \le \frac{n+2}{(n+1)(n+1)!} + \sum_{k=0}^n {1\over k!} \le \left(1+{1\over n}\right)^n \left(1 + {1\over 2n}\right) \tag1
$$ In such case if we prove $(1)$ we are done. I've given it several tries but it gets ugly very soon. The question is: Is it possible to utilize any of those sketches to finish the proof? If not what would be the way to prove the inequality using anything before the definition of a derivative/Taylor series/intergrals Thank you!","['proof-verification', 'calculus', 'sequences-and-series', 'limits', 'inequality']"
3087006,Prove that a map is open in the Zariski topology,Say $k$ is an algebraically closed field and define the equivalence relation on $k^{n+1}$ given by $x \sim y \iff x=\lambda y $ for some $\lambda \in \mathbb{k}^{\times}$ . Clearly $\mathbb{P}^{n} = k^{n+1}/\sim$ . Let the map $q:k^{n+1} \setminus 0 \longrightarrow \mathbb{P}^{n}$ be the quotient map that sends $x$ to its equivalence class. I have to show that it is an open map (for the Zariski topology). Any hint is appreciated.,"['general-topology', 'algebraic-geometry', 'projective-geometry']"
3087013,Solve the equation |x-1|=x-1,"Solve the equation: $|x-1|=x-1$ My solution: Case 1 : $ x\ge1$ , Hence $x-1=x-1$ , therefore infinite solution Case 2 : $ x<1$ , Hence $1-x=x-1$ , $x=1$ , hence no solution But the solution i saw concept used is $ x\le1$ in lieu of $ x<1$ Hence final answer is $[1,\infty]$ , is this concept correct","['algebra-precalculus', 'proof-verification', 'absolute-value']"
3087020,Number of orbits and representatives of an action of $Gl_2(\mathbb{Z}_2)$ in $M_2(\mathbb{Z}_2)$ by conjugation,"So I'm asked to find the number of orbits and representatives of that action, my idea was to find all the possible rationals forms induced by a polynomial of order 2 in $\mathbb{Z}_2[x]$ , thinking of it as modules over $\mathbb{Z}_2[x]$ , but i only seem to find 6, with the modules by $\mathbb{Z}_2[x]/x²,\mathbb{Z}_2[x]/(x-1) \bigoplus \mathbb{Z}_2[x]/x,\mathbb{Z}_2[x]/(x-1)²,\mathbb{Z}_2[x]/(x²+x+1),\mathbb{Z}_2[x]/(x-1)\bigoplus\mathbb{Z}_2[x]/x ,\mathbb{Z}_2[x]/x \bigoplus \mathbb{Z}_2[x]/x$ , but they are supposed to be 7 according to the solutions, can u help me out? Thanks.","['group-actions', 'abstract-algebra']"
3087032,What is the difference between a derivative and a differential equation?,"If function $y=x^2$ , then the derivative of $y$ is $2x$ . We write the derivative as either $f'(x)=2x$ or $\frac{\text dy}{\text dx}=2x$ . In this case $\frac{\text dy}{\text dx}=2x$ is also a differential equation. But if we have the function $y=ax^2+bx+c$ then in this case we will have $\frac{\text dy}{\text dx}= 2ax+b$ . Is $\frac{\text dy}{\text dx}= 2ax+b$ also considered as a differential equation or we will have to remove all arbitrary constants from the function to call it a differential equation?","['calculus', 'derivatives', 'ordinary-differential-equations']"
3087070,For which even integers $k$ has $\varphi(n+1)-\varphi(n)=k$ a solution?,"For which even integers $k$ does the equation $$\varphi(n+1)-\varphi(n)=k$$ have a solution ? $\varphi(n)$ denotes the totient function and $n$ is a positive integer. For the following $|k|\le 1\ 000$ , there is no solution $n$ in the range $[3,10^7]$ : -958 -926 -910 -898 -892 -846 -834 -814 -790 -730 -682 -610 -594 -582 -570 -550
-514 -490 -462 -442 -422 -370 -354 -326 -310 -226 -202 -114 10 86 126 134 182 22
6 242 266 274 278 286 298 326 370 378 386 446 450 466 470 530 538 574 578 610 62
6 634 638 666 678 706 734 738 758 770 786 790 806 822 826 830 842 866 874 898 91
4 926 932 938 970 986 Almost all those numbers are of the form $\ 4k+2$ In fact, the $|k|\le 1\ 000$ divisible by $4$ having no solution in the range $[3,10^6]$ are $-892$ (solution $10\ 814\ 714$ ) and $932$ (no solution in the range $[3,10^8]$ ) Does a solution exist for $k=932$ ?","['number-theory', 'integers', 'totient-function', 'elementary-number-theory']"
3087083,The derivative of an integral of a product of functions.,"I'm trying to comprehend the following result, which is required for fractional calculus: Let $w(x,y)$ and $f(z)$ be two real functions, such that they both vanish at a point $a$ . Then the following relation holds: $$\frac{\text d}{\text dx} \int_a^xw(x,y)f(y)\text dy=w(x)f(x)+\int_a^xf(y)\frac{\partial{w(x,y)}}{\partial{x}}\text dy.$$ My intuition for a proof points towards the integration by parts of a product of functions. But there might be a sign error if that's the case. The reference for this is ""Construction & Physical Applications Of The Fractional Calculus"", Nicholas Wheeler, 1997 . Thank you for the help!","['integration', 'derivatives', 'products']"
3087114,What is the probability that a deck of $52$ cards is more than $0.55$ inches in thickness?,"The thickness of the individual cards produced by a certain playing card manufacturer is normally distributed with mean $0.01$ inches and variance $0.000052$ . What is the probability that a deck of $52$ cards is more than $0.55$ inches in thickness? (The thickness of each card is independent of the others). Solve: \begin{align}P(X>0.55)&=P\left(Z>\frac{\frac{0.55}{52}-0.01}{\frac{\sqrt{0.00052}}{\sqrt{52}}}\right)\\
&=P(Z>0.182)\\
&=0.427\end{align} (from the standard normal tables) From the book solution it should be $P(Z > 0.58) ≈ 0.28$ , but I can't see where I'm wrong, can someone help me?","['statistics', 'probability']"
3087157,Function with finite domain can be linear?,"Consider a function $f:\mathcal{X}\rightarrow \mathcal{Y}$ prescribed by $f(x)=3x$ , 
where $\mathcal{X}=\{1,2,3\}$ and $\mathcal{Y}\equiv \{3,6,9\}$ . Can we say that $f$ is linear? My confusion stems from the finite domain.","['functions', 'linear-algebra']"
3087163,Finding the argument of a complex function,"I've the following transfer function: $$H(s)=\frac{1}{as^3+bs^2+cs+1}$$ Where $a,b,c$ are all real and positive. How can I find $\arg(H(i\omega))$ ? And I know that $\omega\ge0$ What I did: $$H(i\omega)=\frac{1}{a(i\omega)^3+b(i\omega)^2+c(i\omega)+1}=\frac{1}{-a\omega^3i-b\omega^2+c\omega i+1}=$$ $$\frac{1}{1-b\omega^2+(c\omega-a\omega^3)i}$$ Now finding the argument I can write: $$\arg(H(i\omega))=\arg(1)-\arg(1-b\omega^2+(c\omega-a\omega^3)i)=$$ $$0-\arg(1-b\omega^2+(c\omega-a\omega^3)i)=-\arg(1-b\omega^2+(c\omega-a\omega^3)i)$$ Now, how can I setup a function that depends on the value of $a,b,c,\omega$ ?","['transfer-theory', 'laplace-transform', 'complex-analysis', 'triangles', 'complex-numbers']"
3087170,Where does $\in$ come from and where is it defined?,"Kind of a weird question but where does the $\in$ symbol come from exactly and where do we imbue this symbol with any kind of meaning? As far as I can tell it isn't a symbol that is part of the alphabet when it comes to propositional logic or first order logic. It just sort of pops out of nowhere when you get to something like the axioms of ZFC or set theory where we start saying things like $a \in S$ without really discussing what this symbol means or how you use it appropriately. We all know it means ""element of"" but is there a more formal basis for its definition? Is there some kind of rule or axiom that shows how this syntax is meant to be used somewhere? I am coming at this from the perspective of syntax and semantics if that helps. Please note I am not asking about the history of the symbol $\in$ . For example let's say I start throwing around $a★b$ or $a★S$ in my syntax, you'd go, whoa, wait a second, I don't know what that symbol means or what we're allowed to do with it or how we're supposed to use it. Where would I ""point you"" to show these things?","['elementary-set-theory', 'definition', 'math-history', 'notation']"
3087198,Tangent space at a point and optimization under constraint with the sub-manifold $x^2+2y^2-z^2=1$,"Given is the following set M containing all points $\subset \mathbb{R}^3$ such that $x^2+2y^2-z^2=1$ a) Prove that M is a two dimensional sub-manifold of $\mathbb{R}^3$ b) Calculate the tangential space of M in the point $p=(1,0,0)$ c) Determine the points on M with minimal distance to the origin with respect to the euclidean Norm. This problem is very similar to  this one that I asked a month ago : How to find the set of all points in a submanifold minimizing the distance to a given point? But I want to be sure that I proceeded correctly and made no mistakes/ forgot nothing. Thanks for your feedback. a) To prove that this is a sub-manifold, we simply take the gradient, find all points that yield zero, and plug those points into our set. If they aren't included in the set, then this set is a sub-manifold. So $(2x,4y,-2z)=(0,0,0)$ which only yields the point $x=y=z=0$ which is not included in our set because $0\neq 1$ . The dimension is $2$ because the set takes a point in $\mathbb{R}^3$ and outputs a point in $\mathbb{R}^1$ so $3-1=2$ b) To find the tangent space in a point, we input our point into the gradient and find its kernel. So $(2,0,0)\cdot v =(0,0,0)$ . So $a_1=0$ and $ a_2 = b, a_3=c$ . So $a_2, a_3$ are free variables. Thus the kernel is the span of $b(0,1,0)+c(0,0,1)$ c) This is an optimization problem with constraint. The function we want to optimize is the euclidean distance squared (We can square it because it does not change the result since it is a ""monotonically increasing"" function. This allows us to get rid of the square roots to make the algebra nicer.) Our constraint is the set M. So $f(x,y,z)=(x-0)^2+(y-0)^2+(z-0)^2$ and $g(x,y,z)=x^2+2y^2-z^2-1$ .
Using Lagrange multiplier, we get : $(2x,2y,2z)=\lambda (2x,4y,-2z)$ . If $\lambda =1, y=z=0, x^2=1-2*0^2+0^2=1$ so $x=\pm 1$ If $\lambda = -1, x=y=0$ then we have no solutions since $-z^2$ never equals $1$ If $\lambda = \frac{1}{2}, x=z=0, 2y^2=1$ so $y=\pm \frac{1}{\sqrt{2}}$ So our candidates are $(\pm 1,0,0), (0,\pm \frac{1}{\sqrt{2}},0)$ . Now,given that $(0,\pm \frac{1}{\sqrt{2}},0)$ is closer to the origin than $(\pm 1,0,0)$ , our set of points is $(0,\pm \frac{1}{\sqrt{2}},0)$ Thanks for your feedback !","['analysis', 'real-analysis', 'multivariable-calculus', 'manifolds', 'general-topology']"
3087254,Showing that $x^2+5=y^3$ has no integer solutions.,"I'm trying to show that the Diophantine equation $x^2+5=y^3$ has no integer solutions using the fact that $\mathbb Z[ \sqrt{-5}]$ has class number two. I think I have the general idea, but I'm having a tough time establishing the statement in bold below. Any ideas? The equation gives a factorization into ideals $$
(x+\sqrt{-5})(x-\sqrt{-5})=(y)^3
$$ in $\mathbb Z[ \sqrt{-5}]$ . Assuming that $(x+\sqrt{-5})$ and $(x-\sqrt{-5})$ are relatively prime , we know that $(x+\sqrt{-5})=\mathfrak a^3$ and $(x-\sqrt{-5})=\mathfrak b^3$ for some ideals $\mathfrak a, \mathfrak b$ in $\mathbb Z[ \sqrt{-5}]$ . Then the classes of $\mathfrak a$ and $\mathfrak b$ have order dividing 3 in the class group, hence they must both be principal, generated by some $\alpha,\beta\in \mathbb Z[\sqrt{-5}]$ , respectively, as the class number is 2. Hence $\alpha^3=x+\sqrt{-5}$ up to units ( $\pm 1$ ), and matching up real and imaginary parts then gives a contradiction. How can I show that the ideals $(x+\sqrt{-5})$ and $(x-\sqrt{-5})$ are relatively prime? I was trying something along the lines of letting $\mathfrak p$ be a prime of $\mathbb Z[\sqrt{-5}]$ diving both ideals, in which case it also divides their sum (gcd). Then $$2\sqrt{-5}=x+\sqrt{-5}-(x-\sqrt{-5})\in (x+\sqrt{-5},x-\sqrt{-5})\subseteq \mathfrak p,$$ so $\mathfrak p\mid (2\sqrt{-5})$ ... But I'm not totally sure where I'm going with this.","['number-theory', 'algebraic-number-theory', 'dedekind-domain', 'diophantine-equations']"
3087261,Find the standard deviation of $|X−Y|$,"Let $X$ and $Y$ be independent random variables with a Bernoulli Distribution $Ber(1/3)$ . Find the standard deviation of $|X−Y|$ . The Standard Deviation in the square root of the variance. For a $Ber(1/3)$ the $Var(X)=Var(Y)=1/3(1-1/3)=2/9$ , now how can I calculate $\sigma=\sqrt{Var(|X−Y|)}$ ? Because my idea was to subtract the two $Var$ but then the result will be $0$ , but it should be $\frac{2\sqrt{5}}{9}$ , how can I solve it?","['statistics', 'probability']"
3087289,Is $P$ dense in $X$?,"Let $C[0,1]$ denote all the real-valued continuous function on $[0,1].$ Consider the normed linear space $$X = \left \{f \in C[0,1] : f \left ( \frac 1 2 \right ) = 0 \right \},$$ with the sup-norm $,$ $\|f\| = \sup\ \{|f(t)| : t \in [0,1] \}.$ Show that the set $$P = \left \{f \in X : f\ \text {is a polynomial} \right \}$$ is dense in $X.$ I take a basic open set $B(f,\epsilon) \cap X$ in $X,$ where $f \in X$ and $\epsilon > 0.$ Now by Stone-Weierstrass theorem there exists a sequence of polynomials in $C[0,1]$ converging uniformly to $f$ i.e. $\|f_n - f \| < \epsilon,$ for all $n \geq k.$ So if I can find an $n \geq k$ such that $f_n \left (\frac 1 2 \right ) = 0$ then the proof is complete. How can I find such an $n$ ? Please help me in this regard. Thank you very much.","['normed-spaces', 'functional-analysis']"
3087301,Is $\mathcal{U}(\mathfrak{g})$ semisimple (as a module over itself)? (and related examples),"Recall that an object in an abelian category is semisimple if it is a (finite) direct sum of simple objects. An abelian category is semisimple if every object is semisimple. In studying representations of semisimple lie algebras, one often restricts to the subcategory called $\mathcal{O}_{int}$ inside the category left modules for the universal enveloping algebra, $\mathcal{U}(\mathfrak{g})$ .  The main theorem about $\mathcal{O}_{int}$ says it is semisimple (or, at least, that all the objects in $\mathcal{O}_{int}$ are semisimple. Perhaps one needs to check several other things to see that $\mathcal{O}_{int}$ is abelian as a subcategory). I am new to this area and would like to motivate this restriction. A ring $R$ is semisimple in the category of left $R$ modules iff the category of left $R$ modules is semisimple. Thus, Is $\mathcal{U}(\mathfrak{g})$ semisimple as a left $\mathcal{U}(\mathfrak{g})$ -module (for $\mathfrak{g}$ a semisimple Lie algebra)? As a bonus, are there other nice examples of $\mathcal{U}(\mathfrak{g})$ -modules that aren't semisimple?","['abstract-algebra', 'representation-theory', 'lie-algebras']"
3087390,Every nonempty closed subset $M\subset \mathbb C$ is the spectrum of a closed operator,"Several questions on this cite concern themselves with the operator $T:\ell^2(\mathbb N)\to\ell^2(\mathbb N)$ where $T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty$ . Here the sequence $\{r_n:n\in\mathbb N\}\subset M\subset\mathbb C$ is dense in the closed and bounded set $M$ . These questions concern themselves with the continuous nature of the operator $T$ as well as the fact that $\sigma(T)=M$ . Some of these questions include the following: Show that $A:\ell^2(\mathbb N)\to\ell^2(\mathbb N)$ where $A(e_n)=\lambda_ne_n$ is bounded. Prove $\forall$ compact $M:\ M \subset C\quad \exists A:l_2\rightarrow l_2, \sigma(A)=M$ Operator whose spectrum is given compact set One will note that rather than having $T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty$ , we could also have our operator defined by $T(e_n)_{n=1}^\infty=(r_ne_n)_{n=1}^\infty$ , where $\{e_n\}_{n=1}^\infty$ is the usual basis for $\ell^2(\mathbb N)$ . I am interested in this example for the case when $T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N)$ is potentially unbounded but at least closed . The following is an excerpt from Unbounded Self-adjoint Operators on Hilbert Space by Konrad Schmüdgen. The example contained within the excerpt details that an arbitrary nonempty closed subset $M\subset\mathbb C$ is the spectrum for some closed operator. In trying to tackle the closed analogue to the hitherto often discussed bounded case, I am finding it hard to grasp and show the following points: What difference is there - if any - in requiring that $\mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\}$ over stipulating that $M\subset\mathbb C$ be compact? As noted in the opening, we often encounter the requirement that $M\subset\mathbb C$ be compact when $T$ is bounded. Interestingly, requiring that $\mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\}$ just ensures that $T$ is bounded - so are both stipulations equivalent? How does one use the fact that $(r_nx_n)\in\ell^2(\mathbb N)$ in the definition of $\mathcal D(T)$ to show that $T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N)$ is closed? I feel that this is obvious since $T$ acts on all of $\ell^2(\mathbb N)$ , but how do I demonstrate that the limit, $x=(x_m)_{m=1}^\infty\in\ell^2(\mathbb N)$ , of any convergent sequence $(x_n)_{n=1}^\infty\subset\mathcal D(T)$ satisfies that ' $(r_mx_m)\in\ell^2(\mathbb N)$ '? What is the difference between defining $Tx_n=r_nx_n$ and defining $Te_n=r_ne_n$ , as has been propositioned in similar questions? In particular, I feel that this point is best considered when taken with the next question ... How, exactly, do we see that $\{r_n:n\in\mathbb N\}\subset M$ is contained within $\sigma(T)$ ? In particular, I don't see how $Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots)$ has anything to do with the eigenvalue problem; in particular, if we were interested in showing that this was included in the spectrum why don't we look at $Tx=\lambda x=(\lambda x_1, \lambda x_2, \lambda x_3, \dots)$ ? It just seems to me that regarding $Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots)$ seems to say that this whole sequence $(r_n)_{n=1}^\infty$ is an eigenvalue, rather than that each of its components is an eigenvalue. Is this where it makes more sense to look at the operator $Te_n=(r_ne_n)?$","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'unbounded-operators', 'sequences-and-series']"
3087424,Biased coin question,"You have a biased coin, where the probability of flipping a heads is $70%$ . You flip once, and the coin comes up tails. What is the expected number of flips from that point (so counting that as flip $\#0$ ) until the number of heads flipped in total equals the number of tails? I think the answer should be $0.3x+1 = 0.7x \implies x=2.5$ but I am not sure.",['probability']
3087433,"Calculate the value of $\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx$","I'm asked to evaluate the integral $\displaystyle\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx$ . I tried defining a funcion $f(z)=\frac{e^{(1/2+i)\operatorname{Log}(z)}}{z^2+1}$ , taking $\operatorname{Log}$ with a branch cut along the positive real axis: ( $\operatorname{Log}(z)=\ln(|z|)+i\arg(z))$ . Using residue theorem with the ""pacman"" contour. However when trying to bound the integral around a small circle around $0$ , I cannot conclude it converges to $0$ . My attempt was $|\int_{\gamma_\epsilon}f|\leq 2\pi\epsilon|e^{(0.5+i)(\ln|\epsilon|+i\theta))}|\frac{1}{\epsilon^2-1}\leq C\epsilon^{-0.5}.$ I'd love it if someone could either suggest a different way to bound the integral around $0$ of this function, or maybe suggest an easier complex function to work 
with. Edit: The wonderful ""Related"" algorithm of this site managed to link me to this answer Looking at it , a more general statement is proved, but the proof fails when we have $\alpha=0.5+i$ (The circle around $0$ doesn`t converge to $0$ by the proof given there, as a matter of fact any $\alpha$ with $Re(\alpha)>0$ would fail.)","['complex-analysis', 'contour-integration', 'residue-calculus']"
3087476,How many lines are defined by points from 8x8 point grid?,"I have a task to formulate approach and calculate how many different lines are defined by points in 8x8 grid (so 2 or more points lies on the line). Points are evenly distributed ([0,0], [0,1], ..., [1,0], [1,1], ..., [7,7]). I tried to partition into groups, use symmetry, think about it as sequences of numbers and then use combinatorics but it always explodes into a lot combinations and I get different results every time. Can someone point me how to approach this task?","['combinations', 'combinatorics', 'geometry']"
3087480,Regular tilings of n-simplex,"Consider a regular n-simplex (the n-dimensional generalisation of a triangle/tetrahedron). A triangle will tile the plane in a triangular pattern. In 4, 8 and 24 dimensions. Can we tile the volume with n-simplices? And will the vertices of those simplices give the lattices $F_4$ , $E_8$ and Leech lattice in turn? i.e. will a 5-cell tile 4D space where the vertices form the lattice $F_4$ . If not what shape does? (These are the sphere packing solutions in those dimensions). But are they also tiling of n-simplices? Edit: I just read that in fact a 24-cell can tessellate 4D space in a $F_4$ arrangement","['vector-lattices', 'geometry', 'tiling']"
3087483,Is the intersection of Frattini subgroup and a Sylow subgroup contained in the Frattini subgroup of the Sylow subgroup?,"Suppose $G$ is a finite group, $P$ is a Sylow p-subgroup of $G$ . Is it always true, that $\Phi(G) \cap P$ is a subgroup of $\Phi(P)$ ? Here $\Phi(G)$ is the Frattini subgroup of $G$ . I managed to solve the problem for the following cases: $P \cong C_{p^n}$ for some $n$ . Then, because if $p\mid |G|$ , then $p\mid |G/\Phi(G)|$ , $\Phi(G) \cap P \cong C_{p^m}$ , where $m < n$ . Thus it is a subgroup of $\Phi(P)$ . $G$ is nilpotent. Then $G$ is the direct product of its Slow subgroups: $G = Syl_{p_1}(G) \times … \times Syl_{p_n}(G)$ . Thus $\Phi(G) = \Phi(Syl_{p_1}(G))\times … \times \Phi(Syl_{p_n}(G))$ . And that means $\Phi(G) \cap P = \Phi(P)$ However, I do not know, how to solve this problem in general.","['finite-groups', 'abstract-algebra', 'sylow-theory', 'group-theory', 'frattini-subgroup']"
3087504,Generalized Owen's T function,"As Wikipedia teaches us https://en.wikipedia.org/wiki/Owen%27s_T_function the Owen's T function $T(h,a)$ defines a probability of a bivariate event $X>h$ and $0<Y<a X$ where $X,Y$ are standard, independent Gaussian random variables. Now in the context of question Multivariate gaussian integral over positive reals a necessity appeared to deal with a slightly more general quantity. \begin{equation}
T(h,a,b):= {\bf P}\left(X>h \quad \wedge \quad a X+b > Y > 0 \left. \right| X = N(0,1) , Y=N(0,1)   \right)
\end{equation} We have shown that : \begin{eqnarray}
&&T(h,a,b)= \int\limits_h^\infty \frac{\exp(-1/2 \xi^2)}{\sqrt{2\pi}} \frac{1}{2} Erf(\frac{a \xi+b}{\sqrt{2}}) d\xi \quad (i1)\\
&&= \int\limits_0^a \frac{e^{-\frac{b^2}{2}-b h \xi -\frac{1}{2} h^2 \left(\xi ^2+1\right)}}{2 \pi  \left(\xi ^2+1\right)} d\xi - \frac{b}{2\sqrt{2}\sqrt{\pi}} \int\limits_0^a \frac{\xi  e^{-\frac{b^2}{2 \xi ^2+2}} \text{erfc}\left(\frac{\xi  (b+h \xi )+h}{\sqrt{2} \sqrt{\xi ^2+1}}\right)}{\left(\xi ^2+1\right)^{3/2}} d\xi + \frac{1}{4} \text{erf}\left(\frac{b}{\sqrt{2}}\right) \text{erfc}\left(\frac{h}{\sqrt{2}}\right) \quad (i2)
\end{eqnarray} {a, b, h} = RandomReal[{0, 1}, 3, WorkingPrecision -> 50]; b = 0;
NIntegrate[
 Exp[-x^2/2]/Sqrt[2 Pi] 1/2 Erf[(a x + b)/Sqrt[2]], {x, h, Infinity}, 
 WorkingPrecision -> 20]
NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(
   2 (1 + xi^2) \[Pi]) - 
   b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (
    xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 + 
      xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a}, 
  WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4 Update: Let $A_j \in {\mathbb R}$ for $j=1,\cdots,3$ and let $x\in {\mathbb R}$ .
Then we have: \begin{eqnarray}
T(A_1 x, A_2, A_3 x) = 
\frac{1}{2\pi} \left(\arctan(A_2)-\arctan(A_2+\frac{A_3}{A_1})-\arctan(\frac{A_1+A_2 A_3+A_2^2 A_1}{A_3})\right) + \frac{1}{4} erf[\frac{A_3 x}{\sqrt{2} \sqrt{1+A_2^2}}] + T(A_1 x, \frac{A_2 A_1+A_3}{A_1})+ T(\frac{A_3 x}{\sqrt{1+A_2^2}},\frac{A_1+A_2 A_3 + A_2^2 A_1}{A_3}) \quad (ii)
\end{eqnarray} This identity comes from differentiating both sides with respect to $x$ then using the definition of the generalized Owen's T function to evaluate the derivative on the right hand side and having done this integrating both sides with respect to $x$ again. Let us present the proof of that in detail. Firstly we define $f(x) := T[A_1 x, A_2, A_3 x]$ . Now we compute the derivative using the chain rule. We have: \begin{eqnarray}
\frac{d }{d x} f(x) &=& \partial_1 T[A_1 x, A_2 , A_3 x] \cdot A_1 + \partial_3 T[A_1 x, A_2, A_3 x] \cdot A_3 \\
&=& - \left. \rho(h) \frac{1}{2} erf[\frac{a h+b}{\sqrt{2}}] \right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}}\cdot A_1  + 
\left.\frac{1}{\sqrt{1+a^2}} \frac{1}{2} erf[\frac{h+a^2 h+a b}{\sqrt{2} \sqrt{1+a^2}}] \rho(\frac{b}{1+a^2})\right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}} \cdot A_3 \\
&=& -\rho(A_1 x) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} x] \cdot A_1 + 
\frac{1}{\sqrt{1+A_2^2}} \rho(\frac{A_3 x}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} x] \cdot A_3
\end{eqnarray} Now we integrate. We have: \begin{eqnarray}
f(x)- f(0) &=& - \int\limits_0^x \rho(A_1 \xi) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} \xi] d\xi \cdot A_1 + \\
&&\frac{1}{\sqrt{1+A_2^2}}\int\limits_0^x \rho(\frac{A_3 \xi}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} \xi] d\xi \cdot A_3 \\
f(x) - \frac{1}{2\pi} \arctan(A_2) &=& - \frac{1}{2\pi} \arctan\left( \frac{A_1 A_2+A_3}{A_1}\right) + T(A_1 x, \frac{A_1 A_2 + A_3}{A_1}) + \\
&& \frac{1}{4} erf\left( \frac{A_3}{\sqrt{2} \sqrt{1+A_2^2}} x\right) +\\
&&-\frac{1}{2\pi} \arctan\left( \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right) + T\left( \frac{A_3}{\sqrt{1+A_2^2}} x, \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right)
\end{eqnarray} where in the second line we used the results from An integral involving error functions and a Gaussian and the definition of the Owen's T function. This completes the proof. (*A certain derivative. Used in Q869502.nb*)
T[h_, a_, b_] := 
  NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(
     2 (1 + xi^2) \[Pi]) - 
     b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (
      xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 + 
        xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a}, 
    WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4;
{A1, A2, A3} = RandomReal[{-1, 1}, 3, WorkingPrecision -> 50];
u = Range[0, 1, 1/100];
mT = Interpolation[Transpose[{u, T[A1 u, A2, A3 u]}]];
u =.; u = RandomReal[{0, 1}, WorkingPrecision -> 50];
mT'[u]
-rho[A1 u] 1/2 Erf[(A1 A2 + A3)/Sqrt[2] u] A1 + 
 1/Sqrt[1 + A2^2]
   rho[(A3 u)/Sqrt[1 + A2^2]] 1/
   2 Erfc[(A1 + A2 A3 + A1 A2^2)/(Sqrt[2] Sqrt[1 + A2^2]) u] A3

T[A1 u, A2, A3 u]
1/(2 Pi) (ArcTan[A2] - ArcTan[(A2 A1 + A3)/A1] - 
    ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) + 
 1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] + 
 OwenT[A1 u, (A2 A1 + A3)/A1] + 
 OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3]
1/(2 Pi) (-ArcTan[A3/((A1 + A2 A3 + A2^2 A1))] - 
    ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) + 
 1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] + 
 OwenT[A1 u, (A2 A1 + A3)/A1] + 
 OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3]
-1/(2 Pi) Pi/2 (Sign[A3/((A1 + A2 A3 + A2^2 A1))]) + 
 1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] + 
 OwenT[A1 u, (A2 A1 + A3)/A1] + 
 OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3]


-(1/4) Sign[A3/((A1 + A2 A3 + A2^2 A1))] + 
 1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] + 
 OwenT[A1 u, (A2 A1 + A3)/A1] + 
 OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] Now by both taking $x=1$ and replacing $A_1$ , $A_2$ and $A_3$ by $h$ , $a$ and $b$ in $(ii)$ we express the generalized Owen's T function through Owen's T function itself. We have: \begin{eqnarray}
T(h,a,b) = \frac{1}{2\pi} \left(\arctan(a)-\arctan(a+\frac{b}{h})-\arctan(\frac{h+a b+a^2 h}{b})\right) + \frac{1}{4} erf[\frac{b}{\sqrt{2(1+a^2)}}] + T\left( h,\frac{a h+b}{h}\right) + T\left( \frac{b}{\sqrt{1+a^2}},\frac{h+a b+a^2 h}{b}\right)
\end{eqnarray} As a sanity check we look at the limit $b$ going to zero. We have: \begin{eqnarray}
\lim_{b \rightarrow 0_+} T(h,a,b) &=& \frac{1}{2\pi} \left(\arctan(a)-\arctan(a)-\frac{\pi}{2} sign(h))\right) + 0 + T(h,a) + \frac{1}{4} sign(h) \\
&=& T(h,a)
\end{eqnarray} as it should be. As another sanity check we look at the case $a=\imath$ . Going back to the calculations of the derivative above we have: \begin{eqnarray}
\frac{d}{d x} f(x)= -\phi(A_1 x) \frac{1}{2} erf(\frac{A_1 A_2+A_3}{\sqrt{2}} x) A_1 + \frac{1}{2\pi \imath x} \exp(-\frac{1}{2} x^2 (2 A_1 \imath A_3+A_3^2))
\end{eqnarray} where we used the asymptotic expansion for the complementary error function given in https://en.wikipedia.org/wiki/Error_function#Complementary_error_function .
Now we take a number $M$ such that $1< M$ and we  integrate the above from unity to $M$ and we get: \begin{eqnarray}
f(1)-f(M)= 
\left.\left( T(A_1 \cdot \xi,A_2+\frac{A_3}{A_1}) + \frac{1}{4\pi \imath} Ei(-\frac{1}{2}(1+2\imath \frac{A_1}{A_3})(\xi A_3)^2\right)\right|_{\xi=M}^{\xi=1}
\end{eqnarray} where $Ei()$ is the exponential integral. 
Now it turns out that as $M\rightarrow \infty$ both $f(M)$ and $T(\dots M,\dots)$ tend to zero and \begin{equation}
\lim\limits_{M\rightarrow \infty} \frac{1}{4 \pi \imath} Ei((a+\imath b) M) = sign(b) \cdot \frac{1}{4} \cdot 1_{a<0} + \infty \cdot 1_{a>0}
\end{equation} Defining $b:=b_1+\imath b_2$ and taking $h>0$ this gives the final result: \begin{eqnarray}
&&T(h,\imath , b) = \\
&&\left\{
\begin{array}{rr}
 T(h,\imath + \frac{b}{h}) + \frac{1}{4\pi \imath} Ei(\frac{1}{2}(-b_1^2+b_2^2+2 b_2 h-2\imath b_1(b_2+h))) + sign(b_1(b_2+h)) \cdot \frac{1}{4} & \mbox{if $b_2<0$ and $-b_1^2 + b_2^2+2 b_2 h <0$} \\
\infty & \mbox{otherwise}
\end{array}
\right.
\end{eqnarray} My question is the following. Has this quantity been ever analyzed in the literature before?","['indefinite-integrals', 'special-functions', 'probability', 'gaussian-integral']"
3087557,Is there an explicit relationship between the eigenvalues of a matrix and its derivative?,"If we consider a matrix $A$ dependent of a variable $x$ , the eigenvalues and eigenvectors satisfying the equation $$
A \vec{v}=\lambda \vec{v}
$$ will also depend on $x$ . If we consider the matrix $B$ such that $$B_{ij}=\frac{ \mathrm{d}}{ \mathrm{d} x} A_{ij}$$ Then, could we express the eigenvalues of $B$ in terms of the eigenvalues of $A$ ?
I found the question very interesting and was not able to find a satisfying answer myself. For example in the case for $2\times2$ matrices of the form $$
A=\left (
\begin{matrix}
 a(x) & b(x) \\ 
 0 & c(x) 
\end{matrix}
\right ),\implies B=\left (
\begin{matrix}
 a'(x) & b'(x) \\ 
 0 & c'(x) 
\end{matrix}
\right )
$$ I noticed that $\lambda_B(x)= \lambda_A'(x)$ . But I cannot generalise it to general $2\times 2$ matrices. Not even thinking about $n\times n$ matrices... Thank you for your help and any idea!","['matrices', 'derivatives', 'linear-algebra', 'eigenvalues-eigenvectors']"
3087660,Probability for rolling $n$ dice to add up to at least (a specific sum),"To clear up potential misunderstandings and make it easier to understand, I'll use this notation: Instead of writing ""Rolling $n$ $m$ -sided dice"", I'll shorten it to ""Rolling ndm "". ( n is the amount of dice and m is the amount of sides on the dice) (This is the notation used in D&D if you know what that is) Im asking how to calculate the probability of getting at least a sum of s when rolling ndm. Finding the amount of possible outcomes is fairly easy, its just $m^n$ . So f.ex for 3d6, the amount of possible outcomes would be $6^3 = 216$ . I've looked at similar asked questions before and found a very useful, related formula for finding the amount of ways to get the sum s when rolling ndm: Let $k = \lfloor \frac {s-n}m \rfloor$ $$\sum_\limits{i=0}^{k} (-1)^i{n\choose i}{s-1 - im\choose n-1}$$ However, this only gives us the probability of getting exactly s, not at least s.","['dice', 'probability']"
3087700,How to prove binomial coefficient $ {2^n \choose k} $ is even number?,Prove: ${2^n \choose k}$ (for integers $k$ & $n$ : $0<k<2^n$ ) is even number. I have tried induction but was unable to get any useful results.,"['binomial-coefficients', 'combinatorics']"
3087721,Stuck at hypothesis testing assignment,So I have this assignment in statistics that states the following: We need to either accept or throw away a big package of processors. Because of quality control we take take a sample of 200 processors and find 24 that are not working. The maker of the processors claims that in the entire package there are at most 10 processors that are not working. Do we have enough evidence to throw away his statement with a confidence level of 4%. I assume this is a Hypothesis Testing question with the formula being equaled to: z = $\frac{p - po}{\sqrt{\frac{po(1-po)}{n}}}$ I can see that n = 200 however I don't know what is p or what is po Is p = $\frac{24}{200}$ and po = $\frac{10}{200}$ or is it the other way around?,['statistics']
3087773,"Free subgroups of $PSL(2,\mathbb{Z})$ of index 6","There are two ""natural"" subgroups of $PSL(2,\mathbb{Z})\cong C_2\ast C_3$ of index 6. One is the congruence subgroup $\Gamma_0(2)$ which is the kernel of the map $PSL(2,\mathbb{Z})\to PSL(2,\mathbb{Z}/2\mathbb{Z})$ . The other subgroup $H$ is the kernel of the map $C_2\ast C_3\to C_2\times C_3$ . Here are two similarities between these two subgroups: Both $\Gamma_0(2)$ and $H$ are subgroups of $PSL(2,\mathbb{Z})$ of index 6. Both $\Gamma_0(2)$ and $H$ are free groups of rank 2. However, $PSL(2,\mathbb{Z}/2\mathbb{Z})\cong S_3$ and $C_2\times C_3\cong C_6$ so these are different subgroups of $PSL(2,\mathbb{Z})$ . Moreover, $\Gamma_0(2)$ is freely generated by the matrices $\begin{bmatrix}1&2\\0&1\end{bmatrix}$ and $\begin{bmatrix}1&0\\2&1\end{bmatrix}$ whereas $H$ is freely generated by the matrices $\begin{bmatrix}2&1\\1&1\end{bmatrix}$ and $\begin{bmatrix}1&1\\1&2\end{bmatrix}$ . This last statement can be seen by noting that if $a=\begin{bmatrix}0&-1\\0&1\end{bmatrix}$ generates $C_2$ and $b=\begin{bmatrix}-1&-1\\1&0\end{bmatrix}$ generates $C_3$ then $H$ is freely generated by $abab^2$ and $ab^2ab$ . What is going on here? More precisely, Are these two subgroups the largest free subgroups of $PSL(2,\mathbb{Z})$ ? Are there any other free subgroups of $PSL(2,\mathbb{Z})$ of index 6? Is there any reason to expect that $PSL(2,\mathbb{Z})$ contains two free subgroups of rank 2 and index 6 with different quotients?","['matrices', 'modular-group', 'free-groups', 'free-product', 'group-theory']"
3087781,Kernel of $G\ast H\to G\times H$ is free,"Let $G$ and $H$ be groups. The identity homomorphism $G\to G$ and the trivial homomorphism $H\to G$ give a homomorphism $G\ast H\to G$ by the universal property of the coproduct. Similarly, we obtain a homomorphism $G\ast H\to G$ . Then the universal property of the product gives a homomorphism $G\ast H\to G\times H$ . We can consider the kernel $K$ of this homomorphism. It turns out that $K$ is a free group ( $K$ is freely generated by commutators $[g,h]$ for $g\in G\setminus\{1\}$ and $h\in H\setminus\{1\}$ ). The construction of $K$ was very category-theoretic and only required the use of the universal properties of the product and coproduct. Similarly, the conclusion that $K$ is free is also a category-theoretic statement. Is there a proof that $K$ is free that is ""category-theoretic"" and avoids directly showing that the commutators $[g,h]$ for $g\in G\setminus\{1\}$ and $h\in H\setminus\{1\}$ freely generate $K$ ? As people are mentioning in the comments, it is unlikely for such a proof to exist do to the reliance on a choice of generators in the categorical definition of a free group. Is there a (nonabelian) category similar to the category of groups in which this property fails?","['group-homomorphism', 'group-theory', 'free-product', 'category-theory']"
3087787,Implicit function theorem implies inverse function theorem proof,"I believe this will be a very long answer if anyone tries to write the full proof or anything so I'll specify which specific parts I am having trouble with to save people's time. I want prove three things: First we know, $f: U \to V$ where $U \subset \mathbb{R^n}$ and $V \subset \mathbb{R^n}$ . And let $a \in U$ , s.t. $Df(a)$ is invertible. (1) $f$ is one-to-one and onto (hence invertible) (2) The inverse function $f^{-1}$ is of class $C^1$ (3) If $x \in \mathbb{R^n}$ and $y=f(x)\in\mathbb{R^n}$ then $D(f^{-1})(y)=(Df(x))^{-1}$ . Proof: So I know that the (2) follows directly from one of the conclusions in the implicit function theorem. I am needing help in proving that $f$ is invertible. I know from implicit function theorem that there is a function $g$ such that $g(f(a))=a$ . My idea was to prove that $f(g(b))=b$ ? But I'm not sure if this will work and if this approach can work not sure how to make it work. If this works we know that $g=f^{-1}$ . Also, for (3) what I got to was $Dg(y)=Dg(f(x))Df(x)$ by chain rule. And since we know that $g=f^{-1}$ we can simplify the above equation to: $Dg(y)=DxDf(x)$ but not sure how to work with the $DxDf(x)$ to $(Df(x))^{-1}$ . Explicit hints will be greatly appreciate, thanks in advance.","['multivariable-calculus', 'inverse-function-theorem', 'implicit-function-theorem']"
3087802,Nested homeomorphic sets,"Suppose we have a countable collection of sets $\{U_n\}$ such that $U_n\subset U_{n+1}$ for each $n$ and $U_n$ is homeomorphic to $\mathbb{R}$ (or more generally, $X$ ) for each $n$ , then is $\bigcup_{n=1}^\infty U_n$ homeomorphic to $\mathbb{R}$ (or $X$ )? I am not sure pushing $n$ to $\infty$ works and I couldn't construct an explicit homeomorphism. Thanks!",['general-topology']
