question_id,title,body,tags
638012,L'HÃ´pital's rule for $\mathbb R ^n \to \mathbb R $ functions.,"I want to know if there exists a generalization of  L'Hopital rule in $n$ dimensions? For example, let us consider this problem . There it is just said that we should take separate  path and see if they will end with same  number,but can't we generalize L'Hopital rule and partial derivatives in $n$ dimensions? Just a little hint will help me too much.","['partial-derivative', 'calculus', 'derivatives', 'limits']"
638034,Topological equivalence of ODEs,"Let's have ode $x' = f(x)$, $f(0) = 0$, $x\in \mathbb{R^n}$. There is clasical theorem that states that if all eigenvalues of ${\rm Df}(0)$ have nonzero real part, than $x'=f(x)$ and $x'={\rm Df}(0) x$ are topological equivalent at neighbourhood of $0$. Is there any generalization of this theorem? Like take truncuated(to $n$-th term) taylor expansion of $f(x)$ denote it $T_n(x)$. Than under what condition is $x'=f(x)$ topologicaly equivalent to $x'=T_n(x)$ at neighbourhood of $0$? We know the condition for $n=0,1$. For $n=0$ has to be $f(0)\neq 0$. For $n=1$ has to ${\rm Df}(0)$ have eigenvalues with nonzero real part and $f(0)=0$ If conditions for $n=0,1$ fail is there any know condition for $n=2$ ? In general, are there any known conditions for $n\geq2$?","['ordinary-differential-equations', 'reference-request']"
638064,"Order topology on the set $X = \{ 1,2 \} \times \mathbb{Z}_{+}$","I am learning topology with the book ""Topology"" by James R. Munkres and have some difficulty in understanding the Example 4 of section 14 titled ""The Order Topology"" (page 85 of the second edition). Example 4: The set $X = \{ 1,2 \} \times \mathbb{Z}_{+}$ in the dictionary order is another example of an ordered set with a smallest element. Denoting $1 \times n$ by $a_n$ and $2 \times n$ by $b_n$, we can represent $X$ by $$a_1, a_2, \ldots; b_1, b_2, \ldots.$$ The order topology on $X$ is not the discrete topology. Most one-point sets are open, but there is an exception --- the one-point set $\{ b_1 \}$. Any open set containing $b_1$ must contain a basis element about $b_1$ (by definition), and any basis element containing $b_1$ contains points of the $a_i$ sequence. I am confused about the last statement: any basis element containing $b_1$ contains points of the $a_i$ sequence . What is the reason? And why is $\{ b_2 \}$ (or $\{ b_3 \}, \ldots$) open? What is key distinction between $b_1$ and $b_2$?",['general-topology']
638070,How many paths would confirm the existence of limit of a two variable function?,"My question is : Suppose we know that $\lim_{(x,y) \to (a,b)}f(x,y)$ exists in infinitely many paths for a function $f : \mathbb{R}^2\rightarrow \mathbb{R}$ then can we say that limit exists and it can be obtained from choosing any path. May be i should have been more careful when saying so... Actual question is to evaluate $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}$ First thing one would do is to check for ""Non existence"" by which i mean trying out some paths hoping that limit in those two paths would differ and then conclude that limit does not exist. But then what if the limit in more than one path coincide.. In this situation i would take $y=mx$ then : $$\dfrac{x^3y}{x^4+y^2}=\dfrac{mx^4}{x^4+m^2x^2}\rightarrow 0 \text { as x $\rightarrow$ 0}$$ We realize that irrespective of $m$ we would end up with $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}=0$ along the path $y=mx$. I am sure with this we can not say that limit exists... so, how many paths (I have checked uncountably many as my $m\in \mathbb{R}$) should i check to confirm the existence. There might be some other ways to calculate the limit by some squeeze principle or some but then Is there any thing that if you verify that limit coincide in this many paths then you can conclude limit exist. P.S : My question is not about evaluating the limit but actually Existence of limit knowing its value in some paths... so please do not answer with keeping in mind  the word ""Evaluate"" Thank you :)","['multivariable-calculus', 'real-analysis', 'limits']"
638085,closed strong vs. closed in weak convergence,"Studying a chapter about weak topologies and weak convergence I though the following which I have no idea how to prove or disprove it. So here it is: Question: Does there exist  Banach space $X$ and a closed subset $F
 \subset X$ such that $F$ is not closed with respect to weak
  convergence? Any ideas?","['weak-convergence', 'functional-analysis', 'real-analysis']"
638098,Product of two symmetric matrices with eigenvalues all 0 or 1 is idempotent,"Assume $A$, $V$ are symmetric and $V$ is positive definite. If $AV$ has eigenvalues that are all zero or one, show $AV$ is idempotent. My proof so far (haven't used the symmetric property or the fact that $V$ is positive definite - where do those come in?): If the eigenvalue $\lambda=0$, and assume there exists a nonzero $u$ such that $$AVu=\lambda u=0u=0$$
$$(AV)^2u=AVAVu=AV0=0$$ Then $(AV)^2u=AVu=0$ implies $(AV)^2=AV$ since $u\ne 0$. If $\lambda=1$, and assume there exists nonzero $u$ such that $$AVu=\lambda u=u$$ $$(AV)^2u=AVAVu=AVu$$ $$\implies (AV)^2=AV$$","['matrices', 'linear-algebra']"
638099,Why curl free field implies existence of potential function?,"If curl of a vector field F is zero, then there exist some potential such that $$F = \nabla \phi.$$ I am not sure how to prove this result. I tried using Helmholtz decomposition: $$F = \nabla \phi + \nabla \times u,$$ so I need to show that $\nabla \times u=0$ somehow.",['multivariable-calculus']
638118,"Can someone please simplify this, please.","After solving my previous question, click here for question page , I tried to go up a notch and complicate the question just a bit further, turns out $\int e^x\sin(x)\cos(x)dx$ is much more different than $\int xe^x\sin(x)dx$. Much much much much much more. It's extremely longer (at least it was the way I went about it), after a long excruciating amount of time, I had gotten my final result, which needed simplifying. Here it is without simplying: 
$$
I = \frac{1}{2}e^x(\sin(x)+\cos(x))-\frac{1}{2}(I + \frac{1}{2}e^x(x+\frac{1}{2}\sin(2x))-\frac{1}{2}(xe^x-e^x)+\frac{1}{20}e^x(\sin(2x)-2\cos(2x))) + C
$$ and here is what I got after attempting to simplify it, keep in mind I'm not even sure if this is correct. 
$$ 20I =e^x(10(\sin(x)+\cos(x)-x+\frac{5}{4}(\sin(2x) -x)) +\sin(2x)-2\cos(x)) - \frac{I}{2} +C$$ I really hope I didn't mess it up too much, if I've made a mistake in any of the things I've posted, please call me out on it. I didn't know what else to do after I tried to simplfy it, I know this is a lot to ask, and I'm sure you have better things to do, but just if by chance of a miracle, you feel like simplifying an extremely long equation, please, it would be really appreciated, and if not, then thank you for reading this far anyway. Thanks in advance. (Sorry for babbling on)","['trigonometry', 'logarithms', 'calculus', 'indefinite-integrals']"
638138,general formulation for 1/g(x) derivative,"Is there a general formulation for $\frac {d^n(g(x)^{-1})}{dx^n}$ ?
Something like $$\frac {d^n(g(x)^{-1})}{dx^n} = \sum_{i=1}^{f(n)}\prod_{k=1}^{h(n)} ...$$",['derivatives']
638142,"How do I maximize $|t-e^z|$, for $z\in D$, the unit disk?","I guess this question doesn't have a closed form solution for all $t\in \Bbb C$, but I know one for $t=1$ provided by Daniel Fischer in a question I asked. $$\begin{align}
\left\lvert e^w-1\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!}\right\rvert\\
&\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!}\\
&= e^{\lvert w\rvert}-1,
\end{align}$$ with equality for $w \geqslant 0$. So this $|1-e^z|$ maximized by $z=1$. I tried doing the same for other values of $t$, but without success. Here is an attempt for $t=8$ $$\begin{align}
\left\lvert e^w-8\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!} -7\right\rvert\\
&\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!} + 7\\
&= e^{\lvert w\rvert}+6,
\end{align}$$ But I don't get equality for $w \geqslant 0$. Is there a way to maximize $|t-e^z|$ for $z\in D$, the unit disk, for other values of $t$ besides $0,1$?","['optimization', 'complex-analysis']"
638158,$12345679$ and friends,"We can see that in the decimal system each of $12345679\times k$ $(k\in\mathbb N, k\lt 81, k\ \text{is coprime to $9$})$ (note! not $123456789$ ) has every number from $0$ to $9$ except one number as its digit numbers . $$12345679\times 2=[0]24691358$$ $$12345679\times 4=[0]49382716$$ $$12345679\times 5=[0]61728395$$ $$12345679\times 7=[0]86419753$$ $$12345679\times 8=[0]98765432$$ $$12345679\times 10=123456790$$ $$\vdots$$ $$12345679\times 77=950617283$$ $$12345679\times 79=975308641$$ $$12345679\times 80=987654320$$ $$(12345679\times 82=1012345678)$$ I've been thinking about its generalization. Here is my question. Question : Is the following proposition true? Proposition : Let $n\ge2\in\mathbb Z.$ For any $k\in\mathbb N$ such that $k\lt n^2$ and $k$ is coprime to $n$ , if we consider $$[1,2,3,\cdots, (n-3),(n-2),n]_{n+1}\times k$$ as a number with $n$ -digits in base $n+1$ , then it has every number from $0$ to $n$ except one number as its digit numbers, where $$[1,2,3,\cdots, (n-3),(n-2),n]_{n+1}$$ represents $123\cdots(n-3)(n-2)n$ in base $n+1$ . Example : The examples at the top are the $n=9$ cases of the proposition. Remark : Suppose that the $n$ -th digit number of a number with $n-1$ digits is $0$ . For example, suppose that we treat $$12345679\times 2=24691358$$ as $$12345679\times 2=[0]24691358.$$ Motivation : I've known the followings : $$12345679\times 9=111111111$$ $$12345679\times 18=222222222$$ $$\vdots$$ $$12345679\times 72=888888888$$ $$12345679\times 81=999999999$$ Then, I found that the property at the top has already been known. Though I've tried to prove that the proposition is true, I'm facing difficulty. Can anyone prove or disprove it? P.S. $1$ : Before I posted this question at math overflow , but it was considered as off-topic. However, I got helpful comments from S. Carnahan there. ""Isn't this just a manifestation of the base $n+1$ expansion of $1/n^2$ ?"" ""We may assume $k\lt n$ , since the addition of $j/n$ just adds copies of $j$ , preserving the pattern. The progression from one digit to the next in the expansion is addition by $k$ iff the next digit has no carry, and $k+1$ iff the next digit has a carry. The symbol $nâk$ is necessarily skipped, and there is no premature periodicity (since the multiplicative order of $n+1$ mod $n^2$ is unchanged). "" I think these comments must be true, but these are not obvious for me. P.S. $2$ : I'm going to write the proof for the $k\lt n$ cases to get more hints from you. This is because I'm facing difficulty for proving the following though I think the proof for the $k\lt n$ cases would be fine. What I cannot prove is : If the proposition is true for $k\lt n$ , then it is true for $n\lt k\lt n^2.$ (Though this may be obvious, I cannot get a rigorous proof for it...please let me know it.) In the following, I'm going to write the proof for the $k\lt n$ cases . Proof : First, we use the following fact (of course, the proof is needed, but it is easy to prove it.) Fact : $[1,2,3,\cdots,(n-3),(n-1),n]\times n=[1,1,1,\cdots, 1,1,1]$ (with $n$ $1$ s) Using this fact, we can see $$\begin{align}[1,2,3,\cdots, (n-3),(n-2),n]\times k&=[1,1,1,\cdots,1,1,1]\div n\times k\\&=[1,1,1,\cdots,1,1,1]\times k\div n\\&=[k,k,k,\cdots,k,k,k]\div n.\end{align}$$ In the following, let us consider in mod $n$ . We can see that the remainders in the process of calculating $$[k,k,k,\cdots,k,k,k]\div n$$ are $$k,2k,3k,\cdots,(n-1)k,nk(\equiv 0).$$ Since $k$ is coprime to $n$ , we can easily see that there is no $i\not=j\ (1\le i,j\le n-1)$ such that $$ik\equiv jk.$$ This immediately leads that the answer for $$[k,k,k,\cdots,k,k,k]\div n$$ has distinct numbers as its digit numbers. Q.E.D. P.S. $3$ : Now I have a question. Can I say the following at the last step of my proof above?
I thought it was obvious, but now I feel this does not seem obvious... ""This immediately leads that the answer for $$[k,k,k,\cdots,k,k,k]\div n$$ has distinct numbers as its digit numbers.""","['recreational-mathematics', 'number-theory']"
638163,Prove that the sum of two elements is equal third.,"Please help me solve this problem. The set {1, 2, 3,..., 3n} is decomposed into three disjoint subsets, with n elements in each. Prove that from each one we can take an element such that the sum of two of the elements is equal to the third.",['combinatorics']
638165,"If I found that a series converges, how can I know to what number it's converging to?","I started learning series in calculus and I have trouble catching a basic concept. When I try to find if a series converges or diverges I have many ways to go about it. If I see that the series diverges than I stop there. If I see that the series converges than there is a number it's converging to right? For example: $\sum\frac 2 {n^3+4}$. I do the limit comparison test with the series $\sum\frac 1 {n^3}$ and get a finite number $2$. I know that that $\sum\frac1{n^3}$ converges, so now I know that $\sum\frac2{n^3+4}$ converges also. How do I know to what number it converges to?","['sequences-and-series', 'calculus', 'limits']"
638170,Vector by Matrix derivative,"According to wikipedia, there is no widely accepted definition of a Vector by Matrix derivative.
I have a need of such a notion. For matrix w, and vector h.
$$\mathbf{y=w \;h}
 $$ $$
\begin{bmatrix}y_{0}\\
y_{1}\\
\vdots\\
y_{n}
\end{bmatrix}=\begin{bmatrix}w_{0,0} & w_{0,1} & \cdots & w_{0,k}\\
w_{0,0} & w_{1,1} & \cdots & w_{1,k}\\
\vdots & \cdots & \cdots & \vdots\\
w_{n,0} & \cdots & \cdots & w_{n,k}
\end{bmatrix}\begin{bmatrix}h_{0}\\
h_{1}\\
\vdots\\
h_{k}
\end{bmatrix}=\begin{bmatrix}h_{0}w_{00}+h_{1}w_{01}...+h_{k}w_{0k}\\
h_{0}w_{10}+h_{1}w_{11}...+h_{k}w_{1k}\\
\vdots\\
h_{0}w_{n0}+h_{1}w_{n1}...+h_{k}w_{nk}
\end{bmatrix}
$$ It can be seen with a little thought that $$\frac{d\mathbf{y}}{d\mathbf{h}}=\mathbf{w}$$, which is to say w is a jacobian. However taking the element wise derivative of y with respect to each element of w is going to give me a number of sparse vectors, equal to the number of elements of w .
I guess this could be groups into a 4d tensor, but i know nothing of them.
Inparticular this looks like it is not going to work well with the chain-rule, which is essential to the larger problem i am trying to solve. $$
\begin{array}{cc}
\frac{d\mathbf{y}}{dw_{00}}=\begin{bmatrix}h_{0}\\
0\\
\vdots\\
0
\end{bmatrix} & \frac{d\mathbf{y}}{dw_{10}}=\begin{bmatrix}0\\
h_{0}\\
\vdots\\
0
\end{bmatrix}\\
\frac{d\mathbf{y}}{dw_{101}}=\begin{bmatrix}h_{1}\\
0\\
\vdots\\
0
\end{bmatrix} & \frac{d\mathbf{y}}{dw_{11}}=\begin{bmatrix}0\\
h_{1}\\
\vdots\\
0
\end{bmatrix}
\end{array}
$$ Unless I can find a good notion of this derivative, I am going to have to stop thinking about the problem in terms of matrix products, and instead think of it a very large number of equations based around the members of the the matrix.
Thinking about it this way loses me abstraction,
and if i am not clever enough it will increase my algorithms exectution time when it comes time to run this though BLAS Software (Basic Linear Algabra System, is the special software that access the functionality of the CPU that can do matrix math quickly) I suspect thinking of it as elementwise equations is going to be my oldy way forward, most texts i've seen seem to be refering to these relationships, with definations like $$y_{i}=\sum_{0\le j\le k}h_{j}w_{i,j}
 $$ So my question: Is there a good notion of a vector by matrix derivative? For reference I am attempting to rederive the backproperation learning algorithm for neural nets of arbitrary number of layers","['multivariable-calculus', 'vectors', 'matrices', 'tensor-products', 'derivatives']"
638212,"Evaluate $\iint_{x<u,y<v, x^2+y^2<1} dx\,dy$","How can I evaluate the following double integral: $$\iint\limits_{\substack{x<u,y<v, \\ x^2+y^2<1}} dx\,dy$$ If we didn't have the restrictions $x<u, y<v$ polar coordinates would have worked quite nicely to give $\pi$ , the area of a unit circle, but how do I proceed here? All suggestions are welcome. Thank you in advance.","['definite-integrals', 'multivariable-calculus', 'integration']"
638216,Spectral theorem for unbounded self-adjoint operators on REAL Hilbert spaces,"In all books that I have checked the spectral theorem (every self-adjoint operator on a Hilbert space is unitary equivalent to a multiplication operator on some $L_2(\mu)$) is only stated for complex Hilbert spaces (and the use of the Cayley transformation for the reduction to the bounded case requires indeed complex scalars). However, since the spectrum of a a self-adjoint operator is real the theorem should be true in real Hilbert spaces. I can imagine an argument by complexification but there a number of things to do). Hence the question: Is there an easily accessible reference to the spectral theorem in real Hilbert spaces? The question is now also discussed on MathOverflow .","['reference-request', 'functional-analysis']"
638233,Functors and Groups,"Let $\alpha$  be a functor from the category of groups in the category of groups which assigns to every group $G$ a characteristic subgroup $\alpha (G)$ of $G$ and to every homomorphism $\theta : H \rightarrow K$ the restriction  $\theta|_{\alpha(H)}:\alpha(H)\rightarrow \alpha(K)$ (in other words, $\alpha(H)^\theta \leq \alpha(K)$). So we have, in particular, that $\alpha(H)^\theta \leq \alpha(H^\theta)$. Is it true that also happen that $\alpha(H)^\theta$ is equal to  $\alpha(H^\theta)$? I think it holds, but why? References D.J.S. Robinson, ""Finiteness Conditions and Generalized Soluble Groups"", Vol. 1 Pag. 18, (1.3, at the bottom of the page)","['category-theory', 'group-theory', 'abstract-algebra']"
638245,Why isn't $y=(x^6)^{1/3}$ a polynomial function?,I've been told that $y=(x^6)^{1/3}$ isn't a polynomial function because of the radical but I believe that the equation could be simplified to $y=x^2$ which fits the definition of a polynomial function.,"['algebra-precalculus', 'functions', 'polynomials']"
638251,Probability of a path of a given length between two vertices of a random graph,"Suppose that in  random graph $G$ on $n$ vertices any $2$ vertices can be connected by an edge with probability $\dfrac{1}{2}$, independently of all other edges.  What is the probability  $P_n(k)$ that two arbitrary vertices are connected by a simple path of length $k$, $0<k \leq n-1$? My attempt. Fix $2$ vertices. To build a path of length $k$ we have to  choose $k-1$ vertices from the remaining $n-2$ vertices. Since order is important we can do it in $(k-1)! {n-2 \choose k-1}$  ways. There are $2^k$ configurations of the edges for a path of length $k$. Thus the probability seems to be 
$$
P_n(k)=\frac{(k-1)! {n-2 \choose k-1}}{2^k}.
$$
The sum over all path lengths, $\displaystyle \sum_{k=1}^{n-1}P_n(k)$, must equal $1$, but my calculations for small $n$ show that it is not $1$. Where is my mistake?","['probability', 'random-graphs']"
638259,Is it possible to obtain the Uniform distribution as the difference of two independent random variables?,"Is it possible to have two independent random variables X,Y with identical distribution, such that  $X-Y \sim \text{Uniform}[a,b]$? I am almost certain that is not, but maybe I am overlooking something?","['statistics', 'probability-distributions', 'convolution']"
638266,Measure and Probability,Can someone tell me that how did the idea to relate measure and probability come?(What's the conceptual history of measure and probability?),"['measure-theory', 'math-history', 'probability']"
638282,"How is the ""cooking"" done in surveys","In my country there's an official center undertaking surveys of voting intention every 4 months. However, they provide only ""direct"" voting intention, and the statistics obtained are usually pretty far away from the final results in the election day (people voting right wing parties usually pretend they don't or just say they don't know what they are going to vote yet). So, if you want a good estimator of the real voting intention you have to correct the data collected (in my country it is called ""cooking"" the survey, but I don't know how is it called outside), using in some way the information given by the deviations in previous elections. Do you know any paper or reference that studies this cooking corrections with some mathematical rigor? Or can explain how this corrections are developed?","['statistics', 'statistical-inference', 'parameter-estimation']"
638293,Evaluate $\sum_{n=1}^{\infty} \left( \arctan \frac{4n - 1}{2} - \arctan \frac{4n - 3}{2} \right)$,"I got stuck on the following series:
$$ \sum_{n=1}^{\infty} \left( \arctan \frac{4n - 1}{2} - \arctan \frac{4n - 3}{2} \right). $$
I can't seem to make an approach because there's $-3$ not $+3$. Please help!","['summation', 'sequences-and-series']"
638308,Orthogonality of sine and cosine integrals.,"How to prove that
$$ \int_{t_0}^{t_0+T} \sin(m\omega t)\sin(n\omega t)\,\mathrm{d}t$$ 
will equal to $0$ when $m\ne n$ and $\frac{T}{2}$ when $m=n\ne 0$?
Besides
$$ \int_{t_0}^{t_0+T} \cos(m\omega t)\cos(n\omega t)\,\mathrm{d}t$$
will equal to $0$ when $m\ne n$ and $\frac{T}{2}$ when $m=n\ne 0$ and $T$ when $m=n=0$?","['definite-integrals', 'calculus', 'integration']"
638322,The 7-th derivative of $ x^3 \cdot\tan(2x) $ is this right,"I have to find $y^{(7)}\left(0\right)$ of $y(x)=x^3\cdot\tan{(2x)}$ So my idea was to use Taylor expansion for $\tan(2x)$ to the $7$-th element and then multiply the hole thing by $x^3 $ and then replacing $x$ with $ 0$, since $ x^3$ isn't 7-th times differentiable. My question is, is this allowed  and if yes when and how. If not any ideas for an easy way of doing it ?","['calculus', 'derivatives', 'taylor-expansion']"
638323,"Trying to show that $C([0,1])$ is a complete metric space, using the norm $\|f|| = \max_{x\in [0,1]} |f(x)|$.","I think I have this problem almost done. I am taking $C([0,1])$ to be the set of all continuous function $f\colon[0,1] \to \mathbb{R}$. I have already shown that  $\displaystyle\|f\| = \max_{x\in [0,1]} |f(x)|$ is indeed a norm on $C([0,1])$ and makes it a normed space. My next step was to show that if $f_n$ is a Cauchy sequence in $C([0,1])$ then for all $x \in [0,1]$ $f_n (x)$ is a Cauchy sequence in $\mathbb{R}$. That wasn't too hard. Now I'm stuck trying to show the pointwise convergence of each sequence, that is $f(x) = \lim_{n \to \infty} f_n (x)$, by showing that 
$\displaystyle\sup_{x \in [0,1]} |f(x) - f_n (x)| \to 0 ,(n \to \infty)$. I don't think it would be to difficult to show that $f \in C([0,1])$ after that and then I would have shown that $C([0,1])$ is a complete metric space. Any help is greatly appreciated.","['general-topology', 'metric-spaces', 'real-analysis']"
638334,"How should I think about reflexive spaces? What ""property"" do I get from a space being reflexive?","Let $(X,\| \cdot \|_X)$ be a $\mathbb{R}$-vector space with bidual space $X^{**}$. We defined $X$ to be reflexive, if the canonical embedding $\mathcal I: X \to X^{**}$ with $$\mathcal I x(l) := l(x)$$ for all $l \in X^*, x \in X$ is surjective. I know for example Hilbert spaces are reflexive, $L^p$ spaces are reflexive for $1 < p < \infty$ and $L^1$ is not reflexive. However, I have no idea how I should think about reflexive spaces. I have seen theorems requiring reflexivity in the proof, however I don't understand why there is no proof if the canonical embedding is not surjective (of course I can't find any such proof either). For example, we have seen the following ""approximation theorem"": Let $X$ be reflexive, $M \subset X$ non-empty, convex and closed, $x_0 \in X \setminus M$. Then, there exists $m_0 \in M$ such that $$\| x_0 - m_0 \|_X = \operatorname{dist} (x_0, M) = \operatorname{inf}_{m \in M} \| x_0 - m \|_X.$$ It feels to me as if the fact that $M$ is closed should suffice for this theorem, however of course I am imagining the space as $\mathbb{R}^n$ which I guess I shouldn't. Is there some ""property"" every reflexive space automatically gains? I only see that we can use surjectivity very efficiently to prove those theorems, however I have no clue why there can't be any other proof without surjectivity or without using the canonical embedding at all. Usually, for other requirements of a theorem, it is easy to understand why certain property is crucial but with this property I am struggling.",['functional-analysis']
638354,Solving recurrence relation with generating functions - Nearly got the answer,"I'm trying to solve the following recurrence relation (Find closed formula) using generating functions: $f(n)=10f(n-1)-25f(n-2)$, $f(0)=0$, $f(1)=1$ I'm having a small difficulty at the end and can use a nudge in the right direction. My solution Define $$g(x)=\sum_{n=0}^{\infty}f(n)x^n = \sum_{n=2}^{\infty}f(n)x^n+x=10\sum_{n=2}^{\infty}f(n-1)x^n-25\sum_{n=2}^{\infty}f(n-2)x^n+x =$$ $$=10x\sum_{n=2}^{\infty}f(n-1)x^{n-1}-25x^2\sum_{n=2}^{\infty}f(n-2)x^{n-2}+x =$$ $$=10x\sum_{n=1}^{\infty}f(n)x^n-25x^2\sum_{n=0}^{\infty}f(n)x^n+x$$ But since the first element of $f(n)$ is $0$, then $$10x\sum_{n=1}^{\infty}f(n)x^n=10x\sum_{n=1}^{\infty}f(n)x^n+0=10x\sum_{n=0}^{\infty}f(n)x^n$$ So overall: $$g(x)=10x\sum_{n=0}^{\infty}f(n)x^n-25x^2\sum_{n=0}^{\infty}f(n)x^n+x=10xg(x)-25x^2g(x)+x$$ To sum up: $$g(x)=10xg(x)-25x^2g(x)+x$$ Solve for $g(x)$ and get: $$g(x)=\frac{x}{(x-\frac{1}{5})^2}$$ But what do I do now? How can I extract $f(n)$ from this information?","['generating-functions', 'recurrence-relations', 'summation', 'combinatorics']"
638363,Checking random number generators,"Given a function:
$$
f(x) = \begin{cases} ax^2 & \text{for } x\in [ -1, 1], \\0 & \text{for } x\notin [-1,1].\end{cases}
$$
I am to create a random number generator. I did this by finding the CDF and so I end up with
$$X = \sqrt[3]{2F-1}$$
(F being some random variable generated in a spreadsheet, for example) The problem arises, however, with next tasks: a) How can we check that this generator generates numbers with a given distribution? b) Use the generator you found and the knowledge of central limit theorem to create a generator with $N(0,1)$ distribution and test it (One can use spreadsheet or programming language for the tasks) So as for the first, can I just generate a lot of data using the generator and then divide the $<max,min>$ into 10 intervals and see if the numbers that fall into them form a bell curve? As for the latter, If the distribution is to be $N(0,1)$ and the generator from point a) gives me $<-1,1>$, can I just take an absolute value of it and again - divide into intervals, try to see if a bell curve forms?",['statistics']
638374,Prove that the set of all matrices is direct sum of the sets of skew-symmetric and symmetric matrices,"Let $W_1$ be the subspace of $\mathcal{M}_{n \times n}$ that consists of all $n \times n$ skew-symmetric matrices with entries from $\mathbb{F}$, and let $W_2$ be the subspace of $\mathcal{M}_{n \times n}$ consisting of all symmetric $n \times n$ matrices. Prove that $\mathcal{M}_{n \times n}(\mathbb{F}) = W_1 \oplus W_2$. I couldn't really figure out why the sum of an $n \times n$ symmetric matrix and $n \times n$ skew-symmetric matrix would form a $n \times n$ matrix (to satisfy the direct summand property $W_1 + W_2 = \mathcal{M}_{n \times n}(\mathbb{F})).$ Browsing online, I found that $$ M = \frac{1}{2}(M + M^{t}) + \frac{1}{2}(M-M^{t}),$$ where $\frac{1}{2}(M+M^{t}) \in W_2, \frac{1}{2}(M-M^t) \in W_1$, and $M \in \mathcal{M}_{n \times n}(\mathbb{F})$. This reminds me of a formula on how odd and even functions may be be added together to form a generic function. $$f(x) = \frac{f(x)+f(-x)}{2} + \frac{f(x)-f(-x)}{2}.$$ However, to me it is disturbing to use unless I know how it was derived. If anyone could show me why a skew-symmetric matrix may be represented as $\frac{1}{2}(M-M^t)$ and why a symmetric matrix may be represented as $\frac{1}{2}(M+M^t)$ than I may sleep better tonight. Thanks.","['symmetric-matrices', 'matrices', 'linear-algebra']"
638375,Tangent space of Grassmannian $Gr_k (\mathbb{R}^n)$,"I am trying to show that the tangent space of the Grassmannian $Gr_k (\mathbb{R}^n)$ at $L,$ is naturally/canonically isomorphic to $Hom(L,\mathbb{R}^n/L).$ However, I cannot see even intuitively what this isomorphism is. Any help would be appreciated!","['geometry', 'manifolds', 'differential-geometry']"
638406,Interior ball condition,"Let $\Omega\subset\mathbb{R}^n$ be a open set. We say that $y\in\partial \Omega$ satisfies the interior ball condition, if there is $x\in \Omega$ and $r>0$ such that $$B(x,r)\subset\Omega,\ y\in \partial B(x,r),$$ where $B(x,r)=\{z\in\mathbb{R}^n:\ \|z-x\|<r\}$. I am trying to prove that (I don't know if it is true) the set of points in $\partial \Omega$ which satisfies the interior ball condition are dense in $\partial\Omega$. If we go by contradiction then, there is $y\in\partial\Omega$ (which we can assume to not be isolated) and a neighborhood $F$ of $y$ ($F\subset\partial\Omega$) such that $$d(x,\partial\Omega)<d(x,F),\ \forall x\tag{1}$$ Now I am trying to get a contradiction with $(1)$. Any idea is appreciated. Update: I think I have a answer, please verify if it is correct. Assume ad absurdum that there is $y\in \partial\Omega$, $y$ is not isolated in $\partial\Omega$, such that in the set $V_r=\overline{B(y,r)\cap \partial\Omega}$ (for some $r>0$) there is no point which satisfies IBC. If there is $x\in \Omega$ with $d(x,\partial\Omega)= d(x,V_r)$ we are done, hence, assume that $(1)$ is satisfied for $F=V_r$. Take $z\in V_r$ with $\|z-y\|<\delta$ and $0<\delta<r$. As $d(z,\partial\Omega)<d(z,V_r)$, the infimum of $d(z,\partial\Omega)$ is achieved in $\partial\Omega\setminus V_r$ in some point $w_{\delta}$. By choosing $\delta$ sufficiently small, we must have that $\|z-y\|=d(z,y)<d(z,w_{\delta})$, because $w_{\delta}$ is outside the ball $B(x,r)$. Therefore, we have a contradiction.","['proof-verification', 'analysis']"
638414,"Is $\iint\limits_{D}\frac{1}{(x^{2}+y^{2})^{5}+5}dx\,dy$ convergent in $D=[0,+\infty)\times[0,+\infty)$","Can you tell me whether my approach is correct. We first switch to polar coordinates and we get the following integral: $\int\limits_{0}^{\frac{\pi}{2}}\int\limits_{0}^{\infty}\frac{r}{r^{10}+5}d\phi dr=\int\limits _{0}^{\frac{\pi}{2}}d\phi\int\limits _{0}^{\infty}\frac{r}{r^{10}+5}dr=\frac{\pi}{2}\int\limits _{0}^{\infty}\frac{r}{r^{10}+5}dr$ From now on we solve it as it were an improper integral of single variable. We know that $\int\limits _{1}^{+\infty}\frac{1}{r^{\alpha}}$ is convergent $\iff\alpha\ge2$. We use the following criteria. Let $F(x)\ge 0,\,G(x)\ge 0$ be such that $\lim\limits_{x\to\infty}\frac{F(x)}{G(x)}=\lambda,\lambda\in\mathbb{{R}}\cup\{+\infty\}$. If $\lambda$ is real and if $\int\limits_{a}^{+\infty}G(x)dx$ is convergent $\implies \int\limits _{a}^{+\infty}F(x)dx$ is also convergent. We take $G(r)=\frac{1}{r^{9}}$ and compute $\lim\limits_{r\to\infty}\frac{F(r)}{G(r)}=\frac{r^{10}}{r^{10}+5}=1$, hence the integral is convergent.","['multivariable-calculus', 'improper-integrals']"
638423,"Show that $\lim_{n\to \infty}\left[ \int_a^bf(x)^n\,dx \right]^{1/n}=\max_{x\in[a,b]}f(x).$ [duplicate]","This question already has answers here : If $f(x)$ is continuous on $[a,b]$ and $M=\max \; |f(x)|$, is $M=\lim \limits_{n\to\infty} \left(\int_a^b|f(x)|^n\,\mathrm dx\right)^{1/n}$? (2 answers) Closed 10 years ago . Suppose $f:[a,b]\to \mathbb{R}$ is continuous and positive. Show that
  $$\lim_{n\to \infty}\left[ \int_a^bf(x)^n\,dx
Â \right]^{1/n}=\max_{x\in[a,b]}f(x).$$ My progress: A simpler version of the problem is to suppose $x_1, \dotsc, x_m$ are positive numbers, and show that $$\lim_{n\to\infty}\left( x_1^n + \dotsb + x_m^n \right)^{1/n} = \max_i x_i.$$ This we can do by showing that $\log \left( x_1^n + \dotsb + x_m^n \right)^{1/n} \to \log (\max_i x_i)$. $$\log \left( x_1^n + \dotsb + x_m^n \right)^{1/n} = \frac{1}{n}\log \left( x_1^n + \dotsb + x_m^n \right) = \frac{1}{n}\left( n\log\left( \max_i x_i \right) + \log \left( \left(\frac{x_1}{\max_i x_i} \right)^n + \dotsb + \left(\frac{x_M}{\max_i x_i} \right)^n \right)\right)\\ = \log\left(\max_i x_i\right) + \frac{1}{n}\log\left(\text{bounded}\right)\to \log\left( \max_i x_i\right).$$ Now with the case of a function being integrated, if we tried the same argument, letting $M= \max_{x\in [a,b]}f(x)$, we'd have $$\log \left( \left(\int_a^b f(x)^n\,dx \right) ^{1/n}\right) = \log M + \frac{1}{n}\log \left(\int_a^b (f(x)/M)^n \, dx \right),$$ and now the task is to show that the second term goes to zero. I see that it goes to zero if $\{x\mid f(x)=M\}$ has positive measure, since then the integral is bounded below by the measure of that set. How can we show the second term goes to zero otherwise?","['integration', 'analysis']"
638427,Generalization of the Lagrange Multiplier,"Let's say that I have a submanifold cut out of $\mathbb{R}^{n+k}$ as $f^{-1}(0)$ where $f:\mathbb{R}^{n+k} \rightarrow \mathbb{R}^k$ is smooth and $0$ is a regular value. The Lagrange multiplier criterion tells me that if $x\in f^{-1}(0)$ is a critical point of $g|_{f^{-1}(0)}$ where $g:\mathbb{R}^{n+k} \rightarrow \mathbb{R}$, then there is a linear function $\lambda:\mathbb{R}^k \rightarrow \mathbb{R}$ such that $DG(x) + \lambda DF(x) = 0$. One can use this to probe for critical points of $g$ by first considering solutions of the system of equations $DG(x) + \lambda DF(x) = 0$ and $f(x) = 0$ for varying $\lambda$. Can you adapt this in a useful way to the scenario where $g$ is a vector valued function? i.e. $g:\mathbb{R}^{n+k} \rightarrow \mathbb{R}^{l}$ and $\lambda:\mathbb{R}^k \rightarrow \mathbb{R}^{l}$ If not, then what is a good approach to computing the sets of critical points of such vector valued functions.",['multivariable-calculus']
638448,How do i prove that every linear operator between finite-dimensional Hilbert spaces is bounded?,"When I learned basic linear-algebra, ""adjoint"" was only defined for linear operator between finite-dimensional inner product spaces. Right now, I'm studying Hilbert spaces and I want the past definition consistent with a new definition. I have proved following theorem in basic linear-algebra: Let $V,W$ be inner product spaces over $\mathbb{F}$ . Let $T:V\rightarrow W$ be a linear operator. If $V$ is finite-dimensional, there exists a unique function $T^*$ such that $\langle T(x),y\rangle=\langle x,T^*(y)\rangle$ . So my question is; How do I prove that $T$ is bounded when $V$ and $W$ are finite-dimensional? Moreover, is it true when $V$ is finite-dimensional but $W$ is not?",['linear-algebra']
638453,Is a compensated Poisson process uniformly integrable,"Let $(N_t)_t$ be a Poisson process with intensity $\lambda$. Define
$$
\bar{N}_t = N_t - \lambda t
$$
which is clearly a martingale. My question is: is $\bar{N}$ uniformly integrable?
I strongly suspect the answer is NO, but if I try to compute $\mathbb{E}(\bar{N}_{T_i})$ I always get $0$. Here $T_i$ is the $i$-th jump time of $N$. In other words I am not able to give a simple example of a stopping time $T$ such that
$\mathbb{E}(\bar{N}_T) \neq \mathbb{E}(\bar{N}_0)$ Thanks in advance Tom","['probability-theory', 'stochastic-processes', 'uniform-integrability']"
638501,Hartshorne's Exercise II.5.1 - Projection formula,"I'm trying to solve Exercise 5.1 of Chapter II of Hartshorne - Algebraic Geometry . I'm fine with the first $3$ parts, but I'm having troubles with the very last part, which asks to prove the projection formula : Let $f:X\to Y$ be a morphism of ringed spaces, $\mathscr{F}$ an $\mathcal{O}_X$-module and $\mathcal{E}$ a locally free $\mathcal{O}_Y$-module of finite rank. Then there is a natural isomorphism
  $$ f_*(\mathscr{F}\otimes f^*\mathcal{E}) \;\cong\; f_*(\mathscr{F})\otimes \mathcal{E} $$ After thinking quite a long time about it, I checked on the internet and I found the following solution: $$
\begin{eqnarray} 
f_*(\mathscr{F}\otimes f^*\mathcal{E}) 
&\;\cong\;& f_*(\mathscr{F}\otimes \mathcal{O}_X^{\,n}) \\\\
&\;\cong\;& f_*(\mathscr{F}\otimes \mathcal{O}_X)^{n} \\\\ 
&\;\cong\;& f_*(\mathscr{F})^{n} \\\\ 
&\;\cong\;& f_*(\mathscr{F})\otimes \mathcal{O}_Y^{\,n} \\\\ 
&\;\cong\;& f_*(\mathscr{F})\otimes \mathcal{E} \\\\ 
\end{eqnarray}
$$ Is this correct? If it is, could you explain me why do we have the isomorphism
$$ f_*(\mathscr{F}\otimes \mathcal{O}_X^{\,n})
\;\cong\; f_*(\mathscr{F}\otimes \mathcal{O}_X)^{n} \quad ?  $$","['sheaf-theory', 'algebraic-geometry', 'ringed-spaces']"
638574,Text on Probability Theory applied to Actuarial Science,"I am a senior undergraduate who has passed the first three actuarial exams on probability (P), financial mathematics (FM), and models for financial economics (MFE). I am working on passing the life contingencies exam in April. For my final semester as an undergraduate, I am doing an independent study to learn about measure-theoretic probability theory in the context of actuarial science. I am especially interested in learning the theory behind Ito calculus and the proof of the Black-Scholes equation and formula, rather than just doing routine calculations using these formulas (like in exam MFE). The current plan is to start off with A Probability Path and Adventures in Stochastic Proccesses both by Resnick, but none of these cover Ito calculus. They touch on Brownian motion and martingales for a little bit, but not very much of it. I have taken two semesters of real analysis (we covered everything up to complete metric spaces and integration and differentiation in $\mathbb{R}^n$) and will be taking my second semester in abstract algebra (vector spaces, group actions, Sylow $p$-groups, and some other stuff I don't know about). Is there a text that we can use during this independent study that would be accessible to me that pertains to Ito calculus and its applications to finance (and/or actuarial science)? Edit : Two texts that I have found in my research are Brzezniak and Zastawniak and Ãksendal . Does anyone have a particular preference of one of these over the other? Are there any other texts you would recommend?","['stochastic-processes', 'probability-theory', 'finance', 'reference-request', 'actuarial-science']"
638575,how to show that integral depending on a parameter are continuously differentiable,"I'm trying to solve this exercise Let $f:[0,1]\to \mathbb{R} \space$ an integrable function, show: $$g(z):=\int_{0}^1\frac{f(x)}{x-z}dx$$ is a continuous differentiable function on $\mathbb R \backslash[0,1]$. This is what I've done: we have seen two theorems in class. One allows me to see whether an integral is differentiable and calculate its derivative, while the other one allows me to see whether the integral is continuous (If you need them I can post them). Therefore I've decided to check first whether the integral was differentiable and after that whether the derivative of the integral was continuous. To check whether the integral is differentiable I've to check 1) the function inside the integral is in $L^1$, 2) that she is differentiable with derivative $\frac {\delta f(x,z)}{\delta z}$, where $f(x,z):=\frac{f(x)}{x-z}$. 3) I have to check whether the derivative has a dominating function. Here are my calculation: 1) I was unsure about this point. I've considered the fact that $z \in (-\infty,\epsilon) \cup (1+\epsilon, +\infty)$ where $\epsilon \gt0$ and that $x \in [0,1]$ to point out that the denominator must be bounded by some constant $C\gt0$ (is this true? Can I do it?). If I do like this I get that the denominator is never 0 and this implies that the function $\frac{f(x)}{x-z}$ is integrable. 2)I've calculated the derivative (since the derivative exist by the previous point at every point z) $$\frac {\delta f(x,z)}{\delta z}= \frac {\delta}{\delta z} \frac{f(x)}{x-z}=\frac {f(x)}{(x-z)^2}$$ 3) by doing the same reasoning as in 1) I've thought that the denominator can't vanish and hence there exist a dominating function which is in $L^1$ The derivative of g(z) will be $$g(z)'= \int_{0}^1 \frac {f(x)}{(x-z)^2}dx$$ Now what I've done is to check that this function is continuous on $\mathbb {R}\backslash [0,1]$ (I have to check 1') the function inside the integrale is measurable, 2') she is continuous for x fixed and 3') there exist a dominating function of the function inside the integrale) 1) the function $\frac {f(x)}{(x-z)^2}$is measurable since $f(x)$ measurable and $(x-z)^2$ measurable (since is never 0 and never $\infty$, hence is a number, hence is continuous) 2) the function is continuous since composition of continuous functions (same argument as above) 3) same argument as above with dominating function h defined as: $$h(x) =\begin{cases}
f(x) & \text{if } (x-z)\le 1 \\
   (\frac {1}{C}+\epsilon)      & \text{if } (x-z)\lt 1
  \end{cases}$$ where $C = (x-z)$ and $\epsilon \gt 0$ Did I do everything wrong? Is there a simple way to see if an integral depending on a parameter is continuous / differentiable / continuously differentiable?","['measure-theory', 'integration']"
638582,Rings that are isomorphic to the endomorphism ring of their additive group.,"Every ring is isomorphic to a subring of the endomorphism ring of it's underlying group. That's Cayley's theorem for rings . What can we say about rings that are isomorphic to the endomorphism ring of their underlying additive group? (are they always integral domains? ADDED: no, $Z/nZ$ is a counter example. from the comment by egreg)","['ring-theory', 'abstract-algebra']"
638605,How general are $\mathrm{Aut}$ groups and $\mathrm{End}$ rings?,"For any locally small category $X$ and object $A\in X$ the set $\mathrm{Aut}_X(A)$ is a group w.r.t. composition $\circ$.
For any locally small abelian category $X$ and object $A\in X$ the set $\mathrm{End}_X(A)$ is a ring w.r.t. $+,\circ$. Does for any group $G$ exist $X$ and $A$ with $G\cong\mathrm{Aut}_X(A)$? We know that $G$ is a quotient of the free group $F_G$, and is a subgroup of the permutation group $S_G=\mathrm{Aut}_{Set}(G)$. Does for any unital ring $R$ exist $X$ and $A$ with $G\cong\mathrm{End}_X(A)$? We know that $R$ is a quotient of the free ring $\mathbb{Z}\langle R|\emptyset\rangle$. Is it also a subring of some 'typical' ring? Perhaps $\mathrm{End}_{\mathbb{Z}}(?)$. This post is related.","['ring-theory', 'category-theory', 'group-theory', 'abstract-algebra']"
638616,How does the Jacobian relate 3D to 2D?,"May be it is simple, but I'm on Google for hours without finding a clue. I'm reading an article in computer vision where the optical flow equation is $\nabla I\cdot v + {dI \over dt} = 0 $ and for the 3D version it is $\nabla  I\cdot [J_\pi V]+{dI \over dt}=0$ I understand most of the paper but this sentence ""where the associated 3D displacement of a point is related to the motion of its projection by the $2 \times 3$  Jacobian matrix $J_\pi={\partial p \over \partial P}$ "" $P$ is a 3D point and $p$ is a 2D one, $v$ is 2d vector and $V$ is a 3D one, $\pi$ is the projection matrix (I think), I don't understand this Jacobian part, thanks in advance for any help or guidance. EDIT: Link to the original article has been added.",['multivariable-calculus']
638635,"If $A$ and $B$ are independent, what can we say about $P(X\mid A,B)$?","Given two independent events A and B, what can we say about $P(X\mid A,B)$ ? Is the following correct ? $$P(X\mid A,B) = \frac{P(A,B\mid X)P(X)}{P(A,B)}\tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(A\mid X)P(B\mid X)P(X)}{P(A)P(B)} \tag{Independence}$$ $$P(X\mid A,B) = \frac{\frac{P(X\mid A)P(A)}{P(X)}\frac{P(X\mid B)P(B)}{P(X)}P(X)}{P(A)P(B)} \tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(X\mid A)P(X\mid B)}{P(X)}$$",['probability']
638640,Compact operator with closed range has finite dimensional range,"I have to prove that: If $X,Y$ be Banach Spaces, and $T\in B(X,Y)$ is a compact operator, then $T(X)$ is closed in $Y$ if and only if $\dim T(X)<\infty$ . Can anybody help me with this proof, please? There is surely some property I haven't thought about, but I'm getting really weird right now... Thank you!","['compact-operators', 'functional-analysis', 'banach-spaces']"
638646,Can $18$ consecutive integers be separated into two groups such that their product is equal?,"Can $18$ consecutive positive integers be separated into two groups such that their product is equal?  We cannot leave out any number and neither we can take any number more than once. My work: When the smallest number is not $17$ or its multiple, there cannot exist any such arrangement as $17$ is a prime. When the smallest number is a multiple of $17$ but not of $13$ or $11$ , then no such arrangement exists. But what happens, when the smallest number is a multiple of $ 17 $ and $13$ or $11$ or both? Please help!","['elementary-number-theory', 'combinatorics']"
638686,Cute coloring problem on a board,"Suppose we color an $n\times n$ square board using $n$ colors exactly $n$ times each. Prove that there is either a column or a row containing at least $\lceil \sqrt n \rceil$ different colors. A friend of mine gave me this problem and I managed to solve it, but I would like to know if there is a neater way. Regards.","['contest-math', 'combinatorics']"
638702,pull-back and push-forward of quasi-coherent sheaves on affine schemes,"Let $f:Y\to X$ be a map of affine schemes, where $X=\text{Spec}A$ and $Y=\text{Spec}B$. Let $M,N$ be modules over $A$ and $B$, respectively. I know the following three facts: The functors $f^{*}$ and $f_{*}$ on $\mathcal{O}_{X}$-modules and $\mathcal{O}_{Y}$-modules, respectively are adjoint to each other. $f_{*}\widetilde{N}=\widetilde{_{A}N}$, where $_{A}N$ denotes $N$ considered as an $A$-module. $f^{*}\widetilde{M}=\widetilde{M\otimes_{A}B}$. Here, $\widetilde{M}$ denotes the $\mathcal{O}_{X}$-module associated to the $A$-module $M$, etc. Starting with fact 3, the adjunction tells me that $\widetilde{M}=f_{*}\widetilde{M\otimes_{A}B}$, which, by fact 2, is $\widetilde{_{A}(M\otimes_{A}B)}$. However, I don't believe that $_{A}(M\otimes_{A}B)=M$ - for example, $A=M=\mathbb{Z}$ seems to make the left hand side equal to $B$ and the right hand side equal to $\mathbb{Z}$. Am I making a mistake somewhere?","['algebraic-geometry', 'schemes']"
638714,Partial derivative of a function on manifold,"Bishop and Goldberg define (""Tensor analysis on manifolds"") the partial derivative of a smooth function on a manifold $M$ in the following way:
$\partial_i f= \frac{\partial f}{\partial{x^i}}=\frac{\partial g}{\partial{u^i}}\circ\mu$, where $\mu= (x^1,...,x^d)$ is the coordinate system at a point $m\in M$, $g=f\circ\mu^{-1}$ is the coordinate expression for $f$, and $u^i$ are the cartesian coordinates on $R^d$. Notice the difference: $f$ is differentiated with respect to $x^i$ and $g$ with respect to $u^i$. By definition $x^i=u^i\circ\mu$. In many cases $x^i=u^i$ and I don't have any problems. But what if we consider polar coordinates ($x^1=r, x^2=\phi$) instead of standard ($x,y$)? I can't make sense of the formula defining the partial derivative.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
638724,What condition ensures the solution is periodic? (ODE),"Suppose that $\phi$ is a solution to the ODE
\begin{align}
x' = f(x) + \sin(t)
\end{align}
  What condition can we put on $f$ to ensure that $\phi$ is periodic of period $2\pi$?  That is, what do we do to $f$ so that $\phi(0) = \phi(2\pi). Okay, now for my approach.  Please tell me if I've made an error I'm pretty new to this stuff.  So, I want to make $f$ such that... (and there might be something much, much more specific and better) Denote by $x(t,\alpha)$ the solution of the ODE, $x(t)$ such that $x(0) = \alpha$.  Now, consider the function 
\begin{align}
g(\alpha) = x(2\pi,\alpha). 
\end{align}
where $\alpha \in [a,b] \subset [-1,1].$ Now, here's my ""condition"" on $f$: Choose $f$ so that $f$ is defined on the interval $[a,b]$ such that $[-1,1] \subset [a,b]$.  Let $f$ have the condition that if $x > 1, x'<0$ (This means that for $x > 1$, then $f(x) < -1$.  Similarly if $x < -1, f(x) > 1$, and thus $x' > 0$. Therefore, solutions that start in $[a,b]$ remain in $[a,b]$.  Now, this means that
\begin{align}
g: [a,b] \rightarrow [a,b],
\end{align}
and we can use Brouwer's fixed point theorem to guarantee that there exists $\alpha^{*}$ such that $g(\alpha^{*}) = \alpha^{*}$, and thus the solution $x(t,\alpha^{*})$ is $2\pi$ periodic.",['ordinary-differential-equations']
638737,Calculate the determinant of given matrix,"The matrix $A_n\in\mathbb{R}^{n\times n}$ is given by $$\left[a_{i,j}\right] = \left\lbrace\begin{array}{cc}
1 & i=j \\
-j & i = j+1\\
i & i = j-1 \\
0 & \text{other cases}
\end{array} \right.$$ I already showed that it holds $$\det{A_n}= \det{A_{n-1}}+\left(n-1\right)^2\cdot\det{A_{n-2}}$$ However, can we find an explicit expression for the determinant of $A_n$?","['matrices', 'linear-algebra', 'determinant']"
638767,Orbit space of S3/S1 is S2,"I'm having trouble finishing this homework assignment. I did the first part by showing that the orbits are invariant: every element from the same $(S^1(z_1, z_2) \in S^3/S^1)$ is mapped to the same point in $\mathbb{R}$. For the second part I found the following equations. For $(z_1, z_2), (w_1, w_2) \in S^3$: $z_1 z_2 = w_1 w_2$ $\bar{z_1} \bar{z_2} = \bar{w_1} \bar{w_2}$ $z_1 \bar{z_1} = w_1 \bar{w_1} = r$ (for some $r$) $z_2 \bar{z_2} = w_2 \bar{w_2} = 1 - r$ But I don't think that's enough to prove $(z_1, z_2) = (w_1, w_2)$, is there any more information I left out? For the third part I showed that $(f, g, h)$ maps to $S^2$ since $||(f,g,h)(z_1, z_2) = 1||^2$ for $(z_1, z_2) \in S^3$. I think that because it is well defined and point-separating we know certainly know that it's image of $X$ is the whole of $S^2$ but I can't grasp why. Don't I still have left to prove that every element of $S^2$ has an inverse in $S^3/S^2$?","['general-topology', 'low-dimensional-topology', 'algebraic-topology']"
638769,Lottery game question?,"In a lottery, you must match all 6 numbers drawn at random from 1 to 40 without replacement to win the grand prize, 5 out of 6 numbers to win second prize, and 4 out of 6 numbers to win third. The ordering of the drawn numbers is irrelevant. Find the probability of winning each prize. To win the grand prize, I think the probability is just 1/(40 Combination 6). How do you account for the fewer numbers drawn in the other two parts of the question though?","['statistics', 'discrete-mathematics', 'probability']"
638780,Is this periodic solution unique? (ODE),"So, for the ODE
\begin{align}
x' = -x^{3} + \sin t,
\end{align}
we can show that there exists a $2\pi$ periodic solution.  To do this, we denote by
\begin{align}
x(t,\alpha)
\end{align}
The solution $x(t)$ of the ODE such that $x(0) = \alpha$.  Then, let $\alpha \in [-2,2]$.  Consider the function $f(\alpha) = x(2\pi, \alpha)$
\begin{align}
x > 1 &\Rightarrow x' < 0 \\
x < 1 &\Rightarrow x' > 0.
\end{align} Thus, solutions beginning in $[-2,2]$ stay there and we can use Brouwer's fixed point theorem to show that there exists a fixed point of $f$.  Therefore there is some $\alpha^{*}$ such that $f(\alpha^{*}) = \alpha^{*}$, which represents the periodic solution $x(t,\alpha)$. Now, my question: Is this $2\pi$- periodic solution unique? Are there other $2\pi$ periodic solutions of this ODE?  I have started by trying to subtract two periodic solutions from one another but this hasn't taken me anywhere productive.","['fixed-point-theorems', 'ordinary-differential-equations', 'initial-value-problems']"
638796,Lebesgue points of density and similar notions,"Let $F\subset \mathbb{R}^d$ and $\delta(x)=d(x,F)=\inf\{|x-y|:y\in F\}$ be the distance from $x$ to $F$. It is easy to show that $\delta(x+y)\leq |y|$ for all $x\in F$. Prove the more refined estimate: 
$$\lim_{|y|\rightarrow0}\frac{\delta(x+y)}{|y|}=0,\text{ for a.e. }x\in F .$$ Notes A hint is given that says ""Assume $x$ is a point of density of $F$ and use the conclusion: If $E$ is a measurable subset of $\mathbb{R}^d$ then almost every $x\in E$ is a point of density of $E$, and almost every $x\in E^c$ is not a point of density of $E$. I have proved the above result (under notes) using the Lebesgue differential theorem in a previous question. But I am having difficulty relating the limit in the question to that in the definition of a Lebesgue point of density, although they seem very similar. Any help is appreciated. Thanks!","['measure-theory', 'lebesgue-measure', 'real-analysis', 'analysis']"
638829,The Definition of the Second Fundamental Form,"Let $r:M\rightarrow{\mathbb{R}^{n+1}}$ be an isometric immersion and $M$ is an $n$ -dimensional Riemannian Manifold. That is to say, $M$ is the hypersurface in $\mathbb{{R}^{n+1}}$ . Then we can introduce a normal vector field: $N:M\rightarrow{T\mathbb{{R}^{n+1}}}=\mathbb{R}^{n+1}\times{\mathbb{R}^{n+1}}$ satisfies $N_p\in{T_{r(p)}\mathbb{R}^{n+1}}=\{r(p)\}\times\mathbb{R}^{n+1}$ . So we will have $T_{r(p)}\mathbb{R}^{n+1}=r_*(T_pM)\oplus{span\{N_p\}}$ . Before we talk about this problem, we look at the connection on $\mathbb{R}^{n+1}$ . Let $\bigtriangledown$ be its connection and $X=\sum_{i=1}^{n+1}x_ie_i$ , $Y=\sum_{i=1}^{n+1}y_ie_i$ . So $\bigtriangledown_XY=\sum_{i=1}^{n+1}\sum_{j=1}^{n+1}x_je_j(y_i)e_i$ . When I read book, I find two different definitions of The Second Fundamental Form . I want to verify that they are the same. Let $\bar{n}$ denote the Guass Map which is actually: $n=\pi_2\circ{N}:M\rightarrow{\mathbb{R}^{n+1}}$ . The first definition is: $II|_U=\sum_{i=1}^{n}\sum_{j=1}^{n}<\bigtriangledown_{\frac{\partial{r}}{\partial{x_i}}}N,\frac{\partial{r}}{\partial{x_j}}>dx_i\otimes{dx_j}$ The second definition is: $II|_U=\sum_{i=1}^{n}\sum_{j=1}^{n}<\frac{\partial{n}}{\partial{x_i}},\frac{\partial{r}}{\partial{x_j}}>dx_i\otimes{dx_j}$ So I think they are the same. Then I try to prove it. But I am failed. I want to prove $\bigtriangledown_{\frac{\partial{r}}{\partial{x_i}}}N=\frac{\partial{n}}{\partial{x_i}}$ . Proof. Let $\frac{\partial{r}}{\partial{x_i}}=\sum_{k=1}^{n+1}\frac{\partial{r_k}}{\partial{x_i}}e_k$ and $N=\sum_{k=1}^{n+1}n_ke_k$ . Then I have no idea. How to prove??","['surfaces', 'riemannian-geometry', 'differential-geometry']"
638835,How to calculate $\delta(x^4-\alpha^4)$?,"Does the following equality hold?
\begin{equation}
\delta(x^4-\alpha^4)=\frac{1}{4\vert \alpha \vert} \left[ \delta(x-\alpha)+ \delta(x+\alpha) + \delta(x+i\alpha) + \delta(x-i\alpha)\right].
\end{equation}","['calculus', 'integration', 'analysis']"
638836,The distance function on a metric space,"Let $(X,d)$ be a metric space and $A\subset X$ and $x\in X$ . Then $x\to d(x,A)$ is a uniformly continuous function. If $\partial A=\{x\in X\,:\,d(x,A)=0\}\cap\{x\in X\,:\,d(x,X-A)=0\}$ , then $\partial A$ is closed for any $A\subset X$ . If $A,B$ are subsets of $X$ then $d(A, B)=d(B,A)$ . If the function is uniformly continuous then $d(x,y)<\delta $ implies $d(d(x,A)-d(y,A))<\epsilon$ , I can not handle the last expression. Difficulty continues for 3rd choice also.
At least give me some hints. And for the 2nd choice I think it is true, as it is intersection of two closed sets. As finite intersection of closed sets closed $\partial A$ closed. And logic for former two sets closed is that the sets are preimage of closed set (singleton $\{0\}$ is closed as $\mathbb R$ is $T_1$ ) under continuous map. I am not very much sure about my ideas and want a verification.","['general-topology', 'metric-spaces', 'real-analysis', 'uniform-continuity']"
638860,How to construct a bump function ends at different value?,"May I ask how to construct a ''bump'' function ends at different value? For example: $\Psi\colon [0,1] \to [0,1]:$
$$ \Psi (x) = 
  \begin{cases}
    0 & \quad \text{for $0 \leq x < 1/3$}\\
    ??? & \quad  \text{for $1/3 \leq x < 1/2$}\\
   1 & \quad \text{otherwise}
  \end{cases}$$",['analysis']
638861,Integral = 0 implies function = 0?,"If $f : \mathbb{R}^2 \to \mathbb{R}$ is continuous and such that
$$
\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \! f(x,t) \phi(x,t) \, \mathrm{d}x \, \mathrm{d}t = 0
$$
for all $\phi \in C_c^{\infty}(\mathbb{R}^2)$ (that is, for all compactly supported smooth functions), then is it true that $f$ must be identically equal to $0$ ? I thought taking, in particular, $\phi_n \in C_c^{\infty}(\mathbb{R}^2)$ to be equal to $0$ outside the disk of radius $n$ centered at the origin, to $f$ where $f \geq 0$ and to $-f$ where $f < 0$ would permit us to prove this, but unfortunately it seems like such $\phi_n$ need not be $C^{\infty}$...","['definite-integrals', 'improper-integrals', 'integration', 'functions']"
638873,Definition of primary ideal question,"A primary ideal (in a commutative ring with unity) is an ideal $J$ for which if $ab\in J$, then either $a\in J$ or $b^n\in J$ for some integer $n\geq 1$. So it also implies (due to commutativity) that if $ab\in J$, then $a^m,b^n\in J$ for some integers $m,n\geq 1$. Wouldn't the latter be a nicer definition for a primary ideal? Why is it not used?","['ring-theory', 'ideals', 'abstract-algebra']"
638874,factor $z^7-1$ into linear and quadratic factors and prove that $ \cos(\pi/7) \cdot\cos(2\pi/7) \cdot\cos(3\pi/7)=1/8$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Factor $z^7-1$ into linear and quadratic factors and prove that 
$$ \cos(\pi/7) \cdot\cos(2\pi/7) \cdot\cos(3\pi/7)=1/8$$ I have been able to prove it  using the value of $\cos(\pi/7)$. Given here http://mathworld.wolfram.com/TrigonometryAnglesPi7.html","['trigonometry', 'complex-numbers']"
638891,Proving nondifferentiability at all points of a continuous function,"Given: $f_1(x)=x$ if $x\le1/2$ $f_1(x)=1-x$ if $1/2\le x\le1$ $f_1(x+1)=f_1(x)$ $\forall n\ge2,f_n(x)=(1/2)*f_{n-1}(2x)$ Let $S_m(x)=\sum_{n=1}^m f_n(x)$ $S_m$ is a continuous function on $[0,\infty]$ $(S_m)_{m\in N}$ converges uniformly to a continuous function $S$ Task: Show that $S$ is not differentiable at any point in $(0,\infty)$ My work/question: After drawing out $f_1$, $f_2$, and $f_3$, it seems to me that at every $k/(2^n)$, where $k,n$ are natural numbers, f is not differentiable. I don't know if this is useful. Does this expression account for all rational numbers? It seems like a common thing to do with proving that a function is not differentiable is to consider the limit from the left and right. I don't really know where to go with this approach though. Per user117818's comment: $\lim_{h\to 0}(S_m(x+h)-S_m(x))/h=\lim_{h\to 0}(\sum_{n=1}^m [f_n(x+h)-f_n(x)])/h$
$= \sum_{n=1}^m (\lim_{h\to 0}(f_n(x+h)-f_n(x))/h)$ I guess this shows that, for every point $a$, if there exists an $n$ such that $f_n$ is not differentiable at $a$, then $S_m$ is not differentiable at this point either. Would it be possible to show that for every point $a$, there does indeed exist an $n$ that satisfies this condition?","['calculus', 'continuity', 'derivatives', 'analysis']"
638942,Permutations for paths,"What is the counting sequence for paths from $$(0,0)\text{ to }(n,n)$$ where $$2n$$ is the size of the path (number of steps) and n can vary over all nonnegative integers. I don't know how to approach this problem. I know that in general, # of paths from $(a,b)$ to $(c,d)$ is $(m+n)!\,/(m!n!)$ where m and n denote $(c-a)$ and $(d-b)$ respectively. But this size of the path $2n$ confuses me.","['permutations', 'discrete-mathematics', 'combinatorics']"
638977,Obtaining explicit solutions of the differential equation $\left(\frac{dy}{dx}\right)^{2}=\frac{1}{ay^2+by+c}$,"I'm trying to see if it is possible to obtain an explicit form of the following differential equation $$\left(\frac{dy}{dx}\right)^{2}=\frac{1}{ay^2+by+c}$$ where $a,b$ and $c\in\mathbb{R}$\{$0$}","['mathematical-physics', 'ordinary-differential-equations']"
638985,Reading a Character Table in Magma,"These are the outputs of two character tables from Magma.  The first is for $A_5$.  The second is for $GL_3(2)$.  What is the significance of the '$+$' and '$0$' symbols?  I can produce more tables if it would be helpful in determining what these symbols mean.  $Z1$ in both cases is a polynomial expression evaluated at a root of unity, $\omega$, and $\#k$ means to replace $\omega$ with $\omega^k$ in this expression.","['magma-cas', 'representation-theory', 'characters', 'finite-groups', 'group-theory']"
638989,Find $\lim_{n\to\infty}\frac{\sum_{k=1}^{n}\cos k+\sum_{k=1}^{n}\sin k}{\prod_{k=1}^{n}\cos k\sin k}$,"Find the following limit: $$\lim_{n\to\infty}\frac{\sum_{k=1}^{n}\cos k+\sum_{k=1}^{n}\sin k}{\prod_{k=1}^{n}\cos k\sin k}$$ The numerator can be simplified by using Euler's formula and the sum of geometric series. I am struggling on the denomenator. How can we simplify that product? By the way, I don't even know whether or not this limit exist.","['trigonometry', 'sequences-and-series', 'infinite-product', 'limits']"
639024,"Ampleness, Nakai's criterion and pullback","In the book I'm reading ( Geometry of Algebraic Curves ), at some point (page $310$) they make the following claim: One can use Nakai's criterion to establish the general fact that if $f:X\to Y$ is any finite surjective map and $L$ is a line bundle over $Y$, then $f^*L$ is ample if and only if $L$ is ample. Do you know about any reference where I can find a proof for this statement? Or could you give the sketch of a proof here?","['algebraic-geometry', 'vector-bundles']"
639039,Moebius strip as a fibre bundle,"I've alrealdy asked this question, but now I have more clear ideas, so I'm going to ask again and see if I'll understand a bit more. 
It's about the trivialisation of the Moebius strip as a bundle on $S^1$ with fibre an open interval $I\subset \mathbb{R}$. First of all, I write the strip as $E=[0,1]^2/\sim$, where $(0,y)\sim(1,1-y)$ and the other points of $[0,1]^2$ are equivalent to themselves.
Then I write $S^1=[0,1]/\sim$, where $0\sim 1$.
Now I define the projection $\pi: E\rightarrow S^1$, $\pi([(x,y)])=[x]$ (here with $[\cdot]$ I mean the equivalence class of $\cdot$). Now I want to find an open cover  $U_1,U_2$ of $S^1$ (two arcs of $S^1$ substantially) such that there exist homeomorphisms $\phi_i:\pi^{-1}(U_i)\rightarrow U_i\times I$, $i=1,2$ and this homeomorphisms have the property that $\pi_1\circ \phi_i=\pi$, where $\pi_1$ is the canonical projection onto the first factor. Now, my problem is write properly the homeomorphisms. Suppose that $S^1\ni[0]\notin U_1$, so $[0]\in U_2$. Then $\pi^{-1}(U_1)$ is exactly $U_1\times I$ and as homeomorphism I can choose the identity. But now my problem is $\pi^{-1}(U_2)$ which contains the gluing edges.
Can anyone help me, please? For example if $S^1\supset U_2=([0,2/5)\cup(3/5,1])/\sim$, then I could define $\phi_2([(x,y)])=(x,y)$ if $0\le x<2/5$ and $\phi_2([(x,y)])=(x,1-y)$ if $3/5<x<1$. But now the problem is prove that $\phi_2$ is a homeomorphism, I'm confused.","['differential-topology', 'differential-geometry']"
639091,Proving $(\bigcup F)\setminus (\bigcup G)\subseteq \bigcup (F\setminus G)$,"Suppose $F$ and $G$ are families of sets. Suppose $x$ is an arbitrary element of $(\bigcup F)\setminus (\bigcup G)$. It follows that $x\in \bigcup F$ and $x\not \in \bigcup G$. Since xââªF, therefore there exists AâF such that xâA. (1) Since xââªG, x can not be an element of any set in G. Since xâA, so AâG. Since AâF and AâG, so AâF\G. Since xâA and AâF\G, therefore xââª(F\G). Since x is arbitrary, we can conclude that (âªF)\(âªG)ââª(F\G). Above is my initial attempt on proving it. But starting from (1), I think I have made a mistake. Since the $x$ mentioned above is not an arbitrary element of the chosen $A\in F$, we cannot straightforward conclude that $A\not \in G$ since $x$ is only an arbitrary element of $\left(\bigcup F\right)\setminus \left(\bigcup G\right)$. Perhaps there exists some element in $A$ which is an element of some set in $G$. I am stuck here; I have absolutely no idea about solving it. Please help. Thanks in advance.","['elementary-set-theory', 'solution-verification']"
639096,What is completing the square?,"Why is it called, completing the square? Is square metaphorical in this sense? How do you complete the square and what is it used for? Thank you, regards.",['algebra-precalculus']
639102,Why isn't $\int\sin(ix)~dx$ equal to $i\cos(ix)+C$ ?,"I was playing around with imaginary numbers, and I tried to solve $$\int\sin(ix)~dx$$ and ended up getting  $$i\cos(ix)+C$$ But apparently the answer is $$i\cosh(x)+C$$ I was just wondering, is this correct? And what does the ""$h$"" stand for/mean? Where did it even come from. Thanks in advance.","['calculus', 'integration', 'indefinite-integrals', 'trigonometry', 'complex-numbers']"
639106,How do Riemann and Ricci tensors represent curvature?,"I have started an attempt to self-study Riemannian Geometry. I well understand all the algebraic properties of the Riemann tensor (With a symmetric connection), and how it gradually becomes less and less frightening. However, I'm having trouble converting all the properties of this tensor into an explanation of how it represents curvature, and the same goes for the derived Ricci tensor. This is essentially what I'm aiming for in writing this question. I can decompose this question into a set of concrete questions, but I think it is too ""early"" to ask them with regards to my understanding of the subject. A Reference to relevant material would suffice.","['tensors', 'riemannian-geometry', 'curvature', 'differential-geometry']"
639116,Probability a pair of pairs of rows have the same vector sum,"Let $X$ be a random square $n$ by $n$ matrix with $X_{i,j} \in \{0,1\}$.  What is the probability that there is a distinct pair of pairs of rows which have the same vector sum? If you add two rows elementwise then each entry has $0$ with probability $1/4$, $2$ with probability $1/4$ and $1$ with probability $1/2$ and they are independent.   So if the two pairs are disjoint the probability they are the same is $(1/4^2 + 1/2^2+1/4^2)^n = (3/8)^n$.  If the two pairs have one row in common the probability is $1/2^n$. How can you use these facts to give the final probability? Clarification: If we let $r_i$ be row $i$ then I want $i,j,k,\ell$ such that $r_i+r_j = r_k+r_{\ell}$ with rule 1)  that we can't have both $i\in \{k,\ell\}$ and  $j \in \{k,\ell\}$ and rule 2) that both $i \ne j$ and  $k \ne \ell$ hold.","['probability', 'combinatorics']"
639136,Natural Density and Logarithmic Density,"Natural density of a set $S = (a_1,a_2,...) $  is defined (assuming it exists) as
$$\lim_{n \to \infty}\frac{1}{n}\sum\limits_{k\in S, k\le n}1 $$
The logarithmic density of the same set is defined as
$$\lim_{n \to \infty}\frac{1}{\log n}\sum\limits_{k\in S, k\le n}\frac{1}{k} $$ My first question is are there any examples of a set where the natural density does not exist but the logarithmic density does. My second question is, can anyone give rough properties (necessary or sufficient) a set must have in order for its natural density to exist. P.S. I am aware that if you have a set with sufficiently large 'blocks' of elements and then sufficiently large 'gaps', its natural density cannot exist. However the task I am trying to complete is to prove that the natural density of a certain set does exist  (without necessarily finding it) so any conditions this set must have is what I am really looking for.","['sequences-and-series', 'number-theory']"
639152,BV Function times characterstic function still BV?,"I am wondering: given a function $u \in BV(\Theta)$ where $\Theta$ is an open subset in $\mathbb{R}^n$ and a Borel subset $B \in \mathcal{B(\Theta)},$ is the function $w \colon= u \chi_B$ still in $BV(\Theta)$?
I guess so, since clearly $w \in L^1(\Theta)$ and the total variation $V(u\chi_B,\Theta) \leq V(u,\Theta) < + \infty,$
where
\begin{equation}
V  (u, \Theta) := \sup \left\{ \int_\Theta u\, {\rm div}\, \psi : \psi\in  C^\infty_c (\Theta, \mathbb R^n), \, \|\psi\|_{C^0}\leq 1\right\}\, .
\end{equation}
 Is this right? Can we also conclude that for the distributional derivative it holds that
\begin{equation}
Dw(\cdot)=D\chi_Bu(\cdot)=Du(\,\cdot \cap B) ?
\end{equation} I started with noting that similarly
$\tilde w \colon = u \chi_{B^c} \in BV(\Theta)$ and so $\forall \phi \in C_c^{1}(\Theta)$ and $i=1, \dots n:$
\begin{align*}
-\int_{\Theta} \phi \, dD_iu &= \int_{\Theta} u \frac{\partial \phi}{\partial x_i} \, dx = \int_{\Theta}
w \frac{\partial \phi}{\partial x_i} \, dx + \int_{\Theta} \tilde w \frac{\partial \phi}{\partial x_i} \, 
dx \\
&= -\int_{ \Theta} \phi \, d D_iw -\int_{ \Theta} \phi \, d D_i\tilde w = - \int_{ \Theta} \phi \, d ( \underbrace{D_iw  + D_i \tilde w}_{=D_i\left( w + \tilde w \right)} ) \\
&= -\int_{\Theta} \phi \, d\left(D_i(w+\tilde w) \right)
\end{align*} 
and therefore $D_i w + D_i \tilde w = D_i(w+ \tilde w) = D_i u = D_i u(\cdot \cap B )+ D_i u(\cdot \cap B^c ),$ from which we get $D_i w = D_i u(\cdot \cap B )$ and analogously $D_i \tilde w = D_i u (\cdot \cap B )$ for any
 $i,$ i.e.
\begin{equation}
Dw = Du (\cdot \cap B ), \qquad D \tilde w = D u (\cdot \cap B^c ).
\end{equation} Or should I write $Dw(\cdot \cap B) = Du (\cdot \cap B )$ and analogously for tilde? Thanks for any input.","['measure-theory', 'geometric-measure-theory']"
639160,Matrix equation $AX=XB$,"For $A,B \in \big( \mathrm{Mat}_{n}(\mathbb{C}) \big)^2$, I know that there exists $Y \in \mathrm{Mat}_{n}(\mathbb{C})$, $Y \neq 0$, such as $AY=YB$ if and only if $\mathrm{Sp}_{\mathbb{C}}(A) \cap \mathrm{Sp}_{\mathbb{C}}(B) \neq \emptyset$. Here, $\mathrm{Sp}_{\mathbb{C}}(A)$ denotes the set of complex eigenvalues of $A$. The reason to this is the following : Let $u \, : \, \mathrm{Mat}_{n}(\mathbb{C}) \, \rightarrow \, \mathrm{Mat}_{n}(\mathbb{C}) \, ; \, M \, \mapsto \, AM-MB$. One can prove that $\mathrm{Sp}(u) = \mathrm{Sp}(A) - \mathrm{Sp}(B) = \left\{ a-b, \, (a,b) \in \mathrm{Sp}(A) \times \mathrm{Sp}(B) \right\}$. Now, I am wondering whether the result is still true for real matrices. If $A$ and $B$ are in $\mathrm{Mat}_{n}(\mathbb{R})$, can we still find $Y \in \mathrm{Mat}_{n}(\mathbb{R})$, $Y \neq 0$, such that $AY=YB$ while $\mathrm{Sp}_{\mathbb{R}}(A) \cap \mathrm{Sp}_{\mathbb{R}}(B) = \emptyset$ ? $\mathrm{Sp}_{\mathbb{R}}(A)$ denotes the set of real eigenvalues of $A$. I tried to build a counter-example taking, for example $A = \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}$ because it would ensure that $\mathrm{Sp}_{\mathbb{R}}(A) = \emptyset$ but I didn't succeed. This is not an homework question.","['matrices', 'linear-algebra']"
639198,Prove that the Lebesgue measure of a particular set is zero.,"I am doing revision and got extremely stuck with the following exercise, which appeared in an exam from the previous year. Consider the measure space $(\mathbb R, \mathbb B, \lambda)$ where $\mathbb B$ is the Borel sigma algebra and $\lambda$ the Lebesgue measure. Let $\delta > 0$ and 
\begin{align*}
V := \left\{x \in \mathbb R: \exists \text{ infinitely many } p \in \mathbb Z, \,  q \in \mathbb N \text{ where } \left|x - \frac{p}{q}\right| \le \frac{1}{q^{2+\delta}}\right\}.
\end{align*}
Show that $\lambda(V) = 0$. I wish I had an attempt for this, but unfortunately I don't know how to start, I'm afraid. 
Please help me.","['measure-theory', 'lebesgue-measure']"
639212,Structure of partial recursive function over recursively enumerable guard,"I read that the function 
$$
f(n) = \left\{
  \begin{array}{l l}
    g(n) & \quad \text{if $n \in A$}\\
    \text{undefined} & \quad \text{otherwise}
  \end{array} \right.
$$ is recursive if $g(n)$ is recursive and the guard $if$ $n \in A$ is recursively enumerable (since the always $\text{undefined}$ function is recursive). I read also that if the $else$ part is not always $undefined$, we cannot conclude that $f$ is not recursive. Could anyone please explain why we should use the always undefined function in the else part when we have an r.e. guard? And also if $f$ was defined as follows, what conditions should $h(n)$ fulfil (apart from being always undefined) so that $f$ is recursive. $$
f(n) = \left\{
  \begin{array}{l l}
    g(n) & \quad \text{if $n \in A$}\\
    h(n) & \quad \text{otherwise}
  \end{array} \right.
$$","['recursion', 'computability', 'functions']"
639220,"Isomorphisms between the groups $U(10), U(5)$ and $\mathbb{Z}/4\mathbb{Z}$","I think its silly question but I have nt this in my mind at this time. Any one can help How we can see $U(10) \overset{def}= \{1,3,7,9\}$, $\mathbb Z/4\mathbb Z \overset{def}= \{0,1,2,3\}$, $U(5) \overset{def}= \{1,2,3,4\}$ are isomorphic groups where $U(10)$ and $U(5)$ are groups under multiplication?","['modular-arithmetic', 'group-theory', 'abstract-algebra']"
639223,"If $\frac{\sin^4 x}{a}+\frac{\cos^4 x}{b}=\frac{1}{a+b}$, then show that $\frac{\sin^6 x}{a^2}+\frac{\cos^6 x}{b^2}=\frac{1}{(a+b)^2}$","If $\frac{\sin^4 x}{a}+\frac{\cos^4 x}{b}=\frac{1}{a+b}$, then show that $\frac{\sin^6 x}{a^2}+\frac{\cos^6 x}{b^2}=\frac{1}{(a+b)^2}$ My work: $(\frac{\sin^4 x}{a}+\frac{\cos^4 x}{b})=\frac{1}{a+b}$ By squaring both sides, we get, $\frac{\sin^8 x}{a^2}+\frac{\cos^8 x}{b^2}+2\frac{\sin^4 x \cos^4 x}{ab}=\frac{1}{(a+b)^2}$ $\frac{\sin^6 x}{a^2}+\frac{\cos^6 x}{b^2}-2\frac{\sin^4 x \cos^4 x}{ab}-\frac{\sin^6 x \cos^2 x}{a^2}-\frac{\sin^2 x \cos^6 x}{b^2}=\frac{1}{(a+b)^2}$ So, now, we have to prove that, $-2\frac{\sin^4 x \cos^4 x}{ab}-\frac{\sin^6 x \cos^2 x}{a^2}-\frac{\sin^2 x \cos^6 x}{b^2}=0$ I cannot do this. Please help!","['trigonometry', 'algebra-precalculus']"
639239,Integrate $e^{-ax}$ and $xe^{-ax}$?,"I'm making exercises about integration but I don't really get it. How do you solve these two integrals from 0 to +infinity? $\int Ae^{-ax}\,dx$ $\int Axe^{-ax}\,dx$ $A$ is a parameter.","['exponential-function', 'calculus', 'integration']"
639298,Dolbeault cohomology and analytic regularity,"Let $M$ be a complex analytic $n$-manifold. The Dolbeault cohomology complex is defined using a quotient space of smooth differential forms. My question is : would it make a big difference if we were to use $C^n$ sections instead, or $C^2$, or even differential forms in Sobolev spaces ? (obviously with at least enough regularity to define $\overline{\partial}$) EDIT A bit more precision : if I were to consider the quotient space
$A/B$, where $A$ is the space of $C^1$ $(p,q)$-forms $\alpha$ for which $\overline{\partial} \alpha=0$ and $B$ is the set of $\overline{\partial}$ of $C^2 (p,q-1)$-forms, would I get the same dimension as $H^{p,q}$ ? What if I were to replace $C^2$ and $C^1$ by Sobolev spaces with distributional derivatives of order $2$ and $1$ in $L^p$ ?","['homology-cohomology', 'functional-analysis', 'complex-geometry']"
639310,Applications of additive version of Hilbert's theorem 90,"Additive version of Hilbert's theorem 90 says that whenever $k \subset F$ is cyclic Galois extension with Galois group generated by $g$,  and $a$ is element of $L$ with trace 0, there exists an element $b$ of $L$ such that $a = b - g(b)$. The corresponding multiplicative version with norm instead of trace has many interesting applications, for instance determining Pythagorean triples, or solving Pell's equation. How about the additive version? Where it can be useful?","['galois-cohomology', 'number-theory', 'algebraic-number-theory', 'galois-theory', 'field-theory']"
639326,How many functions there is from 3 element set to 2 element set?,"Let say we have a set A = {a,b,c} and B={1,2}. How many functions are there from A to B? This seems like elementary question, but my class mate argued that there is no difference between: $f_1(t)=1$ and $f_2(t)=2$, that's just crazy. I think there are 8 different functions, is that right?",['combinatorics']
639336,Sum over the powers of the roots of unity $\sum \omega_j^k$,"The roots of unity are defined as the points $\omega_n$ to satisfy
$$
   z^n = 1
$$
Explicitly these can be given as 
$$ 
 \omega_k = \exp(2i\pi k ) \,,\qquad 1 \leq k \leq n-1
$$
In my book it is stated that 
$$
	\sum_{j=0}^{n-1} \omega_j^k = 
\left\{
	\begin{array}{ll}
		0 \, , & 1 \leq k \leq n - 1 \\
		n \, , & k = n
	\end{array}
\right.
\tag{1}
$$
and I have proven this algebraically see below. However I want to look at the problem
from a geometrical perspective. As long as $k$ and $n$ are coprime, eg $\gcd(n,k)=1$
then the powers of $\omega^k$ seem to simply permutate $\omega$. n=3 n=5 Can this property of the roots of units be explained geometrically, or by some combinatorial proof? My question is Can equation $(1)$ be explained purely from a geometrical or combinatorial point of view? Proof : 
  Assume that $1\leq k \leq n-1$ then
  \begin{align*}
	\sum_{j=0}^{n-1} w_j^k & = \sum_{j=0}^{n-1} [\exp(2\pi i k/n)]^j
	                         = \frac{1 - [\exp(2\pi i k/n)]^n}{1 - \exp(2\pi i k/n) }
                                 = 0
\end{align*}
  Since the denominator equals zero, eg $\exp(2i\pi k)=1\ \forall k\in \mathbb{N}$.
  The case for $k=n$ must be treated seperately as it leads to a $0/0$ expression above. 
  \begin{align*}
	\sum_{j=0}^{n-1} w_j^n & = \sum_{j=0}^{n-1} \exp(2\pi i j)
	                         = n
\end{align*}
  Where again $\exp(2\pi i k)=1$. This finishes the proof. $\hspace{6cm}\blacksquare$","['complex-analysis', 'combinatorics']"
639368,Compute the definite integral,"Find 
$$\int_0^{\pi}\frac{x}{1+\cos^2(x)}dx$$ I tried letting $u=\tan(\frac{x}{2})$ but could not make it work. A few other trig substitutions failed as well. I noticed the integrand is odd but could not make use of that fact. Any ideas?","['calculus', 'integration']"
639412,Why are derivatives lines?,"If you look at a function ""infinitely close"", the difference between two points is a line: __
   __/ 
__/ Where each ""__"" is a point, and  ""/"" is the value of a derivative (assume the two ""/""s have different slopes). I have this intuition because a function can be approximated by a line at an infinitely close distance (i.e. ""Linear Approximations"") If you use the above graph of the function to graph the derivative, the derivative looks like this: _
 _| So at an infinitely close distance the derivative looks like the second graph above. But now if you look at the derivative at an infinitely close distance, it looks the the first graph.  So how can the derivative look two different ways at an infinitely close distance? It looks like the first graph when you look at it directly at an infinitely close distance, but the second graph if you look at its antiderivative at an infinitely close distance and use that to plot it. I know this obviously isn't rigourous but what part of my intuition is wrong?","['intuition', 'calculus', 'integration', 'derivatives']"
639449,Why is $\det(e^X)=e^{\operatorname{tr}(X)}$? [duplicate],"This question already has answers here : How to prove $\det \left(e^A\right) = e^{\operatorname{tr}(A)}$? (6 answers) Closed 10 years ago . I've seen on Wikipedia that for a complex matrix $X$, $\det(e^X)=e^{\operatorname{tr}(X)}$. It is clearly true for a diagonal matrix. What about other matrices ? The series-based definition of exp is useless here.","['matrices', 'exponential-function']"
639461,Show that the closures in the topology weak and the norm are coincide:,"Let $X$ be a Banach space and $Y \subset  X$a vector subspace. Let $Y_f$ and $Y_F$ are the closures of $Y$ in the topology weak and the norm, respectively. Prove that $Y_F = Y_f$.","['functional-analysis', 'analysis']"
639486,Integral Of $\int \frac{\cos(3x)}{(x^2+1)^2}dx$,"I getting trouble by solving the following:
$$\int _{-\infty}^{\infty}\frac{\cos(3x)}{(x^2+1)^2}dx$$
Hints are welcomed thanks.","['integration', 'complex-analysis']"
639500,Coequalizers in the Category of Sets,"This is an elementary question but I cannot get my head around it: According to the definition of Coequalizers (specifically for the category of Finite Sets), what are the elements of the objects? Different sources talk about equivalence classes and then quotients but they are confusing to understand. Can anyone give a simple example with example Sets and functions even if it is not 100% mathematically right, just to get the idea?","['category-theory', 'elementary-set-theory']"
639531,Computing $\lim_{n\to \infty}{\frac{5\cdot9\cdot13\cdot\dots.\cdot(4n+1)}{7\cdot11\cdot15\cdot\dots.\cdot(4n+3)}}$,"Let $\{a_n\}_{n\ge1}^{\infty}=\bigg\{\cfrac{5\cdot9\cdot13\cdot\dots.\cdot(4n+1)}{7\cdot11\cdot15\cdot\dots.\cdot(4n+3)}\bigg\}$. Find $\lim_{n\to \infty}{a_n}$. I.) In the first step I studied monotony:
$a_{n+1}-a_{n}=\cfrac{5\cdot9\cdot13\cdot\dots.\cdot(4n+1)}{7\cdot11\cdot15\cdot\dots.\cdot(4n+3)}\cdot\cfrac{-2}{4n+7}<0$, $\{a_n\}$ is decreasing. II.) In the second step I studied boundary.
$$1>a_{1}=\cfrac{5}{7}>a_{2}=\cfrac{45}{77}>\dots>a_{n}>0$$ III.) In the last step I know that $\{a_n\}$ converges to $a\in\mathbb R$.
$$a_{n+1}=a_{n}\cdot\cfrac{4n+1}{4n+3}$$
Taking the limit as $n\to\infty$:
$$a=a$$ No conclusion. But if I apply Cesaro-Stolz? IV.) Let $\{x_n\}_{n\ge1}^{\infty}=\{5\cdot9\cdot13\cdot\dots.\cdot(4n+1)\}$ and $\{y_n\}_{n\ge1}^{\infty}=\{7\cdot11\cdot15\cdot\dots.\cdot(4n+3)\}$. Then
$$\lim_{n\to \infty}{\cfrac{x_{n+1}-x_{n}}{y_{n+1}-y_{n}}=\lim_{n\to \infty}{\cfrac{5\cdot9\cdot13\cdot\dots.\cdot(4n+1)^2}{7\cdot11\cdot15\cdot\dots.\cdot(4n+5)}=?}}$$ If you have a simple solution, I would appreciate it. Thank you!","['sequences-and-series', 'calculus', 'infinite-product', 'real-analysis', 'limits']"
639547,Choice of branches for contour integration.,"Suppose I have the following function of a complex variable $$f(z)=\log(z)(z^2+1)^{1/2}.$$ Wolfram Alpha tells me the branch cuts of $f(z)$ are $z\leq 0$ (presumably for the logarithmic term), and $\text{Re}(z)=0$,$|z|\geq 1$ (presumably for the square root), i.e. they are restricted to subsets of either the real or imaginary axes. If I want to use the residue calculus with $f(z)$, my contour had better avoid (i.e. not cross) these branch cuts. I think I'm right in saying that I can choose my branches to suite my needs. Hence, if it turns out that the Wolfram choice of branch cuts permits an awkward contour, can I make a different choice of branch (by way of defining my branch cuts differently) to make life easier? For example, instead of the above choice, could I choose my branch cuts to be $z\geq 0$ for the logarithm, and $z\leq -1$ and $z\geq 1$ for the square root? This choice leaves the entire upper and lower half planes ""free of problems"", whereas the initial choice defines branches along both positive and imaginary axes.","['residue-calculus', 'complex-analysis', 'contour-integration']"
639563,Parametric to cartesian conversion,"$x= t^2-t, y=t^3-2t^2+t $ $x= 1-\sin t, y=\cos t(1-\sin t)$ Find cartesian equations. For 1, I have $x=t(t-1), y=t(t-1)^2$, then $y/x= t-1$ and $t=(y/x)+1$.  $x=(y^2+xy)/x^2$, then $x=(y^2+xy)^{1/3}$. Is there an explicit solution? For 2, I have $t= \sin^{-1}(1-x)$ so $$y=\cos(\sin^{-1}(1-x))(1-\sin(\sin^{-1}(1-x)))= x^{3/2}(2-x)^{1/2}.$$ Is this correct ?",['algebra-precalculus']
639573,"Suppose that for all $t <1$ there are points $x_t$ and $y_t$ such that $d(x_t,y_t) = t$.","Let $(X,d)$ be a compact metric space. Suppose that for all $t <1$ there are points $x_t$ and $y_t$ such that $d(x_t,y_t) = t$. Prove that there exists points $x$ and $y$ such that $d(x,y) = 1$. I have attempted to use the fact that since $A= \{(x_t,y_t) : d(xt,yt)=t\}$ is infinite then $A$ has a limit point since $X$ is compact and then the limit point would be this set $\{(x,y) : d(x,y) =1\}$... but i dont even know if im looking at this in the right way.","['general-topology', 'compactness', 'real-analysis']"
639596,There exists a constant arc length parametrization,"I heard that for any curve in the plane that can be given parametrically by $\vec{r}(t)=\langle x(t),y(t)\rangle$ for $a\leq t\leq b$ that there exists a constant arc length parametrization, i.e. another parametrization $\hat{\vec{r}}(t)=\langle \hat{x}(t),\hat{y}(t)\rangle$ that satisfies $\hat{x}'(t)^2+\hat{y}'(t)^2=1$ and $\hat{\vec{r}}\big((a,b)\big)=\vec{r}\big((a,b)\big)$. What is the name of this theorem and who proved it?  I've been looking around the internet and it seems like the Gauss-Bonnet Theorem comes up a lot, but I don't see the connection between that and this?  Maybe I just don't understand it as well as I need to.","['multivariable-calculus', 'plane-curves', 'parametric', 'differential-geometry']"
639606,Locally path-connected implies that the components are open,"If $X$ is a locally path-connected space, then its connected components are open. I am trying to prove this, but for some reason it doesn't seem right to me, knowing that components are always closed. If the statement is true, wouldn't it be the case the components are the whole space $X$?","['general-topology', 'connectedness', 'path-connected']"
639611,Calculate a hard limit,"Calculate: $$
\lim_{x\to+\infty} x\left( \frac{1}{x^2+1^2}+\frac{1}{x^2+2^2}+\dots+\frac{1}{x^2+x^2}\right)$$","['calculus', 'limits']"
639615,"A naive question about ""random"" probability distributions","So I've come up with this idea, which may be mathematically unprecise, but it goes as follows. Example: Suppose you have a random variable $X$ taking values in the interval $[-1,1]$. Then, say, instead of a definite probability density $f(x)$ we have two different distributions $g$ and $h$ of the variable $X$. The probability that $X=x$ is the result of choosing either $g$ or $h$ by a toss of a coin and then taking the value of the corresponding density at the point $x$. The function $$F(x)=\frac{1}{2} (g(x)+h(x))$$ seems to be resulting probability density function of $X$. Analogously, one can have a finite number $n$ of density functions, then assign $n$ different probabilities, one for each of then, and the result will be the probability density function of the combined different probabilities. Now the question. Take the space $S$ of every continuous function from the interval $I=[-1,1]$ to the positive real axis, such that the integral of every function in this space $S$ in the interval $I$ equals one. Now define a random variable $X$, the value of which is taken in the following manner. First you pick a function $f$, belonging to $S$, completely at random, i. e., the probability of taking $f$ is the same as taking any other function. Then, in this case, the probability density of $X=x$ is just $f(x)$. The problem: is there a ""resulting probability distribution"" as given in the first example, of the above process (taking at random a function and then taking the value of this function at a point $x$)? One can see such resulting function as the ""expected"" or ""mean"" function in the space $S$, with respect to a uniform probability distribution. Again, I don't know if this heuristic construction is precise mathematically, neither, if it is, if this possess an interesting answer. I suspect the most reasonable answer should be the uniform density $F(x)=\frac{1}{2}$. I appreciate any comments in this question!","['probability-theory', 'probability-distributions', 'probability', 'analysis']"
