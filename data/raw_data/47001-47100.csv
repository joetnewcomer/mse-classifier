question_id,title,body,tags
472516,"How to prove that this series is a metric: $d(x,y):=\sum_{i=0}^\infty \frac{|x_i -y_i|}{2^i (1+|x_i-y_i|)}$","I have to prove that this is a metric: $$d(x,y):=\sum_{i=0}^\infty \frac{|x_i -y_i|}{2^i (1+|x_i-y_i|)}$$ 
The only thing that I can't prove is the triangle inequality, it's really hard. I know that $|x_i -y_i|\le |x_i -z_i|+|z_i -y_i|$, and I want to get: $$\frac{1}{2^i (1+|x_i-y_i|)} \le \frac{1}{2^i (1+|x_i-z_i|)}+\frac{1}{2^i (1+|z_i-y_i|)}$$ (I think...) The closest thing I've got is: $2^i (1+|x_i-y_i|)\le 2^i (1+|x_i-z_i|)+2^i (1+|z_i-y_i|)$ but... that's not quite what i want. I don't know how to get this...","['sequences-and-series', 'real-analysis', 'metric-spaces']"
472519,Is this proof of $\liminf E_k \subset \limsup E_k $ correct?,"I am wondering if my proof is correct? Thank you for whoever willing to take a look at it for me. Proof $\liminf E_k \subset \limsup E_k $ If $\{E_k\}_{k=1}^\infty$ is a sequence of sets, we define
\begin{align*}
\limsup E_k & = \bigcap_{j=1}^\infty\left(\bigcup_{k=j}^\infty E_k\right)\\
&= \bigcap_{j=1}^\infty(E_j \cup E_{j+1} \cup \cdots)\\
&= (E_1 \cup E_2 \cup \cdots) \cap (E_2 \cup E_3 \cup \cdots) \cap \cdots.
\end{align*} Therefore, $\limsup E_k$ consists of those points in $\mathbb{R}^n$ which belong to infinitely many $E_k$.
\begin{align*}
\liminf E_k & = \bigcup_{j=1}^\infty\left(\bigcap_{k=j}^\infty E_k\right)\\
&= \bigcup_{j=1}^\infty(E_j \cap E_{j+1} \cap \cdots)\\
&= (E_1 \cap E_2 \cap \cdots) \cup (E_2 \cap E_3 \cap \cdots) \cup \cdots.
\end{align*}
Therefore, $\liminf E_k$ consists of those points in $\mathbb{R}^n$ which belong to all $E_k$ for $k \geq k_0$. Now consider $x \in \liminf E_k$, then $x \in E_1 \cap E_2 \cap \cdots$, or $x \in E_2 \cap E_3 \cap \cdots$ and so on, that is to say, $x \in E_{k_0} \cup E_{k_0+1} \cup \dots$ for some $k_0$. More specifically, $x \in E_k \forall k \geq k_0$. Therefore, $x \in (E_1 \cup E_2 \cup \cdots) \cap (E_2 \cup E_3 \cup \cdots) \cap \cdots$, so we showed $x \in \limsup E_k$.","['limsup-and-liminf', 'elementary-set-theory', 'real-analysis', 'solution-verification']"
472524,Ugly Subsets: Weirdness Within the Axioms of Probability Theory,"I'm watching this video now, and at $36:53$ John Tsitsiklis mentions that for some sets there is no way to assign probabilities to events which occur in them. I'm wondering what sets he is talking about. Tsitsiklis says that one will only encounter them doing doctoral work, but I imagine that the ""theoretical aspects of probability theory"" are more tangible than Tsitsiklis makes them out to be.","['probability-theory', 'set-theory', 'probability']"
472532,Why is the supremum of the empty set $-\infty$ and the infimum $\infty$? [duplicate],This question already has answers here : Infimum and supremum of the empty set (6 answers) Closed 10 years ago . I read in a paper on set theory that the supremum and the infimum of the empty set are defined as $\sup(\{\})=-\infty$ and $\inf(\{\})=\infty$. But intuitively I can't figure out why that is the case. Is there a reason why the supremum and infimum of the empty set are defined this way?,"['elementary-set-theory', 'real-analysis']"
472539,Order of automorphism group of a $p$-group is divisible by $p$.,"Suppose $G$ is a finite $p$-group (where $p$ is prime), so that $|G|=p^n$ for some positive integer $n\ge 2$. How can we prove that $|\text{Aut}(G)|$ is divisible by $p$? Here $\text{Aut}(G)$ is the group of all automorphisms of $G$. I know how to prove this when $G$ is non-abelian. In this case, we look at the action of group on itself by conjugation, i.e. we consider the map $\phi: G\to \text{Aut}(G)$ defined by $\phi(g)=\tau_g$ where $\tau_g: G\to G$ given by $\tau_g(x)=gxg^{-1}$ for each $x\in G$. The kernel of $\phi$ is then $Z(G)$, the center of the group. By First Isomorphism Theorem, we get that $G/Z(G)$ is isomorphically embedded in $\text{Aut}(G)$. Since $Z(G)$ is proper subgroup of $G$ (because $G$ is non-abelian), we see that $p$ divides $\left|G/Z(G)\right|$, so by Lagrange's Theorem, $\text{Aut}(G)$ is divisible by $p$. But what happens when $G$ is abelian? The above homomorphism $\phi$ is no longer of use, since $\phi$ becomes the trivial map [i.e. $G=Z(G)=\text{ker}(\phi)$]. Thanks for your time :)","['p-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
472562,Lim Sup and Lim Inf relations between the root test and the ratio test,"I'm trying to solve the following problem and while looking around I found a couple of notes ( Link ) by Pete L. Clark where it's discussed but can't really comprehend his proof. The problem:
Prove that $ \lim\inf\limits_{n\rightarrow \infty} \frac{A_{n+1}}{A_n} \leq \lim\inf\limits_{n\rightarrow \infty} (A_n)^{1/n} \leq \lim\sup\limits_{n\rightarrow \infty} (A_n)^{1/n} \leq \lim\sup\limits_{n\rightarrow \infty} \frac{A_{n+1}}{A_n}$ His proof, as I understood it, is as follows:
Let $r > \lim\sup\limits_{n\rightarrow \infty} \frac{A_{n+1}}{A_n} $ , so there's an $n_0$ so that for all $k \geq 1$ then $ \frac{A_{n_0+k}}{A_{n_0 + k - 1}} < r $ . From that we get $ A_{n_0 + k} < r A_{n_0+k-1} $ and that implies $A_{n_0 + k} < r^{k} A_{n_0} $ . Rewriting that as $A_{n_0+k} ^{\frac{1}{n_0+k}} < r (\frac{A_{n_0}}{r^n})^{\frac{1}{n_0+k}}$ and by letting $ k \rightarrow \infty$ we see that $\lim\sup\limits_{k\rightarrow \infty} A_{n_0+k} ^{\frac{1}{n_0+k}}$ is at most $r$ . So, we have that $r > \lim\sup\limits_{n\rightarrow \infty} \frac{A_{n+1}}{A_n} $ and $ r \geq \lim\sup\limits_{n\rightarrow \infty} (A_n)^{1/n}$ He says that that implies $\lim\sup\limits_{n\rightarrow \infty} (A_n)^{1/n} \leq 
\lim\sup\limits_{n\rightarrow \infty} \frac{A_{n+1}}{A_n}$ , but I really don't see how that's the case to be honest. And I'm also not too sure how the analogous argument for $\lim\inf$ would look like. I'm sure the proof is correct, as I've seen a lot of people recommend that particular set of notes, but I just can't seem to grasp it and it looks so simple. Any help, both with this particular proof and with any other that applies, would be greatly appreciated.","['limits', 'sequences-and-series', 'real-analysis', 'analysis']"
472572,How to find period of $f$ if $f(x+13) + f(x+630) = 0$,"Let $f:\Bbb{R}\to\Bbb{R}$ be a periodic function with period $T$. The question was to find the (fundamental) period given the following relation.
$$ f(x+13) + f(x+630) = 0 $$ Now, the given method is:
$$\begin{align} 
&f(x+13) + f(x+630) = 0 \\
\implies &f((x+617)+13) + f((x+617)+630) = 0 \\
\implies &f(x+630) + f(x+1247) = 0 \\
\end{align}$$ Subtracting this equation from the 'original', we have:
$$ f(x+1247) = f(x+13) $$ So, the period is $ 1234 $. All this is fine. However, my doubt is this: How do we know that $1234$ is the fundamental and not just any period ?","['algebra-precalculus', 'functions']"
472574,Existence of a normal subgroup in a finite group.,"Let $G$ be a finite group. If a Sylow $p$-subgroup $P$ of $G$ is contained in the centre, then does there exist a normal subgroup $N$ of $G$, such that $P \cap N = \{e\}$ and $PN=G$? Thanks in advance.","['abstract-algebra', 'sylow-theory', 'group-theory', 'finite-groups', 'p-groups']"
472587,About equivalent measure on $\mathbb{R}^n$,"Let $m$ denote the canonical Lebesgue measure on $\mathbb{R}^n$ and $\mu$ be a regular Borel measure on $\mathbb{R}^n$, if for all open balls $B \subset \mathbb{R}$, we have
$$C_1\ m(B)\leq \mu(B) \leq C_2 m(B)$$
for some positive $C_1>0,C_2>0$. The problems asks to show $\mu,m$ is mutually absolutely continuous. The conclusion will following immediately if we can show
$$C_1\ m(E)\leq \mu(E) \leq C_2 m(E)$$
for all Borel set $E$. By regularity it shall be sufficient to reduce this to the case for open set $E$. If we are dealing with dimension 1, then any open set can be decomposed as countable disjoint open intervals and we are done. But for $n\geq 2$, open set does not generally admit such decomposition(i.e. the union of disjoint open balls). Though it is obviously that open sets can be covered with open balls within any given error in measure, it is hard to expect we can take some cover of disjoint balls, so the argument still does not hold. I am not sure if this approach to the proof works, any comment shall be greatly appreciated! [Editted] Thanks to the comment below I have reached conclusion by another approach. Now I have another question: If we let $f:=d\mu / dm$, then intuitively $f$ should be bounded both from below and above, i.e. $f,1/f \in L^\infty(m)$, does this hold true?","['measure-theory', 'real-analysis']"
472594,Prove that: $ \cot7\frac12 ^\circ = \sqrt2 + \sqrt3 + \sqrt4 + \sqrt6$,"How to prove the following trignometric identity?
$$ \cot7\frac12 ^\circ = \sqrt2 + \sqrt3 + \sqrt4 + \sqrt6$$ Using half angle formulas, I am getting a number for $\cot7\frac12 ^\circ $, but I don't know how to show it to equal the number $\sqrt2 + \sqrt3 + \sqrt4 + \sqrt6$. I would however like to learn the technique of dealing with surds such as these, especially in trignometric problems as I have a lot of similar problems and I don't have a clue as to how to deal with those. Hints please! EDIT : What I have done using half angles is this: (and please note, for convenience, I am dropping the degree symbols. The angles here are in degrees however). I know that
$$ \cos 15 = \dfrac{\sqrt3+1}{2\sqrt2}$$ So, $$\sin7.5 = \sqrt{\dfrac{1-\cos 15} {2}}$$
$$\cos7.5 = \sqrt{\dfrac{1+\cos 15} {2}} $$ $$\implies \cot 7.5 = \sqrt{\dfrac{2\sqrt2 + \sqrt3 + 1} {2\sqrt2 - \sqrt3 + 1}} $$","['trigonometry', 'algebra-precalculus', 'number-comparison']"
472604,Question about a base for a topology,"Actually, this is only a clarification about the definition of a base for a topology. In the book of Dshalalow entitled "" Real Analsysis: An Introduction to the Theory of Real Functions and Integration "", CRC Press LLC, USA, 2001, at p.115, defined the base for a topology as follows and I quote: Definition. Let $(X,\tau)$ be a topological space. A subcollection $\mathcal{B}$ of open sets is a base for $\tau$ if every open set is a union of some elements of $\mathcal{B}$. (Specifically, it follows that $\varnothing$ must be an element of $\mathcal{B}$.) I got confused with the definition of a base because as Scott mentioned in here , it is never necesssary to include $\varnothing$ in a base. I want to be clarified with this and many thanks in advance.",['general-topology']
472624,On a Geometric Interpretation of the Local Criterion for Flatness in Eisenbud's,"The local criterion for flatness goes this way: Let $\phi : (A,m)\rightarrow (B,m')$ be a local morphism of local Noetherian rings, and $M$ a finitely generated $B$-module. If $x\in m$ is a non-zero divisor on $A$ then $M$ is flat over $A$ iff $M/xM$ is flat over $A/xA$ and $x$ is a non-zero divisor on $M$. One usual geometric interpretation (see for instance Eisenbud, Commutative Algebra with a View Towards Algebraic Geometry , chapter 6.4) is the following: If we have a morphism of affine varieties $X\rightarrow Y$ over $\mathbb{A}^1$ such that the maps to $\mathbb{A}^1$ are flat and dominant, for any point $p$ in $\mathbb{A}^1$ choose a point $p'$ in $Y$ above $p$ and a point $p''$ in $X$ above $p'$. If the map of fibers $X_{p}\rightarrow Y_{p}$ is flat in a neighborhood of $p''$ in $X_{p}$, then the map $X\rightarrow Y$ is also flat in a neighborhood of $p''$ in $X$. It is easy to see that using the local criterion for flatness we get the flatness of the map $X\to Y$ at the point $p''$, but I fail to see how we get this property on a neighborhood of $p''$ in $X$ without using a much stronger result, namely the openness of the flat locus (or, since we are dealing with irreducible variety, generic flatness (or freeness) type of results, see the discussion in the comments following @Eric Canton answer). Am I missing something here ??",['algebraic-geometry']
472665,Let $f(x)=x^8-16$. Determine the Galois group of the splitting field of $f(x)$ over the fields $\Bbb{Q}$ and $\Bbb{Z}_{17}$.,"Let $f(x)=x^8-16$ . Determine the Galois group of the splitting field of $f(x)$ over the field $K$ in each case. a) $K=\Bbb{Q}$ b) $K=\Bbb{F}_{17}$ . a) The roots of $f(x)$ are $\alpha$ , $\alpha\omega$ , $\alpha\omega^2$ , ... , $\alpha\omega^7$ where $\alpha=16^{1/8} = (2^4)^{1/8} = 2^{1/2}$ and $\omega$ is the $8$ th primitive root of unity. First we need to find the degree of the extension since it is equal to the order of the Galois group. We have $$[\Bbb{Q}(\alpha,\omega):\Bbb{Q}]=[\Bbb{Q}(\alpha,\omega):\Bbb{Q}(\omega)][\Bbb{Q}(\omega):\Bbb{Q}],$$ where $[\Bbb{Q}(\omega):\Bbb{Q}]=\Psi_8(x)$ , where $\Psi_k(x)$ is the $k$ th cyclotomic polynomial. We know that $$x^8-1 = \Psi_1(x)\Psi_2(x)\Psi_4(x)\Psi_8(x)$$ $$\implies x^8-1 = (x-1)(x+1)(x^2+1)\Psi_8(x)$$ $$\implies \Psi_8(x)=x^4+1$$ Since cyclotomic polynomials are irreducible over $\Bbb{Q}$ , we know that $[\Bbb{Q}(\omega):\Bbb{Q}]=4$ . Now we need to find $[\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)]$ . Since $\alpha$ is a root of $x^8-16$ , the minimal polynomial must be a divisor of it. We have $x^8-16 = (x^2-2)(x^2+2)(x^4+4)$ . Here, we can see that $\alpha$ is a root of $x^2-2$ , so we just need to check if $x^2-2$ is reducible. But $x^2-2=(x-\sqrt{2})(x+\sqrt{2})$ , and we know that $\sqrt{2} \not\in \Bbb{Q}(\omega)$ since it is irrational. So $[\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)]=2 \implies [K:\Bbb{Q}]=8$ There are five groups of order 8 up to isomorphism: $\bullet \Bbb{Z}_8$ $\bullet \Bbb{Z}_4 \times \Bbb{Z}_2$ $\bullet \Bbb{Z}_2 \times \Bbb{Z}_2 \times \Bbb{Z}_2$ $\bullet D_8$ $\bullet Q_8$ Since $x^8-16 = (x^2-2)(x^2+2)(x^4+4)$ , the automorphisms are $$\sigma_1: \alpha \rightarrow -\alpha$$ $$\sigma_2: \alpha\omega^2 \rightarrow \alpha\omega^6$$ $$\sigma_3: \alpha\omega \rightarrow \alpha\omega^3$$ $$\sigma_4: \alpha\omega \rightarrow \alpha\omega^5$$ $$\sigma_5: \alpha\omega \rightarrow \alpha\omega^7$$ $$\sigma_6: \alpha\omega^3 \rightarrow \alpha\omega^5$$ $$\sigma_7: \alpha\omega^3 \rightarrow \alpha\omega^7$$ $$\sigma_8: \alpha\omega^5 \rightarrow \alpha\omega^7$$ I guess I can tell which group of order 8 this is isomrophic to by direct computation, but I was kind of confused...for example, let's say I want to check if $\sigma_3\sigma_2(\sigma\omega) = \sigma_2\sigma_3(\alpha\omega)$ . But $\sigma_2$ takes $\sigma\omega^2$ to $\alpha\omega^6$ . But we don't have $\alpha\omega^2$ , we have $\alpha\omega$ . If we just raise it to the 3rd power, then what's the difference between $\sigma_2$ and $\sigma_3$ ? So that doesn't really make sense to me... Also is there an easier way find out which group it's isomorphic to without actually having to directly go through all the elements and subgroups of the Galois group? b) As in part a) we hav $$[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)][\Bbb{F}_{17}(\omega):\Bbb{F}_{17}].$$ So, again, we need to check if $\Psi_8(x) = x^4+1$ is irreducible in $\Bbb{F}_{17}$ . In other words, since $x^4+1=0 \implies x^4=-1 \implies x^8=1$ , we need to check if there are elements of order 8 in $\Bbb{F}_{17}$ . We know that the multiplicative group of $\Bbb{F}_{17}$ is cyclic of order $16$ . So we have a cyclic subgroup of order 8 $\implies$ the minimal polynomial of $\omega$ over $\Bbb{F}_{17}$ is of degree 1 $\implies$ $[\Bbb{F}_{17}(\omega):\Bbb{F}_{17}]=1$ . For $[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)]$ , we get the same polynomial as we did for part a), which is not reducible since $x^2-2=(x-\sqrt{2})(x+\sqrt{2})$ and $\sqrt{2} \notin\Bbb{F}_{17}$ . So $[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=2$ , implying that the Galois group is isomorphic to a cyclic group of order 2. Is my answer for part b), correct? Thanks in advance","['cyclotomic-fields', 'number-theory', 'finite-fields', 'abstract-algebra', 'galois-theory']"
472672,"Prove that if a normal subgroup $H$ of $ G$ has index $n$, then $g^n \in H$ for all $g \in G$","I need some help in relation to this exercise ""Prove that if a normal subgroup $H$ of $ G$ has index $n$, then $g^n \in H$ for all $g \in G$."" I'm not allowed to use quotient groups in the proof, because the exercise is in the chapter before. I tried by induction on $n$. The case $n=1,n=2$ are obvious, but even  the case $n=3$ is giving me trouble so I give up studying the general case of the inductive step. My other approach was studying left or right coset of $G$. But I only proved that if $g \in aH$ then $g^2 \notin aH$ if $a \notin H$, and I can't find a way to demonstrate that $g^n \in H$. (my starting idea was to prove that every power of $g$ is in a different coset but then I realize that in this way I don't handle several case, for example $g$ has period strictly lesser than $n$ and in conclusion it doesn't prove the exercise) 
Maybe I'm missing something about indexes, and this is why I asked here for some help, (I can't use quotient groups because they are introduced later than this exercise, forgot to add this info in the beginning)
Thanks in advance :)","['group-theory', 'abstract-algebra', 'normal-subgroups']"
472684,Expected time for winning in biased Gambler's Ruin,"Consider the random walk $X_0, X_1, X_2, \ldots$ on state space $S=\{0,1,\ldots,n\}$ with absorbing states $A=\{0,n\}$, and with $P(i,i+1)=p$ and $P(i,i-1)=q$ for all $i \in S \setminus A$, where $p+q=1$ and $p,q>0$. Let $T$ denote the number of steps until the walk is absorbed in either $0$ or $n$. Let $\mathbb{E}_k(\cdot) := \mathbb\{\cdot | X_0 = k\}$ denote the expectation conditioned on starting in state $k \in S \setminus A$. How to compute $\mathbb{E}_k(T|X_T = n)$?","['markov-chains', 'random-walk', 'probability']"
472687,Prove $\int^\infty_0\frac x{e^x-1}dx=\frac{\pi^2}{6}$,"I know that $$\int^\infty_0\frac x{e^x-1}dx=\frac{\pi^2}{6}$$ For substituting $u=2$ into $$\zeta(u)\Gamma(u)=\int^\infty_0\frac{x^{u-1}}{e^x-1}dx$$ However, I suspect that there is an easier proof, maybe by the use of complex analysis. I haven't learnt the zeta function yet. All I know is the above formula and $\zeta(2)=\frac{\pi^2}{6}$. Can we can use the above integral to find out some of the $\zeta$'s value?","['calculus', 'integration', 'complex-analysis']"
472705,How to prove $\lim_{n\to\infty}\frac{\log_{2}{(f_{n})}}{(\log_{2}{n})^2}=\frac{1}{2}$?,"For any $n\in N$, such $f_{1}=1$, and such $$f_{2n+1}=f_{2n}=f_{2n-1}+f_{n},$$ prove that
$$\lim_{n\to\infty}\dfrac{\log_{2}{(f_{n})}}{(\log_{2}{n})^2}=\dfrac{1}{2}.$$","['recurrence-relations', 'sequences-and-series', 'limits']"
472726,Online classes/books in multivariable calculus?,"So does anyone know of any good online courses in multivariable calculus? (Or in a possible alternative leap of curriculum, if said path has proven to be better/moar interesting.) I'm coming straight from BC Calc (5); but my high school doesn't offer math past that. As for descriptions of the course...not being free is tolerable. The only real requirement-requirement would be that the class does not require presence in an online classroom. Also something that is important for me is I need some way of getting credit for the course--not necessarily high school type credits, but more of just a general report-card type thing which ensures to my high school that I'm learning math. (So MIT OCW would be difficult in this aspect...) As for books, I have the book Calculus, a New Horizon (ISBN 0471482730)), which is just a normal textbook that tided me over through single variable calc and supposedly should last through multivariable calculus as well. However if you know of books that are significantly better, please name them!","['multivariable-calculus', 'education', 'online-resources']"
472737,"How can I prove that $\operatorname{arctg}(x) + \operatorname{arctg}(\frac{1}{x}) = \frac{\pi}{2}$, given that $x > 0$?","Which would be the easier way to prove that $\operatorname{arctg}(x) + \operatorname{arctg}(\frac{1}{x}) = \frac{\pi}{2}$ in cases where $x > 0$? I don't need explicit solutions, rather keywords and pointers towards the direction of a feasible method that can help me prove this equality.",['trigonometry']
472753,Intersection of two tangents to a parabola,"Problem statement: Two tangents to the parabola $y=x^2$ are perpendicular. Prove that the intersection between the tangents lies on the line $y=-\frac{1}{4}$. Solution: Two tangents $y_1=k_1x+m$, $y_2=k_2x+n$ are perpendicular if $k_1k_2=-1$ so we can reduce the second tangent to $y_2=-\frac{1}{k_2}x+n$. Before finding the intersection which is $y_1=y_2$ I believe we need another condition that relates $y_1,y_2$ to $y=x^2$. I'm sure it has to do with the derivative but I am stuck.","['calculus', 'algebra-precalculus']"
472761,Geometric intuition of adjoint,For a linear operator it holds that $\ker (T^\ast ) = (\operatorname{ran} (T))^\perp$. The star denote the adjoint of $T$ and $\perp$ the orthogonal complement. Is there a geometric intuition for the meaning of $\ker (T^\ast ) = (\operatorname{ran} (T))^\perp$?,['linear-algebra']
472792,Local triviality condition on line bundles,"We recall that a complex line bundle consists of a triple $(\pi,E,B)$ where $E,B$ are topological spaces, $\pi : E \to B$ a continuous map satisfying the following local triviality condition: Local Triviality: There is a cover $\{U_\alpha\}$ of $B$ such that for every $\alpha$, we have homeomorphisms $\varphi_\alpha: \pi^{-1}(U_\alpha) \stackrel{{\cong}}{\longrightarrow} U_\alpha \times \Bbb{C}$ such that $\pi = \operatorname{proj} \circ \varphi_\alpha$, where $\operatorname{proj} : U_\alpha \times \Bbb{C} \to U_\alpha$ is just projection onto the first factor. This local triviality condition also gives that $ \varphi_{\beta}\varphi_{\alpha}^{-1}(x,u) = (x, t_{\beta\alpha})$ for some $t_{\beta\alpha} : U_\alpha \cap U_{\beta} \to \Bbb{C}$; the $t_{\beta \alpha}$ are called transition functions. My question is: Say $B = \Bbb{P}^n$. Can we replace the condition ""there is a cover such that..."" with the condition ""for every open affine cover..."" ?","['fiber-bundles', 'algebraic-geometry', 'algebraic-topology']"
472806,Definition of limit and axiom of choice,"In the definition of limit of a function ($\epsilon-\delta$ definition) we say certain statements such as for every $\epsilon>0$ there exist $\delta>0$ ....
Now my question is, is a choice function required to ensure that for every $\epsilon$ there exist a $\delta>0$? Moreover, how we can we test whether a mathematical statement depends on axiom of choice or not?
I really don't know whether this question has any meaning or not, so please help me.","['axiom-of-choice', 'real-analysis', 'limits']"
472825,Laurent series coefficient calculation by Cauchy’s residue theorem.,"For homework, I've been asked to obtain the Laurent series expansions for the following function:
$$f(z) = \frac{1}{z^2(1-z)}$$ The question says to use Laurent's Theorem (not geometric series), which has been given as $$\tag{1}f(z) = \sum\limits_{n= -\infty}^\infty A_nz^n $$ where $$\tag{2}A_n = \frac{1}{2\pi i} \oint\limits_\gamma \frac{f(z)}{z^{n+1}} dz$$ My initial approach to the problem was to use Cauchy’s residue theorem to evaluate the integral in $(2)$, this theorem states: $$\oint\limits_\gamma f(z) dz = 2 \pi i \sum\limits_{a_k \in A} \mathrm{Res}_{z = a_k} f(z) $$ So in combination with $(2)$ I have, $$A_n = \sum\limits_{a_k \in A} \mathrm{Res}_{z = a_k} \frac{f(z)}{z^{n+1}}$$ to evaluate the residue I'm using the fact that $$\mathrm{Res}_{z = a} f(z) = \frac{1}{(m-1)!} \lim_{z \to a} \left(\frac{\partial}{\partial z}\right)^{m-1} ((z-a)^m f(z))$$ where $a$ is the pole and $m$ its corresponding order. $f(z)$ has poles at $z = 0$ order $2$ and $z=1$ order one (simple pole), so for the first region, $|z| < 1$, only the pole at $z = 0$ needs to be considered in the sum. My problem is that when solving to get a function for $A_n$ without the Residual, the limit comes to $\dfrac{n+1}{0} = \infty$ Can anyone tell me if my method is wrong? or if I've failed to differentiate properly (I apologise for how the question is formatted, I'm new to this) Here is my working to get $A_n$ (INCORRECT, corrected below) $$ A_n = \lim_{z \to 0} \frac{\partial}{\partial z} z^2 \frac{1}{z^{n+3}(1-z)}  $$
therefore
$$ A_n = \lim_{z \to 0} \frac{\partial}{\partial z} \frac{1}{z^{n+1}(1-z)}  $$
by quotient rule
$$ A_n = \lim_{z \to 0} \frac{(z^{n+1}(1-z)(0) - (1)((n+1)z^n - (n+2)z^{n+1}))}{(z^{n+1}(1-z))^2}  $$
..
$$ A_n = \lim_{z \to 0} \frac{z^n((n+1) - (n+2))z)}{z^{2n+2}(1-z)^2}  $$
canceling
$$ A_n = \lim_{z \to 0} \frac{(n+1) - (n+2)z}{z^{n+2}(1-z)^2}  $$
applying limit
$$ A_n = \lim_{z \to 0} \frac{n+1}{(0)(1)^2} = \infty  $$ Correct Answer For $|z| < 1$, a = 0, m = n+3
$$ A_n = \frac{1}{((n+3) - 1)!} \lim_{z \to 0} (\frac{\partial}{\partial z})^{n+3 - 1} z^{n+3} \frac{1}{z^{n+3}(1-z)} $$
..
$$ A_n = \frac{1}{(n+2)!} \lim_{z \to 0} (\frac{\partial}{\partial z})^{n+2} \frac{1}{(1-z)} $$
..
$$ A_n = \frac{1}{(n+2)!} \lim_{z \to 0} \frac{(n+2)!}{(1-z)^{n+1}} $$
apply limit
$$ A_n = \frac{(n+2)!}{(n+2)!} = 1$$
Which is as expected due to the geometric series solution, $n \ge -2$ is a condition for the factorial function Therefore subbing into
$$\tag{1}f(z) = \sum\limits_{n= -\infty}^\infty A_nz^n $$
gives
$$f(z) = \sum\limits_{n= -2}^\infty A_nz^n, |z| < 1 $$
THANK YOU",['complex-analysis']
472854,Which of the given statements are true?,"Which of the following statements are true? a. Consider the subspace $S^1 = \{(x, y)\in \mathbb{R}^2:x^2 + y^2 = 1\}$ of $\mathbb{R}^2$. Then,
there exists a continuous function $f : S^1\to \mathbb{R}$ which is onto. b. There exists a continuous function $f : S^1 \to \mathbb{R}$ which is one-one. c. Let $X = \{A = (a_{ij})\in M_2(\mathbb{R}):tr(A) = 0,~ |a_{ij}|\le2~\forall~1\le i,j\le 2\}$
Let $Y = \{\det(A) :A\in X\}$. Then, there exist $\alpha < 0$ and $\beta> 0$ such
that $Y = [\alpha,\beta].$ My attempt: a) False ($S^1$ is compact but $\mathbb{R}$ is not), b) False (For otherwise $S^1$ being compact $f(S^1)$ is homeomorphic to $S^1$ since any bijection from a compact set to a $T_2$ space is has continuous inverse. Also $f(S_1)$ being connected and compact and non-empty must be of the form $[a, b]$ where $a < b.$ Now removing any point from $S_1$ leave $S_1$ connected. The same doesn’t hold for $[a, b]$ except the points $a$ and $b$), c) True ($X$ is compact,since $X$ is bounded [easy to see]  and $X=tr^{-1} (0)∩[-2,2]^4$  is closed since closeness is productive property and trace is continuous determinant is continuous so $\det X$  is closed and bounded.Also $X$ is path connected,determinant is continuous so $\det X$  is connected & hence an interval also there' s both 
positive and negetive image) Am I right?","['general-topology', 'proof-verification']"
472880,Monotone convergence example,"In the first chapter of Probability wih Martingales (Willams) I came across the following example. Book says it's wrong, I don't understand what is wrong in that. Could somebody please explain why it's wrong ?","['general-topology', 'measure-theory', 'probability-theory']"
472903,Recurrence relation for words length $n$,"I need to solve following question: ""An alphabet consists out of 4 letters $a,b,c,d$ and 3 numbers $1,2,3$. Find the recurrence relation for the number of words of length $n$ where no two numbers are allowed to be adjacent."" This is what I came up with: If the first character of the word is a letter, we have 4 possible choices and leaves us with $n-1$ characters left. If the first character is a number, we know the second one is not allowed to be a number as well, so we're left with 4 choices and $n-2$ left to divide. Which gives me $a_n = 4 a_{n-1} + 4 a_{n-2}$ Not sure if this gives me the correct answer.","['recurrence-relations', 'discrete-mathematics']"
472908,"Given a desired coloring scheme for a stick, how can I brush it with the fewest steps?","If I want to color a stick (regarded as a line segment in one-dimensional space) to a desired coloring scheme using brush, how can I make it with the fewest steps? Notice that, new color will just cover over the olds, and both changing paints and crowhop during brushing will be regarded as causing new steps. For example, 2 steps are required in the case shown below: (Step 1) brush all the stick with blue and then (Step 2) brush the middle with red. and there are some other examples: How can I figure out the minimum step for any given desired coloring scheme, and find a coloring strategy? Thanks in advance for your help.","['puzzle', 'algorithms', 'combinatorics']"
472909,How to define $a^x$?,It's so common that we use the function $f(x)=a^x$. But actually how do we define it? In simple language we can say $a^n$ is the number $a$ multiplied with $a$ $n$ times for any $n$ in $\mathbb{N}$ and $a$ in $\mathbb{R}$. Then what about our $f$?,"['functions', 'real-analysis', 'definition']"
472915,What kind of matrices are non-diagonalizable?,"I'm trying to build an intuitive geometric picture about diagonalization.
Let me show what I got so far. Eigenvector of some linear operator signifies a direction in which operator just ''works'' like a stretching, in other words, operator preserves the direction of its eigenvector. Corresponding eigenvalue is just a value which tells us for how much operator stretches the eigenvector (negative stretches = flipping in the opposite direction).
When we limit ourselves to real vector spaces, it's intuitively clear that rotations don't preserve direction of any non-zero vector. Actually, I'm thinking about 2D and 3D spaces as I write, so I talk about ''rotations''... for n-dimensional spaces it would be better to talk about ''operators which act like rotations on some 2D subspace''. But, there are non-diagonalizable matrices that aren't rotations - all non-zero nilpotent matrices. My intuitive view of nilpotent matrices is that they ''gradually collapse all dimensions/gradually lose all the information'' (if we use them over and over again), so it's clear to me why they can't be diagonalizable. But, again, there are non-diagonalizable matrices that aren't rotations nor nilpotent, for an example: $$
\begin{pmatrix}
  1 & 1  \\
  0 & 1  
\end{pmatrix}
$$ So, what's the deal with them? Is there any kind of intuitive geometric reasoning that would help me grasp why there are matrices like this one? What's their characteristic that stops them from being diagonalizable?","['vector-spaces', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'soft-question']"
472916,Riemann sum error and the integral,"It is a well known, that we have the following approximation error:
$$  \left|\int_{a}^{b}f(t)dt-\sum_{i=0}^{n}f\left(\xi_{i}\right)s_{n}\right|<\frac{b-a}{2}s_{n}\cdot\text{max}_{x\in\left[a,b\right]}\left|f'\left(x\right)\right|,$$
where $s_{n}$ is the length of the equidistant decomposition of the interval $\left[a,b\right]$ and $f\in{C^{1}}\left(\left[a,b\right]\right)$.
My quesstions are:
1.) How this error estimate can be improved, if $f$ and $f'$ are both Lipschitz continuous?
2.) How such estimates look like, if $f$ is a bivariate function? Best regards
Lucas","['calculus', 'integration', 'numerical-methods']"
472927,"Finding the general solution of the differential equation $\,\,y''+y=f(x)$","I am stuck with the following problem: I have to show that the general solution of the differential equation $$y''+y=f(x)\,\, ,x \in (-\infty,\infty)$$, where $f$ is continuous real valued function on  $(-\infty,\infty)$ is $$y(x)=A \cos x+B \sin x + \displaystyle \int_{0}^{x} f(t) \sin (x-t) dt\,\, $$ where $A,B$ are constants. C.F. part of the reduced differential equation $y''+y=0$ is : $A \cos x+B \sin x$. But I am having trouble to get the P.I.(particular integral) which can be obtained by solving $$\frac {1}{D^2+1} f(x)$$,where $D \equiv \frac {d}{dx}$. This is where I am stuck. Am I going in the right direction? Can someone help? Thanks and regards to all.",['ordinary-differential-equations']
472945,"Prove that: $\sqrt{2\sqrt{3\sqrt{4\cdots\sqrt{n}}}}<3,\,\forall n\in\mathbb N.$","I know that: $\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1+\cdots}}}}=3,$ which is one of Ramanujan's infinite radicals. So surely the expression in question is less than $3.$ But how can I prove this without mentioning this or in general how to prove: $\sqrt{2\sqrt{3\sqrt{4\sqrt{\cdots\infty}}}}<3$ ? I'm not quite sure, how to approach this? Expressing the expression as an infinite product: $$\prod_{i=1}^{n} i^{\frac1{2^{i-1}}},\text{ as }n\to\infty$$ and then using some sort underlying inequalities might help! Please suggest. Thanks in advance.","['nested-radicals', 'real-analysis']"
472949,De Rham Cohomology of $M \times \mathbb{S}^1$,"Let $M$ be a closed (compact, without boundary) $m$-dimensional manifold. I want to prove that $H^{k+1}(M \times \mathbb{S}^1) = H^k(M) \oplus H^{k+1}(M)$. ($H^k$ is the $k$-th De Rham cohomology group.) I tried with the Mayer-Vietoris sequence, in two ways. First, I considered the decomposition $M \times \mathbb{S}^1 = (M \times e^{i(0, 3/2 \pi)}) \cup (M \times e^{i(\pi, 5/2 \pi)})$, but apparently it does not work. I tried also the following. Let $U, W \subset M$ diffeomorphic to an $m$-dimensional open ball, and let $\overline W \subset U$. Then the decomposition for the manifold would be $$
M \times \mathbb{S}^1 = (U \times \mathbb{S}^1) \cup ((M \setminus \overline W) \times \mathbb{S}^1)
$$
The argument would the use the Mayer-Vietoris sequence taking into account the fact that introducing a hole should ''reduce dimensions'' and hence help with induction. Any help would be much appreciated.","['homology-cohomology', 'algebraic-topology', 'differential-geometry']"
472952,Understanding concatenating the empty set to any set.,"I know that concatenating the empty set to any set yields the empty set. So, $A \circ \varnothing = \varnothing$. Here $A$ is a set of strings and the concatenation ($\circ$) of two sets of strings, $X$ and $Y$ is the set consisting of all strings of the form $xy$ where $x\in X$ and $y \in Y$. (You may want to take a look at page 65, Example 1.53 of Introduction to the Theory of Computation by Michael Sipser ).
However, I get somewhat puzzled when I try to intuitively understand this. A wrong line of thinking will make one to ask, ""If we concatenate $A$ with $\varnothing$, should not it still be $A$?"" Well, one way force myself to understand the correct answer, may be, to say that, since I am concatenating with an empty set, actually I will not be able to carry out the concatenation. The concatenation will not exist at all. I am asking for help from experienced users to provide hints and real life examples which will help one to modify the thinking process and help one better to really understand the correct answer. I am putting more stress on real life examples. I need to understand this. I am not happy simply memorizing the correct answer.",['elementary-set-theory']
472981,Formula for reversing digits of positive integer $n$,"I was able to work out the cases for $n$ having up to $4$ digits and was wondering if someone could verify my generalization to $m$ digits.  Here I am assuming that when a reversal results in there being a leading $0$ it get ignored (e.g. $76130$ gets reversed to $3167$, $998700$ to $7899$ etc.) I believe the function can be expressed as $r(n): \mathbb{N} \rightarrow \mathbb{N}$ 
$$r(n) = \left \lfloor \frac{n}{10^m}\right \rfloor +\sum_{k=0}^{m-1}10^{m-k} \left( \left \lfloor\frac{n}{10^k} \right \rfloor-10 \left \lfloor \frac{\left \lfloor \frac{n}{10^k}\right \rfloor}{10}\right \rfloor \right)$$ where again, $n$ has $m$ digits. It seems like this combination of the floor function and powers of 10 is the only way to achieve this but is this true?",['discrete-mathematics']
472986,Similar matrices [duplicate],"This question already has an answer here : If $\mathrm{Tr}(A)=0$ then $T=R^{-1}AR$ has all entries on its main diagonal equal to $0$ (1 answer) Closed 4 years ago . Let $A$ be a complex $n×n$ matrix with $tr(A) = 0$. Show that there exists an invertible $n×n$ matrix $B$ such that all diagonal entries of $BAB^{-1}$ are zeros. $\bf Edit:$ Is the fact that $\forall A\in M_{m\times n}(D)$, $D$ is $PID$, then $A$ is equivalent to a matrix which has the diagonal form $diag\{d_1,...,d_2,0,..,0\}$ where $d_i|d_j, i\leq j$and the other entries are zeros, applicable in this question?","['modules', 'matrices', 'linear-algebra']"
472998,Why do we need Hausdorff-ness in definition of topological manifold?,"Suppose $M^n$ is a topological manifold, then $M^n$ locally looks like $\mathbb{R}^n$. 
$M^n$ is locally Hausdorff, since $\mathbb{R}^n$ is Hausdorff and Hausdorff-ness is a topological invariant. All I want to understand is: 1) Does locally Hausdorff-ness imply Hausdorff-ness? (I can not imagine a locally Hausdorff topological space that is not globally Hausdorff) 2) Why do we need Hausdorff-ness in definition of the topological manifold? Is locally Hausdorff-ness not sufficient? If not, why? Can anyone say anything that might be helpful?","['general-topology', 'manifolds', 'differential-geometry']"
473002,"find $\frac{\partial f(u(x(t),y(t)),v(x(t),y(t)))}{\partial t} $","how to find $$\frac{d z}{d t} $$ where is $z=f(u(x(t),y(t)),v(x(t),y(t)))$ and if some one can give me some advice which make me deal more easy with this subject","['multivariable-calculus', 'derivatives']"
473006,Calculating expectations in terms of quantile functions?,"I have a well behaved random variable, $X$, where I can solve for the quantile in closed form, but in general cannot invert it to get the pdf/cdf.  Assume whatever you need on the properties of $X$ and that the quantile function is $F^{-1}(p)$. Then through standard results, we know that the expectation can be calculated as:
$$
E(X) = \int_{-\infty}^{\infty}x F'(x)dx = \int_{0}^{1} F^{-1}(p)dp
$$ My question is whether this generalizes for expectations of functions of $X$.  i.e. for  strictly increasing $h(X)$ assuming whatever measureability necessary, can $E(h(X))$ be written in terms of quantiles?
$$
E(h(X)) = \int_{0}^{1}h(F^{-1}(p))dp ???
$$","['probability-distributions', 'probability']"
473015,Expressing an integral in terms of the Bernoulli numbers,"In Ahlfors' Complex Analysis text, the Bernoulli numbers, $B_k$, are defined as the coefficients in a Laurent development: $$(e^z-1)^{-1}=\frac{1}{z}-\frac{1}{2}+ \sum_1^\infty (-1)^{k-1} \frac{B_k}{(2k)!} z^{2k-1}. $$ (I'm aware that this definition is different from the modern one on Wikipedia.) Over the course of proving Stirling's formula, the author states that it can be shown that for all $\nu \geq1$ $$ (-1)^{\nu-1} \frac{1}{\pi} \int_0^\infty \eta^{2\nu-2} \log \left( \frac{1}{1-e^{-2 \pi \eta}} \right) \mathrm{d} \eta=(-1)^{\nu-1} \frac{1}{(2\nu-1)2\nu} B_\nu$$
""by means of residues"". I have tried showing that by reaching the function in the definition of the Bernoulli numbers, using integration by parts. I found that $$ \frac{1}{\pi} \int_0^\infty \eta^{2\nu-2} \log \left( \frac{1}{1-e^{-2 \pi \eta}} \right) \mathrm{d} \eta=\frac{2}{2\nu-1} \int_0^\infty \eta^{2\nu-1} (e^{2 \pi \eta}-1)^{-1} \mathrm{d} \eta $$
Sadly, I can't find any point $\eta$ with a residue containing $B_\nu$... Maybe if the powers of $\eta$ were in the denominator I could have done something. Can anyone help me prove this identity?","['residue-calculus', 'bernoulli-numbers', 'integration', 'complex-analysis']"
473026,Probability of 1x six from seven dice?,Could someone help me with how the following is calculated: What is the probability of rolling a die seven times and getting at least one six? My instinct told me it would be $1/6+\cdots + 1/6$ but this ends up being $7/6$.,"['dice', 'probability']"
473037,Proof $\mathbb{R}^n$ is a complete metric space.,"$\mathbb{R}^n$ is a complete metric space. Consider a Cauchy sequence $\{\mathbf{x}_k\}$ in $\mathbb{R}^n$ , we want to show it converges to a point $\mathbf{x} \in \mathbb{R}^n$ . That is to say, if $|\mathbf{x - x_k}| \to 0$ as $k \to \infty$ . Hence, we let $\epsilon \to 0$ , and we get $\mathbf{|x_k - x_j|} < \epsilon$ by Cauchy sequence, and let $\mathbf{x = x_j}$ we showed the desired result. Definition $\mathbb{R}^n$ is a complete metric space . Every Cauchy sequence in $\mathbb{R}^n$ converges to a point of $\mathbb{R}^n$ . Definition Cauchy sequence . Given $\epsilon > 0$ , there is an integer $K$ such that $\mathbf{|x_k - x_j|} < \epsilon$ for all $k,j \geq K$ . I am not fond of my proof, because I am not certain if I can approach $\epsilon$ to be zero, nor if I can equate $\mathbf{x}$ to be $\mathbf{x_j}$ since $\mathbf{x_j}$ is changing while $\epsilon$ changes. Edit Especially, I am baffled that why we need to do it in coordinates? I think they can be subtracted directly, as the definition of Cauchy sequence I added a short while ago?","['proof-verification', 'real-analysis']"
473057,Exponent of a finite abelian group,"I have a very basic question: Let $G$ be a finite abelian group and let $m$ be the exponent of $G$. Then does there exist $g\in G$ s.t. o$(g)=m$ and if so, why? Many thanks in advance.","['finite-groups', 'group-theory', 'abelian-groups']"
473075,Proof that 2 funtion of the type $f_t(x) = \frac{1}{t} \cdot e^{-tx²} $ don't intersect,"so as the titles states I wan't to proof that no two functions $f_t$ of type $$f_t(x) = \frac{1}{t} \cdot e^{-tx²} \; \text{given that} \; t>0$$ share a point.
This is a question from my textbook.
However I come to the conclusion that there should be 2 functions should share some point. $$f_a(x) = \frac{1}{a} \cdot e^{-ax²}$$
$$f_b(x) = \frac{1}{b} \cdot e^{-bx²}$$
Let $f_a(x) = f_b(x)$ $$\frac{1}{a} \cdot e^{-ax²} = \frac{1}{b} \cdot e^{-bx²}$$
$$\frac{1}{a} \cdot e^{a} = \frac{1}{b} \cdot e^{b}$$
$$ae^{-a}=be^{b}$$
In order to proof that the 2 functions don't share a point I would need to proof that a=b
This would mean that the function $g(x)=xe^x$ is a one to one function. However this is not true! Now, all continuous one-one functions have to be monotonic (strictly increasing or decreasing). But we know that this is not the case for $g(x)$ since $\lim_{x \to 0} g(x)=\lim_{x \to +\infty}f(x)=0$ whereas $f(1)>0$ Where is my mistake?",['algebra-precalculus']
473083,What does this statement mean? Pertaining to Definition of Lipschitz continuous function,"I'm being introduced into the Picard Existence Theorem. I am fairly comfortable with math terminology but not great at it. In your answer I would appreciate a mathematicians answer, sparsed with some actual english please, to help explain things =). The statement is defining a Lipschitz continuous function. Here is the statement. A function $f: U \times [t_0;t_0 + T ] \rightarrow \mathbb{R}^n,  U \subset \mathbb{R}^n$, is Lipschitz continuous in $U$ if there exists a constant $L$ such that $\| f(y,t) - f(x,t) \| \le L\|x - y\|$ for all $x,y \in U$ and $t \in [t_0;t_0 + T ]$. If $U = \mathbb{R}^n$, $f$ is called globally Lipschitz. What I don't get: 1) The $\times$ after the first $U$. Is that saying the cartesian product of $U$ and $[t_0;t_0 + T ]$? I get the underlying meaning of this statement...I have a function that is mapping $U$ into $\mathbb{R}^n$ but I don't get the specifics of that first part. 2) The second statement I understand the math this is the part I'm most confused about , but don't understand the meaning of it. I mean what is this constant $L$ in the first place? I just don't see where this statement comes from or what it even means. The rest of the statement I understand, thanks for the help!",['ordinary-differential-equations']
473092,"Which is greatest in the sequence $1, \sqrt 2 , \sqrt[3] 3 , \sqrt[4] 4 \cdot \cdot \cdot?$","This problem is from Ivan Niven's ""Maxima and Minima Without Calculus"". What is another way to find this? The solution from the book was: Note that $\large \sqrt[4] 4 =\sqrt 2$ so this hints that $\sqrt[3] 3$ is the largest. Next the book proved that $\sqrt[3] 3>n^{1/n}$ or $3^n>n^3$ for large enough $n.$",['algebra-precalculus']
473111,Schwartz kernel theorem for induced distributions...,"I'm studying periodic pseudo-differential operators on torus and I have a question concearning the Schwartz kernel theorem: If $A:C^\infty(\mathbb T^n)\rightarrow \mathcal{D}^{'}(\mathbb T^n)$ is a continuous linear functional then by the Schwartz kernel theorem there is an unique $K_A\in \mathcal{D}^{'}(\mathbb T^{2n})$ such that, $$\langle A\varphi, \psi\rangle=\langle K_A, \psi\otimes \varphi\rangle.$$ Here $D^{'}(\mathbb T^n)$ is the set of all distributions on $\mathbb T^n$ (linear and continuous functionals on $\mathbb T^n$). In the case the distribution $Af$ is induced by $Af$ (as a mapping) in the standard way, $$\psi\mapsto \int_{\mathbb T^n}Af(x)\psi(x)\ dx,$$ then the distribution $K_A$ is also induced by a function?","['fourier-analysis', 'partial-differential-equations', 'analysis']"
473118,Are positive definite matrices necessarily diagonalizable and when does the famous eigenvalue criterion apply?,"I mean in $\mathbb{C}$ positive definite matrices seem to be self-adjoint. For matrices over real vector spaces this seems to be wrong, but is it still true that they are diagonalizable? Then everyone knows a result similar to this: When a matrix has only positive eigenvalues then it is positive definite. Is this result always true, and do we also have the converse in general?","['matrices', 'linear-algebra', 'abstract-algebra']"
473124,A set of basic abstract algebra exercises,"I wanted to review some basic abstract algebra. Here's a few problems for which I am seeking solution verification. Thank you very much in advance! $\textbf{Problem:}$ Let $H$ be a subgroup of $G$, and let $X$ denote the set of all the left cosets of $H$ in $G$. For each element $a \in G$, define $\rho_{a}: X \rightarrow X$ as follows: $$\rho_{a} (xH) = (ax) H.$$ Prove that $\rho_{a}$ is a permutation of $X$ for each $a \in G$. Prove that $h: G \rightarrow S_{X}$ defined by $h(a)=\rho_{a}$ is a homomorphism. Prove that the set $\{a \in H : xax^{-1} \in H \> \forall x \in G\}$ is the kernel of $h$. $\textbf{Solution:}$ Choose any $a \in G$. We first show that $\rho_{a}$ is injective. So, assume $\rho_{a}(xH) = \rho_{a}(x'H).$ Hence, $(ax)H = (ax')H$; we need to show $ xH = x'H$. Let $g \in xH$. Then, $g = xh_0$ and $ag = (ax)h_0 = (ax')h_1$ by our assumption. Multiplying $ag = (ax')h_1$ on the left by $a^{-1}$ gives us that $g= x'h_1$. Thus, $g \in x'H$. A similar argument gives us the reverse inclusion. To prove the surjectivity of $\rho_{a}$, let $xH \in X$. Since $a^{-1}x \in G$, we have $\rho_{a} (a^{-1}x H) = (aa^{-1}x)H = xH$. Indeed, $\rho_{a}$ is surjective. First, we show $\rho_{ab} = \rho_{a} \circ \rho_{b}$. Let $xH$ be an arbitrary element belonging to $X$. Observe that $$\rho_{a} \circ \rho_{b} (xH) = \rho_{a}((bx)H) = (abx)H = \rho_{ab}(xH).$$ Thus, $$h(ab)=\rho_{ab}=\rho_{a} \circ \rho_{b} = h(a)h(b),$$ and we conclude that $h$ is a homomorphism. Let $K$ denote the kernel of $h$. We show $\{a \in H : xax^{-1} \in H \> \forall x \in G\} = K$. To start, let $k \in K$. Then, $h(k)=\rho_{k}=\rho_{e}$, where $e$ is the identity element of $G$. Since $\rho_{k}=\rho_{e}$, for each $xH \in X$ we have $(kx)H=xH.$ Hence, $kxh_0 = xh_1$ for some $h_0,h_1 \in H$ and $x^{-1}kx=h_{1}h^{-1}_{0}.$ This implies $x^{-1}kx \in H$. For clarity, put $x_0 = x^{-1}$. So, $x^{-1}kx = x_{0}kx^{-1}_0 \in H$. Indeed, $k \in\{a \in H : xax^{-1} \in H \> \forall x \in G\}$. To prove the reverse inclusion, this time let $k \in \{a \in H : xax^{-1} \in H \> \forall x \in G\}.$ Then, we must show $(kx)H=xH$. Let $g\in (kx)H$. Suppose $g = kxh_0$ for $h_0 \in H$. Multiplying on the right by $x^{-1}$, we obtain $x^{-1}g = x^{-1}kxh_0 = h_1$ for some $h_1 \in H$. Multiplying on the right by $x$, we indeed get $g=xh_1 \in xH$. For the reverse inclusion, we let $g \in xH$ so that $g=xh_0$ for some $h_0$. Then, $$kg=kxh_0$$ $$g^{-1}kg=g^{-1}kxh_{0}$$  $$ h_{1}=g^{-1}kxh_0$$ $$g=kxh_0h^{-1}_{1}.$$ The last line gives us that $g \in (kx)H$ as desired.  $\blacksquare$","['abstract-algebra', 'solution-verification']"
473125,Do we need to identify dual spaces in PDEs?,"In PDEs we often use the fact that we can identify dual spaces eg. $L^2(0,T;V)^* = L^2(0,T;V^*)$ in the sense that
$$u_t + Au = f$$
where $u_t$, $f \in L^2(0,T;V^*)$ and $A:L^2(0,T;V) \to [L^2(0,T;V)]^*$ (eg. $A=\Delta$). Because we identify the dual spaces, $Au$ and $f$ both lie in the same space hence the equality makes sense. There are more complicated examples with $L^p(0,T;V)^*$ and $L^q(0,T;V^*)$ where $p$ and $q$ are conjugate. My question is, is this identification always necessary when dealing with PDE problems? Every paper I read seems to use this identification. Suppose I have a very weird space and I cannot show that I can identify the dual spaces (eg. if $V$ is not Banach/reflexive). Can one pose the problem differently?","['functional-analysis', 'partial-differential-equations']"
473127,"If $\mu_1\le\mu_2$ on an algebra, then $\mu_1\le\mu_2$ on the $\sigma$-algebra generated by that algebra","We suppose that $\mu_1$ and $\mu_2$ are finite measures on a $\sigma$-algebra $\Sigma$ generated by the algebra $\Sigma_0$. My question is how to prove that if $\mu_1(A) \leq \mu_2(A)$ holds for all $A$ in $\Sigma_0$, then it holds for all $A$ in $\Sigma$.","['measure-theory', 'real-analysis']"
473159,Prove that the derivative of a scalar field cannot be greater than 0 for a fixed point and for every vector y,"The definition of the derivative of a scalar field with respect to a vector was given as the following: Given a scalar field $f: S \rightarrow R$, where $S \subseteq \mathbf{R}^n$. Let $a$ be an interior point of $S$ and $y$ an arbitrary point in $\mathbf{R}^n$. Then $f'(a;y)$ is the derivative of $f$ at $a$ with respect to $y$:
  $$
f'(a;y) = \lim_{h\rightarrow 0}\frac{f(a+hy)-f(a)}{h}
$$ Prove that there is no scalar field $f'(a;y)>0$ for a fixed vector $a$ and every nonzero vector $y$. I'm not really sure where to go with this. If $f'(a;y)>0$ for all $y$, then $f$ must be increasing in every direction around $a$, so $a$ is a minimum of $f$, maybe? I'm not even sure that's valid, so not too sure what to do, really.","['multivariable-calculus', 'real-analysis']"
473160,"quasi-affine/projective varieties | f=g on dense subset | diagonal subset | how to show that (f,g) is continuous?","Let $f: X \to Y$ and $g: X \to Y$ be morphisms in the category $(QProj-k)$ (its objects are quasi-projective and quasi-affine $k$-varieties). Show that $f=g$ if and only if $f$ and $g$ are identical on a dense subset of $X$. I have been working for a while on this exercice, and made the following progress: We first introduce the notion of the diagonal $\triangle(\mathbb{P}_k^n) \subset \mathbb{P}_k^n \times \mathbb{P}_k^n$. We say that $([x_0,\ldots,x_n], [y_0, \ldots, y_n]) \in \mathbb{P}_k^n \times \mathbb{P}_k^n$ is in $\triangle(\mathbb{P}_k^n)$ if and only if $[x_0,\ldots,x_n] = [y_0, \ldots, y_n]$. This condition can be neatly summarized by
$$V( \ \{ \psi_{ij} = x_i y_j - x_i y_i \| 0 \leq i,j \leq n\} \ )$$
and it is clear that this is a closed subset. If $V \subset \mathbb{P}_k^n$ then $V \times V$ inherits its topology as a subset of $\mathbb{P}_k^n \times \mathbb{P}_k^n$. Therefore $$\triangle_V = \triangle(\mathbb{P}_k^n) \cap (V \times V)$$ is closed in $V \times V$ since $\triangle(\mathbb{P}^n)$ is closed in $\mathbb{P}_k^n \times \mathbb{P}_k^n$. For this reason the special case can easily be reduced to the case where $Y = \mathbb{P}_k^n$. Notice that $\{ x \in X \mid f(x) = g(x) \}$ is the inverse image of $\triangle(Y)$ under the continuous mapping. 
$$(f,g): X \to Y \times Y: x \mapsto (f(x),g(x))$$
Therefore this preimage is closed. But having a closed dense subset means that $f=g$ everywhere. It only remains to show why the above map $(f,g)$ is continuous. Maybe I am making things too complicated. But I suspect something is fishy. In common sense topology (i.e. taking cartesian product $\mathbb{R} \times \mathbb{R}$) we have nice open sets $U \times V$ where $U,V$ are open in $\mathbb{R}$. But the same does not hold with the Zariski topology. Just look at the simple case of $\mathbb{A}^1 \times \mathbb{A}^1$ where each component has as closed sets the singletons respectively. But this obviously does not encompass the Zariski topology on $\mathbb{A}^2$. In other words, to solve this exercice, I have to determine the whole topology on the product, right? This seems an enormous amount of work (cf. the Segre embedding) and in the context of this exercice makes no sense. Am I missing something obvious? Is there an easy way to conclude that $(f,g)$ is continuous? Also, put yet another way, in what sense is $(f,g)$ a morphism ""naturally"" (in the categorical sense for the product) if $f$ and $g$ are morphisms?","['algebraic-geometry', 'abstract-algebra']"
473180,The Diophantine equation $x^2 + 2 = y^3$ [duplicate],"This question already has answers here : Solve $x^2+2=y^3$ using infinite descent? (10 answers) Closed 2 years ago . How to solve the Diophantine equation $x^2 + 2 = y^3$ with $x,y>0$ ?
($x,y$ are integers.)","['mordell-curves', 'diophantine-equations', 'number-theory']"
473185,Derivative of logarithmic function,"If the function $f(x)=\log_{2x}x^2$ is given, what is $f'(4)$? I tried to use the formula for derivative of logarithm but here the base is $2x$, so it made me confused. Note that the answer is $1/(18\ln 2)$.",['derivatives']
473190,unbiased estimator for geometric distribution,"Let $X_1,\ldots,X_n$ to be sample distributed geometric with parameter $p$. Find MLE. Is it unbiased? The distribution for each is $p(1-p)^{x_i-1}$ so the function is $$L(p)=\displaystyle\prod_{i=1}^np(1-p)^{X_i-1}.$$ After taking lns on both sides I got $$l(p)=\ln(L(p))=n\log(p)+\sum_{i=1}^n(X_i-1)\cdot \log(1-p).$$ I derivatied and found maximum in $p_m=\dfrac{n}{n+\sum_{i=1}^n(X_i-1)}$. Now I need to calculate $E[p_m]$: $$E[p_m]=nE\left[\frac{1}{\sum X_i}\right]$$ How can proceed?",['probability']
473198,using definition of derivative,"$f(x)=x^3-6x^2+9x-5$ is given. What is the value of $$\lim_{h\to0}\frac{[f'(1+2h)+f'(3-3h)]}{2h}$$ I tried to use the definition of derivative,and here it seems like the expression will be equal to something like the 2nd derivative of $f(x)$ but I'm confused with $2h$ and $-3h$.",['derivatives']
473229,Expected value of maximum and minimum of $n$ normal random variables,"Let $X_1, \dots, X_n \sim N(\mu,\sigma)$ be normal random variables. Find the expected value of random variables $\max_i(X_i)$ and $\min_i(X_i)$ . The sad truth is I don't have any good idea how to start and I'll be glad for a hint.","['normal-distribution', 'expected-value', 'probability']"
473247,Difference of mapsto and right arrow,Could someone please explain to me what is the difference in the two arrows$$\rightarrow$$ and $$\mapsto$$ For example in Probability wih Martingales (Willams) Thank you.,"['probability-theory', 'functions', 'notation']"
473257,A maximal Hoeffding's inequality?,"Let $X_1, \cdots, X_n$ be real-valued independent random variables satisfying $|X_k|\le 1$ and $\mathbb EX_k=0$. Hoeffding's inequality tells us that for any $k=1,\cdots, n$ and $t>0$,
$$\mathbb P\Big( \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le 2 e^{-t^2/2}.$$ My question is whether there exists a similar bound for the maximum over $k$. More precisely: Question: Do there exist absolute constants $C>0$ and $A>0$ so that
  $$\mathbb P\Big( \max_{1\le k\le n} \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le C e^{-t^2/A}$$
  holds for all $t>0$? If not what can we say about the left hand side?","['statistics', 'probability', 'probability-theory']"
473266,Ideal defining the nilpotent cone of $\mathfrak{gl}_n(k)$,"Let $k$ be an algebraically closed field, and let $\mathfrak{g}=\mathfrak{gl}_n(k)$.  Let $\mathcal{N}\subset\mathfrak{g}$ be the nilpotent cone, that is: $$\mathcal{N}=\{A\in\mathfrak{g}\mid A^n=0\}=\{A\in\mathfrak{g}\mid \text{ch}(A)=x^n\}$$ where ch$(A)$ is the characteristic polynomial of the matrix $A$.  Let $X=(x_{ij})$ be a matrix of indeterminates, and notice that as an affine variety $\mathcal{N}\subset\mathbb{A}_k^{n^2}$ can be defined in two ways.  If $I$ is the ideal generated by the $n^2$ homogeneous polynomial equations of degree $n$ given by $X^n=0$, then $\mathcal{N}=Z(I)$.  Also, if $J$ is the ideal generated by the $n$ homogeneous equations of degrees $1,2,\ldots,n$ which define the non-leading coefficients of ch$(X)$, then $\mathcal{N}=Z(J)$.  Now it follows that $\sqrt{I}=\sqrt{J}$. It is clear to me that $I$ is not radical because $x_{11}+x_{22}+\ldots+x_{nn}\in \sqrt I\setminus I$.  Is $J$ a radical ideal?  I believe it is, based on the comments in this question , but I can't seem to prove it.","['commutative-algebra', 'algebraic-geometry', 'lie-algebras', 'abstract-algebra']"
473275,Entire Function Problem in Complex Analysis,"I am currently working on some review problems in complex analysis and came upon the following conundrum of a problem. ""If $f(z)$ is an entire function, and satisfies $|f(z^2)|\le|f(z)|^2$, prove that f(z) is a polynomial."" My intuition tells me to show that f(z) has a pole at infinity by showing that infinity is not an essential or removable singularity. However, I am getting stuck after this. Thanks for the help,","['complex-analysis', 'analysis']"
473280,"Solve $x^2+y^2=2$ for $x,y\in\mathbb Q$.","Solve $x^2+y^2=2$ for $x,y\in\mathbb Q$. I think the answer should be in terms of 1 integer variable $\in\mathbb Z$ only. I rewrite the equation to $(x+y)^2+(x-y)^2=2^2$, then by the formula of pythagorean triples, $x+y=u^2-v^2,x-y=2uv,2=u^2+v^2$. How can I proceed? Thanks.","['diophantine-equations', 'number-theory']"
473282,An intuitive solution to this problem (Using probability tree),"A group of boys has been lost several days in the dessert. This group has a phone to make phone calls. After a long way walk, they believe that the current area is suitable for phone calls; even though, the battery just allow three call attempts. Due to remote conditions of the current area, the probability of a successful call is 0.2. If the call is not successful, the network would save a register of their location with a probability of 0.375. With a probability of 0.625 the attempt was in vain. If the call attempt was successful or there are 2 registers, they would be rescued within a few hours the same day. 1.) What is the probability that they are not rescued the same day if that just depends on the result of the call attempts.
2.) Which is the probability that the group is rescued with EXACTLY two call attempts
3.) What is the probability of a successful call
4.) What is the probability that the network generates register but they are not rescued I have try a solution by a tree, but i'm blocked with the fact that with 2 calls they are rescued. I really appreciate an explanation, since my self-learning resources are not extremely complete for wide understanding. If you think in a tree, how could it be. I would really appreciate a tree model of the problem","['probability-theory', 'discrete-mathematics', 'probability']"
473285,Almost surely statement in Williams book.,In Probability with Martingales (Williams) I came across the following proposition and then they give the following contradictory example Could someone please explain how it can be so? Also why is that in the truth set they use $\rightarrow \frac{1}{2}$ and not $= \frac{1}{2}$ when comparing each outcome? Thank you.,"['probability-theory', 'measure-theory', 'probability']"
473288,Real Symmetric Matrices,"Let $A$ be a real, symmetric, $n$ x $n$ matrix. Suppose $A^m=I$ for some $m$. Prove $A^2=I$. I think I want to use the symmetric implies diagonalizability...and take powers from there...correct?",['linear-algebra']
473292,Elementary statistics problem,"Suppose that a data set $ \{x_n: n = 1,\dots,N\} $, with $ N = 500,000 $ has average
  \begin{equation}
<x> = \frac{1}{N}\sum\limits_{n=1}^{N}x_n=13.06
\end{equation}
  and root mean square
  \begin{equation}
\sigma = \sqrt{\frac{1}{N}\sum\limits_{n=1}^{N}x_n^2}=13.67
\end{equation}
  Using this information, derive the best upper bound you can, for the number of measurements that are greater than $ 17.1 $. Intuition says that we should determine such $ k \in \mathbb{N}, l_0 \in \mathbb{R} $ so that exactly k measurements would be equal to $ 17.1 $, and exactly $ N - k $ measurements would be equal to $ l_0 $ (so that $ <x> $ and $ \sigma $ would be as given - obviously, it is very easy). But I can't even prove that $ k $ $ is $ an upper boundary, let alone the best one. can anybody hint, is there a well-known formula for this case?","['statistics', 'combinatorics']"
473299,Question on compact metric space.,"Is the set of rationals in $[0,1]$ compact? I seems like every open covering should have a finite sub-covering, yet I have read that compact metric spaces are complete...","['general-topology', 'metric-spaces', 'rational-numbers']"
473312,Find the domain of $\sqrt{x^2-9}$,"$$\sqrt{x^2-9}$$ I know that the domain of square root is greater than or equal to zero. I solve for when $x^2-9<0$ and get $x^2<9$. Now I get $x<-3$ and $x<3$. I know that the domain is $(-\infty,-3] \cup [3,\infty)$ The problem is I do not understand how the $x<3$ gets flipped to $x>3$, am I doing this step properly or is there another way to do it?",['algebra-precalculus']
473320,Negation of uniform convergence,"Suppose $f_{n}$ is a sequence of functions which does not convergence uniformly to $f$. Does this mean that there exists an $\varepsilon_{0} > 0$, an $x_{0}$, and a sequence of integers $n_{k} \rightarrow \infty$ such that $|f_{n_{k}}(x_{0}) - f(x_{0})| \geq \varepsilon_{0}$?","['uniform-convergence', 'real-analysis', 'analysis']"
473340,Inverse function theorem: how show $F \in C^k \Rightarrow F^{-1} \in C^k$ with this method?,"I am reading the proof in Buck's Advanced Calculus of the inverse function theorem, on p. 359. The way he proves it is to show that $(DF)_{p_0}^{-1}$ satisfies $$F^{-1}(p_0 + h) - F^{-1}(p_0) = (DF)_{p_0}^{-1}(h) + o(h).$$ Therefore $(DF)_{p_0}^{-1}$ must be the differential of $F^{-1}$ at the point $p_0$, and since $(DF)^{-1}_p$ is a rational function of the entries of $(DF)_p$ (with denominator = the Jacobian, which is nonzero), $F^{-1}$ must be $C^1$, since $F$ is assumed to be $C^1$. My Question: This has only shown that $$F \in C^1 \Rightarrow F^{-1}\in C^1.$$ It has not shown the result that if $F$ is $C^n$, then $F^{-1}$ is $C^n$. If we want to maintain the structure of this proof, is it easy enough to get that extra result? Or is this stronger result more easily shown with another style of proof altogether? (I am aware there are other methods, based on the contraction principle, or a fixed point theorem.)",['multivariable-calculus']
473342,"Differentiable and Continuous functions on [0,1] with 'weird' conditions.","I've been stuck on this one for a while. Comes from an analysis qual question. Let f be a function that is continuous on $\left[0,1\right]$ and differentiable on $(0,1)$. Show that if $f(0)=0$ and $|f'(x)| \leq |f(x)|$ for all $x \in (0,1)$, then $f(x)=0$ for all $x \in \left[0,1\right]$. What I've tried doing so far is see if there was anything I could do with MVT. I didn't really see anything to do with definitions either..to which I have a feeling I'll be playing around with them. Drawing a picture was a little difficult with these conditions as well Any hints/suggestions?",['real-analysis']
473349,Inverse function theorem: Why is $\frac {\partial \phi }{\partial y} = \frac {-\partial F / \partial y} {\partial F / \partial z}$?,"Given $F(x,y,z) = 0$, $\partial F/\partial z \neq 0$ at $p_0$, by the implicit function theorem we can solve for $z=\phi(x,y)$ near $p_0$. I am told that $$\frac {\partial \phi }{\partial y} = \frac {-\partial F / \partial y} {\partial F / \partial z}.$$ I am told that we can come to this conclusion by taking the total derivative $$dF = \frac {\partial F} {\partial x}dx + \frac {\partial F} {\partial y}dy + \frac {\partial F} {\partial z}dz = 0,$$ setting $dx = 0$, and solving for $dz/dx$. I am aware that this has an interpretation in terms of differential forms, but for now it is just an algebraic manipulation to me. Can someone point me to a proof that $$\frac {\partial \phi }{\partial y} = \frac {-\partial F / \partial y} {\partial F / \partial z}?$$","['multivariable-calculus', 'reference-request']"
473393,Are Fourier Analysis and Harmonic Analysis the same subject?,Are Fourier Analysis and Harmonic Analysis the same subject? I believe that they are not the same. Maybe there is big difference between those subjects but I need to know what is the main difference between those subjects and what is the main intersection? What is the common between those subjects?,"['harmonic-analysis', 'fourier-analysis', 'analysis']"
473396,"Find all critical points of $f(x,y) = x^3 - 12xy + 8y^3$ and state maximum, minimum, or saddle points.","Find all critical points of $f(x,y) = x^3 - 12xy  + 8y^3$ and state whether the function has a relative minimum, relative maximum, or a saddle at the critical points. So I have: $f_x = 3x^2 -12 y$ $f_y = -12x + 24y^2$ $f_{xx} = 6x$ $f_{yy} = 48y$ $f_{xy} = -12$ I found that my critical points were: $(0,0)$ and $(2,1)$, but I still need to classify them. My question is, how do I check if $f_{xx}$ is positive or negative? This seems like a silly question (I'm sure it is), but do I plug in $(0,0)$ for $f_{xx}$? Wouldn't that then be $6\cdot 0 > 0$? That seems wrong.","['optimization', 'multivariable-calculus']"
473402,Sequence of convex functions converges uniformly,"I am working on the following problem. Let $f_{n}: [a, b] \rightarrow \mathbb{R}$ be a sequence of convex functions. Furthermore, for each fixed $x \in [a, b]$, suppose
  $f(x) = \lim_{n \rightarrow \infty}f_{n}(x)$ exists and $f(x)$ is continuous on $[a, b]$. Show that $f_{n} \rightarrow f$ uniformly. The solution seems to have been mentioned here and here . However, the solutions don't seem very satisfactory to me,
so I decided to write out explicitly my own solution (partially because they start with a proof by contradiction). Can anyone check my solution to make sure it is correct? I've tried to formulate a direct proof. Fix $\varepsilon > 0$. Since $f$ is continuous on $[a, b]$, it is uniformly continuous there, and hence there exists an $\delta > 0$ such that when $|x - y| < \delta$,
  $|f(x) - f(y)| <\varepsilon/10$. Partition $[a, b]$ into $\{\alpha_{0}, \alpha_{1}, \ldots, \alpha_{m}\}$ where $\alpha_{0} = a$ and $\alpha_{m} = b$
  such that $|\alpha_{i + 1} - \alpha_{i}| = \delta/2$, $i = 0, 1, 2, \ldots, m - 2$ and possibly $|\alpha_{m} - \alpha_{m - 1}| < \delta/2$. Since for each fixed $x$, $f_{n}(x)$ converges to $f(x)$, there exists an integer $N$ such that $|f_{n}(\alpha_{i}) - f(\alpha_{i})| < \varepsilon/10$
  for all $i = 0, 1, \ldots, m$ and $n \geq N$. For $x \in [a, b]$, $x \in [\alpha_{i}, \alpha_{i + 1}]$ for some fixed $i$. Then $x = \lambda_{x} \alpha_{i} + (1 - \lambda_{x})\alpha_{i + 1}$ for $\lambda_{x}$ between 0 and 1.
  Therefore by convexity of $f_{n}$, for $n \geq N$ (which is independent of $x$), we have
  \begin{align*}
f_{n}(x) - f(x) &\leq \lambda_{x} (f_{n}(\alpha_{i}) - f(x)) + (1 - \lambda_{x})(f_{n}(\alpha_{i + 1}) - f(x))\\
&\leq |f_{n}(\alpha_{i}) - f(x)| + |f_{n}(\alpha_{i + 1}) - f(x)|\\
&\leq |f_{n}(\alpha_{i}) - f(\alpha_{i})| + |f(\alpha_{i}) - f(x)| + |f_{n}(\alpha_{i + 1}) - f(\alpha_{i + 1})| + |f(\alpha_{i + 1}) - f(x)|\\
& < 2\varepsilon/5
\end{align*}
  where the first and third terms in the sum is $< \varepsilon/10$ since $n \geq N$ and the second and fourth terms in the sum is $< \varepsilon/10$ since $x$ is between $\alpha_{i}$ and $\alpha_{i + 1}$ and $|\alpha_{i + 1} - \alpha_{i}| \leq \delta/2$ (and hence apply uniform continuity of $f$). We now show the other direction and consider $f(x) - f_{n}(x)$. Since $|f_{n}(\alpha_{i}) - f(\alpha_{i})| < \varepsilon/10$ for $i = 0, 1, \ldots, m$ and $n \geq N$,
  we may assume that $x \neq \alpha_{i}$. Fix $x \in [a, b]$, then $x \in (\alpha_{i}, \alpha_{i + 1})$ for some fixed $i$. Then there exists a $\mu_{x}$
  such that $f_{n}(\alpha_{i}) \leq \mu_{x}f_{n}(x) + (1 - \mu_{x})f_{n}(\alpha_{i - 1})$. That is
  $$\frac{f_{n}(\alpha_{i}) - (1 - \mu_{x})f_{n}(\alpha_{i - 1})}{\mu_{x}} \leq f_{n}(x).$$
  Therefore
  \begin{align*}
f(x) - f_{n}(x) &\leq f(x) - \frac{1}{\mu_{x}}f_{n}(\alpha_{i}) + \frac{1 - \mu_{x}}{\mu_{x}}f_{n}(\alpha_{i - 1})\\
&= \frac{1}{\mu_{x}}(f(x) - f_{n}(\alpha_{i})) + \left(1 - \frac{1}{\mu_{x}}\right)(f(x) - f_{n}(\alpha_{i - 1}))\\
&\leq \frac{1}{\mu_{x}}|f(x) - f_{n}(\alpha_{i})| + \left|1 - \frac{1}{\mu_{x}}\right||f(x) - f_{n}(\alpha_{i - 1})|\\
&\leq \frac{1}{\mu_{x}}\frac{\varepsilon}{5} + \left|1 - \frac{1}{\mu_{x}}\right|\frac{\varepsilon}{5}
\end{align*}
  where the last inequality is for $n \geq N$ and is by the same reasoning as in the $f_{n}(x) - f(x) < 2\varepsilon/5$ case. Since $x \in (\alpha_{i}, \alpha_{i + 1})$,
  \begin{align*}
\frac{1}{\mu_{x}} = \frac{x - \alpha_{i - 1}}{\alpha_{i} - \alpha_{i - 1}} > 1
\end{align*}
  and
  \begin{align*}
\left|\frac{1}{\mu_{x}}\right| \leq \left|\frac{\alpha_{i + 1} - \alpha_{i - 1}}{\alpha_{i} - \alpha_{i - 1}}\right| \leq \frac{|\alpha_{i + 1} - \alpha_{i}| + |\alpha_{i} - \alpha_{i - 1}|}{\alpha_{i} - \alpha_{i - 1}} = 1 + \left|\frac{\alpha_{i + 1} - \alpha_{i}}{\alpha_{i} - \alpha_{i - 1}}\right| < 2.
\end{align*}
  Therefore, we have
  \begin{align*}
\frac{1}{\mu_{x}}\frac{\varepsilon}{5} + \left|1 - \frac{1}{\mu_{x}}\right|\frac{\varepsilon}{5} = \left(\frac{2}{\mu_{x}} - 1\right)\frac{\varepsilon}{5} \leq \frac{3\varepsilon}{5}.
\end{align*}
  That is, we have found an $N$ (independent of $x$) such that for $n \geq N$,
  $f(x) - f_{n}(x) \leq 3\varepsilon/5$. Therefore $f_{n} \rightarrow f$ uniformly.","['proof-verification', 'real-analysis', 'analysis']"
473421,Cover of n-simplex with balls.,"Consider a $n$-simplex. For each edge $(i,j)$, consider a $n$-ball, such that vertices $i$ and $j$ are antipodal on this ball. Is the simplex covered by the union of these balls? Thank you.",['geometry']
473431,Why does the volume of a hypersphere decrease in higher dimensions? [duplicate],"This question already has answers here : Why does the volume of the unit sphere go to zero? (7 answers) Closed 10 years ago . First let us define an $n$-ball as the euclidean sphere in $\mathbb{R}^n$ including its interior and its surface where $n$ refers to the number of coordinates needed to describe the object (the geometer's notation), NOT the topologist's notation which refers to the dimension of the manifold. All $n$-balls considered here are of radius 1 centered at the origin. So an $n$-ball is the set of points $$\{x=(x_1,x_2,...,x_n)\in \mathbb{R}^n : \sum_{i=1}^n x_i^2 \leq 1\}.$$ It is well known that the volume of the unit $n$-ball is given by $$V(n)=\frac{\pi^{n/2}}{\Gamma(\frac{n}{2}+1)}$$ and before anyone points it out, we will consider all volumes to be unit-less so that they can be compared with each other. So for example $$\pi=V(2)<V(3)=\frac{4}{3}\pi.$$ Now, my question is why does $V(n)\rightarrow 0$ as $n\rightarrow\infty$? This behavior is independent of the radius. Depending on the radius, $V(n)$ may (or may not) increase at first, hit a peak at some $n$, and then monotonically decrease and converge to zero. Considering $n\in\mathbb{N}$ to take on only discrete values, for the unit $n$-ball, the max volume is achieved at $n=5$. I have read all I could find (here/wikipedia and elsewhere) and I do see that the $n$-ball occupies a smaller and smaller portion of the circumscribing cube $[-1,1]^n$ and I have seen the arguments that the diameter should be used as the fundamental quantity instead of the radius. This way, the volume monotonically decreases to zero for all $n$ at least for the unit ball. I also see the analytic reason why the function converges to zero. The gamma function in the denominator grows much faster than the numerator and eventually the whole fraction converges to zero even if the radius is a googol. But my question is, intuitively speaking (as if intuition is a good guide in higher dimensions), $V(n)$ should be monotonically increasing or at the very least non-decreasing. The way I see it, a 2-ball is contained in a 3-ball and a 2-ball can be rotated in $\mathbb{R}^3$ to create a 3-ball. Similarly, you can rotate any $(n-1)$-ball in $\mathbb{R}^n$ around the appropriate axis to create an $n$-ball. I know that any $(n-1)$-ball in $\mathbb{R}^n$ has Lebesgue measure zero but inside any $n$-ball, an $(n-1)$-ball can be rotated around any of the $n$ axes so $V(n)$ should be larger than $V(n-1)$. This specific ""argument"" hasn't been addressed on any of the previous questions that I could find. Any geometric interpretation of what's happening? Bonus points for something intuitive and/or 1-2-3 dimensional examples to show me the fallacy of my argument. Thanks! Addendum: I have seen this thread (and even this one and many others on stack exchange and math overflow) and like I said, they don't address my argument presented in this question. They do mention other arguments such as comparison with the circumscribing cube or analytically looking at fraction to see why it goes to zero. But those I already know...namely by reading these very threads.","['differential-geometry', 'geometry', 'multivariable-calculus', 'real-analysis']"
473432,positive definite and transpose,"When a matrix A has m rows and n columns (m>n), explain why $AA^{T}$ can't be positive definite. For the same matrix A, is $A^{T}A$ always
  positive definite? If so, explain. If not, what is the condition for A
  so that $A^{T}A$ is positive definite? Now $A^{T}$ is the transpose of A. This means the columns of $A^{T}$ are formed with the corresponding rows of A. Positive definite means that $x^{T}Ax$ >0 for all$x\neq 0$. Also with square symmetric matrices, the quadratic form $x^{T}Ax$ is positive definite if and only if the eigenvalues of A are all positive. But how does this show that $AA^{T}$ is not positive definite?",['matrices']
473434,Is it $\sigma$-ring?,"Is it true that if a (not empty) class of sets is closed under the symmetric differences ($A\Delta B:=(A-B)\cup(B-A)$) and countable intersections, then it is a $\sigma$-ring? I proved that ring. I have problem with the countable infinite union. Proof. $E\cup F=(E\Delta F)\Delta(E\cap F)$, and $E-F=E\Delta(E\cap F)$. So a ring. $\blacksquare$ I don't know how to generalize the first identity.",['elementary-set-theory']
473439,About a particular polynomial function,"Let $f:\mathbb{Z}\times\mathbb{Z}\to \mathbb{R}$ a function such that $x\mapsto f(x,a)$ and $x\mapsto f(a,x)$ are both polynomial functions. Show that if the degree of the two polynomials above is always $\le N$, $f$ can be written as a polynomial $P(x, y)$.","['functions', 'polynomials']"
473443,How to integrate this differential form on the boundary of the cube,"The setup. Assume $u = u_1+iu_2: \mathbb{R}^3 \to \mathbb{C}$ and we have the differential 1-forms $$ \star\xi=-x_2 dx_3 + x_3 dx_2 $$ and $$ u \times du = \sum_{i=1}^3 (u \times \partial_i u) dx_i = \sum_{i=1}^3 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.  $$ Assume further that $\Omega_n^3=[-\pi n, \pi n]^3$ which is a 3D cube. The problem. I want to integrate $(u \times du) \wedge \star \xi$ on the boundary of $\Omega_n^3$ to obtain $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = n\pi \sum_{i=2}^N \int_{C_i} u_2\partial_1 u_1 - u_1\partial_1 u_2 $$ where $$ C_2=[-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace \times [-\pi n, \pi n]$$ $$ C_3=[-\pi n, \pi n] \times [-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace. $$ This result is stated in this paper on page 55. For the definition of $\top$ see below. What I tried. As I understand it from this paper on page 70, we have $$ (\star\xi)_\top = x_3 dx_2 $$ and $$ (u \times du)_\top = \sum_{i=1}^2 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.$$ So I compute $$ (u \times du)_\top \wedge (\star \xi)_\top = (u_1 \partial_1 u_2 - u_2 \partial_1 u_1) x_3 dx_1 \wedge dx_2$$ and so $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = \frac{1}{2} \int_{\partial \Omega_n^3} (u_2 \partial_1 u_1 - u_1 \partial_1 u_2) x_3 dx_1 \wedge dx_2 $$ The question. Can anyone help me to proceed from here? I don't have any clue on how to integrate a wedge-product. EDIT: I'm terribly sorry, but I forgot to mention that $u$ is $\pi n$ periodic in every direction, i.e. it is the same on opposing faces of the torus.","['exterior-algebra', 'partial-differential-equations', 'differential-geometry', 'hodge-theory']"
473458,Why do all solutions to this equation have the same form?,"In this paper on page 45, the authors state that Let's assume we know that $$ w \times dw = d\varphi + \sum_{j=1}^3\alpha_jdx_j, \tag{1}$$ where $\varphi \in H^1(\mathbb{R}^3, \mathbb{R})$, $\alpha_j$ are real numbers and $\vert w \vert=1$. One then checks that $$ w(x)= \exp i \left(\varphi(x)+\sum_{j=1}^3 \alpha_j x_j + \theta\right). \tag{2}$$ for some $\theta \in \mathbb{R}$. Here $$w \times dw= \sum_{i=1}^3 (w_1 \partial_i w_2 - w_2 \partial_i w_1) dx_i$$ for $$w=w_1 +i w_2 : \mathbb{R}^3 \to \mathbb{C}.$$ I do not understand this statement. In fact, one can easily check that $w$ from (2) satisfies equation (1). But why does every $w$ that satisfies equation (1) have the form (2)? Any hint would be much appreciated!","['differential-forms', 'partial-differential-equations', 'differential-geometry']"
473470,what is name of this numerical scheme for ode?,"Let's have system of ODEs
$$
\dot x(t) = A(t)x(t)
$$ I came up with this numerical scheme:
$$
x_{n+1} = e^{\frac{h}{2}A(t_{n+1})}e^{\frac{h}{2}A(t_n)}x_n
$$
where $h$ is time step, $t_n = nh$ and $x_n$ is approximate value of $x(t_n)$. It comes from idea that at each time $t_n$ I freeze time in matrix $A$ and move along solution of $\dot x(t) = A(t_n)x(t)$. From this I get scheme:
$$
x_{n+1} = e^{hA(t_n)}x_n.
$$
To make it time reversible I modified it to the form already mentioned. There has to be a theory of this kind of schemes so I would like to know its name so I can search for literature a find out more about these schemes.","['ordinary-differential-equations', 'reference-request', 'numerical-methods']"
473477,A basic question on symmetry of metric space,"In the metric space definiton, the second condition for a metric i.e. symmetry (d(p,q)=d(q,p)) is present. But, I have not seen any example where this condition has been used. Can anyone give any such example Actually, in the analysis book of Rudin, all the theorems can be proved without using this property. I have not found any case where this property has been used. If anyone has any knowledge please share. What kind of results can't be proved using this property.","['metric-spaces', 'real-analysis']"
473481,General formula needed for this product rule expression (differential operator),"Let $D_i^t$, $D_i^0$ for $i=1,\dots,n$ be differential operators. (For example $D_1^t = D_x^t$, $D_2^t = D_y^t,\dots$, where $x$, $y$ are the coordinates). Suppose I am given the identity
$${D}_a^t (F_t u) = \sum_{j=1}^n F_t({D}_j^0 u){D}_a^t\varphi_j$$
where $\varphi_j$ are smooth functions and $F_t$ is some nice map. So
$$
D^t_bD^t_a(F_t u) = \sum_j D^t_b\left(F_t({D}_j^0 u)\right){D}_a^t\varphi_j+\sum_j F_t({D}_j^0 u)D^t_b{D}_a^t\varphi_j
$$
and because
$${D}_b^t (F_t (D_j^0u)) = \sum_{k=1}^n F_t({D}_k^0 D_j^0u){D}_b^t\varphi_k,$$ we have
$$D^t_bD^t_a(F_t u) =  \sum_{j,k=1}^n F_t({D}_k^0 D_j^0u){D}_b^t\varphi_k+\sum_j F_t({D}_j^0 u)D^t_b{D}_a^t\varphi_j
.$$
My question is how do I generalise this and obtain a rule for
$$D^t_{\alpha} (F_t u)$$ where
$\alpha$ is a multiindex of order $n$ (or order $m$)? My intention is to put the derivatives on $u$ and put the $F_t$ outside, like I demonstrated above. Can anyone help me with getting the formula for this? It's really tedious to write out multiple derivatives so it's hard to tell for me.","['sobolev-spaces', 'calculus']"
473483,Inclusion-Exclusion principle problem,"We need to calculate the number of $r$-sized subsets of the set $\{1,\dots,n\}$ that don't contain any consecutive numbers. We spent about 2 days on this...we know it's about the inclusion exclusion principle, and we have found something that works sometimes..but it doesn't cut it: $$\binom n r$$ + This is a link to a sum we thought would work , 
any leads will be appreciated. Some examples:
For $n=4$, $r=3$, there are no valid groups. For $n=4$, $r=2$ there are $3$ valid groups. For $n=5$, $r=3$ there is $1$ valid group.","['inclusion-exclusion', 'discrete-mathematics', 'combinatorics']"
473501,"Are compact spaces characterized by ""closed maps to Hausdorff spaces""?","It is well known that any continuous map from a compact space to a Hausdorff space must be a closed map. Does this fact characterize compactness? That is, if for a space $X$, every continuous map to any Hausdorff space is closed, does it imply that $X$ is compact? My guess is no (especially since this is NOT a common result), but I can't find a counterexample.","['general-topology', 'examples-counterexamples', 'closed-map', 'compactness']"
473502,How to Find Maximal Abelian Subgroups?,"I am studying some groups (they are infinite, finitely represented, nilpotent) and am trying to find their maximal abelian subgroups. Is there any standard approach to do so? Can anyone recommend any reference on this topic? For example, for the Discrete Heisenberg Group $\langle x,y\;\mid\; [x,[x,y]]=[y,[x,y]]=1\rangle $, how to find its maximal abelian subgroups?","['reference-request', 'group-theory', 'abstract-algebra']"
473532,Schwartz Class Functions on Integers,"On $\mathbb{R}$, we define the Schwartz class functions as infinitely differentiable functions such that $$ \lim\limits_{|x|\to \infty} | x^{m}f^{(n)}(x) | = 0 $$ for all $m, n \in \mathbb{N}$ and $f^{(n)}$ denotes the $n^{th}$ derivative of $f$. However, I was asked to define Schwartz class on integers, and I came up with the following: $$ \mathcal{S}(\mathbb{Z}) = \{ f : \mathbb{Z} \to \mathbb{C} \;\; | \;\; \lim\limits_{|n| \to \infty} n^{k}f(n) = 0 \;\; \forall\,\, k \in \mathbb{N} \}$$ The first examples that come to my mind are the restrictions of Schwartz functions on $\mathbb{R}$ to $\mathbb{Z}$. For example, $f(n) = e^{-n^{2}}$ being the restriction of the Gaussian function. I was wondering if the converse is true. That is, given a function in $\mathcal{S}(\mathbb{Z})$, can it be extended to a function in $\mathcal{S}(\mathbb{R})$? I was thinking that we could smoothly interpolate the function in between the integers, where it is already defined. The question remains about the rapid decay of this function. However, since original function goes to zero rather faster, I expect this to go to zero fast enough as well, since the slopes cannot change erratically in this case. So, is the statement true? And if so, what is the justification?",['real-analysis']
473535,Why does this limit exist $x^{x}$,"I was wondering what is the value of $\lim\limits_{x\to 0+} x^{x}$. Assuming that the limit exists, I could show using the usual logarithm techniques that the limit is $1$. However, I am not able to show that the limit exists. Could some one help on that? EDIT: It would be so nice if we could do it without l'Hopital...","['real-analysis', 'limits']"
473551,Logic: what are the cardinalities of the following sets?,"Let $X$ $\subseteq$ $\mathcal P \left({\mathbb{N}}\right)$. Determine the cardinalities of the following sets: $X = \{ A \subseteq \mathbb{N} |$ for every $B\subseteq\mathbb{N}$: $A\cap B=\emptyset$ or $A\cap B=A$ $\}$ $X = \{ A \subseteq \mathbb{N} |$ both $A$ and $\mathbb{N}-A$ are infinite$\}$ $X = \{ A \subseteq \mathbb{N} |$ for every ascending sequence $(a_n)_{n\in\mathbb{N}} \in \mathbb{N}$ there is an $a_n \in A$ with $n \in \mathbb{N}$$\}$ For the first one, I think that $|X|={|\mathbb{N}|}$ (because every $A$ consists of just one natural number). My guess for the second one would be $|X|={|\mathbb{N}|}$, because every $A$ would be of the form $\mathbb{N}-B$ with $B$ some infinite set. For the third one I have actually no idea. Edit The cardinality of the first set is $\mathbb{N}$ and the second set is $2^{\mathbb{N}}$","['logic', 'elementary-set-theory']"
473563,"What is the ""reverse"" of the cartesian product?","Suppose $A = \{a_1,a_2 \}$ and $B = \{b_1,b_2 \}$. Then $A \times B = \{(a_1,b_1), (a_1,b_2), (a_2,b_1), (a_2,b_2) \}$. What is the ""reverse"" of this operation? In particular, what would $A \div B$ be? The motivation for this question is from relational algebra. Consider the following two tables: $$\text{Table A}: \{(s_1,p_1), (s_2,p_1), (s_1,p_2), (s_3,p_1), (s_5,p_3) \}$$ $$\text{Table B}: \{p_1,p_2\}$$ Then $$A \div B = \{s_1 \}$$ In other words, we look at the x-coordinate which has both $p_1$ and $p_2$ as y-coordinates.",['elementary-set-theory']
473595,Characterization of integers which has a $2$-adic square root,"Does anyone know an ""elementary"" proof of the following theorem? Let $k \neq 0$ be a rational integer. Then $k$ admits a square root in $\mathbb{Z}_2$ if $k = 4^a (8b+1)$ for some $a \in \mathbb{N}$, $b \in \mathbb{Z}$. About $p$-adic numbers I don't know anything more sophisticated than Hensel lemma. Thank you!","['p-adic-number-theory', 'reference-request', 'number-theory']"
473599,uniform convergence over a countable union of sets,"I am working a problem on this book which asks to prove or disprove that if $f_n \rightarrow f$ uniformly on $E_1, E_2, E_3, \dots,$ then $f_n \rightarrow f$ uniformly on $\cup_{n=1}^\infty E_n$. Two ideas come to mind: 
1) If $E_n$ is decreasing, then surely the above statement holds. 
2) If a finite union was put in place of the countable union, i.e. $\cup_{n=1}^k E_n$ then the proof for uniform convergence would be straightforward seeing that we can take the maximum of a set with a finite number of elements. The second idea gives me the intuition that the statement above  is not necessarily true. However I am finding it difficult to find counterexamples. I know that $f_n(x)=x^n$ is not uniformly convergent on $[0,1]$ but that it is uniformly convergent on $[0,\sigma]$ where $0\leq\sigma<1$. I cannot think of sets whose countable union is $[0,1]$, unfortunately. Any hints on how to go about constructing one, if possible? Anyone has thoughts about how I should proceed?","['uniform-convergence', 'sequences-and-series', 'real-analysis', 'analysis']"
473601,Evaluating $\int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} dx $ using contour integration,"It was recommended to me that I evaluate $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} \ dx $$ by integrating $ \displaystyle f(z) = \frac{\log^{2}(1+z^{2})}{1+z^{2}}$around a semicircle that has its diameter along the line $ z= e^{i \pi /4}t, t \in \mathbb{R}$. Using the principal branch of the logarithm, there are branch cuts on the imaginary axis from $i$ to $i \infty$ and from $-i$ to $-i  \infty$. Deforming the contour around branch cut in the upper half-plane I get $$ e^{ \frac{i \pi }{4}} \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt   + i \int^{1}_{\infty} \frac{\left(\log (t^{2}-1) + \pi i\right)^{2}}{1-t^{2}} \ dt +  i \int_{1}^{\infty} \frac{\left(\log (t^{2}-1) - \pi i \right)^{2}}{1-t^{2}}  \ dt = 0 $$ which implies $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt = -4 \pi e^{- i \pi /4}  \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt.$$ But $ \displaystyle \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt$  does not converge. What's going on here? EDIT : The issue is the indentation around the branch point at $z=i$. It's contribution doesn't vanish (nor is it finite) in the limit. If you integrate $ \displaystyle f(z) = \frac{\log^{2}(1+iz^{2})}{1+iz^{2}} $ around a semicircular contour that includes the real axis, you run into a similar issue with the branch point at $z=e^{i \pi/4}$. I have not been able to come up with another approach that would make the evaluation less difficult.","['complex-analysis', 'contour-integration']"
473633,T4 and first countable topology that is non metrizable,Does anyone know any example of such topology?,"['general-topology', 'first-countable', 'examples-counterexamples']"
473664,Combinatorial proof for an identity about Stirling cyclic numbers,"Solving through Lovász' Combinatorial Problems and Exercises I found an exercise asking me to prove two identities: $$ \sum_{k = 0}^n {n \brace k} (x)_n = x^n $$
$$ \sum_{k = 0}^n \left[ n \atop k \right] x^k = x^{(n)}$$ (Notation note: I'm using Pochhamer symbols , brackety ones are cyclic Stirling numbers and curly ones are partition Stirling numbers ) First one yields itself to a combinatorial proof, basically a combinatorial interpretation of the fact that every function can be ''transformed'' into a surjection if we restrict its codomain. I was able to prove second one using generating functions, but I was unable to find a combinatorial proof. Due to obvious analogies between two identities (writing powers like a sum of falling factorials/ writing rising factorials like a sum of powers) I'm curious is there a combinatorial proof to the second identity?","['stirling-numbers', 'combinatorics']"
473678,MOOCs for college-level discrete math?,"Specifically I am looking for short lectures (and quizzes) on specific topics. (like Khan Academy offers) Topics I am learning about include; Intro logic-theory + set-theory Notation, negation, simplification, result of set operations) Relations, functions Intro proofs By contradiction, induction, well-ordering Intro graph theory Graph coloring (chromatic numbers), Eulerian paths, Eulerian circuit, Hamiltonian paths, Minimal spanning trees (Prim's and Kruskal's algorithms), shortest path computation Intro combinatorics Permutations, combinations, inclusion-exclusion, binomial theorem","['discrete-mathematics', 'education', 'self-learning', 'online-resources', 'learning']"
