question_id,title,body,tags
456355,Convergence in metric and in measure,"Let $\mu$ be a finite measure on $(X, A)$, with the semimetric 
$$ d(f,g) = \int \frac{|f-g|}{1+ |f-g|}d\mu$$
on all real-valued, A-measurable functions.
 Show that $$\lim_n d(f_n, f) = 0$$ holds iff 
$(f_n)$ converges to $f$ in measure. I know that convergence in mean implies convergence in measure but 
$ \int \frac{|f-g|}{1+ |f-g|}d\mu \leq   \int {|f-g|}d\mu $
and also 
$ \mu(\{x\in X\ : |f_n(x) - f(x) > \epsilon\}) \leq   \int {|f-g|}d\mu $. 
So I don't know what to do.",['measure-theory']
456367,How to find $\sum n^3$ if $\sum n^2$ is given,Problem : Find $\sum_{j=1}^n j^3$ if $\sum_{j=1}^n j^2 =2870$ Can we use the following method : $\sum_{j=1}^n j^2 = \frac{n(n+1)(2n+1)}{6}$ = 2870.. ( As sum of the square of first n natural number is $\frac{n(n+1)(2n+1)}{6}$) But how do we proceed from here to get the result?,"['summation', 'sequences-and-series', 'algebra-precalculus']"
456371,"Suppose $T^2$ is diagonalizable and $\ker{T}=\{0\}$, and every eigenvalue of $T^2$ is nonnegative. Show that $T$ is diagonalizable.","Suppose $T^2$ is diagonalizable and $\ker{T}=\{0\}$, and every eigenvalue of $T^2$ is nonnegative. Show that $T$ is diagonalizable. Of course $T$ is an operator on $V$.
It seems to me that if I take a basis of eigenvectors of $T^2$ I can define:
$$S(e_j)=\sqrt{\lambda_j}e_j$$ So by definition $S$ is diagonalizable since every eigenvector of $T^2$ is an eigenvector of $S$ and so there's a basis of eigenvectors of $S$, and obviously $S^2=T^2$. I want to say that $T$ has to be of this form (perhaps $T(e_j)=\pm\sqrt{\lambda_j}e_j$), and therefore has to be diagonalizable. I feel that this explanation is flawed somehow, and obviously strange since I didn't use the given about $\ker{T}$. Many thanks! EdiT: Okay, I found a different proof(by someone else) that uses the minimal polynomial and @julien 's algebraic note. I'll give it a little more thought but I think I got this down. Thank you.","['linear-algebra', 'operator-theory']"
456377,Proof that $A \subseteq B \Leftrightarrow A \cup B = B$,I want to proof that: $A \subseteq B  \Leftrightarrow  A \cup B = B$ At the moment I have no idea on how to start. Please give me a hint. Thx in advance!,['elementary-set-theory']
456393,Convergence in measure of products,"Let $\mu$ be a measure on $(X,\mathcal A)$ and let $f, f_1, f_2,\dots$ and $g, g_1, g_2,\dots $be real valued $\mathcal A$- measureable functions on $X$. Show that if $\mu$ is finite, $(f_n)$ convergence to $f$ in measure and $(g_n)$ to $g$ in measure, then $(f_ng_n)$ convergence to $fg$.
Can the assumption that $\mu$ is finite be omitted? Intuitively it feels like one could look at the measure of the union where the convergence does not hold, for $f_n$ and $g_n$. Is that correct or what should I do?
And what about the finiteness of $\mu$?","['measure-theory', 'convergence-divergence', 'examples-counterexamples']"
456398,A conjecture about vector space,"Let $V$ be a $(r+1)$-dimensional vector space, and $p$ be a positive integer and $1\leq p\leq r-1$. Let
$$X=\{v_1,\cdots,v_{2r+1-p}\}\subseteq V$$
be a finite set containing $(2r+1-p)$ different vectors, and all these vectors are linearly-independent to each other $\{u,v\}$ is a linearly-independent set for any $u,v\in X$ such that $u\neq v$. Moreover, any (2s+2−p) vectors in X are not in some (s+1)-dimensional subspaces for any set of $(2s+2−p)$ vectors in $X$ there exists no $(s+1)$-dimensional subspace that contains said set, where $s=p,p+1,\cdots,r-1$. Prove or disprove the following conjecture : 
$X$ can be divided into two non-intersecting non-empty subsets
$$X=X_1\cup X_2$$
such that $X_1$ consists of $(r+1)$ linearly-independent vectors and $X_2$ consists of $(r-p)$ linearly-independent vectors. P.S. I am a college lecturer in Macau, and this conjecture is based on some discussions with my colleagues. We think this problem can be set for some math competitions for college students, however we have not reached conclusion regarding this conjecture. Therefore I post it out and invite your attention. My description of the conjecture using English may not look professional, and I welcome your editing to make it more sound. Thank you very much.","['vector-spaces', 'linear-algebra']"
456408,What's the importance of the trig angle formulas?,"What's the importance of the trig angle formulas, like the sum and difference formulas, the double angle formula, and the half angle formula? I understand that they help us calculate some trig ratios without the aid of a calculator, but I guess I don't really understand the point of learning them since they're not the same algorithms used by calculators to calculate trig ratios (most of them use a Taylor series, right?). Wouldn't our time be better spent learning the calculator's algorithms so that we can calculate the ratio at any arbitrary angle? Thanks!",['trigonometry']
456419,"Why are there so many groups (up to isomorphism) of order $p^n$ for $n>2$, especially when compared to groups of similar sized order?","While bounds on the number of isomorphism classes of groups of order $p^n$ where $p$ is prime have been known for quite a while (such as the work of Higman$^{[1]}$  and Sims$^{[2]}$) which give us the bounds for $f(n,p)$ (which returns the number of isomorphism classes of groups of order $p^n$) as follows: $f(n,p) = p^{An^3} \operatorname{where} A(n,p) = \frac{2}{27} + O(n^{-1/3})$ However, while this tells us that for a fixed $p$ the value of $f(n,p)$ grows very rapidly with n, when I've been reading through the papers I don't think I have enough knowledge to understand why exactly they should grow this rapidly - for example, the number of abelian groups of order $p^n$ is simply the number of partitions of $n$, and while this number grows quite rapidly with n, this number is tiny in comparinson to the number of non-abelian groups of the same exponent. Therefore, would it be possible for someone to try and explain to me some reasons for why there are so many groups of order $p^n$ for $n>2$ (as it is fairly straightforward to categorize such groups for $n=1$ and $2$), and also why there are so many such $p$-groups when compared to groups of similar sized order? (I suspect these two questions are closely linked in some respects, which is why I ask them both, although answers on one or the other are equally appreciated) For those who would like them, the references to the papers of Higman and Sims are below: $[1]$ - Proc. London Math. Soc. (1960) s3-10 (1): 24-30. doi: 10.1112/plms/s3-10.1.24 $[2]$ - Proc. London Math. Soc. (1965) s3-15 (1): 151-166. doi: 10.1112/plms/s3-15.1.151","['finite-groups', 'group-theory', 'p-groups']"
456424,Hard integral that standard CAS get totally wrong,"How to solve the following integral: $$\int_{-\infty }^{\infty }\exp \left ( i\left ( ax^3+bx^2 \right ) \right )dx$$ Standard CAS seem to get it totally wrong, see: http://www.walkingrandomly.com/?p=5031 So what is the right ansatz and solution? EDIT There seems to be a problem with the way this question is posed... which I quite frankly don't get. To clarify I posted this follow-up question: In which senses can an integral exist?","['integration', 'complex-analysis']"
456430,Self-teaching myself math from pre-calc and beyond.,"Going to be starting grade 12 (pre-calculus) shortly and looking to get ahead. I would like to try some more rigorous stuff on my own and have a couple questions. Ideally I would like to be prepared for the math I will face in post secondary. How can I get the most out of a math book, without a teacher? Does summarizing chapters help? Is it realistic to try and self teach myself up to differential equations? What else should I be aware of when trying to self teach? If anyone has good book recommendations from pre-calc -> differential equations I would enjoy suggestions. -Thanks","['algebra-precalculus', 'education', 'self-learning', 'reference-request', 'soft-question']"
456437,Prove: $\int_{-\infty}^{\infty} \frac{\tan^{-1}e^{-\pi x}}{\cosh\frac{3x\zeta(2)}{20}} dx = 10$,"I want to solve the following integral: $$\int_{-\infty}^{\infty} \frac{\tan^{-1}e^{-\pi x}}{\cosh\frac{3x\zeta(2)}{20}} dx = 10$$ Have not tried it yet, but it may be tough. All I know is that  ζ(2) is  π²/6. I don't know what to do. Any help would be appreciated. Thanks!","['improper-integrals', 'calculus', 'integration']"
456442,Probability and Statistics 2,"John invites 12 friends to a dinner party, half of which are men. Exactly one man and one woman are bringing desserts. If one person from this group is selected at random, what is the probability that it is a woman, OR a man who is not bringing a dessert? The above question is a GRE practice question and the answer is 11/12.","['statistics', 'probability', 'gre-exam']"
456449,How do I solve the following recurrence?,"Solve the recurrence
  $$X_n =\begin{cases} n & 0 \leq n < m\\
X_{n-m} + 1 & n \geq m.\end{cases}$$ So I've started with several base cases, but since the answer depends on $n$'s relation to $m$, doesn't that mean my base cases have to propose both an $n$ value and an $m$ value? I know the answer is $$\left\lfloor\frac{n}{m}\right\rfloor+(n\bmod m),$$
But I don't know how to get to the answer.
I'm having a really hard time marrying the recurrence material to the floor/ceiling material to the modular arithmetic material. Sorry about the formatting, but if anyone can help, I would really appreciate it!","['recurrence-relations', 'discrete-mathematics']"
456452,Integral vector calculus (by parts),"This is taken from the bottom of page 37 of Griffith's Introduction to Electrodynamics Using integration by parts, $\nabla \cdot (f {\bf A})$ = $ f (\nabla \cdot {\bf A}) + {\bf A} \cdot (\nabla f)$, and therefore, $\int \nabla \cdot (f {\bf A})$ = $ \int f (\nabla \cdot {\bf A}) + \int {\bf A} \cdot (\nabla f)$ The divergence theorem states that $\int_V (\nabla \cdot {\bf A}) d \tau $ = $ \oint_S {\bf A} \cdot dA$. In the textbook, by invoking the divergence theorem, the obtained result was that $\int \nabla \cdot (f {\bf A}) d \tau $ = $\int f(\nabla \cdot {\bf A}) d \tau $ + $\int {\bf A}\cdot (\nabla f) d \tau $ = $\oint f {\bf A} \cdot d{\bf a}$. My confusion begins when substituting the divergence theorem into the equation in the 2nd line. I think that $\int \nabla \cdot (f {\bf A})$ = $ \oint_S {\bf A} \cdot dA$ + $\int {\bf A} \cdot (\nabla f)$, so I am not sure what happens to the $\int {\bf A} \cdot (\nabla f)$  in the textbook's result. Also, any clarification on when exactly to use the $v, s, c$ and all the other integral subscripts are to be used would be appreciated. It's easy to know when the questions asks for a specific volume integral or surface integral etc, but is it possible to tell just from the equations given? With the 2 questions that follow after the example in the book, I am having trouble understanding their solutions. The question is given with its solution here where I am to use product rules and integral theorems to prove equality of the integrals. However, like my problem in the example, I cannot seem to be able to follow when trying to substitute. Thanks.","['multivariable-calculus', 'vector-analysis']"
456453,generating function Homework Question 1,"This is a HW question I am asked to find a closed form generating function for $1,1,0,1,1,0,1,1,0....$
so then $f(x)=x^0+x^1+0x^2+x^3+x^4+0x^5+x^6+x^7+0x^8$ could use some hint or help.","['generating-functions', 'discrete-mathematics']"
456474,What is the difference between the least-upper bound property & cauchy completeness in the real line?,"The real numbers can be characteriesed in two ways: a) It is the unique ordered field with the least upper-bound property b) It is the unique ordered archimedean field in which all cauchy sequences converge Now both the least upper-bound property or the convergence of cauchy sequences can be taken as the idea of completeness. But why the difference? In a) we do not need to specify that it is archimedean, in b) we do. Is this because the completeness in a) is due to order, whereas in b) its due to a metric $d(a,b):=|a-b|$?","['general-topology', 'real-analysis']"
456483,Coin tosses and probability,"A fair coin is flipped 5 times. What is the probability of getting more heads than tails? Note: Since this is a GRE practice question, I want a method that can help me solve this problem in the fastest way possible. Of course, I can compute this probability directly by considering the cases of getting 5, 4, or 3 heads separately. However, this approach would be very time-consuming.",['probability']
456504,Advection Diffusion Equation on Semi-Infinite Domain,"Regarding the BVP $$u_t(x,t) - v\, u_x(x,t) = k\, u_{xx}(x,t),\qquad x\geq0$$ with BC $u_x(0, t)=0$ for $t\geq 0$ , and parameters $v,k>0$ , I have some questions. Does an expression for the Green's function in some relatively nice form exist? If so, what is it? There's the obvious change of variables to convert the above to the heat equation, but with non-standard boundary conditions. I could not think of any nice image singularity solution. We also have the problem of the domain being semi-infinite, making it difficult for there to be any series solutions. If such a solution exists, how would I derive such a Green's function? As another note, I would also be happy with a fundamental solution for the BC $u(0,t)=0$ . A related question is how does one go about solving the heat equation with moving boundary conditions.","['ordinary-differential-equations', 'partial-differential-equations']"
456506,In which senses can an integral exist?,I asked about the value of an integral here: Hard integral that standard CAS get totally wrong The question got downvoted and voted to close because I didn't understand (and wasn't able to answer) the following question: In which sense is the integral supposed to exist? So in what senses can integrals exist? What are the options here?,['integration']
456512,expected value in Poisson distribution [duplicate],"This question already has answers here : Poisson random variable with parameter $\lambda>0$ (2 answers) Closed 10 years ago . E(X) in Poisson Dist, \begin{align}
\mathrm{E}(X) &= \sum_{k=0}^{\infty} \frac{k \lambda^k e^{-\lambda}}{k!}= \\
&= e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^{k+1}}{k!}=\\
&= \lambda
\end{align} then, $\text{E}(X(X-1)) = \sum_{k=0}^{\infty} \frac{k(k-1) \lambda^{k(k-1)} e^{-\lambda}}{k(k-1)!}$ how can I simplify this ?",['statistics']
456531,"Prove that $xRy \longleftrightarrow 7|(2x+5y)$ for all $x,y\in Z$ is an equivalence relation","I'm trying to show that this relation is an equivalence relation.
$$xRy \longleftrightarrow  7|(2x+5y)  \text{ for all }  x,y\in Z$$
I need to show that $R$ is reflexive.  If I take every $x$ and $y$ are the same I can see that it's fine, how to write it in formal way? For the next conditions I need some advice. $(a,b) \in R \Rightarrow (b,a) \in R$, i.e., Symmetry $(a,b) \in R , (a,c) \in R \Rightarrow (a,c)\in R$, i.e. Transitivity Thanks!",['discrete-mathematics']
456532,Expected Sum of 30 sided die rolls,Roll a 30-sided die. Add up each consecutive outcome. Stop rolling when the sum >= 300. What's the most likely result of the sum?,['probability']
456552,Integrating 2-form,"In $\mathbb{R}^3$ I consider the compact 2-dimensional manifold
    $$
M=\left\{(x,y,z)\in\mathbb{R}^2: z=xy\right\}
$$
    which is orientated by the (global) map $\phi\colon\mathbb{R}^2\to\mathbb{R}^3, (x,y)\mapsto (x,y,xy)$.
    Furthermore a 2-form is given by
    $$
\omega:=3zdy\wedge dz+(x^2+y^2)dz\wedge dx+xzdx\wedge dy.
$$
    Consider
    $$
A:=\left\{(x,y,z)\in M: \lvert x\rvert\leq 1,\lvert y\rvert\leq 1\right\}
$$
    and my task now is to calculate the integral
    $$
\int_{A}\omega.
$$ First of all i calculated the pullback $\phi^{\star}\omega$, which is to my calculation
$$
\phi^{\star}\omega=x^2ydx\wedge dy-(x^2+y^2)dx\wedge y dx+xdy+3xydy\wedge ydx+xdy\\
=x^2ydx\wedge dy-(x^2+y^2)xdx\wedge dy-2xy^2dx\wedge dy\\
=(-x^3+x^2y-4xy^2)dx\wedge dy
$$ To my opinion it is $\phi^{-1}(A)=[-1,1]\times [-1,1]$. So if my calculations are correct I have to calculate the following integral:
$$
\int\limits_{[-1,1]\times [-1,1]}(-x^3+x^2y-4xy^2)dx\wedge dy
$$ 1.) Is this right?
2.) If yes, how can I calculate this? Greetings!","['differential-forms', 'manifolds', 'integration']"
456563,"Prove that $(a,b)R(c,d) \longleftrightarrow ad=bc $ is equivalence relation on $A=R^2-\{(0,0)\}$ [duplicate]","This question already has answers here : Equivalence Relation problem [duplicate] (3 answers) Closed 10 years ago . I am trying to prove that $$(a,b)R(c,d) \longleftrightarrow ad=bc $$ is equivalence relation on $$A=\mathbb{R}^2-\{(0,0)\}$$
$A$ is all points on the plane. If I want to show that is reflexivity so I need to take $a$ and $c$, set $(a,a)\in R$ and $(c,c)\in R$ how I can show that $a^2 = c^2$? how to show transitivity? Thanks!",['discrete-mathematics']
456581,Is there a discontinuous function on the plane having partial derivatives of all orders?,"If one requires simply the existence of partial derivatives of first order rather than all orders, then a standard example is the function $$ f(x,y) = \left\{\begin{array}{l l}
\frac{2xy}{x^2+y^2} & \quad \text{if $(x,y)\neq(0,0),$}\\
0                   & \quad \text{if $(x,y)=(0,0).$}
\end{array} \right.$$ However, this does not constitute an answer to my question since the partial derivative of $\frac{\partial f}{\partial x}$ with respect to $y$ does not exist at the origin. PS: This question rose out of my wonder as to whether, in the definition of a smooth function, continuity of partials is an essential requirement or not.","['multivariable-calculus', 'partial-derivative', 'examples-counterexamples', 'real-analysis']"
456585,Partially ordered set question,"R is relation over the set of functions continuous in $[0,1]$ that defined 
$$fRg \Longleftrightarrow f(x) \leq g(x) \rightarrow x\in [0,1]$$
I know that to prove it I need to show that if for all $a \in A$(the functions set) implies $(a,a)\in R \rightarrow$ Reflexivity for all $(a,b) \in R , (b,a) \in R \rightarrow a=b $ i.e. Anti - Symmetry if for all $(a,b) \in R $ and $(b,c) \in R \rightarrow (a,c)\in R $ Transitivity for reflexivity: $fRf \longleftrightarrow f(x)\leq f(x)$ $R$ reflexivity for anti symmetry $fRg ,gRf\longleftrightarrow f(x)\leq g(x) 	\wedge g(x)\leq f(x) \rightarrow f(x)=g(x) $  $R$ anti symmetry
what about transitivity? Thanks!",['discrete-mathematics']
456586,Show $f^*dx_i = \sum_{j=1}^l \frac{\partial f_i}{\partial y_j} dy_j = df_i$,"Guillemin and Pollack's Differential Topology Page 164: $U \subset \mathbb{R}^k$ and $V \subset \mathbb{R}^l$ be open subsets. Let $f: V \to U$ to smooth. Use $x_1, \dots, x_k$ for the standard coordinate functions on $\mathbb{R}^k$ and $y_1, \dots, y_l$ on $\mathbb{R}^l$ . Write $f = (f_1, \dots, f_k)$ , each $f_i$ being a smooth function on $V$ . The derivative $df_y$ at point $y \in V$ is represented by the matrix $$\frac{\partial f_i}{\partial y_j}(y),$$ and its transpose map $df_y^*$ is represented by the transpose matrix. Consequently, $$f^*dx_i  = \sum_{j=1}^l \frac{\partial f_i}{\partial y_j} dy_j = df_i.$$ My solution: For a smooth function $f$ , $df$ is linear. And $df^*$ is the adjoint of the map $df_*$ . Consider a tangent vector $Y \in T_yU$ such that $$Y = \sum_{j = 1}^l Y^j\frac{\partial}{\partial y^j}.$$ Then we have $$(f^*dx_i)(Y) = (f^*dx_i)\sum_{j = 1}^l Y^j\frac{\partial}{\partial y^j}.$$ $f^*$ is linear , $dx_i$ is linear, and the composition of linear function is linear. Hence $f^*dx_i$ is linear. So $$(f^*dx_i)\left(Y^1\frac{\partial}{\partial y^1} + \cdots + Y^l\frac{\partial}{\partial y^l}\right) = (f^*dx_i)\left(Y^1\frac{\partial}{\partial y^1}\right) + \cdots + (f^*dx_i)\left(Y^l\frac{\partial}{\partial y^l}\right).$$ By Commutativity of $Y^j$. : $$ Y^1(f^*dx_i)\left(\frac{\partial}{\partial y^1}\right) + \cdots + Y^l(f^*dx_i)\left(\frac{\partial}{\partial y^l}\right) = \sum_{j=1}^l Y^j (f^*dx_i)\left(\frac{\partial}{\partial y^j}\right).$$ Use the definition $$f^*\omega = \omega \circ f_*.$$ We have $$\sum_{j=1}^l Y^j (f^*dx_i)(\frac{\partial}{\partial y^j}) = \sum_{j=1}^l Y^j dx_i(f_*(\frac{\partial}{\partial y^j})).$$ Because $f$ maps from $V \subset \mathbb{R}^l$ to $U \subset \mathbb{R}^k$ , it can be written as $$f = (f_1, f_2, . . . f_k),$$ with each $f_i$ being a function of the $y_j \in V \subset \mathbb{R}^l$ . Consider and $g:U \to R$ sufficiently differentiable, then the vector field $f_*(\frac{\partial}{\partial y^j})$ on $U$ may be applied to $g$ : $$f_*(\frac{\partial}{\partial y^j})[g(x_1, x_2, . . . x_k)] = \frac{\partial}{\partial y^j}(g(f_1(y_1, . . . y_l), f_2(y_1, . . . y_l), . . . f_k(y_1, y_2, . . . , y_l))),$$ according to the definition $$(F_*X)(f) = X(f \circ F).$$ Hence, $$\frac{\partial}{\partial y^j}(g(f_1(y_1, . . . y_l), f_2(y_1, . . . y_l), . . . f_k(y_1, y_2, . . . , y_l))) = \frac{\partial}{\partial y^j}(g(x_1, \dots, x_k)).$$ Following Chain rule, $$\frac{\partial}{\partial y^j}(g(x_1, \dots, x_k)) = \frac{\partial g}{\partial x^1} \frac{\partial x^1}{\partial y^j} + \cdots + \frac{\partial g}{\partial x^k} \frac{\partial x^k}{\partial y^j} = \sum_{n = 1}^k \frac{\partial g}{\partial x_n} \frac{\partial f_n}{\partial y_j}.$$ That is $$f_*\left(\frac{\partial}{\partial y^j}\right)[g(x_1, x_2, . . . x_k)] = \sum_{n = 1}^k \frac{\partial g}{\partial x_n} \frac{\partial f_n}{\partial y_j}.$$ By commutativity of first-order derivative, $$\sum_{n = 1}^k \frac{\partial g}{\partial x_n} \frac{\partial f_n}{\partial y_j} =
\sum_{n = 1}^k \frac{\partial f_n}{\partial y_j} \frac{\partial g}{\partial x_n} .$$ Thus we see that the vector field $f_*\left(\frac{\partial}{\partial y^j}\right)$ satisfies $$f_*\left(\frac{\partial}{\partial y^j}\right) =  \sum_{n = 1}^k \frac{\partial f_n}{\partial y_j}\frac{\partial}{\partial x_n}.$$ So $$\sum_{j = 1}^lY^jdx_i(f_*(\frac{\partial}{\partial y^j})) = \sum_{j = 1}^lY^jdx_i\left(\sum_{n = 1}^k \frac{\partial f_n}{\partial y_j}\frac{\partial}{\partial x_n}\right).$$ As before, we use the fact that $dx_i$ is linear, and first-order derivative is commutative, $$\sum_{j = 1}^lY^jdx_i\left(\sum_{n = 1}^k \frac{\partial f_n}{\partial y_j}\frac{\partial}{\partial x_n}\right) 
= \sum_{j = 1}^lY^j\left(\sum_{n = 1}^k dx_i \frac{\partial}{\partial x_n}\frac{\partial f_n}{\partial y_j}\right).$$ Using $dx_i(\frac{\partial}{\partial x_n}) = \delta_{in}$ , $$\sum_{j = 1}^lY^j\left(\sum_{n = 1}^k dx_i \frac{\partial}{\partial x_n}\frac{\partial f_n}{\partial y_j}\right) 
= \sum_{j = 1}^lY^j\left(\frac{\partial f_i}{\partial y_j}\right)
= \sum_{j = 1}^l (dy_j Y)\left(\frac{\partial f_i}{\partial y_j}\right).$$ So, $$\sum_{j = 1}^l (dy_j Y)\left(\frac{\partial f_i}{\partial y_j}\right)
=\sum_{j = 1}^l\left(\frac{\partial f_i}{\partial y_j}\right) (dy_j Y).$$ According to Show that $d\phi = \sum \frac{\partial \phi}{\partial x_i}dx_i.$ We have $$df = \sum \frac{\partial f}{\partial y_i}dy_i.$$ So $$\sum_{j = 1}^l\left(\frac{\partial f_i}{\partial y_j}\right) (dy_j Y)
=df_i (Y).$$ Since this holds for any $Y \in T_yV$ , we have shown that $$f^*dx_i = \sum_{j = 1}^l \frac{\partial f_i}{\partial y_j}dy_j = df_i$$","['differential-topology', 'differential-geometry', 'solution-verification']"
456589,Proof of the principle of backwards induction,"I have difficulty in neatly writing down a proof for the following from Terence Tao's Analysis I , where $m{+\!+}$ is the successor function : Let $n$ be a natural number, and let $P(m)$ be a property pertaining to the natural numbers such that whenever $P(m{+\!+})$ is true, then $P(m)$ is true. Suppose that $P(n)$ is also true. Prove that $P(m)$ is true for all natural numbers $m\leq n$ ; this is know as the principle of backwards induction . (Hint: apply induction to the variable $n$ .) First of all, I am unsure about what the base case should look like. For the induction step, I understand that if we suppose inductively that $P(n)$ is true, that then for a natural number $a$ s.t. $a{+\!+}=n$ it holds that $P(a)$ is true, and then for a natural number $b$ s.t. $b{+\!+}=a$ it holds that $P(b)$ is true etc. Hence for all natural numbers $m\leq n$ , $P(m)$ is true. Could anyone please tell me what the base case should look like, and whether there is a neater way of writing down the induction step?","['induction', 'elementary-set-theory']"
456595,Prove: $\frac{1}{1^2} +\frac{1}{2^2} + \cdots + \frac{1}{n^2} + \cdots = \sum_{n=1}^\infty \frac{1}{n^2} < 2$ [duplicate],"This question already has answers here : Need to prove the sequence $a_n=1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots+\frac{1}{n^2}$ converges (8 answers) Closed 10 years ago . While I don't doubt that this question is covered somewhere else I can't seem to find it, or anything close enough to which I can springboard. I however am trying to prove $$\frac{1}{1^2} +\frac{1}{2^2}  + \cdots + \frac{1}{n^2} + \cdots = \sum_{n=1}^\infty \frac{1}{n^2} < 2$$ by induction. I have seen it many times and proved it before but can't remember what it was I did.  I see that for the first two terms $n = 1, n=2$ I get: for $n = 1$, $\frac{1}{1^2} = 1 < 2$
for $n = 2$, $\frac{1}{1^2} + \frac{1}{2^2} = \frac{5}{4} < 2$ Now I am stumped, I know I want to show this works for the $n+1$ term and am thinking, let the series $\sum_{n=1}^\infty \frac{1}{n^2} = A(n)$ Then look to show the series holds for $A(n+1)$ But $A(n+1) = A(n) + \frac{1}{(n+1)^2}$  But now what?  If I tried $A(n+1) - A(n) = \frac{1}{(n+1)^2}$ , but would have to show that this is less than $2 - A(n)$.  I am stuck. Thanks for your thoughts, Brian","['induction', 'sequences-and-series']"
456599,"Sequence of continuous, integrable functions that are not dominated","I am looking for a sequence of continuous functions ${f_n}: [0,1] \rightarrow [0,\infty]$ such that $\int f_n d\mu \rightarrow 0$, $f_n(x) \rightarrow 0$ for all $x$, but $f(x) = \sup f_n(x)$ is not in $L_1$. The ""rotating tower"" functions with growing heights seem to not converge to zero. A function that rises over reducing intervals, such as $f_n(x) = \sqrt{n} {\bf 1}_{[0,\frac{1}{n})}$ wouldn't satisfy the last condition… Would you have any suggestions on how I could find such functions?","['measure-theory', 'real-analysis']"
456603,Let $x>0$. Calculate $\lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds$,"Let $x>0$. Calculate: $$\lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds$$ for $x=1$ it is quite simple. Otherwise, I used the following contours: The left one when $x>1$ and the right one when $0<x<1$. Let us discuss the case $x>1$. The integral on $\Gamma_1$ is what we want. The integral on $\Gamma_3$ vanishes since: $$\bigg| \int_{\Gamma_3}f(s)\bigg|\leq \int_{\Gamma_3}|f(s)| \leq 2R \bigg|\frac{x^s}{s}\bigg| \leq 2R \frac{e^{\ln x \Re s}}{\sqrt{2}R}=\sqrt{2}e^
{-R\ln x} \rightarrow 0$$ But I have no idea what to do with $\Gamma_2$ and $\Gamma_4$.","['definite-integrals', 'integration', 'complex-analysis']"
456613,Does the map $f:\emptyset\longrightarrow \{0\}$ exist?,"What function $f$ maps in the following way:
$$f:\emptyset\longrightarrow \{0\}$$","['elementary-set-theory', 'functions']"
456632,field of rational functions of a projective variety equal to that of an affine variety,"Let $Y \subset \mathbb{P}^n$ be a projective variety and let $U_i$ be the open set $x_i \neq 0$. Let $\phi_i : U_i \rightarrow \mathbb{A}^n$ be the isomorphism of varieties, defined e.g. in Hartshorne p. 10, that takes a point $P=(a_0,\cdots,a_n) \in \mathbb{P}^n$ to $(a_0/a_i,\cdots,a_n/a_i) \in \mathbb{A}^n$. Define $Y_i$ to be the image of the closed set $U_i \cap Y$ under $\phi_i$. Then $Y_i$ is an affine variety of $\mathbb{A}^n$. Question: Hartshorne in the proof of Theorem 3.4(c), p. 18, says that $K(Y)=K(Y_i)$, where $K(\cdot)$ means field of rational functions (function field). Why is this true?",['algebraic-geometry']
456647,An estimate for $\ln(1+f(x))$ using Taylor expansion,"A crucial skill for every aspiring analyst (like myself) is confidence in estimation - knowing when, where, and how to use tools like Big-and-little-O to gain quick upper bounds.  I'm trying to push myself to get better at it, but I'm still a little hesitant sometimes.  Here's an example: I need to determine if the following series converges uniformly $$
\sum_{n=1}^\infty f_n(x)=\sum_{n=1}^\infty\frac{\ln\left(1+\frac{\sin^2(nx)}{n^2}\right)}{n}
$$ I'm pretty sure it does, and my reasoning is as follows: if $n>1$, $\sin^2(nx)/n^2<1$ for all $x\in\Bbb{R}$, and hence we can use the Taylor series for $\ln(1+z)$ about $z=0$ to obtain the following: $$
\left\vert\ln\left(1+\frac{\sin^2(nx)}{n^2}\right)\right\vert\leq\frac{1}{n^2}+\frac{C}{n^4}\tag{$\dagger$}
$$
where $C$ is a constant independent of $x$.  Thus, $$
\left|\,f_n(x)\right|\leq\frac{1}{n^3}+\frac{C}{n^5}
$$and since 
$$
\sum_{n=1}^\infty\left( \frac{1}{n^3}+\frac{1}{n^5}\right)<\infty,
$$the series converges uniformly. My question is: is $(\dagger)$ correct, and do I have the constant in the right place (or does it matter)?  I used the fact that $\ln(1+z)=z+O(z^2)$ to obtain $(\dagger)$.","['sequences-and-series', 'real-analysis', 'analysis']"
456651,Find all circles given two points and not the center,"This is probably pretty straight forward for you. I have two points on a circle, $(-4, 7)$ and $(-5, 0)$. Given these two points and the radius $5$, what are all the possible equations? My first idea was to solve the system $\sqrt{(-4-a)^2 + (7-b)^2} = 5\tag 1$ $\sqrt{(-5-a)^2 + b^2} = 5\tag 2$ Where $(a, b)$ is the center point. However, I don't get the correct answers. Maybe this question should be about how to solve the system. Thanks in advance! Edit: This is the formulation of the problem: Find all circles through the points $(-4, 7)$ and $(-5, 0)$ with a radius of $5$.","['geometry', 'algebraic-geometry']"
456678,"Minimal and Maximal terms in $A=\{1,2,3,4\}$ and $R$ relation on $\mathcal{P}(A)$","I have the set $A=\{1,2,3,4\}$ and my relation is on $\mathcal{P}(A)$ where $X\subseteq Y \wedge XRY$ I wrote $\mathcal{P}(A)$ and get $$\mathcal{P}(A) =\{(1,1),(2,2),(3,3),(4,4),(1,2),(1,3),(1,4),(2,1),(2,3),(2,4),(3,1),(3,2),(3,4),(4,1),(4,2),(4,3)\}$$
my question is if there is minimal or maximal terms in this power set? becuase the definition is that (let say we want the minimal ) for minimal is for all $a\in A \rightarrow xRa$ and there is few minimals terms. Thanks.",['discrete-mathematics']
456681,"Find $a,b\in\mathbb{Z}^{+}$ such that $\large (\sqrt[3]{a}+\sqrt[3]{b}-1)^2=49+20\sqrt[3]{6}$","find positive intergers $a,b$ such that $\large (\sqrt[3]{a}+\sqrt[3]{b}-1)^2=49+20\sqrt[3]{6}$ Here i tried plugging $x^3=a,y^3=b$ $(x+y-1)^2=x^2+y^2+1+2(xy-x-y)=49+20\sqrt[3]{6} $ the right hand part is a square hence can be written as $(p+q)^2$","['elementary-number-theory', 'algebra-precalculus', 'diophantine-equations']"
456695,Simplifying a Rational Expression,How do you simplify the following expression: $$\frac{x^3-27}{x^2+x-6}$$ Thanks for the help. Haven't seen this stuff since high school and I'm trying to help my younger sister out.,['algebra-precalculus']
456703,Are all finite fields isomorphic to $\mathbb{F}_p$?,"I've recently started taking some algebra courses and I was wondering whether or not every finite field is isomorphic to $\mathbb{F}_p$, where $p$ is prime.","['finite-fields', 'abstract-algebra', 'field-theory']"
456722,Strictly diagonally dominant matrices are non singular,"I try to find a good proof for invertibility of strictly diagonally dominant matrices (defined by $|m_{ii}|>\sum_{j\ne i}|m_{ij}|$). 
There is a proof of this in this paper but I'm wondering whether there are are better proof such as using determinant, etc to show that the matrix is non singular.","['matrices', 'linear-algebra']"
456723,"Problems on showing that a reduction map is defined, and that a certain scheme is finite.","I am currently on the last chapters in Liu's book and I am trying to solve the following problem, which is the first step in showing that a certian reduction map is well-defined:
Let $X \rightarrow T$ be a flat proper morphism to a regular locally Noetherian scheme $T$. Let us suppose that $T$ is irreducible with generic point $\xi$. Let $x \in X_\xi$ be a closed point and $D$ its Zariski closure in X, endowed with the reduced closed subscheme structure. a) Show that $D$ is finite over $T$. b) If $x$ is rational over $k(\xi)$, show that $D \rightarrow T$ is an isomorphism. One can thus define a reduction map $X_\xi(k(\xi)) \rightarrow X_t(k(t))$ for every $t \in T$. Here is my work so far, I have only done some work on a), but doesn't seem to get all the way through. What would show that D is finite over T is that it is quasi-finite, since D is proper over T and by Zariski's main theorem proper + quasi-finite implies finite. However, here is where I get stuck. I see that $X$ is (universally) catenary, and so is T. I guess that from this, one should be able to deduce that $\dim D \cap X_t = 0$ for every $t \in T$.So, I tried to use the following identities, which follows from X catenary:
$$dim X_t = \text{codim}(D \cap X_t, X_t)+ \dim(D \cap X_t)$$
and 
$\dim D = \text{codim}(D \cap X_t, D)+\dim(D \cap X_t).$$ I then try to use that $X \rightarrow T$ is flat, but with no luck, to show that $\dim (D \cap X_t) = 0$. Am I thinking completely wrong here? I would appreciate any hint to $a)$ or $b)$ (or if you can see no hint, an answer is OK, though I prefer a hint).","['arithmetic-geometry', 'algebraic-geometry']"
456729,Stone Weierstrass Overkill in the Measurable Setting?,"If $\mu$ is Lebesgue measure on the Borel sigma algebra $\mathcal{B}$ of $[0,1]$. Establishing that the linear span in $L^{2}([0,1]\times[0,1],\mathcal{B}\otimes\mathcal{B},d(\mu \times \mu))$ of the set of measurable functions of the form $(f \otimes g)(x,y)=f(x)g(y)$ where $f\in L^{\infty}([0,1],d\mu)$ and $g\in L^{\infty}([0,1],d\mu)$ is dense is a standard application of the Stone-Weierstrass Theorem. I've always felt that the presence of so many characteristic functions in the dense algebra mentioned above ought to make the use of Stone-Weierstrass overkill to obtain the above result. I wonder if it is easy to use the outer regularity of the Lebesgue measure on $[0,1]$ along with the fact that any open subset of $[0,1]$ is a countable union of pairwise disjoint open intervals to directly prove the above result without the use of the Stone-Weierstrass theorem, perhaps by proving that functions can be approximated adequately using simple functions supported on elementary sets (finite unions of pairwise disjoint measurable rectangles). Question: What is an easy elementary proof of the above density result that does not require or reduce essentially to the use of the Stone-Weierstrass theorem? Filling in the details of the proposed strategy of Davide below would be great!","['measure-theory', 'hilbert-spaces', 'functional-analysis']"
456739,How much is $\lceil\frac{1}{\infty}\rceil$?,"How much is  $\lceil\frac{1}{\infty}\rceil$  ? On one hand, $\frac{1}{\infty}=0$, so its ceiling is also $0$. On the other hand, for all $x\geq 1$, $\lceil\frac{1}{x}\rceil = 1$, so, when $x$ goes to infinity, the function should remain with the same value...","['ceiling-and-floor-functions', 'limits']"
456744,Can $p^{q-1}\equiv 1 \pmod {q^3}$ for primes $p<q$?,"For prime $q$ can it be that
$$
p^{q-1}\equiv 1 \pmod{q^k}
$$
for some prime $p<q$ and for $k\ge 3$? There doesn't seem to be a case with $k=3$ and $q<90000$, and I also checked for  small solutions with $3<k\le 20$ and found none. If we remove the condition $p<q$ then there are always solutions, e.g. $15441^{16}\equiv 1 \pmod{17^5}$. Also for $k=2$ there are many, e.g. $71^{330} \equiv 1 \pmod {331^2}$.","['elementary-number-theory', 'number-theory']"
456764,Finite group with elements of given order,"A few weeks ago, there was a queston on MSE that got edited, as soon as the question was answered well enough, according to OP. In the end, I think this question got reversed to its original question and all later questions were just forgotten. It is the last question I've seen, however, that interests me and I seem to be unable to find it, so I guess it hasn't been asked before or since. The question was: Given $a,b,c\in\mathbb{N}$, find a finite group $G$ containing elements $x$ and $y$, such that $x$ has order $a$, $y$ has order $b$ and $xy$ has order $c$. This question was supposed to be from a course on basic group theory, but I can't find an easy answer, nonetheless. The question therefore is what I'm asking as well. What I tried/noted so far: The group $G$ of course won't be abelian, in general. What I'd deem the two standard approaches didn't get me anywhere: 1) Try it via group presentations. Naïve attempt: $G=\langle x,y,z\mid x^a=1, y^b=1, z^c=1, xy=z\rangle$. This nicely satisfies the given requirements (it is made to), but it seems to fail to be finite. At least, I don't see how $x^2y=xz$ is going to be of finite order, unless $a=2$. This might be a problem, if $G$ has to be finite. 2) Some sort of twisted version of $C_a\times C_b\times C_c$, where $C_n$ is the cyclic group of order $n$ and where the product of generators of two cyclic groups is sent to the generator of the third. This again satisfies the requirements on order (where $x$ and $y$ are the generators of $C_a$ and $C_b$), but this time it fails to be well-defined. We already run into trouble for fairly small $a,b,c$: take $a=2, b=c=3$, call the identity elements $1$ and the generators of $C_a, C_b, C_c$ resp. $r,s,t$. Then $(1,s^2,1)(1,1,t^2) = (1,s,1)(r,1,1)(1,1,t)$ and if we work out the two left-hand terms first, this would be $(1,1,t^2)$, whereas it would be $(1,s^2,1)$ if the right-hand terms were multiplied first. I still have the feeling there will be a group of order $abc$ that fulfills the requirements. Possibly even just a slightly altered version of one of the above. Or something really stupid I'm missing...","['finite-groups', 'group-theory']"
456785,Evaluate an iterated integral by reversing the order of integration,"I'm not sure if I am doing something wrong or if the question has a typo... $$\int\limits_{0}^{3}\!\!\int\limits_{x^{2}}^{9}xe^{y^{2}}\mathsf{d}y\ \mathsf{d}x$$ I notice that $0\leq x\leq 3$ and $x^{2}\leq y\leq 9$. Given these bounds, when I reverse the order I'm coming up with $0\leq y\leq 9$ and $\sqrt{y}\leq x\leq 3$... $$\int\limits_{0}^{9}\!\!\int\limits_{\sqrt{y}}^{3}xe^{y^{2}}\mathsf{d}x\ \mathsf{d}y$$ So now I can easily integrate with respect to x, but I get stuck on the next step... $$\int\limits_{0}^{9}\frac{1}{2}\left[9e^{y^{2}}-ye^{y^{2}}\right]\mathsf{d}y$$ I can integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}ye^{y^{2}}\mathsf{d}y$ with no problem, but I don't see how I can easily integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}9e^{y^{2}}\mathsf{d}y$.",['multivariable-calculus']
456795,"If $\gcd(f(x), g(x))\ne1$, then $F[x]/(fg)$ is not isomorphic to $F[x]/(f)\times F[x]/(g)$","So I thought up this question as an extension to the corresponding one for $Z_m$, $Z_n$, $(m, n)\ne1$. The problems is I am unable to prove it, or disprove it. I try, but I keep getting tripped up since an isomorphism doesn't necessarily have to be the identity when restricted to $F$. I managed to prove it for all finite fields and fields generated by their identity (my 'proof' is far to long to put here though). Can anyone shine some light on the general case? I would really appreciate it. The converse is clearly true, but the problem is that there is no clear way to extend the proof since 1 doesn't generate the arbitrary field.","['ring-theory', 'abstract-algebra', 'polynomials']"
456816,When is the infimum of the sum of two sets equal to the sum of their infima?,"When is the following true? $A$ and $B$ are subsets of real numbers. I don't say that $A$ and/or $B$
are closed:
$$\inf (A + B) = \inf (A) + \inf(B)$$ When is there a strict inequality in between? Could you give an example?
When is the equality for what sufficient condition? Could you give an example? Thanks a lot!","['calculus', 'real-analysis', 'analysis']"
456825,A challenge geometrical,"Let $ABC$ a right isosceles triangle and $M$ the middle point at the hypotenuse $AC$.
Inside the triangle, draw a circle that is tangent to $AB$ at $P$ and to $BC$ at $Q$.The line  $MQ$ cuts newly to the circle in $T$.If $H$ is the orthocenter of the triangle $AMT$,prove that $MH=BQ$. I think that we should prove that $MH$ is equal to the radius of the circle but maybe exist another idea.","['geometry', 'problem-solving']"
456826,Derivative of an integral $\sqrt{t}\sin t dt$,I need to find the derivative of this function. I know I need to separate the integrals into two and use the chain rule but I am stuck. $$y=\int_\sqrt{x}^{x^3}\sqrt{t}\sin t~dt~.$$ Thanks in advance,"['definite-integrals', 'integration', 'derivatives']"
456870,"Help with $\int\limits_{0}^{1}\int\limits_{2x}^{2}x^2\sin(y^4)\,dy\,dx$","I usually do my problems by myself and then check the solution with Wolfram Alpha, but in this situation, it's not helping me at all... I don't know if I got the wrong answer, or if wolfram is using some trig identity that I don't know of... \begin{align}
\int\limits_{0}^{1}\int\limits_{2x}^{2}x^2\sin(y^4)\,dy\,dx&=\int\limits_{0}^{2}\int\limits_{0}^{y/2}x^2\sin(y^4)\,dx\,dy\\
&=\frac{1}{3}\int\limits_{0}^{2}\left[x^3\sin(y^4)\right]_{x=0}^{x=y/2}\,dy\\
&=\frac{1}{24}\int\limits_{0}^{2}y^3\sin(y^4)\,dy\\
&=\frac{1}{96}\left[\sin(y^4)\right]_{y=0}^{y=2}\\
&=\frac{\sin(16)}{96}
\end{align} This is what I came up with, but wolfram is giving me the answer of $$\frac{\sin^2(8)}{48}$$ Needless to say, I'm not the best at remembering my trig identities. I didn't see anything on the wikipedia page of identities to give me any help either.",['multivariable-calculus']
456878,Higher Derivatives of trigonometric functions,"The position of a particle is given by $s = 5 \cos (2t+ (\pi/4))$ at time $t$ . What are the maximum values of the displacement,the velocity,and the acceleration?
The answers are displacement: $5$
velocity: $10$
acceleration: $20$ I tried to do it but I am not getting the right answer.
Here is my solution: $s(t) = 5\cos(2t+ \pi/4)$ $s'(t) = -10 \sin(2t + \pi/4)$ $0= -10[\sin2t\cos\pi/4 + \cos2t\sin\pi/4]$ $-\sin2t(\sqrt{2}/2) = \cos2t(\sqrt{2}/2)$ $-1=\tan2t$ $\tan2t = 3\pi/8, 7\pi/8$ when I substitute the values, I get -5.  For the v(t).I got zero. please help thanks!","['trigonometry', 'physics', 'algebra-precalculus', 'derivatives']"
456879,Any group of order $85$ is cyclic.,Any group of order $85$ is cyclic. My attempt: Let $|G|=85=5\times17$ Let $H_1$ be the sylow-$5$ and $H_2$ be sylow-$17$ subgroup of $G.$ Then $H_1\cap H_2=\{e\}$ So $|H_1\times H_2|=85$ and hence $G\simeq H_1\times H_2$ Since $H_1\times H_2$ is cyclic so is $G.$ I'm not sure about my proof. Please tell me whether it's correct! Apart from voting please leave comment.,"['group-theory', 'proof-verification']"
456883,categorical generalizations of familiar objects,"A couple of days ago I've learned that you can define trace in a very abstract setting. Namely, suppose $F\colon A\to B$ is a functor between two categories. Suppose $E,G\colon B\to A$ are two functors, that are adjoint to $F$, such that $E$ is left adjoint and $G$ is right adjoint. Suppose moreover that $\nu\colon G\to E$ is a natural transformation. Then having this data $\forall x,y\in A$ you can define the trace map $$Tr\colon Hom(F(x),F(y))\to Hom(x,y)$$ for any $f\in Hom(F(x),F(y))$ to be the composition $$x\to GF(x)\to EF(x)\to EF(y)\to y,$$ where the first map is given by the adjunction unit $id_A\to GF$, second map is given by $\nu$, the third map is given by $E(f)$ and the last map is given by the adjunction counit $EF\to id_A$. If we take $A=B=Vect_k$, $F=-\otimes V$ and $G=E=-\otimes V^*$ for some finite dimension vector space $V$ over $k$, and take $x=y=k$, then this construction gives the usual trace of a linear map. From the top of my head I remembered a couple of more examples. For example, if $C$ is a category, the Bernstein center of $C$ is defined to be $Z(C)=End(id_C)$, the (commutative monoid) of endomorphism of the identity functor. If the category $C$ is additive, then $Z(C)$ is a commutative ring. If we take $C$ to be the category of modules over some ring $R$, then $Z(C)$ is isomorphic to the center of $R$. Another one, you can talk about open, closed subfunctors on the category of commutative rings into $Sets$. If your functors are representable, then you get the usual definition of open or closed subschemes. So my question is: What are other nice examples of such categorical generalizations that you now?","['soft-question', 'category-theory', 'big-list', 'abstract-algebra']"
456890,Errata for Hungerford's Algebra,"Currently reading the category theory section of Hungerford's Algebra (the GTM), and I am noticing an egregious amount of typos. However, I have been at a loss to find an errata for this text, despite it seemingly being rather well known. Could anyone suggest an errata?","['reference-request', 'abstract-algebra']"
456898,Application of mean value theorem,"$f$ is differentiable in $[a,b]$, and satisfies $f(a)<f(b)$, $f'(a)=f'(b)=0$.
Show that there exists $c$ in $[a,b]$ \begin{equation}
\frac{f(c)-f(a)}{c-a}=f'(c)
\end{equation} How is the mean value theorem 
\begin{equation}
\frac{f(b)-f(a)}{b-a}=f'(c)
\end{equation}
applicable here?",['calculus']
456899,Integrating $\int_0^{\pi/2} \cos^a(x) \cos(bx) \ dx$,Please help me in this integral : $$\int_0^{\pi/2} \cos^a(x) \cos(bx) \ dx \quad \text{if}\; b>a>-1$$ Please help me I used everything and can't evaluate it.,"['definite-integrals', 'trigonometry', 'calculus', 'complex-analysis']"
456912,Some questions about the Jech's book (Generalized De Morgan's law and distributive law ),"I finished the first chapter of the book Introduction to Set Theory by Jech (I started to love). And I have questions of some exercises where I'm not totally sure if my attempt  was complete or even correct. The two last are where I have more doubts. Here we go: (A) Generalized distributive law : Let $S \not= \emptyset$ and $A$ be a set.  Set, $\;T_{\,1}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A\cap x \,)\,   \right\}$ and prove that: $\, A\cap \bigcup S =\bigcup T_{\,1}.$ Proof: ($\,\Rightarrow\,$) If $\,z \in A\cap \bigcup S$, $z\in A$ and  $\,z\in \bigcup S$. For $\,z\in \bigcup S,\,$ that means $z \in x_{0}$ for some $\, x_{0}\in S.\, $ Then, $\,z\in A$ and $z \in x_{0}$, i.e.,  $\,z\in A\cap x_0\,$   (where $\,x_0 \in S\,$). On the other hand, for $z$ be in the union of $T_{\,1}$, $\,z\in \bigcup T_{\,1}$, it is a sufficient condition that $z\in y_{0}$ for some $\,y_0 \in T_{\,1}.\,$ We define $y_{0} = A \cap x_{0}$. It follows immediately that $y_{0} \in T_{\,1}$ $($as $\,y_{0} \in \wp(A)$ and $\,x_0 \in S\,)$. So as $\,z\in A\cap x_0\,$ and we defined $\,y_{0} = A \cap x_{0}$, then $\,z\in y_{0}$ for some $\,y_0 \in T_{\,1}$, as desired. That is, $\, A\cap \bigcup S \subseteq \, \bigcup T_{\,1}$. ($\,\Leftarrow\,$) If  $z\in \bigcup T_{\,1},\, z\in y_{0}$ for some $y_{0} \in T_{\,1}.\,$ Then, by the definition of $T_{\,1},\,\,y_{0} = A\cap x_{0}\, $ for some $x_{0} \in S.\;$ It follows that, if $z\in y_{0}$, then $z\in x_{0}$ ( this is because $\,y_{0} \subseteq x_{0}\,).\,$  And as there a $x_{0} \in S\,$ for which $\,z\in x_{0},$ by the union axiom we can conclude that $\,z\in \bigcup S$. Hence, $z \in A$ and $\,z\in \bigcup S$, $\,z \in A\cap \bigcup S.\,$ That is, $\bigcup T_{\,1} \subseteq\, A\cap \bigcup S. $  $\;\Box$ (B) Generalized De Morgan's laws : Set,  $\;T_{\,2}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A - x \,)\,   \right\}\,$ and prove  that: ($\,i\,$) $A - \bigcup S = \bigcap T_{2}\,$ and  ($\,ii\,$) $\,A - \bigcap S = \bigcup T_{2}.$ Proof: ($\,i\,$) ($\,\Rightarrow\,$) If $z \in A - \bigcup S,\, z\in A\, $ and $ z\notin \bigcup S$ ( which means that,  for each $x \in S,\, z \notin x$ ). For $z$ be a member of the right-hand side, $z \in \bigcap T_{2},\, $ it is necessary that: for every $y\in T_{2}\,$ ( which assume is nonempty ) $z \in y: = A-x.\,$ Then, $z \in A$ and $z \notin x$  as in our assumption has that properties, it follows that $z \in \bigcap T_{2},\, $ i.e., $  A - \bigcup S \subseteq \bigcap T_{2}. $ ($\,\Leftarrow\,$) If  $z \in \bigcap T_{2},\, $ where assume that $T_{2}$ is nonempty. So, for each $y\in T_{2},\,z \in y: = A-x\,$. Therefore, $z \in A$ and $z\notin x\,$ and by definition of the set $ T_{2},\, x\in S $; which  holds for each $y \in T_{2}. $ For all $y, \,$ we have that $x\in S\,$ and $ z \notin x,\, $  $ z\notin \bigcup S\,$* ?? * (* ** How do we know that $S$ cannot have some element out of the elements
  that we use by the definition of the set $T_{2}$ which could be in? I
  don't know maybe I misunderstood this part *) Hence, $z\in A$ and $ z\notin \bigcup S,\,$ $z \in A - \bigcup S\, $, i.e, $\bigcap T_{2} \subseteq  A- \bigcup S.$ $(\, ii \,)$ $(\, \Rightarrow \,)$ If $z\in A - \bigcap S,\, z\in A\,$ and $z \notin \bigcap S.\,$ For  $z \notin \bigcap S\,$, means that there exist some $x\in S$ for which $z\notin x.$  Then, $z\in A- x_{0}\,$ for some $x_{0} \in S.\,$ We set, $\,y_{0}:= A- x_{0}.\,$ So, $\,y_{0} \in T_{2}\,$ because $\,y_{0} \in \wp(A)$ and $\, x_{0}\in S.\,$ As $\, y_{0} \in T_{2}\,$ and $\, z\in y_0,\,$ it follows that $z \in \bigcup T_{2},\,$ i.e., $A-\bigcap S \subseteq \,\bigcup T_{2}.\, $ ($\,\Leftarrow\,$) if $\,z \in \bigcup T_{2}\,$, then there exist a $\,y_{0} \in T_{2}\,$ for which $\,z\in y_{0}: = A-x_{0}\,$ ( for some $\,x_{0} \in S\,).\,$ Then $z \in A\,$ and for some $\,x_{0} \in S,\, z\notin x_{0}.\,$ Therefore, $z \in A\,$ and $\,z\notin \bigcap S,\, $ $z\in A - \bigcap S,\, $ i.e., $\, \,\bigcup T_{2} \subseteq\, A-\bigcap S .\, $ Claim 1 : The set $T_{2}$ is non empty We'll show that the set $T_{2}$ is empty iff the set $S$ is empty. Proof: Suppose $S = \emptyset$, we need to show that $T_{2}$ is empty. Assume for the sake of the contradiction that $y$ is in $T_{2},$  $\,y\in T_{2} \leftrightarrow y = A-x$ for some $x\in S,\,$ but since $x\notin S:=\emptyset$ we have a contradiction, it follows that $y$ cannot be in $T_{2},\,$ i.e., $y \notin  T_{2}.\,$ Therefore $T_{2} = \emptyset,\,$ as desired. On the other hand, if we assume that $\,T_{2} = \emptyset,\,$ we need to seek if this assumption implies the emptiness of $S.\,$  By contradiction, suppose $S \not= \emptyset,\,$ then $x\in S,\,$ and the set $A-x \in T_{2},\,$ which is a contradiction, because is empty by hypothesis. Therefore, $S = \emptyset.\,$ Then, if we assume that $S \not= \emptyset$ it follows that $T_{2} \not= \emptyset,\,$ as desired.  $\;\Box$ ** I have problems to understand what's going on in that parts where I put the question mark in boldface.... I don't know maybe I'm tired. I need a coffee. As usual, thanks in advance :)",['elementary-set-theory']
456916,How to integrate over polar coordinates,"Evaluate the following double integral by rewriting it in polar coordinates: $\displaystyle\iint\limits_Dxy\,dA$, where $D$ is the disc with center at the origin and radius 5 I have very little understanding about how to do this. The most I know right now is the following: $x=r\cos(\theta)$ $y=r\sin(\theta)$ $dA=r\,dr\,d\theta$ $D=\{(x,y)\mid x^2+y^2\leq 25\}$ or $D=\{(r,\theta)\mid r\leq 5\}$ It's given in the problem that $r=5$, so that's a start. I'm assuming then that my limits for $r$ is $0\leq r\leq 5$. But I have no idea how to define the limits for $\theta$. My guess would be $0\leq\theta\leq 2\pi$, but several examples with different regions seem to use $0\leq\theta\leq\pi$. So here's part of the integral with missing limits on $\theta$: $$\int\limits_{\alpha}^{\beta}\int\limits_{0}^{5}r^3\sin{\theta}\cos{\theta}\,dr\,d\theta$$ Is my limited understanding correct so far? How do I fill in the holes of this problem? I know how to integrate after I have the proper limits; I just don't know how to define the limits given the information I have.","['multivariable-calculus', 'polar-coordinates']"
456959,Are We Teaching Pre-Calc Wrong?,"It took some 1,250 years to move from the integral of a quadratic to that of a fourth degree polynomial. When we jump too fast to the magical algorithm, when we fail to acknowledge the effort that went into its creation, we risk dragging our students past that conceptual understanding. Source. By the time Newton and Leibniz were developing Calculus mathematicians already knew how to solve particular problems of derivatives and integration. There was a good understanding on the way to resolve problems, too. Newton's teacher, Isaac Barrow, already had some understandings of the topics Newton would push to the perfection. Source. For me, pre-calc was plugging and chugging trigonometric, geometric, and algebraic equations. Math books follow a rather narrow and strait path across some imaginary border from the province of pre-calc into calculus. As was mentioned already, that historic transition was anything but discreet. Should Pre-Calc teach the foundations of the fundamental theorem of calculus that were known Pre-Lebniz/Newton? I think that would energize what is otherwise a boring exercise in tedious calculation. A beautiful example of a Pre-Leibniz integration: Who realized $\int \frac 1x dx =\ln(x)+c$?","['algebra-precalculus', 'soft-question', 'math-history']"
456960,Should a high school introductory calculus class teach $\varepsilon$-$\delta$ proofs?,"It seems to me that most high school students are comfortable with the intuitive notion of a limit (""as $x$ gets arbitrarily close to $c$, $f(x)$ gets arbitrarily close to $L$"") and gain little insight from learning the $\varepsilon$-$\delta$ definition. Is the added rigor of the $\varepsilon$-$\delta$ definition worth teaching at the high school level?","['epsilon-delta', 'calculus', 'education', 'soft-question', 'limits']"
456984,Solve $\frac{dy}{dx} = f^{-1}(x)$,"I am doing a differential equations subject, and have been given this as a challenge question. Solve $\frac{dy}{dx} = f^{-1}(x)$ ($f^{-1}(x)$ is the inverse function of x.) I assume that the answer involves separable differential equations, but I can't quite see how to do it. Is there a substitution that will help solve this? Edit: I've tried the following ideas: Idea 1. $$
\begin{align}
y &= \int f^{-1}(x) \, dx\\
\mathrm{let}\,\,u &= f^{-1}(x)\\
x &= f(u)\\
\frac{dx}{du} &= f'(u)\\
dx &= f'(u) \, \, du\\
\mathrm{so} \,\, y &= \int u f'(u)\, du\\
\end{align}
$$ Is this right, and if so, would I just integrate by parts?",['ordinary-differential-equations']
456999,Are my answers correct? (Graphs; paths; path lengths; circuits),"My answers a) Yes, this forms a path.  This is a simple path.  The length of this path is 4. b) Yes, this forms a path.  This is a circuit.  The length of this path is 4. c) Yes, this forms a path.  This is a circuit.  The length of this path is 6. d) Yes, this forms a path.  This is a circuit.  The length of this path is 7.","['graph-theory', 'discrete-mathematics']"
457008,What is the motivation of uniform continuity?,"At the moment, in my very limited knowledge of mathematics (=my first year at college), I've just seen this concept applied to prove that a function is Riemann integrable. I'd like to know if this concept was motivated for some special reason, or what is the importance in further studies of mathematics.","['calculus', 'real-analysis']"
457042,prove that a connected graph with $n$ vertices has at least $n-1$ edges,"Show that every connected graph with $n$ vertices has at least $n − 1$ edges. How can I prove this?  Conceptually, I understand that the following graph has 3 vertices, and two edges: a-----b-----c with $a$, $b$ and $c$ being vertices, and $\{a,b\}$, $\{b,c\}$ being edges. Is there some way to prove this logically? --UPDATE-- Does this look correct?  Any advice on how to improve this proof would be appreciated.  Thank you.","['graph-theory', 'discrete-mathematics']"
457044,"If the group of units of a unital ring is cyclic, must it be finite?","Suppose you have a ring $R$ with $1$ and that the multiplicative subgroup $R^\times$ of $R$ is cyclic. Is then $R^\times$ a finite group? Are there conditions, such that $R^\times$ is cyclic, or is it and if then else relation between these two properties. EDIT: Oky it is wrong! Is this true in Char $R\neq 2,1$?","['cyclic-groups', 'ring-theory', 'group-theory', 'abstract-algebra']"
457090,Powers of 13 expressable as sums of squares,"Show that $$13^k=a^2+b^2,k\in \mathbb{N}$$
has only one solution $(a,b)$
where $a,b\in \mathbb{N^{+}}，gcd(a,b)=1$. For example, $$13=2^2+3^2$$
$$13^2=169=5^2+12^2$$ I  think this is very interesting problem. Thank you everyone.",['number-theory']
457102,Stability of nonlinear system with borderline linearization,"I have the following nonlinear system:
\begin{align}                                                                                                                                                               
x_1'=& x_1-x_2-x_1^3\\                                                                                                                                                      
x_2'=& x_1+x_2-x_2^3                                                                                                                                                        
\end{align}
I wish to classify the equilibrium points and determine their stability using the linearization. First, I found the equilibrium points as follows:
\begin{align}                                                                                                                                                               
\frac{\partial f_1}{\partial x_1} =& 1-3x_1^2 \\                                                                                                                            
\frac{\partial f_2}{\partial x_2} =& 1-3x_2^2 \\                                                                                                                            
\frac{\partial f_1}{\partial x_2} =& -1 \\                                                                                                                                  
\frac{\partial f_2}{\partial x_1} =& 1                                                                                                                                      
\end{align}
Therefore we have equilibria at $(1, \pm \frac{1}{\sqrt{3}})$ and $(\pm \frac{1}{\sqrt{3}}, -1)$. Thus for the jacobian:
\begin{equation}                                                                                                                                                            
J = \begin{pmatrix}\frac{\partial f_1}{\partial x_1}&\frac{\partial f_1}{\partial x_2}\\                                                                                    
                    \frac{\partial f_2}{\partial x_1}&\frac{\partial f_1}{\partial x_2}\end{pmatrix}                                                                        
\end{equation}
And the jacobian at all equilibria points is:
\begin{equation}                                                                                                                                                            
A = \begin{pmatrix}0&-1\\1&0\end{pmatrix}                                                                                                                                   
\end{equation}
Thus the eigenvalues are $\pm i$ which is purely imaginary and implies that we have a center point. However, this is a borderline case and can not be approximated by a linearization. How do I then determine the stability of these equilibrium points then? EDIT I am having trouble solving for the equilibrium points and I also made a mistake in the equation for $x_1'$. It should be a cubic term and not a quadratic term.","['dynamical-systems', 'nonlinear-system', 'ordinary-differential-equations']"
457112,Maximization of function in 3 variables,"If $( x,y,z)$ be the lengths of perpendiculars from any interior point P of a triangle $ABC$ on sides $BC,CA$ and $AB$ respectively then find the minimum value of : $$
x^2+ y^2 + z^2
$$
The sides of triangle being $a,b,c$. I thought of using Lagrange's method of multipliers but am not able to find another function in terms of $x,y,z$ and $a,b,c$ Any help will be appreciated. Thanks.","['optimization', 'multivariable-calculus']"
457116,How to compute the expected distance to a nearest neighbor in an array of random vectors?,"Let us have $k$ independent random vectors $x_1, x_2, \dots, x_k$ with uniform distribution over $ \left[0;1 \right]^n $. Then the distance (preferrably Manhattan) between an arbitrary vector $x_a$ and its nearest neighbor among these vectors is a well defined random variable. How can we estimate its momenta? Especially the expected value ? Since I have no idea how to start let us begin with the case of two vectors $a$ and $b$ in two dimensions: In this case one is the nearest neighbor to the other, so their distance is:
$$
d \left(a, b\right) = \left | a_1 - b_1 \right | + \left | a_2 - b_2 \right | 
$$ 
Where $a_1, a_2, b_1, b_2 \sim  U \left[0;1 \right]$ and are independent. In this case we can compute the expected value as a double integral:
$$
I := \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | + \left | x - y \right | dxdy
$$ Since the integrand is symmetric along $x = y$:
$$
I = 2 \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | dxdy = 4 \int_{0}^{1} \left ( \int_{0}^{x} x - y  dy \right ) dx = 4 \int_{0}^{1} \frac{x^2}{2} dx = \frac{2}{3}
$$ It would probably not be so hard to extend this result to $n$ dimensions. The real challenge is to add other vectors to the picture. If we have three vectors $a,b,c$, then both $b$ and $c$ have equal probability of being the closest individual to $a$. We can then compute the expected distance as the weighted sum of conditional expected values.
$$
\frac{1}{2} E \left [ d \left( a, b \right) | b \text{ is closer}  \right] + \frac{1}{2} E \left [ d \left( a, c \right) | c \text{ is closer}  \right]
$$
Both $E \left [ d \left( a, b \right) | b \text{ is closer}  \right]$ and $E \left [ d \left( a, c \right) | c \text{ is closer}  \right]$ could be computed as integrals in 6 dimensions somehow.","['geometry', 'probability']"
457122,Sketching a Cubic Polynomial?,"Suppose that $f(x)$ has $(x-2)^2$ and $(x+1)$ as its only factors. How do I sketch the graph of $f$? So far what I've done is determine (hopefully correctly) that the x-intercepts will be at $-1$ and $+2$. But what about the $y-$intercept?? If y-intercept is 4, is my sketch below correct (excuse the poor drawing)?","['graphing-functions', 'algebra-precalculus', 'functions', 'polynomials']"
457146,seeming ugly limit,"i want to compute the limit $$\lim_{x \rightarrow 0} \frac{e^x-1-x-\frac{x^2}{2}-\frac{x^3}{6}-\frac{x^4}{24}-\frac{x^5}{120}-\frac{x^6}{720}}{x^7}$$ Instead of doing some messy calculation, I think if there is some ingenious way to compute this limit, but i don't know how to do. thank you so much.","['calculus', 'contest-math', 'limits']"
457154,Compact variety which is not projective,"While reading Andreas Gathmann's notes on Algebraic Geometry, I stumbled upon this statement: ""Projective varieties form a large class of “compact” varieties that do admit such a unified global description. In fact, the class of projective varieties is so large that it is not easy to construct a variety that is not (an open subset of) a projective variety."". I know that we can sometimes glue affine varieties together and create compact spaces (in fact, Gathmann constructs $\mathbb{P^1}(\mathbb{C})$ as a compactification of $\mathbb{A}^1$). Also affine varieties are not compact unless they are single points. But my question is: is there an example of a variety which is ""compact"" but not projective? Gathman does not provide such an example, so maybe someone here can help.",['algebraic-geometry']
457157,Recurrence relation for $n$ numbers in which no 3 consecutive digits are the same.,"I am stuck on trying to find (and solve) a recurrence relation to find all n-digit numbers in which no 3 consecutive digits are the same.  These numbers are in decimal expansion. Now I first imagine trying this for finding the number of n-digit numbers that don't have two consecutive digits.  If I am correct I have 10 choices for the first (we are in decimal expansion so 0 counts), then 9 choices for the second, 9 for the third and so on.  So we would have $10*9^{n-1}$ possible numbers.  This looks like it works for n = 2 as we would have 10 numbers {00,11,..,99} that are repeated.  I however wonder about 00, if that should be counted here, but for n > 2 I could have .001 etc.  I however figure that if .00 is not a valid number in decimal expansion then it also won't have to be removed.  Hence I have 90 numbers which work.  I can't quite see in to the n = 3 case though - it is this next digit (and so on) that boggle me. Now I rigged up a recurrence relation that seems to work for the n = 1 and n = 2 case in the no consecutive 2 digit case.  It is: $T(n) = 10^n - T(n-1) -1$  where T(0) = 0. $T(1) = 10^1 - T(0) - 1 = 9$  Note that 0 is not counted for n = 1 as it is .0 (hence the -1 included)
$T(2) = 10^2 - T(1) - 1 = 10^2 - (10^1 - T(0) - 1) - 1 = 100 - (10 - 0 - 1) - 1 = 90$ Since I don't know what T(3) is supposed to be I didn't bother putting it in.  If this Recurrence relation works, perhaps someone would have a combinatorial reason why it works? I however then am still stuck on the non 3 consecutive digit case and finding a recurrence relation for it. Thanks for any thoughts, Brian","['closed-form', 'recurrence-relations', 'discrete-mathematics']"
457159,Cut vertices and cut edges - did I answer these correctly?,"Problem Find the cut vertices and cut edges for the following graphs My understanding of the definitions: A cut vertex is a vertex that when removed (with its boundary edges) from a graph creates more components than previously in the graph. A cut edge is an edge that when removed (the vertices stay in place) from a graph creates more components than previously in the graph. My Answers 31) The cut vertex is $c$.  There are no cut edges. 32) The cut vertices are $c$ and $d$.  The cut edge is $(c,d)$ 33) The cut vertices are $b, c, d$ and $i$.  The cut edges are: $(a,b)$,$(b,c)$,$(c,d)$,$(c,e)$,$(e,i)$,$(i,h)$ For anyone reading this at a later date: 33) is wrong, per the answers and comments below, e is a cut vertex, not d","['graph-theory', 'discrete-mathematics']"
457177,"Proof the maximum function $\max(x,y) = \frac {x +y +|x-y|} {2}$ [duplicate]","This question already has answers here : Show that the $\max{ \{ x,y \} }= \frac{x+y+|x-y|}{2}$. (7 answers) Closed 10 years ago . I want to prove the maximum function max: $\mathbb{R} \rightarrow \mathbb{R}$, which is defined by $$\max(x,y) = \begin{cases}x,  \text { if }  x \geq y , \\ y,  \text { if }  x < y \end{cases}$$ I want to prove this for 
$\max(x,y) =   \frac {x +y +|x-y|} {2}$. I have no idea on how to start, I just read over my search over the internet that the modulus function could be a way. I really appreciate your help! UPDATE I want to prove that $\max(x,y) =   \frac {x +y +|x-y|} {2}$.","['absolute-value', 'algebra-precalculus', 'functions']"
457183,Normal Number - Intuition,"I find Borel's theorem which asserts that almost all real numbers are normal very counter intuitive. If I think about the interval [0,1) and I imagine the number represented by infinite decimal digits [lets assume base 10] 0.xxxxxxx..... where each x is one digit of the infinite decimal representation of the number in the interval. (x is a digit from 0..9) Then it seems very obvious to me that most of the numbers in the interval do not have the distribution properties of a normal number (like all digits 0..9 show up 1/10th of the time, 00..99 show up 1/100 of the time,etc). See, a simple experiment, using lets say only 10 decimal digits 0.xxxxxxxxxx and filling up the decimal digits with all possible values we get the numbers 0.00000000001, 0.00000000002, etc until 0.9999999999. By simple counting, we see that the numbers who have the property of being normal are a very small subset of all possible numbers (they will only be the permutations of 0.0123456789). This is even easier to see if we take base 2 for instance. Suppose that we experiment with all possible combinations of 2 digits in base 2. We have 0.xx, so we have 4 possibilities: 0.00, 0.01, 0.10, 0.11 Only half of the numbers (0.01 and 0.10) 'are on the way to produce a normal number'. I know that to be normal we need to have infinite number of digits but I can not see how making the number of digits infinite will overcome this phenomenon described above. That is, 0.xxxxxxx..... should not have nicely distributed digits most of the time. Could you please point where i am wrong?","['normal-number', 'number-theory']"
457184,How to find area of a circle using a regular polygon?,If a regular polygon of number of $N$ sides lies within a circle with radius $R$ where the the circle touches every vertex of the the polygon. Can I obtain the area of the circle by increasing the number of sides of the polygon? Area of circle should equal the limit as $N$ approaches infinity? Lim as $N$ -> infinity of  $nr^2\cos{(\theta/2)}\sin{(\theta/2)}$ but that always gives infinity. How can I increase the number of sides of a polygon inside a circle but not get an area bigger than the area of the circle. I know how stupid that sounds.,"['geometry', 'calculus', 'limits']"
457187,Class of functions so that $\int_0^t|f(x)|dx\leq C\cdot t^\alpha$.,I have done something with Lebesgue integrals and It leads me to the following class of functions: Let $\alpha$ be a real number. We consider all Lebesgue measurable function $f$ on $[0;1]$ such that there exists a constant $C>0$ and $\int_0^t|f(x)|dx\leq C\cdot t^\alpha$ for almost everywhere $t\in(0;1]$. Does this class has a name? I think it look simple and usual. Could we construct some non-trivial functions which belong to this class? (I may assume further that $\alpha>0$).,"['functional-analysis', 'real-analysis']"
457201,Using Möbius transformation to change $B\left(a;R\right)$ to halfplane,"In Conway's Functions of One Complex Variable, there is a proposition which says: Let $f$ be analytic in the disk $B\left(a;R\right)$ and suppose
that $\gamma$ is a closed rectifiable curve in $B\left(a;R\right)$.
Then
$$\int_{\gamma}f=0.$$ Now, we have a problem which asks us to use a Möbius transformation
to change $B\left(a;R\right)$ into a half-plane which preserves the integral. How do I proceed?",['complex-analysis']
457213,Big Gamma $\Gamma$ meets little gamma $\gamma$,"I am looking for a proofs of the following limits: $$
\lim_{x \to \infty} \Gamma \left(1+\frac{1}{x} \right)^x = e^{-\gamma}.
$$
I find this limit interesting as it relates the gamma function $\Gamma$ with the other gamma $\gamma$ which is the Euler-Mascheroni constant. The second limit whose proof I am interested in is
$$
\lim_{x \to 0} x \Gamma \left(1+\frac{1}{x} \right)^x = e^{-1}.
$$","['calculus', 'number-theory', 'analytic-number-theory', 'gamma-function', 'limits']"
457231,How to prove $\int_{-\infty}^{+\infty} f(x)dx = \int_{-\infty}^{+\infty} f\left(x - \frac{1}{x}\right)dx?$,"If $f(x)$ is a continuous function on $(-\infty, +\infty)$ and $\int_{-\infty}^{+\infty} f(x) \, dx$ exists. How can I prove that
$$\int_{-\infty}^{+\infty} f(x) \, dx = \int_{-\infty}^{+\infty} f\left( x - \frac{1}{x} \right) \, dx\text{ ?}$$","['improper-integrals', 'calculus', 'integration']"
457234,Measure dualization,"What ways are known to correspond, or transfer, a Borel probability measure $\mu$ over some Banach space $X$ to a Borel probability measure $P$ over $X^{*}$, the dual space? Of course, if $X^{*} = X$, e.g. if $X$ is Hilbert, then the correspondence is trivial. Admittedly, this question might seem a bit vague, and one could reasonably want me to specify what properties I'd like the hypothetical correspondence to satisfy, but for now I'm just wondering what's already out there along these lines.","['measure-theory', 'duality-theorems', 'probability-theory', 'reference-request', 'functional-analysis']"
457241,Proving an inequality in Eigenvalues of a matrix,"If $\lambda_1$, $\lambda_2$, $\lambda_3$ are the eigenvalues of the matrix : $$
        \begin{pmatrix}
        26 & -2 & 2 \\
        2 & 21 & 4 \\
        4 & 2 & 28 \\
        \end{pmatrix}
$$ Show that : $$\sqrt{\lambda_1^2 + \lambda_2^2 + \lambda_3^2} \le \sqrt{1949}$$ I found the characterstic equation as $$\lambda^3 - 75\lambda^2 + 1850\lambda - 15000 = 0$$
This gave $$\lambda_1 + \lambda_2 + \lambda_3 = 75$$ and $$\lambda_1\lambda_2 + \lambda_2\lambda_3 + \lambda_1\lambda_3 = 1850$$
Also $${(\lambda_1 + \lambda_2 + \lambda_3)}^2 = \lambda_1^2 + \lambda_2^2 + \lambda_3^2 + 2{(\lambda_1\lambda_2 + \lambda_2\lambda_3 + \lambda_1\lambda_3)}$$
From this I found out $$\sqrt{\lambda_1^2 + \lambda_2^2 + \lambda_3^2} = \sqrt{1925}$$
But am not satisfied with the way I have approached the problem. Does anyone know of an easier way of doing it?","['linear-algebra', 'eigenvalues-eigenvectors']"
457242,$\det(I+A) = 1 + tr(A) + \det(A)$ for $n=2$ and for $n>2$?,"Let $I$ the identity matrix and $A$ another general square matrix. In the case $n=2$ one can easily  verifies that
\begin{equation}
\det(I+A) = 1 + tr(A) + \det(A)
\end{equation}
or
\begin{equation}
\det(I+tA) = 1 +  t\  tr(A) + t^2\det(A)
\end{equation}
for some scalar $t \in \mathbb{R}$. I have tried to see if there exists a similar formula for $n>3$. This is a natural question. But the calculations are very big and difficulty to see. Then I do the answer. Is there a similar formula for $n>2$?","['matrices', 'determinant']"
457251,Axiom of empty set,"In axiomatic set theory, we have Axiom of empty set: $\exists \varnothing \forall x ( x\notin \varnothing)$. Is there any equivalent statement without the use of quantifiers? For example, $ \exists x\in y (P (x)) $ is equivalent to $ x\in y\: \And\: P (x) $ and $\forall x\in y (P (x) $ is equivalent to $ x\in y\Rightarrow P (x) $ (or are they?). Any try to clear things up is appreciated.",['elementary-set-theory']
457254,pairwise disjoint events example,"Can someone please give me an example of a pairwise disjoint event? Let $S = \{1,2,3,4,5,6,7,8,9\}.$ Will pairwise disjoint events be: $\{1\},\{2\},\{3,4\},\{5,6,7,8,9\}$? In order to be pairwise disjoint event does it just mean that for all $A_i$ inside $S$ the intersection between $A_i$ and $A_j$ ($j$ not equal $i$) is the empty set?",['probability']
457266,maximum using completing the square,"Is it just me, or this problem does sound weird? The Parks Department is fencing a rectangular dog-run (a place for dogs to exercise) in a local park. It will be 7 yards longer than 5 times its width. If the Parks Department has allocated 98 yards of prefabricated fence to this project, what are the dimensions of the maximum possible area for the dog-run? You must use completing the square to answer this question. Attempt: I get too many equations. If the length is 7 + 5 times the width, then we have the following: $$l=7+5w$$ and the perimeter is $$ 98=2w+14+10w=12w+14$$ and we get the width. Where do I use completing the square? If I do not use the information about the length being 7 +5 times the width, then I get $$A=lw$$ and $$98=2l+2w$$ these equations will not give me a concave down quadratic, and hence no use calculating its vertex. Thanks!","['optimization', 'quadratics', 'algebra-precalculus']"
457268,"Why do Mean, Median, Mode, and Range present in school lessons?","I studied in East Europe and post Soviet mathematical education program have no Median , Mode , and Range terms. Mean (or average) on other hand was studied (with root mean square and sometimes with geometric mean ). Looking to education English sites I see a lot of lessons about Median, Mode, and Range. These statistical parameters are strange for me. Why west schools use them? Have Median and Mode any sense in mathematical statistics (in science)?","['statistics', 'education', 'median']"
457274,Is it true that the definition of an open subset in a metric space is different from the combination of the definitions of subsets and opens sets?,"Dear reader of this post, I have a question concerning the equivalence of two definitions of open subsets (in metric spaces). To avoid confusion, I will state the two definitions and then ask my questions. The definition I found is:  Given a metric space $X$ and let $S \subset Y \subset X$. $S$ is an open subset of $Y$ if $\forall  p \in S, \exists r > 0 \ | \ d(p,q)<r, q \in X \rightarrow q \in S$. In contrast, I simply defined $S$ to be an open subset of $Y$ if it is open and a subset of $Y$. The two definition however seem (at least to me) to be quite different because for the set $S$ to be open one only considers whether $S$ consists solely of interior points or not. The first definition however checks the existence of a neighbourhood of $p$ such that all points which are element of the largest set $X$ are also part of the smallest set $S$. I have the following questions in particular: Is it really true that the definition of a open subset is not a combination of two definitions of an open set and a subset? The part ""$q \in X$"" of the first definition appears a bit strange to me. Is it correct that we do not considers points in Y but instead of the larger set $X$? What is then an open subset if one considers two sets instead of three? I am looking forward for your replies.","['general-topology', 'elementary-set-theory', 'real-analysis', 'definition']"
457289,Solutions in positive integers of $a+b\mid ab+1$ and $a-b\mid ab-1$,"I am interested in a proof for the following claim. Suppose that for integers $a>b>1$ the following two conditions hold:
$$a+b\mid ab+1,$$ $$a-b\mid ab-1.$$
Then $\frac{a}{b}<\sqrt{3}$. Furthermore, is it possible to determine all positive integer solutions in this case ?",['number-theory']
457303,"Relation between eigenvectors of covariance matrix and right Singular vectors of SVD, Diagonal matrix","I have a $m \times n$ data matrix $X$, ($m$ instances and $n$ features) on which I calculate the Covariance matrix $C$ and perform eigenvalue decomposition. so $C=W \Sigma W'$ where $W$ are the eigenvectors and $\Sigma$ are the eigenvalues arranged in diagonal matrix. Next, I performed SVD (Singular Value Decomposition) of  $X$ , so $X=U \Sigma V'$. Now I noticed a strange thing, the eigenvectors $W$ and the right singular vectors $V$ are equal (at least in magnitude), there were some differences from 4th decimal point in the values (I used Matlab), but I guess that could just be numerical error. Every odd vector in $W$ and $V$ were showing opposite signs, while every even vector of $W$ and $V$ shows same sign !! So why does this happen ?? ie I know that EVD and SVD are somehow connected, from the formulation, it looks like SVD is generalised form of EVD but I am not sure about that. But why does $V$ vectors and $W$ vectors equal in magnitude ? what does this mean intuitively ? I have used PCA and SVD and have seen the term loading matrix used for both $W$ and $V$, so I knew that should be related, But can someone explain this ?? And what is the significance of left singular vectors ? are they useful anywhere ? Finally, I have a question about Diagonal matrices. Wikipedia in its page on orthogonal matrices says that a matrix Q is orthogonal if its transpose is equal to its inverse: or $Q' = Q^{-1}$ or $QQ' = Q'Q = I$. But for diagonal matrices the first equation does not hold true, but the second equation holds true, (this is because the inverse of diagonal matrix is 1/main diagonal elements). So does that mean a diagonal matrix is not orthogonal ? Can someone clarify this difference ?","['linear-algebra', 'svd', 'eigenvalues-eigenvectors']"
457318,Lie algebra of normal subgroup is an ideal,"I want to prove that if $G$ is a connected Lie group, $H$ is a normal Lie subgroup of $G$, $\mathfrak{g}$ and $\mathfrak{h}$ their respective lie algebras, then $\mathfrak{h}$ is an ideal of $\mathfrak{g}$. I try to proceed as follows: Let $X\in\mathfrak{g}$, $Y\in\mathfrak{h}$, we want to compute $[X,Y]$ and show it is in $\mathfrak{h}$. Let $g:(-\varepsilon,\varepsilon)\rightarrow G$ and $h:(-\varepsilon,\varepsilon)\rightarrow H$ with $g(0) = h(0) = e$ be such that
$$\left.\frac{d}{dt}\right|_{t=0}g(t) = X$$
and
$$\left.\frac{d}{ds}\right|_{s=0}h(s) = Y$$
Then
$$[X,Y]=\left.\frac{d}{dt}\right|_{t=0}Ad_{g(t)}Y = \left.\frac{d}{dt}\right|_{t=0}\left.\frac{d}{ds}\right|_{s=0}g(t)h(s)g(t)^{-1}$$
Since $H$ is normal in $G$, we have that $g(t)h(s)g(t)^{-1}=\tilde{h}(s,t)\in H$ for all $t,s$. This means that differentiating $\tilde{h}$ once at the origin gives us an element of $\mathfrak{h}$, but here we have to differentiate it twice! Am I doing something wrong or there is simply a detail I'm not getting?","['differential-geometry', 'lie-algebras', 'lie-groups', 'abstract-algebra']"
457322,When can an unknown integral be written as an ODE,"I am hoping to numerically solve for the unknown function $I(t)$
\begin{align}
I(t) = \int_0^tf(x,t)\,dx
\end{align}
by converting it into one or more ODEs.  The function $f(x,t)$ is known.  If $f$ were only a function of one variable, then we trivially have
\begin{align}
\frac{dI}{dt} = f(t).
\end{align}
If $f(x,t) = g(x)h(t)$ is separable, then we can also succeed, but in general Leibniz's integral rule leads to complications. Need $f$ be separable to convert its integral into an ODE?","['multivariable-calculus', 'ordinary-differential-equations', 'integration']"
457328,Hartshorne Lemma (I 3.6),"Let $X$ be a variety, $Y \subset \mathbb{A}^n$ an affine variety and $\psi:X \rightarrow Y$ a map such that $x_i \circ \psi$ is a regular function. We want to show that $\psi$ is a morphism of varieties. Since regular functions form a ring, then for any polynomial $f \in k[x_1,\cdots,x_n]$ we have that $f \circ \psi$ is regular and so $\psi$ is continuous. Now we need to show that if $g$ is a regular function on $Y$, then for any open set $V$ of $Y$ the function $g \circ \psi: \psi^{-1}(V) \rightarrow k$ is regular. Hartshorne says that this follows since $g$ is locally a quotient of polynomials. Here is my ""objection"": to show that $f \circ \psi$ is regular, we need to show that it is locally a quotient of polynomials, where the polynomials correspond to the ""correct"" ambient space of $X$. For example, if $X$ is a projective variety, then we need $f \circ \psi$ to be a quotient of homogeneous polynomials of equal degree. In other words, $f \circ \psi$ is locally a quotient of polynomials only after passed through $\psi$... So, what am i missing here?",['algebraic-geometry']
457342,Is the countable sum of a set of measurable functions also measurable?,It is rather straightforward to show that the sum of two measurable functions is also measurable. Therefore we can extend the logic to say that $\sum\limits_{i=1}^n f_i$ is measurable providing $f_i$ is measurable. However can we take $n\rightarrow\infty$ and say that $\sum\limits_{i=1}^\infty f_i$ is a measurable function?,['measure-theory']
457352,Von Neumann's minimax theorem and Carathéodory's theorem,"In J.F. Mertens(1986) (Paywall), there's a neat proof of a version of Von Neumann's minimax theorem. But I can't understand how Carathéodory's theorem is invoked. Suppose, in a two-person zero sum game, player I's strategy space is a compact set $S$ , while player II' strategy space is a finite set $T = \{t_i\}_{1 \leq i \leq n}$ . $f : S \times T \to \Bbb R \cup \{-\infty, + \infty\}$ is player I's payoff function, which is uppersemicontinuous and bounded either from above or below. To show the mixed extension of this game has a value: I guess Carathéodory's theorem here is referred to: For $S ⊂ \Bbb R^d$ , if $x ∈ \operatorname{conv}(S)$ then $x ∈ \operatorname{conv}(R)$ for some $R ⊂ S$ , $|R| ≤ d + 1$ . I can't see how this imply that we only need to consider player I's mixed strategies with a finite support no more than $n$ .","['probability-theory', 'convex-analysis', 'game-theory', 'combinatorics']"
457371,Alternating harmonic sum $\sum_{k\geq 1}\frac{(-1)^k}{k^3}H_k$,"How to analytically prove $$\sum_{k\geq 1}\frac{(-1)^k}{k^3}H_k=-\frac{11\pi^4}{360}+\frac{\ln^42-\pi^2\ln^22}{12}+2\mathrm{Li}_4\left(\frac12\right)+\frac{7\ln 2}{4}\zeta(3) $$ As O.L answer where 
$$H_k = \sum_{n\geq 1}^{k}\frac{1}{n}.$$ Addition So far I developed the following $$\sum_{k\geq 1} \frac{H_k}{k^2} \, x^{k}  = \text{Li}_3(x)-\, \text{Li}_3(1-x)+\, \log(1-x) \text{Li}_2(1-x) +\frac{1}{2}\log(x) \log^2(1-x)+\zeta(3)$$ where $\text{Li}_3(x)$ is the trilogarithm . For the derivation see http://www.mathhelpboards.com/f10/interesting-logarithm-integral-5301/ Update A frined on another site gave the following answer","['closed-form', 'sequences-and-series', 'harmonic-numbers']"
457378,Pseudo inverse of a product of two matrices with different rank,"Let $V$ be an $n \times n$ symmetric, positive definite matrix (of rank $n$). Let $X$ be an $n \times p$ matrix of rank $p$. Define $A^- = (A^\top A)^{-1} A^\top$ as the pseudo inverse of $A$ when $A$ is of full column rank. Note that $V^- = V^{-1}$ because $V$ is invertible. I'd like to prove that $$ (VX)^- = X^- V^{-1} $$ but the only theorem I know about the pseudo-inverses of products requires that both of the matrices be of the same rank AND that the second matrix has full row rank. (To wit: If $B$ is an $m \times r$ matrix of rank $r$ and $C$ is an $r \times m$ 
matrix of rank $r$, then $(BC)^- = C^-B^-$.) There is likely something obvious I'm missing. Any clues?","['matrices', 'linear-algebra', 'inverse']"
457383,A commutative ring in which every prime ideal is 2-generated,"Suppose $R$ is a commutative ring with 1. There are some statements that tells us if prime ideals behave in certain way, then all the ideals will behave in that way. For example, If every prime ideal in $R$ is finitely generated, then every ideal in
  $R$ is finitely generated. Similarly, we have If every prime ideal in $R$ is principal, then every ideal in $R$ is
  principal. I am interested in understanding what happens when we consider ideals that are 2-generated (i.e. they have two generators). So my question is: If every prime ideal is 2-generated, then is it true that every ideal
  in $R$ needs less than or equal to 2 generators? If the answer is affirmative, I guess the natural generalization has also answer ""yes"". If every prime ideal is $k$-generated, then is it true that every
  ideal in $R$ needs less than or equal to $k$ generators? Thanks!","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
