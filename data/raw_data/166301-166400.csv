question_id,title,body,tags
2897404,Interchange of a limit and integral,How would one show the following equality? Trying standard convergence theorems eg DCT (I can't find a choice of a dominating function which is also integrable) do not appear to be successful. $$\lim_{a_n \to 0^+} \int_\mathbb{R} e^{âˆ’a_n|x|}\frac {\sin(x)}x dx=\int_\mathbb{R} \frac {\sin(x)}x dx $$ Thanks,"['integration', 'limits']"
2897434,"We are given an $18\times 18$ table, all of whose cells may be black or white.","We are given an $18\times 18$ table, all
of whose cells may be black or white. Initially all the cells are
colored white. We may perform the following operation: choose one
column or one row and change the color of all cells in this column
or row. Is it possible by repeating the operation to obtain a
table with exactly $16$ black cells? Now I wonder if a following solution is correct? All the matrix here are $18\times 18$ . Let $S$ be a matrix with all entry $1$ and $F$ be a matrix with exactly $16$ entries with $0$ and the other entries are $1$ . Let $A_i$ be a matrix with all entries $1$ on $i$ -th row, for $1\leq
i\leq 18$ and the other are 0 and with all entries $1$ on $(i-18)$ -th column for $19\leq i\leq 36$ and the other are zero.
So, for example: $$A_2 =\begin{bmatrix}
0 & 0 & \dots & 0&0\\
1&1&\dots &1&1\\
0 & 0 & \dots & 0&0\\
\vdots & \vdots & \dots & \vdots &\vdots\\
0 & 0 & \dots & 0&0
\end{bmatrix}
\;\;\;{\rm and}\;\;\; A_{19} =\begin{bmatrix}
1 & 0 & \dots & 0&0\\
1&0&\dots &0&0\\
1 & 0 & \dots & 0&0\\
\vdots & \vdots & \dots & \vdots &\vdots\\
1 & 0 & \dots & 0&0
\end{bmatrix}
$$ We can understand a table as a matrix with entry $1$ if
corresponding cell is white and $0$ if it is black. So $S$ is a
starting matrix and $F$ a final matrix. Now each recoloring of a
given matrix $M$ is actually $M+A_i$ for some $i\leq 36$ So after some transformations we have equality like this $$F = S +
a_1A_1+a_2A_2+...+a_{36}A_{36}$$ where $a_i\in \{ 0,1\}$ for all $i$ . Mark $F-S = D$ , so $D$ is a matrix with exactly $16$ ones. Now what can we say about $a_1,a_2,...$ ? Since $D$ has exactly $16$ ones it must have at least two columns and two rows with only
zeros. We can assume that all entries in first $2$ rows and first $2$ columns are $0$ , so $D$ is like: $$ D =\begin{bmatrix}
0 & 0 & 0&\dots & 0&0\\
0 & 0 &0 &\dots &0&0\\
0 & 0 & *& \dots & *&*\\
\vdots & \vdots & \vdots & \dots &\vdots& \vdots\\
0 & 0 & *&\dots & *&*
\end{bmatrix}
$$ If $a_1=1$ then each $a_{19},a_{20},...a_{36}$ must also be $1$ since in first row must be all $0$ . But then we must have also $a_2,...,a_{18}$ all $1$ since in first column are only $0$ . This
means that $D$ is a zero matrix which is not true. So $a_1=0$ and thus
all $a_{19},a_{20},...a_{36}$ are $0$ and then also all $a_2,...,a_{18}$ are $0$ so $D$ is zero matrix again. A
contradiction. This is not a duplicate. I don't want a solution like in that link, I want a proof verification!","['algebraic-combinatorics', 'solution-verification', 'linear-algebra', 'combinatorics']"
2897441,"Orthogonal family of curves to the level lines of $f(x,y)=xy-1$","Find the orthogonal family of curves to the level lines of $f(x,y)=xy-1$ . My attemp: The level lines are $$\left\lbrace(x,y)\in\mathbb R^2:xy-1=K\quad\text{for some constant }K\right\rbrace\text.$$ Differentiating both sides: $$\mathfrak F:y+xy'=0\Rightarrow\mathfrak F^\perp:y-\frac x{y'}=0\Rightarrow\mathfrak F^\perp:\frac{y^2}2-\frac{x^2}2=c\Rightarrow\boxed{\mathfrak F^\perp:y^2-x^2=C,\;C\in\mathbb R}\text.$$ Is that correct? Thanks!","['orthogonality', 'ordinary-differential-equations']"
2897478,Intuitively speaking why use geodesics to capture the idea of completeness?,"Let $(M,g)$ be a Riemannian manifold. We would like to define one notion of completeness which captures the idea of ""missing points"". For example $\mathbb{R}^n\setminus \{0\}$ should be incomplete in this sense. Now, in the Riemmanian case, the metrig $g$ gives rise to a distance function $d_g : M\times M\to [0,\infty)$ and $M$ is a metric space in the usual sense. This allows us to use the familiar idea of completeness of a metric space. We hence say that $(M,g)$ is $m$-complete (or metrically complete) if the metric space $(M,d_g)$ is complete in the sense that every Cauchy sequence converges. Now forget the metric space structure and focus just on the Riemmanian manifold structure. The usual thing to do is to say that $(M,g)$ is $g$-complete (or geodesically complete) if every inextendible geodesic is defined on the whole $\mathbb{R}$. The Hopf-Rinow theorem them says that $(M,g)$ is geodesically complete if and only if it is metrically complete. Anyway, the question is about geodesic completeness. What we want is to capture the idea that some point is missing. Well it is then natural to pick a curve and ask whether we can continuously extend it to the whole $\mathbb{R}$ or not. If we can't intuitively speaking there's a point missing. Take $\mathbb{R}^2\setminus \{(1,0)\}$ then the curve $(\cos\theta,\sin\theta)$ with $\theta \in (0,2\pi)$ cannot be extended to $\mathbb{R}$ continuously. Indeed whatever the value we set for it at $0,2\pi$ the curve will be discontinuous there. In a sense: it was going in the direction of a missing point and to extend it, it must jump. The question is: why do we need geodesics to define this? Why can't we say: $M$ is complete if every continuous inextendible curve is defined on the whole $\mathbb{R}$. The point is that I don't get why do we need the metric structure encoded in the requirement that the definition is made with geodesics to capture the idea of missing points. What is the intuition that we need geodesics/metric structure to capture the idea that there are points missing in the manifold?","['motivation', 'definition', 'intuition', 'general-topology', 'differential-geometry']"
2897495,"Is $\mathbb R$ with usual euclidean topology, homeomorphic with some topological field of positive characteristic?","Does there exists a topological field of positive characteristic which is homeomorphic with $\mathbb R$ with the usual topology ? By homeomorphism here, I mean just topological homeomorphism, not necessarily preserving any algebraic structure.","['general-topology', 'topological-rings']"
2897527,Find points of discontinuity of $x(x-1)^{2/3}e^{\sqrt[3]{x}}$,"I want to find the points of discontinuity for the following function: $$f(x)=x(x-1)^{2/3}e^{\sqrt[3]{x}}$$ My textbook says it can be derived for every number except $0$ and $1$ which could be points of discontinuity. I have no idea how it reached that conclusion without deriving the function first.  Now, I find the first derivative by using the product rule: $$f'(x)=e^{\sqrt[3]{x}}\left[{\frac {x^{4/3}-x^{1/3}+5x-3}{3(x-1)^{1/3}}}\right]$$ My textbook asks for the domain. I know that $\sqrt[3]{x}$ are defined for any $x$ so I focus on the denominator which should not be equal to $0$, therefore $3(x-1)^{1/3}\neq0\implies x-1\neq0\implies x \neq 1$. Wolfram Alpha says the domain should be $x>1$. Any hints on what I'm doing wrong?","['calculus', 'derivatives']"
2897529,Expressing polynomials as binomial coefficients,"Is there a way to check whether or not a certain polynomial function (of any degree) can be expressed as a binomial coefficient? That is to say, we have the polynomial $f(x)=n_0x^3+n_1x^2+n_3x+n_4$, how do we know if it is possible to express $f(x)$ as$\binom{ax+b}{cx+d}$? Additionally, if possible, how would one go about deriving the binomial expression algebraically? This is essentially working backwards from the expansion of a binomial coefficient.","['binomial-coefficients', 'combinatorics', 'polynomials']"
2897580,A conjecture about big prime numbers,"The fact that each prime number (greater than $9$) ends with one of the four digits $1,3,7,9$, allows us to classify the tens in which the primes are found according to which of these four digits, added to the tens, yields to a prime number. For example, for the first ten we have $1 \rightarrow \{1,3,7,9\}$. In fact, $10+1$, $10+3$, $10+7$ and $10+9$ are all primes. Conversely, for the twentieth ten the association reads $20 \rightarrow \{\}$, since there are no primes between $200$ and $209$. It is easy to see that each ten is associated to one (and only one) group of symbols, chosen among the following $16$ distinct alternatives: $\{\}$, $\{1\}$, $\{3\}$, $\{7\}$, $\{9\}$, $\{1,3\}$, $\{1,7\}$, $\{1,9\}$,  $\{3,7\}$, $\{3,9\}$, $\{7,9\}$, $\{1,3,7\}$, $\{1,3,9\}$, $\{1,7,9\}$, $\{3,7,9\}$, $\{1,3,7,9\}$. For the sake of simplicity, we can identify each of these $16$ distinct groups of symbols  with a single symbol, or with a single color , as illustrated below: Arranging the tens in a Pascal's triangle, we find (*) the following structure (omitting the first ten on the edges of the triangle): (*) I hope that my code is correct! It would be great if someone, more skilled than me, could confirm the emergence of such structure. In case you are interested in double-checking, please have a look to this post for details. However, assuming that I did not mess up too much with the code, my conjecture is that For very big tens, there cannot be colored squares other than on the outer diagonal of the triangle. In other words, big primes $p$ must be in the form $p=10^{\binom{n}{k}}+1$, or $p=10^{\binom{n}{k}}+3$, or $p=10^{\binom{n}{k}}+7$, or $p=10^{\binom{n}{k}}+9$, and $k=1$. Clearly, a weaker version of such conjecture is that $k$ can oscillate among some little integer $2,3,4,5\ldots$ (which ones?). This is probably an obvious result for the experts (I apologize, in case), nevertheless I would be glad to understand the connections between this approach and others, and also to know if there is some technique to attack  such problem. Sorry for possible naivety, and thank you very much for your comments and suggestions! EDIT: The conjecture was based on the assumption that the plot of the triangle was correct. But, as Ross has shown, that was not the case. An improved version of the code producing that plot, in fact, results in this picture:","['number-theory', 'binomial-coefficients', 'combinatorics', 'prime-numbers']"
2897596,What is the difference between a massless pinor and a spinor?,"I was reading the paper ""The Pin Groups in Physics: C, P, and T"" by M. Berg, C. Morette-DeWitt et al. in which they analyze the (double) covering groups of (Lorentzian) orthogonal groups $\operatorname{O}(s, t)$ , the so-called $\mathrm{Pin}$ -groups. In one of the sections they quickly cover the (standard) definition of $\textbf{pinors}$ as sections of a vector bundle associated to a $\mathrm{Pin}$ -bundle. As this paper is linked to quantum field theory, they consider both massless and massive pinor fields and define them as sections of vector bundels associated to $\mathrm{Pin}$ -bundles reducible to a $\mathrm{Spin}$ -bundle and $\mathrm{Pin}$ -bundles that do no admit such a reduction, respectively. On the other hand, they define a $\textbf{spinor}$ field as a section of a vector bundle associated to a $\mathrm{Spin}$ -bundle. What exactly is the difference between a massless pinor and a spinor? Lies the difference in the fact that a $\mathrm{Spin}$ -bundle is not simply a $\mathrm{Pin}$ -bundle admitting a $\mathrm{Spin}$ -reduction, but actually a specific choice of reduction?","['spin-geometry', 'quantum-field-theory', 'general-relativity', 'mathematical-physics', 'differential-geometry']"
2897607,"If $x_0=x$ and $x_{i+1}=x_i+\sqrt{x_i}$, in how many steps $x_r \ge 2x$?","In the question of the title, if I define $r(x)=\inf\{s\in \mathbb {N}:x_s\ge 2x\} $, i want to know how $r(x)$ behaves asymptotically, more precisely to know if $\lim\limits_{x\rightarrow \infty} \dfrac {r(x)}{\sqrt{x}}$ exists, and in that case,to find that limit.",['real-analysis']
2897610,Vector Space with unusual addition?,"I'm studying before my class starts in a few weeks and I encountered this question in one of the practice problems: The addition it has given me is defined as, $(a,b)+(c,d)= (ac,bd)$ It's asking me if this is a vector of space and I am stuck after proving this, There is an element $0$ in $V$ so that $v + 0 = v$ for all $v$ in $V$. I did this -> $(a,b)+(1,1) = (1a,1b) = (a,b)$ Stuck right here, For each $v$ in $V$ there is an element $-v$ in $V$ so that $v+(-v) = 0$. $(a,b)+(0,0) = (0a,0b) = (0,0)$ Is $(0,0)$ $a$ $-v$ when there's no such thing as '$-0$'? Do I stop proving right at the step? So this is not a vector of space? Thank you for your time. Edit: Thank you everyone! The question is stated exactly like so, Show that the set of ordered pairs of positive real numbers is a vector space under the addition and scalar multiplication.
  $$(a,b)+(c,d) = (ac,bd),$$
  $$c(a,b) = (a^c, b^c).$$ So the additive inverse is an element that, when added to $(a,b)$, will give me the additive identity, which in this case is $(1,1)$?","['linear-algebra', 'vector-spaces']"
2897619,"If $f:\Bbb{R}^{+}\to\Bbb{R}^n,\;t\mapsto f(t)=\Vert x(t)\Vert^2,$ then $f$ is differentiable","Assuming that $x:\Bbb{R}^{+}\to\Bbb{R}^n$ be differentiable. I want to prove that \begin{align}f:\Bbb{R}^{+}\to\Bbb{R}\end{align}
\begin{align}t\mapsto f(t)=\Vert x(t)\Vert^2\end{align}
is differentiable and then, compute
\begin{align}\frac{d}{dt}\Vert x(t)\Vert^2\end{align}
where $\Vert x\Vert$ is the Euclidean. MY WORK I know that the answer is: 
\begin{align}\frac{d}{dt}\Vert x(t)\Vert^2=2\dot{x}\cdot x\end{align}
but I want to prove it. Nevertheless, I am thinking of using composition of functions and then use bilinearity. So, I have \begin{align}k:\Bbb{R}^{+}\to\Bbb{R}^n\backslash {0}\times \Bbb{R} \end{align}
\begin{align}t\mapsto (x(t),\langle x(t),x(t)\rangle)\end{align}
and 
\begin{align}g:\Bbb{R}^n\backslash {0}\times \Bbb{R}\to \Bbb{R} \end{align}
\begin{align}(x(t),\langle x(t),x(t)\rangle)\mapsto \Vert x(t)\Vert^2\end{align}
Then, $f=g\circ k$ so that \begin{align}f'(x)(k)=g'\left(h(x))(h'(x)k\right)\end{align}
\begin{align}=g'\left((x(t),\langle x(t),x(t)\rangle))(x'(t),2\Vert x(t)\Vert^2 x'(t)\right)\end{align}
\begin{align}=g\left((x(t),2 \langle x(t),x(t)\rangle x'(t)))+g(x'(t),\langle x(t),x(t)\rangle\right)\end{align}
Even with this approach of mine, I'm not seeing a way-through! Any help please?","['multivariable-calculus', 'calculus', 'derivatives', 'ordinary-differential-equations']"
2897625,"Meaning of expression : ""uniquely determined""","I am having difficulty understanding (also because of my native language) the expression that is widely used in mathematics: ""Uniquely Determined"". For example: $1)$ Cat theorem asserts that the color of the cat $C$ is uniquely determined by its breed $b(C)$ . In this example $ 1) $ it is correct to understand that each breed of cat determines a single color? That is, cats of the race $ X $ can only be, say, blue and never of another color? And the reciprocal, is it also true? That is, if we have a green cat, can we say that it can only be (solely) a single specific breed? An example, minus ""Alice in Wonderland"", the following example is really what interests me: $2)$ ""(...)
The previously given forms of Torelli's theorem follow at onlce from the remark that the symmetric product $(X)^{(g-1)}$ is birationally equivalent to the canonical $\Theta$ -divisor on $J(X)$ , and the fact, proved by A. Weil, that the canonical polarization determines uniquely the $\Theta$ -divisor."" In this example $2)$ it is correct to state that: the canonical polarization of $J(X)$ determines a single $\Theta$ -divisor?
Is it also reciprocal? That is, given a $\Theta$ -divisor to it is associated a single polarization? Thank You!","['algebraic-curves', 'proof-writing', 'notation', 'algebraic-geometry', 'terminology']"
2897631,About the integral $\int_0^{\pi/2} \cos^n(x)\cos(nx) \;dx$ and $\int_0^{\pi/2} \cos^n(x)\sin(nx) \;dx$.,"About the integral $\displaystyle\int_0^{\pi/2}\cos^n{x}\cos{nx} dx$ and $\displaystyle\int_0^{\pi/2} \cos^n{x}\sin{nx} dx$. The value of the first one contains $\pi$ , However, I tried to calculate them by integrating by parts as follows. Let $I(m,n)$ denote the integral $\displaystyle\int_0^{\pi/2} \cos^m{x}\cos{nx} dx$, we have $$
 \begin{split}
I(m,n)&=\displaystyle\int_0^{\pi/2} \cos^m{x}\cos{nx}\,dx=\dfrac{1}{n}\displaystyle\int_0^{\pi/2} \cos^m{x}\,d(\sin{nx})\\
&=\dfrac{1}{n}\cos^m{x}\sin{nx}\biggr|_0^{\pi/2}-\dfrac{m}{n}\displaystyle\int_0^{\pi/2} \sin{nx}\cos^{m-1}{x}\sin{x}\,dx\\
&=-\dfrac{m}{n}\displaystyle\int_0^{\pi/2} \sin{nx}\cos^{m-1}{x}\sin{x}\,dx\\
&=\dfrac{m}{n^2}\displaystyle\int_0^{\pi/2} \cos^{m-1}{x}\sin{x}\,d(\cos{nx})\\
&=\dfrac{m}{n^2}\cos^{m-1}{x}\sin{x}\cos^{nx}\biggr|_0^{\pi/2}-\dfrac{m}{n^2}\displaystyle\int_0^{\pi/2} \cos{nx}\,d(\cos^{m-1}{x}\sin{x})\\
&=-\dfrac{m}{n^2}\displaystyle\int_0^{\pi/2}\cos{nx}(\cos^m{x}+(m-1)\cos^{m-2}{x}\sin^2{x})\,dx\\
&=-\dfrac{m}{n^2}\displaystyle\int_0^{\pi/2} \cos{nx}\cos^m{x}\,d{x}-\dfrac{m(m-1)}{n^2}\displaystyle\int_0^{\pi/2} (1-\cos^2{x})\cos^{m-2}{x}\cos{nx}\,d{x}\\
&=\dfrac{m(m-2)}{n^2}\displaystyle\int_0^{\pi/2} \cos{nx}\cos^{m}{x}\,d{x}-\dfrac{m(m-1)}{n^2}\displaystyle\int_0^{\pi/2} \cos^{n-2}{x}\cos{nx}\,d{x}\\
&=\dfrac{m(m-2)}{n^2}I(m,n)-\dfrac{m(m-1)}{n^2}I(m-2,n),
\end{split}, 
$$ That is, $$I(m,n)=-\dfrac{m(m-1)}{n^2-m^2+2m}I(m-2,n),$$ Then we can calculate $I(m,n)$ by calculating $I(0,n)$ and $I(1,n)$. I can't see where $\pi$ occurs. Or I'm on the wrong way... ? I don't know. Anyone can help me?","['integration', 'calculus', 'definite-integrals']"
2897635,"Does the limit of $\cos^{2n}(n)$, with $n$ a positive integer, converges as $n\to\infty$?","I'm struggling with what it seems to be a pretty simple limit: $$\lim_{n \rightarrow \infty} \cos^{2n}(n)$$ I have arguments to believe that this limit converges to $0$ because $n \in (kÏ€, (k+1)Ï€) $ and $\cos[(k\pi, (k+1)\pi)] \rightarrow 0 $ as $n$ increases. But also I believe that this limit may diverge, because you can always find an integer that is closer to a multiple of $\pi$ (by Dirichlet's approximation theorem), so you may find a subsequence that converges to 1, and so this limit diverges. Many thanks in advance!!","['trigonometric-series', 'irrational-numbers', 'real-analysis', 'sequences-and-series', 'limits']"
2897651,"Cohn, Exercise 2.4.11, Intuition behind my solution?","Here's the problem. Let $(X, \mathscr{A}, \mu)$ be a measure space, and let $f,f_n$ be nonnegative functions that belong to $\mathscr{L}^1(X, \mathscr{A}, \mu, \mathbb{R})$. Prove that if $f_n \to f$ $\mu$-almost everywhere and $\int f_n \to \int f$, then $\int |f_n - f| \to 0$. Note that $|f_n - f| \leq f_n + f$, so $g_n := f_n + f - |f_n -f| \geq 0$. Fatou gives $\int \liminf_n g_n \leq \liminf_n \int g_n$. 
Notice that $g_n \to 2f$, almost everywhere. Since the limit inferior is sub-additive, this means:
$$
\int 2f = \int \liminf_n g_n \leq \liminf_n \int g_n \leq \int 2f + \liminf_n - \int |f_n - f|
$$
Since $\liminf -a_n = -\limsup a_n$, we have $\limsup_n \int |f_n -f| \leq 0$, which implies the claim. It took me a while to find this solution. Assuming it is correct, can someone help me understand why the definition of $g_n$ is natural in some sense here? I think this proof mechanically works, but isn't very intuitive to me.","['proof-explanation', 'measure-theory', 'proof-verification']"
2897668,Symmetric differences and measure theory.,"Let $E \subset \mathbb{R}^{d}$. Suppose that, for any $\epsilon > 0$, there is a measurable $F \subset \mathbb{R}^{d}$ such that
  $$m_{\ast}(E \triangle F) < \epsilon.$$
  Show that $E$ is measurable. I need to show that: for any $\epsilon > 0$, there is an open $O$ with $E \subset O$ such that $m_{*}(O - E) \leq \epsilon$. This question doesn't seem to require specific properties of measure theory. It seems viable to try to show that it is worth the definition. But I couldn't find a good way, maybe some specific property of symmetric differences would be useful. I don't like the answer of the question, I just wanted a hint to try. Thanks for the advance!","['measure-theory', 'real-analysis']"
2897673,Continuity at a point for function of two variables,"If a function of two variables is discontinuous at a particular point, say $(x,y)$, does this mean that the graph of that function has some hole around the point $(x,y,f(x,y))$? Is there any break in the graph at this point in certain direction? This question arises because I have one function which is discontinuous at $(0,0)$ but all of its partial derivatives and directional derivatives exist at $(0,0)$. While calculating its partial or directional derivatives, we naturally look in a certain plane with that point and specified direction and calculate the slope of the tangent line (as you would with one variable). In my example I have all directional derivatives, which seems to imply that there is no break around $(0,0,f(0,0))$ in any direction. Then why is the function discontinuous at $(0,0)$?",['multivariable-calculus']
2897680,"If $2^\mu$ and $2^\lambda$ are isomorphic as boolean algebras, is it true that $\mu = \lambda$?","The content of this question is: Is what I am going to say correct? It is well known that given two cardinals $\lambda < \mu$ it might be the case that $2^{\lambda} = 2^{\mu}$. Even stronger, the Easton theorem says that it is consistent with ZFC to force some of these equalities. This means that there might be a bijection between the set $2^\lambda$ and the set $2^\mu$. On the other hand I claim that this correspondence cannot be a morphism of boolean algebras. In fact, the following seems to hold. Lemma Let If $2^\mu$ and $2^\lambda$ are isomorphic as boolean algebras then $\mu = \lambda$. By boolean algebra morphism I mean a function that preserve sups and inf. The proof is very simple. Such a map $\phi$ would preserve completely join-irreducible elements. In a boolean algebra those correspond to the atoms of the boolean algebra. Thus $\phi$ restrict to a bijection of the atoms, which is the thesis.","['boolean-algebra', 'logic', 'order-theory', 'lattice-orders', 'elementary-set-theory']"
2897685,Proving the index of a subgroup,"For the group $G=\{a+b\sqrt 2 \mid a,b\in\mathbb Z\},$ and the subgroup $H=\{3m+2n\sqrt 2 \mid m,n \in\mathbb Z\},$ I want to prove that the index of $H$ in $G$ is six. On this problem I have guessed that the cosets are of the form
$(3m)(2n),
 (3m)(2n),
(3m+1)(2n),  (3m+1)(2n+1),
(3m+2)(2n),  (3m+2)(2n+1)$ And that they act like $\mathbb Z_3 \times\mathbb Z_2$ and its cosets? How can I proceed in proving that the index is indeed six?",['group-theory']
2897694,"$f(x)-2f(\frac{x}{2})+f(\frac{x}{4})=x^2$ , find $f(x)$","Find $f(x)$ if $f(x)-2f(\frac{x}{2})+f(\frac{x}{4})=x^2$, where $x, f(x)\in (-\infty , \infty)$ and $f(x)$ is continuous.",['functions']
2897746,What is an upper bound on the minimum angle between approximately equally spaced points on a n-dimensional unit hypersphere?,"If we have a unit hypersphere, with ""approximately"" evenly spaced points$^1$, is there any good upper bound on the minimum angle between nearby points? On a unit circle, for $N$ equally spaced points, the minimum angle would be $2\pi/N$. For a unit sphere, we can use the area of a spherical cap to get us a upper bound of the angle: $$
A = \frac{4\pi}{N} = 2\pi \left(1-\cos(\theta)\right) \\
\theta = \cos^{-1}\left(1 - \frac{2}{N}\right)
$$ Where $\theta$ here should be half of the angle between two neighboring points.  This is an upper bound because it assumes we are completely covering the surface with circles around each point, which we can't do.  The actual circles around each point would have to be smaller, so our angle would be smaller. But what about for a higher dimensional hypersphere? Addendum: As Ross noted, the sphere packing density comes into play in this problem, which will likely make it intractable in higher dimensions... I looked up the sphere packing densities (in Euclidean space, which is probably fine for large enough $N$) at Mathworld .  The first 8 dimensions are the only ones that are listed (and I believe known), and they fall off fairly quickly with dimension (it looks close to linear for the first 8, but it is likely exponential or similar), in 8 dimensions the packing density is roughly .25. An idea -- though it depends on getting a decent approximation for the sphere packing density in higher dimensions -- would be to use the sphere packing density to correct the area.  In 3 dimensions: $$
A = \delta_2 \frac{4\pi}{N} = \dots\\
\theta = \cos^{-1}\left(1-\delta_2 \frac{2}{N}\right)
$$ where $\delta_2$ is the sphere packing density for 2 dimensions. More: These lecture notes give an lower bound of the packing density of $2n\cdot2^{-n}$, and an upper bound of 
$2^{-0.599n}$, which have a pretty wide gap, but are enough to bound the problem at least. $^1$ I realize that it isn't really trivial to find such a spacing of points on a hypersphere, but an approximation is fine.",['geometry']
2897750,A Smooth Function with Peculiar Properties,Suppose $f:\mathbb R^n\to\mathbb R$ is a smooth function and define $E_f := \{x\in\mathbb R^n\;|\;f(x)=0\text{ and }\nabla f(x)\ne 0\}$. Can we find $f$ such that $E_f$ has positive $n$-dimensional Lebesgue measure?,"['calculus', 'smooth-functions', 'measure-theory', 'real-analysis']"
2897758,Cross Normal to a Closed Curve,"Does every closed, smooth, non-self-intersecting loop have at least one point in the interior from which two perpendicular lines can be drawn with each intersecting the loop at 90Â° at all four points of intersection?",['geometry']
2897761,How to show a real valued function of several variables is analytic?,"Let $f:\Omega\subset\Bbb{R}^m\to\Bbb{R}^n$ be a given function. In general, how can I show that $f$ is smooth (infinitely differentiable) and analytic. I know this is a bit vaguely stated question, but I just need a general idea about showing smoothness and analyticity. If you can give me some examples that would be great. PDF's and other sources are also welcome.","['analyticity', 'smooth-functions', 'real-analysis', 'multivariable-calculus', 'analytic-functions']"
2897766,Mixed formulation with Volterra integrals?,"I'm going straight to the point. When gathering Volterra equations of the second kind with mixed formulations, one can arrive to the following problem: Let $X,M$ Hilbert spaces and $\mathcal{J}=[0,T]$, with $T<\infty$. Find $(u,\lambda):\mathcal{J}\rightarrow X\times M$ such that \begin{equation}
\label{linear-mixed-problem1}
\begin{aligned}
Au(t) +B'\lambda(t) &=f(t) + \int_{0}^{t}\big[\widehat{A}(t,\tau)u(\tau)+ \widehat{B}'(t,\tau)\lambda(\tau)\big]d\tau,\\
Bu(t)&= \int_{0}^{t}\widehat{B}(t,\tau)u(\tau)d\tau\hspace{0.1cm},
\end{aligned}
\end{equation} a.e. in $\mathcal{J}$. Here $A\in \mathcal{L}(X;X'), B\in\mathcal{L}(X;M')$ and $B'\in\mathcal{L}(M;X')$ are  time-independent linear elliptic partial differential operators acting on an open bounded domain $\Omega\in \mathbb{R}^n$, with $A$ a self-adjoint operator and $B'$ the dual operator of $B$. The functions $f\in X'$ a.e. in $\mathcal{J}$ is a given load, and we assume that appropriate boundary conditions are given. The operators $\widehat{A}(t,\tau), \widehat{B}(t,\tau)$ and $\widehat{B}'(t,\tau)$ satisfies a ""similarity"" condition to $A,B$ and $B'$, respectively. Observe that a weak formulation can be achieved. The big question is: Is this problem make sense?. Any clue or references about how to attack it (well-posedness)?. Thanks.","['ordinary-differential-equations', 'calculus-of-variations', 'convolution', 'finite-element-method', 'functional-analysis']"
2897794,$M$ is orientable iff $\bigwedge^n TM \setminus \{ \text{$0$-section} \}$ has $2$ connected components,"Let $M$ be an manifold of dimension $n$. We say that $M$ is orientable if it has an $n$-form that doesn't varnishes in any point if $M$. My question is about the following claim: $M$ is orientable if and only if $\bigwedge^n TM \setminus \{ \text{$0$-section}\}$ has $2$ connected components. Is it true? If yes, how can I see it?","['vector-bundles', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
2897814,$H$ is normal subgroup of $G$ iff $gHg^{-1}=H$ for every $g$ of $G$,"Given the following definition of normal subgroup A subgroup $H$ of a group $G$ is said to be normal if, for every $g\in G$: $$gH=Hg$$ I've tried to show that $H\mathrel{\unlhd} G$ if and only if we have $gHg^{-1}=H$ for every $g\in G$: (if) Let $H\mathrel{\unlhd} G$, $g\in G$; if $l\in gHg^{-1}$, there exists $h\in H$ such that $l=ghg^{-1}$ and since $gh$ = $h'g$ for some $h'\in H$, then $l=ghg^{-1}=h'(gg^{-1}) = h'\in H$. Let $h\in H$; we can write $h$ as $hgg^{-1}$, and since $hg = gh'$ for some $h'\in H$, we obtain $h = hgg^{-1} = gh'g^{-1}\in ghg^{-1}$. So $gHg^{-1}=H$. (only if) Let $gHg^{-1}=H$, $g\in G$; if we take an $l\in Hg$, $l = hg$ for some $h\in H$, we note immediately that $l=hg=(gh'g^{-1})g=gh'\in gH$. What should I do to show that $gH\subset Hg$ ? I'm also wondering if this mess is correct, and if it is possible a more elegant proof of this fact.","['normal-subgroups', 'abstract-algebra', 'proof-verification']"
2897831,Crossing problem - a puzzle,"I ran across the following problem in Barret O'Neill's Elementary Differenetial Geometry: ""Let C be a Curve in the xy plane that is symmetric about the x axis. Assume C crosses the x axis and always does so orthogonally. Explain why there can be only one or two crossings. Thus C is either an arc or is closed."" I see that $(cos(t),sin(t)cos(t))$ makes a figure eight with three crossings; the middle crossing is not orthogonal, but it seems that you could deform the curve in a continuous fashion so that the crossing would be orthogonal. Does this mean O'Neill was wrong? O'Neill defines a curve as a differentiable function from an open set of R into $E^3$ and mentions in a remark that the velocity should be nonzero. My ""figure 8"" has zero velocity periodically.",['differential-geometry']
2897850,"A Question on certain Hilbert space of continuous functions, and a characteristic of convergence in it","Define $T^k(\Omega)$, $\Omega$ an open subset of $\mathbb{R}^m$ (with a smooth boundary), as a space of function equivalance classes, with the norm defined as $$ \|f\|_{T^k(\Omega)}^2 =     \|f\|_{L^2(\Omega)}^2 + \|(\sum\limits_{i=1}^m(\frac{\partial^{k}f}{\partial x_i^{k}})^2)^{\frac{1}{2}}\|_{L^2(\Omega)}^2 $$ It can be easily noted that $T^k(\Omega)$ is a Hilbert space. Also note that this norm is not a Sobolev norm, as we don't consider cross derivatives. Consider the set $$M = C^0(\bar{\Omega}) \cap T^k(\Omega)  $$ Prove that : If $k > \frac{m}{2}$, every sequence $\{f_n\},f_n \in M$, that converges in the norm $\|.\|_{T^k(\Omega)}$, also converges in the norm $\|.\|_{C^0(\bar{\Omega})}$ (and to a limit $f \in M$) Proof : Consider a sequence $f_n \in M$ and let $f_n\to f \in M$ in the norm $\|.\|_{T^k(\Omega)}$ Idea is to add a small perturbation in the form of a shrinking bump, to produce a simple discontinuity in the limit function $f$. Lets add a small bump function $\psi(n\boldsymbol{x})$ to $f_n(\boldsymbol{x})$ to form a new sequence $$\phi_n(\boldsymbol{x}) = \psi(n\boldsymbol{x}) + f_n(\boldsymbol{x}) $$ Now we show that, in doing so, we blow up the norm and spoil the convergence of the sequence.
For simplicity, assume $\psi_n(\boldsymbol{x}) = \psi(n\boldsymbol{x})$ is radially symmetric. With a change of variable $\boldsymbol{t} = n\boldsymbol{x}$  we can easily see that  $$\|f_n(\boldsymbol{x}) + \psi(n\boldsymbol{x})\|_{L^2(\Omega)} \to \|f\|_{L^2(\Omega)}$$ But when we consider the other term of the norm, again with a change of variable $\boldsymbol{t} = n\boldsymbol{x}$, we can see that $$\begin{align} \int_{\Omega} |\frac{\partial^k{\phi_n}}{\partial{x_i^k}}|^2 \mathop{}\!\mathrm{d}^m\boldsymbol{x} & = \int_{\Omega}|\frac{\partial^k{f_n}}{\partial{x_i^k}}|^2 \mathop{}\!\mathrm{d}^m\boldsymbol{x} + 2\int_{\Omega}\frac{\partial^k{f_n}}{\partial{x_i^k}} \frac{\partial^k{\psi_n}}{\partial{x_i^k}}\mathop{}\!\mathrm{d}^m\boldsymbol{x} +  \int_{\Omega}|\frac{\partial^k{\psi_n}}{\partial{x_i^k}}|^2 \mathop{}\!\mathrm{d}^m\boldsymbol{x} \\\\ & = \|\frac{\partial^k{f_n}}{\partial{t_i^k}}\|_{L^2}^2 + O(n^{(k-m)}\|\frac{\partial^k{f_n}}{\partial{t_i^k}}\|_{L^2} \|\frac{\partial^k{\psi}}{\partial{t_i^k}}\|_{L^2}) +  n^{(2k-m)}\|\frac{\partial^k{\psi}}{\partial{t_i^k}}\|_{L^2}^2\end{align} $$ The last term blows up, when $k > \frac{m}{2}$. So one cannot produce a discontinuity by way of adding a shrinking bump. Hence all sequences in $M$ that converge in the norm $\|.\|_{T^k(\Omega)}$ also converge in the norm $\|.\|_{C^0(\bar{\Omega})}$ Other cases : For a jump discontinuity, we let the bump have a flatter region and we shrink only the transition region. Same logic applies here. For a blow up situation, consider $\phi_n(\boldsymbol{x}) = g(n)\psi(n\boldsymbol{x})$, where $g(n) = \omega(1)$ ( Bachmannâ€“Landau notations ), which means $g(n)$ grows faster than 1, or $\lim\limits_{n\to\infty}g(n) = \infty$. In this case, one can see that the last term in the RHS of the last equation in my proof, blows up when $k\ge\frac{m}{2}$. Hence blow up discontinuity is also ruled out in case of $k>\frac{m}{2}$. Case of Oscillatory discontinuity remains: For oscillatory case consider $\phi_n(\boldsymbol{x}) = \sin(n\boldsymbol{x})\psi_(n\boldsymbol{x})$ Question : Is the above proof complete?(if at all it makes sense) Is there any simpler proof with a direct application of a well known theorem? Similar references appreciated. For $\Omega = [0,1)^m$, with periodic boundary conditions, this norm is equivalent to Sobolev norm, hence by general Sobolev inequality, the result follows. But I am seeking a direct proof as in this approach, without invoking Sobolev inequality.","['partial-differential-equations', 'sobolev-spaces', 'functional-analysis', 'real-analysis']"
2897975,Random Dental Floss Odds,"Awhile back I bought 2 identical rolls of dental floss, each with 50 uses, and picked them randomly.  Tonight, the one I picked hit the 50 use mark.  What is the expected number of uses in the remaining roll? With a 100000 case brute force, I get an expected answer of 8 uses.  Neat, so I have maybe a week. What is the non-brute force answer?",['probability']
2897976,Automorphism group of union of varieties,"A projective hypersurface $\mathcal{V}(F)$, given by a homogeneous polynomial $F$, can always be expressed as the union of its affine components $\mathcal{V}(F_{i})$, where $F_{i}=F(x_{1},\ldots,x_{i-1},1,x_{i+1},\ldots,x_{n})$ is the $i$-th dehomogenisation. That is we have
$$\mathcal{V}(F)=\bigcup_{i=1}^{n}\mathcal{V}(F_{i}).$$
My question is; is there any relationship between the automorphism group of the projective hypersurface, $\mathrm{Aut}(\mathcal{V}(F))$, and the affine automorphism groups, $\mathrm{Aut}(\mathcal{V}(F_{i}))$? To me it seems that each automorphism of $\mathcal{V}(F)$ should act either as an isomorphism between pairs of its affine components $\mathcal{V}(F_{i})$ and $\mathcal{V}(F_{j})$, $i\neq j$, or as an automorphism on each $\mathcal{V}(F_{i})$. So then it should be the case that each $\mathrm{Aut}(\mathcal{V}(F_{i}))$ is a subgroup of $\mathrm{Aut}(\mathcal{V}(F))$?","['automorphism-group', 'algebraic-geometry', 'projective-geometry']"
2897993,prove that there exists no integer in $\pm\frac1k \pm \frac1{k+1}\pm\frac1{k+2}...\pm\frac1{k+n} $,"Prove that there exists no integer among the $2^{n+1}$ numbers $$\pm\frac1k \pm \frac1{k+1}\pm\frac1{k+2}...\pm\frac1{k+n} $$ That is, $$\mathbb{Z} \cap \left\lbrace \frac{\delta_0}{k} + \frac{\delta_1}{k + 1} + \ldots + \frac{\delta_n}{k+n} : \delta_0, \ldots, \delta_n \in \lbrace -1, 1 \rbrace \right\rbrace = \emptyset$$ This is a discrete maths homework question with another part preceding it which wants us to prove that ""in any block of consecutive positive integers there is a unique integer divisible by
a higher power of $2$ than any of the others"". This I could prove (by negation) so you can use this statement to answer the question . Any suggestions of approaches to the problem are welcome.","['number-theory', 'discrete-mathematics', 'elementary-number-theory']"
2898005,Measure of a set invariant under translations with rational numbers,Suppose $E\subset\mathbb{R}$ is measurable and $E=E+\frac{1}{n}$ for every natural number $n\geq1$. Show that either $m(E)=0$ or $m(\mathbb{R}\setminus E)=0$.,"['measure-theory', 'lebesgue-measure', 'real-analysis']"
2898010,Limit as $x \to \infty$ of $\frac{\log(x)^{\log(\log(x))}}{x}$,"I want to compute $\lim\limits_{x \to \infty}\frac{\log(x)^{\log(\log(x))}}{x}$ By graphing it, clearly $x$ grows larger than $\log(x)^{\log(\log(x))}$, so the limit will go to $0$. I tried iterating L'Hopital's rule, but after three derivations, the sequence of limits gets successively more complicated. How can you prove that the limit is indeed $0$?",['limits']
2898020,A cornucopia of confusion on limits?,"I am having a lot of confusion in my multivariable calculus lectures. We usually see that we can try to approach a certain limit with paths and if two paths yield different ""limits"", then the limit does not exist. But finding ""limits"" via any number of different paths does not guarantee the limit exist, in previous lectures, it was not clear if polar coordinates were a considered a kind of path, but the professor didn't say it wasn't. It was said that only the $\epsilon-\delta$ definition actually guarantees the limit exist. In a local calculus book, I found the following theorem (which was also presented in previous calculus lectures): If $\displaystyle \lim_{(x,y)\to {(x_0,y_0)}}f(x,y)=0$ and $|g(x,y)|\leq M$ for $0<|(x,y)-(x_0,y_0)|<r$ with $r>0, M>0$ fixed real numbers, then: $$\lim_{(x,y)\to {(x_0,y_0)}}f(x,y)g(x,y)=0$$ I tried to use it in the following two cases: $$\lim_{(x,y)\to (0,0)} \frac{xy}{\sqrt{xÂ² + yÂ²}} $$ Here we see that: $$\lim_{(x,y)\to (0,0)} \frac{xy}{\sqrt{xÂ² + yÂ²}} = x \frac{y}{\sqrt{xÂ² + yÂ²}} $$ And it's easy to see that $\frac{y}{\sqrt{xÂ² + yÂ²}}$ is bounded and we can use the previous thorem, also Wolfram Alpha asserts it exists. $$\lim_{(x,y)\to (0,0)} x \sin \left( \frac{1}{xÂ²+yÂ²} \right)$$ Now, it seems a lot that $\left |\sin \left( \frac{1}{xÂ²+yÂ²} \right)\right|\leq 1$ and that we can apply our theorem, but Wolfram Alpha says the limit does not exist. Now, as I said before, it was said that approaching via any number of paths does not prove that a limit indeed exists and it was not clear wheather the approach via polar coordinates is considered a ""path"" (although, to me, it looks like something very diferent than the paths $y=mx$ , for example), now there is a new professor who gave us a list of exercises with the following proposition: Given $f: D \subset \Bbb{R}Â² \to \Bbb{R}$ , then $$\lim_{(x,y)\to0 } f(x,y)=L \iff \lim_{r\to0} f(r\cos \theta,r \sin \theta)=L$$ uniformly in $\theta$ .
That is, the limit exists iff the radial limit of $f$ does not depend on $\theta$ . But what is ""uniformly""? What is ""does not depend""?
I have tried to use it on the second example, it gives me: $$\lim_{r\to 0} r \cos \theta \sin\left(\frac{1}{rÂ²}\right) $$ And then I assumed that ""does not depends"" means that no part of the formula contains $\theta$ . But upon inspecting my first example, it gives me: $$\lim_{r\to 0} r\cos \theta \sin \theta $$ If I assume this meaning for ""does not depend"", then this limit does not exist, but the other theorem asserts it does and I have also verified on Wolfram Alpha. I have talked with this professor, she said me that the theorem on radial limits is true and that she saw it in a book (I never saw it anywhere), I asked her the title of the book and am still waiting a response, she also said that the polar coordinates are not really a ""path"". From this, I have these questions: Is the first theorem actually a theorem? Is the second theorem actually a theorem? Where can I find a proof of it? I googled a bit something like ""polar coordinate limits"" and ""radial limits"" but didn't find anything that seemed relevant. I am asking if it is true because if it is, I still can't prove it. If the first theorem is true, then where am I making any mistake? I suspect I may be misreading the condition of the distance bounded by $r$ . What is the meaning of ""depend"" and ""uniformly""? I have noticed the following possibility (may be wrong): $$\lim_{r\to 0} r \cos \theta \sin\left(\frac{1}{rÂ²}\right) =\cos \theta \lim_{r\to 0} r  \sin\left(\frac{1}{rÂ²}\right) $$ and I know that $$\lim_{r\to 0} r  \sin\left(\frac{1}{rÂ²}\right)=0$$ and $|\cos x| \leq 1$ , so what could possibly go wrong if we take a different $\theta$ ? It really seems that a change in $\theta$ won't change the limit.","['limits', 'multivariable-calculus', 'analysis', 'real-analysis']"
2898057,What are Distance Regular Graphs,"I have been trying to understand distance regular graphs and how to compute the intersection array. Distance Regular Graphs , this is the resource I have used. I could not figure what is br in Î´(v,u)=r.br Secondly cr in cr is the number of vertices that are adjacent to u and a distance of r âˆ’ 1 from v Lastly the two clauses for intersection array in the given link. â€‹
P.S : I need its concept to understand a paper, would appreciate the help","['graph-theory', 'combinatorics']"
2898079,What is the probability that a normal number will look periodic?,"Let's take for example $\pi$. The numbe $\pi$ is irrational, hence the decimal pattern is non-periodic. However, could it happen, that by just observing a huge but finite amount of digits of $\pi$, it would ""look periodic"" ? It is not known, but it is conjectured that $\pi$ is a normal number , i.e. any sequence of digits of length $n$ occurs with density $10^{-n}$. So let's assume this is true, and then ask what is the probability that for some sufficiently large $n$, $\pi$ looks like $$\pi\approx 3.\underbrace{x_1x_2\cdots x_n}_{\text{first period}}\overbrace{x_1x_2\cdots x_n}^{\text{second period}}\underbrace{\cdots}_{\llap{\text{other}}\,\rlap{\text{digits}}}\;.$$ Of course, this question is not really restricted to $\pi$ or to digits of numbers, but can be asked in the context of normal sequences (joriki pointed out in the answer that for a specific number the probabilit is always one or zero). Remark. I know that general periodic number can have the form $$0.x_1x_2\cdots x_n\overline{y_1y_2\cdots y_m}$$ with an initial non-periodic sequence $x_1x_2\cdots x_n$. But since in a normal number any finite sequence occures, it is certain that any sequence will also repeat an arbitrary amount of times. The question is specifically about whether such a period can start with the first digit.","['stochastic-processes', 'pi', 'probability-theory']"
2898126,Affine cone over the Grassmannian,"I'm currently working on understanding the affine cone over the Grassmannian, which according to my paper is given by 
$$\text{Spec}(K[p_{ij}^{\pm} : ij \in \binom{\lbrack n \rbrack}{2} ] / I_{2,n}).$$ I know that for the standard projection $p: \mathbb{A}^{n+1} \setminus \{0\} \rightarrow \mathbb{P}^n$ and $Y$ a projective variety given by $Y=V(I)$ for some homogeneous ideal $I \subseteq K[T_0, \dotsc, T_n]$, the affine cone is given by 
$$ C(Y)= p^{-1}(Y) \cup \{(0, \dotsc, 0)\}=V_\text{aff}(I) \cup \{(0, \dotsc, 0)\}.$$ So I tried to argue that, as we have $Gr(2,n)=V(I_{2,n})$ and that for a commutative unital ring $R$, the closed subset $V_\text{aff}(I)$ of Spec($R$) may be identified with Spec$(R/I)$, this would provide me with
$$ C(Gr(2,n))=\text{Spec}(K[p_{ij} : ij \in \binom{\lbrack n \rbrack}{2} ] / I_{2,n}) \cup \{(0, \dotsc, 0)\}.$$ My question : How is this equal to the claim? I.e. how do I get the power $\pm 1$? Respectively where is my mistake? Thank you very much!","['affine-varieties', 'grassmannian', 'algebraic-geometry']"
2898168,Can this basic fact in linear algebra be formulated as a completeness result?,"Suppose we have a system of linear equations $S$. If $E$ is some linear equation, we'll say that $E$ is a logical consequence of $S$ if whenever a vector satisfies $S$, it satisfies $E$. Now, in a first course in linear algebra we're taught one simple way to prove that an equation $E$ is a logical consequence of $S$: express it as a linear combination of equations in $S$. But notice that in theory, there could be equations $E$ which are logical consequences of $S$, and yet are not linear combinations of equations in $S$: maybe linear consequence is a strictly stronger notion that mere logical consequence . Well, it turns out this isn't the case . Taking linear combinations is a sufficiently powerful technique to derive all equations which follow from $S$. Now, this definitely feels like a kind of logical completeness result. We could say that we have the following axioms: the equations of $S$, and the axiom that if two equations are true, any linear combination of them is true. What we've shown is that this set of axioms is complete: it proves all true statements in this formal system. Can this be formally stated as an actual logical completeness result? Could somebody explain the finer details of how to do that?","['logic', 'linear-algebra']"
2898171,Non-free rings of integers,Let $L/K$ be a field extension of number fields such that the class number of $K$ is greater one (i.e. $\mathcal O_K$ is not a principal ideal domain). Are there examples where $O_L$ is not free over $O_K$? If yes: What is the smallest such example? Or even better: Is there for every $K$ such an $L$?,"['extension-field', 'number-theory', 'free-modules', 'algebraic-number-theory']"
2898182,"Why is complex torus ""torus""?","The complex torus is the quotient group of $\mathbb{C}^n$ over a lattice. What is intuition behind that causes us to call it ""torus""?","['group-theory', 'differential-geometry']"
2898184,Motivation on Using Fourier Series to Solve Heat Equation,"There is an approach to solve the heat equation
$$ \begin{align*} \frac{\partial u}{\partial t}(x,t) &= \frac{\partial^2 u}{\partial x^2}(x,t) \quad \text{for $(x,t) \in \mathbb{R} \times (0, \infty)$}  \\ u(x,0) &= f(x) \quad \text{for $x \in \mathbb{R}$} \end{align*} $$
by applying Fourier Series. What is the motivation for that? How did Fourier see that his Fourier Series will help to resolve this equation? What makes Fourier Series to special to be applicable to this problem?","['fourier-series', 'derivatives', 'heat-equation', 'partial-differential-equations']"
2898186,Mean value theorem for vector laplacian,"It is well known that all solutions of the Laplace equation $\nabla^2 u = 0$ satisfy the mean value theorem: the average value of $u$ over a sphere equals its value at the center of the sphere. My question is: does the same theorem hold in case of vector laplacian? Let the vector field $\vec{v}$ satisfy $\nabla^2 \vec{v} = 0$. Is it true that the mean value of $\vec{v}$ over a sphere equals its value at the center of the sphere? I would imagine the answer to be positive. For example, writing $\vec{v}$ in cartesian basis reduces the vector laplacian $\nabla^2 \vec{v} = 0$ to three ordinary laplacians: $\nabla^2 v_x = \nabla^2 v_y = \nabla^2 v_z = 0$ and makes the statement trivial. However, one can imagine using some other, curvilinear basis, in which the statement is far from trivial. Therefore, I would appreciate some insight or a coordinate-free proof of the theorem.","['harmonic-functions', 'coordinate-systems', 'laplacian', 'multivariable-calculus', 'vector-analysis']"
2898201,"Convenient categories in algebraic topology: their importance, and the role topology plays in their construction","Disclaimer. I have stated three questions but I felt that they are so related that they fit within a single post. Context. After reading Hatcher's Algebraic Topology I wanted to learn more about homotopy theory and in particular about spectra. I soon found the $n$Lab's Introduction to Stable Homotopy Theory which I'm reading right now. Let me crudely summarize what I've come across. We start with the desire to find a category of topological spaces which behaves decently from a category-theoretic viewpoint. The category that we end up finding is the category $\mathbf{Top}^*_{\mathrm{cgwh}}$ of pointed compactly generated weak Hausdorff spaces. The definition is somewhat ad hoc , and there are many other choices besides $\mathbf{Top}^*_{\mathrm{cgwh}}$. This does not concern us. We want to endow this with a model structure. We construct the Quillen--Serre structure. It's a rather convoluted struction, and it's not at all the only model structure. Neither of these observations bother us. Once we've set this up, we want to consider the category obtained by stabilizing the Quillen adjunction $\Sigma \dashv \Omega$ on $\mathbf{Top}^*_{\mathrm{cgwh}}$, called the stable homotopy category. We end up looking for models of this category, thus arriving at the category of sequential spectra endowed with the stable model structure. The definitions are more convoluted than ever. Still, this leaves us unmoved. For some reason the failure of a decent smash product on the category of sequential spectra disappoints us and we end up going even further by considering more highly structured models with yet more complicated definitions and constructions. They go entirely beyond me. Questions. In all, I am very surprised by what I've read. It has left me with a few general open-ended questions. Spectra seemed nice to me because they represent cohomology theories. As such I expected stuff about cohomology. But the emphasis on the notes lies pretty much entirely on finding nice categories. Why do we want them so badly? While Hatcher's Algebraic Topology was mostly concerned with investigating spaces, the notes seem to only care for the spaces as being models for the categories we crave for. Does this trend continue as one delves deeper into this subject? If the role of spaces has been reduced to models for certain categories, then why do we not think of letting go of them altogether? I mean, let's be real. The journey from your friendly $\mathbf{Top}$ to the daunting $(\mathbf{Top}^*_{\mathrm{cgwh}})_{\rm{Quillen}}$ to the utterly monstrous $\mathrm{SeqSpec}(\mathbf{Top}_{\mathrm{cgwh}})_{\mathrm{stable}}$ (and yet beyond), is to me a horribly unnatural one. It makes me feel that there should be a more royal road to whatever holy grail of categories we are praying for. So are topological spaces even the right framework in the first place? Or am I being ignorant?","['model-categories', 'general-topology', 'spectra', 'algebraic-topology']"
2898330,Characterisation of the Minkowski metric,"Suppose a manifold is homeomorphic to $\mathbb R^4$, and you've shown that it is equipped with a flat metric of signature $(n-1,1)$. To what extent can I conclude that my space is Minkowski space? My intuition tells me that there exists something like a linear change of coordinates so that my metric is literally diag$(-1,1,1,1)$. If this is indeed the case, how do I formalise this? I cannot conclude that my metric is the Minkowski metric up to a change in basis, since its eigenvalues need not be in $\{-1,1\}$. Essentially I'm after a characterisation of Minkowski space that doesn't require me to say ""the metric is diag$(-1,1,1,1)$"", because I'm working in a more abstract setting and I'd prefer not to compute anything with coordinates.","['riemannian-geometry', 'curvature', 'general-relativity', 'mathematical-physics', 'differential-geometry']"
2898339,Find the set of points where two functions are equal,"Given the function:
$$f(M, \vec{p}, d) = \sum_{i=1}^m log(\frac{\mathbb{I}(|\vec{M}_i - \vec{p}|_2<d)}{|\vec{M}_i - \vec{p}|_2})$$
Where $M \in \mathbb{R}^{m \times n}$ is a matrix, $\vec{p} \in \mathbb{R}^{n}$ is a vector describing a point, $d \in \mathbb{R}$ is a minimum distance scalar, and $|\vec{M}_i - \vec{p}|_2$ is the euclidean distance between two points. Also when $\mathbb{I}(|\vec{M}_i - \vec{p}|_2<d)$ is true 1 is returned, otherwise its zero. If I had two different matrices and plugged them into this function, how would I find the $n$ dimensional points where the two functions are equal to each other? As simple example let us look at the matrices $A$ and $B$:
$$A =
    \begin{bmatrix}
    0.3 & 0.3 \\
    0.3 & 0.4  \\
    0.4 & 0.3 \\
    \end{bmatrix}
B =
    \begin{bmatrix}
    0.6 & 0.6 \\
    0.6 & 0.7  \\
    0.7 & 0.6 \\
    \end{bmatrix}
$$
And the minimum distance is:
$$
d=0.3
$$ How would one go about finding the set of points where $f(A, p) = f(B, p)$?
I know you would make them equal to one another like:
$$\sum_{i=1}^3 log(\frac{\mathbb{I}(|\vec{A}_i - \vec{p}|_2<0.3)}{|\vec{A}_i - \vec{p}|_2}) = \sum_{i=1}^3 log(\frac{\mathbb{I}(|\vec{B}_i - \vec{p}|_2<0.3)}{|\vec{B}_i - \vec{p}|_2})$$
But I don't know how to solve this. Also bare in mind that I need this to work for examples with points of higher dimensionality ($n > 0$), and when the size of the $m$ dimension of the two matrices are not equal. To help you understand the problem more clearly I have created a visual aid: A graph describing the intersection of the two functions, where the red line indicates where the two functions would be equal. If you require any further details feel free to ask.","['summation', 'vector-spaces', 'matrices', 'euclidean-domain', 'functions']"
2898361,The convenient approach to a calculus problem in two variables,"A student came to me with the following problem. Construct a function $g \colon {\Bbb R}\to {\Bbb R}$ such that the function $f \colon {\Bbb R}^2 \to {\Bbb R}$ defined by $$ f(x,y)= \begin{cases} \frac{e^{x^2}-e^{y^2}}{x-y} &\text{if $x \neq y$} \\ g(x) &\text{if $x=y$} \end{cases} $$ is continuous. Is the function $f$ differentiable at the origin? It is immediate to find the unique $g$ that could solve the problem. However, the student was in trouble since he was unable to check that this function $g$ was an actual solution. The computation of $$\lim_{(x,y) \to (x_0,x_0)} \frac{e^{x^2}-e^{y^2}}{x-y}$$ is intuitive, but the student could not prove rigorously his conjecture. The same for the limit $$\lim_{(x,y) \to (0,0)} \frac{f(x,y)-f(0,0)-\nabla f(0,0)\cdot (x,y)}{\sqrt{x^2+y^2}}.$$ I suggested the use of some Taylor expansion of the exponential around zero, but I wonder if there is some straightforward approach. Actually, the definition of $f$ is given as a ""incremental ratio"" of a smooth function, and I guess there is a general result about the extension of the incremental ratio to the diagonal of $\mathbb{R}^2$. Any suggestion is welcome.","['multivariable-calculus', 'derivatives', 'education']"
2898365,Is the distance between two elements of a normed vector space at least the distance between their projections on the unit ball?,"I am stuck on the following question which I am having some difficulty with. Any help is much appreciated. Let $X$ be a normed vector space and define the projection onto the unit ball as $\pi(x)$ = $x/||x||$ for $x \in X \setminus \{0\}$. Let $x,y \in X \setminus \{0\}$ with $||x||,||y|| \geq 1$. Must it be the case that we have $||\pi(x) âˆ’ \pi(y)|| \leq ||x âˆ’ y||$? I can't seem to find a counterexample so am trying to go for a proof. So far the only observation I have been able to make is this: WLOG we can take $||x|| \leq ||y||$. We may also WLOG take $||x|| = 1$ as otherwise we can replace $x$ with $x' = x/||x||$ and $y$ with $y' = y/||x||$ which does not affect the L.H.S of our inequality which reducing the R.H.S which only makes the inequality more strict. Hence the problem reduces to showing $||x-\pi(y)|| \leq ||x-y||$ with $||x|| = 1$ and $||y|| \geq 1$. If we have $||y|| \geq 3$ then we can use the triangle inequality twice to show this. However I can't find a proof using just $||y|| \geq 1$. How should I proceed?","['normed-spaces', 'linear-algebra', 'functional-analysis', 'vector-spaces']"
2898377,What is the Stone space of the free sigma-algebra on countably many generators,The Stone space of the free Boolean algebra on countably many generators is the Cantor space $2^\omega$. What is the Stone space of the free (Boolean) $\sigma$-algebra on countably many generators?,"['boolean-algebra', 'measure-theory', 'order-theory', 'compactification', 'lattice-orders']"
2898385,"When does the limit $|\cos(n)|^{f(n)}$ converges as $n \rightarrow \infty, n \in \mathbb{N}$?","Here we go with a not-so-trivial problem: Inspired by another problem that I myself asked here , I came with this more general formulation: Let be the sequence $a(n) = |\cos(n)|^{f(n)}$. Then, when does the sequence $|\cos(n)|^{f(n)}$ converges as $n \rightarrow \infty$, for $n \in \mathbb{N}$? And the only thing that we may vary is $f(n)$. The only constrain for $f(n)$ will be that $f(n)$ increases monotonically and is unbounded . It is easy to see that the numbers that belong to the open interval $(k\pi, (k+1)\pi)$ tend to $0$ as $f(n) \rightarrow \infty$. And on the other side, all natural numbers will always belong to these intervals (if not, that would be equivalent to claim the rationality of $\pi$). Then, all members of the sequence will tend to $0$... All?? Not necessarily, because by Dirichlet's Approximation Theorem , you can always find an integer that is arbitrarily close to a multiple of $\pi$. And the closer you are to a multiple of $\pi$, the closer would be the following and related function to 1: $$
\lim_{x \rightarrow k\pi} |\cos(x)| = 1
$$ On the other hand, if instead of considering functions with real numbers, we focus on our sequence over the natural numbers, we can see that not all the integers approximate to a multiple of $\pi$ in the same manner. There is an integer sequence that every member of the sequence is closer to a multiple of $\pi$ that the previous member ( https://oeis.org/A046947 ). This integer sequence increases exponentially and let be $b(n)$ that sequence. I've seen computationally, that $b(n) \approx \pi^n$. So... As I can see this, here there are to different opposing forces acting one against the other to make converge or diverge our sequence. On one side, the convergence speed of the members of the open intervals $(k\pi, (k+1)\pi)$ towards $0$ ($k\in\mathbb{N}$), which we can control through playing with $f(n)$; and on the other side, the convergence speed of the sequence $b(n)$ to a bigger multiple of $\pi$. but this ""process"" is fixed and we cannot alter it. It seems that: $$
f(n) = 2n \implies \nexists  \lim_{n \rightarrow \infty} |\cos(n)|^{f(n)} 
$$
This problem seem to be solved here in my previous MSE question. This shows an example of $f(n)$ that makes this sequence diverge, but I strongly think that other expressions for $f(n)$ can make this sequence converge to $0$. My intuition tells me that if $f(n)$ is linear, the sequence will diverge always, but I have that feeling that tells me that if $f(n)$ is exponential , like $f(n) = a^n$, then the sequence will converge if $a > a_0$, being $a_0$ some constant (maybe $\pi$?). So the final question to answer would be: Let $f(n)$ be a monotonically increasing and unbounded sequence whose expression is known. How must be $f(n)$ so: $$ \lim_{n \rightarrow \infty} |\cos(n)|^{f(n)} = 0? $$ Many thanks in advance!","['trigonometric-series', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
2898402,Gap between two level curves of bivariate CDF,"I consider a bivariate cumulative distribution function $F(x,y)$ and two of its level curves.  I can write these level curves as the graphs of functions $c_1(x)$ and $c_2(x)$. Let's say that $c_2$ corresponds to a higher level, so that 
$$c_2(x)-c_1(x)\geq 0.$$ Can I also conclude that the gap between $c_2$ and $c_1$ is monotonic in $x$ -- that is, in case $F$ is absolutely continuous, can I conclude that 
$$c'_2(x)-c'_1(x)\leq 0$$
for all $x$ or 
$$c'_2(x)-c'_1(x)\geq 0$$
for all $x$?","['functions', 'probability', 'real-analysis']"
2898427,In how many ways can we distribute $20$ balls into $5$ boxes?,"In how many ways can we put $20$ balls into $5$ boxes A, B, C, D, E so that A has at most $3$ balls and B at most $2$ balls? $$$$ If we had at least instead of at most we would put the minimum number of balls into these boxes and distribute the remaining balls into the 5 boxes. But what do we have to do now where we have at most ?","['combinatorics', 'discrete-mathematics']"
2898430,(Co)homology of HNN extensions,"Let $G$ be a group with a subgroup $A$, and let $\varphi:A\rightarrow G$ be any injection. The HNN extension with base $G$ and associated subgroups $A$ and $\varphi(A)$ is defined as $$G^{\ast}=\langle\; S_{G},\; t\;|\;R_{G},\;t^{-1}at=\varphi(a),\;a\in A\;\rangle,$$
where $\langle\; S_{G}\;|\;R_{G}\;\rangle$ is a presentation for $G$. Is there any method or theorem that one could use to compute the (co)homology of $G^{\ast}$?","['group-theory', 'group-cohomology', 'homology-cohomology']"
2898434,A sequence for which the running average converges to something other than the expected value,"$X_1,X_2,\ldots$ is a sequence of independent random variables and $$P\{X_n = n^2 - 1\} = 1 - P\{X_n = -1\} = n^{-2}$$ Clearly, $E[X_n] = 0$. However, $\frac{1}{n}S_n \to -1$ almost surely where $S_n = \sum_{i=1}^nX_i$. My proof of this assertion is as follows and I would appreciate it if someone could check its correctness as well as the precision of my reasoning. $(X_n)_n$ being a collection of independent random variables, the event
$\left\{\omega: \lim_{n\to\infty}\frac{1}{n}S_n(\omega) = -1\right\}$ belongs to the tail $\sigma$-algebra and hence has a probability of either zero or one. If I can show that the probability of this event is strictly positive, then I am done. I note that
$$\{X_2 = -1, X_3 = -1, \ldots\} \subset \left\{\lim_{n\to\infty}\frac{1}{n}S_n = -1\right\}$$ By monotone convergence 
$$P\{X_2 = -1, X_3 = -1, \ldots\} = \lim_{n\to\infty}P\{X_2 = -1, \ldots, X_n = -1\}$$
This yields $P\{X_2 = -1, X_3 = -1, \ldots\} = \frac{1}{2}$. Therefore, $P\left\{\lim_{n\to\infty}\frac{1}{n}S_n = -1\right\} \geq \frac{1}{2}$, which implies $\frac{1}{n}S_n \to -1$ almost surely. I would also appreciate seeing different proofs of this claim, in particular ones that do not invoke Kolmogorov's $0-1$ law.","['measure-theory', 'proof-verification', 'law-of-large-numbers', 'probability-theory', 'random-variables']"
2898467,The priority of limits,"How are the two expressions different? $$\lim_{x\to0}\bigg\lfloor\frac{\sin{x}}{x}\bigg\rfloor$$ and $$\bigg\lfloor\lim_{x\to0}\frac{\sin{x}}{x}\bigg\rfloor$$ If limit is inside the floor function, Do I have to apply the limits first? If this is the case, then, $$\lim_{x\to0}\bigg\lfloor\frac{\sin{x}}{x}\bigg\rfloor=0$$ $$\bigg\lfloor\lim_{x\to0}\frac{\sin{x}}{x}\bigg\rfloor=1$$ Am I solving this right? Also how can I calculate, $$\lim_{x\to0}\bigg\lfloor\frac{\sin{x}\cdot \tan{x}}{x^2}\bigg\rfloor$$ Thank you.","['limits', 'ceiling-and-floor-functions']"
2898471,Differentiating the Riemannian exponential map with respect to the base point,"If $(M,g)$ is a Riemannian manifold, $\alpha \in \Omega^1 M$ a smooth $1$-form, $x \in M$ and $y$ in a normal coordinates neighbourhood $U$ of $x$, how should I proceed in differentiating $y \mapsto \alpha_y (\exp_y ^{-1} (x))$ with respect to $y$? (I am interested in the gradient and the Laplacian of this function.) If differentiating were with respect to $x$, I would know what to do (perform the computation in normal coordinates around $x$), but how to deal with the argument being the base point of $\exp$, so that for each $y$ there exists a different set of normal coordinates?","['geodesic', 'riemannian-geometry', 'coordinate-systems', 'smooth-manifolds', 'differential-geometry']"
2898474,Logic equation simplification,How it the following logic equation $$(B \land \lnot C) \lor (A \land B) \lor (A \land C)\tag 1$$ simplified into $$(B \land \lnot C) \lor (A \land C)\tag 2$$ I'm simplifying a boolean equation for a breadboard circuit-work and I've used a couple of online boolean equation simplifiers to verify my solution but I just can't seem to understand how the equation $(1)$ is simplified to equation $(2)$? What happened to $A \land B$? I'm not yet fully knowledgeable on certain boolean algebra laws. I would really appreciate it if someone could show a clear solution together with what law was used.,"['boolean-algebra', 'logic', 'discrete-mathematics']"
2898509,Giving 1 apple to 1 of 3 children fairly with a coinflip,"I wish to give an apple to 1 of 3 children fairly using a coin flip game. Each child calls heads or tails, and I flip the coin once for each child. If exactly one child calls correctly, that child gets the apple. If there is no one who calls correctly the game repeats. If two children call correctly, the game repeats between the 2 children until only of them calls correctly. Is this game fair; i.e., does each child have the same probability of winning? I am assuming yes intuitively. What about a game in which I only flip the coin once, and each child calls. Is this game fair? I am assuming yes intuitively. What is the expected number of coinflips in my original game? I recursively got 6: Let $N_3, N_2$ be the number of flips for three and two children respectively.  Then for three children:
$$P(0\space correct\space calls) = 1/8 $$
$$P(1\space correct\space call) = 3/8 $$
$$P(2\space correct\space calls) = 3/8 $$
$$P(3\space correct\space calls) = 1/8 $$ Hence: $E(N_3) = \frac{3}{8} \cdot3 + \frac{2}{8}\cdot (3 + E(N_3)) + \frac{3}{8}\cdot(3 + E(N_2))$ For two children: $$P(0\space correct\space calls) = 1/4$$
$$P(1\space correct\space call) = 2/4$$
$$P(2\space correct\space calls) = 1/4$$ Hence: $E(N_2) = \frac{1}{2}\cdot 2 + \frac{1}{2}\cdot (2 + E(N_2))$ Thus: $E(N_2) = 4$ and $E(N_3) = 6$ For the curious, I am trying to see if this ""tournament game"" is ""isomorphic"" to randomly assigning ""T"" to a child, then doing 3 coinflips until a permutation of {T,H,H} is achieved and hence the assigned child gets the apple, as described by Tim Crack in Heard On the Street (17e) . That ""assignment game"" expects 8 coinflips whereas I am getting 6 in my ""tournament game."" I am probably misinterpreting his description of ""tournament game"" or incorrectly calculating 6.",['probability']
2898510,Holomorphic Lefschetz formula and basic linear algebra.,"There is a well-known way to prove the fact that the field of complex numbers is algebraically closed using Lefschetz fixed point theorem. Let me recall the idea: The existence of a root for any polynomial with complex coefficients is equivalent to the existence of an eigenvector for any endomoprhism of a finite-dimensional vector space over $\mathbb{C}$. Indeed, any polynomial is a characteristic polynomial of certain matrix. Assume, that $V$ is a finite-dimensional complex vector space and $A \colon V \to V$ is an endomorphism without eigenvectors. In particular, $A$ has trivial kernel, so it induces an automorphism of the projectivization: $$\overline{A} \colon \mathbb{P}(V) \to \mathbb{P}(V).$$ The group $\mathrm{PGL}(n, \mathbb{C})$ is connected (one doesn't need the main theorem of algebra to prove this), so $\overline{A}$ is homotopic to identity as a diffeomorphism of $\mathbb{P}(V)$. Thus its Lefschetz number equals Euler characteristic of complex projective space, which is non-zero. By Lefschetz fixed point theorem, this implies that $\overline{A}$ has a fixed point. If $l$ is a line fixed by $\overline{A}$, then any vector $v \in l$ is eigen for $A$. Now, my question is the following: what if we apply the holomorphic Lefschetz theorem to a linear automorphism of a projective space? In this case it is easy to compute the right-hand-side: since the only non-tirivial Dolbeaut cohomology group of projective space is $H^{0,0}(\mathbb{CP}^n)$,and $\overline{A}$ acts on it trivial, the holomorphic Lefschetz number equals $1$. What is the left-hand-side in this case? It seems to be certain algebraic expression in coefficients of $A$. However, after thinking about it for some time I am not able to write it down explicitly.","['complex-geometry', 'algebraic-geometry', 'linear-algebra']"
2898514,Show that the field of fractions of $\mathbb{Z}[[x]]$ is properly contained in $\Bbb Q((x))$,"I've been working on this for a while but I don't know how to proceed. Here it's what I've done:
Clearly, my goal is to show that every element of the field of fractions is in $\Bbb Q((x))$ and to show that there exist an element of $\Bbb Q((x))$ that is not an element of the field of fractions.
The problem suggests considering the series expansion for $e^x$ so that's what I did. I guess that that's the hint because $e^x$ is the element in $\mathbb{Q}((x))$ that is not in $\text{Frac}(\mathbb{Z}[[x]])$ I'm looking for. So 
$$e^x=\displaystyle \sum_{n=0}^\infty \frac{x^n}{n!}$$
Since $n!\in\mathbb{N}$ then $\frac{1}{n!}\in \mathbb{Q}$ and $e^x\in \mathbb{Q}((x))$
Now, this is where I can't go further. I've tried assuming that $e^x\in \text{Frac}(\mathbb{Z}[[x]])$ and using that it must be a unit to achieve a contradiction but I don't know how to do so. Any hints? Thanks in advance","['field-theory', 'power-series', 'abstract-algebra', 'laurent-series']"
2898536,"For odd primes $p$, are finite groups with self-normalizing Sylow $p$-subgroups solvable?","Is it the case that for odd primes $p\geq5$ , all finite groups with self-normalizing Sylow $p$ -subgroups are solvable? The simple group of order 168 shows that this conjecture does not hold for $p=2$ . Verret's answer provides a counterexample when $p=3$ . Does this conjecture hold for any odd primes $p\geq5$ ? If so, is there a proof that does not rely on the CFSG? Edit: Initially, I thought that I had proved that a minimal counterexample to this conjecture was necessarily simple. Verret's answer shows that this is not the case. Fix a prime $p$ and let $G$ be a minimal counterexample to the conjecture. Suppose that $G$ is not simple. 1) Let $H$ be a nontrivial normal subgroup of $G$ and let $P$ be a Sylow $p$ -subgroup of $G$ .
Then $PH$ is a subgroup of $G$ that contains $N_G(P)$ so $N_G(PH)=PH$ .
Also, $PH/H$ is a Sylow $p$ -subgroup of $G/H$ with $$N_{G/H}(PH/H)=N_G(PH)/H=PH/H.$$ Then $G/H$ is solvable by the minimality of $G$ .
However, $G$ is not solvable so $H$ is not solvable. 2) Let $H$ be a proper normal subgroup of $G$ with $G/H$ simple. Then $G/H$ is cyclic of prime order. If $G/H$ is not cyclic of order $p$ then $H$ contains a Sylow $p$ -subgroup of $G$ and thus Sylow $p$ -subgroups of $H$ are self-normalizing. The minimality of $G$ provides a contradiction. This shows that $G/H$ is cyclic of order $p$ . If $p$ does not divide the order of $H$ then $G\cong H\rtimes_\varphi C_p$ for some homomorphism $C_p\to Aut(H)$ . However, Sylow $p$ -subgroups of $G$ are self-normalizing so this homomorphism must be fixed-point-free. Then $H$ admits a fixed-point-free automorphism of prime order which contradicts the non-solvability of $H$ . In summary, $p$ divides the order of $H$ and $G/H$ is cyclic of order $p$ .","['group-theory', 'simple-groups', 'finite-groups']"
2898557,Is this definite integral positive?,"I have a doubt and I am not able to prove (or disprove): Let $f(x)$ be an odd function with $f(x)>0\,\,\,\forall x\in (0,+\infty)$ . Let $g(x)$ be a non-negative function: $g(x)\geq 0\;\forall x\in \mathbb{R}.$ Also suppose $\displaystyle \int_{-\infty}^0g(x)\,dx<\int_{0}^{\infty}g(x)\,dx.$ I wonder if one can assure that: $$\int_{-\infty}^{\infty}f(x)\,g(x)\,dx>0.$$ EDIT 1 : Has been  proved (by Adrian Keister) that my thesis is false. Now I wonder again if is possible add another hypothesis about $g(x)$ to assure my thesis. EDIT 2 :The problem arrives from here: blue line is $f(x)= \left(e^{-\frac{\cosh ^2(u-1)}{2 }}-e^{-\frac{\cosh ^2(1+u)}{2 }}\right)$ and orange line is $g(x)=e^{-\frac{u^2}{2 }}\cos ^2\left(\frac{\pi  (u-1)}{4 }\right)$ and the function $f(x)g(x)$ graphic As we can see in the graph, the integral $\int_{\mathbb{R}}f(x)g(x)\,dx$ seems to be positive. We can translate the factor $e^{-u^2/2}$ from $g(x)$ to $f(x)$ (in this case the third hypothesis is not fulfilled):","['definite-integrals', 'real-analysis']"
2898585,Looking for a sigmoid-like function with convex segment around origin,I am looking for a function with some specific properties (this is for a probabilistic simulation). It should be a function that is runs though (and is symmetric) the origin and asymptotically approaches $-1$ and $1$ as its parameter goes from negative to positive. Any sigmoid function would fit the bill but I ideally want it to have a convex component around the zero (i.e. I want its value to be more similar around zero) and all sigmoid functions that I am aware of change rather quickly. See the attached badly drawn picture for an illustration. Would appreciate any pointers! Computationally less expensive functions are prefered.,"['functions', 'special-functions', 'analysis']"
2898589,Measure Theory and Cantor Set (couterexample).,"Consider $O_{n} = \{y \in \mathbb{R}^{d} \mid \exists x \in E \text{ with } |y - x| < \frac{1}{n}\}$ where $E$ is a mensurable set. (a) Prove that if $E$ is compact, then $m(E) = \lim m(O_{n})$ . (b) Show that there is $E$ closed and unbounded such that $m(E) < \lim m(O_{n})$ . (c) Show that there is $E$ open and bounded such that $m(E) < \lim m(O_{n})$ . I proved the items (a) and (b). But I'm having trouble with other item. For item (c), I'm trying with the following set: Let $\mathcal{C}$ the Cantor Set, then $[0,1]\setminus \mathcal{C}$ is open. But, I don't know how to ""work"" with $O_{n}$ in this case. I would like help with this example, or some other example would also be helpful","['measure-theory', 'cantor-set', 'real-analysis']"
2898614,On Abelian group product of a Free and a Finite group,"I'd need help with this problem: Let $H$ be an abelian group.
Let $T \leq H$ and $T' \leq H$ be finite subgroups of H.
Let $F \leq H$ and $F' \leq H$ be free subgroups of H. Suppose $H = T \times F = T' \times F'$. Show that $T = T'$. Does the same conclusion hold for $F$? I don't really know how to approach the problem. I feel like I should use the Theorem of Classification of finitely generated abelian groups, but H isn't finitely generated. Thanks in advance for any help!","['group-theory', 'abstract-algebra', 'abelian-groups', 'products']"
2898617,Hierarchy of functions by asymptotic growth,"I am ordering the following function in order of non-decreasing asymptotic growth. $f(n) \in \mathcal{O} \big(g(n)\big) \in \mathcal{O} \big(h(n)\big)$... etc. I believe I have most of the order correct, but there is one function I'm a bit lost on. The order so far is $\log_{2}n, \quad n^{\frac{1}{3}}, \quad n^{5}, \quad 10^{n},
 \quad n^{n}$ The only function I need to figure out is $2^{\sqrt{\log_{2}n}}$ I'm certain that $2^{\sqrt{\log_{2}n}}$ should be in between $\quad \log_{2}n \quad$ and $\quad n^{\frac{1}{3}} \quad$. Unlike the other terms, I am not able to tell from just looking at it, and I'm little lost trying to verify this without a calculator (I'm not allowed to use calculator on my test). It would also help me to know what type of function this is. Is this classified as a logarithmic, or an exponential perhaps? I know that without the square root the function would be linear.","['limits', 'computational-complexity', 'asymptotics', 'logarithms']"
2898620,"Notions of $\beta$-HÃ¶lder smoothness when $\beta\in (1,2]$: are they equivalent?","For fixed $d\geq 1$ and $\beta\in (1,2]$, consider the two following classes of functions: Let $\mathcal{H}^\beta$ denote the collection of all $C^1$ functions $\phi:\mathbb{R}^d\to\mathbb{R}$ for which there exists $L>0$ such that $\|\nabla\phi(y)-\nabla\phi(x)\|_2\leq L\|y-x\|_2^{\beta-1}$ for all $x,y\in\mathbb{R}^d$. [ This is sometimes referred to as a $\beta$-HÃ¶lder class. ] Let $\tilde{\mathcal{H}}^\beta$ denote the collection of all $C^1$ functions $\phi:\mathbb{R}^d\to\mathbb{R}$ for which there exists $\tilde{L}>0$ such that $\lvert\phi(y)-\phi(x)-\nabla\phi(x)^\top(y-x)\rvert\leq\tilde{L}\|y-x\|_2^\beta$ for all $x,y\in\mathbb{R}^d$. Is it true that $\mathcal{H}^\beta=\tilde{\mathcal{H}}^\beta$? I believe the answer is yes if either $d=1$ or $\beta=2$, but I can't see how to tackle the general case. Here are some preliminary remarks and observations: It is not hard to see that $\mathcal{H}^\beta\subseteq\tilde{\mathcal{H}}^\beta$: indeed, fix $x,y\in\mathbb{R}^d$ and apply the chain rule and mean value theorem to the function $\Phi:[0,1]\to\mathbb{R}$ defined by $\Phi(t):=\phi(x+t(y-x))$. The case $d=1$ : if $\phi\in\tilde{\mathcal{H}}^\beta$, observe that since the defining condition in the second bullet point above is symmetric in $x$ and $y$, we can apply the triangle inequality to deduce that $\lvert\{\phi'(y)-\phi'(x)\}(y-x)\rvert\leq 2\tilde{L}\lvert y-x\rvert^\beta$, which implies that $\phi\in\mathcal{H}^\beta$, as required. However, this argument does not generalise to higher dimensions ... The case $\beta=2$ : fix $\phi\in\tilde{\mathcal{H}}^\beta$ and suppose first that $\phi$ is twice differentiable on $\mathbb{R}^d$. Then in view of Taylor's theorem with the Peano form of the remainder (cf. Exercise 9.30(b) in Rudin's Principles of Mathematical Analysis), the defining condition for $\tilde{\mathcal{H}}^2$ implies that the second derivative of $\phi$ is bounded in operator norm by $2\tilde{L}$. But then it follows from the mean value inequality (Theorem 5.15 in Rudin) that $\|\nabla\phi(y)-\nabla\phi(x)\|_2\leq 2\tilde{L}\|y-x\|_2$ for all $x,y$, as required. To handle the case where $\phi$ is not twice differentiable, define $\phi_n:=\phi\ast g_{1/n}$ for each $n\in\mathbb{N}$, where we let $g$ be a smooth bump function supported on the unit ball and define $g_\varepsilon(x):=\varepsilon^{-d}g(x/\varepsilon)$ for $x\in\mathbb{R}^d$ and $\varepsilon>0$. It is easy to verify that each $\phi_n$ is smooth and belongs to $\tilde{\mathcal{H}}^2$ (with the same $\tilde{L}$ as before). Since $\nabla\phi_n\to\nabla\phi$ pointwise, we can obtain the desired conclusion by sending $n\to\infty$.","['holder-spaces', 'functional-analysis', 'real-analysis']"
2898632,Aristarchus' Inequality - algebraic proof,"While looking for trigonometric inequalities, I stumbled upon Aristarchus' inequality, which states that for $0<\alpha<\beta<\pi/2$ $$\frac{\sin(\beta)}{\sin(\alpha)}<\frac{\beta}{\alpha}<\frac{\tan(\beta)}{\tan(\alpha)}.$$ In this post
( Proof of Aristarchus' Inequality ) user141614 shows a completely algebraic proof of the first inequality using only $\sin(\alpha)<\alpha<\tan(\alpha)$. I tried for a long time to reproduce a similar proof for $\tan$ by trying to prove the equivalent inequality
$$\frac{\tan(\beta)-\tan(\alpha)}{\beta-\alpha}>\frac{\tan(\alpha)}{\alpha},$$
by using user141614's same idea, combined with trigonometric identities for the sum and product, but without success. Does someone have hint on how to approach the problem? I really want an algebraic proof (which can potentially rely on easy-to-prove inequalities as the one above), no calculus. Thank you in advance","['trigonometry', 'inequality']"
2898638,Can certain families of probability distributions be considered as groups?,"Disclaimer: It is very possible that the notation I will be using is not formally correct. I am not a mathematician, and I'm just trying to write down this idea in a reasonable way. I wasn't able to find literature addressing this topic As an example, take the family of univariate normal distributions with the sum operation. Let see if it satisfies the four defining properties of a group: Closure : Given $X \sim \mathcal{N}(\mu_1,\,\sigma_1^{2})$ and $Y \sim \mathcal{N}(\mu_2,\,\sigma_2^{2})$, $Z = X+Y$ is also normally distributed, with $Z \sim \mathcal{N}(\mu_1+\mu_2,\,\sigma_1^{2}+\sigma_2^{2})$ Associativity : It is clear that $(X + Y) + Z = X + (Y + Z)$ in distribution, with $X, Y, Z$ each independently and normally distributed with given means and variances. Identity element : The distribution $\mathcal{N}(0,\,0)$ is the identity element, because any $I \sim \mathcal{N}(0,\,0)$ satisfies the property that $Y = X + I = I + X$ is distributed as $X$, with $X \sim \mathcal{N}(\mu_1,\,\sigma_1^{2})$. Inverse element : In this case for any $X \sim \mathcal{N}(\mu_1,\,\sigma_1^{2})$, there exists $-X$ such that $X-X = -X+X = I$, with $I \sim \mathcal{N}(0,\,0)$. The four properties seem to be satisfied, therefore couldn't we say that the family of univariate normal distributions with the sum operation constitutes a group? And the same with other several families of distributions and different operations such as sum, product, ratio, etc. Edit : As pointed out below, I should have added that $X$ and $Y$ have to be independent in the first point, otherwise the expression for the variance of the addition is not correct.","['group-theory', 'probability-distributions', 'probability-theory']"
2898675,Example of a function which is nearly a linear transformation,"Let $V$ and $W$ be vector spaces over the field $\mathbb{F}.$ Let $f$ be a function from $V$ to $W.$ Now $f$ will be called a linear transformation if \begin{align}
&\tag1 f(\alpha + \beta) = f(\alpha) + f(\beta)\,\, \forall \alpha,\beta \in V \\
&f(c\alpha) = cf(\alpha)\,\, \forall c\in \mathbb{F}\tag2
\end{align} I am interested in finding examples of functions where : (a) the first condition $(1)$ fails and second condition $(2)$ holds (b) the second condition $(2)$ fails and first condition $(1)$ holds I have two examples for the (b) part: Consider $f : M_{n\times n}(\mathbb{C}) \rightarrow M_{n\times n}(\mathbb{C}) $ with the mapping $A \to A^*$ where $A^*$ is the conjugate transpose of $A.$ Consider $f : \mathbb{C} \rightarrow \mathbb{C}$ wih the mapping $z \to \overline{z}.$ So far I haven't been able to find an example for (a).Please help me wind this up. Also if you find more examples for (b), please list them too.","['functions', 'linear-algebra']"
2898721,Find the nature of the roots of the equation $ 6x^4-25x^3+81x^2-9x-13=0$ using Descartes's rule of signs,"Let $f(x)= 6x^4-25x^3+81x^2-9x-13=0$ According to Descartes's rule of signs  There are three changes of signs in $f(x)$.Therefore, $f(x)=0$ may have three positive roots or one positive root and two imaginary roots. Again,There are three changes of signs in $f(-x)$.So $f(x)=0$ has one negative root or three negative roots.Now my question is how to conclude my answer with exact nature of the roots.I think some derivative work is needed to conclude the answer but i couldn't figure out. Thanks in advance.","['algebra-precalculus', 'polynomials']"
2898751,How to get the equation where a circle goes through three points [duplicate],"This question already has answers here : find the equation of the circle $x^2 +y^2 +ax +by = c$ passing through points $(6,8), (8,4), (3,9)$ (3 answers) Closed 5 years ago . If I have the equation $ax^2+ay^2+bx+cy+d=0$ how do I get the equation where the circumference goes through the points P = (1,1), Q = (âˆ’1,âˆ’1) and
  R = (âˆ’1,1) I have it in mind to solve it with a matrix, but the instructions seem confusing to me, can I get some help?",['linear-algebra']
2898756,"In ""Analyse fonctionnelle"" of Brezis, in chapter III why do we need Banach spaces ? (especially for Kakutani's theorem)","In the book of Brezis : ""Analyse fonctionnelle : ThÃ©orie et application"", chapter III (i.e. construction of weak topology, weak-* topology reflexives spaces...), why do we need ""Banach spaces"" ? Isn't normed spaces enough ? The particular example I have in mind if theorem III.16 (named as Kakutani) that says : Let $E$ a Banach spaces. Then $$B_E=\{x\in E\mid \|x\|\leq 1\}$$
is compact for the weak topology $\sigma (E,E')$ $\iff$ $E$ is reflexive. I read the proof with attention, and I don't see where we use the fact that $E$ is complete for it's norm. So why do we need the assumption to be Banach ? The only reason for me would be  that we use Banach-Steinhaus's theorem (BST) (and thus, we need completeness). But in the proof of Kakutani's theorem I don't see anywhere the used of (BST). So maybe the completeness is used somewhere I don't see ?","['functional-analysis', 'weak-topology']"
2898765,Domain of composition of functions,"I'm teaching a precalculus course and was wanting to let my students try to solve the following problem. If $$
f(x)=\sqrt{x}, g(x)=\frac{x}{x-1},h(x)=\sqrt[3]{x}
$$ Find the domain of $$f\circ g\circ h
$$ We have the following. $$
(f\circ g\circ h)(x)=f(g(\sqrt[3]{x}))=f(\frac{\sqrt[3]{x}}{\sqrt[3]{x}-1})=\sqrt{\frac{\sqrt[3]{x}}{\sqrt[3]{x}-1}}
$$ Here is where things get interesting. To find the domain of this function, I need to find where $$
\frac{\sqrt[3]{x}}{\sqrt[3]{x}-1}\geq0
$$ And this happens when the numerator and denominator have the same sign. Solving the inequality gives me that 0 and 1 are critical points, so I have the following intervals to test for the domain $$
(-\infty,0),(0,1),(1,\infty)
$$ Testing points in each interval shows that only the middle interval doesn't satisfy the inequality. Thus, the domain of the composition is $$
(-\infty,0],(1,\infty)
$$ However, when I double check this with Wolframalpha and with Symbolab, they both tell me the domain is $$
\{0\}\cup(1,\infty)
$$ I have double checked my work, and even just blindly inputting test values such as -1 gives me a valid output, so I'm wondering what is going on? On Desmos, I graphed the function and it did include the negative portion of the domain. The only thing I can think of is maybe the other sites are simplifying the expression to get $$
\frac{x^{\frac{1}{6}}}{\sqrt{\sqrt[3]{x}-1}}
$$ and maybe they are hesitant to input negative values into the 6th root. However, if you do this, the complex numbers end up cancelling and you get a real numbered answer. Any ideas on what is going on?",['algebra-precalculus']
2898774,Entire function satisfying an iteration formula,"I hope to figure out that what is the entire function $f$ that satisfies the following iteration formula
$$f(z+1)-f(z)=Ce^{-z}$$
for some constant $C$. Actually, I guess that $f$ has to be the form $f(z)=e^{-z+a}+be^{i2\pi{z}}+c$ where $a,b,c$ are complex numbers. Clearly, this kind of function satisfies the above formula. I hope to verify my guess, but I can't solve it completely. Some partial results is obtained. Taking derivative gives 
$$f'(z+1)-f'(z)=-Ce^{-z}.$$
Then we have 
$$f(z+1)+f'(z+1)-f(z)-f'(z)=0,$$
that is, $g(z+1)=g(z)$ where $g(z)=f(z)+f'(z)$. If $f$ satisfies some growth condition so that $g$ meet the requirement of Carlson's theorem ( https://en.wikipedia.org/wiki/Carlson%27s_theorem ), then by Carlson's theorem $g$ has to be constant. Thus $f(z)+f'(z)=C$ which implies that $f''(z)+f'(z)=0$. Then $f'(z)=De^{-z}+A$. Combining these with the iteration formula, we can conclude that $f$ is of the form $e^{-z+a}+b$. I wonder if it is true for the general case. Thank you for your attention.","['complex-analysis', 'entire-functions']"
2898786,Calculating the degree of some extension of $\mathbb{Q}_3$,"Let $p=3$ and $\zeta$ be a cube root of unity not equal $1$. Consider the field of $3$-adic numbers $\mathbb{Q}_3$.
At the beginning of section 5.4 of Fernando Gouvea's book $p$-adic numbers - An Introduction , he states that the field $\mathbb{Q}_3(\sqrt{2},\zeta)$ is an extension of degree $4$. Furthermore, the fields $\mathbb{Q}_3(\sqrt{2})$ and $\mathbb{Q}_3(\zeta)$ are both extensions of degree $2$. Now I would like to understand why this is true. I understand why we have $[\mathbb{Q}_3(\sqrt{2}):\mathbb{Q}_3]=2$. This is true because $f = x^2-2$ is irreducible over $\mathbb{Q}_3$, as 2 is a quadratic nonresidue, so we can apply Eisenstein's criterion. This means that $f$ is the minimal polynomial of $\sqrt{2}$ which has degree $2$. Therefore, the claim holds. I am also really sure about the fact that $[\mathbb{Q}_3(\zeta):\mathbb{Q}_3]=2$ is true. As $\zeta$ is a cubic root of unity, the minimal polynomial of $\zeta$ divides $x^3 - 1$ which has $1$ as a root, so it is obviously not irreducible. If we divide $x^3 - 1$ by $x-1$, then we obtain the polynomial $g=x^2+x+1$. This must mean that $g$ is the minimal polynomial of $\zeta$ if the degree of the extension is really $2$. But I do not know how to show why $g$ is irreducible over $\mathbb{Q}_3$. To show that $[\mathbb{Q}_3(\zeta,\sqrt{2}):\mathbb{Q}_3] = 4$, we only have to show either $\zeta \not\in \mathbb{Q}_3(\sqrt{2})$ or $\sqrt{2} \not\in \mathbb{Q}_3(\zeta)$, so we can apply the tower law. For instance, we assume $\zeta \in \mathbb{Q}_3(\sqrt{2})$. Then there exist coefficients $c_1,c_2 \in \mathbb{Q}_3$ such that $\zeta = c_1 + c_2 \sqrt{2}$ because we know that $\mathbb{Q}_3(\sqrt{2})$ is a vector space of $\mathbb{Q}_3$ of dimension $2$ with basis $\{1,\sqrt{2}\}$. Then
$$ 0 = \zeta^2 + \zeta + 1 = (c_1^2 + 2c_2^2+c_1+1) + (2c_1c_2+c_2)\sqrt{2}  $$
and therefore $c_1^2 + 2c_2^2+c_1+1=0$ and $2c_1c_2+c_2=0$. But this looks like a really difficult system of equations to solve, as I know nothing about $c_1$ and $c_2$. Could you please help me with this problem? Thank you in advance!","['algebraic-number-theory', 'number-theory', 'p-adic-number-theory', 'abstract-algebra', 'extension-field']"
2898798,Differentiability on a function from directional derivatives,"Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ and $a \in \mathbb{R}^2$. Suppose that all $D_v (a)$ exist and that $D_{(v_1, v_2)} f (a)= 5v_1 ^2 + v_2$. Is $f$ differentiable in $a$? I think it is differentiable. The only way I can think of solving this problem is by using the sufficient condition of differentiability: Let $A$ be open in $\mathbb{R}^n$, $a \in A$ and $f:A \rightarrow \mathbb{R}^m$. If the partial derivatives $D_1 f(x),...,D_n f(x)$ exist in an open ball $B(a,r)$ and they are all continuous in $a$ then $f$ is differentiable in $a$. So the values of the partial derivatives in $a$ are $D_1 f (a)= 5 \cdot 1^2+0$ and $D_2 f (a)= 5 \cdot 0^2+1 = 1$  and they exist because all directional derivatives exist by hypothesis. But I don't know how to conclude that the partial derivatives are continuous in $a$ since I don't know their general expression, only their value in $a$.","['multivariable-calculus', 'real-analysis']"
2898823,Find the cumulants of the power level of a given gaussian process,"I have given a zero-mean, circular symmetric, complex gaussian stochastic process $x[n] = a[n] + jb[n]$, where $a[n]$, $b[n]$, are jointly independent and $\sim N (0, \sigma^2)$. And I want to find the cumulants of the function: $z[n] = \sum_{l=1}^{L} |x[l]|^2$ Whereby all samples of $x[n]$ are i.i.d. $\sim \mathcal{N}(0, \sigma ^2)$. It is clear I can write:
$|x[l]|^2 = a[l]^2 + b[l]^2$ However, I am stuck at the further steps of the derivation.","['statistics', 'probability-theory', 'probability']"
2898846,Triangles defined on an infinite Go board by same-colored stones,"You start with an infinite Go board. On every point of the board you place one colored stone. There are $n>1$ different colors. Find all natural numbers $n$ that no matter how the stones are colored, three stones of the same color form the vertices of a right-angled triangle. The catheti (legs) of the right triangle must be on the lines of the board. Any ideas how to solve this kind of problem and to which area of mathematics this question belongs?","['recreational-mathematics', 'combinatorics', 'ramsey-theory']"
2898860,What is the multiplicative order of a product of two integers $\mod n$?,"Standard texts prove that $\textrm{ord}_n(ab)=\textrm{ord}_n(a)\,\textrm{ord}_n(b)$ when  $\textrm{gcd}(\textrm{ord}_n(a),\textrm{ord}_n(b))=1$. What if they are not relatively prime? Here $\textrm{ord}_n(b)$ is the multiplicative order of $b$, i.e. the smallest positive integer $m$ such that $b^m=1 (\textrm{mod}\,n)$. The naive guess that $\textrm{ord}_n(ab)$ is $\textrm{lcm}(\textrm{ord}_n(a),\textrm{ord}_n(b))$ can not be right since it gives $\textrm{ord}_n(b^k)=\textrm{ord}_n(b)$, whereas in fact 
$\textrm{ord}_n(b^k)=\frac{\textrm{ord}_n(b)}{\textrm{gcd}(\textrm{ord}_n(b),k)}$. So the order of the product must depend on more than just orders of the factors, perhaps on something in their prime factorizations? What does it depend on exactly? Is there a formula for the general case? If not, are there formulas for some special cases, e.g. when $a,b$ are relatively prime, square-free, prime powers, when $n$ is prime, etc.? Are there useful bounds for it? Since the product of orders is always an upper bound a lower bound would be interesting. References appreciated.","['number-theory', 'group-theory', 'prime-factorization', 'modular-arithmetic']"
2898886,"Angle Function - Problem 1-8, Lee","This is Problem 1-8 from Lee's Introduction To Smooth Manifolds . I'm having trouble with this problem. Here are some strategies I've thought of: For the forward direction, I was thinking of assuming on the contrary that $U = \mathbb{S}^1$ and showing a contradiction that $\text{Image}(\theta)$ is not closed and hence not compact in $\mathbb{R}$ but $\mathbb{S}^1$ is compact, $\theta$ is continuous, and $\theta$ is surjective from $\mathbb{S}^1$ to $\text{Image}(\theta)$. I've thought about using complex logarithms to solve for $\theta(z)$ and note that the logarithm has a branch cut, but I don't think that's a good approach because there are many ways to solve a complex exponential equation, other than using logarithms. For the backward direction, I think I know what to do: Assume $U \neq \mathbb{S}^1$, which means that $U$ fails to contain at least one point in $\mathbb{S}^1$. We can find a complex logarithm which has a branch cut at this missing point and solve for $\theta(z)$, where it is continuous everywhere except this branch cut point. For the last problem, I'm not sure what to do.","['complex-analysis', 'differential-geometry']"
2898889,Proving similarity of matrices using characteristic polynomial,"Let $\ A $ be a real matrix of $\ 3 \times 3 $ with the characteristic polynom: $\ p(t) = t^3 + 2t^2 -3t $ Prove: the matrix $\ A^2 + A - 2I $ is similar to $\ D = \begin{bmatrix} 0 & 0 & 0 \\ 0 &4 & 0 \\ 0 & 0 & - 2 \end{bmatrix} $ $\ p(t) = t^3 +2t^2 -3t = t(t^2 + 2t -3) = t(t-1)(t+3) $ then $\ A $ has 3 eigenvalues $\ 0,1,-3 $ and is similar to $\ M =  \begin{bmatrix} 1 & 0 & 0 \\ 0 & -3 & 0 \\ 0 & 0 & 0  \end{bmatrix}$ also,  $\ A^2 + A -2I = (A + 2I)(A-I) $ I can see that if I place $\ M$ instead so $\ (M+2I)(M-I) = D$ yet this is far from proving.","['matrices', 'linear-algebra']"
2898895,Vakil 3.2.P - Morphism between Spec induced by Ring Morphism,"I'm currently working my way through Vakil's exercise 3.2.P, which goes as follows Suppose $k$ is a field, $f_1,...,f_n\in k[x_1,...,x_m]$ are given. Let $\phi: k[y_1,...,y_n]\mapsto  k[x_1,...,x_m]$ be the ring morphism given by $y_i\mapsto f_i$ . (a) Show that $\phi$ induces a map of sets $\operatorname{Spec}k[x_1,...,x_m]/I\rightarrow\operatorname{Spec}k[y_1,...,y_n]/J$ for any ideals $I\subset k[x_1,...,x_m]$ and $J\subset  k[y_1,...,y_n]$ (b) Show that the map of part (a) sends the points $(a_1,...,a_m)\in k^m$ (or more precisely, $[(x_1-a_1,...,x_m-a_m)]\in\operatorname{Spec} k[x_1,...,x_m]$ ) to $(f_1(a_1,..,a_m),...,f_n(a_1,...,a_m))\in k^n$ . I think I know how to prove part (a). This comes from applying this fact (which is fairly easy to prove): Fact 1: If $\phi:B\rightarrow A$ is a map of rings, and $\mathfrak{p}$ is a prime ideal of $A$ , show that $\phi^{-1}(\mathfrak{p})$ is a prime ideal of $B$ . What I'm struggling with is part (b). So, suppose I have some prime ideal $(a_1,...,a_m)$ (or, more accurately, $[(x_1-a_1,...,x_m-a_m)]\in\operatorname{Spec}k[x_1,...,x_m]$ ). Obviously by the induced map in part (a), it will be sent to the prime ideal $\phi^{-1}((a_1,...,a_m))\in k^{n}$ . Except I have trouble seeing how $\phi^{-1}((a_1,...,a_m))=(f_1(a_1,...,a_m),...,f_n(a_1,...,a_m))$ . I guess I also don't understand how $\phi$ acts on the above... for instance, is it the case that $\phi:f_1(a_1,...,a_m)\mapsto f_1$ ? I'm not really sure what this means to be honest. There's probably something obvious that I'm missing at the moment... can somebody help (or have I misunderstood something crucial?)","['ring-theory', 'algebraic-geometry', 'commutative-algebra']"
2898944,"$\frac{d}{dx} \int_a^b f(x,t) dt =\int_a^b \frac{\partial}{\partial x}f(x,t)dt?$","I have studied Advanced Calculus by Fitzpatrick which discusses the so called the Second Fundamental Theorem (Differentiating Integrals) but it is when the upper or lower limits of integral is a function of $x$ and differentiation is on $x$. But differentiation of the type in the title is not discussed at all and is used in another textbook without a proof; so what is a clear proof for equation $$\dfrac{d}{dx} \int_a^b f(x,t) \ dt =\int_a^b \frac{\partial}{\partial x}f(x,t) \ dt?$$","['integration', 'definite-integrals', 'derivatives', 'real-analysis']"
2898949,On a differential inequality,"Let $A>0$. If $f$ satisfies the differential inequality $f^{\prime\prime}(t)+f(t)â‰¥A$, and $y$ is the solution to the ODE 
$y^{\prime\prime}(t)+y(t)=A$ with $y(0)=f(0)$ and $y^{\prime}(0)=f^{\prime}(0)$, then
\begin{equation}\label{GP}
 \begin{cases} 
f(t)\leq y(t) \quad \text{for all $t<0$}\\
f(t)\geq y(t) \quad \text{for all $t>0$}.
\end{cases} 
\end{equation} Question: How can I prove this result?","['integral-inequality', 'ordinary-differential-equations']"
2898973,Expected number of students that don't have someone cheating from them.,"I recently watched this 3Blue1Brown video that has a small problem at the end (9:41) , which I haven't been able to solve. The problem is the following (my own phrasing): Suppose that you have $n$ students sitting in a circle taking a test. It's a hard test, so each student tries to cheat off of his neighbour, choosing randomly which neighbour to cheat from. What is the expected number of students that does not have a neighbour cheating from them? I am aware that it is stated in the video that a link to a solution can be found in the description. I have not been able to find a solution following this link, however. I have found the following values:
$$\begin{array}{c|ccccc}
n&3&4&5&6&7\\
\hline
E(n)&\frac{3}{4}&\frac{4}{4}&\frac{5}{4}&\frac{6}{4}&\frac{7}{4}
\end{array},$$
which suggests that $E(n)=\frac{n}{4}$ for $n>2$, but I do not see how to prove this. I keep on running into the problem of the probabilities not being independent. I've also tried to phrase the problem in terms of 'paths' formed by following which student is watching which, but this has not lead to anything so far. Any help or hint is welcome.","['expected-value', 'recreational-mathematics', 'combinatorics', 'probability']"
2898974,Derivative of $d^2x/dy^2$,"Using the quotient rule and the chain rule you get
$$ \frac{d}{dy}\left(\frac{dx}{dy}\right)=\frac{d}{dy}\left(\frac{1}{\frac{dy}{dx}}\right)
=\frac{d}{dx}\left(\frac{1}{\frac{dy}{dx}}\right)\times \frac{dx}{dy}\\$$ I don't understand how this came. First is dy/dx always gonna be equal to dx/dy?  Wouldn't the function have to be inverse to each other. And how to do chain rule in cases like this... I didn't get how the differentiation is done here. Can you explain with a simple example how chain differentiation like these are done. I am not too good at differentiation",['derivatives']
2898981,Question on a proof that there are infinitely many primes,"There are several ways to prove this fact, and I can think of two reasonably clear ways, but my professor presented a sketch of a proof that I can't quite follow. I'm going to replicate his logic as best as I can. Theorem. There are infinitely many primes. Proof. Assume for a contradiction that there are only finitely many primes, which we can list as $p_1, p_2, p_3, \ldots, p_m$ for some $m \in \mathbb{N}$. Then, form the product 
\begin{align*}
N = \mathop{\Pi}\limits_{i=1}^m p_i + 1.
\end{align*}
From here there are several ways to proceed. But, this is where I find myself getting confused. Since $\mathbb{Z}$ is closed under multiplication and addition, $N \in \mathbb{Z}$, and since $N > p_i, \forall i$, $N$ is not a prime. So, there exists some $p_i$ such that $p_i \mid N$, so $\exists a \in \mathbb{Z}, a \cdot p_i = N$, i.e., $a \cdot p_i = p_1 \cdot p_2 \cdot p_3 \cdots p_m + 1$. From here, my professor concluded that $\frac{1}{p_i} \in \mathbb{Z}$, an absurdity and thus a contradiction. I can't quite figure out how to get there. If we divide both sides through by $p_i$, since $1 \leq i \leq m$, we get $a$ on the LHS and two terms on the RHS, one of which is a product of $m - 1$ primes (after cancelling) and one of which is $\frac{1}{p_i}$. From here, perhaps we could subtract the product of $m - 1$ terms, clearly an integer by closure under multiplication, from $a$, also an integer. Then, by closure under subtraction, $a$ less this product is also an integer, in which case we've found our contradiction. Is this correct? Thanks in advance.","['number-theory', 'proof-explanation', 'prime-numbers']"
2898983,Finding a set of continuous functions with a certain property 2,"I need help finding the set of continuous functions $f : \Bbb R \to \Bbb R$ such that for all $x \in \Bbb R$, the following integral converges: $$\int_0^1 \frac {f(x+t) - f(x)} {t^2} \ \mathrm dt$$ I think it might be the set of constant functions but i havent been able to prove it :( I was thinking that you can use the stone weiestrass theorem considering the set of continuous functions on a closed  interval(non trivial) ,and a subset which contains the set of continuous functions whose integral above diverges in some point in that interval along with  with the set of constant functions.
So in order to solve the problem i need only to prove that if two functions do not meet the condition of the problem then their product does not as well . I hope you can provide some insight and thank you .","['calculus', 'general-topology', 'real-analysis']"
2899014,Why a spectral resolution should be left-continuous?,"The usual definition I can find (almost) everywhere on the literature of a spectral resolution on a Hilbert space $\mathscr{H}$ is this: a family of orthogonal projections $(E_t)_{t \in \mathbb{R}}$ such that $t \leq s \implies E_t \leq E_s$ $\lim_{t \rightarrow -\infty} E_t = 0 \ , \quad \lim_{t \rightarrow +\infty} E_t$ $\lim_{t \searrow s} E_t = E_s$, where the limit is always taken in the strong topology sense. I wonder why one would ask the property 3 of a spectral resolution and not left-continuity. I've heard that right-continuity should actually be a better choice for a measure-theoretical reason: we can always take the limit of a measure of a sequence of increasing measurable sets and that doesn't work always if the sequence is decreasing, but I'm not convinced of that.","['spectral-theory', 'functional-analysis']"
2899015,Difference between $\sin^{-1}(x)$ and $\frac1{\sin(x)}$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How are arcsine and cosecant different mathematically if cosecant is $\frac{1}{\sin(x)}$ and arcsine is $\sin^{-1}(x)$ which is $\frac{1}{\sin(x)}$? I have tried to find an answer before but nobody explained it well enough.","['algebra-precalculus', 'inverse-function', 'trigonometry']"
2899031,Prove that $(1+x)^\frac{1}{x}+(1+\frac{1}{x})^x \leq 4$,"Prove that $f(x)=(1+x)^\frac{1}{x}+(1+\frac{1}{x})^x \leq 4$ for all $x>0.$ We have $f(x)=f(\frac{1}{x}), f'(x)=-\frac{1}{x^2}f'(\frac{1}{x}),$ so we only need to prove $f'(x)ï¼ž0$ for $0 < x < 1.$","['jensen-inequality', 'real-analysis', 'maxima-minima', 'inequality', 'exponential-function']"
2899048,"Find all triples $(p,x,y)$ such that $ p^x=y^4+4$","Find all triples $(p,x,y)$ such that $ p^x=y^4+4$, where $ p$ is a prime and $ x$ and $ y$ are natural numbers. I know that this question has already been asked on another forum, but I want to ask different questions about it. $ p^x=y^4+4$ $ p^x=(y^2+2)^2 - (2y)^2$ $p^x = (y^2+2y+2)(y^2-2y+2)$ Then: $p^k = y^2+2y+2$ and $p^j= y^2-2y+2$ The solutions I saw were different from here and they just wanted to prove that $(5,1,1)$ was the only solution. IÂ´ll just ask what I didn't understand: 1) Therefore, $p^k = (y+1)^2+1$ and $p^j= (y-1)^2+1$ And then: $(y+1)^2 \equiv (y-1)^2 \equiv -1 \pmod p$ So here $-1$ is a quadratic residue, and therefore $p= 4n+1$. I understood his solution until this part. I know that $p= 4n+1$ because I saw that was one of the properties of quadratic residues, but would like to see a proof of it if possible. He then says that by$\mod 8$ , $ k$ and $j$ had different parity, so $x$ was odd. Then he assumes that $p, k >1$ and says: If $k=2m$, then: $(y+1)^2= (p^m+1)(p^m -1)$ or if $j= 2m$: then $(y-1)^2= (p^m+1)(p^m -1)$ and affirms those equations have no solution, that might be a property but want to know about it anyway. Then he says there are no solution for $x>1$, then $p = (y^2+2y+2)(y^2-2y+2)$, so $1=y^2-2y+2$ and that was the triple $(5,1,1)$, therefore that is the only solution. 2) He started off by saying: if $y$ is even then $ p^k \equiv  p^j \equiv 2 \pmod 4$ then $a = b =1$ and that is not possible, therefore $y$ is odd. Since $ 4y = p^{b} - p^{a}$, therefore $ p^{b-a}=5$, $ p^{a}=y$ $ 2y^{2}+4=p^{b}+p^{a}$, if $ a\neq 0$, then $ y^2 \equiv 3\mod 5$, which is impossible. I donÂ´t know how you can deduce those things. After that he affirmed that $(5,1,1)$ was the only solution. 3) He showed that $y$ was odd and said: $gcd (y^2+2y+2, y^2-2y+2) = gcd (y^2+2y+2, 4y) = 1$ (I think this is also a property but I donÂ´t even know it). And since $y^2+2y+2 >  y^2-2y+2$, then $y^2+2y+2=p^x$ and $y^2-2y+2 =1$, so $y=1$ and $(5,1,1)$ was the only solution. Sorry if I asked many things, I just thought those things may be useful for other problems. I pointed out the things I didnÂ´t understood so that it was easy to see them. Thanks in advance.","['number-theory', 'quadratics', 'diophantine-equations']"
2899050,Solve $x^3-y^3-z^3=3^t \cdot 2xyz$,"Solve the diophantine equation $x^3-y^3-z^3=3^t \cdot 2xyz,(x,y,z \in \Bbb N)$,  where $t\in \Bbb N.$ We can find infinitely many solutions for $t=1$ from initial solution $x=52,y=21,z=19$. I search for all $x<13000$ but find no solution for $t>1$, I want to know if there are any solutions for  $t>1$.","['number-theory', 'diophantine-equations']"
2899059,Question for triangle,"In the proof of Cauchy-Goursat Theorem, the following fact was used: The distance between any point $z$ on a triangle and a point $z_0$ interior to the triangle is less than half the perimeter of the triangle. I think it is true, but I don't know how to prove it. I'd like to prove the above assertion rigorously. Please let me know if you have any comment for this. Thanks in advance.","['complex-analysis', 'calculus', 'geometry', 'inequality']"
2899075,"Assuming the Axiom of Countable Choice, an infinite set $A$ is Dedekind-infinite","Theorem: Assuming the Axiom of Countable Choice, an infinite set $A$ is Dedekind-infinite. Lemma 1 : assuming the Axiom of Countable Choice, if $A$ is an infinite set, then $A$ contains a countably infinite subset. Please check my below proof! Thank you for your help! By Lemma 1 , there exists a countably infinite subset $B$ of $A$. Let $(b_1,b_2,\cdots)$ be a listing of the elements of $B$, without repetition. We define a function $f:A \to A$ by $f(b_i)=b_{2i}$ for all $i \in \mathbb N$ and $f(a)=a$ for all $a \in A \setminus B$. Then $f$ is clearly injective. Furthermore, $f(A)=A \setminus \{b_1,b_3,b_5,\cdots\}$, then $f(A) \subsetneq A$.  Hence $f:A \to f(A)$ is a bijection from $A$ to a proper subset of $A$. Consequently, $A$ is Dedekind-infinite.","['elementary-set-theory', 'proof-verification']"
2899076,"Limit as $(x,y,z)\to (0,0,0)$ of $f(x,y,z) = \dfrac{xy+yz+xz}{\sqrt{x^2+y^2+z^2}}$","To find this limit, I converted to spherical coordinates and rewrote: $$\lim_{r\to 0} \dfrac{r^2(\sin^2\theta \cos\phi \sin \phi + \sin\theta \cos \theta \sin \phi + \sin\theta \cos \theta \cos \phi)}{r} = 0$$ Is this method alright? Our teacher did using epsilon delta proof, so how can we use something similar to spherical coordinates if say we had four variable limit of kind: $$\lim_{(w,x,y,z) \to (0,0,0,0)} \frac{xy+yz+xz+wx}{
\sqrt{x^2+y^2+z^2+w^2}}$$","['limits', 'multivariable-calculus']"
2899091,"Showing $\lim_{(x,y) \to (0,0)} xy \log(x^2+y^2) = 0$","First I let $x=r\cos \theta, y = r\sin \theta$ and so limit $$\lim_{r\to 0} r^2\sin2\theta \log(r)$$ Now, in region $0<x<1$, $\log(x) < 1/x$ 
$$|r^2\sin 2\theta \log (r) - 0| < |r\sin 2\theta| \le |r| < \delta < \epsilon$$ So limit exist if $\delta < \epsilon$ and limit is 0. Other way, I used L hospital, I don't know if we can apply, but I wrote $r^2 \log r$ as $\log(r) / (r^{-2})$ which again gave 0.","['limits', 'multivariable-calculus']"
2899114,MP test construction for shifted exponential distribution,"For the pdf $f_{\theta}(x)=e^{-(x-\theta)} , x \ge \theta$, find a most powerful test of size $\alpha$, using Neyman Pearson Lemma to test $\theta=\theta_{0}$ against $\theta=\theta_1(> \theta_0)$, based on a sample of size $n$. I am facing difficulty as the parameter here is range dependent 
However, if $X_{(1)}>\theta_1$, then $f_1(x)>\lambda f_0(x)$ if $e^{n(\theta_1- \theta_0)}> \lambda$ would mean rejection of null hypothesis.
But how will I make this test a size $\alpha$ test? The ratio is coming to be constant.
Please help!","['statistical-inference', 'statistics', 'hypothesis-testing']"
