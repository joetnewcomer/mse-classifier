question_id,title,body,tags
3062109,"Is $ f(A) = A + 2A^{T} $ an isomorphism of $ \mathbb R^{5,5} $ onto itself?","I have problem with prove or disprove this hypothesis: Is the linear transformation $ f \in L(\mathbb R^{5,5},\mathbb R^{5,5}) $ $$ f(A) = A + 2A^{T} $$ an isomorphism of the space $ \mathbb R^{5,5} $ onto itself? In order to be an isomorphism, $f$ must be injective and surjective. Checking if it is surjective: Assume that as a result we want to get: $$\mathbf{Q} = 
 \begin{bmatrix}
 q_{11} & q_{12} & \cdots & q_{1n} \\
 q_{21} & q_{22} & \cdots & q_{2n} \\
 \vdots & \vdots & \ddots & \vdots \\
 q_{m1} & q_{m2} & \cdots & q_{mn}
 \end{bmatrix} $$ and we put as argument $$  \mathbf{A} = 
 \begin{bmatrix}
 a_{11} & a_{12} & \cdots & a_{1n} \\
 a_{21} & a_{22} & \cdots & a_{2n} \\
 \vdots & \vdots & \ddots & \vdots \\
 a_{m1} & a_{m2} & \cdots & a_{mn}
 \end{bmatrix} $$ then choose $i,j$ . Factors $a_{ij}$ $a_{ji}$ $q_{ij}$ $q_{ji}$ are only in this linear system: $$q_{ij} = a_{ij} + 2a_{ji}  \wedge  q_{ji} = a_{ji} + 2a_{ij}$$ so $$ a_{ij} = \frac{2q_{ij}-q_{ji}}{3} $$ and $$ a_{ji} = \frac{2q_{ji}-q_{ij}}{3} $$ so the factors $ a_{ij}$ $ a_{ji}$ are determined unambiguously. So it is surjective. But how to deal with checking injectivity? Suppose that $$ A+2A^T=B+2B^T $$ $$ A-B = 2(A^T-B^T) $$ and I don't know how to finish that.","['matrices', 'linear-algebra', 'vector-space-isomorphism']"
3062125,"In $\Delta ABC$ if $(\sqrt{3}-1)a=2b$, $A=3B$, then find $C$","In $\Delta ABC$ if $(\sqrt{3}-1)a=2b$ , $A=3B$ , then find $C$ My Attempt $$
b=\frac{\sqrt{3}-1}{2}a\quad\& \quad \frac{A-B}{2}=B\quad\&\quad\frac{A+B}{2}=2B\\\frac{a-b}{a+b}=\frac{\tan\frac{A-B}{2}}{\tan\frac{A+B}{2}}\implies \frac{3-\sqrt{3}}{\sqrt{3}+1}=\frac{\tan B}{\tan 2B}=\frac{1-\tan^2B}{2}
$$","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
3062126,tough question in Line integral / Multivariable Calculas,"Let $C$ be a curve in the $(x − y)$ -plane. For every point $(x, y)$ of $C$ let $u(x, y)$ denote the unit vector in the direction of the tangent line
  to $C$ at $(x, y)$ . Let $S$ be the surface obtained by taking the union of
  all straight line segments connecting $(1, 2, 3)$ to points of $C$ . Express
  the area of $S$ as an integral of the first type , on the curve $C$ , of some
  function of $x$ and $y$ . (hint: try to use the function $u(x, y)$ .) really Hard question , i couldn't understand how to use the fact that line integral will help here since i don't have a function $f(x,y)$ to calculate $ \int_{C} f(x(t),y(t))\sqrt{x'(t)^2 + y'(t)^2 }\ dt$ also i can parameterize $S$ like that : $S=:k(1-x(t),2-y(t),3) , k\in[0,1]$ where $(x(t),y(t),0)$ is the curve $C$ and why $u(x,y)$ is given here.
Unit vector","['integration', 'multivariable-calculus']"
3062135,Taking a derivative of a magnitude of a vector,"I have found several questions including this as a step in the explanation, but have not been able to find an explicit explanation of how to take a derivative of a magnitude of a vector. I am trying to take the derivative d/dt ||r'(t)|| but don't know how to address the magnitude signs.","['multivariable-calculus', 'vectors']"
3062154,Partial Derivative with Respect to Multiple Variables,"If we take a multivariable function such as $w=f(x,y,z)=x^2+y^2+z^2$ , I understand that we can take its partial derivative with respect to any one of its arguments, while the others stay unchanged. In this case, we can take the partial derivative with respect to $z$ as $\frac{\partial}{\partial z}f(x,y,z)$ . I also understand that we can take its total derivative which is with respect to all of its arguments, which can be expressed as $\frac{dt}{dw}f(x,y,z)$ . My question: how do we represent the derivative with respect to some but not all of a multivariable function's variables? How is this derivative classified? I am tempted to think it is partial but I am not sure since all of the definitions I have seen give it with respect to a single variable. Is it a ""partial"" total derivative?","['partial-derivative', 'multivariable-calculus']"
3062165,Transformation of a second order ODE,"I have to transform a second order differential equation into a Bernoulli type differential equation, however, I am having some trouble.
The original equation is: \begin{equation}
u\frac{d^{2}u}{dt^{2}} - \bigg(\frac{du}{dt}\ \bigg)^{2} +(\gamma -x_{0}\beta u)u\frac{du}{dt}=0
\end{equation} By defining a new function: \begin{equation}
\phi = \frac{dt}{du}
\end{equation} The original equation has to be transformed into: \begin{equation}
\frac{d\phi}{du} + \frac{1}{u}\phi = (y-x_{0}\beta u) \phi^{2} 
\end{equation} Would anyone be willing to suggest any ideas for how this might be achieved?
Thank you!",['ordinary-differential-equations']
3062176,"If every sequence $(x_{n}) \subset X$ and $(\lambda_{n}) \subset \mathbb{R}$ we have $\lim \lambda_{n}x_{n} = 0$, then $X$ is bounded","Let $(V,\Vert \cdot \Vert)$ a normed vector space. (a) Prove that if $A,B \subset V$ with $A$ open, then $A + B$ is open. (b) Is there disjoint open sets $A_{1},A_{2}$ for which there is no disjoint closed sets $F_{1},F_{2}$ such that $A_{1} \subset F_{1}$ and $A_{2} \subset F_{2}$ ? (c) Prove that if $X \subset V$ is bounded, then for every sequence $(x_{n}) \subset X$ and $(\lambda_{n}) \subset \mathbb{R}$ with $\lim \lambda_{n} = 0$ we have $\lim \lambda_{n}x_{n} = 0$ . What about the converse? My attempt. (a) Let $A$ be an open set. So, $A + b = \{a+b \mid a \in A\}$ is translation, therefore, is open. But $\displaystyle A + B = \bigcup_{b \in B}(A+b)$ , then $A+B$ is open. (b) Take $A_{1} = \mathbb{R}_{>0}$ and $A_{2} = \mathbb{R}_{<0}$ , because $\overline{A_{1}} = A_{1}\cup\{0\}$ and $\overline{A_{2}} = A_{2}\cup\{0\}$ (c) If $(x_{n})$ is a sequence in $X$ , then $(x_{n})$ is bounded. But $$(x_{n}) = ((x_{1,n}),(x_{2,n}),...,(x_{k,n}))$$ where each $(x_{i,n})$ is a bounded sequence in $\mathbb{R}$ . Thus, $\lim \lambda_{n}x_{i,n} = 0$ for each $i$ , then $\lim \lambda_{n}x_{n} = 0$ . The converse seems true, but I cannot prove. Can someone help me?","['general-topology', 'metric-spaces']"
3062196,Finite Presentation of a subgroup,"I have the group $\langle a,b \mid a^3b^3\rangle$ Now I send both $a$ and $b$ to the generator of $\mathbb{Z}/3\mathbb{Z}$ . This gives a well-defined homomorphism from our group to $\mathbb{Z}/3\mathbb{Z}$ and I am asked to find a finite presentation of the kernel of this homomorphism. How do I generally tackle these kind of questions? I know about covering spaces, fundamental groups of spaces, I understood I should take a cell complex and then find a cover corresponding to that subgroup, but I don't get how to do it so far.","['group-presentation', 'abstract-algebra', 'covering-spaces', 'geometric-group-theory', 'group-theory']"
3062226,"If $f \circ f = 0 $, show that transformations $f + id_x$ and $f - id_x$ are isomorphisms of $X$","I have a problem with this task: The linear transformation $f \in L(X,X)$ has property $f \circ f = 0 $ Show that transformations $f + id_x$ and $f - id_x$ are isomorphisms of $X$ space with itself If I need to be honest I have no idea how to prove this. I was tryinging something like that: If $f + id_x$ is isomorphism it must be both injective and surjective. Ok, but $id_x$ is injective and surjective. I thought to show that f is surjective but unfortunately sum of two surjectives can give me something what is not surjective... Maybe the key is in $f \circ f = 0 $ ?
Thanks for your time!","['proof-writing', 'linear-algebra']"
3062247,"Function Optimization with Non-linear Constraint, Lagrange Multipliers Fails","I am trying to maximize the function $A(x,y)=\frac{1}{2}(x(12-x)+y(13-y))$ subject to the constraint $x^2+(12-x)^2-y^2-(13-y)^2=0$ . My attempt: $\begin{align*} \nabla A=\frac{1}{2}\langle 12-2x,\,13-2y\rangle &= \lambda\langle4x-24,\, -4y+26\rangle\\ \implies&\begin{cases} -x+6=\lambda(4x-24)\\-y+\frac{13}{2}=\lambda(-4y+26)\\x^2+(12-x)^2-y^2-(13-y)^2=0\end{cases}\end{align*}$ But clearly there is no solution due to the first two equations. Using Wolfram Alpha , however, yields a maximum at $\displaystyle \left(\frac{17}{2},\,\frac{13}{2}\right)$ being $A=36$ and shows a nice little graph.","['multivariable-calculus', 'calculus']"
3062255,On the definition of Liouville number,"Definition : (from Wikipedia) In number theory, a Liouville number is a real number $x$ with the property that, for every positive integer $n$ , there exist integers $p$ and $q$ with $q > 1$ and such that $$
  {\displaystyle 0<\left|x-{\frac {p}{q}}\right|<{\frac {1}{q^{n}}}.} 
$$ A Liouville number can thus be approximated ""quite closely"" by a sequence of rational numbers. [....] My question: How can I convince myself that the above definition is not arbitrary.  In other words, how nice is to know that a given number $\alpha$ is a Liouville number?","['analytic-number-theory', 'number-theory', 'elementary-number-theory']"
3062274,Is there a natural group of subgroups of a group?,"Take a group $G$ , and consider the set of all its subgroups. Is there a natural way to define multiplication of subgroups, in such a manner that the set forms a group? If so, how is the operation constricted, and what is this group called? The reason I came up with the question and why it might seem natural is this. A consequence of the isomorphism theorems is that $HH'/H\cong H'$ whenever $H,H'$ are disjoint subgroups and $H$ is a normal subgroup of $G$ , and furthermore, if $H,H'$ both happen to be normal subgroups in $G$ with $H\leq H'\leq G$ , then $(G/H)/(H'/H)\cong G/H'$ . So in some twisted sense, it seems like for at least a certain situations and for certain types of subgroups of $G$ , there may be a natural method of defining multiplication that allows us to actually ""do arithmetic"" over the subgroups of $G$ ? This is in the sense that, over this proposed group, we can actually just ""cancel $H$ "" in $(G/H)/(H'/H)\cong G/H'$ as a consequence of how multiplication is defined. It seems very interesting (to me, at least) what the consequences of defining such a group might be. Sorry if the question is vague, but here's an idea of what I'm not looking for: Take any group, consider all its $n$ subgroups, and define multiplication in some arbitrary way, such as the multiplication over $\mathbb Z/n\mathbb Z$ . If we do this, we completely lose the fact that these elements started out as subgroups of a group, and the interesting algebraic structure is lost! Instead, I'm interested in whether there is such a way of defining this group of subgroups that preserves the algebraic properties of the original group $G$ . A naïve construction I tried that doesn't work: for two subgroups $H,H'$ of an abelian group $G$ , define $HH'=\{hh':h\in H,h'\in H'\}$ . It's quite easy to verify this always gives a subgroup of $G$ , so we have closure, and associativity and such are easily checked too. The problem is that most subgroups of $G$ have no inverse in this ""group"" of subgroups for a general group $G$ , because for $HH'=1$ , we require $hh'=1$ for every $h\in H$ , $h'\in H'$ which is not possible in all but the most trivial cases. As noted in the comments, if we removed the hypothesis that $G$ is abelian, then its subgroups need not be normal, and this construction fails even more badly since we don't even have closure anymore. So in general, this construction would not go anywhere close to working. Any thoughts, or links to something that has already been done, are greatly appreciated!","['group-theory', 'abstract-algebra']"
3062293,Can a function be smooth at a single point?,"I saw a thread ( Find a function smooth at one isolated point ) in which it is asked whether or not it is possible for a function to be smooth at a point, but not smooth on a deleted neighbourhood  of said point. The thread is closed with an accepted answer despite the answer seeming to be incorrect, so I would like to re-ask the question here. I have read (here: Example of a function continuous at only one point. ) that $$f=\begin{cases}x\,\mathrm{if}\,x\in\mathbb{Q}\\
0\,\mathrm{if}\,x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases}$$ is only continuous at $x=0$ . If it is continuous at $x=0$ , then maybe $$f=\begin{cases}\sum_{k=1}^{\infty}x^k\,\mathrm{if}\,x\in\mathbb{Q}\\
0\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\mathrm{if}\,x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases}$$ is smooth at $x=0$ and nowhere else (does this work?).","['derivatives', 'smooth-functions', 'real-analysis']"
3062304,Subsets of a set with common elements between themselves,"Let $S=\{1,2,\ldots,n\}$ . Let $A_i\subset S$ for $i\in\{1,2,\ldots,m\}$ . Impose the following conditions $|A_i|=r$ with $r<n$ for all $i$ . $|A_i\cap A_j|=t$ for all $i\neq j$ , with $t<r$ . Let $n,r,t$ be fixed. What is the maximum number $m$ of subsets $A_i$ that satisfy these conditions? The question arises from my observation of a game called Rafly, where there are 55 cards, each with 8 images on them. No matter which 2 cards you pick, they have one and only one common image. I want to generalize this game by using the minimum number of $n$ images, having $m$ cards, each with $r$ images and $t$ common images. However, I am having trouble with finding $m$ given $n,r$ and $t$ . In the case of $t=1$ I start to build the cards like this: $$A_1 = \{1,2,\ldots,r\}.$$ A new card must have one common element with the first card: $$A_2 = \{c_{1,2}, r+1,\ldots, 2r-1 \},$$ where $c_{1,2}\in A_1$ . A new card must have one common element with the second and first cards: $$A_3 = \{c_{1,3},c_{2,3}, 2r,2r+1,\ldots, 3r-3\},$$ where $c_{1,3}\in A_1$ and $c_{2,3}\in A_2\setminus A_1$ . Following this reasoning I conclude that there are $n=r(r+1)/2$ different images. But how many cards are there? How are these quantities related to $t$ ? Thanks a lot.","['combinatorial-designs', 'combinatorics', 'extremal-combinatorics']"
3062306,Primes in $\mathbb{Z}[\sqrt{2}]$?,"It's a well known result that the gaussian primes $\mathbb{Z}[i]$ can be characterized as normal primes $3 \bmod 4$ or normal primes $3\bmod 4$ times $i$ . As well as $a+bi$ where $a,b$ are non-zero and $a^2 + b^2$ is prime. How does one characterize the primes of the ring $\mathbb{Z}[\sqrt{2}]$ ? Or generally of $\mathbb{Z}[\sqrt{n}]$ ?","['number-theory', 'ring-theory', 'abstract-algebra', 'algebraic-number-theory']"
3062389,Does the Polygonal Confinement Theorem hold on the set of entire functions?,"The Polygonal Confinement Theorem can be found in Section 2 of this paper by Rosenthal. I am interested in a generalization of Lemma 3.1 in the paper, which states: $\textbf{Lemma 3.1:} $ If $v_1,\ldots,v_m \in \mathbb{R}^n$ , and $\left\|\displaystyle \sum_{i=1}^m v_i\right\|<\epsilon$ , $\|v_j\|<\epsilon$ for all $j$ , then there is a constant $C$ which does not depend on $m$ and a permutation $\sigma$ of $\{1,\ldots,m\}$ such that for each $1\leq j\leq m$ , $$ \left\|\sum_{i=1}^j v_i\right\| \leq C\epsilon.$$ I am wondering whether the following analogue for entire functions holds. In the question below, $\|f\|_R$ denotes the supremum of $f$ on the disk $|z|\leq R$ . $\textbf{Question:}$ Suppose $R>0$ and $f_i$ are entire functions on $\mathbb{C}$ . Let $\epsilon>0$ .  If $\displaystyle \left\| \sum_{i=1}^m f_i \right\|_R< \epsilon$ and $\displaystyle \|f_j\|_R < \epsilon$ for each $j$ , does there exist a constant $C$ independent of $m$ and a permutation $\sigma$ of $\{1,\ldots,m\}$ such that whenever $1\leq j\leq m$ , $$ \left\| \sum_{i=1}^j f_{\sigma(i)} \right\|_R< C\epsilon?$$ Lemma 3.1, called the rearrangement theorem by Rosenthal and the Steinitz lemma by others, was the crucial element for proving the Levy-Steinitz theorem (found in the Rosenthal paper).  The Levy-Stenitz theorem was generalized to metrizable nuclear topological vector spaces by Banaszczyk in this paper .  Since the space of entire functions is a Frechet space, and hence a nuclear space, I am hoping that the analgoue of Lemma 3.1 holds.  In fact, it looks like the Corollary in the Banaszczyk paper on page 196 may be what I'm looking for.  But the generality and technicality of the paper is well beyond my expertise. Any insight or references would be most appreciated.","['complex-analysis', 'topological-vector-spaces']"
3062393,Problem in evaluating logarithm derivatives,"Given the property of the logarithm that $\log{xy} = \log{x} + \log{y}$ , how would one take the 'derivative' of this? To be more clear, $\log{xy} = \log{x} + \log{y}$ (property of $\log$ ) $D(\log{xy}) = D(\log{x} + \log{y})$ (i) (Take derivative on both sides) Now, $D(\log{x} + \log{y}) = D(\log{x}) + D(\log{y})$ (ii) (Derivative of sum is sum of derivatives) Combining (i) and (ii): $D(\log{xy}) = D(\log{x}) + D(\log{y})$ (iii) Implies: $\frac{1}{xy} = \frac{1}{x} + \frac{1}{y}$ (Evaluate derivative of logarithm using $D(\log{x}) = \frac{1}{x}$ $\frac{1}{xy} = \frac{1}{x} + \frac{1}{y}$ looks false to me; e.g. while $\log{6}$ does equal $\log{2} + \log{3}$ , $\frac{1}{6}$ does not equal $\frac{1}{2} + \frac{1}{3}$ . My first guess was that the issue was related to what variable I take the derivative with respect to, but I'd like to understand this a little more formally if someone could guide me. What's going wrong in this example?","['calculus', 'logarithms', 'real-analysis']"
3062424,How to find orthogonal eigenvectors if some of the eigenvalues are the same?,"I have an example: $$A=\begin{pmatrix} 2 & 2 & 4 \\ 2 & 5 & 8 \\ 4 & 8 & 17 \end{pmatrix}$$ The eigenvalue I found is $\lambda_1=\lambda_2=1$ and $\lambda_3=22$ . For $\lambda=1$ , $$\begin{pmatrix} x\\ y \\ z \end{pmatrix}=\begin{pmatrix} -2\\ 1 \\ 0 \end{pmatrix}y+\begin{pmatrix} -4\\ 0 \\ 1 \end{pmatrix}z$$ For $\lambda=22$ , $$\begin{pmatrix} x\\ y \\ z \end{pmatrix}=\begin{pmatrix} 1/4\\ 1/2 \\ 1 \end{pmatrix}z$$ However, those eigenvectors I found are not orthogonal to each other. The goal is to find an orthogonal matrix P and diagonal matrix Q so that $A=PQP^T$ .","['linear-algebra', 'eigenvalues-eigenvectors']"
3062432,Prove the size of a hyperbolic angle is twice the area of its hyperbolic sector.,"I'm trying to figure out how the hyperbolic functions are derived using a unit hyperbola. According to this walkthrough , argument $u$ in $(\cosh(u), \sinh(u))$ should be equal to $2A$ , where $A$ is the area of an intercepted hyperbolic sector from $(0,0)$ to $(\cosh(u), \sinh(u))$ . Confused as to why this is defined as such, I found on Wikipedia : The size of a hyperbolic angle is twice the area of its hyperbolic sector. The hyperbolic functions may be defined in terms of the legs of a right triangle covering this sector . However, I couldn't find a explanation for this anywhere. Can anyone help show me why this is?","['trigonometry', 'calculus', 'geometry', 'hyperbolic-functions']"
3062433,Selecting a menu,"While perusing old unanswered puzzle questions, I came across this one . I found it quite interesting, but a bit vague, so I've decided to recast it. A party is to be held at a restaurant. The restaurant has the ability to make $D$ different dishes, but the menu for the party will be a fixed menu featuring just $d$ dishes, where $d < D$ . To select which dishes should be on the menu, the $n$ guests are asked to rank all D dishes. For which values of $D$ , $d$ and $n$ is it always possible to select $d$ dishes such that for any dish $k$ not on the menu, more than half the guests would prefer one of the dishes in the menu over dish $k$ ? Let's look at a concrete example. Suppose the number of possible dishes was $D=10$ , the number of selected dishes was $d=3$ and the number of guests was $n=10$ . The worst possible ranking I can think of (though I'm not sure it is the worst) is shown below: The ranks are spread out so no guest ranks any dish the same. I now selected the $3$ dishes marked in green so that the ranks of $1,2, 3$ were distributed among the guests as much as possible. Thus, only guest $10$ does not have one of the selected dishes in his top $3$ . If you now go through each of the unselected dishes, you will see that in every case a majority of the guests will have a higher ranked dish among the $3$ selected dishes. So (assuming my worst case actually is the worst case!) with these values of $D$ , $d$ and $n$ , it is always possible to select such a menu. Any input as to whether a worse case ranking is possible, would also be appreciated. EDIT - Partial results After fiddling with this question, I realize I should probably have asked ""Given $n$ and $D$ , what is the minimum required $d$ to fulfill the constraint?"". Afterall, if a certain value of $d$ works, then so will any larger value of $d$ . My biggest problem, oddly, is how to know the worst possible ranking. To test conjectures, I need to test them against the worst case. But I'm not completely sure what that is, for a given $n$ and $D$ . Anyway, an initial result is that a menu is always possible if $d > \frac{n}{2}$ . A second tentative result is that if $n = D$ then $d = 2$ . E.g., if I select dish $1$ and $6$ in my example above, the constraint is fulfilled. But this implies that if a $1000$ people ranked a $1000$ dishes, it would still be possible to select $2$ dishes that fulfilled the constraint. This doesn't seem right. But if I use the ""worst case"" scenario which I used in my example above, this is the result I get. I'd appreciate if someone could post a counter-example. I suspect the problem is that my ""worst case"" is not the actual worst case. EDIT2 - Outragous! Further fiddling and computer simulation suggests the outragous claim that if $n \ge D$ then still $d = 2$ . This implies that if a $1,000$ dishes were ranked by a $1,000,000$ guests, we could always find just $2$ dishes which fulfilled the constraint! I must be doing something wrong. As usual, counter-examples would be greatly appreciated. EDIT3 So I've now done $10,000$ simulations with $30$ dishes and $60$ guests, where the guests ranked the dishes randomly, and in every case a menu of just $2$ dishes was sufficient. My confidence that $2$ dishes will always be sufficient for $n \ge D$ grows. :-) But a proof or counter-example would be nice. Now to look at $n < D$ .","['recreational-mathematics', 'puzzle', 'combinatorics']"
3062462,Catalan numbers: bijection between applications of a binary operator and Dyck words.,"The Wikipedia article on Catalan numbers lists various combinatorial objects that are described by them. I posit that there might be bijections between these various combinatorial objects. For some of them (like Dyck paths, correctly matched parentheses and paths from the bottom left to top right of a $2n \times 2n$ grid) they are quite obvious. I was then trying to find a bijection between the number of Dyck words and the number of ways of associating $n$ applications of a binary operator to $n+1$ items (third one on the list). I attempted to do this for a simple case ( $n=3$ which is the example provided in the Wikipedia article). However, couldn't find one after multiple hours. Is it reasonable to expect such a bijection will exist? If so, how do we go about finding it? EDIT: In addition to the very nice answer by @Marc, the following page also helped me see the bijection: http://math.sfsu.edu/federico/Clase/EC/Homework/3.3.Jorge.pdf ""Let $P$ be the Dyck path and $f(P)$ be the binary tree. If you go up in the Dyck path, create a left child. Otherwise, go up one vertex until creating a new right child is possible and create one."" Here is one of my attempts: Number of Dyck words with length $2 \times 3$ is $\frac{6 \choose 3}{4} = 5$ . They are: hhhttt; hhthtt; hhttht; hthhtt; hththt And the number of applications of a binary operator among $3+1=4$ factors is: ((ab)c)d;     (a(bc))d;     (ab)(cd);     a((bc)d);     a(b(cd)) Both combinatorial objects have been arranged in a way that there is some kind of ordering between them. For the Dyck words for example, if h equals +1 and t equals -1, then the order is lexicographical from the left to the right of the cumulative score along the sequence. Now, the first and last characters of the Dyck words are always h and t respectively. So, we can ignore them. We are left with: hhtt; htht; htth; thht; thth I tried to start from the left of the sequence abcd and if I see 'h', merge the character with the one to its right. This approach didn't produce a valid mapping from the third Dyck word to the third binary operator precedence order.","['permutations', 'catalan-numbers', 'combinatorial-proofs', 'combinatorics', 'sequences-and-series']"
3062488,Derivative of a multivariable function (arises in mathematical statistics),"Suppose that $f(\theta_1,\dots,\theta_n,x)$ is a (positive) probability density function over a finite set $\mathbb{X}$ defined for an open subset $\Theta\in\mathbb{R}^n$ . That is, for every $\theta\in\Theta$ and $x\in\mathbb{X}$ , $f(\theta_1,\dots,\theta_n;x)>0$ and $$
\sum_x f(\theta_1,\dots,\theta_n;x) = 1.
$$ Let \begin{equation}
y_{i,j}(\theta) = \sum_x f(\theta_1,\dots,\theta_n;;x)\frac{\partial}{\partial\theta_i}\log f(\theta_1,\dots,\theta_n;x) \frac{\partial}{\partial\theta_j}\log f(\theta_1,\dots,\theta_n;x).
\end{equation} (This is called Fisher information in statistics) Let $$\widehat{\eta_i}(x) := g_i(\theta_1,\dots,\theta_n;x)$$ and $$\eta_i := \sum_x f(\theta_1,\dots,\theta_n;x) g_i(\theta_1,\dots,\theta_n;x),$$ for some ""nice enough"" functions $g_i$ . Hence $\eta$ is a function of $\theta$ . It can also be shown that $$
\frac{\partial}{\partial\theta_i}\log f(\theta_1,\dots,\theta_n;x) = \widehat{\eta_i}(x) - \eta_i.
$$ By a calculation I am getting $$
\frac{\partial\eta_i}{\partial\theta_j} = y_{i,j}(\theta) + k \cdot \eta_i\eta_j,
$$ for some real constant $k$ . However, what I would like to have is $$
\frac{\partial\eta_i}{\partial\theta_j} = y_{i,j}(\theta).
$$ So is it possible to modify the $g_i$ 's (by scaling/shifting the existing $g_i$ ) appropriately so that we get the above equation? I tried a bit, couldn't succeed. Any help is greatly appreciated.","['multivariable-calculus', 'calculus']"
3062524,What is the reason for commutative property during multiplication of real numbers,"This may seem like a really stupid question, but I am unable to rationalize with myself as to why the commutative property exists when multiplying 2 real number. Take for example: $2 * 5 = 10$ This actually means that if we add $2$ $5$ times we will get $10$ . But its kind of amazing when we can say for sure that if we add $5$ $2$ times we will also get $10$ . What is the reason for this property, I know I may be over-thinking this, but I can't understand intuitively why this happens. I know that $5$ actually ""contains"" $2$ but how does that guarantee commutative property ? For example matrix multiplication is not commutative, yet real number multiplication is. Am I just overthinking something simple? Need some clarity.","['abstract-algebra', 'logic']"
3062530,Approximating $\sum\limits_{r\subset S}|r|!\prod\limits_{x\in r}x$,"There is a set $S=\{x_1, x_2, ..., x_N\}.$ I'm trying to approximate this: $$p(S)=\sum_{r\subset S}|r|!\prod_{x\in r}x$$ I know that: $$\sum_{r\subset S}\prod_{x\in r}x=\prod_{x\in S}(1+x)$$ I was wondering if there is a way to approximate $p(S)$ with something. An idea: Change $x$ in $\prod\limits_{x\in S}(1+x)$ to $a(x)x$ so that: $$\prod_{x\in S}(1+a(x)x)\sim\sum_{r\subset S}|r|!\prod_{x\in r}x$$ Stirling's approximation There is: $$n! \sim (2\pi n)^\frac{1}{2}(\frac{n}{e})^n$$ which for my problem $n^n$ is troubling and I can't fiure out a way for $\prod_{x\in S}(1+a(x)x)$ to make $n^n$ . It could also go up to a power of e: $$n! \sim e^{log(2\pi)/2-n+nlog(n)}$$ But again, can't figure out to handle $nlog(n)$ .","['combinations', 'combinatorics', 'approximation', 'discrete-mathematics']"
3062586,Prove $\lim_{n\to\infty}\frac{2\cdot4\cdot6\cdot...\cdot(2n-2)(2n)}{1\cdot3\cdot5\cdot...\cdot(2n-1)}\frac{1}{\sqrt{2n+1}}=\sqrt\frac{\pi}{2}$,"I have to prove that the following limit is equal to $\sqrt{\pi/2}$ : $$\lim_{n\to\infty}\frac{2\cdot4\cdot6\cdot...\cdot(2n-2)(2n)}{1\cdot3\cdot5\cdot...\cdot(2n-1)}\frac{1}{\sqrt{2n+1}}=\sqrt\frac{\pi}{2}$$ In order to calculate this limit, we know that: $$I_n=\int_0^{\frac{\pi}{2}}\sin^nx\ dx\quad I_{2n}=\frac{1\cdot3\cdot..\cdot(2n-3)(2n-1)}{2\cdot4\cdot..\cdot(2n-2)(2n)}\frac{\pi}{2}\quad I_{2n+1}=\frac{2\cdot4\cdot..\cdot(2n-2)(2n)}{1\cdot3\cdot..\cdot(2n-1)(2n+1)}$$ I have tried to rewrite the limit as: $$\lim_{n\to\infty}\frac{1}{I_{2n}\sqrt{2n+1}}\frac{\pi}{2}$$ But I don't know how to continue... Could you help me? Thanks in advance!","['integration', 'limits', 'sequences-and-series']"
3062597,Conditions for Rouché's theorem,"For the statement of Rouché's theorem, I've always seen that both $f$ and $g$ have to be holomorphic on and inside a simple closed curve $ C $ . However, I am solving a problem which seems to suggest that I should use Rouché's theorem even though I only know that $ f $ is holomorphic in the unit disk $ D $ and continuous in $ \bar{D} $ . I also check Wikipedia's page on Rouché's theorem which says that $ f $ and $ g $ only need to be holomorphic inside the region, not on the boundary. Is this sufficient?",['complex-analysis']
3062625,Prove that minimum of $ f $ on $ |z| = 1 $ is no greater than $ |a_0| + \cdots + |a_m| $,"Let $ D $ be the open unit disk. Suppose $ f \in H(D) \cap C(\bar{D}) $ and write $ f(z) = \sum a_n z^n $ for $ |z| < 1 $ . If $ f $ has exactly $ m $ zeros in $ D $ , prove that $$ \min_{|z|=1} |f(z) | \leq |a_0| + \cdots + |a_m|. $$ My original idea was to prove by contradiction: suppose $$ |f(z)| > |a_0| + \cdots + |a_m| \geq |a_0 + a_1z + \cdots + a_mz^m|. $$ Then if we can use Rouché's theorem, this implies that $ f $ has the same number of zeros as $ f -g $ , which is $ m + 1 $ , a contradiction. However I don't think I can apply Rouché's theorem since $ f $ is not known to be holomorphic on $ \bar{D} $ . How do I solve this problem?",['complex-analysis']
3062649,gradient flows on Hilbert manifolds,"I would like to know if gradient flows of Morse-Bott functions on a Riemannian manifold always converge towards a unique critical point, provided that the flow line is bounded. To be more precise, a Morse-Bott function on a Riemannian manifold $(M,g)$ is a smooth map $f:M \longrightarrow \mathbb R$ such that the set of critical points $Crit f \subset M$ is a submanifold and $T_x Crit f = ker Hess f_x$ for all $x \in Crit f$ . It might be more convenient to express this by using the linear map $A_x:T_xM \longrightarrow T_xM$ given by $g_x(A_xv,w) = 
Hess f_x(v,w)$ for $v,w \in T_xM$ . I am interested in the behaviour of maps $x:\mathbb R_+ \longrightarrow M$ satisfying $\dot x(t) = -\nabla f(x(t))$ . Does $lim_{t \to \infty} x(t)$ exist? An easy computation shows that $df_{x(s)} \longrightarrow 0$ for $s \to \infty$ . So if $x$ is bounded (e.g. if $M$ is compact) $x$ has to ""converge"" towards $Crit f$ . UNfortunately, this does not rule out that $x$ has several limits in $Crit f$ . (This can not happen for Morse functions, since in this case the critical points are isolated). The simplest case is the case where $M$ is finite dimensional. As far as I can see, the answer is already given by Austin and Braam in their paper ""Morse-Bott theory and equivariant cohomology"", 1995. In particular Theorem A.9 is important, stating that the stable manifold of a connected component $C \subset Crit f$ , given by $W^s(C) = \{x \in M | \phi_t(x) \to C\}$ where $\phi$ is the flow of the negative gradient, is indeed a submanifold. The second case is the case where $M$ is a Hilbert manifold (infinite dimensional) endowed with a complete metric on the tangent bundle. Although I could only find a paper dealing with this question in the Morse case (see Abbondandolo, Majer: ""A Morse complex for infinite dimensional manifolds"", Appendix C), I assume that it should be not to hard to extend the result to the Morse-Bott case. The important point here is that the operator $A_x$ mentioned above is symmetric and defined on the whole tangent space, so it has to be bounded. The last case is the one I am particularly interested in. We start again with a Hilbert manifold $M$ , but now endowed with an incomplete Riemannian metric (in my case, I have a Sobolev space $W^{1,2}$ which is only endowed with the $L^2$ metric). Let $H$ denote the complete Hilbert space where $T_xM \subset H$ is dense. Then the operator $A$ is unfortunately of the form $A_x:T_xM \subset H \longrightarrow H$ . Now $A_x$ is unbounded, but at least still symmetric and even essentially self-adjoint. However, here I am failing to apply the results from case 2, which strongly used the boundedness of $A$ . I would be very content if a similar result could be shown at least for the case, where $Crit f$ is finite dimensional. A remark: In the infinite dimensional case, one might have problems with the flow, since it might not be defined for all times. However, I start with a flow line which is already defined for all $t$ . Furthermore, I have found (with completely different techniques) a sequence $t_k \to \infty$ such that $x(t_k) \to p \in Crit f$ , which is enough to ensure that $x(t) \to Crit f$ . I would also be thankful for counterexamples where the gradient flow does not have a unique limit. But I expect those examples not to contain Morse-Bott functions.","['gradient-flows', 'ordinary-differential-equations', 'morse-theory', 'functional-analysis', 'differential-geometry']"
3062690,"For a closed $G_\delta$ set $F\subseteq X,$ does there exist a continuous function $f:X\to [0,1]$ such that $f=0$ on $F$ and $f\neq 0$ outside $F?$","(All spaces are Hausdorff.) This question is a variant of my previous question . Let $X$ be a completely regular space, that is, for every closed set $F\subseteq X$ and $x\not\in F,$ there exists a continuous function $g:X\to [0,1]$ such that $g(F) = \{0\}$ and $g(x) =1.$ Question : For every closed $G_\delta$ set $F\subseteq X,$ does there exist a continuous function $f:X\to [0,1]$ such that $f=0$ on $F$ and $f\neq 0$ outside $F?$ A subset $U\subseteq X$ is a zero set if there exists a continuous function $g:X\to [0,1]$ such that $g^{-1}(\{0\}) = U.$ It is well-known that if $X$ is normal then all closed $G_\delta$ sets are zero sets. However, I am not sure whether the same holds for completely regular space.","['general-topology', 'separation-axioms']"
3062719,Show convergence of inner product of an operator and a weak convergent sequence,"Let $(u_n)_{n\in\mathbb{N}}\subseteq (W^{1,p}_0(\Omega))$ , $u_n \rightharpoonup u \in (W^{1,p}_0(\Omega))$ and $B$ be an operator on $(W^{1,p}_0(\Omega))\times(W^{1,p}_0(\Omega))$ , where $\Omega \subset \mathbb{R}^d$ is a bounded domain with smooth boundary. B is defined by $$\langle B(w,u), v\rangle := \int_\Omega ||\nabla u - h(w)||^{p-2}(\nabla u - h(w))\nabla v dx,$$ where $h:\mathbb{R}\to\mathbb{R}^n$ is continuous and bounded and $\limsup_{n \to \infty} \langle B(u_n, u_n), u_n - u \rangle \le 0$ holds. I want to show that $\langle B(u_n, v), u_n -u\rangle \to 0$ where $v\in (W^{1,p}_0(\Omega))$ . Is it right, that I just have to show that $B(u_n, v)\in(W^{1,p}_0(\Omega))^*$ $\forall n\in\mathbb{N}$ ? Then the statement follows from the weak continuity of $(u_n)_{n\in\mathbb{N}}$ (?)","['weak-convergence', 'ordinary-differential-equations', 'sobolev-spaces', 'functional-analysis', 'convergence-divergence']"
3062733,"Weak convergence of bounded sequence $(x_n)$ in Hilbert space where $\langle{x_n,y\rangle}\rightarrow \langle{x_n,y\rangle}$ for all $y\in D\subset H$","Let $H$ be a Hilbert Space endowed with the inner product $\langle{.,.\rangle}$ and $D$ a subset of $H$ such that span $(D)$ is dense in $H$ . Show that, given a bounded sequence $(x_n)$ in $H$ , such that $\langle{x_n,y\rangle}\rightarrow \langle{x_n,y\rangle}$ for all $y\in D$ , then $x_n$ converges to $x$ weakly. My Attempt Let $f\in H^*$ and $y\in H$ (exist by Riesz): $f(x)=\langle{x,y\rangle}$ for all $x\in H$ . W.T.S $f(x_n)\rightarrow f(x)$ . Let $(y_m)$ sequence in span $(D)$ : $y_m\rightarrow y$ - (I'm not sure if I can do this as D may not countable). \begin{equation} f(x_n)= \langle{x_n,\lim y_m\rangle}=\lim \langle{x_n,y_m\rangle}\rightarrow \langle{x,y\rangle}=f(x).\end{equation} Is this correct please?","['hilbert-spaces', 'functional-analysis', 'weak-convergence']"
3062736,Solve the differential equation $\sin x\frac {dy}{dx}+(\cos x)y=\sin(x^2)$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question $$\sin x\frac {dy}{dx}+(\cos x)y=\sin(x^2)$$ $$\frac {d}{dx} y \sin x=\sin(x^2)$$ $$y\sin x=\int \sin(x^2)dx = -\frac{1}{2x}\cos(x^2)+C$$ $$y=-\frac{\cos(x^2)}{2x\sin x}+\frac {C}{\sin x}$$ where C is constant Is my answer correct?",['ordinary-differential-equations']
3062747,Invertibility of the square root of an operator,"Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on a complex Hilbert space $F$ . Let $M\in \mathcal{B}(F)^+$ (i.e. $\langle Mx\;, \;x\rangle\geq 0$ for all $x\in F$ ). The square root of $M$ is defined to be the unique operator $N$ such that $$N^2=M.$$ In this case we write $N=M^{1/2}$ If $M$ is an invertible operators, is $M^{1/2}$ invertible?","['operator-theory', 'functional-analysis']"
3062748,Measure theory integral,"This is a qualifying exam practice question - so not being graded for homework purposes, just studying! Calculate $\lim_{n \rightarrow \infty} \int_0^\infty \frac{x^n}{ x^{(n+3)}+1} dx$ I tried the following: $\lim_{n \rightarrow \infty} \int_0^\infty \frac{x^n}{ x^{(n+3)}+1} \, dx$ = $\frac{d}{dn}\int_0^\infty \int_0^\infty\frac{x^n}{ x^{(n+3)}+1}dn \, dx$ = - $\frac{d}{dn} \int_0^\infty \frac{\ln(x^3+1}{x^3 \ln(x)} \, dx$ Not really sure where to go from here, any advice would be appreciated!","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'convergence-divergence']"
3062779,"if $f,g$ are linear transformations, find basis of $ \operatorname{im}(f) \cap \ker(f \circ g) $ and $ \operatorname{im}(g \circ f) + \ker(f) $","I have done this task, however, my solutions are suspiciously strange. Could someone verify if my reasoning is okay? Possibly something to advise ... If all is ok (I hope), this post would be nice pattern for future visitors Task Given are linear transformations: $f \in L(\mathbb R^3, \mathbb R[t]_2) $ $$ \vec{x} = [x_1,x_2,x_3]^T \rightarrow f(\vec{x})(t)=(x_1+x_3)t^2 + x_2$$ and $g \in L(\mathbb R[t]_2,\mathbb R^3) $ $$p \in \mathbb R[t]_2 \rightarrow  g(p) = [p(-1),p'(0),p(1)]^T $$ Find basis of subspace: a) $  \operatorname{im}(f)  \cap  \ker(f \circ g) $ b) $  \operatorname{im}(g \circ f)  + \ker(f) $ My solution a) Take a random polynomial: $$p(t) = at^2 + bt + c $$ $$p(1) = a + b + c $$ $$p(-1) = a - b +c $$ $$p'(0) = b $$ so $ g(p) = [a-b+c,b,a+b+c]^T $ Ok now we are looking for $ f\circ g $ $$f(g(p)) = 2(a+c)t^2 + b $$ Ok, now I want its kernel: $$f(g(p)) = 0 \leftrightarrow a = - c \wedge b = 0$$ so $\ker(f\circ g) =  \operatorname{span}[1,0,-1]^T $ I need also $ \operatorname{im}(f)$ so $$ \operatorname{im}(f) =  \operatorname{span}([1,0,0]^T,[0,1,0]^T)$$ but $$ ([1,0,0]^T,[0,1,0]^T,[1,0,-1]^T $$ are linearly independent so $  \operatorname{im}(f)  \cap  \ker(f \circ g) = 0 $ b) Now I am looking for $ \operatorname{im}(g \circ f)$ $$g(f(\vec{x})) = [x_1+x_2+x_3,0,x_1+x_2+x_3]^T =  \operatorname{span}([1,0,1]^T) =  \operatorname{im}(g \circ f)$$ Now $ker(f)$ $$ f(\vec{x})(t)=(x_1+x_3)t^2 + x_2 = 0 \leftrightarrow x_1 = -x_3 \wedge x_2 = 0$$ so $$\ker(f) =  \operatorname{span}([1,0,-1]^T)$$ Ok now we are looking for: $$  \operatorname{im}(g \circ f)  + \ker(f) =  \operatorname{span}([1,0,-1]^T,[1,0,1]^T) $$ but $[1,0,-1]^T,[1,0,1]^T $ are linearly independent so $ \operatorname{span}([1,0,-1]^T,[1,0,1]^T) $ is a basis of $ \operatorname{im}(g \circ f)  + \ker(f) $ Thanks for your time!","['functions', 'linear-algebra', 'proof-verification', 'linear-transformations']"
3062784,Trying to understand a certain form of zeta function,"A month ago I have asked a question about a certain form of the zeta function. I will now try to be more accurate. facts: Let $N_s$ be the number of points on the projective hypersurface $\bar{H}_f(F_s)$ . Under the condition $N_s = \sum_j \beta_j - \sum_i \alpha_i$ for $\beta_j, \alpha_i \in \mathbb{C}$ we can say that the zeta function is rational with $$ Z(u) = \frac{\prod_i 1-\alpha_iu}{\prod_j 1-\beta_ju}. $$ First Question: Now I have $$ N_s = \sum_{k=0}^{n-1} q^{ks} -(-1)^n \sum_{\chi_0,...,\chi_n} [ \frac{(-1)^{n+1}}{q} \chi_0(a_o^{-1}) \cdots \chi_n(a_n^{-1})g(\chi_0) \cdots g(\chi_n)]^s .$$ the $\chi_i$ are characters of $F$ with the following condition: $\chi_i^m = \varepsilon, \chi_i \neq \varepsilon$ and $\chi_0\chi_1 \cdots \chi_n = \varepsilon$ . And here comes my question: why does the zeta function has the following form? $$ Z(u) = \frac{P(u)^{(-1)^n}}{(1-u)(1-qu) \cdots (1-q^{n-1}u)}, $$ where $ P(u) = \prod_{\chi_0,...,\chi_n} (1-(-1)^{n+1}\frac{1}{q}\chi_0(a_o^{-1}) \cdots \chi_n(a_n^{-1})g(\chi_0) \cdots g(\chi_n)u) $ . Thoughts It is clear to me that $\sum_j \beta_j^s = \sum_{k=0}^{n-1} q^{ks} $ and $\sum_i \alpha_i^s =\sum_{\chi_0,...,\chi_n} [ \frac{(-1)^{n+1}}{q} \chi_0(a_o^{-1}) \cdots \chi_n(a_n^{-1})g(\chi_0) \cdots g(\chi_n)]^s  $ but the term $(-1)^n$ disturbs me. Without this term I would have $Z(u) = \frac{P(u)}{(1-u)(1-qu) \cdots (1-q^{n-1}u)} $ . That's totally fine. Just using the fact above. But like I said I don't get it why I get $(-1)^n$ in the exponent of $P(u)$ if I have the term $(-1)^n$ . Second question: Do you see why $\deg (P(u)) = m^{-1}[(m-1)^{n+1}+(-1)^{n+1}(m-1)]$ ? Sorry that I am clueless, here.","['riemann-zeta', 'number-theory', 'characters']"
3062809,"Prove or disprove that there exists $K$ such that $|f(x)-f(y)|\leq K |x-y|,\;\forall\;\;x,y\in[0,1],$ edited version.","Let $f$ be a function on $[0,1]$ into $\Bbb{R}$ . Suppose that if $x\in[0,1],$ there exists $K_x$ such that \begin{align}|f(x)-f(y)|\leq K_x |x-y|,\;\;\forall\;\;y\in[0,1].\end{align} Prove or disprove that there exists $K$ such that \begin{align}|f(x)-f(y)|\leq K |x-y|,\;\forall\;\;x,y\in[0,1].\end{align} DISPROOF Consider the function \begin{align} f:[0&,1]\to 
\Bbb{R},  \\&x\mapsto \sqrt{x} \end{align} Let $x=0$ and $y\in (0,1]$ be fixed. Then, \begin{align} \left| f(0)-f(y) \right|&=\left|0-\sqrt{y}  \right|   \end{align} Take $y=1/(4n^2)$ for all $n.$ Then, \begin{align} \left| f(0)-f\left(\dfrac{1}{4n^2}\right) \right|&=\left|0-\dfrac{1}{\sqrt{4n^2}}  \right| \\&=2n^{3/2}\left|\dfrac{1}{4n^2} -0 \right|   \end{align} By assumption, there exists $K_0$ such that \begin{align} \left| f(0)-f\left(\dfrac{1}{4n^2}\right) \right|&=2n^{3/2}\left|\dfrac{1}{4n^2} -0 \right|\leq K_0\left|\dfrac{1}{4n^2} -0 \right|   \end{align} Sending $n\to\infty,$ we have \begin{align} \infty \leq K_0<\infty,\;\;\text{contradiction}.  \end{align} Hence, the function $f$ is not Lipschitz in $[0,1]$ . QUESTION: Is my disproof correct?","['lipschitz-functions', 'analysis', 'real-analysis']"
3062819,Calculate: $\lim\limits_{x\to0^-} \frac1{\ln(1-x)}+\frac1x$ without LHR/Expansions [duplicate],"This question already has answers here : Limit $\lim\limits_{x\to0}\frac1{\ln(x+1)}-\frac1x$ (4 answers) Closed 5 years ago . How to calculate $$\lim\limits_{x\to0^-} \left(\frac1{\ln(1-x)}+\frac1x \right)$$ without using L'Hopital, expansions nor integration? I found the answer: Using the Mean value theorem on: $f(x)=e^x-\frac{x^2}2-x-1$ We get: $0\le\frac{e^x-x-1}{x^2}-\frac1 2\le \frac{e^x-x-1}{x}$ Thus: $\lim\limits_{x\to0^-} \frac{e^x-x-1}{x^2} = \frac12$ By substituting: $t=\ln(1-x)$ in the original limit we get: $\lim\limits_{t\to0^+} \frac{1-e^t+t}{t(1-e^t)} = \lim\limits_{t\to0^+} \frac{e^t-t-1}{t^2}.\frac{t}{e^t-1} = \frac12$","['limits', 'exponential-function', 'logarithms']"
3062844,Need help understanding differential of function,"I have encountered the term differential/pushforward many times in the literature, although I cannot seem to understand just what is meant by it. I still cannot seem to understand the definition of the differential of a multivalued multivariable function $ f : \mathbb{R}^n \to \mathbb{R}^m $ and its generalization to differentiable manifolds. I have seen many definitions of the differential, particularly those for tangent vectors on manifolds and the definition with derivations of functions and one involving the Jacobian matrix, but I cannot understand this or any of them, thus I also cannot understand just what is meant by tangent space on manifolds. What does the differential ""really mean"" and how to use it? In particular, how is the differential/pushforward related to derivations of functions? Could someone please explain the differential to me and possibly using it to define tangent spaces on manifolds. I am frustrated as I have never understood the differential and lack the proper understanding in tangent spaces. All help is appreciated.","['differential', 'tangent-spaces', 'manifolds', 'derivatives', 'differential-geometry']"
3062845,Liouville's theorem for harmonic functions,"I was reading the proof of Liouville's theorem for harmonic functions (in $\mathbb{R}^n$ ) in Wikipedia, but I could not understand where do they use in that proof the assumption that $f$ is bounded. The proof - Taken from - https://en.m.wikipedia.org/wiki/Harmonic_function","['integration', 'multivariable-calculus', 'calculus', 'harmonic-functions']"
3062908,Show that the maximum value of this nested radical is $\phi-1$,"I was experimenting on Desmos (as usual), in particular infinite recursions and series. Here is one that was of interest: What is the maximum value of $$F_\infty=\sqrt{\frac{x}{x+\sqrt{\dfrac{x^2}{x-\sqrt{\dfrac{x^3}{x+ \sqrt{ \dfrac{x^4}{x-\cdots}}}}}}}}$$ where the sign alternates and the power in each numerator increases by one? Some observations follow. Let $F_k$ be the nested radical up to $x^k$ . For large nests, say after $k=10$ , the function monotonically increases from zero onwards. It is hopeless to simply rearrange $F_\infty$ since the powers increase each time - we can no longer write $F_\infty$ as a function of itself to be solved. Here is a plot of $F_{15}$ . What is striking is that the largest value of $x$ in the domain of $F_k$ decreases as $k$ increases. Based on the plot, I think that the domain of $F_\infty$ is $[0,1]$ . This is because for large $x$ , the denominator of the square roots will be larger than its successor, which is absurd as we are working only in $\Bbb R$ . Furthermore, I also conjecture that $$\max F_\infty=\phi-1,$$ where $\phi$ is the golden ratio. This seems right as $\max F_{15}=0.6179$ from the plot. EDIT: The problem can be reduced to proving that for $x\in(0,1]$ , $$\frac d{dx}\sqrt{\frac{x^3}{x+\sqrt{\dfrac{x^4}{x-\sqrt{\dfrac{x^5}{x+ \sqrt{ \dfrac{x^6}{x+\cdots}}}}}}}}<1.$$","['nested-radicals', 'golden-ratio', 'recursion', 'maxima-minima', 'functions']"
3062909,Does it make sense to talk about limit in this case?,"Suppose I have a function that is defined only for values bigger than $a$ , does it make sense to talk about limit of a function at that point, or only about limit from the right? It seems to me that we can talk about limit of a function, because if we look at the definition $$\forall \epsilon>0 \; \exists \delta>0 \; \forall x\in A: \; 0<|x-a|<\delta \Rightarrow |f(x)-L|<\epsilon$$ ( $A$ is domain of the function), we have the requirement of $x$ being in the domain and so limit still would make sense. But I am not sure. Thanks in advance.","['limits', 'real-analysis']"
3062963,Why is $\cos(i)>1$?,"I always thought that cosine only ranges from $-1$ to $1$ . But, I found out that $$\cos(i)=\frac12\left(e+\frac{1}{e}\right)$$ which is certainly greater than $1$ . Why is that?","['trigonometry', 'complex-numbers']"
3062985,"Find work of the vector field $K(x,y,z)=(-y,x+z,-y+y^3+z)$ along the curve which is the intersection of the sphere of radius 1 and the plane $x=z$","I'm asked to calculate the work of the vector field $K(x,y,z)=(-y,x+z,-y+y^3+z)$ along the curve which is the intersection of the sphere of radius 1 and the plane $x=z$ : a) directly b) using Stoke's theorem My problem is that I obtain different results in both cases. For a) (correction : see edit 1 below), I use as parametrization $(\cos(\theta),\sin(\theta),\cos(\theta))$ . The gradient is $(-\sin(\theta),\cos(\theta),-\sin(\theta))$ . The dot product of that with our vector field in polar coordinates $(-\sin(\theta),2\cos(\theta),-\sin(\theta)+\sin^3(\theta)+\cos(\theta))$ is simply $2-\sin^4(\theta)-\sin(\theta)\cos(\theta)$ . If we integrate that from $0$ to $2\pi$ , we get $\frac{13\pi}{4}$ noting that $\sin(\theta)\cos(\theta)$ vanishes. For b), the curl of our vector field is $(3y^2-2,0,2)$ . Our parametrization is $(r\cos(\theta),r\sin(\theta),r\cos(\theta))$ . The cross product of the partial derivatives is simply $(-r,0,r)$ . The dot product of that with our curl in polar coordinates is $4r-3r^3\sin^2(\theta)$ . So now, we have $$\int_{0}^{2\pi}\int_{0}^{1}(4r-3r^3\sin^2(\theta))rdrd\theta=\pi\int_{0}^{1}(8r^2-3r^4)rdr=\frac{31\pi}{15}$$ So I don't see where I did something wrong, or where I forgot something. Thanks for your help ! Edit 1: Okay, as was pointed out in the comments and in one answer, I used a wrong parametrization in a). I should use $\frac{\cos(\theta)}{\sqrt{2}}$ instead of $\cos(\theta)$ for the parametrization of $x$ and $z$ . In this case, we get the dot product of $(-\sin(\theta), \sqrt{2}\cos(\theta), -\sin(\theta)+\sin^3(\theta)+\frac{\cos(\theta)}{\sqrt{2}})$ and $(\frac{-\sin(\theta)}{\sqrt{2}}, \cos(\theta),\frac{-\sin(\theta)}{\sqrt{2}}) $ which yields $$\frac{\sin^2(\theta)}{\sqrt{2}}+\sqrt{2}\cos^2(\theta)+\frac{\sin^2(\theta)}{\sqrt{2}}-\frac{\sin^4(\theta)}{\sqrt{2}}-\frac{\sin(\theta)\cos(\theta)}{2}$$ . If we integrate that from $0$ to $2\pi$ , the last term vanishes and using the common trig identity, we simply integrate $\sqrt{2}-\frac{\sin^4(\theta)}{\sqrt{2}}$ . So we get $\frac{13\pi}{4\sqrt{2}}$ . But it's still different fom b) though. Edit 2 : As was pointed out in the comments, I also need to use the new parametrization for part b). But even so, I get $\frac{31\pi}{15\sqrt{2}}$ The cross product of the derivatives is $(\frac{-r}{\sqrt{2}},0,\frac{r}{\sqrt{2}})$ . We need to integrate from $0$ to $2\pi$ $d\theta$ and from $0$ to $1$ $dr$ the following (the curl remains the same): $(\frac{4r}{\sqrt{2}}-\frac{3r^3sin^2(\theta)}{\sqrt{2}})r=\frac{4r^2}{\sqrt{2}}-\frac{3r^4sin^2(\theta)}{\sqrt{2}}$ which yields $\frac{8\pi r^3}{3\sqrt{2}}-\frac{3\pi r^5}{5\sqrt{2}}$ evaluated from $0$ to $1$ and so we get $\frac{31\pi}{15\sqrt{2}}$ Edit 3 : problem solved. I multiplied by an extra $r$ in b). I should not have $(\frac{4r}{\sqrt{2}}-\frac{3r^3sin^2(\theta)}{\sqrt{2}})r$ but simply $(\frac{4r}{\sqrt{2}}-\frac{3r^3sin^2(\theta)}{\sqrt{2}})$ See my answer below.","['analysis', 'real-analysis', 'multivariable-calculus', 'calculus', 'vector-analysis']"
3062986,irreducible smooth proper one-dimensional $\mathbb{Z}$-schemes,Is there an irreducible smooth proper one-dimensional $\mathbb{Z}$ -scheme not isomorphic to projective line?,['algebraic-geometry']
3062999,Trying to simplify $\frac{\sqrt{8}}{1-\sqrt{3x}}$ to be $\frac{2\sqrt{2}+2\sqrt{6x}}{1-3x}$,I am asked to simplify $\frac{\sqrt{8}}{1-\sqrt{3x}}$ . The solution is provided as $\frac{2\sqrt{2}+2\sqrt{6x}}{1-3x}$ and I am unable to arrive at this. I was able to arrive at $\frac{1+2\sqrt{2}\sqrt{3x}}{1-3x}$ Here is my working: $\frac{\sqrt{8}}{1-\sqrt{3x}}$ = $\frac{\sqrt{8}}{1-\sqrt{3x}}$ * $\frac{1+\sqrt{3x}}{1+\sqrt{3x}}$ = $\frac{1+\sqrt{8}\sqrt{3x}}{1-3x}$ = $\frac{1+\sqrt{2}\sqrt{2}\sqrt{2}\sqrt{3x}}{1-3x}$ = $\frac{1+2\sqrt{2}\sqrt{3x}}{1-3x}$ Is $\frac{1+2\sqrt{2}\sqrt{3x}}{1-3x}$ correct and part of the way? How can I arrive at the provided solution $\frac{2\sqrt{2}+2\sqrt{6x}}{1-3x}$ ?,['algebra-precalculus']
3063053,Is there a way to find this limit algebraically? $\lim\limits_{x\to \infty} \frac{x}{\sqrt{x^2 + 1}}$,"I'm a Calculus I student and my teacher has given me a set of problems to solve with L'Hoptial's rule. Most of them have been pretty easy, but this one has me stumped. $$\lim\limits_{x\to \infty} \frac{x}{\sqrt{x^2 + 1}}$$ You'll notice that using L'Hopital's rule flips the value of the top to the bottom. For example, using it once returns: $$\lim\limits_{x\to \infty} \frac{\sqrt{x^2 + 1}}{x}$$ And doing it again returns you to the beginning: $$\lim\limits_{x\to \infty} \frac{x}{\sqrt{x^2 + 1}}$$ I of course plugged it into my calculator to find the limit to evaluate to 1, but I was wondering if there was a better way to do this algebraically?",['calculus']
3063087,Integral Operator in $L^2$,"I was trying to do this exercise and I'm wondering if I figured it out well: I have $\mathcal{H} := L^2(0,1)$ and $T$ the operator with integral kernel $K(x,y) = \min\{x,y\}$ , $x,y \in [0,1]$ . I have to show that $T$ is compact and self-adjoint. To show that is compact I was thinking to say that because $\min\{x,y\} \in [0,1]$ then \begin{equation}
\dim(\operatorname{Im}T) = 1
\end{equation} (The self adjointness I think is trivial..)So T belongs to finite rank operators and so it is compact. (Is this correct?) Then it asks me to find eigenvalues and eigenvectors of $T$ and here I really don't know how to proceed...","['compact-operators', 'functional-analysis', 'eigenvalues-eigenvectors']"
3063092,Commutator of the Hamiltonian and Parity Operator - evaluation of derivatives,"I was studying the commutator of the Hamiltonian and parity operators in the $L^2$ space from Quantum mechanics and came upon the following: To show that the two operators commute, assuming we have a symmetric potential $V(x)=V(-x)$ , we had that the commutator of a function $\psi(x)$ was; \begin{align*}[\hat{H},\hat{P}]=&-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}\psi(-x)+V(x)\psi(-x)+\frac{\hbar^2}{2m}\frac{\partial^2}{\partial (-x)^2}\psi(-x)-V(-x)\psi(-x)\\=&-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}\psi(-x)+\frac{\hbar^2}{2m}\frac{\partial^2}{\partial (-x)^2}\psi(-x),
\end{align*} assuming the symmetry of the potential $V(x)$ . Now I struggled to show that the two second derivative terms are the negative of each other. The only possible way I could deduce the were equal was by using the chain rule for the second partial derivative to deduce that: $$\frac{\partial \psi(-x)}{\partial (-x)}=\frac{\partial \psi(-x)}{\partial x}\frac{\partial x}{\partial (-x)}=-\frac{\partial \psi(-x)}{\partial x},$$ and hence the partial derivative terms both cancel out to show the operators commute. Now my main issue is struggling with the derivatives, could this be clarified? As an aside I also had thought about the Lagrange and Leibniz notation, and was wondering whether the following was incorrect or not? $$\frac{\partial \psi(-x)}{\partial x}=-\psi '(-x) \,\text{ and }\, \frac{\partial \psi(-x)}{\partial (-x)}=\psi'(-x).$$","['quantum-mechanics', 'derivatives']"
3063128,Concentration of norm,"Let $(X_1,...,X_n)\in \mathbb{R}^n$ be a random vector with independent sub-gaussian coordinates $X_i$ that satisfy $\mathbb{E}X_i^2=1$ . Then $$||||X||_2-\sqrt{n}||_{\psi_2}\leq CK^2$$ , Where $K=max||X_i||_{\psi_2}$ . In the book ""High dimensional probability"", it is claimed that we can assume $K\geq 1$ and $C$ is a universal constant. But it is not clear why we can do so. Because the above expression is not homogeneous. I tried to change variables but if I change $X_i$ then the property of unit variance no longer holds.","['normal-distribution', 'probability', 'random-variables']"
3063130,"A function holomorphic on $\mathbb{D}(0,2)$ and bounded on a unit circle is a polynomial","Suppose function $f(z)$ is holomorphic on $\mathbb{D}(0,2)$ and $N>0$ is an integer such that: $$ |f^{(N)}(0)| = N! \sup\{|f(z)|: |z|=1\} $$ show that $f(z) = cz^N$ , $c \in \mathbb{C}$ . I have shown that since $f(z)$ is holomorphic in $\mathbb{D}(0,2)$ , then it has a power series expansion around zero. $$ f(z) = \sum_{n=0}^{\infty} a_n z^n $$ Calculating the $N$ -th derivative I got: $$ |f^{(N)}(0)| = N! a_N$$ from which I conclude that $f(z)$ is bounded by $a_N$ on the unit circle. Therefore by maximum principle for holomorphic function we may also conclude that it is bounded in the unit disc. But I still can't figure out how to show that $f(z) = cz^N$ .","['complex-analysis', 'holomorphic-functions', 'power-series']"
3063156,Analytic or perturbative solution in any limits?,"Consider the system of 3 ordinary differential equations $$\dot{x}=v$$ $$\dot{v}=a$$ $$\dot{a}=-Aa+v^{2}-x$$ which can also be written as a single 3rd order ODE $$\dddot{x}=-A\ddot{x}+\dot{x}^{2}-x$$ $A$ is an arbitrary constant and the dot means derivative with respect to time, i.e. $\dot{x}=dx/dt,\ddot{x}=d^{2}x/dt^{2}$ , etc. This system can be thought as describing the time evolution of the position $x$ , velocity $v$ and acceleration $a$ of a particle. Are there any limits where we can solve analytically this system, i.e. find $x(t),v(t),a(t)$ ? For example when $A=0$ ? A perturbative solution would also be good. Or maybe there is a way of reparametrizing time to make the system a known integrable one? I know that the simpler system $$\dddot{x}=-A\ddot{x}\iff \dot{a}=-Aa$$ has the solution $$a(t)=c_{1}e^{-At}$$ which means that $$x(t)=\frac{c_{1}}{A^{2}}e^{-At}+c_{2}t+c_{3}$$","['integration', 'power-series', 'ordinary-differential-equations']"
3063167,A simple game with $n$ points in 3D space - red triangle wins,"(Once again a son is torturing his father...) Alice and Bob play a fairly simple game with $n$ predefined points in 3D space. No four points are complanar (which also implies that no three points are collinear). They play in turns by connecting points that are not yet connected with straight segments. On her turn Alice connects a single pair of unconnected points with a single segment of red color. After that Bob connects $k$ pairs of unconnected points with $k$ segments of blue color. Alice wins if she is able to create a triangle with red sides. If all points are connected and Alice was not able to create a red sided triangle before that, Bob wins. Who has a winning strategy? My thoughts: obviously, the outcome of the game heavily depends on releation between $n$ and $k$ . Suppose that $k=1$ with big enough value for $n$ . Alice will simply draw segment $AB$ , Bob draws his segment at will, Alice then draws $AC$ , Bob blocks triangle $ABC$ by drawing segment BC, Alice draws segment $AD$ and Bob is lost. He cannot block triangles $ABD$ and $ACD$ by drawgin a single segment. On the other side, with $k$ big enough, Bob can easily block creation of all red triangles by drawing a lot of lines. So for $k\le k_1$ , Alice wins. For $k\ge k_2\ge k_1$ , Bob wins. I need some estimate for $k_1$ and $k_2$ (better than mine). Also note that the game always has a winner. Does it mean that $k_1=k_2$ ? I guess it does, but if we are just trying to estimate the lower and the upper bound, we can come up with two different values.","['graph-theory', 'combinatorics', 'coloring', 'combinatorial-game-theory']"
3063184,Counterexample in Radon-Nikodym Theorem. Problem 38 Royden 2ed.,"Use the following example to show that the hypothesis in the
Radon-Nikodym Theorem that $\mu$ is $\sigma$ -finite cannot be omitted. Let $X=[0,1],\ \mathcal{B}$ the class of Lebesgue measurable subsets of $[0, 1]$ , and take $\nu$ , to be Lebesgue measure and $\mu$ to be the counting measure on $\mathcal{B}$ . Then $\nu$ is
finite and absolutely continuous with respect to $\mu$ , but there is no function $f$ such that $\nu E = \int_{E} f d\mu$ for all $E\in\mathcal{B}.$ Solution.  Suppose there is a function $f$ such that $\nu(E) = \int_{E} f d\mu$ for all $E\in\mathcal{B}$ . Since $\nu$ es finite, $f$ is integrable with respect to $\mu$ . Thus $E_0 = \left\{x : f(x)\neq 0\right\}$ is countable. Now $0=\nu(E_0)=\int_{E_0}fd\mu$ . Contradiction. Hence there is no such function
I have a doubts: Why $E_0$ is countable? Why $\int_{E_0}fd\mu=0$ is a contradiction?","['measure-theory', 'radon-nikodym', 'real-analysis']"
3063194,Where does the bias come from in LogLog and HyperLoglog?,"In the original LogLog paper from P. Flajolet, the cardinality estimation function is presented as $$E := \alpha_m m2^{1 \over m} {^{\sum_{j} M^{(j)}}}$$ Where $\alpha$ is needed to correct the systematic bias in the asymptotic limit which cause overestimates. However I am having trouble identifying where does this bias come from. My intuition tells me this is related to the fact we retain the $max$ count of leading zeros, which is probably skewed to higher values. Wikipedia states this is due to the risk of hash collisions, but that seems wrong as hash collision would underestimate not overestimates (this is actually an improvement in the HyperLogLog paper) Has anyone a more explicit definition (ideally in layman terms) or reason explaining this bias? Thank you!","['probability-limit-theorems', 'probability-theory']"
3063201,Some more basics on group operation,"Let $G$ be a group, $H \le G$ and $f \colon G \times G \rightarrow G$ the group operation. We know that $\complement_GH$ (the complement of $H$ in $G$ ) contains the inverse of any of its elements, so, whatever $G$ and $H$ are, $\lbrace e \rbrace \subseteq f(\complement_GH \times \complement_GH)$ . On the other hand, if we take $G=(\mathbb{Z},+)$ and $H=2 \mathbb{Z}$ , we get that $f(\complement_GH \times \complement_GH)=H$ , because by summing pairwise all the odd integers we get all the even integers (and them, only). This makes me conclude that, in general, at least the following holds: $\lbrace e \rbrace \subseteq f(\complement_GH \times \complement_GH) \cap H \subseteq H$ . I ask the following: what's the characterization of $H$ and/or $G$ to get $f(\complement_GH \times \complement_GH)=\lbrace e \rbrace$ , if any? what's the characterization of $H$ and/or $G$ to get $f(\complement_GH \times \complement_GH)=H$ ? (by ""characterization of $H$ and/or $G$ "" I mean something like, e.g., "" $H$ normal in $G$ "", or the like).","['group-theory', 'abstract-algebra']"
3063212,Proving that a function derived from $\arctan(x/y)$ is continuous on $y\ne0$,"$\Omega_1 = \{y > 0\} $ $\Omega_2 = \{y < 0\} $ $\Omega_3 = \mathbb R^2 \backslash \{x \leq 0 \ \ ; \  \ y = 0 \} $ \begin{equation}
  f(x,y) = \left \{
  \begin{aligned}
    &- \arctan \frac x y + \pi, && \text{if}\ (x,y) \in \Omega_1 \\
    & \frac {\pi} 2, && \text{if}  \ y = 0 \ ; \ x > 0 \\
    &- \arctan \frac x y, &&  \text{if}\ (x,y) \in \Omega_2
  \end{aligned} \right.
\end{equation} Prove that : $$ f \in C^1( \Omega_3) $$ So the obviously only problem is on the boundary of $\Omega_1$ and $\Omega_2$ . I don't know how to prove neither continuity nor differentiability. Can you help me ?",['multivariable-calculus']
3063223,Lipschitz continuity of $e^{\sin}$,"We want to use the Picard-Lindelöf-Theorem to show that the ODE $$y'=\mathrm{e}^{\sin(ty)}$$ has a unique solution on $\mathbb{R}$ with the initial value $y(0)=0$ . As far as I know, we have to show that the right hand side is Lipschitz-continuous with respect to $y$ . So we need to proof $$\vert \mathrm{e}^{\sin(tx)}-\mathrm{e}^{\sin(ty)}\vert \leq L \vert x-y\vert$$ for all $t,x,y \in \mathbb{R}$ . I don't get it, to show this. I heard that because the right hand side is differentiable, that is eventually possible to show this with the mean-value theorem or gradient. But I don't know whether this works because I think the derivative is not bounded. What can one do?","['multivariable-calculus', 'lipschitz-functions', 'ordinary-differential-equations', 'real-analysis']"
3063272,Is this way of finding $\lim\limits_{x\to +\infty}(x-\ln(x^2+1))$ valid?,"I needed to find: $$\lim\limits_{x\to +\infty}(x-\ln(x^2+1))$$ So here are the steps I took: Step 1: Replace $x$ with $\ln(e^x)$ : $$\lim\limits_{x\to +\infty}\left(\ln(e^x)-\ln(x^2+1)\right)$$ $$\lim\limits_{x\to +\infty}\ln\left(\frac{e^x}{x^2+1}\right)$$ Step 2: Bring the limit inside of the natural log function since it is continuous on the required interval. $$\ln\left(\lim_{x\to +\infty}\frac{e^x}{x^2+1}\right)$$ Step 3: Apply L'Hospital's rule twice and evaluate: $$\ln\left(\lim_{x\to +\infty}e^x\right)$$ $$\ln(+\infty) = +\infty$$ My question is whether step 2 is valid here because $\lim\limits_{x\to \infty}\frac{e^x}{x^2 + 1}$ doesn't exist (its $+\infty$ ), and in order to move the limit operator inside the function the limit $\lim\limits_{x\to \infty}\frac{e^x}{x^2 + 1}$ must exist according to this theorem in a book about Calculus (ISBN 978-0-470-64769-1): If it's not valid, what would be a valid way to find the limit?","['limits', 'calculus', 'continuity', 'real-analysis']"
3063340,$n$ vertex graph with more edges than its Turan number: $e(G) = t_r(n) + 1$,"I have been struggling with this problem for quite some time now and I cannot think of a way to proceed with either part: Suppose that G is a graph with $n > r + 1$ vertices and $t_r(n) + 1$ edges: (a) Prove that for every $p$ with $r + 1 < p <= n$ there is a subgraph $H$ of $G$ with $|H| = p$ and $e(H) \geq t_r(p) + 1$ . (b) Prove that $G$ contains two copies of $K_{r+1}$ with exactly $r$ common vertices. For part a), I have so far tried to use induction on $n$ . For the base case with $n = r+2$ we have only $H = G$ and $n = p$ to check, which is clearly true. For the $n$ th case I think we want to find a vertex $v$ in $G$ of degree $\delta(T_r(n))$ , so that $H = G-v$ satisfies the induction hypothesis and gives all of the required subgraphs. This is where I am stuck, I cannot seem to find anything close to this required vertex. As $e(G) \geq t_r(n) + 1$ we know $K_{r+1} \leq G$ , so there is a vertex $v$ with $d(v) \geq r$ , which is not enough as $(q-1)r \leq \delta(T_r(v)) \leq qr-1$ . Perhaps useful I thought would also be the fact that if $|G| = n, e(G) = t_r(n), K_{r+1} \nleq G$ then $\delta(G) \leq \delta(T_r(v)) \leq \Delta(T_r(v)) \leq \Delta(G)$ , this would give us a large enough vertex to delete, but we need $G$ to not contain $K_{r+1}$ . Likewise I did not get very far in the second part of the question, apart from the fact that a $K_{r+1}$ would exist in G in that case, but I cannot see how to get a second copy. I noticed that someone has asked this identical problem a few years ago, but unfortunately, that one does not have any responses - which is why I have posted again as I do not have enough reputation to start a bounty without losing some rights on this site.","['graph-theory', 'extremal-graph-theory', 'combinatorics']"
3063347,Chord partition of regular polygon: same fraction of area and perimeter?,"This is a variation of a question posed by James Tanton on Twitter . Let $P$ be a regular $n$ -gon, $n \ge 3$ . A chord $c$ of $P$ is a segment connecting
two distinct points of the boundary of $P$ , on two distinct edges (so not two points on one edge). Such a chord partitions both the perimeter and area of $P$ into two non-zero parts.
For a given chord $c$ , let $a(c)$ and $p(c)$ be the smaller area fractions and
smaller perimeter fractions of the parts.
In other words, $a(c)$ is the area to the smaller side of $c$ divided by the area of $P$ . And similarly for $p(c)$ . Q . For which $n$ -gons do there exist chords $c$ and fractions $a(c) = p(c)$ not equal to $\frac{1}{2}$ ? Tanton's question asks for $n=4$ (a square), can $\frac{1}{3}$ be achieved? ""Simultaneously divide off one-third of the area of a square and one-third of the perimeter of the square?"" And the answer is No . (Image from Tanton .) The generalization asks for all those non-half fractions achievable
for regular $n$ -gons.
Perhaps the answer to Q is: For none?","['geometry', 'polygons', 'plane-geometry']"
3063375,"Logarithmic integral $ \int_0^1 \frac{x}{x^2+1} \, \log(x)\log(x+1) \, {\rm d}x $","At various places e.g. Calculate $\int_0^1\frac{\log^2(1+x)\log(x)\log(1-x)}{1-x}dx$ and How to prove $\int_0^1x\ln^2(1+x)\ln(\frac{x^2}{1+x})\frac{dx}{1+x^2}$ logarithmic integrals are connected to Euler-sums. In view of the last link I'm wondering about the following integral $$
\int_0^1 \frac{x}{x^2+1} \, \log(x)\log(x+1) \, {\rm d}x \, .
$$ I see I can throw it into Wolfram Alpha and get some disgusting anti-derivative with Li's up to ${\rm Li}_3$ . Anyway is there some manually more tractable way to solve this? I have tried two things of which both don't seem to lead anywhere so far. For the first one: I expressed $\frac{x}{x^2+1}$ by it's Mellin transform $\frac{\pi/2}{\cos\left(\frac{\pi s}{2}\right)}$ and interchanged the integral order $$
\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty} {\rm d}s \, \frac{\pi/2}{\cos\left(\frac{\pi s}{2}\right)} \left( -\frac{{\rm d}}{{\rm d}s} \right)\int_0^1 {\rm d}x \, x^{-s} \log(x+1)
$$ where the constant $c>-1$ is right of the first pole of the cosine at $s=-1$ and the contour can be closed in a circle on the left hand side of the plane to use the residue theorem. The $x$ -integral is equal to $$
\int_0^1 {\rm d}x \, x^{-s} \log(x+1) = \sum_{n=1}^\infty \frac{(-1)^{n+1}}{n(n+1-s)} = \sum_{n=1}^\infty \frac{(-1)^{n+1}}{1-s} \left( \frac{1}{n} - \frac{1}{n+1-s} \right)\\
= {\frac {\Psi \left( 1-s/2 \right) - \Psi \left( 3/2-s/2 \right) }{2(1-s)}} + {\frac {\log  \left( 2 \right) }{1-s}}
$$ where $\Psi$ is the Digamma function, related to the harmonic numbers $H_n$ . Deriving with respect to $s$ and picking up the residue $(-1)^k$ of the Mellin transform at $s=-2k-1$ ( $k=0,1,2,3,...$ ) one obtains $$
\sum_{k=0}^\infty (-1)^{k+1} \Bigg\{ {\frac {\Psi \left( 3/2+k \right) - \Psi \left( 2+k \right) }{ 8\left( 1+k \right) ^{2}}} - {\frac {\Psi' \left( 3/2+k \right) - \Psi' \left( 2+k \right) }{8(1+k)}} + {\frac {\log  \left( 2 \right) }{ 4\left( 1+k \right) ^{2}}} \Bigg\}
$$ where $\Psi'$ is the derivative of the Digamma function related to $H_{n,2}$ . The terms with integral argument presumably can be evaluated in closed form, but I'm wondering if the half-integer argument terms can be also evaluated just by algebraic manipulations? Second: I tried to find closed form for the integral by partial integration \begin{align}
I(a) &=\int_0^1 \frac{\log(x) \log(x+1)}{x+a} \, {\rm d}a \\
&=-\frac{\log(2)}{a+1} - \int_0^1 \frac{x\left(\log(x)-1\right)}{(x+1)(x+a)} \, {\rm d}x + \int_0^1 \frac{x\left(\log(x)-1\right) \log(x+1)}{(x+a)^2} \, {\rm d}x \\
&=-\frac{\log(2)}{a+1} - \int_0^1 \frac{x\left(\log(x)-1\right)}{(x+1)(x+a)} \, {\rm d}x - \int_0^1 \left( \frac{\log(x+1)}{x+a} - \frac{a\log(x+1)}{(x+a)^2} \right) + I(a) + a I'(a)
\end{align} and thus $$
I(a) = \int_\infty^a \frac{{\rm d}a'}{a'} \Bigg\{ \frac{\log(2)}{a'+1} + \int_0^1 \frac{x\left(\log(x)-1\right)}{(x+1)(x+a')} \, {\rm d}x + \int_0^1 \left( \frac{\log(x+1)}{x+a'} - \frac{a'\log(x+1)}{(x+a')^2} \right) {\rm d}x \Bigg\}
$$ of which many terms are easy to integrate, but there is one combination which seems very difficult, namely something like $$
\int \frac{{\rm Li}_2(a')}{a'+1} \, {\rm d}a' \, .
$$ $a=\pm i$ at the end. Any insights?","['integration', 'analysis', 'complex-analysis', 'harmonic-numbers', 'polylogarithm']"
3063389,"How is it possible that to prove theorems about some set (say, the naturals) we have to introduce elements from outside that set?","Take as an example, Analytic Number Theory. As far as I have read, it used the tools of complex numbers to reach conclusions about Number Theory (the set here would be the naturals). However, assuming that there exist Number Theory theorems without elementary proofs, how can it be that we don't have enough information about the naturals in the naturals themselves for us to introduce new elements (Reals and i ) which don't have to do with the naturals? Why can't we prove them using only the naturals and nothing else? This question also extends to theorems about the rationals and the reals. Also, I'm sorry if this is a stupid question, or if the tags are not appropiate. Thanks.",['number-theory']
3063391,Interchanging limit and integral.,"Suppose $(X,\mu)$ is a probability space, $W\in L^1(X)$ , $V\in L^\infty(X)$ , and $V_n\to V$ in $L^2(X)$ (in my situation $V_n$ is the partial Fourier sum and so the $L^2(X)$ convergence is automatic). Can we say that $\int_X WVd\mu= \lim_{n\to\infty}\int_X WV_nd\mu$ ? I think so, but I am having trouble showing this.
If $W$ is square integrable then the result follows from Cauchy-Schwarz. But of course this argument does not work for less regular $W$ . I have considered dominated convergence theorem and it's variation, but finding a dominating function is eluding me. Could anyone help out? Both suggestions and solutions are welcome. Thanks in advance!","['measure-theory', 'fourier-analysis', 'cauchy-schwarz-inequality', 'lp-spaces', 'holder-inequality']"
3063412,deformation of Hodge star operator and harmonic forms,"Suppose $(M,g)$ is a compact Riemannian manifold, and $*_g$ is the Hodge star operator defined on the de Rham algebra $\Omega^*(M)$ with respect to the metric $g$ . Let $\phi:M\to M$ be a diffeomorphism. Then, can we find another metric $h$ (which should be related to $\phi$ ) so that $$
(\phi^{-1})^* \circ *_g\circ \phi^*
$$ agree with the new Hodge star operator $*_h$ ? EDIT: I guess this should be the Hodge star operator for the pullback metric. On the other hand, we know $\phi$ induces a map $$
\phi^*:H^*(M)\to H^*(M)$$ on de Rham cohomology groups, and meanwhile we also know for any metric $h$ there is the so-called Hodge isomorphism $\mathcal H^*_h(M) \to H^*(M)$ where $\mathcal H^*_h(M)$ denotes the $h$ -harmonic forms. Now another interesting question is that can we find a metric $h$ so that we can induce a map $$ \phi^*: \mathcal H_g(M) \to \mathcal H_h(M)$$ ?","['hodge-theory', 'riemannian-geometry', 'de-rham-cohomology', 'differential-topology', 'differential-geometry']"
3063413,What's the geometric explanation of Lie Derivative and Covariant Derivative?,"What's the geometric explanation of Lie Derivative and Covariant Derivative?
For my understanding, covariant derivative somehow explain/ provided a way for determine the invariance or for coordinate transformation. While Lie Derivative somehow showed the changes caused by the metric. But it's still a little bit fuzzy to see how to explain them in a more intuitive way. Notation Check: I was reading Hamilton's Ricci Flow by AMS GSM series Volume 77, where on page 11 it stated that $L_X f=Xf $ . Just to check that this was a typo and $L_X f = X \bigtriangledown f$ , right?","['tensors', 'analysis', 'differential-geometry']"
3063415,Combinatorial Proof that $p(n)/(1+\epsilon)^n \to 0$,"I was thinking this morning about the identity $ \prod_{n=1}^{\infty} \left( \frac{1}{1-q^n} \right) = \sum_{n=0}^{\infty} p(n) q^n$ . The product on the left converges for $|q|<1$ , which implies the convergence of the series for $|q|<1$ . Given $\epsilon >0$ , let $q = \frac{1}{1+\epsilon} <1$ . Then, the series must converge at $q$ , implying that the $n^{th}$ term converges to $0$ , which tells us that $\frac{p(n)}{(1+e)^n} \to 0$ as $n \to \infty$ . I want a combinatorial proof that this is true. Note this means that something that relies on this generating function proof (i.e. using the asymptotic formula for $p(n)$ ) is not allowed.","['alternative-proof', 'integer-partitions', 'combinatorics', 'combinatorial-proofs']"
3063422,Does $(1+\frac12-\frac13) + (\frac14+\frac15-\frac16)+(\frac17+\frac18-\frac19)+\cdots$ converge?,"Does the series $$S=\left(1+\frac{1}{2}-\frac{1}{3} \right) + \left(\frac{1}{4}+\frac{1}{5}-\frac{1}{6} \right)+\left(\frac{1}{7}+\frac{1}{8}-\frac{1}{9}\right)+\cdots$$ converge? Here's my attempt at a solution: $$S = \sum_{n=1}^{\infty}\frac{1}{n}-2\sum_{n=1}^{\infty}\frac{1}{3n}=\sum_{n=1}^{\infty}\frac{1}{3n}=\frac{1}{3}\sum_{n=1}^{\infty}\frac{1}{n}$$ As we can ""rewrite"" this series as one third of the harmonical series (that diverges), we conclude the divergence of $S$ . Is this right? Which other convergence tests could be used?","['divergent-series', 'proof-verification', 'calculus', 'sequences-and-series', 'convergence-divergence']"
3063452,How can I prove that $\int _{-1}^{1} \frac{1}{x} dx =0 $,"According to WolframAlpha $\int _{-1}^{1} \frac{1}{x} dx =0 $ . But how can this be proved rigorously? I know that the function is odd, but it's unbounded on $[-1;1]$ . Leibniz–Newton formula cannot be applied here either. I would really appreciate some help with this matter.","['integration', 'calculus', 'real-analysis']"
3063463,Prove an inequality concerning $\ln$ function,"For any real number $p \in (0,1)$ , $\delta \in (0,1)$ and $p+\delta <1$ , prove the following inequality: $$(p+\delta)\ln \frac {p+\delta}{p} +(1-p-\delta)\ln \frac {1-p-\delta}{1-p} \ge 2\delta^2$$ I have tried some appoximation on $\ln$ function such as $\ln(1+x) \le x$ and $\ln(1+x)\ge x-x^2/2$ but it doesn't work.","['inequality', 'derivatives', 'real-analysis']"
3063473,What is the main difference between pointwise and uniform convergence as defined here?,"I have a little confusion here. I have seen the following several times and seem to be a bit confused as to differentiating them. Let $E$ be a non-empty subset of $\Bbb{R}$ . A sequence of functions $\{f_n\}_{n\in \Bbb{N}},$ converges pointwise to $f$ on $E$ if and only if \begin{align}f_n(x)\to f(x),\;\forall\,x\in E.\end{align} On the other hand $\{f_n\}_{n\in \Bbb{N}},$ converges uniformly to $f$ on $E$ if and only if \begin{align}f_n(x)\to f(x),\;\forall\,x\in E.\end{align} QUESTION: Why is $f_n(x)\to f(x),\;\forall\,x\in E,$ is used for both uniform and pointwise convergence or I'm I missing something important? Can't we distinguish them?","['analysis', 'real-analysis', 'definition', 'uniform-convergence', 'pointwise-convergence']"
3063482,Proof of this formula for $\sqrt{e\pi/2}$ and similar formulas.,"\begin{align}
\sqrt{\frac{e\pi}{2}}=1+\frac{1}{1\cdot3}+\frac{1}{1\cdot3\cdot5}+\frac{1}{1\cdot3\cdot5\cdot7}+\dots+\cfrac1{1+\cfrac{1}{1+\cfrac{2}{1+\cfrac{3}{1+\ddots}}}}
\end{align} as seen here . Is there other series that relate $\pi$ and $e$ ? Also, it's possible to rewrite the continued fraction above in terms of known functions/numbers?","['continued-fractions', 'pi', 'exponential-function', 'sequences-and-series']"
3063566,The number of ways the king,"Let the king stand in the upper left corner on an 8x8 chessboard. How many options to get to the cell number $ (i,j), i,j \in \{1,2 \ldots 8\}$ if the king goes to each cell no more than once? I do not know combinatorics very well, but I am very curious about the result. Sorry for not making any attempts. p.s. it's not homework.","['combinatorics', 'discrete-mathematics']"
3063576,"What does it mean that field $\mathbb{F}_{p^n}$ ""contains"" the prime field $\mathbb{Z}_p$?","I have read in few books (example Computational Number Theory , page 77) that any extension field $\mathbb{F}_{p^n}$ ""contains"" as a subfield the prime field $\mathbb{Z}_p$ ? What exactly does ""contains"" mean? Since the representations of the two fields are not same (we have to use polynomials or some other structure to represent $\mathbb{F}_{p^n}$ , while we use modular arithmetic to represent $\mathbb{Z}_p$ ), how can we say that one contains the other? Does it actually mean that it contains a subfield that is isomorphic to $\mathbb{Z}_p$ ? For instance, we can represent $\mathbb{F}_{3^2}$ using arbitrary symbols $\{0, 1, a, b, c, d, e, f, g\}$ or by pairs $\{(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)\}$ . How does this ""contain"" $\mathbb{Z}_3$ ? This is more related to the computational perspective, so for example if I am working in $\mathbb{F}_{p^n}$ , how do I represent the subfield and work directly on integers? Additionally if the subfield is itself an extension field (i.e. $\mathbb{F}_{p^m}$ for some $m$ that divides $n$ ), how can I use a smaller data structure to represent it while at the same time keeping it also part of $\mathbb{F}_{p^n}$ ?","['computational-algebra', 'number-theory', 'finite-fields', 'field-theory', 'extension-field']"
3063606,Is there a group with $2$ generators having exactly $17$ subgroups of index three?,"I recently saw a fun problem from a past qualifying exam from Stanford. It is Problem 10, part (b) in this document . I will screenshot the problem and its solution here: My question is the following. Does there exist a group $G$ which is generated by two elements, and
  has exactly 17 subgroups of index 3? If so, what kind of examples can one find? If the answer to the question is ""No"", then what is the largest value of $c$ such that there exists a group $G$ generated by $2$ elements, and having exactly $c$ subgroups of index $3$ ? All we know from the solution above is that $c\leq 17$ . Remark. I am tagging (finite-groups) since I assume the examples involved in this discussion will be finite groups. However, if there is an example of an infinite group $G$ which satisfies the desired properties, I am happy to learn about it as well!","['computational-algebra', 'finite-groups', 'examples-counterexamples', 'abstract-algebra', 'group-theory']"
3063608,Uniformly convergent on each compact set of $\mathbb R$ but not on $\mathbb R$,"As the title says, I am looking for a sequence of function which is uniformly convergent on all compact sets of $\mathbb R$ but not on $\mathbb R$ . I thought $f_n(x) = \frac{x}{n}$ is such a function since for any x in a bounded and closed subset of $\mathbb R$ . $\sup(f_n(x)-f(x)) \to 0$ as $n\to\infty$ . But since $\mathbb R$ is unbounded $x$ can get infinitely large thus the function sequence does not uniformly converge on $\mathbb{R}$ . I wanted to check if my understanding is correct. Thank you","['sequence-of-function', 'real-analysis', 'uniform-convergence', 'limits', 'convergence-divergence']"
3063610,How many points are needed to uniquely define an ellipse?,"I recently asked a question on this forum regarding why 3 points guaranteed the presence or absence of a unique equation representing a specific circle. (link here What do ""3 different points"" have to do with linear dependence in determining a unique circle? ) Shortly after this, I came across a question in my book that provided a picture of 4 red dots (image below) and asked, ""How many ellipses do these 4 red points define"". Having read the comments on my post with the circle, I thought that this was fairly straight forward. I chose "" 1 "". This was wrong. The answer was infinite. This caught me as surprising as I didn't think of the equations for a circle and an ellipse as differing by much beyond a scaling factor for each quadratic term. I know that the general equation for an ellipse is as follows: $$\left(\frac{x-h}a\right)^2 + \left(\frac{y-k}b\right)^2 = 1$$ The only thing I can think of is that because of the added scaling factors, there are now technically two additional unknowns (for a total of 4 different unknowns... h, a, k, and b), and therefore I need 4 points to specify an unique ellipse. However, I thought to myself again, even if the ellipse is not centered at the origin, if all 4 given points happened to coincide with the intersection between the major axis and the ellipse and the minor axis and the ellipse, then certainly that would specify an unique ellipse. If this is true, then why does the arrangement of the points matter in determining whether or not an unique ellipse is specified? Visual explanations would be greatly appreciated!","['conic-sections', 'linear-algebra']"
3063611,When is a collection of sets closed under union?,"I started studying Probability, and I'm not sure if I understand what is the meaning of ""closed under union"". A collection (say $F$ ) of subsets of a set (say $\Omega$ ) is said to be a $\sigma$ -algebra if: $\Omega \in F$ $F$ is closed under complement $F$ is closed under union Now, consider the following example: Given $\Omega = \{1, 2, 3, 4, 5\}$ , is $F = \{\emptyset, \{1, 2\}, \{3, 4, 5\}, \{5\}, \{1, 2, 3, 4\}, \{1, 2, 3, 4, 5\}\}$ closed under union? I'm asking because I know that $\bigcup_{i = 1}^{6} X_i \in F$ ; however it does not happen for any two elements, for example: $\{1,2\} \cup \{5\} \not\in F$ .","['elementary-set-theory', 'probability']"
3063646,What is the probability that the sum of digits of a random $k$-digit number is $n$?,"Let $X_1, X_2, \dots, X_k$ each be random digits. That is, they are independent random variables each uniformly distributed over the finite set $\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}$ . Let $S = X_1 + X_2 + \dots + X_k$ . Given some large integer $n$ , what is the probability that $S = n$ ? When $n$ or $k$ is small, the exact number can be computed as $$[z^n]\left(\frac{1-z^{10}}{1-z}\right)^k = \frac{1}{10^k} \sum_{10r+s=n} (-1)^{r+s} \binom{k}{r} \binom{-k}{s} = \frac{1}{10^k} \sum_{r} (-1)^{r} \binom{k}{r} \binom{k+n-10r-1}{n-10r}$$ (see the long list of questions below to see derivations) but what I need is an asymptotic expression useful for large $n$ and $k$ , and I don't know how to either derive one from this formula, or arrive at one independently. (For now, I'm not worrying about the complication of insisting that $X_1$ be nonzero, though feel free to consider it if it actually helps.) What I have tried, part 1: As the $X_i$ s are IID random variables (with mean $\mu = 4.5$ and variance $\sigma^2 = 8.25$ ), the central limit theorem applies, so we expect $\Pr(S = n)$ to be highest for $n$ around $4.5k$ , and the probability distribution of $S$ to be bell-curve-shaped around that value (and most of the probability will be distributed for $n$ about $O(\sqrt{k})$ from that value). Trying to make this more precise, the central limit theorem gives us $$\sqrt{k}(S/k - 4.5) \xrightarrow{d} N(0,8.25) \quad \text{i.e.} \quad \lim _{k\to \infty}\Pr \left[\sqrt{k}(S_{k}/k- 4.5)\le z\right]= \Phi\left(\frac {z}{\sqrt{8.25}}\right)$$ where $\Phi(x) = \frac12 \left[1+\operatorname{erf} \left(\frac{x}{\sqrt {2}}\right)\right]$ is the CDF of the standard normal distribution $N(0,1)$ (and erf is a special function ) and therefore $$\Pr(S \le x) = \Pr(S/\sqrt{k} - 4.5\sqrt{k} \le x/\sqrt{k} - 4.5\sqrt{k}) \to \Phi\left(\frac{x - 4.5k}{\sqrt{8.25k}}\right)$$ and so, applying a continuity correction , $$\begin{align}\Pr(S = n) &\approx \Pr(n - 0.5 < S \le n + 0.5) \\
&\to \Phi\left(\frac{n + 0.5 - 4.5k}{\sqrt{8.25k}}\right) - \Phi\left(\frac{n - 0.5 - 4.5k}{\sqrt{8.25k}}\right) \\
&= \frac12\operatorname{erf}\left(\frac{2n+1-9k}{\sqrt{66k}}\right) - \frac12\operatorname{erf}\left(\frac{2n-1-9k}{\sqrt{66k}}\right) \\
&\overset{?}{\approx} \frac{2}{\sqrt{\pi}}\frac{1}{\sqrt{66k}}\exp\left(-\left(\frac{2n-9k}{\sqrt{66k}}\right)^2\right)
\end{align}$$ but I neither know whether this is correct and rigorous, nor what to do with this next. What I have tried, part 2: There are many questions on this site about calculating this number exactly: Probability of random integer's digits summing to 12 how many integers between one and 100000 have the sum equal to fifteen? How many numbers between 100 and 900 have sum of their digits equal to 15? Stars and bars to find ""how many $x$ digit numbers are there with sum of digits $y$ ""? Find numbers whose sum of digits equals a value Counting the numbers with certain sum of digits. How many natural numbers are there less than $90000$ that have the sum of digits equal to $8$ ? How many integers between [3,000, 8,000] have digit sum 20? Counting $4$ -digits numbers whose digits sum is $9$ How many numbers between $1$ and $9999$ have sum of their digits equal to $8$ ? $16$ ? How many numbers between $0$ and $999,999$ are there whose digits sum to $r$ How many positive integers less than 1,000,000 have the sum of their digits equal to 19? How many positive integers < 10^6 have sum of digits equal to 19 For how many integers from 1 through 99,999 is the sum of their digits equal to 10? If I have an integer, how many numbers are there whose digits sum to the integer? Determine the number of positive integer x where x≤9,999,999 and the sum of the digits in x equals 31. Find number of positive integers less than $10^8$ with digit sum of $24$ Find the number of positive integers whose digits add up to 42 Enumerating number of solutions to an equation The best that can be got from reading all of them is the exact formula mentioned at the top of the question (done with generating functions or inclusion-exclusion), not an asymptotic one. In particular I'd like to be able to get something which can be summed over $k$ , to answer the following question: Question 2: Let $X_{i,j}$ each be IID random digits as before, for $i = 1, 2, \dots$ and $j = 1, 2, \dots, i$ . Let $S_k = X_{k,1} + X_{k,2} + \dots + X_{k,k}$ be the sum of $k$ random digits. So we have an infinite sequence of random variables (sums) $S_1, S_2, S_3, \dots$ each obtained by adding the digits of a random number of a different length. Given an integer $n$ , what is the probability that some element of this sequence is exactly equal to $n$ ? In other words, for each $k$ there is a probability distribution over $n$ , and we want to know the total probability that falls on a single integer $n$ . (Basically for each $n$ there will be some significant probability for $k$ around $n/4.5$ and the probability will fall off significantly for $k$ further away from this.) (Again, feel free to add or remove the condition that $X_{k,1}$ is actually distributed over the set $\{1, 2, \dots, 9\}$ , i.e. is nonzero.) What I have tried, part 3: I tried to read Distribution of the sum-of-digits function of random integers: A survey (which I found by searching for some relevant terms), and many of the papers it references. But I got pretty lost trying to figure out what is true for base- $2$ versus base- $10$ , and things like that. Perhaps the answer to my question is buried somewhere in there, but I'm not sure.","['probability-limit-theorems', 'probability-theory', 'asymptotics']"
3063704,Fubini's theorem for series with dependent indices,"As a part of a proposition about power series that I am trying to prove I have to show that $$ \sum_{m=0}^{\infty} \left(\sum_{n=m}^{\infty} \frac{n!}{m!(n-m)!}(b-a)^{n-m}c_n\right)(x-b)^m = \sum_{n=0}^{\infty}c_n(x-a)^n$$ Proof : What I have done so far is to show that $$\sum_{m=0}^{n} \frac{n!}{m!(n-m)!}(b-a)^{n-m}(x-b)^m = (x-a)^n $$ So the next idea is to use Fubini's rearrangement theorem for infinite series (I have also shown that the series are absolutely convergent). However, the theorem does not accomodate for dependent indices. Intuitively (using triangular summation), I think that the proper way to interchange series would be \begin{equation*}
%\begin{array}{ll}
\sum_{m=0}^{\infty} \sum_{n=m}^{\infty} \frac{n!}{m!(n-m)!}(b-a)^{n-m}c_n(x-b)^m = \sum_{n=0}^{\infty} \sum_{m=0}^{n}\frac{n!}{m!(n-m)!}(b-a)^{n-m}c_n(x-b)^m
%\end{array}
\end{equation*} and thus $$=\sum_{n=0}^{\infty} c_n(x-a)^n$$ However, I do not know how to perform this step rigorously in case of infinite summation.","['power-series', 'sequences-and-series', 'real-analysis']"
3063762,What is the mathematical meaning of this question?,"$a,b,c \in\mathbb{Z}$ and $x\in\mathbb{R}$ , then the following expression is always true: $$(x-a)(x-6)+3=(x+b)(x+c)$$ Find the sum of all possible values of $b$ . A) $-8$ B) $-12$ C) $-14$ D) $-24$ E) $-16$ I didn't understand what is the meaning of ""...is always true"" . Even though I can't understand the question, I wrote these: $$(x-a)(x-6)+3=(x+b)(x+c) \Rightarrow x=\frac{6a-bc+3}{6+a+b+c}$$ Here, $b$ can take an infinite number of values. Or do I miss something? For example, let  random values $a=100,b=50,c=3$ then $x=\frac {151}{53}$ . Is there a problem with the question?","['contest-math', 'algebra-precalculus', 'problem-solving', 'means']"
3063763,Probability of reaching a maximum in a random walk,"Let's define a random walk in the following way $$S_0 = 0, S_n = \sum_{i=1}^{n} \epsilon_i,$$ where: $$\epsilon_i = \pm 1.$$ Moreover $$P(\epsilon_i = - 1) = P(\epsilon_i = + 1) = \frac{1}{2}.$$ Again, let's define a random variable $X_n$ which gives us the position of the first maximum of a random walk of length $2n$ . I am to show that $$P(X_n = 2k) = P(X_n = 2k + 1) = \frac{1}{2}u_{2k}u_{2n-2k}.$$ Here $$u_{2n} = \frac{\binom{2n}{n}}{2^{2n}} = P(S_{2n} = 0) = P(S_1 \ge 0, S_2 \ge0, \ldots, S_{2n} \ge 0) = P(S_1 \neq0, S_2 \neq 0, \ldots, S_{2n} \neq 0).$$ I also know that $$u_{2k}u_{2n-2k}$$ tells us about the probability that a randomly walking particle is $2k$ ,,moves'' above the $x$ axis and $2n-2k$ below. However I don't know how to combine all those things and give the proof. I would appreciate any hints or tips.","['stochastic-processes', 'probability-theory', 'random-walk']"
3063807,Combinatorics problem from a contest,"The integers $1, 2, 3, 4, 5, 6, 7, 8, 9, 10$ are written on a blackboard. Each day, a teacher chooses one of the integers uniformly at random and decreases it by $1$ . Let X be the expected value of the number of days which elapse before there are no longer positive integers on the board. Estimate $X$ The answer is given to be $120.7528$ . I solved it in the below manner and wonder if it is right. Let $X_i$ be a random variable denoting number of trials required to hit 0.  The discrete values it can take are $(1,2,.. i,0)$ where I club all non positive integers on trials to 0. For $X_1$ , the sample space is ${0,1}$ . Actually, it should be represented by hypergeometric distrbution with the teacher striking down each integer by 1.  As an approximation as the number of trials can be infinite, geometric distribution is used.  Thus the probability of success for $X_1$ is $\frac{1}{10}.\frac{1}{2} = \frac{1}{20}$ .  The probability of failure is $1-p_{success} = \frac{19}{20}$ . Similary for $X_2$ , the sample space is $(0,1,2)$ and the probability of success for $X_2$ is $\frac{1}{10}.\frac{2}{3} = \frac{2}{30}$ . and that of the failure is $= \frac{28}{30}$ . And thus for $X_{10}$ , the sample space is $(0,1,2,3,..,10)$ and the probability of success for $X_{10}$ is $\frac{1}{10}.\frac{10}{11} = \frac{10}{110}$ and that of the failure is $= \frac{100}{110}$ . Let us define the $X$ as the total number of trials required for the teacher to strike down all integers to 0.
Then $X = X_1+X_2+\cdots+X_{10}$ $E(X) = E(X_1+X_2+\cdots+X_{10}) = E(X_1)+E(X_2)+\cdots+E(X_{10})$ $E(X_i) = \frac{1-p_i}{p_i}$ I did the calculation and I hit a very close answer of $119.2897$ which is $1$ less the contest answer $120.7528$ . Let me know if the approach is right?.  There is no solution provided so I do not know what approach they have taken.","['contest-math', 'combinatorics', 'probability-theory']"
3063812,Make a short exact sequence of abstract groups into a short exact sequence of topological groups (motivated by the Weil Group),"Let $1 \to H_1 \to G \to H_2 \to 1$ be a short exact sequence of abstract groups. Question : If $H_1$ , $H_2$ have fixed topologies, can we endow $G$ with a topology such that the sequence above becomes a short exact sequence of topological groups? If yes, is this topology then uniquely determined? Motivation : I want to understand the topology of the Weil group $W_K$ which is a dense subgroup of the absolute Galois group $G_K$ (which has this weird profinite topology I find hard to get). However, we have a short exact sequence of abstract groups $$1 \to I_K \to W_K \to \langle \operatorname{Frob}_k \rangle \to 1$$ where $I_K$ denotes the inertia subgroup of $G_K$ and $\operatorname{Frob}_k : x \mapsto x^{|k|}$ is the Frobenius element of the absolute Galois group $G_k$ of the residue field $k$ of $K$ . If I understand it correctly, this sequence is not a short exact sequence of topological groups if we give $W_K$ the subspace topology of $G_K$ . However, if we give $I_K$ and $\langle \operatorname{Frob}_k \rangle$ the subspace topologies of $G_K$ and $G_k$ respectively, we can give $W_K$ a unique topology such that this sequence becomes a short exact sequence of topological groups. I heard that this causes $W_K$ to have a finer topology than the usual subspace topology, $I_K$ to be open and the maximal compact subgroup of $W_K$ etc. but I do not really understand that. Could you please explain this to me? Thank you!","['algebraic-number-theory', 'topological-groups', 'group-theory', 'abstract-algebra', 'general-topology']"
3063822,How many uniform polytopes are there in higher dimensions?,"I am not really interested in the exact numbers, but more in the richness of the class of uniform (convex) polytopes in higher dimensions. Wikipedia contains the followin statement : In five and higher dimensions, there are $3$ regular polytopes, the hypercube, simplex and cross-polytope. [...] Most uniform higher-dimensional polytopes are obtained by modifying the regular polytopes, or by taking the Cartesian product of polytopes of lower dimensions. In six, seven and eight dimensions, the exceptional simple Lie groups, $E_6$ , $E_7$ and $E_8$ come into play.[...] I am interested in a quantification of the emphasized sentence above. In what sense are these most uniform polytopes? Does the world of uniform polytopes become ""boring"" in, say, more than $30$ dimensions, because there only remain simple variations on regular polytopes and cartesian products?  Or are there exceptional  polytopes expected in higher dimensions too? I would also be satisfied with something like ""this seems to be unknown"", preferably with some reference.","['polytopes', 'discrete-geometry', 'geometry', 'reference-request']"
3063834,Construct bijections of given sets to show that they have the same cardinality and prove they are correct,"I need to construct bijections of few sets to show that they have the same cardinality and prove their correctness. I have already done $f: \mathbb{N}\rightarrow\mathbb{Z}$ , which was not very hard, but I am struggling with a bit more complex examples. In the following examples $a \bot b$ means, that $a$ and $b$ are coprime numbers. Ex. 1: $\mathbb{N}$ and $\{\langle n,m\rangle \in \mathbb{N}^+\times\mathbb{N}^+ \:|\: m\bot n\}$ It should be a function of the form $g: \mathbb{N}\rightarrow \mathbb{N}^+\times \mathbb{N}^+$ , but I do not know how should a function of one number create a pair of coprime numbers. Ex. 2: $\{\langle n,m\rangle \in \mathbb{N}^+\times\mathbb{N}^+ \:|\: m\bot n\}$ and $\mathbb{Q}^+$ There the function should have the form $h:\mathbb{N}^+\times\mathbb{N}^+\rightarrow \mathbb{Q}^+$ and I was thinking about a function which would divide $n$ by $m$ , which in my opinion would be pretty understandable, but I am not sure whether it is a correct idea. I would like to get some tips how should I get a grasp in solving such problems, as well as some hints how to solve and prove these two examples.",['elementary-set-theory']
3063839,Super hard system of equations,"Solve the system of equation for real numbers \begin{split}
(a+b)    &(c+d)     &= 1 & \qquad (1)\\
(a^2+b^2)&(c^2+d^2) &= 9 & \qquad (2)\\
(a^3+b^3)&(c^3+d^3) &= 7 & \qquad (3)\\
(a^4+b^4)&(c^4+d^4) &=25 & \qquad (4)\\
\end{split} First I used the identity $$(a^2+b^2)(c^2+d^2)=(ac-bd)^2+(bc+ad)^2$$ Use this identity to (4) too
and simplify (3),
we obtain $$(a^2+b^2-ab)(c^2+d^2-cd)=7$$ And suppose $x=abcd$ use $ac=x /bd , bc=x/ad$ But got stuck...","['algebra-precalculus', 'systems-of-equations', 'symmetric-polynomials']"
3063864,Pushforward of the structure sheaf on $\mathbb{P_\mathbb{C}^1}$,"Today I had the final exam of the lesson Algebraic Geometry. There was a question was asked: Let $X=Y=\mathbb{P_\mathbb{C}^1}$ the homogeneous coordinate $(x_0,x_1)$ and $(y_0,y_1)$ , respectively.  Let $f : X \to Y$ be a morphism given by $$
(x_0,x_1) \to (y_0,y_1)=(x_0^2,x_1^2).
$$ Show that $f_\ast O_X $ is a locally free sheaf of $O_Y $ -modules of rank two. ( $ O_X $ is the structure sheaf of $X$ ). Show that the induced map $i : O_Y \to f_\ast O_X $ is injective. Show that the cokernel of $i$ as a sheaf is isomorphic to $O_Y (−1)$ . There is a similar  question with respect to the situation of pullback，but  I don't even know how to deal with this problem. Hopefully someone can give me a hint.","['algebraic-geometry', 'sheaf-theory']"
3063869,How does the vector triple product BAC-CAB Identity come about?,"As in the title, I was studying the proof (from Vector Analysis - Louis Brand) of this identity, however I do not completely understand all of the steps. $$a \times (b \times c) = b(a \cdot c) - c(a \cdot b)$$ I also visited an excellent related post - do the BAC-CAB identity for vector triple product have some interpretation? , but I am still stuck. I reproduce the proof in the book here. I don't really understand, how did the author deduce $\alpha=-\lambda(\textbf{v}\cdot\textbf{w}),\beta=\lambda(\textbf{u}\cdot\textbf{w})$ and the basis steps. Any inputs, suggestions or tips to understand the proof would be incredibly helpful! Proof. The vector $(\textbf{u} \times \textbf{v}) \times \textbf{w}$ is perpendicular to both $\textbf{u}\times\textbf{v}$ and therefore coplanar with $\textbf{u}$ and $\textbf{v}$ . $$(\textbf{u}\times\textbf{v})\times\textbf{w}=\alpha\textbf{u}+\beta\textbf{v}$$ But, since $(\textbf{u}\times\textbf{v})\times\textbf{w}$ is also perpendicular to $\textbf{w}$ , $$(\alpha\textbf{u}+\beta\textbf{v})\cdot\textbf{w}=0$$ All numbers $\alpha,\beta$ that satisfy this equation must be of the form $\alpha=\lambda(\textbf{v}\cdot\textbf{w}),\beta=\lambda(\textbf{u}\cdot\textbf{w})$ , where $\lambda$ is arbitrary. Thus, we have $$\textbf{u}\times(\textbf{v}\times\textbf{w})=\lambda\{(\textbf{u}\cdot\textbf{w})v-(\textbf{v}\cdot\textbf{w})\textbf{u}\}$$ In order to determine $\lambda$ , we use a special basis in which $\hat{i}$ is collinear with $\textbf{u}$ , $\hat{j}$ is co-planar with $\textbf{u, v}$ ; then $$\textbf{u}=u_{1}i,\textbf{v}=v_{1}i+v_{2}j,\textbf{w}=w_{1}i+w_{2}j+w_{3}k$$ On substituting these values, we obtain, after a simple calculation, $\lambda=1$ . We therefore have important expansion formulas, $$(\textbf{u}\times\textbf{v})\times\textbf{w}=(\textbf{u}\cdot\textbf{w})\textbf{v}-(\textbf{v}\cdot\textbf{w})\textbf{u}$$ $$\textbf{w}\times(\textbf{u}\times\textbf{v})=(\textbf{w}\cdot\textbf{v})\textbf{u}-(\textbf{w}\cdot\textbf{u})\textbf{v}$$","['cross-product', 'proof-explanation', 'multivariable-calculus', 'vector-analysis']"
3063872,"$A \in \mathbb{C}^{m\times n}$,$A=FG^*$ and $r(A)=r(F)=r(G)$. Prove $A^\dagger = G(F^*AG)^{-1}F^*$ and $A^\dagger = (G^\dagger)^*F^\dagger$","Let $A^\dagger$ be a Moore-Penrose inverse of a matrix $A$ . If $A \in \mathbb{C}^{m\times n}$ and $A=FG^*$ , for some $F,G$ and $r(A)=r(F)=r(G)$ , prove that $$A^\dagger = G(F^*AG)^{-1}F^*$$ and $$A^\dagger = (G^\dagger)^*F^\dagger.$$ I need to show this using SVD decomposition and maybe some other properties of a Moore-Penrose inverse. I tried to show the statement by writing SVD decomposition of all the matrices included, but it just gets messy and I didn't succeed. Any hints would be really helpful! Thanks in advance!","['linear-algebra', 'svd', 'generalized-inverse']"
3063918,Is the sum of two irrational numbers almost always irrational?,"Clearly the sum of two irrational numbers is not necessarily irrational. But is it true that it is 'almost always' irrational, in the sense that $$\displaystyle\lim_{x\to\infty}\dfrac{\lambda(P\cap B(x))}{\lambda(R\cap B(x))}=1$$ where $\lambda$ is Lebesgue measure, $R\subset \mathbb{R}^2$ is the set of points with irrational coordinates and $P\subset R$ is the set of those points the sum of whose coordinates is irrational (and $B(x)$ the disc of radius $x$ centred at the origin)? And I guess the same question applies to transcendental numbers. Intuitively it seems true, but I don't know how one would prove this. If not, then there is the question of whether the limit exists and if it does what is it.","['number-theory', 'probability-theory', 'real-analysis']"
3063922,Convergence or diverge of the series $\sum_{n=1}^\infty\left(\frac{1}{n} - e^{-n^2}\right)$,"I was studying sequences and series from a book when I ran into the following problem. The text before the problem indicated that I should be using Ratio test or Root test to solve it, however root test didn't seem to fit well and ratio test was inconclusive (resulted in a ratio of $1$ ) $$\sum_{n=1}^\infty\left(\frac{1}{n} - e^{-n^2}\right)$$ Any hints or actual answers would be greatly appreciated. Thanks in advance 
Also please comment as to why it is off-topic before voting to close it.","['divergent-series', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3063952,"For which $P,Q \in \text{SO}$ $T_P\text{SO}$ and $T_Q\text{SO}$ are parallel?","I am curious: For which $P,Q \in \text{SO}_n$ does $T_Q\text{SO}_n=T_P\text{SO}_n$ hold? This reduces to the question at the identity,i.e. for which $Q \in  \text{SO}_n$ , $T_Q\text{SO}_n=T_{Id}\text{SO}_n=\text{skew}$ . I will now prove that $Q^2=Id$ is a necessary condition. Is it sufficient? Since $T_Q\text{SO}_n=QT_{Id}\text{SO}_n=Q\text{skew}$ , this happens if and only if $Q\text{skew}=\text{skew}$ , i.e. $-AQ^T=(QA)^T=-QA$ for every $A \in \text{skew}$ , or $AQ^T=QA$ . Taking traces we get $$ \langle Q,A\rangle=\text{tr}(Q^TA)=\text{tr}(AQ^T)=\text{tr}(QA)=\text{tr}(AQ)=-\text{tr}(A^TQ)= \langle A,Q\rangle,$$ so $\langle Q,A\rangle=0$ for every $A \in \text{skew}$ , i.e. $Q \in \text{skew}^{\perp}=\text{sym}$ , so $Q^T=Q$ , or $Q^2=Id$ . Note that at even dimensions $Q=-Id$ is always a solution. For dimension $n=2$ , this is indeed the only non-trivial solution (since $\text{SO}_2$ is the circle). In that case $Q^2=Id$ , and $Q=\pm Id$ are equivalent.","['riemannian-geometry', 'tangent-spaces', 'orthogonal-matrices', 'lie-groups', 'differential-geometry']"
3063965,How to show that $\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\frac{\pi^2}{6}$,"Wolfram Alpha shows that $$\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\zeta(2)=\frac{\pi^2}{6}$$ I want to prove this. Attempt: I tried to treat this as a telescoping series: $$\begin{align}
\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}&=\sum_{n=1}^{\infty}H_n\left(\frac{1}{n}-\frac{1}{n+1}\right)\\
&=H_{1}\left(1-\frac{1}{2}\right)+H_{2}\left(\frac{1}{2}-\frac{1}{3}\right)+H_{3}\left(\frac{1}{3}-\frac{1}{4}\right)\\
&=1-\frac{1}{2}+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{6}+\frac{1}{3}-\frac{1}{4}+\frac{1}{6}-\frac{1}{8}+\frac{1}{9}-\frac{1}{12}
\end{align}$$ I think this method is not quite useful, so I tried  another one: $$H_n=\int_{0}^{1}\frac{1-t^n}{1-t}dt$$ Then, $$\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\sum_{n=1}^{\infty}\frac{1}{n^2+n}\int_{0}^{1}\frac{1-t^n}{1-t}dt$$ At this point, I do not know how to proceed.","['integration', 'harmonic-numbers', 'closed-form', 'sequences-and-series']"
3063992,Compute the given limit as $x$ approaches $\infty$,"If $f(x) = 8x^3+3x$ then, $$\lim_{x \to \infty} \frac{f^{-1}(8x)-f^{-1}(x)}{x^{1/3}}$$ is? My attempt:
It is clear that the function cannot be easily inverted. So, there must be something in the limit given itself that may simplify the problem. Honestly, I have no clue what to do here. There are a few things which I could see is that the function has only $1$ root(i.e $0$ ) and is bijective on $x \in \mathbb R$ . But that gave no benefit except showing that the inverse of the function exists. Any help would be appreciated.","['limits', 'functions']"
3063993,Is the natural embedding from $X$ to $X^{**}$ a homeomorphism with respect to the weak topologies if $X$ is reflexive?,"If $X$ is a reflexive Banach space, is it true that the natural embedding $\Lambda$ of $X$ into its double dual is a homeomorphism? Here we equip $X$ with the weak topology, and $X^{**}$ with the weak-* topology, i.e. $\sigma(X^{**},X^*)$ . I think that this is true. To start with I have shown that it is at least continuous by using nets. I also wanted to show that the inverse is continuous (but I could not figure this out using nets), but here's how far I got: So assume that the net $f_a \rightarrow f$ weakly (here the $f_a$ lie in $X^{**}$ ). We want to show $\Lambda^{-1}(f_a) \rightarrow \Lambda^{-1}(f)$ weakly. Note that $f_a \rightarrow f$ weakly is equivalent to $f_a(x) \rightarrow f(x)$ for all $x \in X^{*}$ . And that the conclusion is equivalent to $x(\Lambda^{-1}(f_a)) \rightarrow x(\Lambda^{-1}(f))$ weakly for all $x \in X^*$ . This is where I'm getting a bit confused: Is $x(\Lambda^{-1}(f_a))=f_a(x)$ ?","['banach-spaces', 'functional-analysis']"
3064018,Why an unbounded operator is not-constructive relying on Hahn Banach theorem?,"Let $T: \mathcal S(\mathbb R)\to L^2(\mathbb R)$ defined by $$Tf(x)=f'(x),$$ where $\mathcal S(\mathbb R)$ is the Schwarz space on $\mathbb R$ . The question is : is there a continuous extension to $L^2(\mathbb R)$ , and the answer is no, because $\frac{\|Tf_k\|}{\|f_k\|}\to \infty $ where $f_k(x)=e^{-k|x|},$ and thus $T$ is unbounded. You'll see the example here 1) Why is this a counter-example since $e^{-k|x|}\notin \mathcal S(\mathbb R)$ ? and is even not derivable at $0$ , so $f'(x)$ is not well defined on $\mathbb R$ , is it ? Because on $L^2(\mathbb R)\setminus \mathcal S(\mathbb R)$ , the operator $T$ can be different than $Tf(x)=f'(x)$ ? (for example the fourier transform is not the same on $\mathcal S(\mathbb R)$ than on $L^2(\mathbb R)$ . 2) Just under the example in the previous link, they say that the existence of unbounded operators defined everywhere is non constructive relying on Hahn-Banach theorem . Could someone explain what this is true ? I guess that here unbounded mean not continuous ? (and not defined on a subspace of the domain).",['functional-analysis']
3064030,Calculating the area of the parallelogramm given $4$ vertices.,"I want to calculate the area of a parallelogramm given the following four vertices: $$\vec{p}=\begin{pmatrix}2 \\ 0\\3 \end {pmatrix},\vec{q}=\begin{pmatrix}8 \\ 1\\1 \end {pmatrix},\vec{r}=\begin{pmatrix}6 \\ -2\\-1 \end {pmatrix},\vec{s}=\begin{pmatrix}12 \\ -1\\-3 \end {pmatrix}$$ I know I need to find two sides of the parallelogramm and then take the magnitude of the cross product. Here is my problem: Assume that I chose to compute $\vec{q}-\vec{p}$ and $\vec{s}-\vec{p}$ . My picture could look like this: However, since I don't know the spatial location of $p,q,r,s$ then the picture could also look like this: So how do I determine which points to subtract in order to get the correct pair of vectors? Does it even matter which pair I take or will the area be the same because of the symmetry of the problem?",['geometry']
3064037,When is a space homeomorphic to a quotient space?,"Is the following theorem true? It seems straightforward but I haven't seen it published anywhere, not even as a corollary, so I'm concerned I've missed something. Discussions that introduce quotient spaces all seem to dance around this very simple and useful fact. Why don't they just come right out and say it? Let $X$ and $Y$ be a topological spaces. Let $\sim$ be an equivalence relation on $X$ . Then $Y$ is homeomorphic to the quotient space $X/{\sim}$ iff there exists a quotient map $f:X \to Y$ that induces the same partition as $\sim$ .","['equivalence-relations', 'general-topology', 'quotient-spaces']"
3064078,"How to prove that there exist no functions $f,g:\Bbb{R}\to\Bbb{R}$ such that $f(g(x))=x^{2018}$ and $g(f(x))=x^{2019}$? [duplicate]","This question already has an answer here : Existence of two functions $f$ and $g$ for which $f\circ g (x)=x^2 , g\circ f (x)=x^3$ (1 answer) Closed 9 days ago . I have tried a little bit to solve the problem which goes as follows: My intuition says that there exist no $f:\Bbb R\to\Bbb R$ such that $$f(g(x))=x^{2018}\text{ and }g(f(x))=x^{2019}.$$ Note that $$f(g(f(x)))=f(x)^{2018}\implies f(x^{2019})=f(x)^{2018}$$ Similarly, $$g(x^{2018})=g(x)^{2019}$$ Putting $x=1$ in $f(x^{2019})=f(x)^{2018}$ , we get $f(1)=f(1)^{2018}$ and thus $f(1)=0$ or $f(1)=1$ . Similarly, putting $x=1$ in $g(x^{2018})=g(x)^{2019}$ we get $g(1)=g(1)^{2019}$ and thus $g(1)=0,1,-1$ . Now, I can't proceed further. Can anybody solve it? Thanks for assistance in advance.","['calculus', 'functions', 'real-analysis']"
