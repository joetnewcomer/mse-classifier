question_id,title,body,tags
2159546,Prove that the ant can survive,"There is a table with infinite cells. An ant starts from cell $(1,1)$ and each time it can move one cell up or right. Before starting to move, an infinite sequence of cell numbers like $<(x_{1},y_{1}) , (x_{2},y_{2}), ... , (x_{n}, y_{n}) , .... >$ is given to it.
After step $k$, cell number $(x_{k},y_{k})$ will be poisoned and if ant goes there or already is there, it'll die.
Prove with induction that the ant can live forever if it knows sequence elements from the beginning :)","['induction', 'discrete-mathematics']"
2159571,Show that $3+2\sqrt2$ has infinite order in the multiplicative group of units $\Bbb{Z}[\sqrt2]$,"I had a question for the first two parts of this question here . I was told to post a new question for the last two parts. I have a hint concerning the question, but i'm not sure how it relates. Here's the hint: If $a^n=1$, then $|a^n|=1$. If $0<a<1$, how does $|a^n|$ relate to $|a|$ for a positive integer n? If $|a|>1$, how does $|a^n|$ relate to $|a|$ for a positive integer n? I understand that $a^n<a$ for $0<a<1$ and that $a^n>a$ for $a>1$, but I don't see how that relates to the question. The last part of the question is: Show that -1 and 1 are the only units of $\Bbb{Z}[\sqrt2]$ that have finite order in $\Bbb{Z}[\sqrt2]^\times$.","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
2159641,How to solve this calculus problem,"This question was on my quiz for Calc AB, everyone was confused on how to solve it and I did some random substitution but was still getting nowhere. My teacher said it's possible to do it but not possible with the knowledge we have currently and she's going to throw out the problem. The problem was as following: $$\frac{\mathrm{d}y}{\mathrm{d}x}=y-3x$$","['ordinary-differential-equations', 'calculus']"
2159655,A Proof that the distribution becomes unitary after N step 2D lattice random Walk,"I am working with random walks and http://mathworld.wolfram.com/RandomWalk2-Dimensional.html says that ""Amazingly, it has been proven that on a two-dimensional lattice, a random walk has unity probability of reaching any point (including the starting point) as the number of steps approaches infinity."" I have been trying to prove this result with an expression for the probability distribution of a 2D lattice random walk, $P(N)$=$\frac{N!}{(n_r)!(n_l)!(2^N)}$, where $n_r+n_l=N$ $N$ is the total number of steps $n_r$ is the number of steps to the right and $n_l$ is the number of steps to the left and I substituted the value of N as 5000 and approximated the value of the factorial using Sterling Approximation. Then, I looked at different combinations of $n_r$ and $n_l$, such as (1000,4000); (2000,3000) etc and then calcualted the value of the probability function. The probability didn't even come close to 1 for any of the values. Is this the correct way to prove this statement? Also can this process be applied to 3D random walks to find the probability that the walk will pass through the origin?","['random-walk', 'probability-theory', 'probability-distributions']"
2159661,"For $a, b, c$ is the length of three sides of a triangle. Prove that $\left|\frac{a-b}{a+b}+\frac{b-c}{b+c}+\frac{c-a}{c+a}\right|<\frac{1}{8}$ [duplicate]","This question already has answers here : Prove that $\left | \frac{a-b}{a+b}+\frac{b-c}{b+c}+\frac{c-a}{c+a} \right | < \frac{1}{8}.$ (2 answers) Closed 7 years ago . For $a, b, c$ is the length of three sides of a triangle. Prove that $$\left|\frac{a-b}{a+b}+\frac{b-c}{b+c}+\frac{c-a}{c+a}\right|<\frac{1}{8}$$","['inequality', 'substitution', 'rearrangement-inequality', 'absolute-value', 'geometry']"
2159692,Evaluating limits at $-\infty$,"$$\lim_{x\to-\infty}\frac{\sqrt{x^6+729}}{4x^3+\sqrt{2x^6+1}}=\lim_{x\to-\infty}\frac{-\sqrt{1+\frac{729}{x^6}}}{4-\sqrt{2+\frac{1}{x^6}}}=\frac{-1}{4-\sqrt{2}}$$
$$\lim_{x\to\infty}\frac{\sqrt{x^6+729}}{4x^3+\sqrt{2x^6+1}}=\lim_{x\to-\infty}\frac{\sqrt{1+\frac{729}{x^6}}}{4+\sqrt{2+\frac{1}{x^6}}}=\frac{1}{4+\sqrt{2}}$$
Is this correct? Can someone please explain to me the distribution of the negatives in regards to the radicals when dealing with limits to $-\infty?$ Does it depend on the powers whether or not a negative stays outside of the radicals? Also, why does a negative not get applied to the $4$? Any help would be greatly appreciated!","['calculus', 'limits']"
2159698,Is it possible to change position of the segment so that it is parallel to Y axis?,"Let's consider infinite Cartesian system of coordinates. Assume that in any lattice point (i.e. both coordinates are integers) there is a spike. I have a line segment of length $n$ (it is an integer). It is parallel to X axis, as shown below (image shows only a part of system of coordinates). I want to make it parallel to Y axis as shown below. What I can do is rotate and move this line segment, but without raising it up. I can't change shape, length etc. of it. Movement and rotation, as you can see, is limited by the spikes in lattice points. Below is an example of one of possible moves. My question: is it possible to make this line segment parallel to Y-axis? I do believe that Chinese Remainder Theorem has something to do with this.","['number-theory', 'geometry']"
2159702,"Let $K$ be a normal subgroup of $G$, and $H$ a normal subgroup of $K$. If $G/H$ is abelian, prove that $G/K$ and $K/H$ are both abelian.","I think this is not a duplicate Let $K$ be a normal subgroup of $G$, and $H$ a normal subgroup of $K$. If $G/H$ is abelian, prove that $G/K$ and $K/H$ are both abelian. My attempt is to set $f:G/H\to G/K$ given by $f(Hx)=Kx$ for every $x\in G$, so $f(Hx\cdot Hy)=f(H(xy))=K(xy)=Kx\cdot Ky=f(Hx)\cdot f(Hy)$, so $f$ is a homomorphism and $G/K$ is abelian (since homomorphisms preserve conmutativity) Now $G/H$ is abelian so $H(xy)=H(yx)$ for every $x,y\in G$, but every $x,y\in K$ are also in $G$, so $K/H$ is abelian Is the proof right? I don´t see any mistakes but I´ve never seen/thought there could be a homomorphism between two different quotient groups","['abstract-algebra', 'group-homomorphism', 'normal-subgroups', 'abelian-groups', 'group-theory']"
2159714,Justification for indefinite integration by substitution,"I know that if we want to compute a definite integral using substitution, we use $$\int_{a}^b f(\phi(t))\phi '(t)~dt = \int_{\phi(a)}^{\phi(b)}f(x)~dx\tag1$$ I know that this method can go from left to right or right to left. If we want to compute an indefinite integral using substitution, we use $$\int f(t)~dt = \int g(\phi(t))\phi '(t)~dt = G(\phi(t)) + C, \tag{2}$$ where $G$ is an antiderivative of $g$ and $C$ is the constant of integration. For example, for evaluating functions like $\dfrac{1}{\sqrt{4 - x^2}}$ we can make the substitution $x = 2\sin \theta$ and find $dx$ in terms of $d\theta$ . Substituting its value in the integral, it becomes computable. However, pretending that $\dfrac{dx}{d\theta}$ is a fraction and substituting the value of $dx$ in the integral just because it ""works"" is not very rigorous. Is there a rigorous statement for computing indefinite integrals that can't be expressed in the aforementioned form using substitution, just like we have for definite integrals, or can they be computed using $(2)$ in a way that I can't figure out?","['real-analysis', 'substitution', 'calculus', 'indefinite-integrals', 'integration']"
2159720,Evaluate: $\int_{0}^{\pi}\frac{\cos 2017x}{5-4\cos x}dx$,Evaluate: $\int\limits_{0}^{\pi}\dfrac{\cos 2017x}{5-4\cos x}~dx$ I thought of using some series but could not get it,"['integration', 'definite-integrals', 'calculus']"
2159846,Please help me with this combination problem,"Prove that $\sum\limits_{k = 0}^n k{m \choose k}{n \choose k}= n{m+n-1 \choose n}$ We can write ${m \choose k} = m!/(m-k)!(k)!$
similarly  ${n \choose k}$ and ${m+n-1 \choose n}$ can also be written but I am confused how to proceed further.","['combinations', 'combinatorics']"
2159872,fine the limit : $\lim_{ n \to \infty }\frac{1}{n}\int_{0}^{n}{ \frac{x\ln(1+\frac{x}{n})}{1+x}}=?$,"fine the limit : $$\lim_{ n \to \infty }\frac{1}{n}\int_{0}^{n}{ \frac{x\ln(1+\frac{x}{n})}{1+x}}=?$$ My Try:
in the http://www.integral-calculator.com $$I=\int_{}^{}{ \frac{x\ln(1+\frac{x}{n})}{1+x}}=\left(x+n\right)\ln\left(\left|x+n\right|\right)+\left(\ln\left(n\right)-\ln\left(n-1\right)\right)\ln\left(\left|x+1\right|\right)+\operatorname{Li}_2\left(-\dfrac{x+1}{n-1}\right)+\left(-\ln\left(n\right)-1\right)+c$$ now?",['limits']
2159915,How many initial conditions are required?,"Consider the following system of ODE: $$\begin{array}{ll}\ddot y + y + \ddot x + x = 0 \\
y+\dot x - x = 0 \end{array}$$ Question : How many initial conditions are required to determine a unique solution? A naive reasoning leads to four: $y(0),\dot y(0), x(0)$ and $\dot x(0)$. However, if we write the system in a first-order form: $$\begin{bmatrix} 1  & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 \\ 1 & 0 & 0 & 0 \end{bmatrix} \begin{bmatrix} \dot x \\ \ddot x \\ \dot y \\ \ddot y\end{bmatrix} = 
\begin{bmatrix} 0 & 1 & 0 & 0 \\ -1 & 0 & -1 & 0 \\ 0 & 0  & 0 & 1\\ 1 & 0 & -1 & 0 \end{bmatrix}\begin{bmatrix} x  \\ \dot x \\ y \\ \dot y\end{bmatrix}$$ the left matrix is not of full rank, which means the equations are not all independent. 
Indeed, by differentiating the second equation: $\dot y + \ddot x -\dot x=0$ which leads to $\ddot y + y + \dot x - \dot y + x =0$, or, in the first-order form:
$$ \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 1 & 0 & 1 \end{bmatrix}
\begin{bmatrix} \dot x \\ \dot y \\ \ddot y \end{bmatrix} = \begin{bmatrix} 1 & -1 & 0 \\ 0 & 0 & 1 \\ -1 & -1 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ \dot y \end{bmatrix}$$ With the above form, it shows only three initial conditions are required: $x(0),y(0),\dot y(0)$. And, what if I had: $$\begin{array}{ll}\ddot y + y + x^{(n)} + x = 0 \\
\dot x - x = 0 \end{array}$$ for some $n$. Then, I could solve the second equation for some $x(0)$, then differentiate $x$ $n$ times and inject in the first equation, so only $x(0), y(0), \dot y(0)$ are needed. Can this be seen directly, in a robust manner?","['ordinary-differential-equations', 'initial-value-problems']"
2159949,"For finite groups $G$ of order invertible in $R$, is taking $G$-invariants an exact functor on the category of $R[G]$-modules?","Let $G$ be a finite group of order $n$, and $R$ a ring on which $n$ is invertible. Is taking $G$-invariants an exact functor on the category of $R[G]$-modules?","['algebraic-geometry', 'finite-groups', 'abstract-algebra', 'commutative-algebra', 'group-theory']"
2159952,Finding a limit - is my argument correct?,"The limit is:
$$ \lim_{\lambda\to 0} \frac{\int_{\lambda}^{a}{\frac{\cos(x)}{x}dx}}{\ln\lambda}. $$ My argument is: First rewrite the integral:
$$ \lim_{\lambda\to 0} \frac{\int_{0}^{a}{\frac{\cos(x)}{x}dx} - \int_{0}^{\lambda}{\frac{\cos(x)}{x}dx}}{\ln\lambda}. $$ Then use l'Hopital's rule. The first term on the top vanishes as it has not $\lambda$ dependence. The second term is found by applying fundamental theorem of calculus. So I get: $$ \lim_{\lambda\to 0} \frac{-{\frac{\cos(\lambda)}{\lambda}dx}}{\frac{1}{\lambda}} = \lim_{\lambda\to 0}{-\cos(\lambda)} = -1. $$ Are there any problems with my argument?","['real-analysis', 'calculus', 'limits']"
2159963,Find the value of $\arctan(1/3)$,How can I calculate $\arctan\left({1\over 3}\right)$ in terms of $\pi$ ? I know that $\tan^2(\frac{\pi}{6})= {1\over3}$ but don't know if that helps in any way.,['trigonometry']
2159972,computing the fundamental domain for $\Gamma_0(4) \backslash \mathbb{H}$,"how do I compute the fundmental domain for a congruence subgroup of $SL(2, \mathbb{Z})$ This region is important because the theta function $\theta(z) = q^{n^2}$ is invariant under two transformations $z \mapsto z + 1$ and $z \to - \frac{1}{4z}$, and these two generate the congruence subgroup  $\Gamma_0(4)$. I know there is an algorithm for any Fuchsian group. Here is an erroneous comutation of the fundamental domain.  It has too many cusps. I found a blog with a picture of what could be the fundamental domain of $\Gamma_0(2)$.  Therefore the domain for $\Gamma_0(4)$ could be related.  I know that $[SL(2,\mathbb{Z}): \Gamma_0(2)]= 3$ and $[SL(2,\mathbb{Z}): \Gamma_0(4)]= 6$ but I can't figure out which two copies to join.  And ther's no derivation for this particular case.","['automorphic-forms', 'hyperbolic-geometry', 'group-theory', 'group-presentation']"
2159976,Prove by induction that $1+3+3^2+3^3+...+3^n=\frac{1}{2}(3^{n+1}-1)$ [duplicate],"This question already has answers here : Simplifying a geometric sum (2 answers) Why does the geometric series formula intuitively work? (5 answers) Closed 7 years ago . I have $\frac{1}{2}(3^{k+1}-1)+3^{k+1}=\frac{1}{2}3^{k+2}-1$ Not sure where to go from here. First post on Mathematics, please correct me if I did anything wrong.","['induction', 'summation', 'discrete-mathematics']"
2160022,Limit of $n$th root of $n$!,I am asked to determine if a series converges or not: $$\displaystyle\sum\limits_{n=1}^{\infty} \frac{(2^n)n!}{(n^n)}$$ So I'm using the $n$ th root test and came up with $\lim_{n \to {\infty}}\frac{2}{n}\times(\sqrt[n]{n!})$ I know that the limit of $\frac{2}{n}$ goes to $0$ when $n$ goes to infinity but what about the $(\sqrt[n]{n!})$ ?,"['radicals', 'factorial', 'sequences-and-series', 'limits']"
2160027,What will happen to the roots of $ax^2 + bx + c = 0$ if the $a \to 0$?,"Exercise: What will happen to the roots of the quadratic equation
  $$ax^2 + bx + c = 0$$
  if the coefficient $a$ approaches zero while the coefficients $b$ and $c$ are constant, and $b \neq 0$? Attempt: $\lim\limits_{a \to 0}{(ax^2 + bx + c)} = bx + c = 0 \longrightarrow x = -\frac{c}{b}$ However, I don't think my solution is complete; shouldn't I end up with $2$ roots? (I've only found $1$.) Request: Is there indeed another root to find? If so, how to I find it?","['real-analysis', 'limits', 'roots', 'calculus', 'quadratics']"
2160062,Is $\mathbb{S}^2$ self-similar?,"A topological space $X$ is self-similar if there is a proper subspace $Y \subsetneq X$ such that $Y \cong X$ (homeomorphic). Is $\mathbb{S}^2$ self-similar? I guess no, but, how can I prove this?","['algebraic-topology', 'general-topology']"
2160072,"Show that $x$ is within the unit disk if $\overline{x} + xz_1z_2 = z_1 + z_2$ and $|z_1|,|z_2| < 1$.","Let $x \in \mathbb{C}$. Denote the complex conjugate of $x$ as $\overline{x}$. Fix $z_1, z_2 \in \mathbb{C}$ such that $|z_1| < 1$ and $|z_2| <1$. 
The following equation is satisfied:
$$\overline{x} + xz_1z_2 = z_1 + z_2$$ I want to show that $|x| < 1$. I tried a whole bunch of numerics and this seems to be true, but I have difficulty proving it. Any suggestions would be appreciated!",['complex-analysis']
2160156,"The group $SO(1,1)$: this matrix is a generator?","The question is: Show that the matrices 
  \begin{pmatrix}
\cosh \theta & \sinh \theta\\
\sinh \theta & \cosh \theta
\end{pmatrix} leave invariant the real quadratic form $x_1^2-x_2^2$ and constitute the group $SO(1,1).$ I did the invariance part as follows :
$$ x_1^\prime =x_1 \cosh \theta+ x_2\sinh \theta,  \ \ \ x_2\prime =x_1\sinh \theta+x_2\cosh \theta $$
which gives $$(x_1^\prime) ^2- (x_2^\prime) ^2 = x_1^2-x_2^2.$$
But I don't know how to show that this transformation will give the group $SO(1,1).$","['group-theory', 'lie-algebras', 'lie-groups']"
2160181,Canonical symplectic form on cotangent bundle of complex manifold,"Given any smooth manifold $M$, its cotangent bundle $T^*M$ is a symplectic manifold, with the canonical symplectic form . If $M$ is a complex manifold then $T^*M$ is also a complex manifold . Thus, $T^*M$ is a complex symplectic manifold. Does it follow that the canonical symplectic form is holomorphic? If not, what condition can be placed on $M$ so that it is? For example this question on Overflow says that if $M$ is Kahler then the symplectic form is holomorphic.","['complex-geometry', 'differential-geometry', 'symplectic-geometry']"
2160198,Prove $\sqrt{5} \leq 3$,"I was just thinking about how to prove  $\sqrt{5} \leq 3$. I believe I can prove by contradiction by saying suppose  $\sqrt{5} > 3$, then it must be true also that $5 > 9$ by squaring both sides, but this is absurd so it must be that  $\sqrt{5} \leq 3$. However, I was thinking that this doesn't seem valid since we can suppose $\sqrt{5} > -3$ then squaring both sides gives $5 > 9$, which is also absurd! By we know  $\sqrt{5} > -3$, so is something I'm doing not valid? I know this is a simple thing, but I was just trying to prove an irrational number is less than a certain rational number and am stumped.","['real-analysis', 'inequality']"
2160246,The derivative of $x^0$,"For some reason I have not been able to find a straight answer to this. We know that $\frac{d}{dx}x^n=nx^{n-1}$ And this is true for $n=-1$ and $n=1$ $\implies$ $\frac{d}{dx}x^{-1}=-1x^{-2}$ and $\frac{d}{dx}x^1=1$ We also know that $\frac{d}{dx}C=0$ where $C$ is a constant. Suppose that $f(x)=x^0$. Obviously any number to the power of zero is $1$, i.e. $x^0=1$, and $\frac{d}{dx}1=0$, but $x$ is not a constant. So, $$\frac{d}{dx}x^0=x^{-1}$$
Is this true? My thought is possibly. Based on the fact that if $\frac{d}{dx}x^1=1$ and obviously any value to the power of one is equal to that value. I.e. $x^1$ simplifies to be $C$ a constant but $\frac{d}{dx}x^1\not=0$, and we know that $\frac{d}{dx}C=0$. So is it true that $f'(x)=x^{-1}$? Hopefully this is not way more simple than I am making it. UPDATE: I obviously made an error by saying that $\frac{d}{dx}x^0=x^{-1}$ It actually would evaluate directly as $0\times x^{-1}$","['derivatives', 'calculus']"
2160289,How do I prove this identity on $n!-1$?,"Set $n \ge 1$. Prove that $$n!-1 = \sum_{X \in \{1,2,...,n-1\}^P} \prod_{y \in X} y.$$ I found this one while studying my combinatorics lecture notes. Intuitively, $n!-1=(1+1)\cdot(2+1)\cdots(n-1+1)-1$. Expand and it looks like the resulting sum of products. I tried to prove this identity using induction but it somehow got very complicated. Remark: $P=$ powerset.","['combinatorics', 'discrete-mathematics']"
2160300,lists/sets question (about specific notation),"I have a question in my textbook that asks you to evaluate each statement as true or false, but I'm having trouble understanding the notation they're using. $(1,2,3) \in \mathbb{Z}^5$ What does it mean when the set of integers is raised to the power of $5$? Also, what would the P($\mathbb{Z}^5$) mean?","['elementary-set-theory', 'discrete-mathematics']"
2160301,Roots of a canonical line bundle on a compact Riemann surface,"Suppose we have a compact Riemann surface $X$ of genus $g$.  Let $K$ denote the canonical line bundle on $X$, it's well known that $deg\ K=2g-2$.  A square root of $K$ by definition is a  holomorphic line $L$ bundle that satisfies $L\otimes L=K$. Then are $2^{2g}$ different square roots, e.g. see this link . Now suppose $m$ is an integer such that $m$ divides $deg\ K=2g-2$. Let's call a holomorphic line bundle $L$ for which $L^{\otimes m}=K$, an $m$-root of $K$. Is true in general that they are $m^{2g}$ different holomorphic  $m$-roots?","['riemann-surfaces', 'fiber-bundles', 'algebraic-geometry', 'holomorphic-bundles']"
2160306,Multiplicative Inverse Question,"What is the multiplicative inverse of $9\pmod{37}$?
I've done the Euclidean algorithm and found the gcd is $1$. I'm stuck on using the extended Euclidean algorithm. I'm confused because I'm left with $$37=(9\times 4)+1$$ and can't substitute it anywhere.","['number-theory', 'modular-arithmetic']"
2160353,Proof by contradiction: There are infinitely many primes,"I need some help with a proof. I just need to be pointed in the right direction, because I've been looking at this for ages and it's not clicking. I need to prove that there are infinitely many prime numbers, by contradiction. The original statement is: For all $n$ in $\mathbb{N}$ where $n > 2$, there exists a $p$ in $\mathbb{P}$[prime] such that $n < p < n!$. We were given the hint that we're supposed to use cases to solve this. Case one is that $n!-1$ is prime, whereby obviously the statement holds. case two is that $n!-1$ is composite, which is somehow also supposed to prove the statement, and I don't understand how. I know that every natural number $> 1$ has at least one prime factor, but I don't understand how we know that that prime factor is greater than n. I also don't really understand how to do these cases using contradiction. Maybe I wrote the contradiction wrong, but I thought it came out to : For all $p$ in $P$, there exists an $n$ in $\mathbb{N}$ where $n > 2 $, such that $n \le  p \le n!$. But maybe I did that wrong? Can anyone give me a pointer on how to tie this together or where to start? I'd really appreciate it, thank you.","['number-theory', 'proof-writing', 'logic', 'prime-numbers', 'discrete-mathematics']"
2160375,A challenging limit,"In my attempt to understand fractal dimensions, I tried calculating the Minkowski dimension of some basic non-fractal spaces and ran into a limit I can't seem to conquer. For $n>2$, $\lim_{x\to 0^+}\frac{n \left((1-x)^n+x-1\right)}{(1-x) \left((1-x)^n-(-x)^n-1\right)}$ I evaluated the limit in Mathematica and got $n-1$, which is exactly what it should be (the boundary of the $n$-sphere is indeed $n-1$ dimensional), but I'd appreciate a more human solution.","['real-analysis', 'calculus', 'limits']"
2160381,Matrix derivative w.r.t time $\frac{d}{dt}\|A-X(t)\|^2=2\operatorname{tr}\big((X-A)\dot{X}\big)$,"My question is just how to derive this equality? $$\frac{d}{dt}\|A-X(t)\|^2=2\operatorname{tr}\big((X-A)\dot{X}\big)$$ where $A, X\in \mathbb{R}^{n\times n}$ In particular, how to obtain the matrices trace product term? It seems there are three levels chain rule, one for square, one for norm and then $X(t)$ I just know the following:    $$\nabla_x \|Ax-b\|^2=2A^T(Ax-b)$$","['matrices', 'chain-rule', 'derivatives']"
2160390,Where to Find a Matrix Representation of the Monster Group,"On the site for the Atlas of Finite Simple Groups, Robert Wilson posts that the Monster group has a computer representation over GF(2) which is calculable only with special programs (I assume he means GAP, Sage, etc.).  However, I haven't seen any links for the actual 196882 order matrix representation anywhere.  Does anyone know where one might find this data?","['representation-theory', 'computer-algebra-systems', 'group-theory']"
2160405,Proving the sum of two Lebesgue measurable functions is measurable,"I am reading the fourth edition of Real Analysis by Royden. The book provides the following proof that if $f$ and $g$ are measurable functions, then $f+g$ is measurable. For $x \in E$ if $f(x)+g(x) < c$, then $f(x) < c - g(x)$. By the density of the rational numbers, there exists $q \in \mathbb{Q}$ such that $f(x) < q < c - g(x)$. Hence, $\{x \in E : f(x) + g(x)< c\} = \displaystyle\bigcup_{q \in \mathbb{Q}} [ \{x \in E: g(x)<c-q\}\cap\{x \in E: f(x)<q\}]$. Then the fact that the measurable sets are a sigma algebra gives us the result. My only confusion is the statement that$\{x \in E : f(x) + g(x)< c\} = \displaystyle\bigcup_{q \in \mathbb{Q}} [ \{x \in E: g(x)<c-q\}\cap\{x \in E: f(x)<q\}]$. I'm having trouble seeing why this is true.","['real-analysis', 'measure-theory']"
2160438,What should be the value of a for it to be a singular matrix,"for what value of a, $\begin{bmatrix}2a & -1\\-8 & 3\end{bmatrix}$ is a singular matrix. Can you also explain to me how to prove that a matrix is a singular matrix?",['matrices']
2160443,Is there a flaw in the theory of fractional calculus?,"Let's talk about the function $f(x)=x^n$. It's derivative of $k^{th}$ order can be expressed by the formula:
$$\frac{d^k}{dx^k}x^n=\frac{n!}{(n-k)!}x^{n-k}$$
Similarly, the $k^{th}$ integral (integral operator applied $k$ times) can be expressed as:
$$\frac{n!}{(n+k)!}x^{n+k}$$
According the the Wikipedia article https://en.wikipedia.org/wiki/Fractional_calculus , we can replace the factorial with the Gamma function to get derivatives of fractional order. So, applying the derivative of half order twice to $\frac{x^{n+1}}{n+1}+C$, should get us to $x^n$. Applying the half-ordered derivative once gives:
$$\frac{d^{1/2}}{{dx^{1/2}}}\left(\frac{x^{n+1}}{n+1}+Cx^0\right)=\frac{1}{n+1}\frac{\Pi(n+1)}{\Pi(n+1/2)}x^{n+1/2}+C\frac{1}{\Pi(-1/2)}x^{-1/2}$$
where $\Pi(x)$ is the generalization of the factorial function, and $\Pi(x)=\Gamma(1+x)$ Again, applying the half-ordered derivative gives:
$$\frac{1}{n+1}\frac{\Pi(n+1)}{\Pi(n)}x^n+\frac{C}{\Pi(-1)}x^{-1}=x^n$$
which works fine because $\frac{C}{\Pi(-1)}\rightarrow 0$. So, the derivative works good but that's not the case with fractional-ordered integration. Applying the half-ordered integral operator twice to $x^n$ should give us $\frac{x^{n+1}}{n+1}+C$. Applying the half-ordered integral once means finding a function whose half-ordered derivative is $x^n$. So, applying it once gives:
$$\frac{\Pi(n)}{\Pi{(n+1/2)}}x^{n+1/2}+C\frac{1}{\Pi(-1/2)}x^{-1/2}$$ Again, applying the half ordered derivative to this function should give a function whose half-ordered derivative is this function. So, again applying the half-integral operator gives:
$$\frac{x^{n+1}}{n+1}+C+C'\frac{1}{\Pi(-1/2)}x^{-1/2}\neq \frac{x^{n+1}}{n+1}+C$$
where $C'$ is another constant. So, why does this additional term containing $C'$ get introduced? Is the theory of fractional derivatives flawed? Is there any way to get a single constant $C$ in the end by applying the half-integral operator two times?","['derivatives', 'calculus', 'fractional-calculus', 'integration', 'gamma-function']"
2160475,Improper integral of natural log over a quadratic,"I need to evaluate 
$$\int\limits_0^{+\infty}\frac{\ln{x}}{x^2+x+1}\,\mathrm{d}x\,.$$ I don't know how to integrate this, and for the most part, I don't even think it is expressible as elementary functions. In that case, how would I even manipulate the integral using some $u$-substitution to transform this into some integrable function? Or can this all be done without actual integration , and just some clever substitution to somehow find a multiple of this integral's value?","['improper-integrals', 'integration']"
2160487,Prove whether the function is differentiable about a given interval.,"So It's obvious that the given function is continuous between -1 to 0 and 0 to 1, hence the only point left to test is whether the function is continuous at 0 and so I took the limit of x->0+ to be equal to the limit of x->0- and computed the value of a to be 0. As for the second part of the question, I substituted the value of a as 0 and then used the formula of differentiation ie lim(h-->0)  (f(x+h)-f(0))/h and I got the value of -1 for the left hand limit and -4 for the right hand limit. Does that conclude the function is not differentiable, for the value of a when it is continuous?","['derivatives', 'continuity', 'calculus']"
2160489,What does it mean intuitively for a metric and connection to be compatible?,"In General relativity, the metric tensor that satisfies Einstein's equations induces the Levi-Civita connection of that metric. It is said that this connection is somehow ""compatible"" with the metric. Technically Im told this means that straight lines (according to the connection) coincide with geodesics (according to the metric). However, this seems like an arbitrarily restrictive assumption from a mathematical point of view. Shouldn't it be possible for a single specific metric manifold with connection to have straight lines that are not necessarily geodesics? Why not? So my main question is: what does this notion of ""compatibility"" of metric and connection really mean intuitively? Does it mean there cannot exist a metric manifold with connection whose metric and connection are incompatible? (I.e. is it a necessary condition?). Why is the intuitiv enotion of ""compatibilty"" captured formally by the ""straight lines = geodesics"" criterium?","['intuition', 'riemannian-geometry', 'general-relativity', 'differential-geometry', 'connections']"
2160498,Computing the integral $\int \limits_{1}^{\infty}\left(\frac{1}{\lfloor{x}\rfloor}-\frac{1}{x}\right)$ ....,"Prove that $$\large\int \limits_{1}^{\infty}\Bigg(\dfrac{1}{\lfloor{x}\rfloor}-\dfrac{1}{x}\Bigg)dx=\lim \limits_{n \to \infty} \Bigg(-\ln(n) + \sum \limits_{k=1}^n\dfrac{1}{k}\Bigg)$$ I was reading an article on Euler–Mascheroni constant$\Big(\gamma\approx0.577215664901532\Big)$, when I read that it is defined as the limiting difference between the harmonic series and the natural logarithm : $$\gamma=\lim \limits_{n \to \infty} \Bigg(-\ln(n) + \sum \limits_{k=1}^n\dfrac{1}{k}\Bigg)$$ That is completely fine, but in the next ""step"" this limit is equated to a definite integral of reciprocal of $x$ subtracted from the reciprocal of floor of $x$. It can not really understand this transition from limit to a definite integral. Also, I could not find even a single proof of this equivalence anywhere. A geometrical explanation (or even an algebraic one) will surely help me understand this. Thanks in Advance ! :-)","['limits', 'euler-mascheroni-constant', 'definite-integrals', 'harmonic-numbers', 'ceiling-and-floor-functions']"
2160518,$p$ is a prime greater than 3. If $d\mid\frac{2^p+1}{3}$ then $p\mid d-1$,"$p$ is a prime greater than 3. If $d \mid  \dfrac{2^p+1}{3}$ . Prove that $p \mid d-1$ .
I have no clue how to solve this",['number-theory']
2160538,What is the exact value of $\frac{1}{\tan20^{\circ}}-\frac{1}{\sin80^{\circ}}$?,"What is the exact value of $$\frac{1}{\tan20^{\circ}}-\frac{1}{\color{red}\sin80^{\circ}}?$$ By putting the above into a calculator, I get $\sqrt{3}$ , but I cannot seem to be able to do it algebraically.","['algebra-precalculus', 'trigonometry', 'fractions']"
2160560,finding $ \int^{\infty}_{0}\frac{\ln x}{x^2+6x+9}dx$,"finding $\displaystyle \int^{\infty}_{0}\frac{\ln x}{x^2+6x+9}dx$ Attempt: let $\displaystyle I(a) = \int^{\infty}_{0}\frac{\ln (ax)}{(x+3)^2}dx, a>0$ $\displaystyle I'(a) = \int^{\infty}_{0}\frac{x}{ax(x+3)^2}dx = \frac{1}{a}\int^{\infty}_{0}\frac{1}{(x+3)^2}dx = -\frac{1}{a}\bigg(\frac{1}{x+3}\bigg)\bigg|_{0}^{\infty} = \frac{1}{3a}$ so $\displaystyle I(a) = \frac{\ln(a)}{3}+C$ could some help me how  to solve from there, thanks in advanced",['integration']
2160605,Is any extension of DVRs smooth?,Actually I was thinking of a finite (possibly ramified) extension $K$ of $\mathbb Q_p$ and the rings of integers $\mathbb Z_p$ an $O_K$. Is $\text{Spec } O_K \to \text{Spec }\mathbb Z_p $ smooth?,"['abstract-algebra', 'ring-theory', 'algebraic-geometry']"
2160610,"Tangent space of smooth manifold of ""matrices with same rank""","Define $$M(n,M\times N)=\{X\in \mathbb{R}^{M\times N} \mid \operatorname{rank} X = n\}$$ 
We know: $M(n,M\times N)$ is a smooth and connected manifold. The tangent space of $M(n,M\times N)$ at an element $X$ is 
$$T_X M(n,M\times N) = \{AX + XB \mid A\in \mathbb{R}^{M\times M}, B\in \mathbb{R}^{N\times N}\}$$ My question is the following lemma: Does the green part means $$A(t)X(t) + X(t)B(t)$$ is of rank $n$? If yes, why? I cannot follow this.","['matrices', 'smooth-manifolds', 'matrix-rank', 'ordinary-differential-equations', 'differential-geometry']"
2160623,Why do we need to divide?,"What is the difference between ""divide"" (÷) and ""upon"" (/), if any what is the role they play in maths and physics?
I want to know  why we perform this operation in mathematics.","['experimental-mathematics', 'mathematical-physics', 'discrete-mathematics']"
2160650,Determinant of a matrix that is almost lower triangular,"Calculate the determinant of $$ \left[
\begin{array}{cccc}
1 & 0 & 0 & 0  & \cdots & 1\\
1 & a_1 & 0 & 0  &  \cdots & 0 \\
1 & 1 & a_2 & 0  &  \cdots & 0 \\
1 & 0 & 1 & a_3  &  \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots  \\ 
1 & 0 & 0  & \cdots& 1 & a_{n-1} \\
\end{array}
\right]$$ I tried to develop at the first line, but got stuck. Any helps or hints appreciated.","['matrices', 'determinant']"
2160659,What is a conservative field?,"My understanding of the conservative field is that it is any vector field that satisfies any of these three equivalent conditions:
$$\oint_C\vec{F}.d\vec{s}=0$$for any closed path $C$ in the domain,$$\vec{F}=\vec{\nabla}\phi$$for some scalar field $\phi$ defined over the domain, and$$\vec{\nabla}\times\vec{F}=\vec{0}$$ at every point in the domain. However, our teacher told us today that a conservative field and a field derived from a potential are not the same thing. In my research on the issue I found this wolfram page that states that the last condition is not equivalent to the others if the domain $D$ is not simply connected. Can anyone provide me with an example on the case ? And in this case, what becomes the definition of a conservative field ?","['multivariable-calculus', 'vector-analysis']"
2160675,Why is $ \cos^{n+1}(x) - n\sin^2(x)\cos^{n-1}(x)$ equal to $\cos^{n-1}(x)((n+1)\cos^2(x) -n)$,"In reading a correction for an exercice, I stumbled on a strange equality. Suppose $x \in [0, \pi]$, let $f_n(x)= \cos^n(x)\sin(x)$, then the derivative is equal to: $$ \cos^{n+1}(x) - n\sin^2(x)\cos^{n-1}(x)=\cos^{n-1}(x)\left[(n+1)\cos^2(x) -n\right]$$ Could someone explain to me, how is the right part of the equation found?","['real-analysis', 'trigonometry']"
2160689,Evaluate $\lim_{t\to0}\frac{-(t-2)(\sin t +1)-(t+2)\cos t}{(\sin t + \cos t - 1)t^2}$ without L'hopital,"Question: Let
  \begin{align}
&S(t):=\int_{\pi/4}^t (\sin t-\sin\left(\frac\pi4\right))dt\\
&T(t):=\frac{\left(\sin t-\sin\left(\frac\pi4\right)\right)\left(t-\frac\pi4\right)}2\\
\end{align}
  Using $$\lim_{t\to0}\frac{\tan t - t}{t^3}=\frac13\tag1$$
  Evaluate the following (without L'hopital)
  \begin{align}
&\quad\lim_{t\to\frac\pi4}\frac{S(t)-T(t)}{T(t)\left(t-\frac\pi4\right)}
\end{align} What I've done so far is:
$$\lim_{t\to\frac\pi4}\frac{S(t)-T(t)}{T(t)\left(t-\frac\pi4\right)}=\lim_{t\to0}\frac{-\cos\left(t+\frac\pi4\right)+\frac{\sqrt2}2-\left(\sin\left(t+\frac\pi4\right)+\frac{\sqrt2}2\right)\frac t2}{\left(\sin\left(t+\frac\pi4\right)-\frac{\sqrt2}2\right)\frac {t^2}2}$$
$$=\lim_{t\to0}\frac{-(t-2)(\sin t +1)-(t+2)\cos t}{(\sin t + \cos t - 1)t^2}$$
But I don't know how to go from here to the Eq.$(1)$.
Thanks.","['limits-without-lhopital', 'calculus', 'limits']"
2160766,How many resistors are needed?,"I was told about the following problem. Suppose you have infinite number of resistors with only value 1 $\Omega$ . Question is What minimal number of 1 $\Omega$ -resistors is needed to construct given fraction resistance $R$ , i.e. $R\in \mathbb{Q}_+$ . Note that you can connect two resistors ( $R_1$ and $R_2$ ) in two ways: parallel and series. The resulting resistance ( $R_p$ and $R_s$ respectively) in those cases are: $$R_s = R_1 + R_2$$ $$R_p = R_1 \oplus R_2 = \frac{1}{\frac{1}{R_1}+\frac{1}{R_2}},$$ where we introduced $\oplus$ -operation in order to simplify notes. NOTE: only schemes which are able to be written in the form: $$(... 1 + (1\oplus 1) ... )$$ are allowed. For example, this is not allowed: If you know how to formulate this rule better, please, say. For example, you can use the Euclidean algorithm. $$\frac56 = \frac{1}{\frac65}=\frac{1}{1+\frac15} = 1 \oplus 5,$$ so you needed 6 resistors because $$5 = \sum_{k=1}^{5}1$$ But it was not the minimum number of resistors because, for example, $$\frac56 = \frac12 + \frac13 = (1\oplus 1)+(1\oplus 1\oplus 1),$$ where it is enough to use only 5 resistors. I think that Euclidean algorithm often solves the problem. More over, it is needed to consider only one ""half of $\mathbb{Q}_+$ "", for the other half it is enough to replace +'s by $\oplus$ 's and vice-versa. The one who told me about this problem adhered to the following notations. $$[1,1]\quad \text{for}\quad 1\oplus 1.$$ $$(1,1)\quad \text{for}\quad 1 + 1,$$ so our previous example looks like $$[1,(1,1,1,1,1)]\quad \text{and}\quad ([1,1,1],[1,1]).$$","['algebra-precalculus', 'number-theory']"
2160779,Schemes as closed subschemes in étale schemes,"The Nagata compactification theorem asserts that every scheme, separated and of finite type over a Noetherian base scheme $S$, admits an open immersion into a proper $S$-scheme. It would be useful for me if (what I think of as somehow the dual holds, that is if) every scheme, unramified and of finite presentation over a reasonable base $S$, admits a closed immersion into an étale $S$-scheme. Is such a statement known to be true, false, or open? Well, it is trivially true when $S$ is a field, I wonder if things change when $S$ is taken to be an arbitrary Noetherian scheme. Does the statement hold without assuming unramification, if we only ask for a closed immersion into a smooth $S$-scheme? PS Apologies if this is widely known for algebraic geometers, I am not one, yet.","['schemes', 'reference-request', 'algebraic-geometry']"
2160799,Is there any way to Integrate this function?,"After 2 change of variables, and a $x = \log(u)$ transformation, I have this integral... $$\int_0^{\infty } \frac{\alpha  e^x}{\lambda-e^x \lambda+e^{\alpha  x}} \, dx$$ What are some recommendations on how to integrate this? NOTE: The original integral looked like: $$\int_{1 }^{\infty } \frac{\alpha  \left(\frac{1 }{x}\right)^{\alpha }}{1-\lambda (x-1 ) \left(\frac{1 }{x}\right)^{\alpha }} \, dx$$ and for the integral to converge $\alpha > 1$. Finally, when $\alpha = 2$, I did get this expression... $$\frac{8 \tan ^{-1}\left(\frac{\sqrt{\lambda }}{\sqrt{4-\lambda }}\right)}{\sqrt{(4-\lambda ) \lambda }}$$ Thanks,","['integration', 'calculus']"
2160821,Measurability of stopping times,"If $\tau$, $\rho$ are stopping times, then it is easily seen that $\tau+\rho$ is also a stopping time. However $\tau-\rho$ and $\tau\rho$ are not necessarily stopping times as it requires a ""peak into the future"", but I am not sure why this is so and would appreciate any feedback to facilitate my understanding. For the difference case, I think it not as if $(X,\mathscr{F})$ is a measurable space and 
$f, \space g \space :(X,\mathscr{F})\rightarrow([0,\infty),\mathscr{B}([0,\infty))$ are measurable maps then if for some $x\in X$, $f(x)-g(x)<0$ then I say it does not make sense that $f-g$ is measurable as it maps some elements outside of $[0,\infty)$, and $(f-g)^{-1}(\mathscr{B}([0,\infty)))$ is not a sub $\sigma$-algebra of $\mathscr{F}$.  Is my reasoning correct? So in the case of stooping time, $\tau$ we have the added requirement that $1_{\{\tau\leq t\}}$ be adapted to the given filtration. So my question is why does the difference of stopping times require a ""peak into the future""? I have the same qualms about the product case. However in the case of the reciprocal, I think I see why, as if we take $t=1/2$, then $\{1/\tau\leq2\}=\{\tau\geq2\}\in\mathscr{F}_2$ and we have no way on knowing if the event is in $\mathscr{F}_{1/2}$ So any comments and answers would be really appreciated.","['probability-theory', 'stopping-times']"
2160883,If the Gateaux derivative is not linear does this mean the Frechet derivative doesn't exist?,It seems to be true as if the frechet exists then it is the same as the gateaux which would then be nonlinear (contradiction) but this seems useful yet I can't really find it anywhere and the lecturer hasn't mentioned it. Thanks.,"['derivatives', 'real-analysis']"
2160889,The (countable) sum of proper processes is a proper process,"I am working with the script of Günter Last and Mathew Penrose Lectures on the Poisson Process (available online). Definition 2.4 We shall refer to a point process $\eta$ on $\mathbb{X}$ as a proper point if there exist random variables $X_1, X_2, \dots$ in $\mathbb{X}$ and a $\overline{\mathbb{N}_0}$-valued random variable $\kappa$ such that almost surely $$\eta = \sum_{n=1}^\kappa \delta_{X_n} $$ At the end of the section is struggle with Exercise 2.4: Let $\eta_1, \eta_2, \dots$ be a sequence of proper point processes. Show that $\eta:= \eta_1 + \eta_2 + \dots$ is a proper point process My approach: My main problem is that I can't exactly reproduce the Definition 2.4, evidently I have for every $i \in \overline{\mathbb{N}}$ that $$\eta_i = \sum_{n=1}^{\kappa_i} \delta_{X_{n,i}} $$
Where the $\kappa_i$ are $\overline{\mathbb{N}_0}$-valued RV and the $X_{n,i}$ are the random variables for every $i \in \overline{\mathbb{N}}$, therefore $$ \eta = \sum_{i=1}^\infty \eta_i= \sum_{i=1}^\infty\sum_{n=1}^{\kappa_i} \delta_{X_{n,i}}\overset{?}=\sum_{n=1}^\gamma \delta_{X_n} $$
Where the Questionmark refers to Definition 2.4, can I define such a suitable RV $\gamma$ such that my double sum collapses into a (single) sum? My naive approach seems to lead me nowhere so far. Update: I believe one approach that could get me out of my dilemma would be to take the random variables $K_1, K_2, \dots$ with values in $\overline{\mathbb{N}_0}$ and enumerate them anew such that $$K_1\leq K_2 \leq \dots \leq K_\infty:= \max_{i \in \overline{\mathbb{N}_0}} \{ K_i \} $$
This should allow me to naturally redefine $$ \lbrace \underbrace{X_{1,1}}_{=Y_1}, \underbrace{X_{2,1}}_{=Y_2}, \dots, \underbrace{X_{K_1,1}}_{=Y_{K_1}}, \underbrace{X_{1,2}}_{=Y_{K_1+1}}, \dots , \underbrace{X_{K_2,2}}_{=Y_{K_2}}, \dots ,\underbrace{X_{K_n,n}}_{Y_{K_n}}, \dots \rbrace $$ All of the $Y_i$ are indeed RV in $\mathbb{X}$ and $K_\infty$ is a RV with values in $\overline{\mathbb{N}_0}$, thus I can write  $$\eta = \sum_{i=1}^{K_\infty} Y_i $$","['dirac-delta', 'probability-theory', 'point-processes']"
2160923,Intuition for $e^{ix}$ lies on the unit circle.,"I do know that for any $x$, the complex number $e^{ix}$ have to lie on the unit circle because if we plot the points for $\cos x + i\sin x$ for each $x$, we will eventually form a circle. Are there any more intuitive approach on why $e^{ix}$ lies on the unit circle?","['intuition', 'complex-analysis']"
2160940,How to derive the Riemann Curvature Tensor?,"I'm taking a course in General Relativity, and before getting into Physics itself, the required knowledge of Differential Geometry is being taught. In that context, a linear connection on a smooth manifold $M$ was introduced as a collection of maps $\nabla^{(r,s)} :\Gamma(TM)\times \Gamma(T^r_s M)\to \Gamma(T^r_s M)$ which takes a vector field $X$ and an $(r,s)$-tensor field $T$ and produce one $(r,s)$-tensor field $\nabla^{(r,s)}_ X T$. We, however, drop the $(r,s)$ and just denote all maps by $\nabla$. This map is required by the definition to satisfy: It is $C^\infty(M)$-linear on the first entry, that is $X\mapsto \nabla_X T$ for fixed $T$ is $C^\infty(M)$ linear. It is linear on the second entry, that is $T\mapsto \nabla_X T$ is linear for fixed $X$. It obeys Liebnitz rule in the second entry, that is, $\nabla_X(T\otimes S)=(\nabla_ X T)\otimes S+ T\otimes (\nabla_X S)$ for fixed $X$. It reduces to $X$ itself on $(0,0)$-tensors, that is, $\nabla_X f = Xf$ for fixed $X$ and $f\in C^\infty(M)$. Now given a smooth manifold with linear connection $(M,\nabla)$ one can define  the Riemann Curvature Tensor as the tensor field $R : \Gamma(T^\ast M)\times \Gamma(TM)\times \Gamma(TM)\times \Gamma(TM)\to C^\infty(M)$ given by $$R(\omega,Z,X,Y)=\omega(\nabla_X \nabla_Y Z - \nabla_Y\nabla_X Z-\nabla_{[X,Y]}Z).$$ The problem is that this thing was just defined with no motivation whatsoever. It is then said that it gives the change in a vector as paralel transported along a loop formed by $X$ and $Y$. It is also said that this characterizes the curvature of $\nabla$. My question here is: how can one derive this tensor? I mean, given that we have a connection $\nabla$ and we want to define its curvature, how can we derive this expression, and discover that this tensor field will do? I don't know even why it should be a tensor field, let alone follow some steps to arrive at the correct tensor field. I just don't like the approach of ""define this because it works"". I want to be able to find out that this is the correct thing to do.","['tensors', 'riemannian-geometry', 'differential-geometry']"
2160945,What am I doing wrong with this differential equation?,"Take the differential equation $\dot x=\frac{dx}{dt}=x\sqrt x$. Then $\int \frac{1}{x^{1.5}}dx=t=-2x^{-.5}+C$ Hence $x(t)=\frac{4}{(C+t)^2}$ Where if $x_0:=x(0)$,  $C = \frac{2}{\sqrt x_o}$ Final Result : $$x(t)=\frac{4}{(\frac{2}{\sqrt x_o}+t)^2}$$ However, if I set $x_0$ to a positive number, such as $10$, then $x(t)$ is a decreasing function of time. This contradicts the differential equation given, because there the derivative of $x$ w.r.t $t$ is positive if $x$ is positive. What am I doing wrong? Edit : I've further pinpointed down where I'm making the mistake, but I still don't quite understand why it's a mistake: Starting from the equation:
$-2x^{-.5}+C=t$, I moved $C$ to the other side, intentionally leaving out the minus sign: $-2x^{-.5}=C+t$. I have always been taught that the $C$ can be any constant, so it doesn't matter whether we add a minus sign or not (because, we could always have added the constant $\tilde C:=-C $ instead). However, here it seems to matter, because not adding the minus sign gives $x(t)=\frac{4}{(C+t)^2}$ instead of $x(t)=\frac{4}{(C-t)^2}$. I would have quessed that this doesn't matter, because of the reason regarding $\tilde C = -C$. However, because of the square $^2$ in the equation $x(t)=\frac{4}{(C+t)^2}$, both $\tilde C$ and $C$ reduce to $\frac {2}{\sqrt x_0}$, which would imply that $\frac {2}{\sqrt x_0}=- \frac {2}{\sqrt x_0}$. What's going on here? what am I doing wrong?",['ordinary-differential-equations']
2160949,Basic question regarding complexification of a vector bundle,"Let $E\rightarrow M$ be a real vector bundle over a real manifold $M$. By complexification of this bundle we mean the complex vector bundle $E_{\mathbb{C}}$ whose fibers are given by complexifying the corresponding fibers in $E$, i.e. $(E_\mathbb {C})_x = E_x\otimes _{\mathbb {R}}\mathbb{C} \space\space \forall x\in M$. My question: Is the complexification same as the tensor product bundle of $E$ with the trivial bundle $M\times \mathbb{C}$? Intuitively, I think this is true since the fibers seem to be isomorphic, but not sure how to prove they are isomorphic as bundles over $M$. Any help would be appreciated.","['complex-geometry', 'vector-bundles', 'differential-geometry']"
2160974,To show $\mathrm{ker} f=\{0\}$ for linear mapping $f$.,"Let $V$ be a vector space over $F$ with basis $\{e_1,e_2,...e_n\}$.
Let $F$ be a linear mapping from $V$ to $V$ such that
$F(e_1) =e_2,...F(e_n)=e_1$.
Show that  $\mathrm{ker} f=\{0\}$. Also find $f^{-1}$. I just know that $\mathrm{ker} f=\{0\}$ iff $f$ is 1-1. So is it enough to show that basic definition for 1-1? The inverse mapping will be defined as $f^{-1}(e_1) =e_n, f^{-1}(e_2)=e_1,...$
Am I right?",['linear-algebra']
2160984,How to map a square to a triangle?,"I need the opposite direction, I was not quite seeing it. I then decided to try and find a transformation from square to triangle in a hope to invert it. I am trying to find an invertible transformation between the unit square $x,y \in[0,1] \times [0,1]$ and the triangle  $T$ bounded by the coordinate axes and the line $y = -\frac{b}{a}x + b$, ($\xi,\eta   \in T$) . My way of thinking:
If we fix an $x$ then run though $y$, we want the $\eta $ ordinate to end at $b$ and the $\xi$ ordinate to end at 0. 
$$\xi = ax(1-y)$$
$$\eta = by$$ After a few diagrams I am confident this is correct. I am going to try to use it to simplify an integral so I would like to be sure that this transformation is good before moving on. EDIT Putting this in a different way.
I would like an invertible transformation between the unit square defined above and a right-angled triangle bounded by the lines $y = 0$, $x = 0$ and $$y = -\frac{b}{a}x + b$$ This triangle will have vertices $(0,0),(0,b)$ and $(a,0)$. From the constructive comments, I might have to have the restriction that the area of the triangle and the square must be equal. It is not important that I am mapping from the unit square it just seemed the most simple to begin with. The transformation that I found is not invertible either. If we consider the determinant of the Jacobian of the transformation we find that $$|J| = ab(1-y)$$ which is $0$ when $y = 1$. So I have failed in that respect.","['calculus', 'geometry']"
2161003,Different Curvatures Obtained Depending on the Form of the Curvature Equation,"Thank you ahead of time for taking a look at this. My problem is as follows: We have two forms of the equation for the curvature of a space curve $\mathbf{r}(t)$ given by \begin{equation} \kappa(t) = \frac{|\mathbf{T'(t)}|}{|\mathbf{r'(t)}|} \end{equation} and \begin{equation} \kappa(t) = \frac{|\mathbf{r'}(t)\times\mathbf{r''}(t)|}{|\mathbf{r'(t)}|^3} \end{equation} All authors I have been able to find equate the two forms, indicating that both will give the same curvature of a space curve. However, for some space curves, I obtain different forms of the curvature depending on which form of the $\kappa$ equation I use. Take the example $y = 5e^x$. We parameterize this as \begin{equation*} \mathbf{r}(t)=\ <t,\ 5e^t> \end{equation*} and using the first form of the curvature formula obtain $|\mathbf{T'}(t)|= 5e^t$ and $|\mathbf{r'}(t)|= \sqrt{1+25e^{2t}}$ which gives \begin{equation*} \kappa(t) = \frac{5e^t}{\sqrt{1+25e^{2t}}} \end{equation*} yet when I use the second curvature formula I obtain \begin{equation*} \kappa(t) = \frac{5e^t}{(1+25e^{2t})^{3/2}} \end{equation*} I have been puzzling at this for a while now and have not been able to ascertain as to why the two forms of the equation should give different answers.","['multivariable-calculus', 'curvature', 'calculus']"
2161026,"Is the product of consecutive primes in $(a, b)[{n}]$ $=$ $1$ $\pmod ab$?","Two relatively prime integers, $a$ $>$ $2$ and $b$ $>$ $2$, let $(a, b)[{n}]$ denote all primes $p$ which are either $1$ $\mod a$, and or $1$ $\mod b$, and $p$ relatively prime to ab ($n$ denotes the $n$th prime in this set, if defined). Can it be shown that a product of all consecutive primes in $(a, b)[{n}]$ (to infinity) at some point will be $1$ $\pmod {ab}$? In other words, would it ever be the case that the product all primes in $(a, b)[{n}]$ to infinity is never $1$ $\pmod {ab}$. Let $P(a, b)$ be the smallest prime $p$ such that the product of all primes $x$ in $(a, b)[{n}] <= p$ is $1$ $\pmod {ab}$. For example, $P(3, 4) = 19$, since the product of primes $\le 19$ either congruent $1$ $\pmod 3$ and or $1$ $\pmod 4$ relatively prime to $12$, is $1$ $\pmod {12}$. The first three smallest pairs, $P(3, 4) = 19$, $P(3, 5) = 103$, $P(3, 7) = 283$. $(3, 4)$ $5*7*13*17*19$ $=$ 1 $\pmod {12}$ $(3, 5)$ $7*11*13*19*31*37*41*43*61*67*71*73*79*97*101*103$ $=$ $1$ $\pmod {15}$ $(3, 7)$ $13*19*29*31*37*43*61*67*71*73*79*97*103*109*113*127*139*151*157*163*181*193*197*199*211*223*229*239*241*271*277*281*283$ $=$ $1$ $\pmod {21}$","['number-theory', 'products', 'modular-arithmetic', 'elementary-number-theory']"
2161044,Let $f$ be an entire function and $L$ a line in $\mathbb{C}$ such that $f(\mathbb{C})\cap L=\emptyset$. Show that $f$ is constant function.,"Let $f$ be an entire function and $L$ a line in $\mathbb{C}$ such that $f(\mathbb{C})\cap L=\emptyset$. Show that $f$ is constant function. If $f$ is not constant  then $f(\mathbb{C})$ is dense set in $\mathbb{C}$, but how can I use that line does not intersect the image set?","['complex-analysis', 'real-analysis']"
2161061,Conditional Probability 5 card hand,"We have a 5 card hand from a standard deck. What is the probability that the hand is all Spades, given that it has at least two Spades? I know the formula for conditional probability is:
$P(A|B) = \frac{P(A \cap B)}{P(B)}$ So in this case would it be: $P(A|B) = \frac{13 \choose 5}{{13 \choose 5}+{13 \choose 4}{39 \choose 1}+{13 \choose 3}{39 \choose 2}+{13 \choose 2}{39 \choose 3}}$","['combinatorics', 'probability', 'card-games']"
2161077,If $2f(\frac{x}{2})+3f(\frac{2-x}{3})=g(x)$ then find $25ad-bc$,"$2f(\frac{x}{2})+3f(\frac{2-x}{3})=g(x)$, $0 \leq x < 3$, $f''(x)>0$;
  if $g(x)$  is strictly increasing in $(a,b)$ and $g(x)$ is strictly
  decreasing $(c,d)$ then $25ad-bc$ is ? My Attempt: On taking derivative on both sides: $$f'(\frac{x}{2}) - f'(\frac{2-x}{3}) =g'(x)$$ $g(x)$ is strictly increasing in $(a,b)$ implies for some domain $g'(x)>0$ which implies that: $$\frac{x}{2}>\frac{2-x}{3}$$ $$\implies x>\frac{4}{5}$$ as $f'(x)$ is an increasing function ( $\because f''(x)>0$). So $a=\frac{4}{5}$ $b=3$ $c=0$ $d=\frac{4}{5}$ Is my method correct? The answer comes out as $25(\frac{4}{5})(\frac{4}{5})=16$","['algebra-precalculus', 'derivatives', 'calculus', 'functions']"
2161109,Does the series $\sum_{k=1}^\infty\frac{\sin(1/k)}{k}$ converge?,"Does the series $\sum_{k=1}^\infty\frac{\sin(1/k)}{k}$ converge? By Taylor expanding, I see that this can be rewritten as $\sum_{k=1}^\infty\sum_{n=1}^\infty\frac{(-1)^{n+1}}{k^{2n}(2n-1)!}$, but that seems to be making it messier than it needs to be. Can we use the limit comparison test here? Any help appreciated!","['real-analysis', 'sequences-and-series']"
2161166,"Evaluating $\int_0^1 \frac{\ln^m (1+x)\ln^n x}{x}\; dx$ for $m,n\in\mathbb{N}$","Evaluate $\displaystyle \int\limits_0^1 \dfrac{\ln^m (1+x)\ln^n x}{x}\; dx$ for $m,n\in\mathbb{N}$ I was wondering if the above had some kind of a closed form, here some of the special cases have been discussed but this one is really a fascinating one. I guess there's no general taylor expansion for $\ln^m (1+x)$ and so transforming into a series wouldn't be that easy.","['summation', 'integration', 'definite-integrals', 'calculus']"
2161184,Solving for the CDF of the Geometric Probability Distribution,"So I am trying to find the CDF of the Geometric distribution whose PMF is defined as $$P(X=k) = (1-p)^{k-1}p$$ where X is the number of trials up to and including the first success. Now attempting to find the general CDF, I first wrote out a few terms of the CDF: $$P(X=1) = p \\P(X=2) = p(1-p) + p \\ P(X=3) = p(1-p)^2 + p(1-p) + p\\....P(X=k) = p(\sum\limits_{i=1}^{k-1} (1-p)^i)$$ Now I know this last sum has to equal 1, therefore: $$p(\sum\limits_{i=1}^{k-1} (1-p)^i) = 1 $$ Now I am aware that the CDF is supposed to be $$F(X=k) = 1-(1-p)^k$$ What I am trying to figure out is how to go from what I have to the final solution. Any hints or ideas? Thanks","['probability-theory', 'probability', 'probability-distributions']"
2161203,Question about $\lim_{n\to\infty} n|\sin n|$,"I have a question regarding this limit (of a sequence): $$\lim_{n\to \infty} n|\sin(n)|$$ Why isn't it infinite? The way I thought this problem is like this-$|\sin(n)|$ is always positive, and n tends to infinity, so shouldn't the whole limit go to infinity? What is the right way to solve this and why is my idea wrong?","['infinity', 'trigonometry', 'complex-numbers', 'limits']"
2161210,Polygonally connected open sets,I cannot understand the following theorem: An open set $S$ in $\Re^n$ is connected if and only if it is polygonally connected. I would be thankful if some one could present an intuitive proof of this theorem. Thanks for reading!,['real-analysis']
2161249,Collatz divide by -2 instead,"I've been toying around with the Collatz conjecture for a while, and in an effort to extend it to the negative integers I tried diving by $-2$ instead of by $2$. The new iteratively applied function is then: $f(n) =
\left\{
	\begin{array}{ll}
		-\frac{n}{2}  & \text{if n is even} \\
		3n+1  & \text{if n is odd}	\end{array}
\right.$ A couple of examples: $1 \to 4 \to -2 \to 1 \to \dots$ $2 \to -1 \to -2 \to 1 \to \dots$ $-6 \to 3 \to 10 \to -5 \to -14 \to 7 \to 22 \to -11 \to -32 \to 16 \to -8 \to 4 \to -2 \to 1 \to \dots$ I have tested this with a quick python script, and it seems to eventually reach $1$ for all n between $-10^9$ and $10^9$, not including $0$. Is there a relation between this function and the Collatz conjecture? In particular, would this series convergence to $1$ follow from the Collatz conjecture being true?","['collatz-conjecture', 'integers', 'sequences-and-series', 'convergence-divergence']"
2161251,Prove equality concerning differentiable function,"Let $f(x)$ be a function that is n-times differentiable. Prove the following equality( without L'Hospital):
$$(x^{n-1}\cdot f(\frac{1}{x}) )^{(n)}=\frac{(-1)^{n}}{x^{n+1}}\cdot f^{(n)}(\frac{1}{x})\\$$ So, I wanted to prove it by induction, for $n=0$ the statement is obviously true. So let's assume it's true for some $n \in \mathbb{N_0}$
$\\$ Now we need to check for $n+1$ but I'm not sure how to proceed. $$(x^{n}\cdot f(\frac{1}{x}) )^{(n+1)}$$ I thought about taking the first derivative of the product, then separately observe the n-th derivative of the two expressions but haven't reached any useful conclusions. Any kind of hint would be appreciated, thanks in advance!","['ordinary-differential-equations', 'calculus']"
2161263,How to solve this trigonometrical equation $\tan 2x -\tan x=2$?,"The equation to be solve, $$\tan 2x -\tan x=2$$ My Try : $$\tan 2x=\frac{2\tan x}{1-\tan^2x}$$ $$\frac{2\tan x}{1-\tan^2x} -\tan x=2$$ $$\frac{2\tan x-\tan x(1-\tan ^2 x)}{1-\tan^2x} =2$$ $$2-2\tan^2x =2\tan x-\tan x+\tan^3x $$ $$\tan^3x+2\tan^2x+\tan x-2=0$$ $\tan x= t$ $$t^3+2t^2+t-2=0$$ now :?",['trigonometry']
2161321,If $a+b=2$ so $a^a+b^b+3\sqrt[3]{a^2b^2}\geq5$,"Let $a$ and $b$ be positive numbers such that $a+b=2$. Prove that:
  $$a^a+b^b+3\sqrt[3]{a^2b^2}\geq5$$ My trying. Easy to show that $x^x\geq\frac{x^3-x^2+x+1}{2}$ for all $x>0$, but
$$\frac{a^3-a^2+a+1}{2}+\frac{b^3-b^2+b+1}{2}+3\sqrt[3]{a^2b^2}\geq5$$
is wrong for $a\rightarrow0^+$","['real-analysis', 'inequality', 'exponential-function', 'calculus', 'contest-math']"
2161333,Derivative of double integral with direct and inverse functions,"I found a couple of similar question, but I am struggling applying their logic to my example. Derivative of double integral with respect to upper limits Differentiation under the double integral sign Derivative of double integral with respect to upper limits Derivative of double integral using Leibniz integral rule I have the following differentiation of the double integral: $$\frac{d}{dc}\int_{z^{-1}(c)}^{1}\int_{z(x)}^{z^{-1}(c)} (v-y)f(x)f(y)dydx$$ where $f(x)$ and $f(y)$ and probability density functions. Is it possible to apply Leibniz rule right away here to somehow simplify it? Substituting the internal integral for anti-derivatives as in the examples does not seem possible because that's a product of functions. The best I can do is to ""open up"" the internal integral by integrating by parts and then apply the rule: $$\int_{z(x)}^{z^{-1}(c)} (v-y)f(y)dy=(v-z^{-1}(c))F(z^{-1}(c))-(v-z(x))F(z(x))+\int_{z(x)}^{z^{-1}(c)}F(y)dy$$ Then my expression becomes something like: $$\frac{d}{dc}\int_{z^{-1}(c)}^{1}(v-z^{-1}(c))F(z^{-1}(c))f(x)dx-\frac{d}{dc}\int_{z^{-1}(c)}^{1}(v-z(x))F(z(x))f(x)dx+$$
$$\frac{d}{dc}\int_{z^{-1}(c)}^{1}\int_{z(x)}^{z^{-1}(c)}F(y)f(x)dydx$$ where the first term seems to be feasible to take, and even the second one, but the third one - back to square one. Is there any way around it?","['derivatives', 'definite-integrals', 'inverse-function']"
2161337,The following equation to solve :$ \tan x+\cot x=\sqrt{2}(\cos x+\sin x)$,The following equation to solve : $$ \tan x+\cot x=\sqrt{2}(\cos x+\sin x)$$ My try: $$\frac{2}{\sin 2x}=\sqrt{2}(\cos x+\sin x)$$ $$\left(\frac{2}{\sin 2x}\right)^2=(\sqrt{2}(\cos x+\sin x))^2$$ $$\left(\frac{2}{\sin 2x}\right)^2=2(1+\sin 2x)$$ $$2\sin^2 2x +2\sin ^3 2x=4$$ $$2\sin^2 2x +2\sin ^3 2x-4=0$$ $t=\sin 2x$ $$2t^3+2t^2-4=(t-1)(t^2+2t+4)$$ $$\sin 2x =1\\$$ is it right ?,['trigonometry']
2161359,a.e. convergence to a constant implies the sup of the sequence is almost surely finite,"I'd like to show that if $\{X_n\}$ is a sequence of random variables for which $|X_n|\overset{a.e.}\to c$ for some $c>0$, then for every $\epsilon>0$, there exists $M<\infty$ so that $P(\sup_n |X_n|\le M)\ge 1-\epsilon$. We know $X_n \overset{a.e.}\to c$ implies that $P(|X_n-c|>1\ i.o.)=0$, so $P(|X_n|\le c+1\ i.o.)=1$. So there exists a set $N\subset\Omega$ so that $P(N)=0$ and for all $\omega\in N^c$, $|X_n(\omega)|>c+1$ for only finitely many indices, i.e. there exists some $N(\omega)\in\mathbb{N}$ so that $n\ge N(\omega)$ implies $|X_n(\omega)|\le c+1$. So $\sup_n|X_n(\omega)|\le\max\{|X_1(\omega),...,X_{N(\omega)}(\omega)|,c+1\}\equiv M(\omega)$. We want to say that there exists some $M$ independent of $\omega$ so that $P(\sup_n |X_n|\le M)\ge 1-\epsilon$. I'm thinking $\sup_{\omega\in N^c}M(\omega)$ is a good candidate, but I'm not sure how to show that it's finite. Any pointers would be greatly appreciated! Thanks in advance.","['probability-theory', 'convergence-divergence']"
2161361,Ratio of Radius of Circle $B$ to Radius Of Circle $A$ in the form $a + b\sqrt{c}$,"The full question is as follows: Suppose $X, Y, Z$ are three different, circles of equal radius which are mutually tangent. Let circle $A$ be the circle tangent to $X, Y$, and $Z$ inside the gap between them, and let circle $B$ be the circle tangent to $X, Y$, and $Z$ that surrounds them. Find the ratio of the radius of $B$ to the radius of $A$ in the form $a + b \sqrt{c}$ where $a, b, c$ are integers. To start I created an illustration of the problem. Note that the illustration may not be completely to scale, I created with with shapes on Microsoft Word I called $r_o$ the radius of circles $X,Y,Z$. I also labeled $r_b$ the radius of circle $B$ and $r_a$ the radius of circle $A$.(I withheld from including the last two in the illustration because I felt the picture would become hard to navigate) From here I noticed that $$r_b = 2 r_o + r_a$$
So the ratio of radius $B$ to radius $A$ is $$\frac{r_b}{r_a} = 2\frac{r_o}{r_a} + 1$$ My question arises when solving for $r_o / r_a$ From the sketch it looks like the centers of circles $X,Y,Z$ form an equilateral triangle, with side length $2r_o$. Then from that triangle I created a smaller isosceles triangle with base length $2r_o$ and angles $30^\circ$, $30^\circ$, $120^\circ$ . (represented by the blue dashed lines in the illustration) Are my assumptions valid and/or correct? After my assumptions I used the Law of Sines to find $r_o + r_a$ in terms of $r_o$ thus using that to find $r_o / r_a$ , and my final answer for the whole problem is $7 + 4\sqrt{3}$","['circles', 'ratio', 'geometry']"
2161369,Shadow of a 3D object on a plane,"I'm trying to compute the shadow of 3D objects on the ground. To do this I'm assuming parallel rays from Sun origin. Let's assume the Sun direction is given by azimuth $\varphi$ and elevation $\theta$ angles. So the direction unit vector is retrieved as: $$ \hat{\mathbf{s}} = \mathbf{R}_y\left(\theta\right)\mathbf{R}_z\left(\varphi\right)\hat{\boldsymbol{\imath}}$$ where $\mathbf{R}_{x/y/z}$ are the rotation matrices along the $x, y, z$ axes given by, for example, Euler-Rodrigues equation, and $\hat{\boldsymbol{\imath}}$ is the unit vector along $x$-axis. A point on a ray-line has the equation: 
\begin{equation}
\mathbf{r} = \mathbf{r}_p + \lambda\hat{\mathbf{s}} 
\tag{1}
\end{equation} being $\mathbf{r}_p$ a point on that line. A point on a general plane is given by the equation: \begin{equation}
\left(\mathbf{r} - \mathbf{r_0}\right)\cdot \hat{\mathbf{n}} = 0
\tag{2}
\end{equation} being $\mathbf{r}_0$ a point on the plane and $\hat{\mathbf{n}}$ the unit vector normal to that plane. Ensuring the validity of both equations (1) and (2) allows to compute the $\lambda$ multiplier and retrieve the position vector of the projected point (writing $\tilde{\mathbf{r}} = \mathbf{r_p} - \mathbf{r_o}$) \begin{gather}
\lambda = - \left(\frac{\tilde{\mathbf{r}}\cdot \hat{\mathbf{n}}}
{\hat{\mathbf{s}}\cdot\hat{\mathbf{n}}}\right) \\
\mathbf{r}_\text{proj} = \mathbf{r}_p - \left(\frac{\tilde{\mathbf{r}}\cdot \hat{\mathbf{n}}}
{\hat{\mathbf{s}}\cdot\hat{\mathbf{n}}}\right)\hat{\mathbf{s}}
\tag{3}
\end{gather} Applying eq. (3) to all the vertices of a mesh $\left\{\mathbf{r}_{p_i}\right\}$ gives the shadow . A problem can be noted: $\hat{\mathbf{s}}\cdot \hat{\mathbf{n}}$ can be zero (e.g. Sun is horizontal, i.e. the ray is ortogonal to the normal of plane). Are there some conceptual mistakes in my reasoning?
Is there a way to rewrite the operation as a linear operator applied to the set of vertices position vectors? $$ \left[\mathbf{A}\right]\left\{\mathbf{r}_{p_i}\right\} = \mathbf{r}_\text{proj}$$","['linear-algebra', 'projective-geometry', 'geometry']"
2161380,Every subspace of the dual of a finite-dimensional vector space is an annihilator,"Exercise 26 page 115 of Linear Algebra Done Right by Sheldon Axler is the following: Suppose $V$ is finite-dimensional and $\Gamma$ is a subspace of $V'$. Show that $$\Gamma=\{v\in V:\varphi(v)=0\text{ for every }\varphi\in\Gamma\}^0$$ where $V'$ is the dual space of $V$ and, for any $S\subset V$, $S^0$ is the annihilator of $S$. Attempt: Let $S=\{v\in V:\varphi(v)=0\text{ for every }\varphi\in\Gamma\}$. Clearly, $\Gamma\subset S^0$.I tried to show that $S^0\subset\Gamma$ using some bases of $V$ and $V'$, but I failed. I also tried to show that $\dim{\Gamma}=\dim{V}-\dim{S}=\dim{S^°}$. If $s_1,\dots,s_n$ is a basis of $S$ and $s_1',\dots,s_n'$ its dual, and if $\psi_1,\dots,\psi_p$ is a basis of $\Gamma$, it's easy to see that $s_1',\dots,s_n',\psi_1,\dots,\psi_p$ is a linearly independent list of $V'$. Also, if you extend $s_1,\dots,s_n$ to a basis $s_1,\dots,s_n,v_1,\dots,v_m$ of $V$, then its dual $s_1',\dots,s_n',v_1',\dots,v_m'$ is a basis of $V'$; in fact $S^0=\text{span}\{v_1',\dots,v_m'\}$. Two remarkable facts:$$\forall i\in[1,m],\,\exists j\in[1,p],\,\psi_j(v_i)\neq0$$ because $v_j\notin S$, and $$\forall i\in[1,p],\,\exists j\in[1,m],\,\psi_i(v_j)\neq 0$$ because $\psi_i\neq 0$; in other words the matrix of the inclusion map from $\Gamma$ to $V'$ with respect to the basis of $\Gamma$ and the dual base of the chosen basis of $V$ has no $0$ row nor $0$ column. But this doesn't seem to provide a way to prove that any linear comination of the $(v_i')_{1\le i\le m}$ is a linear combination of the elements of the basis of $\Gamma$. I believe that $v_1,\dots, v_m$ should be chosen more carefuly but I fail to. Could you please help me? Thank you in advance!","['duality-theorems', 'linear-algebra', 'linear-transformations', 'vector-spaces']"
2161407,Prove that a torsion module over a PID equals direct sum of its primary components,"Let $R$ be a P.I.D. with $1$ and $M$ be an $R$-module that is annihilated by the nonzero, proper ideal $(a)$. Let $a=p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}$ be the unique factorization of $a$. Let $M_i$ be the submodule of $M$ annihilated by $p_i^{\alpha_i}$. Prove that $M=M_1\oplus M_2\oplus \cdots \oplus M_k$. My attempt so far: For each $1\leq j \leq k$ define $a_j = \prod_{i\ne j}
 p_i^{\alpha_i}$. Let $\sum_{i=1}^{n} (a_jr_i)\cdot m_i$ be an
  arbitrary element of the submodule $(a_j)M$. We have
  $p_j^{\alpha_j}\cdot (\sum_{i=1}^{n} (a_jr_i)\cdot m_i) =
(p_j^{\alpha_j}a_j(r_1 +\cdots + r_n))\cdot (m_1+\cdots +m_n) =(r_1
 +\cdots +r_n)\cdot (a \cdot (m_1+\cdots +m_n)) =0$. So $\sum_{i=1}^{n} (a_jr_i)\cdot m_i \in M_j$, so that $(a_j)M\subset
 M_j$. Next, let $m\in M_j$. Since $R$ is a P.I.D., we know $1= a_jx +
 p_j^{\alpha_j}y$ for some $x, y \in R$. So $m= 1\cdot m = (a_jx +
 p_j^{\alpha_j}y)\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m = 
 xa_j \cdot m +0 \in (a_j)M$. Conclude that $(a_j)M = M_j$. Next, suppose $m\in (a_j)M\cap \sum_{t\ne j} (a_t)M$. We have $1\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m= xa_j\cdot m  + 0$. But note that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = wa\cdot m$ for some $w\in R$, so that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = 0$. It follows that $xa_j = 0$, and $m=0+0=0$. Conclude that $ (a_j)M\cap \sum_{t\ne j} (a_t)M = (0)$. Thus, $\sum_{i=1}^{k} (a_i)M$ is a direct sum. At this point, I'm not sure how to actually show this direct sum is
  equal to $M$. The only thing I tried is applying the Chinese Remainder
  Theorem as follows, but it doesn't seem to work. We have that $(a)M=(0)$. And since $R$ is a PID, we know that since
  $(p_i^{\alpha_i}, p_j^{\alpha_j})= (1) = R$ for any $i\ne j$,
  $(p_i^{\alpha_i})$ and $(p_j^{\alpha_j})$ are comaximal ideals. So apply the Chinese Remainder Theorem to get $M\cong
 M/(p_1^{\alpha_1})M \times \cdots \times M/(p_k^{\alpha_k})M$. I'd appreciate some help on finishing this.","['abstract-algebra', 'ring-theory', 'modules']"
2161409,Suppose $A$ is a countable subset of $\mathbb{R}$. Show that $\mathbb{R} \sim \mathbb{R} \setminus A $.,"Here is the question I am trying to answer: Let $\mathbb{R}$ denote the reals and suppose A is a countable subset of $\mathbb{R}$. Show that $\mathbb{R} \sim \mathbb{R} \setminus A $. My attempt: Because $\mathbb{R}$ is uncountable and the subset $A$ of $\mathbb{R}$ is countable,  $\mathbb{R} \setminus A $ is uncountable. Therefore $ \mathbb{R} \sim \mathbb{R} \setminus A $ . My question:
Is this specific enough or do I need to find a better way to show that $\mathbb{R} \sim \mathbb{R} \setminus A $? If I need to be more specific, do I have to come up with a function $f$ such that $f$ maps $\mathbb{R}$ onto $ \mathbb{R} \setminus A$ such that the function is 1-1 and onto? If I do need to create a function, any helpful hints to help me create this function? Thanks a lot.","['real-analysis', 'real-numbers', 'functions', 'cardinals', 'analysis']"
2161444,Embed 1st order linear differential matrix equation in SDP,"Suppose I have the following 1st order linear differential matrix equation: $$\dot{X}(t) = \frac{1}{2}D(t)X(t) + \frac{1}{2}X(t)D(t)^T $$ $D(t),X(t)\in \mathbb{R}^{n\times n}$ $X$ is positive semidefinite (i.e., $X\succeq 0$). We know the following standard semidefinite programming form: My question is how to embed that differential equation into the SDP? You might consider the following scenario: 1. The variable is evolving over time and $D(t)$ is the given input data changing over time. 2. $C, A_i$ are constant matrices. I do not want to use discretization , i.e., 
$$\dot{X} = \frac{X(k+1)-X(k))}{\Delta t}$$ This is because such differential equation is rank preserving (see the following lemma) and I want the rank of $X$ nor to change over time. ( Optimization and dynamical systems, Helmke and Moore ) Is there any possible way or related papers (or article with similar flavors) about this topic?","['matrices', 'semidefinite-programming', 'convex-optimization', 'ordinary-differential-equations']"
2161454,is it possible to hash a range?,"OK. I am not a math guy. I'm a programmer, so forgive me for the non-math lingo. let's say I have 3 ranges [1 - 3]    //  index 0
[4 - 6]    //  index 1
[7 - 13]   //  index 2
etc etc etc with any arbitrary sorted, non-overlapping range Is it mathematically possible to do something like this?: func(2) -> should print result index[0] or func(8) -> should print result index[2] The idea is that I want to provide any arbitrary sorted range and store it as a hash. The are no overlapping ranges. Then provide a number to the func and it should tell me the index. In order to do this, I think i would need to (for example the first range), take the numbers 1, 2, 3 and convert it into a hash. So that if an input of say 2 was provided, it would map to that exact hash. Is this possible? [Please me me with the correct tags for the question.. i do not know which area of maths this falls under.] Edit : Range count can be any amount. I am trying to avoid looping. Count can reach as high as 60k. That's why i was wondering if hashing was possible with mathematics given the requirements above. If it is possible in maths, then it will be possible in code. Edit #2 : My attempt to make the question more math like.. i hope. Is it possible to take a list of sorted integers: lets say 5 => [1, 2, 3, 4, 5]
And create a hash with them, such that the following is possible. func(0) results false
func(6) results false
func(1) results true
func(2) results true
func(3) results true
func(4) results true
func(5) results true","['algorithms', 'hash-function', 'functions']"
2161462,Could be this :$ \cos^n(i)+\sin^n(-i)$ integer for $n>2$?,"I have tried to look when does :$\cos²(z)+\sin²(\bar{z})=1$ with $z$ is a complex variable and $\bar{z}$ is it's conjugate ,and  I have got that $z=i$ is the best example for that where :$\cos²(i)+\sin²(-i)=1$ , really my question about the nature of the identity :$ \cos^n(i)+\sin^n(-i)$ for $n>2$ , now my question here is : Question: Could be this : $ \cos^n(i)+\sin^n(-i)$ integer for $n>2$?","['number-theory', 'trigonometry', 'integers']"
2161490,"Proof for the ""Fundamental Calculus Theorem"" for two variables.","I`ve been stuck with this proof and mostly because I'm not sure if I can do a certain step, but at least without formality, it sounds good. The problem goes like this:
Be f $\in$C(R) such that $R=[a,b]\times[c,d]$, and we define $F(x,y)=\int^{x}_{a}\int^{y}_{c}f(u,v)du\cdot dv$. Prove that $\dfrac{\partial^{2}F}{\partial x \partial y}=\dfrac{\partial^{2}F}{\partial y \partial x}=f(x,y)$ Now the far that I got, formaly speaking, is to show that by taking the function f with an $x_o \in[a,b]$ fixed and then seeing that function like a composition of fuctions such that $f(h(y))=g(y)$ where $ h(y)=x_o\widehat e_{x}+y\widehat e_{y}$, then I could apply the first part of the fundamental calculus theorem, and show that exist $G(y)=\int^y_cg(v)dv$ with the propety that $G'(y)=g(y)=f(x_o,y)$. Here is were my intuition takes place but I'm stuck trying to write it. Because this contruction leds to verify the existance of $G(y)$ for every $x\in[a,b]$, then I want to define $M(x)=\int^d_cH(y)du=\int^d_c[\int^b_af(u,v)dv]du$ and show that its derivative is $H(y)$ (I suppose that I could use the Fubini's Theorem to show the existance of $M(x)$ with the benefit that would ensure $M's$ integrability in $[a,b]$. But because Fubini's theorem shows the existance of that function with integral intervals from a to b, Im not sure if that could apply to my definition of $M$). And finally with all of this, having the existance of $\dfrac{\partial F}{\partial x},\dfrac{\partial F}{\partial x}$ and $\dfrac{\partial^2F}{\partial x \partial y}$ being continuous by hypothesis, then by another theorem this implies that $\dfrac{\partial^{2}F}{\partial x \partial y}=\dfrac{\partial^{2}F}{\partial y \partial x}$. Well this is more intuitive than formal, I would aprecciate some comments from my idea, NOT a solution, or something that could let me advance with the proof. UPDATE: Justification for the iteration integral. Here is because it describes the function $$\frac{\partial}{\partial y}F(x,y) = \frac{\partial}{\partial y}\int_a^xG(u,y) \, du = \lim_{h\rightarrow 0}\dfrac{\int_a^xG(u,y+h)du-\int_a^xG(u,y)du}{h}$$
$$=\lim_{h\rightarrow 0}\int_a^x\dfrac{(G(u,y+h)-G(u,y))}{h}du$$
and because of the continuity of $G(u,y)$ in $[c,d]$
and its derivate on $y$ exists (for TFC on f) such that 
$$\dfrac{\partial}{\partial y}G(u,y)=f(u,y)$$ and then exist ($\int_a^b \dfrac{\partial}{\partial y}G(x,y) dx$) for the integrability on $f$, 
then applying the mean value theorem exists $\xi\in[y,y+h]$ such that $$\left|\int_a^b \frac{G(x,y+h) - G(x,y)}{h} \, dx - \int_a^b \dfrac{\partial}{\partial y}G(x,y) \, dx\right|\\ 
=  \left|\int_a^b \dfrac{\partial}{\partial y} G(x, \xi) \, dx - \int_a^b \dfrac{\partial}{\partial y}G(x,y) \, dx\right|\\ \leqslant  \int_a^b |\dfrac{\partial}{\partial y}G(x,\xi)  - \dfrac{\partial}{\partial y}G(x,y)| \, dx.$$ Since $f$ is continuous on $[a,b] \times [c,d]$, for its uniformly continuity, for any $\epsilon > 0$ there exists $\delta >0$ such that if $|h| < \delta$ then $ |\dfrac{\partial}{\partial y}G(x,\xi)  - \dfrac{\partial}{\partial y}G(x,y)|= |f(x,\xi)  - f(x,y)|< \epsilon/(b-a)$ and $$\int_a^b |\dfrac{\partial}{\partial y}G(x,\xi)  - \dfrac{\partial}{\partial y}G(x,y)| \, dx < \epsilon.$$ Thus, $$\lim_{h \rightarrow 0} \int_a^b \frac{G(x,y+h) - G(x,y)}{h} \, dx = \int_a^b \dfrac{\partial}{\partial y} G(x,y) \, dx \\ = \int_a^b \lim_{h \rightarrow 0} \frac{G(x,y+h) - G(x,y)}{h} \, dx . $$","['multivariable-calculus', 'proof-writing', 'calculus']"
2161491,Sequence Limit: $\sin(n^3)$,"How can I prove that this sequence does not converge, using  the definition? $$W_n = \sin(n^3)$$ For $n \in \mathbb{N}$. I tried to do a proof by reduction to the absurd but without result.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2161522,Sequence of non-zero holomorphic functions in the unit disk converges locally to 0,"I could not solve the following problem: Let $\{f_n\}_n$ be a sequence holomorphic functions in the unit disk $\mathbb{D}$ such that all $f_n$ are zero-free in $\mathbb{D}$, $|f_n|<1$ for all $n\geq1$ and $lim_{n\rightarrow\infty}f_n(0)=0$. Prove that the sequence converges uniformly on compacts of $\mathbb{D}$ to 0. This is what I tried: Since $|f_n|<1$, the sequence $\{f_n\}_n$ is uniformly bounded in any compact of $\mathbb{D}$ and hence by Montel theorem, $\{f_n\}_n$ is a normal family. Then, there is a subsequence $\{f_{n_k}\}_k$ that converges to a function $f$ uniformly over compact subsets of $\mathbb{D}$. Now, the sequence $\{f_{n_k}\}_k$ has no zeros and has limit $0$ in $z=0$ by the hypothesis, so $f(0)=0$. By Hurwitz theorem, $f$ is identically zero. But I cannot prove that $\{f_n\}_n$ converges to $f$ uniformly over compact sets. In fact, if I prove the uniform convergence for $\{f_n\}_n$ instead of a subsequence, then we are done. Can someone help me? PD: I looked for the same question but I did not find it. If it is duplicated, I apologize.","['complex-analysis', 'holomorphic-functions']"
2161545,The projection of a point onto a convex set is unique with respect to any norm,"Given a convex set $C$, the projection of a point $z$ onto $C$ is a point $x$ in $C$ that minimizes $\|z- x\|$. Say the minimum is achieved at $x^*\in C$. My textbook shows such $x^*$ is unique under the euclidean norm, as shown below. My guess is the uniqueness should hold regardless what norm is chosen, but I have trouble proving it. Thanks!","['optimization', 'linear-algebra']"
2161607,"Continuous function on a closed, bounded set","I am having some trouble dealing with the following Let $\Omega \subseteq \mathbb{R}^m$ be closed and bounded, and $f:\Omega \to \mathbb{R}^n$ continuous in $\Omega$. Without using Heine-Borel theorem, show that $f(\Omega)$ is closed. Can I find some sequence $(f(\mathbf{x}_k))$ such that $f(\mathbf{x}_k) \to f(\mathbf{x})$, with $f(\mathbf{x}) \in f(\Omega)$? Is it the right approach? If so, how do I build it or show it exists? Thanks!","['continuity', 'proof-writing', 'analysis']"
2161660,Let $R$ be the binary relation on $\mathbb{N}$ defined by $xRy$ ($x$ is in relation to $y$) defined by: $xRy$ if $xy=49$,"Let $R$ be the binary relation on $\mathbb{N}$ defined by $xRy$ ($x$ is in relation to $y$) defined by: $xRy$ if $xy=49$ A) $R$ is reflexive and $R$ is symmetric B) $R$ is reflexive and $R$ is not symmetric C) $R$ is not reflexive and $R$ is symmetric D) $R$ is not reflexive and $R$ is not symmetric The answer is C. I understand why it is symmetric, but why it is not reflexive? For example, if I have $xy=7\times7=49$ (which is reflexive relation, isn't it?). Anyone explain please? Thank You",['discrete-mathematics']
2161683,Divorced Couples Problems Combinatorics,"5 couples are sitting in a line but no one wants to sit next to their partner.
How many ways can this be done? Here's my solution. Is this correct?
$$10!-{5 \choose 1}2! \cdot 9!+{5 \choose 2}2!^2 \cdot 8!-{5 \choose 3}2!^3 \cdot 7!+{5 \choose 4}2!^4 \cdot 6!-{5 \choose 5}2!^5 \cdot 5!$$","['inclusion-exclusion', 'combinatorics', 'problem-solving', 'discrete-mathematics']"
2161699,Prove that the union of two ideals is an ideal only if one of the ideals is contained within the other.,"Here's my proof: Let the ideal $I = \{i_1, i_2,...\}$ and $J=\{j_1, j_2,...\}$ Then $I \cup J$ is an ideal only if for all $\nu, \mu$, $i_{\nu}+{j_\mu} \in I \cup J$. Let us assume that there exists an element $i_{\nu}$ of $I$ that does not belong to $J$. Then, for any $j_{\mu}$, either $i_{\nu}+{j_\mu} \in J$, which is a contradiction since it would imply that $i_{\nu} \in J$, or $i_{\nu}+{j_\mu} \in I$, which implies that $j_{\mu} \in I$. Letting $\mu$ run through the index of $J$, we get that $J \subset I$. Thus, our proof is complete. However, here are some things bothering me: There seems something fishy about this proof, but I can't point it out. Is my proof correct? Is this a constructive proof or a proof by contradiction? Does this proof use the Axiom of Choice? Thanks in advance for any help!","['abstract-algebra', 'ring-theory', 'proof-explanation', 'axiom-of-choice', 'ideals']"
2161719,"Two right triangles of equal perimeter share a side. Given an acute angle of one triangle, find the acute angles of the other.","Two right triangles shown below have equal perimeters. The hypotenuse of the orange triangle is one leg of the green triangle stacked on top of it. If the smallest angle of the orange triangle is $20^\circ $, what are the angles of the green triangle? Please help me. I didn't get any idea.","['trigonometry', 'triangles', 'geometry']"
2161769,Compute $\lim_{k\to\infty}E[T_k]$ of this CTMC.,"Consider a CTMC with state space on $\{3,4,5,..\}\times\{3,4,5,...\}$. The exponential rate $\gamma_{(i,j)}$ in state $(i,j)$ equals $i$. $P_{(i,j)\to(3i,j)}=\frac{1}{\sqrt{i}}$ and $P_{(i,j)\to(i,j+1)}=1-\frac{1}{\sqrt{i}}$. Let $T_k$ denote the time of the kth transition in the CTMC. If the CTMC is initialized to state (3,3) at time 0. Compute $\lim_{k\to\infty}E[T_k]$. In my opinion, it seems as $i$ grows, it is more likely that DTMC goes up. But I have no idea how it relates to the result.","['stochastic-processes', 'probability-theory']"
2161830,How to prove that any line contain at least three points?,"Hi i was reading a book called Symmetry and Pattern in Projective Geometry by Eric Lord, in his book the author give these axioms: Any two distinct points are contained in a unique line. In any plane, any two distinct lines contain a unique common point. Three points that do not lie on one line are contained in a unique plane. Three planes that do not contain a common line contain a unique common point. My question is if with these axioms can i prove the statement that any line contains at least three points?","['axioms', 'projective-geometry', 'geometry']"
2161894,Does the equation $a^{2} + b^{7} + c^{13} + d^{14} = e^{15}$ have a solution in positive integers,Does the equation $a^{2} + b^{7} + c^{13} + d^{14} = e^{15}$ have a solution in positive integers Like FLT -- cannot see how to attack this one :(,"['number-theory', 'diophantine-equations']"
