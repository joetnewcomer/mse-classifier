question_id,title,body,tags
2371099,Fourth root of a biquadratic,"Three roots of the equation $x^4-px^3+qx^2-rx+s=0$ are $\tan A$, $\tan B$ & $tan C$ where $A$, $B$, $C$ are the angles of a triangle.The fourth root of the biquadratic is $(p-r)$/$(1-q+s)$ $(p-r)$/$(1+q-s)$ $(p+r)$/$(1-q+s)$ $(p+r)$/$(1+q-s)$ I tried using theory of equations and the identity that in a triangle $\tan A+\tan B+\tan C = \tan A \tan B\tan C$ but could not find the fourth root. My answer doesn't match any option please tell me what have I done wrong and what is the correct way to do this",['algebra-precalculus']
2371101,Derive the weak Nullstellensatz from the strong one,"I'd like to derive the weak Nullstellensatz An ideal $J\subset K[x_1,\dots,x_n]$ has a common zero exactly if it is a proper ideal. from the strong one $\sqrt{J} = I(V(J))$ This seems pretty easy: \begin{align}
J \text{ has no common zero} & \Longleftrightarrow V(J) \text{ is empty  } \\ & \Longleftrightarrow 1\in I(V(J)) = \sqrt{J} \\ & \Longleftrightarrow \sqrt{J} = K[x_1,\dots,x_n] \\ & \overset{(*)}{\Longleftarrow} J=K[x_1,\dots,x_n]
\end{align} The missing part is $(*)$. Obviously $J\subset \sqrt{J}$ for all ideals. But why does $\sqrt{J} = K[x_1,\dots,x_n]$ imply $J = K[x_1,\dots,x_n]$?",['algebraic-geometry']
2371118,Prove $ 2<(1+\frac{1}{n})^{n}$,"How to prove that $ 2<(1+\frac{1}{n})^{n}$ for every integer $n>1$. I was thinking by induction, it works for $n=2$ but then I couldn't move forward.","['algebra-precalculus', 'sequences-and-series', 'calculus']"
2371194,inequality involving the product of lengths of edges of a tetrahedron,"Is there a constant $C$ such that for every tetrahedron with edges $a,b,c,d,e,f$ and volume $V$, the following inequality holds:
$$abcdef\ge C\cdot V^2$$ The trivial case $a=b=c=d=e=f$ gives $72\ge C$, but this is all I obtained. This question is a 3D-version of inequality involving the product of lengths of edges of quadrilateral The method used in RobertZ's solution seems not work here, since both sides would tend to 0.","['volume', 'inequality', 'geometry']"
2371216,"Definition of a ""region""","Definition given - Region: Open set with none, some, or all of its boundary points. This seems quite unimportant... and it seems that almost all sets are regions (I can only think of regions, I can't think of any example that isn't.). It feels like it I'm given a set that is, neither open or closed, it could always be decomposed by taking away the boundary, meaning it is an open set with some of its boundary points. This is why I think the following set is a region: $$S = \{z=x+iy \in \mathbb{C}:x\geq 0, y>0\}.$$ If it is a region, what would be an example for a non-region?","['terminology', 'complex-analysis']"
2371218,Guarantee of matrix inverse for $A'A$,"Suppose I have a matrix $A$. Let $A'$ be the transpose of A. Is there any guarantee that $A'A$ has an inverse? You can find this formula at Adaptive Neuro-Fuzzy Inference System (ANFIS) theory in ""LSE Recursive"" part. Thank you.","['matrices', 'least-squares', 'linear-algebra', 'inverse']"
2371278,What is a simple example of a free group?,"Can someone give me a simple example of a free group with a basis, given the definition below? I don't think I'm understanding the definition clearly. For example if $F= (\Bbb Z, +)$, $X = \{0\}$, $\phi\colon\{0\} \rightarrow G$ is any function, then there should exist a unique homomorphism $\tilde \phi\colon \Bbb Z \rightarrow G$ such that $\tilde \phi(0) = \phi(0)$. But if $\phi\colon\{0\} \mapsto \text{non identity element of $G$}$, then there's no way any homomorphism exists because identities of one group are mapped to the other group.","['examples-counterexamples', 'abstract-algebra', 'free-groups', 'group-theory', 'definition']"
2371282,Exercise from Dixon's book on structure linear groups,"On page 99 of ""Structure of linear groups"" by John D Dixon there's an exercise right after Theorem: Let $G$ be a finite non-modular linear group of degree $n$. Then $G$ has a normal abelian subgroup $A$ with index $[G:A]\leq (49n)^{n^2}$. Exercise 1: Let $G$ be a finite non-modular linear group of degree $n$. Show that if $G$ has an abelian subgroup $B\supseteq Z(G)$ with $[B:Z(G)]>(4\pi)^n$, then $G$ has a normal abelian subgroup $A$ with $B\supseteq A\supsetneq Z(G)$. [Hint: We may suppose $G$ consists of unitary matrices, and the elements of $B$ are diagonal.] I have absolutely no idea what to do here. Neither how to apply the theorem nor how to get to $(4\pi)^n$. I don't know how to make any use of the hint either. Any help would be appreciated.","['representation-theory', 'group-theory', 'linear-groups']"
2371336,Show that $(C^1)^\perp =\{ 0\}$ in the inner product space of continuous functions,"In the book of linear algebra by Werner Greub, at page $195,$ it is asked that Let $C$ be the space of all continuous function in the interval $0\leq t \leq 1$ with the inner product defined as $$(f,g) = \int_0^1 f(t) g(t)dt.$$ If $C^1$ denotes the subspace of all continuous
differentiable functions, show that $(C^1)^\perp =\{ 0\}$ . Since I'm dealing with differentiable functions, I thought using integration by parts might help, and I got $$f(1)G(1)  = f(0)G(0) + \int_0^1 f'(t)G(t) dt, $$ where $G' = g $ , but it didn't give me anything useful, as far as I see. Edit: This question is asked in abstract linear algebra book, and I have only taken freshman year Calculus courses about functional analysis, so I would appreciate if you give your answer according to this fact.","['functional-analysis', 'real-analysis', 'orthogonality', 'linear-algebra']"
2371369,Stability result for analytic continuations,"Let $f(x):\mathbf{R} \rightarrow \mathbf{R}$ be a real function which extends meromorphically to the complex $\mathbf{C}$ plane to a function $\tilde f(z) : \mathbf{C} \rightarrow \mathbf{C}$. Let then $f_n(x): \mathbf{R} \rightarrow \mathbf{R}$, with again meromorphic extensions $\tilde f_n(x): \mathbf{C} \rightarrow \mathbf{C}$, such that: $f_n(x) \rightarrow f(x), x \in \mathbf{R}$ with some convergence criterion (for example uniformly or in some normed sense). Is it true that also: $\tilde f_n(z) \rightarrow \tilde f(z), z \in \mathbf{C}$ for some convergence criterion??? For example can we say that the set of poles of $\tilde f_n$ will tend to the poles of $\tilde f$ I came across this question when trying to understand how analytical continuations can be practically performed. I did not find an answer yet.","['complex-analysis', 'analytic-continuation']"
2371425,Smallest sigma-algebra on which difference of measurable functions is measurable?,"Let's assume that $f,g$ are $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. Then we know by the usual theorem that $f-g$ is also $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. But what's the smallest sigma-algebra $\mathcal{A}$ on which the $f-g$ is measurable? Motivation: This question comes from reading on book an example of a random variable $Y_n:=X_{2n}-X_{2n-1}$. The author states that $Y_n$ is $\sigma(X_{2n},X_{2n-1}),\mathcal{B}(\mathbb{R}^n)$ measurable. And I wondered why... Also have another question, related to this. Is $(f-g)^{-1}(\mathcal{B}(\mathbb{R}^n)) \subset \sigma\{f^{-1}(\mathcal{B}(\mathbb{R}^n))\cup g^{-1}(\mathcal{B}(\mathbb{R}^n))\}$?",['measure-theory']
2371468,"If $\sum\limits_nx_{kn}=0$ for all $k$ and $\sum\limits_n|x_n|$ converges then $x_n=0$ for all $n$, but what if $\sum\limits_n|x_n|$ diverges?","I am trying to answer the following question, specifically, the second part: Let $(x_{n})^{\infty}_{n=1}$ be  real sequence such that $\sum^{\infty}_{n=1}|x_{n}|$ converges and, for each $k\in\mathbb{N}$ , $\sum^{\infty}_{n=1}x_{kn} = 0$ . Show that $x_{n} = 0$ for all $n$ . What if we no longer require $\sum^{\infty}_{n=1}|x_{n}|$ to converge? Source: https://www.dpmms.cam.ac.uk/study/IA/Numbers+Sets/2015-2016/examples-NS-15-3.pdf Solution to first part: Let $p_{i,k}$ denote the $i^{th}$ prime grater than $k$ (e.g $p_{1,7} = p_{1,8} = p_{2,6} = 11$ ). Define $s_{j,k} = \sum_{n\in k\mathbb{N} \setminus A_{j,k}} x_{n}$ where $A_{j,k} = \{n \in k\mathbb{N} | \exists i \leq j\,\,\,\, s.t. \,\, n|p_{i,k} \}$ . $s_{j,k} = \sum_{n\in k\mathbb{N} \setminus A_{j,k}} x_{n} = \sum_{n\in A_{j,k}}x_{n}$ because $\sum x_{kn} = 0$ . Using Inclusion-Exclusion: $s_{j,k} = \sum^{m}_{r=1}\bigg((-1)^{r-1}\sum_{I \subset \{p_{1,k}, p_{2,k}, ..., p_{j,k}\}, |I|=r}\big(\sum_{n\in A_{i,k},i \in I}x_{kn}\big)\bigg)$ . We see the innermost sum is $0$ . Hence $s_{j,k} = 0$ . $s_{i,k} = x_{k} + \sum_{n \in B_{k}}x_{n} = 0$ where $B_{k} \subset \{p_{j+1, k}, p_{j+1,k}+ 1,...\}$ . Hence: $|x_{k}| = |\sum_{n\in B_{k}} x_{n}| \leq \sum_{n \in B_{k}} |x_{n}| \leq \sum_{n \geq p_{j+1,k}}|x_{n}|$ By taking limits as $j \to\infty$ we have $|x_{k}| = 0$ . So $x_{n} = 0 \, \, \, \forall n$ . Unsure on second part of question.","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'analysis']"
2371473,A noncontinuous function which preserves limits,"I know that if a given function $f$ between two topological spaces is continuous then the image of a convergent sequence is a convergent sequence, and $f$ preserves the limit in the sense that $x_n \to x \implies f(x_n) \to f(x)$. The converse is true if the domain is first countable: If $X$ satisfies the first axiom of countability and $x_n \to x \implies f(x_n) \to f(x)$ for any convergent sequence in $X$ then $f$ is continuous. Thus this still holds if the condition on the domain is dropped? I've been trying to find an counterexample using non first countable spaces like the Sorgenfrey's Line and real numbers with the cofinite topology as the domain but every time I try to break the continuity of the function I end up with convergent sequences whose images don't converge. I was wondering if the statement isn't actually true and can be proved without the first axiom using a different technique maybe.","['continuity', 'general-topology', 'limits']"
2371474,How to find tangent planes? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Finding the tangent plane equation is simple for equations with a simple $z$. For example, if $z$ is a function $f(x,y)$ such as $f(x,y)=x^2+y^3$. It's simply: $z-z_0=f_x(x_0,y_0)(x-x_0)+f_y(x_0,y_0)(y-y_0)$ Which in that case would be: $z-z_0=(2x)(x-x_0)+(3y^2)(y-y_0)$ But what if we're dealing with a more complicated $f(x,y,z)$ where values are not necessarily unique along the $z$ axis? Wouldn't we have to add a $f_z$ term?","['multivariable-calculus', 'linear-approximation']"
2371475,Proof for corresponding eigenvalue,"If x is an eigenvector of a matrix A, then show that its corresponding eigenvalue is given by $\lambda=\dfrac{Ax\cdot x}{x\cdot x}$ I tried starting from $(A-\lambda{I})x=0$. $Ax-\lambda{Ix}=0$ $\lambda{Ix}=Ax$ $\lambda=\dfrac{Ax}{Ix}$. This now is a bit confusing. Any help?",['linear-algebra']
2371490,Partitions that separate all triples,"Let $A=\{1,2,\dots,n\}$, and $\mathcal{A}_1,\dots,\mathcal{A}_k$ be partitions of $A$ into three sets. Suppose that for each pairwise distinct $x,y,z\in A$, there exists $1\leq i\leq k$ such that $x,y,z$ are all in different sets in the partition $\mathcal{A}_i$. What is the minimum possible $k$? Since we are interested in partitions into three sets, we might want to write each element of $A$ in base three. Then we can have $\mathcal{A}_i$ be the partition into three sets according to whether the $i$th digit is $0,1,$ or $2$. But this is not enough, because three pairwise distinct elements $x,y,z$ might not have a digit in which they are all distinct.","['combinatorics', 'extremal-combinatorics']"
2371494,"Show/Prove that $F_{\alpha,n,m} =1/F_{1-\alpha,m,n}$","Show/Prove that $F_{\alpha,n,m} = \frac{1}{F_{1-\alpha,m,n}}$ The distributions I'm working with are the Fisher distribution and the Chi-square distribution. I can prove that n and m switch for the F distribution as follows: $$X = \frac{ \frac{A}{n} } { \frac{B}{m} }$$ where A and B follow $\chi^2$ distributions, are independent, and have n, m degrees of freedom respectively.  Then the following holds: $$\frac{1}{X} = \frac{ \frac{B}{m} } { \frac{A}{n} }$$ My question is how do I show that the $F_{\alpha}$ part goes to $F_{1-\alpha}$ Is there a way to do this all at once or do I need to show the degrees of freedom switch separately from the $1-\alpha$ part of the proof?","['statistics', 'probability', 'probability-distributions']"
2371514,"Limit of recursive sequences: $x_{n+1}=\frac 1 3 (x_n+2y_n), y_{n+1}=\frac 1 3 \left( \frac 1 {x_n}+ \frac 1 {2y_n} \right).$","Let $\left(\,x_{n}\,\right)_{\ n\ \geq\ 1}$ and
$\left(\,y_{n}\,\right)_{\ n\ \geq\ 1}$ be two sequences defined as follows
$\left(\,x_{1},y_{1} > 0\,\right)$:
$$
\left\{\begin{array}{rcl}
{\displaystyle x_{n + 1}} & {\displaystyle =} &
{\displaystyle{1 \over 3}\left(\,x_{n} + 2y_{n}\,\right)}
\\[2mm]
{\displaystyle y_{n + 1}} & {\displaystyle =} &
{\displaystyle{1 \over 3}\left(\,{1  \over x_{n}} + {1  \over 2y_n}\,\right)}
\end{array}\right.
$$
Show that the sequences are convergent and find their limits. MY TRY: I think about using the Weierstrass' Theorem ( every bounded and monotone sequence is convergent ), but I can't find the monotonity for any sequence. Afterwards, I can think of denoting the two limits as $L_{1}$ and $L_{2}$ and replacing them in the reccurence relationship.","['sequences-and-series', 'convergence-divergence', 'limits']"
2371550,Eigenvectors of a matrix and its inverse,"Show that an $n\times{n}$ invertible matrix A has the same eigenvectors as its inverse. I can recall that the definition of a matrix and its inverse, together with the equation for the eigenvector $x$. But this proof I am not getting a concept to deal with it. $(A-\lambda{I})x=0$ $(A^{-1}-\lambda{I})x=0$ Thank you!","['eigenvalues-eigenvectors', 'linear-algebra']"
2371562,How do I rotate 3 groups of 4 people into teams of 3 so that each person in one group works with each person in the other groups?,"I have three teams of four people. I would like to create rotating groups of three, where each group has one person from each team, and those people rotate on a staggered schedule so that each person is in the group for 3 slots. 
For example, if team 1 is people a, b, c, and d; team 2 is people e, f, g, and h; team 3 is people i, j, k, l, the start of the schedule might look like this a, e, i b, e, i b, f, i b, f, j c, f, j c, g, j c, g, k d, g, k d, h, k d, h, l a, h, l a, i, l How do I shift the order in future to make sure that the groups change and everyone gets to work with all of the people on the other teams? Thanks!","['combinatorial-designs', 'combinatorics']"
2371563,Is there a fundamental reason to expect $e$ to appear in this probability question?,"I came across the following question, whose answer is $e$. I was sort of amazed, since I didn't see a reason why $e$ should be making an appearance. So, phrasing the main question in the title another way: should it have been possible to predict that at least my answer should involve $e$ in some nontrivial way? Question: Suppose you draw random variables $x_i \in [0,1]$, where the $x_i$ are uniformly distributed. If $x_i > x_{i-1}$, we draw again, and otherwise, we stop. What's the expected number of draws before we stop? Solution: The probability that we take $n$ draws is given by $\frac{n-1}{n!}$ since there are $n!$ ways to order $x_1,\ldots, x_n$, and exactly $n-1$ choices for the placement of $x_{n-1}$ in the ordering $x_1 < x_1 < \cdots < x_{\widehat{n-1}} < x_n$. That is, for it to take precisely $n$ draws, we need $x_1 < x_2, x_2 < x_3, \ldots, x_{n-2} < x_{n-1}$ but then $x_n < x_{n-1}$. Thus, the expected value is given by
$$
E(\text{number of draws}) = \sum_{n = 2}^\infty \frac{1}{(n-2)!}  = \fbox{e}
$$ P.S. It's also possible I simply made a mistake, and if that's the case please point it out and I can edit or delete the question accordingly.","['uniform-distribution', 'probability', 'probability-distributions']"
2371569,"$\lim_{(x,y)\to(0,0)} (y-\sin(y))/(x^2+y^2)$","$$
f(x,y) = \begin{cases} 0 & \text{if } (x,y)=(0,0), \\[6pt]
\dfrac{y-\sin y}{x^2+y^2} & \text{otherwise.} \end{cases}
$$ is $\lim\limits_{(x,y)\to(0,0)} \dfrac{y-\sin y}{x^2+y^2} = 0 \text{ ?}$ according to wolfarm no but can someone show me why?","['functional-analysis', 'functions', 'limits']"
2371609,How to define the differential $df$ of a function $f$ using limits?,"Let $f:A\subseteq\mathbb{R} \longrightarrow \mathbb{R}$ be a differentiable function of $x\in A$. Then its derivative $\displaystyle {df \over dx}: A\subseteq\mathbb{R} \longrightarrow \mathbb{R}$ is also a function of $x\in A$ and it's defined as: $$\begin{align}
{df \over dx} : A\subseteq\mathbb{R} & \longrightarrow \mathbb{R}\\
x & \longmapsto \lim_{\delta\to 0} {f(x+\delta) - f(x) \over (x + \delta) -
 x}, \\
\end{align}$$ meaning it maps each $x \in A$ to the above limit. (That limit exists by hypothesis.) There's another function associated to $f$, namely, the differential $df$ of $f$, with domain $A\subseteq\mathbb{R}$ (and codomain unknown to me), which I cannot define (since I don't know what it is in the first place). I can give some examples, though. (I do know that if $f$ is a differentiable map between differentiable manifolds, then the differential $df_x$ at $x\in \textbf{Dom }f$ is a certain linear map from the tangent space $T_x$ to the tangent space $T_{f(x)}$, but I don't see how this definition uses limits ,  and I don't know if it's equivalent to the one we (implicitly) use for the examples below.) Example 0 . Let $f:x\longmapsto x^2$. Now $$df: x \longmapsto 2xdx$$ and $$ {df \over dx } : x\longmapsto 2x.$$ Example 1 . Let $f:(x,y)\longmapsto x^4 + 3y^2 + 8$. Now $$df: x \longmapsto 4x^3dx + 6ydy + 0$$ and $${df \over dx}: x \longmapsto 4x^3 + 6y{dy \over dx}$$ and $${df \over dy}: x \longmapsto 4x^3{dx \over dy} + 6y.$$ What limit is $df$? How do we define $df$ using limits? What is the codomain of the map $df$? What limit is $dx$? How do we define $dx$ using limits? What is the codomain of the map $dx$?","['multivariable-calculus', 'real-analysis', 'calculus', 'analysis']"
2371666,"Show $\left| \frac{d^m}{dx^m} e^{-|x|^k} \right| \le C^{m+1} |x|^{2(k-1)}e^{-|x|^k}, \forall |x|>a$","How to show the following bound: Let $k \in (0,\infty)$ and let $  |x|>a>0$, then there exists $C>0$ sucht that for all $m\ge 1$ \begin{align}
\left| \frac{d^m}{dx^m}  e^{-|x|^k} \right| \le  C^{m+1} |x|^{2(k-1)}e^{-|x|^k}, \forall |x|>a
\end{align} This question was raised here where it was also pointed out that the bound is almost there but not correct.  The proof by induction was also suggested, but I am not sure how to do that.","['derivatives', 'real-analysis', 'analyticity']"
2371688,What happens if a function is not measurable? Definition aside,"That is, what would be the motivation for mathematicians to restrict their condition to only measurable functions. Desire for integrability is one. What else?","['real-analysis', 'probability', 'measure-theory']"
2371695,Is it true that the weak closure of $\pi(A)$ is the whole of $B(H_{\tau})$?,"I have this question: Is it true that if $\tau$ is a pure state on a $C^*$-algebra $A$ and $(H_{\tau},\pi)$ is the GNS represenation of $A$ with respect to $\tau$, then is it true that the weak closure of $\pi(A)$ is the whole of $B(H_{\tau})$? What do I have to show for this, if this is true? I just am confused on how to proceed for the proof. A hint would do. Thanks for the help!!","['c-star-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras', 'analysis']"
2371698,Why isn't the approach of measurable functions (almost) duplicated in the approach to computable functions?,"Here are the definitions of computable .  There seems to be no direct analogy to measurable functions.  Why can't we make similar definitions to measurable (for computable )?  By that I mean, perhaps the set operations are exchanged for others or added to. For example.  Clearly any finite union of computable sets would also be computable, as well as the elementwise summation over the sets. I think computability should be about construction not decidability.  Then a set $A$ is computable in the traditional sense if $\chi_A$ is constructible.","['computability', 'measurable-functions', 'measure-theory', 'computer-science']"
2371700,"Showing that the event: $X$ is continuous on $[0,t_0)$ belongs to the given filtration. [duplicate]","This question already has an answer here : Show that a certain set is measurable (1 answer) Closed 6 years ago . Let $( \Omega, F, P)$ be a probability space. Let $X$ be a stochastic process defined on such probability space whose sample paths are RCLL (right continuous on $[0, \infty)$ with finite left hand limits on $(0, \infty)$. Let $A$ be the event that $X$ is continuous on $[0,t_0)$. I am tasked in showing that $A \in F^X_{t_0}$, where $F^X_{t_0}:= \sigma(X_s ; 0 \le s \le t) = \{ \{ X_s \in B \}\subset \Omega : B \in \mathcal{B}(\Bbb{R}),  0 \le s \le t  \}$ Some may recognize this exercise as one of the first from Brownian Motion and Stochastic Calculus by Karatzas and Shreve, I am in fact trying to self study this book through august. My problem here is that I can't figure out exactly what $A$ represents, I know that for a fixed $w \in \Omega$ I have that  $X_s(w)$ is RCLL but I can't figure out how to start.","['stochastic-processes', 'probability-theory', 'stochastic-calculus']"
2371738,Tricky Sum involving Binomial Coefficients and Sine,"I am stumped by the sum
$$\sum_{x=0}^n \binom{n}{x}\sin\big(\frac{\pi x}{n}\big)$$
but I can't figure it out. I tried expanding the taylor series of sine and using Euler's identity, but to no avail. Any hints? PLEASE do not give me a full solution - I just need a hint. Thanks!","['binomial-coefficients', 'summation', 'trigonometry']"
2371784,Calculating Trump's Approval Rating for Non-Republicans,"My father asked me this question yesterday, and as a math major I was a little embarrassed that I was not immediately sure that the answer I obtained was correct. He asked: If President Trump's overall approval rating is 38% among 125 million total voters, and the approval rating among the 56 million republican voters is 80%, then what is the approval rating of the other 69 million non-republican voters? Is this a weighted averages sort of problem? I set up my equation as: $$0.448\times 0.8 + 0.552 \times x = 0.38$$ Thus $$x= 0.039$$ giving an approval rating of 3.9%. Is this correct?",['algebra-precalculus']
2371807,Linear independence of Galois conjugates,"Suppose we have an irreducible degree $n$ polynomial in $\mathbb{F}_{q}[x]$ whose roots
$$ \alpha, \alpha^q, \alpha^{q^2}, \dots, \alpha^{q^{n-1}} $$
over the extension field $\mathbb{F}_{q^n}$ do not form a normal basis. If we consider the roots as elements of the vector space over $\mathbb{F}_q$ with basis $\{1,\alpha,\alpha^2,\dots,\alpha^{n-1}\}$, is there a minimum number of these roots which must be linearly independent? For example, take $f(x)=x^3+2x+1$. Over $\mathbb{F}_{3^3}$ viewed as a vector space with basis $\{1,\alpha,\alpha^2\}$, the set of roots $\{\alpha,\alpha^3\}$ is linearly independent but once we add the third root, we find that $\alpha^{3^2} = 2\alpha+2\alpha^3$.","['finite-fields', 'abstract-algebra', 'extension-field', 'field-theory']"
2371824,Counting : Fault in understanding,"There is this example in my text for counting, and I understand the solution they have given. But I can't seem to find the mistake in my initial understanding which gives a different solution which I know must be wrong. I think it is important I understand where my intuition went wrong. Q Each user on a computer system has a password, which is six to eight characters long, where each character is an uppercase letter or a digit. Each password must contain at least one digit. How many possible passwords are there? My solution was $(10 \cdot 36^5) + (10 \cdot 36^6) + (10 \cdot 36^7)$ where I thought that if I kept one slot for only digits,giving 10 choices for it,the rest of the slots could have 36 choices each. The correct solution : $P6 = 36^6 − 26^6 = 2,176,782,336 − 308,915,776 = 1,867,866,560$ Similarly, we have $P7 = 36^7 − 26^7 = 78,364,164,096 − 8,031,810,176 = 70,332,353,920$ and $P8 = 36^8 − 26^8 = 2,821,109,907,456 − 208,827,064,576 = 2,612,282,842,880$ Consequently, $P = P6 + P7 + P8 = 2,684,483,063,360$ Please help me understand where my solution is wrong? P.S. I found this SO question , but the answers didn't quite help understanding my fault except the one by Mark but I need more clarification but not enough rep to comment there.","['combinatorics', 'discrete-mathematics']"
2371916,How can I find an injective resolution for the canonical line bundle on $\mathbb{P}^n$?,"I want to learn how to compute examples of dualizing complexes and it seems like the first step in this direction is learning how to construct an injective resolution for $\omega_{\mathbb{P}^n}$. This is because we can define the dualizing complex as
$$
\omega_X^\bullet =\mathcal{RHom}_{\mathbb{P}^n}(\mathcal{O}_X,\omega_{\mathbb{P}^n})
$$
Are there constructive methods for doing this ""by hand""? I am mainly interested in cases which are not cohen-macaulay, hence the shifted dualizing sheaf does not work. For example, consider the quasi-projective variety
$$
X = \text{Proj}\left(\frac{\mathbb{C}[x,y,z,x]}{(x)(y,z)} \right)
$$
which is a copy of $\mathbb{P}^2$ intersecting a copy of $\mathbb{P}^1$ at a point. What is it's dualizing complex?","['derived-categories', 'derived-functors', 'homological-algebra', 'algebraic-geometry']"
2371955,Question on homeomorphism,"Let $K=[0,1]^n$. Let $L\subset\mathbb{R}^n$ be a set homeomorphic with $K$. Choose $a$ in the interior of $K$, $b$ on the boundary of $L$. Then can $K\setminus \{a\}$ and $L\setminus \{b\}$ be homeomorphic?",['general-topology']
2371956,Curve for which Part of Tangent bisected at point of Tangency,"To find the curve for which the part of tangent cut-off by the axes (the portion of the tangent between the coordinate axes) is bisected at the point of tangency. Let $\dfrac{x}{a} + \dfrac{y}{b} = 1$ be the tangent. It cuts the axes at $(a,0)$ and $(0,b)$. So the mid point of the part of tangent cut-off by the axes is $(\dfrac{a}{2},\dfrac{b}{2})$. The slope of this tangent is $\dfrac{-b}{a}$. $(Since\ y = \dfrac{-b}{a}x + b).$ Let the slope of the required curve at point $(x,y)$ given by $\dfrac{dy}{dx} = f(x,y)$. So we can say that $f(\dfrac{a}{2},\dfrac{b}{2}) = \dfrac{-b}{a} \Rightarrow f(\dfrac{a}{2},\dfrac{b}{2}) = \dfrac{-b/2}{a/2} \Rightarrow f(x,y) = \dfrac{-y}{x}$. Now $f(x,y) = \dfrac{dy}{dx} = \dfrac{-y}{x} \Rightarrow \dfrac{dy}{y} = -\dfrac{dx}{x} \Rightarrow \log(y) = -\log(x) + \log(c) \Rightarrow xy = c$. Is this the correct way to proceed? Any other ideas?","['tangent-line', 'ordinary-differential-equations', 'calculus']"
2371963,Probability about switching choices,"This question is similar to the Monty Hall problem, but this problem I don't understand: There are $99$ doors where $33$ doors have cars and $66$ have goats, and you can only choose one door to win a car. After you make your choice, $33$ other doors are opened to reveal goats. Does your probability of winning a car increase if you decide to switch your door choice? So obviously in the beginning your one door has a $\frac{33}{99}$ or $\frac{1}{3}$ chance of having a car. But I can't tell if switching doors in this case will be better or not, since we don't know what the groupings of the doors are (otherwise we would've won by knowing which group the $33$ cars are in).","['monty-hall', 'probability']"
2371965,Isometries of $\mathbb C^2$,"I have studied isometries of the Euclidean plane $\mathbb R^2$ but am trying to understand what happens when we study $\mathbb C^2$ (over $\mathbb C$) instead. In particular, I would like to see if a certain way of decomposing (uniquely) an isometry of the plane has some nice analogue in $\mathbb C^2$. 
To this end, I decided to generalize the notions of translation, rotation (about $\vec 0$), and reflection about the $x$-axis to get the following conjecture. Given an isometry $\mathcal I$ of $\mathbb C^2$ (under the metric induced by the norm $\|(z,w)\|^2=z\bar{z}+w\bar{w}$), we have that
  $\mathcal I= T_{\vec v}\circ O\circ R$ for some translation $T$ by $\vec v$, some
  orthogonal transformation $O$, and some map $R$ which denotes either
  the reflection $F:(z,w)\mapsto (z, \bar{w})$ or the identity $I$. My initial thought-process is as follows. Set $\vec x =\mathcal I(\vec 0)$. Then the translation in the desired decomposition would be $T_{\vec x}$. Moreover, notice that the map $A:=T_{-\vec x}\circ \mathcal I$ is linear. If $\det A>0$, then set $O=A$. Otherwise, we need $O$ to be something else. An intuitive choice is to set $O=AF$ in this case. But $F$ is not linear considered as map on $\mathbb C^2$ over $\mathbb C$.
However, $F$ is linear as a map on the four-dimensional space $\mathbb R^4$--that is, as the map $(a,b,c,d)\mapsto (a,b,-c,-d)$. And this should be fine, as I think that we can adjust the other maps easily to maps on $\mathbb R^4$. Now, here are my questions. (1) Since I want $O$ to be orthogonal, is there a relatively easy way to show that $A$ or $AF$ (depending on the case) is orthogonal? I am unsure how to write down the matrix representations of these maps. (2) And of course, I haven't shown the details of the actual proof of my conjecture. I just have been able to outline what I think should be the case. But I see no way of getting from the fact that $\mathcal I$ is distance-preserving to the fact that it can be decomposed in the way described. I have vaguely tried to play around with the eigenvalues for $O$, which I know should be complex conjugate pairs with norm $1$. But is it problematic if none of these is real, considering that we're technically using $\mathbb R^4$ and no longer $\mathbb C^2$? And to be honest, I am not sure anyway how studying the eigenvalues would help me with the proof ultimately. Could someone please help me with my efforts so far?","['isometry', 'euclidean-geometry', 'geometry', 'orthogonal-matrices', 'linear-algebra']"
2371991,Classification of Principally polarized abelian surface.,We know that a principally polarized abelian surface is either the Jacobian of a smooth curve of genus 2 or  the canonically polarized product of two elliptic curves.  Can anyone suggest me proof of that.,"['abelian-varieties', 'algebraic-geometry']"
2371993,Showing the existence of an unbounded solution to a periodic system of ODE,"We consider the system
$$
\begin{pmatrix} x \\ y\\ z\end{pmatrix}'
= \begin{pmatrix} \cos^4(t) && 0 && -\sin(2t) \\ \sin(4t) && \sin(t) && -4 \\ -\sin(5t) && 0 && -\cos(t) \end{pmatrix} \begin{pmatrix} x \\ y\\ z\end{pmatrix}.
$$
I'd like to show it has at least one unbounded solution. Since it's $2\pi$-periodic, I can use Floquet theory. I know what I have to show is that it has a characteristic exponent $\lambda$ with positive real part, since then $e^{\lambda t}p(t)$ will be a solution to the ODE where $p(t)$ is a non-vanishing $2\pi$-periodic function. This solution will go to infinity as $t\to \infty$, hence will be unbounded. The main issue is that I'm not sure how to compute the monodromy matrix. The matrix in the ODE doesn't look too nice, so I don't think I could compute a fundamental matrix directly. Any suggestions? Also, are there any standard tricks on how to find a monodromy matrix if a fundamental matrix is too hard to compute?",['ordinary-differential-equations']
2372001,Hessian Matrix And Gauss Curvature Example,"The connection between is written in wikipedia : ""We represent the surface by the implicit function theorem as the graph of a function, $f$, of two variables, in such a way that the point $p$ is a critical point, i.e. , the gradient of $f$ vanishes (this can always be attained by a suitable rigid motion). Then the Gaussian curvature of the surface at $p$ is the determinant of the Hessian matrix of $f$ (being the product of the eigenvalues of the Hessian)."" I am searching for an example to better understand it.",['differential-geometry']
2372010,double integral integrand and region,"Find the volume of the cylinder with base as the  disk of unit radius i the $xy$ plane centred at $(1,1,0)$ and the top being the surface $z=\left[(x-1)^2+(y-1)^2\right]^{3/2}$.
I set up the integral as $$\int\int_C\int_{0}^{\left[(x-1)^2+(y-1)^2\right]^{3/2}}dzdydz$$
$$\implies \int\int_C[(x-1)^2+(y-1)^2]^{3/2}dydx$$
$C=\{(x,y):(x-1)^2+(y-1)^2=1\}$ Hence the integral becomes
$$\int_0^{2\pi}\int_0^1r^4drd\theta$$
Is this correct?","['multivariable-calculus', 'change-of-variable', 'definite-integrals', 'polar-coordinates']"
2372027,What is the rank of the Baer-Specker group $\prod\limits_{n\in\mathbb{N}} \mathbb{Z}$,"Most of the question is said in the title: Is it known what the rank of $\prod\limits_{n\in\mathbb{N}} \mathbb{Z}$ i.e. the dimension of  $\mathbb{Q}\otimes\prod\limits_{n\in\mathbb{N}} \mathbb{Z}$ as a $\mathbb{Q}$-vector-space is? Surely it is infinite but it is uncountable and if so, does one know uncountable of which cardinality? I know that $\hom_\mathbb{Z}(\prod\limits_{n\in\mathbb{N}} \mathbb{Z},\mathbb{Z})\cong\bigoplus\limits_{n\in\mathbb{N}}\mathbb{Z}$, is this already enough to conclude that the rank is countable?","['abstract-algebra', 'group-theory']"
2372067,Locally nontrivializable bundles,"Suppose we define two types of bundles, (1) a triple $(E,\pi,B)$ of two topological spaces $E$ and $B$, and a continuous surjective map $\pi : E \to B$, such that all fibres $F_b = \pi^{-1}(\{b\})$ (for $b \in B$) are pairwise homeomorphic, and (2) a triple $(E,\pi,B)$ of two smooth manifolds $E$ and $B$, and a smooth surjective map $\pi : E \to B$, such that all fibres $F_b = \pi^{-1}(\{b\})$ (for $b \in B$) are pairwise diffeomorphic. We say that a bundle allows a local trivialization if each $b \in B$ has a neighbourhood $O \subseteq B$ and an isomorphism (homeomorphism, diffeomorphism) $\phi : O \times F_b \to \pi^{-1}(O)$ such that $\pi \circ \phi (p,f) = p$ for any $p \in O$ and any $f \in F_b$. The question is: Are there examples of bundles of type (1) or type (2) which don't allow local trivializations? In other words, what could go wrong ?","['general-topology', 'fiber-bundles']"
2372091,Definition of regularity in PDE theory,"I'm studying a course in PDE theory and we talked a lot about ""regularity"". However, we never gave a precise definition about what ""regularity of weak solutions"" is. Also a search on the web didn't clarify for me what regularity exactly is. Somehow I think that we want to find out how smoothly the weak solutions of a PDE behave, i.e. if a solution is $C^\infty$ for instance. My question is: Can someone pin down what people think about, when they talk about ""regularity of weak solutions""? Thanks!","['functional-analysis', 'real-analysis', 'soft-question', 'partial-differential-equations']"
2372100,Proving an operator from $\ell^\infty \to \ell^\infty$ is invertible,"(Just to fix some notation, $\ell^\infty = \ell^\infty(\mathbb{N\cup \{0\}},\mathbb{C})$ in what follows) Let $S:\ell^\infty\to\ell^\infty$ be the left shift operator and let $A:\ell^\infty\to\ell^\infty$ be the the multiplication by the element $a\in \ell^\infty$. 
In other words we have that $S(x)_n = x_{n+1}$ and $A(x)_n=a_n x_n$. Suppose that $a\in \ell^\infty$ satisfies
$$(1)\quad \quad |\Pi_{k=0}^{n-1}a_{j+k}|\leq c\alpha^n \ \ \forall j\geq 0$$ 
where $c>0, \alpha \in (0,1)$.
My problem is the following: Prove that $I-AS$ is invertible ($I$ is the identity operator). Unfortunately $\|AS\|_{\mathcal{\ell^\infty}}= \|a\|_{\ell^\infty}$ that can be greater than $1$ so we cannot exploit the Neumann series to define the inverse. I managed to prove, though, that $I-AS$ is injective, indeed if $y = AS y$ then we would have (by $(1)$) that 
$$y_n = a_n y_{n+1} = a_n a_{n+1}\dots a_{n+N} y_{n+N+1}\leq ||y|||_{\infty}\Pi_{k=0}^{N}a_{n+k}|\leq ||y|||_{\infty} c\alpha^{N+1} $$
for any $N>0$ thus taking the limit $y_n = 0 $ for any $n$. Now this would be sufficient to conclude if for example we manage to prove that $AS$ is a compact operator. But this is not the case since the image of the unit ball through $S$ is the ball itself and $A$ is not compact (for example consider a sequence $a$ such that $a_{2n} = 0$ $a_{2n+1}=1$ so that condition $(1)$ is satisfied). The only way I see to solve this problem is therefore to prove that $I-AS$ is surjective or maybe that is Fredholm of index $0$.
And here I got stuck since I tried to write the inverse  obtaining
$$ (I-AS)^{-1}(y)_n = y_n + \sum_{k\geq 0} a_{n+k} y_{n+k+1}$$ 
but I don't see a way to exploit relation $(1)$ to prove the series is convergent.","['functional-analysis', 'lp-spaces', 'banach-spaces', 'operator-theory']"
2372103,Solving the following problem of convexity,"Let $E$ be a complex Hilbert space. Let $A=(A_1,\cdots,A_d)\in \mathcal{L}(E)^d$. Consider
\begin{eqnarray*}
W_{max}(A)
&=&\{\alpha\in \mathbb{C}^d:\;\exists\,(z_n)\subset E\;\;\hbox{such that}\;\|z_n\|=1,\displaystyle\lim_{n\rightarrow+\infty}\langle A_j z_n,z_n\rangle=\alpha_j,\\
&&\phantom{++++++++++}\;\hbox{and}\;\displaystyle\lim_{n\rightarrow+\infty}\|A_jz_n\|\rightarrow \|A_j\|,\;\forall j=1,\cdots,d \}.
\end{eqnarray*}
It is well known if $d=1$, we have $W_{Max}(A)$ is convex. If $d\geq2$, is $W_{Max}(A)$ convex?? Thank you for your help.",['functional-analysis']
2372131,Evaluating $\iiint_V x^2 dxdydz$ Over a Spherical Sector,"Triple Integral of $$I=\iiint_V x^2 dxdydz$$ where $V=\{(x,y,z) | y\le x, x\ge0, y\ge0, z\ge0, x^2+y^2+z^2\le1\}$. And I set it as $$I=\int_0^1 x^2\int_0^x\int_0^{\sqrt{1-x^2-y^2}}dzdydx$$ and first integrate $dz$ then use polar co-ordinate for $dy$ and $dx$, changing them to $rdrd\theta$. Am I setting the integral right?","['multivariable-calculus', 'integration', 'definite-integrals']"
2372182,What does it mean to integrate with respect to a measure?,"I haven't had measure theory, but now I stumbled on integration with respect to a specific measure, and now I'm confused. $$\int \mathrm{d}x$$ or $$\int \mathrm{d}\mu(x)$$ What is meant here is that the infinitesimal amount $\mathrm{d}x$ implicitly understood as the Lebesgue measure of $x$ can be understood with any kind of measure $\mu$ . How does this reflect the integration, if I, for instance, want to integrate $x^2$ with respect to another measure other than Lebesgue? Of course, I've tried to google my way through, but the basic notion is confusing to me.","['lebesgue-measure', 'measure-theory']"
2372208,"In a locally path connected space, every open connected subset is path connected","I know this has a solution here: Showing that every connected open set in a locally path connected space is path connected But I would like to see if there is a fault in this simpler proof: Let $C \subset X$ be open and connected. I know that every path component of $C$ is open in $X$ by the fact that $X$ is locally path connected. Since the path components of $C$ form a disjoint partition of $C$, and since they are open in $X$, and since $C$ is non empty, $C$ must equal one and not more of those path components. So $C$ is path connected.","['general-topology', 'proof-verification']"
2372240,"If $f:X \rightarrow \Bbb{K}$ is a linear functional,then $\textbf{Ker}(f)$ is a maximal subspace of $X$?","Let $f$ be a linear functional on vector space $X$. $K$ is a Field which can be $\Bbb{R}$ or $\Bbb{C}$. Let $Z(f)$ denote the kernel of $f$ The Maximal subspace of $f$ : $Z$ is said to be a maximal subspace of $X$ if for any subspace $Z_{1}$ with $Z \subset Z_{1} \subset X$ then either $Z = Z_{1}$ or $X = Z_{1}$ definition 2 : $Z$ is a maximal subspace of $X$ $\textbf{iff}$ $\textbf{span}(Z \cup \{a\}) = X$ for any $a \in X\setminus Z$. For $f$ a linear functional on $X$. Now I was thinking to prove that $Z(f)$ is a maximal subspace of $X$. For proving I thought of this- Suppose $Z \neq Z_{1}$ then we need to show that $Z_{1} = X$,but how do I proceed with this? $\textbf{EDIT}:$ Also as pointed out in the comments whether $X$ is finite dimensional or infinite dimensional? So it would be interesting to see if those two case go similarly or are there any different treatment or consequences in the proof of both the cases? Any help is great.","['functional-analysis', 'linear-algebra']"
2372291,ancient principle of mathematics: figure = varying element,"On page 83 in the book Conceptual mathematics by Lawvere et al. it says: An ancient principle of mathematics holds that a figure is the locus of a varying element. What does this quote mean? In particular, what is the ""locus of a varying element"" and in which sense is it the same as a figure?","['category-theory', 'soft-question', 'elementary-set-theory', 'geometry']"
2372297,Solving trigonometric equations,"If we have $$\sin (A) +\cos (A) + \csc (A) + \sec (A) +\tan (A) +\cot (A)= 7$$ and
  $$\sin(2A) =a-b\sqrt{7}= 2\sin(A)\cos(A).$$
  What values can $a$ and $b$ take?","['substitution', 'radicals', 'trigonometry', 'quadratics']"
2372305,"For all $n$, there are integers $x$, $y$, $z$ such that $x^2 + y^2 = z^n$ [duplicate]","This question already has answers here : $x^2+y^2=z^n$: Find solutions without Pythagoras! (2 answers) Closed 4 years ago . Prove that $\forall n \in \mathbb{N},$ there exist integers $x,y,z$ such that $x^2+y^2=z^n$. I know that this is an induction proof, and I am assuming this needs to be broken up into cases where n is even and where n is odd. But how do I even start doing this?","['induction', 'proof-writing', 'discrete-mathematics']"
2372307,What is the reason that $p_i$ does not depend on $i$?,"Consider the following formula : $$p_i=\sum_{j=1}^n\frac{\binom{i-1}{j-1}\binom{n^2-i}{n-j}}{\binom{n^2}{n}},$$ where $i,n$ are positive integer and $i=1,\ldots,n^2$. Suppose there are $n$ boxes (the boxes are labeled with $1,2,\ldots,n$) each containing $n$ balls. The balls in each box are ordered according to their size. The $i$th $(i=1,2,\ldots,n^2)$ smallest ball among all $n^2$ balls is the $j$th smallest ball  $(j=1,2,\ldots,n)$ of a box if and only if  (1) the first $(i-1)$ values contain exactly $(j-1)$ 1's. This can be done in $\binom{i-1}{j-1}$ ways, $(2)$ the $i$th value is a $1$, (3) And therefore there are exactly $(n-j)$ 1's distributed among the remaining $(n^2-i)$ values. This can be done in $\binom{n^2-i}{n-j}$ ways. The total number of ways in which the $n^2$ balls can be randomly allocated to $n$ boxes is $\binom{n^2}{n}$. Then the probability that the $i$th smallest ball among all $n^2$ balls is the  $j$th smallest ball of a box is $$\frac{\binom{i-1}{j-1}\binom{n^2-i}{n-j}}{\binom{n^2}{n}}.$$ We select a ball if it is the $1$st smallest ball of the $1$st box, or  $2$nd smallest ball of the $2$nd box, thus $n$th smallest ball of the $n$th box. It is not possible that the $i$th smallest ball overall was in two boxes, but it had to be in some box. Therefore the event that ""the $i$th smallest ball was in box $j$"", is an exhaustive partition of the possibilities. Consequently there chances add up. Hence the probability that the $i$th smallest ball is selected is $$p_i=\sum_{j=1}^n\frac{\binom{i-1}{j-1}\binom{n^2-i}{n-j}}{\binom{n^2}{n}}.$$ I expected different value of $p_i$ for different $i$. But I was astonished that the $p_i$ is same for all $i$. It seems $$p_i=\sum_{j=1}^n\frac{\binom{i-1}{j-1}\binom{n^2-i}{n-j}}{\binom{n^2}{n}}=\frac{1}{n}.$$ I checked it by calculating $p_i$ for different $n$ such as $2$ or $3$. What is the  reason that $p_i$ does not depend on $i$? Why this complex formula is nothing but a uniform probability?","['probability-theory', 'hypergeometric-function', 'statistics', 'probability', 'uniform-distribution']"
2372327,Check perfect squareness by modulo division against multiple bases,"I am interested in a quick test to see if a number is a perfect square. One good test is to look at how the number ends. In Base-10 , a perfect square ends in 0,1,4,5,6, or 9 . This is helpful because I can trivially filter out numbers that end differently before I need to do more expensive operations. It's also true that in Base-16 , a perfect square ends in 0, 1, 4, or 9 . However, if we look at the non-perfect-square numbers 11 and 17 , we can see 11 passes the Base-10 test, since 11 mod 10 = 1 , but fails the Base-16 test ( 11 mod 16 = 11 ). Likewise, 17 fails the Base-10 test, but passes the Base-16 test. I think this is because 10 has a factor that 16 doesn't have, but I'm not sure. It's easy to see that performing both tests will filter out more numbers than either one on its own, and it stands to reason that there exist more bases which filter out additional numbers. My question is: Why do these two bases test a different set of numbers, and how could I choose a minimal set of bases which filtered out the most numbers? (I realize any method of choosing bases can be extended infinitely, but infinity and quick don't exactly get along. I'm more curious into the theory behind this, and I can discuss a test coverage vs. speed tradeoff in Stack Overflow).",['number-theory']
2372356,Higher-order reflections: differentiable extensions for $C^k(\overline{\mathbb{R}_+})$ functions,"Let  $f \in C^k_b([0,\infty); \mathbb{R})$. We want to extend $f$ to the space $\mathbb{R}$ without loosing regularity and boundedness (thanks zhw. for this observation) , i.e. we want some $F \in C^k_b(\mathbb{R}; \mathbb{R})$ with $F|_{[0,\infty)} = f$. First idea to come into ones mind is to simply reflect, i.e. to set
$$
F(x) = \begin{cases} f(x) &\quad x \geq 0 \\ f(-x) &\quad x < 0\end{cases}
$$ This gives us $F(x) \in C(\mathbb{R}; \mathbb{R})$ but higher derivatives needn't be continuous.
The idea of higher order reflections is to write
$$
F(x) = \sum_{j = 1}^{k + 1} \lambda_j \; f(-jx), \quad (x < 0)
$$
and determine the linear factors $\lambda_j$ such that $D^mF$ is continuous at $x= 0$ for all $m \in \{0,\dots,k\}$. This gives the following set of equations
\begin{align}
f(0) &= F(0) = \sum_{j = 1}^{k + 1} \lambda_j \; f(0) \\
f'(0) &= F'(0) = \sum_{j = 1}^{k + 1} (-j) \lambda_j \; f'(0) \\
&\dots \\
f^k(0) &= F^k(0) = \sum_{j = 1}^{k + 1} (-j)^k \lambda_j \; f^k(0)
\end{align} How would you motivate this procedure? The only references I found so far were this blog post and this other post which are a good start but not completely satisfying. In both posts it is said that to preserve the $C^k$ smoothness, the extension process must preserve polynomials of x of degrees up to $k$ . Could someone elaborate on this fact? Bottom line so far: An extension operator which is a convex combination of ""scaling"" operators"", i.e. some operator
$$
E(u) := \sum_{j = 1}^{k + 1} \lambda_j \; \delta^{-j}(u),
$$
where $\delta^{-j}(u)(x) := u(-jx)$ seems to be an apt candidate for an extension operator that maintains differentiability. Is there some intuition to this? Why would one think this is a good idea, other than making a direct calculation.","['functional-analysis', 'calculus', 'partial-differential-equations']"
2372373,Is the set of sum over a diagram is uncountable set?,"Consider the following diagram: Let $0<x<\frac{1}{2}$ Note that $[.]$ is not box function It is easy to see that $1$ split into $x$ and $(1-x)$ . In next stage $x$ split into $x^2$ and $x(1-x)$ and $(1-x)$ split into $x(1-x)$ and $(1-x)^2$ . Note that I do not write $x(1-x)$ twice, instead of that in this stage we have three values $x^2,x(1-x),(1-x)^2$ . Continue this process in the next stage (see the diagram for more detail) Now comes the important part: Add take $1$ first. Then add either $x$ or $(1-x)$ . If you added $x$ then next add either $x^2$ or $x(1-x)$ and if you added $(1-x)$ then up next add either $x(1-x)$ or $x^2$ . Continue this process again. For example you will get a value $1+\sum_{n=1}^{\infty}x^n$ . Another one could be $1+\sum_{n=1}^{\infty}x(1-x)^{n-1}$ . It depends on which path you choose. Every zigzag path will give you a $\color{red}{\text{different sums}}$ . $\color{red}{\text{different sums}}$ means sum over different zigzag path. Note that $\color{red}{\text{different sums}}$ does not mean two different path always give different values. $\large{F}$ or example $1+(1-x)\sum_{n=0}^{\infty}x^n$ and $1+x\sum_{n=0}^{\infty}(1-x)^n$ are two $\color{red}{\text{different sums}}$ but they yeilds same value $2$ i.e. $1+(1-x)\sum_{n=0}^{\infty}x^n=1+x\sum_{n=0}^{\infty}(1-x)^n=2$ Let say $T_x=\{\text{set of all $\color{red}{\text{different sums}}$ for a given $x$ }\}$ It can be easily seen there is uncountable number of $\color{red}{\text{different sums}}$ . Question : is there uncountable number of distinct elements in $T_x$ for a given $x$ ? Observation: It can be easily seen that minimum element of $T_x$ is $\frac{1}{1-x}$ and maximum element of $T_x$ is $\frac{1}{x}$ . $2\in T_x$ for every $x\in \Big(0,\frac{1}{2}\Big)$ But I could not find a way to prove or disprove uncountability. Any help would be appreciable. $\blacksquare\space\space\blacksquare\space\space\blacksquare\space\space$ Thanks to MANMAID I am attaching a new diagram: Let $0<x<1$","['real-analysis', 'sequences-and-series', 'problem-solving']"
2372382,Showing that no roots of a certain 5th degree polynomial can be written as a sum of cube roots of integers,"Let $f(x) = x^5 +4x^3 +3x^2+2x +7$ and $\alpha\in \mathbb{R}$ be a real root of $f$. Show that there do not exist a positive integer $r\in \mathbb{N}$ and rational numbers $a_1,\dots,a_r \in \mathbb{Q}$ such that $$\alpha = \sqrt[3]{a_1} + \cdots + \sqrt[3]{a_r}$$ I've already shown that $f(x)$ is irreducible in $\mathbb{Q}$ (maybe it is not useful, but at least it was to show that in the previous part of the question). How can I go from here?","['number-theory', 'abstract-algebra', 'field-theory']"
2372386,"Prob. 1, Chap. 6, in Baby Rudin: If $f(x_0)=1$ and $f(x)=0$ for all $x \neq x_0$, then $\int f\ \mathrm{d}\alpha=0$","Here is Prob. 1, Chap. 6, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $\alpha$ increases on $[a, b]$, $a \leq x_0 \leq b$, $\alpha$ is continuous at $x_0$,$f\left( x_0 \right) = 1$, and $f(x) = 0$ if $x \neq x_0$. Prove that $f \in \mathscr{R}(\alpha)$ and that $\int f \ \mathrm{d} \alpha = 0$. My Attempt: As $\alpha$ is continuous at $x_0$, so, given $\varepsilon > 0$, we can find a $\delta > 0$ such that $$ \left\lvert \alpha(t) - \alpha \left( x_0 \right) \right\rvert < \frac{\varepsilon}{4} \tag{*} $$
  for all $t \in [a, b]$ for which $\left\lvert t-x_0 \right\rvert < \delta$. Let $n$ be a natural number such that $n > 2$, and let $P = \left\{ t_0, t_1, \ldots, t_{n-1}, t_n \right\}$ be a partition of $[a, b]$ such that $x_0$ is one of the points of $P$, and such that $\Delta t_j < \frac{\delta}{2}$ for each $j = 1, \ldots, n$. [We have included $x_0$ in $P$ in order to account for the case when $x_0$ is either of the endpoints of $[a, b]$.] Then, for any point $u_j \in \left[ t_{j-1}, t_j \right]$ ($1 \leq j \leq n$), we have 
  $$
\begin{align}
& \left\lvert \sum_{j=1}^n f \left( u_j \right) \left[ \alpha \left( t_j \right) - \alpha \left( t_{j-1} \right) \right] \right\rvert \\ 
&\leq  \begin{cases}  \alpha\left( t_1 \right) - \alpha \left( t_0 \right)  \qquad \mbox{ if $x_0 = a$} \\
\left[ \alpha \left( t_{i+1} \right) - \alpha \left( t_i \right) \right] + \left[ \alpha \left( t_i \right) - \alpha \left( t_{i-1} \right) \right] = \alpha \left( t_{i+1} \right) - \alpha \left( t_{i-1} \right) \qquad \mbox{ if $x_0 \in (a, b)$ and $x_0 = t_i$ for some $i \in \{ 1, \ldots, n-1 \}$} \\
\alpha \left( t_n \right) - \alpha \left( t_{n-1} \right) \qquad \mbox{ if $x_0 = b$}
\end{cases} \\
&< \frac{\varepsilon}{4}. \qquad \mbox{ [ by (*) above ] }
\end{align}
$$
  Thus we can conclude that, for any choice of points $u_j \in \left[ t_{j-1}, t_j \right]$ ($1 \leq j \leq n$), we have 
  $$ - \frac{\varepsilon}{4} \leq \sum_{j=1}^n f \left( u_j \right) \Delta \alpha_j \leq  \frac{\varepsilon}{4}, \tag{0} $$ But 
  $$ L(P, f, \alpha) = \inf \left\{ \ \sum_{j=1}^n f\left( u_j \right) 
\left[ \alpha \left( t_j \right) - \alpha \left( t_{j-1} \right) \right] \ \colon \ u_j \in \left[ t_{j-1}, t_j \right] 
\ \mbox{ for } \ j = 1, \ldots, n \ \right\}, \tag{A}$$
  and 
  $$ U(P, f, \alpha) = \sup  \left\{ \ \sum_{j=1}^n f\left( u_j \right) 
\left[ \alpha \left( t_j \right) - \alpha \left( t_{j-1} \right) \right] \ \colon \ u_j \in \left[ t_{j-1}, t_j \right] 
\ \mbox{ for } \ j = 1, \ldots, n \ \right\}. \tag{B}$$ Here is the link to my post here on Math SE on how we can obtain (A) and (B) Riemann-Stieltjes Upper and Lower Sums as Suprema and Infima So from (0) we can conclude that 
  $$ -\frac{\varepsilon}{4} \leq L(P, f, \alpha) \leq U(P, f, \alpha) \leq \frac{\varepsilon}{4}. \tag{1}$$ Now from (1) we obtain 
  $$ U(P, f, \alpha) - L(P, f, \alpha) \leq \frac{\varepsilon}{2} < \varepsilon; $$
  but as $\varepsilon$ is an arbitrary positive real number, so the last set of inequalities, by virtue of Theorem 6.6 in Baby Rudin, implies that $f \in \mathscr{R}(\alpha)$ on $[a, b]$. Moreover, as 
  $$ \int_a^b f \ \mathrm{d} \alpha = \sup \left\{ \ L(Q, f, \alpha) \ \colon \ \mbox{ Q is a partition of $[a, b]$ } \ \right\} =  \inf \left\{ \ U(Q, f, \alpha) \ \colon \ \mbox{ Q is a partition of $[a, b]$ } \ \right\}, $$ 
  so we must also have 
  $$ L(P, f, \alpha ) \leq  \int_a^b f \ \mathrm{d} \alpha \leq U(P, f, \alpha). \tag{2} $$ So from (1) and (2), we obtain 
  $$ - \frac{\varepsilon}{4} \leq  \int_a^b f \ \mathrm{d} \alpha \leq  \frac{\varepsilon}{4}, $$
  which implies that 
  $$ \left\lvert  \int_a^b f \ \mathrm{d} \alpha  \right\rvert < \varepsilon. \tag{3} $$ But $\varepsilon$ was an arbitrary positive real number. So from (3) we can conclude that 
  $$  \int_a^b f \ \mathrm{d} \alpha = 0, $$
  as required. Is my proof good enough? Or, are there any issues with its logic, rigor, or presentation?","['real-analysis', 'proof-verification', 'integration', 'definite-integrals', 'analysis']"
2372395,"Any known bound on difference between Frobinus norm and 2-norm, especially for a positive definite matrix?","I know the definition of these two norms. Given a matrix ${\bf A} \in \Bbb R^{n\times n}$ or $\Bbb C^{n\times n}$, Frobinus norm $\|{\bf A}\|_F$ is simply the vector 2-norm applied on the vectorized $\bf A$, and $\|{\bf A}\|_2=\max_{{\bf x}:\|{\bf x}\|_2=1}\|{\bf Ax}\|_2$ can be interpreted as the maximum ""stretching"" power of linear operator $\bf A$ on the unit circle w.r.t. vector 2-norm, and it can be shown that $\|{\bf A}\|_2=\sqrt {\max (\sigma({\bf A}^*{\bf A}))}$ where ${\bf A}^*$ is the conjugate transpose of ${\bf A}$, and $\sigma (\cdot)$ denotes the set of all eigenvalues of the matrix. I am curious that if there is any known bound on their difference $|\|{\bf A}\|_F-\|{\bf A}\|_2|$. Especially, if $\bf A$ is positive definite, $\|{\bf A}\|_2$ is the largest eigenvalue of $\bf A$, then in what situation we can use $\|{\bf A}\|_F$ to estimate $\|{\bf A}\|_2$, i.e. the largest eigenvalue?","['matrices', 'numerical-linear-algebra', 'linear-algebra']"
2372404,Example of countably infinite sets that is connected?,"This question arises after the realisation that countable sets and uncountable sets does not necessary differ in the way where the former has gaps while the latter has no gaps. The best topological notion that capture the property of gaps is total disconnectedness. Quoting Wikipedia: A totally disconnected set is a set $S$ where the only connected subsets are the singletons and the empty set. So for example, $\Bbb{Z},\Bbb{N}$ are totally disconnected because they are discrete. $\Bbb{R}$ is connected ""everywhere"" (under the open interval topology) since any intervals cannot be wrote as unions of open intervals without overlapping. whereas $\Bbb{Q}$ is totally disconnected as between any two rationals, we can pick an irrational $r$ and construct open intervals $(-\infty,r)\cup(r,\infty)$ to separate them. Via the proof of this question , the cantor set $\mathcal{C}$ is also totally disconnected as it consists of only endpoints and limit points of said endpoints thus it is totally disconnected, and via the proof here , the p adics $\Bbb{Z}_p$ are also totally disconnected All ordinals, and in general, well ordered sets, are totally disconnected. Take any ordinal $\alpha$ as an example, as shown here , we can take the partitions $\{[0,\beta +1)\cup(\beta,\infty),\beta  \in \alpha\}$ thus the only connected components are the singletons. So we basically have the following table: Therefore: Regardless of whether we accept or reject the axiom of choice, (generalied) continuum hypothesis. Using ZF, do non well ordered countably infinite sets $X$ which has no gaps exists (i.e. can we have a ""countable continuum"", analogous to how $\Bbb{R}$ formed a continuum), if yes what are the examples? If such set cannot exists, what is the theorem that suggests that?","['general-topology', 'set-theory', 'connectedness']"
2372405,Representing polynomials as quadratic forms,"I have the following cubic equation $$x^3-6x^2+11x-6=(x-1)(x-2)(x-3)=0$$ whose solutions are $x=1,2,3$. What if the above equation were represented by quadratic form ? Let $\mathbf x = \begin{bmatrix} x^2 & x & 1\end{bmatrix}^T$. Can the cubic equation above be represented as follows? $$x^3-6x^2+11x-6=\begin{bmatrix}x^2&x&1\end{bmatrix}\begin{bmatrix}0&b&c\\d&e&f\\g&h&-6\end{bmatrix}\begin{bmatrix}x^2\\x\\1\end{bmatrix} = \textbf{x}^T \textbf{A} \textbf{x}$$ There are many possibilities to form matrix $A$. For instance the two matrices below $$\textbf{A}_1 = \begin{bmatrix}0&0.5&0\\0.5&-6&5.5\\0&5.5&-6\end{bmatrix}\quad\quad\quad\textbf{A}_2 = \begin{bmatrix}0&0&0\\1&-3&6\\-3&5&-6\end{bmatrix}$$ Is there any study about finding the homogeneous solution, $\textbf{x}^T \textbf{A} \textbf{x}=0$? Thank you in advance.","['polynomials', 'matrices', 'factoring', 'cubics', 'quadratic-forms']"
2372411,Question about Monty Hall if you already knew a bad door beforehand,"So the setup of the scenario here is exactly the traditional Monty Hall problem. Except, before the game starts, you decide to cheat and open a door and it happens to be a goat. Before you can peek at the two other doors, the game begins, and you pick a door that's not the one you just peeked into (obviously, because you peeked a goat). Here it seems the probability to win a car is $\frac{1}{2}$, because you improved your original $\frac{1}{3}$ chance of winning a car by cheating. Then the game host opens the same door you just peeked at before the game started (knowing it was a goat, like the traditional Monty Hall problem). Is it still a $\frac{2}{3}$ chance of winning the car if you switch, even though you already knew the informatiom beforehand? Or does it still remain $\frac{1}{2}$ because you already knew the information before, so you just screwed yourself out of the better $\frac{2}{3}$ probability by cheating? If you originally picked a door with a goat, then the game host must pick the door you peeked at, because the other door contains the car. In this situation, it doesn't seem like anything changes because you already knew the door the game host opened beforehand by cheating. If you originally picked a door with a car, the game host can open either other door, because they both have goats. If the game host opens the door you did not peek at and reveals a goat, then you know with $100\%$ probability that the door you originally picked contains the winning car. However, if the game host opens the door you peeked at, then it seems like the same situation in the paragraph I described before this one.","['monty-hall', 'probability']"
2372422,Hyperplane intersecting a compact set at exactly one point?,"Let $E$ be a compact subset of $\mathbb{R}^n$. Does there always exist a hyperplane that has exactly one point of intersection with $E$? If not, what is a counterexample? And are there additional properties of $E$ that would make the statement true?","['real-analysis', 'geometry']"
2372436,Is Jacobi Theta function same as Heat Kernel ? How to derive Jacobi Theta from Heat Kernel?,"My understanding is that the Jacobi Theta function is fundamental solution of heat equation: $\displaystyle \vartheta (x,it)=1+2\sum _{n=1}^{\infty }\exp \left(-\pi n^{2}t\right)\cos(2\pi nx)$ The following heat kernel is also fundamental solution of heat equation: $\Phi (x,t)={\frac {1}{\sqrt {4\pi kt}}}\exp \left(-{\frac {x^{2}}{4kt}}\right)$ But I do not see how to expand above heat kernel to get Jacobi Theta function. Can anyone provide some hints on how to expand above heat kernel to get Jacobi Theta function ? Thank you.","['functional-analysis', 'complex-analysis', 'ordinary-differential-equations', 'heat-equation']"
2372440,Let $p$ be a prime and $n$ be a positive integer. Prove that $n! $ divides $(p^n-1)\cdots(p^n-p^{n-1})$,"Let $p$ be a prime and $n$ be a positive integer. Prove that $n! $ divides $$(p^n-1)(p^n-p)(p^n-p^2)\cdots(p^n-p^{n-1})$$
I have checked that it is trivial for $n=3,4$ But cant do the generalised part.
I have also got a group theoretic solution, but I want an elementary number theoretic solution.",['number-theory']
2372458,Prove that there are infinitely many primes ending in either 1 or 9.,"Prove that there are infinitely many primes either ending in 1 or 9. I think a good starting point could be to consider that there are only finitely such primes $p_{1},...,p_{k}$ and consider the number $m = (2p_{1}...p_{k})^{2} - 5$. Not quite sure where to go from here. Any hints or approaches would be appreciated.","['number-theory', 'prime-numbers']"
2372477,The empty set contains irrationals only.,"Is the above statement true; because we can not find any rational in it.
Or false; because it does not contain any irrational. Also is the statement: ""The elements of the empty set are irrationals and no element in it is rational."" true, being vacuous?",['elementary-set-theory']
2372478,Why is the Thomson Problem so hard to crack?,"I read about the Thomson Problem in a Wiki Article ( https://en.wikipedia.org/wiki/Thomson_problem ) The objective of the Thomson problem is to determine the minimum electrostatic potential energy configuration of N electrons constrained to the surface of a unit sphere that repel each other with a force given by Coulomb's law. The physicist J. J. Thomson posed the problem in 1904[1] after proposing an atomic model, later called the plum pudding model, based on his knowledge of the existence of negatively charged electrons within neutrally-charged atoms. Minimum energy configurations have been rigorously identified in only a handful of cases. I was very surprised when I read this because the solutions for the lower cases are very easy. What makes it difficult for scientists to generalize it to $N$ cases? Why is a computer not able to solve this for general $N$ ? Is the Wikipedia Article dubious, especially since it lists solved cases for up to $N=400$ (which are not at all ""handful"") Then the article also lists this strange looking conjecture, According to a conjecture, if $m = n+2$ , $p$ is the polyhedron formed by the convex hull of $m$ points, $q$ is the number of quadrilateral faces of $p$ , then the solution for $m$ electrons is $f(m) = 0^n +3n -q$ Please, is the Thomson problem really tough? If yes, Why?! If no, How has it been solved for arbitrary value of $N$ ?","['3d', 'soft-question', 'geometry']"
2372486,"Prob. 2, Chap. 6, in Baby Rudin: If $f\geq 0$ and continuous on $[a,b]$ with $\int_a^bf(x)\ \mathrm{d}x=0$, then $f=0$","Here is Prob. 2, Chap. 6, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f \geq 0$, $f$ is continuous on $[a, b]$, and $\int_a^b f(x) \ \mathrm{d} x = 0$. Prove that $f(x) = 0$ for all $x \in [a, b]$. My Attempt: Let $c$ and $d$ be any points in $[a, b]$ such that $c \leq d$. As $f(x) \geq 0$ for all $x \in [a, b]$ and as $f$ is continuous on $[a, b]$, so $f(x) \geq 0$ for all $x \in [c, d]$ and $f$ is continuous on $[c, d]$; therefore $f \in \mathscr{R}$ on $[c, d]$ and 
  $$ \int_c^d f(x) \ \mathrm{d} x \geq \int_c^d \hat{0}(x) \ \mathrm{d} x = 0$$
  by Theorem 6.12 (b) in Baby Rudin, where $\hat{0}$ denotes the zero function on $[c, d]$. That is, 
  $$ \int_c^d f(x) \ \mathrm{d} x \geq 0 \tag{0}$$
  for any points $c$ and $d$ such that $a \leq c \leq d \leq b$. Suppose that there is a point $p \in [a, b]$ such that $f(p) >  0$. Then, as $f$ is continuous at $p$, so, for any real number $\varepsilon$ such that 
  $$ 0 < \varepsilon < \frac{  f(p) }{2}, $$
  we can find a real number $\delta > 0$ such that 
  $$ \lvert f(x) - f(p) \rvert < \varepsilon < \frac{ f(p) }{2} $$
  for all $x \in [a, b]$ for which 
  $ \lvert x-p \rvert < \delta$. Therefore, we can conclude that
  $$ \frac{ f(p) }{2} < f(x) < \frac{3 f(p) }{2} \tag{1} $$
  for all $x \in I$, where 
  $$I \colon= [a, b] \cap \left[ p- \frac{\delta}{2}, p+ \frac{\delta}{2} \right]. $$ 
  Let's put $I \colon= [u, v]$. Then we see that 
  $$
\begin{align}
\int_a^b f(x) \ \mathrm{d} x &= \int_a^u f(x) \ \mathrm{d} x + \int_u^v f(x) \ \mathrm{d} x + \int_v^b f(x) \ \mathrm{d} x \\
& \qquad \qquad \mbox{ [ by an extension of Theorem 6.12 (c) in Baby Rudin ] } \\
&\geq \int_u^v f(x) \ \mathrm{d} x \qquad \mbox{ [ by (0) above ] } \\ 
&\geq \int_u^v \frac{f(p)}{2}  \ \mathrm{d} x  \qquad \mbox{ [ using (1) and Theorem 6.12 (b) in Baby Rudin ] } \\
&= \frac{f(p)}{2} (v-u) \\
&> 0, \qquad \mbox{ [ by (2) and our choice of $u$ and $v$ above ] } 
\end{align}
$$
  which contradicts our hypothesis that $\int_a^b f(x) \ \mathrm{d} x = 0$. Is this proof sound enough in terms of its logic and rigor? If so, then is it also lucid enough in its presentation?","['real-analysis', 'proof-verification', 'integration', 'definite-integrals', 'analysis']"
2372503,Let $g(x)$ be analytic on every interval that does not contain $0$ is $f(t)= E[g(X-t)]$ analytic,"Let $g(x)$ be a continuous function that is analytic on every interval of $\mathbb{R}$ that does not contain $0$. An example of such a function is: $e^{-|x|}$. Let $X$ be a random variable and define
\begin{align}
f(t)= E[g(X-t)]
\end{align}
That is we are looking at the convolution integral and suppose that $|g(t)|<c<\infty$ for all $t$. We want to look at analytic properties of $f(t)$ without many assumptions on $X$. I have two question about this: Does $f(t)$ have the same property as $g(t)$? That is $f(t)$ is analytic on every interval of $\mathbb{R}$ except one point. If in addition, we assume that $X$ has an absolutely continuous distribution. Is $f(t)$ analytic everwhere? This question was inspired by a similar question raised here . My attempts I was only more or less able to answer 1). To study this we can fix $t$ and look at
\begin{align}
f(t)=E[g(X-t)]&=E[g(X-t) 1_{X \neq t}]+ E[g(X-t) 1_{X = t}]\\
&= E[g(X-t) 1_{X \neq t}]+  g(0)P[ X = t]. \quad (*)
\end{align} We see from (*) that $f(t)$ is a.e. differentiable.  Moreover, if we assume that $X$ has no atoms then $f(t)$ is differentiable everywhere since $P[X=t]=0$. Let $T=\{t:P[X=t]>0 \}$. Equation(*)  seems to be suggesting that 1) is false if $|T|\ge 2$ and $f(t)$ will not be differentiable for $t$ such that $P[X=t]>0$. Moreover, ,  $T=\{t:P[X=t]>0 \}$  can be a dense set so it appears that $f(t)$ may not be analytic on any neightborhood of $\mathbb{R}$. Unless I am wrong, this appears to be very intersting since I alway thought that convolution makes things ""more"" smooth. However, in this case, things get ""less"" smooth. I would really appreciate if some one can clarify these for me. For 2). It seems that $f(t)$ is infinitely differentiable for all $t$, since $P[X=t]=0$ for all $t$. So, it seem resonable to ask if $f(t)$ is analytic everywhere?","['analyticity', 'real-analysis', 'measure-theory', 'probability-theory']"
2372507,Convex cone generated by extreme rays,"Let $X$ be a vector space and $K \subseteq X$ be a pointed convex cone. Let $L$ denote the set of extreme rays of $K.$ The questions are: under which condition can I guarantee that $$K= cone(conv(L))?$$ Here, $cone(A)=\{\lambda x: x\in A, \; \lambda \geq 0\}$ and $conv(A)$ is the convex hull of $A.$ Any reference that treats this problem? I am particularly interested in the infinite dimensional case. Thanks in advance","['reference-request', 'convex-analysis', 'functional-analysis', 'convex-cone', 'dual-cone']"
2372513,solution set of the inequality $\frac{x^2-1}{(x+2)(x+3)}>2$,"Question: Find the solution set of the inequality $$\frac{x^2-1}{(x+2)(x+3)}>2$$ From the answer given in the previous problem I got this: First $x\neq -2,-3$. solving the equation I get $-(2\sqrt{3}+5)<x<(2\sqrt{3}-5)$. Is this ok?",['algebra-precalculus']
2372520,evans; estimate on derivatives,"I have troubles understanding a certain necessity in Evans' proof of a theorem on the estimates for derivatives of harmonic functions. So consider the following, (this is the same theorem as discussed here , however i am asking a different question) Theorem 7 (Estimates on derivatives).  Assume u is harmonic in U. Then
  \begin{align}
|D^\alpha u(x_0)| \le \frac{C_k}{r^{n+k}} \|u\|_{L^1(B(x_0,r))} \tag{18}
\end{align}
  for each ball $B(x_0,r) \subseteq U$ and each multiindex $\alpha$ of order $|\alpha| = k$. Here 
  \begin{align}
C_0 = \frac{1}{\alpha(n)}, C_k = \frac{(2^{n+1}nk)^k}{\alpha (n)} \text{ for } k=1,2,\ldots \tag{19}
\end{align} Proof. We establish $(\text{18}), (\text{19})$ by induction on $k$, with the case $k=0$ being immediate from the mean value formula $u(x) = \frac{1}{\alpha(n)r^n} \int_{B(x_0,r)} u \, dx = \frac{1}{\alpha(n)r^{n-1}} \int_{\partial B(x,r)} u \, dS$ (which denote average values of $u$ over the ball and sphere, respectively). $$ \, $$ For $k = 1$, we note upon differentiating Laplace's equation that $u_{x_i}$ (for $i=1,...n$) is harmonic. Consequently,
\begin{align}
\left|u_{x_i}(x_0)\right| 
&\le \frac{2n}{r} \|u\|_{L^\infty(\partial B(x_0,\frac{r}{2})}
\end{align}
Now if $x \in \partial B(x_0,\frac{r}{2})$, then $B(x,\frac{r}{2}) \subseteq B(x_0,r) \subseteq U$, and so
\begin{align}
|u(x)| \le \frac{1}{\alpha(n)} \left(\frac{2}{r}\right)^n \|u\|_{L^1(B(x_0,r))}
\end{align}
by (18), (19) for $k=0$. Combining the inequalities above, we get
\begin{align}|D^\alpha u(x_0)| &\le \frac{2^{n+1}n}{\alpha(n)} \frac{1}{r^{n+1}} \|u\|_{L^1(B(x_0,r))} \\
&= \frac{2^{n+1}n}{r^{n+1}} \|u\|_{L^1(B(x_0,r))} \\
\end{align}
if $|\alpha| = 1$. This verifies $(\text{18})$ and $(\text{19})$ for $k = 1$. $$\,$$ Now in the induction step we proceed analogously: assume $k \geq 2$ and (18), (19) are valid for all balls in $U$ and each multiindex of order less than or equal to $k-1$. Fix $B(x_0,r) \subset U$ and let $\alpha$ be a multiindex with $|\alpha| = k$. Then $D^\alpha u = (D^\beta u)_{x_i}$ for some $i \in \{1, \cdots,n\}$, $|\beta|=k-1$. By calculations similar to those in (20) we establish that $$|D^\alpha u(x)| \leq \frac{n\,k} r \, \|D^\beta u\|_{L^\infty(\partial B(x_0,\frac r k))}.$$ If $x \in \partial B(x_0,\frac r k)$ then $B(x,\frac {k-1} k \, r) \subset B(x_0,r) \subset U$. Thus (18), (19) for $k-1$ imply $$|D^\beta u(x)| \leq \frac{(2^{n+1} \, n \, (k-1) )^{k-1} } {\alpha(n) \, (\frac{k-1} k \, r)^{n+k-1} } \, \|u\|_{L^1(B(x_0,r))}.$$
Now combine the two results to conclude the theorem. Question Why don't we just use $\frac r 2$ (as before) instead of $\frac r k$ in the induction step? What is the use of $\frac r k$? I don't see any reason why $\frac r 2$ wouldn't work. Im very glad for any thoughts on this!","['derivatives', 'real-analysis', 'partial-derivative', 'partial-differential-equations']"
2372522,Sum of $k^\text{th}$ Powers of the First $n$ Natural Numbers is a Perfect Square.,"Question: If for some $k$ and $\forall$ $n>2017, n\in \mathbb{N}$ , there exist an $x\in \mathbb{N}$ such that $$1^k+2^k+3^k+\cdots+n^k=x^2$$ then $k=3$ . Minor clarification: The question says : $\forall n$ . Now, we know that $1^3+2^3+..+n^3=\left(\frac{n(n+1)}{2}\right)^2$ . But, for all $n\in \mathbb{N}$ and $n>2017$ , you won't get some positive integer $x$ such that $1^k+2^k+\cdots+n^k=x^2$ . You will get such $x$ only when $k=3$ . I don't think there's any particular significance of $2017$ here. How do we even start this? It looks so weird. How to proceed after that? My idea is to use: $$\sum_{x=0}^n (x+1)^{k+1}-x^{k+1}=n^k \left({k \choose 0} + {k-1 \choose 0} + \cdots + {0 \choose 0}\right) + n^{k-1} \left({k \choose 1} + {k-1 \choose 1} + \cdots + {1 \choose 1}\right) + \cdots + n^{k-k}\left(k\choose k \right)$$ . The $\text {LHS}$ equals $\left(n+1\right)^{k+1}-1$ . And we have the $1^k+2^k+3^k+\cdots+n^k$ term in the $\text {RHS}$ But I don't know if  his helps to show that the sum of the $k^\text {th}$ powers will be a non perfect sqaure $\forall n>2017$ We can also do something like this-
If $1^k+2^k+\cdots+n^k=x^2$ , then $x^2+(n+1)^k=y^2$ . And then, $y^2+(n+2)^k=z^2$ and so on.
First of all, is $a^2+n^k=b^2$ possible for all $n>2017$ (though $2017$ hasn't got any special significance) and for a particular $k$ (and needless to mention, $a,b$ are not constants since $n$ is variable)? But, how do we show that it won't hold unless $k=3$ ?","['number-theory', 'elementary-number-theory']"
2372557,Hessian does not depend of the curve we choice.,"I am trying to understand why the hessian of a function from a surface in $\mathbb{R}$, $\left. \frac{d^2}{dt^2} \right\rvert_{0} (f \circ \alpha)(t)$ does not depend of $\alpha$. In my book you can see: ($\alpha(t)=X(u(t),v(t)),  X$ is a parametrization of the surface )
$$\left. \frac{d^2}{dt^2} \right\rvert_{0} (f \circ \alpha)(t)= \left. \frac{d^2}{dt^2} \right\rvert_{0} (f \circ X)(u(t), v(t))=\left. \frac{d}{dt} \right\rvert_{0} ((f \circ X)_u \dot\ u'(t)+(f \circ X)_v \dot\ v'(t))=$$
$$[(f \circ X)_{uu} \dot\ u'(0)+(f \circ X)_{uv} \dot\ v'(0)]\dot\ u'(0)+(f \circ X)_{u} \dot\ u''(0) + [(f \circ X)_{vu} \dot\ u'(0)+(f \circ X)_{vv} \dot\ v'(0)]\dot\ v'(0)+(f \circ X)_{v} \dot\ v''(0)$$
And now it says that $(f \circ X)_{u} \dot\ u''(0)+(f \circ X)_{v} \dot\ v''(0)=0 $  since the point we are working on is a critical point. I do not understant this last equality. Any suggestion?",['differential-geometry']
2372566,Is a function analytic iff it has antiderivative?,"Fundamental theorem of line integral states that for any function $f$ that has an antiderivative $F$, integrating $f$ from point $a$ to point $b$ yields $F(b) -
 F(a)$, which would imply integration over a closed path yields $0$; However, Cauchy theorem requires the function to be analytic to guarantee $0$ on closed path integration. So does this mean any function that has primitive function $F$ will automatically be analytic and vice versa?","['complex-analysis', 'analytic-functions', 'calculus']"
2372631,Guessing a number,"Find the number $n$ which has exactly $3$ prime divisors: $3$, $5$, and $7$, and has $4$ divisors that are powers of $5$. Moreover, $n$ has as many divisors that are powers of $3$ as there are divisors that are powers of $7$. Finally, $24$ divisors of $n$ are multiples of $3$. What I understood is that $5$, $25$, $125$ and $625$ are the divisors of $n$. But do $7$ and $4$ have the same power in the prime factorization of $n$?","['number-theory', 'modular-arithmetic', 'discrete-mathematics']"
2372637,"If $g'(x)$ is constant, what is the fifth derivative of $f(g(x))$?","I just need some clarification about how to solve and approach this problem, we did it in a Calc 1474 class but I didn't understand how to approach and solve it.","['derivatives', 'contest-math', 'calculus']"
2372639,Left adjoints to some inclusions of categories of topological spaces,"Let us note $\textbf{Top}_{n}$ for the full subcategory of all $T_n$-spaces $n=0,...,4$. Construct left adoints to the inclusion functors $\textbf{Top}_{n+1}\rightarrow \textbf{Top}_n$ for $n=0,...,3$. I can ""solve"" the cases $n=0,1,2$ using the adjoint functor theorem, but $\textbf{Top}_4$ is not as nice a category as the others (it does not have products, or, at least, the inclusion functor does not preserve them) and, therefore, I cannot use the adjoint fucntor theorem. Plus, the phrasing of the problem hints at an explicit construction of these left adjoints. Hence, my question is how do I construct the left adjoints to these functor explicitly? NB: This is problem V.9.4. from Mac Lane.","['category-theory', 'general-topology', 'adjoint-functors', 'separation-axioms']"
2372659,An equation for prime numbers $\frac{p-1}{2}(2^p-1)+1=7k^2$,"If $2^p-1$ is a Mersenne prime, and $k$ is an integer, then solve 
  $$\frac{p-1}{2}(2^p-1)+1=7k^2$$ $$$$
If I take modulo $p$ I get $1 \equiv 14k^2 \pmod{p}$. If I take modulo $q=2^p-1$ I get $1 \equiv 7k^2 \pmod{q}$. Can I use these to solve the equation? Please help me.","['number-theory', 'prime-numbers', 'diophantine-equations', 'elementary-number-theory']"
2372669,Partitions that separate all subsets,"Let $A=\{1,2,\dots,n\}$ and let $\mathcal{A}_1,\dots,\mathcal{A}_k$ be partitions of $A$ into two sets. Suppose that for each subset $B\subseteq A$ of even size, there exists a partition $\mathcal{A}_i$ such that half the elements of $B$ is in one part of the partition and the other half is in the other part. What is the minimum possible $k$ for which this is possible? An asymptotic bound for $k$ would already be good enough. For example, can we use just $k=O(n)$ partitions? Or even some polynomial in $n$ partitions? If we only consider subsets $B$ of size two, then we can do it with $\log n$ partitions by writing each element of $A$ in base two and have $\mathcal{A}_i$ be the partition according to whether the $i$th digit is $0$ or $1$. However this does not work when $B$ is of arbitrary size: For example among the four numbers $001,010,011,111$, none of the digits has $0$ and $1$ appearing twice each.","['combinatorics', 'extremal-combinatorics']"
2372686,What's the correct analog of the (damped) spring for SO(3)/quaternions?,"The traditional (linearly) damped spring is modeled via a standard second-order differential equation: $\ddot{\bf x}(t)+a\dot{\bf x}(t)+b{\bf x}(t)=0$; this can be 'recentered' by letting ${\bf x}(t)={\bf y}(t)-{\bf y_0}$.  With appropriate coefficients (particularly for critical damping, where the equation takes on a doubled eigenvalue), this can be used as an 'ease-in' to a specific target position $\bf y_0$. The same notion — easing-in to a target value — obviously makes sense on $SO(3)$, but the equation itself doesn't: if one takes e.g. the usual quaternionic embedding in $\mathbb{R}^4$ then this equation doesn't guarantee uniticity of $\mathbb{x}(t)$, and if instead one tries to work on the sphere proper, it's not clear to me how one can take what amounts to a 'second-order tangent bundle' here. What would the appropriate mathematical representation of a second-order differential equation like this on the sphere (or presumably on any other manifold, though $SO(3)$ and particularly its quaternion representation is the specific case I'm interested in from a computational standpoint) be?","['quaternions', 'mathematical-physics', 'mathematical-modeling', 'ordinary-differential-equations', 'differential-geometry']"
2372722,Does the series $\sum_{n=2}^{\infty}{\frac{\sin(n^3)}{\ln(n)}}$ converge?,Do you have any idea if the series $\sum_{n=2}^{\infty}{\frac{\sin(n^3)}{\ln(n)}}$ converges? I am totally lost!,['sequences-and-series']
2372736,Computing $\sum\limits_{n=2}^{\infty }\frac{1}{n^3-n}$,I don't understand why I can't get the telescopic sum after the partial fraction decomposition: $$\frac{1}{n^3-n}= \frac{1}{n(n-1)(n+1)}=\frac{-1}{n}+\frac{1}{2(n-1)}+\frac{1}{2(n+1)}=\frac{-1}{n}+\frac{n}{(n-1)(n+1)}.$$ I have $\sum\limits_{n=2}^{\infty }\frac{1}{n^3-n}=\phi(n+1)-\phi(0).$ The answer should be $1/4$.,['sequences-and-series']
2372762,Prove that a function $f:\mathbb R \to\mathbb R$ given by $f(x) = x\left|x\right|$ is a bijection [duplicate],"This question already has answers here : Proving $f(x)=x\cdot |x|$ is a bijection (4 answers) Closed 6 years ago . So I know in order to prove a function is bijective, you need to prove that it is both injective and surjective. I know that to prove it is an injection, I need to make $f(x) = f(y)$, and try to get $x=y$ from that, but I can't seem to manipulate the equations to do so. Also, how would I prove that this is surjective?","['functions', 'discrete-mathematics']"
2372771,Describing all holomorphic functions such that $f(n)=n$ for $n \in \mathbb{N}$,"This question is inspired by a somewhat simpler one . The question is: how can we classify all holomorphic functions $f:\mathbb{C}\rightarrow\mathbb{C}$ satisfying the property $\forall n \in \mathbb{N} \quad f(n)=n $? If we have $g:\mathbb{C}\rightarrow\mathbb{C}$ such that $g\big|_\mathbb{N}\equiv 0$, then $f(z)=z+g(z)$ satisfies the criterion. Conversly, given such $f$ and defining $g(z)=f(z)-z$, we get $g\big|_\mathbb{N}\equiv 0$. So, the question boils down to classifying such $g$. The set $I$ of such $g$, which is $I=\{g:\mathbb{C}\rightarrow\mathbb{C}, g\big|_\mathbb{N}\equiv 0\}$, is an ideal of the algebra of holomorphic functions, so we can ask for its generators. Obviously, $\forall k\in\mathbb{Z}\quad 1-e^{2\pi kz}\in I$, but I am not able to prove that they generate $I$.","['complex-analysis', 'holomorphic-functions']"
2372776,The inverse of triple integrands,"Firstly, I am an engineer by profession and not a student of mathematics. So, my mathematical abilities are severely handicapped. Having said that I could say that indefinite single integrands have inverses. For example, if
$$\int f(x)\mathrm{d}x=g(x)+C$$
Then, I could write
$$f(x)=\frac{\mathrm{d}g(x)}{\mathrm{d}x}$$ I understand that I could write this because 
$$\int f(x)\mathrm{d}x=\int_{C_0}^{x}f(y)\mathrm{d}y=g(x)+C$$
Here in x represents a bound to the integration of the function $f(y)$ and hence the output is a function of that bound {$g(x)$}. But, just as a thought experiment, what about $$\iiint_{V}f(\vec{r})\mathrm{d}^3\vec{r}$$
Here in $V$ is a bound to the function $f(\vec{r})$, so I should be able to write the output as 
$$\iiint_{V}f(\vec{r})\mathrm{d}^3\vec{r}=\rho\left(V\right)$$
Is there an inverse function that when applied on $\rho(V)$ with the knowledge of $V$ gives me back $f(\vec{r})$. I definitely don't know of an inverse function as such. If there isn't, my question is why isn't there one? Is it because, according to your mathemitical senses $f(\vec{r})$ lacks the uniqueness of being the only function which when bound into $V$ would result in $\rho(V)$? Like I said, I'm mathematically illiterate, just saying it again at the risk of sounding like a fool.","['multivariable-calculus', 'calculus', 'vector-analysis']"
2372861,Chern Character of Dual Coherent Sheaf?,"Let $X$ be a $n$ (complex) dimensional variety and let $\mathcal{F}$ be a coherent sheaf on $X$.  Using the sheaf hom which I denote $\mathcal{H}om$, we can define the dual coherent sheaf as $$\mathcal{F}^{\vee} = \mathcal{H}om(\mathcal{F}, \mathcal{O}_{X}).$$ With this definition, I'm hoping someone can explain how to compute the Chern character $\text{ch}(\mathcal{F}^{\vee})$ of the dual sheaf. Given a class $v = \oplus_{i} v_{i} \in H^{*}(X, \mathbb{Q})$, I believe it is standard to define the dual class to be $v^{\vee} = \oplus_{i}(-1)^{i} v_{i} \in H^{*}(X, \mathbb{Q})$.  This is, for example, done in Huybrechts and Lehn.  The motivation behind this definition is supposed to be such that $$\text{ch}^{\vee}(\mathcal{F}) = \text{ch}(\mathcal{F}^{\vee}).$$ Assuming someone can assist me in computing the Chern character of the dual sheaf, will it be consistent with this definition?","['homology-cohomology', 'sheaf-theory', 'algebraic-geometry']"
2372889,Bound of the difference between two converging infinite series,"Let $f(x)$, and $g(x)$ be two functions given by the infinite series : $$f(x)=\sum_{k=0}^{\infty}f_{k}(x)$$
$$g(x)=\sum_{k=0}^{\infty}g_{k}(x)$$
And let the regions of convergence of both series be the same. Furthermore, suppose that : 
$$\lim_{N\rightarrow \infty}(f_{N}(x)-g_{N}(x))=0$$
is there a good way to find the bound : 
$$\left | f(x)-g(x) \right |<a$$","['real-analysis', 'sequences-and-series']"
2372893,Maximum flow problem with flow into two non-adjacent nodes either be simultaneously greater than 0 or all 0s,"I have a directed graph that I want to find a maximum flow. But there are two non-adjacent nodes, say $a$ and $b$, that I want either the flows coming into $a$ and $b$ are simultaneously greater than $0$, or simultaneously $0$. I know max flow algorithm can be extended to edge disjoint, node disjoint and edge demand problems, but the kind of constraint I described above does not seem to have a solution. I tried to add an extra node, say $c$, and then add edges from $a$ to $c$, $b$ to $c$, and $c$ to the sink $t$, and then converted it to some sort of the mentioned extensions, but it seems hopeless. Edit: directed graph, the flow can be integers, but it is not required.","['graph-theory', 'discrete-mathematics']"
2372902,Complex Integration using Cauchy's Theorem,"The problem is the integration of 
$$I=\int_{\left\lvert z-1\right\rvert=1} f(z) dz$$
where 
$$f(z)=\frac{1}{z^3-1}$$
and the path goes $1$ loop in positive direction. I tried to solve the problem using Cauchy's Theorem by finding $z$ that makes $f(z)$ denominator be $0$. That was $z=1$. And I got struck. I think the integral is needed to be treat somehow so that $$\int_{C_a}\frac{1}{(z-\alpha)^n}dz = 2{\pi}i \text{ when } n=1$$ can be used. My question is how should I continue with the integral?","['cauchy-integral-formula', 'complex-analysis', 'complex-integration']"
2372904,Volume of a solid formed by 3 cylinders,"I am trying to find the volume of the solid enclosed by three cylinders given by $x^2+y^2=1$, $x^2+z^2=1$, and $y^2+z^2=1$. I'm supposed to be using a triple integral, and I assume, cylindrical coordinates. So far, I've figured out that I need to evaluate a triple integral of $dV$, which is equal to $rdzdrd\theta$. However, I am having trouble figuring out what bounds to use for $r, \theta, z$. Any assistance or hints with this problem would be greatly appreciated!","['multivariable-calculus', 'integration', 'cylindrical-coordinates']"
2372913,limit of integration after change of variables,"Evaluate $$\int_{0}^{\infty}\int_{0}^{\infty}e^{-(5x^2-6xy+5y^2)}dxdy$$
after applying the change of variables as $$x=u+v~~,y=u-v$$
i got the integral as $$\int\int e^{-4u^2-16v^2}{2}dudv$$
But how do i find the limits of integration?
After seeing the cooments i got the integral set up as $$\int_{-\infty}^{\infty}\int_{0}^{\infty} e^{-4u^2-16v^2}{2}dudv=4\int_{0}^{\infty}\int_{0}^{\infty} e^{-4u^2-16v^2}dudv=4\int_{0}^{\infty}e^{-4u^2}du\int_{0}^{\infty}e^{-16v^2}dv=\dfrac{\pi}{8}$$, 
But when i solve this integral from wolfram it gives $\dfrac{1}{16}\left(\pi+2\tan^{-1}\dfrac{3}{4}\right)$,
i can't find the error in my calculation, can somebody help","['multivariable-calculus', 'change-of-variable', 'definite-integrals', 'gamma-function']"
2372946,Infinite sum and Jacobi Theta function,"I have encountered a sum as following: \begin{equation}
\sum_{n=1}^{\infty} q^{n^2}
\end{equation} \begin{equation}
\sum_{n=1}^{\infty} n^2 q^{n^2}
\end{equation} where $0<q<1$. I know that the first sum is related to Jacobi Theta function, but what about second sum? Can I do anything about that?","['special-functions', 'summation', 'sequences-and-series']"
2372981,Evaluate the integral $\int\limits_0^{2\pi} \frac {d\theta}{5 - 3\cos(\theta)}$.,Evaluate the integral $\displaystyle \int_0^{2\pi} \frac {d\theta}{5 - 3\cos(\theta)}$. Hint : put $z = e^{i\theta}$. Is there a way to solve this without using the Residue Theorem and $\tan(z)$? Is Cauchy's integral formula applicable?,"['cauchy-integral-formula', 'complex-analysis', 'integration']"
2373022,Intuitive approach to topology,"I'm a highschool student (okay, almost a highschool student - it's summer) that's self-studying. I know some basics of naive set theory, linear algebra, and single-variable calculus. I'd like to give topology a shot. I looked up 'Topology without tears' and began reading. It makes sense (so far, anyway) but there's not really any intuition on what exactly a topology is . It's all axioms and definitions, and while I know that's how most math books are written, I'd just thought I'd ask if there was a book that isn't written that way. As this answer puts it: You don't learn what a vector space is by swallowing a definition that says A vector space $\langle V,S\rangle$ is a set $V$ and a field $S$ that satisfy the following 8 axioms: … [...] A good textbook will do this: it will reduce those 8 axioms to a brief statement of what the axioms are actually about, and provide a set of illuminating examples. In the case of the vector space, the brief statement I quoted, boldface in the original, was it: we can add any two vectors, and we can multiply vectors by scalars. What's a textbook like that for topology? (I don't mind definitions; they're important. I'd just like some intuition to go with them.)","['reference-request', 'general-topology', 'self-learning', 'soft-question']"
2373050,Is every vector space an injective module?,"Let R be a commutative ring and $Q$ an $R$-module, we say that $Q$ is injective if it has the property that for all $R$-modules $M$ and $N$ and homomorphisms $$f\ :\ M\to Q$$ and $$\phi\ :\ M\to N$$ such that $\phi$ is injective, there is a homomorphism $\overline{f}\ :\ N\to Q$ such that $\overline{f}\circ \phi =f$. Let $F$ be a field and let $Q$ be a finite dimensional vector space over $F$, that is, a finitely generated $F$-module.  Prove that $Q$ is injective. This question is from an old preliminary exam, and I believe I have a solution, which I will provide below, but my proof does not rely on the fact that $Q$ is finite dimensional.  Is it true that all vector spaces are injective?  I didn't think that was true, but I can't see where my proof goes wrong.  I would appreciate either some validation or a reason why my proof fails.  Thanks. Proof: Let $M$ and $N$ be vector spaces over $F$.  Let $\{x_i\}_{i\in I}$ be a basis for $M$ where $I$ is some indexing set.  I claim that $\{\phi(x_i)\}_{i\in I}$ is linearly indpendent and spans $\text{im}\phi$.  Indeed,for $\{s_i\}_{i=1}^n\subset I$ and $\alpha_{s_i}\in F$ for each $1\le i\le n$, we have 
$$\sum_{i=1}^n\alpha_{s_i}\phi(x_{s_i})=0$$
$$\implies\phi\left(\sum_{i=1}^n\alpha_{s_i}x_{s_i}\right)=0$$
$$\implies \sum_{i=1}^n\alpha_{s_i}x_{s_i}=0$$
$$\implies \alpha_{s_i}=0\text{ for all }i$$
Where the third line follows from the injectivity of $\phi$.  Hence, $\{\phi(x_i)\}_{i\in I}$ is linearly independent.  To see that this set spans $\phi(M)$, let $y\in \phi(M)$  and write 
$$y=\phi(x)=\phi\left(\sum_{j\in J}^n\alpha_jx_j\right)=\sum_{j\in J}\alpha_j\phi(x_j)\text{ for some finite subset }J\text{ of }I\text{ and }\{\alpha_j\}_{j\in J}\subset F.$$
Extend this set to a basis for $N$.  Define $\overline{f}\ :\ N\to Q$ by $\overline{f}(\phi(x_i))=f(x_i)$ and define $\overline{f}$ to be $0$ on all other basis elements.  It appears that $\overline{f}$ has the property required.  Hence, $Q$ is injective. Note that not once did I use the fact that $Q$ had a finite basis.  So, this would imply that all vector spaces are injective.  Note also that I only relied on the fact that $F$ was a field in order to extend the basis.  Could I have also just gotten away with defining $\overline{f}$ to be $0$ on the complement of $\phi(M)$ in order to prove that all free modules are injective?","['injective-module', 'ring-theory', 'modules', 'linear-algebra']"
2373058,How many coefficients do you have to change to lower the rank of a matrix?,"Let $1\leq r \leq n$ be integers. I'd like to find the smallest integer $m$ such that every matrix $A \in M_n(\mathbb R)$ of rank $r$ can be transformed into a matrix $A'$ of rank $r-1$ by changing at most $m$ coefficients. The question is rather arbitrary, but here are some examples and remarks, partly to apologise: If $n =r$, you can transform any invertible matrix $A$ into a non-invertible one by modifying a single coefficient (just pick one whose corresponding cofactor doesn't vanish, and set it to the value that cancels the determinant), so $m = 1$. The matrix $(1)_{i,j}$ is of rank $1$, and you obviously have to change all of its coefficients to lower the rank, so $m=n^2$ when $r = 1$. In general, if $\mathop{\mathrm{rk}} A = r$, you can swap some rows and columns so that the $(r-1) \times (r-1)$ northeast submatrix of $A$ is invertible. Then, it's quite easy to show that you can modify the coefficients in the southwest block so that the rank becomes $r-1$. This proves that in general, $m \leq (n+1-r)^2$. These arguments make me believe (perhaps rather naïvely) that the answer is in fact $m= (n+1-r)^2$, but I haven't got any concrete proof strategy to show it (and the contemplation of small examples quickly gets somehow messy). Can you find the true value of $m$?","['matrices', 'matrix-rank', 'linear-algebra']"
2373068,$\lim_{n\to\infty}na_n=0\Rightarrow\sum_{n=1}^\infty a_n<\infty$?,"Let $\{a_n\}_{n\in\mathbb{N}}\subset\mathbb{R}$ be a nonnegative decreasing sequence satisfying $\lim_{n\to\infty}na_n=0$.
Then, is it true that $\sum_{n=1}^\infty a_n<\infty$? I think the answer is yes from my intuition since $a_n$ decreases faster than $1/n$ as $n\to\infty$, i.e.
$$\exists \alpha>0\ s.t.\  a_n\sim O(1/n^{1+\alpha}),$$
and we know that $\sum_{n=1}^\infty 1/n^s$ converges if $s>1$.
Actually this is the converse of this problem . How can I prove this? Thank you in advance.","['sequences-and-series', 'calculus', 'limits']"
