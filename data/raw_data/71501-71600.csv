question_id,title,body,tags
875910,Paradoxical Game Show Problem [duplicate],"This question already has answers here : Better than random (5 answers) Closed 9 years ago . Here's a problem that has had me scratching my head for a long time: Imagine you're in a game show, and are presented with 2 boxes.  You are told that both boxes contain a sum of cash, but one of the boxes contains twice as much as the other.  You do not know which box has the double prize.  The game works in 2 phases: Choose any of the boxes you want. Look inside the box.  At this point you can decide to keep the contents, or switch to the other box. So imagine that you've chosen a box, and it contains \$100.  From here, you can calculate the ""expected value"" of the other box to be $0.5 \times \$50 + 0.5 \times \$200 = \$125$ and therefore decide to switch. But then it follows that you would have made the same decision for any value $x$ that you would have found in the first box!  So then why not just pick the other box in the first place? In other words, the strategy of ""pick a box at random, and then switch, no matter what"" is equivalent to ""pick a candidate box at random, and then pick the other box, and keep it"", which is also equivalent to ""pick a box at random, and keep it"".  Which means that switching is the same as not switching. But this seems like a paradox, because we just calculated that switching the box after your initial choice increases your expected winnings by a factor of 1.25!","['probability', 'expectation']"
875972,Area of a Curved Surface,Find the area of the part o the surface $z=xy$ that lies within the cylinder $x^2+y^2=1$. I'm not sure how to set up the surface integral to compute this.,"['multivariable-calculus', 'integration']"
875983,Solutions to the Mordell Equation modulo $p$,"It is well known that for any nonzero integer $k$ the Mordell Equation $x^2 = y^3 + k$ has finitely many solutions $x$ and $y$ in $\mathbf Z$, but it has solutions modulo $n$ for all $n$. One proof of this involves using the Weil Bound to show that $x^2 = y^3 + k$ has solutions modulo $p$ for all $p > 3$, then manually checking for $2, 3$, and then using the lifting lemma. However, the first step doesn't seem very elementary. Does anybody know how to prove that it has solutions modulo $p$ for all primes $p$.","['mordell-curves', 'elementary-number-theory', 'diophantine-equations', 'number-theory']"
876021,A game with checkers,Alice puts checkers in some cells of a $8 \times 8$ board such that : There is at least one checker in any $1\times 2$ or $2\times 1$ rectangle. There are at least two adjacent checkers in any $7\times 1$ or $1\times 7$ rectangle. Find the least amount of checkers satisfying these conditions.,['combinatorics']
876024,"What are local homomorphisms, geometrically?","For want of a better name, let us say that a ring homomorphism $f : A \to B$ is local if it (preserves and) reflects invertibility, i.e. $f (a)$ is invertible in $B$ (if and) only if $a$ is invertible in $A$. (A local ring homomorphism is then a local homomorphism in this sense whose codomain is a local ring; note that the domain is then automatically a local ring.) Question. Is there a property of morphism $\operatorname{Spec} f : \operatorname{Spec} B \to \operatorname{Spec} A$, expressible geometrically, that is equivalent to the property of $f : A \to B$ being local? In view of the early answers given, here is a conjecture: Conjecture. $f : A \to B$ is a local homomorphism if and only if the set-theoretic image of $\operatorname{Spec} f : \operatorname{Spec} B \to \operatorname{Spec} A$ contains all the closed points (of $\operatorname{Spec} A$). The conjecture is true if $B$ is a local ring, and also when $f : A \to B$ is surjective, as shown by @zcn below. In the general case, the ""if"" direction holds: indeed, if every maximal ideal of $A$ is the preimage of some ideal of $B$, then $f : A \to B$ preserves non-units, hence is local. What about the converse?","['commutative-algebra', 'algebraic-geometry']"
876028,Solving Differential equations with Laplace transform,"$\displaystyle y''+4y'+3y=e^{-t}$, given $\displaystyle y(0)=y'(0)=1$ My Attempt: Taking Laplace transforms on both sides
$\displaystyle $
$\displaystyle [s^2\bar y-sy(0)-y'(0)]+4[s\bar y-y(0)]+3\bar y=\frac{1}{s+1} $ $\displaystyle [s^2+4s+3]\bar y=\frac{1}{s+1}+s+5 $ $\displaystyle \bar y=\frac{s^2+6s+6}{(s+1)(s^2+4s+3)}$ Resolving into partial fractions, $\displaystyle \frac{A}{s+1}+\frac{B}{(s+1)^2}+\frac{C}{s+3}=\frac{s^2+6s+6}{(s+1)(s^2+4s+3)}$ I get A=7/2; B=1/2 and C=1 Taking inverse,
$\displaystyle y=\frac{7}{2}e^{-t}+\frac{1}{2}te^{-t}+e^{-3t}$ The given answer is $\displaystyle y=\frac{7}{4}e^{-t}-\frac{1}{2}te^{-t}-\frac{3}{4}e^{-3t}$ I can't find where I am going wrong. Please help.","['laplace-transform', 'algebra-precalculus']"
876031,"If $a+b+c+d=4$, then $\sum\frac{1}{a+3}\le \frac{1}{abcd}$","This is somehow related to this problem but I don't have any idea about it. Let $a$, $b$, $c$ and $d$ be positive reals such that $a+b+c+d=4$. Prove that:
  $$\frac{1}{a+3}+\frac{1}{b+3}+\frac{1}{c+3}+\frac{1}{d+3}\le \frac{1}{abcd}$$ Now I also tried to prove the $3$ variable version :
$$\frac{1}{a+2}+\frac{1}{b+2}+\frac{1}{c+2}\le \frac{1}{abc}$$ where $a,b,c>0$ with $a+b+c=3$. But I haven't been able to solve it too. Anyone can help?? Thanks a lot.","['inequality', 'symmetric-polynomials', 'algebra-precalculus']"
876045,List of exercises and examples to see the geometry behind algebraic geometry,What exercises should one solve (understanding proofs included) to gain an intuition for algebraic geometry? What are examples of (not too hard) problems that algebraic geometry handles easier than elementary approaches?,['algebraic-geometry']
876055,How to show a set is compact in a function space?,"I have a question asking if $\{f_n\}$ is a compact in $C_b([0,\infty))$ (bounded continuous) with $||\cdot||_{L^\infty}$.
The sequence is 
$$f_n (t) = \sin\sqrt{t+(2n\pi)^2},$$ I have showed that $f_n \rightarrow 0$ pointwise. The convergence is uniform when looking at $t$ in a bounded interval,
and it is not uniform when $t\in[0,\infty)$. $\{f_n\}$ is equi-continuous. Questions: Now assume that the space is $C_b([0,N])$, can I use Arzelà–Ascoli theorem to show $\{f_n\}$ is sequential compact? Which implies compactness since $C_b([0,N])$ is a metric space? How would I approach this kind of problem, which definition of compactness should I use when working on function spaces? Complete and totally bounded; every bounded sequence has a convergent subsequence ? Thanks a lot!","['general-topology', 'functional-analysis', 'real-analysis']"
876067,Calculating conditional lottery probabilities - and example from DeGroot.,"I'm trying to understand this example in Probability and Statistics in DeGroot: https://i.sstatic.net/b23Sr.jpg ""You learned that the event B = {one of the numbers drawn is 15} has occurred. You want to calculate the probability of the event A that your ticket is a winner [given B]."" It suggests that the probability of P(AnB) = P(A) but how can this be if there exist outcomes in A that aren't in B? Surely it should be equal to P(B) if anything? Thanks.","['statistics', 'conditional-probability']"
876071,Multiple differentiability from Taylor expansion,"Let $f\colon\mathbb{R}\to\mathbb{R}$ be a real function, and let $0\leq n\leq+\infty$ .  We make the following assumption: For every $a \in\mathbb{R}$ and for $k=n$ (resp., in the case $n=+\infty$ : for any $k\geq 0$ ), there exist real numbers $c_0(a),\ldots,c_k(a)$ such that $$f(x) = c_0(a) + c_1(a)\,(x-a) + \frac{1}{2}c_2(a)\,(x-a)^2 + \cdots + \frac{1}{k!}c_k(a)\,(x-a)^k + o((x-a)^k)$$ where, as usual, $o((x-a)^k)$ means $(x-a)^k\,\varepsilon_{a,k}(x)$ for some function $\varepsilon_{a,k}$ tending to $0$ when $x \to a$ . In other words, we assume that $f$ has a power expansion of order $k$ with $o$ error term at (every) $a$ .  Note that no assumption is made on uniformity of the $o$ error term when $a$ varies (e.g., we do not assume that $\varepsilon_{a,k}(x)$ is bounded by some function of $x-a$ ): we only assume that for every $a$ there exists an expansion of order $k$ as above, nothing more. Naturally, the $c_i(a)$ are uniquely determined, we have $c_0 = f$ (that is, $c_0(a) = f(a)$ for every $a$ ) and $f$ is continuous; and moreover, as soon as $n\geq 1$ , clearly, $f$ is differentiable with derivative $f' = c_1$ . We cannot deduce that $f$ is twice differentiable, or even $C^1$ , from the above hypothesis alone, no matter how large $n$ is.  The simple example of $f(x) = x^{n+1} \sin(x^{-n})$ provides a counterexample (it is $o(x^n)$ at $0$ and analytic everywhere else, so it has a power expansion of order $n$ everywhere, yet it is easily seen that it is not even $C^1$ at $0$ ); a slightly more complicated counterexample works for $n=\infty$ . Now here is my question.  Let us make the following additional assumption (which is not satisfied for the above counterexample): For each $0\leq k\leq n$ , the function $c_k$ (that is, $a\mapsto c_k(a)$ ) is continuous. (In particular, if $n\geq 1$ , it is now clear that $f$ is $C^1$ .) Can I conclude from both assumptions that $f$ is $C^n$ ?  (Or, if not, can I conclude something non-trivial?)","['real-analysis', 'taylor-expansion']"
876088,Weak convergence with respect to the uniform topology on cadlag functions,"Suppose I have a random sequence $X_n$ of cadlag functions on $[0,1]$ that converge weakly to $X$. In general this is meant with respect to the Skorkhod metric but suppose here I have that $X$ is continuous and $X_n$ converge weakly to $X$ with respect to the uniform metric on the space of cadlag processes $[0,1]$. (Under this metric this is a complete metric space however it is not separable.) I need that $X_n$ is well defined with respect to the uniform topology but suppose I have this as well. Now suppose $X_n$ are piecewise constant and consider $\tilde{X}_n$,  the linearized version of $X_n$. By this I mean the function I get by drawing straight lines between the jump discontinuities of $X_n$. Is it true that $\tilde{X}_n$ converges in law to $X$ again with respect to the uniform metric on continuous functions? I'm pretty sure that this is true, and I believe I have a proof but I'd like confirmation. I thought this would be written down somewhere. I tried Billingsley, Convergence of Probability Measures , especially Chapter 3, Section 18 (The Uniform Topology), but I couldn't find it. Thanks for your help.","['probability-theory', 'weak-convergence', 'skorohod-space']"
876091,Graph partition that span a third of edges,"Given a graph G is easy to see that we have a partition $V=V_1 \cup V_2$ so that 
$$e(G[V_1])+e(G[V_2])\leq e(G)/2$$. How can we improve this result showing that we can choose $V_i$ such that $e(G[V_i])\leq e(G)/3$ for $i=1,2.$","['bipartite-graphs', 'graph-theory', 'combinatorics']"
876099,Boundary behaviour of holomorphic function on unit disk,"Let $\mathbb{D}=\{z \in \mathbb{C} \ | \ |z|<1 \} $ be the open unit disk in the complex plane. I would like to see explicit examples of the following phenomena: a holomorphic function $f$ on $\mathbb{D}$ which extends continuously to the boundary but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) a holomorphic function $f$ on $\mathbb{D}$ which is bounded on $\mathbb{D}$ but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) Such functions should exist according to this answer to a previous post .
Thanks for any reference/advice.","['analyticity', 'complex-analysis']"
876106,How find this integral $\int_{0}^{\infty}\frac{dx}{(1+x^2)(1+r^2x^2)(1+r^4x^2)(1+r^6x^2)\cdots}$,"prove that this integral $$\int_{0}^{\infty}\dfrac{dx}{(1+x^2)(1+r^2x^2)(1+r^4x^2)(1+r^6x^2)\cdots}=
\dfrac{\pi}{2(1+r+r^3+r^6+r^{10}+\cdots}$$ for this integral,I can't find it.and I don't know how deal this such strange integral. and this problem is from china QQ (someone ask it) before I ask this  question: How find this integral $F(y)=\int_{-\infty}^{\infty}\frac{dx}{(1+x^2)(1+(x+y)^2)}$",['integration']
876119,Separability of conjugacy classes in conjugacy separable semidirect products.,"We say that group $G$ is conjugacy separable if for every $g \in G$ the set $g^G = \{cgc^{-1} \mid c \in G\}$ is closed in the profinite topology on $G$, i.e. for every $f \in G \setminus g^G$ there is a finite index normal subgroup $N$ such that $fN \cup g^G = \emptyset$. Now suppose that $G = K \rtimes R$ is a conjugacy separable group. One can easily show that for every $r \in R$ the set $r^R = \{crc^{-1}\mid c \in R\}$ is closed in the profinite topology on $G$. Can we show the same for elements $k \in K$: is the set $k^R$ closed in $G$ for every $k\in K$? If not, what would be an example of conjugacy separable group that splits as a nontrivial semidirect product and a tuple of elements that cannot be separated?","['examples-counterexamples', 'profinite-groups', 'group-theory', 'normal-subgroups']"
876120,How to evaluate $\lim_{x \to \infty}\left(1 + \frac{2}{x}\right)^{3x}$ using L'Hôpital's rule?,I'm stuck on how to evaluate the following using L'Hôpital's rule: $$\lim_{x \to \infty}\left(1 + \frac{2}{x}\right)^{3x}$$ This is a problem that I encountered on Khan Academy and I attempted to understand it using the resources there.  Here are the tips given for the problem; the portion that I'm having trouble understanding is highlighted: I also attempted to use this video (screenshot following) to help; I understand the concepts in the video but it seems like there are some missing steps in the tips above. I also attempted to use WolframAlpha's step-by-step solution but it was indecipherable to me. Any help is greatly appreciated.,"['derivatives', 'limits']"
876126,At a party $n$ people toss their hats into a pile in a closet.$\dots$ [duplicate],"This question already has answers here : Question on the 'Hat check' problem (4 answers) Closed 9 years ago . Question: At a party $n$ people toss their hats into a pile in a closet. The hats are mixed up, and each person selects one at random. What is the expected number of people who select their own hats? My Attempt: Note,
$$E(X) = \sum_{s\in S} p(s)X(s)$$ $E(x)$ is the expected value. $p(s)$ is the probability of event $s$. $S$ is the sample space. $X(s)$ is the random variable. The probability of one person picking his/her hat is $\dfrac{1}{n}$, two person picking their hat is $\dfrac{1}{n}\dfrac{1}{n-1}$. Let $n$ be the number of people, let $P(n, r)$ be number of $r-permutation$ in $elements$. to generalize, $$p(s) = \dfrac{1}{P(n, s)}$$
where $s$, the sample is the number of people who picked their own hat. Before I plug it all in to the $E(X)$ equation, the random variable is $X(s) = s$, or simply an identity function. My expected value formula is, $$E(X) = \sum_{s\in S} \dfrac{1}{P(n, s)}*s$$ $$E(X) = \sum_{s=1}^{n} \dfrac{1}{P(n, s)}*s$$ Is this anywhere right? If I'm on track, how do I show what it equals to? The answer key said it should equal to one, but I'm lost from here.","['probability-theory', 'discrete-mathematics']"
876134,Parametrizing to Calculate Flux,"Evaluate the flux of $\mathbf{f}$ across the oriented surface $\Sigma$ by computing the surface integral $\iint_{\Sigma} \mathbf{f} \cdot d\sigma$, where $\Sigma$ is the surface $z=xe^y$ for $0 \leq x \leq 1$ and $0 \leq y \leq 1$ with upward orientation. The vector field is $\mathbf{f}(x,y,z)=\langle xy, 4x^2, yz \rangle$. Using the surface integral to evaluate flux, $$\iint_{\Sigma} \mathbf{f} \cdot d\sigma= \iint_R f(x(u,v)),y(u,v),z(u,v)) \left|\left| \frac{\partial r}{\partial u} \times \frac{\partial r}{\partial u} \right|\right| du dv$$ What would $u$ and $v$ be? I'm not sure how to parametrize this.","['multivariable-calculus', 'surfaces']"
876166,What is $\zeta(n)$ as $n$ tends to $\infty$? How fast it goes to the limit?,What is $\zeta(n)$ as $n\to\infty$? How fast it goes to the limit?,"['sequences-and-series', 'riemann-zeta', 'number-theory', 'analytic-number-theory', 'real-analysis']"
876175,"Evaluation of $\int\frac{\sqrt{\cos 2x}}{\sin x}\,dx$","Compute the indefinite integral
  $$
\int\frac{\sqrt{\cos 2x}}{\sin x}\,dx
$$ My Attempt: $$
\begin{align}
\int\frac{\sqrt{\cos 2x}}{\sin x}\,dx &= \int\frac{\cos 2x}{\sin^2 x\sqrt{\cos 2x}}\sin xdx\\
&= \int\frac{2\cos^2 x-1}{(1-\cos^2 x)\sqrt{2\cos^2 x-1} }\sin x \,dx
\end{align}
$$ Let $\cos x = t$, so that $\sin x\,dx = -dt$. This changes the integral to $$
\begin{align}
\int\frac{(2t^2-1)}{(t^2-1)\sqrt{2t^2-1}}\,dt &= \int\frac{(2t^2-2)+1}{(t^2-1)\sqrt{2t^2-1}}\,dt\\
&= 2\int\frac{dt}{\sqrt{2t^2-1}}+\int \frac{dt}{(t^2-1)\sqrt{2t^2-1}}
\end{align}
$$ How can I solve the integral from here?","['algebra-precalculus', 'calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
876195,What is an advatage of defining $\mathbb{C}$ as a set containing $\mathbb{R}$?,"It is a theorem that every field with least upper bound property and Archimedean property is isomorphic to each other. So it seems not necessary to define $\mathbb{R}$ exactly and we simply denote any field with least upper bound property and Archimedean property as $\mathbb{R}$, in general. Until now, i have defined $\mathbb{C}$ as a product of $\mathbb{R}$, that is, $\mathbb{R}\times\mathbb{R}$. (Very precisely in this case $\mathbb{R}$ is not a subset of $\mathbb{C}$) However, i found this definition a bit uncomfortable when i'm doing arguments which should be done successively from real to complex. (i.e Abstract integral theory) So i defined it newly, so that $\mathbb{R}\subset\mathbb{C}$. I found this definition really natural than the first one since under this definition, $\mathbb{R}$ is a (topological) subspace of $\mathbb{C}$. Well, i think this is advantageous, but i'm not sure. Is there an advantage of using this definition?
And is it Okay to use this definition?","['abstract-algebra', 'real-analysis']"
876211,Partial fractions for $\pi \cot(\pi z)$,"I want to derive $$\pi \cot(\pi z) = \sum_{-\infty}^{\infty}\frac{1}{z-n} + \frac{1}{n}$$ without taking derivatives. I know through Mittag Leffler that $$\pi \cot(\pi z) = g(z) +\sum_{-\infty}^{\infty}\frac{1}{z-n} + \frac{1}{n}$$  for some entire analytic $g(z)$ but I'm having a hard time showing that $g(z) = 0$. I do not want to take the integral of $\frac{\pi^2}{\sin^2(\pi z)}$. I have deduced that $g(0) = 0$, $g$ is odd, and $g$ is periodic with period $1$. If I could deduce that $g$ was bounded even in a strip of length $1$ I wold be finished because of Louiville Theorem. To this end, I can show that $\pi \cot(\pi z)$ is bounded towards infinity but I was not able to show that the sum could be bounded.","['partial-fractions', 'complex-analysis']"
876229,"scheme-theoretic image behaves nicely with composition, base change?","Scheme-theoretic image is still somewhat of a mystery to me, and I wasn't able to work out proofs of either of the following two statements that seem plausible to me: If $X\to Y\to Z$ is a map of schemes, $Y'\subset Y$ is the scheme-theoretic image of $X\to Y$, and $Z'\subset Z$ is the scheme-theoretic image of $Y'\to Y\to Z$, then $Z'$ is also the scheme-theoretic image of $X\to Z$. (i.e. you can compute scheme-theoretic image one map at a time) If $X\to Y$ is a map of $S$-schemes, and $X'\to Y'$ is the corresponding map after base-changing to $S'$, then the scheme-theoretic image of $X'\to Y'$ is the base-change of that of $X\to Y$. I wasn't able to get either one to follow immediately from the universal property of scheme-theoretic image, so perhaps these are either false or in need of additional hypotheses (maybe that the images can be computed affine-locally, e.g. all of the maps are quasicompact). Anyway, are these true, possibly with additional hypotheses? Could someone provide proofs?",['algebraic-geometry']
876245,Modulo Big O Problem,"I know this may be really basic, but I am unsure of the complexity of this procedure in Python: def modten(n):

   return n%10 edit: It is done with Python. That is the only additional information provided for this question. The question asks to specify the order of growth",['analysis']
876271,"Frobenius method, why is it an issue when the roots of the indicial equation differ by an integer","When solving second-order differential equations by the Frobenius method at a regular singular point, you are supposed to use the two roots of the indicial equation to give you two independent solutions. If there is only one root, it makes sense that you would need another method to get the second independent solution. However, many texts say that you also need to do this when the roots differ by an integer. Why? Is it that when the roots differ by an integer, the two matching solutions are not independent? If so, why must they be independent? Is it that sometimes they will be independent and sometimes they won't? If so, when will they be independent and when won't they? Is it that there is something that prevents calculating one of the solutions? If so, why?",['ordinary-differential-equations']
876287,"Prove that if the sum of each row of A equals s, then s is an eigenvalue of A. [duplicate]","This question already has answers here : Prove that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. (2 answers) Closed 9 years ago . Consider an $n \times n$ matrix $A$ with the property that the row sums all equal the same number $s$. Show that  $s$ is an eigenvalue of $A$. [Hint: Find an eigenvector] My attempt: By definition: $Ax = sx$ which implies that $(A - sI)x = 0$ $s$ is an eigenvalue for $A$ iff $\det(A - sI)  = 0$ When you do $A - sI$ the sum of each row is now $0$. I think that's important but I don't know what it means. So this is where I'm stuck","['matrix-equations', 'matrices', 'linear-algebra', 'determinant']"
876310,Meaning behind differentials,"So I think I understand what differentials are, but let me know if I'm wrong. So let's take $y=f(x)$ such that $f: [a,b] \subset \Bbb R \to \Bbb R$.  Instead of defining the derivative of $f$ in terms of the differentials $\text{dy}$ and $\text{dx}$, we take the derivative $f'(x)$ as our ""primitive"".  Then to define the differentials we do as follows: We find some $x_0 \in [a,b]$ where there is some neighborhood of $x_0$, $N(x_0)$, such that all $f(x)$ in $\{f(x) \in \Bbb R \mid x \in N(x_0)\}$ are differentiable.  Then we choose another point in $N(x_0)$, let's call it $x_1$, such that $x_1 \ne x_0$.  Then let $dx = \Delta x = x_1 - x_0$.  Now this $\Delta x$ doesn't actually have to be very small like we're taught in Calculus 1 (in particular it's not infinitesimal, it's finite).  In fact, as long as $f(x)$ is differentiable for all $x \in [-10^{10}, 10^{10}]$ we could choose $x_0 = -10^{10}$ and $x_1 = 10^{10}$. Then we know that $\Delta y = f'(x_0) \Delta x + \epsilon(\Delta x)$, where $\epsilon(\Delta x)$ is some nonlinear function of $\Delta x$.  If $f(x)$ is smooth, we know that $\epsilon(\Delta x)$ is equal to the sum of powers of $\Delta x$ with some coefficients, by Taylor's theorem.  But of course, $\epsilon(\Delta x)$ won't be so easy to describe if $f(x)$ is only once differentiable.  So we define $dy$ as $dy = f'(x_0) dx$: that is, $dy$ is the linear part of $\Delta y$.  This has the very useful property that $\lim_{\Delta x \to 0} \frac{\Delta y}{\Delta x} = \frac{dy}{dx} = f'(x_0)$.  This is then not a definition of the derivative, but a consequence of our definitions. It can be seen from this $dy$ really depends on what we choose as $dx$, but $f'$ is independent of both. This definition can be extended to functions of multiple variables, like $z = f(x, y)$ as well, by letting $\Delta x = dx,\ \Delta y=dy$ and defining $dz$ as $dz = \frac{\partial f(x_0, y_0)}{\partial x}dx + \frac{\partial f(x_0, y_0)}{\partial y} dy$.  So $dz$ is the linear part of $\Delta z$.  Does all of the above look correct? If so, then where I'm having a problem is: 1) how then do we define the derivative of $f(x)$ if not by $f'(x_0) = \lim_{\Delta x \to 0} \frac{\Delta y}{\Delta x}$? 2) how do we apply this definition of $dx$ to $\int_a^b f(x)dx$?  It seems like the inherit arbitrariness of $dx$ is really going to get in the way of a good definition of the integral.",['calculus']
876317,Exponential of Squared Brownian Motion,"Long time lurker, first time posting! Have a problem, that looks familiar but I can't put my finger on it. Need to calculate 
$\mathbb{E} [\exp(aW_T^2)|F_t]$ where $W_t$ is an $F_t$ adapted standard Brownian motion and $t \leq T$. Any help on exponentials of squared Brownian motion is very appreciated!","['statistics', 'stochastic-processes', 'probability-distributions', 'conditional-probability']"
876319,"$\forall x \,\exists k$ s.t. $f^{(k)}(x)=0$, then $f$ is a polynomial","My friend sent me the following problem: Suppose that $f$ is real analytic on $(a,b)$, and that for all $x$ in
  $(a,b)$ there exists a non-negative integer $k$ such that
  $f^{(k)}(x)=0$.  Show that $f$ is a polynomial. I believe I solved it (you can read my answer below the fold if you are interested). Then my friend posed the question of what happens if $f$ is only $C^{\infty}$. I believe my argument below has shown that $\{x: \exists \,\,\text{a nbd of } x\,\,\text{on which }f \,\,\text{is a polynomial}\}$ is dense in $(a,b)$. But I can't  seem to show that that implies $f$ is a polynomial. Can someone think of a counter-example, or finish the proof? Proposition: Suppose that $f$ is real analytic on $(a,b)$, and that for all $x$ in $(a,b)$ there exists a non-negative integer $k$ such that $f^{(k)}(x)=0$.  Then $f$ is a polynomial. Proof: If $f$ agrees with a polynomial $p$ on an open interval, then the Taylor expansion at any point in that interval is finite, and so has an infinite radius of convergence. Properties of analytic functions then imply that $f=p$ on $(a,b)$. So suppose for contradiction that $f$ does not agree with a polynomial on an open interval. For all $x\in (a,b)$, define $n_x$ to be the smallest integer $k$ for which $f^{(k)}(x)=0$. Let $x\in (a,b)$ be arbitrary. Then by continuity of all derivatives, there exists a neighborhood $(a_1,b_1)\subseteq (a,b)$ such that $n_y\geq n_x$ for all $y\in (a_1,b_1)$. Now if $n_y=n_x$ for all $y\in (a_1,b_1)$, then $f$ agrees with a polynomial on that interval, a contradiction. So there exists $x_1\in (a_1,b_1)$ such that $n_{x_1}>n_x$. Take $[\alpha_1, \beta_1]\subset (a_1,b_1)$ such that $x_1\in [\alpha_1,\beta_1]$. Now repeat the process, starting with $x_1$, to generate $x_2 \in [\alpha_2,\beta_2]$ such that $n_{x_2}>n_{x_1}$. The nested interval theorem now implies that there exists a point $x^* \in \cap_{i}[\alpha_i,\beta_i]$, and since $n_{x_i}\xrightarrow{i\to\infty} \infty$, $f^{k}(x^*) \neq 0\,\,\forall k$, a contradiction. $\blacksquare$","['analyticity', 'real-analysis', 'polynomials']"
876353,explicit example of computing ray class field for imaginary quadratic?,"Given an imaginary quadratic number field K, we can get its ray class field mod some ideal $\mathcal{m}$ by adjoining the j-invariant of an elliptic curve with complex multiplication given by $\mathcal{O}_K$ and the values of the Weber function at the non-zero $\mathcal{m}$-torsion of the curve. (See http://www.math.leidenuniv.nl/~psh/ANTproc/15cohenpsh.pdf ) I'm trying to get my hands on understanding this construction and explicit examples would be helpful- Does anyone know of a source that really explicitly goes through this computation of the ray class field for particular examples of K and choices of $\mathcal{m}$?","['elliptic-curves', 'class-field-theory', 'algebraic-number-theory', 'number-theory']"
876361,Difficult generating function,"Define a beautiful number to be an integer of the form $a^n$, where $a\in\{3,4,5,6\}$ and $n$ is a positive integer.
Prove that each integer greater than $2$ can be expressed as the sum of pairwise distinct beautiful numbers. *I have added the original problem.","['generating-functions', 'problem-solving', 'number-theory']"
876362,Statistics - Finding the median,"Problem : x =    0-4 , 4-10 , 10-18 , 18-30 , 30-40 f(x) = 15 , 35 , 20 , 20 , 10 Finding the median? This is that I did : Cumulative frequency distribution : F(x) = 15 , 50 , 70 , 90 , 100 Midpoint : 2 , 7 , 14 , 24 , 35 Formula : $Md = L_0 + \frac{\frac{n}{2}-F(x_{m-1})}{f(x_m)}*(L_1-L_0)$ n=100, $$\frac{100}{2} = 50$$ But F(x) = 50? I don't understand how to continue? Thanks.",['statistics']
876387,Submersions and induced homomorphism on fundamental groups,"Suppose that $M$ and $B$ are two smooth manifolds and $\Pi:M\rightarrow B$ a submersion (and onto). Fixed $x\in M$ and $b\in B$, is the induced homomorphism $\Pi_{\#}:\pi_{1}(M,x)\rightarrow \pi_{1}(B,b)$ also onto?
I think so if we assume that the fibres are connected, but I am not sure. This is my argument. If $\gamma:[0,1]\rightarrow B$ is a parametrization of an element of $\pi_1(B,b)$, using that $\Pi$ is a submersion, it is clear that locally we can lift $\gamma$ to $M$, obtaining a finite number of curves $\alpha_i:J_i\rightarrow M$ such that $\Pi(\alpha_i(t))=\gamma(t)$ for all $t\in J_i$, where $J_i$ are closed intervals with $\cup_i J_i=[0,1]$ and $J_i\cap J_{i+1}=\{one point \}$. The problem is that $\alpha_i$ does not need to glue with $\alpha_{i+1}$, but this can be solved easily taking into account that the end point of $\alpha_i$ and the starting point of $\alpha_{i+1}$ are in the same fibre. Indeed. Since we assume that the fibres are connected, we can take an auxiliary curve $\beta_i$ in the fibre joining the end point of $\alpha_i$ and the starting point of $\alpha_{i+1}$. Composing, we obtain a loop $\sigma$ in $M$ such that $\Pi_{\#}([\sigma])=[\gamma]$. Thanks in advance.",['differential-geometry']
876388,A Sperner type problem on infinite antichains,"Let $\mathcal{A} \subset 2^{\mathbb{N}}$ be an antichain (with respect to containment).  I want to measure the size of $\mathcal{A}$ in the following way: I create a set, $S$, by flipping a fair coin for each natural number $x \in \mathbb{N}$, if heads I add $x$ to $S$, otherwise I don't.   Then the ""measure"" of $\mathcal{A}$ will be the probability $S \in \mathcal{A}$. A friend told me about cylindrical sets which seem to capture this notion.  Take those collections consisting of $k \in \mathbb{N}$ fixed bits (elements or nonelements) and define their measure to be $\frac{1}{2^k}$.  For an example of such a collection take $\mathcal{F} = \{A \subset \mathbb{N}: 3 \in A, 8 \in A, 11 \notin A\}$, here $\mu(\mathcal{F}) = 1/8$.  Let $\mu$ be the measure generated from these sets. Unfortunately, $\mu$ seems hard to work with, and I've gotten nowhere. Question: If $\mathcal{A}$ is an antichain in $2^{\mathbb{N}}$, measurable with respect to $\mu$, does it follow that $\mu(\mathcal{A}) = 0$? Background: The motivation is trying to extend Sperner's Thoerem to an infinite setting. Other infinite versions of Sperner's Theorem have been considered but on other structures than sets.","['measure-theory', 'extremal-combinatorics']"
876399,Limit value of the product martingale $\exp(uX_n - nu^2 \sigma^2 / 2)$,"This question came from a problem I was solving for self-study. Statement of the problem Let $Y_n \sim \mathcal N(0,\sigma^2)$ be independent normally distributed variables, $X_n = Y_1+\cdots+Y_n$ their $n$ -th partial sum and, for any real $u$ , define $Z_n^u=\exp(uX_n-nu^2\sigma^2/2)$ . It is straightforward to prove that $Z^u$ is a positive martingale under the natural filtration $\mathscr F_n = \sigma(Y_1,\dots,Y_n)$ . Too see this, it suffices to know that $Z_n^u$ is a product of $n$ independent variables of the form $\exp(uY_j-u^2\sigma^2/2)$ , and that $E(e^{uY_j})$ , the MGF of $Y_j$ , is precisely $e^{u^2\sigma^2/2}$ , so that $Z^u$ is in $L_1$ and $E(Z_n^u) = 1$ for all $n$ . The martingale property follows from $$E[Z_{n+1}^u/Z_n^u|\mathscr F_n] = E[\exp(uY_{n+1}-u^2\sigma^2/2)|\mathscr F_n] = E(e^{uY_{n+1}-u^2\sigma^2/2})=1.$$ It is known, by the martingale convergence theorem, that $Z_n^u$ converges almost surely to $Z_\infty^u$ . The problem asks to compute this limit and to say when it is true that $Z_n^u=E[Z_\infty^u|\mathscr F_n]$ . Some ideas Of course, this last relation would hold if $Z^u$ was
a UI martingale. However, my intuition told me that this was not the case, as the partial sums, which have $\mathcal N(0,n\sigma^2)$ distributions, ""concentrate their measure"" in increasingly larger intervals $[-K, K]$ as $n$ increases (I haven't tried to prove this). I started looking around on the internet and found the law of the iterated logarithm , which I used to (correctly, I hope) compute this limit value to be $0$ a.s. when $u$ is not zero and $1$ if it is. Moreover, I found that there is a product martingale theorem by Kakutani which mentions that $P (Z_\infty^u = 0) = 1$ if and only if $Z^u$ is not a UI family. Main question Is there a more elementary way of computing $Z_\infty^u$ , which doesn't use the aforementioned law or Kakutani's theorem? Maybe using the fact that $X_n/n$ converges to $0$ a.s. and in $L_2$ (by the strong law and by a simple calculation of $V (X_n/n)$ , respectively)? Other questions What am I dealing with here? Is it in some way natural to consider these exponential martingales? Searching on the internet I found the Wikipedia page for the Doléans exponential which mentions the Girsanov theorem for continuous time as an application, but it didn't give me much insight.","['probability-theory', 'martingales', 'random-walk', 'probability-limit-theorems']"
876410,An explicit construction for an everywhere discontinuous real function with $F((a+b)/2)\leq(F(a)+F(b))/2$?,"I would like to know an explicit method on constructing an everywhere discontinuous real function $F$ with the property:
$$F((a+b)/2)\leq(F(a)+F(b))/2.$$ There is a non-constructive example (with the inequality been trivial): Take a Hamel basis $S$ of the $\mathbb{Q}$-linear space $\mathbb{R}$, take in $S$ a countably-infinite subset $X=\{x_1, x_2, ...\}$, then by multiplying a rational number $c_n$ to $x_n$ for each $n$ we can produce a set $Y=\{y_1, y_2, ...\}$ with $0< y_n\leq1/n$. Now we replace the $X$ in $S$ with $Y$ and obtain a new Hamel basis $T$. Take a $t_0\in T$; let $F(t_0)=0$ and let $F(t)=1$ for any other $t\in T$, then $F$ extends to a function on $\mathbb{R}$ linearly, and it is clear this is a required function. By the answer of Conifold below, such an explicit method does not exist. But it would still be nice to know how to give such a non-constructive function with the inequality been strict.","['convex-analysis', 'axiom-of-choice', 'constructive-mathematics', 'analysis']"
876420,Riemann integral enigma,"I tried to solve this problem from Souza Silva - Berkeley Problems In Mathematics: In the Solutions part, I founded next solution for this problem: I do not understand the last statement, so why $|f|\in R[0,1] \implies f \in R[0,1]$? It is clear for me that is false...Or what am I wronging here?",['analysis']
876432,Complex structures on Riemann surfaces,"Let $M$ be a Riemann surface and $[\alpha] \in H^{0,1}(M; T^{1,0} M) \simeq H^0(M;K^2)$.  Considering $\alpha$ as a map $T^{0,1} M \to T^{1,0} M$, the bundle
$$
\{v + \alpha(v) \mid v \in T^{0,1} M\} \subset T_{\mathbb{C}} M
$$
forms the (0,1) part of another complex structure on (the underlying real manifold of) $M$.  Is it true that every complex structure (modulo diffeomorphism) arises in this way? I'm pretty sure this is true and very standard, so a good reference would be great. EDIT I should add that $\alpha$ must be sufficiently small so that its graph inside $T_{\mathbb C} M$ does not intersect the real tangent bundle $TM$.","['teichmueller-theory', 'complex-geometry', 'differential-geometry', 'riemann-surfaces', 'reference-request']"
876436,A question on the proof of 14 distinct sets can be formed by complementation and closure,"In Munkres, problem 20 of Section 2-6, it says that 14 distinct sets can be formed by complementation and closure. I see only five so far.
Let f be the function of closure mapping and g be the function of complementation mapping.
It is clear, f,g, fg,gf, and gfg are the 5 of 15 distinct sets. What are the rests? Was there any topological argument associated with it? How can I understand this intuitively and pictorially?",['general-topology']
876438,A metric on $\mathbb{N}$,"Define a metric on $\mathbb{N}$ by fixing a prime, $p$, and setting $$d(x,y)=\begin{cases} 0 & x=y \\ p^{-k} & \text{otherwise} \end{cases}$$ where $p^k$ is the highest power of $p$ that divides $|x-y|$. There were a couple easy parts like showing that this is a metric space and finding a sequence which converges to zero, but these last two have me stumped. (i) Prove or disprove: The space $(\mathbb{N},d)$ is compact.
I feel like I need to understand what open sets in this topology will look like first, so I tried to work out how open balls behave.  $B(x,2)=\mathbb{N}$ as this contains all numbers since the difference can have $1$ as its largest power of $p$ which divides it, and $2$ is chosen arbitrarily since it is greater than 1.  From here I start to get more confused  it seems like $B(x,p^{-k})$ is the set of integers of the form $n\equiv x\mod{p^{k+1}}$, but I'm not really sure how to prove this.  From here I'm not even sure how to go about making an argument about open covers so if anyone can guide me in the right direction that would be appreciated. (ii) Prove or disprove:  If $p=3$, then the set of prime numbers greater that $101$ is open in $(\mathbb{N})$.
This seems very unlikely to me.  I can pick an element in this set, $103$,  then I don't think I can find an open ball containing $103$ that is a subset of theses primes.  I'm basing this off my assumption that the open balls are of the form described above, but I'm not sure how to show this rigorously. Any tips are greatly appreciated.","['general-topology', 'metric-spaces', 'compactness']"
876442,"""Arbitrary"" Products, Unions, and Intersections of Classes","Recently going through the nlab article on categories, I noticed at the end of this section the use of a disjoint union of disjoint unions of the hom-sets in order to produce the class of morphisms in the given category. This brought to my mind the issue of the well-definability of taking disjoint unions of classes of classes.  Assuming that we are working with $\mathrm{NGB}$, there seems to be some issues with this. The union, intersection, and Cartesian product of two classes $C$ and $C'$ can be easily defined using the Class Comprehension Axiom Schema in $\mathrm{NGB}$ as
$$C\times C':= \{(x,y) \mid x\in C \wedge y\in C'\}$$
$$C\cup C' :=\{x \mid x\in C \vee x\in C' \}$$
$$C\cap C' :=\{x \mid x\in C \wedge x\in C'\}$$
That the arbitrary union of a family (set) of sets is a set is guaranteed by the Axiom of union (for sets), and using the Axiom Scheme of restricted comprehension (for sets) one can similarly conclude that the arbitrary intersection of a family of sets is also a set.  Arbitrary products can be done for indexed families of sets, being shown to be a set because the collection of functions between two sets can be shown to be a function. However, these tools do not (seem to) exist for classes. There are several things stopping one from considering the union of a collection of proper classes: for one, there can be no class containing them by definition so in trying to do so we would not be able to make use of classes of these proper classes. It doesn't seem that the issue exists when we consider classes of classes, however, since the elements of a class are necessarily sets.  Using the Axiom Schema of Class comprehension we can immediately define
$$\bigcup{C}=\{x \mid \exists y (y\in C \wedge x\in y)\}$$
because $\exists y (y\in C \wedge x\in y)$ does not quantify over all classes, only sets.  Similarly, given an indexed class $\{X_i\}_{i\in I}=\{(i,X_i) \mid \exists i( i\in I \wedge X_i\in X \wedge F(i)=X_i)\}$ by another application of the Axiom Schema of Class comprehension 
$$\prod_{i\in I}{X_i}=\left\{ G:I\rightarrow \bigcup_{i\in I}{X_i} \mid \forall i (i\in I \rightarrow G(i)\in X_i)\right\}$$
exists since $\forall i (i\in I\rightarrow G(i)\in X_i)$ does not quantify over classes but sets (admittedly, that $G$ is a class function from $I$ to $\bigcup_{i\in I}{X_i}$ would need to be added, but this does not quantify over classes, so there is no added issue). I guess this leads me to my questions: Is there a way to consider the union/intersection/product of a ""collection"" of proper classes, at least insofar as the expression $\coprod_{x\in C_0}{\coprod_{y\in C_0}{C_1(x,y)}}$ defines a class, where $C_0$ is a class and $C_1(x,y)$ is a class for every pair $x,y\in C_0$?",['elementary-set-theory']
876447,"Geometrically, what is the stereographic projection of a closed $n$-ball?","To show $\overline{B^n}$ is a $n$-manifold with boundary, apparently there is a trick to use stereographic projection after subtracting out the radius connecting $0$ to the north pole. I'm familiar with the geometric interpretation of stereographic projection of $S^n-N$, but not with a closed ball in $\mathbb{R}^n$. What is the stereographic projection for a closed ball?","['differential-topology', 'manifolds-with-boundary', 'manifolds', 'differential-geometry']"
876462,Calculation for the chance of finding something a given distance from a starting point by walking straight in a random direction?,"The premise is basically a 2D plane with a single point, the starting point. Now a landmark sought by a hiker is a certain distance from that point. If the hiker can only see 1 mile in any direction, the chance of him finding the landmark by walking straight in a random direction from the starting point seems like it will go down the further away the thing is. Practically speaking if something is 20 yards from the starting point then any direction I choose to walk I will see it right away. But if something is 20 miles from the starting point then my chance of finding it by walking in a straight line should reduce drastically. I am imagining a circle that has a radius equal to the distance of the landmark (the center of the circle being the starting point). The further the landmark is, the bigger the circle is, which means if I divide by 360 the 'chunks' will be bigger. What am I talking about? What's the math for this? Also, please evaluate my tags, because I am not sure which category this would fall under but I will adjust if you leave a comment (or edit if you have the power). Thanks!","['geometry', 'trigonometry', 'probability']"
876524,"What's the behaviour of $I_n=\int_0^1\left(\frac1{\log x}+\frac1{1-x}\right)^ndx$, as $n \to \infty$?","Set 
  $$
I_n :=\int_0^1\left(\frac{1}{\log x} + \frac{1}{1-x}\right)^n \:\mathrm{d}x \qquad n=1,2,3,\cdots.
$$ We have
$$I_1 =\gamma, \quad I_2 =\log (2 \pi) - \frac 32, \quad I_3 = 6 \log A - \frac{31}{24}, \quad I_4 = 2 \log A + \frac{5 \zeta(3)}{2\pi^{2}}- \frac{49}{72}, \quad ...$$
where $A$ is the Glaisher-Kinkelin constant defined by
$$
\begin{equation} \displaystyle
A :=\lim_{n\to\infty}\frac{1^22^2\cdots
n^n}{e^{-n^2/4}n^{\frac{n^2+n}{2}+\frac{1}{12}}}=1.28242712\cdots.
\end{equation}
$$ I wonder if there is a ""simple"" equivalent for $I_n$ as $n$ tends to $+\infty$? Edit . I had designed the following integral $$\displaystyle \int_0^1\left(\frac{1}{\log x} + \frac{1}{1-x}\right)^2 \mathrm{d}x$$ which I submitted to American Mathematical Monthly ( March 2012 , problem 11629), the problem was then spread and came in this forum with different interesting solutions (I) . An interesting general formula for $I_n$ has been found (II) , but I don't think the latter formula is tractable for the above question on asymptotics .","['calculus', 'integration', 'definite-integrals', 'asymptotics', 'real-analysis']"
876539,Surjectiveness of standard-normal c.d.f. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $\phi:\mathbb R \to (0,1)$ be a function defined as $\phi(y)=\int_{-\infty}^y\dfrac{1}{\sqrt{2\pi}}e^{-\dfrac {x^2}{2}}dx , \forall y\in \mathbb R$ , then is it true that $\phi$ is surjective ? If yes, then what is the proof ?","['definite-integrals', 'normal-distribution', 'functions']"
876564,An empty set minus a nonempty set and the difference between two disjoint nonempty sets?,"Let
$E, F$
be two sets. 1) If $E$ is empty and $F$ is nonempty, is their difference $E \setminus F$ meaningful? 2) If $E, F$ are both nonempty and disjoint, is their difference $E \setminus F$ meaningful?",['elementary-set-theory']
876588,Can the proof of fixed point theorems ever be constructive?,"Overall, Brouwer fixed point theorem and Kakutani fixed theorem are non-constructive. Is there any established paper that demonstrates that there exists constructive proofs that do exactly what these theorems do?","['logic', 'fixed-point-theorems', 'constructive-mathematics', 'real-analysis']"
876590,"""Remainder"" operation in mod 2^32","I debated posting this here, in the cryptography SE, or the programming SE. Obviously, I chose here, but I'm not confident in my choice... I'm attempting to ""undo"" a function, but I've hit a slight snag. I have a function  $h=x*33+c$. I know $h$, and can constrain $c$ to a range of approximately $[65,\ 120]$. Investigating all of those $c$'s is not computationally viable, the reason being that this function is often applied iteratively, so it has an exponential complexity increase. Instead, I figured I could further narrow what $c$'s I have to investigate by using the equation $y=h\mod{33}$. $y$ would be the remainder. From there, I can investigate only those values of $c$ that satisfy this equation: $y \equiv c\mod{33}$, since subtracting $c$ from $h$ must lead to a number that can be evenly divided by 33. The problem is, all this math was evaluated under a 32bit computer, which means every math operation is $\mod2^{32}$. Some x's were large enough that the evaluation of the original function caused $h$ to make one (or possibly several) wraps around this modulus point, otherwise my task would be straightforward. My question is, how can I find the remainder, given that I need to account for this ""overall"" modulus? I asked a related question about division around a modulus here: https://softwareengineering.stackexchange.com/questions/250811/undoing-an-integer-wraparound# and was told about the multiplicative inverse. Does a similar thing exist for remainder operations? For example, if we evaluate the function with values $x = 193492627$ and $c = 98$, we get $h = 2090289493$ (because h is $\mod2^{32}$). Is there an operation $\Omega$ such that $ (h\;\Omega\;33)=32$? (The result being $32$ because $98 \equiv 32 \pmod{33}$) Here's an example of what I can do, in a case where $h$ has not wrapped. $h = 177676$ $y = h\mod{33} = 4$ Values of $c$ where $4\equiv c\mod{33}$: $70$ and $103$ I can now pursue only those two values of $c$. (Find the values of $x$ that correspond to them, etc) Here's an example of the same algorithm above, but in a case where $h$ has wrapped: $h = 2090289493$ $y = h\mod{33} = 28$ <-- Incorrect! Should be 32 Here is an example of the algorithm using the operation $\Omega$ and an $h$ that has wrapped. This is what I'd like to do, but I don't know what operation $\Omega$ represents. $h = 2090289493$ $y = h\ \Omega\ {33} = 32$ Values of $c$ where $32\equiv c\mod{33}$: $65$ and $98$ I can now pursue only those two values of $c$.","['modular-arithmetic', 'discrete-mathematics', 'number-theory']"
876619,Is calculus not rigorous?,"While studying single and multivariable calculus during my first year some people complained that calculus wasn't rigorous enough, when I asked about this no one seemed to be able to really specify exactly what was not rigorous about it. So I want to ask if this is true or if my friends tried to be smarty pants? My professors mentioned nothing about this. The only such thing I can think of is that we considered $\mathbb{R}$ (and $\mathbb{R}^n$) to be given and just kind of ""the number line of every number you possibly can think of"". We didn't care about the construction of the reals at all. But I'm pretty sure that this is not what they meant. I don't think I will take any sturdy course in real analysis so I want to ask if the standard definitions and proofs involving limits, derivatives, differentiability, continuity, integrals etc one stumbles upon in calculus is somehow ""simplified"" in calculus and made more formal and ""clear"" in later and more advanced courses in real analysis? If this is true, does it exist any good examples which can illustrate this for someone who is slightly afraid of epsilon and deltas?","['calculus', 'soft-question']"
876621,"If $R$ is a transitive relation, then $R\circ R\subseteq R$","Here's the question I'm struggling with: Let R be a transitive relation on a set A.  Prove the R composed with R is a subset of R. I'm kind of lost on how to prove this. I've started with saying: ""If R is transitive, then R is the subset of A such that (a,b) is in R and (b,c) is in R, and, due to transitivity, (a,c) is in R when (a,b) and (b,c) have the same b for all a, b, c in A."" Now, for R composed with R, I understand that there is an (a,b) in R and an (b,c) in R, and R composed with R is the set of all (a,c) in A such that (a,b) and (b,c) have the same b. So to continue from here, this is what I've written, continuing from the previous quotation: ""The composition of R and R on the set A is the subset of all (a,c) in A such that (a,b) in R and (b,c) in R have the same b."" And now I'm lost - I'm not sure how to show that R composed with R is a subset of R from here. I was going to write out my attempt but I realized I was simply repeating myself and didn't make much sense, so I'd like to ask for some direction before I try again. Thanks for any help!","['discrete-mathematics', 'elementary-set-theory', 'function-and-relation-composition', 'relations', 'proof-writing']"
876653,"Combination with repition, Representation techniques.","Consider the following Question: A bagel shop has onion bagels, poppy seed bagels, egg bagels, salty bagels, pumpernick bagels, sesame seed bagels, raisin bagels, and plain bagels. How many ways are there to choose e.) a dozen bagels with at least three egg bagels and no more than two salty bagels? In this question, I do have the right answer but not sure if I have the most efficient representation. Later, I will elaborate much more complicated scenarios using the same technique, and ask what then? My Representation: First of all, I represent the information in my head as suggested by the book, by Stars and Bars , where the bars represent the division of source items (in this case the 8 types of bagels each have a bar), and stars that represent the items chosen (in our case the dozen bagels chosen). I represent it, to something like this, $$|*||**|*\dots||$$ If the right of bar have nothing in between, then the bagel represented by the bar is not selected. If the right of bar of $z$ times in between, then the bagel represented by the bar is selected $z$ times. Now that we have a mental model of the problem, it is easy to see that we are just selecting the number of ways we are positioning $*$ or $|$. As the book mentioned, this can be reduced to a Combination problem, let $n$ be the number of choices (bagels types in our case), $r$ be the number of items chosen from $n$ bagels, (a dozen bagels in our case, $${{n + r - 1}\choose{r}}$$ $n-1$ since $n$ objects only need $n-1$ bars to divide them. That all being said, this is still not enough to solve the problem above, we need to factor in ""no more than two salty bagels"". With Stars and Bars , this can be represented by 3 cases, when when 0 salty bar is Thus we need to add the cases of 0 salty bagels, 1 salty bagels, 2 salty bagels. Suppose the first bar is the salty bagel, and the second bar is the second bagel, the rest have $x$ to represent variable stars. $$||*x|x|x|x|x|x|x|x|x|x$$
$$|*|*x|x|x|x|x|x|x|x|x|x$$
$$|**|*x|x|x|x|x|x|x|x|x|x$$ The combination of each are added below, $${{7 + 12 - 3 - 1}\choose{12-3}} + {{7 + 11 - 3 - 1}\choose{11-3}} + {{7 + 10 - 3 - 1}\choose{10-3}}$$ Problem: As you can see, the representation when the constraint is ""at least $b$ of this element"" is very easy. By having at least $b$ items of this element, there's only $r-b$ to choose, where $r$ is the number of element chosen. But to represent ""no more than $c$ elements are to be chosen"", I have to add instances when $0, 1, \dots, c$ elements are in the set. All the problems in this chapter of Generalized Permutation and Combination have this scenario, which if you ask me, does not sound very generalized. So, How do you efficiently represent ""no more than $c$ items of this elements"" problems? How do you represent when there's more than one ""no more than $c$ items of this elements""? (e.g. salty bagels and egg bagels demand for their own maximum items). The only think I can think of now is adding probabilities when $(0 salty, 0 egg), (0, 1), \dots (0, max_{egg}) \dots (max_{salty}, max_{egg}$. But that is very unrealistic in computation standpoint since that will take $O(d^2), d = \max(max_{egg}, max{salty})$, which is very inefficient. Compared to all ""at least $b$ elements"" problems, it is $O(1)$. I have never seen the book in this current chapter describe such phenomena despite having the chapter title that it should be.","['discrete-mathematics', 'combinatorics']"
876685,How to reverse matrix vector multiplication?,"I'm using the simple matrix x vector multiplication below to calculate result . And now I wonder how can I calculate vector if I know matrix and result ? So when I multiply matrix and vector afterwards again I get result . Sorry I don't know how you call this multiplication. I was never deep in those math topics. I have a program that does my calculation. I hope you can understand and classify the multiplication: // float[] matrix = [4x4], float[] vector = [4] column vector

float[] result = new float[vector.Length];
for (int column = 0; column < 4; column++)
{
    for (int row = 0; row < 4; row++)
        result[column] += matrix[column + row * 4] * vector[row];
}
return result; Update: I found this for inverted matrices and I now remember mathematicians don't care for complexity of things but we programmers do. Is there no way to avoid matrix inversion (to lessen complexity) ? Solution: I implemented the raw 4x4 matrix inversion and (alternatively) I inverted the matrix generation . In the end I got the very same matrices and the very same valid results for my vector. I choose the 2nd path because that reduces the complexity to around the same as the calculation done in my first sentence above. Thank you for the help!","['matrices', 'numerical-linear-algebra', 'vectors']"
876731,Group elements $x$ and $y$ satisfying $x^2 = y^2x^2y$ and $yx^{-1}y^2 = x^7$ commute.,"The Question Suppose that $x$ and $y$ are elements of a group such that
$$x^2 = y^2x^2y$$
and
$$yx^{-1}y^2 = x^7.$$
Show that $x$ and $y$ commute. Motivation This came up in another question , where it was asked to establish that the presentation
$$\langle x,y \mid x^2 = y^2x^2y, (xy^2)^2 = yx^2, yx^{-1}y^2 = x^7\rangle,$$
in which the second relation is redundant (pointed out by Derek Holt), is cyclic of order $24$.  I was able to do so, but my argument used all three relations, and I was not able to come up with one that did not use the second, redundant relation.  I tried, but without success, to do it with just the first and third relations, so I'd be interested in seeing such an argument if one can be had.  (The remainder of the proof goes through just fine using only those two relations.) (Note: The linked question may disappear; it is currently on hold.)","['finite-groups', 'group-theory', 'group-presentation']"
876755,Why left multiplication when it comes to Markov chains?,"When working with Markov chains and transition matrices $P$ we multiply from the left, meaning that for example $\mu^{(n)} = \mu^{(0)}P^n$ or that the stationary distribution satisfies $\pi = \pi P$. Especially for the stationary distribution this means that $\pi$ is a left eigenvector of the transition matrix $P$. Why do we do this left multiplication? Is it just a convention or are there any other reasons why this is done? I couldn't think of an intuitive explanation. In my opinion, it seems more intuitive to do $\mu^{(n)} = P'^n\mu{(0)}$ and treat $\pi$ as a (normal/right) eigenvector $\pi = P' \pi$. It seems to me that, in this case, $P' = P^t$.","['matrices', 'markov-chains']"
876782,Evaluate $\int_{0}^{\large\frac{\pi}{4}} \ln {(\sin x)}\cdot\ln {(\cos x)} \left(\frac{\ln{(\sin x)}}{\cot x}+\frac{\ln {(\cos x)}}{\tan x}\right)dx$,"How do I find the value of this integral? $$I=\int_{0}^{\Large\frac{\pi}{4}} \ln {(\sin x)}\cdot\ln {(\cos x)} \left(\dfrac{\ln{(\sin x)}}{\cot x}+\dfrac{\ln {(\cos x)}}{\tan x}\right)dx$$ I  tried substituting $t=\ln {(\sin x)}\cdot \ln {(\cos x)}$ and $t=\dfrac{\ln {(\sin x)}}{\ln {(\cos x)}}$, but it isn't working.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
876789,"Continuous time markov chains, is this step by step example correct","I have some questions regarding CTMC... and most importantly whether the step-by-step example I provide below is correct. My main sources about CTMC are: ( [1] , and [2] ). Let's assume 3 possible states $S = {1, 2, 3}$. There are the following data instances $D = {d_1, d_2, d_3, d_4}$ from which I want to model as a CTMC. In parenthesis the time spent at the state before transiting to the next. $
d_1 = 1(3min) \rightarrow 2(3min) \rightarrow 3\\
d_2 = 1(8min) \rightarrow 2(12min) \rightarrow 3\\
d_3 = 1(2min) \rightarrow 3\\
d_4 = 2(2min) \rightarrow 3
$ The main question(s) I want to ask and answer from the CTMC is: Problem: What is the probability of transiting from state $i$ to state $j$ given that $s$ time has elapsed since entering state $i$? So to form the CTMC I start with the embedded transition matrix for $D$ which is: $
p_{ij} = \begin{bmatrix}
0 & 2/3 & 1/3 \\
0 & 0 & 1 \\
0 & 0 & 1
\end{bmatrix}
$ Now the next step is to calculate the rates. From [1, p3] it says that ""Each time state i is visited, the chain spends, on average, $E(Hi) = 1/a_i$ units of time there before moving on"" . From what I understand $a_i$ is the set of rates for state $i$, also denoted in other texts as $\lambda_i$ or $v_i$, for example an operator receives 2 calls in an hour, hence $a_i = 1$ call in half an hour. However, I am not sure how to calculate this from the above data $D$. But, I can calculate the average time spent at each state and then from the above equation, solving for $a_i = 1 / E(H_i)$ I can obtain these rates... $E(H_i) = \begin{bmatrix}4.33 & 5.66 & 0 \end{bmatrix}$, denoting with 0 the terminal (consume) state. Hence, $a_i = \begin{bmatrix}0.23 & 0.18 & 0 \end{bmatrix}$, again 0 is for consume state. Q1: Is this valid? Q2: Given that in this way I assume that the probability distribution of time spent is an exponential distribution, I lose the true variance of the actual distribution as the variance of the exponential distribution is the same as the mean... Is this OK? Is there any other way? Q3: How can terminal/consume states be represented? Again from [1, p3] I can now compute the transition rate matrix (infinitesimal generator) $Q$: $Q_{ij} = -a_i$, if $i==j$ $Q_{ij} = a_i * p_{ij}$, if $i != j$ $
Q = \begin{bmatrix}
-0.23 & 0.15 & 0.08\\
0 & -0.18 & 0.18\\
0 & 0 & 0
\end{bmatrix}
$ Q4: Although [1, p3] states that $Q_{ii} = -a_i$, [2, p227] says that $Q_{ii} = 0$. Which one is correct then? Now that we know $Q$, from [1, p2] I can calculate $P_{ij}(t)$ as follows: $P_{ij}(t) = e^{Qt}$ (from what I read there are a number of ways to compute that and I can use a numerical software that implements them) Q5: I assume $t = s$, ie the elapsed time since entering state $i$ Q6: Why do I need to calculate the complete matrix $P_{ij}(t)$ if I am interested in one particular ${ij}$. Is there any way to calculate that. Q7: I read in [2, p.228] that if the process can be modelled as a Poisson process then the solution is: $P_{ij}(t) = \dfrac{(\lambda_i t)^k}{k!}e^{-\lambda_i t}$, where $k$ is the number of events in an interval of length t, which in my case above is $1$. Can I assume that the above process is a Poisson process? Q8: And lastly is everything I have explained in the above step-by-step example correct? Thank you the most for your time reading this and if you can provide any answers to my questions.","['statistics', 'markov-chains', 'markov-process']"
876791,"The definition of Compactness for ""set"" and ""space""","Compactness for ""set"" and ""space"" I was wondering if there is any significance between the two settings. Do we treat them as two different things? For example, let $(X,d)$ be a metric space with the topology induced by the metric $d$. From Heine-Borel theorem (for metric space), we know that the following are equivalent: Every sequence has a convergent subsequence; $X$ is a compact space. And this is wrong about sets, take $\left\{\frac{1}{n}\right\}_n$ in $[0,1]$, it has a convergent subsequence, but it is only pre-compact (its closure is compact). Edit: I guess if you take $\left\{\frac{1}{n}\right\}_n$ as a subspace, it does not have any convergent subsequence, therefore not a compact subspace (or set). So the two settings are actually the same?","['general-topology', 'compactness', 'real-analysis']"
876801,Trace of symmetric positive semidefinite matrix when diagonalized (as a bilinear form) in a non-orthogonal basis,"Let $\mathbf{S}$ be symmetric positive semidefinite matrix (i.e. one with all eigenvalues real and non-negative). Then there is an orthogonal matrix $\mathbf{U}$ (with its columns forming an orthonormal basis) such that $\mathbf{U}^\top \mathbf{S} \mathbf{U}$ is diagonal; this basis is of course given by eigenvectors of $\mathbf{S}$. Consider another basis $\mathbf{V}$ consisting of unit-length but non-orthogonal vectors (so columns of $\mathbf{V}$ have unit length but are not orthogonal) that also diagonalizes $\mathbf{S}$, i.e. $\mathbf{V}^\top \mathbf{S} \mathbf{V}$ is diagonal. I suspect that the following is true: $\mathrm{Tr}(\mathbf{V}^\top \mathbf{S} \mathbf{V}) \le \mathrm{Tr}(\mathbf{S})=\mathrm{Tr}(\mathbf{U}^\top \mathbf{S} \mathbf{U})$. Is it true? If so, how can it be proved? Furthermore, is it true that the equality is reached iff V is orthogonal? Update: Following some confusion in the comments, I would like to clarify that I am considering $\mathbf{S}$ to represent a bilinear form, not a linear form. So with a change of basis it is transformed as $\mathbf{V}^\top \mathbf{S} \mathbf{V}$ and not as $\mathbf{V}^{-1} \mathbf{S} \mathbf{V}$. Update 2 Let me illustrate where this question comes from; it might provide some additional intuition. $\mathbf{S}$ is actually a covariance matrix of some data (i.e. I have a set of data points $\mathbf{x}_i \in \mathbb{R}^N$, and $\mathbf{S} = \sum_i \mathbf{x}_i \mathbf{x}_i^\top$, up to a constant factor). Trace of $\mathbf{S}$ is total variance of the data, and it of course stays the same if coordinate system is rotated. Now for any unit vector $\mathbf{v}$, variance of the projection of the data on the axis defined by this vector is equal to $\mathbf{v}^\top\mathbf{S}\mathbf{v}$. If I take $N$ orthogonal unit vectors, then sum of these variances is equal to the total variance. I am interested in the situation when I take $N$ non-orthogonal unit vectors, but they are chosen such that all projections of the data on these vectors have zero correlation (or covariance). This condition is equivalent to $\mathbf{V}^\top \mathbf{S} \mathbf{V}$ being diagonal. This means that my projections are ""independent""; therefore I am pretty sure that their variances together cannot exceed total variance; total variance should give maximum amount of variance that can be ""distributed"" between independent components (with maximum being achieved with principal components).","['trace', 'matrices', 'linear-algebra', 'bilinear-form']"
876804,Functions with compact support,"I have a question about a convergence of functions with compact support. SETTING Let $d\geq 3$ and  $U \subset \mathbb{R^{d}}$ be open and $dx$= Lebesgue measure on $U$. Let $b_{i},c,d_{i} \in L^{1}_{loc}(U;dx) ,\,1 \leq i \leq d$, such that
$cdx-\sum_{i=1}^{d} \frac{\partial b_{i}}{\partial x_{i}} \geq 0$ and $cdx-\sum_{i=1}^{d} \frac{\partial d_{i}}{\partial x_{i}} \geq0$ in the sense of Schwartz distributions. Suppose $b_{i}+d_{i} \in L^{d}_{loc}(U;dx)$, $1\leq i \leq d$, and $c \in L^{d/2}_{loc}(U;dx)$ then I want to show the following assertion: For any $u_{n} \in C_{0}^{\infty}(U)$, $n=1,2,\cdots$, with $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$ there exists a subsequence $(u_{n_{k}})_{k=1}^{\infty}$ with $u_{n_{k}} \to 0$ $\mu$-a.e. Here $\mu=2cdx-\sum_{i=1}^{d} \frac{\partial(b_{i}+d_{i})}{\partial x_{i}}$ (positive radon measure) Solution(unfinished) For any $v \in C_{0}^{\infty}(U)$, $v \geq0 $ on $U$, put $h_{n}=u_{n}v\quad(n=1,2,...)$ . Then ${\rm supp}\,h_{n} \subset K$ for some compact set $K \subset U$ and all $n \in \mathbb{N}$. \begin{eqnarray*}
\frac{1}{2} \int h_{n}^{2} d \mu&=& \int _{K} h_{n}^{2} d\mu\\
&=& \sum_{i=1}^{d} \int_{K} h_{n} \frac{\partial h_{n}}{ \partial x_{i}} (b_{i}+d_{i})dx+\int_{K} h_{n}^{2}c dx\\
&\leq& \left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2} 
\left(\sum_{i=1}^{d}\left\|1_{K}\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\
&\leq&\left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2} 
\left(\sum_{i=1}^{d}\left\|\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\
\end{eqnarray*} By the following inequality (It is called Sobolev Lemma): $\exists C>0$ s.t. $\forall u \in C_{0}^{\infty}(U)$,
$
\|u\|_{L^{q}(dx)} \leq C  \left(\sum_{i=1}^{d} \int \left|\frac{ \partial u}{\partial x_{i}} \right|^{2}dx \right)^{1/2}$ where $1/q+1/d=1/2$. \begin{eqnarray*}
\|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)} \leq C_{1} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}(b_{i}+d_{i})\|_{L^d(dx)}
\end{eqnarray*} \begin{eqnarray*}
\|u_{n}^{2}1_{K}c\|_{L^{1}(dx)} \leq C_{2} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}c\|_{L^{d/2}(dx)}
\end{eqnarray*} Since $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$, $\sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)}\to 0$ Hence $\int h_{n}^{2} d\mu \to 0$ and there exists $(h_{n_{k}})_{k=1}^{\infty}$ with $h_{n_{k}} \to 0$ $\mu$-a.e. . Because $h_{n_{k}}=u_{n_{k}}v$ $k=1,2,...$ and ${\rm supp}\,v \subset K$, I can get $u_{n_{k}}\to 0$ $\mu$-a.e. on ${\rm supp}\,v $. Can I get $u_{n_{k}}\to 0 $ $\mu$-a.e.? Thanks.","['functional-analysis', 'real-analysis']"
876807,Simplify $\frac {\sqrt5}{\sqrt3+1} - \sqrt\frac{30}{8} + \frac {\sqrt {45}}{2}$,"I am trying to find the value of: $$\frac {\sqrt5}{\sqrt3+1} - \sqrt\frac{30}{8} +  \frac {\sqrt {45}}{2}$$ I have the key with the answer $\sqrt 5$ but am wondering how I can easily get to that answer? I realize this is a very basic question on radicals and I know that square roots can be separated into parts, for instance $\sqrt {45} = \sqrt 9 \cdot \sqrt 5$ and I can see how that would be useful here in canceling out radicals but I have not yet been able to reach a solution using this method.","['radicals', 'arithmetic', 'algebra-precalculus']"
876808,relative sign in Hodge star of tensor product,"Let $V$ be a vector space of arbitrary (finite) dimension and let $(V, \langle \ ,\ \rangle, I) = (W_1, \langle\ ,\ \rangle_1, I_1) \oplus (W_2, \langle\ ,\ \rangle_2, I_2)$ be a direct sum decomposition, with respect to scalar products and complex structures, where $W_{1,2}$ are even-dimensional. On $\bigwedge^\bullet V^* = \bigwedge^\bullet W_1^* \otimes \bigwedge^\bullet W_2^*$, for $\delta_i \in \bigwedge^{k_i}W_i^*$, $i=1,2$, the Hodge $\star$-operator of $\delta_1 \otimes \delta_2$ is given by
$$ \star(\delta_1 \otimes \delta_2)=(-1)^{k_1k_2}(\star_1\delta_1) \otimes(\star_2 \delta_2)$$ We can limit ourselvers here to the vector spaces and their exterior structures, forgetting about continuous dependence on the point in some manifold, etc. (i.e., this should be a linear algebra question); my QUESTION is: where does the $(-1)^{k_1k_2}$sign come from? (This comes from the proof of Proposition 1.2.31 in the book Compelx Geometry:an Introduction , by Huybrechts) I have an IDEA how to do it, using the fact that (with appropriate notation)
$$ (\alpha_1 \otimes \alpha_2)\wedge \star(\beta_1 \otimes \beta_2)=
(\alpha_1 \wedge \star_1 \beta_1)\otimes (\alpha_2 \wedge \star_2\beta_2)$$
and then plugging in the desired sign when I swap $\star_1\beta_1$ and $\alpha_2$, but I don't understand why, roughly speaking, the tensor behaves like the wedge, i.e. (e.g. for one-forms)
$$ (e_1 \otimes f_1) \wedge (e_2 \otimes f_2)= -
(e_1 \wedge e_2)\otimes (f_1 \wedge f_2)$$","['riemannian-geometry', 'linear-algebra', 'differential-geometry', 'hodge-theory']"
876819,"If $a_{n+1}=\cos(a_n)$ for $n\ge0$ and $a_0 \in [-\pi/2,\pi/2]$, find $\lim_{n \to \infty}a_n$ if it exists","Let $a_{n+1}=\cos(a_n)$ for $n\ge0$ and $a_0 \in [0,\pi/2]$ Find $\lim_{n \to \infty}a_n$ if it exists. I drew some sketches and it does seem like the limit exists, it's probably $x$ such that $\cos(x)=x$ I have no idea how to go about solving this, hints would really be appreciated. Thank you for your time!","['real-analysis', 'limits']"
876833,How prove: $a=x$ and $b=x^x$ for $x^{a+b}=a^b b$?,"Let $x, a, b$ natural numbers such that $x^{a+b}=a^b b$. How prove: $a=x$ and $b=x^x$?",['algebra-precalculus']
876838,Computing integral using complex analysis methods,"I'm trying to compute the integral $$
\int_0^{\infty} \frac{\ln(x)}{x^2 + 1} \, dx
$$ using complex analysis methods. We haven't learned residue calculus yet though, only contour integrals up through the Cauchy integral formula. I'm trying to make use of a half circle centered at the origin of radius $R$ and then let $R$ tend to infinity, but there is a definite singularity for the $\ln(x)$ function. Does anybody have a suggestion?",['complex-analysis']
876845,A double series $\frac13 \sum_{j=1}^{\infty}\sum_{i=1}^{\infty}\frac{(i-1)! (j-1)!}{(i+j)!}H_{i+j}$ giving $\zeta(3)$,"Here is a symmetric rational double series giving Apery's constant : $$
\frac13 \sum_{j=1}^{\infty}\sum_{i=1}^{\infty} \displaystyle \frac{(i-1)! (j-1)!}{(i+j)!}  H_{i+j} = \zeta(3)
$$ where $\displaystyle H_{n}:=\sum_{1}^{n} \frac{1}{k}$, $n=1,2,\cdots,$ are the harmonic numbers . How would you prove it? Edit. In 2005, I sent this result to Wolfram MathWorld (see equation 25) , I built it as an echo of $$
 \sum_{j=1}^{\infty}\sum_{i=1}^{\infty} \displaystyle \frac{(i-1)! (j-1)!}{(i+j)!}  = \zeta(2).
$$ See Jack's pretty answer and see my answer below.","['sequences-and-series', 'calculus', 'riemann-zeta', 'harmonic-numbers', 'real-analysis']"
876852,Bijection between $\mathbb N^+ \times \mathbb R^+$ and $\mathbb R^+$,Let $\mathbb N^+$ denote the set of natural numbers bigger than $0$ and let $\mathbb R^+$ denote the set of real numbers bigger than $0$. Is there a way to write down an explicit bijection between $\mathbb N^+ \times \mathbb R^+$ and $\mathbb R^+$?,['elementary-set-theory']
876873,Combination of quadratic and cubic series,I'm an eight-grader and I need help to answer this math problem (homework). Problem: Calculate $$\frac{1^2+2^2+3^2+4^2+...+1000^2}{1^3+2^3+3^3+4^3+...+1000^3}$$ Attempt: I know how to calculate the quadratic sum using formula from here: Combination of quadratic and arithmetic series but how to calculate the cubic sum? How to calculate the series without using calculator? Is there any intuitive way like previous answer? Please help me. Grazie!,"['sequences-and-series', 'calculus', 'algebra-precalculus', 'exponentiation', 'summation']"
876880,Upper bounding a Poisson Process with indicators of exponentials,"Define $E_1,E_2,\ldots, E_i,\ldots E_n$ as i.i.d. exponentials with parameter $\lambda$. These define processes on some interval $[0,\delta]$ (think of $\delta$ as very small, it will come into play later) in the following way $I_i(t):=\mathbb 1_{\{E_{i}\leq t\}}$. One could couple each one of the $I_i$'s with a Poisson Process with parameter $\lambda$ in the following way. Define recursively $N_i^1 := E_i$, $N_i^k := N_i^{k-1} + \mathcal E^k$, with $\mathcal E^k\sim \textrm{exp}(\lambda)$. Then $(N_i^j)_{j\geq1}$ are the points of a Poisson Process with parameter $\lambda$ (essentially, $E_i$ is the first point of the coupled Poisson Process). Call $N_i(t)$ the corresponding Poisson Process. It is clear that the stochastic domination $I_i(t)\preceq N_i(t)\qquad\forall t\in[0,\delta]$ holds. Indeed,  $N_i$ and $I_i$ share their first jump, but $N_i(\cdot)$ may have more after that in the interval $[0,T]$. Now, by summing the processes $I_i$'s and the Poisson Processes $N_i(\cdot)$'s over $i\in\{1,\ldots,n\}$ we get the stochastic domination $\sum_{i=1}^nI_i(t) \preceq  \overline N(t)\qquad t\in[0,\delta]$, where $\overline N(t)$ is a Poisson Process with parameter $n\lambda$. I am interested in finding the opposite inequality, possibly holding only with high probability. In other words, given the sequence $(I_i(t))_{i\geq1}$, is it possible to couple $\sum_{i=1}^nI_i(t)$ with a Poisson Process $\underline N(\cdot)$ (with some unknown rate, depending on $n$, but which should be less than $n\lambda$) such that $\lim_{n\rightarrow+\infty}\mathbb P(\sum_{i=1}^nI_i(t)\geq \underline N(t)) = 1$? Furthermore, the rate $\underline \lambda$ of $\underline N(\cdot)$ should be sufficiently close to $\lambda$, for small $\delta$ (otherwise the trivial choice $\underline \lambda = 0$ would be a solution).","['probability-theory', 'stochastic-processes']"
876893,Calculate $\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots$,I'm an eight-grader and I need help to answer this math problem. Problem: Calculate $$\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots$$ This one is very hard for me. It seems unsolvable. How to calculate the series without using Wolfram Alpha? Please help me. Grazie!,"['sequences-and-series', 'calculus', 'algebra-precalculus', 'summation', 'problem-solving']"
876905,Is there a way to determine the matrix of $\Lambda^k(T)$ given the matrix of $T$?,"Let $T$ be an endomorphism of a finite dimensional vector space $V$. Suppose that $(v_1,\ldots v_n)$ is an ordered basis of $V$. And let $[T]$ be the matrix of $T$ with respect to this basis. Is there a way to compute the matrix of $\Lambda^k(T)$ with respect to the obvious basis given $[T]$? The 'obvious' basis is the $\binom{n}{k}$ $k$-wedge tuples from $\{v_1,\ldots,v_n\}$ with increasing indices. There have been many questions on here about how to compute the characteristic polynomial and the coefficients $(-1)^k\text{tr}(\Lambda^k(T))$, but I haven't seen any interest in the matrix of $\Lambda^k(T)$ itself. I suspect it can be built from the minors of $[T]$, but I have no idea how to proceed.","['matrices', 'linear-algebra', 'abstract-algebra', 'exterior-algebra']"
876909,"find a $B_{n,j}$ such that $|A_{n,j}-L_j| \leq B_{n,j}$ $\forall n,j$ and $\sum_{j=0}^{\infty}B_{n,j}$ converges","We have $A_{n,j}= 3(-1)^j2^{n-j+1}\frac{(2(n-j)-4)!}{(n-j)!(n-j-2)!}\binom{j+2}{2}\frac{n^\frac{5}{2}}{8^n}$ and $L_j=(-\frac{1}{8})^j\binom{j+2}{2}\frac{3}{8\sqrt{\pi}}$ So I know $\lim_{n \to \infty} A_{n,j} = L_j$ implies $\lim_{n \to \infty}  \sum_{j=0}^{1000} A_{n,j}=\sum_{j=0}^{1000}L_j $. Now I want to prove that $\lim_{n \to \infty}  \sum_{j=0}^{n} A_{n,j}=\sum_{j=0}^{\infty}L_j $ So I was thinking that I want to show that $\forall$ small $\epsilon > 0, \exists$ large $N$ such that $   |\sum_{j=0}^{N} A_{N,j}-\sum_{j=0}^{\infty}L_j | < \epsilon$. I know that $|\sum_{i=0}^{N} A_{N,j}-\sum_{j=0}^{\infty}L_j | \leq \sum_{j=0}^{N}|A_{N,j}-L_j|+|\sum_{j=N+1}^{\infty}L_j|$. Since $|\sum_{j=N+1}^{\infty}L_j|$ converges say to less than $\frac{\epsilon}{2}$, we need to show that $\sum_{j=0}^{N}|A_{N,j}-L_j|$ is less than $\frac{\epsilon}{2}$. This is similar to the Wierstrauss M-test, I would like to find a $B_{j}$ such that $|A_{n,j}-L_j| \leq |A_{n,j}| \leq B_{j}$  $\forall n,j$ and  $\sum_{j=0}^{\infty}B_{j}$ converges. How do I find such $B_{j}$? Need some help.","['summation', 'sequences-and-series', 'real-analysis', 'analysis']"
876914,Two questions in spectral theory: the spectrum of the Fourier transform and the Hamiltonian of the hydrogen atom.,"I have the following two questions: The Fourier transform defines a unitary (provided that it is normalized properly) map $\hat{\cdot}:L^2(\mathbf{R})\rightarrow L^2(\mathbf{R})$. I figured out its point spectrum, which is very easy; is it possible to determine the whole spectrum of this operator? I know $\sigma_p(\hat{\cdot})=\mu_4(\mathbf{C})$ ($4$-th roots of unity) already; is it the case $\sigma(\hat{\cdot})=\mu_4(\mathbf{C})$ also, maybe because $\sigma_p$ might be dense in $\sigma$? Is there is a concise way (not taking more than two pages say) way to see that the closure $H$ of the Hamiltonian operator of the hydrogen atom (defined on $C^\infty_0$), viz.
$$-\frac{1}{2}\Delta-\frac{1}{\|x\|},$$
has domain $H^2(\mathbf{R}^3)$, is self-adjoint, and determine the spectrum. Remarks on 2: I found a reasonably short proof of self-adjointness in Reed/Simon's Methods of modern mathematical physics, vol. II, Thm. X.15. I look forward to your answers.","['fourier-analysis', 'operator-theory', 'mathematical-physics', 'spectral-theory', 'functional-analysis']"
876922,Intuitive ways to get formula of cubic sum,"Is there an intuitive way to get cubic sum? From this post: combination of quadratic and cubic series and Wikipedia: Faulhaber formula , I get $$1^3 + 2^3 + \dots + n^3 = \frac{n^2(n+1)^2}{4}$$
I think the cubic sum is squaring the arithmetic sum $$1^3 + 2^3 + \dots + n^3 = (1  + 2 + \dots + n)^2$$
But how to prove it? Please help me. Grazie!","['summation', 'sequences-and-series', 'algebra-precalculus']"
876927,Homotopy groups relating to toric varieties,"It is known that the toric variety $X_\Sigma$ of a simplicial fan $\Sigma$ can be constructed as a quotient 
$$X_\Sigma = \bigl(\mathbb C^N \setminus V(B)\bigr)/G.$$
Here $N$ is the number of rays, $B$ is the irrelevant ideal and $G$ is a certain subgroup of the big torus $(\mathbb C^\ast)^N$. Assume that $\Sigma$ is a normal fan of a polytope. Then it is also known that (*) $\mathbb C^N \setminus V(B)$ is the complement of the union of sets of (complex) codimension at least $2$. Questions: I have heard (at several places) that the fact (*) implies that $\mathbb C^N \setminus V(B)$ is simply connected. How can we prove this? Can we see that $\pi_2(\mathbb C^N \setminus V(B))$ vanishes as well? Notes: We follow the notation in Cox's lecture notes . (Lectures on toric varieties) If $X_\Sigma$ is smooth, we can see that $\pi_2(\mathbb C^N \setminus V(B))=0$: Since $A_{n-1}(X_\Sigma) = H_{2n-2}(X_\Sigma) \cong H^2(X_\Sigma)$ is a free abelian group of rank $b$, $G=\mathrm{Hom}_{\mathbb Z}(A_{n-1}(X_\Sigma),\mathbb C^*)$ is a complex torus of dimension $b$. The homotopy long exact sequence gives us a short exact sequence of free abelian groups $0\to\pi_2(\mathbb C^N \setminus V(B))\to\pi_2(X_\Sigma)\to\pi_2(BG)\to0$. Since $X_\Sigma$ is $\pi_2(X_\Sigma)$ is also a free abelian group of rank $b$ ($\because$ Hurewicz theorem), the homomorphism $\pi_2(X_\Sigma) \to \pi_2(BG)$ is an isomorphism. I am looking for a direct proof of the 2-connectedness of the Zariski open subset $\mathbb C^N \setminus V(B)$ . Because if we have such a proof, then we can use it to compute some homotopy groups (and cohomology groups) conversely. Please do not use glueing construction of toric varieties.","['geometric-invariant-theory', 'algebraic-geometry', 'algebraic-topology', 'invariant-theory', 'homotopy-theory']"
876936,A unfamiliar question,I'm sure asking this kinda problem is stupid but somehow I have never seen such problems before. $2{x}^2 + 3{y}^2 =0$ what is $3x+2y$?,['algebra-precalculus']
876937,Do runs of every length occur in this string?,"In reference to the strings defined here (constructed by repeatedly appending the last ""half"" of the current string), consider the particular infinite string $s$ generated by starting with $\text{abc}$: $$\begin{align}
\quad 
&\text{abc}\\
&\text{abcbc}\\
&\text{abcbccbc}\\
&\text{abcbccbcccbc}\\
&\cdots\\
&\text{______________________________}\\
s = \ &\text{abcbccbcccbcbcccbccbcbcccbccccb...}
\end{align}
$$ More formally, the general rewriting rule is 
$$a_0 a_1 \cdots a_{n-1} \ \ \to \ \ a_0 a_1 \cdots a_{n-1} a_{\left\lfloor\frac{n}{2}\right\rfloor } a_{\left\lfloor\frac{n}{2}\right\rfloor+1} \cdots a_{n-1}.
$$
Clearly, $\text{a}$ occurs only in the initial position, $\text{b}^k$ occurs infinitely often for $k=1$, but never occurs for $k\ge2$, and one may conjecture that $\text{c}^k$ occurs for every $k\ge 1$ (and hence, infinitely often for each $k\ge 1$). How to prove or disprove the conjecture? Some possibly-relevant facts: Computations show that the index of the first occurrence of $\text{c}^k$ is as follows, for some small $k$:
$$\begin{align}
&\text{substring} \quad & \text{index}\\
&\text{c} &\text{2}\\
&\text{cc} &\text{4}\\
&\text{ccc} &\text{7}\\
&\text{cccc} &\text{26}\\
&\text{ccccc} &\text{27308}\\
&\text{cccccc} &\approx 10^{519}\\
&\text{ccccccc} &? \ (\gt 10^{40677})\\
\end{align}
$$
(The exact index for the first occurrence of $\text{c}^6$ is a $520$-digit number, and $\text{c}^7$ does not occur in the first $10^{40677}$ terms of $s$.) Let $L_n$  be the length of the $n$th intermediate string in the generating process illustrated above. Then 
$$L_{n+1} = L_n + \left\lfloor\frac{L_n + 1}{2}\right\rfloor,\ \ L_0 = 3.$$
Hence, $L_n$ grows exponentially:  $$L_n  \gtrsim 3(\frac{3}{2})^n.$$ Let $s_n$ be the $n$th intermediate string, and let $t_n$ be the $n$th appended string (so $s_n = s_{n-1} t_n$). Now, every intermediate string ends with $\text{bc}$, so $\text{c}^k$ would first occur only when some $t_n$ begins with $\text{c}^{k-1}$, in which case $s_n= s_{n-1} t_n$ will contain the first occurrence of $\text{c}^k$ beginning at index $L_{n-1}-1$. After $\text{c}^k$ first occurs, the number of instances of $\text{c}^k$ grows approximately exponentially in the number of iterations, as does the length, and the ratio
$$p_k = \frac{\text{number of instances of c}^k\text{ on the }n\text{th iteration}}{L_n} \approx \frac{1}{\text{index of the first occurrence of c}^k}
$$
is approximately a constant independent of $n$. 
Since $\text{c}^{k+1}$ first occurs when one of these instances of $\text{c}^k$ happens to begin the ""last half"" of an intermediate string, this may be compared to a sequence of Bernoulli trials, each with success probability $p_k$. For such a process, the expected number of trials to get the first success is just $1/p_k$, so the index of the first occurrence of $\text{c}^{k+1}$ would be compared to 
$$\frac{2}{3} L_{n_k + 1/p_k} \approx 2(\frac{3}{2})^{n_k + i_k} 
$$
where $n_k$ is the number of iterations to get the first occurrence of $\text{c}^k$, and $i_k$ is the corresponding index. E.g., the first-occurrence index of $\text{c}^6$ would be compared to $2(\frac{3}{2})^{n_5 + i_5} = 2(\frac{3}{2})^{22 + 27308} \approx 10^{4813}$ (when in fact it is approximately $10^{519}$). Similarly, the first-occurrence index for $\text{c}^7$ (if it exists) would be compared to $2(\frac{3}{2})^{n_6 + i_6} \approx 10^{10^{518}}$.
These comparisons are quite poor, but may help to understand how the first-occurrence indices can be so enormous.",['sequences-and-series']
876961,Are noetherian hypotheses necessary for the theory of the etale fundamental group?,"The etale fundamental group, as explained in SGA 1 Expose 5 and various other notes I've read, always makes the assumption that the scheme $S$ (for which one intends to construct a fundamental group), is locally noetherian . How necessary is this assumption? For example, let $\text{FEt}_S$ be the category of schemes finite etale over a fixed connected scheme $S$. Is $\text{FEt}_S$ a galois category when $S$ isn't locally noetherian? From the viewpoint of galois categories, it seems that almost all the axioms for a galois category are obvious for $\text{FEt}_S$ (without any noetherian hypotheses), except possibly the conditions: For any $X\in\text{FEt}_S$ and a finite group $G$ acting on $X$ by automorphisms over $S$, the quotient $X/G$ exists in $\text{FEt}_S$. For a geometric point $s\in S$, and any $X\in\text{FEt}_S$ acted on by a finite group $G$ of $S$-automorphisms, the fiber functor $F_s$ satisfies $F(X)/G\cong F(X/G)$ The latter appears to follow from SGA 1 Expose 5 beginning of section 2 (as presented here http://arxiv.org/abs/math/0206203 ) However, I'm not sure if the first is true. Since $X\rightarrow S$ is finite hence affine, you can reduce to the case where $X,S$ are both affine. In this case if $X = \text{Spec }A$, then $X/G$ is just $\text{Spec }A^G$, but I don't know if $\text{Spec }A^G$ is finite etale over $S$.",['algebraic-geometry']
876974,Where is the error in my proof that all derivatives are continuous?,"I know that this can not be true due to counter-examples but I don't know where the error in my reasoning is. Assumption:
If $f(x)$ is differentiable in $\mathbb{R}$ then the derivative $f'(x)$ is continuous in  $\mathbb{R}$. Faulty Proof:
For every $c \in \mathbb{R}$, using the mean value theorem for $f(x),$ on the interval $x \in [c, c + h] $ where $h$ is positive. $$
\frac{f(c + h) - f(c)}{h} = f'(\xi(h))
$$ Where $\xi(h) \in (c,c+h)$. Because this equation holds for every $h>0$. It must hold in the limit as $h \rightarrow 0^+$. $$
\lim_{h\to 0^+}\frac{f(c + h) - f(c)}{h} = \lim_{h\to 0^+}f'(\xi(h)) 
$$ But the left side of the equation is the right one sided derivative. $$
f'_{+}(c) = \lim_{h\to 0^+}\frac{f(c + h) - f(c)}{h} = \lim_{h\to 0^+}f'(\xi(h)) 
$$ The same can be done for $h$ being negative, but because of differentiability at every point the left and right derivatives must be equal. $$
f'(c) = f'_{+}(c) = f'_{-}(c) = \lim_{h\to 0^-}\frac{f(c + h) - f(c)}{h} = \lim_{h\to 0^-}f'(\xi(h)) 
$$ As $h \rightarrow 0^+$, $\xi(h) \rightarrow c$. So because the limit $\lim_{h\to 0^+}f'(\xi(h))$ exists and $\xi(h) \neq c$, it is equal to $\lim_{x\to c^+}f'(x)$ It follows that $\lim_{x\to c^+}f'(x) = \lim_{x\to c^-}f'(x) = f'(c)$ so the function $f'(x)$ is continuous.","['continuity', 'calculus', 'derivatives', 'real-analysis']"
876982,Does there exist two distinct set which are not an element of a given infinite set?,"Let $X$ be an infinite set. Under ZFC, it is true that $X\notin X$. So there is at least one set which is not an element of $X$. Is there another element distinct from $X$ which is not a member of $X$?",['elementary-set-theory']
876989,"$\sum a_n$ converges, $a_n \in \mathbb{R}$, then there exists real sequence $b_n$ such that $b_n\rightarrow +\infty$ and $\sum a_n b_n$ converges.","Assume that $\sum a_n$ converges, $a_n \in \mathbb{R}$, then there exists real sequence $b_n$  such that $b_n\rightarrow +\infty$ and $\sum a_n b_n$ converges. Same to be easy at first thought, can we find such $b_n$ represented by $a_n$?","['sequences-and-series', 'real-analysis']"
876991,Alternative set theories?,"Is there a version of set theory that allows the existence of a set that does not admit the empty set as a member? I.e., reject the axiom $A\cup \emptyset = A$","['elementary-set-theory', 'soft-question']"
877004,How many strings with seven or more characters can be formed from the letters of EVERGREEN.,"Question: How many strings with seven  or more characters can be formed from the letters of EVERGREEN. I'm lost on this one, the answer is supposed to be 19, 635. My Attempt: I've tried using the permutations with indistinguishable objects formula (some letters repeat), $$P([n_1,n_2,\dots,n_k], n) = \dfrac{n!}{n_1!n_2!\dots n_k!}$$ Where $n$ is the number of objects overall (including repetitions). And the $n1,n2,…,nk$ are the repetition count. 
Added the results for $n = 7, 8, 9$ but only got $8505$.",['probability-theory']
877042,Binomial dependent on a Poisson,I have been working on a problem with a binomial rv dependent on a poisson rv and have worked through to this point: $P(X=x) = \sum_{n=x}^{\infty} \dfrac{n!}{x!(n-x)!} p^x(1−p)^{n−x} \dfrac{\lambda^n e^{-\lambda}}{n!}$ Might someone guide me through a next step?,"['binomial-coefficients', 'poissons-equation', 'probability']"
877049,"Cauchy sequences - can we control the rate at which elements ""get closer""?","In Simon & Reed's book Methods of Modern Mathematical Physics, it is proven in chapter 1 (Theorem 1.12) that $L^1$ is complete (Riesz-Fisher theorem). The proof starts off as follows: Let $f_n$ be a Cauchy sequence of functions in $L^1$. It is enough to show that some subsequence converges (this has been shown earlier) so we pass to a subsequence (labeled in the same way) with $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$ . This arouses my suspicion (although surely I will turn out to be wrong): Can we pick a subsequence such that $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$? This seems strange to me because it seems to say something about the rate of at which elements ""get closer"" under this norm (I should probably specify that $\left|\left| f\right|\right|_1=\int \left| f \right| dx$), rather than just saying that they do get arbitrarily close at some point. In particular, it seems to say that each progressive element is ""twice as close"". The definition of a Cauchy sequence says that for each $\epsilon>0$ we can choose and $N$ such that $n,m>N$ implies $\left|\left| f_n-f_m\right|\right|_1=d(f_n,f_m)\leq\epsilon$, where $d(\cdot,\cdot)$ is the metric induced by the norm. This, to me, does not seem equivalent to saying that for any strictly positive $\epsilon(n)$ there is a subsequence such that $d(f_n,f_{n+1})\leq \epsilon(n)$. Am I mistaken?","['normed-spaces', 'cauchy-sequences', 'real-analysis']"
877074,Asymptote of solution of a differential equation without solving it,"Consider the following differential equation (domain $\mathbb{R}$): $$
u(x) = 1 - u'(x)
$$ and suppose $u(0) = 0$. How can one prove that $u(x) \to 1$ for $x \to \infty$ without solving the equation explicitly?","['ordinary-differential-equations', 'real-analysis']"
877078,Inductive proof that if there is an injection $\mathbb{N_m} \rightarrow \mathbb{N}_n$ then $m\le n$,"The statement to prove is: If there exists an injection $\mathbb{N_m} \rightarrow \mathbb{N}_n$ then  $m\le n$ The solution says to prove by induction on $n$. I just need help on the inductive step: $P(k): \forall m \in \mathbb{Z}^+(\exists \text{ injection } \mathbb{N}_m\rightarrow \mathbb{N}k) \Rightarrow m \le k$ $P(k+1): \forall m \in \mathbb{Z}^+(\exists \text{ injection } \mathbb{N}_m\rightarrow \mathbb{N}_{k+1}) \Rightarrow m \le k+1$ This can be summarized as: Given: $\forall m \in \mathbb{Z}^+(\exists \text{ injection } \mathbb{N}_m\rightarrow >\mathbb{N}k) \Rightarrow m \le k$, $m_1\in \mathbb{Z}^+$, and injection $f:\mathbb{N}_{m_1}\rightarrow \mathbb{N}_{k+1}$ We need to show that this implies: $m_1 \le k+1$ Case 1 Suppose that $f(i) < k+1 $ for all $i\in \mathbb{N_m}$. Then we can restrict the codomain and define a function $f_1:\mathbb{N}_{m_1}\rightarrow\mathbb{N}_k$ by $f_1(i)=f(i)$. The function $f_1$ is also an injection and so, by inductive hypothesis, $m_1\le k$ and so certainly $m_1\le k+1$ as required. Case 2 Suppose that $k+1$ is a value of $f$, say $f(i_0)=k+1$ where $i_0\in \mathbb{N}_{m_1}$. In this case we can define an injection $g:\mathbb{N}_{{m_1}-1}\rightarrow \mathbb{N}_{m_1}$ by: $g(i) = \left\{ \begin{align} i & \text {, for }   i<i_0 \\
i+1 & \text{, for }  i \ge i_0
\end{align}\right.$ Then, we can define $f_1=f \circ g: \mathbb{N}_{{m_1}-1} \rightarrow \mathbb{N}_k$, which is an injection too. So, by the inductive hypothesis, $m_1-1 \le k$, which means $m_1 \le k+1$, as required. Questions Given an injection $f:\mathbb{N}_{m_1} \rightarrow \mathbb{N}_{k+1}$. why do we need to break it into the two cases? Do the cases cover all possibilities of $f$ being an injection from $N_\mathbb{m_1}$ to $\mathbb{N_{k+1}}$? It seems the strategy of this is to show that given an injection $f:\mathbb{N}_{m_1} \rightarrow \mathbb{N}_{k+1}$, this implies an injection $f:\mathbb{N}_{x} \rightarrow \mathbb{N}_{k}$, where $x$ a function of $m_1$, which we can then use the induction hypothesis to eventually conclude that $m_1<k+1$, as required. Is my understanding of this proof correct? My attempt: Given an injection $f:\mathbb{N}_{m_1} \rightarrow \mathbb{N}_{k+1}$, I will immediately call the induction hypothesis to conclude that $m_1\le k+1$. What is wrong with this answer? Is it because the codomain is different (given injection is $\mathbb{N}_{k+1}$ vs induction hypothesis is $\mathbb{N}_k$)that this kind of reasoning is wrong? Suppose we need to prove: For all positive integers $n$, we have the inequality $n\le 2^n$ Then for the inductive step, the inductive hypothesis is $k\le 2^k$ and we need to prove that this implies $k+1 \le 2^{k+1}$. How would the proof for this inductive step look like if the kind of error in point 3 is repeated here? EDIT: $\mathbb{N}_m = \{1,2,\dots, m\}$","['induction', 'proof-writing', 'functions']"
877079,Confusion about Spherical Coordinates Transformation,"We have a function $$f(x,y,z) = \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}}$$ and we want to integrate it over the whole $\mathbb{R}^3$. Then what i got is the following: $$\int_{\mathbb{R}^3}^ \! \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}} \, \mathrm{d}x\mathrm{d}y\mathrm{d}z$$  $$=\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi) }}{\sqrt{r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r, $$ my textbook says that the integral over the whole $\mathbb{R}^3$ is equal to $$\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2}}{\sqrt{r^2}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r. $$
What i dont quite understand - did i go wrong or does $(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)$ somehow equal 1 here (the integration of the final integral is not necessary for the answer)?","['multivariable-calculus', 'integration']"
877105,Permutation Partition Counting,"Consider the number $n!$ for some integer $n$ In how many ways can $n!$ be expressed as $$a_1!a_2!\cdots a_n!$$ for a string of smaller integers $a_1 \cdots a_n$ Let us declare this function as $\Omega(n)$ Consider the value of $10!$ $$10! = 7!6!$$
$$10! = 7!5!3!$$ Thus we know that $\Omega(10)\ge 3$ We note that if a number can be expressed as $$n! = w!(q!)!$$ for integers $w,q$ then another factorization arises naturally as: $$n! = w!(q!-1)!q!$$ such as with the case above We also note that given a composite number $Q!$ in order for it to be factorized $L! | L > P_\max$ must be in the factorization where $P_\max$ is the largest prime less than $Q$ Naturally this implies to us that $\Omega(n)$ for $n \in \ \lbrace \text{Primes} \rbrace = 1$","['integer-partitions', 'elementary-number-theory', 'number-theory', 'combinatorics']"
877106,Trigonometry Question: find Value of.....,Find value of $3 + \cos2x + \cos4x + \cos6x - 4\cos x\cos2x\cos3x$. I tried with $\cos A + \cos B$ identity but it was not simplifying.... Help..,['trigonometry']
877121,How to memorize the trigonometric identities?,"I am stuck trying to memorize the trig identities, and try as I may, I just can't get them to stick (especially the sum-product and product-sum formulas). I am concerned I won't be able to memorize them in time for my test, and I was wondering if there was a better way than rhote memorization. Any suggestions? Thanks. EDIT: Passed the test, thanks to your good suggestions. Thank you all!","['trigonometry', 'algebra-precalculus']"
877128,Evaluate $\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1}$ [duplicate],This question already has answers here : Evaluating $\lim _{x\to 1}\left(\frac{\sqrt[3]{x}-1}{2\sqrt{x}-2}\right)$ [duplicate] (6 answers) Closed 8 years ago . Evaluate $\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1}$ I want to solve this limit by employing the strategy of introducing a new variable $t$ in such a way as to make the problem simpler. I've tried using $t = \sqrt[3]{x} \Rightarrow \lim_{t \to 1} \frac{t -1}{\sqrt{t^3} -1}$ but I can't seem to manipulate the problem in to something simpler. Can anybody give a hint?,"['radicals', 'calculus', 'limits']"
877143,Integral ${\large\int}_0^\infty\frac{\ln x}{1+x}\sqrt{\frac{x+\sqrt{1+x^2}}{1+x^2}}\ \mathrm dx$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Please help me to evaluate this integral:
$$
I={\large\int}_{0}^{\infty}{\ln\left(x\right) \over 1 + x}\,
\,\sqrt{\,x + \sqrt{\,1 + x^{2}\,}\, \over 1 + x^{2}\,}\,\,{\rm d}x.\tag1
$$ Mathematica could not evaluate it in a closed form. A numerical integration returned
$$I \approx 4.25314982536869548103063\ldots\,,\tag2$$
but neither WolframAlpha nor ISC+ could find a plausible closed form for this.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
877160,Simple series divergence problem,"I've got a problem here: $$\sum_{n=1}^{\infty} \frac{5^n}{n(3^{n+1})}$$ I've used the ratio test and essentially did this: $$\sum_{n=1}^{\infty} \left( \frac{5^{n + 1}}{n (3^{n+1+1})} / \frac{5^n}{n(3^{n+1})}\right) = \frac{5^n\,5}{9(n+1)3^n} \cdot \frac{n\,3^n}{5^n}$$ With a bunch of cancellations we get $\dfrac{5n}{9n+9}$, which means it converges, as $\frac{5}{9} < 1$. But the answer says it diverges! I even tried the root test and got the same result. Where am I going wrong?","['divergent-series', 'limits']"
877189,Evaluation of the integral of $e^{-(x^2+y^2)}$ over a disk,"Show that
  $$\renewcommand{\intd}{\,\mathrm{d}}
    \iint_{D(R)} e^{-(x^2+y^2)} \intd x \intd y = \pi \left(1 - e^{-R^2}\right)$$
  where $D(R)$ is the disc of radius $R$ with center $(0,0).$ I have never been asked to calculate a double integral without a defined region, so I don't even know where to start. I don't know the boundaries. This is my guess: $$0 < r < R\\
0 < \theta < 2\pi $$ Is this correct?","['multivariable-calculus', 'calculus', 'integration', 'polar-coordinates', 'exponential-function']"
877190,Transformation rule for partial derivatives,I can't fathom the step I have highlighted in green. Am I using the chain rule in 3 dimensions? What is it that I am transforming here?,"['multivariable-calculus', 'partial-derivative']"
877213,"What is meant by ""m|n""? Two letters separated by a vertical bar (|)","I am new to this subject, and not not sure what ""|"" symbol means on this statement. Let $R_2 \subset\Bbb N \times\Bbb N$ be defined by $(m, n) \in R_2$ if and only if $m|n$.","['relations', 'functions']"
877216,$\int_{0}^{\infty}xe^{-x^2/2}dx= 1$?,"$X \sim N(0, 1)$ $$E(|X|) = \frac1{\sqrt{2\pi}}\int_{-\infty}^{\infty}|x|e^{-x^2/2}dx= \frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}xe^{-x^2/2}dx=\sqrt{\frac{2}{\pi}}$$ I don't understand how the last equality was arrived at. Why is it seemingly obvious that $\int_{0}^{\infty}xe^{-x^2/2}dx= 1$? Is this some common identity?","['normal-distribution', 'probability', 'expectation']"
877236,How to calculate the number of integer solution of a linear equation with constraints? [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . If an equation is given like this ,
 $$x_1+x_2+...x_i+...x_n = S$$
and for each $x_i$ a constraint $$0\le x_i \le L_i$$
How do we calculate the number of Integer solutions to this problem?","['diophantine-equations', 'binomial-coefficients', 'combinatorics']"
877241,How to prove that solution to ODE in spherical coordinate is equivalent to the ODE in cartesian coordinates if it is a thin shell,"Solving a diffusion-type ODE across a spherical shell, the equation is:
$$\frac{d}{dr}\left(r^2\frac{df}{dr}\right)=0\tag{1}$$
with boundary conditions $f(r_1)=f_1$ and $f(r_2)=f_2$. The solution is:
$$f(r)=\frac{f_1-f_2}{\frac{r}{r_1}-\frac{r}{r_2}}+\frac{f_1r_1-f_2r_2}{r_1-r_2}\tag{2}$$
Now I know intuitively that if the overall thickness of the shell $\Delta r=r_2-r_1\ll r_1$, then this can be reduced to Cartesian coordinates. In that case the ODE is:
$$\frac{d^2f}{dr^2}=0\tag{3}$$
With the same boundary conditions, then the solution is:
$$f(r)=f_1+(f_2-f_1)\frac{r-r_1}{r_2-r_1}\tag{4}$$
All fine so far.  What I want to do though is prove that Equation 2 reduces to Equation 4 when $\Delta r\ll r_1$, but I can't seem to figure out how it should be done. My approach has been to substitute $r_1 + \Delta r$ for $r_2$ and substitute $r_1+\xi$ for $r$, and then use the geometric series $\frac{1}{1-x}\approx 1+x$ (for $x\ll 1$) type of substitution to get $r$ up into the numerator, but the terms don't cancel and I can't get it to work out. Is there another approach I should be using?  Some trick or technique I'm not remembering?","['ordinary-differential-equations', 'calculus', 'spherical-coordinates']"
