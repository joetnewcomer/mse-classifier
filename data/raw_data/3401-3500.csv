question_id,title,body,tags
24280,Second-Order Linear Differential Equation,"I have the following differential equation:
$$y''+y=\cos(t)\cos(2t)$$ Maybe something can be done to $\cos(t)\cos(2t)$ to make it easier to solve. Any ideas? Thanks in advance.",['ordinary-differential-equations']
24292,Defining representations; representations and semidirect products,"Let $G$ be a group, $X$ a set. Defining an action $G\times X \to X$ is the same as defining a group morphism $\rho: G\to Sym(X)$, through the formula $g\cdot - = \rho(g)$. The morphism $\rho$ is called a permutation representation . Now, in what little representation theory I have studied one replaces the set $X$ with a vector space $V$, then defining a group morphism $\rho: G \to GL(V)$ is the same as defining an action $G\times V \to V$ such that $g\cdot-$ is linear for every g, through the same formula $g\cdot - = \rho(g)$. The morphism $\rho$ is called a linear representation . The first question is: on what other objects can I make my group act? What are the conditions for the previous constructions to make sense when picking an object $X$ from a given category, and picking $Aut(X)$ the set of isomorphisms of $X$? Addenda: 1) and when is this fruitful ? On what categories have actions been studied? 2) Since we can always define through a morphism such a categorial representation , when is it equivalent to the definition of the form $G\times X \to X$? For the second question: the construction of the semidirect product of groups $N$, $Q$ involves a morphism $Q \to Aut(N)$. One says that $Q$ acts on $N$ by automorphisms. I just noticed why one says so, and it's because it's just another case of an ""action with extra structure"". In this case it's the same giving such a morphism than giving an action $Q \times N \to N$ such that $q\cdot -$ is a group morphism for every $q$. So the semidirect product is linked to representations in this way. The second question is, are there analogue constructions with other type of representations? What I mean is: making a group act on another group yields a new group (the semidirect product) which has as underlying set the direct product of both groups. Do actions over different categories yield new objects in a similar fashion?","['representation-theory', 'group-theory', 'abstract-algebra']"
24294,Is there a good way to compute Christoffel Symbols,"Lets say you have a Riemannian Manifold $(M,g)$, and you have some given chart where $g = g_{ij} dx_i dx_j$ and you wish to compute the Christoffel symbols for the Riemannian connection in this chart. To do this involves: 1) Calculating the inverse matrix of $g$, which is not too bad in dimensions 2 and 3, but becomes quite painful in higher dimensions. 2) Using the formula $\Gamma_{ij}^k = \frac{1}{2} g^{kl}(\partial_i g_{jl} + \partial_j g_{il} - \partial_l g_{ij}) $ which if you look closely the index that is summed over on the right is $l$, so there are $n=dim M$ terms on the right that need to be evaluated, and inside each of these you must take a partial derivative of three terms in $g$, so in total on the right-side there are $3n$ terms to be computed. This is just for each value of $k$. Luckily $\Gamma_{ij}^k$ is symmetric in $ij$, and so you only have to compute about half of the $3n^3$ quantities involved, but it is still a very involved calculation. Does anyone know a simpler method to go about this? Or an easier way to look at the calculation of this? As $\Gamma_{ij}^k$ is an $n \times n$ symmetric matrix for each fixed $k$, maybe there is a way to write $(\Gamma_{ij}^k)$, the matrix, as a matrix product of some other matrices that would be easier to write down. That way you would not have to work with index notation for doing the calculation, which also slows things down.","['riemannian-geometry', 'differential-geometry']"
24306,Ideals as an algebraic integer ring?,"Let $\mathcal{O}_K$ be the ring of integers of some number field $K$. It happens that $\mathcal{O}_K$ might not have unique factorization, but... We can form the multiplicative group of ideals of $\mathcal{O}_K$ It has unique factorization This construction doesn't seem to be a ring Each ideal can be put into the form $(\alpha,\beta)$ with both $\alpha,\beta \in \mathcal{O}_K$ I think the ideal $(\alpha,\beta)$ represents the gcd of $\alpha$ and $\beta$ (analogous to field of fractions) so why can't we build a new ring out of the algebraic integers which has gcd closed and unique factorization?","['algebraic-number-theory', 'abstract-algebra']"
24308,what is the definition of a line in $\mathbb{P}^n(k)$ + how to compute the hilbert polynomial of two intersecting lines?,"(1) I have never studied any projective/affine geometry or algebraic curves. I'd like to see a clear definition of a line in the projective space $\mathbb{P}^n(k)$ , since I need it for my algebraic geometry study. (2) I'm guessing a line is the variety $\mathcal{V}(f_1,\ldots,f_{n-1})$, where $f_i$ are linear homogenous polynomials, whose coefficients form a $n\times n\!-\!1$ matrix of full rank. Yes or no? Another guess would be, that a line in $\mathbb{P}^n(k)$ is uniquely determined by two points $a\!=\![a_0\!:\!\ldots\!:\!a_n]$, $b\!=\![b_0\!:\!\ldots\!:\!b_n]$, such that the matrix $\begin{bmatrix} a \\ b \end{bmatrix}$ is of rank $2$. But how is such a line parametrized ? Is any of my two attempts of a definition correct? (3) What are the defining equations of two intersecting lines in $\mathbb{P}^3$ ? And now, most importantly: how can I compute the Hilbert polynomial of such a variety? For such an elementary concept, one would expect it to be the first object defined, but to my annoyance and frustration, I have yet to see an official definition. I have the book Introduction to Algebraic Geometry (Hassett), as well as Algebraic Curves (Fulton) as my main source. Any references would be highly desirable. thank you","['projective-space', 'commutative-algebra', 'algebraic-geometry', 'projective-geometry']"
24322,Is the product of two open embeddings of schemes an open embedding?,"Question as in title. I only really need the special case where one of the open embeddings is the identity, but the more general case would be useful to know. Edit - By product I mean: given $U\to X$ and $V\to Y$ open embeddings, is the canonical map $U\times V \to X\times Y$ an open embedding?",['algebraic-geometry']
24338,Hilbert Space - Norm of derivative,If $H$ is a Hilbert space of entire functions with weighted norm $||f||^{2}=\int_{R} |\frac{f(t)}{g(t)}|^{2}dt$ for some entire function $g$ (not necessary in $H$). Can we find any relation between the norm of $f$ and the norm of it's derivative? Something like: $||f'||\leq C ||f||$ for some constant $C$. (Note: so far we don't know whether $f'$ belongs to $H$ or not).,['functional-analysis']
24342,Rubik's cube interesting questions?,The upper bound for the number of moves required to solve a regular Rubik's cube has been shown to be 20 . Two questions come to mind: Does this result have more general significance? What are the most pressing issue with regards to Rubik's cube (or generalizations) or its group?,"['rubiks-cube', 'recreational-mathematics', 'group-theory', 'combinatorics']"
24372,"Given a set of 2D points (x,y) (cloud of points), find the points that, when connected, will contain all other points","Given a set of 2D points I have to find the points that when connected will form a polygon that contains all the points in the set. A quick example: imagine you have a set S={(1,1),(2,1),(1,2),(2,2),(4,4)} . The solution would be SolS={(1,1),(2,1),(1,2),(4,4)} as those points (when connected) form a polygon that cointains all the points in the set ( (2,2) is cointained inside the polygon). Here is a diagram describing the problem : And the Solution (Sorry for the quick scketeches): Now, this obviously need to be extended to deal with n 2D points. I have been cracking my head trying to work out an algorithm but I just cant find it. Thank you so much for your help!","['geometry', 'coordinate-systems', 'algorithms', 'signal-processing']"
24377,What do functions on affine schemes preserve?,"I apologize in advance for what is probably an obvious question but here goes: What structure do functions on affine schemes respect? If we consider other types of 'spaces' we have a notion of function on them which respect structure relevant to the type of 'space'. For a smooth manifold, we consider differential functions to $\mathbb{R}$(or $\mathbb{C}$ if you like) which respect the Differential structure. In the case of affine schemes, functions are simply elements of our ring. Why is this natural to think of functions on schemes as elements of the underlying ring, and what structure preservation does this emerge from? I hope this is clear.",['algebraic-geometry']
24385,Factorization of primes and $Spec(\mathcal{O}_K)$,"Let $K$ be a quadratic number field, and $\mathcal{O}_K$ the ring of integers of $K$. The map $\pi: Spec(\mathcal{O}_K) \rightarrow Spec(\mathbb{Z})$ that sends a prime ideal $\mathbb{p}$ to $\mathbb{p} \cap \mathbb{Z}$ is induced since $\mathcal{O}_K$ contains $\mathbb{Z}$. And the fiber $\pi^{-1}$ of the prime ideal $(p)$ of $\mathbb{Z}$ is then understood as the decomposition of $(p)$ in $\mathcal{O}_K$. We then obtain a geometric interpretation of how p factors in $\mathcal{O}_K$ using results obtained from Algebraic number theory. I'm looking for hints to (major or minor!) results that can be proved regarding the behaviour of $(p)$ in $\mathcal{O}_K$, or other interesting aspects of $\mathcal{O}_K$ using ""as much as possible"" Algebraic geometry  (at level of a first course in Schemes, using, say first seven chapters of Liu's ""Algebraic Geometry and Arithmetic Curves""). I'd also appreciate a recommendation of a textbook or notes that discusses these ideas in details.","['algebraic-geometry', 'algebraic-number-theory']"
24396,How to find a Newton-like approximation for that function?,"I want to find the complex fixpoint $t=b^t $ for real bases $b> \eta = \exp(\exp(-1))$. added remark: I'm aware that there is a solution using branches of the Lambert-W-function, but I've no Maple/Mathematica and only a rough implementation in Pari/GP for real values. That motivated to try a solution via Newton/Raphson. And to understand and solve such an implementation (which has to deal with derivatives and complex values) is/was then my question here. See also my comment to Fabian's answer below. I seem to have solved it myself for the ""principal branch"" (see my own answer below) but it is still open for the general case of k'th branch. [end of remark] What I have is a function depending on a parameter $ \beta $ giving the auxiliary values $$  u = \frac{\beta}{ \sin(\beta) } *\exp( i * \beta) $$
$$   t=\exp(u) $$
$$   b= f(\beta) = \exp(u/t) = \exp(u * \exp(-u))  $$ By this I can do an approximation given a base $B$ using binary search. I can find the bounds of an interval taking lower and upper-limit beta's $ \beta_l = \epsilon $ and $ \beta_u = \pi-\epsilon $ with small epsilons giving the lower and upper bases $b_l$ and $b_u$ respectively. Then comparing $b_m = f(\beta_m)$ where $ \beta_m = (\beta_l + \beta_u)/2 $ with my given base $B$ I can implement a binary search which approximates $b_m$ to $B$ arbitrarily well and having $\beta_m$ I can reconstruct u and the fixpoint t by the above formula. However, that binary search needs surprisingly many iterations and I thought, possibly a Newton-like method for that approximation would be more efficient. But since I have complex values involved I do not even see the derivative and even less the formula how to involve that derivative in such an approximation-formula and how to apply this finally to actually do the iterations... [update 4] moved my own findings into an own answer (as suggested in meta.***) [update 1] (in this old plot I used the letter s instead of b )","['exponentiation', 'approximation', 'functions', 'analysis']"
24397,Convex and bounded function is constant [duplicate],"This question already has answers here : Show bounded and convex function on $\mathbb R$ is constant (4 answers) Closed 10 years ago . Let f be a convex and  bounded function, meaning there is a constant $C$, such that $f(x) < C$ for every $x$. I need to prove that $f$ is a constant function. Thanks!",['calculus']
24408,Are there any good algebraic geometry books to recommend? [duplicate],"This question already has answers here : Closed 13 years ago . Possible Duplicate: (undergraduate) Algebraic Geometry Textbook Recomendations I am interested in algebraic number theory and I am recently acquainted with the theory of valuations, which further leads to Riemann-Roch theory, and which is closely related to algebraic geometry, and the algebraic-K-theory. Therefore, my problem is: Are there excellent introductory books of the theory of Algebraic Geometry to recommend? Since I know in general nothing about this theory, I may want a book which explains the ideas as clear as possible and which at the mean time contains as much material as possible. If I am asking too much, then any good book in your view suffices. Thanks very much.","['algebraic-geometry', 'big-list', 'algebraic-number-theory', 'reference-request', 'soft-question']"
24413,Is there a function with infinite integral on every interval?,"Could give some examples of nonnegative measurable function $f:\mathbb{R}\to[0,\infty)$, such that its integral over any bounded interval is infinite?","['measure-theory', 'examples-counterexamples', 'real-analysis']"
24421,Upsetting inequality (à la Cauchy-Schwarz?),"How to prove that: $$
\left(\sum_{i=1}^n w_i n_i \sqrt{\dfrac{y_i(1-y_i)}{n_i+1}}\right)^2 \leq \dfrac{\left(\sum_{i=1}^n w_i n_i y_i\right)\left(\sum_{i=1}^n w_i n_i (1-y_i)\right)}{(\sum_{i=1}^n w_i n_i+1)}
$$
where $w_i\geq0$, $\sum_{i=1}^n w_i=1$, $n_i>0$ and $y_i \in (0,1)$ for $i=1,\dots,n$, with $n>1$? I have verified numerically that it should hold, but I cannot still find an elegant way to show it. The formula comes from an inequality for the variance of a convex combination of beta-distributed variables.","['probability-theory', 'inequality']"
24425,Irreducible homogeneous polynomials of arbitrary degree,"Suppose we have an algebraically closed field $F$ and $n+1$ variables $X_0, \dots, X_n$, where $n > 1$. Does there exist an irreducible homogeneous polynomial in these variables of degree $d$ for any positive integer $d > 1$? In other words, does there always exist an irreducible hypersurface of arbitrary degree? Of course, I am also interested in constructions of these polynomials. Thank you.","['algebraic-geometry', 'irreducible-polynomials', 'polynomials']"
24429,on the boundary of analytic functions,"Suppose I have a function $f$ that is analytic on the unit disk $D = \{ z \in \mathbb{C} : |z| < 1 \}$ that is also continuous up to $\bar{D}$. If $f$ is identically zero on some segment of of the boundary (e.g. $\{ e^{it}, 0 \leq t \leq \pi/2 \}$ ), is it then true that $f$ is identically zero on the entire boundary? I know that analytic functions that are zero at an accumulation point inside the domain of analyticity are identically zero throughout the entire domain, but I don't know what (if anything) can be said if something similar occurs on the boundary of the domain.",['complex-analysis']
24449,Conventions for function notation,"I'm in year 11 right now and I just had a brief discussion with my maths teacher about function notation in trigonometry. For a test, I wrote this, sin(50)^2 I assumed that would be interpreted as sin(50)*sin(50) But I was told the correct notation for this is is sin^2 (50) or optionally (sin (50))^2 I'm curious if that is the 'proper' mathematical convention, or just how things are taught in high schools? I'm Australian, in case there are some regional differences. Thanks for the help!","['notation', 'functions']"
24455,Convergence of Sum over Integer Lattice,"Does the sum 
$$\sum_{z \in \mathbb{Z}^3\setminus \{(0,0,0)\}} \left( \frac{1}{|{\bf x} - {\bf z}|^2} - \frac{1}{|{\bf z}|^2} \right)$$ converge pointwise or even uniformly for $\varepsilon < |{\bf x}| < 1-\varepsilon$?","['integer-lattices', 'sequences-and-series']"
24456,Matrix multiplication: interpreting and understanding the process,"I have just watched the first half of the 3rd lecture of Gilbert Strang on the open course ware with link: http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/ It seems that with a matrix multiplication $AB=C$, that the entries as scalars, are formed from the dot product computations of the rows of $A$ with the columns of $B$. Visual interpretations from mechanics of overlpaing forces come to mind immediately because that is the source for the dot product (inner product). I see the rows of $C$ as being the dot product of the rows of $B$, with the dot product of a particular row of $A$. Similar to the above and it is easy to see this from the individual entries in the matrix $C$ as to which elements change to give which dot products. For understanding matrix multiplication there is the geometrical interpretation, that the matrix multiplication is a change in the reference system since matrix $B$ can be seen as a transormation operator for rotation, scalling, reflection and skew. It is easy to see this by constructing example $B$ matrices with these effects on $A$. This decomposition is a strong argument and is strongly convincing of its generality. This interpreation is strong but not smooth because I would find smoother an explanation which would be an interpretation begining from the dot product of vectors and using this to explain the process and the interpretation of the results (one which is a bit easier to see without many examples of the putting numbers in and seeing what comes out which students go through). I can hope that sticking to dot products throughout the explanation and THEN seeing how these can be seen to produce scalings, rotations, and skewings would be better. But, after some simple graphical examples I saw this doesn't work as the order of the columns in matrix $B$ are important and don't show in the graphical representation. The best explanation I can find is at Yahoo Answers . It is convincing but a bit disappointing (explains why this approach preserves the ""composition of linear transformations""; thanks @Arturo Magidin). So the question is: Why does matrix multiplication happen as it does, and are there good practical examples to support it? Preferably not via rotations/scalings/skews (thanks @lhf).","['faq', 'matrices', 'linear-algebra', 'intuition']"
24459,Differentiable at a point,"My roommates and I have an argument you guys can help to settle (peace is at stake, don't let us down!) In undergrad calculus courses, one usually explains what it means for a function to be differentiable at a point x, and then differentiable in a domain. Then the focus is entirely on this latter notion. My question is: Has the notion of differentiability at a point any interest? That is, I'm looking for a theorem which is valid for a function regular at some point, but which needs significantly less regularity in a neighborhood of this point, or a good reason for which such a theorem doesn't exist. Of course, this question is very flexible, and any insight is welcome.","['soft-question', 'calculus', 'real-analysis', 'definition']"
24460,Fitting data to a portion of an ellipse or conic section,"Is there a straightforward algorithm for fitting data to an ellipse or other conic section? The data generally only approximately fits a portion of the ellipse. I am looking for something that doesn't involve a complicated iterative search, since this has to run at interactive speeds for data sets on the order of 100s of data points. I can downsample or cluster the data if it goes beyond that. I found an article: ""Least-Squares Fitting of Circles and Ellipses"" (Gander et al 1994) and it does seem to address my needs, but it uses a lot of mathematical machinery that I either don't understand or have a library for. I'm sure I can grok it given time, but this isn't something I would like to allocate a week to doing.","['geometry', 'conic-sections', 'computational-geometry', 'regression']"
24465,Compute base price of each item in a list of items given the total sales tax,"I'm having a disagreement with a client that I think is relatively simple mathematics, but I'd like a third party to confirm or dispute my assertions. Here's the situation: We have a list of N final prices p 1 , ..., p N . A final price is tax-inclusive and includes two kinds of tax: flat tax , which is the same for all items sales tax , which is a percentage of the item's price That means that you can define the base price b k of an item to be p k = (1 + t) · b k + t 0 where t 0 is the flat tax and t is the sales tax. Alternatively, you can define the price of an item to be p k = b k + t k p k = b k + t · b k + t 0 b k = p k - t k where t k is the tax for that item. Now, the question is: Given only a list of prices (p 1 , ..., p N ) and the total tax T = t 1 + ... + t k , can you determine (b 1 , ..., b n )? If so, how would you express this?",['algebra-precalculus']
24485,Find the average of a collection of points (in 2D space),"I'm a bit rusty on my math, so please forgive me if my terminology is wrong or I'm overlooking  extending a simple formula to solve the problem. I have a collection of points in 2D space (x, y coordinates). I want to find the ""average"" point within that collection. (Centroid, center of mass, barycenter might be better terms.) Is the average point just that whose x coordinate is the average of the x's and y coordinate is y the average of the y's?","['average', 'geometry']"
24489,"Naive set theory question on ""=""","So I picked up a couple of good undergraduate-level books over the weekend and have been working through them... In Algebra: Chapter 0 , the author of the text writes: The prototype of the well-behaved relation is '=', which corresponds to 'the diagonal'
  $$\{ (a, b) \in S \times S \, | \, a = b \} = \{(a, a) \, | \, a \in S \} \subseteq S \times S $$ The problem I'm having is that the way I'm interpreting this expression makes it seem uninteresting, almost tautological, which I'm thinking can't be correct.  What I think this expression is saying is this:  Suppose I give you elements $a$ and $b$ in the set $S$ to compare for equality.  To do that, write $a = b$ as the ordered pair $(a,b)$, which is the same element as $(a, a)$, which by a previous definition we are told is true iff $\{b\} = \{a\}$. But when I try to bring this to a concrete level, by letting $S$ be the set of all polynomials with integer coefficients, say, I become confused.  Since $(0, 6x + (-6)x)$ is not the same ordered pair as $(0, 0)$, aren't we left to conclude that $(6x + (-6)x) \neq 0$?  That doesn't seem right. The only thing I can see this definition being useful for is writing tautologies like $A = A$. And then I wondered: What does it mean to write an expression like $x^2 = 2x$?  Am I correct in saying that the ""$=$"" there is not the same ""$=$"" as in the definition given above?  How would one write the definition of this new ""$=$"" in set-theoretic terms, with universal quantifiers?",['elementary-set-theory']
24504,What is the image of $\zeta_3$ under the non-identity embedding of $\mathbb{Q}(\zeta_3)$ in $\mathbb{C}$?,What is the image of $\zeta_3$ under the non-identity embedding of $\mathbb{Q}(\zeta_3)$ in $\mathbb{C}$?,"['algebraic-number-theory', 'number-theory']"
24513,Does Hom commute with stalks for locally free sheaves?,"This is somewhat related to the question Why doesn't Hom commute with taking stalks? . My question is this: If $F$ and $G$ are locally free sheaves of $\mathcal{O}_X$ -modules on an arbitrary ringed space $(X,\mathcal{O}_X)$, then is the stalk of the Hom sheaf $\mathcal{H}om(F,G)$ at a point $p$ equal to $\text{Hom}_{\mathcal{O}_{X,p}}(F_p,G_p)$? I ask this because I feel I need it to solve Exercise 5.1(a) from Chapter II in Hartshorne. By proposition 6.8 of Chapter III, the answer to my question is affirmative IF $X$ is a Noetherian scheme, and it holds even if $F$ is only coherent and with no conditions on $G$, but his does not answer my question which is assuming less on $X$ and more on the sheaves. In any case, is there a way to solve the exercise in Hartshorne without going to the stalks?",['algebraic-geometry']
24518,linear algebra basic proof,"F is a linear functional in $V'$ a linear vector space which operates on $\phi\in V$. Show that there is a one-to one correspondence between F and $f\in V $ such that $F(\phi)=(f,\phi)$ where $V$ is also a linear vector space.  $(,)$ represents inner product. Any hint will be helpful. Attempt: I don't even know if this is right but... If $F(\phi)=c$ , $c\in \mathbb{C}$
then let $(f_1, \phi)=c$ and $(f_2, \phi)=c$ $\rightarrow$ $(f_1-f_2, \phi)=0$ But this only means orthogonality. EDIT: so, from hint let $\{e_i\}$ be a linearly independent basis for vectorspace $V$ $F(\Phi) = F (\sum_n \phi_n e_n) =\sum_n \phi_n F(e_n) $ $(f,\Phi) = \sum_n f_n^* \phi_n$ Therefore if $F(\phi)=c$ , $c\in \mathbb{C}$ and $(f,\Phi)=c$ then $\sum_n (f_n^* -F(e_n)) \phi_n =0$ implies (?) $f_n^* =F(e_n)$ $\forall n$? EDIT Ok. So the above implies that if some $(e_i,\Phi)$ vanishes then we cannot have a unique $f$. So is this solved by specifying at the beginning that $\{e_i\}$ is a basis where $\phi_i=(e_i,\Phi)$ is non vanishing for all i?",['linear-algebra']
24521,How do I come up with a function to count a pyramid of apples?,"My algebra book has a quick practical example at the beginning of the chapter on polynomials and their functions. Unfortunately it just says ""this is why polynomial functions are important"" and moves on. I'd like to know how to come up with the function (the teacher considers this out of scope). Even suggesting google search terms to find out more information on this sort of thing would be helpful. The example Consider a stack of apples, in a pyramid shape. It starts with one apple at the top. The next layer is 2x2, then 3x3, and so on. How many apples are there, given x number of layers? The polynomial function $$f(x) = \frac{2x^3 + 3x^2 + x}{6}$$ What I do and don't understand Thanks to @DJC, I now know this is a standard function to generate Square Pyramidal Numbers , which is part of Faulhaber's formula . Faulhaber's formula appears to be about quickly adding sequential coefficients which all have the same exponent. Very cool. But how does one get from: $$\sum_{k=1}^{n} k^p$$ to the spiffy function above? If I'm sounding stupid, how do I make the question better? Fwiw, I'm in intermediate algebra in the USA. The next course would be Trigonometry or Calculus. (to help people place my current knowledge level)","['summation', 'functions', 'polynomials']"
24529,Factoring $a^{10}+a^5+1$,I'm very interested to know how I can factorise $a^{10} +a^5 +1$ in two factors with integer coefficients. I've tried a lot but I don't have any idea how do that.,"['algebra-precalculus', 'polynomials']"
24533,Find the average of $\sin^{100} (x)$ in 5 minutes?,"I read this quote attributed to VI Arnold . ""Who can't calculate the average value of the one hundredth power of the sine function within five minutes, doesn't understand mathematics - even if he studied supermanifolds, non-standard calculus or embedding theorems."" EDIT Source is ""A mathematical trivium"" A book of 100 problems that university students ""should be able to solve"". The statement asks for calculation within 10% accuracy. So the average value over the entire domain should be the same as the average value over $[0,\pi/2]$ $$\langle\sin^{100} (x)\rangle= \frac{\int_0^{\pi/2} \sin^{100}(x) dx}{\int_0^{\pi/2} dx}.$$ So here's what I did: First, this graph would be a train of highly sharp peaks. The integrand would assume values close to zero a up till before it sharply rises to 1. So up till some $\epsilon \in [0,\pi/2]$ we will have $\sin x \approx x$ and for the remaining $\pi/2 - \epsilon$ interval I could find the area of triangle with base $\pi/2 - \epsilon$ and height $1$ $$\langle \sin^{100} (x)\rangle \approx \frac{2}{\pi} \left(\int_0^\epsilon x^{100} dx + .5 (\frac{\pi}{2}-\epsilon)\right).$$ I believe in principal it should be possible to find an $\epsilon$ such that the above expression yields the exact answer. So I try to approximate it, no good. Then I try mathematica and it is looking like there is no $\epsilon$ for which the value I am expecting is even close to the actual value. I plot the original and find that my approximation is hopeless. Not to mention that my 5 minutes were over. So I admit I do not understand mathematics and humbly ask if someone could: Point out my mistake (Other than that $\epsilon$ is probably incomputable within 5 mins) How the hell is this done in 5 minutes? The picture below has the $\sin^{100} x$ in blue (bottom) and my approximation of it plotted against $\epsilon$ (pink). Although there is no reason for them to be together, the upper graph has a minima quite above the exact value of the integral. EDIT Just realized Let $$u=\cos x.$$ $$\int_0^{\pi/2} \sin^{100}(x) dx = \int_0^1 (1-u^2)^{99/2}du\approx \int_0^1 \left(1 - \frac{99}{2} u^2\right) du $$","['approximation', 'integration']"
24535,Is this algebraic identity obvious? $\sum_{i=1}^n \prod_{j\neq i} {\lambda_j\over \lambda_j-\lambda_i}=1$,"If $\lambda_1,\dots,\lambda_n$ are distinct positive real numbers, then 
$$\sum_{i=1}^n \prod_{j\neq i} {\lambda_j\over \lambda_j-\lambda_i}=1.$$
This identity follows from a probability calculation that you can find at the 
top of page 311 in the 10th edition of Introduction to Probability Models by Sheldon Ross. Is there a slick or obvious explanation for this identity? This  question is sort of similar to my previous problem ; clearly algebra is not my strong suit!","['summation', 'algebra-precalculus', 'products']"
24548,what is a tight lower bound on the coupon collector time?,"In the classic Coupon Collector's problem , it is well known that the time $T$ necessary to complete a set of $n$ randomly-picked coupons satisfies $E[T] \sim n \ln n $,$Var(T) \sim n^2$, and $\Pr(T > n \ln n + cn) < e^{-c}$. This upper bound is better than the one given by the Chebyshev inequality, which would be roughly  $1/c^2$. My question is: is there a corresponding better-than-Chebyshev lower bound for $T$? (e.g., something like $\Pr(T < n \ln n - cn) < e^{-c}$ ) ?","['probability', 'combinatorics']"
24558,Why is the Fundamental Group of a Connected Graph $G$ Free on elements in $G-T$; $T$ spanning tree for $G$),"The fundamental group $\Pi_1(G)$ of a connected graph $G$ is defined to consist of all loops
  (i.e., closed paths)  based at  a given fixed basepoint/vertex $g \in G$ as elements,
  and concatenation as the group operation. (for $G$ connected, we can show that the
  group is independent of the choice of basepoint; given $g,g'$ we construct an isomorphism
  between the two groups by joining $g,g'$ with a path.) Also given a connected graph $G$, there is is a result that $G$ has a spanning tree $T$ -- a tree $T\lt G$ that uses all vertices in $G$ ). Now, the main result (all else was a set-up until now) is that $\Pi_1(G) \sim \mathrm{Gp}({E(T-G)})$, i.e., $\Pi_1(G)$ is the free group generated by all edges in $G$ that are not in $T$. My doubt is about this isomorphism; I do see how we need edges in $T-G$ in order to generate loops based at a point, since $T$ is acyclic (so that if $G=T$, the group is trivial). But I do not see how the group is isomorphic to the free group generated by edges in $T-G$. This is what I have so far: let $f_i$ denote a free edge, i.e., an edge in $T-G$. We can assume there is just one path joining any two edges in $T$ (otherwise, $T$ would contain a cycle)
Given $g$ fixed in $G$ (assume WOLG $g$ in $T$), I think every closed loop based at $g$ can be realized as the concatenation of a path within $T$, and an edge $f_i$ (aka, a path in $G-T$), and then a(the) path from an endpoint of $f_i$ to $g$ again. Then, for any edge $f_i$, there is a (class) of loops based at $g$. Question: is the above the sketch of a proof for the fact that $\Pi_1(G)$ is the free group generated by all the edges in $G-T$? Sorry, I did not know how to make the question any more concise; I hope I don't get any Courics for writing too-long of a question. Thanks.","['general-topology', 'graph-theory', 'abstract-algebra']"
24575,What is the quickest way to solve this 2nd Order Linear ODE?,"This appeared on my professor's test review, and its taken me hours to, surprise surprise, get the wrong answer. Could someone help me with the method I should be using to solve this? $$y^{\prime\prime}+y=\tan x$$",['ordinary-differential-equations']
24577,On the limits of weakly convergent subsequences,"Let $\{ f_n \}$ be a sequence in a Hilbert space $L^2(\mathbb{R}^d)$. We say that this sequence converges weakly to an element $f \in L^2$ if $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ (where $\langle \cdot,\cdot \rangle$ denotes the inner product on $L^2$). By definition, we are given that the weak limit $f$ is in $L^2$. However, suppose we know that a sequence ""formally"" converges weakly to a limit $f$ (i.e. $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ for some $f$ which we don't necessarily know yet to be in $L^2$) . Does this, purely by the characteristics of weak convergence, directly imply that $f \in L^2$? I think you could also generalize this question to any Hilbert space, provided that taking the inner product of an element possibly not in the Hilbert space makes sense.",['functional-analysis']
24585,"Product of Smooth Covering Maps a Smooth Covering Map? ( J.Lee, 2-12)","I am trying to review my differential Geometry. In J.Lee's Smooth Manifolds , there is an exercise in which one has to show that the product of smooth covering maps is a smooth covering map. A smooth covering map is a smooth cover $\pi: M' \rightarrow M$, where
$M, \, M'$ are smooth manifolds, and in which every $p$ in $M'$ has a neighborhood $U_p$ in $M$ such that $p|_{p^{-1}} (U_p) \rightarrow U_p$ (i.e., the restriction of $p$ to the inverse image of $U_p$ is a diffeomorphism) . I think this exercise is straightforward, (basically we just use the fact that the product of diffeomorphisms is a diffeomorphism) but I am kind of rusty, and would appreciate your inputs. Now, we need to show that , given covers $p_1:M' \rightarrow M$ and $p_2:N' \rightarrow {N}$ that for any pair $(p,q)$ there is a neighborhood $W$ of $(p, q)$ such that $p_1 \times p_2 |_{p_1^{-1} \times p_2^{-1} (W)} : p_1^{-1} \times p_2^{-1} (W) \rightarrow W$ is a diffeomorphism. But we know that for $p$ in $M$ there is a $U_p$ with $p_1|_{p_1^{-1} (U_p)} : p_1^{-1} (U_p) \rightarrow U_p$ and for any $q$ in $N$ there is a $U_q$ with $p_2|_{{p_2}^{-1} (U_q)} : p_2^{-1} (U_q) \rightarrow U_q$
such that both are diffeomorphisms. Then the product map is a diffeomorphism automatically, isn't it, i.e., isn't the map: $$(p_1, p_2)|_{(p_1^{-1} \times p_2^{-1}) (U_q)} : (p_1^{-1} \times p_2^{-1}) (U_q) \rightarrow U_p \times U_q$$ a diffeomorphism? We know that if $f = (f_1(x_1,\ldots,x_n),f_2(x_1,\ldots,x_n))$ is differentiable with derivative $(f_1',f_2')$ and$f_1^{-1}$ and $f_2^{-1}$ are each differentiable (by the assumption of diffeomorphism), then  I think the differentiable inverse here is given by the identities fof -1 =Id. I imagine there may be some issue in showing that the above is true for manifolds, and not just for subsets of $\mathbb{R}^n$. Other than that, is my setup correct? Basically, I am curious as to whether this problem comes down to the fact that the
product of diffeomorphisms is a diffeomorphism. Thanks.",['differential-geometry']
24588,Is this parametric curve space-filling? Why or why not?,"Really, the curve in question is the polar plot $ r = cos( K * \theta) $, where $K$ is any irrational number (I use $\pi$), but the transformation to a parametric one on $x$ and $y$ with domain $t$ is an unsurprising one. It would appear that the curve is confined to the unit circle, and also that it never repeats -- that it is aperiodic. Given these three things The domain of the function is any real number The range of the function is confined to a finite space The function is aperiodic Does it mean that the unit circle is completely filled for this parametric function from negative infinity to infinity? Can we say that for any given point in the unit circle, there is a number for $t$ where the curve intersects it? I want to say no.  I really do.  My intuition says so.  But why? Are there any other curves with the three bullet pointed conditions above that can be shown to be more clearly non-space-filling? What is the appropriate mathematical term for the way thi curve acts on the unit circle?",['functions']
24589,"Given k real n x n matrices with a common eigenvector, is there some nontrivial polynomial equation the entries of the matrices satisfy?","The following problem has come up in my research and I don't have the tools (i.e., I don't know Algebraic Geometry, especially over $\mathbb{R}$) to solve it. Consider two subsets $X$ and $Y$ of $M_n(\mathbb{R})^k$ with $k\geq 3$.  The subset $X$ consists of all $k$ tuples of n x n matrices $(A_1,..., A_k)$ such that for any two $A_i$ and $A_j$, there is a vector $v_{ij}$ which is simultaneously an eigenvector for $A_i$ and $A_j$ (but perhaps with different eigenvalues). The subset $Y$ consists of all those elements of $X$ such that $v_{ij}$ can be chosen independently from $i$ and $j$ - that is, if $(A_1,.., A_k)\in Y$ then all $k$ matrices have a common eigenvector.  (Of course, when $k=1$ or $k=2$, $X = Y$, hence the above restriction on $k$). Now, I have not been able to prove that $X$ is Zariski closed (though I have not tried that hard - it's not so important for my purposes), but I can prove that it's contained in a proper Zariski closed subset of $M_n(\mathbb{R})^k$ (thought of as $\mathbb{R}^{kn^2}$):  we have $f_{12} = det(A_1A_2 - A_2A_1) = 0$ since $A_1A_2 v_{12} = A_2A_1 v_{12}$.  Or, since we're worker over $\mathbb{R}$, we can put all the $f_{ij}$ into one big polynomial equation $$\sum_{1\leq i < j\leq k} f_{ij}^2 = 0.$$ What I'd like to know is Is there a Zariski closed subset $F$ with $Y\subseteq F\subsetneq X$? Said another way Is there a polynomial which is simultaneously satisfied by all k-tuples of matrices sharing a common eigenvector but for which there are elements in $X$ which do not solve it? Finally, in case it helps, the case I'm most interested in is $n=3$ and $k = 5$, but I imagine the choice of $n$ won't affect the answer greatly and $k=3$ probably contains all the insight necessary to tackle the larger $k$ values. Thank you in advance for your help.","['linear-algebra', 'algebraic-geometry']"
24596,Distribution of the coefficient of variation of independent normal variables?,"Let $X_1,\dots,X_n$ be Gaussian random variables with mean $\mu$ and variance $\sigma^2$. What is known about the distribution of $$\frac{\sqrt{\frac1{n-1}\sum_{i=1}^n(X_i-\bar X)^2}}{\bar X} $$ with $\bar X = \frac 1n \sum_{i=1}^n X_i$? Does this distribution have a name? I am especially interested in its cumulative distribution function. If this is too complicated, I'd settle for $$\frac{\sqrt{\frac1{n}\sum_{i=1}^n(X_i-\mu)^2}}{\mu} $$","['statistics', 'probability-theory']"
24601,"Classsifying $1$- and $2$-Dimensional Lie Algebras, up to Isomorphism","I am trying to find all $1$ - or $2$ -dimensional Lie algebras $\mathfrak{a}$ up to isomorphism. This is what I have so far: If $\mathfrak{a}$ is $1$ -dimensional, then every vector (and therefore every tangent vector field) is of the form $cX$ . Then, by anti-symmetry, and bilinearity: $$
  [X,cX] = c[X,X] = -c[X,X] = 0 \,.
$$ I think this forces a unique Lie algebra because Lie algebra isomorphisms preserve the bracket.  I also know the reals $\mathbb{R}$ are the only $1$ -dimensional Lie group, so its Lie algebra ( $\mathbb{R}$ also) is also $1$ -dimensional. How can I show that every other $1$ -dimensional algebra is isomorphic to this one? Do I use preservation of bracket? For $2$ dimensions, I am trying to use the fact that the dimension of the Lie algebra $\mathfrak{g}$ of a group $G$ is the same as the dimension of the ambient group/manifold $G$ . I know that all surfaces (i.e., groups of dimension $2$ ) can be classified as products of spheres and tori, and I think the only $2$ -dimensional Lie group is $S^1 \times S^1$ , but I am not sure every Lie algebra can be realized as the Lie algebra of a Lie group (I think this is true in the finite-dimensional case, but I am not sure). I know there is a result out there that I cannot yet prove that all $1$ - and $2$ -dimensional Lie algebras are isomorphic to Lie subalgebras of $\mathrm{GL}(2,\mathbb{R})$ (using matrix multiplication, of course); would someone suggest how to show this last? Thanks.","['lie-algebras', 'differential-geometry']"
24628,"Relationship between tuples, vectors and column/row matrices","I am taking a course in linear algebra at the moment, and the book I have uses $1\times n$ matrices, $n\times 1$ matrices and $n$-tuples to represent vectors. In condition I have been taught that $1\times n$ and $n\times 1$ matrices are vectors. What, then, is the difference between an $n$-tuple and a $1\times n$ matrix? What do we need tuples for, that we can't use matrices for? I see that the product between tuples are defined in another way than products between matrices. The product between two $1\times n$ matrices isn't even defined (if $n\neq 1$). But this we can easily solve with trasposing one of them. I hope you can help to clarify this for me.","['linear-algebra', 'definition']"
24637,p-adic numbers and binomial coefficients,"Let $\alpha\in \mathbb{Z}_p$ be an $p$-adic integer and define for $n\in \mathbb{Z}_{\geq 0}$ 
$${\alpha\choose n} := \frac{\alpha(\alpha-1)\cdot\ldots\cdot(\alpha-n+1)}{n!}.$$ This is again a $p$-adic integer, and we can define
$$\alpha_1:=\sum_{n=0}^\infty \overline{{\alpha \choose n}} p^n$$
and
$$\alpha_2:=\sum_{n=0}^\infty \overline{{\alpha \choose p^n}} p^n,$$ where $\overline{(\cdot)}$ means reduction modulo $p$. 
How are $\alpha,\alpha_1,\alpha_2$ related? Are there formulas expressing this relation? Thanks a lot! Edit : Some thinking led me to the following conclusion: Using continuity of $x\mapsto {x\choose p^n}$ as a function $\mathbb{Z}_p\rightarrow \mathbb{Q}_p$ and Lucas' Theorem it follows that $\alpha=\alpha_2$. Does this seem correct?","['p-adic-number-theory', 'binomial-coefficients', 'number-theory']"
24638,Simplifying $\sum 2^k \tan(2^k x)$,"Simplify $\sum\limits_{k = 0}^n {{2^k}\tan ({2^k}x)}$ which $k \in \{ 0,1,...,n + 1\} ,{2^k}x \notin \{ 0,\frac{\pi }{2}\}$",['trigonometry']
24646,How to signal to the reader the difference between a function and a multiplication?,"The following is alpha of t times x: $$\alpha(t)x$$ The following is alpha times t times x: $$\alpha(t)x$$ My instructor had one interpretation, I used the other. ;) Is there an easy or standard way to signify that we're talking about a function rather than a variable multiplication here?","['notation', 'algebra-precalculus']"
24662,How to compute the series $\sum_{n=0}^\infty q^{n^2}$?,"Let $q\in (0,1)$. Is there a way of computing the series
$$
\sum_{n=0}^\infty q^{n^2}
$$
explicitly? Is there at least a nice accurate estimate? All I could get is the estimate
$$\sqrt{\frac{\pi}{4\cdot\mathrm{ln}\frac{1}{q}}}\leq\sum_{n=0}^\infty q^{n^2}\leq 1+\sqrt{\frac{\pi}{4\cdot\mathrm{ln}\frac{1}{q}}}$$
via integration (quite possibly flawed). For $q=\frac{1}{2}$, Maple gives the values
$$
1.064467020\leq 1.564468414\leq 2.064467020,
$$
showing that my estimate is not very precise. (Of course, the sum of the two errors will always be $1$. Here both errors are coincidentally almost exactly $\frac{1}{2}$.)",['sequences-and-series']
24673,Divisors of rational functions on curves at singular points,"Suppose $C$ is an algebraic curve (which has singular points) over an algebraically closed field $k$, and that $f$ is a rational function on $C$. How does one defines the Weil divisor of $f$? The problem is that the local rings of $C$ at singular points are not DVR's, so I do not have an obvious candidate for an order at a point. Thanks! Edit: Let me give an example, inspired by an answer from below. Suppose $C$ is curve $y^2=x^3$. What would be the order of the rational function $x/y$ at the origin?","['algebraic-geometry', 'reference-request']"
24675,Amalgamated Free Product: Practical Uses.,"Suppose $H$ is embedded in $G$ and $H'$ is isomorphic to $H$ and embedded in $G'$. Then we can simultaneously embed $H$, $H'$, $G$ and $G'$ into a single object (the amalgamated free product) such that $H$ and $H'$ become identifiable. This seems similar to the Isomorphism Extension Theorem for fields which is important for developing Galois Theory. What are the practical uses of the amalgamated free product?","['intuition', 'group-theory']"
24676,convex function in open interval is continuous [duplicate],This question already has answers here : Is every convex function on an open interval continuous? [duplicate] (2 answers) Closed 9 years ago . How can I prove that a convex function ƒ defined on some open interval C is continuous on C? Thank you.,['calculus']
24683,Has this Extension to a Series been Studied Before?,"We know from Calculus what a series is, and you might have seen infinite products as well. But the Elementary Symmetric Polynomials give an entire spectrum of operators between a sum and product over a finite set. Given a sequence $s_n$ and an $a \in \mathbb{N}$(representing which operator we're picking), define $S_n$ to be the set $\{s_k | 1 \leq k \leq n\}$. Then our ""generalized series"" is $T_a(s) = \lim_{n \to \infty} e_a(S_n)$ If $a = 0$, you get $1$ no matter what the set is. If $a = 1$, then you get a standard Calculus series. If $a = 2$, then we get $T_2(s) = \sum_{n = 1}^\infty s_n \left(\sum_{m = n+1}^\infty s_m\right)$ If $a=3$, then
$T_3(s) = \sum_{n=1}^\infty s_n \left(\sum_{m = n+1}^\infty s_m \left(\sum_{k = m+1}^\infty s_k \right) \right)$ and so on. I can provide a Mathematica function I wrote to compute them, if you like. My questions are: Is there a standard name or paper for these? I can argue to myself that if $a < b$ and $T_b(s)$ exists, then $T_a(s)$ must exist as well. Does there exist a sequence $s_n$ and a $b > 1$ such that $T_a(s)$ exists for every $a < b$, but $T_b(s)$ doesn't? You can't recover an infinite product with this $T$ function. Short of providing a new function $R$ that swaps $\sum$ for $\prod$ and multiplication for addition in the $T_2$ and $T_3$ expansions above, is there an easy way to recover them? Thank you for your time, -- Michael Burge","['sequences-and-series', 'polynomials', 'generating-functions', 'analysis', 'combinatorics']"
24689,Inequality on balls/bins with nested logs,"Let $k = \lceil \frac{3 \ln n}{\ln \ln n}\rceil$. How does one show that $$ \left(\frac{e}{k}\right)^k \frac{1}{1-\frac{e}{k}} \le n^{-2} ? $$ This is from p. 44 of Motwani and Raghavan, Randomized Algorithms, where they're talking about ball/bin probabilities. The $\left(\frac{e}{x}\right)^x$ is motivated but the $k$ just comes out of nowhere. Ignoring that for the moment, I don't see the derivation of the inequality; even assuming the the 3 is really an approximation for $e$, and throwing out the $\log\log n$... and the geometric series, I get (letting $k^{*}= e \log n$): $$
\left(\frac{e}{k^{*}}\right)^{k^{*}}\approx n^{-\log\log n} \le n^{-2}
$$
for $n \ge e^{e^2}$. But I changed things quite a bit, and this is quite a large constant ($\approx 3^{27}$). So two questions: how does one derive the full inequality? why that particular $k$?","['asymptotics', 'inequality', 'probability']"
24693,Want to learn differential geometry and want the sheaf perspective,"I would like to learn some differential geometry: basically manifolds, differentiable manifolds, smooth manifolds, De Rham cohomology and everything else that is pretty much part of a course in differential geometry. I do however know some deal of category theory and algebraic geometry, and I would therefore like to learn differential geometry from a more ""abstract"" (categorical and algebraical) setting. Are there any good books for this? I was able to find a book called ""Sheaves on Manifolds"" but I don't know if it is a good book for learning the subject (AFAIK, the book might assume prior knowledge of differential geometry) /edit/ Or just lecture notes.",['differential-geometry']
24697,Help complete a proof of Dirichlet on biquadratic character of 2?,"I am stuck proving the theorem that there exists $x$, $x^4 \equiv 2 \pmod p$ iff $p$ is of the form $A^2 + 64B^2$. So far I have got this (and I am not sure if it's correct) Let $p = a^2 + b^2$ be an odd prime, $\left(\frac{a}{p}\right) = \left(\frac{p}{a}\right) = \left(\frac{a^2 + b^2}{a}\right) = \left(\frac{b^2}{a}\right) = 1$ since $p \equiv 1 \pmod 4$ $\left(\frac{a+b}{p}\right) = \left(\frac{(a+b)^2-2ab}{a+b}\right) = \left(\frac{2}{a+b}\right) = (-1)^{((a+b)^2-1)/8}$ using the Jacobi symbol and second supliment of quadratic reciprocity. $(a+b)^{(p-1)/2} = (2ab)^{(p-1)/4}$ since $(a+b)^2 \equiv 2ab \pmod p$ and the last step which I'm stuck on now is for $p = a^2 + b^2$ let $x^2 \equiv -1 \pmod p$ then $2^{(p-1)/4} = x^{ab/2}$. And I don't see how to prove the theorem with this result.","['quadratic-reciprocity', 'number-theory']"
24702,"Given a smooth map which is open, is it a submersion?","A submersion between smooth manifolds is an open map. Is the converse true? That is, is a smooth open map $f:M\to N$ between smooth manifolds a submersion? We can additionally assume that it is surjective, if necessary, because that is the only case I am interested in. I can see how it is almost true, taking a chart $U$ about $m\in M$ and considering a chart $V$ about $f(m)\in N$ contained in the image of $U$ (which is open). Using the isomorphism between the charts and the tangent spaces, I'm fairly sure this gives us a submersion, but I feel there is a slight gap in my argument. So either, does my argument work, or is it true but my argument is incomplete, or is it false?",['differential-geometry']
24704,"Distinct Sylow $p$-subgroups intersect only at the identity, which somehow follows from Lagrange's Theorem. Why?","It seems that often in using counting arguments to show that a group of a given order cannot be simple, it is shown that the group must have at least $n_p(p^n-1)$ elements, where $n_p$ is the number of Sylow $p$ -subgroups. It is explained that the reason this is the case is because distinct Sylow $p$ -subgroups intersect only at the identity, which somehow follows from Lagrange's Theorem. I cannot see why this is true. Can anyone quicker than I tell me why? I know it's probably very obvious. Note: This isn't a homework question, so if the answer is obvious I'd really just appreciate knowing why. Thanks!","['sylow-theory', 'group-theory', 'simple-groups']"
24717,Exchanging order of stochastic integral and $L_2$ norm,"Suppose there is a second-order real-state stochastic process $X: \Omega \times T \rightarrow \mathbb{R}$ with $T= \mathbb{R}$ and probability space $(\Omega, \mathcal{F}, P)$. I was wondering if the following inequality holds for integrals over an interval $[a,b] \subset \mathbb{R}$: $$ \Vert \int_a^b X_t dt \Vert_2 \leq \int_a^b \Vert X_t \Vert_2 dt \ ?$$ Note that the integral on LHS is a stochastic integral while the one on RHS is a deterministic one. $L_2$ norm is on $L_2$ space of squared-integrable random variables as measurable mappings from $(\Omega, \mathcal{F}, P)$ to $(\mathbb{R}, \mathcal{B})$. Is this Jensen's inequality ? I don't think it is, because although the $L_2$ norm is convex, it is not a mapping from $\mathbb{R}$ to $\mathbb{R}$, but from $L_2(\Omega, \mathcal{F})$ to $\mathbb{R}$, and the types of integrals on LHS and on RHS are not the same. So I was wondering if this inequality is true and why? Can it be seen as a generalization of Jensen's inequality? If yes, is it only because of the similarity of their forms or the similarity of some deeper things? Thanks and regards!","['probability-theory', 'stochastic-processes']"
24722,What are useful tricks for determining whether groups are isomorphic?,"In general, it is not too hard to find isomorphisms between two groups when their order is relatively low. However, as their orders grow, it becomes increasingly irritating to write down their entire Cayley tables and such. Is there a set of tricks that is generally useful when trying to prove that two groups are actually isomorphic? After all, it usually seems easier to prove that they aren't, as you just need to point out one property that doesn't correspond... Example: in Armstrong's Groups and Symmetry, it is asked to show that the dihedral group of order 8 and the subgroup of S4 generated by (1234) and (24) are isomorphic. It is easy to send D4's ""single-rotation"" element r to S4's (1234) and D4's ""flipping"" element s to S4's (24), as they are all part of the generating set and their orders coincide, but what is the way to go from here? Also, how far should one go in showing the isomorphism - might pointing out the correspondence in generating elements even be enough?",['group-theory']
24731,Upper bound of the number of local swaps,"Let $\pi$ be an arbitrary permutation of the set $\lbrace 1,\ldots,n,n+1,\ldots,2n \rbrace$ for some $n \in \mathbb{N}$. 
We call a swap local if you swap two neighboring positions in $\pi$, i.e. if you change the positions $i$ and $i-1$ or $i$ and $i+1$ for some  $i$. A $c$-separation of the pairs $(1,n+1),\ldots,(n,2n)$ is a partition of $\pi$ in $L := \lbrace \pi(1), \ldots, \pi(p) \rbrace$ and $R := \lbrace \pi(p+1), \ldots, \pi(2n) \rbrace$ such that for at least $c$ pairs $(k,k+n)$ hold $(k,k+n) \in L \times R$ or $(k,k+n) \in R \times L$. What is a good upper bound on the number of local swaps I have to perform on $\pi$ to get a $c$-separation of the pairs $(1,n+1), \ldots, (n,2n)$?","['permutations', 'combinatorics']"
24739,Navigating though the surface of a hypersphere in a computer game,"People in StackOverflow seems not so into this theme, so I thought I could have better luck in here. I had the idea of an spaceship game where the world is confined in the surface of an 4-D hypersphere (also called a 3-sphere). Thus, in seeing it from inside, it would look like a 3-D world, but by navigating in every direction, I would never leave the limited volume of the 3-sphere. To represent the 3-shpere as a ""flat"" 3-D space, I use a stereographic projection, which is very simple to implement, just need to divide the point in the 3-sphere by one minus its w coordinate. To represent the vertices of the objects I am using normalized 4D vectors, such that $x^2+y^2+z^2+w^2=1$, thus keeping them inside the 3-sphere. The first problem to solve was rotation. But I soon figured out that ordinary 3D rotation matrices would suffice to rotate the world around the viewer in the 3D projection, since it does not mess up with the $w$ coordinate (pretty much like rotating a sphere around the z-axis would also rotate its stereographic projection). Then I figured out that any rotation that included the $w$ coordinate would be equivalent of translation inside the 3D projection (just not commutative, as ordinary 3D translations on ""flat"" spaces), then I could translate along the axis by using a simple around axis rotation matrix $(x', y') = (x \ cos a - y  \sin a, x \sin a + y \cos a)$, but varying $w$ along with another axis. This is so far where I got, and I could not figure out how to navigate forward, based on the position the viewer is facing from the projection. I can apply the inverse transform to derive the normalized 4-D vector (called F) the viewer is facing in the hypersphere coordinates, but I don't know how to navigate in that direction by using a $4\times4$ matrix (what is optimal in OpenGL). I could think on a hackish solution: for every vertex $V$, $d V' = \text{normalize}(dF + V)$, where $d$ is the distance moved forward (in some strange unit I can not exactly precise). This way only works for small values of d, there is no direct correlation between d and the angle variation. Thus the question is: how to move forward (using a $4\times 4$ matrix transform) being in the surface of a 4-D hypersphere? In other words: if I am at $(x, y, z, w)$ now and want to be at $(x', y', z', w')$ next (both vectors of norm 1), how can I derive M such that $M \times (x, y, z, w) = (x', y', z', w')$ ?","['analytic-geometry', 'geometry', 'spherical-geometry']"
24741,Getting generators of graphs automorphism group,Suppose I have a graph like this and a list of its automorphisms. How do I go about getting a set of generators for this group?,"['graph-theory', 'group-theory']"
24743,Does exceptionalism persist as sample size gets large?,"Which of the following is more surprising? In a group of 100 people, the tallest person is one inch taller than the second tallest person. In a group of one billion people, the tallest person is one inch taller than the second tallest person. Put more precisely, suppose we have a normal distribution with given mean $\mu$ and standard deviation $\sigma$. If we sample from this distribution $N$ times, what is the expected difference between the largest and second largest values in our sample? In particular, does this expected difference go to zero as $N$ grows? In another question , it is explained how to compute the distribution $MAX_N$ of the maximum, but I don't see how to extract an estimate for the expected value of the maximum from that answer. Though $E(MAX_N)-E(MAX_{N-1})$ isn't the number I'm looking for, it might be a good enough estimate to determine if the value goes to zero as $N$ gets large.","['statistics', 'probability']"
24744,The inverse of a certain tricky function,"What is the explicit form of the inverse of the function $f:\mathbb{Z}^+\times\mathbb{Z}^+\rightarrow\mathbb{Z}^+$  where $$f(i,j)=\frac{(i+j-2)(i+j-1)}{2}+i?$$",['functions']
24750,How do you calculate the average length of a random binary tree?,"Assuming that you start out with a root node, and decide with 50% probability whether or not to add two children nodes. If they do, repeat this process for them. How can you find the average length of this random binary tree? I'm thinking along the lines of $\displaystyle\lim_{n\to\infty}\sum\limits_{i=1}^n (\frac{n}{2})^2$. because 1/2 * n represents 50% probability, and I'm squaring it because the tree gets exponentially larger. However, I feel like I've done something terribly wrong (probably because I have). Can anyone give me some help?","['trees', 'probability']"
24757,Working out a Group Presentation,"If you have a  group, (say you have group table or any other information), is there an algorithm to find the group presentation? What is the general way of finding presentation of a group?",['group-theory']
24759,Equilibrium distributions of Markov Chains,"I often get confused about when a Markov chain has an equilibrium distribution; when this equilibrium distribution is unique; which starting states converge to the equilibrium distribution; and how finite and countably infinite Markov chains different with respect to the above. (Google isn't quite clearing up my confusion.) Is the following correct/am I missing anything? An irreducible Markov chain (finite or countably infinite) has a unique equilibrium distribution if and only if all states are positive recurrent. (What about reducible Markov chains? A reducible Markov chain has a non-unique equilibrium distribution iff all states are positive recurrent?) However, not all starting states necessarily converge to the unique equilibrium, unless the Markov chain is also aperiodic; that is, an irreducible Markov chain converges to its unique equilibrium regardless of initial state, if and only if all states are positive recurrent and aperiodic.","['stochastic-processes', 'markov-chains', 'probability']"
24763,Proving that $\mathbf{W}$+$\mathbf{W^{\perp}}$=$\mathbb{R^{n}}$,"I am trying to prove that given a subspace $\mathbf{W}$ in $\mathbb{R^{n}}$, the subspace and its orthogonal complement 'cover' whole of $\mathbb{R^{n}}$ through '+' where we define $\mathbf{W}$+$\mathbf{W^{\perp}}$ as linear combinations of vectors both in the subspace and in its orthogonal complement. It seems intuitively right, and I can prove that the sum of their dimensions adds up to n, but I am not sure how to prove the question I am looking at. Thanks!",['linear-algebra']
24767,Square-free zeta function zeros,"It is a well known fact that the geometric series 
$$1+x+x^2+x^3+\ldots$$
has the following form
$$\frac{1}{1-x}$$
Another possible representation  is
$$\prod_{k=0}^{\infty}\left(1+x^{2^{k}}\right)$$
This comes from  the identity
$$1+x+x^2+x^3+\ldots+x^{2^{k}}=\frac{1-x^{2^{k}+1}}{1-x}$$
now taking the numerator of the rhs we have
$$1-x^{2^{k}+1}=\left(1-x^{2^{k}}\right)\left(1+x^{2^{k}}\right)=\left(1-x^{2^{k}-1}\right)\left(1+x^{2^{k}-1}\right)\left(1+x^{2^{k}}\right)$$
proceeding this way we eventually get
$$\left(1-x\right)\left(1+x\right)\left(1+x^{2}\right)\ldots\left(1+x^{2^{k}-2}\right)\left(1+x^{2^{k}-1}\right)\left(1+x^{2^{k}}\right)$$
Taking the limit for the geometric series 
$$\sum_{k=0}^{\infty}x^{k}=\prod_{k=0}^{\infty}\left(1+x^{2^{k}}\right)$$
Now taking the zeta function
$$\zeta(z)=\prod_{p\in\mathbb{P}}\left(1+\frac{1}{p^{z}}+\frac{1}{p^{2z}}+\frac{1}{p^{3z}}+\ldots\right)$$
we can express it as 
$$\zeta(z)=\prod_{k=0}^{\infty}\;\prod_{p\in\mathbb{P}}\left(1+\frac{1}{p^{z\;2^{k}}}\right)$$ Now considere  for $$G(z)=\prod_{k=1}^{\infty}\;\prod_{p\in\mathbb{P}}\left(1+\frac{1}{p^{z\;2^{k}}}\right)$$
note that now $k\geq 1$ and that $G(z)$ converges absolutely for $z>\frac{1}{2}$ Can we say that, after analytic continuation, that $$H(z)=\sum_{k=0}^{^\infty}\frac{|\mu(k)|}{k^{z}}=\prod_{p\in\mathbb{P}}\left(1+\frac{1}{p^{z}}\right)$$ has exactly the same zeros as $\zeta(z)$?","['riemann-zeta', 'zeta-functions', 'number-theory', 'prime-numbers', 'complex-analysis']"
24776,Weak convergence in Sobolev spaces,"Consider the inner product by $\langle f,g \rangle_{H^1} = \langle f, g \rangle_{L^2} + \sum_{|\alpha|=1} \langle D^\alpha f, D^\alpha g \rangle_{L^2}$ where $\alpha$ is a multi-index and $D$ denotes the weak derivative. Define $H^1(\Omega)$ as the space of functions that are finite under the norm induced from this inner product. It can be shown that $H^1(\Omega)$ is a Hilbert space. Now, suppose there exists a sequence of functions $\{ f_n \} \subset H^1(\Omega)$ that converges weakly in $H^1$ to some limit $f \in H^1(\Omega)$. Can I then say that this sequence converges weakly to the same limit under the $L^2$ inner product? By an application of the Banach-Alaoglu Theorem, I know that weak convergence of this sequence in $H^1$ will imply strong convergence of a subsequence in $H^1$. And then I think strong convergence of this subsequence in $H^1$ will imply strong convergence in $L^2$ as well. However, I'm not sure if anything can be said about the entire sequence under the $L^2$ inner product and its weak/strong convergence properties.","['sobolev-spaces', 'functional-analysis', 'weak-convergence']"
24785,The $n$-disk $D^n$ quotiented by its boundary $S^{n-1}$ gives $S^n$,"Define $D^n = \{ x \in \mathbb{R}^n : |x| \leq 1 \}$. By identifying all the points of $S^{n-1}$ we get a topological space which is intuitively homeomorphic to $S^n$.
If $n = 2$, this can be visualised by pushing the centre of the disc $D^2$ down so you have a sack, then shrinking the boundry of the sack to a point which gives you a teardrop shaped object which is clearly homeomorphic to $S^2$. I am new to algebraic topology. How do I prove that the quotient space is actually homeomorphic to $S^n$. I haven't been able to write down explicitly a continuous map between $D^n$ and $S^n$ which maps $S^{n-1}$ to a point on $S^n$, which at the moment is the only way I know how to begin showin that two spaces are homeomorphic.
Is more machinery needed? If so I am interested to hear what is needed. If not, please tell me how stupid I am and give me a hint!","['general-topology', 'quotient-spaces', 'algebraic-topology']"
24789,Why does the sum of a division applied to individual items not equal the division applied to the sum of those items?,"When $a_2/a_1 = b_2/b_1$, $a_1 \neq b_1$, we have $$\frac{a_{1}}{a_{2}/a_{1}}+\dfrac{b_{1}}{b_{2}/b_{1}}=
\frac{a_{1}+b_{1}}{1+\dfrac{(a_{2}+b_{2})-(a_{1}+b_{1})}{a_{1}+b_{1}}}.$$ So why when $a_2/a_1 \neq b_2/b_1 , a_1 \neq b_1$ we don't have a similar equality? $$\frac{a_{1}}{a_{2}/a_{1}}+\dfrac{b_{1}}{b_{2}/b_{1}}\neq \frac{a_{1}+b_{1}}{1+\dfrac{(a_{2}+b_{2})-(a_{1}+b_{1})}{a_{1}+b_{1}}}?$$","['fractions', 'algebra-precalculus']"
24795,How to fit fixed data from two linear functions,"I have a set of points $(x, y)$ where each one comes from either one of two linear functions:
\begin{align*}
    y &= m_1 x + b_1\\
    y &= m_2 x + b_2
\end{align*}
Is there a fitting method to find such functions, without knowing from which function each of the points come from? PS. can somebody add fit (or fitting) to the existing tags",['statistics']
24800,Random points in a rectangular grid defining a closed path,"Suppose we have a $n\times m$ rectangular grid (namely: $nm$ points disposed as a matrix with $n$ rows and $m$ columns). We randomly pick $h$ different points in the grid, where every point is equally likely. If only horizontal or vertical movements between two points are allowed, what is the probability that the points define at least one closed path? ps: we can suppose $m=n$ to simplify For example, let $n=m=4$ and $h=6$.
1 denotes a selected point, 0 a non-selected one. These $6$ points define a closed path: 1  0  0  1 0  0  0  0 1  1  0  0 0  1  0  1 as these $6$ do (the $4$ in the bottom-right corner): 1  0  0  1 0  0  0  0 0  1  0  1 0  1  0  1 while the following $6$ points do not: 1  0  0  0 0  0  0  1 1  1  0  0 0  1  0  1 Substantially, the $h$ points define a closed path if and only if there exist a subset of these $h$ points such that every point in the subset has one other point of the subset on the same row and one on the same column. Thanks for your help.","['probability', 'combinatorics']"
24805,Smooth Poincaré Conjecture,"One of my professors wrote the following open question on the blackboard: If $M$ is a compact, connected smooth $4$-manifold such that $\pi_1(M) = 0$, $\pi_2(M) = 0$ (first two homotopy groups are trivial), does it follow that $M$ is diffeomorphic to the $4$-sphere? and warned us, that if we managed to solve it, we would get an instant Ph.D. -- so, keen on getting a Ph.D. before my bachelor degree, I went to work immediately! ;-) My first thought was the following: If one could endow $M$ with a Riemannian metric giving a Riemannian manifold with constant sectional curvature $1$, then by compactness $M$ would be a complete, connected, simply connected manifold of curvature $1$, which would imply the statement. Now I obviously didn't get much further than this (my dreams were shattered!). Anyways, this leads to the question: ""When is it possible to endow a smooth manifold with a metric which has some desired properties (i.e. constant curvature or bounded curvature)?"" Has there been much work on this? Are there any good books/papers I could take a look at (just to get some impression of how the experts approach this problem)? I was also wondering whether the above is actually an approach to the problem taken by people working in the field? Or may it be completely hopeless to try and gain any control of the metric globally? Well, as always I thank in advance for any comments, answers etc. Best regards,
S.L.","['differential-topology', 'riemannian-geometry', 'differential-geometry']"
24817,What is the vector form of Taylor's Theorem?,"I checked most of the posts about Taylor expansion with scalar functions. Could anyone tell me what is the multivariate version of Taylor's Theorem, and how I can use it?","['multivariable-calculus', 'linear-algebra']"
24840,Finding the norm in the cyclotomic field $\mathbb{Q}(e^{2\pi i / 5})$,"I'm doing one of the exercises of Stewart and Tall's book on Algebraic Number Theory. The problem concerns finding an expression for the norm in the cyclotomic field $K = \mathbb{Q}(e^{2\pi i / 5})$. The exact problem is the following: If $\zeta = e^{2 \pi i / 5}$, $K = \mathbb{Q}(e^{2\pi i / 5})$, prove that the norm of $\alpha \in \mathbb{Z}[\zeta]$ is of the form $\frac{1}{4}(A^2 -5B^2)$ where $A, B \in \mathbb{Z}$. ( Hint: In calculating $\textbf{N}(\alpha)$, first calculate $\sigma_1 (\alpha) \sigma_4 (\alpha)$ where $\sigma_i (\zeta) := \zeta^{i}$. Show that this is of the form $q + r\theta + s\phi$ where $q, r, s \in \mathbb{Z}$, $\theta = \zeta + \zeta^{4}$ and $\phi = \zeta^{2} + \zeta^{3}$. In the same way establish $\sigma_2 (\alpha) \sigma_3 (\alpha) = q + s\theta + r\phi$  ) Using Exercise $3$ prove that $\mathbb{Z}[\zeta]$ has an infinite number of units. Now, I've already done what the hint says and arrived at the following. If we let $\alpha = a +b\zeta^{} + c\zeta^{2} + d\zeta^{3} \in \mathbb{Z}[\zeta]$ then after simplifying I get $$\textbf{N}(\alpha) = \sigma_1 (\alpha) \sigma_4 (\alpha) \sigma_2(\alpha) \sigma_3(\alpha) = ( q + r\theta + s\phi ) ( q + s\theta + r\phi )$$ $$ = q^2 + (qr + qs)(\theta + \phi) + rs(\theta^2 + \phi^2) + (r^2 + s^2)\theta \phi$$ and then it is not that hard to see that $\theta + \phi = -1$, $\theta^2 + \phi^2 = 3$ and $\theta \phi = -1$ so that in the end one obtains $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2)$$ where $q = a^2 + b^2 + c^2 + d^2$, $r = ab + bc + cd$ and $s = ac + ad + bd$. Now, here I got stuck because I just can't take the last expression for the norm into the form that the exercise wants. The purpose is to get that nice form for the norm to find units by solving the diophantine equation $\textbf{N}(\alpha) = \pm 1$, which is what the Exercise $3$ mentioned in the statatement of the problem is about. I already know how to prove the existence of infinitely many units in $\mathbb{Z}[\zeta]$ (without using Dirichlet's Unit Theorem of course), but the exercise also demands a proof that the norm is equal to $\frac{1}{4}(A^2 -5B^2)$. I even asked my professor about this and we were not able to get the desired form for the norm. So my question is if anybody knows how to prove that the norm has that form, and if so, how can I show that? Or if it could be that maybe the hint given in the exercise is not that helpful? Thanks a lot in advance for any help with this. EDIT After looking at Derek Jennings' answer below, to get from the expression I had for the norm to the one in Derek's answer is just a matter of taking out a common factor of $1/4$ in the expression and then completing the square, $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2) = q^2 - q(r+s) + rs - (r-s)^2$$ $$ = \frac{1}{4}( 4q^2 - 4q(r+s) + 4rs - 4(r-s)^2  ) $$ $$=  \frac{1}{4} ( 4q^2 - 4q(r+s) +\overbrace{(r+s)^2} - \overbrace{(r+s)^2} + 4rs - 4(r-s)^2  )$$ $$ = \frac{1}{4} ( (2q -(r+s))^2 -(r-s)^2 - 4(r-s)^2 )$$ $$ = \frac{1}{4}( (2q - r - s)^2 - 5(r-s)^2 ) = \frac{1}{4}(A^2 - 5B^2),$$ as desired. Of course it is easier if you already know what to get at =)","['algebraic-number-theory', 'abstract-algebra']"
24843,every divisor of degree $0$ on a smooth cubic curve $\mathcal{C}\subseteq\mathbb{P}^2$ is equivalent to $A-A_0$ for a fixed $A_0\in\!\mathcal{C}$,"NOTATION: Let $\mathcal{C}=\mathcal{V}(F)\subseteq\mathbb{P}^2$ be a curve of degree $3\!=\!deg(F)$ with no singularities and let $A_0\!\!\in\!\mathcal{C}$ be fixed. Let $Div(\mathcal{C})$ denote the group of divisors on $\mathcal{C}$, i.e. the set of all formal sums $$\{\sum\limits_{P\in\mathcal{C}} n_PP\,|\; n_P\!\in\!\mathbb{Z}, \text{only finitely many } n_P \text{ are not zero}\},$$
let $\mathbb{F}(\mathcal{C})$ be $\{\text{rational functions from }\mathcal{C}\text{ to }\mathbb{F}\}$, i.e. the field of fractions of $\mathbb{F}[x_0\!:\!x_1\!:\!x_2]/I(\mathcal{C})$. Let $\psi:\mathbb{F}(\mathcal{C})\setminus\{0\}\rightarrow Div(\mathcal{C})$ denote the mapping, that sends each rational function $f$ to the principal divisor $(f)=\sum_{P\in\mathcal{C}}\mu_P(f,F)P$ where $\mu_P(f,F)$ is the intersection multiplicity of curves $\mathcal{V}(f),\mathcal{V}(F)$ in $P$. Then $Cl(\mathcal{C})$ denotes the group of divisor classes on $\mathcal{C}$, i.e. $Div(\mathcal{C})/im(\psi)$. So any two divisors $D_1$ and $D_2$ are equivalent, $D_1\sim D_2$, iff $D_1-D_2=(f)$ for some $f\in\mathbb{F}(\mathcal{C})$. QUESTION: Define $\varphi:\mathcal{C}\rightarrow Cl^0(\mathcal{C})\!=\!\{\text{divisor classes on }\mathcal{C}\text{ of degree }0\}$ as a mapping, that sends each $A$ to the divisor class of $A-A_0$. How can I prove that $\varphi$ is surjective ? WHAT IS ALREADY KNOWN: on a smooth cubic curve $\mathcal{C}$ for $P,Q,R,S\in\mathcal{C}$: $P\sim Q\Leftrightarrow P=Q$ $P+Q\sim R+S \;\;\Longleftrightarrow\;\;$ the line through $P,Q$ intersects the line through $R,S$ on $\mathcal{C}$ help","['plane-curves', 'algebraic-geometry', 'algebraic-curves']"
24845,A measurable function on an atom is almost everywhere constant,"Let $f \in m(\Omega,\mathcal{F})$, i.e. $f \mapsto [-\infty,\infty]$ and let $A \in \mathcal{F}$ be an atom. Prove that $f$ is almost everywhere constant on A: there exists $k \in [-\infty,\infty]$ such that $\mu (\{\omega \in A : f(\omega) \neq k \} )=0$. I was thinking let $k=\frac{1}{\mu(A)}\int \limits_{A} f\,d\mu$. Then let $B=\{\omega \in A :f(\omega) \neq k \}$.  Since A is an atom, and B is a subset of A then $\mu(B)=0$, in which case we're done, or $\mu(B)=\mu(A)$.  So I need to show that $\mu(B)<\mu(A)$.","['measure-theory', 'analysis']"
24852,2D Rotation Around Point,"D. My first post here ::- >. I got a rather simple question. But please, allow me to introduce myself a bit first. I think it's polite for a first post ::- D. I'm a game developer (free Flash games) with a few ahem big holes in my math (read: I haven't done any math since high school - thanks to the school, I was totally repulsed by it in University). Even so, I always liked math, but only out of school ::- D. Unfortunately, I haven't kept touch with it (it wasn't necessary so far). So, without further delay, I will get to my problem for a game I'm working on. Anybody helping me wins a free ticket to the game's credits grin . And it's going to be a nice game, much nicer than my previous: http://www.kongregate.com/games/Kyliathy/thunderbirdz (to see that I'm not a fraud, LOL). What I'm trying to do (and failing miserably) is to rotate a Rectangle around a Point, in Adobe Flash. The problem is that Flash rotates an object relative to it's X=0, Y=0 coordinate, which they call a registration point. And I want to rotate the Rectangle around ANOTHER POINT inside that Rectangle. This is a sample Flash which illustrates my problem: http://www.axonnsd.org/W/P002/MathSandBox.swf [LATER EDIT: all SWF samples we talked about in the comments below are now accessible at the same links, except that you have to add '/W/P002'after 'axonnsd.org' - see the above link.] The BLUE circle should stay on top of the RED circle. Instead, the Rectangle rotates around its registration point. For people without Flash or who hate Flash, here is an image of the same problem which also show the registration point via a BLACK Square Now....... My solution to this problem would be to find an equation to MOVE the Rectangle to an appropriate X/Y so that the BLUE circle stays on top of the RED circle. Specifying the rotation in Flash is simple: object.rotation = X, where X can be any number. It will, however, always divide it by 360, of course. But now I have to find SOME method by which I set my object.x and object.y so that the Rectangle appears to rotate around the BLUE/RED circles, NOT around its registration point. And, for the life of me, I don't even know where to START finding that mysterious equation ::- D. I bet it involves a bit of Pi and some drops of trigonometry. But I don't even know where to begin... Pointers, anybody? Thank you for reading my long first message! ::- D.","['geometry', 'trigonometry']"
24855,"Showing groups of order $p^{k}(p+1)$ are not simple, p prime","I want to show that there are no simple groups of order $p^{k}(p+1)$ where $k>0$ and $p$ is a prime number. So suppose there is such a group. Then if we let $n_{p}$ denote the number of $p$-Sylow subgroups of $G$ we have that $n_{p}=p+1$. Now by letting $G$ act on $Sylow_{P}(G)$ by conjugation we obtain a group homomorphism $G \rightarrow S_{p+1}$. Since $G$ is simple then either $ker(f)$ is trivial or all $G$. Now here's my question: assume $ker(f)=G$ this would imply then that $G$ has a unique $p$-Sylow subgroup no? but then such subgroup is normal which contradicts the fact that $G$ is simple. So the map in fact is injective but then $|G|$ divides $(p+1)!$ which cannot be. Basically my question is if my argument is correct, namely thta if $ker(f)=g$ implies the existence of a unique $p$-Sylow subgroup which implies such subgroup is normal in $G$ which cannot be. In case this is wrong, how do you argue that $ker(f)$ cannot be all $G$? Thanks","['group-theory', 'simple-groups']"
24866,Identity for $\sum\limits_{j = a}^{N} 				\binom{N}{j} \binom{j}{a} d^{-j}$?,"I have run across the following multinomial series:
$$ 				\sum_{j = a}^{N}
				\binom{N}{j} \binom{j}{a} d^{-j}
$$
Here, $d>1$. This seems like a formula which has either a well-known identity, or which has no further closed form or simplification. Can anyone shed any light on this formula, or possibly point me to a standard reference?","['sequences-and-series', 'binomial-coefficients', 'combinatorics']"
24873,Elementary proof that $\mathbb{R}^n$ is not homeomorphic to $\mathbb{R}^m$,"It is very elementary to show that $\mathbb{R}$ isn't homeomorphic to $\mathbb{R}^m$ for $m>1$: subtract a point and use the fact that connectedness is a homeomorphism invariant. Along similar lines, you can show that $\mathbb{R^2}$ isn't homeomorphic to $\mathbb{R}^m$ for $m>2$ by subtracting a point and checking if the resulting space is simply connected. Still straightforward, but a good deal less elementary. However, the general result that $\mathbb{R^n}$ isn't homeomorphic to $\mathbb{R^m}$ for $n\neq m$, though intuitively obvious, is usually proved using sophisticated results from algebraic topology, such as invariance of domain or extensions of the Jordan curve theorem. Is there a more elementary proof of this fact? If not, is there intuition for why a proof is so difficult?",['general-topology']
24896,I-adic completion of a ring,"Let $R$ be a ring, $I$ an ideal. According to Atiyah-Macdonald, if $R$ is Noetherian, then, we have $\hat{I}=\hat{R}I$ where hat denotes $I$-adic completion of $R$ and (I presume) $\hat{I}$ denotes the induced completion on $I$. I don't understand how to arrive at this equality and why the Noetherian hypothesis is necessary. Essentially $\hat{I}$ consists of equivalence classes of Cauchy sequences with elements in $I$. Any element of $\hat{R}I$ is an equivalence class of Cauchy sequences consisting of elements of $I$. I don't see how every Cauchy sequence with elements in $I$ is equivalent to one which can be written as a sum of products of a Cauchy sequence and a constant sequence of an element of $I$.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
24898,"$\sin(2\pi nx)$ does not converge for $x \in (0,1/2)$","How to show that $\sin(2 \pi nx)$ does not converge as n goes to infinity?  $x \in (0,1/2)$","['calculus', 'convergence-divergence', 'trigonometry', 'analysis', 'limits']"
24901,$\sum \frac{1}{f(k)}$ converges iff $\sum \frac{f^{-1}(k)}{k^2}$ converges,"Let $f$ be a strictly increasing positive continuous function defined on $[1,\infty)$ with limit $\infty$ as $x$ goes towards $\infty$. Then $\sum_{k=0}^{\infty} \frac{1}{f(k)}$ converges if and only if $\sum_{k=0}^{\infty} \frac{f^{-1}(k)}{k^2}$ converges, where $f^{-1}$ denotes the inverse of $f$. I saw this claim as an exercise in a analysis textbook, linked from this site. Can not remember which one unfortunately. It was listed as a challenging exercise and has proven too challenging for me. My initial idea was to try to use the integral test. $\sum \frac{1}{f(k)}$ converges exactly when $\int \frac{1}{f(x)}$ converges. I thought I might do some smart change of variable to find that $\int \frac{f^{-1}(x)}{x^2}$ converges. I could not come up with one however and I also realized that I do not know that the sum $\sum \frac{f^{-1}(k)}{k^2}$ satisfies the conditions for using the integral test. Unfortunately I ran out of ideas at that point.",['sequences-and-series']
24911,Closed Subspaces of Vector Spaces,"Question: In Functional Analysis we can note things like: every closed subspace of a Banach space is Banach.  In this case, what does ""closed subspace"" mean? Does this mean closed under the norm topology? Or does this mean closed in the sense that multiplication of scalars and addition of vectors is closed? Or does this mean closed with respect to limits? I'm reviewing this material and I realized that even though I have this in my notes a number of times I am unsure of what this actually is.  I thought it was the second statement above, but the third statement makes the ""every closed subspace of a banach space is banach"" statement easy to prove.","['general-topology', 'linear-algebra', 'functional-analysis', 'definition']"
24912,Use of algebra and factorials for a question related to proof by induction,"$$
\begin{align*}
&= (n+1)! − 1 + ( (n+1) · (n+1)! )\\

&= (n+1)! (1+n+1) − 1\\

&= (n+1)! (n+2) − 1\\

&= (n+2)! − 1\\
\end{align*}
$$ I'm confused at how the first step goes to the second step. Can someone please clarify this?","['factorial', 'induction', 'algebra-precalculus', 'discrete-mathematics']"
24921,"Inner Product, definite positive?","While reading through my textbook it says ""the most important example of an inner-product space is $F^n$"", where $F$ denotes $\mathbb{C}$ or $\mathbb{R}$ . Our definition of an inner product on a vector space $V$ is as follows: 1) Positive definite: $\langle v,v \rangle \ge 0$ with equality if and only if $v=0$ 2) Linearity in the first arguement: $\langle a_1v_1+a_2v_2,w \rangle = a_1 \langle v_1,w \rangle + a_2\langle v_2,w \rangle$ 3) Conjugate symmetric: $\langle u,v\rangle = \overline{\langle v,u\rangle}$ Let $$\displaystyle w=(w_1\ldots,w_n) , z=(z_1,\ldots,z_n)$$ Then: $$\displaystyle \langle w,z\rangle =w_1\overline{z_1}+\cdots+w_n\overline{z_n}$$ I'm trying to verify that this is indeed true.  So first I want to check that $\langle w,z\rangle$ satisfies condition (1). Say that $w,z\in \mathbb{C}$. Just looking at say $w_1=a+bi$ and $z_1=c+di$, how can we guarantee that $w_1\overline{z_1}\geq 0$? If we can observe this, it would need to hold true for the other coordinates as well.  So my question is, how do we know that $w_1\overline{z_1}\geq 0$?","['linear-algebra', 'inner-products']"
24922,Find radius of the Smallest Circle that contains this figure,"A two dimensional silo shaped figure is formed by placing a semi-circle of diameter 1 on top of a unit square, with the diameter coinciding with the top of the square. How do we find the radius of the smallest circle that contains this silo?",['geometry']
24939,Why does triply periodic univariate function not exist?,"A univariate function $f$ is periodic with period $p_1,\ldots,p_k$ if $$f(z) = f(z + \sum_{i=1}^k n_i \cdot p_i)$$ for all complex $z$ and integers $n_i$. Elliptic function is an example of doubly periodic function. It is claimed that a triply periodic univariate function cannot exist, but why? Can't we follow the construction of elliptic functions that uses Schwarz-Christoffel formula to map upper-plane onto a triangle, and use the reflection principle to create a lattice which corresponds to three periods? Which step fails to hold when we mimic the construction of an elliptic function to create a triply period meromorphic univariate function? Sorry if the question is stupid. I do not have an access to the original proof that a triply periodic function cannot exist, either. So references are welcome!","['reference-request', 'complex-analysis']"
24942,Universal binary operation and finite fields (ring),"Take Boolean Algebra for instance, the underlying finite field/ring $0, 1, \{AND, OR\}$ is equivalent to $ 0, 1, \{NAND\} $ or $ 0, 1, \{ NOR \}$ where NAND and NOR are considered as universal gates. Does this property, that AND ('multiplication') and OR ('addition') can be written in terms of a single universal binary relation (e.g. NAND or NOR), hold with every finite field (or finite ring)? EDIT : I am interested in mathematical structures where boolean algebra holds (so that I can design a digital circuit.). Comments from JDK and jokiri point out that this is a valid question for finite rings at least and for finite fields in one case (i.e. $1, 0$ case).","['finite-fields', 'boolean-algebra', 'finite-rings', 'abstract-algebra']"
24949,Mysterious step while solving ODE,"I just read a paper in which an ODE was solved using a step I don't understand. $${dI \over \kappa (x) dx} = I$$ 
Let
$$\tau = \int_0^x \kappa(x)dx$$ Rewrite equation as
$${dI \over d\tau} = I$$ 
and solve. How does the final expression follow from the definition of $\tau$?","['ordinary-differential-equations', 'calculus']"
24961,"Why does $\mu(k,n)=\mu(1,\frac{n}{k})$?","Why does $\mu(k,n)=\mu(1,\frac{n}{k})$, where $\mu$ is the Möbius function and $k$ and $n$ are integers. I'm reading about the Möbius function on a poset of integers ordered by divisibility. The author uses this fact several times, but I don't see why it's so obvious. What exactly is this equality saying? Thanks. Edit: The author computes $\mu(1,n)$ as $\mu(1,n)=1$ if $n=1$, $\mu(1,n)=(-1)^k$ if $n$ is the product of $k$ distinct primes, and $\mu(1,n)=0$ otherwise.","['combinatorics', 'number-theory']"
24964,Repeated Factorials and Repeated Square Rooting,"I was talking with friends about silly questions involving what numbers you can get using only a single digit ""3"" and unary operations. We eventually conjectured that using only factorials and square roots you can get arbitrarily close to any number greater than or equal to $1$. But we are having trouble proving or disproving the conjecture. Precisely, start with the number $3$. Then take its factorial $m$ times, and then take the square root of its result $n$ times. Ie, $(3!!\ldots !)^{\frac{1}{2^n}}$ where there are $m$ factorials. Let the set of numbers achievable in this way be $X$. Is $X$ dense in $[1,\infty)$? The only progress we have made is to show that any interval $[x,x^2]$ for $x>1$ there is a limit point $a \in [x,x^2)$ of $X$. This is true because for any $z > x^2$ we can square root it an appropriate number of times to get it in $[x,x^2)$. We can do this for infinitely many points of the sequence $3,3!,3!!,\ldots$. And all points we get through this process are distinct. Let $F(m)$ be $3$ with $m$ factorials. If $F(m)^{\frac{1}{2^n}} = F(a)^{\frac{1}{2^b}}$ then we can raise each side to a power and get an expression of the form $F(m) = F(a)^{\frac{1}{2^c}}$. But factorials are not squares. (To see this for $q!$, note that there is a prime in $[q/2,q]$ by bertrand's postulate. This prime appears only once in the factorization of $q!$). So all numbers we get are distinct. We have infinitely many distinct points in $X \cap [x,x^2)$ and therefore there is a limit point. Other than that, we can't figure anything out. It feels like $X$ should be dense. Consider some interval $[x,x^2]$. Take lots of factorials of $3$. Then take square roots of that until it falls in $[x,x^2]$. It feels like the points we get will be somewhat uniformly distributed around $[x,x^2]$ and therefore dense.","['factorial', 'sequences-and-series', 'limits']"
24978,Nasty examples for different classes of functions,"Let $f: \mathbb{R} \to \mathbb{R}$ be a function. Usually when proving a theorem where $f$ is assumed to be continuous, differentiable, $C^1$ or smooth, it is enough to draw intuition by assuming that $f$ is piecewise smooth (something that one could perhaps draw on a paper without lifting your pencil). What I'm saying is that in all these cases my mental picture is about the same. This works most of the time, but sometimes it of course doesn't. Hence I would like to ask for examples of continuous, differentiable and $C^1$ functions, which would highlight the differences between the different classes. I'm especially interested in how nasty differentiable functions can be compared to continuously differentiable ones. Also if it is the case that the one dimensional case happens to be uninteresting, feel free to expand your answer to functions $\mathbb{R}^n \to \mathbb{R}^m$. The optimal answer would also list some general minimal 'sanity-checks' for different classes of functions, which a proof of a theorem concerning a particular class would have to take into account.","['examples-counterexamples', 'intuition', 'real-analysis']"
24982,Cofinality and its Consequences,"(1)In set theory, what is the purpose for defining the concept of cofinality?is it that important? (2)The concept of cofinality finally leads to 2 types of infinite cardinal, for which the first one is regular cardinal and another one is singular cardinal defined this way: An infinite cardinal $\aleph_{\alpha}$ is regular if $cf (\aleph_{\alpha})=\aleph_{\alpha}$ and singular if $cf (\aleph_{\alpha}) < \aleph_{\alpha}$ . I was wondering here...what is the meaning of this and its consequences(the fact that it has 2 types of cardinal)? Your explanation is very much appreciated. thanks ahead.",['elementary-set-theory']
24984,Using generating functions to find a formula for the Tower of Hanoi numbers,"So the Tower of Hanoi numbers are given by the recurrence $h_n=2h_{n-1}+1$ and $h_1=1$. I let my generating function be 
$$
g(x)=\sum h_nx^n
$$
Then 
$$
g(x)=\sum h_n x^n=\sum (2h_{n-1}+1)x^n=\sum 2h_{n-1}x^n+\sum x^n=2xg(x)+\frac{1}{1-x}.
$$
Solving for $g(x)$ I find 
$$
g(x)=\frac{1}{(1-2x)(1-x)}=\frac{2}{1-2x}-\frac{1}{1-x}=2\sum (2x)^n-\sum x^n.
$$
It seems then that the coefficient $h_n$ of $x^n$ is $2^{n+1}-1$, but wolfram mathworld says it should be $h_n=2^n-1$. What did I do wrong here? Thanks.","['generating-functions', 'combinatorics']"
24994,Young inequality,"I am trying to prove young's inequality for integrals
$$
ab \leq \int\nolimits_0^a \! f(x) \, \mathrm{d}x + \int_0^b \! f^{-1}(x) \, \mathrm{d}x.
$$
Can you help me please?","['inequality', 'calculus', 'integration']"
24995,A question on $\operatorname{GL}_2(\mathbb R)$,I know that all finite subgroups of $\operatorname{SL}_2(\mathbb R)$ are cyclic by standard averaging argument. They are all conjugate to some finite subgroup of $\operatorname{SO}_2(\mathbb R)$ and therefore cyclic. My question is how to classify all finite subgroups of $\operatorname{GL}_2(\mathbb R)$. Thanking you.,"['linear-algebra', 'group-theory', 'abstract-algebra']"
24996,Question related with partial order - finite set - minimal element,Prove by induction . Every partial order on a nonempty finite set has at least one minimal element. How can I solve that question ?,"['induction', 'elementary-set-theory', 'order-theory']"
