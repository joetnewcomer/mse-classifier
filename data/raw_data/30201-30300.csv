question_id,title,body,tags
282644,Is $f(x)=\sin(x^2)$ periodic?,"Is the function $f:\Bbb R \rightarrow \Bbb R$ defined as $f(x)=\sin(x^2)$, for all $x\in\Bbb R$, periodic? Here's my attempt to solve this: Let's assume that it is periodic. For a function to be periodic, it must satisfy $f(x)=f(T+x)$ for all $x\in\Bbb R$, so it must satisfy the relation for $x=0$ as well. So we get that $T^2=k\pi \iff T=\sqrt{k\pi}$, $k\in\Bbb N$ (since $T$ must be positive, we remove the $-\sqrt{k\pi}$ solution). So what now? I tried taking $x=\sqrt\pi$ and using the $T$ I found, and I get this: $$ \sin\pi=\sin(T+\sqrt\pi)\iff-1=\sin(\pi(\sqrt k+1)^2)\iff k+2\sqrt k+1=3/2+l  $$
Is this enough for contradiction? The left side of equation is sometimes irrational and gets rational only when $k$ is perfect square, which doesn't happen periodic, while the right hand side is always rational. Or I'm still missing some steps? Thanks.","['trigonometry', 'real-analysis', 'periodic-functions']"
282655,"Let $a,b$ and $c$ be real numbers.evaluate the following determinant: |$b^2c^2 ,bc, b+c;c^2a^2,ca,c+a;a^2b^2,ab,a+b$|","Let $a,b$ and $c$ be real numbers. Evaluate the following determinant: $$\begin{vmatrix}b^2c^2 &bc& b+c\cr c^2a^2&ca&c+a\cr a^2b^2&ab&a+b\cr\end{vmatrix}$$ after long calculation I get that the answer will be $0$. Is there any short processs? Please help someone thank you.",['linear-algebra']
282665,Integration a function of a single variable over a 2-dim measure,"Let $(X,\mathfrak B(X))$ and $(Y,\mathfrak B(Y))$ be two measurable spaces and let $\mu$ be a finite measure on the product $\sigma$-algebra $\mathfrak B(X)\otimes \mathfrak B(Y)$. Let $f:X\to\Bbb R$ be a bounded $\mathfrak B(X)$-measurable function and define $\nu(A) = \mu(A\times Y)$ to be a measure on $\mathfrak B(X)$. How to show that
$$
  \int_{X\times Y}f(x)\mu(\mathrm dx\times \mathrm dy) = \int_Xf(x)\nu(\mathrm dx).
$$
I guess, this is completely trivial, however I couldn't come with a completely formal solution. Perhaps, that shall follow from some change of variables equality and the fact that $\nu$ is a pushforward measure of $\mu$ under the projection $\pi_X$? Or from the fact that $f:X\times Y\to\Bbb R$ is $\mathfrak B(X)\otimes \{\emptyset,Y\}$-measurable function and both measures coincide on this $\sigma$-algebra?",['measure-theory']
282670,Rational/meromorphic functions on a scheme,"In EGA (IV, §§ 20 – 21), the sheaf of meromorphic functions $\mathscr{M}_X$ on a ringed space $(X, \mathscr{O}_X)$ is defined as the sheaf associated to the presheaf that associates to an open $U \subset X$ the localization of the ring $\Gamma(U, \mathscr{O}_X)$ at its regular elements.  There is a canonical homormophism $\mathrm{div} : \Gamma(X, \mathscr{M}_X^*) \to \mathrm{Div}(X) = \Gamma(X, \mathscr{M}_X^*/\mathscr{O}_X^*)$ that associates to a regular meromorphic function a (Cartier) divisor; and there is a homomorphism $\mathrm{cyc} : \mathrm{Div}(X) \to Z^1(X)$ to the group of 1-codimensional cycles which is defined for positive divisors $D \in \mathrm{Div}_+(X)$ as
$$ \mathrm{cyc}(D) = \sum_{x \in X^{(1)}} \mathrm{long}_{\mathscr{O}_{X,x}} (\mathscr{O}_{D,x}) . \overline{\{ x \}} $$
(and extends in a unique manner to the whole group $\mathrm{Div}(X)$). When $X$ is a locally Noetherian scheme , Vakil (6.5.5) defines the ring of rational functions on $X$ as the inductive limit of the rings $\Gamma(U, \mathscr{O}_X)$ along the family of open sets $U \subset X$ containing the associated points.  He notes that when $X$ is integral, this ring is indeed isomorphic to the traditional ""function field"", i.e. the stalk $\mathscr{O}_{X,\xi}$ of the structure sheaf at the generic point $\xi$.  In Fulton's ""Intersection theory"" (§§ 1.4 – 1.5), for an integral scheme $X$, he defines the 1-codimensional cycle associated to a rational function $r \in K(X)^*$ by
$$ [\mathrm{div}(r)] = \sum_{x \in X^{(1)}} \mathrm{ord}_x(r) . \overline{\{x\}} $$
where $\mathrm{ord}_x : K(X)^* \to \mathbb{Z}$ is the homomorphism defined by
$$ \mathrm{ord}_x(r) = \mathrm{long}(\mathscr{O}_{X,x}/(a_x)) - \mathrm{long}(\mathscr{O}_{X,x}/(b_x)) $$
where $a_x/b_x \in \mathrm{Frac}(\mathscr{O}_{X,x})$ is the fraction corresponding to $r$ under the isomorphism $K(X) \stackrel{\sim}{\to} \mathrm{Frac}(\mathscr{O}_{X,x})$.  (I believe I remember reading about such an isomorphism in Liu's book, but I don't have it with me at the moment so I can't be sure.) I am under the impression that the terms ""rational function"" and ""meromorphic function"" are used more or less interchangeably (I guess the former is more popular in modern literature).  Also I believe that Grothendieck's definition is a generalization of the second one, but I can't quite understand why.  Further I would like to understand how the definitions of the divisor associated to a rational function coincide.","['algebraic-geometry', 'schemes']"
282686,What are these two topologies?,"I'm a beginner in Topology. Today, this came up my mind: (1) For a set $X$, choose a subset $A\subseteq X$. Let $S\subseteq X$ be a closed set if and only if $(A\subseteq S)\vee (S=\emptyset)$. This is a topology on $X$. (2) For a set $X$, let $S\subseteq X$ be a closed set if and only if $(S $ is finite$)\vee (S = X)$. This is another topology on $X$. The questions are: [1] What are these two topologies called? [2] Do they have significance? Are they used somewhere? First question on stackexchange. Thanks!",['general-topology']
282695,In how many ways can 3 distinct teams of 11 players be formed with 33 men?,"Problem: In how many ways can 3 distinct  teams of 11 players be formed with 33 men?
Note: there are 33 distinct men. The problem is similar to this one: How many distinct football teams of 11 players can be formed with 33 men? Fist, I thought the answer was:
$$
\binom{33}{11} \times \binom{22}{11} \times \binom{11}{11}
$$ But there are clearly a lot of solutions overlapping.","['binomial-coefficients', 'combinatorics']"
282714,"Upper semi continuous, lower semi continuous","which of the followings are true? $X$ be a topological space,  $f_n:X\rightarrow \mathbb{R}$ is sequence of lower semi continuous functions then the $\sup\{f_n\}=f$ is also lower semi continuous. every continuous real valued function on $X$ is lower semi continuous. A real valued function on $X$ is continuous iff it is both USC and LSC. I read in my measure theory course and recall that $3$ and $1$ is true though I can not remember the proofs now, but could any one just give me hint how to handle $2$? Thank you.","['semicontinuous-functions', 'real-analysis']"
282717,number of 1-to-1 linear functions on vectorspaces over finite fields,"This is not a homework. I just ask this question myself and thought it would be easy to figure out. But I did not get the solution. Let $\mathbb{F}$ be a finite field with $|\mathbb{F}|=q$. Consider the $\mathbb{F}$-vectorspaces $V_1=\mathbb{F}^n,V_2=\mathbb{F}^m$ with dimensions $n<m$. How many injective, surjective and bijectiv linear functions $f\colon \mathbb{F}^n \to \mathbb{F}^m$ exists? My approach is:
We have any basis $b_1,\ldots,b_n$ of $V_1$ and $c_1,\ldots,c_m$ of $V_2$. It clear that we only have to treat the function on this basis and there cannot be any bijective linear functions since $n<m$. Counting the functions must be similar to count the possibilities to do a injective map from $b_1,\ldots,b_n$ of $V_1$ to $c_1,\ldots,c_m$ of $V_2$. How do I get the number of injective functions?","['vector-spaces', 'finite-fields', 'linear-algebra', 'combinatorics']"
282722,Generalization of a product measure,"Let $(X,\mathfrak B(X))$ and $(Y,\mathfrak B(Y))$ be measurable spaces and further let $\mu$ be a measure on $\mathfrak B(X)$ and let $K$ be a kernel, i.e. for any $x\in X$ we have $K_x$ is a measure on $\mathfrak B(Y)$ and the map $x\mapsto K_x(B)$ is $\mathfrak B(X)$-measurable for any $B\in \mathfrak B(Y)$. Let us further assume that $\mu$ is finite and measures $K_x$ are uniformly bounded. Then there exists a unique measure $P$ on $\mathfrak B(X)\otimes \mathfrak B(Y)$ such that
$$
  P(A\times B) = \int_AK_x(B)\mu(\mathrm dx)
$$
for any measurable rectangle $A\times B$. Thus, $P$ can be considered as a certain product $\mu\otimes_{?}K$ and in case $K_x\equiv\nu$ we have $P = \mu\otimes \nu$ is just a product measure. We know that product measures are not enough to describe all possible measure over the product space, whereas the construction above is thanks to the disintegration theorems. I wonder what are the nice sources for the properties of the construction $\mu\otimes_{?}K$ - e.g. does it have its own name.","['stochastic-processes', 'notation', 'measure-theory', 'probability-theory', 'reference-request']"
282740,Combinatorics Problem: Box Riddle,"A huge group of people live a bizarre box based existence. Every day, everyone changes the box that they're in, and every day they share their box with exactly one person, and never share a box with the same person twice. One of the people of the boxes gets sick. The illness is spread by co-box-itation. What is the minimum number of people who are ill on day n? Additional information (not originally included in problem): Potentially relevant OEIS sequence: http://oeis.org/A007843","['logic', 'combinatorics']"
282746,Essential selfadjointness preserved under unitarily transfomration?,"I am wondering if essential selfadjointness of an operator in a Hilbert space is preserved under unitarily transformations. In other terms: let $H,H'$ be two isomorphic Hilbert spaces, with an isomorphism between the two denoted by $U$.
Let $A$ be an operator in $H$ with domain $D$ and consider the operator
$A':= U A U^{-1}$ in $H'$ with domain $D':= U(D)$. Is it true that $A$ is essentially selfadjoint if and only if $A'$ is? (Essential selfadjoitness means that the operator is symmetric and its closure is selfadjoint. Equivalently the operator is symmetric and has a unique selfadjoint extension.)","['quantum-mechanics', 'hilbert-spaces', 'functional-analysis']"
282747,Characterization of Sequences with Integral Binomial Coefficients,"For any sequence of positive integers $\{ a_i \}_{i \ge 1}$ we can define the generalized binomial coefficients $\binom{n}{k}_{a}$ as follows: 
$$m!_a = a_1 a_2 \cdots a_m, \binom{n}{k}_a = \frac{n!_a}{k!_a (n-k)!_a}$$ When $\{ a_i \}$ is a strong divisibility sequence, i.e. $\gcd (a_n, a_m) = a_{\gcd(n,m)}$, it can be shown that those coefficients are always integral, see this paper by Ward . The problem is that this is only a sufficient condition, and I am looking for a neccesary condition. Why is it only sufficient? Because it proves a stronger reuslt, namely that $\binom{n+1}{k+1}_a$ can be written as a linear integral combination of $\binom{n}{k+1}_a, \binom{n}{k}_a$. There are examples that don't satisfy the conditions but give integral coefficients, for example: $a_n = \binom{n+c}{c+1}$ for $c \ge 1$, see this thesis . Note that $(a_2, a_3) = (c+2, \frac{(c+3)(c+2)}{2})\ge \frac{c+2}{2} > 1$, yet $a_{(2,3)}=a_1 = 1$. What have I come up with? If the binomial coefficients are integral, we have: $a_{n+1} \cdot \cdots \cdot a_{n+k}$ is divisible by $a_{1} \cdots a_{k}$. For any prime $p$ define the sequence $\{ b_{n,p} = v_p(a_n) \}_{n \ge 1}$. We have the condition that any sum of $k$ consecutive integers in the sequence is at least as large as the sum of the first $k$ integers in the sequence. We also have the condition that for any $n$, $v_p(a_n) \neq 0$ for finitely many primes $p$. What do I want? A full compact characterization of sequences giving rise to integral binomial coefficients. Examples of interesting such sequences which are not strong divisibility sequences.","['binomial-coefficients', 'combinatorics']"
282748,"If $X^n$ is a diagonal matrix with distinct eigenvalues, then is $X$ also a diagonal matrix with distinct eigenvalues?","Assume that there exists an invertible matrix $P$ such that $P^{-1}X^nP$ is a diagonal matrix with distinct eigenvalues, then can I say that $P^{-1}XP$ is also a diagonal matrix with distinct eigenvalues? If so, how do I prove it?","['matrices', 'linear-algebra']"
282756,set of all symmetric non-negative definite matrices are closed or not,Can anyone tell me please that set of all symmetric non-negative definite matrices are closed or not in $\mathbb{M}_n(\mathbb{R})$ with usual topology,"['general-topology', 'matrices']"
282757,Square roots of integers and cyclotomic fields,"For every $ N \in \mathbb Z$ there exists an integer $n$ such that $ \sqrt N \in \mathbb Q(\zeta_n)$. I am struggling where to start this question, please suggest me few hints.","['galois-theory', 'number-theory']"
282818,How I find limit of $P_n$,"Let $a_1=1$ and $a_n=n(a_{n-1}+1)$ for $n=2,3,\dots$. Define $$P_n=\left(1+\frac{1}{a_1}\right)\left(1+\frac{1}{a_2}\right)\dots\left(1+\frac{1}{a_n}\right)$$Find $$\lim_{n \to \infty}P_n$$ Trial: $$1+\frac{1}{a_n}=1+\frac{1}{n(a_{n-1}+1)}\;.$$
But I can't simplyfy.Please help.",['sequences-and-series']
282827,Does a red/blue coloring of the infinite subsets of $\mathbb{N}$ necessarily give an infinite monochromatic $M\subset \mathbb{N}$?,"The infinite Ramsey theorem states that for any $n$, if all the subsets of $\mathbb{N}$ of size $n$ are colored red/blue, then there is an infinite $M$ all of whose subsets of size $n$ are monochromatic. My question is whether there is an analogue if the infinite subsets of $\mathbb{N}$ are coloured red/blue--does this imply that there is an infinite subset $M$ all of whose infinite subsets are monochromatic?","['ramsey-theory', 'combinatorics']"
282835,Show that a function $f(x)$ maps to a set of points.Fixed point theorem,Show that the function $f(x)=\frac{1+x^2}{2}$ maps the set of points $0\leqslant   x\leqslant  1$ into itself and has a fixed point in that interval even though there does not exists a positive constant $K<1$ such that $\vert f(a)-f(b) \vert \leqslant   K \vert b-a\vert$.,"['fixed-point-theorems', 'functions']"
282865,Can it be proven in $\sf ZF^{\neg\infty}$ that the sets $x_n=\{x_{n+1}\}$ do not exist?,"This question is my attempt to hone in on the problem of proving the strong form of the Axiom of Regularity $A\neq\emptyset\to\exists x\in A(x\cap A=\emptyset)$ (where $A$ is an arbitrary class) from the weak form $\forall a\!:a\neq\emptyset\to\exists x\in a(x\cap a=\emptyset)$. In ZF with the negation of the Axiom of Infinity (which I abbreviate as $\sf ZF^{\neg\infty}$), all sets have finitely many elements, and this allows us to prove that sets like $x=\{\{\{x\}\}\}$ do not exist, but I don't see how to prove that the infinite family $x_n=\{x_{n+1}\}$ does not exist, since I can't collect all the elements together and use regularity on that, since the resulting class is (provably) not a set. My ultimate goal is to prove that every set has a transitive closure (that is a set), but these sets will foil my attempt if I can't prove their non-existence. Conversely, supposing I couldn't prove this, this would mean that $\infty$ is required for the proof, so could I turn it around and prove, given that every set has a transitive closure, that $\omega\in V$?",['elementary-set-theory']
282875,How many length n binary numbers have no consecutive zeroes ?Why we get a Fibonacci pattern? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: How many $N$ digits binary numbers can be formed where $0$ is not repeated I am really embarrassed to ask this as it seems like a textbook question.But it is not, and I am at a complete loss how to get a grip on it.It is mentioned in the first lecture of a 24 lecture series on Discrete Mathematics by the popular Mr.Arthur Benjamin(Discrete Mathematics-The Great Courses),which I am following.He only fleetingly mentions that we use combinatorics to solve this and starting with n=1 (1 bit number), the answer follows the Fibonacci pattern 2,3,5,8......So please answer this for me lest I get discouraged from the start of the subject itself. i)If we are asked to find the number of n-length binary numbers with no consecutive zeroes,then how do we go about it?I have a fair idea about combinatorics,binary coefficients,permutations, yet I just can't figure how to start.So what is the logic we use? ii)Why does it follow a Fibonacci pattern for n,n+1,n+2 and so on?This further bewilders me.Why on earth is a Fibonacci pattern generated?There must be an explanation... Your clear and easy-to-understand answers will go a long way in motivating me further into the subject.Thanks!","['sequences-and-series', 'combinatorics']"
282879,How many ways can one paint the edges of a Petersen graph black or white?,"How many ways can one paint the edges of a Petersen graph black or white? I know that the symmetrygroup of the Petersen graph is $
[S5][1]$. Furthermore this this seems like a case where I should use Burnside's lemma. I'm sorry if the following is too verbose or uses non standard notation; I haven't been acquainted with graph theory. S5 has 7 conjugacy classes, namely those with cycle types: (1,1,1,1,1),(1,1,1,2),(2,2,1),(2,3),(1,1,1,3),(4,1),(5). S5 has 15 edges so the identity (1,1,1,1,1) would leave $2^{15}$ different colorings fixed. The n-cycle (5) is a rotation of the whole graph and as such would leave $2^3$ colorings fixed. The ""outside"" could be white or black, the connecting edges and the ""inside"" edges could both be either white or black. Rotation around one ""connecting"" edge involves the (2,2,1) cycles. I won't tire you with the details but I found $2^9$ colorings. From here I'm stuck however, I can't find any more symmetries than these. How do I find the colorings left fixed by the other conjugacy classes?","['graph-theory', 'group-theory']"
282889,A function with a non-negative upper derivative must be increasing?,"I am trying to show that if $f$ is continuous on the interval $[a,b]$ and its upper derivative $\overline{D}f$ is such that $ \overline{D}f \geq 0$ on $(a,b)$, then $f$ is increasing on the entire interval. Here $\overline{D}f$ is defined by
$$
\overline{D}f(x) = \lim\limits_{h \to 0} \sup\limits_{h, 0 < |t| \leq h} \frac{f(x+t) - f(x)}{t} 
$$ I am not sure where to begin, though. Letting $x,y \in [a,b]$ be such that $x \leq y$, suppose for contradiction that $f(x) > f(y)$, then continuity of $f$ means that there is some neighbourhood of $y$ such that $f$ takes on values strictly less than $f(x)$ on this neighbourhood. Now I think I would like to use this neighbourhood to argue that the upper derivative at $y$ is then negative, but I cannot see how to complete this argument. Any help is appreciated! :)","['examples-counterexamples', 'monotone-functions', 'derivatives', 'real-analysis']"
282893,Solve Differential Equation,"Solve differential equation 
$$y^2y'^2+2axyy'+(1-a)y^2+ax^2+(a-1)b=0,$$ where $y=y(x)$ and $a,b \in \mathbb{R}.$ My work : Let $y^2=z, \,\,\,z=z(x).$ Then $2yy'=z'$ and our differential equation become 
$$\frac{z'^2}{4}+axz'+(1-a)z+ax^2+(a-1)b=0.$$ But, what now? Thanks.",['ordinary-differential-equations']
282898,Integral help here please?,"I have to solve this $$\int \frac{dx}{(x+1)\sqrt{x^2+2x}}$$ First  make the substitution $u=x+1$ and get $$\int \frac{ds}{u\sqrt{u^2-1}}$$ Next I substitute $s=\sqrt{u^2-1}$  and I get $ds=u\,du/\sqrt{u^2-1}$. I have integral of $1/s^2+1\dots$ I replace for $s$ and I get the integral as $$\arctan\sqrt{u^2-1} \, .$$ The answer on my textbook is $-\arcsin[1/(x+1)]$","['calculus', 'integration']"
282959,"How to prove that $GL(n,\mathbb R)$ is not connected subset and open subset of$M_n (\mathbb{R})$","let $n\gt1$  be a fixed natural number, $S:=${$A $: $M_n (\mathbb{R})$ be all real matrix,define this meter for all $A=[a_{ij}]$ $B=[b_{ij}]$ $d(A,B)$:=max{|$a_{ij}-b_{ij}$|:i,j=1,2,2...,n}
and $GL(n,\mathbb R)$ is set of all $n\times n$ non singular matrix how to prove that $GL(n,\mathbb R)$ is  not connected and open subset of $S$ ? thanks in advance","['linear-algebra', 'analysis']"
282966,Trace and Norm of a separable extension.,"If $L | K$ is a separable extension and $\sigma : L \rightarrow \bar K$ varies
over the different $K$-embeddings of $L$ into an algebraic closure $\bar K$ of $K$, then
how to prove that 
        $$f_x(t) = \Pi (t - \sigma(x))?$$ $f_x(t)$ is the characteristic polynomial of the linear transformation $T_x:L \rightarrow L$ where $T_x(a)=xa$","['galois-theory', 'algebraic-number-theory', 'abstract-algebra', 'field-theory']"
282970,Proof of the sine rule,"So I made my first attempt at a proof. I think it turned out well. Maybe not. But I was wondering if someone could take a look at it and tell me what they think. I'd be glad to hear some criticism on it. So here it goes: The Sine Rule is as follows: $$\frac{\sin(\alpha)}{a}=\frac{\sin(\beta)}{b}=\frac{\sin(\gamma)}{c}$$ $\mathbf{Proof}$: We are given an acute triangle $\triangle OPQ$ with sides $a$,$b$, and $c$. Opposite of the sides are the angles $\alpha$,$\beta$, and $\gamma$, respectively. We will divide $\triangle OPQ$ with $2$ line segments, $h_1$ and $h_2$. The line segment $h_1$ will have an endpoint at angle $\gamma$ and extend to side $c$ to make $h_1$ perpendicular to side $c$. The line segment $h_2$ will have an endpoint at angle $\alpha$ and will extend to side $a$ to make $h_2$ perpendicular to side $a$. We know that $\sin(\alpha)=\frac{h_1}{b}$ and $\sin(\beta)=\frac{h_1}{a}$. We can deduce that $h_1=a\sin(\beta)$ and $h_1=b\sin(\alpha)$. From these two equations, we can produce the following result: $$\begin{align}a\sin(\beta)=b\sin(\alpha)\\ \frac{\sin(\beta)}{b}=\frac{\sin(\alpha)}{a}\end{align}$$ We now turn our attention to see that $\sin(\gamma)=\frac{h_2}{b}$ and $\sin(\beta)=\frac{h_2}{c}$. As before we can deduce that $h_2=b\sin(\gamma)$ and $h_2=c\sin(\beta)$. From this system of equations we can simplify it in the following way: $$\begin{align}b\sin(\gamma)=c\sin(\beta)\\ \frac{\sin(\gamma)}{c}=\frac{\sin(\beta)}{b}\end{align}$$ It follows that if $\frac{\sin(\alpha)}{a}=\frac{\sin(\beta)}{b}$, and $\frac{\sin(\beta)}{b}=\frac{\sin(\gamma)}{c}$, then $\frac{\sin(\alpha)}{a}=\frac{\sin(\gamma)}{c}$. Thus proving that $$\frac{\sin(\alpha)}{a}=\frac{\sin(\beta)}{b}=\frac{\sin(\gamma)}{c}$$ Which concludes my proof. I know it's a pretty basic concept learned in high school trig but I just wanted to start off  on something easy. ANY input would be great.","['geometry', 'trigonometry', 'proof-writing']"
282973,Derivative of $\cos nx$,How to calculate derivative of $ \cos ax$? Do I need any formula for $ \cos ax$? The answer in my exercise book says it is $-a \sin ax$. But I don't know how to come to this result. Could you maybe explain it to me?,"['trigonometry', 'derivatives']"
282982,Improper integral of $\frac{x}{e^{x}+1}$,"The improper integral of $\frac{x}{e^x-1}$ (along the positive real line) comes up in a lot of places, you can even invoke the Riemann-zeta and Gamma functions to solve it nicely. However, I just decided to look at $\int_0^\infty \frac{x}{e^x+1}dx$, to see if it would also be interesting. It has a nice solution, that I have no satisfying way to get (taking a value of dilogarithm). I'm wondering if anyone has a slick way to do it. Residues? Some slick series argument?","['statistics', 'calculus', 'real-analysis']"
282984,Fourier transform of Cauchy principal value,"I try to understand the direct computation of the Fourier transform of the distribution `Cauchy principal value' $p.v. \frac{1}{x}$ . I don't understand the following change of order of integration: $$
p.v.\int_\mathbb{R} \frac{1}{x}\Bigg(\int_\mathbb{R} e^{-kix}\varphi(k)dk\Bigg)dx=\int_\mathbb{R} \varphi(k)\Bigg(p.v.\int_\mathbb{R} \frac{e^{-kix}}{x}dx\Bigg)dk
$$ where $\varphi$ is a Schwartz function and where p.v. denotes the principal value of the integral. Why and how justify rigourously this change of order of integration?","['improper-integrals', 'distribution-theory', 'fourier-analysis', 'integration']"
282996,What is the cardinality of $\Bbb{N^N}$?,What is the cardinality of $\Bbb{N^N}$? my answer: $|\mathbb{R}|$ $=$$|2^\mathbb{N}|$ $\leqslant$ $|\mathbb{N}^\mathbb{N}|$ $\leqslant$ $|\mathbb{R}^\mathbb{N}|$ $=$ $|(2^\mathbb{N})^\mathbb{N}|$ $=$ $|2^{\mathbb{N}\times\ \mathbb{N}}|$ $=$ $|2^\mathbb{N}|$ $=$ $|\mathbb{R}|$ In the end $|\mathbb{N}^\mathbb{N}|$ $=$ $|\mathbb{R}|$ Is that okay?,"['cardinals', 'elementary-set-theory']"
283006,What is a sampling density? Why is the sampling density proportional to $N^{1/p}$?,"I'm reading a book named The Elements of Statistical Learning by Hastie, in section 2.5, Local Methods in High Dimensions , it says that the sampling density is proportional to $N^{\frac{1}{p}}$, where $p$ is the dimension of the input space and $N$ is the sample size. I'm confused, what does it mean by sampling density ? I do know, intuitively, as the dimension becomes larger, the sample becomes more sparse. But I don't understand exactly where does $N^{\frac{1}{p}}$ come from.","['statistics', 'machine-learning', 'probability-theory']"
283014,A subgroup such that every left coset is contained in a right coset.,"Let $G$ be any group, and $H \leq G$ a subgroup. Suppose that for each $x \in G$, there exists a $y \in G$ such that $xH \subseteq Hy$. In other words, every left coset of $H$ is contained inside some right coset of $H$. Question : what can we say about $H$? In particular, does this imply that $H$ is normal? I know that if $G$ is finite, then $H$ must be normal, because then $xH \subseteq Hy$ implies $xH = Hy$, since $|xH| = |Hy|$.","['group-theory', 'abstract-algebra']"
283017,The limit of a convergent Gaussian random variable sequence is still a Gaussian random variable,"I'm trying to prove this conclusion but have some problems with one of the steps. Assume $X_1,\ldots,X_n,\ldots$ is a sequence of Gaussian random variables, converging almost surely to $X$, prove that $X$ is Gaussian. We use characteristics function here. Since $|\phi_{X_n}(t)|\leq 1$, by dominated convergent theorem, we have for any $t$ $$
\lim_{n\rightarrow\infty}e^{it\mu_n-t^2\sigma_n^2/2}=\lim_{n\rightarrow \infty}\phi_{X_n}(t) = \lim_{n\rightarrow \infty}\mathbb{E}\left[e^{itX_n}\right] = \mathbb{E}\left[e^{itX}\right] = \phi_X(t)
$$ this is the step that I cannot figure out : $e^{it\mu_n-t^2\sigma_n^2/2}$ converges for any $t$ if and only if $\mu_n$ and $\sigma_n$ converges. Let $\mu=\lim_n \mu_n$, and $\sigma=\lim_n\sigma_n$, then $\phi_X(t)=e^{it\mu-t^2\sigma^2/2}$, which proves that $X$ is a Gaussian random variable. Why can we get that $\mu_n$ and $\sigma_n$ converge? This looks intuitive for me, but I cannot make a rigorous prove.",['probability-theory']
283021,"Legendre polynomials, Laguerre polynomials: Basic concept","I am asking a simple conceptual question. I saw in many Mathematics and Mathematical physics text books that the Legendre polynomials and Laguerre polynomials ""falling from the sky""! I mean, I didn't get the concept behind and how those polynomials derived. The textbooks rather says a second order differential equation and says the solution is in this form. I wish to know why people assuming this kind of differential equations and also what is the physical concept behind. It would be rather interesting to know how basically the solutions for those differential equations derived. Or please tell me a text book/reference where I can find those concepts Thanks a lot.","['ordinary-differential-equations', 'orthogonal-polynomials']"
283035,Is the intersection of two countably generated $\sigma$-algebras countably generated?,"Let $\mathcal{A}$ and $\mathcal{B}$ be two countably generated $\sigma$-algebras on the set $X$. Is the $\sigma$-algebra $\mathcal{A} \cap \mathcal{B}$ necessarily countably generated? I suspect that the answer is negative since all attempts to prove it failed and there seems to be no apparent reason for the statement to be true. On the other hand, I was unable to come up with a counterexample. If it helps to obtain a positive answer, I don't mind assuming that singletons are measurable. Thanks!",['measure-theory']
283038,What's an example of a non-split extension of Lie algebras?,"Is there a Lie Algebra $\mathfrak g$ so that the extension $$0\xrightarrow{}\mathfrak h\xrightarrow{}\mathfrak g\xrightarrow{}\mathfrak q\xrightarrow{}0$$ does not split, i.e. $\mathfrak g$ is not a semi-direct product of $\mathfrak h$ and $\mathfrak q$ ?
As I understand it, $\mathfrak q$ should not be identifiable with a subalgebra of $\mathfrak g$ , right? Since $\mathfrak h$ is already an ideal in $\mathfrak g$ as the kernel.","['exact-sequence', 'lie-algebras', 'abstract-algebra']"
283047,Compute $\lim_{n\to\infty}\frac{1}{n^3}\sum_{1\le i<j<k\le n} \sin\left(\frac{i+j+k}{n}\right)$,Compute $$\lim_{n\to\infty}\frac{1}{n^3}\sum_{1\le i<j<k\le n} \sin\left(\frac{i+j+k}{n}\right)$$,"['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
283062,Hartshorne Lemma I.6.5; Why is $\mathfrak{m}_R\cap B\neq 0$?,"I've been going back through some theorems in Hartshorne's Algebraic Geometry, trying to really understand the details. I'm looking at Lemma I.6.5, which states (for those who don't have the book): Let $K$ be a finitely generated field extension of transcendence degree one over $k$ ($k$ algebraically closed), and let $x \in K$. Then the set of discrete valuation rings of $K/k$ not containing $x$ is finite. I'm following Hartshorne's proof, and I'm at the point where $y\in K$ is transcendental over $k$, and $B$, defined to be the integral closure of $k[y]$ in $K$, is a Dedekind domain and finitely generated as a $k$-algebra. He then supposes that $k[y]$ is contained in a DVR $R$ of $K/k$, which forces $B\subseteq R$ since $R$ is integrally closed in $K$. The next step is where I'm stuck: If $\mathfrak{m}_R$ is the maximal ideal of $R$ then $\mathfrak{n}:=B\cap\mathfrak{m}_R$ is a maximal ideal of $B$. Part of this is obvious: that is that $\mathfrak{n}$ is a prime ideal of $B$. As $B$ is a Dedekind domain, it suffices to show that $\mathfrak{n}$ is nonzero. I feel like there must be an obvious reason why this is the case, but I'm completely drawing a blank. I'd greatly appreciate it if someone could help me out here.","['commutative-algebra', 'algebraic-geometry']"
283073,Cauchy-Schwarz for metrics with arbitrary signatures,"When the norm of a vector is always greater than or equal to zero, the Cauchy-Schwarz inequality holds, but what if we look at a metric with an arbitrary signature? Then the inner product of a vector with itself could be negative. Is there any Cauchy-Schwarz inequality for an arbitrary metric? I suspect it would look something like this: $$g_{ij}^2\leq |g_{ii}g_{jj}|,$$ but I am not sure if that is necessarily the case (let alone how to go about proving it). Here, $g$ is the matrix representation of the metric tensor.","['inner-products', 'normed-spaces', 'linear-algebra', 'general-relativity', 'metric-spaces']"
283091,Proving an integer is non-negative by showing there is a vector space with it as its dimension.,"The other day I attended a lecture on methods to show whether or not a number is an integer. We were given examples of showing it is the number of ways to count something, and to show there exist groups and subgroups and then apply Lagrange's theorem. But it was stated that from time to time it crops up where in order to prove that an integer is non-negative, one must show there exists a vector space with it as the dimension, hence proving it can't be negative. I really like the sound of this, but no example was given. Could someone give a problem and solution demonstrating this method of proof? Or at least allude to one.","['vector-spaces', 'reference-request', 'combinatorics']"
283111,"What is the limit of $\frac{e^{6x}-2e^{3x} + 1}{x^2}$, as $x \rightarrow 0$?","I am to calculate $\frac{e^{6x}-2e^{3x} + 1}{x^2}$ when $x$ goes towards $0$. I find that $$\frac{e^{6x}-2e^{3x} + 1}{x^2} = \frac{(e^{3x}-1)^2}{x^2} =  \left(\frac{e^{3x}-1}{x}\right)^2$$ $$\left(\frac{e^{3x}-1}{x}\right)^2 \rightarrow 1^2$$ but according to the answer in the book I am incorrect. It agrees with me halfway through, but ends with $$\frac{(e^{3x}-1)^2}{x^2} =  9\left(\frac{e^{3x}-1}{3x}\right)^2 \rightarrow 9 \times 1^2$$ While this is correct mathematically, why would it be $3$ and $9$ instead of for example $4$ and $16$ or, as in my case, $1$ and $1$? I don't see the relevance of adding the $3$ and $3^2$.","['exponential-function', 'calculus', 'limits']"
283123,Structure of the solution set of a 2nd order ODE,"Let $V \in C^1(\mathbb{R}^d)$, and let $S$ denote the solution set for the problem
$$
\ddot{x}+\nabla V(x)=0,\quad x(T)-x(0)=0=\dot{x}(T)- \dot{x}(0).
$$
When $d=1, T=2\pi$, and $V(x)=\frac12|x|^2$ it is clear that
$S$ is the two-dimensional vector space 
$$
\{\alpha\cos+\beta\sin:\ \alpha,\beta\in \mathbb{R}\} \simeq \mathbb{R}^2.
$$
For general $V$ (when the ODE is non-linear), does $S$ have some kind of manifold structure?",['ordinary-differential-equations']
283128,Property holds everywhere except on some subset of arbitrarily small measure is equivalent to holding a.e.?,"Suppose  a property $P$ may or may not hold on a measurable subset of a measure space with measure $\mu$.
Is for every $ε > 0$, there exists a measurable subset $B$ such that $μ(B) < ε$, and $P$ holds on $B^c$. equivalent to there exists a measurable subset $B$ with $μ(B) =0$, and $P$ holds on $B^c$? For example, Egorov's theorem say that if  $(f_n)$ converges $μ$-almost everywhere on $A$ to a limit function $f$, where $A$ is a measurable subset of finite $μ$-measure, then for every $ε > 0$, there exists a measurable subset $B$ of $A$  such that $μ(B) < ε$, and $(f_n)$ converges to $f$ uniformly on the relative complement $A \setminus B$. Thanks!","['measure-theory', 'real-analysis']"
283135,Hardy space question,Let $T$ be the unit circle.  Let $\phi\in C(T)$ and let $\psi$ be a function in $L^2(T)$ such that $\phi+i\psi\in H^2$.  Assume both $\psi$ and $\phi$ are real-valued.  Show $e^{\phi+i\psi}\in H^\infty$. I saw this in a paper by Sarason but it is not proved there.  I tried proving it by writing $e^{\phi+i\psi}=\sum_{n=0}^\infty \frac{(\phi+i\psi)^n }{n!}$ but this I do not think will help since $H^2$ is not an algebra.  Can someone give me a hint on how to prove this?  I mostly need help in showing $\frac{1}{2\pi}\int_0^{2\pi} \left(e^{\phi(e^{i\theta})+i\psi(e^{i\theta})}\right)\chi_n(e^{i\theta})d\theta=0$ for $n>0$.,"['hardy-spaces', 'complex-analysis', 'analysis']"
283157,Uniform Continuity and partial sums equation proof,"Given $f$, a uniformly continuous function defined on the interval $[0,1]$, I need to prove that 
$$\lim_{n\rightarrow \infty} 
\frac{1}{2^n} \sum_{k=1}^n (-1)^k \binom{n}{k} f(k/n)=0.$$ I have tried tackling this exercise from a couple of angles but I seem to lack the intuition and technical skills to crack this egg open, so I am at your mercy.","['sequences-and-series', 'calculus', 'continuity', 'real-analysis', 'limits']"
283159,Evaluating the sum of geometric series [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Value of $\sum\limits_n x^n$ I'm trying to understand how to evaluate the following series: 
$$
\sum_{n=0}^\infty {\frac{18}{3^n}}.
$$ I tried following this Wikipedia Article without much success. Mathematica outputs 27 for the sum. If someone would be kind enough to show me some light or give me an explanation I would be grateful.","['sequences-and-series', 'calculus', 'limits']"
283173,number of multiples of 4 that are multiples of 4 even if you permute their digits,"How many 4 digit numbers are multiples of 4 no matter how you permute them? 
(base 10)","['elementary-number-theory', 'combinatorics']"
283178,Arc sums for a circle of $k$ positive integers whose total sum is $n$,"This problem got me thinking about the following more general scenario: Suppose you have $k$ positive integers with total sum $n$, and you arrange them in a circle. Given such an arrangement, you could look at different sums of consecutively placed positive integers along ""arcs"" of this circle. Furthermore, you could ask which numbers must always appear in an arc for a given $k$ and $n$, i.e., regardless of which $k$ positive integers summing to $n$ are chosen and how they are arranged around the circle. Let $A_{k, n}$ be the set of numbers that necessarily appear in some arc for every circular arrangement of $k$ positive integers whose sum is $n$. (Of course, this set is nonempty iff $k \leq n$.) Trivially, $n \in A_{k, n}$. (Proof: take the arc that corresponds to the entire circle.) The linked problem above demonstrates that $200 \in A_{101, 300}$ using the pigeonhole principle. Another obvious fact: given a positive integer $m < n$ with $m \in A_{k, n}$, then $n-m \in A_{k,n}$ as well. For the linked problem above, this means that $300 - 200 = 100 \in A_{101, 300}$ too. Of course, this latter fact is proven by taking complement arcs. Questions: $1.$ Has this general scenario already been studied under some other name? $2.$ Is there an easy way to determine the elements of $A_{k,n}$ in general? $3.$ If the answers to $1$ and $2$ are both no, what can you show for some special cases? As a final, very simple example: $A_{n,n} = \{1, \ldots, n\}$. (Ideally, if you are going to answer $3$, it would be with a less trivial proposition!)","['pigeonhole-principle', 'recreational-mathematics', 'problem-solving', 'combinatorics']"
283181,A search for integers which can be written as a sum of two squares in multiple ways,"As part of a number theory hobby project, I'm looking for a computational way to enumerate all integers $n$ which can be written as a sum of two integer squares in three or more ways.  The range of $n$ will likely get quite large ( up to $\approx 2^{64}$) so I'm looking for methods that let me specify a search range for $n$, say $11\cdot10^{13}$ to $12\cdot10^{14}$, and return any values such as $$1193162282546 = 1043815^2+321889^2 = 1066211^2+237395^2 = 1076911^2+182825^2$$ My first thought of solving this problem is rather brute force: Enumerating $every$ sum of two squares within a range $n_0..n_1$ by iterating over
$n=a^2+b^2$ in a double loop  over $1\le a \le\sqrt{n_1-1} $ and $\sqrt{n_0^2-a^2}\le b \le \sqrt{n_1^2-a^2}$ , then sorting the list and scanning it for duplicate values of 3 or more values.
I think this will work, but it may be very inefficient, with the vast majority of the computation thrown out. The puzzle for you: Is there a better computational method?","['computational-mathematics', 'number-theory']"
283186,"If $\int_a^b f(x) \ \mathrm{d}x = \int_a^b g(x) \ \mathrm{d}x$ then $\exists x \in [a,b]$ with $f(x) = g(x).$","I am trying to prove the following: Take $f, g:[a,b] \to \mathbb{R}$ such that $f$ and $g$ are continuous. If
$$\int_a^b f(x) \ \mathrm{d}x = \int_a^b g(x) \ \mathrm{d}x,$$ then there exists some $c \in [a,b]$ such that $f(c) = g(c).$ Here's my current proof. I'd welcome any feedback regarding correctness and clarity. Current Proof Assume that there exists no such $c$. There are then three possibilities. First, it is possible that $f(x) > g(x)$ $\forall$ $x \in [a,b]$. However, this cannot be, since then we would have
$$\int_a^b f(x) \ \mathrm{d}x > \int_a^b g(x) \ \mathrm{d}.x$$ Similarly, we cannot have $g(x) > f(x)$ $\forall$ $x \in [a,b]$, since then
$$\int_a^b f(x) \ \mathrm{d}x < \int_a^b g(x) \ \mathrm{d}x.$$
Thus, there exists some $x \in [a,b]$ such that $f(x) > g(x)$ and some $y \neq x$ such that $g(y) > f(y).$ Assume without loss of generality that $x < y.$ Consider a new function $h:[a,b] \to \mathbb{R}$ defined by
$$h(x) = f(x) - g(x).$$
Clearly, $h$ is continuous, as the difference of two continuous functions. From the above, we have that $h(x) > 0$ and $h(y) < 0.$ Apply the Intermediate Value Theorem to $h$ on the interval $(x,y).$ Thus, there exists some $c \in (x, y)$ such that $f(c) = 0$. Since $(x, y) \subset [a, b]$, we have found an element of $[a,b]$ such that $h(c) = 0 \implies f(x) = g(x).$","['integration', 'real-analysis', 'analysis']"
283203,Understanding a definition of radial,"A space $X$ is called radial if, for any $A \subset X$ and any $x \in cl(A)$, there is a transfinite sequence $s=\{a_\alpha: \alpha \in \kappa\} \subset A$ which converges to $x$. What's meaning of ""transfinite sequence"" here? Added: If I may ask more, What is difference between redial space and Frechet space ? It seems that they are same.","['general-topology', 'definition']"
283205,Show that satisfaction of Cauchy-Riemann Equations in polar coordinates implies analyticity,"Suppose that $U(r,\theta),V(r, \theta)$ are continuously differentiable functions on some polar rectangle $R = \{(r, \theta) \colon r \in (a,b), \theta \in (\theta_1, \theta_2) \} \subseteq \mathbb{R}^2.$ Furthermore, assume that $U$ and $V$ satisfy the polar Cauchy-Riemann equations in $R$: $$rU_r = V_\theta, U_\theta = -rV_r.$$ If we now view $R$ as a subset of $\mathbb{C}$ rather than $\mathbb{R}^2$, we can define the function $f : R \to \mathbb{C}$ by $f(re^{i\theta}) = U(r, \theta) + iV(r,\theta).$ Prove that $f$ is analytic on $R$. I am linking this problem to a previous post: Proof of Cauchy Riemann Equations in Polar Coordinates . I believe I am asking a similar question. However, to my best knowledge, the answers to the linked post actually establish the converse of my statement above. That is, they show that analyticity of $f$ implies that these polar Cauchy-Riemann equations are satisfied. Here's what I have so far: I do know that a function $f(x + iy) = U(x,y) + iV(x,y)$ is analytic when its real and imaginary parts are continuously differentiable and satisfy the rectangular Cauchy-Riemann equations $U_x = V_y, U_y = -V_x$. The proof I have seen of this fact comes from Stein, and the key to the argument is to expand $U$ and $V$ via Taylor's formula for $C^1$ functions. That is, for a point $(x_0, y_0) \in \mathbb{R}^2$, we can write: $$U(x,y) = U(x_0,y_0) + U_x(x_0,y_0)(x - x_0) + U_y(x_0, y_0)(y - y_0) + R(x,y),$$ and a similar formula for $V(x,y)$. Here, $R(x,y)$ is a remainder term with $\frac{R(x,y)}{|(x,y) - (x_0,y_0)|} \to 0$ as $(x,y) \to (x_0,y_0)$. I'm wondering if there is some way I can adapt this proof from Stein to the polar case? Hints are solutions are greatly appreciated.",['complex-analysis']
283208,"Number of labelled graphs with $n$ nodes, $k$ edges and $t$ triangles","How many labelled undirected graphs are there with precisely $n$ vertices, $k$ edges, and $t$ triangle subgraphs?  (By triangle I mean a graph with three vertices and three edges.) (Clarification: I am interested only in graphs with no self loops or multiple edges.  The graphs do not need to be connected.) I would appreciate any pointers to results on this problem (exact or approximate). The results I am able to find are typically for unlabelled graphs ( e.g. a count up to $n=12$ ), but in this case I am interested in labelled ones. I am also interested in possible computational methods for this that are better than brute enumeration.","['graph-theory', 'reference-request', 'combinatorics']"
283210,Application of fundamental theorem of calculus,"I have this problem: $$ \frac{d}{dx} \left( \int_{\sqrt{x}}^{x^2-3x} \tan(t) dt \right) $$ I know how found the derivative of the integral from constant $a$ to variable $x$ so: $$ \frac{d}{dx} \left( \int_a^x f(t) dt  \right) $$ but I don't know how make it between two variables, in this case from $\sqrt{x}$ to $x^2-3x$ Thanks so much.","['definite-integrals', 'calculus', 'derivatives']"
283216,How would I find the area of a triangle given three sides and using either the sine/cosine laws?,"Triangle ABC has sides $8.5m$ (a), $7.1$ (b), and $9$ (c). I have been asked to find the area of the triangle using trigonometry.","['trigonometry', 'triangles']"
283221,$\delta$-fined division and Lebesgue measure $\mu$,"Let $E$ be a measurable subset of $[0,1]$. Then we know that we can choose an open set $G$ and a closed set $F$ such that $F\subset E \subset G \subset [0,1]$. For each $t\in [0,1]$, define $$\delta(t) = 
	\begin{cases}
\text{dist}(t,G^c),&\text{if $t\in F$}\\
\text{min}\{\text{dist}(t,b(G)),\text{dist}(t,F)\},&\text{if $t\in G\smallsetminus F$}\\
\text{dist}(t,F),&\text{if $t\in [0,1]\smallsetminus G$.}  
	\end{cases} 
$$ Here we use the notation $b(G)$ to mean the boundary of $G$. Because the sets $G^c$, $b(G)$, and $F$ are closed, it follows that $\delta(t)>0$ for each $t\in [0,1].$ This defines a positive function $\delta$ defined on $[0,1].$ Cousin's Lemma therefore assures that a division $D=\{(t_i,I_i)\}_{i=1}^{n}$ exists such that for each $i=1,\dots,n$ we have $t_i\in [0,1]$ and $$I_i\subset (t_i-\delta(t_i),t_i+\delta(t_i)).$$ Some authors call $D$ as a $\delta$-fined free tagged division of $[0,1].$ My question: How do we show (if it is true) that $$(D)\sum_{t_i\in E}[\mu(I_i)-\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ and $$(D)\sum_{t_i\notin E}\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ where $\mu$ denotes the Lebesgue measure. Any tips?Thanks in advance.","['measure-theory', 'real-analysis']"
283245,Power series relation,"Draks gave the identity, Higher Order Trigonometric Function $$\sum_{k=0}^\infty \frac{(-1)^k x^{km}}{(km)!}=\frac{1}{m}\sum_{k=0}^{m-1} \exp( e^{i\frac{2k+1}{m}\pi}x )$$ How can this be proven?","['power-series', 'sequences-and-series']"
283266,N-nacci Identities: The Final Question (Generalizing Time!),"Okay so here is my personal work on the problem set. I only have question 5 remaining which involves generalization of any recursive sequence. $n$'s correspond to the $n$  in n-nacci. I hope to write a paper in which I discuss my results and to devise a theorem describing a method which to find any ath term of a recursion sequence. (Beginning with a n-nacci sequence) Links to previous postings: Fibonacci Numbers - Complex Analysis Fibonacci( Binet's Formula Derivation)-Revised with work shown Here's my attempt on the problem set on page 106 thus far: (Number 5 being the only question that I have left) http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_a$, note that the n-nacci series is defined by the sequence of numbers $f_a = f_{a-1}+f_{a-2}+f_{a-3} \cdots + f_{a-n}, \ldots )$. If we break this up into $n+1$ separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: for a $F(z) = f_0+f_1z+f_2z^2+...+f_az^a$ $$(0,1,0,0,0...) \rightarrow\,z)$$
$$+(0,f_0,f_1,f_2, \cdots )\to\,zF(z)$$ 
$$+ (0,0,f_0,f_1,f_2, \cdots )\to z^2F(z)$$ $$+ (0,0,0,f_0,f_1,f_2, \cdots )\to z^3F(z)$$ 
$ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ 
$$+ (0_1,0_2,0_3, \cdots ,0_n,f_0,f_1,f_2, \cdots )\to z^nF(z)$$
This all equals $$(0,1, \cdots f_{a-1}+f_{a-2}+f_{a-3} + \cdots +f_{a-n})\to z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2-z^3- \cdots - z^n} \bullet$$ Am I on the right track? ~ I felt that it would make more sense to do (2) before (1) here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. $$\lim_{n\to\infty}\left|\frac{f_{n+1}z^{n+1}}{f_nz^n}\right|=|z|\lim_{n\to\infty}\frac{f_{n+1}}{f_n}=\varphi|z|\;,$$ so the radius of convergence is $\dfrac1\varphi=\dfrac{-1+\sqrt5}2$ Don't have any clue how to generalize this to a n-nacci sequence. ~ (3) $Res(f,c) = \frac{1}{a-1!}\lim_{z\to c}\frac{d^a-1}{dz^a-1} ((z-c)^aF(z)$ for a pole of order $a$. $$1=Res_{z=0}z^{-1}$$ then  $z^{a+1}$ would be the extracting term: $$f_a=Res_{z=0}\frac{1}{z^{a+1}} \sum_{n>1}{f_az^a}$$ Could I instead generalize this to? $$\operatorname {Res}_{z=0}\left(\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots -z^n)}\right)$$ $$\begin{align*}
&=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\left(z^{a+1}\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots - z^n)}\right)\\
&=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\big(F(z)\big)\\
&=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\sum_{k\ge 0}f_kz^k\\
&=\frac1{a!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^a}{dz^a}z^k\\
&=\frac1{a!}\lim_{z\to 0}\sum_{k\ge a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big)z^{k-a}\\
&=\frac1{a!}\lim_{z\to 0}\left(f_aa!+\sum_{k>a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-a}\right)\\
&=f_n+\frac1{a!}\lim_{z\to 0}z\sum_{k\ge a+1}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-(a+1)}\
&=f_n\; \bullet
\end{align*}$$","['fibonacci-numbers', 'complex-analysis']"
283269,How to prove $ {a_n} = \frac{n!}{2^n}$ diverges to $+ \infty$? [duplicate],"This question already has answers here : Alternative way to prove $\lim_{n\to\infty}\frac{2^n}{n!}=0$? [duplicate] (7 answers) Closed 6 years ago . I would like to prove that the sequence $ {a_n} = \frac{n!}{2^n}$ diverges to $+ \infty$. As I understand it, this means that for all numbers $M$, I must find a number $N$ such that for all $n \ge N$, I get $a_n \ge M$. However, I'm not sure how to pick $N$.
Thanks.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'analysis', 'divergent-series']"
283273,Simple bijectiveness question,"If $f$'s image set is $g$'s domain and vice versa, does that imply that their domains have a 1-1 correspondence? That $f$ and $g$ are both bijective mappings? Are my questions even meaningful? Edit:
My question stems from this example from David Brannan's First Course in Mathematical Analysis.
I don't feel entirely comfortable with his argument that f is a one-to-one correspondence. (I do know how to show this by showing surjectivity(which is assumed here) and injectivity separately.)","['functions', 'real-analysis']"
283276,"Given $(x_n)$, does there exist a measure such that $x_n=\int_0^1t^n d\mu$?","Let $(x_n)$ be a sequence of real numbers. Does there exist a measure $\mu$ on $[0,1]$ such that $x_n=\int\limits_0^1t^nd\mu$ ?","['measure-theory', 'integration']"
283278,Set notation for infinite subsets.,"In set notation, how can one express an infinite set of subsets where each subset has exactly two elements $\{an-1, an+1\}$ where $a$ is a constant and $n\ge1$ and the $n$ value for each subset is one more than that of the previous subset. Example:
$\{ \{a1-1, a1+1\},~\{a2-1, a2+1\},~\{a3-1, a3+1\},~. . . \}$","['notation', 'elementary-set-theory']"
283297,Second order linear ODE with variable coefficients,Consider the second-order linear differential equation $u'' + p(x)u' + q(x)u = 0$ where $p$ and $q$ are continuous on the entire $\mathbb{R}$. Suppose that $q(x) < 0 $ everywhere. Show that if $u$ is not identically $0$ then $u$ can have at most one zero on $\mathbb{R}$. Any suggestions on how to go about this? Anything will be deeply appreciated!,"['ordinary-differential-equations', 'derivatives', 'real-analysis', 'analysis']"
283308,Point of discontinuity,"I have a function: 
$$f(x) = x$$
Defined over the domain $\mathbb{R} \backslash 0$.
Is it correct to say that: The function is continuous, but it has a point of discontinuity at $x=0$?",['calculus']
283317,Eigenvector and its corresponding eigenvalue,"For the following square matrix: $$ \left( \begin{array}{ccc} 3 & 0 & 1 \\
 -4 & 1 & 2 \\
 -6 & 0 & -2 \end{array} \right)$$ Decide which, if any, of the following vectors are eigenvectors of
  that matrix and give the corresponding eigenvalue. $ \left( \begin{array}{ccc} 2  \\ 2  \\
 -1  \end{array} \right)$ $ \left( \begin{array}{ccc}
 -1  \\ 0  \\ 2  \end{array} \right)$ $ \left( \begin{array}{ccc}
 -1  \\ 1  \\ 3  \end{array} \right)$ $ \left( \begin{array}{ccc} 0  \\ 1  \\ 0  \end{array} \right)$$ \left( \begin{array}{ccc} 3 \\ 2  \\ 1 
 \end{array} \right)$ If I've understood correctly, I must multiply the matrix by each vector first. If the result is a multiple of that vector, then it's an eigenvector. Only the fourth vector is so. But how should I calculate its corresponding eigenvalue?","['linear-algebra', 'eigenvalues-eigenvectors']"
283332,Outward Flux of a Divergenceless Vector Field on an Ellipsoid,"tl;dr: How do you evaluate $\iint_S \mathbf{F} \cdot d\mathbf{S}$ where $\mathbf{F}(x,y,z) = \frac{1}{(x^2+y^2+z^2)^{3/2}}\langle x,y,z\rangle$ and $\mathbf{S}$ is the outward oriented surface given by $9x^2+4y^2+16z^2=144$? Long story: My multivariate calculus teacher recently gave our class the following problem: Compute the outward flux $\iint_S \mathbf{F} \cdot d\mathbf{S}$ where
$$\mathbf{F}(x,y,z)=(y + \frac{x}{(x^2+y^2+z^2)^{3/2}})\mathbf{i} + (x + \frac{y}{(x^2+y^2+z^2)^{3/2}})\mathbf{j} + (z + \frac{z}{(x^2+y^2+z^2)^{3/2}})\mathbf{k} $$
and $S$ is the surface of the ellipsoid given by $9x^2+4y^2+16z^2=144$. The solution he gave us ran along the following lines: Let $\mathbf{F} = \mathbf{F_1} + \mathbf{F_2}$ where
$$\mathbf{F_1} = \langle y,x,z\rangle;\; \mathbf{F_2} = \frac{1}{(x^2+y^2+z^2)^{3/2}}\langle x,y,z\rangle$$ which gives us $\iint_S \mathbf{F} \cdot d\mathbf{S} = \iint_S \mathbf{F_1} \cdot d\mathbf{S} + \iint_S \mathbf{F_2} \cdot d\mathbf{S} $. By applying the divergence theorem and spherical parametrization, we can find that  $\iint_S \mathbf{F_1} \cdot d\mathbf{S} = 96\pi$. This made sense to me; I had no problem with understanding the transformation and evaluation of the integrals. After that, though, I got lost. According to my notes, he discussed how you can transpose $\iint_S \mathbf{F_2} \cdot d\mathbf{S}$ onto a unit sphere because $\mathbf{F_2}$ is divergenceless, and as a consequence it is equal to the surface integral of the unit sphere, yielding $\iint_S \mathbf{F_2} \cdot d\mathbf{S} = 4\pi$. This raised two questions: first, of course, was what the heck did my teacher just do? Second was: what's wrong with $\iint_S \mathbf{F_2} \cdot d\mathbf{S} = \iiint_E\nabla\cdot\mathbf{F_2}\,dV = \iiint_E{0}\,dV = 0$ (where $E$ is the region enclosed by surface $S$)? A friend said that it had to do with the fact that $\mathbf{F_2}$ is undefined at $(0,0,0)$, but I'm still confused. It would be great if someone could explain to me how to evaluate the outward flux of $\mathbf{F_2}$ on $S$. Thanks.",['multivariable-calculus']
283365,"What does ""toy-contour"" mean?","When I reading Complex Analysis written by Stein and Shakarchi. In Chapter 2, he had introduced a notion ""toy contour ""without explaining. what does this exactly mean?","['terminology', 'complex-analysis']"
283373,Invertibility of laplacian operator,Let $\Omega\in\mathbb{R}^n$ be a bounded open set with smooth boundary. How to prove the invertibility of $$- \triangle:H^2_0(\Omega) \to L²(\Omega) $$ The injectivity is easy. But how to prove surjectivity without the use of weak notion of solution (when the domain becomes $H^1_0(\Omega)$ and this can be easily found in books)?,"['reference-request', 'functional-analysis', 'partial-differential-equations']"
283382,"Prime decomposition of an integer: methods of determining the prime factors $ p_1, p_2, ..., p_r$ and powers $k_1,k_2, ..., k_r$","Any integer n can be written in the form $ n = p_1^{k_1}p_2^{k_2} ... p_r^{k_r} $ , where the powers $ k_1, k_2, ...,k_r $ are integers and 
$ p_1, p_2, ..., p_r$ are primes. Now I am interested in whether there are quicker methods for finding the powers, other than trial and error? For example, if I wanted to write a large number such as 567 788 in the above form, and it looked something like this: $567 788 = p_1^{k_1}p_2^{k_2}p_3^{k_3} $ what methods could could be applied, to determine the relevant prime factors $ p$, and by what power $k$ to raise each prime $p$?","['prime-numbers', 'exponentiation', 'number-theory']"
283396,How I can find this limit?,"If $a_n=(1+\frac{2}{n})^n$ , then find $$\lim_{n \to \infty}(1-\frac{a_n}{n})^n$$. Trial: Can I use $$\lim_{n \to \infty}a_n=e^2$$ Again $$\lim_{n \to \infty}(1-\frac{a_n}{n})^n=\exp(-e^2)$$ Please help.","['sequences-and-series', 'real-analysis', 'limits']"
283397,The image of a morphism between affine algebraic varieties.,"Suppose $F$ is an morphism between algebraic variety $V$ and $W$. Prove that the pull back $F^\#$ between the coordinate ring $C[W]$ and $C[V]$ is surjective if and only if the morphism $F$ is an isomorphism between $V$ and some algebraic subvariety of $W$. This is an exercise from Karen.E.Smith 'An invitation to algebraic geometry.' I can show without difficulty that if $F^\#$ is surjective, then $F$ is injective. But how to prove that the image of $F$ is a subvariety of $W$? Generally it's not true that the image of an injective morphism is an algebraic variety.",['algebraic-geometry']
283400,Wolfram Alpha: How to define constants in a system of equations?,"I'd like to use WA to solve a small system of nonlinear equations, that involve both constants and the variables of interest.  How do I ""tell"" WA which variables are the constants, and which are the ones I want it to solve for?","['wolfram-alpha', 'algebra-precalculus', 'computer-algebra-systems']"
283402,Euler characteristic of a variety and its analytification,"Let $X$ be a smooth projective complex variety and $\mathcal{F}$ a coherent sheaf on $X$. Let $\tau$ be a Grothendieck topology and
$$
\chi(X,\mathcal{F},\tau)=\sum_i(-1)^i dim_{\mathbb{C}}H^i_\tau(X,\mathcal{F})
$$
the Euler characteristic of $(X,\mathcal{F},\tau)$. For a compact closed and connected manifold $\bar X$, the Euler characteristic is
$$
\chi(\bar X)=\sum_i(-1)^i rank_{\mathbb{Z}}H^i(\bar X,\mathbb{Z}).
$$
Note that we may also use singular homology instead of singular cohomology. The number $rank_{\mathbb{Z}}H^i(\bar X,\mathbb{Z})$ is the number of $\mathbb{Z}$-factors of the group $H^i(\bar X,\mathbb{Z})$, the $i$-th Betti number of $X$. This number equals $dim_{\mathbb{C}}(H^i(\bar X,\mathbb{Z})\otimes\mathbb{C})$. This should be the same as $dim_{\mathbb{C}}H^i(\bar X,\mathbb{C})$ if I am not mistaken. To the variety $X$ we can associate its analytification $\bar X$. How do $\chi(X,\mathcal{F},\tau)$ and $\chi(\bar X)$ relate? This question rises from this one where it is said that there is no nice relation for $\tau$ the Zariski topology. In the answers however, a connection with the etale topology and $F=\mathcal{O}_X$ the structure sheaf is suggested. What is this connection precisely? I remember vaguely that one should take finite coefficients somewhere, but I don't see where and why. In this case there is no such direct connection between singular homology and cohomology which makes the thing even more difficult for me to understand.",['algebraic-geometry']
283440,How do I prove that $\exp(\frac{h}{1+h})\leq 1+h$?,"I have come across the inequality $$\exp\left(\frac{h}{1+h}\right)\leq 1+h,\quad\forall h>-1,$$ on http://functions.wolfram.com/ElementaryFunctions/Exp/29/ . I would like some help proving this. A straightforward expansion of the exponential doesn't seem to yield anything.","['inequality', 'exponential-function', 'calculus', 'algebra-precalculus']"
283443,Is composition of measurable functions measurable?,"We know that if $ f: E \to \mathbb{R} $ is a Lebesgue-measurable function and $ g: \mathbb{R} \to \mathbb{R} $ is a continuous function, then $ g \circ f $ is Lebesgue-measurable. Can one replace the continuous function $ g $ by a Lebesgue-measurable function without affecting the validity of the previous result?","['functions', 'measure-theory', 'real-analysis']"
283444,Problem related to a square matrix,"Let $A$ be an $n\times n$ matrix with real entries such that $A^{2}+I=\mathbf{0}$. Then: (A) $n$ is an odd integer. (B) $n$ is an even integer. (C) $n$ has to be $2$ (D) $n$ could be any positive integer. I was thinking about the problem.I noticed for a  $2\times 2$ matrix $A$ of the form 
$$\begin{pmatrix}
1 &-2 \\ 
 1& -1
\end{pmatrix},$$ the given condition holds good.So option (C) is a possibility.But I am not sure about other options. Is there any convenient way to tackle it?With regards..","['matrices', 'linear-algebra']"
283450,Solving linear first order differential equation with hard integral,"I'm try to solve this differential equation: $y'=x-1+xy-y$ After rearranging it I can see that is a linear differential equation:
$$y' + (1-x)y = x-1$$ So the integrating factor is $l(x) = e^{\int(1-x) dx} = e^{(1-x)x}$ That leaves me with an integral that I can't solve... I tried to solve it in Wolfram but the result is nothing I ever done before in the classes so I'm wondering if I made some mistake... This is the integral:
$$ye^{(1-x)x} = \int (x-1)e^{(1-x)x} dx$$","['ordinary-differential-equations', 'integration']"
283453,Saturating Horn's Inequalities,"If I have a matrix product of the form: $C = AB$ where $A = UDU^*$ With A and B square, Hermitian and positive semidefinite, D diagonal, U a unitary and * representing the conjugate transpose, then Horn's inequalities give: $c_{i+j-1} \leq d_i b_j \ $ Where $b_i$, $c_i$ and $d_i$ are the eigenvalues of B, C and D respectively, $b_1 > b_2 > ... > b_n$ and similarly for c and d. Is it generally possible to saturate these inequalities (i.e. replace the $\leq$ with an = for the minimum value of the RHS) by the correct choice of U?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
283473,Wiggly polynomials,"I'd like to be able to construct polynomials $p$ whose graphs look like this: We can assume that the interval of interest is $[-1, 1]$. The requirements on $p$ are: (1) Equi-oscillation (or roughly equal, anyway) between two extremes. A variation of 10% or so in the values of the extrema would be OK. (2) Zero values and derivatives at the ends of the interval, i.e. $p(-1) = p(1) =p'(-1) = p'(1) = 0$ I want to do this for degrees up to around 30 or so. Just even degrees would be OK. If it helps, these things are a bit like Chebyshev polynomials (but different at the ends). The one in the picture has equation $0.00086992073067855669451 - 
 0.056750328789339152999 t^2 + 
 0.60002383910750621904 t^4 - 
 2.3217878459074773378 t^6 + 
 4.0661558859963998471 t^8 - 
 3.288511471137768132 t^{10} + t^{12}$ I got this through brute-force numerical methods (solving a system of non-linear equations, after first doing a lot of work to find good starting points for iteration). I'm looking for an approach that's more intelligent and easier to implement in code. Here is one idea that might work. Suppose we want a polynomial of degree $n$. Start with the Chebyshev polynomial $T_{n-2}(x)$. Let $Q(x) = T_{n-2}(sx)$, where the scale factor $s$ is chosen so that $Q(-1) = Q(1) = 0$. Then let $R(x) = (1-x^2)Q(x)$. This satisfies all the requirements except that its oscillations are too uneven -- they're very small near $\pm1$ and too large near zero. Redistribute the roots of $R$ a bit (somehow??) to level out the oscillations. Comments on answers Using the technique suggested by achille hui in an answer below, we can very easily construct a polynomial with the desired shape. Here is one: The only problem is that I was hoping for a polynomial of degree 12, and this one has degree 30. Also, I was expecting the solution to grow monotonically outside the interval $[-1,1]$, and this one doesn't, as you can see here:","['numerical-methods', 'real-analysis', 'polynomials']"
283476,Rational quartic curve in $\mathbb P^3$,"By using similar arguments to the ones from my answer to this question , I can prove that the homogeneous coordinate ring of the rational quartic curve in $\mathbb P^3$, that is, $$R = K[x_1, x_2, x_3, x_4]/\left< x_1^2x_3-x_2^3,x_1x_3^2-x_2^2x_4,x_2x_4^2-x_3^3,x_1x_4-x_2 x_3\right>,$$ is isomorphic to $K[s^4,s^3t,st^3,t^4]$. (This is also Exercise 18.8 in Eisenbud, Commutative Algebra with a View Toward Algebraic Geometry .) I'm interested in geometric arguments which I expect to be simpler than the algebraic ones. References are also welcome. Edit. There is some connection with this topic where it is proved that $R$ is an integral domain.","['commutative-algebra', 'algebraic-geometry']"
283487,Is the multiplicative Chernoff bound stronger than additive one?,"The multiplicative Chernoff Bound says for $X_i \in \{0,1\}$ that satisfies $\mathbb{E}[X_i] = p$, $$
\mathbb P\left(\sum\limits_i^n{X_i} \geq np(1+\delta)\right) \leq e^{-\frac{1}{3} np\delta^2} \>.
$$ The additive version says that 
$$
\mathbb P\left(\sum\limits_{i}^nX_i \geq np+n\epsilon \right) \leq e^{-2n\epsilon^2} \>.
$$ I wonder if the multiplicative version could be stronger. Let $\epsilon = p \delta$, then the additive Chernoff bound is reduced to 
$$
\mathbb P\left(\sum\limits_{i}^{n}{X_i} \geq np(1+\delta)\right) \leq e^{-2np^2\delta^2} \>.
$$ This is a much weaker bound when $p \ll 1$. How can these two versions of Chernoff bounds have such a difference? I mean, which step in deriving these two bounds diverges, causing the fact I have illustrated?","['inequality', 'probability']"
283498,Exact sequence from $G=G_0\supset G_1\supset G_2\supset\cdots\supset G_r=\{e\}$,"This is Exercise 5.3 from Algebra: Chapter 0 . Given a normal series of subgroups \begin{equation}G=G_0\supset G_1\supset G_2\supset\cdots\supset G_r=\{e\},
\end{equation} construct an exact sequence of groups using $\{e\}, G$ and $H_j=G_j/G_{j+1}$ to connect $\{e\}$ and $G$. I am not sure what the author is asking for. Starting from $\{e\}$, I think the only natural sequence involving only $\{e\}, H_j$ and $G$ is of the form \begin{equation}
\{e\}\longrightarrow G_{r-1}/G_{r}\longrightarrow G_{r-2}/G_{r-1}\longrightarrow\cdots.
\end{equation}  However this is not exact. Can someone give a hint?
Thanks!","['category-theory', 'group-theory', 'abstract-algebra']"
283500,Solutions of $f(f(z)) = e^z$,"It is my impression that if we find a function f(z) that satisfies $$f(f(z)) = e^z $$ there is only one point z that satisfies the relation. This dawned on me when I noticed that the pesky z that kept popping up in my attempts to look at the problem was the one my book proposed I start with, to wit: $z_o = 0.318 + 1.337i.$ So the joke was on me. Now I would like to prove this. I would instinctively begin by assuming there was a $z \neq z_o$ and deriving a contradiction. Hopefully I will make some progress before an answer is posted but I am sure I will miss nuances. Maybe it's as simple as showing that $\log^nz$ has a fixed point, which I don't know to be true. Thanks for any insights.","['tetration', 'complex-analysis']"
283537,Tensor on Exterior Algebra,"I hope someone can help me on showing that $(\wedge^k(M))^*\otimes \wedge^n(M) = \wedge^{n-k}(M)$, where $M$ is a free $R$-module of rank $n$, and $^*$ is the dual. From what I know, $(\wedge^k(M))^* = \mbox{Hom}(\wedge^k(M), R)$. But how do I incorporate it with the tensor product, or am I even on the right track? My intuition tells me that if $\varphi \in \mbox{Hom}(\wedge^k(M), R)$, then it somehow ""reduces"" an element of $\wedge^{k}(M)$ to $R$, and so explains the $\wedge^{n-k}(M)$ part of the equality. Though I am not entirely sure of this. Any help is much appreciated. Thanks!","['tensor-products', 'abstract-algebra']"
283553,Evaluate $\sum_{n=1}^{\infty} \frac{(2n)!}{2^{2n}(n!)^2 (2n-1)}$,"How to evaluate the series
$$S = \sum_{n=1}^{\infty} \frac{1}{2^{2n}(2n-1)} \binom{2n}{n}$$ The original question was to show that for 
$$ a_n=\left(\frac{ 2n-3 }{ 2n }\right)a_{n-1} , a_1 = \frac 1 2, \text{ Show } \; \sum_{k=1}^\infty a_k < 1$$
After simplifying it, I got the above result. But from W|A the above converges to $1$. I hope I haven't made any mistake. Still the I would like to know how to evaluate it.","['catalan-numbers', 'sequences-and-series', 'binomial-coefficients']"
283557,Why isn't this function $f:\mathbb N \to \mathcal P(\mathbb N)$ a surjection?,"Let $f:\mathbb N \to \mathcal P(\mathbb N)$ be a function which maps to each odd natural number an unitary set from $P(\mathbb N)$. Then, we map the even, non-four multiples with the sets formed by two elements. Recursively, we map the numbers whose rest of the division by $2^k$ is $2^{k-1}$ with the sets formed by $k$ elements. I've studied that there is no surjection from $\mathbb N$ to $\mathcal P(\mathbb N)$, so why is not my function surjective?","['cardinals', 'elementary-set-theory']"
283559,"$A$ be a $n \times n$ matrix with $\text{rank}\,(A)\lt n$: multiple choice question","Let $A$ be an $n \times n$ real non-zero matrix of rank less than $n$. Then one of the following is true? : (A) there exists an $n \times n$ real non-zero matrix $B$ such that $BA = 0$. (B) there may not always exist an $n \times n$ real non-zero matrix $B$ such that $BA = 0$. (C) there exists an $n \times n$ real non-zero matrix $B$ such that $BA = I$. (D) if $B$ is such that $BA = 0$, then $AB = 0$. My Attempt: Consider a $2\times 2$ matrix $A$ of the form  $\begin{pmatrix}
0 &1 \\ 
0 & 0
\end{pmatrix}$ and a $2\times 2$ matrix $B$ of the form  $\begin{pmatrix}
0 &a \\ 
0 & c
\end{pmatrix},$ where $a,c$ are any non zero real numbers. Then I have that $BA=0$ holds. So option $(A)$ may hold. Option $(B)$ can also hold if we take $2\times 2$ matrix $B$ of the form  $\begin{pmatrix}
1 & a \\ 
2 & c
\end{pmatrix}$ $(C)$ is clearly false. Also $(D)$ is also false as is evident if we take $2 \times 2$ matrix $A$ of the form  $\begin{pmatrix}
0 &1 \\ 
0 & 0
\end{pmatrix}$ and $2 \times 2$ matrix $B$ of the form  $\begin{pmatrix}
0 &a \\ 
0 & c
\end{pmatrix}$ So I am confused between $(A)$ and $(B)$. Which one should be the right choice?","['matrices', 'linear-algebra']"
283566,Precedence of $\times$ and $\cup$.,"In topology, there is a very strong need of describing subsets of some product $X\times Y$ by means of unions and products. For example, this is a very convenient way of describing subsets of the plane. (Which are common examples in, say, algebraic topology.) Is there any standard convention about the precedence of products and unions? In particular, when I write $A\times B\cup C\times D$ would this be interpreted as $A\times(B\cup C)\times D$ or as $(A\times B)\cup(C\times D)$? I personally would go with the second option, because of the analogy with multiplication and addition, which for some reason seems to make sense to me. (And in that case there is a standard convention). Despite this analogy, I fear the omission of parentheses in the case of sets might be ambiguous to some people. Is it better to always use parentheses? (Of course a downside of parentheses would be that the notation may become very cluttered, when the expressions are long.)","['general-topology', 'elementary-set-theory', 'notation']"
283579,How to model mutual independence in Bayesian Networks?,"It's well known that 3 random variables may be pairwise statistically independent but not mutually independent, for an illustration see: example pairwise vs. mutual relations . Can mutual statistical independence be modeled with Bayesian Networks aka Graphical Models ? These are nonparametric structured stochastic models encoded by Directed Acyclic Graphs. ""Each vertex represents a random variable (or group of random variables), and the links express probabilistic relationships between these variables. The graph then captures the way in which the joint distribution over all of the random variables can be decomposed into a product of factors each depending only on a subset of the variables."" -- CM Bishop Pattern Recognition and Machine Learning , Ch. 8 p. 630. Here's a basic example from Wikipedia: It would appear that hypergraphs are needed to represent the higher order (in)dependence. Is there some trick based on ""d-separation"", ""Markov Blankets"" or maybe grouping variables that would enable such a representation?","['probability-theory', 'bayesian-network', 'probability-distributions', 'statistics']"
283581,How many different sizes of infinity are there?,"It's pretty straightforward to say that there is an infinite number of different sizes of infinity, but then I thought, ""What size of infinity is that?"" My thoughts are that the number of unique cardinalities is equivalent to the number of real numbers, based on the fact that the cardinalities can always be ordered by increasing size. I don't really know how to prove this, though. It's mostly based on intuition, which isn't very reliable when talking about uncountably infinite sets. I originally asked a somewhat related question at a different (and not math-oriented) forum, and the users there told me that it is not possible to talk about the number of cardinalities without talking about the set of all sets, which forms a paradox. If a set were to contain all of the different sizes of infinity, it would have to contain its own power set, which isn't possible. However, I'm not completely convinced that it is not possible to talk about a set of all of the cardinalities. Sure, a cardinality represents a size of infinity, but I think that it should be possible to have a set of the cardinalities without having the set actually contain the various infinities. Would this avoid the above paradox? So, is it possible to measure the number of different sizes of infinity, and what would that size be?","['infinity', 'elementary-set-theory']"
283585,$\lim_{x \to 0} \frac {(x^2-\sin x^2) }{ (e^ {x^2}+ e^ {-x^2} -2)} $ solution?,"I recently took an math exam where I had this limit to solve $$ \lim_{x \to 0} \frac {(x^2-\sin x^2) }{ (e^ {x^2}+ e^ {-x^2} -2)}  $$ and I tought I did it right, since I proceeded like this:
1st I applied Taylor expansion of the terms to the second grade of Taylor, but since I found out the grade in the numerator and in the denominator weren't alike, I chose to try and scale down one grade of Taylor, and I found my self like this: $$\frac{(x^2-x^2+o(x^2) )}{( (1+x^2)+(1-x^2)-2+o(x^2) )}$$ which should be: $$\frac{0+o(x^2)}{0+o(x^2)}$$ which should lead to $0$. Well, my teacher valued this wrong, and I think i'm missing something, I either don't understand how to apply Taylor the right way, or my teacher did a mis-correction (I never was able to see where my teacher said I was wrong, so that's why I'm asking you guys) Can someone tell me if I really was wrong, and in case I was explain how I should have solved this? Thanks a lot.","['taylor-expansion', 'calculus', 'limits']"
283591,Hyperbola is a pair of straight lines?,"I'm confused by this question: If $f(x) = 2x^2 - 6y^2+xy+2x-17y-12=0$ is to represent a pair of
  straight lines, one of which has equation $x+2y+3=0$, what must be the
  equation of the other line? Verify that $f(x)=0$ does, indeed,
  represent a pair of straight lines. Given the general form of a conic section $Ax^2+By^2+Cxy+Dx+Ey+F=0$ we know that if $C^2 > 4AB$ as here, it's a hyperbola. Therefore I don't get how the equation can represent 2 straight lines. Any clues?","['geometry', 'conic-sections']"
283601,$\cot x=0$ is $x$ undefined?,"I'm having trouble with finding the values of $x$ when $\cot x=0$ $$\cot x=\frac{1}{\tan x}=0$$
$$\tan x = \frac{1}{0}$$
Which is not possible. But 
$$\cot x=\frac{\cos x}{\sin x}=0$$
$$\cos x = 0$$
$$x = 90^\circ$$ So is the value of $x$ undefined or not?",['trigonometry']
283603,How to find the total number of distinct terms in a certain expansion?,We know that $(1+x)^2$ has $3$ distinct terms because $(1+x)^n$ has $n+1$ terms going by the popular expansion starting from ${}_nC_0$ to ${}_nC_n$. How do we find total number of distinct terms in expressions like $(a+b+c+f)^{40}$ and what's the generalized result?,['combinatorics']
283608,"Function which gradually rises until some point and then quickly ""falls""","Could someone point me to any function ${ f(x) }$ which is continuous at some interval ${ x \in [x_0; x_1] }$ and can be represented by formula, so that it rises until some point and then quickly ""falls"" like on image below? What may cause such behavior?",['functions']
283612,Is there a sequence whose arithmetic means lie dense in $[-1..1]$?,"Is there a sequence $(a_n)_{n \in \mathbb{N}}$ of real numbers in the range of $[-1..\,1]$ such that the sequence of their arithmetic means $(\alpha_n)_{n \in \mathbb{N}}$, given by
$$\alpha_n = \frac{1}{n}\sum_{k=1}^n a_k,\quad n \in \mathbb{N}$$
has a dense image in $[-1..\, 1]$? My thoughts: Yes, there is and I strongly suspect the sequence which alternates between $1$ and $-1$ such that it will be constantly $1$ for $2^k$ members and then constantly $-1$ for $2^{k+1}$ members and so on ... to do the trick.
And if it doesn't something similiar will do.","['sequences-and-series', 'calculus', 'real-analysis']"
283626,What is the value of $\int_0^1 \frac{\arctan x}{1+x^{2}} dx$?,"$$\int_0^1 \frac{\arctan x}{1+x^{2}} dx = ?$$ 
I tried to evaluate it, but I do not know if it is good:
$$\int_0^1\frac{\arctan x}{x^2+1}\,\mathrm{d}x=\left[\arctan x=t\Rightarrow \frac{\mathrm{d}x}{1+x^2}=\mathrm{d}t\right]=\int_0^{\frac{\pi}{4}}t \, \mathrm{d}t=\left[\frac{t^2}{2}\right]_0^{\frac{\pi}{4}}=\frac{\pi^2}{32}$$","['definite-integrals', 'integration']"
283631,Relation between maximizer's derivative and maximizing function,"Let $u(x)$ be a continous bounded function such that $u'(x) >0$, $u''(x) < 0$. Define $A(x) = -\frac{u''(x)}{u'(x)}>0$. Let $Y$ be a random variable with $\mathbb{E}|Y|<\infty$. I solve a maximization problem
$$
   \mathsf Eu\left( (K-x)C+ x Y \right) \to \max_{x}
$$
This optimization problem may be interpreted as a problem of choosing a part $x$ of all available capital $K>0$ that we will spent on risky assets with random price $Y$, the remaining part $K-x$ of capital will be spent on non-risky assets with fixed price $C$. A solution of the problem will be denoted by $x(K)$. How to show that there is a relation between $x'(K)$ and $A(x)$? 
$$ 
    A(\cdot) \uparrow \implies x'(\cdot)<0 \\
    A(\cdot) \equiv \mathrm{const} \implies x'(\cdot) = 0 \\
    A(\cdot) \downarrow \implies x'(\cdot)>0
$$
where $(\cdot)$ means that this property holds for any possible arguments.","['probability-theory', 'optimization']"
283648,"Poisson distribution, mean time and probability of waiting","We know that average number of planes landing at particular airport during an hour is 36. a) what is the mean time for waiting for the first landing during an hour? b) find probability of waiting more than 1/2 hour to see the first landing? I assumed this is Poisson distribution as Exponential is memoryless (each minute would have independent probability, am I right?) But to be honest I don't really know what to do next.
I wrote down the data from the task: $$\lambda = 36$$ And I'm stuck. Looking more for tips how to solve this task, not full solution. Thank you for help in advance.","['statistics', 'probability-distributions']"
