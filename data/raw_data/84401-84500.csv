question_id,title,body,tags
1106728,"Biased coin probability, uneven probability","Getting at least $2$ heads when flipping a coin $3$ times but the coin is biased
so that heads are $3$ times more likely than tails. Can anyone explain how uneven probability works? Thank you",['probability']
1106737,Lift of isometries of spherical space forms,"If we have an isometry between two spherical space forms, then it is said that it lifts to an isometry of the sphere. Why is that?","['spherical-geometry', 'differential-geometry']"
1106752,slightly different definition of an ordered pair,"In a paper I was reading an ordered pair had a slightly different definition $\langle a,b \rangle = \{a,\{a,b\}\}$ instead the normal Kuratowski definition which is that $\langle a,b \rangle = \{\{a\},\{a,b\}\}$. notice in the first one the $a$ is without braces. now I know that it is wrong , but why is it wrong? is this definition not as good as the real one? related (a question that used the same different definition) I need to disprove an alternate definition of an ordered pair. Why is $\langle a,b\rangle = \{a,\{b\}\}$ incorrect?","['elementary-set-theory', 'definition']"
1106772,Binomial coefficients and cosin,"In this question the user ask to prove the next identity: $$1 + 4\cos{2\theta} + 6 \cos{4\theta} +4\cos{6\theta}+ \cos {8\theta} =16\cos{4\theta} \cos^4 \theta$$ I realized the terms in the left side are expression of a more general term: $$\sum_{k=0}^n {n \choose k} \cos{2k\theta} $$ (the expression of the OP is $n=4$). Question there is a way to calculate that sum? Obviously using the binomial theorem you can show: $$\sum_{k=0}^n {n \choose k} \frac{e^{2ik\theta}+e^{-2ik\theta}}{2}=\frac{1}{2}(1+e^{2i\theta})^n+ \frac{1}{2}(1+e^{-2i\theta})^n$$
$$=\frac{1}{2}e^{2i\theta n}(1+e^{-2i\theta})^n+ \frac{1}{2}(1+e^{-2i\theta})^n$$
$$=\frac{1}{2}(e^{2i\theta n}+1)(1+e^{-2i\theta})^n$$ But how show an expression in terms of $\cos$?","['trigonometry', 'binomial-theorem', 'binomial-coefficients']"
1106804,Finding the equations of an image of a rational map,A map from $\mathbb{P^2} \rightarrow \mathbb{P^3}$ is given by: $$f(x:y:z) = (-xyz:xy(x+y+z):xz(x+y+z):yz(x+y+z))$$ How might one find the equations of it's image?,['algebraic-geometry']
1106812,Factor Group Lemma of Cayley Graph,"Factor Group Lemma: Suppose that 1.$N$ is a cyclic, normal subgroup of group $G$. 2.$(s_1,s_2,\ldots,s_m)$ is a hamiltonian cycle in $Cay(G/N;S). 3.The product $s_1s_2\cdots s_m$ generates $N$. Then $Cay(G;S)$ has a Hamiltonian cycle. I can show the above theorem, but I cannot understand how we can conclude the following corollary. Suppose that 1.$N$ is a cyclic, normal subgroup of $G$, such that |N| is a prime power. $\langle s^{-1}t\rangle=N$ for some $s,t\in S\cup S^{-1}$. There is a hamiltonian cycle in $Cay(G/N;S)$ that uses at least one edge labelled $s$. Then there is a hamiltonian cycle in $Cay(G;S)$.","['graph-theory', 'cayley-graphs', 'group-theory']"
1106814,extracting the middle term of $ (z \cos \theta + w\sin \theta )^m(- z\sin \theta + w\cos \theta )^m $,"Is there a systematic way to extract the middle term of the following expression? $$ (z \cos \theta  + w\sin \theta )^m(- z\sin \theta  + w\cos \theta )^m $$ This is homogeneous polynomial of degree $2m$, so I am looking for the $(zw)^m$ term. Example $m = 2$: $$ (z \cos \theta  + w\sin \theta )^2(- z\sin \theta  + w\sin \theta )^2
= \dots + (zw)^2(\cos^4 \theta - 4 \cos^2 \theta \sin^2 \theta + \sin^4 \theta) + \dots $$ The middle terms can be simplified using the cosine double angle formulas. \begin{eqnarray}\cos^4 \theta - 4 \cos^2 \theta \sin^2 \theta + \sin^4 \theta
&=& (\cos^2 \theta - \sin^2 \theta)^2 - 2 \cos^2 \theta \sin^2 \theta \\
&=& \cos^2 2\theta - \tfrac{1}{2}\sin^2 2\theta \\
&=& \boxed{\tfrac{3}{2}\cos^2 2\theta - \tfrac{1}{2}}
\end{eqnarray} Is it true this middle term can always be expanded as a polynomial in $x=\cos 2\theta$? I learned of this trick while studying the Wigner D-matrices .  It says the Legendre polynomials are certain matrix elements in the representation theory of $SU(2)$.  Checking this fact was surprisingly hard.","['trigonometry', 'generating-functions', 'representation-theory']"
1106870,Can I find the connected components of a graph using matrix operations on the graph's adjacency matrix?,"If I have an adjacency matrix for a graph, can I do a series of matrix operations on the adjacency matrix to find the connected components of the graph?","['graph-theory', 'linear-algebra', 'connectedness', 'spectral-graph-theory', 'algebraic-graph-theory']"
1106888,Prove that $f$ is convex in an interval given an inequality with determinant,"Today,I found a interesting problem: if 
  $$\begin{vmatrix}
\cos{x}&\sin{x}&f(x)\\
\cos{y}&\sin{y}&f(y)\\
\cos{z}&\sin{z}&f(z)
\end{vmatrix}\ge 0$$
  for all $x,y,z$ of an open interval $I$ for which $x<y<z<x+\pi$. show that:
  $f(x)$ is convex on $I$",['analysis']
1106917,Urysohn's Lemma: Proof,"Given a normal space $\Omega$. Then closed sets can be separated continuously:
  $$h\in\mathcal{C}(\Omega,\mathbb{R}):\quad h(A)\equiv0,\,h(B)\equiv1\quad(A,B\in\mathcal{T}^\complement)$$
  Especially, it can be chosen as a bump: $0\leq h\leq1$ Though the idea is very clear it can be strikingly technical. The goal here is to crystalize out the most lucid version! Disclaimer: This is a record for future threads.",['general-topology']
1106923,Sum of closed subspaces of a Hilbert space is closed,"Let $M, N ⊂ H$ ($H$ Hilbert), be two closed linear subspaces.
Assume that $\langle u, v\rangle = 0$ $∀u ∈ M$, $∀v ∈ N$. Prove that $M + N$ is closed. Take a sequence $(g_n)\in M+N$ such that $g_n\to x\in H$. Then for any $n\geq 1$, $\exists v_n\in N, u_n\in M$ such that $g_n=v_n+u_n$. This implies that the sequences $(v_n)$ and $(u_n)$ converge singularly to the elements $v,u\in H$, and by closeness $v\in N$ and $u\in M$. By uniqueness of the limit it must hold $x=u+v$ which implies $x\in N+M$. I did not use any property of orthogonality so I guess this reasoning is wrong. Why? And how should I use orthogonality?","['hilbert-spaces', 'functional-analysis']"
1106976,"Lebesgue point of density on $[0,1]$ and Dynkin's theorem","The problem defines a density point $x\in[0,1]$ for a Borel set $A\subset [0,1]$ if $$ \lim_{\varepsilon \rightarrow 0^+} \frac{\mu([x-\varepsilon,x+\varepsilon]\cap A)}{2\varepsilon}=1.$$Denote all the density point of $A$ to be $A^*$. The problem asks 
to show $$A^*\text{ is Borel}, \mu(A\,\Delta\, A^*)=0, \forall \text{Borel } A\subset[0,1]$$
where $\mu$ is the Lebesgue measure and $\Delta$ means symmetric difference. The point here is that the professor asks to use Dynkin's $\pi-\lambda$ theorem to prove and he note that interval $I$ would have $\mu(I\,\Delta\, I^*)=0$. I manage to show $A^*$ is Borel but do not know how to show the second part.  I let $\pi$ system be all the intervals in $[0,1]$   and the $\lambda$ system to be $S=\{A\text{ is Borel}:\mu(A\,\Delta\, A^*)=0\}$. I got trouble in checking that if $A\in S$ then $A^c\in S$ and if $A_1,\ldots,A_n,\ldots\in S$, $\bigcup A_n\in S$. Indeed, I am not sure that whether Dynkin's theorem could be applied here or make the problem easier. Or we still need to go through the proof using Vitali covering lemma.","['measure-theory', 'lebesgue-measure', 'analysis']"
1107003,Exact solution for ODE: $yy' + y + f(x) = 0$,"Is there is exactly solution for ODE in the form: $yy'+y+f(x)=0$.  Thanks. If there is no such solution for general $f$, does it ease the problem if $f(x)=Ax+B$ for some constants $A$ and $B$? Clarification: solutions below are just particular solution.  What I was looking for is the general solution that works for arbitrary initial condition.",['ordinary-differential-equations']
1107008,Well ordering of $\mathbb{N}$ using inductive sets,"In this book (Elementary Real Analysis by Thomson-Bruckner p.22), $\mathbb{N}=\left\{ 1,2,...\right\}$ (In some, $0\in\mathbb{N}$ ). In an exercise, a set $S\subset\mathbb{R}$ is inductive if $1\in S$ and $\forall x\in\mathbb{R},\,\,x\in S\Rightarrow (x+1)\in S$ I show then that the intersection of the family of all inductive sets is itself inductive. They define then $\mathbb{N}$ to be that smallest inductive set and I prove then the Principle of Induction using it. Now I have to prove the Well Ordering of $\mathbb{N}$ . I know that, since Principle of Induction is correct, Well Ordering of $\mathbb{N}$ is also correct. But I wanted to challenge myself and prove Well Ordering of $\mathbb{N}$ using "" $\mathbb{N}$ to be that smallest inductive set"" as I did for Principle of Induction, without using any other proposition like Archimede Property or the Principle of Induction itself: Let $S\subset\mathbb{N}$ such as $S$ is inductive (i.e., property stated in the Principle of Induction). "" $\mathbb{N}$ to be that smallest inductive set"" so $\mathbb{N}\subset S$ thus $\mathbb{N}=S$ which proves the Principle of Induction. I wrote a prove for the Well Ordering but I'm not sure if it's correct. It's a bit long so could you please tell me if you have an easier? My attempt: Let $S\subset\mathbb{N}$ such as $S\neq\emptyset$ . If $S=\mathbb{N}$ then $\min S=1$ . We're done. If $S\neq\mathbb{N}$ then $S$ isn't inductive and so $1\notin S$ or $\exists n_0\in S,\,(n_0+1)\notin S$ . If $1\in S$ then $\min S=1$ . We're done. If $1\notin S$ . Suppose $\forall n\in S,\,(n+1)\in S$ Suppose $S$ has no minimum,i.e., $\forall n\in S,\,\exists n_0\in S,\,n_0\le n-1$ Let $n_0\in S$ . Thus $\exists n_1\in S,\, n_1\le n_0-1$ $n_1\in S$ . Thus $\exists n_2\in S,\, n_2\le n_1-1$ We can repeat the same prossess until we reach: $n_{n_0-1}\in S$ . Thus $\exists n_{n_0}\in S,\, n_{n_0}\le n_{n_0-1}-1$ By sommation: $\sum\limits_{k=0}^{n_0-1}n_{k+1}\le\sum\limits_{k=0}^{n_0-1}n_k-1$ Thus $n_{n_0}\le 0$ and $n_{n_0}\in S$ , contradiction. Suppose $\exists n_0\in S,\,(n_0+1)\notin S$ If $n_0=\min S$ we're done if not $\exists n_1\in S,\,n_1\le n_0-1$ If $n_1=\min S$ we're done if not $\exists n_2\in S,\,n_2\le n_1-1$ We can repeat the same prossess until we reach: If $n_{n_0}=\min S$ we're done if not $\exists n_{n_0+1}\in S,\,n_{n_0+1}\le n_{n_0}-1$ We do the same as above and find a contradiction.","['real-numbers', 'elementary-set-theory', 'real-analysis']"
1107062,Complement of a point of a Compact Connected Hausdorff Space has no compact maximal connected subspace,This question is a slight modified version of Compact Connected Hausdorff Space has no compact component in the complement of a point Let $X$ be a Hausdorff Compact Connected Space. Prove that $X∖\{x\}$ has no compact component (here a component is a maximal connected subspace). (My attempt is in the question linked above),"['general-topology', 'connectedness', 'compactness']"
1107081,$f:\mathbb{R}^n \to \mathbb{R}$ has expansion $\sum_i g_i(x)x^i$,"Problem 2-35 on page 34 of Spivak's Calculus on Manifolds states If $f: \mathbb{R}^n: \to \mathbb{R}$ is differentiable and $f(0) =0$,
  prove that there exist $g_i: \mathbb{R}^n \to \mathbb{R}$ such that
  $f(x) = \sum_{i=1}^n x^ig_i(x)$. Hint: if $h_x(t) = f(tx)$, then $f(x)
 = \int_0^1 h_x'(t)$. I understand the answer he wants, but hasn't he left out a hypothesis that would ensure $h_x'(t)$ is integrable? (For instance the continuity of $df$.) Secondly, I'm wondering if this theorem is used anywhere. Perhaps in differential geometry it might be useful to write locally $f \in C^\infty (M)$ as $\sum_i g_i(x) x_i$ for some coordinates $x_i$.","['multivariable-calculus', 'differential-geometry']"
1107099,Evaluate a limit of series using Riemann integral,"Let $$ \lim_{n\to\infty} n\cdot \sum_{j=1}^n \frac{\cos\left(\frac{n}{j}\right)f\left(\frac{n}{j}\right)}{j^2} $$ Where $f$ is $C^\infty$ and monotonically decreasing: $\lim_{x\to\infty} f(x) = 0$. I need to evaluate the limit. Riemann integral should be used. I guess there should be some algebraic moves to reach that, and the integrand (my guess) should be $f(x)\cos(x)$. Could you help me please connect the dots?","['calculus', 'integration']"
1107110,"""Pushforward"" over flat morphisms of functions which are constant on fibers","I believe the following should be true, but I'm not sure where to find the required commutative algebra to prove it: If $\mathrm{Spec}\,A \rightarrow \mathrm{Spec}\,B$ is a flat morphism of algebraic varieties over a field $k$  with reduced scheme-theoretic fibers and $a\in A$ is constant on each fiber, then there exists $b\in B$ mapping to $a$. (So $A$ and $B$ are reduced, finitely generated $k$-algebras, where $k$ is some field. Evaluating a function $a\in A$ at a closed point $p\in \mathrm{Spec}\,A$ gives an element of $k$.) Edit : What if $k$ is an algebraically closed field?","['commutative-algebra', 'algebraic-geometry']"
1107111,All matrices which commute with all $2\times 2$ matrices,"I would like to find all matrices which commute with all $2\times2$ matrices. 
I started solving problem in this way: 1) I have this matrix $A$ with real numbers: $$A=\left[\begin{array}{cc}a &b\\c &d\end{array}\right]$$ 2) Matrix which commute with matrix $A$ is matrix $B$: $$B = \left[\begin{array}{cc}e& f\\ g &h\end{array}\right]$$ 3) When i solve the equation $AB=BA$, I get this: $$\left[\begin{array}{cc}ae+bg&af+bh\\ce+dg&cf+dh\end{array}\right]=\left[\begin{array}{cc}ea+cf&eb+df\\ga+ch&gb+dh\end{array}\right]$$ How I can get the general look of wanted matrix?",['matrices']
1107116,"For which $n, k$ is $S_{n,k}$ a basis? Fun algebra problem","Here it is a nice algebra problem I had some fun with Let $V$ be a vector space over $\mathbb R$ of finite dimension $\dim V = n$. Let $v = \{ v_1, \dots, v_n\}$ be a basis for $V$. Let $$S_{n,k} = \{ v_1 + v_2 + \dots + v_k, v_2 + \dots + v_{k+1}, \dots, v_n + v_1 + \dots + v_{k-1}\}$$ 
For which $n, k$ we have that $S_{n,k}$ is still a basis for $V$?","['vector-spaces', 'linear-algebra', 'eigenvalues-eigenvectors', 'problem-solving']"
1107119,What Percentile Do I fall in with this test score vs average?,I just took an online test and I was notified that the average score for the test was 45% (out of 100%) and I received a 72%. Using these 2 pieces of information would it be possible to calculate under what percentile I fall for test scores?,['statistics']
1107129,Are there infinitely many pairs of primes where each divides one more than the square of the other?,"I have the following question on number theory that is eating my head. Are there infinitely many primes $p,q$ such that $p | (q^2 + 1)$ and $q | (p^2 + 1)$? I can see $13,5$ and $2,5$ has the required property by a simple calculation. A computer code reveals the pair $89,233$ as well. But I don't know if there are more. Can someone shed some light on this matter? Thanks!","['prime-numbers', 'divisibility', 'number-theory']"
1107144,Solutions to $y^2 = x^3 + k$?,"The equation $y^2 = x^3 + k$ for $k = (4n-1)^3 - 4m^2$, with $m, n \in \mathbb{N}$ and no prime number that p is congruent to 1 modulo 4 divids m, doesn't have any answer and its proof can be obtained by using quadratic reciprocity law. Do you know answers of this equation for two or three different values of $k$? In addition, do you know any reference about that?","['number-theory', 'mordell-curves', 'algebraic-number-theory', 'prime-numbers', 'diophantine-equations']"
1107177,Limit involving $\sqrt[n]{n!}$,"a)Find $\displaystyle\lim_{n\to\infty}\frac{\sqrt[n]{n!}}{n}$. b)Let $a_n=\frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}$. Find $\displaystyle\lim_{n\to\infty}a_n$ and $\displaystyle\lim_{n\to\infty}\frac{a_n-1}{\ln a_n}$. So, I've managed to find the first two limits, which are $\dfrac1e$ and $1$, but don't know what to do with the last one. Mathematica says it's 1, but I have no idea how to get that. Could I get a hint on how to do this?","['limits', 'analysis']"
1107183,Bertini's theorem for surfaces: informations about singular fibers.,"Let $S$ be a complex non-singular projective surface embedded in some $\mathbb P^n$. Thanks to the Bertini's theorem (Hartshorne theorem II.8.18) there exists a  hyperplane $H\subseteq\mathbb P^n$ such that $H\cap S$ is a smooth projective curve (so irreducible) and moreover the generic hyperplane $L$ in the linear system $|H|$ has such a property. Now suppose that  $H'\in |H|$  is a hyperplane which doesn't satisfy the Bertini theorem, what can we say about the ""curve"" $H'\cap S$?
Is it reduced, connected or irreducible? Moreover what about the singular points of $H'\cap S$? They are nodes? Practically I'd like to know some information about the ""bad"" hyperplane sections of $S$.","['algebraic-geometry', 'schemes', 'algebraic-curves', 'surfaces']"
1107191,Green's Theorem; computing a double integral,"This is the last part of an exercise in Apostol Vol. II.  (p.385, 1 (e), to be precise.)  No doubt there's a trick I'm missing, because evaluating the double integral over the region involved seems unduly complicated. We are supposed to use Green's Theorem to evaluate the line integral $\oint_CPdx + Qdy$ (where $C$ is traversed counterclockwise), with $P = y^2$, $Q = x$, and $C$ described by the parametric equations $x = 2\cos^3t$, $y = 2\sin^3t$ where $t$ ranges from $0$ to $2\pi$. We have $\frac{\partial Q}{\partial x} = 1$, $\frac{\partial P}{\partial y} = 2y$.  So what we want to evaluate is \begin{align}
\iint\limits_R (1 - 2y)dydx
\end{align}
where $R$ is the interior of the the region bounded by $C$.  Trying to evaluate by iterated integration gives us
\begin{align}
\int_{-2}^2\left[\int_{-2\cos^3\left[\arcsin\left(\sqrt[3]{\frac{x}{2}}\right)\right]}^{2\cos^3\left[\arcsin\left(\sqrt[3]{\frac{x}{2}}\right)\right]}(1-2y)dy\right]dx
& = \int_{-2}^24\cos^3\left[\arcsin\left(\sqrt[3]{\frac{x}{2}}\right)\right]dx
\end{align}
and, I mean, give me a break.  There's got to be a better way, right?",['multivariable-calculus']
1107204,"integral $\int \sqrt{x^4+x^3} \, dx$","$$
\int \sqrt{x^4+x^3} \, dx?
$$ Using the binomial method and by setting $\frac{1}{x}+1=t$, I get to solve $$
\int \frac{-t^{\frac{3}{2}}}{(t^2-1)^4} dt? 
$$
It is on degree $\frac 32$. How to solve this it seems a bit hard and impossible.","['calculus', 'integration']"
1107210,"Metrics on $\mathbb R^n$, Counting continuous functions and Open sets","Given the set $\mathbb{R}^n$ with metric $d$. We define continuous functions from $\mathbb{R}^n$ to $\mathbb{R}^n$ by open sets -we say that function is continuous iff the pre-image of every open set is open. Let's say that number of open sets in $(\mathbb{R}^n,d)$ is $\mathfrak{c}$. Does that imply that the number of continuous function in $(\mathbb{R^n}, d)$ is $2^\mathfrak{c}$? Or maybe $\mathfrak{c}$? What if number of open sets is $2^\mathfrak{c}$? Is it an open problem or known one?","['general-topology', 'metric-spaces', 'elementary-set-theory']"
1107212,An Illustrated Classification of Knots.,"Let me be honest here: I know very little about Knot Theory . I'm sorry. I've a friend though, someone with no training in Mathematics at all but who is a huge fan of knots (for whatever reason), who knows even less than I do about it, apparently. Thus I'd like a book or something as a gift we'd both enjoy: an illustrated classification of knots up to some large order, say, like this: , which I found here . Do you have any ideas? They don't have to be books. Please help :)","['book-recommendation', 'general-topology', 'knot-theory', 'art', 'online-resources']"
1107216,A simple lemma on divisors...,"Let $D$ be a strictly positive divisor defined on a compact Riemann Surface such that $\operatorname{dim} \mathfrak{L}(D)=1+\operatorname{deg} D$. There exists a point $p \in X$ such that $\operatorname{dim} \mathfrak{L}(p)=2$? Firstly, we observe  that $\operatorname{codim} \mathfrak{L}(p) \le \operatorname{deg}D-1$ (this is the consequence of the exercise V.3.I by Miranda), so, using the hypothesis and the definitions, we obtain $\operatorname{dim} \mathfrak{L}(p) \ge 2$. I complete the proof if I can show that $\operatorname{codim} \mathfrak{L}(p) = \operatorname{deg}D-1$, that is if I can show the existence of a divisor $D$' such that $\operatorname{deg}D$'$=\operatorname{deg}D-1$ and $D-D$'$=p$. Now, $D$ is linearly equivalent to a divisor $p_1+\dots+p_{\operatorname{deg}(D)}$. May I take the divisor $D$'$=p_2+\dots+p_{\operatorname{deg}(D)}$ to finish the proof?","['divisor-sum', 'algebraic-geometry', 'algebraic-curves']"
1107230,Why is positive (semi-)definite only defined for symmetric matrices?,"When we are defining positive (semi-)definite matrices, we do so for symmetric matrices only. Why do we need symmetry in the definition?","['matrices', 'linear-algebra']"
1107231,Does this sequence of polynomials have a limit?,"Consider the sequence of polynomials $p_n$ defined as follows: $p_n$ is the unique polynomial of degree $2n+1$ satisfying $$p_n(0) = 0$$
$$p_n(1) = 1$$
$$p_n^{(k)}(0) = p_n^{(k)}(1) = 0 \text{ for $k=1$ to $n$}$$ where $p_n^{(k)}$ is the $k$th derivative of $p_n$. For example, $$p_0(x)=x$$
$$p_1(x)=-2 x^3+3 x^2$$
$$p_2(x)=6 x^5-15 x^4+10 x^3$$
$$p_3(x)=-20 x^7+70 x^6-84 x^5+35 x^4$$
$$p_4(x)=70 x^9-315 x^8+540 x^7-420 x^6+126 x^5$$
$$p_5(x)=-252 x^{11}+1386 x^{10}-3080 x^9+3465 x^8-1980 x^7+462 x^6$$ To give some intuition, here is an animated plot of $p_n$ for $n=0$ to $50$. How can I determine, with proof, $\lim_{n \to \infty} p_n(x)$ (if it exists)? I've never worked with functions implicitly defined in this way before, and I have no idea where to begin.","['polynomials', 'limits']"
1107239,"nilpotent elements of $M_2(\mathbb{R})$, $M_2(\mathbb{Z}/4\mathbb{Z})$",Let $R$ be a ring. We define $\mathfrak{N}(R)$ to be the set of nilpotent elements in $R$ . Find $\mathfrak{N}(R)$ for: $R = M_2(\mathbb{R})$ $R = M_2(\mathbb{Z}/4\mathbb{Z})$,"['ring-theory', 'nilpotence', 'abstract-algebra', 'matrices', 'linear-algebra']"
1107263,Is there a monotonic $f$ such that $\sum f(n)$ diverges but $\sum f(p)$ converges?,"(where the former summation is over natural numbers $n$ and the latter is over prime numbers $p$, and $f: \mathbb{N} \to \mathbb{R}$ is a monotonic function.) For the class of functions $f_s(n) = \frac 1 {n^s}$, the sum over the primes converges iff the sum over $\mathbb{N}$ does (and this question perturbs this class of functions by asking about the case $f(n) = \frac 1 {n^{1+\frac 1 n}}$, but again both sums diverge). Indeed, the fact that $\sum \frac 1 p$ diverges is often viewed as a strengthened version of the fact that there are infinitely many primes, saying that the primes are ""not too far"" from being dense in $\mathbb{N}$. But since the primes are not dense in $\mathbb{N}$, I'd expect that there should be reasonable functions $f$ whose sum over the primes converges while the sum over $\mathbb{N}$ diverges. (The monotonicity condition I've imposed on $f$ is meant to rule out ""stupid"" examples such as the characteristic function of the composite numbers. But if there are ""non-stupid"" non-monotonic examples, I'd be interested to hear about that too.) I haven't thought about this question enough to see whether the prime number theorem will be all that matters or whether more refined information will be relevant.","['analytic-number-theory', 'number-theory']"
1107280,"Are all functions $f:\mathbf{Z}\to\mathbf{Z}$ ""continuous""?","I read the following definitions in Glen E. Bredon's ""Topology and Geometry"": Let $\mathbf{x},\mathbf{y}\in\mathbf{R}^n$ and $$
\text{dist}\left(\mathbf{x},\mathbf{y}\right)=\left(\sum_{i=1}^n\left(x_i-y_i\right)^2\right)^{1/2}.
$$ Moreover, let $f:\mathbf{R}^n\to\mathbf{R}^k$ be continuous at
  $\mathbf{x}\in\mathbf{R}^n$ if $$
\forall\epsilon>0,\exists\delta>0\ni\text{dist}\left(\mathbf{x},\mathbf{y}\right)<\delta\implies\text{dist}\left(f\left(\mathbf{x}\right),f\left(\mathbf{y}\right)\right)<\epsilon.
$$ Using these definitions, can I prove that all functions $f:\mathbf{Z}\to\mathbf{Z}$ are ""continuous"" by setting $\delta=1$? I.e., $\text{dist}\left(\mathbf{x},\mathbf{y}\right)<1$ implies that $\mathbf{x}=\mathbf{y}$ and therefore $\text{dist}\left(f\left(\mathbf{x}\right),f\left(\mathbf{y}\right)\right)=0<\epsilon$. Am I correct? Although this fact may be useless, I am trying to ensure that my understanding of these concepts is sound.","['general-topology', 'real-analysis', 'analysis']"
1107286,"Given a line, calculate a perpendicular line to make a T shape","I am working with SVG vector graphics, and I want to make a dynamic T shape by adding a perpendicular line. I have a line with two points (4,17) and (11,3). How can I figure out (x1,y1) and (x2,y2)? The distance between (x1,y1) and (x2,y2) is 10, and the midpoint of the new line is (11,3)","['geometry', 'graphing-functions']"
1107298,How can I complete this proof by contradiction?,"This problem is from Discrete Mathematics and its Applications : Prove that there are no solutions in  integers $x$ and $y$ to the equation $2x^2 + 5y^2 = 14$ . I am trying to use proof by contradiction, which is described by the book as Suppose we want to prove that a statement $p$ is true. Furthermore, suppose that we can find a contradiction $q$ such that $\lnot p \implies q$ is true. Because $q$ is false, but $\lnot p \implies q$ is true, we can conclude that $\lnot p$ is false, which means that $p$ is true. How can we find a contradiction $q$ that might help us prove that $p$ is true in this way? Because the statement $r \land \lnot r$ is a contradiction whenever $r$ is a proposition, we can prove that $p$ is true if we can show that $\lnot p \implies (r \land \lnot r)$ is true for some proposition $r$ . Proofs of this type are called proofs by contradiction . Because a proof by contradiction does not prove a result directly, it is another type of indirect proof. Here is my work/thought process: My initial proposition, $p$ , is that there are no solutions in integers $x$ and $y$ to the equation $2x^2 + 5y^2 = 14$ . I know that by proof by contradiction, I have to assume that the proposition isn't true, $\lnot p$ , meaning there is a solution to $x$ and $y$ in the equation and show that assuming this leads to a contradiction (something that always evaluates to false, no matter the input values). First, I recognized that for the sum be even, $14$ , the two components, $2x^2$ and $5y^2$ have to be even as well. I am able to show that $2x^2$ is even from the definition of even, that is, there is some integer $k$ such that $2x^2 = 2k$ . $k$ would be $x^2$ . However I have a hard time showing that $5y^2$ cannot be even. I first tried the same definition, meaning $k = (5/2) y^2$ but this wouldn't be an integer. However it is possible for $5y^2$ to be even, say $y = 10$ . Am I going about this the right way? Is the even + even justification appropriate for this situation?","['alternative-proof', 'discrete-mathematics', 'proof-verification']"
1107314,Questions about the Fourier transform as a unitary transform,"As far as I know, the Fourier transform is a (linear) unitary transform: $T: \textbf{L}^2(-\infty, +\infty) \rightarrow \textbf{L}^2(-\infty, +\infty)$ where the basis functions {$e^{i \omega x} | \omega \in \textbf{R}, x \in \textbf{R}$} are not $L^2$-functions. Question 1 : does there exist such set of $\textbf{L}^2$ integrable basis in the $\textbf{L}^2(-\infty, +\infty)$? If it does exist, e.g. {$f(x) | x \in \textbf{R}$}, the Fourier transform of this set of basis must be a transform of basis in $\textbf{L}^2(-\infty, +\infty)$, since the $T$ is unitary - am I right? ( a little stretch on question 1: if there exist infinite number of sets of such basis, is there any general constructing/generating method to find one set of such basis? ) Question 2 : the basis element $e^{i \omega x} \notin \textbf{L}^2(-\infty, +\infty)$, however, the Dirac $\delta$-function as follows: $\delta(x - y) = \int_{-\infty}^{+\infty} {
\frac{e^{i \omega x}}{\sqrt{2\pi}}
\frac{e^{-i \omega y}}{\sqrt{2\pi}} d \omega}$ can be viewed as the Fourier (unitary) transform of the very own basis {$e^{i \omega x}$}. The Dirac functions {$\delta (x - y)$} can be viewed as the sort of ""singular"" basis (with the ""singular"" support). Interestingly, the $\delta (x - y)$ is $\textbf{L}^2$ integrable. Now the question about the uniqueness - is this the only possible ""basis transformation"" on the basis {$e^{i \omega x}$}? If not, what else can we have? Given that I am not familiar with the relationship of the Fourier analysis and Hilbert spaces (yet willing to learn), what resources/books would you recommend, if I need to learn more?","['online-resources', 'hilbert-spaces', 'fourier-analysis', 'functional-analysis']"
1107353,Does PSD imply on average diagonal dominant?,"Suppose $A$ is a $N \times N$ positive semidefinite matrix.   This does not necessarily imply that $A$ is diagonally dominant.  But does it imply the following ""average diagonal dominance"" i.e. $$\frac{1}{N} \sum_{i}A_{i,i}\ge \frac{2}{(N-1)N} \sum_{j=1}^{N}\sum_{i<j}A_{i,j}\text{ ?}$$","['matrices', 'linear-algebra']"
1107356,Example for a sequence of continuous functions which converge to a continuous function pointwise but not uniformly on a compact set.,"My actual aim is to verify that each of the conditions in Dini's theorem is essential or not.Theorem says that  A sequence {$f_{n}$} of continuous functions defined on a compact set $E$  converges to $f$ point wise  satisfying the following properties :
$f_{n}$ is monotonic 
and $f$ is continuous. 
Then {$f_{n}$} converges to $f$ uniformly. So there are three hypothesis are used in theorem compactness of $E$ , continuity of $f$ and monotonicity of $f_{n}$ .
First one is essential because $f_{n}= \frac{1}{1+nx}$ defined on open interval $(0,1)$ converge to $o$ point wise but not uniformly.Second condition cannot be omitted since $f_{n}=x^{n}$ defined on $[0,1]$ converges to a discontinuous function. Left out one is monotonicity.For that I need to construct a sequence of functions which are continuous, non-monotonic,and converges point wise to a continuous function.But convergence should not be uniform. I could not get such a sequence.","['uniform-convergence', 'examples-counterexamples', 'real-analysis']"
1107362,Poincare disk and Poincare half plane,"My book claims that the Möbius transforms are isometries of the Poincaré half plane model. Thus, the metric is preserved under these maps. But I know that the Poincaré disk can be derived from applying such a transform to the half plane model. Now, I think it is well-known that the metric tensors of the half plane model and the disk are very different. This means that there is something wrong with my understanding of the statement given in my book.","['differential-geometry', 'mobius-transformation', 'hyperbolic-geometry', 'complex-analysis']"
1107366,"If the red curve is an ellipse, is the green curve also an ellipse? [duplicate]",This question already has an answer here : Enlarging an ellipses along normal direction (1 answer) Closed 9 years ago . See the figure below: The red curve is an ellipse; the blue curve is a unit circle. Green curve is the locus of the circle center. Is the green curve an ellipse?,['geometry']
1107388,Mathematical induction involving inequalities and congruences,"I have the following two problems: ""Prove each of the following statements by induction for all positive integers $n$:"" $2\cdot7^n \equiv 2^n\cdot(2+5n) \bmod 25 \quad$ <-- I have been going at this question for a couple of hours and can't seem to come up with an answer. $\frac{(2n)!}{(n!)^2} \leq 4^n \quad$ <-- This one I have an answer to, but I am curious if it's valid! I'll attach a picture to show my work, but I would really like some help with question 1; I'm having a lot of trouble with that one.","['induction', 'discrete-mathematics', 'number-theory']"
1107389,"Let A1,A2,...,An be distinct subsets of a set X. Then there is subset Y with size <=n-1, s.t. all intersections are all distinct.","Let $A_1,A_2,\dotsc,A_n$ be distinct subsets of a set $X$. Then there is subset $Y$ with size $\le n-1$, s.t. all intersections of $A_i$ with $Y$ are all distinct. I am trying to prove it with induction, but I already got stuck at the base case.
When there are only two sets, how could I construct a set Y such that it satisfies the condition?",['elementary-set-theory']
1107400,Can anyone sketch the proof or provide a link that there is always a prime between $n^3$ and $(n+1)^3$,"In a recent forum discussion on number theory, it was mentioned that A. E. Ingham had proven that there is always a prime between $n^3$ and $(n+1)^3$. Does anyone know if there is a link available on the web or knows a rough sketch of the proof.  Does it use sieve theory? I am very interested in checking out the proof.","['prime-numbers', 'sieve-theory', 'number-theory']"
1107403,Why is this not a function?,"This problem is from Discrete Mathematics and its Applications This is the definition that the book gave of function Here is my work so far It's pretty clear to me that 1b and 1c are not functions because in each case one element of R is not assigned exactly one element of R( sqrt(x) -> +sqrt(x) and -sqrt(x) ).   Why is 1a not a function though? For the ones I tried, a unique element of R was assigned to another unique element of R (4->1/4,  3-> 1/3). In the explanation, would it be possible to give each R a subscript, like you're mapping from R1 to R2? I feel like R to R is kind of confusing. I understand why the author chose not to use the subscripts though - real is the same as real","['real-numbers', 'discrete-mathematics', 'functions']"
1107405,"In the formula $Ax+By=C$, is it true that $A$ and $B$ can't both be zero? If so, why not?","I read in a math book that in the formula $Ax+By=C$, I read that $A$ and $B$ can't both be zero.  I think C will also be zero because anything times zero equals zero and on a graph, the x- and y- intercepts will both be zero meaning the two points will be at ($0$, $0$), so then we wouldn't be able to draw a line for our graph, meaning it would be undefined.  Is this why the two mentioned variables can't both be zero?",['algebra-precalculus']
1107409,Help with a Royden exercise of measure,"I'm solving the exercise 12, of section 4 The General Lebesgue Integral from the Royden's book Real Analysis 3rd edition: Let $g$ be an integrable function on a set $E$ and suppose that $(f_n)$ is a sequence of measurable functions such that $\vert f_n(x)\vert \leq g(x)$ a.e. on $E$. Then
$$\int_E \underline{\lim}f_n \leq \underline{\lim}\int_E f_n$$ I've been able to prove it using Fatou's lemma, but my math teacher asked to prove it with dominated convergence theorem, and I can't do it. Is it possible? I'll appreciate any suggestions, thanks!","['alternative-proof', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1107428,Probability of no students being mechanical engineers,"In a class of 100 students, 30 are computer science majors, 49 are mechaincal engineering majors, 13 are civil engineers and the rest are general engineering majors. Assume students only have one major. Suppose five students from the class are chosen at random what is the probability none are mechanical engineering majors? My info I know: The mechanical engineers account for 49% of the students, making 51% not mechanical engineers? Do I take five out of the 51, so 0.05 X 0.51?",['statistics']
1107444,Is this expression even a function?,"This is from Discrete Mathematics and its Applications My question is on 22c. 
From the book, I inferred from the question that all of the listed mathematical expressions are functions.
Is the mathematical expression $(x + 1)/(x + 2)$ even a function though? What I got from my other question, Why is this not a function? was that 
a function needs to have exactly one output from every possible input in the domain. However this function doesn't have an output for $x = -2$, which is the domain of $\mathbb{R}$.","['discrete-mathematics', 'functions']"
1107449,On Fredholm operator on Hilbert spaces,"Let $u: H \to H'$ be a continuous linear operator and $H,H'$ be Hilbert spaces. Let $u^\ast$ denotes its adjoint. By definition, an operator $u$ is called Fredholm if and only if $\ker u$ has finite dimension and $\mathrm{im}(u)$ has finite codimension. My book states that ""...$u$ is Fredholm if and only if $u(H)$ is closed and $\ker u$ and $\ker u^\ast$ are both finite dimensional"" I am not sure but I beleive that closedness of $u(H)$ is redundant, that is, the following is true: $u$ is Fredholm if and only if $\ker u$ and $\ker u^\ast$ are finite-dimensional. My proof: $\implies$: If $u$ is Fredholm then by definition $\ker u$ is finite dimensional. Also, $(u(H))^\bot =\ker u^\ast$. If $V$ is a vector space and $U$ a subspace then the dimension of all complements of $U$ are equal, in particular, equal to the orthogonal complement. Hence $\ker u^\ast$ is finite dimensional. $\Longleftarrow$: Let $\ker u$ and $\ker u^\ast$ be finite dimensional. By the same argument as before, $u(H)$ has finite codimension. Since $\ker u$ is finite dimensional it follows that $u$ is Fredholm. Where is the mistake in my proof? What am I missing here?","['operator-theory', 'functional-analysis']"
1107460,Formula for encountering C different marbles out of D total draws,"Say we draw $D$ marbles out of a bag (with infinite marbles), where each marble could be one color out of $C$ colors (each with equal probability). What is the expected value of the number of different colors our total draw includes? So for example, if $D=4$ and $C=3$, we are drawing $4$ marbles total, where each could be red, green, or blue with equal likelihood. What is the average number of different colors represented in our draw (anywhere from $1$ to $3$) we can expect to have? After playing around, I came up with the following way to express it: $$E[C;D] = \frac{1}{C^D} \big[ (1)(C) + (2)(\text{number of arrangements of two different colors}) + ... + (C)(\text{number of arrangements of $C$ different colors}) \big]$$ And after testing with some low numbers, I came up with the following formula: $$E[C;D] = C - \frac{(C-1)^{D}}{C^{D-1}}$$ It works for the numbers I tested, and also makes intuitive sense since $\lim_{D \rightarrow \infty}E[C;D] = C$. But I'm curious to know: Is this formula correct? If so, how can I prove it?",['probability']
1107464,Fourth Order Homogeneous Ordinary Differential Equation With Double Complex Conjugate Roots (2.10-14),"This is actually a problem in algebra as shall be seen. I need to find the general solution for the following differential equation: $$y''''+8y''+16y=0$$ The characteristic equation for this is: $$\lambda^4+8\lambda^2+16=0$$ Factoring out gives us: $$(\lambda^2+4)^2=(\lambda^2+4)(\lambda^2+4)=0$$ This generates a set of double complex conjugate roots $\lambda_{1,2}=\pm i2$ and $\lambda_{3,4}=\pm i2$ The general solution I get is: $$y=A\cos(2x)+B\sin(2x)+xC\cos(2x)+xD\sin(2x)$$ Is this correct? If not please explain in detail where I went wrong. Thank you so much.","['roots', 'ordinary-differential-equations', 'calculus', 'algebra-precalculus']"
1107465,Showing ${n + a - 1 \choose a - 1} = \sum_{k = 0}^{\left\lfloor n/2 \right\rfloor} {a \choose n-2k}{k+a-1 \choose a-1}$,"Prove that for integers $n \geq 0$ and $a \geq 1$, $${n + a - 1 \choose a - 1} = \sum_{k = 0}^{\left\lfloor n/2 \right\rfloor} {a \choose n-2k}{k+a-1 \choose a-1}.$$ I figured I'd post this question, which was on an assignment I did, since I thought the solution was so nice.","['summation', 'binomial-coefficients', 'multisets', 'combinatorics']"
1107478,Why do a set of continuous transformations form a manifold?,"I am reading Sean Caroll's book on GR, and he defines manifolds to be ""a space that may be curved and have a complicated topology, but in local regions looks just like R $^n$. Here by ""looks like"" we do not mean that the metric is the same, but only that more primitive notions like functions and coordinates work in a similar way"" (Carrol). Hence, manifolds are a type of space with certain properties. However, later on he states that ""a set of continuous transformations such as rotations in R $^n$ form a manifold."" Why are the set of continuous transformations a manifold? In other words, how do we prove that the set of continuous transformations a manifold?","['manifolds', 'transformation', 'differential-geometry']"
1107498,why does the integral of convolution equal to the product of their integral separately?,"$(f*g)(x)$ is called convolution and is the integral of $f(x-y)g(y)$ with respect to $y$ on $\mathbb{R}^n$.
But why the integral of $f*g$ is equal to product of integral of $f$ and $g$. Wiki says it follows from Fubini's Theorem but I don't see why.","['convolution', 'integration', 'analysis']"
1107507,What is the remainder when polynomial $f(x)$ is divided by $(x+1)(x-3)$ when $f(-1) = -4$ and $f(3) = 2$?,A polynomial $f(x)$ gives remainder $2$ when divided by $(x-3)$ and gives a remainder $-4$ when divided by $(x+1)$. What is the remainder when $f(x)$ is divided by $(x^2 - 2x - 3)$? I have shortened the question by: 1.Showing that $f(-1) = -4$ and $f(3) = 2$ by remainder theorem respectively. 2.Figured out that $(x^2 - 2x - 3)= (x-1)(x-3)$.,"['algebra-precalculus', 'polynomials']"
1107570,$-\Delta u - \alpha u^{1/3} = 0$ implies $u \equiv 0$ if $\alpha$ is small,"Let $\Omega$ be a domain in $\mathbb{R}^{d}$ with smooth boundary. Let $u(x)$ be a $H^{1}(\Omega)$ solution of the equation $-\Delta u - \alpha u^{1/3} = 0$, $u|_{\partial \Omega} = 0$. The problem I am working on is to show that $u \equiv 0$ if $\alpha > 0$ is small. The hint in this problem is to use Poincare's Inequality. Multiplying the given PDE by $u$, we have $-u\Delta u - \alpha u^{4/3} = 0$. Then $$0 = \int_{\Omega}-u\Delta u - \alpha u^{4/3}\, dx = \int_{\Omega}|\nabla u|^{2} - \alpha u^{4/3}\, dx$$ and hence $\alpha\int_{\Omega}u^{4/3}\, dx = \int_{\Omega}|\nabla u|^{2}\, dx \geq \frac{1}{C}\int_{\Omega}u^{2}\, dx$ where $C$ is the constant from Poincare's Inequality. Rewriting, this implies $$\int_{\Omega}u^{2/3}u^{4/3}\, dx \leq C\alpha\int_{\Omega}u^{4/3}\, dx$$ and then
$$\int_{\Omega}u^{4/3}(C\alpha - u^{2/3})\, dx \geq 0.$$ My question is: Are there suggestions on how to finish? Am I approaching this problem correctly?","['sobolev-spaces', 'partial-differential-equations', 'analysis']"
1107604,Convergence of a sequence with assumption that exponential subsequences converge?,"Problem One of my best friends asked me to think about the following problem: Suppose a sequence $\{a_n\}_{n=1}^\infty$ satisfies $\lim_{n\to\infty}a_{\lfloor\alpha^n\rfloor}=0$ for each $\alpha>1$. Is it true that $\lim_{n\to\infty}a_n=0$? He told me that the preceding proposition (if true) implies Kolmogorov's strong law of large numbers in probability theory. I don't know how, but it's irrelevant. Thoughts Suppose $E\subseteq(1,+\infty)$ is countable (for example, $E=(1,+\infty)\cap\mathbb Q$) and $\lim_{n\to\infty}a_{\lfloor\alpha^n\rfloor}=0$ for each $\alpha\in E$, we cannot conclude that $\lim_{n\to\infty}a_n=0$. In fact, we can choose an infinite set $S\subseteq\mathbb Z_{>0}$ such that $S\cap\{\lfloor\alpha^n\rfloor\colon n\in\mathbb Z_{>0}\}$ is finite for each $\alpha\in E$ as follows: Suppose $E=\{\alpha_1,\alpha_2,\dotsc\}$. We choose $S$ inductively. Suppose $T_0=\mathbb Z_{>0}$. Given $T_{n-1}$, we set $s_n=\min T_{n-1}$ and $T_n=(T_{n-1}\setminus\{\lfloor\alpha_n^k\rfloor\colon k\in\mathbb Z_{>0}\})\setminus\{s_n\}$. By a density argument, it's easy to see that $T_n$ are infinite therefore the process doesn't terminate. Let $S=\{s_n\colon n\in\mathbb Z_{>0}\}$. It's apparent that $\#(S\cap\{\lfloor\alpha_n^m\rfloor\colon m\in\mathbb Z_{>0}\})\le n$. Given $S$, we set $a_n=1/n$ if $n\not\in S$, and $a_n=1$ if $n\in S$, then $\lim_{n\to\infty}a_{\lfloor\alpha^n\rfloor}=0$ for each $\alpha\in E$, but $\lim_{n\to\infty}a_n$ doesn't exist. Here we choose $S$ by a diagonal process, therefore we cannot mimic the construction when $E$ is uncountable. In fact, the falsehood of the original statement is equivalent to the existence of $S$, therefore it's essential combinatorial, or related to some topological structure of $\mathbb Z_{>0}$ (say, compactness or Baire category, etc). I have no idea on the general case. Any idea? Thanks!","['general-topology', 'sequences-and-series', 'real-analysis', 'combinatorics']"
1107615,How many of these are topologies?,"Let $X$ be a set with $3$ elements. The set of subsets of the power
  set of $X$ is $2^{2^3}$ elements. How many of these are topologies? Is there a trick to this problem, or is it just a ""plug and chug"" casework thing?",['general-topology']
1107623,IVP of second order linear ODE,"Bumps are often built into roads to discourage speeding. Consider a
  crude model of the vertical motion $y(t)$ of a car encountering the
  speed bump with the speed $V$ is given by $$y(t)=0   \qquad\text{for}\;
 t \leq -L/(2V)$$ $$my''+ky= \begin{cases} F_0\cos(\pi Vt/L) & 
 \text{for}\, |t|<L/(2V)\\ 0                          & \text{for}\,t
 \geq L/(2V) \end{cases}$$ Taking $m=k=1, L=\pi,$ and $F_0 =1$ in
  appropriate units, solve $y(t)$. It reduces to solving $y''+y=\cos(Vt)$. The usual method of undetermined coefficients applies and I get the following, which check with that from Wolfram Alpha:
$$y(t)= \begin{cases} \frac{\cos(Vt)}{1-V^2}+A \cos t + B\sin t &
 \text{if}\, V \neq 1\\ \frac{t \sin t}{2} +A \cos t + B\sin t         &
\text{if}\,V = 1 \end{cases}.$$ When I check the solution provided by the book, I find this:
$$y(t)= \begin{cases} \frac{2V \cos (\pi / 2V)}{V^2-1} \sin t &
 \text{if}\, V \neq 1\\ \frac{\pi}{2} \sin t         &
\text{if}\,V = 1 \end{cases}.$$ I cannot proceed to find these solutions. I tried substituting $t=-\frac{\pi}{2V}$, but I have two unknowns. What am I missing here? Thanks in advance.",['ordinary-differential-equations']
1107682,Elementary proof of the fact that any orientable 3-manifold is parallelizable,"A parallelizable manifold $M$ is a smooth manifold such that there exist smooth vector fields $V_1,...,V_n$ where $n$ is the dimension of $M$, such that at any point $p\in M$, the tangent vectors $V_1(p),...,V_n(p)$ provide a basis for the tangent space at $p$. Equivalently, a manifold is parallelizable if its tangent bundle is trivial. There is a theorem that states that any compact orientable 3-manifold is parallelizable, and 
there is a proof of this result which uses $spin^c$ structures and the Steifel-Whitney class. I am wondering whether there exists a more elementary, perhaps more straightforward proof. Otherwise, I would be grateful for some intuition on why this is true.
Also, it the theorem still true without the compactness assumption? If so, is there a relatively simple proof in that case?","['characteristic-classes', 'differential-geometry', 'fiber-bundles', 'smooth-manifolds', 'intuition']"
1107702,$\aleph_0 \aleph_1 =\aleph_1$? But I don’t know any way to prove or disprove it,What is the value of $\aleph_0 \aleph_1$? Clearly $\aleph_0\le \aleph_1$ implies $\aleph_0=\aleph_0\aleph_0\le \aleph_1 \aleph_0$ and again $\aleph_0 \aleph_1\le \aleph_1 \aleph_1=\aleph_1$. But there is no cardinal number between $\aleph_0$ and $\aleph_1$. So either $\aleph_0 \aleph_1=\aleph_0$ or $\aleph_0 \aleph_1=\aleph_1$. Then....,"['cardinals', 'elementary-set-theory']"
1107722,Questions about decimal expansion being able to represent all real numbers,"I read this in several books, and there's a Wikipedia article unquestionably stating that reals must be representable by means of regular language generated from finite alphabet. My questions are: What would be generated from a regular language with an infinite alphabet? What are the devices we use to extend this alphabet (such as periodic fractions and continued fractions)? I.e. if finite alphabet with just the juxtaposition was enough to construct all reals, what are we constructing when we use periodic fraction notation? If we construct reals as Cauchy sequences, then every term in these sequences is unique and the sequences are infinite: then how come we find a bijection from infinite sequences generated from infinitely many members and sequences generated from finitely many members? Alternate objections: Cauchy sequences (when used in the construction of real numbers) are convergent sequences, which would imply that every real number, written as such a sequence, must converge to something, but isn't this a restatement of the conjecture about normal numbers? I.e. doesn't convergence require that reals must have statistically predictable number of all digits? Since I don't know of that being proved, wouldn't decimal expansion of reals still be a conjecture, not a proved fact? I was trying to read this article: https://www.dpmms.cam.ac.uk/~wtg10/decimals.html which goes into more details about constructing reals in this way, but I don't feel satisfied with the paragraph where it talks about the least upper bound (which I know to be the distinguishing property of real number field, which rationals don't have). But I don't feel satisfied with a proof. It keeps saying ""it's easy to see"" and such, while I don't find it to be easy to see... If you are willing to lay out an answer, just elaborating that part of the article would be enough for me. For example in the mentioned paragraph, the author defines the supremum to be such and such decimal expansion, while I don't think this is a matter of definition. I think that one must prove existence instead. (What would have stopped me from defining a decimal expansion even closer to the extremum than the one the author of the article chose?)","['real-numbers', 'number-theory']"
1107736,Exercise in Probability/Measure Theory,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. Let also $A_{n,j}\in\mathcal{F},n\in\mathbb{N}_0,j\in\{1,2,3,...,2^n\}$, be such that for all $n\in\mathbb{N}_0:\cup_{j=1}^{2^n}A_{n,j}=\Omega$ and: $\forall i,j\in\{1,2,3,...,2^n\}i\neq j:A_{n,i}\cap A_{n,j}=\emptyset$ and $A_{n,i}=A_{n+1,2i-1}\cup A_{n+1,2i}$. Now define: $\mathcal{F}_n=\sigma(\{A_{n,j}:j\in\{1,2,3,...,2^n\}\})$. i.) Prove that $\mathcal{F}$ is a filtration. ii.) Define $\mu:\mathcal{F}\rightarrow[0,\infty)$ probability measure on $(\Omega,\mathcal{F})$. Assume that if $\mathbb{P}(A)=0$, for $A\in\mathcal{F}$ then $\mu(A)=0$.
Define: $M_n(\omega)=\frac{\mu(A_{n,j})}{\mathbb{P}(A_{n,j})},\omega\in A_{n,j},\mathbb{P}(A_{n,j})\neq 0$ and $M_n(\omega)=0$ if $\mathbb{P}(A_{n,j})=0$. Prove that for all $n\in\mathbb{N}_0$ and all $j\in\{1,2,3,...,2^n\}$: $\mathbb{E}(M_{n+1}1_{A_{n,j}})=\mathbb{E}(M_n1_{A{_n,j}})$. For question i.) we need to show that $\mathcal{F}_n\subset\mathcal{F}_{n+1}\forall n$ and also that all $\mathcal{F}_n$ are $\sigma-$algebras. I have already shown that $\Omega\in\mathcal{F}_n\forall n$ and that if $E_n\in\mathcal{F}_n$ then also $\cup_{n=1}^{\infty}E_n\in\mathcal{F}_n$. However I have some hard time showing the condition for the complements. Now for question ii.), first of all if $\mathbb{P}(A_{n,j})=0$ then the equality is obvious. Hence we can assume that $\mathbb{P}(A_{n,j})\neq 0$. Now we have that: $\mathbb{E}(M_{n+1}1_{A{n,j}})=\int M_{n+1}1_{A_{n,j}}=\int \frac{\mu(A_{n+1,j})}{\mathbb{P}(A_{n+1,j})}1_{A_{n,j}}=\frac{\mathbb{P}(A_{n,j})\mu(A_{n,j})}{\mathbb{P}(A_{n+1,j})}$. On the other hand, we have that: 
$\mathbb{E}(M_{n}1_{A{n,j}})=\int M_{n}1_{A_{n,j}}=\int\frac{\mu(A_{n,j})}{\mathbb{P}(A_{n,j}}1_{A_{n,j}}=\mu(A_{n,j})$. I am pretty sure there is something wrong in what I have done, but can not figure out exactly what. Any help would be appreciated.","['probability-theory', 'martingales', 'measure-theory', 'expectation']"
1107771,"If the empty set is a subset of every set, why isn't $\{\emptyset,\{a\}\}=\{\{a\}\}$?","If the empty set is a subset of every set, why it isn't written with the elements of a set? like so $\{1,2,3,\emptyset\}$ Or why isn't $\{\emptyset,\{a\}\}=\{\{a\}\}$? I know one has two elements and the other has 1 but since the empty set is a subset of both, then why it isn't being mentioned explicitly in the definition of the set?","['elementary-set-theory', 'definition']"
1107776,If $x=\pi a y^{1/2}$ then why is $\frac{\partial^n}{\partial x^n}=-2\left(\frac{y^{3/2}}{\pi a}\right)^n \frac{\partial^n}{\partial y^n}$?,"While I was reading this question , I was surprised that the transformation of a 'simple' differential operator $\displaystyle \frac{\partial^n}{\partial x^n}$ by substituting $x=\pi a y^{\frac{1}{2}} $ so that $$\displaystyle\frac{\partial^n}{\partial x^n}=-2\left(\frac{y^{\frac{3}{2}}}{\pi a}\right)^n \frac{\partial^n}{\partial y^n}$$ stumped me; I'm not sure how he derived it. I actually have a simpler question: given $\displaystyle\frac{d^n}{dx^n}$, how will it transform if $x=cu$ where $c$ is a constant? Edit: Here's a very relevant example from wikipedia , I think that the example in the article is essentially the same kind of thing that the OP in the reference link above did. The problem is that I don't really know how to manipulate operators, if I'm allowed to use a ""physicist's"" argument I'd say that for some differentiable function $f$ and if $u=x/c$: $$
\frac{df}{dx}=\frac{du}{dx}\frac{df}{du}=\frac{1}{c}\frac{df}{du}
$$ 
$$
\therefore \frac{d}{dx}=\frac{1}{c}\frac{d}{du}.
$$
Is this even remotely correct? This only addresses the case $n=1$ though, doing the same for latter values seems harder. Edit #2:
The final answer from the original link seems incorrect, the OP's result is:
$$
\frac{\partial^n}{\partial y^n}e^{-\frac{\pi^2a^2}{y}}=\frac{1}{2}e^{-\frac{\pi^2a^2}{y}}(-1)^{n+1}H_n(\pi a y^{-\frac{1}{2}})\left(\frac{y^{\frac{3}{2}}}{\pi a}\right)^n
$$
which is obviously wrong for the smaller values $n=0,1$ (since $H_1(x)=2x)$.","['partial-derivative', 'calculus', 'coordinate-systems', 'derivatives']"
1107784,"Why is the ""i"" disappearing?","The task is: Find the argument in its simplest form. 
  $$(\sin(x) +i(1-\cos(x)))^2$$
  where $x$ is an acute angle. I multiplied out the equation and let alpha be the required argument, then said that
$$\tan(\alpha) = \frac{2i\sin(x)(1-\cos(x))}{\sin(x)^2-(1-\cos(x))^2}.$$ However, the solutions says the same thing except there is no $i$ in $2i\sin(x)(1-\cos(x))$. So I was wondering where the $i$ went?","['trigonometry', 'algebra-precalculus']"
1107893,For which values of $a$ the matrix is diagonalizable,"Given the following matrix: $$B=\begin{bmatrix} 1 & 0 & 0 \\ 1 & 0 & a^2 \\ 1 & 1 & 0 \end{bmatrix}$$
I tried to find for which values of $a$, the matrix $B$ is diagonalizable. I found that the characteristic polynomial is: $P_B(x) = (1-x)(x+a)(x-a)$. ( Stop reading here and skip to the Edit section below ) Therefore I tried to find the eigenspace for each eigenvalue, but eventually concluded that: for $a=(-1)$, the eigenspaces are linearly dependent. for $a=1$, the trace of the diagonal form matrix (call it D ) isn't equal to the trace of the matrix that's composed of the eigenvectors (call it Q ). (' a ' must be 1 or (-1) according to the homogeneous equations with which I found the eigenspaces) The diagonal form matrix that I have found ( D ):
$$D=\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -1 \end{bmatrix}$$ The matrix that's composed of the eigenvectors that I have found ( Q ):
$$Q=\begin{bmatrix} 0 & -1 & 0 \\ 1 & 2 & -1 \\ 1 & 1 & 1 \end{bmatrix}$$ Edit: I have found a mistake in the row reduction process of the matrices...
So now we have: The diagonal form matrix ( D ):
$$D=\begin{bmatrix} 1 & 0 & 0 \\ 0 & a & 0 \\ 0 & 0 & -a \end{bmatrix}$$ The matrix that's composed of the eigenvectors ( Q ):
$$Q=\begin{bmatrix} 1-\frac{a^2+1}{2} & 0 & 0 \\ \frac{a^2+1}{2} & a & -a \\ 0 & 1 & 1 \end{bmatrix}$$ D and Q should be similar, thus by comparing their trace, I have found that:
$a_1=(1+\sqrt{2})$ and $a_2=(1-\sqrt{2})$. Does it make sense? Edit2 - To conclude: I was confused about the relations between the matrices $B,Q \text{ and }D$: At first I thought that matrices $Q \text{ and }D$ must be similar, but that isn't necessarily true! Only matrices $B \text{ and }D$ must be similar. Edit 3 - Response to Marc: I understood everything until the last sentence. Also I tried an example using Wolfram Alpha on this matrix . Does it have something to do with a nilpotent characteristic of the matrix? Indeed I can compute $(B-pI)(B-qI)$ and also could've seen with the example that it's true, but don't understand the rules (or characteristics) which allow this to be true.","['trace', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'diagonalization']"
1107895,The value of $\lim_{n\to \infty}\int_{-\infty}^{\infty}f(x)\cos^{2} nx dx.$,"Using the fact  $\lim_{n\to \infty}\int_{-\infty}^{\infty}f(x)\cos nx dx=0$ ,find the value of $$\lim_{n\to \infty}\int_{-\infty}^{\infty}f(x)\cos^{2} nx dx.$$ I tried through integrating by parts , also through the $1^{st}$ Mean Value Theorem of integral calculus but I c","['improper-integrals', 'integration', 'definite-integrals', 'real-analysis', 'analysis']"
1107926,"Invertible ""Sigmoid + x"" function","I need an invertible function that represents a smooth transition between two straight, parallel line segments, like this: Depicted is $f(x) = -0.3/(1+e^{-10*(x-p)})+0.3/2+x$ (where $p$ is the location of the lowest slope), but it does not seem to be invertible in terms of standard mathematics. Can you recommend a function that looks similar, but is invertible?","['inverse', 'functions']"
1107957,Points at which partial derivatives exist and are continuous,"Given $ E = (xy : xy \neq 0 ) $ . Let $ f : \mathbb R^{2}\longrightarrow \mathbb R$ be defined by 
$$f(x,y)=\cases{0,& if $xy=0$\\y\sin\left(\frac{1}{x}\right)+x\sin\left(\frac{1}{y}\right),& otherwise} .$$ Let $ S_1  $ be set of points in $ \mathbb R^{2}$  , where $f_x$ exists and $S_2 $ be set of points where $ f_y$ exists . Let $E_1$ be points where partial wrt x is continous and $E_2$ be set of points where $f_y$ is continous I heed to determine what $S_i$ and $E_i$ are, $i=1,2 $ ATTEMPT : I calculated partial derivatives as $f_x$ = $ -(y/x^{2}) \cos(1/x) + x\sin(1/y)$ $f_y = \sin1/x - (x/y^{2} )\cdot\cos (1/y) $ These both partials do not exist at X axis and Y axis and origin. At other points in xy plane they exist. Same for continuity. Is that enough, I'm not confident? Can anyone please elaborate? Thanks","['multivariable-calculus', 'partial-derivative']"
1107978,Expected value of an exponential of a gaussian random variable,"$$E (Y_t)=E(e^{X_t}) = E(e^{N(X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)}) =\text{ ?}$$ Knowning that $$X_t \sim N\left[X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)\right]$$ $$X_t= aX_t \, dt+b \, dB_t$$ The processes are standard brownian motions.
Thank you","['statistics', 'stochastic-processes']"
1108007,"Integration: $\;\int \frac{1}{2-x^2}\,dx$","Sorry to ask about a (probably) faily easy task, but I am new to integrals and can't solve this one: I am trying to calculate $\displaystyle \int \frac{dx}{2-x^2}$. The solution is $\displaystyle \frac{\log(x+\sqrt{2})-\log(\sqrt{2}-x)}{2\sqrt{2}}$, but I don't know how to get there. It must have something to do with the rule $\displaystyle \int \frac{1}{x} = log(|x|)+c$. I thought about writing $\displaystyle \int \frac{1}{(2-x^2)}$ as $\displaystyle \int (2-x^2)^{-1}$, but the rule for potences is not applicable here as it seems, because we would divide by zero. So there must be multiple rules to get to the above term. Which ones would you use?","['calculus', 'integration']"
1108020,Proof for the curl of a curl of a vector field,"For a vector field $\textbf{A}$, the curl of the curl is defined by
$$\nabla\times\left(\nabla\times\textbf{A}\right)=\nabla\left(\nabla\cdot\textbf{A}\right)-\nabla^2\textbf{A}$$
where $\nabla$ is the usual del operator and $\nabla^2$ is the vector Laplacian. How can I prove this relation? I tried the ugly/unefficient/brute-force method, by getting an expression for the LHS and the RHS for an arbitrary vector field $$\textbf{A}=\left(a(x,y,z),b(x,y,z),c(x,y,z)\right)$$ It does work (duh), but is there a more elegant way of doing this? Using matrix notation maybe? EDIT: I got very good answers, from various perspectives. I would say @Spencer's derivation is the one I was looking for, using Einstein notation - and as a physics student, this was very helpful. However, @Vectornaut's solution not only is short and elegant, but it also introduced me to a whole new range of mathematics - and as a theoretical physics student, I appreciate learning new mathematical theories and trying to see how we can use them in physics.","['curl', 'multivariable-calculus', 'vector-analysis', 'vector-fields']"
1108043,Adding two convergent series,"If $\sum_{n=1}^{\infty} a_n$ is finite and $\sum_{n=1}^{\infty} b_n$ is also finite, why is it that you can add the two series term by term and get the sum of the two series?  Surely this is reordering the series.",['sequences-and-series']
1108057,Nipotent matrix over a ring,"This question is linked to this one: nilpotent elements of $M_2(\mathbb{R})$, $M_2(\mathbb{Z}/4\mathbb{Z})$ Let $R$ be a commutative ring with unity and let $A\in M_2(R)$. Show that $A$ is a nilpotent matrix iff $\det(A)$ and $\mathrm{trace}(A)$ are nilpotent elements of $R$.","['matrices', 'linear-algebra']"
1108104,closed point of a locally finite $k$-scheme,"Let $X$ be a locally finite $k$-scheme, where $k$ is a field. 
Suppose I have $Spec B \subseteq X$ such that $B$ is a finitely generated
$k$-algebra, and $p \in Spec B$ a closed point inside $Spec B$ with respect to
the subspace topology. Does it then follow that $p$ is in fact a closed point of X?
Thanks!","['algebraic-geometry', 'schemes']"
1108108,"What's the ""real"" reason a finite map has finite fibers?","This is a soft question. I have encountered two very different proofs of what seems like ""basically the same theorem,"" and I want to understand how they relate and ""what the real explanation is."" Please forgive my imprecision here; but I am extremely interested in your thoughts. In Shafarevich's Basic Algebraic Geometry I , Ch. 1 Sec. 5.3, it is proven that a finite map has finite fibers, i.e.: Let $X,Y$ be quasiprojective varieties over an algebraically closed ground field $k$ , and let $f:X\rightarrow Y$ be a regular map that is finite in the sense that $Y$ admits a cover by affine open subsets $V$ such that $U=f^{-1}(V)\subset X$ is affine for each $V$ , and we have $f^*:k[V]\rightarrow k[U]$ is an integral ring map. Then $f^{-1}(p)$ is a finite set for $p\in V$ . The proof is that since the ring maps are integral, the coordinate functions on $X$ satisfy polynomials over the pullbacks of the coordinate functions on $Y$ , which become actual polynomials over $k$ when an image point in $y$ in a specified $V$ is chosen. These polynomials limit the coordinates on $X$ to a finite set of values. Meanwhile, in Atiyah and MaDonald's Introduction to Commutative Algebra , Ch. 5 Exercises 12-15, the ""same result"" is established in a different setting, namely: If $A$ is an integrally closed domain, $K=\operatorname{Frac}A$ , $L$ is a finite field extension of $K$ , and $B$ is $A$ 's integral closure in $L$ , then the map $\operatorname{Spec}B\rightarrow \operatorname{Spec}A$ coming from the inclusion $A\hookrightarrow B$ has finite fibers. The proof is completely different. We look at $L$ as a purely inseparable extension of a separable extension of $K$ and handle each extension separately. For the separable extension, we embed it in its Galois closure and prove that the Galois group (which is finite) acts transitively on the fibers of the map. The argument uses a form of the Going-Up Theorem and the lemma that if an ideal is contained in a finite union of prime ideals, it is fully contained in one of them. For the inseparable part, we show using a calculation that the map on $\operatorname{Spec}$ s is actually injective. Obviously the scope of the two statements is a little different. For the purposes of this question I don't care about the differences coming from the fact that Shafarevich is dealing with quasiprojective rather than affine varieties, so let's just imagine he's in the affine case. Then he's dealing exclusively with finitely generated algebras over an algebraically closed field, but I don't think he needs to make any assumption of integral closure or domainhood. And his argument is only dealing with the closed points of the $\operatorname{Spec}$ . Meanwhile, Atiyah and MacDonald insist on starting with an integrally closed domain, but there's no assumption that there's some underlying algebraically closed field over which everything is a f.g. algebra. Nonetheless, the two books seem to be trying to tell me, in some sense, ""the same story."" Yet in one case we get the result from the basic fact that the degree of a polynomial bounds the number of its roots over a field (although the Nullstellensatz is sitting in the background to identify the closed points of the $\operatorname{Spec}$ with tuples from the field), while in the other case we have to bring a Galois group and a case handling of separable vs. purely inseparable extensions into it! What's ""the real story"" here? I.e.: How general is the result? Is it true for an arbitrary map of schemes? And what's the general proof? How does it relate to these two proofs? Is there a ""moral"" argument that subsumes both of these arguments? How do you sort this out for yourself? Again, please forgive the softness. I hope the question will be of interest in any case.","['commutative-algebra', 'affine-schemes', 'algebraic-geometry', 'soft-question']"
1108131,What is cos²(x)?,"This looks odd to me. I need a definition.
Is it just the square of $\cos(x) $ ? Like $\ \cos^2(x) = \cos(x) \cdot \cos(x) $ ? Then why don't you write it like that: $\cos(x)^2 $ ?","['notation', 'trigonometry', 'functions']"
1108134,Unbounded stopping time,"Suppose we have a sequence of i.i.d. random variables $(X_n)_{n \in \mathbb{N}}$ with $\mathbf{P}(X_n = -1) = \frac{1}{2}, \mathbf{P}(X_n = 0) = \frac{1}{3}, \mathbf{P}(X_n = 1) = \frac{1}{6}$. Denote $\tau = \inf\{n > 0 : X_1 + \ldots + X_n = 1\}$. Show that $\mathbf{P}(\tau = \infty) = \frac{2}{3}$. As a matter of fact, I have no idea how to approach this question. In the same task I had to prove that $(3^{X_1 + \ldots + X_n}, \sigma(X_1, \ldots, X_n))$ is a martingale but I don't see how it helps in any way to solve the main question, because our stopping time is not bounded.","['probability-theory', 'martingales', 'stopping-times']"
1108153,simplicial approximation and infinite complexes,It is well known that if $X$ is a finite simplicial complex then for every continuous map $f:|X|\to |Y|$ there exists a simplicial map $F: X^{(n)}\to Y$ that $|F|$ is homotopic to $f$. Does anyone know an example of a map $f$ where $X$ is infinite and $f$ cannot be homotopic with geometric realization of any map $F: X^{(n)}\to Y$ and any $n\in \mathbb N$. Or maybe there are some generalizations of the simplicial approximation theorem or there are known theorems that say when a map $f:X\to Y$ can be approximated by a simplicial map $F:X^{(n)}\to Y$? For example for locally finite complexes?,"['general-topology', 'simplicial-complex']"
1108171,Evaluating Integrals using Lebesgue Integration,"Suppose we are to evaluate: $$I = \int_{0}^{1} f(x) dx$$ Where $$f(x)=\begin{cases}1 \space \text{if} \space x\space \text{is rational}, & \newline  0  \space \text{if} \space x \space \text{is irrational} \\ \end{cases}$$ I have been told that this can be done using measure theory. Will anyone care to explain how possibly? I am new to measure theory, so I am just researching, please do not say ""no attempt shown"" this is because I dont know Lebesgue yet, but I heard it has great applications on this?","['calculus', 'integration', 'measure-theory', 'real-analysis', 'lebesgue-integral']"
1108186,"How can we say two algebraic expressions are ""equal"" if one is undefined at certain points and the other isn't?","I'm trying to understand why it is that we can say $\frac{x^2-1}{x-1} = \frac{(x-1)(x+1)}{(x-1)} = x+1$ but then have it also be the case that the two functions $f(x) = \frac{x^2-1}{x-1}$ and $g(x)=x+1$ are not equal, since $f$ is undefined when $x=1$. That is, if it is true that $\frac{x^2-1}{x-1} = x+1$ then why can we not just simplify and say that $f(x)=x+1$ so that $f(1) = (1) + 1 = 2$ ?","['logic', 'quantifiers', 'algebra-precalculus', 'functions']"
1108218,Show that function is bounded,"Show that the function is bounded function
I think it is not (from the graph), but how to prove this?
the functions is $$\frac{1}{x^2 \sin x \ln x}$$","['functions', 'limits']"
1108229,Is every simple function on a compact measure space the pointwise limit of continuous functions?,"Question: Let $(X,\mu)$ be a measure space and suppose that $X$ is compact. Is every simple measurable function $s:X\to\mathbb{R}$ (i.e. $s(X)$ is a finite set) the pointwise limit of continuous functions $f_n:X\to\mathbb{R}$? Edit : Actually the answer is no! Thanks to David Mitra for the counterexample. But the question bellow still holds. End Edit. I am asking this question in order to understand a proof in Rudin's Real and Complex Analysis (p. 102). He defines a function $g:[-\pi,\pi]\to\mathbb{R}$ by
$$g(t)=\begin{cases}1 &; D_n(t)\geq 0 \\ -1 &;D_n(t)<0,\end{cases}$$
where
$$D_n(t)=\sum_{k=-n}^ne^{ikt}.$$
He then says (without any explanation) that there are continuous functions $f_k:[-\pi,\pi]\to\mathbb{R}$ such that $-1\leq f_j\leq 1$ and $f_j(t)\to g(t)$ for every $t$, as $j\to\infty$. After some work, I found a way to convince myself that this is true, but I don't find it obvious at all. Since Rudin doesn't give any explanation, this must be very obvious and there should be something that I missed. To prove it, I first used Uryshon's Lemma to obtain continuous functions $f_j$ such that
$$D_n^{-1}([0,\infty))\prec f_j\prec D_n^{-1}((-1/j,\infty)).$$
The limit of these functions is $\chi_{D_n^{-1}([0,\infty))}$ and by making a translation and a scaling, we are done. Question: How would YOU prove it?","['measure-theory', 'real-analysis']"
1108239,How to prove product of measurable set is measurable using dynkin's $\pi-\lambda$ theorem?,"My question: If $E_1$ and $E_2$ are measurable subsets of $R^1$, I want to show that $E_1 \times E_2$ is a measurable subset of $R^2$ and $|E_1 \times E_2|=|E_1||E_2|$. My attempt: First I tried to use the Dynkin's $\pi-\lambda$ theorem to show this holds for $E_1$ and $E_2$ are Borel sets. The proof is as follows. (First, let $C$={$E_1|$$E_2$is closed interval,$E_1 \times E_2$ is a measurable set, $|E_1 \times E_2|=|E_1||E_2|$}). Let $D$={closed interval}, then $D\in C$, and $D$ is a $\pi$ system. Now prove $C$ is a $\lambda$ system. First, $R\in C$. Second, $E_1$,$F_1\in C$, then $E_1$ \ $F_1\in C$. Third, $E_{1n} \uparrow E_1, E_{1n}\in C$, then $E_1 \in C$.So by dynkin's $\pi \lambda$ theorem, Borel sets=$\sigma(D)\in C$. Now, let $C^1$={$E_1|$$E_2$is Borel sets,$E_1 \times E_2$ is a measurable set, $|E_1 \times E_2|=|E_1||E_2|$}). By the last step, $D$={closed interval}, then $D\in C$, iterating the last step, by dynkin's $\pi \lambda$ theorem, Borel sets=$\sigma(D)\in C^1$. So I think I proved(not sure) :
If $E_1$ and $E_2$ are Borel subsets of $R^1$, $E_1 \times E_2$ is a measurable subset of $R^2$ and $|E_1 \times E_2|=|E_1||E_2|$. My question: 1.How to extend this result form Borel sets to Lebesgue measurable sets? 2.About proving $C$ is a $\lambda$ system, I don't know how to justify the second and third conditions: (Second, $E_1$,$F_1\in C$, then $E_1$ \ $F_1\in C$. Third, $E_{1n} \uparrow E_1, E_{1n}\in C$, then $E_1 \in C$.So by dynkin's $\pi \lambda$ theorem, Borel sets=$\sigma(D)\in C$.) Thanks for your help!","['probability-theory', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1108244,Show that the operator $(x_n)_n\mapsto (\frac{x_n}{n}) $ is compact,"I want to show that the following operator is compact: $$T:\mathbb \ell^p\rightarrow \mathbb \ell^p, \text{  }(x_n)_n\mapsto(\frac{x_n}{n})_n \text{   }  1\leq p<\infty$$ Its the first time that I am trying to show that an operator is compact. I know the following three definitions of a compact operator: Let $T:X\rightarrow Y$ be a bounded operator, then $T$ is compact if 1) The image of the unit ball is relatively compact or 2) The image of any bounded set in X is relatively compact or 3) Any bounded sequence $(x_n)$ in $X$ has a subsequence such that $Kx_{n_k}$ converges. But I feel like none of this definitions can help me to prove the compactness of the operator directly. Is there something like a ""general way"" to show this? At least for Operators from $\mathbb \ell^p\rightarrow \ell^p$ ? Thanks in advance","['operator-theory', 'compact-operators', 'functional-analysis']"
1108246,Double sum and zeta function,"This is a personal research that came to an end , since the results were not those which were being anticipated. I was unable to come up with a solution therefore I post the topic here: Prove (it certainly holds because it was checked on a computer) that the following identity holds: $$\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2}=\zeta(2)\sum_{n=1}^{\infty}(-1)^{n-1}\frac{1}{\left ( 2n-1 \right )^2}-\zeta(4)$$ wheras $\zeta$ represents the zeta function defined as $\displaystyle \zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}, \;\; \mathfrak{Re}(s)>1 $. Of course both values of $\zeta$ appearing here are known. For complete of sakeness i quote them : $$\zeta(2)=\frac{\pi^2}{6}, \;\; \zeta(4)=\frac{\pi^4}{90}$$ Now, one can also see (not trivial ) that: $$\sum_{n=1}^{\infty}\frac{1}{n^2 \sinh^2 \pi n}=\frac{4}{\pi^2}\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2} -\frac{\pi^2}{60}$$ This equation also holds (checked by computer). The following result was extracted by using the known formulae $\displaystyle \sum_{n=-\infty}^{\infty}\frac{1}{z+n}=\frac{\pi}{\tan \pi z}$ and the known (?)  Fourier series:
$$\displaystyle \frac{1}{\sinh^2 \pi z}=\frac{1}{\pi^2 z}+\frac{4z^2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{\left ( z^2+k^2 \right )^2}-\frac{2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{z^2+k^2} $$ Of course the last sum at the last equation can easily be computed via residues. What remains now is the proof for the first equation in the post. No-one can guarantee that is going to be an easy task. Some comments: 1. I came across the identity on a book. I checked the validity with a computer and yes it does hold. 2. I have ckecked enough books to see if there is in there somewhere , but unfortunately it was not. So, I speculate that it is not that famous. 3. It can also be linked with other sums (single or double). Unfortunately I don't have my papers in front of me in order to write them down. So, i think it is an interseting identity. I would appreciate your help.","['fourier-series', 'sequences-and-series', 'riemann-zeta']"
1108247,Embeddings into products of projective spaces and multi graded rings,"Let X be a variety over a field $k$. Assume that it is embedded into product of two projective spaces
$$
i : X \subset \mathbb{P}^n \times \mathbb{P}^m.
$$
I want to construct a graded algebra that corresponds to this embedding in the same spirit as we construct homogeneous coordinate ring of a variety embedded into a single projective space. I guess, in this case I need two line bundles 
$$
\mathcal{L} = i^* \mathcal{O}(1,0),
$$
and
$$
\mathcal{M} = i^* \mathcal{O}(0,1),
$$
and corresponding algebra 
$$
R = \bigoplus_{i \geq 0, j \geq 0} H^0(X, \mathcal{L}^i \otimes \mathcal{M}^j)
$$
is bigraded. I think something like this should be well known. Where can I find discussion of this construction and related questions?","['algebraic-geometry', 'reference-request']"
1108271,find a function satisfying the recurrence [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question find a function satisfying the recurrence $$F (n) = 2F (\sqrt{n}) + 1$$ replace $n$ by $2^m$
Thus getting the answer as $$F(n)=\frac{1}{2}c \log(n) + \log(n) - 1$$ Is this  correct","['discrete-mathematics', 'recursion']"
1108274,Solution to Laguerre differential equation using generating function,"This is an exercise in Modern Quantum Mechanics by Sakurai and Napolitano. Follow these steps to show that solutions to Kummer's equation (7.46) can be written in terms of Laguerre polynomials $L_n(x)$, which are defined according to a generating function as
  $$g(x, t) = \frac{e^{-xt/(1-t)}}{1-t} = \sum_{n=0}^\infty L_n(x) \frac{t^n}{n!}$$
  where $0 < t < 1$. The discussion on generating functions for Hermite polynomials will be helpful. (a) Prove that $L_n(0) = n!$ and $L_0(x) = 1$. (b) Differentiate $g(x, t)$ with respect to $x$, show that
  $$L'_n(x) - nL'_{n-1}(x) = -nL_{n-1}(x),$$
  and find the first few Laguerre polynomials. (c) Differentiate $g(x, t)$ with respect to $t$ and show that
  $$L_{n+1}(x) - (2n+1-x)L_n(x) + n^2L_{n-1}(x) = 0.$$ (d) Now show that Kummer's Equation is solved by deriving
  $$xL''_n(x) + (1-x)L'_n(x) + nL_n(x) = 0,$$
  and associate $n$ with the principal quantum number for the hydrogen atom. I've done (a), (b), and (c), but I'm having trouble with (d). The difficulty seems to be that using the result in (d) to shift $n$ invariably introduces two new $n$ values, so I can never get it to be of use in simplifying what I get from (b). No matter what I do, I can't get an equation that only contains one $n$ value. But obviously I just haven't tried the right thing. How can (d) be solved using (b) and (c)?","['generating-functions', 'ordinary-differential-equations']"
1108294,Properties of fibers of a morphism of varieties,"In this question, all varieties are supposed to be over an algebraically closed field $k$. Hypothesis: X is a smooth projective surface and $f:X\longrightarrow \mathbb P^1$ is a morphism with we following properties (maybe some conditions are redundant but for completeness I write the complete list): $f$ is flat, proper and has a section. There is an open dense subset $U \subseteq\mathbb P^1 $ such that the fiber $X_u$ is a    smooth projective curve (i.e. integral, separated scheme of finite type) for every $u\in U$. All fibers are irreducible (and hence connected). The singular fibers can have only one node as singularities (multiple nodes are not allowed) Conclusions: I'd like to show (if true) that all fibers are reduced. Pactically it remains to show that the singular fibers are reduced.","['algebraic-geometry', 'schemes', 'surfaces']"
1108352,What are Carnot groups?,I'm trying to learn the Pansu differentiability theorem and I need to know what Carnot groups are. Can someone please explain what Carnot groups are? An introductory reference would be greatly appreciated as well. Thanks.,"['manifolds', 'riemannian-geometry', 'lie-groups', 'analysis', 'derivatives']"
1108364,$n-1$ dimensional permutation module for $S_n$,"Say $n \ge 5$. Let $P$ be the $(n-1)$ dimensional permutation module for $S_n$, i.e. the permutation representation on $\{(x_1, \dots, x_n) \in {\bf C}^n: \sum x_i  = 0\}$. Prove that: $\wedge^2P$ is always a irreducible $S_n$-module; $\text{Sym}^2P$ is always isomorphic to the sum of the trivial representation, $P$ and an irreducible $S_n$-module. Is there a way to do this problem without using something ""overpowered"" such as Young tableaus?","['representation-theory', 'symmetric-groups', 'abstract-algebra']"
1108371,Discontinuous Differentiable and One to One,"If the derivative of a function (from $\mathbb{R} \rightarrow \mathbb{R}$) at a point $x_0$ is discontinuous, does that imply that the function is not one to one or injective in a neighborhood of $x_0$? If not, how does one go in showing that the function is not injective at $x_0$ given that the derivative of the function is discontinuous at $x_0$. My thoughts: Since the function's derivative is not always positive or negative, then the function is not injective because it is neither always decreasing or always increasing. Does that sound right?","['continuity', 'derivatives', 'analysis']"
1108373,"Galois group, algebraic closure over maximal extension","Let $\overline{\mathbb{Q}}$ be the algebraic closure of $\mathbb{Q}$. Let $\alpha \in \overline{\mathbb{Q}}\setminus \mathbb{Q}$ and let $K \subset \overline{\mathbb{Q}}$ be a maximal extension of $\mathbb{Q}$ in respect to not containing $\alpha$ (so $\alpha \notin K$, but $\alpha$ in every nontrivial extension of $K$). Let $G$ be the Galois group of $\overline{Q}$ over $K$. Show that either $G = \mathbb{Z}/2\mathbb{Z}$ or $G = \mathbb{Z}_p$ ($p$-adic integers) for some prime $p$.","['abstract-algebra', 'polynomials', 'galois-theory', 'group-theory', 'field-theory']"
1108382,Example where a finite group $G$ of order $n$ has no subgroup of order $m$,"Using the Fundamental Theorem of Abelian Groups, one can prove that if $G$ is a finite abelian group of order $n$ such that $m$ is a positive integer that divides $n$, then $G$ contains a subgroup of order $m$. But what are some examples of non-abelian groups $G$ of order $n$ and $m$ a factor of $n$ such that $G$ has no subgroup of order $m$?","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
1108387,The quotient map $q: \mathbb R^{n+1} \setminus \{0\} \to \mathbb P^n$ is open.,"I'd like to show that the quotient map $q: \mathbb R^{n+1} \setminus \{0\} \to \mathbb P^n$ is open, where I'm considering $\mathbb P^n$ as the quotient space of $\mathbb R^{n+1} \setminus \{0\}$ under the equivalence relation $(x_0, \dots, x_n)\sim (y_0,\dots,y_n)$ if there exists a non-zero real number $\lambda$ such that 
$(y_0,\dots,y_n) = \lambda(x_0,\dots, x_n).$ I believe I have a proof, but I'd like to know if there is a cleaner way to do it. I know that this can be done using group actions, but I want to avoid that. My proof: To prove that the quotient map is open, we take an open set in $\mathbb R^{n+1} \setminus \{0\}$ and show that it maps to an open set in $\mathbb P^n$. For an open set  $U$ in $\mathbb R^{n+1}\setminus \{0\}$, to show that $q(U)$ is open, we must show that $q^{-1}(q(U))$ is open in $\mathbb R^{n+1}\setminus \{0\}$. Let $x \in q^{-1}(q(U))$. We show that there exists an open set containing $x$ that is also contained in $q^{-1}(q(U))$. Since $x \in q^{-1}(q(U))$, there exists a $\lambda \in \mathbb R\setminus \{0\}$ such that $\lambda x \in U$. Since $U$ is open, there exists an $\varepsilon > 0$ such that $B(\varepsilon,\lambda x) \subseteq U$. We claim that $B(\frac{\varepsilon}{|\lambda|},x)$ is an open set containing $x$ that is also contained in $q^{-1}(q(U))$. To show this, we choose an arbitrary point $y \in B(\frac{\varepsilon}{|\lambda|},x)$, and show that $y \in q^{-1}(q(U))$. Since $y \in B(\frac{\varepsilon}{|\lambda|},x)$, we know that $\Vert{y - x}\Vert < \frac{\varepsilon}{|\lambda|}$, and moreover, $\Vert{\lambda y - \lambda x}\Vert < \varepsilon$ so that $\lambda y \in B(\varepsilon,\lambda x)\subseteq U$. Thus, $q(y) \in q(U)$ and $y \in q^{-1}(q(U))$ so that $x \in B(\frac{\varepsilon}{|\lambda|},x)\subseteq q^{-1}(q(U))$. This means that $q^{-1}(q(U))$ is open, and that $q$ is an open map.","['general-topology', 'quotient-spaces', 'proof-verification', 'projective-space']"
1108391,yet another simple Laplace transform,"what is $ℒ(t^2e^{3t})$ I have got this far so far: $=\int_{0}^\infty (t^2e^{t(3-s)})$ Integration by parts using: $u = t^2$ and $du = 2t$ $v = \frac{e^{t(3-2)}}{3-s}$ and $dv = e^{t(3-s)}$ Which I think yields: $0 - \int_{0}^\infty \frac{2t}{3-s} e^{t(3-2)}$ and now i'm stuck. if someone could do a step by step instructions, that would be so helpful!","['laplace-transform', 'ordinary-differential-equations', 'exponential-function', 'integration']"
