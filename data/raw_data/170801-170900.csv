question_id,title,body,tags
3021168,Primes of the form $p=x^4+y^4$,"Are there infinitely many prime numbers $p$ such that $$p = x^4+y^4$$ for some $x,y \in \Bbb Z$ ? What if we only require $x,y \in \Bbb Q$ ? I know that $p = a^2+b^2$ with $a,b \in \Bbb Q$ iff $p = a^2+b^2$ with $a,b \in \Bbb Z$ (Davenport-Cassels) iff $p=2$ or $p \equiv 1 \pmod 4$ . But $a$ and $b$ might not be squares. What are some references about this problem, which explain what is (un)known?","['number-theory', 'polynomials', 'prime-numbers']"
3021181,What is the significance of Group Automorphism?,"I have understood the definition of group automorphism and have studied various examples for the same. But what is the significance of an automorphism? When we study isomorphisms, we try to investigate how similar is a group to another group. What do we get from establishing isomorphisms from a group to itself?","['group-theory', 'abstract-algebra', 'soft-question']"
3021208,A problem about the basis of the Zariski topology,"Let $A$ be a commutative ring with $1_A$ . Let $X= \mathrm{Spec}(A)$ be a topological space equipped with the Zariski topology. Let $U \subseteq X$ be an open set and choose $x_1, \ldots, x_n \in U$ . Prove that there exists $f \in A$ such that $$\{ x_1, \ldots, x_n \} \subset D(f) \subseteq U.$$ I'm stuck with proving the existence of such $f$ . Any help will be appreciated. Note: For $x \in X=\mathrm{Spec}(A)$ , we shall write an ideal with $j_x$ . Then $$V(f)= \{x \in X : f \in j_x\} \ \text{and} \ D(f)=X-V(f).$$ Further, we know that $D(f)$ forms a basis for the open sets of $X$ .","['zariski-topology', 'algebraic-geometry']"
3021256,sum of alternating $|f|$ and $|f|^2$,"Does anyone know an example of a function $f$ for which the relation $$
\sum_{n=1}^\infty (-1)^n |f(n)| < \infty \\
\Longleftrightarrow \\
\sum_{n=1}^\infty (-1)^n |f(n)|^2 < \infty
$$ is violated? Even though the counterexamples are somewhat valid I was more thinking about a differentiable function $f(n)$ , possibly even analytic. In a similar manner: Does the following hold $$
\sum_{n=1}^\infty (-1)^n |f(n)|^2 < \infty \\
\Longrightarrow \quad  \sum_{n=1}^\infty \frac{(-1)^n|f(n)|^2}{1+a^2 |f(n)|^2} < \infty
$$ where $a>0$ ? The last one is interesting, because for $a=0$ this matches the assumption and for $a \rightarrow \infty$ the sum is bounded as well since $\left|\sum_{n=1}^\infty (-1)^n\right| \leq 1$ . If it is even possible to show $$
\sum_{n=1}^\infty \frac{(-1)^n|f(n)|^2}{1+a^2 |f(n)|^2} \sim {\cal O}\left(a^{-1-\epsilon}\right) \qquad {\rm as} \qquad a\rightarrow \infty
$$ and $\epsilon>0$ then the integral $$
\frac{1}{\pi} \int_{-\infty}^{\infty} \sum_{n=1}^\infty \frac{(-1)^n|f(n)|^2}{1+a^2 |f(n)|^2} \, {\rm d}a = \sum_{n=1}^\infty (-1)^n |f(n)| < \infty
$$ is well defined and reproduces the first relation.","['summation', 'sequences-and-series']"
3021276,Prove that $4| \sigma(4k+3)$ for each positive integer $k$,"I am struggling with a part of Apostol concerning divisor functions of $\sigma_\alpha(n)$ , when $\alpha =1$ , this denotes the sum of divisors of $n$ I wish to prove that $4| \sigma(4k+3)$ for each positive integer $k$ I started:
Since $\alpha$ is multiplicative we have: $\alpha(p_1^{a_1}...p_k^{a_k}) = \sigma(p_1^{a_1})... \sigma(p_k^{a_k})$ The divisors of a prime power $p^a$ are: $1,p, p^2,...p^a$ This is a geometric series: Hence: $\sigma(p^a) = \frac{p^{a+1}-1}{p-1}$ But I guess I started the wrong way....
Any help appreciated","['number-theory', 'elementary-number-theory']"
3021289,About proof: $\cot^{-1}\left(\frac{\sqrt{1+\sin x}+\sqrt{1-\sin x}}{\sqrt{1+\sin x}-\sqrt{1-\sin x}}\right)=\frac x2$,"I have the following question: Prove that: $$ \cot^{-1}\Biggl(\frac{\sqrt{1+\sin x} + \sqrt{1-\sin x}}{\sqrt{1+\sin x} - \sqrt{1-\sin x}}\Biggl) = \frac x2, \ x \in \biggl(0, \frac \pi4\biggl) $$ The solution: My question is about the second step (i.e., highlighted). We know that it has came from the following resolution: $$ \sqrt{1\pm \sin x} = \sqrt{\sin^2\frac x 2 + \cos^2\frac x 2 \pm2\sin\frac x 2\cos\frac x 2} = \pm \biggl( \cos\frac x 2 \pm \sin\frac x 2 \ \biggl) $$ I've included the $\pm$ symbol in accordance with the standard definition of square root . The above solution uses the positive resolution (i.e., $ \cos\frac x 2 - \sin\frac x 2 $ ) for $ \sqrt{1- \sin x} $ . But, if I use the negative one , then the result changes . The sixth step changes to: $$ \cot^{-1}\biggl(\tan\frac x 2\biggl) = \cot^{-1}\Biggl(\cot\left(\frac \pi 2 - \frac x 2\right)\Biggl) $$ which yield the result: $$ \frac \pi 2 - \frac x 2 $$ Mathematically, this result is different from that provided in the RHS of question. Is the question statement wrong or I've been hacked up?","['trigonometry', 'proof-verification']"
3021290,"Why are the fundamental and anti-fundamental representation in $\text{SL}(2,\mathbb{C})$ not equivalent?","I am currently learning group theory and I learnt that the fundamental representation and the anti-fundamental representation of $\text{SL}(2,\mathbb{C})$ , $2 \times 2$ matrix with determinant of $1$ , are not equivalent.  This means that no similarity transformation can map one of them to the other. My professor gave an explanation (on the 2nd last paragraph on page 75 of the following document http://www-pnp.physics.ox.ac.uk/~tseng/teaching/b2/b2-lectures-2018.pdf ) but I don't see how the difference in the signs in the exponent imply that the representations are inequivalent. Can anyone please explain the explanation of my professor, or perhaps give another explanation?","['group-theory', 'representation-theory', 'lie-groups']"
3021314,Continuity of Lebesgue Stieltjes integral,"I am trying to prove that Lebesgue-Stieltjes integral defines a cadlag function (i.e. right continuous with left limits) when its integrator is a cadlag function. Assume that $A(s)$ , $s\in \mathbb{R}_+$ is a right-continuous function, has left limits and of finite variation. Also assume that function $H(s)$ , $s\in  \mathbb{R}_+$ is measurable function (i.e. Borel measurable on $\mathbb{R}_+$ ). It is well-known that $A$ defines a signed measure and thus we can define Lebesgue-Stieltjes integral $Y(t):=\int_0^t H(s)dA(s)$ for any $t$ as long as $\int_0^t |H(s)|d|A|(s)<\infty$ . To prove that $Y(t)$ is right continuous, I choose a decreasing sequence $t_n\downarrow t$ and have $Y(t_n)=\int_{\mathbb{R}_+}1_{(0,t_n]}(s)H(s)dA(s)$ . We can see that for every fixed $s$ the integrand $1_{(0,t_n]}(s)H(s)$ tends to $1_{(0,t]}(s)H(s)$ . 
As $\int_0^u |H(s)|d|A|(s)<\infty$ for all $u$ , we can use dominated convergence and show that indeed $\lim_{n\to \infty}Y(t_n)=Y(t)$ . This proves that $Y(t)$ is right continuous. Using exactly the same argumens (i.e. by choosing $t_n\uparrow t$ ) we can show that $Y(t)$ is left continuous. However, my intuition says that when $A(s)$ has a jump discontinuity at point $t$ , then $Y(t)$ should also have a jump of size $H(t)\Delta A(t)$ . I can't find a flaw in my proof above.","['measure-theory', 'stieltjes-integral', 'lebesgue-integral', 'signed-measures']"
3021354,For- and backwards well-ordered set is finite.,"I'm working on the following problem and can't seem to come up with a satisfactory proof. Let $X$ be a totally ordered set which is well-ordered forwards and backwards. Show that $X$ is finite. I found this saying that both statements are in fact equivalent but I couldn't find anymore resources that helped. I'm kind of stuck because $X$ being well-ordered forwards and backwards means that $$\forall (A \neq \emptyset) \subset X: (\exists a_{max}, a_{min} \in A: \forall a \in A: a_{min} \preceq a \preceq a_{max})$$ But I know that having a minimal/maximal element makes no statement about the set being finite (i.e. $[0; 1] \subset \mathbb{R}$ has 0 as minimal and 1 as maximal element but is in fact infinite.) So I thought about proving the contraposition: $X$ infinite $\implies X$ is not well-ordered forwards & backwards.
Since $X$ is infinite it holds that $$\not\exists x_{max} \in X: (\forall x \in X: x \preceq x_{max})$$ because for every element we would choose as $x_{max}$ there always exists an $x$ that is bigger than $x_{max}$ because $X$ is infinite.
This means that $X$ cannot be well-ordered forwards. But this seems to straight forward and to informal to be correct. I also thought about how I could use a bijection $f: X \to \{1, \ldots, n\} \subset \mathbb{N}$ to show that $X$ is finite, but I wasn't able to come up with much of anything. Any help is greatly appreciated.","['elementary-set-theory', 'well-orders']"
3021368,Are $\sigma$-finite measures agreeing on a generating set equal?,"Suppose I have two measures $m,n$ and that they are both $\sigma$ -finite and agree on some semi-ring $R$ generating their $\sigma$ -algebras. Must these two measures then agree on the entire $\sigma$ -algebra? Of course, the Caratheodory extension theorem states that if the two pre-measures given by the restriction of $m,n$ to $R$ are themselves $\sigma$ -finite, then their extension to the $\sigma$ -algebra is unique, but I suspect there might be a case where the restriction of a $\sigma$ -finite measure to the semi-ring might not remain $\sigma$ -finite.","['measure-theory', 'real-analysis']"
3021477,What does the following manifold look like?,"In hyperbolic geometry, we know that any complete hyperbolic surface is the quotient $\mathbb{H}^{2}/\Gamma$ where $\Gamma < \text{Isom}(\mathbb{H}^{2})$ a discrete subgroup. We know $\text{Isom}^{+}(\mathbb{H}) \cong PSL(2,\mathbb{R})$ which contains $PSL(2,\mathbb{Z})$ as a discrete subgroup. Also $\Gamma(m)$ which is the kernel of the natual map $PSL(2,\mathbb{Z}) \to SL(2,\mathbb{Z}/m\mathbb{Z})$ acts freely and properly discontinuously on $\mathbb{H}^{2}$ so $\mathbb{H}^{2}/\Gamma(m)$ is a hyperbolic surface. I want to see a geometric picture of this manifold. How can I proceed to see what this manifold look like (at least topologically, if not isometrically)?","['fundamental-groups', 'hyperbolic-geometry', 'differential-geometry']"
3021505,Is there a function that satisfies $f(\log \frac{p}{1-p}) = p(1-p)$?,"Let $p\in (0,1)$ I am wondering there exists a function $f:\mathbb{R}\to[0,{1\over 2}]$ that satisfies $$
f\left(\log \frac{p}{1-p}\right) = p(1-p)
$$ I've tried messing around with exponentials but nothing has worked so far.","['functional-equations', 'functions', 'exponential-function', 'logarithms']"
3021532,"Is it possible for the bisection method to provide ""fake"" zeros","I've read about the bisection method for finding roots of a function in my numerical analysis textbook and one question came to my mind. Given a relatively complicated function, the chances of finding the exact root (that is, a root that is completely represented in the computer's memory, with all significant figures) are very low. This means that most of the time, we will have a value for which the function is very close to, but not exactly equal to zero. So what would happen if the function had one root, and another value at which the function gets extremely close to zero, without actually getting there? Would the algorithm fail? And what is the meaning of that eventual ""fake"" root; is it worth anything? Thank you. EDIT: here is a picture showing what I meant","['numerical-methods', 'roots', 'analysis', 'real-analysis']"
3021562,Rudin's Proof about Winding Numbers,"This is kind of a softball question, an untied loose end that has always bugged me. It is well-known that if $\Gamma_1\sim \Gamma_2$ are two homotopic closed paths in a region $\Omega$ , and if $\alpha\notin \Omega$ , then $n(\Gamma_1;\alpha)=n(\Gamma_2;\alpha).$ I've seen several proofs of this, using approximation by polygonal paths. Rudin's is (surprise!) the slickest, but of course, he leaves some of the details to the reader, and when I do the calculation, I am off by a factor of two at a certain step, which does not affect the proof (one can scale the original hypothesis), but I must be making a mistake, and it has always bugged me. So I'd like to see where my error is. Let $H:I\times I\to \Omega$ be the homotopy. and choose an integer $n$ such that $|s-t|+|s'-t'|<1/n\Rightarrow$ $ |H(s)-H(t)|+|H(s')-H(t')|<\epsilon. $ Define the paths $\{\gamma_0,\cdots ,\gamma_n\}$ by $\gamma_k(s)=H(i/k,k/n)(ns+1-i)+H((i-1)/n,k/n)(i-ns)$ if $i-1\le ns\le i.$ The claim is then that $|\gamma_k(s)-H(s,k/n)|<\epsilon.$ Here is what I am getting, after substituting and applying the triangle inequality: $|H(i/n,k/n)-H((i-1)/n,k/n)|(ns-i)+|H(i/n,k/n)-H(s,k/n)|$ which is easily seen to be $<2\epsilon.$ It seems like the only way to avoid the factor of two, would be to arrive at a tractable expression without using the triangle inequality. But I do not see how to do this. Unless at the outset, we should have simply required that $|s-t|+|s'-t'|<1/n\Rightarrow$ $|H(s)-H(t)|+|H(s')-H(t')|<\epsilon/2. $","['complex-analysis', 'winding-number', 'analytic-geometry', 'analysis']"
3021631,Combinatorial Proof that the Logarithm of a Product is the Sum of the Logarithms,"I've been strongly drawn recently to the matter of the fundamental definition of the exponential function, & how it connects with its properties such as the exponential of a sum being the product of the exponentials, and it's being the eigenfunction of simple differentiation, etc. I've seen various posts inwhich clarification or demonstration or proof of such matters  as how such & such a property proceeds from its definition as $$e^z\equiv\lim_{k\rightarrow\infty}\left(1+\frac{z}{k}\right)^k .$$ I'm looking at how there is a web of interconnected theorems about this; and I am trying to spin the web as a whole . This is not necessary for proving some particular item to be proven - a path along some one thread or sequence of threads is sufficient for that; but I think the matter becomes 'unified', and by reason of that actually simplified , when the web is perceived as an entirety. This is why I bother with things like combinatorial demonstrations of how the terms in a binomial expansion evolve towards the terms in a Taylor series as some parameter tends to ∞, when the matter at hand is actually susceptible of a simpler proof by taking the logarithm of both sides ... & other seeming redundancies. To this end, another 'thread' I am looking at is that of showing that the coefficients in the Taylor series for $\ln(1+z)$ actually are a consequence of the requirement that the logarithm of a product be the sum of the logarithms, and ... if not quite a combinatorial derivation of them from that requirement, at least a reverse- (or sideways-) engineering equivalent of it - the combinatorially showing that if the coefficients be plugged into the Taylor series, then the property follows Taking the approach that $$(1+x)(1+y) = 1+x+y+xy ,$$ plugging $z=x+y+xy$ into the series for $\ln(1+z)$ and hoping that all non-fully-homogeneous terms cancel out, leaving sum of the series for $\ln(1+x)$ & that for $\ln(1+y)$ , we are left with proving that $$\sum_{k=1}^\infty\left((-1)^k(k-1)!×\sum_{p\inℕ_0,q\inℕ_0,r\inℕ_0,p+q+r=k}\frac{x^{p+r}y^{q+r}}{p!q!r!}\right)$$ $$=$$ $$\sum_{k=1}^\infty(-1)^k\frac{x^k+y^k}{k} .$$ The inner sum of the LHS of this quite appalling-looking theorem is the trinomial expansion of $(x+y+xy)^k$ for arbitrary $k$ , & the outer sum is simply the logarithm Taylor series expansion (with its $k$ in the denominator 'absorbed' into the combinatorial $k!$ in the numerator of the inner sum) . This theorem can be quite easily verified by 'brute force' - simply doing the expansions at the first (very!) few terms; but the labour of it escalates extremely rapidly. An algebraic manipulation package would no-doubt verify it at a good few more terms; but what I am looking-for is a showing of the fully general case: but I do not myself have the combinatorial toolage for accomplishing this. So I am asking whether anyone can show me an outline of what to do ... or even actually do it for me, although that would probably take up a very great deal of space and be an extremely laborious task for the person doing it ... so I'm content to ask for just an outline of doing it, or for some 'signposts' as to how to do it - maybe someone knows some text on this kind of thing that they would recommend.","['exponential-function', 'combinatorics', 'taylor-expansion', 'logarithms']"
3021653,Proving that $\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1$,"I want to prove that $$\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1$$ if $f(n)$ grows faster than $g(n)$ for $n\to\infty$ and $\lim_{n\to\infty} f(n) = +\infty = \lim_{n\to\infty}g(n)$ . It is quite easy to see that if $f = g$ the limit is $e$ , but I can't find a good strategy to solve this problem.","['limits', 'calculus', 'exponentiation', 'sequences-and-series']"
3021675,A two player game on compact topological spaces,"I've though of an infinite game that two players may play on a given topological space $(X,\tau)$ . It goes like this. On turn $n$ Player I selects a point $x_n\in X$ and Player II selects a neighborhood $U_n$ of $x$ . They play $\omega$ times, and Player I wins if $\{U_n\}_n$ is a cover of $X$ . Thinking about it I've come up with what I believe are some true statements regarding this game. -If $(X,\tau)$ is not Lindelöf then Player II has always a winning strategy. -If $(X,\tau)$ is countable than Player I has always a winning strategy. -If $X=[0,1]$ then Player II has a winning strategy (just choose interval neighborhoods with increasingly smaller diameter, in such a way that the series given by adding them converges to a value smaller that $1$ ). -If $X=\omega_1+1$ (or any successor ordinal) then Player I has a winning strategy. Now I think it might be that, given that $(X,\tau)$ is compact, one of the players always has a winning strategy (i.e. the game is determined), because open games are determined. I mean, this depends on whether open games on game spaces of the form $S^\omega$ , not necessarily the Baire space, are always determined. My question is whether it is known if this dividing line among compact topologies, namely whether Player I or Player II has a winning strategy in this game, has strong consequences in any direction. For example it might be that this can be framed in terms of classical topological properties.","['game-theory', 'general-topology', 'infinite-games', 'compactness']"
3021679,Values of $x$ satisfying $\sin x\cdot\cos^3 x>\sin^3x\cdot\cos x$,"For what values of $x$ between $0$ and $\pi$ does the inequality $\sin x\cdot\cos^3 x>\sin^3x\cdot\cos x$ hold? My Attempt $$
\sin x\cos x\cdot(\cos^2x-\sin^2x)=\frac{1}{2}\cdot\sin2x\cdot\cos2x=\frac{1}{4}\cdot\sin4x>0\implies\sin4x>0\\
x\in(0,\pi)\implies4x\in(0,4\pi)\\
4x\in(0,\pi)\cup(2\pi,3\pi)\implies x\in\Big(0,\frac{\pi}{4}\Big)\cup\Big(\frac{\pi}{2},\frac{3\pi}{4}\Big)
$$ But, my reference gives the solution, $x\in\Big(0,\dfrac{\pi}{4}\Big)\cup\Big(\dfrac{3\pi}{4},\pi\Big)$ , where am I going wrong with my attempt?","['trigonometry', 'inequality']"
3021738,Pushout in the category of Sets: proof,"Let $f\colon Z\to X$ and $g\colon Z\to Y$ be functions. What is a pushout of $f$ and $g$ in $\mathsf{Set}$ ? Different sources and questions on this site claim that it's the quotient of the disjoint union $X\sqcup Y$ by the equivalence relation $\sim_R$ generated by the relation $R = \{ ((0,x),(1,y)) \in (X\sqcup Y)\times (X\sqcup Y) \mid \exists z \in Z, x = f(z)$ and $y = g(z) \}$ . Define functions $i_1\colon X\to X\sqcup Y/{\sim_R}$ and $i_2\colon Y\to X\sqcup Y/{\sim_R}$ by setting $i_1$ to map each $x \in X$ to the equivalence class $[(0,x)]$ and $i_2$ to map each $y \in Y$ to the equivalence class $[(1,y)]$ . For $X\sqcup Y/{\sim_R}$ together with $i_1$ and $i_2$ to be a pushout in $\mathsf{Set}$ , we first must have $i_2\circ f = i_2\circ g$ . It's easy to check that it's so. Now, let $j_1\colon X\to Q$ and $j_2\colon Y\to Q$ be functions so that $j_1\circ f = j_2\circ g$ . We seek a function $u\colon X\sqcup Y/{\sim_R} \to Q$ . $u\circ i_1 = j_1$ and $u\circ i_2 = j_2$ . Of course, for these identities to hold, this hypothetical function $u$ must satisfy $u([(0,x)]) = j_1(x)$ and $u([(1,y)]) = j_2(y)$ for any $x \in X$ and $y \in Y$ . But I'm not sure how to prove that this data indeed defines a function. We need to prove that it is independent of the choice of $x$ and $y$ . Of course, this needs to use the fact that $j_1\circ f = j_2\circ g$ .","['elementary-set-theory', 'category-theory']"
3021751,Gaussian curvature of ruled surfaces,"Let $c: I \rightarrow \mathbb{R}^3$ be a regular curve, $V: I \rightarrow \mathbb{S}^2$ a vector field and $a < b$ . Then we call $$
f: (a,b)\times I \rightarrow \mathbb{R}^3, \quad f(s,t):= c(t) +sV(t)
$$ a ruled surface . Show that $f$ has gaussian curvature $K(s, t) \leq 0$ . For the first fundamental form, I obtained $$
G = \begin{pmatrix}
1 & \langle V, c'\rangle \\
\langle V, c'\rangle & \lvert c' + sV' \rvert^2
\end{pmatrix}
$$ and for the second fundamental form $$
B = \frac{1}{\lvert V \times ( c' + sV') \rvert} \begin{pmatrix}
0 & \langle V', V \times (c' + sV') \rangle \\
\langle V', V \times (c'+sV') \rangle & *
\end{pmatrix}
$$ and thus (with $V \perp V'$ ) that $$
K = \frac{\det B}{\det G} = \frac{-2 \langle V', V\times c' \rangle}{\lvert c' + sV' \rvert^2 -2\langle V, c' \rangle} \cdot \frac{1}{\lvert V \times (c' + sV') \rvert}.
$$ I know that this question was already answered here: Gaussian and Mean Curvatures for a Ruled Surface . However, there are additional assumptions made such as $c' \perp V'$ and $\lvert V' \rvert = 1$ . I don't know how to apply that as my case is a bit more general.","['surfaces', 'curvature', 'differential-geometry']"
3021805,What functions have the following property?,"I'm looking for differentiable functions $f:\Bbb R\to\Bbb R$ such that $$\left(\int_0^1 |f(t)|dt\right)^2> \frac{f(0)^2+f(1)^2}2$$ I found $f(x)=k$ , for some constant $k$ , $f(x)=x$ , $f(x)=x^2$ and $f(x)=e^x$ that hold the opposite, but I couldn't find any function with this property. What does a function need to have in order for the statement to hold?",['functions']
3021838,Showing that a set is Lebesgue Measurable in Higher Dimensions and Applying Fubini's Theorem,"I have an idea of how to proceed, but I'm suspicious that my efforts were of no use. Let $A\in\mathcal{M}$ be Lebesgue measurable, and let $g,h:A \rightarrow \bar{\mathbb{R}}$ be Lebesgue measurable functions with $g(x)\leq h(x) \ \forall x \in A$ . With this, we define $E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y \leq h(x)\}$ . Prove that $E\in \mathcal{M^2}=\mathcal{M} \times \mathcal{M}$ . And following this, show that if $f:E \rightarrow [0,\infty]$ is $\mathcal{M^2}$ measurable, then $\displaystyle\int_Ef dm^2=\int_A(\int_{g(x)}^{h(x)}f(x,y) \ dy) \ dx$ , where $m^2=m \times m$ . For the first part, may we write $E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq h(x)\}$ $\Rightarrow E=\bigcup\limits_{q \in \mathbb{Q}} \{(x,y) \in \mathbb{R^2} : g(x) \leq q \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq q \leq h(x)\}$ and since $h$ and $g$ are measurable, this is a countable union of measurable sets? I don't feel so good about this reasoning, as I'm pretty sure that I would have to find a way to rewrite $E$ as cartesian product of 2 Lebesgue measurable sets (ideally, one with respect to x and the other with respect to y).
So perhaps $E=(g^{-1}[-\infty,y]\cap h^{-1}[y,\infty]) \times \{y\}$ works instead? As for the second part, I'm not particularly sure how to use Fubini's in this scenario. I'd be very gracious for any help and guidance.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'measurable-functions']"
3021863,Showing there is a unique invariant measure on the unit circumference,"Exercise :Assume that $\Omega$ is a circumference of radius $1$ and centred at the origin of $\mathbb{R}^2$ . Show that there exists a unique measure $\mu$ defined on $\mathscr{B}_{\Omega}$ such that $\mu(\Omega)=1$ and $\mu$ is invariant for all rotations centred at the origin. I tried to solve the question the following way:
I can define de measure using the Lebesgue measure $\mu(A)=\frac{\lambda(A)}{\lambda(\Omega)}=\frac{\lambda(A)}{2\pi}$ for $A \subseteq\Omega$ If $A_j$ is a disjoint sequence of sets so that $\bigcup_{j\in\mathbb{N}}A_j=\Omega$ If there were two measures $\mu_1$ and $\mu_2$ then since by assumption $\mu_1(\Omega)=1$ and $\mu_2(\Omega)=1$ then $\mu_2(\bigcup_{j\in\mathbb{N}}A_j)=\sum_{j\in\mathbb{N}}\mu_2(A_j)=\mu_2(\Omega)=1=\mu_1(\Omega)=\mu_1(\bigcup_{j\in\mathbb{N}}A_j)=\sum_{j\in\mathbb{N}}\mu_1(A_j)$ Since the measure is invariant to the rotations I think it does not matter the measure attributed to each single $A_j$ , so what it needs to be assured in order to have uniqueness is that both $\mu_1$ and $\mu_2$ attribute the same set of values to the different sets. Otherwise if one was the Dirac measure and the other was not the uniqueness would fail. Question: How should I solve the problem? Thanks in advance!","['measure-theory', 'real-analysis']"
3021887,Show two irreducible polynomials from a polynomial field cannot share a root,"The problem is as follows: Let $F$ be a field and $K \leqslant F$ . Let $f(x)$ and $g(x) \in K[x]$ , where $f$ and $g$ are irreducible and not associates of one another. Show that $f$ and $g$ do not share any roots in $F$ . Here is my attempt: AFSOC $\exists a \in F$ s.t. $f(a) = g(a) = 0$ . Then $\exists b(x), c(x) \in F[x]$ s.t. $b(x)(x-a) = f(x)$ , and $c(x)(x-a) = g(x)$ . Here is where I am a little unsure of my work. Since $b(x)$ and $c(x)$ need not be in $K[x]$ , I am not sure if I can make the following claim, but anyways I will proceed. Since $x-a$ cannot be a unit, it must be the case that both $b(x)$ and $c(x)$ are units in $F$ . Thus $f(x) = b(x)c^{-1}(x)c(x)(x-a) = b(x)c^{-1}(x)g(x)$ Contradicting that $f(x)$ and $g(x)$ are not associates. Any hints/feedback would be much appreciated :)","['field-theory', 'ring-theory', 'group-theory', 'abstract-algebra']"
3021890,Choice of volume forms in the Weyl Integration Formula,"The following proof is adapted from Bump's Lie Groups . I've tried to rewrite the parts I find unclear. However, I seem to end up with a discrepancy. Please help me complete the proof or point out any mistakes. Theorem: Let $G$ be a compact connected Lie group, and $T$ be a maximal torus. Let $f$ be a function constant on conjugacy classes of $G$ . Give $G$ and $T$ normalized Haar measures, and write $\mathfrak{g}=\mathfrak{p} \oplus \mathfrak{t}$ where $\mathfrak{p}$ is the orthogonal complement of $\mathfrak{t}$ for some choice of invariant inner product. Then $$\int_G fdg= \frac{1}{|W|}\int_{T}f(t)\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)dt$$ where $W=N(T)/T$ , the Weyl group. Proof: Let $\omega$ , $\beta$ be left-invariant top forms on $G$ , $T$ respectively which integrate to give $1$ . These then give the Haar measures on $G$ , $T$ . These forms are also right-invariant since both $G$ and $T$ are compact. Let $d=\dim(G/T)$ . We can also construct a left-invariant top form $\alpha$ on $G/T$ as follows: Choose bases $\lbrace A_i \rbrace$ and $\lbrace B_i \rbrace$ of $\mathfrak{p}$ and $\mathfrak{t}$ respectively such that $\beta_e(\wedge B_i)=1, \omega_e(\wedge A_i \bigwedge \wedge B_i)=1$ . Identifying $\bigwedge^{d} T_{eT}(G/T) = \bigwedge^d \mathfrak{p}$ , define $\alpha_{eT}(\wedge A_i) = 1$ . We then extend $\alpha_{eT}$ to a differentiable section by setting $\alpha_{xT}\left(\wedge V_i \right) = \alpha_{eT}(\bigwedge dl_{x^{-1}}V_i)$ . Here $V_i$ are tangent vectors at $xT$ and $dl_x$ is the differential of left translation. It remains to check $\alpha$ is well defined and smooth. If $x_1T = x_2T$ , then we would have $x_2 = x_1t$ for some $t \in T$ . so $dl_{x_2^{-1}} = dl_{t^{-1}} \circ dl_{x_1^{-1}}$ . Thus it suffices to show $\bigwedge dl_t (A_i)= \wedge A_i$ . This follows since we may compute $dl_t = Ad(t)|_\mathfrak{p} \in Aut(\mathfrak{p})$ and since $\det\left( Ad(t)|_{\mathfrak{p}}\right)=1$ . $\alpha$ is smooth since the left action of $G$ on $G/T$ is smooth. Thus $\alpha$ is a non-zero, left-invariant, top form and gives us a left invariant measure on $G/T$ . Note, I am aware that left-invariant measures can be constructed using the Riesz representation theorem however, since I intend to use the jacobian change of variables formula, it seems necessary to show that these measures are induced by differential forms. Define $\phi: G/T \times T \to G, \phi(xT,t)=xtx^{-1}$ . We now compute the pullback $\phi^*\omega$ in terms of $\alpha \wedge \beta$ as follows: Fix $(xT,t) \in G/T \times T$ . Identify $\mathfrak{p}\oplus \mathfrak{t}$ with $T_{(xT,t)}\left(G/T\times T\right)$ by $A_i \mapsto \frac{d}{ds}(xe^{sA_i}T,t)$ and $B_i \mapsto \frac{d}{ds}(xT,te^{sB_i})$ . Since $\phi(xe^{sA_i}T,t)=xe^{sA_i}te^{-sA_i}x^{-1} = xt(t^{-1}s^{sA_i}t)e^{-sA_i}x^{-1}$ and $\phi(xT,te^{sB_i})= xte^{sB_i}x^{-1}$ , we see that the differential of $\phi$ is given as in the following commutative diagram: $\require{AMScd}$ \begin{CD}
T_{(eT,e)}(G/T\times T)=\mathfrak{p}\oplus \mathfrak{t} @>{(Ad(t^{-1})-I)\oplus I}>> \mathfrak{p}\oplus \mathfrak{t}=T_e(G)\\
@VVV @V{dl_{xt}\circ dr_x^{-1}}VV \\
T_{(xT,t)}\left(G/T\times T\right) @>{d\phi}>> T_{xtx^{-1}}(G)
\end{CD} Taking exterior powers we get, \begin{CD}
\wedge \mathfrak{p}\otimes \wedge\mathfrak{t} @>{\det\left(Ad(t^{-1})-I\right)}>> \wedge \mathfrak{p}\otimes \wedge\mathfrak{t}=\wedge T_e(G)\\
@VVV @V{\wedge (dl_{xt}\circ dr_x^{-1})}VV \\
\wedge T_{(xT,t)}\left(G/T\times T\right) @>{J\phi}>> \wedge T_{xtx^{-1}}(G)
\end{CD} After dualizing the above diagram, we see that since $\omega$ is bi-invariant, $\omega_{xtx^{-1}}$ pulls back vertically to $\omega_e$ . Since $(\alpha\wedge\beta)_{(eT,e)}(\wedge A_i \otimes \wedge B_i)= \omega_e(\wedge A_i \bigwedge \wedge B_i)=1$ , we see that $\omega_e$ pulls back along the top arrow to $\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)(\alpha\wedge\beta)_{(eT,e)}$ . By the left invariance of $\alpha$ and $\beta$ , we see that $(\alpha \wedge \beta)_{(xT,t)}$ pulls back along the left vertical arrow to $(\alpha\wedge\beta)_{(eT,e)}$ . The commutativity of the above diagram thus shows $\phi^*\omega=\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)(\alpha\wedge\beta)$ . We now use the following fact: There exist dense open sets $U\subset T$ and $V\subset G$ such that $G/T\times U \to V$ is a $|W|$ -fold cover and $\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)$ never vanishes on $U$ . For a proof, see (Bump's Lie Groups $2$ nd Edition, prop. $17.3$ ). We now complete the proof by computing: \begin{equation}
\int_G fdg=\int_G fw=\int_V fw = \frac{1}{|W|}\int_{G/T\times U}\phi^*(fw) = \frac{1}{|W|}\int_{G/T\times U}f(t)\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)(\alpha\wedge\beta)\\
=\frac{1}{|W|}\left(\int_T f(t)\det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)dt\right) \left(\int_{G/T}\alpha\right).
\end{equation} Question: How do I show the form $\alpha$ constructed above integrates to give $1$ ? Edit: I feel like some computation of $d(t) := det\left(Ad(t^{-1})|_{\mathfrak{p}}-I_{\mathfrak{p}}\right)$ is required in the proof. If $\Phi$ denotes the set of weights of $T$ in the adjoint representation on $\mathfrak{p}\otimes_{\mathbb{R}} \mathbb{C}$ , we can write $$d(t) = \prod\limits_{\alpha\in\Phi}\left(\alpha(t^{-1})-1\right) = \prod\limits_{\alpha\in\Phi^+}|\alpha(t)-1|^2.$$ Is there any way to see that the  integral of this is equal to $|W|$ ?","['lie-algebras', 'proof-writing', 'proof-verification', 'lie-groups', 'differential-geometry']"
3021903,Particular solution of second order differential equation,"Given the ode: $$
y''-2y'+y=e^t,
$$ how can I find the form of the particular solution? At first, I tried the form $y=Ae^t$ but $$
\begin{split}
&\frac{d^2y}{dt^2}Ae^t=\frac{dy}{dt}Ae^t=Ae^t\\
\\
&Ae^t-2Ae^t+Ae^t=e^t\\
\\
&0=e^t\\
\end{split}.
$$ So this doesn't work. I also tried the form $y=Ate^t$ , but again $$
\begin{split}
&\frac{d^2y}{dt^2}=A(2e^t+te^t)\\
\\
&\frac{dy}{dt}=A(e^t+te^t)\\
\\
&A(2e^t+te^t)-2A(e^t+te^t)+Ate^t=e^t\\
\\
&2A+At-2A-2At+At=1\\
\end{split}.
$$ and again this doesn't work Generally, what is the best way to guess the form of the solution?",['ordinary-differential-equations']
3021916,Every finite state Markov chain has a stationary probability distribution,"I am trying to understand the following proof that every finite-state Markov chain has a stationary distribution. The proof is from here . Let $P$ be the $k \times k$ (stochastic) transition probability matrix for our Markov chain. Now, ... $1$ is an eigenvalue for $P$ and therefore also for $P^t$ .
  Writing a $P^t$ invariant $v$ as $v = v^+ − v^−$ with $v^+ , v^− \in (
> \mathbb{R}_+ )^k$ , we obtain $P^t v^± = v^±$ because $P^t$ preserves
  the positive cone; if $v^+\neq 0$ take $ν = ( \sum v^+_i )^{-1} · v^+,$ otherwise normalize $v^−$ . The main thing I don't understand is we obtain $P^t v^± = v^±$ because $P^t$ preserves
  the positive cone Why is this true? I also don't understand why $( \sum v^+_i )^{-1} · v^+$ works if $v^+ \neq 0$ . Is there any easier way to show that every finite state Markov chain has a stationary probability distribution?","['stochastic-matrices', 'proof-verification', 'markov-chains', 'probability']"
3021941,Proving the continuity of the Cantor Function,"Consider the Cantor Set $C=\{0,1\}^{\omega}$ , that is, the space of all sequences $(b_1,b_2,...)$ with each $b_i\in\{0,1\}$ . Define $g:C\rightarrow[0,1]$ by $$g(b_1,b_2,...)=\sum\limits_{i=1}^{\infty}\dfrac{b_i}{2^i}$$ In other words, $g(b_1,b_2,...)$ is the real number whose digits in base 2 are $0.b_1b_2...$ Prove that $g$ is continuous. Here is my attempt: Let sequences $(a_n)_{n\in\mathbb{N}}$ and $(b_n)_{n\in\mathbb{N}}$ be elements of the Cantor Set $C.$ For fixed $n\in\mathbb{N}$ let $A_n=(a_1,a_2,...,a_n)$ and $B_n=(b_1,b_2,...,b_n)$ be the first $n$ terms in each of those sequences. If $A_n\neq B_n$ , then $\exists m=min\{k\in\{1,2,...,n\}:a_k\neq b_k\}$ and the following holds: $$\begin{array}{c}
\left|\sum\limits_{k=1}^n\dfrac{a_k}{2^k}-\sum\limits_{k=1}^n\dfrac{b_k}{2^k}\right|=\left|\sum\limits_{k=1}^n\dfrac{a_k}{2^k}-\dfrac{b_k}{2^k}\right|\geq\dfrac{|a_m-b_m|}{2^m}-\left|\sum\limits_{k=m+1}^n\dfrac{a_k}{2^k}-\dfrac{b_k}{2^k}\right|\geq\\ \geq\dfrac{|a_m-b_m|}{2^m}-\sum\limits_{k=m+1}^n\dfrac{|a_k-b_k|}{2^k}    \\
\text{where $|a_m-b_m|$=1 and}\\
\sum\limits_{k=m+1}^n\dfrac{|a_k-b_k|}{2^k}\leq \sum\limits_{k=m+1}^n\dfrac{1}{2^k}=\dfrac{1}{2^m}\\
\text{Now,}\\
\left|\sum\limits_{k=n+1}^{\infty}\dfrac{a_k}{2^k}-\sum\limits_{k=n+1}^{\infty}\dfrac{b_k}{2^k}\right|=\left|\sum\limits_{k=n+1}^{\infty}\dfrac{a_k-b_k}{2^k}\right|\leq\\
\leq\sum\limits_{k=n+1}^{\infty}\dfrac{|a_k-b_k|}{2^k}\leq\sum\limits_{k=n+1}^{\infty}\dfrac{1}{2^k}=\dfrac{1}{2^n}\\
\text{Therefore, if $A_n\neq B_n$, then}\\
\left|f(a)-f(b)\right|=\left|\sum\limits_{k=1}^{\infty}\dfrac{a_k-b_k}{2^k}\right|=\left|\sum\limits_{k=1}^{n}\dfrac{a_k-b_k}{2^k}+\sum\limits_{k=n+1}^{\infty}\dfrac{a_k-b_k}{2^k}\right|\geq\\
\geq\left|\sum\limits_{k=1}^{n}\dfrac{a_k-b_k}{2^k}\right|-\left|\sum\limits_{k=n+1}^{\infty}\dfrac{a_k-b_k}{2^k}\right|\geq\dfrac{1}{2^n}-\dfrac{1}{2^n}=0
\end{array}$$ I think I must have done something wrong because I wanted $|f(a)-f(b)|$ to be greater than or equal to something in terms of $m$ or $n$ so that I can say choose $n$ (or $m$ ) such that (something like) $\dfrac{1}{2^n}<\varepsilon$ , but I just got 0 instead. How can I improve my proof so that I can achieve this?","['continuity', 'general-topology', 'cantor-set', 'real-analysis']"
3021973,"Find all non-negative integers $a, b$ satisfying $|4a^2 - b^{b+1}| \leq 3$","Find all non-negative integers $a, b$ satisfying $|4a^2 - b^{b+1}| \leq 3$ . I have been trying a simpler case $4a^2 - b^{b+1} = 0$ . I found that when $b$ is odd then $b^{b+1}$ have to be in form $b^{b+1} = c^2$ where $c$ is integer. So we have $(2a + c)(2a - c)=0 \implies 2a = c$ (otherwise $a$ would be negative). However, $c$ is odd because $b$ is also odd (odd number times odd number is odd). But this means that $a$ (since $2a = c$ ) isn't integer and that is contradiction. Therefore in this simpler case $b$ can't be odd. But above applies only for specific simpler case. For example for $a = b = 1$ original inequality holds. Can someone help me with this please?","['number-theory', 'inequality', 'modular-arithmetic', 'diophantine-equations']"
3021979,Is the Schwartz topologically emebedded in space of tempered distributions?,"Let $g\mapsto ( \cdot, g)_2$ denote the map from the Schwartz space $S$ into its dual space $S'$ where $(f,g)_2$ is the inner product in $L^2$ . Then is this a linear topological embedding ( $S'$ is endowed with the weak* topology)? Can anyone provide a reference or a simple proof?","['schwartz-space', 'functional-analysis']"
3021998,Physical interpretation of mean squared divided by variance of a distribution,"In chromatography, the signal is shaped like a Gaussian peak, and it is plotted against time vs. instrument's signal. https://en.wikipedia.org/wiki/Chromatography#/media/File:Rt_5_12.png Background: One of the ways to measure chromatographic efficiency is to calculate ""number of theoretical plates"" which is just (time of peak maximum)^2/ (variance of the peak in time units). It is a dimensionless number which essentially shows how narrow the peak is. I have searched the work of Martin & Synge (Nobel Prize) for they came up with the theoretical plate concept, however, nowhere they used this equation. However, every modern textbook, says the number of theoretical plates is defined as (peak maximum)^2/ (variance of the peak). One can use widths of the peak instead of variance, assuming the peak is Gaussian. No logic is provided as to why this measure was invented. https://www.shimadzu.com/an/hplc/support/lib/lctalk/theoretical_plate.html Is there any mathematical analog as to why one would divide the (mean)^2 by its variance or more rigorously, is there any physical interpretation of first-moment squared divided by the variance of the distribution. Thank you.","['statistics', 'mathematical-modeling', 'normal-distribution', 'mathematical-physics']"
3022036,Connection/Consistency Between Different Definitions of Polyhedron? And How Does This Proof Apply to This Definition?,"My textbook gives the following definition of a polyhedron: A polyhedron is defined as the solution set of a finite number of linear equalities and inequalities: $$\mathcal{P} = \{ x \mid a^T_j x \le b_j, \ j = 1, \dots , m, \ c_j^T x = d_j, \ j = 1, \dots , p \}$$ A polyhedron is thus the intersection of a finite number of halfspaces and hyperplanes.  Affine set (e.g., subspaces, hyperplanes, lines), rays, line segments, and halfspaces are all polyhedra. It is easily shown that polyhedra are convex set. I was trying to find a proof of the fact that polyhedra are convex sets, and so I came across this : Let $\mathrm{\mathbf{a}}$ be a vector and let $b$ a scalar. Suppose that $\mathrm{\mathbf{x}}$ and $\mathrm{\mathbf{y}}$ satisfy $\mathrm{\mathbf{a}}' \mathrm{\mathbf{x}} \ge b$ and $\mathrm{\mathbf{a}}' \mathrm{\mathbf{y}} \ge b$ , respectively, and therefore belong to the same halfspace. Let $\lambda \in [0, 1]$ . Then, $\mathrm{\mathbf{a}}'(\lambda \mathrm{\mathbf{x}} + (1 - \lambda)\mathrm{\mathbf{y}}) \ge \lambda b+ (1 - \lambda)b = b$ , which proves that $\lambda \mathrm{\mathbf{x}} +(1 - \lambda) \mathrm{\mathbf{y}}$ also belongs to the same halfspace. Therefore a halfspace is convex. Since a polyhedron is the intersection of a finite number of halfspaces, the result follows from part (a). The author provides a proof of this fact in his own question. However, after trying to understand this proof, a number of questions arose: The proof starts by supposing that $\mathrm{\mathbf{a}}' \mathrm{\mathbf{x}} \ge b$ and $\mathrm{\mathbf{a}}' \mathrm{\mathbf{y}} \ge b$ . But, in the above definition of a polyhedron, it is said that $\mathcal{P} = \{ x \mid a^T_j x \le b_j, \ j = 1, \dots , m, \ c_j^T x = d_j, \ j = 1, \dots , p \}$ ; in other words, we have that $a^T_j x \le b_j, \ j = 1, \dots , m$ , instead of $a^T_j x \ge b_j$ , which it seems is what the proof has? The above definition also has the set condition $c_j^T x = d_j, \ j = 1, \dots , p$ . Is this equivalent to $\mathrm{\mathbf{a}}'(\lambda \mathrm{\mathbf{x}} + (1 - \lambda)\mathrm{\mathbf{y}}) \ge \lambda b+ (1 - \lambda)b = b$ in the proof? The proof says that ""Since a polyhedron is the intersection of a finite number of halfspaces, ..."". What about the hyperplanes? I see no mention of them in the proof. I would greatly appreciate it if people could please take the time to clarify these.","['polyhedra', 'proof-explanation', 'geometry', 'convex-analysis', 'affine-geometry']"
3022037,Calculating $\sum\limits_{n=1}^\infty\frac{{1}}{n+3^n} $,I was able to prove this sum $$\sum_{n=1}^\infty\frac{{1}}{n+3^n}$$ is convergent through the comparison test but I don't get how to find its sum.,"['calculus', 'convergence-divergence', 'summation', 'sequences-and-series']"
3022086,What is the size of these discrete function sets?,"I'm interested in the set $F_n$ of functions $f:\{-1,1\}^n\to\{-1,1\}$ which can be represented as $x\mapsto\text{sign}(a\cdot x)$ for some $a\in\mathbf{R}^n$ .  What is the size of $F_n$ ?  Is there some discrete encoding which is 'better' then to write down the complete lookup table? My idea is to look at the number of connected components in $\mathbf{R}^n\setminus(\cup_x\{x\}^\bot)$ , since if $a,a'$ represent different functions $f,f'$ , say $f(y)\neq f'(y)$ , then I can't go from $a$ to $a'$ without crossing the border $a\cdot y=0$ .  But I still don't know how many such components there are. [EDIT]  I just tried to plot the planes $\{x\}^\bot$ in $\mathbf{R}^3$ (w.l.o.g. $x_1=1$ since $\{x\}^\bot=\{-x\}^\bot$ ), there seem to be $14$ partitions and they seem to correspond to the faces and edges of the $[-1,1]^3$ -cube.  But in even dimensions the picture needs to be different since the edges of the $[-1,1]^{2n}$ -cube lie directly on the planes","['linear-algebra', 'discrete-mathematics']"
3022096,Choosing balls from Urn,"So suppose you have 7 red balls, 7 blue balls, and 7 white balls, what is the probability of choosing 4 balls of one colour and the last ball of another colour without replacement.
Apparently the answer is $$\frac{\binom{3}{1}\times\binom{7}{4}\times\binom{2}{1}\times\binom{7}{1}}{\binom{21}{5}}$$ However, I thought you could get an equivalent answer by computing $$\frac{6}{20}\cdot\frac{5}{19}\cdot\frac{4}{18}\cdot\frac{14}{17}$$ But you get twice the probable chance from the choose method. Could somebody explain why the second way is flawed?",['discrete-mathematics']
3022139,Working with the product of sigma algebras,"I am currently taking a course in measure theory and I am struggling to grasp the concept well of the product of sigma algebras from an exercise. Suppose we have $\mathcal{A} = \sigma_X (\mathcal{E})$ and $B=\sigma_Y (\mathcal{F})$ as the smallest $\sigma$ -algebras on $X$ and $Y$ generated by some $\mathcal{E} \subseteq \mathcal{P}(X)$ and $\mathcal{F} \subseteq \mathcal{P}(Y)$ respectively. Now let $\mathcal{C} = \sigma_{X \times Y}(\{E \times F : E \in \mathcal{E}, F \in \mathcal{F}\})$ , I first want to show that $\mathcal{C} \subseteq \mathcal{A} \times \mathcal{B}$ . After writing down examples of smaller sets with $\sigma$ -algebras to get an idea of what was going on I feel like the right sort of approach would be to find elements that generate $\mathcal{C}$ and show that these are contained in $\mathcal{A} \times \mathcal{B}$ , as then the $\sigma$ -algebra would ensure that the rest of the elements of $\mathcal{C}$ are also contained in this set. To do this I thought that $\mathcal{C}$ was generated by all elements of $\mathcal{E} \times \mathcal{F}$ if I could show any element of $\mathcal{E} \times \mathcal{F}$ is contained in $\mathcal{A} \times \mathcal{B}$ then I would be done, which I feel can be reduced to showing all elements of $\mathcal{E}$ are contained in $\sigma_X(\mathcal{E})$ , though I am not sure as I do not know how to proceed from here. When I wasn't sure I tried the next part which is that the reverse inclusion holds under the condition that $X \in \mathcal{E}$ and $Y \in \mathcal{F}$ , that is that $\mathcal{A} \times \mathcal{B} = \mathcal{C}$ , which I had no idea how to proceed with. Any help or insight would be greatly appreciated thanks :)",['measure-theory']
3022155,Showing that a set is in the product $\sigma$-algebra of $\mathcal{P}(\mathbb{R}) \times \mathfrak{M}$?,"Broadly speaking, I am not sure how to show that a particular set is part of a product $\sigma$ -algebra. In particular, I am trying to show that $S = \{(x,y) \in \mathbb{R} \times \mathbb{R}: x = y\}$ is in $\mathcal{P}(\mathbb{R}) \times \mathfrak{M}$ (as part of a larger question about product measure spaces). Here, $\mathfrak{M}$ denotes the Lebesgue measurable subsets of $\mathbb{R}$ and $\mathcal{P}(\mathbb{R})$ is the power set of the reals. I’m not sure how to proceed. Any tips on how to solve the problem generally (or related exercises) are appreciated!","['measure-theory', 'real-analysis']"
3022189,About a bijective function with the disjoint sets,"In this video by 0:55, it says Lemma: Let $A,B,C,D$ be sets with $A\cap B=\emptyset$ and $C\cap D=\emptyset$ . Suppose that $F_1:A\to C$ and $F_2:B\to D$ are both bijections. Define $F:A\cup B\to C\cup D$ by $$
F(x)=\begin{cases}
F_1(x) & \text{ if } x\in A \\ 
F_2(x) & \text{ if } x\in B 
\end{cases}
$$ Then $F$ is a bijection. To me, it is easy to prove it by looking at the $F|_A$ and $F|_B$ seperately, and then, by construction, $F$ is bijective by collecting the elements of $A$ and $B$ . The question is, why do the intersections $A\cap B$ and $C\cap D$ have to be empty, in particular the last one?",['discrete-mathematics']
3022257,How to find lower Riemann integral in given function?,"$f(x)$ defined on $[0,1]$ as following - $$
\begin{align}
f(x) = \begin{cases}
0 & \text{if $x=0$}\\
\frac{1}{n} & \text{if $1/(n+1)<x\le 1/n$}
\end{cases}
\end{align}
$$ How to find lower Riemann integral of $f(x)$ from $0$ to $1$ .
My question is different from How to find the Riemann integral of following function? Since we know $f(x)$ has countable number of discontinuities hence it is Riemann integrable and we can find it's upper integral for getting the answer .But how to find lower Riemann integral of this function ? EDIT -  I know since $f(x)$ is Riemann integrable hence it's lower Riemann integral is same as upper Riemann integral.But how to find it by partitioning the domain or in other words by using definition of lower Riemann integral.","['measure-theory', 'riemann-integration', 'real-analysis']"
3022284,"Comparing $\ln 1000$, $\sqrt[5]{1000}$, $3^{1000}$, and $1000^{15}$ without calculator","In my Pre-Calculus class we were given the following problem: Put the following four values in order from smallest to largest: $\ln 1000$ , principal $5$ th root of $1000$ , $3^{1000}$ , and $1000^{15}$ . Using a calculator, I was able to figure out that the correct order is as follows: principal $5$ th root of $1000, \ln 1000, 1000^{15}, 3^{1000}$ . However, we are supposed to be able to solve this problem without a calculator, and then it becomes much more difficult for me, to say the least. I know that any exponential growth function (e.g., $3^x$ ) ""eventually"" outpaces any polynomial function (e.g., $x^{15}$ ). So I suppose the teacher could just be assuming that we will see $x = 1000$ and conclude that $1000$ seems ""sufficiently large"" for the exponential, $3^{1000}$ , to have outpaced $1000^{15}$ . Nonetheless, that is somewhat unsatisfying. Furthermore, it still provides no answer to the even trickier question of how you know $\ln 1000$ is greater than the principal $5$ th root of $1000$ . This becomes clear when you graph on a calculator, but as I said I'm supposed to be able to solve this problem without a calculator. And, indeed, the difference between $\ln 1000$ and the principal $5$ th root of $1000$ is only about $3$ , according to my calculator -- so which of the two is bigger seems hardly obvious to me from a quick glance at the two quantities (without plugging them into a calculator). It's an incredibly fascinating problem, but I just can't figure it out. Any answers would be greatly appreciated. Thank you so much!! :)","['exponentiation', 'logarithms', 'number-comparison', 'radicals', 'algebra-precalculus']"
3022290,Composition of two uniformly convergent sequences of functions is uniformly convergent?,"I am trying to prove or provide a counter-example for the following: Let $f_k$ and $g_k$ be sequences of continuous functions on $[0,1]\to[0,1]$ converging uniformly to $f:[0,1]\to \mathbb{R}$ and $g:[0,1]\to \mathbb{R}$ respectively. Does $f_k \circ g_k$ coverge uniformly to $f\circ g$ ? What I've done so far: I know I need to prove that $\forall \epsilon>0, \exists N\in \mathbb{N}$ such that $||f_k(g_k(x)) - f(g(x))|| < \epsilon$ for all $x \in [0,1]$ and $k\geq N$ . At first, I thought I can prove this easily since it follows trivially from the definition of $f_k$ uniformly converging to $f$ . However, I noticed that is only true for all $x \in [0,1]$ and $g$ maps onto all of $\mathbb{R}$ , not just $[0,1]$ . So does that mean it's not necessarily true? Can anyone provide a counter-example?","['sequences-and-series', 'uniform-convergence', 'real-analysis']"
3022309,"Expected number of terms needed to get a sum greater than $T$, for i.i.d. random variables uniformly distributed in $(0,1)$","Suppose we have $T>0$ , and $(X_n)_{n \in \mathbb N}$ is a collection of i.i.d. random variables that are uniformly distributed on $[0,1]$ . Define the random variable: $$
N := \max \left\{ n \in \mathbb N_0 : S_n \leq T \right\}
$$ where $S_n := X_1 + \cdots X_n$ . I want to compute $\mathbb E[N]$ . What I've done: I know $\mathbb E[N] = \sum_{k=0}^\infty k\mathbb P[N=k]$ , so the problem amounts to computing $\mathbb P[N = k]$ . Assume $0 < T \leq 1$ (I think the problem gets complicated for $T > 1$ , and I want to figure out the easy case first). We see that $$
\{N = k\} = \{S_k \leq T < S_{k+1}\},
$$ so the probability can be expressed in the iterated integral \begin{align*}
\mathbb P[N=k] &= \int_0^1\cdots \int_0^1 \mathbb 1_{\{S_k \leq T\}}\mathbb 1_{\{T < S_{k+1}\}} \, dx_{k+1} \cdots dx_1 \\
&= \int_0^T \int_0^{T-S_1} \cdots \int_0^{T-S_k} \int_{T-S_k}^1 dx_{k+1} \,dx_k \cdots dx_2 \, dx_1.
\end{align*} I was able to show by induction that this integral evaluates to $$
\mathbb P[N=k] = \frac{(-1)^k (1-T)^{k+1}}{(k+1)!} + \sum_{i=1}^k \frac{(-1)^{i-1}T^{k-i}}{i!(k-i+1)!}
$$ but this solution for the probability is a serious mess, and applying $\mathbb E[N] = \sum_{k=0}^\infty k\mathbb P[N=k]$ doesn't seem to lead to anything nice. My question. Is there anything standard that this sum converges to? Or anything similar? Something binomial, perhaps? Alternatively, is there an easier way to compute $\mathbb E[N]$ ? I saw on some posts that $$
\mathbb E[N] = \sum_{k=0}^\infty \mathbb P[N > k]
$$ and these probabilities are much easier to compute and work out much more cleanly, but it's not clear to me why this is true.","['expected-value', 'uniform-distribution', 'probability-theory']"
3022310,Has the Riemann Rearrangement Theorem ever helped in computation rather than just being a warning?,"A decent course in elementary analysis will eventually discuss series, absolute convergence, conditional convergence, and the Riemann Rearrangement Theorem. However, in any presentation I've seen, in person or within a text, the discussion sort of ends after Riemann's theorem is given---quite content in proving to the student(s) or the reader that one shouldn't extend finite intuition to infinite settings without providing a proof. I agree that this is an important moral to impart; however, I'm interested in something else: Has the Riemann Rearrangement theorem been used as a computational aid to explicitly calculate a sum? By this vague question, I specifically have in mind that piece of Riemann's Theorem that states an absolutely convergent series is commutatively convergent. So, to be slightly more narrow in scope: Has there been a series $\sum a_k$ which is fairly easy to show absolutely converges; however, the sum itself was computed by a clever choice of bijection $\sigma:\mathbb{N}\rightarrow\mathbb{N}$ and by working with the partial sums of $\sum a_{\sigma(k)}$ ? This is a rather vague question, and I don't expect it to have much of an absolute answer. But I'm interested in any variety of answers, and I'm sure they'd be demonstrative and helpful to future readers.","['big-list', 'real-analysis', 'absolute-convergence', 'sequences-and-series', 'riemann-sum']"
3022318,Showing sequence is Cauchy by Definition,"Question : I have to show that sequence $(x_n)$ defined by $x_n=\frac{n+(-1)^n}{2n-1}$ , $n=1,2,3,...$ . Is Cauchy sequence using definition only. My attempt : (I can see given sequence is Cauchy because it is convergent sequence in $\mathbb{R}$ )But I have to show it Cauchy by using definition of Cauchy sequence only. So I   considered $|x_n-x_m|= |\frac{n+(-1)^n}{2n-1}-\frac{m+(-1)^m}{2m-1}|$ $=|\frac{(n+(-1)^n)(2m-1)-(m+(-1)^m)(2n-1)}{(2n-1)(2m+1)}|$ $=|\frac{m-n+(-1)^n 2m+(-1)^{m+1}2n+(-1)^{n+1}+(-1)^{m+2}}{(2n-1)(2m-1)}|$ but I am unable to proceed further :-( please Help me...","['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
3022329,Solve $\frac{d^2y}{dx^2}+2\frac{dy}{dx}+y=x \sin^2x$,"Solve the differential equation Solve $$\frac{d^2y}{dx^2}+2\frac{dy}{dx}+y=x \sin^2x$$ i used the substitution $\frac{dy}{dx}+y=t$ we get $$\frac{dt}{dx}+t=x\sin^2x$$ which is linear first order, using integrating factor method we get the solution $$te^x=\int xe^x\sin^2xdx+C$$ $$te^x=\frac{1}{2} \left(\int xe^xdx-\int xe^x\cos 2xdx\right)+C=\frac{1}{2}\left(P-Q\right)+C \tag{1}$$ we have $$P=\int xe^x=(x-1)e^x+C'$$ now using integration by parts we have $$Q=\int xe^x \cos2xdx=x\int e^x\cos 2xdx-\int \left(\int e^x\cos 2xdx\right)dx$$ $$\int xe^x \cos2xdx=\frac{xe^x}{5}\left(\cos 2x+2\sin 2x\right)-\frac{1}{5}\int e^x(\cos 2x+2\sin 2x)dx $$ $$\int xe^x \cos2xdx=\frac{xe^x}{5}\left(\cos 2x+2\sin 2x\right)-\frac{1}{5}\left(\frac{e^x}{5}(\cos 2x+2\sin 2x)\right)-\left(\frac{2e^x}{5}(\sin 2x-2 \cos 2x)\right)$$ finally we need to solve another linear differential equation viz: $$e^x\left(\frac{dy}{dx}+y\right)=\frac{1}{2}\left(P-Q\right)+C$$ which is very tedious. is  there a good approach?","['integration', 'algebra-precalculus', 'ordinary-differential-equations']"
3022345,Is the Set of Continuous Functions that are the Sum of Even and Odd Functions Meager?,"Consider $X = \mathcal{C}([−1,1])$ with the usual norm $\|f\|_{\infty} = \sup_{t\in [−1,1]}|f(t)|.$ Define $$\mathcal{A}_{+}=\{ f \in X : f(t)=f(−t) \space \forall t\in [−1,1]\},$$ $$\mathcal{A}_{−}=\{ f \in X : f(t)=−f(−t) \space \forall t \in [−1,1]\}. $$ Is $\mathcal{A}_{+} +\mathcal{A}_{−} = \{f +g : f \in \mathcal{A}_{+},g \in \mathcal{A}_{−}\}$ meager? I know this set is dense by the Stone-Weierstrass Theorem. However, that doesn't really help. I also know that if the set is closed, then it is meager, but I have difficulties deciding whether it is closed or not. I know the exponential function is a limit of a sequence of a sum of even and odd functions, however one could define it to be that, in which case it doesn't help. Any hints on how to get going on this problem, and on whether the set $\mathcal{A}_{+}+{A}_{-} $ is closed or not? Thank you in advance.","['metric-spaces', 'real-analysis', 'functional-analysis', 'general-topology', 'baire-category']"
3022402,"If $f$ is holomorphic on a domain $D$, and satisfies $a\operatorname{Re}(f(z))+b\operatorname{Im}(f(z))=c$ for all $z\in D$, then $f$ is constant","The proposition that I am required to prove is the following Let $D \subset \mathbb{C}$ be a domain and suppose $f(x, y)=u(x,
 y)+iv(x, y)$ is holomorphic on $D$ . Let $a, b, c\in \mathbb{R}$ such
  that $a^2+b^2>0$ and $$au(x, y)+bv(x, y)=c \quad \forall z=(x, y)\in D$$ Prove $f$ is constant I will write $u(x, y)$ as $u$ in short, and similarly for $v(x, y)$ .
My attempt is as follows:
Since f is holomorphic we have: $$\dfrac{\partial u}{\partial x}=\dfrac{\partial v}{\partial y}\qquad \dfrac{\partial u}{\partial y}=-\dfrac{\partial v}{\partial x}$$ If $a=0\neq b$ , then $bv=c \implies v=K\in\mathbb{R}$ $$\implies \dfrac{\partial u}{\partial x}=\dfrac{\partial v}{\partial y}=\dfrac{\partial u}{\partial y}=-\dfrac{\partial v}{\partial x}=0$$ $$\implies f'(z)=0 \quad \forall z\in D$$ Similarly for $a\neq 0=b$ Now the remaining case to check is if $a\neq 0\neq b$ Taking partial derivatives both sides of the given relation we get: $$a\dfrac{\partial u}{\partial x}+b\dfrac{\partial v}{\partial x}=0$$ $$\implies \dfrac{\partial u}{\partial x}=\dfrac{b}{a}\bigg(-\dfrac{\partial v}{\partial x}\bigg)=\dfrac{b}{a}\dfrac{\partial u}{\partial y}$$ Similarly taking partial derivatives w.r.t $y$ we get: $$\dfrac{\partial u}{\partial x}=-\dfrac{a}{b}\dfrac{\partial u}{\partial y}$$ $$\implies \dfrac{a}{b}=\dfrac{-b}{a}$$ $$\implies a^2+b^2=0$$ This is a contradiction, so it is not possible that $a\neq 0\neq b$ . Therefore for all possible values of $a$ and $b$ , the function $f$ is constant.","['complex-analysis', 'holomorphic-functions', 'proof-verification']"
3022425,Prove that $\int_0^{\frac{n\pi}{4}} \frac{1}{3\sin^4(x) + 3\cos^4(x) -1} dx = \frac{n\pi}{4} $,"Prove that $$\int_0^\frac{n\pi}{4} \left(\frac{1}{3\sin^4(x) + 3\cos^4(x) -1}\right) dx = \frac{n \pi}{4} $$ is true for all integers $n$ . Here I've looked at the case where $n=1$ as $t=\tan(x)$ is injective in that domain. Then I could perhaps try to use some argument about periodicity and symmetry to extend it to all the integers. $$
= \int_0^\frac{\pi}{4} \frac{\sec^4(x)}{3\tan^4(x)+3-\sec^4(x)} \text{d}x
= \frac12 \int_0^1 \frac{t^2+1}{t^4-t^2+1} \text{d}t
$$ Which looks a little tough but reminiscent of the well-known integral: $$ \int_0^\infty \frac{1}{x^4 + 2x^2\cos(2a) + 1} \text{d}x = \frac12\int_0^\infty \frac{x^2+1}{x^4 + 2x^2\cos(2a) + 1} \text{d}x = \frac{\pi}{4\cos(a)} $$ Where we choose $a=\frac\pi3$ . But I can't seem to adjust the bounds to get an answer. How would you evaluate this integral?","['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
3022548,"Calculate $\sum_{|\cup S|=k}(-1)^{|S|+1}$ where $S$ is a non-empty subset of $X=\{\{a_1,a_2\},\{a_2,a_3\}\cdots,\{a_n,a_{n+1}\}\}$","Let $x_i=\{a_i,a_{i+1}\}\ (1 \leq i \leq n)$ and $X=\{x_1, \cdots, x_n\}$ . Given $k$ , I'd like to ask how to calculate $\sum_{|\cup S|=k}(-1)^{|S|+1}$ where $S$ is a non-empty subset of $X$ ? The problem can be transformed into $\sum_{t}\sum_{\substack{|\cup S|=k\\|S|=t}}(-1)^{|S|+1}=\sum_{t}(-1)^{t}\sum_{\substack{|\cup S|=k\\|S|=t}}1$ . The last summation can be interpreted as counting how many length- $n$ binary strings with $t$ ones such that the number of consecutive ""11"" substrings is $2t-k$ . But it's still hard to perform calculation.","['elementary-set-theory', 'combinatorics']"
3022617,"Showing that $\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\|$","Exercise : Let $\{e_1,e_2,\dots, e_n\}$ be an orthonormal set over the Hilbert space $H$ . Show that : $$\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\|$$ for every $\lambda_1,\lambda_2,\dots,\lambda_n \in \mathbb R$ . Attempt : Let $x \in H$ and $\varepsilon > 0$ . Then,  we can find $\lambda_1,\dots, \lambda_n \in \mathbb R$ such that : $$\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon$$ But the element $w = x-\sum_{k=1}^n\langle x,e_k\rangle e_k$ achieves the minimum distance of $x$ from the finite dimensional space $ F = \langle e_1,\dots, e_n \rangle$ and then it will be $$\bigg\| x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\| \leq \bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon$$ and thus the inequality which we were asked to show is proven. Question : Is my approach rigorous and legit enough ? If not, any recommendations, hints or elaborations will be greatly appreciated !","['inner-products', 'normed-spaces', 'real-analysis', 'hilbert-spaces', 'functional-analysis']"
3022620,"If $\sum a_k$ converges, does $\sum(a_{k+1}- 2 a_{k+3})$ converge as well?","If $\sum_{k=0}^\infty a_k$ is convergent with value $s$ , what about $\sum_{k=0}^\infty b_k$ where $b_k=a_{k+1}- 2 a_{k+3}$ ? My reasoning: $$\sum_{k=0}^\infty b_k =\lim_{n \rightarrow \infty} \sum_{k=0}^n b_k=\lim_{n \rightarrow \infty} \sum_{k=0}^na_{k+1}-2a_{k+3}
$$ Within the sum we are only dealing with finitely many terms, we can split up the sum and take the limit afterwards: $$ \lim_{n \rightarrow \infty} \sum_{k=0}^n b_k=\lim_{n \rightarrow \infty} \left( \sum_{k=0}^n a_{k+1}- \sum_{k=0}^n 2a_{k+3} \right) $$ Now we want to get $s$ in here, the value of our sum, we need to do some index juggling, since our sum is not of the right form yet. $$\lim_{n \rightarrow \infty} \left( \sum_{k=0}^n a_{k} - a_0- 2\sum_{k=0}^n a_{k}  +2a_0 + 2a_1+2a_2\right) $$ Here we applied an index shift, but then we need to compensate for the terms that we added to the sum, we finally apply the limit and get: $$\sum_{k=0}^\infty b_k=s +a_0-2s+2a_1+2a_2= a_0+2a_1+2a_2 -s $$ Did that all make sense, is my reasoning correct? 
conclusion: it converges as we computed the exact value.","['proof-verification', 'sequences-and-series', 'real-analysis']"
3022648,When an MLE attains the Cramer-Rao bound for an exponential family.,"I'm trying to do the following exercise: Let $$\delta_\theta(x)=S(x)\exp (\theta T(x)-f(\theta))$$ be a family of densities for a random variable $X:\Omega\rightarrow 
 \mathbb{R}$ , where $\theta$ takes values in an open interval, and $T:\mathbb{R}\rightarrow \mathbb{R}$ is a non-constant function. 
  Suppose the maximum likelihood estimator $\hat{\theta}(x)$ exists and has
  finite variance for all $\theta$ .  Prove that $\hat{\theta}(x)$ attains
  the Cramer-Rao lower bound for all $\theta$ if and only if $f'(\theta)$ has the form $\alpha \theta+\beta$ for constants $\alpha$ and $\beta$ . At present, all i know about the MLE $\hat\theta$ is that, for given $x\in \mathbb{R}$ , it is the solution to $$f'(\hat\theta) = T(x) \label{a}\tag{1}$$ On its face, the question doesn't make much sense to me, since the book hasn't given me any information about the bias of $\hat{\theta}$ .  So in principle, the Cramer-Rao lower bound $$Var(\hat{\theta})\geq \frac{[\frac{d}{d\theta}(\mathbb{E}_\theta[\hat{\theta}(x)])]^2}{\mathbb{E}_\theta[( \frac{\partial}{\partial\theta}\log \delta_\theta(x))^2]}$$ isn't really a lower bound, since the numerator depends on the estimator $\hat{\theta}$ .  And the numerator could be zero, in principle. Setting that aside, I think what the question wants me to do is just to write down the condition where the Cauchy-Schwarz inequality (used in the proof of the Cramer-Rao lower bound) gives equality:  We have $$\frac{d}{d\theta}\mathbb{E}_\theta[\hat \theta(x)]=\frac{d}{d\theta}\int_\mathbb{R}\hat \theta(x) \delta_\theta(x) ~~dx=\int_\mathbb{R}\hat \theta(x)~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx=$$ $$\int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx ~~~\text{(since}\int_\mathbb{R}[\frac{\partial}{\partial \theta} \delta_\theta(x)]\delta_\theta(x)^{-1}\cdot~\delta_\theta(x)dx=0 \text{)}$$ $$= \int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~[T(x)-f'(\theta)]~\cdot~\delta_\theta(x)~~dx\leq \sqrt{\int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])^2~ \delta_\theta(x)~dx \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx}=$$ $$\sqrt{Var(\hat \theta) \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx}$$ Whereas if we wanted equality we would need $$\hat \theta(x)-\mathbb{E}_\theta[\hat \theta]= C(\theta)\cdot[T(x)-f'(\theta)] $$ where $C(\theta)$ is a constant depending only on $\theta$ . At this point I am totally stuck. And I haven't even used equation \ref{a}.","['statistics', 'probability']"
3022649,Basic properties of complete intersection ideals,"The title is quite self-explanatory. I'm studying, for an exam, the paper ""The solution to Waring's problem for monomials"" (this is the link https://arxiv.org/abs/1110.0745 ). At the bottom of page 2, Lemma 2.2, we consider $J=(y_1,y_2^{a_2},\ldots, y_n^{a_n}) \subset T=k[y_1,\ldots,y_n]$ ideal with $2\leq a_2\leq\ldots\leq a_n$ . The authors note that $J$ is homogeneous (and I agree) and complete intersection, for which they assert $$A=T/J$$ is an artinian Gorenstein ring, with $\dim A_\tau \neq 0$ for $\tau=a_2+\ldots+a_n-(n-1)$ . My question are: 1) Why we can simply note $J$ is complete intersection? 2) Where can I find a proof of the statement "" $J$ homogeneous and complete intersection $\implies$ A artinian and Gorenstein""? 3) I know what a Gorenstein ring is, but I can't see why $\dim A_\tau \neq 0$ for this $\textit{specific}$ $\tau$ . I know there's a lot of stuff in this question, but I hope someone can help me understaning, or suggesting me some references. Thanks in advance.","['algebraic-geometry', 'commutative-algebra', 'ideals']"
3022669,Let $\Delta ABC$ be a right triangle. Prove that $\angle BEH=\angle HCI$.,"Let $\Delta ABC$ is a right triangle. $D$ is chosen arbitrarily in $AB$ ,the segment $DH$ is perpendicular to the segment $BC$ at $H$ , $E\in AC$ such that $DE=DH$ . $I$ is the midpoint of $HE$ . Prove that $\angle BEH=\angle HCI$ . Let the intersection point of $CI$ and $BE$ be $X$ . So we need to prove that $\angle HCX=\angle XEH$ or $XECH$ is a cyclic quadrilateral. Or $\Delta BHX$ and $BEC$ are similar triangles (side-angle-side) $$\Leftrightarrow \frac{BE}{BC}=\frac{BH}{BX}.$$ Then I do not know how to get it, and that idea has not used $DE=DH$ .","['euclidean-geometry', 'geometry', 'triangles', 'trigonometry', 'problem-solving']"
3022717,Help in understanding why the arithmetic derivative is well-defined.,"I'm reading into the arithmetic derivative at the moment and I just don't get why it is well-defined. For reference, Ufnarovski tried explaining it here on page 2. I would like to understand the not explicitly stated induction. Thanks in advance!","['number-theory', 'definition', 'arithmetic-derivative', 'elementary-number-theory']"
3022721,Confidence interval for mean of a normal population,"Consider a normal population with unknown mean $\mu$ and variance $\sigma^2=9$ . To test $H_{0}:\mu=0$ ,against $H_{1}:\mu \ne 0$ . A random sample of size 100 is taken. Based on this sample, the test of the form $|\bar{X_n}| > K$ rejects the null hypothesis at 5% level of significance. Then, which of the following is a possible 95% confidence interval for $\mu$ ? (A) (-0.488, 0.688) (B) (-1.96, 1.96)
(C) (0.422, 1.598) (D) (0.588, 1.96) Now, if we construct the test statistic $\tau=\frac{\bar{X_n}-\mu}{0.3} \sim N(0,1)$ Therefore our test ,actually based on the observed value of $\tau=\tau_{0}$ is given by $|\tau_{0}|> \tau_{\frac{\alpha}{2}}$ where $\alpha=0.05$ Now,we get $K=\frac{3}{10}\tau_{0.025}=0.588$ Thus the 95% confidence interval for $\mu$ is coming to be $(\bar{X_n}-0.588 ,\bar{X_n}+0.588)$ So, looking at the options it seems that both (A) , (C) are correct but only (C) is given to be correct.
Please help!","['statistical-inference', 'statistics', 'confidence-interval', 'normal-distribution', 'probability']"
3022731,Eigenvalues and power of a operator,"If $\lambda$ is an eigenvalue of $A^k$ , prove that at least one of the $k^{th}$ roots of $\lambda$ is an eigenvalue of $A$ . I know it is easy to prove when $A$ can be presented by a matrix, but $A$ is an operator on a complex inner product space, which may be infinite dimensional.","['operator-theory', 'functional-analysis']"
3022822,Minimum value of the given function,"Minimum value of $$\sqrt{2x^2+2x+1} +\sqrt{2x^2-10x+13}$$ is $\sqrt{\alpha}$ then $\alpha$ is________ . Attempt Wrote the equation as sum of distances from point A(-1,2) and point B(2,5) as $$\sqrt{(x+1)^2 +(x+2-2)^2} +\sqrt{(x-2)^2 + (x+2-5)^2}$$ Hence the point lies on the line y=x+2 it is the minimum sum of distance from the above given two points. But from here I am not able to get the value of x and hence $\alpha$ . Any suggestions?","['algebra-precalculus', 'geometry']"
3022835,let's play a (continuous) probability game!,"Here's the description of the game. We have a target number $x$ in mind and start by picking a number $c_1$ uniformly at random from $(0, 1)$ . Then $c_2$ is picked uniformly at random from $(0, c_1)$ , and in general, $c_i$ is picked uniformly at random from $(0, c_{i -1})$ . The game stops when we pick a $c_i$ such that $c_i < x$ . What is the expected number of times we'll have to pick a number $c_i$ ?
Alternatively, what is the expected length of the sequence of $c_i$ 's? I am guessing that the solution will be in terms of our target $x$ . How would one go about approaching this problem? I thought about conditioning in terms of $c_1$ , but I couldn't work it out. Edit: we have $x \in (0, 1)$ . Edit 2: I am not hell-bent on using a conditional expectation approach. But if there exists some ridiculously simple solution, I am guessing it would involve it.","['statistics', 'conditional-probability', 'probability-distributions', 'probability-theory', 'probability']"
3022878,"Given $\tan\alpha=2$, evaluate $\frac{\sin^{3}\alpha - 2\cos^{3}\alpha + 3\cos\alpha}{3\sin\alpha +2\cos\alpha}$","I need some help with this exercise. Given that $$\tan\alpha=2$$ calculate the value of: $$\frac{\sin^{3}\alpha - 2\cos^{3}\alpha + 3\cos\alpha}{3\sin\alpha +2\cos\alpha}$$ I've tried everything but I always end up having something irreducible in the end. Maybe this is an easy question, but I'm new at trigonometry. If anyone can help me by providing a step-by-step solution to this, I would be really thankful! :)","['algebra-precalculus', 'trigonometry']"
3022907,Bounded operator but not Compact,"Let $T : (C([-1,1]),||.||_{\infty}) \rightarrow  (C([-1,1]),||.||_{\infty}) $ Such as : $(Tf)(x)=\frac{1}{2}(f(x)+f(-x))$ . For all $f\in C([-1,1])$ Why $T$ isn't Compact ? I tried to use the sequence $f_n(x)=x^n$ . For $x\in [-1,1]$ . But I couldn't prove that $(T(f_n))_n$ has no convergent subsequence.","['operator-theory', 'compact-operators', 'functional-analysis', 'unbounded-operators']"
3022916,Related to girth of planar graphs,"From the paper https://web.math.princeton.edu/~pds/papers/girth6/paper.pdf , a cubic (every vertex is degree 3), planar graph has girth (smallest length face) strictly less than 6. It is also true that a cubic, bipartite (all faces even length) graph contains a square (or a 2-gon). I am interested in planar graphs with exactly one degree 2 vertex, the rest degree 3. Is it true that such a graph must contain a face of length 1,2, 3 or 5? (In other words, a face of length less than or equal to 5 that is not a square.)","['graph-theory', 'combinatorics', 'discrete-mathematics', 'planar-graphs']"
3022949,Looking for a proof for this counting problem,"Consider all the coefficients in the expansion of $$(x^a+x^b)^n$$ where $a,b,n$ are non negative integers. Claim: The $\color{Red}{\textit{exponent}}$ with the $\color{blue}{\textit {maximum coefficient value}}$ in the expansion is $\color{red}{\lfloor\frac{n(a+b)}2\rfloor}$ Example : $(x^1+x^3)^4 = \sum\limits_{k=0}^4\binom{4}{k}x^{n-k}x^{3k} = x^{4} +4x^{6}+\color{blue}{6}x^{\color{red}{8}}+4x^{10}+x^{12}$ $\color{red}{\dfrac{4(1+3)}{2} = 8}$ . I feel this is a special case of central limit theorem in probability, but that theorem seems way more complicated to understand than my special case. So I'm trying to make sense of this result w/o using CLT. Any help ?",['combinatorics']
3022958,Is it possible to integrate something that isn't a function?,"How would you ""find the area under the curve"" of something that isn't quite a curve? The graph may be curved at places, but if it's not a function (the same x value has more than one corresponding y value) when how would you find the area of it? Is it possible? Just curious.","['integration', 'calculus', 'area']"
3022966,"$a(x-a)^2+b(x-b)^2=0$ has one solution; $a, b$ are not $0$. Prove $|a|=|b|$","$a(x-a)^2+b(x-b)^2=0$ has one solution; $a, b$ are not $0$ . Prove $|a|=|b|$ simplifying the equation I got: $$(a+b)x^2-2(a^2+b^2)x+(a^3+b^3)=0$$ solving for the Discriminant $D=0$ , I got: $$a(a^2b-2ab^2+b^3)=0$$ and since $a$ cannot equal $0$ , I got: $$a=b \implies |a|=|b|$$ In the same way I also got: $$b=a$$ But I don't need the absolute values of $a, b$ because I got $a=b$ (which means $|a|=|b|$ is not needed) and checking in the equation $a$ cannot equal $-b$ because then the equation will have infinitely many solutions instead of just one as specified in the task. Now, because I need to prove that $|a|=|b|$ and not that $a=b$ , I think that I am missing something. So, am I missing something or is my solution correct?",['algebra-precalculus']
3023006,Bound on $L^1$ norm of $\limsup$ gives convergence in measure?,"Suppose $\{f_n\}$ is a sequence of nonnegative measurable functions on $[0,1]$ such that $f_n(x)\leq K$ for all $n\in \mathbb{N}$ and $x\in [0,1]$ . Let $f=\limsup f_n$ and assume that $||f_n||_1\geq ||f||_1$ for each $n$ . Then, is it true that $f_n\rightarrow f$ in measure? It is true via Fatou's Lemma and the uniform bound that $$\int f(x) \;dx \geq \limsup \int f_n(x)\; dx \geq \liminf \int f_n(x)\;dx\geq \int f(x) \; dx,$$ so we get $\lim \int f_n(x)dx=\int f(x)$ . This is about where I get stuck. Would it be useful to look at the sets $$A_n=\{x\in [0,1]: f_n(x)>f(x)+\epsilon\} \qquad \text{and} \qquad B_n=\{x\in [0,1]:f_n(x)<f(x)-\epsilon\},$$ since we need to show $\lambda(A_n\cup B_n)\rightarrow 0$ as $n\rightarrow \infty$ ? Or is there a better way? I would appreciate any hints or solutions.","['measure-theory', 'convergence-divergence', 'real-analysis']"
3023032,Finding the minimal number of members,"I've been working on the following problem For every issue in the Blue's association, a commission with 10 members (belonging the Blue's) is formed in order to solve the problem. The only condition is There can't be two commissions having more than one member in common The Blue's association has formed this year 40 commissions. What's the minimal amount of members in the Blue's association? I've only found out the following For any commission you can form $\binom{10}{2}=45$ different pairs and none of them can appear in another commission. Since 40 different commissions are formed, the minimal number of pairs is $45\times 40=1800$ . Denote by $n$ the number of members. Thus $$\binom{n}{2}≥1800\Rightarrow n>60$$ $$$$ The minimal amount of members has to be 100 or less. You can observe a distribution for 100 members here My question: Is 100 the answer or is there an ever smaller possible amount of members?
If so, how can I prove it?",['combinatorics']
3023110,Prove that $BH=AH$,"A triangle $ABC$ is given. There's a point $P$ inside it and also it is connected to point $H$ , which lies on edge $BC$ ( $H$ must not be the middle point of edge $BC$ ). Turns out, that bisector of angle $∠AHP$ is perpendicular to edge $BC$ . Also, $BP=AC$ and $∠PCH=∠ABC$ . Prove that $BH=AH$ . What I found out was that since triangle $ACH$ hypothetically should be equal to triangle to $PBH$ , we could prove what we need by proving that for example $PH=CH$ - though again, I have no idea how to do it. Could you recommend me any smart lines or segments to draw?","['euclidean-geometry', 'geometry', 'triangles', 'trigonometry', 'problem-solving']"
3023128,Find UMVU estimator for $e^{-3 \theta}$ given a complete sufficient statistic $X \sim Pois(\theta)$ with $\theta>0$.,"My attempt: We know, since $X\sim Pois(\theta)$ that $\mathbb{P}_{\theta}(X=x)=e^{-\theta}\theta^{x}/x!$ . A given tip is that we must recall that $e^{x}=\sum^{\infty}_{k=0}\frac{x^{k}}{k!}$ . I know that once we find an unbiased estimator that is a function of our complete sufficient statistic $X$ , that this estimator must then automatically be UMVU. However, I'm not sure how to approach this question by even finding an expression for an unbiased estimator. Question: How to approach/solve this exercise? Thanks!","['statistical-inference', 'statistics', 'parameter-estimation', 'probability-theory', 'probability']"
3023219,Finding the maximum of a function on a triangle,"I want to find the maximum of $f(x,y) = x^ae^{-x}y^be^{-y}$ on the triangle given by $x\geq0$ , $y\geq0$ , and $x+y\leq1$ in terms of $a$ and $b$ such that $a,b>0$ . I can see that the vertices of the triangle are $(0,0)$ , $(1,0)$ , and $(0,1)$ . To check whether there is a maximum in the interior of the triangle, would I just check to find points where both partials vanish, or do I need to apply Lagrange multipliers? If so, what would I use for the constraint function? On the boundaries, I know to check the values at the three vertices, but what about all the other points on the boundaries?","['multivariable-calculus', 'lagrange-multiplier']"
3023224,Prove that $\sum_{n=0}^{\infty}\frac{\Gamma^2(n+1)}{\Gamma(2n+2)}=\frac{2\pi}{3^{3/2}}$,"I am seeking alternate proofs for $$\sum_{n\geq0}\frac{\Gamma^2(n+1)}{\Gamma(2n+2)}=\frac{2\pi}{3^{3/2}}$$ Here's mine: Recall that, for $x\in(0,2)$ , $$\frac1x=\sum_{n\geq0}(1-x)^n$$ Hence we have that, for $\frac{1-\sqrt5}2<x<\frac{1+\sqrt5}2$ , $$\frac1{x^2-x+1}=\sum_{n\geq0}x^n(1-x)^n$$ Which gives $$
\begin{align}
\int_0^1\frac{\mathrm dx}{x^2-x+1}=&\int_0^1\sum_{n\geq0}x^n(1-x)^n\mathrm dx\\
=&\sum_{n\geq0}\int_0^1x^n(1-x)^n\mathrm dx\\
=&\sum_{n\geq0}\frac{\Gamma^2(n+1)}{\Gamma(2n+2)}
\end{align}
$$ That last step was from the definition of the Beta function: $$B(a,b)=\int_0^1t^{a-1}(1-t)^{b-1}\mathrm dt=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$$ Setting $I=\int_0^1\frac{\mathrm dx}{x^2-x+1}$ , we complete the square: $$I=\int_0^1\frac{\mathrm dx}{(x-\frac12)^2+\frac34}$$ Preforming the substitution $x=\frac{1+3^{1/2}\tan u}2$ , we have $$I=\frac{3^{1/2}}2\int_{-\pi/6}^{\pi/6}\frac{\sec^2u\ \mathrm du}{\frac34+\frac34\tan^2u}$$ And with a little simplification, we arrive at $$\sum_{n\geq0}\frac{\Gamma^2(n+1)}{\Gamma(2n+2)}=\frac{2\pi}{3^{3/2}}$$ Which brings me to my questions. How else can we prove this? What other series can be evaluated using similar tricks? Have fun!","['alternative-proof', 'special-functions', 'sequences-and-series']"
3023225,Notation when integrating with respect to a measure,"I have seen the following three notations and was wondering if they were all equivalent: Over $(S, \mathcal{A}, \mu)$ , $\int_S f \, d\mu= \; \int_S f(x) d\mu(x) = \int_S f(x) \mu(dx)$ to denote the act of integrating over a measure?
Moreover, while (at least in my course), we assume this to be the Lebesgue integral over the bounds of S which can, should it Riemann integrable over these same bounds, be rexpressed as a Riemann integral - is this true in the general case?","['measure-theory', 'lebesgue-integral', 'probability-theory']"
3023232,A curious geometry problem: Find the $\angle OBC$,"I can not find a Method for to solve this geometry problem.I don't even know how to start.In fact, I didn't want to add my nonsensical attempts.
I looked for a similar question to this question (solved), but unfortunately, I couldn't find it. That's why I need help. I think I don't have enough mathematical information to solve this problem .","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'trigonometry']"
3023371,How can I prove that a continuous decreasing function on $\Bbb R$ has a fixed point?,"I am trying to prove that a continuous decreasing function $f: \Bbb R → \Bbb R$ has a fixed point. I tried to use the function $g(x) = f(x) - x$ , which should be a decreasing one, but I don't know how to obtain a point of $g$ that is $0$ .","['continuity', 'functions', 'analysis']"
3023378,Considering the function $g(x) = 2 + e^x$.,"Considering the function $g(x) = 2 + e^x$ . a) Find $g’(x)$ . So, this is simply derivative of the function. This would be $g’(x) = e^x$ , right? b) Explain how this shows that $g(x)$ is an increasing function for all values of $x$ . In this case, don’t we set the derivative to $0$ and find what the $x$ equals? Then, we put the $x$ values on a sign chart to find out if it is increasing or decreasing? c) Find the equation of the tangent line to $g(x)$ at $x=1$ . For this part, we plug $x$ into our derivative to get the slope, right? Then we plug $x=1$ into the original function, $g(x)$ to get our $y$ value. Then find our $b$ value by plugging our y, x, and slope values.",['functions']
3023401,"The linearization at an equilibrium point of a planar Hamiltonian system has eigenvalues that are either +-a or +-ai, a in R","This is a proposition in our textbook, but it is never explained as to why (we take it as given), and it doesn't seem very intuitive.  Is there an elegant way to show this that I'm missing?",['ordinary-differential-equations']
3023421,Showing that $\int_0^\pi\frac{\cos n\theta}{\cos\theta-\cos\theta_0}d\theta=\pi\frac{\sin n\theta_0}{\sin\theta_0}$,"I am reading Debnath & Bhatta ""Integral Transforms and Their Applications, 3rd"". They cited one example from Zayed ""Handbook of Function and Generalized Function Transformations"" and stated an integral (Eq.(9.5.45)), for a non-negative integer n, $$\int_0^\pi \frac{\cos(n \theta)}{\cos(\theta)-\cos(\theta_0)}d\theta=\pi \frac{\sin(n \theta_0)}{\sin(\theta_0)}$$ It turns out many books on Hilbert transform use this relation for Airfoil Design example, e.g., Prederick W.King, Chapter 11.14 ""Hilbert Transform-V1"". Interestingly, I remember the following one from Paul J. Nahin, Eq.(2.3.8) of ""Inside Interesting Integrals"" $$\int_0^\pi \frac{\cos(n \theta)-\cos(n \theta_0)}{\cos(\theta)-\cos(\theta_0)}d\theta=\pi \frac{\sin(n \theta_0)}{\sin(\theta_0)}.$$ You can find the proof in that book. So, if both integrals are correct, then we should have $$\int_0^\pi \frac{1}{\cos(\theta)-\cos(\theta_0)}d\theta=0,$$ which I cannot see why. Mathmatica gives an pure imaginary result here. How shall I interpret these and how can I prove the first integral?","['integration', 'trigonometry']"
3023438,Finding the derivative of $y= (\ln x)^2$,"In my math class, we are beginning to find derivatives of more complex functions. I’ve been trying questions from my textbook as practice. Here are two of them that I’m trying out: $y=(\ln x)^2$ . First, we take the power rule. This would make it $2(\ln x)$ . Then you multiply it by the derivative of the inside function right? $\ln x$ ’s derivative is $1/x$ . So, multiplied by $1/x$ . This gives us $\frac{2\ln x}x$ . This doesn’t seem correct so I’m a little confused. $y=\frac{3}{\sqrt{2x+1}}$ First, we get the denominator to the top. We get $y=3(2x+1)^{-1/2}$ . Then, we use the power rule. $y=3(x+1/2)$ . Then we multiply by the derivative again. Which is $2$ , I believe. This gives us $y=6(2x+1)$ . Again, this does not seem correct and I’m confused. I feel that my mistakes may be from a mix up of steps but I’m not exactly sure where in my process I went wrong.",['derivatives']
3023455,Proving the number of commuting pairs of elements in $G$ equals number of conjugacy classes in $G$ times $|G|$,"Let $G$ be a finite group. Let $N$ be the number of conjugacy classes of $G$ . Prove that the number of all pairs $\left(a,b\right)\in G \times G$ satisfying $ab = ba$ is $N \cdot \left|G\right|$ . The first part of this problem asks to describe $\operatorname{Hom}(\mathbb{Z}^2,G)$ as a subset of $G \times G$ which turned out that $\operatorname{Hom}(\mathbb{Z}^2,G)$ is the set of pairs of elements which commute in G. Now, I am trying to understand, and later show the fact that $\#\operatorname{Hom}(\mathbb{Z}^2,G) = \#G \cdot N$ where $N$ is the number of orbits of the group action of conjugation by $G$ on itself. My first guess was to try constructing a bijection between the two sides of the equality but I am having a hard time understanding $\#G \cdot N$ as a set. Is this a correct approach?","['group-actions', 'group-theory', 'abstract-algebra']"
3023492,$\sum_{n=1}^\infty \frac{(-1)^n \pi^{n+1}}{2^n (2n-1)!}$ with complex analysis?,"How do I go about evaluating this sum using complex analysis techniques? It is clear that it converges thanks to the ratio test, however I am unsure of how to arrive at the following answer. Thank you. The answer is $-\frac{\pi^{3/2} \sin\big(\sqrt{\frac{\pi}{2}}\big)}{\sqrt{2}}$ .","['complex-analysis', 'sequences-and-series']"
3023500,A pattern in determinants of Fibonacci numbers?,"Let $F_n$ denote the $n$ th Fibonacci number , adopting the convention $F_1=1$ , $F_2=1$ and so on. Consider the $n\times n$ matrix defined by $$\mathbf M_n:=\begin{bmatrix}F_1&F_2&\dots&F_n\\F_{n+1}&F_{n+2}&\dots&F_{2n}\\\vdots&\vdots&\ddots&\vdots\\F_{n^2-n+1}&F_{n^2-n+2}&\dots&F_{n^2}\end{bmatrix}.$$ I have the following conjecture: Conjecture. For all integers $n\geq3$ , $\det\mathbf M_n=0$ . I have used some Python code to test this conjecture for $n$ up to $9$ , but I cannot go further. Note that $\det\mathbf M_1=\det\mathbf M_2=1$ . Due to the elementary nature of this problem I have to assume that it has been discussed before, perhaps even on this site. But I couldn't find any reference on it, by Googling or searching here. Can someone shed light onto whether the conjecture is true, and a proof of it if so?","['fibonacci-numbers', 'determinant', 'linear-algebra']"
3023584,Prove that there exists number $k\in \mathbb{N}$ such that $ V = \operatorname{Ker}A^{k} \dot{+} \operatorname{Im}A^{k}$,"Problem: Let A be linear operator A $\in L(V)$ . Prove that there exists number $k\in \mathbb{N}$ such that $ V = \operatorname{Ker}A^{k} \dot{+} \operatorname{Im}A^{k}$ . Then prove that operator $\left.A\right|_{\operatorname{Ker}A^{k}}$ is nilpotent and operator $\left.A\right|_{\operatorname{Im}A^{k}}$ is regular. My attempt: We know that $A$ can be written as sum of two operators: $A = N + S $ where $N$ is nilpotent and $S$ diagonalizable operator. Then I construct $A^k = \sum_{j=0}^{k} {k\choose j}S^{k-j}N^{j}$ where $k = \operatorname{ind}(N)$ but this does not give anything good. I know that I need to show somehow that for every $v\in V$ : $v=a+b, a\in \operatorname{Ker}A^k, b\in \operatorname{Im}A^k$ but I do not know how. I have no idea how to proceed. Thanks for any help.","['jordan-normal-form', 'eigenvalues-eigenvectors', 'vector-spaces', 'linear-algebra', 'diagonalization']"
3023603,"Is there a name for this relation: for all $x$ there is $y$ such that $xRy$, and for all $x,y,z$, if $xRy$ and $xRz$, then $y=z$?","Suppose for all $x$ there is $y$ such that $xRy$ , and for all $x,y,z$ , if $xRy$ and $xRz$ , then $y=z$ . Does there exist such a binary relation $R$ on some set such that the above properties are satisfied by $R$ ?","['relations', 'discrete-mathematics']"
3023607,Is $S_4 \times C_2$ isomorphic to $(C_2 \times C_2 \times C_2) \rtimes S_3$,"Let $S_n$ denote the symmetric group on $n$ letters and $C_n$ denote the cyclic group of order $n$ . Consider $(C_2 \times C_2 \times C_2) \rtimes S_3$ where $S_3$ acts on $(g_1, g_2, g_3) \in C_2 \times C_2 \times C_2$ as follows: Given $\sigma \in S_3$ , $\sigma \cdot (g_1, g_2, g_3) = (g_{\sigma^{-1}(1)}, g_{\sigma^{-1}(2)}, g_{\sigma^{-1}(3)})$ . My question: Is $(C_2 \times C_2 \times C_2) \rtimes S_3 \cong S_4 \times C_2$ . Progress: Clearly they have the same order. I can show that they indeed have the same center. I have computed the number of elements of each order as follows: \begin{array}{c | c | c}
\text{ order } & \text{ # of elements }\\ 
1 & 1 \\
2 & 19 \\
3 & 8 \\
4 & 12 \\
6 & 8 
\end{array} Both groups of the same number of elements of each order. I've also determined that proving this isomorphism is equivalent to $(C_2 \times C_2 \times C_2) \rtimes S_3$ having a subgroup isomorphic to $S_4$ . The logic goes as follows: Clearly if the two groups are isomorphic, then $(C_2 \times C_2 \times C_2) \rtimes S_3$ has a subgroup isomorphic to $S_4$ . If $(C_2 \times C_2 \times C_2) \rtimes S_3$ has a subgroup isomorphic to $S_4$ , then this subgroup must intersect $Z(G)$ trivially, as $Z(S_4)$ is trivial. Further, $(C_2 \times C_2 \times C_2) \rtimes S_3 = S_4Z(G)$ . Then since the center is normal, $(C_2 \times C_2 \times C_2) \rtimes S_3 \cong S_4 \rtimes Z(G) \cong S_4 \rtimes C_2$ where $Z(G)$ acts by conjugation on $S_4$ . Since $Z(G)$ is the center, we just have $(C_2 \times C_2 \times C_2) \rtimes S_3 \cong S_4 \times C_2$ . I'm fairly stuck at this point. I want to maybe try an find some elements that satisfy the Coexeter relations sitting in $(C_2 \times C_2 \times C_2) \rtimes S_3$ .","['semidirect-product', 'group-theory', 'abstract-algebra', 'group-isomorphism']"
3023641,"Show that $f$ is differentiable on $(0,\infty)$ if and only if $f$ is differentiable at $1$","Suppose $f:(0,\infty) \to \mathbb{R}$ satisfies $f(x/y) = f(x) - f(y)$ for all $x,y>0$ and that $f(1) = 0$ . Question: Show that $f$ is differentiable on $(0,\infty)$ if and only if $f$ is differentiable at $1$ . My attempt on this problem: Let $a \in (0,\infty)$ . Then $f'(x) = \lim_{h\to 0} \frac{f(a+h) - f(a)}{h} = \lim_{h\to 0} \frac{f(\frac{a+h}{a})}{h} = \lim_{h\to 0} \frac{f(1 +\frac{h}{a})}{h}.$ All I know is that the top will go to $f(1) = 0$ and the bottom will also go to $0$ but I don't know how to show that this is differentiable on $(0,\infty)$ . Any help would be appreciated.","['limits', 'derivatives', 'real-analysis']"
3023651,Are the rings $\mathbb{R}^2$ and $\mathbb{R}^3$ isomorphic?,"Are the rings $\mathbb{R}^2$ and $\mathbb{R}^3$ isomorphic, where $\mathbb{R}^2=\mathbb{R}\times\mathbb{R}$ is the set of all pairs $(a,b)$ with $a,b \in \mathbb{R}$ , and $\mathbb{R}^3=\mathbb{R}\times\mathbb{R}\times\mathbb{R}$ is the set of all triples $(a,b,c)$ with $a,b,c \in \mathbb{R}$ , using component wise addition and multiplication?","['ring-isomorphism', 'abstract-algebra']"
3023661,"How to solve E($2X $| Y)? Where $f(x,y) = 4e^{-2y}$","Help, please! How to solve: $E(2X| Y) = ?$ $$f(x,y) = 4e^{-2y}\;,0 < x<y \mbox{ and }\; y>0.$$ After integrating $f(x,y)$ over domain of $y$ we get marginal density of $X$ : $$f_X(x) = 2e^{-2x} \;,\;x>0$$ Similarly, marginal density of $Y$ $$f_Y(y) = 4ye^{-2y}\;,y>0$$ Then I found out the distribution of $2X$ using Jacobian Theorem as $$f_U(u) = e^{-u}\;,u>0$$ How to calculate $E(2X| Y)$ ?","['statistics', 'probability-distributions', 'conditional-expectation', 'probability-theory', 'probability']"
3023669,Odd tangent bundle is the same as mapping stack from shifted affine line?,"Fix a field $k$ of characteristic $0$ . 
Let $X = \operatorname{Spec} A$ be an affine derived scheme of finite type, i.e., $A$ is a cdga such that $H^0(A)$ is a finitely generated over $k$ and $H^{i}(A)$ is finitely generated over $H^0(A)$ for $i<0$ . 
Assume $A$ is quasi-free so the cotangent complex $\mathbb{L}_A$ can be computed by the K\""{a}her differential $\Omega_A$ as in the classical case. 
The odd tangent bundle $\mathbb{T}X[-1]$ is defined to be the relative affine scheme $\operatorname{Spec}_{A} (\operatorname{Sym}^\bullet \Omega_A[1])$ .
Denote $\mathbb{A}[1]$ the derived stack defined by $\mathbb{A}[1](S) = Hom_{DGA_k}(k[\eta],S)$ where $\eta$ is of $\deg 1$ . I'm looking for a proof of the isomorphism: $$ Map(\mathbb{A}[1],X) \cong \mathbb{T}X[-1]$$ where $Map$ denotes the mapping stack. 
I know one can show that they have the same fiber over each $S$ -point $x : \operatorname{Spec}(S) \rightarrow X$ by using the universal property of the cotangent complex. But I don't understand how one can get a global map in the first place? Reference or explanations are both welcome.","['homological-algebra', 'derived-categories', 'geometry', 'algebraic-geometry', 'abstract-algebra']"
3023711,Limitations of Bromwich integral for inverting Laplace transform,"Suppose: $$f(t)=e^{at}+e^{bt};\quad a>b>0$$ Its Laplace transform is: $$\mathbf{L}[e^{at}+e^{bt}]=\frac{1}{s-a}+\frac{1}{s-b}$$ for $Re(s)>a$ where $Re$ stands for the real part; for $Re(s)<a$ Laplace transform of $e^{at}+e^{bt}$ doesn't exist because the transform integral isn't finite. Now suppose we invert $$F(s)=\frac{1}{s-a}+\frac{1}{s-b}$$ using Bromwich integral. $F(s)$ has simple poles at $a,b$ , with corresponding residues equal to $1$ . Therefore the inverse transform using Bromwich integral would be: $$\mathbf{L}^{-1}[F(s)]=\frac{1}{2\pi i}\int_Cds~e^{st}(\frac{1}{s-a}+\frac{1}{s-b})\\
=Res_{s=a}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]+Res_{s=b}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]\\
=e^{at}+e^{bt}$$ Even though it matches with the $f(t)$ we began with, why is this procedure correct? $F(s)$ is not defined when $Re(s)<a$ and the pole at $b$ lies in the region where $F(s)$ isn't defined. But using the residue at that pole nevertheless gives me $f(t)$ correctly. My question: Does a transformed function $F(s)$ whose poles lie outside its domain of validity (in the sense that the Laplace transform of the inverted function $f(t)$ has a limited domain of validity in the complex $s$ -plane) always give the ""correct answer"" $f(t)$ when Bromwich integral is evaluated by summing residues? Since I am not a mathematician I don't how to better phrase my question, but I hope that my example above makes my question clear. Thanks in advance for your help.","['complex-analysis', 'residue-calculus', 'laplace-transform', 'inverse-laplace']"
3023721,Finding the shortest path between two points on the surface of a cube,"A cube with vertices $(0,0,0),(0,0,1),(0,1,0),(0,1,1),(1,0,0),(1,0,1),(1,1,0),$ and $(1,1,1)$ has the point $P_{1}$ with vertices $(\frac{1}{2},0,\frac{1}{4})$ and the point $P_{2}$ with vertices $(0,\frac{3}{4},\frac{3}{4})$ . What is the length of the shortest path between $P_{1}$ and $P_{2}$ such that the path lies on the surface of the cube? Note: $\sqrt{(\frac{1}{2}-0)^2+(0-\frac{3}{4})^2+(\frac{1}{4}-\frac{3}{4})^2}=\frac{\sqrt{17}}{4}\approx1.03078$ is the shortest distance between the two points. However, it is not the correct answer since this path does not lie on the surface of the cube. For the same cube, can we generalize and give an expression to find the length of the shortest path between $P_{1}(x_{1},y_{1},z_{1})$ and $P_{2}(x_{2},y_{2},z_{2})$ , where, clearly, $0\leq x_{i},y_{i},z_{i}\leq1$ ?","['solid-geometry', 'geometry']"
3023726,"If $f : \Bbb{C} \to \Bbb{C}$ is entire, then $|f^{(n)}(0)| < n! n^n$ for some $n \in \Bbb{N}$",I'm trying to solve a problem that I can't seem to work out. $f$ is an entire function. Prove that $|f^{(n)}(0)|< n!n^n$ for at least 1 $n$ . I've been thinking to use the Cauchy estimates somehow but there's no reason for me to believe that $f$ is bounded from above. Any help is appreciated.,['complex-analysis']
3023756,"""Natural"" proof of $P\left(\frac{d}{dx}\right)\bigl(e^{xy}Q(x)\bigr)=Q\left(\frac{d}{dy}\right)\bigl(e^{xy}P(y)\bigr)$.","In the context of linear differential equations, I've stumbled upon the following identity for an arbitrary pair of polynomials $P$ and $Q$ with real or complex coefficients: $$
  P\left(\frac{d}{dx}\right)\bigl(e^{xy}Q(x)\bigr)
  =\sum_{n=0}^\infty\frac{P^{(n)}(y)e^{xy}Q^{(n)}(x)}{n!}
  = Q\left(\frac{d}{dy}\right)\bigl(e^{xy}P(y)\bigr).
$$ This can be more or less easily checked by using Taylor expansions of $P\bigl(\frac{d}{dx}\bigr)$ at $y$ and of $Q\bigl(\frac{d}{dy}\bigr)$ at $x$ : $$
  P\left(\frac{d}{dx}\right)
  =\sum_{n=0}^\infty\frac{P^{(n)}(y)}{n!}\left(\frac{d}{dx} - y\right)^n,
  \quad
  Q\left(\frac{d}{dy}\right)
  =\sum_{n=0}^\infty\frac{Q^{(n)}(x)}{n!}\left(\frac{d}{dy} - x\right)^n.
$$ Is there any easy way to ""see"" that $P\bigl(\frac{d}{dx}\bigr)\bigl(e^{xy}Q(x)) = Q\bigl(\frac{d}{dy}\bigr)\bigl(e^{xy}P(y)\bigr)$ without ""getting hands dirty""? Is this identity a part of some general theory?
It makes me think of Fourier analysis, but I do not know much about it.","['differential-operators', 'ordinary-differential-equations', 'alternative-proof', 'polynomials', 'exponential-function']"
3023781,"Compute $\mathbb{E} \left(\min(X, Y) | \max(X, Y) \right)$ for $(X,Y)$ i.i.d. uniform on $(0,1)$","Let $X, Y$ be independent random variables with uniform distribution on the interval $[0, 1]$ . My task is to find $$\mathbb{E} \big(\min(X, Y) | \max(X, Y) \big).$$ I think it can be done in the following way $$\mathbb{E} \big(\min(X, Y) | \max(X, Y) \big) = \mathbb{E}\big(\min(X, Y)|\sigma(\max(X,Y) \big) = \mathbb{E}\big(\min(X, Y)|\mathcal{F} \big).$$ Of course $\mathcal{F} = \{ \emptyset, [0,1] \}$ thus $\min(X, Y)$ is $\mathcal{F}$ -measurable. That leads us to $$\mathbb{E}\big(\min(X, Y)|\mathcal{F} \big) = \min(X, Y).$$ Is my reasoning correct? That won't stand for other distributions will it?","['conditional-expectation', 'probability-theory']"
3023818,Find $\sin x$ and $\cos x$ knowing $\tan x$,"I know $\tan x=-2\sqrt2$ . How to find $\sin x$ and $\cos x$ if $x\in[-\frac{\pi}{2},0]$ ? They probably would be $-\frac{2\sqrt2}{3}$ and $\frac{1}{3}$ respectively but I don't know how to prove it.",['trigonometry']
3023840,Find $\lim\limits_{n \to \infty} \sum\limits_{k=1}^{\infty}\frac{1}{k^{2}\sqrt[k]{n}}\sin^{2}\left(\frac{n \pi}{k}\right)$,Find $$\lim\limits_{n \to \infty} \sum\limits_{k=1}^{\infty}\frac{1}{k^{2}\sqrt[k]{n}}\sin^{2}\left(\frac{n \pi}{k}\right)$$ This is the first time that I am operating with $\lim_{n\to \infty}\lim_{k \to \infty}$ so I am unsure. My first idea would be to look at: $\frac{1}{k^{2}\sqrt[k]{n}}\sin^{2}(\frac{n \pi}{k})$ where $n \in \mathbb N$ is constant. $\frac{1}{k^{2}\sqrt[k]{n}}\sin^{2}(\frac{n \pi}{k})\leq \frac{1}{k^{2}\sqrt[k]{n}}\leq\frac{1}{k^{2}\sqrt{n}}$ and $\sum_{k=1}^{\infty}\frac{1}{k^{2}\sqrt{n}}=\frac{1}{\sqrt{n}}\sum_{k=1}^{\infty}\frac{1}{k^{2}}$ and we know $\sum_{k=1}^{\infty}\frac{1}{k^{2}} < \infty$ and taking $n \to \infty$ we get $\lim_{n\to \infty}\frac{1}{\sqrt{n}}\sum_{k=1}^{\infty}\frac{1}{k^{2}}=0=\lim_{n \to \infty} \sum_{k=1}^{\infty}\frac{1}{k^{2}\sqrt[k]{n}}\sin^{2}(\frac{n \pi}{k})$ I assume this is incorrect. Help/Corrections would be greatly appreciated.,"['limits', 'sequences-and-series', 'real-analysis']"
3023863,Solve $\sqrt{2}\sec x+\tan x=1$,"Solve $\sqrt{2}\sec x+\tan x=1$ I understand it can be very easily solved by expanding in terms of $\sin x$ and $\cos x$ , gives $x=2n\pi-\frac{\pi}{4}$ . But, what if I do the following: $$
\sqrt{2}\sec x+\tan x=1\\
\text{Differentiating}\implies\sqrt{2}\sec x\tan x+\sec^2 x=0\implies\sqrt{2}\tan x+\sec x=0
$$ Step 1 $$
\sec x=-\sqrt{2}\tan x=\frac{1-\tan x}{\sqrt{2}}\implies2\tan x=\tan x-1\implies\tan x=-1\\
\boxed{x=n\pi-\frac{\pi}{4}}
$$ Step 2 $$
\tan x=1-\sqrt{2}\sec x=\frac{-\sec x}{\sqrt{2}}\implies2\sec x-\sqrt{2}=\sec x\\
\implies\sec x=\sqrt{2}\implies\boxed{x=2n\pi\pm\frac{\pi}{4}}
$$ $$
x=n\pi-\frac{\pi}{4}\quad\&\quad x=2n\pi\pm\frac{\pi}{4}\\\implies \bigg[x=2n\pi-\frac{\pi}{4}\text{ or }x=2n\pi+\frac{3\pi}{4}\bigg]\quad\&\quad x=2n\pi\pm\frac{\pi}{4}\\
\implies \boxed{x=2n\pi-\frac{\pi}{4}}
$$ In my attempt why do I need Step 2 to get the complete solution ? Can someone give a proper explanation to my attempt ?",['trigonometry']
3023889,Why can't a vertex of a $d$-dimensional polytope be in fewer than $d$ edges?,"This is motivated by the definition of simple polytopes: if all vertices of a $d$ -dimensional convex polytope $P$ are in exactly $d$ edges (i.e. $1$ -dimensional faces of $P$ ), then $P$ is simple. I struggle to show that no vertex of $P$ can be in fewer than $d$ edges. Clearly, if this would be the case for some vertex $v$ , the (translated) cone generated by $v$ and its adjacent vertices would have a lower dimension than $d$ . So if I can only show that the cone contains $P$ , I would be done. That appears obvious but I've spent some time struggling with no luck. I feel I am missing something obvious. Edited to add: I use ""polytope"" to mean the convex hull of finitely many points in some Euclidean space. And, for the sake of completeness, when I speak of $P$ being $d$ -dimensional, I mean that its affine hull is $d$ -dimensional, not the ambient space.","['convex-geometry', 'polytopes', 'combinatorics', 'geometry']"
3023939,Express a parametrization of a curve $C$ as a function of $X$ and $Y$,"Express the curve $C$ with parametrization $\{(\cos 3t, \sin 2t) : t \in \mathbb{R} \}$ as a function of $X$ and $Y$ . Here's what I have (I don't know if this is helpful) I let $X= \cos 3t$ and $Y= \sin 2t$ . So I have $X= \cos^3 t -3\sin^2 t \cos t$ and $Y=2 \cos t \sin t$ . I don't know how to go on from here. Please help. Thanks!",['algebraic-geometry']
3023944,Variation of distributing $k$ balls into $n$ distinguishable boxes,"I am interested in understanding a variation problem of distributing balls into boxes. It seems to be not any of the individual case mentioned in twelvefold way classification. The problem is described as follows: In total there are $K$ balls, there are $I$ distinguishable groups by color, and in each color group the balls are indistinguishable with number to be $n_i$ where $i = 1, 2, \ldots, I$ . Meanwhile, we have $N$ distinguishable boxes where $N$ is always bigger than any $n_i$ . Therefore, how many ways are there to distribute these $K$ balls into $N$ boxes, when no box can contain more than one ball from same indistinguishable color group and no empty boxes ? Any suggestion will be appreciated.","['combinatorics', 'discrete-mathematics']"
3023967,"Finding an exact solution for $u(x)+\int_0^{2π}\cos(x+t)u(t)\,\mathrm dt=(π+1)\cos x$","I need to find an exact solution for $$u(x)+\int_0^{2π}\cos(x+t)u(t)\,\mathrm dt=(π+1)\cos x.$$ So far, I have tried to integrate by parts but it does not seem to be helpful because I got this: $$u(t)\sin(x+t)\bigg|_0^{2\pi} - \int_{0}^{2\pi}\sin(x+t)u'(t)\,\mathrm{d}t = (\pi + 1)\cos x - u(x).$$ I think it is a wrong way to solve this equation. Any suggestion for how to solve it would be appreciated.","['trigonometry', 'definite-integrals']"
