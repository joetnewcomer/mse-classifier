question_id,title,body,tags
3290534,Matching hat problem,"I have a question on the famous hat matching problem. Here's the setup:
N people arrive at a party all of whom are wearing hats. We collect all the hats and then redistribute them. What is the probability that at least one of the party members receives his/her own hat? My attempt: 
I noticed we are looking for the probability that at least one party member has his/her own hat back, which in my head triggers the use of the complement rule. Let A be the event that at least one person receives his/her own hat back. Then $A^c$ is the event that no one receives his/her own hat back. $$P(A) = 1 - P(A^c)$$ In my head, $P(A^c)$ should be the probability that the first person doesn't receive his hat times the probability that the second person doesn't receive his hat and so forth... $$P(A^c) = \frac{(N - 1)}{N}\frac{(N - 2)}{N-1}...$$ However continuing down this path, I noticed that for the last two people, the probability of the second to last person not getting his/her hat back is $\frac 12$ and the probability of the last person not getting his/her hat back is $\frac 02$ which doesn't make sense. Obviously my solution is wrong mathematically, but I can't figure out why intuitively my answer is incorrect which seems to be a common trend for combinatorics problems for me. Any advice?","['discrete-mathematics', 'combinatorics', 'probability']"
3290546,"Problem 12, Sec. 24 of Munkres' ""Topology,"" long line cannot be imbedded in reals","I'm doing this exercise in Munkres' ""Topology"" (~paraphrasing). I have two motivations for reading this book: 1, topology is really pretty, but the main one, 2, is that I am not yet an undergraduate; thus have never taken any sort of 'proofs-based' course and would like to learn how to write readable proofs. I would appreciate: A verification of my proof Any advice about how to make my proof more readable. Recall that $S_{\Omega}$ denotes the minimal uncountable well-ordered set. Let L denote the ordered set $S_{\Omega}\times[0,1)$ in the dictionary order, with its smallest element deleted. The set L is a classical example in topology called the long line . Theorem: The long line is path connected and locally homeomorphic to $\mathbb{R}$ , but it cannot be imbedded in $\mathbb{R}$ . The structure of the proof is given by Munkres. (a) Let X be an ordered set; let $a<b<c$ be points of X. Show that $[a,c)$ has the order type of $[0,1)$ iff both $[a,b)$ and $[b,c)$ have the order type of $[0,1)$ . Assume $[a,b)$ and $[b,c)$ have the order type of $[0,1)$ . Then there exist order-isomorphisms $f:[a,b)\rightarrow [0,\frac{1}{2})$ and $g:[b,c)\rightarrow [\frac{1}{2},1)$ , because $[0,1)$ has the same order type as $[0,1/2)$ . Define $h: [a,c) \rightarrow[0,1)$ as follows: $$h(x) = \begin{cases} 
      f(x) \text{ if } x\in [a,b) \\
      g(x) \text{ if } x\in [b,c)
   \end{cases}$$ $h$ is an order-isomorphism, as $p<q$ is true iff $h(p)<h(q)$ . Conversely, assume $[a,c)$ has the order type of $[0,1)$ . Then there exists an order-isomorphism $f:[a,c)\rightarrow [0,1)$ . Restricting the domain to $[a,b)$ gives a new order-isomorphism $g:[a,b)\rightarrow [0,d)$ , where $d\in (0,1)$ . $[0,d)$ is of the order type of $[0,1)$ ; multiplying by $1/d$ is an order isomorphism. Similarly, restricting the domain of $f$ to $[b,c)$ gives order-isomorphism $h:[b,c) \rightarrow [d,1)$ , where $d\in (0,1)$ . (b) Let X be an ordered set. Let $x_0 < x_1 < ...$ be an increasing sequence of points of X; suppose $b=\sup \{x_i\}$ . Show that $[x_0,b)$ has the order type of $[0,1)$ iff each interval $[x_i,x_i+1)$ has the order type of $[0,1)$ . Proving that $[x_0,b)$ having order type $[0,1)$ implies the same for the given intervals is simple, already having proved $(a)$ . Begin with $i=1$ : $[x_0,x_1), [x_1,b)$ is a partition of a set of the same form as we saw in $(a)$ ; thus each must have the same order type as $[0,1)$ . We proceed by induction, considering now the set $[x_1,b)$ and the sequence $x_1<x_2<...$ The proof is the same. edit: Conversely, assume each interval $[x_{i},x_{i+1})$ has order type $[0,1)$ . We seek to construct an order-isomorphism $f:[x_0,b)\rightarrow [0,1)$ by assigning each $[x_{i},x_{i+1})$ to a unique section of $[0,1)$ , as $[x_0,b)=\sqcup_{i\in \mathbb{Z}^{+}}[x_{i},x_{i+1})$ . Define $U_0=[0,\frac{1}{2})$ . Then inductively define $U_{i+1}=[\sup \{ U_{i}\},\sup \{ U_{i}\}+\frac{1}{2^{i+1}})$ , each of which clearly have order type $[0,1)$ and are pairwise-disjoint. Note that the upper bounds of $U_i$ converge to $1$ . Thus we can define order-isomorphisms $f_i:[x_i,x_{i+1})\rightarrow U_i$ , and thereby order-isomorphism $f:[x_0,b)\rightarrow [0,1)$ by the union of all $f_i$ . (c) Let $a_0$ denote the smallest element of $S_{\Omega}$ . For each element $a$ of $S_{\Omega}$ different from $a_0$ , show that the interval $[a_0 \times 0, a\times 0)$ of $L$ has the order type of $[0,1)$ . [ Hint : Proceed by transfinite induction. Either a has an immediate predecessor in $S_{\Omega}$ , or there is an increasing sequence $a_i$ in $S_{\Omega}$ with $a = \sup \{ a_i \}$ ] $[a_0,a)$ is countable by the definition of $S_{\Omega}$ . Following the hint: if $a$ has an immediate predecessor, $b$ , then $[b \times 0, a \times 0)$ has the order type of $[0,1)$ (all points in this set are of the form $b\times x$ , where $x\in [0,1)$ ). By backwards induction to $a_0$ any finite section of $S_{\Omega}$ , of which $a$ is the largest element, is order isomorphic to $[0,1)$ . If $a$ is not the largest element of a finite section of $S_{\Omega}$ , then there is an increasing sequence $a_i$ in $S_{\Omega}$ with $a = \sup \{ a_i \}$ , this sequence being exactly every element of $S_{\Omega}$ strictly less than $a$ , in order (which must be countable). Each $a_{i+1}$ in this sequence has an immediate predecessor, namely $a_1$ , so each $[a_{i}\times 0,a_{i+1}\times 0)$ must be order isomorphic to $[0,1)$ by the above argument. So, by $(b)$ , so must $[a_0\times 0,a\times 0)$ . edit : See JunderscoreH's answer for a neater version of these arguments. (d) Show that $L$ is path connected. Extending $(c)$ to include sets of the form $[a,b), a,b\in L$ is trivial - simply add/subtract sets from the ends - I will assume this.  This implies that $[a,b]$ has the same order type as $[0,1]$ . So between any two points $a,b\in L$ , there exists an order-isomorphism $f:[0,1]\rightarrow [a,b]$ ; which is necessarily a homeomorphism and thereby a continuous map. edit : See JunderscoreH's answer for a more general version of this argument. (e) Show that every point of $L$ has a neighborhood homeomorphic with an open interval in $\mathbb{R}$ . Let $x$ be our point, assume $x\neq a_0$ . Then there exist some points, $a,b\in L$ , such that $a<x<b$ . By $(d)$ , $L$ is path connected, so there exists some homeomorphism $f:[c,d]\rightarrow [a,b]$ such that $f(c)=a$ , $f(d)=(b)$ . Then by restricting the range of $f$ to $(c,d)$ we obtain a homeomorphism $f':(c,d)\rightarrow (a,b)$ . edit : Note that this is the purpose of 'deleting' the smallest element of $S_{\Omega} \times [0,1)$ to get $L$ . And finally... (f) Show that L cannot be imbedded in $\mathbb{R}$ , or indeed in $\mathbb{R}^n$ for any $n$ . [ Hint : any subspace of $\mathbb{R}^n$ has a countable basis for its topology] edits sprinkled throughout : Assume there existed an imbedding $f:L\rightarrow \mathbb{R}^n$ , thereby a homeomorphism $f':L\rightarrow Y$ , $Y\subset \mathbb{R}^n$ obtained by restricting the range of $f$ . $Y$ must have a countable basis because $\mathbb{R}^n$ is metrizable, so $L$ must also have a countable basis for its topology, being homeomorphic with $Y$ . Assume $L$ had a countable basis, call this basis the collection $X = \{U_{i}:i\in \mathbb{Z}^{+}\}$ . Every open set of $L$ must contain, entirely, at least one element of $X$ . Let $Y = \{ x_{\alpha}: x_{\alpha}=\alpha \times \frac{1}{2}, \alpha \in S_{\Omega} \}$ . $Y$ is uncountable, being indexed by $S_{\Omega}$ . Then by (e), there is some uncountable collection $Z = \{ V_{\alpha} \}$ such that each $V_{\alpha}$ is a neighborhood of $x_{\alpha}$ . Note that we can pick, more strongly, $Z$ such that it is pairwise-disjoint: for example, $V_{\alpha} = \{ \alpha \}\times (0,1)$ works. Then each contains some $U_{i}$ ; thus there exists some injective function $f:Z\rightarrow X$ assigning $V_{\alpha}$ to $U_{i}$ if the former contains the latter. $f$ is injective, because $Z$ is pairwise-disjoint. But $Z$ is indexed by $S_{\Omega}$ , $X$ by $\mathbb{Z}^{+}$ , implying the existence of an injection $g:S_{\Omega}\rightarrow \mathbb{Z}^{+}$ , contradicting the uncountability of $S_{\Omega}$ . $\therefore$","['general-topology', 'proof-verification', 'set-theory']"
3290577,Structure of integer pairs which commute under exponentiation,"In the natural numbers, exponentiation is defined as a non-commutative operation, but there are some pairs $\{a,b\}$ for which $a^b=b^a$ , like for example, $\{2,4\}$ . Is there any mathematical structure to which exactly pairs these are, like for example, do they form a sequence?","['elementary-number-theory', 'discrete-mathematics']"
3290604,A singularity at $0$ is removable if the complex function is square integrable.,"I am working on a problem stating as below: Consider a holomorphic function $f$ defined on the puncture disc $D(0,1)\setminus\{0\}$ . Show that $0$ is a removable singularity of $f$ if $f$ is square integrable. This question is similar to the post here: Singularities in the punctured unit disc and square integrability In fact, I've solved it following the idea in above post. Below is my proof: We can write $f(z)$ as Laurent Expansion around $z_{0}=0$ , such that $$f(z)=\sum_{n=-\infty}^{\infty}a_{n}z^{n}.$$ Then, we have $$f(re^{i\theta})=\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta},\ \overline{f(re^{i\theta})}=\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}.$$ Note that for the integral $$\int_{0}^{2\pi}e^{in\theta}e^{im\theta}d\theta,$$ if $n=-m$ , then the above integral is $2\pi$ , but if $n\neq -m$ , then the above integral is a complex integral of a holomorphic function along a circle and thus by Cauchy's Theorem, the above integral is $0$ . Now, with this in mind, we have \begin{align*}
\int_{0}^{2\pi}|f(re^{i\theta}|^{2}d\theta&=\int_{0}^{2\pi}\Big(\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta}\Big)\Big(\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}\Big)d\theta \\
&=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n}.\\
\end{align*} On the other hand, since $\|f\|_{L_{2}}<\infty$ , for any disc $D_{z_{0}}(R)$ centered at $z_{0}=0$ with radius $R$ , we have \begin{align*}
\infty>\int_{D}|f(z)|^{2}dz&=\int_{0}^{R}\int_{0}^{2\pi}|f(re^{i\theta})|^{2}4d\theta dr\\
&=2\pi\int_{0}^{R}\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n+1}dr\\
&=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}\int_{0}^{R}r^{2n+1}dr\\
\end{align*} Now, for all $2n+1\geq 0$ , $\int_{0}^{R}r^{2n+1}dr<\infty$ , but for all $2n+1<0$ , $\int_{0}^{R}r^{2n+1}dr=\infty$ . Thus, the only way to make the above inequality hold is that $2n+1\geq 0$ , which means that $n\geq 0$ since $n\in\mathbb{Z}$ . This implies that in the Laurent series, $a_{n}=0$ for all $n\leq -1$ . This implies that $z_{0}=0$ is a removable singularity. However, this question is the part (c) of a problem, and I am wondering if there is another way to prove it, by using part (a) and (b). Here is the part (a) and part (b): (a) Show that $0$ is a removable singularity if $|f(z)|\leq C|z|^{-\alpha}$ , with $\alpha<1$ . (b) Show that, for any holomorphic function $g$ on the disc of center $b$ , radius $\epsilon$ , we have $$|g(b)|\leq\dfrac{C}{\epsilon}\Big(\int_{D(b,\epsilon)}|g(x+iy)|^{2}dxdy\Big)^{1/2}.$$ I have proven those two parts and they both of a generalization in Stein Chapter 3 Exercise 13 and 20, respectively. However, I have no idea about how to apply those two to part (c). Perhaps they are really not connected to each other.",['complex-analysis']
3290665,Generating prime numbers of the form $\lfloor \sqrt{3} \cdot n \rfloor $,"How to prove the following claims ? Let $b_n=b_{n-1}+\operatorname{lcm}(\lfloor \sqrt{3} \cdot n \rfloor , b_{n-1})$ with $b_1=3$ and $n>1$ . Let $a_n=b_{n+1}/b_n-1$ . Every term of this sequence $a_i$ is either prime or $1$ . Every odd prime of the form $\left\lfloor \sqrt{3}\cdot n \right\rfloor$ greater than $3$ is a term of this sequence. At the first appearance of each prime of the form $\left\lfloor \sqrt{3}\cdot n \right\rfloor$ greater than $5$ , it is the next prime of the given form after the largest prime that has already appeared. A few first terms of this sequence can be found at A323388 . Implementation of this generator in PARI/GP can be found here .","['elementary-number-theory', 'algorithms', 'prime-numbers', 'sequences-and-series']"
3290710,On entire functions of finite order,"An entire function $f(z)$ has said to have finite order if there exist positive constants $c$ and $n$ such that $$ |f(z)|\le ce^{|z|^n} .$$ Prove that if such a function has only a finite number of zeros, then it must be of the form $$ f(z)=p(z)e^{q(z)} ,$$ where $p$ and $q$ are polynomials. My attempt: I have tried considering the function $g(z)\colon=f(z)/e^{z^n}$ but we can not use the condition since $|e^{z^n}|\le e^{|z|^n}$ but $$|g(z)|\ge\frac{|f(z)|}{e^{|z|^n}}\le c.$$ Then I am stuck... I really need some hints to move on. Thank you.","['complex-analysis', 'entire-functions']"
3290711,"Using gcd Bezout identity to solve linear Diophantine equations and congruences, and compute modular inverses and fractions","Isn't finding the inverse of $a$ , that is, $a'$ in $aa'\equiv1\pmod{m}$ equivalent to solving the diophantine equation $aa'-mb=1$ , where the unknowns are $a'$ and $b$ ? I have seem some answers on this site (where the extended Euclidean Algorithm is mentioned mainly) as well as looked up some books but there is no mention of this. Am I going wrong somewhere or is this a correct method of finding modular inverses? Also can't we find the Bézout's coefficients by solving the corresponding diophantine equation instead of using the extended Euclidean Algorithm?","['modular-arithmetic', 'elementary-number-theory', 'inverse', 'discrete-mathematics', 'linear-diophantine-equations']"
3290735,Solving trigonometric equation $\alpha = \arctan(o/q) - \arcsin(b/q)$,"I have the following equation: $$\alpha = \arctan\Big(\frac{a}{q}\Big) \ - \ \arcsin\Big(\frac{b}{q}\Big)$$ The values $\alpha$ , $a$ and $b$ are known, the only missing value is $q$ . So I need to solve the equation for $q$ but I have absolutely no idea how to do it or even where to start. I also tried putting this equation into Wolfram Alpha, but even this didn't give a usable output. I've tried something like this, but it doesn't seem that it would lead to the correct solution $$\sin(\alpha) = \sin\bigg(\arctan\Big(\frac{a}{q}\Big)\bigg) - \frac{b}{q}$$ EDIT: I've tried your hint @Kavi and I came up with the following: $$
\begin{align*}
\tan(\alpha) &= \tan \Bigg(\arctan\Big(\frac{a}{q} - \arcsin\Big(\frac{b}
{q}\Big)\Bigg)
\\
&= \frac{\tan\Big(\arctan\big(\frac{a}{q}\big) - \tan\big(\arcsin\big(\frac{b}{q}\big)\big)\Big)}{1+\tan\Big(\arctan\big(\frac{a}{q}\big)\Big) \ \tan\Big(\arcsin\big(\frac{b}{q}\big)\Big)}
\\
&= \frac{\frac{a}{q} - \frac{\frac{b}{q}}{\sqrt{1-\frac{b^2}{q^2}}}}{1+\frac{a}{q} \frac{\frac{b}{q}}{\sqrt{1-\frac{b^2}{q^2}}}}
\end{align*}
$$ Is this correct so far?",['trigonometry']
3290778,Resolving a differential equation manually,"It is my first week dealing with Differential Equations, and I am stuck at the following question: Find all the solutions of the following equation: $2y^2dx-(x+y)^2dy=0$ I have consulted an online calculator, which gave the solution $log\frac{y(x)}{x}+2arctan\frac{y}{x}=c_1-log(x)$ . However, I would like to be able to do this manually. Could anybody help out?",['ordinary-differential-equations']
3290798,A conjectured value for $\operatorname{Re} \operatorname{Li}_4 (1 + i)$,"In evaluating the integral given here it would seem that: $$\operatorname{Re} \operatorname{Li}_4 (1 + i) \stackrel{?}{=} -\frac{5}{16} \operatorname{Li}_4 \left (\frac{1}{2} \right ) + \frac{97}{9216} \pi^4 + \frac{\pi^2}{48} \ln^2 2 - \frac{5}{384} \ln^4 2$$ I arrived at a result involving the $\operatorname{Re} \operatorname{Li}_4 (1 + i)$ term for the value of the integral while the OP is convinced the integral in question has a simple, elementary answer. If both of us are right, then the conjecture holds. So my question is, is it possible to either (i) prove the conjecture true analytically or (ii) disprove the conjecture based on (very high precision) numerical evidence?","['integration', 'conjectures', 'polylogarithm', 'closed-form']"
3290810,On group varieties and numbers,"Suppose $\mathfrak{U}$ is a group variety. Let’s define $N_{\mathfrak{U}} \subset \mathbb{N}$ as a such set of numbers, that for any finite group $G$ , $|G| \in N_{\mathfrak{U}}$ implies $G \in \mathfrak{U}$ . Examples: If $\mathfrak{O}$ is the variety of all groups, then $N_{\mathfrak{O}} = \mathbb{N}$ . If $\mathfrak{B}_m$ is the variety of all groups of exponent $m$ , then $N_{\mathfrak{B}_m}$ is the set of all divisors of $m$ If $\mathfrak{N}_c$ is the variety of all groups of nilpotency class $c$ , then $N_{\mathfrak{N}_c}$ is the set of all numbers $n=p_1^{e_1}\cdots p_m^{e_m}$ with $p_i^k\not\equiv 1(\mod p_j)$ for $i,j\in\{1,\ldots,m\}$ and $1\leqslant k\leqslant e_i$ , and $e_i \leq c + 1$ for $i\in\{1,\ldots,m\}$ . If $\mathfrak{U}$ and $\mathfrak{V}$ are two varieties, then $N_{\mathfrak{U}\cap\mathfrak{V}} = N_{\mathfrak{U}} \cap N_{\mathfrak{V}}$ My question is: Does there exist some number-theoretic characterisation of all such subsets $N \subset \mathbb{N}$ , such that $N = N_{\mathfrak{U}}$ for some variety $\mathfrak{U}$ ? Any $N_{\mathfrak{U}}$ satisfies the property: If $a \in N_{\mathfrak{U}}$ and $b | a$ , then $b \in N_{\mathfrak{U}}$ Suppose $|G| = b$ and $G \notin \mathfrak{U}$ . Then $G \times C_{\frac{a}{b}} \notin \mathfrak{U}$ . If $\exists n \in \mathbb{N}$ , such that $\forall k \in \mathbb{N}$ $n^k \in N_{\mathfrak{U}}$ , then $\mathfrak{U} = \mathfrak{O}$ . By previous lemma, we can assume without loss of generality, that $n = p$ is prime. The only variety, that contains all $p$ -groups for a fixed prime $p$ is $\mathfrak{O}$ However, I am not sure, whether those two conditions are sufficient to characterise all such sets or not. This question was inspired by this MO question","['universal-algebra', 'number-theory', 'finite-groups', 'abstract-algebra', 'group-theory']"
3290825,Affine manifolds which are not euclidean manifolds.,"I want to find a differentiable $n$ -dimensional compact manifold $M$ which can be endowed with an affine structure but cannot be endowed with a euclidean structure. An affine (resp. euclidean) structure is a geometric structure with $X=\Bbb R^n$ and $G$ is the group of affine (resp. euclidean) transformations of $\Bbb R^n$ . I would like to find such a manifold for every possible dimension $n\geq 1$ . I know that in dimension $1$ and $2$ , such a manifold doesn't exist, since the only affine manifolds in that case are the circle, the torus and the Klein bottle and all of them are euclidean manifolds. In dimension $3$ , I think that $S^1\times S^2$ is an example. It is an affine manifold since it is diffeomorphic to the quotient $$\Bbb R^3-0/x\sim 2x.$$ However I don't really know how to prove that $S^1\times S^2$ has no euclidean structure (maybe we can use some theorem of Thurston about geometries of $3$ -manifolds but it seems to be a ""big tool"") In dimension $n\geq 4$ , maybe $S^1\times S^{n-1}\simeq \Bbb R^n-0/x\sim 2x$ could be an example, but again I don't know how to prove that this manifold doesn't admit a euclidean structure. Is there an elementary proof that these compact affine manifolds don't have euclidean structures? Are there some better examples? Thanks in advance.","['compact-manifolds', 'manifolds', 'homogeneous-spaces', 'differential-geometry']"
3290827,"""Square root"" of a derivative operator?","I have been studying derivatives as operators on a function. Specifically, how we may write, for a function $f(x)$ $$\frac{df}{dx}$$ as $$Df$$ where $D$ denotes $\frac{d}{dx}$ . I've seen how successive application of an operator is seen as multiplying the operators together to give rise to a new operator. For example $$\frac{d^2f}{dx^2}$$ can be written as $D^2f$ . What I have been pondering is this: Consider a certain operator $\Phi$ , which has the property that $$\Phi^2f=Df$$ i.e the $\Phi$ operator acts like a sort of ""square root"" of the derivative operator. This would imply that $$\Phi f = h$$ and $$\Phi h = g$$ where $g(x)$ and $h(x)$ are functions and that $$\frac{df}{dx}=g$$ My question is, has such an operator been studied before? Does it have a unique name? I do not necessarily belive $\Phi$ to be unique, perhaps many unique operators may fill the role of $\Phi$ . But can we determine if such an operator is unique or not?","['differential-operators', 'derivatives']"
3290839,"Show that if the integral of function with compact support on straight line is zero, then $f$ is zero almost everywhere","I want to prove that that given $f:R^2 \rightarrow R$ which is continuous with compact support s.t the integral of $f$ for every straight line $l$ is zero ( $\int f(l(t))\mathrm{d}t=0$ ) then $f$ is almost everywhere $0.$ Well I know how to proof it in case that $l = 1_{B(x,r)}$ is measurable and bounded with compact support (from other thread) , but that's not the case here.
Any idea? thanks!","['integration', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'lp-spaces']"
3290856,Are all proofs direct proofs or proof by contradiction?,"If I prove something can't be proven by direct proof or by contradiction does that mean it can't be proven? I don't know a lot of the jargon, so simpler explanations would be nice if possible.","['logic', 'discrete-mathematics']"
3290876,"Show that any compact metric space $X$ can be isometrically embedded into $C([0,1])$, the space of continuous functions over $[0,1]$","Show that any compact metric space $X$ can be isometrically embedded into $C([0,1])$ , the space of continuous functions over $[0,1]$ with sup-norm $(||f||_\infty = sup_x(|f(x)|)$ I have no idea yet how to approach this, any help would be appreciated.","['metric-spaces', 'general-topology', 'functional-analysis', 'real-analysis']"
3290888,If $|G|=36$ then $G$ has either a normal $2$-Sylow or a normal $3$-Sylow,"As many, I'm trying to classify all groups of order 36. I've seen many posts and in them, they claim this is true, but I can't find why. I know because of this , that $G$ is not simple. But I can't understand why the normal subgroup has to be a Sylow. I know that the number of $2$ -Sylows is either $1, 3$ or $9$ , and the number of $3$ -Sylows is either $1$ or $4$ .","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
3290891,Does there exist a bijection $f: \mathbb N \rightarrow \mathbb N$ such that if $f(a) = b$ then either $b = a^2$ or $a = b^2$,Does there exist a bijection $f: \mathbb N \rightarrow \mathbb N$ such that if $f(a) = b$ then either $b = a^2$ or $a = b^2$ ? Any help would be highly appreciated.,"['number-theory', 'functions', 'analysis']"
3290897,Multiplication subscript,"I'm teaching myself some differential geometry in the hope to understand gauge theory properly. In the definition of the the pullback bundle I came across a strange notation that I've never seen before. The pullback bundle was defined, with $f: M \to N$ , as \begin{equation}
f^\ast \mathcal{E} \equiv (f^\ast E, f^\ast \pi, M , F),
\end{equation} where the total space is given by \begin{equation}
f^\ast E  \equiv N \times_M E := \{ (x,z) \in N \times E | f(x) = \pi(z) \}.
\end{equation} What does the subscript on the $\times$ operator mean? Is it something to do with the operation occurring on the manifold $M$ ?","['notation', 'pullback', 'gauge-theory', 'differential-geometry']"
3290899,On the mean value theorem for random variables.,"Let $X,Y$ be two random variables that take values in $\mathbb{R}$ and let $f$ be a continuous and differentiable function on $\mathbb{R}$ . Then does there always exist a random variable $C$ such that $$f(X) - f(Y) = f'(C) (X-Y)$$ If $X,Y$ are discrete random variables it seems easy to find such a $C$ through the standard mean value theorem. In the continuous case are we guaranteed the existence since $C$ would be a (measurable ?) function of $X,Y$ ?","['probability-theory', 'probability', 'real-analysis']"
3290911,Determine all entire functions $f(z)$ such that $0$ is a removable singularity of $f(\frac{1}{z})$?,"So I am not sure about the answer,
but what I did was write $f(z)$ in the series form i.e $$f(z) = a_0 + ... + a_n z^n$$ then I consider $f(\frac{1}{z})$ - 
(and using the fact that in removable singularity principal part is zero) I get that all $a_i$ except $a_0$ must be $0$ !
So my answer is coming out to be $f(z) = c$ , where $c$ is some constant!?","['complex-analysis', 'singularity', 'complex-numbers']"
3290920,Norm of an operator and topological groups,"$G=(0,+\infty)$ the multiplicative topological group (with respect to the standard topology of the real line) equipped  with the positive Haar measure $\mu=\frac{1}{x} dx$ For $1 \leq p< \infty$ , we define the operator $T:L^p(G) \to L^p(G)$ to be $T(f)(x)=(f\star K)(x)=\int_0^{\infty}K(t)f(\frac{x}{t})\frac{dt}{t}$ , where $K \in L^1(G)$ is  nonnegative. We must compute the norm of $T$ . Clearly from Minkowski's inequality we have that $||T|| \leq ||K||_1$ How can i prove that $||T||=||K||_1$ ? Can you give me a hint? $\text{EDIT}$ Ι can present my attempt when $p=1$ Let $0<\epsilon<1$ and $N>1$ Let $g_{N,\epsilon}=1_{(\epsilon,N)}$ and $K_N=K1_{(0,N)}$ $$(g_{N,\epsilon}\star K_N)(x)=\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t}$$ $||g_{N,\epsilon}||_1=\log{N}-\log{\epsilon}$ Also $1_{(\frac{x}{N},\frac{x}{\epsilon})}(t)=1$ if and only if $1_{(t\epsilon,tN)}(x)=1$ From this and Tonneli's  theorem we have that $$||g_{N,\epsilon}\star K_N||_1=\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t}\frac{dx}{x}$$ $$=\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(t\epsilon,tN)}(x) \frac{dx}{x}\frac{dt}{t}=||K_N||_1(\log{N}-\log{\epsilon})$$ Using the definition of the norm of an operator and letting $N \to +\infty$ we have the desired inequality. Is this correct ? If it is, can someone help me adapting a similar idea to solve this for $p>1$ ? Thank you in advance.","['measure-theory', 'lebesgue-measure', 'topological-groups', 'real-analysis', 'functional-analysis']"
3290921,Nonabelian subgroup of p-groups of maximal class,"Recall that a group of order $p^{m}$ is of maximal class, if $cl(G)=m-1>1$ . Let $G$ be a nonabelian p-group  of maximal class wich have an
abelian subgroup of index $p$ . Note that: $G$ has $p+1$ maximal
subgroup. They are all of maximal class, exept one is not of maximal class
noted by $G_{1}$ and called the fundamental subgroup of $G$ ( $G_{1}=C_{G}(K_{2}(G)/K_{4}(G)) $ ). every nonabelian subgroup of $G$ is of maximal class. I found in exercice of the Book (p-groupe of maximal class $v1$ of Berkovich),
that the number of nonabelian subgroups of index $p^n$ in $G$ equals $p^n$ provided $|G|\geq p^{n+3}$ . why this is true?. Any help would be appreciated so much. Thank you all.","['combinations', 'finite-groups', 'abstract-algebra', 'combinatorics', 'group-theory']"
3290932,$D((A+B)^*)= D(A^*)$ if $B$ is $A$-bounded with $A$-bound $0$,"Let $A:D(A) \subseteq H \to H$ and $B:D(B) \subseteq H \to H$ be linear operators on a Hilbert space $H$ such that $A$ is a closed densely defined operator and $B$ is relatively bounded with respect to $A$ with relative bound $0$ . We have to show that $D((A+B)^*)= D(A^*)$ . Since $B$ is $A$ -bounded with $A$ -bound $0$ and $A$ is closed, we have that $A+B$ is a densely defined closed operator with $D(A+B)=D(A)$ . We know that $D(A^*) \subseteq D((A+B)^*)$ because $A^*+B^* \subseteq (A+B)^*$ , but how can we show that $D((A+B)^*) \subseteq D(A^*)$ . Can you give me any hint or a reference for the adjoint of a relatively bounded perturbation, please?","['operator-theory', 'functional-analysis', 'perturbation-theory']"
3290962,When is the Rayleigh quotient (spherically) convex?,"Suppose that $A$ is a real, $n \times n$ symmetric matrix. Define the map $F: \mathbf{R}^n \to \mathbf{R}$ by $x \mapsto x^T A x$ . Question: For which matrices $A$ is the map $f = F|_{S^{n-1}}$ convex? Let us give an interpretation for convexity in the sense of the question above. Definition: Let $M$ be a Riemannian manifold. A map $f: M \to \mathbf{R}$ is convex , provided that for every geodesic $\gamma: [0, 1] \to M$ , and every $t \in [0, 1]$ , $$ f(\gamma(t)) \leq t f(\gamma(0)) + (1-t) f(\gamma(1)).$$ Let us make three remarks now. First, this definition implies that $f \circ \gamma$ is a convex map for all geodesics $\gamma$ (check this via restricting $\gamma$ , yielding yet another geodesic). Secondly, when $M = \mathbf{R}^n$ with the usual flat metric, this definition reduces to $$
f(x_t) \leq t f(x_0) + (1-t) f(x_1), \qquad \mbox{for every $x_0, x_1 \in \mathbf{R}^n$},
$$ where above $x_t:= tx_0 + (1-t)x_1$ , $t\in [0, 1]$ . In other words, the usual definition of convexity for maps $\mathbf{R}^n \to \mathbf{R}$ . Finally, if $S^{n-1}$ is replaced by $\mathbf{R}^n$ above, then the answer to the question is simply for $A$ nonnegative definite.","['geodesic', 'riemannian-geometry', 'manifolds', 'convex-analysis', 'differential-geometry']"
3290988,Sum of indices of a vector field on a torus equals 0,"I'm having some troubles understanding the proof of a theorem the professor told us, can anybody help me fix some problems? So the theorem states: Statement: Let $M$ be a torus embedded in $R^3$ , let $X$ be a vector field on $M - \{p_1,...,p_m\}$ where $p_1,...,p_m \in M$ , then $$ \sum_{k=0}^m Ind_{p_k}(X) = 0$$ Definitions: Residue: let $\omega \in \Lambda ^1 (M)$ $$ Res_{p_j} \omega = \int_{\partial B_\epsilon} \omega - \int_{B_\epsilon} d\omega$$ where $\epsilon$ is small and $B_\epsilon$ is actually $\phi^{-1}(B_\epsilon(p_j))$ for $(U,\phi)$ chart on $M$ so that $p_j \in U$ . Complex structure $J$ : if $U \subset M$ , $J$ is a map $J:TU \rightarrow TU$ , such that $\forall q \in U$ it is $J_q: T_q U \rightarrow T_q U$ is linear and $J_q ^2 = -id$ . Consequence is that $\forall v \in T_q U$ the pair $(v, Jv$ is a base for $T_q U$ . Index: let $X,Y:M \rightarrow TM$ two vector fields on $M$ , let $p \in M$ and suppose $\forall m \in M-\{p\}$ is $X(m) \neq 0$ . Suppose also $Y \neq 0$ over all $M$ . Suppose $X = uY + vJY$ and let $f:= u + iv$ then $$Ind_p(X) = \frac{1}{2 \pi i}\int_{B_\epsilon} \frac{df}{f}$$ . Proof: Let $J$ be the complex structure on $M$ induced by the Gauss map.
Let $Y$ be a vector field such that $Y(p) \neq 0$ for $p \in M$ , then there are $u,v \in C^\infty(M-\{p_1,...,p_m\})$ so that $$X = uY + vJY$$ Let $f:= u + iv$ ,then let $fY:= Re(f)Y + Im(f)JY$ , so we have $X = fY$ with $f \in C^\infty(M - \{p_1,...,p_n\})$ . But then we have $$Ind_{p_j}(X) \overbrace{=}^{(1)} Res_{p_j}(\frac{df}{f})$$ and for the residue theorem we have $$0 \overbrace{=}^{(2)} \frac{1}{2\pi i}\int_{M}d (\frac{df}{f}) = \sum_{k=0}^m Res_{p_j}(\frac{df}{f}) = \sum_{k=1}^m Ind_{p_j}(X)$$ Problems: Why (1)? Why $\int_{B_\epsilon(p)} d(\frac{df}{f}) = 0$ ? As far as I know if $f \in C^\infty(M)$ then $\frac{df}{f}$ would be a closed form, so I would have won, but in this case I don't have smoothness everywhere. Why (2)? I feel like it has been used Stoke's theorem, but like above I would need $d(\frac{df}{f})$ to be defined on all of $M$ , plus it is Stoke's applied to $\frac{df}{f}$ on $M - \{p_1,...,p_n\}$ and it is a little weird. Edit: also, how is the hypotesis "" $M$ is a torus"" used? Isn't this theorem more general?","['proof-explanation', 'vector-fields', 'differential-geometry']"
3291004,Gradient of $\lVert \mathbf{H}^{\dagger}\mathbf{H} - \mathbf{B}\rVert_F^2$,"I'm trying to get the derivative of $$f(\mathbf{H})=\lVert \mathbf{H}^{\dagger}\mathbf{H} - \mathbf{B}\rVert^2_F$$ with respect to $\mathbf{H}$ , where $\mathbf{H}^\dagger$ denotes the pseudo-inverse of $\mathbf{H}$ . I know that $\nabla f = \mathbf{J}_{\mathbf{H}^{\dagger}\mathbf{H}}(\mathbf{H})^T \cdot \text{vect}\left(2(\mathbf{H}^{\dagger}\mathbf{H}-\mathbf{B}) \right)$ where $\mathbf{J}_{\mathbf{H}^{\dagger}\mathbf{H}}(\mathbf{H})$ is the Jacobian Matrix of $\mathbf{H}^{\dagger}\mathbf{H}$ . By the other hand, from ""Matrix Cook Book"", I know that $d(\mathbf{H}^\dagger\mathbf{H}) = d(\mathbf{H}^\dagger)\mathbf{H} + \mathbf{H}^\dagger d(\mathbf{H}) $ and from Derivative of pseudoinverse with respect to original matrix I know that $\eqalign{d\mathbf{H}^\dagger &= \mathbf{H}^\dagger (\mathbf{H}^\dagger)^T\,d\mathbf{H}^T\,(\mathbf{I}-\mathbf{H}\mathbf{H}^\dagger) + (\mathbf{I}-\mathbf{H}^\dagger \mathbf{H})\,d\mathbf{H}^T\,(\mathbf{H}^\dagger)^T\mathbf{H}^\dagger -\mathbf{H}^\dagger\,d\mathbf{H}\,\mathbf{H}^\dagger \cr
}$ But I don't know how to use the last two differential, I mean, how can I obtain $\mathbf{J}_{\mathbf{H}^{\dagger}\mathbf{H}}(\mathbf{H})$ or $\partial (\mathbf{H}^{\dagger}\mathbf{H})_{(i,j)}/\partial \mathbf{H}_{(k,l)}$ ?","['multivariable-calculus', 'matrix-calculus', 'derivatives', 'pseudoinverse']"
3291023,Kernel Density Estimation intuition,"I just read this article about the motivation for KDE. From what I understand, you are using Gaussian probability density distributions for each datapoint and then, depending on the selected kernel width, you get a KDE curve. I had a few questions: What is the kernel width defined as, for these Gaussian distributions? Is it just the variance? From what I understand, you add the probability densities corresponding to each point to get the full KDE. What does the resulting value curve physically mean? Is it some sort of cumulative probability density?","['data-analysis', 'statistics']"
3291141,Is the inverse image exact on locally free sheaves?,Let $f : X \to Y$ be a morphism of noetherian $k$ -schemes. Under what condition is the functor $f^* : \textbf{Coh}\ Y \to \textbf{Coh} \ X$ exact on locally free finite rank sheaves?,"['algebraic-geometry', 'abstract-algebra', 'coherent-sheaves']"
3291150,Function on the Cartesian product of group-orbits,"Let $\Gamma$ be a group generated by two matrices as follows: $\Gamma:= \bigg\langle \begin{bmatrix}1&0\\3&1\end{bmatrix},\begin{bmatrix}13&12\\12&13\end{bmatrix} \bigg\rangle$ For any $\begin{bmatrix}a&b\\c&d\end{bmatrix}\in \Gamma$ , and for any $x\in  \mathbb{R}$ , we define an action: $\begin{bmatrix}a&b\\c&d\end{bmatrix}(x):=\dfrac{ax+b}{cx+d}$ . Let $\Gamma(1)$ be the set of images of the action of $\Gamma$ on 1. Now we define a function $f$ on the Cartesian product $\Gamma(1)\times \Gamma(1)$ as follows: $f(x,y)= 0$ if $(x \cdot y)>0$ , and $f(x,y)= \sqrt{-x.y}$ otherwise. I knew that: $f(\Gamma(1)\times \Gamma(1)) \subset [0,1]$ . My question: Is $f(\Gamma(1)\times \Gamma(1))$ dense in $[0,1]$ ? I hope someone can help me or give me any hints for this question. Thank you so much for your help!","['cantor-set', 'hyperbolic-groups', 'geometric-measure-theory', 'geometric-group-theory', 'group-theory']"
3291226,Expected overlap of n circles of equal area randomly placed inside a circle of larger area,"Say I have an outer circle of area $\Omega$ . If I randomly position n circles of area $\omega$ ( $0 \le \omega \le \Omega$ ) completely inside the outer circle, then what is the expected overlap area of the inner circles? Assume uniform random positioning. As in, in order to select an inner circle center point, uniformly sample from the points in the outer circle, re-sampling if the point doesn't place the inner circle entirely inside the outer circle. I've calculated the answer fairly easily through simulation, but I'm looking for an analytic solution $E(overlap)=f(n,\frac{\omega}{\Omega})$ . from simulations I'm pretty sure that $\frac{\partial{f(n,\frac{\omega}{\Omega})}}{\partial{\frac{\omega}{\Omega}}}=g(n)$ , and from common sense I know that $f(n,1)=\Omega$ and $f(n,0)=0$ , but beyond that I'm stuck. EDIT: I'm also pretty sure that $f(\inf,\frac{\omega}{\Omega}) = (2\sqrt{\frac{\omega}{\Omega}}-1)^2$ EDIT EDIT: Here are a few examples for $N=3$ , $\frac{\omega}{\Omega}=.4$ . I randomly placed three circles and highlighted the overlap. ex1 ex2","['circles', 'geometry', 'probability']"
3291236,Problem: Associative law and the use of parentheses (Algebra),"this time I have a problem with parentheses, The problem in question I transcribe it in case you can't see it properly: How many ""("" and "")"" symbols do you need to specify completely the order of operations in the product 2*3*4*5*6 ... 99*100? This is how I attempted to solve it: There are actually only 98 numbers of a total of 99 to group into parentheses, because ideally, there should only be two multiplyings numbers: 2*3, 56*78 etc. Nevertheless, to visualize it better I decided to reduce the numbers to: 2*3*4*5*6*7*8*9*10. I organized them like this: [[(2*3)*(4*5)]*[(6*7)*(8*9)]]*10. After manually counting them, there is a total of 14 parentheses . So, per each 8-number group, we see there are 14 parentheses . Then, in 98 numbers, how many 8-number groups are there? 98/8 = 12,5 groups . So, 12,5 groups * 14 parentheses --> 12*14 = 168 parentheses in total. Thanks in advance. Edit: Thanks very much for your answers. Still, I don't seem to fathom how it's done. I'll go over it later.",['algebra-precalculus']
3291255,Euler (equidimensional) equation question,"Consider the equation $$x^2y''-8xy'+20y=0.$$ From an undergraduate ODE course, it is known that the two linearly are $y_1=x^5$ and $y_2=x^4$ . However, why don't we consider solutions, for example, like the following one: $$
y=\left\{
\begin{array}{c}
x^5\;\;{\mbox{if}}\;\;x\leq 0\\
0\;\;{\mbox{if}}\;\;x> 0.
\end{array}
\right.
$$ While the solution above is only differentiable 4 times, it is a perfectly good solution to the equation. I understand that the point $x=0$ is singular and thus the uniqueness theorem does not apply there. Also this is not unique to that equation or that solution. The same type of solutions could be obtained for other equations with singular points. The example above is convenient because it is a simple differential equation with explicit solutions. But my question is this: is there a reason why solutions such as the one above are not considered? Is it just because it is too complicated to be included in textbooks? Perhaps because they do not extend to solutions when the independent variable is allowed to be complex? Or perhaps people shy away to solutions that are not smooth (i.e. not in $C^\infty$ ) when smooth solutions exist?","['frobenius-method', 'ordinary-differential-equations', 'real-analysis', 'complex-analysis', 'singular-solution']"
3291263,Confusion about Notation of the Cardinality of a Set,"One textbook I'm reading says that the definition of two sets having the same cardinality is as follows: "" Two sets A and B have the same cardinality if there exists a bijection $f:A \rightarrow B$ . "" It also says that $|A|$ denotes the equivalence class of all sets having the same cardinality of A. So since equivalence classes in general are sets, then that would mean that $|A|$ is a set. However later on, the textbook wants us to write $|A| = n$ if $A$ has the same cardinality as the set { $1, 2, ..., n$ }. Doesn't that contradict the whole meaning of $|A|$ being an equivalence relation then, since $n$ is not a set but instead a natural number? Thanks in advance.","['equivalence-relations', 'real-analysis', 'notation', 'functions', 'elementary-set-theory']"
3291265,The interior of a manifold with a boundary is a manifold,"I am reading Lee's Introduction to Topological Manifolds and attempting to prove the following proposition: Proposition 2.58. If $M$ is an n-dimensional manifold with a boundary, then $\textrm{Int} M$ is an open subset of $M,$ which is itself an n-dimensional manifold without boundary. Where manifolds with a boundary are defined in terms of charts mapped to open sets in $\mathbb{H}^n = \mathbb{R}^{n-1} \times [0, \infty).$ I need to prove this without using the invariance of the boundary (i.e. that the manifold boundary and interior are disjoint. My attempt so far involved the construction of charts $(U_i, \varphi_i)$ that cover $M$ and the identification of points mapped to $\partial\mathbb{H}^n$ with $\partial M;$ however, I can't use $\textrm{Int} M = M \setminus \partial M$ without invoking the invariance of boundary. I would prefer hints or partial answers suggesting how I should proceed to full proofs.","['manifolds', 'differential-geometry']"
3291276,Prove that $A_n \cap B_n \rightarrow A \cap B$,"If $A_n \rightarrow A$ and $B_n \rightarrow B$ are sequences of sets then is it true that $A_n \cap B_n \rightarrow A \cap B$ ? How to prove or provide a counterexample? I had thought the following possible solution, but I am not convinced about it. I tried to prove the following statements: (i) $\liminf \left(A_n \cap B_n\right) = A \cap B$ ; (ii) $\limsup \left(A_n \cap B_n\right) = A \cap B$ ; thus, we can conclude that $\lim (A_n \cap B_n)$ , i.e., $A_n \cap B_n \rightarrow A \cap B$ To prove these statements I use the following arguments: (i) $\liminf \left(A_n \cap B_n\right) = \liminf A_n \cap \liminf B_n = A \cap B$ ; (ii) $\limsup \left(A_n \cap B_n\right) \subset \limsup A_n \cap \limsup B_n = A \cap B$ ; Therefore, $A_n \cap B_n \rightarrow A \cap B$ . Obs: A similar question was asked here , but the response is not complete. Can anybody help me? Thanks!","['limsup-and-liminf', 'real-analysis']"
3291283,Geometric interpretation of complex inner products,"Thanks for reading. In short, my question is this: What's the geometric interpretation of inner products when we allow our vectors to have complex components? Now, to give a little context... When I think of vectors that allow for complex components, I think of it as we're attaching a new orthogonal axis to each axis of the cartesian plane in which we put that corresponding complex component. So $2$ dimensional vectors that allow for complex components are really $4$ dimensional, since both their $x$ component and their $y$ component have an additional ""complex axis"" attached to them. I'm not sure if this is a good way to think about vectors with complex components, but it's the way I've been thinking about them thus far. The dot product between two real-valued vectors $\vec{a}\cdot\vec{b}$ can be interpreted as multiplying the magnitude of the projection of $\vec{a}$ onto $\vec{b}$ by the magnitude of $\vec{b}$ . If we allow $\vec{a}$ and $\vec{b}$ to be complex, then the above only seems to be true when the components of $\vec{a}$ and the components of $\vec{b}$ point in the same ""direction"" on their corresponding complex planes. An example: Let $\vec{a}=\begin{bmatrix}
i\\ 
1
\end{bmatrix}$ and $\vec{b}=\begin{bmatrix}
i\\ 
-3
\end{bmatrix}$ Then, $\vec{a}\cdot\vec{b}=(i)(-i)+(1)(-3)=(1)-3=-2$ Which can indeed be interpreted as the magnitude of the projection of $\vec{a}$ onto $\vec{b}$ multiplied by the magnitude of $\vec{b}$ . Another example: Let $\vec{a}=\begin{bmatrix}
2+i\\ 
1
\end{bmatrix}$ and $\vec{b}=\begin{bmatrix}
4+2i\\ 
-3
\end{bmatrix}$ Then, $\vec{a}\cdot\vec{b}=(2+i)(4-2i)+(1)(-3)=(8+2)-3=7$ Once again, this can be interpreted as the magnitude of the projection of $\vec{a}$ onto $\vec{b}$ multiplied by the magnitude of $\vec{b}$ . Note that $(2+i)$ and $(4+2i)$ , the two $x$ components of our vectors, point in the same direction on the $x$ complex plane. However, now let: $\vec{a}=\begin{bmatrix}
i\\ 
1
\end{bmatrix}$ ...and... $\vec{b}=\begin{bmatrix}
2+3i\\ 
1+i
\end{bmatrix}$ ...then $\vec{a}\cdot\vec{b}=4+i$ . We got a complex number as a result...how am I supposed to geometrically interpret that? Thanks!!!","['inner-products', 'complex-geometry', 'vector-spaces', 'geometry', 'complex-numbers']"
3291289,Trying to find a flaw in my proof that there are more rearrangements of an infinite series than real numbers,"So I had this thought that I was trying to prove as an exercise Let $\mathbb{R}$ be the set of real numbers and let $\mathbb{S}$ be the set of all possible rearrangements of the alternating harmonic series. Prove that $|\mathbb{R}| < |\mathbb{S}|$ I thought I had a proof of this, but I then posted it to Reddit /r/math only to be downvoted and told the proof was wrong. The only comment I received was to ""look at it from the other direction"", but that confused me. Here is my proof: Two sets have the same cardinality iff there exists a bijection between them. From the rearrangement theorem we can show that a the alternating harmonic series can converge to any real number via the following algorithm: Start with $1$ , if this is larger than the target number add the next negative term, otherwise add the next positive term. We create a mapping from the created rearrangement to the limit of this rearrangement. Notice that this maps to all real numbers. Now take one of the series that we had, and switch the first two terms. This is a new rearrangement since it does not begin with $1$ , so it should be mapped to a new real number. However all real numbers have already had a rearrangement mapped to them. As such we have two rearrangements pointing to a single real number, which means that our mapping is not a bijection. As such there must be more rearrangements than real numbers. Now I am not sure where my proof went wrong, so any help would be appreciated!","['real-numbers', 'infinity', 'sequences-and-series', 'elementary-set-theory', 'general-topology']"
3291339,Prove that $\operatorname{rank}A=\operatorname{rank}B$ if $A$ and $B$ are idempotent matrices and $I - (A+B)$ is invertible,"I've got a very interesting problem and wondering if my idea for the solution is right and complete. Please, take a look. Problem Given two matrices $A$ and $B$ such that $A^2=A$ and $B^2=B$ . Prove that $\operatorname{rank}A=\operatorname{rank}B$ if the matrix $I - (A+B)$ is invertible. Solution $A^2=A$ $B^2=B$ Let's subtract the second equation from the first one. $A^2 - B^2 = A - B$ $(A - B)(A+B) = A - B$ $(A - B)(A+B) - (A-B)= 0$ $(A - B)((A+B) - I))= 0$ $(A - B)(I - (A+B))= 0$ Since $(I - (A+B))$ is invertible, let's multiply the above equation by $(I - (A+B))^{-1}$ from the right. $(A - B)(I - (A+B))(I - (A+B))^{-1}= 0$ $A - B = 0$ Hence, $A = B$ which means that $rankA = rankB$ .","['matrices', 'proof-verification', 'linear-algebra']"
3291348,What is the Precise Definition of a “Complex Vector Space”? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I am studying linear algebra (as a second year) on my own using Axler’s, “Linear Algebra Done Right.” I have run into a definitional problem that I can’t get past. Specifically, Axler (and Wolfram, and others) define a “complex vector space” as a vector space in which the field is the complex numbers.  According to this definition, the complex numbers over the real numbers are not a complex vector space, but the complex numbers over the complex numbers are a complex vector space.  This despite the fact that the two vector spaces are identical (or at least isomorphic). I already see that many theorems concerning eigenvalues/vectors, adjoints, and spectral theory vary according to whether we are looking at complex or real vector spaces.  Thus, the definition of “complex vector space” is critical. I’m sure there is an easy explanation, but I don’t see it.  Thanks.","['linear-algebra', 'functional-analysis', 'linear-transformations']"
3291395,Compact subsets for a given topology,"I am currently studying topology in real analysis and have a problem that I'm stuck on and really don't understand completely. Question: Consider the topology $ \tau$ = { $\emptyset$ , $\mathbb{R}$ } $\cup$ { $ (a,\infty$ )} $_{a \in \mathbb{R}}$ in $\mathbb{R}$ i) What are the compact subsets of ( $\mathbb{R},\tau$ }? I understand that a set is compact if every open cover has a finite subcover. So would the compact subsets of ( $\mathbb{R},\tau$ } just be the $\emptyset $ ?  As any open interval in $\mathbb{R} $ { $(a,\infty)$ } does not have a finite subcover.  Not too sure if this is the correct... Am i wrong here? ii) What is an example of a function $f : \mathbb{R} \rightarrow \mathbb{R} $ that is continuous wrt the topology in both the domain and co-domain such that \begin{align}
 f(x) \leq -x      
\end{align} $\forall x \in \mathbb{R} $ or does such a function even exist? Couldn't I just take the $f(x) = -x-1$ , then $-x-1 \leq -x$ or is this completely wrong? I am new to topology and don't really have a strong understanding here, any help would be appreciated.","['continuity', 'general-topology', 'compactness', 'real-analysis']"
3291435,Does an exponential map defined on all of $T_p M$ for one $p$ imply completeness?,"Let $M$ be a connected Riemannian manifold. Hopf-Rinow states that if $\exp_p$ is defined on all of $T_p M$ for all $p \in M$ , then $M$ is geodesically complete. I'm wondering whether it is sufficient for $\exp_p$ to be defined on the whole tangent space for one $p \in M$ .
(If you go with the interpretation that geodesic incompleteness comes from ""cuts"" or ""holes"" in your manifold, then the exponential map should be able to ""see"" these.)","['geodesic', 'riemannian-geometry', 'differential-geometry']"
3291465,Proof Verification that Every Finite Set has a Unique Cardinality,"Is my proof correct for proving that every finite set has a unique cardinality? My part of the proof is as follows: ""Let $A = \{a_1, a_2, ..., a_n\}$ be an arbitrary set with $n$ elements, and let $f:A \rightarrow \{1, 2, ..., n\}$ be a function defined by $f(a_i)=i$ for all $1 \leq i \leq n$ . Then this function is bijective, so it follows that $|A| = n$ ."" However, I'm still having trouble showing that the cardinality of $A$ is unique. I tried supposing that $|A|=m$ for $m \neq n$ , in which I ended up having two possibilities: either $m \leq n$ or $m \geq n$ . Suppose that $m \leq n$ .  Then there exists a bijective function $f: A \rightarrow \{1, 2, ..., m\}$ . My question is, in order to show it cannot be bijective, how would you show it is not one-to-one? Now suppose that $m \geq n$ . Then again, there exists a bijective function $f: A \rightarrow \{1, 2, ..., m\}$ . In this case, my question is, how would you show that it is onto? I kind of understand it intuitively, but in a formal proof writing, how do you show that these two functions are not one-to-one and not onto? Thanks in advance.","['elementary-set-theory', 'cardinals', 'functions', 'proof-verification']"
3291467,Calculating $H'(x)$ given $H(x) = \int_{x^3 + 1}^{x^2 + 2x} e^{-t^2} dt$,"Given $\displaystyle H(x) = \int_{x^3 + 1}^{x^2 + 2x} e^{-t^2} dt$ , we want to find $H'(x)$ . First, we rewrite $H(x)$ as follows: $$\begin{align}
&= \int_0^{x^2 + 2x} e^{-t^2} dt + \int_{x^3 + 1}^0 e^{-t^2} dt \qquad &\text{Properties of integrals} \\
&= \int_0^{x^2 + 2x} e^{-t^2} dt - \int_{0}^{x^3 + 1} e^{-t^2} dt \qquad &\text{Definition of backwards integrals} \tag{1}
\end{align}
$$ Next, we'll define $\displaystyle F(x) = \int_0^x e^{-t^2} dt$ . We know its derivative is $F'(x) = e^{-x^2}$ , by the Fundamental Theorem of Calculus. Next, we'll define new functions for the two integrals in $(1)$ : $$\begin{align*}
H_1(x) &= \int_0^{x^2 + 2x} e^{-t^2} dt  &\qquad H_2(x) &= \displaystyle\int_{0}^{x^3 + 1} e^{-t^2} dt \\
&= F(x^2 + 2x)& &=F(x^3 + 1)
\end{align*}$$ We use the chain rule to find their derivatives: $$ H_1'(x) = e^{-(x^2 + 2x)^2} (2x + 2) \qquad H_2'(x) = e^{-(x^3 + 1)^2} (3x) $$ Therefore, $$H'(x) = e^{-(x^2 + 2x)^2} (2x + 2) - e^{-(x^3 + 1)^2} (3x)$$ Is my calculation correct?",['calculus']
3291490,Let $X \subseteq \Bbb Q^2$. Suppose each continuous function $f:X \to \Bbb R^2$ is bounded. Then $X$ is finite.,True or false: Let $X \subseteq \Bbb Q^2$ . Suppose each continuous function $f:X \to \Bbb R^2$ is bounded. Then $X$ is finite. Now it will be compact for sure just by using distance function. Now what can we do?,"['metric-spaces', 'continuity', 'calculus', 'functions', 'general-topology']"
3291499,Determine probability that one set is closer to a random point than another set?,"Suppose we have two sets that never intersect on a interval. How do we rigorously determine the probability that one set is closer to a random point than another set. (Closest being the set intersects with the random point). How do we make this rigorous? Can we create a new measure? By intuition I expect, for example 1) The irrationals would have a probability of 1 compared to the rationals. A random point will always be ""on"" the irrationals, while the rationals are infinitesimally close. 2) A set countable and Dense in R would have a probability of 1 compared to a set countable and non-dense in R. 3) A set countable and dense in R cannot have a probability compared to another set countable and dense in R. Both sets can be as close to the random point as possible.","['probability-theory', 'probability']"
3291505,$A$ and $A^2$ have same characteristic polynomial,"Is it possible to have a non-identity $2 \times 2$ diagonalizable, invertible, complex matrix $A$ s.t characteristics polynomials of $A$ and $A^2$ are the same? I am not getting any hint even how to create one. I can start with two different eigenvalues but for this, we won't have the same characteristic poly. I was also trying to play with $$
    \begin{pmatrix}
    0 & i  \\
    i & 0  \\
   \end{pmatrix}
$$ Does not help.","['characteristic-functions', 'matrices', 'linear-algebra', 'diagonalization', 'complex-numbers']"
3291518,"Sequence and series : $a_{n+1}=\frac{na_{n}+1}{a_{n}}$ , $a_0=1$","$a_{n}$ sequence defined as : $a_{n+1}=\dfrac{na_{n}+1}{a_{n}}$ , $a_0=1$ Then evaluate : $\lim_{n\to\infty}n(n-a_{n})$ My attempt : Call $\lim_{n\to\infty}a_{n}=L$ then I will use stolze Cesaro limit theorem $\lim_{n\to\infty}n(n-a_{n})=\lim_{n\to\infty}\frac{n+1-a_{n+1}-n+a_{n}}{\frac{1}{n+1}-\frac{1}{n}}$ From here how can I complete ?",['limits']
3291529,What did I do wrong with this logarithmic equation?,"$$e^{3x-2}e^{-x}=4e, \ \text{round to the nearest thousandths}$$ I keep getting $x\approx2.884$ but the answer is $x\approx2.193$ . What am I doing wrong? Here is my work: \begin{align*}
e^{3x-2}e^{-x}&=4e \\ e^{2x-2}&=4e \\ 2x-2\ln(e)&=\ln(4e) \\ 2x-2&=\ln(4e)\\ 2x&=\ln(4e)+2 \\ x&=\frac{\ln(4e)+2}{2} \\ x&\approx2.884
\end{align*} I've tried looking at $e^{-x}$ as $\frac{1}{e^x}$ or calculating the exact value of some of the simpler natural logs, but I keep getting the same answer. I feel like the mistake I'm making is so ridiculously obvious but I'm just not seeing it. UPDATE: I discovered my mistake was an error of notation. I did not properly include parentheses on the last step on my calculator, and therefore my calculator assumed I was computing $\frac{\ln(4)e+2}{2}$","['algebra-precalculus', 'logarithms']"
3291549,How to prove that $\exp(x)$ and $\log(x)$ are inverse?,"How does one prove that the exponential and logarithmic functions are inverse using the definitions: $$e^x= \sum_{i=0}^{\infty} \frac{x^i}{i!}$$ and $$\log(x)=\int_{1}^{x}\frac{1}{t}dt$$ My naive approach (sort of ignoring issues of convergence) is to just apply the definitions straightforwardly, so in one direction I get: \begin{align}\log(e^x)&=\int_{1}^{e^x}\frac{1}{t}dt\\
&=\int_{0}^{e^x-1}\frac{1}{1+t}dt\\
&=\int_0^{e^x-1}\sum_{j=0}^\infty (-1)^jt^jdt \\
&=\sum_{j=0}^\infty (-1)^j \int_0^{e^x-1} t^jdt\\
&=\sum_{j=0}^\infty \frac{(-1)^j}{j+1}(e^x-1)^{j+1}\\
&=\sum_{j=0}^\infty \frac{(-1)^j}{j+1} \sum_{k=0}^{j+1} \frac{n!}{k!(n-k)!}e^{x(n-k)}(-1)^k\\
&=\sum_{j=0}^\infty \sum_{k=0}^{j+1}  \frac{(-1)^{j+k}n!}{(j+1)k!(n-k)!} e^{x(n-k)}\\
&=\sum_{j=0}^\infty \sum_{k=0}^{j+1}  \frac{(-1)^{j+k}n!}{(j+1)k!(n-k)!} \sum_{\ell=0}^\infty \frac{(-1)^\ell}{\ell !}(n-k)^\ell x^\ell\\
&=\sum_{j=0}^\infty \sum_{k=0}^{j+1} \sum_{\ell=0}^\infty \frac{(-1)^{j+k+\ell}n!(n-k)^\ell x^\ell}{(j+1)k!\ell!(n-k)!} \end{align} and I cant see at all that this is equal to $x$ . My guess is I'm going about this all wrong.",['analysis']
3291556,Maximizing trace of mixed products of two real symmetric matrices,"Let $A$ , $B$ be two $N \times N$ real symmetric matrices whose entries i.i.d.r.v. from a mean 0, variance 1 distribution. Let $I, J$ be even positive integers, and let $i_k, j_k$ for $k = 1,\ldots,n$ be arbitrary finite sequences of positive integers such that $\sum i_k = I$ and $\sum j_k = J$ . Is it true that $\text{Tr} (A^I B^J) \geq \text{Tr}\left( A^{i_1} B^{j_1} \cdots A^{i_n} B^{j_n} \right) $ ? I have run extensive numerical experiments in Mathematica on large (10K x 10K) random real symmetric matrices, and have been unable to find a counterexample; I am wondering if this might be established in a theoretical sense.","['trace', 'linear-algebra', 'functional-analysis', 'symmetric-matrices', 'random-matrices']"
3291606,"If $H$ is a direct factor of $K$ and $K$ is a direct factor of $G$, then $H$ is normal in $G$.","A normal subgroup $H$ of a group $G$ is said to be a direct factor if there exists a subgroup $K$ of $G$ such that $G\cong H\times K$ . If $H$ is a direct factor of $K$ and $K$ is a direct factor of $G$ , then prove $H$ is normal in $G$ . By definition, we have $K\cong H\times K_1$ and $G\cong K\times K_2\cong H\times K_1\times K_2$ . It's easy to check that $H\times\{1\}\times\{1\}\trianglelefteq H\times K_1\times K_2$ and $H\cong H\times\{1\}\times\{1\}$ . But how to prove that $H\trianglelefteq G$ ?",['group-theory']
3291609,Is there a way to find the subfields of a Galois extension without knowing the subgroup structure of the corresponding Galois group?,"Say we have the polynomial $x^4-2$ , the splitting field of this over $\Bbb Q$ is $\Bbb Q(\alpha, i)$ , $\alpha=\sqrt[4]{2}$ , and its Galois group is isomorphic to $D_8$ . Now I know a way to find the lattice of subfields of $\Bbb Q(\alpha, i)$ in the Galois correspondence. If we know the subgroup structure of $D_8$ then we can find the corresponding subfield for each subgroup. Say for example $h$ is an automorphism which maps $\alpha \rightarrow i\alpha$ and $i \rightarrow i$ and another $g$ which maps $\alpha \rightarrow \alpha$ and $i \rightarrow -i$ . Then these generate the galois group and a subgroup is $<g,h^2>$ which has as its fixed field the intersection of the fixed fields of $g$ and $h^2$ . Thos in turn are found by noting that g has order 2, so its fixed field must be degree 8/2=4 over Q and it must contain $\Bbb Q(\alpha) $ therefore it must be $\Bbb Q(\alpha)$ , similarly $h^2$ has fixed field $\Bbb Q(i,\sqrt{2})$ , the intersection (fixed field of $g, h^2$ ) is then $\Bbb Q(\sqrt{2})$ This method works just fine but it requires that you fully know the subgroup structure of the Galois group in order to find the subfields of the galois extension. My questions are 1)Is there a way to find the subfields without knowing anything about the structure of the group 2) Can we then work in the other direction and construct the subgroups from the lattice of subfields. If I haven't quite asked the right question here but you know of some way of doing these problems without having to know subgroup structures , please feel free to answer anyway.","['field-theory', 'galois-theory', 'abstract-algebra', 'galois-extensions', 'group-theory']"
3291646,"Injective, Surjective Question on functions","Consider two functions $𝑓:𝑆→𝑇$ and $𝑔:𝑇→𝑈$ Decide whether each of the following statements is true or false, and prove each claim. a) If $𝑔∘𝑓$ is injective, then $𝑓$ is injective. b) If $𝑔∘𝑓$ is surjective, then $𝑓$ is surjective. c) If $𝑔∘𝑓$ is surjective and $𝑔$ is injective, then 𝑓 is surjective. For part a, injective means: $f(x)=f(y)→x=y$ and therefore is true. I am unsure about part b and c. How do I prove and solve the 3 parts?","['proof-writing', 'functions']"
3291675,Spectrum vs eigenvalues,"Easy question about linear operators - in physics (often) the terms spectrum and (set of) eigenvalues of an operator are used interchangeably. I'd like a simple compare and contrast to know the difference according to mathematicians.
Many thanks!","['spectral-theory', 'linear-algebra', 'functional-analysis']"
3291702,Find the $2022$th derivative $f^{(2022)}(0)$ of the function $f(x) = x^{2019}\cos(x)$.,"Find $f^{(2022)}(0)$ of the function $$f(x)=x^{2019} \cos x.$$ By Taylor series at the point $x =0$ , my answer was $0$ . But someone who gave this question to me said the answer is like the below picture. Who is correct? Did I something wrong?","['derivatives', 'real-analysis']"
3291724,Motivation of Adjoint Transformations,"Linear Algebra Done Right introduces the concept of Adjoint transfomations as Suppose $T \in \mathcal{L}(V, W)$ . The adjoint of T is the function $T^{*} : W \rightarrow V$ such that: $\langle T v, w\rangle=\left\langle v, T^{*} w\right\rangle$ for every $v \in V$ and $w \in W$ But this is introduced without any motivation. We work through some examples and find $T^*$ and I think it is interesting it exists. But other than being neat what is the motivation to introduce such a concept? What does the above definition say about $V,W$ or $T$ ? Why do we need this concept? I can't find a good motivation else where as well.","['matrices', 'abstract-algebra', 'linear-algebra']"
3291737,"Need to find limit, given function","Given that $f(x+y) = f(x) + f(y)$ for all real $x, y$ $f(1) = 1$ . To show that $$\lim_{x \to 0}\frac{f(x)}{x}=1$$ My intuition says that (1) gives us $f(x) = cx$ for some real $c$ ; but I am unable to argue why that should be. Edit: My actual question is to evaluate below : $$\lim_{x \to 0}\frac{2^{f(\tan x)} - 2^{f(\sin x)} }{x^2 f(\sin x) } $$ Which evaluates assuming $\frac{f(x)}{x}$ approaches $~1~$ as $~x~$ approaches to $~0~$ .","['limits', 'functions']"
3291771,Reduced Rings and Algebras,"Still trying to get my head around certain foundational concepts in algebraic geometry here, so pray bear with me... Is it true to say that if $R$ is a ring, then every (associative) algebra over $R$ does itself have the structure of a ring? Furthermore, provided the above holds water, is it true to say that if $R$ is reduced, then any $R$ -algebra, regarded as a ring, is also reduced? I look forward to your responses.","['algebraic-geometry', 'abstract-algebra', 'modules']"
3291785,On the functorial point of view in algebraic geometry.,"Here's a question I've been thinking about lately. I hope it's not too vague - I apologize in advance if this should be the case. Suppose you want to do algebraic geometry using the $\textit{functorial}$ point of view. I'm thinking of questions like $\textit{moduli problems}$ . It seems to me that the functorial point of view should be very natural in this context - given that a moduli space is a representing object of a moduli functor by the very definition. Now I always thought when doing moduli theory, one way to trying to study the moduli problem is by studying the $\textit{geometry}$ of the moduli space of the problem (assuming it exists etc...). One way to study the geometry of a moduli space $\mathcal M$ is by studying its $S$ -valued points $S \to \mathcal M$ . This feels like a very natural approach when it comes to moduli spaces, as one knows the set of morphisms $S \to \mathcal M$ . However, I feel like I'd be interested in morphisms having special properties, like (open/closed) embeddings, smooth morphisms etc. Given that the construction of moduli schemes seems to be rather complicated most of the time I'd rather not like to go through the explicit construction when it comes to checking that a given morphism $S \to \mathcal M$ satisfies a certain property. So ideally, I should be able to tell whether $S \to \mathcal M$ has certain properties $\textit{purely}$ from the $\textit{functorial point of view}$ . One example:
Often one is able to compute the tangent space of a scheme $X$ as the set of $k[\epsilon]$ -valued points of $X$ - something that one can understand rather explicitly for moduli spaces. I think this is actually used to deduce that the tangent space of Hilbert schemes is given as certain first-order deformations. And that through computing these deformations one can really prove interesting results on the moduli problem ""classified"" by Hilbert schemes (i.e. by knowing the dimension of the tangent space etc). So to summarize: Is there a (rather?) complete dictionary translating properties of morphisms of schemes into properties of their corresponding natural transformations? I know that there are translation for open/closed embeddings. I'm not so sure about proper/smooth/unramified and other important properties though. I'd be also interested in comments on whether my ""guess"" on how peoply try to work with moduli spaces is completely wrong or has a certain truth contained in it.","['algebraic-geometry', 'moduli-space', 'representable-functor']"
3291838,Integrate $\ln (x)$ without integration by parts,I know with integration by parts the answer is $x\ln(x) - x$ but I was wondering how to do this without integration by parts.,"['integration', 'indefinite-integrals', 'calculus']"
3291856,How many matrices satisfy this equality?,"How many matrices $A\in\mathcal{M}_{3\times 3} (\mathbb{N})$ satisfy this equality? $$\begin{pmatrix}
1 \ \ 2 \ \ 4
\end{pmatrix}\cdot A=\begin{pmatrix}
3 \ \ 2 \ \ 1
\end{pmatrix}$$ I tried with examples and I found just one but I want to know how to approach this exercise.The right answer is $3$","['matrices', 'linear-algebra']"
3291877,If the derivative of a function is square of it then it is constant [duplicate],"This question already has answers here : $f'(x) = [f(x)]^{2}$. Prove $f(x) = 0 $ (5 answers) Show that $f'(x) = f^2(x)$ and $f(0) = 0$ implies $f$ is the zero function [duplicate] (4 answers) Closed 4 years ago . Let $f:\mathbb{R}\to\mathbb{R}$ is differentiable and $f(0)=0$ . Also $\forall x\in \mathbb{R}$ we have $f'(x)=f^2(x)$ . Prove that $f(x)=0$ , for every $x$ . I tried to use MVT for both derivative and integral. But I got nowhere. I just found out that $f$ is increasing. for positive values $f$ is non negative. $\forall x>0$ , there exists some $c\in (0,x)$ s.t. $f(x)=xf^2(c).$ Intuitively, it seems one can start by a small interval around zero and show that $f=0$ and so on. Any comment!","['calculus', 'derivatives', 'analysis', 'real-analysis']"
3291892,"What is the Girsanov density as a functional on the canonical path space $C[0,1]$?","I'll formulate the question via an example. On $( C[0,1], \mathcal{C} )$ , where $C[0,1]$ is the set of continuous functions on $[0,1]$ and $\mathcal{C}$ the Borel $\sigma$ -algebra given by uniform topology, consider Wiener measure $\mathbb{P}$ . Denote by $t \mapsto W_t$ the Brownian paths given by $\mathbb{P}$ . Let $X$ be specified via $$
dX = \mu(X) dt + dW,
$$ where $\mu: \mathbb{R} \rightarrow \mathbb{R}$ is fixed. Girsanov's theorem says, under the measure $\mathbb{Q}$ given by (assume, e.g., Novikov's condition holds) $$
\frac{d \mathbb{Q} }{ d\mathbb{P} } = e^{ \int_0^1 \mu(X) dW - \frac{1}{2} \int_0^1 \mu(X)^2 dt },
$$ the $\mathbb{Q}$ -law of $W$ is the $\mathbb{P}$ -law of $X$ . Question The Radon-Nikodym derivative $\frac{d \mathbb{Q} }{ d\mathbb{P} }$ is specified via stochastic integral. But in principle, a Radon-Nikodym derivative is an object one must be able to define $\omega$ -by- $\omega$ , $\mathbb{P}$ -almost surely in this case. So what is $\frac{d \mathbb{Q} }{ d\mathbb{P} }$ as a functional on $C[0,1]$ (strictly speaking on the support of $\mathbb{P}$ )? Conjecture Ignore that Brownian paths do not have finite variation, etc.
Formally, it is the functional $\phi : C[0,1] \rightarrow \mathbb{R}$ given by $$
f(\cdot) \stackrel{\phi}{\mapsto} e^{\int_0^1 \mu(x(t)) df(t) - \frac{1}{2} \int_0^1 \mu^2(x(t)) dt }
$$ where $dx = \mu(x) dt + df$ , and $\int_0^1 \mu(x(t)) df(t)$ is a Riemann-Stieltjes integral with respect to $df$ . In other words, given $f \in C[0,1]$ , one acts as if $f$ is a realization of Brownian path and substitute formally into the expression for $\frac{d \mathbb{Q} }{ d\mathbb{P} }$ . Is this correct in some sense---e.g. discretize into step functions and taking weak limit in the Skorohod space $D[0,1]$ ...? Suggestive Example Suppose $dX = a \, dt + dW$ where $a$ is a real number.
Then, $\omega$ -by- $\omega$ , the Radon-Nikodym derivative $$
\frac{d \mathbb{Q} }{ d\mathbb{P} } = e^{ \int_0^1 a dW - \frac{1}{2} \int_0^1 a^2 dt },
$$ is given by the functional $$
f(\cdot) \stackrel{\phi}{\mapsto} e^{ a \int_0^1  df(t) - \frac{1}{2} \int_0^1 a^2 dt }
$$ where $\int_0^1  df(t)$ is interpreted as $f(1) - f(0)$ .","['stochastic-analysis', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
3291897,"Polar coordinates, Gauss Lemma","I don't understand the following statement from the Wikipedia page ""Normal coordinates"": I don't see how this follows from the Gauss Lemma. The statement of the Gauss Lemma I know is:
Let $(M,g)$ be a Riemannian manifold.
Forall $p \in M$ , $x \in D_p \subset T_pM$ , $v,w \in T_x(T_pM)$ it holds $g_{\exp_p(x)} (d \exp _p(v), d \exp _p(w))=g_p(v,w)$ Now $r : U \setminus \{p\} \rightarrow (0, \infty)$ correct? Then how is even $\dfrac{\partial}{\partial r}$ defined?","['semi-riemannian-geometry', 'riemannian-geometry', 'differential-geometry']"
3291919,Assumptions for a variation of Clairaut's theorem,"This question is similar to this one . I am unsure about the assumptions made in Theorem 6.20 of Apostol's Mathematical Analysis , first edition: Let $S \subseteq \mathbb{R}^2$ be open and $f\colon S \to \mathbb{R}$ . If $D_1 f$ , $D_2 f$ and $D_{2,1} f$ are continuous in a neighbourhood of the point $(x_0, y_0) \in S$ , then $D_{1,2} f(x_0, y_0)$ exists and is equal to $D_{2,1} f(x_0, y_0)$ . The theorem and proof is basically the same as the one featured in this blog post , also mentioned in the above question. By definition of partial derivatives, we need to prove that the limit $$ \lim_{h \to 0} \frac{ D_2 f(x_0 + h, y_0) - D_2 f(x_0, y_0) }{h}$$ exists and is equal to $D_{2,1} f(x_0, y_0)$ . For fixed $k$ , introducing the function $$ g_k(t) = f(x_0 + t, y_0 + k) - f(x_0 + t, y_0) $$ lets us write the numerator above as $$ D_2 f(x_0 + h, y_0) - D_2 f(x_0, y_0) = \lim_{k \to 0} \frac{g_k(h) - g_k(0)}{k}.$$ Since $D_1 f$ exists (we do not require continuity of $D_1 f$ ) in a neighbourhood around $x_0, y_0$ , $g_k$ is differentiable (with the obvious derivative) in a suitably small open interval around $0$ . If we require $h$ to be inside this interval, the mean value theorem yields a $\overline h$ between $0$ and $h$ such that $$ \frac{g_k(h) - g_k(0)}{k} = h \frac{g_k'(\overline h)}{k} = h \frac{D_1 f(x_0 + \overline h, y_0 + k) - D_1 f(x_0 + \overline h, y_0)}{k}.$$ For convenience, define the function (Apostol skips the details of the following steps) $$ \phi(s) = D_1 f(x_0 + \overline h, y_0 + s) - D_1 f(x_0 + \overline h, y_0),$$ analogous to the above function $g_k$ . By the existence (again, not continuity) of $D_{2,1}$ in a neighbourhood around $(x_0, y_0)$ , $\phi$ is differentiable in an open interval around $y_0$ . For fixed $k$ , the mean value theorem then gives us a $\overline y$ between $y_0$ and $y_0 + k$ such that $$ \frac{D_1 f(x_0 + \overline h, y_0 + k) - D_1 f(x_0 + \overline h, y_0)}{k} = D_{2,1} f(x_0 + \overline h, \overline y). $$ In total we get $$ \frac{ D_2 f(x_0 + h, y_0) - D_2 f(x_0, y_0) }{h} = \lim_{k \to 0} D_{2,1}f(x_0 + \overline h, \overline y),$$ so the original limit is equal to $$\lim_{h \to 0} \lim_{k \to 0} D_{2,1}f(x_0 + \overline h, \overline y).$$ So far we have not, as far as I can see, used continuity at all. We cannot evaluate the limit directly, so introduce the function $$ F(h) = \lim_{k \to 0} D_{2,1}f(x_0 + \overline h, \overline y), $$ i.e. just the inner limit as a function of $h$ . Now by continuity of $D_{2,1}f$ at $(x_0, y_0)$ (that is, not in a neighbourhood around the point, only at the point itself), given $\epsilon > 0$ there is some $\delta > 0$ such that for $(x,y) \in N((x_0, y_0); \delta)$ we have $$ \lVert D_{2,1} f(x,y) - D_{2,1}f(x_0, y_0) \rVert < \frac{\epsilon}{2}.$$ Choosing $h$ and $k$ such that $\lvert h \rvert, \lvert k \rvert < \delta/2$ , the point $(x_0 + \overline h, \overline y)$ lies in this $\delta$ -neighbourhood, so that $$ 0 \leq \lVert D_{2,1} f(x_0 + \overline h, \overline y) - D_{2,1}f(x_0, y_0) \rVert < \frac{\epsilon}{2}.$$ Now taking the inner limit $k \to 0$ we get, by continuity of the norm, $$ 0 \leq \lVert F(h) - D_{2,1}f(x_0, y_0) \rVert \leq \frac{\epsilon}{2} < \epsilon.$$ As far as I can tell, this does not require continuity of any of the derivatives, but only relies on the definition of the function $F$ . This proves the theorem. Only I cannot see how we use any type of continuity of $D_1 f$ and $D_2 f$ , and it seems like only continuity of $D_{2,1} f$ at the point itself is needed. Apostol does not include a proof of this theorem in the second edition of Mathematical Analysis , but he does mention it (with the same assumptions) on page 360.","['multivariable-calculus', 'calculus', 'real-analysis']"
3291925,Find values of $x$ so that the matrix is invertible,"Find values of $x$ so that the matrix is invertible $$A=\begin{pmatrix}
x &  0 & x \\
x &  2 &  1 \\
2x &  0 &   2x \\
\end{pmatrix}$$ I know that a matrix is invertible if determinant is not $0$ , but I don't know how to find the $x$ values. I feel is a tricky question and this matrix will not be invertible no matter which value $x$ takes, but I don't know how to prove that either.","['matrices', 'linear-algebra', 'inverse']"
3291949,Stars and Bars in terms of dice - Can't spot my error,"I tried to solve the question How many ways are there to pick $k$ times from a set of $n$ objects with replacement? in the following way. First I imagined $k$ fair dice, each with $n$ sides. If the order does not matter the number of different outcomes from the experiment is $\frac{n^k}{k!}$ . This is wrong and I fail to recognize error in my thinking. If I instead think of the problem in terms of putting $k$ balls into $n$ urns and then use the famous method of representing the balls as stars and bars as urns I arrive at the correct answer $\binom{n+k-1}{k}$ . However, to me these formulations seems to be analogous because the number of times the dice show the same side in a given experiment could represent the number of balls in a specific urn. Where is the error?",['combinatorics']
3291973,"Is $f: (0,\infty ) \to \mathbb{R}$ , $f(x):=\ln(x)+e^x$ injective?","i showed that $f$ is strictly monotonically increasing: $\ln(x+1)+e^{x+1} > \ln (x)+e^x$ Both $\ln$ and $\exp$ are monotonically increasing function, this inequaltiy is obviously true, or do I have to prove that fact?","['logarithms', 'monotone-functions', 'real-analysis', 'functions', 'exponential-function']"
3291975,Rearranging the formula,"Transpose this formula to make $y$ the subject. $$x=\sqrt{x^2y^2+1-y}$$ My try: $$x^2=x^2y^2+1-y$$ $$x^2-x^2y^2=1-y$$ $$x^2(1-y^2)=1-y$$ Here I got 2 $y$ terms, but I am not sure what to do next.",['algebra-precalculus']
3291985,"Interpreting the word ""randomly""","Suppose that 3 indistinguishable balls are placed at random into 3 distinguishable
cells. What is the probability that exactly one cell remains empty? The book's answer is $$\frac{3(3-1)}{3+3-1\choose{3}}=\frac{3}{5}$$ . In words, the number of ways of distributing the 3 balls so that there is exactly one cell that is empty divided by the number of ways to distributing the 3 balls. My question is, that if I interpret ""randomly"" to mean the probability that any ball falls into a cell is $ \frac{1}{3} $ . I think the answer comes out different. The probability that the first cell is empty is $\frac{6}{27}$ . So the probability that one of them is empty is $$3 *\frac{6}{27}=\frac{2}{3}$$ . Therefore is it right to say that there are two interpretations to this question and based on the wording we should infer the first interpretation?",['probability']
3292029,Concyclic incenters of triangles concerning Apollonius circle,"Problem: $ABCD$ is a tangential quadrilateral and $P$ is a point such that $$\dfrac{PB}{PD}=\dfrac{AB}{AD}=\dfrac{CB}{CD}.$$ Let $I_1$ , $I_2$ , $I_3$ , $I_4$ be the incenters of $\triangle PAB$ , $\triangle PBC$ , $\triangle PCD$ , $\triangle PDA$ , respectively. Proof that $I_1$ , $I_2$ , $I_3$ and $I_4$ are concyclic. I have read this problem Prove that $ I_1, I_2, I_3, I_4 $ are concyclic , but it is not actually similar to my problem. I suspect the problem has something to do with Apollonius circles (i.e., circle $PAC$ ), but I don't know how to use this information in any way. I cannot understand how Apollonius circles are connected to incenters. Edit: My analysis is that the problem clearly implies two cases: either $AC$ is the perpendicular bisector of $BD$ , or $AB = CB$ and $AD = CD$ (a kite). The first case is trivial, since $I_1$ , $I_2$ , $I_3$ , $I_4$ here forms a rectangular. The real difficult part of this problem is the second case. Based on observations, I have made out the following results, but I cannot prove them. They may provide some clues for the original problem. I would appreciate it if anyone could help with these conjectures too: Assume the outer and inner bisectors of $\angle BAD$ intersect $BD$ at point $M$ and $N$ respectively (so $M$ and $N$ lie on the Apollonius circle), then: $M$ , $I_1$ and $I_4$ are colinear, likewise are $M$ , $I_2$ and $I_3$ ; $N$ , $P$ , $I_1$ and $I_2$ are concyclic, likewise are $N$ , $P$ , $I_3$ and $I_4$ .","['euclidean-geometry', 'circles', 'geometry', 'triangles', 'plane-geometry']"
3292032,Linear trasformation and Lebesgue measure,"Let $T\colon\mathbb{R}\to\mathbb{R}$ a linear trasformation of $\mathbb{R}$ defined as $Tx:=ax+b$ , where $a,b\in\mathbb{R}$ , $a\ne 0.$ We denote with $\mathcal{L}(\mathbb{R})$ the Lebesgue $\sigma-$ algebra and we denote with $\lambda^*$ the Lebesgue outer measure. Let $E\in2^{\mathbb{R}}$ , we must prove that Proposition. $T(E)\in\mathbb{\mathcal{L}(\mathbb{R})}$ $\iff$ $E\in\mathcal{L}(\mathbb{R})$ I just proved that $$\lambda^*(T(E))=|a|\lambda^*(E)\tag1.$$ Regarding the implication $(\Leftarrow)$ there are not problems. $(\Rightarrow)$ Proof. Suppose that $T(E)\in\mathcal{L}(\mathbb{R})$ , then $\lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E))$ for all $Z\in 2^{\mathbb{R}}$ . Therefore we have that $$\lambda^*(T(Z))=\lambda^*(T(Z)\cap T(E))+\lambda^*(T(Z)\cap \complement T(E)),$$ so $$\lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)).$$ Multiplying the members for $|a|^{-1}$ we have $$|a|^{-1}\lambda^*(T(Z))=|a|^{-1}\lambda^*(T(Z\cap E))+|a|^{-1}\lambda^*(T(Z\cap\complement E)),$$ for $(1)$ we obtain $$\lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E),$$ then $E\in\mathcal{L}(\mathbb{R}).$ Proof 2. Observe that $$\lambda^*(E)=\lambda^*(T[T^{-1}(E)])=|a|\lambda^*(T^{-1}(E)),$$ then $$\lambda^*(T^{-1}(E))=\frac{1}{|a|}\lambda^*(E)\tag2.$$ Let $T(E)\in\mathcal{L}(\mathbb{R})$ then $\lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E))$ , therefore $$\lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)).$$ Now, $$\frac{1}{|a|}\lambda^*(T(Z))=\frac{1}{|a|}\lambda^*(T(Z\cap E))+\frac{1}{|a|}\lambda^*(T(Z\cap\complement E)),$$ then for $(2)$ we have $$\lambda^*(T^{-1}[T(Z)])=\lambda^*(T^{-1}[T(Z\cap E)])+\lambda^*(T^{-1}[T(Z\cap\complement E)])$$ and so $$\lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E),$$ then $E\in\mathcal{L}(\mathbb{R}).$ Thanks! Question Are the proofs correct?","['measure-theory', 'proof-verification', 'lebesgue-measure', 'proof-writing']"
3292034,Normalizing a quasi-rotation matrix,"I have a rotation matrix $R$ generated after a lot of multiplications, inverting and so on. However, the outcome is not completely normalized, e.g., $R R^T \neq I$ , but close. How can I fully normalize it?","['matrices', 'rotations']"
3292038,"If $f$ is continuous and $f'(x)\ge 0$, outside of a countable set, then $f$ is increasing","PROBLEM. Let $f:[a,b]\to\mathbb R$ be a continuous function, such that $f'(x)\ge 0$ , for all $x\in [a,b]\setminus A$ , where $A\subset [a,b]$ is a countable set. Show that $f$ is increasing. Attention. In this problem, we DO NOT assume that $f$ is differentiable in the whole $[a,b]$ . Notes. (1) If we assume that $f$ is differentiable in the whole interval, then we can easily show that $f'(x)\ge 0$ , everywhere. For otherwise, if $f'(x_0)=c<0$ , for some $x_0\in [a,b]$ , then by virtue of Darboux's Theorem , $(c,0)\subset f'([a,b])$ , and hence, $f'(x)<0$ , for uncountably many $x$ 's. (2) The conclusion of the problem does not hold if we replace the assumption $A$ is countable with $A$ is a set of measure zero . Take for example the Devil's staircase , with a negative sign in front. (3) If the hypothesis $f'(x)\ge 0$ , is replaced by $f'(x)=0$ , then the conclusion becomes f is constant .","['monotone-functions', 'real-analysis', 'continuity', 'calculus', 'derivatives']"
3292096,Why must probability fields be closed under countable unions?,"Assume a probability triplet $(\Omega, \mathcal{F}, \mathbb{P})$ . My current understanding of $\mathcal{F}$ is that it must define events i.e. the subsets of $\Omega$ where probability is defined. I also understand that $\mathcal{F}$ must be closed under countable complements and unions. Is it correct to say that the intuitive reasoning is as follows: We need closure under complements by Kolmogorov's axioms. If you know $\mathbb{P}(A)$ then you know $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$ . What I don't understand is why we need closure under countable unions. Even, if we know $\mathbb{P}(A), \mathbb{P}(B)$ , we cannot arrive at $\mathbb{P}(A \cup B)$ without knowing $\mathbb{P}(A \cap B)$ . I have read this answer but the author of the answer neglects to answer why we need countable unions when the sets $A$ and $B$ are disjoint: The last axiom is closed under countable unions. Let me give you another stupid example. Consider the roll of a die, or 𝑋={1,2,3,4,5,6}. What if I were to tell you the 𝜎 algebra for this is {∅,𝑋,{1},{2}}. That is, I know the probability of rolling a 1 or rolling a 2, but I don't know the probability of rolling a 1 or a 2. Again, you would justifiably call me an idiot (I hope the reason is clear). What happens when the sets are not disjoint, and what happens with uncountable unions is a little messier but I hope you can try to think of some examples. Help?","['measure-theory', 'probability-theory']"
3292098,Relation between tensor product and wedge product,"Let $V$ be a vector space, $\mathcal B=\{w_1,\dots,w_k\}$ a orthonormal basis for $V$ , and let $T=w_1^\star\otimes\dots\otimes w_k^\star\in\mathcal L^k(V)$ . I don't understand why is this equivalence true: $$w_1^\star\wedge\dots\wedge w_k^\star(w_1,\dots,w_k)=\frac 1 {k!}\sum_{\sigma\in S^k}(w_1^\star\otimes\dots\otimes w_k^\star)^\sigma(w_1,\dots,w_k)$$ Actually, I was sure that the equivalence was $$w_1^\star\wedge\dots\wedge w_k^\star(w_1,\dots,w_k)=\sum_{\sigma\in S^k}(w_1^\star\otimes\dots\otimes w_k^\star)^\sigma(w_1,\dots,w_k)$$ and this made sense to me since $w_1^\star\wedge\dots\wedge w_k^\star(w_1,\dots,w_k)=\mathrm{Det}|w_1,\dots,w_k|=1$ , and $(w_1^\star\otimes\dots\otimes w_k^\star)^\sigma(w_1,\dots,w_k)=1$ if and only if $\sigma$ is the identity, otherwise is equal to zero (so the sum is equal to $1$ ). Can you tell me where I'm wrong? Thank you in advance",['multivariable-calculus']
3292114,Can anybody provide any information about this equation? $2^2 = \left(x+\frac{1}{x}\right)^2 - \left(x-\frac{1}{x}\right)^2 $,"Can anybody provide me with any information about this fascinating equation? $$2^2 = \left(x+\frac{1}{x}\right)^2 - \left(x-\frac{1}{x}\right)^2 $$ I have been told many different things: 1) It is a mathematical Identity. 2) It is not a mathematical identity (because it does not work for
    zero). 3) It is a special case of the difference of squares equation. Can anybody give me any concrete facts? The reason i ask is because it's so interesting. For example: We can link this equation with Pythagoras’s theorem, so that for each number (x) we have a corresponding right angled triangle and each triangle has height (A) = 2, base (B) = x-1/x and hypotenuse (C) = x+1/x. As you can see, we can also link it with Trigonometry. Triangle Formation Animation And because tangents to an arc are always reciprocals, we can use it to get the following equations: SO, why does an equation this interesting not have a name (or does it?) and why is it not more well known? I have been playing around with the geometry of this equation for years and it has allowed me to create many tools to help visualize the symmetry of a number or angle, for example: Symmetry Animation We can also link this equation with the metallic means . Does this equation work for zero? Assuming that (x) is always >= 1 and that (1/x) is always <= 1. As you can see, these variables always cancel each other out. Substituting 1/x = 0 (zero) and x = ∞ (infinity). Tangents to an arc are always reciprocals.","['trigonometry', 'geometry']"
3292136,Prove no zero divisors of a ring with a radical in $\mathbb{Z}_7$,"When having the ring $$R:= \{a+b\sqrt{6}:\, a,b\in \mathbb{Z}_7\}$$ I have to prove the ring has no zero divisors. I want to proceed to prove with contradiction. So I know you can rewrite this to $N(xy) = N(x) N(y)$ so we can rewrite it to: $$N(a+b\sqrt{6}) = (a+b\sqrt{6})(a-b\sqrt{6})$$ First, let's assume $xy = 0$ for some $x\neq 0$ and $y\in \mathbb{Z}_7$ . So $N(xy)=N(x)N(y)=0$ . So either $N(x)=0$ or $N(y)=0$ . If we assume $N(x)=0$ , then we get: $a^2 -6b^2=0$ for some $a,b\in \mathbb{Z}_7$ . Now I'm stuck at the contradiction part, why can't there be any zero divisors in $\mathbb{Z}_7$ ?","['algebraic-number-theory', 'normed-spaces', 'integral-domain', 'ring-theory', 'abstract-algebra']"
3292139,How do you estimate the mean of a Poisson distribution from data?,"I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?","['statistics', 'probability-distributions', 'probability']"
3292170,Distribution of sample variance of Cauchy distributed variables,"Assume $X_i,i\in\left\{1,...,n\right\}$ are i.i.d. standard Cauchy distributed random variables. I know that $\bar{X}_n:=\frac{1}{n}\sum_{i=1}^n X_i$ is standard Cauchy distributed. I would like to know the distribution of the sample variance $$ \frac{1}{n}\sum_{i=1}^n \left(X_i-\bar{X}_n\right)^2 .$$ My foreknowledge: I know that moments like $\mathbb{E}(X),\mathbb{V}(X)$ do not exist for Cauchy distributed $X$ . I know that linear combinations of independent Cauchy random variables is Cauchy distributed as well. Weaker question: If nobody knows the exact distribution of the sample variance, it would be interesting if the distribution is independent of number of samples $n$ ? Like the distribution of the sample mean $\bar{X}_n$ does not depend on $n$ as it is always standard Cauchy for all $n$ . In  the Cauchy distribution Wikipedia article it says: Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. but I think this statement is not correct, because they use a similar (in my opinion very bad) formulation for the sample mean: the sample mean will become increasingly variable as more observations are taken which is not a correct statement, as the distribution of the sample mean $\bar{X}_n$ does not depend on $n$ . After reading the whole (in my opinion very badly written) paragraph Although the sample values $x_{i}$ will be concentrated about the central value $ x_{0}$ , the sample mean will become increasingly variable as more observations are taken, because of the increased probability of encountering sample points with a large absolute value. In fact, the distribution of the sample mean will be equal to the distribution of the observations themselves; i.e., the sample mean of a large sample is no better (or worse) an estimator of $x_{0}$ than any single observation from the sample. Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. I am really not sure what the author of this article wanted to express how the distribution of the sample variance depends on the number of samples $n$ . Do you know more about the distribution of the sample variance of $n$ i.i.d Cauchy distributed random variables?","['statistics', 'probability-distributions']"
3292194,Baby Rudin chapter 2 exercise 8,"Exercise 2.8: Is every point of every open set $E\subset R^2$ a limit point of $E$ ? My Solution: Every point of every open set $E\subset R^2$ is a limit point of $E$ . [Notation: $N_r(p)$ is the set of all point x such that $0< d(x,p)< r $ ] Since $E$ is open, let point $x \in E$ , then x is an interior point of E. There is $r>0$ such that the deleted neighborhood $N_r(x) \subset E$ . For any $s>0$ , the deleted neighborhood $N_s(x)$ contains a point $z\in E$ , if $0<d(x,z)<min(s,r)$ . Thus $x$ is a limit point of $E$ . My question: I think my solution did not use any property of $R^2$ , so this conclusion should be true in other metric spaces. Is that right?",['real-analysis']
3292206,"$\operatorname{Tr}(A^2) \geq-2$, if $A\in SL(2,R)$","I saw as a hint to an exercise that if $A\in SL(2,R)$ then $$\operatorname{Tr}(A^2)\geq-2.$$ I did the exercise with this hint, but I can't prove why this is true. Also, is there a similar inequality to $A\in SL(3,R)$ ?","['matrices', 'trace']"
3292227,why is the median an average of the two values?,"Consider the following population [1, 2, 2, 3, 3, 3] Under the definition of median, it should be 2.5 I am curious why the convention is set for it to be 2.5 specifically. To me, if you were to choose a value of say, 2.2, it is still the case that half the population is less than this value, and half is more than it. Median under a continuous distribution is easier for me to understand, if you were to integrate to the median, half your mass would lie below you and other half would lie above. However in the discrete setting, it is the case that any value between 2 and 3 will satisfy this condition. I believe there is a deeper reason than just ""it's just a convention we adopted"", if you can tell me the exact reason it would be nice. thanks in advance","['statistics', 'median']"
3292254,Value of cos 1 (angle is in radians)?,"How can we calculate the value of $\cos 1$ where the angle is in radians (and not degrees). If this isn't possible, can we somehow find whether this value would be rational or irrational? P.S: I know how to determine the irrationality of $\cos 1$ when angle is in degrees, and also am aware of its explicit formula. But those methods cannot be used here.","['rationality-testing', 'trigonometry', 'irrational-numbers', 'rational-numbers']"
3292280,What Can We Say About the Continuity of $y=\frac{x}{x}$ at $x=0$?,"If we can't divide by $0$ , should $\frac{x}{x}$ be discontinuous and undefined at $x=0$ or is it continuous with value $1$ ? Most online graph calculators plot a continuous curve. If it's continuous at $x=0$ with $y=1$ , then we should be able to say that $\frac{(a-b)}{(a-b)} = 1$ at $a=b$ . Or $q^2*\frac{p}{q}$ is $0$ at $q = 0$ . And that whole proof of $2=1$ would hold true. The graphs online for say $\frac{x^2-4}{x-2}$ at $x=2$ are puzzling me.","['limits', 'continuity', 'calculator']"
3292284,A Proof Related to the Fundamental Theorem of Calculus,"Let $f$ be continuous on $\mathbb{R}$ .
  Due to FTC I, we know that a function of the form∗ $F(x) = \int_a^xf(t)\operatorname dt$ is always an antiderivative of $f(x)$ . In this
  question you will investigate whether all antiderivatives of $f(x)$ can be expressed in this form∗.
  For simplicity, let us further assume $f$ is non-negative $(i.e. ∀x ∈ \mathbb{R}, f(x) ≥ 0)$ . (a) Suppose $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt$ or $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt$ is finite, show there is an antiderivative $G(x)$ of $f(x)$ which does
  not equal $\int_a^xf(t)\operatorname dt$ for any a $\in \mathbb{R}$ (b)Suppose $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty$ and $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty$ , show for any antiderivative $G(x)$ of $f(x), ∃a ∈ \mathbb{R} \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt$ Hint: Think about whether antiderivatives of f(x) need to have zeroes. What I have tried so far: Look thorugh (a) and (b), it's saying if $f$ is continuous on $\mathbb{R}$ we have: $(\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt$ (This is a stronger version of the question, since negation of finite also include $-\infty$ , I'm not sure if this is still true, but this should implies what the question is asking to prove) By assumption, $f$ is non-negative, then we don't need to consider the $-\infty$ cases, just show the following would be sufficient: $(\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt$ I don't have the Intuition of why this is true, at least it's not very trivial to me.. So, first I tried to break it into definitions: 1. $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty$ $\Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A>M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N)$ 2. $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty$ $\Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A<M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N)$ 3. $\forall G(x), ∃a ∈ R \text{ s.t.}G(x) = \int_a^xf(t)\operatorname dt$ (not sure about this one) $\Leftrightarrow\forall G(x), ∃a ∈ R \text{ s.t.}\forall n \in \mathbb{R}, \forall \varepsilon>0, \exists \delta>0\text{ s.t. } \exists P\in \mathbb{P}$ s.t. $( \text{$P$ is a partition of [a,n]} \wedge l(P)<\delta)\rightarrow|S(f(t),P)-G(n)|<\varepsilon$ But those doesn't looks like very useful...where should I start? Any help or hint or suggestion would be appreciated.","['integration', 'definite-integrals', 'calculus', 'definition', 'limits']"
3292296,Is there an injective ring homomorphism from $\Bbb R \oplus \Bbb R$ to $C(\Bbb R)$?,"True or False: There exists injective ring homomorphism from $\Bbb R \oplus \Bbb R$ to $C(\Bbb R)$ , where $C(\Bbb R)$ is the set of continuous functions from $\Bbb R$ to $\Bbb R$ . I was trying to think that I can exploit the fact $\Bbb R \oplus \Bbb R$ is not an integral domain but we can't because $(1,0) \to f$ and $(0,1) \to g$ both non zero continuous function s.t their product is zero.","['real-analysis', 'continuity', 'functions', 'ring-theory', 'abstract-algebra']"
3292322,Open sets having an empty intersection but the intersection of their closure is not empty,"Suppose $V_{n}$ is a decreasing sequence of (bounded) open sets in $\mathbb{R}^{m}$ with $m\geq1$ . Suppose  the intersection of all $V_{n}$ is empty, and let $F$ be the intersection of the closures of $V_{n}$ . Can we say that there exists $N$ such that every $x$ in $F$ belongs to the boundary of $V_{n}$ , for $n\geq N$ ? (This question is suggested by setting $V_{n}=(0,1/n)$ )","['general-topology', 'real-analysis']"
3292324,"Show the quotient space of a finite collection of disjoint 2 simplices obtained by identifying pairs of edges is always a surface, locally homeomorp","Show the quotient space of a finite collection of disjoint 2-simplices obtained
by identifying pairs of edges is always a surface, locally homeomorphic to $\mathbb{R}^2$ . I have thought about doing the following: I think we have to consider several cases To prove that this space is a surface, we must take a point and prove that there is an open that contains it that is homeomorphic to the plane, if the point belongs to the interior of a 2-simplex that this space includes, we are ready the open is 2-simplex itself, the problem is if the point in question belongs to the intersection of two or more 2-simplices, how can I do in this case to be well defined? Thank you! Edit: This question is part of the exercises in Hatcher's book, in particular, exercise $10.(a)$ (pag 131), the complete exercise is: Note that: Each edge is identified with exactly one other edge.","['geometric-topology', 'general-topology', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3292331,Finding a General Pattern for the Partial fraction of $\frac{1}{{{\left( 1+x \right)}^{n}}\left( 1+{{x}^{2}} \right)}$,"I am interested in finding the general pattern for the partial fraction of: $$
\frac{1}{{{\left( 1+x \right)}^{n}}\left( 1+{{x}^{2}} \right)}
$$ where $n=1,2,3,......$ here is the partial fractions from $n=1\quad to\quad 10$ $$
\left( \begin{matrix}
   1 & \frac{1-u}{2\left( {{u}^{2}}+1 \right)}+\frac{1}{2(u+1)}  \\
   2 & -\frac{u}{2\left( {{u}^{2}}+1 \right)}+\frac{1}{2(u+1)}+\frac{1}{2{{(u+1)}^{2}}}  \\
   3 & \frac{-u-1}{4\left( {{u}^{2}}+1 \right)}+\frac{1}{4(u+1)}+\frac{1}{2{{(u+1)}^{2}}}+\frac{1}{2{{(u+1)}^{3}}}  \\
   4 & \frac{1}{2{{(u+1)}^{3}}}+\frac{1}{2{{(u+1)}^{4}}}-\frac{1}{4\left( {{u}^{2}}+1 \right)}+\frac{1}{4{{(u+1)}^{2}}}  \\
   5 & \frac{u-1}{8\left( {{u}^{2}}+1 \right)}-\frac{1}{8(u+1)}+\frac{1}{4{{(u+1)}^{3}}}+\frac{1}{2{{(u+1)}^{4}}}+\frac{1}{2{{(u+1)}^{5}}}  \\
   6 & \frac{u}{8\left( {{u}^{2}}+1 \right)}-\frac{1}{8(u+1)}-\frac{1}{8{{(u+1)}^{2}}}+\frac{1}{4{{(u+1)}^{4}}}+\frac{1}{2{{(u+1)}^{5}}}+\frac{1}{2{{(u+1)}^{6}}}  \\
   7 & \frac{u+1}{16\left( {{u}^{2}}+1 \right)}-\frac{1}{16(u+1)}-\frac{1}{8{{(u+1)}^{2}}}-\frac{1}{8{{(u+1)}^{3}}}+\frac{1}{4{{(u+1)}^{5}}}+\frac{1}{2{{(u+1)}^{6}}}+\frac{1}{2{{(u+1)}^{7}}}  \\
   8 & -\frac{1}{8{{(u+1)}^{3}}}-\frac{1}{8{{(u+1)}^{4}}}+\frac{1}{4{{(u+1)}^{6}}}+\frac{1}{2{{(u+1)}^{7}}}+\frac{1}{2{{(u+1)}^{8}}}+\frac{1}{16\left( {{u}^{2}}+1 \right)}-\frac{1}{16{{(u+1)}^{2}}}  \\
   9 & \frac{1-u}{32\left( {{u}^{2}}+1 \right)}+\frac{1}{32(u+1)}-\frac{1}{16{{(u+1)}^{3}}}-\frac{1}{8{{(u+1)}^{4}}}-\frac{1}{8{{(u+1)}^{5}}}+\frac{1}{4{{(u+1)}^{7}}}+\frac{1}{2{{(u+1)}^{8}}}+\frac{1}{2{{(u+1)}^{9}}}  \\
   10 & -\frac{u}{32\left( {{u}^{2}}+1 \right)}+\frac{1}{32(u+1)}+\frac{1}{32{{(u+1)}^{2}}}-\frac{1}{16{{(u+1)}^{4}}}-\frac{1}{8{{(u+1)}^{5}}}-\frac{1}{8{{(u+1)}^{6}}}+\frac{1}{4{{(u+1)}^{8}}}+\frac{1}{2{{(u+1)}^{9}}}+\frac{1}{2{{(u+1)}^{10}}}  \\
\end{matrix} \right)
$$ Can any body see the pattern if any, Can we write it as a sum?? Problem background: I am trying to find a closed form for the integral: $$\int{\frac{1}{{{\left( 1+x \right)}^{n}}\left( 1+{{x}^{2}} \right)}dx}$$","['integration', 'calculus', 'partial-fractions']"
3292422,Open sets having an empty intersection but the intersection of their closure is not empty 2,"Consider a decreasing sequence of bounded open sets $V_{n}$ in $\mathbb{R}^{m}$ and $m\geq1$ . Suppose $\cap V_{n}=\emptyset$ and $F:=\cap \overline{V_{n}}$ is connected . Can we say there is $N$ such that each $x\in F$ belongs to the boundary of $V_{n}$ , for all $n\geq N$ ?","['general-topology', 'real-analysis']"
3292423,"How do you prove that if $\lim\limits_{n \to \infty}a_n=1$, then $\lim\limits_{n \to \infty}\frac{1}{1+a_n}=\frac{1}{2}$?","More precisely: Prove using only the $\epsilon$ - $N$ definition of convergence that if $\lim\limits_{n \to \infty}a_n=1$ and $a_n>-1$ for all $n\in \mathbb{N}$ , then $\lim\limits_{n \to \infty}\frac{1}{1+a_n}=\frac{1}{2}$ . Here's what I have so far: Let $\{a_n\}$ be a sequence and suppose $\lim\limits_{n \to \infty}a_n=1$ and $a_n>-1$ for all $n\in \mathbb{N}$ . Then for all $\epsilon>0$ , there exists $N\in \mathbb{N}$ such that for all $n\ge N$ , $|a_n-1|<\epsilon$ by the $\epsilon$ - $N$ definition of convergence. Then $-\epsilon<a_n-1<\epsilon$ Then $-\epsilon<1+a_n-2<\epsilon$ Then $\frac{1}{-\epsilon}<\frac{1}{1+a_n}-\frac{1}{2}<\frac{1}{\epsilon}$ Then $|\frac{1}{1+a_n}-\frac{1}{2}|<\frac{1}{\epsilon}$ Let $\epsilon'=\frac{1}{\epsilon}$ Then for all $\epsilon'>0$ , there exists $N\in \mathbb{N}$ such that for all $n\ge N$ , $|\frac{1}{1+a_n}-\frac{1}{2}|<\epsilon'$ Therefore, $\lim\limits_{n \to \infty}\frac{1}{1+a_n}=\frac{1}{2}$ by the $\epsilon$ - $N$ definition of convergence. Is this a valid proof? In particular, I am not sure about step 5. Intuition tells me that it is correct; but I am not 100% sure about the algebra.","['limits', 'proof-verification', 'real-analysis']"
3292430,$(X_k)_{k\in\mathbb{N}}$ uncorrelated $|X_k|<52\ \forall k\in\mathbb{N}$. Show $\frac{1}{n}\sum_{k=0}^{n}X_k-\mathbb{E}[X_k]\xrightarrow{\mathbb{P}}0$,"Not a homework question but an exercise from an past exam. Let $(X_k)_{k\in\mathbb{N}}$ be uncorrelated real valued random variables on a probability space $(\Omega, \mathcal{F}, \mathbb{P}$ and fulfilling $|X_k|<52$ for all $k \in \mathbb{N}$ .
  Show that $$\frac{1}{n}\sum_{k=0}^{n}X_k-\mathbb{E}[X_k]\xrightarrow[n \to \infty]{\mathbb{P}}0$$ (convergence in probability). I attempted to use the following theorem from the lecture: Theorem (Generalisation of the Weak Law of Large Numbers) Let $(X_k)_{k = 1}^{n}$ be pairwisely uncorrelated with finite variance.
  Then $$
\frac{1}{n^2} \sum_{k = 1}^{n} \text{Var}[X_k]
\xrightarrow{n \to \infty} 0
$$ implies $$
\frac{1}{n} \sum_{k = 1}^{n} \left( X_k - \mathbb{E}[X_k] \right)
\xrightarrow[n \to \infty]{\mathbb{P}} 0.
$$ My progress By definition we have $$
\frac{1}{n^2} \sum_{k = 1}^{n} \text{Var}[X_k]
\overset{\textrm{Def.}}{=} \frac{1}{n^2} \sum_{k = 1}^{n} \mathbb{E}[(X_k - \mathbb{E}[X_k])^2]
\le \frac{1}{n^2} \sum_{k = 1}^{n} 2 \cdot 52 
\le \frac{1}{n^2} 2n \cdot 52
= \frac{104}{n}
\xrightarrow{n \to \infty} 0.
$$ Is this correct?","['law-of-large-numbers', 'proof-verification', 'probability-theory']"
3292444,How much are you willing to pay for this treasure chest game?,"I was given an interesting problem that comes in two parts. In front of you is a treasure chest containing \$1000 with a 6-digit
  combination lock. You have to pay a constant amount for each time you
  change a digit. What is the maximum amount you are willing to pay per turn? Not sure if my approach here is correct: if the expected value of the game is $E$ and the amount I pay per turn is $x$ , then $$E=\frac{1}{10^6}(1000-x)+\frac{10^6-1}{10^6}(E-x)$$ $$=E\left(1-\frac{1}{10^6}\right)+\frac{1000}{10^6}-x.$$ $$\Rightarrow E=1000-10^6x.$$ For positive payoff, we require $x<1000/10^6$ , i.e. we want to pay less than \$0.001. My main issue is with the next subproblem. When two or less digits are correct, an LED on the chest glows red.
  When three or more (but not six) digits are correct, the LED glows
  yellow. When all digits are correct, the LED glows green and the chest
  opens. Is there an optimal strategy? How much are you willing to pay
  per turn now? How exactly do we form a strategy? I’m unsure of the most efficient way to keep track of the correct digits, and how to get back on track if a yellow LED switches to red. I am also unsure of how this affects the equation for the expectation. Could someone guide me on this please? Thank you!","['expected-value', 'conditional-expectation', 'probability']"
3292454,Question about proof for intersection of a set family with union of a set,"I am studying this proof and there are a few things I need help understanding. Let $A$ be a set and $B_i$ , for $i \in I$ be a family of sets Prove $ A \cup (\cap_{i \in I}B_i)$ = $\cap_{i \in I}(A \cup B_i)$ proof: suppose $x \in A$ then $x \in (A \cup B_i)$ for all $i \in I$ Also if $x \in \cap_{i \in I}B_i$ , $x \in (A \cup B_i)$ for all $i \in I$ thus $x \in \cap_{i \in I}(A \cup B_i)$ . Can someone please explain to me what's in the set $ \cap_{i \in I}(A \cup B_i)$ . Is it the intersection of $A$ included with the intersection of all the $B_i's$ or is it the intersection of all the $B_i's$ with the union of A In other words is it the intersection of B included with the intersection of the family Or is it the intersection of the family added with the set A?? I don't get most why the set A can be incorporated in the parenthesis with the intersection of the family! It just doesn't seem right to me, I need to know if the notation $\cap_{i \in I}B_i$ , the intersection of all these sets  is restricted to the family.",['elementary-set-theory']
3292466,Find the number of the subgroups,"Here is the question that I've stuck. Question) $G = Z_{100} \times Z_{500}$ Let $H$ is a subgroup of the $G$ How many number of the $H$ s.t. $H \simeq Z_{25} \times Z_{25}$ ? My idea) This is my idea when I tried this question at the first time. The ideal is a really simple. Let me suppose only finite group case. Put the $g (\in G)$ $s.t.$ $\vert g \vert = m$ . Since there are some elements that generate the same subgroups Then All we have to do is (The number of the $H$ whose order is $m$ )  = (The number of the $g$ ) / (The number of the group's element by generated by element, $g$ ) But, I couldn't find any the denominator in formula of the above question.","['group-theory', 'abstract-algebra']"
3292467,"What does it mean for a function of two arguments $f: [0, \infty) \times M \to M$ to be continuous?","Suppose we have a metric space $(M,d)$ Let $f: [0, \infty) \times M \to M$ . What does it mean for $f$ to be continuous? Here are some suggestions: $f$ is continuous if for every open set $V \subseteq   M$ , $f^{-1}(V)$ is open in the product topolgy of $[0 , \infty) \times
M$ , where the product topology is the topology generated by the natural topology on $[0, \infty)$ and the metric topology on $M$ . $f$ is continuous if for all sequences $(t_k, x_k) \to (t,x) $ , $f(t_k,x_k)$ converges to $f(t,x) \in M$ $f$ is continuous if for all $(t,x) \in [0 \times \infty) \times M$ , and for all $\epsilon >0$ , there exists a $\delta >0$ , such that if $(t',x') \in [0, \infty) \times M$ whenever $d((t,x), (t',x')) < \delta \implies  d(f(t,x), f(t',x')) < \epsilon$ Can someone check my definition? And are these conditions equivalent? Note: the last definition is messed up, I just noticed $d((t,x), (t',x'))$ doesn't make sense.","['general-topology', 'definition', 'analysis', 'real-analysis']"
3292475,"What is the closed form of the $f$ with $f(1)=1$, $f(2)=7$ and $f(n)=7f(n-1)-12f(n-2)$ ($n\ge 3$)?","Suppose $f(1)=1$ and $f(2)=7$ . For $n\ge 3$ we have $$f(n)=7f(n-1)-12f(n-2).
$$ What is the closed form of the function $f$ ? I've tried unrolling it but it gets very complicated very quickly without a clear pattern emerging. Any ideas?","['recurrence-relations', 'closed-form', 'discrete-mathematics', 'recursion']"
3292479,"If $X$ is an infinite set, then is $\sum_{i=1}^\infty |X|=|X|$?","I used the above to solve a problem, but I am not sure if this is true (and if it is true does it require a proof or is it obvious). I think it is true because $|X| + |X| = |X|$ , so it should follow that $\sum_{i=1}^\infty |X|=|X|$ . However, I am getting confused because I do not know if there may be different 'rules' for infinite sums of cardinals.","['elementary-set-theory', 'cardinals']"
