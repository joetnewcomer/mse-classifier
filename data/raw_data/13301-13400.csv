question_id,title,body,tags
104752,How can one use the logarithm function to define angles?,"In dealing with the complex logarithm function, I read that the imaginary part of $\log w$, is also called the argument of $w$, $\operatorname{arg }w$, and it is interpreted geometrically as the angle between the positive real axis and the half line from the origin through the point $w$. Using the interpretation, is there a standard way to define angles in triangles in the plane?
I tried to draw a crude little picture. So something like $\Im(\log b)-\Im(\log a)$ would give the angle between the two dashed lines emanating out to $b$ and $a$, but how would one define the angle between the legs $ab$ and $ac$? I would like to avoid angles greater than $\pi$, so I'm hoping there's a definition that returns angles in $[0,\pi]$. Thanks.","['analytic-geometry', 'geometry', 'complex-analysis']"
104765,Expressing Differential Form in Different Coordinates,"All: Please forgive me, I'm new and my editing/Latex needs improvement. I'm trying to derive the formula for change of variables for the differential form $\omega=dx\wedge dy$ in standard $xy$-coordinates in $\mathbb R^2 $, into polar coordinates in $\mathbb R^2$. I know we can use the quick-and-dirty change of variables:
$$
x=r\cos t, \quad y=r\sin t.
$$
Then sub-in, expand, and cancel terms with repeated $dr$'s and/or $dt$'s. But I'm trying to use the layout in J. Lee's Smooth Manifolds , pp 303-304, given by: Definition. Given a smooth map $F\colon M \to N$ and a form $\omega$ defined on $N$, the pullback $F^*$ is given by:
\begin{equation}
(F^*\omega)_p(X_1, \ldots, X_n) := \omega_{F(p)} (F_*X_1,....,F_*X_n). \qquad (**)
\end{equation} Results. a) $F^*$ is linear on the space of smooth sections b) $F^*(\omega\wedge \eta)=F_*(\omega)\wedge F_*(\eta)$ c) In any smooth chart, and for every multi-index index $I=(i_1,i_2,\ldots,i_k)$:
  $$ F^*(\sum' \omega_I dy^{i_1}\wedge dy^{i_2} \wedge \ldots \wedge dy^{i_k})=\sum'(\omega_I \circ F)d(y^{i_1} \circ F)\wedge\cdots\wedge d(y^{i_k} \circ F),$$
where $\sum'$ is a sum over increasing indices. So far, I have: $\omega=dx\wedge dy$; $F\colon\mathbb R^2\to\mathbb {R^2}'$, and $\omega$ is defined on the target ${\mathbb R^2}'$. We pull back by the map $F(x,y)=(r\cos t,r\sin t)$. Then, by  b, $F^*\omega =F^*(dx\wedge dy) =F^*(dx)\wedge F^*(dy)$. (Moreover, Lee has not yet defined the meaning of $dx$, nor of $dy^{i_k}$.) Now, I can only think of using $(**)$, but this does not help: $F^*(dx):=dx(\cos t, \sin t) (F_*X_1,\ldots,F_*X_n)$ where $F_*$ is given by $F_*(X)(f)=X(f\circ F)$. Any ideas?",['differential-geometry']
104768,when the curve $\mathbb{r=a\sin(b\theta)}$ is algebraic?,"A need to show that the curve given in polar equation $\mathbb{r=a\sin(b\theta)}$ is an algebraic curve if  $b=\frac{m}{n}$, $m,n\in \mathbb{N}^{*}$ and $(m,n)=1$. Also I am supposed to find the polynomial which it satisfies. If $b$ is an irrational number then the curve (I don't know the name in English) is not algebraic. I would appreciate any help with this problem. PS. I've studied Algebraic Curves, Commutative Algebra and Algebraic Geometry many years ago (7 years to be exact!). So, I am trying get back to business. If it is a silly question, please delete it.","['plane-curves', 'algebraic-geometry', 'algebraic-curves']"
104772,Algebraic functions are polynomials?,Does any one how to prove that every entire algebraic function is a polynomial? I'm under the impression that this can be achieved by showing that an algebraic function grows no faster than a polynomial.,['complex-analysis']
104773,When is a uniform space complete,"From Wikipedia : a uniform space is called complete if every Cauchy filter converges. I was wondering if the following three are equivalent in a uniform
space: every Cauchy filter converges, every Cauchy net converges, and every Cauchy sequence converges? Or, which one implies which but doesn't imply which? For example, are
the first two equivalent, while the third is implied by but does not
implie any of the first two? How about in a metric space? Thanks and regards!","['general-topology', 'uniform-spaces']"
104777,Are there more general spaces than Euclidean spaces to have the Heine–Borel property?,"From Wikipedia A metric space (or topological vector space) is said to have the
  Heine–Borel property if every closed and bounded subset is compact. Any subset of a Euclidean space, including itself, has the Heine–Borel property. I was wondering if there are more general types of metric spaces, topological vector spaces, or whatever space where boundedness and closedness can make sense, such that they also have the Heine–Borel property? Or does the Heine–Borel property characterize subsets of Euclidean spaces? Thanks and regards!",['general-topology']
104786,Contest problem on domain and range of square root function,I have no clue how to do this problem: Let $f(x)=\sqrt{ax^2+bx}$. For how many real values $a$ is there at least one positive real value of $b$ for which the domain of $f$ and the range of $f$ are the same set? The answer is two but what is the complete solution?,"['algebra-precalculus', 'contest-math']"
104795,"Homotopic maps $(X, A) \to (Y, B)$ induce homotopic maps $X/A \to X/B$","Working with a homework problem: $X$ and $Y$ are topological spaces and $A\subset X$, $B\subset Y$.  I have $f,g:(X,A)\to (Y,B)$ as homotopic maps. I need to show that the induced maps:  $\hat{f},\hat{g}$ are homotopic. My instinct says that the homotopy I should use is $\hat{F}:I\times (X/A)\to (Y/B)$ should be given by $\hat{F}(t,[x]) := [F(t,x)]$.  I showed this map is well defined without any problem. Edit:  More precisely, $\hat{f}$ maps the pair $(t,[x])$, where $x$ is any element in $[x]\in X/A$, to $[y]$, where $y$ is any element in $[F(t,x)]$. But I'm having difficulty showing the map is continuous.  If I take $V$ to be an open subset of $Y/B$, how can I use the continuity of $F$ to show that $\hat{F}$ is continuous?","['general-topology', 'algebraic-topology']"
104801,Characterization of Asymptotic Stability via KL-class functions,"Let us adopt the following definition of stability and asymptotic stability of a dynamical system of the form: $$
\dot{x}=f(x)
$$ The trajectory of this system starting from the initial point $x_0$ at $t_0=0$ will be hereinafter denoted by $\varphi(t,x_0)$. Definition 1 (Stability) . Let $x^\star$ be an equilibrium point for $\dot{x}=f(x)$, i.e. $f(x^\star)=0$. This point is said to be stable if for every $\varepsilon>0$ there is a $\delta=\delta(\varepsilon)>0$ such that
$$
\|x-x^\star\|<\delta \implies \|\varphi(t,x_0)-x^\star\|<\varepsilon
$$
for all $t\geq 0$. Definition 2 (Asymptotic Stability) . Let $x^\star$ be an equilibrium point for $\dot{x}=f(x)$, i.e. $f(x^\star)=0$. This point is said to be asymptotically stable if it is stable and additionally there is an $\alpha>0$ such that
$$\lim_{t\to\infty}\|\varphi(t,x_0)-x^\star\|=0$$
for all $x$ with $\|x-x^\star\|<\alpha$. Definition 3 (Classes of functions) . We define the following four classes of functions:
A function $\alpha:\mathbb{R}^+\to\mathbb{R}^+$ is said to be $\mathcal{K}$-class and we denote $\alpha\in\mathcal{K}$ if it is continuous, strictly increasing and $\alpha(0)=0$. A function $\beta:\mathbb{R}^+\to\mathbb{R}^+$ is said to be $\mathcal{K}_\infty$-class and we denote $\beta\in\mathcal{K}_\infty$ if $\beta\in\mathcal{K}$ and it is unbounded. A $\mu:\mathbb{R}^+\to\mathbb{R}^+$ is said to be $\mathcal{L}$-class and we denote $\mu\in\mathcal{L}$ if it is continuous, strictly decreasing and $\lim_{\tau\to\infty}\mu(\tau)=0$ A $\gamma:\mathbb{R}^+\times\mathbb{R}^+\to\mathbb{R}^+$ is said to be $\mathcal{KL}$-class and we denote $\gamma\in\mathcal{KL}$ if $\gamma(\cdot,t)\in\mathcal{K}$ for all $t\in\mathbb{R}^+$ and $\gamma(r,\cdot)\in\mathcal{L}$ for all $r\in\mathbb{R}^+$ Proposition 1. An equilibrium point $x^\star$ is asymptotically stable if and only if there is a $\gamma\in\mathcal{KL}$ and a constant $\kappa>0$ so that:
$$
 \|\varphi(t;x_0)-x^\star\|\leq \gamma(\|x_0-x_\star\|,t)
$$
for all $x_0$ such that $\|x_0-x^\star\|<\kappa$ and for all $t\geq 0$. I have some problem with the proof! Proof: 1. [The first part looks easy] Let us assume that $x^\star$ satisfies the inequality mentioned above. Let us choose an $\varepsilon>0$; $\gamma(\cdot,t)$ is $\mathcal{K}$-class, so we may choose a $\delta$ such that $0<\delta<\kappa$ and $\gamma(\delta,0)\leq \varepsilon$. Now for $\|x_0-x^\star\|<\delta$ we have: $$
 \|\varphi(t;x_0)-x^\star\|\leq\gamma(\|x_0-x_\star\|,t)\leq\gamma(\|x_0-x_\star\|,0)\leq\gamma(\delta,0)\leq\varepsilon
$$ So if the inequality state above holds then $x^\star$ is stable and more:
$$
 0\leq\lim_{t\to\infty}\|\varphi(t;x_0)-x^\star\|\leq \lim_{t\to\infty}\gamma(\|x_0-x^\star\|,t)=0
$$
Therefore
$$
 \lim_{t\to\infty}\|\varphi(t;x_0)-x^\star\|=0\Leftrightarrow\lim_{t\to\infty}\varphi(t;x_0)=x^\star
$$ What about the converse? How can one prove it? We need to prove that if $x^\star$ is a (locally) asymptotically stable equilibrium point, then there is a $\gamma\in\mathcal{KL}$ and a constant $\kappa>0$ so that:
$$
 \|\varphi(t;x_0)-x^\star\|\leq \gamma(\|x_0-x^\star\|,t)
$$
for all $x_0$ such that $\|x_0-x^\star\|<\kappa$ and for all $t\geq 0$. I would appreciate a proof or at least a reference to some book or article where I can find it clearly explained.","['dynamical-systems', 'analysis']"
104806,Question regarding infinite Blaschke product,"According to Gamelin's $\textit{Complex Analysis}$, a finite Blaschke product is a rational function of the form $B(z)= e^{i \varphi} (\frac{z-a_1}{1-\bar{a_1} z} \cdots \frac{z-a_n}{1-\bar{a_n} z})$ where $a_1, ..., a_n \in \mathbb{D}$ and $0 \leq \varphi \leq 2\pi$. Similarly, I would guess that an infinite Blaschke product would be of the form $e^{i \varphi} \prod_{n=1}^\infty\frac{z-a_n}{1-\bar{a_n} z}$. I believe this is supposed to satisfy what is known as the Blaschke condition, i.e. $\sum_{n=1}^\infty (1-|a_n|) < \infty$, but how is that so? Can this be verified using the log function on the infinite product?",['complex-analysis']
104809,Gluing Lemma for Closed Sets: Infinite Cover Counter-Example,"The gluing lemma for closed sets states: Given a finite closed cover $\{A_i\}$ of a topological space $X$, together with continuous maps $\{f_i : A_i \to Y\}$ into some other topological space $Y$, there exists a unique continuous map $f : X \to Y$ whose restriction to each $A_i$ is equal to $f_i$. Question: What is a good and simple counter-example when the gluing lemma fails in the case that $\{A_i\}$ is infinite, but countably so. My attempt: I have only been able find a silly counter-example: let $\{A_\alpha\}$ be the collection of all points of $X = [0,1] \subset \mathbb{R}$, and let $f_\alpha = 0$ for all $\alpha$ except for $\alpha = \alpha_0$, for which $A_{\alpha_0} = \{0\}$ and $f_{\alpha_0} = 1$.","['general-topology', 'continuity', 'examples-counterexamples']"
104810,Prove that $f:\mathbb R^n\to\mathbb R$ is affine if and only if it is convex and concave,"Suppose $f:\mathbb{R}^n\to \mathbb{R}$ is both convex and concave, how to prove that $f$ is linear? or exactly speaking, $f$ is affine? I thought for the whole day, but I cannot figure it out. When I was working on this problem, I met another problem, are all the convex function continuous? If not, is there any counter example? Actually, I can prove for one dimensional case, in which $f:\mathbb{R}\to \mathbb{R}$. However, I cannot generalize it into n dimensional cases. By the way, I use definition for convex(concave) like this:
$$f(t\vec{x}+(1-t)\vec{y})\leq(or \geq) tf(\vec{x})+(1-t)f(\vec{y}), \forall t\in[0,1].$$ Thank you so much!","['convex-analysis', 'convex-geometry', 'analysis']"
104820,Is this set closed?,"$X=(C[0,1],\rho_\infty)$ where $\rho_\infty$ is the uniform norm. $M\in(0,\infty)$, define
$A=\{f\in X:f(0)=0, f\;\mathrm{differentiable\;on}\;(0,1)\;,|f^\prime(x)|\leq M\;\;\forall x\in(0,1)\}$. I was trying to prove that $A$ is compact, I wanted to use Ascoli-Arzelà, so I proved that $A$ is equicontinuous and bounded, but I don't know how to prove that it's closed, what is giving me problems is that if $(f_n)\subset A$ and $f_n\rightarrow f$ then $f$ is differentiable, I'm not even sure that it's true. I mean, in general it's not true, but I don't know if the other conditions of $A$ force this to be true, could you help me? EDIT: following the hint of yoyo I think that we should take the sequence $f_n(x)=1/2-|x-1/2|$ if $|x|\geq 1/2+1/n$, and $f_n(x)=1/2-n/2(x-1/2)^2-1/(2n)$ if $|x|\leq 1/2+1/n$, but I'm having problems to prove that this sequence converges uniformly to $1/2-|x-1/2|$, any hints? EDIT EDIT: following the hint of Jonas I think I solve the problem: modify the function as Jonas said, then $f(x)-f_n(x)=-|x-1/2|+n/2(x-1/2)^2+1/(2n)$ if $|x-1/2|\leq 1/n$ and zero elsewhere. But $-1/(2n)=-1/n+0+1/(2n)\leq-|x-1/2|+n/2(x-1/2)^2+1/(2n)\leq0+n/2\cdot1/n^2+1/(2n)=1/n$ and so $|f(x)-f_n(x)|\leq 1/(2n)$ and the convergence is uniform. Am I right?","['real-analysis', 'analysis']"
104824,How to determine if a linear system is solvable,"I have this problem
$$\begin{array}{rcccccl}
3x &-&y &+& 2z &=& 2\\
2x &+& y &+& z &=& -1\\
x &+& 3y & & &=&-1
\end{array}$$
This gives me the matrix:
$$\left(\begin{array}{rrr|r}
3 & -1 & 2 & 2\\
2 & 1 & 1 & -1\\
1 & 3 & 0 & -1
\end{array}\right)$$ I remember something about if you can show that a system in inconsistent, you know it's not solvable. I set Row1->Row1 - 2*Row2 + Row3 The result is:
$$\left(\begin{array}{rrr|r}
0 & 0 & 0 & 3\\
2 & 1 & 1 & -1\\
1 & 3 & 0 & -1
\end{array}\right)$$ So 0 = 3 which is inconsistent. Two things, did I do this right and is my assumption that all linear systems that can be shown as inconsistent are unsolvable? Are there less painful ways to show it's not solvable? It seems like this could go on for a while with trial and error to either find an inconsistency or an answer for x y and z.",['linear-algebra']
104829,Using the complex logarithm to find the sum of angles in a triangle.,"Suppose you have a triangle with vertices $a$, $b$, and $c$. I asked earlier how you can define the angles in a triangle based on the $\log$ function. I received the answer that, for instance, the angle at $a$ is found as $\left|\Im\log\left(\frac{c-a}{b-a}\right)\right|$. Can this be used to show that the sum of angles in a triangle is $\pi$? I summed the angles as
$$
\left|\Im\log\left(\frac{c-a}{b-a}\right)\right|+\left|\Im\log\left(\frac{a-b}{c-b}\right)\right|+\left|\Im\log\left(\frac{a-c}{b-c}\right)\right|.
$$ I noticed that $\left|\Im\log\left(\frac{c-a}{b-a}\frac{a-b}{c-b}\frac{b-c}{a-c}\right)\right|=\left|\Im\log(-1)\right|=\pi$, when evaluating on the principal branch. I had to cheat a bit and flip the $\frac{a-c}{b-c}$. Is there a more systematic way to prove this somehow?","['geometry', 'complex-numbers', 'trigonometry', 'complex-analysis']"
104830,Defining the domains that verify and falsefy a proposition,"Find a common domain for the variables x,y, and z for which the statement

 ∀x∀y((x≠y)→∀z((z=x)∨(z=y)))

is true and another domain for which it is false. This problem stumped me. I wrote: The statement is true for any binary domain (such as {0,1}) 
and false for any non binary domain. The corrected paper stated that ""non binary domain"" was incorrect.
I am guessing that this is simply a matter of sloppy wording and that ""greater than binary"" would be correct. It also stated that I needed to justify my answer.
Can anyone give me a starting point for how I would approach a proof?",['discrete-mathematics']
104844,Cards and probability,"There are four cards in a hat. Three cards have 0 on one side and 1 on the other, while the fourth card has a 0 on both sides. If I observe that one side of a card I have chosen at random has a 0 on it, what is the probability of the card I have chosen being the one with 0 on both sides? I think the answer's $\frac{2}{5}$ since we're accounting for sides only. We have five sides with a 0, and the two sided card has two of those 0s. Am I making a mistake?",['probability']
104845,The roots of Hermite polynomials are all real?,The Hermite polynomials are defined as $$H_n(x)=(-1)^n e^{x^2}\dfrac{d^n}{dx^n}e^{-x^2}.$$ How does one prove that all the roots of the Hermite polynomial are real?,"['special-functions', 'orthogonal-polynomials', 'calculus']"
104846,The differences between $\mathbb{R}/ \mathbb{Z}$ and $\mathbb{R}$,"The cosets of $\mathbb{Z}$ in $\mathbb{R}$ are all sets of the form $a+\mathbb{Z}$, with $0 ≤ a < 1$ a real number. Adding such cosets is done by adding the corresponding real numbers, and subtracting 1 if the result is greater than or equal to 1. -- Examples of Quotient Group, Wiki I cannot figure out the differences between $\mathbb{R}/ \mathbb{Z}$ and $\mathbb{R}$. Besides, ""subtracting 1 if the result is greater than or equal to 1"", what does ""the result"" mean here? Why do we need to subtract 1? I was wondering what is the background of $\mathbb{R}/ \mathbb{Z}$.","['group-theory', 'abstract-algebra']"
104854,Characterization of the trace function,"We know that the trace of a matrix is a linear map for all square matrices and that $\operatorname{trace}(AB)=\operatorname{trace}(BA)$ when the multiplication makes sense. On the Wikipedia page for trace , under properties, it says that these properties characterize the trace completely in the following sense: If $f$ is a linear function on the space of square matrices satisfying $f(xy)=f(yx)$ , then $f$ and $\operatorname{tr}$ are proportional. A note on the bottom of the page gives the justification, but I do not understand the logic of it. Thanks","['matrices', 'linear-algebra']"
104864,probability bound,"Let $x_1,\ldots,x_n$ be i.i.d. random variables with continuous and concave distribution function F. It is known that for $t\geq 0$
$$
P\left(\sum_{i=1}^nx_i\leq t\right)\leq\\

\left\{ \begin{array}{rcl}
\frac{1}{n!}\sum_{j=0}^k(-1)^j {n \choose j}\left(nF\left(\frac tn\right)-j\right)^n, &nF^{-1}\left(\frac kn\right)\leq t<F^{-1}\left(\frac{k+1}{n}\right), k=0,\ldots,n-1\\
1,&t\geq nF^{-1}(1),
\end{array}\right.
$$
here $F^{-1}(t)=\inf\{x:F(x)\geq t\}, 0<t\leq 1$. I am wondering if it is possible to bound the RHS of the inequality above (the sum). Is it possible by adding some assumptions on random variables $x_1,...,x_n$ to bound density function F? Continuous distribution function $F$ with support $[0, \infty)$ is called concave, if $F(\lambda s+(1-\lambda t))\geq \lambda F(s)+(1-\lambda)F(t)$, for every $s,t\geq 0, 0\leq\lambda\leq 1$. Any references and ideas would be very helpful. Thank you.",['probability']
104880,Grand Prix Race,"Driver A has boon leading archrival B for a while by a steady 3 miles. Only 2 miles from the finish, driver A ran out of gas and decelerated thereafter at ta rate proportional to the square of his remaining speed. One mile later,driver A's speed was exactly halved.If driver B's speed remained constant,who won the race? i have tried the set up the relation$d^2x\over dt^2$=$K ({dx\over dt})^2$ and integrate it but dont know how to do.",['ordinary-differential-equations']
104887,How many lines can be equidistant from 3 points?,How many lines can be drawn in a plane such that they are equidistant from 3 non-collinear points? @John Bentin has shown below that there are at least 3. Why are there no more than 3?,['geometry']
104895,Sigma-algebras. Countable intersections and distributivity,"It's kind of a classical problem with simple formulation but it turned out to be quite difficult for me. $(\Omega,\mathscr{F},P)$ is a probability space. If $(\mathscr{D}_n,\;n\geqslant 0)$ is a decreasing sequence of sub-$\sigma$-fields of $\mathscr{F}$: $\mathscr{D}_0\supset\mathscr{D}_1\supset\ldots$, $\mathscr{C}$ is another sub-$\sigma$-field of $\mathscr{F}$ independent of $\mathscr{D}_0$, then $$\bigcap\limits_n(\mathscr{C}\vee\mathscr{D}_n)=\mathscr{C} \vee \Bigl(\bigcap\limits_n\mathscr{D}_n\Bigr).$$ Note 1: $\mathscr{C}\vee\mathscr{D}_n$ is a $\sigma$-algebra generated by $\mathscr{C}\cup\mathscr{D}_n$. Inclusion $\bigcap\limits_n(\mathscr{C}\vee\mathscr{D}_n)\supseteq\mathscr{C} \vee \Bigl(\bigcap\limits_n\mathscr{D}_n\Bigr)$ is obvious. But the other one is not. Note 2: I found this problen in Revuz, Yor and there is a hint: show, that if $C\in\mathscr{C}$ and $D\in\mathscr{D}_0$ then $\lim\limits_{n\rightarrow\infty}P(CD|\mathscr{C}\vee\mathscr{D}_n)$ is $[\mathscr{C}\vee(\cap_n\mathscr{D}_n)]$-measurable. First, I don't really understand how to prove that the limit will be [some $\sigma$-algebra]-measurable. Second, with martingale convergence $E(I_C I_D|\bigcap\limits_n(\mathscr{C}\vee\mathscr{D}_n))$  is $[\mathscr{C} \vee (\cap_n\mathscr{D}_n)]$-measurable, what's next?","['probability-theory', 'probability']"
104901,What is $V : S \to V$?,"I came across a problem where I don't know what field to consult. The problem is simple to explain: I have a geometric object $S$, and a finite set of maps $V$ from the points in this object to $V$. Intuitively, any $v \in V$ partitions $S$, and chosing one of these partitions yields a new such partitioning. What kind of thing is this and/or what could I google to get more information on it or similar structures? (I am particularly interested in iterated applications, given an initial element of $V$ (partitioning), to a given sequence of points.) Thank you in advance.","['general-topology', 'geometry', 'functions']"
104902,Von Mises width at half height,"I'm fitting the following Von Mises type function to some data: $(A/2\pi)e^{k\cos(\theta)}+C$ where A and k are positive. I want to calculate the width at half height from the lowest point of the curve. Note that for some values of $A$, $k$, and $C$ this is not the same as $1/2$ of the maximum value taken by the function.  Instead, you can get those values just by setting $\cos(\theta) = 1$ and $\cos(\theta)=-1$.  Those should be the maximum and minimum values taken on by the function for a given set of parameters.  Then, plugging those in to the main equation and subtracting the min from the max, you get: $(A/2\pi)[e^k-e^{-k}]$, Now I want to get the half height, which is half of the above value, so that's $(A/4\pi)[e^k-e^{-k}]$. So far so good.  Now I want to solve for which $\theta$ the original equation takes those values.  There should be two since this a symmetric function, but I only need one, because I know where the peak is, and also since the function is centered at 0, one should be equivalent the negative of the other.  So I proceeded to solve the equation as so: $(A/2\pi)e^{k\cos(\theta)}=(A/4\pi)[e^k-e^{-k}]$ (the $C$ was dropped because when finding the half-height the $C$ was re-centered to $0$). Solving this for $\theta$ gives:
$\theta=\operatorname{acos}(\ln(\sinh(k))/k)$ For large values of $k$ this gives the right answer, as tested against numeric methods.  However, when $k$ becomes small, $\operatorname{acos}()$ becomes imaginary.  I am then unsure of how to retrieve the solution.  It's clear that the solution exists (I can still crawl alongthe contour of the function and numerically find a great approximation).  It's also the case that replacing $\sinh()$ with $\cosh()$ produces a really good approximation, although $\cosh()$ begins to fail to approximate well as $k$ gets larger (again, tested with numerical methods). So the question is, how to solve for those solutions analytically?  Also, why does $\cosh()$ work so well in the range of small k but not in the range of larger $k$? Thanks!","['trigonometry', 'complex-numbers', 'algebra-precalculus', 'mathematical-modeling']"
104910,Mysterious entities by the name of branch points,"Could someone please explain the concept of branch points to me? I have tried searching online and had a read of the textbook Visual Complex Analysis by T. Needham, but I am still not very clear how they work. An excerpt I found online from Introduction to Complex Analysis by H. Priestly says that $a$ is a branch point for [$w(z)$] if, for all sufficiently small $r>0$, it is not possible to choose $f(z)\in[w(z)]$ so that $f$ is a continuous function on $\gamma(a;r)^*$. Firstly, I couldn't find what $\gamma(a;r)^*$ is ... I presume it is an open ball around the point $a$ with radius $r$? Secondly, I just don't understand what it is saying. Why is there no continuous function? How when asked to find branch points would I know which points in $\mathbb C$ have this property? Needham's book basically says a branch point is one which if we circle it once we don't get back to the same point... but I still don't get it! Then I read something about branch cuts and Riemann spheres which really don't help to clarify anything at all! Thank you for your time. [ Added ] For example if I have a map of the form $f(z) =[(z-a)(z-b)...(z-n)]^{1\over m}$ how may branch points are there?",['complex-analysis']
104930,Christoffel Symbol - what does a comma mean in the footer?,"I am trying to understand the expression for Scalar curvature in terms of the Christoffel symbols. This is given on Wikipedia by
\begin{equation}
S = g^{ab}(\Gamma^c_{ab,c} - \Gamma^c_{ac,b} + \Gamma^d_{ab}\Gamma^c_{cd} - \Gamma^d_{ac}\Gamma^c_{bd})
\end{equation}
(see here for the Wikipedia post) The thing I'm not sure about is the comma in expression $ab,c$, for example in the footer of the first Symbol. My guess would be that it means
\begin{equation}
\Gamma^c_{ab,c} = \partial_c \Gamma^c_{ab}
\end{equation} Is that correct ?
The site on Christoffel Symbols on Wikipedia doesn't explain what the comma means so I was wondering whether somebody could help? Many thanks!","['notation', 'differential-geometry']"
104938,$A^{100} = 0$ implies $A^2 = 0$ when $A$ is $2\times 2$,"How to show the following claim $A^{100} = 0 \implies A^2 = 0$ with $A \in Mat(2 \times 2, K)$ If A is the matrix of a linear map $\phi$ then for all $v \in K^2$ the following identity should be true $\phi^{99}(v) = A^{99}\cdot v = A^{99} \cdot col_i(A) = 0$ But how to show that $A^2 = 0$?","['matrices', 'linear-algebra']"
104946,Poisson Process - Courts,"IITK sports facility has $4$ tennis courts. Players arrive at the courts at
a Poisson rate of one pair per $10$ min and use a court for an exponentially
distributed time with mean $40$ min. Suppose that a pair of players arrives
and finds all courts busy and $k$ other pairs waiting in queue. How long will
they have to wait to get a court on the average?","['statistics', 'stochastic-processes']"
104954,Are hyperbolic triangle groups hyperbolic?,"This might be a silly question, but are hyperbolic triangle groups hyperbolic, in the sense of Gromov? By a hyperbolic triangle group, I mean a group given by a presentation, $$\langle a, b, c; a^p, b^q, c^r, abc\rangle$$ where $\frac{1}{p}+\frac{1}{q}+\frac{1}{r}<1$. I think they are, and it seems to be implied in some places, but nowhere seems to state it explicitly (apart from cough wikipedia cough cough ). These groups act on they Hyperbolic plane in some way (they correspond to tilings of the plane with triangles which preserve the orientation of the triangles), so it is natural to generalise my question: is there some criteria $\mathcal{C}$ (faithfully, say) we can place on a group such that, $G$ is Hyperbolic in the sense of Gromov if and only if $G$ acts on some hyperbolic plane in a $\mathcal{C}$ way. (I should say that I understand that the ""hyperbolic"" which Gromov talks about is really talking about the Cayley graph having some hyperbolic properties, such as linear area and the $\delta$-thin triangle condition, and so on. However, hyperbolic groups can be defined in so many different-but-equivalent way and this one seems, well, a natural one to think about, even if it isn't necessarily easy to work with!)","['reference-request', 'geometric-group-theory', 'group-theory', 'gromov-hyperbolic-spaces']"
104967,Why does the sum of these trigonometric expressions give such a simple result?,"During calculations I came across the following identity: $$M+2(1-m) = \sum_{l=1}^{M-1} \frac{\cos\left(2\pi\frac{(2-m)\,l}{M}\right) - \cos\left(2\pi\frac{m\,l}{M}\right)}{2(1-\cos\left(2\pi\frac{l}{M}\right)}, \quad \forall m\in \{2,\dots, M\}, M\in \mathbb{N}$$ I cannot see why this rather complicated sum should give such a simple expression. Does anyone know trig-tricks to simplify the sum? Can one already see intuitively that the result is linear in $m$ ?","['trigonometry', 'calculus']"
104973,Derivative of an integral of differential form,"I have some smooth function $g(x) \colon \mathbb{R}^{n}_{+} \to \mathbb{R}_+$ such that $G_{t} = \{ x \in \mathbb{R}^n_+ \mid g(x) \leqslant t \}$ is compact. I consider a function
$$
  f(t) = \int\limits_{G_t}a(x)dx_1 \wedge  ... \wedge dx_n
$$
I want to find its derivative. In this article http://amath.colorado.edu/pub/wavelets/papers/BEYLKI-1984.pdf author uses the represenation of the form $dx_1 \wedge ... \wedge dx_n = dg(x) \wedge \Omega$ to reduce an integral of the form $dx$ to an iterated integral. Is it possible to do something similar here? I think the answer is
$$
  f'(t) = \int\limits_{ \{ x\mid g(x)=t \}} a(x) \Omega
$$","['differential-forms', 'integration', 'differential-geometry']"
104981,Is a dense subset of the plane always dense in some line segment?,"Consider the following question: Given a dense set in the plane, does there always exist a line segment in which this set is dense? I have been puzzling over this for some time. Can someone help or give me some hints?",['real-analysis']
105005,"Evaluate $\lim_{a \to0,Q \to\infty} \frac{Q}{2\pi}\big[ \log(z-a)-\log(z+a) \big]$","Can anyone help me find
$$\lim_{a \to 0,Q \to\infty} \frac{Q}{2\pi}\left[ \log(z-a)-\log(z+a) \right]$$ Where $aQ=A$ where $A$ is kept constant. I know it is in the form $\mu/z$ for some $\mu$ Thanks very much in advance",['limits']
105018,"Does the graph of $\cos x$ intersect the unit circle other than the point (0,1)?","It would seem the unit circle is nicely tucked under the graph of $\cos x$, touching only at (0,1), but is that what's truly going on here?","['trigonometry', 'circles']"
105043,simulating a fair random process with an unfair one.,"Let's say I have a stochastic process that outputs $1$ or $0$ with probability $p$ or $1-p$ respectively, $p\neq 1/2$. Let's assume this is a repeatable iid process. So I can generate $X_1,X_2\dots$ which are each $1$ or $0$ as above. Can I create a proposition (a logical construction out of the $X_i$s) with probability a half. That is, can I simulate a fair process with this unfair one. If $p=1$ or $p=0$ then obviously no. But (without loss of generality let's assume $1>p>1/2>1-p>0$. Is there always some such proposition? I can get arbitrarily close, sure. Think about the set of binary strings of length $n$ (you can think of my stochastic process as generating these sequences with certain probabilities). For large enough $n$, even the most likely of them is less than a half, and by picking the right ones to go in my ""proposition"" I can get as close to $1/2$ as I like, as long as I can increase $n$ as much as I want. For some values of $p$ you can get to exactly $1/2$. For example, take $p(2-p)=1/2$ and solve for $p$. For this value, $X_1 \lor X_2$ has probability exactly $1/2$. Is it always possible to find a proposition that has exactly probability a half? Or is there a characterisation of the values of $p$ that you can do this for? (Wasn't entirely sure what tags were appropriate)","['statistics', 'information-theory', 'probability-theory']"
105056,Organising a Tournament,"Imagine the following Problem. The Student Union wants to organise a tournament with 2k participants ( $k \in \mathbb{N}$ ). There are to be m rounds and in each round players should be paired according to some rule s.t. no pair that already met meets again in the same tournament 
(i.e. it s not an elimination tournament; each player plays once in each round and gets ranked at the end or whatever ... ) The committee is concerned that after a certain number of rounds a clash will be unavoidable, so they want to come up with the clever way to pair players to avoid this. My question is, how many legal rounds can we be sure of even if we organise it without any consideration for later rounds on an ad-hoc basis round by round. Whats the way to maximise the number of legal rounds and what is that maximum number ? I am also very interested in the way people would model this situation and the reasoning/motivation that leads them to a proof/result.","['discrete-mathematics', 'algorithms', 'graph-theory', 'soft-question', 'combinatorics']"
105068,Domain with $\cosh(x)$,"Take the function
$$y=\frac{\sqrt{\cosh\left(\frac{1+x}{x^2}\right) - 1}}{e^{\frac{2}{x-1}\log\left|x-1\right|}+1}$$
I have to find the domain of this function. These are the condition that I set up:
$$\begin{cases}
e^{\frac{2}{x-1}\log\left|x-1\right|}+1\neq 0&(1)\\
x-1\neq0&(2)\\
\left|x-1\right|>0&(3)\\
\cosh\left(\frac{1+x}{x^2}\right) - 1\ge0&(4)\\
x^2\neq0&(5)
\end{cases}$$
And these are the results:
$$\begin{cases}
\forall x \in\mathbb{R}&(1)\\
x\neq1&(3)\\
\forall x \in\mathbb{R}&(4)\\
x\neq0&(5)
\end{cases}$$ $(1)$ Denominator $(2)$ Denominator of the exponent $(3)$ Argument of the logarithm $(4)$ Argument of the root $(5)$ Denominator of the argument of $\cosh$ And this is the definition set of $y$: $$x\in(-\infty, 0)\cup(0, 1)\cup(1, +\infty)$$ I deleted $(2)$ because it's included in the $(3)$. The $(1)$ is verified for all $x$ because it's an exponential and because I set up the $(3)$ To solve $(3)$ I made the $\vee$ between $x-1<0$ and $x-1>0$. The $(4)$ is verfied for all $x$ because the range of $\cosh(x)$ is $[1;+\infty)$, so it's always greater or equal than $1$. So, is it correct? Or I was wrong something?",['functions']
105080,Equivalence of continuity definitions [duplicate],This question already has answers here : How is the epsilon-delta definition of continuity equivalent to the following statement? (4 answers) Closed 3 years ago . How to show that $(1)\Longleftrightarrow (2)$ in metric spaces ? pre-image of open sets are open $\delta$-$\epsilon$ definition of continuity,"['general-topology', 'continuity', 'metric-spaces']"
105094,A question concerning Borel measurability and monotone functions,"I came across the following exercise in my self-study: If $f: \mathbb{R} \rightarrow \mathbb{R}$ is monotone, then $f$ is Borel measurable. I am unsure about how to proceed from the hypothesis to give the requisite proof, in particular how sensitive I should be to proof by cases. Would anyone visiting have any suggestions, or be up for proving this interesting little result?",['measure-theory']
105097,Groups of units of $\mathbb{Z}\left[\frac{1+\sqrt{-3}}{2}\right]$,"On page 230 of Dummit and Foote's Abstract Algebra, they say: the units of $\mathbb{Z}\left[\frac{1+\sqrt{-3}}{2}\right]$ are determined by the integers $a,b$ with $a^2+ab+b^2=\pm1$ i.e. with $(2a+b)^2+3b^2=4$, from which is is easy to see the group of units is a group of order $6$ given by $\{\pm1,\pm\rho,\pm\rho^2\}$ where $\rho=\frac{-1+\sqrt{-3}}{2}$. First, why change the characterization of unit from integers solutions of $a^2+ab+b^2=\pm1$ to integers solutions of $(2a+b)^2+3b^2=4$? How did they arrive at their answer?","['ring-theory', 'algebraic-number-theory', 'abstract-algebra']"
105105,How smooth is a smooth function?,"Let's say a smooth function is a $\mathcal{C}^\infty$ function on $\mathbb{R}$. Some smooth functions are not analytic, the most notorious example being the bump functions. A non-analytic $\mathcal{C}^\infty$ function seems (formally at least) ""less smooth"" that an analytic function, but I am wondering how one can quantify this. Looking at derivability does not give us anything (since a $\mathcal{C}^\infty$ is, well, $\mathcal{C}^\infty$), and looking at the radius of convergence of the Taylor series does not give us anything we do not already know. So, what if we look at the Fourier transform? This is a classical strategy: to quantify the smoothness of a function, quantify the integrability or the decay of its Fourier transform. Let's assume that we work in Scwhartz space $\mathcal{S} (\mathbb{R})$. Then: For any $f$ in $\mathcal{S} (\mathbb{R})$, if $\hat{f} (x) =_{\pm \infty} O (e^{-|x|^{1+\varepsilon}})$ for some $\varepsilon > 0$, then $f$ is analytic (I am not one hundred percent sure - I have not proved with utter rigour - but it seems rather safe). For all $\varepsilon > 0$, there exists a bump function $f$ such that $\hat{f} (x)$ has a magnitude of roughly(*) $e^{-|x|^{1-\varepsilon}}$ for large enough $|x|$ (again, I am not totally sure, but I think this is what is said in http://math.mit.edu/~stevenj/bump-saddle.pdf ). So I have two questions: Are there analytic functions $f$ in $\mathcal{S} (\mathbb{R})$ such that $\hat{f} (x)$ has a magnitude of roughly $e^{-|x|^{1-\varepsilon}}$ for some $\varepsilon > 0$ ? If it where not the case, and provided what I said before is true, then we would know that functions whose Fourier transform is of order $e^{-|x|^{1-\varepsilon}}$ are $\mathcal{C}^\infty$ but not analytic, and that functions whose Fourier transform is of order $e^{-|x|^{1+\varepsilon}}$ are analytic. What about intermediate growth rates, for instance when $\hat{f} (x)$ has a magnitude of roughly $e^{-C|x|}$? Of course, any more precise criterion or any related reference is welcome. (*) To be more precise : $\limsup_{x \to \pm \infty} \frac{-\ln |\hat{f} (x)|}{|x|^{1-\varepsilon}} = 1$.","['fourier-analysis', 'analysis']"
105107,"Prove: $\int_0^\infty \sin (x^2) \, dx$ converges.","$\sin x^2$ does not converge as $x \to \infty$, yet its integral from $0$ to $\infty$ does. I'm trying to understand why and would like some help in working towards a formal proof.","['improper-integrals', 'calculus', 'integration']"
105112,Weierstrass $\wp$ function doubly periodic,"I'm working my way through Silverman and Tate's Undergraduate Introduction to Elliptic Curves.  I haven't yet been able to study complex analysis, so it comes as no surprise that I'm having a tough time with that portion of the book right now. Let $\omega_1, \omega_2 \in \mathbb{C}$ be two complex numbers which are $\mathbb{R}$-linearly independent and let:
$$L = \mathbb{Z}\omega_1 + \mathbb{Z}\omega_2 = \{n_1\omega_1 + n_2\omega_2 : n_1, n_2 \in \mathbb{Z}\}$$
Let 
$\wp(u) = \frac{1}{u^2} + \sum\limits_{\omega \in L, \omega \neq 0} \left(\frac{1}{(u-\omega)^2} - \frac{1}{\omega^2}\right)$ 
Show that $\wp$ is a doubly periodic function, that is, show that 
$$\wp(u + \omega) = \wp(u)$$ If you are able, please give me a shove in the right direction.  Thank you! Dear Answerers: Thank you, I have been able to figure it out.  Yes, convergence was quite tricky and I was trying to make this particular question much more difficult than it actually was.  Thank you!","['elliptic-functions', 'special-functions', 'elliptic-curves', 'complex-analysis']"
105113,linear maps $\mathbb{R} \to \mathbb{R}$ are bijective or zero,"Proof that every linear map $\phi: \mathbb{R} \to \mathbb{R}$ is bijective or zero. It's not true for $\mathbb{R}^n, n \geq 2$, but how to proof/argue that it is true for $\mathbb{R} \to \mathbb{R}$?","['linear-algebra', 'functions']"
105117,What makes random variables exchangeable and what is implied by exchangeability?,"Consider a $d$-dimensional random vector$\ X=(X_j)$. $\ X$ is called exchangeable if $\ (X_1,\ldots,X_d)\mathrel{\overset d =} ({X_{{j_1}}},\ldots,X_{j_d})$ for any permutation$\ j_1,\ldots, j_d$. If$\ X_j$ are iid,$\ X$ is exchangeable. The converse is false (correct me if I'm wrong). What can we say about just identically distributed $\ X_j$? What can we say about $\ X_j$ if we know that$\ X$ is exchangeable?",['probability']
105133,The group of permutations with almost all points fixed is a maximal normal subgroup of the symmetric group.,"Let $X$ be an infinite set and let $\operatorname{Sym}(X)$ be the symmetric group of $X.$ Let $N$ denote the set of all permutations $\pi\in\operatorname{Sym}(X),$ such that the complement of the set of fixed points of $\pi$ has cardinality strictly less than $\operatorname{card}(X).$ A theorem of Baer is cited in a paper I'm trying to read, which says or implies that $N\lhd \operatorname{Sym}(X)$ and is maximal in the family of normal subgroups of $\operatorname{Sym}(X).$ Baer's paper is in German so I cannot read it. I don't have much trouble with the fact that $N\lhd \operatorname{Sym}(X),$ but the maximality eludes me. Could you please help me with it? If anyone's interested, the cited paper is Baer, R., Die Kompositionsreihe der Gruppe aller eineindeutigen Abbildungen einer unendlichen Menge auf sich , Studia Math. 5 (1934), 15–17.","['set-theory', 'cardinals', 'group-theory', 'symmetric-groups']"
105143,"Three equations (almost linear), five unknowns, solve for three variables.","This problem doesn't seem to make sense to me. I have the following three equations: $$
S\alpha+1.06\beta + \mathcal{F} = S\\
T\alpha+1.06\beta + \mathcal{F} = T\\
98\alpha+\beta + 0\mathcal{F} = 0
$$ where $S,T,\alpha,\beta, \mathcal{F}$ are all unknown, but $S \neq T$, and the question asks me to solve for $\mathcal{F}$. Immediately I think, ""this must be a mistake, there isn't enough information."" However, substituting this into Mathematica yields $$
(\alpha, \beta, \mathcal{F}) = (1,-98,103.88).
$$ How is this possible?, I would think that the solution space would be very large with so many free variables. Especially since the first two equations seem like duplicates.",['algebra-precalculus']
105144,Doubts about a Proof regarding decomposition,"Let $\mu$ be a signed measure. I want to prove the following: (1) If $A$ is a positive set for $\mu$, then $\mu(A)=|\mu(A)|$. (2) If $A$ is a negative set for $\mu$, then $\mu(A)=-|\mu(A)|$. This is what I have done: From $\mu^+ = \frac{1}{2}(|\mu|+\mu)$, I get that $2\mu^+(A)-\mu(A)=|\mu(A)|$. Similarly, from $\mu^-=\frac{1}{2}(|\mu|-\mu)$, I get $2\mu^-(A)+\mu(A)=|\mu(A)$. My questions are the following: Can I say that $\mu^+(A)=\mu(A)$, and $\mu^-(A)=-\mu(A)$, since $A$ is positive in the first case and negative in the second?   If so, how can I prove them?","['measure-theory', 'real-analysis']"
105164,Are intermediate rings of finitely generated ring extensions also finitely generated?,"It's well known that if $K$ is a finitely generated extension of some field $E$, then any intermediate field $F$, $E\subseteq F\subseteq K$, is also finitely generated over $E$. I'm curious, does the same hold for rings? Say $S$ is a ring, and $R\supset S$ is a finitely generated extension of $S$. If $T$ is any intermediate ring, is it necessarily true that $T$ is finitely generated over $S$ as a ring? Is it as simple as saying that for any $t\in T$, $T$ can be generated by the generators of $R$ over $S$? I feel unsure about this statement, since it's not clear to me that the generators of $R$ over $S$ need be in $T$. If not, what is an example what shows otherwise? Thanks.","['ring-theory', 'abstract-algebra']"
105186,Supremums of measurable functions,"According to my textbook, supremums of measurable functions exist and are measurable.  But what about the sequence of functions $f_n: [0, 1] \to \mathbb{R}$ given by $f_n = n$?  I don't think this sequence has a supremum but I do think all those functions are measurable.  How can I reconcile this difference? Thank you!",['analysis']
105220,Generalizing the trick for integrating $\int_{-\infty}^\infty e^{-x^2}\mathrm dx$?,"There is a well-known trick for integrating $\int_{-\infty}^\infty e^{-x^2}\mathrm dx$, which is to write it as $\sqrt{\int_{-\infty}^\infty e^{-x^2}\mathrm dx\int_{-\infty}^\infty e^{-y^2}\mathrm dy}$, which can then be reexpressed in polar coordinates as an easy integral. Is this trick a one-hit wonder, or are there other cases where this trick works and is also necessary? It seems to depend on the defining property of the exponential function that $f(a+b)=f(a)f(b)$, which would make me think that it would only allow fairly trivial generalizations, e.g., to $\int_{-\infty}^\infty 7^{-x^2}\mathrm dx$ or $\int_{-\infty}^\infty a^{bx^2+cx+d}\mathrm dx$. Can it be adapted through rotation in the complex plane to do integrals like $\int_{-\infty}^\infty \sin(x^2)\mathrm dx$? Here I find myself confused by trying to simultaneously visualize both the complex plane and the $(x,y)$ plane. WP http://en.wikipedia.org/wiki/Gaussian_integral discusses integrals that have a similar form and seem to require different methods, but I'd be more interested in integrals that have different forms but can be conquered by the same trick. The trick involves expanding from 1 dimension to 2. Is there a useful generalization where you expand from $m$ dimensions to $n$? This is not homework.","['improper-integrals', 'calculus', 'integration']"
105221,Analog to the primitive element theorem for transcendental extensions?,"The Primitive Element Theorem states that if $E/F$ is a finite separable field extension, then there exists an element $a$ such that $E=F(a)$. There's a similar result I found, that I don't quite fully understand. For instance, let $F$ be a field and $F[a_1,\dots,a_n]$ be a finite separable extension. Suppose also that $F_u=F(u_1,\dots,u_n)$ is a purely transcendental extension of $F$, with $u_1,\dots,u_n$ algebraically independent over $F$. Why is it true that $F_u[a_1,\dots,a_n]=F_u[u_1a_1+\cdots+u_na_n]$? I get that $u_1a_1+\cdots+u_na_n\in F_u[a_1,\dots,a_n]$, and so $F_u[u_1a_1+\cdots+u_na_n]\subseteq F_u[a_1,\dots,a_n]$. However, why is the converse true? I tried reproducing the argument for the primitive element theorem without success. Thank you. Since the $u_i$ are algebraically independent over $F$, and $F_u[a_1,\dots,a_n]$ is finitely generated over $F_u$, I was trying to use the corollary Bill Cook pointed me to, to conclude that by setting $y_1=\sum_{j=1}^n u_ja_j$, then $F_u[a_1,\dots,a_n]$ is integral over $F_u[y_1]$. From this can I conclude the equality? I wary of how to proceed, as I do not know where separability comes into use.","['abstract-algebra', 'field-theory']"
105231,Show that there is no affine transformation that takes a circle to a hyperbola in $\mathbb{R}^2$,"""Show that the standard circle (defined by $f(x,y) = x^2 + y^2 - 1$) is not equivalent to the standard hyperbola (defined by $g(x,y) = x^2 - y^2 - 1$). That is, show that there is no $[A,\overline{s}] \in \text{Aff}(\mathbb{R}^2)$ such that $[A,\overline{s}] \cdot f(x,y) = g(x,y)$. Check that there is such an $[A,\overline{s}]$ if we allow $A \in \text{GL}_2(\mathbb{C}).$"" I've reduced this to showing that there are no $a,b,c,d,s,t \in \mathbb{R}$ such that $$f(ax+as+by+bt,\: cx + cs + dy+dt) = g(x,y).$$
$$\Rightarrow(ax+as+by+bt)^2+(cx + cs + dy+dt)^2 - 1=x^2-y^2-1$$
How should I proceed? Expanding that expression probably isn't the best way to do it.","['algebraic-geometry', 'conic-sections']"
105244,Does the logistic function really uniquely satisfy this?,It is said that the logistic function (denoted $y(u)$ below) is derived from the relation: $$\frac{dy}{du}=y(u)(1-y(u))$$ Does $y(u)=\frac{1}{1+e^{-u}}$ really uniquely satisfy this?  I don't see how.  It seems to me there must be several functions that can satisfy that.  Please help me to see the light. If I am permitted a follow-up question: What do I have to do to the first equation so that $$y(u)=\frac{1}{1+u^{-2}}$$ satsifies it? Thanks,"['logarithms', 'calculus', 'algebra-precalculus']"
105245,"For an analytic function $f(z)$, $|f(z)^2-1|<1$ implies $\Re f(z)>0$ or $\Re f(z)<0$?","Doing a bit of self study, and I'm unsure about a problem. It says, Suppose $f(z)$ (a complex valued function) is analytic and satisfies the condition $|f(z)^2-1|<1$ in a region $\Omega$. Show that either $\Re f(z)>0$ or $\Re f(z)<0$ throughout $\Omega$. I write $f=u+iv$ and suppose to the contrary that $\Re f(z)=0$ at some point $z_0$. Then $f(z_0)^2=-v(z_0)^2$. But $v$ is real valued, and so
$$
|f(z_0)^2-1|=|-v(z_0)^2-1|\geq 1
$$
a contradiction. What makes me uneasy is I don't see if I used that fact that $f$ is analytic. Did I interpret the question correctly, or did it mean that $\Re f(z)>0$ on all of $\Omega$ or $\Re f(z)<0$ on all of $\Omega$, but doesn't take both positive and negative values? Thanks.",['complex-analysis']
105256,another form of the L'Hospital's rule,"I need some help, any Ideas? in L'Hospital's rule, replace the assumption that $\frac{f}{g}$ tends to $\frac{0}{0}$ with the assumption that it tends to $\frac{\infty}{\infty}$. if $\frac{f'}{g'}$ tends to $L$. prove that $\frac{f}{g}$ tends to $L$ also.","['real-analysis', 'limits']"
105258,integral involving a periodic function,"Let $f:[0,1] \longrightarrow \mathbb R$ be a continuous function, and let $g:\mathbb R \longrightarrow \mathbb R$ be a continuous and periodic function with period $1$. Prove that $\displaystyle\lim_{n\to \infty}\int_0^1f(x)g(nx)dx=\left(\int_0^1f(x)dx\right)\left(\int_0^1g(x)dx\right)$. any Ideas?","['real-analysis', 'limits']"
105264,$3D$ rotation matrix uniqueness,Given a $3D$ rotation matrix $R$ in a basis $B$. Can we consider $R$ as being unique in $B$? Is there any other $3D$ rotation matrix $R'$ representing the same $3D$ rotation in $B$? How could I prove that? Note: I do not consider the rotation matrix $R'$ with inverted axis and angle as being the same as $R$.,"['matrices', '3d', 'rotations']"
105276,Differential equations and Fourier and Laplace transforms,"Why do both the Fourier transform and the Laplace transform appear in the study of differential equations? I've never understood why there are some situations where the Fourier transform is used and some other situations where the Laplace transform is used instead. Edit: In response to the comments. I would like to hear an answer in the context of pure mathematics. For example, I hear that the Fourier transform is very very useful in the theory of partial differential equations because it transforms a PDE into an algebraic equation. However, I don't hear about the Laplace transform being so useful in pure mathematics.","['ordinary-differential-equations', 'laplace-transform', 'fourier-analysis', 'operator-theory', 'intuition']"
105282,linearly arranging the group tables of groups of order 128,I'm planning to make a video that shows color coded group tables for all 2328 groups of order 128 -- at 128$\times$128 pixels at 24 frames a second I think I get 97 seconds of video. Is there some logical order that the all these groups can be placed in that would make the most visual sense? It's done! Here: http://www.youtube.com/watch?v=25Qzu-KuVs4,"['group-theory', 'visualization']"
105285,The most common theorems taught in Abstract Algebra,"I am self learning abstract algebra. I want to know which theorems are a must to understand. Now these are limits I have to deal with (please consider when answering): I have limited internet access Few mathematical books written in English are available. I can not afford to order books from abroad． I just want to know what is the core knowledge (theorems, lemmas, etc) of any decent graduate level abstract algebra class.","['soft-question', 'learning', 'abstract-algebra']"
105300,Probability of All Distinct Faces When Six Dice Are Rolled,If six fair dice are rolled what is probability that each of the six numbers will appear exactly once?,"['dice', 'probability']"
105310,"Is an increasing, bounded and continuous function on $[a,+\infty)$ uniformly continuous?","Supose $f$ is increasing, bounded and continuous on $[a,+\infty)$. Is  $f$ uniformly continuous ? I think yes. how to prove that? My idea is to show there exists $X$ , $f$ is uniformly continuous on $[X,+\infty)$. How to fix such $X$?","['calculus', 'real-analysis']"
105330,Equilateral triangle whose vertices are lattice points?,"Is it possible to construct an equilateral triangle with vertices on lattice points? I think the answer is no, but how can I prove this? I started with a triangle with coordinates $(0,0)$ $(a,b)$ and $(c,d)$.
Equating the size of the 3 sides, I get $a^{2}+b^{2}=c^{2}+d^{2}=2ab+2cd$ How should I continue? I see there are solutions based on the fact that the angle between two edges can not be 60°. Is it possible to have a solution based on the fact that the length of the edges can not be the same?","['geometry', 'elementary-number-theory']"
105333,The set of diffeomorphisms preserving some metric.,"Let $M$ be a finite-dimensional, smooth manifold. Call a diffeomorphism $f : M \rightarrow M$ diagonalizable if there exists a Riemannian metric $g$ on $M$ such that $f : (M, g) \rightarrow (M, g)$ is an isometry. I have some questions regarding such objects. a) Is the set Diag(M) of all diagonalizable diffeomorphisms a group under composition? b) Note that, in order to be diagonalizable, a diffeomorphism must possess the following well-known property of isometries: $$\text{If}~f(p) = p~\text{and}~df(p) = \mathrm{Id}_{T_pM}, \text{for some $p \in M$, then}~f = \mathrm{Id}_M. (*)$$ Is $(*)$ also a sufficient condition? In other words, given a diffeomorphism $f \in \mathrm{Diff}(M)$ satisfying $(*)$, is there a Riemannian metric for which $f$ is an isometry? Maybe this is too general, because any diffeomorphism not fixing any point satisfies $(*)$, but I don't know the answer. My motivation here is to know how large is the set of diffeomorphisms that could be isometries within the set of all diffeomorphisms. I apologize if I'm missing some standard notation and/or vocabulary here. I'd appreciate, as always, any references. Thanks in advance.","['riemannian-geometry', 'differential-geometry', 'analysis']"
105336,How to define the sign of a function,"$$y=\arctan\frac{x+1}{x-3} + \frac{x}{4}$$
I know that is necessary to put the function $>$ than $0$, but then?
$$\arctan\frac{x+1}{x-3} + \frac{x}{4}>0$$
It's a sum, so I can't set up a ""false system"" putting the two factors $>0$. In this case which is the rule to study the sign of this function? Note: These are not homeworks.","['inequality', 'functions']"
105337,Explanations of Lebesgue number lemma,"From Planetmath : Lebesgue number lemma: For every open cover $\mathcal{U}$ of a compact metric space $X$, there exists a real number $\delta > 0$ such
  that every open ball in $X$ of radius $\delta$ is contained in some
  element of $\mathcal{U}$. Any number $\delta$ satisfying the property above is called a Lebesgue number for the covering $\mathcal{U}$ in $X$. I feel hard to picture and understand the significance of this result. I was wondering if there are some explanation for this lemma? Intuitively, a number bigger or smaller than a Lebesgue number may not be a
Lebesgue number. So is a Lebesgue number simultaneously measuring
how separated open subsets in an open cover are between each other,
and how big each of them is? how is a metric space being compact make the existence of a Lebesgue
number possible? Added: Is the lemma equivalent to say that for any open cover, there
exist a positive number $\delta$, s.t. any open cover consisting of
open balls with radius $\delta$ is always a refinement of the
original open cover? Thanks and regards!","['general-topology', 'metric-spaces']"
105348,Showing $\prod\limits_{i<j} \frac{x_i-x_j}{i-j}$ is an integer,"Let $x_1,...,x_n$ be distinct integers. Prove that $$\prod_{i<j} \frac{x_i-x_j}{i-j}\in \mathbb Z$$ I know there is a solution using determinant of a matrix, but I can't remember it now. Any help will be appreciated.","['matrices', 'determinant', 'number-theory']"
105351,Is there a classic Matrix Algebra reference?,"I'm looking for a classic matrix algebra reference, either introductory or advanced. In fact, I'm looking for ways to factorize elements of a matrix, and its appropriate determinant implications. Your help is greatly appreciated.","['matrices', 'linear-algebra', 'reference-request']"
105354,Existence of Saddle Point,"Consider a function $g$ with the following properties. It is smooth. $g > 0$. $g \to 0$ at infinity. It has at least two critical points. There are finitely many critical points. Each critical point is isolated. Thanks to the answer below , I am going to add one additional restriction on $g$. $g$ is a rational function. I am adding yet another condition after seeing an edit below. Each critical point of $g$ is non-degenerate; that is, if $x$ is a critical point then $\det g''(x) \neq 0$. In the example below , the critical point that is not a saddle has a zero eigenvalue and hence the determinant is zero. Notice at least one of the critical points has to be a local max. The question is: does $g$ have a saddle point? In particular, for $g \colon \mathbb{R}^n \to \mathbb{R}$, does $g$ have a critical point of index $n-1$? If there is a reference you can point me to that would be terrific. I believe a variant of the Mountain Pass Theorem may work...","['geometry', 'multivariable-calculus']"
105355,Help in understanding the properties of prime numbers,"I was reading about hashing. The oldest/standard approach is to use a prime number to produce the hash. At first I couldn't get why use a prime when I came to this Why hash functions use primes : Primes are unique numbers. They are unique in that, the product of a
  prime with any other number has the best chance of being unique (not
  as unique as the prime itself of-course) due to the fact that a prime
  is used to compose it. This property is used in hashing functions. I am not sure I get completely the concept here. Does it mean that multiplying a*b and c*d the posibility to produce the same result is smaller if one of these numbers e.g. a is a prime? I was wondering how is this proven in an intuitive manner? I mean I can understand abstractly the idea but can not formulate something intuitive to base the whole hashing upon this possibility as a property of primes. Any help? UPDATE: Just to be clear: My main problem was why the prime numbers have always been the standard approach for use in a hash function. An ideal hash function rarely has colisions due to the fact that it produces ""unique"" hash values of its input. The blog I mention in the post seemed to give an explanation in my problem. But if the blog is not correct then I still end up in my original problem. What is the property of prime numbers (I am not refering to 31 because other primes have been used for hashing) that makes them a must for a hash function. Also this is I guess also related to the fact that the table of the hashtable must be of prime size?","['elementary-number-theory', 'hash-function', 'algebra-precalculus', 'prime-numbers']"
105364,"$(\cos \alpha, \sin \alpha)$ - possible value pairs","We introduced the complex numbers as elements of $ \mathrm{Mat}(2\times 2, \mathbb{R})$ with $$
\mathbb{C} \ni x =
\left(\begin{array}{cc}
a & -b \\
b & a \\
\end{array}\right) =
\frac{1}{\sqrt{a^2+b^2}}
\left(\begin{array}{cc}
\frac{a}{\sqrt{a^2+b^2}} & \frac{-b}{\sqrt{a^2+b^2}} \\
\frac{b}{\sqrt{a^2+b^2}} & \frac{a}{\sqrt{a^2+b^2}} \\
\end{array}\right)
$$ Then we concluded that $0 \leq \frac{a}{\sqrt{a^2+b^2}} \leq 1$ and $0 \leq \frac{b}{\sqrt{a^2+b^2}} \leq 1$ and therefore we could find an $\alpha$ so that $\cos \alpha = \frac{a}{\sqrt{a^2+b^2}}$ and $\sin \alpha = \frac{b}{\sqrt{a^2+b^2}}$. Then we can write the matrix with $\cos$ and $\sin$ and can write it as the Euler form as well. So far so good. My question ist about the following: Why is it that we cand find an $\alpha$ so that $\cos \alpha = \frac{a}{\sqrt{a^2+b^2}}$ and $\sin \alpha = \frac{b}{\sqrt{a^2+b^2}}$ for every possible value combination of $a$ and $b$ ?
Can't be there a combination of $a$ and $b$ where we can't find one and the same angle $\alpha$ so that the identites are true?","['trigonometry', 'complex-numbers']"
105365,An equivalence relation on regions of the plane.,"Let $R\subseteq\mathbb{R}^2$. Consider the set of all ""horizontal sections"" $H_R =${$Rb|b\in\mathbb{R}$}, where $Rb=${$a\in\mathbb{R} | (a,b)\in R$}. Similarly consider the set of ""vertical sections"" of $R$, $V_R =${$ aR|a\in\mathbb{R}$} where $aR=${$ b\in\mathbb{R} | (a,b)\in R$}.  Now define the equivalence relation on $\wp (\mathbb{R^2})$ such that $R \sim S$ if, and only if, $H_R=H_S$ and $V_R=V_S$. QUESTION: What is the equivalence class of a disk?","['analytic-geometry', 'geometry', 'elementary-set-theory']"
105378,Prove: $\lim _{x \to \infty}\sum_{1}^{\infty}\frac{x^2}{1+n^2x^2}=\sum_{1}^{\infty}\frac{1}{n^2}$,"I want to ask you if can it be so simple to prove that $\lim _{x \to \infty}\sum_{1}^{\infty}\frac{x^2}{1+n^2x^2}=\sum_{1}^{\infty}\frac{1}{n^2}$ by divide the numerator and denominator with $x^2$ and that's it? If it this simple indeed you can write a comment and I'll delete the question after I'll read it, or perhaps I'm missing something important (and I should involve power series). Thanks!",['calculus']
105383,What volume does $2x \le x^2+y^2+z^2 \le 4x$ represent?,"I'm evaluating $\iiint_V f(x,y,z) dV$ where V is defined by $$2x \le x^2+y^2+z^2 \le 4x $$ To simplify things I swapped x and z, and moved to spherical coordinates: $$ 0 \le \theta \le 2\pi, 2 \cos \phi \le \rho \le 4 \cos \phi$$ and as the last condition implies $ 4 \cos \phi \ge \rho \ge 0$, I added $0 \le \phi \le \pi/2$ The point is: I have no idea if this parametrization is correct, because I can't figure what that disequations represents. From the spherical parametrization it looks like some paraboloid but I'm confused. Could you help in this? And how do I approach such ""confused"" situations? thanks.","['analytic-geometry', 'multivariable-calculus']"
105394,Series with increasing factor inside the summation,"I have a simple question. While doing geometric series: 
$$\sum_{i=1}^\infty ar^i = \frac{a}{1-r}.$$ But what if I have something like $\sum_{i=1}^\infty iar^{i-1}$? I think its geometric series, please correct me if I am wrong!",['sequences-and-series']
105402,"Quick ways to _verify_ determinant, minimal polynomial, characteristic polynomial, eigenvalues, eigenvectors ...","What are easy and quick ways to verify determinant, minimal polynomial, characteristic polynomial, eigenvalues, eigenvectors after calculating them? So if I calculated determinant, minimal polynomial, characteristic polynomial, eigenvalues, eigenvectors, what are ways to be sure that I didn't do a major mistake? I don't want to verify my solutions all the way through, I just want a quick way which gives me that it is highly likely that the calculated determinant is right etc. Let $A$ be a matrix $A \in \operatorname{Mat}(n, \mathbb{C})$, let $\det(A)$ be the determinant of matrix $A$, let $v_1, v_2, ..., v_k$ be eigenvectors of matrix $A$, let $\lambda_1, \lambda_2, ..., \lambda_n$ be eigenvalues of matrix $A$, let $\chi_A(t) = t^n + a_{n-1}t^{n-1}+\cdots + a_0 = (t-\lambda_1)\cdots(t-\lambda_n)$ be the characteristic polynomial of matrix $A$, let $\mu_A(t)$ be the minimal polynomial of matrix $A$. Verifications suggested so far: eigenvectors / eigenvalues $\det(A) = \lambda_1^{m_1} \lambda_2^{m_2} \cdots \lambda_n^{m_l}$ where $m_i$ is the multiplicity of the corresponding eigenvalue $a_0 = (-1)^n\lambda_1\cdots\lambda_n$ eigenvectors can be verified by multiplying with the matrix; the eigenvalues can be verified at the same time; i.e. $A v_i = \lambda_i v_i$ determinant $\det(A) = \lambda_1^{m_1} \lambda_2^{m_2} \cdots \lambda_l^{m_l}$ where $m_i$ is the multiplicity of the corresponding eigenvalue characteristic / minimal polynomial $a_0 = (-1)^n\lambda_1\cdots\lambda_n$ $\mu_A(A) = 0$ and $\chi_A(A) = 0$ $\mu_A(t) \mid \chi_A(t)$","['eigenvalues-eigenvectors', 'polynomials', 'matrices', 'linear-algebra', 'determinant']"
105412,How can I show that $\sum\limits_{n=1}^\infty \frac{z^{2^n}}{1-z^{2^{n+1}}}$ is algebraic?,"Show that $$\sum_{n=1}^\infty \frac{z^{2^n}}{1-z^{2^{n+1}}}$$ is algebraic. More specifically, solve this and get exact values. Then use the result to evaluate $$\sum_{n=0}^\infty \frac{1}{F_{2^n}}$$ where $$F_n=\frac{\alpha^n-\beta^n}{\alpha-\beta}$$  and $\alpha=\frac{1+\sqrt{5}}{2}$  and $\beta=\frac{1-\sqrt{5}}{2}$.","['fibonacci-numbers', 'sequences-and-series']"
105433,Does every set have a group structure?,I know that there is no vector space having precisely $6$ elements. Does every set have a group structure?,"['set-theory', 'group-theory', 'axiom-of-choice']"
105438,How many associative binary operations there are on a finite set?,"I am studying Scott's book Group Theory . In the Exercise $1.1.17$ he asks us to show that if $S$ is a set and $|S|=n$, then there are $n^{\frac{n^{2}+n}{2}}$ commutative binary operations on $S$. But he doesn't talk about how many associative binary operations there are on a finite set. Is there an answer to that question? I mean, how many associative binary operations there are on a finite set?","['semigroups', 'group-theory']"
105441,Convex hull of $n$-gon and $m$-gon,"Suppose you have a convex $n$-gon, and a convex $m$-gon, in the plane.  Take the
convex hull of the $n+m$ vertices.  How many combinatorially distinct hulls can be obtained,
where two hulls are combinatorially distinct if, with the vertices labeled
$a_i$, $i=1,\ldots,n$ and $b_j$, $j=1,\ldots,m$, any two cyclicly distinct strings of labels are considered distinct?  Below the hulls are $(a_1,b_1,a_2,b_2,a_3,b_3)$
and $(a_1,a_2,b_2,b_3)$. I realize this is elementary...","['discrete-geometry', 'combinatorics']"
105451,Orthonormal basis for product $L^2$ space,"Let $(X,\mu)$ and $(Y,\nu)$ be $\sigma$ -finite measure spaces such that $L^2(X)$ and $L^2(Y)$ . Let $\{f_n\}$ be an orthonormal basis for $L^2(X)$ and let $\{g_m\}$ be an orthonormal basis for $L^2(Y)$ . I am trying to show that $\{f_n g_m\}$ is an orthonormal basis for $L^2(X\times Y)$ . So far, I have attempted to show that if $h\in L^2(X\times Y)$ , then \begin{align}
h(x,y) &= \sum_m \sum_n \langle h , f_n g_m\rangle\,f_mg_m \\[0.3cm]
&= \sum_m \sum_n \left(\int_X \int_Y h(r,s) f_n(r)g_m(s) d\nu(s) d\mu(r)\right) f_n(x)g_m(y).\end{align} Using the fact that $x\mapsto h(x,y) \in L^2(X)$ for almost every $y$ and similarly for $y\mapsto h(x,y)$ , I can obtain $h(x,y) = \sum_{m=1} ^\infty (\int_X [\sum_{n=1} ^\infty (\int_Y h(r,s)g_n(s) d\nu(s))  f_m(r)] d\mu(r))  f_m(x)g_n(y)$ . However, I am unable to justify passing the summation outside the integral. Any suggestions?","['measure-theory', 'hilbert-spaces']"
105452,Zeroes of the third derivative of an iterated sine.,"I've been playing with the functions $$f_n:[0,\pi/2]\to[0,1]\\\begin{cases} f_1&=&\sin\\f_{n+1}&=&\sin\circ f_n\end{cases}.$$ A simple argument proves that $f_n(x)\to 0$ for $x\in [0,\pi/2].$ I thought it was interesting, though, how the functions did that. Near $0,$ we have $\sin\approx \operatorname{id},$ so near $0,$ iterating the sine should be close to iterating the identity function. I wanted to see what happens near zero that the function $f_n$ stops behaving like the identity function and starts behaving so as to allow the convergence of the sequence to zero. I've plotted some iterations and it looks like the functions get ""broken"" near zero. The point of the ""breaking"" seems to go to zero as $n$ goes to infinity. And the ""break"" seems to get more and more ""severe"". I'll post some graphs of the following ""normalized"" functions: $$g_n:[0,\pi/2]\to[0,1]\\g_n=\frac{f_n}{f_n(\pi/2)}$$ These functions approximate the indicator function of the domain. (I've actually seen a proof of this. My teacher showed me when I asked him, but I've already forgotten it. I remember it involved the Stolz–Cesàro theorem.) As you can see, there are points when the functions slow down abruptly. I believe the point where it happens should be the unique zero of the third derivative of $g_n.$ It is easy to see that the first derivatives of the functions are all positive and the second derivatives are all negative. However, writing down a general formula for the third derivative is difficult. I've tried doing it despite the length, but I realized that even if I finish doing it, I'll never see anything in such a long formula. So my question is: can you see a way of proving that the third derivative of $g_n$ has a unique zero in $(0,\pi/2)$ for $n>1?$ And if so, that those zeroes converge to zero as $n\to \infty?$ EDIT: I still don't know how to prove it, but my interpretation of the pictures has changed on further reflection. It seems to me that I was wrong, and the points I'm asking about are not the zeroes of the third derivatives, but their minima (zeroes of the fourth derivatives). They are points were the speed of deceleration is the greatest, not the points where the speed of deceleration is zero. This means that there is more to prove apparently. I'm still unable to handle the third derivatives of these functions, so I can't prove that the third derivatives are negative, which I now think is true. But I can't even dream of trying to write down the formula of the fourth derivative and equate it to zero to find out something about the points. $g_1$ $g_{10}$ $g_{200}$ $g_{1000}$ $g_{10000}$ $g_{100000}$","['recurrence-relations', 'sequences-and-series', 'trigonometry', 'real-analysis', 'derivatives']"
105455,How can a probability density be greater than one and integrate to one,"Wikipedia says: The probability density function is nonnegative everywhere, and its integral over the entire space is equal to one. and it also says. Unlike a probability, a probability density function can take on values greater than one; for example, the uniform distribution on the interval $[0, \frac{1}{2}]$ has probability density $f(x) = 2$ for $0 ≤ x ≤ \frac{1}{2}$ and $f(x) = 0$ elsewhere. How are these two things compatible?","['probability-distributions', 'probability', 'integration']"
105471,Why are characteristic classes well-defined?,"In the definition of characteristic classes for a complex vector bundle $E$ ober a topological space $X$, we consider some space $X_S$ and a continuous map $p: X \rightarrow X'$ such that $E$ is the pullback of some vector bundle $F$ over $X'$ and $F$ splits as the sum of some line bundles $F_1,..., F_n$ over $X'$. Then for some formal power series $f$ one considers $f(c_1(F_1))\cdot...\cdot f(c_1(F_n))$ and pulls this back to $X$ to get a characteristic class. My question is: Why is this construction well-defined, i.e. why does it not depend on the choice of $X'$ and $p$?","['characteristic-classes', 'algebraic-topology', 'differential-geometry']"
105476,Remember trig identities like $\cos(\pi/3) = 1/2$,"I have started doing complex analysis and I keep having to switch between rectangular co-ordinates and polar form and I keep running into stuff like -  $\cos(\pi/3) = 1/2$.
I keep having to look these up. Am I expected to memorize these or what, its getting to be a serious pain having to keep looking them up. Do people generally just memorize these identities for complex analysis?","['trigonometry', 'complex-analysis']"
105480,Nilpotent elements of a non-commutative ring with trivial automorphism group form an ideal,Let $R$ be a non-commutative ring with identity such that the identity map is the only ring automorphism of $R$. Prove that the set $N$ of all nilpotent elements of $R$ is an ideal of $R$.,"['noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
105490,Isomorphisms Between a Finite-Dimensional Vector Space and its Dual,"So, we know that there is no ""natural"" isomorphism between a finite dimensional vector space $X$ and its dual $X^{\vee}$. However, given a basis for $X$ $(e_1, \dots, e_n)$ we can always construct a (dual) basis $(e^1, \dots, e^n)$ for $X^{\vee}$ that satisfies $e^i(e_j) = \delta^i_j$. It follows that $V \approx V^{\vee}$ simply because they have the same finite dimension $n$. Now, it seems to me that we can construct an isomorphism by assigning
$$
e_i \mapsto e^i
$$
and extending by linearity. That is, for an arbitrary vector $v \in X$ given by $v = \sum v^ie_i$ we can specify a linear map $$\phi:V \rightarrow V^{\vee}$$ by $$
\phi(\sum v^ie_i) := \sum v^ie^i
$$
It is a quick exercise to check that $\phi$ is an isomorphism. Now, although this construction seems correct, there is something that doesn't quite sit right with me about it. For one thing, there is no way to really make sense of the summation convention as the right side of the function will always contain two superscripts thus requiring an explicit summation sign. The other thing that feels rather off is actually taking a lower index and moving it to an upper index, i.e., $e_i \mapsto e^i$ (which, of course, is the reason that the summation convention doesn't work). So, with this background my questions are Is there any sense in which the above isomorphism is ""favored"" or ""canonical""? Is there another way to construct an isomorphism between a vector space and its dual, that would ""conserve indexes"", for lack of a better way to state it. My guess here is that the answer is no but becomes possible if one assumes $V$ has an inner product.",['linear-algebra']
105513,Cardinality of a discrete subset,"If I am correct, a discrete subset of a topological space is defined to be a subset consisting of  isolated points only. This is actually equivalent to that the subspace topology on the subset is discrete topology. There seems no restriction on the cardinality of a discrete subset, i.e. its cardinality can be any. I was wondering if the following quote from wolfram is true and
why? Typically, a discrete set is either finite or countably infinite. What kinds of topological spaces are ""typical""? Added: Is the following quote from the same link true On any reasonable space, a finite set is discrete. What kinds of topological spaces does ""reasonable"" mean? Is discrete mathematics always under the setting of discrete sets wrt
some topologies? In other words, is it a special case of topology theory? Or can it exist without topology? Thanks and regards!","['general-topology', 'discrete-mathematics']"
105520,Differentiablility of a function of two variables,"Here is a problem from an old comprehensive exam that I am trying to solve Problem: let $f:\mathbb{R}^{2} \to \mathbb{R}$ be a function defined as follows: $f\left ( x,y \right )=\frac{\left ( x^{2}-y \right ).y^{2}}{x^{4}+y^{2}}$ if  $\left ( x,y \right )\neq \left ( 0,0 \right )$ $f\left ( x,y \right )=0$ if $\left ( x,y \right )=\left ( 0,0 \right )$ The question is : Investigate the differentiability of $f$ at the point $\left ( 0,0 \right )$ Here is what I did so far:
$\frac{\partial f}{\partial x}\left ( 0,0 \right )=0  $ and $\frac{\partial f}{\partial y}\left ( 0,0 \right )=-1  $ Now I applied the condition for differentiability for $f$ at the point $\left ( 0,0 \right )$: $lim_{\left ( x,y \right ) \to \left ( 0,0 \right )}\frac{\left \| f\left ( x,y \right )-f\left ( 0,0 \right )-\bigtriangledown f\left ( 0,0 \right ).\left ( x,y \right ) \right \|}{\sqrt{x^{2}+y^{2}}}$ has to be $0$ if $f$ is differentiable at the desired point. After simplifying the above limit, I got the following limit: $lim_{\left ( x,y \right ) \to \left ( 0,0 \right ) }\frac{x^{2}y^{2}+x^{4}y}{\left ( x^{2}+y^{4} \right ).\sqrt{x^{2}+y^{2}}}$ . Here is where I am stuck. I cannot evaluate this limit. I tried everything, like evaluating the limit through different paths... but nothing seems to work out for me. Any help please on how to finish my proof?","['multivariable-calculus', 'limits', 'real-analysis', 'analysis']"
105543,Does continuous imply continuous inverse? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Functions which are Continuous, but not Bicontinuous If $f$ is a continuous map from a subset of $\mathbb{R}^n$ to another subset of $\mathbb{R}^n$, must it have a continuous inverse? (in usual topology) Is the same true of metric spaces?
When is it true/not true? Requesting example if not.",['general-topology']
105569,How to prove that the Galois group of a normal extension transitively permutes the factors of an irreducible polynomial?,"How to do the following problem? Let $K$ be a normal extension of $F$, and let $f(x)\in F[x]$ be an irreducible polynomial over $F$. Let $g(x)$
  and $p(x)$ be monic irreducible factors of $f(x)$ in $K[x]$. Prove that there is a $z\in\operatorname{Gal}(K/ F)$,
  with $z(g)=p$.","['galois-theory', 'abstract-algebra', 'field-theory']"
105582,About example of continuous function on $\mathbb{R}$ which cannot be uniformly approximated by polynomials? [duplicate],"This question already has an answer here : Closed 12 years ago . Possible Duplicate: Weierstrass approximation does not hold on the entire Real Line If a function $f: \mathbb{R}\rightarrow \mathbb{R}$ is continuous then $f$
can be uniformly approximated  by smooth functions (see here ). By the Weierstrass approximation theorem $f$ can be uniformly approximated by polynomials on each compact subinterval of $\mathbb{R}$. What is example of continuous function $f: \mathbb{R}\rightarrow \mathbb{R}$ which cannot be uniformly approximated by polynomials on the whole $\mathbb{R}$? Thanks",['analysis']
105588,Why is the trace map on an abelian variety continuous,"Let $X$ be a (EDIT) variety with a group structure. For $a\in A$, let $t_a$ be the translation on $X$: $t_a(x) = a+x$. Why is the function $f:X\to \mathbf{C}$ given by $$f(a) = \sum_{i} (-1)^i \mathrm{Tr}(t_a^\ast, H^i(X,\mathbf{C}))$$ continuous ? Here I consider the usual singular cohomology with $\mathbf{C}$-coefficients. (The coefficients don't really matter. You can even take $\mathbf{Q}_{\ell}$-coefficients and work with $\ell$-adic cohomology.) I call the function $f$ on $X$ the trace function . Note that one can use the Lefschetz trace formula to see that the image of $f$ lies in $\mathbf{Z}$.","['abelian-varieties', 'algebraic-geometry', 'algebraic-topology', 'functions', 'arithmetic-geometry']"
105593,Limitations of approximating $\sin(x) = x$,"$$\lim _{x\rightarrow 0}{\frac {\cos \left( x \right) \sin \left( x
 \right) -x}{ \left( \sin \left( x \right)  \right) ^{3}}}$$ I know that the real limit is $-2/3$
However, I've noticed that by approximating $\sin(x)$ as $x$ and $\cos(x)$ as $1-(x^2/2)$ I get the following: $(1-(x^2/2))x - x)/ x^3 = (1- (x^2/2) -1 )(1/x^2) = -x^2/(2x^2) = -1/2 $ also if I only partially approximate x like: $(x\cos(x) - x)/(x^3)$  = $(\cos(x)-1)/x^2$ and then use L'hospital's rule to chisel this down I get:
(L'hospital) = $-\sin x / 2x $ = (L'hospital) = $-\cos(x) / 2 = -1/2 $ Why does this conflict with doing L'hospital the whole way through without approximating $\sin(x)$ as $x$ ?  Why is approximating $\sin(x)^3$ as $x^3$ wrong? Isn't this always approaching zero?","['calculus', 'limits']"
105621,"Proving that the ""real part"" function is continuous","I want to use the definition of a limit,
$|f(z) - w_0| < \varepsilon$ whenever $0 < |z - z_0| < \delta$ to prove
$$\lim_{z \to z_0} \mathop{\rm Re}(z) = \mathop{\rm Re}(z_0)$$ By intuition this is obvious but I dont know how to show it using the defn. of a limit. This is question 1(a) from the book Complex Variables and Applications. Here's the basic manipulation I have made going by an example in the book, I dont know where to go from here...
$$|\mathop{\rm Re}(z)-\mathop{\rm Re}(z_0)| = |x - x_0| = |x| - |x_0| = x - x_0$$",['complex-analysis']
105633,"Prove that $a=b$, where $a$ and $b$ are elements of the integral domain $D$ [duplicate]","This question already has answers here : $a^m=b^m$ and $a^n=b^n$ imply $a=b$ [closed] (6 answers) Closed 8 years ago . Let $D$ be an integral domain and $a,~b \in D$. Suppose that  $a^n=b^n$ and $a^m=b^m$ for any two some $m,~n$ such that $(m,n)=1$. Prove that  $a=b$. I know that $ab≠0$ since $D$ contains no divisors of zero, but  I don’t have an idea as to how to prove this.","['ring-theory', 'integral-domain', 'abstract-algebra']"
105668,Why are modules called modules?,"I know that a module is a generalization of a vector space, but I would like to know why are modules called modules? Thanks for your kindly help.","['math-history', 'terminology', 'abstract-algebra']"
