question_id,title,body,tags
4718850,Arbitrarily slow convergence rate,"First I will present two definitions. Let $f:X \to X$ a continuous measurable transformation. A probability measure $\mu$ defined on the Borel sets is said to be $f$ -invariant if $\mu(f^{-1}(A)) = \mu(A)$ for every Borel set $A$ . A map $f$ is said to be mixing with respect to some $f$ -invariant probability measure $\mu$ if $$|\mu(f^{-n}(A) \cap B) - \mu(A)\mu(B)| \to 0, \qquad\text{when } n \to \infty,$$ for any measurable sets $A,B$ . A natural question that arises is the speed of mixing . In some books and articles I see some variation of the phrase:  "" It is possible to find subsets $A, B$ such that the convergence in the definition of mixing is arbitrarily slow. "" When talking about speed of mixing, I'm talking about a sequence $a(n) \downarrow 0$ , such that $$|\mu(f^{-n}(A) \cap B) - \mu(A)\mu(B)| \le Ca(n), \qquad\text{for all } n.$$ Thus, what the phrase means that if $f$ is mixing then given a sequence it is possible to find sets $A,B$ , so that the inequality above is not true for all $n$ . I haven't found a proof for this claim, just specific examples . What I managed to do was prove this statement when I use the definition of mixing with correlation function (see definition below) in $L^2$ . For this, I used the Riesz representation theorem. For the case above I couldn't prove it. I also don't know if it is necessary to make any assumptions about the space $X$ , in this case we only have $\mu(X)=1$ . I would appreciate an idea for the proof or a reference. Definition of mixing with functions: For measurable functions $\varphi,\psi : X \to \mathbb{R}$ we define the correlation function $$C_n(\varphi,\psi) =\left|\int \psi(\varphi\circ f^n)~d\mu - \int \psi ~d\mu \int \varphi~d\mu\right|.$$ We say that $f$ is mixing if $C_n(\varphi,\psi) \to 0$ as $n\to\infty$ .","['measure-theory', 'ergodic-theory', 'analysis', 'probability', 'dynamical-systems']"
4718866,Mysior plane is not realcompact,"Let $X = \mathbb{R}^2$ with $(x, y)\in X$ for $y\neq 0$ isolated and $(x, 0)$ having neighbourhood basis of the form $$U_n(x) = \{(x, y) : y\in (-1/n, 1/n)\}\cup \{(x+y+1, y) : 0 < y < 1/n\}\cup \{(x+\sqrt{2}+y, -y) : 0 < y < 1/n\}.$$ The space $X$ is called Mysior plane, and it's an example of a space which is a union of two closed subspaces, $X_+ = \mathbb{R}\times [0, \infty)$ and $X_- = \mathbb{R}\times (-\infty, 0]$ , which are realcompact, but isn't itself realcompact. Since the map $f:X_+\sqcup X_-\to X$ is perfect, this shows realcompactness is not invariant under perfect mappings. The space $X$ is Tychonoff: Say $(x, y), (w, t)\in X$ . If $y\neq 0$ or $t\neq 0$ this is quite obvious since one of the points is isolated. If $y = t = 0$ , and $x < w$ , then by splitting into three cases $x < w \leq x+1, x+1 < w \leq x+\sqrt{2}$ and $w\geq x+\sqrt{2}$ one can easily see that we have disjoint neighbourhoods. Thus $X$ is Hausdorff. If $(x, y)\notin F$ and $F$ is closed, of course the only interesting case is when $y = 0$ for otherwise $\{(x, y)\}$ is clopen. In that case we can find $n$ with $U_n(x)\subseteq F^c$ . By defining $f(w, t) = 1$ for $(w, t)\notin U_n(x)$ and $f(w, t) = nt$ for $(w, t)\in U_n(x)$ , we see that $f$ is continuous and so $X$ is Tychonoff. To see that $X_+$ and $X_-$ are realcompact, lets focus on $X_+$ . If $\mathcal{F}$ is a real z-ultrafilter on $X_+$ , then since $\mathbb{R}\times [0, a]$ for $a > 0$ is clopen, we can see that if $\mathbb{R}\times (a, \infty)\in\mathcal{F}$ , then $\mathcal{F}\restriction_{\mathbb{R}\times (a, \infty)}$ is a real z-ultrafilter on the realcompact space $\mathbb{R}\times (a, \infty)$ , and as such is fixed, so that $\mathcal{F}$ is fixed. Otherwise, if for all $a > 0$ , $\mathbb{R}\times [0, a]\in \mathcal{F}$ , then $\mathbb{R}\times \{0\}\in\mathcal{F}$ since $\mathcal{F}$ is closed under countable intersections. One can observe that $([a, b]+\mathbb{Z})\times \{0\}$ for $a < b$ are zero sets of $X_+$ by construction appropriate functions (similar to the one in the proof that $X$ is Tychonoff). Thus $([0, 1/2]+\mathbb{Z})\times \{0\}\in \mathcal{F}$ or $([1/2, 1]+\mathbb{Z})\times\{0\}\in \mathcal{F}$ , for example the former case holds. Take $a = \sup \{x\in [0, 1/2] : ([x, 1/2]+\mathbb{Z})\times\{0\}\in \mathcal{F}\}$ and $b = \inf\{x\in [a, 1/2] : ([a, x]+\mathbb{Z})\times\{0\}\in\mathcal{F}\}$ . Once again one would show that $[a, b]+\mathbb{Z}\in \mathcal{F}$ from closure under countable intersections, and if $a\neq b$ we could take $a < c < b$ and by considering $([a, c]+\mathbb{Z})\times\{0\}$ and $([c, b]+\mathbb{Z})\times\{0\}$ obtain a contradiction with choice of $a, b$ . Thus $(a+\mathbb{Z})\times\{0\}\in\mathcal{F}$ for some $a\in \mathbb{R}$ . However, since $(a+\mathbb{Z})\times\{0\} = \bigcup_{n\in \mathbb{Z}}\{(a+n, 0)\}$ is a countable union of zero sets, and since $\mathcal{F}$ is a real z-ultrafilter, we must have $\{(a+n, 0)\}\in\mathcal{F}$ for some $n$ , that is $\mathcal{F}$ is a fixed z-ultrafilter. This proves $X_+$ is realcompact, the proof for $X_-$ is the same. Could anyone help me on how to show that $X$ is not realcompact? Edit: A z-ultrafilter is an ultrafilter on the lattice of zero sets (as to distinguish them from ultrafilters on the lattice of sets), and a real z-ultrafilter is a z-ultrafilter closed under countable intersections. Crossposted with mathoverflow .","['perfect-map', 'general-topology', 'realcompact-spaces', 'tychonoff-spaces']"
4718889,Series expansion for $\text{Li}_2(x)$? Why is this wrong?,"In this answer it is claimed by @ClaudeLeibovici that $\text{Li}_2(x)$ has the following power series expansion: $$S(x)=\sum_{n=0}^\infty \frac{\psi ^{(0)}\left(\frac{n+3}{2}\right)-\psi
   ^{(0)}\left(\frac{n+2}{2}\right)}{2(n+1)}\,x^{2n+1}$$ However, this seems wrong to me, since $$S(1)\simeq0.5797622205888950\dots$$ $$\text{Li}_2(1)\simeq1.6449340668482\dots$$ and this is just one counterexample, they differ for every value of $x$ . To get the series, they suggest to take the series for $-\frac{\log (1-x)}{x}$ and integrate termwise, but the series expansion for this function is $$-\frac{\log (1-x)}{x}=\sum_{k=1}^{\infty}\frac{x^{k-1}}{k}$$ which, when integrated from $0$ to $z$ leads to $$\text{Li}_2(z)=\sum_{k=1}^{\infty}\frac{z^k}{k^2}$$ which is just the definition of the dilogarithm! So no digamma functions at all! Also, if you remove the $2$ in the denominator of the series (it could be a typo), the result is still wrong. Do you have any clue of what is going on here? Am I missing something? Or is this just wrong?","['integration', 'calculus', 'sequences-and-series']"
4718962,"How can we divide an equation by a function, where that function isn't guaranteed to be always non-zero?","Suppose I have the following equation, where r(x) and y(x) are functions of x. r(x)y(x) = y(x)r'(x) My understanding is that we can divide both sides by y(x) , only if we know that y(x) != 0 for all values of x. If that's not necessarily the case, my understanding is we need to consider both cases. The case where y(x) != 0 and the case where y(x) = 0 . In the first case, we arrive at the equation r(x) = r'(x) . In the second case, where the x value makes y(x) = 0 , we are unable to say anything about the relation of r(x) and r'(x) . Is my understanding correct? If it is, than is it true that the equation r(x) = r'(x) is false? (As it's not necessarily true for all x values).",['algebra-precalculus']
4718971,How should you think about cogroups intuitively?,"There have been various previous questions about cogroup objects on MSE and MathOverflow, mainly focussing on why various examples are indeed cogroup objects (e.g. spheres are cogroup objects in the category $\text{hTop}_\bullet$ of pointed topological spaces up to homotopy, abelian groups are cogroup objects in the category of groups etc.). None have focused on intuitively what cogroups are . When we think about groups, one natural way of thinking about the definition is that it kind of axiomatises the symmetries of some object. This on its own has various facets: You can use this to directly come up with heuristic justifications for the axioms and why extra axioms aren't necessary (e.g. symmetries don't in general commute, so groups shouldn't in general commute). It suggests that there should be a meaningful interplay between a group $G$ 's structure and its group actions or $G$ -sets (which is of course very much true). It can even be partially encoded as a theorem, i.e. Cayley's Theorem showing that every group is specifically a permutation group. What is an analogous perspective on cogroups? There are many aspects I find mysterious... To name a couple: I struggle to understand what on earth the unary operation $C\to C\sqcup C$ on a cogroup $C$ could represent. It takes an element... to something in the coproduct of $C$ with itself? So a little like the disjoint union of $C$ with itself?! What then does coassociativity of this operation really mean?! The only cogroup object in the category $\text{Set}$ is the empty set! At least in the case of groups, group objects in $\text{Set}$ recover the original actual notion of groups... Ideally an answer will provide a nice conceptual basis on which to understand cogroups as described above.","['category-theory', 'abstract-algebra', 'intuition', 'group-theory', 'soft-question']"
4718977,A Question on the Pedagogical Logic Behind the Order of Two Given Exercises,"In Lang's Algebra, the following two exercises are presented to the reader in the following order: Groups Exercise 15: Let $G$ be a finite group acting on $S$ , a finite set of at least $2$ elements. Assume there is only one orbit. Prove there is at least one $g\in G$ with no fixed point, i.e. for all $s\in S$ , $g\cdot s\ne s$ . Groups Exercise 19b.: Let $G$ be a finite group action on a finite set $S$ . For each $g\in G$ , define ${\rm Stab}(g):=\{s\in S : gs = s\}$ . Prove the number of orbits of $S$ is equal to $$
\frac{1}{\#G}\sum_{g\in G}\#{\rm Stab}(g).
$$ I can include the proofs I have for both of these if desired to assuage any concerns that I am fishing for the community to give me free proof(s). My question is as follows: The latter exercise appears to just be Burnside's Lemma, which I am all for having as an exercise. But the former exercise to me screams ""Hey, this is the type of problem where Burnside's Lemma does a lot of the heavy lifting."" Am I missing so obvious (or clever) approach to the former that allows one to circumvent using Burnside's Lemma, or should I chalk this up to the order of exercises not really mattering in the grand scheme of pedagogy? Thank you all for your help and insight :D","['abstract-algebra', 'algebraic-combinatorics', 'education', 'group-theory', 'group-actions']"
4719011,Constraints on a polygon in 3D,"I have a 3D geometry related question. Suppose you have a polygon in 3D, determined by the cartesian coordinates of its points $(x_1, .... x_n)$ , and edges $((x_1,x_2), \dots, (x_{n-1},x_n), (x_n, x_1))$ .
Suppose that you fix: $\forall i \in [1,n-1]$ , the distances $|x_{i+1} - x_i|$ , and ${|x_1 - x_n|}$ $\forall i \in [1,n-1]$ , the bond angles $\widehat{x_{i-1}x_ix_{i+1}}$ and $\widehat{x_{n}x_1x_{2}}$ Does this uniquely determine the shape of the possible 3D polygon ? Some thoughts Since we need $n$ points to define our polygon, we need to determine $3n$ variables (the $x$ , $y$ and $z$ variables). The constraints on distances give us $n$ equations. The constraints on the bond angles give us $n$ equations. And because our 3D polygon can rotate and translate in space, we center it around $(0,0,0)$ , and fix a vector of spherical coordinates $(\phi, \psi)$ for it. So that is $5$ more equations.
So in total we have $2n + 5$ equations. My questions is : did I miss some constraints ? Why am I obtaining $2n+5$ and not $3n$ ? It feels intuitive that fixing the bond length and bond angles should give a unique 3D shape, could you give me your thoughts on this ? For those familiar with torsion angles Instead of characterizing the polygon with cartesian coordinates, we can use spherical coordinates as above, with distances $|x_{i+1} - x_i|$ , bond angles, and torsion angles. Another way of putting the question is, does determining the distances and bond angles determine the torsion angles. Thank you for your answers !","['euclidean-geometry', 'geometry', '3d']"
4719045,Trouble with variables in arcsin,"I'm trying to see if the ODE - $ \pi y'=4x\arcsin(\frac{y}{x^2+1})$ has a solution through $y(0) = 0$ and if that solution is the only one to that ODE.
I've been trying to replace the $\frac{y}{x^2+1}$ inside the $arcsin$ with $z$ and the $y'$ with $\frac{dy}{dx}$ and to do integration from there but I'm getting stuck after that.",['ordinary-differential-equations']
4719065,A holomorphic function satisfying $f(z)=f(iz)$,"Let $G\subset \mathbb{C}$ be open and define $\Omega = \{ z\in\mathbb{C}: z^4\in G \}.$ Assume that $f$ is analytic on $\Omega$ and satisfies $f(iz)=f(z)$ for all $z\in \Omega$ . I would like to show that there exists an analytic function $g$ such that $f(z)=g(z^4)$ for all $z\in \Omega$ . The converse is clearly true as $(iz)^4=z^4$ , but it doesn't seem to offer many clues as to how to prove the other and harder direction. Letting $f(z)=u(x,y)+iv(x,y)$ with $z=x+iy$ , the constraint turns into $u(x,y)=u(-y,x)$ and $v(x,y)=v(-y,x)$ with of course $\Delta u=0$ , $\Delta v=0$ . I had the idea of writing, for any $z_0\in \Omega$ and for some neighborhood of $z_0$ , since $f$ is analytic, the following equality holds $$f(z)=\sum_{k\ge 0} \frac{a_k}{k!} (z-z_0)^k.$$ Thus, $$0=f(z)-f(iz)= \sum_{k\ge 0} \frac{a_k}{k!} (z-z_0)^k(1-i^k)=\sum_{k\neq 0 \operatorname{mod} 4} \frac{b_k}{k!} (z-z_0)^k$$ for $b_k=a_k(1-i^k)$ . At this point, I want to conclude that necessarily $b_k\equiv 0$ for all $k\neq 0 \operatorname{mod} 4$ , and thus $a_k=0$ for all $k\neq 0 \operatorname{mod} 4$ . Hence, we can write $$f(z)=\sum_{n\ge 0} \frac{a_{4n}}{(4n)!} ((z-z_0)^4)^n=g((z-z_0)^4)$$ where $$g(z)=\sum_{n\ge 0} \frac{a_{4n}}{(4n)!} z^n$$ is analytic since $f$ is, but $z_0$ is not necessarily zero.",['complex-analysis']
4719136,"Prove posterior mean is positive if and only if signal is positive, assuming zero prior mean [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Suppose that: $\Delta \sim G$ , where $G$ is a distribution that is symmetric about the origin I get a normally-distributed signal: $\hat{\delta} \: |\Delta, \tau^2 \sim N(\Delta, \tau^2)$ How can I prove that the posterior mean $E(\Delta | \hat{\delta})$ is positive if and only if the signal $\hat{\delta}$ is positive. (Intuition: The prior mean is zero, so the posterior mean should assume the sign of the signal $\hat{\delta}$ )","['statistical-inference', 'statistics', 'bayesian', 'probability-theory']"
4719153,The definition of the derivative of $f$. Matrix vs. Linear Mapping.,"The following definitions are two definitions of the derivative of $f$ . Definition. (Definition 1) Let $A\subset\mathbb{R}^m$ , let $f:A\to\mathbb{R}^n$ . Suppose $A$ contains a neighborhood of $a$ . We say that $f$ is differentiable at $a$ if there is an $n$ by $m$ matrix $B$ such that $$\frac{f(a+h)-f(a)-B\cdot h}{|h|}\to 0\,\,\,\,\,\,\text{as}\,\,\,\,\,\,h\to0.$$ The matrix $B$ , which is unique, is called the derivative of $f$ at $a$ ; it is denoted $Df(a)$ . Another Definition. (Definition 2) Let $A\subset\mathbb{R}^m$ , let $f:A\to\mathbb{R}^n$ . Suppose $A$ contains a neighborhood of $a$ . We say that $f$ is differentiable at $a$ if there is a linear mapping $B$ such that $$\frac{f(a+h)-f(a)-B(h)}{|h|}\to 0\,\,\,\,\,\,\text{as}\,\,\,\,\,\,h\to0.$$ The linear mapping $B$ , which is unique, is called the derivative of $f$ at $a$ ; it is denoted $Df(a)$ . Suppose we must solve the following problem. Let $f:\mathbb{R}^2\to\mathbb{R}^2$ be a function such that $f(\begin{pmatrix}x\\y\end{pmatrix})=\begin{pmatrix}e^x\sin y\\x^2 e^y\end{pmatrix}$ . Let $c:=\begin{pmatrix}a\\b\end{pmatrix}$ . Find $Df(c)$ . If we adopt the Definition 1, our answer is like the following: $Df(c)=\begin{pmatrix}e^a\sin b&e^a \cos b\\2a e^b&a^2 e^b\end{pmatrix}.$ If we adopt the Definition 2, our answer is like the following: $Df(c)$ is the lienar mapping such that $\mathbb{R}^2\ni \begin{pmatrix}x\\y\end{pmatrix}\to\begin{pmatrix}e^a\sin b&e^a \cos b\\2a e^b&a^2 e^b\end{pmatrix}\begin{pmatrix}x\\y\end{pmatrix}\in\mathbb{R}^2.$ I think Definition 1 is better than Definition 2. But some authors adopt Definition 2. I want to know an advantage of Definition 2. peek-a-boo, Thank you very much for your kind answer. Let $f:GL(2,\mathbb{R})\ni A\to A^{-1}\in GL(2,\mathbb{R})$ . I checked $Df_A(\xi)=-A^{-1}\xi A^{-1}$ holds when $n=2$ by Wolfram Engine. (Please see the answer by peek-a-boo.)","['multivariable-calculus', 'soft-question', 'derivatives']"
4719161,Gym Locker Combination Puzzle,"Here's a problem I've been trying to solve, but I can't reach the correct answer (39 minutes). Before I can open my gym locker, I must remember the combination. Two
of the numbers of this three-term sequence are 17 and 24, but I have
forgotten the third, and do not know which is which. There are 40
possibilities for the third number. At ten seconds per try, at most
how long will it take me to test every possibility? My reasoning was: For each number out of 40 possibilities, the third number can be in one of the three positions, and the other numbers 17 and 24 can switch orders. So, the total cases are $40*3*2$ . Each try is 10 secs, so the total time is $40*3*2*10$ seconds = 40 minutes. Why is my answer wrong? The correct answer is 39 minutes from the answer key.","['contest-math', 'puzzle', 'combinatorics']"
4719162,Infimum of a holomorphic function,"Assume that f is a holomorphic function on $\mathbb{C}$ except at the origin. Also, suppose that $f(n)=(-1)^n$ for each positive integer n. Prove that $\inf_{z\not=0}\lvert f(z) \rvert =0$ . Now, we know that $z=0$ is the only singular point of $f(z)$ . There are three possibilities. Firstly, zero is a removable singularity, so we can remove zero and the resulting function is entire, and thus the result follows, by Liouville's theorem. Secondly, if zero is an essential singularity, then by Casorati-Weierstrass theorem we have that the image of f is dense so the result follows. Now, if zero is a pole of order k then we must have $f(n)=\frac{g(n)}{n^k}=(-1)^n$ for each positive integer, where g is an entire function. Then I was trying to get a contradiction from this but since the integers do not have an accumulation point in $\mathbb{C}$ then we cannot use the identity theorem, so I got stuck at this point. Any help would be appreciated.",['complex-analysis']
4719243,Average area of intersection between two regular n-sided polygons,"I want to find the average area of intersection between two regular polygons constructed as such: we uniformly choose any random point $M$ on the interior of the first n-sided polygon and reflect the entire polygon about $M$ , so in the figure below the center $O$ of the first polygon becomes $O'$ . I want to find the integral of this area over all possible points $M$ and divide it by the area, which if I'm not mistaken gives the average area. My figure below is not so accurate, but the overlapping area should be symmetric across the perpendicular bisector of $OO'$ . I assume that the apothem of the polygon is 1. Using numerical methods I got the value of $\frac{A}{4}$ , where $A$ is the area of the polygon. However, I want a proof of this for all values $n\geq3$ . I do not know whether there exists a closed form formula to calculate the area of the intersection, but that might help in calculating the integral. The integral could also be split over $2n$ symmetrical triangular areas within the polygon. Other than that, I have no idea how to start proving this, or whether a proof even exists. Edit: After reconsidering the problem requirements, I exclusively want a non-recursive formula for the intersection area, or a confirmation that it is impossible to find.","['integration', 'geometry']"
4719248,Show a convergence in probability using Markov inequality,"Let $(X)_{j\in \mathbb Z}$ be a discrete random process such that $$X_{j}= \theta X_{j-1}+ \epsilon_j, \quad (\epsilon_j) \overset{iid}{\sim} N(0,1), |\theta|<1 $$ How to show that $$P\left(\max_{1\leq j \leq n} |X_j| \geq n^{3/4} \right)\to 0, \quad (n \to \infty)$$ I'm a little unsure about doing the following and I still don't know how to complete it. $$P\left(\max_{1\leq j \leq n} |X_j| \geq n^{3/4} \right)= P\left(\left[\max_{1\leq j \leq n} |X_j|\right]^2 \geq n^{3/2} \right)\leq \frac{E\left( \left[\max_{1\leq j \leq n} |X_j|\right]^2 \right)}{n^{3/2}}$$ or $$P\left(\max_{1\leq j \leq n} |X_j| \geq n^{3/4} \right)= P\left(\left[\max_{1\leq j \leq n} |X_j|\right]^2 \geq n^{3/2} \right)= P\left(\max_{1\leq j \leq n} \{|X_j|^2\} \geq n^{3/2} \right) \leq  \frac{E\left( \max_{1\leq j \leq n} \{|X_j|^2\} \right)}{n^{3/2}}$$ In both cases, I use the Markov inequality. Which alternative is right and how to conclude? I know that in both cases it would suffice to show that the last Expectation is finite. How to justify this?","['convergence-divergence', 'probability-theory', 'probability']"
4719258,Why am I getting different answers using different methods?,"Question: $\sin x+\cos x=1+\sin x\cos x,$ then A) $\sin(x+\fracπ4)=\frac1{√2}$ B) $\sin(x-\fracπ4)=\frac1{√2}$ C) $\cos(x+\fracπ4)=\frac1{√2}$ D) $\cos(x-\fracπ4)=\frac1{√2}$ Method $1$ : Let $\sin x+\cos x=t,$ then $1+2\sin x\cos x=t^2$ Therefore, $t=1+\frac{t^2-1}{2}$ $t^2-2t+1=0\implies t=1$ So, $\sin x+\cos x=1$ , thus, options A) and D) are correct. Method $2$ : Putting $\sin x=0$ in the given equation, I get $\cos x=1$ , thus, $x=2nπ$ . So, options A, C, D are correct. Putting $\cos x=0$ in the given equation, I get $\sin x=1$ , thus, $x=(4n+1)\fracπ2$ . So, option B is also correct. How to streamline the answers of both the methods?","['contest-math', 'trigonometry', 'solution-verification']"
4719272,Trace of an important class of operators,"In Physics , there exists an important class of operators of the form $e^{i A}$ (see equation ( $14$ ) in this article ). It is often of interest to calculate the trace $Tr[B e^{i A}]$ (such as equation ( $18$ ) ). I want to know whether there is some standard way(s) to approach this problem in Mathematics ?","['matrices', 'operator-theory', 'linear-algebra', 'trace']"
4719284,How do I evaluate this integral using Cauchy's theorem?,"I have a physic paper to do and one of the question is to demonstrate this equality using Cauchy's theorem : $$\int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\Pi} e^{\frac{i\Pi}{4}*sng \varphi''(k_0)}$$ sng being the sign function What I have used to try to solve this is this calculation : With $x=\zeta$ and $a=-i*sng\varphi''(k_0)$ , we have : \begin{align*}
I &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \\ 
I^2 &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \int_{-\infty}^{\infty} e^{-ay^2 } dy \\
&=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-ax^2 } e^{-ay^2 } dxdy \\
&=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-a(x^2+y^2) } dxdy \\
&=\int_{0}^{2\pi} \int_{0}^{\infty} e^{-ar^2} rdrd\theta \\
&=2\pi \int_{0}^{\infty} e^{-u} \frac{du}{2a} \\
I^2 &=\frac{\pi}{a}
\end{align*} So $$I=\sqrt{\frac{\pi}{a}}$$ Therefore $$\int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\frac{\pi}{-i*sgn \varphi''(k_0)}} = \sqrt{\pi * i * sgn   \varphi''(k_0)}$$ The result I have is far from what I'm looking for. I also know that the fact that a is complex might make my calculations false, but I have to say that I'm quite lost. I didn't understand how to use Cauchy's theorem for this problem. If anyone could help me I would be very greatful ! :) Thanks in advance and have a good day","['integration', 'complex-analysis', 'cauchy-integral-formula', 'mathematical-physics']"
4719294,Test the convergence of the series $1+\frac{2^2}{3^2}+\frac{2^2.4^2}{3^2.5^2}+\frac{2^2.4^2.6^2}{3^2.5^2.7^2}+\cdots$,"Test the convergence of the series $$1+\frac{2^2}{3^2}+\frac{2^2.4^2}{3^2.5^2}+\frac{2^2.4^2.6^2}{3^2.5^2.7^2}+\cdots$$ I tried solving this problem using Gauss's Test which says, If $\sum u_n$ is a series of positive real numbers, such that, $\frac{u_n}{u_{n+1}}=1+\frac{a}{n}+\frac{b_n}{n^p},$ where, $p>1$ and $b_n$ is a bounded sequence,then,  the series converge if $a>1$ , else if $a\leq 1$ the series diverge. So, the series given here, is $1+\frac{2^2}{3^2}+\frac{2^2.4^2}{3^2.5^2}+\frac{2^2.4^2.6^2}{3^2.5^2.7^2}+\cdots$ . Ignoring the first term of the series, we consider $\sum u_n$ where, $u_n=\frac{2^2.4^2.6^2...(2n)^2}{3^2.5^2.7^2.(2n+1)^2},\forall n\in\Bbb N.$ Then we have, $u_{n+1}=\frac{2^2.4^2.6^2...(2n+2)^2}{3^2.5^2.7^2.(2n+3)^2}.$ We note, that $\lim\frac{u_n}{u_{n+1}}=\lim\frac{(2n+3)^2}{(2n+2)^2}=1+\frac 1{n+1}+\frac{\frac 14}{(n+1)^2}.$ From Gauss's Test, we observe, here $p=2\gt 1$ and $b_n=\frac 14$ is a constant and hence a bounded sequence. Also, $a=1,$ due to which the given series is divergent. I hope that my answer is correct. However, I don't seem to have an explanation for why I could apply Gauss's Test. This is because, Gauss's Test, say, that $\frac{u_n}{u_{n+1}}$ should be of the following form : $$1+\frac{a}{\color{red}{n}}+\frac{b_n}{\color{red}{n^p}}.$$ But in my solution, $\frac{u_n}{u_{n+1}}$ came out to be of the form : $$1+\frac{a}{\color{green}{n+1}}+\frac{b_n}{\color{green}{(n+1)^p}},$$ (,where $p=2,b_n=\frac 14, a=1$ ). But then the denominators were of the form $(n+1)$ and not $n$ as was ""described"" in the test. So, does this create any problem with my solution ? If not, then why it does not matter ?","['solution-verification', 'sequences-and-series', 'real-analysis']"
4719304,Prove $\int_{0}^{1} \frac{\ln\left ( 1+\sqrt{1-x^2} \right ) \ln(1+x)}{ x} \text{d}x =-\frac{5}{16}\zeta(3)+\frac{\pi^2}{8}\ln(2)$,"I recently got an integral accidently( $\zeta(s)$ is Riemann $\zeta$ function), $$
\int_{0}^{1} \frac{\ln\left ( 1+\sqrt{1-x^2}  \right ) \ln(1+x)}{
x} \text{d}x
=-\frac{5}{16}\zeta(3)+\frac{\pi^2}{8}\ln(2),
$$ which seems slightly harmonious. So I put it here to ask for an elegant proof for the integral. Besides, let $\operatorname{Li}_n(z)$ be polylogarithms, do similar expressions hold true for $$
\int_{0}^{1} \frac{\ln\left ( 1+\sqrt{1-x^2}  \right ) 
\operatorname{Li}_n(x)}{
x} \text{d}x
$$ and $$
\int_{0}^{1} \frac{\ln\left ( 1+\sqrt{1-x^2}  \right ) 
\operatorname{Li}_n(-x)}{
x} \text{d}x?
$$ Thanks for helping and enlightening me.","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
4719370,A way to justify interchanging a summation and integration,"For all real $a>0$ consider $$\int_0^\infty x^a \left (\sum_{n = 1}^\infty (-1)^n n e^{-2nx} \right ) \, dx.$$ I would like to interchange the summation with the integration in order to find its value but I am having trouble justifying such a change. Fubini's theorem is not strong enough to justify the interchange for all $a > 0$ . If we put absolute values on the terms, we have $$\left | \sum_{n = 1}^\infty (-1)^n n e^{-2nx} \right | \leqslant \sum_{n = 1}^\infty n e^{-2nx} = \frac{e^{2x}}{(e^{2x} - 1)^2}$$ but $\displaystyle\int_0^\infty \frac{x^a e^{2x}}{(e^{2x} - 1)^2}~dx$ only converges for $a > 1$ and not for all $a > 0$ . So my question is, how can the interchange between the summation and integration be justified so that it holds for all $a > 0$ ?","['integration', 'improper-integrals', 'analysis', 'real-analysis', 'sequences-and-series']"
4719382,General proof tactic for showing a.s. limit equalities?,"I am interested in problems of the form: Show that $$\lim_{n\to \infty} X_n=C \text{ a.s.} $$ where $C$ is some known constant. I would like to know if there are any ""classic"" ways of dealing with such problems. One idea that I had was showing that $\limsup_{n\to \infty} X_n\leq C$ a.s. and $\liminf_{n\to \infty} X_n\geq C$ a.s. but I was hoping for some more ideas one could try when faced with such a problem.","['stochastic-processes', 'limits', 'probability-theory', 'probability', 'random-variables']"
4719396,Statement on a neighborhood of $0$ in topological vector spaces,"Consider a topological vector space $E$ and let $U\subseteq E$ be a neighborhood of $0$ . I want to understand the proof of the following statement: If $K\subseteq E$ is compact and $U$ is open with $K\subseteq U$ , then there exists an open $W\subseteq E$ with $0\in W$ , such that $K+W\subseteq U$ . The author of the book starts the proof as follows: For every $x\in K$ , one can pick $V$ a neighborhood of $0$ , such that $x+V\subseteq U$ . Unfortunately, I do not understand this step. Of course, since $U$ is a neighborhood of $0$ , I can find an open set, which contains $0$ and translating this by $x$ would be a neighborhood of $x$ , since the translation is an open map. However, I do not understand, why this should still be contained in $U$ . I have basically the following question: How can I guarantee, that the set $V$ is 'small' enough, such that $x+V$ is still contained in $U$ ? Besides that, I want to mention that the statement above is only one bullet point of a Lemma. Only for this statement, the author requires, that $U$ should be open. Maybe it has to do with the openness of $U$ ? Any help is appreciated! Thank you in advance!","['general-topology', 'topological-vector-spaces', 'functional-analysis']"
4719406,A (new?) proof of the classification of continuous morphisms from $\mathbb{S}$ to $\text{GL}_n (\mathbb{R})$. Reference request :),"About the classification of continuous group morphisms from $(\mathbb{S},\times)$ the circle of elements of module $1$ in $\mathbb{C}$ to $\text{GL}_n (\mathbb{R})$ which is a well known problem, I prove it without reference and had a completely different proof than the usual proof using (I believe) classification of morphisms from $\mathbb{R}$ to $\text{GL}_n ( \mathbb{R})$ with exponentials. EDIT: I realized this is a well known result for student that aim the ENS (French very hard to get math school), I have the original reference , but it is in French (sorry guys) here are all the references that I know about S. Francinou, H. Gianella, S. Nicolas, Exercices de mathématiques, Oraux X-ENS, Algèbre 2, 2e édition, Cassini.
Exercise 4.29 page 251. A PDF written by a fellow student that does the exact same proof (it follows from the book). However, I did not find any reference that use my proof or something analogous. My question is (since it has very probably been done) do you have one reference? The proof uses various mechanisms and I find it interesting. If my question is off-topic, please tell me, I'll close the subject. Here is the theorem: Theorem :
Let $\varphi: \mathbb{S} \longrightarrow \text{GL}_n (\mathbb{R})$ be a continuous group morphism, then there exist $r \leqslant \frac{n}{2}$ , $m_1, \dots m_r \in \mathbb{Z}$ , $P \in \text{GL}_n (\mathbb{R})$ such that: $$\forall \theta \in \mathbb{R}, \qquad \varphi(e^{i\theta}) =
P
\begin{pmatrix}
R(m_1 \theta) \\
& \ddots \\
&& R(m_r \theta) \\
&&&I_{n-2r} \end{pmatrix}
P^{-1}$$ With $R(\theta)$ the rotation matrix $\begin{pmatrix} \cos(\theta) &\sin(\theta)\\ -\sin(\theta) & \cos (\theta) \end{pmatrix}$ Some intuition about the theorem in itself: $\varphi$ stabilizes planes in $\mathbb{R}^n$ and rotates them as you would rotate $\mathbb{R}^2$ , the more you move on the circle, the more the planes rotate. For the rest of the space, it has to be trivial on it. Here is the proof in multiple steps: Prove that every continuous group endomorphism $\varphi$ of $\mathbb{S}$ is of the form $$z \longmapsto z^m$$ for some $m \in \mathbb{Z}$ . To do so, I apply the lifting path theorem to $t \mapsto \varphi(e^{it})$ and get a continuous endomorphism of $\mathbb{R}$ , $\phi$ . These morphisms are well known and of the form $t \mapsto at$ . A quick study gives $a \in \mathbb{Z}$ which finishes the proof. We get into the deep and fix a goal: use codiagonalisation on the image. For that we already have commutativity since the source group is abelian, we just need to show diagonalisation. Let us take $z \in \mathbb{S}$ of finite order, i.e. $$z \in \bigcup_{n \in \mathbb{N}^*} U_n = U_\infty .$$ Then there exist $n$ for which $z^n = 1$ , so $\varphi(z)^n = I_n$ is idempotent, thus diagonalisable over $\mathbb{C}$ with spectrum in $\mathbb{S}$ . So the image of $U_\infty$ by $\varphi$ is codiagonalisable, which means there exists $ Q \in \text{GL}_n ( \mathbb{C} ) $ such that $$ \varphi_{ | U_\infty } (z) = Q \begin{pmatrix}
\tilde{\lambda_1} (z) \\
& \ddots \\
&& \tilde{\lambda_n} (z)
\end{pmatrix} Q^{-1}. $$ with $\tilde{\lambda_i}$ continuous (hence uniformly continuous) functions from $ U_\infty $ to $ \mathbb{S} $ . Thanks to the theorem of extension for uniformly continuous mappings, we extend each $\lambda$ and $\varphi_{|\mathbb{U}_\infty}$ and by unicity, we obtain: $$\varphi (z) = Q
\begin{pmatrix}
\lambda_1 (z) \\
& \ddots \\
&& \lambda_n (z)
\end{pmatrix} Q^{-1}.$$ Obviously, the $\lambda_i$ are continuous endormorphism of the circle, thus there exists $k_1, \dots , k_n \in \mathbb{Z}$ such that $$\varphi (z) = Q
\begin{pmatrix}
z^{k_1} \\
& \ddots \\
&& z^{k_n}
\end{pmatrix} Q^{-1}.$$ By a quick study of the characteristic polynomial of $\varphi \left( e^{i \frac{1}{ \max_{k_i \neq 0} k_i}} \right) $ which does not depend on the field extension thus it has real coefficients, we can reorganize the $k_i$ in $(m_1, -m_1, m_2, -m_2,\dots, m_r,-m_r, 0, \dots 0)$ . It is common knowledge that these two matrices are $\mathbb{C}$ -conjuguate $$\begin{pmatrix}
e^{i\theta} & 0 \\
0 & e^{-i \theta}
\end{pmatrix}
\sim
R(\theta)$$ We get then $$ \varphi(e^{i\theta}) =
P'
\begin{pmatrix}
R(m_1 \theta) \\
& \ddots \\
&& R(m_r \theta) \\
&&&I_{n-2r} \end{pmatrix}
P'^{-1}$$ with $P' \in \text{GL}_n ( \mathbb{C} ) $ , but two real $\mathbb{C}$ -conjuguate matrices are $\mathbb{R}$ -conjuguate, which proves the result.","['reference-request', 'linear-algebra', 'group-theory', 'diagonalization', 'algebraic-topology']"
4719435,Formula for integral of $x^a \ln^n(x) dx$,"Can you explain this formula, I don't get how it works. Given $a > 0$ , the integral is $$ \int_{0}^{1} x^a \, \ln^n(x) \, dx = \frac{(-1)^nn!}{(a+1)^{n+1}}. $$ I started integrating it (by parts) and understood that the first part is always $0$ . So we are left with $$-\frac{n}{a+1} \, \int_{0}^{1} x^a \, \ln^{n-1}(x) \, dx $$ What happens next?",['integration']
4719436,Vector bundle on surface topologically characterized by rank and degree,"I have read in some texts (e.g. in https://www.math.uni-duesseldorf.de/~grk2240/pdf/ModuliVectorBundles.pdf ) that complex vector bundles over a compact surface $S$ (usually a Riemann surface) are topologically characterized by their degree and rank. For rank one, i.e. line bundles, this is something I am familiar with. Does anybody have a reference for a proof for rank >1? Another question: what about the smooth structure? Is it uniquely determined by the topology?","['riemann-surfaces', 'vector-bundles', 'algebraic-topology', 'differential-geometry']"
4719466,Prove that the function $g(x)=\begin{cases} \sin (\frac 1x)& x \neq 0 \\ 1& x=0 \end{cases}$ has no antiderivative,"Prove that the function $$g(x)=\begin{cases}
    \sin (\frac 1x) & x \neq 0 \\ 1 & x=0
\end{cases}$$ is not a derivative of any function that is differentiable along the whole line. We want to prove that $g$ has no antiderivative. Assume the opposite - let $g$ have an antiderivative $G$ . Every antiderivative has the Darboux property, so for any $a,b$ in the domain of $G$ , if $G(a)G(b)<0$ , then there is $c\in (a,b)$ that $G(c)=0$ . I further tried to use mean value theorem to contradict the Darboux property assumption, but I didn't get anything meaningful. Could you please help me?","['mean-value-theorem', 'derivatives', 'real-analysis']"
4719470,How to transform a function f(x) such that it matches the central moments of g(x) up to nth central moment?,"Suppose I have 2 functions, a given function f(x) and a target function g(x). Let $M_{f}^{n}$ denote the nth central moment of function f(x). In the discrete case for N samples of f(x): $M_{f}^{n}=\tfrac{1}{N}\sum_{i=1}^{N}(f(x) - \mu)^{n}$ And $\mu$ is the mean. In the continuous case: $M_{f}^{n}=E[(f - E(f))^{n}]$ I would like to transform f(x) into $f_{g}^{n}(x)$ such that: $M_{f_{g}^{n}}^{1}=M_{g}^{1}$ $M_{f_{g}^{n}}^{2}=M_{g}^{2}$ [...] $M_{f_{g}^{n}}^{n}=M_{g}^{n}$ Upto a specified n. For n=2 case, there is a direct transformation: $f_{g}^{2}(x) = f_1\cdot\frac{M_{g}^{2}}{M_{f_1}^{2}} + M_{g}^{2}$ Where: $f_1(x) = f(x)-M_{f}^{1}$ I can't think of something for n=3,4. It could be the case that such a transformation might not be possible. In which case, is it possible to propose a numerical method that can find a solution upto a specified epsilon? The only thing we know about g(x) are its n central moments. I'm looking for a computationally efficient transformation, yet a fairly general solution. Ideally, an affine or polynomial transformation is preferred, but not required. The target is computational efficiency . The ""transformation"" for n=2 is O(1), assuming that the computation of the nth moment is O(1), and subtracting the 1st moment is O(1).","['statistics', 'functions', 'numerical-methods']"
4719537,Evaluating $\int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_n(x)^2)}$ and similar integrals.,"This question is inspired by this evaluation of an integral by Michael Penn. Suppose we have a differential equation $y''+p(x) y' +q(x)y =0$ with linearly independent solutions $y_1(x)$ and $y_2(x)$ over some interval $I$ . Given that $p,q$ are continuous then $$
\mathrm{d}\left(\frac{y_2}{y_1} \right) = \frac{y_1 y_2' -y_1' y_2}{y_1^2} \mathrm{d}x= \frac{W(y_1, y_2)(x)}{y_1^2} \mathrm{d}x= W(y_1, y_2)(x_0) e^{-\int_{x_0}^{x}p(t)\, \mathrm{d}t}\frac{\mathrm{d}x}{y_1^2}, \quad x_0 \in I
$$ where Abel's formula was used in the last step. So if we now suppose that we have an integral like $\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)}$ then we can do the following $$
\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \int_{a}^{b} \frac{1}{1+ \left( \frac{y_2}{y_1}\right)^2}\frac{\mathrm{d}x}{y_1^2 } \overset{u = y_2/y_1}{=}\frac{1}{W(y_1,y_2)(x_0)}\int_{\alpha}^{\beta}\frac{\mathrm{d}u}{\left(1+u^2\right)e^{-\int_{x_0}^{\left( \frac{y_2}{y_1}\right)^{-1}(u)}p(t)\, \mathrm{d}t}} 
$$ which is ugly in general, except for when $p =0$ , and then the integral reduces to $$
\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \frac{\arctan\left(\frac{y_2(b)}{y_1(b)}\right)- \arctan\left(\frac{y_2(a)}{y_1(a)}\right)}{W(y_1,y_2)(x_0)}
$$ One application of the above is for the integral $$
\int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_{n}(x)^2)}
$$ where $I,K$ are the modified Bessel functions. If we know that $x^2y'' -\left(x^2 + n^2 - \frac{1}{4}\right)y=0$ has solutions $\sqrt{x}I_n(x)$ and $\sqrt{x}K_{n}(x)$ then we can readily evaluate the integral as $$
\frac{\pi}{x\left(I_nK_{n-1} + I_nK_{n+1}+K_nI_{n-1} + K_nI_{n+1}\right)\Big\vert_{x_0}} = \frac{\pi}{2}
$$ Does this technique have a name? And do you know some other examples of integrals that could be evaluated by a similar method? Thank you!","['integration', 'definite-integrals', 'special-functions', 'ordinary-differential-equations', 'homogeneous-equation']"
4719539,Proving a polynomial in the complex plane has no zeros in a certain radius,"The question is as follows: For $0<r<1$ , prove for sufficiently large n, the polynomial $Q_n(z)=\sum_{k=1}^n kz^{k-1}$ has no zeros for $|z|<r$ I tried using Rouche's theorem multiple times on different terms of the sum and this didn't really lead anywhere. I also tried to use the argument principle but again, this didn't really lead anywhere. I think the maximum principle might be involved somewhere, but again, I'm not gaining much progress trying to use this either. I noticed this sum tends to $1/(1-z)^2$ for large $n$ , so intuitively the polynomial having no zeros makes sense, however I can't seem to put pen to paper following this logic. Any tips? Thanks :)","['complex-analysis', 'roots']"
4719595,Why is gradient symmetric at optimal point for convex functions on the positive semidefinite cone?,"For a convex function $f: \mathbb{R}^{n \times n} \to \mathbb{R}$ , if $X^{*} = \underset{ X\succeq 0 }{ \operatorname{arg min}}f(X)$ , then we have $$\nabla f(X^{*})\succeq 0, \qquad X^{*} \succeq  0, \qquad \left\langle \nabla f(X^{*}),X^{*} \right\rangle = 0$$ How can we show $\nabla f(X^{*})$ is symmetric? I have proved everything else (see below). However, I'm running out of techniques to show that $\nabla f(X^{*})$ is symmetric, I have tried to use orthogonal component of skew symmetric matrix, and some other techniques. My intuition is that this is quite easy, and can be proven by contradiction by finding a direction to decrease in the positive semidefinite range. However, I have not come up with anything solid. Proof: For $\nabla f(X^{*}) \succeq 0$ , suppose not, $\exists u$ s.t. $u^{T} \nabla f(X^{*})u = u^{T}\otimes u^{T}vec(\nabla f(X^{*})) < 0$ . $u^{T}\otimes u^{T} = uu^{T}$ which is a positive semidefinite matrix. Therefore, $\exists t > 0$ s.t. $f(X^{*}+tuu^{T}) < f(X^{*})$ , which contradicts that $X^{*}$ is the global minimum.
Next we show $\langle \nabla f(X^{*}),X^{*} \rangle = 0$ . Suppose not, if $\langle \nabla f(X^{*}),X^{*} \rangle < 0$ , $\exists t> 0$ , s.t. $f(X^{*}+tX^{*}) < f(X^{*})$ . Similarly, if $\langle \nabla f(X^{*}),X^{*} \rangle > 0$ , $\langle \nabla f(X^{*}),X^{*} \rangle < 0$ , since we know for $0 < t < 1$ , $tX^{*} \succeq  0$ , we know $\exists 0<t<1$ s.t. $f(X^{*}-tX^{*})) < f(X^{*})$ . Both cases contradict that $X^{*}$ is the global minimum.","['positive-semidefinite', 'convex-optimization', 'matrices', 'linear-algebra', 'optimization']"
4719614,Recovering an element of a free group from its projections,"Assume you have an unknown word on an alphabet with at least three letters, and you know all the words obtained by erasing each copy of some letter. Then, you can find the first letter of the original word (it is the only one satisfying the following property : it is at the beginning of every word obtained by removing a letter which is not itself). By continuing that way, you recover the whole word.
So the map from the free monoid on $n$ letters to the product of $n$ free monoid on $n-1$ letters obtained by erasing all copies of some letters is injective. Now I'm asking the same question for free groups . Of course, a word in the kernel is trivial in the abelian free group (the algebraic total number of occurrences of some letter can be recovered by removing any other letter), so it is a product of commutators. Also, it is (tautologically) for every letter $l$ a product of conjugates of $l$ . But is it necessarily an empty word? Geometrically : if a loop on the disk with $n$ points removed ( $n\geq 3$ ) is nullhomotopic each time you add one the points back, is it necessarily nullhomotopic? I'm afraid the answer to these questions is no, but I'm failing to either find a proof, a counterexample, or a reference addressing this question. I'm also thinking maybe $n\geq 4$ or something could work with $3$ failing. What do you folks think? Thanks for any help :)","['combinatorics-on-words', 'fundamental-groups', 'free-groups', 'combinatorics', 'algebraic-topology']"
4719627,$(A\subseteq B)\wedge (|A|=|B|) \implies A=B$,"Let $A$ and $B$ be finite sets. I'm trying to prove that, if $A\subseteq B$ and there exists a bijection $f:A\to B$ , then $A=B$ or rather $B\subseteq A$ . My attempt at a proof: Choose $y\in B$ , there exists $f^{-1}:B\to A$ an inverse map to $f$ . Therefore $(f\circ f^{-1})(y)\in B \implies f^{-1}(y)\in f^{-1}(B)=A\subseteq B$ . Then we have $y\in B \implies y\in f(B)$ , from that I infered $B\subseteq f(B) \subseteq f(A) = B$ . So I get $f(A)=f(B)$ . That is where I got stuck. Can I conclude that $A=B$ by injectivity of $f$ ? How do I fully justify this last step?",['elementary-set-theory']
4719628,Why does Fibonacci identity $3 f_n = f_{n+2} + f_{n-2}$? This is from Proofs That Really Count.,"I am reading the book ""Proofs That Really Count"" by Benjamin and Quinn. In chapter $1$ , they establish that: $f_n = f_{n-1} + f_{n-2}$ , and $f_1 = 1$ , $f_2 = 2$ , $f_3 = 3$ , $f_4 = 5$ , etc. The chapter establishes that $f_n$ is the combination of ways to place dominoes and squares on $n$ -tiled board. For example, $f_4=5$ , so there are $5$ ways to place dominoes and squares on a $4$ -tiled board: ▫▫▫▫ ▫▫▭ ▫▭▫ ▭▫▫ ▭▭ The first chapter continues with examples of how to prove identities with $f_n$ based on tiles and squares arguments. In Chapter $1$ , Identity $7$ , they give prove this identity using tiles and squares argument: $3 f_n = f_{n+2} + f_{n-2}$ The argument goes as follows: You have a $n$ -tiled board, and it can be converted into either a $(n+2)$ tiled board or a $(n-2)$ tiled board in the following three ways: Given an $n$ tiled board: Add two squares to get $n+2$ . Add one domino to get $n+2$ . a. If the last position of the $n$ tiled board is a square, add a domino before the last square to get $n+2$ . b. If the last position of the $n$ tiled board is a domino, remove the domino to get $n-2$ . The number of ways to tile either $(n+2)$ or $(n-2)$ tiled board is $f_{n+2} + f_{n-2}$ . That concludes the proof of $3 f_n = f_{n+2} + f_{n-2}$ . The part that confuses me about this proof is in case $3$ . If you assume that an $n$ tiled board's last position has a square, doesn't that mean that the ways to tile such a board is actually $f_{n-1}$ ? Similarly for when the last position is a domino, then wouldn't it always be $f_{n-2}$ ? Maybe I'm missing a deeper intuition here about this combinatoric proof? Edit: updating the wording to more accurately reflect the problem.","['fibonacci-numbers', 'combinatorial-proofs', 'proof-explanation', 'combinatorics', 'tiling']"
4719647,"Stone Cech compactification of $(0,1]$is not $[0,1]$","If I considered $(0,1]\subset \beta(0,1]=[0,1]$ this is trivial because the universal property would mean we would need a continuos function on $[0,1]$ with $g(t)=\sin(1/t)$ fot all $t \in(0,1]$ which is clearly absurd (no $g(0)$ makes $g$ continuous). I do not want to use this continence, because I only assume $\beta(0,1]\approx [0,1]$ and so, $(0,1]$ could be ""scrambled inside"" of $[0,1]$ . Here is what I tried so far: I am interested in proving the Stone Cech compactification of $(0,1]$ is not homeomorphic to $[0,1]$ . Because $[-1,1]$ is a Hausdorff compact space, the universal property of the Stone Cech compactification teaches us there would be a unique continuos map $g:\beta (0,1]\rightarrow[-1,1] $ such that $g(\epsilon(t))=\sin(1/t)$ where $\epsilon$ is the evaluation function given by $\epsilon(t)=(f(t))_{f\in C_b(0,1]}$ . Let $\Phi: \beta(0,1]\rightarrow [0,1] $ be a homeomorphism. In this case, $g\Phi^{-1}\Phi\epsilon(t)=\sin(1/t)$ for $1\geq t>0$ . My initial tought was taking $t=\frac{1}{n}$ in this case $\Phi\epsilon(1/n)\in [0,1]$ is bounded and by Bolzano Weierstrass there is a convergent subsequence, such that $\Phi\epsilon(1/n_k)\rightarrow x_o$ . So, we have $\sin(n_k)=\sin(1/(1/n_k))\rightarrow g\Phi^{-1}(x_o)$ . I thought this would be a contradiction but it appears there are always (Bolzano Weierstrass again) convergent subsequences of the form $\sin(n_k)$ , so it could be $\sin(n_k)$ indeed converges.","['general-topology', 'compactification']"
4719672,Bootstrap Weak Convergence,"Let $X_1, X_2, \dots, X_n$ be an iid sample from an unknown distribution finite mean $\mu$ and finite variance $\sigma^2$ . Furthermore, let $R_1,R_2,\dots,R_n$ . denote iid Rademacher random variables. My goal is to compute the asymptotic distribution of $$T_n := \sqrt n\left(\frac 1n\sum_{i=1}^n R_i(X_i - \hat\mu)\right)$$ given the data $X_1, X_2,\dots, X_n$ . Here $\hat\mu := n^{-1}\sum_{i=1}^nX_i$ . If the $R_i$ 's are constant (e.g., $R_i = c$ for all $i$ ) and $\hat\mu$ is replaced by $\mu$ , the CLT kicks in and I obtain that $T_n$ is asymptotically normal with mean $0$ and variance $\sigma^2$ . The mean of $T_n$ and variance is $\sigma^2$ conditional on the data equals $0$ and $\sigma^2$ , respectively. But how do I obtain the asymptotic distribution of $T_n$ given the data?","['statistics', 'probability-limit-theorems', 'weak-convergence', 'bootstrap-sampling', 'probability-theory']"
4719690,Holomorphic function and inequality on the unit disk,"Suppose that f is an analytic function on the open unit disk and $\lvert f(z) \rvert \geq  \sqrt{\lvert z \rvert}$ for all z on the unit disk. Show that $\lvert f(z) \rvert \geq 1$ on the unit disk. We can write it down as $\frac{\vert z \rvert}{(\lvert f(z) \vert)^2} \leq 1$ , provided that $f(0) \not= 0$ . We know that f cannot be zero for other values since otherwise it would contradict the inequality in the supposition. The above function is holomorphic and is equal to zero at zero, again provided that f is not zero at zero. Thus, we can apply the Schwarz lemma and the result follows. Now, if f is zero is at zero then this argument does not work and I do not know how to handle that case separately, if there is any way. Thanks for your help.",['complex-analysis']
4719735,"Serre: coherent $\iff$ locally finitely presented, when sheaf coherent over itself","Note: this question is relevant but doesn't answer my question. I want to prove the following proposition from (an English translation of) Jean-Pierre Serre's article Faisceaux algébriques cohérents . Serre only gives an outline of the proof. When $\mathscr A$ is a coherent sheaf of rings, we have the following results: PROPOSITION 7. For a sheaf of $\mathscr A$ -modules, being coherent is equivalent to being locally isomorphic to the cokernel of a homomorphism $\phi : \mathscr A^q \to \mathscr A^p$ . In other words, when $\mathscr A$ is coherent over itself, the implications $$
    \text{coherent} \iff \text{locally finitely presented}
  $$ hold for any sheaf $\mathscr F$ of $\mathscr A$ -modules. I'm unable to prove the $\impliedby$ implication. Serre only gives an outline: Proof. The necessity part is Proposition 2; the sufficiency follows from the coherence of $\mathscr A^q$ and $\mathscr A^p$ and from Theorem 2. From earlier: THEOREM 2. Let $\phi$ be a homomorphism from a coherent sheaf $\mathscr F$ to a coherent sheaf $\mathscr G$ . The kernel, cokernel, and the image of $\phi$ are also coherent sheaves. Serre's definition of a coherent sheaf: Definition 2. A sheaf $\mathscr F$ of $\mathscr A$ -modules is said to be coherent if: (a) $\mathscr F$ is of finite type, (b) If $s_1, \ldots, s_p$ are sections of $\mathscr F$ over an open $U \subset X$ , the sheaf of relations between the $s_i$ is of finite type (over the open set $U$ ). I believe (b) is equivalent to the following criterion from the nLab definition : For every open $U$ in the base space, every finite $p \in \mathbb N$ and every morphism $$ \mathscr A^p |_U \to \mathscr F |_U $$ of $\mathscr O |_U$ -modules has a finitely generated kernel. My attempt . Suppose $\mathscr A$ is a sheaf on $X$ , and coherent over itself. Let $\mathscr F$ be a locally finitely presented $\mathscr A$ -module. Then each $x \in X$ is contained in some open $U_x \ni x$ for which a sequence $$
    \mathscr A^q |_{U_x} \to \mathscr A^p |_{U_x} \to \mathscr F |_{U_x} \to 0
  $$ exists. Since $A^q |_{U_x}$ and $A^p |_{U_x}$ are coherent, so is $\mathscr F |_{U_x}$ . $\color{red}{\text{Now what?}}$ The problem is that every morphism $\sigma : \mathscr A^s |_V \to \mathscr F |_V$ must have a finitely generated kernel for any $s$ and any open $V \subseteq X$ , not just the $U_x$ from above. Is there some shortcut I'm missing, or is delving into the details of the sheaf of relations necessary? Can it be proven on stalks?","['algebraic-geometry', 'coherent-sheaves', 'sheaf-theory']"
4719788,Problem when proving the series $1+\frac 13-\frac 12+\frac 15+\frac17-\frac 14 +\frac 19+\frac 1{11}-\frac 16+...$ converges to $\frac 32\log 2.$,"Prove that the series $$1+\frac 13-\frac 12+\frac 15+\frac17-\frac 14 +\frac 19+\frac 1{11}-\frac 16+\cdots$$ converges to $\frac 32\log 2.$ I tried solving the problem as follows: The series given is $$1+\frac 13-\frac 12+\frac 15+\frac17-\frac 14 +\frac 19+\frac 1{11}-\frac 16+\cdots.$$ We write the given series as $\sum u_n$ where $\{u_n\}$ is a sequence defined by $u_n=\frac{1}{4n-3}+\frac{1}{4n-1}-\frac{1}{2n},\forall n\in\Bbb N.$ We consider the partial sum of the given  series $t_n=u_1+u_2+u_3+...+u_n$ ( consisting of $n$ terms). Then, $$t_{3n}=u_1+u_2+\cdots +u_{3n}=(1+\frac 13-\frac 12)+(\frac 15+\frac17-\frac 14) +(\frac 19+\frac 1{11}-\frac 16)+\cdots+(\frac{1}{12n-3}+\frac{1}{12n-1}-\frac{1}{6n})=(1+\frac 13+\frac 15+\frac 17+...+\frac{1}{12n-1})-(\frac 12+\frac 14+\frac 16+\cdots +\frac 1{6n})\tag 1.$$ (Till now, we have grouped all the odd terms (positive terms) together and the negative terms( even terms) together in the partial sum, above. ) Next, we add and subtract $\frac{1}{2}+\frac{1}{4}+\frac{1}{6}+...+\frac{1}{12n}$ in the right hand side of the above equality $(1)$ and rearrange, to get the partial sum $t_{3n}$ of the series as, $$t_{3n}=(1+\frac 13+\frac 15+\frac 17+...+\frac{1}{12n-1})-(\frac 12+\frac 14+\frac 16+\cdots +\frac 1{6n})=(1+\frac 12+\frac 13+\cdots +\frac{1}{12n-1})-(\frac 12+\frac 14+\frac 16+\cdots +\frac {1}{12n})-(\frac 12+\frac 14+\frac 16+\cdots +\frac 1{6n})=(1+\frac 12+\frac 13+\cdots +\frac{1}{12n-1})-2(\frac 12+\frac 14+\frac 16+\cdots +\frac {1}{6n})-(\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n})=(1+\frac 12+\frac 13+\cdots +\frac{1}{12n-1})-( 1+\frac 12+\frac 13+\cdots +\frac {1}{3n})-(\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n})\tag 2$$ We know that, $\lim(1+\frac 12+\frac 13+\cdots+ \frac 1n-\log n)=\gamma.$ Let, $1+\frac 12+\frac 13+\cdots+ \frac 1n-\log n=\gamma_n\tag 3$ then, $\lim\gamma_n=\gamma.$ Using $(3),$ the  equality $(2)$ can be written as, $$t_{3n}=(1+\frac 12+\frac 13+\cdots +\frac{1}{12n-1})-( 1+\frac 12+\frac 13+\cdots +\frac {1}{3n})-(\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n})=\log(12n-1)+\gamma_{12n-1}-\log(3n)-\gamma_{3n}-S,$$ where $S=\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n}.$ We also, note that, $\lim S=0.$ We now proceed to evaluate the limit of $t_{3n}=\log(12n-1)+\gamma_{12n-1}-\log(3n)-\gamma_{3n}-S=\log(4-\frac{1}{3n})+\gamma_{12n-1}-\gamma_{3n}+S.$ We observe, $$\lim t_{3n}=\log 4=2\log 2.$$ As, $t_{3n+1}=t_{3n}+u_{3n+1}$ and $t_{3n+2}=t_{3n+1}+u_{3n+2},$ we have, $$\lim t_{3n+1}=\lim t_{3n+2}=\lim t_{3n}=2\log 2.$$ So, $\lim t_n=2\log 2.$ Hence, the series $$1+\frac 13-\frac 12+\frac 15+\frac17-\frac 14 +\frac 19+\frac 1{11}-\frac 16+\cdots$$ converges to $2\log 2.$ However, as it turns out, this gives the value $2\log 2$ contrary to what was required to be established, i.e $\frac 32\log 2.$ The problem, is precisely, I find no mistake in my solution. I want to know where did things go wrong. Specifically, where is the mistake in this solution? A New Issue As pointed out, in the comment, by @metamorphy, it seems that the evaluation of the limit .i.e $\lim S=0$ is incorrect. It should be, as follows: $$S=\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n}\implies 2S=\frac1{3n+1}+\frac1{3n+2}+\dots+\frac1{6n}\\=\left(1+\frac12+\dots+\frac1{6n}\right)-\left(1+\frac12+\dots+\frac1{3n}\right)\\=\big(\gamma_{6n}+\log(6n)\big)-\big(\gamma_{3n}+\log(3n)\big).$$ This means, $\lim 2S=\log 2,$ or $\lim S=\frac 12 \log 2.$ But here's the problem, what went wrong with this reasoning, i.e the reason by which, I concluded $\lim S$ is $0$ which is: $$S=\frac1{6n+2}+\frac{1}{6n+4}+\cdots+\frac{1}{12n},$$ so, limit of each of the terms $\lim\frac{1}{6n+r}=0$ , such that $r\in\{2,4,...,6n\}.$ This, means $\lim S=0.$ I want to know the mistake in this second limit evaluation explicitly ?","['sequences-and-series', 'real-analysis']"
4719814,Does every preorder induce a partial order?,"A (non-strict) preorder is defined as a reflexive and transitive homogenous relation; a (non-strict) partial order is defined as a reflexive, antisymmetric, and transitive homogenous relation. Clearly, every partial order is a preorder but not every preorder needs to be a partial order (cf. [1]). However, it seems to me that every preorder induces a partial order via the following construction: Every preorder induces a strict preorder (an irreflexive, transitive relation). [2] Every strict preorder is a strict partial order (an irreflexive, transitive, antisymmetric relation). [3] Every strict partial order induces a (non-strict) partial order. [4] Is that correct or where did I go wrong? I appreciate any help you can provide. Sources: [1] StackExchange: Preorders vs partial orders - Clarification [2] Wikipedia: Strict preorder induced by a preorder [3] Wikipedia on preorders: ""A binary relation is a strict preorder if and only if it is a strict partial order."" [4] Wikipedia on partial orders: ""Conversely, a strict partial order $<$ on $P$ may be converted to a non-strict partial order"".","['elementary-set-theory', 'order-theory']"
4719828,Necessary and sufficient mathematical structure for spacetime continuum,"In physics, we often say that spacetime is a collection (set) of all events (idealized occurrences of zero extension in space-time, the ""here and now""s). Moreover, spacetime is said to be a continuum. By continuum, at least in the Euclidean case $(\mathbb{R}^3)$ , a naive intuition is given which reads: if there are two points, no matter how close to each other they are there will always be more points between them. Somehow, this intuition is carried over to the case of spacetime as well, and I do not entirely understand how. I would like to know what the most rigorous definition and minimalist construction of the spacetime continuum is. From some expositions on differential geometry introduced in general relativity courses, I naively guess the following: The notion of continuity is studied in topology. Thus one models the spacetime as a $4$ -dimensional topological manifold (locally isomorphic to $\mathbb{R}^4$ ). In the previous intuitive definition (""if there are two points ... more points between them"") we considered at least two points (events). Therefore we must be able to distinguish two points on the given manifold. As far as I understand, to achieve this one would require some separability axiom. As physicists like their spacetime well behaved, generally, it is assumed that spacetime manifold has Hausdorff property. Now we must understand the closeness of the points. To me, it sounds like we need a metric space to have a notion of distance. So we must consider a metric on the manifold. From this point, I do not understand how to go about this. Because spacetime comes with a metric of Lorentzian signature (signature $2$ , pseudo-Riemannian geometry). That is, a manifold with metric $(\mathscr{M},\mathbf{g})$ is locally isomorphic to $(\mathbb{R}^4,\eta)$ , where the Lorentzian metric $\eta$ is ${\rm diag}(-1,1,1,1)$ . Therefore, my intuition regarding standard metric topology on $\mathbb{R}^4$ , using which one could have defined open $\epsilon$ -Balls, breaks down. For the distances defined with $\eta$ metric is not positive definite. Here is the question(s): How does one mathematically define the notion of a spacetime continuum? Is such a definition possible without the metric and only at the level of some primitive topological constructs or do we need a metric to define a continuum? If we do need a metric then how do we deal with a non-positive-definite metric as one encounters in pseudo-Reimannian geometry? To summarize What are the necessary and sufficient mathematical notions to construct a spacetime ""continuum"" ? The definition of spacetime given by Hawking and Ellis (one of the most mathematically rigorous books on the subject) may be helpful in this context: The mathematical model we shall use for space-time, i.e. the collection
of all events, is a pair $(\mathscr{M}, \mathbf{g})$ where $\mathscr{M}$ is a connected four-dimensional Hausdorff $C^\infty$ manifold and $\mathbf{g}$ is a Lorentz metric (i.e. a metric of
signature + 2) on $\mathscr{M}$ . (P.S.: I am a physics student and have very little experience with abstract mathematics. Brief physical/intuitive explanations of the mathematical concepts used in the answer would be most helpful and much appreciated!)","['smooth-manifolds', 'manifolds', 'general-topology', 'general-relativity', 'differential-geometry']"
4719851,"EV for rolling a consecutive 56, and why?","I’ve seen this question a lot; you roll a fair six-sided die, what’s the expected number of rolls to get a consecutive 5-6? You can solve the problem with some simple total expectation; one method is outlined in the middle of this doc . The answer turns out to be 36. It can’t be a coincidence that it’s 6^2, no? What’s the reason as to why?","['expected-value', 'dice', 'probability-theory', 'probability']"
4719888,Finding unknown function $f(y)$ from $\int_0^{y_{max}} \frac{dy}{\sqrt{\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 -1}} = \frac{d}{2}$,"I was doing some underwater geometric acoustics (like geometric optics) and this equation popped up from my calculations. My question is how do I find unknown function $f(y)$ (which represents underwater sound profile, where $y$ is depth) if $y_{max}$ is solution to $f(y_{max}) = \frac{f(0)}{\cos(\alpha)}$ . We also know values $D$ for all corresponding angles $\alpha \in (0, \frac{\pi}{2})$ . $$\int_0^{y_{max}} \frac{dy}{\sqrt{\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 -1}} = \frac{D}{2}$$ I explored the suggestion in the comment and tried to take $\frac{d}{dy}$ on both sides and solve for $f(y)$ and I get the following: $$0 = \frac{d}{dy}\int_0^{y_{max}} \frac{dy}{\sqrt{\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 -1}} = \int_0^{y_{max}} \frac{\partial}{\partial y} \frac{dy}{\left[\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 -1 \right]^{1/2}} = \int_0^{y_{max}} \frac{\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 \frac{1}{f(y)}}{\left[\left(\frac{f(0)}{f(y)\cos(\alpha)}\right)^2 -1 \right]^{3/2}}dy$$ This whole thing is equal to zero because $\frac{d}{dy}\frac{D}{2} = 0$ . But I am still unable to find $f(y)$ .","['integration', 'functions', 'definite-integrals', 'real-analysis']"
4719914,How can I simulate on R the total variation distance between the Law of the number of fixed points and Pois(1)?,"I am trying to make a graph on the Total Variation Distance between the Law of the number of Fixed Points of a Random Permutation and the Poisson( $\lambda = 1$ ) distribution.
I know that the Total Variation distance is given by ${ ||\mu - \upsilon ||_{TV} }  = \frac{1}{2}{\sum_{x \in \Omega} |\mu(x)-\upsilon(x)|}$ or, equivalently by the $max_{x \subseteq \Omega}|\mu(x)-\upsilon(x)|$ . Actually I should make a graph by sampling something (that I do not understand what, yet) where it is possible to see that the TV decrease as N goes to infinity and that the TV curve stays below a bound that is given by $\frac{2^{N+1}}{(N+1)!}$ .
Here is the formula to obtain the law of the number of fixed points in a
random permutation $\pi(x) = {\displaystyle \frac{1}{x!} \sum _{k=0}^{n-x} \frac{{(-1)}^{k}}{k!}}$ I tried to plot something on R but I was told that it was very wrong because I set on the x axis the number of elements to permutate (n) and on the y axis the distance between $\pi$ and pois(1). I understand that I was wrong because I plotted the sigle difference over n and not the sum over all sets, but I do not how I can find all this sets by sampling. Well, I am very confused because I do not understand how and what I should sample to estimate the TV so any suggestions, comments or corrections to help me to understand it better will be very useful (also only related to the theory).
I hope I explained me decently. Thank you very much","['statistics', 'probability-distributions', 'graphing-functions', 'combinatorics', 'total-variation']"
4719989,Asymptotic expression of a combinatorial formula,"I am currently doing research on the symmetric qudit Dicke states, which are states symmetric under the permutation group. In the article ""Entanglement entropy in the Lipkin-Meshkov-Glick model,"" it is claimed in Eq. 5 that $$p_l=\frac{{L \choose l} {N-L \choose n-l}}{ {N \choose n}},$$ can be approximated for $N\, L\gg 1$ where $p_l$ represent the Clebsch-Gordon coefficients used in a Schmidt decomposition of the Dicke state. Specifically, they write ...the hypergeometric distribution of the $p_l$ can be recast into a Gaussian distribution $p_l\approx \frac{1}{\sqrt{2\pi}\sigma}\exp\left[- \frac{(l-\bar l)^2}{2\sigma^2}\right]$ , of mean value $\bar l=nL/N$ and variance $\sigma^2=n(N-n)(N-L)L/N^3$ , where we have retained the subleading term in $(N-L)$ to explicitly preserve the symmetry $L\to N-L$ . I am looking for a reference or an explanation of how this is achieved; I have used asymptotic formulas before, but never for something of combinatorial nature. Also, I am relatively unfamiliar with hypergeometric functions. Understanding this is important for me, because I am looking to extend this argument from $SU(2)$ to the $SU(2)_q$ , where the binomials in $p_l$ are replaced with $q$ -binomials . Edit: My research professor just sent me a wikipedia link that appears to make the same claim. I still don't understand how this approximation is found. Perhaps this link is relevant? Edit: Reached $1k$ reputation :)","['group-theory', 'combinatorics', 'asymptotics', 'hypergeometric-function']"
4719991,Domination Number of Random Graphs,"I am investigating the domination number of a random graph $G(n,1/2)$ on $n$ vertices. The edges are formed with probability $1/2$ . I know that the domination number of a complete graph $K_n = 1$ . I am thinking of two approaches to this investigation: From a complete graph $K_n$ any random graph that has less amount of edges than $K_n$ will have a high domination number, this means we can imagine a complete graph and we remove edges randomly and this domination number will keep increasing. How much is not an easy question. From the empty graph $E_n$ the domination number is $n$ . Here we can think of forming a graph randomly putting edges. In this approach the domination number will keep decreasing and it must approach $1$ since the domination number of a complete graph is $1$ Is there any improvement that can be made from this?","['graph-theory', 'random-graphs', 'discrete-mathematics']"
4720012,Classify all coherent sheaves on $\mathbb{A}^1_k$,"Given a field $K$ , I want to classify all coherent sheaves on $\mathbb{A}^1_k$ , and moreover saying if there exist locally free sheaves that are not free on $\mathbb{A}^1_k$ . I am following Gathmann's notes on Algebraic Geometry, thus I only know the following: The definition of quasi-coherent sheaf as sheaf of modules $\mathcal{F}$ on a scheme $X$ such that there is an affine open cover of $U_i=\operatorname{Spec} R_i$ with $\mathcal{F}$ restricted on the $U_i$ isomorphic to the sheaf $\tilde{M_i}$ associated to an $R_i$ -module $M_i$ ; The definition of coherent sheaf as above with the additional requirement that the $M_i$ are finitely generated $R_i$ -modules. To start, I know that $\mathbb{A}^1_k=\operatorname{Spec} K[x]$ . And I know that the structure sheaf is always quasi-coherent, so $O_{\operatorname{Spec} K[x]}$ is quasi-coherent, but I don't know why it is coherent, since this condition is not discussed on Gathmann's notes. How can I find the other coherent sheaves? Any help is much appreciated. Thanks in advance.","['quasicoherent-sheaves', 'coherent-sheaves', 'algebraic-geometry', 'sheaf-theory', 'schemes']"
4720027,Radon-Nikodym Density $\mathrm{d}\mathbb{P}/\mathrm{d}\mathbb{Q}$ if distribution of r.v. $X$ is known under $\mathbb{P}$ and $\mathbb{Q}$,"Assumptions Let $(\Omega,\mathcal{F})$ be a measurable space and $\mathbb{P}$ and $\mathbb{Q}$ two equivalent probability measures on $(\Omega, \mathcal{F})$ . Suppose $X: \Omega \rightarrow \mathbb{R}$ is a real-valued random variable with pdf $f_X^{\mathbb{P}}>0$ under $\mathbb{P}$ and $f_X^{\mathbb{Q}}>0$ under $\mathbb{Q}$ . Question Is it true that the Radon-Nikodym Density $\mathrm{d}\mathbb{P}/\mathrm{d}\mathbb{Q}$ is given by $$\mathrm{d}\mathbb{P}/\mathrm{d}\mathbb{Q} = \frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)}>0? $$ So far, I could figure out that it, first, has expectation under $\mathbb{Q}$ equal to 1: $$ \mathbb{E}_{\mathbb{Q}}\left[\frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)} \right] = \int\frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)} \mathrm{d}\mathbb{Q} = \int \frac{f_X^{\mathbb{P}}(x)}{f_X^{\mathbb{Q}}(x)} f_X^{\mathbb{Q}}(x) \mathrm{d}x = \int f_X^{\mathbb{P}}(x) \mathrm{d}x =1.  $$ and that, second, for all $A \in \mathcal{F}$ it holds $$ \mathbb{P}(A) = \int_A \mathrm{d} \mathbb{P} = \int_A \frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)} \frac{f_X^{\mathbb{Q}}(X)}{f_X^{\mathbb{P}}(X)} \mathrm{d}\mathbb{P} = \int_{A}  \frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)} \mathrm{d}\mathbb{Q} = \mathbb{E}_{\mathbb{Q}}\left[\frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)}\mathbf{1}_A\right].$$ Yet, I'm not sure whether this is enough as proof (I'm not a measure theory expert). Background Let $\mu>r>0$ , $\sigma>0$ and $T>0$ and $X$ be lognormal distributed in the following way under $\mathbb{P}$ : $X\overset{\mathbb{P}}{\sim} \mathrm{LN}((\mu-1/2\sigma^2)T,\sigma\sqrt{T})$ , and under $\mathbb{Q}$ : $X\overset{\mathbb{Q}}{\sim} \mathrm{LN}((r-1/2\sigma^2)T,\sigma\sqrt{T})$ Then $\mathrm{d}\mathbb{P}/\mathrm{d}\mathbb{Q} = \frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)} = \mathrm{exp}(\kappa Z -1/2\kappa^2T)$ where $Z \overset{\mathbb{Q}}{\sim} N(0,\sqrt{T})$ and $\kappa = (\mu-r)/\sigma$ . If the claim above was true, I could also compute the change of measure for different $\sigma$ under the two measures, i.e., $X\overset{\mathbb{P}}{\sim} \mathrm{LN}((\mu-1/2\sigma_1^2)T,\sigma_1\sqrt{T})$ and $X\overset{\mathbb{Q}}{\sim} \mathrm{LN}((r-1/2\sigma_2^2)T,\sigma_2\sqrt{T})$ ,  as $$\mathrm{d}\mathbb{P}/\mathrm{d}\mathbb{Q} = \frac{f_X^{\mathbb{P}}(X)}{f_X^{\mathbb{Q}}(X)}.$$","['measure-theory', 'probability-distributions']"
4720046,Is Sequence Convergence a topological Invariant?,"I am stuck on a question that goes like this: Let $(X, \mathcal{T})$ be a topological space, and let $A \subseteq X$ . $A$ is called sequentially closed if the limit point of every convergent sequence $\{x_n\} \subseteq A$ is in $A$ . We already know that every closed set is sequentially closed. $(X, \mathcal{T})$ is called sequential if every sequentially closed subset is closed. Show that the property of being sequential is a topological invariant. I have a solution but that relies on the postulate that sequence convergence is a topological invariant. Here is my proof: Let's suppose we have two topological spaces $(X, \mathcal{T})$ and $(Y, \mathcal{U})$ that are homeomorphic, with a homeomorphism $f: X \to Y$ . We want to show that if $(X, \mathcal{T})$ is sequential, then $(Y, \mathcal{U})$ is also sequential, and vice versa. First, let's prove that if $(X, \mathcal{T})$ is sequential, then $(Y, \mathcal{U})$ is sequential. We need to show that every sequentially closed subset $B \subseteq Y$ is closed in $(Y, \mathcal{U})$ Suppose $B$ is a sequentially closed subset of $(Y, \mathcal{U})$ . We want to prove that $B$ is closed in $(Y, \mathcal{U})$ . Consider the preimage $A = f^{-1}(B) \subseteq X$ . Since $f$ is a homeomorphism, $A$ is a subset of $X$ , and we have $f(A) = B$ Now, let ${y_n}$ be a convergent sequence in $B$ with limit point $y$ . Since $f$ is a homeomorphism, the preimage ${x_n} = f^{-1}({y_n})$ is a convergent sequence in $A$ with limit point $x = f^{-1}(y)$ . Since $A$ is sequentially closed in $(X, \mathcal{T})$ , $x$ belongs to $A$ .
By continuity of $f$ , we have $f(x) = y$ . Thus, $y$ is in the image of $A$ under $f$ , which is $B$ . Therefore, $B$ contains its limit point $y$ , and $B$ is closed in $(Y, \mathcal{U})$ . Hence, if $(X, \mathcal{T})$ is sequential, then $(Y, \mathcal{U})$ is also sequential The converse that $(X, \mathcal{T})$ is sequential if $(Y, \mathcal{U})$ is can also be proven in the same way as there was nothing special about $(Y, \mathcal{U})$ . Therefore, we have shown that the property of being sequential is a topological invariant. Any comments on my proof/idea is welcome. I need help in solving this problem.","['invariant-subspace', 'general-topology', 'functions']"
4720110,Equivalent for an integral,"I am looking for an equivalent (or something weaker) of the following integral: $$u_n=\int_{1}^{+\infty}e^{-t}\log^n(t)\,\mathrm dt$$ when $n\rightarrow\infty$ . I have tried some recurrence relations that leads to $u_n^{\frac{1}{n}}=o(n^{\epsilon})$ for any $\epsilon>0$ , but I'm sure it is possible to get something sharper. Any hint is welcome! Thank you.","['integration', 'sequences-and-series', 'asymptotics', 'real-analysis']"
4720176,"Evaluating $\int \sin^{7/2} x \,dx$","How can I evaluate $\int \sin^{7/2} x \,dx$ ? Actually, I know how to compute integral $\int \sin^{n} x dx $ where $n \in \mathbb N$ and I specifically chose $7/2$ I can generalize this as any $q \in \mathbb Q -\mathbb N$ . Also, there is no importance of $\sin x$ I can change it with $\cos x, \tan x$ I checked the calculators and they can not compute. I have an idea to write maclaurin series of sin and take its power then integrate but I am not sure","['integration', 'calculus', 'trigonometric-integrals', 'indefinite-integrals', 'hypergeometric-function']"
4720195,Well-defined set in naive set theory,"I am wondering what is a well-defined set in the context of Naive set theory (since Wikipedia says that Naive set theory is often sufficient to do math). Wikipedia says that “in Naive set theory, a set is described as a well-defined collection of objects.” Does well-defined here mean that given a collection of objects, it is a set if an element (anything) is either in it or not (no ambiguity)? Thank you!",['elementary-set-theory']
4720222,How can we solve the particular equation $16x^5-200x^3-200x^2+25x+30=0$ in closed form?,"How can we solve the following quintic in closed form ? $$16x^5-200x^3-200x^2+25x+30=0$$ What is special about this equation?  What can we say about solvability?  I'm not particularly into math.  I saw this equation in a discussion group.  Here are some ideas about the equation from non-mathematicians . There is no closed-form formula for $5$ -degree equations. Therefore there is no solution.  In my opinion this is wrong.  For example, $x^5=1$ can be easily solved.  The true version if that idea would be there is no general solution formula . (by radicals) The equation is not factored.  Therefore, there is no closed-form solution.  This idea is also wrong in my opinion.  Because the factors do not have to be rational numbers. Wolfram Alpha does not give closed form for the equation.  Therefore, it cannot be solved.  I cannot comment on this idea. I found that the quintic is irreducible over $\Bbb Q$ . I've heard a little bit about Galois theory.  But I don't have the mathematical knowledge.  If possible, could you help to find out if this equation is solvable?  The problem author argues that the equation has a solution. I tried WA software several times. But, it does not succeed.","['galois-theory', 'abstract-algebra', 'polynomials', 'radicals', 'algebra-precalculus']"
4720263,Hartshorne Chapter III: How to find an covering of a curve,"Hartshorne has an exercise given as follows ( Chatper III 10.6 ): Let $Y$ be the plane nodal cubic curve $y^2=x^2(x+1)$ . Show that $Y$ has a finite etale covering $X$ of degree $2$ , where $X$ is a union of two irreducible components, each one isomorphic to the normalization of $Y$ . This question/answer explores this exercise quite comprehensively. In particular, it says that the etale covering is given by the curve $\operatorname{Spec}k[s,t]/(t^2-(s^2-1)^2)$ . While I understand why this candidate works, what's more puzzling to me is how one can approach this problem and arrive at this very curve. What I understand is that we have a normalization of the curve $Y$ : its the affine line with the morphism induced by $t\mapsto (t^2-1,t(t^2-1))$ ; there are plenty of answer here that address this: for example this one and these ones: Finding normalization of nodal cubic , Normalization of a variety , normalization of the nodal cubic , so I'm comfortable with this. In particular, it makes sense why this would be its normalization and the morphism describes a parametrization of the nodal cubic. Now, with this knowledge equipped, how do one realize how to describe the curve $X$ ? We know that $X$ must be a union of two affine lines, where each is the normalization of $Y$ we saw earlier. Knowing just that, how do you the $X$ described as earlier is the correct idea? In fact, the irreducible components of $X$ are given by $\operatorname{Spec}k[s,t]/(t\pm(s^2-1))$ ; why are they isomorphic to the normalization of $Y$ ? Lastly, even if we knew the restriction morphism $(s,t)\mapsto (s^2-1,st)$ defined on $\mathbb{A}^2_k$ is the what describes $f$ , how do we arrive at the description of $X$ ? My question is quite fundamental: how does one approach questions of finding a (etale) covering of a given curve. For example, consider the cuspidal cubic curve $C=k[x,y]/(x^2-y^3)$ . How does one go about finding an etale covering of $C$ of an appropriate degree? In fact, if it's possible, how does one go about finding etale coverings of the nodal cubic curve a given degree? Any help will be extremely helpful! Thank you so much!","['algebraic-curves', 'algebraic-geometry', 'elliptic-curves']"
4720312,Can we construct an intersection of an ellipse and a circle sharing the same center when the center and five points on an ellipse is given? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I am given: Five points on the ellipse, The sharing center of the ellipse and the circle, And the circle. One of those five points is one of the intersections of a circle and an ellipse. Can we construct the three intersections of an ellipse and a circle that is not given? Blue ones are given, and greens are the points I want to find.","['conic-sections', 'geometry', 'geometric-construction']"
4720339,How do we maximize noise immunity between two combinational devices by choosing a single set of voltage thresholds?,"I am taking a course on MIT OCW entitled ""Computation Structures"". There is a problem in a problem set (Problem 2) that I'd like to solve mathematically. There is a solution to the problem , but it seems to have just the answer but not the work to get there. Now, there is a lot of domain specific knowledge here to understand what the math problem is. I will write out the problem statement, then try to explain the domain knowledge, and then reach the math problem. Here is the problem The following are voltage transfer characteristics of single-input,
single-output devices to be used in a new logic family Your job is to choose a single set of signaling thresholds $V_{OL},
 V_{IL}, V_{OH}$ , and $V_{IH}$ to be used with both devices to give the
best noise margins you can. Let me try to explain a bit about what the terms in the problem statement mean. Each of the two devices takes as an input a voltage and generates as output another voltage. Internally, each device interpret an input voltage as a 0 or 1 based on rules that we can summarize in the depiction below What this picture says is that input voltages below $V_{IL}$ are considered a 0, and input voltages above $V_{IH}$ are considered a 1. ""IL"" stands for ""Input Low"" and ""IH"" for ""Input High"". In addition, when generating an output voltage, the devices are specified to generate some voltage below $V_{OL}$ when they want to signal a 0, and to generate some voltage above $V_{OH}$ when they want to signal a 1. ""OL"" and ""OH"" stand for ""Output Low"" and ""Output High"". The graphs in the first picture show what each device outputs given each input. So, for example, in the first picture, we see that for low input voltages that device generates high output voltages. For the second device, low input voltages generate low output voltages, and high input voltages generate high output voltages. $V_{IL}, V_{IH}, V_{OL}$ , and $V_{OH}$ are like thresholds for specifying rules determining how a device interprets an input voltage and how it generates an output voltage. Here is an example of choices for these variables for one of the devices In this example, we have $$V_{OL}=0.5$$ $$V_{IL}=1.5$$ $$V_{IH}=3$$ $$V_{OH}=4.4$$ So, any input voltage of below 1.5V is interpreted by this device as a 0. If the device is to output a 1 signal for this input signal, then since it is generating an output voltage of 5 for these input voltages, we need to make sure that $V_{OH}$ is smaller than or equal to 5. Similarly, we see from $V_{IH}=3$ that any input voltage above 3 is interpreted as a 1, and to signal a 0 as output we need $V_{OH}$ to be larger than or equal to 0.5 (which are the voltages generated by the device for inputs $\geq 3$ ). Note that it must always be the case that $$V_{OL}<V_{IL}<V_{IH}<V_{OH}\tag{1}$$ otherwise it will be possible to have a valid input signal but an invalid output signal. That is, for example if $V_{OH}<V_{IH}$ for a device, then if this device wants to output a signal of 1, it may output a voltage $w$ such that $V_{OH}<w<V_{IH}$ . But then $w$ would not be interpreted as a 1 by another device with these same thresholds. Let's see a specification of the parameters that doesn't work. where all I did relative to the previous drawing was reduce $V_{IH}$ . Notice that the problem here is that there for input voltages between $V_{IH}$ and 3, we have a valid signal input of 1 but the device does not generate an output signal of 0 since these input voltages generate an output voltage that is above $V_{OL}$ . To try to fix this we would need to increase $V_{OL}$ , for example as below But now this is also an invalid specification because $V_{OL}=2>V_{IL}=1.5$ , which violates (1). We are almost at the actual problem. But first we need to define noise margin, which can be seen in the second picture above (starting at the top of the post). There are two noise margins $$V_{IL}-V_{OL}\tag{2}$$ $$V_{OH}-V_{IH}\tag{3}$$ These margins represent the amount of error we could have in an output voltage and still have that output signal the intended value. Ie, if the output voltage from a device is $V_{OH}-\epsilon$ , then if this value is above $V_{IH}$ it is still a 1 signal. Finally, noise immunity is defined as the smallest noise margin between the two. The math problem It is already a math problem to choose the parameters such that noise immunity is maximum, given (1). Then, the actual math problem in the original problem is to choose a single set of four parameters used for both devices and that maximizes the noise margins when we consider the two devices. Now, I think this means that we are trying to maximize the sum of the two noise immunities. For the problem of a single device, what I did was consider multiple cases for the value of $V_{IL}$ and try to go from there. I might write out this attempt in an answer, so that this question doesn't become too huge. Anyways, to sum up my question: how does one solve the original problem using just math (ie, without resorting to insights based on the the graphs presented initially)?","['optimization', 'multivariable-calculus']"
4720370,Is measure theory only for integrals?,"I am trying to self-study probabilistic measure theory after completing my undergrad degree, and I am curious if there are more interesting applications of measure theory aside from Lebesgue integration ? It seems like (correct me if I am wrong here) measure on its own is a rich field before delving in integration of measurable functions.","['applications', 'measure-theory', 'lebesgue-integral', 'probability']"
4720375,Compute the integral: $\int_{0}^{\frac{\pi}{2}}\ln(\sec(x)+\tan(x))\csc(x)dx$,"This question is originally a simplified version from a qualifying exam problem from Archimedean Integration Bee (Cambridge University). I tried doing angular symmetry but that gives me $$\int_{0}^{\frac{\pi}{2}}\ln(\csc(x)+\cot(x))\sec(x)dx.$$ I thought I could add both integrals and perform reverse product rule, but unfortunately $$\frac{d}{dx}\left [ \ln(\sec(x)+\tan(x))\ln(\csc(x)+\cot(x)) \right ]=\sec(x)\ln(\csc(x)+\cot(x))-\csc(x)\ln(\sec(x)+\tan(x)).$$ According to wolframalpha, the answer is $\frac{\pi^2}{4}$ . This made me think that it uses some sort of Taylor Series somewhere, or a certain identity, but what's the quick solution to this problem?","['integration', 'improper-integrals', 'definite-integrals', 'calculus', 'trigonometric-integrals']"
4720404,Inequality of $k$-th moment of independent sum,"Recently, I am self-studying Stanford Stat 300B and encounter an exercise in the problem set, which is to prove the following: Suppose that $X_i$ are independent mean-zero random variables with $\mathbb{E}[|X_i|^k]<\infty$ , let $S_n=\sum_{i=1}^n X_i$ and prove that: $$
\mathbb{E}[|S_n|^k]\leqslant C_k \mathbb{E}\left[\left(\sum_{i=1}^n X_i^2\right)^{\frac{k}{2}}\right].
$$ I have tried to expand left hand side into terms of $X_{i_1}^{\alpha_1}\cdots X_{i_t}^{\alpha_t}$ and use the fact of independency, but in vain. Can any body give me some hints on this problem, or provide the solution provided in https://web.stanford.edu/class/stats300b/exercise.html , since I don't have access to the solution link. Thank you very much!","['statistics', 'probability']"
4720412,"In $\Delta ABC$, $AC=\sqrt{3}AB$ and $BC=2$. D is a point inside $\Delta ABC$ such that $\angle BDC=90^\circ, \angle DAC=18^\circ$ and $BD=1$","Question: In $\Delta ABC$ , $AC=\sqrt{3}AB$ and $BC=2$ . D is a point inside $\Delta ABC$ such that $\angle BDC=90^\circ, \angle DAC=18^\circ$ and $BD=1$ , find $\angle BAD$ . I can solve this problem using trigonometry and I get $\angle BAD = 48^\circ$ . But I wonder if this can be done without the use of trigonometry. I have tried many different ways to construct isosceles triangles, adding new lines etc but still cannot solve the problem.","['contest-math', 'euclidean-geometry', 'geometry']"
4720414,How to find the number of solutions of $(0.01)^x=\log_{0.01}x$?,"How to find the number of solutions of $(0.01)^x=\log_{0.01}x$ ? I drew the graph of $a^x$ and $\log_ax$ , with $0<a<1$ , and thought they intersect just once. But the answer given is $3$ . Wolfram and Desmos have confirmed it. All three solutions are between 0 to 1. I tried taking $x$ as $0.01, 0.1, 0.5$ to see if I could make sense of the graph but not able to do so.","['contest-math', 'logarithms', 'calculus', 'algebra-precalculus', 'exponential-function']"
4720468,"If $x+xy+y=55$, what is $x+y$?","If $x,y\in \mathbb N$ is s.t. $$x+xy+y=55,$$ find $x+y$ ? I tried to write $x+xy+y=65$ as an equation of $x+y$ , but can't go anywhare : Using the fact that $$xy=\frac{1}{4}((x+y)^2-(x-y)^2,$$ I have that $$x+xy+y=55\iff (x+y)+\frac{1}{4}(x+y)^2-\frac{1}{4}(x-y)^2=65,$$ but I just transposed the problem with $x-y$ . Other things I tried is to replace $xy$ by $$\frac{1}{2}((x+y)^2-x^2-y^2)$$ but still, I can't do anything with $x^2+y^2$ . any idea ?",['algebra-precalculus']
4720489,Sum involving the Euler's Pentagonal Number function derivative.,"Being: $$\sum_{n=-\infty}^{\infty}(-1)^nq^{n(3n-1)/2}(3n^2-n) \tag{1},$$ it can be shown: $$\sum_{n=-\infty}^{\infty}(-1)^nq^{n(3n-1)/2}(3n^2-n)=-\frac{1}{12}(1-P(q))\prod_{n=1}^{\infty}(1-q^n)\tag{2},$$ where $$P(q)=1-24\sum_{n=1}^{\infty}\frac{nq^{n}}{1-q^{n}}\tag{3}.$$ Then beautiful series like: $$\sum_{n=-\infty}^{\infty}(-1)^ne^{-\pi n(3n-1)/2}(3n^2-n)=2^{1/8}e^{\pi/24}\left(\frac{\Gamma{(\frac{1}{4})}(6-\pi)}{24\pi^{7/4}}-\frac{\Gamma{(\frac{1}{4})}^5}{64\pi^{15/4}} \right)\tag{4},$$ can be obtained. Question Can we improve this result to the consecutive derivatives of $(2)$ and get a more general result?","['modular-forms', 'elliptic-functions', 'closed-form', 'sequences-and-series']"
4720491,$\lim\limits_{x \to \infty} \sqrt{\ln(x)} - \sqrt{\ln(x)-\ln(\ln(x))}$,"Question: Find $\lim\limits_{x \to \infty} \sqrt{\ln(x)} - \sqrt{\ln(x)-\ln(\ln(x))}$ For some independent work I would like to analyse this limit. Graphing it, I observe that the function reaches a unique global maximum. Examining the derivative I obtain that this holds when $$x^2 = \ln(x) \exp[(\ln(x)-1)^2]$$ But to obtain a closed form expression for $x$ seems not easy. And even if I prove this, it still doesn't help to compute the limit which is what I am really interested in. I also tried factoring $\sqrt{\ln(x)}$ and using L'Hopital but it didn't help much. I guess we can also just inspect $\sqrt{y} - \sqrt{y - \ln(y)}$ to understand what is really happening.","['limits', 'calculus', 'logarithms']"
4720493,"Find the distribution of $Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\}$ and converges in distribution","Let $(U_n)_n$ be a sequence of i.i.d random variables such that $U_{n} \sim U[0,1] \forall n$ . Define $Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\}$ , prove that $Y_n$ converges in distribution to a variable $Y$ , whose law must identify. Hint: Investigate beta distribution. My attempt: My idea was to use the distribution of the maximum in this case, thus obtaining that, for $n\in \mathbb{N}$ : $$\mathbb{P}(Y_{n}\leq y)=\mathbb{P}\left(\bigcap_{i=1}^{n}\{\frac{U_{i}}{i}\leq y\}\right)=\prod_{i=1}^{n}\mathbb{P}\left(\frac{U_i}{i}\leq y\right)$$ It follows: $$\mathbb{P}(Y_{1}\leq y)=y1_{[0,1]}(y)+1_{(1,+\infty)}(y)$$ $$\mathbb{P}(Y_{2}\leq y)=2y^{2}1_{[0,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y)$$ $$\mathbb{P}(Y_{3}\leq y)=6y^{3}1_{[0,1/3]}(y)+2y^{2}1_{(1/3,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y)$$ $$\vdots$$ Assuming that this development is correct. What would be the expression for $\mathbb{P}(Y_{n}\leq y)$ ? Does $Y_n$ converge in distribution to a beta random variable? Actualization: I obtain $\forall n\geq 2$ : $$\mathbb{P}(Y_{n}\leq y)=n!y^{n}1_{[0,1/n]}(y)+\sum_{k=1}^{n-1}k!y^{k}1_{\left(\frac{1}{k+1},\frac{1}{k}\right]}(y) + 1_{(1,+\infty)}(y)$$ But I can't see to which distribution this expression should converge.","['uniform-distribution', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
4720542,Is this a correct visualization of the topological quotient?,"I was trying to come up with a visual intuition of the smash product of two topological spaces, and ended up understanding it as the result of the following process: 1. start with the topological product, 2. cut along the wedge product of the two spaces (in two steps if need be), 3. stretch the sections until you can finally 4. join the sections along their cuts. Here are three examples of how I visualized $S^1\land S^1$ , $S^1\land[0,1]$ , and $[0,1]\land [0,1]$ . I then wondered if this process of ""cut, stretch, join"" applied to any topological quotient. Does it? Also, is $[0,1]\land [0,1]$ really a flower?",['general-topology']
4720565,Why this solids also lives below z axis?,"The base of a certain solid is the circle $x^2 + y^2 = a^2$ . Each plane perpendicular to the x-axis intersects the solid in a square cross-section with one side in the base of the solid. Find its volume. Here is my try : $$y = \sqrt{a^2-x^2}$$ $$dV = (a^2-x^2)dx$$ $$V= 8\int_0^a  (a^2-x^2)dx = \frac{16}{3}a^3$$ which is the correct answer given by textbook. I know that solid has eight octants, for the book answer is $16a^3/3$ , Can someone help me understand why it has 8 octants, I integrate one part of the solid and then multiply by eight, why do I have to multiply by eight instead of four? If the solids live above the z-axis then I have to multiply by four but in this case, how do I know the solid is also above the z-axis then multiply by eight","['integration', 'calculus', 'definite-integrals', 'solid-of-revolution']"
4720595,Prove that the sequence ($s_n$) is convergent if |$s_{n+1}$-$s_n$|<${1}/{2^n}$: Is my proof correct?,"Last week we had our long exam in Advanced Calculus/Real Analysis and this question was asked: Prove that the sequence ( $s_n$ ) is convergent if | $s_{n+1}$ - $s_n$ |< ${1}/{2^n}$ . My proof goes like this,
Proof:
Note that ${1}/{2^n}$ =| ${1}/{2^n}$ | for all natural numbers n. Thus, $|s_{n+1}-s_n|=|(s_{n+1}-s_n)-0|<{1}/{2^n}$ implies that ( $s_{n+1}$ - $s_n$ ) converges to $0$ . Hence, for every $\epsilon >0$ , there exists a natural number $K$ s.t if $n \geq K$ , then $|(s_{n+1}-s_n)-0|=|s_{n+1}-s_n|< \epsilon$ . Then, $n+1,n \geq K$ . And if we set $m:=n+1$ , we have $|s_{m}-s_n|<\epsilon$ . Hence, $(s_n)$ is a Cauchy sequence. Therefore, by Cauchy Convergence Criterion, ( $s_n$ ) is convergent. QED If I am wrong, can you please explain it why? I cannot get this question out of my head. Thank you.","['calculus', 'real-analysis']"
4720617,How to show $\int_0^\infty \frac{t\ln x}{(x+1)^2+t^2}dx=\frac12\arctan(t)\ln(1+t^2)$ [duplicate],"This question already has answers here : Contour integral for finding $\int_0^\infty \frac{\ln x}{(x+a)^2+b^2} \, dx$ (3 answers) Closed last year . In this post , it mentions the following result without giving a proof. $$\int_0^\infty \frac{t\ln x}{(x+1)^2+t^2}dx=\frac12\arctan(t)\ln(1+t^2)\tag{1}$$ I know how to compute the case for $$\int_0^\infty \frac{t\ln x}{x^2+t^2}dx$$ after do the sub $x=ut$ , $$\int_0^\infty \frac{t\ln x}{x^2+t^2}dx=\int_0^\infty \frac{\ln u}{u^2+1}du+\int_0^\infty \frac{\ln t}{u^2+1}du=0+\frac\pi2\ln t$$ But for (1) there is a shift for $x\to x+1$ , and we can't use the way we did above. How should I prove this result? Any hint will be appreciated.","['integration', 'complex-analysis', 'improper-integrals', 'real-analysis']"
4720643,Question about notation of symmetry permutations in tensors,"In Introduction to Smooth Manifolds, John Lee writes: $$
{ }^\sigma \alpha\left(v_1, \ldots, v_k\right)=\alpha\left(v_{\sigma(1)}, \ldots, v_{\sigma(k)}\right)
$$ Note that ${ }^\tau\left({ }^\sigma \alpha\right)={ }^{\tau \sigma} \alpha$ , where $\tau \sigma$ represents the composition of $\tau$ and $\sigma$ , that is, $\tau \sigma(i)=\tau(\sigma(i))$ . (This is the reason for putting $\sigma$ before $\alpha$ in the notation $\alpha$ , instead of after it.) Later on, he writes:
If $\tau \in S_k$ is any permutation, then $$
\begin{aligned}
(\operatorname{Sym} \alpha)\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right)
& =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\sigma}\alpha\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right) \\
& =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\tau \sigma} \alpha\left(v_1, \ldots, v_k\right)
\end{aligned}
$$ Question: Why is it $\tau\sigma$ and not $\sigma\tau$ ? $\tau$ is being applied first and so it must stand second, right?","['permutations', 'tensors', 'tensor-products', 'differential-geometry']"
4720683,Integral inequality involving modulus,"Suppose $f,g \in C^{1}([0,1])$ with $f(x) \ge c > 0$ and $g$ can take negative values. Question: Is it true that $$ \left| \int_{0}^{1} f(x)g(x)~dx \right| \ge  c \left| \int_{0}^{1}g(x)~dx\right| $$ I think that it could be false if we take a $g$ which is oscillating and $f$ chosen appropriately so that  the integral of the product is $0$ but the integral of $g$ is non-zero (the oscillation will have to be so that the area bounded by the curve and the x-axis in the region where it is negative must be larger than the area where it is positive). I am not entirely sure if my intuition is correct however so I would appreciate a counterexample or a proof. Thank you!","['calculus', 'functional-analysis', 'analysis', 'real-analysis']"
4720692,Does this definition of the element come from the definition of the set? [duplicate],"This question already has answers here : Does mathematics become circular at the bottom? What is at the bottom of mathematics? [duplicate] (8 answers) Closed 9 months ago . I've gotten some contradictory answers on where the definition of the element within a set comes from. From a quick Google search, I got this strange idea that the definition of the element comes from the definition of a set. I reached this conclusion because some websites state simply that the element is A member of a set But I feel this results in some type of circular logic (At least I think that's what this logical fallacy is called). Since the definition of a set is A set is a collection of objects whose contents can be clearly
determined. The objects in a set are called the elements of the set. (Robert blitzer college algebra) I am almost certain that the issue here lies in the definition of an element I found, But I can't seem to find a definition of the element that is independent of the set so to speak. I hope you guys can help clear this up for me thanks","['elementary-set-theory', 'logic']"
4720761,$n$ Mice Problem: Description of the position of the mouse when a certain distance has been covered.,"Problem Introduction Question The Mice Problem : In the mice problem [...] $n$ mice start at the corners of a regular $n$ -gon of unit side length, each heading towards its closest neighboring mouse in a counterclockwise direction at constant speed. [...] - Weisstein, Eric W. ""Mice Problem."" From MathWorld--A Wolfram Web Resource. I would like to calculate the distance of the closest mice given a distance traveled $s$ . Background If you're wondering why I want to calculate this, I just read about the problem in Math World > History and Terminology Disciplinary Terminology Biological Terminology > Mise Problem . That's when I saw the animations of the mise and wanted to animate them too. The connection between this problem and the Whirl struck me, and that's when the question came up after the Whirl gave me a context. With a few seconds of thinking I figured that position doesn't just depend on distance traveled, previous position and speed, so it should change to an ODE / PDE, which sounds like a fun project. My Two Best Trys Numerical Trys A plot of the first $3$ steps ( $\color{green}{\frac{1}{2}}$ distance and $\color{orange}{\frac{1}{4}}$ distance (for the first step)): Are $\left( x_{1}, y_{1} \right)$ the coordinates of one mouse $a_{1}$ and $\left( x_{2}, y_{2} \right)$ those of the other, then $a_{2} = \left( \frac{x_{1} + x_{2}}{2}, \frac{y_{1} + y_{2}}{2} \right)$ when half distance. Now say that $\left( x_{n}, y_{n} \right)$ are the coordinates of the other mouse in $n - 1$ step: $$
\begin{align*}
a_{1} &= \left( x_{1}, y_{1} \right)\\
a_{2} &= \left( \frac{x_{1} + x_{2}}{2}, \frac{y_{1} + y_{2}}{2} \right)\\
a_{3} &= \left( \frac{\frac{x_{1} + x_{2}}{2} + x_{3}}{2}, \frac{\frac{y_{1} + y_{2}}{2} + y_{3}}{2} \right)\\
&\dots\\
a_{n} &= \left( \frac{\frac{\frac{\frac{x_{1} + x_{2}}{2} + x_{3}}{2} + \ddots}{\ddots} + x_{n}}{2}, \frac{\frac{\frac{\frac{y_{1} + y_{2}}{2} + y_{3}}{2} + \ddots}{\ddots} + y_{n}}{2} \right)\\
\end{align*}
$$ So $\lim\limits_{n \to \infty}\left[ a_{n} \right] = 0$ . The whole thing is the same for each step for any distance with small changes in the formula, but the appearance changes only minimally. If we do this for all points, we could represent the distance between the points as infinite continued fractions, but that's not exactly what I want. Try with Polar Coordinates You could also try the pursuit curve to determine which describes the positions of the mise in space: Let's say $r_{m}$ is the perimeter of the polygon in at $m$ . If we form the gradient of one of the lines we are looking for into a subwhirl, we get $\Delta = \frac{r \cdot \sin\left( \theta + \frac{2 \cdot \pi}{n} \right) - r \cdot \sin\left( \theta \right)}{r \cdot \cos\left( \theta + \frac{2 \cdot \pi}{n} \right) - r \cdot \cos\left( \theta \right)} = \frac{\left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right) \cdot \sin\left( \theta \right) + \sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \cos\left( \theta \right)}{\left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right) \cdot \cos\left( \theta \right) - \sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \sin\left( \theta \right)}$ . For this we assume that the polygons have been wired for $y$ -axis symmetry. Since they move the mice on their respective pursuit curve, the following applies: ""The slope of the line is also equal to the derivative of the pursuit curve."" aka: $$
\begin{align*}
\frac{\operatorname{d}y}{\operatorname{d}x} &= \frac{r' \cdot \sin\left( \theta \right) + r \cdot \sin'\left( \theta \right)}{r' \cdot \cos\left( \theta \right) + r \cdot \cos'\left( \theta \right)}\\
\frac{\operatorname{d}y}{\operatorname{d}x} &= \frac{\cos\left( \theta \right)\, \operatorname{d}\theta + \sin\left( \theta \right)\, \operatorname{d}r}{\cos\left( \theta \right)\, \operatorname{d}r - \sin\left( \theta \right)\, \operatorname{d}\theta}\\
\end{align*}
$$ Both equations describe the same thing aka $\Delta = \frac{\operatorname{d}y}{\operatorname{d}x}$ applies, which means that: $$
\begin{align*}
\Delta &= \frac{\operatorname{d}y}{\operatorname{d}x}\\
\frac{\left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right) \cdot \sin\left( \theta \right) + \sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \cos\left( \theta \right)}{\left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right) \cdot \cos\left( \theta \right) - \sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \sin\left( \theta \right)} &= \frac{\cos\left( \theta \right)\, \operatorname{d}\theta + \sin\left( \theta \right)\, \operatorname{d}r}{\cos\left( \theta \right)\, \operatorname{d}r - \sin\left( \theta \right)\, \operatorname{d}\theta}\\
\end{align*}
$$ Wolfram|Alpha simplifies the whole thing to $\sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \frac{1}{r}\, \operatorname{d}r = \left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right)\, \operatorname{d}\theta$ aka we'll get (assuming $r \in \mathbb{R}^{+})$ : $$
\begin{align*}
\sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \frac{1}{r}\, \operatorname{d}r &= \left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right)\, \operatorname{d}\theta\\
\int \sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \frac{1}{r}\, \operatorname{d}r &= \int \left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right)\, \operatorname{d}\theta\\
\sin\left( \frac{2 \cdot \pi}{n} \right) \cdot \int \frac{1}{r}\, \operatorname{d}r &= \left( \cos\left( \frac{2 \cdot \pi}{n} \right) - 1 \right) \cdot \theta + \text{cconstant}\\
\int \frac{1}{r}\, \operatorname{d}r &= \frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \theta + \text{constant}\\
\ln\left( r \right) &= \frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \theta + \text{constant}\\
r &= e^{\frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \theta + \text{constant}}\\
\end{align*}
$$ We can determine the constant by the boundary condition that there are at least $3$ points lying on the unit circle. Let's just say that the curve $\left( 1,\, \frac{3 \cdot \pi}{2} - \frac{\pi}{n} \right)$ goes, then $\text{costant} \equiv \frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \left( \frac{\pi}{n} - \frac{3 \cdot \pi}{2} \right)$ holds. We can now rotate the spiral arbitrarily by an angle $\theta_{0}$ in order to define it for the other mises and not for the $y$ -axis symmetrical polygons: $$\fbox{$
\begin{align*}
r &= e^{\frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \left( \theta - \theta_{0} \right) + \frac{\cos\left( \frac{2 \cdot \pi}{n} \right) - 1}{\sin\left( \frac{2 \cdot \pi}{n} \right)} \cdot \left( \frac{\pi}{n} - \frac{3 \cdot \pi}{2} \right)}\\
\end{align*}
$}$$ Checking the formula for some examples like a rectangle seems to work aka I assume the formula is right: However, I have some problems with the curve: Of course I could use it to determine the distances between the mise, but only as a function of the angle $\theta - \theta_{0}$ and not the distance. We could calculate the arc length from the angle, but the resulting integral seems a bit too complicated to me. In addition, I can't really understand the simplification that led to the result and I can't reconstruct it either... But for the record: $$
\begin{align*}
\operatorname{arc length}\left( \begin{matrix} t_{1}\\ t_{2}\\ \end{matrix};\, y\left( x \right) \right) &= \int\limits_{t_{1}}^{t_{2}} \sqrt{\operatorname{d}x + \operatorname{d}y}\, \operatorname{d}t\\
\operatorname{arc length}\left( \begin{matrix} t_{1}\\ t_{2}\\ \end{matrix};\, r\left( t \right) \right) &= \int\limits_{t_{1}}^{t_{2}} \sqrt{\left( \frac{\operatorname{d}r\left( t \right)}{\operatorname{d}t} \right)^{2} + \left( r\left( t \right) \right)^{2} \cdot \left( \frac{\operatorname{d}\theta\left( t \right)}{\operatorname{d}t} \right)^{2}}\, \operatorname{d}t\\
\operatorname{arc length}\left( \begin{matrix} \theta\left( t_{1} \right)\\ \theta\left( t_{2} \right)\\ \end{matrix};\, r\left( t \right) \right) &= \int\limits_{\theta\left( t_{1} \right)}^{\theta\left( t_{2} \right)} \sqrt{\left( \frac{\operatorname{d}r\left( \theta \right)}{\operatorname{d}\theta} \right)^{2} + \left( r\left( \theta \right) \right)^{2}}\, \operatorname{d}\theta\\
\end{align*}
$$","['integration', 'ordinary-differential-equations', 'geometry', 'calculus', 'polar-coordinates']"
4720764,Solving an inexact ODE,"Given the ODE: $y'=\frac{2x^2y-xy^2+0.5y^2}{x^2-xy+y-1}$ Given that $M(x,y) = -2x^2y+xy^2-0.5y^2$ and $N(x,y)= x^2-xy+y-1$ , $N_x \neq M_y$ , I've been trying to look for an integration factor to make this ODE an exact one.
The Integration factor I've found is: $ \mu(x) = \frac {e^{-2x+2}}{(x-1)^2}$ But that dosen't make the ODE exact. I've triple checked my way of solving and I can't find any reason to that error.
I did try finding an integration factor for the variable $y$ but that doesn't solve it either. My way of finding the integration factor: $ \frac{M_y-N_x}{N(x,y)} = \frac{-2x^2+2xy-y-(2x-y)}{x^2-xy+y-1} =\frac{-2x^2+2xy-2x}{x^2-xy+y-1} = \frac{-2x(x-y+1)}{(x-1)(x-y+1)} = \frac{-2x}{x-1}$ $ \mu(x)  = e^{\int\frac{-2x}{x-1}dx} $ $=  e^{-2x+2-2\ln(x-1)}  = e^{-2x+2} \cdot \frac{1}{(x-1)^2}  $",['ordinary-differential-equations']
4720767,Question about notation $f(x)=O(g(x))$ over the base $\mathcal{B}$,"The following definitions are taken from Zorich's book and I am fairly familiar with them, but I noticed one interesting point that I had not noticed before. Definition 1. A set $\mathcal{B}$ of subsets $B\subset X$ of a set $X$ is called a base in $X$ if the following conditions hold: $\forall B\in \mathcal{B} \ (B\neq \varnothing)$ ; $\forall B_1\in \mathcal{B} \ \forall B_2\in \mathcal{B} \ \exists B\in \mathcal{B} \ (B\subset B_1\cap B_2)$ Definition 2. We shall say a certain property of functions or a certain relation between functions holds ultimately over a given base $\mathcal{B}$ if there exists $B\in \mathcal{B}$ on which it holds. Definition 3. Let us agree that the notation $f=O(g)$ over the base $\mathcal{B}$ means that the relation $f(x)=\beta(x)g(x)$ holds
ultimately over $\mathcal{B}$ where $\beta(x)$ is ultimately bounded
over $\mathcal{B}$ . Let us write Definition 3 in more detail. The notation $f=O(g)$ over the base $\mathcal{B}$ means that $\exists \beta:X\to \mathbb{R}$ and $\exists B_1\in \mathcal{B}$ such that $\forall x\in B_1$ we have $f(x)=\beta(x)g(x)$ and $\exists B_2\in \mathcal{B}$ such that $\forall x\in B_2$ we have $|\beta(x)|\leq C$ . By definition of base it follows that $\exists B_3\subset B_1\cap B_2$ and we notice that $\forall x\in B_3$ we have $|f(x)|=|\beta(x)||g(x)|\leq C|g(x)|$ . Can we summarize it as follows? If $f(x)=O(g(x))$ over the base $\mathcal{B}$ , then $\exists C>0
 \ \exists B_3\in \mathcal{B}: \forall x\in B_3 \ (|f(x)|\leq C|g(x)|)$ I don't think that we can do it because the constant $C>0$ depends on $B_3$ and $B_3$ depends on $\beta$ . For example, Wikipedia says that $f(x)=O(g(x))$ as $x\to +\infty$ if there exists a positive real number $M$ and a real number $x_0$ such that $$|f(x)|\leq M|g(x)| \quad \text{for all} \quad x\geq x_0.$$ I'd be very grateful if you can explain my question please! Thank you!","['functions', 'asymptotics', 'real-analysis']"
4720781,Question about the scalar second fundamental form being proportional to the hessian of the defining function,"I'm working on problem 8.3 of Lee's Riemannian Manifold textbook:
let $\Omega \subset R^{n+1}$ be an open set, $F:\Omega\rightarrow R$ a smooth submersion, and $M=F^{-1}(0)$ . Show the scalar second fundamental form of M with respect to the unit normal vector field $N=grad F/\|grad F\|$ is given by $h(V,V)=-\frac{\partial_i\partial_jFV^{i}V^j}{\|gradF\|}$ , where $V=V^i\partial_i$ in the Euclidean coordinates on $R^{n+1}$ . (the original book had an error and the corrected form is given here). I made two attempts. I wonder why they differ from each other AND the true answer: #1 The scalar second fundamental form is the inner product between the second fundamental form and the unit normal. The definition of the second fundamental form: $II(V,V)=\tilde \nabla_VV-\nabla _VV$ , where $\tilde \nabla$ is the connection in the ambient euclidean space and $\nabla$ on the manifold). If I take the inner product with the unit normal on both sides, since $\langle\nabla_VV,N\rangle=0$ , I get the scalar second fundamental form $h(V,V)=\langle II(V,V),N\rangle=\langle\tilde\nabla_VV,N\rangle=\langle V(V^i)\partial_i,(\partial_iF)\partial_i/|gradF| \rangle =V(V^i)(\partial_iF)$ . This is clearly not right so what's wrong?? Is expanding $gradF$ into $\partial_iF\partial_i$ right? Is doing the inner product this way (only taking the coefficients of $\partial_i$ on both terms and multiply them) correct? #2
The other way is to use the Weingarten equation: $h(V,V)=\langle N,II(V,V)\rangle=-\langle\tilde\nabla_VN,N\rangle=-\langle V(N^j)\partial_j,V^j\partial_j\rangle=V^i\partial_i(\partial_jF/|gradF|)V^j$ . Now from here, if I treat $|gradF|$ as constant and take it outside of the $\partial_i$ , then I would recover the solution. But I can't see a reason why that is the case. If I continue the derivation, I get: $(\partial_i\partial_jF / |grad F| + \partial_jF\partial_iF/|gradF|^3)V^iV^j$ . So what's wrong in my derivation?? I would really appreciate any help!! Thanks!!","['riemannian-geometry', 'differential-geometry']"
4720786,How can I solve this challenging card counting problem?,A deck of 52 cards is shuffled and evenly split amongst 13 people(4 cards each). What is the probability that one of them has exactly 2 aces and 2 others have exactly 1 ace each? I feel like a good way to think about this would be to divide the number of ways to place 2 aces in one sequence of 4 cards and 1 ace in two sequences of 4 cards each by the number of ways to place 4 aces in 52 cards(52C4). I'm really confused about how to calculate the numerator though. Any insights on how to solve this? Would also appreciate general tips for solving more challenging counting problems.,"['combinatorics', 'card-games', 'probability']"
4720816,"If $\sin x+\sin y+\sin z=2$, $\cos x+\cos y+\cos z=11/5$, $\tan x+\tan y+\tan z=17/6$, $x,y,z\in\mathbb{R},$ find $\sin(x+y+z)$ without a calculator","Given $$\begin{align}
\sin x+\sin y+\sin z &=2 \\[4pt]
\cos x+\cos y+\cos z &=\frac{11}{5} \\[4pt]
\tan x+\tan y+\tan z &=\frac{17}{6}
\end{align}$$ where $x,y,z\in\mathbb{R}.$ Find the value of $\sin{(x+y+z)}$ , without a calculator. By ""without a calculator"", I mean without any electronic computing device, i.e. just pen and paper. I do not know if such a solution is possible. I made up this problem. The answer is $4/5$ , but I don't know how to find it without a calculator. When making the problem, to get nice numbers in the question and answer, I let $x=y=\arctan\frac34$ and $z=\arctan\frac43$ . My attempt: Let $A=\cos x, \space B=\cos y, \space C=\cos z$ . Since $\sin x+\sin y+\sin z=2$ , we know that $\sin x$ , $\sin y$ , $\sin z$ are all non-negative. So we get the following two equations with $A$ and $B$ : $$\sqrt{1-A^2}+\sqrt{1-B^2}+\sqrt{1-(2.2-A-B)^2}=2$$ $$\frac{\sqrt{1-A^2}}{A}+\frac{\sqrt{1-B^2}}{B}+\frac{\sqrt{1-(2.2-A-B)^2}}{2.2-A-B}=\frac{17}{6}$$ But I don't know how to solve for $A$ and $B$ , nor $\sin{(x+y+z)}$ . I also tried, without success, to use the identities $$(\sin x+\sin y+\sin z)^2+(\cos x+\cos y+\cos z)^2$$ $$=3+2(\cos{(x-y)}+\cos{(y-z)}+\cos{(z-x)})$$ $$\sin x=\frac{2\tan\frac{x}{2}}{1+\tan^2\frac{x}{2}}$$ $$\cos x=\frac{1-\tan^2\frac{x}{2}}{1+\tan^2\frac{x}{2}}$$ I also tried, without success, to use complex numbers.","['trigonometry', 'systems-of-equations', 'complex-numbers']"
4720840,a surpring thing about the hook formula,"The hook formula gives the dimension of the irreducible representations of the symmetric group $S_N
$ . I note that this is an amazing formula even from the point of view of a middle school student. It is too obvious at all the formula will yield an integer! Could anyone give a proof of this fact? Not to prove the formula, just to prove that the value is an integer not merely a rational number.","['number-theory', 'combinatorics', 'representation-theory']"
4720889,Expected Value of the Difference of Two Dice,"Problem : If a six-sided die is fair, what is the expected value of the difference between two die rolls? Attempted solution : The expected value can be thought of as the midpoint of the outcomes. If the die is rolled twice, the difference of the two sides could be $$0,0,0,0,0,0,1,1,1,1,1,2,2,2,2,3,3,3,4,4,5$$ The midpoint is then $1$ . Here, I have assumed that two rolls with sides $4,5$ is the same as $5,4$ . Is there a more sensible way to answer this problem?","['expected-value', 'dice', 'probability-theory', 'probability']"
4720975,Is the set of 'crossing points' of every curve closed?,"I want to know if the following statement is true or not: $\gamma : [a, b] \to \mathbb{R}^k$ is continuous then $E := \{ t \vert \exists s \neq t: \gamma (t) = \gamma (s) \}$ is closed. So here, $E$ is just the set of 'crossing points' of the curve $\gamma$ . I hope this is true so that I can find 'the first' crossing point $t_0 = \min (E)$ . I found the statement is true for a special case where $\gamma$ is a polygonal path(finite number of consecutive line segments) but failed in this general case. Edit: The statement is simply false, as the counterexamples in the comments show.
What I wanted to prove was the existence of $\min (E)$ and I succeeded with polygonal path since it had a simple structure: finite number of edges.
My question was messed up while thinking about the general case. FYI, My original problem was Show that any closed polygonal path can be decomposed into a finite union of simple closed polygonal paths , which is Exercise 8.7 of Joseph Bak, Complex Analysis. Here I wanted to use $\min (E)$ and got curious about the general case.",['analysis']
4720984,Two forms of the Specification Axiom and their relations,"I have seen two slightly different forms of the axiom schema of specification. a) For each formula $\psi(x,t)$ , the following is an axiom: $\forall t\forall A\exists B\forall x(x\in B\leftrightarrow x\in A\land \psi(x,t))$ . b) For each formula $\psi(x)$ , the following is an axiom: $\forall A\exists B\forall x(x\in B\leftrightarrow x\in A\land\psi(x))$ . I know that a) implies b) because a formula $\psi(x)$ in which $t$ occurs as a bound variable can also be written as $\psi(x,t)$ . And my question is, does b) imply a)? And I found that one could use either a) or b) to construct the set $\{x\in\mathbb{C}:x\in\mathbb{R}\}$ . a) provides an easy approach; using b), however, requires lots of effort. Using a): Let $\psi(x,t)=x\in t$ . Then we have $\forall t\forall A\exists B\forall x(x\in B\leftrightarrow x\in A\land x\in t)$ . In particular, for sets $\mathbb{R}$ (playing the role of $t$ ) and $\mathbb{C}$ (playing the role of $A$ ), there exists a (unique) set $B$ such that $\forall x(x\in B\leftrightarrow x\in\mathbb{C}\land x\in\mathbb{R})$ . Using b): We need to first rewrite the property $x\in\mathbb{R}$ as a formula $\psi(x)$ . It is this process that requires lots of effort. After obtaining the formula $\psi(x)$ , one could deduce from b) that $\forall A\exists B\forall x(x\in B\leftrightarrow x\in A\land\psi(x))$ .In particular, for the set $\mathbb{C}$ (playing the role of $A$ ), there exists a (unique) set $B$ such that $\forall x(x\in B\leftrightarrow x\in \mathbb{C}\land\psi(x))$ , i.e., $\forall x(x\in B\leftrightarrow x\in \mathbb{C}\land x\in\mathbb{R})$ . I'm so confused about these two  approaches that seem to be so different from each other. A related question :
One can easily justify the existence of the intersection of any two sets using a). Just take $\psi(x,t)=x\in t$ and then deducing that $\forall t\forall A\exists B\forall x(x\in B\leftrightarrow x\in A\land x\in t)$ . But is it possible to construct $A\cap B$ for all $A$ and $B$ using b)?  Here is what puzzles me: Suppose that $A$ and $B$ are any sets. If we intend to apply b) to construct the intersection $A\cap B$ , then a formula $\psi(x)$ is needed.It seems that "" $x\in B$ "" is the right formula. However, as I understand it, $B$ is a free variable in "" $x\in B$ "", while the symbol $\psi(x)$ indicates that the only possibly free variable is $x$ . I can't tell whether $B$ is free or not in "" $x\in B$ "". If not, then it is a $\psi(x)$ and we're finished.","['predicate-logic', 'first-order-logic', 'logic', 'elementary-set-theory', 'set-theory']"
4720998,Prove that the orthogonal projection $P$ does not depend on the chosen orthonormal basis used in the construction of $P$,"Let $\left\{e_1, \ldots, e_n\right\}$ be a finite orthonormal system in an inner product space $(E,\langle\cdot, \cdot\rangle)$ and let us abbreviate $F:=\operatorname{span}\left\{e_1, \ldots, e_n\right\}$ . The mapping $$
P: E \longrightarrow E, \quad P f=\sum_{j=1}^n\left\langle f, e_j\right\rangle e_j
$$ is called the orthogonal projection onto the subspace $F$ . I would like to prove that $P$ does only depend on the subspace $F$ and not on the chosen orthonormal basis of $F$ used in the construction of $P$ . My attempt Let $f, g \in E$ such that $g \in F$ and $f-g \perp F$ , I have to prove that $g=P f$ . Since $f-g \perp F$ and $f-Pf\perp F$ , we have that $$\langle f-g, e_i\rangle=\langle f-Pf, e_i\rangle=0\quad \forall i$$ then $$\langle f-g, e_i\rangle-\langle f-Pf, e_i\rangle=0$$ and so $$\langle f-g -(f-Pf), e_i\rangle=0\quad \forall i$$ from which $$\langle Pf-g, e_i\rangle=0\quad \forall i$$ And now? How could I proceed? I think that $Pf-g\perp F$ is not true, so we should have $Pf=g$ .","['projection', 'functional-analysis']"
4721012,Riesz-Markov theorem and positive linear functionals on real-valued continuous functions,"Riesz-Markov theorem : Let $X$ be a locally compact Hausdorff space. For any continuous linear functional $\Psi$ on $C_0(X)$ , there is a unique regular countably additive complex Borel measure $\mu$ on $X$ that $$ \forall f \in C_0(X): \Psi(f)=\int_X f(x)d\mu(x). $$ The norm of $\Psi$ as a linear functional is $||\Psi||=|\mu|(X)$ . Finally, $\Psi$ is positive if and only if the measure $\mu$ is non-negative. The different versions I have found of the Riesz-Markov theorem do not specify if the set of continuous functions on X which vanish at infinity are real or complex valued functions.
I want to say that if I have a positive linear functional defined on $C^\mathbb{R}_0(X)$ where $X$ is a compact Hausdorff space, and $||\Psi||=1$ , then the measure given by the theorem is a probability measure. Any help on this topic? Thanks.","['measure-theory', 'borel-measures', 'riesz-representation-theorem', 'real-analysis', 'functional-analysis']"
4721056,"Mathematical Analysis I by Zorich: show $f^{-1}(f(A)) \supset A$, $f(f^{-1}(B^{'})) \subset B'$","I ask someone to check if my proof is correct. I'm self-studying Mathematical analysis by Zorich and the book doesn't have any answers, so I would like to catch any logical mistakes early on. Very not sure about the second question in particular. Let $f:X\rightarrow Y$ be a map from $X$ to $Y$ . Show that for any $A \subset X$ and any $B^{'}\subset Y$ : $f^{-1}(f(A)) \supset A$ $f(f^{-1}(B^{'})) \subset B'$ 1} Let $x \in A$ . Then $f(x) \in f(A)$ . Then $f^{-1}(f(x))=x \in f^{-1}(f(A))$ . So $A \subset f^{-1}(f(A))$ . 2} Let $y \in f(f^{-1}(B^{'}))$ . Then $f^{-1}(y) \in f^{-1}(B^{'})$ . Then $f(f^{-1}(y))=y  \in f(f^{-1}(B^{'}))=B^{'}.$ So $f(f^{-1}(B^{'})) \subset B^{'}$ 1_edited) Let $x \in A$ . Then $f(x) \in f(A)$ . Then $x \in f^{-1}(f(x)) \subset f^{-1}(f(A))$ . So $A \subset f^{-1}(f(A))$ 2_edited) Let $y∈f(f^{−1}(B′))$ . Then $f^{−1}(y) \subset f^{−1}(B′)$ . Then $f(f^{−1}(y)) \subset f(f^{−1}(B′))=B′.$ So $f(f^{−1}(B′))⊂B′$ .",['elementary-set-theory']
4721059,Determinant of all possible matrices with elements $\pm 1$,"Given that A is an element of set $\mathbb{B}$ consisting of all $N\times N$ matrices with elements $\pm 1$ , how can I find the following sum: \begin{equation}
\sum_{A\in \mathbb{B}} \det(A) 
\end{equation} My initial approach was to use elementary row operations to reduce the matrix to the following form: \begin{equation}
\begin{bmatrix}
1 & 0 \\
0 & A^{N-1}
\end{bmatrix}
\end{equation} where $A^{N-1}$ consists of elements $\{-2,0,2\}$ . Since each row has those elements, we can divide each row to 2. That will reduce the determinant to $2^{N-1}A'$ . But the road ended here. My insight is that, as we have $\pm 1$ for each element, determinants should cancel out and give $0$ .","['matrices', 'determinant', 'linear-algebra']"
4721061,Proving a polynomial to be positive for all real values,"I'm trying to prove the following theorem: $$\sum_{j=0}^{2n} (-x)^j >0\ \forall x \in \mathbb{R}, n \in \mathbb{N}  $$ I have verified this theorem for $n=1$ (just a quadratic) and for $n=2$ (by simple factoring). However I'm stuck for higher values of $n$ and generalizing it. I'm thinking of proving this by proving it to be positive for one value of $x$ ( $x=0$ should suffice) and then proving it has no real roots. I'm not sure how to do this though.",['algebra-precalculus']
4721109,How to show that $\coth(\frac z2) = \frac{\sinh(x)-i\sin(y)}{\cosh(x)-\cos(y)}$ [duplicate],"This question already has answers here : Troubles with the following trigonometric identity (2 answers) Closed last year . How would I show that $\coth(\frac z2) = \frac{\sinh(x)-i\sin(y)}{\cosh(x)-\cos(y)}$ What I've done so far is using the definitons for $coth(z), cosh(z)$ and $sinh(z)$ and Euler's identity as follows: \begin{align}
\coth(z/2) &= \frac{\cosh(z/2)}{\sinh(z/2)} \\
\\
 & = \frac{\cosh(\frac{x+iy}{2})}{\sinh(\frac{x+iy}{2})} \\ 
\\
 & = \frac{e^{(x+iy)/2}+e^{-(x+iy)/2}}{e^{(x+iy)/2}-e^{-(x+iy)/2}} \\
\\
 & = \frac{(e^{x/2}e^{iy/2})+(e^{-x/2}e^{-iy/2})}{(e^{x/2}e^{iy/2})-(e^{-x/2}e^{-iy/2})} \\
\\
 & = \frac{(e^{x/2}(\cos(\frac y2)+i\sin(\frac y2))+(e^{-x/2}(\cos(\frac y2)-i\sin(\frac y2))}{(e^{x/2}(\cos(\frac y2)+i\sin(\frac y2)))-(e^{-x/2}(\cos(\frac y2)-i\sin(\frac y2))} \\
\\
 & = \frac{\cos(\frac y2)\cosh(\frac x2) + i\sin(\frac y2)\sinh(\frac x2)}{\cos(\frac y2)\sinh(\frac x2) + i\sin(\frac y2)\cosh(\frac x2)}
\end{align} From this point on, I don't see how to factor or cancel terms so that I'm left with the desired expressions.","['calculus', 'solution-verification', 'trigonometry', 'algebra-precalculus', 'complex-numbers']"
4721112,Finite dimensional cokernel of a map coming from a product Fedholm map,"Let $X$ , $Y_1$ , $Y_2$ be Banach spaces (if that helps I will be happy to assume they are Hilbert spaces) and let \begin{align}
T_1 : X \rightarrow Y_1, \\
T_2 : X \rightarrow Y_2
\end{align} be bounded linear maps such that $T:= T_1 \times T_2 : X \rightarrow Y_1 \times Y_2$ is a Fredholm map. Is it true that $T_1|_{\ker T_2}$ is also Fredholm? Its kernel is finite-dimensional since it is the kernel of $T$ but why is the cokernel finite-dimensional?","['hilbert-spaces', 'banach-spaces', 'functional-analysis', 'analysis']"
4721123,"Prove $\tan x + \tan y + \tan z \le \frac{17}{6}$ for reals $\sum\limits_{\mathrm{cyc}} \sin x = 2, \sum\limits_{\mathrm{cyc}} \cos x = \frac{11}{5}$","Problem . Let $x, y, z$ be real numbers
with $\sin x + \sin y + \sin z = 2$ and $\cos x + \cos y + \cos z = \frac{11}{5}$ .
Prove that $$\tan x + \tan y + \tan z \le \frac{17}{6}.$$ I found this inequality when I dealt with this question: If $\sin x+\sin y+\sin z=2$, $\cos x+\cos y+\cos z=11/5$, $\tan x+\tan y+\tan z=17/6$, $x,y,z\in\mathbb{R},$ find $\sin(x+y+z)$ without a calculator In detail, I let $\sin x = \frac{2a}{1 + a^2},  \cos x = \frac{1 - a^2}{1 + a^2}, 0 \le a < 1$ etc. and use Mathematica to find
the maximum and minimum of $\frac{2a}{1-a^2} + \frac{2b}{1 - b^2} + \frac{2c}{1 - c^2}$ subject to $\frac{2a}{1 + a^2} + \frac{2b}{1 + b^2} + \frac{2c}{1 + c^2} = 2$ and $\frac{1 - a^2}{1 + a^2}
+ \frac{1 - b^2}{1 + b^2} + \frac{1 - c^2}{1 + c^2} = \frac{11}{5}$ .
Mathematica output: The maximum is simply $\frac{17}{6}$ when $a = 1/3, b = 1/3, c = 1/2$ .
The minimum
is $984703/350796$ when $a = 9/32, b = 19/43, c = 19/43$ . I want to see a human verifiable proof.","['maxima-minima', 'algebra-precalculus', 'trigonometry', 'inequality']"
4721127,Calculus using degrees,"Is it possible to do integration with degrees rather than radians with trigonometric functions? For example, if I want to find $\int_{0}^{180} \sin(x) \,dx $ where $x$ is measured in degrees, I can write it as $\int_{0}^{180} \sin(\frac{x\pi}{180})\,dx $ where $x$ is measured in radians, however this gives me $\frac{360}{\pi}.$ And if I wanted to differentiate $\sin(x)$ where $x$ is in degrees, I can get $\frac{\pi}{180} \cos(x).$ To get the correct answer for the  integral, which is $2$ , I have to cancel $\frac{180}{\pi}$ down to 1; why?","['integration', 'trigonometry', 'derivatives']"
4721157,"Is it possible to find a universal $\delta_U$, such that $|x-y|<\delta_U\Longrightarrow |f_n(x)-f_n(y)|<\epsilon, \forall n=\color{red}0,1,2\dots$","Suppose $f_n(x)$ ( $n=1,2,\dots$ ) are continuous on $[a, b]$ , $f_n(x)\rightarrow f(x)$ pointwisely, and $f(x)$ is continous on $[a, b]$ . Define $f_0(x)=f(x)$ . We know continuous on compact set implies uniformly continuous, hence $f_n(x)$ ( $n=\color{red}0, 1,2,\dots$ ) are uniformly continuous on $[a,b]$ . Then for any fixed $\epsilon>0$ , we can find $\delta_0>0, s. t,~|x-y|<\delta_0\Longrightarrow|f(x)-f(y)|<\epsilon$ . Similarly, we can find $\delta_n>0, s. t,~|x-y|<\delta_n\Longrightarrow|f_n(x)-f_n(y)|<\epsilon$ . My question is, If we define the set $S=\{\delta_k|k=0,1,2\dots\}$ , how can we say about $\inf S$ ? For exmaple, we can always make $\inf S=0$ , we can find $\delta'>0, s. t,~|x-y|<\delta'\Longrightarrow|f_1(x)-f_1(y)|<\epsilon$ . Set $\delta_1=\min(\delta', \frac12\delta_{0})$ we can find $\delta''>0, s. t,~|x-y|<\delta''\Longrightarrow|f_2(x)-f_2(y)|<\epsilon$ . Set $\delta_2=\min(\delta'', \frac12\delta_{1})$ Keep going, we can guarantee $\delta_n\le\frac12\delta_{n-1}$ , hence $\inf S=0$ . But is it possible to construct $\delta_n$ such that $\inf S>0$ ? If this is possible (or with some additional conditions), then it means we can find a universal $\delta_U$ , such that whenever $|x-y|<\delta_U\Longrightarrow |f_n(x)-f_n(y)|<\epsilon, \forall n=\color{red}0,1,2\dots$","['uniform-continuity', 'analysis', 'real-analysis', 'continuity', 'sequences-and-series']"
4721159,Find the domain of $f(x)=\sqrt{\sin(\sin(\sin x))}$,"Find the domain of $f(x)=\sqrt{\sin(\sin(\sin x))}$ My Attempt: $\sin(\sin(\sin x))\ge0$ $\sin(\sin x)\in[0,1]$ $\sin x\in[0,\arcsin1]$ $x\in[0,\arcsin(\arcsin1)]$ Is this correct? Wolfram doesn't seem to agree.","['contest-math', 'calculus', 'functions', 'solution-verification']"
4721190,Difference between measure-theoretic integral and differential-geometric integral,"In measure theory on $\mathbb{R}^n$ , whenever you need an integral, you induce it from the measure $m$ of the space you are working with using the Lebesgue-integral: $$\int_{M} f \,\mathrm{d}m.$$ Obviously, this brilliant concept was not going to work smoothly on curved manifolds, since we do not have a uniform coordinate system and what used to be a rectangle in one coordinate system, becomes a parallelogram in the other - complete mess! So we cannot just write $$\int_{M} 1 \,\mathrm{d}m = \operatorname{vol}(M)$$ since we would be getting different, coordinate-dependent volumes for the same figures. The solution, as given in most differential geometry books, is to induce the measure from the tangent spaces via the anti-symmetric covariant tensor fields, aka differential n-norms, which give you a ""signed length meter to each 1-dimensional subspace of each tangent space in a coordinate independent way"". In other words, we get stuff like ""the integral of the covector field $\omega$ over a curve $\gamma$ "": $$\int_{\gamma} \omega = \int_{[a,b]} \gamma^*\omega$$ or integrate the covector field $\omega$ over $U$ (well-definedly using coordinate charts) $$\int_{U} \omega = \int_{\varphi(U)} (\varphi^{-1})^* \omega$$ QUESTION At this point, I lost the connection between the original problem and the proposed solution. Our problem was that we cannot measure volumes because of the coordinate dependency. Is my understanding correct that we replace sets (whose volumes we want to measure) by expressing these sets as images of $\mathbb{R}^k$ -valued functions and accordingly integrating $k$ -forms over them? If that is so, is there an intuitive, non-rigorous way to explain why a real number that we get in the end for the integral is not coordinate-dependent? Any other comments about further conceptual differences between two approaches are welcomed.","['integration', 'measure-theory', 'lebesgue-integral', 'differential-forms', 'differential-geometry']"
4721232,A confusing question about adding an element to a set,"The following question was discussed in my Discrete Math class, but we couldn't reach a consensus. Think of a set as a collection of bins . Each bin contains exactly one object distinct from all others. While we are allowed to move the objects around between bins, we cannot remove any object, nor can we place two objects into the same bin. Someone hands us a new object. Can we place that object into a bin, after moving around some of the objects already sitting in bins? A. Yes, for some sets this works just fine. B. Sets are not composed of bins and this question makes no sense whatsoever. C. No, there is no room for another object, all bins are already filled. D. It depends on the new object. I'll try to summarize the general arguments for why each answer is correct or incorrect: A: A few of us think this is right, because we can insert the new object into the set iff it's not already in it. However, this is similar to answer choice D, which was given to be wrong (see below). B: Many of us shy away from the answer because it ""sounds"" incorrect, but I personally believe this is the right answer. This is because I disagree with the representation of a set as a collection of bins (each of which contains exactly one object), for the simple reason that the model does not seem to account for adding new bins (and hence does not account for adding new elements). C: Some thought this was correct, if we assume that the number of bins cannot increase (i.e. if we cannot add elements to the set). Some thought this was incorrect for the same reason; because it would mean we can't add any elements to the set at all. This answer was given to be wrong. D: Most thought this was correct - if the new object is different from all the objects already in the set, then we can add it, and otherwise we can't. However, this answer was given to be wrong. And the fact that this is wrong seems to also imply A is wrong (i.e. the intended answer isn't talking about whether or not the element is already in the set). Could someone give a justified answer to this question using concepts from Discrete Math and Set Theory?","['elementary-set-theory', 'discrete-mathematics']"
4721250,Chain rule (multivariate) and implicit differentiation problem,"I have been worked out a solution for the following problem, but I am wondering if there is an easier way to solve it. I would be very grateful for any suggestions! Let $z=f(x,y)$ a function of two independent variables $x$ . and $y$ . Show that, if we perform a change of variables with $u$ and $v$ $u=x^2+y^2$ and $u=e^{\frac{y}{x}}$ , then $$x \frac{\partial z}{\partial x} + y \frac{\partial z}{\partial y} = 2v \frac{\partial z}{\partial v} \:.$$ My solution: By the multivariate chain rule, we have $$\frac{\partial z}{\partial v} = \frac{\partial z}{\partial x} \cdot \frac{\partial x}{\partial v} + \frac{\partial z}{\partial y} \cdot \frac{\partial y}{\partial v}
\:.$$ Hence it is sufficient to show that $\frac{\partial x}{\partial v} = \frac{x}{2v}$ and $\frac{\partial y}{\partial v} = \frac{y}{2v}$ . There are two ways in which we can do this (I will consider only $\frac{\partial x}{\partial v}$ ): Either we calculate the partial derivatives $\frac{\partial v}{\partial x}$ , $\frac{\partial v}{\partial y}$ , $\frac{\partial u}{\partial x}$ and $\frac{\partial u}{\partial y}$ and use the fact that, by the inverse function rule , $$
\begin{bmatrix}
    \frac{\partial x}{\partial v} & \frac{\partial x}{\partial u} \\
    \frac{\partial y}{\partial v} & \frac{\partial y}{\partial u}
\end{bmatrix}
=
\begin{bmatrix}
    \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \\
    \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y}
\end{bmatrix}^{-1}
$$ to obtain $$\frac{\partial x}{\partial v} = \frac{\frac{\partial u}{\partial y}}{\frac{\partial v}{\partial x} \cdot \frac{\partial u}{\partial y} - \frac{\partial v}{\partial y} \frac{\partial u}{\partial x}} = \frac{x}{2v}
.$$ Or we simply notice that $\ln(u) = \frac{y}{x}$ and thus $y = x \cdot \ln(u)$ . Substituting this into $v=x^2+y^2$ , we get $x^2=\frac{v}{1+[\ln(u)]^2}$ and, if we partially differentiate both sides with respect to $v$ , we obtain $2x\frac{\partial x}{\partial v} = \frac{1}{1+[\ln(u)]^2} = \frac{1}{1+\left[\frac{y}{x}\right]^2} = \frac{x^2}{x^2+y^2} = \frac{x^2}{v}$ , as required.","['multivariable-calculus', 'change-of-variable', 'implicit-differentiation', 'partial-derivative', 'chain-rule']"
4721257,Getting the original matrix from the projection,"If I have the projection matrix of $X$ , $$
P = X\,{(X^TX)}^{-1} X^T, 
$$ how can I recover $X$ by only knowing $P$ ?
Is there a way to do that?","['projection-matrices', 'matrices', 'linear-algebra', 'matrix-equations', 'matrix-decomposition']"
4721311,Determine the equations of the circles,"EXERCISE: Determine the equations of the circles that pass through the points $(2, 3)$ and $(3, 6)$ , and are tangent to the line $2x + y − 2 = 0.$ My idea was, first, to notice that the points $(2,3)$ and $(3,6)$ belong to the circle, then substitute in the general equation the equation of a circle. Thus I arrived at the equation of the possible centers of the circumference. Then, it remained to look for the circles with a center satisfying the equation that I found, and that were tangent to the line $2x+y-2=0,$ so I calculated the distance between a possible center and the tangent and said that this was equal to the radius. But then I didn't know what to do. I hope someone can help me to solve it","['analytic-geometry', 'circles', 'geometry']"
4721318,Problem 1.5.17 in Karatzas and Shreve,I'm reading through Karatzas and Shreve Browninan motion and stochastic calculus and the problem $5.17$ asks: The solution of this problem is based on localization and is included on the book: I understand how they define the process $\langle X\rangle_t$ however I think that this definition works for almost every $\omega\in \Omega$ as we could have a set of probability zero such that $R_n$ doesn't converge. I also can't see why the process is adapted for the same reason.,"['stochastic-processes', 'probability-theory', 'probability']"
4721350,Changing Variables in Discrete Calculus,"In discrete calculus one soon meets the $h$ -difference operator $$\Delta_h[f(x)] = f(x+h) - f(x)$$ and we often define $\Delta = \Delta_1.$ We can similarly define the indefinite sums $\Delta_h^{-1}$ and set $\Delta^{-1} = \Delta_1^{-1}.$ Most books on discrete calculus only include results for $h=1.$ For example, the above link gives that $$\Delta^{-1}\sin rx = \frac{-\cos(r[x-\frac{1}{2}])}{2\sin\frac{r}{2}}$$ Through an ugly computation I managed to work out that $$\Delta_h^{-1}[\sin rx] = \frac{-\cos(r[x-\frac{h}{2}])}{2\sin\frac{rh}{2}}$$ What I'd like is a uniform procedure for recovering the "" $h$ -version"" from such results. How could I have derived the second formula from the first? Is there something like the change of variable formula in calculus? Maybe some version of 'dimensional analysis' that tells you where to insert $h$ 's? As another example, given that $$\Delta[\log x] = \log(1 + \frac{1}{x})$$ I'd like to be able to see immediately that $$\Delta_h[\log x] = \log(1 + \frac{h}{x})$$ Any help or references would be welcome.","['summation', 'calculus', 'discrete-mathematics', 'discrete-calculus', 'finite-differences']"
