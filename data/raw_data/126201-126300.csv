question_id,title,body,tags
1917298,Finding the MLEs of the Odds Ratio and the Log-Odds Ratio,"Take two random variables $Y$ and $Z$ with support $\{1,2\}$ each, and let
$p_{i,j} = P(Z = i,Y = j).$ We define the odds ratio to be
$$\psi = \frac{p_{1,1}p_{2,2}}{p_{1,2}p_{2,1}}$$
and the log-odds ratio to be
$$\gamma = \log(\psi).$$ I want to show that the MLE for $\psi$ is
$\hat{\psi} = \frac{X_{1,1}X_{2,2}}{X_{1,2}X_{2,1}}$
where
$X_{i,j} = \#\{Z = i \wedge Y = j\},$
and I want to show that the MLE for $\gamma$ is
$\hat{\gamma} = \log(\hat{\psi}).$ The MLE for $\gamma$ is trivial given the property of equivariance of
estimators. I do see that $$\hat{\psi} = \frac{\hat{p}_{1,1}\hat{p}_{2,2}}{\hat{p}_{1,2}\hat{p}_{2,1}}.$$ Although this is again using equivariance of estimators. What I would like to
consider is how to get the MLEs for $\hat{p}_{i,j}, (i,j) \in \{1,2\}^2$.
However, I am having difficulty figuring out how to find the MLEs of
my data, since it seems as though the only realized random variable is
$X = (X_{1,1},X_{1,2},X_{2,1},X_{2,2}).$ How do I go about finding this
MLE?","['statistics', 'probability']"
1917304,Intermediate measure theorem?,"Statement: Let $\lambda$ be the Lebesgue measure on the real line and $f$ be a continuous function. For every $0\le\epsilon \le 1$, there is a compact set $S\subseteq [0,1]$ with $\lambda(S) = \epsilon$ and \begin{align*}
\int_0^1 f(x)\mathbf{1}_S(x)\, \lambda(\mathrm{d}x) = \epsilon\int_0^1 f(x)\,\lambda(\mathrm{d}x)\,\,.
\end{align*} Is this statement true? If so, what would be the name of this principle? I only work with discrete mathematics in my day-to-day life and I apologize if this question is too naive.","['lebesgue-measure', 'integration', 'lebesgue-integral', 'measure-theory']"
1917313,Combinatorial proof of a binomial identity: $\sum_k \binom {2r} {2k-1}\binom{k-1}{s-1} = 2^{2r-2s+1}\binom{2r-s}{s-1}$,"I am to find a combinatorial argument for the following identity: $$\sum_k \binom {2r} {2k-1}\binom{k-1}{s-1} = 2^{2r-2s+1}\binom{2r-s}{s-1}$$ For the right hand side, I was think that would just be number of ways to choose at least $s-1$ elements out of a $[2r-s]$ set. However, for the left hand side, I don't really know what it is representing. Any help would be greatly appreciated!","['combinatorics', 'summation', 'binomial-coefficients', 'combinatorial-proofs']"
1917319,Square roots in ring of strictly upper triangular matrices,"Let $k$ be field, $M_n(k)$ the algebra of $n\times n$ matrices over $k$, and let $N\subset M_n(k)$ be the subring of strictly upper triangular matrices in $M_n(k)$.  Note that every element of $N$ is nilpotent. Let $N^2=\{X^2|X\in N\}$, i.e. the set of matrices in $N$ with a square root in $N$.  My question is: can we describe $N^2$? I conjecture that it is $N^2$ is the set of all matrices with zeroes below the second main diagonal, i.e.
$$
\begin{pmatrix}0 & 0 & * & \cdots & *
\\\vdots & \ddots & \ddots & \ddots &
\\ & & &\ddots & *
\\ \vdots & & &  \ddots & 0
\\ 0 & \cdots & & \cdots & 0
\end{pmatrix}
$$
where $*$ denotes any element of $k$. Thoughts/ideas?  Any help is appreciated!","['matrices', 'linear-algebra', 'algebraic-geometry']"
1917364,Verifying a combinatorics problem: choosing 54 numbers out of 108?,"I have the problem and a proposed solution, however I want to verify that it's correct, as sometimes I struggle visualizing combinatorics. Let's say you have a grid of 108 squares. You have 54 blue and 54 red balls. How many different ways can you place the blue and red balls? My proposed solution: assign each square a number 1-108. That leaves us 108 numbers. Because it's the same number of red and blue balls, you can just ask the question: ""how many different ways can I place blue or red balls on this grid?"" or the same as saying $108 \choose 54$ which is over $2 * 10^{31}$ . Is this correct? Out of curiosity, how would you approach it if there weren't the same number of red and blue balls?","['combinations', 'combinatorics']"
1917378,How to find the determinant of this matrix [duplicate],"This question already has answers here : Determinant of circulant-like matrix (2 answers) Closed 5 years ago . I've got to calculate determinant for this matrix:
$$\begin{bmatrix} a_{ 1 } & 0 & 0 & \cdots  & 0 & b_{ n } \\ b_1 & a_2 & 0 & \cdots  & 0 & 0 \\ 0 & b_2 & a_3 & \cdots  & 0 & 0 \\ \vdots  & \vdots &  & \vdots & \vdots & \vdots \\ 0 & 0 & 0 & \cdots & a_{n-1} & 0 \\ 0 & 0 &  0& \cdots & b_{n-1} & a_n \end{bmatrix}$$
Is there any clever way to find out the determinant of above matrix? Thanks in advance.","['matrices', 'determinant']"
1917410,How to compare the values $\sqrt 2$ and $\ln(3).$,How to compare the values $\sqrt 2$ and $\ln(3)?$ I know only $\ln(x)<x$ and $\sqrt{x}<x$. Please help. Thanks.,"['real-analysis', 'real-numbers']"
1917422,Question about associated points in Vakil's notes,"I have a question about Exercise 5.5.E in Vakil's algebraic geometry notes.  Here's the statement: Show that the locus on $\text{Spec } A$ of points $[p]$ where $\mathcal{O}_{\text{Spec } A;[p]} = A_p$ is nonreduced is the closure of those associated points of $\text{Spec } A$ whose stalks are non reduced. The statement of the problem further indicates that we are supposed to do this using the following two properties of associated points: A. The associated points of $\text{Spec }A$ are precisely the generic points of irreducible components of the support of some element of $A$. B. $\text{Spec }A$ has finitely many associated points. My problem is that I seem to have solved it using A but not B! Question : Where did I go wrong? Here's my purported solution.  I will use A repeatedly (without comment), but I will never use B: Assume first that $[p]$ is an associated point of $\text{Spec } A$ where $A_p$ is non-reduced and $[q]$ is a point in the closure of $[p]$.  We then have $p \subset q$, and thus $A_p$ is a localization of $A_q$.  If $A_q$ were reduced, then this would imply that $A_p$ is reduced; we therefore deduce that $A_q$ is non-reduced. Now assume that $[r]$ is a point of $\text{Spec } A$ where $A_r$ is non-reduced.  Our goal is to prove that $[r]$ is in the closure of some associated point $[s]$ where $A_s$ is non-reduced.  Since $A_r$ is non-reduced, there exists some $f \in A$ and $n \geq 2$ and $x \in A \setminus r$ such that $x f^n = 0$, but where $y f \neq 0$ for all $y \in A \setminus r$.  Set $g = x f$.  We then have $g^n = 0$, but $y g \neq 0$ for all $y \in A \setminus r$.  This implies that $[r] \in \text{Supp } g$.  Moreover, since $g$ itself is nilpotent it witnesses the fact that $A_{r'}$ is non-reduced for all points $[r']$ in $\text{Supp } g$.  In particular, if $[s]$ is the generic point of an irreducible component of $\text{Supp } g$ containing $[r]$, then $[s]$ has the desired property.",['algebraic-geometry']
1917449,Rotate polygon around center and get the coordinates,"First off I am a computer programmer, so excuse my lack of math understanding. Also I know this question has been asked before, but the answers don't seem to apply to this specific situation. Given a polygon, which is made up of points. For example: [{""x"":301.1848472789287,""y"":216.523742955658},{""x"":299.92410285162424,""y"":241.37037128550003},{""x"":296.227787218953,""y"":264.523742955658},{""x"":290.347798182831,""y"":284.40599394956655},{""x"":282.68484727892877,""y"":299.6621817189641},{""x"":273.761151947722,""y"":309.25262227940857},{""x"":264.18484727892877,""y"":312.523742955658},{""x"":254.60854261013552,""y"":309.25262227940857},{""x"":245.6848472789288,""y"":299.6621817189641},{""x"":238.02189637502653,""y"":284.40599394956655},{""x"":232.14190733890456,""y"":264.523742955658},{""x"":228.44559170623327,""y"":241.37037128550003},{""x"":227.1848472789288,""y"":216.52374295565804},{""x"":228.44559170623327,""y"":191.67711462581605},{""x"":232.14190733890456,""y"":168.52374295565807},{""x"":238.02189637502653,""y"":148.64149196174952},{""x"":245.68484727892877,""y"":133.38530419235195},{""x"":254.60854261013552,""y"":123.79486363190748},{""x"":264.18484727892877,""y"":120.52374295565804},{""x"":273.761151947722,""y"":123.79486363190746},{""x"":282.68484727892877,""y"":133.38530419235192},{""x"":290.347798182831,""y"":148.64149196174947},{""x"":296.2277872189529,""y"":168.52374295565798},{""x"":299.92410285162424,""y"":191.67711462581596}] Where each coordinate is in the global coordinate system (top left is 0,0 and right and down is positive). I want to figure out where each point would be if I were to rotate the polygon around it's center (is that called centroid?). These polygons may be whatever a user decides to draw on the screen, so they might be concave or convex or anything. In the array of coordinates above, it is a circle as a bunch of points. So basically instead of rotating the shape and keeping the points local, I want to move the points in the global coordinate system, and figure out where they should be when rotated around a point. I know in the past I used matrix math, but I am just not sure how to do it. I've been at this for weeks now. I believe it's something like moving the shape to 0,0 and rotating it to 0 and doing the rotation matrix on the shape and moving it back but it does not seem to work for me. Edit: I know the center of the bounding box of the polygon.","['matrices', 'trigonometry', 'rotations', 'geometry']"
1917451,Show that $\int_{\partial P}z\frac {f'(z)} {f(z)} dz $ is on the lattice $\Lambda$,"Problem: Let $f(z)$ be a meromorphic function on the complex torus $\mathbb C/\Lambda$ that as a function on $\mathbb C$ has no zeros and no poles on $\partial P$, the boundary of the fundamental parallelogram $P$. Show that \begin{equation}
                \frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz \in \Lambda \, .
\end{equation} Thoughts: By the Residue Theorem 
\begin{equation}
\frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz = \sum_{z_0 \in \text{ Int }P} v_{z_0}(f)z_0.
\end{equation}
 I don't know why the latter is on the lattice. Thanks!","['riemann-surfaces', 'complex-analysis', 'differential-geometry']"
1917459,find all $f$ satisfying $f * f = 1$,"Let $f : \mathbb{N} \rightarrow \mathbb{C}$. Find all $f$ satisfying $$f*f = 1,$$ that is $$\sum_{d|n} f(d)f(\frac{n}{d}) = 1$$ for all $n \in \mathbb{N}.$ Sol. Clearly, $f(1) = 1$ or $f(1) = -1$
Assume first $f(1) = 1$. Let $p$ be prime. Then $$1 = 2f(p).$$ Now, for any $p, q$ distinct prime, $$1 = 2f(pq) + 2f(p)f(q)$$ which yields $f(pq) = 1/4.$
I guess that $f(p_1p_2...p_k) = 1/2^k$, but proving  by induction involves a complicated terms. Moreover, for general $n$, I am not sure for possible formula. Any help, or suggestion for a more effective ways to deal with this question ?","['number-theory', 'analytic-number-theory']"
1917471,Easing function: Ease-out-in (opposite of Ease-In-Out),"I'm seeking an easing function that is the twin of the popular Ease-In-Out easing function-- Desired Behaviour Begins quickly, slows down in middle, ends quickly. References Keep your eye on the black portion of the screen in this Sonic Heroes Stage Intro animation. Notice how the black screen gives way quickly at first, slows down when the screen is half-revealed, then quickly disappears. https://youtu.be/pnLvwfvHCV4?t=71 Here's a quick reference of what the graph should look like My attempts at curve fitting and experimentation haven't given me the equation / function I need, unfortunately. Any help would be appreciated!","['bezier-curve', 'functions']"
1917476,Regularity of rational functions at infinity,"I'm confused about this basic notion in algebraic geometry. If $u$ has an expression $u = p/q$, where $q(P) \neq 0$, then we call $u$ a regular function at $P$. Now we would like to know which rational functions (of one variable) are regular at the point at infinity in projective space. So if we have $u(x) = p(x)/q(x)$, we can homogenize this, and look at its representation in projective space. In particular, we want the denominator to be non-zero at the point $[1:0]$ of projective space. Here's my problem. It is claimed in this question here: Which rational functions $\mathbb{P}^1\rightarrow k$ are regular at the point at infinity? that the rational functions regular at infinity have degree of $q$ at least that of degree of $p$. I don't understand why this is true. Consider the rational function defined by $p(x) = x^2 + x + 1$, and $q(x) = x + 1$. We can homogenize this guy, and assuming I didn't goof any arithmetic, the result is $\frac{x^2 + xy + y}{x+y}$. My problem is that the denominator is not $0$ at infinity, although $\deg q < \deg p$. What am I not understanding about this process?","['algebraic-curves', 'algebraic-geometry']"
1917480,Calculate $\lim_{n\to\infty}\frac{e^\frac{1}{n}+e^\frac{2}{n}+\ldots+e}{n}$,"Calculate $$\lim_{n\to\infty}\frac{e^\frac{1}{n}+e^\frac{2}{n}+\ldots+e^\frac{n-1}{n}+e}{n}$$by expressing this limit as a definite integral of some continuous function and then using calculus methods. I've worked this out with a friend and we've come to the conclusion that this is equivalent to $\int e^\frac{x}{n}\,dx$. However, we would like a confirmation that this is what the above evaluates to.","['calculus', 'limits']"
1917484,$g_n$ converges to $0$ in $L1$ implies $fg_n$ converges to $0$ in $L1$,"Let $f:X\rightarrow \mathbb{C}$ be an integrable function and $g_n:X\rightarrow \mathbb{C}$ be a sequence of integrable functions so that $\|g_n\|_1\rightarrow 0$ and $|g_n(x)|\leq 1$ for every $n, x$. Show that $\|fg_n\|_1\rightarrow 0$. I think the $|g_n(x)|\leq 1$ part is only so we can say $g_n \geq g_n^2$, but that's just intuition. There is no obvious inequality (Holder came to my mind...) Any suggestions?","['lp-spaces', 'measure-theory', 'convergence-divergence']"
1917511,Given a matrix of the form $A=a\otimes b$ then $|A|_{nm}=|a|_{n} |b|_{m}$,"I consider this matrix in $\mathbb{M}^{m\times n}$
$$A=a\otimes b,$$ with $b\in \mathbb{R}^m$ and $a\in\mathbb{R}^n$. I would like to prove that $|A|_{nm}=|a|_{n} |b|_{m}$,
where $|.|_{p}$ is the module on $\mathbb{R}^p$. Is there a simple way to prove this? Should I use some other matrix norms to prove that?
Thanks for the help!","['matrices', 'normed-spaces', 'tensor-products']"
1917513,How does this inequality follow from Hölder's inequality?,"In a paper that I am reading, an inequality is given and the justification is Hölder's inequality:
$$\left(\sum_{i=1}^n a_{ii}\right)^m \le n^{m-1} \sum_{i=1}^n a_{ii}^m$$
where $a_{ii}\ge0$ for all $i$. However, I do not know why the justification works. I've tried justifying it by writing $a_{ii}$ as $a_{ii}\cdot1$, then applying the inequality. I get somewhat close, since $n$ raised to a power comes out as a factor, but unfortunately I'm not arriving at the above inequality.","['real-analysis', 'inequality', 'holder-inequality', 'summation']"
1917520,Do fiber functors have adjoints?,"Let $X$ be a nice connected topological space, and $x\in X$ a point. Let $F$ be the functor from covering spaces of $X$ to $\textbf{Sets}$ given by sending $Y\stackrel{f}{\rightarrow} X$ to the fiber $f^{-1}(x)$. Does this have an adjoint? (I don't really have any good reason for thinking that it might, but I'm just curious) If not, is there a good reason it doesn't? EDIT: What if I were to restrict $F$ to finite covering spaces / finite sets?","['algebraic-topology', 'category-theory', 'general-topology']"
1917524,Show that for any $n\in\mathbb{N}$ we have $ |x-a_0.a_1a_2\cdots a_n|\leq \frac{1}{10^n}$,"Let $a_0\in \mathbb{N}\cup\{0\}$ and $\{a_1,a_2,\ldots\}\subset\{0,1,2,\ldots, 9\}$. Define the infinite decimal exansion $x=a_0.a_1a_2\cdots$. Show that for any $n\in\mathbb{N}$ we have $ |x-a_0.a_1a_2\cdots a_n|\leq \frac{1}{10^n}$. I was thinking of using the proof that $\sup(S+T)=\sup(S)+\sup(T)$ (I've done this in class already) and separating the infinite decimal sequence as $a_0 + a_1*(10^{-1}) + a_2*(10^{-2})+\cdots$ to prove this but I'm not exactly sure how.","['real-analysis', 'analysis']"
1917534,What is the intuition behind the unit/counit for the Spec/GlobalSections adjunction?,"Let Sch be the category of schemes, and Ring be the category of commutative rings, then Spec and the global sections functor $\Gamma$ are adjoint between these two categories. Ie, for any scheme $X$ and ring $A$ there is a natural bijection
$$Hom_{Sch}(X,{\rm Spec}\,A) = Hom(A,\Gamma(X))$$
If $A = \Gamma(X)$, then we get
$$Hom_{Sch}(X,{\rm Spec}\,\Gamma(X)) = Hom(\Gamma(X),\Gamma(X))$$
Thus, the identity on the right side corresponds to some special morphism $X\rightarrow{\rm Spec}\,\Gamma(X)$. Now, the definition of this morphism is given in rather grueling detail in http://stacks.math.columbia.edu/tag/01HX My question is - how should I think about this intuitively? I suppose one obstacle to thinking about this is the lack of examples. The only examples I'm comfortable with are either affine or projective curves, and in either case this morphism is trivial.","['category-theory', 'algebraic-geometry']"
1917548,Proof that the intersection of basis' is a basis for the intersection of their respective subspaces,"I'm doing some linear algebra review and I'm trying to prove two things. Let $U$ and $W$ be subspaces of $V$. Firstly, suppose $U+W$ has finite dimensions. Let $B_1$ be a basis for $U$ and Let $B_2$ be a basis for $W$. I need to show that I can choose $B_1$ and $B_2$ such that $B_1 \cap B_2$ is a basis for $U \cap W$. Secondly, I need to show that the previous statement is not true in general. I think a counter example would suffice but I can't think of any.","['linear-algebra', 'vector-spaces']"
1917574,Is $\mathcal {F}$ a sigma algebra?,"$(C[0,1],d)$ be metric space with usual 'sup-norm' metric. Let $(C[0,1],\mathcal {B})$ be a measurable space where $\mathcal {B}$ is Borel sigma algebra on $C[0,1]$.Let $\mathcal{F}_t=\sigma(W_s:s \in [0,t])$ where $W_s$ denotes the evaluation map.Let $\mathcal {F}= \bigcup_{ t \in [0,1)} \mathcal{F}_t$. Is $\mathcal {F}$ a $\sigma-$ algebra ? I am having trouble in showing that $\mathcal {F}$ is closed under countable union.I really dont have any intuition whether $\mathcal {F}$ is a $\sigma-$ algebra or not? Any idea to prove or disprove this?",['measure-theory']
1917581,How do I define exactly what a function is?,"While it is easy to understand what a function is intuitively, I've been trying to wrap my head around how to precisely define what a function is using only mathematical notation.  My attempt at this is below, but here is my preliminary understanding: A function can have multiple inputs or parameters, but it generates a single output Each output is unique for the input values provided. Here is my attempt at a definition: A relation $R \subset (D \times C)$ is a function if: $$ (\forall (d_1, c_1) \in R)(\forall (d_2, c_2) \in R)(d_1 = d_2 \rightarrow c_1 = c_2)$$ This definition should cover all functions, not just functions with one input, as $d_1$ and $d_2$ could be n-tuples that define the n inputs of a function, as every element of $R$ is actually an ordered pair $((x_1, x_2, ..., x_n),c)$ Does this look like a correct and precise definition?  Or could it be written better?  I couldn't find any formal definition of a function on the web, even on Wikipedia. Finally, is it correct to say that all functions with n inputs are (n+1)-ary relations?  Since $((x_1, x_2, ..., x_n),c)$ is the same as $(x_1, x_2, ..., x_n,c)$. Thanks.","['relations', 'functions', 'definition']"
1917587,"What does ""Principal"" mean in ""Principal Unit Normal Vector""?","When working with space curves, why is it called the ""Principal Unit Normal Vector""?  I know there are two.  So how do we know which one is the principal one?  Also, is there a principal unit binormal vector and principal unit tangent vector?  Why or why not?  What makes the naming scheme need the word principal for some and not others?  And what does ""principal"" mean?","['multivariable-calculus', 'differential-geometry', 'terminology']"
1917588,Algebra Problem: $a + 1/b = b + 1/c = c + 1/a = t $ [duplicate],"This question already has answers here : If $a+\frac1b=b+\frac1c=c+\frac1a$ for distinct $a$, $b$, $c$, how to find the value of $abc$? (7 answers) Closed 7 years ago . a, b, c are distinct reals such that $$a + 1/b = b + 1/c = c + 1/a = t $$for some real t. Show that t 
= -abc
I tried using continued fractions to isolate a,b and c but equations of degree more than 2 are formed.",['algebra-precalculus']
1917591,An orientable two plane bundle is trivial over a surface with boundary,"Why an orientable two plane bundle is trivial over a surface with boundary? When, I read a lecture notes ""Legendrian and transversal knots by Jhon B Etnyre"", I seen this result(he just state it). I don't know how the problem will go. Can any one fix it??? Thanks advance.","['fiber-bundles', 'vector-bundles', 'differential-geometry', 'differential-topology']"
1917593,Prove that this is a norm,"Let $X$ be a real or complex vector space. Let $N:X\rightarrow\mathbb{R}$ be a function with the following properties $N(x)\geq 0$, $N(x)=0$ if and only if $x=0$, $N(\lambda x)=|\lambda|N(x)$, The set $B=\lbrace x\in X\text{ }|\text{ }N(x)\leq 1\rbrace$ is convex. Prove that $N$ is a norm. I am unable to prove the triangle inequality.","['functional-analysis', 'normed-spaces', 'metric-spaces']"
1917598,"UCT and Künneth, Hom-Tensor adjunction","A few days ago, there was a similar question in an other context. Künneth: Consider the tensor product of modules $H_i(X;\mathbb{Z})\otimes A$, where $A$ is an abelian group, $X$ is a topological space and $H_*$ denotes singular homology.  The theorem states there is a short exact sequence
$$0 \to H_i(X; \mathbf{Z})\otimes A \, \to \, H_i(X;A) \to \operatorname{Tor}(H_{i-1}(X; \mathbf{Z}),A)\to 0.$$ UCT: There is also a short exact sequence in singular cohomology $H^*$ $$0 \to \operatorname{Ext}_\mathbf{Z}^1(\operatorname{H}_{i-1}(X; \mathbf{Z}), A) \to H^i(X; A) \,  \to \, \operatorname{Hom}_\mathbf{Z}(H_i(X; \mathbf{Z}), A)\to 0.$$ What I want to know: I know a proof of both theorems with projective and injective resolutions respectively and Eilenberg-Zilber for Künneth. Nevertheless, is it possible to deduce the theorems from each other using the fact that Hom and Tensor are adjoint functors ? (A paper ""Adjoint Functors and Equivalences"" brought me to the idea)","['algebraic-topology', 'abstract-algebra', 'category-theory', 'adjoint-functors']"
1917607,"In a metric space $(S,d)$, assume that $x_n \to x$ and $y_n \to y$. Prove that $d(x_n, y_n) \to d (x, y)$.","Let $(X,d)$ be a metric space and $(x_n)$,$(y_n)$ be sequences in $X$. (a) If $x_n \to x$ and $y_n \to y$, prove that $d(x_n,y_n) \to d(x,y)$. (b) If $x_n$ and $y_n$ are Cauchy sequences in $X$, prove that the real sequence $d(x_n,y_n)$ is convergent. Proof. (a) Is this correct?: Let $x,y,w,z∈X$. The triangle inequality implies that $|d(x,z)-d(w,y)| \leq d(x,y)+d(z,w)$, so $|d(x_n,y_n)-d(x,y)| \leq d(x_n,x)+d(y_n,y)$ which implies that $d(x_n,y_n) \to d(x, y)$ as $n \to ∞$ if $d(x_n,x) \to 0$ and
$d (y_n, y) \to 0$. (b) I have no ideas, you help me please?","['metric-spaces', 'cauchy-sequences', 'analysis', 'proof-verification']"
1917610,Differential equation (Brachistochrone problem),"I'm really only supposed to solve the differential equation $(1+(y')^2)y=k^2.$ I haven't encountered any problem with $(y')^2$. How do you start with a problem like this, I did try googling it but all I got was basic differential equation, should I substitute for something? Grateful for any help at this point!",['ordinary-differential-equations']
1917622,Under-site like subspace topology,"Let $X$ be a topological space and $Op(X)$ the category of its open sets. It is well known that $Op(X)$ has a canonical Grothendieck topology which makes of it a site. Let $U\in Op(X)$ be an object (an open set) of this category. It is naturally a topological space for the subspace topology. Hence there is a site $Op(U)$. I'd like to know if we can generalize this construction. Let $(\mathcal{C},J)$ be a site and $c\in C$ an object. Can we talk of the ""under-site"" generated by $c$ ? It should be a good generalization of the subspace topology. What subcategory $\mathcal{C}_c$ of $\mathcal{C}$ should I consider ?","['category-theory', 'general-topology', 'topos-theory', 'grothendieck-topologies']"
1917647,Proving $E[X^4]=3σ^4$,"Given a random variable $X\sim\mathcal N(0,\sigma^2)$, how can we prove that $E[X^4]=3\sigma^4$? I am having trouble even starting with the proof.","['statistics', 'expectation', 'normal-distribution']"
1917676,if ${dy\over dx}$ is not ratio then why can we use commutative law of multiplication on it?,"In maths class i have been taught not to treat ${dy\over dx}$ as a ratio but in physics why do we treat it like one. $$dw = f ds \implies dw = m \times {dv\over \color{red}{dt}} \times ds \implies dw = m\times dv\times{ds \over \color{red}{dt}}$$ $$\text{w is work done, f is force, v is velocity, s is displacement, t is time and m is mass}$$ If ${dy\over dx}$ is not a ratio then how did it change its numerator ? I think it will be clear if somebody can rewrite the above equation in Lagrange's notation. I hope i did not trouble anyone by asking this question. Thanks.","['derivatives', 'ordinary-differential-equations', 'calculus']"
1917679,Is $x^{-1}$ a linear function?,"I want to know if $\frac1x$ is a linear function or not. I read that a linear function can also be defined as a function of the first degree. Since $\frac1x=x^{-1}$, the function is of the first degree, isn't it? But the function's graph does not look linear at all. What am I missing?",['algebra-precalculus']
1917800,Solution of $\frac{xdx - ydy}{xdy - ydx} = \sqrt{\frac{1 - y^{2} + x^{2}}{x^{2} - y^{2}}}$ [duplicate],"This question already has answers here : solve$\frac{xdx+ydy}{xdy-ydx}=\sqrt{\frac{a^2-x^2-y^2}{x^2+y^2}}$ (2 answers) Closed 7 years ago . Find the solution of $$\frac{xdx - ydy}{xdy - ydx} = \sqrt{\frac{1 - y^{2} + x^{2}}{x^{2} - y^{2}}}$$ I was able to bring it down to $$\frac{d(x^2-y^2)}{\sqrt{1+x^2-y^2}}=2\left(\frac{x.d(y/x)}{\sqrt{1-(y/x)^2}}\right)$$ Any help would be greatly appreciated. Thanks in advance!
$$$$
Edit: An answer exists here , but I'm trying to solve the question $without$ using trigonometric or hyperbolic substitution (I was told it could be done without both, and that the solution was quite neat). 
$$$$
EDIT: Also the question that is mentioned as a possible duplicate is $\textbf{different}$ from mine.","['integration', 'ordinary-differential-equations', 'calculus']"
1917807,Game Theory Optimal Solution to 2 Player Betting Game,"Both players start with $\$n$ Each player antes $\$1$ and rolls a private 100-sided die so that they are the only one that sees the result. After the rolls a round of betting occurs (same method as Poker betting which is described below) Player 1 chooses to either check keeping the stakes at $\$1$ or raise increasing the stakes to whatever integer amount he wishes. If Player 1 checked then Player 2 can choose to either check as well ending the round in which the results of the rolls are revealed and the player with the higher roll receives the $\$2$ pot. Alternatively Player 2 can raise the stakes to whatever integer amount he wishes. If Player 1 raised then Player 2 can choose to either fold, call, or raise. If Player 2 folds then he forfeits the pot to Player 1. If he calls then the rolls are revealed and the player with the higher roll wins the pot. If he raises then play returns to Player 1. Betting continues until either player calls the other player's raise. If there is a tie and neither played folded then the pot is split. Given this game what is the Game Theory Optimal play for each player?","['game-theory', 'probability-theory', 'gambling', 'dice']"
1917852,"For an integrable function $f$, the measure of the set $\{x: |f(x)|=a \}$ is zero for all but countably many $a's$","Suppose $(\Omega, \mathcal{F}, \mu)$ is a probability space and $f$ is integrable function. Then, is it true that $\mu \{ \omega: |f(w)|=\alpha\}=0$ for all but countably many $\alpha$ ? \",['measure-theory']
1917860,Prove: $|xy|=|x|\cdot |y|$,"Can you help me to prove this equality?
$$|xy|=|x|\cdot |y|$$ I don't know how to start proving the equality.","['algebra-precalculus', 'absolute-value']"
1917909,How do I calculate the derivative of a derivative w.r.t. another derivative?,"The question is a bit of a mouthful. In Classical Mechanics by Goldstein I have seen the use of the following: $$ \frac{d\dot{F}}{d\dot{q}_i} = \frac{dF}{dq_i} $$ where $F = F(q_1,q_2,...,q_n;t)$, $ \dot{F} = \frac{dF}{dt} $ and $ \dot{q_i} = \frac{dq_i}{dt} $ . How would I show this? The use of this result is used on page 17 of the PDF solutions guide (Page 10 within the derivations chapter) by showing that the transformation $L'(q,\dot{q},t) = L(q,\dot{q},t) + \frac{dF(q,t)}{dt}$ keeps the form of the Euler-Lagrange equation invariant: http://www.slideshare.net/venuatsrr/solution-manual-classical-mechanics-goldstein","['derivatives', 'euler-lagrange-equation']"
1917948,When we can equate two probability functions $p(r)dr=p(\gamma)d\gamma$?,"I am doing wireless communication the signal envelope is assumed to have rayleigh fading given by $$p(r_i)= \frac{r_i}{\sigma^2} \exp\left(-\frac{r_i^2}{2\sigma^2}\right)$$ and we need to find distribution of SNR given by$$p(\gamma)|d(\gamma_i)|=p(r_i)|d(r_i)|   ~~~\text{and}~~~~ \gamma_i=\frac{r_i^2}{2N}\tag{1}$$ I want to know how equation one comes, I mean to say I have seen in coordinate geometry $\text{slope} = \frac{|\text{length of } y|}{|\text{length of }x|} $, but what specifically leads to (1).","['derivatives', 'calculus']"
1917993,"Maximum value $c$ s.t. $\exists$ a subset $S$ of $\{z_1,z_2,\ldots,z_n\}$ s.t. $\left|\sum_{z\in S}z\right|\geq c$ ($\sum_{i=1}^{n}|z_i|=1$).","The original question is unclear so I completely rephrased the question and provided full context: This is the original question (from CMO 1986): Let $z_1,z_2,\cdots ,z_n$ be complex numbers satisfying $$|z_1|+|z_2|+\cdots +|z_n|=1.$$ Prove that there exists a subset $S$ of $\{z_1,z_2,\ldots,z_n\}$ such that $$\left|\sum_{z\in S}z\right|\geq\frac16.$$ But obviously the lower bound $\frac16$ is far less than optimal. For example, by simply using pigeonhole principle and the inequality $|z|\leq\Re(z)+\Im(z)$ it is easy to show that for every set of complex numbers $\{z_1,z_2,\ldots,z_n\}$ there always exists $S$ such that $\left|\sum_{z\in S}z\right|\geq\frac14$. But I wonder how to obtain the optimal value, i.e.: Let $z_1,z_2,\cdots ,z_n$ be complex numbers satisfying $$|z_1|+|z_2|+\cdots +|z_n|=1.$$ Find the maximum value $c$ such that for every set of complex numbers $\{z_1,z_2,\ldots,z_n\}$ satisfying the condition above, there always exists a subset $S$ of $\{z_1,z_2,\ldots,z_n\}$ such that $$\left|\sum_{z\in S}z\right|\geq c.$$ I read from the book 101 Algebra Problems from the Training of the USA IMO Team (p85) that ""Using advanced mathematics, the lower bound can be
further improved to $\frac1{\pi}$."" But how exactly do I obtain that result?","['complex-analysis', 'complex-numbers', 'analysis']"
1918080,Commutative endomorphism rings.,"Let $A$ be a commutative ring, and $M$ an $A$ -module. Are there some reasonably general conditions (both on $A$ or $M$ ) assuring that the ring $\mathrm{End}_A(M)$ is commutative? I am also interested in classes of $A$ -modules which have this property. Do they have a name?","['abstract-algebra', 'modules']"
1918086,"Isomorphism $C_0(X) \otimes A \to C_0(X,A)$","Let $A$ be a $C^*$-algebra. I want to prove that 
$$
\phi : C_0(X) \otimes_\alpha A \to C_0(X,A): f \otimes a \mapsto a \cdot f
$$
is an isomorphism, where $\alpha$ is a norm making the tensor product into a $C^*$-algebra. Note that $C_0(X)$ is commutative hence nuclear. Since $\phi(C_0(X) \otimes A)$ is dense (with $\otimes$ the algebraic tensor product) one is done, if the restriction of   $\phi $ to $C_0(X) \otimes A$ is an isometry. Then $\phi$ is clearly surjective and also injective. (On the algebraic tensorproduct $\phi$ is injective but I think this does not necessarily  extend to the completion.) So my question would be what one can take for $\alpha$ to prove in an efficient way that $\phi$ is an isometry.","['functional-analysis', 'tensor-products', 'c-star-algebras', 'operator-algebras']"
1918124,Gliders on a Rubik's Cube,This question is bugging me for a long while: Is it possible to turn an unmodified 3x3x3 Rubik's Cube into a position where there is a Glider pattern (from Conway's Life) on every side of the cube? How many different solutions are there if we only care of the relative position of the gliders but not their colors? What are these? (Being unmodified is important because it is possible to disassemble and then reassemble a cube so that it can't be solved again with standard turning moves. So reassembling a cube to a form matching my requirements doesn't count as a solution in itself.),"['rubiks-cube', 'combinatorial-geometry', 'geometry']"
1918181,"Infinitely many discontinuities for a bijective function from $[0,1)$ to $(0,1)$","Show that any bijection from $[0,1)$ to $(0,1)$ has infinitely many discontinuities. I have thought about this question but I have no any idea. Any idea is valuable for me, thanks.",['general-topology']
1918192,Game with relative prime numbers,"We have a two player game where you start with a number $s_0$ and then you have a goal number $g$ (with $1 < g < s_0$). Both $s_0$ and $g$ are natural numbers. Each turn you choose a new number $s_n$ following these rules: $s_n$ must be less than the previous number $s_{n-1}$, $s_n$ must always be relatively prime to $s_{n-1}$, The numbers you choose can never be smaller than your goal number $g$. The player who is able to write/choose the goal number wins the game. I've already calculated an example with $s = 27$ and $g = 15$. If player 1 chooses $s_1 = 20$ in the first round, then player 2 must choose $s_2 = 19$ or $s_2 = 17$ in the second round. Either way, player 1 can choose $s_3 = 15$ in the third round, and wins the game. Now, let's assume $g$ is an even number. Which values of $s_0$ will guarantee that the first player wins the game? 
I know that as long as $s_n$ is also an even number you can never choose $g$ in your turn. So the trick seems to be to make sure your opponent ends up with an even $s_n$. Is there any way to prove that for any odd number $x$ you can always find an even number $y$ that is relative prime to $x$? In that case, just set an odd number as $s_0$ and the first player will win by picking $y$ as $s_n$ every time.","['number-theory', 'prime-numbers', 'game-theory']"
1918217,The mod97 operation in IBAN validation,"The international bank account number(IBAN) is validated by a $\bmod 97$ operation. Suppose an account number is like sd1234abcd78965h then the following steps are performed: the first four characters of the IBAN number are pulled out from the beginning and are appended at the end of the string. All the letters in the hence obtained string of characters are replaced by the ASCII value of their corresponding uppercase letter decreased by $55$ . (ascii value $-55$ ) The modulus of the hence obtained number, let's say $x$ , with respect to $97$ is checked. If the modulus is $1$ , then it's a valid IBAN number . For the third step, Wikipedia mentions an algorithm , which goes as follows: A nine digit number is formed by taking the leftmost $9$ digits of $x$ . The mod of this number with respect to $97$ , $r$ is obtained. Then another nine digit number, $q$ is formed by concatenating $r$ and the next $7$ digits of the number. This process is continued till the last value of $q\bmod {97}$ is obtained.
If it is $1$ then that validates the number . But, I couldn't prove that a number, $n$ , for whom $n \bmod 97$ is $t$ where $t$ is in between $1$ to $96$ , when subjected to above algorithm, will in the end yield $t$ . Or is this a special case for numbers $n$ for whom $ n\bmod{97}$ is $1$ ? Can you show me a proof of this algorithm or disprove it?",['number-theory']
1918281,Generalizing a Trig Identity,"It is well known and somewhat easy to show that
$\prod\limits_{j=1}^n \cos\frac{x}{2^j} = 2^{-n}\frac{\sin x}{\sin\frac{x}{2^n}}$. The ""2-ness"" of $2$ (in $\cos\frac{x}{2^j}$) is really important to deriving this identity. I was wondering if there was anything nice known about products of the form $\prod\limits_{j=1}^n \cos\frac{x}{k^j}$ where $k$ is a positive integer $\ge 3$.","['products', 'trigonometry']"
1918355,Is $\cos(\alpha x + \cos(x))$ periodic?,"Consider the function $f: \mathbb{R} \to [-1, 1]$ defined as $$f(x) = \cos(\alpha x + \cos(x))$$ What conditions must be placed on $\alpha \in \mathbb{R}$ such that the function $f$ is periodic? First of all, I tried plotting some values on Wolfram|Alpha , and for all the values of $\alpha$ that I tested, it seems that any $\alpha$ works... But I couldn't prove it. My attempt: We want to study $\alpha$ such that the following statement is true: $$\exists \,\, T > 0 \quad \forall \,x \in \mathbb{R} \quad \cos(\alpha (x + T) + \cos(x + T)) = \cos(\alpha x + \cos(x))$$ I was able to show, with some trigonometric substitutions, that this statement is equivalent to the following statement: $$\exists \,\, T > 0 \quad \forall \,x \in \mathbb{R} \quad \exists \,\, K \in \mathbb{Z} \quad \text{such that}$$
$$\sin(x + T) = \dfrac{\alpha T - K\pi}{\sin (T)} \quad \text{or} \quad \cos(x + T) = \dfrac{K\pi - \alpha(x + T)}{\cos (T)}$$ I couldn't make any progress after that, though. EDIT: Inspired by a quick comment by @ZainPatel, I was actually able to show that all $\alpha \in \mathbb{Q}$ works! It's quite simple, I am surprised I didn't try this before. Let $\alpha \in \mathbb{Q}$, $\alpha = \dfrac{p}{q}$. Then $T = 2q\pi$ works, since $$f(x + 2q\pi) = \cos(\alpha (x + 2q\pi) + \cos(x + 2q\pi)) = \cos(\alpha x + 2p\pi + \cos(x)) = f(x)$$ The matter is still open for irrationals though!","['real-analysis', 'trigonometry', 'periodic-functions', 'functions']"
1918375,Set of values of $a$ for which function always increases,"If the set of all values of the parameter $a$ for which the function $$f(x)=\sin (2x)-8(a+1) \sin x+(4a^2+8a-14)x$$ increases for all $x \in R$ and has no critical point for all $x \in R$ is $(- \infty, m- \sqrt n) \cup (\sqrt n, \infty)$, then find the value of $m^2+n^2$ (where $m,n$ are prime numbers). After finding $f'(x)$, we need to set $f'(x)>0$ but I am not having any clue how to extract condition on $a$? Could someone help me with this?","['derivatives', 'maxima-minima', 'calculus']"
1918406,"A hypothesis about the conjecture: ""Every even number is the difference of two primes""","If the conjecture ""Every even number is the difference of two primes"" holds then we conclude the following hypothesis: Hypothesis. For every distinct non-zero integers $a, b$, at least one of the numbers $a, b$ and $a-b$ can be expressed as the difference of two primes. Question. Is the converse true (does the hypothesis imply the conjecture)?","['number-theory', 'analytic-number-theory', 'prime-numbers', 'elementary-number-theory']"
1918415,Globally generated implies nef,"For globally generated line bundles it is quite clear to see that they are nef: 
Let $L$ be globally generated, then the global sections in $H^0(X,L)$ define a morphism $\Phi \colon X \to \mathbb{P}_N$, such that $L = \Phi^*(\mathcal{O}_{\mathbb{P}_N}(1))$. The line bundle $\mathcal{O}_{\mathbb{P}_N}(1)$ is ample which imples nef, and the pullback is nef as well, hence $L$ is nef. How do we obtain this for vector bundles $E$ as well, such that if $E$ is globally generated it is nef? Thanks in advance.","['vector-bundles', 'algebraic-geometry']"
1918438,Product of all elements in finite nonabelian group,"Let $G$ be a finite group. By indexing $G = \{g_1,\ldots,g_n\}$ arbitrarily, we can make sense of the product
$$
\prod_{i = 1}^n g_i.
$$
If $G$ is abelian, the result is clearly the product of all elements of order 2, which is $1$ unless there is a unique element of order 2. If $G$ is not abelian, the ordering of the group (or, the product) matters, and there are at least two possible outcomes (just exchange two adjacent non-commuting elements). Can something be said in general about which outcomes are possible?","['finite-groups', 'group-theory']"
1918453,Dirac Operator on Riemann Surface,"Let $ \Sigma $ be a Riemann surface with canonical bundle $ K $ and hermitian metric $ h $. A spin bundle is a line bundle $ L $ that squares to $ K $. More concretely, given a trivializing atlas $ \{ \phi_i : U_i \rightarrow \mathbb{C} \} $ with holomorphic transition maps $ f_{ij} $, the transition maps for the canonical bundle are $ f^{-1}_{ij} $, and for the spin bundle $ \pm \sqrt{f^{-1}_{ij}} $. The Dirac operator is defined by composing $ \bar \partial : C^\infty(L) \rightarrow C^\infty(L \otimes \bar K ) $ with an isomorphism $ L \otimes \bar K \simeq \bar L $ induced by the hermitian metric $ h $. My question is: What is this isomorphism exactly? What does it look like in the coordinate charts?","['riemann-surfaces', 'mathematical-physics', 'manifolds', 'differential-geometry', 'definition']"
1918461,how to solve $x^2 = 3x + 4$,"I am a programmer in the eighth grade taking algebra 1. I am only about a month into the school year, and I need to know how to solve something similar to this equation: $x^2 = 3x + 4$ However, the problem is that whenever I try to get the square root of both sides of the equation to get rid of the $x^2$, I get something like this: $x = \sqrt{3x + 4}$ After this, I couldn't figure out what to do, because my only option was to square both sides of the equation, which would get me back where I started. So, how would I solve this? Please make the answer simple enough so that an algebra 1 student would understand. Also, sorry for the tag that probably isn't  great, my rep is so low I cant create a new tag (I would probably tag this as algebra 1).",['algebra-precalculus']
1918485,GRE math question,"I have the following problem in a GRE practice exam, I was wondering if someone could help me figure it out. Suppose $y(t) = y$ solves $y' = (y^2-1)e^{2012y-1}$ with initial condition $y(0)=0$, then which of the following are true? a) $\lim_{t \to \infty} y(t) = \infty$ b) $\lim_{t \to \infty} y(t) = 1$ c) $\lim_{t \to \infty} y(t) = -1$ d) $-1 < y(t) < 1$ for all $t$ e) Both C and D","['gre-exam', 'ordinary-differential-equations', 'limits']"
1918499,Closure of the set of weak solutions of conservation laws,"Consider the conservation law $$u_t + q(u)_x = 0 \quad \tag{CL}$$ A function $u$ is a weak solution of $(CL)$ if $u \in L^\infty_\text{loc}((0, \infty)\times \mathbb{R})$ and $$\int_0^\infty \int_{-\infty}^{+\infty} uv_t + q(u)v_x \ \  dt \, dx = 0,$$ for every test function $v \in C_c^\infty((0,\infty)\times \mathbb{R}).$ Let $\{u_\epsilon\}$ be a sequence of weak solutions of $(\text{CL})$ and $u \in L^\infty((0,\infty) \times \mathbb{R})$. How does one prove that if, for every $\epsilon$, $\Vert u_\epsilon
 \Vert_{L^\infty((0,\infty)\times \mathbb{R})} < B$ for some $B > 0$
   and $u_\epsilon \to u$ in $L^1_\text{loc}((0,\infty) \times \mathbb{R})$,
   then $u$ is a weak solution of $(\text{CL})$? Also, is it possible to prove a stronger similar theorem?","['functional-analysis', 'analysis', 'partial-differential-equations']"
1918535,ODEs uniqueness of nonlinear equation,"I am to show that solutions to the ODE: $x'(t) = -\frac{1}{2} \left(x(t)^2 - 3 c \right)$, are not unique. I don't know why this is problematic, since, the ODE clearly has a solution that seems to work for all $t$: $x(t) = \sqrt{3} \sqrt{c} \tanh \left(\frac{1}{2} \left(\sqrt{3} \sqrt{c} t+2 \sqrt{3} \sqrt{c} c_1\right)\right)$, where $c_1$ is a constant. But, my professor insists that this is not a unique solution!","['real-analysis', 'ordinary-differential-equations', 'dynamical-systems']"
1918557,Roles of $\bf A^TA$ ($\text {A transpose A}$) matrices in orthogonal projection,"$\bf A^TA$ forms (or equivalently (?) positive semidefinite matrices , or more particularly, covariance matrices($\bf \Sigma$)) are linked in practice to many operations in which data points are orthogonally projected: In ordinary linear regression (OLS) is part of the projection matrix $\bf P = X(\color{blue}{X^TX})^{−1}X^T$ of the ""dependent variable"" on the column space of the model matrix. In principal component analysis (PCA) the data is projected on the eigenvectors of the covariance matrix. The covariance matrix informs white random ""white"" samples into diagonal projections in Gaussian processes , which seems intuitively to correspond to a way of projecting. But I am looking at a unifying explanation. A more generic concept. In this regard, I have come across the sentence, ""It is as if the covariance matrix stored all possible projection variances in all directions,"" a statement seemingly supported by the fact that a for data cloud in $\mathbb R^n$, the variance of the projection of the points onto a unit vector $\bf u$ will be given by $\bf u^T \Sigma u$. So is there a way of unify all these inter-related properties into a single set of principles from which all the applications and geometric derivations can be seen? I believe that the unifying theme is related to the the orthogonal diagonalization $\bf A^T A = U^T D U$ as mentioned here , but I'd like to see this idea explained a bit further. EXEGETICAL APPENDIX for novices: It was far from self-evident, but after some help by Michael Hardy and @stewbasic, the answer by Étienne Bézout may be starting to click. So like in the move Memento , I'd better tattoo what I got so far here in case it is blurry in the morning: Concept One: Block matrix multiplication: \begin{align}
A^\top A & = \begin{bmatrix}  \vdots & \vdots & \vdots & \cdots & \vdots \\
                   a_1^\top    & a_2^\top    &  a_3^\top   & \cdots & a_{\color{blue}{\bf n}}^\top\\
                   \vdots & \vdots & \vdots & \cdots & \vdots\end{bmatrix}
          \begin{bmatrix}
                   \cdots & a_1 & \cdots\\
                   \cdots & a_2 & \cdots \\
                   \cdots & a_3 & \cdots \\
                   & \vdots&\\
                    \cdots & a_{\color{blue}{\bf n}} & \cdots
             \end{bmatrix}\\
            &= a_1^\top a_1 + a_2^\top a_2 + a_3^\top a_3 + \cdots+a_n^\top a_n\tag{1}
\end{align} where $a_i$'s are $[\color{blue}{1 \times \bf n}]$ row vectors. Concept Two: The $\color{blue}{\bf n}$. We have the same dimensions for the block matrix multiplication $\bf \underset{[\text{many rows} \times \color{blue}{\bf n}]}{\bf A^\top}\underset{[\color{blue}{\bf n} \times \text{many rows}]}{\bf A} =\large [\color{blue}{\bf n} \times \color{blue}{\bf n}] \small \text{ matrix}$, as for each individual summand $\bf a_i^\top a_i$ in Eq. 1. Concept Three: $\bf a_i^\top a_i$ is deceptive because of the key definition: row vector. Because $\bf a_i$ was defined as a row vector, and the $\bf a_i$ vectors are normalized ($\vert a_i \vert =1$), $\bf a_i^\top a_i$ is really a matrix of the form $\bf XX^\top$, which is a projection matrix provided the $a_i$ vectors are independent (check: ""...are linearly independent""), and orthonormal (not a requisite in the answer (""I'm no longer saying they are orthogonal"")) - $\color{red}{\text{Do these vectors actually need to be defined as orthonormal?}}$ Or can this constraint of orthonormality of the vectors $a_i$ be relaxed, or implicitly fulfilled by virtue of other considerations? Otherwise we have a rather specific $\bf A$ matrix, making the results less generalizable. Concept Four: A projection onto what? Onto the subspace spanned by the column space of $\bf X$ (think OLS projection ${\bf A}\color{gray}{(A^\top A)^{-1}} {\bf A^\top}$). But what is $\bf X$ here? None other than $\bf a_i^\top$, and since $\bf a_i$ is a row vector, $\bf a_i^\top$ is a column vector. So we are doing ortho-projections onto the column space of $\bf A^\top$, which is in $\mathbb R^{\color{blue}{\bf n}}$. I was hoping that the last sentence could have been, ""... onto the column space of $\bf A$... What are the implications?","['projection-matrices', 'linear-algebra']"
1918578,Automorphism of Curves - Explanation of Notion and a question,"So, I'm starting out working through Shafarevich's Basic Algebraic Geometry, and while of course it's expected I be familiar with notions from algebra, apparently I have missed a few in my first year courses. In particular, the one that's giving me grief at the moment is that of an 'automorphism of a curve.' In particular, Shafarevich asks me to figure out what the automorphism group of the curve $$y^2 = x^3 + x^2$$ Now I already know in some sense what this should be. The automorphisms should be structure preserving, bijective self-maps of this curve. From clicking around the internet, I gather that the 'structure' here is the property of satisfying $f(x,y) = 0$, i.e. being solutions to the polynomial in two variables given by just shoving everything over to one side. Assuming this is correct, so far so good. Now the problem is actually computing these automorphisms. My intuition tells me that they should be maps taking $x,y$ to polynomials in $x$ and $y$, and in particular, we want them to have the same image as this equation does. I'm not 100% sure if this is quite the right idea or not, but Shafarevich doesn't seem to define the notion anywhere, so I'm kind of on my own. However, if this fuzzy notion is on the right track, I have been able to spot one such automorphism: $$ x \mapsto x, \space \space \space y \mapsto -y$$ We can see this is an automorphism, because the negative sign just squares away, and we get back the curve. Now I suspect this is the only automorphism, because intuitively I am thinking of automorphisms of curves as kind of like a group of symmetries of the curve, and we can write $$y^2= x^3 - x^2 = x^2 (x+1)$$ so that this curve has a node at the origin. That makes visualization of this curve not so hard, because between the vertical symmetry found above, and the fact that it has a node, we can kind of see what it looks like. For this reason, I think that the automorphism group, whatever that means, is just $\mathbb Z /  2\mathbb Z$. While aesthetically pleasing, it lacks rigor. Can anyone help fill me in? It would also be really nice if someone could give me some general guidelines for how to find automorphisms of other curves. Another graduate student has informed me that there are some facts from commutative algebra like 'primary ideal decomposition' and such that are useful. I do not currently know about these things (although I probably should). If your guidelines require any such facts, it would be wonderful if you could please include a reference. Edit: I forgot to include that I also know that this curve is rational. It can e parameterized by $x = t^2 - 1$, $y= t(t^2-1)$, in case this is useful information.","['algebraic-curves', 'algebraic-geometry']"
1918611,functions with floors,"If
$$z = \frac{ \left\{ \sqrt{3} \right\}^2 - 2 \left\{ \sqrt{2} \right\}^2 }{ \left\{ \sqrt{3} \right\} - 2 \left\{ \sqrt{2} \right\} }$$
find $\lfloor z \rfloor$. I don't rely know how to do this, but I was thinking about multiplying the denominator by it's conjugate, but idk.",['algebra-precalculus']
1918636,"Why does Khinchin's constant ""work""?","I apologize if I missed an existing question on this, perhaps with a different spelling of Khinchin's name. I feel like I'm missing something basic. From Wikipedia , almost all real numbers have a continued fraction representation whose terms have a geometric mean of $K_0=2.685...$ From the definition of ""almost all"", I would understand that there is an at-most-countable set of counter-examples, ie real numbers with continued fraction representations whose terms have a different geometric mean. But I also see here that continued fractions provide a homeomorphism between real numbers and and sequences of positive integers, seemingly confirming the intuition that the two sets should be isomorphic. This seems to imply that there should be only a countable number of positive integer sequences with a geometric mean different from Khinchin's constant. But this seems preposterous! If nothing else, we should be able to generate uncountably many sequences with a geometric mean of $2K_0$, by simply doubling the terms of any ""normal"" sequence with a mean of $K_0$. Where did I go wrong?","['continued-fractions', 'sequences-and-series']"
1918657,"$l^p$ not norm, $p<1$",please I tried to find counterexamples to see that $l^p$ is not norm with $p<1$ in the triangle inequality but I have problems with convergence when I choose some successions. Thanks.,['functional-analysis']
1918669,When is the Zariski topology $T_2$?,"In my general topology course, our instructor introduced the Zariski topology as a topology on $F^n$, where $F$ is a field, as the topology $\tau$ generated by the basis $\mathcal{B} = \{ f^{-1} (F \setminus \{ 0 \}) : f \in F[x_1 , \ldots, x_n] \}$, or equivalently generated by closed sets which are the pre-image of $\{ 0 \}$ under some $n$-variate polynomial in $F$. For $F$ infinite, $n = 1$, we can note that $F$ is given the cofinite topology, which is not $T_2$. Now for $\mathbb{R}^{n}, n \geq 2$, the Zariski topology must necessarily be $T_1$ and not $T_2$ (a prescribed exercise). The former can be seen via the equivalent definition of $T_1$ as leaving all singletons closed (consider merely a linear polynomial). The not Hausdorff part, however, comes from observing that the pre-image of $\{ 0 \}$ under an $n$-variate non-constant polynomial can have dimension at most $n - 1$, so the open sets have too great a codimension for the topology to be Hausdorff, where the dimension is taken in the sense of Hausdorff (though I think the implicit function theorem would let us instead say simply that it's a manifold of dimension $< n$). Similar justifications hold for $\mathbb{C}$. However, in these cases we're appealing to properties of $\mathbb{R}$ and $\mathbb{C}$ beyond merely algebraic properties, but geometric properties of the two; in particular we're considering properties of $\mathbb{R} ^ n , \mathbb{C} ^ n$ as Banach spaces, an object that doesn't even make sense except in terms of subfields of $\mathbb{C}$. Alternatively, for finite fields $F = \mathbb{F}_{p^{k}}^{n}$, we can again show the topology is discrete, again by counting methods. So the problem of discerning when $F^{n}$ is $T_2$ is simple for $n = 1$, coming down to cardinality arguments about $F$. Moreover, the problem is simple for finite $F$ for all $n \in \mathbb{N}$. The problem is also resolvable for $F = \mathbb{R}$ or $F = \mathbb{C}$, but these cases must be addressed by geometric methods, referring to relations between $\mathbb{R}[x_1 , \ldots, x_n]$ (resp. $\mathbb{C} [x_1 , \ldots, x_n ]$) and the thoroughly studied geometric properties of $\mathbb{R}$ (resp. $\mathbb{C}$). But when I broached to my professor the question of how me might address the Zariski topology on, say, $\mathbb{Q}^2$, he said he'd leave the question to me, as it was beyond his area of knowledge. So I took it to the MSE community. How would we go about discerning whether the Zariski topology on $F^n$ is $T_2$ for arbitrary fields $F$, where $n \geq 2, |F| = \infty$? My attempts thus far What I've figured out is that $X$ is $T_2$ iff for every $x_1 , x_2 \in X, x_1 \neq x_2$, there exist closed $K_1, K_2$ such that $x_1 \in K_1 \setminus K_2, x_2 \in K_2 \setminus K_1, K_1 \cup K_2 = X$. My argument is as follows: $(\Rightarrow)$ If $X$ is $T_2$, then there exist open $U_1, U_2$ such that $x_1 \in U_1, x_2 \in U_2, U_1 \cap U_2 = \emptyset$. Let $K_1 = U_2^{\complement}, K_2 = U_1^{\complement}$. Then $x_1 \in K_1, x_2 \in K_2$. Moreover, $K_1 \cup K_2 = U_1^{\complement} \cup U_2^{\complement} = (U_1 \cap U_2)^{\complement} = X$. $(\Leftarrow)$ Let $x_1 \in K_1 \setminus K_2, x_2 \in K_2 \setminus K_1$, and let $U_1 = K_2^{\complement}, U_2 = K_1^{\complement}$. Then $x_1 \in U_1, x_2 \in U_2$, and $U_1 \cap U_2 = \left( K_1^{\complement} \cup K_2^{\complement} \right) ^{\complement} = \emptyset$. This completes the proof (hopefully). This means that I wanna be able for arbitrary point $\mathbf{x} = (x_{1}, \ldots, x_{n}), \mathbf{y} = (y_1 , \ldots, y_n ) \in F^n, \mathbf{x} \neq \mathbf{y}$, find polynomials $f, g \in F[x_1, \ldots, x_n]$ such that $f(\mathbf{x}) = 0 \neq f( \mathbf{y}), g(\mathbf{y}) = 0 \neq g(\mathbf{x})$, and $f^{-1}(\{0\}) \cup g^{-1}(\{0\}) = F^n$. Then $fg \equiv 0$. I feel as if there is a short line to add here to conclude that no such $f, g$ exist, but I don't know what it is. Thanks!","['zariski-topology', 'general-topology', 'algebraic-geometry']"
1918673,How can i prove that the finite extension field of real number is itself or the field which is isomorphic to complex number?,"How can i prove that the finite extension field of real number is itself or the field which is isomorphic to complex number ? In deed, this example is included in Fraleght . Abstract Algebra text.
I did try the followings:
 $\mathbb{R}$ is real number. Then $\mathbb{C}$ is explassd as the smallest extension field including $ \mathbb{R} \cup ${$i$} How about considering this set . Let set $\mathbb{H}$ is the smallest field including 
$\mathbb{R} \cup${$i,j,k$} where $i, j, k$ are called Hamilton number or quaternion
their square are equal to $-1$. Firstly, I do know that this set is a ring. But i check that this set is a field. Of course, $\mathbb{H}$ may be not a field. Becasue, if that is true, then The Fraleght text book is wrong. However, I would like to know the specific reasons and Example's solution .
Please help me to get this.",['abstract-algebra']
1918699,Trouble with the derivation of the Reynolds Transport Theorem,"I have been trying to reconcile two different forms of the Reynolds Transport Theorem (RTT) that I have seen in textbooks. The first form comes from a finite volume method cfd textbook. It directly relates the rate of change of a property within a material volume (MV) to some integrals of an associated control volume (CV). I did not understand how they arrived at this form and was trying to derive it myself from the more well know form of RTT (described in paragraph below). The second RTT form I think is much more common, particularly from a math perspective.
 $$ \label(1)~~~~~~~~~~~~\frac{d}{dt} \int_{V(t)} F ~dV 
= \int_{V(t)} \frac{\partial F}{\partial t} ~dV 
 ~+ \int_{A(t)} F\mathbf b \cdot \mathbf n  ~dV $$ where V is an arbitrary volume bounded by surface A. F is the (scalar in this case) field of interest, b is the velocity of the surface A and n is the normal vector for the surface A. All of these quantities are in general variable, both spatially and temporally. My understanding is that this second form of the RTT (eqn 2) can be applied to both a material volume (MV) as well as any arbitrary control volume (CV) (this is done in some derivations of the continuity equation I have been looking at. So now we have both $$ 2)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV 
= \int_{MV(t)} \frac{\partial F}{\partial t} ~dV 
 ~+ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ (In the case of the material volume analysis the velocity of the surface A (i.e. b ) is equal to the fluid velocity u ) And $$ 3)~~~~~~~~~~~~\frac{d}{dt} \int_{CV(t)} F ~dV 
= \int_{CV(t)} \frac{\partial F}{\partial t} ~dV 
 ~+ \int_{A_{CV}(t)} F\mathbf b \cdot \mathbf n  ~dV $$ Now borrowing again from the derivation of the continuity equation and assuming that the two volumes CV and MV are instantaneously coincident we can draw some conclusions. Obviously the first terms of eqns 2 and 3 are not, in general, equal even with CV and MV coincident. However if MV is the same as CV even temporarily then the second terms from each equation should be equal $$ 4)~~~~~~~~~\int_{MV(t)} \frac{\partial F}{\partial t} ~dV 
= \int_{CV(t)} \frac{\partial F}{\partial t} ~dV $$ Additionally the third term of equation 2 can be rewritten in terms of an integral over CV rather than MV. $$ 5)~~~~~~~ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV
= \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV$$ In an effort to derive the first form of the RTT described earlier I substituted eqns. 4 and 5 into 2 to arrive at $$ 6)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV 
= \int_{CV(t)} \frac{\partial F}{\partial t} ~dV 
 ~+ \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ So now we have the rate of change of the field inside the material volume described by integrals over the control volume but I feel like it is absolute non-sense for several reasons. The most evident reason being that there is now no reliance at all on b which was never assumed to be zero and should therefore play a role I think in this final equation. So my question FINALLY is what did I do wrong here? Equating the integrals (MV and CV) when the volumes coincide is right out of the textbook derivation of the continuity equation so I feel okay about that.","['multivariable-calculus', 'fluid-dynamics']"
1918702,Using representation theory to understand averaging processes: an example,"I have been reading about some elementary representation theory (of finite groups), and have been puzzled by the following question, which of all of the questions I have worked on thus far is the most natural to me, and is perhaps the only one which seems like it'd be of significant interest ""external to the subject"".  So I'd like to remedy my complete confusion about how to bring representation theory to bear on this. The question: Let G be the group of rotations of a cube, and  $_{\mathbb{C}[G]}V = _{\mathbb{C}[G]}\mathbb{C}X$, where $X$ is the set of vertices of the cube, be the permutation module arising from the action of G on the vertices of the cube. Let $T:V \rightarrow V$ be the map replacing the number at a vertex by the average of the numbers at the three adjacent vertices. Let $w= (w_{1}, \cdots, w_{8}) \in V$. I want to understand how to compute $lim_{n \rightarrow \infty} T^{n}w$, using respresentation theory. What I've considered: For full disclosure, this is part of a homework assignment, but not my homework assignment, and I am just aiming to gain some understanding, not turn anything in. So far, I have: Come to understand that $G \cong S_{4}$, via the action of $G$ on the main diagonals. Written down the character table for $S_{4}$, using the irreducible representations already known to me ( the trivial, and sign), then forming the rest with the aide of tensor product, complements in the regular representation, and orthonormality of the irreducible characters. I should note that I have avoided thinking explicitly about these other irreducible reps at this point. Decomposed $_{\mathbb{C[S_{4}]}} V$ into irreducible submodules, by computing the character of $V$ directly with pictures (using the fact that $\chi (g) = \#$ (fixed points of g in X) for a permutation representation $_{\mathbb{C}[G]}\mathbb{C}X$), and then using the fact that the irreducible characters form an orthonormal basis for class functions. Edit: I have seen this question but, like Ron, I fail to understand how the first answer involves my considerations about the representation (or rather, analogous considerations about the relevant permutation module).","['representation-theory', 'modules', 'group-theory']"
1918709,"What is the English name of the result known as the ""Shared-Edge Theorem"" in Chinese?","There is this theorem that I think is pretty useful, but I don't know the English name. It's called 共边定理 in Chinese which literally means Shared-Edge Theorem. There is a Chinese Wikipedia article about it at https://zh.wikipedia.org/wiki/%E5%85%B1%E8%BE%B9%E5%AE%9A%E7%90%86 . (source: hudong.com ) The theorem says that following for this triangle: $$\frac{\triangle PAB}{\triangle QAB}=\frac{PM}{QM}$$ I need to know the English name for this so I can reference it on my tests. As you can see, this works because a side is shared.","['triangles', 'geometry']"
1918726,"If $f :X \to Y$ is a diffeomorphism, then $df_x$ is an isomorphism of vector spaces.","${\bf Proposition}$: If $f: X \to Y$ is a diffeomorphism, then $df_x$ is an isomorphism of tangent spaces. ${\bf Proof}$: Let $f: X \to Y$ be a diffeomorphism. Then $f$ is a smooth bijection and so is $f^{-1} : Y \to X$. Since $f$ is a bijection, $\dim X = \dim Y$. Therefore, $\dim T_x(X) = \dim T_y(Y)$ for all $x \in X, y \in Y$. Take any $h_1, h_2 \in T_x(X)$ for some $x \in X$ and take $\alpha \in \mathbb{R}$. If $f(x) = y$, we need to show that $df_x(h_1 + h_2) = df_x(h_1) + df_x(h_2)$ and that $df_x(\alpha h_1) = \alpha df_x(h_1)$ and that $df_x:T_x(X) \to T_{y}(Y)$ is a bijection. $df_x$ is a linear map so it is trivially true, by the definition of linearity, that it preserves the vector space structure between $T_x(X)$ and $T_y(Y)$. To prove that it is a bijection, I need to show that $df_x(T_x(X)) = T_y(Y)$ and that if $df_x(h_1) = df_x(h_2)$, then $h_1 = h_2$. How can I go about proving these surjective and injective properties? Thanks.","['general-topology', 'differential-geometry', 'differential-topology']"
1918731,Properties of a permutation matrix,"Let $P$ be a permutation matrix, i.e. an $n \times n$ matrix consisting of
$0$ and $1$ such that there is exactly one $1$ in every row and every column.
I want to prove that there exists some $N > 0$ such that $P^N = I.$ I was given the recommendation that I should consider how there is only
finitely many permutations. This suggests to me that I should consider
the fact that if $N$ does exist, $N$ must be finite. However, I am considering
going about this proof using an assumption for the sake of contradiction,
such that
$P^N = Q, Q \neq I$. I think the first step is proving that if $P$ is a permutation matrix, then
$P^N$ is a permutation matrix for $N > 0.$ I imagine that I can do this
inductivity by showing that $P^2$ is a permutation matrix. However, is
this a bit of an unnecessary way to prove our lemma? Any suggestions would be
appreciated.","['matrices', 'permutation-matrices', 'linear-algebra']"
1918738,Genus of a curve Silverman's book,"In problem numerated by 2.7. in Silverman's book ""The Arithmetic of Elliptic Curves"" is required to calculate genus of the nonsingluar curve $C$ given by equation $F=0$, where $F=F(x,y,z)$ is homogeneous polynomial of degree $d$. There is the suggestion to use Hurwitz formula and I am interested in solution which actually uses this formula. I agree that we can suppose that point $[0,1,0]$ is not on the curve $C$, therefore we can define map $C\longrightarrow \mathbb{P}^1$ by $[x,y,z]\mapsto[x,z]$, but I cannot determine indices of ramification of points on the curve. I do not know the uniformizers at points on the curve. How can I determine these uniformizers since $F$ can be almost any homogeneous polynomial of degree $d$?","['algebraic-curves', 'elliptic-curves', 'algebraic-geometry']"
1918740,Show that $F$ is a field,"Suppose $F_0$ is the collection of finite unions of disjoint half-open half-closed subsets in $(0,1]$, i.e. $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ How to show $F_0$ is a field (algebra)? I am able to prove two of the conditions needed, see below: 1, By definition, we can take $A=(a_1,b_1]$, where $0\leq a_1=b_1\leq 1$, so that $A$ is an empty set and is in $F_0$. 2, Suppose $A$ has the general form $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ So $A^c=(0,a_1)\cup (b_1,a_2]\cup (b_3,a_3]...\cup (b_J,1]$ which is a finite union of disjoint half-open half-closed subsets in $(0,1]$. So $A^c\in F_0$. For the closure under finite unions since each $A_i$ can be overlapped, I have no ideas to show that. Can anyone help?","['real-analysis', 'measure-theory']"
1918858,Minimizers of polynomial functions?,"Let $p: \mathbb{R}^2 \to \mathbb{R} $ be a polynomial function of two real variables. Suppose that (P) $\; \; \; \; \; \; p(x,y) \ge 0, \; \; \forall \; (x,y) \in \mathbb{R}^2 $ 1: Prove that if $p$ is of degree two, it has a minimizer over $\mathbb{R}$. 2: Prove that if a polynomial function $p$ verifies property (P) its degree is necessarily even. 3: Suppose that degree $p=2n$ with $n \gt 1  $. Does property (P) imply the existence of a minimizer for $p$ over $\mathbb{R}$?
$$\\ \\$$ My ideas: Since $f(x,y)$ is a degree two polynomial, it'd be of the form $$ f(x,y) = ax^2 +by^2 + cx + dy + kxy + l  $$ Taking all the second derivatives to compute the Hessian gives: $$\left\lbrack
\matrix{2a & k\cr k & 2b}
\right\rbrack$$ My hunch is that since the function has to be equal or greater than zero, $a, b$ and $k$ have to be non-negative, which would mean the Hessian is always non-negative, which I think would mean that there has to be a minimizer. I'm not really sure about the other parts, but I think that the answer to part ""3"" is YES. At least a local minimizer I think","['matrices', 'polynomials', 'optimization']"
1918872,"What do local coordinates look like for the quotient space $\operatorname{SL}(2, R) / \operatorname{SL}(2, Z)$?","OK, let me see first if what I understand is correct. So start with $\operatorname{SL}(2, \mathbb{R})$. This is literally the subset $$\{\begin{pmatrix}a & b \\ c & d\end{pmatrix} ``\in"" \mathbb{R}^4 \mid a d - b c = 1\}.$$ It inherits a subspace topology from $\mathbb{R}^4$, and that is fine. Now let me see if I got the coordinate system correctly. One of $a, b, c, d$ will be non-zero, say $a$. In that case, $d = \frac{1 + bc}{a}$. Let $\epsilon > 0$ be small enough so that $0 \not\in [a - \epsilon, a + \epsilon]$, and define $p : (a-\epsilon, a + \epsilon) \times (-\epsilon, \epsilon) \times (-\epsilon, \epsilon) \to \operatorname{SL}(2, \mathbb{R})$ by $(x, y, z) \mapsto \begin{pmatrix} x & y \\ z & \frac{1 + yz}{x}\end{pmatrix}$. This defines a coordinate map around any $\begin{pmatrix} a & b \\ c & d\end{pmatrix} \in \operatorname{SL}(2, \mathbb{R})$. I have not done the arithmetic, but I believe that considering the different cases will show that the transition maps are diffeomorphisms, and hence that what we are dealing with is a 3-manifold. There must be nicer coordinate systems, but I digress. Now, we take the quotient of $\operatorname{SL}(2, \mathbb{R})$ by $\operatorname{SL}(2, \mathbb{Z})$. It gets the quotient topology, and that is also fine. But what about the parametrization? How do we give it local coordinates? Actually, what does this space look like (geometrically speaking)?","['matrices', 'geometry', 'differential-geometry', 'quotient-spaces', 'lie-groups']"
1918879,"Poles and Zeros on $C=\{[X,Y,Z] \in \mathbb P^2\mathbb C \mid X^4 + XY^3 + Z^4=0\}$ of $f=\frac X Z$.","Problem: Let $X,Y,Z$ be homogeneous coordinates in $\mathbb P^2\mathbb C$ and $$C=\{[X,Y,Z] \in \mathbb P^2\mathbb C \mid X^4 + XY^3 + Z^4=0\}.$$ Let $f$ be the meromorphic function $f=\frac X Z$ . Calculate poles and zeros for $f$ with their order. Calculate ramification points with their index, and calculate the genus $g$ of $C$ using Hurwitz Formula. Find 3 linearly independent holomorfic differentials on $C$ . Thoughts: I checked the derivatives and the curve is smooth. Thus $g=(d-1)(d-2)/2=3$ , but we are asked to use Hurwitz Formula to find $g$ . We try to find zeros and poles for $f$ : In the chart $Z \not = 0$ our curve is $x^4 + xy^3 + 1=0$ and $f=X/Z=x$ . We need $x=0$ but no point of this kind is on the curve in this chart. Since $f$ gives us the first coordinate $x$ , we see that $y^3= \frac{-1-x^4}{x}$ gives us a ramification point iff $RHS=0$ ie we find $4$ ramification points of index 3. We need to check the remaining points with $Z=0$ . Namely $P=[0,1,0]$ and $Q_i=[1,a_i,0]$ for $i=1,2,3$ and $a_i$ the third roots of $-1$ . We look for $P$ in the chart $Y\not = 0$ . We get that the curve is $x^4 + x +z^4=0$ and $f=\frac X Z = \frac X Y \cdot \frac Y Z = \frac x z = \frac {-z^3}{x^3+1}$ using the curve, thus $P$ is a zero of order 3 and $Q_i$ are 3 poles of order 1. Hurwirz Formula states: $$2n + 2g - 2= \sum_{p \in C}(e_p(f)-1).$$ We set $n=3$ because we found $3$ poles, and $RHS=3(1-1)+(3-1)+4\cdot (3-1)$ for the $3$ simple poles, a zero of order 3 and 4 points of ramification. Thus $g=3$ . I don't know if this is correct in any way, and how to solve question 3! Thanks!","['algebraic-curves', 'riemannian-geometry', 'differential-geometry', 'algebraic-geometry']"
1918889,Estimating the Lower Bound of A Summation Related to Probability,"I am working on a probability problem which requires me to find a lower bound of a sum. The sum is
$$\sum_{i=n}^{100}{100\choose i}\left(\frac{80}{100}\right)^i\left(\frac{20}{100}\right)^{100-i}\geq 0.9$$ How do I find $n$ here in order to satisfy the inequality? Wolfram Alpha cannot calculate it, but can we perhaps give an estimate?","['summation', 'probability', 'estimation']"
1918890,Is a function a special kind of relation?,"Is a function a ""special kind of relation"", or, does it ""describe a specific relation""? My text on discrete mathematics explains: A relation is a subset of a Cartesian product and a function is a
  special kind of relation. But it would make more sense to me if a function described a relation as a subset of the Cartesian product. My thoughts being: Given a function, f(x) = y , we can compute a set of (x,y) coordinates within the Cartesian plain. And this set of coordinates would be the relation that is the subset of the Cartesian product. Am I confused? Could anyone help explain how a function IS a relation?","['relations', 'functions', 'discrete-mathematics']"
1918972,Finding an explicit formula for $a_n$ defined recursively by $a_{n+1}=a_n^2+6$.,"Let $\{a_n\}$ be a sequence defined recursively by $a_1=1,a_{n+1}=a_n^2+6$, find an explicit formula for $a_n$. I tried some of the usual mathods but none of them led to a solution. It seems that there just isn't such a formula (with only elementary functions). So is there? If there isn't, how do you prove that there isn't such a formula?","['recurrence-relations', 'sequences-and-series']"
1918994,Holonomy of Lie groups,"Simple compact Lie groups have unique bi-invariant metrics. Hence, they are Riemannian manifolds in a unique way, so we can ask what is their holonomy group. Is there a relationship between the group $G$ and its holonomy group? For example, is the holonomy group $G$ itself?","['holonomy', 'riemannian-geometry', 'differential-geometry', 'lie-groups']"
1919027,I can't find 'the easiest way' to simplify this expression?,$\large\dfrac{3^{2008} (10^{2013} + 5^{2012} + 2^{2011})}{5^{2012} (6^{2010} + 3^{2009} + 2^{2008})}$ $\large=\dfrac{3^{2008} ((2\cdot5)^{2013} + 5^{2012} + 2^{2011})}{5^{2012} ((2\cdot3)^{2010} + 3^{2009} + 2^{2008})}$ $\large=\dfrac{3^{2008} (2^{2013}\cdot5^{2013} + 5^{2012} + 2^{2011})}{5^{2012} (2^{2010}\cdot3^{2010} + 3^{2009} + 2^{2008})}$ This is where I get stuck. Any help would be appreciated.,"['algebra-precalculus', 'arithmetic']"
1919086,Calculate: $\frac{1}{2! \cdot 2} + \frac{1}{4! \cdot 4} + \frac{1}{6! \cdot 8} + \frac{1}{8! \cdot 16} + ...$,"Task from an old exam: Calculate (express without an infinite sum): $$\frac{1}{2! \cdot 2} +
\frac{1}{4! \cdot 4} + \frac{1}{6! \cdot 8} + \frac{1}{8! \cdot 16} +
...$$ I think this means on the way to the solution, we are allowed to use the sum symbol but the final result may not be in a sum symbol. Else I don't see another way of solving this task. In sum, the thing above would be: $$\sum_{n=1}^{\infty} \frac{1}{(2n)!\cdot 2^{n}}$$ And now we need to do something so the sum symbol is eliminated but I have no idea what it could be... What about seeing $$\frac{1}{(2n)!\cdot 2^{n}}$$ as a function and using taylor series on this? But no it would be too hard to derivate something like that and with factorial.. and I don't think it makes sense saying ""Hey, let's replace this sum symbol with a function and say this thing is a function now!"" But what else can I do in a situation like this? If you are doing something complicated, please do explain me. I have big troubles in understanding things.","['taylor-expansion', 'sequences-and-series', 'calculus', 'analysis']"
1919088,Schur decomposition to show matrix has $n$ orthonormal eigenvectors,"From Gilbert Strang's ""Introduction to Linear Algebra."" We are trying to show by Schur decomposition that all symmetric matrices are diagonalizable. We write down the Schur decomposition as $A=QTQ^{-1}$ where $A$ is square, $T$ is upper triangular and $\bar Q^{T}=Q^{-1}$, $\bar Q$ is the complex conjugate of $Q$. The text looks for $AQ=QT$ and argues that the first column of $Q$ has to be an eigenvector. Since $T$ is triangular and not necessarily diagonal, the first proposed step is to use the first column of $Q$ and supplement it with $n-1$ columns to complete an orthonormal matrix $Q_{1}$. Then we write:
$\bar Q^{T}_{1}AQ_{1}=
        \begin{bmatrix}
        \bar q^{T}_{1} \\
        \vdots \\
        \bar q^{T}_{n} \\
        \end{bmatrix}
        \begin{bmatrix}
        Aq_{1} & \cdots & Aq_{n} \\
        \end{bmatrix}
=
        \begin{bmatrix}
        t_{11} & \cdots \\
        0 & A_{2} \\
        \end{bmatrix}
$ (1) Why do we get the right hand side? I am able to reach it by multiplication and from the properties of a complex conjugate. At the same time, shouldn't the right hand side simplify to a triangular matrix? What am I missing? Going on, the book makes and argument by ""induction"" (not a formal one). It assumes a Schur factorization $A_2=Q_{2}T_{2}Q_{2}^{-1}$ is possible for $A_{2}$ of size $n-1$. Then it ""puts"" $Q_2$ and $T_2$ into $Q$ and $T$:
$Q=Q_{1}
        \begin{bmatrix}
        1 & 0 \\
        0 & Q_{2} \\
        \end{bmatrix}$
and
$T=     \begin{bmatrix}
        t_{11} & \cdots \\
        0 & T_{2} \\
        \end{bmatrix}$
and $AQ=QT$ (2) Where do we get this transformation from? In particular how can we see where $Q_{1}, T_{1}, Q_{}2, T_{2}$ fit into $Q$ and $T$? Once this is cleared, I am able to show that for a symmetric matrix $T$ is diagonal and the matrix has the requisite number of eigenvectors. Just to be clear, this is the first time the Schur decomposition is presented in the material so the answer might be obvious if you have mastered the decomposition but it definitely is not at this point in the book.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'schur-decomposition']"
1919114,Does complex dynamics offer any insights into real dynamics?,"One of the most fascinating things about complex analysis is that it provides insights into real analysis. Here are two pictures from Needham's book Visual Complex Analysis (p. 65): Picture 1 (real). Consider the following two functions. Both have the radius of convergence $R = 1$. But while it's clear what is the problem with [a] (its behavior at $x =\pm 1$), it's not clear what's stopping [b] from having a larger radius of convergence. Picture 2 (complex). The mystery is revealed when we realize that from the point of view of the complex analysis, both [a] and [b] are slices of the same function and the radius of convergence is just the distance to the nearest pole. Is there something similar (not necessarily with pictures) regarding complex dynamics? Does complex dynamics offer any insights into real dynamics? Edit : by ""real dynamics"" I mean dynamics of real maps.","['real-analysis', 'dynamical-systems', 'complex-analysis', 'complex-dynamics', 'applications']"
1919146,How can we parametrise this matricial hypersphere?,"What I call a matricial hypersphere for lack of a recognised name is the set in $\mathbb{R}^{p\times k}$ defined by
$$\mathfrak{H}=\left\{
a_1,\ldots,a_k\in \mathbb{R}^{p};\ \sum_{i=1}^k a_i a_i^\text{T} = \mathbf{A}
\right\}$$
where $\mathbf{A}$ is a $p\times p$ symmetric positive semi-definite matrix of rank $k$ $(k\le p)$. My questions are Is this a well-known object? Given the matrix $\mathbf{A}$ is there a completion of $\mathbf{A}$ into an object in bijection with $\{a_1,\ldots,a_k\}$, which is my meaning of parameterisation ? what is the size or dimension of $\mathfrak{H}$? Note: This object does not stem out of nowhere. It appears in linear
  regression, where the $a_i$ vector is a collection of regression
  coefficients,  and in connection with Wishart distributions, where the
  $a_i$'s are Normal variates. I actually need to find a
  reparameterisation of the $a_i$'s given $A$ to proceed a research
  problem.","['multivariable-calculus', 'random-matrices', 'linear-algebra', 'algebraic-geometry']"
1919216,Set vs abstract space: what's the difference?,"According to wikipedia, roughly: A space is a set with some attached structure (measure, order, etc). An abstract space is a set with no structure attached What is then the difference between a set and an abstract space? Is it the same as the difference between a pipe (abstract space) and a picture of a pipe (set)?","['general-topology', 'elementary-set-theory']"
1919242,"Problem on understanding the definition of ""Real Numbers""","Assume that a cut is defined like this : A cut of a set like $M$ is a subset of $M$ like $A$ such that : 1. $A \neq \emptyset $ and $A\neq M$ 2. $\forall a,b \in M \space \space a\in A \space\land b<a \implies b \in A$ 3. $A$ doesn't have a maximum. Then, we can define real numbers like this : $R=\{A\subseteq \Bbb Q :A \text{ is  a  cut}\}$ Now, I have three problems. Isn't $\Bbb R$ supposed to be larger than $\Bbb Q$? I've learned that $\Bbb Q\subset \Bbb R$ . But with this definition, $\Bbb R$ is the union of many subsets of $\Bbb Q$. So again, it's a subset of $\Bbb Q$ . What's the reason of adding the 3rd statement? From second statement, Can we conclude that $A$ doesn't have minimum? Note 1 : By $\Bbb Q$, I mean Rational Numbers. Note 2 : This is the definition of one my professors who wanted to explain it briefly. I'm not sure if it's complete or wrong.  That's why I asked it here. Thanks in advance.","['real-analysis', 'real-numbers', 'rational-numbers', 'elementary-set-theory']"
1919305,Why is the kernel of an integral transform called kernel?,"I mean, in mathematics things with the same name are usually related. So, what is the relationship between the kernel of an integral transform and the kernel of an linear transformation? If it is none, why the kernel of an integral transform is called like that? There is another post here that says that there is no relationship but I don't think that is true.","['integral-transforms', 'linear-algebra']"
1919345,"(Hausdorff ) Locally convex spaces and their ""natural"" metric","Today we were introduced to locally convex spaces, defined thusly: A vector space is locally convex iff it has a family of semi-norms $(p_i)$ such that $x=0$ if and only if $p_i(x)=0$ for all $i$. The professor then said we would limit ourselves to countable families $(p_i)$ and introduced the following function: $$d(x, y) = \sum_{n=0}^\infty \frac 1 {2^n} \frac {p_n(x-y)}{1+  p_n(x - y)}$$ He explained that this is always a metric, and called it the ""natural"" metric. Naturally, it didn't seem that natural to any of us. This same formula is also found on Wikipedia . Is there some property of this metric which characterizes it? Is it for instance the only metric having some form of compatibility with the family of semi-norms $(p_i)$?","['functional-analysis', 'locally-convex-spaces']"
1919378,Proving $f(x+a) \geq f(x)$ almost everywhere,"I encountered the following problem in past analysis qualifying exam: Problem. Let $f \in L_{loc}^{1}(\mathbf{R})$ be real valued and assume that for each $n > 0$ , we have $f(x+ \frac{1}{n}) \geq f(x)$ for almost all $x \in \mathbf{R}$ . Show that for each real number $a \geq 0$ we have $f(x+ a) \geq f(x)$ , for almost all $x \in \mathbf{R}$ . It is trivial to check that the statement is true for any nonnegative rational number $a$ but what about irrationals? I don't know how to use the given condition $f \in L_{loc}^{1}(\mathbf{R})$ . Would anyone help me? Thanks in advance!",['real-analysis']
1919409,Mori Cone of a surface,"Suppose we have generic surface in a Toric variety (say an elliptically fibered 3-fold), it can be branched over a divisor too, and suppose we actually know the complete set of divisors over this surface (where the number them is the same as the Picard number), and their intersection form. So can anyone help me to see how can I find a new set of basis such that every effective divisor can be expended in terms of them with positive integer coefficients (i.e. to find it's Mori Cone, if I'm right). Thanks a lot,","['toric-varieties', 'algebraic-geometry']"
1919417,Non-compact operator $T\in\mathcal{B}(\ell_2)$ with $\|Te_n\|\rightarrow 0$,"I'm looking for an example of a non-compact linear operator in $\mathcal{B}(\ell_2)$ such that, for an orthonormal basis $\{e_1,e_2,\ldots\}$ of $\ell_2$, we have $\lim_{n\rightarrow\infty}\|Te_n\|=0$. I've been trying shift operators but I'm hitting some snags. A forward unilateral shift is compact iff its weights converge to $0$ so I'm thinking such operators won't do the trick.","['functional-analysis', 'compact-operators', 'examples-counterexamples', 'operator-theory']"
1919423,Equivalence to essentially self-adjoint,"In a book I have found a statement (without proof): Let $A$ be a symmetric operator on a Hilbert space $\mathcal H$ , the following are equivalent: $A$ is essentially self-adjoint $\nu(i)=\nu(-i)=0$ The ranges of $A-i \mathbb{1}$ and $A+i\mathbb 1$ are dense in $\mathcal H$ Here $\nu(\lambda)$ is defined as the dimension of the $\ker(A^*-\lambda \mathbb 1)$ . I don't really know where to begin with the proof. For 2. and 3. is it necessary to have both parts of the statement or are they already equivalent to each other? How can the statement be proven? I think at this point I would appreciate hints more than the direct proof.","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
1919432,"Every point of a grid is colored in blue, red or green. How to prove there is a monochromatic rectangle?","I have a $3$-coloring of $\mathbb{Z}\times\mathbb{Z}$, i.e. a function $f:\mathbb{Z}\times\mathbb{Z}\to\{\color{red}{\text{red}},\color{green}{\text{green}},\color{blue}{\text{blue}}\}$. I have to prove that there is a monochromatic rectangle with its sides being parallel to the axis, i.e. to prove that for some choice of $a,b,c,d\in\mathbb{Z}$ with $a\neq b$ and $c\neq d$, all the points $(a,c),(a,d),(b,c),(b,d)\,$ have the same color. I tried to work by contradiction, without achieving much. Additionally, can we prove some upper bound on $|a-b|$ and $|c-d|$?","['combinatorics', 'coloring']"
1919450,Is the closure of a countable $G_\delta$ set countable?,"This is in Cantor space ($2^\omega$ with the usual topology). In the course of trying to prove something else, I've found myself wanting to show that whenever $X$ is a countable $G_\delta$ set, the closure $\overline{X}$ is also countable. This seems perfectly reasonable (keep in mind that countable $G_\delta$ sets are nowhere dense), but I can't seem to prove it (note that the closure of a countable nowhere dense set can easily have size continuum - take the endpoints of a Cantor-like set). Even worse, I vaguely remember having this problem on an analysis exam years ago and getting it right . I'm sure I'm just having a silly moment (I was unsuccessful this morning in my quest to secure coffee) , but: is the closure of a countable $G_\delta$ subset of Cantor space, itself countable?","['general-topology', 'real-analysis']"
1919451,Does the linear transformation that a matrix encodes depend on a choice of basis?,"Context Let $M$ be an $m \times n$ matrix of real numbers. Let $\mathbf{x}$ be column vector of length $n$ with elements $x_1, \ldots , x_n \in \mathbb{R}$. Let $\vec{x} = (x_1, \ldots , x_n) \in \mathbb{R}^n$ be its analogue in $\mathbb{R}^n$. Let $\vec{\mathbf{e}}^t$ denote the standard basis in $\mathbb{R}^n$ so that $$
\vec{\mathbf{e}} = 
\left[
\begin{array}
.\vec{e_1} \\
\vec{e_2} \\
\vdots \\
\vec{e_n}
\end{array}
\right]
$$ and let $\vec{\mathbf{b}}^t$ denote a non-standard basis in $\mathbb{R}^n$ with $$
\vec{\mathbf{b}} = 
\left[
\begin{array}
.\vec{b_1} \\
\vec{b_2} \\
\vdots \\
\vec{b_n}
\end{array}
\right]
$$ Fact from Linear Algebra: $M$ encodes a linear transformation $T:  \mathbb{R}^n \rightarrow \mathbb{R}^m$ such that $$
M \mathbf{x} = \mathbf{y}
$$ where $\mathbf{\vec{e}}^t M \mathbf{x} = T(\vec{x}) = \vec{y}$ is some vector in $\mathbf{R}^m$. Question Does the linear transformation $T$ that $M$ corresponds to depend on our choice of basis? That is, if instead of working with  $\mathbf{\vec{e}}^t$  we instead worked with $\mathbf{\vec{b}}^t$, would $M$ encode a different linear transformation? For example, if $$
\mathbf{\vec{e}}^t \mathbf{x} = \vec{x} = \mathbf{\vec{b}}^t \mathbf{x'}
$$ then do we have that $$
\mathbf{\vec{e}}^t M \mathbf{x} = T(\vec{x}) = \mathbf{\vec{b}}^t M \mathbf{x'}?
$$ EDIT Ok. Upon reflection, it is obvious that our choice of basis matters significantly. For example, let us work in $\mathbb{R}^2$ and let our non-standard basis be $(1,1)$ and $(1, -1)$. Then the identity matrix $$
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$ will now send $(1,0)$ to $(1,1)$ since $$
\begin{bmatrix} (1, 1) & (1, -1) \end{bmatrix} \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \left[
\begin{array}
& 1 \\
0
\end{array}
\right] = (1,1)
$$ which is clearly a different mapping than the identity mapping that would result were we to use the standard basis (where $(1, 0) \mapsto (1,0)$).","['matrices', 'linear-algebra']"
1919538,"Consider $f: S^1 \to$ Figure Eight. $f$ is an immersion, but how?","I am reading Guillemin and Pollack. The definition of an immersion they give is: $f: X \to Y$ is an immersion at $x \in X$ if $df_x : T_x(X) \to T_y(Y)$ is injective. If $f$ is an immersion $\forall x \in X$, then we say that $f$ is an immersion. So apparently the map from the circle to the figure 8 is an immersion, as they state on the next page. But what about the critical point in the mapping $f$? There is no tangent space defined here, correct? So then how could $f$ possibly be an immersion? Also, is there a simple example of something that isn't an immersion that will help me remember this definition? Thank you.","['differential-geometry', 'differential-topology']"
1919595,Use the Cauchy-Schwarz inequality to prove $||x||_1 \leq \sqrt{n}||x||_2$,"If $x,y \in \mathbb{R}^n$, then the Cauchy-Schwarz Inequality tell us that
$$|x^Ty| \leq ||x||_2||y||_2,$$
where
\begin{align*}
\|x\|_2 &= \sqrt{\sum_{i=1}^nx_i^2},\\ 
\|x\|_1 &= \sum_{i=1}^n|x_i|.
\end{align*}
To show that 
$$||x||_1 \leq \sqrt{n}||x||_2,$$
we let $x = (|x_1|, |x_2|, \cdots, |x_n|)$ and $y = (1,1, \cdots, 1)$. 
Then
$$|x^Ty| \leq ||x||_2||x||_2 \Rightarrow |\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1},$$
but for each $i = 1,2, \ldots,n$, we have
\begin{align*}
|x_i| &>0,\\ 
|x_i|^2 &= x_i^2,
\end{align*}
hence it follows that 
$$|\sum_{i=1}^n|x_i|| = \sum_{i=1}^n|x_i| \text{ and } \sqrt{\sum_{i=1}^n|x_i|^2} = \sqrt{\sum_{i=1}^nx_i^2}.$$
Therefore,
$$|\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1} \Rightarrow ||x||_1 \leq \sqrt{n}||x||_2,$$
as required. Is this approach correct?","['functional-analysis', 'normed-spaces', 'inequality', 'proof-verification']"
1919616,Riemann surfaces and folding,"I am learning about Riemann surfaces as covering, and was interested to know how Riemann first thought of them. Looking at his collected papers, I found the following definition in his lecture called “Foundations for a general theory of functions of a complex variable” (p. 3-4 in “Collected Papers. Bernhard Riemann” of Kendrick Press): “For the following treatment we permit $x, y$ to vary only over a finite region. The position of the point $0$ is no longer considered as being in the plane $A$, but in a surface $T$ spread out over the plane. We choose this wording since it is inoffensive to speak of one surface lying on another, to leave open the possibility that the position of $0$ can extend more than once over a given part of the plane. However, in such a case we suppose that the portions of surface lying upon one another do not connect along a line. Thus a folding [Umfaltung] of the surface, or a splitting of the surface into superimposed parts, does not occur.” Here $A$ is the complex plane $\mathbb{C}$ or the sphere, i.e. $\mathbb{C}  \cup \{ \infty \} $.  After this definition Riemann defines the branching point of such a cover, where, if $f: T → A$ is the cover, then $f(z)$ is the branch point if it is locally of the form $f(z) = z^m$. However, what I didn’t understand is what is actually this “folding”. There is later (p. 24-25) a definition, where it seems that Riemann means by that, that $df/dz$ vanishes along a line,  but I am not sure that I understood it correctly…. Are there more possibilities that this “folding” would appear, acc. to Riemann? I also must admit, that I didn’t find any other references of this singularity in his writings, or maybe it was renamed...","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry', 'branch-points']"
1919632,"If $X$ is infinite and $x \in X$ , show $X \thicksim X \setminus \big\{x \big\}$.","I need to prove that If $X$ is infinite and $x \in X$ , show $X \thicksim  X  \setminus \big\{x \big\}$. here ~ is an equivalence relation meaning they must have same cardinality So far I have said: Let $x_{n} = \big\{x_{1} , x_{2}, x_{3}, \ldots \big\}$ where $x_n \in X \setminus \big\{x \big\}$.
We are looking for a bijection from $x \rightarrow X\setminus \big\{x \big\}$ Here I am having trouble with the bijection. 
$$
\begin{aligned}
f(y)=
\begin{cases}
c_{1}&\text{if }y=x\\
c_{i+1}&\text{if }y=c_{i}\\
y&\text{otherwise}
\end{cases}.
\end{aligned}
$$ How do i prove the piecewise function to be onto and 1-1","['elementary-set-theory', 'functions']"
1919689,Christoffel symbols and their transformation law,"I have a problem with derivation of the transformation law for Christoffel symbols: two different approaches give me two different results. I assume that the equation for the covariant derivative of a vector shall be transformed as a tensor and transform it and those parts in it which I know. Here is what I get ($A^i_{\,;l}$ denoting covariant derivative):
$$A^i_{\,;l} = \frac{\partial A^i}{\partial x^l}+\Gamma^i_{\,kl}A^k = 
\frac{\partial x^{'m}}{\partial x^l}  \frac{\partial}{\partial x^{'m}} \left(A^{'n} \frac{\partial x^i}{\partial x^{'n}} \right) + \Gamma^i_{\,kl} A^{'n}\frac{\partial x^k}{\partial x^{'n}} =\\ =\frac{\partial x^{'m}}{\partial x^l}  \frac{\partial A^{'n}}{\partial x^{'m}} \frac{\partial x^i}{\partial x^{'n}}+ \frac{\partial x^{'m}}{\partial x^l}A^{'n} \frac{\partial^2 x^i}{\partial x^{'n}\partial x^{'m}} + \Gamma^i_{\,kl} A^{'n}\frac{\partial x^k}{\partial x^{'n}} $$
On the other hand,
$$ A^i_{\,;l} = A^{'m}_{\enspace;n}\frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'n}}{\partial x^{l}} = \frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'n}}{\partial x^{l}} \frac{\partial A^{'m}}{\partial x^{'n}} + \frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'n}}{\partial x^{l}} \Gamma^{'m}_{\enspace nk} A^{'k}$$
From here I get, as far as $A^{'n}$ can be any vector,
$$\frac{\partial x^{'m}}{\partial x^l}A^{'n} \frac{\partial^2 x^i}{\partial x^{'n}\partial x^{'m}} + \Gamma^i_{\,kl} A^{'n}\frac{\partial x^k}{\partial x^{'n}} = \frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'n}}{\partial x^{l}} \Gamma^{'m}_{\enspace nk} A^{'k} = \frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'k}}{\partial x^{l}} \Gamma^{'m}_{\enspace kn} A^{'n}
\\
\Gamma^i_{\,kl} \frac{\partial x^k}{\partial x^{'n}} = \frac{\partial x^i}{\partial x^{'m}}\frac{\partial x^{'k}}{\partial x^{l}} \Gamma^{'m}_{\enspace kn} - \frac{\partial x^{'m}}{\partial x^l} \frac{\partial^2 x^i}{\partial x^{'n}\partial x^{'m}}
\\
\Gamma^{i}_{\,kl} = \frac{\partial x^i}{\partial x^{'m}} \frac{\partial x^{'n}}{\partial x^{k}} \frac{\partial x^{'k}}{\partial x^{l}}\Gamma^{'m}_{\enspace,nk} - \frac{\partial x^i}{\partial x^{'m}}\frac{\partial^2 x^{'m}}{\partial x^{k}\partial x^{l}}$$
Meanwhile, if I express $A^{'m}_{\enspace;n}$ through $A^{i}_{\,;l}$ I get a different result:
$$ A^{'m}_{\enspace;n} = \frac{\partial A^{'m}}{\partial x^n}+\Gamma^{'m}_{\enspace nk} A^{'k} = ...  =\frac{\partial x^{r}}{\partial x^{'n}}  \frac{\partial A^{i}}{\partial x^{r}} \frac{\partial x^{'m}}{\partial x^{i}}+ A^{i}\frac{\partial x^{r}}{\partial x^{'n}} \frac{\partial^2 x^{'m}}{\partial x^{i}\partial x^{r}} + \Gamma^{'m}_{\enspace nk}A^{i} \frac{\partial x^{'k}}{\partial x^{i}} 
\\ 
 A^{'m}_{\enspace;n} = A^{i}_{\,;l}\frac{\partial x^{'m}}{\partial x^{i}}\frac{\partial x^{l}}{\partial x^{'n}} = \frac{\partial x^{'m}}{\partial x^{i}}\frac{\partial x^{l}}{\partial x^{'n}} \frac{\partial A^{i}}{\partial x^{l}} + \frac{\partial x^{'m}}{\partial x^{p}}\frac{\partial x^{l}}{\partial x^{'n}} \Gamma^{p}_{\enspace li} A^{i} \\ 
\Gamma^{i}_{\,kl} = \frac{\partial x^i}{\partial x^{'m}} \frac{\partial x^{'n}}{\partial x^{k}} \frac{\partial x^{'k}}{\partial x^{l}}\Gamma^{'m}_{\enspace,nk} + \frac{\partial x^i}{\partial x^{'m}}\frac{\partial^2 x^{'m}}{\partial x^{k}\partial x^{l}}$$ I know that the correct formula is the second one. Could you explain me what is wrong with the first approach? I am sorry for a really silly question, as I guess.",['differential-geometry']
