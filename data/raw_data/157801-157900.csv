question_id,title,body,tags
2700456,Find all postive integers $n$ such that $n+\varphi{(n)}=2\tau{(n)}$,"Let $n$ be a positive integer such that $$n+\varphi{(n)}=2\tau{(n)}$$ where φ is the Euler's totient function and τ is the divisor function i.e. number of divisors of an integer. since $$4+\varphi(4)=4+2=6=2\cdot 3=2\tau(4)$$ $$6+\varphi(6)=6+2=8=2\cdot 4=2\tau(6)$$ maybe $n=4,6$ is only solution? and How prove it, I asked a similar question earlier, but it seemed different. Find all postive integers $n$ such that $n+\tau{(n)}=2\varphi{(n)}$","['number-theory', 'divisor-counting-function', 'totient-function']"
2700512,Is $x^5+x+5=y^2$ solvable over the integers?,"With Falting's theorem, it can be shown that $$y^2=f(x)$$ where $f(x)$ is a squarefree polynomial with integer coefficients and degree at least $5$ has only finite many rational solutions. Hence, an equation like $$x^5+x+5=y^2$$ can have only finite many integer solutions. I did neither find a number $p$ such that the equation is not solvable modulo $p$ nor did I find a solution yet. Can I decide whether such an equation is solvable over the integers in general ? In other words, are efficient bounds known (they need not be unconditional) ?","['diophantine-equations', 'algebraic-geometry', 'number-theory', 'algebraic-curves', 'elementary-number-theory']"
2700527,Arranging numbers from $1$ to $n^2$ in a $n\times n$ board,"Can the numbers $1,2,...,n^2$ be written in the cells of an $n\times n$ board in such a way that any two consecutive numbers are in adjacent cells (sharing a side), and all perfect squares are in the same column? Note: The original problem comes from All-Russian Mathematical Olympiad 1995 (fourth round, question 8) for the special case where $n=11$. By counting the number of cells in the left and right side of that column we know that for an odd number $n$, there's not an arrangement satisfying those conditions. So we only have to consider the case where $n$ is even. For $n=4k+2$ we can make explicit construction, but writing it down clearly may be difficult. For $n=4k$, it seems that there's no arrangement. However, I have no idea how to prove it. Can someone solve the case completely where $n$ is even?","['contest-math', 'puzzle', 'combinatorics', 'recreational-mathematics', 'discrete-mathematics']"
2700581,Determine the probability density function for $Y=X^2$.,"Question: Let $X\sim U(0,1)$.Determine the probability density function of the following variable $Y=X^2$. Defining the p.d.f for $X$ we have $f_X(x)=\begin{cases}0\:\:if\:x\notin[0,1]\\1\:\:if\:x\in[0,1]\end{cases}$ I know that $E(Y)=\int_\limits{R}{}g(x)f_x(x)dx=\int_\limits{0}^{1} x^2\times 1=\frac{1}{2}$, for $Y=g(X)=X^2$ $Var(Y)=E(Y^2)-(E(Y))^2=\frac{1}{5}-\frac{1}{9}=\frac{4}{45}$ According to my resolution the p.d.f should remain the same $f_X(x)=\begin{cases}0\:\:if\:x\notin[0,1]\\1\:\:if\:x\in[0,1]\end{cases}$. Question : What is the point of askin the p.d.f for $Y$? Or is my answer wrong? If so, why? Thanks in advance!","['statistics', 'probability']"
2700600,"What is the solution to this peculiar Integral: $\int \tan \left(\frac 1 x\right) \, dx$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I tried to integrate: $$\int \tan \left(\frac 1 x\right) \, dx$$ using integration by parts, and also by universal substitution but to no avail. WolframAlpha reports that ""no result found in terms of standard mathematical functions."" What could it be?","['real-analysis', 'calculus', 'indefinite-integrals', 'integration', 'special-functions']"
2700614,A question regarding localization of ring,"Let $A, B$ be two commutative rings. Let $p$ be a prime ideal of A. Now, suppose we have two ring homomorphisms $f:A \rightarrow B$ and $g: B \rightarrow A_{p}$ such that $g \circ f$ is the canonical map from $A$ to $A_{p}$. Then is it true that $A_{p}$ is isomorphic to $B_{g^{-1}(pA_P)}$? If yes, how can we prove it? I think it is at least true if $f$ is an injective map. Also, I think I can show that the canonical map from $A_p$ to $B_{g^{-1}(pA_P)}$ is injective.","['abstract-algebra', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
2700621,Are there explicit constructions of codes attaining the GV bound?,"I am looking for a code with the following parameters: Has $k= 128$ and a rate $R$ of at least $1/20$ Has a relative distance of at least $\delta = 3/10$ Provides efficient encoding Is binary This basically boils down to codes that attain the GV bound. I ruled out random linear codes, because I need to be sure that the code really has the required minimal distance. I am relatively new to coding theory and the best approach I could find so far were algebraic geometric codes, because I read in some places that they attain or even beat the GV bound. However, in some of the theorems I also read that the proofs were not constructive, but only probabilistic. Hence, before diving into algebraic geomtry, I have the following questions: Are there efficient constructions of algebraic geometric codes attaining the GV bound with the parameters listed above. Are there maybe other codes that achieve the parameters above? I also saw the paper Explicit, almost optimal, epsilon-balanced codes . It has a lot of asymptotics in it, but since my $n$ and $k$ are relatively large compared to usual applications, I thought it might work out.","['coding-theory', 'algebraic-geometry']"
2700642,Given any sets $X$ and $Y$ with $(X\times X)\cap Y\subseteq X$ must it be true that $(X\times X)\cap Y=\emptyset$?,"Given any sets $X$ and $Y$ with $(X\times X)\cap Y\subseteq X$ must it be true that $(X\times X)\cap Y=\emptyset$? I believe it is, I mean $(X\times X)\cap Y\subseteq X\times X$ so if its not empty $(X\times X)\cap Y$ then its a set of ordered pairs of the elements of $X$ contained in $X$ which doesn't seem right to me. However I've made dumb/trivial mistakes with the axiom of regularity before and other times when I'm dealing with multiple sets operating on each other while also being defined in terms of each other and with my naive intuition often causing me to think of elements as objects in their own right rather then just sets themselves belonging inside other sets this sometimes can cause me to make errors. Anyway to iterate if this is trivial/obvious I am sorry. I thought I had an okay grasp on set theory but as I've been playing around with various definitions it seems I know far, far less then I thought I did. So I'm often doubting myself when manipulating objects containing sets within sets etc. or where I have a set that is sort of related to another set it contains in such a manner that it seems like something is self referencing from within itself to another set lower down contained in it.",['elementary-set-theory']
2700660,Bounded linear operator (between Banach spaces) with second category range has closed range,"I'm attempting a problem about closed range of a bounded linear operator. Assume $X, Y$ are Banach spaces and $A$ is a bounded linear operator. 
  If $\operatorname{Ran}(A)$ is of the second category,
  then show that $\operatorname{Ran}(A)$ is closed. I want to use the Closed Graph Theorem and assume that $Ax_i \to y$ in $Y$,
if we can show that $x_i \to x$ in $X$, then the result follows by continuity of $A$. But I'm having a hard time showing that $\{x_i\}$ is a convergent sequence in $X$, and don't know how to use the fact that $\operatorname{Ran}(A)$ is of the second category. Any help would be appeciated!",['functional-analysis']
2700663,foliation with many tangencies,"Suppose you have smooth foliation on a Euclidean ball $\mathbb{B}^{4} \subset \mathbb{C}^{2}$, whose leaves are holomorphic curves with respect to the standard complex structure. Let $(z_{1},z_{2})$ be coordinates on $\mathbb{C}^{2}$. Suppose that at every point $p$ in the $z_{1}$-axis, the leaf of the foliation through $p$ meets the $z_{1}$-axis tangentially. Can we deduce that in fact the $z_{1}$-axis must be a leaf of the foliation? how to show it?","['complex-geometry', 'complex-manifolds', 'foliations', 'geometric-topology', 'holomorphic-functions']"
2700674,Counting 3-cycles in $S_6$,"I've bolded the incorrect part. Find the number of order $3$ elements in $S_6$ My ""Solution"": There are two ways to obtain these, either a 3-cycle or product of 2 disjoint 3-cycles. Counting 3-cycles: Choose 3 of 6 elements, this will determine the first 3 elements. We don't worry about the order of the rest. To get the distinct cycles (noting $(1 2 3) = (2 3 1)$), we fix the first element and permute the remaining elements. Thus:
$\frac{6!}{3!3!} (3-1)!=40$ Counting Disjoint 3-cycles: Choose 3 of 6 elements, this will determine the first 3 elements. Using the above computation we obtain $40$. We need to account for of the rest. Noting again that some cycles are similar, we fix the first element and permute the remaining to get distinct cycles, thus: $40\times (3-1)! = 80$ Thus: $120$ elements of order $3$. The bolded reasoning is incorrect. The answer key says it should be 40. How am I over counting?","['abstract-algebra', 'group-theory', 'proof-verification']"
2700711,Probability basics,"Just a quick Q on the last question (c).
Based on research of the average lifetime a couple assumes a probability of $0.75$ that the husband will still be alive in $20$ years while the wife has a chance of $0.8$. How likely are the following events? (a) Both are still alive in $20$ years. $$P(A∩B)= 0.75 \cdot 0.8$$ (b) None of them is still alive in $20$ years. $$P(A∩B)= 0.25 \cdot 0.2$$ (c) At least one of them is still alive in $20$ years. Now for c I used $$P(A∪B)= 0.75 + 0.8 -(0.75\cdot0.8)$$ but my friend said it's wrong and said I should use $(A∩B)$ but with additions. Is this correct? Was I wrong?","['probability', 'probability-distributions']"
2700749,A closed ball in a metric space is closed,"Prove that any closed ball in a metric space is closed. (Note that this is not a duplicate as this is a proof verification question and have a different proof, in my opinion, as compared to other proofs on this site) My Attempted Proof: Let $(X, d)$ be a metric space. Pick a closed ball $\Phi = \overline{B(x, r)} = \{y \in X \ | \ d(x, y) \leq r\}$. Note that at this moment in time $\overline{B(x, r)}$ is just a notation, we don't know if $\Phi$ is actually closed. We now show that $\Phi$ is closed. To do this we show that $X \setminus \Phi$ is open. Observe that $X \setminus \Phi = \{y \in X \ | \ d(x, y) > r\}$. Pick $y \in X \setminus \Phi$. For this $y$ we have $d(x, y) > r$ which implies that $d(x, y) = r + \epsilon$ for some $\epsilon > 0$. We claim that $B(y, \epsilon) \subseteq X \setminus \Phi$. To prove this claim, pick $z \in B(y, \epsilon)$. We now show that $z \in X \setminus \Phi$ by showing that $d(x, z) > r$. To that end observe that the triangle inequality gives us \begin{align*} 
		& d(x, y) \leq d(x, z) + d(z, y) \\ 
		& \implies \epsilon + r \leq d(x, z) + d(y, z) \\
		& \implies \epsilon + r < d(x, z) + \epsilon \ \ \ \ \ \  \ \ \  \text{since $d(y, z) < \epsilon$} \\
		& \implies r < d(x, z)
		\end{align*} as desired. Hence $z \in X \setminus \Phi$ and we have $B(y, \epsilon) \subseteq X \setminus \Phi$, and since $y$ was arbitrary we have that $X \setminus \Phi$ is an open set in $(X, d)$ and thus $\Phi$ is a closed set. $\square$ Is this a rigorous and satisfactory proof? Can it be improved in any way?","['general-topology', 'metric-spaces', 'proof-writing', 'proof-verification']"
2700767,Proving a probability equation,"Prove that $$P[\overline D ∩F] = P[F]−P[D ∩F].$$ It is known that  $$F = (D∩F)∪(\overline D∩F)  $$ So I tried to prove it but I am stuck at $$ P[(D ∩F) ∪ (D ∩F)] - P[(D ∩ (D ∩F) ∪ (\overline D ∩F)  $$
Am I on the right track so far?","['probability-theory', 'probability']"
2700795,Is $x$ not actually equal to $e^{\ln(x)}$?,"Yeah, this is a silly question, but I can't seem to convince myself that the graph $f(x)=x$ is really equal to the graph of $g(x)=e^{\ln(x)}$. Specifically, doesn't this fail on negative values of $x$? Since $g(x)$ is not defined on negative values of $x$, I don't see how these two could be equal. How could I remedy $g(x)$ without using piecewise functions to make these functions have the same domain?","['algebra-precalculus', 'logarithms', 'exponential-function']"
2700834,Equivalance of surjections from a surface group to a free group,"Let $g \geq 2$.  Let $S = \langle a_1,b_2,...,a_g,b_g | [a_1,b_1] \cdots [a_g,b_g] \rangle$ be the fundamental group of a genus $g$ surface and let $F_g$ be a free group with $g$ generators.  Given two surjections $f_1,f_2 : S \to F_g$ is there a way to determine if there are automophisms $\phi: S \to S$ and $\psi: F_g \to F_g$ so that $f_1 = \phi \circ f_2 \circ \psi$?","['combinatorial-group-theory', 'geometric-topology', 'group-theory']"
2700854,Product of two Hermitian matrices,"According to Wikipedia: The product of two Hermitian matrices $A$ and $B$ is Hermitian if and only
  if $AB = BA$. So if I understood correctly, if $C=AB$, then C will be Hermitian if and only if $AB=BA$. But... I've been able to create a matrix $S$ then did $R=SS^H$, and $R$ turned out to be Hermitian, even though $SS^H \neq S^HS$. So I'm clearly misunderstanding that property I quoted. Could anyone help me? Thank you!","['matrices', 'hermitian-matrices']"
2700869,Expectation and Variance of $\bar{X}/S$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I got stuck on the following problem: Let $X_1 , \dots , X_n$ be iid from  $N(\mu,\sigma^2)$. How can I obtain E$(\bar{X}/S)$, E$((\bar{X}/S)^2)$ and E$(\bar{X}^2)$, E$((\bar{X}^2)^2)$? $\bar{X}$ is the sample mean and $S^2$ sample variance. I've tried jacobian method for the first without success, and no idea on how to deal with the second. Thanks for your help","['statistics', 'probability', 'statistical-inference']"
2700890,Chain rule for multivariable gradients - a matrix of gradients,"In my coursebook, there was a function to be differentiated. Its definition was: $$\varphi(x,y) = f(u(x,y), v(x,y)) $$ where $$f(u(x,y), v(x,y)) \in \mathbb R$$ This function is clearly a composition: $$(x,y) \mapsto_{g} (u(x,y), v(x,y)) \mapsto_f \varphi $$
Therefore, to calculate its derivative we need to apply the chain rule. On the one hand, the derivative is: $$\nabla \varphi = \left(\frac {\partial \varphi}{\partial x}, \frac{\partial \varphi}{\partial y} \right)$$
On the other hand, the derivative of $\varphi$ is: $$f' \cdot g' = \nabla f \cdot \nabla g$$ Now, here comes the part which I do not understand. I know that the derivative of a multivaiable function is a vector, therefore, I expect $\nabla g$ to be a vector looking something like this:
$$\nabla g = \left(\frac{\partial g}{\partial u}, \frac{\partial g}{\partial v}
 \right)$$
However, the textbook presentes $\nabla g$ as a matrix looking exactly like this: $$ \nabla g = \begin{bmatrix}\nabla u \\ \nabla v \end{bmatrix} $$
I do not understand why it is possible to present one gradient as a matrix of other gradients. Could you, please, clarify a little bit what is going on here?","['multivariable-calculus', 'calculus', 'vector-analysis']"
2700903,"Statistics - Chebyshev's rule, my answer is wrong for some reason?","I have the following problem : Determine what age interval will contain at least 95% of the data (Chebyshev's) ? Now, I have standard deviation of 1.516, mean of 19.211. The formula is $1-(1/k^2) = .95$ So I solve for k to get $\sqrt 2$. Now, I calculate the interval by mean + $\sqrt 2$*standard deviation = RIGHT AGE INTERVAL Why is this wrong? I get approximately $21.3578$. The left interval, let's just skip it for now. Is my logic off?",['statistics']
2700907,How much does each fraction contribute to decreasing a value?,"Say I have a value: 0.68. And this is decreased in half to 0.34 by multiplying it by $\frac{3}{4}$ and $\frac{2}{3}$. Let's consider this decrease of $\frac{1}{2}$ as 100% of the decrease. So then we can consider the idea that $\frac{3}{4}$ and $\frac{2}{3}$ each contributed to this decrease, but in different magnitudes. I want to quantify the magnitude that each contributed to the decrease by assigning a percent. If the total product contributes 100% to decreasing the value from 0.68 to 0.34, how can I get two percentages that represent how much the $\frac{3}{4}$ contributed and how much the $\frac{2}{3}$ contributed, respectively. Clearly the $\frac{2}{3}$ contributes more to the decrease of the value, but how much more? All of my attempts have been squandered by, what I think is an error in, order of operations. If I pull out $\frac{3}{4}$ and $\frac{2}{3}$ and multiply the 0.68 individually, it doesn't make sense to pull it back in to see it's impact because I have just ruined my order of operations.","['algebra-precalculus', 'fractions']"
2700917,$1$ as difference of composites with same number of prime factors,"I noticed and found only first three cases: We can write $1$ as difference of two composites that have one prime factor $$3^2-2^3=1$$ and as difference of two composites that have two prime factors $$3\cdot 5 - 7\cdot 2 = 1$$ and as difference of two composites that have three prime factors $$2^2 \cdot 3^2 \cdot 43-7 \cdot 13 \cdot 17=1$$ I believe that this holds for every $k \in \mathbb N$, that is, that for every $k \in \mathbb N$ there exist composites $a_k$ and $b_k$ that have exactly $k$ prime factors and are such that we have $a_k-b_k=1$. Is my belief true? Is this known? What is known about all of this and similar problems? Can someone find solutions for some larger $k$´s? There is a similar question here by Peter where he wants that all prime factors are different.","['number-theory', 'prime-numbers']"
2700921,"If $a_{n+1}+1=(na_n+1)^{\frac{1}{n}}$, prove that $a_{n+1}/a_n \to 1$ and $na_n \to 0$","Let $(a_n)_{\geq 2}$ with $a_2 > 0$ and $$a_{n+1}+1=(na_n+1)^{\frac{1}{n}}$$
  Prove that $\displaystyle\frac{a_{n+1}}{a_n}\to 1$ and $na_n \to 0$, eventually using the inequality $$\ln(1+x)>\frac{x}{x+1}, \: \forall x>0$$ I managed to prove that $a_n \to 0$. Using Bernoulli's inequality we get that $(a_n)$ is decreasing and it is obviously bounded by 0. If it were convergent to $l \neq 0$, we yould have 
$$\lim_{n \to \infty}\frac{\ln(na_n+1)}{n}=\lim_{n \to \infty}\frac{\ln(na_n+1)}{na_n}\cdot a_n=0\cdot l=0$$ since $na_n \to \infty$ and so $\lim_{n \to \infty}(na_n+1)^{\frac{1}{n}}=1$ hence
$$l+1=\lim_{n \to \infty}(a_{n+1}+1)=\lim_{n \to \infty}(na_n+1)^{\frac{1}{n}}=1$$ which is a contradiction, so $l=0$. This is where I got stuck. I don't know how to approach either of these two limits, but I'm pretty sure that their hint with the $\ln(x+1)$ inequality must be used somehow.","['real-analysis', 'limits', 'sequences-and-series', 'calculus', 'convergence-divergence']"
2700929,The distribution of random sum of random variables,There is a random variable $η$ with distribution continuous function $F(x)$ and a random variable $q$ with Poisson distribution with parameter $λ/µ$. What is the distribution of random sum of random variables $X(t)=η_1+η_2+...+η_{q(t)}$?,"['probability-theory', 'probability-distributions']"
2700938,"Find the equation of the normal at the point $(1,2)$ to the curve $y=x+\frac{1}{x}$.","The answer in the textbook is listed as $x=1$, however I don't understand why this is. My working: $$y=x+\frac{1}{x}$$ $$f'(x)=1-x^{-2}$$
$$f'(x)=1-\frac{1}{x^{2}}$$
$$f'(1)=1-\frac{1}{1}=0$$ Therefore the gradient of the tangent to the curve at $x=1$ is $0$. The gradient of the normal is given by: $$m_1m_2=-1$$
$$m_2=\frac{-1}{0}$$ As anything divided by $0$ is undefined, how do I then use this to find the the normal to the tangent, to the curve, at $x=1$? Is there a way of analytically working out tangents/normals when they are undefined, or is an alternative approach required? EDIT: 
My alternative approach would entail ascertaining the tangent at $(1,2)$, which turns out to be $y=2$ - a horizontal line; which means that the normal would be perpendicular to this and is thus given by $x$-value at this point, i.e. $x=1$. Is a visual way the only method of producing an answer? Is there a better way of demonstrating this?","['algebra-precalculus', 'tangent-line', 'calculus']"
2700941,Combinatorial proof: ${n \choose 1}+6{n \choose 2}+6{n \choose 3} = n^3 $,"Prove $${n \choose 1}+6{n \choose 2}+6{n \choose 3} = n^3$$ without algebra. I've been trying to think of it in terms of the volume of a cube, and also as the set $\{(x,y,z)|x,y,z \in \mathbb{N}, 1 \leq x,y,z \leq n\}$ (is this correct syntax?) , but that's as far as I've gotten.",['combinatorics']
2700968,sequence of square root of positive operators is convergent,"I'm trying to prove the next: a) If $A_{n}\geq 0,$ $A_{n}\rightarrow A$ in norm, then $\sqrt{A_{n}}\rightarrow\sqrt{A}$ in norm, b) Suppose that $A_{n}\rightarrow A$ strongly for a sequence $\{A_{n}\}.$ Then $\sqrt{A_{n}}\rightarrow\sqrt{A}$ strongly. I'm stuck prove this. I've seen the proof of a) using spectral theorem, but I don't familiar with this. I was thinking in a proof more elementary. I was thinking in something of the form 
$$||\sqrt{A_{n}}-\sqrt{A}||=||\frac{A_{n}-A}{\sqrt{A_{n}}+\sqrt{A}}||,$$ and then bounding denominator an use the hypotesis of convegence in norm, but I guess this is not correct and useless. Any kind of help is thanked in advanced.","['functional-analysis', 'operator-theory']"
2700977,Definition of Suspension (Topology).,"I am a bit confused with the definition of a suspension. This the definition. For a space $X$, denote $SX$ the suspension of $X$ in which this is the quotient space $$\frac{X \times I}{\sim}$$ where $\sim$ is the equivalence of relation of $X \times \{0\}$ and $X \times \{1\}$ collapsed to a point. The typical example is to set $X = S^n$. For $n = 1$, this is a ""cylinder"". What I don't understand is that why when we collapsed the top and end point of the cylinder our quotient space immediately becomes a ""double-cone""? For example let's say $X \times \{1\} \to \{x_1 \} \times \{1 \}$ and $X \times \{0\} \to \{x_2\} \times \{0\}$. I don't understand why suddenly points close to $0$ and $1$ ""shrink"". For example, at $X \times \{3/4\}$, the ""cone' picture depicts $S^1$ with a smaller radius. To clarify what the problem is when we ""shrink"", at $\{3/4\}$ $X$ is no longer $S^n$ If the above example is too diffuclt to explain, we can work with $X = I$, so that $(X \times I) / {\sim}$ is a ""diamond"" on $\mathbb{R}^2$","['algebraic-topology', 'general-topology', 'definition']"
2700980,C$^*$-algebras: When is there equality in the triangle inequality?,"(I had never thought about this question before, and I want to record the basic answer here for future reference) Let $A$ be a C$^*$-algebra, and $x,y\in A$. When do we have equality in the triangle inequality? $$\|x+y\|=\|x\|+\|y\|$$","['functional-analysis', 'normed-spaces', 'c-star-algebras', 'operator-algebras']"
2700989,Using Jordan Normal Form to determine when characteristic and minimal polynomials are identical,"Say I want to immediately write down a matrix with an identical minimal and characteristic polynomial. Say, $$ (t-1)^{3}(t-2). $$ My first instinct is to write down Jordan Blocks in a block diagonal matrix with blocks  $$ J_{3}(1), \text{ }J_{1}(2)$$  to give a matrix $$ \begin{bmatrix} 1 & 1  & 0 & 0 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 2
\end{bmatrix}. $$ Clearly this gives the required characteristic polynomial specified above. However, since we know that the minimal polynomial divides the characteristic polynomial, and that distinct roots must show up in the minimal polynomial, using the ease of Jordan Normal Form when multiplying matrices, we can quickly check each case  $(t-1)(t-2)$, $(t-1)^{2}(t-2)$, $(t-1)^{3}(t-2)$ and show that the last one is the only such zero matrix required. However, is it sufficient to argue from the get go, that because we've included only one Jordan Block of each eigenvalue of maximum size, we can immediately say that the characteristic and minimal polynomial are the same (due to the minimal polynomial of each individual block being the same as each of the factors in the characteristic polynomial)? In other words, if the minimal and characteristic polynomial are the same and is $$ \prod_{i=1}^{k} (t- \lambda_{i})^{n_{i}}, $$ then a matrix which immediately satisfies this is $$\begin{bmatrix} J_{n_{1}}(\lambda_{1}) & 0 & \dots & 0 \\ 0 & \ddots & & 
 \\ 0 & 0 & 0 & J_{n_{k}}(\lambda_{k}) \end{bmatrix}. $$ Does this seem reasonable? Thanks in advance.","['matrices', 'jordan-normal-form', 'linear-algebra', 'minimal-polynomials']"
2700995,From integral to expected value of probabilities,"I was reading about KL divergence and stumbled upon this post . In the Equation (2), we can see the following: \begin{align*}
D_{KL}(Q||P) &= \int_{-\infty}^{\infty} q(\theta|X) \log\frac{q(\theta|X)}{p(\theta|X)} d\theta \\
             &= \int_{-\infty}^{\infty} q(\theta|X) \log\frac{q(\theta|X)}{p(\theta,X)} d\theta +
                \int_{-\infty}^{\infty} q(\theta|X) \log{p(X)} d\theta \\
             &= \int_{-\infty}^{\infty} q(\theta|X) \log\frac{q(\theta|X)}{p(\theta,X)} d\theta +
                \log{p(X)} \\
             &= E_q\left[\log\frac{q(\theta|X)}{p(\theta,X)}\right] + \log p(X) \\
            \tag{2}
\end{align*} To go from line (1) to line (2), $p(\theta|X) = \frac{p(\theta,X)}{p(X)}$ and $\log{AB} = \log{A} + \log{B}$ are applied. Then, to go from line (2) to (3): given that $q(\theta|X)$ is a probability, $\int_{-\infty}^{\infty} q(\theta|X) = 1$ is applied. I don't understand how to go from line (3) to line (4). I think the same rule cannot be applied because the other terms are also dependent of $\theta$. Can someone help me to understand why: \begin{align*}
\int_{-\infty}^{\infty} q(\theta|X) \log\frac{q(\theta|X)}{p(\theta,X)} d\theta = E_q\left[\log\frac{q(\theta|X)}{p(\theta,X)}\right]
\end{align*} Any help is appreciated.","['probability-theory', 'probability', 'expectation']"
2701030,Generic element of a linear system; Bertini's theorem,"Bertini's theorem (see Griffiths and Harris, Principles of Algebraic Geometry) states that:The generic element of a linear system is smooth away 
from the base locus of the system. My questions are: 1)What is ""generic element of a linear system""? 2)what does it mean "" smooth away 
from the base locus of the system""? Thank you!","['line-bundles', 'algebraic-geometry']"
2701035,Writing the Beta Function in terms of the Gamma Function,"I am studying the gamma and beta functions and I have seen an exercise which asks you to re-write the beta function in terms of the gamma function as follows: $B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$ The only hint that the exercise gives is that you should start with a function of the form: $f(\alpha,\beta,t)=\int_0^tx^{\alpha-1}(t-x)^{\beta-1}dx$ The first thing I notice is that the right-hand side can be considered as a convolution of two functions, so: $L[f]=L[x^\alpha-1]L[(t-x)^{\beta-1}]$ However, this just ends up with the Laplace transform of f on the LHS and then a mess of transforms on the right.  The other thing is that if you set $t=1$, $f$ becomes the beta function: $f(\alpha,\beta,1)=B(\alpha,\beta)=\int_0^1x^{\alpha-1}(1-x)^{\beta-1}dx$ Hence I am hoping that if I convert $f$ to this form we have the beta function and then take the product of the Laplace transforms of the two functions in the convolution, it somehow comes out as a set of integrals which are equivalent to the given identity once I use the integral formula for the gamma function.  However, I have tried this and got a mess, could someone assist (if this is the right way of doing it)? Edit: I have looked on Wikipedia and seen that the identity can be proved just by taking the product of two gamma functions and then changing variables to show that this is $B(\alpha,\beta)\Gamma(\alpha+\beta)$: however, the exercise is in a section on Laplace transforms so I think it wants you to take the Laplace transform of the given function $f$ and work it out that way.","['complex-analysis', 'gamma-function', 'laplace-transform', 'beta-function']"
2701064,Proving $\int_{a}^{b}\vert P^{\prime}_{n}(x)\vert\text{d}x\leq 2n \max_{a\leqslant x\leqslant b}\vert P_{n}(x)\vert $,"So Assume that $P_{n}(x)$ is an algebraic polynomial of degree n. Prove that
$$\int_{a}^{b}\vert P^{\prime}_{n}(x)\vert\;\text{d}x\leq 2n\cdot\max_{a\leqslant x\leqslant b}\vert P_{n}(x)\vert$$
Please use the method of variable limit integral I know A.A.Markoff$\;\;$Theorem ——The above conditions are the same
$$\vert P^{\prime}_{n}(x)\vert\leq\dfrac{\displaystyle 2\max_{a\leqslant x\leqslant b}\vert P_{n}(x)\vert\cdot n^2}{b-a}
$$
So when you integrate the inequality on both sides from a to b, you can get
$$\int_{a}^{b}\vert P^{\prime}_{n}(x)\vert\;\text{d}x\leq 2n^2\cdot\max_{a\leqslant x\leqslant b}\vert P_{n}(x)\vert$$
That is so close to the final integral, but it's not So please help me,by the method of variable limit integral(That's the hint of the question) Thank you very much","['calculus', 'analysis']"
2701067,Differential Equation with Shifted Input,"So I'm fairly new to differential equations, and while tinkering around with graphs, I came up with one that is confusing me quite a bit. I have both a simpler form and a more complicated form. The simpler one is: $$
f(x)=f'(x-c)
$$ I see that when $c=0$, a solution is $f(x)=e^x,$ and that when $c=\frac{\pi}{2},$ solutions are $f(x) = \sin x$ and $f(x) = \cos x,$ but I don't see how to generalize it to any c. Conceptually, I view this equation as saying that when you take the derivative, the function is shifted over by $c.$ [ Edit : I couldn't get anywhere assuming the function was a sinusoidal, but I was able to get some results assuming an exponential: If we assume $f(x) = Ae^{bx}$, where $A$ and $b$ are real constants, we get the equation $$
Ae^{bx}=Abe^{b(x-c)}
$$ Taking the natural log of both sides and simplifying yields the following: $$
c=\frac{\ln b}{b}
$$ However, I can't figure out how to solve this for $b.$
] The more complicated form is: $$
f(x)=f^{(n)}(x-nc)
$$ This reduces to the simpler case when $n = 1,$ and when $c=\frac{\pi}{2},$ regardless of $n,$ solutions are again $f(x) = \sin x$ and $f(x) = \cos x$. However, again, I don't see how to generalize to both $n$ and $c,$ nor how to determine whether such a general solution exists. Conceptually, I view this equation as saying that each time you take the derivative of a function, it gets shifted $c$.",['ordinary-differential-equations']
2701071,"Prove an equivalent definition of $\sup\{T>0:x\in\overline{\mathbb R^n\setminus D_t },t \in [0,T) \},D_t\subset\mathbb R^n,x\in\partial D_0$","Let $D_t$ be closed, bounded and non-empty subsets of $\mathbb{R}^n$ for $t \ge 0$. Let $x \in \partial D_0$ and define
$$\mathcal{A}= \sup \{T>0: x \in \overline{\mathbb{R}^N \setminus D_t } \text{ for almost every } t \in [0,T) \}.$$
Assume that such sup exists and is finite.
Then let 
$$\mathcal{B}= \lim_{\delta \to 0^+}  \inf\{t>0: D_t \cap B_\delta(x) \not\subset D_0 \cap B_\delta(x) \},$$
where $B_\delta(x)$ is the ball of radius $\delta$ and centre $x$. How can I prove that $\mathcal{A} = \mathcal{B}$? Assume also that if $D_0 \subset B_{R_0}(0)$, then    $$D_t \subset B_{R_0 + C t^{\alpha}}\left(0\right),$$
where $C>0$ is fixed (possibly large) and $\alpha<1$ is fixed.","['general-topology', 'real-analysis', 'measure-theory']"
2701128,What is the index of a subgroup $H$ in a group $G$?,"I have read multiple definitions so far but something is not clicking. My most naive understanding is that $|G:H|$ is a ""number"" (could be infinite) that represents how many times $H$ is in $G$. But even this doesn't seem fully correct. I would like a general non-formal explanation and perhaps an example to understand the intuition.","['intuition', 'abstract-algebra', 'group-theory', 'definition']"
2701175,Confusion with Matrix calculus derivative computation.,"The text I am reading has the following $$E=(I+\nabla I\frac{\partial W}{\partial p}\Delta p -T)^2$$
where $\nabla I$ us a row vector $1$ by $2$, $\frac{\partial W}{\partial p}$ is a $2$ by $3$ matrix and $\Delta p$ is a $3$ by $1$ column vector. $I$ and $T$ are scalars.
 We seek the gradient $\frac{\partial E}{\partial \Delta p_k}$, but I do not understand their solution. I will present my attempt, and than their solution. In index notation, we have $(I+\nabla I_i\frac{\partial W^i}{\partial \Delta p_k}\Delta p^k -T)^2$, where summation if implied by repeated indicies, Than the derivative is $$\frac{\partial E}{\partial \Delta p_m}=2(I+\nabla I_i\frac{\partial W^i}{\partial p_k}\Delta p^k -T)\nabla I_n\frac{\partial W^n}{\partial p_m}$$
or returning to the matrix notation $$\frac{\partial E}{\partial \Delta p}=2(I+\nabla I\frac{\partial W}{\partial p}\Delta p -T)\nabla I\frac{\partial W}{\partial p}\tag{1}\label{1}$$ But their solution is $$\frac{\partial E}{\partial \Delta p}=2(\nabla I\frac{\partial W}{\partial p})^T(I+\nabla I\frac{\partial W}{\partial p}\Delta p -T)\tag{2}\label{2}$$ Why is their solution correct and where did I make the mistake? My solution is equation \eqref{1}, but theirs is \eqref{2}. I am confused, why in theirs, 
$$(\nabla I\frac{\partial W}{\partial p})$$
is transposed?","['derivatives', 'matrix-calculus']"
2701183,"The following domain is not integrally closed $\mathbb C[x,y]/\langle y^2 - x^3\rangle$","Consider the ideal in  $\mathbb C[x,y]$ given by $ \mathfrak{a} = \langle y^2 - x^3 \rangle$. We can easily prove that $\mathfrak{a}$ is prime by considering the morphism of rings
$$
\mathbb C[x,y] \to \mathbb C[t]
$$
given by  $x \mapsto t^2$ and $y \mapsto t^3$. Thus, $A := \mathbb C[x,y] / \mathfrak{a}$  is a domain. However, this domain is not integrally closed as
$$
(y/x)^2 - x =0
$$
is an integral dependence realtion for $y/x$ and $y/x \notin A$. My first question is Is there any relation (geometric) between the curve $y^2 = x^3$ and the fact that $y/x$ suffices an integral dependence realtion in $A$ but it is not in $A$? Moreover, since $A$ is not integrally closed, we know one of its localization at maximal ideals (a point, since $\mathbb C$ is algebraically closed) is not integrally closed (since $A = \bigcap_{\mathfrak{m}} A_\mathfrak{m}$). By the graph of the curve we could guess it is the origin (when I saw de the graph I immediatly thought it was the origin, as it appears to be weird, what's the correct term for this weirdness ?). Thus, I believe
$$
\mathbb C[x,y]/\langle y^2 - x^3 \rangle_{(x,y)} \simeq \mathbb C[t^2,t^3
]_{(t^2,t^3)}
$$
is not integrally closed, but I was not able to simplify the expression. Then, my second question question comes What's the relation between this singularity at the point, integrality and in spirit of the first question $y/x$? I believe I lack the geometric (and algebraic) intuition to completely understand what is happening.","['algebraic-geometry', 'commutative-algebra']"
2701192,Book Recommendations: Combinatorial Group Theory and Topological Prerequisites.,"I'm doing a PhD in combinatorial group theory and I can't help but notice that topology is adjacent to the research I'm doing. (In particular, I black box the combinatorial asphericity of certain presentations.) My topology isn't very good: off the top of my head, I can't remember the definition of a topology${}^1$ - that's how bad it is. Do you have any book recommendations for the topology of combinatorial group theory and what are each book's topological prerequisites ? A simple Google search produces a number of books but no review I've found of any of them states the topological prerequisites of the book at hand . Simple bullet points of topic titles would be satisfactory. Ideally, I'd like a book that introduces the very basics of topology alongside its applications to combinatorial group theory in depth. [1] It is 2:38 am . . . now . . . where I am, so, yeah, that's my excuse.","['self-learning', 'combinatorial-group-theory', 'book-recommendation', 'general-topology', 'group-theory']"
2701223,"Example of a (transient, countable state) Markov Chain with no invariant measure?","I would like to know whether an irreducible Markov chain on a countable state space must necessarily have at least one ($\sigma$-finite) invariant measure. (By an invariant measure I mean a possibly infinite measure which is preserved by the dynamics.) I suspect this is not true, so I'm looking for an example of such a Markov chain without an invariant measure, or a reference to a theorem confirming the above.","['markov-chains', 'probability-theory']"
2701249,"Given $0<\lambda<1.$ Prove that if all $x,y>0,$ $f(x+y) = \lambda f(x) + (1-\lambda)f(y),$ then $f$ is a constant function.","Question : Let $f:(0,\infty)\to\mathbb{R}$ be a measurable function and $0<\lambda<1.$ Prove that if all $x,y>0,$ $$f(x+y) = \lambda f(x)
 + (1-\lambda)f(y),$$ then $f$ is a constant function. My attempt: Fix $x,y>0.$
Note that 
$$f(2x)=f(x)$$
and 
$$f(2y) = f(y).$$
Also,
$$f(2x+y) = \lambda f(2x) + (1-\lambda)f(y) = \lambda f(x) + (1-\lambda)f(y) =  f(x+y).$$
Also, 
$$f(2x+y) = f(x+(x+y)) = \lambda f(x) + (1-\lambda)f(x+y).$$
Since $\lambda\neq 0,$ so we have 
$$f(x) = f(x+y).$$
By symmetry, we also have 
$$f(y) = f(x+y).$$
So 
$$f(x)=f(y).$$
So $f$ is a constant function. Is my attempt correct?","['real-analysis', 'measure-theory', 'proof-verification']"
2701251,Positive scalar curvature in dimension 4,"Let $M^n$ be a compact simply connected spin manifold. Gromov, Lawson, and Stolz proved that if $n\geq 5$, then $M$ admits a metric of positive scalar curvature iff $\alpha(M)=0$. Question: What happens in dimension 4? Are there compact simply connected spin manifolds of dimension 4 which have a metric of positive scalar curvature and $\alpha(M)\neq 0$? Are there compact simply connected spin manifolds of dimension 4 which have $\alpha(M)=0$ but no metric of positive scalar curvature? What are necessary and/or sufficient conditions for a compact simply connected spin 4-manifold to have a metric with positive scalar curvature?","['4-manifolds', 'riemannian-geometry', 'differential-geometry']"
2701336,Is a constant a random variable?,Can a constant $c$ be regarded as a random variable? Is it correct to define it as a discrete random variable X with probability mass function $P(X=c)=1$?,"['probability-theory', 'probability', 'measure-theory']"
2701348,Count the probability of a random $20$ bit string,"Consider binary words of length $20$. They are formed in such a way that a $1$ occurs with probability $0.6$, and a $0$ does with probability $0.4$ (diﬀerent places are independent). Also, a “run” is a maximal substring of only ones or only zeros; e.g., $00110001101011111111$ has $8$ runs. I think this question should be solved using Linearity of Expectation from Discrete Math II but It is kind of hard for me to make the connections between probability and counting theories. 1) What is the probability that a random bit string of length $20$ starts in a $0$, has exactly $8$ ones, and has exactly $10$ runs? I worked out that the probability of ""a random bit string of length $20$ starts in a $0$, has exactly $8$ ones"" is equal to $(0.6^8)\cdot(0.4^{11})$ because it starts with $0$ and then there're $19$ bits left. Then I want to use stars and bars theory to count the number of ways we can arrange $8$ ones and $11$ zeros to make it a ""$10$ run"" string. It is like choosing $4$ walls of ones to separate $19$ zeros. I am stuck here because I don't know how to make the connection between runs and the possibility of $o$'s and $1$'s ($0.4/0.6$). 2) What is the probability that a random bit string of length $20$ has exactly $10$ runs? Same idea here, to use the stars and bars theory to separate $4-16$ $1$'s or $0$'s using $4-16$ $0$'s or $1$'s. Ah, I just don't know how to start from here...","['combinatorics', 'probability']"
2701352,When does a polygon gives the maximum area?,"I have a polygon with $n$-vertices and of fixed length, I need to find a condition for which the polygon gives the maximum area without using isoperimetric inequality. I tried with the simple polygon ""Triangle"" ($n=3$) and find that it gives maximum area when it's 3 sides are equal. ( See here for proof ) Next, I break one side of the triangle to form a Quadrilateral ($n=4$). And find that it gives maximum area when it is a Square. ( See proof here ) My intuition tells me that if I increase $n$ then the corresponding polygon will give maximum if their sides are all equal, I assumed this is true for $n=k$ but I am unable to show this for $n=k+1$. Or is there is any other way to prove it? Any help will be appreciated. Thanks in advance.","['polygons', 'differential-geometry', 'geometry']"
2701375,What do the covariance function really tell us?,"Let the covariance function be defined as $C(s,t)=\mathbb{E}(X_{s}X_{t})-\mathbb{E}(X_{s})\mathbb{E}(X_{t})$. I seen atleast two places where authors claim that this function together with the mean ""characterises"" a square integrable process up to a isometry of $L^{2}(\Omega,\mathcal{A},P)$ for fixed $P$. I cant really see why this is the case since even if we know $C(s,t)$ we still now nothing about the finite dimensonal distributions. This could be the covariance between any kind of variables. These are the places https://www.amazon.com/Course-Theory-Stochastic-Processes-Wentzell/dp/0070693056 , page 17 https://www.amazon.com/Introduction-Stochastic-Control-Electrical-Engineering/dp/0486445313/ref=sr_1_1?s=books&ie=UTF8&qid=1521619878&sr=1-1&keywords=stochastic+control page 26 Update In Astrom he adds weak stationarity, but I cant find anything like this in Wentzell tho, here is that text,","['stochastic-processes', 'probability-theory']"
2701380,Given the function $f(x)=\frac {1}{\sqrt[3] {1-x^3}}$ find $\underbrace {f(f(\cdots f(19)\cdots))}_{95}$,Given the function $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ My try: Define $$f^n(x)=\underbrace {f(f(\cdots f(x)\cdots))}_{n}$$ We see that  $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ $$f^2(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ $$f^3(x)=x$$ And again $$f^4(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ Hence $$f^{3k+2}(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ Substituting $k=31$ and $x=19$ I can find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ So am I going on the right path.,"['contest-math', 'recursion', 'functions']"
2701381,Prove that the area of $\triangle DEF$ is twice the area of $\triangle ABC$,"Let $\triangle ABC$  be an equilateral triangle and let $P$ be a point on its circumcircle. Let lines $PA$ and $BC$ intersect at $D$ , let lines $PB$ and $CA$ intersect at $E$, and let lines $PC$ and $AB$ intersect at $F$. Prove that the area of $\triangle DEF $ is twice the area of $\triangle ABC$. I had used my method and it required that $\triangle DEF $ have to be isosceles triangle which means $ P $ should be the mid point of $\widehat {BC}$ or $\widehat{AC}$ or $\widehat {BC}$. But the problem does not said so. So, how to solve it correctly?","['circles', 'triangles', 'geometry']"
2701385,Adaptive Step Size in RK45 for Second-Order ODE,"My question pertains to the answer given in this post , but I am implementing the RK45 or RKF45 algorithm. Following the explanation in that post for a second order ODE, as an example I am looking at a pendulum whose equation of motion is
$$\ddot{\theta} = -\Omega_0^2 \sin\theta$$
Setting $\Omega_0$ (or converting to dimensionless variables) for simplicity, I separate this into two equation
$$\dot{v} = -\sin\theta$$
$$\dot{\theta} = v$$
I change this into a vector relationship,
$$
\begin{pmatrix}
	\dot{v} \\ \dot{\theta} 
\end{pmatrix}
=
\begin{pmatrix}
	-\sin\theta(t) \\ v(t)
\end{pmatrix} 
$$
Let's define the vector $\vec{y} = (v,\theta)^T$, then the left hand side is $\dot{\vec{y}}$ and the right side $\vec{f}(\vec{y}) = \vec{f}(\theta,v)$. The initial condition is given by $\vec{y}(t_0)$. Note there is no explicit time dependence, therefore the RK45 equations become
\begin{align*}
	\vec{k}_1 &= \delta t\,\vec{f}(\vec{y}(t_n)) \\[4pt]
	\vec{k}_2 &= \delta t\,\vec{f}\left(\vec{y}(t_n) + \tfrac{1}{4}\vec{k}_1\right) \\[4pt]
	\vec{k}_3 &= \delta t\,\vec{f}\left(\vec{y}(t_n) + \tfrac{3}{32}\vec{k}_1 + \tfrac{9}{32}\vec{k}_2\right) \\[4pt]
	\vec{k}_4 &= \delta t\,\vec{f}\left(\vec{y}(t_n) + \tfrac{1932}{2197}\vec{k}_1 - \tfrac{7200}{2197} \vec{k}_2 + \tfrac{7296}{2197}\vec{k}_3\right) \\[4pt]
	\vec{k}_5 &= \delta t\,\vec{f}\left(\vec{y}(t_n) + \tfrac{439}{216}\vec{k}_1 - 8\vec{k}_2 + \tfrac{3680}{513}\vec{k}_3 - \tfrac{845}{4104}\vec{k}_4\right) \\[4pt]
	\vec{k}_6 &= \delta t\,\vec{f}\left(\vec{y}(t_n) - \tfrac{8}{27}\vec{k}_1 + 2\vec{k}_2 - \tfrac{3544}{2565}\vec{k}_3 + \tfrac{1859}{4104}\vec{k}_4 - \tfrac{11}{40}\vec{k}_5\right)
\end{align*}
where $\vec{y}(t_n) = (v(t_n),\theta(t_n))^T$. The new values are given to fourth order by
$$\vec{y}^{(4)}(t_{n+1}) = \vec{y}(t_n) + \left(\tfrac{25}{216} \vec{k}_1 + \tfrac{1408}{2565}\vec{k}_3 + \tfrac{2197}{4101}\vec{k}_4 - \tfrac{1}{5} \vec{k}_5\right)$$
or to fifth order by
\begin{align*}
	\vec{y}^{(5)}(t_{n+1}) &= \vec{y}(t_n) + \left(\tfrac{16}{135}\vec{k}_1 + \tfrac{6656}{12825}\vec{k}_3 + \tfrac{28561}{56430}\vec{k}_4 - \tfrac{9}{50} \vec{k}_5 + \tfrac{2}{55} \vec{k}_6\right) 
\end{align*}
Here is where my question is. In computing the new step size, $\delta t \to s \delta t$, and the formula generalizes to 
$$s = \left(\frac{\epsilon\,\delta t_{old}}{2\left|\vec{y}^{(5)}(t_{n+1}) - \vec{y}^{(4)}(t_{n+1})\right|}\right)^{1/4}$$
I assume then that I can just treat the magnitude as the vector norm, but I am not certain this is correct. I have written a code which works (produces reasonable results with a fixed step size) but the adaptive step size seems to always want to rapidly decrease to zero, even if my error tolerance is relatively large, say $10^{-4}$. I'm not sure if this is a bug in my code or if I am misunderstanding how to apply the adaptive step size algorithm. Any help appreciated.","['numerical-methods', 'ordinary-differential-equations', 'runge-kutta-methods']"
2701415,$T\in B(H)$. Why is $\forall x\in H$ $Tx=x \iff T^*x=x$?,"Let $H$ be a Hilbert space, $T:H\to H$ linear and bounded, $\|T\|\le 1$. Prove that: $\forall x\in H$ $Tx=x \iff T^*x=x$. I tried it but there must be a mistake, because I haven't used $\|T\|\le 1$. For all $\forall x\in H$: $\langle Tx-x,x\rangle =\langle x,T^*x\rangle- \langle x,x\rangle =\langle x, T^*x-x\rangle$. I want to conclude from here that $Tx=x \iff T^*x=x$, but this seems to be wrong because I don't use $\|T\|\le 1$, right? Alternatively, my guess is to do this with Cauchy-Schwarz somehow and then I have to use  $\|T\|\le 1$, but how exactly?","['functional-analysis', 'hilbert-spaces']"
2701500,$n$ consecutive composites that have exactly two prime factors,"user477343 found an example of three consecutive composites $1041,1042,1043$ with exactly two prime factors. It came as a surprise that they also found four consecutive composites $445=5 \cdot 89,446=2 \cdot 223,447=3\cdot 149,448=2^6 \cdot 7$ with exactly two prime factors. Can one find $n$ consecutive composites with exactly two prime factors for some other values of $n \in \mathbb N \setminus \{1\}$? Do they exist for every $n \in \mathbb N \setminus \{1\}$?","['number-theory', 'prime-numbers']"
2701503,Gradient of a function with respect to a matrix,"How can I compute the gradient of the following function with respect to $X$, $$g(X) = \frac{1}{2}\|y-AX\|^2$$ where $X\in\mathbb{R}^{n\times n}$, $y\in\mathbb{R}^m$, and $A:\mathbb{R}^{n\times n}\to \mathbb{R}^m$ is linear. We can assume that $A$ is of the form, $$A = \begin{pmatrix}\langle X| A_1\rangle\\\vdots\\\langle X|A_m\rangle\end{pmatrix}$$ where $A_1,\ldots,A_m$ are $n\times n$ real matrices and the inner product is the Frobenius inner product. Edit: my attempt at finding the gradient, $$g(X+H) = \frac{1}{2}\langle y-A(X+H), y-A(X+H)\rangle,\\
= \frac{1}{2} \langle y-AX-AH, y-AX-AH\rangle,\\
=\frac{1}{2} \left(\langle y-AX, y-AX\rangle -\langle y-AX,AH\rangle -\langle AH, y-AX\rangle +o(\|H\|)\right),\\
=g(X) - \langle y-AX, AH\rangle,\\
=g(X)-\langle A^*\left(y-AX\right),H\rangle,\\
\implies \nabla g(X) = -A^*\left(y-AX\right)$$ Now I must compute the adjoint operator $A^*$ of $A$. To find $A^*$ we do the following, $$\langle y, AX\rangle = \sum\limits_{i=1}^m y_i\langle X, A_i\rangle=\sum\limits_{i=1}^m \langle X, y_iA_i\rangle = \langle X, \sum\limits_{i=1}^my_iA_i\rangle$$ to see that $A^*y = \sum\limits_{i=1}^m y_iA_i$. Applying this to the expression we found above gives, $$\nabla_Xg(X) = -A^*(y-AX) = -\sum\limits_{i=1}^m\left(y_i-\mbox{tr}(X^TA_i)\right)A_i.$$","['matrices', 'normed-spaces', 'scalar-fields', 'matrix-calculus']"
2701566,Manifold of SU(3) group,"I understand that matrix elements of SU(2) can be arranged on the 3-sphere, thanks to the relations among the matrix coefficients.
If I repeat the same reasoning for SU(3) which kind of manifold do I obtain? I tried to do myself but got lost.
Excuse me for the sloppiness but I am a physicist not expert in group theory or differential geometry.","['manifolds', 'group-theory']"
2701591,How can one quantify the convergence of relative frequency to probability?,"I have a rather basic question about statistics but I am unable to find an answer in the literature I have at hand. Say I run a simple Bernoulli trial a number of times and compute the relative frequency for success. Clearly the relative frequency should represent the underlying probability for success better the more experiments I run. My question is this: Is there any way to say how close the two values are given the number of times the experiment was run? For example if I run the experiment $N$ times, what is the expected deviation of the relative frequency and the probability? Or turning the question around: If I want to know the probability up to an uncertainty of $\varepsilon$, how many experiments do I have to run? Any pointers to results in this direction would be appreciated.","['statistical-inference', 'probability-theory', 'statistics', 'confidence-interval', 'descriptive-statistics']"
2701622,Normal subgroups with an additional property,"Consider a normal subgroup $H\lhd G$, and let $g\in G$ be some element. In some cases, there exists a constant $k\in\mathbb Z$, s.t. $hg=gh^k$ for every $h\in H$. This $k$ can be different for different elements $g$, so denote it by $k_g$. I'm interested in normal subgroups with the property that every element $g$ has such $k_g$. For example: In the center of every group $Z(G)\lhd G$, $hg=gh$ for all $h\in Z(G),g \in G$, hence $k_g=1$ for all $g\in G$. Consider the dihedral group $D_n=\langle\sigma,\tau|\sigma^n=\tau^2=\tau\sigma\tau\sigma=1\rangle$ with its cyclic normal subgroup $\langle\sigma\rangle\lhd D_n$. It holds $\sigma^i\tau=\tau \sigma^{-i}$, hence $k_g=-1$ for all $g\in\tau\langle\sigma\rangle$ and $k_g=1$ for $g\in\langle\sigma\rangle$. Is there some characterization of groups where this property holds?","['abstract-algebra', 'normal-subgroups', 'group-theory']"
2701633,"Distribution of $ZX+(1-Z)Y$ where $X,Y\sim\mathcal N(0,1)$ and $Z\sim\mathcal U(0,1)$ are independent","Let $X$ and $Y$ be independent $\mathcal N(0,1)$ random variables. Let $Z\sim\mathcal U(0,1)$ be independent of $X$ and $Y$. What is the distribution of $U=ZX+(1-Z)Y$? Clearly, $[U\mid Z=z]=zX+(1-z)Y\sim\mathcal N(0,z^2+(1-z)^2)$, using the reproductive property of Normal distribution. So by the total probability theorem, density of $U$ is given by $$f_U(u)=\int_0^1 f_{U\mid Z=z}(u|z)\cdot1\,\mathrm{d}z$$ $$=\int_0^1\frac{1}{\sqrt{z^2+(1-z)^2}}\phi\left(\frac{u}{\sqrt{z^2+(1-z)^2}}\right)\,\mathrm{d}z$$ [where $\phi$ is the pdf of $\mathcal N(0,1)$ distribution]. But seeing that $U$ has a mixed distribution, it may not have a density in which case the above integral would not make sense. In any case, I don't think this integral can be evaluated. So I should look for the CDF of $U$. $\displaystyle F_U(u)=\Pr(U\leqslant u)=\int_0^1\Pr(zX+(1-z)Y\leqslant u\mid Z=z)\cdot1\,\mathrm{d}z$ $\displaystyle\qquad\qquad\qquad\qquad\quad=\int_0^1\Pr(zX+(1-z)Y\leqslant u)\,\mathrm{d}z$ $\displaystyle\qquad\qquad\qquad\qquad\quad=\int_0^1\Phi\left(\frac{u}{\sqrt{z^2+(1-z)^2}}\right)\,\mathrm{d}z\,,\qquad u\in\mathbb R$ [$\Phi$ denoting the CDF of standard normal distribution]. But is that all I can say? What should be my final answer to the distribution of $U$?","['normal-distribution', 'probability-theory', 'probability-distributions', 'uniform-distribution', 'random-variables']"
2701650,Orthogonality and norm of Hermite polynomials,"I wish to prove that the Hermite polynomials defined as $$H_n(x) := (-1)^n e^{x^2} D^n(e^{-x^2})$$ are orthogonal  wrt the inner product $$\langle f,g\rangle = \int_{\mathbb{R}} e^{-x^2} {f(x)}\overline{g(x)} dx $$ and that $||H_n||^2=n!2^n\sqrt{\pi}$. Not much else to do than compute $\langle H_m, H_n \rangle$. The integral becomes $$(-1)^{n+m} \int_{\mathbb{R}} e^{x^2}D^m(e^{-x^2})D^{n}(e
^{-x^2}) dx $$
Let's look at the derivatives of $e^{-x^2}$:
$$ \begin{array}{|} \hline n &&D^n(e^{-x^2}) \\ \hline 1 &&-2xe^{-x^2} \\ \hline2 &&-2e^{-x^2}+4x^2e^{-x^2} \\\hline3 &&4xe^{-x^2}+8xe^{-x^2}-8x^3e^{-x^2}\\ \vdots && \vdots\end{array}$$
It is obvious $D^{n}(e^{-x^2}) = P_n(x)e^{-x^2}$ for a polynomial $P_n$ of degree $n$ where the leading coefficient in $P_n$ is $(-1)^n2^n$. It should also be apparant that $P_n$ only contains terms $\{c_kx^k |k \equiv n \mod 2, 0\leq k\leq n, c_k\neq 0\}$. However, I am struggling to find the rest of the coefficients of $P_n$ under closed form. So, I am looking for a way to compute this integral without having to find the coeffiecients. Alas, I still haven't found what I am looking for. Any ideas?","['real-analysis', 'hermite-polynomials', 'orthogonal-polynomials']"
2701665,Naturals representable as differences of powers,With paper-and-pencil method I found only a first $5$ cases: $$1=3^2-2^3$$ $$2=3^3-5^2$$ $$3=2^7-5^3$$ $$4=5^3-11^2$$ $$5=2^5-3^3$$ This looks interesting and if a natural $n$ can be represented as difference of two powers (we do not take here $a^1$ into consideration but only exponents $\geq 2$ and we do not take into consideration powers $1^m$) we can call $n$ a power-representable natural number. It is very reasonable to expect that some numbers can be represented in more than one way but I would like to know here is it known to be true and is it true a following statement: Every natural number is power-representable .,"['number-theory', 'perfect-powers', 'prime-numbers']"
2701675,"Math History: Who was the first to use the word ""map"" in its modern meaning in Mathematics?","So far the first explicit mention of the word map to describe sets or in connection with functions i found was in the Paper ""Homotopy Relations in Fibre Spaces"" by W. Hurewicz and N. E. Steenrod from 1941.
But so far i could not find a comprehensive etymological analysis of the word map or mapping in mathematics. 
My suspicion so far is that it emerged through the course of the four colour theorem since there was at first a ""real map"" wich was solved using sets.
Any help on this topic would be widely appreciated.","['general-topology', 'math-history', 'functions']"
2701683,Algebraic Fractions,"Hi I am struggling with solving this, I am 12 years old and am trying to work my way through extended maths IGCSE, but have been stumped by this for a few days: $\dfrac{13x + 2}{(2x + 1)(x - 1)} =\dfrac{A}{2x + 1} + \dfrac{B}{x - 1}$, what are the value of A and B? I have the answer, A = 3 and B = 5",['algebra-precalculus']
2701735,On proving that $f(x) = f'(x)\iff f(x) = e^x$. (Not aware of a possible duplicate.) [duplicate],"This question already has answers here : Are the any non-trivial functions where $f(x)=f'(x)$ not of the form $Ae^x$ (6 answers) Closed 6 years ago . This is just a curious question, but is the following true? $$f(x) = f'(x)\iff f(x) = e^x.$$ I can prove that $\dfrac{\mathrm d}{\mathrm dx}\left(e^x\right) = e^x$ from using the the formula, $e^x := \operatorname*{\lim}\limits_{n\to 0}(1+n)^{1/n}.$ For those who are not familiar with the proof, it can be found here . Or, you can go here for a similar approach. However, my question is asking whether or not $f(x) = e^x$ is the only function equal to its own deriv. I suspect it is true, but how can we prove that $e^x$ is the only value equal to its derivative, for any $x$? I consider it very likely that there exists another question out there, perhaps exactly like this. If so, please comment the link below, and I will go straight to it, delete this post, and give you a muffin. I do not intend on trolling or wasting anyone's time. Thank you in advance.","['derivatives', 'exponential-function', 'calculus', 'proof-writing', 'ordinary-differential-equations']"
2701757,The probability of rolling $N$ 10-sided dice and forming groups that add at least 10,"I'm trying to answer this question for an RPG game. The player (or the GM) has to roll $N$ 10-sided dice and then she has to form groups that sum at least 10 (I'll call them Raises, using the game term). As an example, if I roll 3d10 and get 10, 7 and 3, I get two Raises: {10}, {7,3}. If I roll 3d10 and get 2, 9 and 9, I get only one Raise: {2,9}. I'm interested in computing the probability of getting $R$ Raises by rolling $N$ d10, either in a closed form or recursively (I'm thinking of putting this in a script to compute the expected value for some fixed values of $N$). I'm trying to use this entry on Wolfram MathWorld to solve the problem, but I'm still stuck. Any help will be appreciated. This is by no means an assignment or a homework or a life-saving problem. I'm doing it just out of curiosity. Thank you very much in advance! Edit: to clarify, the player should choose the largest number of Raises. For example, if I roll four dice and get 4, 5, 6, 10, although {4, 5, 6, 10} is one Raise, {4, 6} and {10} (or {5, 6} and {10}) are two Raises. In this case the player should choose the second alternative.","['probability', 'dice']"
2701764,"Distribution of $\sum_{i=1}^n \max\{(r-X_i),0\}$, with $X_i$ continuous positive iid","Let $X^{(r)} = \sum_{i=1}^n\max\{(r-X_i),0\}$ with $X_i$ a sequence of i.i.d., positive, continuous random variables with CDF $F$ and PDF $f$ .
We want to understand the distribution $X^{(r)}$ . Suppose first that $n=1$ thus $X^{(r)} = \max\{(r-X),0\}$ , then we find: $$
f_{X^{(r)}}(x)
=
\begin{cases}
0 & \mbox{ if } x < 0\\
f(r-x) & \mbox{ if } 0 \leq x \leq r\\
0 & \mbox{ if } r < x,
\end{cases}
$$ while $\mathbb{P}\{X^{(r)}=0\} = 1-F(r)$ . Now I wonder if we can generalize this to $n > 1$ in particular $n=2$ .","['real-analysis', 'density-function', 'probability-theory', 'calculus', 'integration']"
2701892,How does 11 split in the ring $\mathbb{Z}[\sqrt[3]{2}]$,"I learned that the splitting of primes in a number field $K = \mathbb{Q}(x)/p(x)$ depends on the factorization of $p(x) \pmod p$.  While this is not at all obvious to me, let's use it: $$x^3 - 2 \equiv (x-7)(x^2 + 7x + 6) \pmod {11}$$ and I do not think that second factor splits.  What does this say about the factorization of $p = 11 \in \mathbb{Z}[\sqrt[3]{2}]$ ? My best guess is that $p = 11$ splits as a linear and a quadratic.  For some integers: $a,b,c,d,e \in \mathbb{Z}$ we have: \begin{eqnarray*} 11 &=& (a + b\sqrt[3]{2}) (c + d \sqrt[3]{2}+ e\sqrt[3]{4}) \\ 
&=& (ac + 2be) + (bc + ad)\sqrt[3]{2} + (bd+ae)\sqrt[3]{4}\end{eqnarray*} Most by tautology, we get 3 equations in 5 unknown integers and we can try to solve it: \begin{eqnarray*}
ac + 2be &=& 11 \\
bc + \,\,ad &=& 0 \\
bd + \,\,ae &=& 0
\end{eqnarray*} This is looking pretty bad, however I noticed the three determinants.  And maybe that could be useful.","['abstract-algebra', 'intersection-theory', 'polynomials', 'algebraic-number-theory']"
2701914,(Connected) non-contractible schemes,"This question is motivated by this other question and this answer, which show that irreducible algebraic varieties and more generally integral schemes are contractible as topological spaces. What are examples of connected non-contractible schemes? I expect some gluing involved in the answer. But could such a scheme also be affine?","['algebraic-geometry', 'schemes', 'affine-schemes', 'algebraic-topology', 'general-topology']"
2701916,Some set notation clarification,"So for the product properties of sets, I can show that : $(A \times B )^c=(X \times B^c)\cup (A^c\times Y)$, where $A\subset X$ and $B\subset Y,$ but I have a problem showing that $(A \times B )'=(\overline{A} \times B')\cup (A'\times \overline{B}),$ where the overline denotes the closure of the set, also note that $A'$ denotes the limit points of the set $A.$ Could anyone help me explain why the second equality holds? I have alot of topology question at the moment as my midterms are coming up, help would be much appreciated.","['general-topology', 'elementary-set-theory']"
2701928,Sharpe Ratio with two assets,"You have $1 million to invest. You can only invest in two stocks, A and B, with the following annualized expected returns and volatilities (i.e. standard deviation of return): Stock Expected Return Volatility
A     10 %     10 %
B     15 %     20 % Assume that interest rates are zero, and that the stocks’ returns are independent. Find the fully invested portfolios that maximize the Sharpe ratio, which is defined as the ratio between expected return and volatility.
What is the maximum Sharpe ratio you can achieve by combining investments in A and B in this way? Attempt: I believe the expected returns are $E[R] = (1-w)*.10 + w*.15 = .10 + .05w$ However, the I am not sure how to set up the volatility. I would appreciate a thorough solution and explanation of this problem.","['statistics', 'finance']"
2701989,"Bounded vs. unbounded, closed vs. open sets","I am looking for some examples / definitions of these concepts so I can better understand other ones. Namely, I am looking for all four permutations: Unbounded and closed Unbounded and open Bound and closed. Bound and open. Apparently this is also related to the concept of ""compactness"" but ""every open cover of the space has a finite subcover"" doesn't mean anything to me. Seeing some examples and understanding how these are defined would be helpful (I am trying to eventually understand the intuition behind the proof of Extreme Value Theorem but I need to understand these concepts first).","['definition', 'calculus', 'analysis']"
2702019,Prove monotonicity of a function by a given relationship and integration,"I have a differentiable function $f:\mathbb{R}\to \mathbb{R}$ for which is true that
$$f''(x)=f'(x)\cdot f(x)\text{ }\forall x\in\mathbb{R}$$
and $\exists x_0\in\mathbb{R}$ for which is true that $$f(x_0)=f'(x_0)=k, \quad k\in(0,2).$$ I want to prove that $f$ is strictly increasing. So I do the following:
$$
\begin{split}
f''(x)&=f'(x)\cdot f(x)\\
f''(x)+f'(x)&=f'(x)\cdot f(x)+f'(x)\\
(f(x)+f'(x))'&=\left[\frac{1}{2}(f(x)+1)^2\right]'\\
f(x)+f'(x)&=\frac{1}{2}\left(f(x)+1\right)^2+c \quad \forall x\in\mathbb{R}
\end{split}
$$
I prove that $c=-(k-1)^2$ but now I don't know how to continue. Any ideas?","['integration', 'monotone-functions', 'functions']"
2702041,Intuition for spheres in high dimension,"In particular, I'm interested in the property that the surface area of a sphere in D dimensions gets concentrated near the equator. I know it can be shown with some integrals, for example done in Section 1.2.5 here . What I want to know, if anyone can give me a short relatively verbal argument for this. It's a point that I need to make in a talk that I'm giving, and I'd like to give some intuition for why this result is true, but going into an integral or something would detract away too much from my main content. A little math is fine (It's going to be an applied math/physics audience), but something which wont take up too much time to explain if possible. Thanks.","['intuition', 'spheres', 'geometry']"
2702060,In what sense is the length of a parameterized curve an area?,A little confusion on my part. Study of multi variable calculus and we are using the formula for length of a parameterized curve. The equation makes intuitive sense and I can work it OK. But I also recall using the same integral with out the parameterizing to find the length of a curve where the first term of the square root in just one. The former formula is the general case. Now for the question:  I had just previously used the integral for completing the quadrature i.e.  Find the area under a curve.   Is the single integral used for finding both area and length ?  I guess I am trying to unify the concepts in my mind to understand the context of how they are used and know the difference. Thank you.,"['multivariable-calculus', 'integration']"
2702071,How to solve this definite integration problem?,"I can't seem to solve this integration problem, despite many attempts. The question goes like this: $$\int_{0}^{1}\frac{\tan^{-1}\left(\frac{x}{x+1}\right)\,{\rm d}x}{\tan^{-1}\left(\frac{1+2x-2x^2}{2}\right)}  
$$
I have tried using the rule of replacing $x$ by $1-x$ in the hopes, the numerator and denominator might cancel, but no! Then I also tried adding multiple integrals obtained on the way of simplification, but I could not reach to a result. Please help me figure this out. Thank You :)","['definite-integrals', 'trigonometry']"
2702084,Non-vanishing Jacobian determinant is bounded below?,"Let $F:\mathbb{R}^n \to \mathbb{R}^m$ ($m < n$) be a Lipschitz function whose Jacobian determinant $J F$ does not vanish on a compact set $A \subseteq  \mathbb{R^n}$. Assume $J F$ exists everywhere. Does this imply $J F(x)$ is bounded away from zero for all $x \in A$? I know this would follow from $x \mapsto J F (x)$ being a continuous map or even a closed map, but I don't see why either of those should be true. The Jacobian determinant of $F$ is defined as $$J F(x) = \sqrt{ \text{det}( DF(x) DF(x)^T )  },$$ 
where $D F$ is the $m \times n$ matrix of partial derivatives  of $F$.","['multivariable-calculus', 'real-analysis', 'jacobian']"
2702119,$\mathcal{C}^{\alpha}$ Besov spaces: Definition,"I'm reading an article for my future thesis (I'm a third-year undergraduate) where the authors define the generalized Holder Spaces as a special class of Besov Spaces. Define $\chi,\tilde{\chi}\in C_{c}^{\infty}(\mathbb{R}^d)$ such that Supp$(\chi)\subset B(0,8/3) \setminus B(0,3/4)$ and Supp$(\tilde{\chi}) \subset B(0,4/3),$ and such that $\tilde{\chi}(x)+\sum^{+ \infty}_{k=0} \chi(x/2^k)=1 \quad \forall x\in \mathbb{R}^d$. Define $\chi_{-1}:=\tilde{\chi},$ and $\chi_k(\cdot):=\chi(\cdot/2^k).$
Now, $\forall f \in C^{\infty}(\mathbb{T}^d),$ set $\delta_k(f):=\mathscr{F}^{-1}(\hat{f} \cdot \chi_k$), where $\hat{f}(k):=\int_{\mathbb{T}^d}f(x)e^{-2\pi i k\cdot x} dx$ and $\mathscr{F}^{-1}(g)(x):=\sum_{k\in \mathbb{z}^d} g(k)e^{2 \pi i k\cdot x}.$
Heuristically, $\delta_k(f)$ is just a part of the frequencies of the smooth function $f.$ Now, for every $\alpha \in \mathbb{R},$ we can define the $\mathcal{C}^{\alpha}$ norm of a smooth function, which is $\|f\|_{\mathcal{C}^{\alpha}}:=sup_{k\geq1} 2^{\alpha k} \|\delta_k(f)\|_{L^{\infty}}.$ The space $\mathcal{C}^{\alpha}$ is defined as the completion of $C^{\infty}(\mathbb{T}^d)$ with respect to this norm. The definition given is a bit different from the one which is mostly given in literature: the space of all tempered distributions such that the above-mentioned norm (which is well-defined because the Fourier antitransform of a compactly-supported distribution is a function) is finite. Now, me questions are: Why the $\mathcal{C}^{\alpha}$ norm is finite for every smooth function defined on the torus? Why does it coincide (well, I don't think they precisely coincide, but they should be equivalent or at least generate the same completion) with the classical $\alpha-$Holder norm ($\|f\|_{\mathcal{C}^{\alpha}}=sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|^{\alpha}})$? Do the $\mathcal{C}^{\alpha}$ spaces respectively defined via completion of $C^{\infty}$ and via the tempered distributions coincide? The article can be found here .","['functional-analysis', 'real-analysis', 'besov-space']"
2702135,Are the iterates of the cosine linearly independent?,"Consider the cosine function $f = \cos : \Bbb R \to \Bbb R$. Is it true that the set of iterates
$$\left\{f_n := \cos \circ \dotsb \circ \cos,  \; n \text{  times }   \mid  n \geq 1\right\}$$
is linearly independent over $\Bbb R$ ?
That is, I am wondering if,  for any $r \geq 1$ and any real numbers $a_k$, we have :
$$\sum_{k=1}^r a_k f_k = 0 : \Bbb R \to \Bbb R \implies a_k=0 \;\forall k.$$ I know that this true if we consider the powers of $\cos( \cdot )$, but I don't know how to deal with compositions.
What I tried is to take derivative, or induction on the minimal length of linear dependence relation.","['real-analysis', 'linear-algebra']"
2702228,$\det(A_1\cdot B_1 +A_2\cdot B_2)=0$,"Let $A_1, A_2\in M_n(\mathbb{R})$  two symmetric matrices s.t. $det(A_1^2+A_2^2)=0$. Show that $det(A_1\cdot B_1 +A_2\cdot B_2)=0$ for every $B_1, B_2\in M_n(\mathbb{R})$. My idea: I consider the matrix C :\begin{bmatrix}
    A_1 & A_2 \\
    B_1^t & B_2^t 
\end{bmatrix} $det(C\cdot C^t)\geq 0\Rightarrow det(\begin{bmatrix}
    A_1^2 +A_2^2 & D \\
    D^t & E\\
\end{bmatrix})\geq 0 
$ where $D=A_1B_1+A_2B_2$. I tried to expand the determinant with Laplace Rule. I am not sure if $ det(\begin{bmatrix}
    A_1^2 +A_2^2 & D \\
    D^t & E\\
\end{bmatrix}) = -det(D\cdot D^t)$. In this way I would  get $det(D)=0$.","['matrices', 'linear-algebra', 'determinant']"
2702250,Showing that the Differential Operator is continuous in a topological vector space,"Earlier this day, I asked a question , on how to prove continuity of scalar multiplication and addition in a specific topological vector space. To repeat it here, I was talking about this space: Let $\mathcal{D}_K$ be the space of all on $K\subseteq \mathbb{R}$
  compactly supported, infinitely differentiable functions. I have shown for $N \in \mathbb{N}$, $\epsilon > 0$ and
  $U_{N,\epsilon} := \{f \in \mathcal{D}_K: \max_{0\leq i \leq N}
> ||f^{(i)}||_\infty < \epsilon\}$, that the sets $f + U_{N,\epsilon}$
  with $f\in \mathcal{D}_K$ form a basis of a topology on our space. I do now indeed understand how to prove that this space is a topological vector space. However, I also want to show that the differentiation operator $D_i: \mathcal{D}_K \rightarrow \mathcal{D}_K , f \mapsto f^{(i)}$ is continuous under this topology. As far as I have understood, this topology is induced by the norms $$||g||_N := \max_{i \leq N} ||g^{(i)}|| $$
so essentially my open sets are just unions of balls $B_N(g,\epsilon)$, with some norm $||\cdot||_N$ I now tried to use this to prove the continuity of $D_i$, by showing that its preimage of such an open ball $$D_i^{-1}(B_N(f,\epsilon)) = \{g \in \mathcal{D}_K : \max_{k\leq N} ||g^{(i+k)}-f^{(k)}||_\infty  < \epsilon \} $$
is contained in a union of other open balls containing $f$. This is where I get stuck. I always end up with derivatives of different order on each of my functions, so I do not know how I can find such a union. Any help would be greatly appreciated!","['functional-analysis', 'topological-vector-spaces']"
2702267,What is the probability that $n$ integers chosen at random are coprime?,"It is extremely well-known that the probability of any two random integers being relatively prime is $\zeta(2)^{-1}$ ( see here ). From An Introduction to Analytic Number Theory by Apostol, the proof involves counting lattice points and finding the limit $$\lim_{r\to\infty}\frac{N'(r)}{N(r)}$$ where $N(r)$ is the number of lattice points in the square governed by $|x|\le r$ and $|y|\le r$, and $N'(r)$ is the number of lattice points visible from the origin. For some background, the term ""visible"" is defined as follows: Two lattice points $P$ and $Q$ are said to be visible if the line joining the two does not go through any other lattice points. Now what if $n\neq2$; that is, What is the limit of the probability that $n$ integers chosen at random in the interval $[1,N]$ are coprime as $N\to\infty$ with $n>2$ ? Let's consider the simplest case: $n=3$. We imitate the proof for when $n=2$. Firstly, an extension to Thm 3.8 can be easily proven. Theorem: Two lattice points $(a_1,\cdots,a_n)$ and $(b_1,\cdots,b_n)$ are visible iff $a_1-b_1$, $a_2-b_2$ up to $a_n-b_n$ are relatively prime. The $24$ lattice points nearest the origin are all visible from the origin - there are $24$ points ""surrounding"" the origin of unit distance. By symmetry, we see that $N'(r)$ is equal to $24$, plus $24$ times the number of visible points in the region $$\{(x,y,z):2\le x\le r, ???\}$$ We cannot use $1\le y\le x$ since the gradient of the line joining the origin and $(r,r,r)$ is no longer $1$. Of course, we can try to use this , but I feel that this makes it more complicated than it should be. So how should I continue? Is there an alternative method? And what would be the general approach for large $n$, ie. is there an expression (in terms of $n$) that finds the probability that $n$ integers chosen at random are coprime?","['analytic-number-theory', 'probability']"
2702334,To compute the sum using 2011 th roots of unity,"Question: Let $x$ be a complex number such that $x^{2011}=1$ and $x\neq1$ then, compute the sum $$S=\dfrac{x^2}{x-1}+\dfrac{x^4}{x^2-1}+\dfrac{x^6}{x^3-1}+\dots+\dfrac{x^{4020}}{x^{2010}-1}$$ My attempt: $$x=(1)^{\frac{1}{2011}}\implies x=1,e^{\frac{2\pi i}{2011}},e^{\frac{4\pi i}{2011}},\dots,e^{\frac{2010\pi i}{2011}}$$ let, $\alpha= e^{\frac{2\pi i}{2011}},$ then roots of given equation are $x=\alpha,\alpha^2,\alpha^3,\dots,\alpha^{2010}$ also $$\alpha^{2010}=\dfrac{1}{\alpha};\ \alpha^{2009}=\dfrac{1}{\alpha^2};\ \dots;   
 \ \alpha^{1006}=\dfrac{1}{\alpha^{1005}}$$ now, we have to compute: $$S= \dfrac{\alpha^2}{\alpha-1}+\dfrac{\alpha^4}{\alpha^2-1}+\dfrac{\alpha^6}{\alpha^3-1}+\dots+\dfrac{\alpha^{4020}}{\alpha^{2010}-1}$$ then, I combined first term and last term, similarly second term and second last term and so on in this way i ended up here $$S=\dfrac{\alpha^{2}-\alpha^{-3}}{\alpha-1}+\dfrac{\alpha^{4}-\alpha^{-6}}{\alpha^2-1}+.........+\dfrac{\alpha^{2010}-\alpha^{-1006}}{\alpha^{1005}-1}$$ here i got stuck , somehow i just wanted to exploit the property that sum of all roots of unity (who itself are in G.P) is zero but I couldn't please give me hint or provide right way to solve this question. thank you! edit: I also tried taking logarithmic derivative of $f(x)=x^{2011}-1$ but no progress further","['algebra-precalculus', 'contest-math', 'sequences-and-series', 'complex-numbers']"
2702348,Solving following System of ordinary differential equations.,"How to solve system of ODEs which contains independent variable like t in equation as in this particular case : 
$$\frac{dx}{dt}= -x + ty $$ $$ \frac{dy}{dt} = tx-y$$ can we solve them or additional information may be needed (may be about t) ?",['ordinary-differential-equations']
2702365,Inequalitiy of Kounias,"I have the following exercise to do:
For the events $A_i \in \mathfrak{C}, i \in \mathbb{N}$ of a probability space $(\Omega,\mathfrak{C},\textbf{P})$ prove the Inequality of Kounias $$\textbf{P}(\bigcup_{i=1}^{n}A_i)\leq min_{k\in{\{1,...,n\}}}\{\sum_{i=1}^n\textbf{P}(A_i)-\sum_{i:i\neq k}\textbf{P}(A_i\cap A_k)\}$$ I tried to use the properties of the probability measure $\textbf{P}$ and the $\sigma$-Algebra $\mathfrak{C}$ but I'm stuck because I don't know anything about the events $A_i$.","['probability', 'measure-theory']"
2702372,Recovering a matrix after multiplication by its transpose,"Let $A$ be a $p \times k$ matrix (with $p > k$) that has full column rank, i.e., $\mbox{rank}(A) = k$. Suppose we have $$B = A A^t$$ $A$ and $B$ have the same degree of freedom. How can the original values of $A$ be calculated from $B$?","['matrices', 'transpose', 'matrix-equations', 'matrix-decomposition']"
2702400,How can I formalize the following sentence into first-order logic?,"Every by $10$ divisible number is ending by the digit $0$. My solution: let be $N(x)$ a natural number, which is divisible by $10$, let be $L(x)$ the last digit of a number $( \forall x)( N(x) \implies L(x)) $ and the negation of it is: $ (\exists x)( \neg N(x) \implies \neg L(x)).$","['predicate-logic', 'logic', 'first-order-logic', 'discrete-mathematics']"
2702414,Isometry between cone and plane,"Question: Exercise 1, Section 4.2, Do Carmo Differential Geometry of Curves and Surfaces: Let F be a parametrization $F: U\in \mathbb{R}^2\rightarrow \mathbb{R}^3$, $F(u,v)=$(u sin$\alpha$ cos$v$, u sin$\alpha$ sin$v$, u cos$\alpha$), $(u,v)\in U= \{(u,v)\in \mathbb{R}^2; u>0\}$, $\alpha=$const. Is F a local isometry? My attempt/ problem: I believe the answer should be yes (since plane and cone are indeed locally isometric, and being isometric should not be dependent on parametrization.) To show that two surfaces are isometric, we need to show they have the same first fundamental forms. I do not know how to parametrize plane to get the same E, F, G as what we get for the above parametrization of cone, which is E= 1, F=0, G= $u^2sin^2\alpha$.","['isometry', 'differential-geometry']"
2702435,Lower bound of the injectivity radius,"Suppose $F:M^n \rightarrow \mathbb{R}^m$ is an isometric immersion with bounded second fundamental form. This means the following: There exists a constant $C>0$ such that for any $p \in M^n$ and for any orthonormal basis $e_1,\ldots,e_n$ of $T_pM$ we have
$$ |h(e_i,e_j)| \leq C$$
where $h$ is the second fundamental form defined by
$$ h(X,Y) = \text{normal part of } D_{dF(X)} dF(Y) $$
for vector fields $X$ and $Y$ on $M$ and where $D$ is the regular derivative on $\mathbb{R}^m$. Does there exist a lower bound for the injectivity radius on $M$ (note we do not assume $M$ to be compact)? The injectivity radius is defined as the lowest radius for which the exponential map is a diffeomorphism.","['riemannian-geometry', 'differential-geometry']"
2702439,Equivalent form of Central Limit Theorem,"Commonly we use Central Limit Theorem in the following form. Theorem: Let $\{X_i\}_{i=1}^\infty$ be a sequence of i.i.d. random variables such that $E(X_i)=\mu$, $\operatorname{Var}(X_i)=\sigma^2<\infty$. Then, $$\sqrt{n}\frac{\overline{X}_n-\mu}{\sigma}\stackrel{d}{\longrightarrow}\mathcal{N}(0,1), \tag{1}$$ where $\overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$. I need to show that expression $(1)$ can be replaced by expression $(2)$: $$\overline{X}_n - \mu \overset{d}{\longrightarrow}\mathcal{N}(0,\frac{\sigma^2}{n}). \tag{2}$$ I tried to use Slutsky theorem : Let $\{A_n\}$ and $\{B_n\}$ be sequences of random variables. If $A_n \overset{d}{\longrightarrow} A$ and $B_n \overset{P}{\longrightarrow} c$ then $A_n \cdot B_n \overset{d}{\longrightarrow} cA\,$ (and $A_n + B_n \overset{d}{\longrightarrow} A + c$). If we define $A_n = \sqrt{n}\frac{\overline{X}_n-\mu}{\sigma}, \, B_n = \sigma, \, \forall n$, then by Slutsky theorem we have $$A_n \cdot B_n = \sqrt{n} (\overline{X}_n-\mu) \overset{d}{\longrightarrow} \sigma \cdot \mathcal{N}(0,1) \equiv \mathcal{N}(0,\sigma^2). \tag{3}$$ Next, I wanted to show that $(3)$ implies $(2)$. I tried to use Slutsky theorem one more time for sequences $\widetilde{A_n} = \sqrt{n} (\overline{X}_n-\mu), \, \widetilde{B}_n = \frac{1}{\sqrt{n}}$:
$$\widetilde{A}_n \cdot \widetilde{B}_n = \overline{X}_n-\mu \overset{d}{\longrightarrow} 0 \cdot \mathcal{N}(0, \sigma^2).$$ As you see, direct usage of the Slutsky theorem give zero as a result because $\widetilde{B}_n \overset{P}{\longrightarrow} 0$. So how to show correctly that expression $(3)$ implies $(2)$ (or, equivalently, $(1)$ implies $(2)$)? Maybe it is easier to proof this without using Slutsky theorem?","['probability-theory', 'probability', 'central-limit-theorem']"
2702520,Proving that a sphere is a closed set,"I have to prove that a sphere centered at $x_0$ with radius $r$ $S(x_0,r) = \{x \in X | d(x,x_0) = r\}$ is a closed set. I know I should prove that the complement is open. If I take a point $y$ inside the complement and consider the open ball with radius $\epsilon = \frac{d-r}{2}$ where $d$ is the distance from $x_0$ to $y$ I have to show that the distance $d(x_0,y) > r$. This is where I am stuck. I thought about using the triangle inequality, but I am sure how to proceed. Any help would be greatly appreicated.","['general-topology', 'real-analysis', 'elementary-set-theory']"
2702561,Calculating the points of minimum pressure on the surface of a cylinder,"I was wondering if anyone could help me with the following problem, as I'm unsure on how to begin.  The problem is the following. Two equal line sources of strength $k$ are located at $x=3a$ and $x=-3a$, near a circular cylinder of radius $a$ with axis normal to the $x$-$y$ plane and passing through the origin. The fluid is incompressible and the flow is irrotational and inviscid. I have used  the Milne-Thomson circle theorem to show that the complex potential for this flow is 
$$ w(z) = k\ln\left(a^{4}-9a^{2}z^{2}-9\frac{a^{6}}{z^{2}}+81a^{4}\right). $$ I also know that the speed of the flow at the surface of the cylinder is given by $\left|\frac{dw}{dz}\right|$. This was given in the previous part of the question that I am doing: 
$$ \left|\frac{dw}{dz}\right| = v = \frac{18k\sin(2\theta)}{a(41-9\cos(2\theta))} $$ 
However I do not know how to show this. Computing the derivative gives 
$$ \frac{dw}{dz}=\frac{2kz}{z^{2}-9a^{2}} - \frac{2kz^{2}a^{4}}{a^{4}z^{3}-9a^{2}z^{3}} $$ 
If anyone could show me how to simplify this expression to the required one i would be extremely grateful. My main problem is how to determine the positions of the points on the surface of the cylinder at which the pressure is minimum? Edit: The problem about computing the flow speed on the cylinder has been answered here: How can I show the following trigonometric function?","['derivatives', 'fluid-dynamics', 'mathematical-physics']"
2702605,Is the following arithmetic on conjugation of a set correct?,"I am given a set $H$ subset of a group $G$ closed under the binary operation and satisfying that if $g \in G$ then $g^2 \in H$. And I am to prove that $H$ is a normal subgroup of $G$ and that $G/H$ is Abelian. What I have done is: Take an an arbitrary $g \in G$. We were told that for all $g \in G$, $g^2 \in H$ so $(gHg^{-1})^2 \subseteq H$ However $(gHg^{-1})^2 = gHg^{-1}gHg^{-1} = gH^2g^{-1} = gHg^{-1}$ I am not sure if my argument above is correct because I am not sure if my approach is mathematically correct.","['abstract-algebra', 'proof-writing', 'group-theory', 'proof-verification']"
2702610,Double integral of maximum function.,"Let $D:= \lbrace (x,y) \in [0,\infty)^2: 1 \le x^2+y^2\le9 \rbrace$.
Determine the integral :
$$\int\int_D \max(3x^2,y^2)\;dx\,dy.$$
I have a little problem, because I'm not sure where the maximum is $3x^2$ or $y^2$.","['multivariable-calculus', 'integration', 'maxima-minima']"
2702640,What makes this integral so hard to solve?,"The integral $$ F(x) = \int \frac{x}{\sqrt{x^4+10x^2-96x-71}} \, dx ,$$ has a closed-form expression, namely, $$F(x) = -\frac{1}{8} \ln\left((x^6 + 15x^4-80x^3 + 27x^2-528x + 781)\sqrt{x^4 + 10x^2-96x - 71} - (x^8 + 20x^6 -128 x^5 + 54x^4-1408x^3 + 3124x^2 + 10001)\right) \\ +C. $$ It seems that most, if not all, computer integrators such as Mathematica fail to find its antiderivative. What makes this integral so hard to solve, and how do you begin solving it?","['indefinite-integrals', 'integration']"
2702642,Notation for subgroup of $\mathrm{GL}(n)$ consisting of matrices with determinant +1 or -1?,"$\mathrm{SL}(n)$ is the standard notation for the subgroup of matrices with determinant $1$, but what about the subgroup of all matrices with determinant $+1$ or $-1$? Is there a standard notation for this in the literature? I am considering using $\mathrm{SL}_{\pm}(n)$ to denote this group, but if there is already a standard notation in the literature I would prefer to use that instead.","['notation', 'group-theory', 'lie-groups']"
2702683,"Exercise ""Mathematical Statistics - Jun Shao""","I'm trying to solve this problem: Let $X_1, ...,X_n, (n \ge 2)$ be i.i.d. random variables having the
  normal distribution $N(\theta, 2)$ when $\theta=0$ and the normal
  distribution $N(\theta, 1)$ when $\theta \in {\rm I\!R}-\{0\}$. Show that the sample mean $\bar{X}$ is not a sufficient
  statistic for $\theta$. So, first I found the sample distributions, 
$\bar{X} \sim N(0,2/n)$, when $\theta = 0$, and $\bar{X} \sim N(\theta,1/n)$, when $\theta \neq 0$. Then I wrote the function as
\begin{align}
f_{ \theta  }(x)={ \left[ { (4\pi ) }^{ -1/2 }\exp\{ \frac { -{ x }^{ 2 } }{ 4 } \}  \right]  }^{ I_{ \{ \theta =0\}  } }{ \left[ { (2\pi ) }^{ -1/2 }\exp\{ \frac { -{ (x-\theta ) }^{ 2 } }{ 2 } \}  \right]  }^{ I_{ \{ \theta \neq 0\}  } }
\end{align} But I'm not sure how to procedure with that. I thought of using the factorization theorem, but I'm stuck in this density. Any hint?","['statistics', 'statistical-inference', 'probability-distributions']"
2702704,Intuition behind the critical difference of ANOVA,"I am studying Analysis of Variance. Suppose,  we have done ANOVA and found out that null hypothesis is rejected. This means there is a significant difference between at least one pair of the treatments. Now, we would like to know about those pairs. For that my book is calculating something called as Critical Difference between any two pairs: $CD.=t_{n-k}(\alpha/2).S_{E}^2\sqrt{2/n}$ Here, $n-k$ is the degree of freedom of the error. And $S_{E}^2$ is the sum of square due to error. I am not able to understand the intuition behind the above formula for critical difference.","['self-learning', 'statistics', 'variance']"
2702764,Direct ceiling proof,I'm stuck on this for quite of few hours now. Can someone please explain me how would I prove this? TIA $\lceil x + n \rceil = \lceil x \rceil + n $ (x is a real number and n is an integer),['discrete-mathematics']
2702775,Torsion in weird groups,"Let $\mathbf{C}$ be the complex numbers, and $\mathbf{Q}_p$ the $p$-adic rationals, embedded into $\mathbf{C}$ by some field embedding $s$. Is the abelian group $\Gamma := \mathbf{C}/s(\mathbf{Q}_p)$ a torsion abelian group? $s$ must restrict to the identity on $\mathbf{Q}\subset\mathbf{Q}_p$, so there is a surjective group homomorphism
$$\mathbf{C}/\mathbf{Q}=\mathbf{R}/\mathbf{Q}\oplus\mathbf{R}\to\Gamma.$$ Is it true that $s(\mathbf{Q}_p)$ is always not contained in the copy of $\mathbf{R}$ as a subfield of $\mathbf{C}$? If so, the intersection of $s(\mathbf{Q}_p)$ and the second copy of $\mathbf{R}$ in $\mathbf{C} = \mathbf{R}\oplus\mathbf{R}$ as an abelian group, must contain $\mathbf{Z}$, so the surjection factors through $\mathbf{C}/\mathbf{Q}\oplus\mathbf{R}/\mathbf{Z}$, and $\Gamma$ is torsion.","['algebraic-geometry', 'topological-groups', 'arithmetic-geometry', 'abelian-groups', 'group-theory']"
2702817,When every minimal subgroup is contained in the center,"Let $G$ be a finite group and $(*)$ be the property: $(*)$: Every minimal normal subgroup is contained in the center. $(a)$ Let $N$ and $M$ be normal subgroups of $G$, both of which satisfy $(*)$. Then prove:
  $NM$ satisfies $(*)$. $(b)$ If $G$ satisfies $(*)$, then prove: every normal subgroup of $G$ satisfies $(*)$. I would also agree that it may be a possible duplicate of this post . However, unfortunately, I could find that post a little complicated to understand and not well developed, of which the logic, notation, and language might not have been so polished . It would be greatly appreciated, if you could throw light on this question and be kind enough to give an  elegant proof . Thanks a lot! $\ddot\smile$","['finite-groups', 'abstract-algebra', 'proof-verification', 'proof-explanation', 'group-theory']"
2702846,"Proving existence of unique fixed point in C([a,b]) satisfying integral equation","The question is: Let $[a,b]$ be a closed interval in $\mathbb{R}$ and let $A$ and $K$ be continuous real-valued functions on $[a,b]$ and $\{(x,y) \in \mathbb{R}^2: a \leq y \leq x \leq b\}$ respectively. Prove that there is a unique $\phi \in C([a,b])$ such that
$$\phi(x) = A(x) + \int_{a}^{x} K(x,y) \phi(y)dy$$
for all $x \in [a,b]$. I did a problem prior to this of a similar nature, which was: Let $[a,b]$ be a closed interval in $\mathbb{R}$ and let $A$ and $K$ be continuous real-valued functions on $[a,b]$ and $\{(x,y) \in \mathbb{R}^2: x,y \in [a,b]\}$ respectively. Assume $|(b-a)K(x,y)|<1$ for all $x,y$. Prove that there is a unique $\phi \in C([a,b])$ such that
$$\phi(x) = A(x) + \int_{a}^{b} K(x,y) \phi(y)dy$$
for all $x \in [a,b]$. This can be done by showing $F: C([a,b]) \rightarrow C([a,b])$ defined by $F(\psi)(x) = A(x) + \int_{a}^{b} K(x,y) \psi(y)dy$ is a contraction map. However, without $|(b-a)K(x,y)|<1$, I'm unsure of how to proceed. The problem has the following hint: Imitate the procedure in the preceding problem if $|(b-a)K(x,y)|<1$ whenever $a \le y \le x \le b$. To do the general case, note that for any $a_1 \in (a,b)$, the problem reduces to proving the existence of a unique $\phi_1 \in C([a,a_1])$ such that 
$$\phi_1(x) = A(x) + \int_{a}^{x} K(x,y) \phi_1(y)dy$$
for all $x \in [a,a_1]$ and the existence of a unique $\phi_2 \in C([a_1,b])$ such that 
$$\phi_2(x) = A(x) + \int_{a}^{a_1} K(x,y) \phi_1(y)dy + \int_{a_1}^{x} K(x,y) \phi_2(y)dy$$
for all $x \in [a_1,b]$. I'm not sure what to make of the hint. Thank you.","['real-analysis', 'analysis']"
2702848,"For any sets $X$ & $Y$ can the group of automorphisms for the digraph $G(X,Y)=(X\cup Y,X\times Y)$ be express in terms of symmetric groups?","For any sets $X,Y\neq \emptyset$ if we define a permutation group $G(X,Y)$ on the set $X\cup Y$ as follows:
$$G(X,Y)=\left\{\sigma\in \text{Sym}(X\cup Y):\forall x,y\left[(x,y)\in X\times Y\iff (\sigma(x),\sigma(y))\in X\times Y\right]\right\}$$ Then I'm pretty sure $G(X,Y)$ can be expressed in terms of symmetric groups on subsets of $X\cup Y$ using various group theoretic products between them. What I first did was define the three sets $A,B,C$ by letting $A=X\setminus Y$ and $B=Y\setminus X$ with $C=X\cap Y$ so all these sets were pairwise disjoint, with $A\cup B\cup C=X\cup Y$ and we could express the cartesian product of $X$ with $Y$ as: $$X\times Y=(A\cup C)\times (B\cup C)=(C\times C)\cup(C\times B)\cup(A\times C)\cup(A\times B)\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }\text{ }$$$$=\begin{cases}(A\times B)&\text{ if }(A\neq \emptyset)\land (B\neq \emptyset)\land (C=\emptyset)\\(C\times C)&\text{ if }(A=\emptyset)\land(B=\emptyset)\land (C\neq \emptyset)\\(A\cup C)\times (A\cup C)&\text{ if }(A\neq \emptyset)\land (B=\emptyset)\land (C\neq\emptyset)\\(B\cup C)\times (B\cup C)&\text{ if }(A=\emptyset)\land(B\neq\emptyset)\land (C\neq \emptyset)\\(C\times C)\cup(A\times C)&\text{ if }(A\neq\emptyset)\land(B=\emptyset)\land (C\neq \emptyset)\\(C\times C)\cup(C\times B)&\text{ if }(A=\emptyset)\land(B\neq\emptyset)\land (C\neq \emptyset)\\(C\times C)\cup(C\times B)\cup(A\times C)\cup(A\times B)&\text{ if }(A\neq\emptyset)\land(B\neq\emptyset)\land (C\neq \emptyset)\end{cases}$$ Now noting that the permutations in $G(X,Y)$ fix the sets $A,B$ and $C$ with: $$\forall (v,\sigma)\in (X\cup Y)\times G(X,Y)\left[\sigma(v)\in A\iff v\in A\right]$$
$$\forall (v,\sigma)\in (X\cup Y)\times G(X,Y)\left[\sigma(v)\in B\iff v\in B\right]$$
$$\forall (v,\sigma)\in (X\cup Y)\times G(X,Y)\left[\sigma(v)\in C\iff v\in C\right]$$ I believe we can express $G(X,Y)$ in each of these cases as follows: 1. $G(X,Y)\cong \text{Sym}(X\setminus Y)\text{Sym}(X\setminus Y)$
       2. $G(X,Y)\cong \text{Sym}(X\cap Y)$
       3. $G(X,Y)\cong \text{Sym}(X)$
       4. $G(X,Y)\cong \text{Sym}(Y)$
       5. $G(X,Y)\cong \text{Sym}(X\cap Y)\text{Sym}(X\cap Y)$
       6. $G(X,Y)\cong \text{Sym}(X\cap Y)\text{Sym}(Y\cap X)$
       7. $G(X,Y)\cong \text{Sym}(X\setminus Y)\text{Sym}(Y\setminus X)\text{Sym}(X\cap Y)$ Since if we consider the digraph $D=(X\cup Y,X\times Y)$ then our group is just $\text{Aut}(D)=G(X,Y)$ where $\text{Aut}(D)$ is the automorphism group of our digraph $D$ now with this set of source vertices in $D$ is simply the set $A$ while the set of sink vertices in $D$ is $B$ and lastly the set of internal vertices in $D$ is $C$ further because every digraph automorphism must map sink vertices to sink vertices, source vertices to source vertices and internal vertices to internal vertices I deduced that each permutation fixed each of the three sets $A,B$ and $C$. From there the result seems kinda obvious, however I'm not totally sure because I haven't done stuff like this in a while. Update: Not thinking haven't slept in a while....  alright so clearly I didn't need to separate it out into eight cases not sure why I did that. Anyway under convention taking $\text{Sym}(\emptyset)$ to be a trivial group up to isomorphism, we can write $G(X,Y)$ out explicitly as: $$G(X,Y)\cong \text{Sym}(X\setminus Y)\times \text{Sym}(Y\setminus X)\times\text{Sym}(X\cap Y)$$ Because by the previous reasoning $G(X,Y)$ induces a natural action on the block system $\{A,B,C\}$","['automorphism-group', 'abstract-algebra', 'directed-graphs', 'algebraic-graph-theory', 'group-theory']"
