question_id,title,body,tags
774956,A Pell equation inside a Pell equation,"While working on another problem (see https://mathoverflow.net/questions/143599/solving-the-quartic-equation-r4-4r3s-6r2s2-4rs3-s4-1 ), I found the following equation to be solved:
$$ \bigl((r+s)^2-2s^2\bigr)^2 - 2(2rs)^2 = 1.  \tag{*}$$ Conjecture : There are no solutions with $r > 3$; put another way the solution $(r,s)=(3,2)$ is the only solution with $r>s>0$. Clearly, $(*)$ is the Pell equation $u^2-2v^2=1$, the fundamental solution of which is [perhaps coincidentally?] $(u,v)=(3,2)$. However, in this case, every other solution $u$ is of the same form, i.e. , $u=(r+s)^2-2s^2$. This leads me to believe there is some sort of elementary descent argument that can prove the conjecture. Can anyone point me in the right direction? Thanks, Kieren. EDITED to incorporate Will Jagy's observation about ""every [other] solution"". EDIT: In addition to (*), the following similar Pell equation is simultaneously true:
$$
    \bigl((r-s)^2-2s^2\bigr)^2 - 2(r^2-s^2)^2 = -1.
$$ EDIT (2014/06/05): Is there a way to prove that these two simultaneous Pell equations force $(r,s)$ to be a solution to $X^2-2Y^2=\pm1$?","['quadratic-forms', 'elementary-number-theory', 'number-theory']"
775002,Lognormal Distribution,"I have a question about MLEs and their regarding to a certain distribution: the lognormal distribution. $$
f_{X}(x ; \mu, \sigma)=\frac{1}{x \sigma \sqrt{2 \pi}} e^{-\frac{(\ln x-\mu)^{2}}{2 \sigma^{2}}}, \quad x>0
$$ And, I have that the expected value for the distribution is: $$
e^{\mu+\sigma^{2} / 2}
$$ The MLE for the expected value and the variance are, respectively: $$
\widehat{\mu}=\frac{\sum_{k} \ln x_{k}}{n}, \quad \hat{\sigma}^{2}=\frac{\sum_{k}\left(\ln x_{k}-\widehat{\mu}\right)^{2}}{n}
$$ Now, I'm confused since I need to show if the following are true for my mle for the expected value: consistent I have that the mle is unbiased, but now, I am not so sure...and since I am dealing with an mle, how am I to show consistency? Any help or references would be great!",['statistics']
775032,Does existence of a non-continuous linear functional depend on Axiom of Choice?,"Well, it is easy to construct a non-continuous linear functional on an arbitrary infinite-dimensional vector space (assuming Choice, and taking a basis etc.). I think it is intuitive to say that: Every non-finite-dimensional space has a non-continuous linear functional. depends on the axiom of choice. But what if I am not so demanding, and just want an example of a vector space where there exists a non-continuous linear functional. Do I need choice for that? (OBS: I'm restricting myself to normed spaces)","['vector-spaces', 'functional-analysis', 'banach-spaces', 'axiom-of-choice']"
775036,Probability a Random Variable will assume a value,"In a fictional town of ABC, the weather patterns on different days are all independent of each other. Assume that each given day in ABC is sunny with probability 30% and rainy with probability 70%. Let T denote the random variable representing the number of days you need to wait to see two sunny days in a row in ABC. For example, if it is sunny both tomorrow and the day after, the value of T will be 2. If it is sunny tomorrow, rains the day after, and is then sunny the two days after that, the value of T will be 4. What is the probability that T=4? So if the question was asking the probability of T=3, the first day would have to rain and the last two would be sunny, so the probability would be given by 0.7*0.3*0.3. For T = 4, the last two days are sunny but the first two can either be both rainy or have one rainy and one sunny. I'm not sure how to assign probability to that. Any help would be appreciated!",['statistics']
775045,How do I show that all continuous periodic functions are bounded and uniform continuous?,"A function $f:\mathbb{R}\to \mathbb{R}$ is periodic if there exits $p>0$ such that $f(x+P)=f(x)$ for all $x\in \mathbb{R}$. Show that every continuous periodic function is bounded and uniformly continuous. For boundedness, I first tried to show that since the a periodic function is continuous, it is continuous for the closed interval $[x_0,x_0+P]$. I know that there is a theorem saying that if it is continuous on a closed interval, then it is bounded. However, I'm not allowed to state that theorem directly. Should I just aim for a contradiction by supposing f is not bounded on the interval stated above?","['continuity', 'periodic-functions', 'real-analysis', 'uniform-continuity']"
775060,Computing double integrals,"If $f(x)$ is continuous on $[0,1]$ and $$\int^{1}_{0} f(x) \ \mathrm{d}x = \sqrt{2}$$ compute $$\int_{0}^{1} \int^{1}_{x} f(x)f(y) \ \mathrm{d}y \ \mathrm{d}x$$ First I change the order of integration: $$\int_{?}^{?} \int^{?}_{?} f(x)f(y) \ \mathrm{d}x \ \mathrm{d}y$$ but what happens to the limits? What do I change them to?",['multivariable-calculus']
775093,"Prove that if f is a continuous strictly monotone function defined on an interval, then its inverse is also a continuous function.","There is a theorem on continuous function that goes as follow: If f is a continuous strictly monotone function defined on an interval, then its inverse is also a continuous function. I have quite an ugly proof on this theorem. My textbook proof doesn't look good either. So I am just wondering if someone can provide me with a more elegant proof. Thanks. On top of that, I am just wondering why must the function be strictly monotone? Is it to ensure that it is one-to-one so that the inverse exists? Thanks.","['continuity', 'real-analysis']"
775121,How to prove this series converges $\sum_{n=2}^\infty \frac{\ln(n)}{n^{3/2}}$?,"What test do you use to prove that $$\sum_{n=2}^\infty \frac{\ln(n)}{n^{3/2}}$$ converges? I tried the limit comparison test using $\frac{1}{n^{3/2}}$ as the comparison, but it did not converge.","['convergence-divergence', 'sequences-and-series']"
775170,Proving a function is one to one over a domain and codomain,"I know that the definition of a one-to-one function is $f(x_{1})=f(x_2) \implies x_1 = x_2$. I am having trouble understanding how to prove that a function is one-to-one. This was a given example: $f(x)=x^3$
$$f(x_{1})=f(x_2) \implies (x_1)^3 = (x_2)^3$$
$$(x_1)^3 = (x_2)^3 \implies x_1 = x_2$$ therefore $f(x)$ is one-to-one. What I got from this example is to assume that $f(x_1)=f(x_2)$ then try to simplify the equation in order to obtain $x_1=x_2$. Now let's say I have a different function $g(x)=x^2$ and $g:\mathbb{R}\to \mathbb{R}$. I know that this function is not one to one but using the same proof method above I get this: $$g(x_1) = g(x_2) \implies (x_1)^2 = (x_2)^2$$
$$(x_1)^2 = (x_2)^2 \implies x_1 = x_2$$ This means that $g(x)$ is one to one but this is clearly not true. Am I missing something in the proof or am I doing one-to-one proofs completely wrong? What I am currently doing is trying to solve the equation to end up with $x_1 = x_2$. Another example:
$$f(x)=3x^3-2x$$
$$f(x_1)=f(x_2) \implies (3x_1)^3-2x_1 = (3x_2)^3-2x_2$$ Using the same proof strategy as before I am stuck on this step. How would I continue to conclude whether or not he function is an injection?","['algebra-precalculus', 'functions']"
775184,Difficult time finding critical points using Lagrange,"The function is $f(x,y,z) = xyz$ on $x^2 + y^2 + z^2 = 1$. So I have: $yz = 2x \lambda \\
xz = 2y \lambda \\
xy = 2z \lambda \\
x^2 + y^2 + z^2 = 1$ I guessed $x = \pm 1, y = 0, z = 0, \lambda = 0$ but apparently this isn't a critical point. There's many more that I can't seem to find using algebra either. I can't divide anything out because I can't divide by $0$, and I also can't factor anything. How can I find all the critical points?","['optimization', 'multivariable-calculus']"
775200,Closed form of $ \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx$,"Hello I am trying to solve an incredible integral given by
$$
\int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx=\pi \ln\bigg[\frac{1}{2}\left(\cos^2\alpha +\sqrt{\cos^4 \alpha +\cos^2\frac{\beta}{2} \sin^2 \frac{\beta}{2}}\right)\bigg],\qquad \alpha > \beta >0.
$$
I defined
$$
I\equiv 
\int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx
$$
and using $\cos^2 x=1-\sin^2 x$ but obtained a more complicated expression. Usually it is easier to work with a closed form of Log Sine so I was trying this.  I am not really sure how else to approach this at all. The result looks like very nice and similar to something we all know :) I am looking for real or complex methods to solve this problem.  I am not sure of what substitutions to make but maybe we could work in hyperbolic space","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'trigonometric-integrals']"
775206,"Integral $\int_0^{\pi/2} \ln(1+\alpha\sin^2 x)\, dx=\pi \ln \frac{1+\sqrt{1+\alpha}}{2}$","$$
I_1:=\int_0^{\pi/2} \ln(1+\alpha\sin^2 x)\, dx=\pi \ln \frac{1+\sqrt{1+\alpha}}{2}, \qquad \alpha \geq -1.
$$
I am trying to prove this integral $I_1$.  We can write 
$$
\int_0^{\pi/2} \ln(\alpha(1/\alpha+\sin^2 x))dx=\int_0^{\pi/2} \left(\ln \alpha+\ln (\frac{1}{\alpha}+\sin^2 x)\right)dx=\frac{\pi}{2} \ln \alpha+I_2
$$
where
$$
I_2=\int_0^{\pi/2}\ln (\frac{1}{\alpha}+\sin^2 x) \,dx
$$
however I am not sure what that will do for us....  I also tried differentiating wrt $\alpha$ but didn't get placed.  How can we prove $I_1$ result?  Thanks","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
775216,How to show this function is surjective,"$T(x,y,z) = (2x + y + 3z, 3y - 4z, 5x)$ for $R^3 \rightarrow R^3$ I read the meaning of surjective over and over, but I don't understand how to show it algebraically. So I just guessed: $2x + y + 3z = a \\
3y - 4z = b \\
5x = c$ So $x = \frac{c}{5}$. Then we have $\frac{2c}{5} + y + 3z = a$ and $3y - 4z = b$ I'm lost here. I'm not sure what I'm supposed to do, but I just guessed and and trying to express things in other variables. I'm not sure what I am doing.","['multivariable-calculus', 'functions']"
775217,Proving a function is injective using the definition,"The definition of an injective function is $f(x_1)=f(x_2) \implies x_1 = x_2$. I am having trouble understanding at what point into the proof do you give up and conclude that a function is not injective? For example the function $f(x)=3x^3-2x$ $$f(x_1)=f(x_2)$$
$$3x_1^3-2x_1 =3x_2^3-2x_2$$
$$x_1(3x_1^2-2)=x_2(3x_2^2-2)$$ I am pretty sure that I am not allowed to get rid of everything in the parentheses since this function is not injective. At what point in the proof would you say that it is unable to solve for $x_1 = x_2$ and how would you find the values that make this function not injective?","['algebra-precalculus', 'functions']"
775219,Integral $\int_0^{\pi/4} \frac{\ln \tan x}{\cos 2x} dx=-\frac{\pi^2}{8}.$,"$$I:=\int_0^{\pi/4} \frac{\ln \tan x}{\cos 2x} dx=-\frac{\pi^2}{8}.$$ 
I am trying to see nice solutions to this integral.  I tried the following
$$
I=\int_0^{\pi/4}\frac{\ln \sin x}{\cos 2x} dx-\int_0^{\pi/4} \frac{\ln \cos x }{\cos 2x}dx
$$
but am not sure how to work with this denominator of $\cos 2x$.  If this helps:
$$
\int_0^{\pi/4}\log \sin x \, dx=-\frac{1}{4}\big(2K+\pi \ln 2\big)
$$
where K is the Catalan constant (note I am using Borwein convention not mathematica of using a C to define this constant.)  It is given by
$$
K=\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)^2}=\beta(2) 
$$
where $\beta(2)$ is the  Dirichlet beta function.
However I cannot solve this integral either.  Thanks","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
775269,If $\sin A + \cos A + \tan A + \cot A + \sec A + \csc A = 7$ then $x^2 - 44x - 36 = 0$ holds for $x=\sin 2A$,"If 
$$\sin A + \cos A + \tan A + \cot A + \sec A + \csc A = 7$$
then prove that 
$$\sin 2A \quad\text{ is a root of }\quad x^2 - 44x - 36 = 0$$ I have no idea how to solve it. Plz help.",['trigonometry']
775303,Hardy-Littlewood-Sobolev fractional integration inequality fails at endpoints,"Here's a version of the theorem: If $1 < p, r < \infty$ and $ 0 < \alpha < n $ be such that $ \frac{1}{p} + \frac{ \alpha }{ n} = \frac{1}{r} + 1 $. Then for any $ f \in L^p ( \mathbb R ^n )$, the function $$I_\alpha f (x): = \int_{ \mathbb R^n } \frac{f (y) }{  |x - y| ^\alpha } d y $$ is well defined almost everywhere and lies in $L^r ( \mathbb R^n )$. Moreover, $$|| I_ \alpha f ||_{ L^r ( \mathbb R ^n )} \le C_{p ,\alpha , n } ||f||_{ L^ p(\mathbb R^n )} $$ for some constant $ C_{ p ,\alpha , n } > 0$. I want to show the theorem fails for $ p =1 ,r = \infty$, or $\alpha = n$. I tried a long time but don't make any progress. Any help is appreciated.","['interpolation', 'sobolev-spaces', 'functional-analysis']"
775307,"Quadrature Rule ""is exact for polynomials of degree n""","Could someone kindly explain what ""a quadrature rule is exact for polynomials of degree n"" means? Here is what I understand about numerical (Newton-Cotes) quadrature rules:
Suppose we want to integrate f(x) on the interval [a,b] but it is hard. Hence, one way to do it numerically is to approximate f(x) with a polynomial of degree n and then integrate the polynomial. For Newton-Cotes formulas, we already know (n+1) nodes, so we can interpolate those nodes using Lagrange basis and get the polynomial interpolant of f(x). Then, the book (Numerical Analysis by Suli and Mayers) says on page 205 that ""the Newton-Cotes formula is exact for all polynomials of degree n"" if n is odd. <-- What does this statement really mean?","['numerical-methods', 'integration', 'analysis']"
775328,Proof that infinitely many $f$ exist if $f(f(x))=f(x)^{2013}$,"Suppose $f(x)$ is function from $\mathbb{R}$ to $\mathbb{R}$ such that $f(f(x))=f(x)^{2013}$. Show that there are infinitely many such functions, of which exactly four are polynomials. If $f$ is constant ($f(x) = c$), the value of $c$ satisfying $f(f(x)) = f(x)^{2013}$ would be $-1$, $0$ and $1$. For non-constant $f$, the polynomial $g(x)=f(x)-x^{2013}$ would have all elements of the range of $f$ ($\{f(x)\mid x \in \mathbb{R}\}$) as its roots. Since $f(x)$ is everywhere continuous, $g$ has infinitely many roots, making it the zero polynomial. Thus $f(x)=x^{2013}$ for all real values of $x$.  This proves the existence of the four polynomials. Now, how would I prove the existence of infinitely many $f$?","['contest-math', 'analysis']"
775330,Compact operator whose range is not closed,"I am asked to find a compact operator (on a Hilbert space) whose range is not closed, but I am having trouble coming up with one. My guess is that you need to have some sequence in the range that converges to something outside the range, but this feels like it contradicts the definition of compactness. [Our definition of an operator being compact is that the closure of the image of the closed unit ball is sequentially compact.] Any pointers/suggestions would be appreciated. Thanks in advance!","['compact-operators', 'hilbert-spaces', 'functional-analysis']"
775353,Range and kernel of linear operators,"I have a compact linear operator $T$, and I would like to show $$\operatorname{range}(\lambda I-T)=(\ker(\overline{\lambda}I-T^*))^\perp.$$
I have shown the forward inclusion ""$\subset$"" directly by using the definition of adjoint. However, I'm having trouble with the reverse inclusion ""$\supset$""... it seems much harder to begin with the orthogonal complement with a kernel as well as to show that something is in a range. Any suggestions/hints would be appreciated. Thanks!","['hilbert-spaces', 'functional-analysis']"
775443,Is $\pi$ the best constant in this inequality?,"Let $E$ be the set of completely monotonous functions on $[0,+\infty)$, that is $f \in C^\infty([0,+\infty))$ and $\forall\, n\geq 0,\forall\, x\geq 0,\quad(-1)^nf^{(n)}(x)\geq 0.$. For $f\in E$ and $\lambda>0$, we have
$$\eqalign{
\left(\int_0^\infty f(x)dx\right)^2&\leq \left(\int_0^\infty\frac{dx}{1+\lambda^2 x^2}\right)\left(
\int_0^\infty f^2(x)dx+\lambda^2 \int_0^\infty x^2f^2(x)dx\right)\cr
&\leq \frac{\pi}{2}\left(
\frac{1}{\lambda}\int_0^\infty f^2(x)dx+\lambda \int_0^\infty x^2f^2(x)dx\right)\cr}
$$
Now choosing $\lambda=\sqrt{\int  f^2(x)dx\Big/\int x^2f^2(x)dx}$ we find that
$$
\left(\int_0^\infty f(x)dx\right)^2\le\pi \,\sqrt{\int_0^\infty  f^2(x)dx \int_0^\infty x^2f^2(x)dx}.
$$
Noting, that we restrict our attention to functions $f\in E$, and that $t\mapsto \dfrac{1}{a^2+t^2}\notin E$. Is $\pi$ the best possible constant in this inequality? That is: What is the least $M>0$ such that
$$
\left(\int_0^\infty f(x)dx\right)^2\le M \,\sqrt{\int_0^\infty  f^2(x)dx \int_0^\infty x^2f^2(x)dx}.
$$
for every $f\in E$? Remark: Note that by choosing $f(x)=\dfrac{1}{(1+x)^2}$, we get $3\leq M$, so the best constant belongs to the interval $[3,\pi]$.","['inequality', 'real-analysis']"
775487,From finitely additive to countably additive,"Given a finitely additive measure $\mu : \mathcal{B} \rightarrow [0,\infty]$. If we want to show that it is also countably additive, finite additivity implies 
$$\mu(E) \geq \sum_{n=1}^\infty \mu(E_n)$$ 
where $\cup E_n = E$ with $E_n$ disjoint automatically. For the inequality in the other direction, clearly countably subadditive is sufficient. I was wondering if there are weaker conditions that would also be sufficient. (Just take $\mathcal{B}$ to be the Borel $\sigma$-algebra on $\mathbb{R}$) I know for fact that if $\mu$ is a Radon measure would also be enough (maybe $\sigma$-finite with some regularity properties).","['measure-theory', 'real-analysis']"
775498,Comparing the expected stopping times of two stochastically ordered random processes (Prove or give a counterexample for the two claims),"Information: a-) $X$ and $Y$ are two continuous random variables on $\mathbb{R}$ having continuous distribution functions $F$ and $G$ with $G(y)\geq F(y)$ for all $y$ . b-) $S^X_n=\sum_{i=1}^n X_i$ , $S^Y_n=\sum_{i=1}^n Y_i$ , $A>0$ , and $B<0$ ; where $X_i$ and $Y_i$ are i.i.d. replicas of $X$ and $Y$ respectively. c-) $E[X]<0$ and $E[Y]<0$ . What I know: By coupling (since $G\geq F$ ), I know that there exist a pair of random variables $(X^{'},Y^{'})$ such that $X=X^{'}$ in distribution, $Y=Y^{'}$ in distribution, and $X^{'}\geq Y^{'}$ almost surely. Using this result, I also have $S_n^{X^{'}}=\sum_{i=1}^n X^{'}_i\geq \sum_{i=1}^n Y^{'}_i=S_n^{Y^{'}}$ . Since this holds for all $n$ , I am able to compare the following: $$\tau_A^{X^{'}}=\inf\{n\geq 0:S_n^{X^{'}}\geq A\}$$ $$\tau_A^{Y^{'}}=\inf\{n\geq 0:S_n^{Y^{'}}\geq A\}$$ $$\tau_B^{X^{'}}=\inf\{n\geq 0:S_n^{X^{'}}\leq B\}$$ $$\tau_B^{Y^{'}}=\inf\{n\geq 0:S_n^{Y^{'}}\leq B\}$$ with $\tau_A^{X^{'}}\leq \tau_A^{Y^{'}}$ since $S_n^{X^{'}}\geq A$ implies $S_n^{Y^{'}}\geq A$ and similarly $\tau_B^{X^{'}}\geq \tau_B^{Y^{'}}$ . Please see ( for details ). Claim- $1$ : $$E[\min\{\tau_A^{X^{'}},\tau_B^{X^{'}}\}]\geq E[\min\{\tau_A^{Y^{'}},\tau_B^{Y^{'}}\}]$$ holds for any $(A,B)$ and $(X,Y)$ . Claim- $2$ : $$E[\min\{\tau_A^{X^{'}},\tau_B^{X^{'}}\}]\geq E[\min\{\tau_A^{Y^{'}},\tau_B^{Y^{'}}\}]$$ holds for any $(A,B)$ and $(X,Y)$ , if additionally $\partial F/\partial G$ is increasing.","['probability-theory', 'stochastic-processes', 'probability']"
775507,Concepts of left group and right group. [duplicate],"This question already has answers here : Any Set with Associativity, Left Identity, Left Inverse is a Group (4 answers) Closed 3 years ago . I have somewhere the concepts of left groups (A non empty set with an associative binary operation, a left identity and each element has left inverse) and right groups . I have also studied some basic properties of identities and inverses here . Now I have a question. Does there exist a left group which is not right group?",['group-theory']
775524,Is a bounded continuous function defined on $\Bbb R$ differentiable?,"Is a bounded continuous function defined on $\Bbb R$ differentiable?
Why so? The query is fueled by the following question: Let $f : \Bbb R \rightarrow \Bbb R$ be a bounded continuous function. Define $ g : [0,\infty) \rightarrow \Bbb R$ by $$g(x) = \int_{-x}^x (2xt + 1)f(t)dt .$$ Show that $g$ is differentiable on $(0,\infty)$ and find the derivative of $g$.","['examples-counterexamples', 'calculus', 'derivatives', 'real-analysis']"
775552,What does the derivative of area with respect to length signify?,"Suppose that we have a square sheet of edge length $L$. Its area $A=L^2$. Differentiating $A$ w.r.t. L, we get $$\dfrac{dA}{dL}=2L$$ I do understand what it means to differentiate, graphically, it gives you the slope of the tangent at a point on the graph. But now, when I think of what differentiating means in the context of Area and length, it doesn't make any sense to me at all. What does $2L$ signify?","['calculus', 'derivatives']"
775583,$2\pi^2(x-1)^2+4a\cos(2\pi x)-9a^3=0$ For which $a$ has only one solution...,"For which values of real parameter $a$ the following equation has only one solution:
$$2\pi^2(x-1)^2+4a\cos(2\pi x)-9a^3=0$$ Frankly I have no idea and I hope you'll give me some understandable hint to help me find the way to solve this exercise. Thank you!","['trigonometry', 'parametric']"
775613,Some aspects of inner products in $\mathbb R^3$,"I read several descriptions about inner products recently due to an exercise ( here it is no longer active so I like to ask again). I am still very confused about this concept. Any clarification will be greatly appreciated. The very first definition of inner product I encountered is $\langle
    v, w\rangle =v_1w_1+v_2w_2+v_3w_3$. Or in general, it is a function
defined on $\mathbb R^3\times\mathbb R^3$ into $\mathbb R$ which
satisfies certain positivity and linearity conditions. I have no
problem in understanding this definition. Then people talk about the set of inner products in $\mathbb R^3$.
It seems that an inner product can be represented by a matrix. Why?
And how? This does not make sense to me because if we write inner
product in vector notation, then we have $\langle v, w\rangle=v^Tw$.
There is no matrix in this notation, is there? Moreover, what does
it mean by a set of inner products? Does that mean a set of
functions (since inner product can be treated as a function as
indicated in 1)? What is the natural topology on the set of inner products? Can I say
that the topology is the sub product topology of $\mathbb R^3\times
\mathbb R^3$?","['linear-algebra', 'self-learning', 'differential-geometry', 'analysis']"
775629,Gronwall inequality for $\frac{d}{dt}u(t) \leq C_1u(t) + C_2\sqrt{u(t)}$,"I have the inequality
$$\frac{d}{dt}u(t) \leq C_1u(t) + C_2\sqrt{u(t)}$$
for a positive function $u$. Is there a Gronwall inequality that I can use to write
$$u(t) \leq C_3u(0)?$$
or something similar. I definitely need something where the right hand side is $u(0) \times \text{something}$.","['ordinary-differential-equations', 'functional-analysis', 'partial-differential-equations']"
775643,Show that $E(Y\mid X=x)$ is a linear function in $x$,"Let $Y$ and $X$ be bivariate normal distributed with expectationvector $\mu=(\mu_Y,\mu_X)^T$ and covariance matrix $\Sigma=\begin{pmatrix}\sigma_Y^2 & p_{XY}\\p_{XY} & \sigma_X^2\end{pmatrix}$. Show that the conditional expectation $E(Y\mid X=x)$ is a linear function in $x$. Hello! To my knowledge it is
$$
E(Y\mid X=x)=\int_{\mathbb{R}}y\cdot f_{Y\mid X}(y\mid x)\, dy.
$$
So first I tried to determine $f_{Y\mid X}(y\mid x)$ by
$$
f_{Y\mid X}(y\mid x)=\frac{f_{Y,X}(y,x)}{f_X(x)}.
$$ To my calculation this is
$$
f_{Y\mid X}(y\mid x)=\frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right)
$$ Is that right? In case it is: How can I know determine $$
\int y\cdot f_{Y\mid X}(y\mid x)\, dy,
$$
i.e. how can I determine
$$
\frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int_{\mathbb{R}}y\cdot\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right)\, dy?
$$ Edit: If I set 
$$
c:=-\frac{\sigma_X^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, d:=\frac{2p_{XY}(x-\mu_X)}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, q:=\frac{\sigma_Y^2(x-\mu_X)^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}
$$
and
$$
w:=\frac{(x-\mu_X)^2}{2\sigma_X^2}
$$
then I have to calculate the following:
$$
\frac{\sigma_X\exp(-q+w)}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int y\cdot\exp(c(y-\mu_Y)^2+d(y-\mu_Y))\, dy
$$","['statistics', 'stochastic-integrals', 'proof-verification']"
775644,Platonic solids and charged particles,"It is known that there are five Platonic solids: If, lets say, there are 4 particles with the same electricity charge and whose movement is constrained to be on a sphere, resulting forces will eventually move particles to form a tetrahedron. I have two questions here: 1) If number of particles are 8, 6, 20, and 12, would resulting solid (in similar experiment) be hexahedron, octahedron, dodecahedron, and icosahedron, respectively? 2) What would happen if number of particles is not 4, 8, 6, 20, or 12? Would an equilibrium be reached ever? Would the equilibrium shape be unique or not? Are those solids (resulting from such experiments) widely known? What would be their other properties? I attempted some simulations, and researche the internet but didn't reach any sound conclusion.","['optimization', 'geometry', 'physics', 'solid-geometry', 'platonic-solids']"
775652,Polynomial with given group of symmetries,"Let $f$ be a polynomial in $n$ variables and $G$ - its group of symmetries (group of permutations of variables wich left $f$ in place). I'm trying to such $f$ for given group $G$. I have troubles when $G\subset S_5$ is a cyclic group of fifth order. I have a fifth degree polynomial (for example, $x_1^2x_3x_4x_5+x_2^2x_1x_4x_5+x_3^2x_1x_2x_5+x_4^2x_1x_2x_3+x_5^2x_2x_3x_4$). Is it possible to find such $f$ with lower degree?","['group-theory', 'invariant-theory', 'polynomials']"
775663,Are there infinitely many non-negative integers not covered by one of these 7 polynomials?,"Consider the following polynomials: $$
\begin{align}
f_1(n, m) &= 30nm + 23n + 7m + 5   \\
f_2(n, m) &= 30nm + 17n + 13m + 7  \\
f_3(n, m) &= 30nm + 23n + 11m + 8  \\
f_4(n, m) &= 30nm + 11n + 29m + 11 \\
f_5(n, m) &= 30nm + 29n + 17m + 16 \\
f_6(n, m) &= 30nm + 19n + 7m + 4   \\
f_7(n, m) &= 30nm + 31n + 13m + 13 \\
\end{align}
$$ where $n, m \in \mathbb{Z_{\ge 0}}$ Let $F = (f_1 \cup f_2\: \cup\: ... \cup \:f_7)$ How can I prove that  $\left\vert{\:\mathbb{Z_{\ge 0}} \setminus F\:}\right\vert = \infty$?",['number-theory']
775694,"Integral$\int_0^\infty \ln x\,\exp(-\frac{1+x^4}{2\alpha x^2}) \frac{x^4+\alpha x^2- 1}{x^4}dx$?","I am trying to prove
$$
I:=\int_0^\infty \ln x\,\exp\left(-\frac{1+x^4}{2\alpha x^2}\right) \frac{x^4+\alpha x^2- 1}{x^4}dx=\frac{\sqrt{2\alpha^3 \pi}}{2\sqrt[\alpha]e},\qquad \alpha>0.
$$ Note: The proof below shows how this is just a Gaussian integral! I am not sure how to start this one.  It seems very difficult to me However the answer is very nice. I thought maybe trying to write $I(\alpha)$ and $I'(\alpha)$ to try and simplify things but it didn't help much.  at $x=0$ there seems to be a problem with the integrand also however I am not sure how to go about using this.  Perhaps we could try and use a series expansion for $e^x=\sum_{n=0}^\infty x^n / n!$ however the function $e^{-1/x^2}$ is well known that its taylor series is zero despite the function not being. The factor of $x^4+\alpha x^2-1$ has been giving me trouble with simplifying the integrand.  Thanks. To those who just made an edit:  If you are looking for a +2, please edit something worthwhile.  I edited it back to what I had considering you didn't fix anything as is shown in the Edit History.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
775718,A real continuous periodic function with two incommensurate periods is constant.,"I think I have a proof for the statement, but I can't think of a counter-example when $f: \mathbb{R} \to \mathbb{R}$ is not continous. Here's the problem: Let $f: \mathbb{R} \to \mathbb{R}$ be a continuous periodic function with two incommensurate periods $T_1$ and $T_2$; that is $\displaystyle \frac{T_1}{T_2}$ is irrational. Prove that $f$ is a constant function. Give an example of a nonconstant periodic function with two incommensurate periods. Consider the set $G= \{n_1T_1+n_2T_2 : n_1,n_2 \in \mathbb{Z} \}$. It's straight forward to verify that this set forms a subgroup of $\mathbb{R}$ under addition. Since $\displaystyle \frac{T_1}{T_2}$ is irrational, $G$ will not be cyclic, because if it's cyclic, then there exists an element $m_1T_1+m_2T_2 \in G$ such that for any $n_1T_1+n_2T_2 \in G$ there exists a $p \in \mathbb{Z}$ such that: $$n_1T_1 + n_2T_2 = p (m_1T_1+m_2T_2)$$ Rearranging the terms we obtain: $$\frac{T_1}{T_2} = \frac{n_2-pm_2}{pm_1 -n_1} \in \mathbb{Q}$$
Which is contradiction. Therefore $G$ is not cyclic. Since $G$ is a subgroup of $\mathbb{R}$ which is not cylic, we conclude that $G$ is dense in $\mathbb{R}$. Assume that $f(0)=C$. I'm going to show that $f(x)=C$. Since $G$ is dense in $\mathbb{R}$, every point $x \in \mathbb{R}$ can be approached by elements of $G$ of the form $n_1T_1+n_2T_2$. In particular, for any $\delta>0$ there exists $c_1,c_2 \in \mathbb{Z}$ such that: $$ |x - (c_1T_1+c_2T2)| < \delta$$ Since $f$ is assumed to be continuous, this means that for any $\epsilon>0$ we have: $$|f(x) - f(c_1T_1+c_2T_2)|< \epsilon$$ but $f(c_1T_1+c_2T_2)=f(c_2T_2)=f(0)=C$. Therefore, for any $x \in \mathbb{R}$ we have shown that $\forall \epsilon>0: |f(x)-C|< \epsilon$ which implies $f(x)=C$. I can't think of a counter-example for when $f$ is not continuous. Can someone suggest a counter-example?","['examples-counterexamples', 'calculus', 'proof-verification', 'real-analysis']"
775745,Topology of space of symmetric matrices with fixed number of positive and negative eigenvalues,"Let $M$ be real non-singular symmetric $n \times n$ matrix with $p$ positive and $n-p$ negative eigenvalues. What is the topology of the space of such matrices? For a trivial case $n=1$ the matrix is an ordinary number (which is also its eigenvalue), there are two 1-dimensional spaces with a trivial topology, one for negative and one for positive eigenvalue. For $n=2$, if eigenvalues have the same sign, space of such matrices is 3-dimensional space of trivial topology, but if they have different signs, then space of such matrices is isomorphic to $\mathbb R^2 \times S^1$. How to find the topology for a general case of $p$ positive and $n-p$ negative eigenvalues?","['general-topology', 'eigenvalues-eigenvectors', 'homotopy-theory', 'algebraic-topology']"
775747,Formal logic and functions (I am struggling with writing my proof),"I wish to show that $f\left(\bigcup_aX_a\right)=\bigcup_af(X_a)$ My attempt: $$y\in f\left(\bigcup_aX_a\right)\implies\exists x\in\bigcup_aX_a:y\in f(\{x\})$$
which I didn't like, so I re-wrote it as: $$\forall y\in f\left(\bigcup_aX_a\right)\exists x\in\bigcup_aX_a:y\in f(\{x\})$$ I have to introduce an $x$, I need to put an exists somewhere (unlike proving De Morgan's laws, where you can just say $x\in$left hand side $\implies\in$RHS and then the other way) Now I can write the ""if $x$ is in the union of some sets it is in at least one of them"" nicely as: $$\forall x\in\bigcup_aX_a\exists b:x\in X_b$$ - given an $x$ I can get a $b$. How do I use this above? $$\forall y\in f\left(\bigcup_aX_a\right)\exists x\exists b:x\in X_b\implies y\in f(\{x\})$$ I am saying for all y there exists an x (based on that y) there exists a b based on that x and y with $x\in X_b$.... surely I could also say ""there exists a b where there exists an x such that x in $X_b$ implies...."" I will want to go to: $\forall y\in f\left(\bigcup_aX_a\right)\exists b:y\in f(X_b)$ which makes me want to swap round the order of exists. Then from this we go (not sure how to write it with equal rigor) that y would be in the union of $f(X_a)$ over a. Completing the proof My first attempt: $y\in f\left(\bigcup_aX_a\right)\implies f^{-1}(\{y\})\subset \bigcup_aX_a$ so $\exists x\in f^{-1}(\{y\})$ with $x\in\bigcup_aX_a$ which doesn't feel as concrete as I'd like.","['logic', 'elementary-set-theory']"
775750,Integral $\int_0^{\infty} \frac{\ln \cos^2 x}{x^2}dx=-\pi$,"$$
I:=\int_0^{\infty} \frac{\ln \cos^2 x}{x^2}\text{d}x=-\pi.
$$ Using $2\cos^2 x=1+\cos 2x$ failed me because I ran into two divergent integrals after using $\ln(ab)=\ln a + \ln b$ since I obtained $\int_0^\infty x^{-2}\text{d}x$ and $\int_0^\infty (1+\cos^2 x)\text{d}x $ which both diverge.  Perhaps we should try a complex analysis approach?  I also tried writing $$
I(\alpha)=\int_0^\infty \frac{\ln \cos^2 \alpha \,x}{x^2}\text{d}x
$$ and obtained $$
-\frac{dI(\alpha)}{d\alpha}=2\int_0^\infty \frac{\tan \alpha x}{x}\text{d}x=\int_{-\infty}^\infty\frac{\tan \alpha x}{x}\text{d}x.
$$ Taking a second derivative $$
I''(\alpha)=\int_{-\infty}^\infty {\sec^2 (\alpha x)}\, \text{d}x
$$ Random Variable pointed out how to continue from the integral after the 1st derivative, but is it possible to work with this integral $\sec^2 \alpha x$ ?  Thanks","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
775758,Can the cohomology vanish on $X$ but on no restriction to hyperplane sections?,"I would need a result asserting that if, say, a locally free sheaf $\mathcal{F}$ on a projective $X$ has non-vanishing cohomology when restricted to any smooth hyperplane section, then $H^1(X, \mathcal{F}) \neq 0$, too. I fear that this is too naive, so I will be more specific in two steps, to contextualize. Also, to be fair, I should substitute ""complex of sheaves"" to ""sheaf"" (and ""hypercohomology"" to ""cohomology""). Let $X$ be a projective complex surface, and $F^\bullet = F^1 \xrightarrow{\theta} F^2 \xrightarrow{\theta} F^3$ a 3-steps complex of locally free sheaves. Suppose that we know that for every smooth hyperplane section $i \colon C \subset X$, the hypercohomology $\mathbb{H}^1(C, i^*F^\bullet)$ of the restriction $i^*F^\bullet = i^*F^1 \xrightarrow{i^*\theta} i^*F^2$ is not zero (in my situation, I actually know that this has just 2 steps). Is it possible that $\mathbb{H}^1(X, F^\bullet) = 0$? Some more background (explaining the, probably useless, condition on lengths of complexes). I actually have a flat bundle $\mathcal{V}$ on $X$, with a decomposition $\mathcal{V} = \bigoplus_k U_k$ and maps $\theta \colon U_k \to \mathcal{A}^{1,0}(U_{k+1})$, where $\mathcal{A}^{1,0}$ denotes $(1,0)$-forms, such that $\theta \wedge \theta = 0$, i.e., for every $k$ a complex
$$
F_{X,k}^\bullet = U_k \xrightarrow{\theta} \mathcal{A}^{1,0}(U_{k+1}) \xrightarrow{\theta} \mathcal{A}^{2,0}(U_{k+2}).
$$
By Lefschetz hyperplane theorem, since $\pi_1(C) \twoheadrightarrow \pi_1(X)$, we get an injection $H^1(X, \mathcal{V}) \hookrightarrow H^1(C, i^*\mathcal{V})$. The above decomposition gives a decomposition
$$
H^1(X, \mathcal{V}) \cong \mathbb{H}^1\big(\mathcal{V} \xrightarrow{\theta}\mathcal{A^{1,0}(V)} \xrightarrow{\theta} \mathcal{A^{2,0}(V)}\big) = \bigoplus_k \mathbb{H}^1(F_{X,k}^\bullet),
$$
and we actually have an analogous decomposition on $C$ (of course, with only 2 steps complexes, since on curves $\mathcal{A}^{2,0} = 0$). The natural injective map, then, sends $\mathbb{H}^1(F_{X,k}^\bullet)$ to $\mathbb{H}^1(F_{C,k}^\bullet)$, and every restriction must be injective. I would like to deduce that if the former vanishes for some $k$, then the latter does, too, for the same $k$ and at least one smooth hyperplane section $C$ (a fortiori, in my situation this will imply that it vanishes for every such $C$, but some other arguments are needed). I apologize in advance for the long trivial-but-disguised-as-serious question, no matter how, basic algebraic geometry always escapes me...","['homology-cohomology', 'algebraic-geometry']"
775768,Reference request: Gronwall's inequality with negative sign(s),"The following claim is a consequence of Gronwall's theorem Let $x \colon [0,\infty) \to \mathbb R$ with $x(0) = 0$ be a continuously differentiable function, whose derivative satisfies
  $$ \dot x(t) \le a(t)x(t) + C$$
  with a constant $C \ge 0$ and an integrable function $a \colon [0,\infty) \to (-\infty,0]$.
  Then we have
  $$ x(t) \le tC $$ See e.g. this blog post . Gronwall's theorem can be found in many text books; however, all those that I looked at only considered the case of nonnegative $x$ and $a$, whereas I need $x$ to be arbitrary and $a$ to be nonpositive. Q : Is there a (standard) text book (which can be cited) that treats this general case?","['ordinary-differential-equations', 'reference-request']"
775774,Prove convergence and find the value of the limit of the sequence,"Sequence $$a_{n+1}=(1+\frac{1}{3^n})a_n$$
$$a_1=1$$ The question asks to prove its convergence and find its limit. I have tried all the usual ways but am unable to solve it. The question also says that we should try to prove that it is bounded by 3. Please help.","['sequences-and-series', 'calculus', 'recursion']"
775776,Finding the value of one-sided limits and greatest integer function.,"$$
\lim_{x \to 0} \frac{a}{x} \left\lfloor\frac{x}{b} \right\rfloor
$$ The $\lfloor \rfloor$ stands for the greatest integer function. I have calculated and the left-hand limit is coming as (ab). But, I have doubt in the right-hand limit. I did this problem by sandwich-theorem. Can, anyone help me to find the right-hand limit correctly?","['ceiling-and-floor-functions', 'calculus', 'limits']"
775787,Computing cohomology of hypersurface,"I'm taking a course on differential geometry now, and we got the following exercise from the lecturer: compute the (de Rham) cohomology groups $H_{dR}^i(M)$ of your favourite space . In all the examples I've seen, these groups are only calculated for easy spaces, like spheres, tori, or combinations of these, or spaces that can be built from these. However, even for the basic example of a smooth hypersurface in $\mathbb R^n$, the zero set of a polynomial in $n$ variables, I have no clue how to proceed. So the question is this: let $M$ be the zero set in $\mathbb R^n$ of a smooth polynomial (i.e. such that the partial derivates and the polynomial share no zeros) in $n$ variables. What is, and how can I compute the de Rham cohomology groups of $M$? If that makes it easier, assume the polynomial is homogeneous of degree $d$. Then how can one compute the de Rham cohomology groups of the corresponding projective hypersurface in $\mathbb {P}_{\mathbb R}^n$? Added: For that matter, one could also ask the same question with $\mathbb R$ replaced by $\mathbb C$.","['homology-cohomology', 'differential-geometry', 'projective-geometry']"
775788,Logical issues with the weak law of large numbers and its interpretation,"In several probability textbooks I have found what amounts to the following argument: Let A be an event in some probabilistic experiment. Let p=P(A) be the
  probability of this event occurring in n trials. Let $M$ be the
  fraction of time $A$ occurs in $n$ trials: $M = \frac{X_1+...+X_n}{n}$ where $X_i$ is 1 whenever A occurs, and 0 otherwise; in particular
  $E[X_i]=p$. From simple properties of expectation and variance: $E[M] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =
 \frac{np}{n} = p$ $Var[M] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} =
\frac{\sigma^2}{n}$ So using Chebyshev's inequality: $P(|M-p|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so: $\lim_{n \to \infty} P(|M-p|) = 0$ It is often claimed that this derivation links the mathematical theory of probability with the concept of frequency, but I think is not true and the derivation is either pointless or tautological, for consider the following: if you proceed purely from mathematical axioms, the result holds true in an abstract sense, but there is no logical reason for the particular quantities to have the interpretations we give to them intuitively, e.g. one can not interpret M as a frequency of occurrence without adding an additional axiom specifying what P(A) is, at least this is how it seems to me. On the other hand, if you choose the frequency interpretation of probability, the moment you say ""let p=P(A) be the probability of A"" the very same moment you make an assumption of  existence of a single number p that is the limit of the relative frequency of occurrence of the event A, so what amounts to placing: $\lim_{n \to \infty} P(|M-p|) = 0$ among the axioms . Ideally I would like to know what someone familiar with mathematical logic or research in foundations of mathematics where such issues are examined thinks about this, while in areas like set theory there are volumes written about issues of this kind, in probability theory, while there are plenty of philosophical books about various ways of interpreting probability, I have not found a single work on the mathematical logic of the subject, besides Kolmogorov's Grundbegriffe. My questions are the following: Is my reasoning correct? Is there any reason I miss for this derivation to be important or interesting in some sense? Are there any works that examine probability theory from the standpoint of mathematical logic, where issues of this kind are made more clear? For reference, textbooks are either very mysterious about this, or altogether avoid motivating or interpreting the result. Jim Pitman's ""Probability"", page 101 this is called a ""mathematical confirmation of our intuitive idea of probability as a limit of long-run sequences"". In Bertsekas and Tsitskilis, page 270, M is called the empirical frequency, and it is said that ""Loosely speaking, this allows us to conclude that em­pirical frequencies are faithful estimates of p. Alternatively, this is a step towards interpreting the probability p as the frequency of occurrence of A."". Mark Kac in ""Probability and related topics in the physical sciences"", page 4, writes: Actually, the theorem says disappointingly little. All it says, in
  fact, is the following: If the probability of a certain event was
  calculated in accordance with certain assumptions and rules, then the
  probability (again calculated, according to the same assumptions and
  rules) that the frequency with which the event will occur in a large
  assembly of trials will differ significantly form the calculated
  probability is low. In the notes for a probability theory course by Rota and Baclawski, the interpretation seems more similar to what I have written above: This is essentially just a psychological theorem, for it does not
  provide the information necessary for concrete applications. The
  Central Limit Theorem is far more useful and in fact the law of large
  numbers is a consequence of the Central Limit Theorem. We leave the
  proof as an exercise. In any case the law of large numbers is a purely mathematical theorem.
  In order for it to make sense we must already have the concepts of
  probability, random variables, means, variances, etc. We cannot use
  this as a definition of probability. But we cannot even use the law of
  large numbers as a justification of the frequentist point of view.
  This point of view says that probabilities represent a physically
  measurable quantity (at least in principle). But there is no concept
  of a physical ""measurement"" corresponding to the mathematical concept
  of the limit: lim n->inf of (X_1+...+X_n)/n The relationship between physical experiments and the theory of
  probability is much more subtle than the frequentist point of view
  would have one belive. Finally, Grinstead and Snell write what seems also very reasonable, but not very precise: The Law of Large Numbers, which is a theorem proved about the
  mathematical model of probability, shows that this model is consistent
  with the frequency interpretation of probability.","['probability-theory', 'logic', 'philosophy', 'probability']"
775858,What is a sheaf of rings? (question regarding the definition),"I was reading some notes on Algebraic Geometry and it says,
""Suppose $O_X$ is a sheaf on rings on a topological space $X$
(i.e., a sheaf on $X$ with values in the category of rings)."" What does this ""sheaf on $X$ with values in the category of rings""
mean? Does it mean given an open set $U$ in X, 
$O_X(U)$ is some ring (in the category of rings)? Thanks!","['sheaf-theory', 'algebraic-geometry']"
775935,Divergence Free Vector Fields that are undefined at the origin,"I am aware of vector fields which are  undefined at the origin but whose divergence everywhere else is 0. In particular, my students have already seen the inverse square vector field, i.e. $\vec{F}=\frac{\vec{r}}{||\vec{r}||^3}$ where $\vec{r}=\langle x,y,z \rangle$ and the vector field for an ideal electric dipole $\vec{E}=\nabla \left(\frac{z}{||r||^3} \right)$. Are there still other examples of divergence free vector fields that blow up at the origin? I want to hammer the concept of computing the flux of these vector fields across solids which enclose the origin by constructing a smaller solid inside (whose flux we can easily compute) and applying the divergence theorem to the solid sandwiched in between. Thanks!","['multivariable-calculus', 'calculus', 'physics']"
775943,Closed expression for infinite series,"How can I find the value of the series $$\sum_{n=1}^\infty \frac{1}{(b+n)(a+n)}$$
where $a,b\in[0,1)$? It is obvious by standard arguments that the series converges, but how can I derive the explicit value dependent on $a$ and $b$. Thanks EDIT: $a,b$ can be assumed to be different.","['convergence-divergence', 'sequences-and-series', 'analysis']"
776007,Is there a generating function for $\sqrt{n}$?,"I tried to come up with a closed form for the ordinary generating function for the sequence $\{\sqrt{n}\}_0^{\infty}$ but I could not. Is there a way to derive it using the recurrence relation $$a_{n+1} = \sqrt{a_n^2+1}. $$
Because if there is, it is no obvious to me how to do so. I noticed that the task is trivial if we use a Dirichelt series generating function, namely $\zeta(s-\frac{1}{2})$ but this seems less in interesting to me than having a closed form for the ogf or perhaps even the exponential generating function.","['generating-functions', 'recurrence-relations', 'sequences-and-series']"
776017,Bounded data means bounded solution to parabolic PDE,"Let $u_0 \in L^\infty(\Omega)$ and $f \in L^\infty((0,T)\times\Omega).$ Consider
$$u_t - \Delta u = f$$
$$u|_{\partial\Omega} = 0$$
$$u(0) = u_0$$
or more generally replace $\Delta$ with a suitable elliptic operator $A$. How does one show that $u \in L^\infty((0,T)\times\Omega)$? (My question stems from this paper: http://www.mat.uniroma2.it/~porretta/papers/Blanchard-Porretta-JDE.pdf . See Theorem A.1 in the appendix (page 425). It is a different nonlinear equation but this should still be true). Thanks","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
776026,Probability question-help! P(A)+P(B)>1,"Firstly I wanted to ask for this question how can probability of a and b add up to more then one. If this happens then are they saying the two events do not belong to the same sample space because that's the only way that their probabilities can add up to more than 1 I think. Also, if we have two different events from two different experiments is it possible for us to compare them e.g to see if they are independent. E.g let one experiment be rolling a die once and another experiment be tossing a coin. Then if we choose an event from experiment 1 and an event from experiment two is it possible for us to compare the independence of those two events? (Although they would be independent anyways.) Sorry if this seems like a stupid question.",['probability']
776029,Spectrum and induced homomorphisms,"Let $K$ be an algebraically closed field of characteristic two. Consider the the $K$-algebra homomorphism, $\varphi: K[x] \to K[x]$ defined by $\varphi(x)= x^2$. How can I describe the induced map $\varphi^*: \operatorname{Spec} K[x] \to \operatorname{Spec} K[x]$? I'm not quite sure how this works. What comprises the domain $Spec K[x]$. In other words how does the homomorphism effect the domain $Spec K[x]$. Intuitively I would say we have $x^2-1$ in the fiber of $(x-1)$. I apologize for rambling, someone set me straight.","['commutative-algebra', 'algebraic-geometry']"
776039,Intuition behind normal subgroups,"I've studied quite a bit of group theory recently, but I'm still not able to grok why normal subgroups are so important, to the extent that theorems like $(G/H)/(K/H)\approx G/K$ don't hold unless $K$ is normal, or that short exact sequences $1\to N \stackrel{f}{\to}G\stackrel{g}{\to}H\to1$ only holds when $N$ is normal. Is there a fundamental feature of the structure of normal subgroups that makes things that only apply to normal subgroups crop up so profusely in group theory? I'm looking here for something a bit more than ""$gN=Ng$, so it acts nicely"".","['intuition', 'group-theory', 'normal-subgroups']"
776050,l'Hopital's questionable premise?,"Historians widely report that l'Hopital's 1696 book Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes contains a questionable premise expressed by an equation of type $x+dx=x$ (sometimes written as $y+dy=y$ as in Laugwitz 1997). I used to believe this until I looked in l'Hopital's book and did not find any such equation. What I did find is an axiom right at the beginning of the book to the effect that the $dx$ can be neglected. What l'Hopital wrote, more precisely, was: On demande qu'on puisse prendre indifféremment l'une pour l'autre deux quantités qui ne différent entr'elles que d'une quantité infiniment petite: ou (ce qui est la même chose) qu'une quantité qui n'est augmentée ou diminuée que d'une autre quantité infiniment moindre qu'elle, puisse être considérée comme demeurant la même . l'Hopital did not say that they are equal, but rather that ""qu'on puisse prendre indifféremment l'une pour l'autre"" meaning that ""one can take one for the other"". This viewpoint is close to the one adopted in the hyperreal formalisation of this idea in terms of the standard part function and is not known to entail contradictions like $x+dx=x$. Does the equation perhaps appear elsewhere in the book, or is this simply an inaccuracy? A 17th century scholar I consulted with agreed that the equation is probably not in the book; it would be nice to have a reference to that effect.","['calculus', 'math-history', 'reference-request', 'soft-question', 'nonstandard-analysis']"
776070,Suppose $z \neq -1$ is a complex number of norm 1. Prove that $(\frac{1+z}{|1+z|})^2 =z $,"Suppose $z\neq -1$ is a complex number of norm 1m $(|z| =1)$. I know that $z= n + mi$, what is the most straightforward way of solving this problem? I was also given the following sketch for a possible approach.","['geometry', 'complex-numbers']"
776111,"Probability that random variable greater than its mean by some value, related to its variance","I'm attempting to show the following is true for all random variables $X$, where $\lambda > 0$ is a constant: $$P(X - EX \geq \lambda) \leq \dfrac{\sigma^2(X)}{\sigma^2(X) + \lambda^2}$$ Here's what I've got so far: $$P(|X-EX| \geq \lambda) = P((X-EX)^2 \geq \lambda^2) = P((X-EX)^2 + \sigma^2(X) \geq \lambda^2 + \sigma^2(X)) \leq \dfrac{E[(X-EX)^2 + \sigma^2(X)]}{\sigma^2(X)+\lambda^2} = 2\left(\dfrac{\sigma^2(X)}{\sigma^2(X)+\lambda^2}\right)$$ Now $P(|X-EX|\geq\lambda) = P(X-EX\geq \lambda) + P(EX-X \geq \lambda)$ $ = P(X-EX \geq\lambda) + P((-X)-E(-X)\geq \lambda)$. Therefore one of $P(X-EX\geq\lambda)$ and $P((-X)-E(-X)\geq\lambda)$ must be at most half of $P(|X-EX|\geq\lambda)$,  and so given any $\lambda>0$ and random variable $X$, the desired statement is true for either $X$ or for $-X$. Now my issue is in showing that this statement holds for any random variable $X$. My intuition is to assume that the statement holds for $-X$ and somehow show that it must also hold for $X$, but I've not been able to make any real progress on this. I basically keep working myself in circles at this point. Is there perhaps an easier or better approach for me to take to this problem altogether? Is the statement even true for all random variables $X$ and constant $\lambda > 0$?","['probability-theory', 'probability']"
776127,Branch Cuts of $f(z) + g(z) = \sqrt{p(z)} + \sqrt{q(z)}$,"How does one find the branches of $$f(z) + g(z) = \sqrt{p(z)} + \sqrt{q(z)}$$ where $p$ & $q$ are second degree polynomials? It would be very nice to see this general method applied to, say, $$f(z) + g(z) = \sqrt{2z^2 + 3z - 1} + \sqrt{z^2 + 4z - 2}$$ or something better that's nice though similar. This is apparently an impossible problem, evading just about everybody in our class, though it looks so simple.","['branch-cuts', 'complex-analysis']"
776172,Gap between the induced norm of a matrix and largest Eigenvalue?,"Are there any known results on how big the gap between the absolute value of the largest Eigen  value of matrix and the induced norm can be? More formally, let the induced norm of A is given by $\|A\| = max_{\|x\| = 1}\|Ax\|$ and let $\lambda_{max}$ denote the largest Eigenvalue. I am interested in the quantity $\|A\| - |\lambda_{max}|$. Since the norm bounds the absolute value of the Eigenvalues, the quantity $\|A\| - |\lambda_{max}|$ is always positive. I also know that for positive-definite matrices, the quantity $\|A\| - |\lambda_{max}|$ is zero. But are there any results known for a generic matrix $A$? p.s: I am working on a problem where I am trying to compute a bound on the norm of a matrix. I have bounds on the Eigenvalues of my matrix via Gresghorin's circle theorem and I am trying to see whether I can use that in some way to obtain a bound on the matrix norm.... Edit: To clarify, A is a square matrix over the field of reals and I am using the standard 2-norm on $R^n$",['linear-algebra']
776182,A closed form for the infinite series $\sum_{n=1}^\infty (-1)^{n+1}\arctan \left( \frac 1 n \right)$,"It is known that $$\sum_{n=1}^{\infty} \arctan \left(\frac{1}{n^{2}} \right) = \frac{\pi}{4}-\tan^{-1}\left(\frac{\tanh(\frac{\pi}{\sqrt{2}})}{\tan(\frac{\pi}{\sqrt{2}})}\right). $$ Can we also find a closed form for the value of  $$\sum_{n=1}^{\infty} (-1)^{n+1} \arctan \left(\frac{1}{n} \right)? $$ Unlike the other infinite series, this infinite series only converges conditionally.","['complex-analysis', 'sequences-and-series', 'real-analysis']"
776198,"Is $\sqrt{x^2}$ equal to $|x|$, or to $\pm x$, or to both?","If ${f(x) = \sqrt{x^2}}$ , then f(x) can also be expressed as: C. $\;|x| \quad$ D. $\;\pm x$ I thought the answer was D, but it's C. Couldn't it be both?","['absolute-value', 'algebra-precalculus']"
776201,"Find, with proof, the following limit","$$\lim_{x \to \infty} \, \cos \left(\dfrac{1}{x}\right)^{x} $$ So with this type of limit, does the value cos(1/x) take priority of the power of x as $x \rightarrow \infty$ ? I checked it on wolfram and found the limit to be 1; So would you realise that cos(1/x) as $x \rightarrow \infty$ goes to 1, and $1^{x}$ as $x \rightarrow \infty$ is just 1? Any help on the correct approach would be appreciated.","['limits', 'real-analysis', 'analysis']"
776219,How to generalize the Thue-Morse sequence to more than two symbols?,"The Thue-Morse sequence is defined as a binary sequence and can be generated like 0, 01, 01 10, 01 10 10 01, 01 10 10 01 10 01 01 10, ... . So the second half of the series is always the binary complement of the first half of the series. But is there a way to generate an analogous ternary sequence?
Intuitively my first guess for a ternary Thue-Morse sequence was like 0, 01, 012, 012 120, 012 120 120 201, 012 120 120 201 120 201 201 012, ... So here the second half of the series is the ""ternary complement"" (rotation $0 \to 1, 1 \to 2, 2 \to 0 $ instead of $0 \to 1, 1 \to 0 $) of the first half. But it could also be 0, 01, 012, 012 120 201, 012 120 201 120 201 012 201 012 120, ... Here the second third is the ""ternary complement"" of the first third and the third third is the ""ternary complement"" of the second third. Does any of my constructions for a ternary Thue-Morse series make sense? Is there maybe a unique way to generate an analogous ternary sequence? And how to construct n-ary versions of the Thue-Morse series in general?","['sequences-and-series', 'combinatorics']"
776245,What is the motivation behind a product solution?,"Let's consider the simple differential equation: $$\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0$$ And let's assume we have some regular homogeneous boundary conditions like: $$ u(a, y) = 0$$ 
$$ u(L, y) = 0$$ 
$$ u'(x, y) = 0$$ (I just made these up at the top of my head so feel free to improvise if they don't work with what you want to say.) My question is: What is the intuition/motivation needed in taking a product solution of the form: $$\Psi = X(x)Y(y)$$ From what I understand, we also assume that the BCs apply to $\Psi$ too. From what  I've been told, there is no proof of this, it's just a reasonable trial that seems to work well in a lot of cases.","['homogeneous-equation', 'ordinary-differential-equations', 'intuition', 'partial-differential-equations']"
776256,"$r=(x,y,z)$ prove that $\mathrm{curl}\; r = 0$","Example $\bf 84\,\,\,$ Let $\,\mathbf r=(x,y,z)$ and $r=|\!\,\mathbf r|=\sqrt{x^2+y^2+z^2}$. Then $$\operatorname{div}\mathbf r=
\dfrac{\partial x}{\partial x}
+
\dfrac{\partial y}{\partial y}
+
\dfrac{\partial z}{\partial z}
=3; \\
\operatorname{curl}\mathbf r=
\left|\begin{matrix}
\mathbf i & \mathbf j & \mathbf k \\
\tfrac{\partial}{\partial x} & \tfrac{\partial}{\partial y} & \tfrac\partial{\partial z}\\
x & y & z 
\end{matrix}\right|=\rlap{\rlap{0}\rlap00}0.$$ I fail to see how this equals zero Is $\tfrac{dz}{dy} - \tfrac{dy}{dz} = 0$ and same for other terms too? Thanks","['multivariable-calculus', 'calculus']"
776279,"Finding correlation of Max and Min of two IID random variable in U[0,1]","I have a hw problem and can't figure out how to do it. Basically, $X,Y$ are iid $U[0,1]$, we need to find the correlation between max$(X,Y)$ and min$(X,Y)$. My thought is to find the pdf of $U=$max$(X,Y)$ and $V=$min$(X,Y)$ and then find pdf of UV and use the definition of Variance to find the correaltion. But this seems way to substantial to do. I wonder if there is some simpler method.","['uniform-distribution', 'probability']"
776287,Functions $f$ such that $f(x+1)-f(x-1)=2f'(x)$.,"What can one say about functions $f:\mathbb{R}\to\mathbb{R}$ satisfying the condition $f(x+1)-f(x-1)=2f'(x)$? Is is possible to find all such functions, or is this defining equation the best characterisation that one is likely to get? I know that all polynomials with degree at most 2 satisfy the conditions. This is most easily seen by noting that constants, $f(x)=x$ and $f(x)=x^2$ satisfy the conditions and then noticing that if two functions $f$ and $g$ satisfy the condition then so does any linear combination of $f$ and $g$. One can also see that no polynomial with degree more than 2 will satisfy the condition by noting that $f(x)=x^3$ does not satisfy the condition and then noticing that if $f$ satisfies the condition then so does its derivative (Provided that $f'$ is also differentiable, which is obviously the case for polynomials). Thus the existence of any polynomial $f$ of degree more than 2 which satisfies the condition would imply that there exists such a cubic by repeatedly differentiating $f$, and the existence of such a cubic implies that $f(x)=x^3$ satisfies the condition because $f(x)=x^3$ is a linear combination of the obtained cubic and some quadratic polynomial.","['calculus', 'derivatives', 'functions']"
776291,"Game With 21 Squares, How Many Possible Answers? Function Building","We played this game in our math class, okay, I'll explain how it's played.
There are 21 squares in a straight line across, the first person shades in 2 adjacent squares.  The next player shades in 2 more adjacent squares.  They continue taking turns until there are no more adjacent squares to shade in. The last player to play wins. That's how you play, but the question we got after was how many possible combinations of shaded and unshaded squares are there? He then introduced what he calls ""function building"" which is basically taking a more simple problem and keep adding onto it until you can find a function for it. I really would appreciate any help, and I hope I can learn from this! Edit: I guess I forgot to include that for a solution to be considered a solution, it has to be a finished game, so no two adjacent squares are left unshaded.","['special-functions', 'algebra-precalculus', 'exponential-function', 'functions', 'generating-functions']"
776300,Soft: Why does the existence of a singularity cause problems for deRham cohmology?,"I've heard that if a variety has a singularity then the deRham theory has ""problems"". What exactly are these?
Im guessing there is some sort of issue with the defintion of a differential form, but what exactly? I'm guessing the deRham theorem fails to apply (but why)?","['analytic-geometry', 'algebraic-geometry', 'differential-geometry']"
776333,Prove that (x+1)! is not O(x!),"Discrete math question which is as follows: Prove that $(x+1)!$ is not $O(x!)$ using only the definition of big-O notation. (Hint!: $\log(ab) = (\log a + \log b)$ ) I used a proof by contradiction saying that if it was $O(x!)$ , by definition: $(x+1)! \leq (c)x!$ for $x > k$ for some $k$ . This simplifies to $(x+1)(x!) \leq c(x!)$ where the factorials cancel and we get $x+1 \leq c$ for $x \gt k$ for some $k$ . We can always pick an $x$ that breaks this condition no matter what. Therefore $(x+1)!$ is not $O(x!)$ . Is this correct? I did not need to use the $\log(ab)$ property at all, and therefore am skeptical.","['computational-complexity', 'asymptotics', 'discrete-mathematics', 'algorithms']"
776337,Why is the set of positive definite matrices in $\mathbb R^{n\times n}$ a positive cone,"The set of positive definite matrices in $\mathbb R^{n\times n}$ is geometrically a positive cone. This statement appears in almost every article on real positive definite matrices I read but without a proof. Where can I find a general proof, please? In addition, if I assume this statement is true, does it imply that the set of positive definite matrices is a manifold or a sub-manifold of $\mathbb R^n$ for some $n$?","['self-learning', 'differential-geometry']"
776398,A Riemann integrable function must have infinitely many points of continuity,"I was wondering whether anyone would be so kind as to briefly check my proof? I am supposed to prove the statement without using any theorems which would render the proof trivial. If $\displaystyle\int_a^b f$ exists then $f$ has infinitely many points of continuity in $[a,b]$ For the sake of contradiction suppose $f$ has finitely many. It suffices to show that there is an interval $[u,v]\subset [a,b]$ over which $f$ is not Riemann integrable. Pick any $[u,b]\subset [a,b]$ such that $f$ is discontinuous everywhere in $[u,v]$. For any finite partition $D=\{x_1\cdots x_n\}$ of $[u,v]$ let: $$s(f,D)=\sum_i (x_{i+1}-x_i)\inf_{x\in[x_{i},x_{i+1}]}f\quad\text{and}\quad S(f,D)=\sum_i (x_{i+1}-x_i)\sup_{x\in[x_{i},x_{i+1}]}f$$
We prove $\sup_D s(f,D) <\inf_D S(f,D)\;(1)$. To achieve this consider an arbitrary chain:
$$D_0\subset D_1\subset \cdots$$
Pick any $I_0\subset I_1\subset \cdots$ where $I_k=[u_k,v_k]$ and $I_k$ is an interval of the partition $D_k$. Without loss of generality $\bigcap_i I_i=z$. Given that $f$ is discontinuous everywhere, there exists $\epsilon>0$ such that for any $\delta>0$ there exists $y$ such that $|z-y|<\delta$ yet $|f(z)-f(y)|\geq \epsilon$. This immediately implies $\displaystyle\sup_{I_n} f>\inf_{I_n} f$ and hence $\displaystyle\sup_{D_n} s(f,D)<\inf_{D_n} S(f,D)$. This is valid for any sequence $D_n$ so claim $(1)$ holds, contradicting the integrability of $f$.","['riemann-sum', 'integration', 'real-analysis', 'analysis']"
776447,What number appears most often in an $n \times n$ multiplication table?,"The question is precisely as stated in the title: What number appears most often in an $n \times n$ multiplication table? Note: By ""an $n \times n$ multiplication table"" I mean the multiset $$M_n := \{a \cdot b: \mathbb{Z}^{+}\ni a, b \leq n \} $$ I realize the answer is often not unique - though one could make it so by asking for the minimal entry in the case of a tie - but I am wondering whether there is a general approach to this question. I am not sure about how difficult this problem is; for example, a related question about distinct entries turns out to be quite nontrivial: See the discussion of the Erdos Multiplication Table problem, which was formulated in the mid-twentieth century and resolved only recently by Ford (2008), in the MathOverflow post here .","['prime-numbers', 'number-theory']"
776463,Evaluating $\lim_{\theta \to 0^+}\frac{\sin\theta}{\theta^2}$,"How do I evaluate $$\lim_{\theta \to 0^+}\frac{\sin\theta}{\theta^2}?$$ I tried the following: $$\lim_{\theta \to 0^+}\frac{\sin\theta}{\theta^2} = \lim_{\theta \to 0^+}\frac{1}{\theta}\cdot \lim_{\theta \to 0^+}\frac{\sin\theta}{\theta} = \lim_{\theta \to 0^+}\frac{1}{\theta} = +\infty$$ However, I feel that there is an error with my work, since I believe it isn't acceptable to separate a limit when it separates into something that has a value of infinity. Is there an issue with my work here?",['limits']
776477,Trouble understanding Big O notation for a sum of n integers [duplicate],"This question already has answers here : Big-O notation and polynomials (3 answers) Closed 10 years ago . This problem is an example in a Discrete Math textbook. How can big-O notation be used to estimate the sum of the first n positive integers? Solution: Because each of the integers in the sum of the first n positive integers does not exceed n, it follows that
$$1+2+...+n \le n+n+...+n=n^2$$
From this inequality it follows that $1+2+...+n$ is $O(n^2)$. I do not understand how the sum of $n$'s is equal to $n^2$. Can anyone explain to me what the book used to get this?","['asymptotics', 'discrete-mathematics', 'functions']"
776491,Find the inverse of $f(x) = (x+1)/(x-8)$,Find the inverse of this function: I have gotten this far: $x = y+1/y-8$ $x(y-8) = y+1$ $x(y-8)-1=y$ $xy-8x - 1 = y$ I think I went backwards?,"['inverse', 'algebra-precalculus', 'functions']"
776507,"Maximum Likelihood (ML) vs Maximum a Posteriori Estimation (MAP), When to Use Which?","ML = Maximum Liklihood MAP = Maximum a-posteriori ML is intuitive/naive in that it starts only with the probability of observation given the parameter (i.e. the likelihood function) and tries to find the parameter best accords with the observation. But it take into no consideration the prior knowledge. MAP seems more reasonable because it does take into consideration the prior knowledge through the Bayes rule. So, I think MAP is much better. Is that right? And when should I use which? Here is a related question, but the answer is not thorough - Differences Using Maximum Likelihood or Maximum a Posteriori for Deconvolution / Deblur ?","['statistics', 'maximum-likelihood', 'optimization', 'probability']"
776508,tangent line to a level curve,"Given the function $f:\mathbb{R}^2\to\mathbb{R}$ defined by $$f(x,y)=x^3 + 3x^2y-y^3$$ find the points $(a,b)$ of the plane that satisfy the tangent of the level curve $M=f(a,b)$ in the point $(a,b)$ passes through $(0,1)$. I tried solving this simply by using the equation of the tangent to a level curve: $$f_x(a,b)(x-a)+f_y(a,b)(y-b)=0$$ Hence, I get $$(3a^2+6ab)(x-a)+(3a^2-3b^2)(y-b) = 0$$ Then should I substitute $x,y$ for $(0,1)$? If so, after working it out, I get $$-a^3 -3a^2b+a^2-b^2+b^3=0$$ But how can I solve the points from here on out?","['multivariable-calculus', 'partial-derivative']"
776529,Electric charge is distributed over the disk $x^2 + y^2 \leq 5$...Find the total charge on the disk.,"Electric charge is distributed over the disk 
  $x^2 + y^2 \leq 5$ so that the charge density at $(x,y$) is $\sigma(x,y) = 2 + x^2 + y^2$ coulombs per square meter. Find the total charge on the disk. $$\int_0^{2\pi}\int_0^5(2+r^2)\space r\space dr\space d\theta=\frac{725\pi}2$$ is not the right answer.  I don't know why. Any help?",['multivariable-calculus']
776534,1Prove that limit n tends to infinity $1 + 2 \sum_{k=0}^n1/\binom{n}{k} = e^2$,Prove that limit n tends to infinity $1 + 2 \sum_{k=0}^n1/\binom{n}{k} = e^2$ I have not been able to proceed ..tried many things like ratio of nck and nc(k+1)...also opened it.!! Not able to slove.!!,"['binomial-coefficients', 'limits']"
776557,Galois Group of Composite Field vs. Second Isomorphism Theorem,"$\DeclareMathOperator{\Gal}{Gal}$
In my abstract algebra class, we learned about how Galois groups interact with composite fields. Namely, if $K/F$ is Galois, and $L/F$ is any extension:
$$\Gal(KL/L) \cong \Gal(K/(K \cap L))$$
and
$$[KL : F] = \frac{[K : F][L : F]}{[K \cap L : F]}$$ This immediately reminds me of the second isomorphism theorems. For groups: If $H \le G$ and $N \trianglelefteq G$, then:
$$ HN/N \cong H/(H \cap N) $$
and
$$ |HN| = \frac{|H||N|}{|H \cap N|}, \textrm{ equivalently } |G : HN| = \frac{|G : H||G : N|}{|G : H \cap N|} $$ For rings: if $S$ is a subring and $I$ is an ideal of $R$, then:
$$ (S + I)/I \cong S/(S \cap I) $$
and
$$ |S + I| = \frac{|S||I|}{|S \cap I|}, \textrm{ equivalently } |R : S + I| = \frac{|R : S||R : I|}{|R : S \cap I|} $$ If $K$ is replaced with $H$ (or $S$), $L$ with $N$ (or $I$), and degree with index, these become the same. I can see the connection between the field and group versions with the Fundamental Theorem of Galois Theory, and the group and ring versions by just verifying that multiplication still checks out. But it feels like this is a statement about algebraic structures in general. Is there a way of showing this holds for certain kinds of structures? It feels like a problem for homological algebra or category theory, but I don't know enough about either to tackle it myself. EDIT: More examples. The second isomorphism theorem for modules fits this mold, and it's proved pretty much the same as for rings. In particular, this works for vector spaces. But the ""size function"" doesn't have to be the index (which is not helpful for $\mathbb{R}$-spaces, for example), it can also be dimension (which is what's going on with the Galois groups). The Subspace Sum-Intersection theorem seems to fit this mold as well: for two subspaces $S$ and $T$ of $V$, $\dim (S + T) = \frac{\dim S + \dim T}{\dim (S \cap T)}$.","['galois-theory', 'soft-question', 'abstract-algebra']"
776563,Differential equation with initial value problem,"I am trying to solve the differential equation $$y'= \frac{1}{ty}$$ where $y(1)=2$. 
I have no idea how to solve this, and any help would be great!",['ordinary-differential-equations']
776601,A question on Zhang's result on prime gaps,"I'd like to know which is the right way to mention the result that Yitang Zhang obtained in his paper ""Bounded gaps between primes"". In some places it is said that Zhang proved that there are infinitely many pairs of prime numbers which differ by $70,000,000$ or less, whereas in other places it is said that he proved that there are infinitely many pairs of prime numbers which differ by less than $70,000,000$. In his paper, Zhang mentions that it is conjectured that $$\liminf_{n\to\infty}(p_{n+1}-p_n)=2,$$ which is the Twin Prime Conjecture. Besides, the abstract states that he proves that $$\liminf_{n\to\infty}(p_{n+1}-p_n)<7\times 10^7.$$ So, I think that the right thing is to say that Zhang proved that there are infinitely many pairs of prime numbers which differ by less than $70,000,000$. Any comments?","['prime-numbers', 'prime-gaps', 'number-theory']"
776603,Solve $\cos x+8\sin x-7=0$,"Solve $\cos x+8\sin x-7=0$ My attempt: \begin{align}
&8\sin x=7-\cos x\\
&\implies 8\cdot \left(2\sin \frac{x}{2}\cos \frac{x}{2}\right)=7-\cos x\\
&\implies 16\sin \frac{x}{2}\cos \frac{x}{2}=7-1+2\sin ^2\frac{x}{2}\\
&\implies 16\sin \frac{x}{2}\cos \frac{x}{2}=6+2\sin^2 \frac{x}{2}\\
&\implies 8\sin \frac{x}{2}\cos \frac{x}{2}=3+\sin^2 \frac{x}{2}\\
&\implies 0=\sin^2 \frac{x}{2}-8\sin \frac{x}{2}\cos \frac{x}{2}+3\\
&\implies 0=\sin \frac{x}{2}\left(\sin \frac{x}{2}-8\cos \frac{x}{2}\right)+3
\end{align} I'm not sure how to proceed from here (if this process is even right at all?) . Any help would be appreciated. Thanks.","['trigonometry', 'algebra-precalculus']"
776615,How to find a counter example for non convexity?,"Consider a simple function $f(x,y)=\frac{x}{y}, x,y \in (0,1]$, the Hessian is not positive semi definite and hence it is a non convex function. However, when we plot the function using Matlab/Maxima, it ""appears"" convex. For the sake of clarity we want to find points which violate the definition of convexity, in other words identify the region (in the plot) where the function is non-convex. Can you suggest a procedure to do the same ?","['convex-optimization', 'functions']"
776622,Good family of kernels in $\mathbb{R}^n$,"I'm trying to prove that, given the heat equation $u_t = \Delta u$ with boundary values $u(x,0) = f(x)$, the solution given by $$u(x,t) = f \star H_t^{(d)}(x)$$ is continuous up to the boundary $t=0$, where $H_t^{(d)} = \frac{1}{(4 \pi^2 t)^{d/2}} e^{-\frac{|x|^2}{4t}}$ and $f \in \mathbb{S}(\mathbb{R})$ We know that $H_t^{(d)}$ is a family of good kernels/approx. to the identity as $t \to 0$ Question : Can we say $ f \star H_t^{(d)}(x)$ converges to $f(x)$ uniformly as $t \to 0$ as in the one dimensional case?  Stein and Shakarchi say that, for a good family of kernels $K_{\delta}$ in  $\mathbb{R}^n$, $f \star K_{\delta} \to f(0)$ for $f$ of Schwartz class, which confuses me.","['heat-equation', 'fourier-analysis', 'analysis']"
776638,Why do we study Polish spaces?,"In descriptive set theory, a lot of space is devoted to properties of Polish spaces . (A Polish space is a topological space, which is separable and completely metrizable.) I would like to know why there is so much interest in this class of spaces. Why are they useful? What are interesting applications? Which important tools do they give us? Do they bring new insights into other areas? TL;DR: What is the motivation for studying Polish spaces?","['general-topology', 'descriptive-set-theory', 'soft-question']"
776645,Is a basis for a given topology always closed under finite intersections?,"Define a basis $S$ for a given topology $\delta$ on $X$ as a subset of $\mathcal{P}(X)$ which satisfies the following conditions: $S \subseteq \delta$ and, for every $U \in \delta$ and every $p \in U$, there is a $V \in S$ such that $p \in V$ and $V \subseteq U$. It seems clear that, from this definition, it follows that every $U \in \delta$ will be equal to $\bigcup\limits_{i \leq n} V_i$ for some $V_1, \dots, V_n \in S$. My question is: does it also follow from this definition that, if $V_1, \dots, V_n \in S$, then $V_1 \cap \dots \cap V_n \in S$? Again, it's obvious that, for each $p \in V_1 \cap \dots \cap V_n$, there will be a $C \in S$ such that $p \in C$. But it doesn't seem clear to me that $S$ is necessarily closed under finite intersections. Am I missing something? Or is there a quick counterexample to this?",['general-topology']
776662,Bounding a deviation from the mean,"Suppose $\xi_1,\ldots,\xi_n$ denote independent (but not necessarily identically distributed) random variables. Let $\mathcal{G}$ denote a finite set of $N$ functions and assume that for every $g\in \mathcal{G}$, $$\sup_x |g(x)|\leq \beta \textrm{ and } \sum_{i=1}^n Eg^2(\xi_i)\leq \delta^2.$$ I'm trying to show that there exists a positive constant $C$ such that $$E \max_{g\in \mathcal{G}} \big| \sum_{i=1}^n (g(\xi_i)-Eg(\xi_i)) \big|\leq C \delta \sqrt{\log(2N)} \textrm{ if } \beta\leq \delta/\sqrt{\log(2N)}.$$ Does anybody have a suggestion for how to go about this? I'm stuck, honestly. I've been trying to use Jensen's inequality and the fact that $g(\xi_i)-E g(\xi_i)$ is subgaussian.","['probability-theory', 'concentration-of-measure']"
776675,Isomorphism of the fundamental groups,"Given two complex algebraic varieties $X$ and $Y$. 
If there exists a birational proper morphism $f\colon X\rightarrow Y$ 
then a Theorem of Grothendieck (SGA.X) say that $\pi_1^{et}(X)\cong \pi_1^{et}(Y)$.
Is it possible to obtain the same isomorphism for the topological fundamental group?
What conditions i have to imposse to get this? Thanks in advance.","['algebraic-geometry', 'fundamental-groups']"
776679,Integral $\int_0^\infty \log(1+x^2)\frac{\cosh{\frac{\pi x}{2}}}{\sinh^2{\frac{\pi x}{2}}}\mathrm dx=2-\frac{4}{\pi}$,"Hi I am trying to show$$
I:=\int_0^\infty \log(1+x^2)\frac{\cosh{\frac{\pi x}{2}}}{\sinh^2{\frac{\pi x}{2}}}\mathrm dx=2-\frac{4}{\pi}.
$$
Thank you.
What a desirable thing to want to prove!  It is a work of art this one.  I wish to prove this in as many ways as we can find. Note I tried writing
$$
I=\int_0^\infty \log(1+x^2)\coth \frac{\pi x}{2} \sinh^{-2} \frac{\pi x}{2}\mathrm dx
$$
but this didn't help me much.  We can also try introducing a parameter as follows
$$
I(\alpha)=\int_0^\infty \log(1+x^2)\frac{\cosh{\frac{\alpha \pi x}{2}}}{\sinh^2{\frac{\pi x}{2}}}\mathrm dx,
$$
But this is where I got stuck.  How can we calculate I?  Thanks.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
776680,Algebra question: Finding inverse function,"This question is about finding the inverse function of $f(x)=-\sqrt{9-x^2}$ I seem to be making an error with one of the manipulations. Here is my attempt. $$x=-\sqrt{9-y^2}$$
$$x^2=(-\sqrt{9-y^2})^2$$
$$x^2= -(9-y^2)$$
$$x^2=y^2-9$$
$$x^2+9=y^2$$
$$\sqrt{x^2+9}=\sqrt{y^2}$$
$$y=\sqrt{x^2+9}$$ The answer is $f^{-1} (x)=-\sqrt{9-x^2},-3≤x ≤0$ In which step did I make a mistake? Thank you for your time.","['inverse', 'algebra-precalculus']"
776693,Converse of mean value theorem,"I am wondering if the following converse (or modification) of the mean value theorem holds. Suppose $f(\cdot)$ is continuously differentiable on $[a,b]$. Then for all $c \in (a,b)$ there exists $x$ and $y$ such that
$$
f'(c)=\frac{f(y)-f(x)}{y-x}
$$","['mean-value-theorem', 'derivatives', 'real-analysis']"
776717,Sum of the series $\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt$,"From the relation: $$\csc z=\frac{1}{z}+\sum_{k=1}^\infty (-1)^k \frac{2z}{z^2-k^2 \pi^2}$$ can we obtain the sum of following series? $$\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt$$ I have tried using the absolute value, but I got: $$\sum_{k=1}^\infty \left|\frac{2z}{k^2 \pi^2-z^2}\right|$$ and I can not go on. Any suggestions please?",['complex-analysis']
776735,How can I prove $\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1$?,"How can I prove $\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1$ ? I have looked through all my logarithm rules to find something useful, but the only thing that comes close is $\ln(a/b) = \ln(a)-\ln(b)$. How can I proceed ?","['limits', 'sequences-and-series', 'real-analysis', 'analysis']"
776736,Exponential of matrix with negative entries only on the diagonal,"Suppose I have a matrix $A$ with real entries such that the off-diagonal entries of $A$ are positive or zero. (The diagonal entries may be positive, negative or zero.) From doing a few examples in Python, it looks like the following might be true of the matrix exponential $e^A$: The entries of $e^A$ are all real and non-negative (both on and off the diagonal), and If an entry of $A$ is non-zero, the corresponding entry of $e^A$ will be positive. (For zero entries of $A$, the corresponding entry in $e^A$ might be zero or positive.) Are these things indeed the case? How can this be shown? Is there a result that will allow me to predict which elements of $e^A$ will be positive, depending on which elements of $A$ are non-zero?",['linear-algebra']
776803,Vague convergence implies convergence of oscillations,"Let $G$ be a compact metrisable abelian group. For any real-values $f \in C_c(G)$ and any Borel probability measure $\mu$ on $G$, define the oscilation $\text{osc}_f(\mu)$ of $\mu$ with respect to $f$ to be the quantity $\text{osc}_f(\mu):= \sup_{y\in G} \int_G \tau_yfd\mu(x)-\inf_{y\in G} \int_G \tau_y fd\mu(x)$. I want to show that is a sequence $\mu_n$ of Borel probability measures converges in the vague topology to a Borel probability measure $\mu$, then $\text{osc}_f(\mu_n) \to \text{osc}_f(\mu)$ for all $f \in C_c(G)$. \ I am actually not quite sure why this is true at all. For any $y \in G$, obviously $\int_G \tau_yfd\mu_n(x) \to \int_G \tau_yf\mu(x)$ but it seems like as the sequence goes along, the supremum may be different. Also, I tried working with corresponding linear functionals to see if there were any properties there that would help but it didn't seem like it. EDIT: I sort of found something? Let $\mu * f: G \to \mathbb{R}$ be defined as $\mu *f(y) = \int_G \tau_yfd\mu$. Clearly $\mu *f$ is continuous and compactly supported so it reaches a minimum and maximum. Vague convergence implies  $\mu_n * f \to \mu * f$ pointwise so therefore they reach the same min and max. This last step is not correct. EDIT2: Are the $\mu_n * f$ uniformly equicontinuous? cause then we have uniform convergence and my statement about the min and max will work. EDIT3: Not quite sure about that uniformly equicontinuous claim. Seems more promising to figure out something to do with compactness.",['measure-theory']
776812,Elegant proof of $\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}}$?,"Let $a, b > 0$ satisfy $a^2-4b^2 \geq 0$. Then:
$$\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}}$$
One way to calculate this is by computing the residues at the poles in the upper half-plane and integrating around the standard semicircle. However, the sum of the two residues becomes a complicated expression involving nested square roots, which magically simplifies to the concise expression above. Sometimes such 'magical' cancellations indicate that there is a faster, more elegant method to reach the same result. Is there a faster or more insightful way to compute the above integral?","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
776813,Are rank of $T$ and $T^*$ equal?,Let $H$ be a infinite dimensional Hilbert space and $T:H\to H$ be an operator on $H$ .Is it true that $\operatorname{rank}T=\operatorname{rank}T^*$ . We know that this is true for finite dimension. Is it true for infinite dimensional Hilbert space or is there any example of $T$ and $T^*$ that their rank are different? Thanks!,"['operator-theory', 'functional-analysis']"
776826,Find an explicit formula for the recursive sequence,"Problem: A sequence is defined recursively as follows: $$
S_0 = 1, ~S_k = 2^k - S_k - 1 ~\forall k \in \mathbb{N}_{\geq 1}
$$ Use iteration to guess the explicit formula for the sequence. Use mathematical induction to verify that the sequence matches the explicit formula you guessed. My attempt: $$
S_0 = 1,~S_1 = 1,~S_2 = 3,~S_3 = 5,~S_4 = 11
$$ From here, I saw that the answer to $S_1$ could be substituted into  $S_2$ and so on.. This gave me the equation 
$$
S_k = 2^k - 2^{k - 1} + (k - 1)
$$ When trying to prove this via induction, I stuck here: S j+1 = 2 j+1 - (2 j + 2 j-1 ) + (j - 1) At this point, I don't really know what to do or how to end up with S j+1 . Is my explicit formula wrong? Is there something else I should be looking for? Another thing I have trouble with on these problems is finding the pattern for each explicit formula. Every single problem I've had seems to get the formula with a different pattern each time, doing something I wouldn't have guessed in a million years. Is there a good strategy to find a pattern for these formulas, or are there any tips to recognize these patterns? Thanks.","['recurrence-relations', 'sequences-and-series', 'discrete-mathematics', 'recursion', 'induction']"
776840,Find general solution of first order non-linear in a transcendental function,"I have the function $$\frac{dV}{dT}=1-V^2$$ Just looking to see if my working is okay. $$dV=1-V^2dT$$
$$\frac{1}{1-V^2}dV=dT$$ Integrate $$\int{}\frac{1}{1-V^2}dV=\int{}dT$$
Let $V=\tanh(x)$ $\frac{dV}{dx}=sech^2(x)$ $dV=sech^2(x)dx$ $$\int{}\frac{1}{1-\tanh^2(x)}sech^2(x)dx=\int{}dT$$ $1-tanh^2(x)=sech^2(x)$
$$\int{}\frac{1}{sech^2(x)}sech^2(x)dx=\int{}dT$$
$$\int{}\frac{sech^2(x)}{sech^2(x)}dx=\int{}dT$$
$$\int{}\ dx=\int{}\ dT$$
$$x=\int{}dT$$
$V=\tanh(x)$ so take $\tanh^{-1}$ of both sides to find x
$$\tanh^{-1}(V)=x$$
$$\tanh^{-1}(V)=\int{}dT$$
$$=T+C$$
Take tanh of both side
$$V=\tanh(T+C)$$ Therefore the general solution of $\frac{dV}{dT}=1-V^2$ is $V=\tanh(T+C)$ It is then asking for the particular solution of this for when t=0, v=0 for V is a function of T. I have no idea what they mean.","['ordinary-differential-equations', 'calculus', 'integration', 'indefinite-integrals', 'transcendental-equations']"
