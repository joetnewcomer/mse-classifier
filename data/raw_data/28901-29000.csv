question_id,title,body,tags
268591,How to derive inverse hyperbolic trigonometric functions,"$e^{i\theta}=\cos\theta + i\sin \theta$ $e^{i\sin^{-1}x}=\cos(\sin^{-1}x)+i\sin(\sin^{-1}x)$ $i\sin^{-1}x=\ln|\sqrt{1-x^2} + ix|$ $\sin^{-1}x=-i\ln|\sqrt{1-x^2} + ix|$ Now from here I'm kind of lost, since it seems like this should be the definition, but when I look it up, the definition of inverse hyperbolic sine is: $\sinh^{-1}x=\ln(\sqrt{1+x^2} + x)$ So although they're very similar, I guess I just don't know how to handle the logarithm and anything to the ith power or drop off the absolute value.",['trigonometry']
268597,integer partitions and Faà di Bruno coefficients,"I'm trying to check whether the following statement is true. Let $n$ be a non-negative integer and $p(n)$ the number of integer partitions of $n$. Is it true that
\begin{equation}
p(n)=\sum_{m_1+2m_2+\dots+nm_n=n} \frac{n!}{\prod_{i=1}^n m_i! (i!)^{m_i}}
\end{equation}
where the notation for the sum means summing over all $\{m_i\}$ possible solutions of the equation 
\begin{equation}
m_1+2m_2+\dots+nm_n=n,
\end{equation}
where all $m_i$ are non-negative integers? The fractions in the sum are Faà di Bruno coefficients. It this is true, then I would assume a similar result applies to the extension to partitions in which the maximum element is restricted, say to $k<n$. Concretely,
\begin{equation}
p(n,k)=\sum_{m_1+2m_2+\dots+km_k=n} \frac{n!}{\prod_{i=1}^k m_i! (i!)^{m_i}}
\end{equation}","['number-theory', 'combinatorics']"
268613,How to do diagram chasing effectively?,"I am trying to teach myself some homological algebra, and the book I am using is Aluffi's wonderful Algebra: Chapter 0 , which introduces homology at the end of chapter 3. I have spent a lot of time on this book, doing all the exercises because I am new to category theory. But when the author reaches the Snake Lemma , I felt quite lost. I can produce a proof but it is a quite painful experience. I also searched here, and got a better understanding of the Snake after someone recommended Bergman's Salamander Lemma , but I am still uncomfortable chasing diagrams. In particular, I am wondering whether there is some effective way to do diagram chasing. Is it just experience or I need to change my mindset? Again I am trying to teach myself, so I cannot actually get those visual proofs . Thanks!","['diagram-chasing', 'abstract-algebra', 'homological-algebra', 'category-theory', 'soft-question']"
268635,What is the probability that the center of the circle is contained within a triangle formed by choosing three random points on the circumference?,Consider the triangle formed by randomly distributing three points on a circle. What is the probability of the center of the circle be contained within the triangle?,"['geometric-probability', 'probability', 'circles']"
268636,alternating series test of $\sum(-1)^n\frac{\sqrt{n+1}-\sqrt{n}}{n}$,"I want to know if the sum $$\sum_{n=1}^\infty(-1)^n\frac{\sqrt{n+1}-\sqrt{n}}{n}$$ converges or not.
So I've tried the alternating series text: $\lim\limits_{n\rightarrow\infty}\frac{\sqrt{n+1}-\sqrt{n}}{n}=0$ is clear. I also need $a_{n+1}\leq a_n$. So my question is if there is an very easy way to show 2. ? (I've tried to calculate the inequation but I don't get a nice result.)","['sequences-and-series', 'real-analysis', 'analysis']"
268639,Convergence or divergence of the series $\sum_{n=1}^{\infty}\left(\frac{1}{n}\right)^{1+\frac{1}{n}}$,"I have problem in determining the convergence of the series $\sum_{n=1}^{\infty}\left(\frac{1}{n}\right)^{1+\frac{1}{n}}$. It seems like it is convergent given that $(1+\frac{1}{n})>1$ for all n, but I still cannot prove it rigorously. Can anyone help me ??","['sequences-and-series', 'calculus', 'limits']"
268654,Proving connectedness of punctured disc without using path-connectedness,"Using path-connectedness it is easy to see that the punctured disc $$D:=\lbrace(x,y)\in\mathbb{R}^2:0<x^2+y^2<1\rbrace$$ is connected. I was wondering if there is a proof that $D$ is a connected set of $\mathbb{R}^2$ from the definition of connectedness, or without using path-connectedness ?","['general-topology', 'metric-spaces']"
268661,What is the law of the ratio of two independent gaussian random variables? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: How calculate the probability density function of $Z = X_1/X_2$ The probability density function of the ratio of two normal R.V.s Consider two independent randon variables $N , N' \sim \mathcal N (0,1)$ .What is the law of $N/N'$ ?","['probability-theory', 'probability']"
268665,Proof of $X(\mathcal{O}_K)\simeq X_K(K)$,"I have problems to understand a proof of the following theorem (Algebraic Geometry and Arithmetic Curves, Qing Liu, Theo 3.3.25, page 107). Theorem: let $\mathcal{O}_K$ be a valuation ring over $K$, $X$ a proper $\mathcal{O}_K$-scheme. Then the canonical map $X(\mathcal{O}_K)\to X_K(K)$ is bijective. If I have well understand the canonical map associate to $\varphi:\mathrm{Spec}\mathcal({O}_K)\to K$ the map $\varphi_K:\mathrm{Spec}(K)\to X_K$ base change of $\varphi$ under $\mathrm{Spec}(K)\to\mathrm{Spec}(\mathcal{O}_K)$. The proof is going so: Proof: injectivity: ok surjectivity: let $\pi:\mathrm{Spec}(K)\to X_K\in X_K(K)$. Let $x=\pi((0))\in X_K$. Let $Z=\overline{\{x\}}\subseteq X$: problem 1 , why can we suppose that $x\in X$? Should we reasonning on $y$ image of $x$ by $X_K\to X$? We endowed $Z$ with the structure of reduced closed subscheme, so $Z$ is integral: ok The $\mathcal{O}_K$-scheme $Z$ is proper: ok The point $x$ is closed in $X_K$: ok The point $x$ is dense in $Z_K$: problem 2 , why? I don't have the beaginning of a explanation. Then $Z_K=\{x\}$: ok Image of $Z\to\mathrm{Spec}(\mathcal{O}_K)$ is $\mathrm{Spec}(\mathcal{O}_K)$: ok Let $t\in Z_\mathfrak{m}$ ($\mathfrak{m}\subseteq\mathcal{O}_K$ is the maximal ideal). $\mathcal{O}_{Z,t}$ is dominating $\mathcal{O}_K$: ok The field of fraction of $\mathcal{O}_{Z,t}$ is $\mathcal{O}_{Z,x}$ and $\mathcal{O}_{Z,x}=K$: problem 3 , why $\mathcal{O}_{Z,x}=K$? It should be linked with $\{x\}=Z_K$ but how? Then $\mathcal{O}_{Z,t}=\mathcal{O}_K$ and so we have $\mathrm{Spec}(\mathcal{O}_K)\to X$: ok Thank you for your help","['algebraic-geometry', 'schemes']"
268693,Is there a more elegant way of computing $\int \frac{1}{\sin(x)}dx$ and $\int \frac{1}{\cos(x)}dx$?,"Both integrals can be solved by substitution, and while I am comfortable with that, in both cases I find the method unbearably ugly, mostly because there are hundreds of overtly feasible substitutions (and the corresponding factor the denominator and numerator is multiplied by) a when you look at the integral for the very first time, and so the one that happens to work must be memorised, either by rote or experience using it. Is there a faster or more aesthetically appealing method of computing these (types of) integrals that  'forces the answer upon you' to a greater extent so that the solution does not require bursts of insight or previous experience, and can be applied generally to many types of awkward trigonometric integrals? Something using complex analysis maybe? Or am I asking mathematics to be a little too easy on me?",['integration']
268708,How can I evaluate this improper integral?,"I have a problem: evaluate $$\int_{0}^{\infty}\frac{\cos(x)-\cos(2x)}{x}dx\,.$$ I am told this integral is not an elementary one and that's why I am stuck where to start. Thank you for helping me.","['improper-integrals', 'calculus', 'integration']"
268726,Are there real-life relations which are symmetric and reflexive but not transitive?,"Inspired by Halmos ( Naive Set Theory ) . . . For each of these three possible properties [reflexivity, symmetry, and transitivity], find a relation that does not have that property but does have the other two. One can construct each of these relations and, in particular, a relation that is symmetric and reflexive but not transitive: $$R=\{(a,a),(a,b),(b,a),(b,b),(c,c),(b,c),(c,b)\}.$$ It is clearly not transitive since $(a,b)\in R$ and $(b,c)\in R$ whilst $(a,c)\notin R$ . On the other hand, it is reflexive since $(x,x)\in R$ for all cases of $x$ : $x=a$ , $x=b$ , and $x=c$ . Likewise, it is symmetric since $(a,b)\in R$ and $(b,a)\in R$ and $(b,c)\in R$ and $(c,b)\in R$ . However, this doesn't satisfy me. Are there real-life examples of $R$ ? In this question, I am asking if there are tangible and not directly mathematical examples of $R$ : a relation that is reflexive and symmetric, but not transitive. For example, when dealing with relations which are symmetric, we could say that $R$ is equivalent to being married. Another common example is ancestry. If $xRy$ means $x$ is an ancestor of $y$ , $R$ is transitive but neither symmetric nor reflexive. I would like to see an example along these lines within the answer. Thank you.","['relations', 'elementary-set-theory']"
268758,Prove $\sin x$ is uniformly continuous on $\mathbb R$,"How do I prove $\sin x$ is uniformly continuous on $\mathbb R$ with delta and epsilon? I proved geometrically that $\sin x<x$ and thus, $$|f(x_1)-f(x_2)|=|\sin x_1 - \sin x_2|\le|\sin x_1|+|\sin x_2|<|x_1|+|x_2|$$ But this doesn't help me much finding a delta... Thanks for any help! P.S. I'm only at the beginning of calculus so I can't use many theorems and derivation  (because they haven't been regorously proven).","['calculus', 'continuity', 'functions']"
268767,Probability of a certain dice roll sum disregarding lowest rolls,"The number of ways to obtain a total of $p$ in $n$ rolls of $s$-sided dice is: $$c=\sum_{k=0}^{\lfloor(p-n)/s\rfloor}(-1)^k\binom{n}k\binom{p-sk-1}{n-1}\;.$$ What I'm interested in is making the $n$ rolls, but then disregarding the lowest $m$ rolls. E.g. out of five rolls $1, 5, 3, 5, 6$, disregard the lowest two - the $1$ and $3$. I want to know the number of ways to obtain $p$ as the sum of the remaining $n-m$ rolls. (In my example, the sum was $5+5+6=16$, with of course $n=5, m=2$)","['dice', 'binomial-coefficients', 'combinatorics']"
268770,Dirichlet Problem on an annulus.,"Having found the solution for the Dirichlet problem in the region $A=\{x+iy: 0\leq y\leq 1\}$ such that $u(x,0)=0$ and $u(x,1)=1$ to be $u(x,y)=y$, I am asked to find, using conformal maps, the solution in $B=\{z:r_1\leq|z| \leq r_2 \}$ such that $u(z)=0$ on the internal disc and $u(z)=1$ on the external one. Now, I could find a conformal map from $A$ onto $B$ to be $z \rightarrow e^{i((z-i)\log r_1- z\log r_2)}$ But I think I need a map from $B$ onto $A$ instead and this one is obviously not invertible.. Once I find this conformal map I would be done as the solution wound simply be the composition of the solution in the strip and the conformal map. EDIT1: I can find a solution quite easily which is $u(x,y)= \frac{1}{\log\frac{r_2}{r1}}\log(\frac{\sqrt{x^2+y^2}}{r_1})$ but I would like to use the conformal map method! EDIT2: continuing on mrs's hint: having found the solution, we have that if there is a conformal map $f$ from $B$ onto $A$ then $f(x+iy)=u_1(x,y)+i\ u_2(x,y)$ where $u_2=u$ the solution we found, then we use C-R equations to work out the harmonic conjugate of $u$ and we find that $f(x,y)=\frac{1}{\log\frac{r_2}{r1}}(\frac{r_2}{r_1}\tan^{-1}\frac{x}{y}+ i\log\frac{\sqrt{x^2+y^2}}{r_1})$ EDIT3: the $f$ I found, sadly, has two problems: it is
possibly not holomorphic when $y=0$ and the image of the annulus under it is only a rectangle...",['complex-analysis']
268778,CDF related to sampling with replacement,"Consider a random process where integers are sampled uniformly with replacement from $\{1...n\}$.  Let $X$ be a random variable that represents the number of samples until either a duplicate is found or both the values $1$ and $2$ have been found.  So if the samples where $1,6,3,5,1$ then $X=5$ and if it was $1,6,3,2$ then $X=4$. How does one find the cumulative distribution function. That is how does one find $P(X \geq x)$?",['probability']
268786,The property of line bundle corresponding to birational map,"For a variety, if it has a base point free line bundle, then one can define a morphism from the variety to a $\mathbb{P}^n$. And if a variety is a projective variety(in the sense of Hartshorne), it is equivalent to have a very ample line bundle. In the same vein, I was wondering if there are properties of line bundle corresponding to birational map. To be precisely: Let $V$ be a variety, $L$ be a line bundle on $V$. Which conditions are needed to ensure the $map$ defined by $L$ (i.e. using all the basis of $H^0(V,L)$)is a birational map to its image in $\mathbb{P}^n$? Here $n=dim\ H^0(V,L)-1$.",['algebraic-geometry']
268789,Symmetry of function defined by integral,"Define a function $f(\alpha, \beta)$, $\alpha \in (-1,1)$, $\beta \in (-1,1)$ as $$ f(\alpha, \beta) = \int_0^{\infty} dx \: \frac{x^{\alpha}}{1+2 x \cos{(\pi \beta)} + x^2}$$ One can use, for example, the Residue Theorem to show that $$ f(\alpha, \beta) = \frac{\pi \sin{\left (\pi \alpha \beta\right )}}{ \sin{\left (\pi \alpha\right )} \,  \sin{\left (\pi \beta\right )}} $$ Clearly, from this latter expression, $f(\alpha, \beta) = f(\beta, \alpha)$.  My question is, can one see this symmetry directly from the integral expression?","['definite-integrals', 'symmetry', 'calculus', 'integration']"
268803,Another difficultl limit I need help with,"Can someone help me calculate:
$$  \lim_{x \to \infty} \frac {xe^{x/2}}{1+e^x}\quad?$$ Using l'Hospital doesn't help, but I can't figure out how to do it with Taylor polynomial... it doesn't give me anything! Help anyone? Thanks!","['calculus', 'limits']"
268817,Show that every orbit is forward bounded,"This was a question in an exam on ODEs:
For the planar system
$$
\begin{align}
x' &= 3y\\ 
y' &=-x^3+x-4y
\end{align}
$$
show that every orbit is forward bounded. I have no idea how to show this. What can I do?",['ordinary-differential-equations']
268821,What does it mean $\int_a^b f(G(x)) dG(x)$? - An exercise question on measure theory,"I am reading Folland's book and definitions are as follows (p. 108). Let $G$ be a continuous increasing function on $[a,b]$ and let $G(a) = c, G(b) = d$. What is asked in the question is: If $f$ is a Borel measurable and integrable function on $[c,d]$, then $\int_c^d f(y)dy = \int_a^b f(G(x))dG(x)$. In particular, $\int_c^d f(y) dy = \int_a^b f(G(x))G'(x)dx$ if $G$ is absolutely continuous. As you can see from the title, I did not understand what does it mean $\int_a^b f(G(x))dG(x)$. Also, I am stuck on the whole exercise. If one can help, I will be very happy! Thanks.","['measure-theory', 'real-analysis']"
268822,"What is the T-distribution, and what is it used for?","(I'll post my own answer to this, but don't hesitate to post your own!) Student's t-distribution, or T-distribution, was introduced in 1908 by William Sealey Gossett writing under the pseudonym ""Student"". What is it, and what is it for?",['statistics']
268830,Why do we choose $3$ to be positive after $\sqrt{9 - x^2}$ in the following substitution?,"The integral $$\int \frac{\sqrt{9 - x^2}}{x^2}dx$$ is solved in my book by letting $x = 3\sin\theta$ where $-\frac {\pi}{2} \le \theta \le \frac {\pi}{2}$. 
Then, $dx = 3\cos\theta\,d\theta$ and, $$\sqrt{9-x^2} = 3|\cos\theta| = 3\cos\theta$$ So, $$\int \frac{\sqrt{9 - x^2}}{x^2}dx = \int \cot^2 \theta \ d\theta = -\cot\theta - \theta + C$$ Returning to the original variable, $$\int \frac{\sqrt{9 - x^2}}{x^2}dx = -\frac {\sqrt{9 - x^2}}{x} - \sin^{-1}\left(\frac{x}{3}\right) + C$$ I don't understand why $\sqrt{9-x^2} = 3|\cos\theta| = 3\cos\theta \,$ instead of $\sqrt{9-x^2} = |3||\cos\theta| = |3|\cos\theta$. I feel like I have problems understanding this because I am not sure what is the purpose of the absolute value signs in this case, are they to indicate that, for example, $|\cos\theta| = \pm\cos\theta$? If that's the case, why do we choose $3$ to be positive instead of negative?","['calculus', 'integration']"
268843,Convention for labeling vertices of quadrilaterals.,"I am wondering if there is a convention for labeling the vertices of various quadrilaterals ABCD etc. For example ABCD is a parallelogram. E is a point on DC extended, such that D and E are on opposite sides of BC. Normally I put A in the top left then B in the top Right then C in the bottom left then D in the bottom right but it seems sometimes this results in incorrect construction. Thanks!",['geometry']
268857,Anderson's Inequality for Gaussian measures,"Let $C\subset \mathbb R^n$ be convex and symmetric about the origin. I am trying to prove that $\gamma(C) \geq \gamma(C+x)$ for any $x\in \mathbb R^n$, where $\gamma$ is the standard Gaussian measure. I tried using the following, which can be deduced from the Prekopa Leindler inequality: $$\gamma(tA + (1-t)B) \geq t\gamma(A) + (1-t)\gamma(B)$$ for convex sets $A$ and $B$. However, for any of the various choices of $A$ and $B$ I can think of, this does not yield the desired inequality for $C$. Any suggestions for how to precede? EDIT: The inequality I stated above is wrong; the right side should have the geometric mean. Here is a proof of the correct form of the inequality, using Prekopa Leindler. Let $f(x) = \chi_{tA + (1-t)B} (x) e^{-|x|^2/2}$, $g(x) = \chi_{A} (x) e^{-|x|^2/2}$, $h(x) = \chi_{B} (x) e^{-|x|^2/2}$, where $\chi$ denotes an indicator function. We claim that $f,g,h$ satisfy the hypothesis of the Prekopa Leindler inequality, i.e. $f(tx + (1-t)y) \geq g(x)^t h(y)^{1-t}$. This is obvious if $x\notin A$  $y\notin B$. If $x\in A$ and $y\in B$, then our claim reduces to showing $$ e^{-|tx + (1-t)y|^2/2} \geq e^{-t|x|^2 - (1-t)|y|^2}$$ which is immediate from convexity of $x\mapsto |x|^2$. Thus Prekopa Leindler gives $$\int f(x)\, dx \geq \left(\int g(x)\, dx\right)^t \left(\int h(x)\,dx\right)^{1-t}$$ which is equivalent to $$\gamma(tA + (1-t)B ) \geq \gamma(A)^t \gamma(B)^{1-t} .$$","['probability-theory', 'convex-analysis']"
268869,Eigenvalues of the block matrix $C=\begin{bmatrix}−I &-I\\L&0\end{bmatrix}$,"Consider the following matrix $$C=\begin{bmatrix}−I &-I\\L&0\end{bmatrix}$$ where for $L$ we have: $$L\mathbf{1}=0$$ $$\mathbf{1}^TL=0$$ $$\text{rank}(L)=\dim(L)-1$$ $$L+L^T\geq 0$$ zero is a simple eigenvalue of $L$ and $L+L^T$ . We can show that $C$ has a zero eigenvalue and another one equal to $-1$ , what does we can say about the rest of eigenvalues? For example, we know that when $L=L^T$ , $C$ has only one simple zero and the rest of the eigenvalues have negative real parts. Numerical examples show that most of the time $C$ has only one simple zero and the rest of the eigenvalues have negative real part, but sometimes there is a pair of eigenvalues with zero real part also appearing. Under what conditions does this pair appear?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'block-matrices']"
268873,A finite group of even order has an odd number of elements of order 2 [duplicate],"This question already has answers here : Group of even order contains an element of order 2 (2 answers) Closed 10 years ago . Need some help with this, i'm a bit stuck: Show that if $G$ is a finite group of even order, then $G$ has an odd number of elements of order $2$. Note that $e$ is the only element of order $1$.","['group-theory', 'abstract-algebra']"
268876,Why does $y'' + y = 0$ contain essential singularity at $z =\infty$?,"$y'' + y = 0$ has sine and cosine solutions. It has no regular singularities, although it has an essential singularity at $z \to \infty$ because if you let 
$$w = \frac{1}{z}$$ 
$$\frac{dy}{dz} = \frac{dy}{dw}\frac{dw}{dz} = -w^2\frac{dy}{dw}$$
$$\frac{d^2y}{dz^2} = -\frac{d}{dw} \left(w^2\frac{dy}{dw}\right) \frac{dw}{dz} = w^3\left(2\frac{dy}{dw} + w\frac{d^2y}{dw^2}\right)$$ Now I evaluate the behavior $w \to 0$; $z \to \infty$. Plugging these new differentials into the previous differential equation I get $$w^4\frac{d^2y}{dw^2} + 2w^3\frac{dy}{dw} + y = 0$$
$$\frac{d^2y}{dw^2} + \frac{2}{w}\frac{dy}{dw} + \frac{1}{w^4}y = 0$$ This contains an essential singularity at $z =\infty$. I'm not quite sure I understand why. Is it because sinusoids are not analytic at infinity? They contain no poles do they? Edit: I don't need a formal explanation, maybe something intuitive will be more helpful.",['ordinary-differential-equations']
268881,"An inequality $\frac{(1-\lambda)^{2}}{4}\leq m\{x\in [0,1]: |f(x)|\geq \frac{\lambda}{2}\}$","In this question $f$ is a Lebesgue measurable function on $[0,1]$ with the property that $\|f\|_{2}=1,\|f\|_{1}=1/2$. I am trying to prove that 
$$
\frac{(1-\lambda)^{2}}{4}\leq m\left\{x\in [0,1]: |f(x)| \geq \frac{\lambda}{2} \right\}\>,
$$
for all $0\leq \lambda \leq1$. Here, $m$ denotes the Lebesgue measure on $[0,1]$.
I think I should use the Chebyshev's inequality to prove this; also I need to split the interval in order to get use $\|f\|_{2}=1,\|f\|_{1}=1/2$, but so far I have no idea about what to do next. This is an old qual problem.","['probability-theory', 'measure-theory', 'inequality', 'real-analysis']"
268883,Perron-Frobenius theorem,"In the proof of the Perron-Frobenius theorem why can we take a strictly positive eigenvector corresponding to the eigenvalue $1$? Before that, why can we even take a non-negative eigenvector? Books simply take such a vector, no explanation whatsoever. Pisses me off. Wikipedia only proves it assuming the matrix is irreducible. Any help? Thanks. EDIT: Nevermind, got it. Delete this question, please.","['matrices', 'linear-algebra', 'markov-chains']"
268895,Complex Analysis - Location of roots of a polynomial,"How many roots does the polynomial $z^4 + 3z^2 + z + 1$ have in the right-half complex plane (i.e. $Re(z) \gt 0$)? I honestly can't think of how to approach the problem as it seems different from the regular Rouche's Theorem problems. I can only say that the answer is either 0, 2 or 4 as all the roots come in complex conjugate pairs. (By the Rational Roots Theorem tested on +1 and -1, the polynomial has no real roots.) Attempt at Solution [1 hour after posting question] After pondering on this question a bit, I wonder if the following argument will work: [The Rational Roots Theorem bit above shows that the number of roots in the right-half plane is either 0, 2 or 4.] The coefficient of $z^3$ in the polynomial is 0, indicating that the sum of the roots of the polynomial is 0. If all 4 roots were in the right-half complex plane, or left-half complex plane, then this coefficient would not be 0. Thus, the polynomial has 2 roots in the right-half complex plane. Could someone comment/help to verify this please? Thanks.","['roots', 'complex-analysis', 'polynomials']"
268906,Determine a formula for a dual basis.,"Let $\beta= \{ (2,1),(3,1) \} $ be an ordered basis for $\Bbb R^2$. Suppose that the dual basis of $\beta$ is given by $\beta^*= \{f_1,f_2 \} $ To explicitly determine a formula for $f_1$ we need to consider the equations $$1=f_1(2,1)=f_1(2e_1+e_2)=2f_1(e_1)+f_1(e_2)$$ $$0=f_1(3,1)=f_1(3e_1+e_2)=3f_1(e_1)+f_1(e_2)$$ Solving this equations, we obtain $f_1(e_1)=-1$ and $f_1(e_2)=3$, that is $f_1(x,y)=-x+3y$. My question is why do we need to solve the above equations for 1 and 0 respectively?",['linear-algebra']
268911,Why is $\frac{(x-1)+2}{(x-1)(x+1)} = \frac{1}{x-1}$?,"According to the solution to a problem, the following equation holds true: $$\frac{(x-1)+2}{(x-1)(x+1)} = \frac{1}{x-1}$$ I can't see a way for this to work out.",['algebra-precalculus']
268914,Why does the condition of a function being differentiable always require an open domain?,"Going through Spivak's Calculus on Manifolds and in his definition of a differentiable function from a subset $A$ of $\mathbb{R}^n$ to $\mathbb{R}^m$, $f$ is said to be differentiable if it can be extended to a differentiable function on an open set containing $A$. Why is this? So we dont have to worry about taking limits at boundary points? Why is that even a problem? If thats not the problem, what is wrong with defining $f$ to be differentiable on $A$ if it is differentiable at each point in $A$?","['differential-geometry', 'derivatives', 'real-analysis', 'definition']"
268915,Why are these angles equal for object on inclined plane?,This is a common setup for kinematics problems in physics. My geometry is rusty and I want to understand this very simple idea. I am having trouble understanding why the angle $\theta$ formed by $\overrightarrow{w}$ is equal to $\theta$ = $\angle$ BOA. My initial ideas: If we extend $w$ we can get a right triangle and somehow prove the angles equal by similarity. Some sort of use of interior angles and parallel lines.,"['geometry', 'physics']"
268918,Should $x=-2$ be included as an answer for $\frac{x^2+8x+12}{x^2+5x+6}>0$?,"$$\frac{x^2+8x+12}{x^2+5x+6}>0$$
First of all while solving inequalities I need to check domain so in this case $$x^2+5x+6\neq0$$
$$x\neq-2,\ x\neq-3$$ 
Later on
$$\frac{(x+6)(x+2)}{(x+3)(x+2)}>0$$
Then get critical values draw number line and get
$$x\in(-\infty;-6)\cup(-3;-2)\cup(-2;+\infty)$$
However according to wolframalpha $x=-2$ is included as an answer. So am I wrong or wolframalpha is wrong? Also I checked $\frac{x}{x}=1$ and wolframalpha also includes $x=0$ but once again I think it's incorrect?","['wolfram-alpha', 'linear-algebra']"
268943,Closure of a subset of a subspace of a topological space,"Let $X$ be a topological space.
Let $Y$ be a subspace of $X$.
Let $T$ be a subset of $Y$.
Let $\overline T$ be the closure of $T$ in $X$.
Then $Y \cap \overline T$ is the closure of $T$ in $Y$?.",['general-topology']
268950,Norm inequality for sum and difference of positive-definite matrices,"If $X_{1}$ and $X_{2}$ are positive definite matrices, how to show
that $\left\Vert X_{1}-X_{2}\right\Vert \le\left\Vert X_{1}+X_{2}\right\Vert$ for the spectral norm? and how about for the nuclear norm? Thanks in advance.","['inequality', 'matrices', 'normed-spaces', 'linear-algebra', 'nuclear-norm']"
268955,Complexity of a quadratic program,"I have a quadratic program: $$\displaystyle\min_{\mathbf{X}} (\mathbf{X^TQX +C^TX}) \quad{} \text{subject to} \quad{} \mathbf{A X \leq Y}$$ $\mathbf{Q}$ is positive definite and is $N \times N$, $\mathbf{A}$ is $M \times N$ and $\mathbf{X}$ is an $N \times 1$ vector. I'm trying to compute the complexity in terms of multiplications, but can not figure out how to approach it. I'd appreciate it if anyone can provide help/guidance or any references I can check.
I'm using the interior point convex algorithm.","['optimization', 'linear-algebra', 'computational-complexity']"
268956,Question about sets and classes,"I know every set is a class and not the other way around, but can one consider the set of, say, two classes? Is this ""well-defined""?",['elementary-set-theory']
268957,Demonstrate: $ \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} $,"Demonstrate that $\sqrt2$ can be expressed as: $$ \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} $$ Where $\left(z\right)_i$ is the Pochhammer symbol
$\left(z\right)_i=z(z+1)(z+2)...(z+i-1);  (z)_0=1$ This is a nice problem, just wanted to share it.","['sequences-and-series', 'calculus', 'limits']"
268984,Upper bound of an analytic function (application of Pick's Lemma),"Let $f$ be holomorphic and non zero in the disk $ |z|<1$ with $|f(z)|\leqslant 1$ in $|z|<1$ and $f(0)= e^{-1}$ . What is the best possible bound upper bound for $|f'(0)|?$ Is this bound attained? If so, for what function $f$? So, I applied Pick's Lemma and got the bound $1-e^{-2}$, and according to the same lemma I can claim that this bound can be attained if the function is conformal self map of $\mathbb D$. I did not see how can I get the function. I can guess it should be related somehow with the non-zero behavior of $f$ in the unit disk. But I stuck. Please help.",['complex-analysis']
268988,Why is the subdifferential of norm of a matrix ||A|| defined like this?,"I read in a paper called ""Characterization of the subdifferential of some matrix norms""
that it defines the subdifferential of the matrix norm like this: $$\partial ||A||=\{G \in R^{m\times n} : \forall B \in R^{m\times n}, ||B|| \geq ||A|| + \operatorname{Tr}[(B-A)^TG] \}$$
Can someone tell me why they define it like this? I really don't know the intuition behind it! Thanks!","['matrices', 'normed-spaces', 'derivatives']"
268992,First examples in Galois theory,"I'm studying Field Theory and after studying theorems and problems about extensions, splitting fields, etc... I'm starting with the first theorems of the Galois Theory itself. In order to see if I understand such theorems, I'm trying to prove the first examples in Galois Theory such that the Galois group of $x^3-2\in \mathbb Q[x]$ is the group of symmetries of the triangle. I know that the roots of the equation of $x^3-2=0$ are $2^{1/3},2^{1/3}w,2^{1/3}w^{2}$, where $w$ is a root of the irreducible polynomial $x^2+x+1$ over $\mathbb Q(2^{1/3})$. Thus we write $x^3-2=(x-2^{1/3})(x-2^{1/3}w)(x-2^{1/3}w^{2})$, whence $E=\mathbb Q(2^{1/3},w)$. It follows that $[E:\mathbb Q]=6$. Since E is a splitting field and therefore normal we have also $G(E/\mathbb Q)=6$, then we have six automorphisms of $E$. I'm stuck here, I can't go further, I need help please. Thanks a lot.","['galois-theory', 'field-theory', 'abstract-algebra', 'polynomials']"
269000,n-th derivative of $\frac{\ln x}{x}$.,"Let $f(x)=\frac{\ln x}{x},x>0$. Show that $$f^{(n)}(1)=(-1)^{n+1}(n!)(1+\frac{1}{2}+\cdot+\frac{1}{n})$$ Trial: n-th derivative of $\ln x$ is $$(-1)^{n-1}(n-1)! x^{-n}$$ and n-th derivative of $\frac{1}{x}$ is $$(-1)^n n! x^{-(n+1)}$$Then If I use Leibnitz's Theorem I need to face a big calculation.Please help.","['calculus', 'derivatives']"
269002,Six Frogs - Puzzle (order reversal using special transpositions),"I had come across a puzzle: The six educated frogs in the illustration are trained to reverse their order, so that their numbers shall read 6, 5, 4, 3, 2, 1, with the blank square in its present position. 
  They can jump to the next square (if vacant) or leap over one frog to the next square beyond (if vacant), just as we move in the game of draughts, and can go backwards or forwards at pleasure. Can you show how they perform their feat in the fewest possible moves? It is quite easy, so when you have done it add a seventh frog to the right and try again. 
  Then add more frogs until you are able to give the shortest solution for any number. 
  For it can always be done, with that single vacant square, no matter how many frogs there are. Answer: Move the frogs in the following order: 2, 4, 6, 5, 3, 1 (repeat these moves in the same order twice more), 2, 4, 6. 
  This is a solution in twenty-one moves - the fewest possible. If $n$, the number of frogs, be even, we require $\frac{n^2+n}{2}$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $n$ simple moves. If $n$ be odd, we shall need $\frac{n^2+3n}{2}-4$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $2n-4$ simple moves. In the even cases write, for the moves, all the even numbers in ascending order and the odd numbers in descending order. 
  This series must be repeated $\frac{1}{2}n$ times and followed by the even numbers in ascending order once only. 
  Thus the solution for 14 frogs will be (2, 4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 3, 1) repeated 7 times and followed by 2, 4, 6, 8, 10, 12, 14 = 105 moves. In the odd cases, write the even numbers in ascending order and the odd numbers in descending order, repeat this series $\frac{1}{2}(n-1)$ times, follow with the even numbers in ascending order (omitting $n-1$), the odd numbers in descending order (omitting 1), and conclude with all the numbers (odd and even) in their natural order (omitting 1 and n). 
  Thus for 11 frogs: (2, 4, 6, 8, 10, 11, 9, 7, 5, 3, 1) repeated 5 times, 2, 4, 6, 8, 11, 9, 7, 5, 3, and 2, 3, 4, 5, 6, 7, 8, 9, 10 = 73 moves. ( source ) which I had tried to solve but could not find the reasoning behind the moves used in the solution could anybody tell how to handle this type of puzzles without hit and trial?","['permutations', 'puzzle', 'finite-groups', 'group-theory', 'combinatorics']"
269006,For any curve of unit length there exists a closed rectangle with area at most $A$ that covers the curve.,Find the minimum possible value of $A$ such that for any curve of unit length there exists a closed rectangle with area at most $A$ that covers the curve.,"['optimization', 'contest-math', 'plane-curves', 'real-analysis', 'analysis']"
269011,Is there a similar concept for a sigma algebra like a base for a topology?,"For both a sigma algebra and a topology, we can talk about their generators. For a topology, a base is a special generator only using union, which is a useful concept in topology. 
In parallel comparison, is there a similar concept for a sigma algebra like a base for a topology? How useful can it be? Thanks and regards!","['general-topology', 'measure-theory']"
269025,Probability question.,"Consider a random process where integers are sampled uniformly with replacement from $\{1,\ldots,n\}$.  Let $X$ be a random variable that represents the number of samples until a duplicate is found. So if the samples were $1,6,3,2, 5,1$ then $X=6$. Let $Y$ be a random variable that represents the number of samples before  both the values $1$ and $2$ have been found.  So in our example $Y=4$. How does one find the following. The probability $P(X<Y)$ or in other words $P(Y-X > 0)$. The conditional probability $P(X \geq x \,\mid \, X<Y)$.",['probability']
269032,Understanding two similar definitions: Fréchet-Urysohn space and sequential space,"Here are the definitions: Fréchet-Urysohn space: A topological space $ X $ where for every $ A \subseteq X $ and every $ x \in \text{cl}(A) $ , there exists a sequence $ (x_{n})_{n \in \mathbb{N}} $ in $ A $ converging to $ x $ . Sequential space: A topological space $ X $ where a set $ A \subseteq X $ is closed iff $ A $ contains the limit points of every sequence contained in it. As the title explains, I would like to know the difference between them. Thanks for any help.",['general-topology']
269038,A formula to calculate summations over all divisors of a fixed integer,"I don't know much about number theory, it seems this summation might involve some facts from number theory. Could you give me some idea of doing it? Thank you very much. The summation is $$
g(n)=\sum_{d|n} f(d)
$$ where $f(d)=k^d$, for some fixed positive integers $k$ and $n$. for example, if $n=6$, $g(6)=k+k^2+k^3+k^6$. thanks if no formula, what is the asymptomatic behaviour of it when n large. thanks again.",['number-theory']
269043,Definition for Covariant Derivative,"What is simple definition of the covariant derivative that looks like the definition of the derivative of a function in calculus? definition of the derivative of a function in calculus is: $$\frac {df(x)}{dx}=\lim_{\Delta x\to o}\frac {f(x+\Delta x)-f(x)}{\Delta x}$$ what about Covariant derivative, what is definition of the Covariant derivative of a function in calculus?
$$\frac {{\mathcal D}f(x)}{dx}$$ Remark: ok lets say that: $$\frac {{\mathcal D}f(x)}{dx}=\frac {df(x)} {dx} +\delta f(x)$$ where the covariant derivative is broken into two parts, the extrinsic normal component and the intrinsic covariant derivative component . Now, how do we define a simple definition for the intrinsic covariant derivative component $\delta f(x)$ (this small addition is the result of parallel translation)","['calculus', 'differential-geometry', 'definition']"
269044,Check my proof of an algebraic statement about fractions,"I tried to prove the part c) of "" Problem 42 "" from the book "" Algebra "" by Gelfand. Fractions $\frac{a}{b}$ and $\frac{c}{d}$ are called neighbor fractions if their difference $\frac{cb-ad}{db}$ has numerator ±1, that is, $cb-ad = ±1$ . Prove that: b) If $\frac{a}{b}$ and $\frac{c}{d}$ are neighbor fractions, then $\frac{a+c}{b+d}$ is between them and is a neighbor fraction for both $\frac{a}{b}$ and $\frac{c}{d}$ . Me: It is easy to prove. c) No fraction $\frac{e}{f}$ with positive integer $e$ and $f$ such that $f < b+d$ is between $\frac{a}{b}$ and $\frac{c}{d}$ . Me: We know that $\frac{a+c}{b+d}$ is between $\frac{a}{b}$ and $\frac{c}{d}$ . The statement says that if we make the denominator smaller than $b+d$ , the fraction can't be between $\frac{a}{b}$ and $\frac{c}{d}$ with any numerator. Let's prove it: Assume that $\frac{a}{b}$ < $\frac{c}{d}$ , and $cb-ad = 1$ , ( $cb = ad + 1$ ). I also assume that $\frac{a}{b}$ and $\frac{c}{d}$ are positive. Start with the fraction $\frac{a+c}{b+d}$ , let $n$ and $m$ denote the changes of the numerator and denominator, so we get $\frac{a+c+n}{b+d+m}$ ( $n$ and $m$ may be negative). We want it to be between the two fractions: $$\frac{a}{b} < \frac{a+c+n}{b+d+m} < \frac{c}{d}$$ Let's see what the consequences will be if the new fraction is bigger than $\frac{a}{b}$ : \begin{align*}
\frac{a+c+n}{b+d+m} & > \frac{a}{b}\\
b(a+c+n) & > a(b+d+m)\\
ba+bc+bn & > ba+ad+am\\
bc+bn & > ad+am
\end{align*} But $bc = ad + 1$ by the definition, so \begin{align*}
(ad + 1) + bn & > ad + am\\
bn - am & > -1
\end{align*} All the variables denote the natural numbers, so if a natural number is bigger than $-1$ , it implies that it is greater or equal to $0$ : $$bn - am \geq 0$$ Let's see what the consequences will be if the new fraction is less than $\frac{c}{d}$ : \begin{align*}
\frac{a+c+n}{b+d+m} & < \frac{c}{d}\\
...\\
cm - dn & \ge 0
\end{align*} We've got two equations, I will call them p-equations , because they will be the base for our proof (they both have to be right): $$\begin{cases} bn - am \ge 0\\ cm - dn \ge 0\end{cases}$$ Suppose $\frac{a}{b} < \frac{a+c+n}{b+d+m} < \frac{c}{d}$ . What $n$ and $m$ have to be? It was conjectured that if $m$ is negative, so for any $n$ this equation would not be right. Actually if $m$ is negative, $n$ can be only less or equal $0$ , because when the denominator is getting smaller, the fraction is getting bigger. Suppose that $m$ is negative and $n = 0$ . Then the second p-equation can't be true: $$-cm - d\cdot 0 \ge 0 \implies -cm \ge 0$$ If both $n$ and $m$ are negative, the p-equations can't both be true. I will get rid of the negative signs so we can treat $n$ and $m$ as positive: \begin{gather*}
\begin{cases}(-bn) - (-am)  \ge 0\\ (-cm) - (-dn)  \ge 0\end{cases}\\
\begin{cases}am - bn  \ge 0\\ dn - cm  \ge 0\end{cases}
\end{gather*} If something is greater or equal $0$ then we can multiply it by a positive number and it still will be greater or equal $0$ , so multiply by $d$ and $b$ : \begin{gather*}
\begin{cases}d(am - bn) \ge 0\\ b(dn - cm) \ge 0\end{cases}\\
\begin{cases}da\cdot m - dbn \ge 0\\ dbn - bc\cdot m \ge 0\end{cases}
\end{gather*} But $bc$ is greater than $da$ by the definition. You can already see that the equations can't both be true, but I will show it algebraicly: By the definition $bc = da + 1$ , then \begin{gather*}
\begin{cases}dam - dbn \ge 0\\ dbn - (da + 1)m \ge 0\end{cases}\\
\begin{cases}dam - dbn \ge 0\\ dbn - dam - m \ge 0\end{cases}
\end{gather*} If two equations are greater or equal $0$ , than if we add them together, the sum will still be greater than  or equal to $0$ . \begin{align*}
(dam - dbn) + (dbn - dam - m) & \ge 0\\
-m & \ge 0
\end{align*} It is impossible (I changed $n$ and $m$ from negative to positive before by playing with negative signs). QED . If $n$ and $m$ are positive, the p-equations can both be true, I won't go through it here because it is irrelevant to our problem. But it is the common sense that I can choose such big $n$ and $m$ to situate $\frac{a+c+n}{b+d+m}$ between any two fractions. PS: Maybe my proof is too cumbersome, but I want to know is it right or not. Also advices how to make it simpler are highly appreciated.","['fractions', 'algebra-precalculus', 'solution-verification']"
269061,"Show f is uniformly continuous on $(a,b)$ if it is continuous and $\lim\limits_{x\to a^+}f(x)$ and $\lim\limits_{x\to b^-}f(x)$ exist","Let $f:(a,b)\to\mathbb{R}$ be continuous at all $x\in(a,b)$. If $\lim\limits_{x\to b^-}f(x)$ and $\lim\limits_{x\to a^+}f(x)$ exist in $\mathbb R$, how can we prove that $f$ is uniformly continuous on $(a,b)$? This is my attempt, but I'm just not certain it is correct: Let $\epsilon>0$. It is clear that $[a+\epsilon,b-\epsilon]\subseteq(a,b)$. It is known that $f(x)$ is continuous on $(a,b)$, so it is uniformly continuous on the bounded interval $[a+\epsilon,b-\epsilon]$. But, $[a+\epsilon,b-\epsilon] \iff (a,b)$. Thus $f$ is uniformly continuous on $(a,b)$. Is my proof correct? Is there a better way?","['functions', 'continuity', 'real-analysis']"
269066,Game combinations of tic-tac-toe [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How many combinations are possible in the game tic-tac-toe ( Noughts and crosses )? So for example a game which looked like: (with positions 1-9) A1   --   B1

A2   --   B2

A3   --   -- [1][3][4][6][7] would be one combination","['tic-tac-toe', 'combinatorial-game-theory', 'combinatorics']"
269074,Confusion in the proof of properties for $\psi$-irreducibility,"Let $P$ be a stochastic kernel on a measurable space $(\mathsf X,\mathfrak B(\mathsf X))$. The kernel $P$ is called $\varphi$-irreducible if for a positive measure $\varphi$ and for all measurable sets $A$ it holds that:
$$
\tag{1}\varphi(A)>0 \quad \Rightarrow \quad \sum\limits_{n\geq 1}P^n(x,A) >0 \quad \forall x\in \mathsf X.
$$ One of the statements of Proposition 4.2.2 (p. 90 here ) is that if $P$ is $\varphi$-irreducible, then it holds that $P$ is $\psi$-irreducible where the measure $\psi$ is given by 
$$
  \psi(A) = \int\limits_\mathsf X \sum_{n\geq 0}2^{-(n+1)}P^n(x,A)\varphi(\mathrm dx).
$$
The definition of $\psi$ is not that important for my question, though. In the first part of the proof, also page 90, the following is stated To see (i), observe that when $\psi(A)>0$, then [...] 
  $$
\tag{2}  \left\{y:\sum\limits_{n\geq 1}P^n(y,A)>0\right\} = \mathsf X.
$$ This fact is further elaborated and used to show the $\psi$-irreducibility of $P$. It seems to me, however, that the cited part explicitly implies irreducibility as it is equivalent to $(1)$. I guess, I am missing something - otherwise it is a cyclic argument. Also, I don't know how to show $(2)$.","['probability-theory', 'stochastic-processes', 'markov-chains']"
269081,Calculating the integral $\int_0^{\infty}{\frac{\ln x}{1+x^n}}$ using complex analysis,"I need to calculate $\int_0^{\infty}{\frac{\ln x}{1+x^n}}$ $,n\geq2$ using complex analysis. I probably need to use the Residue Theorem. I use the function $f(z)={\frac{\ln z}{1+z^n}}$ in the normal branch. I've tried to use this contour. Where $\theta$ is an angle so that only $z_{0}$ will be in the domain (I hope this is clear from the drawing) I estimated $|\int_{\Gamma_{R}}|$ and $|\int_{\Gamma_{\epsilon}}|$ and showed that they must tend to $0$ when $\epsilon \rightarrow0$ and $R \rightarrow\infty$. (Is it true?) However I'm having trouble calculating $\int_{\Gamma_{2}}$ . Does it have something to do with choosing the ""right"" $\theta$? Any ideas? Thanks! UPDATE After Christopher's comment I chose $\theta=\frac{2\pi}{n}$ which gives, after the paramatrization $\Gamma (t) = te^{\frac{2\pi i}{n}}$, $t\in(\epsilon,R)$: $$\int_{\Gamma_{2}}{\frac{\ln z}{1+z^n}dz} = \int_{\epsilon}^{R}{\frac{\ln (te^\frac{2\pi i}{n})}{1+t^n}e^\frac{2\pi i}{n}dt} = 
e^\frac{2\pi i}{n}\int_{\epsilon}^{R}{\frac{\ln t}{1+t^n}dt} +
ie^\frac{2\pi i}{n}\int_{\epsilon}^{R}{\frac{\frac{2\pi}{n}}{1+t^n}dt}  =$$
$$
=
e^\frac{2\pi i}{n}\int_{0}^{\infty}{\frac{\ln t}{1+t^n}dt} +
ie^\frac{2\pi i}{n}\int_{0}^{\infty}{\frac{\frac{2\pi}{n}}{1+t^n}dt}
$$ But I have no idea how to deal with the second integral.","['integration', 'complex-analysis']"
269086,Differential equation $xy^3y'=2y^4+x^4$,"Solve the differential equation
$$xy^3y'=2y^4+x^4$$","['ordinary-differential-equations', 'calculus', 'real-analysis']"
269091,Bounded index of nilpotency,"A ring $R$ is said to have a bounded index (of nilpotency) if there is a positive integer $m$ such that $x^m = 0$ for every nilpotent $x\in R$. I wonder whether this property transfers to the ring of matrices, that is, If $R$ has bounded index, then $M_n(R)$ has bounded index? If $R$ is a field, then the answer is positive and extends obviously to integral domains. Noetherian rings have also the bounded index property, and it would be nice to have an answer in this case. (When $R$ is noetherian and reduced the answer is also positive.) Remark. This question was suggested by Bound on nilpotency index of endomorphisms .","['commutative-algebra', 'abstract-algebra']"
269093,"How to calculate $\sum \limits_{x=0}^{n} \frac{n!}{(n-x)!\,n^x}\left(1-\frac{x(x-1)}{n(n-1)}\right)$","What are the asymptotics of the following sum as $n$ goes to infinity?
$$
S =\sum\limits_{x=0}^{n} \frac{n!}{(n-x)!\,n^x}\left(1-\frac{x(x-1)}{n(n-1)}\right)
$$ The sum comes from CDF related to sampling with replacement . Consider a random process where integers are sampled uniformly with replacement from $\{1...n\}$.  Let $X$ be a random variable that represents the number of samples until either a duplicate is found or both the values $1$ and $2$ have been found.  So if the samples where $1,6,3,5,1$ then $X=5$ and if it was $1,6,3,2$ then $X=4$. This sum is therefore $\mathbb{E}(X)$. We therefore know that $S = \mathbb{E}(X) \leq \text{mean time to find a duplicate} \sim \sqrt{\frac{\pi}{2} n}$. Taking the first part of the sum, 
$$\sum_{x=0}^{n} \frac{n!}{(n-x)!\,n^x} = \left(\frac{e}{n} \right)^n \Gamma(n+1,n) \sim \left(\frac{e}{n} \right)^n  \frac{n!}{2} \sim  \sqrt{\frac{\pi}{2} n}. $$","['asymptotics', 'summation', 'limits']"
269101,Communicating information about functions in plain English.,"I am having a bit of trouble with communicating information about functions in  English. I know that $f(x)$ is read $f$ of $x$, but how would I use this in a sentence? Say, we have a argument x=5, and I want to express the process of passing this input to the function, would I then say: taking $f$ of 5 gives $f(5) = 5^2+1$, putting the argument $x=5$ gives $f(5) = 5^2+1$ (this seems ambiguous if multiple functions exists), or putting $x=5$ and applying function $f$ gives $f(5) = 5^2+1$? I suspect that the first option is correct, but English is not my native language and I'd love some feedback on this.",['functions']
269105,$T$ surjective iff $T^*$ injective in infinite-dimensional Hilbert space?,"Let $T:H_1\rightarrow H_2$ be a bounded linear operator where $H_1$ and $H_2$ are Hilbert spaces. The Hilbert-adjoint is defined to the the operator $T^*:H_2\rightarrow H_1$ such that $\langle Tx,y\rangle_{H_2}=\langle x,T^*y\rangle_{H_1}$ for all $x\in H_1$ and $y\in H_2$. It can be shown that $\ker T^*=\left(\operatorname{im}\, T\right)^\perp$ and $\left(\ker T^*\right)^\perp=\overline{\operatorname{im}\, T}$ (see, e.g., here ). It follows that $$T \text{ surjective} \Rightarrow \operatorname{im}\, T = H_2 \Rightarrow \ker T^* = H_2^\perp = \{0\}\Rightarrow T^* \text{ injective}$$ In the finite-dimensional case, we have that $$T \text{ surjective} \iff T^* \text{ injective}$$ In the general infinite-dimensional case, does the same statement hold, or is there a counterexample where $T^*$ is injective but $T$ is not surjective?","['operator-theory', 'functional-analysis', 'real-analysis']"
269107,What is the result of deriving a polygon?,"If you define a polygon - say, for simplicity, a triangle - as a list of functions, defined piecewise, for example: $a(x)=2x$ defined on $[0,1]$ $b(x)=-2x+2$ defined on $[1,2]$ $c(x)=0$ defined on $[0,2]$ What do you get by deriving the functions on their intervals and plotting $a'(x)$, $b'(x)$ and $c'(x)$?
(In this specific case, the result is made of three segments parallel to the x axis, but what is the result of any given polygon?)","['geometry', 'derivatives']"
269109,Factorization of Ideals in Dedekind Domains Proof,"I am trying to understand a proof of the following statement: Let $R$ be a Dedekind ring and let $I$ be an ideal of $R$. $I$ is contained in only a finite number of prime ideals $\mathfrak{p}_1,...,\mathfrak{p}_n$ of $R$ and $I=\mathfrak{p}_1^{a_1}\cdots \mathfrak{p}_n^{a_n}$ for some $a_1,\cdots,a_n \in\mathbb{N}^+$. The proof, which was taken from Janusz's Algebraic Number Fields and modified by me, goes as follows: Consider the ring $S=R/I$. Note that since $R$ is of Krull dimension 1, $S$ is a commutative ring in which every prime ideal is maximal. Therefore every ideal of $S$ contains a product of prime ideals. The prime ideals of $S$ correspond bijectively with the prime ideals of $R$ which contain $I$. Note that there can be only finitely many prime ideals of $S$ and hence only finitely many prime ideals $\mathfrak{p}_1,\cdots,\mathfrak{p}_n$ of $R$ which contain $I$. In particular, there exists $a_1,\cdots, a_n \in \mathbb{N}$ such that $({\mathfrak{p}_1/I})^{a_1}\cdots ({\mathfrak{p}_n/I})^{a_n}=0$. This implies $\mathfrak{p}_1^{a_1}\cdots \mathfrak{p}_n^{a_n}\subseteq I$. Let $\widetilde{R}=R/\mathfrak{p}_1^{a_1}\cdots \mathfrak{p}_n^{a_n}$. Since the ideals $\mathfrak{p}_i$ and $\mathfrak{p}_j$ are maximal for all $i$ and $j$, they are comaximal for all $i\neq j$. Thus by the Chinese remainder theorem we have 
$$
\widetilde{R}\cong R/{\mathfrak{p}_1}^{a_1}\times \cdots \times R/{\mathfrak{p}_n}^{a_n}.
$$
The ideals of $\widetilde{R}$ are of the form $I_1\times \cdots \times I_n$, where $I_k$ is an ideal of $R/{\mathfrak{p}_k}^{a_k}$. Since the ideals of $R/\mathfrak{p}_k^{a_k}$ are all powers of $\mathfrak{p}_k/\mathfrak{p}_k^{a_k}$, the ideals of $\widetilde{R}$ are the image of some product $\mathfrak{p}_1^{b_1}\cdots \mathfrak{p}_n^{b_n}$ for some $b_i \leq a_i$. In  particular, this means $I$ has the same image as some $\mathfrak{p}_1^{c_1}\cdots \mathfrak{p}_n^{c_n}$, where $c_i \leq a_i$ for all $i$. Since both $I$ and $\mathfrak{p}_1^{c_1}\cdots \mathfrak{p}_n^{c_n}$ contain $\mathfrak{p}_1^{a_1}\cdots \mathfrak{p}_n^{a_n}$ and map to the same element ideal of $\widetilde{R}$, we must have $I=\mathfrak{p}_1^{c_1}\cdots \mathfrak{p}_n^{c_n}$. $\square$ The part which I do not understand is the final step: Since both $I$ and $\mathfrak{p}_1^{c_1}\cdots \mathfrak{p}_n^{c_n}$ contain $\mathfrak{p}_1^{a_1}\cdots \mathfrak{p}_n^{a_n}$ and map to the same element ideal of $\widetilde{R}$, we must have $I=\mathfrak{p}_1^{c_1}\cdots \mathfrak{p}_n^{c_n}$. I'm sure the reason is staring me right in the face, but I cannot see it. Question What is the reasoning behind the final step?","['algebraic-number-theory', 'abstract-algebra']"
269112,"How do I find, by the definition of a derivative, the derivative of $\tan x$?","How do I find, by  the definition of a derivative, the derivative of tanx? $$f'(x)=\lim_{\Delta x \to 0}{f(x+\Delta x)-f(x)\over \Delta x}=\lim_{\Delta x \to 0}{\tan(x+\Delta x)-\tan(x)\over \Delta x}=\lim_{\Delta x \to 0}{{\sin(x+\Delta x)\over \cos(x+\Delta x)}-{\sin(x)\over \cos(x)}\over \Delta x}$$ I tried using identities but I always reached something like ${0\over \cos(x+ \Delta x)\cos(x)}$ which is no good... Thanks for any help! P.S. I'm only at the beginning of the derivatives subject, so we need to find the derivative of $tanx$ using definition only.","['trigonometry', 'calculus', 'functions']"
269120,Semisimple objects in abelian categories,"Let $\mathcal A$ be any Grothendieck abelian category and $0 \neq M \in \cal A$ an object.
It is true that $M$ admits a simple subquotient? It is certainly true for $\mathcal A=R-Mod$ since $M$ contains a cyclic module and any (left)ideal is contained in a maximal. Motivation: In the category of modules over a ring $R$ the following are equivalent for an object $M$. 1) $M$ is a (maybe infinite) direct sum of simple modules. 2) Every short exact equence 
$$0 \rightarrow M'\rightarrow M\rightarrow M''\rightarrow 0$$ 
splits. I want to generalize this statement to any abelian category and the above seems crucial for $2) \Rightarrow 1)$. Edit: Hanno Becker informed me, that there are abelian categories without any irreducible objects, see Jeremy Rickards answer to this question . 
I changed my question accordingly.","['representation-theory', 'abstract-algebra', 'category-theory', 'modules', 'abelian-categories']"
269128,Compact maps problem in Lax,"In Functional Analysis of Peter Lax there are the following exercise Show that if $\bf C$ is compact and $\{{\bf M}_n \}$ tends strongly to $\bf M$, then $\bf CM_n$ tends uniformly to $\bf CM$. Assumptions are that ${\bf C}: {\bf X} \rightarrow {\bf X},{\bf M_n}: {\bf X} \rightarrow {\bf X}$ where $\bf X$ is a Banach space I was thinking that one could use that if let $x_i$ be such that
$|({\bf M_i-M})x_i|\ge||{\bf M_i-M}|| - \epsilon $. Then from compactness of $\bf C$ we have that there is a finite sequence $j=1\ldots,n$ of ${\bf C}({\bf M_j-M})x_j$ s.t $\min_j ||{\bf C}({\bf M_j-M})x_j - {\bf C}({\bf M_i-M})x_i||<\epsilon$ for all i. But I dont get anywhere.","['operator-theory', 'convergence-divergence', 'functional-analysis', 'compactness']"
269170,Why is $ab+bc+ac = 0$ in some situation?,"This is originally a Computer Science question, but I ran a equation that is too hard to solve. Here goes. So the problem is quite simple, given positive integers $a$, $b$, $c$, and calculate $\sqrt{a^2+b^2+c^2}$ But here's the problem, if I calculate any of the squares, I will trigger an integer overflow, where the computer have not enough allocated space to save the result. So the problem gives me an additional condition: the difference between the minimum of the three and the bigger other two is perfect squares. That said, if $c$ is the smallest of the three. $b-c$ and $a-c$ will both be perfect squares. And the answer itself is an integer, which means $a^2+b^2+c^2$ is also a perfect square. So, here's what I got so far. assume $c$ is the smallest of the three. let $m=\sqrt{a-c}$, and $n=\sqrt{b-c}$, so $2m^2n^2=2ab-2ac-2bc+2c^2$ and $a^2+b^2+c^2=(a+b-c)^2-2ab+2ac+2bc$ Organize the two, and I am able to get: $(a+b-c)^2-2(a-c)(b-c)=a^2+b^2+c^2$ And the answer to this problem simply output: $a+b-c$, so $2(a-c)(b-c)$ must be zero under the given condition. Here's some sample to test it out. 2, 2, 1   - 3
3, 6, 2   - 7
4, 12, 3  - 13 And the following is wrong, since $\sqrt{a^2+b^2+c^2}$ is not an integer: 2, 5, 1   - 6, which is wrong, should be sqrt(30)
7, 6, 6   - 7, which is wrong, should be 11, here's what I think
          - it violate the clues set by the problem. The problem state
          - the smallest ONE, and the bigger TWO. P.S. I tagged it under elementary number theory , if you think it's better off to be somewhere else, comment below. Need more information? Comment below. Thanks!","['computer-science', 'algebra-precalculus']"
269171,Can a sample space depend on the parameter to be estimated (example: # of cabs in a city),"In our intro statistic lecture the following we said that the following components made up an estimation problem an at most countable space $\mathcal{X}$ of all possible samples we can observe a family $(P_\theta)_{\theta \in \Theta} $ of distributions on $\mathcal{X}$ a function $f:\Theta \rightarrow \mathbb{R}$ that we would like to estimate Then we discussed an example were the aim was to find out how many cabs there are in this city: We assumed that -> all cabs within the city are numbered with numbers from the set $\{1,\ldots,M\}$ -> we observe cabs with numbers $t_1<\ldots<t_m$ The problem I have with this example is that we said that $\mathcal{X}$ is the set of all subsets of size $m$ of $\{1,\ldots,M\}$. What bothers me about that, is that $M$ is a parameter it $\Theta=\mathbb{N}$, which we wish to estimate, so our space $\mathcal{X}$ actually depends on it: Thus we actually have a family $(\mathcal{X}_M)_{M\in \Theta}$ instead of a fixed $\mathcal{X}$. Is that allowed ? I thought in the general definition above that $\mathcal{X}$  shouldn't depend on $\theta$; otherwise it should have been written $(\mathcal{X}_\theta)_{\theta\in \Theta}$.","['statistics', 'definition']"
269172,$\int_{0}^{\pi}\left|\frac{\sin nx}{x}\right|~dx \geq \frac{2}{\pi}(1+\frac{1}{2}+ \cdots +\frac{1}{n})$,Show that  $$\int_{0}^{\pi}\left|\frac{\sin nx}{x}\right|~dx \geqslant \frac{2}{\pi}\left(1+\frac{1}{2}+ \dots +\frac{1}{n}\right)$$ I know $0 \leqslant \left|\sin nx\right| \leqslant 1 $. But with this I can't solve. Please help.,"['inequality', 'integration', 'real-analysis']"
269179,How come $\frac{n!}{n_1!\cdot n_2!\cdot...\cdot n_k!}$ is always an integer? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Division of Factorials For a set of $n$ objects of which $n_1$ are alike and one of a kind, $n_2$ are alike and one of a kind, ... , $n_k$ are alike and one of a kind, such that $n_1+n_2+...+n_k=n$, the number of distinguishable permutations is: $$\frac{n!}{n_1!\cdot n_2!\cdot...\cdot n_k!}$$
How come this is always an integer?",['combinatorics']
269188,Is the maximum-likelihood estimator always biased?,"To avoid answers too complicated for me to understand/to clear notation, I'm describing quickly the setting in which everything takes place: In our intro statistic lecture the following we said that the following components made up an estimation problem an at most countable space $\mathcal{X}$ of all possible samples we can observe a family $(P_\theta)_{\theta \in \Theta} $ of distributions on $\mathcal{X}$ a function $f:\Theta \rightarrow \mathbb{R}$ that we would like to estimate We defined the maximum-likelihood estimator $\hat{\theta}_x$ as maximal $\theta$ that is attained by the function $P_\theta(x)$, if such a maximum exists and the expectancy of any estimator $S$ as $E_\theta S:=\sum_{x\in \mathcal{X}} S(x)_\theta (x)$. Is it then true that $\boldsymbol{\hat{\theta}_x=\sup\{ P_\theta (x) \mid \theta \in \Theta \} }$ ? $\boldsymbol{E_\theta \,\hat{\theta}_x =\hat{\theta}_x}$ ? I think this holds, since $\hat{\theta}_x$ is just a number in the unit interval and the expectancy of a number is that number. This would mean that the ML is always biased, since it doesn't hold that for all $\theta \in \Theta$ we have $E_\theta \,\hat{\theta}_x =f(\theta)$ -- except when $f$ maps everything to $\hat{\theta}_x$ which seems odd.","['statistics', 'probability-theory']"
269202,Convergence of sum of independent random variables.,"Given a sequence $X_i$ of independant variables we denote $S_n$ as $\sum_{i=1}^{n}X_i$. We know that $S_n$ converges in distribtion (weak* convergence). Does that imply that $S_n$ converges almost surely? When $\forall_{i}\ \mathbb{E}X_i = 0$, then, I guess, the sum sequence is a martingale and the convergence comes from definition.","['probability-theory', 'convergence-divergence']"
269207,"Is the set of all polynomials in $\log(x)$ dense in $L^2[0,1]$?","Is $\{(\log(x))^k\mid k=0,1,2,\ldots\}$ dense in $L^2 [0,1]$? That is, is the set of all polynomials of logarithm functions dense in the set of square integrable functions on $[0,1]$?",['real-analysis']
269216,Inverse of random variable,"Let's say we have a random variable $X$ of which the distribution is unknown. Now there are these general rules like $E[X + Y] = E[X] + E[Y]$ etc. But what if we would define $ \quad Y = \dfrac{1}{X} $ and we would be interested in the expected value $E[Y]$ and the variance $Var(Y) = E[(Y-\bar{Y})^2]$? Now, I do realize that $X$ might be zero and therefore it is undefined. But what if we would assume $X \neq 0$? My quick solution was to assume $X$ being a log-normal random variable. But I would prefer something more general. Maybe a power series expansion is possible?","['statistics', 'random-variables']"
269218,"High School Geometry - If $BC$ is the greatest side of $\triangle ABC$, $D$ & $E$ are points on $BC, CA$...","If $BC$ is the greatest side of $\triangle ABC$, and $D$ & $E$ are points on $BC$ & $CA$, respectively, prove that $BC \ge DE$. Clearly, equality holds iff $D$ is on $B$ and $E$ is on $C$. I have tried to prove the inequality comparing $\angle BAC$ and $\angle DEC$. If $\angle DEC \ge \angle BAC,$ then $DC$ hence $BC$ is $\gt DE$. Else, on similar grounds $DE\lt EC$ hence $\lt BC$. Is there something I am missing out. And, most importantly, can someone suggest a more neat version?","['geometry', 'triangles']"
269219,Compact subspaces of the Poset,"On page 172, James Munkres' textbook Topology(2ed), there is a theorem about compact subspaces of the real line: Let $X$ be a simply-ordered set having the least upper bound property. In the order topology, each closed interval in $X$ is compact. My question is whether there is a generalized theorem about a Poset(or a lattice, complete lattice, maybe). Is there some elegant way to define a topology on Poset?",['general-topology']
269228,Order of Operations: What is value of the $6/4*4\;$? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: What is 48÷2(9+3)? My friend asked me value of expression 16/4*4. So what is value of 16/4*4 ? Is it 16 or 1 .
if you solve it right to left it's 1. 
But if you solve it from left to right its value is 16.
So which one is correct. And why?","['arithmetic', 'discrete-mathematics']"
269232,Expectation inequality,"Let $X, Y$ be random variables with $0 \leq X \leq Y$ and $\mathbb E[Y]=1$. Let $t>0$. Does the inequality $$
\mathbb E[e^{tX}] \leq x\, \mathbb E[e^{tY}]+1-x
$$ where $x=\mathbb E[X]$ hold?","['inequality', 'probability']"
269242,"""Dirichlet's theorem"" on pairs of consecutive primes","The number of primes in each of the $\phi(n)$ residue classes relatively prime to $n$ are known to occur with asymptotically equal frequency (following from the proof of the Prime Number Theorem). Does the same result hold on pairs of consecutive primes on the $\phi(n)^2$ pairs of congruence classes? To wit: Consider $\{(2, 3), (3, 5), (5, 7), (7, 11), \ldots\}\pmod n$. Does $(a,b)$ occur with natural density
$$\begin{cases}
1/\phi(n)^2,&\gcd(ab,n)=1\\
0,&\text{otherwise}
\end{cases}
$$
?","['prime-numbers', 'reference-request', 'sieve-theory', 'number-theory']"
269278,An algebraic equation; $ x^n -x =a $,"Let $n\ge 2$ be an integer and $a$ be a real number such that $|a|\le (n-1)n^{-\frac n{n-1}}$. Can we find the real solutions of the algebraic equation
$$
x^n -x =a.
$$",['algebra-precalculus']
269281,Peano Space filling Curve Surjective,"I'm having a little trouble understanding why the peano space filling curve is surjcetive. If we have the usual Hilbert Peano space filling curve $f:[0,1]\rightarrow [0,1]^2$ and we know that $f$ is continuous. Do we have to use the compactness of $[0,1]$? So that the image of $f$ is compact in $\mathbb{R}^2$ and then it is closed. Once we have it is closed and then by the construction of the function $f$ we have that each point in $[0,1]^2$ is a limit point of $f$? so then it is in $f([0,1])$? Is this the right idea? Thanks for any help","['general-topology', 'real-analysis']"
269282,Difference between $u_t + \Delta u = f$ and $u_t - \Delta u = f$?,What is the difference between these 2 equations? Instead of $\Delta$ change it to some general elliptic operator. Do they have the same results? Which one is used for which?,"['functional-analysis', 'partial-differential-equations']"
269295,"Showing $\lim_{n \to \infty} m(E_n) = 0$, assuming $f > 0$ a.e. and $\lim_{n \to \infty} \int_{E_n}f \,dm =0$","Let $f:[0,1] \to \mathbb{R}$ be Lebesgue measurable with $f > 0$ a.e. Suppose that $\{E_n\}$ is a sequence of measurable sets in $[0,1]$ with the property that $\displaystyle \lim_{n \to \infty}\int_{E_n} f \,dm = 0$. Prove that $\displaystyle \lim_{n \to \infty} m(E_n) = 0$. This question is from an old analysis qual I am studying. So far I have tried a proof by contradiction: if $\displaystyle \lim_{n \to \infty} m(E_n) \neq 0$, then there is an $\epsilon > 0$ and a subsequence $\{n_k\}$ so that $m(E_{n_k}) \ge \epsilon$ for all $k$. I am trying to somehow use this subsequence and show $\displaystyle \lim_{k \to \infty}\int_{E_{n_k}} f \,dm \neq 0$, which would give me a contradiction. Another fact I know from my measure theory course is that, for meausurable $E \subseteq [0,1]$, the map $\displaystyle \nu(E) = \int_E f \,dm$ defines a measure on the Lebesgue measurable subsets of $[0,1]$. Will this fact be useful to me?",['measure-theory']
269299,Eigenvalues of a Sturm-Liouville problem,"Consider the Sturm-Liouville problem $$-u''(x) + V(x)u(x) = \lambda u(x)$$ for $u : \mathbb R \rightarrow \mathbb R$, $\lambda \in \mathbb R$. I am looking for a method to find the eigenvalues $\lambda$ which produce solutions $u \in L^2(\mathbb R)$ for various choices of $V$, e.g. $V(x) = c/\cosh^2(Cx)$ or $V(x) = e^x$. Is there a general procedure for doing this? If not, can someone provide suggestions for finding the eigenvalues at least in the two cases I mentioned?",['ordinary-differential-equations']
269307,proving a limit of a function,Let $h:\mathbb R\rightarrow\mathbb R$ a function and $\alpha\in\mathbb R\backslash\{0\}$. I want to proove that if $\lim_{x\rightarrow 0}\frac{h(x)}{x}=c$ then $\lim_{x\rightarrow 0}\frac{h(\alpha x)}{x}=\alpha c$. I've tried to define $\xi(x):=\frac{h(x)}{x}$ and so $\xi(\alpha x)=\frac{h(\alpha x)}{\alpha x}$ what is equivalent to $\alpha\cdot \xi(\alpha x)=\frac{h(\alpha x)}{x}$. So it's $\lim_{x\rightarrow 0}\frac{h(\alpha x)}{x}=\alpha\cdot\lim_{x\rightarrow 0}\xi(\alpha x)$. But now I am stuck. Anybody could help? Thanks a lot!,"['real-analysis', 'analysis']"
269336,How to apply reduction of order to find a 2nd linearly independent solution?,"I have some questions about writing a general solution, $y$, for $y''-y=0$
when $y_1 = e^x$ is a known solution. I do not understand the logic of the method of reduction of order. How do we apply this to find a second, linearly independent solution?",['ordinary-differential-equations']
269337,$\infty - \infty = 0$ ?,"I am given this sequence with square root. $a_n:=\sqrt{n+1000}-\sqrt{n}$. I have read that sequence converges to $0$, if $n \rightarrow \infty$. Then I said, well, it may be because $\sqrt{n}$ goes to $\infty$, and then $\infty - \infty = 0$. Am I right? If I am right, why am I right? I mean, how can something like $\infty - \infty = 0$ happen, since the first $\infty$ which comes from $\sqrt{n+1000}$ is definitely bigger than $\sqrt{n}.$?","['sequences-and-series', 'proof-writing']"
269348,matrix representation of operator,"Vector $\vec v\ $ in basis E = $[\vec e_1 \vec e_2 \ldots \vec e_n]$ $$\vec v = E \ \begin{bmatrix}v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix}$$ Now, operator acts upon it $$A(\vec v) = v_1 A(\vec e_1) + v_2 A(\vec e_2) + \ldots + v_n A(\vec e_n) = [A(\vec e_1) A(\vec e_2) \ldots A(\vec e_n)] \ \begin{bmatrix}v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix}$$ Now, when v is a first standard vector, we get the first column, $A(\vec e_1)$. Everybody says that it is decomposable into sum, like I did for $\vec v$, $$A(e_1) = a_{11} e_1 + a_{21} e_2 + \dots + a_{n1} e_n = \sum a_{i1} e_i = E \vec a_1$$ This is a matrix E by vector (column) $a_1$ multiplication. It produces another vector $\vec {A(\vec e_1)}$). I just wonder what is the column $a_1$? Which matrix it belongs to? Everybody says that the resulting A($e_1$) column must be the first col of the wanted matrix A. So, $a_1$ cannot be part of A also. What is the matrix of columns $[a_1 a_2 ... a_n]$? How do yo call it? Dear, is it the real operator matrix whereas notorious $[A(\vec e_1) A(\vec e_2) \ldots A(\vec e_n)]$ is just A mixed up with the basis vectors? Is it a wrong matrix A then? Elaboration My purpose is to understand the matrix, which represents the operator. I follow the Miami tutorial and it seems that they assume that we must be able to determine the elements $a_{ij}$ by acting with operator A on every basis vector $|i\rangle$ and know the coordinates (or components?) $$\begin{bmatrix}a_{1i}\\a_{2i}\\a_{3i}\end{bmatrix}$$ of the response column vector $|a_i\rangle = A\,|i\rangle$ in the same basis $\begin{bmatrix}|1\rangle |2\rangle |3\rangle  \end{bmatrix} = E$: $$A\,|i\rangle =\begin{bmatrix}|1\rangle |2\rangle  |3\rangle \end{bmatrix} \  \begin{bmatrix}a_{1i}\\a_{2i}\\a_{3i}\end{bmatrix} = E\ \begin{bmatrix}a_{1i}\\a_{2i}\\a_{3i}\end{bmatrix}.$$ If we apply A to all basis vectors in series, that is if we apply A to matrix E, we get $$AE = A \begin{bmatrix}|1\rangle |2\rangle |3\rangle \end{bmatrix} = \begin{bmatrix}|1\rangle |2\rangle |3\rangle \end{bmatrix} \begin{bmatrix}a_{11}&a_{12}&a_{33} \\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33} \end{bmatrix} = E \ \begin{bmatrix}a_{11}&a_{12}&a_{33}\\a_{21}&a_{22}&a_{23} \\a_{31}&a_{32}&a_{33} \end{bmatrix}. $$ Multiplying by $E^{-1}$, we get $$E^{-1}AE = \begin{bmatrix}a_{11}&a_{12}&a_{33}\\a_{21}&a_{22}&a_{23} \\a_{31}&a_{32}&a_{33} \end{bmatrix} = [A]$$ I have just introduced the shortcut $[A] = \begin{bmatrix}a_{11}&a_{12}&a_{33}\\a_{21}&a_{22}&a_{23} \\a_{31}&a_{32}&a_{33} \end{bmatrix}$ Now, any vector $|v\rangle = E\ \begin{bmatrix}v_1 \\ v_2 \\ v_3 \end{bmatrix} = E\ [v] $ where $[v] = \begin{bmatrix}v_1 \\ v_2 \\ v_3 \end{bmatrix}$ is the vector of coordinates (or components?) is translated to $|u\rangle = E\,[u] = A \,|v\rangle = A\,E\,[v] $ by the operator A. Therefore, the coordinates of new vector, $$[u] = E^{-1}AE[v] = [A]\,[v] $$ I have got $E^{-1}AE = [A]$ instead of get $A = [A]$ expected.  It seems that Miami tutorial treats $[A]$ as the matrix representation of the operator. My question is about the relationship between matrix of A and obtained matrix $[A]$. I see that $E^{-1}AE = A$ in case of standard basis, E = I. Should I compute the matrix A in standard basis and then translate it into the sought matrix of the operator A? Which of the matrices, $A$ or $[A] = E^{-1}AE$ is the operator matrix and which is the operator in the standard basis? Why I cannot find tutorial which says that I must use standard basis to look for the matrix of my operator? Quantum mechanics How is this approach related with Quantum mechanics , who use orthonormal bases, so that operator O elements are $o_{ij} = \langle i | O | j \rangle\ $? I see how similar this expression is to our $E^{-1}AE$. The inner product with $\langle i|$ gives i-th component of $O|j\rangle$ in case of orthonormal $|i\rangle$ and $|j\rangle$, as it is in quantum mechanics. This is not true in the general case of $E^{-1}AE$. I do not understand what is computed with $E^{-1}AE$. If $\langle i | O | j \rangle\ $ computes i-th component of O-transformed j-th basis vector then it is a number, the element of sought matrix. But what is $E^{-1}AE$? How do I find the elements of this matrix?","['matrices', 'terminology']"
269352,When to use Frobenius method,"Am I correct in believing Frobenius' method is simply a general case of a power series solution? For instance, if the Differential Equation has a regular singular point, would you be forced to use Frobenius' method instead of a regular power series?","['ordinary-differential-equations', 'sequences-and-series']"
269353,isomorphism of Dedekind complete ordered fields,"In the last chapter of Spivak's Calculus, there is a proof that complete ordered fields are unique up to isomorphism. I find the first steps in it somewhat suspicious. Specifically, I believe he is treating numbers as rational numbers which are at best isomorphic to them. (Here $\mathbb{R}$ is the field of Dedekind cuts. Also: Spivak is going to denote addition in $F$ with $\oplus$, in contrast to addition in $\mathbb{R}$, denoted by $+$.) Verbatim: Theorem : If $F$ is a complete ordered field, then $F$ is isomorphic to $\mathbb{R}$. Proof : Since two fields are defined to be isomorphic if there is an isomorphism between them, we must actually construct a function $f$ from $\mathbb{R}$ to $F$ which is an isomorphism. We begin by defining $f$ on the integers as follows: $$f(0) = \mathbf{0}$$
  $$f(n) = \underbrace{ \mathbf{1} \oplus \text{ } ... \text{ } \oplus \mathbf{1}}_{n \text{ times}} \text{, }\text{   for $n > 0$}$$
  $$f(n) = -( \underbrace{ \mathbf{1} \oplus \text{ } ... \text{ } \oplus \mathbf{1}}_{|n| \text{ times}}) \text{, }\text{   for $n < 0$.}$$ It is easy to check that $$f(m + n) = f(m) \oplus f(n) $$
  $$f(m \cdot n) = f(m) \odot f(n) $$ for all integers $m$ and $n$, and it is convenient to denote $f(n)$ by $\bf{n}$. We then >define $f$ on the rational numbers by $$f(\frac{m}{n}) = \bf{\frac{m}{n}} = \bf{m \odot n^{-1}}$$ (notice that the $n$-fold sum $\mathbf{1} \oplus \text{ } ... \text{ } \oplus \mathbf{1} \neq \bf{0}$ if $n>0$, since $F$ is an ordered field). This definition makes sense because if $\frac{m}{n} = \frac{k}{l}$, then $ml = nk$, so $\bf{m} \odot \bf{l} = \bf{k} \odot \bf{n}$, so $\bf{m} \odot \bf{n^{-1}} = \bf{k} \odot \bf{l ^ {-1}}.$ It is easy to check that $$f(r_1 + r_2) = f(r_1) \oplus f(r_2)$$
  $$f(r_1 \cdot r_2) = f(r_1) \odot f(r_2)$$ for all rational numbers $r_1$ and $r_2$ and that $f(r_1) \prec f(r_2)$ if $r_1 < r_2$. My problem with this is - well, actually, I have two problems with this. The first one is, \begin{align} \text{what does  } \underbrace{ \mathbf{1} \oplus \text{ } ... \text{ } \oplus \mathbf{1}}_{n \text{ times}} \text{  mean?}
\end{align} I get that you can say, ""look, $1x = x$, $2x = x+x$, $3x = (x+x)+x$, and so on."" But hold it, I say: ""and so on"" sounds like induction. And the $n$ we referred to isn't really an integer (much less a positive integer in $\mathbb{N}$), but rather a member of $\mathbb{R}$. So, how can we induct on its value? My other question needs still more introduction! If $z$ is an ""integer"" $\{t \in \mathbb{Q}: t<n\} \in \mathbb{R}$, we say $z \in \mathbb{Z_R}$. By $\mathrm{quot}_{\mathbb{R}}$, we will denote the set of products $\{m \cdot n^{-1} \in \mathbb{R}: m, n \in \mathbb{Z_R} \land n \neq 0 \}$. Finally, put $\Theta_x = \{f(y) \in F: y < x, y \in \mathrm{quot_\mathbb{R}} \}$.  In these terms, Spivak subsequently claims things like ""Given $x, y \in \mathbb{R}$, it is clear that $x<y \implies \Theta_x \subset \Theta_y$."" (He really does say ""clear"". This would be clear if $\mathrm{quot_\mathbb{R}}$ were equal to $\mathbb{Q}$; then it would just require us to say, ""if $x$ and $y$ are Dedekind cuts, then the set $X$ of rationals contained in $x$ is a subset of those rationals $Y$ contained in $y$; thus, $f(X) \subset f(Y)$"". But you can't freakin' do that!) His basic goal is to say that $\phi: x \rightarrow \sup \Theta_x$ is an isomorphism (he claims that $\phi$ agrees with $f$ wherever both are defined, i.e. on $\mathrm{quot}_{\mathbb{R}}$). So, this has all left me wondering, \begin{align} \text{how do I navigate his multiple meanings for rationals?} \end{align} I mean, I really don't know how to prove any of his claims without playing fast and loose with how $\mathbb{N}, \mathbb{Q}$ and $\mathrm{quot}_{\mathbb{R}}$ relate. Can somebody give me some ideas/hints? (A little note here: when I think of $\mathbb{N}$, formally I think of the minimal successor set, satisfying the Peano axioms. I'm willing to accept $\mathbb{N}$, $\mathbb{Z}$ and $\mathbb{Q}$ as god-given, but $\{t \in \mathbb{Q}: t<n\} \in \mathbb{R}$ is very different from $n \in \mathbb{N}$. I do know the obvious isomorphism between them.)","['ordered-fields', 'field-theory', 'analysis']"
269363,Proof: $\lim_{n\to\infty} (1-\frac{1}{n})^{-n} = e$,"If $e:=\lim_{n\to\infty} (1 + \frac{1}{n})^n$, prove that $$ \lim_{n\to\infty} \left(1-\frac{1}{n}\right)^{-n} = e $$
  without using the property that says: if $\lim_{n\to\infty} a_n = \infty$, $\lim_{n\to\infty} x_n = x$, then $\lim{n\to\infty}(1+\frac{x_n}{a_n})^{a_n} = e^x$... I've tried rewriting $1-\frac{1}{n}$, and operating $\lim_{n\to\infty}(1-\frac{1}{n})^n = 1 / \lim_{n\to\infty}(1+\frac{1}{n})^n $ but I couldn't prove it. Any hint? Thanks in advance.","['real-analysis', 'limits']"
269384,Help understanding Algebraic Geometry,"I while ago I started reading Hartshorne's Algebraic Geometry and it almost immediately  felt like I hit a brick wall. I have some experience with category theory and abstract algebra but not with algebraic or projective geometry. I'm wondering if any of you out there know of any articles, blog posts or whatever offering a light, intuitive and geometric introduction the subject. I really wanna get back to Hartshorne's book cause I am very curious about the categorical description. I have provided the first few problems I ran into to give you an idea of where I come from. Of course if you can answer any of the questions that would be welcome. First of all I'm having trouble grasping the very basic notion of a continuous function with respect to the Zariski topology. I don't which they are or know how to conceptualize them. I get how the rational polynomials work but I don't know if they are a subclass of the continuous functions or if they exhaust them. Any help in this regard is welcome. Further I couldn't really get the projective part. I guess part of my problem comes from the fact that this is a set theoretic quotient of an algebra, which is then interpreted as an algebraic object. At least that's what I read, might be wrong. 
I seem to get lost during this transition and I don't know how to relate, are there any universal properties involved, whats the big picture? Thanks in Advance Edit1:
Also, where is the hyperbolic geometry in all this? Edit2: I want to express my gratitude towards all the people who have takes their time to give me recommendations and sympathy. Thank you!","['algebraic-geometry', 'reference-request', 'projective-geometry']"
269386,Fundamental group of multiplicative group in Zariski topology,"What is the fundamental group of the multiplicative group of the complex numbers $\mathbb{G}_m(\mathbb{C})$ with respect to the Zariski topology. More precisely, what are the homotopy classes of continuous loops $f:[0,1]\rightarrow \mathbb{G}_m(\mathbb{C})$ with a fixed base point?","['general-topology', 'algebraic-geometry', 'algebraic-topology']"
269387,Some basic questions about Stochastic Calculus,"I have a transition function for a Markov process $X_t$.  I want to find a density function for the stochastic process $Y_t := \int_0^t X_s \,ds$.  Some questions about this: Is this the same as the transition function for the stochastic process $Y'_t := \int_0^t 1 \,dX_s$?  If not, what is the difference in real-world meaning between $Y_t$ and $Y'_t$? In normal calculus, one typically integrates by invoking the Fundamental Theorem and taking antiderivatives.  Is there a Fundamental Theorem analog in stochastic calculus that might be useful here? My best lead so far is to use the Feynman-Kac formula on $X_t$ to find the characteristic function of the density function of $Y_t$, then invert it.  The transition function for $X_t$ is very long and ugly, so this would be hugely complicated to execute.  I've got Mathematica as my integration calculator, so I can handle some amount of ugliness, but this strategy was too complicated for Mathematica to stomach, and it froze up.  Is there a known simpler method? Thanks - advice on any of these three questions is appreciated.","['stochastic-calculus', 'stochastic-processes', 'stochastic-integrals', 'probability']"
269392,is it possible to construct a continuous bijective map from $\mathbb{R}$ to $\mathbb{R^{2}}$,"is it possible to construct a continuous bijective map from $\mathbb{R}$ to $\mathbb{R^{2}}$. if it is, please give an example.If not, how to prove?","['general-topology', 'analysis']"
269396,Largest eigenvalue of a $A^T A$ matrix?,"I have a large real matrix A of size $40K\times 400K$, is there an efficient way to calculate the largest eigenvalue of $A^T A$ (size $400K\times 400K$)? Thanks.","['matrices', 'linear-algebra']"
269402,How should I prove the duality?,"Rudin asked ( Real Complex Analysis, First edition, Chapter 6, Problem 4 ): Suppose $1\le p\le \infty$, and $q$ is the exponent conjugate to $p$. Suppose $u$ is a $\sigma$-finite measure and $g$ is a measurable function such that $fg\in L^{1}(\mu)$ for every $f\in L^{p}(\mu)$. Prove that then $g\in L^{q}(\mu)$. I am being troubled with the fact that $|g|_{q}$ might be unbounded if we select wierd enough $f$. Holder inequality only gives us $$|fg|_{1}\le |f|_{p}|g|_{q}\leftrightarrow |g|_{q}\ge \frac{|fg|_{1}}{|f|_{p}}$$All  the constructions I know proving $g\in L^{q}$ starts by assuming $f\rightarrow fg$ is a bounded linear operator，so I cannot use circular reasoning at here. It suffice to prove the statement for finite measure spaces and simple functions. So emulating Rudin we can assume $|g|=\alpha g$, where $|\alpha|=1$ and $\alpha$ is measurable. Let $E_{n}=x:|g(x)|\le n$ and let $f=\chi_{E_{n}}\alpha g^{q-1}$. Then we have $$\int_{E_{n}}|g|^{q}d\mu=\int_{X}|fg|d\mu\le K_{n}$$ for some $K_{n}<\infty$. But this constant obviously shift with the $n$ I choose, hence probably does not have a finite upper bound (for example $K_{n}=n$). And I got stuck. In problem 6, Rudin now ask: Suppose $1<p<\infty$, and prove that $L^{q}(\mu)$ is the dual space of $L^{p}(\mu)$ even if $\mu$ is not $\sigma$-finite. I keep thinking about it but do not know what is the best way to prove it.","['lp-spaces', 'real-analysis']"
269411,How to be sure that the $k$th largest singular value is at least 1 of a matrix containing a k-by-k identity,"In section 8.4 of the report of ID software , it says that the $k$th largest singular value of a $k \times n$ matrix $P$ is at least 1 if some subset of its columns makes up a $k\times k$ identity. I tried to figure it out but couldn't be sure of that. Any ideas on how to prove it?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
269432,"Solution of the Wave Equation, the not so simple direction","I read that the solution of the one-dimensional wave equation
$$
 \frac{1}{c^2} \frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2}
$$
are exactly the function of the form
$$
 u(t,x) = f(x + ct) + g(x - ct)
$$
with $f$ and $g$ being twice differentiable. To show that every such function is a solution is simply, but what about the other direction, how can I show that if I have a solution $u$ then it must have the form as a sum of two functions f and g? In my textbooks I just find the simple direction, but not the other?","['functional-analysis', 'partial-differential-equations', 'analysis']"
