question_id,title,body,tags
703687,"Solve $\int\ e^x \sin(9x)\,dx$ using integration by parts","I have this Integration by Parts question that I can't seem to find an answer to. The question is: $$\int\ e^x 
\sin(9x)\,dx$$ I used u-substitution: $$u=e^x,du=e^x\,dx$$
$$dv=\sin(9x)\,dx, v=-\frac{1}{9}\cos(9x)$$ Then I got: $$-\frac{1}{9}e^x\cos(9x)+\frac{1}{9}\int\ e^x\cos(9x)\,dx$$ After a second integration I used: $$u=e^x, du=e^x\,dx$$ $$dv=\cos(9x)\,dx, v=\frac{1}{9}\sin(9x)$$ Furthermore, $$\int\ e^x\sin(9x)dx=-\frac{1}{9}\ e^x\cos(9x)+\frac{1}{9}\left(\frac{1}{9}\ e^x\sin(9x)-\frac{1}{9}\int\ e^x\sin(9x)\,dx\right)$$ $$\int\ e^x\sin(9x)dx=-\frac{1}{9}\ e^x\cos(9x)+\frac{1}{81}\ e^x\sin(9x)-\frac{1}{81}\int\ e^x\sin(9x)\,dx$$ I'm stuck and I'm not sure exactly what to do after this. Any help would be very grateful..thanks!","['calculus', 'integration', 'indefinite-integrals']"
703695,Crazy calculation for winding numbers,"Find the winding number around $z=-i, z=-1, z=0$ in the following figure. The purpose of this exercise is to complete a complex integral with singularities at the stated points. My attempt is that the winding number around $z=0$ is $1$, and that the winding numbers around $z=-i$ is zero, and $z=-1$ is $-1$. The reason it is zero for $z=-i$ is because the curve winds around $-i$ clockwise once, and then winds around it counterclockwise once. The reason it is $-1$ for $z=-1$ is because the curve winds around that point clockwise once. My shakiest solution is the winding number for $z=-1$. For some reason, I have a competing thought that the winding number is in fact zero. In my head, I figure I'm free to ""move"" the knot around $z=-i$ and ""unfold"" it to get a figure that does not wind around $z=-1$ at all. Informally, I think of the curve as a rope where the intersections are actually a part of the rope lying on top of another part. I hope that is not too unclear.",['complex-analysis']
703714,Rotating a table so that at least two name cards are correct,"Fifteen chairs are evenly placed around a circular table. On the table are the name cards of fifteen guests. After the guests sit down, it turns out that none of them is sitting in front of their own card. Prove that the table can be rotated so that at least 2 guests are seated in front of their own name card. The extreme case is having swapped names in pairs i.e. 1 sits where 2 should sit and vice versa, 
3 sits where 4 should sit and vice versa,... Because no rotation will get two correctly seated, unless their number is odd from pigeon. 
Missing something? Is this really the extreme case?","['pigeonhole-principle', 'combinatorics']"
703718,Show isometry of flow on a compact Riemannian manifold where the vector field is Killing,"Let $(M,g)$ be a Riemannian manifold, $\nabla$ the Levi-Civita connection of $g$. A vector filed $V$ on $M$ is called a Killing field if for every $p\in M$ and every $X,Y\in T_p M$,
$$
g(\nabla_X V, Y)+g(X,\nabla_Y V)=0
$$
Show that if $(M,g)$ is a compact Riemannian manifold, and $V$ is a Killing field, then the flow $\Psi_t$ of $V$ is an isometry for each $t$. Now to get us started,
First we shall show that the rate of change of the metric $g_{\Psi_t(x)}(D_x\Psi_t X, D_x\Psi_t Y)$ with $t$ is zero at $t=0$ for any $X$ and $Y$ in $T_p M$. 
Then use the local group property of the flow. Any help is appreciated. First we claim that
$$
\nabla_{Xg} (X_i,X_j)=X(g(X_i,X_j))-([X,X_i],X_j)-([X,X_j],X_i)=X(g(X_i,X_j)),\dagger
$$ Step 1 Define a connection for differentiating convector fields (1-forms). The derivative $\nabla_Y\omega$ should satisfy
$$
Y(\omega(X))=(\nabla_Y\omega)(X)+\omega(\nabla_Y X).
$$
Hence, 
$$
(\nabla_Y\omega)(X) := Y(\omega(X))-\omega(\nabla_Y X).\qquad (1)
$$
Apply (1), we have
    \begin{align*}
		(\nabla_X g)(X_i, X_j)&=[Y,g](X_i,X_j)\\
	&=Y(g(X_i,X_j))-g(\nabla_Y(X_i,X_j))\\
		&=Y(g(X_i,X_j))-g(\nabla_Y X_i,X_j)-g(X_i,\nabla_Y X_j)
	\end{align*}","['semi-riemannian-geometry', 'riemannian-geometry', 'differential-geometry']"
703755,probability of the sum of i.i.d. RV with uniform distribution being $>x$,"I am solving a question for applied stochastic processes homework and I am stuck on this part: Let $X_1,X_2,\cdots, X_n$ be independent identically distributed random variables with uniform distribution on $[0,1]$. Let $0<x<1$. 
I need to find $$\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x).$$ I think that the answer should be $\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x)=\frac{x}{n}$,  for reasons of symmetry , since we have $n$ RV then each of them in average should be less then $\frac{x}{n}$  so that the total sum is less then $x$. Is my guess correct? And how can I state it in more mathematical basis?","['probability', 'random-variables', 'conditional-probability']"
703798,Proof this curious trigonometric identity,"Proof that $$\cos^2{10^\circ} + \cos^2{50^\circ} - \sin{40^\circ}\sin{80^\circ} = \frac{3}{4}$$ I notice that $10^\circ + 80^\circ = 90^\circ$, and $50^\circ +40^\circ = 90^\circ$. I tried doing some manipulation but my efforts were futile. Any hints?",['trigonometry']
703800,Nonexistence of a functor from $Group$ to $Set$ taking each group to its set of automorphism,"I am struggling with this question: show that there does not exist functor from $Group$ to $Set$ taking each group to its set of automorphisms. I have thought about it for a while now, not having any insight. There is a thread on MSE showing the nonexistence of a functor taking each $\mathcal{G}$ in $Group$ to Aut( $\mathcal{G}$ ) in $Group$ , which is relevant but not of help. Edit: I know that for some 1-1 homomorphism $f:G\longrightarrow H$ , there is an automorphism $A$ on $G$ such that there is more than one automorphisms $g_1$ and $g_2$ on $H$ , for which $g_1\circ f=g_2\circ f=f\circ A$ . On the other hand, for  some 1-1 homomorphism $f:G\longrightarrow H$ , there is an automorphism $A$ on $G$ , such that there is no automorphism $g$ on $H$ for which $g\circ f=f\circ A$ This rules out one way of defining the functor, but I am not sure how it helps in the general case.","['category-theory', 'group-theory']"
703816,"If T is a bounded linear map, what does $(T^\ast T)^{1/2}$ mean?","If $T: H_1 \rightarrow H_2$ is a continuous linear map between two Hilbert spaces, $H_1$ and $H_2$, what does the notation $(T^\ast T)^{1/2}$ mean?  The book I'm reading defines $|T|$ to mean $(T^\ast T)^{1/2}$. ($T^\ast$ is of course the adjoint)","['functional-analysis', 'analysis']"
703817,The Probabilistic Pigeon Hole Principle,"Many people are aware of the Pigeonhole Principle: If we distribute $n+1$ pigeons into $n$ pigeonholes, at least one hole will contain at least two pigeons. However, much fewer are aware of the $\bf{Probabilistic}$ Pigeonhole Principle, which answers the question, 'How many do we usually need?' Those familiar with the famous birthday problem might have good intuition for this. Let's recall the birthday problem: How many (randomly chosen) people do you need in a room for the probability that some two share a birthday to be more than 1/2? Wikipedia has a nice article on this here . (If this is the first time you've heard the question, it's a great one to think about.) For most  people, the answer is quite a surprise, as it is only 23. Returning to the general problem, if we randomly distribute $n^{1/2}$ pigeons into $n$ pigeonholes, the probability of some overlap approaches 1, as $n \to \infty$. Let's state that more precisely: Take any $\epsilon > 0.$ Randomly place $\lfloor n^{1/2 + \epsilon} \rfloor$ pigeons into $n$ holes. (Each is placed independently of the others and with uniform distribution.) Let $\Pr{(n,\epsilon)}$ be the probability that at least two pigeons are placed in the same hole. Then we have, 
$$\lim_{n \to \infty} \Pr{(n,\epsilon)} = 1.$$ 
I'm having some trouble proving this, and I also haven't found a proof online. In any case, the proof itself should not be difficult. Here is what I have so far: Let $m = \lfloor n^{1/2 + \epsilon} \rfloor$. Then we have, $$\Pr{(n,\epsilon)} = 1 - \frac{(n)_m}{n^m},$$ where $(n)_m$ is the falling factorial. i.e. $(n)_m = n(n-1)\times \ldots \times (n-(m-1))$. I tried applying Stirling's formula but after doing some algebraic manipulatoin, I couldn't quite finish the proof. (I also crunched some numbers with Python, providing some numerical evidence.) So, what would be a proof of this? Here is an extra note on my background to the question. I first became acquainted with it at a math conference when two people, (Piotr Przytycki and another person, whose name I don't recall), gave a short introduction to random (finitely presented) groups. The above principle is used to prove part of a basic result. You can read it in the literature on the bottom of page 31 of the excellent 2005 survey article (on random groups) which Yann Ollivier wrote.","['pigeonhole-principle', 'probability', 'limits']"
703825,combinatorics questions from studying,"Hi all I need some assistance How many 5-digit briefcase combinations contain 1.Two pairs of distinct digits and 1 other distinct digit. (e.g 12215)
I wasn't sure on which approach was correct. 10 * 9 * 8 (because there are three distinct digits) or 10C2 * 5C2* 3C2 * 8 (because you have to take into account how the doubles can be orientated) 2.A pair and three other distinct digits. (e.g 27421)
same issue as above 10*9*8*7 or (5C2*10) * 9 * 8 * 7 lastly How many ways are there to pick a collection of 12 coins from piles of pennies, nickels, dimes, quarters, and half-dollars? Base on the following condition:
1.There are only 10 coins in each pile. 16C4 - 5^2 because it's the total minus how many ways I can get from the 11th coin and the 12th coin. = 1795 2.There are only 10 coins in each pile and the pick must have at least one penny and two nickels? 1795 - 13C4(?)
my logic is that it's because 12-3+4 C 4 but I'm not sure if I have to set it to 12 or 10. Saw a variation on the problem: stating that it original had 10 and now there 8 piles 1 Penny, and 2 nickels.
but the answer was 11C4 - 1. (how is this possible?)
Thank you!","['discrete-mathematics', 'combinatorics']"
703866,Big Oh and Big Theta relations confirmation,"I just want to confirm these statements, I know that Big O, and Big theta, are partial order and equivalence relations respectively, all positive integers, but not sure on these restrictions. $f:N \rightarrow R^+$ where $f$ R $g$ is and only if $f(n) = O(g(n))$
This is still a PO (Partial Order) where $f$ R $g$ is and only if $f(n) = Θ(g(n))$ 
This is still a ER (Equivalence Relation) Thank you!","['asymptotics', 'discrete-mathematics']"
703876,Fourier transform of $\operatorname{erfc}^2\left|x\right|$,"Could you please help me to find the Fourier transform of
$$f(x)=\operatorname{erfc}^2\left|x\right|,$$
where $\operatorname{erfc}z$ denotes the the complementary error function .","['special-functions', 'fourier-analysis', 'calculus', 'integration', 'error-function']"
703895,Find $n$ satisfying the equation $[\log_21]+[\log_22]+[\log_23]+\dots[\log_2n]=1538 $,"If $[\cdot]$ denotes greatest integer function, then what is the value of natural number $n$ satisfying the equation $$[\log_21]+[\log_22]+[\log_23]+\dots[\log_2n]=1538 ?$$ My try: Note that 
$$0+1\times2+2\times2^2+3\times2^3+4\times2^4+5\times2^5+6\times2^6+7\times2^7=1538$$ But the answer is $$n=\sum_{i=0}^72^i=255.$$ How is it derived?","['logarithms', 'algebra-precalculus']"
703923,Integral $ \int_0^1 \frac{\ln \ln (1/x)}{1+x^{2p}} dx$...Definite Integral,"Calculate
$$
I_1:=\int_0^1 \frac{\ln \ln (1/x)}{1+x^{2p}} dx, \ p \geq 1.
$$
I am trying to solve this integral $I_1$.  I know how to solve a related integral $I_2$
$$
I_2:=\int_0^1 \frac{\ln \ln (1/x)}{1+x^2} dx=\frac{\pi}{4}\bigg(2\ln 2 +3\ln \pi-4\ln\Gamma\big(\frac{1}{4}\big) \bigg)
$$
but I am not sure how to use that result here. In this case I just use the substitution $x=e^{-\xi}$ and than use a series expansion.  The result is
$$
I_2=\int_0^\infty \frac{\xi^s e^{-\xi}}{1+e^{-2\xi}} d\xi=\sum_{n=0}^\infty (-1)^n \frac{\Gamma(s+1)}{(2n+1)^{s+1}}=\Gamma(s+1)L(s+1,\chi_4)
$$
where L is the Dirichlet L-Function where $\chi_4$ is the unique non-principal character.  This result is further simplified but takes some work.  I am interested in the general case above, $I_1$ Thanks","['special-functions', 'integration', 'definite-integrals', 'real-analysis', 'contour-integration']"
703925,"Gram-Charlier expansion, option price, higher derivative and integration by parts","I am currently reading a finance paper of Backus et al. (2004), called 'Accounting for biases in Black-Scholes'. To explain an abnormality called 'volatility smirk' that can be found in option prices, the authors use a Gram-charlier expansion of normal density whose function is defined as $$
f(w)=\left(1-\frac{\gamma_{1}}{3!}D^{3}+\frac{\gamma_{2}}{4!}D^{4}\right)\phi(w),
$$
where $\gamma_{1}$ is skewness of the density, $\gamma_{2}$ is kurtosis of the density, $\phi(w)=(2\pi)^{1/2}\exp(-w^{2}/2)$ and $w$ stands for the one-period log-return $\log S_{t+1}-\log S_{t}$. As you may already know, a price of European call option $C(S(t),K,t,\tau)$ with underlying price $S(t)$, stirke price $K$, current time $t$ and time to maturity $\tau$ can be defined as $$
C(S,K,\tau)=e^{-r\tau}E(S(t+\tau)-K)^{+} \\
= e^{-r\tau}\int_{\log(K/S(t))}^{\infty}(S(t)e^{w}-K)p(w)dw,
$$
where $p$ is the probability density function for the underlying asset price which is random. This paper says that given the distribution $f$ above, the integral part of call price equation becomes
$$
\int_{\log(K/S(t))}^{\infty}(S(t)e^{w}-K)f(w)dw=\int_{w^{*}}^{\infty}(S(t)e^{\mu+\sigma w}-K)\phi(w)dw \\
-\frac{\gamma_{1}}{3!}\int_{w^{*}}^{\infty}(S(t)e^{\mu+\sigma w}-K)\phi^{'''}(w)dw \\
+\frac{\gamma_{2}}{4!}\int_{w^{*}}^{\infty}(S(t)e^{\mu+\sigma w}-K)\phi^{(4)}(w)dw \\
\equiv I_{1}-\frac{\gamma_{1}}{3!}I_{2}+\frac{\gamma_{1}}{4!}I_{3},
$$
where $w^{*}=\log(K/S_{t}-\mu)/\sigma$, $\mu$ is the expected rate of return, and $\sigma$ is the volatility of underlying asset price. My question is about the derivation of $I_{3}$. In this paper, authors say that
$$
I_{3}=\sigma K\phi(w^{*})[(w^{*})^{2}-1+\sigma w^{*}+\sigma^{2}]+\sigma^{4}I_{1}+\sigma^{4}K\Phi(-w^{*}),
$$
where $\Phi$ is the cumulative density function for $\phi$. It is mentioned that repeated application of integration by parts and a property of derivatives of the normal density $\lim_{x\rightarrow\infty}e^{x}\phi^{(n)}(x)=0$ are used for this derivation. Now I can derive all the other terms, but I still cannot find where the minus one in the middle comes from. I would be really appreciated if someone could tell me where it comes from. The original paper can be found at http://faculty.baruch.cuny.edu/lwu/papers/bias.pdf . This question is related to the proof of proposition 1, which can be found on page 23 and 24.","['probability-distributions', 'integration', 'derivatives']"
703956,Construct a rational matrix $A$ s.t. $A^m = I$,"Let $K$ be a field of either $\mathbb{C}$, $\mathbb{R}$ or $\mathbb{Q}$, Let $V$ be a $n$ dimensional vector space over $K$. I want to construct a matrix $A \in GL(V)$ s.t. $A^m = I$ for some $m$ and $A^k \neq I$ for $ 0 < k < m$ (In other words, I want to construct an element $g$ of a finite group that has order $m$ and represent it in $GL(V)$) If $K = \mathbb{C}$, I can construct $A$ as a diagonal matrix with values from the unity of $\mathbb{C}$, i.e. $\{ z \in \mathbb{C}: z^m = 1 \}$
then, I will get $A^m = I~~~\forall m \in \mathbb{N}$ If $K = \mathbb{R}$, I can construct $A$ as a matrix with block like: $
\begin{bmatrix}
R_m & 0 \\
0 & I_{n-2} 
\end{bmatrix}
$ where $R_m = \begin{bmatrix}
\cos ( \frac{2 \pi}{m} ) & -\sin( \frac{2 \pi}{m} ) \\
\sin ( \frac{2 \pi}{m} ) & \cos( \frac{2 \pi}{m} ) \\
\end{bmatrix}
$ Then, I can also get $A^m = I~~~\forall m \in \mathbb{N}$ However, if $K = \mathbb{Q}$, the problem is different, I don't think I can construct $A$ for every $m$. If I think the problem as a cyclic subgroup $C_m$ of symmetric group $S_n$, and then I can represent the element of $C_n$ by permuting the rows of a identity matrix, e.g. For $n=3$, let $A = \begin{bmatrix}
0 & 0 & 1\\
1 & 0 & 0\\
0 & 1 & 0 
\end{bmatrix}$, then $A^3 = I$, but $A^k \neq I$ for $0 < k < 3$ I can do the same thing for all $m \leq n$ by fixing $n-m$ rows of the identity matrix. How about if $m > n$? By adding odd numbers of minus sign to the rows of the identity matrix, like: For $n=3, m=6$, let $A = \begin{bmatrix}
0 & 0 & -1\\
1 & 0 & 0\\
0 & 1 & 0 
\end{bmatrix}$, then $A^6 = I$, but $A^k \neq I$ for $0 < k < 6$ I think I can construct up to $m \leq 2n$ by using the above method. (But I think some $m$ is missed, like $m=5$ for $n=3$) Is it possible to construct $A$ for $m > 2n$? (In other words, is there any faithful linear representation of the cyclic group $C_m$, $m > 2n$ on $GL(n,\mathbb{Q})$?) I know that there is a bound of the order of an element $h$ from $S_n$ by Landau's function $g(n)$.
By permuting the rows of an identity matrix and adding sign, the maximum order I can represent should be bounded by $2g(n)$, right? For $m$ between $n < m \leq 2g(n)$, are there any positive integer $m$ that I cannot construct $A$ s.t. $A^m = I$ and $A^k \neq I$ for $0 < k < m$? What are they?","['linear-algebra', 'representation-theory']"
703957,"How is a set of the form $\{\emptyset,\{\emptyset\}\}$ defined?","My textbook ""Introduction to Set Theory"" mentions the following set $$\{\emptyset,\{\emptyset\}\}$$ This confuses me. Is it possible that $\emptyset$ be an element of a set? I thought only sets of the form $\{\{\dots\{\emptyset\}\dots\}\}$ were allowed to be elements of other sets. By what I've understood until now, $\emptyset$ is not a member of the set $\{a,b,c\}$, but is a member of $\{\emptyset,a,b,c\}$. Is this correct?",['elementary-set-theory']
703962,Algorithms for factoring multivariate polynomials,"I am wondering if there are any algorithms to factor polynomials in multiple variables, when you know that the factors are other polynomials with rational or integer coefficients. I know you have the rational root theorem, which helps out a lot, but it isn't always obvious how to apply this. Suppose we have the expression
$$ 2y^6 - 5x^6 + x^5y^5 - 10xy $$ (I deliberately choose factors with x and y in high powers, to avoid the solutions being solving by completing the square, Cardano's formula, or Ferrari's formula) This case might be doable: the powers in the terms suggest terms of $x^5$ and $y^5$ and $x$ and $y$, so with a little inspection one might expect the factorization to be of the form $(ax^5+by)(cy^5+dx)$. The term $x^5y^5$ suggests $a=c=1$ and from there it's almost trivial (you can use the rational root theorem, but I don't think that is even necessary). It seems to be doable in this case, which makes it plausible that there is an algorithm who does something like this. Also, I was wondering about another specific case, in just one variable:
$$ (x - a)(x - b)(x - c) $$ With $a, b, c$ integers with a very large absolute value. You can't use Cardano for this (casus irreducibilis), and in order to use the rational root theorem, you need to factorize abc, a very large number (which is very slow). Besides, using the rational root theorem would not make use of the information that the values $a + b + c$ and $bc + ac + ab$ are also known (because they are coefficients in the polynomial). One trivial algorithm I can come up with is to enumerate all polynomials (we do this by enumerating their coefficients, and integers and rationals are countable, so we can do this) with powers equal to or lower than the powers in the original polynomial, and try if long division yields a rest term (if not, we found a factor). Of course, this is too slow to be practical, but this and the fact that Wolfram Alpha can usually find the factorization of complicated polynomials (though I haven't tried this thoroughly), suggests there is at least one algorithm to do this in a more or less practical way.","['nonlinear-system', 'algebra-precalculus', 'abstract-algebra', 'polynomials']"
703973,"The space of continuous functions $C([0,1])$ is not complete in the $L^2$ norm","I am trying to prove that under the $L^2$ norm, $C([0,1])$ does not give rise to a  complete metric space. To do this I am trying to find a Cauchy Sequence which does not converge in $C([0,1])$ . As a template (on $C([a,b])$ ) I am led to believe the following is Cauchy: $$f_n (x) = \begin{cases} 
1 &\mbox{if } 0 \leq x \leq \frac{1}{2} \\ 
1 - 2n(x-\frac{1}{2}) & \mbox{if } \frac{1}{2}\leq x \leq \frac{1}{2n} + \frac{1}{2}\\
0 & \mbox{if } \frac{1}{2n} + \frac{1}{2} \leq x \leq 1
 \end{cases} 	$$ But I am struggling to show this is Cauchy, I have tried integrating from 0 to 1 but this is giving a very nasty integral and I was wondering if anyone has a better method?","['functional-analysis', 'inner-products', 'cauchy-sequences', 'real-analysis', 'lp-spaces']"
703977,A question about the hierarchy of sets.,"My textbook ""Introduction to Set Theory"" builds a hierarchy of sets in the following manner. It takes $V_0$ to be a set, and defines $V_1$ to be $V_0\bigcup \mathcal{P}(V_0)$, where $\mathcal{P}(V_0)$ is the power set of $V_0$. In general, $V_{n+1}=V_n\bigcup \mathcal{P}(V_n)$. Thus we obtain succesively $V_0,V_1,V_2,\dots$ We know that $\emptyset\in V_1$. Hence, $\{\emptyset\}\in V_2$, and so on. He then goes on to say that we still don't get the infinite set $\{\emptyset,\{\emptyset\},\{\{\emptyset\}\},\dots\}$. For that we have to take the infinite union $V_\omega=V_0\cup V_1\cup\dots$, and then let $V_{\omega+1}=V_\omega\cup \mathcal{P}(V_\omega)$. Why should we have to define $V_\omega$ in this way? I don't understand why we don't get $\{\emptyset,\{\emptyset\},\{\{\emptyset\}\},\dots\}$ even without it. We are anyway assuming that $V_n$ is getting defined for all $n\in\Bbb{N}$. Thanks in advance!",['elementary-set-theory']
703982,Integral values of an expression,"Let $b=\sqrt{a^2+5a+8}-\sqrt{a^2-3a+4}$ Find number of integral values of b. My $long$ way using Calculus : Find domain of function : $R$ Note that function is continuous Prove the function is always increasing Find limit as $x -> \infty$ and $x->-\infty$ Get it as $-4$ and $4$ Conclude that only possible integral values are ${-3,-2,-1,0,1,2,3}$. But I am not happy as that is too long for a 3 marker question (in my exam) I want nice way perhaps using theory of quadratic expressions? EDIT Well you guys gave a short proof using calculus but I wanted to see a proof without using calculus as it was not in the syllabus of the test. And I have definitely not studied about asymptotes in detail (only in hyperbola briefly) Both of the answers are excellent.","['quadratics', 'calculus', 'number-theory']"
703987,Solution of definite integrals involving incomplete Gamma function,"The solution of the integral $$\int_0^{\infty}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx $$ is given as $$2^{-\frac{1}{2}\nu}\alpha^{\nu}\beta^{\frac{1}{2}\nu-1}\Gamma(\nu)\exp(\frac{\alpha^2}{8\beta})D_{-\nu}(\frac{\alpha}{\sqrt{2\beta}})$$ [Re $\beta>0$, Re $\nu>0$]. I need to calculate the same integral for finite limit such as $0$ to $a$. So how can I calculate $\{\int_0^{a}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx\}$. Is there any given form of solution for this definite integration?","['improper-integrals', 'special-functions', 'integration', 'definite-integrals', 'functions']"
704024,Pythagoras's theorem as a special case of the law of cosines,"I heard that the Pythagorean theorem is a special case of the more general theorem relating the lengths of sides in any triangle, the law of cosines?","['geometry', 'triangles', 'trigonometry']"
704033,"Notation for ""set of all possible unions""","For a set $S$, for ""all possible subsets of $S$"" you have $\mathcal{P}(S)$. For a set $S$ consisting of sets, for ""the union of all sets $T\in S$"" you have $\bigcup_{T\in S}T$. Is there a notation for ""all possible unions of one or more sets $T\in S$""? e.g. for $S=\{\{1,2\},\{3,4\},\{5\}\}$, such an ""all possible unions"" set would be
$\{\{1,2\},\{3,4\},\{5\},\{1,2,3,4\},\{1,2,5\},\{3,4,5\},\{1,2,3,4,5\}\}$.","['notation', 'elementary-set-theory']"
704037,How to prove $\sin{b}\sin{c}\sin{(b-c)}(\sin^2{b}+\sin^2{c}+\sin^2{(b-c)})+\dots=0$,"If $a,b,c\in (0,\pi)$ and $a+b+c=\pi$, show that:
  $$\sin b \sin c \sin(b-c) \left(\sin^2 b + \sin^2 c + \sin^2(b-c)\right) \\ 
+ \sin c \sin a \sin(c-a) \left(\sin^2 c + \sin^2 a + \sin^2(c-a)\right) \\ 
+ \sin a \sin b \sin(a-b) \left(\sin^2 a + \sin^2 b + \sin^2(a-b)\right) \\
+ \sin(b-c)\sin(c-a)\sin(a-b) \left(\sin^2(b-c) + \sin^2(c-a) + \sin^2(a-b)\right) = 0$$ This problem is from my friend. He asked me and I can't solve it. Thank you for your help. My idea: let $\sin{a}=x,\sin{b}=y,\sin{c}=z$. Then $LHS=\cdots$.
I fell very hard, so I can't do any work. Thank you.","['geometry', 'trigonometry']"
704058,Problems with the definition of transitive relation,"Recently I found this problem, which made me realize I have some problems with relations that are vacuously transitive. Problem: Assume that $R$ is a relation on $A$ and define the relation $S$ as 
$$ S : = \{ (X, Y) \in \wp(A) \times\wp(A) : \exists x \in X, \exists y \in Y ((x,y) \in R) \}.$$ Statement: If $R$ is transitive, then $S$ is transitive. Is the statement true or false? Solution: I think that the statement is false, and working on a counterexample, I came up with the following relations, where the first picture represents the relation $R$, while the second picture represents the relation $S$. This should be a counterexample, because $R$ is transitive, while $S$ fails to be transitive. Indeed, the $(X,Z)$ fails to be in $S$, because $(x,z) \notin S$, while $(X,Y) \in S$ and $(Y,Z) \in S$, with $(x,y) \in R$ and $(x,y^\prime) \in R$. QUESTION: Is my line of reasoning sound? More specifically, is $R$ transitive? To me, $R$ looks transitive, but only vacuously, because it fails to have $(x,y)$ and $(y,z)$, thus the antecedent of the material implication is false, that makes the implication automatically true. Am I right? Any feedback will be greatly appreciated. Thanks a lot!","['relations', 'elementary-set-theory', 'fake-proofs']"
704068,Two-dimensional unital complex Banach algebras,"Let $A_1$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & 0 \\ 0 & \beta\\ }$$ and let $A_2$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & \beta \\ 0 & \alpha\\ }.$$ I want to prove that these algebras are not isomorphic and that every two-dimensional unital complex Banach algebra is isomorphic to one of them. I have proved the first part: If such isomorphism exists, it would have to be multiplicative and bijective. Hence, a idempotent matrix in $A_1$ would be transformed to idempotent matrix in $A_2$. But those algebras have different numbers of idempotent algebras; a contradiction. Sadly, I have been defeated by the second part. Anyone can help?","['banach-algebras', 'abstract-algebra']"
704073,justification of a limit,"I encountered something interesting when trying to differentiate $F(x) = c$. Consider: $\lim_{x→0}\frac0x$. I understand that for any $x$, no matter how incredibly small, we will have $0$ as the quotient. But don't things change when one takes matters to infinitesimals?
I.e. why is the function $\frac0x = f(x)$, not undefined at $x=0$? I would appreciate a strong logical argument for why the limit stays at $0$.","['infinity', 'derivatives']"
704094,"Product of reflections is a rotation, by elementary vector methods","Let $\mathbf{u}$ and $\mathbf{v}$ be two 3D unit vectors. The transform that performs reflection in the plane normal to $\mathbf{u}$ is given by
$$
T_{\mathbf{u}}(\mathbf{x}) = \mathbf{x} - 2(\mathbf{x} \cdot \mathbf{u})\mathbf{u}
$$
and similarly, reflection in the plane normal to $\mathbf{v}$ is performed by
$$
T_{\mathbf{v}}(\mathbf{x}) = \mathbf{x} - 2(\mathbf{x} \cdot \mathbf{v})\mathbf{v}
$$
Let $\theta$ be the angle between $\mathbf{u}$ and $\mathbf{v}$, and let $\mathbf{n}$ be the unit vector in the direction of $\mathbf{u} \times \mathbf{v}$. So, then we know that $\cos\theta = \mathbf{u} \cdot \mathbf{v}$, and $\mathbf{u} \times \mathbf{v} = (\sin\theta)\mathbf{n}$. The composition of these two reflections is a rotation around $\mathbf{n}$ by an angle of $2\theta$ (I believe), and that rotation is given by Rodrigues' formula:
$$
R(\mathbf{x}) = (\cos2\theta)\mathbf{x} + 
                   (1 - \cos2\theta)(\mathbf{x} \cdot \mathbf{n})\mathbf{n} +
                    (\sin 2\theta)(\mathbf{x} \times \mathbf{n})
$$
It seems to me that we ought to be able to prove from first principles that 
$$
T_{\mathbf{u}}\big(  T_{\mathbf{v}}(\mathbf{x})  \big) = R(\mathbf{x})
$$
I've slogged through pages of vector algebra for a few hours, but to no avail. It's depressing -- I used to be good at this stuff, but apparently not any more. I'd like a proof that uses nothing but elementary vector arithmetic, and I'd like it to be coordinate-free, please. Edit As a couple of people have mentioned, it seems sensible to work in the $\mathbf{u}\text{-}\mathbf{v}\text{-}\mathbf{n}$ coordinate system. This doesn't violate my ""coordinate free"" requirement as long as we don't start writing out explicit coordinates for $\mathbf{u}$, $\mathbf{v}$ and $\mathbf{n}$. The vector $R(\mathbf{x}) - \mathbf{x}$ should be entirely in the 
$\mathbf{u}\text{-}\mathbf{v}$ plane, so all of its $\mathbf{n}$ terms must vanish, and we should be left with an expression that involves only $\mathbf{u}$ and $\mathbf{v}$, which (I hope) will give us the link to the reflections. The algebraic grunt-work involved is what's giving me trouble.","['geometry', 'linear-algebra', 'vectors', 'rotations']"
704108,A generalization of the mean value theorem?,"Let $U \subset \mathbb{R}^d$ be open and path-connected. Let $f: U \to \mathbb{R}^m $ be differentiable on $U$ and suppose there exists a real $M$ such that $|| D_f(x) || \leq M $ for all $x \in U$. then, $$ \|f(b) - f(a) \| \leq M\|b-a\|.$$ for all $a,b \in U$. Is this result true. Can someone show me how to prove it? thanks","['multivariable-calculus', 'calculus', 'vector-analysis', 'real-analysis']"
704121,What is the difference between Curve Fitting and Regression(Machine Learning)?,"I know that Machine Learning regression algorithms try to find the function of the data. That is, if we have 1000 data points (x,y), to find a general continuous function that follows the trends of the data and which can provide estimated values y for other x that we do not know their actual value y. But curve fitting doesn't do very similar thing? I mean, yes, we may have a function this time and not only those 1000 points, but it also tries to find a general continuous function that follows the trends of the data. Therefore what is the most actual difference between the two? The algorithms that work for Regression in ML can't they be applied at curve fitting as well? Update 28 Apr 14 I am reading this paper and it says that it uses Curve fitting and Regression techniques. What is actually their difference? What algorithms/techniques can be considered as Curve Fitting and what as Regression?","['regression', 'machine-learning', 'functions', 'numerical-methods']"
704139,Sum of random numbers is divisible by $10$,"Suppose that $15$ three-digit numbers have been randomly chosen and we are about to add them. What is the probability that the sum would be divisible by $10$? If there were only two or three random numbers we could enumerate the cases in which last digit comes out to be $0$ and hence calculate probability but for $15$ numbers that seems messy so is there a smart way to do it Edit: I have tried another approach which finds the possible sums of $15$ three-digit numbers and then find the sums divisible by $10$ in the same range. So I get: Number of Sums divisible by $10$ in $[1500,14985]=1349$ Total Number of Sums in $[1500,14985]=13486$ And then $P=\frac{1349}{13486}$, but as a comment suggests that this approach does not cater for the fact that a sum may be reached in a multiple of ways. So how can we cater for this fact? I am guessing may be multinomial can be of help ?","['probability', 'random-variables']"
704142,Convergence of characteristic functions to $1$ on a neighborhood of $0$ and weak convergence,"Prove the following statement: $ X_n \Rightarrow 0 $ (convergence in distribution) if and only if $ (\exists\; \epsilon>0: |t|<\epsilon) \;\; \phi_n(t) \rightarrow 1  $ , where $\phi_n(t)$ is the characteristic function of the random variable $X_n$ . We could write $X_n \rightarrow 0 $ in probability since convergence in probability to a constant and convergence in distribution to a constant are the same concept. I guess Lévy's continuity theorem implies the 'only if' part. Thank you very much for your help in advance!","['probability-theory', 'weak-convergence', 'characteristic-functions', 'random-variables']"
704163,Integration of $1/(1+\sin x)$,"I solved it using $t=\tan(\frac{x}{2})$ substitution and got $-2/(1+\tan(x/2))+C$, but in my math book solution is $\tan(x/2-\pi/4)+C$. Are those the same expressions and if they are, how do I transform from one to another, or are one(or both) solutions incorrect ?","['trigonometry', 'calculus', 'integration']"
704186,Indefinite double integral,"In calculus we've been introduced first with indefinite integral, then with the definite one. Then we've been introduced with the concept of double (definite) integral and multiple (definite) integral. Is there a concept of double (or multiple) indefinite integral? If the answer is yes, how is its definition, and why we don't learn that? If the answer is no, why it is so?","['indefinite-integrals', 'calculus', 'integration', 'soft-question']"
704202,Order of a point on an Elliptic Curve,"I am currently struggling with the determination the order of a point on an elliptic curve. We had to do the following exercise: $C = V(y^2+x^3-1)$ and $P = (0,1)$. Now Wikipedia told me that I can calculate the sum of two point with the following formulas: Let $P=(x_P,y_P), Q=(x_Q,y_Q)$. Then $S=P+Q=(X_S,y_S)$ with $x_S=m^2-x_P-x_Q$ and $y_S=-y_P+s(x_P-x_S)$, where $m = \frac{y_P-y_Q}{x_P-x_Q}$. So then I get $P+P = (0,-1)= -P$ so that $P+P+P=\infty$. Now my question is, how this formula works. Because it does not depend anyhow on the formula of the elliptic curve right? So for any elliptic curve my point $P=(0,1)$ has the order $3$? This seems very weird to me. (I also don't see where the formula for the addition of two points comes from.) I would be very happy if someone could explain me how this works, and if you know good literature about elliptic curves. Best, Luca","['algebraic-geometry', 'elliptic-curves']"
704217,Weierstrass $ \tanh \frac{\theta}{2} $ substitution confusion.,"I'm already familiar with the trigonometric version of this substitution $ t = \tan \frac{\theta}{2} $ and it's geometrical derivation involving the unit circle found here. However, I'm not sure how the hyperbolic equivalents (shown below) are derived. $$ t = \tanh \dfrac{\theta}{2} = \dfrac{\sinh \theta}{\cosh \theta + 1} = \dfrac{\cosh \theta - 1}{\sinh \theta} $$ $$ \cosh \theta = \dfrac{1+t^2}{1-t^2}, \ \sinh \theta = \dfrac{2t}{1-t^2}$$ At the bottom of the page , it refers to projecting the point $ (\cosh \theta, \sinh \theta)$ which is found on the right branch of a hyperbola onto the y-axis from the center $ (-1, 0) $ but I'm unsure of what this means. Can anybody provide a geometrical take on deriving these?","['hyperbolic-functions', 'integration']"
704238,Singular Value Decomposition of Rank 1 matrix,"I am trying to understand singular value decomposition.  I get the general definition and how to solve for the singular values of form the SVD of a given matrix however, I came across the following problem and realized that I did not fully understand how SVD works: Let $0\ne u\in \mathbb{R}^{m}$.
Determine an SVD for the matrix $uu^{*}$. I understand that $uu^{*}$ has rank 1 and thus only has one singular value i.e. $$\Sigma =  \begin{pmatrix} 
  \sigma_1 & \ldots & 0\\
  0& \ldots & 0 
\end{pmatrix} 
\in\mathbb{R}^{m\times m}$$ and I realize since $uu^{*}\in\mathbb{R}^{m\times m}$ then for $uu^{*}=U\sum V^{*}$ that $U,\Sigma,V\in\mathbb{R}^{m\times m}$.  Additionally, I realize that the columns of $U$ and $V$ are orthonormal. I guess my question is how do you determine U and V from $uu^{*}$?","['matrices', 'linear-algebra', 'svd']"
704263,Conditional expectation as an orthogonal projection to what subspace?,"Given a random variable $X$ and a sub sigma algebra $N$ of its sampling space, it is often said that $E(\dot \, \mid N)$ is an orthogonal projection, since $X-E(X\mid N)$ and $E( X\mid N)$ are uncorrelated. I understand that to be $X-E(X\mid N)$ is orthogonal to some subspace of random variables which include $E(X\mid N)$. I wonder how to determine the subspace of random variables from $N$? Here do we require $X$ to be $L^2$ or $L^1$? Thanks!","['probability-theory', 'hilbert-spaces', 'conditional-probability']"
704306,Subgroups between $p\mathbb{Z}\oplus p\mathbb{Z}$ and $\mathbb{Z}\oplus \mathbb{Z}$,"I'm looking for a nice description of all proper subgroups of $G=\mathbb{Z}\oplus \mathbb{Z}$ that contain $K=p\mathbb{Z}\oplus p\mathbb{Z}$ properly ($p$ prime). I know how to get all such subgroups. I look at the quotient $G/K$. It's a vector space over $\mathbb{F}_p$ of dimension $2$. I take a nonzero vector in $\mathbb{F}_p^2$, pull it back to $G=\mathbb{Z}\oplus\mathbb{Z}$ and see what it spans together with $K=p\mathbb{Z}\oplus p\mathbb{Z}$. In other words, I choose integers $a,b$ in the range $0,\dotsc,p-1$, not both zero, and see what abelian group $(a,b)$ generates together with $(p,0)$ and $(0,p)$. (I know that different choices and $a,b$ may give the same subgroup. That's ok). The part that I don't like about this description is the part ""see what subgroup $(a,b)$ generates together with $(0,p)$ and $(p,0)$"". This part involves ""Gauss elimination"" over the integers, and it's not so clear what the basis for the resulting subgroup is. Here's a concise form of my question: Let $p$ be prime. Let $a,b$ be integers in the range $0,\dotsc,p-1$, not both zero. Let $H$ be the subgroup of $\mathbb{Z}\oplus \mathbb{Z}$ generated by $\{(a,b),(p,0),(0,p)\}$. Is there a ""nice"" basis for $H$?",['group-theory']
704311,$\epsilon$-$\delta$ limit proof that $\lim_{n\to \infty}\frac{n^2-n+2}{3n^2+2n-4}=\frac{1}{3}$,I need to prove that  $$\lim_{n\to \infty}\frac{n^2-n+2}{3n^2+2n-4}=\frac{1}{3}$$ using the epsilon definition. I'm having specific trouble understanding how to make it less than epsilon once I've simplified the equation.,"['calculus', 'functions', 'limits']"
704361,I made a primality test and want to publish it,"So I am a high school student, and I am very interested in maths, and I made my own primality test which also expresses all composite numbers with last digits of 1,3,7, or 9 in just 9 simple functions. I made sure that no one else has published such test, and also made sure it was true, as I ran it by some maths professors I know. I even made an application that uses it and has never given a false answer. Any ideas where I can publish it?  The entire paper can be written in about 150 words or so.","['primality-test', 'soft-question', 'number-theory']"
704378,Number of groups of a given order,"In general, for what $n$ do there exist two groups of order $n$? How about three groups of order $n$? I know that if $n$ is prime, there only exists one group of order $n$, by Lagrange's Theorem, but how do you classify all other such $n$ that have $2, 3, 4, ...$ groups? This question came to me during a group theory class, when we were making a table of groups of order $n$. For instance, all groups of order $4$ are isomorphic to either $C_4$ or $C_2\times C_2$.","['self-learning', 'group-theory', 'abstract-algebra']"
704396,Totally real vs totally complex Galois cubic fields,"I read that there are only two types of cubic Galois extensions of rationals: totally real and totally imaginary. As I understand it,  totally real cubic Galois extension is an extension with exactly 3 real embeddings, i.e roots of the minimal polynomial are all real.
Let's take
 $K=\mathbb{Q}(\theta)$ where $\theta$ is a real root of $x^3+x^2-2x-1$ and the remaining two are also real. So this would be an example of a totally real cubic Galois field (cyclic). What is the condition for the totally imaginary cubic Galois field? Any example of such field?
 On Wikipedia  the totally imaginary field is defined as the one that cannot be embedded in the real numbers. Does it mean that all embeddings must be complex? But a cubic polynomial always have at least one real root... Thank you","['galois-theory', 'abstract-algebra']"
704404,Clarify my understanding for central limit theorem from a statement,"Asked what the central limit theorem says, a student replies, ""as you take larger and larger samples from a population, the histogram of the sample values looks more and more Normal"". Is the student right? Explain your answer. My answer the student is wrong because the histogram of the sample values will look like the population distribution, whatever that distribution might look like as the sample size increases. The CLT says the sample mean follows a normal distribution with mean $u$ and variance $σ^2/n$ as the sample size goes to infinity. But CLT fails to population
that has fat tails such as Cauchy Distribtion. Is this right? If so, do you think I could add a little more?","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
704410,Will anyone check my primality test?,"The proof is very straightforward and simple. We all know that all prime numbers have a last digit of 1, 3, 7 or 9, and I found that any composite number with a last digit of 1,3,7 or 9 is a product of two numbers having a last digit of 1,3,7 or 9. It can't be anything else.
So this way we can express any composite number $N$ with the stated last digit by :
$N=(10x+m)(10y+n)$ 
where x and y are any positive integer. $m$ and $n$ are the possible last digits for a certain number, for example if $N \equiv 1 \pmod{10}$ then $(m,n)$ could be $(1,1),(9,9),(3,7)$
so we have 3 separate equations to check if any number ending in 1 is composite or not. of course if there is no pair of  positive integer $x$ and $y$ that satisfy any of the 3 equations (other than having any of the values within any of the brackets 1). so the way to do the test would be by making a simple change of subject to get
$y=N/(100x+10m)  - n/10$
and run it for all integers of x less than the square root of the number we want to test
so this way we have 9 different equations to express any composite number having a last digit of 1,3,7 or 9 3 for numbers ending in 1 2 for numbers ending in 3 2 for numbers ending in 7 3 for numbers ending in 9 I know it's not as fast as other tests out there, but please tell me: what do you think of my work?","['primality-test', 'number-theory']"
704412,How do I find the Jacobi matrix?,"I've never done questions like these, so I would very much like some help. We are given a function $f: \mathbb R^n \to \mathbb R$ given by $f(x)=\langle x,\xi\rangle^2$ where $\langle\,,\rangle$ is the standard inner product of $\mathbb R^n$ and $\xi \in \mathbb R^n$. Find $D_f(a)$, meaning, the differential of $f$ in point $a$, or in other words, the jacobi matrix multiplied by vector $a$. Thanks, I would very much like an explanation on how to approach this","['multivariable-calculus', 'inner-products', 'calculus']"
704425,How to proof that $\lim_{h \to 0}\frac{e^h-1}{h} = 1$ using the definition $e = \lim_{n \to \infty}(1+\frac{1}{n})^n$?,"In other words, how I can prove that these two definitions of $e$ is equal? I saw these two definitions while trying to find proofs for $\frac{d}{dx}e^x$ and $\frac{d}{dx}\ln x$; some use the former definition, and others used the latter, and I cannot find a proof that these two definitions are equal. So how do I prove this? Thank you!","['definition', 'constants', 'limits']"
704428,Do we need AC to prove Principle of Dependent Choices,"For any nonempty set $X$ and any entire binary relation $R$ on $X$, there is a sequence $(x_n)$ in $X$ such that $x_nRx_{n+1}$ for each $n \in \mathbb{N}$. (Here an entire binary relation on $X$ is one such that for each $a$ in $X$ there is a $b$ in $X$ such that $aRb$.) I cant understand why we cant prove DC bu usual induction: let $x_1=x$ for some $x \in X$ and given $x_n$ there exist $y_n$ such that $x_nRy_n$. We set $x_{n+1}=y_n$. It seems that we dont need AC in proving this theorem.","['elementary-set-theory', 'axiom-of-choice']"
704457,"Is there a relation that is irreflexive, anti-symmetric and not transitive?","from the set $\{a, b, c, d\}$? Of the one's I have tried, it at best is two of the three, but never all.","['discrete-mathematics', 'order-theory', 'relations', 'graph-theory', 'combinatorics']"
704491,Tangent plane passes through origin,"This is from a section in my course book on elementary differential geometry: Since the tangent plane $T_p S$ of a surface $S$ at a point $p \in S$ passes through the origin of $\mathbb{R}^3$, it is completely determined by giving a unit vector perpendicular to it... There are plenty of surfaces with points whose tangent plane doesn't pass through the origin, so why does it say so here?","['multivariable-calculus', 'differential-geometry']"
704512,Efficient low rank matrix-vector multiplication,"If I have large matrix, but with very low rank, say 2. Is there an efficient way to multiply this matrix by vector (to achieve linear complexity)?","['matrices', 'linear-algebra']"
704573,Solving a differential equation $\displaystyle \frac{d \alpha}{dt}=w \times\alpha$,Let $\alpha$ be a regular curve in $\mathbb{R}^3$ such that $\displaystyle \frac{d \alpha}{dt}=w \times\alpha$ for $w$ a constant vector. How can we determine $\alpha$ ? $\displaystyle w \times\alpha$  : cross product Any hint would be appreciated.,"['differential-geometry', 'ordinary-differential-equations', 'real-analysis']"
704578,Uncorrelatedness and conditional expectation,"Two random variables $X$ and $Y$ . How are the following two statements related: $E(XY) = E(X)E(Y)$ , ( $X$ and $Y$ are called uncorrelated) $E(X\mid Y)= E(X)$ a.s., (what is this case called?) Does one imply the other, and/or are there counterexample to such implications, or are there some condition that can make one imply the other? Thanks! From a deleted reply, there is an interesting statement $E(X\mid Y) E(Y) = E(XY)$ a.s. I don't quite remember it correctly. Can anyone who can see it (with 10k reputation) verify that? I wonder when it is true? Any implication with the previous two statements?","['conditional-expectation', 'probability']"
704585,Alias/alibi in permutation groups,"This question came up in teaching a course on basic group theory to high school students. I gave the class the task of enumerating as many subgroups as they could find in $S_4$ and in the group $O$ of rotations of the cube. The students became suspicious that the groups were isomorphic, and came up with the idea of considering the rotations' actions on the cube's long diagonals to get a map $f:O\rightarrow S_4$, which they (rightly) suspected was an isomorphism. The conversation stalled out when they tried to prove that it was an isomorphism. I directed them first to the question of whether $f(xy)=f(x)f(y)$, figuring that this would make it easier to deduce injectivity or surjectivity, e.g. by finding generators in the image. However, they were already stuck on whether $f(xy)=f(x)f(y)$, although when they actually calculated $f(xy)$ and $f(x)f(y)$ for two or three pairs of rotations $x,y$ (which involved some intense visualizing work to compose the rotations in 3-space, since they do not know about matrices), the answers did match. As I listened to them talk about it, I realized that there were some subtleties here having to do with the way we labeled the group elements that made me realize there was something fundamental I wanted to understand better here too. I want to get to the bottom of this. Here's the setup: We were looking at rotations of the cube in terms of a fixed coordinate system; you could see them as alibi transformations . Thus, for example, although we didn't do this, you could see the cube as the one with vertices $\{\pm 1,\pm 1,\pm 1\}$ in $\mathbb{R}^3$, and $O$ as the group generated by matrices $$x=\begin{pmatrix} & &1\\1& & \\ &1& \end{pmatrix},\; y=\begin{pmatrix}1& & \\ & &-1\\ &1& \end{pmatrix}$$ The point is that we imagine that the coordinate system is fixed, the group elements are fixed alibi transformations in the coordinate system, and the cube is being moved around. Meanwhile, we were writing down the permutations as functions from the index set $\{1,2,3,4\}$ to itself, and composing them accordingly, using the right-to-left convention of function composition. $(123)$ applied to $1$ equals $2$, etc. The map $f$ was given by choosing some labeling on the long diagonals of the cube in its initial position, for example $\overline{(-1,-1,-1)(1,1,1)} = 1$, $\overline{(1,-1,1)(-1,1,-1)} = 2$, $\overline{(1,-1,-1)(-1,1,1)} = 3$, and $\overline{(1,1,-1)(-1,-1,1)} = 4$. Then for a given rotation $\rho$, defining $f(\rho)$ as the permutation that describes where $\rho$ sends each index when the cube is in its original position. To illustrate, in the present example, this means $y\mapsto (1234)$, for example, and $x\mapsto (243)$. We have $$xy = \begin{pmatrix} & &1\\1& & \\ &1& \end{pmatrix}\begin{pmatrix}1& & \\ & &-1\\ &1& \end{pmatrix} = \begin{pmatrix} &1& \\1& & \\ & &-1\end{pmatrix}$$ and $f(xy) = (14)$. Meanwhile, $f(x)f(y) = (243)(1234) = (14)$ (remember that we are composing permutations right to left). Thinking about both the permutations and the rotations as functions, in the former case on the set of indices and in the latter case on the cube, and the action can be restricted to the long diagonals, it is clear ( obvious ) to me why $f$ is a homomorphism. All $f$ does is it records what a rotation $\rho$ does to the diagonals. So $f(\rho\eta)$ is what $\eta$, followed by $\rho$, does to the diagonals, and $f(\rho)f(\eta)$ is what $\eta$ does to the diagonals followed by what $\rho$ does to the diagonals.  These are obviously the same. But there is another way of thinking about it that I can engage in that confuses me about this, and I can't quite sort through where the problem is. Furthermore, this (clearly wrong) way of thinking deals with some issues that the above doesn't engage at all. So my question is: (A) What is wrong with the following train of thought? (B) Can you explain in terms that engage with this train of thought why $f$ is a homomorphism? As above, think of the group $O$ as acting on the cube by rotations in a fixed coordinate system. $\rho\in O$ refers to a rotation with reference to the fixed coordinate system; changes in orientation of the cube do not affect the meaning of $\rho$. Choose an initial orientation of the cube, and a labeling of the long diagonals, as above. For each $\rho\in O$, write down the permutation $f(\rho)$ that describes the action of $\rho$ on the long diagonals in this initial orientation. Now consider $f(\rho\eta)$. $\eta$ moves the diagonals somewhere, $\rho$ moves them again, and $f$ writes down what the composition did, in terms of the original orientation of the cube. On the other hand, consider $f(\rho)f(\eta)$. $f(\eta)$ is unproblematic; it writes down what $\eta$ did to the diagonals, which is the same as before. But now the diagonals are in new spots, so when $\rho$ acts on them, it will not do the same thing it did when it acted on the cube in its original orientation. Thus what $\rho$ does to the diagonals after $\eta$ has been applied will not be the same as $f(\rho)$, which is trying to describe what $\rho$ did to the diagonals in their original orientation. Thus $f(\rho)f(\eta)$ should come out to something different. Empirically, this logic is wrong, and furthermore it contradicts the above logic explaining why $f$ is (obviously) a homomorphism. I assume there is some kind of alias/alibi confusion in it. Be that as it may, I can't shake it completely. Can you help? An ideal answer would both explain where the fallacy is and also give a correct explanation of what's going on that engages with the alias/alibi issues in the fallacious logic. Thanks in advance.","['permutations', 'group-theory']"
704595,Proper functions,"I'm a bit confused with the definition of proper function, i.e.: ""$f: X \to Y$ is proper if the inverse image of every compact set in $Y$ is compact in $X$."" Can anyone provide a more intuitive definition (even if less formal)? Some simple examples of proper and non proper functions would help a lot. Edit : As additional question, is there a simple way to verify that a certain function is proper?","['functional-analysis', 'definition']"
704622,Example of a Hausdorff sheaf of germs,"Let $X$ be a topological space, and let $A$ be a presheaf on $X$. Let $\mathscr{A}$ be the sheaf of germs on $X$. We define a a topology on $\mathscr{A}$ as follows: Given an open set $U \subset X$, fix a section $s \in A(U)$ and consider the germ $s_x$, of $s$, at $x \in U$. The set of all germs $s_x$ for all $x \in U$ is defined to be open in this topology on $\mathscr{A}$. In general, the sheaf $\mathscr{A}$ is not Hausdorff. My question is: Can anyone give an explicit, non-trivial example of a Hausdorff sheaf?","['general-topology', 'sheaf-theory']"
704633,Is invariant theory OK in positive characteristic?,"Let G be a connected reductive group over an algebraically closed field of characteristic p.  Let X = Spec(A) be an affine variety over the same field, with an action of G. Are the closed points in Spec(A^G) in one-to-one correspondence with the closed orbits in X?","['algebraic-geometry', 'invariant-theory']"
704638,How to show the pushforward is linear using equivalence classes of curves?,"Let $M$ be a $C^k$ manifold of dimension $n$. I've constructed the tangent space at $a \in M$ as follows: first I've introduced the following equivalence relation in the set of maps $\gamma : (-\epsilon,\epsilon)\to M$ with $\gamma(0)=a$: we say $\gamma_1\sim \gamma_2$ if and only if $\gamma_1(a)=\gamma_2(a)$ and if for some chart $(x,U)$ around $a$ we have $(x\circ\gamma_1)'(0)=(x\circ\gamma_2)'(0)$. Then I've shown that this independs on the chart. To make the set $T_a M$ of all equivalence classes a vector space, I've proceeded as follows: I've constructed $\psi : T_aM\to \mathbb{R}^n$ by $\psi([\gamma]) = (x\circ \gamma)'(0)$. It was easy to show that $\psi$ is a bijection, thus I've introduced the operations by: $$[\gamma_1]+[\gamma_2]=\psi^{-1}(\psi([\gamma_1])+\psi([\gamma_2]))$$
$$k[\gamma_1] = \psi^{-1}(k\psi([\gamma_1])$$ This would turn $T_a M$ a vector space isomorphic to $\mathbb{R}^n$ by $\psi$. That's all fine, but the pushforward then is giving me trouble. Suppose $f : M \to N$ is differentiable at $a$, then we want to build $f_{\ast a}: T_a M \to T_{f(a)}N$. The idea is easy, we set $f_{\ast a}([\gamma]) = [f\circ \gamma]$, but I must show $f_{\ast a}$ to be linear and I'm not seeing how. The reason is this: $$f_{\ast a}([\gamma_1]+[\gamma_2]) = f_{\ast a}(\psi^{-1}(\psi([\gamma_1])+\psi([\gamma_2])))$$ Now what? There's this $\psi$ map and I don't know how to proceed. Showing the pushforward is linear using derivations was easy, but this seems a little more tricky. Thanks very much in advance.","['linear-algebra', 'differential-geometry']"
704642,Schemes to the rescue?,"I am reading chapter 1 of Gille and Szamuely's book Central Simple Algebras and Galois Cohomology , on quaternion algebras. In it they prove (remark 1.3.1 on p. 18) that the conic associated to a quaternion algebra is an intrinsic invariant of the algebra, i.e. does not depend (at least up to isomorphism of the conic) on the basis chosen for the algebra. The argument almost convinces me, but not quite (see below). I am wondering if the ingredient that I need to convince me is to cast the argument in scheme-theoretic language. Thus, my first question is, can you help me formulate the argument in a way that speaks to my discomfort with it? My second question is, can we use schemes to do this? Background: Let $k$ be a field of characteristic $\neq 2$. The quaternion algebra $$A = \binom{a,b}{k}$$ for $a,b\in k^\times$ is the four-dimensional associative $k$-algebra with basis $1,i,j,ij$ and (noncommutative) multiplication defined by $i^2=a, j^2=b, ij = -ji$; $1$ is identified with the unit of $k$. (Thus the usual Hamilton quaternions are the case $a=b=-1, k=\mathbb{R}$.) A change of basis is elements $1,i',j',i'j'$ in $A$ satisfying $i'^2=a', j'^2=b', i'j'=-j'i'$ for some (possibly different) $a',b'\in k^\times$. The subspace spanned by $i,j,ij$ does not depend on the basis since a calculation shows that this is exactly the set of elements of $A\setminus k$ whose square is $\in k$. This is called the subspace of pure quaternions . The conic associated to $A$ is the conic in $\mathbb{P}^2_k$ defined by the form $ax^2+by^2-z^2$. Up to a simple substitution, this is the same as the conic defined by $ax^2+by^2-abz^2$. $A$ is said to be split if it is isomorphic to $M_2(k)$. For example, if $a=1$, $A$ is split, because it can be mapped isomorphically onto $M_2(k)$ by $$i\mapsto \begin{pmatrix}1& \\ &-1\end{pmatrix},\; j\mapsto \begin{pmatrix} &b\\ 1& \end{pmatrix}$$ A basic theorem says that $A$ is split if and only if the associated conic has a $k$-rational point. The argument: Gille and Szamuely argue that changing basis in a quaternion algebra, which may change $a,b$, nonetheless does not change the isomorphism class of the associated conic. Their argument is essentially that the form $ax^2 + by^2 - abz^2$ which defines the conic is just given by squaring the pure quaternion $xi + yj + zij$. Since the space of pure quaternions is basis independent, so is this form, and thus so is the conic. My discomfort with it: I like this argument, and I buy it in essence, but a detail troubles me. Namely, when I try to actually write down a basis-independent description of the conic, I come up empty (literally): Okay, so the conic ""is"" the vanishing set in $\mathbb{P}_k^2$ of the form $ax^2+by^2 - abz^2$. Great, I can conceive of $\mathbb{P}_k^2$ as being the quotient of the space of pure quaternions by the scalar $k^\times$ action. Then the conic is the vanishing set of the form $\alpha^2$, where $\alpha$ is a pure quaternion. The problem is this. In all interesting cases, i.e. whenever $A$ is not split, the conic I've just described is, as a set, empty . (Because the conic does not have $k$-rational points when $A$ is not split.) This empty set has lost the ability to distinguish between nonsplit nonisomorphic quaternion algebras, so it is not doing the job I came to it for. This objection does not feel very substantive. The conic is not really the set of its $k$-rational points. (This seems like just the type of distinction that scheme theory is good at, hence the title of the question.) My question: Clearly I need a more robust basis-independent description of the conic. I'd like it to be the $\operatorname{Proj}$ of $k[x,y,z]/(ax^2+by^2-abz^2)$, but this description is not basis-independent. Your thoughts? Thanks in advance.","['noncommutative-algebra', 'algebraic-geometry', 'schemes']"
704679,Does the operator $T(f)(t) := f(t) - f(0)$ preserve measurability?,"Denote by $\mathcal{B}$ the Borel field on $\mathbb{R}$, denote by $\mathbf{C}_{\left[0,\infty\right)}$ the set of continuous, real-valued functions over the domain $\left[0,\infty\right)$ and denote by $\mathcal{B}_{\left[0,\infty\right)}$ the minimal $\sigma$-algebra that renders each projection function $\pi_t:\mathbf{C}_{\left[0,\infty\right)}\rightarrow\mathbb{R}$
$$
\pi_t\left(f\right) := f\left(t\right)
$$
$\mathcal{B}_{\left[0,\infty\right)}/\mathcal{B}$-measurable. Consider the following operator $T: \mathbf{C}_{\left[0,\infty\right)} \rightarrow \mathbf{C}_{\left[0,\infty\right)}$
$$
T\left(f\right)\left(t\right) := f\left(t\right) - f\left(0\right)
$$ Let $A \in \mathcal{B}_{\left[0,\infty\right)}$. Is $T\left(A\right) \in \mathcal{B}_{\left[0,\infty\right)}$? If the answer to the first question is: ""No"", is it still ""No"" if $A$ is a tail event? ($B \in \mathcal{B}_{\left[0,\infty\right)}$ is a tail event iff $B \in \bigcap_{t \in \left[0,\infty\right)}\sigma\left(\pi_s :\mid s \in \left[t, \infty\right)\right)$.) My attempts at solving this problem Attempt #1 If $T$ were defined instead like this:
$$
 T\left(f\right) := f + c
 $$
for some constant $c \in \mathbb{R}$, in other words, if $T$ were a rigid translation of $f$, then $T$ would be measurable and invertible, its inverse being itself a translation, and therefore $T\left(A\right)$ would indeed belong to $\mathcal{B}_{\left[0,\infty\right)}$. Unfortunately, $f\left(0\right)$ is not constant, so this approach fails. Attempt #2 Suppose we know that for all $f \in A$, $f\left(0\right) \in \mathbb{Q}$. Then
$$
 A = \bigcup_{q \in \mathbb{Q}}\underbrace{A \cap \left\{\pi_0^{-1} \in \left\{q\right\}\right\}}_{=: A_q}
 $$
and therefore
$$
 T\left(A\right) = \bigcup_{q \in \mathbb{Q}}T\left(A_q\right)
 $$
For each $q \in \mathbb{Q}$, $A_q \in \mathcal{B}_{\left[0\infty\right)}$ and $T\left(A_q\right) = A_q - q$, so by attempt #1, $T\left(A_q\right) \in \mathcal{B}_{\left[0,\infty\right)}$ and hence $T\left(A\right) \in \mathcal{B}_{\left[0,\infty\right)}$. Unfortunately, it may not be the case that for every $f \in A$, $f\left(0\right) \in \mathbb{Q}$, in which case this attempt fails. However, the rationals are dense in $\mathbb{R}$ and in addition, every $f \in \mathbf{C}_{\left[0,\infty\right)}$ is uniquely determined by the values $f$ assumes at the non-negative rationals. Can we take advantage of this additional structure, together with the result of attempt #2, to solve question 1 in the affirmative? (In which case question 2 is automatically resolved as well.)","['probability-theory', 'stochastic-processes', 'measure-theory']"
704680,Determine real number exists for relation with square roots,"We have $$\sqrt{x -2} = 3 -2\sqrt{x}$$. I am to find whether a real number exists for this relation, and the real number that satisfies. I start by squaring both sides, which yields: $$x - 2 = 4x - 12\sqrt{x} + 9$$. Whence: $$ -3x = -12\sqrt{x} + 11 \\
\sqrt{x} = \frac{x}{4} + \frac{11}{12}.
$$ But once i get here i am stuck. How can i find whether a solution exists for x from here?","['real-numbers', 'algebra-precalculus', 'square-numbers']"
704694,Generating Functions Interpretation - Expanding around other points?,"Generating functions are incredibly useful for solving all kinds of combinatorial problems. Whenever they are used, though, the generating function is always expanded around $x=0$ to obtain the series. Why is this the case? Is there a combinatorial use/interpretation of a 'generating function' expanded around other points on the line (or the complex plane)?","['taylor-expansion', 'generating-functions', 'combinatorics']"
704709,What is the dual matrix (of a sample covariance matrix)?,"Let $A$ be a matrix. I am most interested in the real, symmetric case, but for full understanding let's let $A$ be complex. What does it mean for $A^D$ to be the dual matrix of $A$? Can we interpret it in terms of the SVD of $A=U\Sigma U^T$? Note: This is not merely the transpose. See 6.1 in http://arxiv-web3.library.cornell.edu/pdf/1211.2671v4.pdf for an example of this term. I've included the tags random matrices and probability distributions since that has something to do with the unconventional context in which I found this term used. I do not know to what extent they are relevant.","['matrices', 'random-matrices', 'linear-algebra', 'probability-distributions', 'symplectic-linear-algebra']"
704718,Linear algebra questions that a high-schooler could explore,Are there any deep/significant concepts in linear algebra that are not overly complicated that a high schooler could explore in depth?,"['linear-algebra', 'soft-question']"
704730,Discrete and compact subset must be finite,"Show that a discrete and compact subset $D \subset \mathbb{C}$ must be finite. Does this conclusion hold if $D$ is just discrete and bounded? How about discrete and closed? Compact is the usual (for these simple spaces), closed and bounded, where closed is contained under the limit operation/contains all limit points. Bounded it can be contained in a ball of some radius around the origin. $D \subset \mathbb{C}$ is a discrete subset if $\forall z \in D$ there exists a ball of radius $r>0$ such that $D \cap B_r(z)$ = $\{z\}$. Okay, for bounded set: why is discrete required? Can you give mme an example of a bounded set that is NOT finite?","['general-topology', 'real-analysis']"
704732,How do I prove this trigonmetric identity?,"I need to prove that the following identity is true: $$
\frac{\cos^2x-\sin^2x}{1-\tan^2x}=\cos^2x
$$ This isn't homework; just a practice exercise. But I keep getting stuck! Thanks much.","['trigonometry', 'algebra-precalculus']"
704737,Triple integral in cylindrical coordinates question,Can someone explain the answer given split the integral into a cylinder and volume below a sphere? Thanks.,"['multivariable-calculus', 'integration']"
704745,Matrix of Linear Transformation by right multiplication,"I am trying to solve the following problem: Let $A$ be an $n\times n$ matrix, and let $V$ denote the space of $n$-dimensional row vectors. What is the matrix of the linear operator ‘‘right multiplication by $A$’’ with respect to the standard basis of $V$? I am not sure where to begin with this problem.","['matrices', 'linear-algebra', 'abstract-algebra']"
704773,What is the derivative of a vector with respect to its transpose?,"I've already looked at Vector derivative w.r.t its transpose $\frac{d(Ax)}{d(x^T)}$ , but I wasn't able to find the direct answer to my question in that question. What is the value of $$\frac{d}{dx} x^T\text{ ?}$$
My initial intuition is that it is $1$, but I'm not exactly sure of why that would be so.","['matrices', 'matrix-calculus', 'calculus', 'multivariable-calculus']"
704791,Number of Solutions to a Diophantine Equation,"I am asked the following: Show that the number of integer solutions to $y^p=x^2+2$ for any odd prime $p$ is at most $p-1$. I checked that for $y^p=x^2+2$, the same method for $y^3=x^2+2$ works and I get that $x+\sqrt{-2}=(a+b\sqrt{-2})^p$ for some integer $a$ and $b$. I then expand RHS with Binomial Theorem and get
$$\sum_{k=0}^p {p\choose k}a^k (b\sqrt{-2})^{p-k}$$ Since $(\sqrt{-2})^n$ is real whenever $n$ is even, equate real and imaginary parts and get
$$x=\sum_{k=0, k \mbox{ odd}}^p {p\choose k}a^k (b\sqrt{-2})^{p-k}$$
and
$$\sqrt{-2}=\sum_{k=0, k \mbox{ even}}^{p-1} {p\choose k}a^k (b\sqrt{-2})^{p-k}$$
Divide through by $\sqrt{-2}$ and take $b$ out to get
$$1=b\left(\sum_{k=0, k \mbox{ even}}^{p-1} {p\choose k}a^k (b\sqrt{-2})^{p-k-1}\right)$$ So we must have $b=1$ or $b=-1$. Also, the horrible sum inside the bracket is a polynomial of degree $p-1$, so for each choice of $b$ there can be at most $p-1$ (integer) choices of $a$. Now here is the problem. Because there are two choices of $b$, there are at most $2(p-1)$ choices of $(a,b)$ that satisfy the last equality. Thus there are at most $2(p-1)$ choices of $x$. But I can't seem to find a way to lower this upper bound to just $p-1$. I am feeling so close! Any help will be appreciated!","['diophantine-equations', 'number-theory']"
704826,Regarding limits: $\lim\limits_{n\to \infty}\left(\frac{f\left(x+\frac{1}{n}\right)}{f(x)}\right)^n$,"If $f$ is positive and differentiable in $(0,\infty)$, then I want to find the following limit. $\lim\limits_{n\to \infty}\left(\dfrac{f\left(x+\dfrac{1}{n}\right)}{f(x)}\right)^n$. I have done as follows:
$\lim\limits_{n\to \infty}\left(\dfrac{f\left(x+\dfrac{1}{n}\right)}{f(x)}\right)^n=\left(\lim\limits_{n\to \infty}\dfrac{f\left(x+\dfrac{1}{n}\right)}{f(x)}\right)^n=1$ as $f$ is continuous at $x=\dfrac{1}{n}$. Am I right? I doubt. Please help!","['calculus', 'limits']"
704837,questions about Global Proj,"Can someone explain the construction of the global $\mathbf{Proj}$ to me?
Although this question has been asked here , I still have several questions. For each open affine subset $U = \mathrm{Spec} A$ of $X$, let $\mathcal{S}(U) = \Gamma(U, \mathcal{S}|_{U})$, which is a graded $A$-algebra. Then we have a natural morphism $\pi_{U}: \mathrm{Proj} \mathcal{S}(U) \rightarrow U$. This map is from $A \rightarrow \mathrm{Proj} \mathcal{S}(U)_{f}: a \rightarrow a/1 $, right? Let $f \in A$ and $U_{f} = \mathrm{Spec} A_{f}$. Since $\mathcal{S}$ is quasi-coherent we have $\mathrm{Proj} \mathcal{S}(U_{f}) \cong \pi_{U}^{-1}(U_{f})$. I don't really understand the explanation under that question. Why $\mathcal S(U_f)=\mathcal S(U)_f$? And why we need $\mathcal{S}$ to be quasi-coherent? How to glue the invertible sheaves $\mathcal{O}(1)$ on each $\mathrm{Proj} \mathcal{S}(U)$ to get an invertible sheaf $\mathcal{O}(1)$ on $\mathbf{Proj}S$ Can someone explain more explicitly? Thank you very much! Here is my understanding: Suppose $\mathcal{S}|_{U}=\tilde{M}$, then $\mathcal{S}|_{U}(U)_f=M_f=\mathcal{S}|_{U}(U_f)$.
Then we have this commutative diagram:
$\require{AMScd}$
$$\begin{CD}
\mathrm{Proj}\mathcal{S}(U_f)=\mathrm{Proj}\mathcal{S}(U)\times_{\mathrm{Spec}A}\mathrm{Spec}\,\mathcal A_f @>>> \mathrm{Spec}\,\mathcal A_f\\
@VVV @VVV \\
\mathrm{Proj}\mathcal{S}(U) @>>> \mathrm{Spec}\,\mathcal A.
\end{CD}$$","['algebraic-geometry', 'projective-schemes']"
704841,Ensuring I have a closed point,"Hartshorne, Algebraic Geometry , Exercise II.3.20, reads (in part): Let $X$ be an integral scheme of finite type over a field $k$. (a) [Prove:] For any closed point $P \in X$, $\dim X = \dim \mathcal{O}_P$, where for rings we always mean the Krull dimension. [...] I'm stuck on a point which is completely tangential to the actual business about dimension.  Here's my proof: Let $\emptyset \neq X_0 \subset X_1 \subset \cdots \subset X_n \subseteq X$ be an increasing chain of irreducible closed subsets of $X$ of maximum length, so that $n = \dim X$.  (In fact $X_n = X$ since $X$ is irreducible.)  Let $U \subseteq X$ be an open affine subset which meets $X_0$, and write $A := \mathcal{O}_X(U)$. As $X$ is of finite type over $k$, $A$ is a finitely-generated $k$-algebra by Exercise II.3.3(b). It follows from general topology that $\dim U = \dim X$. [etc.] We've now done enough to reduce the problem to the affine case.  To see this, consider a closed point $P \in X$.  $P$ is contained in some open affine set $V$, which intersects $U$ since $X$ is irreducible. Let $Q$ be a closed point in $U \cap V$. Assuming the affine case, we have
  $$\dim \mathcal{O}_{X, P} = \dim V = \dim \mathcal{O}_{X, Q} = \dim U = \dim X$$
  which establishes the desired result. So suppose that $X = \operatorname{Spec} A$ for some finitely-generated $k$-algebra $A$. [etc.] I'm concerned with the bolded sentence, ""Let $Q$ be a closed point of $U \cap V$.""  In particular, how do I ensure that $U \cap V$ contains a closed point?  As I understand it, the hypothesis that $X$ is integral of finite type over a field is vital here -- if I take two arbitrary open affines and glue them together then I can easily create a situation where $U \cap V$ doesn't contain a closed point. However, I'm having trouble seeing how to get anything out of this hypothesis.  For instance, $U \cap V$ isn't necessarily affine, and though it contains some affine set a point could be closed in that affine but not in $U \cap V$. Am I just being stupid here?  How do you do this?",['algebraic-geometry']
704852,"Prove that $f$ is continuous at $(0, y_0)$. where $f$ is defined on $\Bbb R^2$.","Prove that f is continuous at $(0, y_0)$ $f(x, y) =
\begin{cases} (1+xy)^{1/x} &\mbox{if } x \neq 0 \\
e^y & \mbox{if } x \equiv 0. \end{cases} $ Thank you!","['multivariable-calculus', 'continuity', 'real-analysis']"
704904,What does $\sin(\sin(x))$ mean?,"What does an equation like $\sin(\sin(x))$ mean? I know it can be seen as a composite function $f(f(x))$, where $f(x)=\sin(x)$. Is there a way to simplify functions like this, and where will this be used? Thanks in advance. P.S. I have looked at the graph of $f(x)=\sin(\sin(x))$ and compared it to the graph of $g(x)=\sin(x)$. They look pretty similar, but $f(x)=\sin(\sin(x))$ has a smaller amplitude",['trigonometry']
704917,"Integral $\int_0^\infty F(x)\,F\left(x\,\sqrt2\right)\frac{e^{-x^2}}{x^2} \, dx$ involving Dawson's function","I need your help evaluating this integral: $$I=\int_0^\infty F(x)\,F\left(x\,\sqrt2\right)\frac{e^{-x^2}}{x^2} \, dx,\tag1$$ where $F(x)$ represents Dawson's function/integral : $$F(x)=e^{-x^2}\int_0^x e^{y^2} \, dy = \frac{\sqrt{\pi}}{2} e^{-x^{2}} \operatorname{erfi}(x).\tag2$$ Dawson's function can also be represented by the infinite integral $$F(x) = \frac{1}{2} \int_{0}^{\infty} e^{-t^{2}/4} \sin(xt) \,  dt.$$ Since $F(x)$ behaves like $x$ near $x=0$ and like $\frac{1}{2x}$ for large values of $x$ , we know that integral $(1)$ converges.","['calculus', 'integration', 'special-functions', 'definite-integrals', 'error-function']"
704928,Trace and determinant of composition of a left-multiplication and a right-multiplication on a space of matrices,Determine the trace and determinant of the linear operator (on the space $\mathbb{F^{n\times n}}$) that sends the matrix $M\to AMB$ where $A$ and $B$ are $n\times n$ matricies,"['trace', 'matrices', 'linear-algebra', 'determinant']"
704958,Showing that the norm of the canonical projection $X\to X/M$ is $1$,"How do I show that given $M$ a closed subspace of a normed space $X$, and let $\pi$ be the canonical projection of X onto $X/M$. Prove that $\|\pi\| = 1$. I figure I could use Riesz' lemma and set $\|\pi\| = 1$, that's as far as I got. I could also use the fact that the canonical map is a contraction so I would have $\|\pi(x)\| \leq \|x\| \Rightarrow \frac{\|\pi(x)\|}{\|x\|} \leq 1$ and taking a supremum then we get the desired result. This doesn't seem as rigorous.","['normed-spaces', 'functional-analysis', 'analysis']"
704961,Proof that $0 < \lim(a_n/b_n) < \infty$ implies convergence/divergence of $a_n$ and $b_n$,"Suppose that $a_n, b_n > 0$ for all $n$. Prove that if $0 < \lim(a_n/b_n) < \infty$, then $\sum a_n$ and $\sum b_n$ either both converge or both diverge. I'm a bit unsure on how to proceed with the proof... Any suggestions? My class uses Ross' book.","['summation', 'sequences-and-series', 'real-analysis', 'limits']"
704975,"$\exists c>0$, $\forall A\subseteq \Bbb R_{\ne 0}$ s.t. $|A|=n$, $\exists B\subseteq A$ s.t. $|B|>cn$ & $b_1+2b_2=2b_3+2b_3$ has no solutions in $B$.","EXERCISE 2.7.2 fron Alon and Spencer's The Probabilistic Method . Prove that there is a positive constant $c$ so that every set $A$ of $n$ nonzero reals
contains a subset $B\subseteq A$ of size $|B| > cn$ so that there are no $b_{1},b_{2},b_{3},b_{4}\in B$ satisfying $$b_{1}+2b_{2}=2b_{3}+2b_{4}\,.$$ My idea is to regard the elements of $A$ in modulo $m$ for some $m>0$ , then I must find numbers which they are not true in above relation in modulo $m$ .  This is just the Idea but my problem is to make rigid and exact.","['number-theory', 'probabilistic-method', 'probability', 'combinatorics']"
705000,Conformal maps from the upper half-plane to the unit disc has the form,"Prove that the conformal maps from the upper half-plane $\mathbb{H}$ to the unit disc $\mathbb{D}$ has the form $$e^{i\theta}\dfrac{z-\beta}{z-\overline{\beta}},\quad\theta \in \mathbb{R} \text { and }\beta \in \mathbb{H}.$$ Any hints?","['conformal-geometry', 'complex-analysis']"
705012,Self-study: what fractions of problems to solve?,I am self-studying measure-theoretic probability out of Billingsley's Probability and Measure . So far I have been trying to solve all the exercises. While the exercises are wonderful and I can ultimately solve most they do take up a lot of time. I would like to know what fraction of problems from this or similar books are students expected to solve in graduate courses on this topic?,"['probability-theory', 'self-learning']"
705021,Trigonometry Identity: Prove that $\sin(a-b)=\sin a \cos b - \cos a \sin b$,"First, I do not want a proof using $\sin(a+b)=\sin a \cos b + \cos a \sin b$. Second, I suspect that it has something to do with Euler's formula; $e^{ix}=\cos x + i\sin x$, but I am not sure. Can anyone give me some direction? Thanks in advance. P.S. I apologize if this question is a duplicate. I did not find any when scrolling down the ""Questions that may already have your answer"" list.","['trigonometry', 'proof-writing']"
705048,Finite Product Spaces of Normal Spaces,"So I am practicing some basic topolgy questions, and I came upon the statement: If $X=X_{1} \times \cdots \times X_{n}$ is normal, then each $X_{j}$ is normal. I have a proof, but I am not convinced that it is correct. Some helpful hints, better solution(s), or correct solution, or any feedback if I am correct (or not) will be greatly appreciated. Thanks. Here is my solution: We can assume, for simplicity of the proof, that $X=X_{1} \times X_{2}$. Let $E$ and $F$ be two disjoint closed subsets of $X_{j}$ for fixed $j=1$. Fix an element $y$ in $X_{2}$. Then the slices $E \times \{y\}$ and $F \times \{y\}$ are thus disjoint closed subsets of $X$. So since $X$ is normal, there are two disjoint open sets $U$ and $V$ containing $E \times \{y\}$ and $F\times \{y\}$, respectively in $X$. Now, the projection maps $\pi_{j}(U)$ and $\pi_{j}(V)$ are disjoint open sets containing $E$ and $F$, as required. Thus, $X_{j}$, for $j=1$ is normal. By the same argument for $j=2$, we can conclude that $X_{j}$ is normal as well.",['general-topology']
705096,"Why is this allowed? (""Fourier's Trick""; finding the coefficients in a Fourier Series)","In my textbook ( Introduction to Electrodynamics , D. Griffiths), we derive the equation for some strange potential function. Eventually, we get to this (for $n \in \mathbb{Z}^+$ ): $$ V_0(y) = \sum_{n=0}^{\infty} C_n\sin{\frac{n\pi}{a}y} \tag{3.31}$$ Here's where things go awry for me. ... how do we actually determine the coefficients $C_n$ , buried as they are in that infinite sum? The device for accomplishing this is so lovely it deserves a name—I call it Fourier's trick , though it seems Euler had used essentially the same idea somewhat earlier. Here's how it goes: Multiply Eq. 3.31 by $\sin{n'\pi y/a}$ (where $n'$ is a positive integer), and integrate from 0 to a: $$ \displaystyle \sum_{n=0}^{\infty} C_n \int_0^a\sin{\frac{n\pi}{a}y} \sin{\frac{n'\pi}{a}y} dy ~~~=~~~ \int_0^a V_0(y)\sin{\frac{n'\pi}{a}y} dy$$ The answer understandably comes out to something very nice and convenient. But... why is this something you can do? There's no obvious reason for why that doesn't intrinsically change the problem (in the same way that I can say ""Multiply both sides by $0$ . You've successfully reduced the problem to zero. Well done!) (While typing out the above, I suspect that it has something to do with the inner product of a function and an orthonormal basis? The infinite $\sin$ functions create an orthonormal basis, and taking that integral over all possible values effectively extracts the coefficients for each basis function. When it is suggested that we multiply by $\sin{\frac{n'\pi}{a}y}$ and integrate, this isn't changing the basis at all, it's just (sneakily) extracting the coefficients, which only exist when $n = n'$ (because the $\sin$ functions are all orthogonal). It's like taking the coefficients of a basis with itself... right? I think this may be one of those cases where, in the process of asking the question, I figure out the answer—but this is all fairly new to me, and I'd like to ask it anyway for confirmation and, possibly, a clearer explanation).","['fourier-series', 'summation', 'sequences-and-series', 'physics']"
705100,Derive a model for the variances $\sigma_i^2$ for which $b_1$ is the best linear unbiased estimator (BLUE) of $\beta$,"Consider the model $y_i=\beta x_i + \epsilon_i$ (without a constant term and with $k=1$ ), where $\mathbb{E}[\epsilon_i]=0, \mathbb{E}[\epsilon_i \epsilon_j]=0, \forall i \neq j$ , and $\mathbb{E}[\epsilon_i^2]=\sigma_i^2$ . Then consider following estimators of $\beta:$ $$b_1=\frac{\sum{x_iy_i}}{\sum{x_i^2}},$$ $$b_2=\frac{\sum y_i}{\sum x_i}$$ and derive a model for the variances $\sigma_i^2$ for which this estimator is the best linear unbiased estimator (BLUE) of $\beta$ My attempt so far: I thought I should write this model in the 'standard form' for which we know that the OLS estimator is BLUE. So I tried to deduce the variance of this estimator so that maybe this could be corrected by a certain factor (similarly to in Weighted Least Squares). The variance that I got is: $$\mathrm{Var}[b_1]=\frac{\sum x_i^2 \sigma_i^2}{\left(\sum x_i^2\right)^2}.$$ However, it doesn't seem that I can correct this variance by a factor to bring it to that of the standard model. Same problem for $b_2$ . Could anyone please help?","['statistics', 'probability-distributions', 'least-squares', 'probability-theory']"
705104,Prove: Number of derangement is odd if and only if number of items is even .,Let $D_n$ be a number of derangement of $n$ items. Prove that $D_n$ is odd if and only if $n$ is even. I was trying to use induction on the $!n=(n-1)(!(n-1)+!(n-2))$ recurrence relation but I can't derive the parity of the $!(n-2)$ . The other way I was thinking about is direct proof using the standard sum we get from  inclusion-exclusion principle $$n!\sum_{i=0}^{n}\frac{(-1)^i}{i!}$$ but I don't see how I can prove it's odd if and only if $n$ is even.,"['derangements', 'inclusion-exclusion', 'proof-writing', 'combinatorics']"
705114,"Let $f(x)=\int_0^1|t-x|t~dt$ for all real $x$. Sketch the graph of $f(x)$, what is the minimum value of $f(x)$","Let $f(x)=\int_0^1|t-x|t~dt$ for all real $x$. Sketch the graph of $f(x)$, what is the minimum value of $f(x)$ I could not in any way understand how to approach this problem. I think I will be able to plot the graph if I know how the function looks like, so one can wish to avoid that part. To find the minimum value I thought of differentiating the function. But, there is $x$ on one side and $t$ along with $x$ on the other side. I got really confuse how should I do that. Please help.","['definite-integrals', 'derivatives', 'integration', 'real-analysis']"
705123,Prove:that in any set of 1009 positive integers exits two numbers $a_i$ and $a_j$ such that $a_i-a_j$ or $a_i+a_j$ is divisible by 2014,"Show that in any set of 1009 positive integers exits two numbers $a_i$ and $a_j$ such that $a_i-a_j$ or $a_i+a_j$ is divisible by 2014 without remainder ($i\not=j$). I think the ""pigeonholes"" here is the remainder of division by 2014 . 
now i need to think of a way to define the ""pigeons"" but cant think of anything .","['pigeonhole-principle', 'combinatorics']"
705127,Field isomorphism of $\mathbb{C}$ onto itself,"I am trying to find a field isomorphism of $\mathbb{C}$ onto itself other than the identity map. The isomorphism preserves the algebraic structures $f(x+y)=f(x)+f(y)$ and $f(xy)=f(x)f(y)$. This means $f(i^2)=f(-1)=f(i)f(i)$. With this in mind, I have tried to come up with a bunch of different bijections $f$ like $f(z)=iz$, which fails that latter algebraic property, since: $$
f(i)=i^2=-1 \Rightarrow f(i)f(i)=1
$$
$$
f(-1)=i
$$ Could anyone give me some hints that would lead me to the solution? Because I'm not sure my approach is the righ one.",['analysis']
705164,What is the importance of the spectral theorem?,"I know that the spectral theorem tells us that in the case of a real inner product space, an operator is self adjoint if and only if there is an orthonormal basis with only eigenvectors of that operator and that in the case of a complex inner product space, an operator is normal if and only if there is an orthonormal basis with only eigenvectors. However, I am unable to see what is so important about this. I know that this means I can diagonalize the matrix but I don't know what is so good about diagonalizing a matrix. Also, why do we have to have an orthonormal basis? Why can it not be a standard basis? Thank you!","['motivation', 'linear-algebra', 'big-picture']"
705173,What does it mean if $\det(A)$ equals $1$?,What does it mean if $\det(A)$ equals $1$? Does it mean that the identity matrix can be obtained from $A$ by only adding multiples of rows onto others?,"['matrices', 'linear-algebra', 'determinant']"
705174,Counting number of bijections satisfying given inequality,"Given two sets $$A=\{a_{1},a_{2},\cdots,a_{m}\},B=\{b_{1},b_{2},\cdots,b_{m}\}$$ where 
$$a_{i}<b_{i}<a_{i+1}<b_{i+1},i=1,2,\cdots,m-1$$
and the function
$$g(a,b)=\begin{cases}
1&a>b\\
0&a\le b
\end{cases}$$
I'm expected to find the number of bijections
$f:A\to B$ satisfying the inequality
$$2\sum_{i=1}^{m}g(a_{i},f(a_{i}))>m$$ My attempt: We have 
$$a_{i}>f(a_{i})\,\Longrightarrow g(a_{i},f(a_{i}))=1$$
and 
$$a_{i}\le f(a_{i})\,\Longrightarrow g(a_{i},f(a_{i}))=0$$
and that's as far as I managed to get. Thank you for your help.",['combinatorics']
705188,Sigmoid function with separate control of derivative at 0 and sharpness of bend.,"For a physical relationship, $f(x)$, I'm trying to model, i have a fairly good determination of some of the boundaries, such that $ f(0) = 0$ $f'(0) = B$ $ \lim_{x\to\infty} f = A $ So far, what I have is: $ f(x) = A \tanh(b x)$ This fulfills the requirements listed. But one thing that is not known until data becomes available, is how fast f approaches A. So I have narrowed my needs down to that I need a Sigmoid function, that will allow me to vary the rate of convergence to the upper asymptote independently of the derivative at zero. Wikipedia has an illustration of what I need - but rather than a discrete set of functions, I need to vary the curvature with a parameter. Please give suggestions for closed form solutions that satisfy these requirements. /AdamAL - an engineer with a math problem Edit The function does not need to be true Sigmoid. Fulfilling the requirements for $x>0 $ is sufficient. However, sharpness of bend parameter $c\to\infty$, the solution should tend to the piecewise linear given by,  f=$Bx$ and $f=A$, respectively","['interpolation', 'data-analysis', 'functions']"
705191,Decomposing real line as a union of a nullset and a set of first category,"$\Bbb R$ can be written of the form $A\cup B$ such that $A$ is of measure zero and $B$ is of the first category!
can anybody prove this?
I guess $A$ must be an $G_{\delta}$ set which is dense in $\Bbb R$ and obviously $B=\Bbb R-A$.","['measure-theory', 'baire-category', 'examples-counterexamples', 'descriptive-set-theory']"
705193,Does there exist a vector field s.t. all orbits are dense on $\mathbb{R}^2$,"Is there a complete vector field such that the all orbits are dense on a contractible manifold?
For example, $\mathbb{R}^2$,the interior of a $n$-unit ball.","['differential-topology', 'manifolds', 'differential-geometry']"
705248,Generators of the first commutator subgroup,"I found this statement in some lecture notes, and I am having trouble proving it, so I just want to make sure that I understand the statement: Let $G$ be a group generated by a subset $S$ . Then the first commutator subgroup of $G$ is generated by conjugates of commutators of elements in $S$ . I think it means that $$G'= \langle g[a,b]g^{-1} :  g\in G, a,b \in S \rangle,$$ am I right? In case I am right: I am trying to show that every commutator $[x,y]$ ( $x,y \in G$ ) can be represented in this form. But I can't find a way of doing it. Any hint will be appreciated! Thank you.","['group-theory', 'derived-subgroup']"
705258,$\lim\limits_{n\to\infty}\Bigl[\sin\Bigl(\dfrac{n}{n^2+1^2}\Bigr)+\sin\Bigl(\dfrac{n}{n^2+2^2}\Bigr)...+\sin\Bigl(\dfrac{n}{n^2+n^2}\Bigr)\Bigr]$,"Find the limit of $\Bigl[\sin\Bigl(\dfrac{n}{n^2+1^2}\Bigr)+\sin\Bigl(\dfrac{n}{n^2+2^2}\Bigr)...+\sin\Bigl(\dfrac{n}{n^2+n^2}\Bigr)\Bigr]$ using Riemann integrals of a suitable function. $\Bigl[\sin\Bigl(\dfrac{n}{n^2+1^2}\Bigr)+\sin\Bigl(\dfrac{n}{n^2+2^2}\Bigr)...+\sin\Bigl(\dfrac{n}{n^2+n^2}\Bigr)\Bigr]=\dfrac{1}{n}\Bigl[\sin\Bigl(\dfrac{1}{1+(\dfrac{1}{n})^2}\Bigr)+\sin\Bigl(\dfrac{1}{1+(\dfrac{2}{n})^2}\Bigr)+...\Bigr]$ Hence the function is $\sin\Bigl(\dfrac{1}{1+x^2}\Bigr)$ and it goes from $0$ to $1$ $\displaystyle\int_0^1\sin\Bigl(\dfrac{1}{1+x^2}\Bigr)dx=?$ This is not an easy integral to compute, but the main question in this exercise is i think to convert the sum into an integral and not the computing, So maybe i did a mistake somewhere ?","['riemann-sum', 'calculus', 'integration']"
705268,How to prove that $\sum_{n=1}^{\infty}\frac{1!+2!+\cdots+n!}{(2n)!}$ converges?,"Show that this series converges:
  $$\sum_{n=1}^{\infty}\dfrac{1!+2!+\cdots+n!}{(2n)!}$$ My solution: this series converges since
$$1!+2!+\cdots+n!\le n!+n!+\cdots+n!=n\cdot n!$$
and
since
$$\sum_{n=1}^{\infty}\dfrac{n\cdot n!}{(2n)!}$$ is convergent because
$$\lim_{n\to\infty}\dfrac{a_{n+1}}{a_{n}}=\lim_{n\to\infty}\dfrac{(n+1)\cdot(n+1)!}{(2(n+1))!}\cdot\dfrac{(2n)!}{(n\cdot n!}=\lim_{n\to \infty}\dfrac{n+1}{2(2n+1)n}=0.$$ My question: are there other methods to solve this problem? Such as if we let $$a_{n}=\dfrac{1!+2!+\cdots+n!}{(2n)!},$$ then can we prove $$\lim_{n\to\infty}\dfrac{a_{n+1}}{a_{n}}<1?$$
Thank you very much!","['convergence-divergence', 'sequences-and-series']"
