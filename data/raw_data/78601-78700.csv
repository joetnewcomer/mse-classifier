question_id,title,body,tags
1006120,At which p-adic fields does the equation have no solution?,"I have to check if the equation $3x^2+5y^2-7z^2=0$ has a non-trivial solution in $\mathbb{Q}$. If it has, I have to find at least one. If it doesn't have, I have to find at which p-adic fields it has no rational solution. Theorem : We suppose that $a,b,c \in \mathbb{Z}, (a,b)=(b,c)=(a,c)=1$. $abc$ is square-free. Then, the equation $ax^2+by^2+cz^2=0$ has a non-trivial solution in $\mathbb{Q} \Leftrightarrow$ $a,b,c$ do not have the same sign. $\forall p \in \mathbb{P} \setminus \{ 2 \}, p \mid a$, $\exists r \in \mathbb{Z}$ such that $b+r^2c \equiv 0 \pmod p$ and similar congruence for the primes $p \in \mathbb{P} \setminus \{ 2 \}$, for which $p \mid b$ or $p \mid c$. If $a,b,c$ are all odd, then there are two of $a,b,c$, so that their sum is divided by $4$. If $a$ even, then $b+c$ or $a+b+c$ is divisible by $8$.
  Similar, if $b$ or $c$ even. The first sentence is satisfied. For the second one: $$p=3:$$ $$5+x^2(-7) \equiv 0 \pmod 3 \Rightarrow x^2 \equiv 2 \mod 3$$
$$\left ( \frac{2}{3} \right)=-1$$ So, we see that the equation hasn't non-trivial solutions in $\mathbb{Q}$. EDIT : To check if there is a solution in $\mathbb{Q}_2$, we use the following lemma: If $2 \nmid abc$ and $a+b \equiv 0 \pmod 4$, then the equation $ax^2+by^2+cz^2=0$ has at least one non-trivial solution in $\mathbb{Q}_2$. In our case, $a+b=8 \equiv 0 \pmod 4$, so there is no solution in $\mathbb{Q}_2$, right? For $p=3,5,7$, we use the following lemma: Let $p \neq 2$ be a prime, $a,b$ and $c$ be pairwise coprime integers with $abc$ square-free and $p \mid a$, and $Q: ax^2+by^2+cz^2=0$ a quadratic form.
Then there is a solution to $\mathbb{Q}$ over $\mathbb{Q}_p$ iff $-\frac{b}{c}$ is a square $\mod p$. $$\left( -\frac{5}{-7}\right)=\left( \frac{5}{7} \right)=-1$$ So, there is no non-trivial solution in $\mathbb{Q}_3$. $$\left( \frac{-3}{-7} \right)=\left( \frac{3}{7} \right)=-1$$ So, there is no non-trivial solution in $\mathbb{Q}_5$. $$\left( -\frac{3}{5}\right)=-1$$ So, there is no non-trivial solution in $\mathbb{Q}_7$. It remains to check if the equation has non-trivial solutions in $\mathbb{Q}_p, p \neq 2,3,5,7$. Can we do this, by only using the pigeonhole principle? Or do we have to apply Hensel's Lemma? If so, how could we do this? I haven't understood it..","['diophantine-equations', 'p-adic-number-theory', 'number-theory']"
1006127,"Closed form of $\mathscr{R}=\int_0^{\pi/2}\sin^2x\,\ln\big(\sin^2(\tan x)\big)\,\,dx$","Inspired by Mr. Olivier Oloa in this question . Does the following integral admit a closed form? \begin{align}
\mathscr{R}=\int_0^{\Large\frac{\pi}{2}}\sin^2x\,\ln\big(\sin^2(\tan x)\big)\,\,dx
\end{align} It will be my last question before I take a long break from my activity on Mathematics StackExchange. So, please be nice. No more downvotes for no reason because this is a challenge problem . Edit : I am also interested in knowing the numerical value of $\mathscr{R}$ to the precision of at least $50$ digits. If you use Mathematica to find its numerical value, please share your method & the code.","['closed-form', 'calculus', 'integration', 'real-analysis']"
1006140,Evaluating $\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}}$ [duplicate],"This question already has answers here : Evaluating $\lim_{n\to \infty}\frac1{2n}\log\left({2n \choose n}\right)$ [duplicate] (3 answers) Closed 9 years ago . I am trying to evaluate $$\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}},$$ which came from trying to find the radius of convergence of the complex power series $$\sum_{n\ge0} z^{2n}\frac{\sqrt{(2n)!}}{n!}$$ In the limit I we have some cancellation: $$\frac{(2n!)}{n!^2}=\frac{1\cdots n\cdot (n+1)\cdots(2n)}{1\cdots n\cdot 1\cdots n}=\frac{(n+1)\cdot(2n)}{1\cdots n},\,\,\,(*)$$
and the right hand side is less than $2^n$, so an upper bound on the limit is $$(2^n)^{\frac{1}{4n}}=2^{1/4}$$
The right hand side of $(*)$ is at least $1$, so I have the bounds $1,2^{1/4}$, but I don't know how to get a better estimate. How can I compute this limit?",['limits']
1006156,Why are some convergent Lebesgue integrals 'undefined'? [duplicate],"This question already has answers here : Why do we restrict the definition of Lebesgue Integrability? (8 answers) Closed 9 years ago . I sometimes read statements such as The integral $$\int_0^{\infty} dx \, \frac{\sin x}{x}  $$ does not exist as a Lebesgue integral, because it is not absolutely convergent. But according to my understanding, the integral
$$\int_0^{R} dx \, \frac{\sin x}{x}  $$
exists as a Lebesgue integral for every $R>0$. Why can't we simply define
$$
\int_0^{\infty} dx \, \frac{\sin x}{x}  = \lim\limits_{R \rightarrow \infty} \int_0^{R} dx \, \frac{\sin x}{x},  
$$
and hence give meaning to the former integral as a Lebesgue integral? Isn't this also how one defines improper Riemann integrals, as a limit of proper integrals? Please point out any misunderstandings.","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'integration']"
1006165,Binomial Coefficient Combinations,"I have tried to figure this out and I cannot. The professor gave us an answer of 13,536 but I do not see any way in which he got to his answer. Any help would be greatly appreciated. A certain classroom has two rows of seats. The front row contains 8 seats and the back row contains 10 seats. How many ways are there to seat 15 students if a certain group of 4 or them refuses to sit in the front row?","['statistics', 'permutations', 'combinatorics']"
1006175,Confusion about superposition principle of the PDE and Boundary Condition of an ODE.,"I want to solve a PDE like this: $\frac{\partial y}{\partial t}=a\frac{\partial ^2y}{\partial x^2}-b\frac{\partial y}{\partial x}-c y,(a,b,c\in \mathbb{R})\tag{1}$ with the boundary conditions: $
\begin{equation}\begin{cases}
y|_{x=0}=y_0+y_1 \cos (\text{$\omega $t})\\
y|_{x\rightarrow +\infty }=y_2\\
\end{cases}\
\tag{2}
\end{equation}\
$ In the second BC, $y_2\neq 0$ I uncoupled the problem using superposition principle into two sub problems: $
\begin{equation}\begin{cases}
\frac{\partial y}{\partial t}=a\frac{\partial ^2y}{\partial x^2}-b\frac{\partial y}{\partial x}-c y\\
y|_{x=0}=y_0\\
y|_{x\rightarrow +\infty }=y_2\\
\end{cases}
\tag{3}
\end{equation}
$ and $
\begin{equation}\begin{cases}
\frac{\partial y}{\partial t}=a\frac{\partial ^2y}{\partial x^2}-b\frac{\partial y}{\partial x}-c y\\
y|_{x=0}=y_1 \cos (\text{$\omega $t})\\
y|_{x\rightarrow +\infty }=0\\
\end{cases}
\tag{4}
\end{equation}
$ I have 3 questions: Is this uncoupling correct? If not, how can I use superposition principle to uncouple this problem? If the actual system is only changed by $\cos (\text{$\omega $t})$. In other words, if there's no $\cos (\text{$\omega $t})$ term, the system is in steady state. On this occasion can I write sub problem(3) like this: 
$
\begin{equation}\begin{cases}
0=a\frac{\partial ^2y}{\partial x^2}-b\frac{\partial y}{\partial x}-c y\\
y|_{x=0}=y_0\\
y|_{x\rightarrow +\infty }=y_2\\
\end{cases}
\tag{5}
\end{equation}
$ The problem(5) is actually an ODE. If I solve it, I get into trouble. The general solution of the ODE is: 
$y=C_1 \exp \left(\frac{b+\sqrt{4 a c+b^2}}{2 b}\right)+C_2 \exp \left(\frac{b-\sqrt{4 a c+b^2}}{2 b}\right)\tag{6}$
But I cannot deal with the second boundary condition. The first term of the general solution tend to positive infinity and the second term tend to zero. No matter what the value of $C_1$ and $C_2$ is, the condition is not satisfied. Does this trouble imply that I cannot set the boundary condition like $y|_{x\rightarrow +\infty }=y_2$? I wonder if the BC here can only be set like: $y|_{x\rightarrow +\infty }=0$ or $\left.\frac{\partial y}{\partial x}\right|_{x\rightarrow +\infty }=0$?","['boundary-value-problem', 'ordinary-differential-equations', 'partial-differential-equations']"
1006181,Interesting Gradient problem? Don't know how to write it?,"if $p=q+\varepsilon v$, where $v=\dfrac{\nabla f(q)}{\|\nabla f(q)\|}$. $f(q)=0$.  $\nabla f(x) $ is not $0$ on the domain. How to prove there exists $\varepsilon_1>0$ such that if $\varepsilon_1>\varepsilon>0$, then $f(p)>0$? I know gradient direction is the fastest increasing direction, so by the condition given, it seems obvious. How to write it rigorously?","['calculus', 'partial-differential-equations', 'analysis']"
1006205,Calculate difficult Fourier Transform,"I have to calculate a quite difficult Fourier Transform for my class
$$\int_{-\infty}^\infty dw\frac{(\varGamma-iw)w^3}{(\varGamma-iw)^2+1}\frac{J_{1}(|wr|)}{|wr|}e^{-iwt}$$
$J_1$ is the normal Bessel function of first order. Please help me.","['fourier-analysis', 'analysis']"
1006221,How to derive the following from Azuma's inequality?,"This is claimed in Proposition 1 in the paper http://arxiv.org/abs/1409.6110 Let $A$ be a $n \times d$ matrix. $A$ can have only $K$ different types of rows i.e. rows of $A$ are chosen from a  set of $K$ vectors in $\mathbb{R}^d$ . $A$ is not random. Consider the model $$r = A\theta^* + e$$ where each $e_i$ is iid, mean 0, and bounded in $[-\sigma,\sigma]$ . Let $\hat{\theta}$ be the least squares estimate of $\theta^*$ i.e. $$\hat{\theta} = \arg \min_\theta \|A\theta-r\|^2$$ or $\hat{\theta} = (A^T A)^{-1} A^T r$ . The result claims that for $x$ chosen from the set of $K$ vectors, we have for any $n \in \mathbb{N}$ $$P\left(\left| x^T \theta^* - x^T \hat{\theta} \right| \leq c \|x\|_{(A^T A)^{-1}}\sqrt{\log (c'n^2 K/\delta)}\right) \geq 1-\delta$$ where $c = 2\sigma\sqrt{2}$ and $c'=6/\pi^2$ . Any idea how I can prove this? Apparently it can be proved using Azuma's inequality. I don't even know where to start, I would appreciate any ideas/hints.","['inequality', 'probability-theory', 'concentration-of-measure', 'linear-algebra', 'probability']"
1006252,Is there a measure of 'evenness' of dispersion?,"I looked up on the web, but couldn't find anything helpful. I'm basically looking for a way to measure how 'evenly' a value is distributed. As in, an 'evenly' distributed distribution like X : and an 'unevenly' distributed distribution Y of roughly the same mean and standard deviation: But is there any evenness measure m, such that m(X) > m(Y)? If there isn't, what would be the best way to create a measure like that? (Images screenshot from Khan Academy)","['statistics', 'standard-deviation', 'descriptive-statistics']"
1006256,"Are two random vectors independent, iff every pair of components from each vector are independent?","Let $X$ and $Y$ be two random vectors in $\mathbb R^n$. Are $X$ and $Y$  independent, iff any component $X_i$ of $X$ and any component $Y_j$ of $Y$ are independent? If not, is it true when $X$ and $Y$ are both normally distributed? If not, is it true when $X$ and $Y$ are jointly normal distributed? Thanks.","['probability-theory', 'probability']"
1006267,"$\mathbb{Z}$ homeomorphic to $X=\left\{ 1, \frac{1}{2}, \frac{1}{3},... \right\}$?","Is $\mathbb{Z}$ homeomorphic to $X=\left\{ 1, \frac{1}{2}, \frac{1}{3},... \right\}$? (Each set is equipped with the subspace topology induced by $\mathbb{R}$) I would assume that the answer is yes, since they are both discrete (so every subset is open) and have the same cardinality. Is this sufficient?",['general-topology']
1006293,Is the square-wheeled tricycle at MoMath stable?,"My question has to do with the geometry of the square-wheeled tricycle ride Pedal on the Petals at the National Musuem of Mathematics in New York (MoMath). The tricycles ride on a circular track (see video or pictures below), whose surface forms what I might call a fanned catenary. Note that the inner wheels of the tricycles are smaller squares than the outer wheels, in order that they fit the smaller track length there. Note also that the two rear wheels each have their own axle, and the smaller inner wheel axle is correspondingly lower, although they are geared so that they turn together at the same angular rate. Thus, the two wheels turn in unison, with their corners sinking into the crevices between the catenary pieces at the same time. Another detail is that the turn angle of the tricycle is fixed — the rider cannot steer. The point of the exhibit, of course, is that despite the square wheels and bumpy road, the tricycles offer a smooth ride around the course. Each axle stays the same distance above the floor as it turns, because the uneven track exactly makes up for the change in the radius of the square as it turns. My question has to do with the observation that each tricycle operates properly only at a certain fixed radius from the center of the track, namely, the radius at which the circumference of the wheels matches that of the track surface. If you look in the photos, you can see that this radius is marked on the track with a solid red center line for the front wheel and dashed lines for the rear wheels. The wheels have a rubber surface that does not slip on the surface of the track. Question. Is the geometry of this arrangement stable under small perturbations? In other words, it seems inevitable that the tricycles will get bumped in some way or pushed a little off their line, and then the wheels will no longer exactly fit the track. Will the precise way that they don't fit tend to force them back onto the track properly? 
And what if the fixed angle of the steering is a little off? Will the operation of the tricycle simply force it back into place? Looking at the operation of the exhibit in practice, it seems to be fairly stable, and I have never seen a rider simply get stuck. I asked the guy running the exhibit at MoMath, but he made only a non-committal answer, although he did suggest that it might be at least a little stable. I am hoping that someone with a strong geometrical sense will be able to explain to me why the tricycles seem to operate smoothly even when subject to random forces of kids jostling them.","['geometry', 'recreational-mathematics']"
1006299,Convergence in Total Variation Implies Convergence in Distribution,"Suppose $X,Y$ are random variables. We define the total variation distance of random variables to be $d(X,Y)= \inf \{P(|X′−Y′|>0): X′,Y′$ are couplings of $ X,Y$ respectively$\}$. Does convergence in total variation imply convergence in distribution? My feeling is that it should but I'm having trouble proving it. Thanks!","['measure-theory', 'probability']"
1006322,"Why is the character group defined as $\mathsf{Hom}(G,\mathbb T)$, i.e why is the codomain specifically $\mathbb T$?","In the paper Category Theory Applied to Pontryagin Duality by Roeder, the character group of an lca group is defined as the topological (under the compact-open topology) abelian group of continuous homomorphisms from $G$ to $\mathbb {T}=\mathbb R/\mathbb Z$. Why does the definition specifically involve $\mathbb{T}$? What is special about it and why is the class of continuous homomorphisms from some group to $\mathbb{T}$ more informative (if it is) than to some other group?","['topological-groups', 'abelian-groups', 'characters', 'group-theory', 'locally-compact-groups']"
1006325,"A Learning Roadmap to the ""foundations"" of Nonlinear Analysis (and certain specific topics)","I'm searching for throughout references that -- in the long term -- can help me gradually gain a solid background and firm foundations to understand the main methods and theorems to deal with nonlinear problems (in particular, wave equations, solitary wave solutions (solitons) , nonlinear elliptic and hyperbolic PDEs,  periodic solutions of Lagrangian and Hamiltonian Systems , etc .) that arise in science (specifically, mathematical and theoretical physics ). The following textbooks caught my attention: Zdzislaw Denkowski, Stanislaw Migórski, and Nikolaos S. Papageorgiou, An
Introduction to Nonlinear Analysis: Theory ; Antonio Ambrosetti and Giovanni Prodi, A Primer of Nonlinear Analysis ; Antonio Ambrosetti and David Arcoya, An Introduction to Nonlinear Functional Analysis  and Elliptic Problems ; Abdul-Majid Wazwaz, Partial differential equations and solitary waves theory ; Herbert Koch, Daniel Tataru, and Monica Vişan, Dispersive Equations and Nonlinear Waves ; Kung Ching Chang, Methods in Nonlinear Analysis . I would like to receive some advice from the experienced researchers in nonlinear analysis and mathematical physics of Mathematics Stack Exchange : Question: How should I go about learning nonlinear analysis? That is, assuming knowledge of real analysis, what resources and what kind of approach (and order) to read through them would you
    recommend to build a solid knowledge of nonlinear analysis?","['partial-differential-equations', 'nonlinear-analysis', 'mathematical-physics', 'reference-request', 'analysis']"
1006350,Showing countable additivitiy of Lebesgue measure,"The following is taken from the classic Probability and Measure by Patrick Billingsley, Theorem 2.2 (page 26 in the 3rd edition). I have a question on his proof, but I give the necessary defintions to make my question self-contained. Denote by $\mathcal B_0$ the field of all finite unions of half-open sub-intervals $(a,b]$ of $(0,1]$, i.e. it is a system of sets containing all half-open sub-intervals of $(0,1]$ and closed under finite intersection and complementation (and therefore also finite unions). It is easy to see that $\mathcal B_0$ is exactly the set
$$
 \mathcal B_0 = \left\{ \bigcup_{i=1}^n (a_i, b_i] : (a_i, b_i] \subseteq (0,1] ~ \mbox{disjoint} \right\}
$$
of all subsets of $(0,1]$ that could be written as finite unions of disjoint subintervals of $(0,1]$. The following property is needed in the following: If $I = \bigcup_k I_k$ and the $I_k$ are disjoint, then $|I| = \sum_k |I_k|$. (*) Then define a mapping $\lambda : \mathcal B_0 \to [0,1]$ by
$$
 \lambda(A) = \sum_{i=1}^n (b_i - a_i).
$$
Then $\lambda : \mathcal B_0 \to [0,1]$ is countable additive , i.e. we have for $A \in \mathcal B_0$ and $A_1, A_2, \ldots \in \mathcal B_0$ disjoint and $A = \bigcup_{k=1}^{\infty} A_k$
$$
 \lambda(A) = \lambda(\bigcup_{k=1}^{\infty} A_k) = \sum_{k=1}^{\infty}\lambda(A_k).
$$ Proof: Suppose that $A = \bigcup_{k=1}^{\infty} A_k$, where $A$ and the $A_k$ are $\mathcal B_0$-sets and the $A_k$ are disjoint. Then $A = \bigcup_{i=1}^n I_i$ and $A_k = \bigcup_{j=1}^{m_k} J_{kj}$ are disjoint unions of subintervals of $(0,1]$, and the above, and (*) give \begin{align*}
 \lambda(A) & = \sum_{i=1}^{n} |I_i| = \sum_{i=1}^n \sum_{k=1}^{\infty} \sum_{j=1}^{m_k} |I_i \cap J_{kj}| \\
 & = \sum_{k=1}^{\infty} \sum_{j=1}^{m_k} |J_{kj}| = \sum_{k=1}^{\infty} \lambda(A_k).
 \qquad \square
\end{align*} To quote the book: [...] proving countable additivity on $\mathcal J$ [i.e. the set of all subintervals of $(0,1]$] requires the deeper property of compactnness. Where exactly is compactness used in the above proof? I do not see where it is applied.","['measure-theory', 'probability-theory', 'analysis', 'lebesgue-measure', 'probability']"
1006352,Calculate $\lim_{n\rightarrow +\infty}\binom{2n} n$,"Calculate
$$\lim_{n\rightarrow +\infty}\binom{2n} n$$
without use Stirling's Formula. Any suggestions please?","['calculus', 'binomial-coefficients', 'real-analysis', 'limits']"
1006354,Probability of passing this multiple choice exam [duplicate],"This question already has answers here : Probability in multiple choice exams (2 answers) Closed 9 years ago . A multiple choice exam has 175 questions. Each question has 4 possible answers. Only 1 answer out of the 4 possible answers is correct. The pass rate for the exam is 70% (123 questions must be answered correctly). We know for a fact that 100 questions were answered correctly. Questions: What is the probability of passing the exam, if one were to guess on the remaining 75 questions? That is, pick at random one of the 4 answers for each of the 75 questions.",['probability']
1006445,"Proving $(0,1)$ and $[0,1]$ have the same cardinality [duplicate]","This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Bijection between an open and a closed interval (4 answers) Closed 9 years ago . Prove $(0,1)$ and $[0,1]$ have the same cardinality. I've seen questions similar to this but I'm still having trouble.  I know that for $2$ sets to have the same cardinality there must exist a bijection function from one set to the other.  I think I can create a bijection function from $(0,1)$ to $[0,1]$, but I'm not sure how the opposite.  I'm having trouble creating a function that makes $[0,1]$ to $(0,1)$.  Best I can think of would be something like $x \over 2$. Help would be great.","['discrete-mathematics', 'elementary-set-theory']"
1006454,"Will any two elements of orders 4 and 6 generate SL(2,Z)?","Ie, if $A,B$ are matrices in $\text{SL}_2(\mathbb{Z})$ with orders 4 and 6 respectively, is $\text{SL}_2(\mathbb{Z}) = \langle A,B\rangle$?",['group-theory']
1006461,"Why is $e^{-f(z)} = 1-z$, when $f(z)=\sum_{n=1}^\infty \frac{z^n}{n}$?","Why does the following hold?
    $$e^{-f(z)} = 1-z$$
where $f(z)$ is defined as:
    $$f(z)=\sum_{n=1}^\infty \frac{z^n}{n}$$
Clearly, $f'(z)=\sum_{n=2}^\infty z^n =\frac{1}{1-z}$ by the known sum of geometric series, so the question is similar to:
    $$e^{f(z)} = f'(z)$$
Thanks in advance.",['complex-analysis']
1006492,Proof of Multivariable Implicit Differentiation Formula,"If the equation $F(x,y,z)=0$ defines $z$ implicitly as a differentiable function of x and y, then by taking a partial derivative with respect to one of the independent variables (in this case x), you get $\large F_x(x,y,z)\frac{\partial x}{\partial x}+F_y(x,y,z)\frac{\partial y}{\partial x}+F_z(x,y,z)\frac{\partial z}{\partial x}=0.$ Because dx/dx = 1 and dy/dx = 0 , you can solve for the desired partial derivative: $\large \frac{\partial z}{\partial x}=-\frac{F_x(x,y,z)}{F_z(x,y,z)} $ The bolded dy/dx = 0 is what I don't get. I mean, it makes sense that an independent variable doesn't change in response to another, but it doesn't seem very formal and I feel like there's more to it than that. So basically, is there a more formal or detailed explanation or is that all there is to it?","['multivariable-calculus', 'implicit-differentiation', 'calculus']"
1006493,Why is this operator self-adoint,"We have that $\lambda, \overline{\lambda} \in \rho(T)$ and $\lambda \in \mathbb{C}$. Now, I want to show that a symmetric operator and closed operator $T: \operatorname{dom(T)} \rightarrow H$ must be self-adjoint. Notice, that $T$ is not necessarily densily defined. Does anybody here have any ideas? Actually, I concluded the closedness of this operator from the fact that the resolvent is not empty by myself, so this may be somehow a tautology in this exercise.","['operator-theory', 'functional-analysis', 'real-analysis']"
1006500,Find the closed form of the gamma function related series,"I see a possible way of computing  the series by using integrals, but I wonder if it possible to avoid the use of them, to get a neat evaluation by only using series. Compute $$\sum_{n=1}^{\infty} (-1)^{n+1}\log\left(\frac{\displaystyle \Gamma\left(\frac{n+2}{2}\right)\displaystyle\Gamma\left(\frac{n}{2}\right)}{\left(\displaystyle\Gamma\left(\frac{n+1}{2}\right)\right)^2}\right)$$ And here is a supplementary question $$\sum_{n=1}^{\infty} (-1)^{n+1}\psi^{(0)}(\alpha n)\log\left(\frac{\displaystyle \Gamma\left(\frac{n+2}{2}\right)\displaystyle\Gamma\left(\frac{n}{2}\right)}{\left(\displaystyle\Gamma\left(\frac{n+1}{2}\right)\right)^2}\right),\space \alpha >0$$","['sequences-and-series', 'calculus', 'integration', 'real-analysis']"
1006526,"GRE basic algebra problem, plugging in works, algebreic method fails me","Simple GRE practice problem, but for some reason my algebraic approach is failing me, can someone point out my error? Given:  $$\theta x = x^{-3}(2x)(\frac{x}{2})(2)$$ Question: Which is greater: $\theta 8$ or $\theta 4$ I approached it by solving for theta: $$\theta x = x^{-3}(2x)(x)$$
$$\theta x = \frac{2x^2}{x^3}$$
$$\theta x = \frac{2}{x}$$
$$\theta = \frac{2}{x^2}$$ Then plug in for $\theta 8$ and $\theta 4$:
$$\theta * 8 = \frac{2}{x^2} (8) = \frac{16}{x^2}$$
$$\theta * 4 = \frac{2}{x^2} (4) = \frac{8}{x^2}$$ For any value of $x$, other than $0$, $\theta 8$ is larger. But clearly amiss here, because the opposite is true, if I plug in $\theta 8$ directly I get: $$\theta 8 = 8^{-3}(2*8)(\frac{8}{2})(8) = \frac{1}{4}$$
$$\theta 4 = 4^{-3}(2*4)(\frac{4}{2})(4) = \frac{1}{2}$$ Now it's clear that $\theta 4$ is larger. Ooff! for the life of me I don't see why my algebraic approach failed. How'd I get myself into this quandary? And more importantly, how do I get out using algebra?","['algebra-precalculus', 'gre-exam']"
1006540,A question in representations theory,"My question is about irreducible representations of groups over the field $\mathbb{Q}$. Let $G$ be a cyclic or an abelian group. I want to check that under what conditions we have a $\mathbb{Q}G$-module that is irreducible.
Because $\operatorname{char} \mathbb{Q}=0$, by Maschke 's theorem , we know that every $\mathbb{Q}$-representation of G is com­pletely  reducible. Although, because $\mathbb{Q}$ is not algebraically closed, we can not say that every irreducible $\mathbb{Q}$-representations of an abelian group has degree 1. Specially, I want to find a faithful irreducible $\mathbb{Q}$-representation of degree $\phi(n)$ (where $\phi$ is Euler's function) for a cyclic group of order $n$. I know that I should use $n^{th}$ roots of unity but I don't know how I can move this representation to $\mathbb{Q}$. Thanks a lot.","['representation-theory', 'group-theory']"
1006552,Show that random walk is a random variable,"I am working on this question. Suppose $\{X_n, n \ge 1\}$ are random variable on the probability
  space $(\Omega, \mathcal{B},P)$ and define the induced random walk by 
  \begin{align*} S_0=0, \, S_n=\sum_{i=1}^n X_i, \, n \ge 1 \end{align*}
  Let  \begin{align*} \tau:=\inf \{n>0: S_n>0 \} \end{align*} be the 
  first upgoing ladder time. Prove that $\tau$ is a random variable.
  Assume we know $\tau(\omega) < \infty$ for all $\omega \in \Omega$.
  Prove $S_{\tau}$ is a random variable. What I tried. 
So, I know some thing is a random variable if it is measurable or 
\begin{align}
[X \le  \lambda] \in \mathcal{B} \text{ for all } \lambda \in \mathbb{R}
\end{align}
If we apply this to $\tau$ we get
\begin{align*}
&\{\tau \le \lambda\}=\{\inf \{n>0: S_n>0 \}  \le \lambda\}
\\&= \left\{\inf \{n>0: \sum_{i=1}^n X_i>0 \}  \le \lambda\right\}
\end{align*}
I am stuck now what should I do next?","['measure-theory', 'probability']"
1006610,How many strings of five ASCII characters contain the character @ (“at” sign) at least once?,"I'm given the question: ""How many strings of five ASCII characters contain the
character @ (“at” sign) at least once?"" Note: There are 128 different ASCII characters. I realized I'd have to use rule of product and sum on this one right away. I approached it by figuring out 5 cases and summing them to get the answer. Case I: @ is contained once in the string I have to pick the position of @ which can be done in 5 ways. Then I have to pick the remaining 4 characters which can be done in $127^4$ ways. $5 * 127^4$ ways to do this case Case II: I have to pick the position of the first @ (5 ways to do that) then the position of the second @ (4 ways to do that) then $127^3$ ways to pick the remaining characters from the string. $5*4*127^3$ ways to do this step Case III: I have to pick the position of the first second and third @. Then I have to pick the remaining $2$ characters. $5*4*3*127^2$ ways to do this step. Case IV: I have to pick the position of first,second,third, and fourth @. Then I have to pick the last character. $5*4*3*2*127$ ways to complete this step. Case V: The whole string is @. Only one way to do this step. I summed all my cases and the result was $1,342,673,846$ the back of the book gave the answer $1,321,368,961$. Where did I go wrong?","['discrete-mathematics', 'combinatorics']"
1006615,Laurent-series expansion of $1/(e^z-1)$,"Find the Laurent series for the given function about the indicated point. Also, give the residue of the function at the point.
$$
z\mapsto\frac{1}{e^z - 1} 
$$
The point is $z_0=0$ (four terms of laurent series). I have wrote $e^z -1$ as $z+z^2/2!+z^3/3!$.... Now i don't know how to proceed with this further. Please answer in detail I am very weak with this. Thank you.","['laurent-series', 'calculus', 'complex-analysis']"
1006637,Setting up a Green's Theorem Problem where C is not oriented counterclockwise,"Use Green's Theorem to evaluate $\mathbf{F}(x,y)=\langle y^{2}\cos x, x^{2}+2y\sin x\rangle$, where $C$ is the triangle from $(0,0)$ to $(2,6)$ to $(2,0)$ to $(0,0)$. Taking the appropriate partial derivatives, I have my integral set up as $\displaystyle \int_{C}y^{2}\cos x\, dx +(x^{2}+2y\sin x)\,dy = \displaystyle \int_{2}^{0}\int_{0}^{3x}2x\, dy\, dx$.  My reasoning for the order of the limits of integration was that since we are going from 2 to 0 along the bottom edge of the triangle, the $dx$ integral should have limits of integration from 2 to 0. For the $dy$, integral, however, I'm not quite as sure.  In the y-direction, it seems as though we're going from 0 to $3x$, because of how the curve is oriented along the hypotenuse. But, I'm second-guessing myself - I still don't feel like I have the hang of setting these problems up, so if you could 1) tell me whether I'm right, and 2) if I'm not right, explain to me why, so I don't make the same mistake again.","['multivariable-calculus', 'calculus', 'vector-analysis']"
1006680,Determining whether a differential equation is separable,"The differential equation $y' = 3y − 2x + 6xy − 1$ is separable. The differential equation $y' = x + 2y$ is NOT separable. I can see why the second equation is not separable, but why is the first equation separable?",['ordinary-differential-equations']
1006699,"Counterexample to the set of all algebraic polynomials being dense in $[0,1]$","Today in class the professor said that if we consider $X = [0, 1]$ to be equipped with the Lebesgue measure, then  the set of all algebraic polynomials is not dense in $L^\infty([0, 1])$. But I couldn't come up with a counterexample to convince myself. Could someone come up with one?","['functional-analysis', 'real-analysis']"
1006707,How to compute the following integral in $n$ variables?,"How can the following integral be calculated:
$$
I_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1-\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n
$$
There should be $n$ integral signs, but I didn't know how to write that. It is easy to show that $I_1=\ln(2)$. After partial fractioning and the help of Wolfram Alpha, I managed to show that $I_2=4\ln(2)-2\ln^2(2)-\frac{\pi^2}{6}$. But how to derive a general result? Any help would be highly appreciated! Edit: As a supplementary question, how to calculate this slightly modified integral:
$$
J_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1+\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n
$$
Again, it can be shown easily, that $J_1=1-\ln(2)$.","['calculus', 'products']"
1006721,Find the degree $[E:\mathbb{Q}]$,"Let $p$ a prime number. Find a splitting field $E$ of the polynomial $x^p-2 \in \mathbb{Q}[x]$. I have done the following: The solutions of $x^p-2=0$ are :
$$\sqrt[p]{2}, \sqrt[p]{2}\omega, \dots, \sqrt[p]{2}\omega^{p-1}, \text{ where } \omega=e^{\frac{2 \pi i}{p}}$$ Therefore, the splitting field is $E=\mathbb{Q(\sqrt[p]{2}, \omega)}$ Is this correct so far?? How can I find the degree $[E:\mathbb{Q}]$ ?? EDIT: $[E:\mathbb{Q}]=[\mathbb{Q(\sqrt[p]{2}, \omega)} : \mathbb{Q}]=[\mathbb{Q(\sqrt[p]{2}, \omega)} : \mathbb{Q}(\sqrt[p]{2})][\mathbb{Q(\sqrt[p]{2})} : \mathbb{Q}]=[\mathbb{Q(\sqrt[p]{2}, \omega)} : \mathbb{Q}(\sqrt[p]{2})]p$ Since $Irr(\sqrt[p]{2}, \mathbb{Q})=x^p-2 \Rightarrow [\mathbb{Q(\sqrt[p]{2})} : \mathbb{Q}]=p$. But how can we find $[\mathbb{Q(\sqrt[p]{2}, \omega)} : \mathbb{Q}(\sqrt[p]{2})]$ ?? EDIT: Proof that the degree is the product of p and p-1: $$[\mathbb{Q}(\omega, \sqrt[p]{2}) :\mathbb{Q}]=[\mathbb{Q}(\omega, \sqrt[p]{2}):\mathbb{Q}(\sqrt[p]{2})][\mathbb{Q}(\sqrt[p]{2}):\mathbb{Q}]=a \cdot p$$ $$[\mathbb{Q}(\omega, \sqrt[p]{2}):\mathbb{Q}]=[\mathbb{Q}(\omega, \sqrt[p]{2}):\mathbb{Q}(\omega)][\mathbb{Q}(\omega):\mathbb{Q}]=b \cdot (p-1)$$ $$a \cdot p = b \cdot (p-1) \Rightarrow p \mid a \cdot p \overset{(p, p-1)=1}{ \Longrightarrow } p \mid b \Rightarrow p \leq b \tag 1 $$ $$\Rightarrow a \cdot p \leq a \cdot b \Rightarrow b \cdot (p-1) \leq a \cdot b \Rightarrow p-1 \leq a \tag 2 $$ $$\mathbb{Q} \leq \mathbb{Q}(\omega) \leq \mathbb{Q}(\omega, \sqrt[p]{2}) \Rightarrow Irr(\sqrt[p]{2}, \mathbb{Q}(\omega)) \mid Irr(\sqrt[p]{2}, \mathbb{Q}) $$ $$\Rightarrow \deg Irr(\sqrt[p]{2}, \mathbb{Q}(\omega)) \leq \deg Irr(\sqrt[p]{2}, \mathbb{Q}) \Rightarrow b \leq p \tag 3$$ $$\mathbb{Q} \leq \mathbb{Q}(\sqrt[p]{2}) \leq \mathbb{Q}(\omega, \sqrt[p]{2}) \Rightarrow Irr(\omega, \mathbb{Q}(\sqrt[p]{2})) \mid Irr(\omega, \mathbb{Q}) $$ $$ \Rightarrow \deg Irr(\omega, \mathbb{Q}(\sqrt[p]{2})) \leq \deg Irr(\omega, \mathbb{Q}) \Rightarrow a \leq p-1 \tag 4$$ From $(1)$ and $(3)$ we have that $b=p$ and from $(2)$ and $(4)$ we have that $a=p-1$ Therefore, $[\mathbb{Q}(\omega, \sqrt[p]{2}) :\mathbb{Q}]=p(p-1)$.","['splitting-field', 'abstract-algebra', 'field-theory']"
1006735,Inconsistency in two-sided hypothesis testing,"Suppose you have two sets of data with known population variances and want to test the null hypothesis that two means are equal, ie. $H_{0}: \mu_{1} = \mu_{2}$ against $H_{1}: \mu_{1} > \mu_{2}$. There's a certain way I want to think about it, which is the following: \begin{align}
P(\mu_{1} > \mu_{2}) &= P(-(\mu_{1} - \mu_{2}) < 0) \\
&= P\left(\frac{\bar{x}_{1} - \bar{x}_{2} - (\mu_{1} - \mu_{2})}{\sigma_{\delta \bar{x}}}<\frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}} \right) \\
&=P\left(z < \frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}}  \right)
\end{align} To me, this 'derivation' makes it perfectly clear what's actually going on. You're actually calculating the probability that $H_{1}$ is true and not just blindly looking up some $z$-score. However, now suppose that $H_{1}: \mu_{1} \neq \mu_{2}$. The problem with this is that the method I just described doesn't seem to work. If I write $$
P(\mu_{1} \neq \mu_{2}) =  P(\mu_{1} < \mu_{2}) + P(\mu_{1} > \mu_{2})
$$ Then all that happens is $P(\mu_{1} \neq \mu_{2}) = 1$. I think I'm probably not interpreting the above equation correctly.",['statistics']
1006785,"If $X < a$, $EX < a$?","If a r.v. $X < a$, does it imply $EX < a$? If not, why is it different from what I know: If a r.v. $X \leq a$,
it  implies $EX \leq a$, proved by replacing $X$ with $a$ as the integrand. Note that $a \in \mathbb R$. If it allows that $a= \infty$, the
answer is no: if $X$ has a Pareto distribution with $α=1$, then $X <
\infty$, but $EX = \infty$, from http://en.wikipedia.org/wiki/Pareto_distribution and https://stats.stackexchange.com/a/91515/1005 .
How can we explain that difference? Thanks.","['probability-theory', 'probability', 'real-analysis']"
1006794,"f is continuous, show that f(closure) is a subset of closure of f","If $f:X\rightarrow Y$ is continuous and $E\subset X$, prove that $f(\overline{E})\subset \overline{f(E)}$. Provide an example to show that the inclusion does not have to be equality. So far what I have is that the preimage of a closed set in $Y$ is closed in $X$. So $f^{-1}(\overline{f(E)})$ is closed and contains $E$.",['real-analysis']
1006836,How prove this integral inequality $\int_{0}^{\infty}(f(t))^2t^{-\delta}dt\le\frac{4}{(1-\delta)^2}\int_{0}^{\infty}(f'(t))^2t^{2-\delta}dt$?,"Question: let $\delta\in(0,1)$, and $f\in C_{0}^{1}(R_{+})$,show that
  $$\int_{0}^{\infty}(f(t))^2t^{-\delta}dt\le\dfrac{4}{(1-\delta)^2}\int_{0}^{\infty}(f'(t))^2t^{2-\delta}dt$$ My idea:
I think we must use Cauchy-Schwarz inequality $$\int_{0}^{\infty}(f'(t))^2t^{2-\delta}dt\int_{0}^{\infty}t^{-2-\delta}dt
\ge\left(\int_{0}^{\infty}f'(t)t^{-\delta}dt\right)^2$$ But I can't know this  coefficient 
$\dfrac{4}{(1-\delta)^2}$ How do have it?  Thank you","['integral-inequality', 'analysis']"
1006839,Subgroup notation on Wikipedia,"Surfing wikipedia about finite groups, I see a lot of notation similar to that found in this section (image below). 
Its meaning is not clear to me and I didn't find an explanation on wikipedia. Could anyone elaborate?","['notation', 'reference-request', 'finite-groups', 'group-theory']"
1006846,"Arguing the correctness of an alternative, way to count how many bit sequences with exactly n zeroes and k+1 ones are there","I was trying to count how many bit sequences with exactly n zeroes and k+1 ones are there. One obvious reasoning is just by doing $ \binom {k+n+1}{k+1}$, by doing choose. However, I was told that you could also do it by doing the following summation: $$\sum^{n}_{i=0}\binom {k+i}{k}$$ If that is true then: $$\sum^{n}_{i=0}\binom {k+i}{k} = \binom {k+n+1}{k+1}$$ Which after a lot of algebra that I will omit, can be verified by induction! Incredible. However, I am unsure what is the combinatorial reasoning is. Does someone know how to reason it combinatorially to establish the equality? Can you also justify the correctness of your argument? In fact, I was told that the following is the ""correct"" reasoning, though I can't make sense of why its correct: On the other hand, the number of zeroes i to the left of the rightmost
  one ranges from 0 to n. For a fixed value of i, there are $\binom {k+i}{k}$ possible
  choices for the sequence of bits before the rightmost
  one. If we sum over all possible i, we find that the number we want is $\sum^{n}_{i=0} \binom {k+i}{k}$ My main concern is with the summation. I can't understand the interpretation of the summation. Is it summing over disjoint subsets? Or why is it summing things? The only time I have seen sums in counting is when there are disjoint subsets (or with the inclusion-exclusion principle). Even if you explain me what the interpretation means, I feel it might not be too helpful unless it has an explanation of its correctness . Please provide as much detail on the combinatoric interpretation of the summation, the part of the question that I am having trouble understanding. Thats I guess what is giving me trouble. I fail to see why that description gives the desired equality. For example, one aspect that I would liked addressed is, how come is that sum NOT double counting? As i increases, combinations from previous steps are ""reconsidered""...or not? It seems to me they are. Then if they are, why is that summation NOT double counting? BOUNTY I am not able to put a bounty yet, but the answer that justifies the correctness well enough and convinces me to accept their answer, I will gladly reward you when the times comes. Take it that if there is no accepted answer, I have not yet had my confusion/doubt clarified.","['discrete-mathematics', 'combinatorics']"
1006850,Prove that the sum of harmonic series 1..n can be expressed as (n+1)H_n -n,"Prove by induction that the sum of harmonic series Hn from 1 to n where n is a natural number is as follows.
$$
H_n = \sum\limits_{i=1}^n 1/i 
$$
Prove:
$$
 \sum\limits_{i=1}^nH_i = (n+1)H_n -n 
$$
n=1
$$
H_1 = 1 = (1+1)(H_1) -1 = 2(1)-1 =1
$$
n=k+1
$$
H_{n+1} = H_n +1/(n+1)
$$
$$
H_1 +H_2 +... +H_{n+1} = (n+1 +1 )H_{n+1} -(n+1)
$$
$$
H_1 +H_2 +... +H_{n+1} = (n+2)H_{n+1} -n -1
$$
$$
H_1 +H_2 +... +H_{n+1} = (n+2)H_{n+1} -n -1
$$
$$
H_1 +H_2 +... +H_{n+1} = nH_{n+1} +2H_{n+1} -n -1
$$
$$
H_1 +H_2 +... +H_{n} = nH_{n+1} +2H_{n+1} -n -1 = (n+2)(H_{n+1}) -n -1
$$
$$
H_1 +H_2 +... +H_{n} =(n+2)(H_n +1)/(n+1) -n -1
$$
At this point I get lost.  I've been at this for a while and I don't know if I'm even on the right track, does anyone have a solution.  Did I go wrong anywhere?","['summation', 'discrete-mathematics', 'harmonic-numbers']"
1006855,Evaluate $\lim_{x \rightarrow 0} \frac{(1-\cos x)^2}{\log (1 + \sin^4x)} $,"According to Mathematica, $$\displaystyle\lim_{x \rightarrow 0} \frac{(1-\cos x)^2}{\log (1 + \sin^4x)} = \frac{1}{4}$$ For my purposes it is sufficient to know this limit exists and is finite, but I may not use L'Hopital's rule (or anything relying on differentiability). However, I am stuck on how to show this limit holds. I've tried giving an epsilon-delta proof, but it seems needlessly complicated. Ideally I should be able to show the limit exists using only trig rules, algebra, and eventually reducing this out of being an indeterminate form so that I can simply plug in $0$. However the problem with this is that I can't seem to break the log term. It seems like I would need to factor its argument, but to do so I need to manipulate $1 + \sin^4 x$ so that I can factor it and separate out the terms. But nothing has worked thus far.","['limits-without-lhopital', 'real-analysis', 'limits']"
1006856,"If $f$ is bounded and twice differentiable in $\mathbb{R}$, show that there exists $\xi\in\mathbb{R}$, s.t. $f''(\xi)=0$.","My idea: If $f$ has maximum and minimum, then $f'=0$ at these two points, and the conclusion is further derived using Mean Value Theorem. But what if $f$ has no maximum/minimum, like $f=\frac{1}{1+e^{-x}}$? $f$ is twice differentiable in $\mathbb{R}$, so $f'$ is continuous in $\mathbb{R}$. If $\forall x,y,~f'(x)\neq f'(y)$, then $f'$ is a monotonic function (how to prove this?). 
Then use second-order Taylor approximation to show $f$ is unbounded (inspired by Simon S), which contradicts the assumption. So $\exists x,y,~f'(x)=f'(y)$ and $\exists \xi,~ f''(\xi)=0$ [Mean Value Theorem].",['derivatives']
1006895,Existence of roots of $A_1\sin(\omega_1t+\phi_1)+A_2\sin(\omega_2t+\phi_2)$,"It seems very intuitive that $$f(t)=A_1\sin(\omega_1t+\phi_1)+A_2\sin(\omega_2t+\phi_2)$$ has roots, but how to prove it? $A_i>0$, $\omega_i>0$ and $\phi_i\geqslant0$ (even though these restrictions are not necessary). I'm not able to find $t_1$ and $t_2$ so that $f(t_1)$ and $f(t_2)$ have opposite signs (intermediate value theorem); I tried using complex exponentials but end up with the same expression appearing in the argument; I wrote $\omega_1t+\phi_1=-\arcsin(\dots)$ but it does not help (and the converse requires attention); I considered $f'$ but don't see any perspective. It could be easier to prove if $\dfrac{\omega_1}{\omega_2}\in \mathbb{Q}$, but I'm looking for a general proof. Any clues?","['trigonometry', 'roots', 'real-analysis']"
1006897,Prove that the derived set of a closed is closed,"Suppose $A \subset \mathbb{R}$. Then derived set of $A$, denoted by $A^{\prime}$, is the set of all accumulation points of $A$. Prove that the derived set of a closed set is closed. Attempt: Suppose $A$ is a closed set. Then we have $A=A^{\prime}$. Hence, $A^{\prime}$ is closed by equality. Is this correct? It seems 'too good to be true'.",['general-topology']
1006915,Explaining the purpose of the remaining part of this proof .,"I'm given that:= $E\subseteq \mathbb R^n$ be open and $f:E\to \mathbb R^n$ be a $C^1$ map . Suppose that for some $a\in E$ , the linear map $f'(a)$ is invertible ,and $b=f(a)$ .Then := I've to show that  := There are open set $U$ and $V$ in $\mathbb R^n$ such that $a\in U,b\in V$ and $f|_{U}$ is one-one and onto $V$ i.e. $f(U)=V$ . The proof in my notes involves $1.)$ first proving $f:U\to \mathbb R^n$ is $1$-$1$ . which I understood.. I can't understand the motive of the remaining part of the proof whose outline I'm presenting below: $2.)$ Outline of remaining part of proof : Let $V=f(U)$ then $b=f(a)\in V$ .Then we show that $V$ is open . Let $y_0=f(x_0)\in V $ and let $r\gt 0$ is such that $B=N(x_0,r)\subseteq U$ with $\overline B\subseteq U$. We show that : $N(y_0,\epsilon r)\in V$ and so $y_0$ is interior point of $V$ .Hence,then $V$ is open.. I'll be obliged if there is someone kind enough to explain me the motive behind $2.)$ and also I can't understand why nowhere in the proof did we prove  $f:U\to \mathbb R^n$ is onto , whereas it was proved in the beginning of the proof that it is $1$-$1$.. Thanks in advance for any help...",['multivariable-calculus']
1006920,"If f(x)dx is a rectangle with height f(x) and width dx, what is f(z)dz in complex analysis","I am trying to intuitively understand the multiplication $f(z)dz$ in complex analysis. For instance, $f(x)dx$, we are all aware, is a rectangle with height $f(x)$ and width $dx$ so its multiplication is an area of this rectangle. Is there a similar way to visualize $f(z)dz$ also?","['intuition', 'complex-analysis']"
1006946,"If the coordinate ring $k[V]\simeq k$, is $V$ necessarily a singleton?","Suppose $V$ is a quasi-affine set such that $k[V]\simeq k$, where $k[V]$ is the coordinate ring, and $k$ a field such that $k=\bar{k}$. Does this force $V$ to just be a point? I'm curious because I know that if $V$ consists of $m$ points, then $k[V]\simeq k^m$ as $k$-algebras. So if $V$ is a singleton, then $k[V]\simeq k$, and my question is just the converse. Does something like this make any sense? If $k[V]\simeq k$, then $k\simeq k[\mathbb{A}^n]/I(V)$, so since $k$ is a field, $I(V)$ is maximal, so it corresponds to a point and then $V$ is just a point? Or is it more complicated than that?",['algebraic-geometry']
1006961,Heegaard splitting and mapping class group,"I would like to ask questions about the definition of the Heegaard splitting. The following are the facts I know. A Heegaard splitting says that any 3-manifold is built up from two
  handlebodies and a homeomorphism between boundaries of the
  handlebodies. If $f$ and $g$ are isotopic such homeomorphisms, the 3-manifolds
  obtained are homeomorphic. This is the fact what I know and want to prove it. But I don't know how to prove the second part. How do I show that two isotopic homeomorphisms of boundaries of handlebodies produce the homeomorphic 3-manifolds? Also, more generally, let $M$ and $M'$ be 3-manifolds with boundary. Suppose that $A\subset \partial M$ and $B \subset \partial M'$ are homeomorphic sub manifolds.
Let $f:A \to B$ be a homeomorphism from $A$ to $B$.
We glue $M$ and $M'$ via $f$. Does the homeomorphism class of the resulting manifold depend only on the isotopy class of the homeomorphism $f$? Does the answer of the previous questions depend on what 3-manifolds I want to consider? Like, smooth, topological, piece-wise linear etc. Edit: I am not familiar with ''collar'' in the comment below. I appreciate if one can explain more detail. I also want to know if collar exists for any type of manifolds.","['general-topology', 'low-dimensional-topology']"
1006975,Adjoint Operator and Inverse,"I am solving the following question and I am not really sure about the way I approach Question 1: Assume that $T:U\rightarrow U$ is invertible map. Prove that $(T^*)^{-1}=(T^{-1})^*$ Here is my answer: Notice that $\langle Tv,u\rangle = \langle v, T^*u \rangle$ for all $u,v\in U$ Then  $\langle T^*(T^{-1})^*v,u\rangle = \langle (T^{-1})^* v, Tu \rangle = \langle v,T^{-1}(Tu)\rangle = \langle u,v\rangle$ $T^* (T^{-1})^* = 1 $ so $(T^{-1})^* $ is the inverse of $T^*$. Hence, $(T^{-1})^*=(T^*)^{-1}$. Question 2: Prove that for every operator $T$ the operators $T^*T$ and $T T^*$ are self-adjoint Assumption: I have to prove $T^*T = T$ and $T T^* = T $ Suppose $T\in L (V,W)$. Fix $ w\in W$ . $\langle Tv,u\rangle = \langle v, T^*u \rangle$ for all $u,v\in U$ Then  $\langle TT^*v,u\rangle = \langle ((Tv)T^*,u \rangle = \langle Tv,Tu\rangle $ ?? $\langle T^*Tv,u\rangle = \langle (T^* (Tv),u \rangle = \langle Tv,Tu\rangle$ ??? I am not sure whether I am right or wrong for the above problem so please help me correct the above problem and understand adjoint and self-adjoint.",['linear-algebra']
1007058,Las Vegas algorithm to satisfy most clauses in SAT,"Consider an instance of SAT with $m$ clauses, where every clause has exactly $k$ literals. Give a Las Vegas algorithm (i.e., an algorithm that always gives the correct result) that finds an assignment satisfying at least $m(1-2^{-k})$ clauses, and analyze its expected running time. A possible Las Vegas algorithm is to randomly assign true/false to every variable, each with probability $1/2$. If the assignment satisfies less than $m(1-2^{-k})$ clauses, rerandomize all variables. Keep doing this until we get an assignment satisfying at least $m(1-2^{-k})$ clauses. This is a valid Las Vegas algorithm, but I'm not sure it's one that would be expected by the question. Also, to analyze the expected running time, we would need to compute the probability that a random assignment works. This means the random assignment satisfies at least $m(1-2^{-k})$ clauses, and it doesn't seem easy to compute. What would be a better Las Vegas algorithm?","['satisfiability', 'computer-science', 'probability']"
1007061,"Classify $\mathbb{Z_6} \times \mathbb{ Z_{24}} / \langle(3,2)\rangle$ according to fundamental theorem of finitely generated abelian groups","Classify $\mathbb{Z_6} \times \mathbb{ Z_{24}} / \langle(3,2)\rangle$ according to fundamental theorem of finitely generated abelian groups. The order of $G/H = 12$ So it can be isomorphic to 
$\mathbb{Z_3} \times \mathbb{Z_4}$ or 
$\mathbb{Z_3} \times \mathbb{Z_2} \times \mathbb{Z_2}$ $(0,1)$ has order of 4, 
$(1,0)$ has order of 12,
$(1,1)$ has order of 24 so I'm picking group which has order 4, in this case isomorphic to $\mathbb{Z
_3} \times \mathbb{Z_4}$. a) Is this correct and any other better way to do it? b) If I were to use $3a+2b =0$, how can I find the isomorphic group (not too sure how to do it)? Thanks for the help folks","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
1007071,How to use the Spectral Theorem to Derive $L^{2}(\mathbb{R})$ Fourier Transform Theory,"Without using Fourier transforms, how do I derive the spectral measure for
$A=\frac{1}{i}\frac{d}{dt}$ on the domain $\mathcal{D}(A)$ consisting of absolutely continuous functions $f\in L^{2}(\mathbb{R})$ with $f' \in L^{2}(\mathbb{R})$? Hint: Show $A$ is selfadjoint, and use Stone's formula for constructing the Spectral Measure $E$ for $A$.
$$
    \lim_{\epsilon\downarrow 0}\frac{1}{2\pi i}\int_{a}^{b}\left\{(A-(s+i\epsilon) I )^{-1}f-(A-(s-i\epsilon) I)^{-1}f\right\}\,ds \\
    =\frac{1}{2}\{ E[a,b]+E(a,b)\}f \\
$$
Show that $E[a,b]f=E(a,b)f$ in this case because $A$ has only continuous spectrum. Warning: I have posted a solution to preserve for the record. The Spectral Theorem for Unbounded Selfadjoint Operators on a Hilbert Space is used to derive the $L^{2}$ theory of the Fourier transform in a constructive way without assuming anything about Fourier analysis.","['operator-theory', 'spectral-theory', 'fourier-analysis', 'functional-analysis']"
1007118,Book recommend for topics of Integrals in multivariable calculus.,"I am an average student and have to study following topics on my own for the exam : The measure of a bounded interval in $\mathbb R^n$ , the Riemann integral of a bounded function defined 
  on a compact interval in $\mathbb R^n$ , Sets of measure zero and Lebesgue’s criterion for existence of a 
  multiple Riemann Integral, Evaluation of a multiple integral by iterated integration. Please can anyone suggest some good self-study book providing good insight into the above topics ..","['multivariable-calculus', 'book-recommendation', 'reference-request', 'soft-question', 'advice']"
1007155,Example of a $T_1$ space that does not have the property that every compact subspace of $X$ is closed.,Let $X$ denote a topological space. Then each condition in the following list implies the next. $X$ is $T_2$ Every compact subspace of $X$ is closed. $X$ is $T_1$. I know that 2 does not imply 1 (see here ). I'm also guessing that 3 does not imply 2. Does anyone know of an example?,['general-topology']
1007181,A bounded function on $\mathbb{R}^2$,"How to prove that the function $f(x,y)=\displaystyle\frac{xy^2}{x^2+y^4}$ if $(0,0)\not = (0,0)$ and $f(x,y)=0$ is bounded on $\mathbb{R}^2$? I like some advice to this problem. Thanks!",['multivariable-calculus']
1007190,Exercise 1.1 in Serre's trees,"I have in fact become stuck by the very first problem in Serre's book on Trees. It is a little bit embarrassing but ho-hum. I start with Serre's definition of direct limits. Let $(G_i)_{i \in I}$ be a family of groups and for each pair $(i,j)$, let $F_{ij} \subset \mathrm{Hom}(G_i,G_j)$. There exists a unique group $G$ and a family of homomorphisms $f_i \colon G_i \to G$ such that $f_j \circ f = f_i$ for all $f \in F_{ij}$ that has the following universal property: if $H$ is a group and if $h_i \colon G_i \to H$ is a family of homomorphisms such that $h_j \circ f = h_i$ for all $f \in F_{ij}$, then there exists exactly one homomorphism $h \colon G \to H$ such that $h_i = h \circ f_i$. We say $G$ is the direct limit of $G_i$ relative to $F_{ij}$. Take three groups $A$, $G_1$, $G_2$ and two homomorphisms $f_1 \colon A \to G_1$,  $f_1 \colon A \to G_2$. The amalgamated free product $G_1 \ast_A G_2$ is the direct limit of $A, G_1, G_2$ relative to $f_1, f_2$. Usually one defines the amalgamated free product with monomorphisms, however the next exercise shows that there isn't any difference between Serre's definition and the definition with monomorphisms. Take $G =G_1 \ast_A G_2$ relative to the above maps. Define subgroups $A^n$, $G_1^n$, $G_2^n$ recursively by the following conditions:
$$
A^1 = \{ 1 \}, \quad G_1^1 = \{1 \}, \quad G_2^1= \{ 1 \}
$$
$$
A^n = \text{subgroup generated by } f_1^{-1}(G_1^{n-1}) \text{ and } f_2^{-1}(G_2^{n-1})
$$
$$
G^n_i = \text{subgroup generated by } f_i(A^{n})
$$
Let $A^{\infty}$ and $G_i^{\infty}$ be the unions of $A^n$ and $G_i^n$ respectively. Now the exercise says to show that $f_i$ defines an injection $A / A^{\infty} \to G_i / G^{\infty}_i$ and that $G$ may be identified with the amalgam $G_1 / G_1^{\infty} \ast_{A / A^{\infty}} G_2 / G_2^{\infty}$. The question I have is: why are  $A^{\infty}$ and $G_i^{\infty}$ normal inside $A$ and $G_i$ respectively? EDIT: So after discussing this with user10193, here is another reason why we think $G_i^n$ are meant to be the normaliser of $f_i(A^n)$. First note that whenever $\varphi \colon G \to H$ is a homomorphism and $S$ is a subgroup of $G$ then $\varphi^{-1}(\varphi(S)) = SK$ where $K$ is the kernel of $\varphi$. Set $K_1 = \mbox{ker}(f_1)$ and $K_2 = \mbox{ker}(f_2)$. Then $A^2 = \langle K_1, K_2 \rangle = K_1 K_2$ as $K_1$ and $K_2$ are normal. Then if $G^n_i$ are meant to be defined as it is, it follows that $G_1^2 = f_1(K_2)$ and $G_2^2 = f_2(K_1)$. Hence
$$
A^3 = \langle f_1^{-1}(f_1(K_2)), f_2^{-1}(f_2(K_1)) \rangle = \langle K_1 K_2, K_1 K_2 \rangle = K_1 K_2.
$$
Therefore $A^n$ and $G_i^n$ stabilise. This just seems nonsense. So my question just reduces to: why is $A^{\infty}$ normal inside $A$?","['trees', 'geometric-group-theory', 'group-theory']"
1007206,Differentiate $f(x)=\int_x^{10}e^{-xy^2}dy$ with respect to $x$,"I am trying to find $f'(x)$ when $0\leq x\leq 10$. I know I could use the formula given on this wikipedia page: http://en.wikipedia.org/wiki/Differentiation_under_the_integral_sign but I have been asked to justify all steps of the calculation so this isn't allowed. I have been given a hint to let $I(a,b,c)=\int_a^bf(x,c)dx$ and then told to show that $f$ satisfies all conditions necessary for FTC1 and the theorem of differentiation of integrals depending on a parameter. The problem I am having is translating $f(x)$ into something of the same form as $I(a,b,c)$. Can anyone help? EDIT: I think I've done it now using the method described by @mvggz . Is this the final answer once the $u$ has been substituted back out: $$ f'(x)=-\frac{1}{x} \int_x^{10} e^{-xy^2} dy + \frac{5}{x} e^{-100x}-\frac{3}{2}e^{-x^3}$$","['calculus', 'integration', 'real-analysis', 'analysis', 'derivatives']"
1007249,Regularity of the heat kernel,"Let $(M,g)$ be a compact Riemannian manifold. 
Let $H:M\times M\times\mathbb{R}_{>0}\to\mathbb{R}$ be the heat kernel. i.e. $H\in C^0(M\times M\times\mathbb{R}_{>0})$ is the unique continuous function such that for all $y\in M$, (A) $H^y\in C^{2,1}(M\times\mathbb{R}_{>0})$ (B) $\left(\Delta^g-\dfrac{\partial}{\partial t}\right)H^y=0$ (C) $\displaystyle\lim_{t\to0}H^y_t=\delta_y$ , where $H^y(x,t):=H(x,y,t)$, $H^y_t(x):=H^y(x,t)$, $C^{2,1}(M\times\mathbb{R}_{>0}):=\{\varphi:M\times\mathbb{R}_{>0}\to\mathbb{R}|\text{ For each chart }(U;x^1,\cdots,x^m)\subset M, \dfrac{\partial\varphi}{\partial t}, \dfrac{\partial\varphi}{\partial x^i},\text{ and }\dfrac{\partial^2\varphi}{\partial x^i\partial x^j}:U\times\mathbb{R}_{>0}\to\mathbb{R} \text{ are well defined and continuous.}\}$. ${\bf [Question 1]}$ From (A) and (B) above it is derived that $H^y\in C^\infty(M\times\mathbb{R}_{>0})$ for all $y\in M$. How about the regularity of H as a function on $M\times M\times\mathbb{R}_{>0}$? Does it hold that $H\in C^\infty(M\times M\times \mathbb{R}_{>0})$? If not, aren't there any regularity result of $H:M\times M\times\mathbb{R}_{>0}\to\mathbb{R}$ which is useful to exchange integrals and differentiation? ${\bf [Question 2]}$ Suppose that $F:M\times[0,T]\to \mathbb{R}$ is a continuous function. Then is it true that the function
\begin{eqnarray}
u(x,t):=-\int_0^t\int_M H(x,y,t-\tau)F(y,\tau)\mu_g(dy)d\tau
\end{eqnarray}
belongs to $C^{1,0}(M\times[0,T])\cap C^{2,1}(M\times(0,T))$? ${\bf [Question 3]}$
Suppose that $f:M\to\mathbb{R}$ be a $C^1$ function. Does the function
\begin{eqnarray}
v(x,t):=\int_M H(x,y,t)f(y)\mu_g dy
\end{eqnarray}
belong to $C^{1,0}(M\times[0,\infty))\cap C^{2,1}(M\times\mathbb{R}_{>0})$? Please tell me also references. Thank you.","['differential-geometry', 'partial-differential-equations', 'regularity-theory-of-pdes', 'heat-equation', 'analysis']"
1007253,Understanding this pattern behind the Fibonacci sequence,"To be honest, I'm pretty awful at mathematics however, when up till 6AM I do like to do random things throughout the night to keep me occupied. Tonight, I began playing with the Fibonacci sequence in the Python programming language. I understand that the Fibonacci sequence is just adding the previous two numbers together to produce your next value so I defined a function to spit out the sequence up to the 200th number like so, def fib(n):
    a, b = 0, 1
    i=1
    while i < 200:
        print(""ITERATION: "" + str(i))
        a, b = b, a + b
        print(a)
        i += 1
print(fib(1)) What I found interesting is a pattern I came across when adding up the total amount of numbers before the sequence added the next digit. (see picture A.) PICTURE A: from there, I added up the number ""sets"" and the pattern emerged.(see picture B.) PICTURE B: This pattern continued, I went up to the 22nd ""set"" of numbers and the whole pattern was like so: 1
  2
  1
  3
  1
  4
  1
  5
  1
  2
  1
  4
  1
  4
  1
  3
  1
  4
  1
  3
  1
  4 I found it interesting that the numbers added a digit sequentially by either 4 or mainly 5 integers and how the overall pattern that emerged out of the ""sets"" appeared to become less stable after the 8th set which was ironically 5; 1
  2
  1
  3
  1
  4
  1
  5 forgive me if this seems obvious or silly, but like I said, I'm pretty bad at math. Can anyone explain why this pattern emerges and a little bit more in depth on what the fibonacci sequence can be used for?","['fibonacci-numbers', 'sequences-and-series', 'pattern-recognition', 'discrete-mathematics']"
1007275,Prove that $f(x) = |x|$ belongs to $D'( \mathbb{R})$,"Prove that $f : \mathbb{R} \rightarrow \mathbb{R}, f(x) = |x|$ belongs to $D'(\mathbb{R})$ and find its first and second distributional derivatives, $f', f''$. To prove its linearity I used the linearity of the integral so:
$\langle f, \alpha\phi+\beta\psi \rangle = \int_\mathbb{R}{|x|[\alpha\phi(x) + \beta\psi(x)]dx} = \alpha \langle f, \phi \rangle +\beta \langle f, \psi \rangle$ Then I tried to proved its continuity showing that $|\int_\mathbb{R}{|x|\phi(x)dx}| <M||\phi||_{D(\mathbb{R})}$ :
$$\left|\int_\mathbb{R}{|x|\phi(x)dx}\right| \leq \left|\int_\mathbb{R}{|x| |\phi(x)|dx}\right| = \left|\int_{\operatorname{supp}(\phi)}{|x| |\phi(x)|dx}\right| \leq ||\phi||\int_{\operatorname{supp}(\phi)}{|x|dx}$$ but $\int_{\operatorname{supp}(\phi)}|x|dx$ doesn't converge if $\operatorname{supp}(\phi) = \mathbb{R}$. So I tried to prove continuity by showing that it's continuous in zero. $\langle f, 0 \rangle = 0$ $\langle f, \phi_k \rangle - \langle f, \phi \rangle = \int_\mathbb{R}|x|(\phi_k-\phi)dx \leq \sup|\phi_k-\phi|\int_\mathbb{R}|x|dx \rightarrow 0$ for $\phi_k \rightarrow\ \phi$ Is this correct? Do I have to make some observations to justify it?
Is generally more convenient or easier to prove continuity in the latter way than in the former?","['distribution-theory', 'functional-analysis']"
1007299,Square is not an algebraic set.,"I am trying to show that square with vertices at $(\pm1,0)$ and $(0,\pm1)$ is not a zero set of a polynomial in $\mathbb{R}[x,y]$. Clearly, square is the zero set of a function 
$$
f: \mathbb{R}^2\to \mathbb{R};
$$
$$
(x,y)\mapsto |x|+|y|-1,
$$
which is not a polynomial. But how to show that there is no polynomial which has square as the zero set?","['geometry', 'algebraic-geometry']"
1007327,Injection from $\mathbb{R}^n$ to $\mathbb{R}$,I'm doing some set theory problems. They ask me to find the cardinality of some specific set and it seems that it would often be useful to have a function that mapped any tuple of real numbers to a real number. Is there a simple function I can use?,"['elementary-set-theory', 'functions']"
1007337,Does an overdetermined system always have no solutions? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question What is the problem with over-determined systems in linear algebra? Do they always have no solution? Is there a proof of that?","['matrices', 'linear-algebra', 'systems-of-equations']"
1007342,"Riemann sphere, metric derivation-Completed","I have been calculated Riemann sphere, but i got stuck with calculating its metric. Consider complex plane $\mathbf{C}$ and its point $\zeta=\xi+i\eta$. And consider a point in $S^2 / (0,0,1)$ which $(x_1, x_2, x_3)\neq (0,0,1)$. Now consider a line which connect two points, North pole $(0,0,1)$ and point $(x_1, x_2, x_3)$, 
\begin{align}
t(x_1, x_2, x_3) + (1-t)(0,0,1) = (t x_1, t x_2, t(x_3-1)+1)
\end{align}
and the intersection with plane $\mathbf{C}$ to be $(\xi, \eta, 0)$. At the intersection point $t=\frac{1}{1-x_3}$ we have
\begin{align}
\xi=\frac{x_1}{1-x_3}, \quad \eta =\frac{x_2}{1-x_3}
\end{align}
Note from $x_1^2 +x_2^2 +x_3^2=1$, I found that
\begin{align}
x_1 =\frac{2\xi}{||\zeta||^2+1}, \quad x_2 =\frac{2\eta}{||\zeta||^2+1}, \quad x_3 =\frac{||\zeta||^2-1}{||\zeta||^2+1}
\end{align} Here are the problems. 
I try to obtain following expression in textbook, but my calculation does not fit with this. Also i got trouble for $ds^2$, Plug $dx_1$ to $dx_3$ below, i could not obtain the last equation. Is the textbook wrong? 
\begin{align}
&dx_1 = \frac{2(1-\xi^2+\eta^2)d\xi -4\xi\eta d\eta}{(1+||\zeta||^2)^2} \\
&dx_2 = \frac{2(1+\xi^2-\eta^2)d\eta -4\xi\eta d\xi}{(1+||\zeta||^2)^2} \\
& dx_3 = \frac{4\xi d\xi +4\eta d\eta}{(1+||\zeta||^2)^2}
\end{align} \begin{align}
ds^2 = dx_1^2+dx_2^2 +dx_3^2 =\frac{4(d\xi^2 + d\eta^2)}{(1+\xi^2+\eta^2)^2}
\end{align} It was trivial calculations... 
Just using complex variable defined above $\zeta$, properly, i have been finished my calculations.  I will post it next time.","['riemannian-geometry', 'differential-geometry']"
1007361,Uniform limit of uniformly continuous functions,"Let $f_n:\mathbb{R}\to\mathbb{R}$ be a sequence of uniformly
  continuous functions. Assume that $f_n$ converges uniformly on all
  bounded intervals $[a,b]$ to a function $f$, i.e.
  $\displaystyle\lim_{n\to \infty}\sup_{a\leq x\leq b}|f_n(x)-f(x)|=0$ 
  for all $a<b$. Is the limit $f$ also uniformly continuous ? In the case where the convergence is uniform on the whole real line, I can prove that the limit is also uniformly continuous.","['convergence-divergence', 'uniform-convergence', 'real-analysis', 'analysis', 'uniform-continuity']"
1007373,The disease problem,"Students are sitting in a n * n grid. There's a disease spreading among them in a particular fashion. At start, there a 'k' students infected(At random). After every time step(equal intervals), the number of students infected, increase. The manner of increment after each time step is - The students that were previously infected, are continued to be infected. The students(non- infected) that were adjacent to at least 2 of the infected students, get infected. *Adjacent means that the infected students should be in top, right, left or bottom cell, of a particular student into consideration. Theorem - If fewer than n students in class are initially infected, the whole class will never be completely infected. i.e k < n, then all the students would never be infected. If possible, prove this by induction.","['induction', 'invariant-theory', 'discrete-mathematics', 'computer-science']"
1007399,"Evaluate $\int\frac{1}{1+x^6} \,dx$","I came across following problem Evaluate $$\int\frac{1}{1+x^6} \,dx$$ When I asked my teacher for hint he said first evaluate $$\int\frac{1}{1+x^4} \,dx$$ I've tried to factorize $1+x^6$ as $$1+x^6=(x^2 + 1)(x^4 - x^2 + 1)$$
and then writing $$I=\int\frac{1}{1+x^6} \,dx=\int\frac{1}{(x^2 + 1)(x^4 - x^2 + 1)} \,dx=\int\frac{1+x^2-x^2}{(x^2 + 1)(x^4 - x^2 + 1)} \,dx$$
$$I=\int\frac{1}{x^4 - x^2 + 1} \,dx-\int\frac{x^2}{(x^2 + 1)(x^4 - x^2 + 1)} \,dx$$ However $$x^4-x^2+1=\left(x^2-\frac12\right)^2+\frac{3}{4}$$
But I can't see how it helps I've also tried to reverse engineer the solution given by Wolfram Alpha And I need to have terms similar to $$\frac{x^2-1}{x^4-x^2+1} \quad , \quad \frac{1}{1+x^2} \quad , \quad \frac{1}{(x+c)^2+1}\quad , \quad \frac{1}{(x+c)^2+1}$$ in integrand, How can I transform my cute looking integrand into these huge terms? Since in exams I will neither have access to WA nor time to reverse engineer the solution moreover it does not seem intuitive,is there any way to solve this problem with some nice tricks or maybe substitutions?","['calculus', 'integration', 'indefinite-integrals']"
1007419,Solving Trigonometric Equation Problem,"im kinda stuck to solve the following problems below Problem: 4cos²2x+sin2x=3   (0 < x <= π) Steps: 4cos²2x+sin2x=3 2+2cos4x+sin2x=3 2cos4x+sin2x=1 2(1-2sin²2x)+sinx=1 2-4sin²2x+sinx=1 Bring every term to the right side 0= 1-2+4sin²2x-sinx 4sin²2x-sinx-1=0 Let M= sin2x, sin 4m²-m-1=0 X=+0.64 , x=-0.39","['trigonometry', 'algebra-precalculus']"
1007424,Finding the positive integer numbers to get $\frac{\pi ^2}{9}$,"As we know, there are many formulas of $\pi$ , one of them $$\frac{\pi ^2}{6}=\frac{1}{1^2}+\frac{1}{2^2}+\frac{1}{3^2}......
$$
and this $$\frac{\pi ^2}{8}=\frac{1}{1^2}+\frac{1}{3^2}+\frac{1}{5^2}......$$
Now,find the positive integer numbers $(a_{0}, a_{1}, a_{2}....)$ to get $$\frac{\pi^2 }{9}=\frac{1}{a_{0}^2}+\frac{1}{a_{1}^2}+\frac{1}{a_{2}^2}....$$","['sequences-and-series', 'number-theory']"
1007428,Product of nilpotent ideal and simple module is zero,"I am stuck with trying to show that if an ideal $I$ of a ring $R$ is nilpotent and $M$ is a simple $R$-module, then $IM = 0$. I have attempted showing this by using the fact that the annihilator of a simple module is the primitive ideal, and I'm guessing trying to show that a nilpotent ideal and a primitive ideal are some how related but i think i am missing some crucial information. I have tried using properties of maximal ideals but to no conclusion, I'm sure I'm just missing an initial step any help on this will be greatly appreciated thanks in advance","['modules', 'ring-theory', 'ideals', 'abstract-algebra']"
1007455,Hartshorne Corollary III.9.4,"I am reading the section of Flatness from Hartshorne. I have a doubt in the proof of the corollary of the following proposition : $\textbf{Proposition 9.3}$ Let $f:X\longrightarrow Y$ be a separated morphism of finite type of noetherian schemes and let $\mathcal{F}$ be a quasi-coherent sheaf on $X$. Let $u:Y'\longrightarrow Y$ be a flat morphism of noetherian schemes. Then for all $i\geq 0$, there are natural isomorphisms $u^*R^if_*(\mathcal{F})\cong R^ig_*(v^*\mathcal{F})$. I understood the proof of this. I have a doubt in the corollary to this. $\textbf{Corollary 9.4}$ Let $f:X\longrightarrow Y$ and $\mathcal{F}$ be as in (9.3) and assume that $Y$ is affine. For any point $y\in Y$, the $X_y$ be the fibre over $y$, and let $\mathcal{F}_y$ be the induced sheaf. On the other hand, let $k(y)$ denote the constant sheaf $k(y)$ on the closed subset $\bar{\{y\}}$ of $Y$. Then for all $i\geq 0$ there are natural isomorphisms.
$H^i(X_y,\mathcal{F}_y)\cong H^i(X,\mathcal{F}\otimes k(y))$ They begin the proof by saying : Let $Y'\subset Y$ be the reduced induced subscheme structure on $\bar{\{y\}}$., and let $X'=X\times_Y Y'$, which is a closed subscheme of $X$. Then both sides of the desired isomorphism depend only on the sheaf $\mathcal{F}'=\mathcal{F}\otimes k(y)$ on $X'$. Thus we can replace $X,Y,\mathcal{F}$ by $X',Y',\mathcal{F}'$. Why can we assume this? Why can we replace as said above? Clearly, on the right side $\mathcal{F}\otimes k(y)$ is $\mathcal{F}'$. But why is it true on the left? Any help will be appreciated!","['homology-cohomology', 'algebraic-geometry']"
1007473,"Determining the dimension of span$\{AB-BA : A,B \in M_{n \times n}(\mathbb R) \}$","Let $S$ be the subspace , of  $M_{n \times n}(\mathbb R)$ (the vector space of all $n \times n$ real matrices ) , generated by matrices of the form $AB-BA$ , where $A,B \in M_{n \times n}(\mathbb R)$ , then how do we prove that $\dim S=n^2-1$ ? The only thing that I can determine is that the trace of all matrices of $S$ is $0$ . Please help","['vector-spaces', 'matrices', 'linear-algebra']"
1007476,Hartshorne Proposition 9.5,"The Proposition is that : Let $f:X\longrightarrow Y$ be a flat morphism of schemes of finite type over a field $k$. For any point $x\in X$, let $y=f(x)$. Then 
$\dim_x(X_y)=\dim_x(X)-\dim_y(Y)$. Here for any scheme $X$ and any point $x\in X$, by $\dim_x(X)$, we mean the dimension of the local ring $\mathcal{O}_{x,X}$. They begin the proof as follows : First we make a base change $Y'\longrightarrow Y$ where $Y'=\textrm{Spec }  \mathcal{O}_{y,Y}$ and consider the morphism $f':X'\longrightarrow Y'$ where $X'=X\times_{Y} Y'$. Then $f'$ is also flat, $x$ lifts to $X'$ and the three numbers are the same. What is meant by : $x$ lifts to $X'$. It is not the inverse image, because the inverse image could contain  more than one element. What does it mean? Thank you in advance!",['algebraic-geometry']
1007511,Prove $\sqrt{-7} \not\in \mathbb{Z}\left[\frac{2+3\sqrt{-7}}{4}\right]$,"I have the following problem. Consider the ring $\mathbb{Z}$ and define:
  $$x = \sqrt{-7}\qquad z = \frac{2+3x}{4}$$
  Show that $\mathbb{Z}[x] \not\subset \mathbb{Z}[z]$ and $\mathbb{Z}[z] \not\subset \mathbb{Z}[x]$. First of all, I describe the ring extensions:
\begin{align}
\mathbb{Z}[x] 
&= \left\{a_0 + a_1 x + a_2 x^2 +a_3 x^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\}\\
&= \left\{a + b x \ | \ a,b \in \mathbb{Z}\right\}
\end{align}
Where we use $x^2 + 7 = 0$ ($x$ is an algebraic integer). On the other hand
\begin{align}
\mathbb{Z}[z] 
&= \left\{a_0 + a_1 z + a_2 z^2 +a_3 z^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\}
\end{align}
admits no further simplification (we have $16z^2 - 16z + 67 = 0 \Rightarrow z$ is not an algebraic integer). I think it is easy to show $z \not\in \mathbb{Z}[x]$. To see this, assume you can find $a,b\in \mathbb{Z}$ such that $z = a+bx$. Now consider this identity in $\mathbb{Q}(x) = \mathbb{Q}[x]$, where $\{1,x\}$ is a basis. Since 
$$z=\frac{2}{4} + \frac{3}{4}\!x= a +bx $$
it must be $a=\frac{2}{4}$, $b=\frac{3}{4}$, so $a, b$ are not in $\mathbb{Z}$. Thus $z\not\in\mathbb{Z}[x]$. Is this correct? Any idea for the other part?","['ring-theory', 'extension-field', 'abstract-algebra']"
1007524,Prove that $\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right)$,"In my course, I have to prove formula below
$$I=\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right)$$
for $a,b,c>0.$ I know that this integral can be easily solved with complex analysis using
$$f(z)=\frac{1}{2} \ \mathbb{R} \left(\int_{-\infty}^\infty \frac{\exp\left(e^{iaz}+ibz\right)}{c^2+z^2}dz\right)$$
but right now I am in a course dealing with real analysis. I tried to use parametrization integral method
$$I'(a)=-\int_0^\infty \frac{xe^{\cos(ax)}\sin(\sin(ax)+(a+b)x)}{c^2+x^2}dx $$
but it doesn't look easier to handle. I tried to differentiate it again, but I just got a horrible form. An idea came to mind to differentiate with respect to parameter $b$ and set a differential equation
$$I''(b)+x^2I(b)=0$$
plugging this ODE to W|A, I got
$$I(b)=c_1\cos(bx^2)+c_2\sin(bx^2)$$
It's definitely wrong! After seeing Samrat's answer, I tried to plug in again to W|A and I got
$$I(b)=c_1 D_{-1/2}((i+1)b)+c_2 D_{-1/2}((i-1)b)$$ where $D_n(z)$ is the parabolic cylinder function but I have no idea what does that mean. Any idea? Thanks in advance.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
1007576,Expected number of rolls,A fair m-sided dice is rolled and summed until the sum is at least N. What is the expected number of rolls? In other words what is the number of rolls if we roll a m-sided dice and the sum of rolls become at least N.,"['discrete-mathematics', 'probability', 'combinatorics']"
1007582,Maximum Likelihood Estimation with Laplace Distribution,"I want to estimate the parameters $a$ and $b$ of the model $y_i = ax_i + b + \varepsilon_i, i=1,...,n $ via Maximum Likelihood. The $\varepsilon_i$ are assumed to be Laplace-distributed with density 
$f(x) = \frac{2}{\beta}\exp\left(\frac{\vert x\vert}{\beta}\right)$,
and therefore $y_i \sim \text{Laplace}(\beta, \mu=ax_i + b)$. Maximizing the log-likelihood over a and b is then equivalent to minimizing
$\sum_{i=1}^n \vert y_i - ax_i -b \vert$
I've come up with the following partial derivatives of the log-Likelihood l: $$
\frac{\partial l}{\partial a} = c*\sum_{i=1}^n -\text{sgn}(y_i-ax_i-b)x_i \\
\frac{\partial l}{\partial b} = c*\sum_{i=1}^n -\text{sgn}(y_i-ax_i-b) \\
$$ Edited:
It seems to me, that
$$\hat{b} = min \{b \in \mathbb{R}: \sum_{i=1}^{n}\frac{\mathbb{1}\{y_i-ax_i\leq b \}}{n}\geq \frac{1}{2}\} $$
Whereas $a$ has to be a solution of:
$$
\sum_{i=1}^{n} \mathbb{1}\{y_i- \hat{b} \geq ax_i\}x_i = \sum_{i=1}^{n}\mathbb{1}\{y_i- \hat{b} < ax_i\}x_i
$$ Any ideas?","['statistics', 'probability-distributions', 'estimation']"
1007585,Verifying if system has periodic solutions,"Given the following system $\dot{x} = y$ $\dot{y} = y(9-x^2-2y^2) - x$ verify whether it has periodic solutions and if so are they attracting or repelling. I thought: The critical points or fixed point is (0,0) but is this correct and if the answer is yes then is that a periodic solution? And in general, how does one find out the periodic solution? Finding fixed points is easy, you set $\dot{x}$ and $\dot{y}$ equal to zero and to verify the stability you find the derivatives of the fixed points. But I don't know how to find the periodic solutions... Maybe rewriting the system in polar coordinates helps somehow?","['dynamical-systems', 'ordinary-differential-equations', 'periodic-functions']"
1007672,"Joint distribution $(X_1,X_{(n)})$ order statistics","Let $X_1, \ldots, X_n$ a random sample of a Uniform(0,1), I want to show which the joint distribution of $(X_1,X_{(n)})$ is. I do the following: $$
P(X_1\leq x, X_{(n)}\leq y)=P(X_1\leq x, X_1\leq y, \ldots , X_n\leq y)=$$
$$
P(X_1\leq \min(x,y), X_2\leq y, \ldots, X_n\leq y)=P((X_1\leq \min(x,y))P(X_2\leq y)\ldots P( X_n\leq y)=$$
$$ = \min(x,y)y^{n-1}$$ When I compute the density function (by derivation), it is: $f(x,y)=(n-1)y^{n-2}$ in $0\leq x\leq y\leq 1$ and it doesn't integrate $1$ but $\frac{n-1}{n}$. I don't know where the problem is.","['statistics', 'probability-distributions', 'order-statistics']"
1007677,Sum of digits of all 4-digit numbers divisible by 7,What would be the way to approach this problem?,['sequences-and-series']
1007709,Proof that continuous partial derivatives implies differentiability,"This is the statement of Theorem 2.8 from Spivak's Calculus on Manifolds. I'd like feedback on if this looks fine as far as a generalization to his proof goes: Theorem: If $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, then $Df(a)$ exists if all $D_jf^i(x)$ exist in an open set containing $a$ and if each function $D_jf^i$ is continuous at $a$. Proof: Let $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ and suppose that all $D_jf^i(x)$ exist in an open set containing $a=(a^1,...,a^n)$ and that each function $D_jf^i$ is continuous at $a$. Then, for each $j$ such that $1 \leq j \leq n$, by the mean value theorem, we can find $b^j$ satisfying $a^j<b^j<a^j+h^j$, so that, $$\lim_{h \to 0} \frac{|f(a+h)-f(a)-(\sum_{j=1}^n D_jf^1(a)(h^j),...,\sum_{j=1}^n D_jf^m(a)(h^j))|}{|h|}=$$ $$\lim_{h \to 0} \frac{|f(a^1+h^1,a^2...,a^n)-f(a)+...+f(a+h)-f(a^1+h^1,...,a^{n-1}+h^{n-1},a^n)-(...)|}{|h|}=$$ $$\lim_{h \to 0} \frac{|D_1f(b^1,a^2...,a^n)(h^1)+...+D_nf(a^1+h^1,...,a^{n-1}+h^{n-1},b^n)(h^n)-(...)|}{|h|}=$$ $$\lim_{h \to 0} \frac{| (\sum_{j=1}^n [D_jf^1(c_j)-D_jf^1(a)](h^j),...,\sum_{j=1}^n [D_jf^m(c_j)-D_jf^m(a)](h^j))|}{|h|} \leq$$ $$\lim_{h \to 0} |(\sum_{j=1}^n |D_jf^1(c_j)-D_jf^1(a)|\frac{|h^j|}{|h|},...,\sum_{j=1}^n |D_jf^m(c_j)-D_jf^m(a)|\frac{|h^j|}{|h|})| \leq$$ $$\lim_{h \to 0} |(\sum_{j=1}^n |D_jf^1(c_j)-D_jf^1(a)|(1),...,\sum_{j=1}^n |D_jf^m(c_j)-D_jf^m(a)|(1))|=0,$$ where $h=(h^1,...,h^m)$, each $c_j$ is defined suitably in terms of $a^j$'s, $b^j$'s and $h^j$'s, and the last equality holds by the continuity hypothesis. Therefore $Df(a)$ exists. Thanks in advance.","['multivariable-calculus', 'proof-verification']"
1007744,Conditional expectation to de maximum $E(X_1\mid X_{(n)})$,"Let $X_1, \ldots, X_n$ a random sample of a Uniform(0,1): Which is $E(X_1\mid X_{(n)})$ ? where $X_{(n)}=\max\{X_1,\ldots,X_n\}$","['conditional-expectation', 'probability', 'order-statistics']"
1007765,Normal distribution - how to solve P(-b<X<b)=0.95,"$X\sim N(2,3^2)$ How do you find $b$ where $P(-b<X<b)=0.95$ other than trial and error? You can't directly transform to $z$ because if you find an appropriate $z$, transforming back will give you the difference between $b$ and $z$, not $\pm z$. I know it's a simple question but I'm stuck in a rut.","['normal-distribution', 'probability-distributions', 'probability', 'problem-solving']"
1007775,"Let $f: [0,1] \to \Bbb R^+$ be continuous map then is it possible to have $\int_0^x f(t)dt \geq f(x)$?","Let $f: [0,1] \to \Bbb R^+$ be continuous map then is it possible to have $\int_0^x f(t)dt \geq f(x)$? If such functions exists then what will be the cardinality of the set having these kind of functions? If I have $f$ is differentiable then we get $f(x) \leq e^x$. But for $e^x$ the condition will not be satisfied. So how can we proceed?","['ordinary-differential-equations', 'real-analysis', 'analysis']"
1007789,Iterated integer-valued decimation,"This question is for those who have wondered what it means to decimate an army when the number of soldiers is not a multiple of ten. I am interested in really good upper bounds on the length of a certain finite sequence.  I will define the sequence and then show what is, I think, a pretty good upper bound on its length.  A colleague of mine suggested that one should be able to do better, and I realize that I don't know much about what kind of tools ought to be brought to bear on this type of elementary, but nontrivial problem. By $\mathbb{N}$ I mean the natural numbers: $\{0,1,2,\ldots\}$.  Let $d$ be a positive integer, and consider the ""$d$-decimation function"" $D_d: N \mapsto N - \lceil \frac{N}{d} \rceil$. You can think about this function as follows (and this is how it arises in my intended application): we have $N$ discrete objects and we place each into one of $d$ boxes.  Then we are allowed to remove all the objects from any one box.  If we want to minimize the number of objects remaining, we simply choose the box which has the most (or tied for the most) objects.  By the Pigeonhole Principle at least one box must have $\frac{N}{d}$ objects.  But because everything is integer-valued, there must in fact be a box with at least $\lceil \frac{N}{d} \rceil$ objects, hence if we empty that box we are left with at most $D_d(N)$ objects. Now we redistribute the remaining objects in the (still $d$ -- we don't remove the box, just empty it) boxes and repeat.  Thus for $i \geq 1$ define $D_d^i = D_d \circ \ldots \circ D_d: \mathbb{N} \rightarrow \mathbb{N}$, the $i$-fold composition.  Because $D_d(N) < N$ for all $N \geq 1$, for each $N \in \mathbb{Z}^+$ there is some $i$ such that $D_d^i(N) = 0$.  We define the d-decimation length of $N$ to be the least such $i$ and denote it by $\ell_d(N)$.  I want really good upper bounds on $\ell_d(N)$. Some quick comments: For all $N \in \mathbb{Z}^+$ we have $D_1(N) = 0$, so $\ell_1(N) = 1$. For all $N \leq d$ we have $D_d(N) = N-1$, so $\ell_d(N) = N$ if $d \geq N$. So the interesting case is $2 \leq d < N$: let's assume that. I will now give the upper bound that I know.  It comes from the fact that $D_d(N) = N - \lceil \frac{N}{d} \rceil \leq N - \frac{N}{d} = (1-\frac{1}{d})N$, so $D_d^i(N) \leq N (1-\frac{1}{d})^i$. Since $e^x$ is convex, it lies above its tangent line, thus $1+x \leq e^x$ for all $x$, with strict inequality for all $x \neq 0$.  Using this we get $N (1-\frac{1}{d})^i < N e^{\frac{-i}{d}}$ If we choose $i$ such that $N e^{\frac{-i}{d}} < d$, then $D_d^i(N) < d$, so $D_d^{i+d-1} = 0$ and $\ell_d(N) \leq i + d-1$.  An easy calculation shows that we can take $i = \lceil d \log \frac{N}{d} \rceil$, so $\ell_d(N) \leq \lceil d \log \frac{N}{d} \rceil + d-1 < d (1+\log \frac{N}{d})$. I would like to do better than this.  My colleague says that one can get instead $\ell(d) \leq d(\gamma + \epsilon + \log \frac{N}{d})$, where $\gamma = 0.577\ldots$ is the Euler-Mascheroni constant and $\epsilon$ approaches $0$ as $\min(d,\frac{N}{d})$ approaches infinity.  (I certainly believe him; I just don't understand how to get this.)  He also suggests a better bound involving partial sums of the harmonic series which is valid in all cases.  More than anything, I would like to see how someone who knows what they are doing attacks this kind of problem.","['asymptotics', 'sequences-and-series']"
1007839,Proving basics of $(a+b)^2$,"I need to prove this: Consider the following inequality: $$a^2+ab+b^2 > 0$$ I know that $^2$ makes $a$ and $b$ positive numbers, so it always be $>0$, but i got stuck with the ab thing. I thought about $a^2+b^2+ab+ab=(a+b)^2,$ but no results... I also tried to think when the sum of $a^2+b^2$(not just a number) might bigger then $ab,$ but I'm having trouble using any of this to solve it. Would be glad for any help! p.s. sorry if i took it to the wrong section SORRY to mention it! $b\neq0$ and $b,a$ are real numbers.","['inequality', 'algebra-precalculus']"
1007878,On the Definition of multiplication in an abelian group,"In class we had the following Definition : Let $(A,+)$ be an abelian Group with $a \in G$. We define: $$na:= \begin{cases}na, \ \forall n \in \mathbb{N} \\ |n|(-a), \ \forall n \in \mathbb{Z}\setminus\mathbb{N} \end{cases} $$ Fair enough, doesn't seem too complicated. But when introducing a beginning student like me to the notion of a Module this becomes incredible confusing. Apparently the above definition is the only and the most natural way to show that for an $(A,+)$ abelian group the mapping $$\cdot : \begin{cases}\mathbb{Z} \times A & \longrightarrow A \\ (r,a) & \longmapsto r\cdot a  \end{cases} \\ $$
follows the laws of a $\mathbb{Z}$-Module. While it makes sense to me that the above definition comes in handy when trying to verify this, I am still absolutely puzzled about how to work with it. Let me try to elaborate on my confusion (this might get tedious for a trained Mathematician). I am aware that in (higher) mathematics the simple notation of $na$ has absolutely no meaning whatsoever until we give meaning to it by a definition . Since we have done this with the above, one could mean that it is possible to work with it and show certain properties. One of my tutors however meant that it's not clever to write $na$ as in the definition above, it would be better to define it recursively by a sum, because $$na=  \underbrace{a+\dots + a}_{n-\text{times}} \tag{*} $$ isn't mathematically rigorous and again, has in that context no meaning. Note that (*) is what they use in most papers I find online when exhausting google about this topic, see for example this paper here and the same thing for the Wikipedia entry here . So in order to rigorously proof that the above definition of multiplication follows the laws of a $\mathbb{Z}$-Module I would have to write (I suppose) $$\sum_{i=1}^{n+1} x:= \begin{cases}(\sum_{i=1}^n x) +x, \ \forall n \in \mathbb{N} \\ (\sum_{i=1}^{|n|}(-x)) + (-x), \forall n \in \mathbb{Z}\setminus \mathbb{N} \\0\cdot x = 0 \cdot(-x) =0 \text{ for } n=0 \end{cases} $$
I hope that this is right. However with this definition I manage to show for example the distributivity law only for $n \in \mathbb{N}$ (by induction). For negative values of $n$ I would say that $|n|= -n$ which is again a positive number and try induction over $p=|n|$, but there nothing seems to work. Let $p=1$ then $$\sum_{i=1}^1 (x+y)=\left(\sum_{i=1}^0(-(x+y)\right)+(-(x+y)) = (-(x+y)) $$
and I have no chance to continue with this. Is my definition wrong or do I just apply it in a flawed way? Also, despite to what my tutor said, might it be better to work with the original definition at the very top of this post and if so how? If you plan on answering this question you don't have to show me all the properties of a $\mathbb{Z}$-Module, I'd be happy to see exemplary calculations of lets say the distributivity.","['abelian-groups', 'group-theory', 'abstract-algebra', 'definition']"
1007891,Is it sufficient to check only open intervals in order to prove that a real function is measurable?,"Let $f : \mathbb R \to \mathbb R$. We say that $f$ is measurable if, for every $S \in \mathcal B$ where $\mathcal B$ is the Borel algebra on $\mathbb R$, we have that $f^{-1}[S] \in \mathcal B$. I would like to know if the following holds:
$$f \text{ is measurable } \iff f^{-1}[(a,b)] \in \mathcal B \text{ for all } a,b \in \mathbb R.$$ The ""$\Longrightarrow$"" implication obviously holds, but I was wondering if the other one holds as well. This might be true thanks to the fact that $\mathcal B$ is the $\sigma$-algebra generated by open sets (in the euclidean topology of $\mathbb R$), and the set of all open intervals is a base for the euclidean topology, so the open intervals generate the whole $\mathcal B$, and maybe it is always sufficient to check the measurability property for any $\sigma$-algebra just on a base of it. The aim of this question is to find a quick, but still rigorous, way to prove that (e.g.) the function defined by
$$f(x)=
\begin{cases}
x &\text{ if } x \leq 0 \\
x+1 &\text{ if } x > 0
\end{cases}$$
is measurable. Thanks","['measure-theory', 'real-analysis']"
1007898,Prove composition of bijections is bijection,Let f : A → B and g : B → C be bijections. Prove that g◦f : A → C is a bijection Can someone show me the steps I should take to solve this problem?,"['discrete-mathematics', 'functions']"
1007903,What's wrong with the calculation with polar coordinates here?,"Suppose $x=r\cos t$ and $y=r\sin t$. I did the following calculation: $$
\begin{align}
&x^4+y^4=(r\cos t)^4+(r\sin t)^4\\
=&r^4(\sin^4t+\cos^4t)\\
=&r^4[(\sin^2t+\cos^2t)^2-2\sin^2t\cos^2t]\\
=&r^4(1-2\sin^2t\cos^2t)=r^4-2r^4\sin^2t\cos^2t
\end{align}
$$
On the other hand
$$
\begin{align}
x^4+y^4&=(x^2+y^2)^2-2x^2y^2\\
&=r^4-2r^2\sin^2t\cos^2t
\end{align}
$$ What is wrong with the calculation?",['algebra-precalculus']
1007926,An Infinite Double Summation $\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} \frac{1}{n^2k^2(n+k)^2}$?,"While Solving some integral problem, I encountered the following infinite series: $$\displaystyle \sum_{k=1}^{\infty} \sum_{n=1}^{\infty} \frac{1}{n^2k^2(n+k)^2}$$ I have tried many methods including partial fractions... I seek help! Please provide hints if you don't have the complete answer.",['sequences-and-series']
1007947,Number of sudokus with no consecutive arithmetic progression of length 3 in any row or column.,"How many such Sudokus are there? Any reference to papers, books, articles or any insight into the problem will be greatly appreciated. I've tried several search engines, scholarly and not, with no results. Maybe there is a  terminology for them I am unaware of. EDIT1 Title updated. No AP for any row or column. EDIT2 Title updated. Consecutive AP.","['arithmetic-combinatorics', 'number-theory', 'algorithms', 'arithmetic', 'combinatorics']"
1007976,How can I represent this in group theory?,"I ran into a problem in real life that I'm pretty sure has a representation in group theory, but I don't know how. Suppose you flip a coin four times. The 16 outcomes are: HHHH
HHHT
...
TTTT First of all, if you have a finite set S (in this case S={H, T}), what do you call the set of all sequences of length N where each of the N positions is chosen from S? Given that set, I'm trying to count the number of distinct outcomes if you consider cycles; that is, the identity of a sequence can shift, so that (HHHT) is the same as (HHTH) (everything shifts to the left, and the left-most value shifts to the right-most place). I believe it should be possible to represent an outcome as an element of a finite group, and the factorizations in that group would give the distinct elements modulo the shift, but I'm not sure where to begin. This also reminds me of permutation groups, but is different enough that I'm not sure how to use that either.","['finite-groups', 'group-theory']"
1007988,Remainder when $p$ is divided by $6$,"Let $p$ be a prime. If there is a remainder of $1$ on division of $p$ by $3$, then what is the remainder when $p$ is divided by $6$? why? I know the remainder is $1$ in both the cases, but I'm not sure how to explain why. Help is appreciated.","['elementary-number-theory', 'discrete-mathematics']"
1008062,Using Induction to prove complete binary trees,"Prove a complete binary tree has an odd number of vertices. My attempt at the solution: Basis step: A binary tree with a height of 0 is a single vertex. This would result in the tree having an odd number of vertices (1). Correct. Inductive hypothesis: A complete binary tree with a height greater than 0 and less than k has an odd number of vertices. Prove: A binary tree with a height of k+1 would have an odd number of vertices. A complete binary tree with a height of k+1 will be made up of two complete binary trees k1 and k2. K1 and K2 are both complete binary trees meaning they have an odd number of vertices. They can be represented by (2m+1) and (2n+1). A tree with the hieght of k+1 can be represented by (2m+1) + (2n+1) plus 1 connecting vertice. Since (2m+1)+(2n+1) = (2m+2n+2) = 2(m+n+1) we can see that the number of vertices in k1+k2 is even. By adding the connecting vertex we get 2(m+n+1)+1. An odd number. Therefor  a tree with the height of k+1 has an odd number of vertices. Does this work, or have I made a mistake?","['induction', 'discrete-mathematics']"
1008067,An annoying Pell-like equation related to a binary quadratic form problem,"Let $A,B,C,D$ be integers such that $AD-BC= 1 $ and $ A+D = -1 $. Show by elementary means that the Diophantine equation
  $$\bigl[2Bx + (D-A) y\bigr] ^ 2 + 3y^2 = 4|B|$$ has an integer solution (that is, a solution $(x,y)\in\mathbb Z^2$). If possible, find an explicit solution (involving $A,B,C,D$, of course). Motivation: I arrived at this equation after trying to find explicitly the matrix $g$ suggested by Will Jagy on his answer to this question of mine . Concretely, if $\gamma=\binom{A\ \ B}{C\ \ D}$, then $\gamma$ has order $3$ in $\operatorname{SL_2}(\mathbb Z)$. By indirect methods it can be shown that $\gamma$ is conjugated in $\operatorname{SL_2}(\mathbb Z)$ to one of the matrices $P$ or $P^{-1}$, being $P=\binom{\ \ \,0\quad1}{-1\ \ -1}$ (see studiosus' answer to the same question.). Unfortunately this argument is rather sophisticated to my knowledge, and besides I think that a direct argument is possible. Because of this I tried to find a explicit matrix $g=\binom{x\ \ y}{z\ \ w}\in\operatorname{SL_2}(\mathbb Z)$ such that $gP=\gamma g$ or $gP^{-1}=\gamma g$. The matricial equalities lead to a system of $4$ linear equations in the unknowns $x,y,z,w$ , which can be easily solved. Plugging these solutions $(x,y,z,w)$ (recall that we are considering the two possibilities of conjugation, to $P$ or $P^{-1}$) into the equation $xy-zw=1$ yields $Bx^2+(D-A)xy+(-C)y^2=\pm1$. Completing the square and using the equalities $AD-BC=1$ and $A+D=-1$ we obtain the required equation. I tried to solve it explicitly, with no success.","['matrices', 'quadratic-forms', 'diophantine-equations']"
1008068,Can Cauchy Schwarz inequality be proven using Jensen's inequality?,"After reading a comment on If $\mathrm{E} |X|^2$ exists, then $\mathrm{E} X$ also exists ,
I wonder if Cauchy Schwarz inequality can be proven using Jensen's inequality?","['jensen-inequality', 'cauchy-schwarz-inequality', 'probability', 'real-analysis']"
1008104,How do endomorphisms of Banach space modulo compact operators look like?,"It is well-known that given a Banach space $X$, the set of compact operators (let's denote it by $K(X)$) on $X$ forms a both-sided ideal in $L(X)$, the ring of bounded linear operators on $X$. My question is Is there any natural interpretation of the quotient ring $L(X)/K(X)$? Here ""natural"" is probably too vague, so I will explain what I have in mind: Is there some canonical surjective ring homomorphism $L(X)\rightarrow R(X)$, where $R(X)$ is again some ring ($\mathbb{C}$-algebra) such that $K(X)$ is its kernel? I obviously do not mean the quotient map as such; I am looking for some description in terms of functional analysis (ideally, the ring $R(X)$ should be described in terms of functional analysis and the space $X$). Moreover, it also holds that all the compact operators form a both-sided ideal in the $\mathbb{C}$-linear category of Banach spaces. So the general question is Is there a $\mathbb{C}$-linear functor (again, described in terms of functional analysis) from the category of Banach spaces such that its kernel consits precisely of all compact operators? I apologize if the question is too vague, but it seems to me that this is one of the vague questions worth asking. Thanks in advance for any help.","['compact-operators', 'banach-spaces', 'abstract-algebra', 'category-theory', 'functional-analysis']"
