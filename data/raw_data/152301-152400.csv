question_id,title,body,tags
2551518,Sanity check: bounded linear map commutes with Bochner integral,"I wanted to check whether the following claim and proof are valid. Let $X,Y$ be separable Hilbert spaces, $(S,\mu)$ a measure space, and $A:X\rightarrow Y$ a bounded linear map. Let $f:S\rightarrow X$ be a Bochner-integrable function, so that the Bochner integral $$\int_S f(s)\,d\mu(s)$$ gives an element of $X$. Suppose also that $$\int_S Af(s)\,d\mu(s)$$ exists as an element of $Y$. Claim: $$A\int_S f(s)\,d\mu(s) = \int_S Af(s)\,d\mu(s).$$ Proof: Observe that by the answer to ""Point-wise"" value of Bochner integral of $L^2$ functions , the above is true if $A$ were a bounded linear map $X\rightarrow\mathbb{C}$. Let $\{v_i\}_{i\in I}$ be a Hilbert basis for $Y$ and $p_i$ be the bounded linear functional $\langle\,\cdot\,,v_i\rangle$ for each $i\in I$. Then applying the previous observation to $p_i\circ A:X\rightarrow\mathbb{C}$ and $p_i:Y\rightarrow\mathbb{C}$ gives $$p_i\circ A\int_S f(s)\,d\mu(s) = \int_S p_i\circ Af(s)\,d\mu(s) = p_i\int_S Af(s)\,d\mu(s)$$ for all $i\in I$. The claim follows by non-degeneracy of the inner product on $Y$.","['hilbert-spaces', 'functional-analysis', 'integration', 'measure-theory', 'analysis']"
2551526,Definite integral of absolute value function?,In my math textbook I had to compute definite integral which have a absolute value function like these below: $$\int_{-2}^{3} |x| dx$$ $$\int_{-2}^{3} |x-1| dx$$ $$\int_{-2\pi}^{2\pi} |sin x| dx$$ Should I use additive integration rule to compute them? Or should I assume that absolute value is always positive? Or both? Any suggestion?,"['integration', 'definite-integrals', 'absolute-value']"
2551556,Integer solutions of $x^3-19 = y^2$,"I am asked to find all integer solutions of the elliptic curve $x^3-19 = y^2$.
I've noticed so far that $x=7$ and $y=18$ is a solution and I've also noticed that $x$ and $y$ are coprime and that $x$ must be odd. I've been trying to work in $K=\mathbb{Q}(\sqrt{-19})$, but since $19 \equiv 1 \pmod{4}$, I haven't found a way to relate this equation with the ring of integers of $K$.","['number-theory', 'algebraic-number-theory']"
2551602,Two monotone functions which equal on rational numbers,"Let $f,g:\mathbb R\to \mathbb R$ be increasing and $f(r)=g(r)$ for every $r\in\mathbb Q$. Must we have $f(x)=g(x)$ for every $x\in\mathbb R$? Thanks in advance!","['real-analysis', 'calculus', 'functions']"
2551645,$\exists$ a non-compact space in which every proper open subset is compact?,"I was recently asked by a student whether there exists a topological space which is not compact, but in which every proper open subset is compact. I haven't been able to give an example, or a proof that no such space exists. So far the best I've been able to show is that such a space cannot contain a closed compact subset (in particular, it cannot be T1).","['general-topology', 'compactness']"
2551660,When are two measures equal?,"I am having trouble with a certain technical part of solving a problem. The question can be formulated as the following: Let $X$ be a locally compact Hausdorff space and $M(X)$ be the space of all regular Borel complex measures on $X$. Pick any $\mu, \nu \in M(X)$. We have that $$\int f \ d\mu = \int f \ d\nu$$
for every bounded continuous function $f$ on $X$. Is it sufficient to conclude that $\mu = \nu$? If not,then what additional condition is needed? I believe that since $C_0(X) \subset C_b(X)$ and $C_0(X)$ is a separating family of functions, it should be true.","['functional-analysis', 'measure-theory']"
2551670,$T$ selfadjoint with nonnegative spectrum implies $T=S^2$ for some selfadjoint $S$,"I have question regarding the following problem: Let $H$ be a Hilbert space and $T$ a bounded linear operator from $H$ to $H$. If we assume that $T$ is selfadjoint with spectrum in $[0,\infty)$ can we conclude that $T=S^2$ for some selfadjoint bounded operator $S$ (I know that this implies that $T$ is positive but I want to show the implication directly)? I started to define $X = T-aI$ where $a \in (-\infty,0)$. Then $X$ is selfadjoint and invertible but I don't know how to proceed.","['functional-analysis', 'spectral-theory', 'operator-theory', 'analysis']"
2551677,$T$ compact operator implies that every weakly convergent sequence $x_n$ implies strong convergence of $Tx_n$,"I'm working on a problem regarding compact operators and weakly convergent sequences. We know that an operator $T$ on a Hilbert space $H$ is compact iff for every bounded sequence $(x_n)_n \subset H$ its image $(Tx_n)_n \subset H$ admits a convergent subsequence (one can use this as a definition of a compact operator. I wanna show the following: Let $T$ be a compact operator on $H$. Then for every sequence $(x_n)_n \subset H$ which converges weakly to $0$, the sequence $(Tx_n)_n)$ converges to $0$ in norm. Can someone help me?","['functional-analysis', 'spectral-theory', 'operator-theory', 'analysis']"
2551698,How are the two forms of Green's theorem are equivalent?,"By the book's reasoning the two forms of Green's theorem are equivalent because if let F= G1 for the tangential form, we'd obtain the equation of the normal form of green's theorem and if assumed F=G2 in the Normal Form, we'd obtain the equation of the Tangential Form. How does being able to assume different vector fields F and plugging that vector field F in to obtain the other counterpart/side of Green's theorem/ the other side of the coin of Green's theorem imply that the tangential forma and normal form are equivalent? Why/how are there two versions of Green's theorem that are equivalent? The two forms don't look the same to me. We're substituting different vector field Fs in to make the circulation convertible to normal form and vise versa to show that theorem 4 equivalent to theorem 5 and that doesn't make sense or sound correct as a proof. Below: they used this switching technique of vector fields that I'm uncomfortable with. 
I don't think what they're doing makes sense:","['multivariable-calculus', 'greens-theorem', 'vector-analysis']"
2551745,"Arranging the letters of the word EDUCATION, so that the following conditions hold","How many ways to arrange the letters of the word EDUCATION, so that the following conditions hold: The vowels occur in the same order The consonants occur in the same order no two consonants are next to each other My approach: Suppose I arrange the consonants and so it looks like _D_C_T_N_ Now we need to arrange the vowels in the same order as they occur in the original word(they are being placed in the underscores ) Now, note that there are $5$ underscores and total no. of vowels $=5$ So, the problem boils down to the following: Find all integer solutions to the equation:$$x_1+x_2+x_3+x_4+x_5=5,$$
  where $x_2,x_3,x_4$ are not equal to $0$ I said that $x_2,x_3,x_4$ are not equal to $0$ , because no two consonants are next to each other , but $x_1$ and $x_5$ can be $0$. Now this is a modification of the famous Stars and Bars problem. How to go from here?","['permutations', 'combinatorics', 'combinations']"
2551859,Use greens theorem to find work done,"Use Green's Theorem to find the work done by the force $\mathbf{F}(x,y)=x(x+y)\mathbf{i}+xy^2\mathbf{j}$ in moving a particle from the origin along the $x$ -axis to $(1,0)$ , then along the line segment to $(0,1)$ , and back to the origin along the $y$ -axis. So I was able to find $\frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y}$ to be $y^2 -x$ and I integrated that with respect to $y$ and $x$ by using $y= 1-x$ as my upper bound and $y=0$ as my lower bound, and $0 < x < 1$ for my $x$ integral. but it came out to $-\frac{7}{36}$ , and the answer is $-\frac1{12}$ . I'm not sure if I'm doing something fundamentally wrong here or if its a calculation error. I checked it twice. How do I do it correctly?","['multivariable-calculus', 'greens-theorem', 'line-integrals']"
2551876,Every oriented vector bundle admits an orientation reversing isomorphism?,"Let $E$ be a real oriented vector bundle over a smooth manifold $M$.
Is there a vector bundle isomorphism $\Phi:E \to E$ which reverses the orientation? (I know there are oriented manifolds with no orientation-reversing diffeomorphism, but this is not the same question, of course. Even when we specialize $E=TM$, I am allowing morphisms which are not differentials of maps ).","['differential-topology', 'orientation', 'algebraic-topology', 'vector-bundles', 'differential-geometry']"
2551890,Restriction of adjoint map on measure space,"I am stuck at a certain computation in solving a problem. The problem can be formulated as the following: Let $X, Y$ be locally compact spaces and $C_b(X)$ denotes the space of bounded continuous functions on $X$ and $M(X)$ denotes the space of regular complex Borel measures on $X$. We have a linear map  $T: C_b(Y) \rightarrow C_b(X)$. Then we can get the adjoint map $T^*: C_b(X)^* \rightarrow C_b(Y)^*$ given by $$T^*(m)(f) = m(Tf)$$
for each $m\in C_b(X)^*, f\in C_b(Y)$.
We know that $M(X) \subset C_b(X)^*$. My question is the following: If for every $x\in X$, we have that $$T^*(\delta_x) = \delta_{x'}$$ for some $x'\in Y$ (here $\delta_x$ is the Dirac measure at the point $x$), then can we conclude that
$$T^*({M(X)}) \subset M(Y) \ \ ?$$ I believe it should be true since $C_0(X)^* = M(X)$ and since $C_0(X) \subset C_b(X) = C(\tilde{X})$ where $\tilde{X}$ is the one-point compactification of $X$. But I am not sure if this is the correct line of thought or if I am missing something here. Any help is greatly appreciated !","['functional-analysis', 'adjoint-operators', 'measure-theory', 'operator-theory']"
2551905,Find the sum of the double series $\sum_{k=1}^\infty \sum_{j=1}^\infty \frac{1}{(k+1)(j+1)(k+1+j)} $,"First, the original problem follows, 
$$\sum_{k=1}^\infty \frac{H_{k+1}}{k(k+1)}$$
where $$H_{k}=\sum_{j=1}^k \frac{1}{j}$$ is the $k$-th partial sum of harmonic series. Using the following identity,
$$H_{k+1} = \sum_{j=1}^\infty (\frac{1}{j} - \frac{1}{k+j+1}).$$
I was able to get this one.
$$\sum_{k=1}^\infty \frac{H_{k+1}}{k(k+1)}=\sum_{j=1}^\infty [\frac{1}{j} - \frac{1}{j+1} + \frac{1}{j+1}\sum_{k=1}^\infty \frac{1}{(k+1)(k+1+j)}] $$
So, If I get the sum of the double series, 
$$\sum_{k=1}^\infty \sum_{j=1}^\infty \frac{1}{(k+1)(j+1)(k+1+j)}.$$
I can also find the original problem. What method can I use at this problem?","['multivariable-calculus', 'harmonic-numbers', 'sequences-and-series']"
2551927,Isomorphic Chief series,"The question is as follows: A chief factor $\frac{K}{L}$ of a finite group $G$ is said to be central if $\frac{K}{L} \subseteq Z(\frac{G}{L})$. Show that all chief series for $G$ contain the same number of central factors. $\textbf{Definitions:}$ We know that a chief series of a group G is an invariant (normal) series
$$\{ e \} = G_r \subseteq \cdots G_1 \subseteq G_0 = G$$
of G such that $ G_i \subset G_{i-1}$ and if $G_i \subseteq N \subseteq G_{i-1}$ with $N \vartriangleleft G$, then either $G_{i-1}=N $ or
$N=G_i$. The factor groups $\frac{G_{i-1}}{G_i}$ are called the chief factors. A finite sequence 
$$ \{ e \} = G_n \subseteq \cdots G_1 \subseteq G_0 = G$$
of subgroups of $G$ is called subnormal series of $G$ if $G_i$ is a normal subgroup of $G_{i-1}$ for each $i$, $1 \leq i \leq n$. A subnormal series 
$$ \{ e \} = G_n \subseteq \cdots G_1 \subseteq G_0 = G$$
of group $G$ is called composition series if for $1 \leq i \leq r$ , all the non trivial factor group $\frac{G_{i-1}}{G_i}$ are simple. The factor groups of this series are called composition factors. Now let $ \{ e \} \subseteq G_n \subseteq \cdots G_1 \subseteq G_0 = G$ be a subnormal series  of $G$. Then a subnormal series  $ \{ e \} = H_n \subseteq \cdots H_1 \subseteq H_0 = G$  is called refinement of $G$ if every $G_i$ is one of the $H_j$’s. $\textbf{Idea}$  $\textbf{for} $ $ \textbf{to}$  $\textbf{prove} $ $\textbf{the}$ $\textbf{statement}$: First it is possible to prove that any two invariant (normal) series have isomorphic refinements. And then by using this we can prove that for a given Chief series, any other chief series is isomorphic to the given one. Now my question is that will it prove the desired result in the statement of the question? Thanks!","['finite-groups', 'group-theory']"
2551946,Other references for Marstrand's density theorem,"I am currently working on topics closely correlated with Marstrand's density theorem (If the measure has a density, then the exponent of the density is an integer). I was reading together Preiss's article and De Lellis's notes but I realised that the proof of Mastrand theorem in De Lellis's note is wrong: The mistake is that at pg 27 the baricenter $b(r)$ cannot pass to blowup, since it has not been normalized properly. Does anyone know another (modern enough) reference which I can use to read the proof? Marstrand's paper uses quite an obsolete notation and it is very hard to follow. Thank you in advance","['reference-request', 'geometric-measure-theory', 'measure-theory']"
2551961,Prove that for $(1-x)^m (1+x)^n$ there is no $k$ such that the coefficients of $x^k$ and $x^{k+1}$ are both $0$,"Prove that for
  $$(1-x)^m (1+x)^n$$
  there is no $k$ such that the coefficients of $x^k$ and $x^{k+1}$ are both $0$. I thought about this problem several times and can't make even a tentative answer I thought of two ways in breaking through so far thinking of it as $f(x)$ and the coefficient can be given as $f^{(k)}(0)$ (I mean the $k$-th order derivative and $0$ inserted on the derivative function) Then there may be some $k$ so that the $k$-th derivative can be divided by $x^2$. I can't get further from this point. expand the combination function as when $r$ is negative or is above $n$, $C(n,r)=0$ then the coefficient can be written as
$$\sum_{i=0}^k (-1)^iC(m,i)C(n,k-i)$$ This is my best.","['derivatives', 'binomial-theorem']"
2552024,Is there an example of an injective infinite triangular matrix?,"Let $A$ be an infinite upper triangular matrix with complex entries and all diagonal entries nonzero, i.e., \begin{align}
A=\left(\begin{matrix}
a_{11}&a_{12}&a_{13}&\cdots\\
a_{21}&a_{22}&a_{23}&\cdots\\
a_{31}&a_{32}&a_{33}&\cdots\\
\vdots&\vdots&\vdots&\ddots
\end{matrix}\right)
\end{align} where $a_{ij}=0(j<i)$ and $a_{ii}\neq 0(\forall i)$. Moreover, assume that $A$ represents a bounded linear operator on an $\ell^p$-space, and for convenience, say, from $\ell^2(\mathbb N)$ to itself. Although for the finitely dimensional case, such a triangular matrix must be bijective, the infinite-dimensional matrix $A$ does not have to be so. I previously asked a problem about it and a compact operator as an counterexample for it was formulated. What I would like to ask are: Is there any example that $A$ is injective and there are infinitely many subdiagonals of $A$ that are not eventually zero? and moreover, Is there any condition (sufficient or necessary) on the entries of $A$ for $A$ to be injective? Thanks in advance...","['functional-analysis', 'linear-algebra', 'hilbert-spaces', 'operator-theory']"
2552066,Limit of sum with binomial coeffs,"Let
$$S_{n}=\frac{1}{2^n}\sum_{k=1}^{n}{n\choose k}\frac{k}{n+k}$$, find the
$$y=\lim_{n\to +\infty}{S_{n}}$$ I can prove that $ \frac{1}{4} \leq S_{n} \leq \frac{1}{2}$: $$ {n\choose k}\frac{k}{2n} \leq {n\choose k}\frac{k}{n+k} \leq {n\choose k}\frac{k}{n} $$ $$ \frac{1}{2}\sum_{k=1}^{n}{n\choose k}\frac{k}{n} \leq \sum_{k=1}^{n}{n\choose k}\frac{k}{n+k} \leq \sum_{k=1}^{n}{n\choose k}\frac{k}{n} $$ $$ \frac{1}{2}\sum_{k=1}^{n}{n-1\choose k-1} \leq \sum_{k=1}^{n}{n\choose k}\frac{k}{n+k} \leq \sum_{k=1}^{n}{n-1\choose k-1} $$ $$2^{n-2} \leq \sum_{k=1}^{n}{n\choose k}\frac{k}{n+k} \leq 2^{n-1} $$ $$\frac{1}{4} \leq \frac{1}{2^n}\sum_{k=1}^{n}{n\choose k}\frac{k}{n+k} \leq \frac{1}{2} $$ Numeric evaluation shows that probably $y=\frac{1}{3}$. Also, I tried to apply differentiation and integration: $$(1+x)^n=\sum_{k=0}^{n}{n\choose k}{x^k}$$
differentiate:
$$n(1+x)^{n-1}=\sum_{k=1}^{n}{n\choose k}k{x^{k-1}}$$
multiply by $x^n$:
$$n{x^n}(1+x)^{n-1}=\sum_{k=1}^{n}{n\choose k}k{x^{n+k-1}}$$
take the $\int_{0}^{1}$:
$$n\int_{0}^{1}{x^n}(1+x)^{n-1}\,dx=\sum_{k=1}^{n}{n\choose k}\frac{k}{n+k}$$
that finally gives:
$$S_n=\frac{n}{2^n}\int_{0}^{1}{x^n}{(1+x)^{n-1}}\,dx$$ But I stuck finding the limit of this expression as ${n\to +\infty}$","['summation', 'binomial-coefficients', 'sequences-and-series', 'limits']"
2552073,Let $f(x)=|x|+|x-1|$. Check the differentiability of $f$ at $x=0$ and $x=1$,"Let $f(x)=|x|+|x-1|$. Check the differentiability of $f$ at $x=0$ and
  $x=1$ The short answer would be since $|x|$ is not differentiable at $x=0$ and $|x-1|$ is not differentiable at $x=1$, so $f(x)$ will not be differentiable at $x=0,1$ 
{Is it valid to claim this in every case ?} Long answer: $f(x)= \begin{cases} 1 - 2x & \text{ if } x< 0 \\ 1 & \text{ if } 0 \leq x < 1 \\ 2x -1 & \text{ if }x\geq1 \end{cases}$ $\lim_{x\to 0^{+}} \frac{f(x) - f(0)}{x-0}  = \lim_{x\to 0^+} \frac{1-1}{x-0} = 0$ $\lim_{x \to 0^-}\frac{f(x) - f(0)}{x-0}=\lim_{x \to 0^-} \frac{1-2x}{x-0}=  -\infty$ is not finite. So not differentiable at 0 $\lim_{x\to 1^+}\frac{f(x) - f(1)}{x-1}= \lim_{x\to 1^+}\frac{2(x-1)}{x-1} =2$ $\lim_{x \to  1^-}\frac{f(x) - f(1)}{x-1}=\lim_{x\to 1^-}\frac{1-1}{x-1}=0$ which are unequal and hence not differentiable at 1. Is this proof fine ?","['derivatives', 'real-analysis']"
2552106,How to show $|x|$ is convex on R?,How to show $f(x):=|x|$ is convex on R? $f(x) = \left\{ \begin{array}{cc}x & x\geq 0 \\ -x & x<0 \end{array} \right.$ $f'(x) = \left\{\begin{array}{cc} 1 &x> 0 \\ -1 & x<0 \end{array} \right.$ $\; \; f'(x)$ does not exist for $x=0$ $f''(x)=\left\{\begin{array}{cc} 0 &x> 0 \\ 0 & x<0 \end{array}\right.$ But still I don't know $f''(0)$ I wanted to show $f''(x)\geq 0 \; \forall \; x \in R$ to show that it is convex on R,"['derivatives', 'real-analysis']"
2552127,Interplay of Hausdorff metric and Lebesgue measure,"Consider the space $\mathcal{K}(\mathbb{R}^{n})$ of compact subsets of $\mathbb{R}^{n}$ endowed with the Hausdorff metric $\rho$, and let $\lambda$ denote the $n$-dimensional Lebesgue measure on $\mathbb{R}^{n}$. Now, I understand that $\lambda$ is not continuous with respect to $\rho$, i.e. that $[ \lim_{k \to \infty} \rho(K, K_{k}) = 0 ] \not \Rightarrow [ \lambda(K) = \lim_{k \to \infty} \lambda(K_{k}) ]$. But my question is: Suppose $\lambda(K_{i}) = \lambda(K_{j}) = C$ for every $i, j \in \mathbb{N}$, i.e. the sequence $k \mapsto \lambda(K_{k})$ is constant; does this imply that $\lambda(\lim_{k \to \infty} K_{k}) = C$? If not, I'm interested to see a counterexample. Thanks.","['lebesgue-measure', 'measure-theory']"
2552190,Show that $\left|\int_{-n}^{n}e^{iy^2}dy\right|\le 2$ for $n\ge 5.$,"Question is to show that 
$$\left|\int_{-n}^{n}e^{iy^2}dy\right|\le 2$$ when $n\geq5$, $x \in \mathbb R $ and $i$ is an imaginary unit. My effort: $$|\int_{-n}^{n}e^{iy^2}dy|\leq \int_{-n}^{n}|e^{iy^2}|dy=\int_{-n}^{n}|\cos(y^2)+i\sin(y^2)|dy$$ $$ \leq \int_{-n}^{n}|\cos(y^2)|dy+\int_{-n}^{n}|i||\sin(y^2)|dy$$ $$\leq \int_{-n}^{n}|\cos(y^2)|dy+\int_{-n}^{n}|\sin(y^2)|dy$$ It is also known that $|\cos(x)|,|\sin(x)|\leq1$ but its leading nowhere since integral then evalutes to $0$.. Any tips?","['fresnel-integrals', 'limits', 'complex-analysis', 'integration', 'analysis']"
2552278,An inner product which does not produce a Hilbert norm.,"I have a simple question: Consider the space of sequences $x = (x_1, x_2, \ldots$, $x_i,\ldots) \in \mathbb{R}$, for all $i \in \mathbb{N},$ such that $\sum_{k=1}^{+ \infty} x_k^2 < + \infty,$ with the product $\langle x,y \rangle = \sum_{k=1}^{+\infty} \frac{x_k y_k}{\sqrt{k}}$. Prove that this space is Euclidean, but not Hilbert. $\textbf{Idea for to show it:}$ For being Euclidean it is clear from the assumption $\sum_{k=1}^{+ \infty} x_{k}^{2} < + \infty$. For to not be Hilbert, we have to show that the norm induced by the defined inner product not satisfies in parallelogram equality $$\|x + y\|^2 + \|x-y\|^2 = 2(\|x\|^2 + \|y\|^2)$$
For example, if we suppose $x=(0, 0, \ldots , 1 , 0 , \ldots , 0)$, for 1 in the $m$th component and $y=(0, 0, \cdots , 1 , 0 , \ldots , 0)$ , for $1$ in the $n$th component for $m <n$, then we have
$$\|x\| = \sqrt{\langle x,x \rangle}= \sqrt{\frac{1}{\sqrt{m}}}$$ and $$\|y\| = \sqrt{\langle y,y \rangle}= \sqrt{\frac{1}{\sqrt{n}}}$$ and $$\|x+y\| = \sqrt{\langle x+y,x+y \rangle}= \sqrt{\frac{1}{\sqrt{n}}} + \sqrt{\frac{1}{\sqrt{m}}}$$ and $$\|x-y\| = \sqrt{\langle x-y,x-y \rangle}= \sqrt{\frac{1}{\sqrt{m}}} - \sqrt{\frac{1}{\sqrt{n}}}.$$ So we will have $\left(\sqrt{\frac{1}{\sqrt{n}}} + \sqrt{\frac{1}{\sqrt{m}}}\right)^2 + \left(\sqrt{\frac{1}{\sqrt{m}}} - \sqrt{\frac{1}{\sqrt{n}}}\right)^2 = 2\left(\sqrt{\frac{1}{\sqrt{m}}}\right)^2 + 2\left(\sqrt{\frac{1}{\sqrt{n}}}\right)^2 $ which will give us $2\left(\frac{1}{n} + \frac{1}{m}\right) = 2\left(\frac{1}{n} + \frac{1}{m}\right)$. So this example was not our counter example and we need to find an another example which shows the parallelogram equality not satisfies. Can you please give me a counter example? Thanks!","['functional-analysis', 'real-analysis']"
2552293,one-to-one correspondence between words an numbers,"How can I show that the set of all words using the letters a, b, and c are countable? The hint I was given says to establish a one-to-one correspondence with non-negative integers but I am not following the reason why.",['discrete-mathematics']
2552295,Proving MLE is asymptotically normal.,"I'm proving that mle is asymptitocally normal and I roughly follow the steps in this question . My problem now would be to proof that $$Z_n' = \frac 1 n \frac{d^2}{d\theta^2} \log \ell(\theta^*\mid x) \text{ converges to } I(\theta_0)$$ Here $\theta^*$ is the point obtained between the real value of the parameter and the solutions of the likelihood equation $\hat \theta = \hat \theta(X_1,\ldots,X_n)$. $\ell$ is the likelihood function. I clearly have that $\theta^* \to \theta_0$ almost surely. And as most texts cite Slutsky theorem I would like to apply what my notes state as Slutsky-Fréchet theorem, that is: $X_n \to X$ in probability and $g$ continuous then $g(X_n) \to g(X)$
  in probability. So I could take $\frac{d^2}{d\theta^2} \log(\theta\mid x)$ as $g$, in fact, to have a unique solution of the likelihood equation, I impose that it is continuous uniformly on $\theta$. The problem is that, in this way $g$ depends on $n$ and therefore I cannot obtain the wanted result $I(\theta_0)$. How do I solve this? My thoughts Apparently, this is further explained in Wilk's Mathematical Statistics 4.3.8. Someone dares to give a comprehensive approach to my situation? There are some things that surprise me even in this proof. What is $g_l,g_u$?  If $g$ is not continuous does it need to have a least upper bound and a greatest lowest bound? Also, how is that a stochastic process can have several variables (I read in Wikipedia that they need to be defined over the same probability space)?","['probability-theory', 'statistics', 'statistical-inference']"
2552376,Does a Homotopy on the Boundary Induce a Homotopy to the Entire Manifold?,"Let $M$ and $N$ be smooth manifolds where $M$ has a non-empty boundary.
Let $F:M\to N$ be a smooth map, and the restriction of $f$ on $\partial M$ be denoted as $f$.
Let $H:\partial M\times I\to N$ be a homotopy between $f$ and a smooth map $g:\partial M\to N$. Question. Does there necessarily exist a map $G:M\to N$ such that $G$ is homotopic to $F$ and the restrction of $G$ to $\partial M$ is $g$. The answer is true if we work in the continuous category rather than the smooth category, that is, $M$ and $N$ are topological manifolds, and $F, H, f$, and $g$ are continuous maps. This is because if $H:\partial M\times I\to N$ is a homotopy between $f$ and $g$, with $H_0=f$ and $H_1=g$, then we can paste $\partial M\times \{0\}$ along $\partial$ $M$ by identifying $(x, 0)$ with $x$, and get a new map $G:(M\cup (\partial M\times I))/\sim \ \to N$ which has the property that $G|_M = F$ and $G|_{\partial M\times \{1\}} = g$. Now we use the fact that $M$ admits a collar neighborhood homeomorphic to $\partial M\times I$ around its boundary to construct a homotopy between $F$ and $G$. Of course, this construction, as such, does not work for the smooth case, because there is no guarantee that the $G$ that we get is smooth, provided we give the manifold obtained after pasting a suitable smooth structure.","['general-topology', 'smooth-manifolds']"
2552422,When is an ordinary differential equation truly inexact?,"An exact ordinary differential equation is one of the form: $$M(x,y)dx+N(x,y)dy=0\tag{1}$$ where we must have that $$\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}\tag{2}$$ This is equivalent to saying that there is an underlying potential function whose total derivative gives the differential equation (1). When we have an ordinary differential equation of the form (1) that does not satisfy (2), we say that it is inexact. However what we normally do is realize that if we cleverly multiply the entire equation (1) by a function $\mu(x,y)$, called an ""integrating factor"", we can actually make the equation exact. In a sense, this seems to indicate to me that it actually was exact all along, just not manifestly exact. Is there a way to tell whether or not a differential equation of the form (1) is truly inexact, i.e. there exists no such integrating factor $\mu$ that will make it exact? Of course, I'm restricting my attention to well-behaved functions $M$ and $N$.",['ordinary-differential-equations']
2552441,Kernel of homomorphism in Zassenhaus/Butterfly lemma,"I was reading the proof of Zassenhaus Lemma in my textbook ""Fundamentals of Abstract Algebra by Malik, Moderson, Sen"". The lemma states that: Let $ H',H,K',K $ be subgroups of group $G$ such that $H'$ is normal
  in $H$ and $K'$ is normal in $K$.Then $H'(H\cap K')$ is normal in
  $H'(H\cap K)$ and $(H'\cap K)K'$ is normal in  $(H\cap K)K'$. Furthermore, $${H'(H\cap K)\over H'(H \cap K')} \cong {(H\cap K)K'\over (H'\cap K)K'}$$ The proof considers a homomorphism:
$$f: H'(H\cap K) \to {(H\cap K)\over (H\cap K')(H'\cap K)} $$
We need to show that the kernel of homoorphism $f$ is $H'(H \cap K').
$ Further using the First isomorphism theorem the lemma can be proved conveniently but only once we can obtain the kernel of $f$. 
I am not able to obtain this. Please help me to proceed. UPDATE: I got a way to somewhat proceed with this. It goes like: If we consider $a=h'x\in Ker(f)$ where $h'\in H',x\in (H\cap K)$ => $x\in J$
where $J=(H\cap K')(H'\cap K)$. Thus, $x=pq$ where $p\in (H\cap K') ,q\in (H'\cap K) \subset H' $. Hence, $a=h'x=h'pq=(h'q)p\in  H'(H \cap K')$ Any better explanation for the above portion please?",['group-theory']
2552445,Am I going to use the Lambert W function for this one?,"The question is simple. Now I have: $a \cdot \ln(b)=p$ and $a\cdot b^3=q$ Can I make $a$ and $b$ the subjects and express them in terms of $p$ and $q$? I looked up a bit and seems that the Lambert W function, $z=W(ze^z)$ is what is relevant, but I still cannot manage to make $a$ and $b$ the subjects. Thanks in advance!","['algebra-precalculus', 'lambert-w']"
2552463,A matrix raised to a high power ($87$),"So, I have this matrix: $$\pmatrix {0&0&0&-1\\1&0&0&0\\0&1&0&0\\0&0&1&0}^{87}$$ My teacher never discussed eigenvalues. So, I do not know what they are and there must be another way to do this (without multiplying the matrix $87$ times). Thanks for your help.","['matrices', 'linear-algebra']"
2552488,What is the sound of one argument permuting?,"A function $M:\left(\mathbb{R}^{n}\right)^{k}\to\mathbb{R}$, written $M\left[\mathfrak{a}_{1},\dots,\mathfrak{a}_{k}\right]$; where $\mathfrak{a}_{i}\in\mathbb{R}^{n}$ is said to be k-multilinear on $\mathbb{R}^{n}$ if it is linear in each of its arguuments. It is said to be alternating if $$M\left[\dots,\mathfrak{a}_{i}\dots,\mathfrak{a}_{i},\dots\right]=0.$$ That is, if any pair of arguuments are equal. Or, equivalently, if interchanging a pair of arguments reverses the the arithmetic singn of the function. That is, if 
$$M\left[\dots,\mathfrak{a}_{i}\dots,\mathfrak{a}_{j},\dots\right]=-M\left[\dots,\mathfrak{a}_{j}\dots,\mathfrak{a}_{i},\dots\right].$$ For example, $D:\left(\mathbb{R}^{n}\right)^{n}\to\mathbb{R},$ the determinant of an $n\times n$ matrix written as a function the column vectors $$D\left[\mathfrak{a}_{1},\dots,\mathfrak{a}_{n}\right]=\left|\begin{bmatrix}a_{\cdot1}^{1} & \dots & a_{\cdot n}^{1}\\
\vdots & \ddots & \vdots\\
a_{\cdot1}^{n} & \dots & a_{\cdot n}^{n}
\end{bmatrix}\right|,$$ is such a function. Edwards condescends: Notice that every linear function on $\mathbb{R}^{n}$ is automatically alternating. How do I interchange or make equal a pair of arguments in the function $L\left[\mathfrak{a}\right]\in\mathbb{R}$? Or, why should I conclude that a ""1-multilinear function"" is althernating?","['determinant', 'multivariable-calculus', 'logic', 'linear-algebra', 'definition']"
2552499,Show that $\mathbb{R}^{n}$ ($n>2$) minus a countable number of lines is still path-connected [duplicate],"This question already has answers here : Let $X$ be obtained by removing finitely many lines from $\mathbb{R}^3$. How do I prove $X$ is connected? (2 answers) Closed 6 years ago . Define $C$ to be a set of countable number of lines. Let $p,q$ be a couple of points in $\mathbb{R}^{n}\setminus C$. Then if the line segment $\bar{pq}\cap C=\emptyset$, we're done. If $\bar{pq}\cap C\neq\emptyset$, the intersection is a set of countable number of points. Since $n>2$, at each point in the intersection, there exists an arc that goes around the point. Thus, there exists a path connecting $p$ and $q$ that goes along the line segment $\bar{pq}$ with arcs replacing the points in $\bar{pq}\cap C$. Therefore, $\mathbb{R}^{n}\setminus C$ is path-connected. It's pointed out to me that this proof is not exactly correct. I don't know where it went wrong.","['general-topology', 'path-connected']"
2552524,Is a linear vector space a vector space?,"On the first page of the classical book ""Ordinary Differential Equations"" by Jack Hale (Revised Edition, 1980) there is the following definition: An abstract linear vector space (or linear space ) $\mathcal{X}$ over $\mathbb{R}$ is a collection of elements $\{x,y,\ldots\}$ such that for each $x,y \in \mathcal{X}$, the sum $x+y$ is defined, $x+y \in \mathcal{X}$, $x+y=y+x$ and there is an element $0 \in \mathcal{X}$ such that $x+0=x$ for all $x \in \mathcal{X}$. Also, for any number $a,b \in\mathbb{R}$, scalar multiplication $ax$ is defined, $ax \in \mathcal{X}$ and $1 \cdot x = x$, $(ab)x=a(bx)=b(ax)$, $(a+b)x=ax+bx$ for all $x,y \in \mathcal{X}$. The terminology linear vector space is the same as vector space (i.e., without the adjective linear )? I am asking this because a classical axiom of vector spaces is missing here: given an $x \in \mathcal{X}$ there is an element $z \in \mathcal{X}$ such that $x+z=0$, where the element $0$ was defined above. Question improvement : with respect to the definition of vector space , more axioms seem to be missing too, namely the associativity under $+$ and the scalar distributivity as $a(x+y) = ax + ay$. This was mentioned by more than one comment/post of contributors. Why is that?","['abstract-algebra', 'linear-algebra', 'vector-spaces']"
2552578,Limit of a function given a condition,"if $\lim_{x\to\infty}(f(x)+ \frac{1}{f(x)})$ exists.Prove or Disprove that $\lim_{x\to\infty}f(x)$ exists. I am totally clueless about this.
I don't know how to start and from where to start.
I tried to find some counter examples but could not get any","['functions', 'limits']"
2552594,Proving that there is no total ordering of $\mathbb{C}$ such that it is an ordered field,"Posting for proof verification and tips! Ordered field axioms used: 1. $\forall_{a,b\in\mathbb{F}}(0\leq a \land 0\leq b \implies 0\leq ab)$ 2. $\forall_{a,b\in\mathbb{F}}(a\leq b \implies a+c\leq b+c)$ Theorem 1: Let $\mathbb{F}$ be a field. If $x\in\mathbb{F}$, then  $\forall_{x\neq0}(0<x^2)$. Proof: Let $0\leq x$, then $ 0\leq x \land 0\leq x \implies 0\leq x^2$ by axiom (1) . 
We also know that $x^2=(-x)^2$, so that $ 0\leq x \land 0\leq x \implies 0\leq x^2$  and $ 0\leq x \land 0\leq x \implies 0\leq (-x)^2$. As $0\leq x$, $-x \leq 0$, so then $\forall_x(0\leq x^2).$ Let $x\neq0 \iff x^2\neq0$, then $[x^2\neq0 \land \forall_x(0\leq x^2)] \implies [\forall_x(0\lt x^2)]$$\tag*{$\Box$}$ With this fact, we can move on to the second part; there is no total orering of $\mathbb{C}$ such that it is an ordered field. Proof: We know that $i^2=-1<0$, which contradicts the just proven property: $\forall_{x\neq0}(0<x^2)$. This proof was originally a bit longer, but I saw that some steps were unnecessary or just stating the same thing repeatedly. However, having it reduced to this one line, I can't really believe this would pass as a valid proof... Maybe it's wrong to use the fact that $i^2=-1?$","['complex-analysis', 'ordered-fields']"
2552607,How is the volume of this pyramid obvious?,The corner of a unit cube is chopped off such that the cut runs through the three vertices adjacent to the vertex of the chosen corner. The chopped of part is a pyramid. The source says the volume of the pyramid is obviously $\frac16$. I don't understand how this is obvious. Can someone help me visualize this? I don't want a proper proof because I can also do that ie find the area of base and height and volume is $\frac13$ × base area × height. I want someone to help me visualize the result as to why this is obvious that the volume of the chopped off pyramid is $\frac16$th of the volume of the cube.,"['volume', '3d', 'geometry']"
2552613,How to find matrix exponential $e^A$,"I have the matrix $$A =\begin{pmatrix} 0 & 1 \\ - 1 & 0 \end{pmatrix}$$ and I have to find $e^A$ I've found two complex-conjugate eigenvalues $\lambda_{1,2} = \pm i$ so substracting $\lambda_1 = i$ from the matrix's diagonal I got: $$A_1 = \begin{pmatrix} -i & 1 \\-1 & i \end{pmatrix}$$ and therefore. to find eigenvector I have to solve the system: $$A_1 = \begin{pmatrix} -i & 1 \\-1 & i \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}$$ so the first eigenvector is $h_1 = \begin{pmatrix}1 \\ i\end{pmatrix}$
 and the second one is $h_2 = \begin{pmatrix}1 \\ -i\end{pmatrix}$ so the general solution is $$x(t) = C_1e^{it}\begin{pmatrix} 1 \\i\end{pmatrix} + C_2e^{-it}\begin{pmatrix} 1 \\-i\end{pmatrix}$$ I know that now I have to solve two Cauchy's problems for the standard basis $\mathbb{R}^2$ with vectors $v_1 = (1, 0)$ and $v_2 = (0,1)$ But I do not know how to approach it for complex numbers","['cauchy-problem', 'matrices', 'complex-analysis', 'matrix-exponential', 'ordinary-differential-equations']"
2552648,Order of automorphism group of abelian group,"In Derek Robinson's A Course in the Theory of Groups , exercise 1.5.13 states: Let $G=\mathbb{Z}_{p^{n_1}}\oplus\cdots\oplus\mathbb{Z}_{p^{n_k}}$, where $n_1<n_2<\cdots<n_k$. Prove there exists a chain of characteristic subgroups $1=G_0<G_1<\cdots<G_t=G$ such that $[G_{i+1}:G_i]=p$ and $t=\sum n_i$. Deduce that $|Aut(G)|=(p-1)p^r$ for some $r$. Now, this exercise is wrong.  What is true, however, is that $$|Aut(G)|=(p-1)^kp^r$$ for some $r$.  Is there an elementary way to prove this? It's pretty easy to see that if $\alpha\in Aut(G)$ fixes pointwise the quotients $G_{i+1}/G_i$, then it has order a power of $p$. If $N\lhd Aut(G)$ is the subgroup of all such $\alpha$, then for every $xN\in Aut(G)/N$, $(xN)^{p-1}=1$. That is, $Aut(G)/N$ has exponent $p-1$. But I don't see a way to show $|Aut(G)/N|=(p-1)^k$. Of course, it is entirely possible such an easy proof does not exist. But that makes me wonder what the point of Robinson's exercise is.","['p-groups', 'automorphism-group', 'finite-groups', 'abelian-groups', 'group-theory']"
2552673,"$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}$","what is the minimum number of $k$ for which the following limit exist
$$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}$$ 
I know that  $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{n}$$
doesn't exist, and $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^8}}} = 0.$$
But i don't know what is the minimum  number of $k$ for existing that limit.
(note that here n's are positive integers not real numbers)","['sequences-and-series', 'calculus']"
2552687,Distance between line and point,"Using 2D cartesian co-ordinates: $Point = (x, y)$ $Line = (x_1,y_1),(x_2,y_2)$ Here we are taking $(x_1,y_1)$ and $(x_2, y_2)$ as line segment ends, not points on the infinitely extended line between those points. How can we calculate, if the point is perpendicular to the line, the distance between the two?",['trigonometry']
2552710,$|G| \geq4 |Z(G)|$,"Let $(G, \times)$ be a finite non abelian group and let $Z(G)$ be it center. I would like to proove that : $| G | \geq 4 | Z(G) |$ I don't have the intuition of this result and 
I don't know how to prove this result but maybe I should use the following properties : $Z(G)$ is a group $| Z(G) |\mid |G|$ Cayley table","['finite-groups', 'group-theory']"
2552775,Show that $\sin x$ lies between $x-x^3/6$ and $x \;$ $\forall x \in R$ [duplicate],This question already has answers here : Proving that $x - \frac{x^3}{3!} < \sin x < x$ for all $x>0$ (5 answers) Closed 6 years ago . Show that $\sin x$ lies between $x-x^3/6$ and $x \;$ $\forall x \in R$ I am getting: $$\sin(x) = x - \frac{x^3}{3!} + R_4(x)$$ where $R_4(x) = \frac{\cos(c)x^5}{5!}$ for some $c$ between $0$ and $x$ I want to prove $R_4(x)\geq 0$ to arrive at the result $x-x^3/3 \leq \sin(x)$. for:$$0 \leq x \leq \pi/2 \Rightarrow 0<c<\pi/2 \Rightarrow R_4(x)\geq 0$$ but for: $$-\pi/2 \leq x < 0 \Rightarrow -\pi/2 < c < 0  \Rightarrow R_4(x) < 0$$ How can I proceed with this ? There are many cases that I need to check,"['real-analysis', 'ordinary-differential-equations']"
2552776,Smallest positive integer $n$ such that $S_n$ has an element of order $2n$,"The Problem: Find the smallest positive integer $n$ such that $S_n$  has an element of order greater than $2n$ Let $n$ be an even positive integer. Prove that $A_n$ had an element of order greater than $2n$ if and only if $n\ge 14$ I know that a permutation can be written as a product of disjoint cycles and the order of the LCM of the lengths of these cycles is the order of that permutation. Also if you write a permutation as a product of its disjoint cycles considering the invariant elements to be $1$-cycles, then the lengths of the disjoint cycles, $\{n_1,n_2,\cdots,n_k\}$, constitute a partition of the integer $n$. Then we need to find out the least integer $n$ such that the LCM of $n_1,n_2,\cdots,n_k$ for some partition of $n$ is $\ge 2n$. I don't know what to do next? Please help.","['abstract-algebra', 'group-theory', 'symmetric-groups']"
2552883,Greasy (not greedy) Traveling Salesman Problem,"This is a variation upon the Traveling Salesman Problem. We've got a greasy salesman, Harold Hill, who is going to try to con towns into buying marching band equipment. To simplify things, the n towns are represented as $K_{n}$ complete graph with the distance between each town being the same. We define a step to be the following. For each step, Hill travels to another town that he has not visited before. Each town that he has visited has another salesman come from it, going to a different random town and spreading the word that Hill is a con man. Hill will never go to a town that knows he is a con, and he will never go to a town that another salesman is going to at the same time. What is the expected number of towns that Hill will be able to visit? For $n=2$, call the towns A and B.
At $t=0$, Hill cons town A. At $t=1$, he travels to town $B$, conning them. Another salesman starts at town A. E[towns] = 2 For $n=3$ with towns A, B, and C.
At $t=0$, Hill cons town A. At $t=1$, he travels WLOG to town $B$, conning them. Another salesman starts at town A. At $t=2$, Hill can only head to town C. However, the salesman at town A has a $\frac{1}{2}$ probability of going to town C, which would prevent Hill from going. Thus, E[towns] = 2.5. For $n=4$ with towns A, B, C, and D.
At $t=0$, Hill cons town A. At $t=1$, he travels WLOG to town $B$, conning them. Another salesman starts at town A. At $t=2$, Hill can head to town C or D. If the salesman goes to one of these, he goes to the other, and at that point has no more towns to go to. Probability is (2/3) and E[towns] = 3. If the other salesman goes to town B, we say Hill goes to town C. Furthermore, as said, town B, having just been scammed by Hill, has another salesman come from it. Thus, we now have Hill at C and two salesmen at town B. Hill can only go to town D, but there is a 5/9 chance that at least one of the other two salesmen also head there, preventing him from going. Probability of Hill getting to 3 towns is (1/3)*(5/9) and probability of 4 towns is (1/3)(4/9). Thus, E[towns] = $(2/3)*3 + (5/27)*3+(4/27)*4 = 85/27 = 3.148\dots$. The specific question that I have is to calculate E[towns] when $n = 10$. I've got a simulation running to get a decent estimation, but I would like to know if there is a better way to calculate this.","['graph-theory', 'recreational-mathematics', 'probability']"
2552890,Expected number of coin tosses with a coin that changes over time,"Imagine that I have a coin that changes monotonically over time. -- casino example -- (This is not necessary to understand mathematical problem, but just can help to imagine a real life situation, you can skip it) Imagine that you are in a very clever casino
The coin is made of insulator, one side is charged with positive charges and another with negative ones. Croupier flips the coin on a table that is made of a metal board covered with an insulator. Casino charged the metal board with positive charges. The croupier tosses the coin - it has higher probability to end 'positive up' (the negative charges on coin are attracted by positive ones on table) and I am winning. Then between tosses casino slightly charges the metal board with negative charges, so the coin becomes more likely to end 'negative up'. And with time I start loosing - good fortune seems gone. -- end of example -- Let's note $p(t)$ the probability of tossing a tail in a discrete moment $t \ge 0$. We assume that: $p(t+1) > p(t)$, $\lim_{t\rightarrow\infty}p(t) = 1$ Questions: A. How to calculate an expected number of coin tosses to get $n$ consecutive tails? This is a general question, we are just assuming $p(t)$ as above. B. What would be a formula for this particular form of $p(t)$: $$
p(t) = \frac{1}{1+e^{-\frac{1}{\tau}(t-t_0)}}
$$
with $t_0 \ge 0$, $\tau > 0$. I am interested in a formula of a form:
$$
N(n, t_0, \tau) = \dots
$$ I am looking for answers to both questions. But if you only give me an answer to  B., I will be very grateful too. PS This is a generalization of this question .","['probability', 'gambling']"
2552893,Are all smooth functions Lipschitz?,"Can we prove the following statement:
 $$\|\triangledown f(x)-\triangledown f(y)\|\leq\beta\|x-y\|\xrightarrow{?} \| f(x)-f(y)\|\leq L\|x-y\|$$
i.e. every smooth function is Lipschitz? If it is not correct please tell me under what conditions it can be correct. In the comments of this question an example is given that exponential function is smooth and is not Lipschitz. However I can't find any $\beta$ such that $\|e^x-e^y\|\leq \beta\|x-y\|$ and derivative of exponential equals to itself!","['lipschitz-functions', 'functions']"
2552895,"Uniformly random number on $[0,1]$ has zero entropy?","I am computing then entropy of the uniform distribution on $[0,1]$: $$ H(X) = \frac{1}{1-0} \int_0^1 (1 - 0) \log 1 \, dx = 0 $$ Does that mean at $X$ has zero entropy?","['information-theory', 'entropy', 'probability']"
2552992,"Given 4 mutually non-intersecting lines in the given projective spaces of dimension $3$, how many lines intersect them all?","I have the following question as a part of my homework set, I'm having trouble deciding on how to approach the problem: Given 4 mutually non-intersecting lines in a) $\mathbb{P(C^4)} \ $ b) $\mathbb{P(R^4)}$ how many lines intersect them all? I know that in $\mathbb{P_3}$, 3 mutually non-intersecting line have infinite many lines intersecting them, forming the ruling unique smooth quadric. What can I say if I introduce a 4th line? So, is it correct to say that there are at most 2 lines intersecting them? As the 4th line will intersect the quadric at at most 2 points?",['algebraic-geometry']
2553072,Example of submanifold without subspace topology,"I am interested in giving an example for a closed, connected submanifold of a connected manifold which does not carry the subspace (or relative) topology. With some help from Boothby (III.4 p.71-72), I believe an example could be the following: Let $F : \mathbb{R} \to \mathbb{R}^2$ be given by $$F(t) = \left( 2 \cos\left( t - \frac{1}{2} \pi \right), \sin 2 \left(t - \frac{1}{2} \pi \right) \right) {;}$$ the image is a figure eight. Now, let $g(t)$ be a monotone increasing smooth function on $- \infty < t < \infty$ such that $g(0) = \pi$, $\lim\limits_{t \to - \infty} g(t) = 0$ and $\lim\limits_{t \to \infty} g(t) = 2 \pi$ (e.g., we may use $g(t) = \pi + 2 \arctan{t}$). Then define $G : \mathbb{R} \to \mathbb{R}^2$ by composition of $g(t)$ with $F(t)$: $$G(t) = F(g(t)) = \left( 2 \cos \left( g(t) - \frac{\pi}{2} \right), \sin 2 \left( g(t) - \frac{\pi}{2} \right) \right) {;}$$ note that $G(t)$ is an injective immersion. By definition, it follows that $G(\mathbb{R}) = \tilde{N}$ is a submanifold (or immersed submanifold) of $\mathbb{R}^2$. From this point, it gets tricky and I am unsure of how to show whether or not $\tilde{N}$ is closed. Boothby notes that $\mathbb{R}$ is not homeomorphic (under $G$) to $\tilde{N}$ considered as a subspace of $\mathbb{R}^2$. It seems reasonable that $\tilde{N}$ is closed, if $\mathbb{R}^2 - \tilde{N}$ is open, though I would like to be able to justify this rigorously. Is this an example of what I am looking for? If not, could someone point me in the right direction? Any hints or suggestions would be greatly appreciated. Edit: The image of a connected space under a continuous map is connected, and thus $\tilde{N}$ is connected.","['examples-counterexamples', 'smooth-manifolds', 'submanifold', 'general-topology', 'differential-geometry']"
2553103,"$C_c(X)$ is complete, then $X$ is compact","Let $X$ be a locally compact Hausdorff space such that $C_c(X),$ the space of all continuous functions with compact support is complete. Show that $X$ is compact. My attempt: I have shown that $C_c(X)$ is dense in $C_0(X),$ the space of all continuous functions vanishing at infinity. Since $C_c(X)$ is complete, therefore $$C_c(X)=C_0(X).$$ Now to conclude that $X$ is compact, it suffices to find a function in $C_0(X)$ which vanishes nowhere on $X.$ Is this always possible?","['functional-analysis', 'banach-algebras']"
2553131,Solving functional differential equation $f'(x)=2f(2x)-f(x)$,"Show that there is at least a nonzero function $f$, differentiable on $[0,+\infty)$, satisfying $$f'(x)=2f(2x)-f(x) \qquad \forall x>0 $$
  $$M_n:=\int_{0}^{\infty}x^nf(x)dx<\infty \qquad \forall n\in
 \mathbb{N} $$ My best idea so far is to assume that the solution is a power series, i.e. 
$$ f(x)=\sum_{n=0}^{\infty}a_nx^n\qquad \forall x>0$$
Then the equation becomes
$$ \sum_{n=0}^{\infty}na_nx^{n-1}=2\sum_{n=0}^{\infty}a_n2^nx^n-\sum_{n=0}^{\infty}a_nx^n$$
equating all the coefficients of the same degree I get
$$na_n=(2^{n}-1)a_{n-1}\qquad \forall n\geq 1$$
So setting $a_0=1$, I get
$$a_{n}=\frac{1}{n!}\prod_{k=1}^{n}(2^k-1) \qquad \forall n$$
But does the power series actually converge? Using Hadamard's formula, and that $2^{k}-1\geq 2^{k-1}$,
$$ |a_n|^{1/n}\geq\frac{1}{(n!)^{1/n}}\left[2^{n(n-1)/2}\right]^{1/n}\sim\frac{e}{n(2\pi n)^{1/2n}}2^{(n-1)/2}\to \infty$$
so the radius of converge of the series is $0$, so it doesn't actually define a solution on $[0,+\infty)$.","['ordinary-differential-equations', 'functional-equations']"
2553135,How many ways can 8 boys and 8 girls be paired,I am trying to figure out how many combinations you can get if $8$ boys are paired up with $8$ girls. I was thinking it could possibly be something like $8!$ or $8! \cdot 8!$. Something with factorials but I'm not sure.,['discrete-mathematics']
2553167,"Calculate $\lim\limits_{n\rightarrow \infty} \int\limits_0^\infty \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)} \, d x$","In preparation for finals, I am trying to calculate $$\lim_{n\rightarrow \infty} \int\limits_0^\infty \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)} \, d x$$ with proof. Here is my approach/what I have done so far: 
If we can find a dominating function, we have $$\lim_{n\rightarrow \infty} \int\limits_0^\infty \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)} \, d x = \int\limits_0^\infty \lim_{n\rightarrow \infty}  \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)} \, d x$$ by the Dominated Convergence Theorem. If we let $f_{n} = \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)}$, then $f_{n}(x)$ converges to $0$ for all $x > 0$, which implies the limit is equal to 0 because the Dominated Convergence Theorem only requires a.e. convergence (so not having convergence at $x = 0$ is no issue). Operating under the assumption that dominating function exists, is this correct? As far as finding a dominating function is concerned, we have 
$$ 
|f_{n}| = \left| \frac{n^2 \sin(x/n)}{n^3x + x(1 + x^3)} \right| = \frac{|n^2 \sin(n/x)|}{n^3x + x(1 + x^3)} \leq \frac{n^2}{n^3x + x(1 + x^3)},
$$
which is where I get stuck. The two directions that seemed the most clear from here was to either 
$$ 
\frac{n^2}{n^3x + x(1 + x^3)} \leq\frac{n^2}{n^3x} = \frac{1}{x} \quad \text{or} \quad \frac{n^2}{n^3x + x(1 + x^3)} \leq \frac{n^2}{x(1 + x^3)}.
$$
The former is not integrable and I cannot seem to grapple with the $n^2$ on the latter and sufficiently bound it. So my main question is how can I bound $|f_{n}|$?","['real-analysis', 'integration', 'limits']"
2553189,Surface area of a cone contained in a cylinder,"Given the cone $z^2=x^2+y^2$, $z\geq 0$ and the cylinder $z^2+y^2=64$ I am looking for the surface area of the section of the cone inside of the cylinder. I can parametrize the cone as: $r(t,\theta)=\langle tcos(\theta), tsin(\theta), t \rangle$ The cone gives me the inequality: $z^2 \leq 64-y^2 \iff z \leq \sqrt{64-y^2}$ (since $z \geq 0$) Plugin in the values of the parametrization: $t^2 \leq 64-t^2\sin^2(\theta) \iff t \leq \frac{8}{\sqrt{sin^2(\theta)+1}}$ I know the Jacobian of the partial derivatives is: $|r_\theta\times r_t| = \sqrt2t$ Thus the surface area should be: $\int^{2\pi}_0\int^{\sqrt{\frac{8}{sin^2(\theta)+1}}}_0\sqrt2t$ $dt d\theta$ However with this method I end up trying to integrate $\frac{1}{sin^2(\theta)+1}$ with respect to $\theta$ which not only do I not know how to do, but it makes me think my method is wrong. EDIT: attempting to compute that integral with the help of wolfram tells me the surface area is 0, which is trivially false. So I have done something wrong.","['calculus', 'multivariable-calculus', 'integration', 'differential-geometry', 'vector-analysis']"
2553196,Convolution formula for multisets coefficients,"I've been trying to solve the following problem: (a) Give two proofs of the binomial coefficient identity, called the convolution formula, $\sum_{j = 0}^k \binom{m}{j}\binom{n}{k - j} = \binom{m + n}{k}$. (b) Discover and prove an analogous identity for multiset coefficients $\bigg(\binom{n}{k}\bigg)$ Part (a) is not hard to prove since $\binom{n + m}{k}$ represents all the ways in which we can form a group with $k$ members with $m$ men and $n$ women. The left-hand side is counting exactly the same fixing previously the number of women or men. But I do not know how to solve incise (b). Please a hint would be awesome! Thanks in advance!","['binomial-theorem', 'multisets', 'binomial-coefficients', 'generating-functions', 'combinatorics']"
2553201,Universal Property of Integral Closure,"I'm trying to understand an exercise from Hartshorne's book, Algebraic Geometry , about normalization of an integral scheme. So, I'm reduced to prove the affine case and then glue. In dealing with this case, I did not know how to express the dual property for rings. Being specific, Let $A$ be an integral domain, and $\tilde A$ its integral closure in its total ring of quotients. I guess that the universal property enjoyed by $\tilde A$ is this: Given a ring $B$ integrally closed, and a ring homomorphism $f:A\longrightarrow B$, there is a unique ring homomorphism $\tilde f:\tilde A\longrightarrow B$, such that $\tilde f\iota=f$, where $\iota$ is the inclusion of $A$ in $\tilde A$. As I mentioned, I don't know if this property is the right one, or if I have to put something more on the morphism $f$. I tried without success to show that in fact, $\tilde A$ has the property that I wrote. I guess I'm missing something. I've looked in Matsumura's book and Eisenbud's book, but I did not find this formulation. I would be very grateful if someone can tell me what is the correct property, and in case I was correct, how to prove it.","['algebraic-geometry', 'commutative-algebra']"
2553266,Ellipse: Concurrency of Normals,"Consider ellipse $E$ with foci $S_{1}$, $S_{2}$ and its minor and major auxiliary circles (denoted by $W_{1}$ and $W_{2}$).  Let the circle $W$ be tangent to $W_{1}$ and $W_{2}$, and meet ellipse $E$ at $P$, $Q$, $R$, $T$.  Prove that some three of the four normals at $P$, $Q$, $R$, $T$ are concurrent. I wish to solve this using Coordinate Geometry , but my approach seems to be very lengthy and time-taking. Here's what I propose: Assuming the equation of a standard ellipse, corresponding major and minor auxiliary circles Finding a circle ( I'm not sure if this circle is unique, or not. If not, then how should I write the general equation of such a circle? ) touching both $x^2+y^2=a^2$ and $x^2+y^2=b^2$ (major and minor auxiliary circles). Solving the equation obtained in (2) with the ellipse. I expect a fourth degree equation to arise, as the ellipse intersects the circle at exactly four points (as shown in the figure). Writing the equation of normal to an ellipse at some point $(a\cos \phi, b\sin \phi)$.  Note that this point also satisfies equation obtained in (3) I'm not sure how to proceed further. Also, is there a shorter method to approach this problem?
It'd be great if someone could post a solution using Coordinate Geometry. Thanks a lot!","['circles', 'contest-math', 'conic-sections', 'geometry']"
2553272,"Proof. Given a DAG $G$, for every vertex $v$ in $G$, there is a path from $v$ to some sink in $G$.","Given a DAG $G$, for every vertex $v$ in $G$, there is a path from $v$ to some sink in $G$. I am really having difficult understand the given solution since I am still improving my English skill. Thank you for any tips to understand it. Given solution: True. Consider the proof below. Proof. Suppose by contradiction that there exists a vertex $v_0$ such that there is no path from $v_0$ to a sink. Suppose that $G$ has $n$ vertices. Then we can make a path by following any of the outgoing edges of $v_0$. Call the next vertex in the path $v_1$. Since $v_1$ is not a sink ( How do we know V1 is not a sink? ), it has an outgoing edge ( Yes, we call a vertex a sink when it has not outgoing edges, but how do we know it has outgoing edge at the first place? ), follow one of its outgoing edge and call the adjacent vertex $v_2$. Keep on doing this until you get a list of $n+1$ vertices $v_0,v_1,\ldots,v_n$. ( Even we finish all the vertex, how do we know there are at least two vertices in the list are the same? I don't think it is not necessary; for example: $A\to B\to C\to D$, it is DAG and even we visited all the vertices start from $0$ to $n+1$ there doesn't exit a cycle. ) By the pigeonhole principle, at least two vertices in this list are the same and therefore there exists a cycle. Thank you again.","['graph-theory', 'proof-explanation', 'discrete-mathematics']"
2553292,Explanation of this hint involving the summation of cosine and sine [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 6 years ago . I have this question Let $n \ge 2$ be an integer.  Prove that $$\sum_{k=0}^{n-1}\cos(\frac{2k\pi}{n}) = 0 = \sum_{k=0}^{n-1}\sin(\frac{2k\pi}{n})$$ I was given the hint to Set $z = \cos(\frac{2\pi}{n}) + i\sin(\frac{2\pi}{n})$, so $z^n=1$.  Now write this as $(z-1)(z^{n-1}+z^{n-2}+...+z^2+z+1)=0$ and go from there... I get that $(z-1)(z^{n-1}+z^{n-2}+...+z^2+z+1)=0$ is just an expansion and rearrangement of $z^n=1$, but what I don't understand is, why set $z = \cos(\frac{2\pi}n) + i\sin(\frac{2\pi}{n})$ and how do we know that $z^n=1$","['proof-writing', 'trigonometry', 'sequences-and-series', 'complex-numbers']"
2553301,Proof the Grassmannian is a local functor?,"The Grassmannian functor $\mathrm{Gr}_{n, r}$ sends a ring $A$ to the set of rank $n$ summands of the free module $A^{n + r}$.  This is a local functor and I.1.3.13 of Demazure and Gabriels book ""Introduction to Algebraic Geometry and Algebraic Groups"" supposedly contains a proof of this fact. I've been staring at this proof for a week and I just can't parse it.  I would love if there was a second source that I could compare with but everything I've found deals with the Grassmannian as a locally ringed space, not a functor.  Does anyone know of a second source that deals with the Grassmannian as a functor?","['category-theory', 'reference-request', 'grassmannian', 'algebraic-geometry']"
2553341,"How to construct a bijection between $\{0,1,\dots,2017\}×\Bbb N$ and $\Bbb N$?","How to construct a bijection between $\{0,1,\dots,2017\}×\Bbb N$ and $\Bbb N$? I've tried to come up with different combinations, but no luck. Any ideas how to solve this problem?",['functions']
2553367,Is $\aleph_0 = \mathfrak{c}$?,"As we all know that $2^{\aleph_0}=\mathfrak{c}$, where $\aleph_0$ (pronounced as aleph-not) is the cardinality of the set of natural number(countably infinite) and '$\mathfrak{c}$' is the cardinality of the set of real numbers,which is uncountably infinite.
From the above given formula one can easily conclude that $\mathfrak{c}$ can never be equal to $\aleph_0$. However,when we consider infinite sets ,there is a very well known theorem that an infinite set is numerically equivalent to a subset of itself.
Considering the set of natural numbers which is a subset of real numbers, then the above theorem states that the cardinality of the set of natural numbers is equal to the cardinality of real numbers. Therefore we can conclude that $\aleph_0$ = $\mathfrak{c}$. 
Is it that the  definition of subset changes when we consider an uncountably infinite set? When we consider subsets of an uncountably infinite set,does it implies that the subsets are also uncountably infinite?","['cardinals', 'infinity', 'elementary-set-theory']"
2553378,Prove diagonal entries of positive definite matrices cannot be smaller than the eigenvalues,"The aim is to prove that the diagonal entries of a positive definite matrix cannot be smaller than any of the eigenvalues. I know a positive definite matrix must have eigenvalues that are > 0, and that just because a matrix has all positive values, does not make it a positive definite matrix. 
I've also looked at the wikipedia for Positive-definite matrices and understand the definition given there, but am having a hard time convincing myself that the diagonal entries have to be greater than the eigenvalues. The starting point of the proof should be to consider $A−a_{ii}I$, where $A=A^T$, and A is the positive definite matrix. Can anyone help push me in the right direction to complete the proof?","['matrices', 'positive-definite', 'linear-algebra']"
2553381,"Given a convergent series of positive rationals, how many subseries can converge to the same number?","Let us have a sequence $a_n$ of positive rational numbers, for which $\sum a_n = R \in \mathbb R$. Now suppose $b_n$ is a subsequence of $a_n$ such that $\sum b_n = r < R$. The question is "" Can there be an uncountable number of subsequences of $a_n$ whose sum is $r$, for some sequence of positive rationals $a_n$ and some $r\in\mathbb R$? "" To be clear on definitions, a sequence and all its subsequences must be mappings from $\mathbb N\to X$, where in this case $X$ is the set of positive rational numbers.",['sequences-and-series']
2553406,Rank of a matrix of L.T. which is not one one,If we take a linear transformation $T$ from $R^n$ to $R^n$ and assume that it is not one-one. Can we find what exactly its rank is? If it is one-one then $\ker T =\{0\}$ and the matrix of the L.T. must be non singular and therefore rank will be $n$. But if it is not one-one then rank must be less than $n$. But can we get the exact rank of the matrix of L.T.?,"['matrices', 'matrix-rank', 'linear-algebra', 'linear-transformations']"
2553408,First Order Time-Variant System : Picard Method,"I looking at a time variant first order system. I am trying to prove that a sequence of functions $x^{[k]}(t)$ generated using Picard iterations converges uniformly on some interval $[0,T]$. Given: $\dot{x}(t)=A(t)x(t)$ where $x(0)=x_0$ $x(t)=x∈R^n$ where $A(t)$ is a $n×n$ matrix Assume there exists $M$ such that $||A(t)||\le M$ for all $t\ge 0$ and that $A(t)$ is a piecewise continuous function. Show that, for any $T > 0$, a solution exists in the interval $[0,T]$. I know that $x(t)=x_0+\int^t_0A(τ)x(τ) dτ$ must be satisfied if the solution does indeed exist. I am supposed to use Picard iterations to prove this, which I am not familiar with yet. But I know that they are of the form: $x^{[k+1]}=x_0+\int^t_0A(τ)x^{[k]}(τ) dτ$. Where $x^{[0]}(t)=x_0$ Can I use the standard Picard proof to prove this or do I need to start somewhere else? I was also asked to show that this method satisfies $|x^{[k+1]}(t)-x^{[k]}(t)|\le |x_0| $$\frac{π^{k+1}(t)}{(k+1)!}$ where $π(t)=\int^t_0||A(τ)||dτ$. I have no idea where to start with this, but hopefully it will become clearer once I finish the first part.","['real-analysis', 'uniform-convergence', 'picard-scheme', 'ordinary-differential-equations', 'convergence-divergence']"
2553545,How can we find $\lim_{n \rightarrow +\infty}\int_{1}^{n} \frac{\cos(nx)(x-1)}{\sqrt{\ln^3(x)(1+x^4)}}dx $?,"I have a question about improper integrals: How can we find $\lim_{n \rightarrow +\infty} \int_{1}^{n} \frac{\cos(nx)(x-1)}{\sqrt{\ln^3(x)(1+x^4)}}dx$? $\textbf{Some effort:}$ We know that $-1 \leq \cos(nx) \leq 1$, so we will try to sandwich it: $$-\lim_{n \rightarrow +\infty} \int_{1}^{n} \frac{(x-1)}{\sqrt{\ln^3(x)(1+x^4)}}dx \leq \lim_{n \rightarrow +\infty} \int_{1}^{n} \frac{\cos(nx)(x-1)}{\sqrt{\ln^3(x)(1+x^4)}}dx \leq \mbox{$\displaystyle\lim_{n \rightarrow +\infty} \int_{1}^{n} \frac{(x-1)}{\sqrt{\ln^3(x)(1+x^4)}}dx$} $$
The next step is to get rid of the natural logarithm, which will be by using the change of variables and letting $\ln(x)=u$. But this makes the situation worse. I am interested of using again sandwich rule for natural logarithm as well. But I do not know that $\ln(x) < ?$ and $\ln(x) > ?$ for $x \in [0,+\infty]$? Can you please give me an idea? Thanks!","['improper-integrals', 'real-analysis', 'integration']"
2553568,"Hello folks, how should I proceed to solve this differential equation through power series?","The problem is: $$
y'-y = x \\   
y(0) = 0
$$ I know I have use the general form and its derivatives $$
\sum a_n(x-x_0)^n
$$ My problem is with the alone $x$ variable on the right side. Could someone give me any tips? Thanks in advance!","['ordinary-differential-equations', 'power-series']"
2553598,Value of an expression involving polynomial function,"If $f(1) = 10$, $f(2) = 20$, $f(3) = 30$ and $f(x) =(x^4 +ax^3 + bx^2 +cx + d) $ then find the value of $\frac{f(12) + f(-8)}{(10)}$ My attempt: I tried to substitute the values in the numerator but could not get rid of d. Since there are three known values I don't know how to get values of all four constants. Any help will be appreciated.","['polynomials', 'functions']"
2553733,"From a ""low-level"" point of view, is the curvature form a covariant exterior derivative?","Let $(\mathcal E,\pi,M)$ be a G-vector bundle with a linear connection. On the associated principal bundle, it is true that $\Omega=d_\omega\omega$, where $\Omega$ is the curvature form, $d_\omega=d\circ h^*$ is the covariant exterior derivative and $\omega$ is the $\mathfrak g$-valued connection form. On the other hand, if we consider the vector bundle $\mathcal E$ only, if $\psi$ is a section, we can describe its covariant derivative locally as $$ d_\omega\psi=d\psi+\omega\psi. $$ Here $\omega$ is a local Lie-algebra valued 1-form. If we ignore its pathological transformation properties under the change of a local trivialization, we may see $\omega$ as either a local section of the adjoint bundle (adjoint bundle as in $P\times_{Ad}\mathfrak g$ where $P$ is the associated principal bundle), or as a local section of $\mathcal E \otimes\mathcal E^\ast$. The action $\omega\psi$ is understood naturally if we go with the $\mathcal E \otimes\mathcal E^*$ view, otherwise if $G$ acts on the model fibre $E$ via a representation $\rho$, we may understand the action $\omega\psi$ to be happening through the corresponding Lie algebra representation $d\rho_e$. We may extend the covariant exterior derivative to an $\mathcal E$ valued $k$-form as follows: If locally $$ \psi=\sum_{\mu_1<...<\mu_k}\psi_{\mu_1...\mu_k}dx^{\mu_1}\wedge...\wedge dx^{\mu_k}, $$ then $$ d_\omega\psi=\sum_{\mu_1<...<\mu_k}d_\omega\psi_{\mu_1...\mu_k}\wedge dx^{\mu_1}\wedge...\wedge dx^{\mu_k}. $$ We may also extend $d_\omega$ to $k$-forms which take their values in the tensor product bundle constructed out of $\mathcal E$ and $\mathcal E^*$. Particularily, for a $\mathcal E \otimes \mathcal E^*$-valued $1$-form $\lambda$ we have $$ d_\omega \lambda=d_\omega\lambda_{\mu}\wedge dx^\mu=(d\lambda_\mu+\omega\lambda_\mu-\lambda_\mu\omega)\wedge dx^\mu=d\lambda+(\omega_\nu\lambda_\mu-\lambda_\mu\omega_\nu)dx^\nu\wedge dx^\mu=d\lambda+\omega\wedge\lambda+\lambda\wedge\omega.$$ If we apply this to $\omega$ itself, we get $$ d_\omega\omega=d\omega+2\omega\wedge\omega, $$ on the other hand, the curvature form is $$ \Omega=d\omega+\omega\wedge\omega. $$ So questions: Is the curvature actually the covariant exterior derivative of the connection? Doing this on the principal bundle says yes, the derivation here says no. If so, how come I get that factor of 2 here? Did I make a mistake or what? Is the covariant exterior derivative of an adjoint-bundle valued form not the same as the covariant exterior derivative of an $\mathcal E \otimes \mathcal E^*$-valued form?","['connections', 'vector-bundles', 'differential-geometry', 'curvature']"
2553751,Total number of roots of $f(x)=g(x)$,"Let $f(x)$ be non positive continuous function and $F(x)=\int_0^x f(t) dt,\forall x\geq 0$ and $f(x)\geq cF(x)$ where $c \gt 0$ and let $g:[0,\infty]\to R$ be a function such that $\frac{d}{dx} g(x)< g(x),\forall x>0$ and $ g(0)=0$ The question is to find the total number of roots of $f(x)=g(x)$ Since $f(x)$ is a non positive function it implies that $F(x)$ is a decreasing function also F(0)=0 implies $F(x)\leq 0$.So $f(0)=0$ from $f(0)\geq cF(0)$ and the condition that $f$ is non positive. I couldn't proceed after this.Any ideas?","['ordinary-differential-equations', 'calculus']"
2553776,Higher-order Lipschitz conditions?,"There is a sequence of conditions on functions generalizing Lipschitz continuity; these conditions bear the same relationship to higher-order derivatives that Lipschitz continuity bears to first-order derivatives.  Are these known and under what name? To be specific, let $I$ be an interval in the real line, $f$ a real-valued function on $I$ , and $C$ a positive real number. $f$ is $0$ -Lipschitz (aka bounded ) on $I$ with constant $C$ if, for all $a \in I$ , $\lvert{f(a)}\rvert \leq C$ ; $f$ is $1$ -Lipschitz (aka Lipschitz ) on $I$ with constant $C$ if, for all $a < b \in I$ , $\left| \frac {f(b) - f(a)} {b - a} \right| \leq C$ ; $f$ is $2$ -Lipschitz on $I$ with constant $C$ if, for all $a < b < c \in I$ , $\left| \frac {\frac {f(c) - f(b)} {c - b} - \frac {f(b) - f(a)} {b - a}} {c - a} \right| \leq \frac 1 2 C$ ; $f$ is $3$ -Lipschitz on $I$ with constant $C$ if, for all $a < b < c < d \in I$ , $\left| \frac {\frac {\frac {f(d) - f(c)} {d - c} - \frac {f(c) - f(b)} {c - b}} {d - b} - \frac {\frac {f(c) - f(b)} {c - b} - \frac {f(b) - f(a)} {b - a}} {c - a}} {d - a} \right| \leq \frac 1 6 C$ ; etc. In general, $f$ is $n$ -Lipschitz on $I$ with constant $C$ if, for all $a_0 < \cdots < a_n \in I$ , $$ \left| \frac {\det \begin{bmatrix} 1 & 1 & \cdots & 1 & 1 \\ a_0 & a_1 & \cdots & a_{n-1} & a_n \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ a_0^{n-1} & a_1^{n-1} & \cdots & a_{n-1}^{n-1} & a_n^{n-1} \\ f(a_0) & f(a_1) & \cdots & f(a_{n-1}) & f(a_n) \end{bmatrix}} {\det \begin{bmatrix} 1 & 1 & \cdots & 1 & 1 \\ a_0 & a_1 & \cdots & a_{n-1} & a_n \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ a_0^{n-1} & a_1^{n-1} & \cdots & a_{n-1}^{n-1} & a_n^{n-1} \\ a_0^n & a_1^n & \cdots & a_{n-1}^n & a_n^n \end{bmatrix}} \right| \leq \frac 1 {n!} C .$$ (The denominator is a Vandermonde determinant, and the numerator is the same with the highest powers replaced by the values of the function.) Of course, in this case, then the same inequality holds if $a_0, \ldots, a_n$ are out of order (since this amounts to swapping columns in the determinants), as long as they are distinct, and they don't even have to be distinct if you clear fractions: $$ n! \left| \det \begin{bmatrix} 1 & 1 & \cdots & 1 & 1 \\ a_0 & a_1 & \cdots & a_{n-1} & a_n \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ a_0^{n-1} & a_1^{n-1} & \cdots & a_{n-1}^{n-1} & a_n^{n-1} \\ f(a_0) & f(a_1) & \cdots & f(a_{n-1}) & f(a_n) \end{bmatrix} \right| \leq C \left| \det \begin{bmatrix} 1 & 1 & \cdots & 1 & 1 \\ a_0 & a_1 & \cdots & a_{n-1} & a_n \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ a_0^{n-1} & a_1^{n-1} & \cdots & a_{n-1}^{n-1} & a_n^{n-1} \\ a_0^n & a_1^n & \cdots & a_{n-1}^n & a_n^n \end{bmatrix} \right| ;$$ if the list $(a_0, \ldots, a_n)$ has any repetition, then this just says that $0 = 0$ .  But I like to think of using an increasing list, since that shows where the formulas come from.  For example, the expression inside the absolute value in the $2$ -Lipschitz condition is a sort of second-order difference quotient, saying how much the difference quotient (which appears in the ordinary $1$ -Lipschitz condition) changes as we move from $(a,b)$ to $(b,c)$ , relative to the overall range.  (I don't have any slick reason for why the result can be neatly packed up as a ratio of determinants, but it's easy enough to prove this using induction and basic facts about Vandermonde determinants.) Some basic results: Assuming that $f$ is differentiable $n$ times on $I$ , then $f$ is $n$ -Lipschitz on $I$ with constant $C$ if and only if the $n$ th derivative $f^{(n)}$ is bounded (on $I$ with constant $C$ ). More generally, assuming that $f$ is differentiable $k$ times on $I$ , then $f$ is $n$ -Lipschitz if and only if $f^{(k)}$ is $(n - k)$ -Lipschitz.  (The factorials guarantee the same constant.) I'd like to say that, if $f$ is $n$ -Lipschitz, then $f^{(n)}$ exists almost everywhere, still bounded by the same constant, but I haven't proved this. I don't know how to make sense of this in an arbitrary metric space, or even in $\mathbb{R}^2$ .  Neither the form with the higher-order difference quotient nor the form with the determinants makes sense a priori for even a $2$ -Lipschitz function.  The metric-space derivative is defined by essentially putting absolute values around every subtraction in a difference quotient, changing $b - a$ into $\lvert{b - a}\rvert$ , which is reinterpreted as $d(a,b)$ .  But for the $2$ -Lipschitz condition, this applies the absolute value too soon, before a necessary additional subtraction, so it's not the same. Anyway, if anybody has seen anything like this or has any thoughts on it, then I'm interested.","['real-analysis', 'lipschitz-functions']"
2553798,Probability of Occurence of HEART or EARTH,"This is one of the questions I came across and I could only solve it partially. The question went A man is randomly typing on a keyboard. Then, what is the probability that the word HEART comes before EARTH? My attempts The first $4$ letters of EARTH are the same as last 4 of HEART. For EARTH to appear before HEART, any letter other than H must've appeared first and then should be followed by EART and then a H later on. For HEART to appear first before EARTH, only the letter H must've appeared first and then may be followed by EART. Since, the number of letters to appear in the case of HEART is less than EARTH, the probability of occurrence of HEART is more than that of EARTH. To calculate how much, I'm just considering in case of EARTH first: $$P(E)=\frac{25}{26}.\frac{1}{26}.\frac{1}{26}.\frac{1}{26}$$ HEART first: $$P(E)=\frac{1}{26}.\frac{25}{26}.\frac{25}{26}.\frac{25}{26}$$ This obviously isn't correct, since it doesn't give any individual probability for the occurrence of each letter. So, can anyone calculate the probability for each of these two?",['probability']
2553817,Inequalities on matrix norm,Let $K=(A+D)^{-1}A$ where $A$ is symmetric positive definite and $D$ is a diagonal matrix with positive elements. Is it true that $\|K\|\leq 1$ where $\|\cdot\|$ is the induced $2$-norm? Thank you.,"['matrices', 'normed-spaces', 'linear-algebra']"
2553845,Finding the range of $\frac{x^2}{x^2-9}$,"I am a student who is studying about functions (only basic ones) and was practicing till I found this - Finding the range of $$ \frac{x^2}{x^2-9} $$ Since I have only learnt the basics , I can only play around with the numbers and not use limits (which was what I found online). I was Told to try this method -  to try to assign $y=\frac{x^2}{x^2-9}$ This means expressing $x$ in terms of $y$ $x = \sqrt { \frac{9y}{y-1} } $ Now I then go on to find the range of this function - range =$ y \leq 0  $ or $ y>1$ This is simple to do. But what I'm confused with is this - Since Range is all the possible 'y' values obtainable from the domain, then this confuses me because I express x in terms of y. Finding the x value feels like finding the 'domain' for me . I believe I'm having a conceptual problem and I don't understand what does expressing x in terms of y do to help me find the range. does this mean that I can express all other simple functions into x in terms of y to find the range too ? Thanks !! Note : I'm being taught on How to read the domain And range off a function. So I can't use the graphical method .","['calculus', 'functions']"
2553847,A fast introduction to Psuedo-Riammanian Manifolds and Riemannian Manifolds,"I apologize in advance for the long length of this question Okay so let me explain my background. I know quite a bit of General Topology, including Topological Manifolds. I know some basic stuff about Algebraic Topology, and Differential Topology (about half of Milnor's Topology from the Differentiable Viewpoint and the half of the first chapter of Guillemin and Pollack) My strength is Topology, but I'm currently trying to to read up on a paper that deals with a topological construction on smooth manifolds. I can understand the topological aspects just fine, however there are a number of examples given of this construction on Pseudo-Riemannian Manifolds, of which I've never dealt with and I need to understand these examples of Pseudo-Riemannian examples to be able to fully understand the paper (which is geared towards the application of this topological construction to Pseudo-Riemannian Manifolds). Now I need to learn this material fast, as the research group I'm working with hopes to publish a paper sometime in June next year. I'm giving myself around 1 month to learn the pre-requisite Riemannian and Pseudo-Riemannian Geometry I'm currently reading through Lee's Introduction to Smooth Manifolds, and I'll soon be fairly comfortable with the first 3 chapters. What's the fastest way to learn enough Riemannian and Pseudo-Riemannian Geometry to understand the examples given below provided that I have no knowledge of tensors / tensor fields differential forms vector bundles and tensor bundles But I do have a solid knowledge of metric spaces, metrics (not riemannian metrics, just metrics on metric spaces), and linear algebra and basic group, ring and module theory. For example I find Keith Conrad's notes on tensor products of modules quite readable ( http://www.math.uconn.edu/~kconrad/blurbs/linmultialg/tensorprod.pdf ) What chapters (and in what order) should I look at in Lee's Introduction to Smooth Manifolds to gain a solid grasp of Pseudo-Riemannian Geometry and Riemannian Geometry? If there is another book which is more streamlined to Riemannian Geometry and Pseudo-Riemannian Geometry, and which would allow me to learn the material faster, please let me know. The two disadvantages to this is that I'd have to get used to another authors notation (which is really not an easy process especially in Differential Geometry), and I wouldn't be using Lee's book which I plan to use for DIfferential Geometry. Below is the level of Riemannian Geometry that I need to learn, it's an example taken from the paper.","['reference-request', 'riemannian-geometry', 'differential-geometry', 'soft-question']"
2553900,"Proof verification, limit of cumulative distribution function","Let $X$ be a random variable and let $F_X:\mathbf{R}\to\mathbf{R}$ be the cumulative distribution function of $X$.
Let $x\in\mathbf{R}$ such that $\mathbf{P}(X=x)=0$. Prove that $\lim_{y\to x^-} F_X(y)=F_X(x)$. My try: $F_X$ is monotone and bounded, so $\sup_{y<x} F_X(y)=\lim_{y\to x^-} F_X(y)$ exists (completeness of $\mathbf{R}$). We will show that $\lim_{y\to x^-} F_X(y)=F_X(x)$:
\begin{align*}
\lim_{y\to x^-} F_X(y) &\stackrel{1}{=}\lim_{n\to\infty} F_X(x-\tfrac{1}{n}) \\
&\stackrel{2}{=}\lim_{n\to\infty }\mathbf{P}(X\leqslant x-\tfrac{1}{n}) \\ 
&\stackrel{3}{=}\mathbf{P}\left[\bigcup_{n=1}^\infty \{X\leqslant x-\tfrac{1}{n}\}\right]\\
&\stackrel{}{=}\mathbf{P}(X<x)\\
&\stackrel{4}{=}\mathbf{P}(X\leqslant x) \\
&\stackrel{2}{=}F_X(x)
\end{align*} (1): Take a sequence $(x_n)$ for which $x_n<x$ for all $n\in\mathbf{N}$ and $\lim_{n\to\infty} x_n=x$, for example $x_n=x-\frac{1}{n}$. (2): Definition of the cumulative distribution function. (3): Continuity of the probability measure. (5): $\mathbf{P}(X\leqslant x)=\mathbf{P}(X<x)+\mathbf{P}(X=x)$ and $\mathbf{P}(X=x)=0$. Is this correct? Can I indeed take one sequence if I show first that the limit exists or do I need to show it for all sequences converging to $x$ but strictly less than $x$?",['probability-theory']
2553927,Are the components of the curvature tensor w.r.t *changing* normal coordinates smooth?,"Let $M$ be a smooth Riemannian manifold, and let $p \in M$. Let $U$ be a sufficiently small neighbourhood of $p$, such that $U$ is a normal neighbourhood of each of its points. We can choose $U$ in such a way that for every $q\in U$, $\exp_q: B_{h_0}^q(0) \to B_{h_0}(q)$ is a diffeomorphism. Now, we fix a smooth orthonormal frame $F$ of $TM|_U$. For every $q\in U$, we identify $T_qM \sim \mathbb{R}^d$ using $F_q$, so that $\exp_q$ defines normal coordinates on $B_{h_0}(q)$. Finally, let $\mathcal{R}_{ijkl}(q)$ be the components of the curvature tensor of $M$ at the point $q$, calculated w.r.t the normal coordinates centered around $q$ (using $\exp_q$ and $F_q$ as described above). I am trying to show the map $q\mapsto \mathcal{R}_{ijkl}(q)$ is smooth, or at least continuous. I know that the exponential map is smooth when regarded as $\exp:TM|_U \to M$, but I am not sure how to use this here. Any ideas?","['multivariable-calculus', 'riemannian-geometry', 'coordinate-systems', 'smooth-manifolds']"
2553965,laurent series of $\frac{z^2-2z+2}{(z-1)(z^2-2z-3)}$ around $z-1$ for $0<|z-1|<2$,"I want to find the Laurent series of $L=\frac{z^2-2z+2}{(z-1)(z^2-2z+3}$ around $(z-1)$ Here, I used the fact that 
$L=\frac{5}{8(z-3)}+\frac{5}{8(z+1)}-\frac{1}{4(z-1)}$ When $|z-1|<2$, we have $L=\frac{-1}{4(z-1)}+\frac{5}{8} \frac{1}{(z-1)-2} +\frac{5}{8( (z-1)+2)}$ $=\frac{-1}{4(z-1)} +\frac{5}{-16}\frac{1}{1- \frac{(z-1)}{2}} + \frac{5}{16} \frac{1}{1+ \frac{(z-1)}{2}} =-\frac{1}{4(z-1)}+ \frac{5}{16} \sum_{k=0}^\infty \frac{(z-1)^k}{2^k}(-1+(-1)^k)=-\frac{1}{4(z-1)}+\frac{5}{16} \sum_{n=0}^\infty \frac{(z-1)^{2n+1}}{2^{2n+1}} (-2)$ However,in my book, Elements d'analyse complexe by Real Gelinas,
the answer for 0<|z-1|<2 is $\frac{-1}{4} (z-1 + \frac{1}{z-1} )\sum_{n=0}^\infty (\frac{z-1}{2n})^{2n}.$ Hence, I am missing a term.
Where is my mistake?",['complex-analysis']
2554011,Product of the entries in a row of Pascal's triangle,"The sum of the $n$-th row in Pascal's triangle
\begin{equation}
\sum_{k=0}^{n}\binom{n}{k}
\end{equation}
has the well-known value of $2^n$. Now, I'm looking for the value of the product of the $n$-th row in Pascal's triangle, given through
\begin{equation}
s_n=\prod_{k=0}^{n}\binom{n}{k}.
\end{equation}
Any ideas how to calculate this value? Is it even possible? I found some papers (e.g. Finding e in Pascals Triangle ) dealing with the growth of this sequence, and it seems to be that the ratio of the ratios $\frac{s_{n+1}/s_n}{s_n/s_{n-1}}$ has the limiting value of 
\begin{equation}
\lim_{n\rightarrow\infty}\frac{s_{n+1}s_{n-1}}{(s_n)^2}=e.
\end{equation}
Is this helpful for calculating the value of $s_n$? So far, it is not clear to me how the growth rate of a sequence relate to its value.","['products', 'binomial-coefficients', 'sequences-and-series']"
2554024,A convex closed plane curve never intersects itself?,"Intuitively, I think that a convex closed curve has to be simple (i.e. cannot intersect itself except at the starting and the ending points). How one can prove it rigorously? My attempt: Suppose it is a convex closed curve and it intersects itself. There exists(?) a neighborhood that the curve is not convex anymore, leading to contradiction. Also, do we need any smoothness condition?","['curves', 'differential-geometry']"
2554046,Extending isomorphism of punctured Riemann surfaces,"In Schlag's book on Riemann surfaces, we have Problem $4.15$, which is: Let $M, N$ be compact Riemann surfaces and suppose $f: M\setminus\mathcal{S} \to N\setminus\mathcal{S}'$ is an isomorphism, where $\mathcal{S}$ and $\mathcal{S}'$ are finite sets. Show that $f$ extends to an isomorphism from $M\to N$. This is also Exercise 8.2 in Forster's text. I think we can prove this as follows (but I am not totally sure about this either). Let $a\in \mathcal{S}$ and pick a sequence $a_n \subset M \setminus
> \mathcal{S}$ such that $a_n \to a$. Then, by compactness of $N$, there
  is a subsequence $f(a_{n_k})$ converging to some $p \in N$. Suppose $p \in f(M \setminus \mathcal{S})$, and let $K:= \{f(a_{n_k}),
> p\}$. Since $f$ is continuous, we have $f^{-1} (K)$ is closed, hence
  $f^{-1} (K)$ is compact (by compactness of $M$). And, since $f$ is
  injective, we have $f^{-1} (K) = \{a_{n_k}, f^{-1} (p)\}$. Let $U_k$ be a neighborhood of $a_{n_k}$ containing none of the other
  elements of sequence $a_n$. Then for any neighborhood $U$ of $f^{-1}(p)$
  , the cover $\{U_k, U\}$ has a finite subcover, so all but
  finitely many elements of $a_{n_k}$ are in $U$. Thus, $a_{n_k} \to f^{-1} (p)$
  , which implies $f^{-1} (p) = a$, contradiction. So, $p \in \mathcal{S}'$. Now, by the lemma in this answer and
  discreteness of $\mathcal{S}'$, it follows that $f(a_n) \to p$.
  Further, if $b_n \to a$ is a different sequence, then discreteness
  again implies $f(b_n) \to p$. Thus, we can continuously extend $f$ to
  $M$, hence we can holomorphically extend. Now, we have an injective holomorphic map $M \to N$ of compact Riemann
  surfaces. By the open mapping theorem, it has to be an isomorphism. However : in an old problem set of Curt McMullen, a similar problem is given: Let $X$ be a compact Riemann surface and $A \subset X$ a finite set. Show that any injective holomorphic map $f: X\setminus A \to Y$, where $Y$ is another compact Riemann surface, may be extended to an isomorphism $X\to Y$. The difference here is that we have to show ourself that $Y \setminus f(X\setminus A)$ must be discrete. How can we do this?","['riemann-surfaces', 'complex-analysis']"
2554078,Can only the existence of the right and left derivatives imply continuity?,"If $f:X\rightarrow \mathbb{R} \,$ is a function with $x_0 \in \overline{X}   \,\setminus \partial(\overline{X}) $ such that : $$\exists \,\,\,\,f'_-(x_0)=\lim_{x\rightarrow x_0^-}\dfrac{f(x)-f(x_0)}{x-x_0},$$ $$\exists \,\,\,\,f'_+(x_0)=\lim_{x\rightarrow x_0^+}\dfrac{f(x)-f(x_0)}{x-x_0}$$
 but with possibly $f'_-(x_0) \not= f'_+(x_0)$,  does this still imply continuity of $f$ ?","['derivatives', 'real-analysis', 'limits', 'calculus', 'continuity']"
2554079,Proof of a sequence $\{S_n\}$ converging to $0$,"First, the question asks Prove that $1+\frac12+\frac13+\cdots+\frac1n<2\sqrt n$ At first glance, I see that this is a proof involving induction, and I arrived at an inequality as shown below where I complete my proof: $$\frac1{\sqrt{k+1}-\sqrt k}<2k+2$$ Then, the question asks further Let $S_n=\frac{1}{n}+\frac{1}{2n}+\frac1{3n}+\cdots+\frac1{n^2}$ for each $n\in\Bbb N$. Prove that $\{S_n\}$ converges to $0.$ The second part of the question is where I am stuck. I don't know how I can make use of the first part of the question to answer the latter part.","['induction', 'sequences-and-series', 'proof-verification', 'limits']"
2554082,Solve the differential equation $\frac{\mathrm{d}y}{\mathrm{d}x} = \cos(x+y) + \sin(x+y)$,"Problem: Solve the differential equation,$$\frac{\mathrm{d}y}{\mathrm{d}x} 
 =\cos(x+y) + \sin(x+y)$$ My attempt at the problem: $$\frac{\mathrm{d}y}{\mathrm{d}x} 
 =\cos(x+y) + \sin(x+y)=\cos(x+y)\biggr(1+\tan(x+y)\biggr)$$ Now let, $$\cos(x+y)=u$$ So that, $$\frac{\mathrm{d}y}{\mathrm{d}x} 
 = u(1+\sqrt{\frac{1}{u^2}-1})$$
using    $\tan^2A = \sec^2A - 1$ Also, $$\frac{\mathrm{d}(\cos(x+y))}{\mathrm{d}x} 
 = -\sin(x+y)\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr) $$ and
$$\frac{\mathrm{d}u}{\mathrm{d}x} 
 = -\sqrt{1-u^2}\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr)$$ Solving for $\frac{\mathrm{d}y}{\mathrm{d}x}$ and plugging it in the problem gives a very ugly integral upon separating variables $$\int{\mathrm{d}x} = - \int \frac{\mathrm{d}u}{\biggr((u+1)+\sqrt{1-u^2}\biggr)\sqrt{1-u^2}}$$ I just can't solve it any further. Please correct me if I'm wrong or please direct me towards an alternate solution. All help appreciated!","['integration', 'ordinary-differential-equations', 'calculus']"
2554085,How to expalin the pathologie of this zero distribution(or measure).,"Assume $\delta$ is the zero Dirac distribution (measure) on $\Bbb R$. namely, $$(\delta,f)= \int_\Bbb R f\delta(dx) =f(0)$$ We know if $T\in \mathcal {D'}(\Bbb R)$ is a distribution then for every $ \phi \in C^\infty(\Bbb R)$ we have that  $\phi T$ is also a distribution defines by $$(\phi T, f) = ( T, \phi f)$$ 
Moreover, $$(\phi T)'= \phi'T+\phi T' $$ My problem . If we consiser the particular case $\phi= x$ or $\phi=x^2$ and $T= \delta$ we have, $$(x\delta, f)= (xf)(0)=0~~~\forall ~~f$$ Question : does this means that $\color{red}{x\delta \equiv 0}$ in $ \mathcal {D'}(\Bbb R)$? If yes how to explain the fact that $$\color{blue}{0 =(x\delta)' = \delta +x\delta'}$$ If no what is $\color{red}{x\delta }$ as a distribution? Patently if one consider the measure $$\mu(dx) = x^2 \delta(dx)$$
then it happens that $$\int f\mu(dx) = 0~~~\forall ~~f$$ Why is $\mu$ a trivial measure.?","['dirac-delta', 'distribution-theory', 'measure-theory', 'analysis']"
2554102,"$e-2\approx0.71828$, but I got $1$","We know that: $$\frac 1{2!}+\frac 1{3!}+\frac 1{4!}+\frac 1{5!}+\frac 1{6!}+\cdots =e-2\approx0.71828$$ But I am getting the above sum as $1,$ as shown below: \begin{align}
S & = \frac 1{2!}+\frac 1{3!}+\frac 1{4!}+\frac 1{5!}+\frac 1{6!}+\cdots \\[10pt]
& = \frac 1{2!} + \frac {3-2}{3!} +\frac {4\times2-7}{4!}+\frac {5\times7-34}{5!}+\frac {6\times34-203}{6!}+\cdots \\[10pt]
& = \frac 1{2!}+\frac 1{2!}-\frac 2{3!}+\frac 2{3!}-\frac 7{4!}+\frac 7{4!}-\frac {34}{5!}+\frac {34}{5!}-\frac {203}{6!}+\cdots \\[10pt]
& = 1
\end{align} Please indicate my mistake","['fake-proofs', 'exponential-function', 'calculus', 'proof-verification', 'sequences-and-series']"
2554107,Is there a function satisfying the following equation: $f(\sin x)+f(\cos x) = \frac{\tan x}{2}$?,Define a function $f(x)$ such that: $$f(\sin x)+f(\cos x)=\frac{\tan x}2$$ What is $f(x)?$ My attempt: I hypothesized the denominator of the function to be like of the form $x+(1-x^2)^{1/2}$,"['algebra-precalculus', 'trigonometry', 'functions']"
2554111,Prove that $\lim\limits_{n\rightarrow\infty} \left(1+\frac{1}{a_{n}} \right)^{a_{n}}=e$ if $\lim\limits_{n\rightarrow\infty} a_{n}=\infty$,"What would be the nicest proof of the following theorem: If $\lim\limits_{n \rightarrow \infty} a_{n} = \infty$ , then $\lim\limits_{n \rightarrow \infty} \left(1 + \frac{1}{a_{n}} \right) ^ {a_{n} } = e$ . If $\lim\limits_{n \rightarrow \infty}b_{n} = 0$ , then $\lim\limits_{n \rightarrow \infty} \left(1 + b_{n} \right) ^ {\frac {1} {b_{n}} } = e$ . I somehow failed to find a proof here on the website and in the literature.","['sequences-and-series', 'calculus', 'limits']"
2554143,Probability at least one spade and card higher than a 7,There is a 52 card deck and you are dealt 13 cards. Question: What is the probability neither of the following cases happen: no spades and no card higher than 7 Thus that means you get at least one spade and the card is higher than 7. I'm not sure if it's and or or with that wording though. I understand that the $P(\text{at least one spade}) = 1 - P(\text{no spades})$. $$P(\text{no spades}) = \frac{\binom{39}{13}}{\binom{52}{13}}$$ But how do I factor in the second requirement of the card being higher than a 7?,"['combinations', 'combinatorics', 'probability', 'discrete-mathematics']"
2554162,Is every commutative ring contained in a field?,"I imagine the answer to this question is very simple, but I haven't been able to locate it. Can every commutative ring be imbedded in a field? This seems very plausible to me, for it seems we could just take the ""closure"" under inverses. Thanks!","['abstract-algebra', 'ring-theory']"
2554165,largest geometric progression that can be obtained from a set,"The question is to find out the longest geometric progression (the common ratio $r \neq 1$) that can be obtained from the set $(100,101,102,...,1000)$ The common ratio must be greater than $1$ and for the common ratio $2$ the number of terms is $4$ which starts from $100$ I have no idea on how to proceed with this.Any thoughts?Thanks.",['sequences-and-series']
2554179,Have I found a counterexample in this question?,"If $f:X\rightarrow \mathbb{R} \,$ is a function with $x_0 \in \overline{X}   \,\setminus \partial(\overline{X}) $ such that : $$\exists \,\,\,\,f'_-(x_0)=\lim_{x\rightarrow x_0^-}\dfrac{f(x)-f(x_0)}{x-x_0},$$ $$\exists \,\,\,\,f'_+(x_0)=\lim_{x\rightarrow x_0^+}\dfrac{f(x)-f(x_0)}{x-x_0}$$
 but with possibly $f'_-(x_0) \not= f'_+(x_0)$,  does this still imply continuity of $f$ ? if so then why can I have a function such as $$f(x) =       \begin{cases}       3x \, , \text{  if}  \,\,\, x<x_0 \\       10x+1 \, ,\text{  if}  \,\,\, x=x_0 \\       -2x \, , \text{  if}  \,\,\, x>x_0       \end{cases} $$
that does have $f'_-(x_0)=3$ and $f'_+(x_0)=-2$ but is not continuous, does that mean that only the existence of the left and right side derivatives on a point do not guarantee that $f $ is continuous at $x_0$ ?","['derivatives', 'real-analysis', 'examples-counterexamples', 'limits', 'calculus']"
2554223,"Does a continuous function $f: [0,1] \cup [2,3] \to [5,6]$ exist?","Does a continuous function $f: [0,1] \cup [2,3] \to [5,6]$ exist? I have been trying to solve this problem and I could think of such function. I am still new to the concept of the continuity of a function and I am simply too puzzled to answer whether this function is continuous or not. On the one hand, intuitively, it is hard for a function to be more discontinuous than this, but as I try to work with the $\epsilon, \delta$ definition of continuity, it makes intuitive sense. Could you help me decide whether or not this function is continuous? Some simple clarification would be most appreciated. EDIT: My original question was not precise. $[5,6]$ is supposed to be the range of this function.","['continuity', 'general-topology', 'calculus']"
2554270,Differentiable functions $f'(x)=f(-x)^4f(x)$,"Find all differentiable functions $f\colon \mathbb{R}\to\mathbb{R}$ with $f(0)=1$ such that $f'(x)=f(-x)^4f(x)$, for all $x \in \mathbb{R}$.","['derivatives', 'real-analysis', 'ordinary-differential-equations', 'functional-equations']"
2554403,Calculate unique combinations for unique guests per table contraint,"I'm working on this application that generates a table layout based on some criteria. The criteria consists of these things A list of guests The amount of tables The amount of dinner courses The type of algorithm Place guests at table at random Place guests at a unqiue table each course Place guests at a table with other unmet/unique guests each course Right now I'm looking for the formula to calculate the constraint for the last algorithm (nr 3).
After spending some time googling I found a formula for combinations/permutations, though it only works when the maximum amount of guest per table is less then three. $$
\frac{n!}{r!(n − r)!}
$$ In my cause I use r as the amount of guests and n as the amount of guest per table ( e.g. ceil( guest count / table count ) ) For example,
With 4 guests and 3 tables, n=4 and r=2, the formula returns 6. Which matches my calculations 12 23 34
13 24
14 Same for 6 guests and 3 tables, n=6 and r=2, the formula returns 15. This also matches the calculations 12 23 34 45 56
13 24 35 46
14 25 36
15 26
16 But when the guests per table increases, the formula returns unwanted results. For example, n=7 and r=3, returns 35. But my calculation comes down to 7 combinations 123 246 356
145 257 347
167 I was hoping if someone could help me find or alter this formula so it matches these three calculations. Thus honoring the constraint: maximum amount of combinations where each number can only be returned once in combination with the other numbers. Thank you for your time","['combinations', 'combinatorics', 'combinatorial-designs', 'extremal-combinatorics']"
2554448,Calculate $\lim_{x\to 0} \frac{x(\cosh x - \cos x)}{\sinh x - \sin x}$,"Beside using l'Hospital 10 times to get 
$$\lim_{x\to 0} \frac{x(\cosh x - \cos x)}{\sinh x - \sin x} = 3$$ and lots of headaches, what are some elegant ways to calculate the limit? I've tried to write the functions as powers of $e$ or as power series, but I don't see anything which could lead me to the right result.","['limits-without-lhopital', 'limits']"
2554480,Proving inequation with maximum and 2nd derivative,Let $f(x)$ be twice-differentiable and $f(a)=f(b)=0$ with $a<b$ How to prove that $$\max|f(x)| \le \frac 18(b-a)^2 \max|f''(x)|$$ (With $\max|f(x)|$ beeing maximum (or minimum) between a and b.) How would I use Taylor-Expansion and Mean Value Theorem here?,"['derivatives', 'real-analysis', 'inequality', 'calculus']"
2554526,Introduction of $ln$ in defining derivative of $a^x$,"I am reading R. Shankar's Basic Training in Mathematics . In the first chapter, the author is attempting to give meaning to what $a^x$ means for any (potentially irrational) x. As the very first step, he presents the following method of determining the derivative of $a^x$ (before either $a^x$ or $ln$ have been defined): [1] $\Delta a^x$ = $a^{(x + \Delta x)} - a^x$ [2] = $a^x(a^{\Delta x} - 1)$ [3] = $a^x(1 + \ln(a)\Delta x + ... - 1)$ [4] $\frac{da^x}{dx}$ = $a^x\ln(a)$ He justifies step [3] by saying that it is obvious that $a^{\Delta x}$ is very close to 1, and that: The deviation from 1 has a term linear in $\Delta x$, with a coefficient that depends on $a$, and we call it the function $\ln(a)$... How is he justified in asserting that, for any choice of $a$, the deviation from $1$ must be represented by a term linear in $\Delta x$? I can see that, if there were any higher-order terms $a_2(\Delta x)^2$, $a_3(\Delta x)^3$, ..., they would all disappear as $\Delta x \rightarrow 0$ in the derivative, but how do we know that a suitable linear function even exists?","['algebra-precalculus', 'exponentiation', 'calculus', 'derivatives']"
