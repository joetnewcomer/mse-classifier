question_id,title,body,tags
2203534,The $n$-th derivative of the reciprocal of a function and a binomial identity,"While I was looking for an answer to this MSE post in order to prove
\begin{align*}
\frac{d^n}{dx^n}\left(\frac{1}{1-e^{-x}}\right)=(-1)^n\sum_{j=1}^n{n\brace j}j!\frac{e^{-jx}}{\left(1-e^{-jx}\right)^{j+1}}\tag{1}
\end{align*}
with the  numbers ${n\brace j}$ denoting the Stirling numbers of the second kind I considered the following formula of the reciprocal of the $n$-th derivative of a function which might be interesting by itself. With $D_x:=\frac{d}{dx}$ the following relationship is valid according to (3.63) in H.W. Goulds Binomial Identities, vol. I \begin{align*}
D_x^n\left(\frac{1}{f(x)}\right)=\sum_{j=0}^n(-1)^j\binom{n+1}{j+1}\frac{1}{\left(f(x)\right)^{j+1}}D_x^n\left(\left(f(x)\right)^j\right)
\end{align*} $$ $$ Applying this formula to the function $f(x)=\frac{1}{1-e^{-x}}$ we obtain
  \begin{align*}
D_x^n&\left(\frac{1}{1-e^{-x}}\right)\\
&=\sum_{j=0}^n(-1)^j\binom{n+1}{j+1}\frac{1}{\left(1-e^{-x}\right)^{j+1}}D_x^n\left(\left(1-e^{-x}\right)^j\right)\\
&=\sum_{j=0}^n\frac{(-1)^j}{\left(1-e^{-x}\right)^{j+1}}\binom{n+1}{j+1}D_x^n\left(\sum_{k=0}^j\binom{j}{k}(-1)^ke^{-kx}\right)\\
&=(-1)^n\sum_{j=0}^n\frac{(-1)^j}{\left(1-e^{-x}\right)^{j+1}}\binom{n+1}{j+1}\sum_{k=0}^j\binom{j}{k}(-1)^kk^ne^{-kx}\\
&=\frac{(-1)^n}{(1-e^{-x})^{n+1}}\sum_{j=1}^n(-1)^j\left(1-e^{-x}\right)^{n-j}\binom{n+1}{j+1}\sum_{k=1}^j\binom{j}{k}(-1)^kk^ne^{-kx}\tag{2}
\end{align*} On the other hand with the identity ${n\brace j}=\frac{1}{j!}\sum_{k=0}^j(-1)^{j-k}\binom{j}{k}k^n$ we obtain from (1)
  \begin{align*}
D_x^n&\left(\frac{1}{1-e^{-x}}\right)\\
&=(-1)^n\sum_{j=1}^n{n\brace j}j!\frac{e^{-jx}}{\left(1-e^{-jx}\right)^{j+1}}\\
&=(-1)^n\sum_{j=1}^n\frac{e^{-jx}}{\left(1-e^{-jx}\right)^{j+1}}\sum_{k=0}^j(-1)^{j-k}\binom{j}{k}k^n\\
&=\frac{(-1)^n}{(1-e^{-x})^{n+1}}\sum_{j=1}^n(-1)^je^{-jx}(1-e^{-x})^{n-j}\sum_{k=1}^j\binom{j}{k}(-1)^{k}k^n\tag{3}
\end{align*} I have difficulties to prove the equality of (2) with (3). So putting $y=e^{-x}$ I would like to ask for a prove of the following relationship Claim: The following is valid for $n\geq 1$ and $y\geq 0$.
  \begin{align*}
\sum_{j=1}^n&(-1)^j\left(1-y\right)^{n-j}\binom{n+1}{j+1}\sum_{k=1}^j\binom{j}{k}(-1)^kk^ny^k\\
&=\sum_{j=1}^n(-1)^jy^j(1-y)^{n-j}\sum_{k=1}^j\binom{j}{k}(-1)^{k}k^n
\end{align*} Please note I'm not interested in a proof by induction. I would like to see how to transform one side into the other, maybe with the help of generating functions. Many thanks in advance.","['derivatives', 'binomial-coefficients', 'stirling-numbers', 'generating-functions', 'summation']"
2203591,Lognormal random variable times a constant,"If $X$ is a random variable lognormally distributed, then can we say that $Y=cX$ for $x\in \mathbb{R}^+$ is lognormal too?
I think that if $c$ is large enough the central limit theorem applies and $Y$ will be normal. But I guess for reasonable values of $c$ (for example $c<30$) maybe it is not true. Mostly I'm thinking in the case when we need to change the units of $X$. Does it changing the units of a quantity change also its distribution? Thanks in advance.","['statistics', 'probability']"
2203600,Measurability of the argmin,"Suppose $ \Gamma$ is a compact space and I have a stochastic process $ ( X (
\gamma) , \gamma \in \Gamma ) $ on a probability space $ ( \Omega , \mathscr{A}
, \mathbb{P})$ such that $ \gamma \mapsto X ( \gamma) $ is continuous $
\mathbb{P}$-a.e. Then, $\arg\!\min_{ \gamma \in \Gamma} X ( \gamma) $ exist $
\mathbb{P}$-a.e. My question is, whether there is a measurable function $
\widehat{ \gamma} : ( \Omega , \mathscr{A} , \mathbb{P}) \to ( \Gamma,
\mathscr{B}_{ \Gamma})  $ with $ \widehat{ \gamma} = \arg\!\min_{ \gamma \in \Gamma} X ( \gamma)  $ $ \mathbb{P} $-a.e.,where $ \mathscr{B}_{ \Gamma}$ is the borel $ \sigma$-Algebra on $ \Gamma$. Any help would be appreciated.","['stochastic-processes', 'probability-theory', 'measure-theory']"
2203606,Which one of these options is false?,"Given two independent events $A$ and $B$, with given conditions: $0 \lt P(A) , P(B) <1 $. Which one of the following options is/are false? $A$ and $B’$ are independent. $A’$ and $B’$ are independent. $P(A|B) = P(A|B’)$ For any event c, with $0 \lt P(c) \lt 1$, $P(AB|c)= P(A|c)\cdot P(B|c)$ Here is what I tried: A and B are independent iff:  $P(A \cap B)$ $=$ $P(A)\cdot P(B)$ Now, we have : $P(A) = P(A \cap B) + P(A \cap B')$ So, $ P(A \cap B')$ $=$ $P(A) - P(A \cap B)$ $=$ $P(A) - P(A)\cdot P(B)$ $=$ $[1-P(B)]\cdot P(A)$ $=$ $P(A)\cdot P(B')$ Thus, 1 is true. We know that, $P(A’ \cap B’) =P(A \cup B )’$ $ =1 - P(A \cup B)$ $  =1 - P(A) - P(B) + P( A \cap B)$ $  =1 - P(A) - P(B) + P(A)\cdot P(B)$ $  = [1-P(A)] \cdot [1-P(B)]$ $  =P(A’)P(B’) $ Thus, 2 is also true. By conditional probability,  $P(A | B)$ $=$ $\frac{P(A \cap B)} {P(B)}$ $=$ $\frac{P(A)\cdot P(B)}{P(B)}$ $=$ $P(A) $ And $P(A | B') $ $ =$ $\frac{P(A \cap B')}{P(B')}$ $=$ $\frac{P(A)\cdot P(B')}{P(B')}$ $=$ $P(A) $ The problem is with 4. I tried to disprove it, by finding a counter-example, and I couldn't. What is the correct answer?",['probability']
2203742,Finite union of affine schemes,"Let $X$ be a scheme and suppose that $X$ admits a finite open covering $(U_i)_{i\in I }$ of affine schemes, such that $X_i\cap X_j$ is an affine scheme, for all $i,j\in I$. In this case is it true that $X$ is an affine scheme?","['schemes', 'affine-schemes', 'algebraic-geometry']"
2203755,Proposition $3.20$ of Algebraic Geometry and Aritmetic Curves- Qing Liu,"Can anyone explain me how the author can say that $Z$ is an affine scheme? I thinked in a first moment that this was the key point, but it doesn't work. EDIT:","['schemes', 'algebraic-geometry']"
2203759,Mathematical name for the flipped matrix and the subsequent matrix dot product in a discrete convolution,"In full-disclosure I asked this question on Quora anonymously, because I thought the answer was going to be embarrassingly self-evident, but given the single, tangential answer (albeit very interesting), I want to maximize my chances by posting the question here with a follow-up immediately related secondary question. Before convolving a filter with an image, or a kernel with a layer in convolutional neural networks, the filter (or kernel) is flipped in its rows and columns. I am looking for the name of this flipped matrix. The matrix $\begin{bmatrix}a&b\\c&d\end{bmatrix}=\begin{bmatrix}\color{red}{\blacksquare}&\color{blue}{\blacksquare}\\\color{green}{\blacksquare}&\color{aqua}{\blacksquare}\end{bmatrix}$ with flipped columns and rows would be $\begin{bmatrix}d&c\\b&a\end{bmatrix}=\begin{bmatrix}\color{aqua}{\blacksquare}&\color{green}{\blacksquare}\\\color{blue}{\blacksquare}&\color{red}{\blacksquare}\end{bmatrix}.$ To be clear (given prior experience - I know it is by and large completely unnecessary), I am not asking for the transpose: $\begin{bmatrix}a&b\\c&d\end{bmatrix}^\top=\begin{bmatrix}a&c\\b&d\end{bmatrix}=\begin{bmatrix}\color{red}{\blacksquare}&\color{green}{\blacksquare}\\\color{blue}{\blacksquare}&\color{aqua}{\blacksquare}\end{bmatrix}.$ Immediately after getting this flipped filter or kernel the convolution consists of a sum of all the entries of a Hadamard product , which really is sort of a ""dot product of matrices"". What is the name of this matrix operation in general: $$\text{elementwise}\sum\left(\begin{bmatrix}a&b\\c&d\end{bmatrix}\circ \begin{bmatrix}z&w\\v &y\end{bmatrix}\right)=\text{elementwise}\sum\begin{bmatrix}az&bw\\cv&dy\end{bmatrix}=az+bw+cv+dy$$ ? Thanks to @Omnomnomnom the answer to the second question is the Frobenius inner product : For $A = \begin{bmatrix}a&b\\c&d\end{bmatrix}$ and $\begin{bmatrix}z&w\\v &y\end{bmatrix}$, the Frobenius inner product, $\langle A,B \rangle_\mathbf F$ takes two matrices and returns a number. $$\small\sum_{\text{el.wise}}\left(\begin{bmatrix}a&b\\c&d\end{bmatrix}\circ \begin{bmatrix}z&w\\v &y\end{bmatrix}\right) =  tr\left(\begin{bmatrix}a&b\\c&d\end{bmatrix}^\top\cdot \begin{bmatrix}z&w\\v &y\end{bmatrix}\right)=tr\left(\begin{bmatrix}a&c\\b&d\end{bmatrix}\cdot \begin{bmatrix}z&w\\v &y\end{bmatrix}\right)=\tiny az+cv+bw+dy$$ and thanks to @Hurkyl $$\small\sum_{\text{el.wise}}\left(\begin{bmatrix}a&b\\c&d\end{bmatrix}\circ \begin{bmatrix}z&w\\v &y\end{bmatrix}\right)=\small\sum_{\text{el.wise}}\left(\begin{bmatrix}az&bw\\cv&dy\end{bmatrix}\right)=\begin{bmatrix}1&1\end{bmatrix}\begin{bmatrix}az&bw\\cv&dy\end{bmatrix}\begin{bmatrix}1\\1\end{bmatrix}=\tiny az+cv+bw+dy
$$","['terminology', 'machine-learning', 'convolution', 'linear-algebra']"
2203767,Determine whether the integral $\int_{0}^{\infty}\frac{\cos(x)\sin(1/x)}{x^p}dx$ is convergent or divergent,"Determine whether the improper integral $\int_{0}^{+\infty}\frac{\cos(x)\sin(1/x)}{x^p}dx$ is convergent or divergent for $p\in\mathrm{R}$. According to the Dirichlet test, I find it is convergent when $-1<p<2$. But how can I show its divergence? Applying Integration by parts seems tedious.","['real-analysis', 'integration', 'calculus', 'analysis']"
2203770,How to find all values of $z$ such that $z^3=-8i$,"If I am asked to find all values of $z$ such that $z^3=-8i$, what is the best method to go about that? I have the following formula:
$$z^{\frac{1}{n}}=r^\frac{1}{n}\left[\cos\left(\frac{\theta}{n}+\frac{2\pi k}{n}\right)+i\sin\left(\frac{\theta}{n}+\frac{2\pi k}{n}\right)\right]$$ for $k=0,\pm1, \pm2,...$ Applying this formula, I find the cubed root of $8$, which is $2$.  And then when I apply it to the formula, I get the following: $$z = 2\left[\cos\left(\frac{\pi}{3}+\frac{2\pi k}{3}\right)+i\sin\left(\frac{\pi}{3}+\frac{2\pi k}{3}\right)\right]$$ for $k=0,\pm1, \pm2,...$ I am confused, because the given solution is as follows:
$$z = 2\left[\cos\left(\frac{\pi}{2}+\frac{2\pi k}{3}\right)+i\sin\left(\frac{\pi}{2}+\frac{2\pi k}{3}\right)\right]$$ for $k=0,\pm1, \pm2,...$ Where did I go wrong?  How would my approach changed if I was asked to find all values for $-8$, or $8i$?","['complex-analysis', 'complex-numbers']"
2203781,Does this variant on Rolle's theorem have a name?,"The following seems to be true: Suppose $f : (a,b) \rightarrow \mathbb{R}$ is continuously differentiable. Then $$|x \in (a,b):f(x) = 0| \leq |x\in (a,b):f'(x) = 0|+1.$$ (By $|x \in X : P|$, I just mean the number of $x \in X$ satisfying $P$. This can be viewed as shorthand for the more long-winded $|\{x \in X : P\}|$.) I'm having trouble formalizing the details, but the proof is basically by Rolle's theorem. Since $f$ is continuous, there are two cases: The zeroes of $f$ are isolated from each other. There exists a non-empty open interval on which $f$ is zero. In the second case, both the LHS and RHS are $|\mathbb{R}|$, so we're done. So assume the zeros of $f$ are isolated from each other. Then we repeatedly apply Rolle's theorem to get a stationary point of $f$ for each root of $f$ beyond the first. That's the idea. Anyway, just wondering if this result has a name? It's basically the same as Rolle's theorem, but perhaps bit easier for young people to understand and use. For instance, suppose we wish to prove that $\sqrt{2}$ refers to exactly one real number. Define $f(x)=x^2-2.$ We want to show that $f$ has precisely one root in $(0,\infty)$. We get a lower bound on the cardinality its set of roots by computing $f(0) = -2$ and $f(2) = 2$, hence by IVT, we have: $$1 \leq |x \in (0,\infty) : x^2 -2 = 0|$$ For an upper bound, use the above theorem to get $$|x \in (0,\infty) : x^2 -2 = 0| \leq |x \in (0,\infty) : 2x = 0|+1 = 0+1 = 1$$ Ergo: $$|x \in (0,\infty) : x^2 = 2| = 1$$","['terminology', 'reference-request', 'real-analysis', 'calculus']"
2203801,Meaning of the inverse of a differential operator,Consider the Poisson's equation $$\nabla^2\phi(\textbf{x})=-\rho(\textbf{x})/\epsilon_0.$$ What is the meaning of the inverse operator in the following $$\phi(\textbf{x})=-\frac{1}{\nabla^2}\frac{\rho(\textbf{x})}{\epsilon_0}.$$ How do I show that $\frac{1}{\nabla^2}$ is equivalent to an integral operator acting on $\rho(\textbf{x})$?,"['operator-theory', 'greens-function', 'integral-operators', 'ordinary-differential-equations', 'fourier-transform']"
2203816,Prove that $\displaystyle \prod_{j=1}^{2n}\left(j^j(2n+j)^{j-1}\right)$ is a perfect square,"For any positive integer $n$, prove that $\displaystyle \prod_{j=1}^{2n}\left(j^j(2n+j)^{j-1}\right)$ is a perfect square. Let $f(n) = \prod_{j=1}^{2n}\left(j^j(2n+j)^{j-1}\right)$. Then $$f(1) = 2^4, \quad f(2) = 2^{20} \cdot 3^4 \cdot 7^2, \quad f(3) = 2^{32} \cdot 3^{18} \cdot 5^8 \cdot 11^4.$$ I didn't see a way to prove the expression is a perfect square for all $n$.",['number-theory']
2203827,Angle between two straight lines,"Two straight lines are given: $$
\left(
\begin{array}{c}
1\\
1\\
4
\end{array}
\right) + t  \left(
\begin{array}{c}
4\\
1\\
1
\end{array}
\right)
$$ and $$
\left(
\begin{array}{c}
5\\
5\\
2
\end{array}
\right) + s  \left(
\begin{array}{c}
0\\
1\\
-1
\end{array}
\right)
$$ I want to calculate the angle between them (which should be simple, arccos of the scalar product over the product of their norms). Since the angle should not change no matter which $s$ and $t$ we choose, I took arbitrary parameters $t = 2$ and $s = 1$ and calculated first just the scalar product of $(9,3,6)$ and $(5,6,1)$ - that is clearly non-zero, though the solutions state that the angle between the lines should be 90 degrees - what am I doing wrong? Thanks",['geometry']
2203841,"For $p$ prime and greater than 3, prove that $42p$ divides $3^p - 2^p - 1$","Prove the following:
$$42p \;|\; 3^p - 2^p - 1$$ $p$ is a prime number greater than 3. I started working through my old olympiad problem books, but I couldn't solve this one.","['number-theory', 'elementary-number-theory']"
2203868,Path component of the direct limit of topological spaces.,"We consider a direct limit of a tower $X_1\subset\cdots\subset X_n$ of spaces, where each $X_n$ is a subspace of $X_{n+1}$. The direct limit is $X_{\infty}:=\cup_n X_n$ endowed with the topology $\mathcal{T}_{\infty}$ defined as follows: $U\subset X_{\infty}$ is open if and only if $\forall n\in \Bbb{N},\quad U\cap X_n$ is open on $\mathcal{T_n}.$ I don't have any idea for the following question (I can write the definition and so on but I am stuck ): Is it true if $x$ and $y$ are in the same path component of $X_{\infty}$ then there are also on same path component of $X_{n}$ for $n$ big enough? Defintion path component of a topological space $Y$ are the equivalence classes of the equivalence relation on $Y$ defined by $x\sim y$ if and only if there exist a path connecting $x$ to $y$ edit It's assumed that $X_{\infty}$ is Hausdorff and each $X_i$ is closed in $X_{i+1}$ for all $i\ge 1$.","['general-topology', 'connectedness']"
2203871,difference between tending to zero and close to zero,"In calculus we are taught that the derivative of function $y$ with respect to $x$ is defined as ""the quantity which $\dfrac{\bigtriangleup{y}}{\bigtriangleup{x}}$ tends to when $\bigtriangleup{x}$ tends to zero"" Can we also define it as ""the ratio of $\dfrac{\bigtriangleup{y}}{\bigtriangleup{x}}$ when $\bigtriangleup{x}$ is a quantity very close to zero""?","['derivatives', 'infinitesimals', 'calculus', 'limits']"
2203900,Inscribed hypersphere of a simplex,What is the formula to calculate the radius $r$ and center $x$ of the inscribed hypersphere from the $n+1$ vertices of an arbitrary simplex in $R^n$? A matrix based solution is preferred.,"['matrix-equations', 'computational-geometry', 'euclidean-geometry', 'geometry', 'linear-algebra']"
2203932,On Mazur-Ulam theorem,"From classical theorem of Mazur-Ulam it follows that if $(X,\|\cdot\|)$ Banach space and $T\colon X\to X$ is surjective isometry (i.e. $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$) with $T(0)=0$ then $T$ is linear. My question is what if we instead of $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$ require $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$. In other words is it true: if $(X,\|\cdot\|)$ Banach space and map $T\colon X\to X$ continuously bijective map such that $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$ and $T(0)=0$ then $T$ is linear? Thank's in advance.",['functional-analysis']
2203946,A little problem on Lie Brackets relating it with the commutator of matrices,"I am trying to solve this problem: There is a hint saying that I can use the fact that for 
$$X=a_i\frac{\partial }{\partial x_i}\text{ with } a_i\in C^\infty(U)$$
and
$$Y=b_i\frac{\partial }{\partial x_i}\text{ with } b_i\in C^\infty(U)$$
we have
$$[X,Y]=\left(a_{i}\frac{\partial b_{j}}{\partial x_{i}}-b_{i}\frac{\partial a_{j}}{\partial x_{i}}\right)\frac{\partial}{\partial x_{j}}
 $$ But I did not manage to use this hint in any useful way. Also, the obvious procedure seems to be the following:
$$\Psi([X,Y])(P)=P[X,Y]=P(XY-YX)=PXY-PYX$$
and
$$[\Psi(X),\Psi(Y)](P)=\left(\Psi(X)\Psi(Y)-\Psi(Y)\Psi(X)\right)(P)\\=\Psi(X)\left(\Psi(Y)(P)\right)-\Psi(Y)\left(\Psi(X)(P)\right)=\Psi(X)\left(PY\right)-\Psi(Y)\left(PX\right)=PYX-PXY$$ And this is clearly wrong. So: 1) What did I miss in my attempt? 2) Any hints on solving this using the given hint? EDIT: I believe I can solve this using the hint if $[\tilde{X},\tilde{Y}](P)=[\tilde{X}(P),\tilde{Y}(P)]$. However, I do not know why/if this is true, and question 1) still holds.","['manifolds', 'differential-geometry']"
2204052,Definition of the rank of an abelian group,"According to wikipedia , the rank of an abelian group $G$ is the size of the largest free abelian group contained in $G$. So, is the rank of $G$ equal to:
$$\sup \{|F|\mid {F\text{ is a subgroup of }G\text{, }F\text{ is a free abelian group} }\}$$
? here, $|F|$ is the cardinality of $F$. I'm looking for a symbolic definition in general case. What is meant by largest in wikipedia?","['abelian-groups', 'group-theory', 'elementary-set-theory']"
2204112,Pascal Triangle Vs Sierpinski Triangle,What is the relation between these two triangles? I can remember an skew Sierpinski triangle in Pascal Triangle's page in wikipedia but it has been deleted? Can anybody explain the relation between these two?,"['combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
2204129,Rigid manifolds,"Definition A compact complex manifold M is called rigid if $H^1(M,\Theta_M) = 0$ $\Theta_M$ is the sheaf of holomorphic sections of the complex tangent bundle. Let's consider a proper map $f : M \rightarrow B$ whose differential is everywhere surjective. Let's suppose $B$ is connected and choose a point $b \in B$, set $M_b = f^{-1}(b)$. My question is: If $M$ is rigid then $H^1(M_b, \Theta_{M_b}) = 0$ for every choice of $b \in B$? I guess my claim is true but I don't find a way to prove it. I thought I could use some exact sequence of sheaves and then the induced long exact sequence but I didn't succeed in applying this idea. Any help would be very appreciated. Thank you in advance!","['tangent-bundle', 'sheaf-theory', 'sheaf-cohomology', 'algebraic-geometry']"
2204152,Bounding a sum of covariances under $\alpha$-mixing,"Assume that $Y=(Y_t, t \in \mathbb{N})$ is a strictly stationary $\alpha$-mixing process, and let $G_h(x)=G(x/h)=\int_{x/h}^{+\infty}K(u)du$, where $K$ is a Kernel function(symetric density in this case), and $h$ is the sequence of bandwidths, that satisfy certain properties, which can be found in the assumptions of Chen's work, that I will provide a link for, shortly. Moreover, assume that Y is a geometric $\alpha$-mixing process (i.e, there exist $C, \rho>0$ such that 
$\alpha(k)\leq \rho^k$, for all $k\geq 1$), and let $\nu_p$ be the $(1-p)$-th order quantile of Y_t. I am trying to show that, for $i=0, 1$ and $j=0, 1$,
\begin{align*}
\Bigg|\sum_{k=1}^{n-1}\left(1-\frac{k}{n}\right)\Big[\text{Cov}\Big(Y_{1}^{i}G_{h}&(\nu_{p}-Y_{1}), Y_{k+1}^{j}G_{h}(\nu_{p}-Y_{k+1})\Big) \\
&-\text{Cov}\left(Y_{1}^{i}I\left(Y_{1}>\nu_{p}\right), Y_{k+1}^{j}I\left(Y_{k+1}>\nu_{p}\right)\right)\Big]\Bigg| = o\left(h\right).
\end{align*} This lemma is in Chen's work, and he doesn't prove it. He refers to another article of his for the proof of i=j=0, and says the other cases are similar. You can find it here, under Lemma 4. http://www.public.iastate.edu/~songchen/shortfall.pdf The proof for i=j=0 is done in two steps. The first is to conclude that
$$\Bigg|\text{Cov}\Big(G_{h}(\nu_{p}-Y_{1}), G_{h}(\nu_{p}-Y_{k+1})\Big)-\text{Cov}\left(I\left(Y_{1}>\nu_{p}\right), I\left(Y_{k+1}>\nu_{p}\right)\right)\Bigg| \leq Ch^2,$$ which can be found in Cai and Roussas http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.7779&rep=rep1&type=pdf under lemma 2.2 (i). The proof provides interesting insight. The second step is to notice that, under the assumption of an $\alpha$-mixing process, we get that
$$\sup\limits_{(x,y) \in \mathbb{R}^2} \left|F_k(x,y)-F(x)F(y)\right| \leq \alpha(k)$$
Now, since 
$$\text{Cov}\left(I\left(Y_{1}>\nu_{p}\right), I\left(Y_{k+1}>\nu_{p}\right)\right) = F_k(\nu_p,\nu_p)-F^2(\nu_p) \leq \sup\limits_{(x,y) \in \mathbb{R}^2} \left|F_k(x,y)-F(x)F(y)\right| \leq \alpha(k),$$ and using the same idea as is done in Cai and Roussas, from a change of variables and Hoeffding's identity we get \begin{align*}
\text{Cov}&\Big(G_{h}(\nu_{p}-Y_{1}), G_{h}(\nu_{p}-Y_{k+1})\Big) \\
&= \int_{\mathbb{R}^2}\left[ F_k\left(\nu_p-hr, \nu_p-hs\right)-F\left(\nu_p-hr\right)F\left(\nu_p-hs\right) \right] K\left(r\right)K\left(s\right) dr ds \\
&\leq \sup\limits_{(x,y) \in \mathbb{R}^2} \left|F_k(x,y)-F(x)F(y)\right| \int_{\mathbb{R}^2} K\left(r\right)K\left(s\right) dr ds \\
&= \sup\limits_{(x,y) \in \mathbb{R}^2} \left|F_k(x,y)-F(x)F(y)\right| \leq \alpha(k)
\end{align*}
we get that 
$$\Bigg|\text{Cov}\Big(G_{h}(\nu_{p}-Y_{1}), G_{h}(\nu_{p}-Y_{k+1})\Big)-\text{Cov}\left(I\left(Y_{1}>\nu_{p}\right), I\left(Y_{k+1}>\nu_{p}\right)\right)\Bigg| \leq 2\alpha(k).$$ Let us write $ \gamma_h^{i,j}(k) = \text{Cov}\left(Y_{1}^i G_{h}\left(\nu_{p}-Y_{1}\right), Y_{k+1}^j G_{h}\left(\nu_{p}-Y_{k+1}\right)\right)$ and $\gamma^{i,j}(k) = \text{Cov}\left(Y_{1}^i I\left(Y_{1}>\nu_{p}\right), Y_{k+1}^j I\left(Y_{k+1}>\nu_{p}\right)\right)$. These two bounds we provided for $\Bigg|\gamma_h^{0,0}(k)-\gamma^{0,0}(k)\Bigg|$ allow us write $$|\gamma_h^{0,0}(k)-\gamma^{0,0}(k)|= |\gamma_h^{0,0}(k)-\gamma^{0,0}(k)|^{2/3} |\gamma_h^{0,0}(k)-\gamma^{0,0}(k)|^{1/3}\leq Ch^{4/3}\alpha^{1/3}(k),$$ which allows us to conclude $$\left|\sum_{k=1}^{n-1}\left(1-\frac{k}{n}\right) \left[\gamma_h^{0,0}\left(k\right)-\gamma^{0,0}\left(k\right)\right]\right| \leq \sum_{k=1}^{n-1} \left|\left[ \gamma_h^{0,0}\left(k\right)-\gamma^{0,0}\left(k\right)\right]\right| \leq Ch^{4/3}\sum_{k=1}^\infty \alpha^{1/3}(k) = o\left(h\right),$$
which concludes the proof for the case i=j=0. In his article, Chen says that for the other cases of i and j, the proof is similar, but I can not conclude. I have already shown that, for i=j=1, 
$$\Bigg|\gamma_h^{1,1}(k)-\gamma^{1,1}(k)\Bigg|\leq Ch^2.$$
However, I am not being able to show anything of the sort $\Bigg|\gamma_h^{1,1}(k)-\gamma^{1,1}(k)\Bigg| \leq C\alpha(k)$. This would allow me to conclude. Thank you very much for reading and for any help you can provide.","['real-analysis', 'asymptotics', 'statistics', 'probability', 'analysis']"
2204160,Graph Theory - Application of Kirchoff's Matrix Tree Theorem,Calculate the number of spanning trees of the graph that you obtain by removing one edge from $K_n$ . (Hint: How many of the spanning trees of $K_n$ contain the edge?) I know the number is $(n-2)n^{n-3}$ and that Kirchoff's matrix tree theorem applies but how do I show this?,"['graph-theory', 'trees', 'determinant', 'combinatorics', 'algebraic-combinatorics']"
2204162,Real Cyclic Extensions of $\mathbb Q$ of given degree,"An old qual problem asks us to Show that for every positive integer $n$, there exists a cyclic extension of $\mathbb{Q}$ of degree $n$ which is contained in $\mathbb{R}$. A first thought might be towards Kummer theory: we could adjoin an $n^\text{th}$ root of, say, a prime number.  But when $n>2$, $\mathbb{Q}$ lacks the full cohort of roots of unity that would make this work.  If $n$ is a power of $2$ we can get what we want by adjoining ($\mathbb{Q}$-linearly independent) square roots to $\mathbb{Q}$, and I think some casus irreducibilis things can be done in other degrees ( at least $n=3$ and $n=5$)  but a more general $n$ has me stumped. Could I get a nudge in the right direction on this problem?","['abstract-algebra', 'galois-theory', 'field-theory']"
2204203,"$f(x,y)=(e^x \cos(y), e^x\sin(y))$ is one-to-one proof. And onto?","Let $A:=\mathbb{R} \times (0,2\pi)$. Show that the function $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ defined by $f(x,y)=(e^x \cos(y), e^x\sin(y))$ is one-to-one on $A$. Is it onto? My attempt (one-to-one) Let $f(x_1,y_1)=f(x_2,y_2)$. Then $$e^{x_1}\cos y_1=e^{x_2}\cos y_2$$ and
$$e^{x_1}\sin y_1=e^{x_2} \sin y_2$$ Squaring both and then adding we get: $$e^{2x_1}\cos^2y_1+e^{2x_1}\sin^2 y_1=e^{2x_2}\cos^2y_2+e^{2x_2}\sin^2 y_2$$
$$=e^{2x_1}(\cos^2y_1+\sin^2y_1)=e^{2x_2}(\cos^2y_2+\sin^2y_2)$$
$$e^{2x_1}(1)=e^{2x_2}(1)$$
$$x_1=x_2$$ Not sure how to get $y_1=y_2$ here...Also not sure how to intuitively know if this is onto (and provide such proof). Thanks for the help!","['multivariable-calculus', 'real-analysis']"
2204230,Are the definition of cosx got from power series and the triangle definition of cosx same?,"For right angled triangle $ABC$,  $\cos x = \frac{adjacent}{hypotenuse} = \frac{AB}{BC}$ Again from power series expansion of $\cos x$ we get
$$\cos x = 1-\frac{x^{2}}{2!}+\frac{x^{4}}{4!}-\frac{x^{6}}{6!}+......$$
  Are these two definitions same?","['trigonometry', 'power-series']"
2204250,Proving $\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot\left(2-{\sin x\over \sin\left({x\over 2}\right)}\right)^{n+1}={2n\choose n}\pi$,"Given integral $(1)$ $$\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot\left(2-{\sin x\over \sin\left({x\over 2}\right)}\right)^{n+1}={2n\choose n}\pi\tag1$$
  Where $n\ge0$ How does one prove $(1)$? An attempt: Recall $$\sin(2x)=2\sin x\cos x$$ $(1)$ becomes $$2^{n+1}\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot\left(1-\cos\left({x\over 2}\right)\right)^{n+1}\tag2$$ Applying binomial series to $(2)$, then we have $$2^{n+1}\sum_{k=0}^{n+1}(-1)^k{n+1\choose k}\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot\cos^k\left({x\over 2}\right)\tag3$$ Not sure how to proceed...","['calculus', 'integration', 'definite-integrals', 'pi', 'sequences-and-series']"
2204258,Roundest ellipse with specified tangents,"Suppose you are given two points $\mathbf p_1$ and $\mathbf p_2$ in the plane with associated vectors $\mathbf v_1$ and $\mathbf v_2$. You want to find an ellipse passing through $\mathbf p_1$ tangent to $\mathbf v_1$ and through $\mathbf p_2$ tangent to $\mathbf v_2$. There are infinitely many solutions , but a natural choice is to take the one that is the closest to a circle, i.e. the one with the minimum eccentricity. Is there an elegant way to compute such an ellipse given $(\mathbf p_1, \mathbf v_1)$ and $(\mathbf p_2, \mathbf v_2)$?","['conic-sections', 'geometry']"
2204261,are constants the only stationary martingales?,"Let $(X_n,\mathcal{F}_n)_{n\in\mathbb{Z}_+}$ be a nonnegative bounded martingale. Assume that the process $X_n$ is strictly stationary. Does it imply that $X_n$ is constant almost surely?","['stochastic-processes', 'probability', 'martingales']"
2204284,Solvable word problems and quasi-isometries,"It is known that a finitely presented group has a solvable word problem if and only if it satisfies a recursive isoperimetric inequality (ie., its Dehn function is bounded above by some recursive function), so that having a solvable word problem turns out to be a quasi-isometric invariant among finitely presented groups . So my question is: Let $G,H$ be two quasi-isometric (finitely generated) groups which are not finitely presented. Suppose that $G$ has a solvable word problem. Has $H$ a solvable word problem as well?","['group-theory', 'geometric-group-theory']"
2204295,Prove that three segments in a convex hexagon intersect at one point,"Let $ABCDEF$ be convex hexagon such that $\angle ABC=\angle BCD=\angle DEF=\angle EFA$ and $|AB|+|DE| =|AF|+|CD|$. Prove that line $l_{AD}$ and perpendicular bisectors of sides $\overline{BC}$ and $\overline{EF}$ intersect at some point. This is the diagram: As you can see, I prolonged segments $\overline{CD}$ and $\overline{AB}$ to intersect at $X$ and, similarly, $\overline{DE}$ and $\overline{AF}$ to intersect at $Y$. Then, as $\angle ABC=\angle BCD$, we have that triangle $\triangle BXC$ is equilaterial and the perpendicular bisector of the side $\overline{BC}$ is in fact the bisector of the angle $\angle BXC$, and, similarly, perpendicular bisector of $\overline{FE}$ bisects $\angle EYF$. But what now? Any hints?","['contest-math', 'geometry']"
2204318,Pseudo Inverse of product of Matrices,"Let $A$ and $B$ are two matrices where $A \in \mathbb{R}^{m\times p}$ and $B \in \mathbb{R}^{p\times n}$ and both $A$ and $B$ are full rank matrices  Now I really want to know in what cases $(AB)^+ = B^+A^+$  ,where $A^+$ is Moore-Penrose Pseudo-inverse of $A$ Here $m,p$ and $n$ are in any order like $m<p<d$ or $m>p<d$ etc.","['pseudoinverse', 'linear-algebra']"
2204325,Suggestions for a project in matlab [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm doing a project on numerical integration in Matlab and I'm looking for some nice things to program. So far, I programmed: Trapezium rule Simpson rule Double integral over a rectangle Estimating $\pi$ using the integral $$\int\limits_0^{1}\frac{4dx}{1+x^2}$$ Do you know any other things that involve integrals and are not too hard to program (I am a first year university undergraduate). Any ideas are welcome. I'm aware that this is a subjective question, but I'm interested in all kind of things. Thanks in advance.","['numerical-methods', 'integration', 'matlab']"
2204348,Why is the Complete Flag Variety an algebraic variety?,"Let $V$ be a $\mathbb C $ - vector space of dimension $n$.
Let's consider the set $Fl(n)$ of all the complete flags $F_{\bullet}$  $$F_1 \subset F_2 \cdots \subset  F_n$$ where the $F_i$ are subspaces of $V$ with $\dim(F_i)=i$ for every $1 \leq i \leq n$. Why is this an affine/projective variety? I know that given that we can use the transitive action of $GL(n, \mathbb C)$ and deduce that $$Fl(n) \simeq GL(n, \mathbb C)/B_n$$ where $B_n$ is the subgroup of the upper triangular matrices. But first we need to show that it is an algebraic variety. Thanks!","['schubert-calculus', 'linear-algebra', 'algebraic-geometry', 'lie-groups']"
2204349,Difference between the Lorentz group and the restricted Lorentz group,"I'm studying actions on Minkowski space ($\mathbb R^4$) in the context of the Lorentz transformations. In particular, the Lorentz group is the group of all linear endomorphisms on $\mathbb R^4$ that preserves the quadratic form $$(t,x,y,z) \mapsto t^2-x^2-y^2-z^2$$ $\forall x,y,z,t \in \mathbb R$. This group is shown to be equivalent to the generalised orthogonal group $O(1,3)$ where $(1,3)$ is the signature of the quadratic form. The identity component of the Lorentz group is denoted $SO^+(1,3)$ and is called the restricted Lorentz group. This group consists of the Lorentz transformations that preserve the orientation of space and the direction of time. What I am trying to understand is how these two groups are different. Which transformations would be in the group $O(1,3)$ but not in $SO^+(1,3)$? In particular, I am trying to construct a general isomorphism from the Mobius group to the Lorentz group but it seems that this is only possible for the restricted Lorentz group.","['mathematical-physics', 'group-isomorphism', 'group-theory', 'linear-transformations']"
2204375,Space curve of Trefoil knot made of ideal flexible nonstretchable steel wire.,"What space curve defines a Trefoil knot made of ideal flexible nonstretchable steel wire? By ideal flexible nonstretchable steel wire I mean wire that meets this requirements: a wire cannot shorten or extend but can be bend without limit a wire tends to straighten itself in every point a wire has zero friction with itself. Curve can be defined explicitly, implicitly, parametrized or numerically. EDIT:
I uploaded an example of torus knot made of steel wire to show that the shape is unique. You can squeeze it and it returns into the same shape (of course the wire is real world and not ideal, but you can get the idea).",['differential-geometry']
2204449,"$f(x,y)= (x^2-y^2, 2xy)$. Show $f$ is one-to-one","Let $A:=\{(x,y)\in \mathbb{R},x>0\}$. Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ be defined by $f(x,y)= (x^2-y^2, 2xy$). Show that $f$ is one-to-one on $A$. My attempt: $$f(x_1,y_1)=f(x_2,y_2)$$ so
$$\tag{$*$} x_1^2-y_1^2=x_2^2-y_2^2$$ and
$$2x_1y_1=2x_2y_2$$
$$\tag{$**$}x_1y_1=x_2y_2$$ From $(**)$, we have two cases. Either $y=0$ or $y\neq 0$. CASE $1$ : $y=0$. From $(*)$: $$x_1^2=x_2^2$$ Taking the square root of both sides $$x_1=x_2$$ where $x_1,x_2>0$. CASE $2$: $y \neq 0$ I am stuck on Case $2$...","['real-analysis', 'functions']"
2204536,What does it mean geometrically for a divisor to be numerically effective?,Let $D$ be a $\Bbb Q$-Cartier divisor on an algebraic variety $X$. We say $D$ is numerically effective if $D\cdot C\geq 0$ for every algebraic curve $C$ in $X$. How should one interpret this geometrically?,"['divisors-algebraic-geometry', 'intersection-theory', 'algebraic-geometry']"
2204550,Extending the Definition of Asymptotic Density to rationals,"$\require{enclose}$ Edit: Replace rationals with $\enclose{horizontalstrike}{\mathbb{Z}\times\mathbb{Z}}$. And view fractions as $\enclose{horizontalstrike}{(\text{Numerator},\text{Denominator})}$ instead of $\enclose{horizontalstrike}{\frac{\text{Numerator}}{\text{Denominator}}}$. For more information look at Hurkyl's answer I want to extend the definition of asymptotic density to countably dense sets. The Asymptotic density of a subset of $\mathbb{N}$ gives the ratio of the number of elements from the subset, compared to the number of elements from $\mathbb{N}$, between $[0,n]$ as $n\to\infty$. I want to apply a similar concept to the subsets of rationals which gives a ratio of number of elements from the subset of $\mathbb{Q}$, compared to number of elements from $\mathbb{Q}$, based on restricted intervals. Note this is not the same as extending the definition of asymptotic density to $\mathbb{Z}\times\mathbb{Z}$, as this takes the density of the numerator and denominator separately and counts the same element more than once. This ""new density"" should act as an informal measure. If such a density exists and that density of set $X$ is $D(X)$, then the density for sets $A$ and $B$ should be meet the following requirements such that If set $A=B$ then $D(A)=D(B)$ If set $A\subset{B}$ then $D(A)\le D(B)$ However, I am not sure how to answer this question. So far I determined the following. The rationals or $\left\{\left.\frac{m}{n}\right|m,n\in\mathbb{Z}\right\}$ can be divided into groups of sets that contain eachother. \begin{equation}
\left\{\left.\frac{2^{k}m}{2n+1}\right|m,n\in\mathbb{Z}\right\}\subset...\subset\left\{\left.\frac{2m}{2n+1}\right|m,n\in\mathbb{Z}\right\}\subset\left\{\left.\frac{m}{2n+1}\right|m,n\in\mathbb{Z}\right\}\subset\left\{\left.\frac{m}{4n+2}\right|m,n\in\mathbb{Z}\right\}\subset...\subset\left\{\left.\frac{m}{2^{k}(2n+1)}\right|m,n\in\mathbb{Z}\right\}=\left\{\left.\frac{m}{n}\right|m,n\in\mathbb{Z}\right\} \qquad (1)
\end{equation} However, each set can be permuted diffferently. For example $\left\{\left.\frac{m}{2n+1}\right|m,n\in\mathbb{Z}\right\}=\left\{\left.\frac{m}{3(2n+1)}\right|m,n\in\mathbb{Z}\right\}=\left\{\left.\frac{m}{5(2n+1)}\right|m,n\in\mathbb{Z}\right\}$ Hence we need identical sets with different permutations to be permuted in the same permutation before taking their density. I believe all sets should be rearranged to have permutations similar to the sets in (1) for two reasons. One, the union of the numerator and denominator of all the set covers every integer that could be in the numeator and denominator. Second, due to their permutations, the sets can easily be shown as the subsets of one another. For example, we can convert $(1)$ into \begin{equation}
\left\{\left.\frac{2^{2k}m}{2^k(2n+1)}\right|m,n\in\mathbb{Z}\right\}\subset...\subset\left\{\left.\frac{2^{k+1}m}{2n+1}\right|m,n\in\mathbb{Z}\right\}\subset\left\{\left.\frac{2^{k}m}{2n+1}\right|m,n\in\mathbb{Z}\right\}\subset\left\{\left.\frac{2^{k-1}m}{4n+2}\right|m,n\in\mathbb{Z}\right\}\subset...\subset\left\{\left.\frac{m}{2^{k}(2n+1)}\right|m,n\in\mathbb{Z}\right\}=\left\{\left.\frac{m}{n}\right|m,n\in\mathbb{Z}\right\} \qquad (1)
\end{equation}
then we can compare the density of the numerators. From here, I attempted an answer below this post but I am not sure if its correct. 
If I'm wrong could there still be way of extending asymptotic density to subsets of rationals?","['real-analysis', 'asymptotics', 'analysis']"
2204571,How do I find the cumulative distribution function of the sequence of random variables $X_n=(-1)^{n+X}+1/n$?,"The related question is the following. The solution is as follows. I know that $$F_{X}(x)=P(X\leq x)=\begin{cases} 0, &x<-1 \\ 1/2, &x\in[-1,1) \\ 1, &x\geq 1\end{cases}.$$ But how do I find $F_{X_n}(x)=P(X_n\leq x)$?","['probability-limit-theorems', 'probability', 'functions']"
2204627,Repeated squaring techniques,"Here is the problem and the solution my text gives me. When I first approached this problem, I looked up ""repeated squaring"" online and tried the following algorithm from khan academy . Find the binary representation of the exponent $383 \Rightarrow 101111111$ This means that the quantity $3^{383}$ can be written as $3^{256+64+32+16+8+4+2+1}$ This also means that $3^{383} = 3^{256}3^{64}3^{32}3^{16}3^8 3^4 3^2 3^1 $ Khan Academy's article says to take the mod of each one of those factors, multiply them together, and then reduce by the mod. While this makes sense, computing $3^{256}$ seems just as hard as $3^{383}$. Well that's fine, since we have a way to compute large exponents, we can recursively go through and compute $3^{255}$, etc. the same way, but this seems wasteful. My text's solution seems much simpler to do by hand but I can't find an explanation of why or how it works.","['exponentiation', 'modular-arithmetic', 'discrete-mathematics']"
2204671,For any bounded operator T on H there exists a sequence of finite rank operators $(T_n)_{n=1}^{\infty}$ such that $T_n → T$ strongly.,"I have come up with a proof which I want to confirm as some parts of it make me unsure whether its correct or not. Note: $T_n \to T$ strongly means 
$$\|T_n(x)-T(x)\| \to 0 \ \ \ \forall x\in H.$$ Here is my proof attempt. Let $(e_j)_{j=1}^{\infty}$ be an orthonormal basis for $H$ ($H$ is assumed separable) and $(g_k)_{k=1}^{\infty}$ be a sequence consisting of finite linear combinations of $e_j$, more precisely for each g in H, we choose 
$$g_k= \sum_{i=1}^{k} \langle g,e_i\rangle  e_i.$$ 
Now define $T_n$ by 
$$T_n(g_k)=\begin{cases} T(g_k) & \text{for }k\leq n, \\ 0 &\text{for } k>n.\end{cases}$$
Clearly each $T_n$ has finite rank since the range of each $T_n$ is the span of $(g_1,..,g_n)$. Also $||T_n (g_k)-T(g_k)||=0$ for $n \geq k$ Let now g be an arbitrary element of H. Then since $(g_k)_{k=1}^{\infty}$ is dense in H, $||g-g_k||\to 0$ as $k\to \infty$. Then by the triangle inequality, $$||T_n(g)-T(g)||\leq ||T_n(g)-T_n(g_k)|| + ||T_n(g_k)-T(g)||$$ First taking the limit as $n\to \infty$, we get that the first term goes to 0 (by continuity of norm) since $T_n(g_k)=T_n(g)$ for $n\geq k$, and the second term goes to $||T(g_k)-T(g)||$. Now 
$$||T(g_k)-T(g)||\leq \|T\| \|g_k-g\|$$ 
by definition of operator norm. Since $||T||<\infty$, taking the limit as k goes to $\infty$ and using the fact that $||g_k-g||\to 0$ we get that $||T_n(g)-T(g)||\to 0$ as $n\to\infty$ My question is, the definition my book uses for a basis is that $(e_n)$ is a basis if finite linear combinations are dense (in the norm) in H. Now for me that means for each g in H,given $\epsilon>0$ there exists a $(g_k)$ which is a finite linear combination of $e_j$ such that $||g_k-g||< \epsilon$. Is that equivalent to the existence of a sequence $(g_k)$ where each $g_k$ is a finite linear combination of $e_j$'s such that $||g_k-g||\to 0$ as $k\to \infty$ ? Also, is my proof correct? Taking limits with respect to k and n bothers me a bit whether I am allowed to do that or not. Thanks in advance for any comments. Edit: Reading my notes, it seems I need to be more precise on what the $g_k$ are. They depend on the g that would be chosen. More precisely, $g_k= \sum_{i=1}^{k} <g,e_i> e_i$. Then it works?","['functional-analysis', 'operator-theory']"
2204715,"Proof C(n,r) = C(n, n-r)","Hello just want to see if my proof is right, and if not could someone please guide me because I am not clearly seeing the steps to this proof. I don't know if I correctly solve the proof in the second to last step. If I did any mistake it would be great if someone could point at it.
$$
C(n, n-r) = \frac{n!}{r!(n-r)!} = \frac{n!}{(n-r)!(n-(n-r))!} = \frac{n!}{(n-r)! (r)!} = C(n,r) 
$$",['discrete-mathematics']
2204746,"If $f(x) = -3x^2 + 6x + 2$, prove that $f(x)$ is $O(x^2)$","I had a question on Big-O. If $f(x) = -3x^2 + 6x + 2$, prove that $f(x)$ is $O(x^2)$ Generally my teacher gave us these strategies to follow:
 1. Eliminate Negative Terms
 2. Multiply to match highest order term. So in this case Would I be getting rid of $-3x^2$ term and end up with $6x+2$? So my $c = 8$ and $k = 1$. Any help would be appreciated.",['discrete-mathematics']
2204765,Theory of Transfinite Numbers (Georg Cantor),"I would appreciate if someone could help me understand how the author, Georg Cantor, arrived at the three conclusions in the second to last line of page 96: http://www.maths.ed.ac.uk/~aar/papers/cantor1.pdf The three conclusions are: {$t_{2v-1}$} ~ {$s_v$} {$t_{2v}$} ~ {$t_v$} $X_1$ ~ $X_1$ Thank you!",['elementary-set-theory']
2204807,How many distinct distances in an $n$ x $n$ lattice?,"I calculated the values to this question for $n = 2 - 14$ and got: $2, 5, 9, 14, 19, 26, 33, 41, 50, 60, 70, 82,$ and $92$. I can't figure out the pattern going on here, and this sequence aren't on OEIS. I suppose the problem could be generalized to the $n$ x $n$ x $n$ 3D lattice, the $n$x $n$x $n$x $n$ 4D and so on, but I couldn't even figure out the 2D case.","['discrete-geometry', 'euclidean-geometry', 'geometry', 'combinatorics', 'discrete-mathematics']"
2204832,boundedness of signed measure $\mu$ with $\mu(A) < \infty$ for all $A$,"In my text, the claim is made that ""if for every $A \in \mathcal{A}, |\mu(A)| < \infty$, then $|\mu(A)|$ is bounded by the larger of $\mu^{+}(X)$ or $\mu^{-}(X)$."" The proof the textbook gives is annoyingly complicated, and I'm at a loss to see why the following doesn't suffice instead: ""We have $\mu(A) \le \mu^{+}(A) \le \mu^{+}(X)$ and $-\mu^{-}(X) \le -\mu^{-}(A) \le \mu(A)$, so that $|\mu(A)| \le \max\{\mu^{+}(X), \mu^{-}(X)\}$. Taking a Hahn decomposition we have $\mu^{+}(X) = \mu(P)$ and $\mu^{-}(X) = \mu(N)$, and if either of these were infinite then the corresponding set $P$ or $N$ would have measure $\pm \infty$, and so $|\mu(P)|$ or $|\mu(N)|$ would be $\infty$, contradicting our hypothesis about all $A \in \mathcal{A}$. Thus $\max\{\mu^{+}(X), \mu^{-}(X)\}$ will be a finite positive bound on $|\mu(A)|$."" Is there a subtlety I overlooked?","['real-analysis', 'measure-theory']"
2204834,Why is $5^{n+1}+2\cdot 3^n+1$ a multiple of $8$ for every natural number $n$?,"I have to show by induction that this function is a multiple of 8. I have tried everything but I can only show that is multiple of 4, some hints? The function is
$$5^{n+1}+2\cdot 3^n+1 \hspace{1cm}\forall n\ge 0$$, because it is a multiple of 8, you can say that$$5^{n+1}+2\cdot 3^n+1=8\cdot m \hspace{1cm}\forall m\in\mathbb{N}$$.","['algebra-precalculus', 'induction']"
2204935,Linearity in Expected Value,"I have 4 cards, number 1, 2, 3, and 4. I draw 2 cards at random and without replacement. What is the expected value of the sum? Solution:
$E[X_1+X_2]=E[X_1]+E[X_2],$  where $E[X_i]= 1/4(1+2+3+4)=2.5$. Thus $E[X_1+X_2]=2*2.5 =5.$ I totally understand that regardless $X_1,X_2$ are dependent or independent, linearity in expectation holds. My question is, how come after taking the expectation, you can treat $E[X_1]=E[X_2]=E[X_i]?$ This has sharp contrast with the Coupon Collection problems, in which the problem asks the expected number of attempts in order to collect at least 1 coupon of each N type. Linearity of expectation still holds. 
The solution is: $E[Coupon_1 + Coupon_2 + .. + Coupon_N] = E[Coupon_1] + ... + E[Coupon_N]$ however, $E[Coupon_1] \neq E[Coupon_2]\neq E[Coupon_3].....$. Whereas in the former problem, you can treat $E[X_i]$ to be the same, while in both cases, they are all dependent on the other random variables. But in the later case, the $E[X_i]$ are no longer the same.  I am confused!","['probability-theory', 'probability', 'probability-distributions']"
2205005,Show that if $y=x^{n-1}e^{1/x}$ then $D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}}$,"Show that if $y=x^{n-1}e^{1/x}$ then $D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}}$ $y_1={{\rm e}^{{x}^{-1}}} \left( {x}^{n-2}n-{x}^{n-2}-{x}^{n-3} \right) $ $y_2={\frac {{{\rm e}^{{x}^{-1}}} \left(  \left( -1+ \left( n-2 \right) x
 \right)  \left( n-1 \right) {x}^{n-2}-{x}^{n-3} \left( -1+ \left( n-3
 \right) x \right)  \right) }{{x}^{2}}}
$ I want to use Leibnitz rules for successive differentiation. Please help.","['derivatives', 'calculus']"
2205068,Example of a linear operator whose graph is not closed but it takes a closed set to a closed set,"I want an example of a linear operator $T:X\to Y$, where $X$ and $Y$ are normed linear spaces, such that graph of $T$ is not closed but $T$ maps closed sets of $X$ to closed sets in $Y$. For functions other than linear operators it is not that difficult. If we consider $f:\mathbb R\to \mathbb R$ by $f(0)=0$ and $f(x)=1$ for all $x\in \mathbb R\setminus \{0\}$, then $f$ maps every subset of $\mathbb R$ to a closed set in $\mathbb R$ but grapf of $f$ is not closed. Any help will be appreciated. We know that there always exists a discontinuous linear functional $f:X\to \mathbb R$, where $X$ is an infinite dimensional normed linear space. If $f:c_0\to \mathbb R$ is a discontinuous linear functional then for every $n>0$, there exists $x^{(n)}\in c_0$ such that $|f(x^{(n)})|>n\|x^{(n)}\|_{\infty}$. Now we define $T:c_0\to c_0$ by $T(x)=(f(x),x_1,x_2,\ldots)$ for all $x\in c_0$. Then $\|T(x^{(n)})\|_{\infty}=\sup\{|f(x^{(n)})|,|x_1|,|x_2|,\ldots\}>n\|x^{(n)}\|_{\infty}$. Thus $T$ is a discontinuous linear operator. Since $c_0$ is a Banach space, therefore graph of $T$ is not closed. Is the function $T$ maps every closed set in $c_0$ to a closed subset of $c_0$?","['banach-spaces', 'closed-map', 'functional-analysis', 'closed-graph', 'linear-transformations']"
2205103,Correct $\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\left(1-{\sin x\over x}\right)^n={\pi\over n+1}?$,"Consider the integral $(1)$ $$\text{Conjecture}\ \int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\left(1-{\sin x\over x}\right)^n=\color{blue}{\pi\over n+1}\tag1$$
  Where $n\ge1$ Required help to prove conjecture $(1)$ An attempt: Apply binomial series to $(1)$, then we have $$\sum_{k=0}^{n}(-1)^k{n\choose k}\int_{-\infty}^{+\infty}{x^{n-k}\sin^k x\over x^2}\mathrm dx\tag2$$ We can apply the trick of $(3)$ $$\int_{-\infty}^{+\infty}f(x){\sin^2 x\over x^2}\mathrm dx=\int_{0}^{\pi}f(x)\mathrm dx\tag3$$
then $(2)$ becomes
$$I_k=\sum_{k=0}^{n}(-1)^k{n\choose k}\int_{0}^{\pi}{x^{n-k}\sin^{k-2} x}\mathrm dx\tag4$$ I guess we could apply integration by parts to $(4)$ but seem difficult...","['calculus', 'improper-integrals', 'integration', 'definite-integrals', 'sequences-and-series']"
2205118,Prove $\liminf (a_n) \leq \limsup (a_n)$,"I've been working on this for a bit and haven't got far :/ So the full question is: Suppose $(a_n)_{n=1}^{\infty}$ is a bounded sequence of real numbers. Prove that $$\liminf (a_n) \leq \lim\sup (a_n)$$ (Hint: apply the result of the previous question to a difference of two sequences.) So the previous question was basically: $(a_n)_{n=1}^{\infty}$ is a convergent sequence and $a_n \in [0, \infty) \forall n$ . Prove the limit lies in $[0, \infty)$ . How I solved it was fixed $\epsilon > 0$ then $\exists$ $N \in \mathbb{N}$ $\forall$ $n\geq N$ I let the limit $=a$ . $\therefore$ $|a_n - a| < \epsilon$ Since $a_n$ took finitely many values $\implies$ $M_1 = \max\{|a_1|,...,|a_{N-1}|\}$ , let $M_2 = |a| + \epsilon$ Since it converges it's bounded by some M $\implies$ $(a_n)^{\infty}_{n=1}$ within $[0, M]$ Since $[0, M]$ is closed, it contained its limit points $\implies$ $\lim_{n\to\infty} a_n \in [0,M] \subset [0, \infty)$ . So far I've said; $(a_n)_{n=1}^{\infty} \in [\mathbb{R}]$ $M_1 = \inf\{a_n\}, M_2 = \sup\{a_n\}$ (From previous question) Therefore, $\sup\{a_n\} = |a_n| + \epsilon$ $\inf{a_n} = \max\{a_1, a_2, ..., a_{N-1}\}$ $|a_n|<M_1 \implies |a_n| < \inf\{a_n\}$ $|a_N| < |a| + \epsilon \implies |a_N|< \inf\{a_n\}$ That's all I have not sure if it actually means anything but yeah as I said any help would GREATLY be appreciated. Thanks ;)","['sequences-and-series', 'limits']"
2205174,Calculus of variations with two functions and inequality,"I wish to extremise $$ Q = \int_0^h u \, \,dy $$ with the following constraints $$B = \int_0^h u g \, \, dy \\ M = \int_0^h u^2 +\left(\int_0^y g \, \,dy^*\right) \, \, dy$$ where $M,B$ are constant. So my idea is to set this up as a variational problem as such $$\varepsilon \left(Q + \lambda B + \mu M\right) = 0$$ We assume $$u = u_0 + \varepsilon u_1 \\ g = g_0 + \varepsilon g_1 $$ I also wish to constrain that $0 < g \leq g^*$ for some given $g^*$, but I will ignore that for the time being. Taking $O(\varepsilon)$ terms gives $$\varepsilon \left[\int_0^h u_1 + \lambda(u_0g_1+u_1g_0) + \mu 2 u_0u_1 +  \mu\left[y \int_0^h g_1 \right]_0^h - \mu \int_0^h y  g_1  \, \,dy \right] = 0$$ Where I have used integration by parts on the $\int g$ term in $M$. This gives $$ \int_0^h \left[ u_1(1 + \lambda g_0 + 2 \mu u_0) + g_1(\lambda u_0 + \mu(h-y) \right] = 0 $$ Taking the two terms to be independent gives $$u_0 = -\frac{\mu}{\lambda}(h-y) \\ g_0 = -\frac{1}{\lambda} + 2\left(\frac{\mu}{\lambda}\right)^2(h-y)$$ All good so far I think? I expected $u_0,g_0$ to be linear. For ease of notation set $\omega = -\mu / \lambda$ and $-1/\lambda = \beta$. Then we can arrive substituiting $u_0, g_0$ into the definitions of $M,B$ with some algebra, at $$M = \omega^2 h^3 + \frac{\beta h^2}{2} \\ B = \frac{2}{3}\omega^3 h^3 + \frac{\beta \omega h^2}{2}$$ And hence, these two simultaneous equations give $$Q = \frac{(3(M \omega - B)^{2/3}}{2 \omega} $$ So here is where I run out of steam a bit. I guess I want to extremise $Q$ so take $$\frac{\partial Q}{\partial \omega} = 0 \Rightarrow \omega = \frac{3B}{M}$$ However, this $\omega$ implies that $\beta = -2M / h^2 < 0$, which means that the constant term in $g_0$ is negative, which is unphysical in my set up, so we must have $\beta = 0$ at the maximal value. Proceeding with $\beta = 0$ gives us $$\omega = \frac{3B}{2M}$$ which gives me a maximal $$Q = \frac{M}{2^{2/3} 3^{1/3} B^{1/3}}$$. However, I am not sure if this answer/my method is correct, nor how to incorporate the inequality constraint that $g_0$ is smaller than some fixed value. I can get a measurement for maximal $Q$ via a different method, which provides me with the correct powers/dimension, but the prefactors (in particular the $2^{2/3}$) are incorrect. Any pointers on how to answer this type of question? How to incorporate the inequality? Or if indeed my method is correct. EDIT To show why I select $\beta = 0$ as the maximal case. Consider the plot of $Q$ against $\omega$. If we input some reasonable (physically sound) values for $M = 4.5$ and $B = 2$ we have So we can see that $Q$ has a maximal value. However, plotting $\beta$ against $\omega$ for the same values of $M,B$ shows us that $\beta$ gives a negative value at this maximal value, which is unphsyical. So the maximal $Q$ goes with $\beta = 0$.","['calculus-of-variations', 'calculus']"
2205176,Finding the p-value in a proportion statistics with binomial distribution,"Given that the sample is 40, we observed that 80% of the sample (32 participants) have a successful trial.
We want to test the hypothesis $H_{0} = p_{0} = 0.7$ versus $H_{a} \neq 0.7$ at 5% significance level. I would to calculate the $p$-value. My attempt Let X be the distribution under the nul hypothesis, where X ~ Bin(n,$p_{0}$), i.e. $P(X=x)= \binom{n}{x}(p_{0})^{x}(1-p_{0})^{40-x}$. For values less than the observed test statistic, i.e. for $x \lt 32$: $p$-value $= 2 * P(X \leq x)$. For $x =32$: p-value = 1. For values greater than the observed test statistic i.e. for $x \gt 32$:$p$-value $= 2 * P(X \geq x)$. However, i am getting p-values greater than 1, wish is wrong. i am wondering if there is any logical error in my testing.","['statistics', 'hypothesis-testing']"
2205209,Angle Bisector of Parallel Lines,"Today I came across a question in which equations of two lines (Which were parallel) were given and it was asked to find their angle bisector. My answer for this was : Since there is no point of intersection of Parallel lines, there is no origin of angle bisector. So, answer should be Doesn't Exist , obviously. But when I checked the answer it was the line equidistant (and parallel) from both of these two i.e. if lines are $ax+by+c_1=0$ and $ax+by+c_2=0$ than angle bisector will be $ax+by+\frac{c_1+c_2}{2}=0$ I am asking this question since I feel that I am not wrong here, bisector shouldn't exist. Can someone please confirm. Someone may say this is the extension of the property of angle bisector that each point of angle bisector is equidistant from the original lines but I am asking what is defined to be angle bisector ? For example : $\binom{n}{r}=0$ when $n<r$ is an extension of property of binomial coefficients. But originally $n<r$ isn't in domain of this function.","['coordinate-systems', 'geometry']"
2205274,3 congruent shapes in a $5 \times 5$ square board,"Given a $5 \times 5$ board of $25$ cells. Is it possible to color $24$ of them in one of three colors in such a way, that the resulting three shapes of the particular colors are congruent to each other?","['combinatorics', 'coloring', 'geometry']"
2205323,To find factor of a polynomial equation,One of the factors of $4x^2+y^2+14x-7y-4xy+12$ is equal to $2x-y+4$ $2x-y-3$ $2x+y-4$ $2x-y+3$ Step $1$ : $4x^2+y^2-4xy$ can be simplified as $(2x-y)^2$ Step $2$ : $14x-7y$ can be simplified as $7(2x-y)$ and finally $(2x-y) (2x-y+7) + 12$ I can able to factor to this extent only. however can't able to arrive at the answer. The answer is given in the book. it states that $4x^2+y^2+14x-7y-4xy+12$ is product of $(2x-y+3)$ and $(2x-y+4)$ I am in need of steps,['linear-algebra']
2205348,Is every entire function is a sum of an entire function bounded on every horizontal strip and an entire function bounded on every vertical strip?,"Is it true that every entire function  is a sum of an entire function bounded on every horizontal strip (horizontal strip is a set of the form $H_y:=\{x+iy : x \in \mathbb R \}$ ) and an entire function bounded on every vertical strip (vertical strip is a set of the form $V_x:=\{x+iy:y\in \mathbb R \}$) ? I see no way of rigorously deciding it anyway. NOTE : By entire function , I mean any holomorphic function $f: \mathbb C \to \mathbb C$","['complex-analysis', 'holomorphic-functions', 'entire-functions']"
2205364,Finding the value of trignometric series $\Sigma^{\infty}_{0}\dfrac{\cos nx}{3^n}$,"$Q. $ It is being given that $\cos x\in(0,\frac{\pi}{2})$ and $\cos(x) = \frac{1}{3}$ we need to find
$$\Sigma^{\infty}_{0}\dfrac{\cos nx}{3^n}$$ I tried writing some terms, and then multiplying by three and subtracting original from it , but that took me nowhere! Then I tried using expansions of $\cos(nx)$ but realised this wasn't needed here and made it more unsolvable. I also wanted to know if there was a more general method to geometric-trigonometric series like these","['summation', 'trigonometry', 'sequences-and-series', 'trigonometric-series']"
2205379,Can it be proven/disproven that there are highly composite numbers that prime-factorize into larger primes such as $9999991$?,"Of course, following the rules found by Ramanujan, such a highly composite number would need to factorize into all primes ascending up to 9999991 (with descending powers as the primes progress) so the highly composite number would be insanely large. However a highly composite number needs more factors than all other numbers before it, so surely any number with very large prime factors like 9999991 is automatically at a disadvantage? So is there a limit to the size of the largest prime factor of a highly composite number, or is it limitless? Is there even a way to know?","['number-theory', 'prime-factorization', 'prime-numbers']"
2205384,Convergence in Probability of Random Variables -- But what Probability Measure?,"When people use the concept of convergence in probability they often just write down e.g. $X\rightarrow^p0$ to denote that $X$ converges in probability to $0$. But from what I know about convergence in probability, the concept(/definition) relies on a probability measure $\mu$: Definition. Let $(\Omega, \mathcal F, \mu)$ be a probability space and let $f,f_n:\Omega\longrightarrow W$ be measruable functions for every $n\in\mathbb N$. We say that $f_n$ converges in probability to $f$ if for every real $\epsilon>0$ and real $\delta>0$ there exists a $N\in\mathbb N$ such that for every $n\in\mathbb N$ that satisfies $n\geq N$ it holds that $$\mu\Bigg(\bigg\{\omega\in\Omega:\Vert f_n(\omega) - f(\omega)\Vert\geq\delta\bigg\}\Bigg)<\epsilon.$$ $\\$ In the example below, I have problems to find the associated measure to apply convergence in probability. Example. Let $(\Omega^n,\mathcal B_{\Omega^n}, P_\theta^n)$ be a probability space where $\Omega\subseteq\mathbb R^n$ and $\mathcal B_{\Omega^n}$ is (canonical) Borel $\sigma$-algebra. Note that the probability measure $P_\theta^n$ depends on a parameter $\theta\in\Theta\subset\mathbb R^k$. Let $(\Theta,\mathcal B_\Theta)$ be measruable space and $\tau_n:\Omega^n\longrightarrow\Theta$ a measurable function. $\\$
I am now concerned with the following equestions: Convergence in probability of $\tau_n$ to some constant $\vartheta\in\Theta$ (""Consistency of the estimator $\tau$"") Convergence in probability of $f_n(\theta)$ to some real constant where $f_n(\theta)$ denotes the Radon-Nikodym derivative (assuming that $P_\theta^n$ is differentiable of course). My thoughts so far (assuming the preceeding is correct): Since $\tau_n$ is measurable, probabilities are well defined. But what is the probability measure? Is it the pushforward measure $P_\theta^n\circ\tau_n^{-1}$? That seems wrong though as the measure itself depends on $n$ (or does this not matter for convergence in probability?) Again, due to the measurability of $f_n$ (Radon-Nikodym-derivative is measurable by definition) probabilities are well-defined. The corresponding measure space is the non-negative reals equipped with the associated Borel $\sigma$-algebra. But what is the measure used to proof convergence in probability? The pushforward measure?","['probability-theory', 'convergence-divergence', 'probability-distributions']"
2205390,There exists $v_0 \in V$ such that $\forall v \in V \space\space T(v)=\lambda v+ \alpha(v) v_0$,"Let $V$ be a vector space and $\lambda$ a constant real number. Suppose that $T: V \to V$ is a linear map and $\alpha: V \to \mathbb R$ is a linear functional on $V$. Suppose that for every $v \in Ker(\alpha)$ we have $T(v)=\lambda v$. Prove that:   There exists $v_0 \in V$ such that  $\forall v \in V
 \space\space T(v)=\lambda v+ \alpha(v) v_0$ I'm completely blind! I don't know where to start! The question says if $v \in Ker(\alpha)$, $T(v)=\lambda v$. So, If $\alpha(v)=0$,  then $T(v)=\lambda v$. But how is this related to the existence of $v_0$?","['linear-algebra', 'linear-transformations', 'vector-spaces']"
2205435,Solving $\lim_{ x \to 0^+} \sqrt{\tan x}^{\sqrt{x}}$,"The limit to be calculated is: $$\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ I tried: $$L =\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ $$\log L = \lim _{x\to 0^+} \ \ \dfrac{1}{2}\cdot\dfrac{\sqrt{x}}{\frac{1}{\log(\tan x)}}$$ To apply the L'hospital theorem but failed, as it went more complex. How can we solve this, with or without L'Hospital?","['indeterminate-forms', 'calculus', 'limits']"
2205447,Inequality in the proof of unique solution of an ODE,"I'm studying a proof from a unique solution theorem of an ODE where I encountered an inequality. I don't know if this is applied Gronwall, unfortunately I can't see it. So $y'(s)=f(t,y(s))$ and $f$ is a continuous and Lipschitz $$\|f(t,y)-f(t,z)\|\leq L\|y-z\|
$$
  And we definie this norm $\|y\|_{C^0}=\max (e^{-2(s-t_0)}\|y(s)\|)$ Then this inequality occurs $$\int_{t_0}^t L\|y(s)-z(s)\|\mathrm{d}s\leq \left(\int_{t_0}^t Le^{2L(s-t_0)}\mathrm{d}s \right)\|y-z\|_{C^0}$$ Is this Gronwall? It confuses me that there is an integral on the LHS.
I computed RHS of the integral but I'm not seeing the inequality: $$\left(\int_{t_0}^t Le^{2L(s-t_0)}\mathrm{d}s \right)\|y-z\|_{C^0}=\frac{1}{2} \left(e^{2 L (t - t_0)} - 1\right)\max (e^{-2(s-t_0)}\|y(s)-z(s)\|)$$","['real-analysis', 'inequality', 'ordinary-differential-equations', 'calculus']"
2205474,Determining the image of a map,"Let $\mathbb{P}^1(\mathbb{C})\times \mathbb{P}^1(\mathbb{C})\rightarrow \mathbb{P}^3(\mathbb{C})$, $[a:b],[c:d]\mapsto[ac:ad:bc:bd]=[z_0:z_1:z_2:z_3]$. How to show that $Z_0=Z(z_0z_3-z_1z_2)$ is a subset of the image of this map? I take a point $[z_0:z_1:z_2:z_3]\in Z_0$ and I need to find its preimage. I tried to consider two cases: $z_0=0$ and $z_0\ne 0$. The former yields $5$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(0, \ne 0, \ne 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, \ne 0)$ $(z_1,z_2,z_3)=(0,0,\ne 0)$ And the latter yields $4$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0,0$ $(z_1,z_2,z_3)=(0,0,0)$ $(z_1,z_2,z_3)=(\ne 0, \ne 0, \ne 0)$ I concentrate on the first $5$ subcases. I managed to find preimages for cases $1$ and $3$ (they are respectively $[z_0:z_2],[1:0]$ and $[1:0],[z_0:z_1]$), but I don't know how to proceed because for example in case $2$ I need to find a preimage of $[z_0:0:z_2:z_3]$ with $z_i\ne 0$, but I think this is impossible.","['algebraic-geometry', 'projective-space', 'projective-geometry', 'functions']"
2205547,Did computers render useless the teaching of approximating the Binomial with Poisson and Normal distribution?,"When considering a binomial distribution with large $n$, it is (was?) usefull to use the Poisson or Normal distribution instead. One of the reason being the difficuty to compute the binomial coefficient for large $n$. Computers have since grown in performance and algorithms in efficiency. Is it still worth teaching students about approximating $B(n;p)$ with $Po(np)$ for small values of $np$ (or small values of $n(1-p)$) and with $N(np;np(1-p))$ otherwise? An ideal answer would include reference (personal or theoretical) to what is actually done in practice and to the applications of such approximations in undergraduate or graduate courses.","['computational-mathematics', 'probability', 'approximation', 'probability-distributions']"
2205573,Curve fitting on dataset,"For my master's thesis I'm writing on a specific subject which requires curve fitting. In the first part I fixed everything with 12th degree polynomial fits. But when I derive the data from the place measures, to get the speeds, I get a curve which is hard to fit. The curve looks like a sinewave, but they go much more pointy on the minimas. Does anyone have any idea about what a good polynomial or other function would be for this kind of curves? My Curve I have tried this already with 12th degree polynomial and with some sorts of sine wave. But maybe it might be a good idea to combine a sine wave and a triangle wave? EDIT: as people are advising me to get into sine waves, the reason why I don't do this is because I need to fit a lot of datasets which are completely different to this dataset. I made another screenshot to show that sine waves are not a real option for me. This dataset would be way harder with a sine wave","['algebraic-curves', 'statistics', 'data-analysis', 'curves']"
2205577,Find residue at poles of $\frac{1}{z\sin z}$,"$$f(z)=\dfrac{1}{z\sin z}$$ At poles, the denominator is $0$, so the poles are $z=0$ and points where $\sin z=0$ i.e. $z=n\pi$ Now, to find residue at $z=0$,
I take the series expansion of $sinz$ and proceed as follows: $$f(z)=\dfrac{1}{z\sin z}= \dfrac{1}{z(z-\frac{z^3}{3!}+\frac{z^5}{5!}+\cdots)} = \dfrac{1}{z^2(1-\frac{z^2}{3!}+\frac{z^4}{5!}+\cdots)}
= \dfrac {[1-(\frac{z^2}{3!}+\frac{z^4}{5!}+\cdots)]^{-1}}{z^2}$$ Expanding the numerator by binomial theorem and simplifying, we get: $$\dfrac{1}{z^2}+\dfrac{1}{3!}-\dfrac{z^2}{5!}+\cdots$$ Hence we see the coefficient of $z^{-1}$ is $0$ and so the residue at $z=0$ is $0$. Is this approach correct? If yes, how do I find residue at $z=n\pi$? I do not need the complete working out, I just need hints. Thanks!","['complex-analysis', 'residue-calculus', 'proof-verification']"
2205612,Surface area of a sphere with integration of disks [duplicate],"This question already has answers here : Areas versus volumes of revolution: why does the area require approximation by a cone? (4 answers) Closed 4 years ago . Why it is not correct to say that the surface area of a sphere is: $$
2 \int_{0}^{R} 2\pi r \text{ } dr
$$ In my mind we are summing up the perimeters of disks from $r=0$ to $r=R$, so by 1 integration, we would have $\frac{1}{2}$ of the surface area of the sphere. I know that it's not correct because that will give us $2\pi R^2$ that it's different from $4\pi R^2$, but why??? Thanks!","['spheres', 'integration', 'definite-integrals', 'geometry']"
2205618,"Proving that $\mathbb{Z}_m\oplus \mathbb{Z}_n \cong \mathbb{Z}_d\oplus \mathbb{Z}_l $ as groups, where $l=\mathrm{lcm}(m,n)$ and $d=\gcd(m,n)$","How would one go about proving that $\mathbb{Z}_m\oplus \mathbb{Z}_n \cong \mathbb{Z}_d\oplus \mathbb{Z}_l $ as groups, where $l=\mathrm{lcm}(m,n)$ and $d=\gcd(m,n)$ ? I am attempting to use the fundamental theorem of finitely generated abelian groups but am struggling.
In the interest of honesty, this is a past exam question that I am attempting for which the solutions are not available. EDIT: As the question was asked in the paper, the Chinese Remainder Theorem would not be permitted since this is only proved in the follow-up course.","['abelian-groups', 'finitely-generated', 'group-theory']"
2205638,Iterated integral question,"Show $$\lim_{n \to\infty} \int_0^1 \cdots  \int_0^1  \int_0^1 \frac{ x_1^2 + \cdots +  x_n^2}{x_1 + \cdots + x_n} \, dx_1 \cdots dx_n = \frac 2 3.$$ Not sure how to start off this iterated integral question, any help would be appreciated.","['real-analysis', 'calculus', 'integration', 'probability', 'sequences-and-series']"
2205683,Find the maximum of the multivariable function,"Find the maximum of the following function:
  $$h(x, y)  =  \ln(x^{40} y^{60}) $$
  given the constraints:
  $$2x^2 + 3y^2  =  10, \quad \quad x > 0,   y > 0. $$ I know that for the first step I the $h$'s should $= 40/x , 60/y$ and the $g$'s should be $4x , 6y$. But i'm not should I should do with this information to get to the final answer. What is the final answer? It should be rounded to 5 decimal points.","['multivariable-calculus', 'calculus']"
2205722,Conditional Expectation of Gaussian Random Vector of length n,"I am trying to prove the following: Let $(X_1,\dots,X_n)$ be a Gaussian vector with mean 0 and covariance matrix B.  Find the distribution of $E(X_1\mid X_2,\dots,X_n).$ I know in general for two Gaussian r.v. $X_1$ and $X_2$ we can show that $f_{X_1|X_2} (x_1|x_2) = \frac{1}{\sigma_{X_1} \sqrt{2 \pi (1-\rho^2)}}\exp\frac{(-(x_{1}- \rho(\sigma_{X_1}/ \sigma_{X_2})x_2)^2)}{2 \sigma^{2}_{X_1}(1- \rho^{2})}$ where $\rho$ is the correlation and $E(X_{1}|X_{2})=\int x_{1} f_{X_1|X_2} (x_1|x_2)dx_{1}.  $ How can I generalize this for a gaussian random vector of size $n$?  Can I conclude on the distribution of $E(X_1|X_2,...X_n)$ based on the form of $f_{X_1|X_2,\dots,X_n} (x_1|x_2,\dots,x_n)$?  For example, in the case of 2 Gaussian r.v we produce a normal r.v with variance $2 \sigma^{2}_{X_1}(1- \rho^{2})$ and mean $\rho(\sigma_{X_1}/ \sigma_{X_2})x_2$.","['probability-theory', 'probability', 'random-variables']"
2205732,Integrating the Gaussian Curvature of the Torus on the Torus and Subsets of the Torus,"I have recently come across a problem that I think I understand but am unsure about. I have been asked to integrate the Gaussian Curvature of the Torus onto the Torus itself. The parametrization is given as:
$$T(\varphi, \theta) = ((R+r\cos(\theta))\cos(\varphi), (R+r\cos(\theta))\sin(\varphi), r\sin(\theta))$$ Now I computed the Geodesic Curvature of $\theta=\text{constant}, \varphi = \text{constant}$, which both gave $0$. I am told to integrate on three surfaces. a) The Torus b)The portion of the Torus bounded by $\theta\in[\frac{-\pi}{2}, \frac{\pi}{2}]$ c)The portion of the Torus bounded by $\varphi\in[\frac{-\pi}{2}, \frac{\pi}{2}]$ Now for a), I used the Gauss-Bonnet Theorem, assuming that $\kappa_G=0$ based on the Geodesic Curvatures giving zero. Then, I concluded: $$\int_T K\cdot dA = 2\pi\chi(T)$$ The Euler Characteristic of the Torus is $0$, thus I concluded that the integral of $K\cdot dA=0$ on the torus. Now for b) and c), would I just integrate the $K$, which is:
$$K= \frac{\cos(\theta)}{r(R+r\cos(\theta))}$$
as such? b)$$\int_0 ^{2\pi} d\varphi\int_{\frac{-\pi}{2}}^{\frac{\pi}{2}}K \sqrt{EG-F^2}d\theta = 0$$ c) $$\int_0^{2\pi} K \sqrt{EG-F^2}d\theta\int_{\frac{-\pi}{2}}^{\frac{\pi}{2}}d\varphi=0$$ I'm slightly confused as the integral gives $0$ in all three cases, I feel like I am going wrong somewhere. If someone could help it would be appreciated!","['manifolds', 'integration', 'differential-geometry', 'geodesic']"
2205742,Multiple variable differential equation,Find the general solution to the following differential equation. $\frac{dy}{dx}  =  \frac{4y}{3x}$ For this question I got the solution $y = Ce^{(4/3)^x}$ but this is some how incorrect. How? What is the right answer? Could someone show me their formatting so that I know where I went wrong?,"['multivariable-calculus', 'calculus']"
2205763,3 variable measurements of a box question,"A box is to be constructed with a total volume of 600 $cm^3$, but the sides have different costs. The top, bottom, left and right sides cost 5 dollars per $cm^2$, but the front and back cost 3 dollars per $cm^2 . What are the dimensions of the box that have the correct volume, but minimize cost? I know that this is an xyz question since the dimensions of a box means 3 dimension (height, width, & length). But I'm not sure how to go about answering this question to  find the separate costs. (x, y, z)","['multivariable-calculus', 'calculus']"
2205787,Tychonoff's Theorem and Axiom of Choice,"I know that Tychonoff's Theorem requires the Axiom of Choice, but I am struggling to see where I have used it in the proof below. I suspect it lies somewhere in the step of going from basis elements to elements of the open cover, but it seems that only finitely many choices are needed there. Let $X_i$, $i \in I$, be compact spaces. We wish to show $X:=\prod_{i \in I}X_i$ is compact. Let $\{U_j~|~j \in J\}$ be an open cover of $X$. Each $U_j$ is of the form $U_j=\cup_k U_{j,k}$ for some basis sets $U_{j,k}$. That is, each $U_{j,k}$ is of the form $\prod_{i \in I} V_i$ where $V_i$ is open in $X_i$ and $V_i=X_i$ for all but finitely many $i$. Now consider the collection of all the $U_{j,k}$'s. Choose one such $U_{j,k}=\prod_{i \in I}V_i$. Since $V_i=X_i$ for all but finitely many $i$, we just need to ""fill in"" the coordinates for which $V_i \neq X_i$. For each such coordinate $i$, the projections of the $U_{j,k}$'s onto the $i$th coordinate cover $X_i$. Since $X_i$ is compact, finitely many of the projects cover it, and from those projections we recover finitely many of the $U_{j,k}$. Note this only requires finitely many choices. We do this for finitely many coordinates and find that finitely many basis elements cover $X$. Finally, from each of these finitely many basis elements we recover a set $U_j$ from the open cover containing it. Again this only requires finitely many choices, and these $U_j$'s must cover $X$.","['general-topology', 'logic', 'axiom-of-choice']"
2205832,Consider the following relations on the set of all functions from Z to Z,"I have been struggling with this problem for a while now.  It is: Consider the following relations on the set of all functions from Z to Z. Are they equivalence relations? If so, prove this and describe the equivalence classes. In particular, define [f] where f(n) = n. If not, argue which properties they do not satisfy. 1) {(f, g) | f(1) = g(1)} 2) {(f, g) | ∃k ∈ Z, ∀x ∈ Z, f(x) + k = g(x)} I found this for part 1, but I am confused on reflexive as would I have to say that g and g are equivalent such that g(1) = g(1)? For part 2, I am looking for a nudge in the right direction to start it.  I did notice it has an offset relation such that for reflexive where k = 3 f(x) + 3 does not equal f(x) showing that it is not reflexive.","['relations', 'functions', 'discrete-mathematics']"
2205865,Some Subgroup of Dihedral Group is Normal,"I ran into this question when I was studying for my abstract algebra midterm. Show that the subgroup $H$ of rotations is normal in the dihedral group $D_n$. Find the quotient group $D_n/H$. I'm not quite sure where to begin. I know that for a Dihedral group of $n\geq 3$, then $r^n=1$ where $r$ is a rotation, and $s^2=1$ where $s$ is a reflection, and $srs=r^{-1}$. I was not sure how to prove something is a normal subgroup from here. Any advice, thanks!","['abstract-algebra', 'normal-subgroups', 'dihedral-groups', 'group-theory']"
2205883,Is the sequence defined by $a_{n+1} = \frac{1}{a_n} + 1$ convergent?,"The sequence defined by $a_1=1$ and
 $$a_{n+1} = \frac{1}{a_n} + 1$$
is increasing. And I can get the limit which is equal to $$\frac{1+\sqrt{5}}{2}$$
But $a_2 = 2$ which is larger than the limit. So is the sequence convergent or divergent?","['fibonacci-numbers', 'continued-fractions', 'sequences-and-series']"
2205908,Solving binomial theorem via induction,"I'm trying to prove binomial theorem by induction, but I'm a little stuck. I would look at online resources as this problem has been done many times, but the version I am trying to prove the binomial theorem in a different form. $$(1 + x)^n = \sum_{k = 0}^{n} \binom{n}{k} x^k$$ I'm mostly confused as to how I can make the left side be equivalent to a summation, any help is appreciated. Try to hint me along!","['induction', 'binomial-theorem', 'discrete-mathematics']"
2205915,"Are there any integer solutions to f(x) = cos(x) besides (0,1)?","I'm teaching a course that covers basic set theory and relations/functions.  We asked them to come up with a function from $\mathbf{N} \to \mathbf{N}$ that is neither one-to-one nor onto. One of my students wrote down $f(x) = \cos(x)$ as their response.  Now, most likely they simply didn't understand the question and were simply desperately grabbing for points ($f(x) = \cos(x)$ is not even a function from $\mathbf{N} \to \mathbf{N}$ because, for example, $\cos(2)$ is not in the codomain). However, it got me to thinking - are there any integers besides 0 that do have an integer image in the codomain of $f(x) = \cos(x)$?","['trigonometry', 'integers']"
2205966,Integrating a function's gradient,"Given the gradient of a function, how do you find the function itself? For a scalar-valued function $f : \mathbb{R}^n \to \mathbb{R}$, the gradient of $f$, denoted $\nabla f : \mathbb{R}^n \to \mathbb{R}^n$, is defined as $\nabla f(x)_i := \frac{\delta f(x)}{\delta x_i}, \quad i=1,\ldots,n.$ For example, for $A \in \mathbb{R}^{n \times n}$ and $b,x \in \mathbb{R}^n$, the gradient of the function $f(x) := \frac{1}{2} (Ax-b)^T(Ax-b)$ is $\nabla f(x) = (Ax-b)^T A.$ Now suppose we are told that the gradient of a scalar-valued function $g$ is $\nabla g(x) = (Ax-b)^T D$ for some diagonal matrix $D \in \mathbb{R}^{n \times n}$. Is there a nice closed-form expression for $g(x)$? These two threads ( here , here ) seem to use guess-and-check. We tried looking at function of the form $g(x) := \frac{1}{2} (Ax-b)^T W (Ax-b)$ for various weighting matrices $W$, but no dice.","['multivariable-calculus', 'linear-algebra', 'vector-analysis']"
2205980,Smooth function with infinite oscillation,"I'm curious to know if there's a function which: Has an infinite number of solutions for $f(x)=0$ on $x \in [-a,a]$ for an $a > 0$ (like $f(x) = \sin(\frac 1 x)$) Has an $n$th derivative for all $x\in[-a,a]$, for any $n$. There is no interval $[b,c]\subset[-a,a]$ ($b<c$) for which $f(x)=0$ on the whole interval Does such a function exist? If not, how could that be proven?","['derivatives', 'calculus']"
2206023,Expectation of sequences of random variables that converge to 0 in probability,"Let $X_n, n \geq 1$ be a sequence of random variables that converges to zero in probability, that is, $\forall \varepsilon >0$,
$$\lim_{n \to \infty} P(|X_n| < \varepsilon) = 1$$
Moreover, let $X_n=o_p(n^{-1})$, that is, $\forall \varepsilon >0$,
$$\lim_{n \to \infty} P\left(\left|\frac{X_n}{n^{-1}}\right| < \varepsilon\right) = 1,$$
or equivalently,
$\forall \varepsilon, \eta >0$, there exists $n_0$ such that for $n\geq n_0$,
$$P\left(\left|\frac{X_n}{n^{-1}}\right| < \varepsilon\right) \geq 1-\eta,$$ My question is, what can we say about $E(X_n)$ when $n \to \infty$? For instance, is it true that $E(X_n)=o(n^{-1})$? Or more generally, is it true that $E(o_p(n^{-1}))=o(n^{-1})$? How can I prove so?","['real-analysis', 'probability-theory', 'asymptotics', 'calculus', 'probability']"
2206046,Modeling path of a rolling ellipse,"I'm trying to solve Project Euler problem 525 . My approach is to find a parametric equation that can model the path of the center point as it rolls, then take the arc length of that function for one rotation. A rotated ellipse can be expressed with the equation: $$\frac{(x\cos\theta-y\sin\theta)^2}{a^2}+\frac{(x\sin\theta+y\cos\theta)^2}{b^2}=1$$ And in order to make this ellipse lie tangent or ""rest"" on the x axis when rotated $\theta$ degrees, there is a y shift of: $\sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. Here is a visual representation of this. Therefore the y component of my final equation will be: $y(\theta) = \sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. The x component of the equation is harder. After $\theta$ degrees of rotation, the point of the ellipse touching the x axis will have traveled a distance equal to the arc length of the ellipse from 0 to $\theta$. This can be expressed with the arc length formula using the parametric form of an ellipse: $$L(\theta) = \int_{0}^{\theta} \sqrt{y'(\theta)^2 + x'(\theta)^2} d\theta$$ This almost solves it, but there is an additional horizontal distance between the tangent point and the center point as seen in the picture below. How do I express this extra x-distance? I think it might not even require any calculus. (Note, I don't want a solution to the problem, that takes the fun out of the problem. Just some help to get through this step or a point in the right direction.)","['project-euler', 'recreational-mathematics', 'simulation', 'calculus']"
2206090,Proving that there are no other integer solutions,"The integer solutions for this equation:
$m ^ 2 = 2 \cdot 3 ^ n - 5$ 
are these four couples: $(n; m): (1;-1) (1;1) (3;7) (3;-7)$. How can I prove there are no other solutions?","['number-theory', 'diophantine-equations']"
2206111,"If $\int f \bar g \, d \mu \leq \|g\|$ for all square integrable $g$, does it follow that $f$ is square integrable?","Let $(X, \mu)$ be a measurable space. The Cauchy-Schwarz inequality tells us that if $f \in L^2(X)$, then $|\int_X f \bar g\, d\mu|$ is bounded as $g$ ranges over the elements of $L^2(X)$ with norm $1$. I was wondering if the following partial converse holds Let $f$ be a complex-valued measurable function on $X$. Suppose that for all $g \in L^2(X)$ with norm $1$, the inequality $|\int_X f \bar g \, d\mu| \leq 1$ holds. Then $f$ is square integrable. (i.e. $f \in L^2(X)$)","['functional-analysis', 'real-analysis', 'lp-spaces', 'lebesgue-integral']"
2206116,"If |A|=|B|, then $|P(A)|=|P(B)|$","If $|A|=|B|$, then $|P(A)|=|P(B)|$ This is what I have done so far: Assume $|A|=|B| \Rightarrow \exists$ a bijection $f:A \to B$ Define $F: P(A) \to P(B)$ where $ F(S)=\{f(a)| a\in S\}\subseteq B $ Claim: $F$ is injective Suppse $ F(S)=F(S') \Rightarrow s=s'$. Let $$ a \in S \Rightarrow f(a) \in F(S)=F(S') \Rightarrow f(a) \in F(S')= \{f(b)| b \in S'\}=$$ This is where I get stuck. Should I show $ \exists b \in S'$ such that $f(a)=f(b) \Rightarrow a=b$. Since $a \in S, $ then $a=b \in S' \Rightarrow a \in S'$. Does this prove that $s=s'$ ? Claim: $F$ is surjective Since $F(S) \subset B $, then $ F(S) \in P(B) $ for all $ b \in B,  \exists$ a unique $f^{-1} (b) \in A$. So $$F(\{f^{-1}(b): b \in B\})= \{f(f^{-1}(b))| b \in B\}=\{b |b \in B\}=B$$ So, $F$ is surjective. Comment: I know I probably did something wrong here. Any suggestion is appreciated. Thank you.","['proof-writing', 'proof-verification', 'discrete-mathematics']"
2206158,Finding Hessian of tr ((AB)' (AB)),"I'm trying to find Hessian of $\text{tr}((AB)' (AB))$ where $A,B$ are matrices. There are nice expressions for $H_{AA}$ and $H_{BB}$ using standard approach from Magnus 1 , can anyone suggest how to do same for $H_{AB}$ and  $H_{BA}$ ? More specifically if $A$ is 2x3 and $B$ is 3x4, then we can vectorize A,B and stack them on top of each other so that we have a function from vectors, and Hessian is a block partitioned matrix with blocks 6x6, 6x12, 12x6 and 12x12 corresponding to $H_{AA}$, $H_{AB}$, $H_{BA}$ and $H_{BB}$ Edit (after following techniques in answer, I get following) $$H_{AA}=2(BB'\otimes I_2)$$
$$H_{BB}=2(I_4 \otimes A'A)$$
$$H_{AB}=2(B\otimes A)+2 (I_3 \otimes AB)K_{3,4}$$
$$H_{BA}=2(B'A'\otimes I_3)K_{2,3}+2(B'\otimes A')$$ BTW, the Hessian looks as follows when evaluated with all values being 1. Four colors represent values 0,2,4,8 so that $H_{AB}$ consists of just 2's and 8's. Mathematica code used to generate. 1 (Theorem 1 in 10.6 of Magnus/Nuedecker Matrix Differential Calculus with Applications in Statistics ebook )","['kronecker-product', 'matrices', 'matrix-calculus', 'vectorization', 'linear-algebra']"
2206171,Zero is least element of ordinal,"Definition. An ordinal is a well-ordered set $X$ such that for all $x\in X$, $(−∞, x) = x$. Lemma. Zero is least element of ordinal. Proof. Let $\alpha$ be an ordinal. Let $x$ be least element of $\alpha$. So, $x=x\cap\alpha=\emptyset$. Thus $\emptyset$ is least element of $\alpha$, that is $0$ is least element of $\alpha$. My questions: Why $x\cap\alpha=\emptyset$?","['elementary-set-theory', 'ordinals']"
2206200,$ \lim_{h\to0} f(x+h)-f(x-h)=0$ does not imply $\lim_{h\to0} f(x+h)-f(x)=0$,"Let $f$ be defined on an open interval (a,b) and assume $x\in(a,b)$. Consider the two statements (a) $$\lim_{h\to0} f(x+h)-f(x)=0$$ (b)$$ \lim_{h\to0} f(x+h)-f(x-h)=0$$. Prove that (a) always implies (b) and give an example in which (b) holds but (a) does not . My solution :
(a) Shows that the function $f$ is continuous at $x$ . So both $$\lim_{h\to0} f(x+h)-f(x)=0$$ and $$\lim_{h\to0} f(x)-f(x-h)=0$$ exists . You add both of the limits and that proves (b) .This proves the first part of the problem . For second part: Now lets consider the function $f(x)=1$ when $x=0$ and $f(x)=0$ otherwise . For this function $\lim_{h\to 0} f(h)-f(-h)=\lim_{h\to0}0-0=0$ but $f$ is not continuous . I was also thinking about the function $f(x)=0 ,x\in\mathbb{Q}$ and $f(x)=1$ . I think this function too two satisfy the limit in (b) but not (a) as it is not a continuous . I would just like to clear out my if my thinking process about continuous function is correct or not . Thank you","['real-analysis', 'alternative-proof', 'proof-verification', 'calculus', 'analysis']"
2206252,Independent and dependent events with drawing 2 cards without replacement,"Independence and dependence with events like first card red and second card black and of course, without replacement. I believe they are dependent but have not found the best way to explain this. A few of my very bright students in discrete math believe these events are independent but I think they are dependent. Can anyone help me to give a good, concise explanation?",['discrete-mathematics']
2206266,Computing Conditional Expectation with Continuous Martingales,"I am trying to compute the following question: Let $(X_t,F_t)_{t \in \mathbb{R}}$ be a martingale with continuous realizations.  For $0 \le s \le t$ find $E(\int_{0}^{t} X_u du | F_s).$ I am confused how to compute the conditional expectation with the integral inside.","['probability-theory', 'probability', 'martingales']"
2206268,Estimating the Length of a Coin Tossing Game,"I am looking to solve the following: A person plays a coin tossing game where he receives $1$ point for every heads and $5$ points for every tails.  The game stops when he receives $1,000$ points.  Estimate within $\pm{2}$ the expectation of the length of the coin tossing game. I know this is discrete martingale problem but I'm not sure how to approach it.","['probability-theory', 'probability', 'martingales']"
2206328,Intrinsic vs. extrinsic properties of surfaces,"I'm reading about the differential geometry of surfaces in $\mathbb{R}^3$. I keep seeing statements about certain surface properties being either ""intrinsic"" or ""extrinsic"". Sometimes people say that the intrinsic properties are those that depend only on the coefficients of the first fundamental form. I don't see why you would ever make a definition like this. Why does it matter? People say that the ""intrinsic"" properties are related only to the surface itself, whereas extrinsic ones depend on how the surface is ""embedded in $\mathbb{R}^3$"". I don't understand this at all. What does ""embedded in $\mathbb{R}^3$"" mean?  If the surface isn't ""embedded in $\mathbb{R}^3$"", then where is it? Is there more than one way to embed a given surface in $\mathbb{R}^3$? I see that Gauss was very happy when he managed to prove that Gaussian curvature is an intrinsic property. Gauss was a fairly practical fellow, so I assume that this result has some practical significance. In other words, being ""intrinsic"" must be a helpful property, somehow. But how? I work with surfaces in engineering (ship hulls, turbine blades, airfoils, car bodies, etc.) so I like concrete physical explanations better than abstractions. I have read numerous texts on basic differential geometry, so repetition of the standard material probably won't help me much, unless you can throw some new light on it.","['differential-geometry', 'surfaces']"
2206350,Uniformly continuous homeomorphism onto $\mathbb{R}^n$,"Let $f:U\to\mathbb{R}^n$ be a homeomorphism from an open subset of $\mathbb{R}^n$ onto $\mathbb{R}^n$, where $f$ is also uniformly continuous. Show that $U=\mathbb{R}^n$. The solution I found here Uniformly continuous homeomorphism from open set to $\mathbb{R}^n$. but I don't understand the last part of the accepted answer: Since $f$ is uniformly continuous with image in a complete metric space, $f$ can be continuously extended $F:\overline{U}\to\mathbb{R}^n$. If $U\not=\mathbb{R}^n$, then $\overline{U}\not=U$ (otherwise, $U$ is a proper clopen subset of the connected space $\mathbb{R}^n$). Since $f$ maps $U$ onto $\mathbb{R}^n$, $F$ can't be injective, which contradicts $f$ being a homeomorphism. I'm confused about the last line. Why does this contradict $f$ being a homeomorphism. Does it have something to do with connectedness? I know $U$ and hence $\overline{U}$ must be connected, but what is the contradiction?","['general-topology', 'metric-spaces', 'proof-explanation']"
2206370,Find $\lim_{n \to \infty} \left[\frac{(n+1)^{n + 1}}{n^n} - \frac{n^{n}}{(n-1)^{n-1}} \right]$ (a question asked at trivia),"My friend's trivia league had this math question: $$\lim_{n \to \infty} \left[\frac{(n+1)^{n + 1}}{n^n} - \frac{n^{n}}{(n-1)^{n-1}} \right]$$ After computing a few values, one could guess the answer is $e$ = 2.718...But how can we prove that is the limit? Someone offered up a hand-wavy proof like this: \begin{align}
\lim_{n \to \infty} \left[\frac{(n+1)^{n + 1}}{n^n} - \frac{n^{n}}{(n-1)^{n-1}} \right] & = \lim_{n \to \infty} \left[\frac{(n+1)(n+1)^{n}}{n^n} - \frac{n \cdot n^{n-1}}{(n-1)^{n-1}} \right] \\
&= \lim_{n \to \infty} \left[(n+1)\frac{(n+1)^{n}}{n^n} - n\frac{n^{n-1}}{(n-1)^{n-1}} \right] \\
&= \lim_{n \to \infty} \left[(n+1)\left(1 + \frac{1}{n} \right)^n - n\left(\frac{n - 1 + 1}{n-1} \right)^{{n-1}} \right] \\
&= \lim_{n \to \infty} \left[(n+1)\left(1 + \frac{1}{n} \right)^n - n\left(1 + \frac{1}{n-1} \right)^{n-1} \right] \\
&= \lim_{n \to \infty} \left[(n+1)e - n \cdot e \right] \\
&= \lim_{n \to \infty} e \\
&= e
\end{align} The part about substituting $e$ is hand-wavy since technically this is an indeterminate form of $\infty - \infty$. And using $e$ as as upper bound did not lead me to an easy proof either. Is there a way to rigorously prove the limit? I tried a few approaches: (a) sandwiching the limit--I could prove $e$ was a lower bound, but I could not find a suitable upper bound converging to $e$, (b) using L'Hopital's rule with no luck, (c) using the mean value theorem--but that also got complicated. So this is a pretty tough problem to ask at trivia! Is there a way to prove this limit formally? Sources Trivia question: http://learnedleague.com/question.php?72&16&4 Thread on trivia: http://learnedleague.com/viewtopic.php?f=10&t=7961&hilit=euler Hand-wavy proof: https://i.sstatic.net/dMZzV.jpg Idea for mean value theorem: http://www.pharout.com/trickylimitproblem.pdf","['indeterminate-forms', 'limits']"
