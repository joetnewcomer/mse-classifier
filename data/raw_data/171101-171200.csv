question_id,title,body,tags
3030072,"Let $P(X_j=j)=P(X_j=-j)=1/2j^{\beta}$ and $P(X_j=0)=1-j^{-\beta}$ where $\beta\in(0,1)$, then $S_n/n^{(3-\beta)/2)}\Rightarrow c\chi$","Suppose $P(X_j=j)=P(X_j=-j)=1/2j^{\beta}$ and $P(X_j=0)=1-j^{-\beta}$ , where $\beta>0$ . Show that: (i) If $\beta>1$ then $S_n\to S_\infty$ a.s. (ii) If $\beta\in(0,1)$ then $S_n/n^{(3-\beta)/2}\Rightarrow c\chi$ . (iii) If $\beta=1$ then $S_n/n\Rightarrow\aleph$ , where $$E\exp(it\aleph)=\exp\left(-\int_0^1 x^{-1}(1-\cos(xt)\,\mathrm{d}x\right).$$ This is problem 3.4.13 in Durrett's Probability text , part (i) was rather trivial, I feel fine about that part. I am having a difficult time on part (ii) though and would like verification for part (iii). My ideas so far for part (ii) is to define the triangular array as $S_{n,m}=\dfrac{X_m}{n^{(3-\beta)/2}}$ , and then use the Lindeberg-Feller theorem, but I am getting hung up on the details. For part (iii) consider: It is a well-known theorem of Levy that if $\{X_n\}$ is a collection of random variables and $Y$ is another random variable then $X_n \Rightarrow Y$ iff $\phi_{X_n}(t) \rightarrow \phi_Y(t)$ as $n \rightarrow \infty$ and $\phi_Y$ is continuous at $t = 0$ .  Moreover, by properties of Fourier transforms, $\phi_{S_n/n}(t) = \prod\limits_{1 \leq j \leq n} \phi_{X_j/n}(t)$ . Now, $$\phi_{X_j/n}(t) = \int_{\mathbb{R}} \mathrm{d}\lambda e^{it\lambda} \mathbb{P}\left(\frac{X_j}{n} = \lambda\right) = 1-\frac{1}{j} + \frac{1}{2j}(e^{it\frac{j}{n}} + e^{-it\frac{j}{n}}) = 1-\frac{1}{j}(1-\cos(tj/n)).
$$ This is clearly real-valued and positive, so that we can write $$
\log\phi_{S_n/n}(t) = \sum_{j = 1}^n \log\left(1-\frac{1}{n}\cdot \frac{n}{j}(1-\cos(tj/n)\right),
$$ so, up to an $O(1/n)$ error term, we have $$
\log \phi_{S_n/n}(t) = \frac{1}{n}\sum_{j=1}^n \frac{n}{j}(1-\cos(tj/n)) + O\left(\frac{1}{n}\right).
$$ The sum on the right side is a Riemann sum for the exponential, so taking $n \rightarrow \infty$ , we get $\phi_{S_n/n}(t) \rightarrow E\left(e^{it\aleph}\right)$ , in our notation, the latter of which is continuous at $0$ .","['probability-limit-theorems', 'central-limit-theorem', 'probability-theory']"
3030203,"RSA: Show how to factor $n=pq$, the product of two primes, given $(p-1)(q-1)$","As an exercise in my discrete mathematics textbook, for my first-year course, the following question is asked, on the topic of RSA encryption:
Show that we can easily factor $n$ when we know that $n$ is the product of two primes, $p$ and $q$ , and we know the value of $(p-1)(q-1)$ . So far my attempted solution has been to expand $(p-1)(q-1)$ , to lay a foundation of the known value. $$(p-1)(q-1)=pq-p-q+1$$ and rewrite $$(p-1)(q-1)=pq-(p+q)+1$$ The book suggests calling $p+q=s$ and then attempting to use that to find the product $n$ , since $q=s-p$ , we can write the product as $n=p(s-p)$ . Expanding this leads to the quadratic equation $$0=p^2-ps+n$$ Using the quadratic formula to solve this leads to the following solution: $$p=\frac{s\pm\sqrt{s^2-4n}}{2}$$ As shown by @misterriemann in the comments, the discriminant can not be negative, which leaves out any complex solutions, however i am unsure how to extract $q$ from this, after being given $p$ as a function of $s$ .
Any help on this would be appreciated.","['cryptography', 'discrete-mathematics', 'prime-numbers']"
3030286,Reference for algebro-geometric definition of the $\cup$-product in (sheaf) cohomology.,"Can anyone give me a reference on how the $\cup$ -product of sheaf cohomology is defined? I read somewhere that it has to do with the Yoneda pairing of Ext, but my naive approach did not work, because $H^i(X,\mathcal{F}) \cong \text{Ext}^i(\mathcal{O}_X,\mathcal{F})$ and $H^j(X,\mathcal{G}) \cong \text{Ext}^j(\mathcal{O}_X, \mathcal{G})$ do not pair up.","['algebraic-geometry', 'homology-cohomology', 'sheaf-cohomology']"
3030327,Random time change for a Poisson process and convergence with respect to the Skorohod topology,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\left(Y^{(n)}_k\right)_{k\in\mathbb N_0}$ be a time-homogeneous Markov chain on $(\Omega,\mathcal A,\operatorname P)$ and $$X^{(n)}_t=Y^{(n)}_{\lfloor nt\rfloor}\;\;\;\text{for all }t\in[0,1]$$ $(N_t)_{t\ge0}$ be a Poisson process on $(\Omega,\mathcal A,\operatorname P)$ with intensity $1$ independent of $Y^{(n)}$ for all $n\in\mathbb N$ and $$Z^{(n)}_t:=\begin{cases}Y^{(n)}_{N_{nt}}&\text{for }t\in[0,1)\\ Z^{(n)}_{1-}\end{cases}$$ for $n\in\mathbb N$ Now, let $\tau_0:=0$ , $$\tau_k:=\inf\left\{t>\tau_{k-1}:\Delta N_t=1\right\}\;\;\;\text{for }k\in\mathbb N$$ as well as $$\tau^{(n)}_k:=\frac{\tau_k}n\;\;\;\text{for }k\in\mathbb N$$ and $$\lambda^{(n)}_t:=\sum_{k=0}^\infty 1_{\left[\frac kn,\:\frac{k+1}n\right)}(t)\left(\tau^{(n)}_k+(nt-k)\left(\tau^{(n)}_{k+1}-\tau^{(n)}_k\right)\right)\;\;\;\text{for }t\ge0$$ for $n\in\mathbb N$ . How can we show that $$\sup_{t\ge0}\left|\lambda^{(n)}_t-t\right|=\sup_{t\in[0,\:1)}\left|\frac{N_{nt}}n-t\right|\tag1$$ for all $n\in\mathbb N$ ? ( I'm unsure whether there isn't an error in the domain of one of the suprema. I could imagine that the left should be taken only over $[0,1)$ or the right actually over $[0,\infty)$ .) I've read that we obtain claim by noting that $N_{nt}=\lfloor n\frac{N_{nt}}n\rfloor$ for all $t\ge0$ and $n\in\mathbb N$ , but while that's trivially true, I don't see how we can make use of it. Moreover, I've read that the supremum is attained at one of the jump times (I guess the jump times of $X^{(n)}$ , i.e. $\frac kn$ for $k\in\mathbb N$ , are meant), but I don't know why. However, we may observe the following: Let $t\in\left[\frac kn,\frac{k+1}n\right)$ . Then, there is an $\alpha\in[0,1)$ with $$t=\frac{k+\alpha}n$$ and hence $$\lambda^{(n)}_t-t=\left(\tau^{(n)}_k-\frac kn\right)+\left(\tau^{(n)}_{k+1}-\tau^{(n)}_k\right)\alpha.\tag2$$ Since this is linear in $\alpha$ , the supremum of $(2)$ is attained for $\alpha=0$ or $\alpha=1$ . Thus, we should obtain $$\sup_{t\ge0}\left|\lambda^{(n)}_t-t\right|=\sup_{k\in\mathbb N_0}\left|\tau^{(n)}_k-\frac kn\right|=\frac1n\sup_{k\in\mathbb N_0}\left|\tau_k-k\right|\tag3.$$ Maybe we need to use $k=N_{\tau_k}$ almost surely such that $$\sup_{t\ge0}\left|\lambda^{(n)}_t-t\right|=\sup_{k\in\mathbb N_0}\left|\frac{N_{n\tau^{(n)}_k}}n-\tau^{(n)}_k\right|\tag4\;\;\;\text{almost surely}.$$ Now, clearly, $\left\{N_{n\tau^{(n)}_k(\omega)}(\omega):k\in\mathbb N_0\right\}=\left\{N_{\tau_k(\omega)}(\omega):k\in\mathbb N_0\right\}=\left\{N_t(\omega):t\ge0\right\}$ , but this still doesn't yield $(1)$ . However, it yields $$\left[\tau^{(n)}_k,\tau^{(n)}_{k+1}\right)\ni t\mapsto\frac{N_{nt}}n-t=k-t$$ which clearly attains its supremum at $t=\tau^{(n)}_k$ or $t=\tau^{(n)}_{k+1}$ . We may note that $\left(\frac{N_{nt}}n-t\right)_{t\ge0}$ is a martingale, but I'm not sure if we need this fact here.","['stochastic-analysis', 'stochastic-processes', 'poisson-process', 'skorohod-space', 'probability-theory']"
3030335,Write the algebraic closure of $F_p$ as union of finite fields,"In Field theory by Steven Roman Chapter 9 Exercise 20, if we write the algebraic closure of finite field $F_q$ as $\Gamma(q)$ and $a_n$ be any strictly increasing infinite sequence of positive integers, the exercise wants to prove that $\Gamma(q)=\bigcup_{n=0}^{\infty}GF(q^{a_n})$ . However, if $a_n$ is an arbitrary sequence, we are even unable to prove $\bigcup_{n=0}^{\infty}GF(q^{a_n})$ is a field. I wonder whether the exercise has omitted some condition since the equality doesn't hold under current conditions offered. Hope for answers!","['field-theory', 'finite-fields', 'abstract-algebra']"
3030376,"Solving the Diophantine equation $y^3 = 4x^2+4x+ 5$ for $x,y \in \mathbb{Z}$","I want to solve the Diophantine equation $y^3 = 4x^2+4x+ 5$ for $x,y \in \mathbb{Z}$ . The right hand side factors as $(2x+1-2i)(2x+1+2i)$ . 
Am I right that such a factorization can be found using the quadratic formula? Now I think that the equation can be solved by performing a descent as $\mathbb{Z}[i]$ is a UFD. But for doing that we need that the above two factors are coprime. 
Are the above two factors coprime, and how do I show that?","['gaussian-integers', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'euclidean-domain']"
3030377,Evaluating the limit using Taylor Series,"We're asked to find the following limit by using Taylor expansions $$\lim_{x\to{}0}\frac{e^{3x}-\sin(x)-\cos(x)+\ln(1-2x)}{-1+\cos(5x)}$$ My Attempt: Expressing $e^{3x}$ , $\sin(x)$ , $\cos(x)$ , $\ln(1-2x)$ and $\cos(5x)$ in their respective taylor expansions yielded the following monstrous fraction, https://i.sstatic.net/I9Qd0.jpg (Picture size too big to be uploaded here for some reason, plus fraction too large to be expressed in the space given :/) But anyways, I can't seem to factorize this thing and evaluate the limit as $x\to{}0$ , any help would be appreciated.","['limits', 'calculus', 'taylor-expansion', 'analysis']"
3030394,Triple integral of portion of cone (cylindrical polar coordinates)?,$V$ is the portion of the cone $z=\sqrt{x^2+y^2}\;$ for $\; x\geq 0.$ Find $$\iiint\limits_{V} xe^{-z} dV.$$ I am trying to solve this question.  The answer is supposed to be just $4.$ I have worked out the limits as $0\leq z \leq \infty\;$ and $\;-\pi/2\leq  \theta \leq \pi/2\;$ and $\;0\leq R \leq z.$ What am I doing wrong?,"['multivariable-calculus', 'calculus']"
3030406,Difficult variation of the committee problem,"It is a trivial exercise in the pigeonhole principle to show that if an organization contains $m$ people and forms disjoint committees of $n$ members each, then at most $$\bigg \lfloor \frac{m}{n} \bigg\rfloor$$ committees can be formed. However, I have recently attempted a seemingly simple variation on this problem: what if the committees need not be disjoint, but no two committees can share more than one member. It seems like another easy exercise in the pigeonhole principle, but I have been unable to come up with a formula for the largest possible number of committees in terms of $m$ and $n$ . Does anyone know of such a formula?","['elementary-set-theory', 'pigeonhole-principle', 'combinatorics']"
3030482,Can a degree $p^n$ field extension always be factored in a sequence of prime extensions?,"Suppose $L/K$ is a field extension of degree $p^n$ for some prime $p$ (if necessary, assume the characteristic of $K$ is not $p$ ). Then, is it always possible to find a sequence of extensions $K = K_0 \subset K_1 \subset K_2 \dots \subset K_n = L$ such that $[K_r:K_{r-1}] = p$ ? Using Galois theory, this problem translates into the following: Suppose $G$ is a finite group with a subgroup $H$ such that $[G:H] = p^n$ . Is it always possible to find a subgroup $G \supset H' \supset H$ so that $[H':H] = p$ ?","['field-theory', 'galois-theory', 'group-theory']"
3030484,"Number Theory: Prove that $\gcd(a,b) \le \sqrt{a+b}$","For positive integers $a$ and $b$ , we know $\dfrac{a+1}{b} + \dfrac{b+1}{a}$ is also
  a positive integer. Prove that $\gcd(a,b) \le \sqrt{a+b}$ . Using Bézout's lemma, we know that $\gcd(a, b) = sa + tb$ . I want to prove that $(sa+tb)^2 \le a+b$ . We know $ab\,|\,a(a+1) + b(b+1)$ . Therefore, $(sa + tb)^2 \le (sa)^2 + (tb)^2 + 2st(a(a+1)+b(b+1))$ . I'm not sure how can  continue from here. Any ideas to continue, or for a better way to prove the statement? Thanks in advance.","['elementary-number-theory', 'discrete-mathematics']"
3030505,How to determine if a set relation is Transitive?,"So, as far as binary relations go, I have a firm grasp on the symmetric, anti-symmetric, and reflexive relations. However, when it comes to transitive relations, I run into a block. In this problem, for example, I had to determine the transitive closures for the given set that contained: (1,1) (1,2) (2,3) (3,2) (4,4) The additional elements that would enable this set to be a transitive relation were: (1,3) (2,2) (3,3) I think I understand that if there is a (1,2) and a (2,3) then there must also be a (1,3). I see that there is a (2,3), but why doesn't there have to be a (3, 4) and a (2,4)? I need some enlightenment as to how I can properly go about determining transitive closures, or determining if a completed relation set includes the right elements to make it transitive.","['relations', 'discrete-mathematics']"
3030536,Show that the union of convex sets does not have to be convex.,"The following is an example that I've come up with: Suppose that $p\in A$ and $q\in B$ so that $p,q \in A\cup B$ , where $A$ and $B$ are two mutually disjoint, convex, unit circles centered at $x=0,2$ in $\mathbb{R^2}$ , respectively. Also let $p:=(\frac{1}{2},0)$ and $q:= (\frac{3}{2},0)$ . The set of points satisfying $\lambda p + (1-\lambda)q$ for $0 < \lambda < 1$ forms a line between $p$ and $q$ . But for $\lambda = \frac{1}{2}$ , we have that $z = \frac{1}{2}p + (1-\frac{1}{2})q = \frac{1}{2}(p+q)=(1,0)$ , which is not in $A\cup B$ . I was wondering if there's a simpler example that shows that the union of two convex sets does not have to be convex?","['convex-analysis', 'analysis']"
3030607,Can every connected reductive group over a char $p$ field be defined over $\mathbb F_p$?,"If I have a connected reductive group $G$ over a field with characteristic $p>0$ , can it always be defined over $\mathbb F_p$ ? For split groups like $GL_n, GSp_{2n}$ it's trivial, how about general case?","['algebraic-geometry', 'algebraic-groups']"
3030672,Find the analytical form or the order of the spectral radius (or eigenvalues) of a special sparse matrix.,"Let $\hat{\bf H}$ be a $p\hat{N}\times p \hat{N}$ sparse matrix consisting of $p\times p$ blocks, where each block is of size $\hat{N}\times\hat{N}$ . The values in $\hat{\bf H}$ is illustrated below (empty places are zero): Asking for help to find the analytic form of the spectral radius (or eigenvalues) of this matrix. If  analytic form is hard to calculate, would it be possible to at least determine the order of the spectral radius approaching 1? I did a simple numerical experiment as the following, If we fix $p = 5$ and let $\hat{N}$ go from 5 to 100, we have If we fix $\hat{N} = 10$ and let $p$ go from 5 to 100, we have","['linear-algebra', 'eigenvalues-eigenvectors']"
3030745,'selfish' set to be a set which has its own cardinality (number of elements) as an element,"Define a selfish set to be a set which has its own cardinality (number of elements) as an element. Find, with proof, the number of subsets of $\{1, 2, \ldots, n\}$ which are minimal selfish sets, that is, selfish sets none of whose proper subsets is selfish. My Attempt:
Assume $\textbf{A}$ to be a selfish set. If the cardinality of $\textbf{A}$ is $c$ , then can $\textbf{A}$ contain $1,2,3....c-1$ . Definitely answer is no. because if it contains $k<c$ then deleting $c-k$ elements except $k$ from $\textbf{A}$ gives a subset of k elements contradicting the fact that $\textbf{A}$ is minimal selfish.
Thus $\textbf{A}$ must contain elements greater than or equal to $c$ . But how do I find the minimal selfish sets with order $c$ ?","['combinatorics', 'discrete-mathematics']"
3030753,"Can a continuous real valued function, differentiable everywhere but $x_0$, be expressed as $g(x)+h(x)|x-x_0|$ for some differentiable $g$ and $h$?","Let $f:\mathbb R \rightarrow \mathbb R$ be a continuous function and $x_0 \in \mathbb R$ such that f is differentiable on both intervals $(-\infty, x_0]$ and $[x_0, +\infty)$ . Prove or disprove that there exist two functions $g, h : \mathbb R \rightarrow \mathbb R$ differentiable everywhere such that $$
f(x) = g(x) + h(x)|x - x_0|\ \ \forall x \in \mathbb R.
$$ This feels like it characterizes every non-differentiable point of a continuous function in terms of absolute values but I couldn't come up with a function to disprove nor I was able to construct $g$ and $h$ . Help and directions appreciated.","['real-analysis', 'continuity', 'calculus', 'functions', 'derivatives']"
3030779,Finding $n$ using Chebyshev’s inequality,"The height of a person is a random variable with variance $\leq 5$ square inches. According to Mr. Chebyshev, how many people do we need to sample to ensure that the sample mean is at most $1$ inch away from the distribution mean with probability $\geq 95$ %? According to Chebyshev’s inequality, $$P(|X-\mu| \leq \alpha) \geq \sigma^2/\alpha^2.$$ In my case I have $\alpha=1$ . But I am not able to understand how to apply this formula into the question.",['statistics']
3030793,"If the square of every element of a ring is in the center, must the ring be commutative?","Let $R$ be a ring with identity such that the square of any element belongs to the center of $R$ . Is it necessary true that $R$ is commutative? (I can show that for any $x,y\in R$ , $2(xy-yx) =0 $ but I cannot prove commutativity of $R$ .)","['ring-theory', 'abstract-algebra']"
3030805,"Proving $E[\max(X^2,Y^2)]\le 1+\sqrt{1-\rho^2}$","The question is Let $X$ and $Y$ be random variables with mean $0$ , and variances $1$ and correlation coefficient $\rho$ . Show that $E[\max(X^2,Y^2)]\le 1+\sqrt{1-\rho^2}$ . My attempt: $$E[\max(X^2,Y^2)]=
E\left(\frac{X^2+Y^2-|X^2-Y^2|}{2}\right)=
1-\frac{E|X^2-Y^2|}{2}$$ which is certainly lesser than the rhs. Is there anything wrong in my reasoning?","['expected-value', 'statistics', 'probability-theory', 'inequality']"
3030828,The number of non-singular $n\times n$ matrices over $\mathbb{F}_2$ with exactly $k$ non-zero entries,"Suppose $M_{n}^{k}$ is the number of regular matrices in $M_n(\mathbb{F}_2)$ , that have exactly $k$ non-zero entries. 
Is there some sort of formula to calculate $M_n^k$ ? $$(k < n\;\lor\;k > n^2 - n + 1)\overset{\text{pigeonhole principle}}\implies M_n^k = 0$$ (in $1^{\text{st}}$ case we always have at least one zero row, in $2^{\text{nd}}$ case we always have at least two identical rows). 
If $k = n$ , then all such regular matrices have to be permutation matrices. Thus $M_n^n = n!$ . 
However, I do not know, how to deal with the situation, where $n < k < n^2 - n + 1$ . Any help will be appreciated.","['finite-fields', 'matrices', 'abstract-algebra', 'linear-algebra', 'combinatorics']"
3030852,Is the two-point compactification the second-smallest compactification?,"We know that the Alexandroff one-point compactification of $\mathbb{R}$ is in a precise sense its smallest Hausdorff compactification. Is the two-point compactification of $\mathbb{R}$ , in a precise sense, the second-smallest? In other words, given the two-point compactification $(\frac{2}{\pi}\text{arctan}(x),[-1,1])$ and some other compactification $(k, \gamma \mathbb{R})$ of $\mathbb{R}$ that is not equivalent to the one-point or two-point compactification, is there a continuous map $\gamma \mathbb{R}\rightarrow [-1,1]$ making the obvious diagram commute?",['general-topology']
3030879,Graded global sections of Proj(S) for S a polynomial ring and more general,"Throughout, suppose $S$ is a graded ring which is finitely generated by $S_{1}$ and an $S_{0}$ -algebra. Let $X = \text{Proj} S$ . There is the usual associated graded module given by $$
\Gamma_{\bullet}(\mathcal{O}_{X}) = \bigoplus_{d \in \mathbb{Z}} \Gamma(X, \mathcal{O}_{X}(d)).
$$ My question is about what this graded module is in various cases. It is well known that if $S = A[x_{0}, x_{1}, \ldots , x_{r}]$ , then $\Gamma_{\bullet}(\mathcal{O}_{X}) \simeq S$ . In particular, this is true even if $A$ is not an integral domain. A standard proof of this is given in Hartshorne Proposition 5.13. I was studying the proof of this, and noticed that the crucial step in that proof is observing that $\Gamma_{\bullet}(\mathcal{O}_{X})$ can be identified with the intersection $$
\bigcap S_{x_{i}} \subseteq S_{x_{0}x_{1} \cdots x_{r}}.
$$ This observation, along with the inclusion in the above math environment, depends only on the $x_{i}$ not being zero divisors. This leads me to think that this proof admits a significant generalisation. Let $S$ be a graded ring with $S_{0} = A$ an arbitrary commutative ring with identity and suppose $S$ is finitely generated by $S_{1}$ as an $A$ -algebra. Suppose further that a family of generators $x_{0}, x_{1}, \ldots , x_{r}$ can be chosen so that none of the $x_{i}$ are zero-divisors. Is it still true that $$
\Gamma_{\bullet}(\mathcal{O}_{X}) \simeq \bigcap S_{x_{i}} \subseteq S_{x_{0}x_{1} \cdots x_{r}} ?
$$ An immediate followup question would be to ask whether the above question is even well-posed. In particular, if I chose a different family of generators $y_{0}, y_{1}, \ldots y_{q}$ , with possible algebraic dependencies, does the same fact remain? Of course one would hope so. Finally, what is the most general setting in which this holds. In particular, what adjectives do I need to add to the statement "" $S$ is a graded ring finitely generated by $S_{1}$ as an $S_{0}$ -algebra"" in order for $$
\Gamma_{\bullet}(\mathcal{O}_{X}) \simeq \bigcap S_{x_{i}} \subseteq S_{x_{0}x_{1} \cdots x_{r}}
$$ to hold?","['graded-rings', 'projective-schemes', 'algebraic-geometry', 'sheaf-theory', 'schemes']"
3030926,"Real Analysis, $\lim\limits_{n\rightarrow\infty} \int_{0}^{1} \frac{e^{-nt}-(1-t)^n}{t} dt$","I was trying to compute $\lim\limits_{n\rightarrow\infty} \int_{0}^{1} \frac{e^{-nt}-(1-t)^n}{t} dt$ using Lebesgue's dominated convergence THM, but I can't exactly figure out how to do. I mean, I managed to prove that each the integrand function $f_n(t)$ is less or equal than $g_n(t)=e^{-nt}\sqrt{n}e^\frac{1}{\sqrt{n}}\, \forall n\in\mathbb{N}$ . And since we are dealing with positive functions and $\int_{0}^{1} g_n(t)dt\leq\frac{e}{\sqrt{n}}\overset{\mathrm{n\rightarrow\infty}}{\rightarrow}0$ , I can deduce that the original limit is $0$ . Now, I was just wondering if anyone is able to show analytically that there exists a function in $\mathcal{L}^1$ which dominates all the $f_n$ in order to apply Lebesgue's dominated convergence THM. I made some attempts, but I failed. Thanks in advance,
a humble half-mathematician.","['integration', 'definite-integrals', 'real-analysis', 'limits', 'convergence-divergence']"
3030974,"Is there an outer measure on $\mathbb R$ whose only measurable sets are $\mathbb R, \emptyset$?","I.e. an outer measure $\mu^*$ on the reals such that if for some $A \subset \mathbb R$ , we have that for all $B \subset R$ $\mu^*(B) = \mu^*(B \cap A) + \mu^*(B \setminus A)$ , then $A=\mathbb R$ or $A = \emptyset$ .","['measure-theory', 'outer-measure']"
3030978,"Find largest possible domain and largest possible range of $F(x)=1+\cos2x$. Find inverse of $G(x)=x^2+2x-2, \;x \in [0,\infty)$, state it's domain.","Let $F(x)=1+\cos2x$ Find the largest possible domain and the largest possible range of $F(x)$ . $G(x)=x^2+2x-2, \;x \in [0, \infty)$ . Find the inverse function $G^{-1}(x)$ and state it's domain.","['functions', 'inverse', 'set-theory', 'inverse-function']"
3030981,"Given two equations $(xax)^3 = bx$ and $x^2a = (xa)^{-1}$ in a nonabelian group, solve for $x$.","This is for a basic non-commutative group. My steps: $(xax)^3 = bx$ $xaxxaxxax = bx$ $xax^2ax^2ax = bx$ $xax^2ax^2a = b$ $x^2a = (xax^2a)^{-1}b$ Now, substituting $x^2a$ into the second equation: $(xax^2a)^{-1}b = (xa)^{-1}$ $b = (xax^2a)(xa)^{-1} $ $b = (xax^2a)(a^{-1}x^{-1})$ $b = xax$ Now back to the first equation: $b^3 = bx$ $b^2 = x$ Apparently, this is not the correct answer according to my answer sheet. Am I making a mistake somewhere?","['group-theory', 'abstract-algebra']"
3031020,Prove that $\prod_{r=1}^m \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m}$,"Prove that $$\prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m}$$ My try: $$\prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\prod_{r=1}^m \left(\frac {e^{\frac {ir\pi}{2m+1}} -e^{\frac {-ir\pi}{2m+1}}}{2i}\right) =\frac {1}{2^mi^m}\left(\prod_{r=1}^m e^{\frac {-ir\pi}{2m+1}}\right) \prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right)$$ But I can't get a clue to tackle $$\prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right)$$ . I tried to use it's relation with roots of unity but couldn't proceed much. I also tried writing the $\sin$ using Euler's reflection formula that for $z\in (0,1)$ $$\sin (\pi z)=\frac {\pi}{\Gamma(z)\Gamma(1-z)}$$ where in our case $z=\frac {r}{2m+1}$ . But that too didn't last long. Any help is greatly appreciated. Thanks.","['gamma-function', 'calculus', 'sequences-and-series', 'trigonometry', 'complex-numbers']"
3031031,Show that $N$ is orthcenter of triangle $AYZ$,"Triangle $ABC$ has height $BE,CF$ . $M$ is the midpoint of $BC$ . $EF$ and AM intersects at point $N$ . Draw $NX\perp BC, XY\perp AB, XZ\perp AC(X\in BC, Y\in AB, Z\in AC)$ .Show that $N$ is orthcenter of triangle $AYZ$ . I can't find any lemma to solve this problem. How we draw any another geometry element to solve.Show me pls!",['geometry']
3031045,Finding the minimum value.,"I'm struck on this question, I tried hard but couldn't solve it. Question: if a quadratic equation in $x$ : $$ax^2 - bx + 5 = 0$$ does not have two distinct real roots, then find the minimum value of $5a + b$ . So far, I tried using the condition that the discriminant should be negative or zero, but couldn't proceed further. Moreover, as the given equation doesn't have two distinct roots so the graph will be either concave upwards or downwards, by double differentiation, I found that graph will be concave upwards so this equation will be positive or zero for all real $x.$ Any help will be appreciated.","['calculus', 'quadratics', 'algebra-precalculus', 'quadratic-forms']"
3031077,Picard's method does not solve first order differential equation?,"I have the following first order differential equation $$x^\prime(t)=-(x(t))^2+2x(t),\quad t\geq 0,\quad x(0)=1$$ Now I want to obtain an approximation of $x(t)$ by using Picard's method. Then the first Picard's iterates of this problem are given by: $$x_1 = x_0 + \int_0^t F(s,x_0(s))ds=1+\int_0^t -(1)^2+2ds=t+1 $$ $$x_2 = 1+ \int_0^t-(s+1)^2+2(s+1)ds=-\frac{1}{3}t^3+t+1 $$ $$x_3 = 1+ \int_0^t -(-\frac{1}{3}s^3+s+1)^2+2(-\frac{1}{3}s^3+s+1)ds=-\frac{1}{63}t^7 + \frac{2}{15}t^5 + -\frac{1}{3}t^3 + t+1 $$ This should converge to the true solution of $x(t)$ but when I derive the solution analytically i get the following: $$x^\prime(t)=-(x(t))^2+2x(t)\Longleftrightarrow \frac{x^\prime(t)}{-(x(t))^2+2x(t)}=1$$ Using the fact that: $$\frac{1}{x(2-x)}=\frac{1}{2}\left(\frac{1}{x}+\frac{1}{2-x}\right) $$ differentiating both sides then yields: $$\int_0^t\frac{x^\prime(s)}{x(s)}ds + \int_0^t \frac{x^\prime(s)}{2-x}ds = \int_0^t2ds   $$ $$\Longleftrightarrow \ln|x(t)| -\ln|2-x(t)|=2t+c_1,\quad c_1\in\mathbb{R}  $$ $$\Longleftrightarrow \frac{x(t)}{2-x(t)} = c_2e^{2t}, \quad c_2 = \pm e^{c_1}$$ $$\Longleftrightarrow x(t) = \frac{2e^{2t}}{c_3 + e^{2t}}, \quad c_3 = \frac{1}{c_2}$$ Combining this with the fact that $x(0)=1$ yields that we have $x(t)$ given by: $$x(t)=\frac{2e^{2t}}{1+e^{2t}}$$ When I plot the functions obtained by the Picard method I get a totally different result then when I plot the above given function of $x(t)$ . Why is this? Shouldn't the Picard method converge to its true solution? I also used more Iterations but both methods keep giving a different answer. Does anyone know why this is or am I doing something wrong?","['fixed-point-theorems', 'contraction-operator', 'ordinary-differential-equations', 'picard-scheme']"
3031087,How to prove that the set-theoretic difference operation $\setminus$ cannot be defined through $\cap$ and $\cup$,"How does one go about proving that the set-theoretic difference operation $\setminus$ cannot be defined through the operations $\cap$ and $\cup$ ? My thoughts: I first assumed $A$ and $B$ are two non-disjoint non-empty sets since if they are disjoint and non-empty, then we have that $A\setminus B= A =A\cap A=(A\cap B) \cup A$ . Therefore we have defined, in this case, $\setminus$ in terms of $\cap$ and $\cup$ . Next, I drew three Venn diagrams for $A\cap B $ , $A\cup B $ and $A\setminus B $ and made the observation that $A \setminus B$ involves an exclusion of a part of $A$ . When I looked at the definitions, I could see this clearer: $$A\cap B = \{x\mid (x\in A)  \land  (x\in B)\}$$ $$A\cup B = \{x\mid (x\in A)  \lor  (x\in B)\}$$ $$A\setminus B = \{x\mid (x\in A)  \land  \mathbf{(x\notin B)}\}$$ From this, I decided to conclude that since the intersection and union operations have the condition that $(x\in B)$ whereas the set difference operation requires $(x\notin B)$ , we cannot define set difference through the operations union and intersection only. This is as far as I could go. How can I prove this formally?","['elementary-set-theory', 'discrete-mathematics']"
3031091,"In mathematics, which word should I use, ""in"" or ""on"" or ""over""?",Which option should I choose? $f:\mathbb{R}^3 \to \mathbb{R}$ is a function. Then we say that $f$ is bounded ____ $\mathbb{R}^3$ . a) on; b) in;   c) over,"['terminology', 'real-analysis']"
3031093,Convergence or divergence of $ \sum_{n=1}^{\infty}\frac{\sqrt{n+2}-\sqrt{n}}{n^{3/2}} $: How to argue?,"Does the series $$
\sum_{n=1}^{\infty}\frac{\sqrt{n+2}-\sqrt{n}}{n^{3/2}}
$$ converge or diverge? My attempt was to write the series as $$
\sum_{n=1}^{\infty}\frac{\sqrt{n+2}-\sqrt{n}}{n^{3/2}}=\sum_{n=1}^{\infty}\frac{\sqrt{n+2}}{n^{3/2}}-\sum_{n=1}^{\infty}\frac{1}{n}
$$ The first series can be estimated from below by the harmonic series: $$
\sum_{n=1}^{\infty}\frac{\sqrt{n+2}}{n^{3/2}}=\sum_{n=1}^{\infty}\frac{(n+2)^{1/2}}{n^{1/2}\cdot n}\geqslant\sum_{n=1}^\infty \frac{1}{n}=\infty
$$ and hence diverges. The second series is the harmonic series and hence diverges. Now, I am not sure what the whole thing does.","['convergence-divergence', 'sequences-and-series']"
3031114,Is it true that every totally bounded set in a metric space is compact?,"Every compact set is totally bounded, but can we say that every totally bounded set is compact? I'm a beginner in metric space. My thinking is that a totally bounded set behaves like a finite set and in some sense it is small. So it is very much like a compact set. Someone please help me to clear my doubts. Thanks.","['general-topology', 'metric-spaces', 'real-analysis']"
3031147,Changing variables or coordinates?,"While posing another question I got stuck on the distinction of the following two concepts; The components of a vector is usually referred to as it's coordinates, while trying to understand what ""change of variables"" means when it comes to systems of ODE's, I saw several sourse talked about change of variables as ""a change of coordiinates"". Sure a function has a graph $(x,f(x))$ where if we do some kind of transformation we get a new graph. But this should be the same kind of coordinates as in a linear space. Is this the thing that one refers to when one says ""change of coordinates"" as in change to polar coordiantes?","['multivariable-calculus', 'analysis']"
3031150,Pair up $\{1..2n\}$ that the sums of each pair are different primes.,"Pair up $\{1..2n\}$ that the sums of each pair are different primes.
I found 9 examples: $\{(1,2)\},$ $\{(1,2),(3,4)\},$ $\{(1,2),(3,4),(5,6)\},$ $\{(1,4),(2,5),(3,8),(6,7)\},\{(2,3),(1,6),(4,7),(5,8)\},$ $\{(1,4),(2,5),(3,8),(6,7),(9,10)\},\{(2,3),(1,6),(4,7),(5,8),(9,10)\},$ $\{(1,4),(2,5),(3,8),(6,7),(9,10),(11,12)\},\{(2,3),(1,6),(4,7),(5,8),(9,10),(11,12)\}.$ Is there another example like this?","['combinatorics', 'prime-numbers']"
3031194,There are arbitrary large singular cardinals $\aleph_\alpha$ such that $\aleph_\alpha=\alpha$,"Definitions: Let $(\alpha_\xi \mid \xi < \lambda)$ be a transfinite sequence of ordinals of length $\lambda$ . We say that the sequence is increasing if $\alpha_\nu < \alpha_\mu$ whenever $\nu<\mu<\lambda$ . If $\lambda$ is a limit ordinal and if $(\alpha_\xi \mid \xi < \lambda)$ is an increasing sequence of ordinals, we define $$\alpha=\lim_{\xi \to\lambda}\alpha_\xi:=\sup\{\alpha_\xi \mid \xi <\lambda\}$$ and call $\alpha$ the limit of the increasing sequence. An infinite cardinal $\kappa$ is called singular if there exists an increasing transfinite sequence $(\alpha_\xi \mid \xi < \lambda)$ of ordinals $\alpha_\xi$ such that $\alpha_\xi < \kappa$ for all $\xi < \lambda$ $\lambda<\kappa$ $\lambda$ is a limit ordinal $\kappa=\lim_{\xi \to\lambda}\alpha_\xi$ Theorem: There are arbitrary large singular cardinals $\aleph_\alpha$ such that $\aleph_\alpha=\alpha$ . My textbook Introduction to Set Theory by Karel Hrbacek and Thomas Jech presents the proof as follows Proof : Let $\aleph_\gamma$ be an arbitrary cardinal. Consider the sequence $(\alpha_n \mid n\in\omega)$ defined recursively by $\alpha_0=\omega_\gamma$ and $\alpha_{n+1}=\omega_{\alpha_n}$ . Let $\alpha=\lim_{n\to\omega}\alpha_n$ . It is clear that the sequence $(\aleph_{\alpha_n} \mid n\in\omega)$ has limit $\aleph_\alpha$ . But then we have $$\aleph_\alpha=\lim_{n\to\omega}\aleph_{\alpha_n} = \lim_{n\to\omega}\alpha_{n+1}=\alpha$$ Since $\aleph_\alpha$ is the limit of a sequence of smaller cardinals of length $\omega$ , it is singular. I have some confusion about this proof: In the authors' definition of limit , the sequence must be increasing. But if we choose $\aleph_\gamma$ such that $\aleph_\gamma=\gamma$ , then the sequence $(\alpha_n \mid n\in\omega)$ is certainly constant and thus not increasing. How can $\alpha=\lim_{n\to\omega}\alpha_n$ be well defined? Similarly, if we choose $\aleph_\gamma$ such that $\aleph_\gamma=\gamma$ , then the sequence $(\alpha_n \mid n\in\omega)$ is certainly constant. It follows that the sequence $(\aleph_{\alpha_n} \mid n\in\omega)$ is constant and thus not increasing. How can the limit of the sequence $(\aleph_{\alpha_n} \mid n\in\omega)$ be well defined? Put the above problems aside, I assume that the limit of sequence $(\aleph_{\alpha_n} \mid n\in\omega)$ is well defined. I am unable to prove $$\alpha=\lim_{n\to\omega}\alpha_n \implies \aleph_\alpha=\lim_{n\to\omega}\aleph_{\alpha_n}$$ Please shed some lights! Thank you so much!","['elementary-set-theory', 'proof-explanation', 'ordinals', 'cardinals']"
3031280,Solve $2y''+y'=0$ using power series,"I got the answer $C_0e^{-x/2}$ by doing $$\sum_{n=1}^{\infty }\:\left(x^{n-1}\right) \left(2n\left(n+1\right)C_{n+1}\:\right)+\left(nC_n\right) = 0$$ thus giving $$C_{n+1}= -\dfrac{C_n}{2(n+1)}.$$ This leads me to the answer $y = C_0e^{-x/2}$ . However, the answer in my textbook is $C_1e^{-x/2} + C_0$ .  I've found this to be true, but still couldn't figure out a method of solving the equation so that there are two constants. Edit: what my textbook did was $$c_{n+2}= -\dfrac{1}{2(n+2)}c_{n+1}.$$ , and then  substitute $$c_{0}=C_0-2c_1$$ and $$c_1=\dfrac{-1}{2}C_1$$ into $y=c_0 +c_1 - \dfrac{1}{2*2!}c_{1} x^2. + \dfrac{1}{2^2*3!}c_{1} x^3........$ Where did the substitutions come from?","['power-series', 'ordinary-differential-equations']"
3031288,Probability on first hitting time of Brownian motion with drift,"I am struggling with the following problem: Let $B$ be a one dimensional Brownian motion and $a,b>0$ . Show that $$P[B_t=a + bt \text{ for some } t\geq 0] = e^{-2ab}.$$ The following hint is given: Consider the martingale $(X_t)_{t\geq 0} = (\exp(2bB_t -2b^2 t))_{t \geq 0}$ . I already showed that $(X_t)$ is a martingale but I do not have any idea how I can use this to prove the statement. Could somebody help me?
Thanks in advance!","['martingales', 'stopping-times', 'brownian-motion', 'probability-theory']"
3031324,Proving $\binom{n+1+m}{n+1}=\sum_{k=0}^m(k+1)\binom{n+m-k}{n}$,Use any method to prove that $$\binom{n+1+m}{n+1}=\sum_{k=0}^m(k+1)\binom{n+m-k}{n}$$ My Try: Base case: Let $m=1$ LHS $$\binom{n+1+m}{n+1}=\binom{n+2}{n+1}=(n+2)$$ RHS $$\sum_{k=0}^m(k+1)\binom{n+m-k}{n}=\binom{n+1-0}{n}+(1+1)\binom{n+1-1}{n}$$ $$=\frac{(n+1)!}{n!}+2$$ $$=(n+3)$$ If $m=2$ LHS $$\binom{n+3}{n+1}=\frac{n^2+5n+6}{2!}$$ RHS $$=\binom{n+2}{n}+2\binom{n+1}{n}+3\binom{n}{n}$$ $$=\frac{n^2+3n+2+4n+4+6}{2}=\frac{n^2+7n+12}{2}$$ Clearly $LHS\ne RHS$ If LHS and RHS are not equal then how to prove this proof? Can anyone explain how to prove this.,"['induction', 'combinatorics', 'combinatorial-proofs', 'discrete-mathematics']"
3031331,expected value of Consecutive numbers [duplicate],"This question already has answers here : Probability and expectancy problem [closed] (2 answers) Closed 5 years ago . We choose randomly a subset $\mathit S$ of size 25 from the set $\{ 1,2,...,100\}$ , what is the expected value of number of Consecutive numbers in $\mathit S$ ? Consecutive numbers in $\mathit S$ : is a pair $\{ i,i+1\}$ where i $\in$$\mathit S$ and i+1 $\in$$\mathit S$ .","['expected-value', 'probability']"
3031341,Continuity of the Euler characteristic with respect to the Hausdorff metric,"Hadwiger's theorem of integral geometry states that all continuous valuations which are invariant under rigid motions are expressible in terms of the intrinsic volumes. The continuity property means with respect to the Hausdorff distance: $$d_H(X, Y) = \max{(
\sup_{x \in X} \inf_{y \in Y} d(x,y),
\sup_{y \in Y} \inf_{x \in X} d(x,y) )}$$ where $X,Y \subseteq \mathbb{R}^n$ and $d(\cdot,\cdot)$ is the Euclidean distance metric. Now, the zero dimensional intrinsic volume is the Euler characteristic $\chi$ . I am confused by how $\chi$ is continuous with respect to the Hausdorff distance. Consider the following example: two identical balls $A,B$ having diameter $\sigma$ are separated by a distance $r$ . The Euler characteristic of their union is a valuation, i.e. $$\chi(A \cup B) = \chi(A) + \chi(B) - \chi(A \cap B)$$ And according to standard texts on integral geometry (e.g. Klain & Rota Introduction to Geometric Probability (2006)) this is continuous with respect to the distance metric above. However, explicitly the Euler characteristic is discontinuous: $$\chi(A \cup B) = \begin{cases}1 & \forall \; r < 2\sigma \\ 2 & \forall \; r > 2\sigma\end{cases}$$ whereas the Hausdorff distance between them is simply their separation $d_H(A,B)\equiv r$ . How is the Euler characteristic in my counter example continuous with respect to $d_H(A,B)$ ? Edit: It is quite rightly pointed out in the comments that Hadwiger’s theorem applies to strictly convex sets. I am in fact assuming a second extension theorem due to Groemer which generalises the result to so-called polyconvex sets, i.e. sets formed by countable union of convex sets.","['convex-geometry', 'integral-geometry', 'geometric-probability', 'differential-geometry']"
3031344,Find eigenvectors of the $(n+1) \times (n+1)$-matrix,"Find eigenvectors of the $(n+1) \times (n+1)$ -matrix: $$\left(\begin {array}{cccccccc} 0&0&0&0&0&0&-1&0\\ 0&0&0&0&0&-2&0&n\\ 0&0&0&0&-3&0&n-1&0
\\ 0&0&0&\ldots&0&n-2&0&0\\ 0&0&-(n-2)&0&\ldots&0
&0&0\\ 0&-(n-1)&0&3&0&0&0&0\\ -n&0&2&0
&0&0&0&0\\ 0&1&0&0&0&0&0&0\end {array}  \right)$$ The eigenvalues of the matrix are $ n, n-2, n-4, \ldots, -(n-2), -n$ see the question Let $e_{\lambda}$ denotes the eigenvector corresponding to the eigenvalues $\lambda$ . So far I have found $$
e_0=[a_0, a_1, \ldots, a_n], a_i=\begin{cases} 0, \text{ $i$ odd}\\ \displaystyle\binom{\frac{n}{2}}{ \frac{i}{2}}, \text{$i$ even} \end{cases}
$$ For example for $n=8$ we have $e_0=[1, 0, 4, 0, 6, 0, 4, 0, 1]$ . Also $$
e_1=[a_0, a_2, \ldots, a_n], a_i=\begin{cases} 0, \text{ $i$ even}\\ \displaystyle\binom{\frac{n-1}{2}}{ \frac{i-1}{2}}, \text{$i$ odd} \end{cases}.
$$ for example for $n=7$ we have $e_1=[0, 1, 0, 3, 0, 3, 0, 1]$ , 
and $$
e_2=[a_0, a_2, \ldots, a_n], a_i=\begin{cases} \displaystyle 
       \binom{\frac{n}{2}-1}{\frac{i}{2}-1}-\binom{\frac{n}{2}-1}{\frac{i}{2}},  i\text{ even} \\ \\
      \displaystyle 2(-1)^{i-1}\binom{\frac{n}{2}-1}{\frac{i-1}{2}} , i\text{  odd}
   \end{cases}.
$$ for example for $n=8$ we have $e_2=[-1, 2, -2, 6, 0, 6, 2, 2, 1]$ . Question: What is  an eigenvector $e_{\lambda}$ (with integer coordinates) for arbitrary $\lambda \in \{ n, n-2, n-4, \ldots, -(n-2), -n\}$ ? I hope the problem was  already solved in 19th century.","['matrices', 'linear-algebra', 'combinatorics', 'eigenvalues-eigenvectors']"
3031388,Spectrum of $l^p$ multiplication operator (Brezis 6.17),"I would just like a brief sanity check for a question in Brezis's functional analysis book so I can be sure I understand the basics of spectral theory. Take $l^p(\mathbb{R})$ , for $1\leq p \leq \infty$ . For a fixed, bounded, real sequence $\lambda_n$ define the multiplication operator $M: l^p \to l^p$ by: $$
M(x_1,x_2,x_3, \cdots ) = (\lambda_1 x_1 , \lambda_2x_2, \lambda_3x_3 ,\cdots)
$$ i.e, a pseudo-dot product type thing. The question asks me to determine the Eigenvalues of $M$ , and then the spectrum, $\sigma(M)$ . First, if we have an eigenvalue $\mu$ , we have: $$
\mu x_1 = \lambda_1 x_1
\\
\mu x_2 = \lambda_2 x_2 
\\
\mu x_3 = \lambda_3x_3
\\ 
\vdots  
$$ But $\lambda_n$ need not be a constant sequence, so this operator in general does not have an eigenvalue. For the Spectrum, we have that: $$
\sigma(M) = \{\mu \in \mathbb{R} : (M - \mu I) \text{ is not invertible}\}
$$ In general, if $M - \mu I$ has an inverse, it is reasonable to assume its action on some $y$ is given by: $$
\left(\frac{1}{\lambda_1 - \mu}y_1, \frac{1}{\lambda_2- \mu}y_2,\frac{1}{\lambda_3 - \mu}y_3 , \cdots \right)
$$ Thus, the operator is not invertible when $\mu = \lambda_k$ for some $\lambda_k$ . Thus, the spectrum is given by $\{\lambda_n : n \in \mathbb{N}\}$ .","['operator-theory', 'spectral-theory', 'functional-analysis']"
3031393,Symmetric continued fractions property where $q^2\equiv(-1)^n$ mod $p$,"Let $[a_0,a_1,a_2,\ldots,a_n,a_n,\ldots,a_2,a_1,a_0]=:\frac{p}{q}\in\mathbb{Q}$ be a symmetric continued fraction. This sequence of $a_i$ 's consists of finitely many elements because $\frac{p}{q}$ is rational. I need to prove that $q^2\equiv(-1)^r$ mod $p$ with $r$ the length of the sequence of $a_i$ 's. I'm getting pretty stuck from the beginning. There's a big chance I have to use the property $p_{n-1}q_n-p_nq_{n-1}=(-1)^n$ . I guess saying that $\frac{p_n}{q_n}=\frac{p_n}{p_{n-1}}$ would really come in hand for this would prove the statement immedeately, but I don't see/know how to prove this last equality. Any help is appreciated. Note: the $p_i$ 's and $q_i$ 's are from the continued fractions of $p$ and $q$ respectively. Try: By a lemma from my book we can use the following algorithm: $$\begin{bmatrix}
p_i&p_{i-1}\\
q_i&q_{i-1}
\end{bmatrix}
=
\begin{bmatrix}
p_{i-1}&p_{i-2}\\
q_{i-1}&q_{i-2}
\end{bmatrix}
\begin{bmatrix}
a_i&1\\
1&0
\end{bmatrix},\ \text{where }\begin{bmatrix}
p_{-1}&p_{-2}\\
q_{-1}&q_{-2}
\end{bmatrix}=I_2\ \text{and } i\geqslant0.$$ So we have the following using symmetry of the continued fractions: $$\begin{align*}q_0&=1,\\ q_1&=a_1,\\
&\vdots\\q_{n-1}&=a_{1}q_{n-2}+q_{n-3}\ (a_1=a_{n-1}),\\\ q_n&=a_0q_{n-1}+q_{n-2}.\end{align*}$$ We also have: $$\begin{align*}
p_0&=a_0,\\ p_1&=a_1p_0+1,\\
&\vdots\\p_{n-1}&=a_{1}p_{n-2}+p_{n-3}\ (a_1=a_{n-1}),\\\ p_n&=a_0p_{n-1}+p_{n-2}.
\end{align*}$$ Somehow it should now turn out to be true that $q_n=p_{n-1}$ . How to continue from here on? Please verify my answer below if you are able to.","['number-theory', 'continued-fractions', 'modular-arithmetic', 'recurrence-relations']"
3031398,Did I apply the Ceva's theorem correctly to this problem?,"I need to confirm the following solution. I'm making a mistake somewhere. But I can't find the error. I apply the trigonometric form of the Ceva's theorem: $$\frac{\sin \angle 3}{\sin \angle 4}× \frac{\sin \angle 1}{\sin \angle 2}×\frac{\sin \angle 5}{\sin \angle 6} =1$$ $$\frac{\sin \angle 3}{\sin \angle 4}=\frac {\sin \angle 2 ×\sin \angle 6}{\sin \angle 1 ×\sin \angle 5}$$ $$\angle 3+\angle 4=\phi, \angle 1=\alpha, \angle 2=\frac{180°-\phi}{2}-\alpha ,\angle 3=x, \angle 4=\phi-x , \angle 5= \frac{180°-\phi}{2}-θ, \angle 6=θ$$ $$\frac {\sin x}{\sin (\phi -x)}=\frac{\sin \beta ×\sin θ }{\sin \alpha ×\sin \gamma}$$ $$\tan x=\frac{\frac{\sin \beta ×\sin θ }{\sin \alpha ×\sin \gamma}×\sin \phi}{1+\frac{\sin \beta ×\sin θ }{\sin \alpha ×\sin \gamma}×\cos\phi}$$ $$\tan x=\frac{\sin \beta ×\sin θ×\sin \phi}{\sin \alpha × \sin \gamma+\sin \beta ×\sin θ×\cos\phi}$$ $$x= \arctan \frac{\sin \beta ×\sin θ×\sin \phi}{\sin \alpha × \sin \gamma+\sin \beta ×\sin θ×\cos\phi}$$ $$\angle OBC=\phi-\arctan \frac{\sin \beta ×\sin θ×\sin \phi}{\sin \alpha × \sin \gamma+\sin \beta ×\sin θ×\cos\phi}$$ Finally, $$\alpha=\sqrt[3]{66,666°},\beta=6,667°-\sqrt[3]{66,666°}, \gamma=6,667°-\arctan 0,10666, θ=\arctan 0,10666$$ MathLab says that, $x≈4,345102733435...°, \angle OBC= \phi-x≈166,666°-4,345102733435...°=161,654897266...°$ But, this answer creates a contradiction in my solution https://math.stackexchange.com/a/3026556/548054 Where is the error in my solution? Please show me where I made a mistake. Unfortunately, I can not see. Thank you.","['contest-math', 'euclidean-geometry', 'proof-verification', 'triangles', 'trigonometry']"
3031456,Limit of the composistion of two functions when the limit of $f$ does not exist?,"The theorem about the limit of composition of two real functions $f$ and $g$ is proved here . But it is required that the two limits (of $f$ and $g$ ) both exist. I can't understand how to deal with the case in which the limit of $f$ does not exists. In particular I would like to know if the following is correct. Consider $f(x)$ and $g(x)$ (real functions). If I find out that $\lim_{x \to x_0} f(x)$ does not exists, can I conclude that $\lim_{x\to x_0 }g(f(x))$ does not exist? Under what conditions is this correct?","['limits', 'calculus', 'function-and-relation-composition']"
3031500,Prove the identity $\sum_{k=0}^{n}\sum_{r=0}^{k} \binom{k}{r} \binom{n}{k} = 3^n$,"Prove the identity $\sum_{k=0}^{n}\sum_{r=0}^{k} \binom{k}{r} \binom{n}{k} = 3^n$ . I believe I need to use the binomial theorem here, but I don't know how to deal with the double summations.","['summation', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3031503,Proof verification for $\lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty$,"Show that: $$
\lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty
$$ I've tried the following way. Consider the following sum: $$
\sqrt n + \sqrt{n-1} + \dots + \sqrt{n-\frac{n}{2}} + \dots + \sqrt{2} + 1
$$ Now if we take only $n\over 2$ terms of the sum we obtain that: $$
\sqrt n + \sqrt{n-1} + \dots > {n \over 2} \sqrt{n\over 2}
$$ Let: $$
x_n = {1 \over n}(1 + \sqrt{2} + \dots + \sqrt{n}),\ \ n\in \Bbb N
$$ Using the above we have that: $$
x_n > {1\over n} {n\over 2}\sqrt{n\over 2} = {1\over 2}
\sqrt{n \over 2}
$$ Now taking the limit for RHS its obvious that: $$\lim_{n\to\infty}{1\over2}\sqrt{n\over2} = +\infty
$$ Which implies: $$
\lim_{n\to \infty}x_n = + \infty
$$ Have I done it the right way? Also i would appreciate alternative ways of showing  that limit. Thanks!","['limits', 'calculus', 'proof-verification', 'sequences-and-series']"
3031546,Using Wallis' product to derive $\sqrt\pi$,"Recall Wallis' product: $$\lim_{n\to\infty}\Big(\frac{2}{1}\cdot\frac{2}{3}\cdot\frac{4}{3}\cdot\frac{4}{5}\cdot\frac{6}{5}\cdots\frac{2n}{2n-1}\cdot\frac{2n}{2n+1}\Big)=\frac{\pi}{2}$$ We have to show that $$\lim_{n\to\infty}\frac{(n!)^22^{2n}}{(2n)!\sqrt n}=\sqrt\pi$$ The hint I got was to use $$P_n=\frac{(n!)^42^{4n}}{[(2n)!]^2(2n+1)}$$ which is just simply the inside of the limit in Wallis' product, multiplied and divided by $2\cdot2\cdot4\cdot4\cdots(2n)\cdot(2n)$ alternatively. How do I use $P_n$ to derive $\sqrt\pi\:$ ?","['analysis', 'sequences-and-series']"
3031556,Why do we use $Df$ rather than $f'$ for the derivative of a multivariable function?,Is there any reason we use $Df$ for derivatives of multivariable functions but $f'$ derivatives of single variable functions despite having a definition that works for both: $$Df(c) = f'(c) = L \iff \lim_{x \to c} \frac{f(x) - f(c) - L(x-c)}{||x-c||} = 0$$,"['notation', 'math-history', 'derivatives']"
3031612,Sizes of a pair of sequences with identical sums of pairs,"I am currently collecting various problems for an exam for my students. While looking through old homework assignments of my colleagues I came upon the following problem (marked as difficult): Given two sequences of natural numbers $\{a_k\}$ and $\{b_k\}$ , $k=1,\ldots,n$ (with non-identical sets of elements) such that the sets of their pairwise sums $$\{a_1+a_2,a_1 + a_3,\ldots, a_{n-1}+a_n\}$$ and $$\{b_1+b_2,b_1 + b_3,\ldots, b_{n-1}+b_n\}$$ coincide, show that $n=2^m,\ m\in\mathbb{N}.$ Of course, I am not going to assign a problem I couldn't solve myself to the students, but I would like to see a solution to this. This problem was accompanied with the following tip: ""Use the fact that if for two polynomials $F(x)$ and $G(x)$ if $F(1)=G(1)$ , then $F(x)-G(x)=(x-1)^kH(x)$ , where $H(1)\neq 0$ "".","['combinatorics', 'discrete-mathematics']"
3031628,Solving a linear system of differential equations,"Given that $v_1 = \begin{bmatrix}1&1\end{bmatrix}$ and $v_2 = \begin{bmatrix}2 &1\end{bmatrix}$ are eigenvectors of the matrix $$
\begin{bmatrix}-1&-2\\1&-4\end{bmatrix}
$$ which is a $2\times 2$ matrix. Find the solution to the linear system of differential equations \begin{align*}
x' &= -x - 2y\\
y' &= x - 4y
\end{align*} satisfying the initial conditions $x(0)=7$ and $y(0)=5$ . So I already found the eigenvalues, $-3$ and $-2$ and I know that you need to plug the eigenvalues into the matrix you get from doing $\det(It - A)$ but I'm not sure where to go from there in terms of making it into an equation?","['linear-algebra', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
3031671,Is the function measurable with respect to Lebesgue measure,"Let $h: [a,b]\rightarrow \mathbb{R}$ be a continuous function. For every $y\in \mathbb{R}$ , denote $$
S(y)=\begin{cases} 0 & \text{, if } h^{-1}(y) = \emptyset \\
\# h^{-1}(y) &\text{, if } h^{-1}(y) \text{ is finite}\\
\infty, &\text{, if } h^{-1}(y) \text{ is infinite}    
\end{cases}
$$ Is the function measurable (as a function from $\mathbb{R} \mapsto \mathbb{R}$ ) with respect to the Lebesgue measure in $\mathbb{R}$ ?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3031674,How to calculate the indefinite integral of $(x-1)^{\frac 12}-(x-3)$?,Why is the following integral wrong? $$ \int[(x-1)^{\frac 12}-(x-3)]dx=\frac 23 (x-1)^{\frac32}-\frac12(x-3)^2+c $$ The answer given by my textbook is: $$ \int[(x-1)^{\frac 12}-(x-3)]dx=\frac 23 (x-1)^{\frac32}-\frac12x^2+3x+c $$ I understand why the textbook's answer is right. But I don't understand what I did wrong in mine.,"['integration', 'indefinite-integrals', 'calculus']"
3031713,"Uniform Law of Large Numbers - questions on supremum, infimum, and weak vs almost sure continuity","I am currently reading up on uniform convergence in probability and I have been trying to familiarize myself with the uniform law of large numbers. As I am not a mathematician or statistician by education, however, I found myself struggling with a few aspects of that proof. I'll try to be concise. However, I will gladly give a bit more context, if that helps. Consider a probability space $(\Omega,\mathcal{F},\mathbb{P}_{\theta_0})$ and a sequence of random variables $X_j:\Omega\to\mathbb{R}$ . The assumptions for the following are: a) $\quad$ The parameter space $\Theta$ is compact b) $\quad g(X,\theta)$ is continuous at each $\theta\in\Theta$ with probability one c) $\quad g(X,\theta)$ is dominated by a function G(X) such that $|g(X,\theta)|\leq G(X)$ d) $\quad E[G(X)]<\infty$ Question 1 Am I supposed to read assumption b) as $\mathbb{P}(\theta\mapsto g(X,\theta)\,\text{is continuous}$ ) $=1$ or as $\mathbb{P}(\theta\mapsto g(X,\theta)\,\text{is continuous at }\theta^*$ ) $ = 1$$\quad\forall\quad\theta^*\in\Theta$ ? If that is not clear from the way assumption b) is formulated, I can give a instance of where it is used. I do understand that the first would imply the latter, I'd just like to know whether the latter would suffice. More importantly: Question 2 Somewhere, in the middle of the proof, it is stated that $$\max_{k\in K}\sup_{\theta\in\Theta}\left[n^{-1}\sum_{j=1}^ng(X_j,\theta)-\text{E}\big[g(X_j,\theta)\big] \right]\leq\max_{k\in K}\left[n^{-1}\sum_{j=1}^n\sup_{\theta\in\Theta_k}g(X_j,\theta)-\text{E}\big[\inf_{\theta\in\Theta_k} g(X_j,\theta)\big] \right]$$ While it seems viscerally plausible to me, in the sense that I know that $$\sup_x\,\sum\,f_j\,(x)\leq\sum\sup_xf_j\,(x)$$ and since it would make sense that for every $\theta$ $$\text{E}\big[ g(X_j,\theta)\big]\geq\text{E}\big[\inf_{\theta_*} g(X_j,\theta_*)\big],$$ I am afraid that I don't see how this inequality is established - in particular why does the infimum appear and how does it move into the expectations operator. I would very much appreciate to see some sort of step-by-step line of reasoning as to why that is true. Question 3 I might be at a loss there, but how do I see that for any arbitrary $\varepsilon>0$ $$o_p-\varepsilon\leq\inf_{\theta\in\Theta}\left[n^{-1}\sum_{j=1}^ng(X_j,\theta)-\text{E}\big[g(X_j,\theta)\big] \right]\leq\sup_{\theta\in\Theta}\left[n^{-1}\sum_{j=1}^ng(X_j,\theta)-\text{E}\big[g(X_j,\theta)\big] \right]\leq o_p(1)+\varepsilon$$ implies that $$\sup_{\theta\in\Theta}\left|\,n^{-1}\sum_{j=1}^ng(X_j,\theta)-\text{E}\big[g(X_j,\theta)\big]\, \right|\,\overset{p}{\longrightarrow}0.$$ Thank you very much for your help. Best, Jon","['measure-theory', 'supremum-and-infimum', 'probability-theory', 'uniform-convergence']"
3031753,"If $\phi$ is a characteristic function, then $1-|\phi(2t)|\leq 8\{1-|\phi(t)|\}$","Question If $\phi$ is a characteristic function, show that $\text{Re}\{1-\phi(t)\}\geq \frac{1}{4}\text{Re}(1-\phi(2t))$ and deduce that $1-|\phi(2t)|\leq 8\{1-|\phi(t)|\}$ . My attempt I have managed to show the first part, but unable to deduce the second part. Here is a proof of the first part. It is immediate that $\text{Re}\{1-\phi(t)\}=E(1-\cos tX)$ and $\text{Re}(1-\phi(2t))=E(1-\cos 2tX)$ , but then $$
4E(1-\cos tX)-E(1-\cos2tX)=2E(1-\cos tX)^2\geq 0
$$ from which the first claim follows. My problem I have not been able to use the first part to deduce the second claim. I tried squaring and both sides and using the fact that $|\text{Re}\; z|\leq |z|$ (so in particular $1-|\phi(2t)|\leq 1-|\text{Re}\;\phi(2t)|$ ) but did not get too far. Any help is appreciated.","['characteristic-functions', 'probability-theory', 'probability', 'real-analysis']"
3031786,Order of $\operatorname{Gal}(K_s/K_\ell)$,"I am reading the proof of Grothendieck’s proposition about $\ell$ -adic representations of the decomposition group of some discretely valued field, the proposition in the appendix of Serre and Tate’s Good Reduction of Abelian Varieties , and have a question. The setting is that $K$ is a field complete with respect to a discrete valuation, and $K_\ell$ is the $\ell$ -part of the maximal tamely ramified  extension of $K_{nr},$ which itself is the maximal nonramified extension of $K$ ; i.e. $K_\ell$ is generated over $K_{nr}$ by the $\ell^{n\text{th}}$ roots of a uniformizer ( $\ell$ is a prime distinct from $p$ , the characteristic of the residue field — $p$ may be $0$ ). The proof goes on to say that one sees easily that, if $L$ is a finite extension of $K_\ell$ , every element of $L$ is an $\ell^{\text{th}}$ power, hence the order of $\operatorname{Gal}(K_s/K_\ell)$ is prime to $\ell$ . In other words, there is no finite Galois extension of $K_\ell$ of order divisible by $\ell$ . I don’t understand this reasoning. My understanding of the situation is that $\operatorname{Gal}(K_s/K_\ell)$ is an extension of a group isomorphic to $$\prod_{q\text{ prime}\ne p,\ell}\mathbf{Z}_q$$ by a pro- $p$ group (where $p$ is the characteristic of the residue field).
This should imply that no element of a finite quotient of $\operatorname{Gal}(K_s/K_\ell)$ has order divisible by $\ell$ , and in turn this can be used to see that every element of $L$ as above is an $\ell^\text{th}$ power. Can someone explain to me the reasoning in the original proof?","['galois-theory', 'algebraic-number-theory', 'algebraic-geometry']"
3031809,"How many words of length $n$ over the alphabet $\{0,1, 2\}$ contain an even number of zeros?","How many words of length $n$ over the alphabet $\{0,1, 2\}$ contain an even number of zeros? I can't understand why it isn't $3^{n-1} \cdot 2$ . For $n-1$ letters, we have $3$ options. That means $3^{n-1}$ . And then for the last letter ( $n$ ), we have two cases: first - if there were odd zeros the last letter will be $0$ ( $1$ option) second - if there were even zeros, the last letter will be $1$ or $2$ ( $2$ options) means $3^{n-1} \cdot 2$ Why am I wrong? THX","['combinatorics', 'discrete-mathematics']"
3031916,"Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a measurable function, is $f \circ \sin$ measurable?","If $f \circ \sin$ is measurable, then we need to show that $(f \circ \sin)^{-1}(B) = \sin^{-1}(f^{-1}(B))$ is measurable for every Borel set $B$ , it is sufficient to show that $\sin^{-1}$ takes a Lebesgue set into a Lebesgue set. We have also tried to work with the fact that $\arcsin$ is locally Lipschitz, so if this property is sufficient to show that the image of a Lebesgue set is Lebesgue, then $\sin^{-1}(f^{-1}(B)) = \cup_{n \in \mathbb{Z}} \arcsin(f^{-1}(B)) + 2n\pi $ would measurable. It could happen that $f\circ \sin$ is not measurable, but the task of finding a set $B$ such that $\sin^{-1}(f^{-1}(B))$ is not measurable seems very difficult (maybe impossible?).","['measure-theory', 'lebesgue-measure']"
3031937,Can an uncountable group have a countable number of subgroups?,"Can an uncountable group have only a countable number of subgroups? Please give examples if any exist! Edit: I want a group having uncountable cardinality but having a countable number of subgroups. By countable number of subgroups, I mean the collection of all subgroups of a group is countable.","['group-theory', 'infinite-groups', 'examples-counterexamples']"
3031944,Holomorphic function on an annulus,Let $f$ be a holomorphic function on the set $U=\{z \in \mathbb{C}: 1 \leq |z| \leq \pi \}$ . Assume that $max_{|z|=1}|f(z)| \leq 1$ and $max_{|z|=\pi}|f(z)| \leq \pi^{\pi}$ . How to prove that $max_{|z|=e}|f(z)| \leq e^{\pi}$ ? Usually in such exercises one considers $g(z)$ of the form $\alpha z^nf(z)$ where $\alpha$ and $n$ are such that our assumptions on $f$ gives $|g(z)| \leq 1$ on both circles being the boundary of $U$ . However it is not guarantedd that $n$ would be integer thus in general we don't get a holomorphic function $g$ for which we could apply the maximum principle. If $n$ happens to be rational one can overcome this difficulty by considering $(\alpha z^n f(z))^q$ where $n=\frac{p}{q}$ . However in our example $n$ turns out to be $\pi$ and by considering $g(z)=f(z)/z^{\pi}$ we don't get holomorphic function. How to handle this case?,"['complex-analysis', 'optimization', 'holomorphic-functions', 'maximum-principle']"
3031948,Calculate path length of solution to differential equation,"Suppose I have a parameterized path $\gamma:[0,\infty)\rightarrow\mathbb C$ with initial condition $\gamma(0)=1$ and which satisfies the following: $$\gamma'(t)=u\Big(i\gamma(t)-\gamma(t)\Big)=\exp\Big(\frac{3\pi}{4}i\Big)\frac{\gamma(t)}{|\gamma(t)|}$$ where $u:\mathbb C^*\rightarrow\mathbb D$ denotes the unit vector function. In other words, $\gamma(t)$ is always moving at constant unit speed towards its rotation in the plane by $\pi/2$ . I found computationally that $$\lim_{t\rightarrow\infty}\gamma(t)=0$$ Questions: Is there a formula for $\gamma(t)$ ? Does $\gamma$ reach the origin in finite time? In other words, does there exist $T<\infty$ such that $\lim_{t\rightarrow T}\gamma(t)=0$ ? Edit: Originally we had $\gamma'(t)=s(i-1)\frac{\gamma(y)}{|\gamma(t)|}$ but without loss of generality set $s=1/\sqrt{2}$ so that $\gamma'(t)$ has unit magnitude. Also I realize that the path length $\int_0^\infty|\gamma'(t)|dt$ must be infinite since $|\gamma'(t)|$ is constant.",['ordinary-differential-equations']
3032003,Did I just discover this integration formula?,"One night, I discovered an integration relationship. That relationship allows to quickly integrate squares of functions (and even more, but I will talk about this at the end). I was wondering if anyone has found a formula like this before. So I researched on the internet, but couldn't find anything like this. The formula: $$\int f(x)^2\,dx\;=\;xf(x)^2\;-\;2f(x)\cdot F^{-1}_{(1)}(f(x))\;+\;2\,\cdot F^{-1}_{(2)}(f(x))\;+\;C$$ Where $F^{-1}_{(n)}$ denotes the $n$ th anti -derivative of the inverse function of $f$ . The formula looks rather complicated, but it's really not, on further inspection. Note: the formula doesn't work on the function $f(x)=x$ for a reason that I wasn't able to determine yet. Edit: it actually works. An example in action: Let's compute $\int \ln^2x\,dx$ . We have then: $f(x)=\ln x$ $f^{-1}(x)=e^x$ $F^{-1}_{(1)}(x)=e^x$ $F^{-1}_{(2)}(x)=e^x$ Applying the formula, the integral becomes: $$\int\ln^2x\,dx=x\ln^2x-2\ln x\cdot e^{\ln x}+2\cdot e^{\ln x}+C$$ $$=x\ln^2x-2x\ln x+2x+C$$ Derivation (for the curious): I derived this formula by substituting for inverse functions and doing repeated integration by parts. First, substitute $x=f^{-1}(u)$ . Then, we have $dx=df^{-1}(u)$ . This changes the original integral to: $$\int f(x)^2\,dx=\int f(f^{-1}(u))^2\,df^{-1}(u)=\int u^2\,df^{-1}(u)$$ At this point, I did integration by parts (probably the funkiest integration by parts you have ever seen). Note, that I am using the ""DI table"" trick for integration by parts, where in one column, derivatives of one function are specified, and integrals of another are put into the other column. Terms are multiplied diagonally left-down. $$\begin{array}{ l | c | r }
\pm & D & I \\
\hline
+ & u^2 & df^{-1}(u) \\
- & 2u & f^{-1}(u) \\
+ & 2 & F^{-1}_{(1)}(u) \\
- & 0 & F^{-1}_{(2)}(u) \\
\end{array}$$ $$\int u^2\,df^{-1}(u)\;=\;u^2f^{-1}(u)-2uF^{-1}_{(1)}(u)+2F^{-1}_{(2)}(u)+C$$ Now, simply subsitute back $u=f(x)$ and we arrive at the formula. Generalization to composition of functions: It didn't take long for me to realize that this method can be extended to compositions of functions. Just for the curious folks, this is my integral of composition formula: $$\int f(g(x))\,dx\;=\;\sum^{\infty}_{k=0}(-1)^k\cdot D_k(g(x))\cdot A_k(g(x)) + C$$ Where $D_k={d^k f\over dx^k}$ and $A_k={d^{-k}g^{-1}\over dx^{-k}}$ . Interesting, isn't it? Back to the question: Have I discovered this formula? If I didn't can someone point me to a further reading on this topic? I really can't find anything myself, probably because I don't know how to search.","['integration', 'calculus']"
3032007,"""line at infinity"" in projective plane","(""Algebraic Geometry: A Problem Solving Approach"" by Thomas Garrity) I am struggling with Exercise 1.4.12.1 in the above, which I quote with some context: Here is my intuitive thinking: (a) lines in $\mathbb{C}^3$ with some elevation from the x-y plane (ie where $z \neq 0$ ) are reduced to a single point, where that point is the intersection of the line with the plane $z =1$ . This point is unique (which is why $\phi$ in 1.4.9 is a bijection), and it is labelled $(x:y:1)$ (b) the lines in the x-y plane in 1.4.11/1.4.12 do not hit $z=1$ . Those lines are of the form $( x,\frac{-ax-c}{b},0 )$ , or alternatively $( bx,-ax-c,0 )$ But then : I do not understand why under $\phi$ these lines are assigned the point stated in 1.4.12.1 even so, why are such points necessarily distinct from those assigned to lines for the prior case, where $z \neq 0$ ? EDIT #1: I add the rest of the exercise (ie 1.14.12.3)  to show the conclusion reached by the author. Personally, I feel able to reach that conclusion directly from my (b) above:","['algebraic-geometry', 'projective-geometry', 'projective-space']"
3032030,When Should I Use Taylor Series for Limits?,"I get confused between when to apply L'Hospital Rule and Taylor Series. Is there any set of trigger points in the questions, that would be easier to solve with Taylor Series? For Example, If the denominator is in terms of a large power of $x (>3)$ , then L'Hospital Rule usually becomes complicated and is not advised. Edit:
Solve $\lim _{x\to 0}\left(\left(\sin x\right)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin x}\right)$ The options given are: $0, 1, -1, \infty$","['limits', 'calculus', 'limits-without-lhopital', 'taylor-expansion']"
3032040,What is uniqueness quantification?,"Can someone explain the concept of Uniqueness quantification ∃! in an easily understandable way since I can't understand the definition of it, what's special about it with other logical operators like and, or, not? *","['definition', 'logic', 'discrete-mathematics']"
3032117,"Integral Closure, Galois extension,and Dedekind Domain","Let $A$ : Dedekind domain, $K$ : $\operatorname{Frac}(A)$ , $B$ : Dedekind domain with $A \subset B$ , $L$ : $\operatorname{Frac}(B)$ Let $L/K$ : galois extension with galois group: $G$ . $B^G=\{b \in B \mid \sigma(b)=b \text{ for all } \sigma \in G\}=A$ $\implies B$ is the integral closure of $A$ in $L$ Is this true?
I already prove the converse, but not sure if this holds.
Thank you in advance.","['number-theory', 'field-theory', 'galois-theory', 'ring-theory', 'abstract-algebra']"
3032238,Determine if this specific sequence is a Cauchy sequence,"I have the following sequence: $$a_n =\sum_{k = 1}^n (-1)^{b_k} {1\over k^2}  $$ And the hint is that I have to prove that: $$ {1\over k^2}  < {1\over k-1} - {1\over k}  $$ So assuming $m>n$ , I have to prove that: $$\forall \epsilon >0,  \exists N \in \mathbb{N},$$ so that $$  \forall m,n > N \Rightarrow \lvert a_m - a_n\rvert < \epsilon $$ What I gathered so far: $ \lvert a_m - a_n\rvert = \lvert \sum_{k = n+1}^m (-1)^{b_k} {1\over k^2}\rvert $ $b_k$ is a sequence of natural numbers ${1,2,3.....}$ , so in absolute value, $(-1)^{b_k} $ is $1$ .
Therefore: $ \lvert a_m - a_n\rvert = \lvert \sum_{k = n+1}^m (-1)^{b_k} {1\over k^2}\rvert \leq \sum_{k = n+1}^m {1\over k^2}. $ From here on, its not so clear to me as to how to proceed.
What should be my next steps?","['limits', 'calculus', 'cauchy-sequences', 'sequences-and-series']"
3032251,Intuition on Stokes's Theorem,"Stokes's Theorem says that $$\int_C\vec{F} \cdot d\vec{r} = \int
\int_S (curl \space\vec{F}) \space\cdot \vec{n} \space dS$$ I understand that $curl \space\vec{F}$ is the ""spin"" or ""circulation"" on a given surface. I also understand that the integral is essentially a summation of a quantity. However, why is $curl \space \vec{F}$ dotted with $\vec{n}$ ? Setting aside the fact that integrals require scalar functions (i.e. a dot with some vector is necessary), the dot product says that vector $\vec{a} \cdot \vec{b} = 0$ if $\vec{a}$ and $\vec{b}$ are orthogonal. If you visualize some surface $S$ with a curl vector $\vec{a}$ , assuming it is measuring the circulation of particles actually on the surface, and a normal vector $\vec{b}$ , dotting $\vec{a}$ and $\vec{b}$ would yield $0$ , or, in other words, not the circulation. What am I missing? Thanks.","['vectors', 'vector-fields', 'multivariable-calculus', 'stokes-theorem', 'intuition']"
3032271,"Riesz representation theorem for $C([0,1])$","I’m trying to prove the special case of Riesz representation theorem:
Every positive (non-negative on non-negative functions) linear continuous functional $\phi$ on the normed space $C([0,1])$ is given by some measure $\mu$ by the rule: $\phi\left(f\right)=\int_{\left[0,1\right]}fd\mu$ I want to do it with using measure extension theorem:
First I need to build $\mu$ on elementary sets. But I don't know what it should be like.
Can you help me with this? (for open interval, for example)","['measure-theory', 'stieltjes-integral', 'riesz-representation-theorem', 'real-analysis', 'functional-analysis']"
3032301,Sequence such that every subsequence can have a different real limit [duplicate],This question already has answers here : Give an example of a sequence of real numbers with subsequences converging to every real number (3 answers) Closed 5 years ago . I would like to find a sequence of real numbers $(a_n)_{n\in\mathbb{N}}$ with this property: for any $L\in\mathbb{R}$ there is a subsequence $a_{k_n}$ such that $$\lim_{n\to\infty} a_{k_n} = L$$ Does such a sequence exist?,"['limits', 'analysis', 'sequences-and-series']"
3032310,$\lim \int_1^2 \ln^n x dx$,"a) show that $\lim \int_1^2 \ln^n x dx$ goes to $0$ as $n$ goes to $\infty$ b) show that $\lim \int_2^3 \ln^n x dx$ goes to $\infty$ as $n$ goes to $\infty$ a) on $1<x<2$ , $\ln(x) < 1$ , so $ln^n(x)$ goes to $0$ b) on $2<x<e$ ; $\ln(x) < 1$ but in $e\le x \le 3$ , $\ln (x) \ge 1$ so $\lim \int_2^3 \ln^n x dx = \lim (\int_2^e \ln^n x dx + \int_e^3 \ln^n x dx)$ $|\int_2^e \ln^n x dx + \int_e^3 \ln^n x dx|\le |\int_2^e \ln^n x dx| + |\int_e^3 \ln^n x dx|$ Now the problem for me is that  for all $\epsilon > 0$ $|\int_2^e \ln^n x dx| < \epsilon$ , and for all $M > 0$ , $|\int_e^3 \ln^n x dx| > M$ . What should I do next? (Computing integrals is not allowed)","['integration', 'limits']"
3032321,Solve recurrence for strings that do not contain the substring 101,"Let's say $A_n$ is the number of binary string that has length $n$ and does not contain the substring 101. Calculate $A_n$ for $n=1,2\cdots8.$ Find a recurrence relation for $A_n$ . What does the solution of that recurrence look like? These are the solutions that I have found for calculations for $A_n$ . $1, 4, 7, 12, 20, 32, 48, 96$ . I've calculated this by hand. But how I do find the recurrence? I see that 4, 7, 12, 30 are Fibonacci - 1, but not after or before that. But I'm not sure how to do this or if this is even correct.","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
3032326,Sard's theorem for orientation preserving diffeomorphism of the circle,"thanks in advance for helping me. First I'll introduce some definitions: (1) Suppose that $f : \mathbb{S}^{1} \rightarrow \mathbb{S}^{1} = \mathbb{R} / \mathbb{Z}$ is an orientation preserving diffeomorphism of the circle. Then $f$ may be lifted to a homeomorphism $F:\mathbb{R} \rightarrow \mathbb{R}$ of the real line, satistying $$F(x+m)=F(x)+m.$$ The rotation number $\rho(f)$ of $f$ is defined as the fractional part of $$\rho_{0}(f) = \lim_{n\to\infty} \frac{F^{n}(x)}{n}.$$ That is, $\rho(f)$ is in the unique number in $[0,1)$ for which $\rho_{0}(f)-\rho(f)$ is an integer. The rotational number exists (proved by Poincaré) and is independent of the starting point $x$ . (2) An orientation of a smooth m-dimensional manifold $M$ is a choice of orientation on every tangent space $T_{x}M$ satisfying the condition: for each $x \in M$ there is a neighborhood $U \subset M$ and an orientation-preserving diffeomorphism (i.e. a coordinate system) $h$ from $U$ to an open set in $\mathbb{R}^{n}$ (3) Let $f$ and $g$ be two k-times differentiable functions from $\mathbb{R} $ to $\mathbb{R}$ . The $C^{1}$ -distance between $f$ and $g$ is given by $$d_{1}(f,g)=\sup_{x\in \mathbb{R}}(|f(x)-g(x)|,|f^{(1)}(x)-g^{(1)}(x)|).$$ Now, my question: how to prove the following proposition using Sard's theorem? Suppose $f$ is an orientation-preserving diffeomorphism of the circle with $\rho(f) = 0$ . Then there is a $C^{1}$ (meaning continuously differentiable) diffeomorphism $g$ which is arbitrarily close to $f$ with respect to the $C^{1}$ -distance and which has only isolated fixed points.","['chaos-theory', 'differential-geometry', 'orientation', 'differential-topology', 'rotations']"
3032369,Estimate of a weak solution in a nonhomogeneous equation,"$\textbf{Problem}$ Let $\Omega \subset \mathbb{R}^n$ be open, bounded and connected with $\partial \Omega\in C^1$ . For each $i,j=1,\cdots,n$ , assume that $a_{ij},b_i,c \in L^{\infty}(\Omega)$ (real valued function) , and assume that there exists a constant $\mu \in (0,1)$ satisfying \begin{align*}
\mu \vert \xi \vert^2\leq \sum_{i,j=1}^n a_{ij}\xi_i\xi_j \leq \frac{1}{\mu} \vert \xi \vert ^2 \; \textrm{a.e. in } \Omega, \; \textrm{ for all } \xi\in \mathbb{R^n}
\end{align*} Define \begin{align*}
Lu:=-\sum_{i,j=1}^n\partial_{j}(a_{ij}\partial_iu)+\sum_{i=1}^nb_i \partial_iu+cu
\end{align*} For given functions $f\in L^2(\Omega)$ and $g\in H^{1}(\Omega)$ , suppose that $u \in H^1(\Omega)$ is a weak solution to the following boundary value problem \begin{align*}
\begin{cases}
Lu=f & \textrm{ in } \Omega \\
u=g & \textrm{ on } \partial \Omega
\end{cases}
\end{align*} If the homogeneous boundary value problem \begin{align*}
\begin{cases}
Lu=0 & \textrm{ in } \Omega \\
u=0 & \textrm{ on } \partial \Omega
\end{cases}
\end{align*} has only trivial weak solution, then prove that there exists a constant $C>0$ (independent of $u,f$ and $g$ ) so that \begin{align*}
\Vert u \Vert_{H^1(\Omega)} \leq C(\Vert f \Vert_{L^2(\Omega)}+\Vert g \Vert_{H^1(\Omega)})
\end{align*} $\textbf{Attempt}$ Take $w:=u-g $ . Then, $w$ satisfies the following boundary value problem \begin{align*}
\begin{cases}
Lw=f-Lg & \textrm{ in } \Omega \\
w=0 & \textrm{ on } \partial \Omega
\end{cases}
\end{align*} We get $w \in H^1_0(\Omega)$ . Also, \begin{align*}
\Vert u \Vert _{H^1(\Omega)} &= \Vert w+g \Vert_{H^1(\Omega)}\\ 
&\leq \Vert w \Vert_{H^1(\Omega)} + \Vert g \Vert_{H^1(\Omega)}\\
\end{align*} ( $\textbf{Update}$ ) We remain that $\Vert w \Vert_{H^1(\Omega)}$ is bounded by $\Vert f \Vert _{L^2(\Omega)}$ and $ \Vert g \Vert_{H^1(\Omega)}$ . Define a bilinear map $B[\cdot,\cdot]$ from $H^1(\Omega)$ to $H^1(\Omega)$ by \begin{align*}
B[w,v]:= \int_{\Omega} \sum_{i,j=1}^n a_{ij} \partial_i w \partial_j v +(\sum_{i=1}^n b_i\partial_i w + cw) v \; dx 
\end{align*} Then, we easily check that \begin{align*}
B[w,w]=\int_{\Omega} fw \; dx -\int_{\Omega} \sum_{i,j=1}^n a_{ij} \partial_i g \partial_j w +(\sum_{i=1}^n b_i\partial_i g +cg)w \; dx
\end{align*} $\textbf{Note}$ We have the following properties: \begin{align*}
&(1) \; \beta \Vert w \Vert_{H^1(\Omega)}^2 \leq B[w,w]+\gamma \Vert w \Vert _{L^2(\Omega)}^2 \; \textrm{for some constants }\beta>0, \gamma\geq 0 \\
&(2) \; \Vert w \Vert_{L^2(\Omega)}\leq C_p \Vert Dw \Vert_{L^2(\Omega)} \; \textrm{(Poincare's inequality)}\\
&(3) \; \Vert w \Vert_{L^2(\Omega)} \leq \Vert w \Vert_{H^1(\Omega)},\; \Vert Dw \Vert _{L^2(\Omega)} \leq \Vert w \Vert_{H^1(\Omega)} \\
&(4) \; ab\leq \epsilon a^2 +\frac{b^2}{4\epsilon} \; (a,b>0, \epsilon>0) \; \textrm{(Cauchy's inequality with }\epsilon)
\end{align*} By using the properties and Holder's inequality, I induced \begin{align*}
\beta \Vert w \Vert_{H^1(\Omega)}^2 \leq \Vert f \Vert_{L^2(\Omega)} \Vert w \Vert _{L^2(\Omega)} +C_1\Vert g \Vert_{H^1(\Omega)}\Vert Dw \Vert_{L^2(\Omega)} +C_2 \Vert g \Vert _{H^1(\Omega)} \Vert w\Vert_{L^2(\Omega)} +\gamma \Vert w \Vert _{L^2(\Omega)}^2  
\end{align*} However, I stuck $\Vert w \Vert_{H^1(\Omega)}$ is bounded by $\Vert f \Vert_{L^2(\Omega)}$ and $\Vert g \Vert_{H^1(\Omega)}$ because of the last term $\Vert w \Vert_{L^2(\Omega)}^2$ Any help is appreciated... Thank you!","['elliptic-equations', 'analysis', 'sobolev-spaces', 'partial-differential-equations', 'boundary-value-problem']"
3032466,Looking for another way to calculate the integral $\iint_{D}{\sin(x)e^{\sin(x)\sin(y)}}\text{d}A$,"Here, I have a little unpleasant way to calculate the following double integral $$\iint_{D}{\sin(x)e^{\sin(x)\sin(y)}}\text{d}A$$ where $D$ is the square area $D=\{(x,y)\in\mathbb{R}^2: 0 \le x \le \pi/2, 0 \le y \le \pi/2\}$ my attempt: with the symmetry of the area we know $$I=\iint_{D}{\sin(x)e^{\sin(x)\sin(y)}}\text{d}A=\iint_{D}{\sin(y)e^{\sin(x)\sin(y)}}\text{d}A$$ thus $$I=\frac1{2}\iint_{D}{(\sin(x)+\sin(y))e^{\sin(x)\sin(y)}}\text{d}A$$ with the substitution $u=\sin(x)$ and $v=\sin(y)$ , we have $$I=\frac1{2}\iint_{D^{*}}{\frac{u+v}{\sqrt{(1-u^2)(1-v^2)}}e^{uv}}\text{d}A$$ and now the integral area is $D^{*}=\{(u,v)\in\mathbb{R}^2: 0 \le u \le 1, 0 \le v \le 1\}$ notice that the function $\frac{u+v}{\sqrt{(1-u^2)(1-v^2)}}e^{uv}$ also holds a symmetric form, thus $$I=\iint_{D^{*}\cap(u\le v)}{\frac{u+v}{\sqrt{(1-u^2)(1-v^2)}}e^{uv}}\text{d}A=\iint_{D^{*}\cap(u\ge v)}{\frac{u+v}{\sqrt{(1-u^2)(1-v^2)}}e^{uv}}\text{d}A$$ so I can only foucs on area $D^{*}\cap(u\ge v)$ , set another substitution $$u+v=\alpha$$ $$uv=\beta$$ under the condition $u\ge v$ , the determinant of Jacobian matrix writes $$|J(\alpha,\beta)|=\frac1{\sqrt{\alpha^2-4\beta}}$$ and $$\frac1{\sqrt{(1-u^2)(1-v^2)}}=\frac1{\sqrt{(1+\beta)^2-\alpha^2}}$$ the integral area change to $\{(\alpha,\beta)\in\mathbb{R}^2: 2\sqrt{\beta} \le \alpha \le 1+\beta, 0 \le \beta \le 1\}$ , so $$\begin{align}
I&=\int_{0}^{1}\int_{2\sqrt{\beta}}^{1+\beta}{\frac{\alpha}{\sqrt{((1+\beta)^2-\alpha^2)(\alpha^2-4\beta)}}e^{\beta}}\text{d}\alpha \text{d}\beta
\\&=\int_{0}^{1}\left(-\tan^{-1}\sqrt{\frac{(1+\beta)^2-\alpha^2}{\alpha^2-4\beta}}\right)\biggr|_{\alpha=2\sqrt{\beta}}^{1+\beta} e^{\beta}\text{d}\beta
\\&=\frac{\pi}{2}(e-1)
\end{align}$$ obviously, I choose an inconvenient way in the second half of this calculation, but I still can not come up with another good method. thanks in advance for any suggestion!","['multivariable-calculus', 'calculus']"
3032487,Show some theorem concerning of the uniform convergence on compacts of a sequence of polynomials of order $<k$,"Let $k,s\in \mathbb N$ , let $x_0,x_1,...,x_s$ be given pairweise different real numbers, let $m_0,m_1,...,m_s$ be given nonnegative integers such that $\sum_{i=0}^s m_i=k$ , and let $$
P_n(x)=a_{n0}+a_{n1}x+...+a_{n,k-1}x^{k-1} (\textrm{ for } n\in \mathbb N, x\in \mathbb R)
$$ be a sequence of real polynomials of order $\leq k-1$ . Assume that there exist limits of derivatives: $$
\lim_{n\rightarrow \infty} P_n^{(j)}(x_0) (\textrm{ for } j=0,1,...,m_0);
$$ $$
\lim_{n\rightarrow \infty} P_n^{(j)}(x_1) (\textrm{ for }   j=0,1,...,m_1);
$$ ........................... $$
\lim_{n\rightarrow \infty} P_n^{(j)}(x_s) (\textrm{ for }  j=0,1,...,m_s).
$$ I wish to know that $P_n(x)$ is uniformly convergent on compact intervals. It would be sufficient to show that there exist limits: $$
\lim_{n\rightarrow \infty} a_{nj}       (\textrm{ for } j=0,...,k-1).
$$ Maybe proof or references. Thanks.","['uniform-convergence', 'convergence-divergence', 'polynomials', 'analysis']"
3032519,Take the derivative of a product of sequence,"How to take the derivative of $\prod_{i=1}^{n}(1-e^{-\lambda _{i}\cdot x})I(x>0)$ with regard to x? Here $F(X)=\prod_{i=1}^{n}(1-e^{-\lambda _{i}\cdot x})I(x>0)$ is a CDF, and I want to take the derivative of it and get the pdf of X. I try to take the log of F(X), so $\frac{d}{d x}logF(x)=\frac{d logF(x)}{d F(x)}\cdot \frac{d F(x)}{d x}$ , @Ankit Kumar help me with: $$\frac{d(logF(x))}{dx}=\sum_{i=1}^n\frac{d(log(1-e^{-\lambda_ix}))}{dx}$$ ,
then $$\frac{1}{F(x)}\frac{d(F(x))}{dx}=\sum_{i=1}^n\frac{1}{\log(1-e^{-\lambda_ix})}{\lambda_ie^{-\lambda_ix}}$$ , but I don't know how to move on with $\frac{d(F(x))}{dx}=\sum_{i=1}^n\frac{1}{\log(1-e^{-\lambda_ix})}{\lambda_ie^{-\lambda_ix}}\cdot \prod_{i=1}^{n}(1-e^{-\lambda _{i}\cdot x})$ , how to simplify it? since it is a multiplication of a sum of sequence and a product of sequence.","['calculus', 'derivatives', 'probability']"
3032553,"How many non-negative solutions for $x_{1} + x_{2} + x_{3} + x_{4} = 40$ where $2 \leq x_{1} \leq 8, x_{2} \leq 4, x_{3} \geq 4, x_{4} \leq 5$?","My solution: We have: $x_{1} + x_{2} + x_{3} + x_{4} = 40$ where $2 \leq x_{1} \leq 8, x_{2} \leq 4, x_{3} \geq 4, x_{4} \leq 5$ $\Leftrightarrow  x_{2} + x_{3} + x_{4} = 40 - x_{1} \quad (*)$ Consider: $x_{2} + x_{3} + x_{4} = 40 - x_{1}$ where $x_{2} \geq 0, x_{3} \geq 4, x_{4} \geq 0 \quad (**)$ $x_{2} + x_{3} + x_{4} = 40 - x_{1}$ where $x_{2} \geq 5, x_{3} \geq 4, x_{4} \geq 6 \quad (***)$ Let $f$ is the function that compute the number of non-negative solutions of an equation. $\implies f(*) = f(**) - f(***)$ Thus, the number of non-negative solutions of (*) is $\sum_{x_{1} = 2}^{8}( {40 - x_{1} + 3 - 1  \choose 3 - 1} - {25-x_{1}+3 - 1 \choose 3 - 1}) = 3045$ I found that the right answer is 210 by trying some programming script. But I don't know what was wrong with my solution. Please help me. Thank you!",['combinatorics']
3032622,When change of variable makes an empty interval,"Please consider the following case: $$I = \int^1_{-1}x^2dx$$ $$u(x) = x^2 \rightarrow du = 2x\,dx$$ $$u(-1) = 1, u(1) = 1$$ So $$I = \int^1_1\frac{u}{2\sqrt u} du = 0$$ Obviously the problem here is to only consider the positive root of u. I don't know how to consider both roots. This example is trivial but I have another example where such substitution would be really helpful: $$I = \int^1_{-1}\frac{x^2(1 - x^2)^\frac{3}{2}}{3} - \frac{x^2(1 - x^2)^\frac{5}{2}}{5} - \frac{x^4(1 - x^2)^\frac{3}{2}}{3} dx$$ I don't want you to solve it for me using another method, I know how to use an integral solver online. My question is how to properly do the change of variable.","['integration', 'change-of-variable', 'definite-integrals']"
3032636,Question involving Characteristic Functions and the Existence of a Distribution,"Question Is it possible for $X$ , $Y$ and $Z$ to have the same distribution and satisfy $X=U(Y+Z)$ where $U$ is uniform on $[0,1]$ and $Y$ , $Z$ are independent of $U$ and of one another? The above question is from Grimmett and Stirzaker. My attempt We translate the condition into characteristic functions. Let $\phi(t)=Ee^{it X}$ be the characteristic function of $X$ . Then $$
\phi(t)=Ee^{itUY}Ee^{itUZ}=(Ee^{itUX})^2=\left[\int_0^1 \int e^{itux}\,dF(x)\, du\right]^2=\left[\int_0^1 \phi(tu)\, du\right]^2 
$$ using the independence and equality of distribution assumptions. We can write the above equation as $$
\phi (t)=\frac{1}{t^2}\left[\int_0^t \phi(y)\, dy\right]^2 
$$ but I am not sure where to proceed from here. I guess we have to solve a differential equation. Put $\Phi(t)=\int_0^t \phi(y)\, dy$ . Then we have that $$
\Phi'(t)=\frac{1}{t^2}\Phi(t)^2
$$ but I am unable to solve this differential equation. Any help is appreciated.","['characteristic-functions', 'probability-theory', 'probability', 'real-analysis']"
3032776,Finding a limit involving roots without derivatives,"I need to find the following limit $$
\lim_{x\to-1}\frac{1+x^{1/7}}{1+x^{1/5}}
$$ using no derivatives. I've tried attempting to rationalize or divide by certain polynomials, but nothing has worked. It's simple using L'Hopital's rule, but that involves derivatives. (I'm also wondering if the technique used to evaluate that limit could be extended to $$
\lim_{x\to-1}\frac{1+x^{1/m}}{1+x^{1/n}} = \frac{n}{m} \qquad m,n\text{ odd}
$$ but that's not the main question.)","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
3032808,$\text{SL}_2(\mathbb Z)$ acts on upper plane $\mathbb H$. What kind of points have non-trivial stabilizer? And how many orbits are there?,"$\text{SL}_2(\mathbb Z)$ acts on upper plane $\mathbb H= \{z \in \mathbb{C} | \Im(z) > 0 \}$ via Mobius transformation. $$
    \text{ For } \gamma =\begin{bmatrix} 
    a &b \\c&d \end{bmatrix} \in\text{SL}_2(\mathbb Z), \ \gamma z =\begin{bmatrix} 
    a &b \\c&d \end{bmatrix}\cdot z = \frac{az +b}{cz+d}   $$ Stabilizer of $z$ means set $\{\gamma \in \text{SL}_2(\Bbb Z), \gamma z=z\}$ . I want to know what kind of points have non-trivial stabilizer and the number of orbits. My effort:
For $z \in \Bbb H$ , suppose $z = x + i y$ . $\text{For } \gamma =\begin{bmatrix} a &b \\c&d \end{bmatrix}, \gamma z =\frac{az+b}{cz+d}=z\iff az+b=cz^2+dz$ $$\iff ax+ayi+b = cx^2-cy^2+2cxyi + dx +dyi$$ $$\iff ay=2cxy+dy\ \&\  ax+b=cx^2-cy^2+dx$$ $$\iff a=2cx+d \ \&\  ax+b=cx^2-cy^2+dx$$ $$\implies b=-c(x^2+y^2),\ \gamma =\begin{bmatrix} 2cx+d &-c(x^2+y^2) \\c&d \end{bmatrix}.$$ $$\gamma \in \text{SL}_2(\Bbb Z),\ (2cx+d)\times d-(-c(x^2+y^2))\times c=1 $$ $$\implies (cx+d)^2+(cy)^2=1.$$ Then how to proceed? Thanks in advance. I haven't learnt modular form yet, and I don't know if these help: Good description of orbits of upper half plane under $SL_2 (Z)$ Orbit of complex unit $i$ under moebius tranformation in $SL_2(\mathbb{Z})$ Edit: GTM $105$ , Serge Lang, SL $_2(\mathbb R)$ might help. Comment: It's an exercise of section about group action on set, and before this section the book just introduces definition and basic property of group, so this problem is a bit more difficult than I thought.","['modular-arithmetic', 'mobius-transformation', 'abstract-algebra', 'group-theory', 'group-actions']"
3032825,Showing that the ratio of two standard independent normals is a Cauchy using Characteristic Functions,"Question Let $X$ and $Y$ be independent standard normals. Use characteristic functions to find the distribution of $X/Y$ . My attempt We will attempt to show that $Ee^{itX/Y}=e^{-|t|}$ (the c.f. of a Cauchy random variable) from which the claim will follow. To this end, note that $$
Ee^{itX/Y}=\int\frac{1}{\sqrt{2\pi}}e^{-y^2/2}\int e^{itx/y}\frac{1}{\sqrt{2\pi}}e^{-x^2/2}\, dx\, dy=\int \frac{1}{\sqrt{2\pi}}e^{-y^2/2}\exp\left(-\frac{t^2}{2y^2}\right)\, dy
$$ where we used the fact that $Ee^{it X}=\exp(-0.5t^2)$ . We can write it as $$
Ee^{itX/Y}=\int \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left[\frac{t^2}{y^2}+y^2\right]\right)\, dy.
$$ But at this point I don't know how to evaluate the integral. I tried completing the square in the exponent but I couldn't make progress from there. Any help is appreciated.","['characteristic-functions', 'statistics', 'probability-theory', 'probability']"
3032849,Integrating $\int \sec xdx$: Why is $\ln|\text{sec}x + \text{tan}x| + C$ preferred over $\tanh^{-1}(\sin x) + C$?,"I was trying to integrate $\sec^3x$ and discovered that I would have to integrate $\sec x$ in the process. I had not seen the ""standard"" approach and came up with my own solution, which is apparently quite different: $$\int \sec xdx = \int \frac{dx}{\cos x}$$ I substituted $u = \sin x$ so that $dx = \frac{du}{\cos x}$ . Then $$\int \frac{dx}{\cos x} = \int \frac{du}{\cos^2x} = \int \frac{du}{1 - \sin^2x} = \int \frac{du}{1 - u^2}$$ The solution to this is $\tanh^{-1}u + C$ . Since $u = \sin x$ , this means that $$\int \sec xdx = \tanh^{-1}(\sin x) + C \tag{1}$$ After looking it up, I found out that the standard form of the integral is $$\int\sec x dx = \ln|\text{sec}x + \text{tan}x| + C \tag{2}$$ I couldn't find anything about the alternate form $(1)$ which is, as far as I can tell, equivalent to $(2)$ . So, did I make a mistake here? If not, is there a reason to prefer the usual form $(2)$ ?","['calculus', 'trigonometric-integrals', 'indefinite-integrals', 'trigonometry', 'soft-question']"
3032872,"Show that the open interval (a, b) is Lebesgue measurable","I have to show that an open interval in the form $(a,b)$ , where $a,b \in {\mathbb R}$ and $a < b$ is Lebesgue measurable. 
I think I'm supposed to show, that the subset $(a,b)$ is Lebesgue measurable, if and only if: $$m(A) = m(A ∩ S) + m(A ∩ S^c)$$ where $S \subseteq {\mathbb R}^n$ and $S^c$ is the complement of $S$ . 
But how do I actually prove that the open interval $(a,b)$ is Lebesgue measurable?","['measure-theory', 'lebesgue-measure', 'analysis']"
3032887,Logistic map (discrete dynamical system) vs logistic differential equation,"I have to roughly illustrate the logistic discrete dynamical system (as a model for population growth) to some non mathematics students. I'm not an analyst or an expert of dynamical systems. Looking things up in the internet, I find the logistic map $$x_{n+1}=rx_n(1-x_n)$$ with initial condition $x_0\in [0,1]$ , and where $r\in[0,4]$ is a parameter (the condition $0\leq r \leq 4$ guarantees that $x_n$ doesn't escape the unit interval $[0,1]$ throughout the evolution of the system). Here $x_n$ represents the ratio between the population at time $n$ and the total population the environment is able to support. I find also different behaviors according to the value of the parameter $r\in[0,4]$ . For example, For $0<r\leq 1$ there's extinction of the population. For $1<r\leq 3$ the sequence tends to a stable equilibrium $x_\infty:=1-1/r$ . For $3<r\leq 1+\sqrt{6}$ there's convergence to a period- $2$ cycle. For $1+\sqrt{6}<r\leq r^*$ (where $r^*$ is a certain constant) several bifurcations occur with limit a cycle of period that doubles as $r$ traverses that range. For $r>r^*$ there's chaotic behavior. I would expect that a similar span of different behaviors also happens for the logistic differential equation $$\dot{x}(t)=rx(t)(1-x(t))$$ upon varying the parameter $r$ . But on the internet I found no reference to anything like this. On the contrary, many pages care to solve the differential equation explicitely and illustrate the solution, which is the famous logistic function : the S-shaped increasing curve (depending on $r$ ) with a horizontal asymptote and an inflection point. It seems this solution is obtainable no matter what $r$ is. This looks only like case number 2. of the discrete dynamical system above. So where are the analogous to cases 1.,3.,4. and 5. where the time is continuous?? Or am I misunderstanding some aspects of how a continuous-time dynamical system gets discretized? Also, Which correspondence is there between the $r$ of the discrete version and the $r$ of the continuous version?","['nonlinear-system', 'recurrence-relations', 'ordinary-differential-equations', 'dynamical-systems']"
3033047,Show circle with points coloured red and blue must have monochromatic red equilateral triangle,"Colour each point on a circle of radius $\frac{1}{2}$ red or blue, such that the region of blue points has length $1$ . Prove that we can inscribe an equilateral triangle in the circle such that all three vertices are red. I think the Pigeonhole Principle will be involved, but don't quite see how to apply it. The length condition also seems a bit hard to work with, so any hints or suggestions would be much appreciated.","['combinatorics', 'discrete-mathematics']"
3033052,Ordered subfields of $\mathbb{Q}_p$,"I recently read about real ordered fields. Using real closures, I figured out that for each algebraically closed field $C$ of characteristic $0$ , there exists a real closed subfield $R\subseteq C$ such that the extension is algebraic (and $[C:R]=2$ ). This follows very easily using real closures and Zorn's lemma. Applying this to the field $\overline{\mathbb{Q}}_p$ , it follows that there exists an ordered subfield $R\subseteq \mathbb{Q}_p$ such that the extension is algebraic. The field $\mathbb{Q}_p$ cannot be ordered itself (as $-1$ is a sum of squares), it follows that $R\subseteq \mathbb{Q}_p$ is a strict extension. However, $\mathbb{Q}_p$ has no nontrivial endomorphisms, so the extension cannot be normal. Are there any explicit constructions for $R$ ? And if the extension is finite, what would be a generator for $\mathbb{Q}_p$ ?","['p-adic-number-theory', 'abstract-algebra', 'ordered-fields']"
3033093,Coloring grid points with two colors,"Let $S$ be a set of finite many grid points (points in the coordinate system with integer coordinates).
Is it always possible to color them with two colors, red and blue, such that in each vertical and horizontal line the following statements is true: if there are $R$ number of red and $B$ number of blue points, than $|R-B|\leq 1$ ? This is an olympiad combinatorics problem (from 1986), but I still can’t solve it. I tried to find strategies to color them, but now I am not even sure that the statement is true.","['contest-math', 'coloring', 'graph-theory', 'combinatorics', 'discrete-mathematics']"
3033112,Pigeonholes and onto functions,"I've been scratching my head at this problem for a while and can't seem to figure out why the number of pigeonholes is $3^5 - C(3, 2)2^5 + C(3, 1)1^5$ and not $3^5 - C(3, 2)2^5 - C(3, 1)1^5$ Could my profs answer key be wrong or is there something that I am missing. Because I believe that you have to subtract $3$ in the end since there is a case in which only $1$ is selected from the target as range.","['pigeonhole-principle', 'functions', 'combinatorics', 'discrete-mathematics']"
3033122,is $\det(A^2 + I)$ always non negative?,"Obviously $\det(A^2)$ is (casework), but is the above matrix non-negative? $\det(A)\det(A) \geq 0$ as $\det(A) > 0$ or $\det(A) < 0$ yields positive when squared. However, I am not sure that when adding the identity matrix that it is also positive.","['determinant', 'linear-algebra']"
3033154,Expected number of coin flips until all cars move to end of array?,"Imagine that we have an array of length $2n$ , where the first $n$ entries are a $C$ (representing a toy car) and the remaining $n$ entries are empty. Additionally, we have $n$ fair coins labeled $1$ through $n$ , where coin $i$ corresponds to car $C_i$ in the array. On each timestep, we flip all $n$ coins. If coin $i$ comes up as heads, then car $C_i$ moves forward in the array by one spot, but only if it is not blocked by another car directly in the slot in front of it. Else, if blocked or the coin comes up tails, car $C_i$ does nothing. The question has two parts: What is the expected number of timesteps until the $n$ - $th$ car reaches the end of the array (reaches slot $2n$ )? What is the expected number of timesteps until all of the $n$ cars have moved from the first $n$ slots of the array to the last $n$ slots? I have worked out part 1 as follows. The expected number of flips for one coin to land as heads is $2$ , and the $n$ - $th$ car has to move $n$ slots to get to the end (and is not blocked by anything ever), so the expected number of timesteps is $2n$ . However, I am lost on the approach to part 2. I reason that it should be on the order $O(n\log n$ ) but do not know how to proceed. I keep running into a long chain of conditional probabilities and wonder if there is a more elegant way I am missing.","['expected-value', 'probability', 'random-variables']"
3033159,"Why we only need to verify additive identity, and closed under addition and scalar multiplication for subspace?","In the book Linear Algebra Done Right , it is said that to determine quickly whether a given subset of $V$ is a subspace of $V$ , the three conditions, namely additive identity, closed under addition, and closed under scalar multiplication, should be satisfied. The other parts of the definition of a vector space are automatically satisfied. I think I understand why commutativity, associativity, distributive properties, and multiplicative identity works because their operations are still within the subspace. But, why don't we need to verify additive inverse, similar to verifying additive identity? Could there be cases where there will be no $v + w = 0$ in the new subspace, $v, w \in U$ , $U$ is a subspace?",['linear-algebra']
3033189,Prove the definition of the arcsin(s).,"I am given $\arcsin: S \rightarrow (-\pi/2,\pi/2) $ is the inverse function of sin(t) (restricted to [ $-\pi/2,\pi/2$ ]).  I'm trying to prove that $\arcsin(s)$ = $\int_{0}^{s}1/\sqrt{1-x^2}$ . My initial thoughts for an attempt of a proof: By definition, we know: $\sin(\arcsin(x)) = x$ Thus by the chain rule: $(\sin(\arcsin(x)) = x)' $ $ \cos(\arcsin(x)) \times d (\arcsin(x))/dx  = 1$ Also by definition, we know: $\sin(x)^2 + \cos(x)^2 = 1$ It has been given that $\cos(x) > 0 $ over the interval $(-\pi/2,\pi/2)$ , which implies $\sin(\arcsin(x))^2 + \cos(\arcsin(x))^2= 1$ . Therefore, $\cos(\arcsin(x)) = \sqrt{(1-x^2)}$ So, $\sqrt{(1-x^2)}\times d (\arcsin(x)) /dx = 1$ and $d (\arcsin(x)) /dx = 1/\sqrt{(1-x^2)}$ From there I think we will use parts of the MVT or the fundamental theorem of calculus to prove the result $\arcsin(s)=\int_{0}^{s}1/\sqrt{1-x^2}$ , but I'm having trouble with the formalities.","['proof-writing', 'real-analysis', 'calculus', 'trigonometry', 'chain-rule']"
3033223,"If $\cos(x+a)=\cos(x+y+z)$, then can we deduce that $a=y+z$?","If I have the following equation: $$\cos(x+a)=\cos(x+y+z)$$ Can I take the inverse cos of both sides? $$\begin{align}
\cos^{-1}(\cos(x + a))&=\cos^{-1}(\cos(x+y+z)) \\
x+a&=x+y+z \\
a&=y+z
\end{align}$$ Is this correct?","['algebra-precalculus', 'trigonometry']"
3033247,"Is there a non-planar, non-hamiltonian and eulerian graph?","I'm trying to find a graph that is non-planar, non-hamiltonian and eulerian but I can't find anyone.
Is this possible? Thanks","['graph-theory', 'hamiltonian-path', 'discrete-mathematics', 'planar-graphs']"
3033251,Seeking Methods to solve $F\left(\alpha\right) = \int_{0}^{1} x^\alpha \arcsin(x)\:dx$,"I'm looking for different methods to solve the following integral. $$ F\left(\alpha\right) = \int_{0}^{1} x^\alpha \arcsin(x)\:dx$$ For $\alpha > 0$ Here the method I took was to employ integration by parts and then call to special functions, but can this equally be achieved with say a Feynman Trick? or another form integral transform? My approach in detail: Employ integration by parts: \begin{align}
    v'(x) &= x^\alpha & u(x) &= \arcsin(x) \\
    v(x) &= \frac{x^{\alpha + 1}}{\alpha + 1} & u'(x) &= \frac{1}{\sqrt{1 - x^2}}
\end{align} Thus, \begin{align}
    F\left(\alpha\right) &= \left[\frac{x^{\alpha + 1}}{\alpha + 1}\cdot\arcsin(x)\right]_0^1 - \int_0^1 \frac{x^{\alpha + 1}}{\alpha + 1} \cdot \frac{1}{\sqrt{1 - x^2}} \:dx \\
    &= \frac{\pi}{2\left(\alpha + 1\right)} -  \frac{1}{\alpha + 1}\int_0^1 x^{\alpha + 1}\left(1 - x^2\right)^{-\frac{1}{2}} \:dx
\end{align} Here make the substitution $u = x^2$ to obtain \begin{align}
     F\left(\alpha\right) &= \frac{\pi}{2\left(\alpha + 1\right)} -  \frac{1}{\alpha + 1}\int_0^1 \left(\sqrt{u}\right)^{\alpha + 1}\left(1 - u\right)^{-\frac{1}{2}} \frac{\:du}{2\sqrt{u}} \\
     &= \frac{\pi}{2\left(\alpha + 1\right)} -  \frac{1}{2\left(\alpha + 1\right)}\int_0^1 u^{\frac{\alpha}{2}}\left(1 - u\right)   ^{-\frac{1}{2}} \:du     \\   
     &= \frac{1}{2\left(\alpha + 1\right)} \left[ \pi  - B\left(\frac{\alpha + 2}{2}, \frac{1}{2} \right) \right]
\end{align} \begin{align}
    F\left(\alpha\right) &=\frac{1}{2\left(\alpha + 1\right)} \left[ \pi  - \frac{\Gamma\left(\frac{\alpha + 2}{2}\right)\Gamma\left(\frac{1}{2}\right)}{\Gamma\left(\frac{\alpha + 2}{2} + \frac{1}{2}\right)} \right] \\
    &= \frac{1}{2\left(\alpha + 1\right)} \left[ \pi  - \frac{\Gamma\left(\frac{\alpha + 2}{2}\right)\sqrt{\pi}}{\Gamma\left(\frac{\alpha + 3}{2}\right) } \right] \\
    &= \frac{\sqrt{\pi}}{2\left(\alpha + 1\right)} \left[ \sqrt{\pi}  - \frac{\Gamma\left(\frac{\alpha + 2}{2}\right)}{\Gamma\left(\frac{\alpha + 3}{2}\right) } \right]
\end{align} Edits:
Correction of original limit observation (now removed)
Correction of not stating region of convergence for $\alpha$ .
Correction of 1/sqrt to sqrt in final line. Thanks to those commentators for pointing out.","['integration', 'definite-integrals', 'beta-function', 'error-function', 'gamma-distribution']"
