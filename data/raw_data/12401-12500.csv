question_id,title,body,tags
96790,Integral domain that is not a factorization domain,"I am looking for rings that are integral domains but not factorization domains, that is, rings in which it is not possible to express a nonzero nonunit element as a product of irreducible elements. Do you know any example?","['commutative-algebra', 'ring-theory', 'integral-domain', 'abstract-algebra']"
96815,"Possible Jordan forms for a nilpotent $A$, given the ranks of $A$ and $A^2$","Could you help me to solve this exercise? Let $A$ be an $8\times8$ nilpotent matrix over $\mathbb{C}$ with $\mathrm{rank}(A)=5$ and $\mathrm{rank}(A^2)=2$. List all possible Jordan canonical forms for $A$ and show that knowledge of $\mathrm{rank}(A^3)$ would allow one to determine the Jordan canonical form. This is what I have done: $A$ is nilpotent so the characteristic polynomial is $x^8$ and the minumum polynomial is $x^n$ with $3\leq n\leq8$. But now I don't know how to continue, any idea?","['matrices', 'linear-algebra']"
96826,The Monty Hall problem,"I was watching the movie $21$ yesterday, and in the first 15 minutes or so the main character is in a classroom, being asked a ""trick"" question (in the sense that the teacher believes that he'll get the wrong answer) which revolves around theoretical probability. The question goes a little something like this (I'm paraphrasing, but the numbers are all exact): You're on a game show, and you're given three doors. Behind one of the doors is a brand new car, behind the other two are donkeys. With each door you have a $1/3$ chance of winning. Which door would you pick? The character picks A, as the odds are all equally in his favor. The teacher then opens door C, revealing a donkey to be behind there, and asks him if he would like to change his choice. At this point he also explains that most people change their choices out of fear; paranoia; emotion and such. The character does change his answer to B, but because (according to the movie), the odds are now in favor of door B with a $1/3$ chance of winning if door A is picked and $2/3$ if door B is picked. What I don't understand is how removing the final door increases the odds of winning if door B is picked only. Surely the split should be 50/50 now, as removal of the final door tells you nothing about the first two? I assume that I'm wrong; as I'd really like to think that they wouldn't make a movie that's so mathematically incorrect, but I just can't seem to understand why this is the case. So, if anyone could tell me whether I'm right; or if not explain why, I would be extremely grateful.","['probability-theory', 'monty-hall', 'probability', 'popular-math']"
96827,How to compute the change of basis matrix that conjugate a matrix to its rational canonical form,"Let $A=\begin{pmatrix} 2&-2&14\\0&3&-7\\0&0&2\end{pmatrix}$, then its rational canonical form is $R=\begin{pmatrix}2&0&0\\0&0&-6\\0&1&5\end{pmatrix}$. How can I compute a matrix $P$ such that $P^{-1}AP=R$? And in general what is the algorithm?","['matrices', 'linear-algebra']"
96828,Vector field and normal of the field are both gradient fields,"Are there any general conditions to use to find a vector field f(x,y) that is a gradient field and f(-y,x) is also a gradient field.  It seems to me like if their second partial derivatives are zero then this is true or at least I haven't find an exception to that yet.",['multivariable-calculus']
96830,Is there an entire function with a conditionally convergent power series?,"Does there exist an entire (holomorphic on all of $\mathbb C$) function $f(z) =\displaystyle\sum_{n=0} ^\infty a_n z^n$ such that $\displaystyle\sum_{n=1} ^\infty |a_n| = \infty$? If not, how can one prove that there is no such function?","['sequences-and-series', 'complex-analysis']"
96835,Are there any geometries/spaces where pi is a simple (or at least rational) constant?,"I found this article on pi: http://blog.plover.com/math/pi.html and while I found it very interesting, it seemed unfinished.  The basic point of the article is that pi is complicated (for example e has a simple continued fraction representation:  [2; 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, 1, 1, 10, 1, ...], but pi does not), and the author claims that this complicatedness is due to the nonlinear nature of the euclidean distance metric.  However, the author doesn't really have a conclusion, and I felt that I still had some questions that weren't satisfied: How does such a complex constant (pi) arise from such a simple definition (a circle)? a) Is it because the base-10 decimal representation is flawed, and there is another representation of numbers where pi is simple?  If so, what is this representation? b) Or is it because of some property of euclidean space, like the nonlinear nature of the distance metric.  If so, where exactly does this property come into play in the definition of pi, and how does it create such complexity?  It seems like a the simple square root of sum of squares metric shouldn't create such a bizarre constant (or if it did, that the constant would have something to do with the number 2). Furthermore, if the answer is b, then are there any geometries or spaces that don't have this property, such that pi would be a simple constant? I hope my questions aren't too vague!  Thanks! edit: By complex (I probably should have said complicated) I mean that, as pointed out in the article, whereas other irrational numbers like sqrt(2) or e have nice representations (in those two cases, they have nice continued fraction forms), pi does not have a nice continued fraction form. That's why I was wondering if there are any real number representations where pi does have a nice form, akin to e's representation in continued fraction form. My main line of inquiry (which is the same line of inquiry of the linked incomplete article), is: how does such a simple definition of a circle: all points that are distance r away from a center, create such an incredibly complicated number?","['pi', 'geometry', 'euclidean-geometry']"
96840,Does the improper integral $\int_0^\infty e^{-x^2}dx$ converge?,"I want to show the convergence of the following improper integral $\int_0^\infty e^{-x^2}dx$.
I try to use comparison test for integrals
$x≥0$, $-x ≥0$, $-x^2≥0$ then $e^{-x^2}≤1$. So am ending with the fact that $\int_0^\infty e^{-x^2}dx$ converges if $\int_0^\infty dx$ converges but I don’t  appreciate this. Thanks","['integration', 'real-analysis']"
96842,"A question in Probability, aces drawn from two halves of a shuffled deck","""A deck of cards is shuffled and then divided into two halves of 26 cards each. A card is drawn from one of the halves, it turns out to be an ace. The ace is then placed in the second half-deck. The half is then shuffled and a card is drawn from it. Compute the probability that this drawn card is an ace."" Source : A First Course in Probability, Sheldon Ross, Chapter 3, Exercise 37 (My intention was not to be lazy and let the community do all the work for me, but I think that is what has been misunderstood seeing the 2 dislikes this question received. I just thought I should not clutter the question with more text than necessary) What I've tried : Probability that the second half already contained 0,1,2 or 3 aces before the ace from the first half was added to it. Then, when the new ace was added to it from the first half, we could calculate the probabilities of drawing an ace considering each of these cases, and add them to get the answer. But I am not sure how do I calculate the P(second half contained 0/1/2/3 aces)..","['card-games', 'probability']"
96857,Does $\log(ab)^n$ equal $(\log(a)+\log(b))^n$ or $n\log(a)+n\log(b)$?,"I think this might be a case of slight ambiguity in notation, but here goes: On a test question, I was required to expand the expression $\log (ab)^n$. Since the logarithm is a function, I reasoned as follows: \begin{align*}
\log(ab)^n &= (\log(ab))^n\\
&= (\log(a)+\log(b))^n
\end{align*} However, after having our tests returned, I found that the teacher reasoned as follows: \begin{align*}
\log(ab)^n &= \log((ab)^n)\\
&= \log(a^nb^n)\\
&= \log(a^n)+\log(b^n)\\
&= n\log(a)+n\log(b)
\end{align*} I thought about asking, but decided to look in the textbook first, and found that the textbook does something like $\log(a+b)^n =n\log(a+b)$, so here I am. My question is, which expansion is correct? Is one of them more standard than the other, or are they both acceptable interpretations? If you can link to some sources using one way or the other, that would also be appreciated.","['logarithms', 'algebra-precalculus']"
96868,Regularity of root spacing of $G(z)=\sum_{n=1}^{\infty} \frac{e^{-n^{2}}}{n^{z}}$,"Define, on $\mathbb{C}$:
$$G(z)=\sum_{n=1}^{\infty} \frac{e^{-n^{2}}}{n^{z}}$$ A domain colored portrait of $G(z)$ (boxes are supposed to be negative signs): suggests that the roots of $G(z)$ are equally spaced along lines of fixed real component. So: Are the roots of $G(z)$ regularly spaced for some fixed $\Re(z)$? and if so: Are there analytic expressions for the roots? Can $G(z)$ expressed as a Weierstrass product?","['dirichlet-series', 'roots', 'complex-analysis']"
96917,"If $T$ has finite rank, then: $I-T$ is injective if and only if $I-T$ is surjective?","I have a Banach Space $X$ and an linear continuous operator $T\colon X\to X$ that has finite rank (i.e. $\dim {T(X)}<\infty$). Then, $I-T$ is injective if and only if $I-T$ is surjective?","['operator-theory', 'functional-analysis', 'banach-spaces']"
96924,Can every line or every j-plane contain all integers exactly once in $\mathbb N^i$,"For which pairs of integers $0<j<i$, is there a function $f:\mathbb N^i \to \mathbb N$, $f(x_1,x_2,...,x_i)$ which outputs every positive integer exactly once when any $i-j$ of the variables are kept constant on any $(i-j)$-tuple of positive integers, while the other $j$ variables are varied over all $j$-tuples of positive integers? And is there a $g$, defined on all infinite sequences of positive integers, such that for all such sequences, if we replace any one element by a variable, say $x$, then $g(x)$ is a bijection between the integers? (ie. $j=1, i=\infty$)","['number-theory', 'elementary-set-theory', 'functions', 'real-analysis', 'combinatorics']"
96929,Jordan decomposition/Levi decomposition in GL(n) in positive characteristic,"Let $k$ be a non archimedean field of positive characteristic. Lets consider a parabolic subgroup $P \subset GL(n, k)$. I am a little bit confused by the following statement in ""Laumon - Cohomology of Drinfeld Modular ... "": I have an issue with the following two assertions $P = MN$ has a Levi decomposition over $k$ ( pg.123 ) and $\gamma \in P$ can be written as $\gamma = \gamma_m \gamma_n$ with $\gamma_m \in M$ and $\gamma_n \in N$ (pg.124) Now, I have read that the Jordan decomposition and Levi decomposition need not to hold in positive characteristic (e.g. in Humpreys, Waterhouse). Do they mean that the decomposition are not functorial with respect to field extensions, and are available for the group, but not the group scheme? Why is this not a contradiction? Remark: I understand that elliptic element can become unipotent in an algebraic extension, since the minimal polynomial might not be separable in general.","['algebraic-geometry', 'algebraic-groups', 'abstract-algebra']"
96938,Generic Elements of a Set.,"Mild Motivation: In writing a post about the Baire Category Theorem, I learned the neat fact that a ""generic"" $f\in C^{0}([a,b], {\mathbb R})$ was nowhere differentiable and not monotone on any subinterval.  The term ""generic"" was defined as follows: if $A$ is the complement of a meagre set and all points in $A\subseteq X$ for $X$ some space share some property, then the property is said to be generic of the set . Question: How standard is this definition of generic , and how useful is it to talk about something which is generic of a set? To expand on this last part a bit: a generic real number is an irrational number (since the rationals are not comeagre) so what does this tell us about the real numbers?  If we were to prove something for just a generic element, how would we describe this (as in, for a set of measure zero we say, ""almost everywhere,"" --- would we say something is true ""up to a meagre set"")?","['general-topology', 'descriptive-set-theory', 'terminology']"
96944,Are all subrings of the rationals Euclidean domains?,"This is a purely recreational question -- I came up with it when setting an undergraduate example sheet. Let's go with Wikipedia's definition of a Euclidean domain . So an ID $R$ is a Euclidean domain (ED) if there's some $\phi:R\backslash\{0\}\to\mathbf{Z}_{\geq0}$ or possibly $\mathbf{Z}_{>0}$ (I never know what $\mathbf{N}$ means, and the Wikipedia page (at the time of writing) uses $\mathbf{N}$ as the target of $\phi$, but in this
case it doesn't matter, because I can just add one to $\phi$ if necessary) such that the usual axioms hold. Now onto subrings of the rationals. The subrings of the rationals turn out to be in bijection with the subsets of the prime numbers. If $X$ is a set of primes, then define $\mathbf{Z}_X$ to be the rationals $a/b$ with $b$ only divisible by primes in $X$. Different sets $X$ give different subrings, and all subrings are of this form. This needs a little proof, but a little thought, or a little googling, leads you there. If $X$ is empty, then $\mathbf{Z}_X=\mathbf{Z}$, which is an ED: the usual $\phi$ taken is $\phi(x)=|x|$. If $X$ is all the primes then $\mathbf{Z}_X=\mathbf{Q}$ and this is an ED too (at least according to Wikipedia -- I think some sources demand that an ED is not a field, but let's not go there); we can just let $\phi$ be constant. If $X$ is all but one prime, say $p$, then $\mathbf{Z}_X$ is the localisation of $\mathbf{Z}$ at $(p)$, and $\phi$ can be taken to be the $p$-adic valuation (if we're allowing $\phi$ to take the value zero, which we may as well). Note however that this is a rather different ""style"" of $\phi$ to the case $X$ empty: this $\phi$ is ""non-archimedean"" in origin, whereas in the case of $X$ empty we used an ""archimedean"" $\phi$. This sort of trick generalises to the case where $X$ is all but a finite set of primes -- see the ""Dedekind domain with only finitely many non-zero primes"" example on the Wikipedia page. Of course the question is: if $X$ is now an arbitrary set of primes, is $\mathbf{Z}_X$ an ED?","['principal-ideal-domains', 'commutative-algebra', 'ring-theory', 'number-theory']"
96945,An existence of global solution of differential equation of first order,"Let $f: (a,b) \times \mathbb{R} \rightarrow \mathbb{R}$ be of class $C^1$ in $D:=(a,b) \times \mathbb{R}$ and satisfies condition $$| f(t,x)| \leq A+B|x|  \textrm{ for }  (t,x) \in D,$$ where $A,B$ are fixed real constants and let $t_0 \in (a,b)$. How to prove using the fixed point method that for arbitrary $x_0\in \mathbb{R}$ there exist exactly one solution $x: (a,b)\rightarrow \mathbb{R}$ of differential equation
$$\frac{dx}{dt}=f(t,x) $$ with condition $x(t_0)=x_0$ ? Thanks. Added. Maybe it would be. Let $X=\{x:(a,b) \rightarrow \mathbb{R}: \sup_{t\in (a,b)}  e^{-B\gamma|t-t_0|} |x(t)|   <\infty, x(t_0)=x_0 \}$,
$d(x,y)=\sup_{t\in (a,b)} e^{-B\gamma|t-t_0|} |x(t)-y(t)|$ for $x,y \in X$, where $\gamma$ is a suitable positive constant.
Then $(X,d)$ is a complete metric  space and $Tx(t):=x_0+\int_{t_0}^t f(s,x(s))ds$, for $x \in X$ and $t\in (a,b)$, maps X into itself
(because  $|f(s,x(s))|\leq A+Be^{B\gamma|t-t_0|}\cdot sup_{t\in (a,b)} |x(s)|e^{-B\gamma|t-t_0|} |x(t)|$ and      $| \int_{t_0}^t e^{B \gamma |s-t_0|} ds| \leq \frac{1}{B \gamma} e^{B\gamma|t-t_0|}$).
However I don't know is it $T$ a contraction with some $\gamma>0$ and whether or not each solution of the differential equation belongs to $X$.","['ordinary-differential-equations', 'analysis']"
96946,"How to prove $1$,$\sqrt{2},\sqrt{3}$ and $\sqrt{6}$ are linearly independent over $\mathbb{Q}$?","How do I prove that $1$,$\sqrt{2},\sqrt{3}$ and $\sqrt{6}$ are linearly independent over $\mathbb{Q}$? $\mathbb{Q}$ is the rational field. I want to know the detail about the proof. Thanks in advance. Actually I know any two of them and three of them are linearly independent.","['radicals', 'linear-algebra', 'abstract-algebra']"
96950,If $f$ is a Riemann integrable prove $|f|$ is also Riemann integrable,"Show that if $f$  is Riemann integrable on $[a,b]$ then $|f|$ is also Riemann integrable on $[a,b]$. My idea is:
let $f$ be in $[a,b]$ less than $|f|$, since $f$ is integrable then $|f|$ is also integrable on $[a,b]$.",['integration']
96962,"Putnam problem of the day, roots of a polynomial","I've been lately having fun with some Putnam problems (http://www.math.harvard.edu/putnam/) and I would like to see how todays problem can be solved and for somebody more experienced to check my attempted solution. Find all real polynomials $p(x)$ of degree $n \geq 2$ for which there exists real numbers $ r_1 < r_2 < ... < r_n$ such that $p(r_i) = 0$,  $i = 1,2,...,n,$ and $p'(\frac{r_i + r_{i+1}}{2}) = 0$,  $i = 1,2,...,n-1$, where $p'(x)$ denotes the derivative of $p(x)$ (messy) attempt involving checking coefficients; Any polynomial of degree $n$ with roots in $r_1, r_2, ...,r_n$ will have the following form: $p(x) = c(x-r_1)(x-r_2)...(x-r_n)$ Expanding this we must get that the coefficient of $x^{n-1}$ is: $-c(r_1 + r_2 + ... + r_n)$. This would imply that the coefficient of $x^{n-2}$ of the (monic equivalent) derivative $p'(x)$ is: $\frac{(1-n)}{n}(r_1 + r_2 + ... + r_n)$ (1) So the derivative function must have same coefficient in front of $x^{n-2}$, and from description we get that it is supposed to have following form: $p'(x) = (x-\frac{r_1 + r_2}{2}) (x-\frac{r_2 + r_3}{2})... (x-\frac{r_n-1 + r_n}{2})$ Expanding this will yield $x^{n-2}$ term with following coefficient: $-(\frac{r_1}{2} + r_2 + r_3 + ... + r_{n-1} + \frac{r_n}{2})$ (2) By inspecting equations (1) and (2) we see that they are equal in case of $n = 2$ and never else. So the answer would be the set of polynomials of degree 2? (btw, how do I make the numeration of equation look nice? :))","['calculus', 'contest-math']"
96966,"Nonexistence of a certain norm on $C[0,1]$","Question: Let $X=C[0,1]$, show that there is no such norm $\lVert\cdot\rVert_*$ on $X$ that for any series $\{f_n\}_{n=1}^{\infty}\subset X$, $$\lim_{n\to\infty}\lVert f_n\rVert_*\to 0\Longleftrightarrow
\lim_{n\to\infty}f_n(t)=0,\quad\forall t\in[0,1]$$ ============ I've tried to define a new norm (supposing such $\lVert\cdot\rVert_*$ exists):
$$\lVert f\rVert_+=\lVert f\rVert_*+\max_{t\in[0,1]}|f(t)|=\lVert f\rVert_*+\lVert f\rVert_C$$ it is easy to show that $\lVert\cdot\rVert_+$ is a complete norm on $X$ (so is $\lVert\cdot\rVert_C$), and this implies $\lVert\cdot\rVert_+$ and $\lVert\cdot\rVert_C$ are equivalent norms, so there is a constant $M$ s.t. $$\lVert f\rVert_*\leq M\lVert f\rVert_C,\quad f\in X$$ and I got stuck at the above inequality (or maybe it is useless).",['functional-analysis']
96967,Prove that these two integer groups have equivalent Cayley tables.,"This is an extension of a question from M.A. Armstrong's ""Groups and Symmetry"" (1988). 7.1 Check that the numbers 1, 2, 4, 5, 7, 8 form a group under multiplication modulo 9 and show that this group is isomorphic to $\mathbb{Z}_6$. First, I computed the Cayley table for the $\mathbb{Z}_9$ subgroup and determined that these six elements do in fact form a group. I did the same for $\mathbb{Z}_6$ both under multiplication and addition, and did not find a match for the subgroup mentioned above. Fine. I figure that there are a number of permutations of Cayley tables for any given group, so I'll just play around with a few until the elements appear congruent i.e. taking the same place in the table. After doing this for 3 tables, I decided to change up my approach. I remembered that the power of each element was an important part of the structure of the group, so I counted the number of steps it takes for each element to reach identity. For $\mathbb{Z}(6,+): 0 = 1^6 = 2^5 = 3^4 = 4^3 = 5^2$ where e.g. the 1 element takes six iterations to reach 0 under addition modulo 6. After doing the same for the six element $\mathbb{Z}_9$ subgroup, I found that the elements had congruent powers. I thought this is a good sign. Here is what I found: $1 = 2^4 = 4^5 = 5^2 = 7^3 = 8^6$ where again the power represents the number of operations taken to reach identity, in this case under multiplication modulo 9. Equating the elements of the same power takes the first map of $\mathbb{Z}_6$ to the $\mathbb{Z}_9$ subgroup thus: $0 \rightarrow 1; 1 \rightarrow 8; 2 \rightarrow 4; 3 \rightarrow 2; 4 \rightarrow 7; 5 \rightarrow 5$. My question is if the powers of the elements correspond, why don't they form equivalent Cayley maps. The patterns of each are totally different!",['group-theory']
96968,Identifying Independent And Dependent Variables In Differential Equations,"I've been given a second order differential equation $$x^2y'' + xy' + (x^2 - v^2)v = 0$$(where $v$ is a parameter)* and asked to identify the dependent and independent variables.
Question is How do i know which are dependent and independent? I'am only used to equations of the form $x^2\frac{d^2y}{dx^2} + \frac{dy}{dx} = 0$ where i can easily tell that $y = f(x)$. *I don't know what that means! Thanks In Advance.","['ordinary-differential-equations', 'soft-question']"
96985,Subgroup(s) of a group of order 25,"I am working on a problem (self-study) from Artin - 2.8.8 which goes: ""Let G be a group of order 25. Prove that G has at least one subgroup of order 5, and that if it contains only one subgroup of order 5, then it is a cyclic group."" I can see that there is an element of order 5, and this can generate a cyclic subgroup of order 5. -- So my first question is: what would make one think that there might be more than one subgroup of order 5, and what would they look like. And what would be the criteria for there being only one rather than more than one? For the second part, I am familiar with a proof that a group of order $p^2$ is abelian, by showing the center is all of G. -- My second question is how to show G is cyclic - and how does this use the stipulation that there is only one subgroup of order 5 (in the text there is a statement that if there is only one subgroup of a particular order then it is normal). And how does there being more than one subgroup of order 5 prevent G from being cyclic. Thanks.","['group-theory', 'abstract-algebra']"
96986,A question about independent events,"While studying probability, the following question arose: Let $H$ be an event and let $\mathcal{H}=\lbrace H_\lambda|\lambda\in\Lambda\rbrace$ be a family of events in probability space $(\Omega,\mathcal{F},P)$, such that for every $\lambda\in\Lambda$ the following holds: $P(H_\lambda\cap H) = P(H_\lambda)P(H)$, i.e. the events $H_\lambda$ and $H$ are independent. Let $\mathcal{G}=\sigma(\mathcal{H})$ be the $\sigma$-algebra generated by $\mathcal{H}$. Let $G\in\mathcal{G}$ be any event. Are $G$ and $H$ necessarily independent i.e. does it follow that $P(G\cap H) = P(G)P(H)$? This would be quite a useful lemma, I think. I had an idea for a proof, but the last step didn't quite work as expected. The argument went like this: We shall write $\mathcal{G}$ as a union of an increasing sequence of more simple sets. Let $\mathcal{B}_0 = \mathcal{H}$. For every successor ordinal $\alpha+1$ define $\mathcal{A}_{\alpha+1} = \lbrace\bigcup\mathcal{J}|\mathcal{J}\subseteq\mathcal{B}_\alpha,\mathrm{card}(\mathcal{J})\leq\aleph_0\rbrace$, the set of all countable unions of the previous sets, and $\mathcal{B}_{\alpha+1}=\lbrace A|\Omega - A\in\mathcal{A}_{\alpha+1} \lor A\in\mathcal{A}_{\alpha+1}\rbrace$, the same with their complements added. For limit ordinals we define $\mathcal{B}_\beta=\bigcup_{\alpha<\beta}\mathcal{B}_\alpha$. Finally define $\mathcal{B} = \bigcup_{\alpha<\omega_1}\mathcal{B}_\alpha$. I guess such an union should make sense, since at each step we stay inside $\mathcal{G}$ ... Next we prove that $\mathcal{B}$ is a $\sigma$-algebra and since every set in the construction of this $\sigma$-algebra is a subset of $\mathcal{G}$, we must have that $\mathcal{B} = \mathcal{G}$. The only tricky part in proving $\mathcal{B}$ is a $\sigma$-algebra is closure under countable unions. Let $(A_n)_n$ be a sequence of events in $\mathcal{B}$. Then for each $n\in\mathbb{N}$ there is an ordinal $\alpha_n$ such that $A_n\in\mathcal{B}_{\alpha_n}$. Then there must be some ordinal $\gamma < \omega_1$ such that $\forall n:\alpha_n \leq \gamma$. (Since otherwise $\omega_1$ would be a countable union of countably many sets which it can't be, since it isn't countable. (Assuming the axiom of choice.)) So these events are all elements of $\mathcal{B}_\gamma$ which implies their countable union must lie in $\mathcal{A}_{\gamma+1}\subseteq\mathcal{B}_{\gamma+1}$ and therefore in $\mathcal{B}$. I was hoping the rest would follow by transfinite induction: if $A\in\mathcal{B}_{\alpha+1}$ then either $A\in\mathcal{A}_{\alpha+1}$ or $\Omega-A\in\mathcal{A}_{\alpha+1}$. The second case would follow from the first case using complements. But the first case is problematic: $P(A\cap H) = P((\bigcup_{E\in\mathcal{J}}E)\cap H) = P((\bigcup_{\tilde{E}\in\mathcal{J}_0}\tilde{E})\cap H) = \sum_{\tilde{E}\in\mathcal{J}_0}P(\tilde{E}\cap H)$. Here $\mathcal{J}\subseteq\mathcal{B}_\alpha$ exists by definition of $\mathcal{A}_{\alpha+1}$ and $\mathcal{J_0}$ is a set of mutually exclusive events giving the same union. The problem is that such a set $\mathcal{J_0}$ can in this case only be proven to lie under $\mathcal{B}_{\alpha+1}$, so we cannot write $P(\tilde{E}\cap H) = P(\tilde{E})P(H)$. So the proof sadly fails at this last step. Is this proof salvageable? (Perhaps by taking relative complements instead in the definition of $\mathcal{B}_{\alpha+1}$ or something like that?) Does such a lemma even hold or do we have to modify it? Are such proofs by transfinite induction useful in probability? It seems to me probabilists implicitly use lemmas like this all the time, so I am also wondering if such a lemma or a similar one would in fact be useful. [Comment: The definition of $\mathcal{B}$ above originally used $\mathbf{On}$ which was a slight overkill, so I changed it to $\omega_1$, following the kind suggestion of Asaf Karagila.] Added: In a comment below Dilip Sarwate suggests the following variation on the problem: Let $H$ be an event and let $\mathcal{H}=\lbrace H_\lambda|\lambda\in\Lambda\rbrace$ be a family of events in probability space $(\Omega,\mathcal{F},P)$, such that the family of events $\mathcal{H}\cup\lbrace H\rbrace$ is independent i.e. for every finite $\mathcal{S}\subseteq\mathcal{H}\cup\lbrace H\rbrace$ we have $P(\bigcap_{E\in\mathcal{S}}E) = \Pi_{E\in\mathcal{S}}P(E) $, where $\Pi$ denotes the product of the probabilities, as usual. Let $\mathcal{G}=\sigma(\mathcal{H})$ be the $\sigma$-algebra generated by $\mathcal{H}$. Let $G\in\mathcal{G}$ be any event. Are $G$ and $H$ necessarily independent i.e. does it follow that $P(G\cap H) = P(G)P(H)$? This case actually interests me even more than the ""original question"" above, since it is this case that I actually needed. (I thought somehow that I can get more out of it by relaxing the conditions to what the question above says. Silly me.)","['measure-theory', 'probability']"
96990,Question about finding the limit at an undefined point.,"This may be braindead, but I'm trying! If I have a function $f$ and that function is not defined at some x, then asking for the derivative of the function at $x$ makes no sense since there is no $f(x)$ at $x$. But if I want to find a gradient for that function as close as possible to x, then how does that work?  Isn't that the same as the derivative at x?  It's like, I can do the same calculation but I have to disregard the result because I'm asking for something that doesn't exist. For example, if $f(x)=\frac{1}{x−2}$, then $f(x)$ is not defined at $x=2$. So I can't find the derivative at that point since it doesn't exist, But the limit is 2. But the limit is the derivative, and the derivative doesn't exist! I'm confused. I felt like I understood this but I woke up this morning with no idea.  Last week I was happily finding the volume of cylindrical wedges, now I can't understand limits O_O Please set me straight. EDIT: I think my problem is the way I'm thinking about limits.  It seems that there are two limits and I'm confusing them.  The limit that $f(x)$ approaches and the limit that $x+h$ approaches.  In the above example where $f(x)=\frac{1}{x-2}$, $2+h$ approaches $2$ and $f'(x)$ is undefined since the numerator contains a division by zero. Is that my answer? 2nd EDIT:  This is what I'm really asking: How do I find $lim_{x\to a}f'(x)$?","['calculus', 'derivatives', 'limits']"
97004,A projection satisfying $\| Px \| \leq \|x\|$ for all $x$ is an orthogonal projection [duplicate],"This question already has answers here : Orthogonal Projection (3 answers) Closed 6 years ago . How to prove that if $V$ is a finite dimensional inner product space and $W$ a subspace of $V$, if $P$ is projection map ($P^2=P$) having $W$ as its range and is such that $\|Px\| \leq \|x\|$ for all $x \in V$, then $P$ is orthogonal projection of $V$ onto $W$.",['linear-algebra']
97021,How does one prove $\int_0^\infty \prod_{k=1}^\infty \operatorname{\rm sinc}\left( \frac{t}{2^{k+1}} \right) \mathrm{d} t = 2 \pi$,"Looking into the distribution of a Fabius random variable :
$$
    X := \sum_{k=1}^\infty 2^{-k} u_k
$$
where $u_k$ are i.i.d. uniform variables on a unit interval, I encountered the following expression for its probability density:
$$
   f_X(x) = \frac{1}{\pi} \int_0^\infty \left( \prod_{k=1}^\infty \operatorname{\rm sinc}\left( \frac{t}{2^{k+1}} \right) \right) \cos \left( t \left( x- \frac{1}{2} \right) \right) \mathrm{d} t
$$
It seems, numerically, that $f\left(\frac{1}{2} \right) = 2$, but my several attempts to prove this were not successful. Any ideas how to approach this are much appreciated.","['definite-integrals', 'probability-distributions', 'calculus']"
97036,From continuity to differentiability and analyticity- what's next?,"Continuity is an intuitive concept. I will not dwell on the precise definitions of continuity and the rest here. Note that differentiability is a more restrictive condition than continuity, while analyticity for complex-valued functions is even more restrictive than differentiability. To some extent, I understand the motivation behind defining these terms as they are defined right now. My question is: what is the next condition in the sequence continuity, differentiability(scalar/vector/left-right/partial:all), analyticity $\cdots$? Does there exist a next term in this sequence? If yes, in what context? if no, what is the reason? are all possible restrictions on functions' behavior covered in some sense? As one goes on in higher dimensions, is there some behavior that prompts any further restriction, so to speak? PS: I am talking in very general terms, with their usual connotations.","['philosophy', 'complex-analysis', 'soft-question', 'real-analysis']"
97054,Suppose $H$ is the only subgroup of order $o(H)$ in the finite group $G$. Prove that $H$ is a normal subgroup of $G$.,"Suppose $H$ is the only subgroup of order $o(H)$ in the finite group $G$ . Prove that $H$ is a normal subgroup of $G$ . I've been trying this problem for quite a while but to no avail. What I can't understand is, how do you relate the subgroup being normal to its order? This question is from I.N. Herstein's book Topics in Algebra , page 53, Problem no. 9. This is NOT a homework problem!! I'm studying this book on my own.","['group-theory', 'abstract-algebra', 'normal-subgroups']"
97056,Uniform Continuity and Differentiation,"Is the following true or false?: Let $f\colon  [0,1) \to \mathbb{R}$ be a function differentiable in $[0,1)$ (where the derivative at zero means ""right derivative"") such that both $f$ and $f'$ are uniformly continuous in $(0,1)$. Then $f'$ is continuous. Note that the mistery lies at $x=0$. So the question is: can we say with these hypotheses that $f'(0)=\lim_{x\to 0^{+}}f'(x)$ (which exists thanks to the uniform continuity of $f'_{\mid (0,1)}$). Note also that the uniform continuity of $f'_{\mid (0,1)}$  makes redundant the analogous requirement for $f$ (which will even more become a Lipschitz function).","['calculus', 'derivatives', 'real-analysis']"
97057,Four generators of $S(9)$ - A smart way of showing that this generates the entire group?,"I have four 4-cycles, given by: $(1452),(2563),(4785),(5896)$.  I know that the group generated by these guys are $S(9)$ by asking mathematica for the order of the permutation group generated by these four 4-cycles, which came out to be 9! I am looking for an elegant way to show this statement, but I can't come up with anything. We tried to show directly that we can get a 2-cycle and a 9-cycle without success. The motivation for the problem is as follows: 9 squares are arranged in a 3 by 3 grid. I will refer to this grid as the ""big square"". You have some kind of a picture drawn in the big square. The individual squares are scrambled in some weird manner. Is it possible to get the original picture back, using only the operation given by rotating four squares with the the center of the rotation on the vertex of the central square? So basically: \begin{pmatrix}
1 & 2 & 3 \\\
4 & 5 & 6 \\\
7 & 8 & 9
\end{pmatrix} can become \begin{pmatrix}
2 & 5 & 3 \\\
1 & 4 & 6 \\\
7 & 8 & 9
\end{pmatrix} which corresponds to the cycle (1452).","['permutations', 'finite-groups', 'group-theory']"
97070,Linear independence of function vectors and Wronskians,"I am taking a course in ODE, and I got a homework question in which I am required to: Calculate the Wronskians of two function vectors (specifically $(t, 1)$ and $(t^{2}, 2t)$). Determine in what intervals they are linearly independent. There are more parts to this question, but I figured that I will deal with them when I understand the basic concepts better. So these are my questions: I know how to calculate the Wronskian of n functions: 
$f_{1} \cdots  f_{n}: \begin{vmatrix}
f_{1} & \cdots & f_{n} \\ 
\vdots  &  & \vdots \\ 
f_{1}^{(n-1)} & \cdots & f_{n}^{(n-1)} 
\end{vmatrix}$. 
I assume that when I'm asked to calculate the Wronskian of a function vector, my $n$ functions would be the vector's components? I know that if the Wronskian of $n$ functions is not $0$ for some $t$, I can deduce that they are linearly independent. How can I use this information to find the intervals in which two vectors are independent? I would love to read a good explanation on why these methods work (sadly, I cannot understand a thing from my notebook and the library is closed on the weekend), so if you could explain it or direct me to a good online resource, preferably not Wikipedia, I will be glad. And finally, I apologize in advance if I'm not very clear, I am not a native English speaker. Thanks!","['ordinary-differential-equations', 'wronskian']"
97071,Binomial distributions,"If I'm tossing 4 pennies at once, and then recording how many heads there came out to be 32 times, is that a Binomial experiment?","['statistics', 'discrete-mathematics']"
97095,definition of Krull dimension of a module,"Let $R$ be a commutative ring with $1$. We know that the Krull dimension of $R$ is by definition the length of the longest chain of prime ideals of $R$. Now if $M$ is a  $R$-module, the Krull dimension of $M$ is by definition $\dim(M):=\dim(R/\mathrm{Ann}_R(M))$. Since every ideal $I$ of $R$ is also a $R$-module, the Krull dimension of $I$ is $\dim(I)=\dim(R/\mathrm{Ann}_R(I))$. However, in the literature, the Krull dimension of an ideal is $\dim(I):=\dim(R/I)$. Are the two definitions equivalent?","['krull-dimension', 'commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
97098,A question about groups: may I substitute a binary operation with a function?,"I have a fundamental question about groups. Consider the definition from Wolfram Mathematica: A group  is a finite or infinite set of elements together with a binary operation (called the group operation) that together satisfy the four fundamental properties of closure, associativity, the identity property, and the inverse property. In this definition, may I substitute a binary operation with a function, say something like $f(a,b)$ where $f$ is not necessarily a simple operator like addition?",['group-theory']
97119,Solvable group determined by the action on its Fitting subgroup and the isoclass of some of its Sylows,"Let Q ≤ P be finite p -groups, H ≤ Aut( Q ). Is it really true that there is at most one p -solvable group G such that $Q \unlhd G$, $C_G(Q) \leq Q$, P is a Sylow p -subgroup of G , and the map from G to Aut( Q ) surjects onto H ? I think this is true (up to an isomorphism of G restricting to the identity on Q ), but I am worried about a consequence:$\newcommand{\Aut}{\operatorname{Aut}}\newcommand{\Fit}{\operatorname{Fit}}$ Let F be a finite nilpotent group, let H be a subgroup of Aut( F ), and for each prime p dividing the order of F , let F p ≤ E p be a Sylow p -subgroup of F contained in some finite p -group. Say that G is a model of $(H,E)$ if G is solvable, $F \unlhd G$, $C_G(F) \leq F$, the homomorphism from G to $\Aut(F)$ is surjective onto H , and each E p is a Sylow p -subgroup of G . Is it really true that given F , H , and E there is at most one (up to an isomorphism restricting to the identity on F ) model of $(H,E)$? In such a model, F is the largest nilpotent normal subgroup of G , and a theorem of Fitting guarantees that $G/Z(F) \cong H$, so of course $G/Z(F)$ is uniquely determined by H .  I had no idea G itself could be uniquely recovered if only ones knows the Sylow subgroups (assuming I am not wrong). If it is false, I would appreciate an example where F = Q is a p -group. If it is true, I would appreciate an older reference than 21st century topology, as surely this is “Fitting's other theorem.” A special case is clear: if F has vanishing second cohomology as an H -module, then G must be the semi-direct product.  In particular, if the orders of F and H are coprime, then of course G is uniquely determined. On the other hand, if the second cohomology does not vanish, then while multiple extensions can arise, in the examples I've seen, each extension is uniquely identified by its Sylow subgroups that intersect the Fitting subgroup non-trivially. I am not sure I understand how knowing the Sylows, but not knowing how they interact is sufficient to know the group.  A good answer (if it is true) might begin “but Jack we do know how they interact, because…”.","['finite-groups', 'group-theory', 'p-groups']"
97126,"If $1\leq p < \infty$ then show that $L^p([0,1])$ and $\ell_p$ are not topologically isomorphic","If $1\leq p < \infty$ then show that $L^p([0,1])$ and $\ell_p$ are not topologically isomorphic unless $p=2$. Maybe I would have to use the Rademacher's functions.","['lp-spaces', 'functional-analysis', 'banach-spaces']"
97130,"How to prove $(1-2x)^2=1/3+4/\pi^2\sum_1^\infty \cos(2n x \pi)/n^2$ for $x \in [0,1)$?","I tried to prove that
$$(1-2x)^2=1/3+4/\pi^2\sum_1^\infty \cos(2n x \pi)/n^2$$ for $x \in [0,1)$ with Fourier analysis, but I just found a Fourier series which defines the function. I also found the fourier series of $\cos(2n x \pi)$. I don't think these results are helpful. Any suggestions on how to prove this equation?","['fourier-series', 'fourier-analysis', 'analysis']"
97142,Compact subgroups of the general linear group,"Let $V$ be a finite-dimensional real linear space, and let $K$ be a compact subgroup of $GL(V)$ (with the usual topology); then is there a basis of $V$ such that every $f\in K$ is an orthogonal matrix under this basis?","['topological-groups', 'linear-algebra']"
97154,Evaluate the definite integral: $y(x) = \int_{0}^{\pi} \sin(x+y(x)) dx$,We were recently asked to evaluate this - $y(x) = \int_{0}^{\pi} \sin(x+y(x)) dx$ I think we can start by breaking up the integral as $y(x) = \int_{0}^{\pi} \sin(x)\cos(y(x)) dx + \int_{0}^{\pi} \cos(x)\sin(y(x)) dx$ and then assuming the form that $y$ would take as $y(x) = A\sin(x) + B\cos(x) + D$.,"['trigonometry', 'calculus', 'integral-equations']"
97171,"Cauchy Sequence in $X$ on $[0,1]$ with norm $\int_{0}^{1} |x(t)|dt$","In Luenberger's Optimization book pg. 34 an example says ""Let $X$ be the space of continuous functions on $[0,1]$ with norm defined as $\|x\| = \int_{0}^{1} |x(t)|dt$"". In order to prove $X$ is incomplete, he defines a sequence of elements in $X$ by $$ x_n(t) =
\left\{ \begin{array}{ll}
0 &  0 \le t \le \frac{1}{2} - \frac{1}{n} \\ \\
nt-\frac{n}{2} + 1 &  \frac{1}{2} - \frac{1}{n} \le t \le \frac{1}{2} \\ \\
1 & t \ge \frac{1}{2}
\end{array} \right.
 $$ Each member of the sequence is a continuous function and thus member of space $X$. Then he says: the sequence is Cauchy since, as it is easily verified, $\|x_n - x_m\| = \frac{1}{2}\left|\dfrac1n - \dfrac1m\right| \to 0$. as $n,m \to \infty$. I tried to verify the norm $\|x_n - x_m\|$ by computing the integral for the norm. The piecewise function is not dependent on $n,m$ on the last piece (for $t \ge 1/2$), so norm $\|x_n - x_m\|$ is 0. For the middle piece I calculated the integral, it comes up zero. That leaves the first piece, and I did not receive the result Luenberger has. Is there something wrong in my approach?","['functional-analysis', 'cauchy-sequences', 'analysis']"
97175,How would you input xkcd.com/287 into WolframAlpha?,"In this XKCD comic , a stick figure asks an NP-complete problem to order exactly 15.05 worth of appetizers out of a menu that includes the following list of prices: {2.15, 2.75, 3.35, 3.55, 4.20, 5.80} . What is the mathematical name and procedure for this kind of problem, and how would you input something like this to WolframAlpha if possible?","['np-complete', 'wolfram-alpha', 'popular-math', 'combinatorics']"
97182,Cauchy-Formula for Repeated Lebesgue-Integration,"Recently, I came across the following statements. They were annotated as consequences of Fubini's Theorem but neither proof nor reference were given. Let $f:[a,b]\times [a,b]\to\mathbb{R}$ be Lebesgue integrable. Then it holds:
$$
\int_a^b\int_a^y f(x,y)\,\mathrm{d}x\,\mathrm{d}y
=\int_a^b\int_x^b f(x,y)\,\mathrm{d}y\,\mathrm{d}x\text{.}
$$ Let $f:[a,b]\to\mathbb{R}$ be Lebesgue integrable and $x\in[a,b]$. Then it holds:
$$
\int_a^x\int_a^{x_1}\cdots\int_a^{x_{n-1}} f(x_n)\,\mathrm{d}x_n\cdots\,\mathrm{d}x_2\,\mathrm{d}x_1
=\int_a^x \frac{(x-t)^{n-1}}{(n-1)!}f(t)\,\mathrm{d}t\text{.}
$$ Proof: Let
$$g:[a,b]\times [a,b]\ni(x,y)
\mapsto\left\{\begin{array}{ll}
1 & \text{, }x\le y \\
0 & \text{, otherwise}\end{array}\right\}\in\mathbb{R}\text{.}
$$
Then $g$ is measurable since $g^{-1}(S)$ is open or closed for all $S\subseteq\mathbb{R}$. Since $g$ is non-negative, it is clearly Lebesgue integrable. Consequently, $h:=f g$ is Lebesgue integrable. By Fubini's Theorem it follows that
$$
\int_{[a,b]\times [a,b]} h(x,y)\,\mathrm{d}(x,y)
=\int_a^b\int_a^b h(x,y)\,\mathrm{d}x\,\mathrm{d}y
=\int_a^b\int_a^b h(x,y)\,\mathrm{d}y\,\mathrm{d}x\text{.}
$$
Finally,
$$
\int_a^b\int_a^b h(x,y)\,\mathrm{d}x\,\mathrm{d}y
=\int_a^b\int_a^b f(x,y) g(x,y)\,\mathrm{d}x\,\mathrm{d}y
=\int_a^b\int_a^y f(x,y)\,\mathrm{d}x\,\mathrm{d}y
$$
and
$$
\int_a^b\int_a^b h(x,y)\,\mathrm{d}y\,\mathrm{d}x
=\int_a^b\int_a^b f(x,y) g(x,y)\,\mathrm{d}y\,\mathrm{d}x
=\int_a^b\int_x^b f(x,y)\,\mathrm{d}y\,\mathrm{d}x
$$
conclude the proof. We proceed by induction with respect to $n$.
For $n=1$ the statement is trivial.
Assuming its correctness for $n=m-1\in\mathbb{N}$, we prove the statement for $n=m$. Application of the induction hypothesis yields
$$
\int_a^x\int_a^{x_1}\cdots\int_a^{x_{m-1}} f(x_m)\,\mathrm{d}x_m\cdots\,\mathrm{d}x_2\,\mathrm{d}x_1
=\int_a^x\int_a^{x_1} \frac{(x_1-t)^{m-2}}{(m-2)!}f(t)\,\mathrm{d}t\,\mathrm{d}x_1\text{.}
$$
We show that
$$
g:[a,x]\times [a,x]\ni(t,u)
\mapsto\frac{(u-t)^{m-2}}{(m-2)!}f(t)\in\mathbb{R}
$$
is Lebesgue integrable. First of all, $(t,u)\mapsto\frac{(u-t)^{m-2}}{(m-2)!}$ is Lebesgue integrable since it is continuous. Moreover, $(t,u)\mapsto f(t)$ is Lebesgue integrable as tensor product of Lebesgue integrable functions. Eventually, $g$ is Lebesgue integrable as product of Lebesgue integrable functions.
Finally, 1. yields
$$
\begin{align}
\int_a^x\int_a^{x_1}\cdots\int_a^{x_{m-1}} f(x_m)\,\mathrm{d}x_m\cdots\,\mathrm{d}x_2\,\mathrm{d}x_1
& =\int_a^x\int_t^x \frac{(x_1-t)^{m-2}}{(m-2)!}f(t)\,\mathrm{d}x_1\,\mathrm{d}t\\
& =\int_a^x\int_t^x \frac{(x_1-t)^{m-2}}{(m-2)!}\,\mathrm{d}x_1\,f(t)\,\mathrm{d}t\\
& =\int_a^x\frac{(x-t)^{m-1}}{(m-1)!}\,f(t)\,\mathrm{d}t.
\end{align}
$$ My questions: Is the proof correct and complete? Are the arguments unnecessarily complicated? Can the proof be simplified? How would you prove the statements? Do you know a reference of the statements in a textbook or scientific article? Edit: Corrections included.","['proof-writing', 'measure-theory', 'integration', 'analysis']"
97196,"Definition of ""point at infinity""","When looking for integral solutions of Diophantine equations there are sometimes trivial solutions. For example, in the Fermat equation $x^n+y^n=z^n$ such a solution is (1,0,1) and in the cubic equation $x^3+y^3=60z^3$ a trivial solution is (1,-1,0). In a paper these were called ""points at infinity"" of the corresponding curve. Given a projective variety, is there a general (best algebraic) definition of such points at infinity ?",['algebraic-geometry']
97201,Is the composition of blowing-up a blowing-up?,"Is the composition of blowing-up of algebraic varieties itself a blowing-up ? I think this is true but I am surprised not to have found any reference, though it seems to be an interesting property. Of course, I'm not able either to prove it myself... If one blows up quasi projective varieties, then the result is easy : since the composition is be a projective birationnal morphism, it is a blowing-up [Hartshorne, th 7.17, p. 166].
But what about the general case ? Edit In the late but very good answer of Lierre (!), it is claimed that “There exists a $p$ and an ideal sheaf $J\subset \mathcal O_{X_0}$ such that $J\cdot \mathcal O_{X_1} = E_0^p I_1$.” How to prove it ? I not sure we can patch the argument of the short answer.",['algebraic-geometry']
97213,How can a function have a vertical tangent and be continuous?,"I read somewhere that, ""a function with a vertical tangent may be continuous but not differentiable."" Is this correct and, if so, what is an example of it? I can't think how a function with an asymptote can be continuous.","['calculus', 'derivatives', 'limits']"
97215,Sylvester's Theorem and Schur Theorem,"I'll probably end up asking more programming questions on StackExchange forums than math questions, but I'll lead off with a math question. In my Number Theory class this past semester, I worked on a project on Bertrand's Postulate (aka Chebyshev Theorem) and came across this paper towards the end, but didn't have time to go through it. I find it very fun (because it uses very neat objects called Newton polygons which I hadn't heard of before) so I've looked at it over break, and I'm guessing it would be pretty easy for most people here to understand (though I think it's advanced enough that I didn't put it under elementary-number-theory based on topics listed for that).  So I was wondering if anyone would be interested in discussing it with me?  There are some things in it which I don't quite understand, but I could also maybe explain some things to others here if any of you would like; and that would help me know whether I truly understand what I think I do. Anyways, the areas where I'm confused are as follows: On page 10, it says: ""It is easy to see that there is no loss of generality in
restricting to $a_j = 1$ for $0 \le j \le m$.""  Am I correct in my thinking that, because $|a_0| = |a_m| = 1$ is a condition of the lemma rather than a conclusion of it, this sort of generalization is acceptable?  Which is also why it can later be stated that $b_j = m!/j!$, since it doesn't violate a restriction on $b_j$?  I hope that my question is clear. I'm a little fuzzy on the reasoning used in page 13 for why certain terms remain when deleting other terms.  Like when $k = 3$, is it true that we can conclude that either $x$ or $x-1$ must be $3$ because otherwise those three consecutive terms contain a prime factor larger than $3$ (a special case of Theorem 2 which obviously would've had to come from different reasoning)?  I think I'm missing something pretty obvious here, and I hope it doesn't have something to do with Bertrand's Postulate but I don't see how it would. On page 14 (under ""For this, we observe"") it states that $_xC_k$ equals the product of all $p^a$ for which $p \le k$.  I must be missing something here, because (for example) $_{22}C_{11}$ has 17 as a factor but $17 > 11$.  I'm accounting for the fact that $x \ge 2k$ and $k \ge 11$.  What else is there? On page 16, how are $17 \le k \le 29$ excluded by (2)?  Does that mean $_xC_k \ge _{4k}C_k$ fails to hold for all $x \ge 4k$ when $k$ is in that range?  And how would such verification be performed without testing all of those $x$, which is impossible. Finally, I wish either the proof of (b) or the proof of (c) would have been finished, as I'm thinking those are more similar than they are to the proof of (a).  I don't see how to finish (c) in a manner similar to (a), especially since I don't see another formula (besides the one at the end) relating $_xC_k$ to an expression in only $x$ the way it was related to an expression in only k for proving (a). If anyone could address any of these points, I would really appreciate it.  Have a nice day! :)","['prime-numbers', 'discrete-mathematics', 'binomial-coefficients', 'number-theory']"
97229,How many rationals of the form $\large \frac{2^n+1}{n^2}$ are integers?,"This was Problem 3 (first day) of the 1990 IMO. A full solution can be found here. How many rationals of the form $\large \frac{2^n+1}{n^2},$ $(n \in \mathbb{N} )$ are integers? The possible values of $n$ that i am able to  find is $n=1$ and $n=3$, so there are two solutions and this seems to be the answer to this problem. But now we have to prove that no more of such $n$ exists, and thus the proof reduces to: Proving that $n^2$ does not divides $2^n+1$ for any $n \gt 3$ . Does anybody know how to prove this?","['problem-solving', 'contest-math', 'number-theory']"
97232,$\frac 1 2$ in the definition of total variation distance between two probability measures,"From Wikipedia In probability theory, the total variation distance between two
  probability measures $P$ and $Q$ on a sigma-algebra $F$ is $$
     \sup\left\{\,\left|P(A)-Q(A)\right| : A\in F\,\right\}. $$ Informally, this is the largest possible difference between the
  probabilities that the two probability distributions can assign to the
  same event. For a finite alphabet we can write $$
     \delta(P,Q) = \frac 1 2 \sum_x \left| P(x) - Q(x) \right|\;. $$ Sometimes the statistical distance between two probability
  distributions is also defined without the division by two. I was wondering if there is some particular consideration when having that $\frac 1 2$ for the finite case, while not in the general case? 
My understanding of this total variation distance/metric is that it is induced from upper variation of the whole set (which is a norm if I am correct). From there, I can't see the need of dividing by 2. Also in the finite case, why not define similarly in terms of $\sup$ over $A \in F$? Thanks and regards!","['probability-theory', 'measure-theory']"
97236,Is this true about integrating composite functions?,"Let's say that I'm integrating a composite function, say $f(g(x))$, that is in a form to which I can apply the substitution rule.  Is it true to say that both $f$ and $g$ must be differentiable? I understand that the substitution rule requires $g$ to be differentiable and that the substitution rule relies on the chain rule, and the chain rule requires both f and g to be differentiable.","['calculus', 'integration', 'derivatives', 'limits']"
97250,Consecutive Coin Toss with static tosses,"I'm writing an algorithm for a coin toss problem. But I have a problem understanding the calculation given. Here is the question: You have an unbiased coin which you want to keep tossing until you get
  N consecutive heads. You've tossed the coin M times and surprisingly,
  all tosses resulted in heads. What is the expected number of
  additional tosses needed until you get N consecutive heads? If N = 2 and M = 0, you need to keep tossing the coin until you get 2
  consecutive heads. It is not hard to show that on average, 6 coin
  tosses are needed. If N = 2 and M = 1, you need 2 consecutive heads and have already have
  1. You need to toss once more no matter what. In that first toss, if you get heads, you are done. Otherwise, you need to start over, as the
  consecutive counter resets, and you need to keep tossing the coin
  until you get N=2 consecutive heads. The expected number of coin
  tosses is thus 1 + (0.5 * 0 + 0.5 * 6) = 4.0 If N = 3 and M = 3, you already have got 3 heads, so you do not need
  any more tosses. Now my problem is understanding the calculation: 1 + (0.5 * 0 + 0.5 * 6) = 4.0 when N = 2 and M = 1. I understood how they got the 6 (which is basically calculating it when M = 0, formula here ). Now what if I'm going to calculate N = 3, M = 1 or N = 3, M = 2 ? Could someone write this calculation in a formula for me please? What is the 1 ? What is (0.5 * 0 + 0.5 * 6) ?",['statistics']
97252,what are the normal subgroups of the group $S_3 \times S_3$?,Find all normal subgroups of $S_3 \times S_3$. What are normal subgroup and $S_3 \times S_3$? Could I have some examples?,"['group-theory', 'normal-subgroups']"
97261,Need Help: Any good textbook in undergrad multi-variable analysis/calculus?,"This semester, I will be taking a senior undergrad course in advanced calculus ""real analysis of several variables"", and we will be covering topics like: -Differentiability.
-Open mapping theorem.
-Implicit function theorem.
-Lagrange multipliers. Submanifolds.
-Integrals.
-Integration on surfaces.
-Stokes theorem, Gauss theorem. I need to know if anyone of you guys know  good textbooks that contain practice problems with full solutions or hints that can be used to understand the material. Most of the textbooks I found are covering only the material with few examples.","['multivariable-calculus', 'calculus', 'reference-request', 'real-analysis', 'analysis']"
97266,Definition of Affine Independence in Brondsted's Convex Polytopes?,"At one point in the book (An Introduction to Convex Polytopes, by Arne Brondsted) a definition of affine independence is given as follows, An n-family $(x_{1},...,x_{n})$ of points from $\mathbb{R}^d$ is said to be affinely independent if a linear combination $\lambda_{1} x_{1} + ... + \lambda_{n} x_{n}$ with $\lambda_{1} + ... + \lambda_{n} = 0$ can only have the value zero vector when $\lambda_{1}=...=\lambda_{n}=0$. It is my hunch that affine independence is analogous to linear independence in that, a set of vectors is (affinely/linearly) independent if none of the vectors is an (affine/linear) combination of the others. If this is the case, then what does the condition $\lambda_{1} +... +\lambda_{n} = 0$ have to do with anything? Shouldn't it be that the linear combination $\lambda_{1}x_{1} +...+\lambda_{n}x_{n}$, with $\lambda_{1} + ... +\lambda_{n} =1$ can only have the value zero vector when $\lambda_{1}=...=\lambda_{n}=0$?","['affine-geometry', 'linear-algebra']"
97283,Borel Measure such that integrating a polynomial yields the derivative at a point,"Does there exist a signed regular Borel measure such that $$ \int_0^1 p(x) d\mu(x) = p'(0) $$ for all polynomials of at most degree $N$ for some fixed $N$. This seems similar to a Dirac measure at a point. If it were instead asking for the integral to yield $p(0)$, I would suggest letting $\mu = \delta_0$. That is, $\mu(E) = 1$ iff $0 \in E$. However, this is slightly different and I'm a bit unsure of it. It's been a while since  I've done any real analysis, so I've forgotten quite a bit. I took a look back at my old textbook and didn't see anything too similar. If anyone could give me a pointer in the right direction, that would be great. I'm also kind of curious if changing the integration interval from [0,1] to all of $\mathbb{R}$ changes anything or if the validity of the statement is altered by allowing it to be for all polynomials, instead of just polynomials of at most some degree. Thanks!","['measure-theory', 'distribution-theory', 'analysis']"
97284,Intuition for Blow-up.,"If I blow up a complex manifold along a submanifold, can you give me a picture to have in mind for the blown-up manifold? Can you also tell me why this is the right picture?","['blowup', 'algebraic-geometry']"
97294,Effect the zero vector has on the dimension of affine hulls and linear hulls,"I am currently working through ""An Introduction to Convex Polytopes"" by Arne Brondsted and there is a question in the exercises that I would like a hint, or a nudge in the right direction, please no full solutions (yet)! The question is as follows, For any subset $M$ of $\mathbb{R}^d$, show that $\dim(\text{aff M}) = \dim(\text{span M})$ when $\textbf{0} \in \text{aff M}$, and $\dim(\text{aff M}) = \dim(\text{span M}) - 1$ when $\textbf{0} \notin \text{aff M}$. My general approach thus far has been to try and interpret the dimension of the affine hull aff $M$ in terms of the affine basis of $M$ and the linear hull span $M$ in terms of the linear basis of $M$. I tried to prove a lemma Let $L=(x_{1},...,x_{n})$ be the linear basis of $M$ and let $A=(x_{1},...,x_{k})$ be the affine basis of $M$. For any $M \subseteq \mathbb{R}^d$, $\dim(L)=\dim(\text{span M})=n$ and $\dim(A)=\dim(\text{aff M})=k-1$. I'm fairly certain that it is true, but I'm having trouble coming up with a rigorous proof. In any case, taking that lemma to be true I was able to come up with following attempt at a proof, We are guaranteed that there exists a linearly independent n-family $(x_{1},...,x_{n})$ of vectors from $M$ such that $\text{span M}$ is the set of all linear combinations $\sum_{i=1}^{n} \lambda_{i}x_{i}$; and that there exists an affinely independent k-family of $(x_{1},...,x_{k})$ of points from $M$ such that $\text{aff M}$ is the set of all linear combinations $\sum_{i=1}^{k} \lambda_{i} x_{i}$, with $\sum_{i=1}^{k} \lambda_{i} = 1$. This is equivalent to saying that for any $M \subseteq \mathbb{R}^d$, there exists a linear basis $L=(x_{1},...,x_{n})$ of $M$ and there exists an affine basis $A=(x_{1},...,x_{k})$ of $M$. We show that when $\textbf{0} \in \text{aff M}$ that $\dim(\text{aff M}) = \dim(\text{span M})$ and that when $\textbf{0} \notin \text{aff M}$ that $\dim(A) = \dim(L)$. By the lemma, this is equivalent to saying when $\textbf{0} \in \text{aff M}$ that $\dim(A)=\dim(L)$ and that when $\textbf{0} \notin \text{aff M}$ that $\dim(A)= \dim(L) -1$.
  Assume that for an arbitrary $M \subseteq \mathbb{R}^d$ that $\textbf{0} \in \text{aff M}$. We want to prove that $\dim(A)=\dim(L)$. Since $A=(x_{1},...,x_{k})$ is an affine basis of $M$, $A$ has dimension $k-1$ and since $L=(x_{1},...,x_{n})$ is a linear basis of $M$, $L$ has dimension $n$. We show that $k-1=n$. Since $\textbf{0} \in \text{aff M}$, then some affine combination from $M$ is equal to the zero vector. So, for $\lambda_{1}+...+\lambda_{k}=1$ we have that, 
  \begin{equation}
  \sum_{i=1}^{k} \lambda_{i} x_{i} =\sum_{i=1}^{k} \lambda_{i} \cdot \sum_{i=1}^{k} x_{i} = \sum_{i=1}^{k} x_{i} = 0
  \end{equation}
  [From here somehow relate this to a property of linear dependence or something else that shows $k-1=n$].
  Assume that for an arbitrary $M \subseteq \mathbb{R}^d$ that $\textbf{0} \notin \text{aff M}$. We want to prove that $\dim(A)=\dim(L)-1$, which is that $k-1 = n-1$, so $k=n$. [Try a similar approach to the first part if it ends up working and show that $k=n$].
  Therefore, $\dim(\text{aff M}) = \dim(\text{span M})$ when $\textbf{0} \in \text{aff M}$, and $\dim(\text{aff M}) = \dim(\text{span M}) - 1$ when $\textbf{0} \notin \text{aff M}$. I would appreciate some suggestions that have a fair bit of detail, but nothing like a full solution please. If you happen to be able to rip off a quick proof of the lemma I'd like to see that, and if it is wrong or useless please tell me! EDIT: I realize my other approach was a bit off. From the suggestion Robert gave I was able to construct the outline of the proof (I just need to actually show that either $B$ or $B \cup \textbf{0}$ is an affine basis of aff $M$ depending on the condition) as follows, Let $M$ be an arbitrary subset of $\mathbb{R}^d$. We want to show that if $\textbf{0} \in \text{aff M}$, then $\dim(\text{aff M}) = \dim(\text{span M})$ and that if $\textbf{0} \notin \text{aff M}$, then $\dim(\text{aff M}) = \dim(\text{span M}) - 1$. Since aff $M$ is an affine subspace of $\mathbb{R}^d$, then for an affine basis $A=(x_{1},...,x_{n})$ of aff $M$, $\dim(A)=\dim(\text{aff M})=n-1$. Similarly, since span $M$ is a linear subspace of $\mathbb{R}^d$, then for a linear basis $L=(x_{1},...,x_{n})$ of span $M$, $\dim(L)=\dim(\text{span M})=n$. So, we equivalently show for a linear basis $B$ of span $M$ that if $\textbf{0} \in \text{aff M}$, then $B \cup \{\textbf{0}\}$ is an affine basis for aff $M$ and that if $\textbf{0} \notin \text{aff M}$, then $B$ is an affine basis for aff $M$.
  Assume that $\textbf{0} \in \text{aff M}$ and that $B=(x_{1},...,x_{n})$ is a linear basis of span $M$. We want to prove that $B \cup \{\textbf{0}\}$ is an affine basis of aff $M$, since that would show $\dim(B \cup \{\textbf{0}\})=\dim(\text{aff M})=n$. Since $B$ is a linear basis of span $M$, then it would show that $\dim(B)=\dim(\text{span M})=n$, so we would have that $\dim(\text{aff M}) = \dim(\text{span M})$. [Show here that $B \cup \{\textbf{0}\}$ is an affine basis of aff $M$] .
  Assume that $\textbf{0} \notin \text{aff M}$ and that $B=(x_{1},...,x_{n})$ is a linear basis of span $M$. We want to prove that $B$ is an affine basis of aff $M$, since that would show $\dim(B)=\dim(\text{aff M})=n-1$. Since $B$ is a linear basis of span $M$, then it would show that $\dim(B)=\dim(\text{span M})=n$, so we would have that $\dim(\text{aff M})=\dim(\text{span M}) -1$. [Show here that $B$ is an affine basis of aff $M$] .
  Therefore, for any subset $M$ of $\mathbb{R}^d$, if $\textbf{0} \in \text{aff M}$ then $\dim(\text{aff M}) = \dim(\text{span M})$, and if  $\textbf{0} \notin \text{aff M}$ then $\dim(\text{aff M}) = \dim(\text{span M}) - 1$. Given that I can prove the condition for the affine basis in each case, would this be a complete proof? I'm still working on showing the condition, but I want to know if the construction of the proof is correct. Thanks! SECOND EDIT:
I have posted an attempted proof as an answer, please comment on it and let me know if it is correct.","['affine-geometry', 'convex-analysis', 'linear-algebra']"
97308,Zorn's Lemma And Axiom of Choice,How can I prove Zorn's lemma is equivalent to Axiom of choice?,"['elementary-set-theory', 'axiom-of-choice']"
97319,some confusion about the concept of gradient,"I think everyone should know the directional derivatives $D_vf=\nabla f\cdot v$ but actually why this is true? As I know,the derivatives is $\displaystyle\lim_{h\rightarrow 0} \frac{f(x+h)-f(x)}{h}$ but this is a scalar not a vector. So why is that true?","['multivariable-calculus', 'calculus']"
97333,Why is $\mathbb{F}_{p}\subseteq\mathbb{F}_{p^{k}}$ a field extension?,"In our algebra course our professor said, during a the beginning of
a chapter on field extension, that $\left[\mathbb{F}_{p^{k}}:\mathbb{F}_{p}\right]=k$
(where $p$ is obviously prime). My question is: Why can we even assume that $\mathbb{F}_{p}$ is a subfield of $\mathbb{F}_{p^k}$ ? $\mathbb{F}_{p}$
isn't closed under the restriction of the multiplication in $\mathbb{F}_{p^{k}}$
to $\mathbb{F}_{p}$, so $\mathbb{F}_{p}$ doesn't form a subfield
(for example, for $1,2\in\mathbb{F}_{3}\subseteq\mathbb{F}_{3^{2}}$
we have that $2+1=3\in\mathbb{F}_{3^{2}}$ and not $0$, as we should
obtain in $\mathbb{F}_{3}$), so in my opinion we can't even talk
about $\left[\mathbb{F}_{p^{k}}:\mathbb{F}_{p}\right]$, since we
defined this only for field extension (I realize that we still can
talk about $\left[F:G\right]$, if we define this in a more general
way just for fields $F,G$ such that $F$ is a $G$-vector space;
but in that case I would be annoyed by the slopiness of our course).","['abstract-algebra', 'field-theory']"
97351,How to recognize a pigeonhole problem?,"I'm going to split this into 2 questions, the first I think might have an answer, the second may not. First, is there a general way to recognize a pigeonhole problem as such?  I mean are there some general traits which characterize a pigeonhole problem? Second, once you've recognized the type of problem, is there a systematic way of figuring out what the holes and pigeons are, or is it just a eureka kind of thing?","['pigeonhole-principle', 'combinatorics']"
97356,"Is the space $C[0,1]$ complete?","In order to prove $C[0,1]$ is complete, my functional analysis book says: It is only necessary to show that every Cauchy sequence in $C[0,1]$ has a limit. It goes on by supposing $\{x_n\}$ is a Cauchy sequence in $C[0,1]$ . Then for each fixed $t \in [0,1]$ $|x_n(t)-x_m(t)| \le \|x_n - x_m\| \to 0$ , so $\{x_n(t)\}$ is a Cauchy sequence of real numbers. I guess this inequality makes sense, since difference of function sequences would be larger than pointwise difference (at a specific $t$ ) of those functions.. But I did not understand how the author could conclude the sequence $\{x_n(t)\}$ is Cauchy. Second question: the explanation continues, ""Since the set of real numbers is complete, there is a real number $x(t)$ to which the squence converges; $x_n(t) \to x(t)$ "". I know set of real numbers is complete, but how can $\{x_n(t)\}$ represent the entire set of real numbers?","['convergence-divergence', 'functional-analysis', 'real-analysis']"
97362,Justification of algebraic manipulation of infinitesimals,"As an engineering student, I regularly see people making arguments like this: Consider a rectangle of dimensions $x\times 4x$. If we make $x$ bigger by a small quantity $dx$ then this will make $4x$ bigger by $4\cdot dx$ so the area of that $x \times 4x$ rectangle will change from $4x^2$ to $$(x+dx)(4x+4dx)=4(x^2+2x\cdot dx+(dx)^2)\approx4x^2+8x\cdot dx$$
with the final step justified because $dx$ is a 'small' quantity so $(dx)^2$ will be so small as to be ignorable in some mathematically rigorous way. Thus the change in area $dA$ would be $8x\cdot dx$. Arguments like this are very common. Another random example would be in Wikipedia's proof of the brachistochrone problem which starts with the statement $$ds^2=dx^2+dy^2$$ and proceeds to manipulate these infinitesimals as if they were ordinary constants or variables. I'm wondering if there's a simple, analytically rigorous justification for all of this manipulation. While I feel perfectly comfortable with the idea of the derivative of a function (considered as a limit), I've never seen a similar, rigorous justification for the algebraic manipulation of infinitesimals and the cancellation of 'small' terms (like $(dx)^2$). Any thoughts or help would be appreciated. Thankyou","['calculus', 'infinitesimals']"
97390,"Function theory: codomain and image, difference between them","Can't figure out the difference between them. I have read wiki article about codomains and images , but what is the difference? It seems confusing the examples part in codomain article. How can we claim this: $f: \mathbb R \to \mathbb R$, where $f(x) = x^2$? This function will never assume negative number, so why the codomain is R? After all, the authors might have gone even further and claim that codomain is the set of complex numbers!","['terminology', 'functions']"
97397,"pigeonhole principle: at least 1 match/hr for 75 hrs, at most 125 matches, then exactly 24 matches in some interval","This is for self-study. This question is from Rosen's ""Discrete Mathematics And Its Applications"", 6th edition. An arm wrestler is the champion for a period of 75 hours. (Here, by an hour, we mean a period starting from an exact hour, such as 1 P.M., until the next hour.) The arm wrestler had at least one match an hour, but no more than 125 total matches. 1 - Show that there is a period of consecutive hours during which the arm wrestler had exactly 24 matches. 2 - Is the statement in the previous exercise true if 24 is replaced by a) 2? b) 23? c) 25? d) 30? My solution to part 1 is the following, based on Rosen's solution to a similar problem given as example in the text: 1 - If I consider $a_i$ to be the number of competitions until the $i^{th}$ hour, then, $1\leq a_1<a_2<\cdots<a_{75}\leq 125$, because there are no more than 75 hours and the total number of competitions is no more than 125. Now I will add 24 to all the terms of the above inequality: $25\leq a_1+24<a_2+24<\cdots<a_{75}+24\leq 149$. There are 150 numbers $a_1,\cdots,a_{75},a_1+24,\cdots,a_{75}+24$. By the inequalities above, these numbers range from 1 to 149. Then, by the pigeonhole principle, at least two of them are equal (in a list of 150 integers ranging from 1 to 149, at least two are equal). Because all the numbers $a_1,\cdots,a_{75}$ are distinct, and all numbers $a_1+24,\cdots,a_{75}+24$ are also distinct, it follows that $a_i = a_j + 24$ for some $i > j$. Therefore, from the $(j+1)^{th}$ hour to the $i^{th}$ hour, there were exactly 24 competitions. Now, I will show the attempt at a solution for part 2: 2 - a) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 2 to all terms: $3\leq a_1 + 2<a_2 + 2<\cdots<a_{75} + 2\leq 127$ So, there are 150 numbers that range from 1 to 127. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{127} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 2$. This guarantees that there is a period of consecutive hours during which there were exactly 2 competitions. b) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 23 to all terms: $24\leq a_1 + 23<a_2 + 23<\cdots<a_{75} + 23\leq 148$ So, there are 150 numbers that range from 1 to 148. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{148} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 23$. This guarantees that there is a period of consecutive hours during which there were exactly 23 competitions. c) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 25 to all terms: $26\leq a_1 + 25<a_2 + 25<\cdots<a_{75} + 25\leq 150$ In this case, there are 150 numbers that range from 1 to 150. So, there are not necessarily two equal numbers. Therefore, we can't conclude anything directly. But it is possible to show that the statement is not true for 25, because an explicit counter-example (suggested below in the comments) can be found. Suppose the number of matches until each one of the 75 hours is, respectively: $\{1,2,\cdots,25,51,\cdots,75,101,\cdots,125\}$. Here, there are no pairs of numbers whose difference is 25. d) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 30 to all terms: $31\leq a_1 + 30<a_2 + 30<\cdots<a_{75} + 30\leq 155$ In this case, there are 150 numbers that range from 1 to 155. So, we can't apply the pigeonhole principle here, similarly to the above situation. It is not easy to find a counter-example in this case; I think that, for 30, the statement is always true (that is, there is always a period of consecutive hours during which there were exactly 30 matches). But I'm not sure how to prove it. Edit : I think I found a way to prove it, based on the suggestion given by Lopsy; I've included it as an answer to this question. Thank you in advance.","['pigeonhole-principle', 'discrete-mathematics', 'combinatorics']"
97408,Probability measures on a Polish space,"Let $X$ be a Polish space, that is a separable metric complete topological space. Is the space of Borel probability measures on $X$, equipped with its weak topology, is Polish too ? It is metric, but what about completeness and separability ?","['general-topology', 'probability', 'probability-theory']"
97409,Evaluating $\int\sqrt{150^2-x^2} \cdot dx$,"I'm studying for my finals and I have this integral that I'm trying to evaluate ( part of a bigger problem ): $$\int\sqrt{150^2-x^2} \cdot dx$$ I have evaluated a few integrals of this type before so the first thought that came to my mind was to substitute $x = \sin t$ and $dx = \cos t \cdot dt$. So now I have: $$\int \sqrt{150^2-\sin^2t} \cdot \cos t \cdot dt$$ However, here is where I'm getting stuck. Usually instead of having $150^2$ I have $1$, and by using $1-\sin^2t = \cos^2t \space$ I can continue, but not in this case. How should I go on?","['trigonometry', 'calculus', 'integration']"
97413,On the product of $\mathfrak c$-many separable spaces,"I already figured out how to show that the countable product of separable topological spaces is separable,  but I'm out of ideas when the index set has cardinality of $\mathfrak c$. My textbook says it is possible but gives no references. Any suggestions how to prove this statement? In a less general setting, I would also be interested to see how a dense countable set is constructed to $\mathbb{R}^{\mathbb{R}}$. Thanks in advance.","['general-topology', 'separable-spaces', 'product-space']"
97435,Any good Graduate Level linear algebra textbook for practice/problem solving?,"I am looking for good graduate linear algebra books that contain practice problems with solutions (which is better) or hints to solve the problems. By the way, two graduate courses I am gonna take are a continuation of the undergrad course I have already taken based on the textbook: ""Linear Algebra: A modern Approach"" by ""D.Poole"". I did find some textbooks that cover the material, like: ""Linear Algebra done right"", ""Linear Algebra done wrong"", etc and some of these books suggest few problems without given solutions. So, I need books with many solved problems (or hints) that help me to practice what I will learn in the lecture and to ensure I well understand the material. Any suggestion is more than welcome. Thanks","['linear-algebra', 'book-recommendation', 'reference-request']"
97437,"When two functions are equal, but not.","I haven't looked into it much, but this is something I've been aware of that I know I need to look into. When I have a function $f(x)=\frac{x+1}{x+1}$, There is a discontinuity at $x=-1$, yet $\frac{x+1}{x+1}=1$ and has no discontinuity.  It's like they're equal but not. The qualities of the function are not preserved after the algebraic manipulation, so I can't strictly say that $\frac{x+1}{x+1}=1$. This is an issue for me when understanding integrals.  For instance, finding the definite integral of the quotient, if the discontinuity is within my limits, doesn't make sense.  But after changing the quotient to a constant, it's possible: but I've found the area under a curve that wasn't complete.  I've found a solution for an unanswerable, insensible question. I hope I've made this clear.  My question is, is this right?  How do I come to terms with this?","['calculus', 'integration', 'limits']"
97440,Do limits of sequences of sets come from a topology?,"In measure theory we frequently see the following definitions: $$\limsup_{n\to\infty} A_n = \bigcap_{n=1}^{\infty}\left(\bigcup_{j=n}^{\infty} A_j\right)$$ $$\liminf_{n\to\infty} A_n = \bigcup_{n=1}^{\infty}\left(\bigcap_{j=n}^{\infty} A_j\right)$$ where $(A_n)_n$ is a sequence of measureable sets i.e. $\forall n: A_n\in\mathcal{M}$, where $\mathcal{M}$ is a $\sigma$-algebra on $X$, for example $\mathcal{M} = 2^X$. Therefore it makes sense to also define: $$\lim_{n\to\infty}A_n = \limsup_{n\to\infty} A_n = \liminf_{n\to\infty} A_n$$ when the last two agree. If $\mu$ is a finite (positive, to keep things simple) measure, it is easy to see that under such definition we have $\mu(\lim_{n\to\infty}A_n) = \lim_{n\to\infty}\mu(A_n)$, whenever $\lim_{n\to\infty}A_n$ exists, which looks like some kind of continuity. Does this kind of convergence of sequences of measurable sets arise from a (preferably Hausdorff, so that limits are unique) topology on $\mathcal{M}$? If such a topology exists, is $\mu:\mathcal{M}\to[0,\infty)$ in fact a continuous function? (A related question that may be of interest would be: what happens if we allow arbitrary sets? Can we make the Von Neumann universe $V$ into a topological space in such a way?)","['general-topology', 'measure-theory', 'limsup-and-liminf']"
97450,Question about singularities and path integrals,"I'm given a vector field that has an obvious singularity at a point $(a,b)$.  In order to learn more about the singularity I place a circle around it with the singularity at it's center.  The line integral for the field across the circle gives me $18\pi \,r$.  What conclusion can I get from the solution to the line integral?",['calculus']
97460,Number of subgroups of prime order,"I've been doing some exercises from my introductory algebra text and came across a problem which I reduced to proving that: The number of distinct subgroups of prime order $p$ of a finite group $G$ is either $0$ or congruent to $1\pmod{p} $. With my little experience I was unable to overcome this (all I was able to conclude is that these groups are disjoint short of the identity), and also did not find any solution with a search on google (except for stronger theorems which I am not interested in because of my novice level). I remember that a similar result is widely known as one of Sylow Theorems. This result was proven by the use of group actions. But can my problem be proved without using the concept of group actions? Can this be proven WITH the use of that concept? EDIT: With help from comments I came up with this: The action Derek proposed is well-defined largely because in a group if $ab = e$ (the identity), then certainly $ba = e$. By Orbit-Stabilizer Theorem we can see that all orbits are either of size 1 or $p$ (here I had most problems, and found out cyclic group of order $p$ acts on the set of solutions in the same way).
The orbits of size 1 contain precisely the elements $(x,x,x....,x)$ for some element x in G. In addition, orders of all orbits add up to $|G|^{(p-1)}$ because the orbits are equivalence classes of an equivalence relation.
But certainly $(e,e,e....,e)$ is in an orbit of size 1, and that means there has to be more orbits of exactly one element, actually $p-1 + np$ more for some integer $n$. These elements form the disjoint groups I am looking for. if $p-1$ divides $(p-1 + np)$, it's easy to check the result is 1 mod p. Could someone check if I understood this correctly?","['self-learning', 'finite-groups', 'group-theory', 'abstract-algebra']"
97471,The incenter and Euler line.,"It seems well known that the incenter of a triangle lies on the the Euler line if and only if the triangle is isosceles (or equilateral, but that is trivial). Searching the internet, I could not find a simple geometric proof of this fact. Can anyone provide such a proof? Also, when the incenter lies on the Euler line, does it do so in a set location? (For example, we know the centroid is a third of the way from the circumcenter to the orthocenter on the Euler line, does the incenter satisfy any nice ratios like that?)","['geometry', 'triangles']"
97480,Is the limit of a sequence of biholomorphisms surjective?,"I wondered about the following some time ago: Let $\Omega \subsetneq \mathbb C$ be a domain. Let $\psi_n: \Omega \to \Omega$ be a sequence of biholomorphisms converging to some $\psi$ locally uniformly on $\Omega$. Is $\psi$ necessarily surjective? Some observations: We have $\psi_n(z) = \frac{z}{n}$ as a counterexample on $\Omega = \mathbb C$. There is a biholomorphism $\phi$, which maps $\Omega$ into the unit disc $\mathbb D$. So considering $$(\phi\circ \psi_n\circ \phi^{-1}): \phi(\Omega) \to \phi(\Omega)$$
we can reduce the general case to the case of $\Omega \subset \mathbb D$ being bounded. Assuming $\Omega$ to be bounded: The derivatives $\psi'_n$ of $\psi_n$ also converge locally uniformly to $\psi'$, so 
$$
\begin{align}
\mu(\psi(\Omega)) &= \iint_{\Omega} |J_{\psi}(z)| \; \mathrm dx\,\mathrm dy \\
&\ne \lim_{n\to \infty} \iint_{\Omega} |J_{\psi_n}(z)| \; \mathrm dx\,\mathrm dy \\
&= \lim_{n\to \infty} \iint_{\psi_n(\Omega)} \; \mathrm dx\,\mathrm dy \\
&= \mu(\Omega)
\end{align}  $$ 
i.e. $\psi$ is 'almost surjective'. I don't know how one might proceed from here (I hope I haven't made a mistake in my obeservations). I'd be interested to see an answer to this question. =)",['complex-analysis']
97509,Why doesn't this work imply that there are countably many subsets of the naturals?,"Cantor's theorem shows us that the power set of the natural numbers is uncountably infinite. But today (and before remembering Cantor's proof) I was trying to prove the incorrect version: that the power set of the natural numbers is actually countably infinite. My work obviously has to be wrong, so I'm hoping that someone can spot a false implication. So, to prove that the set of natural numbers is of the same cardinality as the power set of the natural numbers, I intend to show that a bijection $f: \mathcal{P}(\mathbb{N}) \to \mathbb{N}$ exists. Now, it suffices for $f$ to be injective; Afterwards, we can just sort the image of $f$ and number the results starting from 1 to make it surjective as well. So here is my $f$: For any set $A$ consisting of natural numbers, $$f(A) = p_1^{\delta(1)}p_2^{\delta(2)}p_3^{\delta(3)}\cdots$$
where $p_i$ is the $i$-th prime number and 
$$
\delta(x) = 
\begin{cases}
1, &  x\in A\\ 
0, & x\not \in A 
\end{cases}
$$ So, as an example, if $A = \{1,3,4\}$, then $f(A) = 2^1\cdot5^1\cdot7^1 = 70$.
This function should be one-to-one, since each integer has a unique prime factorization. Therefore, any set in $\mathcal{P}(\mathbb{N})$ will be associated with a unique natural number. We sort these natural numbers are re-number them starting with 1, producing a bijection between the power set of naturals and the naturals, meaning that the power set of the naturals is actually countably infinite. But this is wrong. Where is the weakness in my proof?",['elementary-set-theory']
97518,Ring with subring isomorphic to $\mathbb{Z}$ and subring isomorphic to $\mathbb{Z}_{3}$,"This is a homework question that I'm either not thinking through all the way, or I'm overcomplicating the issue. It reads Give an example of a ring that contains a subring isomorphic to $\mathbb{Z}$ and a subring isomorphic to $\mathbb{Z}_3$. My quick answer is that $\mathbb{Z}_3 \oplus \mathbb{Z}$ is such a ring. We can take $R = \{(a,0) | a \in \mathbb{Z}_3\}$ to be a subring isomorphic to $\mathbb{Z}_3$ and $S = \{(0,a) | a \in \mathbb{Z}\}$ to be a subring isomorphic to $\mathbb{Z}$. Is there something crucial I'm missing here, or is the problem really that simple?","['ring-theory', 'abstract-algebra']"
97527,Probability that ace of spades is at bottom of deck IF ace of hearts is NOT at top,"What is the probability that the ace of spades is at the bottom of a standard deck of 52 cards given that the ace of hearts is not at the top? I asked my older brother, and he said it should be $\frac{50}{51} \cdot \frac{1}{51}$ because that's $$\mathbb{P}(A\heartsuit \text{ not at top}) \times \mathbb{P}(A\spadesuit \text{ at bottom}),$$ but I'm not sure if I agree. Shouldn't the $\frac{50}{51}$ be $\frac{50}{52}$? Thanks you!",['probability']
97537,Defining addition of supernatural numbers?,"In the comments on this question Bill Dubuque mentions the supernatural numbers .   My curiosity was piqued by the statement on Wikipedia that ""there is no natural way to add supernatural numbers"" and I soon invented this example: Let $a$ be the supernatural product of all primes congruent to 1 mod 4, and let $b$ be the supernatural product of all primes congruent to 3 mod 4.  Because GCD is defined for supernatural numbers, and the sum of two relatively prime numbers is relatively prime to each of them, we can say that $2a + b = 1$ and also that $a + 2b = 1$; adding these gives $3a + 3b = 2$ or $a + b = \frac{2}{3}$.  The value $\frac{2}{3}$ can apparently be interpreted as a ""super-rational"" number, a supernatural-like number where negative exponents are permitted.  So it seems  that I can give a consistent definition of addition at least for some supernatural numbers (although the result in this case is ""super-rational""). What is the basis of the claim that ""there is no natural way to add supernatural numbers""?  Do the assumptions underlying my idea lead to any contradiction?  If not, to what extent can it be extended to allow the addition of more general forms? EDIT: I hadn't read the article closely enough to realize that supernatural numbers are allowed to have exponent values of $\infty$, and also it has been pointed out that my idea does not work in any case.  What remains of this question I feel is too unfocused.  I am accepting Greg Martin's answer.","['prime-numbers', 'number-theory']"
97541,When can the maximal sigma algebra be generated by all singleton subsets?,"The maximal sigma algebra on a set is its power set. When the set is countable, its maximal sigma algebra can be generated by all singleton subsets, i.e. subsets each consisting of exactly one element. Conversely, if the maximal sigma algebra on a set can be generated by all singleton subsets, must the set be countable? Thanks and regards!",['measure-theory']
97544,What the implicit function theorem is actually showing,"Theorem : Let $F: X\subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ be of class of $C^1$ and let $a$ be a point of the level set $S=\{x\in\mathbb{R}^n \mid F(x)=c\}$. If $F_{x_n}(a)\neq 0$ then there is a neighborhood $U$ of $(a_1,a_1\dots a_{n-1}) \in \mathbb{R}^{n-1}$, a neighborhood $V$ for of $a_n\in\mathbb{R}$ and a function $f:U\subseteq\mathbb{R}^{n-1} \rightarrow V$ of class $C^1$ such that if $(x_1,x_2,\ldots,x_{n-1})\in U$ and $x_n \in V$ satisfy $F(x_1,x_2,\ldots,x_n)=c$ ,then $x_n = f(x_1,x_2,\ldots,x_{n-1})$ is representable as a function of $(x_1,\ldots,x_{n-1})$ . I don't quite get what the theorem is trying to show. Can someone explain it? Is it just as simple as we just consider different part of the function?",['multivariable-calculus']
97548,Does $\sum_{n=1}^{\infty} \sin(\pi(2+\sqrt{3})^n)$ converge? Converge absolutely? [duplicate],"This question already has answers here : Consider convergence of series: $\sum_{n=1}^{\infty}\sin\left[\pi\left(2+\sqrt{3}\right)^n\right]$ (3 answers) Closed 4 years ago . Per the title, does $\displaystyle\sum_{n=1}^{\infty} \sin(\pi(2+\sqrt{3})^n)$ converge? Converge absolutely? I'm stuck on this question, not sure how to approach it. Thank you!","['convergence-divergence', 'sequences-and-series']"
97558,Prove: Fourier series of $e^{\cos x} \sin (\sin x)$ is $\sum_{n=0}^{\infty}\frac{\sin (nx)}{n!}$,I'd love your help with proving that the following series  $$\sum_{n=0}^{\infty}\frac{\sin (nx)}{n!}$$ is the Fourier series of $e^{\cos x}  \sin (\sin x)$. I tried to find $\hat f(n)$ using integration by parts and I tried to use Taylor's series of $e^x$ in order to get $n!$ by I didn't reach to anything close of what I should. Thanks a lot.,"['fourier-series', 'fourier-analysis', 'calculus']"
97560,Numerically Efficient Approximation of cos(s),"I have an application where I need to run $\cos(s)$ (and $\operatorname{sinc}(s) = \sin(s)/s$) a large number of times and is measured to be a bottleneck in my application. I don't need every last digit of accuracy: $10^{-10}$ over an input range of $[-15^\circ < s < 15^{\circ}]$ should be sufficient (This is the limit of the input sensor data). I have implemented a simple Taylor approximation, but would like to ask: (a) Is there a more efficient approximation? (b) If Taylor is the most efficient, is there a better way to implement it? // Equation Coefficients
double s_2  = 0.25 * omega_ebe.squaredNorm();
double s_4  = s_2 * s_2;
double s_6  = s_4 * s_2;
double s_8  = s_6 * s_2;
double s_10 = s_8 * s_2;

double cos_coef  = 1.0 - s_2 /  2.0 + s_4 /  24.0 - s_6 /   720.0 + s_8 /  40320.0 - s_10 /  3628800.0;
double sinc_coef = 0.5 - s_2 / 12.0 + s_4 / 240.0 - s_6 / 10080.0 + s_8 / 725760.0 - s_10 / 79833600.0; EDIT: I haven't forgotten to select an answer! I'm going to code a few of the up and run them on target (an embedded PowerPC and an embedded ARM) to see how they perform.","['trigonometry', 'approximation', 'numerical-methods']"
97564,Is the matrix exponential map injective?,Is the matrix exponential $exp:M_n(\mathbb C) \to GL_n(\mathbb C)$ injective? Can it be that $e^A=I$ where $A$ is not the zero matrix?,"['matrices', 'linear-algebra']"
97568,Calculating $\sin(10^\circ)$ with a geometric method,"Excuse me if this is a simple question: What is a simple geometric method for calculating $\sin(10^\circ)$ using only the sines of $30^\circ$, $45^\circ$, $60^\circ$ and $90^\circ$? Generally, is there any geometric solution for this problem or should we use algebra?","['geometry', 'trigonometry']"
97587,Solution of a polynomial of degree n with soluble galois group.,"Background: Given the fundamental theorem of algebra every polynomial of degree n has n roots. From Galois Theory we know that we can only find exact solutions of polynomials if their corresponding Galois group is soluble. I am studying Galois Theory ( Ian Stewart ) and I am not getting the result out of it that I expected. I expected to learn to determine for a polynomial of degree n its corresponding Galois group, and if it that group is soluble a recipe to find the exact roots of that polynomial. My experience thus far with Galois Theory is that it proves that there is no general solution for a polynomial of degree 5 and higher. Question: I want to learn to solve polynomials of degree 5 and higher if they have a corresponding soluble Galois group. From which book or article can I learn this?",['abstract-algebra']
97589,Graphing Inequalities in Two Variables,"When we have to graph an inequality in two variables, we usually graph the corresponding equality, i.e. the straight line on the coordinate plane, which divides the plane into two parts. Then, we use a so-called 'test point' to decide which of the two parts represents the inequality. So, here we clearly assume that one of the two parts formed by the straight line represents the '>' inequality, whereas the other part represents the '<' inequality. Is there any rigorous proof that can show that this is indeed the case? Thanks.","['inequality', 'algebra-precalculus', 'graphing-functions']"
97620,Probability of either dice showing a specific number,"If I throw 4 dice together, what is the probability that either one of them will show the number 3 ?
I tried to calculate it and got to $\frac{(4)}{6}$ (which is highly unlikely to be correct).. any ideas?","['dice', 'probability', 'combinatorics']"
97628,Distance from $x^n$ to lesser polynomials,"I am interested in the $L_1$ distance of $x^n$ to the $\mathbb R$-span of $\{1,x,\ldots,x^{n-1}\}$ over some interval. We can WLOG consider the interval $[0,1]$ (say) because scaling and shifting only affects the distance by a constant factor. So far we have these basic results: Theorem $x^n$ is not in the $\mathbb R$-span of $\{1,x,\ldots,x^{n-1}\}$ Proof Suppose it was: $x^n = \sum_{i=0}^{n-1} a_i x^i$. Differentiate $n$ times to get the contradiction $n! = 0$. We can rephrase this theorem as saying that $\| x^n - p(x) \| > 0$ for all polynomials of degree $< n$. Theorem There is no sequence of polynomials in the span, with limit $x^n$. Proof We would have a sequence $p_n(x) = \sum_{i=0}^{n-1} a_{i,n} x^i$ where $x^n = \lim_{n \to \infty} p_n(x) = \sum_{i=0}^{n-1} (\lim_{n \to \infty} a_{i,n}) x^i$, but that is a contradiction. Together with the previous result this implies there should be some positive $h(n)$ such that $\| x^n - p(x) \| > h$. My question is about finding some $h$. How could we go about doing this? Are there relevant theorems? My first idea was that we might use induction and find some way of saying: Since we can only get within $r$ of the derivative we can only get within $h(r)$ of the function itself.. but finding $h(r)$ seems just as hard as finding $h$ at all.","['approximation-theory', 'real-analysis', 'polynomials']"
97648,Why is $L^{\infty}$ not separable?,"$l^p (1≤p<{\infty})$ and $L^p (1≤p<∞)$ are separable spaces. What on earth has changed when the value of $p$ turns from a finite number to ${\infty}$? Our teacher gave us some hints that there exists an uncountable subset such that the distance of any two elements in it is no less than some $\delta>0$. Actually I don't understand the question very well, but I hope I have made the question clear enough. Thank you in advance.","['functional-analysis', 'separable-spaces', 'normed-spaces', 'real-analysis', 'lp-spaces']"
97653,What contour should be used to evaluate $\int_0^\infty \frac{\sqrt{t}}{1+t^2} dt$,"Could anyone help me decide what contour to use to evaluate this integral? $$\int_0^\infty \frac{\sqrt{t}}{1+t^2} dt$$ So we have simple poles at $i$,$-i$. Why does using a quarter of a circle in the upper right quadrant not work -is it a problem having $i$ on the contour of integration? My second idea was to let
$$\sqrt{t}=e^{\frac{1}{2}\operatorname{log}t}$$ And defining the branch of the logarithm to be the negative imaginary axis. Then using an upper semi-circular contour. With a hole at 0, which will tend to the point 0 as the radius of the semi circle tends to infinity. Then we'll divide by two to get the integral from $0$ to $\infty$. Does this work, as this does not seem to be an even function we're integrating. I apolygise for the poor explanation of my contours, it's quite difficult without pen and paper! EDIT: Ok, so using an upper semi circle, with a semicircular hole about $0$. let us call the contour $\gamma$, we have: $$\int_\gamma \frac{e^{\frac{1}{2}\operatorname{log}t}}{1+t^2}dt =2\pi i\Big(\frac{e^{\frac{1}{2}\operatorname{log}t}}{t+i}\Big)\Big|_{t=i}=\frac{e^{\pi/4}}{2i}$$ But by letting on the positive real axis $z=x+iy$ implies $log(z)=log(x)+0$ and on the negative axis $log(z)=log(x)+\pi$ Therefore if we tend the large arc's radius to infinity and the small arc about the origin's radius to zero we find the integral along the arc tends to zero. So $$\int_\gamma \frac{e^{\frac{1}{2}\operatorname{log}t}}{1+t^2}dt=\int_0^\infty \frac{\sqrt{x}}{1+x^2} dx+\int_0^\infty \frac{\sqrt{x}e^{\pi/2}}{1+x^2} dx=(1+e^{\pi/2})\int_0^\infty \frac{\sqrt{x}}{1+x^2} dx$$ $$\Rightarrow \int_0^\infty \frac{\sqrt{x}}{1+x^2} =\frac{e^{\pi/4}}{2i(1+e^{\pi/2})}$$ This is wrong but can anyone point out what mistake I have made here?","['integration', 'complex-analysis', 'contour-integration']"
97654,Is $\sin^3 x=\frac{3}{4}\sin x - \frac{1}{4}\sin 3x$?,$$\sin^3 x=\frac{3}{4}\sin x - \frac{1}{4}\sin 3x$$ Is there any formula that tells this or why is it like that?,['trigonometry']
97655,Local-Global Principle and the Cassels statement.,"In a recent article I have read, i.e. "" Lecture notes on elliptic curves "", Prof.Cassels remarks in page-110 that There is  not merely a  local-global principle for  curves of genus-$0$, but 
  it has  a  quantitative  formulation  ( and also,  more generally for  linear 
  algebraic groups.  The modern formulation is  in terms of the "" Tamagawa 
  number  "" ) . Can any person please help me in understanding the above sentence by expanding it in more clear words, I mean I am looking for an explanation that how can the Modern-Formulation of Tamagawa Number act as a Local-Global Principle. But I never have any view how can one use the Tamagawa-number as Local-global principle, it seems very interesting for me. This is the major confusion I have in my mind, I tried writing to many people , but due to scarcity of people working in this area I didn't get an answer. If anybody helps me I will be much thankful to them. And I am also looking for beautiful articles on Tamagawa numbers, can anyone provide a reference. Edit: Can I request Prof.Mathew Emerton to see this question and answer it if he is free. Thanking you all. Yours truly, Iyengar.","['number-theory', 'algebraic-geometry', 'elliptic-curves', 'algebraic-number-theory', 'locally-compact-groups']"
97671,Odds of getting specific color of Jelly Beans in a handful?,"I have a bag of jelly beans with approx 1190 Jelly Belly's in it. There are 50 different flavors. Assuming the amount of Jelly Belly's per flavor are equal (so, 23.8 of each bean): If I pull 6 Jelly Beans from my unopened bag, what are the odds that 3 of them will be the same color? I'm asking because I got a bag of jelly beans for Christmas and got 3 of the same color in the handful I just pulled out... and it's been many many years since my statistics class in college. Thank you for the help. It's driving me batty and nobody at work cares about my Jelly Belly question except me =( I would have tried to figure this out on my own as it seems very easy, but I don't even know where to begin looking.","['statistics', 'probability']"
97685,Integral closure in the total ring of fractions,"My question is linked with normalization of reduced algebraic curves that are not necessarily irreducible. Let $(A,\mathfrak{m})$ be a local reduced noetherian ring with Krull dimension $1$, let $\mathfrak{p}_1, \dots, \mathfrak{p}_n$ be the minimal primes of $A$ and let $S$ the multiplicative subset made up of regular elements of $A$, i.e. $S = A \setminus (\mathfrak{p}_1 \cup \cdots \cup \mathfrak{p}_n)$. ($S^{-1}A$ is called the total ring of fractions of $A$.) It is quite easy to prove that $A \subseteq S^{-1}A$ and that $S^{-1}A \simeq k(\mathfrak{p}_1) \times \cdots \times k(\mathfrak{p}_n)$ as rings. It is quite obvious that $A_{\mathfrak{p}_i} = B_{\mathfrak{p}_i}$, where $B$ is the integral closure of $A$ in $S^{-1}A$. My question is: when $A$ is integrally closed in $S^{-1}A$? More precisely, I have the suspect that the following assertion holds: If $A$ is integrally closed in its total ring of fractions, then $A$ is a domain, i.e. $A$ has only one minimal prime. Could one prove or disprove this assertion?
Thanks to all!","['commutative-algebra', 'ring-theory', 'algebraic-geometry', 'algebraic-curves']"
97692,Maximal ideals in $C(X)$ and Axiom of Choice,"The following result are true if we assume full axiom of choice: A. If $X$ is a compact Hausdorff space, then every maximal ideal of the ring $C(X)$ has the form $A_p=\{f\in C(X); f(p)=0\}$. B. If $X$ is a compact Hausdorff space, then every ideal of the ring $C(X)$ is contained in an ideal of the form $A_p=\{f\in C(X); f(p)=0\}$. I wonder how much choice is needed. To be precise, do we get a statement equivalent to some known form of AC if we assume validity of A/B for every compact space, for every compact metric space, for every complete totally bounded metric space or for the case $X=[0,1]$? I've tried to answer A at least partially in my answer here . If I did not make a mistake there, I've shown that in ZF the claim A holds for complete totally bounded metric space, B holds for compact spaces. I've also gathered a few relevant references in that answer. According to those references validity of A of every compact regular space is equivalent to ultrafilter theorem. According to the same book, in ZF it can be shown that A holds if and only if $X$ the form $[0,1]^I$ and B holds if and only of $X$ is compact. As I am not experienced with working in ZF (without AC), I'll be glad if you check my work there and point out any mistakes and add any additional references/proofs/insights. This question is also related, but not identical: https://math.stackexchange.com/questions/97603/realizing-a-homomorphism-mathcalcx-to-mathbbr-as-an-evaluation","['general-topology', 'axiom-of-choice']"
97693,Upper bound for the partial sum $\sum k \lg k$ via summation?,"In this lecture of an introductory class to algorithms (video here , time 74:09), the professor cites the following as an upper bound: $$ \sum_{k=2}^n k \lg k \leq \frac{1}{2} n^2 \lg n - \frac{1}{8} n^2.$$ The professor cites two ways of seeing the inequality: 1) by ""using purely summations and facts about summations by splitting the summation into two pieces and reconstituting it"", and 2) by using an integral. The integral method can be solved by integration by parts: $$ \sum_{k=2}^n k \lg k \leq \int_{2}^n x \lg x = \frac{1}{2} x^2 \lg x - \frac{1}{4\ln 2} x^2 < \frac{1}{2} n^2 \lg n - \frac{1}{8} n^2.$$ I tried doing it by sums, but am not sure what to split. One can find:
$$\begin{align}
 \sum_{k=2}^n k \lg k &= 2 \lg 2 + 3 \lg 3 + \cdots + (n-1)\lg(n-1) \\
&\leq 2\lg(n-1) + 3\lg(n-1) + \cdots (n-1) \lg(n-1) \\
&\leq \lg(n-1) \sum_{k=2}^n k = \lg(n-1) \frac{n^2-n-2}{2}, 
\end{align}$$
which satisfies the first term in the upper bound. But how does one get the square term $(-n^2/8)$ by sums?","['algebra-precalculus', 'algorithms']"
97698,What is it to be normal?,"I'm interested to find out why the word 'normal' crops up so many different areas of mathematics, especially but not exclusively in abstract algebra, and how the definitions are related, if at all. Some common examples are: A subgroup $H$ of a group $G$ is normal if $gHg^{-1}=H$ for each $g \in G$ . An algebraic extension $L$ of a field $K$ is normal if every polynomial in $K[X]$ with a root in $L$ splits in $L$ . A topological space $X$ is normal if for any disjoint closed subsets $A,B \subseteq X$ there exist disjoint open subsets $U,V \subseteq X$ with $A \subseteq U$ and $B \subseteq V$ . A real number is normal if, in each base $b$ , each of the digits from $0$ to $b-1$ has asymptotic density $\frac{1}{b}$ in its base- $b$ expansion. A vector $v \in \mathbb{R}^3$ is normal to a $2$ -manifold $X$ at the point $p \in X$ if $\langle v, w \rangle = 0$ for each $w \in T_p X$ . A random variable $X : (\Omega, \mathcal{F}, \mathbb{P}) \to \mathbb{R}$ is normal if its probability density function takes the form $\dfrac{1}{\sqrt{2\pi \sigma^2}} \exp \left \{ -\dfrac{(x-\mu)^2}{2\sigma^2} \right \}$ for some $\mu \in \mathbb{R}$ and $\sigma^2 > 0$ . Normal groups and normal field extensions are related thanks to Galois theory: if $F/K$ is a Galois extension with Galois group $G$ then $H \le G$ is a normal subgroup if and only if $F^H/K$ is a normal extension. But how about normal subgroups and normal topological spaces, for example? Is there a rationale behind using the word normal , or are the meanings disjoint, having evolved in separate fields for unrelated reasons? Or, to whittle this all down to a single question: is there a well-defined notion of 'normality' in mathematics, and if so, what is it?","['abstract-algebra', 'definition']"
