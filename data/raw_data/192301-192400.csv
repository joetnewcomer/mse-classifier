question_id,title,body,tags
3661902,"Finding a chain with no least or greatest elements for $(\mathcal{P}(\mathbb{N}),\subseteq)$","I have a poset $(\mathcal{P}(\mathbb{N}),\subseteq)$ , where $\mathcal{P}$ is a power set, and I need to find a non-empty chain, such as that chain would not have the least or greatest element. It is easy for me to imagine a chain in $(\mathcal{P}(\mathbb{N}),\subseteq)$ , but I can't really grasp the idea of how do I make up a chain with no least element. From what I have googled so far, I can suppose it should be somehow related to the poset $(\mathbb{Q},\subseteq)$ , but I don't know how to develop that idea (in case it shall lead me to an answer at all).","['order-theory', 'discrete-mathematics']"
3661917,Necklace combinations with three group of beads,"I have a hard question about a way how many different necklaces can be made. Suppose that we have the following restrictions: We have 3 groups of beads: 4 triangle beads 6 square beads 8 circle beads All the beads in one group are completely identical. This means that if you put two triangle beads next to each other and then switch their positions this counts as one necklace because the beads are identical Necklaces are identical if they are identical under symmetric operations just as rotate them (ùëü) or turning them around (ùë†). So if we have a necklace ordered in one way and we rotate it 180 deg or just flip a side this is count as one necklace. We need to use all the 18 beads in each and every new necklace. We can not create a necklace from 17, 16 or less than 18 beads. I read all the topics here but could not find a question about a group of identical beads.
I also read Burnside lemma and P√≥lya_enumeration_theorem and Necklace_(combinatorics) in wikipedia, but could not find a way how to solve this and what is the correct answer. From Burnside lemma, I found that the answer should be 57, but is this correct? I used directly the formula from Burnside lemma, but it does not seem quite right for me, because I do not take into account that the three groups are with different numbers of beads. $$\frac{1}{24} * (n^6 + 3 * n^4 + 12 * n^3 + 8 * n^2)$$ where n is 3 from three groups. $$\frac{1}{24} * (3^6 + 3 * 3^4 + 12 * 3^3 + 8 * 3^2) = 57$$ However, as I said earlier despide the fact that the result looks some kind realisting I am not sure that this is the right answer, because I do not use in the formula that we have 4 triangle, 6 square and 8 circle beads. It looks like P√≥lya enumeration theorem weighted version is the thing that I need. However, I am not sure how to get to the right answer Thanks in advance.","['recreational-mathematics', 'combinatorics', 'necklace-and-bracelets', 'discrete-mathematics', 'group-theory']"
3661928,Find all function $f : \mathbb{R} \to \mathbb{R}$ s.t. $\lim_{x \to 0} \frac{f(x)}{x}=1$ & $f(x+y)=f(x)+f(y)+2xy$.,"Find all function $f : \mathbb{R} \to \mathbb{R}$ such that : $\lim_{x \to 0} \frac{f(x)}{x}=1$ and for all reals $x,y$ : $$f(x+y)=f(x)+f(y)+2xy$$ I tried to solve it and I got the following  : If $x=y=0$ we have $f(0)=0$ I wanted to use the limit but I couldn't : $$\text{We know that :} f(x+y)=f(x)+f(y)+2xy$$ Thus : $$f(x)=f(x+y)-f(y)-2xy$$ $$\therefore \frac{f(x+y)-f(y)-2xy}{x}=\frac{f(x+y)-f(y)}{x}-2y$$ I think that I need to substitute that $f(x+y)$ but I don't even know if this is true or no !","['functional-equations', 'continuity', 'calculus', 'functions', 'limits']"
3661938,Alternate definition of Entropy,"I am going through the book Computational Optimal Transport by Peyr√© and Cuturi.
In it (see Formula (4.1), P. 65/209) I came across the definition of the discrete entropy, which is not what I expected: $$
H(P) = - \sum_{i,j}P_{i,j}(\log(P_{i,j})-1),
$$ with $P \in [0,1]^{n,m}$ being a coupling matrix, i.e. describing the transformation of discrete propability distributions.
What confuses me is the $-1$ in the sum and I would like to know, why it is included. Since $\sum_{i,j} P_{i,j}=1$ it is shifting the result by $-1$ .  Still it confuses me.","['statistics', 'optimal-transport', 'entropy', 'information-theory']"
3662019,"If $H_{1}$ and $H_{2}$ are subgroups of (G,$\bullet$), then $H_{1}\triangle H_{2}$ is a subgroup of (G,$\bullet$) ? Prove or give a counterexample","Let (G, $\bullet$ ) be a group. If $H_{1}$ and $H_{2}$ are subgroups
of (G, $\bullet$ ), then $H_{1}\triangle H_{2}$ is a subgroup of (G, $\bullet$ )
where $\triangle$ is the symmetric difference. I think that is false. My argument: Because (G, $\bullet$ ) is a group, then exist $e\in$ G where $e$ is the identity element. Now, because $H_{1}$ and $H_{2}$ are subgroups of (G, $\bullet$ ) then $e$ $\in$ $H_{1}$ and $e$ $\in$ $H_{2}$ . Then, for definition of intersection betwen sets,
we have that $e$ $\in$ $H_{1}\cap H_{2}$ . Now by definition of
symmetric difference we have that $H_{1}\triangle H_{2}$ = ( $H_{1}\cup H_{2})-(H_{1}\cap H_{2})$ . Then we have that $e$$\notin$ $H_{1}\triangle H_{2}$ and then,
because $H_{1}\triangle H_{2}$ don't have the identity element, we
have that $H_{1}\triangle H_{2}$ is not a group. It is my argument correct? What counterexample can I use to disprove it?","['group-theory', 'abstract-algebra', 'discrete-mathematics']"
3662022,A question on primitive notions.,"This is a follow up question of sorts to my previous question at: On the notion of set equality. In ZFC, we have to consider a collection of primitive notions. In particular, we consider the notion of 'set' and 'element' to be primitive. https://arxiv.org/pdf/1212.6543v1.pdf In this paper, an alternative but equivalent axiomization using 'functions' and 'sets' as primitive is used. Essentially, they use the notion of function to construct the elements of sets. Has there ever been an attempt at a 'theory of ""units""' where one takes 'elements' or 'objects' to be primitive and studies their relationship with other objects directly with 'relation' or 'function' as another primitive notion? Then can we use these to construct the notion of set?","['elementary-set-theory', 'foundations']"
3662033,Compactly Supported Flow [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Consider the following initial value problem $$ 
\begin{cases}
\frac{d}{dt} Y_t = \rho(Y_t)\\
Y_0 = 0
\end{cases}
$$ where $\rho(x)$ is a bump function supported near $0$ on $\mathbb{R}^1$ .  Let $f:t\mapsto Y_t$ . Why is $Im(f)\subseteq supp(\rho)$ ?","['differential', 'differential-geometry', 'ordinary-differential-equations', 'real-analysis']"
3662054,interpretation of a group action [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $G$ be a group and $A$ be an abelian group. Let $\beta$ , $\alpha :G\rightarrow Aut(A)$ be two homomorphisms. It is well known that if there
exist $\sigma \in Aut(A)$ , $\rho \in Aut(G)$ such that $(\beta \circ
\rho )(g)=\sigma \circ \alpha (g)\circ \sigma^{-1}$ for all $g\in G$ , then the semidirect products $A\rtimes _{\alpha
}G$ and $A\rtimes_{\beta}G$ are isomorphic. However, in one stage of a proof, I get that there
exist $\sigma \in Aut(A)$ , $\rho \in $ $Aut(G)$ such that $(\alpha \circ
\rho )(g)=\sigma \circ \alpha (g)\circ \sigma^{-1}$ for all $g\in G$ . Is there
any interpretation of this formula in group theory? why this might be an interesting property? Thank you in advance.","['group-theory', 'group-actions', 'finite-groups']"
3662140,The Chow ring of affine space,"I want to show that $\operatorname{CH}(\mathbb{A}^n) = \mathbb{Z}$ from first principles. There's a proof of this in 3264 by Eisenbud and Harris that utilizes the definition of rational equivalence given by differences of cycles on $\mathbb{P}^1 \times \mathbb{A}^n$ ; I would like to show this using the divisors on subvarieties formulation. The key part of the proof is to show that any proper subvariety $Y \subset \mathbb{A}^n$ is rationally equivalent to zero. The idea I have is to find a subvariety $Z$ such that $Y \subset Z \subset \mathbb{A}^n$ and $Z$ is one dimension larger than $Y$ ; then $Y$ is a divisor on $Z$ since it is cut out by equations, and therefore rationally equivalent to zero. Does this work? How can I show rigorously that we can always find such a $Z$ ?","['algebraic-geometry', 'solution-verification', 'intersection-theory']"
3662185,Weakening the assumptions of the Hellinger-Toeplitz theorem,"The Hellinger-Toeplitz theorem states that if $T$ is a linear map from a Hilbert space $H$ to itself, satisfying $ \langle Tx,y\rangle=\langle x,Ty\rangle$ for all $ x,y \in H$ , then $T$ is bounded. But can we not instead have the assumption that there is a linear map $ T^*$ such that $ \langle Tx ,y \rangle = \langle x, T^* y \rangle$ for all $ x,y \in H$ ? Then we can take $ x_n \to x$ and set $ z = \lim_{n\to \infty} Tx_n $ , so that for all $ y \in H$ \begin{align}
\langle z,y \rangle \leftarrow \langle Tx_n,y \rangle = \langle x_n, T^*y\rangle \to\langle x , T^*y\rangle = \langle Tx,y\rangle
\end{align} so that $ z = Tx$ , and so the graph of $T$ is closed, so by closed graph theorem $T$ is bounded. It is the same proof as for the usual Hellinger-Toeplits, so I don't see why we need the operator to be symmetric?","['hilbert-spaces', 'functional-analysis', 'closed-graph']"
3662219,Can every lattice polyhedron be subdivided into lattice tetrahedra?,"In 2D, every polygon can be triangulated without introducing new vertices. In particular, lattice polygons can be divided into lattice triangles. In 3D, the Sch√∂nhardt polyhedron cannot be triangulated into tetrahedra without adding new vertices. What about the following weaker question?: Can every lattice polyhedron be subdivided into lattice tetrahedra, allowing the introduction of new vertices (as long as they are lattice vertices)?","['solid-geometry', 'triangulation', 'geometry']"
3662241,"Proving that $u_{n}\in\mathbb{Z}\forall n\ge 0$, such that $\det \begin{bmatrix}u_{n} & u_{n+1} \\ u_{n+2}&u_{n+3}\end{bmatrix}=n!\forall n\ge 0$","Define a sequence $u_n\forall n\ge 0$ such that $u_{0},u_{1},u_{2}=1$ and $\det\begin{bmatrix}u_n & u_{n+1} \\ u_{n+2} & u_{n+3}\end{bmatrix}=n! \forall n\ge 0$ . Prove that $u_n\in\mathbb{Z}\forall n\ge 0$ . As of now I have just gone on to find the values of the sequence to see if they form a pattern. The first few terms come out to be $1,1,1,2,3,5,8,15, 48, 105$ . No obvious pattern is visible. Also induction is used, will have to be multi counter induction, and I am not familiar with its application. Also if we try to replace $n$ by $n-1$ , we get following expressions. $$\begin{aligned}u_{n}u_{n+3}-u_{n+1}u_{n+2}&=n!\\ u_{n-1}u_{n+2}-u_{n}u_{n+1}&=(n-1)!\end{aligned}$$ On subtracting we get the equality $u_{n}(u_{n+3}-u_{n+1})-u_{n+2}(u_{n+1}-u_{n-1})=(n-1)^{2}(n-2)!$ . I can not see how to proceed. Any hints are appreciated. Thanks.","['contest-math', 'determinant', 'sequences-and-series']"
3662313,Probabilty that none of n i.i.d uniform samples from R^2 are larger in both coordinates than first.,"I am randomly sampling n elements from a square within R^2. They are independently uniformly distributed. What is the probability that for any arbitrarily but fixed previously selected sample index, it is true that no other sample is greater in both coordinates? I do not know anything else about the preselected sample. This is part of a larger problem which I have reduced to this question, I can explain it should it be neccessary.","['statistics', 'combinatorics', 'order-statistics']"
3662314,Statistics of a Gaussian random variable with the floor function transformation,"Suppose $X$ is a Gaussian random variable, i.e., $X\sim N(\mu, \sigma)$ . Let $Y$ be defined as $Y=\lfloor X \rfloor$ , where $\lfloor \cdot \rfloor$ denotes the floor function (greatest integer lesser or equal than $X$ ). It can be seen from here that $$P(Y=y)=P(y\le X< y+1)=P(X<y+1)-P(X\le y)\\ =\Phi\left(\frac{y+1-\mu}{\sigma}\right)-\Phi\left(\frac{y-\mu}{\sigma}\right) \\ =\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y+1-\mu}{\sigma\sqrt{2}}\right)\right]-\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y-\mu}{\sigma\sqrt{2}}\right)\right]$$ where $\Phi(\cdot$ ) is the CDF for standard Gaussian and $\operatorname{erf}(\cdot)$ is the error function. I have two questions: (1) Is $Y$ a regular discrete random variable? Or it does not have a standard expression (i.e., does it belong to any families of distributions)? (2) More importantly , what is the mean and variance of random variable $Y$ ? Please help and thanks in advance!","['ceiling-and-floor-functions', 'probability-distributions', 'normal-distribution', 'probability', 'random-variables']"
3662326,volume of an infinite dimensional ball.,"I am was doing some problems from my text book and one of them says "" let the volume of of the nth dimensional ball be denoted by $vol(B^n(R))$ where $R$ is the radius of the ball. Show that $\lim_{n\to\infty} vol(B^n(R))$ "" I have seen explanations of this, but all of them use the gamma function. I was wondering if there was any way to do it without using it. So far I have shown that $vol(B^n(R)=vol(B^{n-2}(R))\frac{2\pi R^2}{n}$ . Using this I was thinking you could keep iterating and you would get $n(n-2)(n-4)$ in the denominator and so on which is less than $n!$ and whatever is above will not depend on n so we could treat it as a constant, thus you would have something like $\frac{T}{n!}<\frac{T}{n(n-2)(n-4)..}$ so then by taking limits the RHS crushes the left hand side so they both go to 0. Is this right ? I am not sure if this is even rigorous enough. Any help is appreciated :). Thank you.","['integration', 'real-analysis', 'linear-algebra', 'vector-analysis', 'differential-geometry']"
3662420,derivative manipulation,I was reading a book and was hoping to get clarification. here is the image from the book And here it is again: $$ M{d^2x\over dt^2} = f(x)  $$ they claim can be written as $${M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = f(x)$$ Is the factor $\frac 1 2$ incorrect? I find: $${M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = {\frac M 2}{d \over dx}{dx \over dt}{dx \over dt} = {\frac M 2}{d \over dt}{dx \over dt}={\frac M 2}{d^2x \over dt^2}$$,"['calculus', 'derivatives']"
3662450,Initial Value Problems defined on some interval,"Let $a$ be a positive real number. Find all of solutions, defined on (‚àía, a), for the following initial-value problem: $|y'(x)| + y(x) = 0$ , and $y(0) = -1$ . My progress: I struggle to understand the correlation between given $a$ and solution of the DE. Meanwhile, is it allowed in such problems to divide into 2 cases and solve them separately? Any help would be strongly welcomed!",['ordinary-differential-equations']
3662461,How to think about the isomorphism $V/\ker T\cong\operatorname{im}T$,"My question is in the context of linear algebra (of a linear map $T$ between two FDVS $V$ and $W$ ), though I‚Äôve heard it is a more general result in group theory (First Isomorphism Theorem). I‚Äôve seen some answers about intuition for this theorem, but they are in the context of group theory and more general/abstract. Do the following observations related to this theorem hold? Am I thinking about this result correctly? I would also appreciate any general comments about this result (whether in linear algebra or in general). (Visualizing movement between points and between affine subsets) A movement between two points in the image corresponds to a movement between two affine subsets of the domain that are parallel to the kernel (and vice versa). (See image below (I drew this, so not sure if accurate).) Specifically, if we move from $T(x)\in\operatorname{im}T$ to $T(x‚Äô)\in\operatorname{im}T$ then we move from $x+\ker T$ to $x‚Äô+\ker T$ in the domain (and vice versa). In fact, we can be more general: we can use any element in the fiber of $T(x)$ to represent $x + \ker T$ , and any element in the fiber of $T(x‚Äô)$ to represent $x‚Äô + \ker T$ . (Application to systems of linear equations) Let $A$ be the matrix of $T$ . The solution set of $Ax = 0$ is $\ker T$ . More generally, consider $Ax = b$ . If this system is consistent, i.e. if $b$ is in the image of $T$ , then its solution set is given by $v + \ker T$ , where $v$ is any solution $Av = b$ . Edit: Here are a few more observations (some overlap a bit with what I‚Äôve already said); they may or may not be accurate: (Removal of useless/trivial solutions) The map $T$ from $V$ to $W$ (or to im $T$ ) may not be injective, but if we think about the map $\tilde{T}$ from $V/\text{ker $T$}$ to im $T$ that sends $v + \text{ker $T$}$ to $v$ , we get a bijection. We‚Äôve sort of ‚Äúremoved duplicates‚Äù and achieved a one-to-one-correspondence. Also, we've collapsed the kernel into a single point (i.e. 0), so all the extra trivial solutions have been removed; now, only 0 gets mapped to 0. (Partitioning the domain into copies of the kernel) The quotient space $V/\text{ker $T$}$ is the set of all affine subsets parallel to the kernel. So intuitively the isomorphism tells us that if we chop up the domain into copies of the kernel then we get something isomorphic to the image. (Number of remaining directions required to fill up the domain) $V/\text{ker $T$}$ has dimension $\dim V - \dim \ker T$ , so it sort of tells us how many more directions we need to fill up the space. E.g. in $\mathbb{R}^3$ , if the kernel has dimension 2, then $V/\text{ker $T$}$ has dimension 1; there is ‚Äúone more direction‚Äù to go. Geometrically, sweeping a plane through a line (that's not in the plane) gives us all of 3D space. (The image is isomorphic to the subspace perpendicular to the kernel) The orthogonal complement $U^\perp$ of a subspace $U$ has dimension $V - U$ . Setting $U = \text{ker $T$}$ tells us that $(\ker T)^\perp$ has the same dimension as im $T$ , i.e. they are isomorphic. Thinking in $\mathbb{R}^3$ again, if the kernel is a plane, then im $T$ and $(\ker T)^\perp$ are lines, so they are isomorphic. Thinking of $V/\ker T$ as chopping up $\mathbb{R}^3$ into a line of parallel planes also shows how $V/\ker T$ is like a line as well.","['group-theory', 'abstract-algebra', 'linear-algebra', 'linear-transformations']"
3662606,"Maximize $\log(2)+\log(3/2)x+\log(2)y+\log(5/2)z$ if $x+y+z\leq 1$ and $(y+z)^2+2x-x^2-2xy\leq 1-2\gamma$, $0.24 \leq \gamma \leq 0.25$","I am trying to maximize the function $$f(x,y,z)=\log(2)+\log(3/2)x+\log(2)y+\log(5/2)z$$ with the following constraints: $$x\geq 0, y\geq 0, z \geq 0,$$ $$x+y+z\leq 1,$$ $$x+y\geq 4/5,$$ $$(y+z)^2+2x-x^2-2xy\leq 1-2\gamma,$$ where $$0.24 \leq \gamma \leq 0.25.$$ I claim that the maximum value is $\frac{\log(12)}{2}+\frac{\sqrt{1-4\gamma}}{2}\log\left( \frac{4}{3} \right)$ , and that this maximum is obtained when $x=\frac{1+\sqrt{1-4\gamma}}{2}$ , $y=\frac{1-\sqrt{1-4\gamma}}{2}$ , and $z=0$ . I am trying to avoid using Lagrange Multipliers because it becomes complicated. I am wondering if there is another way. I would also be satisfied if I could show that $f(x,y,z)\leq \frac{\log(12)}{2}+\frac{\sqrt{1-4\gamma}}{2}\log\left( \frac{4}{3} \right)$ . Programs like Maple and Mathematica give me solutions for specific $\gamma$ , but I would like to find a step by step way to show this for ANY $\gamma$ . Thank you. Note: I want to point out that we treat $\gamma$ as a FIXED constant that lies in the real interval $[0.24, 0.25]$ . Also, all logarithms considered are real.","['nonlinear-optimization', 'lagrange-multiplier', 'maxima-minima', 'multivariable-calculus', 'optimization']"
3662631,"Showing that if $\forall n \ge 0: \int_{-1}^{1} f(t)t^{2n+1} dt = 0$ and $f$ is continuous, then $f$ must be even","I am trying to prove the following problem: Suppose that $f:[-1,1] \to \mathbb{R}$ is continuous and for sufficiently large $n$ , we have $$ \int_{-1}^{1} f(t)t^{2n+1} dt =0$$ Show that $f$ is even. I believe I have seen a similar problem before, and the solution inovolved some manipulations like I do above. However, I'm unable to come up with the complete solution. I do not remember clearly, but the solution may or may not involve the Stone-Weierstrass Theorem. My Attempt: Instead of ""sufficiently large $n$ "", we can assume $n \ge 0$ . It is easy to generalize later. Using the substitution $t \mapsto -t$ , we get that $$\int_{-1}^1 f(-t) t^{2n+1}.$$ Subtracting the two integrals gives $$\int_{-1}^1[f(t)-f(-t)] t^{2n+1} dt=0$$ Let $g(t) =  f(t)-f(-t)$ . This function $g$ is in fact odd. However, I'm not sure what to do after this point.","['integration', 'calculus', 'analysis', 'real-analysis']"
3662638,"Not Assuming Choice, Nilradical Not Equal to Intersection of Prime Ideals","Every proof I‚Äôve seen that, for a commutative ring $A$ , $$\newcommand{\Nil}{\operatorname{Nil}}\Nil(A)=\bigcap_{x\in \newcommand{\Spec}{\operatorname{Spec}}\Spec(A)}x$$ assumes Zorn‚Äôs lemma. So my question is, Within ZF but not ZFC, does there exist a commutative unital ring $A$ such that $\Nil(A)\neq ‚à©_{x‚àà \Spec(A)}x$ ? (Here, I define the nilradical to be the set of nilpotents of $A$ .) Perhaps it‚Äôs better to define $\Nil(A)$ to be the standard conclusion in commutative algebra, obfuscating this (potential?) issue, but I‚Äôm still curious.","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra', 'axiom-of-choice', 'set-theory']"
3662677,Extensions over $\mathbb{Q}$ by $\cos(\theta)$,Suppose that $K = \mathbb{Q}(\cos(\theta))$ . I want to run this by someone but I am sure it's most likely true: $\mathrm{Gal}(K / \mathbb{Q})$ is abelian $\Leftrightarrow$ $\theta$ is a rational multiple of $\pi$ . Thanks!,"['number-theory', 'algebraic-number-theory']"
3662722,Can the computability of a specific function be independent of ZFC?,"If I understand correctly there exist artificial examples. Let P be a statement known to be independent of ZFC, such as CH, $g:\mathbb{N}\rightarrow\mathbb{N}$ be a function known to be uncomputable, such as the one related to halting problem. Define a function $f:\mathbb{N}\rightarrow\mathbb{N}$ as follows: if P holds then $f=0$ ; otherwise $f=g$ . Then whether $f$ is computable would be independent of ZFC. My questions are: Is there any natural example? Actually this is what I initially wanted to ask: is there any provably ineffective result in number theory (here ""effective"" is synonym for ""computable"")? The Siegel's theorem leads to many ineffective results, but Generalized Riemann Hypothesis (GRH) implies effective version of those results. Virtually everyone believes GRH is provable, and hence Siegel's result actually is effective.","['analytic-number-theory', 'number-theory', 'logic', 'computability']"
3662868,Any known bounds for convex function say $f$ with $L$-Lipschitz continuous gradient: $( x - y)^T A \left( \nabla f(x) - \nabla f(y)\right)$?,"There are several known bounds for a convex function say $f$ with $L$ -Lipschitz continuous gradient, for instance, \begin{align}
\left( x - y \right)^T  \left( \nabla f(x) - \nabla f(y)\right) \leq L \| x - y \|_2^2, \forall x, y .
\end{align} Exhaustive list can example be found here . Now, I am wondering if there is any known bound for this case, \begin{align}
\left( x - y \right)^T {\color{red} A} \left( \nabla f(x) - \nabla f(y)\right) \leq \ {\color{red}?}, \forall x, y ,
\end{align} where $A$ is a square matrix . Questions If there is any lower bound, what is it and how to derive that? Moreover, what are the requirements on such a matrix $A$ ? Positive (semi)definite? (except the trivial case where matrix $A$ is a scaled identity)","['convex-analysis', 'functional-analysis', 'lipschitz-functions', 'real-analysis']"
3662891,"Justifying ""multiplying by a differential"" or a random variable in a stochastic differential equation","This is a very basic question relating to why we are allowed to multiply by random variables within an SDE.  Every text/notes set that I've seen does the following, for $X_t$ continuous + adapted and $L_t$ a semimartingale: $$dX_t = \frac{1}{X_t}dL_t \quad \text{as} \textbf{ shorthand} \text{ for meaning} \quad X_t = \int_0^t\frac{1}{X_s}dL_s \quad \quad (1)$$ Because it's only ever referred to as shorthand, I don't understand why no one ever proves the fact that we are allowed to then write: $$X_tdX_t = dL_t, \quad \text{i.e. once again shorthand for} \quad L_t = \int_0^tX_sdX_s \quad \quad (2)$$ What is the rigorous justification for $(2)$ ?  Am I an idiot for missing something trivial about the definition of the integral or of Ito's formula that makes the equivalence of $(1)$ and $(2)$ obvious?  Sorry if this is dumb.  Please help if you can","['stochastic-differential-equations', 'probability-theory', 'stochastic-calculus']"
3662903,"Lie derivative ""commutes"" with pullback by time dependent diffeomorphisms","I've seen the following equality being used in a book on the Ricci flow I'm reading but I've been stuck on proving it: $$\varphi_{t}^{*}\left(\mathcal{L}_{W(t)} g(t)\right)=\mathcal{L}_{\left[\left(\varphi_{t}^{-1}\right)_{*} W(t)\right]}\left(\varphi_{t}^{*} g(t)\right)$$ The context here is as follows: $(\mathcal{M}, g_0)$ is a Riemannian manifold on which $W$ is a time dependent vector field, $\{g(t) \}_{t \in I}$ is a family of time-dependent metrics on $\mathcal{M}$ , and the $1$ -parameter family of diffeomorphisms $\varphi_{t}: \mathcal{M}^{n} \to \mathcal{M}^{n}$ satisfies the non autonomous ODE: $$\begin{aligned}
\frac{\partial}{\partial t} \varphi_{t}(p) &=-W\left(\varphi_{t}(p), t\right) \\
\varphi_{0} &=\mathrm{Id}_{\mathcal{M}^{n}}
\end{aligned}$$ I don't have a lot of experience with Lie derivative computations and this is the last step I need to finally finish a proof that solutions to the Ricci-deTurck flow can be produced by solutions from the Ricci-Hamilton flow. I know that if $M$ and $N$ are smooth manifolds, $F: M \to N$ is a diffeomorphism and $X \in \mathcal{X}(M)$ it's true that $$F_{*}\left(\mathcal{L}_{V} X\right)=\mathcal{L}_{(F_{*} V)} (F_{*} X)$$ but I'm having a hard time adapting this to pullbacks where everything is time dependent. This has been troubling me for some time now, so I'll be grateful for any help.","['riemannian-geometry', 'geometry', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
3662977,How to find the intervals on which $f$ is concave up? $f(x) = \arctan(\sin x )$,"\begin{align*}f(x) &= \arctan(\sin x )\\[4pt]
f'(x) &= \frac{\cos x }{1+\sin^2 x }\\[4pt]
f''(x) &= -\frac{(\sin x )(2+\cos^2 x )}{(1+ \sin^2 x )^2}
\end{align*} So I need to use these three equations to find the intervals on which $f$ is concave up.
Can you reason why it is?","['multivariable-calculus', 'calculus', 'derivatives', 'trigonometry']"
3662984,How to solve this first order ODE right,"Here is ODE of first order: $$ y'=- \frac{x^2}{y^3} $$ with $y(0)=1 , y(0)=-1 $ Can my method be the separation method? If I use it, it doesn't work out: $ \frac{dy}{dx}= -x^2 \frac{1}{y^3} $ $ \leftrightarrow y^3 dy = -x^2 dx $ By integration I get: $$ \int y^3 dx = \int -x^2 dx $$ $$ \leftrightarrow \frac{1}{4} y^4+c = - \frac{1}{3} x^3+c $$ $$ \leftrightarrow y= \mp \sqrt[4]{ - \frac{4}{3} x^3 +c } $$ Where is my mistake?","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3663017,$f:\mathbb Q\to\mathbb C$ satisfying $f(x_1+\dots+x_{1988})=f(x_1)\dots f(x_{1988})$ and $\overline{f(1988)}f(x)=f(1988)\overline{f(x)}$,"I came across this super interesting question (Chinese Team Selection Test 1988, Problem 2) which I have not quite seen something like this and not quite sure where to start. Any suggestions/ help would be much appreciated. Thanks! Find all functions $f: \mathbb{Q} \to \mathbb{C}$ satisfying For any $x_1, x_2, \ldots, x_{1988} \in \mathbb{Q}$ , $f(x_1 + x_2 + \dots + x_{1988}) = f(x_1)f(x_2) \dots f(x_{1988})$ . $\overline{f(1988)}f(x) = f(1988)\overline{f(x)}$ for all $x \in \mathbb{Q}$ .","['contest-math', 'functional-equations', 'functions', 'complex-numbers']"
3663049,The time convergence of stochastic integral and Doob's convergence.,"Consider the process $$X_{t}=\int_{0}^{t}e^{-s}dW_{s},$$ where $e^{-s}$ is deterministic. I am wondering if $\lim_{t\rightarrow\infty}X_{t}$ exists almost surely... I understand that $X_{t}$ in the case is a martingale, so we can use Doob's martingale convergence theorem. However, I have no idea about how to show $$\sup_{t}\mathbb{E}X_{t}^{-}<\infty.$$ If we can show this, then yes, $X_{t}$ converges almost surely to a limit.. Also, is there any way to know the distribution of the limit? I know that the distribution converges since it converges almost surely, but I am not sure how to compute the limiting distribution.. using central limit theorem?? Thanks!","['weak-convergence', 'probability-distributions', 'stochastic-processes', 'martingales', 'probability-theory']"
3663100,Is the square root of a monotonic function whose all derivatives vanish smooth?,"Now cross-posted at MO. Let $g:[0,\infty] \to [0,\infty]$ be a smooth strictly increasing function satisfying $g(0)=0$ and $g^{(k)}(0)=0$ for every natural $k$ . Is $\sqrt g$ is infinitely (right) differentiable at $x=0$ ? I know that $\sqrt g \in C^1$ at zero*, and that in complete generality, one cannot expect for $\sqrt g$ to be even $C^2$ . However, in the counter-example given in the linked question, $g$ was not monotonic. Does this additional assumption of (strict) monotonicity save us? I tried to look at the literature, but did not find a treatment of this particular case. *The proof that $\sqrt g \in C^1$ goes by rewriting $g(x)=x^2h(x)$ where $h \ge 0$ is smooth (this is possible since $g(0)=g'(0)=0$ ). Comment: If we assume that $g''>0$ in a neighbourhood of zero (which implies that $g'>0$ ), then $\sqrt g \in C^2$ . (details below). I think that there is a chance for smoothness under the additional assumption that $g^{(k)}>0$ in a neighbourhood of zero for every $k$ , but I am not sure. The calculations become quite messy even when trying to establish $\sqrt g \in C^3$ . A proof $\sqrt g \in C^2$ when $g',g''>0$ near zero: (We use these assumptions when applying L'H√¥pital's rule). $$\sqrt{g}'' = \frac{g''}{2\sqrt{g}} - \frac{(g')^2}{4g^{3/2}}.$$ Thus it is enough to prove that $(g'')^2/g\to 0$ and $(g')^4/g^3\to 0$ . $$
\lim_{x\to 0^+} \frac{(g'')^2}{g} = \lim_{x\to 0^+} 2\frac{g''g^{(3)}}{g'} = \lim_{x\to 0^+} 2\frac{g''g^{(4)}+(g^{(3)})^2}{g''} = 0,
$$ where in the last equality we applied $\frac{(h')^2}{h}\to 0$ above for $h=g''$ . $$
\lim_{x\to 0^+} \frac{(g')^4}{g^3} = \lim_{x\to 0^+} \frac{4(g')^2g''}{3g^2} = \lim_{x\to 0^+} \frac{8(g'')^2 + 4g' g^{(3)}}{6g} = \lim_{x\to 0^+} \frac{2g' g^{(3)}}{3g} = \lim_{x\to 0^+} \left(\frac{2g^{(4)}}{3} + \frac{2g''g^{(3)}}{3g'}\right)=\lim_{x\to 0^+} \frac{2g''g^{(3)}}{3g'} = \lim_{x\to 0^+} \frac{2g^{(4)}}{3}+\frac{2(g^{(3)})^2}{3g''} = 0,$$ where in the first row we used the first calculation, and in the second we again applied $\frac{(h')^2}{h}\to 0$ to $h=g''$ .","['singularity', 'reference-request', 'real-analysis', 'calculus', 'derivatives']"
3663288,Prove that $f(x)\leq\cosh(x)$ $\forall$ $ x\in\mathbb{R^+} $,"Let $ f:\mathbb{R^+}\to(1,+\infty) $ be continuously differentiable function such that $ f^{2}(x) -(f^{'})^{2}(x)\geq 1$ $\forall$ $ x\in\mathbb{R^+} $ and $ f(0) =1$ . Prove that $f(x)\leq\cosh(x)$ $\forall$ $ x\in\mathbb{R^+} $ My proof : Put $f(x)=\cosh(g(x))$ with $g(0)=0$ we get : $$\cosh^2(g(x))-(g'(x))^2\sinh^2(g(x))\geq 1$$ Or : $$-(g'(x))^2\sinh^2(g(x))\geq 1-\cosh^2(g(x))$$ Or: $$-(g'(x))^2\sinh^2(g(x))\geq -\sinh^2(g(x))$$ Or: $$(g'(x))^2\leq 1$$ Integrating we get : $$|g(x)|\leq |x|$$ So we get the desired result since $\cosh(x)$ is increasing $\forall$ $ x\in\mathbb{R^+} $ My question I'm really curious to see an alternative proof so : Have you another proof ? Thanks a lot for all your contributions","['integration', 'alternative-proof', 'inequality', 'derivatives', 'exponential-function']"
3663394,Binomial Euler sums: Evaluate $\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s}$,"Denote $$f(s;s_1,s_2,\ldots,s_k)=\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s}$$ Can $f(\cdots)$ always be represented as $\mathbb Q$ -linear combination of alternating Euler sum of weight $W$ ? Here $s$ and $s_i$ are positive integers and $W=s+\sum_i s_i$ . Alternating Euler sums are defined as $$\sum_{n=1}^\infty (-1)^{l(n-1)}\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s},$$ where $l=0,1$ and $s,s_i\in\mathbb Z^+$ . By Editor: Examples and related things: Here , here , here , here , here , here , here . By Editor again: Harder examples and generalizations: Here , here , here , here . Numerical Evidence and Motivation I did some calculation of this binomial sum of small $n$ 's. The table in the appendix is a part of that.
I also did some research on alternating Euler sum. The constants involved in the alt. Euler sums are exactly the same when $n\le4$ . I randomly chose and evaluated some sums of weight $5$ and found that their constants are again same. Possible Conversion Although I noticed $\frac1{4^n}\binom{2n}n=\frac2\pi\int_0^1(4x-4x^2)^{n-1/2}dx$ , I'm unsure about how to convert it into the whole sum into an integral and then (possibly making some substitution?) convert it into the form of alternating Euler sum. Appendix The number in the blanks are the coefficients. \begin{array}{|c|c|} \hline
&\ln2\\\hline
f(1)&2\\\hline
\end{array} \begin{array}{|c|c|c|}\hline
&\zeta(2)&\ln^22\\\hline
f(2)&1&-2\\\hline
f(1;1)&2&0\\\hline
\end{array} \begin{array}{|c|c|c|c|} \hline
&\zeta(3)&\zeta(2)\ln2&\ln^32\\\hline
f(3)&2&-2&\frac43\\\hline
f(2;1)&\frac92&-4&0\\\hline
f(1;2)&\frac32&0&0\\\hline
f(1;1^2)&\frac{21}2&0&0\\\hline
\end{array} \begin{array}{|c|c|c|c|c|c|} \hline
&\zeta(4)&\zeta(3)\ln2&\zeta(2)\ln^22&\ln^42&\operatorname{Li}_4(1/2)\\\hline
f(4)&\frac94&-4&2&-\frac23&0\\\hline
f(3;1)&-\frac{13}4&-2&2&\frac13&8\\\hline
f(2;2)&3&-3&0&0&0\\\hline
f(2;1^2)&-14&7&-8&\frac43&32\\\hline
f(1;3)&\frac{37}4&-7&2&-\frac13&-8\\\hline
f(1;2,1)&\frac{49}4&-7&2&-\frac13&-8\\\hline
f(1;1^3)&\frac{115}4&35&-10&\frac53&40\\\hline
\end{array}","['definite-integrals', 'euler-sums', 'harmonic-numbers', 'closed-form', 'sequences-and-series']"
3663396,"Concentration (or two sided tail bounds around expectations) of maximum and minimum of $n$ iid, subgaussian random variables","Having no answer so far, I asked this on MO now. My question is motivated by this question and this question , where the first was aimed for giving a one sided tail bound for maximum of subgaussians, and the second one was for two sided tail bounds for gaussians. I'm also motivated by questions like this one . Let $\{X_1 \dots X_n\}$ be $n$ iid, subgaussian random variables so that $P[|X_i| \ge t] \le 2 exp (- \frac{ct^2}{ ||X_1||_{\psi_2}^2 }) \forall i, ||*||_{\psi_2}$ denoting the Orlicz norm. I'm looking for concentration inequalities for : $$  X_{max} := max_{1 \le i \le n} X_i, \hspace{1mm}    X_{min} := min_{1 \le i \le n} X_i   $$ So to be more precise, I'm looking for tail bound functions $\alpha(t), \beta(t)$ of the form: $$ P[  | X_{max} - \mathbb{E}X_{max} | \ge t ] \le  \alpha(t), P[  | X_{min} - \mathbb{E}X_{min} | \ge t ] \le  \beta(t)  $$ where the following are decreasing functions of $t$ : $$ 0 \le \alpha(t), \beta(t) \to 0, t \to \infty.$$","['probability-distributions', 'random-matrices', 'probability-theory', 'probability', 'random-variables']"
3663413,Parseval identity to compute $ \int_{-\infty}^{\infty} (\frac{\sin x}{x})^2dx$,"The Parseval identity in Hilbert space $H$ is If $h \in H$ , $\lVert h\rVert = \sum \{|<h,e>|^2:e \in S\}  $ then when $S$ is a basis for $H$ How to use this to compute $$ \int_{-\infty}^{\infty} \left(\frac{\sin x}{x}\right)^2dx$$",['functional-analysis']
3663537,Holomorphic at infinity (definition),"I struggle quite a bit with the usage of $\infty$ in complex analysis. In some cases, I can translate a definition involving infinity to equivalent statements using limits, or in the case of continuity I just make use of the topology defined on the Riemann sphere. However, what I don't understand is why the notion of differentiability is defined at the point infinity. A function $f(z)$ is said to be holomorphic at $\infty$ if $f(1/z)$ is holomorphic at $z=0$ . Same can be said about singularities. I just don't see why we would do this. For instance, when I'm asked to determine singularities, it often forget to check the point $\infty$ , because the definition feels so arbitrary: yea, let's check this random point which is actually a limit, and then somehow that tells us something? My source of confusion lies in the fact that I don't see why being holomorphic at $\infty$ tells us anything (well, I guess, besides that our function is bounded). I understand that being holomorphic around some complex number $a$ is useful, as we can then write our function as a power series around $a$ , of in the case of isolated singularities, we can work with Laurent expansion. But we don't have these things when it comes down to $\infty$ (except when we switch to $f(1/z)$ , but that's a whole different function now, no?) I hope someone understands my confusion and could shed some light on this issue.",['complex-analysis']
3663614,Brownian Motion Hitting Time,"A grocer receives revenue at rate $q$ and pays refunds at rate $r$ . Let $u=q-r$ and $u>0$ . Let the grocer's cash position at time $t$ be given by: $X_t=x_0+\mu t + \sigma B_t$ where $B_t$ is Brownian motion, constants $\sigma,x_0 >0 $ and $x_0$ is the grocer's starting cash balance. Let $X_{\tau}$ be the time the grocer's cash balance reaches $0$ . What is the probability of reaching $0$ ? What is $E[\tau]$ ? The grocer's cash position can be modeled as Brownian motion with drift coefficient $\mu$ . This reminds me of the gambler's ruin problem, but with drift. How can we find the hitting time of the zero cash balance?",['probability-theory']
3663645,Triple integral $\iiint_{D}\cos(x+2y+3z) dV $ over a sphere of radius 1,"My math problem is to evaluate the integral $$\iiint_{D}cos(x+2y+3z) dV  $$ where $D=\left \{ (x,y,z):x^2+y^2+z^2\leq 1  \right \}$ I tried approaching it with spherical coordinate by substituting $x=\rho \space \sin\phi \space \cos\theta$ , $y=\rho \space \sin\phi \space \sin\theta$ , $z=\rho\space  \cos\phi $ , but it doesn't help much since the function inside the integral ends up being more complicated. (cosine and sine functions inside cosine) I also tried using Cartesian coordinate, and changing the integral into $$8\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}}\int_{0}^{\sqrt{1-x^2-y^2}} \cos(x+2y+3z) \space \space dzdydx $$ $$=8\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}} \frac{\sin(x+2y+3\sqrt{1-x^2-y^2})-\sin(x+2y)}3 \space \space dydx$$ But I have no idea how to evaluate it, and I don't have any more ideas on this problem. I see someone else in another post saying we can make use of spherical symmetry and ""replace the integrand by $\cos(hz)$ , where $h=|(1,2,3)|$ . Then, integrate in slices perpendicular to the $z$ -axis."", but I have no idea if it would work or why it would work. (and I don't have enough reputation points to comment on that post :( ) Any help is appreciated. Thanks!","['integration', 'multivariable-calculus']"
3663662,"Show that there exist $[a,b]\subset [0,1]$, such that $\int_{a}^{b}f(x)dx$ = $\int_{a}^{b}g(x)dx$ = $\frac{1}{2}$","Let $f(x)$ and $g(x)$ be two continuous functions on $[0,1]$ and $$\int_{0}^{1}f(x) dx= \int_{0}^{1}g(x)dx = 1$$ Show that there exist $[a,b]\subset [0,1]$ , such that $$\int_{a}^{b}f(x) dx= \int_{a}^{b}g(x)dx = \frac{1}{2} $$ The question can be solved by considering the fundamental group of $S^1$ , now I am wondering if we can solve it by real-analysis. Here is the topological solution: Assume that for any $[a,b]\subset[0,1]$ , we always have $$(\int_{a}^{b}f(x) dx\neq \frac{1}{2}) \quad \vee \quad(\int_{a}^{b}g(x)dx \neq \frac{1}{2}) $$ Consider mapping $$\phi:D\rightarrow\mathbb{E}^2\backslash\{(\frac{1}{2},\frac{1}{2})\},\,\,(x,y)\mapsto(\int_{y}^{x}f(t) dt,\int_{y}^{x}g(t) dt)$$ where $D=\{(x,y)|0\leq x\leq y\leq 1\}$ . Let $a$ be path from $(0,0)$ to $(0,1) $ in $D$ and $b$ be path from $(0,1)$ to $(1,1) $ in $D$ , then $ab$ is a path from $(0,0)$ to $(1,1) $ in $D$ and $$\phi\circ (ab):[0,1]\rightarrow\mathbb{E}^2\backslash\{(\frac{1}{2},\frac{1}{2})\} $$ Notice that $$(\phi\circ (ab))(0)=(\phi\circ (ab))(1)=(0,0)$$ so $\phi\circ (ab)$ is a loop based on $(0,0)$ in $\mathbb{E}^2\backslash\{(\frac{1}{2},\frac{1}{2})\}$ . For any $t\in [0,\frac{1}{2}]$ , it's not hard to get that $$(\phi\circ (ab))(t+\frac{1}{2})=(1,1)-(\phi\circ (ab))(t)$$ is equivalent to $$(\phi\circ (ab))(t+\frac{1}{2})-(\frac{1}{2},\frac{1}{2})=-((\phi\circ (ab))(t)-(\frac{1}{2},\frac{1}{2}))$$ Define retraction $$r:\mathbb{E}^2\backslash\{(\frac{1}{2},\frac{1}{2})\}\rightarrow S^1,\quad (x,y)\rightarrow\ \frac{(x,y)-(\frac{1}{2},\frac{1}{2})}{||(x,y)-(\frac{1}{2},\frac{1}{2})||}$$ Then $r\circ \phi\circ (ab)$ is a loop on $S^1$ , such that $$(r\circ \phi\circ (ab))(t+\frac{1}{2})=-(r\circ \phi\circ (ab))(t),\quad\forall t\in [0,\frac{1}{2}]$$ So $<r\circ \phi\circ (ab)>$ is not trivial in $\pi_1(S^1)$ . However, $ab$ is path homotopic to $c$ in $D$ , where $c$ is the path between $(0,0)$ and $(1,1)$ in $D$ . In this case, $r\circ \phi\circ (ab)$ is a point-path in $S^1$ by $$(\phi\circ c)(t)=\phi(t,t)\equiv (0,0)$$ which leads to contradiction.","['algebraic-topology', 'real-analysis']"
3663795,Intersection of pullback divisor and exceptional divisor,"Let $X,Y$ are nonsingular complex projective surfaces and $f:Y\to X$ be a birational morphism. Let $E_1,\ldots,E_k$ are irreducible exceptional divisors of $f$ . In this situation, we have $K_Y=f^{\ast}K_X+\sum_{i=1}^{k}m_iE_i (m_i>0)$ ( $K_Y,K_X$ : canonical divisor of $Y,X$ ) How to prove $(f^{\ast}K_X)\cdot E_i=0 (\forall i)$ ? More generally,Is it true that $(f^\ast D)\cdot E_i=0$ for all $i$ and for all divisor $D$ on $X$ ?","['algebraic-geometry', 'birational-geometry']"
3663805,"What is the measure of the set $\left\{\frac{1}{2}\right\}\cup\left\{\frac{1}{4},\frac{3}{4}\right\}\cup\cdots$?","Consider the set $S=\left\{\frac{1}{2}\right\}\cup\left\{\frac{1}{4},\frac{3}{4}\right\}\cup\left\{\frac{1}{8},\frac{3}{8},\frac{5}{8},\frac{7}{8}\right\}\cup\cdots$ . This set can be created by iteratively taking out the midpoints from a set of line segments ( Sketch ). Firstly one takes out the midpoint of the interval $(0,1)$ , leaving two line segments: $\left(0,\frac{1}{2}\right)\cup\left(\frac{1}{2},1\right)$ Ôºå then takes out the midpoints $\left\{\frac{1}{4},\frac{3}{4}\right\}$ of this two intervals, leaving line segments: $\left(0,\frac{1}{4}\right)\cup\left(\frac{1}{4},\frac{1}{2}\right)\cup\left(\frac{1}{2},\frac{3}{4}\right)\cup\left(\frac{3}{4},1\right)$ ... This process is continued ad infinitum because one just takes out finite points each time.
And after each time the remaining part is a countable uion of intervals so it is a measurable set, e.g. after the nth step there are $2^n$ intervals with the measure $\frac{1}{2^n}$ , hence the measure of the set left is always $1$ .The original set $(0,1)$ has the measure $1$ , so the measure of $S$ is $1-1=0$ . On other hand, the elements in $S$ can be writen in binary form $S=\left\{0.1_2\right\}\cup\left\{0.01_2,0.11_2\right\}\cup\left\{0.001_2,0.011_2,0.101_2,0.111_2\right\}\cup\cdots$ . So $S$ is the set of all the binary number in interval $(0,1)$ , that is $S=(0,1)$ . So the measure of $S$ is $1$ . So what is the measure of $S$ ? Update Why I think $S=(0,1)$ is because one can write $S$ in this form: $$
S=\bigcup_{n=1}^{\infty}S_n
\\
S_n=\{x|x=(0.a_1\cdots a_{n-1}1)_2=\frac{1}{2^n}+\sum_{k=1}^{n-1}a_k2^{-k},a_k=0\ \mathrm{or}\ 1\}
$$ and I think the infinite binary decimal like $\frac{1}{3}$ is belong to the subset $S_{\infty}$ . Also I want the Lebesgue measure of $S$ .","['elementary-set-theory', 'measure-theory', 'real-analysis']"
3663825,How to prove that whether it is a Banach space or not?,"We consider the Banach space of all continuous functions on $X$ such that for each $f$ in the space, \begin{equation*}
||f||=\sup_{x\neq y}\frac{\left\vert
f(x)-f(y)\right\vert }{\left\vert x-y\right\vert }.
\end{equation*} How I can prove that it is a Banach space?","['functional-equations', 'banach-spaces', 'normed-spaces', 'metric-spaces', 'functional-analysis']"
3663846,"Does a term exist to describe the output cardinality of a function, analogous to function 'arity'?","I've seen functions described as bivariate, multivariate, etc. or as unary, binary, n-ary as a way to denote that they take a certain number of inputs or parameters. However, I have not found an equivalent term to describe the number of outputs a function can/does produce. For example, a function like the following: [r, phi] = polar(x, y) would be described as bivariate, binary, or dyadic since it has two parameters, but how would one describe the property of also having two output values? Of course, I understand that these sorts of multi-valued outputs can be contained as a ""single"" vector/matrix/array, but I'd still like to know the general terminology.","['functions', 'terminology']"
3663986,Solving $\int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x} \right)dx$,"In this answer to another question, the following equation comes up $$g(x)=\sum_{m = -\infty}^{\infty} 2^m x \cdot e^{- 2^m x}$$ I am interested in the average value of $g(x)$ in the interval of $1 < x < 2$ , which would be $$\frac{1}{2-1} \int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x}\right) dx = \sum_{m=-\infty}^{\infty}\left( \int_1^2 2^mx\cdot e^{-2^mx}dx\right)$$ Mathematica gives the inner integral as $(-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m}$ , so this can be simplified to $$\sum_{m=-\infty}^{\infty} \left((-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m}\right) \approx 1.4427$$ This is very close to $\frac{1}{\ln(2)}$ , which leads me to believe that that is the closed form (although I am not sure). This is as far as I managed to get. How can I find the exact value of $\int_1^2 g(x)dx$ ? Edit: I managed to rewrite the sum as $$\lim_{N \to \infty}\left( 2^N-\sum_{m=-N+1}^{N}\left(1+2^{-m}\right)e^{-2^{m}}\right)$$ However, this form is much worse for numerical calculations.","['integration', 'definite-integrals', 'real-analysis', 'sequences-and-series', 'exponential-function']"
3663995,Number of random unit vectors which are less than theta apart,"Given $n$ unit vectors which are uniformly distributed on a unit sphere, what the expected number of groups of $k$ vectors which are within an angle $\theta$ of one another For example, if I have $n=50$ unit vectors, what is the expected number of triplets of vectors ( $k=3$ ) that are within $\theta=20^\circ$ of one another? From simulation it seems like ~13.5","['statistics', 'combinatorics', 'geometric-probability', 'probability']"
3664030,How do we find the number of sub-intervals whose intersection with the subset of the entire interval is non-empty?,"Suppose we have set $A=\left\{\frac{1}{k}:k\in\mathbb{N}\right\}$ and we divide interval $[0,1]$ into $n$ sub-intervals of equal length. How do we find the exact forumula (or approximation) of the number sub-intervals $f(n)$ whose intersection with $A$ is non-empty? Here is what I found $$\begin{array}{|c|c|}
\hline
n & f(n) \\ \hline
1  &  1  \\ \hline
2  &  2  \\ \hline
3  &  3  \\ \hline
4  &  4  \\ \hline
5  &  4  \\ \hline
6  &  5  \\ \hline
7  &  5  \\ \hline
8  &  6  \\ \hline
9  &  6  \\ \hline
11 &  6  \\ \hline
12 &  8  \\ \hline
13 &  7  \\ \hline
14 &  8  \\ \hline
15 &  8  \\ \hline
\end{array}$$ It seems difficult to find an exact formula since $f(n)$ can, at times, go backwards as $n$ increases. An approximation is more reasonable. In case you find an approximation, can you go into detail on how you found it? Edit: Using graphs I found the approximation is $$f(n)\approx \frac{\ln(n)^2}{2\ln(2)^2}-\frac{3\ln(n)}{2\ln(2)}+4$$ When $n>32$ but I don't know how to mathematically derive it. Edit: I was wrong, see @Joriki‚Äôs answer. However, he didn‚Äôt fully answer my second question. How would you apply your process to approximate $f(n)$ for more complex sets such as $$A=\left\{\frac{1}{2^x}+\frac{1}{2^y}+\frac{1}{2^z}:x,y,z\in\mathbb{N} \right\}\cap[0,1]$$","['number-theory', 'pattern-matching', 'elementary-set-theory', 'descriptive-set-theory', 'pattern-recognition']"
3664112,Understanding a Measure-valued (Bochner?) Integral,"Let $X$ be a compact metric space, and let $\mathcal P(X)$ be the (compact, metrisable) space of Borel probability measures on $X$ . Similarly, $\mathcal P (\mathcal P (X))$ is the space of Borel probability measures on $\mathcal P (X)$ . I want to make sense of the integral $$ \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \tag{INT}\label{INT} $$ where $\tau \in \mathcal P (\mathcal P (X))$ . Is there an elementary definition of this integral? (See the end of the question for an elaboration of what I mean by ""elementary"".) It seems one way to interpret \eqref{INT} is to view it as a Bochner integral , by considering $\mathcal P(X)$ as a (compact, convex) subset of the Banach space of finite signed Borel measures on $X$ with the total variation norm. One property of the Bochner integral is that, for any bounded operator $T\colon \mathcal P(X) \to Y$ where $Y$ is another Banach space, we have that $$ \int_{\mathcal P (X)} T\mu\,\mathrm d\tau (\mu) = T \left( \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \right). \tag{*}\label{*} $$ In particular, suppose that $Y = L(C(X),\mathbb R)$ , the space of bounded linear functionals on $C(X)$ , and $T$ is the operator given by $$ \mu \mapsto \left(\begin{align*} C(X) &\to \mathbb R \\ f &\mapsto \int_X f(x) \,\mathrm d \mu(x) \end{align*}\right). $$ Then, we can parse \eqref{*} as $$ \int_X f(x) \, \mathrm d \mu_0 (x) = \int_{\mathcal P(X)} \int_X f(x) \,\mathrm d \mu(x) \,\mathrm d \tau (\mu) \tag{+} \label{+} $$ for each $f \in C(X)$ , where $\mu_0$ is just the value of \eqref{INT}. Hopefully, everything I've said so far is correct. (Please do point out mistakes if there are any.) If so, can I take \eqref{+} as the definition of \eqref{INT}? That is, I would like to define \eqref{INT} as the $\mu_0 \in \mathcal P(X)$ that satisfies \eqref{+} for each $f \in C(X)$ . Do I lose any important properties of the integral by using this definition? I am looking for a definition of \eqref{INT} without too much additional machinery, beyond what you would see in a typical introductory measure theory or functional analysis course. I was hoping \eqref{+} would do, but I am also open to alternative suggestions. Additionally, if anyone can recommend a nice, readable reference for this material, I'd appreciate that as well. An ideal reference would be one that's accessible to someone who only knows a little measure theory and functional analysis, but I'll take what I can get.","['integration', 'measure-theory', 'reference-request', 'functional-analysis', 'convex-analysis']"
3664117,Prove that every point has been assigned the same number.,"Question: Every point in a plane is assigned some real number. It is found that for any triangle, the
  number at its incenter is the arithmetic mean of numbers at the vertices. Prove that every
  point has been assigned the same number. Solution: Let us take any two random points $A$ and $D$ on the real plane $\mathbb{R}^2$ . Now let us select two points $B$ and $C$ such that $AD||BC, AD<BC$ and $AB=DC$ . Also let the real numbers assigned to $A,B,C,D$ be $a,b,c,d$ respectively. Observe that $ABCD$ is an isosceles trapezium with $AB=DC$ . Now let us produce $BA$ and $CD$ to meet at $E$ . Observe that in $\Delta EAD$ , we have $\angle EAD=\angle EDA\implies EA=ED$ . Thus we also have $EB=EC$ . Hence, $\Delta EAD$ and $\Delta EBC$ are both isosceles triangles with $EA=ED$ and $EB=EC$ respectively. Let the perpendicular dropped from $E$ to $BC$ meet $BC$ at $F$ . Now consider $\Delta EBD$ . $EF$ is the angle bisector of $\angle BED$ and let that the angle bisector of $\angle EBD$ meet $EF$ at $I$ . Thus $I$ is the incentre of $\Delta EBD$ . Now consider $\Delta ECA$ . $EF$ is the angle bisector of $\angle AEC$ . Join $C$ and $I$ . Observe that $\Delta EBI$ and $\Delta ECI$ are congruent triangles, which implies that $\angle EBI=\angle ECI=x$ (let). This implies that $\angle EBI=\angle IBD=x$ , which in turn implies that $\angle EBD=
2x$ . Again, $\Delta ADB \cong \Delta DAC\implies \angle DBA=\angle ACD\implies 2x=x+\angle ICA\implies \angle ICA=x.$ Hence, $\angle ICD=\angle ICA=x$ , which implies that $CI$ is the angle bisector of $\angle ECA$ . Hence, we can conclude that $I$ is also the incenter of $\Delta ECA$ . Hence the number assigned to $$I=\frac{b+d+e}{3}=\frac{a+c+e}{3}.$$ Thus we have $b+d=c+a$ . Thus, we can conclude that for any random isosceles trapezium $ABCD$ with $AD||BC$ and $AD<BC$ having real numbers $a,b,c,d$ assigned to vertices $A,B,C,D$ respectively, we will have $$a+c=b+d.$$ Let this property be called $\phi$ . Now select any two random points $A'$ and $B'$ on the real plane $\mathbb{R}^2$ and construct a regular pentagon $A'B'C'D'E'$ . Let the real number assigned to $A',B',C',D',E'$ be $a',b',c',d',e'$ respectively. Now $B'C'E'D'$ is an isosceles trapezium, hence by $\phi$ , we have $b'+d'=e'+c'$ . Similarly, $e'+c'=a'+d'$ , $a'+c'=b'+d'$ and $b'+e'=a'+d'$ . From these four equations we can conclude that $a'=b'=c'=d'=e'$ . Thus we have $a'=b'$ . From here, we can conclude that, since $A$ and $B$ were randomly chosen, therefore, we can reach to the same conclusion, i.e, $a'=b'$ , with any other pair of points $\in\mathbb{R}^2$ . Hence, we can conclude that every point on the real plane $\mathbb{R}^2$ has been assigned the same number. Is this solution correct and is there a better solution than this one?","['combinatorial-geometry', 'solution-verification', 'combinatorics', 'geometry']"
3664131,What is the degree of a vector bundle?,"I heard that the degree of a vector bundle encodes the number of ""twists"" of the bundle. I heard also that it is roughly the difference between number of roots and number of poles of a  function in a local ring. Which one is true? I couldn't find any reference to that in Hartshorne or in the Vakil. Thank you for any help/hints.","['vector-bundles', 'algebraic-geometry']"
3664142,Equivalence of Hausdorff and Spherical measure on $\mathbb{S}^{n}$,"Let $\Sigma$ be a submanifolds $C^{1}$ of $\mathbb{R}^{n}$ $k$ -th dimensional and let $g : \Omega \subseteq \mathbb{R}^{k} \longmapsto \Sigma \subseteq \mathbb{R}^{n}$ $C^{1}$ with $g$ injective and $\text{D}g(x)$ injective. Given $A \subseteq \Omega$ Borel set or Lebesgue measurable we define $H_{k}(g(A)) := \int_{A} \sqrt{\text{det}(\text{D}g(x)^{T}\text{D}g(x))} dH_{k}$ . $H_{k}$ defines a well defined measure invariant by $C^{1}$ reparametrization. Now, let $E \subseteq \partial B(0,1,\mathbb{R}^{n+1})$ be a Borelian set. We set $m(E) := \frac{n+1}{r} \lambda_{n+1}([0,1]E)$ , where $\lambda_{n+1}$ is the Lebesgue $n+1$ dimensional measure and $[0,1]E = \left\lbrace tx : t \in [0,1] , x \in E\right\rbrace$ . I'd like to prove that the measure defined are equivalent. I know there is an important characterization of uniformely distributed measure by Christensen, cited here , but since I don't have the knowledge required to understand it. I determined a parametrization of $\mathbb{S}^{n}$ , with polar coordinates I tried to compute $\text{det}(\text{D}g(x)^{T}\text{D}g(x))$ , without success. The idea was to compute the determinant cited above and compare with the integral given by the defition of $m(E)$ , but I was unable to do so. Was my intetion correct ? Any help or hint would be appreciated.","['measure-theory', 'lebesgue-measure', 'submanifold', 'lebesgue-integral', 'polar-coordinates']"
3664146,"Is ""False"" in logic analogous to ""Null set"" in set theory?","I have been doing proofs in elementary set theory, and so far, just using definitions (like below) and applying propositional logic has sufficed. A ‚ãÉ B = e ‚àà A ‚à® e ‚àà B
A ‚äÇ B = e ‚àà A ‚üπ e ‚àà B
A' = e ‚àâ A = ¬¨(e ‚àà A) So the proofs are as follows: Convert set theory operations to their ""logical"" definitions Shuffle the symbols using logical identities Convert back from logic land to set theory land Here is my question : Is the logical analogous to the null set - √ò - the boolean false? Is the logical analogous to the universal set - U - the boolean true? More formally, are these definitions correct? √ò = {e | false}
U = {e | true} Here's my proof for: A ‚äÇ B ‚üπ A ‚ãÇ B‚Äô = √ò , for example, where I use false for √ò: A ‚äÇ B ‚üπ A ‚ãÇ B‚Äô = √ò
‚â° {Definition of Set Intersection and Subset, Definition of √ò}
[e ‚àà A ‚üπ e ‚àà B] ‚üπ [e ‚àà A ‚àß e ‚àà B‚Äô = false]
‚â° {Exportation: A ‚üπ [B ‚üπ C] ‚â° [A ‚àß B] ‚üπ C}
[e ‚àà A ‚àß e ‚àà B] ‚üπ [e ‚àà A ‚àß e ‚àà B‚Äô = false]

Context 1. e ‚àà A
Context 2. e ‚àà B

e ‚àà A ‚àß e ‚àà B‚Äô
‚â° {Context 1}
e ‚àà B‚Äô 
‚â° {Definition of ‚Äò}
¬¨(e ‚àà B)
‚â° {Context 2, Contradiction}
false
‚â° {Definition of √ò}
√ò Is the use of false for √ò valid in the proof above?","['elementary-set-theory', 'logic', 'discrete-mathematics']"
3664244,"Let $Z\in \mathcal{N}(0,I)$ and $A=\{(x_1,x_2,x_3): x_1\le x_2 \le x_3 \}$. Show $P(Z+\mu \in A) \le P(Z \in A)$ is $\mu \notin A$.","Suppose that $A=\{(x_1,x_2,x_3):  x_1\le x_2 \le x_3 \}$ .  Let $Z \in \mathbb{R}^3$ be a standard normal random vector. I am trying to see if the following inequality is true \begin{align}
P(Z+\mu \in A) \le  P(Z \in A)
\end{align} for all $\mu \notin A$ . My intuition: I am thinking of $Z$ as a ball centered at zero and $A$ as a cone starting at zero.  If we move a center of the ball farther from the cone, then the intersection (probability) should go down.","['probability-theory', 'probability']"
3664254,Possible periods of periodic sequences of reals obeying $x_{n+2} = 1+x_{n+1} x_n.$,"If $\{x_n\}$ is a real sequence with period $T$ obeying $x_{n+2} = 1+x_{n+1} x_n,$ what are the possible values of $T$ ? $T=3$ is possible: $2, -1, -1, 2, \dots$ . In fact, some analysis shows this to be the only example. I have ruled out $T=2, 4$ after some work, and $T=1$ does not work since the roots of $x^2+1=x$ are non-real. Does anyone have any ideas about non-brute force methods for ruling out or finding higher values of $T$ ? Edit: I have determined $0$ cannot be part of a periodic sequence, and a periodic sequence must have sign pattern $+--+--\dots,$ ruling out all periods that are not multiples of $3.$ First note $++$ makes the sequence unbounded, so $+$ is followed by $-.$ This also means $-+$ is followed by $-.$ A lengthy analysis of magnitudes reveals that $+-+$ is impossible, so $+-$ is followed by $-.$ Finally, $--$ is clearly followed by $+.$ If $0, a, \dots, b, 0, a, \dots$ is periodic, then $a = b \cdot 0 + 1 = 1,$ so the sequence begins $0,1,$ which does not work.","['periodic-functions', 'sequences-and-series']"
3664348,Pouring water from bottles,"There are three buckets of size $x_1, x_2$ , and $x_3$ liters (positive, but not necessarily integers), and some bottles, possibly of different sizes, containing a total of $x_1+x_2+x_3$ liters of water. We want to pour water from the bottles into the buckets. A bottle is split if it is poured into more than one bucket. Is it true that for any $x_1,x_2,x_3$ , there are bottle sizes such that we need to split two bottles? By pouring water into the first bucket until it is full, then second bucket, and third, we will never need to split more than two bottles. For the case $(x_1,x_2,x_3)=(1,3,6)$ , @WhatsUp's example with three bottles of capacity $10/3$ shows that we do need to split two bottles (that is, splitting one bottle does not suffice).","['optimization', 'combinatorics', 'algorithms']"
3664507,"Integral $\lim _{n\to \infty}\int _0^1\sqrt{\frac{1}{x}+n^2x^{2n}}\,dx$","Evaluate $\displaystyle \lim \limits _{n\to \infty}\int \limits _0^1\sqrt{\frac{1}{x}+n^2x^{2n}}\,dx$ . The integral is non asymptotic. The convergence is non uniform at both $x=0$ and $x=1$ . I'm not sure how to proceed.","['integration', 'measure-theory', 'real-analysis', 'calculus', 'limits']"
3664540,"Real Analysis, Folland Proposition $2.34$","Proposition $2.34$ : a. if $E\in \mathcal{M}\times \mathcal{N}$ , then $E_x\in\mathcal{N}$ for all $x\in X$ and $E^y\in\mathcal{M}$ for all $y\in Y$ . In the proof of the above, we define $$\mathcal{R}:=\{F\subseteq X\times Y|\enspace F_x\in\mathcal{N}\text{ for all }x\in X\text{ and }F^y\in\mathcal{M}\text{ for all }y\in Y\}$$ We do the following two things: (i) $\mathcal{R}$ is a $\sigma$ -algebra (ii) $\mathcal{M}\times\mathcal{N}\subseteq\mathcal{R}$ Now, to show that $\mathcal{R}$ is a $\sigma$ -algebra $\phi$ , $X\times Y\in\mathcal{R}$ This is true because $\phi\in\mathcal{N}$ and $\phi\in\mathcal{M}$ . Similarly, $Y\in\mathcal{N}$ and $X\in\mathcal{M}$ . For $F\in \mathcal{R}$ , then need to show: $F^c\in\mathcal{R}$ $(F^c)_x\stackrel{?}{=}(F_x)^c$ and $(F^c)_y\stackrel{?}{=}(F_y)^c$ If $\{F_j\}_{j\ge1}\in\mathcal{R}$ , then need to show that $\bigcup_{j=1}^\infty F_j\in\mathcal{R}$ $(\bigcup_{j=1}^\infty F_j)_x\stackrel{?}{=}\bigcup_{j=1}^\infty(F_x)_j$ and $\bigcup_{j=1}^\infty(F_j)_y\stackrel{?}{=}\bigcup_{j=1}^\infty(F_y)_j$ Can anyone help me to understand the question mark(?) in the above? Thanks.",['measure-theory']
3664620,"If $T_n = \{\frac{a}{n} \mid a \in \mathbb{Z}\}$, then what are $\bigcup_{n\in\mathbb{N}}T_n$ and $\bigcap_{n\in\mathbb{N}}T_n$?","For each positive integer $n$ , let $T_n = \{\frac{a}{n} \mid a \in \mathbb{Z}\}$ . What are $\bigcup_{n \in \mathbb{N}} T_n$ and $\bigcap_{n \in \mathbb{N}} T_n$ ? I'm pretty sure the first one is just $\mathbb{Q}$ , the rationals. Since the set will have all possible numerators over all possible denominators. The second I'm not so sure of. It's certainly not empty, since $1/2 = 2/4$ so $T_2$ and $T_4$ have non-empty intersection. I am currently leaning towards this set also being $\mathbb{Q}$ , since we will get every fraction here as well: if $a/b$ is in $T_b$ , then it is also in $T_{2b}$ as $2a/2b$ .","['elementary-set-theory', 'elementary-number-theory']"
3664794,Find $\lim _{r\to \infty}\frac{\left(\prod_{n=1}^{r}\sin\left(nx\right)\right)}{\left(\frac{1}{r}\right)}$,"$\lim _{r\to \infty}\frac{\left(\prod_{n=1}^{r}\sin\left(nx\right)\right)}{\left(\frac{1}{r}\right)}$ I tried using the product sin formula but got nowhere.& even after multipling and dividing by $2cos (x)$ ,   answer couldnt be obtained as only multiples of two cut out themselves. it is a 0/0 indeterminate form. Also I didn't get the answer by using the l's-hopital rule. I even tried graphing it on desmos, but the graph was strange--- ( I think even desmos couldn't compute it further) please help. thanks in advanced..............","['trigonometric-series', 'limits-without-lhopital', 'calculus', 'limits', 'trigonometry']"
3664810,Solving a functional equation in CDF's of probability distributions,"Reading a paper I've come across the following functional equation for unknown CDF's $F_1, F_2$ of centered probability distributions $\mu_1, \mu_2$ with variance $1$ : $$F^{-1}(G_2(x+y)) = F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y))\qquad \text{for all} \ (x,y) \in \mathbb{R}^2$$ where $G_i$ is the CDF of a centered gaussian with Variance $i$ and $F$ is the CDF of the convolution $\mu_1 \ast \mu_2$ . The unique solution is actually $F_1 = F_2 = G_1$ but I've not been able to proof that. I (think I) can show that $F_1 = F_2$ : $$F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y)) = F^{-1}(G_2(x+y)) = F^{-1}(G_2(y+x)) = F_1^{-1}(G_1(y))+ F_2^{-1}(G_1(x))$$ so $$F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x)) = F_1^{-1}(G_1(y)) - F_2^{-1}(G_1(y))$$ which means, that $F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x))$ is constant, since the right-hand side does not depend on $x$ . If the difference was not $0$ then either $\mu_1$ or $\mu_2$ is not centered since, $\mathbb{E}[\mu_i] = \int_0^1 F_i^{-1}(y)dy$ , so $F_1 = F_2$ . Is this argument correct? How can I proceed to show uniqueness of solution? You can find the paper here - the functional equation is part of the proof of Theorem 2 on page 49.","['functional-equations', 'measure-theory', 'probability']"
3664828,How can I calculate the curl of this vector field?,"I have a vector field which is originallly written as $$ \mathbf A = \frac{\mu_0~n~I}{2} ~\hat \theta$$ and I translated it like this $$\mathbf A = 0 ~\hat{r},~~ \frac{\mu_0 ~n~I~r}{2} ~\hat{\theta} , ~~0 ~\hat{\phi}$$ ( $r$ is the distance from origin, $\theta$ is azimuthal angle and $\phi$ is the polar angle). I want to calculate its divergence, so I have two options either change it into Cartesian system and then take the curl or take the curl in spherical coordinates. Let‚Äôs take the curl in spherical coordinates: $$(curl~\mathbf A)_r = \frac{1}{r\sin \theta} \frac{\partial (A_{\phi} \sin \theta)}{\theta} -\frac{1}{r\sin \theta} \frac{\partial A_{\theta}}{\partial \theta}$$ I really don't know what is $r$ and that $\sin \theta$ which appearing in the first term above, nevertheless, it is zero as $A_{\phi}$ is zero and even our $A_\theta$ is independent of $\theta$ , therefore, whole term above is zero. So, we have $(curl~\mathbf A)_r = 0$ . We have $$(curl~\mathbf A)_{\theta} = \frac{1}{r\sin \theta} \frac{\partial A_r}{\partial \phi} - \frac{1}{r} \frac{\partial ( r A_{\phi} )}{\partial r}$$ I want to repeat that I don't know if those $r$ and $\sin \theta$ are part of my vector field or not, nonetheless, both terms will be zero because $A_r$ and $A_{\phi}$ are zero. Therefore, $(curl~\mathbf A)_{\theta} = 0$ . The last component, $$(curl~\mathbf A)_{\phi}=\frac{1}{r} \frac{\partial (rA_{\theta})}{\partial r} - \frac{1}{r} \frac{\partial A_r}{\partial \theta}$$ I'm just assuming that $r$ which appears in the formula above is same as the one which appears in my vector field. $$(curl~\mathbf A)_{\phi}= \frac{\mu_0 ~n~I}{2r} \frac{\partial r^2}{\partial r}$$ $$ (curl~\mathbf A)_{\phi} = \mu_0~n~I $$ Now, I want to know if I'm correct. How can convert the above result into cartesian system? Well, I have something like this (if we call curl of $\mathbf A$ as $\mathbf B$ ) $$ \mathbf B( r, \theta, \phi) = \left( 0, 0 , \mu_0 ~n~I \right)$$ we don't have $\phi$ as an angle and all three $x, ~y, ~z$ involve either $sine$ or $cosine$ of $\phi$ and multiplication by $r$ as $$ x=r\sin\phi \cos\theta\\ \hspace{10px} y=r\sin\phi \sin\theta \\ z =r\cos\phi$$ so, in that sense all the cartesian components are zero because $r$ is zero. Please guide me through it.","['multivariable-calculus', 'spherical-coordinates', 'derivatives', 'curl']"
3664872,Prove that $\sin(\tan 1)>\tan(\sin 1)$,"Prove that $\sin(\tan 1)>\tan(\sin 1)$ ?
All given measurements are in radians. I have tried comparing the graphs of $\sin x$ and $\tan x$ but I wasn't able to proceed with it.",['trigonometry']
3664901,What will be the probability of the sum of n random numbers to be greater than X?,"I want to figure out a way/formula by which I can compute the probability of the sum of $n$ random numbers to be greater than $X$ . All the random numbers fall in the range of $[-1000 , -1.01]\cup \{0\}\cup [1.01,1000]$ and step size is $0.01$ Each random number is chosen independently. Use Case: I am working on the development project of a gaming engine. For each round a player is awarded a random score in the range of $[-1000 , -1.01]\cup \{0\}\cup [1.01,1000]$ . In the beginning, player can make a bet that after n rounds of the play the total sum of his score will be X. I just want to get the probability of the accuracy of his bet. Current Progress - I was able to somehow get the results using brute force approach ( n rolling dice problem ), however the brute force method is taking lots of computation power. I want an efficient formulae/solution (in terms of computation) I don't know if Convolutions is the right approach for it. Thanks for the help, in advance!","['statistics', 'probability-distributions', 'probability']"
3664923,Relationship Between Topological Closure and Group Generation,Let $X\subset G$ be a subset of a topological group $G$ .  How are $cl(\langle X\rangle)$ and $\langle cl(X)\rangle$ related in general?  Are there results giving conditions on equality of the two? Here $\langle X\rangle $ is the subgroup generated by $X$ and $cl(X)$ is the (topological) closure of $X$ in $G$ .,"['general-topology', 'topological-groups', 'group-theory']"
3664946,What exactly is a tangent space?,"I'm self learning differential geometry and got confused by the definition of tangent space. The note I'm using defines tangent space of a smooth manifold $X\subset R^N$ with parametrization $f:U\rightarrow X$ as follow: $$T_xX=df_0(R^N) $$ where $$df_x=lim\frac{f(x+th)-f(x)}{t}$$ and $f(0)=x$ . So I suppose that if $f:R^N\rightarrow R$ , the tangent space would consist of real numbers. However, when I was reading the example on page 4 of this note ( https://folk.ntnu.no/gereonq/TMA4190V2018/TMA4190_Lecture12.pdf ), it states that the tangent space of a $f:R^3 \rightarrow R$ is $span\{(-z,0,x),(0,-z,y)\}$ which is not an output of the $df_x$ defined previously. Can someone please explain what exactly a tangent space is? Any help would be appreciated. I realized that I mistook the direction of the map in the example mentioned above.","['manifolds', 'differential-topology', 'differential-geometry']"
3664966,Isomorphism between schemes,I'm trying to show that every closed subscheme $Y$ of an affine scheme $X = \operatorname{Spec}(R)$ is isomorphic to $\operatorname{Spec}(R/I)$ for some ideal $I$ of $R$ . I try to show that there exists an isomorphism of schemes $Y \to \operatorname{Spec}(R/I)$ where $I = \ker\big( R \to \mathcal{O}_Y(Y)\big)$ . I already managed to show that the map on the underlying topological spaces is a homeomorphism but I'm having trouble proving that the map $\mathcal{O}_{\operatorname{Spec}(R/I)} \to \mathcal{O}_Y$ is a bijection. I know that by definition it is surjective but I don't really know how I can show injectivity.,"['algebraic-geometry', 'schemes']"
3664974,How to improve $\int_{0}^{\frac{\pi}{2}}x\left(\frac{\sin(nx)}{\sin(x)}\right)^{4}dx<\frac{\pi^{2}n^{2}}{4}$,"I have proved this inequality $\int_{0}^{\frac{\pi}{2}}x\left(\frac{\sin(nx)}{\sin(x)}\right)^{4}dx<\frac{\pi^{2}n^{2}}{4}$ . Using $\left|\sin(nx)\right|\leq n\left|\sin(x)\right|$ on $[0,\frac{\pi}{2n}]$ and $\frac{\left|\sin(nx)\right|}{\left|\sin(x)\right|}\leq\frac{\pi}{2x}$ on $[\frac{\pi}{2n},\frac{\pi}{2}]$ ,we can have $$\int_{0}^{\frac{\pi}{2}}x\left(\frac{\sin(nx)}{\sin(x)}\right)^{4}dx<\frac{\pi^{2}n^{2}}{8}+\frac{\pi^{2}}{8}\left(n^{2}-1\right)<\frac{\pi^{2}n^{2}}{4}.$$ But using mathematica I found this inequality can still be improved. And after calculating some terms I found it seems that when $n\geq 2$ we can have $$\int_{0}^{\frac{\pi}{2}}x\left(\frac{\sin(nx)}{\sin(x)}\right)^{4}dx<\frac{\pi^{2}n^{2}}{8}.$$ But I cannot prove this.So is there any method to improve my result?Any help will be thanked.","['integration', 'calculus', 'inequality', 'real-analysis']"
3665045,Radius of convergence of all taylor series of f are uniformly bounded then analytic,"Let $f \in C^{\infty}( \mathbb{R},\mathbb{R})$ such that the radius of convergence of all taylor series of $f$ are uniformly bounded . Then $f$ is analytic. I don't know if this result is true or not , i was working on analytic functions and i asked myself this question . I searched to find something similar , i am not able to prove it or find an example ...","['complex-analysis', 'real-analysis']"
3665131,$\lim\limits_{x\to \infty} f'(x)=1$ implies $f:\mathbb {R\to R}$ is unbounded.,"Is my solution to the following problem correct?This is a problem from TIFR GS $2014$ .Can someone provide me with a better solution? Let $f:\mathbb {R\to R}$ be differentiable and $f'(x)\to 1$ as $x\to \infty$ ,show that $f$ is unbounded. Solution: Since, $\lim\limits_{x\to \infty} f'(x)=1$ ,so there exists $x_0\in \mathbb R$ such that, $x>x_0\implies 1-\frac{1}{100}<f'(x)<1+\frac{1}{100}$ So, $ f'(x)>0$ for all $x\in [x_0,\infty)$ So, $f$ is increasing on $[x_0,\infty)$ . If $f$ is bounded,then let $s=\sup\limits_{x\in [x_0,\infty)} f(x)$ . Let $\epsilon>0$ (small) Take $s-\epsilon$ ,then there exists $x\in [x_0,\infty)$ such that $s-\epsilon<f(x)\leq s$ . Since, $f$ is increasing on $[x_0,\infty)$ ,so for each $t>x$ we have $s-\epsilon<f(x)\leq f(t)\leq s$ . Choose $x+2\epsilon>x$ We can apply LMVT on $f$ in the interval $[x,x+2\epsilon]$ to get $c\in (x,x+2\epsilon)$ such that $f(x+2\epsilon)=f(x)+2\epsilon . f'(c)$ Now, $1-\frac{1}{100}<f'(c)<1+\frac{1}{100}$ So, $2\epsilon(1-\frac{1}{100})<2\epsilon.f'(c)<2\epsilon(1+\frac{1}{100})$ $\implies f(x)+2\epsilon(1-\frac{1}{100})<f(x+2\epsilon)<f(x)+2\epsilon(1+\frac{1}{100})$ Now, $s-\epsilon<f(x)\leq s$ ,so $s<s+\frac{49\epsilon}{50}=s+\epsilon-\frac{\epsilon}{50}=s-\epsilon+2\epsilon(1-\frac{1}{100})<f(x)+2\epsilon(1-\frac{1}{100})<f(x+2\epsilon)$ ,which is a contradiction as $f(x+2\epsilon)\leq s$ .","['real-analysis', 'alternative-proof', 'solution-verification', 'limits', 'derivatives']"
3665204,What would be the domain of the function $\sqrt{\frac{\log_{0.2}(x-1)}{x^2-2x-8}}$?,"I need to find the domain of the function $$f(x)= \sqrt{\frac{\log_{0.2}(x-1)}{x^2-2x-8}}$$ Here's how far I could get: So clearly for the square root to be real, whatever's inside has to be greater than or equal to 0. $$\implies \frac{\log_{0.2}(x-1)}{x^2-2x-8} \geq 0$$ $$\implies \frac{\log_{0.2}(x-1)}{(x+2)(x-4)}\geq 0$$ Also, for the logarithm to exist, clearly $x>1$ But how do I proceed? Clearly for this to be greater than 0, both the numerator and the denominator must be of the same sign, i.e, either both have to be positive or both have to be negative. But how do I set those conditions?","['functions', 'logarithms']"
3665377,Example of set which has a boundary of non-zero measure,"A subset $S$ of $\Bbb R^n$ is Jordan measurable if and only if the measure of the set of its boundary points is zero. Basically I tried to imagine a set which has boundary points of nonzero measure, but I couldn't. Can you give me some examples? In my mind every boundary set of points of any set has zero measure.","['measure-theory', 'functional-analysis', 'examples-counterexamples', 'real-analysis']"
3665386,Isometric isomorphism between Hardy Space $h^p(\mathbb{D})$ and $L^p(\mathbb{T})$,"I know the question below is a known result but, I would need some help to prove it! Well, I know that in the Poisson integral induces an isometric isomorphism between $L^p(\mathbb{T})$ and the Hardy space $h^p(\mathbb{D})$ for $p>1$ . I'm reading Function Spaces and Partial Differential Equations: Classical analysis and this question is the remark 5.24 but it's not proved. Now how can I do to prove this? Thanks. EDIT: The definition of $h^p$ that I have is this: $h^p(\mathbb{D})=\{u\in Har{\mathbb{D}: ||u||_{h^p}=sup_{0<r<1}M_{p}(u,r)< \infty}$ }, where the $Har\{\mathbb{D}\}$ are the group of harmonic functions while $M_{p}(u,r)=(\int_{-\pi}^{\pi}|u(re^{it})|^p\frac{dt}{2 \pi})^\frac{1}{p}$ .","['complex-analysis', 'isometry', 'group-isomorphism', 'harmonic-analysis']"
3665390,Is$ \int_{0}^{\pi} f^{2}(x) d x$ divergent or convergent?,let be $f(x) = \sum_{n=1}^{\infty} \frac{\sin n x}{n^{2 / 3}}$ Find $\int_{0}^{\pi} f^{2}(x) d x$ I have understood that $\quad \sum_{n=1}^{\infty} \int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t=\int_{0}^{\pi} \sum_{n=1}^{\infty} \frac{\sin (n t)}{n^{2 / 3}} d t$ $$\int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t = \frac{1-\cos (\pi n)}{n^{5 / 3}} \Rightarrow \int_{0}^{\pi} f(x) d x = \sum_{n=1}^{\infty}\frac{1-\cos (\pi n)}{n^{5 / 3}}$$ But it's all that I can,"['integration', 'analysis', 'real-analysis']"
3665458,Solving this trigonometric equation,"I want to solve this equation $$
\arccos(x)+\arcsin(x^2-x+1)=\pi/2
$$ I write this: for all $x\in [-1,1]$ $\arcsin(x^2-x+1)=\pi/2-\arccos(x)$ then $x^2-x+1=\sin(\pi/2-\arccos(x))=\cos(\arccos(x))=x$ $x^2-x+1=x\Rightarrow x^2-2x+1=0\Rightarrow (x-1)^2=0\Rightarrow x=1 $ Is it true ?","['trigonometry', 'solution-verification']"
3665501,"Find best approximation of $\sin(\pi x)$ over $[0,1]$ with quadratic polynomial $a_0+a_1x+a_2x^2$","Use the theory of orthogonal functions to find best in the mean approximation of the function $\sin(œÄx)$ on the interval $[0,1]$ by a second-order polynomial That is, find such coefficients $a_0, a_1$ and $a_2$ that, $$\int^1_0 (\sin(\pi x)-a_0-a_1x-a_2x^2)^2 \, dx, $$ takes a minimal possible value. I feel as though this has something to do with Fourier series but I really cant be sure because I am not very familiar with this area. Also, I'm not sure what ""best in mean approximation"" means, so any help with that would be great.","['fourier-series', 'fourier-analysis', 'linear-algebra', 'ordinary-differential-equations']"
3665547,Proving that the derivative is unique in higher dimensions,"Can someone help me prove this please? I am thinking of using triangle inequality. However, I feel as if I would be doing to much and there is a better way to prove the following. $\def\h{{\mathbf h}}
\def\x{{\mathbf x}}
\def\f{{\mathbf f}}
\def\0{{\mathbf 0}}
\def\R{{\mathbb R}}  
\def\L{{\mathcal L}}$ Let $\f\colon D\to \R^m$ where $D\subseteq\R^n$ is open.  Let $\x_0\in D$ and suppose that $\f$ is differentiable at $\x_0$ .  Prove $T\in\L(\R^n,\R^m)$ satisfies the definition of derivative, such that $$\lim_{\h\to\0}\frac{\|\f(\x_0+\h)-\f(\x_0)-T(\h)\|}{\|\h\|} = 0$$ is unique. Essentially, I want to conclude $\|T-S\|<\epsilon$ . $\textit{Proof.}$ Suppose $T$ and $S$ are two linear transformations which satisfy our definition. By $\epsilon-\delta$ definition of limit, for any given $\epsilon >0$ , there exists $\delta >0$ such that $0< \|\h\| < \delta$ then $\displaystyle{\frac{\|\f(\x_0+\h)-\f(\x_0)-T(\h)\|}{\|\h\|}<\frac{\epsilon}{2}}.$ Now, $0<\|\h\|<\delta$ implies $\displaystyle{\|\f(\x_0+\h)-\f(\x_0)-T(\h)\| < \frac{\epsilon}{2}\|\h\|}$","['epsilon-delta', 'normed-spaces', 'real-analysis', 'multivariable-calculus', 'linear-algebra']"
3665571,"Why is this arbitrary-looking identity of arithmetic functions ""obvious""?","This question is about exercise 2.31 in Apostol's Introduction to Analytic Number Theory . The question asks us the following: if $f$ is a multiplicative arithmetic function, and $g$ is a completely multiplicative arithmetic function, and furthermore for all primes $p$ and $n \geq 1$ we have the relation $$
f(p^{n+1}) = f(p)f(p^n) - g(p)f(p^{n-1}),
$$ then for all $n, m$ $$
f(n)f(m) = \sum_{d \mid \gcd(n, m)} g(d) f\left(\frac{nm}{d^2}\right).
$$ More than any exercise so far in this book, this looks completely arbitrary to me. I have solved it: you can consider the question only for $n=p^a, m=p^b$ , and then it follows for arbitrary $n, m$ by multiplicativity of $f, g$ ; and we can prove it for $p^a \leq p^b$ by induction on $a$ . But that has really taught me nothing: I don't understand why it might make some sense that this is true. If $g(p) = 0$ for all primes $p$ , then the relation we start from becomes $f(p^n) = f(p)^n$ -- i.e., $f$ is completely multiplicative. Thus maybe we can see the $g(p)f(p^{n-1})$ as a sort of error term of the complete multiplicativity of $f$ . But this doesn't help me see why the result makes sense. Another approach I tried was noting that the relation allows us to write $f(p^k)$ as a polynomial in $f(p), g(p)$ , but I wrote out a few and I didn't see a pattern I understood. So my question is: where does this identity come from? How should I understand it, visualize it, ""get"" it? How would one come up with an exercise like this?","['analytic-number-theory', 'number-theory', 'alternative-proof', 'arithmetic-functions']"
3665586,Show $\sqrt[3]{5}$ is not contained in any cyclotomic extension of $\mathbb{Q}$.,"Find the Galois group of $x^3-5$ over $\mathbb{Q}$ , then show $\sqrt[3]{5}$ is not contained in any cyclotomic extension of $\mathbb{Q}$ . My attempt: The roots of $x^3-5$ are $\sqrt[3]{5},\zeta_3\sqrt[3]{5},\zeta_3^2\sqrt[3]{5}$ . So the splitting field for $x^3-5$ over $\mathbb{Q}$ is $\mathbb{Q}(\sqrt[3]{5},\zeta_3)$ , where $\zeta_3$ is a primitive $3^\text{rd}$ root of unity. By the Degree Formula for field extensions, we have $$
[\mathbb{Q}(\sqrt[3]{5},\zeta_3):\mathbb{Q}]=[\mathbb{Q}(\sqrt[3]{5},\zeta_3):\mathbb{Q}(\zeta_3)][\mathbb{Q}(\zeta_3):\mathbb{Q}]=3\varphi(3)=3\cdot2=6,
$$ where $\varphi$ is Euler's totient function.
Define the automorphisms $$
\sigma_{ij}:=\begin{cases}
\sqrt[3]{5}&\longmapsto\quad\zeta_3^i\sqrt[3]{5}\\
\zeta_3&\longmapsto\quad\zeta_3^j
\end{cases}
$$ where $0\leq i\leq 2$ and $1\leq j\leq 2$ . Counting the $\sigma_{ij}$ , we see we have found $6$ automorphisms, so we have found all elements of the Galois group. Since there is no element of order $6$ , we know the Galois group is $S_3$ . Finally, suppose $\sqrt[3]{5}$ is contained in a cyclotomic extension of $\mathbb{Q}$ , call it $\mathbb{Q}(\zeta_n)$ . By the Fundamental Theorem of Galois Theory, $S_3$ is a subgroup of $\text{Gal}(\mathbb{Q}(\zeta_n)/\mathbb{Q})$ . Since $\text{Gal}(\mathbb{Q}(\zeta_n)/\mathbb{Q})$ is abelian, this implies $S_3$ is abelian, a contradiction. Hence $\sqrt[3]{5}$ is not contained in any cyclotomic extension of $\mathbb{Q}$ . Is this correct?","['field-theory', 'galois-theory', 'abstract-algebra', 'solution-verification']"
3665617,"$L_p(X)$ separable if $(X,\mu)$ is separable measure space.","A measure space $(X,\mu)$ is separable if there is a countable family of measurable subsets $\{E_k \}_{k=1}^\infty $ so that if $E$ is any measurable set of finite measure , then $$\mu(E \triangle E_{n_k}) \to 0 \,\,\,\,\,\,\,as \,k\to0$$ for an appropriate subsequence $\{n_k \}$ which depends on $E$ . Prove that if the measure space $X$ is separable, then $L_{p}$ is separable when $1 ‚â§ p < ‚àû$ . I try to prove it like this: We have for every measurable set $E$ with finite measure associated measurable set $E_{nk}$ s.t. $\mu(E \triangle E_{n_k})<\epsilon$ . CLAIM: The collection $$ F:= \{\sum_{i=1}^Nr\chi_{E_{n_{i}}
}\}\,\,\,\,\,\,\, r\in Q  $$ is countable dense in $L^p$ . Since simple functions are dense in $L^p$ given $f \in L^p$ , Let $\epsilon >0$ and choose $\phi$ such that $\|\phi-f\|_{L^p} < \frac{\epsilon}{2}$ . Now, let $$\phi = \sum_{i=1}^{N} c_i \chi_{E_i}$$ with $E_i$ pairwise disjoint meaurable with finite measure. Let $\psi \in F$ with $$\psi = \sum_{i=1}^{N} r_i \chi_{E_{n_i}}$$ be such that $\mu(E_n \triangle E_{n_i})  < {\epsilon^p}$ with the $E_{n_i}$ pairwise disjoint. Then, \begin{eqnarray*}
\left( \int_\mathbb{X} |\phi-\psi|^p \, d\mu \right)^\frac{1}{p} &\leq& \left( \int_\mathbb{X} \left(\sum_{i=1}^{N}|c_i\chi_{E_i}-r_i\chi_{E_{n_i}}| \right)^p \, d\mu  \right)^\frac{1}{p} \\
& \stackrel{Minkowski}{\leq}& \sum_{i=1}^{N} \left( \int_\mathbb{X} |c_i\chi_{E_i}-r_i\chi_{E_{n_i}}|^p \, d\mu \right)^\frac{1}{p} \\
\end{eqnarray*} I got stuck..!! I try to connect the last above inequality with symmetric difference between $E_n$ and $E_{n_i}$ but I have difficulties in that because of existences of $r_i$ and $c_i$ . I need help to complete the proof. Thanks.","['measure-theory', 'lebesgue-measure']"
3665629,A question on the relation of two different forms of the Spectral Theorem for bounded operators,"I am going through some spectral theory, and I have found two results under this name. I state this results: (I)  Spectral Theorem I: Let $\mathcal{H}$ be a separable Hilbert space. If $A\in L(\mathcal{H})$ is self adjoint. Then there exists a unique projection valued measure $\mu^A$ on the Borel- $\sigma$ algebra of the spectrum $\sigma(A)$ such that $$\int_{\sigma(A)} \text{Id}_{\sigma(A)} \; d\mu^A =A. $$ (II)  Spectra Theorem II Let $\mathcal{H}$ be a separable Hilbert space. If $A\in L(\mathcal{H})$ is self adjoint. Then there exists a $\sigma-$ finite measure $\mu$ on the spectrum $\sigma(A)$ , a direct integral $$\Gamma(A)=\int_{\sigma(A)}^\oplus H_\lambda\; d\mu (\lambda)  $$ and a unitary map $U:\mathcal{H}\to \Gamma(A)$ such that $$[UAU^{-1}(s)](\lambda)=\lambda s(\lambda) $$ for all sections $s$ in $\Gamma(A)$ . So, maybe a bit of terminology is required. Given a $\sigma-$ finite measure space $(X,\Omega, \mu )$ and a indexed family $\{H_\lambda \}_{\lambda\in X}$ of Hilbert spaces, we can costruct the obvious vector bundle $$\pi: \xi=\bigsqcup_{\lambda\in X} H_\lambda \to X$$ $$\psi\mapsto \lambda \quad \text{if } \psi\in H_\lambda $$ A section $s$ of $\xi$ is defined as a map between $X$ and $\xi$ such that $\pi \circ s=\text{Id}_X$ as it usual, but we further impose a measurability condition. This can only make sense with a measure structure is $\xi$ . This measure structure is given by an indexed family of  sequences $\{ \{e_j^\lambda \}_{j=1}^\infty\}_{\lambda \in X}$ such that for any $\lambda \in X$ we have $\{e^\lambda_j \}_{j=1}^\infty \subseteq H_\lambda$ , $$\langle e_j^\lambda,e_k^\lambda \rangle=0 \text{ for } j\neq k$$ and the norm of every $e_j^\lambda $ is either $1$ or $0$ . We also ask the maps $$\lambda\mapsto \text{dim}(H_\lambda) \quad \text{and} \quad \lambda \mapsto \langle e^\lambda_j,e^\lambda_k \rangle \quad \forall j,k>0 $$ to be measurable. With this, we call a section $s$ measurable if $\lambda\mapsto \langle s(\lambda),e^\lambda_j\rangle $ is a measurable map. Now, the direct integral $$\int_{X}^\oplus H_\lambda\; d\mu (\lambda)   $$ Is the set $\Gamma(\xi)/ \sim $ where $\Gamma(\xi)$ is the set of measurable sections $s$ in $\xi$ for which $$\Vert s \Vert^2=\int_{X} \Vert s(\lambda) \Vert^2 \; d\mu(\lambda)<\infty  $$ and $s_1\sim s_2$ if they agree $\mu-$ almost every where. Now, it seems like we could recover the spectral theorem (I) from (II). Let's try,  suppose (II) and for each $E$ in the borel $\sigma-$ algebra of $\sigma (A)$ , define $V_E\subseteq \Gamma(A)$ as the set of all section $s$ such that $\text{support}(s)\subseteq E$ . Let $P_E $ be the orthogonal projection onto $V_E$ , now we define a projection valued measure $\mu^A$ on $\sigma(A)$ as $$\mu^A(E)=U^{-1}P_E U $$ where $U$ is as in (II). The question is how could I prove that $$\int_{\sigma(A)} \lambda \;d\mu^A(\lambda)=A. $$ Also, does (I) implies (II)? I think it does not, but cannot figure out where does the equivalence fail. Here's my attempt: So, I need to show that for any $\psi\in \mathcal{H}$ we have $$\Bigr\langle \left(\int_{\sigma(A)} \lambda \; d\mu^A (\lambda)\right) \psi, \psi \Bigr\rangle =\langle A\psi, \psi \rangle. $$ Let $\psi=U^{-1}s$ for some $s$ in the direct integral, then $$\langle A\psi,\psi \rangle=\langle AU^{-1}s , U^{-1}s  \rangle=\langle UAU^{-1}s , s \rangle =\int_{\sigma(A)} \langle UAU^{-1}s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)= \int_{\sigma(A)} \langle \lambda s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda) =   \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda). $$ Hence, it suffices to show that $$ \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)=\int_{\sigma(A)} \lambda \;d\mu^A_{\psi}(\lambda) $$ where $\mu^A_\psi$ is the real valued measure on $\sigma(A)$ defined by $$\mu^A_\psi(E)=\langle \mu^A(E)\psi , \psi \rangle=\langle U^{-1}P_EU \psi , \psi \rangle= \langle P_E s,s \rangle=\int_{\sigma (A)} \langle P_E s(\lambda),s(\lambda) \rangle \; d\mu(\lambda). $$ Here is where I am stuck. Other notes By support( $s)\subseteq E$ I mean that the $s(\lambda)=0$ for $\mu-$ almost every $\lambda\in E^c$ . Id $_X$ denotes the identity in $X$ and the inner product is assumed to be linear in the first entry. Also, all inner products are missing the label for in which it is defined, it is just to avoid writing the labels too much, figuring out what this label is should not be hard.","['integration', 'operator-theory', 'geometric-measure-theory', 'hilbert-spaces', 'functional-analysis']"
3665656,Prove that there is no probability measure on $\mathbb{N}$,"Prove that there is no probability measure on $\mathbb{N}$ such that for any $n\geq 1$ , the probability of the set of multiples of $n$ is $1/n$ . I'm trying to proof this by contradiction, but actually I have no clue so far. Much appreciated if someone can help.","['measure-theory', 'probability-theory']"
3665704,Why can't some functions be integrated?,"There are some functions (such as xtan(x)dx [without limits] ) which can't be integrated, why? How can one understand which function is integrable or not?","['integration', 'multivariable-calculus', 'calculus', 'functional-calculus']"
3665707,Measurement of the traffic generated by the packet source,"I'm working on resolving a statistical problem and I came across some difficulties. The content of the task: A measurement of the traffic generated by the packet source indicates that the average traffic is $\lambda$ [packets/s] and maximum traffic is $\sigma$ [packets/s]. The classic exponential distribution is not appropriate for modeling such a source of traffic, because the exponential distribution contains only one parameter (and two parameters were measured). To model such a source of motion, you can use the shifted exponential distribution which is described by two parameters ( $\gamma, \delta > 0$ ): $$f(\tau) = \left\{\begin{matrix}
0 & \tau<d \\ 
\gamma e^{-\gamma (\tau-d)} & \tau\geq d
\end{matrix}\right.$$ Random variable $\tau$ is the time interval between successive packets. Draw a distribution graph (1). What is the relationship between the maximum traffic  and $\delta$ , for the distribution (#)? Designate a mean value of the distribution (#). Based on measurements of traffic sources $(\lambda, \sigma)$ select firstly $\delta$ parameter for distribution (#), then $\gamma$ parameter for distribution (#). So far I've managed to solve the subsection 2. and this is what I've came up with: my solution to subsection 2.","['statistics', 'probability-distributions', 'exponential-distribution']"
3665806,Best self study books for Algebraic Number Theory?,I have experience in abstract algebra up to fields and field extensions using Artin's Algebra. I am wondering what book would be the most user friendly but also rigorous introduction to algebraic number theory.,"['algebraic-number-theory', 'self-learning', 'book-recommendation', 'reference-request', 'abstract-algebra']"
3665851,Formula for the $\mathbb{E}[X] = \sum_{n\geq1}P(X\geq n)$ with density function,"Let $X>0$ be non-negative random variable: Show that, if $X$ is an integer random variable, then $\mathbb{E}[X] = \sum_{n\geq1}P(X\geq n)$ Find and prove the corresponding formula for the case, when $X$ has a density function. For the first one, I have already found a solution: Find the Mean for Non-Negative Integer-Valued Random Variable However, for the second one, I have tried by myself but I am not sure, whether my answer is correct. My answer is the following: \begin{eqnarray*}
 \sum_{n=0}^{\infty}P(X>n)&\overset{\small P(X>n)=(1-P(X \leq n))}{=} \: &\sum_{n=0}^{\infty} (1-F_X(n))\\
 &=& \sum_{n=0}^{\infty} \left(1- \int_{-\infty}^{\infty}f(x)\ dx\right)\\
&= &\sum_{n=0}^{\infty} \left(\int_{-\infty}^{\infty}f(x)\ dx - \int_{-\infty}^{n}f(x)\ dx\right) \\
& =& \sum_{n=0}^{\infty} \left(\int_{-\infty}^{n}f(x)\ dx + \int_{n}^{\infty}f(x)\ dx - \int_{-\infty}^{n}f(x)\ dx\right) \\
& = &\sum_{n=0}^{\infty} \left(\int_{n}^{\infty}f(x)\ dx\right).
\end{eqnarray*} I am not sure if $$ \int_{-\infty}^{\infty} f(x)\ dx=1 $$ hold in this case? I would appreciate any kind of remarks or help in this case.","['random-variables', 'expected-value', 'probability-theory', 'probability', 'density-function']"
3665865,Why are the Eigenvalues of the shape operator the principle curvatures?,"For now I would be content with understanding why the eigenvalues of the shape operator of a surface are the principle curvatures, let's call them $k_1,k_2$ . Let $f: M \rightarrow S^2$ be the Gauss map of an oriented surface $M$ into the sphere. This map simply sends the unit normal vector at any point of our surface to it's point on the sphere, I like to think of this map sort of like a trippy compass. The differential of this map is called the Shape Operator . Given a point $x \in M$ , the tangent plane at $x$ is denoted $T_xM$ is an inner product space. The shape operator can be defined as a linear operator on $T_xM$ by the equation: $$ (S_x(v),w)=(df_x(v),w) \quad \text{for any $v,w \in T_x M.$} $$ Apparently, the equation is above is symmetric in $v$ and $w$ , and thus the shape operator is a self-adjoint operator. Hm... So it's symmetric in $v$ and $w$ , so $(df_x(v),w)=(df_x(w),v)$ ? Can somebody explain to me why that makes sense?? And then yeah, if somebody could help me understand why the eigen-values of this operator are the principle curvatures, i.e. the maximum and minimum values of possible curvatures as you depart from our given point, $x$ , I'd really appreciate it. Thanks!","['geometry', 'calculus', 'linear-algebra', 'soft-question', 'differential-geometry']"
3665879,Sum and difference formulas for $\csc$ and $\sec$,"We all are familiar with the sum and difference formulas for $\sin$ and $\cos$ , but is there an analogue for the sum and difference formulas for secant and cosecant?  That is, $$\csc (A\pm B) = ?$$ and $$\sec (A \pm B) = ?$$ I tried a variation of the sum and difference formulas, but they were incorrect.  Can it be derived geometrically?",['trigonometry']
3665882,Number of surjections from A to B if |B|=|A|-1,"In trying to figure out the above problem I looked at Number of surjections from $\{1,...,m\}$ to $\{1,...,n\}$ and i'm fairly confused on a few things. Following op's argument, if we look at {1...m} to {1...n} then there are $n^m$ total functions. This makes sense to me. But these include non subjective functions where 1,2,3... elements in the co-domain have no mapping. So we subtract non subjective function: $n \choose 1$$(n-1)^m$ -> set $S_1$ of functions missing 1 element $n \choose 2$$(n-2)^m$ -> set $S_2$ of functions missing 2 elements. But then op makes the comment"" but how many times did we count this in the previous count?"" This I don't get. These functions are ones where 2 elements in the co-domain have no input that maps to them. The previous ones consisted of functions where only 1 element in the co-domain had no input that mapped to them. So how could there be duplicates? Any function you choose from $S_1$ will differ from another in $S_2$ as functions in $S_2$ will have an additional element in co-domain with no mapping. Also is there a way to do the given problem Find the number of surjections from A to B if $|B|=|A|-1$ without the inclusion-exclusion thing or if not could someone explain it.","['cardinals', 'functions', 'combinatorics']"
3665894,Growth of a function with every derivative everywhere increasing,"If a function $f: \mathbb{R} \to \mathbb{R}^{+}$ , is infinitely differentiable everywhere, and is such that every derivative is monotonically strictly increasing everywhere, then what is the slowest-growing function that $f$ could be? What if the derivatives are just monotonically nondecreasing everywhere? Feel free to add in additional properties (which you would specify) if this question is not well-formulated enough. This question just popped into my head. I have suspicions and will work on it too.","['calculus', 'real-analysis']"
3665926,$X^TX$ not full rank when $X$ is full rank?,"$X$ is an $n \times m$ matrix, where $n \geq m$ and $\mbox{rank}(X) = m$ . Is it possible for $X^TX$ to not be full rank? If $X$ can only be square I could easily prove this with $$
\det(X^TX) = \det(X^T)\det(X) = \det(X)^2 > 0
$$","['matrices', 'matrix-rank', 'linear-algebra']"
3665946,Existence and uniqueness proof check/critique,"Problem statement, as written: Let $f\colon A \rightarrow C$ and $g\colon A \rightarrow B$ be functions. Prove that there exists a function $h\colon B \rightarrow C$ such that $f = h \circ g$ if and only if $\forall x,y \in A$ , $g(x) = g(y) \rightarrow f(x) = f(y)$ . Prove that $h$ is unique. The theorem is vacuously true if any of $A,B,C$ are empty. Thus, $A,B,C \ne \emptyset$ . As such, let $c_0 \in C$ . Define $h\colon B \rightarrow C$ by $h = \{(b,c)|\exists x \in A$ such that $b = g(x)$ and $c = f(x)\}$ $\cup$ $\{(b,c_0) | b \in \{B -\{g(a) | a \in A\}\}\}$ . To see that $h$ satisfies the definition of function, we show that 1) $dom(h) = B$ , 2) $ran(h) \subseteq C$ , and 3) $(x,y_1),(x,y_2) \in h \rightarrow y_1 = y_2$ . To prove 1), first, let $b \in dom(h)$ . Then by the definition of $h$ , $\exists a \in A$ such that $b=g(a)$ . But $g\colon A \rightarrow B$ ,so $g(a) = b \in B$ . So $dom(h) \subseteq B$ . To prove the converse, let $b\in B$ . Note since $g\colon A \rightarrow B$ , either $\exists a \in A$ such that $b = g(a)$ , or $\forall a\in A, b \ne g(a)$ . Thus, we break the proof into two exhaustive cases. Case 1) $ \exists a\in A$ such that $ b = g(a)$ . Then by the definition of $h$ , $b \in dom(h)$ . So this case results in $B \subseteq dom(h)$ . Case 2) $ \forall a \in A, b \ne g(a)$ . This time, by the definition of $h$ , $(b,c_0) \in h$ , so again, we have that $b\in dim(h)$ . This case also results in $B \subseteq dom(h)$ . Thus, $B = dom(h)$ .
To prove 2), let $c \in ran(h)$ . Then by the definition of $h$ , $\exists a \in A$ such that $c = f(a)$ . Since $f\colon A \rightarrow C$ , $f(a) = c \in C$ . Thus, $ran(h) \subseteq C$ .
Lastly, to show 3), assume $(x,y_1),(x,y_2) \in h$ . Then by the definition of $h$ , $\exists a\in A$ such that $x = g(a)$ . Furthermore, $y_1 = f(a) = y_2$ . Thus, in particular, $y_1 = y_2$ . In other words, every domain element is mapped to a (unique) range element. Now we prove the biconditional statement form of the theorem. $(\rightarrow)$ Suppose $f=h\circ g$ . Let $x,y \in A$ and assume $g(x) = g(y)$ . Then $(h \circ g)(x) = h(g(x)) = f(x)$ . Since $g(x) = g(y), h(g(x)) = h(g(y)) = f(y)$ (The rightmost equalities in each of the preceding two strings of equalities are a result of applying the definition of $h$ ). Thus, in particular, $f(x) = f(y)$ , as desired. $(\leftarrow)$ Now suppose $\forall x,y \in A, g(x) = g(y) \rightarrow f(x) = f(y)$ . To see that $f = h\circ g$ , take $a \in A$ . $(h \circ g)(a) = h(g(a)) = f(a)$ , where the last equality, again, follows from the definition of $h$ . To see that $h$ is unique, suppose $l$ is any other function such that $f = l \circ g$ if and only if $\forall x,y \in A$ , $g(x) = g(y) \rightarrow f(x) = f(y)$ . To see that $h = l$ , we proceed by contradiction. Thus, suppose (to the contrary) $l \ne h$ . Then $\exists \beta \in B$ such that $h(\beta) \ne l(\beta)$ . Since $g$ is surjective, by hypothesis, $\exists a_1 \in A$ such that $\beta = g(a_1)$ ; also, $h(\beta) = f(a_1) = c_1$ . Suppose $x,y \in A$ and $g(x) = g(y)$ . Then by the definition of $h$ applied to $g(x)$ , we find that $f(x) = f(y)$ . Thus we may conclude that $f = h \circ g$ and $f = l \circ g$ , so $h\circ g = l\circ g$ . Observe that $(a_1,c_1)\in f = h\circ g$ , so $(a_1,c_1)\in h\circ g$ . This means $\exists b_1 \in B$ such that $(a_1,b_1)\in g$ and $(b_1,c_1) \in h$ . Recall, however, that $h\circ g = l\circ g$ also. Hence, $(a_1,c_1) \in l \circ g$ . So $\exists b_* \in B$ such that $(a_1,b_*) \in g$ and $(b_*,c_1) \in l$ . But since $g\colon A\rightarrow B, b_* = b_1$ . Thus, as $\beta = g(a_1) = b_* = b_1$ , $l(\beta) = c_1 = h(\beta)$ , a contradiction. Therefore, it must be that $l = h$ .",['functions']
3665961,Solving an ODE with singular point: is this correct?,"This is from a text book by Tsai Tai-Peng ""Lectures on Navier-Stokes Equations"", page 148 if anyone wants to read. But I am only asking about how to solve this ODE, $$(1-t^2) L'' +2L+LL' = 0, \quad t\in(-1,1)\\L(-1)=L(1)=0.$$ The author begins by noticing that $(1-t^2)$ is a solution to the linear problem (just deleting the $LL'$ term) $$ (1-t^2) L'' +2L = 0.$$ ""Therefore"", as a kind of variation of parameters method, he decides to set $$ L(t) \overset{\Delta}=u(t)(1-t^2).$$ Apparently, it follows that $u$ solves $$ u' + \frac{u^2}2 = 0?$$ I really can't prove this, and must be going crazy. If you want some scratch work to see: \begin{align} L &= (1-t^2)u\\ L‚Äô &= (1-t^2)u‚Äô -2tu\\
L‚Äô‚Äô &= (1-t^2)u‚Äô‚Äô - 2tu‚Äô - 2tu‚Äô - 2u\\
&= (1-t^2)u‚Äô‚Äô - 4tu‚Äô - 2u 
\end{align} divide L equation by $1-t^2$ , \begin{align}
(1-t^2)u‚Äô‚Äô - 4tu‚Äô - 2u + 2u + u L‚Äô &= 0\\
(1-t^2)u‚Äô‚Äô - 4tu‚Äô 
            + u[ (1-t^2)u‚Äô -2tu ]&=0
\end{align} Any pointers? This is apparently from the thesis of the author Tsai Tai-Peng but I don't have access to it at the moment.","['singular-solution', 'ordinary-differential-equations']"
3665993,Why does Hanson-Wright inequality give a poor bound in this example?,"The following is from High-Dimensional Probability by Roman Vershyni (Hanson-Wright inequality) Let $X = (X_1, \dots, X_n) \in \mathbb{R}^n$ be a random vector with independent, zero-mean, and sub-Gaussian coordinates. Let $A$ be an $n \times n$ matrix. Then, for every $t\geq 0$ , we have $$P(|X^\intercal A X - E[X^\intercal A X ]| \geq t) \leq 2 \exp \Big[ -c \min (\frac{t^2}{K^4 \|A\|_F^2}, \frac{t}{K^2 \|A\|_2})\Big],$$ where $K = \max_i \|X_i\|_{\psi_2}$ . I give an example where this bound is quite poor. Suppose that $A$ is a positive definite matrix and $X_i$ are i.i.d. standard Gaussian. For any vector $X$ it is trivial that $P(X^\intercal A X \leq 0) = 0$ . I apply Hanson-Wright to this probability: \begin{align}
P(X^\intercal A X \leq 0) = P(- X^\intercal A X + E[X^\intercal A X] \geq  E[X^\intercal A X]) = P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)])
\end{align} Hanson-Wright gives the following bound \begin{align}
P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)]) \leq \Big[ -c \min (\frac{\text{tr}(A)^2}{K^4 \|A\|_F^2}, \frac{\text{tr}(A)}{K^2 \|A\|_2})\Big]
\end{align} Now, this bound is poor when $A$ is not well-conditioned, even though the correct probability is zero. For example, if eigenvalues of $A$ are $(1, \epsilon/(n-1), \dots, \epsilon/(n-1))$ , then $$\frac{\text{tr}(A)}{\|A\|_2} = 1+\epsilon.$$ Why does this bound poor in this example? Simulations show that this is also true when $A$ is nearly positive definite (e.g. $A = B^\intercal B - \epsilon x x^\intercal$ ).","['statistics', 'normal-distribution', 'linear-algebra', 'probability-theory', 'probability']"
3666042,$T$ is compact operator Hilbert space,"I'm getting troubles to show the following Let $X$ be an infinite-dimensional separable Hilbert space and $T$ a self-adjoint operator. Assume $T^n$ is compact for some $n \in \mathbb{N}$ . Prove that $T$ is compact. I was thinking about using the spectral theorem. However, I don't see this clearly. Any hint would be amazing. Thank you.","['compact-operators', 'functional-analysis']"
3666055,Prove $\frac1{\cos6¬∞}+ \frac1{\sin24¬∞} + \frac1{\sin48¬∞ }- \frac1{\sin12¬∞ }= 0$,"Prove that $$\frac1{\cos6¬∞}+ \frac1{\sin24¬∞} + \frac1{\sin48¬∞ }- \frac1{\sin12¬∞ }= 0$$ I tried to solve this question by grouping together the first and last term, and applying the sum and product rule, 
 (same for the middle two terms). But I wasn't able to do it that way. Any help? PS:  I am just a 15 year old,  so please be patient and explain line by line (preferably with only trig identities).
Thanks.","['trigonometric-series', 'trigonometry']"
3666098,Why matrices commuting with $\small\begin{bmatrix} 0&1\\-1&0\end{bmatrix}$ represent complex numbers?,"I am trying to understand which $2$ by $2$ real matrices represent complex numbers in following way. Let $J=\begin{bmatrix} 0&1\\-1&0\end{bmatrix}$ and $A=\begin{bmatrix} a&b\\c&d\end{bmatrix}$ be any real matrix. If $A$ represents a complex matrix (by standard embedding of complex field into matrix ring) then $A$ should commute with the matrix $J$ , which image of complex number $i$ . Q. I want to understand why the matrices commuting with $J$ are precisely the matrices representing complex numbers?","['matrices', 'ring-theory', 'abstract-algebra', 'linear-algebra', 'complex-numbers']"
3666222,Expectation over an expected value in ergodic process,"From ergodic theorem we can see that: $\frac{1}{N} \sum_{i}f(x_{i}) \to {E}[f(x)]$ as $n \to \infty$ Does this imply that in ergodic process we can similarly write: $\frac{1}{N} \sum_{i}E[f(x_{i})] \to \lim_{n \to \infty}{E}[f(x_{n})]$ If this statement is right, then I am a little bit confused about how can we write this?","['statistical-inference', 'statistics', 'probability']"
3666255,If $AB=BA$ and $AB$ is diagonal are $A$ and $B$ both diagonal?,So I'm stuck with this problem. If $AB=BA$ and $AB$ is diagonal are $A$ and $B$ both diagonal?,"['matrices', 'linear-algebra']"
3666270,Variance of max of $m$ i.i.d. random variables,"I'm trying to verify if my analysis is correct or not. Suppose we have $m$ random variables $x_i$ , $i \in m$ . Each $x_i \sim \mathcal{N}(0,\sigma^2)$ . From extreme value theorem one can state $Y= \max\limits_{i \in m} [\mathcal{P}(x_i \leq \epsilon)] =  [G(\epsilon)]$ as $m\to\infty$ , if $x_i$ are i.i.d and $G(\epsilon)$ is a standard Gumbel distribution. My first question is can we state that: $$\text{Var}[Y]= \text{Var}\left[\max_{i \in m} [\mathcal{P}(x_i \leq \epsilon)] \right]= \text{Var}[ [G(\epsilon)]] = \frac{\pi^2}{6}$$ My second question is, if we have $n$ of such $Y$ but all of them are independent with zero mean, can we state: $$\text{Var}\left[\prod_{i}^n Y_i\right] = \left(\frac{\pi^2}{6}\right)^n$$ Thanks. Update: There's final result for the second point at Distribution of the maximum of a large number of normally distributed random variables but no complete step by step derivation.","['extreme-value-theorem', 'variance', 'probability-theory', 'extreme-value-analysis']"
3666290,Number of elements of permutation group,"Let $G$ be a permutation group of a set $X\neq \emptyset$ and let $x,y\in X$ . We define: \begin{align*}&G_x:=\{g\in G\mid g(x)=x\} \\ &G_{x\rightarrow y}:=\{g\in G\mid g(x)=y\} \\ &B:=\{y\in X\mid \exists g\in G: g(x)=y\}\end{align*} I have shown that $G_x$ is a subgroup of $G$ als that the set $\{G_{x\rightarrow y}\mid y\in B\}\subseteq 2^G$ is a partition of $G$ . Let $g\in G_{x\rightarrow y}$ and let $u\in G_x$ and $v\in G_{x\rightarrow y}$ and so it holds that $g\circ u\in G_{x\rightarrow y}$ and $g^{-1}\circ v\in G_x$ .
The maps \begin{align*}\alpha:G_x\rightarrow G_{x\rightarrow y}, \ u\mapsto g\circ u \\ \beta: G_{x\rightarrow y}\rightarrow G_x, \ v\mapsto g^{-1}\circ v\end{align*} are to each other inverse bijections. Let $G$ be finite. I want to show that that $|G|=|B|\cdot |G_x|$ . Could you give a hint? We have that $\{G_{x\rightarrow y}\mid y\in B\}\subseteq 2^G$ is a partition of $G$ . Does this mean that $|G|=|\{G_{x\rightarrow y}\mid y\in B\}|$ ? If it is like that, then we have to show that $|\{G_{x\rightarrow y}\mid y\in B\}|=|B|\cdot |G_x|$ , right? It is also given a hint that we can use the idea that we use when we show that there are $48$ symmetries of a cube.","['permutations', 'group-theory', 'linear-algebra', 'set-partition']"
3666294,The sign of the second order derivative sign,"Suppose that we know the sign of $\frac{\partial f(x,y)}{\partial x}$ and $ \frac{\partial f(x,y)}{\partial y}$ on a specific domain. Can we say that the sign of $ \frac{\partial^2 f(x,y)}{\partial x \partial y}$ is basically the product of the signs of the first order derivatives? Example: $f(x,y)=\frac{1}{x y}$ : $\frac{\partial f(x,y)}{\partial x}\leq 0$ and $ \frac{\partial f(x,y)}{\partial y}\leq 0$ and $ \frac{\partial^2 f(x,y)}{\partial x \partial y}\geq 0$ for all $x\geq 0$ and $y\geq 0$ . If this is correct, do you have a source? My search engine attempts didn't give me something :-( Thanks a lot","['derivatives', 'analysis']"
