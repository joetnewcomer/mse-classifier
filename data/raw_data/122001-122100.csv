question_id,title,body,tags
1834087,What is level of significance?,"I am always confused with meaning of level of significance especially when my null hypothesis got accepted at 5% level and rejected at 1% level, how it could be possible that investigators would have two different decisions by merely changing levels of significance ?
Can anybody please explain procedures for selecting correct level of significance?",['statistics']
1834119,wrongly asked question about precalculus?,"Im seeing the following question in a precalc textbook: Suppose $f$ is a function whose domain is $[-5,5]$ and $f(x) = \frac{x}{x+3}$ for every $x$ in $[0,5]$. Suppose $f$ is an odd function. Evaluate $f(-3)$. Isnt this a bad formulated problem?? I mean, $f(-3)$ is not even defined, but since $f$ is odd, then $f(-3) = - f(3) = - \frac{1}{2}$. Or, am I just misinterpreting the question?",['algebra-precalculus']
1834135,Intermediate Value Like Property for Lebesgue Measure,"Below is a question from N.L. Carother's book Real Analysis .  I've provided my attempt at a solutions, however, any feed back would be very appreciated. Suppose $E$ is a measurable subset of $\mathbb{R}$ such that $m(E) = 1$ .  Show that: (a) There is a measurable set $F$ with $F \subset E$ such that $m(F) = 1/2$ . (b) There is a closed set $F$ , consisting entirely of irrationals, such that $F \subset E$ and $m(F) = 1/2$ . (c) There is a compact set $F$ with empty interior such that $F \subset E$ and $m(F) = 1/2$ . My Attempt: (a) Define $f: \mathbb{R} \to \mathbb{R}$ be defined by $f(x) = m(V_x)$ , where $V_x = E \cap (-\infty, x]$ for each $x $ . It suffices to show that $f$ is an increasing continuous function and apply the Intermediate Value Theorem. To show that $f$ is increasing, suppose that $x<y$ and note that $V_x \subset V_y$ so that, by the monotonicity of the Lebesgue measure, $f(x) = m(V_x) \leq m(V_y) = f(y)$ . Fix any $x \in \mathbb{R}$ and $\epsilon > 0$ ; choose $\delta = \epsilon$ . Then, whenever $|x-y| < \delta$ with $x < y$ , we have that \begin{align}
|f(x) - f(y)| \leq m(V_y \setminus V_x) \leq |x-y| < \delta = \epsilon,
\end{align} which shows that $f$ is continuous. Now, as $x$ increases, the sets $V_x$ increase to $E$ . Hence $0 \leq f(x) \leq m(E) = 1$ for all $x$ . Thus, by the Intermediate value theorem, there exists some $u \in \mathbb{R}$ for which $f(u) = 1/2$ ; that is, $m(V_u) = 1/2.$ Setting $F = V_u = E \cap (-\infty, u]\subset E$ is our desired measurable set. (b) Let $(r_n)$ be an enumeration of the rationals. Define the set $R$ to be the union $$
R = \bigcup_{n=1}^{\infty} \left( r_n - \frac{1}{2^n}, r_n + \frac{1}{2^n} \right).
$$ Once can see, without too much effort, that $m(R) = 2$ ; hence its complete, a closed set of infinite measure, $R^c$ as constructed consists of only irrationals. *From here I've been pretty stuck; I'm still sitting on the ideas, however, I'm not sure where to go.  Any HINTS would be of great asset.  : )","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
1834166,Why doesn't derivative difference quotient violate the epsilon-delta definition of a limit?,"So the difference quotient is defined as: $$\lim \limits_{h \to 0} \frac{f(x+h)-f(x)}{h}$$ So if we take a function such as $f(x)=x^2$ and go through the simplification, we get $$\lim \limits_{h \to 0} 2x+h $$ We say $h$ is zero, and that makes sense because it becomes negligible. But here's what I don't understand: $\delta$-$\epsilon$ says (in casual terms) we can make $h$ as close as we want to zero and $2x+h$ will be sufficiently close to $2x$. But isn't one of the constraints of delta epsilon that $|\delta - c| > 0$? So how can we say $h$ is exactly zero if this constraint must be met? In other words, we always say the value of the limit at the point of interest does not necessarily equal the value of the function - but here it seems like we're saying that they are by making $h$ exactly zero, not just sufficiently close. Why can we do this?","['derivatives', 'real-analysis', 'limits', 'calculus', 'epsilon-delta']"
1834174,"Real Analysis, Folland Proposition 2.11/Exercise 10 Measurable Functions","Question Proposition 2.11 (Exercise 10) - The following implications are valid if and only if the measure is complete: a.) If $f$ is measurable and $f = g$ $\mu$-a.e., then $g$ is measurable. b.) If $f_n$ is measurable for $n\in \mathbb{N}$ and $f_n\rightarrow f$ $\mu$-a.e., then $f$ is measurable. Attempted Proof a.) We want to show that for every Borel set $B\subset \mathbb{R}$, $g^{-1}(B)$ is measurable. Suppose $\mu$ is complete, since $f = g$ $\mu$-a.e., there exists a measurable set $E$ such that $\mu(E) = 0$, in fact, for all $x\notin E$ $f(x) = g(x)$. Then $$g^{-1}(B) = (g^{-1}(B)\cap E)\cup(f^{-1}(B)\setminus E)$$
since $f$ is measurable we have that $f^{-1}(B)$ is measurable, and since $\mu$ is complete, we have $g^{-1}(B)\cap E$ is measurable. Thus $g^{-1}(B)$ is measurable. Now suppose part a.) holds. Let $N\subset E$, where $E$ has measure zero. Let $f = 1_{E}$ and $g = 1_{N}$ then $f = g$ a.e., so $g$ is measurable. Thus, $g^{-1}(\{1\}) = N$ is measurable. Therefore $\mu$ is complete. Attempted proof b.) We are given $f_n$ to be measurable for $n\in\mathbb{N}$, and $f_n\rightarrow f$ a.e., from proposition 2.7 we can let $$\hat{f} = \lim_{n\rightarrow \infty}\sup f_n$$ Since $f_n$ is measurable then so is $\hat{f}$. Thus given the fact that $f_n\rightarrow f$ e.e. then we have $\hat{f} = f$ a.e., so by part a.) $f$ is measurable. I am not sure how to proceed with the converse of part b.). Any suggestions is greatly appreciated. Background Information Proposition 2.7 - If $\{f_j\}$ is a sequence of $\overline{\mathbb{R}}$-valued measurable functions on $(X,M)$, then the functions \begin{align*}
g_1(x) &= \sup_{j}f_j(x) \ \ \ \ \ &g_3(x) = \lim_{j\rightarrow \infty}\sup f_j(x)\\
g_2(x) &= \inf_{j}f_j(x) \ \ \ \ \ &g_4(x) = \lim_{j\rightarrow \infty}\inf f_j(x)
\end{align*}
  are all measurable. If $f(x) = \lim_{j\rightarrow \infty}f_j(x)$ exists for every $x\in X$, then $f$ is measurable.","['real-analysis', 'measure-theory']"
1834215,A puzzle about integrability,"I know there is a Proposition: for $f(x)$ is bounded on $[a,b]$,then $f(x)$ is integrable if and only if given $\epsilon>0$, there exists a partition such that $U(f,P)-L(f,P)<\epsilon$ But my question is that: Assume $f(x)$ is bounded and integrable on $[a,b]$, then given  $\epsilon>0$   does it must exist a $\delta>0$ for any partition $|P|<\delta$,$U(f,P)-L(f,P)<\epsilon$. If it is true, how to prove it? Thanks in advance.","['real-analysis', 'integration']"
1834227,Find a matrix with determinant equals to $\det{(A)}\det{(D)}-\det{(B)}\det{(C)}$,"Assume I have 4 matrices $A,B,C,D\in\Bbb{R}^{n\times n}$. I want to build a matrix $E\in\Bbb{R}^{m\times m}$ such that: $$\det{(E)}=\det{(A)}\det{(D)}-\det{(B)}\det{(C)}$$ under the following assumptions: $m$ can be any number we want, but I prefer $2n$. $E$ should not contain the terms $\det{(A)},\det{(B)},\det{(C)},\det{(D)}$. that means that the matrix 
$\begin{pmatrix}
\det{(A)} & \det{(B)} \\
\det{(C)} & \det{(D)}
\end{pmatrix}
$ is not the case... There can't be any further assumptions on $A,B,C,D$ I've already checked the matrix 
$\begin{pmatrix}
A & B \\
C & D
\end{pmatrix}
$
but it's not that... Does anyone have an idea what $E$ can be?","['matrices', 'linear-algebra', 'determinant']"
1834240,If $f(x) = \frac{\cos x + 5\cos 3x + \cos 5x}{\cos 6x + 6\cos4x + 15\cos2x + 10}$then..,If $f(x) = \frac{\cos x + 5\cos 3x + \cos 5x}{\cos 6x + 6\cos4x + 15\cos2x + 10}$ then find the value of $f(0) + f'(0) + f''(0)$. I tried differentiating the given. But it is getting too long and complicated. So there must be a way to simplify $f(x)$. What is it?,"['algebra-precalculus', 'trigonometry', 'calculus']"
1834257,Number of subgroups equal to order of group,"Here is a fun question. Consider the dihedral group $\mathcal{D}_4=\left\langle a,b\mid a^4=b^2=1, bab=a^{-1}\right\rangle$ of order $8$. This group has exactly $8$ genuine subgroups (but not all different up to isomorphism). Are there other finite groups that have as many genuine subgroups as their order? Can there be infinitely many such groups? What would be a reasonable way to tackle this question? Edit: By genuine subgroup I mean proper subgroup, forgot the terminology there.","['finite-groups', 'abstract-algebra', 'group-theory']"
1834261,Asymptotic behaviour of sum over the inverse japanese symbol,"I am interested in the asymptotic behavior of the sum
$$\sum_{m=1}^M\frac{1}{\sqrt{m^2+\omega}}$$
for $1>\omega>0$ in the Limit $M\to\infty$ up to order $\mathcal{O}(M^{-1})$. The first thing I did was splitting the sum as follows: $$\sum_{m=1}^M\frac{1}{\sqrt{m^2+\omega}}=\sum_{m=1}^M\frac{1}{m}+\sum_{m=1}^M\left(\frac{1}{\sqrt{m^2+\omega}}-\frac{1}{m}\right)$$ For the first sum I use the Euler approximation to get
$$\sum_{m=1}^M\frac{1}{m}=\log(M)+\gamma_E+\mathcal{O}(M^{-1}).$$ Now I suspect that the remainder goes like
$$\sum_{m=1}^M\left(\frac{1}{\sqrt{m^2+\omega}}-\frac{1}{m}\right)=c(\omega)+\mathcal{O}(M^{-1}).$$ The question is, how can I explicitly compute $c(\omega)$?","['real-analysis', 'summation', 'asymptotics']"
1834262,Is the Fermat primality test secure enough for very big numbers?,"The random variable $X_m$ is the number of trials before $n\notin\mathbb P\wedge n\mid 2^{n-1}-1$ where $n$ is an odd random integer 
$2^{m-1} < n < 2^m$. Computer simulations makes me believe that $\text E[\log X_m]=\frac{m}{6}$ and that $\operatorname{Var}[\log X_m]<1$. I'm looking for some kind of proof of this conjecture and would like to know how to compute or estimate $P(X_{1000}=1)$, given that the conjecture is true. The context is: how secure is the Fermat primality test with base $2$ on numbers with $1000$ binary bits? Compared with the probability of hardware errors? Well, perhaps the 10 in the logarithm doesn't flag for an exact $\frac{m}{6}$. The regression line is $\log N= 0.1666\cdot m+0.006$ which is interpreted as $N=10^{\frac{m}{6}}$ but might also be interpreted as $N=\pi^{\frac{m}{3}}$ within the marginals. $\overset{..}{\smile}$ $3251$ simulations total so far. Some lower experiments $(m=10)$ has been removed, since lower intervalls gives more irregular results. In some intervalls there are no discrepancies. Also long time running results from $m=40$ is included, so the equation of the line of regression has changed a little. Diagram of the mean values of each m","['conjectures', 'algorithms', 'probability', 'prime-numbers', 'primality-test']"
1834269,Conditional expected value of mutlitple draws from uniform distribution,"There are $m$ i.i.d. draws of $x$ made from a uniform distribution on $[0,1]$. The $n$ ($n\leq m$) lowest draws are ""winners"", i.e. if we write $x_1\leq\ldots\leq x_n\ldots\leq x_m$, the draws $x_1$ to $x_n$ are ""winning draws"". Now player/draw $i$ learns his $x_i$ and the fact that he is a winner, i.e. $i\in[1,n]$. What is the expected value of the remaining $(n-1)$ winning draws, given $i$'s knowledge of his own draw and the fact that he is a winner (but not knowing his ""rank""/position among the winners). EDIT: With the help of the comments below, this is what I have managed to do (credits to the commentators!): The unconditional expected value of the winning draws is $\frac{1}{n}\sum_{i=1}^n \frac{i}{1+m}=\frac{n+1}{2(m+1)}$. Obviously, the unconditional cdf is given by $F(x)=x$ for $x\in[0,1]$. $i$ can be the 1st, 2nd, ... nth of the winners. For each rank, compute the expected value of the remaining $n-1$ winners (distributed below/above him, depending on $i$'s rank) and weight it by the probability of this rank. The expected value of the remaining winners, conditional on $x_i$ and the knowledge that $i$ is a ""winner"", can hence be computed by (incomplete and possibly wrong!): \begin{alignat*}{3}
\frac{1}{n-1}\bigg(%
	&(1-x_i)^{m-1}			&\cdot\binom{m-1}{0}	&[(1-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-1}(x_i+(1-x_i)E[x_{(k)}^{m-1}])]\\
+	&(1-x_i)^{m-2}x_i^1		&\cdot\binom{m-1}{1}	&[(2-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-2}(x_i+(1-x_i)E[x_{(k)}^{m-2}])]\\
+	&\ldots\\
+	&(1-x_i)^{m-j-2}x_i^{j-1}	&\cdot\binom{m-1}{j-1}	&[(j-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-j}(x_i+(1-x_i)E[x_{(k)}^{m-j}])]\\
+	&\ldots\\
+	&(1-x_i)^{m-n-1}x_i^{n-1}	&\cdot\binom{m-1}{n-1}	&[(n-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-n}(x_i+(1-x_i)E[x_{(k)}^{m-n}])]%
\bigg)
\end{alignat*} QUESTIONS: Is the above correct? For example, am I missing a normalisation? Is it correct that if in addition $i$ also knew his ""rank"", rather than using the summation above, he would only consider the respective summand indicating the correct position. (From the comments, this seems to be correct.) How does this change a potential normalisation? Is it correct that
$$ E[x_{(k)}^{m-j}]=\frac{k}{m+1-j} $$
in the equation above, with $x_{(k)}^{m-j}$ being (if I understand it correctly) the k-th lowest out of $m-j$ iid draws? If I was also interested in the expected square of the other ""winners"" (not the square of the expected other winners), I would need to modify the formula above such that: replace $(j-1)\frac{x_i}{2}$ by
$$E[\sum_{k=1}^{j-1}x_k^2|x_k\sim U(0,x_i), \text{ iid}]=\frac{x_i^2 (2j-1)}{6j}$$ and $E[x_{(k)}^{m-j}]$ by
$$E[(x_{(k)}^{m-j})^2]=(\frac{k}{m+1-j})^2$$ Also, should I delete my lengthy (and wrong) comments below? Should I make this question more ""canonical"" (and if so, how)?","['statistics', 'probability', 'order-statistics']"
1834273,$\int_0^4\frac{\log x}{\sqrt{4x-x^2}} dx=0$ [duplicate],This question already has answers here : Prove that $\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}}~dx=0$ (without trigonometric substitution) (5 answers) Closed 8 years ago . I am having trouble proving that it is equal to zero analytically. I have tried plotting and know that for $0<x<1$ the integrand is negative and positive otherwise. I have tried substitution $u\to \sqrt{x}$ but I cannot proceed further.,['calculus']
1834304,Estimate the value of f at a given point,"Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ be a differentiable everywhere. Assume $f(-\sqrt2,-\sqrt2)=0$, and also that 
$|\dfrac{\partial f}{\partial x}(x,y)|\le |\sin(x^2+y^2)|$ and $|\dfrac{\partial f}{\partial y}(x,y)|\le |\cos(x^2+y^2)|$ for each $(x,y) \in \mathbb{R}^2\setminus \{(0,0)\} $. Prove that $|f(\sqrt2,\sqrt2)|\le 4$. I tried to use the Taylor expansion at the point $(-\sqrt2,-\sqrt2)$ as follows, $f(x,y)=f(-\sqrt2,-\sqrt2)+ \dfrac{\partial f}{\partial x}(-\sqrt2,-\sqrt2)(x+\sqrt2)+\dfrac{\partial f}{\partial y}(x,y)(y+\sqrt2)+ \epsilon(||(x+\sqrt2,y+\sqrt2)||) $ $=\dfrac{\partial f}{\partial x}(-\sqrt2,-\sqrt2)(x+\sqrt2)+\dfrac{\partial f}{\partial y}(x,y)(y+\sqrt2)+ \epsilon(||(x+\sqrt2,y+\sqrt2)||).$ Using Cauchy-Schwartz inequality, we obtain the upper bound of $ \dfrac{\partial f}{\partial x}(-\sqrt2,-\sqrt2)(x+\sqrt2)+\dfrac{\partial f}{\partial y}(x,y)(y+\sqrt2)$ at the point $(\sqrt 2, \sqrt2)$ is 4. However, I don't know how to deal with the $\epsilon(||(x+\sqrt2,y+\sqrt2)||) $. I would appreciate it if someone could help me with this.","['multivariable-calculus', 'real-analysis', 'calculus', 'analysis']"
1834331,Finding all $z\in \mathbb{C}$ such that the series $\sum\limits_{n=1}^{\infty} \frac{1}{1+z^n}$ converges,"I am trying to find out all $z\in \mathbb{C}$ such that the series $\displaystyle \sum_{n=1}^{\infty} \frac{1}{1+z^n}$ converges. I notice that for $\left|z\right|\leq 1$, we have $\left|1+z^n\right|\leq 1+\left|z\right|^n\leq 1 + 1=2$ and hence $\limsup_{n\to \infty}\frac{1}{1+z^n}\ge 1/2$ which means that $\frac{1}{1+z^n}$ does not go to zero and so the series does not converge for $|z|\leq 1$. $\left|\frac{1}{1+z^n}\right|=\sqrt{1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)}$ and I suspect $1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)^{1/2n}$  goes to $1/\left|z\right|$ but I am unable to prove that. Edit: 
Suppose $|z|>1$. Suppose $z=r(\cos\theta + i \sin \theta)$ with $r>1$. Then $\displaystyle |1+z^n|=\sqrt{1+2r^n\cos n\theta+r^{2n}}>(r^n-1)$, so $\displaystyle \frac{1}{|1+z^n|}<\frac{1}{r^n-1}$. We will try to prove that $\displaystyle \sum \frac{1}{r^n-1}$ is convergent which will give us our desired result by the comparison test. Note that $\displaystyle \frac{r^n-1}{r^{n+1}-1}=\frac{r^{n-1}+\dots+1}{r^n+\dots+1}=1- (r-1)\frac{r^n}{r^{n+1}-1}$ which goes to $1/r<1$ and hence $\displaystyle \sum \frac{1}{r^n-1}$ is convergent by the ratio test.","['complex-analysis', 'sequences-and-series', 'complex-numbers']"
1834355,Matrix-by-matrix derivative formula,I need to derive $$\frac{\delta(X^{T}MX)}{\delta X}$$ where $X$ and $M$ are $n \times n$ matrices. I know that $$\frac{\delta(AXB)}{\delta X}=B^{T} \otimes A$$ but am having a hard time deriving what I need from that or from scratch.,"['matrices', 'matrix-calculus', 'derivatives']"
1834356,Prove: $|a\sin x+b \cos x|\leq \sqrt{a^2+b^2}$,$$|a\sin x+b \cos x|\leq \sqrt{a^2+b^2}$$ I have tried: $$|a\sin x+b \cos x|\leq |a+b|\leq \sqrt{a^2+b^2}$$ Suffices to prove: $$|a+b|\leq \sqrt{a^2+b^2}$$ But I can't find how to continue from here.,"['algebra-precalculus', 'inequality']"
1834365,Brocard Angles proof by Sine and cosine formulae.,"The angles denoted by $\omega$ are the Brocard angles. Recently i came to know about the Brocard Angles and also their property i.e $\cot{\omega}=\cot{A}+\cot{B}+\cot{C}$. In my previous question I got the answer on proving the identity.  But I want to prove this identity only through the sines and cosine formula(excluding any excessive use of geometry parts) Now I tried the question this way: In $\triangle APC$, $\angle CAP=A-\omega; \angle CPA=\pi-A$. Thus using the sine rule we can write $\frac{\sin{(A-\omega)}}{CP} = \frac{\sin{A}}{b}$. Similarly using the same rule in other triangle we can write: For $\triangle CPB$ $\frac{\sin{(C-\omega)}}{PB} = \frac{\sin{C}}{a}$ For $\triangle APB$ $\frac{\sin{(B-\omega)}}{AP} = \frac{\sin{B}}{c}$ Now in the respective sine formulae I expanded the expressions of $\sin{(A-\omega)}$, $\sin{(B-\omega)}$ and $\sin{(C-\omega)}$ This gave me-
  $$\frac{CP}{b}=\cos{\omega}-\sin{\omega}\cot{A}\tag{1}$$
  $$\frac{PB}{a}=\cos{\omega}-\sin{\omega}\cot{C}\tag{2}$$
  $$\frac{AP}{c}=\cos{\omega}-\sin{\omega}\cot{B}\tag{3}$$ Adding the equations $(1),(2)$ and $(3)$
  $$\frac{CP}{b}+\frac{PB}{a}+\frac{AP}{c}=3\cos{\omega}-\sin{\omega}(\cot{A}+\cot{B}+\cot{C})$$ I got stuck after this. Please tell me whether I can proceed further or is my method completely inconclusive.","['euclidean-geometry', 'trigonometry']"
1834371,Exponential of Operators,"Let $H$ be an Hilbert Space $\exp(T)$ the exponential for an operator $T \in L(H)$.
I know that $\exp(A)^{*} \exp(A)=\exp(A) \exp(A)^{*}=id$. Can I conclude that $A^{*}A=AA^{*}$?
Cannot find an counter example neither succeeded my attempts at rearranging. Any hint is appreciated.
EDIT:
For my task i just need that i can conclude
$$ \exp(A)\exp(A)^{*} = \exp(A)^{*}\exp(A) = \exp(A+A^*) $$","['functional-analysis', 'operator-theory']"
1834379,"If the sides of a triangle satisfy $(a-c)(a+c)^2+bc(a+c)=ab^2$, and if one angle is $48^\circ$, then find the other angles.","In triangle $ABC$ one angle of which is $48^{\circ}$, length of the sides satisfy the equality:
  $$(a-c)(a+c)^2+bc(a+c)=ab^2$$
  Find the value in degrees the other two angles of the triangle. I have no idea how to solve this problem","['trigonometry', 'triangles', 'geometry']"
1834397,Convergence in $L^p$ and convergence almost everywhere,Why $f_n$ converges to $f$ in $L^p$ space implies that exists subsequence of $f_n$ converging to $f$ almost everywhere?,"['functional-analysis', 'lp-spaces', 'measure-theory']"
1834442,What is this manifold?,"As picture below ,it is a Mobius band with a cylinder crossing it .Let it be $\Omega$ . Obviously , $\partial \Omega$ is a circle. Now , what is $\Omega/\partial \Omega$ ( I mean glue the boundary to a point )? And how to show it ?","['algebraic-topology', 'geometric-topology', 'manifolds', 'geometry']"
1834444,Second Differential,"Let $(x,y,z)$ a coordinate system, $M=\mathbb{R}^3$ and we also denote by $x$ the first coordinate function : $x:M \rightarrow \mathbb{R},\; q=(a,b,c) \mapsto a$. We have $dx:TM \rightarrow \mathbb{R},\; (q,v=(v_1,v_2,v_3)) \mapsto dx[q](v)=v_1$. Let $f=dx[q]$. We have $df:TM \rightarrow \mathbb{R},\; (p,u=(u_1,u_2,u_3)) \mapsto df[p](u)=u_1$. How to get $d(dx) = df = 0$ ?","['multivariable-calculus', 'differential-geometry', 'derivatives']"
1834474,Endomorphism ring of an abelian variety and its reduction mod $\mathfrak{p}$,"Let $A$ be an abelian variety defined over a number field $K$. Let $\mathfrak{p}$ be a prime of $K$ for which $A$ has good reduction and let $k=\mathcal{O}_{K,\mathfrak{p}}/\mathfrak{p}$. Let $\mathcal{A}$ be a Neron model for $A$ over $\mathcal{O}_{K,\mathfrak{p}}$. Then I have seen it mentioned that the following composition is an injection: $$\operatorname{End}_K(A)= \operatorname{End}_{\mathcal{O}_{K,\mathfrak{p}}} (A)\to \operatorname{End}_k(\mathcal{A}\otimes k).$$ I cannot however seem to prove this. It seems like it should be easy though. Any help or direction is appreciated.","['number-theory', 'algebraic-geometry', 'abelian-varieties']"
1834478,Motivation for the study of algebraic structures,I am currently studying group theory and I realized that most concepts we study are just definitions on which we build theory. I do understand that some theorems are beautiful and don't need any practical use to be interesting to study. My question now is: What are the motivations behind the following concepts: Normal subgroups Permutation groups Right and Left cosets,"['abstract-algebra', 'motivation']"
1834521,"Prove $\lim_{(x,y)\to (0,0)} \frac{x^2 y^3}{x^4 + y^4} =0$ without $\varepsilon - \delta$.","Unlike Multivariable Delta Epsilon Proof $\lim_{(x,y)\to(0,0)}\frac{x^3y^2}{x^4+y^4}$ --- looking for a hint I would like to avoid the $\varepsilon - \delta$ criterium. Prove $$\lim_{(x,y)\to (0,0)} \frac{x^2 y^3}{x^4 + y^4} =0 \,.$$ Approaching this limit from $y=0$, $x=0$, $y=x$, $y=x^2$ etcetera all yields 0 as value, so my proposal is that this limit is indeed 0. I have been able to solve most similar limits so far by finding some convergent upper bound for the absolute limit, but with this one the difference between the numerator and the denominator is so small I can't find anything to fit inbetween. For example, $(x,y)\to(0,0)$,
$$ \left| \frac{x^2 y}{x^2 + y^2} \right| \le \left| \frac{(x^2 + y^2)y}{x^2 + y^2} \right| \to 0 \,. $$ Also, Continuity of $\frac{x^3y^2}{x^4+y^4}$ at $(0,0)$? and Proving $ \frac{x^3y^2}{x^4+y^4}$ is continuous. contain some helpful hints.","['multivariable-calculus', 'real-analysis', 'limits']"
1834523,Analytical solution to coupled nonlinear ODEs,"I am looking to solve several coupled nonlinear ODEs like this one: $\hspace{20mm} \frac{d x(t)}{dt} = C_1 \cdot x(t) + C_2 \cdot y(t) + C_3\cdot (x(t)^2 + y(t)^2) x(t),$ $\hspace{20mm} \frac{d y(t)}{dt} = C_1 \cdot y(t) - C_2 \cdot x(t) + C_3\cdot (x(t)^2 + y(t)^2) y(t).$ I have tried multiplying the first by $y(t)$ and the second by $x(t)$ and adding them or subtracting them, but with no luck. I have noticed that each system is almost symmetrical, is there any general procedure for such systems? If not, how do I solve this system? Context I am looking into Rain-Wind induced vibrations of stay cables. I am trying to approximate the model I have derived using a Multiple Time-Scale Perturbation Analysis. During this analysis, many coupled nonlinear ODEs need to be solved, which are almost symmetrical.","['perturbation-theory', 'ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
1834566,If unions of two families sets are disjoint then families of sets are disjoint too.,"I have read that theorem ""Suppose $\mathcal{F}$ and $\mathcal{G}$ are families of sets. If $\cup\mathcal{F}$ and $\cup\mathcal{G}$ are disjoint, the so are $\mathcal{F}$ and $\mathcal{G}$"" is incorrect. But I can not understand way. May somebody explain to me why this theorem is wrong or provide a counterexample?","['proof-writing', 'elementary-set-theory']"
1834575,"Find all continuous functions $f:[0,1]\rightarrow \mathbb{R}$ that satisfy: $\int_0^1 f(x)dx=1/3 + \int_0^1 f^2(x^2)dx$","(Note that $f^2(x)=f(x)\cdot f(x)$ and not composition.) Since both integrals are defined, derivation is out of the question. I tried integrating the second integral by parts but reached something chaotic, so I'm more than sure there's a catch to this I'm not getting. Any hints will be appreciated.","['real-analysis', 'integration', 'definite-integrals', 'calculus']"
1834578,Solution of $e^{-z}+z=\lambda$,"Let $\lambda\in\mathbb{C}$ with $\Re(\lambda)>1$ be given. I want to show, that $e^{-z}+z=\lambda$ has exactly one solution in $U=\{z\in\mathbb{C}:\Re(z)>0\}$. I think that exercise can be solved by using Rouché's theorem (symmetric version) . Can you tell me how to apply that theorem please? Thank you!","['complex-analysis', 'holomorphic-functions']"
1834593,How to prove that the series $\sum\limits_{n=1}^\infty {\sin^2n} $ diverges,I want to use a divergence test to prove that $\lim_{n\to \infty} \sin^2n$ does not converge. So $\sum_{i=1}^\infty \sin^2 n $ diverge. But because $\pi$ is an irrational number. So I cannot use subsequence with $n=n\pi$ and $n=\frac{(2n-1)\pi}{2}$. So how can I prove that the sum diverges? Where $n \in \Bbb{N}$,"['divergent-series', 'sequences-and-series', 'calculus']"
1834598,Determine all possible $\phi$,"Let $\phi: S_6 \to \mathbb{Z}/6\mathbb{Z}$ be a homomorphism. Explain why $[S_6,S_6]$, the commutator subgroup of $S_6$, is a subset of ker($\phi$) and after that determine all possible $\phi$. For the first part I picked a random element in the commutator subgroup $a^{-1}b^{-1}ab$. From the definition of homomorphisms it follows that: $\phi(a^{-1}b^{-1}ab)=\phi(a^{-1})\phi(b^{-1})\phi(a)\phi(b)$ Since $\mathbb{Z}/6\mathbb{Z}$ is abelian we can rearrange the above as follows: $\phi(a^{-1})\phi(a)\phi(b)\phi(b^{-1})=\phi(a^{-1}abb^{-1})=\phi(1_G)=1_H$ That proves the inclusion. When it comes to the second part I get totally stuck. I'm not even sure I fully understand the question. How do I do this?",['group-theory']
1834617,Tightness and Inner Regularity,"Let $P$ be a probability measure on a Borel $\sigma$-algebra (on some metric space, $\Omega$). It is called tight if for every $\epsilon >0$, there exists a compact $K$ such that $P(X \in K) \geq 1 - \epsilon$. It is called inner regular if $P(A) = \sup \{P(K) | K \subset A, K \text{ compact}\}$ for every $A$ in the Borel $\sigma$-algebra. It is clear that inner regularity implies tightness if we choose $A=\Omega$. For an arbitrary set $A$, using tightness we can obtain a
compact $K(\epsilon)$ such that $P(A\cap K(\epsilon)) \geq P(A) - \epsilon$. If $A$ is closed then $K \cap A$ is compact and hence we get
inner regularity for closed sets $A$. How can I prove this for general $A$? Thanks.",['measure-theory']
1834623,Why can a quartic polynomial never have three real and one complex root?,"It seems that a quartic polynomial (degree $4$) either can have $0$ real, $1$ real, $2$ real, or $4$ real roots, and the rest is complex roots. Why can't it have $3$ real roots and $1$ complex?","['quartics', 'polynomials', 'complex-numbers', 'roots', 'algebra-precalculus']"
1834638,Pattern in numbers,"I bumped into this mathematical calculation while driving my car. With lot of traffic jams and lot of time to kill, I did some scrambling of the registration numbers of the cars in front of me. I came across a rather strange pattern that I could not relate to any law in mathematics. For a given number, partition it into any number of partition and where each partition can be any combination of digits from that number. For example Take any number - say, 5437, partition it in any two sets, say 57  and 43 (Other valid partition sets will be 543/7, 37/45, 347/5, 3/4/37, 3/4/7/5) add those partition - 57 + 43 = 100 repeat 2 and 3 till 3 comes to single digit. In this case 100 is partitioned into 10/0 : 10 + 0 = 10, 10 => 1/0 : 1 + 0 = 1 So 5437 => 1    (Result 1) For same number, choose any other partition 543 and 7 543+ 7 = 550 550 partitioned in to 5/50 5 + 50 = 55,  partition 55 into 5/5 => 5+5 = 10, partition 10 into 1 + 0 = 1  (same as result 1) For same number, choose any other partition 537/ 4 3 537 + 4 = 541 4, 541 : 45 /1 45 + 1 = 46, 46=> 4/6 : 4 + 6 = 10, 10=> 1/0 1 + 0 = 1 (Result 1) Apply any combination of partition, for this number it will be always 1. Lets take any other number - 91522 Partition - 922 and 15, 922 + 15 = 937, Partition 937 -> 73 and 9, 73 + 9 = 82, 82 -> 8 + 2 = 10, 10 : 1 + 0 = 1 Partition - 522 and 91, 522 + 91 = 613, Partition 613 -> 63 and 1, 63 + 1 = 64, 64 -> 6 + 4 = 10, 10 -> 1 + 0 = 1 One more 4443 Partition - 344 and 4, 344 + 4 = 348, Partition 348 -> 84 and 3, 84 +3 = 87, 87 -> 8 + 7 = 15, 15 : 1 + 5 = 6 Partition - 44 and 43, 44 + 43 = 87, Partition 87 -> 8 + 7 = 15, 15 : 1 + 5 = 6 3  Partition - 4 and 443, 4 + 443 = 447, Partition 447 -> 74 + 4 = 78, 78 : 7 + 8 = 15, 15: 5 + 1 = 6 Partition - 4, 4, 4, 3, 4 + 4+ 4+3 = 15, 15: 5 + 1 = 6 How can this be explained?","['number-theory', 'decimal-expansion', 'modular-arithmetic', 'divisibility']"
1834650,Distribution of throws of die rigged to never produce twice in a row the same result,"A die is “fixed” so that each time it is rolled the score cannot be the same as the preceding score, all other scores having probablity 1/5. If the first score is 6, what is the probability that the nth score is 6 and what is the probability that the nth score is 1?","['markov-chains', 'probability-theory']"
1834669,Showing that $x$ is an element of group $G$ by left multiplication,"$G$ is a group and $H \leq G$ with $|G:H|=3$. Show that $x$ is an element of $H$ if $x \in G$ with $|x|=7$. Hint: let $\langle x \rangle$ act on $G/H$ by left multiplication and look at the orbits. Since the index of $H$ in $G$ is $3$ we can name the elements of $G/H$: $1H=H$, $g_1H$ and $g_2H$ Except for the neutral element all the elements of $\langle x \rangle$ have order $7$ since $7$ is a prime. $x^n \cdot H$ is a subset of one of $H$, $g_1H$ or $g_2H$ $x^n \cdot g_1H$ is a subset of one of $H$, $g_1H$ or $g_2H$ $x^n \cdot g_2H$ is a subset of one of $H$, $g_1H$ or $g_2H$ So far for my thoughts. I don't know how I can conclude anything about the orbits let alone conclude that $x$ is an element of $H$. How to proceed?","['group-actions', 'group-theory']"
1834672,Let $S$ be a set consisting of all positive integers less than or equal to $100$.,"Let $S$ be a set consisting of all positive integers less than or equal to $100$. Let $P$ be a subset of $S$ such that there do not exist two elements $x,y\in P$ such that $x=2y$. Find the maximum possible number of elements of $P$. Is answer 67?",['combinatorics']
1834679,Is there a mathematical reason why rotation in the counterclockwise direction positive and clockwise rotation negative?,"This inquiry has recently come to me in my study of trigonometry and the unit circle. It was said right from the very start that counterclockwise rotation were positive while clockwise rotations are negative, and I was wondering if there was a mathematical reason for this or if it was just picked that way.","['trigonometry', 'soft-question', 'convention']"
1834686,"Why do we use the word ""scalar"" and not ""number"" in Linear Algebra?","During a year and half of studying Linear Algebra in academy, I have never questioned why we use the word ""scalar"" and not ""number"". When I started the course our professor said we would use ""scalar"" but he never said why. So, why do we use the word ""scalar"" and not ""number"" in Linear Algebra?","['terminology', 'linear-algebra']"
1834701,Solving for $x$ of different powers,I want to solve the following equation for $x$ $$\left(x + \frac{6}{x} \right)^2 + \left( x + \frac{6}{x} \right) = 30$$ I done my working till - $$x^4 + x^3 - 18x^2 + 6x + 36 = 0$$ From here how do I solve for $x$ when I have any different powers ?,['algebra-precalculus']
1834738,If $x= m-m^2-2$ then find $x^4+3x^3+2x^2-11x+6$ where m is a cube root of unity,"If $$x= m-m^2-2$$ then find $$x^4+3x^3+2x^2-11x+6$$ where $m$ is a cube root of unity. My try: Since $ m+ m^2+1=0$ the value of $x$ is $-1$. Let $f(x)=x^4+3x^3+2x^2-11x+6$
then $ f(-1)=5$ So the answer is $5$. Am I correct? In my book it says that answer is $1$. Please help me to identify my mistake.",['complex-analysis']
1834756,Taylor Series for a Function of $3$ Variables,"The Taylor expansion of the function $f(x,y)$ is: \begin{equation}
f(x+u,y+v) \approx f(x,y) + u \frac{\partial f (x,y)}{\partial x}+v \frac{\partial f (x,y)}{\partial y} + uv \frac{\partial^2 f (x,y)}{\partial x \partial y}
\end{equation} When $f=(x,y,z)$ is the following true? $$\begin{align}
f(x+u,y+v,z+w) \approx f(x,y,z) &+ u \frac{\partial f (x,y,z)}{\partial x}+v \frac{\partial f (x,y,z)}{\partial y} + w \frac{\partial f (x,y,z)}{\partial z}
\\
&+uv \frac{\partial^2 f (x,y,z)}{\partial x \partial y} + vw \frac{\partial^2 f (x,y,z)}{\partial y \partial z}+ uw \frac{\partial^2 f (x,y,z)}{\partial x \partial z} \\
&+ uvw \frac{\partial^3 f (x,y,z)}{\partial x \partial y \partial z}
\end{align}$$","['multivariable-calculus', 'taylor-expansion', 'sequences-and-series', 'approximation']"
1834757,Is the contraction of an harmonic form harmonic?,"As I'm still a beginner in complex differential geometry, as soon as I tried reading an article I got stuck on what (I think) should be a minor detail. I hope someone can help me a bit. Let $M$ be a complex manifold of complex dimension $m$, and let $g$ be a Kähler metric on $M$ with Kähler form $\omega$ and Ricci form $\rho$. Let $h=h_{i\bar{j}}dz^{i}\wedge d\bar{z}^{j}$ be the harmonic part of $\rho$ in the Hodge decomposition for $\bigwedge\nolimits^{1,1}M$. Can I conclude that the function $\varphi=g^{i\bar{j}}h_{i\bar{j}}$ is also harmonic? I think that the answer should be ""yes"", but I'm struggling to prove it. So far I've reasoned as follows: since $\varphi$ is a function, it is enough to show that $d\varphi=0$; moreover for functions we know that $d=\nabla$, if $\nabla$ is the Levi-Civita (or Chern) connection on $M$. Since $g$ is $\nabla$-parallel we have, for every $a=1,\dots,m,\bar{1},\dots,\bar{m}$
$$\nabla_a(g^{i\bar{j}}h_{i\bar{j}})=(\nabla_ag^{i\bar{j}})h_{i\bar{j}}+g^{i\bar{j}}(\nabla_ah_{i\bar{j}})=g^{i\bar{j}}(\nabla_ah_{i\bar{j}})$$
so to prove that $\varphi$ is harmonic it is enough to show that $h$ is parallel. However, I fail to see why this should be true. Could someone please tell me what I'm missing? Any help is greatly appreciated. edit : Since there are various different notions of ""Laplacian"" on a Kähler manifold I should have specified that the Laplacian I am talking about here is the Hodge Laplacian , $\Delta:=\bar{\partial}^*\bar{\partial}+\bar{\partial}\bar{\partial}^*$, where $\bar{\partial}^*$ is the adjoint of $\bar{\partial}$.","['complex-geometry', 'hodge-theory', 'kahler-manifolds', 'differential-geometry']"
1834758,Prove any function can be written as a composition between an injective and a surjective function.,"Given an arbitrary function $f:A\rightarrow B$, write it as a composition between an injective and a surjective function, respectively.","['elementary-set-theory', 'function-and-relation-composition', 'functions']"
1834777,About the minimal equivalence relation identifying some points.,"I am solving a problem where I have a set $X$ together with a subset of elements that I want to identify. To do this I consider the minimal equivalence relation identifying these points. I have a function $f: X \to Y$ that satisfies $f(x)=f(y)$ for every two points that I have declared to be equivalent. Can I conclude that this function factorizes to the quotient? A bit of context: For a given ring $A$ I am trying to show that the colimit of the functor 
$$F: Fields \to Set$$
$$ K \mapsto Hom(A,K)$$ is in bijection with the set of prime ideals of $A$.To do this I need to define a function of the colimit and  I need to check that it is well defined.","['category-theory', 'elementary-set-theory']"
1834783,Derivation of standard error of regression estimate with degrees of freedom,"I am taking a course of Econometrics: I need help to understand as to how do we arrive at the formula for standard error of regression $$\hat{\sigma}^2=\frac{\sum{e_i^2}}{n-k}.$$ I understand the bessel's correction required to remove the bias inherent in sample variance. The proof being available at Bessels Correction Proof of Correctness . I also found Standard deviation of error in simple linear regression How to derive the standard error of linear regression coefficient But I could not find the proof for the above expression (standard error of regression estimate). I tried to open the equation on the lines of Bessels Correction proof. $$e_i=\text{Total SS}- \text{Explained SS}$$ Then I try to expand the Explained sum of squares term, but I got stuck at $$ \sum _{i=1}^n \operatorname {E} \left((\beta\mathbf{ X}-\bar{y} )^2 \right) = \beta^2 E(x^2)-2\beta\bar{xy}+E(\bar{y}^2)$$ I don't know how to proceed. Can anyone please help ? Then I read this : The term ""standard error"" is more often used in the context of a regression model, and you can find it as ""the standard error of regression"". It is the square root of the sum of squared residuals from the regression - divided sometimes by sample size n (and then it is the maximum likelihood estimator of the standard deviation of the error term), or by $n−k$ ( $k$ being the number of regressors), and then it is the ordinary least squares (OLS) estimator of the standard deviation of the error term. on Standard Error vs. Standard Deviation of Sample Mean Can anyone suggest a textbook where I can read about these derivations in more details ?","['statistics', 'standard-deviation', 'regression-analysis']"
1834787,About transpose matrix transformation problem.,"I have this problem that I don't understand so I can't solve. I wish someone could explain me it or solve it. Let $M_2(\mathbb{R})$ the vector space generated by all the square
  matrices of $2\times 2$. Consider the linear transformation $T\colon
 M_2(\mathbb{R})\longrightarrow M_2(\mathbb{R})$ given by $T(A)=A^T$
  (where $A^T$ is the transpose of $A$). Calculate a basis for
  $M_2(\mathbb{R})$ such that the transformation $T$ is represented by a
  diagonal matrix. Which are the possible values for the diagonal?","['matrices', 'linear-algebra', 'linear-transformations']"
1834806,Global section defines a map from structure sheaf,"Let $X$ be a smooth projective scheme over an algebraically closed field. Let $F$ be a coherent torsion-free sheaf on $X$. A global section $f$ of $F$ defines a morphism $O_X\rightarrow F$ given by: on each open set $U$, $O_X(U)\rightarrow F(U)$, $c\mapsto c.f|_U$. Is this morphism injective? When is this morphism injective?","['sheaf-theory', 'algebraic-geometry']"
1834826,Find a matrix $B$ such that $B^3 = A$,$$A=\begin{pmatrix} 1 & -1 \\ -2 & 1 \end{pmatrix}$$ Find a matrix $B$ such that $B^3$ = A My attempt: I found $\lambda_1= 1+{\sqrt 2}$ and  $\lambda_2= 1-{\sqrt 2}$ I also found their corresponding eigenvectors $\vec v_1 =\begin{pmatrix} \frac{-\sqrt 2}{2} \\ 1 \end{pmatrix}$ and $\vec v_2 = \begin{pmatrix} \frac{\sqrt 2}{2} \\ 1 \end{pmatrix}$ I know the Power function of a matrix formula $A=PDP^{-1}$ Because it's the cubed root I'm looking for I don't know how to get the cubed root of the eigenvaules and keep the maths neat. Is there another way to solve this problem or an I going the wrong way about doing it ?,"['matrices', 'linear-algebra']"
1834837,Finding counterexamples in elementary set theory.,"I had the following two problems: Find a counterexample for $f_*(A \cap B) \supseteq f_*(A) \cap f_*(B)$ and $ f_*(A-B) \subseteq f_*(A) -f_*(B).$ Where $f_*(X)$ is the image of $X$ under $f$ for some function $f:A \rightarrow B $ and some subset $X \subseteq A$. I came with the following answer: Let $ f: \mathbb{Z} \rightarrow \mathbb{Z} $, where $f: x\mapsto 0$; let $A=\{1,2\}$, and $B=\{3,4\}$. For $f_*(A \cap B) \supseteq f_*(A) \cap f_*(B)$, $$ f_*(A \cap B) = f_*\{ \varnothing\} = \varnothing \hspace{1cm} \text{and} \hspace{1cm} f_*(A) \cap f_*(B)=\{0\} \cap \{0\} = \{0\}. $$ It follows that $ \varnothing \nsupseteq \{0\} $. For $ f_*(A-B) \subseteq f_*(A) -f_*(B)$, $$f_*(A-B)=f_*(\{1,2\})=\{0\} \hspace{1cm} \text{and} \hspace{1cm} f_*(A) - f_*(B) = \{0\} - \{0\} = \varnothing$$ It follows that $ \{0\}  \nsubseteq \varnothing $. Now (assuming my answer is correct), let's say I want to find more counterexamples or maybe a more general answer (e.g. all the conditions under which the inclusion fails). Other than by trial and error or just intuition, how would I do that? I know this is a broad question, so I'm specifically asking for methods or advice on how to build counterexamples in elementary set theory (for example, tips on where to begin or rules that apply in general that may be unobvious).","['elementary-set-theory', 'soft-question', 'functions']"
1834902,A 'bad' definition for the cardinality of a set,"My set theory notes state that the following is a 'bad' definition for the cardinality of a set $x:$ $|x|=\{y:y\approx x\}$ $(y\approx x\  \text{iff} \ \exists\  \text{a bijection}\  f:x\rightarrow y )$ The reason this is a 'bad' definition is since if $x\neq \emptyset$ then $|x|$ is a proper class and I am asked to prove this. For the moment, let's consider $x$ to be finite. Say $|x|=n$ as $x$ contains a finite number of elements. But then $x\approx \{n+1,...,n+n\}$ as $|\{n+1,...,n+n\}|=n$ and we can 'keep going up' in this way such that  $\bigcup On\subseteq|x|$ and since $\bigcup On = On$  and $On$ is a proper class we must have $|x|$ being a proper class as well. This argument is certainly not rigourous and I am unfortunately very much stumped on what to do if $x$ not finite. $\underline{\text{Please correct me if $\ $} \bigcup On \neq On}$ Any feedback is very much appreciated.","['cardinals', 'elementary-set-theory', 'ordinals']"
1834925,Why is matrix multiplication called 'multiplication' if it is non-commutative?,"This question begins with the assumption that matrix multiplication was termed 'multiplication' as a form of comparison/parallel to multiplication of integers and real numbers. Why was matrix multiplication termed 'multiplication' if it does not share the commutativity that other methods of multiplication typically adhere to? And by extension, why was another term not adopted (such as 'matrix application') in respect to this lack of commutativity? Edit: To further clarify, it seems to me that the natural choice for the operation termed 'multiplication' performed with matrices ought to be the Hadamard Product given that it is a direct multiplication of the elements of the matrix (thus retaining the properties of multiplication of real numbers), and that the operation now termed "" Matrix Multiplication "" should have received a different name because it does not retain the properties exhibited by multiplication in more basic contexts. So perhaps my question would be better phrased as: ""How did an operation which does not have all the properties of multiplication on real numbers come to be termed 'multiplication'?"" or: ""Why is matrix multiplication called 'multiplication' when the operation it represents seems to have no analogy to multiplication of real numbers?""","['matrices', 'math-history', 'terminology']"
1834975,How to easily solve this trigonometric equation?,"Given equation:
$$\frac{\sin(x) + \sin(5x) - \sin(3x)}{\cos(x) + \cos(5x) - \cos(3x)} = \tan(3x),$$
what is the easiest way to solve it? I know it can be solved by expanding each $\sin(nx)$ and $\cos(nx)$ terms, but is there an easier way?","['algebra-precalculus', 'trigonometry']"
1835006,Proving the Cardinality of a set in R,"Let $\ A\subset R $ have the following characteristic: For all $\ a,b \in A$ , $\ \frac{a+b}{2} \notin A$. Prove that there exists a maximal set A. Prove its cardinality is $\ \aleph $. The first part is relatively simple using Zorn's Lemma, taking any chain with the inclusion relation, of sets with the said characteristic, and binding them above by their union. As for the second part. Let $\ max{A}=M $. $\ M\subset R $ so $\ |M| \leq  \aleph $ . My question is, how can I find a set of Cardinality $\ \aleph $  with the stated characteristic (or prove one exists) to be a lower bound for M?","['cardinals', 'elementary-set-theory']"
1835020,properties of distributions,"If $$\int_{-\infty}^\infty f dx = 1$$, with $f > 0 \forall x$, then prove or disprove: $$\int_{-\infty}^\infty \frac{1}{1 + f} dx $$ diverges.
The hint I got is to consider the measure of the set$(x:f > 1)$. May be the measure is zero thereby ensuring the divergence of integral?","['real-analysis', 'measure-theory', 'calculus']"
1835035,Element of infinite order for a given group presentation,"Let $G=\langle a,b,c,d \mid abcda^{-1}b^{-1}c^{-1}d^{-1}\rangle$ be our presentation. The claim is that the commutator $[a,b]$ has inifinite order in $G$. I think this might be related to small cancellation, but not really sure how promising that approach really is. I am grateful for any hints, thanks!","['hyperbolic-geometry', 'abstract-algebra', 'word-problem', 'finitely-generated', 'group-theory']"
1835068,Extending a morphism to a proper scheme using the valuative crierion for properness,"Here's an example I'm trying to work out. Let $f : U := \mathbb{A}^1 -\{0\} \rightarrow X$ be a morphism of schemes, where X is a proper scheme over a field $k$. I am trying to extend this morphism to a morphism from $\mathbb{A}^1 \rightarrow X$. If we consider the morphism $q : \text{Spec} (k) \rightarrow X$ sending the point to $0$, then by the valuative criterion for properness we get a morphism from the local ring $g : \mathcal{O}_{\mathbb{A}^1,0} \rightarrow X$ such that $q \circ i = g$, where $i : \text{Spec} (k) \rightarrow \mathcal{O}_{\mathbb{A}^1,0}$ is the natural map. So now I have a map from the local ring at $0$ - the map $g$, and a map from $U$ - the map $f$. How am I supposed to glue it to a map from $\mathbb{A}^1$? Or am I applying the valuative criterion in a completely wrong way here? Thanks!",['algebraic-geometry']
1835093,Is this proof of convergence in probability correct?,"${X_i}, i = 1,2,\dots$ i.i.d random variables, and $S_n = \sum_{i=1}^nX_i$ is defined as partial sum as usual. If $\frac{S_n}{n} \to 0 \quad $ in probability show that $$\lim_{n\to \infty} \min_{1\leq k \leq n}\mathbb{P}\left(\frac{\left|S_n - S_k\right|}{n} < \epsilon\right) = 1 .$$ My proof: Is this proof correct? Can I just fix k and claiming it is uniformly convergent?
Thanks in advanced.","['real-analysis', 'probability-theory', 'proof-verification', 'probability', 'convergence-divergence']"
1835096,Is there an alternative way to represent the $\operatorname{diag}$ function?,"In optimization, it is common to see the so called $\operatorname{diag}$ function Given a vector $x \in \mathbb{R}^n$, $\operatorname{diag}(x)$ =  $n \times n$ diagonal matrix with components of $x$ on the diagonal For example: Optimization that involves inverse operation. Reformulation of BQP to SDP The reason of using  $\operatorname{diag}$ is because it is used in several platforms such as MATLAB, and people generally understands what the function is supposed to do Is there a more linear algebra, step by step way of converting a
  vector $x \in \mathbb{R}^n$ into a diagonal matrix with components on
  the diagonal without having a define a function that directly performs
  the task ? i.e. given $x$, we find a series of functions/steps $f_2 \circ f_1 (x)$ which give us the same matrix as  $\operatorname{diag}(x)$","['matrices', 'computational-mathematics', 'soft-question', 'article-writing', 'linear-algebra']"
1835103,A very curious rational fraction that converges. What is the value?,"Is there any closed form for the following limit? Define the sequence
  $$ \begin{cases} 
  a_{n+1} = b_n+2a_n + 14\\
  b_{n+1} = 9b_n+ 2a_n+70
\end{cases}$$
  with initial values $a_0 = b_0 = 1$. Then $\lim_{n\to\infty} \frac{a_n}{b_n} = ? $ The limit is approximately $0.1376$. My math teacher Carlos Ivorra says that this limit have a closed form involving the sine of an angle. What is the closed form for is limit? NOTE: I have found this (and another series of converging sequences) by the use of an ancient method for calculating sines recently rediscovered. I'll give the details soon as a more general question.","['real-analysis', 'limits', 'trigonometry', 'sequences-and-series', 'analysis']"
1835151,The group algebra $KG$,"If $G$ is a cyclic group of order $m$. Then $KG\cong K[t]/(t^m-1)$. Where $K$ is a field. I define \begin{align*}
\varphi:K[t]&\longrightarrow KG\\
\sum_ia_it^i&\longmapsto\sum_ia_ig^i
\end{align*}
 where $\left\langle g\right\rangle=G$ and $a_i\in K$ and $\varphi$ is surjective and homomorphism. Let $I=\left\langle t^m-1\right\rangle$. So I want to prove that $ker\varphi\subseteq I$. Thus Let $p(t)\in ker\varphi$, where $p(t)=\sum_ia_it^i$, and $e$ the identity of $G$. Then
\begin{align*}
\varphi(p(t))&=\varphi\left(\sum_ia_it^i\right)\\
&=0\\
&=\sum_ib_ig^i-\sum_ib_ig^i\\
&=\sum_ib_ieg^i-\sum_ib_ig^i\\
&=\sum_ib_ig^mg^i-\sum_ib_ig^i\\
&=\sum_ib_ig^{m+i}-\sum_ib_ig^i\\
&=\varphi\left(\sum_ib_it^{m+i}\right)-\varphi\left(\sum_ib_it^i\right)\\
&=\varphi\left(\sum_ib_it^{m+i}-\sum_ib_it^i\right)\\
&=\varphi\left(\sum_ib_it^{i}(t^m-1)\right)\\
&=\varphi\left(q(t)(t^m-1)\right)
\end{align*}
 Where $q(t)=\sum_ib_it^i$ and $b_i\in K$. How I can guarantee that $p(t)=q(t)(t^m-1)$?","['abstract-algebra', 'group-theory']"
1835156,Can $Y$ and $\frac{X}{Y}$ be uncorrelated if neither $X$ or $Y$ is constant?,"Suppose I have two variables $X$ and $Y$ with $Y>0$.  Can the random variables $Y$ and $\frac{X}{Y}$ ever be uncorrelated, i.e.,
$$\mathbb{E}(X)=\mathbb{E}(Y)\mathbb{E}\left(\frac{X}{Y}\right).$$  This seems counterintuitive since both are dependent on $Y$.  But I just want to make sure there is not some weird case I am not thinking of. Actually, I just realized as I type that this is true if $X$ or $Y$ is a constant.  How about in cases other than constant $X$ or $Y$ then? I guess this question simplifies to what are the conditions for 
$$\mathbb{E}\left(\frac{X}{Y}\right)=\frac{\mathbb{E}(X)}{\mathbb{E}(Y)}?$$","['probability-theory', 'probability', 'expectation', 'random-variables']"
1835181,Rolling a die until obtaining the face 6. Whats the expected amout of the sum?,"A game where you roll a fair die, repeatedly, adding up the faces that show up, until the face 6 appears. What is the expected sum (including the 6)? All I can think of is that the expected value of each roll is $7/2$. I'd appreciate your help!",['probability']
1835194,Frechet derivative of square root on positive elements in some $C^*$-algebra,"Let $A$ - is some unital $C^*$ algebra, and $P$ is set of all strictly positive elements in $A$. We can define map $\sqrt{?} : P \to A$ which takes positive element and returns its (unique) strictly positive square root. How to evaluate its Frechet derivative?","['functional-analysis', 'c-star-algebras', 'frechet-derivative']"
1835220,Theorem regarding Change of Variables in finite dimesnion,"My question is based on Change of Variables in Multiple Integrals II
Peter D. Lax > It is not necessary to read the paper before answering this question.The author tried to prove change of variables formula using elementary method but turns out to be buried in complexity. My question is essentially theorem 2(on this post) To ask my question , I will first state and prove the obvious result in one-dimension: $$\quad \epsilon>0, n>0,x \in R,[a b] \subset R,b>a,y:R->R$$ Theorem 1 : Given any continuously differentiable function $y(x)$  and if $\frac{dy}{dx}>0 $ for $x \in [a, b]$: Then there exists a variable $\varphi_n$, and $\varphi_n(x)$ is continuously differentiable over $\mathbb{R}$ with the following properties: i.  $|\varphi_n(x)-y(x)| \le \epsilon$ for $x \in (a, b)$ ii. $\varphi_n(x)=x$ for sufficiently large $|x|$ iii. $\lim\limits_{n\mapsto 0}\varphi_n(x)=y$ and $\lim\limits_{n\mapsto 0}\frac{d\varphi_n}{dx}=\frac{dy}{dx}>0$ for $x \in (a,  b)$ iv. The mapping $\varphi:x\to R$ is one-to-one, so it is invertible Proof : $r(x)=-{\frac {n}{x^2-a^2}}$ $h(x)=-{\frac {n}{b^2-x^2}}$ $\psi_n(x) =
\begin{cases}
e^{r(x)+h(x)},  & \text{if $a <x< b$ } \\
0, & \text{otherwise}
\end{cases}$ define $\varphi_n=x(1-e^{-nx^2})+\psi_n(x) y(x)+\int_{-\infty}^x2nt(\frac{-1}{(t^2-a^2)^2}+\frac{1}{(b^2-t^2)^2})\psi_n(t)y(t)dt$ it is easily seen $\frac{d\varphi_n}{dx}=(1-e^{-nx^2})+2nx^2e^{-nx^2}+\psi_n(x)\frac{dy}{dx}$ all the terms on the right hand side are greater than zero Taking limits and using inverse function theorem in one dimension, the theorem follows Theorem 2 : $f:\mathbb{R}^N\to\mathbb{R}^N$, $x \in R^N$, $y=f(x)$, $y=[y_1(x), y_2(x),y_3(x),..y_N(x)]$,  $x=[x_1,x_2,\dots,x_N]$, and the the determinant of the Jacobian matrix of $y$ denoted as $\det J$ . Under what conditions can we always find a conitnuously differentiable $\varphi_n: \mathbb{R}^N\to\mathbb{R}^N$ such that: i. $|\varphi_n(x)-y(x)| \le \epsilon$ inside some bounded region A ii. $\varphi_n(x)=x$ for sufficiently large norm $|x|$ iii. $\lim\limits_{n\mapsto 0}\varphi_n(x)=y$ and $\lim\limits_{n\mapsto 0}\det J_n =\det J$ inside some bounded region  and $|\det J_n|>0$ for all $x$,where $\det J_n$ is determinant of Jacobian matrix of $\varphi_n(x)$ ? This is of practical importance because if the above properties are satsified by $\varphi_n$, then according to Hadamard's global inverse function theorem then the mapping $\varphi_n :R^N->R^N$ is  globally bijective.","['multivariable-calculus', 'real-analysis', 'constructive-mathematics']"
1835222,Law of large numbers for moving mean,"Consider the following process: For $n = 1,\ldots$ $U_n \sim U[0, 1]$, that is, uniformly distributed on $[0, 1]$, $X_n = U_n 1_{U_n > q_n}$, where $q_n = \frac{1}{n-1} \sum_{i=1}^{n-1} X_i$, and $q_1 \in [0, 1]$. Hence, $q_n$ is the average of the first $X_i$s. That is, we observe $U_n$ if $U_n$ is bigger than the current running average, and zero otherwise. I want to show that $q_n \to q^*$ (don't really care what mode of convergence), where $q^* = \sqrt{2} - 1$. Why $\sqrt{2} - 1$? If we define $\mu(q) = E(X_n \mid q_n = q)$ (for arbitrary fixed $n$), then it seems clear that $q^*$ must be a fixed point of $\mu$. But $\mu(q) = 0.5(1-q^2)$ which has unique fixed point $\sqrt{2} - 1$ in $[0,1]$. However, what is a nice way to show that the process actually converges to $q^*$? My hunch is that there is a martingale argument for this, but I haven't been able to find it. Another observation is that $q_{n} = q_{n-1} + \frac{1}{n} (x_n - q_{n-1})$ which is a gradient step of minimizing $y$ in $\|y - X_n\|^2_2$ from $q_{n-1}$ with step size $\frac{1}{2n}$. Perhaps there is a nice relation with convergence results on stochastic gradient descent. Any pointers are much appreciated!","['law-of-large-numbers', 'probability-theory', 'martingales']"
1835248,Temperature/heat equation,"I solved this problem
$$\left\{\begin{array}{ll}
u_{t}=ku_{xx}, & x\in(0,1), t>0 \\
u(0,t)=2, u(1,t)=3, & t>0 \\
u(x,0)=x^{2}+x+2, & x\in(0,1)
\end{array}\right.$$
and I got this
$$u(x,t)=2+x+\sum_{n=1}^{\infty} c_{n}e^{-n^{2}\pi^{2}kt}\sin(n\pi x)$$ About this, I had no problem. My questions are (actually, my teacher's questions): 1- After a long time, is there any point in the bar which the temperature is $10^ºC$? If yes or no, why? 2- Can I use the fact that both temperatures in the bar's extremes are less than 10? If not, how could I answer this?","['heat-equation', 'ordinary-differential-equations', 'partial-differential-equations']"
1835269,Why is $\frac{d(x^n)}{d(x)}=nx^{n-1}$,"So I was thinking about what I have learnt and I realised that I kind of took the derivative of a function for granted. So I did some research as I wanted to find out how this was discovered and I stumbled upon this . More specially, here is a passage from it: Without going into too much complicated detail, Newton (and his contemporary Gottfried Leibniz independently) calculated a derivative function $f'(x)$ which gives the slope at any point of a function $f(x)$. This process of calculating the slope or derivative of a curve or function is called differential calculus or differentiation (or, in Newton’s terminology, the “method of fluxions” - he called the instantaneous rate of change at a particular point on a curve the ""fluxion"", and the changing values of x and y the ""fluents""). For instance, the derivative of a straight line of the type $f(x) = 4x$ is just $4$; the derivative of a squared function $f(x) = x^2$ is $2x$; the derivative of cubic function $f(x) = x^3$ is $3x^2$. I was wondering if anyone could explain (or point me to a resource) the ""complicated details"" (or hopefully, a rigorous proof) of how the derivative function $f'(x)$ was discovered?",['derivatives']
1835294,On the definition of free products,"I am a little confused about the definition of free products. Given a collection of groups $\{G_\alpha\}_\alpha$ in order to create their free product, I don't understand what properties these $G_\alpha$ must have. I tell you three different circumstances that I met studying this definition. 1) In some forums and very brief notes I read that I have to consider the disjoint union of the $G_\alpha$ and define a word as a string of elements of this disjoint union. 2) In other the authors pick generic groups and when they want to show that the free product exists, some assume that the groups are pairwise disjoint, others that they have the unity $1$ in common. This confuses me a lot. So from this, isn't writing $\mathbb Z*\mathbb Z$ an abuse of notation? I mean, if I have to consider the free product of two equal groups, as $\mathbb Z*\mathbb Z$, it means that actually what I wrote is a free product of two disjoint groups both isomorphic to $\mathbb Z$? 3) Other books don't mention this problem. They just give the definitions picking generic groups but they don't think to the case where two or more groups are equal. So what is the real definition? Why is there confusion about it?
  Moreover, I can't find a very good reference that treats the union disjoint approach neither that explains how and if these different definitions are equivalent.","['free-product', 'group-theory', 'free-groups']"
1835295,"What is $\gcd(12345,54321)$?","What is $\gcd(12345,54321)$? I noticed that after trying $\gcd(12,21),\gcd(123,321),$ and $\gcd(1234,4321)$ that they are all less then or equal to $3$. That leads me to question if there is an easy way to calculate such greatest common divisors.",['number-theory']
1835310,New series formula for $\arctan(x)$? $\ln(x)$?,"I discovered this equation, but have no idea if it has been previously discovered.  Please help determine if it has been previously developed. Or please prove that the equation is not correct. $$\sum_{n=0}^\infty \frac{x^{2n+1}}{(x^2+1)^{n+1}}\cdot\frac{(2n)!!}{(2n+1)!!}=\arctan(x),$$ for $|x|\leq \pi$ , or possibly all $x$ . Likewise, using the same method for $x> .001$ , or possibly $x > 0$ . $$\sum_{n=1}^\infty \frac{x^{n}-1}{(1+x)^{n}}\cdot\frac{(1)}{(n)}=\ln(x),$$ all follows from $dx/dx =1$ .","['power-series', 'real-analysis', 'sequences-and-series', 'calculus']"
1835313,prove that Doléans-Dade exponential is a local martingale,"I want to prove that $Z_t$ the Doléans-Dade exponential is a local martingale i.e. that there exists a stopping time $\tau_n$ tending to infinity such that the stopping process $\mathbb{1}_{\tau_n>0}Z_{\tau_n}$ is a martingale. I don't know how to start and how to prove the existence of such stopping time ! any hint or help will be appreciated.. thank you for your time :) Doléans-Dade exponential:
$$
Z_t=e^{-\int_0^t\beta_s dW_s-\frac{1}{2}\int_0^t \beta_s^2 ds}
$$ where $W_t$ is a Brownian motion and $\beta_t$ is stochastic process.","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-integrals', 'stochastic-calculus']"
1835346,chances of a group being all of the same sex [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I was wondering, if there are 10 girls and 10 boys in a classroom, and they were randomly assigned in groups of four, what are the chances of there being a group with all people inside it the same sex (all boys, for example?) If possible, give the explanation and the result clearly visible a part from the rest, in percent.
Example, 'there is a 20% chance for 1 group, 5 % for two', etc.","['statistics', 'probability']"
1835360,the uniform convergence of the sequence of functions [duplicate],"This question already has answers here : $f_{n+1}(x):= \int_a ^x f_n(t)dt$, $\sum_{m=1} ^{\infty} f_m(x)$ is uniformly convergent (2 answers) Closed 5 years ago . Let $f_1:[a,b]\rightarrow \mathbb{R}$ be a Riemann integrable function. Define the sequence of functions $f_n:[a,b] \rightarrow \mathbb{R}$ by $f_{n+1}(x)=\int_a^x f_n(t)dt,$ for each $n\ge 1$ and each $x\in [a,b]$. Prove that the sequence of functions $g_n(x)=\sum\limits_{k=1}^n f_k(x)$ converges uniformly on [a,b]. I try to use Ascoli Theorem to prove this problem by considering 
$|g_n(x)-gn(y)|\le\sum\limits_{k=1}^n |f_k(x)-f_k(y)|$. However, $|f_k(x)-f_k(y)|\le M |b-a|^{k-2} |x-y|, $ where $M>0$ is a constant achieving by the condition that $f_1$ is an integrable function. However, this estimation depends on $k$, so I cannot apply Ascoli-Azela Theorem. Thank you in advance for your help.","['real-analysis', 'calculus', 'functional-analysis', 'multivariable-calculus', 'vector-analysis']"
1835364,Notation for minimum,"I'm reading Huber's Robust Statistics right now, and at the beginning of Chapter 3, he writes the following notation: $$\sum \rho(x_i;T_n) = \min!$$ Similarly, a few lines down, he writes: $$\sum \rho(x_i - T_n) = \min!$$ Can someone help me understand what this $\min!$ notation means? Thanks!","['statistics', 'notation', 'robust-statistics']"
1835388,real values of $x$ which satisfy the equation $\sqrt{1+\sqrt{1+\sqrt{1+x}}}=x$,"All real values of $x$ which satisfy the equation $\sqrt{1+\sqrt{1+\sqrt{1+x}}}=x$ $\bf{My\; Try::}$ Here $\sqrt{1+\sqrt{1+\sqrt{1+x}}} = x>0$ Now Let $f(x)=\sqrt{1+x}\;,$ Then equation convert into $f(f(f(x)))=x$ Now Here $f(x)=x$ be one function which satisfy above equation. My question is how can we calculate other function which satisfy above functional equation. Help required, Thanks","['radicals', 'functional-equations', 'calculus', 'algebra-precalculus', 'nested-radicals']"
1835455,Algebraic Geometry Project ideas related to Computer Science,"I am a Computer Science Undergrad student with an interest towards Algebraic Geometry.I have just recently started and am currently reading Miles Reids' Undergraduate Algebraic Geometry(I have read Reid's Undergraduate Commutative Algebra). Apart from ""just reading"" up some texts, I want to do a specific project related to both computer science and algebraic geometry. By project , I mean something like a specific problem related to CS which can be solved by algebraic geometric methods or a programming exercise (an example would be a Sudoku-Solver using Grobner Basis).
I am not very interested in implementing a particular algorithm (say, Buchberger's Algorithm) and would rather build an application which uses it. I have seen a few ideas in the appendix to David Cox's Ideals,Varieties and Algorithms but I am not very satisfied. Any ideas would be extremely helpful.","['soft-question', 'algebraic-geometry']"
1835495,Definition of cotangent and conormal bundle,"I have read the following definition of cotangent bundle: Let $X$ be a $n$-dimensional smooth algebraic variety. For any $p\in X$ there exist a neighbourhood $U_{p}\subseteq X$ and functions (named local parameters) $u_{1},\ldots,u_{n}\in \mathcal{O}_{X}(U_{p})$ such that 
  $$
\mathfrak{M}_{q}=\langle u_{1}-u_{1}(q),\ldots,u_{n}-u_{n}(q)\rangle
$$
   for every $q\in U_{p}$, where $\mathfrak{M}_{q}$ is the maximal ideal of the local ring $\mathcal{O}_{X,q}$. Associating to each open subset $U_{p}$ the module $\Omega_{S/R}$ of relative differential forms of $S=\langle u_{1},\ldots,u_{n}\rangle$ over $R=\mathcal{O}_{X}(U_{p})$, gives rise to a locally free coherent sheaf. We define the cotangent bundle to be the associated vector bundle $\Omega_{X}$. Now, suppose we have a closed immersion $Y\subset X$. We can find an open cover $X=\bigcup_{i\in I}U_{i}$ such that on each $U_{i}$, the closed subscheme $Y\cap U_{i}$ can be described as the zero locus of $r:=\mathrm{codim}(Y,X)$ regular functions $f_{1},\ldots,f_{r}\in\mathcal{O}_{X}(U_{i})$. The conormal bundle $\mathcal{N}^{*}_{Y/X}$ of $Y$ in $X$ is defined to be the kernel of the surjective morphism
$$
\Omega_{X}|_{Y}\rightarrow \Omega_{Y}
$$
induced by the restriction of differentials. My problem is that I don't understand this morphism and therefore I don't understand the definition of conormal bundle. What does ""restriction of differentials"" mean? Any help (or correction in case I was misunderstanding something) would be appreciated.","['vector-bundles', 'algebraic-geometry']"
1835506,sum of series using mean value theorem,"Let $f(x)$ be a function which is differentiable on $[0,1]$ with $f(0)=0$ and $f(1)=1$.
Show that for every $n\in \Bbb N$ there exists numbers $x_1,x_2,\ldots,x_n\in [0,1]$ such as
$$
 \sum_{k = 1}^n \frac{1}{f' (x_k)} = n
$$
I think the mean value theorem should be applied.
So there exists $x_1$ in $[0,1]$  such that $f ' (x_1) = \frac{f(1) - f(0)}{1-0} =1$  and there exists $x_2$ in $[0,x_1]$ such that $f ' (x_2) = \frac{f(x1) - f(0)}{x1-0} = \frac{f(x1)}{x1}$, so on and so forth for $x_3 ,x_4, \ldots,x_n$ and we have the sum $$1+\frac{x_1}{f(x1)} + \frac{x_2}{f(x2)} +\cdots+\frac{x_{n-1}}{f(x_{n-1})}$$  and from here I have no idea what to do .
I was wondering if anyone could be so kind to help ?","['calculus', 'analysis']"
1835511,Norm of convolution,"Let $f,g: \mathbb{R}^n \to \mathbb R$ . Let $\Vert \cdot \Vert_T$ be a translation invariant norm on functions on $\mathbb{R}^n$ . How can I prove that $\Vert f*g\Vert _T \leq \Vert f\Vert _1 \Vert g\Vert _T$ (where $f*g$ means convolution and $\Vert  \cdot \Vert _1$ means $L^1$ norm). I suppose I should specify the class of functions $f,g$ are of, but just take them to be functions such that the norms are well defined. In fact I will settle for a formal proof of the inequality. Any help is appreciated!","['functional-analysis', 'normed-spaces', 'convolution']"
1835628,Maximal ideals in the ring of measurable functions,"The $R$ ring of continuous functions from $[0,1]$ to $\mathbb{R}$ has a property that its maximal  look like a subset of $R$ consisting of those functions which vanish at a common single point in $[0,1]$. Question: Let $S$ be the ring of all the measurable functions from $[0,1]$ to $\mathbb{R}$. How maximal ideals look like in this ring?","['abstract-algebra', 'ring-theory', 'measure-theory']"
1835654,Proof by contradidction that the mean of a set cannot be greater than the greatest value in that set.,"I want to prove that given a set of values $x_1, x_2, ..., x_n$, the mean of those values cannot be greater than the greatest of those values. Let the mean $\frac{x_1 + x_2 +... + x_n}{n} = a$ Assume that $a > x_1, x_2, ..., x_n$ and let $x_1 + x_2 +... + x_n = b$ Then $b < a \cdot n$ Therefore $\frac{b}{n} < \frac{a \cdot n}{n}$, so that $\frac{b}{n} < a$ But since by definition $\frac{b}{n} = a$, this is a contradction. QED(?)","['means', 'statistics', 'proof-verification']"
1835666,Is it justifiable to call the probability mass function by the name “discrete probability density function”?,"Commonly, the probability density function (PDF) is used when dealing with continuous random variables, while the probability mass function (PMF) is used for discrete random variables. This is the reason they are called “density function” and “mass function” respectively. However, my professor would talk about a “continuous PDF” and a “discrete PDF”, instead of a PDF and PMF. It seems that my professor is not the only one to use the term “discrete probability density function”. It is also used in these UBC lecture notes . Is it correct to call the probability mass function by the name “discrete probability density function”?","['density-function', 'probability-theory', 'terminology', 'probability', 'random-variables']"
1835697,Does the commutator group of $S_n$ equal $A_n$ in general?,"And how would one deduce this? $[S_n, S_n]$ consists of even permutations so it's obvious  that $[S_n, S_n] \leq A_n$, but is $[S_n, S_n] = A_n$ true as well? If so, how to deduce this? If not, how do we show that it's true for particular cases like $S_6$? I can only show that it's a subgroup.","['abstract-algebra', 'group-theory', 'symmetric-groups']"
1835733,Bounding a series: $\frac{\pi}{2} < \sum_{n=0}^\infty \frac{1}{n^2 + 1} < \frac{3\pi}{2} $ [duplicate],"This question already has answers here : Prove This Inequality ${\pi \over 2} \le \sum_{n=0}^{\infty} {1 \over {1+n^2}} \le {\pi \over 2} + 1$ (5 answers) Closed 4 years ago . I have the following statement - $$\frac{\pi}{2} <  \sum_{n=0}^\infty \dfrac{1}{n^2 + 1} < \frac{3\pi}{2} $$ So I tried to prove this statement using the integral test and successfully proved the lower bound. But when I tried to calculate the upper bound I was required to calculate the integral from -1 - $\int_{-1}^{\infty} \frac{1}{x^2 +1}\,dx$.
If someone can explain why it will be great , thanks!","['inequality', 'integration', 'sequences-and-series', 'calculus']"
1835770,"I want to show that, ${\Phi\tan{9^\circ}-\phi\tan{27^\circ}\over \sin^2{9^\circ}-\sin^2{27^\circ}}=4$","$\phi$: golden ratio, $\Phi={1\over \phi}$ I want to show that, $${\Phi\tan{9^\circ}-\phi\tan{27^\circ}\over \sin^2{9^\circ}-\sin^2{27^\circ}}=4$$ Using $\sin^2{x}={1\over 2}(1-\cos{2x})$ $${\Phi\tan{9^o}-\phi\tan{27^o}\over \cos{54^\circ}-\cos{18^\circ}}=2$$ As for numerator $${\sqrt5(\tan{27^\circ}-\tan{9^\circ})-\tan{27^\circ}-\tan{9^\circ}\over \cos{54^\circ}-\cos{18^\circ}}=4$$ exact trig values if I was to plug in the corresponding values it would be a lot of work to simply and might not even get to the result. Any idea would help me to simplify the LHS?",['trigonometry']
1835806,Why is the CLT stated like it is?,"The CLT says that given finite variance of iid RVs, we have 
$$\sqrt{n}( \bar{X} - \mu) \rightarrow \mathcal{N}(0,\sigma^2),$$
but if this is true, then $\bar{X} - \mu$ should converge to $\mathcal{N}(0,\sigma^2 /n)$, right? And if this is true, then $\bar{X}$ should converge to $\mathcal{N}(\mu, \sigma^2/n)$, right? My questions are: are above two statements true (i.e, can we just multiply and subtract constants like we'd normally do with a normal distribution), and if so, why isn't the latter $\left( \bar{X} \rightarrow \mathcal{N}(\mu, \sigma^2/n) \right) $statement the way we state the CLT which seems much more intuitive, since it clearly says that the mean of our RVs are almost normally distributed with the proper mean and a diminishing variance, while it's not immediately obvious what the other statement is on about?","['probability-theory', 'asymptotics', 'statistics']"
1835836,Integration with respect to a Poisson random measure,"Let $N$ be a Poisson random measure (PRM) on a Polish space, $\left(X,\mathcal{B}(X)\right)$,
and let $\tilde{\nu}$ be its mean measure. Then, let $f$ be any non
negative and bounded function on $X$. The following are equivalent:
$$
1. \int_{X}f(x)N(dx)<+\infty,\ a.s.;
$$ $$
2. \int_{X}\left(1-e^{-f(x)}\right)\tilde{\nu}(dx)<+\infty;
$$ $$
3. \int_{X}\min\left\{ \left|f(x)\right|,1\right\} \tilde{\nu}(dx)<+\infty.
$$
Why is it so?","['stochastic-analysis', 'point-processes', 'probability-theory', 'levy-processes']"
1835849,Every family $\mathscr{A} $ of sets satisfies $|\mathscr{A} \setminus \mathscr{A}| \geq |\mathscr{A}|$,"Let $\mathscr{A} $ be a set of sets. Let's denote $\{A 
\setminus B : A,B \in \mathscr{A}\}$ by $\mathscr{A} \setminus \mathscr{A} $. The Marica-Schönheim theorem in combinatorics says that $|\mathscr{A} \setminus \mathscr{A}| \geq |\mathscr{A}|$ for every finite $\mathscr{A}$. This immediately implies the result for countably-infinite $\mathscr{A}$, since if we had $|\mathscr{A} \setminus \mathscr{A}|=n $ is finite, then taking a subset of size $n+1$ out of $\mathscr{A}$ gives a contradiction. There seems to be no natural one-to-one mapping $\mathscr{A} \to \mathscr{A} \setminus \mathscr{A} $, so this raises the question: Do we have $|\mathscr{A} \setminus \mathscr{A}| \geq |\mathscr{A}|$ for families $\mathscr{A}$ of arbitrary cardinality?","['elementary-set-theory', 'infinitary-combinatorics']"
1835871,Is there a prime of the form $11^k+k^{11}\ $?,"Is there a natural number $k\ge 1$, such that $11^k+k^{11}$ is prime ? I checked the numbers upto $k=3000$ and did not find a prime number.
On the other hand, for $k=76$ and for $k=142$, there is no small prime factor ( http://factordb.com/index.php?query=11%5En%2Bn%5E11&use=n&n=1&sent=Show&VP=on&VC=on&EV=on&FF=on&perpage=200&format=1 ) I cannot find a reason that $11^k+k^{11}$ must be composite for every $k\ge 2$ , for example because we can show that algebraic or aurifeuillian factors must exist.","['number-theory', 'prime-numbers']"
1835892,Are compact sets on $\mathbb R^n$ always connected?,I am unsure if compact sets on $\mathbb R^n$ are always connected. Can someone explain it to me?,"['general-topology', 'analysis']"
1835951,"In how many ways can an inspector visit $4$ normal sites and $1$ ""suspicious"" one?","I cannot figure out why my answer to the following question is wrong: Suppose that a weapons inspector must inspect each of five different sites twice, visiting one site per day. The inspector is free to select the order in which he visits these sites, but cannot visit site $X$, the most suspicious site, on two consecutive days. In how many ways can the inspector visit these sites? The set of sites is $$S=\{a, a, b, b, c, c, d, d, X, X \}$$ The set of sites where the inspector visits $X$ on consecutive days is 
$$R=\{a, a, b, b, c, c, d, d, (X, X) \}$$ My idea is to do $$\text{number of distinguishable permutations of S}-\text{number of distinguishable permutations of R}$$ $$\dfrac {10!}{2! \cdot 2! \cdot 2! \cdot 2!\cdot 2!}-\dfrac {9!}{2! \cdot 2! \cdot 2! \cdot 2! \cdot 1!}$$ However, the right answer is $90,720$. Any help is appreciated!","['permutations', 'combinatorics', 'discrete-mathematics']"
1835975,The number of partitions of $n$.......Subbarao,"(Subbarao) The number of partitions of $n$ in which each part appears 
two, three, or five times equals the number of partitions of $n$ into parts 
congruent to $2, 3, 6, 9,$ or $10$ modulo $12$. Someone please give a Hint(direction) to the problem....to start with .","['combinatorics', 'integer-partitions', 'discrete-mathematics']"
1835992,Neural Network - Why use Derivative,"Good Day I am trying to get an understanding of Neural Network. Have gone through few web sites. Came to know the following: 1)  One of main objective of neural network is to “predict” based on data.
2)  To predict
a.  Train the network with known data 
b.  Calculate weights by finding difference between “Target Output” and “Calculated Output”.
c.  To do that we use derivative, partial derivative(chain rule etc..) I can understand the overall concept of neural network 
a)  I can also understand “Derivative” is nothing but Rate of change of one quantity over another(at a given point).
b)  Partial derivative is Rate of change of one quantity over another, irrespective of another quantity , if more than two factors are in equation. The point that I canNOT relate or understand clearly is,
a)  why should we use derivative in neural network, how exactly does it help
b)  Why should we activation function, in most cases its Sigmoid function.
c)  I could not get a complete picture of how derivatives helps neural network. Can you guys please help me understand the complete picture, iff possible try not to use mathematical terms, so that it will be easy for me to grasp. Thanks,
Satheesh","['derivatives', 'neural-networks']"
1836008,The diameter of a convex hull.,"I want to prove the following statement: Given $A\subset \mathbb{R}^n$ let $C(A)$ be its convex hull. Prove that $\text{diam }(A)=\text{diam }(C(A))$. I can suppose that $A$ is a bounded closed set and I know that if $x,y\in A$ are such that $d(x,y)=\text{diam }(A)$ then $x,y\in \partial A$. I tried proving that if $z,w\in \partial C(A)$ then $d(z,w)\leq d(x,y)$ but it is a little difficult to me using the fact $C(A)$ is the convex hull. Any hint?","['convex-hulls', 'geometry']"
1836028,Proving the Well-Ordering Principle for Natural Numbers,"I know the WOP is treated like axiom of a natural number, but I was curious if I can prove WOP defined for the set of natural numbers N by following: Suppose A is a subset of N, which then obeys all axioms from Peano postulates, and let us assume that A does not have a least element.  Then, 1 in A must be a successor to another natural number, which is 0.  However, 0 is neither in A nor N.  (If 0 is in N, then we argue that 0 must be a successor to -1, which is not part of N).  Also, 1 in A being a successor contradicts with the Peano axiom (1 cannot be a successor).  Hence, our assumption that A having no least element is not true.  Therefore, A has a least element.  Without out loss o generality, every subset of the N has a least element. I understand this is silly proof, but I wanted to make sure that I have reasoning for WOP in N before moving on.","['number-theory', 'analysis']"
1836035,"On ""good"" numbers and $m \times n$ real matrices","Let $m,n > 1$ be odd integers. Different real numbers are written in the cells of the $m \times n$ table ($m$ rows and $n$ columns). The number is called ""good"" if 1) It is the largest in its row (column). 2) It is the median value in his column (row). What is the largest possible number of ""good numbers"" ? My work so far: I solved the problem for table $3\times3$: \begin{bmatrix}
1 & 7 & 9 \\
2 & 6 & 4 \\
5 & 3 & 8 
\end{bmatrix} $5,6,7,8 -$ ""good numbers"" . If $m>3$ or $n>3 -$ I need help here.","['combinatorics', 'integers', 'elementary-number-theory']"
1836057,Complicated Laplace Transform,"I have found the following Laplace Transform in a list $$\int\limits_0^{\infty}e^{-st}\frac{e^{-u^2/4t}}{\sqrt{\pi t}}dt = \frac{e^{-u\sqrt{s}}}{\sqrt{s}}.$$ I am wondering how to prove this? I tried to do some substitutions for the integral, but nothing worked. Can someone explain it to me? I appreciate any help!","['substitution', 'integration', 'laplace-transform']"
1836066,Show that an integer matrix with following conditions is the identity $I$,"every entries of $A$ is integer every entries of $A-I$ is multiple of a prime $p$ ($p\geq3$) there exists $n\ge1$ such that $A^n=I$ show that $A=I$ I tried $A=I+p^kB$ where not every entries of $B$ is multiple of $p$. then $(I+p^kB)^n=I+np^kB+{n(n-1)\over2}p^{2k}B^2+...+p^{nk}B^n $
but how should I proceed? thanks in advance","['algebra-precalculus', 'linear-algebra', 'elementary-number-theory']"
