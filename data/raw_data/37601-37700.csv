question_id,title,body,tags
364765,$x_n$ is the $n$'th positive solution to $x=\tan(x)$. Find $\lim_{n\to\infty}\left(x_n-x_{n-1}\right)$,$x_n$ is the $n$'th positive solution to $x=\tan(x)$. Find $\lim_{n\to\infty}\left(x_n-x_{n-1}\right)$.,"['sequences-and-series', 'calculus', 'trigonometry', 'analysis', 'limits']"
364775,Bijection for algebraic numbers,"Is there a bijective function $f(n)$, where $n \in \mathbb{N}$, which enumerates all algebraic numbers? Is it possible to define such function?","['cardinals', 'elementary-set-theory', 'functions']"
364782,What is duality?,"I have seen some examples of duality. Sometimes applied to theorems, as for example Desargues theorem and Pappus theorem. Sometimes applied to spaces, for example the dual space of a vector space. Sometimes even applied to a method like simplex and dual simplex methods in linear programming. My question is what is the general meaning behind the term duality and what is its relevance to mathematics. Do we mean the same always when we use the term? Or the examples I have put have no connection whatsoever? Thanks a lot","['geometry', 'linear-algebra', 'duality-theorems', 'intuition']"
364805,How to prove that $\|AB-B^{-1}A^{-1}\|_F\geq\|AB-I\|_F$ when $A$ and $B$ are symmetric positive definite?,Let $A$ and $B$ be two symmetric positive definite $n \times n$ matrices. Prove or disprove that $$\|AB-B^{-1}A^{-1}\|_F\geq\|AB-I\|_F$$ where $\|\cdot\|_F$ denotes Frobenius norm. I believe it is true but I have no clue how to prove it. Thanks for your help.,"['matrices', 'linear-algebra', 'inequality']"
364828,Relation between noncommutative geometry and functional analysis,"Recently I came across the subject of noncommutative geometry via my interest in functional analysis. My very little exposure to this subject gives me a sense that part of it is built on the theory of operator algebras and that together with many other tools/techniques are used to study geometric or topological problems. I couldn't help but ask (perhaps naively) whether things can go the other way, i.e. using tools in noncommutative geometry to study operator algebras (or even other objects that one would associate to functional analysis, such as operator spaces etc.). If anyone knows of such an approach, I would appreciate some descriptions or references.","['operator-theory', 'operator-algebras', 'functional-analysis', 'noncommutative-geometry']"
364848,Convergence of sum of random variables,"Let $X_n$, $n\geq 0$, be i.i.d. random variables such that: $\mathbb E(X_1)=0$, and $0<\mathbb E(|X_1|^2)<\infty$. Given that $\alpha >\frac{1}{2}$, I need to show that $$S_n=\sum_{k=1}^{n}\frac{X_k}{k^\alpha}$$ Converges almost surely. Can I have a hint for how to do this? To show that $$S_n=\sum_{k=1}^{n}\frac{X_k}{k^\alpha}$$ converges, we use Kolmogorov's Three Series Theorem, which implies that we have to show three conditions are satisfied: a.) For some $A>0$,  $\displaystyle \sum_{k=1}^{\infty}\mathbb P\left(\left|\frac{X_k}{k^{\alpha}}\right|\geq A\right)$ converges b.) Let $\displaystyle Y_{k}:=\frac{X_k}{k^{\alpha}}1_{\{\left|\frac{X_{k}}{k^{\alpha}}\right|\leq A\}}$, Then $\displaystyle \sum_{k=1}^{\infty}\mathbb E[Y_{k}]$ converges; c.) $\displaystyle \sum_{k=1}^{\infty}\mathrm{Var}(Y_{k})$ converges.","['probability-theory', 'convergence-divergence', 'random-variables']"
364908,Heuristics for the Yamabe Problem,"I am trying to understand the Yamabe problem, and I was naturally lead to a question: given a manifold with a Riemannian metric on it, why is it interesting to find a conformally related metric that has constant scalar curvature? Do you know any situation in which this is applied? Could you give me any reference in which some heuristics are explained? I think a good understanding of the 2-dimensional case would be enough...","['reference-request', 'differential-geometry']"
364923,"Evaluate $ \int^{\frac{\pi}{2}}_0 \frac{\sin x}{\sin x+\cos x}\,dx $ using substitution $t=\frac{\pi}{2}-x$","This problem is given on a sample test for my calculus two class. $$ \int^{\frac{\pi}{2}}_0 \frac{\sin x}{\sin x+\cos x}\,dx $$ I can find the value of this integral using other substitutions which lead to partial fractions but the prof added a hint to use the substitution $$t=\frac{\pi}{2}-x $$ so I've been trying to figure out how to do it his way but am pretty lost. Any ideas?","['calculus', 'integration']"
364947,Algebraic description of a stalk in the fppf topology,"Let $X$ be a scheme and $x\in X$ a point. The stalk of $X$ at $x$ in the Zariski topology is the local ring $\mathcal{O}_{X,x}$. The stalk of $X$ at $x$ in the étale topology is the strict henselization $\mathcal{O}_{X,x}^{sh}$ of the local ring $\mathcal{O}_{X,x}$ ( Wikipedia ). What is an algebraic description of the stalk of $X$ at $x$ in the fppf topology ? To define algebraic description I can only say what it's not. It shouldn't mean something like: ''the stalk of $X$ at $x$ in the fppf topology is the direct limit of the sections of the structure sheaf over all the fppf neighborhoods of $x$''. Probably the question could be rephrased as: ''How can I compute the  stalk of $X$ at $x$ in the fppf topology?''","['commutative-algebra', 'algebraic-geometry']"
364976,"Inverse of a matrix exponential, ${(e^{At})}^{-1} = {e^{-At}}$","Consider the matrix exponential
$$
e^{At} = \frac{1}{4}
\begin{bmatrix}
      -e^{-t} + 5e^{3t} &  e^{-t} - e^{3t} \\
     -5e^{-t} + 5e^{3t} & 5e^{-t} - e^{3t}
  \end{bmatrix}
$$ And
$$
{(e^{At})}^{-1} =  {e^{-At}}
$$ What does that identity mean?  Can I just multiply the exponent by $-1$ to find  $e^{-At}$?","['matrices', 'exponential-function', 'matrix-exponential']"
364980,Show that the identity matrix $I$ must have norm $1$.,"I am trying to understand why the identity matrix $I$ must have a norm $1$, for any choice of matrix-norm $|\cdot|$?  How would i show this?",['matrices']
364981,Solving linear system of differential equations of 2nd order,"I need to solve the following system of differential equations: $$ \ddot{x} = 8x + 4y \\
\ddot{y} = -4x$$ Here's what I've done so far: I have reduced this system to a first order system, by saying $x_1 := x, \ x_2 := \dot{x}, \ x_3 := y, \ x_4 := \dot{y}$. This yields the system $\dot{X} = A \cdot X$ with $$ A = \begin{pmatrix} 0 & 1 & 0 & 0\\ 8 & 0 & 4 &0\\0 & 0 & 0 &1\\ -4 & 0 & 0 &0\end{pmatrix} \ \ \ X = \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\x_4 \end{pmatrix}$$ Then I've determined the eigenvalues $\lambda_1 = 2, \ \lambda_2 = -2$, with the corresponding eigenvectors $v_1 = \begin{pmatrix}1 & 2 & -1 & -2\end{pmatrix}^{T}$ and $v_2 = \begin{pmatrix}1 & -2 & -1 & 2\end{pmatrix}^{T}$. Now what I'm struggling with is: how do I determine my set of fundamental solutions? I know that the terms $c_1e^{2t}$ and $c_2e^{-2t}$ are part of it for sure, but since I have two double eigenvalues, I also should have a solution somewhat like $te^{2t}$ resp. $te^{-2t}$. But I just don't see how they alle come together.","['ordinary-differential-equations', 'calculus']"
364986,Probability of getting exactly 2 heads in 3 coins tossed with order not important?,"I have been thinking of this problem for the post 3-4 hours, I have come up with this problem it is not a home work exercise Let's say I have 3 coins and I toss them, Here order is not important so possible sample space should be 0 H, 1 H, 2 HH, 3 HHH (H being heads)
  TTT, HTT, HHT, HHH since P(T) and P(H) =1/2; Here we have fair coins only, Since each and every outcome is equally likely, answer should be 1/4 (is this correct) and if that is correct, all of the probabilities don't add up to one, will I have to do the manipulation to make it add up to one, or I am doing anything wrong. EDIT In my opinion, with order being not important, there should be only 4 possible outcomes. All of the answers have ignored that condition.",['probability']
365005,How do I sell out with abstract algebra?,"My plan as an undergraduate was unequivocally to be a pure mathematician, working as an algebraist as a bigshot professor at a bigshot university.  I'm graduating this month, and I didn't get into where I expected to get into.  My letters were great and I'm published, but my GRE was bad and my grades were good but not perfect.  My current plan, I guess, is to start a PhD program at my backup school, and then reapply to the better schools next year. Reality is starting to hit, though, and I'm starting to think about ""selling out.""   I would still love to work in algebra, but I'm not as in love with the Ivory Tower as I was a few years ago, and I don't want to give up my entire life for it.  If the institution isn't going to let me do what I wanted to do, or if I'll never be as talented as I wanted to be, it isn't worth the sacrifice.  In other words, I'd rather be a well-paid applied mathematician in industry than a poor, mediocre pure mathematician at a low-end university. The problem is it seems that most of the applied jobs out there are all about analysis / continuous mathematics, and I am firmly in the algebra / discrete camp. I really do not want to spend my life-solving fluid flow PDEs. I always hear about cryptography as an ""applied algebra"" job, but I'm not particularly crazy about working for the NSA or a telecom (plus crypto can't be the only option). I read some of the answers from Can I use my powers for good? but it's not clear to me which of these suggestions value algebraic thinking.  Many seem very quantitative , rather than structural - is it possible to avoid this in the industry?  Also, I have a lot of debt from a long undergraduate career across several majors, so ""how much"" is unfortunately also a concern.  I don't want to sell out cheap. Are there applied math jobs in industry which focus on structural mathematics reminiscent of abstract algebra, earn an appreciably high salary, and aren't cryptography? How would one best go about pursuing these jobs starting as a recent graduate / first-year graduate student?","['applications', 'abstract-algebra', 'career-development', 'soft-question', 'advice']"
365010,Writing a series using Sigma notation,"How do I write $$2+ \frac{3x}{2} + \frac{4x^2}{4}+\frac{5x^3}{8}+\frac{6x^4}{16}?$$ I have been struggling with these types of problems, so please, an explanation of how to get the result will be appreciated.",['algebra-precalculus']
365029,Intuitive proofs that $\lim\limits_{n\to\infty}\left(1+\frac xn\right)^n=e^x$,"At this link someone asked how to prove rigorously that
$$
\lim_{n\to\infty}\left(1+\frac xn\right)^n = e^x.
$$ What good intuitive arguments exist for this statement? Later edit: . . . where $e$ is defined as the base of an exponential function equal to its own derivative. I will post my own answer, but that shouldn't deter anyone else from posting one as well.","['exponential-function', 'calculus', 'real-analysis']"
365033,Explain why $U_{44} \cong (\mathbb{Z}_{10} \oplus \mathbb{Z}_2) $.,"Explain why $\newcommand{\Z}{\mathbb{Z}} U_{44} \cong (\Z_{10} \oplus \Z_2) $ I know that $\Z_{20} \cong (\Z_{10} \oplus \Z_2)$, so if I can show $U_{44}   \cong \Z_{20}$, then I can conclude that $U_{44} \cong (\Z_{10} \oplus \Z_2) $ since isomorphism is transitive. In order to show $U_{44} \cong \Z_{20}$, I need to show that the function $ \varphi: U_{44} \to \Z_{20}$ is bijective and structure preserved.  I know that $U_{44} \text{ and } \Z_{20}$ have order $20$, so the function can be bijective, but it's not enough to show $\varphi: U_{44} \to \Z_{20} $ is bijective. I wonder if anyone can show me how to show $ \varphi: U_{44} \to \Z_{20} $ is bijective and structure preserving.","['group-isomorphism', 'finite-groups', 'group-theory', 'abstract-algebra']"
365054,What is a general solution to a differential equation?,"I understand how to find the general solution of a differential equation, for complex roots, simple roots, nonhomogeneous equations etc... but I still don't really know what the general solution is? As in, what is the purpose of it? What is it used for? thanks...",['ordinary-differential-equations']
365058,simple application of Bezout's Theorem,"Let $f(x),g(x) \in \mathbb{C}[x_1,\cdots,x_n]$ be two irreducible homogeneous polynomials of degree $n,m$ respectively. Does Bezout's Theorem say that the system of equations $f(x)=0, g(x)=0$ has precisely $m \cdot n$ solutions? Now let $y(y_1,\cdots,y_n)$ be a new set of indeterminates. Then $f(x+y),g(x+y)$ are still homogeneous of degree $m,n$ respectively, albeit they lie in the rings $\mathbb{C}[x_1,\cdots,x_n,y_1,\cdots,y_n]$. Does Bezout's Theorem say that the system of equations $f(x+y)=0, g(x+y)=0$ has still $m \cdot n$ solutions?","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
365064,Dice throwing probability of three different faces.,A standard six side die is rolled three times. Find the chance that three different faces appear? My thoughts: Probability p(same face pops up is)= $1- P$. You roll first one and record what you get. The probability of next (2) two rolls give you same face is...? My chances of rolling any given face is $1/6$. It does not matter what you get first role the next two rows have to the same as the first one role. Therefore$= (1-(1/6)^2)= 1-(1/6^2)=1-(1/36)$,['probability']
365069,"An exercise on cyclic extensions of Hungerford's book, Algebra.","I'm trying to show the following exercise of the book, it is in the section of cyclic extensions and says the following: Let $\overline{\mathbb Q}$ be a fixed algebraic closure of $\mathbb Q$, let $v\in\overline{\mathbb Q}-\mathbb Q$ and let $E\subseteq\overline{\mathbb Q}$ be a subfield maximal with respect to the property $v\notin E$. Prove that every finite dimensional extension of $E$ is cyclic. Well, this is my attempt of proof: First I prove that one can restrict himself to a finite Galois extensions. Then I prove that $E(v)$ is a Galois extension of $E$, by noting that for every $\sigma\in Aut_E E(v)$, $\sigma(v)\notin E$; and that $E(v)$ is a cyclic extension of $E$, because the absence of intermediate fields and applying the fundamental theorem of Galois theory . Next, I intend to proceed inductively in $n=[F:E]$ with the case $n=1$ being trivial: suppose that the proposition is true for every $m\leq r$, and that $r+1=[F:E]$; consider the intermediate field $E\subseteq E(v)\subseteq F$, if $E(v)=F$ the proposition has already been proven. If not then $[F:E(v)]\leq r$, and we have that $F$ is Galois over $E(v)$ (fundamental theorem), therefore the induction hypothesis shows that $Aut_{E(v)}F$ is cyclic. The fact that $E(v)$ is Galois over $E$ implies that $Aut_{E(v)}F$ is normal in $Aut_E F$ and again by the fundamental theorem $Aut_E E(v)=Aut_E F/Aut_{E(v)}F$. At this point I had been thinking about a proposition of the form ""If a finite group G contains a normal cyclic subgroup such that the quotient $G/N$ is also cyclic then G is cyclic""; which is false, even if one replace normal cyclic, for maximal normal cyclic, and things like this. I don't know what to do at this stage, I would be very grateful for a solution that follows this path. Thanks in advance.","['galois-theory', 'abstract-algebra', 'field-theory']"
365074,How do I append an integer to the left of another integer?,"For example: . is my append operator f(x,y)    = |x| . |y|
f(1,45)   = 145
f(233,10) = 23310
f(8,2)    = 82
f(0,1)    = 1 This is a trivially easy problem to solve in programming using string concatenation. However, I can't seem to think of a good way to do this using purely arithmetic operations.","['arithmetic', 'elementary-number-theory', 'number-theory']"
365155,Showing that no Hamilton Circuit exists,"I was confused about a certain concept and I was wondering if I could get some help. There were three points that were made in my textbook to show that a graph does not contain a Hamilton circuit: A graph with a vertex of degree one cannot have a Hamilton circuit. Moreover, if a vertex in the graph has degree two, then both edges that are incident with this vertex must be part of any Hamilton circuit. A Hamilton circuit cannot contain a smaller circuit within it. I understand 1 and 3, but I'm a bit confused about 2. I wasn't really sure how this helps. I realize that the definition of a Hamilton circuit is a simple circuit in a graph that traverses over all vertices in the graph. But this is exactly what we are trying to disprove, so how is it helpful to say that both edges must be part of a Hamilton circuit when we don't even know if the graph contains a Hamilton circuit? How is that not circular? Hopefully you can understand my confused, sleep deprived thought process. If you can't, could somebody at least elaborate on the significance of number 2? Thanks for the help.","['graph-theory', 'discrete-mathematics', 'hamiltonicity']"
365161,What do angle brackets ($\langle\rangle$ ) mean in mathematics/statistics (autocorrelations)?,"Okay, so the logarithmic return on a stock is given by: $$r_τ (t) = \ln P(t+τ) - \ln P(t),$$ where τ is the interval of time. I have no problem calculating that. My question comes to the following formula: $$ρ(T) \sim 〈r_τ (t+T) \cdot r_τ (t)〉$$ This is supposedly the autocorrelation function of log-returns. What's the deal with the brackets?","['statistics', 'correlation', 'notation']"
365166,"Combinatorial Proof: $ n\binom {n-1}{k-1} = k \binom nk$ , where $n$ is a positive integer and $k$ is an integer.","I have trouble coming up with combinatorial proofs. How would you justify this equality? $$
n\binom {n-1}{k-1} = k \binom nk
$$ where $n$ is a positive integer and $k$ is an integer.","['combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
365234,Embedding of $SO(3)$ into $S_{\infty}$,This is a nice question which I don't have any clue. Let $S_{\infty}$ be the group of all permutations of $\mathbb{N}.$ Is it possible to embed $SO(3)$ into $S_{\infty}?$,['group-theory']
365237,Does the sequence converges?,"I am trying to prove if the sequence $a_n=(\root n\of e-1)\cdot n$ is convergent.  I know that the sequences $x_n=(1+1/n)^n$ and $y_n=(1+1/n)^{n+1}$ tends to the same limit which is $e$. Can anyone prove if the above sequence $a_n$ is convergent? and if so, find the limit. My trial was to write $a_n$ as $a_n=n(e^{1/n}-1)$ and taking $1/n=m$ so that $a_n=\frac{1}{m}(e^m-1)$ and taking the limit $\lim_{x\to 0^+}\frac{e^x-1}{x}$, but I don't know how to continue. Thanks to every one who solve this for me.",['analysis']
365251,How to construct a Riemann surface for the inverse of $k(z)=z+1/z$,"The following is (a rephrasing of) problem 2, in Chapter 10 of Greene and Krantz's Function Theory of One Complex Variable: Construct Riemann surfaces for the (local) ""inverse functions"" of
  $$k(z)=z + \frac{1}{z}.$$ I think I understand the construction for $\log$, and for $z^n$. What would be a generic method for constructing such surfaces, and how, in particular, to construct the specific one in the question above ?","['riemann-surfaces', 'complex-analysis']"
365261,Question on groups of order $pq$,"Let $G$ be a group of order $pq$ , $p>q$ and $p$ , $q$ are primes. Then prove that If $q\mid p-1$ then there exists a non abelian group of order $pq$ . Any two non-abelian groups of order $pq$ are isomorphic. I have proved that if $q\not\mid p-1$ then $G$ is cylic . But how to prove this one I have no idea.
Any kind of hint is very much welcome. This problem is in Herstein book, page 75.","['finite-groups', 'group-theory', 'abstract-algebra']"
365286,The graphs in which radius is equal to diameter,"I was working out on a problem. Came out with a result in $C_n$: radius = diam. Worked out on other few graphs where radius=diam. Can we generalize the result? A little hint will be helpful. The examples on which I worked out, turned out to be regular too. Thanks","['graph-theory', 'computer-science', 'discrete-mathematics', 'combinatorics']"
365310,Conditional expectation on more than one sigma-algebra,"I'm facing the following issue. Let $X$ be an integrable random variable on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ and $\mathcal{G},\mathcal{H} \subseteq \mathcal{F}$ be two sigma-algebras. We assume that $X$ is independent of $\mathcal{G}$, i.e. $\sigma(X)$ is independent of $\mathcal{G}$. Can I say (and can I prove) that $$ E(X \mid \sigma(\mathcal{G} \cup \mathcal{H})) = E(X\mid \mathcal{H}) ?$$ Thank you very much for your help!","['probability-theory', 'measure-theory', 'random-variables', 'conditional-probability']"
365313,"Computing $\int\frac{7x^{13}+5x^{15}}{(x^7+x^2+1)^3}\,dx$","Compute the indefinite integral $$
\int\frac{7x^{13}+5x^{15}}{(x^7+x^2+1)^3}\,dx
$$ My Attempt: $$
\int\frac{7x^{13}+5x^{15}}{x^{21}(x^{-7}+x^{-5}+1)^3}\,dx = \int\frac{7x^{-8}+5x^{-6}}{(x^{-7}+x^{-5}+1)^3}\,dx
$$ Let $t=(x^{-7}+x^{-5}+1)$ such that $$
\begin{align}
dt&=(-7x^{-8}-5x^{-6})\,dx\\
-dt&=(7x^{-8}+5x^{-6})\,dx
\end{align}
$$ We can change the variables of the integral  to get $$
\begin{align}
-\int \frac{1}{t^3}\,dt &=\frac{1}{2}\cdot\frac{1}{t^2}+C\\
&= \frac{1}{2}.\frac{1}{(x^{-7}+x^{-5}+1)^2}+C\\
&= \frac{x^{14}}{2.(1+x^2+x^7)^2}+C
\end{align}
$$ I'd prefer to compute the integral using methods of differentiation rather than integration, i.e. $$\frac{7x^{13}+5x^{15}}{(x^7+x^2+1)^3} = \frac{d}{dx} \left(\frac{ax^2+bx+c}{(x^7+x^2+1)^2}\right)
$$ but I could not get the same answer as above.","['calculus', 'integration']"
365346,Weierstrass Approximation Theorem for continuous functions on open interval,"I am studying for my introductory real analysis final exam, and here is a problem I am somewhat stuck on. It is Question 2, in page 3 of the following past exam (no answer key unfortunately!): http://www.math.ubc.ca/Ugrad/pastExams/Math_321_April_2006.pdf Give an example of each of the following, together with a brief
explanation of your example. If an example does not exist, explain why
not. (c) A continuous function $f : (−1,1) → \mathbb{R}$ that cannot be uniformly approximated by a polynomial. By Weierstrass Approximation Theorem, every continuous real-valued function on closed interval can be uniformly approximated by a sequence of polynomials. Since in this question the domain of the function is an open interval $(-1, 1)$ , I have a feeling that such example must exist. My attempts: The proof of Weierstrass approximation theory uses the fact that a continuous function a compact set (a closed interval by Heine-Borel Theorem) achieves a maximum, so we can guess that the example we are looking after will not achieve a maximum on $(-1, 1)$ . Such example of continuous function is $$ f(x)=\frac{1}{x+1} $$ So now my question: is it true $f$ cannot be uniformly approximated by a sequence of polynomials? And if so, how do proceed to prove such a statement? Thanks!","['approximation', 'real-analysis']"
365355,Newton's method — for which initial guesses does it converge?,"We've got a function: $ f : \Bbb R \to \Bbb R$ defined by $f(x) = x^3 - 9$ .
Let $x^* $ be its root, which means $ f(x^*) = 0$ . We want to find approximation for $x^*$ using a Newton's method.
There are two questions I don't know how to answer: We choose an initial guess: $x_0 = 2,5$ . Does it lineary converge for such $x_0$ ? And quadratically? And, most of all, I'm interested how to find range of $x_0 $ for which this method converges. How to do it? Can we show that $|x_3 - x^*| < 2^{-15}$ ? Is there a posiibility to do it without computing $x_3$ , which is not that easy without a calculator?","['dynamical-systems', 'basins-of-attraction', 'newton-raphson', 'real-analysis', 'numerical-methods']"
365358,Every injective function is an inclusion (up to a unique bijection),"Let $X$ be a set and let $A$ be a subet of $X$. Let $i:A\longrightarrow X$ be the usual inclusion of $A$ in $X$. Then $i$ is an example of an injective function. I want to show that every injective function is of this kind. More precisely: for every set $Y$ and every injective function $f:X\longrightarrow Y$, there exist a subset $B$ of $Y$ and a bijection $g:X\longrightarrow B$ such that $f$ factors through $B$, i.e. $f=j\circ g$, where $j$ is the inclusion of $B$ in $Y$. Moreover, $g$ is unique with respect to this property. I can take $B:=f(X)$ and $g:=f$ (so that $g$ is the same of $f$ as a rule, but with different codomain) and it is easely checked that everything works. Moreover $g$ is unique, since $j\circ g=f=j\circ g'$ implies $g=g'$ by injectivity of $j$. There is something that does not convince at all, in the unicity part. I mean, $g$ is unique if I fix $B=f(X)$, but what about the unicity of $B$? Is there a $B'$, different from $B$, and a $g'$ from $X$ to $B'$ bijective, such that $j'\circ g'=f$ holds?","['abstract-algebra', 'functions']"
365363,Find all differentiable functions $f$ such that $f\circ f=f$,"I want to find all differentiable functions $f:\mathbb R \to \mathbb R$ such that $f\circ f=f$, My attempt since $f$ is differentiable, $f'(f(x))f'(x)=f'(x)$ Now if $f'(x)\neq0$($f'=0$ means constant and they satisfy) then $f'(f(x))=1$, so we are looking for functions which satisfy $f'(f(x))=1$, How to proceed in this case? ($f(x)=x$ is also an obvious solution)","['real-analysis', 'functional-equations']"
365375,Continuous function need not be Riemann-Stieltjes integrable if $\alpha$ is not monotone.,"For a given function $\alpha: [0, 1]\to \mathbb{R}$, let's denote $\mathcal{R}(\alpha)$ to be the set of all Riemann-Stieltjes integral functions with respect  to $\alpha$. It is a well-known fact that (for example, see Theorem 6.8 in Rudin's Principles of Mathematical Analysis ) if $f: [0,1]\to\mathbb{R}$ is a continuous function, and $\alpha: [0,1]\to\mathbb{R}$ is a monotonically increasing , then $f\in\mathcal{R}(\alpha)$. I am interested in the following: Question 1: What is an example of function $\alpha:[0,1]\to\mathbb{R}$ and a continuous function $f:[0,1]\to\mathbb{R}$ such that $f\not\in\mathcal{R}(\alpha)$? Question 2: Does there exist an example of continuous function $\alpha:[0,1]\to\mathbb{R}$ and a continuous function $f:[0,1]\to\mathbb{R}$ such that $f\not\in\mathcal{R}(\alpha)$? Thanks!","['integration', 'real-analysis']"
365386,A surjective map which is not a submersion,"Is there an example of a smooth map between smooth manifolds which is surjective, but not a submersion? I feel there can't be one, but don't know of a proof. Nor do I know of a counter-example. Kindly help!","['differential-topology', 'analysis']"
365409,steady states and stability,"im just checking to see if im doing this right? $$\frac{du}{d\tau}=u(1-u)-h    $$ show this equations has 2 steady states and check their linear stability. this is what i have done: $u=0$ and $u=1$ $$\frac{d^2u}{d\tau^2} = -2u+1    $$ at $u=0$, $\frac{d^2u}{d\tau^2}$=1 which is unstable at $u=1$, $\frac{d^2u}{d\tau^2}$=-1 which is stable is this right? thanks in advance","['ordinary-differential-equations', 'biology']"
365424,"Is the $ϵ,δ$ definition of a limit not well-defined? [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 2 years ago . Improve this question I just watched this youtube video: http://www.youtube.com/watch?v=K4eAyn-oK4M He lays out his objections against the $ϵ,δ$ definition around 14 min. Here is the discription of the video: In this video we aim to give a precise and simpler definition for what
  it means to say that: a rational polynumber on-sequence p(n) has a
  limit A, for some rational number A. Our definition is both much
  simpler and more logical than the usual epsilon -delta definition
  found in calculus texts. What is required is that we need to find two
  natural numbers: k called the scale, and m called the start that allow
  us to bound in a pretty simple way the difference between p(n) and A. The epsilon-delta definition of a limit is usually considered a high
  point of logical rigour. Not so. It is also considered too logically
  involving to be taken seriously as a pedagogical pillar for most
  undergrads. Hence students may be told about the definition, but are
  not required to seriously understand it, or be able to use it--unless
  they are prospective maths majors. There is a subtle ambiguity in the definition: given an epsilon we are
  supposed to demonstrate there is a delta (with certain properties) but
  how are we to do this, since an potential infinity of epsilons are
  involved? In practice what is required is a correspondence
  (function/relation etc) between epsilon and delta but the nature of
  this required correspondence is not clear. We return to our familiar
  conundrum of using the work``function'' without a proper definition of
  it. The key point that makes our simpler more intuitive notion of limit of
  a sequence work is that we are dealing with very particular and
  clearly defined on-sequences: those generated by a rationl polynumber.
  A good example of the benefits of being careful rather than casual
  when dealing with the foundations of analysis! My question is: Is this an opinion shared by more mathematicians ? I kind a feel like that this Professor of the University of New South Wales is standing completely alone as it comes to this. I don't really undestand his objections, but I don't think I'm skilled enough to understand if his objections are legit.","['soft-question', 'real-analysis', 'analysis']"
365431,How to prove that every space can be decomposed into scattered and perfect subspace,"How to prove the following claim: A space $X$ can be represented as the union of two disjoint subset $A$ and $B$, where $A$ is a scattered and $B$ satisfies $B=B'=:\{x: x \text{ is the accumulation point of B}\}$. A scattered space is a space for which every not empty subset has an isolated point. My idea: Let $A$ is the set of all isolated points, $B=X\setminus A$. However, I'm not sure $B=B'$. Thanks for your help.","['general-topology', 'elementary-set-theory']"
365447,When are the sections of the structure sheaf just morphisms to affine space?,"Let $X$ be a scheme over a field $K$ and $f\in\mathscr O_X(U)$ for some (say, affine) open $U\subseteq X$. For a $K$-rational point $P$, I can denote by $f(P)$ the image of $f$ under the map
$$\mathscr O_X(U) \to \mathscr O_{X,P} \twoheadrightarrow \mathscr O_{X,P}/\mathfrak m_P = K.$$
This yields a map $f:U(K)\to K$. Giving $U$ the induced subscheme structure, when does this uniquely define a morphism $f:U\to\mathbb A_K^1$ of schemes? It certainly works when $X$ is a variety (and $K$ algebraically closed), so there should be some ""minimal"" set of conditions for this interpretation to make sense. Thanks a lot in advance!","['rational-functions', 'algebraic-geometry', 'schemes']"
365473,Why is this Poisson distribution incorrect?,"Assume power failures occur independently of each other at a uniform rate through the months of the year, with little chance of $2$ or more occurring simultaneously. Suppose that $80\%$ of months have no power failures. What is the probability that a month has more than one power failure. I used a Poisson distribution with parameters $\lambda=0.2$ and $t=1$. Letting $X$ be the total number of failures in the month, I calculated $1-P(X=0)-P(X=1)$ and obtained $1-e^{-0.2}-0.2e^{-0.2}\approx 0.017523$. However, the book gives a solution of $0.0215$. Which step was I wrong?","['statistics', 'probability-distributions', 'probability']"
365476,Writing a group element as $ghg^{-1} h^{-1}$ and as $g^2 h^2$,"I recently read the elegant paper Generalized Frobenius Schur Numbers , by Bump and Ginzburg, which I learned about here . The results in this paper imply the following: Let $G$ be a finite group where every element is conjugate to its inverse. Then, for any $x \in G$, the number of ways to write $x$ as $ghg^{-1} h^{-1}$ is equal to the number of ways to write $x$ as $g^2 h^2$. I'll give the proof below, using character theory. I tried to find an elementary proof and failed. Can you do it? $\def\CC{\mathbb{C}}$We need to prove the equality $\sum_{g, h \in G} g^2 h^2 = \sum_{g, h \in G} g h g^{-1} h^{-1}$ in $\CC[G]$. Since we have $\CC[G] \cong \bigoplus_V \mathrm{End}(V)$, where the sum is over irreps of $V$, it is enough to show that both group elements act the same way on each $V$. As I computed in this answer , $\sum_{g, h \in G} ghg^{-1} h^{-1}$ acts on an irrep $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. Now consider $\sum_{g \in G} g^2$ acting on an irrep $V$. Since $\sum_{g \in G} g^2$ is central in $\CC[G]$, it must act by a scalar, and computing traces we find that this scalar is $\frac{1}{\dim V} \sum_{g \in G} \chi_V(g^2)$. The quantity $\frac{1}{|G|} \sum_{g \in G} \chi_V(g)^2$ is known as the Frobenius-Schur indicator and is $\pm 1$ for a group where every element is conjugate to its inverse. So $\sum_{g \in G} g^2$ acts on $V$ by $\pm \frac{|G|}{dim V}$
and
$\left( \sum_{g \in G} g^2 \right)^2$ acts on $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. We have shown that $\sum_{g, h \in G} ghg^{-1} h^{-1}$ and $\left( \sum_{g \in G} g^2 \right)^2 = \sum_{g,h \in G} g^2 h^2$ act on every irrep by the same scalar, so they are equal in the group algebra. QED. The same argument shows that, in any finite group, the number of ways to write $x$ as $f^2 g^2 h^2$ is the same as the number of ways to write $x$ as $f^2 g h g^{-1} h^{-1}$, using that the Frob. Schur indicator is always $-1$, $0$ or $1$ and thus obeys $\epsilon^3 = \epsilon$. In case anyone finds that easier to think about...","['representation-theory', 'abstract-algebra', 'finite-groups', 'alternative-proof', 'group-theory']"
365482,Composition of holomorphic function and constant functions,"I am trying to solve a problem, that might seem easy to you, but i am really stuck with it and would be great if somebody could help me or give me a hint how to show that proof. Given are two holomorphic functions on the whole $\mathbb{C}$: $f$ and $g$ and $\forall z\in \mathbb{C}: f(g(z))=0$. To show is that $f\equiv 0$ or $g$ is constant. Okay, what i know is that a composition of two holomorphic functions is also holomorphic. I know also what the theorem of Liouville says: every bounded entire function is constant. $g$ is entire, this is clear, but how to show that it's bounded? Or do i have to show that $\mid g\mid $ could have a local minimum at some point $z_{0}$, so it's $g(z_{0})=0$ or constant? Thank you in advance!",['complex-analysis']
365493,Relation and the complementary relation: reflexivity and irreflexivity,"How do I show that the relation R on a set A is reflexive if and only if the complementary relation R is irreflexive. Because of iff: I start with let R be a relation from a set A to B. The complementary relation R is the set $\{(a,b):(a,b) \not\in R\}$ I think a relation R on the set A is irreflexive if for every a is an element of A, $(a,a)$ is in R. That is, R is irreflexive if no element in A is related to itself.","['relations', 'elementary-set-theory']"
365496,Prove $7\mid x^2+y^2$ iff $7\mid x$ and $7\mid y$,"The question is basically in the title: Prove $7\mid x^2+y^2$ iff $7\mid x$ and $7\mid y$ I get how to do it from $7\mid $ and $7\mid y$ to $7\mid x^2+y^2$ , but not the other way around. Help is appreciated! Thanks.","['modular-arithmetic', 'elementary-number-theory', 'divisibility', 'discrete-mathematics']"
365499,An identity related to Legendre polynomials,"Let $m$ be a positive integer. I believe the the following identity
 $$1+\sum_{k=1}^m (-1)^k\frac{P(k,m)}{(2k)!}=(-1)^m\frac{2^{2m}(m!)^2}{(2m)!}$$
 where $P(k,m)=\prod_{i=0}^{k-1} (2m-2i)(2m+2i+1)$, is true, but I don't see a quick proof. Anyone?","['analysis', 'sequences-and-series', 'hypergeometric-function', 'combinatorics']"
365512,Binomial Coefficients for $(x+1)^4$,"Find $(x + 1)^4$ using binomial coefficients. I'm confused as to how to start this, as I thought binomial coefficients were things like $9 \choose 2$.","['binomial-theorem', 'discrete-mathematics', 'binomial-coefficients']"
365516,Why does the taylor series of $\ln (1 + x)$ only approximate it for $-1<x \le 1$?,I'm looking for an intuitive understanding instead of a formal proof. Thanks for the help.,"['sequences-and-series', 'power-series', 'calculus']"
365529,how the number of steps needed depends on the number of nodes and depends on the transmission range?,"I run the consensus algorithm, and for each round k, we record the norm of the disagreement vector(|(|δ(k)|)|>〖10〗^(-6)). We stop, at a predefined value|(|δ(k)|)|>〖10〗^(-6) and we call this “k_stop”. We have then a vector of these disagreement values as a function of the round number, which we can plot. Now the next step is to see how the number of steps needed depends on the number of nodes, and on the average degrees, which in turn depends on the transmission range. 
Then, the step of the evaluation, we are following:
We fix the network size, e.g., 100 nodes, and evaluate how the convergence time, i.e., the number of rounds needed to have the ""local averages"" equal to the known global average changes as we change the nodes transmission range. Thus we do as follows:
-We take a given value of the transmission range, and generate 10 different networks, each with a given number of nodes , e.g., 100 nodes but in different random positions. For each network, measure the convergence time, and then take the average. And then we had the two cases: 
1) Iterations as a function of the number of nodes for given radius, and 
2) Iterations as a function of the radius for given number of nodes
Can you help me the explain how the number of steps needed depends on the number of nodes and  depends on the transmission range and so on when the looking figure..","['random-graphs', 'matrices', 'graph-theory', 'discrete-mathematics']"
365535,Pushforward of Lie Bracket,"I am trying to figure out why the following equality is true : $$f_*[X,Y]=[f_*X,f_*Y]$$
where $f:M\rightarrow N$ is a diffeomorphism, $M$, $N$ are smooth manifolds, $X$, $Y$ are smooth vector fields on $M$. I have tried to write $$f_*[X,Y]=\dfrac{\partial f^i}{\partial x^j}\left( \chi^k \dfrac{\partial \psi^j}{\partial x^k}-\psi^k \dfrac{\partial \chi^j}{\partial x^k}\right)\dfrac {\partial}{\partial y^i}$$
where $$X=\chi^k \dfrac{\partial}{\partial x^k},Y=\psi^k \dfrac{\partial}{\partial x^k}, [X,Y]=\left( \chi^k \dfrac{\partial \psi^j}{\partial x^k}-\psi^k \dfrac{\partial \chi^j}{\partial x^k}\right)\dfrac {\partial}{\partial x^j}.$$
However, when it comes to write the second part of the equality:
$$[f_*X,f_*Y]=\left( (f_*X)^k \dfrac{\partial (f_*Y)^j}{\partial y^k}-(f_*Y)^k \dfrac{\partial (f_*X)^j}{\partial y^k}\right)\dfrac {\partial}{\partial y^j}$$
where $y^j$ is a coordinate basis of N. The problem I face is that I cannot differentiate $f_*Y, f_*X$ with respect to the basis $y^j$, in the above expression. Any help would be appreciated. 
( I would prefer an answer which is based on the definition of Lie Bracket with coordinates, as I worked above)","['multivariable-calculus', 'manifolds']"
365563,Differentiability in the proof of Rademacher theorem,"I have a question about the proof of Rademacher theorem due to C. B. Morrey. (I'm reading it in Simon's Lectures on geometric measure theory .)
The proof can be summarized in the following steps: For every $ v \in R^n $, $ |v|=1 $, the directional derivative $ D_vf $ exists a.e. in $ R^n $. The directional derivative $ D_vf $ is a weak derivative and therefore it holds that: $$D_vf(x)= v\cdot \nabla f(x) \text{ a.e. in } R^n.$$ There exists $ A \subset R^n $ such that $L^n(R^n-A)=0 $ ($L^n $ is the Lebesgue measure) and such that for every $ x \in A $ and for every $ v $ the directional derivative $ D_vf(x) $ exists. Note the difference between this step and the first step. As I've read, these three steps should be conclude the proof. But my doubt is obviously the following one: Since a continuous function with all of its directional derivatives at a point $ x $ is not necessarily differentiable at $ x $, how can I conclude the proof using only these three steps?","['measure-theory', 'geometric-measure-theory', 'real-analysis']"
365577,Determine all subgroups of $\mathbb{R}^*$ (nonzero reals under multiplication) of index $2$.,"Determine all subgroups of $\mathbb{R}^*$ (nonzero reals under multiplication)
of index $2$. how can I able to solve this problem","['group-theory', 'abstract-algebra']"
365593,What points of affine space can be mapped to zero by an étale morphism?,"Let $K$ be a field and $n$ a positive integer. For what points $x\in\mathbb{A}^n_K$ can I find an étale morphism $f_x:\mathbb{A}^n_K\to \mathbb{A}^n_K$ mapping $x$ to zero and how does such a morphism look like on the level of $K$-algebras $g_x:K[X_1,\ldots,X_n]\to K[X_1,\ldots,X_n]$? Edit: By ''points'' $x\in\mathbb{A}^n_K$ I mean ''elements of $\operatorname{Spec} K[X_1,\ldots,X_n]$'', all prime ideals.","['commutative-algebra', 'algebraic-geometry']"
365600,Limit of $\frac{1}{n}\sum\limits_{i =2}^n \frac{1}{\ln i}$ as $n \to \infty$,"For the sequence $a_n =\frac{1}{n}\sum_{i =2}^n \frac{1}{\ln i}$ (with $n \ge 2$), I would like to determine if the limit exists, and, if so, find its value. Some observations I have made so far: integral comparison does not seem to help--we do have $a_n \le \sum_{i = 2}^n \frac{1}{i\ln i}$. But, by integral comparison, this sum diverges as $n \to \infty$. To get some concrete handle on the problem, I have computed some values in the sequence and found $a_{10} \approx .61$, $a_{100} \approx .3$. So the series appears to be approaching $0$. Is there a  standard analysis trick I am missing or is there some more advanced technique needed to establish the limit?",['sequences-and-series']
365603,Series of iterates of a power series,"Let $f = \sum_{n \ge 2} a_{n} x^{n}$ be a formal power series of order higher/equal two. By $$ f^{\circ n} := \underbrace{f \circ \dots \circ f}_{\text{ n times}}$$ we denote the $n^{th}$ iterate of $f$ and set $$f^{0} = x. $$ It is easily seen that the order of $f^{\circ n}$ is higher/equal $2^{n}$, so we may define the formal series  $$S(z):= \sum_{n\ge 0} f^{\circ n}.$$
If we assume that $f$ is a convergent power series, it is also not hard to show that $\sum_{n = 0}^{N} f^{\circ n}$ converges locally uniformly to $S$, especially $S$ is again a convergent power series.
Note however that $S \neq (x + f)^{ \circ -1}$ - it is in general not the composite inverse of (x+f). I don't have a particular reason for studying this series, but it seems to be interesting to ask - what is $S$?. In the sense that whether $S$ relates to $f$ in any ""familiar"" way, i.e. is the value of some better known operator evaluated at $f$ or does it have any interesting properties?
Maye someone already had a thought on it,thanks for all answers. EDIT: Here is the proof the $S(z)$ is analytic if $f$ is of order $\ge 2$ and convergent:
Since $f(0)=0$ you can find a neighborhood in which the modulus of $f$ is strictly smaller then one, so there exist $R>0$ and $M \in (0,1)$ so that $$\vert a_{n} \vert \le \frac{M}{R^{n}}.$$ And you obtain $$\vert f(x) \vert \le \vert \frac{x}{R} \vert ^{2} \frac{ M}{1 - \vert \frac{x}{R}\vert }$$ Since $0<M<1$ there is an $s>0$ so that $\frac{ M}{1 - \vert \frac{x}{R}\vert } \le 2$ for all $x \in D_{s}:= \{ \vert x \vert \le s\}$ and we choose $s$ so small that $\vert \frac{s}{R} \vert \le \frac{1}{2}$. Now I claim that on $D_{s}$ we have $$\vert f^{\circ n }(x) \vert \le \left\vert\frac{x}{R}\right\vert^{n} 2^{n},$$ which is proven by induction: Let $n=1$. Then $\vert f(x) \vert \le \vert\frac{x}{R} \vert^{2} \frac{ M}{1 - \vert \frac{x}{R}\vert } \le \vert\frac{x}{R} \vert \vert\frac{x}{R} \vert 2 \le \vert\frac{x}{R} \vert$. Now the step $n\to n+1$: $$ \vert f(f^{\circ n}) \vert \le \vert \frac xR \vert^{2 n} 2^{2n -2}
\frac{ M}{1 - \underbrace{\vert (\frac xR^{n}) 2^n\vert}_{\le \vert \frac{x}{R}\vert }} \le \vert \frac{x}{R} \vert^{2 n} 2^{2n -2} \cdot 2 \le 2^{n} \vert \frac{x}{R} \vert^{n+1}$$","['complex-analysis', 'combinatorics']"
365605,Model a function with specific shape,"I need a function with a specific shape: Quadratic/gaussian concave shape ($-x^2$ like) Centered in $\frac{1}{2}$ where it reaches the max value 1 On 0 and 1 to become null I first tried using a second-degree polynomial function and I failed. By repeated tries on graph.tk , after I deduced on paper that $c=0$, I got $-4x^2+4x$ to be what I need. Then I found the function $e^{-x^2}$ which have a very nice shape. But now I have to span it in $[-0.5, 0.5]$ and add an offset. $e^{-(x-0.5)^2}$ is centered in $\frac{1}{2}$ where it reaches 1, but it does not descend down to zero in 0 and 1 . I'm interested in either the solution to this problem and in the process of reaching that solution. How is this usually done? If Q above is unclear: How do I model $e^{-x^2}$ to meet the requirements in bullets above?","['graphing-functions', 'functions']"
365610,New to generating functions - how do I get the function from the sequence defined by $a_n= n$ for $n\geqslant 0$?,"I'm given: $a_n= n$ for $n \geqslant 0$. I'm quite good at recursive generating functions, but I haven't came across a simpler one like this, so I'm sure I'm just overlooking something really basic.","['statistics', 'generating-functions', 'discrete-mathematics', 'combinatorics']"
365617,How to get a unit vector from another unit vector and angle between them?,"How to get a unit vector from another unit vector and angle between them? Is it possible?
I need something like  this:","['multivariable-calculus', 'vectors']"
365628,Matrix Representation of Trace Class Operators,"Suppose we have a separable Hilbert space (thus with a countable basis) and that represent an operator in matrix form, i.e: $A: H \rightarrow H $$$x \;\rightarrow \sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot\langle x,e_k\rangle  \right)e_j$$ Given that: The series of complex numbers $\sum_{k \in \mathbb{N}} a(j,k)\cdot\langle x,e_k\rangle $ converges. That $\sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot\langle x,e_k\rangle  \right)e_j$ converges. That $\sum_{j \in \mathbb{N}}\sum_{k \in \mathbb{N}} \left |a(j,k) \right|^2 < \infty$ (the previous conditions + this one imply that A is a Hilbert-Schmidt operator). And that $\sum_{k \in \mathbb{N}} \left |a(k,k) \right| < \infty$. Prove that $A$ is a trace class operator. My attempt at a solution By these conditions we know that $\left | Tr (A) \right | \leq \displaystyle{\sum_{k \in \mathbb{N}}} \left | a(k,k) \right | < \infty$. But  I can't see the connection to $Tr(\left |A \right |)$. Any hints on how to proceed?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
365643,Multinomial Theorem Example Questions,"I'm learning about the multinomial theorem and working 2 examples in a book.  I thought I understood the examples until I did example 5c.  I don't understand why these two examples are different.  In example 5c it says that order is now irrelevant.  What do you mean order is irrelevant?  Why was the order relevant in 5b?  In both examples we are separating into 2 groups of 5...  Thank you in advance!!! EXAMPLE 5b
Ten children are to be divided into an A team and a B team of 5 each. The A team will play in one league and the B team in another. How many different divisions are possible? Solution is 10! / (5! 5! ) = 252 EXAMPLE 5c
In order to play a game of basketball, 10 children at a playground divide themselves into two teams of 5 each. How many different divisions are possible? Solution. Note that this example is different from Example 5b because now the order of the two teams is irrelevant. That is, there is no A and B team, but just a division consisting of 2 groups of 5 each. Hence, the desired answer is [10! / (5! 5!) ]/2!","['multinomial-coefficients', 'combinatorics']"
365657,Cyclic Sylow $p$-subgroups are central in their normalizer when $p$ is the smallest prime divisor of $|G|$.,"Let $p$ be the smallest prime dividing the order of a finite group $G$.  If $P$ in $\operatorname{Syl}_p(G)$ and $P$ is cyclic, prove that $N_G(P)=C_G(P)$. This is not homework.  It is from Dummit and Foote.  I'm not sure how to apply that $p$ has the smallest order.","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
365662,"If $B\times \{0\}$ is a Borel set in the plane, then $B$ is a Borel set in $\mathbb{R}$.","I'm trying to figure out how to prove the following ""obvious"" fact: Let $B\times \{0\}\subset \mathbb{R}^2$ be a Borel set, then $B\subset \mathbb{R}$ is a Borel set. The problem here is that I can't see a nice constructive way of expressing a Borel set, so I just can't intersect stuff with $\mathbb{R}\times\{0\}$ in some countable union/intersection, which is what I tried by starting by taking the countable family sets $[a,b]\times [c,d]$, $a,b,c,d\in \mathbb{Q}$ as the generators of the Borel sets of the plane. Is there a nice technique of approaching results like this?","['measure-theory', 'real-analysis']"
365663,Evaluating the integral $ \int_{-\infty}^{\infty} \frac{\cos \left(x-\frac{1}{x} \right)}{1+x^{2}} \ dx$,"I'm curious about the proper way to evaluate $$ \int_{-\infty}^{\infty} \frac{\cos \left(x-\frac{1}{x} \right)}{1+x^{2}} \, dx =  \text{Re} \int_{-\infty}^{\infty} \frac{e^{i(x- \frac{1}{x})}}{1+x^{2}} \, dx$$ using contour integration. If I let $f(z) = \frac{e^{i(z- \frac{1}{z})}}{1+z^{2}}$, there is an essential singularity at the origin. So if I integrate around a closed semicircle in the upper half-plane, the contour goes right through the singularity. Can you indent a contour around an essential singularity?","['integration', 'complex-analysis', 'contour-integration']"
365668,"difference between ""minimal"" and ""minimum"" edge cuts.","I was going through the topic about connectivity of graphs. There it was mentioned about the terms "" minimum edge cut "" and "" minimal edge cut "". I know both are the sets of edges if removed from the graph $G$, makes $G$ disconnected. But I am unable to catch the basic difference betwen these two terms. Is minimal always minimum or vice versa? thanks.","['graph-theory', 'discrete-mathematics', 'terminology']"
365680,how to prove that $(1 + \frac{1}{n})^{n+1}$ is decreasing? [duplicate],"This question already has answers here : Given $y_n=(1+\frac{1}{n})^{n+1}$ show that $\lbrace y_n \rbrace$ is a decreasing sequence (7 answers) Closed 11 years ago . Please, help me to prove that $$x_n=\left(1+\frac{1}{n}\right)^{n+1}$$decreases.
I know I must to prove that that $$\frac{x_n}{x_{n+1}}> 1$$ What to do next?",['sequences-and-series']
365682,"Give an example of a function $h$ that is discontinuous at every point of $[0,1]$, but with $|h|$ continuous on $[0,1]$","Give an example of a function $h:[0,1]\to\mathbb{R}$ that is discontinuous at every point of $[0,1]$, but such that the function $| h |$ that is continuous on $[0,1]$. I don't really even know where to start with this one. I would have to prove that the function $| h |$ is continuous on $[0,1]$, ie if we're given any $\varepsilon>0$, there exists $\delta>0$ such that if $x$ and $c$ are any two points in $[0,1]$ with $|x-c| < \delta$, then $|f(x) - f(c)| < \varepsilon$. Alternatively I could use the limit definition. But I can only think of functions that are discontinuous at some points in  $[0,1]$ rather than all... I feel like I'm missing something obvious here, but any help is greatly appreciated. This is a question on a past final.","['continuity', 'examples-counterexamples', 'real-analysis']"
365714,"$\mathbb{Q}$ is not open, is not closed, but is the countable union of closed sets.","I want to prove that $\mathbb{Q}$ (the set of rational numbers) is not open, is not closed, but is the countable union of closed sets. I tried to show that $\mathbb{Q}$ doesn't contain all of its limit points which would imply not closed. However, I am not able to prove the other two things. I need little help to prove this. Thanks.",['general-topology']
365721,Circumference of a superellipse?,"Could someone help me formulate the circumference of a superellipse? 
$$\frac{x^n}{a^n} + \frac{y^n}{b^n} = 1$$
If it makes things easier, I'm considering only the cases $n>2$, and $n\in\mathbb{Q}$. Since the formula for an ellipse ($n=2$) involves special functions, I assume the general case won't be any simpler, but I can't seem to find any sources on this. I've also seen the circumference for an ellipse approximated by:
$$C \sim \frac{2\pi}{\sqrt{2}}\sqrt{a^2 + B^2}$$
Can this approximation be extended to the case of a superellipse, i.e:
$$C \sim A\sqrt{a^n + B^n}$$
Any help greatly appreciated. Edit: Someone by the name of Maher Izzedin Aldaher posted some approximate numerical formulae online, one of them being: $$4 \left[a+b \frac{ b\left(\frac{2.5}{n+0.5} \right)^{1/n} + \frac{0.566 a(n-1)}{n^2} }{b + \frac{4.5 a}{0.5+n^2}} \right]$$
I have no idea how this was derived or how good it is.","['plane-curves', 'special-functions', 'integration', 'algebraic-curves']"
365747,Definition of nebentypus in $L$-functions.,"In Iwaniec and Kowalski, the term nebentypus is mentioned several times in the book. Every time it seems to just refer to a character $\chi$. Since I don't see the authors defining nebentypus, can anyone give me a concise definition? Thanks!","['analytic-number-theory', 'algebraic-number-theory', 'number-theory']"
365770,What is a simple example of a limit in the real world?,"This morning, I read Wikipedia's informal definition of a limit: Informally, a function f assigns an output $f(x)$ to every input $x$. The
  function has a limit $L$ at an input $p$ if $f(x)$ is ""close"" to $L$ whenever
  $x$ is ""close"" to $p$. In other words, $f(x)$ becomes closer and closer to $L$
  as $x$ moves closer and closer to $p$. To me that sounds like something that might be better described as a 'target'. If I take a simple function, say one that only multiplies the input by $2$; and if my limit is $10$ at an input $5$: then I've described something that seems to match the elements contained in Wikipedia's definition. I don't believe that that's right. To me it looks like an elementary-algebra problem ($2p = 10$). To make it more calculusy, I could graph the function's output when I use inputs other than $p$, but that really wouldn't give me anything but an illustration of the fact that one's answer moves farther from the right answer as it becomes more wrong (go figure). So limits are important; what I've just described is trivial. I do not understand them. I know calculus is often used for solving real-world challenges, and that limits are an important element of calculus, so I assume there must be some simple real-world examples of what it is that limits describe. What is a simple example of a limit in the real world? Thank you -Hal.","['applications', 'calculus', 'algebra-precalculus', 'analysis', 'limits']"
365774,How to solve this determinant: $a_{ij}=|i-j|+1$?,"I have to solve determinant of the following form: $$a_{ij}=|i-j|+1$$ It looks like this: $$
\begin{pmatrix}
1 & 2 & 3 & 4 & \cdots & n \\
2 & 1 & 2 & 3 & \cdots & n-1 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
n & n-1 & n-2 & n-3 & \cdots & 1
\end{pmatrix}
$$ It looks something like Toeplitz matrix, but I haven't found any method of solving it. I would appreciate also a kind of hint that would help. EDIT: OEIS gives a formula for absolute value: $(n+1)\cdot2^{n-2}$ http://oeis.org/A001792 Thanks in advance!","['matrices', 'determinant']"
365782,"show $ -\int \frac{d^{3}p}{(2\pi)^3}p\frac{\partial f(p,t)}{\partial p}=3F$","Hi I am stuck with an integral problem trying to show  $$ -\int \frac{d^{3}p}{(2\pi)^3}p\frac{\partial f(p,t)}{\partial p}=3F$$ where $F=\frac{1}{(2\pi)^3}\int d^{3}pf(p,t)$ I have read in many books that simply integrated by parts to get the solution, but I just dont get it can anyone help?","['integration', 'physics']"
365790,How to calculate $ \lim_{n\to\infty} (2^n+3^n+\cdots+n^n)^{1/n}/n ?$,I need help in calculating the following limit. $$\lim_{n\to\infty}\frac{\sqrt[n]{2^n+3^n+\cdots +n^n}}{n}$$,['limits']
365810,A diagonal matrix can be expressed as a difference of two squares ($A=B^2 − C^2$ where $BC = CB = 0$),"I got one interesting question from matrix theory. I tried but I am not finding any clue to solve this question.  I need help and suggestions. Thanks in advance. Let $A$ be a real $n\times n$ matrix. We say that $A$ is a difference of two squares if there exist real $n\times n$ matrices $B$ and $C$ with $BC = CB = 0$ and $A = B^2 − C^2$ .
Now If $A$ is a diagonal matrix, then I have to show that that it is a difference of two squares.","['matrices', 'linear-algebra']"
365827,how to prove following matrix is invertible? [duplicate],"This question already has an answer here : Prove that a matrix is invertible [duplicate] (1 answer) Closed 11 years ago . how to prove A is invertible or $\ detA\neq 0$
$$A=\begin{pmatrix}
    \frac11 & \frac12 & \frac13 & \cdots & \frac1n \\
     \frac12 & \frac13 & \frac14 & \cdots & \frac{1}{n+1} \\
     \vdots  & \vdots& \vdots & \ddots & \vdots \\
     \frac1n & \frac{1}{n+1} & \frac{1}{n+2} & \cdots & \frac{1}{2n-1}    
     \end{pmatrix}$$ Thanks in advance","['matrices', 'linear-algebra', 'contest-math']"
365829,Derivative of the linear functional given by an inner product form,"Let $L\colon\mathbb{R}^n\to \mathbb{R}$ such that $L_y(x)=\langle x,y\rangle$ for some inner product, and $DL$ be the derivative of $L$. Then which of the following is/are true? $DL(u)=DL(v)\quad \forall u,v\in\mathbb{R}^n$; $DL(0,\dots,0)=L$; $DL(x)=\|x\|^2\quad \forall x\in\mathbb{R}^n$; $DL(1,\dots,1)=0$. Could any one help me to solve this problem? I have no Idea how to solve it","['multivariable-calculus', 'linear-algebra', 'derivatives', 'real-analysis']"
365837,$I-AB$ be invertible $\Leftrightarrow$ $I-BA$ is invertible [duplicate],"This question already has answers here : $I_m - AB$ is invertible if and only if $I_n - BA$ is invertible. (4 answers) Closed 11 years ago . assume $A,B\in M_n(F)$ if  $I-AB$ be  invertible then  how  to prove $I-BA$ is invertible and how find inverse of $I-BA$ Thanks in advance","['matrices', 'linear-algebra']"
365849,Complex differentiability implies real differentiability,"First, we think of $\mathbb{R}^2$ as related to the complex plane by the following: $(x,y) \leftrightarrow x+iy$. Show that if $f(x,y)=(u(x,y),v(x,y))$ is complex differentiable at $z_0$, then $f$ is differentiable at $z_0$.  Also, at $z_0$ establish the Cauchy Riemann equations. I have not taken Complex analysis, but I am familiar with the definition of complex differentiable. Suppose $f$ is complex differentiable.  Then $\lim\limits_{z \to z_0}\frac{f(z)-f(z_0)}{z-z_0}=a+bi=\beta$.  Then $\lim\limits_{z \to z_0}|\frac{f(z)-f(z_0)-\beta(z-z_0)}{z-z_0}|=0$. At the above step, do I just sub in $z=x+yi$ and $z_0=x_0+iy_0$ to show real differentiability?","['complex-analysis', 'analysis']"
365853,Can one define the derivative of a function using tangent cones? Does such a notion already exist?,"I'm interested in finding an analogue of a derivative that applies to functions which are defined more general subsets of $\mathbb{R}^n$ than open subsets. In particularly, I'm looking at functions defined on the non-negative orthant of $\mathbb{R}^n$. I've been thinking that one could use tangent cones to such an end. The question is organised as follows, first are the standard definitions of a tangent cone and a differentiable function, then comes my candidate extension of differentiability and finally are the questions. Thank you very much in advanced (even if for just having a read!). EDIT: Does anyone think that this would be an appropriate (or not) question for MathOverflow? Tangent Cones: Let $X\subseteq\mathbb{R}^n$ and $x\in X$. Then the tangent cone to $X$ at $x$ , $T_X(x)$ is defined as the closure of the cone formed by all half-lines emanating from $x$ and intersecting $X$ in at least one point $y\in X$ distinct from $x$. Formally $$T_X(x)=\{0\}\cup\left\{y:y\neq0,\exists (x_k)_{k\in\mathbb{N}}\subseteq X,\quad x_k\neq x\quad \forall k,\quad \frac{x_k-x}{||x_k-x||}\rightarrow\frac{y}{||y||}\right\}.$$ Differentiable function: Suppose $E$ is an open set in $\mathbb{R}^n$, $f$ is a function that maps $E$ into $\mathbb{R}^m$, and $x\in E$. If there exists a linear transformation $A$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ such that $$\lim_{h\rightarrow 0}\frac{|f(x+h)-f(x)-A(h)|}{|h|}=0,$$ where $|\cdot|$ denotes any p-norm, then we say that $f$ is differentiable at $x$, and we write $$f'(x)=A.$$ Tentative extension of ""differentiability"": Suppose $X\subseteq\mathbb{R}^n$, $x\in X$ and $f:X\rightarrow\mathbb{R}^m$. We say that $f$ is differentiable at $x$ if there exists a ""pseudo-linear"" transformation $\tilde{A}$ from $T_X(x)$ to $\mathbb{R}^m$ such that for any sequence $$(h_k)_{k\in\mathbb{N}}\subset T_X(x)$$ that satisfies $h_k\rightarrow 0$ as $k\rightarrow\infty$ $$\frac{|f(x+h)-f(x)-\tilde{A}(h)|}{|h|}=0,$$ then we say that $f$ is differentiable at $x$, and we write $$f'(x)=\tilde{A}.$$ By $\tilde{A}$ being pseudo-linear I mean that for any $a,b\in\mathbb{R}$ and $x,y\in X$ such that $ax+by\in X$ $$\tilde{A}(ax+by)=a\tilde{A}(x)+b\tilde{A}(y).$$ Note that, because $x\in int(X)$ implies that $T_X(x)=\mathbb{R}^n$, the above definition coincides with the usual one if $X$ is open. My questions then are: Does the above notion of a differentiable function and its derivative already exist? If so what is it called? Or is there a more general notion for which the above is a special case? If 1., does there exist an analogue of the chain rule that applies to it? Similarly, if $\tilde{A}$ is a continuous, is there an easy way to compute the $\tilde{A}$ in the standard basis of $\mathbb{R}^n$ (much in the same way we use the partial derivatives to compute the derivative of a continuously differentiable functions)? Similarly, can one extend a differentiable (in the sense above) function on $X$ to a differentiable (in the usual sense) function on $\mathbb{R}^n$? Is there any reason why any or all the above could not be answered affirmatively (for example, something that does not make sense in the derivative)? Any answers or references that might contain them would be greatly appreciated. If it helps, please add any extra conditions on $X$ that are satisfied by the orthant (closed, convex, closure of an open set, ...etc).","['multivariable-calculus', 'convex-analysis', 'calculus', 'real-analysis', 'analysis']"
365900,"If $U$ is finite dimensional, then operator norm is finite","Let $M:U\to V$ be a linear map between normed vector space $U$ and $V$. We know $U$ is finite dimensional (but don't know about $V$). Define $\|M\| = \sup \{\|Mv\|\;:\;\|v\| = 1\}$. I want to show that $M$ is continuous and that $\|M\|$ is bounded. There are two difficulties, first is that I know the proof for $M:\mathbb{R}^m\to\mathbb{R}^n$. Continuity of $M$ is due to each entry of operator matrix of $M$ is linear thus continuous. I show unit sphere is compact and therefore continuous function obtains max. But now we are not in $\mathbb{R}$ any more, I don't know if unit sphere is compact or not. The second difficulty is that $V$ might not be finite dimensional any more, so I can't represent $M$ in a matrix of finite dimension any more. Please help. Further, not knowing if $U$ and $V$ are finite dimensional or not, I want to prove that $M$ continuous then $\|M\|$ finite.","['normed-spaces', 'linear-algebra']"
365920,Prove a square is homeomorphic to a circle,"$s:=\{|x|\le 1,|y|\le 1\} $ $c:=\{{x}^{2}+{y}^{2}\le1\}$ Prove $\overset{\circ}{s}  \cong \overset{\circ}{c}$ ok... not to sure what to do. I think $\overset{\circ}{s}  \to\overset{\circ}{c}$ is something like: $$(x,y)\rightarrow\left(\frac{x}{\sqrt{{x}^{2}+{y}^{2}}},\frac{y}{\sqrt{{x}^{2}+{y}^{2}}}\right)$$ What is the inverse for this? Do i need an inverse? Do i just prove the function is continous and the inverse is continuous? Please help...",['general-topology']
365936,Can't prove this limit of complex numbers from a paper,"Okay so I found in a paper, marked as ""simple exercise"", the following thing: for $z,b \in \mathbb{C}$, $$\lim_{b\to0} \frac{1}{z-b} + \frac{1}{2b} - \frac{1}{\overline{b}{\vphantom{b}}^2(z-\frac{1}{\overline{b}})} - \frac{1}{2\overline{b}} = z + \frac{1}{z} + Constant$$ And no one has so far managed to confirm it. Can someone please help me.","['complex-numbers', 'complex-analysis', 'limits']"
365961,$U = (I-iT) (I + iT) ^ {-1}$ is a unitary operator when T is self-adjoint,"Let $V$ complex inner product space of finite dimension and $T$ an operator over $V$. Show that the transformation
$$U = (I-iT) (I + iT) ^ {-1}$$
is a unitary operator My Attempt: $$\langle U \alpha, U\alpha \rangle = \langle (I−iT)(I+iT)^{-1} \alpha , (I−iT)(I+iT)^{-1} \alpha \rangle = 
\langle \alpha , (I−iT)^{-1}(I+iT)(I−iT)(I+iT)^{-1} \alpha \rangle $$ and I need proof this  $(I−iT)^{-1}(I+iT)(I−iT)(I+iT)^{-1} = I $","['linear-algebra', 'functional-analysis']"
365974,Computing the class number of $\mathbb{Q}(\sqrt{1533157})$,"I am trying to compute the class number of $\mathbb{Q}(\sqrt{1533157})$ in Magma. Can anyone explain why it's taking so long to compute? I'm currently running Magma V2.18-7. Below is my code: SetClassGroupBounds(""GRH""); 
K := QuadraticField(1533157);
ClassNumber(K);","['algebraic-number-theory', 'number-theory']"
365986,Prove that if $\mathrm{rank}(A) < n$ then $\det(A) = 0$?,"If $A$ is an $n \times n$ matrix with $\DeclareMathOperator{\rank}{rank}$ $\rank(A) < n$, then I need to show that $\det(A) = 0$. Now I understand why this is - if $\rank(A) < n$ then when converted to reduced row echelon form, there will be a row/column of zeroes, thus $\det(A) = 0$ However, I have been told to use the fact that the determinant is multilinear and alternating and subsequently deduce that if $\det(A)$ is non-zero, $A$ is invertible. How do I use the properties of the determinant to prove these claims?","['matrices', 'linear-algebra']"
366006,The image of the diagonal map in scheme,"Let $X\rightarrow S$ be a separated morphism of schemes, that is, the diagonal map $\Delta:X\rightarrow X\times_S X$ is a closed inmersion. In general (see Closure of image of diagonal morphism of S-scheme ) it is not true that $\Delta(X)=\{z\in X\times_S X:p_1(z)=p_2(z)\}$ where $p_1,p_2:X\times_SX\rightarrow X$ are the projections. Now let $Y$ be another $S$-scheme and let $f,g:Y\rightarrow X$ be $S$-morphisms with product $f\times g:Y\rightarrow X\times_SX$. If $y\in Y$ satisfies $f(y)=g(y)$, can we ensure that $f\times g(y)\in\Delta(X)$?. I am asking this question because I've been stack for a long with Exersice 4.2 of Hartshorne's book (Chap 2) and searching on the web I saw that everybody assume this fact. Many thanks!","['algebraic-geometry', 'schemes']"
366010,Does a nonlinear additive function on R imply a Hamel basis of R?,"A function is additive if $f(x+y) = f(x) + f(y)$.  Intuitively, it might seem that an additive function from R to R must be linear, specifically of the form $f(x) = kx$.  But assuming the axiom of choice, that is wrong, and the proof is rather simple: you just take a Hamel basis of $\mathbb{R}$ as a vector space over $\mathbb{Q}$, and then you define your function f to be different in at least two distinct elements of the basis. But my question is this: if there is no Hamel basis of $\mathbb{R}$, then must $f$ be linear?  To put it another way, does ZF + the existence of a nonlinear additive function imply the existence of Hamel basis of $\mathbb{R}$? I checked the Consequences of the Axiom of Choice Project, a database of choice axioms and their relationships here , and it said that it didn't know.","['logic', 'set-theory', 'axiom-of-choice', 'analysis']"
366012,Finding squared norm of vector,"Suppose you have a $2\times 1$ column vector $x=[7,2]^{T}$. How would you find $||x||^{2}$? Would it be $7^{2} + 2^{2}$? Is this equivalent to the distance from the origin?",['linear-algebra']
366025,Calculus of residue of function around poles of fractional order (complex analysis),The complex function $f(z)=\frac{1}{\sqrt{z^2+r_0z}}$ with $r_0>0$ has two poles (at $z=0$ and $z=-r_0$). But they are not simple poles. They are poles of fractional order. Am I right? How I can calculate residue of the function at the poles? Please help me. Thanks Vahid,"['residue-calculus', 'complex-analysis']"
366035,Showing a contraction without a fixed point,"Suppose $f: [1, \infty) \to [1, \infty]$ defined by $f(x) = x + \frac{1}{x}$ for all $x \geq 1$. I want to prove that: \begin{equation}
|f(x)-f(y)| < |x-y|
\end{equation}
except when $x=y$, but $f$ does not have a fixed point. By the Banach fixed point theorem we know that if a function $f: X \to X$ is a contraction of a complete metric space, then $f$ has a unique fixed point $p$ and the sequence of $(f, f \circ f, f\circ f\circ f, ...)$ that is the sequence of $f$ composed with itself $n$ times at index $n$ converges to p for all $x$. But $[1, \infty]$ is not a complete metric space. So it seems like a good idea to proceed via contradiction? Where can I go from here All help is greatly appreciated","['fixed-point-theorems', 'analysis']"
366045,How do you factor $2ab-6ac-15c^2+5bc$,"$$2ab-6ac-15c^2+5bc$$ Here is what I have done: $$(2ab-6ac)-(15c^2+5bc)$$
$$2a(b-3c)-5c(3c+b)$$
$$2a(b-3c)+5c(-3c-b)$$
$$2a(b-3c)+5c(-b-3c)$$
$$(b-3c)(2a-5c)$$ I know this isn't the correct answer but I can't figure out what I did wrong. Could someone please explain this to me?","['factoring', 'algebra-precalculus']"
366067,Show that dB/dt . B = 0,"B is a binormal vector where B = T x N. T is the unit tangent and N is the principal normal vector. Basically, the derivative of the binormal vector is perpendicular to both the unit tangent and the binormal vector. I expanded everything out using B = T x N and the cross product differentiation rule but I ended up with (N' x T) . (T x N).",['multivariable-calculus']
366075,How to solve the equation $ (x-2)^{\log_{100}(x-2)}+\log_{10}(x-2)^5-12 = 10^{2\log_{10}(x-2)}$?,"If $\displaystyle (x-2)^{\log_{10^2}(x-2)}+\log_{10}(x-2)^5-12 = 10^{2.\log_{10}(x-2)}$ , then value of $x$ is ... My Try Let $$\log_{10}(x-2) = y \quad \Leftrightarrow \quad (x-2)=10^y .$$ Then $$(10)^{(y) (\frac{1}{2})(y)}+5y-12=10^{2y} .$$ Now, how can I calculate the value of $y$ ? Thanks.","['logarithms', 'algebra-precalculus', 'roots']"
366093,Calculate the number of real roots of $x^8-x^5+x^2-x+1 = 0$,"Calculate the number of real roots of $$x^8-x^5+x^2-x+1 = 0 .$$ My Try $$\left(x^4-\frac{x}{2}\right)^2+\frac{3}{4}x^2-x+1 = \left(x^4-\frac{x}{2}\right)^2+\frac{3}{4}\left(x^2-\frac{4}{3}x+\frac{4}{3}\right)$$ $$\implies \left(x^4-\frac{x}{2}\right)^2+\frac{3}{4}\left(x-\frac{2}{3}\right)^2+1-\frac{4}{9}>0\quad \forall x\in \mathbb{R}$$ My question is whether any other method like using inequality exists to solve the given question. If yes, then please explain here.","['algebra-precalculus', 'roots', 'polynomials']"
366096,curvature of the boundary of a convex set is positive,"Let's consider $J\subset \mathbb R^2$ such that J is convex and such that it's boundary it's a curve $\gamma$. Let's suppose that $\gamma$ is anti-clockwise oriented, let's consider it signed curvature $k_s$. I want to prove the intuitive following fact: $$
\int\limits_\alpha  {k_s } \left( s \right)ds \geqslant 0
$$ For every sub-curve $\alpha \subset \gamma $. And then prove that $k_s(s) \ge 0$ I have no idea how to attack this problem, intuitively I can see the result.",['differential-geometry']
366103,Justification for this manipulation in a proof of the first variation of energy formula,"As a part of my current homework assignment, I am to derive the first variation of energy identity. Working out the problem with my friends, we came to exactly the same argument as presented in these notes (I have cut out some irrelevant parts from the presentation there, but kept the explanation of terminology and notation; at any rate, I am just using the notes to save myself the work of typing the whole thing). I understand every step except the second: $\color{blue}{\bf \large (3)}$ $\nabla$ is a metric connection and $\langle\,\cdot\,,\,\cdot\,\rangle$ is symmetric $\color{blue}{\bf \large (4)}$ $\nabla$ is torsion-free (this is mentioned above: ""where in the fourth equality..."") $\color{blue}{\bf \large (5)}$ $\nabla$ is a metric connection $\color{blue}{\bf \large (6)}$ fundamental theorem of calculus What is the justification for step $\color{red}{\bf (2)}$ ? We have an ordinary scalar function on $[a,b]\times (-\epsilon,\epsilon)$ , which for convenience let's name $h$ : $$h(t,s)=\langle \dot{\gamma}_s(t),\dot{\gamma}_s(t) \rangle.$$ We take the partial derivative of $h$ w.r.t. $s$ , which is again a scalar function on $[a,b]\times(-\epsilon,\epsilon)$ . Now, I'm fine with the equality $$\dot{\gamma}_s(t)=\frac{\partial f}{\partial t},$$ but how exactly does the differentiation $\dfrac{\partial}{\partial s}$ get turned into $\nabla_{\tfrac{\partial f}{\partial s}}$ ?","['riemannian-geometry', 'differential-geometry']"
366116,Composition of a continuous function with functions that converge uniformly,"Here is problem that appeared in one of the past final exams for my introductory real analysis course, that I am having hard time to solve. It is Question 5 in 8 of the following file: http://www.math.ubc.ca/Ugrad/pastExams/Math_321_April_2008.pdf Let $\{f_n\}_{n\in\mathbb{N}}$ be a uniformly convergent sequence of
  continuous real–valued functions defined on a metric space $M$ and let
  $g$ be a continuous function on $\mathbb{R}.$ Define, for each
  $n\in\mathbb{N}$, $h_n(x) = g(f_n(x))$. (a) Let $M = [0, 1]$. Prove that the sequence
  $\{h_n\}_{n\in\mathbb{N}}$ converges uniformly on $[0, 1]$. (b) Let $M = \mathbb{R}$. Either prove that the sequence
  $\{h_n\}_{n\in\mathbb{N}}$ converges uniformly on $\mathbb{R}$ or
  provide a counterexample. I have proved part (a). I am having trouble with part (b). It seems to me that part (b) has a counterexample. This is because, the key point in part (a) is that $g$ is uniformly continuous on $[0,1]$ (because $[0,1]$ is compact), but in part (b) compactness is removed. So my guess is that counter-example will involve something like $g(x)=x^2$ (which is an example of continuous function which is not uniformly continuous on $\mathbb{R}$). Is this guess correct? What would be an example of uniformly convergent sequence $\{f_n\}$ of functions in this case? I would very much appreciate any help!","['convergence-divergence', 'continuity', 'real-analysis']"
366118,Does the equality $\lim_{x\rightarrow\infty} f(g(x)) = f(\lim_{x\rightarrow\infty} g(x))$ hold?,"Does the equality $\lim_{x\rightarrow\infty} f(g(x)) = f(\lim_{x\rightarrow\infty} g(x))$ hold? If it is not always true, what is the condition that makes the equality hold?",['limits']
