question_id,title,body,tags
2176849,A method to count the number of monic irreducible polynomials of degree 2 or 3 or 4 in $\mathbb F_{p}[x]$,"$p$ is a prime number.
I use the method as following to find out the number of monic irreducible polynomials of degree 2. Count the number of monic not irreducible polynomials of degree 2: If a monic polynomial $f(x)\in \mathbb F_{p}$ is of degree 2 and not irreducible, $f(x)=(x-\alpha)g(x)$ for some $g(x) \in \mathbb F_{p}$. As   $deg(g)=2-deg(x-\alpha)=2-1=1$.So $g=x-\beta$ for some $\beta \in \mathbb F$. Thus all the not irreducible monic polynomial of degree $2$ is of the form $f(x)=(x-\alpha)(x-\beta)$. If $\alpha =\beta$ $f(x)=(x-\alpha)^2$. We have $p$ polynomials $f(x)$ in this form. If $\alpha \neq \beta$ , we have ${p \choose 2}=\frac{p!}{2!(p-2)!}=\frac{p(p-1)}{2}$ polynomials $f(x)$ in this form. Hence, the total number of monic not irreducible polynomials of degree $2$ in $\mathbb F_{p}[x]$ is $p+\frac{p(p-1)}{2}=\frac{p(p+1)}{2}$ Monic polynomial of degree $2$ in $\mathbb F_{p}[x]$ has the form $x^2+ax+b$ with $a,b \in\mathbb F_{p}[x]$. Thus we have $p^2$ such polymials. Thus the number of irreducible polynomial of degree $2$ in $\mathbb F_{p}[x]$ is $p^2-\frac{p(p+1)}{2}=\frac{p^2-p}{2}$ But when I turn to find out the number of monic irreducible polynomials of degree 3. I find that all the not irreducible monic polynomial of degree $2$ is of the form $f(x)=(x-\alpha)(x^2+cx+d)$,so it seems that we have $p$ choices of $\alpha$,  $p$ choices of $c$ and $p$ choices of $d$, thus we have $p^3$ not irreducible polynomials of degree $3$ in $ \mathbb F_{p}$. But monic polynomial of degree $3$ in $\mathbb F_{p}[x]$ has the form $x^3+a_{1}x^2+a_{2}x+a_{3}$ with $a_{1},a_{2},a_{3} \in\mathbb F_{p}[x]$. Thus we have $p^3$ such monoc polymials. So I think  my counting when I try degree 3 is wrong. I use the method as following to find out the number of monic irreducible polynomials of degree 4. By using counting argument I have found that the number of irreducible polynomial of degree $2$ in $\mathbb F_{p}[x]$ is $p^2-\frac{p(p+1)}{2}=\frac{p^2-p}{2}$. And we have $p^3-\frac{2p^3+p}{3}=\frac{p^3-p}{3}$ monic irreducible polynomials of degree $3$. EDIT: Now I am doing the case of degree 4, could someone please have a look to my counting to see if it is correct? Thanks so much! Monic polynomials of degree $4$ is of the form $x^4+a_{1}x^3+a_{2}x^2+a_{3}x+a_{4}$ where$a_{1},a_{2},a_{3},a_{4}$. Thus we have $p^4$ of them. Let $f(x)$ be a not irreducible monic polynomials of degree $4$, then there are several possible form of $f(x)$ (i):$f(x)=(x-\alpha)(x-\beta)(x-\gamma)(x-\delta)$ with $\alpha,\beta,\gamma,\delta \in \mathbb F_{p}$. (ii):$f(x)=(x-\alpha)(x-\beta)(x^2+ax+b)$ with $\alpha,\beta,a,b \in \mathbb F_{p}$ and $(x^2+ax+b)$ is a irreducible polynomial of degree $2$. (iii)$f(x)=(x^2+ax+b)(x^2+cx+d)$ with $a,b,c,d \in \mathbb F_{p}$ and $(x^2+ax+b), (x^2+cx+d)$ are irreducible polynomials of degree $2$. (iv)$f(x)=(x-\alpha)(x^3+ax^2+bx+c)$ with $\alpha,a,b,c \in \mathbb F_{p}$ and $(x^3+ax^2+bx+c)$ is a irreducible polynomial of degree $3$.
We have $p+3{p \choose 2}+3{p \choose 3}+{p \choose 4}$ monic reducible polynomials of degree $4$ of form (i).
$(p+{p \choose 2})\frac{p^2-p}{2}$  monic reducible polynomials of degree $4$ of form (ii).
$\frac{p^2-p}{2}+{\frac{p^2-p}{2} \choose 2}$  monic reducible polynomials of degree $4$ of form (iii).
and $p(\frac{p^3-p}{3})$ monic reducible polynomials of degree $4$ of form (iv). But the wolfram alpha does not give me the desire number of number of irreducible polynomials of degree 4. So I guess something is wrong. Could someone help me to find out what is wrong here and show the correct way? Thanks in advance!","['irreducible-polynomials', 'polynomials', 'proof-verification', 'combinatorics', 'field-theory']"
2176868,What does $\sim$ mean in math and statistics?,"For example in the following picture above, the red sentence means what exactly with this $\sim$ symbol?","['statistics', 'probability', 'notation']"
2176998,Show that every composite Fermat number is a pseudoprime base 2.,"Question: Show that every composite Fermat number $F_m=2^{2^m}+1$ is a pseudoprime base 2. Hint: Raise the congruence $2^{2^m}\equiv-1($mod $F_m)$ to the $2^{2^m-m}$th power. Even with the hint, I'm fairly lost. I understand that $2^{2^m}+1\equiv0($mod $ F_m)$, so clearly it follows that $2^{2^m}\equiv-1($mod $F_m)$. I also know that for a positive integer $b$, if $n$ is a composite positive integer and $b^n\equiv b($mod $n)$ then $n$ is called a pseudoprime to the base $b$. So, we want to show that $2^{F_m}\equiv2($mod $F_m)$ I don't understand how the hint helps us do this. Thank you for your help, I'm happy to answer any questions that come up.","['number-theory', 'pseudoprimes', 'fermat-numbers']"
2177006,How to define a plane based on 4 points,"I have a set of points $A,B,C,D$ in 3-D space:
$$A = (x_a, y_a, z_a)$$
$$B = (x_b, y_b, z_b)$$
$$C = (x_c, y_c, z_c)$$
$$D = (x_d, y_d, z_d)$$ They belong to a 3-D figure, e.g.: I'm trying to define the entire plane $ABCD$ by a set of functions, based on the points I have: $ x(y,z)$ defines the x-coordinates on the plane, depending on y and z $ y(x,z)$ ... $ z(x,y)$ ... I'm finding it a difficult problem. This, I think, is the best way to solve the problem, but maybe there is a better way based on basis vectors (which I also have). The reason: I'm trying to develop a molecular dynamics software that can handle any periodic system, so I'm trying to find the way to universalize periodic boundary conditions. For example, in a simple cubic system, I would just do (this pseudocode): move_the_particle();    
if (particle[x] < -x_length/2)
        particle[x] = particle[x] + x_length ...to check if my particle escaped the box on the left side, and move it over to the right side. If this is unclear please let me know. I can try to clarify further.","['periodic-functions', 'plane-geometry', 'computer-science', 'geometry', 'linear-algebra']"
2177146,"If $f,g,h$ are functions such that $f \circ g=f \circ h \implies g=h$, how to prove that $f$ is injective?.","Let $f:B \rightarrow C$ be a function. Assume that for every pair of functions $g, h:A \rightarrow B$ such that $f \circ g=f \circ h$, we know that $g=h$. Prove that $f$ is injective. I'm questioning about the validity of the theorem, if this theorem is true, I'm gonna try to show it: Let $y_1,y_2 \in B$ such that $f(y_1)=f(y_2)$, I need show that $y_1=y_2$, but how i can show this?, I can´t say: Let $y_1=g(x_1)$ and $y_2=h(x_2)$ for some $x_1, x_2 \in A$ because the theorem don't say me if $g$ and $h$ are surjective functions. I appreciate your help.",['elementary-set-theory']
2177157,"How to solve the differential equation $x^2 \cos{y} + \dfrac{dy}{dx} x \sin{y} =\sin^2y$, given in a competitive exam? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question How do I solve $x^2 \cos{y} + \dfrac{dy}{dx} x \sin{y} =\sin^2y$? I found the problem in a competitive exam.",['ordinary-differential-equations']
2177204,On matrix tridiagonalization,"Can any matrix $X \in \mathbb R^{n \times n}$ be decomposed into a tridiagonal matrix, i.e., $$X = P^{-1}DP$$ where $P \in \mbox{SO}(n)$ and $D$ is tridiagonal ?","['tridiagonal-matrices', 'matrices', 'matrix-decomposition', 'orthogonal-matrices', 'linear-algebra']"
2177215,Asymptotic probability that two binomial variables are equal,"$X_1,\ldots,X_k$ are independent random variables distributed like $\text{Binomial}[n,p]$. What is the probability that they are all equal, as a function of $k$ $p$ and $n$, when $n$ is very large? Currently I have two solutions. Solution A is general but quite informal. When $n$ is large, a Binomial random variable behaves like a normal random variable, and most of its probability mass is concentrated in the interval $\mu \pm \sigma$, where $\mu$ is the mean value and $\sigma$ is the standard deviation. So we can approximate the variables as being drawn independently at random from a set with $2\sigma$ elements. After the first variable is determined, each of the remaining $k-1$ variables has probability $\approx 1/(2\sigma)$ to have the same value, so the probability that all are equal is $\approx 1/(2\sigma)^{k-1}$.  Here $\sigma=\sqrt{p (1-p) n}$, so the probability is: $${1 \over (4 p (1-p) n)^{(k-1)/2}} $$ Solution B is more formal but works only for $p=1/2$ and $k=2$ variables. Define $Y_2 := n - X_2$. So the event $X_1=X_2$ is identical to the event $X_1+Y_2 = n$. $Y_2$ is distributed like $\text{Binomial}[n,1-p]$, but here $p=1-p$ so it is distributed like $X_1$. Therefore $X_1+Y_2$ is distributed like $\text{Binomial}[2n,1/2]$ and the probability that it equals $n$ is just:  ${2n\choose n}2^{-2n}$. By Stirling's approximation , the binomial coefficient is $\approx {4^n \over \sqrt{\pi n}}$, so the probability that $X_1=X_2$ is approximately: $$ {1\over \sqrt{\pi n}}$$ This is a constant times the outcome of Solution A, which means that both solutions are at least asymptotically correct. What is a solution that works for every $p$ and $k$? EDIT: See also: What is the probability that two univariate Gaussian random variables are equal?",['probability']
2177262,Let $\{ x_n \}_{n=1}^{\infty}$ such that $x_{n+1}=x_n-x_n^3$ and $0<x_1<1$,"Let $\{ x_n \}_{n=1}^{\infty}$ such that $x_{n+1}=x_n-x_n^3$ and $0<x_1<1, \ \forall n\in \mathbb{N}.$ Prove: $\lim_{n \rightarrow \infty} x_n=0$ Calculate$\ \lim_{n \rightarrow \infty} nx_n^2$ Let $f$ be a differentiable in $\mathbb{R}$ such that $f(n)=x_n,\forall n\in \mathbb{N}.$ Prove that if $\lim_{x \rightarrow \infty} f'(x)$ exists, then it equals to $0$. I proved the first, but struggling with the next two. My intuition tells me that $\lim_{n \rightarrow \infty} nx_n^2=0$, and I tried to squeeze it but got stuck. I tried to prove by contradiction the third, and I managed to contradict the limit is greater than $0$, but couldn't get further. Any help appreciated.","['derivatives', 'sequences-and-series', 'calculus', 'limits']"
2177270,Why is it that $x^4+2x^2+1$ is reducible in $\mathbb{Z}[x]$ but has no roots in $\mathbb{Q}$?,$\textbf{ Lemma:}$  A non constant primitive polynomial $f(x) \in \mathbb{Z}[x]$ is irreducible in $\mathbb{Q}[x]$ if and only if $f(x)$ is irreducible in $\mathbb{Z}[x]$. I am reading a book in which it is given that $f(x)=x^4+2x^2+1$ is primitive in $\mathbb{Z}[x]$ and it has no roots in $\mathbb{Q}$ but it is reducible over $\mathbb{Z} $ as $f(x)=(x^2+1)(x^2+1)$. My question is doen't it conradict this lemma?  since irreducible over $\mathbb{Z}$ and irreducible over $\mathbb{Q}$ is the same thing for primitive polynomial.,"['irreducible-polynomials', 'abstract-algebra', 'ring-theory', 'roots']"
2177273,Using the pigeonhole principle prove that the decimal expansion of $1/k$ for any $k\in\Bbb N_{>0}$ becomes cyclic at some point [duplicate],"This question already has answers here : How can I prove that all rational numbers are either terminating decimal or repeating decimal numerals? (4 answers) Closed 7 years ago . Prove if $k$ is any positive integer, the decimal expansion of $\frac{1}{k}$ eventually gets into a repeating cycle. I'm stuck here , i've thought about applying the pigeonhole principle and induction here but to no avail... My answer is asking for a proof through pigeonhole principle or induction.. the one linked does not show those.. Please don't close this.","['combinatorics', 'pigeonhole-principle', 'induction']"
2177344,$\lim_{x \to 0}\lfloor\frac{\tan^{98}x - \sin^{98} x}{x^{100}}\rfloor=?$,"fine the limit : $$\lim_{x \to 0}\lfloor\frac{\tan^{98}x - \sin^{98} x}{x^{100}}\rfloor=?$$ We denote the floor funtion by $\lfloor x\rfloor$.
My try: \begin{align}
\lim_{x \to 0}\frac{\tan^{n}x - \sin^{n} x}{x^{n + 2}} &= \lim_{x \to 0}\frac{\tan x - \sin x}{x^{3}}\cdot \sum_{i = 0}^{n - 1}\frac{\tan^{n - 1 - i}x}{x^{n - 1 - i}}\cdot\frac{\sin ^{i}x}{x^{i}}\\
&= \frac{1}{2}\cdot\sum_{i = 0}^{n - 1}1\\
&= \frac{n}{2}
\end{align}
So:
\begin{align}
\lim_{x \to 0}\frac{\tan^{98}x - \sin^{98} x}{x^{100}}&=49\\
\lim_{x \to 0}\left\lfloor\frac{\tan^{98}x - \sin^{98} x}{x^{100}}\right\rfloor&=49 
\end{align} is this correct?",['limits']
2177349,How to calculate limit $S_n=\sum\limits_{k=1}^n\sin\Big( \dfrac{k\sqrt{k}}{n^2\sqrt{n}}+\dfrac{1}{n^2}\Big)$,"How do I calculate the following limit:
 $$\lim\limits_{n \to +\infty} S_n=\lim\limits_{n \to +\infty}\sum\limits_{k=1}^n\sin\Big( \dfrac{k\sqrt{k}}{n^2\sqrt{n}}+\dfrac{1}{n^2}\Big) = \text{?}$$
I think that you need to use Riemann sum, but I don't understand how to get rid of the sine. Please provide a hint (and not the full solution).","['real-analysis', 'sequences-and-series', 'limits']"
2177407,Finding a subgroup of index 2 using a representation,"Let $G$ be a group and $\rho \colon G \rightarrow GL(k, \mathbb{C})$ a representation. The question is to show that for an element of order 2, $g$ in $G$, $\chi(g) \equiv k$ (mod 4) given that there is no subgroup of index 2 in $G$. I have managed to reduce the problem to showing that if there is an element $A \in im(\rho)$ with $det(A) = -1$ then there must be a subgroup of index 2 in $G$. If I let $\phi = det \circ \rho$ I can show that $\frac{G}{ker(\phi)}$ is abelian and of course $A \not \in ker(\phi)$. Any hints on where to go from here? I'm hoping that $ker(\phi)$ is going to be the subgroup I'm looking for as I can't see anything else to test.","['representation-theory', 'group-theory']"
2177454,Moment Generating Function with Taylor Series,"I'm studying moment generating function(MGF). In the video it says The MGF of a random variables(r.v.s.) is $M_x(t) = E (e^{tx})$ and for discrete r.v.s. is $M_x(t) = \sum_x e^{tx} P(X=x)$ I do understand that, for example the MGF of Bernoulli (X~Bern(p)) is $M(t) = E(e^{tX}) = P(X=1)*e^t + P(X=0) * 1 = pe^t + q$ What I do not understand is from the book ""Introduction to probability"" by Joseph K. Blitzstein and Jessica Hwang page 256 talks about the topic of ""Moments via derivatives of the MGF"" it says. ""Given the MGF of X, we can get the nth moment of X by evaluating the nth derivative of the MGF at $0: E(X^n) = M^{(n)}(0)$
This can be seen by noting that the Taylor expansion of M(t) about 0 is $$M(t) = \sum_{n=0}^\infty M^{(n)}(0) \frac{t^n}{n!}$$ While on the other hand we also have $$M(t) = E(e^{tX}) = E(\sum_{n=0}^\infty X^n \frac{t^n}{n!})$$
"" How to go from $E(e^{tX}) $ to $ E(\sum_{n=0}^\infty X^n \frac{t^n}{n!})$ ??? I only know taylor series around 0 (Maclaurin series) of $e^x = \sum _{n=0} ^\infty \frac{x^n}{n!} $ but in this case it is $e^{tX}$ which also involve the r.v.s. X. How to calculate that??? how to take derivative?","['taylor-expansion', 'probability', 'sequences-and-series', 'moment-generating-functions']"
2177469,Dense subspaces of $L^p$,"Let $B$ a separable Banach space and $\nu$ a Borel probability measure on $B$. 
Let us consider the space $C^1_b(B)$ of the continuously differentiable functions bounded and with bounded derivative. 
Is it true that $C^1_b(B)$ is dense in $L^p(B,\mu)$ for every $p \ne \infty$?","['functional-analysis', 'geometric-measure-theory', 'measure-theory']"
2177497,Equivalence of two definitions of modular forms,"I am a theoretical computer science student, so have only a limited background in complex geometry. As part of my study on Ramanujan graphs, I came across modular forms. As I understand it, there are different ways to approach and define a modular form $f$ of weight $k$:
1)  A holomorphic function $f:\mathbf{H} \to \mathbb{C}$ that is also holomorphic at the limit $i \infty$ and satisfies a function equation
$$f\left( \frac{az+b}{cz+d} \right)= (cz+d)^k f(z)$$
for every
$$\begin{pmatrix}
a & b\\c & d
\end{pmatrix} \in SL(2,\mathbb{Z})$$ 2) A complex-valued function $f$ on the set of lattices in $\mathbb{C}$ defined as follows: for a lattice $\Lambda=<1,z>$, $f(\Lambda)=f(z)$ is an analytic function of $z$, and for an equivalent lattice $\alpha \Lambda$,
$$f(\alpha \Lambda)=\alpha^{-k}f(\Lambda)$$ So on the one hand, a modular form is a function defined on the upper half plane $\mathbf{H}$ that is ""well-behaved"" with respect to the action of the modular group $\Gamma$. On the other hand, a modular form is a function on the set of lattices in $\mathbb{C}$ whose ""growth"" is prescribed.
I am trying to see how to relate the two definitions and intuitively understand their equivalence. The first definition tells us that given $f(z)$, the values taken by $f$ on the orbit of $z$ under the action of $\Gamma$ is fully known. So if this orbit is a lattice in $\mathbf{H}$ (which can then be extended to a lattice in $\mathbb{C}$), then we would find some common ground between the two definitions. So my questions are:
1) Is the orbit of $z \in \mathbf{H}$ under the action of $\Gamma$ a lattice in $\mathbb{C}$? If so, do we have a simple expression for a basis of this lattice? 2) Conversely, can every lattice in $\mathbb{C}$ be expressed (or at least equivalent to) as the orbit of some element of $\mathbf{H}$ under the action of $\Gamma$ ? I apologize if these questions are trivial, but most references on these topics seem to require too many prerequisites and are way too rigorous to be of much immediate help. Thanks.","['complex-geometry', 'group-actions', 'complex-analysis', 'elliptic-curves', 'modular-forms']"
2177524,"How to find the numbers of sets of positive numbers $\{a,b,c\}$ such that $(a)(b)(c) =2^{4}3^{5}5^{2}7^{3}$?","How to find the numbers of sets of positive numbers $\{a,b,c\}$ such that $(a)(b)(c) =2^{4}3^{5}5^{2}7^{3}$ ? $$\binom{4+2}{2} \binom{5+2}{2}  \binom{2+2}{2} \binom{3+2}{2}$$ This would give the number of tuples $(a,b,c)$. But isolating the individual sets $\{a,b,c\}$ is harder as there would be duplicates. Any ideas how to do it?","['combinatorics', 'elementary-number-theory']"
2177575,Partitions of a multiset into blocks of same size,"I've got a combinatorial question: Let $n, k\ge 1$ integers and let $S$ be a finite multiset of order $nk$ (counted with multiplicities). I want to count partitions of $S$ into blocks subject to the following conditions: (1) Each block has got exactly k elements (counted with multiplicities) (2) The order of the blocks in the partition is irrelevant, i.e. permuting the blocks inside the partition doesn't give rise to a new partition (3) The order of the elements in a block is relevant, i.e. permuting the elements in a block can give rise to a new block Example : $S=\{1,2,2,3\}$, $n=k=2$. Then $\{\{1,2\},\{2,3\}\}$ is such a partition and $\{\{2,3\},\{1,2\}\}$ is the same one but $\{\{1,2\},\{3,2\}\}$ is a different one.
 Counting this way we get six partitions:
 $\{\{1,2\},\{2,3\}\}, 
\{\{1,2\},\{3,2\}\}, \{\{1,3\},\{2,2\}\}, \{\{2,1\},\{2,3\}\}, \{\{2,1\},
\{3,2\}\}, \{\{2,2\},\{3,1\}\}$ Is there a name for this kind of partition? 
Does anybody know a formula for the number of such partitions? Asymptotics? 
Clearly, if all elements in $S$ are different the searched for formula is $(nk)!/n!$. But what if there are multiple elements?","['combinatorics', 'multisets', 'set-partition']"
2177598,"Squaring a polar equation, extraneous solutions?","If I have the equation $y=x$, it provides a graph of a single line.  However, if I square both sides, I have $y^2=x^2$ whose graph is both $y=x$ and $y=-x$.  Should the same be true for polar equations and graphs instead of rectangular?  For instance, say I have $$r=\frac{4}{1+\sin \theta}$$ and want to write it as a rectangular equation.  If I first graph it by hand, I can see it looks like it is producing a downward opening parabola.  And, in fact, if I find its rectangular equation, it is $y=-\frac{x^2}{8}+2$.  However, in obtaining that equation, I had at one point $r=4-y$.  I then squared both sides to obtain $r^2$ on the left so I could substitute $r^2=x^2+y^2$.  Why didn't I create extraneous solutions?  I know I did not because the polar graph of $r=\frac{4}{1+\sin \theta}$ and rectangular graph of $y=-\frac{x^2}{8}+2$ match up.  Thanks!","['polar-coordinates', 'calculus', 'functions', 'algebra-precalculus', 'graphing-functions']"
2177657,Patterns for eigenvalues of Vandermonde matrix,"Let $A$ be a Vandermonde type matrix $A =
\begin{bmatrix} 
1 & 1 & \dots & 1 \\
x_1 & x_2 &\dots & x_n \\
\dots& \dots & \dots&  \dots\\
x_1^{n-1} &x_2^{n-1} &\dots & x_n^{n-1}
\end{bmatrix}$ When I was testing some such real matrices with positive entries for their eigenvalues I have noticed that eigenvalues are also real and positive. How such property (if true in general case) can be explained ? Moreover in examples   which I tested (when it was assumed for $i<j$ that  $x_i <x_j$) the greatest eigenvalue was always close to the greatest value in this matrix and the smallest one always less than $1$. How to explain also these facts ? Examples of $3 \times 3$ matrices generated from natural numbers $A =
\begin{bmatrix} 
1 & 1 &    1 \\
2 & 3   & 5 \\
4 & 9   & 25
\end{bmatrix}$ Eigenvalues: $\{ 27.09 , \ 0.12  , \ 1.79 \} $ $A =
\begin{bmatrix} 
1 & 1 &    1 \\
3 & 7   &  11 \\
9 & 49   & 121
\end{bmatrix}$ Eigenvalues: $\{ 125.63,  \ 0.37 , \ 3.03  \} $ Of course if two eigenvalues in the examples above are rather small then the third must be rather great from the trace of the matrix, but why these two must be small ? If the answer for general case is hard to find let dimension of a
matrix be specific i.e. $ 3 \times 3$ and entries only natural.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2177692,Corollary of Fubini's Theorem: the product of integrals is the integral of the product,"Consider the function
$$
f(x,y)=h(x)\times g(y)
$$
By Fubini's Theorem
$$
\int_{X}h(x)dx \times \int_{Y}g(y)dy= \int_{X\times Y}h(x)g(y)d(x,y)
$$ Questions: (1) Is this correct? (2) Can be extended to the product of any number of functions? (3) Are there particular conditions to check other than measurability?","['integration', 'measure-theory', 'riemann-integration']"
2177726,Show that the number of solutions of the equation $f(x) = 4x^5+x^3-2x-m$ has at least one solution and at most 3 solutions,"Show that the number of solutions of the equation $f(x) = 4x^5+x^3-2x-m$ has at least one solution and at most 3 solutions for any real values of $m$. What I have done so far: $f(x)=4x^5+x^3-2x-m\\f'(x)=20x^4+3x^2-2=(4x^2-1)(5x^2+2)\\f(m)=4m^5+m^3-3m=m(4m^4+m^2-3)=m(4m^2-3)(m^2+1)$ What I do next is to find test certain values of $m$ Case 1: $-\frac 34<m\le0\\
f(-\frac 12)=\frac 34-m>0\\
f(-2)=-132-m<0\\
f(\frac 12)=-\frac34-m<0\\
f(2)=132-m>0$ Hence, by the Intermediate Value Theorem, I can conclude that there are at least 3 roots in Case 1. I will use Rolle's Theorem to prove that there are exactly 3 roots when $-\frac34<m\le0$ Case 2: $0<m<\frac34$ I will use similar argument to show that there are exactly 3 roots. Case 3: $m\le-\frac{\sqrt3}{2}$ $f(-\frac 12)=\frac 34-m<0\\
f(m)<0\\
f(\frac 12)=-\frac34-m<0$ And yes, this is one of the problems I have encountered. I can sort of argue that $x=-\frac12$ is the local maximum and $x=\frac12$ is the local minimum and hence, there are no roots. I can even use Rolle's Theorem to show that there cannot be any roots. However, what value of $m$ can I substitute to show that in this particular case, there is at least one root by the Intermediate Value Theorem. (After doing this, I can use Rolle's Theorem to show that there is only 1 root). I will encounter the same problem for $m\ge\frac{\sqrt3}{2}$ But the greatest problem I have now is what values of $x$ do I substitute into $f(x)$ for $-\frac{\sqrt3}{2}<m\le-\frac34$ and $\frac34\le m<\frac{\sqrt3}{2}$ to show that there is at least 1 solution and at most 3 solutions? Any help or any other solutions are appreciated! Thank you!","['real-analysis', 'calculus', 'functions']"
2177743,Find the maximum and minimum of a function (involving an trigonometric integral),"Question: How can I find the maximum and minimum of this function, for a value of $\text{n}$? $$\text{G}_\text{sc}\left(\text{n}\right)=\alpha\cdot\left(1+\epsilon\cos\left(\theta\right)\right)^2\tag1$$ Where $\alpha\space\wedge\space\epsilon\in\mathbb{R}^+$ And, for $\theta$ we know that: $$\frac{\text{n}}{\text{A}}\int_0^{2\pi}\frac{1}{\left(1+\epsilon\cos\left(x\right)\right)^2}\space\text{d}x=\int_0^\theta\frac{1}{\left(1+\epsilon\cos\left(x\right)\right)^2}\space\text{d}x\space\Longleftrightarrow\space\theta\left(\text{n}\right)=\dots\tag2$$ Where $\text{A}\in\mathbb{R}$ and $0<\text{n}\le\text{A}$ and $\color{red}{\text{when you solve}}$ $\color{red}{\theta}$ $\color{red}{\text{we will get that}}$ $\color{red}{\theta}$ $\color{red}{\text{a function is of}}$ $\color{red}{\text{n}}$ My work: In order to find the minumum and maximum: $$\text{G}'_\text{sc}\left(\text{n}\right)=\frac{\text{d}}{\text{d}\text{n}}\left(\text{G}_\text{sc}\left(\text{n}\right)\right)=0\tag3$$ But I do not understand how to proceed.","['optimization', 'trigonometry', 'calculus', 'integration', 'definite-integrals']"
2177749,What's the number of poker hands where one of the cards is Ace of clubs and none of the other cards can be Aces or clubs,"There are $5$ cards in a poker hand. Fix one of them to be Ace of clubs. Then there are $12$ ranks and $3$ suits left. First we choose $4$ ranks out $12.$ Then we choose $1$ suit out of $3$ for each chosen rank, like so: $\binom{12}4 \binom31^4$ but this doesn't agree with the given answer. What might have gone wrong?","['combinatorics', 'probability', 'discrete-mathematics']"
2177754,"Integral of $ 1 \, / \, (1 + a \, \cos(x) )$","Let $a<1$ be a positive constant. How can I compute the following integral? $$
\int_{0}^{2\pi} \frac{1}{1 + a \, \, \cos(x)} dx 
$$","['real-analysis', 'integration', 'trigonometry', 'definite-integrals']"
2177807,"Is this a composition of two functions of random variables, or two independent functions?","I'm reviewing some topics that were tricky for me in the past, and this problem from Grimmett and Stirzaker (4.7.1) came up: Let $X,Y,Z$ be independent and uniformly distributed on $[0,1]$. Find the joint density function of $XY$ and $Z^2$, and show that $P(XY < Z^2) = \frac{5}{9}$. I'm not clever with these types of problems, so I just stick with the change of variables, but I don't know if I'm preparing the right statements to evaluate $P(XY < Z^2)$ (as the second part of the problem is clearly just a self-test): Let $u = xy, v = x, w = z^2 \implies t_1(v) = v, t_2(u,v) = \frac{u}{v}, t_3(w) = \sqrt{w}$. Compute Jacobian: \begin{equation}
     \left| \begin{matrix} 0 & \frac{1}{v} & 0 \\
                           1 & -\frac{u}{v^2} & 0 \\
                           0 & 0 & \frac{1}{2\sqrt{w}}
     \end{matrix} \right| = -\frac{1}{2v\sqrt{w}}
   \end{equation} Stating the joint density function: \begin{equation}
   f_{U, V, W} (u, v, w) = f(t_1(v), t_2(u,v), t_3(w))|J(v,w)|
   \end{equation} (in the domain of the variables) \begin{equation}
   f_{U, W} (u, w) = f(x, \frac{u}{x}, \sqrt{w}) \left| \frac{1}{2x\sqrt{w}}\right|
   \end{equation} (for $w \geq 0$) Assuming I have that right, I think $P(XY < Z^2)$ can be phrased as \begin{equation}
   P(XY < Z^2) = F_{U} (u=w) = \int_{-\infty}^w \int_{-\infty}^\infty f(x, \frac{u}{x}) \left| \frac{1}{x}\right| dxdu
   \end{equation} (for $w \geq 0$), since $Z^2$ is independent of $XY$. I don't have any confidence in what I did in (3) and (4), however (despite the $XY$ function being derived as an example in the same text), and I'm not sure how to come up with a PDF to substitute in the last integrand to compute with. Am I on the right track?","['multivariable-calculus', 'jacobian', 'random-variables']"
2177817,Determine the eigenvector and eigenspace and the basis of the eigenspace,"The yellow marked area is correct, so don't check for accuracy :) $A=\begin{pmatrix} 0 & -1 & 0\\  4 &  4 & 0\\  2 &  1 & 2
\end{pmatrix}$ is the matrix. Characteristic polynomial is $-\lambda^{3}+6\lambda^{2}-12\lambda+8=0$ The (tripple) eigenvalue is $\lambda=2$. Calculate the eigenvectors now: $\begin{pmatrix}
-2 & -1 & 0\\  4  &  2 & 0\\  2  &  1 & 0 \end{pmatrix} \begin{pmatrix} x\\  y\\  z \end{pmatrix}= \begin{pmatrix} 0\\  0\\  0
\end{pmatrix}$ We get the equations: $I: -2x-y=0 \Leftrightarrow y = -2x$ $II: 4x+2y=0$ $III: 2x+y=0 \Leftrightarrow 2x-2x=0 \Leftrightarrow 0=0$ We see that in every eequation $z$ is unknown, so we can choose an arbitrary $z$. $x\begin{pmatrix}
1\\ 
-2\\ 
z
\end{pmatrix}$ and this is the eigenspace...? And what is the basis of this eigenspace? Can I just set $x=1$ and some value for $z$? So this would be a correct basis of the eigenspace: $\begin{pmatrix}
1\\ 
-2\\ 
3
\end{pmatrix}$? Now we need three linearly independent eigenvectors but I couldn't find them as I always got linearly dependent vectors... I need a detailled, not too complicated answer that explains it well and I will give that answer a nice bounty (up to 200 rep) because I couldn't find another site explaining this correctly to me and I'm really in need of it.","['matrices', 'eigenvalues-eigenvectors', 'algebra-precalculus', 'linear-algebra']"
2177862,Why should one be fascinated with $e^{i \pi} +1 = 0$? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question I know some people say that $e^{i \pi} +1= 0$ is cool because it links fundamental yet disparate constants. But to me, the existence of a ""nice"" equation like this is not surprising. For hundreds of years mathematicians have been trying to make everything as ""nice"" as possible; we define trigonometry to line up with the informal notion of the unit circle (as opposed to the $2$ units circle, or the $.352546...$ units circle), we always try to make sure our functions are differentiable or at least continous when we extend them, we define complexes so that the reals are nicely embedded in them, etc. So to me it just doesn't seem that surprising that after hundreds of years of fine-tuning our definitions to be nice, the definitions come full circle and spit out some nice equations.","['complex-analysis', 'complex-numbers', 'soft-question']"
2177866,Prove if $f(x+y)=f(x)f(y)$ then $f(x)=a^x$,"Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that $f(x+y)=f(x)f(y), \ \forall x,y\in \mathbb{R}$. Prove: if $f \not \equiv 0$, then there exists constant $a$ such that $f(x)=a^x.$ I tried to deduce the result from this question and this question , but had hard time with it. Any help appreciated.","['continuity', 'calculus']"
2177882,Let $f:\mathbb{R}^n\rightarrow\mathbb{R}$ be differenciable and $[\nabla f(y)-\nabla f(x)]\cdot (y-x)\ge 0$. Is $f$ a convex fuucntion?,"Let $f:\mathbb{R}^n\rightarrow\mathbb{R}$ be differenciable and $[\nabla f(y)-\nabla f(x)]\cdot (y-x)\ge 0\ \forall x,y\in \mathbb{R}^n$. Is $f$ a convex function? Since $f$ is differentiable then convexity is equivalent to the condition $$f(y)\ge f(x)+\nabla f(x)\cdot (y-x)\ \forall x,y\in \mathbb{R}^n\ \ \ \ \ \ (1)$$ So If there is a function whose derivative satisfy $$[\nabla f(y)-\nabla f(x)]\cdot (y-x)\ge 0\ \forall x,y\in \mathbb{R}^n\ \ \ \ \ \ (2)$$ but $(1)$ is not true then the statement is false. I know that $$f(y)\ge f(x)+\nabla f(x)\cdot (y-x)\ \forall x,y\in \mathbb{R}^n\Rightarrow [\nabla f(y)-\nabla f(x)]\cdot (y-x)\ge 0\ \forall x,y\in \mathbb{R}^n,$$ but I can't prove the conversely or find a counterexample.","['derivatives', 'convex-analysis']"
2177916,Different proof that $\overline{A\cup B}\subset \overline{A}\cup \overline{B}$,"As Paul Erdos once said, first find a proof that works, and then go looking for the beautiful proof. Before looking at the proof my textbook gives for $\overline{A\cup B}\subset \overline{A} \cup \overline{B}$, I attempted something myself. What I did is nothing like the proof given in the text, and might be needlessly complicated, but I wanted to check that it still works. I don't always trust my judgment that the mathematical logic is correct, so sometimes an extra set of eyes is useful. First, perhaps I should define $\overline{A}$. It is the set of adherence points of the set $A\subset X$ meaning it is the set of all points $x\in X$ such that any neighborhood of $x$ also contains points of $A$. Now, here is my proof: Suppose $x\notin \overline{A}\cup \overline{B}$. Then, $x\notin \overline{A}$ and $x\notin \overline{B}$. $x\notin \overline{A}$ implies that $\exists$ neighborhood $U(x)$ such that $x \in U(x)$ and $U(x) \cap A =\emptyset$, which implies that $x\in A^{c}$. Likewise, $x\notin \overline{B}$ means that $\exists$ a neighborhood $W(x)$ such that $x\in W(x)$ and $W(x)\cap B = \emptyset$. This implies that $x\in B^{c}$. So, $x\in A^{c}$ and $x\in B^{c}$, which means that $x \in A^{c}\cap B^{c}\subset\overline{A^{c}\cap B^{c}}\, \implies \, x\notin \overline{A\cup B}$ So, I showed that $x\notin \overline{A}\cup \overline{B}\, \implies \, x\notin \overline{A \cup B}$, which is the contrapositive of $x\in \overline{A \cup B}\, \implies \, x\in \overline{A} \cup \overline{B}$, at least I think it is. I've experienced some setbacks as of late that have caused me to lose a little bit of confidence in my judgment when it comes to mathematical logic. Thanks in advance.","['general-topology', 'alternative-proof', 'elementary-set-theory', 'proof-verification']"
2177922,A communication complexity problem for finding near matches,"I am stuck with this problem that looks like it should be a counting argument.  Consider two binary strings $A$ and $B$. String $A$ is of length $n$ and $B$ is of length $2n$. Alice has both strings $A$ and $B$ and wants to send one single message to Bob (who doesn't get to see the strings at all) telling him approximately how close $A$ is to every substring of $B$ of length $n$.  In particular, for every substring of $B$ of length $n$,  Bob wants to be able to work out the Hamming distance between $A$ and that substring to within a multiplicative factor of $2$ just from this single message. As an example, let $A = 101$ and $B = 011001$. The true Hamming distances are $2, 2, 1, 1$.  Bob, having received the message from Alice, has to output 4 numbers. Bob's  outputs values must be in the range 2 to 4 for the first two numbers and 1 to 2 for the next two. Assuming that Alice and Bob can agree on a determinisic protocol
  beforehand, how many bits does Alice have to send to Bob? Now posted to https://mathoverflow.net/questions/264959/a-communication-complexity-problem-for-finding-near-matches .","['information-theory', 'combinatorics', 'computational-complexity']"
2177955,Fermat's test to prove pseudoprimes,I'm self teaching myself number theory as I'm doing a course in cryptography and anything I've found hasn't helped. The question I'm stuck on is: Use Fermat Test to show 19 is a pseudoprime base 3 Thank you for any help.,"['number-theory', 'pseudoprimes']"
2177966,Weakly compactness of a set of finitely additive measures,"Let $\Gamma$ be an infinite set and denote its power set by $\wp(\Gamma)$. A finitely additive measure on $\Gamma$ is a function $\lambda : \wp(\Gamma) \to \mathbb{R}$ such that $\lambda(A \cup B) = \lambda(A) + \lambda(B)$, for all disjoint $A,B \subset \Gamma$. Let $X$ be a (real) Banach space and denote by $\ell_\infty(\Gamma,X)$ the Banach space of all bounded functions $f : \Gamma \to X$, equipped with the supremum norm. If $X= \mathbb{R}$, we'll denote $\ell_\infty(\Gamma,X)$ simply by $\ell_\infty(\Gamma)$. The dual space $\ell_\infty(\Gamma)^*$ is isometrically isomorphic to the space of all bounded finitely additive measures on $\Gamma$, equipped with the variation norm. Given $x = (x_i)_{i \in \Gamma} \in \ell_\infty(\Gamma,X)$ and $A \subset \Gamma$, denote by $x \chi_A$ the element of $\ell_\infty(\Gamma,X)$ defined by $x\chi_A(j)= 0$, if $j \notin A$, and $x\chi_A(j) = x_j$, if $j \in A$. A sequence $(x^*_n)_{n \geq 1}$ in the dual space of $X$ is weak$^*$-null if $x_n(x) \to 0$, for all $x \in X$. I'm trying to follow the proof of Lemma 2 from Leung-Räbiger's paper . This lemma states: Lemma: Let $(x_n)_{n \geq 1}$ be a bounded sequence in $\ell_\infty(\Gamma,X)$ and $(x^*_n)_{n \geq 1}$ be a weak$^*$-null sequence in $\ell_\infty(\Gamma,X)^*$. Define finitely additive measures $(\lambda_n)_{n \geq 1}$ on $\Gamma$ by $\lambda_n(A) = x^*_n(x_n\chi_A)$, for all $A \subset \Gamma$. Then $(\lambda_n)_{n \geq 1}$ is relatively weakly compact in $\ell_\infty(\Gamma)^*$. They begin by arguing by contradiction. I'm having trouble with the following argument: If $(\lambda_n)_{n \geq 1}$ is not relatively weakly compact, then we may assume that there exist disjoint subsets $(A_n)_{n \geq 1}$ of $\Gamma$ and $\varepsilon > 0$ such that $|\lambda_n(A_n)| > \varepsilon$ for all $n \geq 1$. Any help or hint regarding this step of the proof will be highly appreciated.","['banach-spaces', 'measure-theory', 'compactness']"
2177982,Combinatorics logic,"Say you have a bag with one black, two white and three red balls. How
  many different ways can you pick the the balls? Now i've tried to visualise the problem in my head, and written it down on my paper but i still can't grapple with the logic when it comes to combinatorics. Yes i understand that we have a total of 6 balls. Which means that for the first ball we choose we have 6 positions, now here is where my logic gets skewed. Since the second ball we pick could be white, and there are two white balls. Then the we dont have 5 places to put the second one. This is because one black, followed by two whites, and three reds is the same combination if you get what i mean. There is where my intuition gets lost. Any help would be greatly appreciated.","['permutations', 'combinatorics', 'probability']"
2177988,Calculate max size of rectangle in pie chart,"I'm trying to get the maximum possible width and height of a rectangle inside a pie chart. All fields have the same angle. $\alpha$ is never bigger than $90^{\circ}$. I have the variables $\alpha$, $r$, $b$ and I know that $w = 3h$. I'm searching for $w$, $h$ and $P_1 (x_1, y_1)$. I'm a programmer, so I'm not that good with math and I have to translate this to Code afterwards. Thanks for your help! Edit: I'm using Javascript. Thanks to Paul . He explained me, that I have to use radians instead of degree using Math.tan . In addition, there is no Math.cot in Javascript. That's why I had to create two more functions. const tan = (deg) => Math.tan(deg * Math.PI / 180);
const cot = (value) => 1 / tan(value);",['geometry']
2178029,Ignoring absolute values in differential equation,Consider the differential equation $\frac{dy}{dx} = \frac{3y - 1}{x}$. It is separable and we get $\ln|3y - 1| = C + \ln(|x|^3)$. On wolfram the solution is reported as $y(x) = c_1 x^3 + \frac{1}{3}$ but wouldn't this ignore solutions like $y(x) = \frac{|x|^3 + 1}{3}$?,"['integration', 'ordinary-differential-equations']"
2178037,Does Euclidean geometry require a complete metric space?,"Note: I'm not sure how to tag this question so please fix tags as appropriate and necessary. This question relates to Tarski's axioms of Euclidean geometry, not Hilbert's axioms. It says on the same page (Theorem 3.1 -- see also this related question on Math.SE ) that: For every model of Euclidean Plane Geometry (using Tarski's axioms) there is a real closed field $R$ such that $M \cong R \times R$ as models. From what I gather from nLab's page on real closed fields , these are strictly more general than the real numbers, for example the real algebraic numbers is also a real closed field. However, the real algebraic numbers are not metrically complete . (I think.) In other words, not every Cauchy sequence converges. Question: How can a real closed field, which is not metrically complete, serve as a model for Euclidean plane geometry? In particular, how can the real algebraic numbers serve as a model for Euclidean geometry? For example, such a field cannot express the ratio of the circumference of a circle to its diameter in Euclidean plane geometry since $\pi$ is transcendental and thus only contained in the metric completion of the rational numbers, but not the (real) algebraic completion. One of Tarski's axioms is described on the nLab page as being a ""Dedekind cut axiom expressed in first order terms"". If I remember real analysis correctly, Dedekind cuts allow one to construct the metric completion of the rational numbers (the real numbers). So if one of Tarski's axioms implies metric completeness (does it not? if not, why doesn't it?), then how can the real algebraic numbers, which aren't metrically complete (I think) serve as a model? I'm not sure if the Cantor-Dedekind axiom is one of Tarski's axioms or the same as the aforementioned ""Dedekind cut axiom"". If Tarski's axioms don't require a metrically complete space, then is the Cantor-Dedekind axiom not generally valid for models of Tarski's axioms? The answers to this related question seem to suggest that $\mathbb{Q}$ is insufficient for Euclidean geometry, which makes sense since $\mathbb{Q}$ is not real closed. However, it is unclear from the answers given if the problems with $\mathbb{Q}$ arise only because of the non-existence of algebraic irrational numbers (e.g. $\sqrt{2}$ ) or also because of the non-existence of transcendental irrational numbers, $\pi$ . The latter would imply that the real algebraic numbers are also insufficient for Euclidean geometry. Also, one of the axioms given for Euclidean plane geometry (on p. 171, M.2) in Agricola, Friedrich's Elementary Geometry is that the plane is a complete metric space. I had assumed that these axioms were just a (possibly less rigorous) rewording of Tarski's axioms, but if non-complete metric spaces also serve as models for Euclidean geometry, then it would seem that this axiom is an invention/addition of the authors, which perhaps should have been mentioned explicitly.","['real-analysis', 'model-theory', 'axioms', 'euclidean-geometry', 'soft-question']"
2178077,Prove $\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}}$,"Let $f:[a,b]\rightarrow \mathbb{R}$ be a positive and differentiable function. Prove: $$\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}}$$ I tried to apply the MVT and make some algebraic manipulations, but got stuck. Any help appreciated.","['derivatives', 'calculus']"
2178106,Basic Quantile Calculation,"I have a slight confusion with the current method of calculation of a quantile for a give ungrouped distribution. To give you an example, i shall refer to calculation of a Quartile, but this doubt applies to any quantile. Let's take a distribution as follows: 0,2,4,9,10 n=5 The formulae to calculate the lower quartile and upper quartile are as follows: Q1=(n+1)/4 Q3=3*(n+1)/4 So as per these formulae, the upper and lower quartile should appear at positions 1.5 and 4.5 We can all agree here that the median of the distribution is 4 (i.e., position 3) However, to derive the upper and lower quartile values, we have to assume that the end point values of the range are 0 and 10 (i.e, position 1 and 5). Hence by this logic, and assuming the end point values of the range are 0 and 10 (position 1 and 5) and the median as 4 (position 3), we should get the upper and lower quartile positions as 2 (i.e. (1+3)/2) and 4 (i.e. (5+3)/2) respectively. However, going by the accepted formula we see that we see that the lower quartile 1.5 is a median position between a non-existant position 0 and 3, and the upper quartile 4.5 is a median position between position 3 and a non-existant position 6. Can anyone please clarify why the non-existant positions are assumed? Perhaps I'm looking at it from a wrong angle, so please let me know.","['statistics', 'quantile']"
2178172,Evaluation of $\sum\limits_{k=1}^n\left(x^{k}+\frac{1}{x^k}\right)^k$,"Can anyone find a simplified expression for the sum $\displaystyle \sum_{k=1}^n\left(x^{k}+\frac{1}{x^k}\right)^k$? I have tried expanding the first few terms but it gets a little messy with no clear leads. I suspect formulae for geometric series may come into it somehow, but at the moment it isn't clear how to start.","['algebra-precalculus', 'binomial-theorem', 'sequences-and-series']"
2178178,Geometry book using Erlangen program,"Long ago I saw a book on the AMS (American Mathematical Society) or the MAA (Mathematical Association of America) bookstore website that would do geometry following the Erlangen program. In the introduction, the authors indicated that a second book would be written about non-Euclidean geometry, and I then decided to wait until this second book was written. Now I was thinking about  buying the  book but I cannot find it any more. 
I remember it was written by two authors -- one I think from the University of Texas and I think it was published in 2009. Does anyone recognise this book? Update 01/10/2017 I found the book I was looking for ( but I do think gave some wrong hints) The book I was looking for was: Continuous Symmetry,  from Euclid to Klein By Barker and Home, American Mathematical Society 2007, (mbk-47) ISBN 987 0 8218 9300 3 (No part two yet , but hope it will come some time) Thanks for all other suggestions and sorry for all wrong hints","['reference-request', 'book-recommendation', 'geometry']"
2178271,Algebra on Equivalent Infinitesimals,"Question: Is algebra on equivalent infinitesimals valid? Example: $$\sqrt{1+x} - 1 \sim_0 \frac{x}{2} \longrightarrow \sqrt{1+x} \sim_0 \frac{x}{2} + 1$$ I'm aware that both the left and right equalities are true, but is this just a coincidence that it looks like I added $1$ to both sides of the left equality to get the the right?","['algebra-precalculus', 'infinitesimals', 'analysis', 'limits']"
2178272,Finding limit using inequalities: $\liminf \frac{a_{n+1}}{a_n} \le \liminf (a_n)^ {1/n}\le\limsup (a_n)^ {1/n}\le \limsup \frac{a_{n+1}}{a_n}$ [duplicate],"This question already has an answer here : Inequality involving $\limsup$ and $\liminf$: $ \liminf(a_{n+1}/a_n) \le \liminf a_n^{1/n} \le \limsup a_n^{1/n} \le \limsup(a_{n+1}/a_n)$ (1 answer) Closed 7 years ago . The purpose of this exercise is to prove that $\lim \frac{n}{(n!)^{1/n}}=e$ when $n$ goes to infinity. In order to find the limit, the following inequality is used when $n$ goes to infinity with ${a_n}$ a sequence of positive terms: $$ \liminf \frac{a_{n+1}}{a_n} \le \liminf (a_n)^ {1/n}\le\limsup (a_n)^ {1/n}\le \limsup \frac{a_{n+1}}{a_n}$$ What is the proof of this inequality?","['limsup-and-liminf', 'real-analysis', 'inequality', 'limits']"
2178274,How can I find the monodromy of a cyclic galois cover of the affine line minus a few points?,"Consider the following cyclic covering of the affine line minus a few points:
$$
\text{Spec}(\mathbb{C}[t,x]/(x^n - t(t-1)(t-2))) \to \mathbb{A}^1_t - \{ 0, 1, 2 \}
$$
How can I find the local monodromy representations around one of these points of degeneracy?","['galois-theory', 'covering-spaces', 'representation-theory', 'algebraic-geometry']"
2178277,Find unbiased estimator,"Let $X_i$ be observations from $U[0, \theta]$ (continuous uniform distribution). Find unbiased estimator for $\frac{1}{\theta}$ What i did is: let $\theta^* = g(X)$ be an estimator. Than, to be unbiased, the following must hold: $$\int\limits_{0}^{\theta} \theta^*(x) \frac{1}{\theta} dx =\frac{1}{\theta}\int\limits_{0}^{\theta} g(x) dx = \frac{1}{\theta}\big[G(\theta) - G(0) \big]$$ where $G' = g$, so the clue is to find some function $g$ with such properties. This is the part where i need help.","['statistics', 'estimation', 'probability']"
2178323,Peculiar pattern concerning primes and semi-primes?,"Define the function $f:\mathbb N^+\to\mathbb N^+$ as: $f(n)$ is the least semi-prime $pq$ such that $n+p+q$ is a prime. (One must prove that this really is a function, but it should be and my tests doesn't contradicts that). There is a sequence of numbers 
$$21\to 14\to 15\to 10\to 9\to 6\to 4$$ such that if $f(n)\neq 4$ is a number in this sequence, then $f(n+1)$ equals to the successor of $f(n)$ in the sequence. This is tested for all values of $n<100,000$. I would like a proof of that $f$ really is a function, that is, for all 
  $n\in\mathbb N^+$ it exists a semi-prime $pq$ with the property that
  $n+p+q\in\mathbb P$. Also, if anyone can find a counter-example from the peculiar pattern, I would like to see that. And off course, if anyone can explain the pattern I would be very glad.","['conjectures', 'computational-mathematics', 'prime-numbers', 'functions']"
2178346,Prove that $\sum\limits_{cyc}\frac{a}{a^2+ab+b^2+3}\leq\frac{1}{2}$,"Let $a$, $b$ and $c$ be non-negative numbers. Prove that:
  $$\frac{a}{a^2+ab+b^2+3}+\frac{b}{b^2+bc+c^2+3}+\frac{c}{c^2+ca+a^2+3}\leq\frac{1}{2}$$ I think this inequality is very interesting because most of the contest's inequalities are homogeneous, 
but this inequality is non-homogeneous. Testing for $c=0$ gives
$$\frac{a}{a^2+ab+b^2+3}+\frac{b}{b^2+3}\leq0.455...<\frac{1}{2}.$$
For $b=c=0$ we obtain something obvious. One of the standard ways to prove these inequalities is to try to make a homogenization. By the way, trying of homogenization gives a wrong inequality:
$$\sum\limits_{cyc}\frac{a}{a^2+ab+b^2+3}\leq\sum\limits_{cyc}\frac{a}{2\sqrt{3(a^2+ab+b^2}}.$$
Thus, it remains to prove that
$$\sum\limits_{cyc}\frac{a}{\sqrt{3(a^2+ab+b^2)}}\leq1,$$
which is wrong for $c=0$ and $a\rightarrow+\infty$. Also we can try the following. We know that $\sum\limits_{cyc}\frac{x}{2x+y}\le1$ for positives $x$, $y$ and $z$. Indeed, by C-S we obtain:
$$1-\sum_{cyc}\frac{x}{2x+y}=1-\frac{3}{2}-\sum_{cyc}\left(\frac{x}{2x+y}-\frac{1}{2}\right)=\frac{1}{2}\sum_{cyc}\frac{y}{2x+y}-\frac{1}{2}=$$
$$=\frac{1}{2}\sum_{cyc}\frac{y^2}{2xy+y^2}-\frac{1}{2}\geq\frac{1}{2}\frac{(x+y+z)^2}{\sum\limits_{cyc}(y^2+2xy)}=\frac{1}{2}-\frac{1}{2}=0.$$
Thus, it's enough to prove that
$$a^2+ab+b^2+3\geq2(2a+\sqrt{ab})$$ 
because if it's true so 
$$\sum_{cyc}\frac{a}{a^2+ab+b^2+3}\leq\sum_{cyc}\frac{a}{2(2a+\sqrt{ab})}=\frac{1}{2}\sum_{cyc}\frac{\sqrt{a}}{2\sqrt{a}+\sqrt{b}}\leq\frac{1}{2}.$$
But the inequality $a^2+ab+b^2+3\geq2(2a+\sqrt{ab})$ is wrong! Try $a=2$ and $b=\frac{1}{4}$ Also we can try to use a full expanding (I tried!) and to hope to use AM-GM, but I think this way is very ugly and it's probably nothing. Any hint would be desirable. Thank you!","['algebra-precalculus', 'contest-math', 'inequality']"
2178350,Can a Homogeneous Differential Equation be Nonlinear?,"First of all, I am not asking about $v=y/x$ transformation kinda homogeneous. Can we say  this nonlinear differential equation is homogeneous $$y^{\prime}=ty^2.$$ Here there is no term without $y$, this is okay. But this is nonlinear equation. I saw here some discussions and some people said it is just for linear equations. I want to give two links: Dummies Series (assumes it can be nonlinear) (I also see some universities documents too). Wolfram Math World (assumes it has to be linear) Which one is the definition: 1) No term without $y$, 2) Linear and No term without $y$. 3) $y$ is a solution, then $\lambda y$ is solution for all $\lambda \in \mathbb R$. Considering the references, I will use the 3rd one. This option is also meaningful.","['reference-request', 'ordinary-differential-equations', 'definition']"
2178372,Show that $\mathfrak{F}_A$ is a filter on $X$.,"Let $A\subseteq X$ be fixed non-empty subset of $X$. Show that the set of subsets of $X$ that contains $A$ is a filter on $X$. My proof-trying. Let $\mathfrak{F}_A:=${$B\subseteq X:$ $A\subseteq B$}. Initially, assume $A\in\mathfrak{F}_A$ and $A\subseteq B\subseteq X$. We need to show that $B\in\mathfrak{F}_A$. Since $A\subseteq X$, $A\subseteq A$ and $ B\subseteq X$,  $B\subseteq B$ then $B\in\mathfrak{F}_A$. Can you check my proof-trying ? Secondly, assume $A,B\in\mathfrak{F}_A$, we need to show that $A\cap B\in\mathfrak{F}_A$. So, what should I do? Finally, we need to show that $\emptyset$ is not in $\mathfrak{F}_A$ and $X\in\mathfrak{F}_A$. Can you help?","['filters', 'elementary-set-theory']"
2178391,How is this Taylor's Theorem?,"When doing A-levels, we showed that any $n$th degree polynomial function $p(x-a)$ can be expressed in terms of its $n$ derivatives $$p(x)=\sum_{i=0}^n \frac{p^{(i)}(a)}{i!}(x-a)^n$$ and this was the Taylor's theorem that we learned. Now at university, in our Analysis II course, we did the following theorem, also dubbed Taylor's theorem: If $f:[a,b]\to\mathbb R$ is a continuous function that is differentiable on  $(a,b)$, and $x,x+h\in(a,b)$, then $f(x+h)-f(x)=f'(x+\theta h)h$ for some $\theta\in(0,1)$. Which we proceeded to prove using the mean value theorem. This seems to me to be quite an unrelated theorem - does it have anything to do with the polynomial expansion in terms of derivatives?","['taylor-expansion', 'calculus', 'analysis']"
2178401,A paratopological group $T_1$ that is not $T_2$?,"A group $G$ endowed with a topology is called a paratopological group if the multiplication $G\times G\to G$ is continuous. It is known every $T_1$ topological group is completely regular, and I've seen mentioned in several places that in the class of paratopological groups $T_1$ does not even imply the Hausdorff separation axiom. But I don't know examples. Can anyone help me to find some example about this?","['general-topology', 'topological-groups']"
2178416,Only one chart to parameterize a unit-cylinder,"I want to parameterize a unit-cylinder $x^2+y^2=1$ with only one chart in a complete atlas (the sets must be open). The cylinder is in $\mathbb{R}^3$. One way to do the parametrization with two charts is:
$$ \textbf{x}(u,v)=(\cos u, \sin u, v)$$
with $v\in \mathbb{R}$ and $0<u< 2\pi$ (this is the open set $U_1=(0,2\pi)\times \mathbb{R}$) and
$$ \textbf{y}(\overline{u}, \overline{v}) = (\cos \overline{u}, \sin \overline{u}, \overline{v})$$
with $\overline{v}\equiv v\in \mathbb{R}$ and $-\pi < \overline{u} < \pi$ (this is the open set $U_2 = (-\pi,\pi)\times\mathbb{R}$). So the atlas is $\{ \textbf{x}, \textbf{y}\}$ into $U_1 \times U_2.$ So, it has two charts $\textbf{x}$ and $\textbf{y}$ defined in open sets (this is important: the set $(0,2 \pi]\times \mathbb{R}$ is not open , and a parametrization has to be defined into an open set). Do someone know an atlas with only one chart? For example, with a reparametrization. The only thing I know is that the atlas with one chart exists in this case$^*$. * Introduction to Topological Quantum Matter & Quantum Computation, Tudor D. Stanescu PD: Something similar in General Relativistic to changing Schwarzchild coordinates by Kruskal–Szekeres ones to extend the well-behaved domain.",['differential-geometry']
2178502,"If g∘f is Onto and g is Onto, Can f Ever Not Be Onto?","Let $f: A\to B$ and $g: B\to C$ be functions, $g∘f$ be onto, and $g$ be onto. Does it follow that $f$ is necessarily onto? Give either a proof or counterexample. Work So Far If g is onto, then there is at least one $b∈B$ for every $c∈C$. However, the next portion, $g∘f$, is re-written as $g(f(x))$, which is also onto. I don't understand what statement I can make with that information given.","['logic', 'functions']"
2178569,Show that $P = A(A^TA)^{-1}A^T$ is a projection matrix.,"Let $A\in \mathbb{R^{m\times n}}$ have full column rank, $b\in \mathbb{R^m}$ with $b \neq 0$ Show that $P = A(A^TA)^{-1}A^T$ is a projection matrix. Onto what space does $P$ project? I tried looking at videos,at textbooks, and lecture notes. Which version best answers the question? version 1: Since $ATA$ is an invertible matrix, take the normal equation $A^TAx=A^Tb$ and solve for $x$. We get, $x=(A^TA)^{-1}A^Tb$. For $Ax=Pb$, we have $Ax$ as a projection, and $P$ is an orthogonal projector onto the range of $A$. It follows, $A(A^TA)^{-1}A^Tb = Pb$, $\forall b$. Generally, for any matrices $M$ and $N$ s.t. $Mx=Nx$,$\forall x \Rightarrow M=N$, thus $P=A(A^TA)^{-1}A^T$. $P$ projects a vector $b$ onto the spaced spanned by the columns of $A$. version 2 Given a matrix $A$, the projection of $b$ onto $C(A)$ is $P=Ax$, where $x$ solves $A^TAx=A^Tb$. Since A has full column rank, $A^TA$ is invertible. We write, the projection matrix is $P=A(A^TA)^{-1}A^T$. version 3 The vector $Ax$ is always in the column space of $A$. We project b onto a vector $P$ in the column space of $A$ and solve $Ax=P$. In matrix form, $A^T(b-Ax)=0 \Rightarrow A^TAx=A^Tb$. Since $A^TA$ is a square matrix, we multiply by $(A^TA)^{-1}$ In $n$ dimensions, $x=(A^TA)^{-1}A^Tb \Rightarrow P=Ax=A(A^TA)^{-1}A^Tb \Rightarrow P=A(A^TA)^{-1}A^T$",['linear-algebra']
2178572,Contour integral of $\frac{e^{-ux}}{Ax^2+Bx+C}$,"I'm having a little trouble figuring this one out. I've found the poles to be at $$\frac{-B\pm\sqrt{B^2-4AC}}{2A}$$ Am I right to assume the residues can be found by this? $$\text{Res}\bigg[ \lim_{s\to \frac{-B+ \sqrt{B^2-4AC}}{2A}}\frac{(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})} \\ +\lim_{s\to \frac{-B- \sqrt{B^2-4AC}}{2A}}\frac{(s-\frac{-B+ \sqrt{B^2-4AC}}{2A})\cdot e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})}\bigg]$$
My only problem is this seems a bit excessive. Is there an alternative, simpler way to find the residue here?","['complex-analysis', 'contour-integration']"
2178607,"If $\bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset$, then for each $\beta \in\Lambda$, $A_\beta \ne\emptyset$","Prove or disprove , where $A$ , $B$ are sets: a)Let $\{A_\alpha\, :\, \alpha \in \Lambda\}$ be an indexed collection of sets. If $\bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset$ , then for each $\beta \in\Lambda$ , $A_\beta \ne\emptyset$ . b) $A \subseteq (B \setminus A)$ if and only if $A = \emptyset$ . For (a) , I think it is false:
let $A_1=\{1,2\}$ , and $A_2=\emptyset$ , $A_3=\{5\}$ So, $A_1 \cup A_2 \cup A_3 =\{1,2,5\}$ For (b) , I think it is true , and I know how I can prove it. Could you please check these for me?","['proof-writing', 'logic', 'elementary-set-theory']"
2178626,Deriving Parameterization of Great Circle,"I am trying to find a spherical parameterization of the great circle path on a sphere of radius R. I parameterize my sphere as follows: $(R\sin\theta\cos\phi, R\sin\theta\sin\phi, R\cos\theta)$. I know that the great circle is the intersection of a plane passing through the origin. The equation of such a plane is 
$ax+by+cz = 0$. According to this article http://sgovindarajan.wikidot.com/twosphere , by substituting $x,y,z$ into the equation of my plane I should be able to obtain: $\cot\theta = c_1(\cos(\phi + c_2))$ where $c_1$ and $c_2$ are simply constants. However, I cannot seem to see how the $\sin \phi$ disappears. I began by isolating the $\theta$'s and $\phi$'s. But I cannot seem to arrive at the above result. Is there a trigonometric property I should be using? Thanks!","['parametrization', 'differential-geometry', 'calculus']"
2178644,Local trivialization and local frame,"The textbook told me if $(\pi,E,M)$ is a vector bundle, if we have a local frame $s_i$ of $E$ over $U$ then forall vector $v_p$ at $p$ we have $$v_p=c_1s_1+\cdots+c_ks_k$$ Then we define k maps $c_i$ from $\pi^{-1}(U)$ to $\mathrm{R}$ , so we can define a local trivialization of $E$ over $U$ by setting： $$\Omega_U(p,v_p)=(p,c_1,…c_k)$$ But how can I prove that each $c_i$ is smooth?","['vector-bundles', 'differential-geometry', 'differential-topology']"
2178653,Induced isomorphism on elliptic curves,"Let $\Lambda_1$ and $\Lambda_2$ be lattices over $\mathbb{C}$ and $F(z)$ an entire function such that for all $\omega_1 \in \Lambda_1$ there exists an $\omega_2 \in \Lambda_2$ such that $F(z+\omega_1)=F(z)+\omega_2$ for all $z \in \mathbb{C}$. (i) Show that $F(z)$ is of the form $F(z)=Az+B$ for some $A,B \in \mathbb{C}$, and that $A\Lambda_1 \subset \Lambda_2$. In this case, $F$ induces a map between elliptic curves $\underline{F}:\mathbb{C}/\Lambda_1 \rightarrow \mathbb{C}/\Lambda_2$ which is an isomorphism if $A\Lambda_1=\Lambda_2$. (ii) Suppose that $\Lambda_1=<1,\tau_1>$, $\Lambda_2=<1,\tau_2>$. Show that $\underline{F}$ is an isomorphism iff $\tau_1=\frac{a\tau_2+b}{c\tau_2+d}$ where $ad-bc=\pm1$. I have already shown (i) to be true. For (ii), it is clear that since $A1,A\tau_1 \in \Lambda_2$, there exist integers a,b,c,d such that \begin{align*}
A\tau_1&=a\tau_2+b\\
A&=c\tau_2+d
\end{align*} Which gives $\tau_1=\frac{A\tau_1}{A}=\frac{a\tau_2+b}{c\tau_2+d}$, but I'm not sure how to proceed from here.","['complex-analysis', 'elliptic-curves']"
2178679,Mean value theorem for convex functions,"Let $f$ be a real function with left and right derivatives $f'_-$ and $f'_+$ on the open interval $(a,b)$, and continuous on $[a,b]$ (e.g., let $f$ be convex on $[a,b]$). Then, Is there something like the mean value theorem for $f$?","['derivatives', 'convex-analysis', 'calculus']"
2178808,Is there a name for this algebraic structure in which $a \cdot (b + c) = (a \cdot b) \cdot c$?,"Today I was toying around with reflecting points over other points, which I expanded to reflecting lists of points over other lists of points.  In the process, I found an interesting yet somewhat bizarre algebraic structure to describe what I was doing, and I would like to know if there exists a name for it or if similar structures have been studied previously. What follows is a description of the ""observed properties"" of this algebraic structure.  I'm not currently certain which properties should be considered axioms and which are derived from others. Let $(R, +, \cdot )$ be a set $R$ with two binary operations. Furthermore, each element of this set belongs to one of two possible ""types."" Each element of the first type (to be indicated with a subscript $_0$ such as $a_0$) represents a ""translation,"" while each element of the second type ($a_1$) represents a ""reflection.""  If a subscript is not provided then the relation should hold regardless of the type. Addition acts as a ""list-like"" operator, based on how it interacts with multiplication (described later).  It is associative but not commutative. $$(a + b) + c = a + (b + c)$$ When two elements are added, their types xor together. $$a_x + b_y = c_{x \oplus y}$$ Any element added to its negation (additive inverse) results in the identity. $$a + -a = I_0$$
$$a + I_0 = I_0 + a = a$$ Any type-$1$ element is its own negation, as is the identity, but all other type-$0$ elements do not equal their negation. $$a_1 = -a_1$$
$$I_0 = -I_0$$ Swapping the order of operands require that you negate both operands and the expression.  The negation does not ""distribute"" over addition. $$a + b = -(-b + -a)$$ I believe, but am not entirely certain, that $(R, +)$ qualifies as a group. The multiplication operation represents the translation/reflection of one element by/over another: reflection of $a_1$ over $b_1$ $$a_1 \cdot b_1 = c_1$$ $$a_1 \cdot a_1 = a_1$$ translation of $a_1$ by $b_0$ $$a_1 \cdot b_0 = c_1$$ reflection of $a_0$ over $b_1$ $$a_0 \cdot b_1 = -a_0$$ translation of $a_0$ by $b_0$ $$a_0 \cdot b_0 = a_0$$ The identity plays a special role here as well: $$a \cdot I_0 = a$$
$$I_0 \cdot a = I_0$$ Multiplication is a non-associative, non-commutative, yet flexible operation, meaning that the following always holds: $$(a \cdot b) \cdot a = a \cdot (b \cdot a)$$ Furthermore, $$(a \cdot b) \cdot -a = (a \cdot b) \cdot a = a \cdot (b \cdot a) = a \cdot (b \cdot -a)$$ My somewhat bizarre addition operation was constructed to give multiplication of property of ""folding over"" addition from the left. That is, $$a \cdot (b + c) = (a \cdot b) \cdot c$$
$$a \cdot (b + c + d + \ldots + y + z) = a \cdot b \cdot c \cdot d \cdot \ldots  \cdot y \cdot z$$ I call this ""folding"" based on programming terminology, and I think this property is one of the more interesting ones.  It follows from the above that there is no concept of left(?) division: $$a \cdot (b + a) = (a \cdot b) \cdot a = a \cdot (b \cdot a)$$
$$(b + a) \ne (b \cdot a)$$
$$a_0 \cdot b_0 = a_0 = a_0 \cdot c_0$$
$$b_0 \ne c_0$$ Multiplication also distributes right, similar to the concept of ""mapping"" in programming. $$(b + c) \cdot a = (b \cdot a) + (c \cdot a)$$ Negating the first argument of a multiplication expression is equivalent to negating the whole expression. $$-a \cdot b = -(a \cdot b)$$ There also also some other useful equations to relate addition, multiplication, and negation: $$-a + b + a = b \cdot a$$
$$a \cdot b = c \leftrightarrow c \cdot -b = a$$
$$a_0 \cdot b = a_0 \cdot -b$$ Again, I am not entirely confident on the self-consistency of these relationships.  I don't have a real axiomatization yet.  With the properties above I've been able to ""prove"" some simple equivalences such as $$c_x \cdot (c_x \cdot a_1) \cdot b_x = c_x \cdot (b_x \cdot a_1 \cdot c_x)$$ which corresponds to this diagram (which uses ""r"" for ""reflection"" instead of ""$\cdot$""): Have similar algebraic structures been named/studied before?  I am particularly interested in structures that obey $a \cdot (b + c) = (a \cdot b) \cdot c$.  If possible, I would also like to find ways to reduce the role of ""typing"" in the properties listed above.","['terminology', 'abstract-algebra']"
2178827,A method to evaluate functional roots of $e^x$,"I've an idea to find exact function $f(x)$ such that $f(f(x))=e^x$. But it involves solving complicated systems of non-linear equations, the skills for which I don't have. Here's how I intend to do it: The Taylor series of $e^x$ around $x=0$ is:
$$1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+......$$
If we assume our required function $f(x)$ to be:
$$f(x)=a_nx^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+......a_2x^2+a_1x+a_0$$
i.e. a polynomial of degree $n$. From that we can get $f(f(x))$. I think it can be proved that the  $f(f(x))$ that we get will have terms containing all the powers of $x$ ranging from $x^{(n^2)}$ to $x^0$ (i.e. a constant term). Now, when $x$ is small the higher power terms don't matter, so we ignore the terms containing $x^{n+1}$, $x^{n+2}$.........$x^{(n^2)}$. After ignoring these terms, the remaining terms contain these powers of $x$: $x^0$, $x$, $x^2$,........$x^n$. Now, we compare the coefficients of these terms with the coefficients of the like powers of $x$ in the Taylor series of $e^x$. In this way, we get $n+1$ equations in $n+1$ variables. Now, we solve these equations to get the coefficients $a_0,a_1,a_2......a_n$. These will be functions of $n$ (I think). Now we apply $\lim_{n\rightarrow \infty}$ to these functions to get the exact value of coefficients. It would be a stressful task to solve those non-linear equations to get the coefficients in terms of $n$. But would this method work? EDIT: Even if $x$ is not small, the higher power terms can be ignored because the higher power terms will have very large factorials in their denominators. Also, we're applying $\lim_{n\rightarrow \infty}$ in the end and $\lim_{n\rightarrow \infty}\frac{x^n}{n!}=0$ for any finite $x$. EDIT:By using a first degree polynomial, I got this function, which when applied twice to $c$ gives you exactly $a^c$(not approximately because I didn't have to ignore any terms in case of a first degree polynomial) :
$$x\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$
 Problem is it itself depends upon $c$, so I guess there's a family of these square-root functions.
Similarly, the $n^{th}$ root of $a^x$ at $x=c$ is:
$$x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)}{\sum_{k=0}^{n-1}(a^c\log_ea)^{\frac{k}{n}}}$$
$$=x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)((a^c\log_ea)^{\frac{1}{n}}-1)}{a^c\log_ea-1}$$ At $x=c$, my square-root function is: $$c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$. Now substituting this in place of $x$ is my function gives, $$\left(c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}\right)\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$ $$=ca^c\log_ea+a^c(1-c\log_ea)$$ $$=a^c$$","['taylor-expansion', 'polynomials', 'systems-of-equations', 'exponential-function', 'functions']"
2178872,Prime factor of a composite three digit integer,"Q: What is the largest possible prime factor of a composite three digit integer? A: The largest $3$-digit is $999$ and $\sqrt {999}=31.61....$ and the largest prime factor less than this is $31$. The above is one example showing in the discrete math textbook under theorem If $n$ is composite, then $n$ has a prime divisor $p$ such that $p\le \sqrt n$. I found this question is unfounded. Let's say $37$. Basically it is one of the prime factor of $740$. So the answer provided is wrong. Am I right? I think the answer should be $499$.","['prime-numbers', 'discrete-mathematics']"
2178878,Subgroup of the free group on 3 generators,"I have a question about a subgroup of the free group on three generators, inspired by the following riddle: Can you hang a painting using a string and two nails so that if either of the nails is removed, the painting falls? [This has been mentioned on the stack before: see this post for a solution and discussion.] In short, this question is equivalent to asking if there is an element of the free group on $a$ and $b$ whose image under either quotient map $a \mapsto 1$ or $b \mapsto 1$ yields the identity element. (I'm thinking of the free group on two generators as the fundamental group of the plane minus two points; each generator corresponds to wrapping the string around one of the nails.) The commutator $[a,b] = aba^{-1}b^{-1}$ is the simplest solution: the set of elements that work is (I think) exactly the commutator subgroup of $\mathbb{Z} * \mathbb{Z}$. I want to know about the analogous question for the free group on $a,b$ and $c$: if $f_a, f_b$ and $f_c$ denote the quotients by the generators $a,b$ and $c$, respectively, then what is the intersection $H$ of the kernels of $f_a, f_b$ and $f_c$? $H$ is a normal subgroup of $\mathbb{Z} * \mathbb{Z} * \mathbb{Z}$, since the intersection of normal subgroups is normal, and it's non-trivial: one element that works is $[a,b]c[a,b]^{-1}c^{-1}$. Is there a nice characterization of this subgroup as in the case with two generators? This paper has a lot of cool results about this type of question, though their work is mostly about finding the shortest length word that satisfies the condition I'm talking about. As far as I can see, they don't discuss a characterization of all solutions to the painting puzzles. If we can find a solution for the free group on three generators, maybe we can generalize: let $H_k^n$ be the intersection of the kernels of all the quotient maps of the free group on $n$ generators by any distinct $k$ generators. (So $H_1^3$ is what I asked about above.) Is there a simple characterization of the elements in $H_k^n$, similar to $H_1^2$ being the commutator subgroup of $\mathbb{Z} * \mathbb{Z}$?","['normal-subgroups', 'group-theory', 'free-groups']"
2178906,complete graph as an union of bipartite graphs,I am trying to understand the proof of the theorem that says The complete graph $K_n$ can be expressed as the union of $k$ bipartite graphs if and only if $n\leq2^k$ using the mathematical induction . Graph Theory by West gives the proof but I don't understand it. I need some one help me to understand it and simplify the proof step by step,"['combinatorics', 'graph-theory', 'induction', 'proof-explanation']"
2178926,Finding the cardinality of a set given a set property.,"Suppose a set $B$ has the property that $|{X:X \in P(B), |X| = 6}| = 28$. Find $|B|$ My solution to this problem is as follows: We know we have $28$ subsets of $B$ with $6$ elements each, so we can write $\frac{n!}{(n-6)!6!} = 28$. We notice that $28=4*7$. We move $6!$ to the other side so now we have $(2*3*4*5*6)*(4*7) = \frac{n!}{(n-6)!}$. This means that $3*4*5*6*7*8 = n(n-1)(n-2)(n-3)(n-4)(n-5)$. It follows that $n = 8$, so $|B| = 8$. Question: Is this solution correct and a good way to go about this problem? Is there another way to think about this problem? Mention: This problem comes from The Book of Proof (Section 3.3 problem 4)",['combinatorics']
2178952,Is it possible for a 3 by 3 matrix to use Trace-Determinants plane to see convergency?,"I am showing in a report the trace det graph if solutions to different equations for linear systems will convert (attractor) or divert (repulsor). Is it possible to draw a 3D graph showing the correlation between the Trace(A) and Det(A) for a 3 by 3 linear system to show if the system will converge or not, in the same way you would for a 2 by 2 system.",['ordinary-differential-equations']
2178973,Constructing a convex function with prescribed Hessians at two given points,"Given two positive definite matrices $A, B \in \Bbb R^{n \times n}$, is there a way to construct a convex function $f: \Bbb R^n \to \Bbb R$ such that $$\nabla^2f(x)=A \qquad \text{and} \qquad \nabla^2f(y)=B$$ for two distinct $x,y \in \Bbb R^n$ (say $x=0_n$, $y=1_n$)? I've tried the usual suspects (stuff with quadratics, exponentials, etc) without going anywhere.","['hessian-matrix', 'convex-analysis', 'calculus']"
2178981,"Clarification of answer to ""Connectedness of the spectrum of a tensor product""","I recently came across this interesting question here on Mathematics Stackexchange: Connectedness of the spectrum of a tensor product Its only answer is excellent, but there is one part of it that I don't understand. The answerer claims that $i_g(X)\cap i_h(X)\neq\varnothing$ if and only if $gh^{-1}$ belongs to the inertia subgroup $I_x$ of some $x\in X$. First of all I believe that should be $h^{-1}g$ in stead of $gh^{-1}$, but more pertinently it seems to me that it is sufficient that $h^{-1}g$ belongs to the decomposition group $G_x$ of some $x\in X$. After all, if $i_g(x)=i_h(y)$ for some $x,y\in X$ then $x=y$ and $g(x)=h(y)=h(x)$, so $h^{-1}g\in G_x$. Although this is no problem for the validity of the proof, it does leave me wondering what I am misunderstanding, if anything at all. EDIT: I see now that if $h^{-1}g\in I_x$ then $gh^{-1}=h(h^{-1}g)h^{-1}\in I_{hx}$, so my first concern is solved. But my main point of confusion, that I believe it to be sufficient for $h^{-1}g$ (or $gh^{-1}$) to belong to a decomposition group in stead of an inertia group, remains.","['algebraic-geometry', 'connectedness', 'commutative-algebra', 'algebraic-number-theory', 'proof-explanation']"
2179043,"What does ""Kuratowski's theorem"" refer to in the context of dense linear subspaces being Borel?","Kuratowski was a busy man who showed many results in topology and functional analysis, so when a writer says that some result follows from ''Kuratowski's theorem"", it could apply to many different ones. I am currently studying ""Stochastic Partial Differential Equations: An Introduction"", by Wei Liu and Michael Röckner and in Chapter 4, they introduce the Gelfand triple $\left(V,H,V^*\right)$ and sketch the situation where they work in. For this Gelfand triple (or evolution triple), we have a reflexive Banach space $\left(V,\|\cdot\|_{V}\right)$ and a Hilbert space $\left(H,\langle\cdot,\cdot\rangle_{H}\right)$, such that $V \subset H$ and $V$ can be continuously and densely embedded in $H$. It also follows that $H^*$ can be densely embedded into $V^*$, by restricting the functionals on $H$ to $V$ (call this (isomorphic!) map $\rho$). As the Hilbert space $H$ and its dual are isomorphic by the Riesz representation map $\Phi$, we can identify $H$ and its image under the map $\rho\circ\Phi$; we will write $\bar{H}$ for $\rho(\Phi(H))$. Then, they claim that by Kuratowski's theorem , we know that 
$$
V \in \mathcal{B}(H) \quad \text{ and } \quad \bar{H}\in\mathcal{B}\left(V^*\right)
$$
but I don't know which theorem they refer to and that is my question. I've scoured the internet to find what they mean, but my attempts have not yet been fruitful, so I was wondering if any of you could help me out.","['functional-analysis', 'reference-request', 'topological-vector-spaces']"
2179077,WolframAlpha says limit exists when it doesn't?,"I was trying to calculate the following limit: $$
\lim_{(x,y)\to (0,0)} \frac{(x^2+y^2)^2}{x^2+y^4}
$$ and, feeding it into WolframAlpha, I obtain the following answer, stating the limit is $0$: However, when I try to calculate the limit when $x = 0$ and $y$ approaches 0, the limit is 1... Is the answer given by WolframAlpha wrong? or am I?","['multivariable-calculus', 'wolfram-alpha', 'limits']"
2179154,Prove $\lim_{x \rightarrow 0} \frac{f(x+g(x))-f(g(x))}{x}=f'(0)$,"Given $f:\mathbb{R}\rightarrow \mathbb{R}$ differentiable continuously, and $g:\mathbb{R}\rightarrow \mathbb{R} \ s.t.\lim_{x \rightarrow 0}g(x)=0$ $$\text{Prove:} \lim_{x \rightarrow 0} \frac{f(x+g(x))-f(g(x))}{x}=f'(0) $$ $f'(x)$ is continuous $\Rightarrow\lim_{x \rightarrow 0}f'(g(x))=f'(\lim_{x \rightarrow 0}g(x))=f'(0) $ By definition of the derivative: $\lim_{x \rightarrow 0} \frac{f(x+0)-f(0)}{x}=f'(0)$ How can I continue to get the result? Any help appreciated.","['derivatives', 'calculus']"
2179174,Raising Powers (Negative),"I'm playing around with Raising Powers and had a strange result (it's probably not strange but I simply don't understand it). $(-7)^2 = -49$ (wrong) $(-5)^3 = -125$ (correct) $(-3)^4 = -81$ (wrong) $(-2)^5 = -32$ (correct) My question here is, why are some of the above apparently cancelling out the negative(s) whilst others aren't?","['algebra-precalculus', 'exponentiation']"
2179204,Can calculus be used for real number?,"I recently learned that there is no positive infinitesimal real number. The only infinitesimal real number is 0. For calculus integral, dx is always interpreted as infinitesimal small but non-zero which contradict with the property of real number. And I don't think zero would be a valid infinitesimal number for calculus as real numbers divided by zero is undefined. So my questions are:
1) Can we use calculus for real number in strictly speaking?
2) Is it correct to say the infinitesimal concept for calculus doesn't exist under real number system?","['real-analysis', 'infinitesimals', 'calculus', 'limits']"
2179232,How can I prove that this infinite product equals $0$?,"I am having trouble to prove that $$\prod_{n=1}^\infty\frac{2n-1}{2n}=0$$
I know that the sequence of partial products $(p_n)$ converges to a limit $L\ge0$, because $$p_n=\frac{(2n)!}{2^{2n}(n!)^2}$$ is decreasing and bounded below by zero. I believe that proving that the limit equals zero would involve finding a sequence $(a_n) \to 0$ such that, eventually, $p_n \le a_n$; however, I could not find such sequence. How can it be done?",['real-analysis']
2179241,How to solve $\frac{\text{d}y}{\text{d}\tau} = -\varepsilon y/\left(1+\frac{k\Delta}{(ky+1)^2}\right)$,"If we take $$\frac{\text{d}y}{\text{d}\tau} = -\varepsilon y/\left(1+\frac{k\Delta}{(ky+1)^2}\right) \qquad\qquad (1)$$ with $y(0)=y_0$ then we can solve it as such:
\begin{align}
-\varepsilon\tau + C_0
&=
\int
\frac
{1+\frac{k\Delta}{\left(ky+1\right)^2}}
{y}
\ \text{d}y
\\
%%
&=
\int
\frac
{1}
{y}
%
+
%
\frac
{k\Delta}
{y\left(ky+1\right)^2}
\ \text{d}y\\
%%
&=
\log{y}
%
+
%
\frac{\Delta}{k}\log{\left(\frac{y}{k+y}\right)}
%
+
%
\frac{\Delta}{k+y}
\end{align} with
\begin{align}
C_0
&=
\log{y_0}
%
+
%
\frac{\Delta}{k}\log{\left(\frac{y_0}{k+y_0}\right)}
%
+
%
\frac{\Delta}{k+y_0}
\end{align} Therefore we can write:
\begin{align}
\tau=
-
\frac{1}{\varepsilon}
\left(
\log{y}
%
+
%
\frac{\Delta}{k}\log{\left(\frac{y}{k+y}\right)}
%
+
%
\frac{\Delta}{k+y}
-C_0\right) \qquad\qquad (2)
\end{align} I have solved $(1)$ numerically, using an ODE solver in MATLAB, with the following parameters:
$$\Delta=0.4351$$ 
$$\varepsilon=4.4261\times 10^{-5}$$
$$k=22.9806$$ 
$$y_0=0.5945$$
$$\tau\in [0,200000]$$ This is plotted by the black line in the following figure. I then solved $(2)$ for $\tau$ for $y\in[y_\text{min},y_0]$ where $y_\text{min}$ was the smallest value for y output from the numerical simulation. I then plotted this on the same figure, in dashed magenta. They don't match! I have checked this over and over, I do not know what I have done wrong here. Any help would be really appreciated.",['ordinary-differential-equations']
2179262,Operators on modular forms.,"My question is a lemma in the following paper. Serre J P, Stark H M. Modular forms of weight 1/2 Modular functions of one variable VI. Springer Berlin Heidelberg, 1977: 27-67. Let $\chi:(\mathbb{Z}/N\mathbb{Z})^*\longrightarrow\mathbb{C}^*$ be a character ($\mod N$),
and $\kappa$ be a positive
odd integer.
A function $f$ on upper half plane $H$ is called a modular form of type $(\kappa,\chi)$ on $\Gamma_0(N)$ if $f(\gamma z) = \chi(d) j(\gamma,z)^\kappa f (z)$ for every $\gamma=\left(
                 \begin{array}{cc}
                   a & b \\
                   c & d \\
                 \end{array}
               \right)$
           in $\Gamma_0$
this makes sense since $4\mid N$; f is holomorphic, both on H and at the cusps. One then calls $\kappa/2$ the weight of $f$, and $\chi$ its character. 
The space
of such forms will be denoted by $M_0(N,\kappa/2,\chi).$ Besides, operator $V(m)$ is defined by
\begin{align}
[f\mid V(m)](z):=f(mz).
\end{align}
Equivalently, if $f(z)=\sum_{n=0}^{\infty}a_nq^n$, then $f|V(m)=\sum_{n=0}^{\infty}a_nq^{mn}$. With the notation above, they claim in their Lemma 2 in page 40 that The operator $V(m)$ takes $M_0(N,\kappa/2,\chi)$ to $M_0(Nm,\kappa/2,\chi\chi_m)$. I do not understand why $f|V(m)$ is in $M_0(Nm,\kappa/2,\chi\chi_m)$, where $\chi_m$ is the Kronecker character for $\mathbb{Q}(\sqrt{m})$.  Any help will be appreciated. :)","['number-theory', 'algebraic-number-theory', 'modular-forms']"
2179266,Inequality for incomplete Gamma Function,"I am trying to find if the following inequality is correct or not \begin{align}
f_a(x) \le f_b(x), \forall x\in \mathbb{R}
\end{align}
for $0<a\le b$, where
\begin{align}
f_a(x)= \frac{\gamma \left( \frac{1}{a}, \frac{|x|^a}{2} \right)}{\Gamma \left( \frac{1}{a} \right)},
\end{align} and where the gamma functions are defined as follows
\begin{align}
\Gamma\left(x \right)= \int_0^\infty t^{x-1} e^{-t} dt, \\
 \gamma(x,s) = \int_0^s t^{x-1}\,e^{-t}\,dt.
\end{align} I tried some simulation and this inequality seems to hold.  However, I can not show it. This inequality can also be seen as a monotonicity result in terms of a variable $a$ for $f_a(x)$. Simulation, results seem to suggest the inequality is true, see the figure below (on the figure x-axis is $x$). Thanks.","['special-functions', 'complex-analysis', 'inequality', 'gamma-function']"
2179342,"In polynomial functions, is the midpoint of two adjacent minimum and maximum always a point of inflection?","For any generic polynomial function, it seems that a point of inflection is always half-way between the nearest minimum and maximum (if they exist). Is there a way to prove that midpoints of adjacent minima and maxima are POIs? Or might I be missing a simple counterexample?","['derivatives', 'polynomials', 'calculus']"
2179367,Motivation behind the open covering definition of compactness,"I can easily understand the notion of compactness for Euclidean spaces $\mathbb{R}^n$ . But, I am having a hard time for more general spaces. Precisely, my question is: Whoever first defined compactness using the open cover definition, how
did he arrive at this definition? I have read a lot of similar posts, like this and this , but beyond examples of closed and open subsets of $\mathbb{R}$ , I have nowhere seen an example of a space where compactness is anything different other than the Bolzano-Weierstrass Property, or the Heine-Borel property. What is the motivation behind this definition, or in other words, how do we justify that this is the correct definition of compactness? Just in the scope of real and complex analysis, why do we have to work with such a complicated definition?","['general-topology', 'compactness']"
2179455,Martingale representation theorem and Itô's lemma,"Let $W_t=\int_0^t dW_s$ be a wiener process and let $Y_t = Y_t(W_t)$ be a martingale. By the martingale representation theorem $dY_t = h_t dW_t$ for some unique, predictable process $h_t$. Given that we know that $Y_T = g(W_T)$ for some function $g(x)$ and at some time point $T$, is it possible to find $h_t$ for $t<T$? Intuitively I had the idea to apply Itô's lemma at the time $T$ to get 
\begin{equation}
dY_T = \frac{\partial g}{\partial x}(W_T) dW_T
\end{equation}
and identify $h_T = \frac{\partial g}{\partial x}(W_T)$ and then simply let $h_t = E[h_T | \mathcal{F}_t]$. This actually seems to work for the specific problem I'm looking at, but it's not exactly formal and I don't think it would hold as a proof. Is there any validity to this idea? What other methods could be used to find $h_t$?","['stochastic-processes', 'martingales', 'probability-theory', 'stochastic-calculus']"
2179456,A geometric matrix inequality,"Let $0 < \sigma_i \in \mathbb{R}$ ($i=1 \dots d$). Is it true that $$ c \sum_{i=1}^d (\sigma_i-1)^2 \le \sqrt{\sum_{i=1}^d (\sigma_i^2-1)^2} \tag{1}$$ for some $c>0$ which does not depend on the $\sigma_i$. (I actually suspect this holds for $c=1$). Motivation: This inequality is equivalent to the following $$c \|\sqrt{A^TA}-I\|^2 \le \|A^TA-I\|, \tag{2}$$ where $A$ is a $d \times d$ real matrix. (The equivalence is obtained by considering SVD). (Inequality $(2)$ comes from comparing different ways to measure deviation of a linear transformation from being an isometry).","['matrices', 'inequality', 'matrix-calculus', 'linear-algebra']"
2179486,trigonometry equation - $\sin^3(x)+\sin^3(2x)+\sin^3(3x) = (\sin(x)+\sin(2x)+\sin(3x))^3$,"how can i find all possible solutions to this equation? $\sin^3(x)+\sin^3(2x)+\sin^3(3x) = (\sin(x)+\sin(2x)+\sin(3x))^3$ I've tried writing it all as a sum in the form $\sin^m(x)\cos^n(x) + ... sin(x)$, with just $\sin(x)$ and $\cos(x)$ occuring. For my luck, you can write it in the form $\sin(x)* (...) = 0$ and therefore you can find a few solutions. But inside the brackets there is an expression starting with somthing like $\sin^7(x)$ which i cant handle and dont find any other solutions.",['trigonometry']
2179504,Coupled second order differential equations,"I would like to solve this coupled second order differential equations $$x^2E''(x)+xE'(x)-(p_2x^2+p_0\nu^2)E(x)+s\nu \,xG'(x)=0,$$ $$x^2G''(x)+xG'(x)-(q_2x^2-q_0\nu^2)G(x)+s\nu \,xE'(x)=0,$$ where $x$, $p_0$, $p_2$, $q_0$, $q_2$, $s$ are positive real numbers. $\nu$ is an integer. $x$ is from $x_0$ to $\infty$. I am expecting to have two different type of solutions. The 1st type should be exponentially increasing, and the 2nd type should be exponentially decaying. for our application, we are only interested in the exponentially decaying solution, which has a physically meaning. The equation can be discussed in two cases: $\nu=0$ and $\nu\neq 0$. When $\nu=0$, the equation system becomes: $$x^2E''(x)+xE'(x)-p_2x^2E(x)=0,$$ $$x^2G''(x)+xG'(x)-q_2x^2G(x)=0.$$ Therefore, $E(x)$ and $G(x)$ are uncoupled, which are both modified Bessel equations. The general solution of them are: $$E(x)=C_1I_0(\sqrt{p_2}x)+C_2K_0(\sqrt{p_2}x)$$
$$G(x)=D_1I_0(\sqrt{q_2}x)+D_2K_0(\sqrt{q_2}x)$$ Since the $I_0(x)$ function will have the infinite value when $x\to \infty$, we have to remove it. Hence the solution will be
$$E(x)=C_2K_0(\sqrt{p_2}x)$$
$$G(x)=D_2K_0(\sqrt{q_2}x)$$ However, when $\nu\neq 0$, things become complicated. We are expecting that the solution would be the combination of Bessel functions and the total behavior is similar to $K_{\nu}(x)$. But unfortunately, we don't know how to solve this problem. Does anyone have an idea how to solve it? We will really thank you so much for the help! P.S. Some people mentioned that we can try the numerical method. However, the boundary condition $E(x_0)$, $E(x_0)'$, $G(x_0)$, $G(x_0)'$ contains another two unknowns variable $A$ and $B$. Hence I guess it is not possible to feed the boundary condition to the software?","['differential', 'functions']"
2179506,"Can the cosine function be written in ""simpler"" expressions?","I recently found that the constants $\pi$ and $\phi=\frac{1+\sqrt{5}}{2} $ can be related by the identity 
$$
2\cos \frac{\pi}{5} = \phi.
$$ Is there some way to write the cosine function by ""simpler"" mathematical expressions?","['trigonometry', 'functions']"
2179522,Reparametrization of a curve,"Given a parametrized curve, we know that its arc length parametrization is its unit speed reparametrization. However, I wanted to know if there was any generic procedure to find any other reparametrizations of the same curve, which are not unit speed, and are non trivial?","['differential-geometry', 'calculus', 'vector-analysis']"
2179578,Existence of a least subcover of an open cover.,"If $\mathcal{O}$ is an open cover of $X$ , does there exist an open cover $\mathcal{U}\subseteq \mathcal{O}$ , such that, if $\mathcal{U}'\subsetneq \mathcal{U}$ , $\mathcal{U}'$ does not cover $X$ ? For example, it is true for compact spaces. (Any open cover has a finite subcover. The finite subcover clearly has a minimal subcover.) It is not immediately clear whether in non-compact spaces we have minimal subcovers. (Or whether this is true at least in some spaces.)","['general-topology', 'compactness']"
2179621,"""Anti-curl"" operator in a topologically non-trivial domain","$\DeclareMathOperator{\div}{div}\DeclareMathOperator{\rot}{rot}$Let $D$ be an open bounded connected domain in $\mathbb R^3$ and let $X$ be a smooth vector field in $D$ such that
$$
   \int_S X \cdot dS = 0 \tag{1}
$$
for any closed surface $S$ in $D$. In particular, $\mathop{\mathrm{div}} X = 0$ in $D$ since
$$
   \mathop{\mathrm{div}} X(x) = \lim_{\varepsilon \to +0} \tfrac{3}{4\pi \varepsilon^3} \int_{|x-y| = \varepsilon} X(y) \cdot dS_y = 0
$$
by the Ostrogradski-Gauss formula and the mean-value formula. But condition (1) is stronger than just $\mathop{\mathrm{div}} X = 0$ in $D$, it also means that $X \cdot dS$ integrates to $0$ for any closed surface $S$ enclosing a ""hole"" in $D$. I think that (1) implies that $X = \mathop{\mathrm{rot}} B$ for some smooth vector field $B$ in $D$, and I think that I can show it using differential forms. But is it possible to prove this and to find an explicit expression for such $B$ using ""elementary"" tools (without de Rham's theorem)? Here are some thoughts. As $\div X = 0$, there exists a small covering of $D$ by $U_\alpha$'s such that $X = \rot Y_\alpha$ in $U_\alpha$. Then
$$
   Y_\alpha - Y_\beta = \nabla \varphi_{\alpha\beta} \quad \text{in $U_\alpha \cap U_\beta$},
$$
for some $\varphi_{\alpha\beta} \in C^\infty(U_\alpha \cap U_\beta)$ such that $\varphi_{\alpha\beta}+\varphi_{\beta\alpha}=0$. Next,
$$
   \varphi_{\alpha \beta}+\varphi_{\beta\gamma}+\varphi_{\gamma\alpha} = c_{\alpha\beta\gamma} \in \mathbb R \quad \text{in $U_\alpha \cap U_\beta \cap U_\gamma$}
$$
where $c_{\alpha\beta\gamma}$ satisfy the $2$-cocycle conditions. Condition (1) must somehow imply that $c_{\alpha\beta\gamma}$ is a $2$-coboundary but I don't see why. I tried to rewrite (1) as
$$
  \int_S X \cdot dS = \sum_\alpha \int_{S\cap U_\alpha} \rot Y_\alpha \cdot dS - \sum_{\alpha\beta}\int_{S \cap U_\alpha \cap U_\beta} \rot Y_\alpha\cdot dS + \sum_{\alpha\beta\gamma}\int_{S \cap U_\alpha \cap U_\beta \cap U_\gamma} \rot Y_\alpha \cdot dS \\
 = \sum_\alpha \int_{S \cap \partial U_\alpha} Y_\alpha \cdot dl+ \cdots = 0
$$
but I don't see how to deduce from here some equations on $c_{\alpha\beta\gamma}$.","['multivariable-calculus', 'analysis']"
2179646,Using Lagrange Multipliers to determine the point on a surface nearest to P,"I'm attempting to figure this problem out. I would appreciate some guidance on how to get the answer. Thanks. Consider the surface defined as $S: x^2+y^2+z^2 = 8$. If we have a $P = (0,1,1)$, use Lagrange multipliers to determine the point on $S$ nearest to $P$.","['multivariable-calculus', 'surfaces', 'lagrange-multiplier', 'calculus']"
2179659,Understanding metric tangent cones.,"Just here trying to grasp better the concept of metric tangent cones in a metric space (in the sense of rescalings). And maybe said better, I'm trying to understand a bit more the 'bad' behaviours of these cones. The main problem being that my intuition outside nice smooth spaces is very poor. Specifically, let $(X,d)$ be a metric space. And call $(Y,d_Y,p_y)$ a tangent cone of $X$ at $p$ if it is the pointed Gromov-Housdorff limit of the pointed spaces $(X,\lambda d,p)$ for some sequence $\lambda\to\infty$. Now, it is clear to me that such a limit might not exist. Its already a bit less clear that a tangent cone might exist but it need not be unique. I think I can come up with some examples of this last behaviour but more examples would definitively help. So, 1) Could someone please explain some simple and maybe not so simple examples of non-unique tangent cones? Maybe a simple examples, but also for instance examples where the cones are not homeomorphic? can this happen? Next I was wondering how bad things can get. For instance, the tangent cone at a point might be completely different from cones of nearby points. But, 2)are there examples, for instance, where the cones are different (not iso, not homeo?) for every point inside some neighbourhood. (some similar behaviour?) and lastly, 3) Any examples of interesting 'bad' behaviours that would be nice to keep in mind? I would be really greatful if someone could help me built a bit more of intuition on these matters. Thanks!","['metric-spaces', 'differential-geometry', 'geometry']"
2179726,Solving an ODE by integration,"Suppose $f$ is differentiable on $[0,1]$, and that $f'(x) = g(x)$ on $(0,1]$. Can I conclude that for $x \in [0,1]$,
$$f(x) - f(0) = \int_0^x g(x) dx?$$
My issue is that we don't know that $f'(0) = g(0)$, but that shouldn't matter since the integral of two functions that differ on a set of measure zero are the same, right? Also, what if all we knew was that $f$ was differentiable on $(0,1]$?",['ordinary-differential-equations']
2179751,"Bounded linear function on $C[a,b]$ given by $f(x)=x(t_{0})$","I have the following question from a textbook. Let $f:C[a,\,b]\rightarrow\mathbb{R}$ be defined by $f(x)=x(t_{0})$ for a fixed $t_{0}\in[a,\,b]$. Show that $f$ is a bounded linear function and $\|f\|=1$. In order to show this I thought I should show that $f$ is continuous and use the following theorem Theorem: $f$ is continuous if and only if it is bounded. How ever am stuck on how to do this. Is there a way to do this with this technique?","['functional-analysis', 'normed-spaces', 'operator-theory', 'linear-transformations']"
2179784,Minimum steps adding edges to form a complete graph,"Consider a graph $G$ with $t$ vertices and $0$ edges. Turn it into the complete graph $K_t$ by repeatedly applying the following move $M$: $M$: Choose $n$ vertices in $G$ and add edges between each of them to make a complete subgraph $K_n$ within $G$. This gives the new $G$. Question: Given $t$ and $n$, what is the least number $m$ of times $M$ has to be applied before $G$ is $K_t$? Notes: If $n=2$ then $m$ is ${t \choose 2}$. If $n=t-1$ then $m$ is 3. I'd prefer a comprehensive derivation of some estimation over precise candidates for computation.","['combinatorics', 'graph-theory', 'recreational-mathematics']"
2179803,Ring with $\frac{n+1}{2}$ squares,"Let $R$ be a ring with $n=|R|\geq3$ elements, which has $\frac{n+1}{2}$ squares. Prove that $1+1$ is invertible and $R$ is a field. I thought that if there are $\frac{n+1}{2}$ squares, then $n+1$ is even, which means $n$ is odd. Let $k$ be the order of $1$. Obviously, $k|n$, hence $k$ is odd, which implies $(2,n)=1$, resulting that $1+1\neq0,$ i.e. $1+1$ is invertible. We see that for any $x\in R$, $x\neq-x$, but I got stuck here.","['abstract-algebra', 'ring-theory', 'field-theory']"
2179810,"Prob. 4, Chap. 4 in Baby Rudin: A continuous image of a dense subset is dense in the range.","Here is Prob. 4, Chap. 4 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $f$ and $g$ be continuous mappings of a metric space $X$ into a metric space $Y$, and let $E$ be a dense subset of $X$. Prove that $f(E)$ is dense in $f(X)$. If $g(p) = f(p)$ for all $p \in E$, prove that $g(p) = f(p)$ for all $p \in X$. (In other words, a continuous mapping is determined by its values on a dense subset of its domain.) I think I can prove both of these two facts. Now my question is, is either of the above two results still valid if $X$ and / or $Y$ be replaced by general topological spaces? My effort: Suppose $X$ and $Y$ are topological spaces, $E$ is a dense subset of $X$, and $f$ is a continuous mapping of $X$ into $Y$. Let $q$ be any point of $f(X)$. Then this point $q = f(p)$ for some point $p$ of $X$. Let $V$ be any open set in $Y$ containing $q$. Then $f^{-1}(V)$ is an open set in $X$ containing $p$. So there is a point $a \in E$ such that $a \in f^{-1}(V)$, which implies that $f(a) \in f(E) \cap V$, from which it follows that $f(E)$ is dense in $f(X)$. Am I right? Now for the second result: Suppose $X$ and $Y$ are topological spaces, $E$ is a dense subset of $X$, $f$ and $g$ are continuous mappings of $X$ into $Y$, and $g(x) = f(x)$ for all $x \in E$. Let $p \in X$. What next?","['real-analysis', 'continuity', 'general-topology', 'metric-spaces', 'analysis']"
2179824,Differential equation $cos(x-t)=x'$,"So we have following equation to solve: $$\cos(x-t)=x'$$ This is the first time I use substitution, so I want to ensure that I'm doing it correctly, even though it is probably very easy example.
We have: $$\cos(x-t)=\frac{dx}{dt}$$ We substitute $y=x-t$ $$\cos y=\frac{d(y+t)}{dt}=\frac{dy}{dt}+1$$ So: $$dt=\frac{dy}{\cos y-1}$$ And now I have to solve integrals: $$\int dt=\int\frac{dy}{\cos y-1}$$ Is it correct?","['integration', 'ordinary-differential-equations']"
2179831,Derivative of $x|x|$,"I am trying to find the derivative of $f(x)=x|x|$ using the defition of derivative. For $x > 0$ I found that $f'(x)=2x$ and for $x<0$ the derivative is $f'(x)=-2x$. Everything is fine up to here. Now I want to check what happens when at $x=0$. By the way, I know that $|x|$ is not differentiable at $x=0$. So I am checking the left & right limits of $f$ when $x$ approaches $0$. $\lim_{x \to 0^-}\cfrac{x|x|}{x} = \lim_{x \to 0^-}\cfrac{x(-x)}{x}=\lim_{x \to 0^-}\cfrac{(-x)}{1} = -0? = 0. $ $\lim_{x \to 0^+}\cfrac{x|x|}{x} = \lim_{x \to 0^4}\cfrac{x(x)}{x}=\lim_{x \to 0^+}\cfrac{(x)}{1} = 0. $ I think that $f$ is not differentiable at $x=0$ since $|x|$ is not differentiable at that point. So , what do I do wrong? Should I write something like $\lim_{x \to 0^-}\cfrac{x|x|}{x} = -0^{-}$ and $\lim_{x \to 0^+}\cfrac{x|x|}{x} =0^{+}$ so that $f'$ does not exist at $x=0$?","['algebra-precalculus', 'calculus', 'derivatives']"
2179854,Alternative solutions for $\cos(x)=-\frac{1}{2}$,"I have a function $f(x)=x+2\sin(x)$ and we are asked to find at which points the graph of $f$ has  Horizontal tangents. How we solve is to find where $f'=0$.  So $$f' = 1+ 2\cos x = 0 \implies \cos x = -\frac 12$$ and from this, to determine the solution set. I am familiar with unit circle and periodicity of $\sin,\cos$ functions so I found out that the solution set is $$x \in \left\{(2k+1)\pi \pm \frac{\pi}{3}:   k \in \mathbb{Z}\right\}$$ I know that is the usual way but is there any alternative solution -simpler if possible- to this problem? Especially for the people who does not the subject well?","['algebra-precalculus', 'trigonometry', 'calculus']"
