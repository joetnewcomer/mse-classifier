question_id,title,body,tags
1623104,"Determine function value, given inequalities","For each real number $r$ there is a real number $g(r)$. Moreover, it is known that for all real numbers $r$ and $s$ the inequalities $g(r) \leq r$ and $g(r+s)\leq g(r) + g(s)$ hold. Determine $g(200)$.","['inequality', 'functions']"
1623129,Misunderstandings of the fundamental theorem of calculus?,"One part of the fundamental theorem of calculus is that
$$F(x)=\int_a^x f(t)\;dt\tag1$$
However,
$$\int_a^b f(t)\;dt=F(b)-F(a)\tag2$$
So my first question is why doesn’t equation 1 take the form of $\int_a^x f(t)\;dt=F(x)-F(a)$? Where did $F(a)$ disappear to? Also, whenever you see an integral in the form of $F(x)=\int_x^a f(t)\;dt$,
why is it that you must always change it to $F(x)=-\int_a^x f(t)\;dt$? That is, why is it necessary for $x$ to be the upper limit and not the lower? I know that it’s written in the fundamental theorem of calculus as the upper limit, but why?","['integration', 'definite-integrals', 'calculus']"
1623146,A non-zero section of an invertible sheaf on a geometrically integral (smooth?) projective $k$-scheme is regular?,"Let $X$ be a projective, geometrically integral $k$-scheme $X$ for a field $k$ (possibly we also need $X$ smooth, i.e. $X_{\overline{k}}$ regular). It seems implicit in Hartshorne's discussion (with the smoothness hypothesis) of linear systems (beginning about half way down page 156, continuing through page 157) that if $\mathscr{L}$ is an invertible $\mathscr{O}_X$-module and $s\in\Gamma(X,\mathscr{L})$ is non-zero, then in fact $s$ is regular in the sense that the corresponding $\mathscr{O}_X$-module map $\mathscr{O}_X\to\mathscr{L}$ is injective (explicitly: if $U\subseteq X$ is open and $f\in\Gamma(U,\mathscr{O}_X)$ is non-zero, then $f\cdot(s\vert_U)$ is non-zero in $\Gamma(U,\mathscr{L})$). This would ensure that the so-called divisor of zeros of $f$ is actually a Cartier divisor. Minimally, I think one needs a trivialization of $\mathscr{L}$ with the property that $s$ does not restrict to zero on any member of the trivialization (so regularity is sufficient at least). On page 395 of the book of Görtz-Wedhorn, they work with $X$ projective and satisfying $\Gamma(X,\mathscr{O}_X)=k$ (which implies in particular that $X$ is geometrically connected) in their discussion of linear systems and seem to take the same fact about sections of invertible modules for granted. I can't see why this is true. Question: If $s\in\Gamma(X,\mathscr{L})$ is non-zero, is $s$ necessarily regular in the sense described above?","['divisors-algebraic-geometry', 'algebraic-geometry']"
1623164,A smart way to do this question.,"Let $S=\{0,1,2,\dotsc,25\}$ And $T=\{n\in S : n^2+3n+2\text{ is divisible by }6\}$ Then the number of elements in $T$ is? One way I know is to factorise it as $(n+1)(n+2)$. And then put each $n$ and check whether we get a $2$ and $3$  or their multiples in the factors. However it is a bit time consuming. So I ask for a smarter(quicker) way if any,  to this?","['algebra-precalculus', 'prime-factorization']"
1623198,"Is ${\{\emptyset,\{\emptyset\},\{\{\emptyset\}\},\{\{\{\emptyset\}\}\},...\}} $ a set?","Define M: 
$$ \emptyset \in M \wedge \forall x\in M \rightarrow \{x\}\in M $$
How to construct this set in ZFC system? 
I know the axiom schema of replacement and the definition of recursion, but first I need a function to produce this set. A function is a map of pairs, so M must be the subset of the function's codomain, which means I still need M before I use the function...",['elementary-set-theory']
1623210,Hahn-Banach Theorem for separable spaces without Zorn's Lemma,"I was reading about the Hahn-Banach Theorem, its many versions and their proofs. It's known that in the proofs we need Zorn's Lemma. But in the book that I'm reading, the author said if $X$ is a separable space then it's possible to prove the Hahn-Banach Theorem without the Zorn's Lemma. How can we show there is a suitable extension of a linear functional without Zorn's lemma?","['hahn-banach-theorem', 'normed-spaces', 'functional-analysis', 'axiom-of-choice', 'vector-spaces']"
1623211,Why is a linear transformation called linear? [duplicate],"This question already has answers here : Why are linear functions linear? (2 answers) Closed 8 years ago . $T(av_1 + bv_2) = aT(v_1) + bT(v_2)$ Why is this called linear? $f(x) =ax + b$, the simplest linear equation does not satisfy $f(x_1 + x_2) = f(x_1) + f(x_2)$. Thank you.","['terminology', 'linear-algebra']"
1623263,A 2nd order nonlinear ODE with one boundary and two algebrac equation constraints,"How to solve the following nonlinear ODE with two algebraic equations and one  boundary condition? $$y''(x)=\dfrac{2\left((x+15)y'(x)-y(x)\right)\left(y'(x)^2+1\right)}{\left(y(x)^2+x(x+30)+236\right)^2}$$ The boundary condition:
$$y(-14)=0$$ The algebraic equation constraint: $$\left\{
\begin{array}{ll}
 y(x_0)=\sqrt{1-x_0^2} &\\[15pt]
 y'(x_0)=\dfrac{-x_0}{\sqrt{1-x_0^2}}& \text{where: }-1\lt x_0\lt 0 \\
\end{array}
\right.$$","['boundary-value-problem', 'ordinary-differential-equations', 'nonlinear-system']"
1623292,Determining the limit of $\bigl(1 + \frac{1}{x+1}\bigr)^x$ as $x\to\infty$,"$$L = \lim_{x\to \infty} \biggl(1+\frac{1}{x+1}\biggr)^x $$ This one has to solved using $$\lim_{x\to \infty} \biggl(1+\frac{1}{x}\biggr)^x = e.$$ I did this
\begin{align}L &= \lim_{x\to \infty}\biggl( \biggl(1+\frac{1}{x+1}\biggr)^{x+1}\biggr)^{\frac{x}{x+1}}\\
& = e^{\frac{x}{x+1}}
\end{align} I get the limit to be (I figured it out this is wrong) $$\frac{1}{e}$$ 
while the answer is $e$.","['calculus', 'limits']"
1623297,Finding $(a+\sqrt b)^n+(a-\sqrt b)^n$ where $n$ is natural,"For the expression $\left(a+\sqrt{b}\right)^n+\left(a-\sqrt{b}\right)^n$ where $n \in \mathbb{N}$, and $a,b, \in \mathbb{Q}$, the radical is always ends up cancelled, and the result is always in $\mathbb{Q}$.  Is there any way that this could be reexpressed with the assumption that n is always a positive integer without the use of a square root operation, such as an alternative closed form for even $n$, and another closed form for odd $n$, or am I always stuck having to calculate a square root?",['algebra-precalculus']
1623358,Why is there no unbiased estimator for $\frac{1}{\theta}$ for Poisson Distribution?,"Suppose that $X_1,\dots,X_n$ is an iid random sample from a Poisson distribution with mean $\theta$. I would like to prove that there exists no unbiased estimator of $\frac{1}{\theta}$. To do so, I will let $\bar\theta(X)$ be an estimator of $\frac{1}{\theta}$. Then, I'd like to equate the expectation of $\bar\theta(X)$ and $\frac{1}{\theta}$
$$E\left[\bar\theta(X)\right] = \sum_{x=0}^{\infty}\bar\theta(x)P(X=x)$$ Now, my problem is that I don't know what to do next. I can write the probability $P(X=x)$ out but how do I continue from there? I have no information of $\bar\theta$ which is inside the sum. Any ideas?","['statistics', 'estimation', 'probability', 'poisson-distribution']"
1623403,"References about Iterating integration, $\int_{a_0}^{\int_{a_1}^\vdots I_1dx}I_0\,dx$","Are there any references that discuss Iterating integration in general, $\int_{a_0}^{\int_{a_1}^\vdots I_1dx}I_0\,dx$, conditions in which they converge, some special values, some special tricks to compute them, for example $$\Large\int_0^{\displaystyle\int_0^{\displaystyle\int_0^{\vdots}(1-x)^3dx}(1-x)^2dx}(1-x)^1dx$$","['reference-request', 'real-analysis', 'integration']"
1623404,"Prob 15, Chap. 1 in Baby Rudin: If this condition also sufficient for equality?","Here's Prob. 15, Chap. 1 in the book Principles of Mathematical Analysis by Wlater Rudin, 3rd edition: Under what conditions does equality hold in the Schwarz inequality? Now the Schwarz inequality, which is Theorem 1.35 in Rudin, is as follows: If $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ are complex numbers, then $$ \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 \leq \sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2.$$ If there is a complex number $z$ such that $a_j = z b_j$ for each $j=1, \ldots, n$ , then we have $$
\begin{align}
\left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 &= \left\vert \sum_{j=1}^n z b_j \overline{b_j} \right\vert^2 \\ 
&= \left\vert z \ \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\
&= \vert z \vert^2 \cdot \left\vert  \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\
&= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2,  
\end{align}
$$ whereas $$
\begin{align}
\sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 &= \sum_{j=1}^n \left\vert z b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\ 
&=  \sum_{j=1}^n  \vert z \vert^2 \left\vert  b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\
&= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2 \\ 
&= \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2.
\end{align}
$$ Now is this condition also a necessary condition for the equality to hold in the Schwarz ""inequality""?","['real-analysis', 'inequality', 'calculus', 'complex-analysis', 'analysis']"
1623415,How was Zeno's paradox solved using the limits of infinite series?,"This is a not necessarily the exact paradox Zeno is thought to have come up with, but it's similar enough: A man (In this photo, a dot 1 ) is to walk a distance of one unit from where he's standing to the wall. He, however, is to walk half the distance first, then half the remaining distance, then half of that, then half of that and so on. This means the man will never get to the wall, as there's always a half remaining. This defies common sense. We know a man(or woman, of course) can just walk up to a wall and get to it. My calculus book says this was solved when the idea of a limit of an infinite series was developed. The idea says that if the distances the man is passing are getting closer and closer to the total area from where he started to the wall, this means that the total distance is the limit of that. What I don't understand is this: mathematics tells us that the sum of the infinite little distances is finite, but, in real life, doesn't walking an infinite number of distances require an infinite amount of time, which means we didn't really solve anything, since that's what troubled Zeno? Thanks.","['intuition', 'calculus', 'limits']"
1623417,How to show that $\frac{\ln x}{x}$ is monotone for $x\ge e$?,"How to show that $\frac{\ln x}{x}$ is monotone for $x\ge e$? Looking at the graph of $\ln x$ I can tell that for $x<e$ the $\ln x$ goes to $-\infty$ very fast and for $x\ge e$ it grows very slow. Also, I know that $\ln x$ is monotone on $[0,\infty)$ and so is $g(x)=x$.","['algebra-precalculus', 'monotone-functions', 'calculus', 'functions']"
1623470,Solve $\sin x = x - 2 \pi/3$,What is $x$ if $\sin x = x - 2 \pi/3$? The answer is $x \approx 2.61$ but how do I work that out (without Taylor series - this is homework for 10th grade)? Thanks.,['trigonometry']
1623527,Show that $f_n\to f$ uniformly on $\mathbb{R}$,"Let $$P_n(x) = \frac{n}{1+n^2x^2}$$. First, I had to prove that $$\int_{-\infty}^\infty P_n(x)\ dx = \pi$$ And that for any $\delta > 0$: $$\lim_{n\to\infty} \int_\delta^\infty P_n(x)\ dx = \lim_{n\to\infty} \int_{-\infty}^{-\delta} P_n(x)\ dx = 0$$ I've done that easily. Now I need to prove that for $f:\mathbb{R}\to\mathbb{C}$ which is $2\pi$ periodic and continuous and:
$$f_n(x) = \frac{1}{\pi} \int_{-\infty}^\infty f(x-t)P_n(t)\ dt$$ $f_n\to f$, uniformly on $\mathbb{R}$. We learned in class about convolution and about Dirichlet/Fejer kernels.
Also, we learned that the trigonometric polynomials, $\{e^{inx}\}_{n\in\mathbb{Z}}$ are a dense set on $C(\mathbb{T})$ and the density is uniform. Meaning, there's a $P_n(x)=\sum c_n e^{inx}$ converges uniformly to $f$ where $f\in C(\mathbb{T})$. note: $f\in C(\mathbb{T})$ is a continuous and $2\pi$ periodic function (T is for Torus).","['integration', 'fourier-series', 'fourier-analysis', 'calculus']"
1623532,$\mathcal{C}_1 \subseteq \mathcal{C}_2 \implies \sigma( \mathcal{C}_1) \subseteq \sigma( \mathcal{C}_2) $,"$\mathcal{C}_1$, $\mathcal{C}_2$ are collections of subsets of $X$,then Im having hard time seeing why the  following is true. Can someone explain them to me? $\mathcal{C}_1 \subseteq \mathcal{C}_2 \implies \sigma( \mathcal{C}_1) \subseteq \sigma( \mathcal{C}_2) $ $\sigma(\sigma( \mathcal{C} )) = \sigma( \mathcal{C} ) $ where $\sigma( \mathcal{F} ) $ is the sigma field generated by the collection $\mathcal{F}$ of subsets of $X$ thanks","['real-analysis', 'measure-theory']"
1623551,Dimension of vector space of matrices with zero row and column sum.,Let $V(\mathbb{R})$ be the vector space of $m\times  n$ real  matrices such that each row sum and each column sum is zero. What is the dimension of $V(\mathbb{R})$? I know by General thinking that its dimension is $(m-1)(n-1)$. But I don't know what is the method to find its dimension. Please tell me how to think about its dimension. Thanks a lot.,"['matrices', 'linear-algebra']"
1623558,"Which assumptions on $Ω\subseteq\mathbb R^d$ do we need in order to show density of $C_c^∞(Ω)$ in $(L^p(Ω),\left\|\;\cdot\;\right\|_{L^p(Ω)})$?","Let $\Omega\subseteq\mathbb R^d$, $u\in\mathcal L^1(\Omega)$ and $$u_\varepsilon(x):=\frac 1{\varepsilon^d}\int_\Omega\rho\left(\frac{x-y}\varepsilon\right)u(y)\;{\rm d}\lambda(y)\;\;\;\text{for }\varepsilon>0\text{ and }x\in\mathbb R^d$$ where $\rho\in C^\infty(\mathbb R^d)$ has support in the unit ball and $$\int\rho\;{\rm d}\lambda=1\;.$$ We can show, that if $u\in\mathcal L^p(\Omega)$ for some $p\in[1,\infty)$, then $u_\varepsilon\in\mathcal L^p(\Omega)$ for all $\varepsilon>0$ and $$\left\|u_\varepsilon-u\right\|_{L^p(\Omega)}\stackrel{\varepsilon\to 0}\to 0\tag 1$$ (see Elliptic Partial Differential Equations of Second Order by Gilbarg and Trudinger , Lemma 7.2 ). If $\Omega$ is bounded, then $u_\varepsilon\in C_c^\infty(\mathbb R^d)$ and we can conclude that $C_c^\infty(\Omega)$ is dense in $(L^p(\Omega),\left\|\;\cdot\;\right\|_{L^p(\Omega)})$. However, I found many lecture notes (as well as questions here on the board) where they state, that this result is true for any (open) subset $\Omega$. So, which assumptions on $\Omega$ do we really need and where can I found a rigorous proof for the result in that case?","['partial-differential-equations', 'probability-theory', 'lp-spaces', 'lebesgue-integral', 'measure-theory']"
1623562,Find $\lim_{x \to 1} \frac {x-1}{\log_e x} $,":$$ L= \lim_{x \to 1} \frac {x-1}{\log_e x} $$ Let $ x = h + 1, h = x - 1. $ as $ x \to 1,  h \to 0$ $$L = \lim_{h \to 0} \frac{h} {\log_e (h+1)}$$ here we have a formula
 $$ \lim_{x \to 0} \frac{\log(1+x)}{x} = 1 $$
can i use it here!?",['limits']
1623569,Sumset of a subset of a group,I am interested in the following which I believe is known: Let $S$ be a subset of a finite group $G$ containing more than half of $G$'s elements.  Then $S+S = G$. I have been looking but can not find a reference.  Does anyone know of one?  Or know a nice proof? Thanks!,"['additive-combinatorics', 'combinatorics', 'group-theory']"
1623599,Show that for $n$ distinct numbers the following holds,"Show that for all $n\in\mathbb{N}$ there exist $a_i\in\mathbb{Z}, i=1,2,\dots,n$ distinct numbers so that:
$$\sum_{i=1}^{n}a_i^2=\sum_{i=1}^{n}a_i^3$$ Using normal induction wont bring me anything, so maybe using an induction step on would be nice, like if it holds for n then it will also hold for n+2, then we need only to show that there exist two numbers so that $a^2+b^2=a^3+b^3$.",['number-theory']
1623601,Problems using Rejection Sampling method,"I'm supposed to generate random numbers from the following distribution: $$ f(x) = \begin{cases} \frac{3}{4}(2x-x^2) &\mbox{if } x \in (0,2) \\ 
0 & \mbox{else} \end{cases} $$ I'm given the following algorithm in my script, which looks slightly different from those that I have found in the literature: Simulate $ U \sim U(0,1)$ Simulate $Y \sim q$ Accept $X=Y$ if $ U \leq \dfrac{1}{M}\dfrac{f(Y)}{q(Y)}$, otherwise go to step 1. Now first I have to find a function q which is easier to sample from, such that there exists a $M \in \mathbb{R}$, so that $Mq(x) \geq f(x), \forall x \in (0,2)$. I decided to pick $q \sim U(0,2)$ and have $M := \sup_{x \in (0,2)} f(x) = \frac{3}{4}$ Now I sample from $U(0,1)$, for which I get $U = 0.32$, then I sample from $Y \sim q \Rightarrow 1.28$ and now I'm supposed to accept the sampled value $y$ from step 2 if $ U \leq \frac{1}{M} \frac{f(Y)}{q(Y)}$ which in my case gives me: $0.32 \leq \frac{4}{3}f(1.29)=0.92$, so I'm supposed to accept $X=1.28$, however $1.28$ can hardly be from $f$. So what am I doing wrong.","['statistics', 'probability']"
1623602,Surjective function from a countable set,"In Lang ""Real and Functional analysis"" is demonstrated that given a countable set $A$ and a function $f: A \rightarrow B$ which is surjective on $B$, then $B$ is finite or countable. Proof: Consider $y \in B$ then there exists a non void set $F_y= \{x \in A | f(x)=y \}$, consider one element of the set , say $x_y \in F_y$. Now the assosiation $y \rightarrow x_y$ is injective from $B \rightarrow A$ (the proof of injectivity is easy) then, for the definiton of countability we have that also $B$ is countable. My questions are: It seems to me that this proof uses the axiom of choice to choose the elements in the family $F_y$, is this correct? If yes, there are proof of the same ""theorem"" without the AOC? I've heard of a theorem which says that if there exist a pair of injection $i_1,i_2, \ \ i_1:A \rightarrow B \ \ i_2:B \rightarrow A$ then there is a bijection $ f:A \rightarrow B$. And that this theorem can be demonstrated without AOC, is this true? There is a similar theorem for surjective functions?","['elementary-set-theory', 'functions', 'axiom-of-choice']"
1623609,"Is ""Generalized functions"" by Gelfand published in 5 or 6 volumes?","From what I know, ""Generalized functions"" by Gelfand is published in five volumes. Do you know whether there exist a 6th volume? Thanks a lot!","['functional-analysis', 'reference-request']"
1623629,Sin(x): surjective and non-surjective with different codomain?,"Statement that $\operatorname{sin}(x)$ not surjective with codomain $\mathbb R$ and surjective with codomain $[-1,1]$ found here : Non-surjective: $\mathbb{R}\rightarrow\mathbb{R}: x\mapsto\operatorname{sin}(x)$ Surjective: $\mathbb{R}\rightarrow[-1,1]: x\mapsto\operatorname{sin}(x)$ where the image $Im(f)=[-1,1]$ in both cases and the codomain is $\mathbb R$ and $[-1,1]$ for the case 1 and case 2, respectively. In the second case, $\forall x\in\mathbb R : \operatorname{sin}(x)\in [-1,1]$ where the codomain equals the image of $f$. Surjection means that the image of the function equals to the codomain. Why is sin not surjection with one codomain and surjective with other codomain?","['trigonometry', 'functions']"
1623630,Let $A$ be a subset of $\Bbb{R}$ such that the following $7$ sets are all different [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am suppose to come up with an example of an subset $A$ such that the sets $ A$ $int(A)$ $cl(A)$ $ cl(int(A))$ $ int(cl(A))$ $int(cl(int(A)))$ $ cl(int(cl(A)))$ are all different. I am not really sure how to come up with example like that so any hint or idea is great.","['general-topology', 'metric-spaces']"
1623641,Erasing numbers from the front of the row,"Numbers $1,2,\ldots,k$ are written in this order in a row. For $i=1,\ldots,k$, in the $i$th step, a random variable $V_i$ is drawn uniformly from the interval $[0,2i]$. If $V_i$ is greater than the first remaining number, that number is erased. What is the expected number of numbers that will be erased? For example, if $k=1$, then we have the number $1$ and $V_1$ drawn from $[0,2]$, so $1/2$ numbers will be erased in expectation. If $k=2$, then with probability $1/2$ we have $V_1>1$ and it is 50-50 whether the second number is erased. Otherwise $V_1<1$ and with probability $3/4$ the first number is erased. So the answer is $(1/2)(3/2)+(1/2)(3/4)=9/8$. For $k=3$, a similar case analysis shows that the answer is $85/48$ (if I calculated correctly.) It could be that no closed form can be found in general. If so, upper/lower bounds would still be interesting.","['expectation', 'probability']"
1623657,Evaluate the following integral involving $\sin \pi x$,"Let $F: \Bbb{R} \to \Bbb{R}$ be defined by $$F(s)=\begin{cases}1, & \text{if }s\ge \dfrac12 \\[0.2cm]0, & \text{if }s< \dfrac12 \end{cases}$$
  I need to evaluate $$\int^{1}_{0} F(\sin \pi x) dx\,$$ I noticed that $\sin (\pi x)$ is greater than $\frac{1}{2}$ for $\frac{1}{6}\le x \le \frac{5}{6}$ thus integral reduces to $\int^{\frac{5}{6}}_{\frac{1}{6}} 1 dx=\frac{2}{3}$. Is it okay?","['real-analysis', 'integration']"
1623667,Class group of the cone,"This is from exercise 6.3a of Hartshorne. Let $V$ be a projective variety over a field $k$ of dimension $\geq 1$ that is non-singular in codimension 1. Let $X = C(V)$ be the affine cone over $V$ in $\mathbb{A}^{n+1}_k$ and let $\overline{X}$ be its projective closure in $\mathbb{P}^{n+1}_k.$ Let $P \in X$ be the vertex of the cone. Consider the projection map $\overline{X}-P \rightarrow V.$ It is easy to show that there is a covering of $V$ by open subsets $U_i$ such that $\pi^{-1}(U_i) \cong U_i \times \mathbb{A}_k^1$ for each $i.$ I want, using this prove that the pullback map $\pi^\ast: Cl (V) \rightarrow Cl(\overline{X}-P)$ is an isomorphism between the class groups. I can actually prove this using a method that's clearly overkill, namely, using that $\overline{X}-P \rightarrow V$ is a vector bundle over $V,$ and then quoting a theorem from Fulton's ""Intersection theory"" showing that this induces an isomorphism of the Chow groups $A_{n-1}(V)$ and $A_n(\overline{X}-P).$ But this is certainly not what was intended. Another method of proof would be to show that the map $Div(V-U_i) \rightarrow Div(\pi^{-1}(V-U_i))$ is surjective and then use a snake lemma proof to finish it off. I think this is true, but I have some concerns since it only requires one $U_i$ such that $\pi^{-1}(U_i) \cong U_i \times A_i.$ Any help would be welcome.",['algebraic-geometry']
1623679,Continuity of Popcorn Function (Thomae's Function),"I have to prove that the function $f:]0,1] \rightarrow \Bbb R$ :
$$
f(x) =
\begin{cases}
\frac1q,  & \text{if $x \in \Bbb Q$  with $ x=\frac{p}q$ for $p,q \in \Bbb N$ coprime} \\
0, & \text{if $x \notin \Bbb Q $}
\end{cases}
$$ is continuous in  $x \in \ ]0,1] \backslash \Bbb Q$ (irrational numbers). I already tried to solve this exercise and I understood how to prove that this function is discontinuous for rational numbers. 
I was trying, now, to understand how to prove that for the irrational numbers it is continuous. I already have the solutions but they are a bit complicated, and I come up using sequences to prove it's continuous:
$$\forall x_n \quad x_n\rightarrow a \quad \Rightarrow \quad f(x_n) \rightarrow f(a)$$ I created a sequence $ x_n=\frac1n + a$, and we consider $a$ an irrational number. In order to be continuous $f(x_n)$ has to converge to $f(a)$.
In fact: $$\lim_{n\to\infty} f(x_n)= f(a) = 0 $$ So my proof ends here, but I know that I'm missing something really big because in the solution there is another complicated step using a set and the Epsilon-Delta theorem after what I've showed. Can someone explain what's wrong and help me with this proof?","['real-analysis', 'functions', 'calculus', 'continuity', 'analysis']"
1623682,Does there exists such real analytic function? (NBHM 2016),"a)Let $f(z)=e^x+iv$ then Cauchy Riemann equation will give us contradiction thus this cannot be true as $e^x=v_y \text{and} 0=v_x$, now $v_x=0 \implies v=g(y)$ and first equation then gives $g'(y)=e^x$ which is not true. b) is true take the zero function. c) This is not true since $f$ is entire and bounded thus constant and $f(0)=1 \implies f(z)=1 \quad \forall z\in \Bbb{C} $ but that contradicts $|f(z)|\le e^{-|z|}\quad \forall z$. Am I correct?",['complex-analysis']
1623693,Arranging the alternating harmonic series to sum to $\sqrt{2}$,"Since the alternating harmonic series
$$ \sum_{n=1}^\infty \frac{(-1)^{n+1}}{n} = \frac11-\frac12+\frac13-\frac14+\cdots
$$
is convergent but not absolutely convergent, any real number can be obtained by suitable re-arrangement and grouping of the terms.  But finding a re-arrangement that yields a specific real number can be a challenge. Find a grouping/re-arrangement that sums to 1. Find a grouping/re-arrangement that sums to 0. And my real question is: Find a grouping/re-arrangement that sums to $\sqrt{2}$. Later edit: I believe the re-arrangement leading to any particular real value $\alpha$ is not unique.  For example, split the original series into two parts, one with terms $\frac11, -\frac12, \frac15, -\frac16, \frac19, -\frac1{10} \cdots$ and the other with the remaining terms.  Each of these can be re-arranged to form $\frac12 \log 2$.  By inserting those re-arrangements in the order first term from first group, first term from second group, second term from first group, 
and so forth, you get a re-arrangement of terms adding to $\log 2$, which is distinct from the ""obvious"" trivial re-arrangement.","['absolute-convergence', 'sequences-and-series']"
1623699,Prove the triangle is equilateral,"HINTS ONLY please. This is very confusing right off the bat. My guess was that we show the angle $C, M, N$ are all $60^{\text{o}}.$ But I am having difficulty doing as as none of the givens have led me to any success.","['contest-math', 'triangles', 'geometry']"
1623701,Change of order of limits,"Is it OK to change the order of the limits here : $$ \lim\limits_{n \rightarrow \infty} \lim\limits_{m \rightarrow \infty}\frac{1}{2\pi} \int_{0}^{2\pi} p(t)q_m(nt) \; dt ~\overset{?}{=}~  \lim\limits_{m \rightarrow \infty}\lim\limits_{n \rightarrow \infty}\frac{1}{2\pi} \int_{0}^{2\pi} p(t)q_m(nt) \; dt, $$ where $p, q_m$ are a trigo polynomials and $q_m(t) \xrightarrow[m \rightarrow \infty]{\text{unif.}}g(t)$ for some $g \in C[0,2\pi]$ $2\pi$-periodic. My idea I'm inclined to think that uniform convergence and the compactness of $[0,2\pi]$ allow us to pass both limits under the integration sign, then we can swap limits due to uniform convergence and finally we pass both limits outside. Does this work ?",['limits']
1623705,Axiom of Powers,"Something I'm failing to understand from Halmos ""Naive Set theory"" book. If $\Phi $  is a collection of subsets of a set E (that is, $\Phi$ is a subcollection of $\rho (E)$), then write First of all I would like to point out that letters Phi and rho aren't the ones used in Halmos book. I do not recognize the letters from the book so I had no option but to pick my own. $$\rho(E) = \{X:X\subset E\}$$ This is the definition of $\rho (E)$ from the book. My question is: What is the difference between $\rho (E) $ and $\Phi$?","['axioms', 'elementary-set-theory']"
1623708,Prove a condition equivalent to the Lyapounov's one.,"This is an exercise our professor gives to us during an exam. I did it partially, but now I would like to solve it completely. Show that for a sequence of random variable $\{X_n \}_{n \ge 1}$ and for a real number $r > 2$
  $$\forall \epsilon >0, \quad \lim_{n\rightarrow \infty} \frac{1}{s_n^r} \sum_{j=1}^n \mathbb{E}(|X_j|^r 1_{|X_j|>\epsilon s_n})=0$$
  if and only if
  $$\lim_{n\rightarrow \infty} \frac{1}{s_n^r} \sum_{j=1}^n \mathbb{E}(|X_j|^r)=0$$
  where $s^2_n = \sum_{j=1}^n \mathbb{E}(X_j^2)$. Progress so far: (""$\Leftarrow$"") This direction is straightforward. We have
$$\mathbb{E}(|X_j|^r) \ge \mathbb{E}(|X_j|^r1_{|X_j|>\epsilon s_n}),$$
and so the result follows. (""$\Rightarrow$""). In this direction I am not even sure whether the implication is true. Also, I was wondering whether the assumption $\mathbb{E}(X_j) = 0$ is necessary or not.
$$$$","['probability-limit-theorems', 'probability-theory', 'probability', 'central-limit-theorem']"
1623725,"Prove that Helly Theorem is not true in $L^{\infty}[0,1]$","Prove that Helly Theorem is not true in $X=L^{\infty}[0,1]$ Helly's Theorem: Let $X$ be a separable normed linear space and $\{T_n \}$ a sequence in its dual space $X^*$ that is bounded, that is, there is an $M > 0$ for which $|T_n(f)|\leq M \cdot ||f||$ for all $f$ in $X$ and all $n$ . Then there is a subsequence $\{T_{n_k}\}$ of $\{T_n\}$ and $T$ in $X^*$ for which $\lim\limits_{k \to \infty} T_{n_k} =T(f)$ for all $f$ in $X$ My thoughts: Since one of the condition of the theorem is $X$ is separable normed linear space, I thought that will be enough to prove that $L^{\infty} [0,1]$ is not separable (and we can do this by contradiction) but I think it is not enough and maybe a counterexample (that I can't see) will solve this problem easily, any clues or solutions? Thanks","['functional-analysis', 'real-analysis']"
1623729,double integral getting different results,"I am trying to calculate the double integral $$\lim_{b \to 0^+} \int_{b}^1 \int_b^1 \frac{y-x}{(y+x)^3}dydx$$ If you plug this into wolfram, you get $-\frac{1}{2}$ and if you plug it into symbolab you get $\frac{1}{2}$ I will show you my steps, I just want to make sure I got the right answer. $$\lim_{b \to 0^+} \int_{b}^1 \int_b^1 \frac{y-x}{(y+x)^3}dydx=\lim_{b \to 0^+} \int_{b}^1 \int_b^1 \frac{y+x}{(y+x)^3}-\frac{2x}{(y+x)^3}dydx$$
$$=\lim_{b \to 0^+} \int_{b}^1 \frac{-1}{(1+x)^2}dx=\lim_{b \to 0^+} \frac{1}{1+x}\Big|_b^1=\frac{-1}{2}$$ I just wanted to verify because these two different websites are giving me different answers.","['definite-integrals', 'limits']"
1623772,Problem: differential equation,"Hi I try solve the following problem of differential equation $$ x''+tx'+\frac{1}{1+t+t^2}x=0\tag 1$$ when $$x(1)=0\ \ \ ;\ \ \ x'(1)=1 $$ is the solution analytic in $t_0=1$ and his convergence radius is $R>1$? Ok, I think I need put the differential equation like a frobenius differential equation, then I get, with the initial equation, that my solution is define by $$ \varphi_1(t)=\sum_{n=0}^{\infty} a_n(t-1)^{n+1}$$
$$\varphi_2(t)=C\varphi_1(t)\log(t-1)+\sum_{n=0}^{\infty} b_n(t-1)^n $$ I can not work with $\varphi_1$ in $(1)$, I do not know... someone could help me?","['real-analysis', 'calculus', 'frobenius-method', 'ordinary-differential-equations', 'power-series']"
1623793,What is the probability that two numbers between 1 and 10 picked at random sum to a number greater than 5?,"We have the numbers $1$ through $10$ in a box, we pick one at random, write it down and put it back in the box. We pick another of those numbers at random and write it down again. If we add the two numbers, what is the probability that it will be greater than $5$? At first I though that I could count the number of ways we could add two numbers to get six, i.e. $2+4$ and see what are the chances to get numbers bigger than those choices. Then adding all the probabilities that relate to each way. However, I get numbers greater than $1$ which is impossible. I also thought about the chance of getting a $1$ and then a number equal to or bigger to $5$, $P(x \ge 5) = \frac 12$ multiplying them together and repeating until all numbers run out. Again, wrong answer. My question is: how do we get to the correct answer? Is it possible to generalize? Say that the probability of $n$ numbers picked at random from $N$ choices add to something greater than $k$.","['combinatorics', 'probability']"
1623806,"Prob. 19, Chap. 1, in Baby Rudin: For what $\mathbf{c}$ and $r > 0$ does this equivalence hold?","Here's Prob. 19 in Chap. 1 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $\mathbf{a} \in \mathbb{R}^k$, $\mathbf{b} \in \mathbb{R}^k$. Find $\mathbf{c} \in \mathbb{R}^k$ and $r > 0$ such that, for all $\mathbf{x} \in \mathbb{R}^k$, we have  $$\vert \mathbf{x} - \mathbf{a} \vert = 2 \vert \mathbf{x} - \mathbf{b} \vert$$ if and only if $$\vert \mathbf{x} - \mathbf{c} \vert = r.$$ Although Rudin has given a solution, namely $3\mathbf{c} = 4 \mathbf{b} - \mathbf{a}$, $3r =  2\vert \mathbf{b} - \mathbf{a} \vert$, I'm wondering  how he's obtained it. How to attack this type of a problem? Is this problem part of the exercises by some well-thought-out design? I mean is it going to be used later on in the book? Or, is it just to give the reader some practice?","['real-analysis', 'analysis', 'analytic-geometry']"
1623901,General clarification for derivative notation,"I am a bit confused on the different notations of derivatives, could you help me clear it up? The following can be interpreted as: the total derivative of f wrt x, or equivalently, the derivative of f(x) wrt x the partial derivative of f wrt x, or equivalently, the derivative of f(x,y,z) wrt x $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx},\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x},\, f=f(x,y,z)$ now the above is different from the below, which is: the total derivative of f wrt x, evaluated at the point a the partial derivative of f wrt x, evaluated at the point a, b, c $\dfrac{df}{dx}(a)=\dfrac{d(f(x))}{dx}(a),\, f=f(x)$ $\dfrac{\partial f}{\partial x}(a,b,c)=\dfrac{\partial(f(x,y,z))}{\partial x}(a,b,c),\, f=f(x,y,z)$ however if we do a super contrived example and set a = x and a, b, c=x, y, z then the following equality holds (except super contrived, yes?) $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx}=\dfrac{d(f(x))}{dx}(x),\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}(x,y,z),\, f=f(x,y,z)$ no, this is not how I normally write derivatives, and I am only bending the rules so far as to test the boundaries/semantics Is the preceding interpretation correct?","['derivatives', 'notation']"
1623908,"Radical ideal of $\langle x^2+y^2+z^2, xy+yz+xz\rangle$","The following is exercise 3.7 from Undergraduate Algebraic Geometry by Reid. Let $J=\langle x^2+y^2+z^2, xy+yz+xz\rangle$; identify $V(J)$ and $I(V(J))$. The question did not specify the field. It is easy to see that in $\mathbb{R}[x,y,z]$, $V(J)=\{(0,0,0)\}$ and $I(V(J))=\langle x,y,z\rangle$. Consider it in $\mathbb{C}[x,y,z]$. From the defining equations, I got $x+y+z=0$. Substituting $x=-y-z$ into $x^2+y^2+z^2$, we get $y^2+yz+z^2=0$, this is equivalent as $(y+\frac{1}{2}z)^2+\frac{3}{4}z^2=0$. This gives 
$$y=\left(-\frac{1}{2}\pm\frac{\sqrt{3}}{2}i\right)z$$ So 
$$I(V(J))=\left\langle y-\left(-\frac{1}{2}+\frac{\sqrt{3}}{2}i\right)z, x-\left(-\frac{1}{2}-\frac{\sqrt{3}}{2}i\right)z\right\rangle \\\cap \left\langle y-\left(-\frac{1}{2}-\frac{\sqrt{3}}{2}i\right)z, x-\left(-\frac{1}{2}+\frac{\sqrt{3}}{2}i\right)z \right\rangle$$ Since $\mathbb{C}$ is algebraically closed, this should also be $\sqrt{J}$. My question is, Is it possible to find the generators so we don't have to write it as an intersection? Thank you for your help.","['algebraic-geometry', 'commutative-algebra']"
1623917,Why does an argument similiar to 0.999...=1 show 999...=-1?,I accept that two numbers can have the same supremum depending on how you generate a decimal representation. So $2.4999\ldots = 2.5$ etc. Can anyone point me to resources that would explain what the below argument that shows $999\ldots = -1$ is about? Here is the most usual proof I see that $0.999\ldots = 1$ : $x=0.999\ldots$ $10x=9.999\ldots$ $10x - x = 9$ $x=1$ Using this same argument template I can show $999\ldots=-1$ : $x= \ldots9999.0 $ $0.1x= \ldots9999.9$ $0.1x - x = 0.9$ $x=-1$ What might this mean? Edit from one of the comments: $$\sum_{k=0}^{\infty}{9 \cdot 10^k}=-1$$,"['decimal-expansion', 'p-adic-number-theory', 'real-numbers', 'arithmetic', 'sequences-and-series']"
1623928,How to check the correctness of calculated eigenvalues?,"Let's say you are given the following easy matrix: $$\begin{bmatrix}{-1}&{0}\\
{1}&{1}\end{bmatrix}$$ and you've calculated the following two eigenvalues: $\lambda_{1} = -1$ $ \lambda_{2} = 1$ Is there a way to check whether the calculated eigenvalues are correct? I know that with the eigenvectors you can just check everything all at once by checking it with this formula: $$A. \vec{x} = \lambda \vec{x}$$ But how can you check the correctness of the computed results without having to calculate all the eigenvectors and fill in the formula?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1623934,Prove $x^TAx = 0$ $\implies$ A is skew-symmetric,"We know for a skew-symmetric matrix A, $x^TAx = 0$. But is the converse statement true, i.e. does $x^TAx = 0$ imply A is skew-symmetric? If yes, then how to prove it?","['matrices', 'transpose', 'linear-algebra']"
1623942,What can go wrong if we let sigma algebra to admit the union of uncountable union of elements?,"By definition we only allow the union of countable infinite of elements to be also include the $\sigma$ field, why not uncountable many? Is there a historical view behind this？","['probability-theory', 'measure-theory']"
1624012,If $G$ is a group show that if $(a \cdot b)^2 = a^2 \cdot b^2$ then $G$ must be abelian.,If $G$ is a group show that if $(a \cdot b)^2 = a^2 \cdot b^2$ then $G$ must be abelian. $\begin{aligned}(a \cdot b)^2 = a^2 \cdot b^2 & \iff (a\cdot b)\cdot(a \cdot b) = (a \cdot a)\cdot (b \cdot b) \\& \iff a \cdot (b \cdot (a \cdot b)) =a(a \cdot (b\cdot b)) \\& \iff (a^{-1} \cdot a) \cdot (b \cdot (a \cdot b)) =(a^{-1}\cdot a)(a \cdot (b\cdot b))\\& \iff (b \cdot (a \cdot b)) =(a \cdot (b\cdot b)) \\& \iff (b \cdot a) \cdot b =(a \cdot b)\cdot b\\& \iff (b \cdot a) \cdot (b \cdot b^{-1}) =(a \cdot b)\cdot (b \cdot b^{-1}) \\& \iff b \cdot a = a \cdot b\end{aligned}$ Thus $G$ must be abelian. Is this right? Is there less clunky way to write it if it's?,"['abstract-algebra', 'group-theory', 'proof-verification']"
1624052,If every Sylow's subgroup is cyclic then $G$ is supersolvable.,"I've this exercise to resolve : prove that if $G$ is a finite group and all its Sylow subgroups are cyclic then G is supersoluble. 
My solution follows: is it correct? Thanks to everyone for the help! Let's proceed for induction on $|G|$. Let $p_1$$<$$p_2$$...$$<$$p_n$ the distinct primes that factorise $|G|$ and let $P_i$ be the corresponding p-Sylow's subgroups. Since $p_1$ is the smallest prime dividing $|G|$ then exists $K$$\vartriangleleft$ $G$ such that $G$$=$$K$$\rtimes$$P_1$ (hence $K$$=$$P_2$$P_3$$...$$P_n$). Now applying to $K$ the inductive hypothesis, 
$1$$\lt$$K_1$$\lt$$...$$\lt$$K_s$$\lt$$K$ is a normal series whose factors have prime order. On the other hand $G/K$$\simeq$$P_1$ is a finite abelian p-group so I can consider each subgroup $H_i/K$$\leq$$G/K$ with $|H_i/K|$$=$$p^i_1$ for $i$$=$$1,...,n-1$ and  $|P_1|$$=$$p_1^n$. In conclusion $1$$\lt$$K_1$$\lt$$...$$\lt$$K_s$$\lt$$K$$\lt$$H_1$$...$$\lt$$H_{n-1}$$\lt$$G$ is a normal series for $G$ whose factors have prime order.","['finite-groups', 'abstract-algebra', 'group-theory']"
1624054,Nonstandard construction of sheafification,"Let $F$ be a presheaf on a topological space $X$ of some category of ""sets with structure.""  In Borel's Linear Algebraic Groups, he gives the following explanation for how to construct the associated sheaf $F'$: Roughly speaking, $F'$ can be constructed in two steps.  First, define $F_1(U)$ to be $F(U)$ modulo the equivalence relation which relates $s$ and $t$ if their restrictions agree on some open cover of $U$.  Then form $F'(U)$ by ""adding"" to $F_1(U)$ all elements obtainable from compatible local data on some open covering of $U$.  This process makes sense thanks to step 1. Unfortunately, this process does not make sense.  I permit no thanks to step 1.  Anyway, this differs from other constructions of sheafification which I have seen before.  The main one I am familiar with is to define $F'(U)$ to be the set of functions $f$ from $U$ into the disjoint union of stalks $F_x : x \in U$ such that the following holds: for each $x \in U$, $f(x) \in F_x$, and there is an open covering $U_i$ of $U$, and sections $s_i \in F(U_i)$, such that $f(x) = (s_i,U_i)_x$ for each $x \in U_i$. Is there a nice way to understand what Borel is talking about?  I just don't get it.  Is there a nice way to relate these two notions of sheafification together?  (besides universal property shenanigans)","['category-theory', 'algebraic-groups', 'sheaf-theory', 'algebraic-geometry']"
1624142,"How to generalize ""Seven trees in one"" to labelled/colored trees?","In the famous paper Seven trees in one , Andreas Blass showed that there is ""a particularly elementary bijection between the set $T$ of finite binary trees and the set $T^7$ of seven-tuples of such trees"". For the Haskellers, if we define data Tree = Leaf | Node Tree Tree this leads to a bijection of types iso :: Tree -> (Tree, Tree, Tree, Tree, Tree, Tree, Tree) The justification, which this paper elaborates on, stems from the fact that for the set $T$ of trees, the recursive definitions yields an isomorphism $$T \cong T^2 + 1.$$ Treating this as an equation of complex numbers , we'd get $$T = \frac 1 2 \pm \frac 1 2 i \sqrt 3$$ which is a primitive sixth root of unity, thus yielding $T^7 = T$. This fascinating isomorphism just works for trees with no information attached to the nodes, as it just operates on the structure of the tree. I would love to see how we could incorporate actual, labelled nodes though (or better: colored nodes, see comments below). What do we get if we introduced labels on the nodes (with one of $n$ possibilities)? Say data Label = A1 | ... | An
data Tree = Leaf | Node Label Tree Tree Now we have an isomorphism $$T \cong 1 + nT^2$$ with complex solution
$$T = \frac 1{2n}(1+i\sqrt{4n-1}).$$ E.g. for $n=2$ we had $$T = \frac 1 4 (1 \pm i\sqrt 7).$$ None of these solutions can be roots of unity for $k>1$ because of their absolute values, so some nontrivial isomorphism $T^k \cong T^\ell$ won't arise. Are there other results one can achieve? I know that this question basically amounts to asking if there is nice integral polynomial equation satisfied by the complex value for $T$ above, which means nice polynomial multiples of $nT^2-T+1$. Has there been any work done on these? Thank you for your comments I know this question , though it's way broader (and hasn't received an answer anyway).","['category-theory', 'abstract-algebra', 'combinatorics', 'computer-science']"
1624151,Proving a total-order is a well-order if and only if every initial segment is determined by an element,"I managed to prove the $\longrightarrow$ part, but I'm not entirely sure how to prove the second part. I can assume by contradiction that the total order $(X, \leq)$ is not a well-order, which means there is an infinite monotonically-decreasing sequence, but how do I arrive to a contradiction? Can I show there exists an initial segment which is not determined by any element in $X$? Would appreciate any help or hints.","['order-theory', 'elementary-set-theory']"
1624184,$f_{\scriptscriptstyle{\vert H}}=g_{\scriptscriptstyle{\vert H}}$ implies $f=g$ for groups,"Is it possible to find a group $G_0$ and a proper subgroup $H$ such that for all morphism $f,g$ from $G_0$ to $G_1$ such that $f_{\scriptscriptstyle{\vert H}}=g_{\scriptscriptstyle{\vert H}}$ implies $f=g$ ? It seems to be a natural question, but I can't find any example, of proof that is not possible. Any ideas ?","['group-homomorphism', 'examples-counterexamples', 'group-theory']"
1624203,Hint on computing the series $\sum_{n=2}^\infty \frac{1}{n^2-1}$.,"I'm supposed to determine whether this sum diverges or converges and if it converges then find its value: 
$$
\sum_{n=2}^\infty \frac{1}{n^2-1}.
$$ Using the comparison test I eventually showed that this converges.  But I can't figure out how to show what this sum converges to.  The only sums we actually found values for in my notes are geometric series which this clearly isn't. I saw that I could use partial fraction decomposition to represent the terms as 
$$\frac{1/2}{n-1}- \frac{1/2}{n+1} $$
but that just gets me $\infty - \infty$, so this isn't the way to do it. I'm not sure how to find the value of this sum.  I don't need the full solution but a hint would be appreciated. Thanks. :)","['sequences-and-series', 'calculus']"
1624216,"Limit of real function, theoretical exercise","I'm a freshman in mathematics and this is my exercise: Prove that for function $f:\langle -a,a\rangle\setminus\{0\}\longrightarrow\langle0,+\infty\rangle$ so that is
  $$\lim_{x\to 0} \left(f(x)+\frac{1}{f(x)}\right)=2$$
  is also
  $$\lim_{x\to 0} f(x)=1.$$ I've tried to solve this problem from the Cauchy's definition of limit
$$(\forall \varepsilon>0) (\exists\delta>0) (\forall x \in \langle -a,a\rangle\setminus\{0\})\qquad (0< \lvert x-0\rvert  < \delta) \implies \Big( \Big| f(x)+\frac{1}{f(x)} \Big| < \varepsilon \Big)$$ by trying to get $\Big|f(x)-1\Big|<\varepsilon $ but I got that just in case $f(x)\in\langle0,1]$. Any thoughts on solving the problem this way or I should use another approach?","['proof-verification', 'real-analysis', 'functions', 'limits']"
1624217,Random Samples and Sample Variance Bound,"Let $X_{1}, X_{2}, \dots, X_{n}$ be a random sample from a population. Show that: $$\max_{1 \leq i \leq n}|X_{i}-\bar{X}|<\frac{(n-1)}{\sqrt{n}}S$$ Where we have the sample variance $S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\bar{X})^{2}$, unless all $n$ observations are equal or $n-1$ of the $X_{i}$'s are equal. I'm not sure on how to begin with the exercise. Maybe one could use one of the convergence theorems (weak law of large numbers or central limit theorem) and obtain a bound depending on $n$? What would be a good way to get started?","['statistics', 'probability', 'convergence-divergence', 'random-variables']"
1624235,every sigma algebra is a borel set prove it,"Is this right? Q: Find an infinite collection of subsets of $\mathbb{R}$ that contains $\mathbb{R}$, is closed under the
formation of countable unions, and is closed under the formation of countable intersections, but is not a $\sigma$-algebra. A: $\{[-a,a]:a\in\mathbb{R}^{+}\}\cup\{(-a,a):a\in\mathbb{R}^{+}\}\cup\{0\}\cup\{\mathbb{R}\}$ ?","['real-analysis', 'measure-theory']"
1624238,Reduced row echelon form and linear independence,"Let's say I have the set of vectors $S = \{v_1, v_2, ..., v_n\}$ where $v_j \in R^m$, $v_j = (a_{1j}, a_{2j}, ..., a_{mj})$. If the matrix formed by each of the vectors $A=[v_1, v_2, ..., v_n]$ looks like this (I believe), which is not a square matrix : $$A = \begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}$$ Then does A's reduced row echelon form help me determine whether the vectors of $S$ are linear dependent or independent? If so, how? I hope I got all the indices, notation and terminology right, since I am a beginner in linear algebra, and English is not my native language.","['independence', 'linear-algebra']"
1624260,Separable Kernel in Volterra integral equation,"I can't get my head around why the kernel in the Volterra integral equation can't be separable. 
$$u(x) = f(x) + \int_a^x K(x,s)u(s)ds, x \in [a,b]$$
A separable kernel $K(x,s)$ is the one that can be rewritten in the form of 
$$K(x,s ) = \sum_{i=1}^NA_i(x)B_i(s ).$$
It's supposed to be a ""text book"" problem, and the hint is ""$K(x,s)=0$ when $s>x$"", which really doesn't help much at all. I tried to somehow use the fact that it can be rewritten as the Fredholm integral equation in a triangle area:
$\hat{K}(x,s)=\begin{cases}
K(x,s) & a\leq s\leq x\\
0 & x\leq s\leq b
\end{cases}$ but so far no luck. Edit: It seems that for the condition ""$K(x,s)=0$ when $s>x$"" to hold, if we assume separability, then we can't effectively make it zero. Either $A_i(x)$ will depend on s ($A_i(x)=0$ when $x<s$) or $B_i(s)$ will depend on x ($B_i(s)=0$ when $s>x$). This contradicts separability. Thoughts?","['functional-analysis', 'integration', 'integral-equations', 'linear-algebra']"
1624279,Intersection of twisted cubics in $\mathbb{P}^3$,"Suppose we have two twisted cubics $C_1$, $C_2$ in $\mathbb{P}^3$ such that both of them lie in some cubic surface, which means that $h^0(\mathbb{P}^3, I_{C_1\cup C_2}(3))>0$. I want to show that in this case they intersect. Suppose that they do not intersect. Then $\mathcal{O}_{C_1\cup C_2}=\mathcal{O}_{C_1}\oplus\mathcal{O}_{C_2}$. Twisting by 3 the exact sequence
$$0\to I_{C_1\cup C_2}\to \mathcal{O}_{\mathbb{P}^3}\to\mathcal{O}_{C_1\cup C_2}\to0$$
and taking cohomologies we obtain
$$0\to H^0(\mathbb{P}^3, I_{C_1\cup C_2}(3))\to H^0(\mathbb{P}^3, \mathcal{O}_{\mathbb{P}^3}(3))\stackrel{f}\to H^0(\mathbb{P}^3, \mathcal{O}_{C_1\cup C_2}(3))\to H^1(\mathbb{P}^3, I_{C_1\cup C_2}(3))\to0.$$
But $h^0(\mathbb{P}^3, \mathcal{O}_{\mathbb{P}^3}(3))=20$ and $h^0(\mathbb{P}^3, \mathcal{O}_{C_1\cup C_2}(3))=2h^0(\mathbb{P}^3, \mathcal{O}_{C_1}(3))=2h^0(\mathbb{P}^1, \mathcal{O}_{\mathbb{P}^1}(9))=20$, so it seems that the map $f$ is an isomorphism, which contradicts the assumption $h^0(\mathbb{P}^3, I_{C_1\cup C_2}(3))>0$. Is it true or not that $f$ is an isomorphism? If yes, then how to prove this? $\textbf{Edit}$ It seems that the approach I gave in the post is not the best possible. If someone could give a canonical answer based on the different argument it would be welcomed! $\textbf{Edit 2}$ I received the following suggestion. Since $C_1$ and $C_2$ do not intersect, $I_{C_1\cup C_2}=I_{C_1}\otimes I_{C_2}$. For $I_{C_i}$ there is a resolution of the form $$0\to\mathcal{O}(-3)^{\oplus2}\to\mathcal{O}(-2)^{\oplus3}\to I_{C_i}\to0.$$ Tensoring these two resolution and twisting by 3 we obtain the exact sequence $$0\to\mathcal{O}(-3)^{\oplus4}\to\mathcal{O}(-2)^{\oplus6}\to\mathcal{O}(-1)^{\oplus9}\to I_{C_1}\otimes I_{C_2}(3)\to0.$$ The first three terms do not have cohomologies, so it seems that the fourth doesn't have too. How to prove this? Should I use some spectral sequence?","['algebraic-curves', 'coherent-sheaves', 'algebraic-geometry']"
1624291,Calculate the Derivative of the Integral,"The integral is $$ \frac d{dx} \int_0^{47/x} \cos^3(t)\ dt $$ I am stuck on where to begin. I believe I have to use the fundamental theorem of calculus, however I'm not sure how to start.","['integration', 'calculus']"
1624305,"$X$ normal $f:X \longrightarrow Y$ continuous, surjective, closed $\Longrightarrow$ $Y$ normal","Let $X$ and $Y$ be two topological spaces and $f:X \longrightarrow Y$ continuous, surjective and closed (i.e. it send closed sets in $X$ to closed sets in $Y$). How can I prove that if $X$ is normal, that $Y$ is normal too? So far I have the following: Let $E,F$ be closed, disjoint sets in $Y$. Since $f$ is continuous, $f^{-1}(E)$ and $f^{-1}(F)$ are closed too, and since $X$ is normal, there are two disjoint open sets $U,V \subset X$, such that $f^{-1}(E) \subset U$ and $f^{-1}(F) \subset V$. Now let be $U' := f(U^c)^c$ and $V' := f(V^c)^c$. Then $U',V'$ are open (as $f$ is closed), and it's easy to show that $U' \cap V' = \emptyset$. Now I need to show that $E \subset U'$ and $F \subset V'$. Let be $y \in E \Longrightarrow \exists x \in f^{-1}(E): f(x) = y$ (since $f$ is surjective). Now I had to approaches $(i)$ Then $x \in U \Longrightarrow x \in V^c \Longrightarrow y = f(x) \in f(V^c) = V'^c$. And then I'm stuck. $(ii)$ Then $x \in U \Longrightarrow x \notin U^c \Longrightarrow y = f(x) \notin f(U^c) \Longrightarrow y \in f(U^c)^c = U'$. But that one is wrong, , I noticed, since $x \notin U^c \Longrightarrow y = f(x) \notin f(U^c)$ is not necessarily right. I think the approach should be right, but I can't conclude. Any hints?","['closed-map', 'general-topology', 'separation-axioms']"
1624333,neighborhood basis on a set,"Given a topological space $(X,\tau)$ I know perfectly what is a neighborhood basis at $x\in X$. Now suppose that $X$ is just a set, fix a point $x\in X$ and consider a collection $\mathcal B(x)$ of subsets of $X$ containing $x$. What are the properties that I have to check for $B(x)$ in order to ensure that there exists a topology on $X$ such that a local basis at $x$ is $B(x)$? This question arises from the following consideration. Very often topologies in books are presented in a weird way; the author simply says ""Consider on the set $X$ the topology $\tau$ having this particular neighborhood basis"". I'd like to check that what he claims to be a ""local basis"" is indeed a good choice.","['general-topology', 'elementary-set-theory']"
1624352,How to use a proof by contradiction in group theory!,"A group $G$  is said to be abelian-by-finite if it has a normal subgroup $H$ of finite index in $G$.
I want to prove the following statement: ""If a group $G$ has property $\mathcal P$ then it is  abelian-by-finite"", and I want to use the proof by contradiction.
Can I formulate it in this way: Suppose $G$ has property $\mathcal P$ and it is not abelian-by-finite, therefore it exists a normal subgroup $H$ which is not of finite index in $G$? Can I use this to prove this statement by contradiction?","['abstract-algebra', 'group-theory', 'discrete-mathematics']"
1624371,Finding roots of cubic (trig),The question is By putting $x$ $=$ $\frac 23 \cos (\theta)$ Find the exact roots of the equation in terms of $\pi$ $$ 27x^3 - 9x = 1 $$ What I have attempted: $$ 27x^3 - 9x = 1 $$ $$x=\frac 23 \cos (\theta)$$ $$ x^3=\frac 8{27} \cos^3 (\theta)$$ $$ \therefore 27\left(\frac 8{27} \cos^3 (\theta)\right) - 9\left(\frac 23 \cos (\theta)\right) = 1$$ $$ 8\cos^3(\theta) - 6\cos(\theta) - 1 = 0 $$ Now I tried letting $\cos(\theta)$ = $z$ and try solving the cubic but the solutions aren't exactly nice looking (rational). Is there a special trig identity that I can reduce this equation to?,"['polynomials', 'roots', 'trigonometry', 'algebra-precalculus', 'cubics']"
1624375,Finding an example of nonhomeomorphic closed connected sets,"Question: Find two closed, connected subsets in $\mathbb{R}^2$, $A$ and $B$, such that $A$ is not homeomorphic to $B$, but there is a continuous bijection $f:A \rightarrow B$ and a continuous bijection $g:B \rightarrow A$. This is a homework question, so please only very small hints. I realize that both $A$ and $B$ must not be compact. Since they both must be closed, then they must be unbounded. However, I am having a hard time getting started on this. It is very easy to find two closed, unbounded, connected subsets of the plane that are not homeomorphic to each other, but it is hard to find the continuous bijections required. I know the classic example of a continuous bijection with a discontinuous inverse is a map $f: [0,2\pi) \rightarrow \mathbb{S}^1$ given by $f(x) = (\cos x, \sin x)$. I am trying to use this map as a template to come up with my sets but I am having no success.","['general-topology', 'real-analysis', 'examples-counterexamples', 'analysis']"
1624376,Solving second-order ODE using an integrating factor,"Solve the ODE 
  $$ \frac{\partial^{2} u }{\partial \eta^{2}} + \frac{\eta}{2\nu} \frac{\partial}{\partial\eta} = 0 $$ The book uses integrating factor = $ e^{\int\frac{\eta}{2\nu} d\eta}$ Can someone explain from here, how to proceed? I get $ IF = e^\frac{\eta^{2}}{4\nu}$. Multiply this with the ODE. Not sure what to do next? Because the answer the book gives is 
$$ \frac{\partial u}{\partial \eta} = A e^{\frac{-\eta^{2}}{4/nu}}$$  and I don't understand how to get this.",['ordinary-differential-equations']
1624390,"Why isn't integer factorization in complexity P, when you can factorize n in O(√n) steps?","It is said that integer factorization is an NP problem. Why isn't it P? You can solve it in $O(\sqrt{n})$ time with trial factorization, and since $\sqrt{n} = n^{1/2}$, to me that looks like a number of form $n^k$ which is a polynomial. I am having difficulty determining what P vs NP vs NP-Complete vs NP-Hard means because I don't know how to separate the definitions and how complexity is measured and defined.","['number-theory', 'computational-complexity', 'factoring']"
1624405,Polar to Cartesian: r = 3 + sin(theta/2),"I am asked to convert the following polar function to cartesian:
$$r = 3 + sin(\theta/2)$$ I would be able to do it if it weren't for the fraction. I have already tried substituting the identity $sin(\theta/2) = \pm\sqrt{\frac{1 - cos(x)}{2}}$ but that is a dead end as far as I can tell.","['polar-coordinates', 'functions']"
1624420,Limit $\lim_{x\to\infty}x\tan^{-1}(f(x)/(x+g(x)))$,"I am investigating the limit $$\lim_{x\to\infty}x\tan^{-1}\left(\frac{f(x)}{x+g(x)}\right)$$ given that $f(x)\to0$ and $g(x)\to0$ as $x\to\infty$. My initial guess is the limit exists since the decline rate of $\tan^{-1}$ will compensate the linearly increasing $x$. But I'm not sure if the limit can be non zero. My second guess is the limit will always zero but I can't prove it. Thank you. EDIT 1: this problem ca be reduced into proving that $\lim_{x\to\infty}x\tan^{-1}(M/x)=M$ for any $M\in\mathbb{R}$. Which I cannot prove it yet. EDIT 2: indeed $\lim_{x\to\infty}x\tan^{-1}(M/x)=M$ for any $M\in\mathbb{R}$. Observe that $$\lim_{x\to\infty}x\tan^{-1}(M/x)=\lim_{x\to0}\frac{\tan^{-1}(Mx)}{x}.$$ By using L'Hopital's rule, the right hand side gives $M$. So the limit which is being investigated is equal to zero for any $f(x)$ and $g(x)$ as long as $f(x)\to0$ and $g(x)\to0$ as $x\to\infty$. The problem is solved.",['limits']
1624469,Suppose f is analytic in some region containing $\bar{B}(0;1)$ and $ |f(z)| = 1$ where $|z| = 1$. Find a formula for $f$.,"The following is a problem from Conway chapter 6 section 2:
Suppose f is analytic in some region containing $\bar{B}(0;1)$ and $
|f(z)| = 1$ where $|z| = 1$. Find a formula for $f$. (Hint: First consider the case where f has no zeros in B(0;1).) I have figured that $f$ is analytic over $B(0;1)$, so by Maximum Modulus principle it attains its maximum on the boundary of $B(0;1)$, and so again by the maximum modulus principle $f$ must be constant in $B(0;1)$. So $f(z)=c$ where $|c|=1$ for all $z\in$ $\bar{B}(0;1)$. Any hints how to continue from here? Also I'm not entirely sure the argument I gave so far is totally correct.",['complex-analysis']
1624535,If $A=\sin^{20}\theta +\cos^{48}\theta $ then identify the correct option.,"If $A=\sin^{20}\theta +\cos^{48}\theta $, then for all values $\theta$ a) $A\geq 1$ b) $ 0< A\leq 1$ c) $1<A< 3$ d) None of these $0 \leq \sin^{20}\theta \leq 1$ $0 \leq \cos^{48}\theta \leq 1 $ So I think it is $d.)$ , but I am confused. I look for a short and simple way. I have studied maths upto $12$th grade.",['trigonometry']
1624537,Finite group with three proper subgroups,"The Klein-$4$ group is a finite group with exactly three subgroups $H$ such that $1<H<G$. Conversely, if $G$ is a finite group with exactly three subgroups $H$ such that $1<H<G$, then what can be said about $G$?","['finite-groups', 'group-theory']"
1624550,Can you create non transitive dice for any finite graph?,"Let's say you have a finite directed graph, with no two nodes that point at each other. Can we assign each node a dice, so that each node beats the node it is pointing at. This is easy for acyclic graphs, but it is possible for some non-acyclic graphs: see Nontransitive dice . By dice, I mean any probability distribution the natural numbers (including those of infinite support). A dice beats another if the probability of it being higher than the other is more than a half. Can we assign nontransitive dice to an arbitrary graph? Also: Can this still work with certain infinite graphs?","['graph-theory', 'probability-theory', 'probability-distributions', 'probability', 'dice']"
1624553,"Grothendieck's ""Relative"" Point of View","I have often read that Grothendieck's insight was to put emphasis on studying the morphisms between schemes as opposed to just the schemes by themselves. What do we gain from this point of view? Why is it important that we study S-schemes, change of base, fibered products, and the like? Are there any specific concrete examples of this point of view in action?","['soft-question', 'algebraic-geometry']"
1624557,Evaluate the limit of function $\lim_{x\to\infty}\frac{(9x^2+1)^{1/2}}{x+2}.$,"Find the limit:
$$\lim_{x\to\infty}\frac{(9x^2+1)^{1/2}}{x+2}.$$
I want to divide each of the terms by the highest power of $x$ but I failed to elimite the square root on it.","['radicals', 'limits']"
1624568,Do standard gradient descent methods work on complex variables,"I am currently whishing to optimize a function numerically $f(z)$ where $z \in \mathbb{C} $ ($f(z) \in \mathbb{R}$) . I am doing this via numerical packages (specifically scipy in python) and I have noticed that all the optimization methods in this package are tailored to only functions of domain in $\mathbb{R}$. I Played around for a bit with the complex optimization problem and at first sight it just seems like numerically optimizing a function of two variables since $z = (x,y) \equiv z = x + iy$ . I am aware that the definition of an analytic function is more rigorous than that of a real differentiable function in the sense that it should be differential from all directions $\Delta z = (\Delta x, \Delta y)$ so things become a bit more complicated. Given the situation above how can one approach the task of numerical optimization on a function of complex domain? Are there any standard routines for this ?","['complex-analysis', 'optimization', 'numerical-optimization']"
1624570,Number of lines formed by sides of polygon,"Let $n\geq 3$, and consider an $n$-gon, not necessarily convex. What is the minimum number of distinct lines that are formed by sides of the $n$-gon? When $n=3,4,5$ the answer is $3,4,5$ respectively. For $n=6$ we can save one line, for example if we draw the ""V-shaped"" $6$-gon so that the two sides at the top of the V form the same line. For larger $n$ we should be able to halve the number of distinct lines by forming a ""star shape"" so that opposite sides of the star form the same line. But can we do better?","['combinatorial-geometry', 'geometry']"
1624591,An Inequality for a Trigonometric Sum,"Using the equirepartion of the sequence $(n \mod 2\pi)$ one can show that $$\lim_{n\to\infty}
\frac1n \sum_{k=0}^n|\cos k|=\frac{2}{\pi}$$ Numerical evidence shows that, for every $n$, $$
 \sum_{k=0}^n|\cos k|>\frac{2}{\pi}n.$$ Can someone help proving this?","['inequality', 'sequences-and-series']"
1624614,"If $\tan A+\tan B+\tan C=6$ and $\tan A\tan B=2 $ in $\triangle ABC$, then find the type of triangle.","In $\triangle ABC$, $\tan A+\tan B+\tan C=6 \\
\tan A\tan B=2
$ Then the triangle is $a.)\text{Right-angled isosceles} \\
 b.) \text{Acute-angled isosceles}\\
\color{green}{c.)\text{Obtuse-angled}} \\
 d.)\text{equilateral} $ $\ \ \ $ $\tan A+\tan B+\tan C=6 \\
\tan A\tan B=2 \\
A+B=180-C\\
\dfrac{\tan A+\tan B}{1-\tan A\tan B}=-\tan C\\
\tan A+\tan B=\tan C\\
\tan C=3 \\
\tan A\tan B=2\ \text{and} \ \tan A+\tan B=3  \\
\implies \tan A=2, \tan B=1\ \ \text{or}\ \  \tan A=1, \tan B=2
 $ Now I am stucked, I look for a short and simple way. I have studied maths upto $12$th grade . Note:- Calculator is not allowed.",['trigonometry']
1624617,Proving the surprising limit: $\lim\limits_{n \to 0} \frac{x^{n}-y^{n}}{n}$ $=$ log$\frac{x}{y}$,"A few months ago, while at school, my classmate asked me this curious question: What does $\frac{x^{n}-y^{n}}{n}$ tend to as $n$ tends to $0$? I thought for a few minutes, became impatient, and asked ""What?"" His reply, log$\frac{x}{y}$, was surprising, but his purported 'proof' was more surprising: Consider $\lim\limits_{n \to 0}\,\int_y^x t^{n-1}\, dt$. ""Pushing the limit into the definite integral"", we have $$\int_y^x \lim\limits_{n \to 0}\,t^{n-1}\, dt \implies \int_y^x \frac{1}{t}\, dt \implies \mathsf{log} \frac{x}{y}$$ Leaving the fact that he had the inspiration to pull this integral out of thin air aside, is the limit allowed to pass into the definite integral? We hadn't learned Real Analysis (we were just taking a basic high school, hand-wavy single-variable calculus course), and I remember feeling very uneasy about the sorcery. I still am, hence, this question. I've since thought about approaching it using $\mathsf{L'Hospital}$, but I still feel uneasy, since it involves differentiating with respect to different variables, which is a little bit confusing. I'd also appreciate your help in this regard. If you have a better proof, I'll truly appreciate it.","['limits-without-lhopital', 'definite-integrals', 'calculus', 'limits']"
1624621,"Let $f(r)$ be the number of integral points inside circle of radius $r$ and center at origin,then $\lim_{r\to \infty}\frac{f(r)}{\pi r^2}$","Let $f(r)$ be the number of integral points inside circle of radius $r$ and center at origin,then $\lim_{r\to \infty}\frac{f(r)}{\pi r^2}$ I know the formula for number of lattice points inside the boundary of a circle of radius $r$ with center at the origin is given by $f(r)=1+4\lfloor r\rfloor+4\sum_{i=1}^{\lfloor r\rfloor}\lfloor \sqrt{r^2-i^2}\rfloor$ But i am not able to find $\lim_{r\to \infty}\frac{f(r)}{\pi r^2}$.",['limits']
1624651,What is the geometry behind $\frac{\tan 10^\circ}{\tan 20^\circ}=\frac{\tan 30^\circ}{\tan 50^\circ}$?,"This identity is solvable by the help of trigonometry identities, but I guess there is an interesting and simple geometry interpretation behind this identity and I can't find it. I found it when I was thinking about World's Hardest Easy Geometry Problem","['euclidean-geometry', 'trigonometry', 'proof-verification', 'geometry']"
1624660,Compute the (multiplicative) inverse of $4x+3$ in the field $\frac {\Bbb F_{11}[x]}{\langle x^2+1 \rangle}$?,"So I am finding a polynomial $px+q$ ($p,q \in \Bbb F_{11}$) which is multiplicative inverse of $4x+3$ in $\frac {\Bbb F_{11}[x]}{\langle x^2+1 \rangle}$. i.e. $[(4x+3)+\langle x^2+1 \rangle][(px+q)+\langle x^2+1 \rangle]=1+\langle x^2+1 \rangle$ $\Rightarrow$ $(4x+3)(px+q)+\langle x^2+1 \rangle=1+\langle x^2+1 \rangle$ $\Rightarrow$ $4px^2+(4q+3p)x+3q+\langle x^2+1 \rangle=1+\langle x^2+1 \rangle$. We see that the remainder,when $(4x+3)(px+q)$ is divided by $x^2+1$, is $1$.
So by Division algorithm, $$
\require{enclose}
\begin{array}{r}
4p \\[-3pt]
x^2+1 \enclose{longdiv}{4px^2+(4q+3p)x+3q} \\[-3pt]
\underline{4px^2+4p} \\[-3pt]
(4q+3p)x+(3q-4p) \\[-3pt]
\end{array}
$$ So I equate $(4q+3p)x+(3q-4p)=1$ and solve the simultaneous linear equations $4q+3p=0, 3q-4p=1$. I get $p=6,q=1$ Hence $6x+1$ is the required inverse. I am pretty sure that the answer is correct but is the method to achieve it right?","['abstract-algebra', 'ring-theory', 'proof-verification', 'quotient-spaces']"
1624684,How to evaluate $\int_{0}^{1}\frac{x^{4}\arctan x}{\sqrt{1+x^{2}}}\mathrm{d}x$,"How to evaluate$$\int_{0}^{1}\frac{x^{4}\arctan x}{\sqrt{1+x^{2}}}\mathrm{d}x$$
I tried to define:$$I\left ( \alpha  \right )=\int_{0}^{1}\frac{x^{4}\arctan \left ( \alpha x \right )}{\sqrt{1+x^{2}}}\mathrm{d}x$$
and
$$I'\left ( \alpha  \right )=\int_{0}^{1}\frac{x^{5}}{\sqrt{1+x^{2}}\left ( 1+\alpha ^{2}x^{2} \right )}\mathrm{d}x$$
but I have no idea how to do next.","['integration', 'sequences-and-series', 'calculus']"
1624690,Compute $\lim_{n \to +\infty} n^{-\frac12 \left(1+\frac{1}{n}\right)} \left(1^1 \cdot 2^2 \cdot 3^3 \cdots n^n \right)^{\frac{1}{n^2}}$,"How to compute
  $$\displaystyle \lim_{n \to +\infty} n^{-\dfrac12 \left(1+\dfrac{1}{n}\right)} \left(1^1\cdot 2^2 \cdot 3^3 \cdots n^n \right)^{\dfrac{1}{n^2}}$$
  I'm interested in more ways of computing limit for this expression My proof: Let $u_n$be that sequence we've: \begin{eqnarray*}
\ln u_n &=& -\frac{n+1}{2n}\ln n + \frac{1}{n^2}\sum_{k=1}^n k\ln k\\
&=& -\frac{n+1}{2n}\ln n + \frac{1}{n^2}\sum_{k=1}^n k\ln \frac{k}{n}+\frac{1}{n^2}\sum_{k=1}^n k\ln n\\
&=&  \frac{1}{n^2}\sum_{k=1}^n k\ln \frac{k}{n}\\
&=& \frac{1}{n}\sum_{k=1}^n \frac{k}{n}\ln \frac{k}{n}\\
&\to&\int_0^1 x\ln x\,dx = -1/4
\end{eqnarray*} Therefore the limit is $e^{-\frac{1}{4}}$","['contest-math', 'sequences-and-series', 'limits']"
1624703,Constructing an explicit non-contractible path in $\text{GL}_n(\mathbb{R})$,"As can be seen here , the fundamental group of $\text{GL}_n(\mathbb{R})$ is $\mathbb{Z}/2\mathbb{Z}$ (for $n \ge 3$ ). (For $n=2$ it is $\mathbb{Z}$ ). Is there a way to find an explicit representing path for the non-trivial element of $\pi(\text{GL}_n(\mathbb{R}))$ ? i.e describing a non-contractible (closed) path? (I guess for $n=2$ it's just like in $SO(2)\cong \mathbb{S}^1$ ?)","['matrices', 'algebraic-topology', 'lie-groups']"
1624739,"In a $\triangle ABC,$ Evaluation of minimum value of $\cot^2 A+\cot^2 B+\cot^2 C$ [duplicate]","This question already has answers here : Minimizing $\cot^2 A +\cot^2 B + \cot^2 C$ for $A+B+C=\pi$ (3 answers) Closed 8 years ago . In a $\triangle ABC,$ Evaluation of minimum value of $\cot^2 A+\cot^2 B+\cot^2 C$ , Given $A+B+C = \pi$ $\bf{My\; Try::}$ Using $\bf{A.M\geq G.M}$ $$\frac{\cot^2 A+\cot^2 B}{2}\geq \cot A\cdot \cot B\Rightarrow \cot^2 A+\cot^2B \geq 2\cot A\cdot \cot B$$ Similarly $$\cot^2 B+\cot^2 C\geq 2\cot B\cdot \cot C$$ and $$\cot^2 C+\cot^2 A\geq 2\cot C\cdot \cot A$$ So $$\cot^2 A+\cot^2 B+\cot^2 C\geq \cot A\cdot \cot B+\cot B\cdot \cot C+\cot C\cdot \cot A=1$$ Using $$A+B+C = \pi\Rightarrow A+B=\pi-C$$ So $$\cot\left(A+B\right) = \cot\left(\pi-C\right)\Rightarrow \frac{\cot B\cdot \cot A-1}{\cot B+\cot A} = -\cot C$$ So we get $$\cot A\cdot \cot B+\cot B\cdot \cot C+\cot C\cdot \cot A=1$$ My question is Instead of using $\bf{A.M\geq G.M}$ Inequality, Can we use Jensen inequality directly $$\frac{\cot^2A+\cot^2 B+\cot^2 C}{3}\geq \cot^2\left(\frac{A+B+C}{3}\right)$$ So we can Write it as $$\cot^2A+\cot^2 B+\cot^2 C \geq 1$$ If no, then what wrong with it, Thanks","['triangles', 'inequality', 'trigonometry', 'optimization']"
1624753,Countability of Collection of All Finite Subsets of a Countable Set,"Let V be a countable set. Ok, first thing to say is that this isn't a question as to whether $S = \{ A \subseteq V \mid A \ \text{finite} \}$ is countable -- there are plenty of other duplicates on SE asking the same question! This question is regarding the legitimacy of a method that I've been thinking about. Wlog let $V$ be infinite, otherwise the result is trivial. Fix $n \in \mathbb{N}$ and consider $S_n = \{ A \subseteq V \mid |S| = n\}$. ($S_0 = \emptyset$.) For $n = 1$, this is just the set of singletons of $V$, and so is countable. For $n = 2$, this is just the set of pairs of $V$, and so, by the ""countable collection of countables is countable"" argument, is countable. For general $n \in \mathbb{N}$, consider $N \choose n$, which, for fixed $N \in \mathbb{N}$, is a polynomial in $n$. Since we can iterate the ""countable collection of countables is countable"" argument, we have countability for each $n \in \mathbb{N}$. (That is to say, this follows since the set of all polynomials with integer coefficients of degree $n$ is countable.) Now, further we know that the set of all polynomials with integer coefficients is countable. Letting $P_n$ be the set of polynomials (with integer coefficients -- assume this whenever talking about polynomials) of degree $n$, we have that the set of all polynomials $P = \cup_{n\in\mathbb{N}} P_n$. Similarly (in our above notation), $S = \cup_{n\in\mathbb{N}} S_n$. From this can we then deduce that $S$ is countable? My main concern is the following. If $|V| = N \in \mathbb{N}$ (so $V$ is finite), then $|S_n| = {N \choose n}$. Since the union is disjoint, we then have that
$$|S| = \sum_{n=1}^N {N \choose n} = 2^N.$$
But $\aleph_1 = 2^{\aleph_0}$. So if we just let $N \to \infty$ in the above equation, then naively we get $|S| = 2^{\aleph_0} = \aleph_1$, which says that $S$ is uncountable. Alternatively, we can think of it another way (very similar). Without considering polynomials, we can just say that $S_n$ is countable for each $n \in \mathbb{N}$, and we're summing/unioning over a countable set, and so the result follows from the ""countable collection of countable is countable"" argument. Any comments on this would be most appreciated. The 'proof' (if it is a proof) does seem to be fine to me (I'm pretty sure the concern mentioned above is just that if you do the rigorous maths then you'll find that you can't just swap the limits naively). However, in the many SE questions asking if $S$ is countable, everyone (that I've seen) tries to set up some function that is an injection to deduce the result. This is fine, if you can come up with the injection, but my above method seems much more intuitive. (There is one that has a similar method, but they claim that $S_n$ is finite for each $n \in \mathbb{N}$, and that's (a place) where their proof fell down.)","['cardinals', 'elementary-set-theory', 'proof-verification']"
1624766,How do I simplify and evaluate the limit of $(\sqrt x - 1)/(\sqrt[3] x - 1)$ as $x\to 1$?,"Consider this limit: $$ \lim_{x \to 1} \frac{\sqrt x -  1}{ \sqrt[3] x -  1} 
$$ 
The answer is given to be 2 in the textbook. 
Our math professor skipped this question telling us it is not in our syllabus, but how can it be solved?","['derivatives', 'radicals', 'calculus', 'limits']"
1624780,Find the conditional probability of 6 appearing exactly once in $3$ rolls of a die given that it appeared at least once.,"Did I find the correct probability? A fair die is rolled $3$ times. The conditional probability of 6 appearing exactly once, given that it appeared at least once. So,the combined probability that 6 appeared exactly once and it appeared at least once is $$3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}$$
since, the case is that the 6 appears only once in the $3$ throws and it can appear at any throw: 1, 2 or 3.
And the probability that 6 appeared at least once is $$1-\left(\frac{5}{6}\right)^3$$ So the required probability is $$\frac{3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}}{1-\left(\frac{5}{6}\right)^3}$$
P.S.I don't have anything to check the answer, so I posted it here to verify. Please don't mind.",['probability']
1624795,$\sigma$-algebra generated by random variable : Show that if $\sigma(X)=\sigma(Y)$ then $\sigma(X+Y)\subseteq \sigma(X)$,"Let $(\Omega,\mathcal{F},P)$ be a probability space and $X$ be a random variable. The $\sigma$-algebra generated by $X$ is defined as $$\sigma(X):=\{X^{-1}(B)\; | \; B\in B_{\mathbb{R}}\}$$ where $B_{\mathbb{R}}$ is the Borel $\sigma$-algebra of subsets of $\mathbb{R}$. The problem statement is as follows : Let $(\Omega,\mathcal{F},P)$ be a probability space and $X,Y$ are random variables such that $\sigma(X)=\sigma(Y)$. Show that $\sigma(X+Y)\subseteq \sigma(X)$. I can show that $X+Y$ is a random variable. So, how do I go about proving this?","['probability-theory', 'measure-theory']"
1624822,Countability of a Totally Ordered Set [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove or disprove the following statement: If $X$ is a totally ordered set with the property that for every two elements $x$ and $y$ in $X$ such that $x<y$ , there exists another element $z$ such that $x<z<y$ , then $X$ is uncountable. What about the converse of the statement?",['elementary-set-theory']
1624888,Can epsilon be a matrix?,"Question In the following expression can $\epsilon$ be a matrix? $$ (H + \epsilon H_1) ( |m\rangle +\epsilon|m_1\rangle + \epsilon^2 |m_2\rangle + \dots) = (E |m\rangle + \epsilon E|m_1\rangle + \epsilon^2 E_2 |m_2\rangle + \dots) ( |m\rangle +\epsilon|m_1\rangle + \epsilon^2 |m_2\rangle + \dots) $$ Background So in quantum mechanics we generally have a solution $|m\rangle$ to a Hamiltonian: $$ H | m\rangle = E |m\rangle $$ Now using perturbation theory: $$ (H + \epsilon H_1) ( |m\rangle +\epsilon|m_1\rangle + \epsilon^2 |m_2\rangle + \dots) = (E |m\rangle + \epsilon E|m_1\rangle + \epsilon^2 E_2 |m_2\rangle + \dots) ( |m\rangle +\epsilon|m_1\rangle + \epsilon^2 |m_2\rangle + \dots) $$ I was curious and substituted $\epsilon$ as a matrix: $$ \epsilon =
\left( \begin{array}{cc}
0 & 0 \\
1 & 0 \end{array} \right) $$ where $\epsilon$ now, is the nilpotent matrix, we get: $$ \left( \begin{array}{cc}
H | m \rangle & 0 \\
H_1 |m_1 \rangle + H | m\rangle & H |m_1 \rangle \end{array} \right) = \left( \begin{array}{cc}
E | m \rangle & 0 \\
E_1 |m_1 \rangle + E | m\rangle & E |m_1 \rangle \end{array} \right)$$ Which is what we'd expect if we compared powers of $\epsilon$'s. All this made me wonder if $\epsilon$ could be a matrix? Say something like $| m_k\rangle \langle m_k |$ ? Say we chose $\epsilon \to \hat I \epsilon$ then there exists a radius of convergence. What is the radius of convergence in a general case of any matrix?","['quantum-mechanics', 'matrices', 'perturbation-theory', 'convergence-divergence', 'linear-algebra']"
1624891,(Non-continuous) solutions to $f\big(f(x)\big)=kx$ and $f\left(x^2\right)=xf(x)$,"Given a fixed non-zero constant $k\in\mathbb{R}$ , find all functions $f:\mathbb{R}\to\mathbb{R}$ satisfying $$f\big(f(x)\big)=kx\quad\text{and}\quad f\left(x^2\right)=xf(x).$$ If $f$ is continuous, then we can show that the solutions to the second equation are of the form $f(x)=mx$ (see here for example). With the first equation, this immediately implies that $f(x)=\sqrt{k}x$ or $f(x)=-\sqrt{k}x$ . However, I am struggling to extend this to non-continuous $f$ . Any help would be appreciated.","['algebra-precalculus', 'real-analysis', 'functional-equations']"
1624902,"I need to find $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}$","I need to find $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}$. My attempt: $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\lim_{h \to 0, h\ne 0}\exp(\frac{\log(\frac{2^h+3^h}{2})}{h})=\exp(\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h})$ $\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h}= \lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})-\log(\frac{2^0+3^0}{2})}{h-0}=(\log(\frac{2^h+3^h}{2}))'(0)=\frac{1}{2^0+3^0}0(2^{(0-1)}+3^{(0-1)})=0$ So $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\exp(0)=1$ Was my solution correct? I am asking because I tried to check numerically with Matlab and have not noticed the convergence to $1$.",['limits']
1624915,Finding a random variable $X$ such that $X_n$ (given) converges in distribution to $X$,"For every $n\in\Bbb{N}$, let $X_n$ be a random variable which gets the
  values $\{-1, -\frac{n-1}n,...,-\frac 1 n, 0, \frac 1
 n,...,\frac{n-1}n, 1\}$ with equal probability. Find a random variable $X$ such that $X_n$ converges in distribution to $X$. I got $X\sim U[-1,1]$. Find a random variable $Y$ such that $X_1, X_2^2, ..., X_n^n,...$ converges in distribution to $Y$. Any ideas on this one?","['weak-convergence', 'probability-theory', 'random-variables']"
1624919,Need help with notation for total derivatives,"consider the function $$f = f(x(t),y(t))$$ I know that its total derivative wrt t is $$\frac {df}{dt} = \frac {\partial f} {\partial x} \frac {dx}{dt} + \frac {\partial f}{\partial y} \frac {dy}{dt}$$ and that the total derivative wrt x is
$$ \frac {df} {dx} = \frac {\partial f} {\partial x} \frac {dx}{dx} + \frac {\partial f} {\partial y} \frac {dy} {dx}$$ However I am not fully familiar with the notation and the forms in which it takes during more extreme conditions, such as the following, could anyone fill the blanks in for me? 1)$$f = f(x(t,w),y(t,w))$$
$$\frac {df}{dt} = ?$$
2)
$$f = f(x(g(t,w)),y(g(t,w)))$$
$$\frac {df}{dt} = ?$$
3)
$$f = f(x(g(t,w),z),y(g(t,w),z))$$
$$\frac {df}{dt} = ?$$
4)
$$f = f(x(g(t)),y(g(t)))$$
$$\frac {df}{dt} = ?$$ how would I go about writing these properly? Any answer will help illustrate the semantics in much greater detail","['derivatives', 'partial-derivative', 'differential', 'calculus']"
