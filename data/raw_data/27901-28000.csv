question_id,title,body,tags
258736,Limit of sequence of growing matrices [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 10 months ago . Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. Let $$
H=\left(\begin{array}{cccc}
0 & 1/2 & 0 & 1/2 \\
1/2 & 0 & 1/2 & 0 \\
1/2 & 0 & 0 & 1/2\\
0 & 1/2 & 1/2 & 0
\end{array}\right),
$$ $K_1=\left(\begin{array}{c}1 \\ 0\end{array}\right)$ and consider the sequence of matrices defined by $$
K_L = \underset{2^{L}\times 2^{L}}{\underbrace{\left[H\otimes I_{2^{L-2}}\right]}}\underset{2^{L}\times 2^{L-1}}{\underbrace{\left[I_2 \otimes K_{L-1}\right]}}\in\mathbb{R}^{2^L\times 2^{L-1}},
$$ where $\otimes$ denotes the Kronecker product, and $I_n$ is the $n\times n$ identity matrix. I am interested in the limiting behaviour of the singular values of $K_L$ as $L$ tends to infinity. Some calculations indicate that the $2^L\times 2^{L-1}$ -matrix $K_L$ has $L$ non-zero singular values and that the empirical distribution of those nonzero singular values converges to some limit. Can this limit be described in terms of the matrix $H$ ? I am wondering if it is possible to use some kind of fixed-point theorem to characterise the limit (in any sense) $\lim_{L\to\infty}K_L$ as an operator on some sequence space. Edit: I did some more experiments and it seems that the limiting behaviour of the singular values of $K_L$ does not only depend on the matrix $H$ , but also on the initial value $K_1$ . To illustrate this, let $K_1(\alpha)=\left(\begin{array}{c}1 \\ \alpha\end{array}\right)$ and consider the sequence $$
K_L(\alpha) = \left[H\otimes I_{2^{L-2}}\right]\left[I_2 \otimes K_{L-1}(\alpha)\right].
$$ The largest singular value of $K_{10}(\alpha)$ is depicted in the following figure. (The graph looks essentially the same for all $L\geq 4$ instead of $L=10$ .) $K_{10}(\alpha)$ "" /> The minimum is approximately $(-.2936,0.7696)$ . This makes it unlikely for fixed-point arguments to work in this setting. I, therefore, modify my question and ask if the limiting behaviour of the singular values of $K_L$ (or $K_L(\alpha)$ ) can be characterised directly in terms of $H$ and the initial value $K_1$ (or $K_1(\alpha)$ ). Edit 2 (March 2015): As the question is still receiving attention, let me add that I came up with a conjecture for the asymptotic behaviour of the singular values of $K_L(\alpha),$ as detailed in this MO post .","['matrices', 'linear-algebra', 'convergence-divergence', 'operator-theory']"
258738,Abstract characterization of Borel $\sigma$-algebras,"Suppose we are given a measure space $(X,\mathfrak{M},\mu)$, but we know nothing more than this information. (Assume that $\mu$ is a positive, extended real-valued function.) Is there any ""nice"" way to tell whether or not there exists a topological space $Y$ and a measure $\nu$ on the Borel sets $B(Y)$ of $Y$ such that there is a bimeasurable bijection between $X$ and $Y$ i.e. a measure space isomorphism of $(X,\mathfrak{M},\mu)$ with $(Y,B(Y),\nu)$? Either this question is ridiculous as asked, or there is probably some kind of set-theoretic business connected to it...sorry if it's the former!",['measure-theory']
258742,Local-global principle for Galois groups,"Is there any sort of local-global principle for Galois groups? For example, given a polynomial $f \in \mathbb{Q}[X]$ and assuming we know $\mathrm{Gal}(f/\mathbb{Q}_p)$ at all primes $p \le \infty$, what can we say about $\mathrm{Gal}(f/\mathbb{Q})$?","['galois-theory', 'abstract-algebra']"
258744,Every Hilbert-Schmidt is an integral operator?,"Let $(X,\mu)$ be a $\sigma$-finite measure space. If $K\in\mathcal{L}^2(X\times X,\mu\times\mu)$ then the map $A_K:\mathcal{L}^2(X,\mu)\to\mathcal{L}^2(X,\mu)$ defined by\begin{equation}
A_Kf(x)=\int_XK(x,y)f(y)d\mu(y)
\end{equation} is Hilbert-Schmidt. But Arveson (Proposition 2.8.6) says this $K\mapsto A_K$ is an isomorphism from $\mathcal{L}^2(X\times X,\mu\times\mu)$ to the space of Hilbert-Schmidt operators on $\mathcal{L}^2(X,\mu)$. So in particular this map is onto. I do not know how to prove this. I tried to focus on the easiest case $X=[0,1]$ but still got no progress. Can someone give a hint?
Thanks!","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
258748,Find a one-to-one conformal mapping from $D(0;1) \setminus \overline{D(1;1)}$ onto $D(0;1)$,I'm working on the conformal mappings of complex analysis. I can find conformal mappings from&onto simple domains but cannot find one from the abnormal domains. Can any one give me a hint? Is there a rule that I can apply to find such mappings? ($D(z;r)$ means the open disk centered at $z$ with radius $r$.),"['conformal-geometry', 'complex-analysis']"
258752,Closed form for $\sum_{n=2}^\infty \frac{1}{n^2\log n}$,"I had attempted to evaluate $$\int_2^\infty (\zeta(x)-1)\, dx \approx 0.605521788882.$$ Upon writing out the zeta function as a sum, I got $$\int_2^\infty \left(\frac{1}{2^x}+\frac{1}{3^x}+\cdots\right)\, dx = \sum_{n=2}^\infty \frac{1}{n^2\log n}.$$ This sum is mentioned in the OEIS . All my attempts to evaluate this sum have been fruitless.  Does anyone know of a closed form, or perhaps, another interesting alternate form?","['closed-form', 'sequences-and-series', 'integration', 'riemann-zeta']"
258754,Integral $ \int \frac{\operatorname d\!x}{\sin^3 x} $,"I need to calculate the following integral for my homework, but I dont know how. If someone show me step by step solution I would really appreciate it.
 $$\int \frac {1}{\sin^3(x)} dx$$",['integration']
258761,Expectation of an exponential function,"Why is the expectation of an exponential function: 
$$\mathbb{E}[\exp(A x)] = \exp((1/2) A^2)\,?$$ I am struggling to find references that shows this, can anyone help me please? If anyone could enlighten me it would be great!",['probability']
258775,From a vector to a skew symmetric matrix,"Is there an existing linear mapping that maps a 3-dimensional vector:
$$\mathbf{v}=\begin{pmatrix} v_1\\v_2\\v_3 \end{pmatrix}$$
to a corresponding skew-symmetric matrix:
$$\mathbf{V}=\begin{pmatrix} 0 & -v_3 & v_2 \\ v_3 & 0 & -v_1 \\ -v_2 & v_1 & 0\end{pmatrix}$$ 
A tensor of order 3 should probably be defined. Edit The question is related to the following one:
knowing that there exists a matrix $\mathbf{V}\in\mathbb{R}^{3,3}$ such that for a given vector $\mathbf{v}\in\mathbb{R}^3$:
$$\forall\mathbf{x}\in\mathbb{R}^3,\quad\mathbf{V}\mathbf{x}=\mathbf{v}\times \mathbf{x}\quad\Leftrightarrow\quad \mathbf{V}=\mathrm{CPM}(\mathbf{v})$$
where CPM means cross-product matrix, can we express in a frame-invariant fashion the quantity:
$$ \mathbf{V}_\mathrm{A}=\mathrm{CPM}(\mathbf{Av})$$
where $\mathbf{A}$ is any $3\times 3$ real matrix? (the result is $\mathbf{V}_\mathrm{A}=(\mathbf{VA})^T-\mathbf{VA}+\mathrm{tr}(\mathbf{A})\mathbf{V}$ but was obtained by calculating each coordinate of the left-hand and right-hand side matrices and subsequently identifying each term)","['matrices', 'linear-algebra']"
258776,Set of limit points of a subset of a Hausdorff space is closed.,"Let $X$ be a Hausdorff space and $A\subset X$.  Define $A'=\{x\in X\mid x\text{ is a limit point of }A\}$.  Prove that $A'$ is closed in $X$. Relevant information: 
(1.) Every neighborhood of a point $x\in A'$ contains a point $y\in A'$ distinct from $x$ (in fact, in a Hausdorff space, every neighborhood of $x$ contains $\infty$-many points of $A$ distinct from $x$) (2.) In a Hausdorff space, every sequence has a unique limit. On first glance, it should be an easy proof, but I've made little progress.  I was planning on showing $\overline{A'}=A'$.  Firstly, $A'\subset \overline{A'}$ trivially.  To show $\overline{A'}\subset A'$, proceed by contradiction.  Assume there exists $x\in\overline{A'}$ such that $x\not\in A'$.  This should yield an easy contradiction but I don't see it.  In particular, I'm unsure if the fact that $x\in\overline{A'}$ implies that there actually exists a sequence in $A'$ converging to $x$.  By (2) we know all sequences have unique limits, but do we know that elements in the closure are limits of sequences?  If this is true, it should yield an easy contradiction.  Any help?",['general-topology']
258780,How to solve indeterminations of the type $0/0$,"I am unable to find these limits: 1)
$$
\lim_{x \to 1} \frac{3(1 - x^2) - 2(1 - x^3)}{(1 - x^3)(1 - x^2)}
$$ 2)
$$
\lim_{x \to 0} \frac{\sqrt{1 - 2x - x^2} - (x + 1)}{x}
$$ 3)
$$
\lim_{x \to 0} \frac{\sqrt{x + 2} + \sqrt{x + 6} - \sqrt{6} - \sqrt{2}}{x}
$$ 4)
$$
\lim_{x \to 0} \frac{1 - \sqrt[3]{1 - x}}{1 + \sqrt[3]{3x - 1}}
$$ My interest is not in the answers, but in the algebraic manipulations i can use to eliminate the indeterminations of the type $0/0$. My english skills are not so good, i'm sorry for this.","['calculus', 'limits']"
258792,Different notions of local compatness and why are they implied by compactness?,"There are several definitions of local compactness - from ""every point has a compact neighbourhood"", ""every point has a base of compact neighbourhoods"" to Hatcher's: ""every neighbourhood contains a compact neighbourhood"". It is easy to see that the second implies the third and vice versa. I can't see why the first (+Hausdorff) is equivalent to them. I would like to know why compactness (assuming Hausdorff) implies local compactness (defined by 3.) and implication 1=>2&3 seems useful here ;)","['general-topology', 'compactness']"
258802,verify k-form is exact,"I wonder how to check some simple 1-form or 2-form is exact. For instance,  2-form $w=xdy \wedge dz + ydz \wedge dx − 2zdx \wedge dy$  or 1 form $w=(2x^2y^2+6xy^3)dx + (8x^2y+x^2y^2)dy$. I know that by definition, if there is an $f$ for which $df=w$, then for the first example, $f$ has to be 1 form, and for the second, $f$ has to be 0 form. But in practice, I am confused how to actually compute and get such $f$.",['differential-geometry']
258803,How many citations to read before convergence?,"So I have the following question assuming I start with N academic papers, though I was thinking to make this simple I start with one academic paper. And say it has C citations, and each one of these C citations, has their own D citations. Is there a way I could estimate when there would be a convergence of the number of citations. Basically when I would end up reading citations that I had already read? (So basically D would be one of the N papers) (The inspiration for this question is because I have to do a literature review in Bioengienering, and I was wondering, what depth I should go to to read relevant papers, that are cited by a relevant paper, that is sufficient to have done an in depth analysis of my sub field)","['statistics', 'estimation', 'graph-theory', 'network', 'combinatorics']"
258819,Solving for $y$ with $\arctan$,"I know this is a very low level question, but I honestly can't remember how this is done. I want to solve for y with this:
$$
x = 2.0 \cdot \arctan\left(\frac{\sqrt{y}}{\sqrt{1 - y}}\right)
$$
And I thought I could do this:
$$
\frac{\sqrt{y}}{\sqrt{1 - y}} = \tan\left(\frac{x}{2.0}\right)
$$ But it seems like I've done something wrong getting there. Could someone break down the process to get to $y =$ ? Again, I know this is very basic stuff, but clearly I'm not very good at this.",['trigonometry']
258824,Symmetric Group $S_n$ is complete,"I am just checking some properties of the symmetric group and found on Wikipedia the statement that ""Conversely, for $n \neq 6$ , $S_n$ has no outer automorphisms, and for $n \neq 2$ it has no center, so for $n \neq 2, 6$ it is a complete group, as discussed in automorphism group, below."" I could show that $Z(S_n)=1$ but do you know an easy proof for $\mathrm{Aut}(S_n)=\mathrm{Inn}(S_n)$ ?","['group-theory', 'abstract-algebra']"
258831,Are these two bounds close to each other?,"Recently I proved a some bound about something. The bound is 
(details : come soon) Upper bound $f(k)< k^{k^{O(k)}}$. Lower bound $f(k)< k^{k^2-o(k)}$ My question is Are these two bounds close? For general meaning. What should I call the lower bound? An exponential function? Or something other looks like a litter larger. Clearly it is not as large as double exponential. Should I need to stress that the exponent in the lower bound is $k^2$.",['functions']
258872,"Eigenvalues and column space, nullspace","Is there a way to relate Eigenvalues to the column space and nullspace of a matrix? I believe a matrices with different eigenvalues would have a different column spaces and/or nullspace.
Is this correct? I am wondering if you can prove that the Eigenvalues of $A$ and $A^T$ are equal using properties of column spaces and nullspaces. My thinking is: If you transform a matrix $A$ into $B$, if the row space of $B$ is orthogonal to the nullspace of $A$, and the column space of $B$ is orthogonal to the left nullspace of $A$, then matrices $A$ and $B$ have the same eigenvalues.",['linear-algebra']
258878,What is the derivative of a power series composed with a sum of iterations on x?,"Assume the following situation. I want to evaluate the derivative of a function for which I have a power series. In principle this is well known: just insert the derivatives at each coefficient:
$$ S(x) = \sum_{k=0}^\infty a_k \cdot x^k \to S(x)' = \sum_{k=0}^\infty (k+1)\cdot a_{k+1} \cdot x^k $$
and evaluate. So far, so good. The convergence-radius of the power series is small,  but fortunately I can reexpress it as 
$$ S(x) = x_0-x_1+x_2-\ldots - x_{m-1}+\sum_{k=0}^\infty a_k \cdot x_m^k $$
and I do not know, how I reflect the leading $x_k$ into the derivative. It is with a transfer-function $f(x)=b^x-1$ that  $$x_1=b^x-1,x_2=b^{x_1}-1,\ldots x_m=b^{x_{m-1}}-1$$ such that $x_m$ is in the radius of the power series for $S(x)$.
So my question is now how to include that leading terms in the formula for the derivative? Is it simply to write the derivative 
$$ S(x)' = f'(t)_{|t=x} - f'(t)_{|t=x_1} + \ldots - f'(t)_{|t=x_{m-1}} + \sum_{k=0}^\infty (k+1)\cdot a_{k+1} \cdot x_m^k \qquad \text{???}$$
but this is just a guess...","['power-series', 'derivatives']"
258891,"Is the set $\{\{1\},\emptyset\}$ a subset of $\{\{1\}\}$?","Let $A = \{\{1\},\emptyset\}$, $B=\{\{1\}\}$. Is it true that $A\subset B$?",['elementary-set-theory']
258898,Why the Picard group of a K3 surface is torsion-free,"Let $X$ be a K3 surface. I want to prove that $Pic(X)\simeq H^1(X,\mathcal{O}^*_X)$ is torsion-free. From  D.Huybrechts' lectures on K3 surfaces I read that if $L$ is torsion then the Riemann-Roch formula would imply that $L$ is effective. But then if a section $s$ of $L$ has zeroes then $s^k\in H^0(X,L^k)$ has also zeroes, so no positive power of $L$ can be trivial. What I am missing is how the Riemann-Roch theorem can imply that if $L$ is torsion then $L$ is effective?","['algebraic-geometry', 'k3-surfaces', 'complex-geometry']"
258914,S-Unit equations in cyclotomic fields,"By a Siegel's result, one knows that there exist only finitely many solutions of the equation: $$x+y=1$$ where the unknowns $x$ and $y$ are units in the ring of integers of a cyclotomic field. Do you know an algorithm that can describe all the solutions?",['number-theory']
258918,formula that can be used to integrate powers of log-sin,"I found a formula which, upon differentiating, can be used to evaluate various powers of log-sine or log-cos integrals. $\displaystyle I(a,p)=\int_{0}^{\frac{\pi}{2}}x\cos^{p-1}(x)\sin(ax)dx$ $=\displaystyle\frac{\pi}{2^{p+1}}\Gamma(p)\left(\frac{\psi(\frac{p+a+1}{2})-\psi(\frac{p-a+1}{2})}{\Gamma(\frac{p+a+1}{2})\Gamma(\frac{p-a+1}{2})}\right); \;\ p>0, \;\ |a|<|p+1|$ For example, this can be differentiated w.r.t $a$, set $a=0$, then differentiate w.r.t $p$, then the result $\displaystyle\int_{0}^{\frac{\pi}{2}}x^{2}\ln^{2}(2\cos(x))dx=\frac{11{\pi}^{5}}{1440}$ is obtained. My question is, how can the above formula be derived.  I realize it looks nasty, but may 
not be as bad as it appears.  It would seem the trig version of the Beta function could be 
applied, but that $ax$ in the $\sin$ throws me off. The digammas in the solution make it seem 
as if some differentiating of the Gamma function has been done.  Does anyone have any 
ideas how to evaluate the above integral to that result?  I know some here, like Sasha 
and Robjohn, are very adept at using the digamma, so I thought perhaps this problem would 
be of interest. I ran a few examples, and it does work.  The differentiation is a little 
tedious, though, depending on the power one wants to integrate. I had a thought.  For what it's worth.  Maybe the identity: $\displaystyle\frac{1}{\pi}\int_{0}^{\pi}\left(2\cos(t/2)\right)^{x}\cos(ty)dt=\frac{\Gamma(x+1)}{\Gamma(\frac{x}{2}+y+1)\Gamma(\frac{x}{2}-y+1)}$ could be applied with $x=p-1$ and $y=a/2$.  It looks like it may be promising. :)",['integration']
258931,"In a metric space, compactness implies completness","Proposition Let $(M,d)$ be a metric space. If $K\subset M$ is compact, then $K$ is complete. Proof Let $\{x_n\}_{n=1}^\infty \subset K$ be a Cauchy sequence, then
$$ \forall \varepsilon > 0 \quad \exists n_0 \in \mathbb N \quad \forall m,n\geq n_0 \quad d(x_n,x_m) < \varepsilon.  $$
$(\text{Step } 1)$ Since $K$ is compact, $\{x_n\}_{n=1}^\infty$ has an accumulation point $x^*\in K$ (already proved for every metric space). Let's see that $\lim_{n\to\infty} x_n = x^*$. $(\text{Step }  2)$ Since $x^*$ is an accumulation point $$\forall k\in \mathbb N \quad \exists x_{n_k} \quad\text{s.t.}\quad d(x_{n_k}, x^*) <\frac{1}{k} $$ $(\text{Step }  3)$ Let $\varepsilon > 0$, then $\exists k_0 \quad n_{k_0} \geq n_0 \quad d(x_{n_{k_0}} x^*) < \varepsilon $. Now if $n \geq n_0$, then
$$ d(x_n,x*) \leq d(x_n, x_{n_{k_0}}) + d(x_{n_{k_0}}, x*) \leq \varepsilon + \varepsilon = 2\varepsilon $$
so every Cauchy sequence converges and $K$ is complete. Question Is this proof correct? I can't understand steps $(2)$ and $(3)$ (why uses $\frac{1}{k}$?). Thanks in advance. Edit Is this proof correct? Let $\{x_n\}_{n=1}^\infty \subset K$ be a Cauchy sequence, by definition $\forall
\varepsilon >0 \;\, \exists n_0\in \mathbb N \;\, \forall m,n \geq n_0 \;\, d(x_n,
x_m) < \varepsilon$. Since $K$ is compact, the sequence has an accumulation point  $x^*\in K$ (already proved). Let's see that $\lim_{n\to\infty}x_n = x^*$: since $x^*$ is an accumulation point, then exists a subsequence
    $\{x_{n_k}\}_{k=1}^{\infty}\subset \{x_{n}\}_{n=1}^{\infty}$ that converges to $x^*$, in other words $\forall
	\varepsilon > 0 \;\, \exists k_0\in\mathbb N \;\, \forall k \geq k_0 \;\,  d(x_{n_{k}}, x^*) < \varepsilon$. Because of the triangular property $d(x_n,x^*) \leq d(x_n, x_{n_{k}}) + d(x_{n_{k}}, x^*) \leq 2\varepsilon$, so every Cauchy sequence converges and $K$ is complete.","['general-topology', 'separable-spaces', 'metric-spaces', 'compactness']"
258932,Distribution Probability Problem,"Let $X_1$ and $X_2$ denote the survival times of two computer components. Assume that $X_1, X_2 \sim \text{Exp}(1)$. Find the distribution of the total survival time of the two components ($T=X_1+X_2$) and the distribution of the ratio of the survival time of the first component and the total surviving time of the two components($R=X_1/(X_1+X_2)$) by deriving the joint pdf of $T$ and $R$ and integrating out $R$ and $T$ to the marginal pdfs of $T$ and $R$. Identify the two distributions. My professor told me the answer is $R \sim \text{Unit}[0,1]$ but it doesn't help me very much. Just shows me that I can't solve it. Any help would be greatly appreciated!","['statistics', 'probability', 'probability-theory']"
258952,What kind of matrix/tensor notation is this?,"I'm hoping someone on here recognises this and has an answer, because I'm having serious memory issues. About a year ago, I came across the following way of representing tensors of rank $n$ in matrix form, in a way similar to block matrices. Maybe this is just an alternative to block matrices actually. Consider a simple $2 \times 2$ matrix definition: I can represent a $2 \times 2 \times 2$ rank-3 tensor as a cuboid, but this is rather hard to show in a paper or proof, so a convenient notation exists that ""splits up"" the layers of the cuboid into $2 \times 2$ matrices, which can be flattened out and shown contiguously as follows: Ditto a $2 \times 2 \times 2 \times 2$ rank-4 tensor can be represented as follows: For both of these equalities, the notation on the left of the $=$ sign is the standard way of writing block matrices. However the explicit partition on the right is what I'm after: is there a particular name for this notation? Is it actually used somewhere to represent cuboids and other higher rank tensors or did I imagine it? Thanks in advance if anyone has any info!","['notation', 'matrices', 'linear-algebra', 'block-matrices', 'multilinear-algebra']"
258978,"Let $X$ be a connected space, $f:X\to X$ continuous involution, $g:X\to\mathbb{R}$ continuous. Prove that $\exists$ $x\in X$ such that $g(x)=g(f(x))$.","This is a homework problem in an undergraduate topology class that I am ludicrously (and probably stupidly) stuck on. Any guidance would be appreciated: Let X be a connected space, $f:X\to X$ a continuous involution (i.e. f is its own inverse), $g:X\to\mathbb{R}$ continuous. Prove that $\exists$ $x\in X$ such that $g(x)=g(f(x))$. Here are the things I understand: Some examples of $f$ include the identity map, $f(x)=-x$, $f(x)=\frac{1}{x}$ if $x\neq0$, etc. The result clearly holds if $f$ has a fixed point. I know any continuous involution in $\mathbb{R}^2$ has a fixed point, but we are on an arbitrary connected space, and I have no results I can use for such a thing. I can define a new continuous function $h:X\to\mathbb{R}$ so that $h(x)=g(f(x))-g(x)$. If this function has a zero, the result follows, but I don't know how to show it does. I could apply the intermediate value theorem since X is connected and $g:X\to\mathbb{R}$, but I again don't see how this would be helpful. Thanks very much in advance!",['general-topology']
258985,Showing directly that the principal directions are going to be orthogonal,"So first of all, I know that the Weingarten map (which from now on I shall denote by $L$) is a symmetric linear operator, so there is an orthonormal basis of eigenvalues (Spectral Theorem). I have been trying this concrete example for a while but I am just stuck and I would appreciate an extra pairs of eyes. I will use the result that claims $L=G^{-1}H$ where $G$ is the matrix for the first fundamental form and $H$ is the matrix for the second fundamental form. Our surface is given by $f(u,v)=(u\cos v, u\sin v , v)$. Then: $f_u=(\cos v, \sin v, 0)$, $f_v=(-u\sin v, u \cos v, 1)$, $f_{uu}=(0,0,0)$, $f_{uv}=f_{vu}=(-\sin v, \cos v, 0)$, and $f_{vv}=(-u\cos v, -u \sin v, 0)$. Thus, $g_{11}=f_u\cdot f_u=1$, $g_{12}=g_{21}=f_u\cdot f_v=0$, and $g_{22}=f_v\cdot f_v =u^2+1$. Then, $f_u\times f_v=(\sin v, -\cos v, u)$, so $n=\frac{1}{\sqrt{1+u^2}}(\sin v, -\cos v, u)$. Then, $h_{11}=n\cdot f_{uu}=0$, $h_{12}=h_{21}=n\cdot f_{uv}=\frac{-1}{\sqrt{u^2+1}}$, and $h_{22}=0$. Then as $G^{_1}=Diag[1,\frac{1}{1+u^2}]$, we have that $L=G^{-1}H$, is: $L_{11}=0$, $L_{12}=\frac{-1}{\sqrt{u^2+1}}$, $L_{21}=\frac{-1}{(u^2+1)^{3/2}}$, and $L_{22}=0$ (here is where I start to doubt because I thought I would always wind up with a symmetric matrix). I get that the eigenvalues of this matrix are given by $\det(\lambda I-L)=\lambda^2-\frac{1}{(1+u^2)^2}$, so $k_1=\frac{1}{u^2+1}$, and $k_2=-k_1$. Then to find the first principal direction, we have to find the eigenvector correspoding to $k_1$, which turned out to be $(\frac{-1}{\sqrt{u^2+1}},1)$, and the other principal direction turned out to be $(\frac{1}{\sqrt{u^2+1}},1)$, which are not always orthogonal, so I dont know where I went wrong.",['differential-geometry']
258996,Bourbaki Proof of Zorn's Lemma in Lang's Algebra,"Serge Lang in his book Algebra has a nice appendix on set theory at the end of the book. In particular, in paragraph 2, pp. 881-884 he provides a proof of Zorn's Lemma from ""other properties of sets which everyone would immediately grant as acceptable psychologically"" (see middle of p. 881). As I understand Zorn's Lemma is equivalent to the Axiom of Choice and to the Well Ordering Principle. However, in Lang's proof I can not identify a point where either of the above two axioms is used. At the top of p. 882 he gives an argument according to which ""we can assume that the set under consideration has a least element"", but this, ""without loss of generality"". So, even though this resembles the ""well ordering principle"", it does not seem to be it. My question is: Are indeed the axiom of choice or the well-ordering principle not used in Lang's proof? If yes where? If not, then what is the subtle set-theoretic axiom that this proof uses to deliver Zorn's Lemma? Edited: In the appendix that I am referring to, Zorn's Lemma appears as Corollary 2.5. However, when by ""proof of Zorn's Lemma"", I mean all the material that Lang proves to get to Corollary 2.5, i.e. Theorem 2.1, Lemma 2.2, Lemma 2.3, Corollary 2.4.","['set-theory', 'abstract-algebra', 'axiom-of-choice']"
259001,A continuous surjection that is not a quotient map,"I was going through an old topology prelim, and encountered a question which I'm really not sure how I should work out. Here it is: Suppose we let $X = \mathbb{R} \times \{3,4,…\} \subset \mathbb{R}^2$. Now let $L_{\theta} \subset \mathbb{R}^2$ be the line through the origin with slope $\tan \theta$, i.e. the directed angle from the positive $x$-axis to $L_{\theta}$ is $\theta$. Further, we let 
$$ Y= \bigcup_{i \geq 3} L_{\pi/i}.$$ Also, we define $g: X \rightarrow Y$ by $g(x,i)= (x, x\tan(\pi/i))$. We have to show that $g$ is a continuous surjection, but not a quotient map. Any ideas how I should approach this?",['general-topology']
259031,Proving that a closed simple polygon in the plane is convex if and only if all the interior angles measure less than or equal to $\pi$ radians,"Consider a closed simple polygon in the plane. It is intuitively obvious that the polygon is convex if and only if all the interior angles measure less than or equal to $\pi$ radians. I have never seen a rigorous proof of this fact and I was wondering if anyone could provide such a proof. A related question: Given a concave polygon (or more generally a higher dimensional polytope), how can we prove that there will always be two vertices of the polygon which cannot be joined by a line lying entirely inside the polygon?","['geometry', 'polygons', 'reference-request', 'convex-geometry']"
259034,Equivalent condition for a vector space to be finite dimensional,"Let $k$ be a field and let $V$ be a vector space over $k$. Then $V$ is finite dimensional if and only if for every $\phi\in End_k(V)$, there are $a_0,\dots,a_{m-1}\in k$ such that 
  $$\phi^m+a_{m-1}\phi^{m-1}+\cdots+a_1\phi+a_0id_V=0.$$ I have no idea on how to prove this statement. I was trying to use the fact that $V$ is finite dimensional if and only if $End_k(V)$ is finite dimensional... Could you help me with this? Thanks!","['linear-algebra', 'abstract-algebra']"
259035,why a geodesic is a regular curve?,"In most definitions of the geodesic, it is required to be a regular curve,i.e. a smooth curve satisfying that the tangent vector along the curve is not 0 everywhere. I don't know why.",['differential-geometry']
259047,Solving a trig equation $1+ \sin (x)=2 \cos(x)$?,"How would I solve the following equation?
$$
1+ \sin (x)=2 \cos(x)
$$
I am having difficult with it.",['trigonometry']
259058,Find the smallest possible value of $a_1$.,"Let $a_1,a_2,...,a_{11}\in \mathbb{N}$ with $a_1<a_2<...<a_{11}$. If $\frac{1}{a_1}, \frac{1}{a_2},...,\frac{1}{a_{11}}$ forms an arithmetic sequence, find the smallest possible value of $a_1$. My answer is 2520, I get this by finding the LCM of 1, 2, ..., 11, which means the arithmetic sequence is 1/27720, 2/27720, ..., 11/27720, 11/27720=1/2520, so the answer is 2520. But the answer should be 2310, what's wrong with my solution? Thank you.",['sequences-and-series']
259078,Showing that the infinite grid is Eulerian,"In a post to usenet in 2004 , I wrote: I'm currently remembering learning [sic] some (long forgotten) things about
  Graph Theory via Robin J. Wilson's ""Introduction to Graph Theory"", 2nd.
  ed., 1972. Unfortunately, I'm having a hard time with one of the exercises, which
  asks for the reader to show that the infinite square grid is an Eulerian
  graph by showing an explicit two-way Eulerian path (i.e., one path that
  covers every edges of the graph and that extends in both directions). Where can I find a hint for this excercise? At that point, I had already seen that the infinite square grid (considering only the vertical or horizontal lines as being the ""edges"" of the grid) is Hamiltonian by a simple drawing of two ""concentric"" spirals, as the following figure shows: One of the replies that I received was from David Eppstein, who told me: ""Hint: spiral."" Unfortunately, I have revisited the problem from time to time and I have not found a way to solve it. I asked some colleagues and they were not also able to come up with an answer. So, how can one systematically traverse all the edges of the unit grid without getting stuck at some point by the two-sided infinite path bumping into itself?","['graph-theory', 'combinatorics']"
259079,Find the value of : $\lim_{n\to\infty}[(n+1)\int_{0}^{1}x^{n}\ln(1+x)dx]$.,I am stuck on the following problem: Find the value of :  $$\lim_{n\to\infty}[(n+1)\int_{0}^{1}x^{n}\ln(1+x)dx].$$ My attempts:  Let $$I_{n}= \lim_{n\to\infty}[(n+1)\int_{0}^{1}x^{n}\ln(1+x)dx]=\lim_{n\to\infty}[\ln(2)-\int_{0}^{1}\frac{x^{n+1}}{1+x}dx]$$ and now i can not progress. Please help. Thanks in advance for your time,"['definite-integrals', 'integration']"
259102,Young's inequality without using convexity,"I was doing some problems from Rudin's Principles of Mathematical Analysis and came across a problem in which he asks you to prove Hölder's inequality via Young's inequality: If $u$ and $v$ are nonnegative real numbers, and $p$ and $q$ are positive real numbers such that $\displaystyle \frac{1}{p}+\frac{1}{q}=1$, then $\displaystyle uv \leq \frac{1}{p}u^p+\frac{1}{q}v^q$. I'm familiar with the proof using convexity of the $\log$ function and Jensen's inequality, but Rudin hasn't defined the $\log$ function by chapter $6$ (where this problem originates) and hasn't done anything with convexity. Usually he gives everything necessary for a problem before he poses one, so this seems to be something of an omission. Perhaps he wants us to read Chapter $8$ to learn about $\log$ and prove Jensen's inequality before attacking this problem? But then why put it in Chapter $6$? My question: is there a proof of Young's inequality that does not use convexity of $\log$ or something similar? If one exists, can it be done using only the material from chapters $1-6$ of Principles ? (For clarity, chapter 1-6 essentially cover the real number system, metric space topology, sequences and series, continuity, differentiability, and the Riemann-Stieltjes integral.)","['young-inequality', 'inequality', 'real-analysis']"
259129,Is $10^n+1$ composite for all $n\in \mathbb{N}$ greater then $2$?,"Is $10^n+1$ composite for all $n\in \mathbb{N}$ greater then $2$? I tried many values of $n$, and $10^n+1$ is composite each time (excpet $n=1,2$). Is my conjecture correct? Thank you.",['number-theory']
259145,The trick to proving trigonometric identities,"This question is motivated from the following excerpt from Rational Points on Elliptic Curves by Silverman and Tate: $$\cos \theta = \frac{1 - t^2}{1 + t^2}, \sin \theta = \frac{2t}{1+t^2}$$ If you have some complicated identity in sine and cosine that you want
to test, all you have to do is substitute these formulas, collect powers of $t$ ,
and see if you get zero. (If they had told you this in high school, the whole
business of trigonometric identities would have become a trivial exercise in
algebra!) I realized that they are absolutely right. The above substitution and de'Moivre's formula allows us to convert any polynomial equation in $\left\{\sin n \theta, \cos n\theta \right\}_{n\in \mathbb{N}}$ into a polynomial equation in $t$ . And a polynomial equation in $t$ can be simple to verify (may be laborious at times though). Are there trigonometric formulas in one variable that cannot be derived through this method? If you know any, please point it out. Additionally, are there software packages that use this method to verify trigonometric formulas? I would like to know any algorithms used to verify trig. identities. Thank you :)","['trigonometry', 'algebra-precalculus', 'algorithms']"
259146,Equations Modulo a Prime p,"How many solutions has the equation $$x^2+y^2+z^2=0,$$ in the finite field $\mathbb Z_p$, where $p$ is a prime number?",['number-theory']
259158,Prove an identity including determinant,"Prove that: $$\begin{equation}   \begin{vmatrix}     x_0^{2n+1}&x_0^{2n}&\cdots&x_0&1\\ x_1^{2n+1}&x_1^{2n}&\cdots&x_1&1\\ \vdots&\vdots&\cdots&\vdots\\ x_n^{2n+1}&x_n^{2n}&\cdots&x_n&1\\ (2n+1)x_0^{2n}&2nx_0^{2n-1}&\cdots&1&0\\ \vdots&\vdots&\cdots&\vdots&\cdots\\ (2n+1)x_n^{2n}&2nx_n^{2n-1}&\cdots&1&0\\   \end{vmatrix}=(-1)^{n}\prod_{n\geq i>j\geq 0}(x_i-x_j)^4 \end{equation}$$ where $(x_i^{2n+1})'=(2n+1)x_i^{2n}$,$\cdots$,$x_i'=1$,$1'=0$.","['matrices', 'determinant']"
259167,"An isomorphism between $( \mathbb{R} , + )$ and $ ( P , \cdot )$","Am I incorrect in believing that the following exercise is not possible? Prove that the additive group $( \mathbb{R}, + )$ of real numbers is isomorphic to the multiplicative group $( P , \cdot )$ of positive reals. My reasoning is that if we had $\phi \colon \mathbb{R} \to P$ as our isomorphism, then we have $$\phi(\tfrac{1}{3}) = \tfrac{1}{3}$$ 
and
$$\phi(-3) = \tfrac{1}{3}$$ Am I missing something?","['group-theory', 'abstract-algebra']"
259196,About the meaning of the notation $\cup_{S \in C}$,"I have encounter this example in the notes, but not sure what did it mean. $\cup_{S \in C} S = \emptyset \cup \{ \emptyset \}=\{\emptyset\}$
  where $C= \{\emptyset,\{\emptyset\}\}$ Is this means union set ""S"" itself and ""S"" is in the ""C"" set?",['elementary-set-theory']
259213,Question about a proof about singular cardinals,"The following is a lemma in Just/Weese on page 179: Lemma 17: Let $\kappa$ be an infinite cardinal. Then $\kappa$ is singular iff there exist an $\alpha < \kappa$ and a set of cardinals $\{\kappa_\xi : \xi < \alpha \}$ such that $\kappa_\xi < \kappa$ for every $\xi < \alpha$ and $\kappa = \sum_{\xi < \alpha}\kappa_\xi$. I think the following constitutes a proof of the $\implies$ direction, can you please tell me where it's wrong? Thank you! Let $\alpha = \mathrm{cf}(\kappa) < \kappa$. Then by a previous exercise (23 (f)) there exists a strictly increasing function $f: \alpha \to \kappa$ such that the range of $f$ is cofinal in $\kappa$. Now for $\xi < \alpha$ define $\kappa_\xi = |f(\xi)|$. Now we want to show that $\kappa = \sum_{\xi < \alpha}\kappa_\xi$. To see this observe that ""$\ge$"" immediately follows from theorem 14 on the same page. The part I need you to check starts here: To show $\le$, assume that we have strict inequality $ \sum_{\xi < \alpha}\kappa_\xi < \kappa $. We distinguish two cases: $\kappa$ is either an infinite successor cardinal or a limit cardinal. If $\kappa = \left ( \sum_{\xi < \alpha}\kappa_\xi \right )^+$ is an infinite successor cardinal then by corollary 15 (on the same page) $\kappa$ cannot be the union of fewer than $\kappa$ sets each of which has cardinality less than $\kappa$. But $\bigcup_{\xi < \alpha}f(\xi) = f[\alpha] = \kappa $ where $|f(\xi)| = \kappa_\xi < \kappa$ and $\alpha < \kappa$ which would be a contradiction. Hence $\kappa$ must be a limit cardinal so that there exists a cardinal $\eta$ with $\sum_{\xi < \alpha}\kappa_\xi < \eta < \kappa$. But $f$ is cofinal in $\kappa$ hence there is $\xi$ such that $f(\xi) \ge \eta$. Then $\kappa_\xi = |f(\xi)| \ge \eta$. Which is a contradiction. We have: And also, the reason why I am asking this question: in the proof in the book, $\kappa_\xi$ are defined as $\kappa_\xi = \left | f(\xi) \setminus \sum_{\eta < \xi} f(\eta) \right |$.","['cardinals', 'elementary-set-theory', 'ordinals']"
259214,Show that the set is closed,"Let $(E, d)$ be a metric space, $x$ element of $E$. Show that the set
\begin{equation}
 A = \{y \in\ E : d(x, y) \geq 5 \}
\end{equation}
is closed. Generally, how would you go about this? I have an exam soon and I want to learn this.","['metric-spaces', 'analysis']"
259231,Show that the set given is closed,"A question that I encountered which looks different than a normal open/closed sets proofs: Let $(E, d)$ be a metric space, let $f : E\to R$ be continuous and $a$ element of $R$. Show that the set
  \begin{equation}
 A = \{x \in\ E : f(x) = a  \}
\end{equation}
  is closed. There is no inequality, instead there is equality, so do we still prove it the same way? Thank you. PS. I am a beginner and want to learn these for an exam soon.","['general-topology', 'metric-spaces', 'analysis']"
259243,"How to find all morphisms from $(\mathbb{N}, \mid)$ to $(\mathbb{N}, \mid)$?","I just need a small hint, not the full answer. I know that, if $f$ is a morphism, $a \mid b \implies f(a) \mid f(b)$ $a \mid b$ and $a \mid c \implies a \mid b+c$, so $f(a) \mid f(b),   f(a) \mid f(c), f(a) \mid f(b + c)$. Also, $f(a) \mid f(b) + f(c)$ $\forall a \in \mathbb{N}, a \mid 0$, so $\forall a \in \mathbb{N}, f(a) \mid f(0)$ $\forall a \in \mathbb{N}, 1 \mid a$, so  $\forall a \in \mathbb{N}, f(1) \mid f(a) $ From these I can draw some conclusions: a. From 3., $f(0) = a$ ($a \neq 0$), $f(\mathbb{N})$ only contains divisors of $a$. b. From 4., if $f(1) = a$, then $f(\mathbb{N})$ only contains multiples of $a$. The most general form I can think of for f is this: $f(x) = ax^{b} (a, b \in \mathbb{N})$, but I can't seem to go any further than this. Any help is appreciated.",['abstract-algebra']
259247,"Relationships between AC, Ultrafilter Lemma/BPIT, Non-measurable sets","How is it possible to reconcile the following... In 1970, Solovay constructed Solovay's model, which shows that it is consistent with standard set theory, excluding uncountable choice, that all subsets of the reals are measurable. A not too well known application of the Boolean prime ideal theorem is the existence of a non-measurable set[2] (the example usually given is the Vitali set, which requires the Axiom of Choice). From this and the fact that the BPI is strictly weaker than the Axiom of Choice, it follows that the existence of non-measurable sets is strictly weaker than the axiom of choice. Also, a similar question regarding... The ultrafilter lemma is equivalent to the Boolean prime ideal theorem, with the equivalence provable in ZF set theory without the axiom of choice. Many other theorems of general topology that are often said to rely on the axiom of choice are in fact equivalent to BPI. For example, the theorem that a product of compact Hausdorff spaces is compact is equivalent to it. If we leave out ""Hausdorff"" we get a theorem equivalent to the full axiom of choice. Now, Janich's Topology gives a proof of the full blown Tychonoff theorem from the Ultrafilter Lemma (after showing Zorn's Lemma implies the Ultrafilter Lemma).  But this should not be possible since Tychonoff is equivalent to AC and UL is weaker than AC.  So do I need to read his proof more carefully...is he still using the full power of AC elsewhere?","['general-topology', 'set-theory', 'axiom-of-choice']"
259250,Roots of 1 in $\mathbb Q_p$,"How to prove, that all roots of 1
in $\mathbb Q_p$ are roots of $x^{p-1}-1$?
If we consider the ring homomorphism 
$$
\mathbb Z_p \to \mathbb F_p^*,
$$
then we see, that all the roots in power $p-1$ are
equal to 0 modulo $p$. Using Hensel's lemma
we can construct a solusion to $x^{p-1}-1=0$,
which is the same as the first modulo $p$.","['p-adic-number-theory', 'abstract-algebra', 'number-theory']"
259282,Rewriting Conditionals In Their Well Known Form,"The question is, ""Write each of these statements in the form “if p, then q” in English. [Hint:Refer to the list of common ways to express conditional statements.] a) It snows whenever the wind blows from the northeast. b)The apple trees will bloom if it stays warm for a week. c) That the Pistons win the championship implies that
they beat the Lakers. d)It is necessary to walk 8 miles to get to the top of
Long’s Peak. e) To get tenure as a professor, it is sufficient to be world-
famous. f) If you drive more than 400 miles, you will need to buy
gasoline. g)Your guarantee is good only if you bought your CD
player less than 90 days ago. h)Jan will go swimming unless the water is too cold. I am having a little trouble with c), g), and h). For c): Presumably, it would appear that this sentence is discussing a championship match, one between the Lakers and Pistons. Hence, I am having difficulty seeing why it has to be written a particular way. Doesn't ""If the Pistons win the championship, then they beat the Lakers,"" and ""If the Pistons beat the Lakers, then they win the championship,"" convey the same meaning? For g): This is another instance of me not seeing why this conditional statement has to be written any particular way. To me, ""If you bought your CD player less than 90 days ago, then your guarantee is good,"" and ""If your guarantee is good, then you bought your CD player less than 90 days ago,"" convey the same meaning. For h): I wrote, ""If the water is too cold, then Jan won't go swimmming;"" however, the answer key says, ""If the water is NOT too cold, then Jan will go swimming."" Would my answer be acceptable?","['logic', 'propositional-calculus', 'discrete-mathematics']"
259305,Proving a number defined by a sequence is a square number,"I found this problem in a math magazine: Given the sequence $(x_n)_{n \in \mathbb{N}}$ defined by:
  $$
x_0 = 0\\
x_1 = 1\\
x_{n+2}+x_{n+1}+2x_{n}=0
$$
  Prove that $s_n = 2^{n+1}-7x_{n-1}^2, n > 0$ is a square number. I tried searching a rule between the numbers of the sequence and the square numbers ($s_n$) formed:
$$
x_2=-1\\
x_3=-1\\
x_4=3\\
x_5=-1\\
x_6=-5\\
x_7=7\\
x_8=3\\
x_9=-17\\
$$
$$
s_1 = 2^2\\
s_2 = 1^2\\
s_3 = 3^2\\
s_4 = 5^2\\
s_5 = 1^2\\
s_6 = 11^2\\
s_7 = 9^2\\
$$
If I rewrite the rule and square it:
$$
x_{n-1} = -x_{n-2}-2x_{n-3}, n > 3\\
x_{n-1}^2=x_{n-2}^2 + 4x_{n-3}^2 + 4x_{n-2}x_{n-3}\\
$$
apply for the next two, $x_{n-2}$, $x_{n-3}$ the same rule:
$$
x_{n-2}^2=x_{n-3}^2 + 4x_{n-4}^2 + 4x_{n-3}x_{n-4}\\
x_{n-3}^2=x_{n-4}^2 + 4x_{n-5}^2 + 4x_{n-4}x_{n-5}\\
$$
substitute:
$$
x_{n-1}^2=x_{n-3}^2 + 4x_{n-4}^2 + 4x_{n-3}x_{n-4}+4x_{n-3}^2 + 4x_{n-2}x_{n-3}\\
x_{n-1}^2=5x_{n-3}^2 + 4x_{n-4}^2 + 4x_{n-2}x_{n-3} + 4x_{n-3}x_{n-4} \\
x_{n-1}^2=5(x_{n-4}^2 + 4x_{n-5}^2 + 4x_{n-4}x_{n-5}) + 4x_{n-4}^2 + 4x_{n-2}x_{n-3} + 4x_{n-3}x_{n-4}\\
x_{n-1}^2=9x_{n-4}^2 + 20x_{n-5}^2 +  4x_{n-2}x_{n-3} + 4x_{n-3}x_{n-4} + 20x_{n-4}x_{n-5}\\
$$
It seems to lead to a dead end. A help would be really appreciated.","['elementary-number-theory', 'exponentiation', 'sequences-and-series', 'problem-solving']"
259313,"Find the upper and lower limits of $xf(x)$, as $x\rightarrow \infty$","Define $$f(x)=\int_{x}^{x+1}\sin(t^2)dt$$ Find the upper and lower limits $xf(x)$, as $x\rightarrow \infty$. I find the answer as $+1, -1$ since $|\sin(x)| \le 1$. (Of course I calculated that function) Is that right or did I miss something? ========================================================== I solved this way. $2xf(x)=\cos(x^2)-\cos[(x+1)^2]+r(x)$  where $r(x)=\frac{\cos(x+1)^2}{x+1}-2x\int_{x^2}^{(x+1)^2}\frac{cos(u)}{4u^{3/2}}du$ Therefore $xf(x)=\frac{1}{2}{\cos(x^2)-\cos(x+1)^2}+\frac{r(x)}{2}$ Using trigonomeric formula: $2\sin(a)\sin(b)=\cos(a-b)-\cos(a+b)$ Rewrite $xf(x)=±\sin(x^2+x+\frac{1}{2})\sin(x+\frac{1}{2})+\frac{r(x)}{2}$. As $x\rightarrow \infty, r(x) \rightarrow 0$. Suppose $x^2=2k\pi$ for integer $k$. To achieve $±1$, we have to show that $x+\frac{1}{2} \rightarrow 2n\pi+\frac{\pi}{2}$ for some $n$ as $x\rightarrow \infty$. For each $n$, there exists $k$ such that $\sqrt{2\pi k}+\frac{1}{2} < 2n\pi+\frac{\pi}{2} <\sqrt{2\pi (k+1)} +\frac{1}{2} $ Distance between $\sqrt{2\pi k}+\frac{1}{2}$ and $2n\pi+\frac{\pi}{2}$ is at most $\sqrt{2\pi (k+1)} +\frac{1}{2} -\sqrt{2\pi k}+\frac{1}{2}$. As $k \rightarrow \infty$ the distance becomes arbitrary small. Therefore $ x \rightarrow \infty$, $xf(x)=±\sin(2n\pi+\frac{\pi}{2})=±1$.",['analysis']
259316,Cardinal sums over successor ordinals are equal?,Can you tell me if the following claim and subsequent proof are correct? Thanks. Claim: If $\alpha = \delta + 1$ is an infinite successor ordinal then $\sum_{\xi < \alpha } \kappa_\xi = \sum_{\xi < \delta} \kappa_\xi$. Proof: Let $f: \delta + 1 \to \delta $ be a bijection. Then $f$ induces a bijection $F: \bigcup_{\xi < \alpha} \kappa_\xi \times \{\xi \} \to \bigcup_{\xi < \delta} \kappa_\xi \times \{\xi \}$ so that $\sum_{\xi < \alpha} \kappa_\xi = \sum_{\xi < \delta} \kappa_\xi$. Thanks for your help.,"['cardinals', 'elementary-set-theory']"
259325,"$H=\langle a,b| a=bab, b=aba\rangle $ and $\frac{H}{A}\cong\ Q_8$","Here is my problem: Let $$H=\langle a,b| a=bab, b=aba\rangle $$ and $\frac{H}{A}\cong\ Q_8$ wherein $A\leq Z(H)\cap H'$. Show that $H\cong Q_8$. Working on the elements, I could see that $H\cong Q_8=\langle a,b| a^4=1, a^2=b^2,ab=ab^3\rangle$. In fact, the $G$'s relations can be yielded by $H$'s. Yet; I don't see the additional points, above problem wanted to give me? Thanks.","['finite-groups', 'group-theory']"
259329,Constructing a Simple Group with a Specific Number of Sylow $p$-subgroups,"I've been studying for my final exams, and I came across the following question: If possible, give an example of a simple group $G$ with $n>1$ Sylow $p$-subgroups such that the order of $G$ does not divide $n!$. If not possible, briefly explain why. Now, it didn't take me long to think of the following ""numerical"" example: a group of order $60=2^2\cdot3\cdot5$ where there are $3$ Sylow $2$-subgroups. My question is whether or not such a group exists, and if it does, is there any simple way to describe these groups based on knowing how the Sylow structure is built? In trying to describe the above group, I think I showed that it can't exist. This is because there either have to be $4$ Sylow 3-subgroups or $10$ Sylow 3-subgroups. The second case leads to a contradiction since then there would have to be $k$ Sylow 5-subgroups such that $k(5-1)=30$, and likewise, in the first case, we find we'd have to have 13 Sylow 5-subgroups, also a contradiction. Is all of this correct and is there an easy way to determine whether such a group exists or not?","['sylow-theory', 'group-theory', 'abstract-algebra']"
259347,How to find $(-64\mathrm{i}) ^{1/3}$?,"How to find $$(-64\mathrm{i})^{\frac{1}{3}}$$
This is a complex variables question.
I need help by show step by step.
Thanks a lot.","['complex-numbers', 'computational-complexity', 'complex-analysis']"
259351,Permutations with a cycle $>\frac{n}{2}$,"I'm interested in the following question: Let $S_n$ be the set of all permutations over $\{1,...,n\}$. We know that $|S_n|=n!$. How many permutations of this set has a cycle larger than $\frac{n}{2}$? Thanks PS - not hw.","['permutations', 'discrete-mathematics', 'combinatorics']"
259352,Why do we need a diagonal matrix?,"Apart from simplifying matrix powers, why do want to diagonalize a matrix? Do they have any appealing application which can be used to motivate to study diagonal matrices. 
Thanks for any answers.","['matrices', 'linear-algebra']"
259356,An inequality from the handbook of mathematical functions (by Abramowitz and Stegun),"Prove that $$\frac{1}{x+\sqrt{x^2+2}}<e^{x^2}\int\limits_x^{\infty}e^{-t^2} \, \text dt \le\frac{1}{x+\sqrt{x^2+\displaystyle\tfrac{4}{\pi}}}, \space (x\ge 0)$$","['inequality', 'calculus', 'special-functions', 'integral-inequality', 'real-analysis']"
259358,If $f(x)=x^2$ why $f(x+1)=f(x)+2x+1$ instead of $f(x+1)=x^2+2x+1$?,"I'm reading Spivak's Calculus , there's a part where he suggests that the student should check some assertions: $$f(x)=x^2$$ Then I've evaluated for $f(x+1)$ which is $f(x+1)=(x+1)^2=x^2+2x+1$. Why he says that $f(x+1)=f(x)+2x+1$? Does $f(x)=x^2$ in this case?","['calculus', 'functions']"
259386,Solve this equation : $y'(x)+\frac{1}{x}=\frac{1}{y}$,General and particular solution for this first-order nonlinear ODE : $$y'(x)+\frac{1}{x}=\frac{1}{y}$$,['ordinary-differential-equations']
259396,$f:\mathbb D\rightarrow \mathbb D$ be holomorphic with $f(0)=0$ and $f(1/2)=0.$,"I was trying to solve the following problem: Let $f:\mathbb D\rightarrow \mathbb D$ be holomorphic with $f(0)=0$ and $f(1/2)=0,$ where $\mathbb D=\{z:|z|<1\}.$ Then which of the following statements are correct? (a) $|f'(1/2)|\leq 4/3,$ (b) $|f'(0)|\leq 1,$ (c) $|f'(1/2)|\leq 4/3$ and $|f'(0)|\leq 1,$ (d) $f(z)=z$ for $z\in \mathbb D.$ My Attempts: Clearly, here we can apply  Schwarz Lemma.By this lemma,we can say that $|f(z)|\leq |z|$ for all $z \in\mathbb D$ and $|f'(0)|\leq 1$ and so i can say option $(b)$ is definitely correct.But i can not say anything about option $(a)$ .Please help.Thanks in advance for your time.",['complex-analysis']
259406,"If ideal quotients of a ring are isomorphic, are these ideals isomorphic?","Suppose that $R$ is a ring, $I$ and $J$ are ideals in $R,$ and $R/I\cong R/J$ as rings. When does $I\cong J$ as $R$-modules hold?","['ideals', 'abstract-algebra']"
259408,How would I solve the following trig equation?,It is $3\sin x+4\cos x=2 $ What I did is $(3\sin x)^2=((2-4\cos x)^2$ to get $9-9\cos^2x=4-16\cos x+16\cos^2 x$ then I got $25\cos^2 x-16\cos x-5=0$ However I am having trouble finding the root I tried using the quadratic formula and got x=.866 I am not sure what  I do wrong.,['trigonometry']
259430,Sorting Matrix to Block structure,"I have a symmetric matrix and I want it to be as block-like as possible. I don't have a clear definition. I want the smallest number of groups of non zero elements or maybe the most non-zero elements as close as possible to the diagonal. Example:
$$
X = \begin{pmatrix}1& 0 & .3& 0& .5& 0\\
0& 1& 0& .2& 0& .4\\
.3 &0 &1& 0& .3& .1\\
0 & .2 & 0 & 1 & 0 & .3\\
.5 & 0 & .3 & 0 & 1 & 0\\
0 & .4 & .1 & .3 & 0 & 1\end{pmatrix}$$ Output: 
$$
Y = \begin{pmatrix}1& .5 & .3& 0& 0& 0\\
.5 & 1 & .3 & 0 & 0 & 0\\
.3 & .3 & 1 & 0 & 0 & .1\\
0 & 0 & 0 & 1 & .2 & .3\\
0 & 0 & 0 & .2 & 1 & .4\\
0 & 0 & .1 & .3 & .4 & 1\end{pmatrix}$$ I only had to swap column and row 2 with 5 to get this result. My algorithm was that I swapped rows and colums for the largest non-diagonal element (in the upper triangle) to a closer position to the diagonal. Is there a Matlab/Octave function that does this? What is this process called? What should a good algorithm that does this look for? (When to stop, which row to swap, etc). What should be the definition of what I want? The domain my question is related to is that these is a term-term affinity matrix (from Information Retrieval). So if $a_{ij}$ is large then the terms $i$ and $j$ occur often in the same documents. I want to sort the matrix such that the blocks (which broadly refer to topics) can be visualised. In the current state (see image) one can't see much. EDIT: I found out that this is called matrix permutation.","['matrices', 'block-matrices']"
259431,"Different equivalence relations of the set $\{a,b\}$","In the book of Richard Hammack, I come accross with the following question: There are two diﬀerent equivalence relations on the set $A = \{a,b\}$.
  Describe them. OK, I found that the solution is, $$R_1 = \{(a,a),(b,b),(a,b),(b,a)$$
and
$$R_2 = \{(a,a),(b,b)\}$$ Then I thought two more equivalence classes $R_3 = \{(a,a)\}$, $R_4 = \{(b,b)\}$. But when I looked the answer, I saw that, $R_1$ and $R_2$ are true but others are false. Why is that?","['relations', 'equivalence-relations', 'discrete-mathematics']"
259438,Terminology: facet versus face in polytope,"In a polytope , what are the difference and relation between facet and face? How are they defined respectively?
Thanks and regards!",['geometry']
259447,"Is there an ""opposite"" of a geodesic?","If I understand correctly, a geodesic between two points $a$ and $b$ is the ""most direct"" path from $a$ to $b$. Geodesics on a plane are straight lines, geodesics on a sphere are great circle arcs. Geodesics can be defined on any Riemannian manifold (right?). If I've got that roughly correct, then what might be the ""opposite"" of a geodesic? And can a unique ""opposite"" be defined? What about this definition: let a cisedoeg (the opposite of a geodesic) be a curve that connects $a$ and $b$ but that nowhere intersects the geodesic between $a$ and $b$. Also let the tangents to the cisedoeg all be parallel.","['riemannian-geometry', 'differential-geometry', 'geodesic']"
259494,"In a metric space, if a set is compact, then it is closed: improving proof","Let $(M,d)$ be a metric space. If $K\subset M$ is compact, then it is closed (and bounded). Proof Let's see that $M\setminus K$ is open. Let $x\in K$ $$\exists \varepsilon_1 (x), \varepsilon_2(x) \text{ so that } B(x, \varepsilon_1(x))\cap B(y,\varepsilon_2(x)) = \emptyset$$
then $K \subset \cup_{x\in K} B(x, \varepsilon_1(x))$ and, since $K$ is compact $\exists N \in \mathbb N \; \exists x_1,...,x_N \in K$ s.t.
$$ K\subset \bigcup_{i=1}^N B(x_i, \varepsilon_1(x_i)) $$
let $r = \min\{\varepsilon_2(x), i = 1,...,N \} > 0$, then
$$ B(y,r)\cap B(x_i, \varepsilon_1(x_i)) = \emptyset \quad\forall i = 1,...,N $$
therefore $B(y,r)\subset M\setminus K$ and $K$ is closed. Question Why uses $\varepsilon_1(x)$ and $\varepsilon_2(x)$? If we consider, in $\mathbb R$ the interval $[0,1]$ it can't be covered using open balls without covering elements of $\mathbb{R}\setminus[0,1]$, so what happens when choosing $r$? Am I missing something? Thanks in advance.","['general-topology', 'metric-spaces', 'compactness', 'real-analysis']"
259498,How to get from $\frac{x}{x+1}\;$ to $\;1 - \frac{1}{x+1}$?,Please show me how to manipulate $\dfrac{x}{x+1}\;\;$ to get $\;\;1 - \dfrac{1}{x+1}$,"['fractions', 'algebra-precalculus']"
259504,On the impossibility of proving certain problems using double counting.,"Usually in combinatorics, I love proofs by double counting. It gives me a very happy feeling to know a double counting proof. I feel I understand the problem better. A close younger sibling of this technique is to interpret a given expression as a solution to a smartly constructed counting problem. So whenever somebody asks me to prove that a ratio involving factorials is an integer, I try to interpret the ratio as a solution to a counting problem. But throughout my counting life, I have encountered certain expressions which never admit an interpretative proof. One of them is jasoncube's question posted here . I searched online and I could not find a slick proof for jasoncube's question. So this post has the following two questions: 1) For $m,n \in \mathbb{N}$ can you find a counting problem whose solution is $\dfrac{(2m)! (2n)!}{m! n! (m+n)!}$? 2) Is there any literature on the extent of this technique or it's limitations? That is, has anybody proved impossibility results for certain expressions? Thanks, Iso","['reference-request', 'contest-math', 'combinatorics']"
259514,How to define the $0^0$? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Zero to zero power According to Wolfram Alpha : $0^0$ is indeterminate. According to google:
$0^0=1$ According to my calculator: $0^0$ is undefined Is there consensus regarding $0^0$? And what makes $0^0$ so problematic?",['real-analysis']
259516,Finding expected value of $X^2$,"The question is: $X$ is a random variable, and $f(x) = (x-1)/2$ for $1 \le x \le 3$ Find $\Bbb E (X^2)$ Here's my solution:
\begin{align}
\Bbb P(1)&= 0/2= 0 \\
\Bbb P(2)&= 1/2  \\
\Bbb P(3)&= 2/2= 1 \\
\end{align}
\begin{align}
\Bbb E(X^2) =
& 1^2 \Bbb P(1) + 2^2 \Bbb P(2) + 3^2 \Bbb P(3)
\\
 =
& 1 \cdot 0 + 4 \cdot 1/2 + 9 \cdot 1 
\\
=
&
11
\end{align}
This is my solution, but it is wrong. I need help in understanding where my mistake is. Thanks for your help!","['statistics', 'probability']"
259543,Rate of convergence of $\left[1+\frac{a}{x}\right]^x$ to $\operatorname{exp}[a]$ as $x\rightarrow\infty$,"It's well-known that $\lim_{x\rightarrow\infty}\left[1+\frac{a}{x}\right]^x=\operatorname{exp}[a]$.  I am wondering how fast does the limit converge as $x$ increases, and how the speed of convergence depends on $a$. That is, I would like to find out what $f(x,a)$ is where: $$\left|\left[1+\frac{a}{x}\right]^x-\operatorname{exp}[a]\right|=\mathcal{O}(f(x,a))$$ However, I'm having trouble evaluating that absolute value.  Any tips?  Perhaps this a known result...","['asymptotics', 'exponential-function', 'limits']"
259547,Equi-integrability of a single function: is it the same as summability?,"Let $(\Omega, \mathcal{M}, \mu)$ be a measure space and let $f\ge 0$ be a measurable function on $\Omega$. Suppose that $f$ satisfies the following properties: For all $\varepsilon > 0$ there exists a $\delta > 0$ such that for any measurable subset $A\in \mathcal{M}$ such that $\mu(A)<\delta$, we have $$\int_A f(x)\, \mu(dx) < \varepsilon\;$$ For all $\varepsilon > 0$ there exists a measurable subset $B\in \mathcal{M}$ such that $\mu(B)<\infty$ and $$\int_{\Omega \setminus B} f(x)\, \mu(dx) < \varepsilon.$$ Question Does it follow that $f\in L^1(\Omega)$? Clearly it is sufficient to consider only the special case in which $\Omega$ is a probability space. Then I am able to answer affirmatively if $\Omega$ is non-atomic by appealing to the decomposition result explained in this post by Byron Schmuland . That is, since $\Omega$ supports a random variable with uniform $(0, 1)$-distribution, for a fixed value of $\varepsilon$ (say, $\varepsilon = 1$) we can decompose $\Omega$ into a finite disjoint union of sets of measure smaller then $\delta$ and then conclude by means of assumption 1. But this seems too complicated for a result which I feel should be trivial. What am I overlooking? Thank you.","['probability-theory', 'lebesgue-integral', 'measure-theory', 'uniform-integrability']"
259551,Nature of D-finite sets.,"A is called D-finite if A is not containing countable subset. With the above strange definition I need to show the following two properties: For a D-finite set A, and finite B, the union of A and B is D-finite. The union of two D-finite sets is D-finite. By the way, can we construct such D-finite set? Only hints... Thank you.",['elementary-set-theory']
259569,Strengthening My Foundation in Mathematics,"Someone told me that each equation I included in the book would halve the sales. From Stephen Hawking's A Brief History of Time (1988), this quote summarizes why I believe that I have a weak foundation in mathematics. I've always been fascinated by equations; their applications, implications, and histories. I would always wonder where equations came from and how they were developed, meanwhile losing track of the information that teachers were throwing at me. Unfortunately, this is still the case even now :P As an electrical engineering major/math minor, I feel obligated to understand the concepts that I learn in math at a fundamental level. Unfortunately, I didn't really respect math back in middle school and high school, so my understanding of certain topics in math are fuzzy at best. For example, I've passed Calculus I/II/III and Differential Equations, but I never really understood what I was doing; the calculations I'd make were by rote and not by intuition. So I'll ask, where can I start? What do you all recommend I do? Any specific books/sources? Thanks","['education', 'calculus', 'reference-request', 'self-learning']"
259572,Chinese Remainder Theorem result varies,"Sorry if this question is lame. First post! I was going through this book Abstract Algebra
  Theory and Applications
  Thomas W. Judson
  Stephen F. Austin State University In the Chapter 16. Ring Theory the author explains about how Chinese Remainder Theorem can be used to schedule work to Multi-Processor systems in case of Large Integer Calculations. In a particular example of calculating 2134*1531. He broke it down to this: x≡ 9 (mod 95) x≡ 0 (mod 97) x≡ 30 (mod 98) x≡ 55 (mod 99) The result should be 3,267,154. I used two online calculators Calc 1 and Calc 2 and to solve this. Both are giving different and wrong answers 2774788984 and 111543404 respectively. Is there a short and easy way to calculate this?. What is wrong with those calculators? Thanks in advance.","['prime-numbers', 'modular-arithmetic', 'ring-theory', 'number-theory']"
259590,An absolute convergence criterion in $\Bbb C$,"Here's a problem I'm having trouble with: Show that if $\sum u_k$ converges for $u_k\in\Bbb C$, and $|\arg(u_k)|\leq c<\pi/2$ for all $k$, then $\sum |u_k|$ converges too. All I have after looking at it for an hour is that I kind of believe it could be true (I didn't at first), but I don't really know where to start. Could you give me a hint? I know of course that $$u_k=|u_k|(\cos(\arg(u_k))+i\sin(\arg(u_k))),$$ but I don't have any ideas. I've tried looking at it geometrically too, but I just don't see anything.","['sequences-and-series', 'complex-analysis']"
259599,Matrix Determinant,"So I'm reading through my linear algebra textbook to review for my final, and happened upon this statement: The determinant of a matrix with positive entries must be positive. Off the top of my head, I can think of an exception to this: $$A=\begin{bmatrix}1 & 2\\8 & 3\end{bmatrix}$$ where $\det A= (1\cdot 3) - (2\cdot 8) = 3 - 16 = -13$ Am I misinterpreting what I am reading, or is this a misprint? The book is Elementary Linear Algebra, 2nd ed. by Spence, Insel, Friedberg","['matrices', 'linear-algebra', 'determinant']"
259607,Can someone intuitively explain the towers of Hanoi and how a proof by induction can be used?,"I'm having trouble understanding precisely how the proof by induction is used to show that it takes at most $2^n-1$ moves to get all the disks from one peg to another.  Are there any helpful sources or particular insight that you have that may help me, and others, understand this problem more intuitively?","['recursive-algorithms', 'induction', 'discrete-mathematics']"
259609,Hartshorne Exercise II. 3.19 (a),"Let $X$ be a noetherian space.
We say a subset $Z$ of $X$ is constructible in $X$, if it is a finite union of locally closed subsets of $X$. There is the following theorem of Chevalley(we are not supposed to prove it in this thread). Theorem of Chevalley Let $X$ be a scheme.
Let $Y$ be a noetherian scheme.
Let $f\colon X \rightarrow Y$ be a morphism of finite type.
Then $f(Z)$ is constructible in $Y$ for every constructible subset $Z$ of $X$. Hartshorne Exercise II. 3.19 (a) is as follows.
Show that the above thorem can be reduced to the following proposition. Let $X, Y$ be affine and integral noetherian schemes.
Let $f\colon X \rightarrow Y$ be a dominant morphism of finite type.
Then $f(X)$ is constructible in $Y$. How do we show this?",['algebraic-geometry']
259634,Proper mapping theorem,"My professor mentioned a proper mapping theorem after the name of Remmert which says: Let $X$ and $Y$ be complex manifolds, $f:X \to Y$ be a proper holomorphic map, and $V \subset X$ be a complex analytic subvariety of $ X$ , then $f(V)$ is a subvariety of $Y$ . I know this is a deep result, and the proof is not easy, but is there any simple reason which can convince me $f(V)$ is a subvariety, at least intuitively? Besides, what is the analog result in algebraic geometry? In Hartshorne, he can only say the image is constructible set. EDIT : One of intuitive explanation which mix the language of complex and algebraic geometry may be following: suppose X,Y are projective analytic varieties over $\mathbb{C}$ , than they are algebraic varieties. Because proper morphism are closed, and also because the image is a constructible set, it has to be a variety. The problems of above explanation are: (1) The question is obviously local on Y, but I have to assume X,Y are projective analytic varieties in order to translate back to algebraic varities(GAGA).(2)I still use the result that the image is constructible which is not obvious intuitively，and GAGA to connect analytic variety to algebraic variety. All in all, it is not a good idea to use algebraic geometry to explain complex geometry.","['analytic-geometry', 'algebraic-geometry', 'complex-geometry']"
259641,"Is $W^{k,p}$ a reflexive Banach space?","Let $U\subset \mathbb{R}^n$ be an open bounded subset with smooth boundary. Is the Banach space $W^{k,p}(U)$ a reflexive Banach space? If not, for what $k$ and $p$ is it reflexive?","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
259661,"What is an ""indecomposable"" matrix?","What is an indecomposable matrix? I tried to find what it is, but Wikipedia does not have an entry for it. Also, what properties does such matrix have?","['matrices', 'linear-algebra', 'terminology']"
259691,Normal vector to a surface,"I've been reading in my calc book that the gradient vector is always orthogonal to the surface. So for a surface in space described by the level surface $f(x,y,z) = k$ where $k$ is a constant, $\nabla f$ is orthogonal to the surface at every point because the gradient is the normal vector of the surface at every point. Then later I read about parametric surfaces where a surface is described by vector valued function $r(u,v) = <x(u,v), y(u,v), z(u,v)>$ and a normal vector $r_u \times r_v$ or $r_v \times r_u$ How are $r_u \times r_v$ and $\nabla f$ related here? I am referring to James Stewart's Text. Also a last comment I want to make is, what about a normal vector to a surface that doesn't need to be described by a level surface? For example $f(x,y) = z = x^2 + y^2$? How would I go finding the normal vector at any point without rewriting it as $z - x^2 - y^2 = 0$ or parametrizing it? A final Remark: I've been confusing the notion of the gradient vector being tangent to a surface instead of normal to it. There is this rather confusing picture I have which seems to suggests that the gradient vector really is tangent to a surface rather than normal because the gradient is formed by the vector sum of $\partial/\partial x$ and $\partial/\partial y$ and according to the picture I have, both $\partial/\partial x$ and $\partial/\partial x$ are ""flat"" and their sum should also be ""flat"" and not ""pointing up"" Added PIcture","['multivariable-calculus', 'calculus']"
259725,What are Dirichlet characters?,"What are Dirichlet characters? I don't really understand the definitions given by wikipedia or wolframalpha, are they defined to be partially multiplitictive just because that gives them, an euler product representation? Or is there some other reason?","['analytic-number-theory', 'number-theory']"
259729,How does an Indefinite Integral = Definite Integral with Variable as Upper Limit?,"Source: P36 of Elementary Differential Equations, 9th Ed by Boyce, DiPrima et al. $${\int{f(t)\text{ }dt} = \int_{t_0}^t f(s) \text{ } ds \quad \text{ where $t_0$ is some convenient lower limit of integration.}}  \tag{$*$}$$ $\Large{\text{1.}}$ I now know: 
$ \int{f(t)\text{ }dt} \qquad$ is $\color{green}{\text{  a set of functions $\qquad$ (**)}} $ and  $  \int_{t_0}^t f(s) \text{ } ds \qquad$ is $\color{#B53389}{\text{ an element of set (**) above.}} \quad $ So how and why is $(*)$ true? How can a $\color{green}{\text{  a set of functions}}$ = $\color{#B53389}{\text{ an element of the same set}}  $  ? Supplementary to William Stagner's answer and Peter Tamaroff's comment Thanks to your explanations, I now know that: 
$\int{f(t)}\text{ }dt = g(t) + C \qquad \forall \ C \in \mathbb{R}\ \tag{$\natural$}$
$\int_{t_0}^t f(s) \text{ } ds = g(t) - g(t_0) \tag{$\blacklozenge$}$ Since $g(t)$ is one function and $t_0$ is one arbitrarily chosen argument/number, thus $-g\left(t_0\right)$ is ONE FIXED number. In contrast, $C$ is ANY real number. $\Large{\text{3.}}$ So $(\natural) \mathop{=}^{?} \, (\blacklozenge) \iff C \mathop{=}^{?} -g(t_0).$ But how and why is : $ C \mathop{=}^{?} -g\left(t_0\right) \; $?","['calculus', 'integration', 'analysis']"
259751,Trying to figure out a formula with given input and outputs.,"I'm playing this video game where people can get kills, deaths, and assists , and all this is recorded on a stats website. The stats website gives you a rating by directly manipulating these numbers. In the first entry, I have 26 kills, 5 deaths, and 19 assists. The KDA ratio the website gave me was 29.8. At first thought, I guessed that the formula was ratio = (kills*5 + assists)/deaths. But then the second entry threw me off. 21.33 Kills, 1.33 deaths, and 4.33 assists. And the ratio outputted here is 24.58. Is there a good approach to figuring out the formula or function when the inputs and outputs are given?",['functions']
259757,Markov inequality example,"If I have $x_1, x_2,\ldots, x_n$ independent NON-identically distributed Bernoulli random variables, how do I show that:
$$\mathrm{Pr}\left(\sum_{i=1}^nx_i>\beta\mu\right)\le e^{-g(\beta)\mu}$$ where $$\beta>1$$$$\mu=E\left(\sum_{i=1}^nx_i\right)$$$$g(\beta)=\beta\times \ln(\beta)-\beta+1$$?  I believe this can be accomplished using the Markov inequality (because that's what we've been covering), but I'm still not sure how to apply it.","['probability-theory', 'inequality']"
259766,"Prove or disprove that $f(x) = \sin x/x$ is uniformly continuous over the interval $(0,1)$?",I am thinking of $\lim_{x \to 0} \ {f(x)} = 1$ but I am confused as $x=0$ is not in the domain and also I want to write an $\epsilon$-$\delta$ proof. So any help is much appreciated! Thanks!,"['continuity', 'analysis']"
259768,Finite covering is compact Hausdorff iff base space is,I am in need of solution or tip for this question. I thank you. Let $ p: \widetilde X \to X $ be a covering space with $ p^{-1}(x) $ finite and nonempty for all $ x \in X$. Show that $ \widetilde X$ is compact Hausdorff iff $ X$ is compact Hausdorff.,"['general-topology', 'algebraic-topology']"
259784,How to find $1/x^3 + 1/y^3$?,"If I am given, $x + y = a$  and $xy = b$, how would I find the value of $\dfrac1{x^3} + \dfrac1{y^3}$?","['algebra-precalculus', 'polynomials']"
259808,Are there straightforward methods to tell which function has fastest asymptotic growth without a calculator?,"For example, suppose I wanted to determine which of the following has the fastest asymptotic growth: $n^2\log(n)+(\log(n))^2$ $n^2+\log(2^n)+1$ $(n+1)^3+(n-1)^3$ $(n+\log(n))^22^{100}$ Are there any straightforward methods to tell which is fastest without actually graphic the functions?","['notation', 'asymptotics', 'discrete-mathematics', 'functions']"
259809,Evaluating $\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2}$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Evaluate the integral: $\int_{0}^{1} \frac{\ln(x+1)}{x^2+1} dx$ $$\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2}$$ I am having a hard time deriving the answer, $\frac{\pi}{8} \log(2) $.  I have tried Taylor expansion of both numerator and denominator, both seem too complicated and fruitless.","['definite-integrals', 'calculus']"
259826,"Purely ""algebraic"" proof of Young's Inequality","Young's inequality states that if $a, b \geq 0$, $p, q > 0$, and $\frac{1}{p} + \frac{1}{q} = 1$, then $$ab\leq \frac{a^p}{p} + \frac{b^q}{q}$$ (with equality only when $a^p = b^q$).  Back when I was in my first course in real analysis, I was assigned this as homework, but I couldn't figure it out.  I kept trying to manipulate the expressions algebraically, and I couldn't get anywhere.  But every proof that I've seen since uses calculus in some way to prove this.  For example, a common proof is based on this proof without words and integration.  The proof on Wikipedia uses the fact that $\log$ is concave, which I believe requires the analytic definition of the logarithm to prove (correct me if I'm wrong). Can this be proven using just algebraic manipulations?  I know that that is a somewhat vague question, because ""algebraic"" is not well-defined, but I'm not sure how to make it more rigorous. But for example, the proof when $p = q = 2$ is something I would consider to be ""purely algebraic"": $$0 \leq (a - b)^2 = a^2 + b^2 - 2ab,$$ so $$ab \leq \frac{a^2}{2} + \frac{b^2}{2}.$$","['inequality', 'young-inequality', 'algebra-precalculus', 'real-analysis']"
259878,Use of $\mathbb N$ & $\omega$ as index sets,Why all the properties of a sequence or a series or a sequence of functions or a series of functions remain unchanged irrespective of which of $\mathbb N$ & $\omega$ we are using as an index set? Is it because $\mathbb N$ is equivalent to $\omega$?,"['motivation', 'elementary-set-theory']"
259884,Central limit theorem application,"I am trying to prove the following fact: Let $X$ be i.i.d. real random variables such that $E[X_i] = 0$, $\mathrm{Var}[X_i] = \sigma^2$. Moreover it is know that $S_n = \sum_{i=1}^{n}X_i$ is distributed as $x_n X_1 + y_n$ for each $n \geq 1$ and some real $x_n, y_n$. I would like to prove that $X_1$ is distributed as normal distribution $N(0, \sigma^2)$. My approach: By Central Limit Theorem,
$\frac{S_n}{\sigma \sqrt{n}} = \frac{x_n X_1 + y_n}{\sigma \sqrt{n}}$ (1) converges weakly to $N(0,\sigma^2)$ as $n \to \infty$. Therefore $E\left[ \frac{x_n X_1 + y_n}{\sigma \sqrt{n}} \right] = y_n$ converges weakly to $E[N(0, \sigma^2)]$. Hence $y_n \to 0$.
Similarly, applying this argument for variances (i.e. variances of weakly convergent sequence converge to the variance of the limit), I would conclude that $\frac{x_n}{\sigma \sqrt{n}} \to 1$ as $n \to \infty$.
Then from (1) it would follow that $X_1$ is distributed as $N(0, \sigma^2)$. I have feeling that I am missing/overlooked some issues here. Would be grateful for your comments or ideas whether this approach is correct or not. Thanks.",['probability-theory']
259893,Every finite set contains its supremum: proof improvement.,"Every finite subset of $\mathbb R$ contains its supremum (and its infimum) Proof Let $A=\{a_1,...,a_n\}$ be a finite subset of $\mathbb{R}$. Since it is non-empty and it is bounded ($\max A$ is an upper bound), it has supremum, that is $\exists \sup A$ and by definition $\forall a \in A \;\, a \leq \sup A$. Let's suppose that $\sup A  \not\in A$ then, since $\max A \in A$ we have that $\max A < \sup A$. But considering that $\mathbb Q$ is dense in $\mathbb R$ we can conclude that $\exists r \in \mathbb Q$ s.t. $\max A < r < \sup A$, but this is absurd since $r$ is an upper bound of $A$ and it is lower than the supremum. Necessarily, $\sup A\in A$. Is there anything wrong? Is there any way to prove this without using density of $\mathbb Q$ or another property? Thanks in advance.","['proof-writing', 'real-analysis']"
