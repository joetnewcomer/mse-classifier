question_id,title,body,tags
257579,Real analysis question $e^{-1/x^2}$,"Let $f$ be defined on $\mathbb{R}$ by $f(x) = e^{-1/x^2}$ for $x$ not equal to $0$. and $f(0)= 0$. Prove that $f^{(n)}(0)=0$ for all $n = 1, 2,3$ ... Do I need to use Taylor expansion from calculus class? Any hint would be appreciated.",['real-analysis']
257584,Can the graph of a bounded function ever have an unbounded derivative?,"Can the graph of a bounded function ever have an unbounded derivative? I want to know if $f$ has bounded variation then its derivative is bounded. The converse is obvious. I think the answer is ""yes"". If the graph were to have an unbounded derivative, it would coincide with a vertical line.","['bounded-variation', 'real-analysis']"
257606,Analogue of $S^{\bot \bot} = \overline{S}$ for Banach spaces which aren't Hilbert spaces,"Let $X$ be a Banach space over the complex field. Let $X^*$ denote its topological dual. If $S$ is a subspace of $X$ , write $$\mathrm{ann}_L(S)= \{ \varphi \in X^* : \varphi S = 0\}$$ and note the result is a weak-star closed subspace of $X^*$ . Similarly, if $S$ is a subspace of $X^*$ , write $$\mathrm{ann}_R (S) = \{ x \in X : S x = 0 \}$$ and note the result is a weakly closed subspace of $X$ . It is obvious that $\mathrm{ann}_L$ and $\mathrm{ann}_R$ are order-reversing. Also, if $S, T$ are subspaces of $X, X^*$ respectively, we have $$ S \subset \mathrm{ann}_R(T) \Leftrightarrow T \subset \mathrm{ann}_L(S) \Leftrightarrow TS = 0$$ so that $\mathrm{ann}_L$ and $\mathrm{ann}_R$ set up an (antitone) Galois connection between the posets of subspaces of $X$ and $X^*$ . Various things then follow by abstract nonsense. For instance, $\mathrm{ann}_R \circ \mathrm{ann}_L$ and $\mathrm{ann}_L \circ \mathrm{ann}_R$ are abstract closure operators and the associated ""closed subspaces"" of $X$ and $X^*$ are put into order-reversing bijection by $\mathrm{ann}_L$ and $\mathrm{ann}_R$ . In light of the fact that the range of $\mathrm{ann}_L$ consists of weak-star closed subspaces and the range of $\mathrm{ann}_R$ consists of weakly closed subspaces, it is natural to wonder whether these closure operators are, in fact, equal to the weak and weak-star closure operators. In essence, I am asking the following. Question 1 (answered): Let $S$ be a subspace of $X$ and let $x \in X$ . If $\varphi S = 0$ implies $\varphi(x) =0$ for all $\varphi \in X^*$ , does it follow that $x$ is in the weak closure of $S$ ? Question 2: Let $S$ be a subspace of $X^*$ and let $\varphi \in X^*$ . If $S x= 0$ implies $\varphi(x) =0$ for all $x \in X$ , does it follow that $\varphi$ is in the weak-star closure of $S$ ? Thank you in advance for any answers or clarification on surrounding issues. Added: I've managed to answer Question 1 affirmatively. First recall that the weak closure of $S$ is the same as the norm closure of $S$ . More generally, the weak closure and norm closure coincide for convex subsets of $X$ (Conway, A Course in Functional Analysis , Theorem V.1.4). The Hahn-Banach Theorem implies the following statement: If $S \subset X$ is a subspace and $x \in X$ is a positive distance $d$ away from $S$ , then there exists a functional $\varphi \in X^*$ with $\|\varphi\| = 1$ and $\varphi(x) = d$ and $\varphi S = 0$ . It is easy to answer Question 1 using these two facts.","['functional-analysis', 'banach-spaces']"
257624,Examples of algebraic techniques from algebraic geometry solving geometric problems.,"Classical algebraic geometry begins by interpreting the solutions to polynomial equations as geometric objects.  The solutions can then be studied geometrically, and a correspondence between their algebra and geometry is established.  Through this correspondence, geometric properties can sometimes be derived algebraically. In this case, however, we defined a geometric object starting from an algebraic object.  My question is, what are some examples where the algebraic side of algebraic geometry can be applied to understand geometric objects which are not a priori defined based off of some algebraic object?  I imagine, for example, that there are geometric objects that turned out to be algebraic varieties although they were originally motivated some other way.  A more interesting example might be a geometric object that isn't an algebraic variety, but where algebraic techniques from algebraic geometry can still be applied.","['algebraic-geometry', 'soft-question']"
257626,Bound of a function $f_n=\frac{x^2}{x^2+(1-nx)^2}$,"Let $\displaystyle f_n=\frac{x^2}{x^2+(1-nx)^2}$ where ($0\le x\le 1,\; n=1,2,3,...$) Then $|f_n(x)| \le M$. Find this $M$. The answer is $1$. Without any restriction of n, how can we find that bound?",['analysis']
257633,Measurable Function - Past Exam question,"This is an exercise from a past exam I'm using to try to help me study. Let $f$ be measurable and bounded on $[0,1]$ satisfying $$f(x+y)=f(x)+f(y);\quad f(1)=1.$$ I'm trying to show that $f(x)=x$. We're given a hint to show it is continuous by using the hypothesis in a ""mildly clever"" way, show that it is the identity on the rational points, then extend by continuity. I am able to show that the function is the identity on $[0,1]\cap\mathbb{Q}$ without any trouble, but I'm not sure how to show it's continuous. From there, showing the function is the identity would be easy since it follows from the fact that the rational numbers are dense in $\mathbb{R}$.","['measure-theory', 'real-analysis']"
257634,Let T be a linear transformation on the real vector space $\mathbb{R^n}$ over $\mathbb R$ such that $T ^2 =μT$ for same $μ∈\mathbb R$ [duplicate],"This question already has answers here : Linear transformation $T:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ such that $T^{2}=\lambda T.$ [closed] If $T\colon \mathbb R^n \to \mathbb R^n $ linear and $T^2 = kT$   [closed] (3 answers) Closed 6 years ago . Let $T$ be a linear transformation on the real vector space $\mathbb R^n$ over $\mathbb R$ such that $T^2 =\mu T$ for some $\mu\in\mathbb R$ . Then which of the following is/are true? $\|Tx\| = |\mu| \|x\|$ for all $x \in\mathbb {R^n}$ If $\|Tx\| =  \| x\| $for some non zero vector $x \in\mathbb R^n$, then $\mu=\pm1$ $T= \mu I$ where $I$ is the identity transformation on $\mathbb R^n$ If $\|Tx \|>\|x\|$ for a non zero vector $x \in \mathbb R^n$, then $T$ is necessarily singular. I am completely stuck on it. Can anybody help me please?","['linear-transformations', 'linear-algebra']"
257650,Analogue of the Cantor-Bernstein-Schroeder theorem for general algebraic structures,"The Cantor-Bernstein-Schroeder theorem states that if there are two sets $A$ and $B$ such that there exist injective (alternatively, surjective, assuming choice I think) maps $A \to B$ and $B \to A$, then $A$ and $B$ are in bijection.  It then seems natural to try to strengthen the result to other structures.  If $A$ and $B$ are, say, groups (or rings, modules, etc) such that there are injective homomorphisms from each to the other, then $A$ and $B$ are isomorphic. I'm wondering if there are any results on this, or if there are known counterexamples.  The theorem for sets alone is nontrivial, so I feel like any results about how it holds for other structures would be quite interesting.","['category-theory', 'abstract-algebra']"
257655,Hyperreal measure?,"If AC be accepted, then there exists a Lebesgue unmeasurable set called Vitali Set . However, I'm curious about measure valued in hyperreal numbers. Argument in disproof of unmeasurability of Vitali sets had used the fact that no positive real number countable infinite sums finite. But can the Vitali sets have infinitesimal measure? Then the countable infinite copy of its measure may sums sutible positive finite. However there still a problem: $\mathbb Z$ is also a countable infinite set of points but has $0$ measure whereas Vitali set has non-zero. So I'm not sure if its feasible to use hyperreal measure to make Vitali set measurable.","['measure-theory', 'nonstandard-analysis', 'elementary-set-theory']"
257676,Probability distribution for the position of a biased random walker on the positive integers,"I initialize a biased one-dimensional random walk on the positive integers at the origin, $x = 0$, which also serves as a reflecting boundary blocking steps onto the negative integers.  Let's say that a $+1$ step for the walker has probability $p$, and an $-1$ step (away from the origin) has probability $q$, where $(p+q) \leq 1$ allowing the walker to stay in place with probability $r = 1 - (p+q)$. If $p < q$, what is the probability distribution for the walker on the positive integers?  What are the implications if $p = q$ provided that a 1D random walk shouldn't be transient? I've always appealed to simulations when problems like this arise, however, the formulation of this system seems simple enough that I'd imagine an analytic solution should exist (beyond the generalization that we should have exponential increasing hitting times as we linearly increase the distance to the origin)?  Is there a formulation of, say, Gambler's ruin that deals with this problem?  We can of course eliminate the reflecting boundary by making $p$ the probability of stepping away from the origin, $q$ the probability of stepping towards the origin, etc. Some additional questions that come to mind: how long would it take a randomly placed walker to achieve this distribution?  If we place a walker at the origin, how fair or unfair would it be to assume that the hitting time at some site $x_{t}$ would be proportional to its occupancy probability from the distribution?  And, in the case that this is unfair, what does the probability distribution look like for initial hitting times on the positive integers conditioned on the walker being initialized at the origin? Clarification - A walker can occupy the origin, though here, we have a $-1$ step probability of $q = 0$, the same $+1$ step probability $p$, and a probability of remaining at the origin for a step of $r = (1 - p)$.","['markov-chains', 'random-walk', 'probability']"
257679,"Union of Sets Dense in $[0,1]$","I'm working on a past exam to help me study for my finals and I came across the following question: Let $\varepsilon>0$ and define $A=\bigcup_{j=1}^\infty(x_j-\varepsilon,x_j+\varepsilon)$ where $x_j\in\mathbb{R}$. Suppose that $A\cap[0,1]$ is dense in $[0,1]$. Then $|A\cap[0,1]|=1$ (Lebesgue measure). A hint is provided, suggesting the use of Lebesgue's Differentiation Theorem. On one hand, I don't see how to use the theorem, but, is it necessary? My line of thinking is as follows: Since we're in $\mathbb{R}$ and $A$ is open (as a union of open sets), that means $A$ can be written as a countable union of disjoint open intervals, say $\bigcup_{j=1}^\infty(a_j,b_j)$. Assume the measure of $A\cap[0,1]$ is strictly less than $1$, say $1-\delta$ for some $\delta>0$. By the minimum fixed length of $b_j-a_j$, this implies there is some nondegenerate interval in $[0,1]$, which in turn implies there are elements with open sets disjoint from $A$, which is a contradiction since $A$ is dense in $[0,1]$. In fact, if I'm thinking about the construction correctly, it would seem to contain all but finitely many (based on the idea that $b_j-a_j\geq2\varepsilon$ for each $j$). I realize my proof doesn't generalize to any higher dimensions (although something similar might work) since an open set can't be written as a countable union of disjoint open sets in higher dimensions. Will anyone critique my proof and possibly suggest a line of proof using Lebesgue's Differentiation Theorem? Thanks!","['measure-theory', 'real-analysis']"
257700,Old graduate analysis qualifying exam question,"I am working through an old real analysis qualifying exam. Most of the problems are measure theory related except perhaps one, which I am having some trouble (probably because I have not seen this type of question before). I would be very appreciated if someone can help me. Here is the question: Compute $$\underset{a,b,c}{\min}{\textstyle\int_{-1}^{1}} \left\vert x^{3}-a-bx-cx^{2}\right\vert dx$$ and find $$\max{\int_{-1}^{1}}x^{3}g(x)dx,$$ where $g$ is subject to the restrictions
$$\begin{gather*}
\int_{-1}^{1}g(x)dx={\int_{-1}^{1}x}g(x)dx={\int_{-1}^{1}}x^{2}g(x)dx=0;\\
{\int_{-1}^{1}}\left\vert g(x)\right\vert ^{2}dx=1
\end{gather*}$$","['measure-theory', 'integration', 'real-analysis']"
257743,Using Green's Theorem to compute area in the complex plane,"I'm attempting to use Green's Theorem to express the area of a region in the complex plane in terms of a contour integral, but I'm a little confused as to how this works.  I have a simple closed curve $\gamma$ with interior $D$, and I believe I'm supposed to get $$\mathrm{Area}(D)=\frac{1}{2i} \oint_\gamma \overline{z} \,dz.$$  Can anyone help me justify this?",['complex-analysis']
257747,Proving at least 99 pairwise sums of the reals are non-negative,"Suppose, one hundred real numbers are given and their sum is 0.Then how can I prove that at least 99 of the pairwise sums of these hundred numbers are non-negative? I tried this:
Let the real numbers be $a_i$,$1\leq i\leq100$.
By the given condition, $a_1+a_2+\dots +a_{100}=0$.Suppose for the sake of contradiction, that at most 98 of the pairwise sums of these given reals are non-negative.I just tried to examine the case when exactly 98 of them are non-negative.
I labelled the sums $S_1$,$S_2,\dots S_{4950}$,WLOG assume that sums $S_1,S_2,\dots S_{4852}$ are negative, the rest are non-negative.
$$S_1+S_2+\dots +S_{4950}=99(\sum_{i=1}^na_i)=0$$
Case I: $S_{4853}+a_{4854}+\dots +a_{4950}=0$.That simply means that $S_1+S_2+\dots +S_{4852}=0$.But, by the given condition, $S_1+S_2+\dots +S_{4852}<0$,a contradiction.After that, I am not able to make any progress. Can anyone please suggest a more efficient method to solve this problem.I feel this approach will involve enormous case work.","['summation', 'discrete-mathematics']"
257770,Differential Geometry past an introductory course?,"I'll be doing an independent study with one of my profs in differential geometry next semester (my university did not happen to offer an intro diff. geometry course next semester like it usually does).  I'll be mainly working out of Barrett O'Neill's book but will also be checking out different perspectives by looking at do Carmo's book (and maybe Spivak's?)  I've been planning out the rest of my semesters and even if I end up taking courses in a wide range of branches in mathematics, I'll still have quite a bit of free credits to delve more deeply into one subject.  If I do choose to go further into differential geometry, what are some important classes to take/books to read?  Books I've looked into so far are Do Carmo's Riemannian Geometry, Barrett O'neill's Semi-Riemannian Geometry, as well as differential topology books like Milnor's topology from a differentiable viewpoint or Lee's introduction to smooth manifolds (I understand these are important for more advanced work in differential geometry?)  What is the recommended order I should learn these subjects in?  Any other suggestions/recommendations? Thanks!","['advice', 'soft-question', 'differential-geometry']"
257777,Invariants of binary forms under a $\begin{pmatrix} 1& 1 \\ 0& 1 \end{pmatrix}$ action,"The special linear group $\text{SL}_2(\mathbb{Z})$ of $2\times 2$ invertible matrices in $\mathbb{Z}$ acts on binary cubic forms $\{ax^3 + bx^2y + cxy^2 + dy^3\}$ by acting on the vector $(x,y)^T$. This action descends to an action of the group $\Gamma_\infty := \left\{ \begin{pmatrix} 1 & n \\ 0 & 1 \end{pmatrix} : n \in \mathbb{Z}\right\}$ on binary cubic forms. It happens to be that $\Gamma_\infty$ is generated by $\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}$. So understanding the action of this one element allows us to understand the whole $\Gamma_\infty$ action. (This is the action that sends $(x,y) \to (x+y, y)$) I am interested in the invariants of binary forms under this action. In this (the binary cubic forms) case, the invariants form a 3-dimensional algebra, and I know the invariants. This action makes sense on other binary forms as well. It happens to be that the invariants of the binary quadratic case form a 2-dimensional algebra, which I also know. But I found these through the ""brute force"" method. I am not really familiar with invariant theory at all, so I don't know if this is an easy or a hard question. But I'm wondering if there's some nice form for the invariants of binary n-degree forms under $\Gamma_\infty$? Alternately, perhaps there's a nice form for the invariants under $\text{SL}_2(\mathbb{Z})$ that one might perhaps be able to modify?","['reference-request', 'invariant-theory', 'group-theory', 'group-actions']"
257785,Differentiation; trouble finding $\frac{dy}{dx}$ in terms of $y$,"I'm self-studying through some exercises on differentiation, and have found a section which I've gotten almost every question wrong.  Can anyone help me find out where I'm going wrong? An example of one of the questions and my attempt to answer it is Q: Find $\frac{dy}{dx}$ in terms of $y$ when $x = 4y^5-8\sqrt{y}$ My answer: $$x = 4y^5-8\sqrt{y} = 4y^5 - 8y^\frac{1}{2}$$
$$\frac{dx}{dy} = 20y^4 - 4y^{-\frac{1}{2}}$$
$$ = 20y^4-\frac{4}{\sqrt{y}}$$
since: 
$$ \frac{dy}{dx} = \frac{1}{\frac{dx}{dy}} \\
\therefore \frac{dy}{dx} = \frac{1}{20y^4}-\frac {y^{-\frac{1}{2}}}{4} \\
= \frac {4 - 20(y^{-\frac{1}{2}})}{80y^4} \\
= \frac {1 - 5(y^{-\frac{1}{2}})}{20y^4}
$$ But the listed answer is:
$$\frac{y^\frac{1}{2}}{4(5y^\frac{9}{2}-1)}$$ I suspect that due to the fact I've gotten only 2 out of the 6 questions right I'm doing something fundamentally wrong!  Can anyone help me figure out either where I'm going wrong, or what I'm missing?","['self-learning', 'derivatives']"
257786,Show that estimates are unbiased,"The following is a problem in my book that I don't really understand: We take a random sample: $x_1,x_2,\ldots,x_n$ from a population that is $N(μ,σ)$ where $\mu$ and $\sigma$ are unknown. We build two estimates: $$\mu^*_{\text{obs}} = \overline{x} = (x_1 + x_2 + \cdots + x_n)/n$$ and $$\hat{\mu}^*_{\text{obs}} = (x_1+x_2)/2$$ Show that both estimates are unbiased. I know that an estimate of a sample mean is unbiased when we divide by $n-1$ instead of $n$. How come those two estimates are unbiased? In my eyes they are biased.","['statistics', 'parameter-estimation']"
257802,is it possible to find the closest rational number to an irrational number?,"given an irrational number is it possible to find the closest rational number to the irrational number? If so, how?",['real-analysis']
257811,How to prove that $\cos (2\pi/n)$ is algebraic?,"Prove that for all integers $n$, $\cos (2\pi/n)$ is an algebraic number.","['abstract-algebra', 'field-theory']"
257839,Solving an inhomogenous parameter dependent ODE,"I was trying to solve the ODE \begin{equation}
\ddot{r} r = \alpha(\dot{r}^2-1)
\end{equation}
where $\alpha$ is an arbitrary constant. There are some simple cases when $\alpha = -1 $ then you can use separation of variables to find the solution. For the initial condition when $r'(0)=1$ it also simplifies, $r(t)= t + r(0)$. Not sure how take on the general case. Any help is welcome!",['ordinary-differential-equations']
257850,Ideal of the pullback of a closed subscheme,"Let $f\colon X \to Y$ be a morphism of schemes and $J \subseteq \mathcal{O}_Y$ a quasi-coherent ideal. Let $I$ denote the image of $f^* J \to f^* \mathcal{O}_Y = \mathcal{O}_X$. Then $I \subseteq \mathcal{O}_X$ is a quasi-coherent ideal and we have the equality of sets $f^{-1}(V(J)) = V(I)$. This is easy and should be well-known. I would like to have a reference in the literature, preferred EGA. In EGAI I could only find the affine case, this is Proposition 1.2.2. PS: Of course this can be also stated as follows: The scheme-theoretic pullback of a closed subscheme has as underlying set precisely the preimage of the underlying closed subset. EDIT: Here is a deduction from EGA-results: Since $f^* J \to f^* \mathcal{O}_Y \to f^* (\mathcal{O}_Y/J) \to 0$ is exact, we have $\mathcal{O}_X/I = (f^* \mathcal{O}_Y) / I = f^* (\mathcal{O}_Y/J)$. Now apply EGA I, Chapitre 0, 5.2.4.1:
$$f^{-1}(V(J))=f^{-1}(\mathrm{supp}~ \mathcal{O}_Y/J ) \stackrel{!}{=} \mathrm{supp}~ f^*(\mathcal{O}_Y/J) = \mathrm{supp}~ \mathcal{O}_X/I = V(I)$$","['algebraic-geometry', 'reference-request']"
257856,Curves in a linear system on a surface,"I'm looking for references on a very classical question: Let $X$ be a compact surface and let $L \to X$ be an ample line bundle. We assume that $L$ has nonzero sections. Then the linear system $|L|$ defines a family of curves $\mathcal C \to |L|$ on the surface $X$, most of whom are nonsingular of genus $1 + \frac 12 L \cdot (L + K_X)$. I'm very interested in the singular curves in this family. What kind of singularities can arise here? For example, can we say (under some conditions on $X$ and $L$) that some curve in the system will have only nodal singularities and predict the number of nodes? Is there any way of predicting what the ""worst"" singular curve in this system looks like? I apologize for the vague question, but like I said, this is more of a reference hunt than a precise question.","['algebraic-geometry', 'algebraic-curves', 'complex-geometry']"
257873,"Why isn't the inverse of the function $x\mapsto x+\sin(x)$ expressible in terms of ""the functions one finds on a calculator""?","The function $f(x)=x+\sin(x)$ is easily checked to be a bijection from the reals to itself, and so it has a unique inverse $y\mapsto g(y)$ such that $f\circ g=g\circ f$ are both the identity map. Now $g$ will almost certainly be a function which is not expressible using ""the functions in a high-schooler's toolkit"" (by which I guess I mean $\exp$, $\log$, and, if you like, the usual trigonometric functions and their friends like $\sinh$, although of course these can all be of course built from exponentials anyway). For purely recreational reasons (stemming from conversations I've had whilst teaching undergraduates) I'm interested in how one proves this sort of thing. A few years ago I was interested in a related question, and took the trouble to learn some differential Galois theory. My motivation at the time was learning how to prove things like why $h(t):=\int_0^t e^{x^2} dx$ is not expressible in terms of these calculator-button functions (I'm sure there's a better name for them but I'm afraid I don't know it). I've realised that since then I've forgotten most of what I knew, but furthermore I am also unclear about whether this is the way one is supposed to proceed. Is the idea that I come up with some linear differential equation satisfied by $g$ and then apply some differential Galois theory technique? In fact, one of the many things that I have forgotten is the following: if $F$ is a field equipped with a differential operator $D$, and $E/F$ is the field extension obtained by adding a non-zero root of $Dh=ch$, with $c\in F$, then the Galois group of $E/F$ is solvable, whereas the equation itself might not be, in terms of calculator-button functions, if I can't integrate $c$. Can a more enlightened soul explain to me how one is supposed to proceed? I wonder whether I am somehow conflating two ideas and the differential Galois theory business is a red herring, but it seemed simpler to ask rather than continuing to flounder around.","['closed-form', 'field-theory', 'functions', 'galois-theory', 'elementary-functions']"
257874,Estimate variance given a sample of size one (7th Kolmogorov Student Olympiad),"This is problem 10 of the seventh Kolmogorov Student Olympiad in Probability Theory as translated by Jonathan Christensen in this thread . Given a sample of size one from the random variable $\xi \sim N(\mu,\sigma^2)$, both of whose parameters are unknown, give a confidence interval for $\sigma^2$ with confidence level at least $99\%$.","['probability-theory', 'contest-math']"
257878,Approximation of binomial distribution with normal distribution,"The Central Limit Theorem implies that near the center of mass we can approximate the binomial distribution with the normal distribution: $$
P(B(n,p) \geq i) \approx P(Z \geq \frac{i - n p}{\sqrt{n p (1-p)}})
$$ where $Z$ is the standard normal. I am interested in cases where $n \rightarrow \infty$ while $p$ remains constant. However, I am integrating a function over all integers $i$, so I cannot assume that $i$ itself is bounded. So the standard Central Limit Theorem, which only asserts that the above approximation holds pointwise in the limit, is not adequate for me. Are there any references which give explicit (or asymptotic) error estimates for this type of approximation?","['asymptotics', 'probability-distributions', 'probability']"
257880,Field extension with dihedral Galois group,"In an old exam of my Galois Theory class there is the following question which troubles me: Let $p \neq 2$ be a prime number and $k \geq 1$ an integer. Give an example of a galois extension $L/K$ such that $Gal(L/K) = D_{2p^k}$ and $[K:\mathbb{Q}]<+\infty$. My idea was to consider the $p^k$-th roots of unity on which $D_{2p^k}$ acts and then take $L=\mathbb{Q}(\mu _{p^k})$ and $K=\mathbb{Q}(\mu _{p^k})^{D_{2p^k}}$ which by (what we called in class) Artin's theorem would give us $Gal(L/K) = D_{2p^k}$. What troubles me is that I want to stop here and say that I'm done but I haven't use the $p^k,p\neq2$ conditions (what i did would work all the same with $D_{2n}$ for all $n$) so I feel that I have very probably made a mistake.","['galois-theory', 'dihedral-groups', 'abstract-algebra']"
257881,Question with inner product,"This is a question that I'm trying to solve since yesterday. Let $T:\mathbb{R}^n\rightarrow\mathbb{R}^n$ be a linear transformation such that $$\begin{equation}
    \langle u,v\rangle = 0, \langle Tu,v\rangle >0\quad\Rightarrow\quad \langle u,Tv\rangle >0
\end{equation}$$ We have to proof the following 1) $\langle u,v\rangle = 0$, $\langle Tu,v\rangle =0\quad\Rightarrow\quad \langle u,Tv\rangle =0$; 2) There exists an orthonormal basis for $T$; 3) $T$ is symmetric. Im stuck in the first item...it really looks easy but i just cant prove this. 
I used Cauchy-Schwarz inequality to see that if we have $\langle u,v\rangle=0$ and $\langle Tu,v\rangle=0$, then $|\langle u,Tv\rangle + \langle v,Tv\rangle| = 0$, in that case I want to show that $\langle v,Tv\rangle=0$ so I this implies $\langle u,Tv\rangle=0$.
Also, with this $u$ and $v$, I have that $\langle u,v+T^\ast v\rangle=0$. I dont know what to do from here...I`m out of ideas, any help is very welcome.","['linear-algebra', 'inner-products']"
257889,Question about proof of Hessenberg: $\kappa \cdot \lambda = \lambda$,The following is a theorem: (Hessenberg) Let $1 \le \kappa \le \lambda$ where $\lambda$ is an infinite cardinal. Then $\kappa \cdot \lambda = \lambda$. The proof in the book proceeds by transfinite induction showing $\lambda \cdot \lambda \le \lambda$. I have a question about the induction step. In the proof they define a well-order on $\lambda \times \lambda$ and then show that every proper initial segment of $\lambda \times \lambda$ has cardinality less than $\lambda$. It seems long-ish. Why can't one argue like this: By the inductive assumption we have $\kappa \cdot \kappa \le \kappa$ for all $\kappa < \lambda$. Hence $\sup (\kappa \cdot \kappa) \le \sup \kappa $. But $\sup \kappa = \lambda$ and $\sup \kappa \cdot \kappa = \lambda \cdot \lambda$ which proves the claim. Thanks for your help.,"['cardinals', 'elementary-set-theory', 'ordinals']"
257895,calculate the period of an hypotrochoid,"I'm curious how to find out the period of an hypotrochoid . x = (a-b) * cos(t) + h * cos( ((a-b)/b) * t )
y = (a-b) * sin(t) - h * sin( ((a-b)/b) * t ) I know that for a single cos(x) function to find the period you divide 2π by the multiplier of the x, but i have no idea with more tri function like cos(x) + cos(x1) + m1","['trigonometry', 'periodic-functions']"
257904,Hölder Continuity of Fractional Brownian Motion,"I would like to prove the following theorem: Let $H\in (0,1)$. The fractional Brownian motion $B_H$ admits a version whose sample paths are $a.s.$ Hölder continuous of order strict less than $H$. For any $\alpha >0$ we have by self similarity $$\mathbb{E}[|B_H(t)-B_H(s)|^{\alpha}]=\mathbb{E}[|B_H(1)|^{\alpha}]|t-s|^{\alpha H}.$$ The proof is done after applying the criterion of Kolmogorov which says: A process $(X_t)_{t\in\mathbb{R}}$ admits a continuous modification if there exist constants $a,b,k>0$ such that $$\mathbb{E}[|X(t)-X(s)|^a]\leq k|t-s|^{1+b}$$ for all $s,t\in\mathbb{R}$. But I don't know how to apply this criterion. Any help please. Edit: Well, maybe I should try to state my problem more precisely. I just would like to understand the proof. If I use the criterion of Kolmogorov it should hold $$\mathbb{E}[|B_H(t)-B_H(s)|^{\alpha}]=\mathbb{E}[|B_H(1)|^{\alpha}]|t-s|^{\alpha H}\leq k|t-s|^{1+\beta}$$ for $\alpha,\beta,k>0$, right? I don't see any relationship to the Hölder continuity. Is there nobody who can demonstrate the proof for me to understand? Maybe I should set $k=\mathbb{E}[|B_H(1)|^{\alpha}]$ and $\beta=\alpha H$ and say that $B_H$ is $\gamma$-Hölder continuous for every $\gamma\in\big[0,{\alpha H\over \alpha}\big)$?","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'holder-spaces', 'brownian-motion']"
257905,"Characterization of Dirac Masses on $C([0,1],\mathbb{R}^d)$","Let $f:X\to Y$ be a Borel Map from the measure space $(X,\mathcal{B},\mu)$ to the measurable space $(Y,\mathcal{M})$. The pushforward of $\mu$ denoted by $f_\#\mu$ is defined as $$f_\#\mu(E)=\mu(f^{-1}(E))$$ for $E\in\mathcal{M}$. Let $C([0,1];\mathbb{R}^d)$ be the space of all continuous functions defined on $[0,1]$ with the supremum norm. Let $t\in[0,1]$ and let $e_t$ denote the evaluation map $$e_t:C([0,1];\mathbb{R}^d)\to \mathbb{R^d}$$ given by $e_t(f)=f(t)$. Question: I recently read in a paper, pp14 , Exercise 14, that a measure $\sigma$ on $C([0,1];\mathbb{R}^d)$ is a Dirac measure iff the pushforward measures $e_t{_\#}\sigma$ are Dirac measures on $\mathbb{R^d}$ for all $t\in\mathbb{Q}\cap[0,1]$. One way is trivial. The other way I cannot prove. The obvious way to proceed, I thought, was to construct a function $$f:[0,1]\to \mathbb{R^d}$$ by $f(t)=x_t$ for $t\in\mathbb{Q}\cap[0,1]$ where $e_t{_\#}\sigma=\delta_{x_t}$ for some $x_t\in\mathbb{R^d}$. Then, I thought of defining the function for $t\notin\mathbb{Q}\cap[0,1]$ by choosing a rational sequence $t_n$ converging to $t$ and looking at the corresponding sequence $x_{t_n}$. But without any form of continuity available for $f$ on $\mathbb{Q}\cap[0,1]$  I cannot conclude that this sequence $x_{t_n}$ is Cauchy, without which I cannot define $f$ on $[0,1]$. Could someone please help! Thank you.","['probability-theory', 'measure-theory', 'analysis']"
257907,Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$.,"Let $f$ be a real-valued function continuous on $[a,b]$ and differentiable on $(a,b)$. Suppose that $\lim_{x\rightarrow a}f'(x)$ exists. Then, prove that $f$ is differentiable at $a$ and $f'(a)=\lim_{x\rightarrow a}f'(x)$. It seems like an easy example, but a little bit tricky. I'm not sure which theorems should be used in here. ============================================================== Using @David Mitra's advice and @Pete L. Clark's notes I tried to solve this proof.
I want to know my proof is correct or not. By MVT, for $h>0$ and $c_h \in (a,a+h)$
$$\frac{f(a+h)-f(a)}{h}=f'(c_h)$$ and $\lim_{h \rightarrow 0^+}c_h=a$. Then $$\lim_{h \rightarrow 0^+}\frac{f(a+h)-f(a)}{h}=\lim_{h \rightarrow 0^+}f'(c_h)=\lim_{h \rightarrow 0^+}f'(a)$$ But that's enough? I think I should show something more, but don't know what it is.","['continuity', 'derivatives', 'real-analysis', 'limits']"
257912,Properties of $\det$ and $\operatorname{trace}$ given a $4\times 4$ real valued matrix,"Let $A$, be a real $4 \times 4$ matrix such that $-1,1,2,-2$ are its eigenvalues. If $B=A^4-5A^2+5I$, then which of the following are true? $\det(A+B)=0$ $\det (B)=1$ $\operatorname{trace}(A-B)=0 $ $\operatorname{trace}(A+B)=4$ Using Cayley-Hamilton I get $B=I$, and I know that $\operatorname{trace}(A+B)=\operatorname{trace}(A)+\operatorname{trace}(B)$. From these facts we can obtain easily about 2,3,4 but I am confused in 1. How can I verify (1)? Thanks for your help.",['linear-algebra']
257916,"Prove that $1/f$ is Riemann integrable on $[a,b]$","Prove that if $f$ is Riemann integrable on $[a,b]$ and $0<\rho \le f(x)$ for all $x \in [a,b]$ then $1/f$ is Riemann integrable on $[a,b]$.",['analysis']
257951,Consider a matrix $A$ with integer entries such that $a_{ij}=0$ for $i>j$ and $a_{ii}=1$ . then which of the followings are true?,"Consider a matrix $A=(a_{ij})_{ n ×n }$ with integer entries such that $a_{ij}=0$ for $i>j$ and $a_{ii}=1$ for $i=1,…,n$. then which of the followings are true? $A^{-1}$ exists and it has integer entries. $A^{-1}$ exists and it has some entries that are not integer. $A^{-1}$ is a polynomial of $A$ with integer coefficients. $A^{-1}$ is not a power of $A$ unless $A$ is the identity matrix. By the given conditions $A$ is the upper triangular matrix with diagonal elements $1$.so eigenvalues are $1$.so their product=determinant of $A =1.$ So 1 is true.
Inverse of the identity matrix is itself with has all integer entries so 2 is false.
But I have no idea about (3) and (4) can anyone help me please.","['matrices', 'linear-algebra']"
257955,Irreducibles are prime in a UFD,"Any irreducible element of a factorial ring $D$ is a prime element of
  $D$. Proof. Let $p$ be an arbitrary irreducible element of $ D$. Thus $ p$
 is a non-unit. If $ ab \in (p)\smallsetminus\{0\}$, then $ ab = cp$
 with $ c \in D$. We write $ a,\,b,\,c$ as products of irreducibles:
 $$\displaystyle a \;=\; p_1\cdots p_l, \quad b \;=\; q_1\cdots q_m,
 \quad c \;=\; r_1\cdots r_n.$$ Here, one of those first two products may
 be empty, i.e., it may be a unit. We have $$\displaystyle p_1\cdots
 p_l\,q_1\cdots q_m \;=\; r_1\cdots r_n\,p\tag{1}$$ Due to the uniqueness of prime factorization, every factor $ r_k$ is
  an associate of certain of the $l+m$ irreducibles on the left
  hand side of $(1)$. Accordingly, $p$ has to be an associate of one of
  the $ p_i$'s or $ q_j$'s. It means that either $ a \in (p)$ or $ b \in
 (p)$. Thus, $ (p)$ is a prime ideal of $ D$, and its generator must be
  a prime element. It may be too simple, but why $ a \in (p)$ instead of $p_1 \in (p)$?
Is it because $p$ has to be an associate of one of the $ p_i$'s or $ q_j$'s? Let's say $p_2$ is an associate of $p$. So, $p_2=pw$, $w\in R$. Since $a=p_1p_2\cdots p_l$ then $a=p_1pwp_3\cdots p_l$ and $a=p(p_1p_3\cdots p_lw)$, $p_1p_3\cdots p_lw \in R$ so $a$ is divisible by $p$ hence $a\in (p)$?","['proof-explanation', 'ring-theory', 'unique-factorization-domains', 'abstract-algebra']"
257974,Curvature $\kappa$ Proof,"The curvature of a curve (rate of change of the unit tangent vector with respect to arc length) is defined as $$\kappa = \frac{|\underline{r}'(t) \times \underline{r}''(t)|}{|\underline{r}'(t)|^3}$$ The proof of this is shown in my textbook, but I don't understand one step. They say: $\underline{r}'(t) = \underline{T}(t) |\underline{r}'(t)| = \underline{T}(t) s'(t)$ and then $ \underline{r}''(t) = \underline{T}'(t) s'(t) + \underline{T}(t)s''(t).$ First question: Would $s''(t)$ not equal $0$? My reasoning being since $s'(t) = |\underline{r}'(t)|,$ a constant and then subsequently differentiate again to get $0$? After the above step, they say $\underline{r}'(t) \times \underline{r}''(t) = [s'(t)]^2 \underline{T}(t) \times \underline{T}'(t)$. I am not sure how they get this. The expression I got when I simplified was:$$ \underline{T}(t)s'(t) \times (\underline{T}'(t)s'(t) + \underline{T}(t)s''(t)) = \underline{T}(t)s'(t) \times \underline{T}'(t)s'(t) + \underline{T}(t)s'(t) \times \underline{T}(t)s''(t)$$ And the latter term disappears because $\underline{T}(t) \times \underline{T}(t) = \underline{0}$ Many thanks.","['multivariable-calculus', 'vector-analysis']"
257978,Is there any non-monoid ring which has no maximal ideal?,"Is there any non-monoid ring which has no maximal ideal? We know that every commutative ring has at least one maximal ideals -from Advanced Algebra 1 when we are study Modules that makes it as a very easy Theorem there. We say a ring $R$ is monoid if it has an multiplicative identity element, that if we denote this element with $1_{R}$ we should have: $\forall r\in R;\: r.1_{R}=1_{R}.r=r$","['ring-theory', 'ideals', 'rngs', 'abstract-algebra']"
257980,Vector perpendicular to timelike vector must be spacelike?,"Given $\mathbb{R}^4$, we define the Minkowski inner product on it by $$ \langle v,w \rangle = -v_1w_1 + v_2w_2 + v_3w_3 + v_4w_4$$
We say a vector is spacelike if $ \langle v,v\rangle >0 $, and it is timelike if $ \langle v,v \rangle < 0 $. How can I show that if $v$ is timelike and $ \langle v,w \rangle = 0$ , then $w$ is either the zero vector or spacelike? I've tried to use the polarization identity, but don't have any information regarding the $\langle v+w,v+w \rangle$ term in the identity. Context: I'm reading a book on Riemannian geometry, and the book gives a proof of a more general result: if $z$ is timelike, then its perpendicular subspace $z^\perp$ is spacelike. It does so using arguments regarding the degeneracy index of the subspace, which I don't fully understand. Since the statement above seems fairly elementary, I was wondering whether it would be possible to give an elementary proof of it as well. Any help is appreciated!","['linear-algebra', 'riemannian-geometry']"
257981,Product of connected spaces - Proof,"I'm working on the ""iff""-relation given by: $X=\prod_{i\in I}X_i$ is connected iff each $X_i$ non-empty is connected for all $i\in I$ . I could prove the "" $\Rightarrow$ ""-direction very easily. I also proved that a finite product of connected spaces is connected. Now I want to prove the following: - Choose $z=(z_i)\in\prod_{i\in I}X_i$ . For every finite subset $J\subset I$ the set $X_J:=\left\{x\in X:x_i=z_i\ \forall I-J\right\}$ is connected. I have given the follwoing proof: This set is homeomorphic with a finite product $\prod_{j\in J}X_j$ given by the map defined by: $x=(x_j)_{j\in J}$ mapped on $y=(y_i)_{i\in I}$ such that $y_j=x_j$ if $j\in J$ and $y_j=z_j$ if $j\notin J$ . This mapping is continuous and injective (and also the inverse is continous since it is the projection map). But then we know that $X_J$ is connected since every finite product is connected (if the components are connected). Is this proof correct? The only thing that I have to prove now is that $Y=\cup_{J\subset I,J\ finite}X_J$ is dense in X. How do I do that? Can someone help? Thank you.","['general-topology', 'connectedness']"
257997,$X$ is a Geometric random variable find the expectation of $1/X$,"Let $X$ be a geometric random variable with parameter $p$, find the expectation of $E[1/X]$. I need help simplifying the series.","['probability-theory', 'stochastic-processes', 'sequences-and-series', 'probability']"
258008,Correlation and dependence between $X$ and $Y:=X^2$,"If we say $X$ has a uniform distribution on $\{-1,0,1\}$ and let $Y=X^2$, are $X$ and $Y$ uncorrelated and are they independent? I would say that they are not independent since $Y$ clearly depends on $X$, but a friend told me that that's not correct. How would I show that they are dependent? (Or maybe he is correct?) Also I said that they were correlated because $Y$ changes as $X$ changes, meaning correlation right? I'm just feeling doubtful now. Some help please?","['probability-theory', 'probability']"
258017,Geodesics on the product of manifolds,"Given two Riemannian manifolds $(M, g_1)$ and $(N, g_2)$, and geodesic curves $\gamma(t)$ in $M$ and $\chi(t)$ in $N$.
Is the curve $\Gamma(t) = (\gamma(t),\chi(t))$ a geodesic in the product manifold $(M \times N, g_1 + g_2)$ ? Is it a geodesic if we now consider the product manifold $(M \times N, \alpha g_1 + \beta g_2)$ where $\alpha$ and $\beta$ are two positive (or zero) scalar constants ? $$ $$ EDIT: Although I feel it should be the case (geodesic), could you tell me if my counter-example is right: Let's say $g_1$ is euclidean, and $g_2$ is not. I am interested in whether $\nabla_{\dot\Gamma}\dot\Gamma$ has only components along $\dot\Gamma$  (ie., $\Gamma$ is autoparallel). Let's call the Levi-Civita connections on $M$ and $N$, respectively $\nabla^1$ and $\nabla^2$. Since $g_1$ is euclidean, $\nabla^1_{\dot\gamma}\dot\gamma=0$. Projecting $\nabla_{\dot\Gamma}\dot\Gamma$ on $\dot\Gamma^\perp$ (to check whether its perp component is $0$), I get $\nabla^{(\pi)}_{\dot \Gamma}\dot\Gamma = (0, \nabla^2_{\dot\chi}\dot\chi - \frac{g_2(\nabla^2_{\dot\chi}\dot\chi,\dot\chi)}{g_1(\dot\gamma,\dot\gamma)+g_2(\dot\chi,\dot\chi)}\dot\chi)$. This second term isn't expected to be zero, right? Since $\chi$ is geodesic, only $\nabla^2_{\dot\chi}\dot\chi - \frac{g_2(\nabla^2_{\dot\chi}\dot\chi,\dot\chi)}{g_2(\dot\chi,\dot\chi)}\dot\chi)$ is zero... Thanks!","['riemannian-geometry', 'differential-geometry']"
258018,Complex differentiability vs differentiability in $\mathbb{R}^2$,"I was wondering about the following for quite a while: The euclidean topology on $\mathbb{R}^2$ is homeomorphic with the topology induced by the modulus function on $\mathbb{C}$. Hence limit behavior is the same in both. So, doesn't that mean that the limit which defines the complex derivative converges if and only it converges in $\mathbb{R}^2$? Clearly, I am missing something, since not every differentiable function $\mathbb{R}^2 \rightarrow \mathbb{R}^2$ is smooth, but over $\mathbb{C}$ this is true. P.S.: I read the question: Is Complex Analysis equivalent Real Analysis with $f:\mathbb R^2 \to \mathbb R^2$? , it does however not clear up my confusion.","['complex-analysis', 'real-analysis']"
258022,Expected value of a max,"We have a roulette with the circumference $a$. We spin the roulette 10 times and we measure 10 distances, $x_1,\ldots,x_{10}$, from a predefined zero-point. We can assume that those distances are $U(0,a)$ distributed. An estimation of the circumference $a$ is given: $$a^* = \max(x_1,\ldots,x_{10})$$ To check whether it's biased or not I need to calculate: $$E(a^*) = E(\max(x_1,\ldots,x_{10}))$$ How do I proceed? I don't know any rules for calculating the estimate of a $\max$.","['statistics', 'parameter-estimation']"
258027,Averaging the values of $\cos x$ over one period,"I'm calculating the average value of $\cos x$ by dividing the period $[0,2\pi]$ into ten intervals which means that I should be looking for the average of 11 results. What I get is approx. 0.09. The expected result 0 is only obtained if I average over the values of the first 10 points. However, 10 points do not span the whole period $[0, 2\pi]$. What are your thoughts on this apparent problem?","['average', 'trigonometry', 'algebra-precalculus']"
258056,Co-Domain of composite function,Let's say I have $f: X \to Y$ where $f(x) = x^2$ $g: Y \to Z$ where $ g(y) = \cos(y)$ and $h: Z \to X$ where $h(z) = 2x-1$ If I take $ f \circ (g \circ h)$ I get $\cos^2(2x-1)$ What is the co-domain of this function? Is there some sort of rule for finding the co-domain? It's easy enough to find the domain and range but I'm not sure about the co-domain.,['functions']
258064,Does every line segment in $\mathbb{R}^n$ contains a point having only rational coordinates?,Let $S$ be the subset of $\mathbb{R}^n$ consisting of all points which have only rational coordinates. I know that $S$ is a dense subset of $\mathbb{R}^n$. Is it true that every line segment in $\mathbb{R}^n$ intersects S?,"['general-topology', 'multivariable-calculus', 'analysis']"
258096,Limit as $x$ goes to zero of an arbitrary function,"Let $f:\mathbb R\to\mathbb R$ be a function with the property that $f(a+b)=f(a)+f(b)$ for all real numbers $a$ and $b$. Assume that the limit as $x\to 0$ of $f(x)$ is equal to some real number $L$. Show $L=0$. I started to attempt to use the epsilon-delta definition of continuity, but I'm stuck. Please help! Edit: While I know that the functions for which this is true are, for example, $f(x)=cx$, I can't assume anything that is not given.","['functions', 'real-analysis', 'limits']"
258103,Boundary value problem of a second order linear differential equation,"A real-valued function $f$ defined on a closed interval $[a, b]$ has the properties that $f (a) = f (b) = 0$ and $f (x) = f'(x) + f''(x),\;\forall x \in [a, b]$. Prove: $$f (x) = 0, \;\forall x \in [a, b].$$","['ordinary-differential-equations', 'calculus']"
258107,Continuity criteria for Radon-Nikodym derivative,"I have been looking for results or theorems which give me regularity conditions of the Radon-Nikodym derivative, but I have not found any :( For instance, we know that if $\nu\ll\mu$ then there exists $f\in L^1$ s.t. $\nu = \int f d\mu$. I wonder if, under extra conditions, we can say more about $f$, like $f\in \mathcal{C}$ or similar. Are there results? Thank you very much for any help!","['measure-theory', 'calculus', 'functional-analysis', 'real-analysis']"
258108,A subspace of a dual space is norm closed if and only if it is weak star closed.,"I am trying to figure out if the statement holds true, the literature i am following says that its not true but i don't seem to understand, If $Y$ is a Banach space and let subspace $A \subset Y'$, such that $Y'$ is a dual . $A$ is norm closed if and only if $A$ is weak star closed ? Looks like reflexivity comes into play to argue this statement . 
Thank you for your hints !",['functional-analysis']
258127,Square root of an integer has only even digits,"Is there a non-square positive integer $n$, that $\sqrt{n}$ has only even digits in its decimal representation ?","['decimal-expansion', 'ergodic-theory', 'number-theory']"
258131,Noetherian module implies Noetherian ring?,"I know that a finitely generated $R$-module $M$ over a Noetherian ring $R$ is Noetherian. I wonder about the converse. I believe it has to be false and I am looking for counterexamples. Also I wonder if $M$ Noetherian imply that $R$ is Noetherian is true? And if $M$ Noetherian implies $M$ finitely generated is true? That is, do both implications fail or only one of them?","['modules', 'commutative-algebra', 'abstract-algebra']"
258137,Prove Noether-Skolem theorem for $M_2(\mathbb{C})$ by calculation,"Noether-Skolem Theorem for the case the ring is $M_2(\mathbb{C})$ says that ""Every $\mathbb{C}$-algebra automorphism of $M_2(\mathbb{C})$ is inner."" Now, how to prove it by a direct calculation? I have done the following: Suppose $\phi: M_2(\mathbb{C})\to M_2(\mathbb{C})$ is a $\mathbb{C}$-algebra automorphism, then we want to find an invertible matrix $A=(\begin{array}{cc}x&y\\z&w\end{array})$, suppose $A^{-1}=(\begin{array}{cc}x'&y'\\z'&w'\end{array})$, such that $\phi(X)=AXA^{-1}, \forall X\in M_2(\mathbb{C})$. Then, since $\phi$ is uniquely determined by $\phi(E_{1,2}), \phi(E_{2,1})$, where $E_{i,j},1\leq i,j\leq 2$ are the matrix units for $M_2(\mathbb{C})$. Calculation shows that $\phi(E_{1,2})=(x\ z)^T(z'\ w'), \phi(E_{2,1})=(y\ w)^T(x'\ y')$. Then, how to proceed?","['ring-theory', 'linear-algebra', 'abstract-algebra']"
258138,'H' symbol as a power of matrix,"Here is capture of problem That is what I saw while I was studying maximum ratio combining (MRC) in communication.
It is probably very simple and stupid thing to ask. 
I guess it is Hermitian of a matrix but i am not sure..
Here is entire content: http://www.dsplog.com/2008/09/28/maximal-ratio-combining/","['notation', 'matrices']"
258142,Well-Ordered Sets and Functions,"I need some assistance with the following problems. I've come up with some ideas but may need some clarification. 1) Let $S$ be a well-ordered set. a) Need to show $S$ has a first element. Solution: We know that any subset of $S$ has a first element, and since $S$ $\subseteq$ $S$, then clearly $S$ must have its own first element. b) Need to show that $S$ is linearly ordered. c) Show that $S$ is order-complete; that is, every subset that is bounded above has a suprenum. My intuition for this is to relate this to the Completeness Axiom of $\mathbb R$. d) Let $A$ be a non-empty subset of $S$, and show $A$ is well-ordered using the same ordering. 2) Let $f:$ $A \rightarrow$ $B$ be a surjective function; show $\exists$ an injective function $g:$ $B \rightarrow$ $A$. (This would imply $|A| \geq |B|$).","['elementary-set-theory', 'functions', 'order-theory']"
258149,Derivatives of a the Matrix diagonal function,"If A is a not diagonal but symetric matrix and diag() is a function such that returns the diagonal, i.e. diag(A) is a matrix of zeros except on the diagonal. Im interested in the derivative of vec(diag(A)) with respect to x where A is a function of the vector x. So, how do I do This in the best way? Thanks in advance!",['matrices']
258163,"Compute the subgroup $M_{\{0, -3, \infty\}} \subset M$ consisting of 6 transformations, preserving the set $\{0, -3, \infty\}$","Compute the subgroup $M_{\{0, -3, \infty\}} \subset M$ consisting of 6 transformations, preserving the set $\{0, -3, \infty\}$, together with an explicit isomorphism $$
M_{\{0, -3, \infty\}} = S_3
$$ I said that this would be some transformation that will send $\{0, 1, \infty\}$ to $\{0, -3, \infty\}$, i.e $L: z \mapsto -3z$. We therefore have $$
M_{\{0, -3, \infty\}} = L M_{\{0, 1, \infty\}} L^{-1}
$$ However I am now unsure as to how to get the answer, with the explicit isomorphism from here. Can someone help please? Thanks","['complex-analysis', 'group-theory', 'abstract-algebra']"
258174,Power series related problem,"I came across a problem that says: It is given that $\sum_{n=0}^{\infty}a_{n}z^{n}$ converges at $z=3+4i.$ Then the radius of convergence of the power series $\sum_{n=0}^{\infty}a_{n}z^{n}$ is (a)$\leq 5$ (b)$\geq 5$ (c)$<5$ (d)$>5$. We know if a power series $\sum_{n=0}^{\infty}a_{n}z^{n}$ converges for $z=z_{0},$ then it is absolutely convergent for every $z=z_{1},$ when $|z_{1}|<|z_{0}|.$ Using this property, i can conclude that $(a)$ is the correct choice as equality sign occurs keeping in mind that the given series converges at $|3+4i|=5.$ Am i going in the right direction? Please help. Thanks in advance for your time.","['power-series', 'real-analysis', 'analysis']"
258199,What are the prerequisites for taking introductory abstract algebra? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am a maths student in my second year of university. I have taken and done quite well in Calculus I, II, III as well as a linear algebra (application focused) class. I have not worked much with proofs. My school's course catalog lists Abstract Algebra as one of the next courses but suggests a remedial ""introduction to mathematical proofs"" class for some. My question is if the community thinks it would be doable to go ahead with Abstract. Our Abstract Algebra class is at the level of Thomas Hungerfords ""Abstract Algebra: An Introduction"".","['advice', 'education', 'abstract-algebra']"
258226,"""Commutativity"" of integrals","Let $\mu$ and $\nu$ be two measures on a space $X$. Suppose $$ \int_X fd\mu \int_X gd\nu = \int_X fd\nu \int_X gd\mu$$ for any integrable functions $f,g$. I would like to show that this implies that $\mu = \lambda\nu$ for some $\lambda > 0$, but I don't know how. Any help would be appreciated! Thanks!","['measure-theory', 'real-analysis']"
258228,Probability that the 10th class this semester is the 3rd class cancelled when chances are independent with 0.05 probability each day?,"Every day, a lecture may be cancelled due to inclement weather with probability 0.05. Class cancellations on different days are independent. Compute the probability that the tenth class this semester is the 3rd class cancelled? This is a practice exam so the exact answer isn't near as important as the proper solution. My assumption is P(3rd cancelled is 10th class) = P(2 cancellations in 9 classes)*P(cancelled)","['statistics', 'probability']"
258239,probability of a large sub-sequence within a huge sequence,"You toss a fair coin one million times.
What is the probability of getting at least one sequence of six heads followed by six tails?",['probability']
258253,Cumulative density function of a maximum and minimum,"It is given that both $Y$ and $X$ are $U(0,a)$, and that $Z_+ = \max(X,Y)$ and $Z_- = \min(X,Y)$. I need to find the CDF for both zetas. I know that both $X$ and $Y$ have to be smaller or equal to $Z_+$ and bigger or equal to $Z_-$. For $Z_+$: $$F_{Z_+}(z) = P(Z \leq z)$$ And for $Z_-$: $$F_{Z_-}(z) = P(Z \leq z)$$ This were I'm stuck, what is the next thing to do?","['statistics', 'probability']"
258269,Estimation with method of maximum likelihood,"Can anybody help me to generate the estimator of equation: $$Y_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2}+\cdots+\beta_4X_{i4}+\varepsilon_i$$ using method of maximum likelihood, where $\varepsilon_i$ are independent variables which have normal distribution $N(0,\sigma^2)$",['statistics']
258273,How do I prove that $\lim_{x\to0^+} x\cdot\ln x=0$,"How do I prove (without L'Hôpital's rule) that $$\lim_{x\to0^+} x\cdot\ln x = 0$$ . I'm trying to get some intuitive sense for this, but it's quite hard. It's like trying to prove that $x$ goes faster to $0$ then $\ln x$ goes to $-\infty$ , right ? I tried this, for $x\in(0,1)$ $$x \ln x=x⋅-\int_x^1 \frac{1}{t}dt>x\cdot\frac{(1-x)}{-x}=-1+x$$ So when $x\to0^+$ , I conclude that $x\cdot\ln x\ge-1$ .","['integration', 'real-analysis']"
258274,Determinants of block matrices,"Let $A,B \in \mathbb{R}^{n,n}$. Now $C = \begin{pmatrix}  A & iB \\ -iB & A \end{pmatrix}$ and $D = \begin{pmatrix} A & B \\ -B & A \end{pmatrix}$. Show that $\det(C) \in \mathbb{R}$ and $\det(D) \ge 0$. I tried to transform $C$ so I could use $\det \begin{pmatrix} E & F \\ 0 & G \end{pmatrix} = \det(E)\det(G)$, but I didn't manage to. I have no clue how to show $\det(D) \ge 0$. I'd rather have hints than fully-fledged solutions. Thanks.","['matrices', 'linear-algebra', 'block-matrices', 'determinant']"
258289,Inverse trig question?,Hello everyone I have a question about trig. How would I solve the following. $$\tan\left(2\arcsin(4/5)+\arccos(12/13)\right)=\frac{253}{204}$$ Please help.,['trigonometry']
258295,Eigenvalues of symmetric matrix in real inner product space,"I got the following exercise to solve: Let $A\in\mathbb{R}^{n\times n}$
  be a symmetric matrix and let $\lambda_{1}\geq\lambda_{2}\geq\cdots\geq\lambda_{n}$
  be its eigenvalues sorted in a desecnding order. Show that: $$\lambda_{k}=\max_{V,\,\dim\left(V\right)=k}\left\{ \min\frac{\left<x,Ax\right>}{\left<x,x\right>}\,:\, x\in V\,,\, x\neq0\right\} $$
 There is no mention of some specific inner product being taken here so I assume it needs to be proven for a general inner product on an $n$
  dimensional real inner-product space. I'm completely stumped with this, help would be greatly appreciated!","['matrices', 'eigenvalues-eigenvectors', 'inner-products']"
258331,Frattini subgroup of an abelian group equals to Prime subgroup,The prime subgroup $\wp(G)$ of an abelian group (maybe infinite) $G$ is defined as $\wp(G)=\bigcap_{p \in \Pi}pG$ where $\Pi$ is the set of all primes. Is it true that $\wp(G) = \Phi(G)$. Where $\Phi(G)$ is the Frattini subgroup of $G$?,"['group-theory', 'abelian-groups']"
258332,"Prove that if $a^x=b^y=(ab)^{xy}$, then $x+y=1$ using logarithms","Prove that if $a^x=b^y=(ab)^{xy}$, then $x+y=1$. How do I use logarithms to approach this problem?","['logarithms', 'algebra-precalculus']"
258343,Is it possible to algebraically prove that the $n$th degree Taylor remainder of $f(x)$ is less than $K|\Delta x|^{n+1}$ for $K \in \mathbb{R^+}$?,"I found a purely algebraic proof, given below, that for a mononomial $f(x) = x^n$ the magnitude of the error of its linear approximation  $| f(x) - [f(a) + f'(a)(x-a)] |$ is less than $K(x-a)^2$ for $K \in \mathbb{R^+}$. I can generalize this result to polynomials, and hence any Taylor series. I was wondering if it's possible, using algebraic means*, to generalize this proof for the error of any kind of approximation. For example, I'm looking to prove that the magnitude of the error of the quadratic approximation of a monomial, $| f(x) - [f(a) + f'(a)(x-a) + f''(a)(x - a)^2 / 2! ] |$, is less than or equal to $K(x-a)^3$ . Furthermore, is it possible to prove that it is impossible to find $K$ such that $| f(x) - [f(a) + f'(a)(x-a)] | < K(x-a)^n$ for $n > 2$? Or to find $K$ such that the $n$th degree Taylor remainder is less than $K(x-a)^{n+2}$? I'm asking all of this mainly to attain a better understanding of the Taylor series, and the limitations of algebra as opposed to tools such as the bisection algorithm. *(I'm aware that what I'm asking can be proven using, for example, the Lagrange form of the Taylor remainder.) Proposition 1 (What I've proved). Let $f(x) = x^n$. Then for all $a, x \in
[-I,I]$, there exists $K \in \mathbb{R^+}$ such that the error of the linear
approximation of $f(x)$ at $a$ is less than $K(x-a)^2$: $$|f(x) - f(a) -
f'(a)(x-a)| \leq K(x-a)^2$$ Proof. \begin{align*}
  f(x) - f(a) - f'(a)(x-a)&=
    (x-a)\sum_{i=1}^n x^{n-i}a^{i-1} - (x-a)na^{n-1} \\
  &=
    (x-a)\sum_{i=1}^n(x^{n-i}a^{i-1}-a^{n-1}) \\
  &=
    (x-a)\sum_{i=1}^n(x^{n-i}-a^{n-i})a^{i-1}.\\
  &=
    (x-a)\sum_{i=1}^{n-1}(x^{n-i}-a^{n-i})a^{i-1}\\
  &=
    (x-a)\sum_{i=1}^{n-1}(x-a)\sum_{j=1}^{n-i}(x^{n-i-j}-a^{j-1})a^{i-1} \\
  &=
    (x-a)^2\sum_{i=1}^{n-1}\sum_{j=1}^{n-i}x^{n-i-j}a^{i+j-2}.\\
\therefore \quad |f(x) - f(a) - f'(a)(x-a)| &=
  (x-a)^2\left|\sum_{i=1}^{n-1}\sum_{j=1}^{n-i}a^{n-i-j}x^{i+j-2}\right|\\
&\leq 
  (x-a)^2\left|\sum_{i=1}^{n-1}\sum_{j=1}^{n-i}I^{n-i-j}I^{i+j-2}\right|.\\
\end{align*} Proposition 2 (An attempt to generalize Proposition 1). Let $f(x) = x^n$. Then for all $a, x \in
[-I,I]$, there exists $K \in \mathbb{R^+}$ such that the error of the quadratic
approximation of $f(x)$ at $a$ is less than $K(x-a)^3$: 
  $$|f(x) - f(a) - f'(a)(x-a) - f''(a)(x-a)^2| \leq K(x-a)^3$$ Proof (Incomplete). The right hand side of this proof is identical to the proof for proposition 1, save for the final set of equations after the $\therefore$ sign.
\begin{array}{l}
  f(x) - f(a) - f'(a)(x-a) - \frac{f''(a)}{2!}(x-a)^2 + \frac{n(n-1)a^{n-2}}{2}(x-a)^2\\
  = x^n - a^n - (x-a)na^{n-1} \\
  = (x-a)\sum_{i=1}^n x^{n-i}a^{i-1} - (x-a)na^{n-1}\\ 
  =
    (x-a)\sum_{i=1}^n(x^{n-i}a^{i-1}-a^{n-1})\\ 
  =
    (x-a)\sum_{i=1}^n(x^{n-i}-a^{n-i})a^{i-1}\\  
  =
    (x-a)\sum_{i=1}^{n-1}(x^{n-i}-a^{n-i})a^{i-1} \\
  =
    (x-a)\sum_{i=1}^{n-1}(x-a)\sum_{j=1}^{n-i}(x^{n-i-j}-a^{j-1})a^{i-1} \\
  =
    (x-a)^2\sum_{i=1}^{n-1}\sum_{j=1}^{n-i}x^{n-i-j}a^{i+j-2}\\
\therefore\quad f(x) - f(a) - f'(a)(x-a) - \frac{f''(a)}{2!}(x-a)^2 \\
  = (x-a)^2\sum_{i=1}^{n-1}\sum_{j=1}^{n-i}x^{n-i-j}a^{i+j-2} - \frac{n(n-1)a^{n-2}}{2}(x-a)^2\\
  = (x-a)^2\left[\sum_{i=1}^{n-1}\left(\sum_{j=1}^{n-i}x^{n-i-j}a^{i+j-2} - \frac{na^{n-2}}{2}\right)\right]\\
\end{array}","['taylor-expansion', 'summation', 'sequences-and-series', 'analysis']"
258358,How does intuition fail for higher dimensions?,"From this answer : Now, Algebraic Geometry is one of the oldest, deepest, broadest and
  most active subjects in Mathematics with connections to almost all
  other branches in either a very direct or subtle way. The main
  motivation started with Pierre de Fermat and René Descartes who
  realized that to study geometry one could work with algebraic
  equations instead of drawings and pictures (which is now fundamental
  to work with higher dimensional objects, since intuition fails there ). What are these failings? Can you give me some examples?","['geometry', 'algebraic-geometry', 'intuition']"
258372,A problem about convergence in finite measure space,"Suppose we have a measure space $(X,M,\mu)$, where $\mu(X)<+\infty$. Let ${f_n}$ be a sequence of non-negative functions, $f_n\in L_1,\ \forall n$ and $f_n$ converges to some $f$ pointwise. $f$ is not necessarily in $L_1$. Suppose now $\underset{X}{\int} f_nd\mu$ also converges to $\underset{X}{\int}fd\mu$, as $n\rightarrow \infty$. Is it true that $\underset{E}{\int} f_nd\mu\rightarrow\underset{E}{\int}fd\mu,\ \forall E\in M$? If not, can you give a counter-example? I've encountered a similar problem, where I have the condition $f\in L_1(X,M,\mu)$ but don't have the condition $\mu(X)<+\infty$. In that case it is pretty easy to prove this problem. But here I don't have this condition, and $\underset{X}{\int}fd\mu = \infty$ can indeed happen, so how can I prove the problem now? I tried using Egoroff's theorem, but I failed to get it to work. Any suggestions? Thanks!",['real-analysis']
258407,Inner regularity property of Radon measures in metric spaces,"Let us agree to say that $\mu$ is a Radon measure on a metric space $X$ if it is a Borel measure which is finite on compact subsets and is such that: Every measurable subset $A$ is outer regular, meaning that $$\mu(A)=\inf\{\mu(V)\ |\ A\subset V,\ V\ \text{is open}\};$$ Every open subset $U$ is inner regular, meaning that $$\mu(U)=\sup\{\mu(K)\ |\ K\subset U,\ K\ \text{is compact}\}.$$ The present question regards inner regularity. Indeed, as I read in Evans-Gariepy's Measure theory and fine properties of functions , Theorem 4, Chapter 1 (*), if $X=\mathbb{R}^n$ then every measurable subset is automatically inner regular. Is this a property of $\mathbb{R}^n$ alone? Formally: Question . Which metric spaces have the property that for any Radon measure every measurable subset is inner regular? (*) Notation and conventions in this book are a bit different from the ones of the present post. EDIT . Specifically, in Evans-Gariepy's book a measure is a extended-real valued set function which is monotone and subadditive (usually, this is called a outer measure ). A measurable set is one which satisfies Caratheodory's criterion:
$$E\ \text{is measurable} \iff \forall T\subset X,\ \mu(T)=\mu(T\cap E)+
\mu(T\cap E^c).$$
A Radon measure is a (outer) measure which is: Borel regular, meaning that every Borel set is measurable and every set (even nonmeasurable ones) is contained in a Borel set of the same (outer) measure; Finite on compact subsets. The aforementioned Theorem 4 of Chapter 1 says that, given a Radon (outer) measure on $\mathbb{R}^n$, every set (measurable or not) is outer regular and every measurable set is inner regular. Remark 1 . If $\mu$ is a Borel regular measure on $X$ such that every Borel set is inner regular, then every measurable subset of finite measure is inner regular. Indeed, if $M\subset X$ is measurable and has finite measure, then by applying two times the Borel regularity property we can get a Borel set $M'$ which is contained in $M$ and has the same measure as $M$. Remark 2 . In particular, if $X$ is locally compact and is expanding union of compact sets, as in Micheal's kind answer below, and if $\mu$ is a Borel regular Radon (outer) measure, I believe that every (Caratheodory) measurable subset is inner regular. Indeed let $M\subset X$ be measurable. If $\mu(M)<\infty$ we are done. If $\mu(M)=\infty$ then we can write it as an expanding union of sets of finite measure: $M=\cup_1^\infty M_j$. Every $M_j$ contains a compact $K_j$ such that $\mu(K_j)\ge \mu(M_j)-1$. Letting $j\to \infty$, $\mu(M_j)\to \mu(M)=\infty$ and so $\mu(K_j)\to \infty$ too. This proves the claim.","['measure-theory', 'geometric-measure-theory']"
258425,Linear Fractional Transformation - proof that it preserves circles,"Since linear fractional transformations are compositions of translations, mutliplications by a constant and inversion, I tried proving that an LTF would transform circles into circles by writing the equation of a circle as $z_0 + r\cdot\exp ( i \cdot \theta )$ , $0 \le \theta \le 2\pi$ and then looking at the effect of translations, multiplications by a constant and inversion. The first two clearly leave me with a circle, as does inversion of a circle centered around the origin, but I can't get this to work for a circle centered at an arbitrary point $z_0$. On the other hand, if I write down the general equation of a circle: $$A(x^2 + y^2) + Bx +Cy +D = 0$$ ...and write $w = u+iv = \frac{1}{z} = \frac{1}{(x+iy)}$ and make the appropriate substitutions, I get the equation of circle in terms of $u$ and $v$. Is it possible to write $$\frac{1}{z_0 + re^{i\theta}}$$ 
where $0 \le \theta \le 2\pi$,  in the form $$w_0 + r'e^{i\phi}$$ with $0 \le \phi \le 2\pi$?",['complex-analysis']
258436,What is the PDF of the Square Length of a Normally-Generated Vector?,"Consider a vector $\mathbf{x}\in\mathbb{R}^n$, where each element in $\mathbf{x}$ is sampled independently from a normal distribution $\mathcal{N}(0,\sigma^2)$. What is the probability density function of $||\mathbf{x}||_2^2$?","['normal-distribution', 'probability-distributions', 'probability']"
258442,A Continuous Nowhere-Differentiable Function,"The book Understanding Analysis by Stephen Abbott asserts that $$
g(x)=\sum_{n=0}^{\infty}\frac{1}{2^n}h(2^nx),
$$ where $h(x)=\left|x\right|$, $h:\left[-1,1\right]\to\mathbb{R}$, and $h(x+2)=h(x)$, is continuous on all of $\mathbb{R}$ but fails to be differentiable at any point. However, if I am not mistaken, can the $2^n$'s be cancelled out in $g$? I tried plotting this and could not obtain a nowhere-differentiable function.",['real-analysis']
258448,Summation of combinations [duplicate],This question already has answers here : Closed 11 years ago . Possible Duplicate: simple binomial theorem proof Why is $${6\choose 0} + {7\choose 1} + \ldots + {n+6 \choose n} = {n+7 \choose n}\;?$$,['combinatorics']
258463,Proof of random work property given the absolute value of variables,"This hints that $E(|S_n|)\,\!$, the expected translation distance
  after ''n'' steps, should be of the order of $\sqrt n$. In fact, $$\lim_{n\to\infty} \frac{E(|S_n|)}{\sqrt n}= \sqrt{\frac 2{\pi}}.$$ (from http://en.wikipedia.org/wiki/Random_walk#One-dimensional_random_walk ) Why is it like this? After looking at Wikipedia contents all below, I was not able to find proof - so can anyone provide me proof?","['probability-theory', 'random-walk']"
258465,"Iterated Integrals - ""Counterexample"" to Fubini's Theorem","Showing the iterated integrals $$\int_{[0,1]}\left[\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2}dx\right]dy\quad\text{and}\quad\int_{[0,1]}\left[\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2}dy\right]dx$$ are different isn't too hard, so this certainly implies $f(x,y)\notin L^1([0,1]^2)$ (otherwise it would be a counterexample to Fubini's Theorem), so how do we show that $$\iint_{[0,1]^2}|f|\;dx\:dy=\infty?$$ I've been thinking about this, but my intuition always leads me back to iterated integrals. Any help would be appreciated in guiding me in which direction I should take.","['measure-theory', 'calculus', 'real-analysis']"
258494,Why does the Central Limit Theorem break down for the Poisson Process,"I am considering this in the sense that I know according to the central limit theorem, for an i.i.d. process $X_n$ (with mean $m$ and variance $σ^2$), the corresponding normalized sum process is:
$$
    Z_n = \frac{S_n-nm}{σ\sqrt{n}}
$$
with $S_n = X_1+X_2+ . . . + X_n$. I know that this does indeed converge in distribution to a zero-mean unit-variance Gaussian. My question is why does this not happen for the Poisson Process. I am speaking of the Poisson process derived as a limit of the Binomial counting process, where $n$, the number of infinitesimal intervals, went to $∞$, and $p$, the success probability, went to $0$, while their product $np$ stayed constant at $\lambda t$. I believe if CLT had worked here, we would have obtained a Gaussian $N(t)$ instead of a discrete $N(t)$. For the purposes of exploring this problem, if we consider the Taylor expansion:
$$E\left[\exp\left(-\frac{j \omega}{\sigma \sqrt{n}}(X_1-m)\right)\right]=\displaystyle\sum\limits_{k=0}^∞ \frac{1}{k!}\left(-\frac{j \omega}{\sigma \sqrt{n}}\right)^k E \left[(X_1-m)^k\right]$$ I desire to examine higher-order the terms when $X_1$ is
$$\mathrm{Bernoulli}\left(\frac{\lambda t}{n}\right)$$
as in the Poisson Process. Can we say these term are really neglible when compared to the terms for $k=0,1,2$? Any help would be greatly appreciated.
Thanks!","['probability-theory', 'stochastic-processes']"
258502,Do $T$-invariant subspaces necessarily have a $T$-invariant complement?,"Suppose $T$ is a linear operator on some vector space $V$, and suppose $U$ is a $T$-invariant subspace of $V$. Does there necessarily exist a complement (a subspace $U^c$ such that $V=U\oplus U^c$) in $V$ which is also $T$-invariant? I'm curious because I'm wondering if, given such $U$, it is always possible to decompose the linear operator $T$ into the sum of its restrictions onto $U$ and $U^c$, but I don't know if such a $T$-invariant $U^c$ exists.",['linear-algebra']
258503,The $n$ Immortals problem.,"I saw this riddle posted on reddit a long time ago, called the ""Seven Immortals."" In the beginning, the world is inhabited by seven immortals, ageless and sexless, who begin to multiply and populate the land.  Any immortal can mate with any other to produce exactly one child, and the same is true of their descendants, with the caveat that no immortal could mate with his own ancestors or relatives.  No couple can mate more than once, and they continue to intermingle until no more matings are possible.  How many immortals are left in the end? The solution is $19873$, which I lazily confirmed by writing a Mathematica program. Having a mathematical mind, I of course immediately wondered about the ""$n$ Immortals"" problem.   Surely a combinatorial solution with binomial coefficients should be attainable by extending the ""genes"" approach discussed in the comments.
But is this the only way?  It feels like a graph theory problem to me. My second question is, is there any significance to this problem?  Does the solution arise in any other mathematical contexts?","['graph-theory', 'puzzle', 'recreational-mathematics', 'combinatorics']"
258511,Prove that every convex function is continuous,"A function $f : (a,b) \to \Bbb R$ is said to be convex if $$f(\lambda x+(1-\lambda)y)\le \lambda f(x)+(1-\lambda)f(y)$$ whenever $a < x, y < b$ and $0 < \lambda <1$ . Prove that every convex function is continuous. Usually it uses the fact: If $a < s < t < u < b$ then $$\frac{f(t)-f(s)}{t-s}\le \frac{f(u)-f(s)}{u-s}\le\frac{f(u)-f(t)}{u-t}.$$ I wonder whether any other version of this proof exists or not?","['convex-analysis', 'continuity', 'real-analysis']"
258517,sum of two connected subset of $\mathbb{R}$,"$A$ and $B$ are  two connected subset of $\mathbb{R}$ define $A+B=\{x+y:x\in A,y\in B\}$, then is $A+B$ also connected? naturally I was thinking about two disjoint connected subsets of $\mathbb{R}$, say $A=[0,1]$ and $B=[4,5]$ then $A+B=[4,6]$? so is it ingeneral true?",['general-topology']
258521,How to do $\frac{ \partial { \mathrm{tr}(XX^TXX^T)}}{\partial X}$,"How to do the derivative 
\begin{equation}
\frac{ \partial {\mathrm{tr}(XX^TXX^T)}}{\partial X}\quad ?
\end{equation} I have no idea where to start.","['matrices', 'calculus', 'derivatives', 'multivariable-calculus']"
258568,Isolated Singularities of Complex Square Root and Logarithmic Functions,"On page 171 of Theodore Gamelin's Complex Analysis, there is an example saying the following: ""The functions $\sqrt{z}$ and $\log(z)$ do not have isolated singularities at $z=0$; they cannot be defined even continuously on any punctured disk centered at $0$."" I don't really understand why they can not be defined continuously.  Suppose there is a punctured disk centered at $0$.  For the square root, isn't every value on the plane defined?  For either case, why are they not defined continuously?",['complex-analysis']
258590,Explicit example of Koszul complex,"Let $R$ be a commutative ring and $x$ and $y$ two elements in $R$. I want to construct the Koszul complex on $x$ and $y$. We start by the following two chain complexes $$C_2=0\to C_1=R\xrightarrow{\ x\ } C_0= R\to C_{-1}=0$$
$$D_2=0\to D_1=R\xrightarrow{\ y\ } D_0= R\to D_{-1}=0$$
Now we construct the tensor product chain complex which we denote $CD:=C\otimes D$:
$$CD_2=C_1\otimes D_1=R\otimes R$$
$$CD_1=C_1\otimes D_0 \oplus C_0\otimes D_1 =R\otimes R \oplus R\otimes R $$
$$CD_0=C_0\otimes D_0=R\otimes R$$ and we get the chain complex
$$CD_3=0 \to CD_2=R \otimes R\xrightarrow{\ \partial_2\ } CD_1= R \otimes R \oplus  R \otimes R \xrightarrow{\ \partial_1\ } CD_0= R \otimes R \to CD_{-1} =0$$ We now compute $\partial_1$ and $\partial_2$: $$\partial_2 (c_1\otimes d_1)=(xc_1)\otimes d_1-c_1\otimes (yd_1)$$ and 
$$\partial_1 (c_1\otimes d_0+c_0\otimes d_1)=(xc_1)\otimes d_0+c_0\otimes (yd_1).$$ Now I want to move from here to express $\partial_1$ and $\partial_2$ in the way expressed in the wikipedia page (section Introduction). I don't understand the notation $R^2$ and the matrix expression of the differentials and where did the tensor product disappear from the final result. Thank you for your help!!","['homological-algebra', 'commutative-algebra', 'abstract-algebra', 'tensor-products']"
258601,Conditioning on an event with probability close to one,"Let $(\Omega,\mathcal{F},P)$ be a probability space. If $A\in\cal F$ is an event with $P(A)=1$, then
$$
P_{\mid A}(B)=P(B\mid A)=\frac{P(B\cap A)}{P(A)}=P(B),\quad B\in\cal F.
$$
I wonder if something can be said about how ""close"" $P_{\mid A}$ and $P$ are, when $A\in\cal F$ is an event with probability close to $1$ and also what ""close"" should mean. For example, if $P(A)=p$ and let's say that $p=0.99$, can we give a non-trivial upper bound on the maximal distance
$$
\sup_{B\in\cal F}|P_{\mid A}(B)-P(B)|
$$
in terms of $p$? And could other types of distances be interesting? This is just me thinking, so anything you can add will be appreciated. Thanks.","['statistics', 'probability']"
258620,boundedness of harmonic conjugates,Let $u$ be an harmonic function in the open simply connected set $U$. Then $u$ has a harmonic conjugate $v$ in $U$ (i.e. $f=u+iv$ is analytic on $U$). Suppose $u$ bounded in $U$. Can I say that $v$ is also bounded?,['complex-analysis']
258635,How to solve $2{x_{1}}+2{x_{2}}+{x_{3}}+{x_{4}}={12}$,How many solutions possible for the equation$$2{x_{1}}+2{x_{2}}+{x_{3}}+{x_{4}}={12}$$ all x are non-negative integer. I see these links but I don't know how to solve this problem.(I know how to solve ${x_1}+{x_2}+{x_3}+{x_4}=12$) How many solutions possible for the equation $x_1+x_2+x_3+x_4+x_5=55$ if Enumerating number of solutions to an equation,"['inclusion-exclusion', 'discrete-mathematics', 'combinatorics']"
258643,"Visually, why is the 2-sphere $S^2$ not contractible?","In topology, can someone please describe why the sphere $S^2$ is not contactable? Surely it can just 'shrink' to a point?",['general-topology']
258654,cyclic vector exists for symmetric operator iff there no repeated eigenvalues,"Considering a symmetric operator $A$ acting on a finite dimensional Hilbert space $H$, we say $x\in H$ is a cyclic vector for $A$ if the set of finite linear combinations of $\{A^n x:n=0,1,2,...\}$ is equal to $H$. I am looking for a proof of whether $A$ must have a cyclic vector iff $A$ has no repeated eigenvalues. Hints are welcomed.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
258665,What does the localization of a finite ring look like?,"Let $A$ be the ring $\mathbb{Z}/60$. What does it look like under the localization at the prime (2)? Everything that is not divisible by 2 should be a unit, so one might thing this looks like $\mathbb{Z}/4$ - but on the other hand, rings always inject into their localizations... I'm asking because Vakil in his notes says that the stalk at (2) of this ring is $\mathbb{Z}/4$. But this doesn't make sense to me because of the above confusion.","['ring-theory', 'algebraic-geometry', 'finite-rings', 'abstract-algebra']"
258673,Need help on proof for injectivity of a function,"I have a function, $f(x, y) = (x + y, x)$. The proof that this function is injective, is as follows: Say that $f(x,y)=f(x′,y′)$. We are assuming that two different inputs give the same output. For $f$ to be injective we need to prove that the inputs actually are the same. So we have $f(x,y)=f(x′,y′)$ and we need to prove that $x=x′$ and $y=y′$. That $f(x,y)=f(x′,y′)$ means that $(x+y,x)=(x′+y′,x′)$. But if this is true then we certainly have that $x=x′$. What I don't understand is the "" But if this is true "" part. If it is true seems to imply that it also could not be true, so how does this proof anything? I mean, the proof seems to be assuming a couple of things, so how does this make for a concrete proof?",['functions']
258702,root test: why $\lim\sup$?,We just had the root test in class: $\sum_{n=1}^\infty a_n$ (in $\mathbb R)$ converges if $\lim\limits_{n\rightarrow\infty}\sup\sqrt[n]{|a_n|}<1$ Why is it important to take the $\lim\sup$ and not taking just $\lim$? Any examples? I've considered some series but with none of them I had a problem of taking $\lim$ instead of $\lim\sup$.,"['sequences-and-series', 'real-analysis', 'analysis']"
258712,"Matrix P to the power of 4, i.e $P^4$, is this the same as $P^2 \cdot P^2$?","Basically, what it says in the title. I have a $5 \times 5$ matrix and I need to work out $P^4$, is it possible to just do $P^2$ and multiply this with itself?","['matrices', 'exponentiation', 'linear-algebra']"
