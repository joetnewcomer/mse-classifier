question_id,title,body,tags
2888868,Geometric intuition behind an n-dimensional rotation matrix,"How do I derive an n-dimensional rotation matrix from a geometric perspective? I have read on wikipedia that it preserves distance so that $Q^TQ = I$ but the explanation to be honest isn't very clear. I've had a thorough look on Google and can't find a decent explanation that starts from the geometry first. Also, on Wikipedia (see here: https://en.wikipedia.org/wiki/Rotation_matrix ) it says that $det(Q) = 1$ but it isn't clear at all why! Thanks.","['matrices', 'linear-algebra', 'linear-transformations', 'rotations']"
2888908,How do not generate a $\sigma$-algebra,"Let  $\mathscr{C}\subset \mathscr{P}(\Omega)$ be  a class of subsets of a nonempty set $\Omega$ containing $\Omega$ and $\varnothing$. Define $\mathscr{C}_0=\mathscr{C}$ and for each  $n\geq 1$ define 
$$
\mathscr{C}_{n+1}=\mathscr{C}_n\cup \{A^c:~ A\in \mathscr{C}_n\}\cup \{\bigcup_{i=1}^\infty A_{i}: ~\{A_{i}\}_{i=1}^\infty\subset \mathscr{C}_n\}.
$$ Question: I am looking for an example of $\Omega$ such that   $\mathscr{A}(\mathscr{C})=\bigcup_{i=1}^\infty \mathscr{C}_n$ do not equal to $\sigma(\mathscr{C})$ the sigma álgebra generated by $\mathscr{C}$. I first try to pick a $\Omega=\mathbb{R}$ and consider $\mathscr{C}$ the class given by the finite and cofinite sets, however applying the above procedure we get the the class of the contable and co-countable subsets, which is a sigma álgebra.... I know that must be examples that $\mathscr{A}(\mathscr{C})=\bigcup_{i=1}^\infty \mathscr{C}_n$ do not equal to $\sigma(\mathscr{C})$  because we need of an ordinal argument in the construction...","['measure-theory', 'lebesgue-measure', 'analysis', 'reference-request', 'real-analysis']"
2888948,A question relating to uniform integrability and tightness,"Let $(f_n)$ be a sequence of integrable functions on $\mathbb{R}$ . I want to show that $(f_n)$ is uniformly integrable
and tight over $\mathbb{R}$ if and only if for each $\varepsilon>0$ , there are positive numbers $r$ and $\delta$ such that for
each open subset $\mathcal{O}$ of $\mathbb{R}$ and index $n$ , if $m(\mathcal{O}\cap (-r,r))<\delta$ , then $\int\limits_{\mathcal{O}}|f_n|dm<\varepsilon$ . If the given condition holds, then it is easy to show that $f$ is uniformly integrable and tight. Let $\varepsilon >0$ . Then there exist $\delta >0,r>0$ such that for all open sets $\mathcal{O}$ with $m(\mathcal{O}\cap (-r,r))<\delta\implies \int\limits_{\mathcal{O}}|f_n|dm<\varepsilon$ . Let $A$ be a measurable subset of $\mathbb R$ with $m(A)<\frac{\delta}{2}$ . Thus there exists an open set $\mathcal{O}$ containing $A$ such that $m(\mathcal{O}\setminus A)<\frac{\delta}{2}$ . Thus \begin{align}
m(\mathcal{O}\cap (-r,r)) & = m((\mathcal{O}\setminus A) \cap (-r,r))\\
&\quad +m(A\cap (-r,r))\\
& <\frac{\delta}{2}+\frac{\delta}{2}\\
& =\delta.\end{align} Thus by hypothesis $\int\limits_{\mathcal{O}}|f_n|dm<\varepsilon$ . Hence $\int\limits_A |f_n|dm\leq \int\limits_{\mathcal{O}}|f_n|dm<\varepsilon$ . Also $\mathbb R\setminus [-r,r]$ is an open set such that $(\mathbb R\setminus [-r,r])\cap (-r,r)=\emptyset$ . Thus $\int\limits_{\mathbb R\setminus [-r,r]}|f_n|dm<\varepsilon$ and so $(f_n)$ is tight. But how to prove the converse? Help please!","['integration', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
2888956,"If $f(x)=\lim_{t\to\infty}{\frac{(1+\sin{\pi x})^t-1}{(1+\sin{\pi x})^t+1}}$, then range of $f(x)$ is?","If $$f(x)=\lim_{t\to\infty}{\frac{(1+\sin{\pi x})^t-1}{(1+\sin{\pi x})^t+1}}$$ Then range of $f(x)$ is? My Attempt: I was able to conclude that when, $$\sin{\pi x}\to0^+, f(x)\to1$$ $$\sin{\pi x}\to0^-, f(x)\to-1$$ But the answer is $\{-1,0,1\}$ When will $f(x)$ assume the value $0$?",['functions']
2888976,The Definite Integral Problem (with a twist)?,"The Definite Integral Problem (with a twist) In the Riemann integral one essentially calculates the area by splitting the area into $N$ rectangular strips and then taking $N \to \infty$ . Here's something I asked myself related to the Riemann integral. Let's say I split the area into say $3$ strips however I recount the first strip $a_1$ times, the $2$ 'nd strip $a_2$ times and the third strip $a_3$ times. Similarly we ask about $N= 4$ and recount the first strip $a_1$ times, the $2$ 'nd strip $a_2$ times, the third strip $a_3$ times and the fourth strip $a_4$ times: Now while this all is doable (but hardwork ?) is there any way to make it work for the case $N \to \infty$ after which I take the limit $k \to \infty$ Notice in the above pictures the area beneath the curve (in the Riemann integration sense where $a_r=1$ for all $r$ ) is obviously infinite. Let's add the conditions that the curve $f(x)$ is a smooth continuous function whose integral $\int_0^\infty f(x) d x  $ is absolutely convergent. Conjectured solution I discovered the following relation for arbitrary $a_r$ : $$ \lim_{k \to \infty}  \lim_{n \to \infty}\ \sum_{r=1}^n a_r \left(  f(\frac{k}{n}r)\frac{k}{n} \right) =  \lim_{s \to 1} \! \underbrace{\frac{1}{\zeta(s)}   \sum_{r=1}^\infty  \frac{a_r}{r^s}}_{\text{removable singularity}} \int_0^\infty f(x) \, dx  $$ Where $f(x)$ is a smooth continuous function whose integral $\int_0^\infty f(x) d x  $ is absolutely convergent. $a_r$ is the $r$ 'th number of a sequence. Heuristic Proof (a lot of cheating involved) Consider an integral such that $$ \int_0^\infty f(x) \, dx = C,$$ where, $f(x)$ is a smooth and continuous function and absolutely converges. Now we raise both sides to the power s: $$\left(\int_0^\infty f(x) \, dx\right)^s = C^s $$ We substitute $x$ with $rx$ to get: $$\left(\int_0^\infty f(rx) \, dx\right)^s = (C/r)^s $$ Multiplying both sides by an arbitrary coefficient: $$ (b_r)\left(\int_0^\infty f(rx) \, dx\right)^s = (b_r)( C/r)^s $$ Taking their sum: $$ \sum_{r=1}^\infty b_r \left(\int_0^\infty f(rx) \, dx\right)^s = C^s \underbrace{\sum_{r=1}^\infty \frac{b_r}{r^s}}_{\text{dirichlet series}}   $$ We write the integral as a limit of a Riemann sum: $$ \sum_{r=1}^\infty  \lim_{k \to \infty} \lim_{n \to \infty}\ b_r \left( \sum_{x=1}^n f(\frac{kx}{n}r)\frac{k}{n} \right)^s  = C^s \sum_{r=1}^\infty \frac{b_r}{r^s} $$ Using the mobius inversion formula: $$ \sum_{r=1}^\infty  \lim_{k \to \infty} \lim_{n \to \infty}\ b_r \left( \sum_{x=1}^n f(\frac{kx}{n}r)\frac{k}{n} \right)^s  = C^s \frac{1}{\zeta(s)}\sum_{r=1}^\infty \frac{a_r}{r^s} $$ We define $ a_r = \sum_{e|r} b_e $ Note: $$ (\frac{b_1}{1^s} + \frac{b_2}{2^s} + \frac{b_3}{3^s} + \frac{b_4}{4^s} + \dots) \times (\frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \frac{1}{4^s} + \dots) = \frac{b_1}{1^s}  + \frac{b_1 + b_2}{2^s} + \frac{b_1 + b_3}{3^s} + \frac{b_1 + b_2 + b_4}{4^s} + \dots $$ Now focusing on the L.H.S ( $s \nearrow  1 $ ): $$ \sum_{r=1}^\infty  \lim_{k \to \infty} \lim_{n \to \infty}\ b_r \left( \sum_{x=1}^n f(\frac{kx}{n}r)\frac{k}{n} \right)^s = \sum_{r=1}^\infty  \lim_{k \to \infty} \lim_{n \to \infty}\ b_r \left( \sum_{x=1}^n f(\frac{kx}{n}r)\frac{k}{n} \right) $$ Focusing on the L.H.S (and vertically summing): $$ \lim_{k \to \infty }\lim_{n \to \infty} b_1 ((f(\frac{k}{n}) + f(2 \frac{k}{n}) + f(3 \frac{k}{n}) +f(4 \frac{k}{n}) + \cdots)\frac{k}{n} $$ $$+$$ $$ \lim_{n \to \infty} b_2 (0.f(\frac{k}{n}) + f(2 \frac{k}{n}) + 0.f(3 \frac{k}{n}) +f(4 \frac{k}{n}) +\cdots) \frac{k}{n}$$ $$+$$ $$ \vdots $$ $$ = \lim_{n \to \infty} (\underbrace{b_1}_{a_1} (f(\frac{k}{n}) + \underbrace{(b_1 + b_2)}_{a_2}f(2 \frac{k}{n}) + \underbrace{(b_1 + b_3)}_{a_3}f(3 \frac{k}{n}) +\underbrace{(b_1 + b_2 + b_4)}_{a_4}f(4 \frac{k}{n}) + \cdots)\frac{k}{n} $$ Note: this resummation trick can be only done for special functions ( $f$ must absolutely converge) Hence, for special $a_r$ the L.H.S converges: $$     \lim_{k \to \infty}  \lim_{n \to \infty}\ \sum_{r=1}^n a_r \left(  f(\frac{k}{n}r)\frac{k}{n} \right) = \lim_{s \to 1} \underbrace{\frac{1}{\zeta(s)}   \sum_{r=1}^\infty  \frac{a_r}{r^s}}_{\text{removable singularity}}  \times \int_0^\infty f(x) \, dx  $$ Example: Let $f(x) = e^{-x}$ $$ a_{2r} = 1$$ $$ a_{2r+1} = 0$$ Hence, Let us compute the R.H.S $$\lim_{s \to 1} \frac{1}{\zeta(s)} (\frac{2^{(-s)}}{\zeta(s)}) . 1 = \frac{1}{2}$$ Looking at the L.H.S: We are essentially adding all the even strips! This can be computed also by doing: $$ \int_{0}^\infty e^{-x} dx = 1 $$ $$ \implies \int_{0}^\infty e^{-2x} d(2x) = 1 $$ $$ \implies \int_{0}^\infty e^{-2x} d(x) = 1/2 $$ Hence both answers match! Here's a crazier example with non-periodic $a_r$ but the notation there is ( $a_r = d_r$ ) What is the limit of this Dirichlet series? Questions from Measure Theory Is it possible to prove the formula (without cheating :P)? 
( edit: answered with brilliance https://math.stackexchange.com/a/3359525/430082 ) When all $a_r=1$ for all $r$ then we have a Riemann integral formula. Is it possible to associate the conjectured formula with a measure (the LHS in variable form) rigorously ? $$ \lim_{k \to \infty}  \lim_{n \to \infty}\ \sum_{r=1}^n a_r \left(  f(\frac{k}{n}r)\frac{k}{n} \right) =  \lim_{s \to 1} \! \underbrace{\frac{1}{\zeta(s)}   \sum_{r=1}^\infty  \frac{a_r}{r^s}}_{\text{removable singularity}} \int_0^\infty f(x) \, dx  $$ where the curve $f(x)$ is a smooth continuous function whose integral $\int_0^\infty f(x) d x  $ is absolutely convergent","['dirichlet-series', 'measure-theory', 'riemann-integration', 'recreational-mathematics']"
2889024,"Explicit homeomorphism from $I \times I$ to itself that maps $I\times \{0\} \cup \{0,1\} \times I$ to $I \times \{0\}$","My question is basic and I apologize in advance if it's too easy. I've been reading some books on basic topology and I keep seeing the same thing: that there is an ""obvious"" homeomorphism: 
$$\varphi: I \times I  \to I \times I, $$
that takes $I \times \{0\} \cup \{0,1\} \times I$ to $I \times \{0\}$. But I cannot find an explicit formula. The statement is quite general and I have found this question but the author says that it's obvious without explaining why. I'm sure it's obvious but I really want to see it. Can anyone help ? Thank you.","['general-topology', 'algebraic-topology']"
2889030,Conditions for a matrix to have non-repeated eigenvalues,"I am wondering if anybody knows any reference/idea that can be used to adress the following seemingly simple question ""Is there any set of conditions so that all the eigenvalues of a real positive definite matrix are different?"" Motivation Duality in principal component analysis","['matrices', 'linear-algebra']"
2889055,What is $\lim_{x \to 0}\frac{\sin\left(\frac 1x\right)}{\sin \left(\frac 1 x\right)}$ ? Does it exist?,"Does $$\lim_{x \to 0}\;\frac{\sin\left(\frac 1x\right)}{\sin \left(\frac 1 x\right)}$$ exist? I believe the limit should be $1$. Because function being defined at the point is not a condition for limit to exist. This question came in my test and the answer given is limit does not exist. But if we see the graph , it is quite clear the function is exact 1 as $x \to 0$, so the limit should be 0. Even wolfram alpha gives the limit to be 1. But we are playing with infinity, so who knows? Maybe I am missing out on something? So what exactly is the limit and why? Edit: Wolfram alpha's widget (the link to which I have posted above) says the limit is 1. But here wolfram alpha says that the limit doesn't exist on the real line.",['limits']
2889091,"Show that $\lim_{s\rightarrow \infty} e^s m\left( f^{-1}\left([s,\infty)\right) \right) =0$.","Problem Suppose that $f:[0,1]\rightarrow [0,\infty)$ be a Lebesgue measurable function such that $$\int_{0}^{1} e^{[f(x)]}dx <\infty.  $$ Show that $$\lim_{s\rightarrow \infty} e^s m\left( f^{-1}\left([s,\infty)\right)  \right) =0$$ My attempt: According to the given condition, it seems I need to put $f(x)$ into $s$ , exponent of $e$ . But,, I lost my way. $$e^s m\left( f^{-1}\left([s,\infty)\right)  \right)=e^s \int_{0}^{1} \chi_{[s,\infty)}\circ f(x) dx \\=\int_{0}^{1} e^s \chi_{[s,\infty)}(f(x))dx.......  $$","['measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
2889179,Ring structure of $\mathbb{R}[x]/(p(x))$.,"Let $p(x) = ax^2 + bx + c \in \mathbb{R}[x]$ be a degree 2 polynomial with real coefficients such that $D := b^2 - 4ac$. I'd like to examine the structure of the ring $\mathbb{R}[x]/(p(x))$ in the following three cases: $D > 0, D < 0,$ and $D = 0$. (Note that $(p(x))$ is the ideal generated by $p(x)$.) Where I Am: Well, if $D>0$ (I think I've got this case)... ...then $p(x)$ has two distinct (real) roots; call them $\alpha$ and $\beta$. Therefore, we can write $p(x) = (x - \alpha)(x - \beta)$. So, by the Chinese Remainder Theorem, we have that
$$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R}[x]/(x - \alpha) \times \mathbb{R}[x]/(x - \beta). $$
Now, we claim that $\mathbb{R}[x]/(x - \alpha) \cong \mathbb{R}$. Indeed, consider the homomorphism $\phi:\mathbb{R}[x] \to \mathbb{R}$ given by $\phi(q(x)) = q(\alpha)$. Then, since
$$ \phi(q(x)) = q(\alpha) = 0 \iff q(x) \in (x - \alpha), $$
we see that $\ker(\phi) = (x - \alpha)$. Furthermore, since we may consider every real number to be a constant polynomial, we see that $\phi$ is surjective. Thus, it follows from the First Isomorphism Theorem that
$$ \mathbb{R}[x]/\ker(\phi) = \mathbb{R}[x]/(x - \alpha) \cong \phi(\mathbb{R}[x]) = \mathbb{R}. $$ 
Similarly, $\mathbb{R}[x]/(x - \beta) \cong \mathbb{R}$. Therefore,
$$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R} \times \mathbb{R}. $$ Now, if $D < 0$... ...then $p(x)$ has no real roots. Thus, $p(x)$ is irreducible. So, $\mathbb{R}[x]/(p(x))$ is certainly a field of some sort. I know that $\mathbb{C} \cong \mathbb{R}[x]/(x^2+1)$; but is this true of any quadratic irreducible in $\mathbb{R}[x]$? I would think not... but I'm having trouble describing this ring any further than this. (Note that I don't know anything about ""field extensions""...) And, finally, if $D=0$... ...then $p(x)$ has a single (real) root of multiplicity two; call it $\gamma$. Therefore, we can write $p(x) = (x - \gamma)(x - \gamma)$. May I make the same conclusion here that I did from the first case? I don't see why not, but I just don't feel all that confident doing so...","['ring-theory', 'abstract-algebra', 'polynomials']"
2889188,How many whole pieces can be taken out in this way? (Infinite chocolate bar problem),"The animation above implies that we can eat an infinite amount of chocolate from the same chocolate bar, but it is misleading—after each reassembly of the chocolate bar, the height of the chocolate bar actually decreases slightly. Suppose you kept on cutting, taking out one whole piece while reassembling the remaining pieces into a solid rectangular bar without holes. How many whole pieces can be taken out in this way? Let the number of whole pieces removed from the bar—out of the ten pieces labeled 1 to 10 below—be $n$ and let the number written on the last piece removed be $x.$ What is $nx?$ Details and Assumptions: • At the start, the sloping cut passes through the bottom right corner of piece 9, so that all the pieces below it stays the same each time the cut pieces are reassembled. • Each reassembly is done with 3 cut pieces (out of 4), as in the animation, along and above the red, dotted line. Remember, 1 labeled piece is always eaten up after each reassembly. • If after taking out a whole piece, the remaining pieces cannot be reassembled into a solid bar without holes, that piece does not count.","['problem-solving', 'geometry']"
2889195,Is a $3D$ volume possible with only $3$ faces?,"I was wondering if a $3D$ volume with only $3$ faces was possible. I know that in the Euclidean space, it is technically not possible (the minimum being $4$ faces), but maybe there was some other way. Like the moebius strip that only has one side and one face. Maybe by bending the space? Thank you!","['noneuclidean-geometry', 'geometry', '3d']"
2889197,Pointwise convergence of sequence $(f_n)_n$ of functions to $f$ and changing limits,"My analysis notes contains the following question: if $(f_n)_n$ is a sequence of functions of $A \subset \mathbb{R} \to \mathbb{R}$ and $a \in \mathbb{R} \cup \{-\infty, +\infty\}$ an accumulation point in $A$. Assume that for all $n$, $\lim_{ x \to a}f_n(x) = L_n$ exists and is finite. Suppose $(f_n)_n$ converges pointwise to $f:A \to \mathbb{R}$. 1) Does $\lim_{x \to a} f(x)$ exists? 2) Does $\lim_{n \to \infty} L_n$ exists? 3) Can we change limits (in case both limits exist)? If know all questions should be no. I have found examples for 1) and 3). However, I can not find an example for 2). I know I should look for a sequence of functions which does not converge uniformly. Any hints would be appreciated. My solutions to 1) 
Define $$f_n: \mathbb{R} \to \mathbb{R}: x \mapsto \begin{cases} -1 &\text{ if } x \leq -1/n\\ nx & \text{ if } -1/n < x < 1/n\\ 1 &\text{ if } x \geq 1/n\end{cases}.$$ This functions converges to the function $f$ which equals to -1 for $x > 0$, 0 for $x = 0$ and $1$ for $x > 0$. The limit in zero does not exist. and 3):
define $$f_n: \mathbb{R} \to \mathbb{R}: x \mapsto \frac{(nx)^2}{1 + (nx)^2}.$$ This sequence converges to $f$ which equals 1 everywhere, except for $x = 0$, where it equals to $0$. We have that 
$$1 = \lim_{x \to 0} \lim_{n \to \infty} f_n(x) \neq \lim_{n \to \infty} \lim_{x \to 0} f_n(x) = 0$$","['convergence-divergence', 'pointwise-convergence', 'real-analysis']"
2889206,Equation for great circles of a sphere [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Background : I have a sphere of some radius R. What I'm trying to do is essentially create a wireframe consisting of great circles that run along the sphere. I want an equation to represent the great circles so that I can find points that run along those trajectories. I don't have enough credit to post links, but there a post in the Mathematica stack exchange titled: How to draw a great circle on a sphere? Which is what I want to achieve. However, I want to implement it in python and require a further breakdown of the equations that are happening behind the scenes. I will be plotting these equations in python.","['parametric', 'spheres', 'geometry', 'differential-geometry']"
2889224,"The hunting of ""missing primes""","First, I would like to introduce a peculiar way to display the prime numbers (greater than $9$ ) by means of the ten they belong to ( $x$ -axis), and their ending digit ( $y$ -axis). Here's an example of such layout, reporting the first $25$ primes. (You might be interested in the following conjecture , which is based on this two-dimensional representation of prime numbers). We can now organize the primes (except $17, 19,29$ ) in a series of parallelograms, defined by four points corresponding to the four integers $N+1$ , $N+11$ , $N+49$ , and $N+59$ , where $N=0,3,6, 9\ldots$ denotes an increasing number of tens ( $N$ -parallelogram). As it was conjectured (and then shown) in this post , on the edge of each of these parallelograms, we can find at most $7$ primes . The red crosses in the picture below indicate the ""missing primes"" for each $N$ -parallelogram, i.e. the integers that lie on the $N$ -parallelogram (in one of the eight positions in which we could locate a prime), but that are not prime numbers. Now, we can easily see that the missing primes divisible by $7$ are located in a well defined position on each $N$ -parallelogram, as one can easily verify in the following scheme: Each gray segment, indeed, connects four missing primes divisible by $7$ .   For instance, the first segment from the left connects $49, 77, 133, 161$ . Similarly, we can recognize the missing primes divisible by $17$ in correspondence of the green segments in the following picture (again, four missing primes for each segment). For instance, the first segment from the left connects the missing primes $119, 187, 323, 391$ . It is clear that this scheme can be generalized, always yielding to a neatly organized structure (somehow cylindrical) of missing primes. Exactly here comes my question. Given $N$ , is there an elementary way to determine the exact number of missing primes, and their position, on the $N$ -parallelogram? I tried to use the interesting comments and the clever answers related to this post and also to this one , but I could not go far. Therefore, I will be very thankful for any suggestion. I apologize in case of confusion and/or naivety, and I will ask you also to improve the correctness of this question. Thanks again!","['quadrilateral', 'number-theory', 'prime-numbers', 'euclidean-geometry']"
2889232,Arranging finite balls of different color such that no balls of the same color are adjacent [duplicate],"This question already has answers here : Number of possible permutations of n1 1's, n2 2's, n3 3's, n4 4's such that no two adjacent elements are same? (2 answers) Permutation with no adjacent elements. (1 answer) In how many ways can $3$ red, $3$ blue, and $3$ green balls be arranged so that no two balls of the same colour are consecutive (up to symmetry)? (3 answers) Closed 5 years ago . The problem involves arranging balls of different color in a line such that no two balls of the same color are adjacent to each other. Eventually I would like to find a generalization of having $m$ different colors of balls and $n$ balls of each color, where each ball besides color are indistinguishable. But for now I will start with $3$ colors, red blue and yellow, and having $3$ of each color. If we had an infinite number of each ball, then i know the answer would be $3(2^8)$ but this is including arrangements where we might only have red and blue balls alternating and not have any yellows. One thought was to consider ""grouping"" the colors in its $3!$ permutations and finding the number of arrangements of the groups. But this wouldn't consider arrangements such as $RYRYBYBRB$ I feel like recurrence may be needed for a generalization but without being able to find this simple case I don't know if I can use it. Searching other questions of this sort doesn't help me either as it isn't this type of restriction. Brute forcing it is one option but it seems like a mess even for this smaller case, so it would only be good for smaller cases. Any help would be greatly appreciated",['combinatorics']
2889262,Calculate the Hessian of a Vector Function,"I'm working with optimisation. I am trying to obtain the hessian of a vector function: $$
\mathbf{F(X) = 0} \quad \text{or} \quad
  \begin{cases}
    f_1(x_1,x_2,\dotsc,x_n) = 0,\\
    f_2(x_1,x_2,\dotsc,x_n) = 0,\\
    \vdots\\
    f_n(x_1,x_2,\dotsc,x_n) = 0,\\
  \end{cases}
$$
I know that the Jacobian for a vector function is calculated as: $$
\mathbf{J}= \begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_1} \\ 	\vdots & \ddots & \vdots \\ \frac{\partial f_n}{\partial x_1} & \dots &\frac{\partial f_n}{\partial x_n} 
\end{bmatrix} 
$$
I also know that the hessian for a single function is calculated as: $$
\mathbf{H}_{f_1}= \begin{bmatrix}
\frac{\partial ^2 f_1}{\partial {x_1}^2} & \frac{\partial ^2 f_1}{\partial {x_1}{x_2}} & \dots & \frac{\partial ^2 f_1}{\partial {x_1}{x_n}}  \\  \frac{\partial ^2 f_1}{\partial {x_2}{x_1}} & \frac{\partial ^2 f_1}{\partial {x_2}^2} & \dots & \frac{\partial ^2 f_1}{\partial {x_2}{x_n}}  \\	\vdots & \vdots & \ddots & \vdots \\ \frac{\partial ^2 f_1}{\partial {x_n}{x_1}} & \frac{\partial ^2 f_1}{\partial {x_n}{x_2}} & \dots & \frac{\partial ^2 f_1}{\partial {x_n}^2}  
\end{bmatrix} 
$$ but I don't have an idea of how does the Hessian for a vector function should look like, neither how to calculate it. My idea was to calculate the hessian of each function, but I have no idea how to structure the result matrix $$
\mathbf{H}_{f_1}, \mathbf{H}_{f_2} , \dots , \mathbf{H}_{f_n}
$$","['multivariable-calculus', 'matrix-calculus', 'hessian-matrix', 'vector-analysis']"
2889278,When are almost block companion matrices which yield a given characteristic polynomial connected?,"This is motivated by this question Are matrices which yield a given characteristic polynomial and have specified structure connected? Let $\mathcal E \in M_n(\mathbb R)$ be a subset with following form: we first construct a block diagonal matrix in $M_n(\mathbb R)$ such that \begin{align*}
  C = \begin{pmatrix}
C_{k_1} & 0 & 0 & \cdots & 0 \\
0 & C_{k_2} & 0 & \cdots & 0 \\
0 & 0 & \ddots & \vdots & 0 \\
0 & 0 & 0 & \cdots & C_{k_r}
\end{pmatrix},
\end{align*} with $k_1 + k_2 + \dots + k_r = n$ such that each block $C_{k_j}$ is in the companion form \begin{align*}
\begin{pmatrix}
0 & 0 & \cdots & 0 & -c_0 \\
1 & 0 & \cdots & 0 & -c_1 \\
0 & 1 & \ddots & \vdots & \vdots \\
0 & 0 & \cdots & 1& -c_{k_j-1}
 \end{pmatrix}.
\end{align*} Now for each block we extend the last column to fill up the whole matrix. For example, suppose we have two blocks $C_1$ and $C_2$ with $C_1 \in \mathbb R^{2 \times 2}$ and $C_2 \in \mathbb R^{3 \times 3}$ , elements in $\mathcal E$ would look like \begin{align*}
\begin{pmatrix}
0 & -a_1 & 0 & 0 & -b_1 \\
1 & -a_2 & 0 & 0 & -b_2 \\
0 & -a_3 & 0 & 0 & -b_3 \\
0 & -a_4 & 1 & 0 & -b_4 \\
0 & -a_5 & 0 &1 & -b_5
\end{pmatrix}.
\end{align*} It is also clear for any monic $n^{th}$ degree real polynomial, we can at least find one realization in $\mathcal E$ since we can choose a matrix in block diagonal form. Let $f: \mathcal E \to \mathbb R^n$ be the map sending the coefficients of characteristic polynomial to $\mathbb R^n$ . Let $q(t) = t^n + a_{n-1} t^{n-1} + \dots + a_0$ be a fixed polynomial. I am wondering whether there are sufficient conditions on $a = (a_{n-1}, \dots, a_0)$ such that $f^{-1}(a)$ is a connected set? This question Are matrices which yield a given characteristic polynomial and have specified structure connected? asked a specific case, i.e, $n=4, k_1 = k_2 = 2$ . There is a very nice answer proving: as long as the polynomial has a real root, then it is connected. The technique by the answer does not seem to generalize. But I am very interested to know whether the same condition holds here: if $q(t)$ has a real root, then $f^{-1}(a)$ is connected where $a = (a_{n-1}, \dots, a_0)$ is the coefficient vector of $q(t)$ ? EDIT: This question might be too tricky to answer (This is the third time I put a bounty). But I would be happy to reward the bounty if someone gives an answer on a very special polynomial with coefficients vector of $a$ such that $f^{-1}(a)$ is connected. For example, is $f^{-1}((0, \dots, 0))$ connected, i.e., the polynomial with all roots to be $0$ or some other special polynomials?","['connectedness', 'companion-matrices', 'linear-algebra', 'polynomials', 'general-topology']"
2889288,How to minimize $f(x) = \|Ax-b\|$,"Solve the problem of minimizing $f(x) = ||Ax-b||$. Consider all the cases and interpret geometrically. If we write $$\|Ax-b\| = (a_{11}x_1 + \cdots + a_{1n}x_n - b_1)^2 + \cdots +  (a_{n1}x_1 + \cdots + a_{nn}x_n - b_1)^2$$ then $$\frac{\partial \|Ax-b\|}{\partial x_j} = 2(a_{11}x_1 + \cdots + a_{1n}x_n - b_1)a_{1j} + \cdots +  (a_{n1}x_1 + \cdots + a_{nn}x_n - b_1)a_{nj}$$ If I try to do $\frac{\partial \|Ax-b\|}{\partial x_j} = 0$ I get nothing useful. For $x$ to be a minimizer, I have to have gradient $0$ and hessian positive definite. If we do the hessian just to see: $$\frac{\partial^2 \|Ax-b\|}{\partial x_k\partial x_j} = 2a_{1k}a_{1j} + \cdots + 2a_{nk}a_{nj}$$ I see nothing useful here. I think the geometric interpretation comes from the conditions for the gradient to be $0$ and the hessian to be $>0$, but I don't find these conditions useful. Any ideas?","['maxima-minima', 'multivariable-calculus', 'calculus', 'optimization', 'derivatives']"
2889289,"If $\sigma: \mathbb{R}\to \mathbb{R}^2$ is a function that spirals,goes to infinity and repeats itself, then is $\sigma$ non-injetive?","Let $\sigma:\mathbb{R}\to \mathbb{R}^2$ be a smooth function such that $$\frac{\text{d}\sigma}{\text{d}t}(s) \neq 0, \quad \forall s \in \mathbb{R},$$ and 
$$\sigma(t+n) = \sigma(n) +\sigma(t),\  \forall\  n \in \mathbb{Z}, \  t\in [0,1]. $$ Moreover, assume that we can write $\sigma'$ in polar coordinates as 
$$\sigma'(t) = (r(t) \cdot\cos(\theta(t)),r(t) \cdot\sin(\theta(t))), $$
where $r,\theta: \mathbb{R}\to \mathbb{R}$ are smooth functions, and $\forall \ n$ $\in$ $\mathbb{Z}$
$$\theta(n) -\theta(n-1) = 2\pi . $$ My Doubt: Can $\sigma$ be an injective function? By drawing some figures, I came to the conclusion that, most likely, $\sigma$ is a non-injective function, once $\sigma$  is a function that spirals and $\lim\limits_{t\to \infty}\|\sigma(t)\| = \infty$. But I wasn't able to figure out a demonstration for this question. Can anyone help me? Intuition All $\sigma$ that I drew was something like the plot bellow, once $\sigma(1+t) = \sigma(1) + \sigma(t)$, if we continue to draw the image of $\sigma$, we clearly are able to clonclude that $\{\sigma(t); \ t \in [0,1)\}\cap\{\sigma(t); \ t \in [1,2)\} \neq \emptyset $ (but this is just my intuition about the problem).","['plane-curves', 'slope', 'smooth-manifolds', 'differential-geometry']"
2889347,Is the Banach space of continuous functions $I \to \ell^2$ separable?,"Inspired by this question . Consider the vector space $V$ of all continuous functions $I \to \ell^2$ for $I=[0,1]$ the closed unit interval and $\ell^2$ the Hilbert space of all square-summable sequences. Under the $\sup$ norm $V$ becomes a Banach space.
I would like to know is $V$ separable. Suppose $p_1,p_2,\ldots : I \to \ell^2$ form a countable dense subset. Believing the answer is no, we might try a diagonal argument to construct some $f$ with all $\|f-p_n\|>1$. One idea is to demand for $x = 1-1/n$ that the $n$-th coordinate of $f$ is equal to $p_n(x)+1$. Then we have a lot of freedom choosing the rest of the values for $f$. The problem with the approach is we have to choose those values so the limit $f(1-1/n) \to f(1)$ and that's hard to do knowing nothing about  $p_1,p_2,\ldots $.","['epsilon-delta', 'separable-spaces', 'hilbert-spaces', 'functional-analysis', 'general-topology']"
2889390,On Atiyah-Macdonald Exercise 3.26,"I am trying to prove the exercise 3.26 on Atiyah-Macdonlad: Let $(B_{\alpha},g_{\alpha \beta})$ a direct system of rings and $B$ the direct limit. For each $\alpha$, let $f_{\alpha}:A\rightarrow B_{\alpha}$ be a ring homomorphism such that $g_{\alpha \beta}\circ f_{\alpha}=f_{\beta}$ whenever $\alpha\leq \beta$. Then $f_{\alpha}$ induce $f:A\rightarrow B$. Show that 
  $$f^{\ast}(\mathrm{Spec}(B))=\bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))$$ Following the hint, I figured out 
$$\begin{aligned}\mathfrak{p}\notin f^{\ast}(\mathrm{Spec}(B)) &\Leftrightarrow  \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0\end{aligned}$$
and
$$\begin{aligned}\mathfrak{p}\notin \bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))&\Leftrightarrow  B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha\end{aligned}$$ By exercise 2.21 on Atiyah-Macdonald, we have $$ \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0 \Rightarrow B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha$$ But I have no idea how to prove the converse, which is true according to Atiyah-Macdonald. Since the direct limit is the direct sum modulo something, consider the direct sum of $B_{\alpha}$. The zero rings will be killed. The quotient part is unknown but intuitively should not be the direct sum of the rest non-zero rings. Does the fact that $B_{\alpha}\otimes_A k(\mathfrak{p})$ is a $k$-module matter here? Any hint and answers are welcomed!","['abstract-algebra', 'commutative-algebra']"
2889412,Optimization for a sum of submodular functions,"I know $H(A), A\in E$, $F(B), B\in W, E\cap W = \varnothing$, and $K(C), C\in E\cup W$ are all submodular functions. I am wondering whether I can maximize $H(A)+F(B)+K(C)$ via the greedy method with the 1/2 approximation guarantee.","['elementary-set-theory', 'optimization', 'combinatorics', 'discrete-mathematics']"
2889428,Where does Kolmogorov stand among the pantheon of mathematicians? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Kind of a soft question. More out of historical curiosity than really seeking an affirmative answer. Reading up a little bit, over time, I am increasingly tempted to believe that, the Soviet mathematician Andrey Kolmogorov is not celebrated as much as an equivalent European or American genius of similar calibre. His contribution to modern science, including probability theory and computational complexity are not often talked about as much in the mainstream. Is this a mere coincidence or just that his work missed the visibility aspect, because of the geo political situation of the 20th century? Isn't  Kolmogorov, one of the top 3 applied mathematician of 20th century?","['measure-theory', 'math-history', 'soft-question', 'probability']"
2889439,"Prove that $\ell(\Bbb{R}^n,\ell(\Bbb{R}^m,\Bbb{R}^q))=\ell_b(\Bbb{R}^n\times\Bbb{R}^m,\Bbb{R}^q)$","Prove that \begin{align}\ell(\Bbb{R}^n,\ell(\Bbb{R}^m,\Bbb{R}^q))=\ell_b(\Bbb{R}^n\times\Bbb{R}^m,\Bbb{R}^q)\end{align} where $\ell(\Bbb{R}^n,\ell(\Bbb{R}^m,\Bbb{R}^q))$ represents the space of continuous linear maps from $\Bbb{R}^n$ to $\ell(\Bbb{R}^m,\Bbb{R}^q)$ and $\ell_b(\Bbb{R}^n\times\Bbb{R}^m,\Bbb{R}^q),$ the space of bilinear maps from $\Bbb{R}^n\times\Bbb{R}^m$ to $\Bbb{R}^q.$ Also $\dim \Bbb{R}^n,\dim \Bbb{R}^m,\dim \Bbb{R}^q<\infty.$ How do I go about this? Any help?","['analysis', 'real-analysis', 'multivariable-calculus', 'calculus', 'derivatives']"
2889507,Proving $\lim_{z\to\infty}f(z)=\lim_{z\to 0}f\left(\frac{1}{z}\right)$,"I am trying to show that $\lim_{z\to\infty}f(z)=\lim_{z\to 0}f\left(\frac{1}{z}\right)$ by definition. My attempt: Let $\lim_{z\to\infty}f(z)=L$, so by definition, $$\forall\epsilon\in\mathbb{R^+} \ \exists R\in\mathbb{R^+} \ \text{s.t} \  |z|>R\implies |f(z)-L|<\epsilon.$$
Similarly, let $\lim_{z\to 0}f\left(\frac{1}{z}\right)=m$, so by definition, $$\forall\epsilon'\in\mathbb{R^+} \ \exists \delta\in\mathbb{R^+} \ \text{s.t} \  0<|z|<\delta\implies \left|f\left(\frac{1}{z}\right)-m\right|<\epsilon'$$
But I do not know how to show how they are equal?","['complex-analysis', 'limits']"
2889573,Euler Characteristic of Spherical Polygon,"I am a little confused on what the Euler Characteristic of an n-sided spherical polygon would be. Because the polygon is 3 dimensional, would it be considered to have 2 faces or 1? Following that, I would think that the Euler Characteristic would simply be equal to the number of faces as the number of edges and vertices are the same.","['geometry', 'algebraic-topology', 'differential-geometry']"
2889602,Monotonicity of function at a point,"The question says : Let
  $$f(x)=\begin{cases} 
-x^3+\frac{b^3-b^2+b-1}{b^2+3b+2} &:0\le x\lt1\\                                  2x-3 &:1\le x\le3\end{cases}$$.    Find all possible values of b such that f(x)has the smallest value at $x=1$. Since this question was an example question, the solution said, The Limiting value of f(x) from the left of $x=1$ should be either greater or equal to the value of the function at $x=1$. My question is for $x=1$ to have the smallest possible value, shouldn't the limiting value be Less than or equal to the function at $x=1$? The answer is $b\in (-2,-1)\cup (1,+\infty)$","['maxima-minima', 'derivatives']"
2889622,Characterisation of Continous function using 2 open sets,"Let $f:\mathbb  R\to \mathbb R$ be function . Define $2$ sets as A and B in $\mathbb R^2 $ as follows: A={$(x,y)|y<f(x)$},B={$(x,y)|y>f(x)$} . Then $f$ is continous on $\mathbb R$ iff A and B are open subset of $\mathbb R^2$ $\to $ to show A open that means for any $(a_1,a_2)\in A$ There exist some $r>0$ ball which contain in A .i.e $K=B_r((a_1,a_2))\subset A$ $(m,n)\in K$
As f is continous on R$\forall \epsilon >0,\exists \delta >0 $ such that $\forall x\in R$ $|x-y|<\delta$ then $|f(x)-f(y)|<\epsilon$ $f(a_1)>a_2$ I could not get idea to proceed further for any part.
Actually I don't able to understand how is this set look like.And How to use continuty assumption Any help will be appreciated","['continuity', 'analysis', 'real-analysis']"
2889633,Covering $X^2$ with countable subsets of $X$ for uncountable set $X$,"Let $X$ be an uncountable set and consider a map $x\mapsto C_x$ assigning to every $x\in X$ a countable subset $C_x$ of $X$. Now for any $x\in X$ define $$R_x:=\{x'\in X|x\in C_{x'}\}.$$
Obviously $R_x$ can be any subset of $X$. It is also clear that $R_x=X$ can hold for at most countably many $x$. But what happens if $R_x$ is just a bit smaller than $X$? Specifically, is it possible that $R_x$ is co-countable for all $x$? My intuition says NO. It is based on the following picture. For each $x$ $C_x$ can be taken to define a column in $X^2$: $$C_x':=\{(x,y)\in X^2|y\in C_x\}.$$ The union of all these columns defines a very ""sparse"" subset of $X^2$. The union can also be written as the union of all rows. If these rows would all be co-countable, the set doesn't look that ""sparse"" anymore. However, making this precise by turning $X^2$ into a measure space doesn't seem the way to go as the sets $C_x$ can be very wild.","['measure-theory', 'set-theory']"
2889665,Integrating linearly,"I came across this question and just want to make sure my understanding is correct. I need to find the general solution of: $$
\frac{dx}{dt} = a(1 - x)
$$ In this case, I'm finding the how $x$ changes with respect to $t$ so I'm integrating with respect to $t$. Does that mean the answer is $at - xat + C$? Thanks :)","['integration', 'calculus']"
2889732,Find the maximum value of $a+b$,"The question: Find the maximum possible value of $a+b$ if $a$ and $b$ are different non-negative real numbers that fulfill
  $$a+\sqrt{b} = b + \sqrt{a}$$ Without loss of generality let us assume that $a\gt b$. I rearrange the equation to get $$a - \sqrt{a} = b - \sqrt{b}$$ If $f(x)= x - \sqrt{x},$ then we are trying to solve $f(a)=f(b).$ Using some simple calculus I found that the turning point of $f(x)$ is $(\frac{1}{4}, -\frac{1}{4})$. Hence $0 \le b \le \frac{1}{4}$ and $\frac{1}{4} \le a \le 1$. From here, I have no idea how to proceed. I used trial and error to find that when $a$ increases, the value of $a+b$ increases as well. Hence I hypothesise that $a+b$ is at a maximum when $a=1$ and $b=0$, which implies that $a+b=1$ is a maximum. Can anyone confirm this?","['contest-math', 'elementary-number-theory', 'algebra-precalculus', 'optimization']"
2889737,"How many nondecreasing functions $f:\{1,2, \ldots, n\} \to \{1,2, \ldots, n\}$ with $f(i)\leq i$ are there?","As in title, how to determine the number of nondecreasing functions $f:\{1,2, \ldots, n\} \to \{1,2, \ldots, n\}$ such that $f(i)\leq i$, for all $i \in \{1,2, \ldots, n\} $? I know that there is in general ${2n-1}\choose{n-1}$ nondecreasing functions. I also have tried to solve the problem for small n's: For n=1 we have one such function, for n=2 we have two such functions and for n=3 we have five such functions. If we list all the possible values that functions can take for $n=3$, we see that there are as many functions as paths connecting all the columns's, for example f(1)=1, f(2)=2, f(3)=3. Starting with f(3)=3, at each step we can go ""left"" and ""down"" or remain ""at the same level"" but we cannot go ""up"", because then the function would be decreasing. $f(1)=1$ $f(1)=2$ $f(2)=2$ $f(1)=3$ $f(2)=3$ $f(3)=3$ Having that said we can count how many nondecreasing sequences of the form $(a_1, a_2, \ldots, a_n)$ we have such that $a_i = f(i)$.","['functions', 'discrete-mathematics']"
2889768,How to prove that $\sum_{k=1}^n\frac{1}{\sqrt[n]{k!} }\sim \frac{n}{\ln n}$,"Recently I have met this asymptotic estimation:
prove that $\sum_{k=1}^n\frac{1}{\sqrt[n]{k!} }\sim \frac{n}{\ln n}$，$n\to \infty$. Here is the way I think: According to area principle，
\begin{align*}
 \Bigg|\sum_{k=1}^n\frac{1}{\sqrt[n]{k!} }-\int_1^n\frac{1}{\sqrt[n]{\Gamma(x+1)}}d x\Bigg|\leqslant \frac{1}{\sqrt[n]{\Gamma(n+1)}}
\end{align*}
Thus we have
\begin{align*}
\frac{\ln n}{n}\Bigg|\sum_{k=1}^n\frac{1}{\sqrt[n]{k!} }-\int_1^n\frac{1}{\sqrt[n]{\Gamma(x+1)}}d x\Bigg|\leqslant \frac{\ln n}{n}\frac1{\sqrt[n]{\Gamma(n+1)}}\sim \frac{\ln n}{n}\cdot \frac1{\sqrt[n]{2\pi n}} \frac{e}{n}\to 0,~~n\to \infty
\end{align*}
To this end we only need to show
\begin{align*}
\int_1^n\frac{1}{\sqrt[n]{\Gamma(x+1)}}d x\sim \frac{n}{\ln n}
\end{align*}
 But my train of thought is stuck here.Can you give me any help? Thanks a lot.","['limits', 'summation', 'sequences-and-series']"
2889805,Elliptic primes?,"Given the series of prime numbers greater than $9$, we organize them in four rows, according to their last digit ($1,3,7$ or $9$). The column in which they are displayed is the ten to which they belong, as illustrated in the following scheme. My conjecture is: Given any two primes, it is always possible to find an ellipse whose foci coincide with the two points corresponding to the given primes in the previous representation, and  passing through at least other two points,  corresponding to other two primes. Here I present some examples, where the red segments connect the two foci of each illustrative ellipse. Sorry if the picture is a bit chaotic! Since I am not an expert of prime numbers, this can be an obvious result. In this case, I apologize for the trivial question. Anyway, I tried to prove this conjecture by means of the interesting observations related to this post, which is strongly related. Thanks for your comments or suggestions, also to improve the quality and correctness of this question!","['euclidean-geometry', 'number-theory', 'conic-sections', 'algebraic-geometry', 'prime-numbers']"
2889814,Evaluate $\int_0^1\ln(\frac{1+x}{1-x})dx$ using power series,"I would like to evaluate the integral $\int_0^1\ln(\frac{1+x}{1-x})dx$ by expanding the integrands into power series. Asking wolframalpha the answer should be $2\ln(2)$ but I don't get there. What I tried so far: I know that $\ln(x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}(x-1)^k$ if $|x-1|\leq 1$ and $x\neq 0$. We also have $\ln(\frac{1+x}{1-x})=\ln(1+x)-\ln(1-x)$.
Using the formula for the power series, I get $\ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^k$ on $[0,1]$ and $\ln(1-x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}(-x)^k=-\sum_{k=1}^\infty \frac{1}{k}x^k$ on $[0,1)$. Can I just substract this know? Is it right that then $\ln(\frac{1+x}{1-x})=\ln(1+x)-\ln(1-x)=2\sum_{k=0}^\infty \frac{x^{2k+1}}{2k+1}$? I am not sure if this is right and how can I proceed from there?","['integration', 'logarithms', 'analysis', 'real-analysis']"
2889818,$a<b(b+2)$ then $f(a)< 2f(b).$,"I am looking for a positive continuous function $f$ such that for all positive $a,b>0$ $$a < b(b+2)\Longrightarrow f(a)<2f(b)$$ and $$a=b(b+2)\Longrightarrow f(a)=2f(b).$$ Does such a function exist? I tried to constructing one using exponential functions, as they are positive, but I failed.","['elementary-number-theory', 'analysis', 'real-analysis', 'linear-algebra', 'functional-analysis']"
2889822,Number of labelled trees with exactly 3 leaves,"I have seen some relevant questions here about that matter [1] , [2] but I am getting a different result and I cannot understand if I am wrong. So the question is: Find the number of labelled trees on $n\geq 4$ vertices that have exactly $3$ leaves. This problem can be translated as follows: From the Prüfer code we want to count the number of codewords in which exactly $n-3$ different numbers appear. We know that a Prüfer code for $n$ vertices will have a length of $n-2$ . So we have to place $n$ items in $n-3$ positions without repetitions and this can be done in $\frac{n!}{(n-3)!}$ times their permutations ( $(n-3)!$ ) and then we have 1 position to choose from $n-3$ numbers (because we have $3$ leaves) and therefore $\binom{n-3}{1}$ ways to fill that position. So in total we have $\frac{n!(n-3)!(n-3)!}{(n-3)!(n-4)!}=n!(n-3)$ trees with exactly three leaves. Am I missing something in my enumeration?","['graph-theory', 'trees', 'combinatorics', 'permutations']"
2889845,"Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? [duplicate]","This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 4 years ago . To solve the following problem Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? I tried $1\cdot\frac12\cdot\frac12$ where $1$ is the probability for the first coin that shows tails, and $\frac12$ is the probability for the other two coins that can be heads or tails. This answer does not match the expected one. Where am I wrong?",['probability']
2889855,"Calculate, $f\bigg(\frac{1}{1997}\bigg)+f\bigg(\frac{2}{1997}\bigg)+f\bigg(\frac{3}{1997}\bigg)\ldots f\bigg(\frac{1996}{1997}\bigg)$ [duplicate]","This question already has an answer here : find $f(\frac{1}{2014})+f(\frac{2}{2014})+.....+f(\frac{2013}{2014})$ of $f(x)=\frac{2}{2+4^x}$ (1 answer) Closed 5 years ago . If $$f(x)=\frac{4^x}{4^x+2}$$ Calculate, $$f\bigg(\frac{1}{1997}\bigg)+f\bigg(\frac{2}{1997}\bigg)+f\bigg(\frac{3}{1997}\bigg)\ldots
 f\bigg(\frac{1996}{1997}\bigg)$$ My Attempt: I was not able to generalise the expression or get a solid pattern, so I started with smaller numbers and calculated, $$f\bigg(\frac{1}{2}\bigg)=\frac{1}{2}$$ $$f\bigg(\frac{1}{3}\bigg)+f\bigg(\frac{2}{3}\bigg)=1$$ $$f\bigg(\frac{1}{4}\bigg)+f\bigg(\frac{2}{4}\bigg)+f\bigg(\frac{3}{4}\bigg)=\frac{3}{2}$$ I could see that, $$f\bigg(\frac{1}{n}\bigg)+f\bigg(\frac{2}{n}\bigg)+f\bigg(\frac{3}{n}\bigg)\ldots
 f\bigg(\frac{n-1}{n}\bigg)=\frac{n-1}{2}$$ So,  $$f\bigg(\frac{1}{1997}\bigg)+f\bigg(\frac{2}{1997}\bigg)+f\bigg(\frac{3}{1997}\bigg)\ldots
 f\bigg(\frac{1996}{1997}\bigg)=998$$ which is indeed the right answer. But I am not satisfied with my method. How else can I solve it?","['calculus', 'functions']"
2889868,$-3$ is a quadratic residue iff $p \equiv 1 \pmod 3$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question So this is the question:
Let $p$ be an odd prime, prove that $-3$ is a quadratic residue modulo $p$ iff $p \equiv 1 \pmod 3$. My idea was:
$$\left(\frac{-3}{p}\right) = \left(\frac{-1}{p}\right)\cdot \left(\frac{3}{p}\right)$$ also: 
$$\left(\frac{-3}{p}\right)= (-3)^a$$
when $a$ stands for  $\frac{p-1}{2}$. No idea how to continue... I would appreciate any help. Thanks!","['number-theory', 'quadratic-residues', 'legendre-symbol']"
2889876,"Does there exist $a_0$, such that $\{a_n\}_{n=0}^{\infty}$ is unbounded?","Suppose $\{a_n\}_{n=0}^{\infty}$ is a sequence, defined by the recurrence relation $$
a_{n+1} = \phi(a_n) + \sigma(a_n) - a_n,
$$ where $\sigma$ denotes the divisor sum function and $\phi$ is Euler's totient function. Does there exist $a_0$ such that the corresponding $\{a_n\}_{n=0}^{\infty}$ is unbounded? As $\phi(a_n) + \sigma(a_n) \geq 2a_n$ (see here: Is $\phi(n) + \sigma(n) \geq 2n$ always true? ), every sequence of this type is monotonically non-decreasing. This means that it is bounded iff it contains an element $a_n$ such that $\phi(a_n) + \sigma(a_n) = 2a_n$ . We know, that to satisfy this equation, $a_n$ must either be $1$ or prime (see: Find all positive integers $n$ such that $\phi(n)+\sigma(n)=2n$ . ). Thus, the question is equivalent to: ""Does every such sequence $\{a_n\}_{n=0}^{\infty}$ with $a_0 \geq 2$ contain a prime element?"". And I do not know how to proceed further. Any help will be appreciated.","['number-theory', 'elementary-number-theory', 'recurrence-relations', 'totient-function', 'divisor-sum']"
2889884,"Formalize the notion that ""$A$ has no relevant information about $X$ that $B$ doesn't have"" in probability theory","Assume a probability space $(\Omega, \mathcal B, \mathbb P)$ . Assume two $\sigma$ -algebras on $\Omega$ : $A,B$ , that represent information about $\Omega$ . Consider some random variable $X:\Omega\to O$ . How do we formally state the notion that "" $A$ has no relevant information about $X$ that $B$ doesn't have""? I at first thought that we could represent this by $$\forall x\in O, \quad\mathbb P (X=x|BA)= \mathbb P (X=x|B)$$ But then I realized that this is a necessary but not sufficient condition for the desired intuitive notion: It can be that $A$ DOES contain relevant information in the sense that $A$ consists of $2$ ""observations"" that exactly balance each other out so as to leave the conditional distribution unchanged. For example, if $X$ denotes whether the $9$ th coin flip of a possibly unfair coin is heads or not, and $B$ contains no information, and $A$ contains the information that half of the first $8$ were heads, (and the prior was 50%), then $\forall x\in \{H,T\}, \quad\mathbb P (X=x|BA)= \mathbb P (X=x|B)$ , but it is not the case that the observations were ""irrelevant"", in an intuitive sense. EDIT : Probably this has to be done by some kind of subset condition on sigma algebras?",['probability-theory']
2889898,Convergence of $\sum_{n=1}^\infty \frac{1}{n^{a_n}}$,"Let $\lim _{n\to\infty}a_n=l$. Show that $\sum_{n=1}^\infty \frac{1}{n^{a_n}}$ converges if $l>1$ and diverges if $l<1$. What happens if $l=1$? I tried to use the ratio test, but could not get a good estimate, I have difficulties, that there is the series $a_n$ involved. I know that $\sum_{n=1}^\infty \frac{1}{n^p}$ converges if $p>1$ and diverges if $p\geq 1$ but I am not sure how to use this exactly. For $l=1$, I guess both things could happen? Definitely, we can take $a_n=1$ for all $n$ and then we get the harmonic series which is divergent. Is there an example where the series converges?","['convergence-divergence', 'sequences-and-series', 'analysis', 'real-analysis']"
2889909,Is $\frac{1-z}{|1-z|}$ is holomorphic in $|z|<1$?,"Let $f(z) = \frac{1-z}{|1-z|}$ with $z\in\mathbb{C}$ such that $|z|< 1$. I want to know whether $f(z)$ is holomorphic in $|z|<1.$ Write $\frac{1-z}{|1-z|}=e^{i\arg(1-z)}$, where $\arg$ denotes the principal argument (from $-\pi$ to $\pi$). Then $$f(z)=e^{i\arg(1-z)}.$$
I know $e^w$ is an entire function of $w$. So it suffices to see if $\arg(1-z)$ is holomorphic in $|z|<1.$ Is this true?","['complex-analysis', 'complex-numbers']"
2889914,Problem with simply connected 3D domains,"I was going through this website . I am not understanding the definition of a simply connected domain, it says ""A simply connected domain is a path-connected domain where one can continuously shrink any simple closed curve into a point while remaining in the domain "" I thought I understood it and my understanding went well with the bellow 2D domains: I can understand that a closed loop path can be shrunk to a point and still be in the domain for the left figure but not for the right one because if it's shrunk to a point then it will breach the inner boundary and form a point inside the inner boundary, which is not in the domain. (Please correct me if my understanding is wrong) But now when I see the bellow 3D domains, I get confused. I don't understand why the $2^{nd}$ figure (A sphere having a hollow spherical region) from the left is simply connected . There is a small hollow sphere ( out of domain region) at the centre so if I try to shrink a closed curve (not just any curve but a big circle with radius 99% of the radius of the sphere which is enclosed in the sphere) won't it shrink to a point that's inside the hollow sphere (which is out of the domain)? Note : The 3D figures with the caption ""Non-simply connected"" have holes that are drilled all the way through.",['complex-analysis']
2889929,Find limit $x\rightarrow0$ of $f(x)=x^2\cdot\left({\sin{\frac 1 x}}\right)^2$,"I have following function: $$f(x)=x^2\cdot\left({\sin{\frac 1 x}}\right)^2$$ I want to find the limit of the function for $x\rightarrow0^\pm$. First I analyze $\frac 1 x$: $\frac {1}{x}\rightarrow +\infty$ for $x\rightarrow0^+$ but the $\sin$ of infinity does not exist. Then I use the comparison theorem (I don't know how it's called in English) and conclude that, because $$\left|{x^2\left({\sin{\frac 1 x}}\right)}^2 \right| \le \frac{1}{x^2}\rightarrow0^+$$ therefore the initial function tends to $0$. Is this reasoning correct? Are there better ways?",['limits']
2889931,"UMVUE of $\frac{\theta}{1+\theta}$ and $\frac{e^{\theta}}{\theta}$ from $U(-\theta,\theta)$ distribution","Let $X_1,X_2,\dots, X_n$ be rvs with pdf:
  $$f(x\mid \theta)=\frac{1}{2\theta}I(-\theta<x<\theta)$$ Find UMVUE of $(i)\dfrac{\theta}{1+\theta}$ and $(ii)\dfrac{e^{\theta}}{\theta}$. Note that, $(X_{(1)},X_{(n)})$ is complete sufficient statistic. But now I have to find unbiased estimator of $(i),(ii)$ of the form $g(X_{(1)},X_{(n)})$, then $g$ will become UMVUE. But I could not find such $g$. Thanks for any help. I tried to find $E(X_{(1)}/X_{(n)})$, but it came out a total mess. Here $X_{(1)}=\min(X_1,X_2,\dots, X_n)$ and $X_{(n)}=\max(X_1,X_2,\dots, X_n)$.","['statistical-inference', 'statistics', 'probability-distributions', 'parameter-estimation', 'order-statistics']"
2889952,Integer solutions to a particular degree 2 equation,"Let $q>5$ be an odd sum of two nonzero squares and consider the equation $$X^2-mkX+m\frac{qk+1}{4}=0$$ for some integers $m\ge 1$ and $7\le k\equiv 3\pmod{4}$ depending on $q$ . The condition on $k$ of course is so that the fraction is an integer. After running some test, it seems like The equation has integer solutions for some $m,k$ if and only if $q$ is not a square. This equation comes from trying to write a particular continued fraction as a sum of two unitary fractions, but the background is not really important here. Does anyone have any idea of how to start attacking this problem? From the numerical tests, it doesn't look like there is an obvious way to explicitly compute $m,k$ from $q$ ; so (assuming the claim is true) I am expecting a non constructive approach or method.","['number-theory', 'elementary-number-theory']"
2890005,"Functional equation $ f \big( f ( x ) - 2 y ) = 2 x - 3 y + f \big( f ( y ) - x \big) $ - not so trivial, or is it?","Consider the following functional equation: $$ f \big( f ( x ) - 2 y ) = 2 x - 3 y + f \big( f ( y ) - x \big) $$ for all real $ x $ and $ y $ . Find $ f $ . It is easy to observe that the only polynomial solution of the FE is $ f ( x ) = x $ . However, I haven't been able to prove that $ f ( x ) = x $ is the only solution. How do I prove or disprove it? In fact, what's the best way to approach the above functional equation? A rather general solution and less guesswork would be appreciated. Thanks a lot!","['functional-equations', 'calculus', 'functions']"
2890009,All norms of $\mathbb R^n$ are equivalent,"1) First, all $\|x\|_p=\sqrt[p]{|x_1|^p+...+|x_n|^p}$ are equivalent. In my course, they used Hölder inequality, i.e. that $$\|x\cdot y\|_1\leq \|x\|_p\|x\|_q$$ for $p,q\geq 1$ s.t. $\frac{1}{p}+\frac{1}{q}=1$ . But can I do as follow : Let $1\leq p<\infty $ . I denote $\|x\|_\infty =\max\{|x_1|,...,|x_n|\}$ . Then, $$\|x\|_\infty ^p\leq |x_1|^p+...+|x_n|^p\leq n\|x\|_\infty^p ,$$ and thus $$\|x\|_\infty \leq \|x\|_p\leq n^{1/p}\|x\|_\infty .$$ Therefore, if $1\leq r,p <\infty $ , then $$\|x\|_p\leq C\|x\|_\infty \leq C\|x\|_r\leq Cn^{1/r}\|x\|_\infty \leq Cn^{1/r}\|x\|_p.$$ Therefore, $\|\cdot \|_p$ and $\|\cdot \|_r$ are equivalent. Question 1: Does it work ? (then no need Hölder?) 2) All norms of $\mathbb R^n$ are equivalent. Let $N$ a norm. Question 2: By what I did previously, I just need to prove that $N$ is equivalent to $\|\cdot \|_\infty $ to conclude that all norm are equivalent, true ? To do it I tried as follow : $$N(x)=N(x_1e_1+...+x_ne_n)\leq |x_1|N(e_1)+...+|x_n|N(e_n)\leq \|x\|_\infty (N(e_1)+...+N(e_n)),$$ where $e_i=(0,...,0,1,0,...,0)$ where $1$ is at the $i-$ th position. Question 3: How can I show that $ N(x)\geq C\|x\|_\infty$ ?","['normed-spaces', 'real-analysis']"
2890024,Bounds of rotated egg?,"I'm attempting to find the bounding box for a rotated egg shape without resorting to interpolation if at all possible.  In researching this I've come across this link which lists useful equations for plotting the $(x, y)$ coordinates of an egg shape as: \begin{align*}
  x &= \frac{r((c-2) \cos \theta + c + 2)(\cos \theta + 1)}{4}, \\
  y &= r \cdot \sin \theta.
\end{align*} But if I were to normalize it to the centerpoint of the circular area—$(0, 1)$ in the image below, then rotate it by some arbitrary angle about that new centerpoint­—how can the $x$ and $y$ bounds be found without interpolation?","['trigonometry', 'geometry']"
2890069,If $f(x) =\frac{1}{3} ( \frac {5}{f(x+2)}+f(x+1))$ then $\underset{x \to \infty}{\lim}f(x) = ?$,If $f(x) =\frac{1}{3} ( \frac {5}{f(x+2)}+f(x+1))$ and $f(x) > 0$ for all $x \in \mathbb R$    then $\underset{x \to \infty}{\lim}f(x) = ?$ can anyone please give me a hint to find it? I know how to find the limit when the limit exists. But I have no idea how to prove it's existence.,"['limits', 'functions', 'limits-without-lhopital']"
2890112,"Continuous, proper, injective map into first-countable space is homeomorphism onto image","Theorem: Let $X, Y$ be topological spaces where $Y$ is first-countable and Hausdorff and let $f: X\rightarrow Y$ be an injective, continuous map which is proper. Then $f$ is a homeomorphism into it's image. Proof: The only thing left to show is that $f^{-1}: f(X) \rightarrow X$ is continuous. Since $Y$ is first-countable the subspace $f(X) \subseteq Y$ is first-countable too. In particular $f(X)$ is a compactly generated space. Therefore it is enough to show that for each compact subset $K\subseteq f(X)$ the restriction $f^{-1}|_K: K\rightarrow f^{-1}(K)$ is continuous. As a compact subset of $f(X)$ the set $K$ is also compact in $Y$. Since $f$ is proper $f^{-1}(K)\subseteq X$ is compact. So $f|_{f^{-1}(K)}: f^{-1}(K) \rightarrow K$ is a continuous and bijective map on a compact space into a Hausdorff space. It is well-known that this already implies that $f|_{f^{-1}(K)}$ is a homeomorphism. In particular the inverse function $f^{-1}|_K: K\rightarrow f^{-1}(K)$ is continuous. This proves the theorem. Is this proof correct?","['general-topology', 'compactness']"
2890139,Completing the space of series so there is a slowest converging series,"It is well known that there is no slowest converging infinite series (see e.g. here ). But there is also no largest rational number whose square <=2. Once we complete the rationals to the reals, such a number exists. Looking at the standard examples of series that diverge ever more slowly: ${1\over n}, {1 \over {n \ log(n)}}, {1\over{n \ log(n) \ log(log(n))}} ... $ you get the feeling that these are tending towards something , even if this something is not itself a series, or it is not a limit in the usual sense. Is there some notion of completion of the space of infinite sequences, so that some member of the larger space lies exactly at the border of convergence and and divergence? Edit : One possible way to do this would be via nonstandard analysis. Hyperreals are equivalence classes of sequences, and are totally ordered - i.e. they provide a way to say whether any sequence is larger than any another. So one might expect to find a ""boundary"" between sequences whose sum converges, and sequences whose sum does not converge. Specifically, you would totally order non-negative series by comparing the hyperreals defined by their partial sums $A_n = \sum_{m=1}^n a_m$. This order would respect convergence, in the sense that a divergent series could not be ""less than"" a convergent series, and would also respect convergence speeds, in the sense that if $a_n$ would be less than $b_n$ if $A_n/B_n \to 0$. However the hyperreals are not complete , so there need be no supremum to the set of sequences whose sum converges. It is possible to complete them , but the question then becomes what sort of objects are these completed hyperreals, and can we gain any intuition from them about our original question concerning convergent and divergent series. I found a related previous question . But no complete answer.","['nonstandard-analysis', 'asymptotics', 'real-analysis', 'functional-analysis', 'sequences-and-series']"
2890142,principal curvature in high dimensions,"The principal curvature of a 2D (m=2) manifold in a 3D (n=3) ambient Euclidean space, is given by the eigenvalues of the second fundamental form (or the Hessian matrix) $\Pi \in \Re^{m \times m}$ at each point of the surface. The principal directions are the corresponding eigenvectors. I'm looking for the generalization of this for higher dimensions of both the manifold and its ambient space (i.e., both $m$ and $n$). According to wikipedia the eigenvectors of the second fundamental form of a hypersurface can give us the principal directions, and therefore the generalization is straight-forward. However, this seems to hold only if $n = m+1$, because otherwise the hypersurface has a normal hyperplane rather than a normal vector , and the second fundamental form will be a 3D array $\Pi \in \Re^{m \times m \times (n-m)}$, rather than a matrix. In this case, what is the generalization of principal (directions of) curvatures, and how do we calculate them?","['curvature', 'tensor-decomposition', 'riemannian-geometry', 'differential-geometry']"
2890165,Find the partial derivative of a weighted sum function,"I am a high school student who is having problems understanding a resource which I am using for a research project. I basically am trying to get a derivative of a weighted sum function in relation to a particular value of weight (particular index of the wjk matrix). $W_{jk}$ is a specific index in a matrix so can be thought of as a numerical value. $$\frac{\partial}{\partial W_{jk}}\left(\sum_{j}W_{jk}\cdot O_j\right)$$ My resource states that $O_j$ is the derivative. I think because we are looking at the derivative of the function output in relation to a specific index ($W_{jk}$), the summation can be ignored/dropped as it takes in values which as I understand, don't influence how the particular index ($W_{jk}$) changes the function output. Or this is at least how I understand it (the book explains the removal of another summation in a similar way). My resource gives and answer but doesn't explain the process so I am left scratching my head. I would appreciate any help!","['partial-derivative', 'summation', 'derivatives']"
2890187,How to find the analytical representation of eigenvalues of the matrix $G$?,"I have the following matrix arising when I tried to discretize the Green function， now to show the convergence of my algorithm I need to find the eigenvalues of the matrix $G$ and show it has absolute value less than 1 for certain choices of $N$. Note that the explicit formula for entry $(i,j)$ is $-i(N+1-j)$ when $i\le j$ and it is symmetric, so we can get the formulas for $i>j$ by interchanging $i$ and $j$ in the $i\le j$ case. Any one has any ideas about how to find the analytical representation of eigenvalues of the matrix $G$, i,e, the eigenvalues represented by $N$? Thank you so much for any help! $\begin{pmatrix}
 - N & - N + 1 & -N+2 & -N+3 &\ldots & 1(-2) & 1(-1) \\
 - N + 1 & 2( - N + 1) & 2(-N+2) & 2(-N+3) &\ddots & 2(-2) & 2(-1) \\
 - N + 2 & 2( - N + 2) & 3(-N+2) & 3(-N+3) &\ddots & 3(-2) & 3(-1) \\
 - N + 3 & 2( - N + 3) & 3(-N+3) & 4(-N+3) &\ddots & 4(-2) & 4(-1) \\
 \vdots & \vdots & \ddots & \vdots & \vdots \\
 - 2 & 2(-2) & 3(-2) & 4(-2) &\ddots & ( - 1 + N)( - 2) & ( - 1 + N)( - 1) \\
 - 1 & 2(-1) & 3(-1) & 4(-1) &\ldots & ( - 1 + N)( - 1) & N( - 1) \\
\end{pmatrix}$","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
2890214,A cable of 80 meters (m) is hanging from the top of two poles that are both 50 m from the ground. What is the distance between the two poles,"Hey guys I ran accross this problem while watching a YouTube video. A cable of $80$ meters (m) is hanging from the top of two poles that are both $50$ m from the ground. What is the distance between the two poles, to one decimal place, if the center of the cable is: (a) 20 m above the ground? And yes, I did come across a solution involving hyperbolic trig but that's not what I am interested in. I am interested in figuring out another way to solve this problem that does not involve using $sinh$. I am thinking that we can assume that this is a parabola because clearly there is a vertex there is symmetry. Is this assumption correct? Am I going to get anywhere with this assumption?","['trigonometry', 'calculus', 'algebra-precalculus']"
2890249,Surjective closed morphism of schemes induces inequality of dimensions,"Let $f: Y\to X$ be a surjective closed morphism of schemes. Prove
  $\dim Y\geq \dim X$. I was made to believe that this should be easy, but I somehow did not manage to prove this. Using the fact that $f$ is closed and surjective, it is easy to reduce this to the case where both $X$ and $Y$ are irreducible. Now, if both were (locally) of finite type over a field, then the inequality would follow from the fact that the morphism induces an extension of the function fields. In the general case, however, I did not manage to produce a proof. Clearly it would be enough to prove the following lemma: Let $f:Y\to X$ be a closed morphism of schemes. Then for any $y\in Y$ and any generization $x_0$ of $x=f(y)$ there is a generization $y_0$ of $y$ with $f(y_0)=x_0$. This lemma is true in the case where $f$ is an open morphism, but I don't know whether it is true in the closed case as well. At any rate, I also failed to prove this so far. Any input on this problem would be highly appreciated, especially as I suspect that I am making things unneccessarily complicated right now.",['algebraic-geometry']
2890291,Is it possible to isolate and thereby by integration compute a zeta zero gap when accentuating the zeros and counting them?,"The starting point is this integrable formula for the von Mangoldt function: $$\Lambda(n)=\lim\limits_{s \rightarrow 1} \zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{(s-1)}}$$ We can plot the Dirichlet series: $$f(N,t)=\Re\left(\zeta(1/2+it)\sum\limits_{\substack{n=1 \\ d|n}}^{N} \frac{\mu(d)}{n \cdot t \cdot d^{1/2+it-1}}\right)$$ on the critical line: where the red curve is: $$g(N,t)=\frac{H_{\text{N}}+\frac{\partial \vartheta (t)}{\partial t}}{t}$$ where $\vartheta (t)$ is the Riemann-Siegel theta function, and $H_{\text{N}}$ is a Harmonic number. Dividing the Dirichlet series with the asymptotic we get: $$\frac{f(N,t)}{g(N,t)}$$ Part of the question is if this division with $g(N,t)$ can be avoided and the then possibly integrable function later still can be achieved. Now consider the integrable (zeta zero) counting function: which was generated by integrating the Euler-Maclaurin formula over the Möbius $\mu(d)$ function of the divisors of $n$ and adding Riemann-Siegel theta $\vartheta(t)$ as R. Manzoni does: $$N(t)=\frac{1}{\pi}\left(\vartheta (t)-\Re\left(\sum _{n=1}^{\text{nn}} \frac{1}{n^c} \left(\underset{d \mid n}{\sum\limits_{d=1}^{n}} \left(f(\frac{1}{2}+it, d)-f(\frac{1}{2}+i0, d) \right)\right)\right)\right)$$ where: $$f(s,d)=-i \mu (d) \left(\sum _{n=0}^{q-1} \left(\sum _{i=0}^{2 n+1} -\frac{d B_{2 (n+1)} k^{-2 n-1} \left|S_{2 n+1}^{(i)}\right| \log ^{-i-1}(d k) \Gamma (i+1,s \log (k d))}{(2 (n+1))!}\right)+\sum _{n=2}^k -\frac{d^{1-s} n^{-s}}{\log (d)+\log (n)}+\text{If}\left[d=1 \text{ then } 0\text{ else }-\frac{1^{-s} d^{1-s}}{\log (d)+\log (1)}\right]+\frac{d^{1-s} k^{-s}}{2 (\log (d)+\log (k))}+\text{Ei}(-(s-1) \log (d)-(s-1) \log (k))\right)$$ If something was lost in translation then the correct formula is found in the Mathematica program here at the end of this answer . And $c=1$. Now as already pointed out by H.M. Edwards in his book, the analytic continuation of the above is: $$N(t)=\frac{\vartheta (t)}{\pi }+\frac{\Im\left(\log \left(\zeta \left(i t+\frac{1}{2}\right)\right)+i \pi \right)}{\pi }$$ But as far as I know $\log (\zeta(s))$ is not integrable, which is what this whole question is about. Anyways for faster computation I will use the analytic continuation to produce the following plot: The (Mathematica) program for this plot is: (*Mathematica start*)
scale = 600;(*scale=5000 gives the plot below*)
Print[""Counting to 60""]
f[t_] = D[RiemannSiegelTheta[t], t];
Monitor[g1 = 
  ListLinePlot[
   Table[Re[
     1/(f[t] + HarmonicNumber[scale])*Zeta[1/2 + I*t]*
      Total[Table[
        Total[MoebiusMu[Divisors[n]]/
           Divisors[n]^(1/2 + I*t - 1)]/(n), {n, 1, scale}]]*(-1)^
       Round[RiemannSiegelTheta[t]/Pi + 
         Im[Log[Zeta[1/2 + I*t]] + I*Pi]/Pi]], {t, 0 + 1/1000, 60, 
     N[1/30]}], DataRange -> {0, 60}, PlotRange -> {-3.5, 3.5}, 
   PlotStyle -> {Thickness[0.004]}, ImageSize -> Large], Floor[t]]
(*end*) where (-1)^Round[
RiemannSiegelTheta[t]/Pi + Im[Log[Zeta[1/2 + I*t]] + I*Pi]/Pi]] is in latex: $$(-1)^{\text{Round}\left[\frac{\vartheta (t)}{\pi }+\frac{\Im\left(\log \left(\zeta \left(i t+\frac{1}{2}\right)\right)+i \pi \right)}{\pi }\right]}$$ Now it is not neccessary, and for the function to be integrable one must not add the Absolute Value function, but I do it here for beautification and clarity (which this question lacks - somewhat), like this: $$(-1)^{\left|\text{Round}\left[\frac{\Im\left(\log \left(\zeta \left(i t+\frac{1}{2}\right)\right)+i \pi \right)}{\pi }+\frac{\vartheta (t)}{\pi }\right]\right|}$$ By then changing the multiplying factor to: $$(-1/100000000)^{\left|\text{Round}\left[\frac{\Im\left(\log \left(\zeta \left(i t+\frac{1}{2}\right)\right)+i \pi \right)}{\pi }+\frac{\vartheta (t)}{\pi }\right]\right|}$$ I, with this program: scale = 150;(*scale=5000 gives the plot below*)
g = 1;
Print[""Counting to 60""]
f[t_] = D[RiemannSiegelTheta[t], t];
Monitor[g1 = 
   ListLinePlot[
    Table[Re[
      1/(f[t] + HarmonicNumber[scale])*Zeta[1/2 + I*t]*
       Total[Table[
         Total[MoebiusMu[Divisors[n]]/
            Divisors[n]^(1/2 + I*t - 1)]/(n), {n, 1, scale}]]*(-1/
          100000)^Abs[
         Round[-g + 1 + RiemannSiegelTheta[t]/Pi + 
           Im[Log[Zeta[1/2 + I*t]] + I*Pi]/Pi]]], {t, 0 + 1/1000, 60, 
      N[1/30]}], DataRange -> {0, 60}, PlotRange -> {-3.5, 3.5}, 
    PlotStyle -> {Thickness[0.004]}, ImageSize -> Large], Floor[t]];
g21 = Graphics[
   Rotate[{Text[
      N[Im[ZetaZero[If[g == 1, 1, g - 1]]]], {Im[
        ZetaZero[If[g == 1, 1, g - 1]]], -3/2}]}, Pi/2]];
g22 = Graphics[
   Arrow[{{Im[ZetaZero[If[g == 1, 1, g - 1]]], -1}, {Im[
       ZetaZero[If[g == 1, 1, g - 1]]], -1/7}}]];
g31 = Graphics[
   Rotate[{Text[N[Im[ZetaZero[g]]], {Im[ZetaZero[g]], -3/2}]}, Pi/2]];
g32 = Graphics[
   Arrow[{{Im[ZetaZero[g]], -1}, {Im[ZetaZero[g]], -1/7}}]];
Show[g1, g21, g22, g31, g32] plotted this: (the first zeta zero gap) and this: (the second zeta zero gap) and this: (the third zeta zero gap) Question What I am trying to say before I now go to bed is: Is it possible to construct an integrable function (maybe by not
  dividing with the red curve - the Riemann-Siegel theta and the
  Harmonic numbers) that gives the value of the $n$-th Riemann zeta
  zero gap? This since the zeta zero counting function is integrable and: Series[(-1)^x, {x, 0, 6}] gives: $$1+i \pi  x-\frac{\pi ^2 x^2}{2}-\frac{1}{6} i \pi ^3 x^3+\frac{\pi ^4 x^4}{24}+\frac{1}{120} i \pi ^5 x^5-\frac{\pi ^6 x^6}{720}+O\left(x^7\right)$$ $1/100000000$ is just a small number meant to go to zero (but never reaching it).","['riemann-zeta', 'number-theory', 'fourier-analysis', 'real-analysis']"
2890305,Close form for a sequence of integrals involving the Gamma function,"I'm trying to find a close form for these integrals (with $n\in\mathbb{N}$) :
$$\int_{0}^{1}\ln(\Gamma(x+1))\cdot x^n \, \text{d}x$$ Wolfram is able to give a close form for every specific value of n, and the result leads to believe there is indeed a pattern ; however it fails to find the general formulae for $n\in\mathbb{N}$. An integration by part turns it into similar-looking integrals involving the digamma function.
Do you think there is any way to find a close form, or is it a lost battle ?","['integration', 'gamma-function', 'real-analysis']"
2890379,Continuous function $f:\mathbb R\to \mathbb R$ such that $f(B)$ is not measurable for a Borel set $B$.,"1) I saw in a book that there are $\mathcal C^1(\mathbb R)$ function $f:\mathbb R\to \mathbb R$ such that $f(B)$ is not measurable for $B$ a Borel set. I don't really find such an example. Any idea ? 2) If $f$ is continuous, does $f(O)$ measurable for $O$ open or closed or that is even not correct ?","['measure-theory', 'real-analysis']"
2890383,How can the Neron-Tate height pairing be considered an intersection number?,"Given the Neron-Tate height $\hat h$ on an elliptic curve we defined the associated bilinear form:
$$\langle P,Q\rangle = \frac{1}{2} \bigl( \hat h(P+Q) - \hat h(P) - \hat h(Q) \bigr) $$
My professor offhandedly mentioned that this form can be considered a sort of ""intersection number"", or specifically when $P=Q$ a self-intersection number. The notation certainly seems to suggest it, but I can't immediately see why. How is Neron-Tate an intersection number?","['algebraic-geometry', 'elliptic-curves']"
2890426,Row-sum condition for Runge-Kutta methods,"Consider a general RK-method with weights $\vec{b}$ $(s\times 1)$ , nodes $\vec{c}$ $(s\times 1)$ and matrix $\vec{A}$ $(s\times s)$ . In the literature, there is a widely repeated minimum condition for consistency called the row-sum condition: $$c_i = \sum_{j=1}^{s}A_{ij}, $$ see e.g. Wikipedia . However, I have not been able to find any proof of this fact. Any ideas? The odd thing is that there seems to be another, just as fundamental, condition for consistency rarely mentioned, namely that $$\sum_{j=1}^{s}b_{j}=1.$$ Indeed, recall that the RK-method, for the equation $y'=f(t,y)$ , is defined by: $$Y_j' =  f(t_n+c_jh,Y_j), \ j = 1,...,s$$ $$Y_j = y_n+\sum_{k=1}^{s}A_{ik}hY_k', \ j=1,...,s$$ $$y_{n+1} = y_n + \sum_{j=1}^{s}b_jhY_j'$$ Taking exact data at $t_n$ and expanding to lowest order gives: $$Y_j' =  f(t_n+c_jh,Y_j)=f(t_n,y(t_n))+\mathcal{O}(h), \ j = 1,...,s$$ $$Y_j = y(t_n)+\mathcal{O}(h), \ j=1,...,s$$ $$y_{n+1}|_{\mathrm{exact}} = y(t_n) + \sum_{j=1}^{s}b_jhY_j'=y(t_n) + hf(t_n,y(t_n))\sum_{j=1}^{s}b_j + \ \mathcal{O}(h^2)$$ while $$y(t_{n+1}) = y(t_n+h) = y(t_n)+hy'(t_n) + \mathcal{O}(h^2) = y(t_n)+hf(t_n,y(t_n)) + \mathcal{O}(h^2), $$ showing that we must have $$\sum_{j=1}^{s}b_{j}=1$$ for consistency of order 1.","['numerical-methods', 'ordinary-differential-equations']"
2890432,Number of vertices of degree n not connected to vertices of degree 1,Imagine a tree made up only of vertices of degree 1 and vertices of degree $n$. Let $m$ be the number of vertices of degree 1 and $\frac{m-2}{n-2}$ be the number of $n$-vertices of the tree. How can I find the number of vertices not connected to a vertex of degree 1? I.e. the number of $n$-vertices connected only to other $n$-vertices.,"['graph-theory', 'combinatorics']"
2890435,Where does the symplectic structure on coadjoint orbits of Lie groups on their Lie algebras come from?,"I have read in several places that if $\Omega$ is the coadjoint orbit of $\zeta \in \mathfrak{g}^*$, the map from $G \to \Omega$ that sends $g \mapsto Ad^*(g)(\zeta)$ gives a surjection, and taking the differential of this map at the identity gives a surjection from $T_eG = \mathfrak{g} \to T_{\zeta}\Omega$, and then the $2$-form is defined by identifying elements of the tangent space with elements of $\mathfrak{g}$ and taking the Lie bracket. But a priori this only seems to define the $2$-form at $\zeta$, ie: $\omega(\zeta) (\hat{X}, \hat{Y})  = \zeta([X,Y])$ where $\hat{X},\hat{Y} \in T_\zeta \Omega$. But what about $\omega(\eta)$ for $\eta \in \Omega$ but $\omega \neq \zeta$? The surjection is from $\mathfrak{g} \to T_\zeta \Omega$, but not from $\mathfrak{g} \to T_{\eta}\Omega$.","['symplectic-geometry', 'lie-algebras', 'lie-groups', 'differential-geometry']"
2890441,Exercise from Harris Algebraic Geometry: Homogeneity Implies Smoothness?,"I'm rather confused by Exercise 14.13 in Harris's Algebraic Geometry , which asks the reader to prove that the Veronese and Segre varieties are smooth. The suggestion is that, 'given Exercise 14.3', this follows without calculation from the homogeneity of the defining equations. But Exercise 14.3 asks the reader to prove that the singular points of any variety form a proper subvariety. Surely this is a mistake? Exercise 14.3 seems unrelated, and the homogeneity of the defining equations does not seem sufficient by itself to prove smoothness.",['algebraic-geometry']
2890447,Construction G-Invariant Riemannian Metric,"Let $M$ be a smooth manifold and $G$ be a lie group acting transitively on $M$. I know by Corollary 1.27 of these notes that there to exist a Riemannian metric $g_G$ on $M$ satisfying the in-variance relation
$$
(\forall x,y \in M)(\forall g \in G)
\,g_G(x,y)=\,g_G(g\cdot x,g\cdot y)?
$$
When is this Riemannian metric unique?  How can it be contructed explicitly if $M$ is $\mathbb{R}^d$?","['group-actions', 'riemannian-geometry', 'lie-groups', 'differential-geometry']"
2890449,"Chern classes of tangent bundle over the Grassmannian G(2,4)","What are the Chern classes of the tangent bundle $\tau_G$ of the Grassmannian $G=G(2,4)$ of lines in $\mathbb{P}^3$? This is Exercise 5.37 on page 191 of 3264 & All That by Eisenbud and Harris. By Theorem 3.5, the tangent bundle $\tau_G$ is isomorphic to $\mathcal{S}^{*} \otimes \mathcal{Q}$, where $\mathcal{S}$ and $\mathcal{Q}$ are the universal sub and quotient bundles of $G$. From Section 5.6.2, we have $c(\mathcal{Q})=1+\sigma_{1}+ \cdots+ \sigma_{n-k}$ and $c(\mathcal{S}^{*})=1+\sigma_1+\sigma_{1,1}+\cdots+\sigma_{1,1,\dots,1}$. I found the following formulas here ( https://stacks.math.columbia.edu/tag/02UK ) for the first two Chern classes of a tensor product of vector bundles $\mathcal{E}$ and $\mathcal{F}$ which are finite locally free of ranks $r,s$. 
$$ c_1(\mathcal{E} \otimes \mathcal{F})=rc_1(\mathcal{F})+sc_1(\mathcal{E})$$ 
$$ c_2(\mathcal{E} \otimes \mathcal{F})=r^2c_2(\mathcal{F})+rsc_1(\mathcal{F})c_1(\mathcal{E})+s^2 c_2(\mathcal{E}).$$ 
So I think the first two Chern classes are
$$ c_1(\tau_G)=2\sigma_1+2\sigma_1=4\sigma_1$$ 
$$c_2(\tau_G)=4\sigma_2+4\sigma_2\sigma_{1,1}+4\sigma_{1,1}=4(\sigma_2+\sigma_{1,1}),$$
but I haven't been able to find a formula for $c_3$.","['grassmannian', 'algebraic-geometry', 'intersection-theory', 'characteristic-classes']"
2890451,How to correctly express a variable with two solutions?,"Say we have $(x+1)(x+2) = 0$.
So possible solutions of $x$ are $x=-1$, and $x=-2$; Would it be considered correct syntax to say ""$x = -1, -2$"" ?",['discrete-mathematics']
2890469,A compact complex manifold admits an ample line bundle if and only if it is projective,"Given a holomorphic line bundle $L$ on a complex manifold $X$, a point $x\in X$ is called a base point of $L$ if $s(x)=0$ for all $s\in H^0(X,L)$ (the space of global holomorphic sections of $L$). The base locus $\operatorname{Bs}(L)$ is the set of all base points of $L$. Given a basis $s_0,\dots,s_N$ of $H^0(X,L)$, one can define a map
\begin{equation}
\phi_L:X\backslash\operatorname{Bs}(L)\rightarrow \mathbb{CP}^n
\end{equation}
sending a point $x$ to $[s_0(x):\dots:s_N(x)]$. This is well-defined, since not all $s_i(x)$ are zero (we exclude $\operatorname{Bs}(L)$ in the domain) and since changing trivialisation scales all components $s_i(x)$ by the same amount. I am told that the line bundle $L$ is called very ample if for any such basis, the associated map $\phi_L$ is an embedding. $L$ is called ample if there exists a positive integer $m_0$ such that $L^m$ is very ample for all $m\geq m_0$. In Huybrechts' book Complex Geometry, he says that by definition, a compact complex manifold is projective (i.e. embeds as a complex submanifold of $\mathbb{CP}^n$) if and only if it admits an ample line bundle. But I do not understand how this follows? Do we not only get an embedding of $X\backslash \operatorname{Bs}(L)$ into $\mathbb{CP}^n$, rather than the whole of $X$? I would agree with this statement if $L$ was also assumed to be globally generated , i.e. satisfies $\operatorname{Bs}(L)=\emptyset$, but this is not assumed. Any help would be much appreciated!","['complex-geometry', 'vector-bundles', 'algebraic-geometry', 'differential-geometry']"
2890472,"$G$ acts on $\operatorname{Hom}(G,K)$ by conjugation","I am working on an example of the Drinfeld Double of the Group Algebra and stumbled upon the book On Characters of Finite Groups . My issue is with 8.1.1, page 192 of the PDF ( relevant part here ). It says: The Group $G$ acts on $\operatorname{Hom}(G,K) = \operatorname{Fun}(G,K)$ the $K$-valued maps from $G$ with conjugation: For $g \in G$ and $\varphi \in \operatorname{Fun}(G,K)$ we set $g.\varphi := g \varphi g^{-1}$, that is $(g.\varphi)(s) := \varphi(g^{-1}sg)$ for all $s \in G$. For me it seems that there are two different definitions for the action which gets me confused ($(g.\varphi)(s) := \varphi(gsg^{-1})$ and $(g.\varphi)(s) := \varphi(g^{-1}sg)$). I do not think that it is an error in the book as the author states $(g.\varphi)(s) := \varphi(g^{-1}sg)$ again somewhere else. What is meant with $g.\varphi := g \varphi g^{-1}$? If I try to check that $(g.\varphi)(s) := \varphi(g^{-1}sg)$ is an action, I encounter a problem: \begin{align*}
(g.(h.\varphi))(x) &= g. \varphi (h^{-1}xh) = \varphi ( g^{-1}h^{-1}xhg) \\
&= \varphi ((hg)^{-1}xhg) = (hg).\varphi (x)
\end{align*}
which is not $(gh).\varphi(x)$ for all $x \in H$.","['group-actions', 'group-theory', 'functions']"
2890489,A question about Bochner's theorem.,"I am studying Fourier analysis and finding two Bochner's theorem: Bochner's theorem VERSION  $1$ : In order that a function $f:\mathbb{R}^d\rightarrow \mathbb{R}$ be positive definite and continuous, it is necessary and sufficient that it be the Fourier transform of a nonnegative finite-valued Borel measure on $\mathbb{R}^d$. [In Cheney's book---A course in approximation theory] VERSION  $2$ :   Let $f:\mathbb{R}^d\to \mathbb{R}$ be a bounded and continuous function on $\mathbb{R}^d$. Then $f$ is a positive semi-definite function on $\mathbb{R}^d$ if and only if there is a probability measure $\mu$ on $\mathbb{R}^d$ such that
$$ f(x) =f(0) \int_{\mathbb{R}^d} e^{2\pi i x\cdot \xi}\, d\mu(\xi),\   \ \forall x\in \mathbb{R}^d.$$ [In my course note] My question is in the necessary parts of version 1 and 2. I am wondering whether they are same? or is there a relationship between them? In my understanding, VERSION $1$ says if $f$ is a positive definite then it be the Fourier transform of a Borel measure. But in VERSION  $2$ , it says if $f$ is a positive semi-definite then it be the inverse Fourier transform of a Borel measure(i.e. the probability measure in version 2). Thanks in advance!","['fourier-analysis', 'functional-analysis', 'positive-definite', 'real-analysis']"
2890502,Proving $V(x) = \frac{|y|^2-|x|^2}{|y-x|^N}$ is harmonic in $\mathbb{R}^N-\{y\}$,"$$V(x) = \frac{|y|^2-|x|^2}{|y-x|^N}$$ for fixed $y\in\mathbb{R}^n$, and $x\in\mathbb{R}^n-\{y\}$ I need to prove that this this is harmonic. That is, the sum of its second partial derivatives are $0$. Let's calculate them. $$\left(\frac{f}{g}\right)' = \frac{fg'-gf'}{g^2}$$ so: $$\frac{\partial V(x)}{\partial x_j} = \frac{(|y|^2-|x|^2)N|y-x|^{N-1}\frac{(-x_j)}{|y-x|} - |y-x|^N(-2|x|\frac{x_j}{|x|})}{|y-x|^{2N}} = \\\frac{-Nx_j(|y|^2-|x|^2)|y-x|^{N-2}+2x_j|y-x|^N}{|y-x|^{2N}}$$ so $$\frac{\partial^2 V(x)}{\partial x_j^2} = \frac{\left(-Nx_j(|y|^2-|x|^2)|y-x|^{N-2}+2x_j|y-x|^N\right)\left(2N|y-x|^{2N-1}\frac{(-x_j)}{|y-x|}\right)-|y-x|^{2N}\left(\cdots\right)}{|y-x|^{4N^2}}$$ where $\left(\cdots\right)$ is the derivative of $\left(-Nx_j(|y|^2-|x|^2)|y-x|^{N-2}+2x_j|y-x|^N\right)$. It has a product of three things, and another term. It's huge. Multiplied by the other things, it's even bigger. I think this is not the right way to solve this exercise. Is there a better way? If not, how can I do these giant calculations by hand? It's too already in the computer using LaTeX.","['partial-derivative', 'calculus', 'derivatives', 'partial-differential-equations']"
2890508,"$\mathbf{H}(3)$ is diffeomorphic to $\mathbf{SL}\left( 2,\mathbf{C}\right) \mathbf{/SU}\left( 2\right) $","I'm reading the book from Jensen's ""Surfaces in Classical Geometries"".
Could anyone help me understand why $\mathbf{H}(3)$ is diffeomorphic to $\mathbf{SL}\left( 2,\mathbf{C}\right) \mathbf{%
/SU}\left( 2\right) $? The following is a print.","['riemannian-geometry', 'hyperbolic-geometry', 'quotient-spaces', 'group-theory', 'differential-geometry']"
2890518,What am I doing wrong?- Differential equations and Integrals,"I am trying to find an equation for $\int x^x dx = h$ (I've not been told it's impossible... so I tried to... just to for fun) So we know that $f^{g(x)}(x) = h(x)$ where $g(x) = k$ (constant) so: $h'(x) = k \cdot f^{k-1} $ $x^x = h'(x) = k \cdot f^{k-1}(x)$ and thus:  $f(x) = (\dfrac{x^x}{c}) ^ {\dfrac{1}{c-1}}$ and if we substitude back ""f(x)"" we get: $h(x) = ((\dfrac{x^x}{c}) ^ {\dfrac{1}{c-1}})^{c} = (\dfrac{x^x}{c}) ^ {\dfrac{c} {c-1}}$ and we get that: $\int x^x dx = h(x) = (\dfrac{x^x}{c}) ^ {\dfrac{c}{c-1}}$ but it doesn't work out for let's say $c=2$ or $c=3$ ...  any ideas why? I am new to this field of maths.","['integration', 'ordinary-differential-equations']"
2890541,Does $\int_{0}^{1} (-1)^x dx$ have any geometric interpretation?,"I calculated the integral of this complex function $(-1)^x$: $$\int_{0}^{1}(-1)^x dx = \frac{(-1)^x}{\mathrm{Ln}(-1)}\bigg|_{0}^{1}=\frac{(-1)^x}{\ln|-1|+i\theta(-1)}\bigg|_{0}^{1}=\frac{(-1)^x}{i\pi}\bigg|_{0}^{1}=-\frac{2}{i\pi}=\frac{2i}{\pi}$$
This is the plot of $(-1)^x$: Does this value have any geometric meaning, like could be the area of something related to the graph multiplied by $i$? (Also, please verify my calculation. I used the principal branch of logarithm, but I am not sure if that is what I am supposed to do in this case). Thanks!","['complex-analysis', 'complex-integration']"
2890543,Is it correct to solve the equality this way?,"$\sinh(z)= i$ $\frac{e^z-e^{−z}}2 = i$ $e^z-e^{−z}= 2 i$ $e^z-2i-e^{−z} = 0$ $e^{z}(e^z-2i-e^{−z}) = 0$ $e^{z}= p$ ${p^2}-2ip-1=0\tag{1}$
Quadratic $(1)$ has solutions:
$$p_{1,2}= \left(\frac{2i+-\sqrt{(-2i)^2-4\cdot(-1)}}{2}\right)
= \frac{2i\pm\sqrt{-4+4}}{2}=i$$ $z \in \operatorname{Ln}{i}$ $z \in {\ln (1) + i (\frac{\pi}{2}+2k\pi)}$. Is this solution ok? Thank you","['complex-analysis', 'complex-numbers']"
2890579,Sum of Distinct Positive Integers Different from Sum of Any Combination of The Same Integers,"Let $\|\vec{x}\|_1$ represent the sum of the components (the L1 norm) of $\vec{x}$.
  Define
  $$A_n = \{\vec{x}:\vec{x}\in\mathbb{\mathbb{N}}^n, x_i\ne x_j \textrm{ for } i\ne j,\|\vec{x}\|_1\notin B(\vec{x})\},$$
  where 
  $$B(\vec{x}) = \left\{\sum_{i=1}^{n} a_ix_i: (a_1,\ldots,a_n)\in\mathbb{Z}^{n}_{\ge 0}-(1, 1, \ldots, 1)\right\}.$$
  Furthermore, let
  $$C_n=\{\vec{c}\in A_n:\|\vec{c}\|_1=\min_{A_n} \|\vec{a}\|_1\}.$$ Can we determine $C_n$? Forgive me if my notation is off, this seems to be a bit of a complicated problem. To explain in words, $A_n$ is the set of all vectors $\vec{x}$ with $n$ components where each component is a distinct positive integer satisfying the property that the sum of the components of each $\vec{x}$ cannot be formed by summing the components of any combination (with repetition) of the components of $\vec{x}$, excluding $\vec{x}$ itself, of course.  Hence, $C_n$ is set of vectors in $A_n$ having the smallest L1 norm. Through a brute force approach in Python, I found for $n=1, 2, 3, 4$: $C_1 = \{(1)\}$ $C_2 = \{(2, 3)\}$ $C_3 = \{(4, 6, 7)\}$ $C_4 = \{(8, 12, 14, 15)\}$ And I think the pattern that emerges is clear.  But can you mathematically prove that this pattern continues? Here's the Python code, for reference: https://www.onlinegdb.com/Sk9-TaQ8Q","['summation', 'vectors', 'proof-writing', 'combinatorics', 'discrete-mathematics']"
2890585,Differentiability of $f(x)={x^2\sin{(\dfrac{1}{x})}}$ at $x=0$ [duplicate],"This question already has answers here : Show that the function $g(x) = x^2 \sin(\frac{1}{x}) ,(g(0) = 0)$ is everywhere differentiable and that $g′(0) = 0$ (2 answers) Closed 5 years ago . I'm a bit confused here. When we take the derivative of 
$$f(x)=\begin{cases}
  x^2\sin{\biggl(\dfrac{1}{x}\biggr)}&x\neq0\\
  0 &x=0\\
\end{cases}
$$
It's derivative is not defined at $x=0$ as 
$f(x)=2x\sin{\biggl(\dfrac{1}{x}\biggr)}-\cos{\biggl(\dfrac{1}{x}\biggr)}$. However, approaching this problem through the limit form of the derivative gives the value of the derivative at $x=0$:
$$f'(x)=\lim_{h\to 0}\dfrac{f(x+h)-f(x)}{h}$$
$$\implies f'(0)=\lim_{h\to0}\dfrac{h^2\sin{\biggl(\dfrac{1}{x}\biggr)}-0}{h}=0$$ What I'm curious about here is why differentiating $f(x)$ first and then entering $x=0$ is failing in contrast to finding the derivative through limits?","['limits', 'derivatives']"
2890609,"Why the set $\{1\}$ is equal to the set $\{1,1,1\}$ ? A box with 3 equal elements is NOT the same as a box with only one of those elements.","Why the set $\{1\}$ is equal to the set $\{1,1,1\}$? A box with 3 equal elements is NOT the same as a box with only one of those elements. This just doesn't seems right, i can't explain it further than the title. I do know why there isn't multiplicity in sets due to the axiom of extensionality by the way, but that's not the point!","['elementary-set-theory', 'definition']"
2890617,The asymptotic expansion of an integral of an exponential function,"What is the asymptotic expansion of $f(x) := \int_0^1 e^{-x(1-u^2)}du$? The integrand steeply declines near $u=1$. I tried to transform $u$ into something that is suitable for the method of steepest descent, but have not found an appropriate transformation. Integration by parts has not yield a satisfactory result, perhaps due to I having not found the right components to integrate.","['asymptotics', 'real-analysis']"
2890631,Understanding a proof that the topologist's sine curve is not path connected.,"I have encountered a proof of the statement that the ""The Topologist's sine curve is connected but not path connected"" and I am not able to understand some part. Example 5.2.23 (Topologist’s Sine Curve-I). Let
  $$
  A := \{ (x, \sin(\pi/x)) : 0 < x \leq 1 \}
  \quad\text{and}\quad
  B := \{ (0,y) : -1 \leq y \leq 1 \}.
$$
  Let $X = A \cup B \subset \mathbb{R}^2$ be given the induced metric topology.
  We claim that $X$ is connected but not path connected. Let $\gamma \colon [0,1] \to X$ be a path joining $(0,0)$ to $(1,0)$.
  We write $\gamma(t) = (\gamma_1(t), \gamma_2(t))$.
  Since $B$ is closed in $X$, the inverse image $\gamma^{-1}(B)$ is closed, $0 \in \gamma^{-1}(B)$.
  Let $t_0$ be the least upper bound of this closed and bounded set.
  Obviously, $t_0 \in \gamma^{-1}(B)$.
  Note that $0 < t_0 < 1$.
  We claim that $\gamma_2$ is not continuous at $t_0$. For $\delta > 0$ with $t_0 + \delta \leq 1$ we must have $\gamma_1(t_0 + \delta) > 0$.
  Hence there exists $n \in \mathbb{N}$ such that $\gamma_1(t_0) < 2/(4n+1) < \gamma_1(t_0 + \delta)$.
  By the intermediate value theorem applied to the continuous function $\gamma_1$, we can find $t$ such that $t_0 < t < t_0 + \delta$ and such that $\gamma_1(t) = 2/(4n+1)$.
  Hence $\gamma_2(t) = 1$ and $|\gamma_2(t) - \gamma_2(t_0)| \geq 1$.
  We therefore conlude that $\gamma_2$ is not continuous at $t_0$. (Original images here and here .) My doubt here is whether if : $t_0$ is Sup{$\gamma^{-1}(B)$}, B={$(0,y)|-1\leq y\leq 1$} then
why $\gamma_2(t_0)<0$ as there is statment that $|\gamma_2(t)-\gamma_2(t_0)|\geq 1$ ?[I know that value of $\gamma_2(t)=1$ Any help will be appreciated.","['connectedness', 'path-connected', 'proof-explanation', 'real-analysis', 'general-topology']"
2890637,"Function $f:[0,1] \to [0,1]$ taking on each value in $[0,1]$ exactly twice","I want to find a function $f:[0,1] \to [0,1]$ such that $f$ takes on each value in $[0,1]$ exactly twice. I think this means there are an infinite number of discontinuities. Can anyone help me figure this one out? Anyone have any pointers?",['real-analysis']
2890730,Understanding uniform convergence of sequence,"Given $f_n(x)=(x-1)^{3n}$ on $(0,2]$ we can show point-wise convergence to the function
$$
f(x)=\begin{cases} 0&x\in(0,2)\\1&x\in\{2\}\end{cases}
$$
But how do I show that uniform convergence is not true? I've tried the following: For $x\in(0,2)$ we can show point wise convergence of $f_n(x)$ to $f(x)=0$ by observing that
$$
|(x-1)^{3n}|\le|x-1|^{3N}
$$
for all $n\ge N$. Let $N=\lceil\frac{1}{3}\frac{\log\epsilon}{\log|x-1|}\rceil$. For all $\epsilon>0$ we have that
$$
|(x-1)^{3n}|\le|x-1|^{3N}=\epsilon
$$
for all $n\ge N$. Since $N(x,\epsilon)$ is a function of $x$, $N$ is not chosen independently of $x$ and thus uniform convergence is not true on $(0,2]$.","['uniform-convergence', 'sequences-and-series']"
2890743,Convergence of measure,"Let $X_1,\dots,X_n$ be iid random variables with mean $\theta$ and variance 1. Let $F_n$ denote the distribution of $\sqrt{n}(\bar{X}-\theta)$, where $\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$. Let $\Phi$ denote the standard normal distribution. Are there sufficient conditions on the distribution of the $X_i$s so that $$\sup_g \left| \frac{\int g(x) dF_n(x)}{\int g(x) d\Phi(x)} - 1 \right| \to 0,$$ where the supremum is over all bounded functions on the interval $[0,1]$  (excluding the case $g=0$ $\Phi$-a.s.). Convergence in total variation seems not strong enough.","['measure-theory', 'probability-theory']"
2890761,Prove $|x - y|\le|x| + |y|$ (Spivak's Calculus Book),"I was doing this problem and I got stuck so much time, and then I conclude this. $$|x - y|\le|x| + |y| .$$ Then, square both sides $$|(x - y)(x - y)|\le(|x| + |y|)².$$ Since $(x - y)²$ is always positive, as well as $x²$ and $y²$, we get $$(x - y)²\le x² + 2|xy| + y².$$ Develop the product $$x² -2xy + y² \le x² + 2|xy| + y²$$ $$-2xy\le2|xy|$$ $$-xy\le|xy|$$ And this is true. I'd like to know if I did this correctly and If there's a smaller/easier proof because the problem is doing by a very short proof.","['algebra-precalculus', 'inequality']"
2890785,Name for the trivial extension of a single-variable real function to several variables,"This is a question about terminology. Is there any common name for the trivial extension of a real function $f \colon \mathbb{R} \to \mathbb{R}$ to several variables $\tilde{f} \colon \mathbb{R}^n \to \mathbb{R}^n$? By ""trivial extension"", I mean defining $\tilde{f}$ in terms of $f$ as $\tilde{f}(x_1, \dots, x_n) = (f(x_1), \dots, f(x_n))$. As a simple example, if we have a trigonometric function like $sin(x)$, we can trivially extend it to $\mathbb{R}^3$ as $\sin(x, y, z) = (\sin(x), \sin(y), \sin(z))$. I'm just wondering if there is any accepted name and well-known reference for this simple way of building multivariate functions.","['functions', 'terminology', 'reference-request']"
2890839,"Homeomorphism group of compact metric space $K$ is $G_{\delta}$ in $C(K,K)$","Let $(K,d)$ be a compact metric space and denote $\ C(K,K):=\{ f:K \to K \ ; \space f \space \text{is continuous}  \}$. Endow the set $C(K,K)$ with the supremum metric $\ \rho (f,g):=\mathrm{sup} \ \{ d(f(x),g(x)) \ ; \ x \in K \}$. I'd like to show that the group of homeomorphisms of $(K,d)$ is a $G_{\delta}$ subset of the metric space $( C(K,K),\rho)$. I managed to show that it is enough to prove that the set $\{ f \in C(K,K) \ ; \space f \space \text{is injective} \}$ is $G_{\delta}$, but then I got stuck. I'll appreciate any help.","['general-topology', 'metric-spaces']"
2890854,Do a specific inequality hold under integration?,"As we know that if  we have the inequality $f\leq g$, it does not imply $f'\leq g'$. Now Let  $f(x)\leq g(x)$ for each $x\in [a,b]$,
 where $0<a,b<\infty$. Is it possible to prove $$\int_{a}^{b} f'(x)dx\leq \int_{a}^{b}g'(x)dx$$ ,where $f$ denotes the derivative of $f$? Thanking you in advance.","['integration', 'inequality', 'derivatives', 'integral-inequality']"
2890891,"If $g$ solves $\sum\limits_{d|n}g(d) = \log n$, then $g(p^e)=\log p$ for every prime $p$ and integer $e$, and $g(n)=0$ otherwise","A function $g(n)$ is defined for positive integers $n$ by the rule
$\displaystyle\sum_{d|n}g(d) = \log n$.
Prove that $g(n)=\log p$ if $n=p^e$ where $p$ is a prime and $e\in \mathbb{Z}^+$, and $g(n)=0$ otherwise. I have no idea how to start this question at all does it include mathematical induction?","['proof-writing', 'discrete-mathematics', 'prime-numbers']"
2890905,In a group of $n$ people everybody with a mutual friend know different number of people. Do there exist somebody knowing only one person?,"In a group of n people ($n \geq 2$) at least two person knows each other. Assume that if two persons have a mutual friend, they know different number of people.
  Prove that in this group there exist a person that knows only one person. My approach is the following:
Let $G=(V,E)$ be a graph such that $|V(G)|=n$. Assume the contrary, that $deg(v)\geq 2$, for all $v \in V(G)$. At least two person knows each other so let $v,w \in V(G)$ be such that $(v,w) \in E(G)$. But, from the assumption $deg(v),deg(w)\neq 1$, so there is at least one person $s\in V(G)$ such that $v,w,s$ form a cycle. But then they all have a mutual friend, so all know different number of people. But know I am stuck and don't know how to finish the argument.","['graph-theory', 'discrete-mathematics']"
2890970,Cards game and probabilities,"From a standard 52-cards deck we randomly pull out 2 cards.
  One is black and the other is a 4.
  We choose one of the two cards.
  What is the probability: The card we pick is a 4 The card we pick is black The card we pick is a face card For 1: I believe it must be 1/2 (since 1 of the 2 cards is a 4) plus the probability for the other card also to be a 4. Since the other card is black, we know there are 2 fours in 26 black cards so 2/26? So finally $1/2+2/26$? Not sure. Similarly, 1/2 + the probability for the ""4"" card to be black - it can't be $1/2+2/4$ though. The black card can be a face card with probability $6/26$. Can you help me out?","['card-games', 'probability']"
2890989,"Number of ways to distribute objects, some identical and others not, into identical groups","The question I initially thought of that prompted this was ""How many distinct integer-sided cuboids are there with a volume of $60^3$?"". A small example to clarify: There are $3$ integer-sided cuboids with a volume of $8$, namely $8\times 1\times 1$, $4\times 2\times 1$, $2\times 2\times 2$. I realised that since the prime-factorisation of $60^3$ is $60^3=(2^2\times 3\times 5)^3=2^6\times 3^3\times 5^3$ Then the problem is equivalent to ""How many ways can we distribute $6$ identical objects (i.e. the $2$s), and $3$ identical objects of a different kind (i.e. the $3$s), and $3$ identical objects of a different kind again (i.e. the $5$s) into $3$ identical groups?"" For example, $60^3=(2^4\times 3)\times (2\times 5^2)\times (2\times 3^2\times 5)$ would be one possible cuboid. Note that any of the $3$ identical groups are allowed to be empty (this would mean a side length of $1$ in the cuboid). To put the problem another way, how many ways can we distribute the letters of the word ""AAAAAABBBCCC"" into $3$ identical groups? I have actually come up with a solution, $475$, by a sort of recursive method that I devised. I have copied my solution below. It feels very long and involved, so I would like to know if there a quicker way that relies on more standard recursively-defined functions, and is more easily generalisable. I am aware that related problems can be solved using Sterling numbers of the second kind, for example, or Bell numbers. But I have not been able to find any example of a problem like this, where the objects are a mixture of identical and distinct (what should I call this? Categorised?) and the groups are identical. Feel free NOT to read on, but here is my long-winded solution: Firstly, how many ways are there to distribute the 6 2s across the 3 groups? We can enumerate them: 0,0,6 0,1,5 0,2,4 0,3,3 1,1,4 1,2,3 2,2,2 Total: 7 ways Ok now how many ways are there to distribute the 3 3s? 0,0,3 0,1,2 1,1,1 Total: 3 ways Does this mean that there are 7 x 3 = 21 ways to distribute the 6 2s and the 3 3s? No! Since, it matters which of the 7 distributions of 2s we combine with which of the 3 distributions of 3s. The important feature of a distribution, for seeing how it combines with a set of possible distributions “overlaid” onto it, is which groups (if any) have been made distinguishable from each other by the first distribution. There are 3 possible patterns: All groups indistinguishable (call this A) Two groups indistinguishable, the other distinguishable (call this B) All groups distinguishable (call this C) Going back to the 7 possible distributions of 2s and labelling them A, B or C accordingly: 0,0,6   B 0,1,5   C 0,2,4   C 0,3,3   B 1,1,4   B 1,2,3   C 2,2,2   A So overall we have 1 A, 3 Bs and 3 Cs. At this point we can create our own “algebra” and use an algebraic-style shorthand (bearing in mind that A, B and C don’t represent numbers but patterns): A + 3B + 3C And for the 3 3s, we have: 0,0,3   B 0,1,2   C 1,1,1   A Making A + B + C Similarly, for the 3 5s we would have A + B + C Now, how do these all combine? First let’s consider overlaying the 3 possible distributions of 3s onto the 7 possible distributions of 2s. And let’s suppose that we overlay a C-distribution (all 3 containers distinguishable) onto another C-distribution. How many combined distributions does that give us? It gives us 3 x 2 x 1 = 6. And what are the patterns (A, B or C) for these distributions? They are all Cs. And so, in our homemade algebra, we can introduce a * symbol for overlaying distributions of given patterns, and say: C * C = 6C So, how many distributions do we get, and with what patterns, by overlaying the 1 C-distribution of 3s onto the 3 C-distributions of 2s? C * 3C = 18C Now we can go through a similar process for combining B with C, B with B etc. Note that, since an A-pattern is equivalent to the blank slate we started with, “multiplying” by A has no effect: A * C = C A * B = B A * A = A Note also that this form of “multiplication” is commutative, i.e. B * C = C * B etc, since we’ll get the same number of combined distributions whichever distribution we “put there first”. Some thought tells us that B * C = 3C, since if we begin with a C, there are 3 possible places to overlay the distinguishable container of the B. And by similar sorts of reasoning, B * B = B + C Now combining everything together, (A + 3B + 3C) * (A + B + C) = (A * A) + (A * B) + (A * C) + 3(B * A) + 3(B * B) + 3(B * C) + 3(C * A) + 3(C * B) + 3(C * C) (Interesting to note that the distributive rule for “multiplication” in this sense is valid, since we are combining every possible distribution of 2s with every possible distribution of 3s) = A + B + C + 3B + 3(B + C) + 9C + 3C + 9C + 18C = A + 7B + 43C All that is left to do now is overlay the possible distributions of 5s:
(A + 7B + 43C) * (A + B + C) = A + B + C + 7B + 43C + 7(B * B) + 50(B * C) + 43(C * C) = A + B + C + 7B + 43C + 7B + 7C + 150C + 258C = A + 15B + 459C Making a total of 475 distinct cuboids.","['combinatorial-geometry', 'combinatorics']"
2891120,What can we say about $a_n$ if $\sum a_n/n$ converges?,"Suppose that $\sum_{n=1}^{\infty} a_n/n$ converges, with $a_n \geq 0$ but not necessarily decreasing. What can we say about $a_n$? We can't say $a_n \to 0$. (Consider $a_n=1$ for n square, 0 otherwise.) But we can say that for any $\epsilon>0$, there are an infinite number of $a_n \leq \epsilon$. Is there a name for this property? What else can we say about $a_n$?","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
2891131,How many convex quadrilaterals can be formed between two parallel lines where 5 points lies in one line and 7 in the other?,"My approach to solve this problem has been first choose all the possible combinations of 4 points from the 12 available. Which is, $^{12}C_4=\frac{12!}{4!8!}=495$ Then, since they have to be convexed I get rid of all of the four collinear points. Which are, $^5C_4=\frac{5!}{4!}=5$ and $^7C_4=\frac{7!}{4!}=210$ So I have that, $^{12}C_4-(^5C_4+^7C_4)=495-(5+210)=495-215=280$ So there are 280 convexed quadrilaterals, but, should I get rid of the 3 collinear points too? If I do it I got, $280-(^5C_3+^7C_3)=280-(10+35)=280-45=235$ Thank you in advanced for any help on the matter.","['combinations', 'combinatorics', 'discrete-mathematics']"
2891159,"Asymptotic behaviour of sums involving $k$, $\log(k)$ and $H_{k}$","In the solution to the interesting problem Evaluation of $\int_{0}^{1}\int_{0}^{1}\{\frac{1}{\,x}\}\{\frac{1}{x\,y}\}dx\,dy\,$ I found that the existence of a possible closed form depends on the asymptotic behaviour of the following three sums $$\sigma_{a}(m) = \sum_{k=1}^m \frac{\log(k)}{k+1}$$ $$\sigma_{b}(m) = \sum_{k=1}^m k \log(k+1)\log(k)$$ $$\sigma_{c}(m) = \sum_{k=1}^m H_{k}\log(k)$$ To be more precise we need the asymptotic behaviour to the order of $1/m^3$ and possible logarithmic factors. This is a challenge question. Because of a lack of space here I'll show my solution attempts in a self answer. This reveals in more depth where I am stuck and gives a more detailed definition of the question.","['asymptotics', 'sequences-and-series']"
2891169,Curious ODE with Dirac comb,"I got stuck in my calculations trying to solve the following problem: Given the ODE $$\dot{x} = -\alpha x + a\sum_{n=0}^\infty\delta(t-n\tau)$$ where $\alpha \gt 0$ , define $$x_k = x(k\tau +0 )$$ and find $x_k$ as a function of $x_{k-1}$ .
What is the value of the following limit $$\lim_{k\rightarrow \infty}x_k?$$ My attempt First of all we define the following function $$f(t) = a\sum_{n=0}^\infty\delta(t-n\tau)$$ then the ODE becomes pretty much standard $$\dot{x}(t) = -\alpha x(t) + f(t)$$ for which the general solution is $$x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}f(t')\,dt'\\ x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}a\sum_{n=0}^\infty\delta(t'-n\tau)\,dt'.$$ Now we interchange the sum with the integral (being a physicist I impudently change them without checking uniform convergence!) and get $$x(t)= e^{-\alpha t} x(0)+\sum_{n=0}^\infty a\int_0^t e^{-\alpha(t-t')}\delta(t'-n\tau)\,dt'$$ By the definition of $x_k$ $$\begin{align}x_k = x(k\tau+0) &=  e^{-\alpha k\tau} x(0)+\sum_{n=0}^\infty a\int_0^{k\tau} e^{-\alpha(k\tau-t')}\delta(t'-n\tau)\,dt'\\&=\underbrace{e^{-\alpha k\tau}x(0)}_{\text{first term}}+\underbrace{\sum_{n=0}^kae^{-\alpha(k\tau-n\tau)}}_{\text{second term}}\end{align}$$ We can easily calculate $x_{k-1}$ from the value of $x_k$ $$ x_{k-1} =  \underbrace{e^{-\alpha(k-1)\tau}x(0)}_{\text{first term}}+\underbrace{a\sum_{n=0}^{k-1}e^{-\alpha(k\tau-n\tau)}}_{\text{second term}}.$$ It is clear that is we want to make a relation between $x_k$ and $x_{k-1}$ , the first terms of both can be written as $$e^{-\alpha k\tau}x(0) = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0)$$ so I'm bound to say that, at list for the first terms $$x_k = e^{-\alpha\tau}x_{k-1}\tag2$$ The real problem arises when we try to make adjustments to $(2)$ to make the second terms equal, mainly from definition $(2)$ we get $$x_k = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0) + \color{red}{e^{-\alpha\tau}a\sum_{n=0}^{k-1}e^{-\alpha(k-n)\tau}}$$ My questions now are Question 1: How can I adjust that second term to get $x_k$ as a function of $x_{k-1}$ ? Question 2: Is there an easier way to solve this problem?","['limits', 'dirac-delta', 'ordinary-differential-equations', 'sequences-and-series']"
2891182,Optimal orthonormal basis to represent a Gaussian,"I am looking at representing a set of Gaussians, of the form $\exp(-\frac{(r-r_i)^2}{2 \sigma^2})$, on a 1D domain. I do not know $r_i$ and $\sigma$ prior to defining the basis $\{ \phi_k(r) \}_{k=1}^n$. For the representation, I want to use a basis which can be defined based on four criteria: The basis is as complete as possible given a target number $n$ of basis functions. The basis functions are fully defined from the domain size, $r \in (0,r_\text{cut})$, and $n$. That is, the basis functions depend on $r$ and, parametrically, on $r_\text{cut}$ and $n$. The basis is orthonormal. The basis is optimally suited for representation of Gaussian functions. This means that I can obtain the expansion coefficients analytically. Basically, the end result is an approximant to my original function: $\exp(-\frac{(r-r_i)^2}{2 \sigma^2}) \approx \sum\limits_{k=1}^n w_k \phi_k (r)$ where, as said, I'm aiming at being able to obtain the $w_k$ analytically. These expansion coefficients can depend parametrically on $r_i$, $\sigma$, $r_\text{cut}$ and $n$. Is there any basis suited for this problem? Why I want to do this My final application requires a 3D representation of a series of points. The radial representation is done using Gaussians along the radial direction; the angular representation is done using spherical harmonics. The whole goal of doing a representation in a basis is to use the expansion coefficients. These expansion coefficients can be used to build a rotationally-invariant discrete representation of the set of points. For this to be computationally efficient, the basis needs to be as small as possible. To represent the radial part, I want a fixed basis which is optimally suited to represent 1D Gaussians. I cannot use the Gaussians themselves because I need to represent literally millions of Gaussians using a fixed-size basis, which needs to be always the same.","['change-of-basis', 'linear-algebra', 'normal-distribution']"
