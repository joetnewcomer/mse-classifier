question_id,title,body,tags
2813244,"Why is Axiom of Choice ""a convenient and safe labour-saving device""?","In Terence Tao's Analysis , he states The axiom is almost universally accepted by mathematicians. One reason for this conﬁdence is a theorem due to the great logician Kurt Godel, who showed that a result proven using the axiom of choice will never contradict a result proven without the axiom of choice.
  More precisely, Godel demonstrated that the axiom of choice is undecidable; it can neither be proved nor disproved from the other axioms of set theory, so long as those axioms are themselves consistent. Then he writes In practice, this means that any “real-life” application of analysis (more precisely, any application involving only “decidable” questions) which can be rigorously supported using the axiom of choice, can also be rigorously supported without the axiom of choice, though in many cases it would take a much more complicated and lengthier argument to do so if one were not allowed to use the axiom of choice. Thus one can view the axiom of choice as a convenient and safe labour-saving device in analysis. In ZF, if a proposition is ""decidable"", and if we prove the proposition in ZFC, then it is true in ZF. I understand it. If we prove sth is true in ZFC, then it is undecidable or true in ZF. but I think the hardest part is to demonstrate a proposition is 
""decidable"". How can we do that? Is there anyway to prove a proposition ""decidable""? So I think the axiom of choice is not safe. I don't understand Tao's words. Also, I don't understand why he asserts ""real-life"" application is always ""decidable"".","['real-analysis', 'axiom-of-choice', 'axioms', 'set-theory', 'analysis']"
2813258,Does there exist a topological space which is not separable but has the Souslin property?,"Does there exist a topological space which is not separable but possess the Souslin property (i.e. there is no uncountable family of pairwise disjoint nonempty open sets)?
I guess it should be something really large, e.g.
$[0,1]^\mathbb{R}$ or even $[0,1]^\mathbb{2^\mathfrak{c}}$
Thanks in advance.","['general-topology', 'separable-spaces']"
2813283,Does Cauchy Principal Value always exist?,"Is there any theorem that guarantees the existence of Cauchy Principal Value? I know that for many improper integrals, the Cauchy Principal Value exists but the improper integral might not exist, such as $$\int_{-\infty}^{\infty}x\,\mathrm{d}x.$$ So, I am wondering the reason that leads to such a result. Some says that it lies under the fact whether the limiting process is symmetric or non-symmetric. This seems to make sense. But why? Is there any more detailed explanation? Thank you!","['complex-analysis', 'cauchy-principal-value']"
2813361,Find the coefficient of $x^{20}$ in $(x + x^2 + x^3 + x^4 + x^5)(x^2 + x^3 + x^4 + \cdots)^5$,"Find the coefficient of $x^{20}$ in $$(x + x^2 + x^3 + x^4 + x^5)(x^2 + x^3 + x^4 + \cdots)^5$$ I have transformed it into $$x^{11} (1+x+x^2+x^3+x^4) \left( \frac{1}{1-x} \right)^5$$ So I got an idea that from $x^{11}(1+x+x^2+x^3+x^4)$ we can get $x^{15},x^{14}, x^{13}, x^{12}, x^{11}$ and then on the right side we should have respectively $x^5, x^6, x^7, x^8 , x^9$. Am I right? Having $$\left( \frac{1}{1-x} \right)^5 = \sum_{n=0}^\infty {5+n-1\choose 5-1}x^{n}$$ the final result that I got is $$ {9\choose 4} + {10\choose 4} + {11\choose 4} + {12\choose 4} + {13\choose 4}$$ Is it correct?","['generating-functions', 'combinatorics']"
2813390,"If $m$ tickets are drawn out of $n$ tickets numbered $1$ to $n$, find variance of the sum of the numbers on tickets","$m$ tickets are drawn out of $n$ tickets which are numbered from $1$ to $n$ . If $X$ denote the sum of the numbers on the tickets drawn. Find $V(X)$ . $X = X_1+X_2+\cdots+X_m$ , if $X_i$ can be treated as the $i$ th number drawn.
Otherwise, $X_i$ can be treated as the indicator variable of the number $i=1,2,...,n$ . In either way, I am able to get expectation since dependence of variables does not matter. However, while calculating Variance, dependence does matter. While calculating $E(X_iX_j)$ the second draw is supposed to be dependent on the first draw since there is a constraint of the sum $X$ . Please answer.","['variance', 'probability', 'expected-value']"
2813407,Area of circle inside a square,"I'm doing a question where I have a circle that is inscribed in a square. In the gap between the outside of the circle and the inside of the square, a 2-by-4 cm rectangle is at the vertex. I'm supposed to find the area of the circle. - I know I need to find the radius of the circle to get the area but I'm sure how to get the radius. I wanted to exploit symmetry but I couldn't get it to go anywhere.","['circles', 'geometry']"
2813416,"Find the extrema of the implicit function $f(x,y,z(x,y)) = x^2 + y^2 - z^2 = 0$","Find the extrema of the implicit function $f(x,y,z(x,y)) = x^2 + y^2 -
 z^2$ Of course, I start with calculating the partial derivatives by implicit differentiation.
$$\frac{\partial z}{\partial x} = \frac x z$$
$$\frac{\partial z}{\partial y} = \frac y z$$
Which yields that the only feasible stationary point is $(0,0)$. By the general formula of the function, $z = 0 $. But now we have a problem. Since $z = 0$, no partial derivatives at this point exist. We could try to check if $(0,0,0)$ is an extremum straight from the definition, but we don't have the formula for $z$. I need to find the extremum of $z$.
How do I proceed form here?","['multivariable-calculus', 'implicit-differentiation', 'calculus', 'derivatives']"
2813419,One-sided confidence interval for variance,"I am little bit confused about how we get the upper bound for CI for variance:
We have $\frac{(n-1) s^2}{\sigma^{2}}\sim X^2(n-1)$ $$P\left(\frac{(n-1)s^2}{\sigma^{2}}>X^2_{1-\alpha,n-1}\right)=1-\alpha$$ and if we solve for $\sigma^{2}$ then we should get $$P\left(\frac{1}{\sigma^{2}}>\frac{X^2_{1-\alpha,n-1}}{(n-1)s^2}\right)=1-α\Longrightarrow P\left(\sigma^{2}>\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right)=1-α\\\Longrightarrow CI=\left[\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}},+\infty\right].$$ But I do not know how the upper bound CI come out to be 
$\left[0,\dfrac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right]$???",['statistics']
2813422,"If $f$ is a non-unit element of an integral damain $A$, then $A[f^{-1}]$ is not finitely generated $A$-module.","I would like to solve the following exercise: Let $A$ be an integral domain. Let $f$ be a non-unit element of $A$. Then show that $A[f^{-1}]$ is not finitely generated $A$-module. Here is my attempt: Let $K$ be the quotient field of $A$. Let $B$ be a subring of $K$ containing $A$ and $f^{-1}$. We have to show that $A[f^{-1}]$ is not finitely generated $A$-module. On contrary, suppose $A[f^{-1}]$ is finitely generated $A$-module. Then $f^{-1}$ is integral over $A$ by proposition 5.1 of the book Commutative Algebra by Atiyah. $i.e.,$ there are $a_{1}, a_{2},...,a_{n}\in A$ such that \begin{equation}
f^{-n}+ a_{n}f^{-(n-1)}+...+ a_{1}=0
\end{equation}
By multiplying with $f^{n}$ on both sides, we have 
\begin{equation}
1+ a_{n}f+...+ a_{1}f^{n}=0
\end{equation}
$i.e.,$ \begin{equation}
-f(a_{n}+...+a_{1}f^{n-1})=1
\end{equation}
Thus $f$ is a unit that yield a contradiction of the hypothesis. Is the above argument correct? Another solution would be highly appreciated.","['abstract-algebra', 'linear-algebra', 'commutative-algebra']"
2813426,"""reverse birthday problem"" - inferring days in the year from collisions in sample [duplicate]","This question already has an answer here : Magic 8 Ball Problem (1 answer) Closed 6 years ago . Say you have n randomly selected students from another planet whose birthdays are known. x of them have birthdays that collide with at least one other student. How do you estimate the number of days in their year? Alternatively, perhaps you can use the fact that you know these n students have $x_1$ birthday collision pairs, $x_2$ birthday collision triplets and so on. How could the number of days in their year be estimated from that? Edit for context : I am building a framework where teachers can build small programs to procedurally generate math questions and I would like to show them an estimation of how many actual questions they are generating. I can sample their program a bunch of times to get different questions and check if I have seen them before (birthday collisions). Of course immediately after giving up and posting here I realize that $x_1$, $x_2$ etc mentioned above would give me a binomial distribution where if I can get P, I beleive the ""population size"" should be 1/P. I am trying this approach right now and will sanity check and compare to wolfram alpha. Also please be gentle, I'm just a programmer, I don't really know what I am doing.","['birthday', 'statistics']"
2813456,Misconception on Jordan Canonical Form,"Say we have matrix $$M= \begin{pmatrix} 
2 & 0 & 1 & -3\\
0 & 2 & 4 & 8\\
0 & 0 & 2 & 0\\
0 & 0 & 0 & 3
\end{pmatrix}\DeclareMathOperator{\Id}{Id}$$ It follows that $$\chi_{M}=(x-2)^{3}(x-3)$$ I found that $\ker(M-2\Id)=\{(1,0,0,0)^{T},(0,1,0,0)^{T}\}$, so dimension 2 . Similarly, we get dimension of $\ker(M-3\Id)=1$. I want to focus on $ker(M-2\Id)$: Looking at $ker(M-2Id)^{2}$, we get a basis of $\{(1,0,0,0)^{T},(0,1,0,0)^{T}, (0,0,1,0)^{T}\}$, so dimension 3 . In our notes, we have written down: Find a vector $v \in \ker(M-2\Id)^{2}$, such that $v \notin \ker(M-2\Id)$. It follows that $Mv \in \ker(M-2\Id)$ ( First question, should this not be $(M-2\Id)v \in \ker(M-2\Id)?).$ How does this help us in terms of the Jordan Form? I'm not sure how invariant subspaces fit into all of this either, other than the fact 
$\ker(M-2\Id)\subset \ker(M-2\Id)^{2}$. An intuitive explanation would be of great assistance.","['jordan-normal-form', 'linear-algebra']"
2813490,Directional Derivatives...,"There is a proof for how the limit definition of the direction derivative can be expressed as $\nabla f\cdot u$ that I found online where we define a function $g(h) = f(x+ha, y+hb)$ and find the derivative of it at $h=0$ which is equal to the limit definition of the directional derivative. Then we use the chain rule and evaluate that at $h=0$ too, and the two expressions of $g'(0)$ which is equal to the limit def. of a directional derivative. What I don't undetstand is the first step. Why do we create a function $g(h) = f(x_0 + ha, y_0 + hb)$ and when we find the derivative of it, why do we evaluate it at $h=0$? Also why do we evalautate the chain rule expression at $h=0$ too?","['multivariable-calculus', 'derivatives', 'calculus', 'limits']"
2813493,An inequality on the geometric mean of sines,"Let $n \in \mathbb{N}$,  $n \geq 2$. Let $x_1, \ldots,  x_n \in (0, \pi)$. Set $x = \frac{(x_1 + \cdots + x_n)}{n}$.
Which of the following statements are true? (b) $\prod_{k=1}^n \sin x_k \leq \sin^n x$ Option b is correct. We proceed by induction. Take $n = 2$. Then, we have $$\sin x_1+\sin x_2 = \frac{1}{2} \cos(x_1-x_2)- \cos(x_1+x_2)) \leq \frac{1-\cos(x_1+x_2)}{2} = \sin^2 x$$ as $\left|\cos x\right| \leq 1$. How to prove further?","['inequality', 'trigonometry', 'multivariable-calculus', 'arithmetic', 'jensen-inequality']"
2813500,Number of $10$ digit numbers such that every digit that appears appears exactly twice,"I need to find the number of $10$-digit numbers in which every digit that appears appears exactly twice. I have attempted to solve this but am not sure if I am not overcounting something. The only problem is that a $0$ cannot stand on the leftmost position. The first digit, say $i$, can be chosen in $9$ ways. Then, there are $9$ remaining places for the second $i$. Now, we have $9$ possible remaining digits and $8$ remaining places. We need to choose $4$ digits, we can do so in $\binom{9}{4}$ ways. Now, the remaining places must be divided into two-element subsets, which can be done in ${8\brace 2}$ ways (Stirling numbers of the second kind). Finally, we only need to distribute these $4$ numbers between these subsets, in $4!$ ways. And so the final answer is:
$$9 \cdot 9 \cdot \binom{9}{4} \ {8 \brace 2} \cdot 4!$$
Is it the correct answer?",['combinatorics']
2813522,Mobius function of the power set,"I'm having difficulties understanding the derivation of the Mobius function for the power set, and would like to ask some questions. Does the equality ""1"" come about as the result of the induction hypothesis? How do we get ""2"" and the equality in green? I suspect that there are some identities there that I've forgotten.","['number-theory', 'mobius-function', 'discrete-mathematics']"
2813526,Is this a mistake in the proof of Hall's Marriage Theorem from https://proofwiki.org?,"I read the proof from https://proofwiki.org/wiki/Hall%27s_Marriage_Theorem/General_Set . Here are screenshots from that link: I suspect that the statement Then for any $k\in I$, $\left\{ {g \left({x}\right): g \in \mathcal F \land k \in \operatorname{Dom} \left({g}\right)}\right\}$ is finite is possibly not correct. My reasoning: If $I$ is infinite, then for any $k$, it is possible that the number of function $g$ such that $g \in \mathcal F$ and $k \in \operatorname{Dom} \left({g}\right)$ is infinite by adding a new element from $I$ to the domain of existing function $g$. Please check if my spot is correct! Thank you so much!","['combinatorics', 'graph-theory', 'elementary-set-theory', 'proof-explanation']"
2813531,"If $a$ and $b$ are generators of the group $G$ and $ab=ba,$ Prove that $G$ is abelian.","I would like to verify if my proof is rigorous enough and is logically correct. THE PROOF- Let$\ z$ be an element of $G.$ This means $z$ can be expressed as $a^{n_1} b^{m_1} a^{n_2} b^{m_2} \cdots a^{n_p} b^{m_p}$. Since $ab=ba$ we can shift each $a$ towards the left until it reaches $a^{n_1}$. This would give us $a^{n_1+n_2\cdots n_p} b^{m_1+m_2 \cdots m_p}$. Let $x,y∈G$
where
$x=a^{n_1+n_2\cdots n_p} b^{m_1+m_2\cdots m_p}$ and $y=a^{r_1+r_2\cdots r_q} b^{s_1+s_2\cdots s_q}$ Then
$$xy=a^{n_1+n_2\cdots n_p} b^{m_1+m_2\cdots m_p} a^{r_1+r_2\cdots r_q} b^{s_1+s_2\cdots s_q}$$ Now we can repeat the process of moving every $a$ towards the left to get $$xy=a^{n_1+n_2\cdots n_p+r_1+r_2\cdots r_q} b^{m_1+m_2\cdots m_p+s_1+s_2\cdots s_q}$$ $yx$ would similarly be equal to $a^{r_1+r_2\cdots  r_q+n_1+n_2\cdots n_p} b^{s_1+s_2\cdots s_q+m_1+m_2\cdots m_p}$ which is equal to $a^{n_1+n_2\cdots n_p+r_1+r_2\cdots r_q} b^{m_1+m_2\cdots m_p+s_1+s_2\cdots s_q}$ Since $xy=yx$, $G$ is abelian.","['abelian-groups', 'abstract-algebra', 'group-theory', 'solution-verification']"
2813532,What's an Extension of a Function?,"Wikipedia says: An extension of a function $f$ is a function $g$ , such that $f$ is a restriction of $g$ . That's about it. Doing some searches doesn't provide much. I'm not quite seeing the implications or meaning of this. This came up in a question on the definition of the universal property for groups: The universal property for a group and generating set is a set of maps from the generating set to a new subset that can be extended to a unique homomorphism from the group to that second subset. Formally, every $ϕ:A→H$ can be extended to $\varphi^∗:G\to H$ . It is mentioned in the answer that: ...[if] $f:A\to H$ is a function then extending $f$ to $G$ simply means finding a function $f':G\to H$ such that $f'(g)=f(g)$ for $g\in A$ . Wondering what this means, if more depth could be gone into. Also wondering when you should extend functions, and how to use it. Not sure what is happening with it in the example.",['functions']
2813588,Classification of the positive integers not being the sum of four non-zero squares,"It is well known that every positive integer is the sum of at most four perfect squares (including $1$). But which positive integers are not the sum of four non-zero perfect squares ($1$ is still allowed as a perfect square) ? I showed that the numbers $2^k$ , $2^k\cdot 3$ and $2^k\cdot 7$ with odd positive integer $k$ have this property. I checked the numbers upto $10^4$ and above $41$, no examples , other than those of the mentioned forms , occured. So my question is whether additional positive integers with the desired property exist.","['number-theory', 'summation', 'square-numbers', 'elementary-number-theory']"
2813589,"$a,b,c,d$ are positive integers such that $ad=bc$. Prove that $n=a+b+c+d$ cannot be prime","The question is from Round $1$ of $1996/97$ Iranian National Mathematical Olympiad. My attempt at a solution is as below: $a,b,c,d$ cannot all be odd because then their sum would be even and therefore not prime. So, at least one of $a,b,c,d$ is even. Given that $ad=bc$, at least two of $a,b,c,d$ are even. If only two of $a,b,c,d$ are even, then $a+b+c+d$ is even and is not prime. Therefore, the only possibility is that three of $a,b,c,d$ are even. Without loss of generality, let $a,b,c$ be even. Using $ad=bc$, we can prove that (after cancelling out any higher powers of $2$ that $a,b,c$ might share), $a\equiv 0\pmod 4$, $b\equiv 2\pmod 4$ and $c\equiv 2\pmod 4$, basically that $a$ has one extra power of $2$ than $b,c$. I am stuck after this and do not know how to proceed","['divisibility', 'number-theory', 'contest-math', 'prime-numbers', 'elementary-number-theory']"
2813598,What are tolerance intervals for linear regression?,"What are tolerance intervals for linear regression.  I am trying to break down this paper into general terms, not a specific problem.  What are they used for?  What is the basic principles behind this technique, and how does it differ from other statistical analysis?: https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200500218","['regression', 'statistics', 'linear-regression']"
2813631,Zeros of Polynomials in Arbitrary Rings [duplicate],"This question already has answers here : A nonzero polynomial over a domain has no more roots than its degree [closed] (2 answers) Closed 5 months ago . The book I'm reading introduces polynomials over a field and proves the statement that a polynomial of degree $n$ has at most $n$ zeros. They do this by using division algorithm and induction. Then they make the following remark: This is not true for polynomial over arbitrary rings. For instance $x^2 + 7 \in \mathbb{Z}_8$ has roots $1,3,5,$ and $7$. My question: what fails in the previous proof for arbitrary rings? They just made that remark and moved on. Edit -- Proof (from Gallian): We proceed by induction on $n$. Clearly, a polynomial of degree $0$ over a field has no zeros. Now suppose that $f(x)$ is a polynomial of degree $n$ over a field and $a$ is a zero of $f(x)$ of multi­plicity $k$. Then, $f(x)=(x-a)^kq(x)$ and $q(a) \neq 0$. Note we have $\text{deg }f = n = k + \text{deg }q$. If $f(x)$ has no zeros other than $a$, we are done. On the other hand, if $b \neq a$ and $b$ is a zero of $f(x)$, then $0=f(b)=(b-a)^kq(b)$ so that $b$ is a zero for $q(x)$ with the same multiplicity it has for $f(x)$. By the Second Principle of Mathematical Induction, we know that $q(x)$ has at most deg $q(x)=n-k$ zeros, counting multiplicity. Thus, $f(x)$ has at most $k + n -k = n$ zeros, counting multiplicity.","['abstract-algebra', 'ring-theory', 'polynomials', 'soft-question']"
2813634,"Why $SO(3,\mathbb{R})$ is $3$-dimensional?","$SO(3,\mathbb{R})$ is a 3-dimensional manifold. However, when we can represent a fixed angle using the sphere coordinate, there are only $2$ parameters. Why?","['analysis', 'lie-groups']"
2813655,What is $E|\langle A\rangle|$?,"Suppose $A$ is a random subset of $S_n$, such that each element of $S_n$ independently belongs to $A$ with probability p. What is the expectation of $|\langle A\rangle|$? The case with $p = 1$ ($E|\langle A\rangle| = n!$) is quite obvious, however, I do not know, how to deal with the situation when $0 < p < 1$. Any help will be appreciated.","['expectation', 'abstract-algebra', 'probability', 'permutations', 'group-theory']"
2813683,Prove the Lindeberg condition is satisfied.,"Let $ X_1 ,..X_n$ iid with $E(X_i)=\mu$ and finite variance $\operatorname{var}(X_i)=\sigma^2$. Show that $$\frac{1}{n\sigma^2}\sum_{i=1}^n E\left[(X_i-\mu)^2I(|X_i-\mu| \geq \epsilon\sigma (n)^{0.5} \right]$$ goes to zero as n goes to $\infty$. can anyone help me out to figure out starting point ? I can see that when n goes to $\infty$ , $\sigma (n)^{0.5}$ goes to $\infty$. 
so 
$$E(X_i-\mu)^2I(|X_i-\mu| \geq \epsilon\sigma (n)^{0.5} = 0.$$ But my question is, is that valid for all $n$? Thank you","['probability-limit-theorems', 'probability-theory', 'statistics']"
2813729,Show that a continuous map $f: S^n \to S^1$ is nullhomotopic.,I'm trying to show that if $n>1$ then any continuous map $f: S^n\to S^1$ is nullhomotopic. I can only prove this when f is not surjective. I guess this has something to do with the fact that $\pi_1(S^n)$ is trival for $n\geqslant2$ but I can't see how to proceed. Thanks in advance!,"['algebraic-topology', 'general-topology']"
2813735,Let be $f:\mathbb R \to \mathbb R$ be a function satisfying $f(x+y)=f(x).f(y)$. Which one of the following are correct?,"Let be $f:\mathbb R \to \mathbb R$ be a function satisfying
  $f(x+y)=f(x)\cdot f(y)$ and $\displaystyle\lim_{x \to 0}f(x) = 1$. which of the following
  are necessarily true? $f$ is strictly increasing $f$ is either constant or bounded $f(rx)=f(x)^r, \forall r \in \mathbb Q$ $f(x)\ge 0, \forall x \in \mathbb R$ $f(2x)=f(x)^2$
We can prove by induction that
$\forall m\in \mathbb Z f(mx)=f(x)^m$ $f(\frac{nx}{n})=f(\frac{x}{n})^n \implies f(\frac{mx}{n})= f(x)^\frac{m}{n}$. hence 3. is correct.
$e^x$ satisfying above condition, So, 1,4 are right. Hence, 1,3,4 are correct answers. But answer given in the answer key were 3 and 4. I am not able to give any counter example for 1.","['real-analysis', 'monotone-functions', 'functions', 'limits']"
2813789,Proving that $\omega_1$ is a limit ordinal,"I'm new to set theory and can't find my way through this. I've defined $\omega_1$ as the Hartogs number of $\omega$, that is $\omega_1:=H(\omega)=\{\alpha\in On: |a|\leq\omega\}$. I believe contradiction is the only way through this, so let's suppose that $\omega_1=\beta+1$ for some ordinal $\beta$. Then $\beta<\omega_1$, therefore $\beta\in\omega_1,$ and consequently $|\beta|\leq\omega$. But then $\beta+1$ is at most countable, a contradiction, since $\omega_1$ is the first non-countable ordinal. Now my question has two parts: 1) Is the proof above correct? 2) Is it true that $\omega_{a+1}:=H(\omega_a)$ is a limit ordinal for all $a\in  On$? If so, can you provide a proof description since the above cannot be modified (in the initial situation we had the benefit of $\omega$ being countable)","['cardinals', 'elementary-set-theory', 'ordinals']"
2813810,Where did I make a mistake in my simplification of the algebraic expression?,"I need to simplify
$$\left(\frac{x^{-1}+y^{-1}}{yx^{-1}+xy^{-1}}\right)^{-1}+\left(\frac{x^{-1}+y^{-1}}{2}\right)^{-1}-\frac{x^{-1}-y^{-1}}{x^{-1}y^{-1}}$$
The conditions are
$$xy\neq0$$
$$x\neq-y$$
And the solution is
$$2x$$ My attempt $$\left(\frac{x^{-1}+y^{-1}}{yx^{-1}+xy^{-1}}\right)^{-1}+\left(\frac{x^{-1}+y^{-1}}{2}\right)^{-1}-\frac{x^{-1}-y^{-1}}{x^{-1}y^{-1}}$$
$$\frac{yx^{-1}+xy^{-1}}{x^{-1}+y^{-1}}+\frac{2}{x^{-1}+y^{-1}}-\frac{x^{-1}-y^{-1}}{x^{-1}y^{-1}}$$
$$\frac{2+yx^{-1}+xy^{-1}}{x^{-1}+y^{-1}}-((x^{-1}-y^{-1})(xy))$$
$$\frac{2+yx^{-1}+xy^{-1}}{x^{-1}+y^{-1}}-(y-x)$$
$$\frac{2+yx^{-1}+xy^{-1}}{x^{-1}+y^{-1}}-\frac{(y-x)(x^{-1}+y^{-1})}{x^{-1}+y^{-1}}$$
$$\frac{2+yx^{-1}+xy^{-1}}{x^{-1}+y^{-1}}-\frac{yx^{-1}-xy^{-1}}{x^{-1}+y^{-1}}$$
$$\frac{2(1+xy^{-1})}{x^{-1}+y^{-1}}$$
Where's my mistake?","['algebra-precalculus', 'exponentiation']"
2813817,Are there uncountable antichains in $\mathcal{P}(\mathbb{N})$,"As the title states, I am unsure of how to construct an uncountable antichain in the power set $\mathcal{P}(\mathbb{N})$. Recall that an antichain is a set $\mathcal{A}\subset\mathcal{P}(\mathbb{N})$ where each element of $\mathcal{A}$ is not a subset of another element of $\mathcal{A}$. It seems that everything I attempt requires me to assign a property to the ""$n$-th set"" but that already makes it countable...","['real-analysis', 'cardinals']"
2813858,Solve $\int_{|z| = 3} \tan (\pi z) dz$ using argument principle,"$\int_{|z| = 3} \tan (\pi z) dz = \int \frac{d(\cos \pi z)}{ (-\pi)\cos \pi z} dz = -2i(N-P)$ where N = num of zeroes inside C:|z| = 3 and P is num of poles inside C (Is this correct or should we also consider on C??? ) zeroes for $\cos \pi z$ = -0.5,-1.5,-2.5,0.5,1.5,2.5 $\implies $ N = 6 No poles for $\cos \pi z$ value of given integral = $-2i (N-P) = -2i(6-0) = -12i$ Is this correct? pls correct me if i am doing wrong","['complex-analysis', 'trigonometry', 'contour-integration']"
2813884,Lipschitz constant of $\|Ax-b\|_2^2$ and $A^T(Ax-b)$,"The Lipschitz constant $L$ of a function $f$ is defined as follows $$\| f(y) - f(x) \|_2 \leq L \|y-x\|_2$$ I want to find the Lipschitz constants for the following functions: $$f_1(x) = \|Ax-b\|_2^2$$ $$f_2(x) = A^T (Ax-b)$$ where $A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n, b\in\mathbb{R}^m$. Any help?","['derivatives', 'inequality', 'optimization', 'calculus', 'lipschitz-functions']"
2813886,Does the following hold for any matrix $A$ with non-negative eigenvalues?,"If $A\in\Re^{q\times{q}}$ is a square matrix with non-negative eigenvalues. Is it possible to show that $x^TAx\geq{0}$ for any non-zero vector $x$? I know this is obvious for positive semi-definte matrices but when it is not, is there a way to show that $x^TAx\geq{0}$? I know this holds for an eigenvector $x$ corresponding to eigenvalue $\lambda$, $Ax=\lambda{x}$ and $x^T{A}x=\lambda\|x\|^2\geq{0}$. But in case when $x$ is not an eigenvector is that claim true?","['matrices', 'matrix-decomposition', 'linear-algebra']"
2813891,show that any orbit that intercepts the unitary sphere $S^{n-1}$ is contained in it also,"Let $X : U \rightarrow R^n$ a vector field such that $ \langle X(p); p \rangle = 0 \,\,\,\,\,\,\,\,\ \forall p \in R^n; \,\,\,\,\,\ ||p|| = 1$; where $\langle \cdot ; \cdot \rangle$ is the inner product canonic in $R^n$ and $||\cdot ||$ is the Euclidian norm. show that any orbit that intercepts the unitary sphere $S^{n-1} := \{p \in R^n; ||p|| = 1 \}$ is contained in the sphere. I've tried several local theorems to use, but none seems to work well. Can anyone help?","['vector-fields', 'ordinary-differential-equations']"
2813915,Find $ \ f:\mathbb Z \to \mathbb C$ such that $f(n)= -f(-n+m)$ for $m\in \mathbb Z \setminus 3\mathbb Z$ and $n\in \mathbb Z$.,"Can we expect to find no-zero function  $ \ f:\mathbb Z \to \mathbb C$ such that $f(n)= -f(-n+m)$ for $m\in \mathbb Z \setminus 3\mathbb Z$ and $n\in \mathbb Z$? Edit : the example in my mind is: $f(n)=(-1)^n= (e^{\pi i})^n$, this satisfy the above situation if we take $m\in \mathbb Z \setminus 2\mathbb Z.$ I'm willing to generalize the property of $f$ for $m\in \mathbb Z \setminus 3\mathbb Z.$","['real-analysis', 'examples-counterexamples', 'functions', 'combinatorics', 'sequences-and-series']"
2813959,Most valuable rectangle contained in an equilateral triangle,"A measure $V$ (for ""value"") is defined on an equilateral triangle. $V$ is absolutely-continuous with respect to the Lebesgue measure, and the value of the entire triangle is $1$. What is the largest $r$ such that, for every $V$, the triangle contains a rectangle with a value $\geq r$? One special case is that $V$ is the Lebesgue measure, so the value of a rectangle is its area. The largest area of a rectangle is $1/2$ , so $r\leq 1/2$: However, there is a worse case: if the measure $V$ is spread evenly in a thin strip along the perimeter of the triangle, then any rectangle can contain a value of at most $1/3$, so $r\leq 1/3$: Is there a measure $V$ for which $r$ is smaller? P.S. the question is related to both geometry and measure theory. Is there a field that deals with such questions?","['geometric-measure-theory', 'rectangles', 'triangles', 'geometry']"
2813972,can one order the elements of a finite group such that their product is equal to the first element in the list?,"This question is inspired by this question. Given a finite group $G$, is there an ordering $G=\{a_1, \dots, a_n\}$ of its elements such that the product of all group elements in that specified order equals the first element, i.e $a_1\cdot\dots\cdot a_n=a_1$. Equivalently, can we multiply all but one element of the group in such a way to obtain the unit $1$. Trivial cases (probably not very helpful): $G$ is abelian (just define $a_1$ to be the product of all elements). $G$ has no element of order $2$ ($a_1=1$ and pair the elements with their inverses in the list). $G$ has a unique element of order $2$ (set $a_1$ to be that element and pair the others with their inverses). Slightly less trivial cases (still probably not that useful) $G=S_3$ (symmetric group) if $a=(12), b=(23)$ are the standard generators, then $(aba)=(aba)(a)(ba)(b)(ab)1$ $G$ with $|G|>6$ has exactly two or three elements of order $2$: Consider the conjugation action of $G$ on the set $X$ of elements of order $2$. If this action is non-trivial, then for at least one $x\in X$ the centralizer of $x$ has at most $\frac{|G|}{2}$ elements, hence we find a $g\in G\setminus X$ with $y:= gxg^{-1}\neq x$; then the product $ygxg^{-1}$ followed by all the elements of order $\geq3$ paired with their inverses is trivial. If the action is trivial, then $X$ lies in the center and is thus an abelian subgroup (because the product of commuting elements of order $2$ has order $\leq 2$); hence we can first multiply all elements of $X$, followed by all other elements paired with their inverses.","['finite-groups', 'group-theory']"
2813980,Let $X$ be a separable Banach space. Let $Y$ be the space formed by adding a point at infinity. Is $Y$ homeomorphic to the unit sphere of $X$?,"More specifically, let $Y= X \cup \{\infty\}$ and declare open sets to be the usual open sets in $X$ together with those that are of the form $(X-C)\cup \{\infty\}$, where $C$ is norm closed and norm bounded. So $Y$ is formed in the same way that the one point compactification is when $X$ is finite dimensional. Clearly if $X = \Bbb R^n$ we have $Y \cong S^n$, which motivates the question. Note that all separable Banach spaces are homeomorphic, so I think $Y$ should not depend on which Banach space is chosen (which makes the Hilbert space the natural candidate to try to work with.) Any references to a paper/text with a proof or a sketch of a proof (or disproof) are greatly appreciated. Thanks in advance!","['general-topology', 'real-analysis', 'functional-analysis']"
2814040,Show that those random quantities converge in distribution to a normal variable (hard analysis problem),"We have $(X_i)_{i \in \mathbb Z}$ iid random variables with $1\le X_i \le2$ almost surely. We define $X(x,\omega) \equiv X_i (\omega)$ if $x\in [i,i+1[$ and $X_\epsilon (x, \omega) \equiv X(x/\epsilon, \omega)$. Define $$Y (x,\omega) \equiv \frac 1 {E[\frac 1 {X_1}]} (1- \frac 1 {E[\frac 1 {X_1}] X_\epsilon (x,\omega)})$$ We would like to show that there exists real numbers $\alpha$ and $\beta$ such that $$\epsilon^\alpha \int_0^1 Y(x, \omega)g(x)\,dx \to \mathcal N(0, \int_0^1\beta g^2(x) \,dx)$$ in distribution when $\epsilon \downarrow 0$ for any sufficiently smooth function $g$. Another very similar problem is the following, but I don't know if it's harder or easier. EDIT: the following problem is harder, it has been moved to a separate question How to use the Lindeberg CLT in this scenario ? (analysis problem) Define $$u'_\epsilon(x,\omega)= \frac {c_\epsilon(\omega) - F(x)}{X_\epsilon(x,\omega)}$$ where $F$ is an $L^1([0,1])$ function and $c(\omega)$ is defined by $$c_\epsilon(\omega)\equiv \frac{\int_0^1 \frac{F(y)}{X_\epsilon(y,\omega)} \, dy}{\int_0^1\frac 1 {X_\epsilon(y,\omega)}\, dy}$$ Show that $$\epsilon^\alpha\int_0^1 u'_\epsilon(x,\omega) g(x)\, dx \to \mathcal N(?, ?)$$ for a certain $\alpha\in\mathbb R$, in distribution when $\epsilon \downarrow 0$ for any sufficiently smooth function $g$, where we need to characterize the expectation and the variance. A hint says for this problem that we should notice that $u'_\epsilon(x,\omega)$ can be written as a product of a random part and a deterministic part + an error that can be controlled in $L^2(]0,1[ \times \Omega)$. We can easily notice that $$u'_\epsilon(x,\omega)= \frac {F(x)}{X_\epsilon(x,\omega)} + err_\epsilon(x,\omega)$$ where $$err_\epsilon(x,\omega)=\frac {\int_0^1 \frac {F(y)}{X_\epsilon(y,\omega)} dy}{X_\epsilon(x,\omega)\int_0^1 \frac {1}{X_\epsilon(y,\omega)} dy}$$ I have no idea how to control this and how will this help. The question related to this control can be found here : Controlling this function in $L^2$ norm Another post that brings more information about $u'_\epsilon$ is the following: Showing an $L^2$ convergence (with convergence rate)","['stochastic-processes', 'real-analysis', 'probability-theory', 'probability', 'measure-theory']"
2814041,A positive sequence which is arbitrarily small and diverging,"Let $(a_n)_{n\in\mathbb{N}}$ be a positive sequence. Assume, that $\lim_{n \to \infty} a_n = \infty$. $\forall\ \zeta > 0, \exists\ n=n(\zeta) \geq 1: a_n < \zeta.$ From 1. we know, that $\forall\ C > 0, \exists\ N = N(C) \geq 1: a_n \geq C, \forall\ n \geq N.$ The difference $N(C) - n(\zeta)$ can be interpreted as the 'recovery time', i.e. the time the sequence needs from being arbitrarily small to become larger than an arbitrary positive constant $C$  for the rest of its existence. Question: Can somebody think of an example where $\forall\ C > 0: N(C) - n(\zeta)$ is arbitrarily large? (Is this even possible?)","['real-analysis', 'sequences-and-series', 'calculus']"
2814061,Do the complex conjugate eigenvalues add up in pairs for the addition of a matrix and its transpose?,"I encountered a few matrices like the ones in the following: $A_1=\begin{bmatrix}1 & -1 & 0\\0 & 1 & -1\\-1 & 0 & 1\end{bmatrix}$, $A_2=\begin{bmatrix}0.84 & -0.62 & -0.22\\-0.22 & 0.84 & -0.62\\-0.62 & -0.22 & 0.84\end{bmatrix}$ which respectively have eigenvalues $\lambda(A_1)=0,~1.5\pm{j*0.866}$ and $\lambda(A_2)=0,1.26\pm{j*0.3464}$. What surprises me is $\lambda(A_1+A^T_1)=0,3,3$ and $\lambda(A_2+A^T_2)=0,2.52,2.52$, i.e. the eigenvalues of the resultant matrix are sum of corresponding complex and complex conjugate eigenvalues. Is this associated to any property of matrices which make the resultant eigenvalues of $(A_i+A^T_i)$ twice the real part of eigenvalues of $A_i$? I have one more matrix to show similar situation. $V=\begin{bmatrix}-0.5773 & -0.5773 & 0.5773\\-0.5773 & -0.288675 & -0.288675\\-0.5773 & -0.288675 & -0.288675\end{bmatrix}$, which gives $\lambda(V)=0,-0.5773\pm{j*0.8164}$ and $\lambda(V+V^T)=0,-1.1547,-1.1547$. My approach: any matrix $A=\dfrac{1}{2}(A+A^T)+\dfrac{1}{2}(A-A^T)$ and for a nonzero vector $x$, we get
 $x^T{A}x=\dfrac{1}{2}x^T(A+A^T)x$ since $x^T(A-A^T)x=0$ due to skew-symmetricity of $A-A^T$. Therefore $x^T(A+A^T)x=2x^T{A}x=2x^T{P}DP^{-1}x$, where $A$ is decomposed as $A=PDP^{-1}$ with $D$ being a diagonal matrix with all eigenvalues of $A$ along its diagonal and $P$ is a unitary matrix with complex conjugate transpose denoted by $P^*=P^{-1}$. [The eigenvectors of $A_{1},A_2,V$ are independent and constitute a basis for $\mathbb{C}^3$]. Since $2x^T{PDP^{-1}}x\leq{2}x^T\text{tr}(PDP^{-1}){x}=2x^T\text{tr}(D){x}=4*\text{real}(\lambda)\|x\|^2$. But this does not help me prove the claim. Ant hint or references will be greatly appreciated.","['eigenvalues-eigenvectors', 'matrices', 'matrix-calculus', 'matrix-decomposition', 'linear-algebra']"
2814062,Birth-death-process: probability for at least one birth up to $t$,"Consider a Birth-and-Death Process with individual birth rates $\lambda(t)$ and individual death rates $\mu(t)$, starting at $n_0$. 
My question is if there is a formula for something like $$\mathbb P_{n_0} (\text{more than one birth happens up to time $t\ge0)$}$$ or—in a similar spirit—the expected time until the first birth happens. 
I know that the time spend at a position $n$ is distributed exponentially with parameter $n(\lambda(t)+\mu(t))$ but I couldn't find anything concerning probabilities where we look only at e.g. births.","['stochastic-processes', 'probability-theory', 'probability', 'birth-death-process']"
2814102,Prove De Morgan's Law: $(A \cap B)^c=A^c\cup B^c$,"Prove De Morgan's Law: $(A \cap B)^c=A^c\cup B^c$ and derive from it the law $(A \cup B)^c=A^c\cap B^c$. Proof of first: Let x be an arbitrary element of $(A \cap B)^c$ then x does not belong to A and B. Then by law of excluded middle(not sure if this is correct) x is either not in A, not in B or not in either. Thus x belongs to $A^c \cup B^c$ and $(A \cap B)^c \subseteq A^c \cup B^c$ Let x be an arbitrary element of $A^c \cup B^c$. Then either x does not belong to A or x does not belong to B. Then x can't belong to $A \cap B$. Thus $A^c \cup B^c \subseteq (A \cap B)^c$. For the second part I'm not entirely sure what is meant by derive. But my guess is to use the inclusive case from $A^c \cup B^c$. Suppose x belongs to $A^c \cap B^c$ then by the first law x belongs to $(A \cap B)^c$ and since x belongs to $A^c$ and $B^c$ then x belongs to $(A \cup B)^c$.","['elementary-set-theory', 'proof-verification']"
2814119,Metaphysical/psychological aspects of describing a formal language (mentioned in Bourbaki),"In the introduction to Bourbaki vol. 1, we read: ""It goes without saying that the description of the formalized language
is made in ordinary language, just as the rules of chess are. We do not
propose to enter into a discussion of the psychological and metaphysical
problems which underlie the use of ordinary language in such circumstances
(for example, the possibility of recognizing that a letter of the
alphabet is ""the same"" in two different places on the page, etc.)."" I would really like to read more about such ""psychological and metaphysical"" aspects mentioned here. What is meant by ""letter of alphabet being the same in two places""? I'd appreciate it if someone could introduce some literature/books that discuss these issues.","['meta-math', 'foundations', 'logic', 'elementary-set-theory', 'philosophy']"
2814177,Characterizing uniform probability on a finite group,"The following exercise comes from Diaconis' book Group Representations in Probability and Statistics . Here $G$ is a finite group, and $U$ is the uniform distribution on $G$, i.e., $U(s) = 1/|G|$ for all $s\in G$. Exercise 5. Let $P$ be a probability on $G$. Define $\overline P(s) = P(s^{-1})$. Show that $U = P\ast \overline P$ if and only if $P$ is uniform. A probability $P\colon G\to\Bbb R_{\ge 0}$ is a function satisfying $\sum_{s\in G}P(s) = 1$. Note that if $P$ and $Q$ are probabilities, then by definition,
$$
P\ast Q(s) = \sum_{t\in G}P(st^{-1})Q(t).
$$
If $P = U$, then it's not hard to show $U = P\ast \overline P$. My question is about the other direction. I have tried using the Fourier inversion formula:
$$
P(s) = \sum_id_i\operatorname{Tr}(\rho_i(s^{-1})\hat P(\rho_i)),
$$
where the $\rho_i$ are the irreducible representations of $G$ and $d_i$ is the degree of $\rho_i$. By definition, $\hat P(\rho_i) = \sum_{s\in G} P(s)\rho_i(s)$. However, this didn't yield anything besides $P(s) = 1/|G| \cdot P(s)\cdot |G|$. I did manage to show that $\sum_{s\in G}P(s)^2 = 1/|G|$ by looking at the regular representation of $G$, which is certainly a property that the uniform distribution on $G$ has, but I haven't been able to make further progress. Also relevant here is the Plancherel formula :
$$
\sum_{s\in G}f(s^{-1})h(s) = \frac{1}{|G|}\sum_id_i\operatorname{Tr}(\hat{f}(\rho_i)\cdot\hat h(\rho_i)),
$$
where $f,h$ are any two functions $G\to\Bbb C$ and the sum on the right is over all irreducible representations of $G$. Another relevant equation is
$$
\widehat{P\ast Q}(\rho) = \hat P(\rho)\cdot\hat Q(\rho).
$$
Any hints or suggestions are welcome in figuring this out.","['representation-theory', 'probability', 'fourier-analysis']"
2814179,"How to integrate the product of two or more polynomials raised to some powers, not necessarily integral","This question is inspired by my own answer to a question which I tried to answer and got stuck at one point. The question was: HI DARLING. USE MY ATM CARD, TAKE ANY AMOUNT OUT, GO SHOPPING AND TAKE YOUR FRIENDS FOR LUNCH. PIN CODE: $\displaystyle \int_{0}^{1} \frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 - 3x + 2}} \, dx $ I LOVE YOU HONEY. Anyone knows? Are we gonna get an integer number? My attempt: Does this help? $$\frac{3x^3-x^2+2x-4}{x-1}=3x^2+2x+4$$
  (long division)
  \begin{align*}
I&=\int\frac{3x^3-x^2+2x-4}{[(x-1)(x-2)]^{1/2}} dx = \\
&=\int\frac{(3x^2+2x+4)(x-1)^{1/2}}{(x-2)^{1/2}} dx = \\
&=\int 3(u^4-4u^2-4)(u^2+1)^{1/2}du \times 2
\end{align*}
  after the substitution
  \begin{gather*}
(x-2)^{1/2}=u\\
du=\frac1{2(x-2)^{1/2}}dx\\
u^2=x-2\\
(x-1)^{1/2}=(u^2+1)^{1/2}
\end{gather*} Update: This may help us proceed. I tried to proceed: $$6\int (u^4-4u^2-4)(u^2+1)^{1/2} du = 6\int ((t-3)^2-8)t \frac{dt}{2u}$$
  after $u^2+1=t$ and $dt=2udu$
  \begin{align*}
u^4-4u^2-4
&= (u^2+1)^2-(6u^2+5) \\
&= (u^2+1)^2-6(u^2+1)+1 \\
&= ((u^2+1)-3)^2-8
\end{align*} I wonder whether this question can be solved from here? Update: This has been getting a lot of views, and I think most people came for the sort of problem mentioned in the title (where I got stuck) rather than the original problem itself. Keepin this in mind, I'm reopening the question and here's the kind of answers I expect — Solutions to the original problem are good, but I'd prefer solutions that continue from the part where I got stuck — the polynomial in $u$ — that's the sort of problem mentioned in the title.","['definite-integrals', 'integration', 'polynomials']"
2814186,"If $\{j_n\}$ is increasing and $\lim\limits_{n→∞}\frac{j_n}n=+∞$, then $\sum\limits_{n=1}^∞\frac{(-1)^{[\sqrt n]}}{j_n}$ converges","My friend gave me an interesting analysis problem, and I was tackling it but it was very hard indeed. Here is the problem: Let $j_1,j_2,j_3,\cdots$ be a sequence of strictly increasing positive integers such that $\lim\limits_{n\rightarrow \infty} \dfrac{j_n}{n} = +\infty$. Prove that $\sum\limits_{n=1}^{\infty}\dfrac{(-1)^{[\sqrt{n}]}}{j_n}$ converges. Note: $[x]$ is the greatest integer less than or equal to $x.$ I think this is some hardcore analysis problem, I would really love to know how you solve this problem, and possibly a full out solution. I am trying my hardest to solve it too, and would appreciate any help offered. My attempt at proof of the above: We know that $$\lim_{n \rightarrow \infty}\frac{\frac{1}{j_n\sqrt{n}}}{\frac{1}{n\sqrt{n}}}=0$$ and clearly the summation: $$\sum_{n=1}^{\infty} \frac{1}{n\sqrt{n}}$$
converges, so we cann directly deduce that 
$\sum_{n=1}^{\infty} \frac{1}{j_n\sqrt{n}}$ converges by the limit comparison test. Now, let $k_n =\frac{1}{j_n}$, and claim that $S_l=\sum\limits_{n=1}^{l}(-1)^{[\sqrt{n}]}k_n$ is Cauchy. Now we take the terms $S_l-S_{m-1}=\sum\limits_{n=m}^{l}(-1)^{[\sqrt{n}]}k_n$ in to consideration, and to bound the term from above, we delete all terms with $[\sqrt{n}]=[\sqrt{m}]$ if $[\sqrt{m}]$ is odd and insert all missing terms with $[\sqrt{m}] =  [\sqrt{n}]$ if  $[\sqrt{m}]$ is even. Hence for a fixed $l,$ taking $1< m < l$, there exists $n,s$ with $n\le s$ such that:
$$S_l-S_{m-1}=\sum\limits_{t=m}^{l}(-1)^{[\sqrt{t}]}k_t\le \sum\limits_{t=(2n)^2}^{(2s+1)^2-1}(-1)^{[\sqrt{t}]}k_t\le $$ $$\sum\limits_{t=(2n)^2}^{(2s+1)^2-1}k_t + \sum^s_{t=n+1}\bigg[2k_{(2t+1)^2-2}+\sum_{u=0}^{(2t)^2-(2t-1)^2-1}(k_{(2t)^2+u}-k_{(2t-1)^2=u})\bigg]$$
$$\le (4n+1)k_{(2n)^2}+\sum^{s}_{t=n+1}2k_{(2t+1)^2-2}\le (4n+1)k_{(2n)^2}+2\sum^s_{t=n+1}\frac{1}{8t}\sum^{(2t+1)^2-2}_{u=(2t-1)^2-1}k_u$$
$$\le (4n+1)k_{(2n)^2}+\sum^s_{t=n+1}\sum^{(2t+1)^2-2}_{u=(2t-1)^2-1}\frac{k_u}{\sqrt{u}}\le  (4n+1)k_{(2n)^2}+\sum^{(2s+1)^2-2}_{u=(2n+1)^2-1}\frac{k_u}{\sqrt{u}} $$ It is not hard to see that as $m \rightarrow \infty,$ $n \rightarrow \infty$. We finally claim that the last expression goes to $0$ as $n \rightarrow \infty$. Note that the second term of the last expression tends to $0$ as as $n \rightarrow \infty$ as $\frac{k_u}{\sqrt{u}}$ converges. So it remains to show that the first term tends to $0$. We prove this by contradiction. Proof: For some $\epsilon > 0,$ assume that $(4n+1)k_{(2n)^2} >\epsilon$ infinitely often. If we recursively take $n_t>2n_{t-1}$ for $t \ge 1,$ with $(4n+1)k_{(2n)^2}>\epsilon$, then:
$$\sum_{l=1}^{\infty} \frac{k_l}{\sqrt{l}}\ge \sum_{t=1}^{\infty}\sum_{u=n_t^2}^{(2n_t)^2}\frac{k_u}{\sqrt{u}}\le \sum_{t=1}^{\infty}3n_t^2 \frac{k_{(2n_t)^2}}{2n_t}=\frac{3}{2}\sum^{\infty}_{t=1}n_t k_{(2n_t)^2}$$ $$\ge \frac{3}{10}\sum^{\infty}_{t=1}(k_{(2n_t)^2} \ge \frac{3}{10}\sum^{\infty}_{u=1}\epsilon =+\infty$$ This is a clear contradiction. So $\lim_{l\rightarrow \infty}\sup\{S_l-S_{m-1}:m<l\}\le 0$. We can repeat the above with $S_l-S_{m-1}$ bounded from below and get $\lim_{l\rightarrow \infty}\inf\{S_l-S_{m-1}:m<l\}\ge 0$, hence clearly $ S_l$ is Cauchy and thus converges. The reason I tried to come with a different idea is that I do not know what Dedekind's Test is, and even though I looked it up just so I can understand the accepted answer, it did not seem to make me fully satisfied. Although I am more aware of Dirichlet's Criterion for series. But of course I now come to realize that they are infact similar.","['real-analysis', 'sequences-and-series']"
2814213,Isomorphism between $\mathbb{C}^* $ under multiplication with $\mathbb{C}$ under addition.,"Does there exists an Isomorphism between $\mathbb{C}^* $ under multiplication with $\mathbb{C}$ under addition. Attempt
In my opinion It does not exists. If there exists such an isomorphism say $\phi :\mathbb{C}^* \to \mathbb{C}$ then, from the fact that Isomorphism takes identity to identity we have $$\phi \left( 1 \right)=0$$ From the fact Given $\phi:G \to H$ be an isomorphism, then For a fixed integer $k$ and a fixed group element $b$ in $G$, the
  equation $x^k=b$ has the same number of solutions in $G$ as does
  the equation $x^k=\phi\left(b\right)$ in $H$. We have $x^4=1$ and $x^4=0$ must have same number of solutions, but the solutions to these equations are 4 and 1 only.","['group-theory', 'group-isomorphism']"
2814220,How does Schur determine Galois groups of truncated exponential series?,"On Serge Lang (page.274 Example 8) and several algebra textbooks, it goes as 
$$f_n=\sum_{m=0}^n \frac{X^m}{m!}\qquad \operatorname{Gal}(f)=\begin{cases}
\mathfrak{S}_n& 4\nmid n\\ \mathfrak{A}_n& 4\mid n\end{cases}$$
It is claimed that the result is due to Schur, but the reference is in German and the full text is unavailable. Are there any textbook introducing it, or some review on it? And I know nothing about $f_n$, what can we say about it, such as its discriminant?","['galois-theory', 'polynomials', 'abstract-algebra', 'reference-request', 'field-theory']"
2814248,Which of these subsets are dense in $l^2$?,"Let $l^2$ be the Hilbert Space of Square summable sequence and $e_{k}$ denote the coordinate vector in which the $k$th position is $1$ and rest $0$.Then which of the following subspaces is not dense in $l^2$? 1.$\operatorname{span}\{e_{1}-e_{2},e_{2}-e_{3},e_{3}-e_{4}, \ldots\}$ 2.$\operatorname{span}\{2e_{1}-e_{2},2e_{2}-e_{3},2e_{3}-e_{4},\ldots\}$ 3.$\operatorname{span}\{e_{1}-2e_{2},e_{2}-2e_{3},e_{3}-2e_{4},\ldots\}$ 4.$\operatorname{span}\{e_{2},e_{3},\ldots\}$ I think option (4) cannot be dense in $l^2$ as we cannot find any sequence from the set in option 4 which converges to $(1,0,0,....)$. And observing option (3) (simply adding the vectors)leads to $(1,-1,1,-1,1,-1,...)$ which is not square summable and hence cannot be dense in $l^2$, please correct me if I am wrong? How to observe other options?","['functional-analysis', 'lp-spaces', 'linear-algebra', 'hilbert-spaces']"
2814377,Deriving Rodrigues Formula and Generating function of Hermite Polynomial from $H_n(x)= e^{x^2/2}(x-\frac{d}{dx})^ne^{-x^2/2}$,"There are a variety of ways of first defining the Hermite Polynomials in a certain way and then to derive alternative representations of them. For example in Mary Boas' Mathemmatical methods (p. 607, 3rd edition) she starts with the differential equation $y''_n-x^2y_n = -(2n+1)y_n$. Arfken's Mathematical Methods (p. 817, 6th edition) starts with a generating function $g(x,t)=e^{2xt-t^2}=\sum_{n=0}^{\infty}\frac{t^n}{n!}H_n(x)$. Griffiths Intro to Q.M. (p.57,problem 2.17, 2end edition) starts with Rodrigues formula: $H_n(x)= (-1)^ne^{x^2}\frac{d^n}{dx^n}e^{-x^2}$. I'd like to do the following: Start from the defintion $H_n(x)= e^{x^2/2}(x-\frac{d}{dx})^ne^{-x^2/2}$ and then derive both Rodrigues Formula  $H_n(x)= (-1)^ne^{x^2}\frac{d^n}{dx^n}e^{-x^2}$ and then the generating function $g(x,t)=e^{2xt-t^2}=\sum_{n=0}^{\infty}\frac{t^n}{n!}H_n(x)$. I'm not sure where to begin. My primary interest in this is quantum mechanics and how this Hermite Polynomial is used as a solution to the quantum Harmonic oscillator. I have never used Hermite Polynomials (or Laguerre, Legendre or Bessel functions)... So I'd be grateful for some advice on how to do this. edit: Okay so here's my approach for deriving Rodrigues Formula  $H_n(x)= (-1)^ne^{x^2}\frac{d^n}{dx^n}e^{-x^2}$: I use induction on $n$. For $n = 0$ both $H_n(x)= e^{x^2/2}(x-\frac{d}{dx})^ne^{-x^2/2}$ and Rodrigues give $1$. Now assume the equality holds for  some $n$ and show it for $n+1$: but now I'm stuck again...","['quantum-mechanics', 'hermite-polynomials', 'special-functions', 'ordinary-differential-equations', 'analysis']"
2814405,Why can different symmetry groups be isomorphic?,"What I understand : A group is characterized by how any two of its elements interact. It is the ""structure"" of the group that describes it. Thus two groups having the same structure are basically the same (isomorphic). The additive group $\Bbb R$ can be regarded as the set of all sliding symmetries of the ""number"" line. Any number can be seen as the sliding action that takes $0$ to that number. Similarly the multiplicative group $\Bbb R^+$ is the set of all stretching/squishing symmetries of the number line. A number here represents the action that takes $1$ to that number. The problem : It seems to me that the two groups mentioned above are very different in the sense that sliding and stretching/squishing are very different types of actions. But, the two groups are isomorphic. I would always see two isomorphic groups as being the same; however, after looking at $\Bbb R$ and $\Bbb R^+$ as groups of symmetries of the number line, I'm not so sure I would consider them as being the same. P.S. I am not familiar with the concept of a ""group action""","['symmetry', 'group-theory', 'group-isomorphism']"
2814413,Is the complement of countably many disjoint closed disks path connected?,"Let $\{D_n\}_{n=1}^\infty$ be a family of pairwise disjoint closed disks in $\mathbb{R}^2$.  Is the complement
  $$
\mathbb{R}^2 -\bigcup_{n=1}^\infty D_n
$$
  always path connected? Here “disk”  means a round, geometric disk.  (As shown below, the answer is no if we allow arbitrary topological disks.) Note that the union $\bigcup_{n=1}^\infty D_n$ can be dense in the plane.  For example, it's possible to find a collection of disjoint closed disks of positive radius whose union contains $\mathbb{Q}\times\mathbb{Q}$. It is easy to show that the complement of a countable set of points in the plane is always path connected. In particular, if $S \subset\mathbb{R}^2$ is countable, then there is always 
path between any two points in $\mathbb{R}^2-S$ consisting of two line segments. It is not true that the complement of a countable set of disjoint line segments  is path connected, as shown in the following figure. By thickening the line segments slightly, one can find a countable collection of disjoint topological disks whose complement is not path connected.","['geometric-topology', 'general-topology', 'connectedness']"
2814424,Fermat's Little Theorem: $r \equiv s \pmod {p-1} \implies a^r \equiv a^s \pmod p$,"An implication of Fermat's Little Theorem is the following: If $p$ is prime, and $a$ is not a multiple of $p$ , then $$r \equiv s \pmod {p-1} \implies a^r \equiv a^s \pmod p.$$ I need this implication to prove the verification of the Elgamal signature, but I honestly do not see how to derive from Fermat's Little Theorem to this implication and I could not find any proof of this. Any help would be much appreciated!","['discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2814453,How to find $\sum_{n=0}^{+\infty} \dfrac{1}{(kn)!}$? [duplicate],"This question already has answers here : Sum of $\sum \limits_{n=0}^{\infty} \frac{1}{(kn)!}$ (3 answers) Closed 6 years ago . I want to calculate $$S_k = \sum_{n=0}^{+\infty} \dfrac{1}{(kn)!}$$ when $k\in\Bbb N ^*$. I tried to find a recurrence equation for $k$, but I found nothing really interesting. I already know that for $k=1, S_1 = e$ and $S_2 = ch(1)$, but I don't know what to do for $k\geq 3$.",['sequences-and-series']
2814454,"Natural Deduction Proof that irreflexive, transitive relations on a Set S are not three-cycles","I am looking for a natural deduction proof for above question.
I have formalized the argument in the following way: $$
\forall x \neg Rxx, \ \forall x\forall y \forall z (Rxy\land Ryz \rightarrow Rxz) \vdash \forall x \forall y \forall z \neg(Rxy\land Ryz \rightarrow Rzx)
$$
I may have made an error in the formalization, and if this is the case I would be very happy for anybody to point this out. I currently have problems with showing that a relation is not three-cycle when there are no elements a,b,c such that
$$
\neg (Rab\land Rbc)
$$
I have already managed to show this from the premises, with only 
$$
Rab \land Rbc \rightarrow Rca
$$
as undischarged premiss.","['natural-deduction', 'formal-proofs', 'logic', 'elementary-set-theory', 'relations']"
2814474,"Probability puzzle app: Correlation coefficient question, Uniform distribution, Cannot get the write answer.","Suppose mathematical and writing ability are independent — and therefore uncorrelated — in the general population. To keep things tractable, imagine math and writing ability are independently uniformly distributed on the interval [0, 1], and that students attend college if and only if the sum of their mathematical and writing abilities is larger than one. Each point below is a simulated person; the color indicates whether they attend college. Among the population of college students, what is the correlation between writing and math ability? My approach so far I really do not get what I am doing wrong? $Corr\left( x,y\right) = \dfrac {cov\left( xy\right) }{\sigma _{x}\sigma _{y}} $ So then I try and calcuate $cov\left( xy\right) = E\left( XY\right) -E\left( X\right) E\left( Y\right)$ $E(XY) = \int ^{1}_{0}\int ^{1}_{1-y}xydxdy = \dfrac {5}{24}$ I do a similar process and calculate $E\left( X\right) =  E\left( Y\right) = \dfrac {1}{3}$ So that my final answer is $Corr\left( x,y\right)$ = $\dfrac {7}{10}$ But apparently this is not correct?","['algebra-precalculus', 'probability']"
2814531,group-like elements of a Hopf algebra and the group algebra,Suppose we are given a $n$-dimensional Hopf algebra $H$ over field $\mathbb K$. I want to prove that $H$ contains n distinct group-like elements if and only if there exists a group $G$ such that $H\simeq \mathbb K[G]$ as Hopf algebras. We know that if $H$ is a cocommutative Hopf algebra then there exists such group $G$ such that $H\simeq \mathbb K[G]$ as Hopf algebras. But I don't know if this is related to the above statement? Can someone let me know that how can I prove it? Thanks!,"['abstract-algebra', 'noncommutative-algebra', 'group-theory', 'hopf-algebras']"
2814551,inequality related to roots of $(x-1)\log(x)=m$,"$f(x)=(x-1)\log {x}$, and $f(x_1)=f(x_2)=m, 0<x_1<x_2$.
Show that $\frac{9}{5}+\log{(1+m)}<x_1+x_2<2+\frac{m}{2}$. If we apply Hermite-Hadamard inequality, it's easy to show $2<x_1+x_2$, but it's not strong enough. 
I also tried to replace $m$ with $f(x_1)$, then it became super complicated.
There should be some easy way to simplify $x_1, x_2$","['inequality', 'analysis']"
2814571,Is There Entire Function $|f(z)|=|1-|z||$ For All $z\in\mathbb{C}$,"Is There Entire Function $|f(z)|=|1-|z||$ For All $z\in\mathbb{C}$? Looking at $z=e^{i\theta}$ we have $|f(z)|=|1-|e^{i\theta}||=0$ So this is an entire function with infinite zeros, which can not be by the identity theorem, So therefore there is not such entire function Is this correct?","['complex-analysis', 'entire-functions', 'proof-verification']"
2814598,Satisfying explanation of Aristotle's Wheel Paradox.,"The paradox: We have a circle and there is another circle with smaller radius. They are co-centeric. If circle make full turn without sliding , both smaller and bigger circle make full turn too. If we assume that the passed road is equal to the circumference of circles. We have got smaller circle's radius is equal to bigger one's. Unsatisfying Solutions I found: ""Do not assume that smaller circle's circumference is equal to passed road since the surface that contacts to the ground is bigger one. "" // Okey but it does not explain the paradox, it explains just what is the wrong assumption (even does not explain why it is a wrong assumption.) It is undeniable that every point on both smaller and bigger circle will contact exactly one and only one point on their path. Therefore we can think that this is a bijective maps and smaller circle is isomorphic to bigger one. (Okey but ....) Question: What is the true answer? What is wrong with the definition of circumference of a circle and relationship with its taken path.","['equivariant-maps', 'paradoxes', 'geometry']"
2814604,Can I always choose $1$ in the integral basis of a number field?,"I am trying to show that given any number field $K$ of degree $n$, 
I can always find an integral basis $\{ w_1, ..., w_n \}$ where $w_1 = 1$.
I am interested in how to proving this, but I am stuck at the moment. I would greatly appreciate any suggestions. 
Thank you very much!","['number-theory', 'algebraic-number-theory']"
2814609,Matrix Representation of linear operators,"Let $S:\mathbb R^n \to \mathbb R^n$ be given by $S(v) = \alpha (v)$, for a fixed $\alpha \in \mathbb R, \alpha \neq 0$. Let $T:\mathbb R^n \to \mathbb R^n$ be a linear operator such that $B = (v_1, v_2, ..., v_n)$ is a set of linearly independent eigen vectors of $T$. Then prove or disprove that the matrix of $T-S$ with respect to $B$ is diagonal. Clearly, $B$ forms a basis for $\mathbb R^n$. This implies that $T$ is diagonalizable and hence the matrix representation of $T$ with respect to $B$ (i.e. $[T]_B$) is diagonal, with corresponding eigen values of $T$ (say $\lambda_1, \lambda_2, ..., \lambda_n$) as the diagonal entries. Also, $S$ is another linear operator on $\mathbb R^n$, by its definition in the problem. With respect to $B$, the matrix representation of $S$ (i.e. $[S]_B$) is also diagonal, with $\alpha$ as the diagonal entries. Therefore, the matrix representation of $T-S$ with respect to $B$ is again diagonal, with diagonal entries $\lambda_1-\alpha, \lambda_2-\alpha, ..., \lambda_n-\alpha$ because $(T-S)(v_i) = T(v_i) - S(v_i) = (\lambda_i - \alpha)(v_i)$, $v_i \in B, 1 \leq i \leq n$. Is my conclusion correct?","['diagonalization', 'linear-algebra', 'proof-verification']"
2814634,Is it $\mu(dx)$ or $d\mu(x)$? or they are equal?,"In probability theory, I have seen two forms of an integral. Let $\mu$ be a Borel measure and $f$ is a function. What is the difference between the following two forms: \begin{eqnarray}
\int_{\mathbb{R}^d} f(x) \mu(dx)
\end{eqnarray} and \begin{eqnarray}
\int_{\mathbb{R}^d} f(x) d\mu(x)
\end{eqnarray} Please give some references for your answer.","['probability-theory', 'lebesgue-measure', 'measure-theory']"
2814643,Measurable selection of geodesics,"Let $(X, d)$ be Polish and geodesic (i.e. for all $x,y \in X$ there exists a so called constant speed geodesic curve $\gamma :[0,1] \rightarrow X$, s.t. $$\gamma (0) = x, \gamma (1) = y$$ and $$d(\gamma(t), \gamma(s)) = |t-s|d(\gamma (0), \gamma (1)) = |t-s|d(x, y)$$ for all $t,s \in [0,1]$). The set of constant speed geodesics is denoted by $Geod(X)$ and is equipped with the sup-norm to form a complete metric space. I am looking for a measurable selection theorem which ensures the existence of a Borel measurable map $GeodSel: X^2 \rightarrow Geod(X)$ such that $GeodSel(x,y)$ is a constant speed geodesic from $x$ to $y$. My question arises from the proof of Theorem 2.10, page 35 in Ambrio's, Gigli's 'A user's guide to optimal transport' ( https://pdfs.semanticscholar.org/c453/e5ea0b6061d87cfa98f5b260a26f8497d3a1.pdf ).
In the mentioned book they refer to the following lemma and state that it would, together with classical measurable selection theorems, imply the existence of such a map. The multivalued map from $G:X^2 \rightarrow Geod(X)$ which associates to each pair $(x,y)$ the set $G(x,y)$ of constant speed geodesics connecting $x$ to $y$ has closed graph. I've searched for some theorems on my own and came across the Kuratowski and Ryll-Nardzewski measurable selection theorem ( https://en.wikipedia.org/wiki/Kuratowski_and_Ryll-Nardzewski_measurable_selection_theorem ). But then I struggled to show the condition of weak measurability. This was also discussed on MathOverflow some time ago https://mathoverflow.net/questions/145351/x-polish-geodesic-implies-p-2x-w-2-geodesic ).
But it seems to me that my question is still unanswered if $X$ isn't compact. I appreciate any help and hints!","['reference-request', 'optimal-transport', 'measure-theory', 'geodesic']"
2814684,Sum of powers mod p,"I've this problem that I did halve of the proof but I can't do the rest of it. Let $p$ be an odd prime. We define $S_n$ as $S_n =  1^n +2^n + ... +(p-1)^n$ Prove that
  $S_n \equiv
\begin{cases}
0  & \text{if $p-1 \nmid n $  } \\
-1, & \text{if $p-1 \mid n$ }
\end{cases}$ Partial proof: If $p-1\mid n$, then $\varphi(n)=p-1=kn$ for some k. 
As $p$ is prime, then every number from 1 to $p-1$ is relatively prime to it. So, using the Fermat-Euler Theroem, $a^{\varphi(n)} \equiv 1$ if $1 \leq a \leq p-1$. 
We see that every term in the sum becomes congruent to 1, and $\sum_1^{p-1} 1 = p-1 \equiv -1 \pmod p $. I don't know what to do if $p-1 \nmid n $. I've tried taking a primitive root mod p, but I got stuck.Any help or tip would be much aprecciated.","['group-theory', 'primitive-roots']"
2814703,Is every open interval a union of half open intervals?,"I am reading lower limit topology on Wikipedia, which states that the lower limit topology [...] is the topology generated by the basis of all half-open intervals $[a,b)$, where a and b are real numbers. [...] The lower limit topology is finer (has more open sets) than the standard topology on the real numbers (which is generated by the open intervals). The reason is that every open interval can be written as a (countably infinite) union of half-open intervals. I cannot see how to write $(a,b)$ as a countably infinite union of half-open intervals.",['general-topology']
2814724,Cadlag and adapted imply progressively measurable (related to Protter theorem 6),"I am trying to figure out the proof  of Theorem 6 in Protter's Stochastic Integration and Differential Equations. I have a hunch that what may have been used is the statement in the title. I've seen it used a couple of places already, but I cannot figure out why it is true. For example in this question Measurability of a stopped random variable. , both answers use the statement. As far as I'm aware, cadlag means that ALMOST every path is cadlag. I showed that if a process $X$ has each sample path cadlag and is adapted, then it is progressively measurable by using the the functions $X^n(s,\omega) = X(0,\omega)\mathbf{1}_{\{0\}}(s)+\sum\limits_{k = 1}^{2^n}X(tk/2^n,\omega)\mathbf{1}_{(t(k-1)/2^n, tk/2^n]}(s)$ on $[0,t]\times \Omega$. $X^n$ is $\mathcal{B}([0,t]) \bigotimes \mathcal{F}_t$ measurable and by right continuity, $X^n$ converges everywhere to $X$ on $[0,t]\times \Omega$, so X is progressively measurable. However, if we drop the assumption that $X$ has every path cadlag and instead just almost every path is cadlag (ie $X$ is a cadlag process) we can let $N = \{\omega \in \Omega: X(\cdot,\omega) \text{ is not cadlag}\}$. Then N is a null set. Even if $\mathcal{F}_t$ is complete, $N$ is a measurable null set in $\mathcal{F}_t$ and therefore $[0,t]\times N$ is null in $\mathcal{B}([0,t]) \bigotimes \mathcal{F}_t$. Since $X^n$ converges to $X$ pointwise on $([0,t]\times N)^c$ we have that $X^n$ converges to $X$ almost everywhere. Now, if we don't know that the product measure space ($[0,t] \times \Omega, \mathcal{B}([0,t]) \bigotimes \mathcal{F}_t) $ is complete, then we can't say that the limit $X$ is $\mathcal{B}([0,t]) \bigotimes \mathcal{F}_t$ measurable. So if anyone can clear up my confusion I would be very appreciative. I've been stumped for weeks now. I think that there must be another way to show the result than how I did with the simpler case above using sequences. *Update: In theorem 6 of Protter, I was able to show that regardless of whether $\mathcal{F}_t$ is complete or not, $\mathcal{G}^* = \sigma(\{X_T: X \text{ is everywhere cadlag and adapted to } \{\mathcal{F}_t\}\}) = \{A \in \mathcal{F}: \text{ for each } t \geq 0, A \cap T^{-1}([0,t]) \in \mathcal{F_t}\} = \mathcal{F}_T$ However, I still cannot show the analogue for $\mathcal{F_t}$ satisfying the usual conditions.","['stochastic-processes', 'real-analysis', 'stopping-times', 'measure-theory', 'stochastic-analysis']"
2814734,Can Greatest integer function and limit be Interchanged,"Consider the Limit $$
L_1 = \lim_{x \to 0}\left\lfloor\frac{\sin x}{x}\right\rfloor
.
$$ We have
$$
L_1 = \lim_{x \to 0} \left\lfloor \frac{x-\frac{x^3}{6} + \dots}{x} \right\rfloor
= \lim_{x \to 0}\left\lfloor{1-\frac{x^2}{6}+\cdots}\right\rfloor
.
$$
Now my Doubt is what value we will take for $1-\frac{x^2}{6}$ because as per my knowledge limit cannot be taken inside the Greatest integer function. But where as the Limit $$L_2 = \left\lfloor\lim_{x \to 0}\frac{\sin x}{x}\right\rfloor=0$$ So are the two limits essentially same, if same does not it mean limit and Greatest integer function are interchanged?","['algebra-precalculus', 'ceiling-and-floor-functions', 'power-series', 'limits']"
2814767,How can I deduce the existence of the image set $f(S)$ from the axiom of specification,"Let $f:X\to Y$ be some function and $S\subseteq X$ a subset of its domain. It is clear that the image set $f(S)$ exists, as $$f(S):=\{f(x)\mid x\in S\}=\{y\mid \exists x\in S(f(x)=y)\},$$ and for each $x\in S$, there is at most one $y$ for which $\exists x\in S(f(x)=y)$ holds. Thus, by the axiom of replacement , this set $f(S)$ exists so that
$$z\in f(S)=\{y\mid \exists x\in S(f(x)=y)\}\iff (z\in S \land\exists x\in S(f(x)=z)).$$
Is it possible to deduce the existance of $f(S)$ from the axiom of specification? (because the page on which this axiom appears in my book is not available in the google preview, I will include it here): Axiom. Let $A$ be a set and $P(x)$ some property pertaining to $x\in A$. Then there exists a set $\{x\in A\mid P(x)\}$ such that for any object $y$, 
$$y\in\{x\in A\mid P(x)\}\iff (y\in A\land P(x))$$",['elementary-set-theory']
2814791,Independence of random variables and events,"I was reading text on probability (in discrete mathematics) and there they state that: A set of events $A_1, A_2, \dots A_n $ is mutually independent iff for
  $\forall S \subset [1,n]$: $Pr(\cap_{j\in S}A_j)=\prod_{j\in S}
 Pr(A_j)$. Thus to prove that a set of events is independent we need to consider all the subsets of the set. And when they talked about probability of random variables they stated that: Random variables $R_1, R_2, \dots R_n$ are mutually independent iff
  $Pr(R_1=x_1\cap R_2=x_2\dots R_n=x_n)=\prod_{1\leq i\leq
 n}Pr(R_i=x_i)$ for all $x_1,x_2,\dots x_n$. What I understood is that random variable taking a certain value is in itself an event, however still when checking for mutual independence among random variables, we are not considering all the subsets of the random variables as we did in case of events but we check for all values of $x_i$. Can anyone please explain me why we are doing so?","['independence', 'discrete-mathematics', 'probability-theory', 'probability', 'random-variables']"
2814797,Differential equation $ x y y' = x^2 + ( 1+ a ) y^2 $,"I have to solve this equation, where $ a \in \mathbb R $: $$ x y y' = x^2 + ( 1+ a ) y^2 $$ And I firstly thought about Bernouilli's method : we set $ y^2 = z$
then the equation :
$$ x \frac {z'} z = x^2 + (1+a) z $$ so then the homogenous equation gives :
$$\frac{ z' } { z^2 } = \frac{1+a}{x} $$
so $$ \frac 1 z = \ln ( \frac{1}{ x^{1+a}   })+ cst  $$ It seems already false comparing to the answer I'm suppose to have. Can you tell me where is my mistake and if the substitution recommanded by Bernouilli's is a good idea?",['ordinary-differential-equations']
2814820,$\lim_{x\to\ \frac{\pi}{2}^-}\frac{1}{x-\frac{\pi}{2}}+\tan{x} $,$$\lim_{x\to\ \frac{\pi}{2}^-}\frac{1}{x-\frac{\pi}{2}}+\tan x $$ Can anyone give me a hint I'm struggle. Edit maybe I should say what I've done: I used the following change of variable: $t=x-\frac{\pi}{2}$ so I got: $$\lim_{t\to\ 0^-}\frac{1}{t}+\tan \left(t+\frac{\pi}{2}\right)$$ $$\lim_{t\to\ 0^-} \frac{1+t\tan\left(t+\frac{\pi}{2}\right)}{t} $$ I used B.H and I got something like $\frac{1}{0}$ so it's undefined...,"['calculus', 'limits']"
2814844,Help with Method of Undetermined Coefficients,"Solve the following ODE using the method of undetermined coefficients: $$y''-4y'+4y=(x+1)e^{2x}$$ My work . I have the homogeneous solution:
$$y_h=C_1e^{2t}+C_2te^{2t}$$
I use this function to get the particular solution of the ODE:
$$y=(Ax+B)xe^{2x}$$
And after substitution on the ODE, I get:
$$2A=(x+1)e^{2x}$$
What about $B$? I don't know what I am missing. Could someone give me a hint? Thank you.","['ordinary-differential-equations', 'calculus']"
2814852,"Produce an infinite collection of sets $A_1, A_2, A_3,...$ with the property that [duplicate]","This question already has answers here : Partition of N into infinite number of infinite disjoint sets? [duplicate] (7 answers) Closed 6 years ago . Abbott's Understanding Analysis, Problem 1.2.4 Produce an infinite collection of sets $A_1, A_2, A_3,...$ with the property that every set $A_i$ in the collection: (1) Contains an infinite number of elements, (2) $$A_i \cap A_j = \emptyset, \quad \forall i \neq j,$$ and (3) $$\cup_{i=1}^{\infty} A_i = \mathbb{N}.$$ I am unable to come up with a response. The property that $$\cup_{i=1}^{\infty} A_i = \mathbb{N}$$
implies that these sets can only contain elements of the natural numbers. However, it seems to me difficult to produce an infinite collection of sets that contain infinitely many natural numbers each and that are mutually disjoint. Thank you, for your help. :)","['real-analysis', 'natural-numbers', 'elementary-set-theory']"
2814867,Some properties of convex functions $ g : \mathbb{R} \rightarrow \mathbb{R}$.,"In my lecture we proved Jensen's inequality: For any convex and measurable function $g : \mathbb{R} \rightarrow \mathbb{R}$ and random variable $x \in \mathbb{R}$ , it holds that: $$\mathbb{E}(g(x)) \geq g(\mathbb{E}(x)) $$ Here is our short proof:  Linearize the function $g$ in $\mathbb{E}(x)$ . Note that $g$ is measurable, so the expected value $\mathbb{E}$ doesn't make a problem. We know that $g$ is convex, so there are $s,t \in \mathbb{R} $ with: $g(x) \geq sx + t  \ \forall x \in \mathbb{R}$ and $g(\mathbb{E}(x)) = s\mathbb{E}(x) + t $ .
Now $\mathbb{E}(g(x)) \geq \mathbb{E}(sx+t) = s\mathbb{E}(x)+ t =g(\mathbb{E}(x))$ . So I don't know how to prove why a convex function $g$ is measurable and I don't know how to prove why there are $s,t \in \mathbb{R}$ with $g(x) \geq sx + t  \ \forall x \in \mathbb{R}$ and $g(\mathbb{E}(x)) = s\mathbb{E}(x) + t $ . Here is my attempt : For the first claim : If we want to check measurability of $g$ , we have to check if { $g < \alpha$ } $\in {B}(\mathbb{R}) $ ( Borel - $\sigma$ - algebra ). We know that $g$ is convex, so it holds that: $g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) \  \forall x,y \in \mathbb{R} $ and $ \forall c \in [0,1] $ . If $g(x) \geq \alpha$ ,{ $g < \alpha$ } is the empty set $ \in {B}(\mathbb{R}) $ and if $g(x), g(y) < \alpha$ for some $x,y \in \mathbb{R}$ , we have $ g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) < \alpha$ ? maybe this could help somehow? Moreover I read that the inverse image of a convex function is convex, and thus an interval  (without proof). Maybe this could be useful, if we prove that?  Like you see I really need help here. For the second claim : For all $ x < u < y $ , we have $u = cx + (1-c)y$ with $c = \frac{y-u}{y-x}$ Thus $ g(u) \leq cg(x) + (1-c)g(y) $ , which implies $\frac{g(u)-g(x)}{u-x} \leq \frac{g(y)-g(u)}{y-u}$ . Thus, taking $\sup_{x<u} \frac{g(u)-g(x)}{u-x} \leq s \leq \inf_{u<y} \frac{g(y)-g(u)}{y-u} $ , we have that for all $x < y \in \mathbb{R}$ , $g(x) \geq s(x-u) + g(u) = sx + (g(u)-su)$ . For the second part of the second claim: I need your help again.","['real-analysis', 'measurable-functions', 'convex-analysis', 'statistics', 'probability']"
2814898,Proof of a Combinatorial Abel Identity,"Question Derive the identity
  $$
\sum_{k}\binom{tk+r}{k}\binom{tn-tk+s}{n-k}
\frac{r}{tk+r}=\binom{tn+r+s}{n}\tag0{}$$ This question is from Aigner's A course in Enumeration . Context A construction given prior to this problem is said to be useful in deriving the identity. Namely, any generating function $F(z)=\sum_{n\geq 0}a_n z^n$ with $a_0=1, a_1\neq 0$, defines a polynomial sequence by $\exp(x\log F(z))=F(z)^x=\sum_{n\geq 0}p_{n}(x)z^n$ where $p_n(1)=a_n$ and $p_n(0)=[n=0]$. I showed that $p_n$ is a polynomial of degree $n$ and that
$$
p_n(x+y)=\sum_{k=0}^np_{k}(x)p_{n-k}(y)\tag{1}
$$
as well as
$$
(x+y)\sum_{k=0}^nkp_{k}(x)p_{n-k}(y)=nxp_n(x+y).\tag{2}
$$ My attempt Equation (0) looked like a manifestation of the convolution in (1) with $p_n(x)=\binom{tn+x}{n}$. But I was unable to find an expression for $\sum_{n\geq 0 } \binom{tn+x}{n} z^n$ in closed form. It looks similar to
$$
\sum_{n\geq 0}\binom{n+k}{n}z^n=\frac{1}{(1-z)^{k+1}}
$$
but the $tn$ in the binomial coefficient is throwing me off. Any help with an attempt using the context outlined above is preferred but other solutions are welcome as well.","['generating-functions', 'combinatorics', 'sequences-and-series', 'discrete-mathematics']"
2814982,Understanding a step in Baire Category Theorem,"I have a (probably stupid) question about the Baire Category Theorem. I am looking at the statement that says that in a complete metric space, the intersection of countable many dense open sets is dense in the metric space.
Assume that we have the countable collection of dense open sets $\{U_n\}$ in a complete metric space $X$, and let $x \in X, \epsilon>0$. Since $U_1$ is dense in $X$, there is $y_1\in U_1$ with $d(x,y_1)<\epsilon$. Also, as $U_1$ is open, there is $r_1>0$ with $B(y_1;r_1)\subset U_1$. Then, we can arrange $r_1<1$ such that  $\overline{B(y_1;r_1)} \subset U_1\cap B(x;\epsilon)$. Now my question is why we can arrange that the closure will be contained in each of them? I think intuitively it sounds correct, but I didn't succeed to prove it rigorously. Can you please help me here?","['general-topology', 'metric-spaces', 'baire-category']"
2814984,Interesting result on differential equations : proof that a function nullify itself a infinity times,"I have an amazing exercice to do, and I share it with you. I have one answer, but I understand it only partially, and it sets an intermediary function, that makes the proof  fuzzy. Let $ q : \mathbb R^*_+ \rightarrow \mathbb R^*_+ $, such that
  $\int^{+\infty}_1 q(t) \, dt = + \infty $ Show that the solutions of this differential equation, nullify
  themselves infinity times: $$y''(x) + q(x) y(x) = 0$$ P.S. maybe the expression to nullify themselves infinity times is not english... the idea is that : $| \{x\in \mathbb R\mid f(x)=0\}| =\infty$ My attempt : I tackle the problem in this way :
I assume by absurdo that the solution of the differential equation vanishes only a finite times. Thus, since one point (called $a$), the solution is of constant sign. WLOG the solution is positive since one point. 
Then we set the function : $$z(x) = - \frac {y'(x)}{y(x)} $$
we have that : $$ z'(x) = q(x) + z^2(x)$$
So $$ \forall x > a, z(x) = z(a) + \int_a^x z'(t) dt \geq z(a) + \int_a^x q(t) dt > + \infty$$
So $$ \exists b > a, z(b) > 0 $$ 
Thus finally : $$y'(b) = y(b) z(b) < 0.$$",['ordinary-differential-equations']
2814999,On the positivity of the distance between two disjoint ellipsoids,"Let closed convex sets $P_1$ and $P_2$ be defined as follows $$P_i := \{ x \in \Bbb R^n  : x^\top A_i x + b_i^\top x + c_i \leq 0  \}$$ where $A_1$ and $A_2$ are positive semidefinite matrices. Assume $P_1 \cap P_2 = \emptyset$ . Prove (or provide a counter-example) that $$d(P_1 , P_2):= \inf \{ \|x-y\| \; | \; x \in P_1 ,~ y \in P_2  \}  >  0$$","['real-analysis', 'convex-optimization', 'convex-analysis']"
2815079,"How to prove statements in formal set theory? Substitution, the empty set and an example.","I would like to better understand how to formally prove a statement in the first order axiomatic set theory or ZFC. One example of an axiomatization can be found here . There are a few issues. First, what can be substituted in place of the variables and how (when eliminating the $\forall$ quantifiers)? I read that the empty set is a constant of the language but on some sources it isn't. Which is the case? This becomes even more confusing when starting to think about how the theory proves (or has an axiom) that the empty set indeed exists. What is the meaning of this if the empty set is indeed a constant... If the empty set is a constant, is there a reason why axiom such as $\forall a\space a\notin\emptyset$ is not in place. If it isn't a constant, what actual formula does $a\in\emptyset$ stand for (used in axiom of infinity for example)? Is the natural deduction proof calculus suitable for the task? Especially I would like an example. How would a proof demonstrating the existence of the set $\{\emptyset\}\cup{\emptyset}$ be conducted. Informally one possible proof is: by the axiom of empty set there exists an empty set. The power set of the empty set is the set with only the member empty set. By the axiom of union/pairing the union of these two sets exists. \begin{align}
 (1) &\exists X\forall y \space (y\notin X) && [\text{Ax. EmptySet}] \\
 (2) & \forall X\exists Y\forall Z \space (Z\in Y\leftrightarrow\forall z(z\in Z\land z\in X)) && [\text{Ax. Powerset}] \\
 (3) & \forall x\forall y\exists Z \forall z \space (z\in Z \leftrightarrow z=x \lor z=y) && [\text{Ax. Pairing}] \\
 (4) & \forall X \forall Y \space (X=Y \leftrightarrow \forall z (z\in Y \leftrightarrow z \in X))                                       && [\text{Ax. Extensionality}] \\
(5) & \forall X \exists Y \forall y \space (y\in Y \leftrightarrow  \exists Z( Z\in X \land y\in Z)) && [\text{Ax. Union}   ] \\
(6) &  && [\text{} ] \\
(7) &  && [\text{} ] \\
(8) &  && [\text{} ] \\
(9) &  && [\text{} ] \\
(10) &  && [\text{} ] \\
(11) &  && [\text{} ] \\
(12) &  && [\text{} ] \\
\end{align}","['first-order-logic', 'elementary-set-theory', 'proof-theory']"
2815092,"Computing $e^{tA}$, where $A$ is a matrix","Given $$A = \begin{bmatrix} 0&-1\\1&0\end{bmatrix}$$ find $e^{tA}$, where $t \in \mathbb{R}$. I have read about calculating the matrix exponential here . I know that when $A$ is written in its diagonal form it's kind of easy. The same with nilpotent matrices. Unfortunately, I don't know how to deal with $t$. Especially when the eigenvalues are complex (in the given example they are).","['matrices', 'matrix-exponential', 'exponential-function']"
2815097,"A sequence of closed bounded (not necessarily nested) intervals $I_1, I_2, I_3,...$ with the property that","Abbot's Understanding Analysis Problem 1.4.8 (d) If the following statement is possible, give an example; if it is not, provide a compelling argument as to why it is not possible. A sequence of closed bounded (not necessarily nested) intervals $I_1, I_2, I_3,...$ with the property that (1) $$\cap_{n=1}^{N} I_n \neq \emptyset, \quad \forall N \in \mathbb{N},$$ and (2)$$\cup_{n=1}^{\infty} I_n = \emptyset.$$ It seems to me that the statement is not possible. I considered the sequence of nested intervals $(0,1/n]$ for all $n \in \mathbb{N}.$ I know that this does not satisfy the given conditions (it is not closed), but I went through it simply as an exercise. This sequence of open intervals would satisfy both conditions. Since the sequence of intervals must all include zero (as each interval must be closed), it would not otherwise satisfy the properties. Does the falsity of the statement have anything to do with the properties of open and closed intervals? I tried considering sequences of intervals that were not nested, yet was unable to produce such a sequence that would satisfy both properties. If the statement is not true, would you give an complete explanation as to why it is impossible? It would seem to me (if it is not true) that it has something to do with the fact that the intervals are closed . Moreover, it seems to me that a sequence that fulfills both properties cannot be nested, as for all nested, closed sequences of intervals, $$\cup_{n=1}^{\infty} I_n \neq \emptyset.$$","['real-analysis', 'elementary-set-theory']"
2815104,Annihilator of a vector space $V$ is the zero subspace of $V^*$,"I am reading Hoffman and Kunze's Linear Algebra and in Section 3.5, page 101, they define the annihilator of a subset as follows: Definition. If $V$ is a vector space over the field $F$ and $S$ is a subset of $V$, the annihilator of $S$ is the set $S^0$ of linear functionals $f$ on $V$ such that $f(\alpha) = 0$ for every $\alpha$ in $S$. In the following paragraph, they say that If $S = V$, then $S^0$ is the zero subspace of $V^*$. (This is easy to see when $V$ is finite-dimensional.) My question is regarding the statement within the parentheses. Is there some subtlety when considering infinite-dimensional vector spaces? Below is my proof of the fact that $S^0 = \{ 0 \}$ when $S = V$. Let $S = V$. If $f \in V^*$ is a non-zero functional, then $f(v) \neq 0$ for some $v \in V = S$. So, $f \not\in S^0$. So, $S^0 \subseteq \{ 0 \}$. Also, if $0$ is the zero functional, then it maps every $v \in V = S$ to $0$, and so $\{ 0 \} \subseteq S^0$. Hence, $S^0$ is the zero subspace of $V^*$. I don't see where the dimension of $V$ plays a role in the above proof. Is the statement given within the parantheses redundant, or am I missing something crucial in understanding the case $\dim V = \infty$?","['abstract-algebra', 'linear-algebra', 'linear-transformations', 'dual-spaces']"
2815193,Every $L^2$ function is the divergence of a $L^2$ vector field,"As in the title, I am struggling with the following statement: For any  $f\in L^2(\mathbb R^n)$ there exists a vector field $F\in L^2(\mathbb R^n, \mathbb R^n) $ such that $f=div F$. Apparently this should follow from the Hodge decomposition... Any help appreciated!","['functional-analysis', 'hodge-theory', 'divergence-operator', 'partial-differential-equations']"
2815227,"Is there any counterexample to show that $X,Y$ are two random variables and $E(X\mid Y)=E(X)$, but $X$ and $Y$ are not independent.","Is there any counterexample to show that $X,Y$ are two random variables and $E(X\mid Y)=E(X)$, but $X$ and $Y$ are not independent. I already know that if $X,Y$ are independent, then $E(X\mid Y)=E(X)$.","['probability-theory', 'conditional-expectation', 'probability', 'expectation']"
2815229,Basic Geometry: Triangles,"I'm trying to find an easy way to solve the problem below: Of course you could solve it by ""brute force"", example: - numerical means (vectors and dot product), or - long algebra calculations (law of sines/cosines and trigonometric identities). However, considering this was a question in a high school exam (3~5 min per question), most likely there is a shortcut. Any idea?",['geometry']
2815230,"How are both of these true: $J = \nabla f ^T $, and also $\nabla f = J^T f$?","From questions such as this one: Gradient and Jacobian row and column conventions I understand that for cases where $f$ maps from $\mathbb{R}^n$ into $\mathbb{R}$ , i.e. $f: \mathbb{R}^n \rightarrow \mathbb{R}$,  the transpose of the gradient is equal to the jacobian:  $J = \nabla f ^T $.  Again, see Gradient and Jacobian row and column conventions as my resource. However, I am still occasionally confused by this, because when finding an expression of the gradient for when $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ I see expressions such as $\nabla f = J^T f$.   An example of this is in Nocedal and Wright, first edition on page 260: Question is how are both of these true:  $J = \nabla f ^T $, and also $\nabla f = J^T f$ ?","['derivatives', 'differential', 'gradient-descent', 'jacobian', 'differential-geometry']"
2815244,Is this a correct construction of the underlying sets of free semigroups?,"Question: Is the following a correct formal construction of the set of ""strings""/""words"" used in the construction of free semigroups? (And free monoids and free groups?) Define for all $n \ge 1$ the set $[n]:= \{1, 2, \dots, n\}$ and $[0]:= \emptyset$. In what follows, use exponential notation for function spaces, i.e. the space of all functions $X \to Y$ is denoted $Y^X$. Claim: The underlying set (i.e. I am not yet addressing the definition of multiplication) of the free semigroup generated by the elements of an arbitrary set $X$ can be taken to be: $$\bigcup_{n \ge 1} X^{[n]}  $$ (Should this be a disjoint union instead of a union? There is no set of all sets, and I haven't explicitly identified a common superset of all of the $X^{[n]}$.) Correspondingly I also claim that the underlying set of the free monoid generated by the elements of an arbitrary set $X$ can be taken to be: $$\bigcup_{n \ge 0} X^{[n]} $$ There is exactly one function $\emptyset \to X$. My implicit claim is that we can sensibly identify the empty function with the empty string. Multiplication would of course then just be ""concatenation"", but precisely defining that is annoying especially when the underlying idea is so much simpler than all of the constructions I can think of, so I will ""leave it as an exercise for the reader"". Mostly I'm just interested in whether or not this is a standard construction of the set of all strings, or if there are better, more sensible ways to do it/think about it. The underlying sets for free monoids and as a special case free abelian groups are given precise constructions in the sources I've read, but the same was not true for free semigroups/free monoids/free groups. (For free groups one could replace $X$ with $X \times X$ or something like that.)","['abstract-algebra', 'elementary-set-theory']"
2815252,Is $\mathbb Q$ a quotient of $\mathbb R[X]$?,Is there some ideal $I \subseteq \mathbb R[X]$ such that $\mathbb R[X]/I \cong \mathbb Q$? $I$ is clearly not a principal ideal.,"['abstract-algebra', 'real-numbers', 'ring-theory', 'rational-numbers', 'field-theory']"
2815263,How to label the events in a probability problem?,"I'm starting a statistics and probability class and it's still pretty hard for me to ""name"" my probability events, which I think makes it very difficult to solve problems. I'll pick an example from my exercises to illustrate my problem : We asked 1000 persons which magazines do they regularly read between magazine A, B and C. We obtained the following results : 60% read A, 50% read B, 50% read C. There are 20% which read B and C, 30% read A and C and 30% read A and B. There is 10% of the 1000 persons who read the 3 magazines. Given one person, calculate the probability that this person: Reads A or C. Doesn't read a magazine at all Reads A but not B Reads only one magazine. So, in this example the events were labelled : A = {Probability that this person reads A} B = {Probability that this person reads B} C = {Probability that this person reads C} If this were an exercise, I might have started by naming the probability event according to the question so : X = {Probability that this person read's A or C} Y = {Probability that this person doesn't read a magazine} etc.. or something like that. I would have messed around for a while, not being able to find the answer, and at some point I would have figured out the events like they are labelled in the example. I know that this example is pretty easy to figure out, but in more complex exercices I find it difficult to label the events properly. IMO, it's kind of like not being able to identify variables properly in an algebra problem. Without proper variables it's impossible to figure out the answer. So, I'm sure there's a ""way to follow"" in order to label the events in a probability problem and I would like to find out what it is. Edit For my current problem, there are three cards. One with a red face, red background. The other with a red face, black background and the last with black face black background. I need to find the probability that given a picked card where the face is red, the background is black. I am not looking for answers to the problem I'd just like to know how I'm supposed to figure out what should be the labels to my events. One per card? One per face color?","['probability', 'elementary-probability']"
2815268,Proving an analytic function $f$ is bounded on $|z|\le1/2$ independent of $f$ subject to certain conditions,"Let $f:D(0,1) \to \mathbb C$ be analytic. Show that there is a constant $C$ independent of $f$ such that if $f(0)=1$ and $f(z) \notin (-\infty,0]$ for all $z \in D(0,1)$, then $|f(z)| \le C$ whenever $|z| \le 1/2$. I have (finally) figured out how to prove this, and I ended up with $C=9$. I am curious what the “best” bound is though, and what the best approach would be for proving this. In other words, what is the supremum of all analytic functions $f$ on $|z|\le 1/2$, subject to the two conditions above?",['complex-analysis']
2815283,"Integral from yesterdays test: $\int_0^\pi {{1+\sin^2x}\over{6-\cos^2x+\left|\cos x\right|}} \sin x \cdot x \, dx$","This was the integral we had on the test yesterday: $$\int_0^\pi {{1+\sin^2x}\over{6-\cos^2x+\left|\cos x\right|}} \sin x \cdot x \, dx$$ None of my friends including me managed to solve it. Does anyone know how to solve this integral? I tried literally everything but couldn't manage to solve it ... By the way, do you think that this integral is way too hard to be on the test? (First year of college, 90 min test )","['integration', 'definite-integrals', 'calculus']"
2815309,Can we say $\lim_{x \to 0} \frac{\sin x}{x} $ exactly $1$,"Can we say $$\lim_{x \to 0} \frac{\sin x}{x} $$ is exactly equal to $1$ I got this doubt while solving the limit $$\lfloor\lim_{x \to 0}\frac{\sin x}{x}\rfloor$$ because as per my knowledge $\lim_{x \to 0} \frac{\sin x}{x}$ approaches $1$ from below hence $$\lfloor\lim_{x \to 0}\frac{\sin x}{x}\rfloor=0$$ But some books give it as $1$, so what exactly is the concept here?","['algebra-precalculus', 'derivatives', 'limits']"
2815314,"Switching ""For all $\epsilon$, there exists $\delta$, ..."" to ""For all $\delta$, there exists $\epsilon$, ..."" in the definition of function's limit [duplicate]","This question already has answers here : What's wrong with this ""backwards"" definition of limit? (5 answers) Closed 6 months ago . Formal accepted definition: For all $\epsilon >0$, there exist $\delta >0$ such that if $0<\vert x-a\vert<\delta$, then $\vert f(x)-L\vert<\epsilon$. The other statement: For all $\delta >0$, there exist $\epsilon >0$ such that if $0<\vert x-a\vert<\delta$, then $\vert f(x)-L\vert<\epsilon$. I know that in quantifier logic, switching quantifiers might change the statement itself, but both of the above statements seem non-contradicting to me so must it be the same?","['definition', 'real-analysis', 'limits']"
2815336,is function convex?,"Suppose that $a_i$ has a normal distribution with mean $E(a_i)$ and variance $var(a_i)$ ,  we have for  $\sum_{i=1}^n a_i x_i $ , $$E (\sum_{i=1}^n a_i x_i) = \sum_{i=1}^n E(a_i) x_i,$$ and $$var (\sum_{i=1}^n a_i x_i)=\sum_{i=1}^n var(a_i) x_i ^2 +2\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} cov(a_i,a_j)x_ix_j,$$ where $cov(a_i,a_j)x_ix_j$  is a covariance. Is this function convex ? $$\sqrt{ \sum_i x_i ^2 var(a_i)+ 2 \sum_{i=1}^{n-1} \sum_{j=i+1}^{n}cov(a_i,a_j)x_ix_j  +  \sum_{i=1}^n E(a_i) x_i } $$","['nonlinear-optimization', 'optimization', 'convex-analysis', 'functional-analysis', 'convex-optimization']"
2815426,Why is the spectral norm of a weighting matrix for a Hopfield network less than or equal to $1$?,"We define weighting matrix $W$ as follows $$W := \frac{1}{Md}\left[\sum_{m=1}^{M}x^{(m)}(x^{(m)})^{T}\right] - \frac 1d \Bbb I_d$$ where $\Bbb I_d$ is the $d \times d$ identity matrix and $x^{(m)} \in \{\pm 1\}^d$. Why is $\| W \|_2 \leq 1$? For reference, the claim that $\| W \|_2 \leq 1$ is made on page 4 here , on the bottom left.","['matrices', 'normed-spaces', 'neural-networks', 'linear-algebra']"
2815429,Proof that the number of proofs is countably infinite,"I think that the number of mathematical statements is countably infinite, since each statement is a finite string of finitely many symbols, but i am not sure how to prove it.
Once i prove that, i can say that a every math proof with $n$ steps is a subset of the cartesian product $A^n$ where $A$ is the set of all mathematical statement, and each element in the resulting set is a statement that is a step in the proof.
Since the cartesian product of countably infinite sets is countably infinite, then the set of all proofs with $n$ steps is countably infinite, for any $n$.
How can i prove that the number of mathematical statements is countably infinite, and is the rest of the proof correct?","['cardinals', 'elementary-set-theory']"
2815436,Can someone explain to me how we derive the alternative form of Bayes theorem?,"I understand how we get this formula $$\Pr(H\mid E) = \frac{\Pr(H)\Pr(E\mid H)}{\Pr(E)}$$ from the fact that  $\Pr(H\cap E)$ is equal to both $\Pr(H)\Pr(E\mid H)$  and  $\Pr(E)\Pr(H\mid E),$ and solving for $\Pr(H\mid E).$ But how do we go from the denominator in the boldfaced formula to this new denominator below $$\Pr(E) =\Pr(H)\Pr(E\mid H)+\Pr(\bar H)\Pr(E\mid \bar H)$$ ? Please explain it to me like I'm ten years old.  I'm new to Bayes and learned the above after going over Venn diagrams several times, so break it down for me. Thanks so much.","['bayes-theorem', 'probability']"
2815438,Finding the last two digits of the given number.,"Question : Given $N=2^5+2^{{5}^{2}}+2^{{5}^{3}}+2^{{5}^{4}}... 2^{{5}^{2015}}$ Written in the usual decimal form, find the last two digits of the number $N$. My attempt : We know that every exponential number repeat its last,last two,last third , $\ldots$ digits. For eg.: unit digits of $3^n$ repeats itself as $3,9,7,1,3,9,7,1...$ On applying this for last two digits of $2^n$ we get $02,04,08,16,32,64,28,56,12,24,48,96,92,84,68,36,72,44,88,76,52$ and $04,08...$ again. This repetitive series has $21$ numbers with first one(i.e.$1$) occurring only once. Also all $n$ in $2^n$; $5,125,625...$ when divided by $20$ give $5$ as remainder so the last two digits will be $32,16,16,16...16$ with $16$ occurring $2014$ times which gives $32+32224=32256$ which means last two digits will be $56$ but when doing the same for last digit, I get $0$ which is a contradiction. I can't find what mistake I did. Thanks for finding my mistake.","['algebra-precalculus', 'contest-math', 'natural-numbers', 'elementary-number-theory']"
