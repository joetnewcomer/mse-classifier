question_id,title,body,tags
191695,"If $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ has coordinates $f^1 \ldots f^m$, and each $f^i$ is differentiable at $0$...","...then does it follow that $f$ is differentiable at 0? My motivation for asking this is as follows: in Spivak's Calculus on Manifolds, in theorem 2.9, he uses this with the additional condition that each $f^i$ is continuously differentiable in a nbh of 0, to conclude that $f$ is differentiable and I don't think is necessary. Namely, if each $f^i$ has derivative $Df^i$, I claim the matrix with $i^{th}$ row $Df^i$ will serve as $Df$. Indeed, let $v_j$ be a sequence tending to 0 in $\mathbb{R}^n$,  we have (by the triangle inequality, if you wish)$$\frac{| f(v_j) - f(0) - \sum_i Df^i(v) |}{|v_j|} \leqslant \frac{\sum_i |f^i(v_j) - f^i(0) - Df^i(v_j)|}{|v_j|}$$Taking the limit as $j \rightarrow \infty$, each summand goes to 0 by the differentiability of $Df^i$ (and there's only $m$ of them), hence the limit is 0. Is this wrong? Thanks in advance! EDIT: btw, conditional on the above proof being right and/or the claim being right, does anyone know maybe what Spivak was going for?",['multivariable-calculus']
191711,How many rows and columns are in an m x n matrix?,"A simple question: By definition, does an m x n matrix have m rows and n columns, or is it vice versa?",['matrices']
191736,Help with integrating $\int_0^{\infty} \frac{(\log x)^2}{x^2 + 1} \operatorname d\!x$ - contour integration?,"George Arfken's book: Mathematical Methods for Physicists has the following problem in a chapter on contour integration: $\displaystyle \int_0^{\infty} \dfrac{(\log x)^2}{x^2 + 1} dx$. Their suggestion is to make the substitution $x \rightarrow z=e^t$. I'm not sure what they meant by this, but I tried making the substitution $x = e^t$, which turns the integral into: $\displaystyle\int_{-\infty}^{\infty} \dfrac{t^2 e^t}{1+e^{2t}} dt$. The hint is then to take the contour from -R to R, to R+$\pi i$, to -R + $\pi i$, to -R. Since this has a pole at $t = \pi i/2$, a Laurent series expansion about this point gives the residue as $i \pi^2/8$, so the contour integral equals $-\pi^3/4$. I've been able to show that the integral along R to R + $\pi i$ and along -R + $\pi i$ to -R goes to zero by the ML inequality - the denominator grows exponentially but the numerator quadratically. But at this point, I'm a bit lost as to what to do with the integral over Im $t = \pi$. Any help? The book gives the answer as $\pi^3 /8$.","['complex-analysis', 'contour-integration']"
191738,Help evaluating a limit,"I have the following limit: $$\lim_{n\rightarrow\infty}e^{-\alpha\sqrt{n}}\sum_{k=0}^{n-1}2^{-n-k} {{n-1+k}\choose k}\sum_{m=0}^{n-1-k}\frac{(\alpha\sqrt{n})^m}{m!}$$ where $\alpha>0$. Evaluating this in Mathematica suggests that this converges, but I don't know how to evaluate it.  Any help would be appreciated.","['summation', 'exponential-function', 'binomial-coefficients', 'limits']"
191741,Existence of T-invariant complement of T-invariant subspace when T is diagonalisable,"Let $V$ be a complex linear space of dimension $n$. Let $T \in End(V)$ such that $T$ is diagonalisable. Prove that each $T$-invariant subspace $W$ of $V$ has a complementary $T$-invariant subspace $W'$ such that $V= W \oplus W'$. Note: Let $\{e_1,...e_n\}$ be the set of eigenvectors together with eigenspaces $V_{\lambda_1},...V_{\lambda_n}$ of $T$. It's sufficient to show that every $T$-invariant subspace $W$ must be a direct sum of eigenspaces, then it'll be trivial to find $W'$ (just take the rest eigenspaces not in the direct sum and glue them to $W$).. But how to prove $W$ is a direct sum of eigenspaces?",['linear-algebra']
191747,How to find eigenvector of one second order differential equation for Hermit?,"After read http://math.tut.fi/~piche/pde/pde.pdf , do not know how to calculate eigenvector How to find eigenvector of one second order differential equation? why some people use sin as eigenvector? is it only sin can be eigenvector? The problem is for eigenfunction expansion, 
first step is finding eigenvalue and eigenvector, 
but do not know how to calculate eigenvector for differential equation for example
Maple code x*diff(f(x), x$2) + 2*x*diff(f(x),x) + f(x) = 0
    x*diff(f(x), x$2) + 2*x*diff(f(x),x) + x = 0 Updated sol := dsolve(t*diff(phi(x),x$2)-x*diff(phi(x),x)+n*phi(x),phi(x));
phi := unapply(rhs(sol), x);
BC := [phi(0)=0,phi(1)=0];
with(linalg):
Ccoef := genmatrix(BC, [_C1,_C2]);
CharEqn := det(Ccoef) = 0;

restart;
sol := dsolve(t*diff(phi(x,t,n),x$2)-x*diff(phi(x,t,n),x)+n*phi(x,t,n),phi(x,t,n));
phi := unapply(rhs(sol), x);
BC := [phi(0,0,0)=0,phi(1,1,1)=0];
with(linalg):
Ccoef := genmatrix(BC, [_C1,_C2]);
CharEqn := det(Ccoef) = 0; **sorry only Sunday have time to seriously read this file,
i find the sin function coming from the step of calculating characteristic equation
use pdf file's method to calculate above differential equation for eignvector, this equation is Hermit
after tried, characteristic equation is zero, it imply no eigenvector
i guess this calculation maple code has something wrong how to calculate this?** Updated 2 Originally i expect to find Hermit H(x) and then use sum(H*z^m/m!, m=0..infinity) to
find a A*exp(B) where B is in term of z and t and it is just a simple formula
now following the steps, i guess the H is the solution of green function about the expansion it become more compicated for H(x), and i find there is a D[2] but do not know where it come from.
then do not know which step is H(x), i just guess vterm or vv sol := dsolve(t*diff(phi(x),x$2)-x*diff(phi(x),x)+n*phi(x),phi(x));
phi := unapply(rhs(sol),x);
odetest(sol,ode);
eq1:=limit(rhs(sol),x=0,right)=0;
eq2:=eval(rhs(sol),x=1)=0;
Ccoef := LinearAlgebra:-GenerateMatrix([eq1,eq2],[_C1,_C2]);
CharEqn:=LinearAlgebra:-Determinant(%[1])=0;
solve(CharEqn,t);
step1 := map(xi->simplify(subs(t=RootOf(KummerM(1/2-(1/2)*n, 3/2, 1/(2*_Z))),xi)),Ccoef);
with(linalg):
NN := nullspace(step1);
subs(_C1=NN[1][1],_C2=NN[1][2],t=RootOf(KummerM(1/2-(1/2)*n, 3/2, 1/(2*_Z))),phi(x));

phi := (n,t,x) -> KummerM(1/2-(1/2)*n, 3/2, (1/2)*x^2/RootOf(KummerM(1/2-(1/2)*n, 3/2, 1/(2*_Z))))*x;

assume(j,posint):
interface(showassumed=0):
Gterm := unapply(-phi(n,t,x)*phi(n,t,x)*exp(-lambda(j)*t)/int(phi(n,t,x)^2,x=0..1),(j,n,x,y,t)):
G:=Sum(Gterm(j,n,x,y,t),j=1..infinity);
vterm := int(D[2](Gterm)(n,1,x,t-tau),tau=0..t);
vv := sum(Sum(op(n,vterm),j=1..infinity),n=1..2);","['ordinary-differential-equations', 'partial-differential-equations']"
191752,What's umbral calculus about?,"I've read Wikipedia about it and it says: In mathematics before the 1970s, the term umbral calculus referred to
  the surprising similarity between seemingly unrelated polynomial
  equations and certain shadowy techniques used to 'prove' them. What are these techniques? These similarities allow one to construct umbral proofs, which, on the
  surface cannot be correct, but seem to work anyway. What does ""seem to work"" mean here? It seems that umbral calculus is a mathematical idea with almost no uses, why? (At least it's not so famous as calculus and algebra, for example.)","['umbral-calculus', 'calculus']"
191775,Inequality for Fourier transform of measure,"I am having trouble with the following question. Let $\mu$ be finite measure on $\mathbb{R}$ and let 
$\hat{\mu}(\xi) = \int_{-\infty}^\infty e^{-ix \xi} d\mu(x)$ be its Fourier transform. Prove that $$|\mu(\{x\})| \le \limsup_{|\xi| \rightarrow \infty} |\hat{\mu}(\xi)|$$","['limsup-and-liminf', 'measure-theory', 'fourier-analysis', 'analysis']"
191786,Does this multivariate integral make sense and can it be evaluated?,"I have very hard instructor for multivariate calculus. He ask if the next integral is well-defined. $$ \iint\limits_D\,{\cos(z)\sin^3(z)\cos(y)\sin(y)\over (\cos^2(z)+\sin^2(z)\cos^2(y))(\cos^2(z)+\sin^2(z)\cos^2(y)-b)}\,dy\,dz $$ $D$ is the region $[0,\pi] \times [0,\pi]$ and $b \in (0,1]$. Is it possible to calculate integral with Mathematica or by hand for all $b$? I consider this an improper integral. For $b=1$, the free version of Wolfram Alpha says that the integral is $0$, but it is not strong enough to calculate the integral for general values of $b$.","['multivariable-calculus', 'integration']"
191791,"Showing $H=\langle a,b|a^2=b^3=1,(ab)^n=(ab^{-1}ab)^k\rangle$.","Let $G=\langle a,b|a^2=b^3=1,(ab)^n=(ab^{-1}ab)^k \rangle$ . Prove that $G$ can be generated with $ab$ and $ab^{-1}ab$ . And from there, $\langle(ab)^n\rangle\subset Z(G)$ . Problem wants $H=\langle ab,ab^{-1}ab \rangle$ to be $G$ . Clearly, $H\leqslant G$ and after doing some handy calculation which takes time I've got: $ab^{-1}=(ab^{-1}ab)(ab)^{-1}\in H$ $b=b^{-2}=(ab)^{-1}ab^{-1}\in H$ $a=(ab)b^{-1}\in H$ So $G\leqslant H$ and therefore $G=H=\langle ab,ab^{-1}ab\rangle$ . For the second part, I should prove that $N=\langle(ab)^n\rangle\leqslant Z(G)$ . Please help me. Thanks.","['combinatorial-group-theory', 'group-theory', 'group-presentation']"
191796,Expansion of $\bigl(\sum x_i\bigr)^4$,Show that $$(\sum_{i=1}^n X_i)^4=\sum_{i=1}^n X_i^4+4\sum_{i\neq j}^n X_i^3X_j+3\sum_{i\neq j}^n X_i^2X_j^2+6\sum_{i\neq j\neq k}^n X_i^2X_jX_k+\sum_{i\neq j\neq k\neq l}^n X_iX_jX_kX_l$$ Please show it step by step.Thanks in advance.,['algebra-precalculus']
191800,Characterize finite dimensional algebras without nilpotent elements,"Characterize all finite dimensional algebras (may not be commutative) over a field $K$ without nilpotent elements. My condition: Let $A$ be any algebra (may not be finite dimensional), then it's easy to prove that $A$ has no nilpotent elements iff the equation $x^2=0$ has a unique solution (the trivial solution). But is there a more explicit characterization of these finite dimensional algebras?","['noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
191820,Adjoint of forgetful functor between category of vector spaces and category of abelian groups,"I've just found out about the forgetful functor between the category of vector spaces and the category of abelian groups . It maps a vector space to it's additive abelian group. My question is, is there an adjoint of this forgetful functor, and if so what is it? If we considered the forgetful functor between the category of vector spaces and the category of sets that forgets all structure, I think the adjoint functor would take a set and create a generic free vector space generated by the elements of the set. However, when forgetting only to the level of an abelian group, there still retains some additional structure, so I don't think it's that simple. For example, just by looking at the additive group, you know $v$ and $v+v$ are related by the scalar multiplication $v+v=2v$. Similarly, one could deduce that rational combinations like $6v$ and $9v$ are related through multiplication, since there would exist an element $3v$ that can be added to itself several times to create both. On the other hand, just by looking at the additive structure, I think there is no way to tell that $v$ and $\pi v$ were once related since $\pi$ is irrational.","['vector-spaces', 'category-theory', 'abstract-algebra', 'abelian-groups']"
191837,Zeros of a solution between successive zeros of another solution,"Let $q$ be a real valued non-trivial solution solution of 
$$
y'' +A(x)y = 0 \text{ on } a<x<b,
$$ 
and let $w$ be a real valued non-trivial solution of 
$$
y'' + B(x)y = 0 \text{ on } a<x<b.
$$ 
Here $A$ and $B$ are real valued continuous functions satisfying 
$$
B(x)>A(x) \text{ for } a<x<b.
$$ 
How to show that if $x_1$ and $x_2$ are successive zeros of $q$ on $(a,b)$, then $w$ must vanish at some point $p \in (x_1, x_2)$? Partial answer: Let $q, w>0$ on $(x_1, x_2)$,then with $(wq'-qw')'= (B-A)qw$, and by integration from $x_1$ to $x_2$ we get $w(x_2)q'(x_2)-w(x_1)q'(x_1)> 0$. Somehow I want to show that that $q'(x_1)< 0$ or $q'(x_2)>0$, which will then contradict $q > 0$ on $(x_1, x_2)$",['ordinary-differential-equations']
191842,Integrating Out,"In probability integrating out a variable is viewed as marginalization; One probability function turns into another probability function. In other cases and fields, taking a regular function as example, for example $f(x,y)$, when I integrate out $y$, $$
\int_{-\infty}^{\infty}f(x,y)dy
$$ which would give me a function based on only $x$. My question: question is when would this particular way of summarizing necessary (other than probability)? What are the common places this is used? Another one: can I call this function $f(x)$? It seems like the answer is no because I am not realy getting ""the value of $f$ for $x$""; I believe I get a different function, and I lose some information,and lose it in a particular way. Thanks,","['calculus', 'functions']"
191845,Compute $\lim_{x\to0} \frac{\cosh x\cosh 2x\cosh 3x \cdots \cosh nx-1}{x^2}$,Compute: $$\lim_{x\to0} \frac{\cosh x\cosh 2x\cosh 3x \cdots \cosh nx-1}{x^2}$$ How would you tackle this problem? Thanks.,"['calculus', 'real-analysis', 'limits']"
191848,Reference requested: 'decomposition' of Haar measure on the adeles.,"Since the adeles $\mathbb{A}$ (with addition) are a locally compact Hausdorff topological group there exists a Haar measure $\mu$. Now people claim that it can be normalized such that for every function of the form $f = \prod_p f_p$ such that $f_p = \mathbb{1}_{Z_p}$ for almost all $p$ and $f_p$ integrable for all the rest, one has $$\int_{\mathbb{A}} f = \prod_p \int_{Q_p} f_p(x_p) dx_p$$ where $dx_p$ is the additive Haar measure on $Q_p$, normalized such that the measure of $Z_p$ is one (the lebesgue measure up to some factor for $p=\infty$ respectively). My question is: why is this the case? In one of the books i tried to find the answer in, the author proceeds as follows: he defines simple sets to be sets of the form $M = \prod_p M_p$ where $M_p = Z_p$ for almost all $p$ and $M_p = U_p$ is open in $Q_p$ for all the rest. Then he defines another measure $\nu(M) := \prod_p \mu_p(M_p)$ where $\mu_p$ is the additive Haar measure on $Q_p$. Since simple sets are stable under finite intersections, one can continue this to a measure on the whole Borel-$\sigma$-algebra. The question here is: why is it a Radon measure, i.e. one has to show that $\nu(K) < \infty$ for compact $K$ and that it is outer regular for all borel sets and inner regular for open sets and sets of finite measure. How to do that? I guess that there is a better way to achieve this by starting with the abstract nice measure $\mu$ and then show that the relation above holds up to a factor. Does somebody know where to find that or can somebody point out a basic reference for the construction of the Haar-measure on the adeles? Thanks, Fabian Werner","['p-adic-number-theory', 'analysis']"
191849,Uniqueness of Weak Limit,As we know that weak limit of a sequence of Borel probability measures on metric space is unique. Do we have this property for general sequence of signed Borel measures on metric space? Thank you.,"['measure-theory', 'convergence-divergence', 'limits', 'analysis']"
191855,$ K(G)=3 \Longrightarrow G\cong\mathbb Z_3\ \mathrm{or} \ G\cong S_3$,"According to J.S. Rose book ""A Course on Group Theory"": In class equation $$|G|=\sum_{i=1}^k|G:C_G(x_i)|$$ where $x_1,x_2,...,x_k\in G$ one from each of above $k$ classes; $K(G)$ is called the class number of $G$. Now I want to verify: $$ K(G)=3 \Longrightarrow G\cong\mathbb Z_3\ \mathrm{or} \ G\cong S_3$$ If $K(G)=3$ then I see $|Z(G)|=1$, $|Z(G)|=2$ or $|Z(G)|=3$. $|Z(G)|=3$ leads $G$ to be abelian so I have $G\cong\mathbb Z_3$. If $|Z(G)|=2$ so I have an element, say $x$, in $G$ which doesn't belong to its center. Therefore $d=|G:C_G(x)|\big|\ |G|$ and so $d=1$ or $d=2$. It is clear to me that these two make contradictions. I see myself very close to $S_3$ when $|Z(G)|=1$. Please, if I am on a right way help me about the final choice $|Z(G)|=1$. Thanks","['finite-groups', 'group-theory']"
191862,$ \sum_{k=1}^{\infty} \ln{\left(1 + \frac{1}{4 k^2}\right)}$ Computing this sum,"Compute the limit: $$ \sum_{k=1}^{\infty} \ln{\left(1 + \frac{1}{4 k^2}\right)}$$ My teacher says it can be solved by only using high school knowledge , but I don't see how. What did I try? Well, I thought of Riemann sums but I see no way to connect this sum to it. Thanks. I'm only interested in a solution at high school level if possible ! UPDATE: Now, I'm my own teacher.","['sequences-and-series', 'calculus', 'real-analysis']"
191877,Invertible operator not preserving Hilbert dimension,It is known that for a bijective linear operator $T:X\to Y$ the algebraic dimensions of the linear spaces $X$ and $Y$ coincide. I am asking for an example of an invertible (bounded) linear operator between (infinite dimensional) Hilbert spaces such that their Hilbert dimension is different.,"['hilbert-spaces', 'functional-analysis']"
191879,Nilpotent matrices over field of characteristic zero,"From this Wikipedia link . Let $K$ be a field of characteristic zero and let $A$ be an $n \times n$ matrix over $K$ . Prove the following: (a) $N$ is nilpotent iff $\mathrm{tr}(N^m)=0$ for all $0<m \leq n$ iff $\mathrm{tr}(N^m)=0$ for all $m \in \mathbb{N_{+}}$ . (b) If $N$ is nilpotent, then $N$ is similar to a strictly upper triangular matrix. Additional Query: Is above true if $K$ is not assumed to be algebraically closed? (Then one can't apply Jordan normal form anymore.)","['matrices', 'linear-algebra']"
191897,Compositum of abelian Galois extensions is also abelian?,Suppose I have a field $k$ and two extensions $K/k$ and $L/k$ which are both abelian Galois extensions of $k$. Then (assuming $K$ and $L$ are both contained in some bigger field) is the compositum $KL$ an abelian Galois extension of $k$?,"['galois-theory', 'field-theory', 'number-theory']"
191920,Fibonacci nth term,"It is known that the nth term of the Fibonacci sequence can be found by the formula: $F_n = \frac{\phi^n - (-\phi)^{-n}}{\sqrt{5}}$, where $\phi$ is the golden ratio (1.618...). Would this be the best formula to generate large terms of the sequence (eg. $n = 10^{15}$)? How many decimal places of $\phi$ should be known to generate such a large term? How can this formula be reversed (ie. finding $F_n^{-1}$)?","['fibonacci-numbers', 'sequences-and-series']"
191921,Min Max Principle and Rayleigh-Ritz-Method for eigenvalues of unbounded operators?,"Finding eigenvalues of matrices using the Rayleigh-Ritz quotient is well-known, c.f. http://en.wikipedia.org/wiki/Min-max_theorem Does the following generalization of that fact also hold? Theorem: Let $H$ be a complex Hilbert space, $T:D \to H$ be an unbounded operator defined on a dense domain $D \subset H$. Assume that $T$ is self-adjoint and has discrete spectrum contained in some interval $[c,\infty[$, $c > 0$. Enumerate the eigenvalues by $\lambda_1 \leq \lambda_2 \leq \ldots$ counting with multiplicities. Then for each $k \in \mathbb{N}$
$$ \lambda_k = \min_{\substack{U \subset D, \\ \dim U=k }}{\max_{\substack{x \in U, \\\|x\|=1}}{\langle Tx, x  \rangle}} $$ If this is true, can you give a good reference for this?","['operator-theory', 'reference-request', 'eigenvalues-eigenvectors', 'functional-analysis']"
191924,Calculate the flux of the vector field through the sphere - please help me understand the solution,"Calculate the flux of the field $F(x,y,z) = (yz, xz, xy)$ through the sphere:
$$
x,y,z > 0, \space x^2 + y^2 + z^2 = a^2
$$
With outer normal. Solution says: The normal is $N = \frac{1}{a}(x,y,z)$, hence $\langle F,N \rangle = \frac{3}{a}xyz$, and using spherical coordinates, we get:
$$
flux_F(M) = \int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}} \frac{3}{a}(a\cos(\varphi)\sin(\theta)\times a\sin(\varphi)\sin(\theta)\times a\cos(\theta))\times  {\color{Red} \sin(\theta)} d\theta d\varphi = ... = \frac{3a^2}{8}
$$ My question is - shouldn't the part marked in red be $a^2\sin(\theta)$? Because $r=(a\cos(\varphi)\sin(\theta), a\sin(\varphi)\sin(\theta), a\cos(\theta))$ is a mapping $r:\mathbb{R}^2 \rightarrow \mathbb{R}^3$, the formula for surface integrals is:
$$
\int_{M}f = \int_{\Omega}f\circ r \sqrt{det(D_r^T D_r)}
$$
and $\sqrt{det(D_r^T D_r)} = a^2\sin(\theta)$. Thanks!",['multivariable-calculus']
191936,A question about a closed set,"Let $X = C([0; 1])$. For all $f, g \in X$, we define the metric $d$ by
$d(f; g) = \sup_x |f(x) - g(x)|$. Show that $S := \{ f\in X : f(0) = 0 \}$ is closed in $(X; d)$.
I am trying to show that $X \setminus S$ is open but I don't know where to start showing that. I wanna add something more, I have not much knowledge about analysis and I am just self taught of it, what I have learnt so far is just some basic topology and open/closed sets.","['general-topology', 'metric-spaces']"
191957,Fixed points of coset operation,"Let $G$ be a finite group which operates on two finite sets $E_1$ and $E_2$. Say that $E_1$ and $E_2$ are weakly $G$-isomorphic if for every $g \in G$, $\mathrm{Card}(E_1^g)=\mathrm{Card}(E_2^g)$, with $E^g$ the set of points fixed by $g$. An equivalent definition is : for every $g$ there exists a bijection $f_g : E_1 \to E_2$ such that $f_g(gx_1)=gf_g(x_1)$ (for every $x_1 \in E_1$) (this is not obvious but not difficult either). I would like to prove that if $H_1,H_2$ are subgroups of $G$, then the $G$-sets $G/H_1$ and $G/H_2$ are weakly $G$-isomorphic iif for every conjugacy class $C$ in $G$, $\mathrm{Card}(C \cap H_1) = \mathrm{Card}(C \cap H_2)$. Now for $xH \in G/H$ to be a fixed point of $g$, a necessary and sufficient condition is that $x^{-1}gx \in H$. We can't define a mapping $xH \mapsto x^{-1}gx \in C \cap H$, because if $xH=yH$ there is no reason for $x^{-1}gx$ to be the same as $y^{-1}gy$. But we can map the fixed point $xH$ to the set of $h^{-1}x^{-1}gxh$, i.e. the conjugacy class of $x^{-1}gx$ for $H$ (note that $H$ operates on $C \cap H$ by conjugation). I've been playing around with this kind of things for quite some time but eventually didn't succeed in construction a bijection from $C \cap H_1$ onto $C \cap H_2$, assuming $G/H_1$ and $G/H_2$ are weakly $G$-isomorphic. Does anyone have an idea?","['finite-groups', 'group-theory']"
191959,Solving the functional equation $f(x) = f(\frac{x}{\phi}) f(\frac{x}{\phi^2} - 1)$,"I'm trying to find a function $f(x)$ such that the spacing between consecutive roots looks like the infinite Fibonacci word: $$1, \phi^{-1}, 1, 1, \phi^{-1}, 1, \phi^{-1}, 1, 1, \phi^{-1}, 1, 1, \phi^{-1}, \ldots$$ If I'm not mistaken, any solution to the functional equation $f(x) = f(\frac{x}{\phi}) f(\frac{x}{\phi^2} - 1)$ must have roots at the points that I want. And I simply have no idea where to go from here. How can I solve this functional equation? Update . I've found that this one similar problem has an easy solution. Change the denominators of $\phi$ and $\phi^2$ both to $2$ , so that we have the equation $g(x) = g(\frac{x}{2}) g(\frac{x}{2} - 1)$ . A change of variables gives us this equation: $$g(2x) = g(x) g(x - 2)$$ Which differs from this double-angle formula only by scaling on the $x$ -axis: $$\sin 2 \theta = \sin \theta \sin (\theta + \frac{\pi}{2})$$ Thus, we have the easy solution $g(x) = \sin (-\pi \frac{x}{4})$ . It's not obvious how to apply this solution to the original problem, however.","['sequences-and-series', 'functional-equations']"
191981,"ord $(b)|\max\{\text{ord}(g)|g\in G\}$ for all $b\in G\,$ a finite abelian group","Let $a$ be an element of maximum order from a finite Abelian group $G$. Prove that for any element $b$, $|b|$ divides $|a|$ (order of $b$ divides order of $a$).","['finite-groups', 'group-theory', 'abelian-groups']"
191982,germ finitely determined,"Does anyone know any result on finitely determined germs to help me prove that the germ $f(x,y)=x^3+ xy^3$ is $4$- determined? I tried using the definition of germs finitely determined, which is:$f: \mathbb{R}^n \rightarrow \mathbb{R}$ is $k$-determined if for any other germ $g: \mathbb{R}^n \rightarrow \mathbb{R}$ such that the $k$-jet of g is equal to $k$-jet of the $f$, then $f$ and $g$ are right equivalents, i. e., exist a difeomorfism $h$ such that $f=g\circ h$, but not getting success. I think there should be some results to help me prove it.
Thanks!","['singularity-theory', 'differential-geometry', 'germs']"
191984,Every normal subgroup of a finite group is contained in some composition series,"In this context composition series means the same thing as defined here. As the title says given a finite group $G$ and $H \unlhd G$ I would like to show there is a composition series containing $H.$ Following is my attempt at it. The main argument of the claim is showing the following. Lemma. If $H \unlhd G$ and $G/H$ is not simple then there exist a subgroup $I$ such that $H \unlhd I \unlhd G.$ The proof follows from the 4th isomorphism theorem since if $G/H$ is not simple then there is a normal subgroup $\overline{I} \unlhd G/H$ of the form $\overline{I} = H/I.$ Suppose now that $G/H$ is not simple. Using the above lemma we deduce that there exist a finite chain of groups (since $G$ is finite) such that $$H \unlhd I_1 \unlhd \cdots \unlhd I_k \unlhd G$$ and $G/I_k$ is simple. Now one has to repeat this process for all other pairs $I_{i+1}/I_{i}$ and for $I_1/H$ until the quotients are simple groups. This is all fine since all the subgroups are finite as well. Now if $H$ is simple we are done otherwise there is a group $J \unlhd H$ and we inductively construct the composition for $H.$ Is the above ""proof"" correct? If so, is there a way to make it less messy?","['finite-groups', 'group-theory', 'abstract-algebra', 'simple-groups']"
191987,Solving differential equation for an expanding bubble,"I need to solve the equation 
\begin{eqnarray}
R^3  \frac{d } {dt} \left [        \frac{4}{3} \rho_{\rm ext} \left ( \frac{dR}{dt} \right )^2  \right ]+ 4 p R^2 \frac{d R} {dt}  =\frac{F_E}{4\pi}
\end{eqnarray} Could you please help in this regard?","['fluid-dynamics', 'ordinary-differential-equations']"
191988,What's $P(\{k\})$ in this exercise?,"The question is based on the following problem in the book Probability Essentials by Jacod: Here is my question: What does $P(\{k\})$ mean in the second problem? The probability on a finite or countable measurable space $(\Omega,\Sigma)$ is determined by $P(\{\omega\})$ where $\omega\in\Omega$. As I understand, for the binomial distribution $B(p,n)$ the sample space is $\Omega=\{(a_1, a_2):a_1,a_2=0,1\}^n$. How does $P(\{k\})$ come out here?","['probability-theory', 'measure-theory']"
192001,$f(z)$ has a zero of order $k$ iff $1/f(z)$ has a pole of order $k$,"If $f(z)$ is analytic at $z_0$, show that $f(z)$ has a zero of order
  $k$ at $z_0$ if and only if $\dfrac 1 {f(z)}$ has a pole of order $k$
  at $z_0$. I solved it but I'm not sure about my solution. ($\Rightarrow$) Since $f(z)$ is analytic at $z_0$, we have a power series expansion $f(z)=\sum_n a_n (z-z_0)^n$ for some nbd of $|z-z_0|<r$. But since $z_0$ is a zero of order $k$, $a_0=\cdots=a_{k-1}=0$ and $a_k \neq 0$. So $f(z)=\sum_{n=k}^{\infty} a_n (z-z_0)^n$. Since $f(z)$ is analytic on $|z-z_0|<r$, $\dfrac1{f(z)}$ is so on $0<|z-z_0|<r$. Then $$\displaystyle \lim_{z \to z_0}(z-z_0)^k \dfrac1{f(z)}=\lim_{z \to z_0}\dfrac1{a_k+a_{k+1}(z-z_0)+\cdots}=\frac1{a_k}\neq 0,\infty.$$ So $\dfrac1{f(z)}$ has a pole of order $k$ at $z_0$. But is it okay to substitute $f(z)$ by power series in the denominator? I feel somewhat careful to deal with power series.",['complex-analysis']
192007,Understand simple problem on inflation,"If the average food basket costs $100$ euros at 2nd quarter prices, how much will it cost for 3rd quarter prices? Below is the graph. I know that the answer is $97$ and can be achieved using follows: $$100 \left( 1 - \left(\frac{97.5-95}{95}\right)\right)$$ But can someone explain me the logic behind this?",['statistics']
192039,Help for Divergence operator,I'm a newbie and may be this question is bit simple for you but pardon me if it's too simple. Can some one tell me some reference to study about the invertibility of Divergence operator  $\operatorname{div}\colon C^1(\omega)\to G$ where $G$ is a space of  real valued function and $\omega$ is a subset of $\Bbb R^2$. Here I assume a Dirichlet type condition on the boundary of $\omega$ is specified and all boundary and domain have nice smoothness. In above context can someone give me some reference on the Null space structure of the divergence operator operating on differentiable maps defined on $\Bbb R^2$ ? Ariwn,"['operator-theory', 'functional-analysis', 'analysis']"
192043,Divergence of the harmonic series and the Cauchy criterion imply $\lim_{n\to\infty} \sqrt[n]n=1$,Why the divergence of the harmonic series and the Cauchy criterion immediately imply $\displaystyle\lim_{n\to{+}\infty}{\sqrt[n]{n}}=1$? Thanks for your help,"['sequences-and-series', 'radicals', 'real-analysis', 'analysis', 'limits']"
192044,Properties of Eigenfunctions of a Kernel,"I'm a newbie and may be this question is bit simple for you but pardon me if it's too simple and provide me some references. I've and Kernel function $K(x,y)$ $f(x)=(Kg)(x)=\int_{\Omega}K(x,y)g(y)dy$ $\Omega$, a compact set of $\Bbb R^2$. Let's assume that $K$ maps from one Hilbert space to another; let's say $L^2(\Omega)$ and it has an orthonormal basis of eigenpairs$(\lambda_i,f_i)_{i \in N }$. My question is: is there any general theory regarding the nature of $K(x,y)$ in the following cases If I need all the eigenfunctions $(f_i(x))$ such that  for   all  $f_i$ the partial derivatives of $f_i$ wrt $x_1$ and $x_2$ will  be same.$\partial_{x_1} f_i(x)=\partial_{x_2} f_i(x) , \forall i \in \Bbb N $ This's simple. I only need the Eigenfunctions to have nice regularity. Here I need only some reference in some books or papers. Lastly I've tried here writing Latex but it seems the same code as it is does not work here.Any tricks? Arwin","['integral-transforms', 'functional-analysis', 'real-analysis', 'analysis']"
192055,What is (a) geometry?,"There is no question what topology is and what it's about: it's about topologies (= topological spaces), and that's it. There is also no question what (universal) algebra is and what it's about. (Among other things, it's about algebras.) But what is geometry and what is it about? Is there a thorough and generally agreed upon definition of a geometry (= geometric structure) comparable to the unequivocal definition of a topology or an algebra?",['geometry']
192061,Quadratic equations that are unsolvable in any successive quadratic extensions of a field of characteristic 2,"Show that for a field $L$ of characteristic $2$ there exist quadratic equations which cannot be solved by adjoining square roots of elements in the field $L$. In $\mathbb{Z_2}$ adjoining all square roots we obtain again $\mathbb{Z_2}$, but $t^2+t+1$ does not have roots in this field. I don't know how to do the general case.","['galois-theory', 'abstract-algebra', 'field-theory']"
192065,Evaluation of $ \sum_{k=0}^n \cos k\theta $,I just wanted to evaluate $$ \sum_{k=0}^n \cos k\theta $$ and I know that it should give $$  \cos\left(\frac{n\theta}{2}\right)\frac{\sin\left(\frac{(n+1)\theta}{2}\right)}{\sin(\theta / 2)}   $$ I tried to start by writing the sum as $$ 1 + \cos\theta + \cos 2\theta + \cdots  + \cos n\theta $$ and expand each cosine by its series representation. But this soon looked not very helpful so I need some clue about how this partial sum is calculated more efficiently ...,"['trigonometry', 'summation', 'trigonometric-series']"
192071,Implicit Euler for 2nd Order DE,"I have given the following 2nd order DE: $$
\ddot{q_1} = - \frac{q_1}{|q|^3}
$$
$$
\ddot{q_2} = - \frac{q_2}{|q|^3}
$$
with $|q| = \sqrt{q_1^2 + q_2^2}$ The assignment is to solve this using explicit and implizit Euler. As for the explicit, I could split this into a system of 1st order DEs using $\dot{q} = p$, thus I had
$$
\dot{p_1} = - \frac{q_1}{|q|^3}
$$
$$
\dot{p_2} = - \frac{q_2}{|q|^3}
$$
$$
\dot{q} = p
$$ But now I am stuck at the implicit Euler. The reason is: The equation for this is $\dot{y}_{n+1} = y_n + \Delta t f(y_{n+1})$. My problem now is: I do not have all q or all p in my function f, but $\dot{p} = f(q)$ So how can I formulate this method?","['ordinary-differential-equations', 'numerical-methods']"
192072,Sum of divisors,"Bonjour! I'm trying this number-theory problem, but i don't have any idea how to solve it. Can you give me some hints ? We have got any $\mathbb{Z_+}$ number. Let it be $n$. Then we must proof that $2 \nmid \sigma(n) \implies n = k^2 \vee n = 2k^2$. Thanks for any help","['elementary-number-theory', 'number-theory']"
192085,Can I prove this inequality algebraically?,"With $x+y\ge z$ $(x,y,z\ge0)$, prove that: $$\frac{x}{1+x}+\frac{y}{1+y}\ge\frac{z}{1+z}$$ I'm aware that using analytic view this is easy since $f(x)=\frac{x}{1+x}$ is concave in $[0,\infty)$. However I want to prove it using merely algebraic techniques. Is that possible?","['inequality', 'algebra-precalculus']"
192094,$|G-H|<\infty$ so $|G|<\infty$,"Let $G$ is a group and $H<G$ such that $|G-H|<\infty$. Prove that $|G|<\infty$. Truthfully, there is a hint for it: $H$ cannot be an infinite subgroup. It is clear if $|H|<\infty$, since $|G-H|<\infty$ then $|G|<\infty$ and problem will be solved. But cannot understand why ""$H$ cannot be an infinite subgroup"". Thanks for your help.",['group-theory']
192106,"How can I compute $\int_{-\infty}^\infty f(x)f(y-x)\, \mathrm dx$","If $f(x)=\text{arccot}(x)$ for non-negative $x$ and $0$ otherwise, how can I calculate $$\int_{-\infty}^\infty f(x)f(y-x)\, \mathrm dx$$ for $y\in\mathbb{R}$?","['definite-integrals', 'trigonometry', 'integration', 'convolution']"
192119,clarification errata in Munkres Topology?,"While reading the second edition of Munkres' Topology, I came across this (page 129): Theorem 21.1 Let $f: X \rightarrow Y$; let $X$ and $Y$ be metrizable with metrics $d_X$ and $d_Y$, respectively. Then continuity of $f$ is equivalent to the requirement that given $x \in X$ and given $\epsilon > 0$, there exists $\delta > 0$ such that $d_X(x,y) \implies d_Y(f(x), f(y)) < \epsilon$. Shouldn't the last part be $d_X(x,y) < \delta \implies d_Y(f(x), f(y)) < \epsilon$ ?
I've looked at the errata here but didn't find mention of this. am i missing something? Thanks for any help/clarification. :)",['general-topology']
192125,Solve $\sqrt{x-4} + 10 = \sqrt{x+4}$,"Solve: $$\sqrt{x-4} + 10 = \sqrt{x+4}$$
Little help here? >.<",['algebra-precalculus']
192130,"Is the ""field"" I learned about in analysis different from the ""field"" I learned about in econometrics?","Today was my first day of econometrics, and real analysis, and in both courses the professor defined something called a ""field"". Unfortunately, the field I learned about in real analysis seems completely different from the field I learned about in econometrics. The field from analysis is a set with addition and multiplication which obeys 11 familiar axioms. I had already been familiar with this definition of a field from linear algebra but here it was again. But the field from econometrics was completely different! My notes say, If $S$ is a sample space, a collection of subsets $\mathcal{S}$ of $S$
  is called a field if: $S\in\mathcal{S}$ Whenever $A\in \mathcal{S}$, $A^C\in \mathcal{S}$ Whenever $A$ and $B$ are in $\mathcal{S}$, $A\cup B\in \mathcal{S}$ Is the field that I learned about in econometrics a completely different thing? Or are they somehow related?","['probability-theory', 'field-theory']"
192138,What is the meaning of the vertical line in $\left.\left(\frac{2x^3}{3} - 4x^2 + 10x\right) \right|_1^3 = 12 - 20/3$,"$$\left.\left(\frac{2x^3}{3} - 4x^2 + 10x\right) \right|_1^3 = 12 - 20/3$$ I guess my first question would be: What is the meaning of the vertical line in this equation? I was under the impression it is meant to represent a range of $x$ values. However I'm not sure how both sides are equal, or how one would go about solving this.","['notation', 'algebra-precalculus']"
192164,Rank product of matrix compared to individual matrices. [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: How to prove $\text{Rank}(AB)\leq \min(\text{Rank}(A), \text{Rank}(B))$? If $A$ is an $m\times n$ matrix and $B$ is a $n \times r$ matrix, 
  prove that the rank of matrix $AB$ is at most $\mathrm{rank}(A)$. I asked a similar question earlier phrased incorrectly. The above is closer to the actual question generalised.","['matrices', 'linear-algebra', 'matrix-rank']"
192177,What is the expected number of times a dice has to be rolled to get two consecutive sixes? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Basically, on average, how many times one should roll to expect two consecutive sixes?","['statistics', 'dice', 'probability']"
192187,GRE Algebra question,"A group can charter a particular aircraft at a fixed total cost. If 36 people charter the aircraft rather than 40 people, then the cost per person is greater by $12. (a) What is the fixed total cost to charter the aircraft? (b) What is the cost per person if 40 people charter the aircraft? ans: 15. (a) $\$$4,320 (b) $\$$108 Can the answers be found with the information provided in the question? If yes , how? As far as I understand the question, my approach to the question is as follows:
for 40 people, cost per person be x
for 36 people, cost per person is x+12
so for 40 people, total cost is 40x
for 36 people, total cost is 36(x+12)","['algebra-precalculus', 'gre-exam']"
192198,*understanding* covariance vs. contravariance & raising / lowering,"There are lots of articles, all over the place about the distinction between covariant vectors and contravariant vectors - after struggling through many of them, I think I'm starting to get the idea.  I'm wondering if some-one/people can help me understand the meaning / significance of it. My background is physics, with no training in 'abstract algebra' per se .  The language I use below is basically as technical as I understand (sorry...). My understanding: Contravariant vectors (like normal displacement/velocity/etc vectors---with upper indices: $\vec{v} = v^i \, \bf{e}_i$ , on a basis $\vec{\bf{e}} = \bf{e}_i$ ) transform like, $$v^{\prime j} = \frac{dx^{\prime j}}{dx^i} v^i.$$ Covariant vectors (like gradient vectors–with lower indices: $\vec{w} = w_i \,  \bf{e}^i $ , on a basis $\vec{\bf{e}} = \bf{e}^i$ ) transform like, $$w_{\prime j} = \frac{dx^i}{dx^{\prime j}} w_i.$$ We also have a metric $g_{ij}$ or $g^{ij}$ which can transform a contravariant vector to a covariant vector. Questions: If these vectors exist in the same 'space' (vector space?), and we want to make them interact---i.e. take the dot-product between them (which requires one to be upper-index and the other lower-index), then why are they being expressed with difference bases (basises?)?---doesn't that mean they're in different reference frames? What is the meaning behind changing a vector from covariant to contravariant?  The components change in some way, but the 'meaning' of the vector is supposed to stay the same, right? Does something being a contravariant vector simply mean it is being defined with respect to a basis of tangent vectors; while a covariant vector is one in reference to a basis of normal vectors? [this is my interpretation of the first figure of http://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors ]","['differential-geometry', 'vector-spaces', 'abstract-algebra']"
192215,SDE - removal of the diffusion coefficients,"I'm currently looking at stochastic differential equations with irregular coefficients such as $W^{1,p}_\mathrm{loc}$. If I have
\begin{align}
dX_t=b(X_t) \, dt+\sigma \, dW_t,
\end{align}
where $b\in W^{1,1}_\mathrm{loc}$ and $\sigma$ is a constant, I can write this SDE as a ODE for every Brownian path $w$ by defining $Y_t=X_t-w_t$ and a new vector field $b^w=b(Y,t)=b(Y_t+w_t)$, so the ODE is
\begin{align}
dY=b^w(t,Y) \, dt
\end{align}
with initial condition $Y_0=y$. Since $b^w$ has Sobolev regularity I can then apply DiPerna-Lions theory (1989), which guarantees the existence and uniqueness of the flow of the ODE. My question is now what happens if $\sigma$ is not a constant, \begin{align}
dX_t=b(X_t) \, dt+\sigma(X_t) \, dW_t.
\end{align}
Apparently the above argument is NOT correct in general. Is there any ways that the diffusion coefficients $\sigma(X_t)$ can be absorbed into the Brownian motion? or maybe there are some conditions on $\sigma$ under which the above argument still hold? Many thanks!!","['probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
192232,Is the propositional set countably infinite?,"Recently I'm learning logic. Here is the definition from the book ""Logic For Computer Science"": A countable set $PS$ of proposition symbols: $p_0,p_1,\dots$ The set $\text{Prop}$. propositions is the smallest that satisfies: Every proposition symbol $p_i$ is in
$\text{Prop}$. Whenever $\varphi$ is in $\text{Prop}$, $\neg \varphi$ is also in
    $\text{Prop}$. Whenever $\varphi, \psi$ are in $\text{Prop}$, $(\varphi \vee \psi), (\varphi\wedge \psi)$ and $(\varphi\rightarrow\psi)$ are also in $\text{Prop}$. A string is in $\text{Prop}$ only if it is
formed by applying the rules $1, 2$ and  $3$. Now I want to know whether $\text{Prop}$ is countably infinite, and if so how to prove that.","['logic', 'propositional-calculus', 'elementary-set-theory']"
192250,I am trying to prove the identity $ \sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m}$,"Prove algebraically $\sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m}$ I have an idea as to how to prove it when m = 1, but am having trouble otherwise. When m=1, we just have $\sum_{k=1}^{n} k^{\downarrow 1 }{n \choose k} = n^{\downarrow 1 } 2^{n-1} = n2^{n-1} $ I would appreciate any insight you guys could give would be appreciated.  I do understand the identity combinatorially but am having issues with the algebra. Longtime lurker, 1st time poster, so please forgive if I am not following proper protocol.","['statistics', 'probability', 'combinatorics']"
192253,Converting an IF condition to a mathematical equation,"I am trying to study about converting algorithms into mathematical equations. For this I just started with a simple random example : function set_b( int b):int
{
    if ( b >= 0)
    {
     a = 5 ; 
    }
    else
    if ( b < 0 )
    {
     a = -20  
    } 


} By looking at the above algorithm, one can say : a is dependent upon b. So :  a = f(b). Also, the two blocks of Ifs are actually talking about -ve and +ve number lines. But after this i get stuck, where to start approaching the solution from. Some equation like a = b + blah blah - blah blah * blah blah  etc. Any clues or hints pls ?","['computer-science', 'algebra-precalculus', 'functions']"
192261,limit at infinity $f(x)=x+ax \sin(x)$,"Let $f:\Bbb R\rightarrow \Bbb R$ be defined by $f(x)= x+ ax\sin x$. I would like to show that if $|a| < 1$, then $\lim\limits_{x\rightarrow\pm \infty}f(x)=\pm \infty$. Thanks for your time.","['real-analysis', 'limits']"
192264,Compute $ \int_{0}^{1}\frac{\ln(x) \ln^2 (1-x)}{x} dx $,"Compute
$$ \int_{0}^{1}\frac{\ln(x) \ln^2 (1-x)}{x} dx $$ I'm looking for some nice proofs at this problem. One idea would be to use Taylor expansion and then integrating term by term. What else can we do? Thanks.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
192294,How to prove this combinatorial identity?,"I am wondering how to prove the following identity:
$$\sum_{i=0}^{n-r} \frac{2^i (r+i) \binom{n-r}{i}}{(i+1) \binom{2n-r}{i+1}}=1?$$ It seems this might be related to the hypergeometric distribution, but I could not convert that form back into hypergeometric distribution form.","['probability-distributions', 'combinatorics']"
192298,Geometry triangle question,"In the figure below, AB=BC=CD. If the area of triangle CDE is 42, what is the area of triangle ADG? I think triangles are similar. Are there any properties of similar triangles regarding their area. Help me get the answer with explanation please ans :378","['geometry', 'triangles', 'education']"
192311,The product of all elements in $G$ cannot belong to $H$,Let $G$ be a finite group and $H\leq G$ be a subgroup of order odd such that $[G:H]=2$. Therefore the product of all elements in $G$ cannot belong to $H$. I assume $|H|=m$ so $|G|=2m$. Since $[G:H]=2$ so $H\trianglelefteq G$ and that; half of the elements of the group are in $H$. Any Hints? Thanks.,"['finite-groups', 'group-theory']"
192340,Smallest Subfield Generated by a set,"So I'm essentially trying to find an explicit description of the smallest subfield generated by a subset of the field.  I know that if s is an element of the subset, we must also have its additive and multiplicative inverse.  Is there a succint way of describing the subfield set-theoretically?  Again, the intuition seems clear, but I'm struggling with a formal description...","['abstract-algebra', 'field-theory']"
192345,Calculate position of rectangle lower left corner on center rotatiton,"Since I forgot all the basics of math, I'm asking you to help me out with simple task. I need to rotate text box in PDF. Rotation point is lower left corner, but I need to rotate it as if the rotation point would be on the center. Since I am using a programming language, I can convert an angle in degrees to its radian equivalent (although I'm not sure if this will help) Can you help me out to find lower left corner coordinates if rotation point is center?",['geometry']
192363,Solving differential equations through integration?,"In ordinary calculus, one can solve a function by taking its ""anti-derivative,"" in a form of integration. Likewise, in differential equations, one can look for solutions by integrating the equation in some way. Is this analogous to ""taking an anti-derivative?"" Does the process have a name, perhaps ""anti-differential?"" And is this made possible (as in the case of taking an anti-derivative) by the fundamental theorem of calculus?",['ordinary-differential-equations']
192391,Are matrices rank 2 tensors?,"I know that this is sometimes the case, but that some matrices are not tensors.
So what is the intuitive and specific demands of a matrix to also be a tensor?
Does it need to be quadratic, singular or something else? Some sources I read seem to suggest that all rank 2 matrices are tensors while other just claims that ""some"" matrices are rank 2 tensors. What's the connection between tensors and matrices?","['matrices', 'tensor-rank', 'tensors']"
192393,Verification the integral identity $\int_0^\pi \ln(1+\alpha\cos(x))dx=\pi\ln\left(\frac{1+\sqrt{1-\alpha^2}}{2}\right)$.,I have to verify that $$\int_0^\pi \ln(1+\alpha\cos(x))dx=\pi\ln\left(\frac{1+\sqrt{1-\alpha^2}}{2}\right)$$ with $|\alpha|<1$. It is my homework and don't know where to begin.,"['calculus', 'integration']"
192396,Are all multiplicative functions additive?,"Suppose $cf(x)=f(cx)$ and $f:\mathbb{R}\to\mathbb{R}$. I believe it follows that $f(x+y)=f(x)+f(y)$. Proof: There is some $c$ such that $y=cx$. Then 
$$f(x+y)=f\left((1+c)x\right)=(1+c)f(x)=f(x)+cf(x)=f(x)+f(cx)=f(x)+f(y)$$ QED. I wonder if the same thing holds for when $f:\mathbb{R}^n\to\mathbb{R}^n$? I can't use the same trick, because all vectors are not scalar multiples. I tried thinking of it in terms of basis units, but didn't get anywhere.","['linear-algebra', 'functions', 'functional-equations']"
192402,Equivalence of two definitions of differentiablitity on Regular Surfaces,"When dealing with differentiable surfaces one defines a function $f:S\rightarrow \mathbb{R}$ as being differentiable if its expression in local coordinates is differentiable. But one could also define it to be differentiable if there exists differentiable function $F: V\subset \mathbb{R}^3 \rightarrow \mathbb{R}$ from an open set $V$ of $\mathbb{R}^3$ such that $S\subset V$ and $F|_{S} = f$, i.e. a differentiable extension of $f$. Are these two definitions of differentiability equivalent? More precisely, when given a differentiable function on a surface can you always extend it to a differentiable function of an open set of $\mathbb{R}^3$ containing the surface?","['surfaces', 'differential-geometry']"
192408,Is this actually true?,"This exercise appeared in my real analysis test last year, and is still puzzling me since then. Ironically, even the professor doubts if the b part is actually truth (still...) Let $A \subset \mathbb{R}$ a) If $\displaystyle0<m^*(A)<\infty$, then for every $\alpha\in (0,1)$, exists an open interval $I$ such that $\displaystyle \alpha m^*(I) \leq m^*(A \cap I) $ b) If $ \displaystyle m^*(A \cap I) \leq  \frac{m^*(I)}{2}$ for every open interval, then $m^*(A) = 0$","['measure-theory', 'real-analysis']"
192416,"In how many sequences of length $n$, the difference between every 2 adjacent elements is $1$ or $-1$?","How do I find a recursion formula to solve the following question: In how many sequences of length $n$, with elements from $\{{0,1,2,3,4}\}$, the difference between every 2 adjacent elements is $1$ or $-1$? I've been trying to solve the problem for the last 5 hours maybe, I'm sure that I'm missing something.. This is a problem in combinatorics, and the solution must be by finding a recursion formula for the problem. best solution I've come so far is that if we say that $a_n$ is the solution to the question, so let's count how many sequences of size $n-1$ there are that meet the requirement, and we complete the first element to make it a sequence of $n$ elements. so for $n-1$ there $a_{n-1}$ sequences, and for each sequence we have $2$ options to choose the first element (one option is to take a plus $1$ number from the number that start the $n-1$ sequence, and the other option to to take a minus $1$ number from the number that start the $n-1$ sequence), only problem as you figured out is that if the $n-1$ sequnce starts with $0$ or $4$ there is only $1$ option left for the first element in the sequnce.. so $a_n=2a_{n-1}$ won't work. I think that the solution may involve using $2$ or maybe $3$ recursion formulas. Hope I was clear enough.","['recurrence-relations', 'combinatorics']"
192421,Obtaining the discriminant of the characteristic polynomial directly from the matrix,"Let $M \in \mathbb{Z}_{n \times n}$ be a square matrix with integer coefficients. Let $P(x)$ be its characteristic polynomial $$
    P(x) = \det\left(x \cdot \mathbb{I}_{n \times n}- M\right)
$$
I would like to compute the discriminant of $P(x)$, and I am wondering if it can be obtained from $M$ directly. The intent is to determine whether $M$ has distinct eigenvalues. I am looking for references, ideas, algorithms. Thank you.","['linear-algebra', 'reference-request', 'polynomials']"
192423,How to guess the number of inflection points?,"I am asked to find fast the number of possible inflection points of:
$$y=(x-1)(x-2)^2(x-3)^4(x-4)^3$$ I know if the degree of any polynomial is even, its plot starts from the 2th quadrant to 1st quadrant of $\mathbb R^2$. This was what I could do fast . Any Ideas? Thanks.",['calculus']
192431,Finding $E\Bigl(\overline{Y^2}\Bigm|\overline{Y\vphantom{Y^2}}\Bigr)$ by Basu's theorem?,"Suppose $Y_1,\ldots,Y_n$ are a random sample of normal distribution $\mathcal{N}(\mu,1)$. If $\overline{Y^2}=\displaystyle\frac{1}{n}\sum_{i=1}^n Y_i^2$, how can I find $E\Bigl(\overline{Y^2}\Bigm|\overline{Y\vphantom{Y^2}}\Bigr)$ by Basu's theorem ?","['statistics', 'probability']"
192433,Derivative of Neural Network function,"I would like to code this neural net activation function, using the C language: $$f(x) = 1.7159 \tanh( \frac{2}{3} x )$$ and I will also need to code its derivative. I've read that the derivative of $\tanh(x)$ is $\operatorname{sech}^2(x)$, but since C doesn't have a hyperbolic secant function I will need to use $\cosh$, i.e. the derivative of $\tanh(x)$ is $1\over \cosh^2(x)$, I think. Since my knowledge of calculus is very rusty, my best attempt for the derivative of the above function is: $$1 \over \cosh^2(\frac{2}{3}x)$$ Is this correct?","['neural-networks', 'calculus', 'derivatives']"
192442,Oscillation frequencies in an ODE,"Given the following ODE:
$$\ddot{x}(t)+\sin(\omega t)x(t)=0$$
its solution can be expressed in terms of the Mathieu functions. 
Plotting this solutions and assuming known the initial conditions it can be found a main oscillatory behaviour with another superimposed oscillation close to the maxima and minima of the solution. Now my question is: how can I find the frequencies of these oscillations knowing $\omega$? Or in other words, is there a formula linking the frequencies to $\omega$?","['ordinary-differential-equations', 'special-functions']"
192445,Simple partial differentiation $x = r\cos\theta$ and $y = r\sin\theta$,"If \begin{align}
x &= r\cos\theta,\\
y &= r\sin\theta,
\end{align} find $$\dfrac{\partial^2\theta}{\partial{x}\partial{y}}.$$ How can I find this partial derivative? I need to prove that $$
\frac{\partial^2\theta}{\partial{x}\partial{y}} = -\frac{\cos2\theta}{r^2}.$$","['polar-coordinates', 'derivatives']"
192460,There exists an injection from $X$ to $Y$ if and only if there exists a surjection from $Y$ to $X$.,"Theorem. Let $X$ and $Y$ be sets with $X$ nonempty. Then (P) there exists an injection $f:X\rightarrow Y$ if and only if (Q) there exists a surjection $g:Y\rightarrow X$. For the P $\implies$ Q part, I know you can get a surjection $Y\to X$ by mapping $y$ to $x$ if $y=f(x)$ for some $x\in X$ and mapping $y$ to some arbitrary $\alpha\in X$ if $y\in Y\setminus f(X)$. But I don't know about the Q $\implies$ P part. Could someone give an elementary proof of the theorem?","['elementary-set-theory', 'functions']"
192463,Accumulation points of sequences as limits of subsequences?,"I'm trying to extract more useful information from the following definition: A point $x^*$ is an accumulation point of the sequence $\{x_n\}$  if, for every open set  containing x , there are infinitely many indices such that the corresponding elements of the sequence belong to the open set. I would like to say that this is equivalent to saying the following: $x^*$ is an accumulation point if there exists a subsequence $x_{a_n}$ such that $lim_{n\rightarrow\infty} x_{a_n}=x^*$. Is this true?","['sequences-and-series', 'limits']"
192477,All asymptotes of $f(x)=\sqrt{x^2-4x}+\frac{1}{x^2-1}$,"Find the number of all possible asymptotes of: $$f(x)=\sqrt{x^2-4x}+\frac{1}{x^2-1}$$ Since we know $\sqrt{ax^2+bx+c}\approxeq \sqrt{a}\big|x+\frac{b}{2a}\big|$ when $(x\rightarrow\pm\infty)$ so, working with $\sqrt{x^2-4x}$ in $f(x)$, makes two following lines : $$x\rightarrow +\infty\Rightarrow y=x-2\\x\rightarrow -\infty\Rightarrow y=-x+2$$ I see the second part of $f(x)$ tends to zero. So, I agree that this function has 2 oblique asymptotes and one horizontal asymptote $y=0$. For vertical asymptote, I say $x=\pm1$ are that ones. Overall, Am I thinking right about the number of all asymptotes for $f(x)$? Is taking the function apart to two sections allowed in this function? Thanks.","['asymptotics', 'functions']"
192487,Trying to understand LMS algorithm,"This is what's written: So, $h(x)$ is basically a linear function to predict values of some training set. I understand everything that's happening up to the point where we take the partial derivative of $h(x)$ in summation form (the second equation above the black line), but how do we get the partial derivative of $h(x) - y$ to just $x_j$? Also, why does the update in the equation under the black line change what's calculated before: $(h(x) - y)x_j$ to $(y - h(x))x_j$? I'm sorry if I'm not being clear enough. Please let me know if that's the case. Thank you!","['statistics', 'machine-learning', 'derivatives']"
192494,Cokernels - how to explain or get a good intuition of what they are or might be,"When I think about kernels, I have many well-worked examples from group theory, rings and modules - in the earliest stages of dealing with abstract mathematical objects they seem to come up all over the place, whenever I see a homomorphism. BUT no-one really seems to mention cokernels until you get to commutative diagrams and category theory. And then they can easily just be ""things which make the diagram work"" with limited intuition or sense of useful reality. [maybe I exaggerate] So I am looking for good examples to illustrate what a cokernel is, extending to non-trivial examples [I was taught about the kernels of homomorphisms between non-abelian groups before anyone taught me about modules].","['homological-algebra', 'category-theory', 'big-list', 'abstract-algebra']"
192496,An injection from an infinite set $X$ to $\mathbb{N}\implies X$ is countable.,"Let $X$ be an infinite set. I've been trying to prove that an injection from $X$ to $\mathbb{N}$ implies that $X$ is countable. I know this boils down to showing that an injection from $X$ to $\mathbb{N}$ implies the existence of a surjection from $X$ to $\mathbb{N}$. Or, equivalently, that a surjection from $\mathbb{N}$ to $X$ implies the existence of an injection from $\mathbb{N}$ to $X$. Could someone give a proof of one of the above statements?",['elementary-set-theory']
192520,Sum of the sequence,"What is the sum of the following sequence $$\begin{align*}
(2^1 - 1) &+ \Big((2^1 - 1) + (2^2 - 1)\Big)\\
&+ \Big((2^1 - 1) + (2^2 - 1) + (2^3 - 1) \Big)+\ldots\\
&+\Big( (2^1 - 1)+(2^2 - 1)+(2^3 - 1)+\ldots+(2^n - 1)\Big)
\end{align*}$$ I tried to solve this. I reduced the equation into the following equation $$n(2^1) + (n-1)\cdot2^2 + (n-2)\cdot2^3 +\ldots$$ but im not able to solve it further. Can any one help me solve this equation out. and btw its not a Home work problem. This equation is derived from some puzzle. Thanks in advance","['exponential-sum', 'combinatorics']"
192529,Why does the tail $a_N+a_{N+1}+a_{N+2}\ldots$ of convergent series $\sum a_n$ tend to $0$ as $N\to\infty$?,"Let $a(n)>0$ for all $n \in \mathbb{N}$ be such that $\sum a(n)$ converges. Define $r(n):=\sum\limits_{k=n+1}^\infty a(k)$. The claim is $$\lim_{n \to \infty} r(n) = 0,$$ but I cannot see how to prove it. Please help.","['sequences-and-series', 'real-analysis']"
192537,The solution of Cauchy-Riemann equation,"Can you give me an example that there is a $f \in C_0^{\infty}(\mathbb C)$, such that the equation $\bar \partial u=f$ has no  $C_0^{\infty}(\mathbb C)$ solution?","['partial-differential-equations', 'complex-analysis']"
192552,How to self study Linear Algebra,"I have no idea if this question is appropriate for this forum, but I hope you guys can overlook the fact that I asked it on a wrong forum (if I did) and still help me answer it (of course, if this is indeed the wrong forum for the type of question I'm about to ask, do please say so). I am a 16 year old guy who is passionate about physics and as a result wants to increase his knowledge in mathematics, the language of physics. I've read and heard a lot about Linear Algebra and how crucial it is to physics and I am deeply motivated to self study this intriguing part of mathematics. However, I have limited knowledge of maths. I (for example) know basic algebra, trig, diff/int calc and some analytical geometry, but I wouldn't say I master these subjects past the high school curriculum. Now my question is: Would you kind people say I am able to self study Linear algebra or is it too tough and/or does it require too much of a math background? And are there any good books out there for BEGINNERS in LA? I found this (free) e-book called: Elementary Linear Algebra by Kenneth Kuttler and another one called 'Linear Algebra: Theory and its applications' also by Kuttler? Are these any good? Or would you recommend other books? If you guys have any tips regarding books for LA but also tips in general, please, I'd appreciate them!","['linear-algebra', 'self-learning', 'reference-request']"
192555,What does it mean when a statistician says I’m 90% confident that the mean of the population is between 1 and 9?,Does that mean if I draw samples from the population that 90% of the time I'll get a number between 1 and 9? Added : assume normal distribution for the population.,['statistics']
192564,dot product identity,"$$a \cdot (a \cdot b)=(a \cdot a)(a \cdot b)$$ Is this identity true when $a$ and $b$ are vectors, and when $\cdot$ is the dot product operator?  And assuming that $()()$ means multiplying the contents of the parentheses. Can anyone please post explanation and links of this identity?  I saw it used somewhere, but I cannot seem to find documentation of it in textbooks or in search engine research using the key words I could think of. Thank you. It is used in a suggested solution for the following problem: ""Show that the vector orth_a b = b - proj_a b is orthogonal to a.  (It is called an orthogonal projection of b.)"" Where a and b are vectors, and proj_a b is the vector projection of b onto a. Really what I need is to learn to answer this problem, and the part of the suggested proof I don't understand is given in my initial post above.  If you have a better answer to this problem, I would love to learn how your approach works.","['multivariable-calculus', 'calculus', 'vector-analysis']"
192565,A proof of the fundamental theorem of symmetric polynomials,"I'm reading Exploratory Galois Theory by John Swallow. On page 123 he gives the following remark / alternate proof of the fundamental theorem of symmetric polynomials: Let $K$ be a field and $L$ be the field of rational functions $K(X_1,\dots,X_n)$. Now consider the subfield $K(\sigma_1,\dots,\sigma_n)$ generated over $K$ by the elementary symmetric polynomials. Then $L$ is the splitting field of $X^n − \sigma_1X^{n−1} +\cdots +(−1)^n\sigma_n$, since this polynomial is equal to the product $(X − X_1)(X − X_2) \cdots (X − X_n)$. The Galois group must be a subgroup of $S_n$; on the other hand, every permutation in $S_n$ gives a different automorphism of $L$ over $K(\sigma_1,\dots,\sigma_n)$. Hence $K(X_1,\dots,X_n)/K(\sigma_1,\dots,\sigma_n)$ is Galois with group $S_n$, and $K(\sigma_1,\dots,\sigma_n)$ is the fixed field of $S_n$. To perform the final step – to say that every symmetric polynomial is a polynomial in the elementary symmetric functions, that is, that each symmetric polynomial lies not only in $K(\sigma_1,\dots,\sigma_n)$
  but $K[\sigma_1,\dots,\sigma_n]$ – requires a notion of integrality beyond the scope of this text. Could anyone explain how to finish this proof? I am familiar with integral ring extensions but I'm not sure what to do with it.","['galois-theory', 'symmetric-polynomials', 'abstract-algebra']"
192567,Are the derivatives of symmetric functions symmetric?,"Suppose $f(x,y)=f(y,x)$. Does it follow that $\frac{\partial f}{\partial x}=\frac{\partial f}{\partial y}$? Intuitively it seems like it must, because taking a ""step"" in the $x$ direction must be the same as taking one in the $y$. But when I try to prove it I get lost as to which is ""really"" x or y. EDIT: I should have been more clear. What I meant was: does $\frac{\partial f(x,y)}{\partial x}=\frac{\partial f(y,x)}{\partial y}$? (At some intuitive level this is like doing a ""find and replace"" s/x/y/, but my intuition fails when taking the derivative.)",['multivariable-calculus']
192570,Conditions for a curve to be defined over a subfield,"I have just finished reading Hartshorne, Chapter 1, Section 6 and have some questions about curves defined over a subfield of an algebraically closed field. For simplicity, let $k$ be a perfect field, $\overline{k}$ a fixed algebraic closure. 1) Let $E$ be a funtion field of transcendence degree 1 over k. Then $\overline{E}=E\cdot\overline{k}$ is a funtion field of transcendence degree 1 over $\overline{k}$, and hence (keeping the notation of Hartshorne) $C_{\overline{E}}$ is isomorphic to a non-singular projective curve, $X$ say. Is $X$ necessarily defined over $k$? 2) if $\varphi:X\rightarrow Y$ is a morhpism of curves and $X$ is defined over $k$, then is $Y$? Same question but with $\varphi$ a birational map. Any help much appreciated (as always).","['arithmetic-geometry', 'algebraic-geometry', 'algebraic-curves']"
192572,Function which is $2^n$ - periodic for all integers $n$,"Is there a non-constant, continuous function $f: \mathbb{R} \longrightarrow \mathbb{R}$ such that for all integers $n$, $f$ is $2^n$-periodic? Notes: $n$ can be any integer, and so can be negative as well as positive. If I did not require $f$ to be continuous, then I think $f: \mathbb{R} \longrightarrow \mathbb{R}$ defined by:
$$f(x) =  \begin{cases}
   1 & \text{$x$ rational} \\
   0       & \text{$x$ irrational}
  \end{cases}$$
would do the trick.",['functions']
192596,The distance function is continuous.,"Let $S\subset\Bbb R$ not empty, define $f:\Bbb R\rightarrow\Bbb R$ such that $f(x)=
\inf\{|x-s| ;s\in S\}$ then, prove that  $|f(x)-f(y)|\le|x-y| $ for any $x,y \in \Bbb R$","['real-analysis', 'analysis']"
192603,Can I get better approximation of $\sum_{k=1}^{n} k^k$,"Is it possible to get approximation$f(n)$ of $\sum_{k=1}^{n} k^k$ with
\begin{align}
\lim_{n\to +\infty }\left(f(n)-\sum_{k=1}^{n} k^k\right)=0
\end{align}
Thanks for your attention!",['analysis']
192608,How would I solve $(x-3)(x-2)(x-1)\gt0$?,This problem is on my Calculus Readiness Test and I was having a lot of trouble with it. The problem is $$(x-3)(x-2)(x-1)\gt0$$ I know how to solve $(x-3)\gt0$ but I have never seen these type of problem before. I've tried to distribute everything but it gets messy and doesn't really simplify neatly. How should I go about solving this? Thanks,"['inequality', 'algebra-precalculus']"
192610,How to build a orthogonal basis from a vector?,"Anybody know how I can build a orthogonal base using only a vector? I have a vector in the form $v_1 = [a, b, -a, -b]$, where $a$ and $b$ are real numbers. I did try build in the ""adhoc way"" but, nothing, I only got two orthogonal vectors: $$v_1 = [a, b, -a, -b], \text{    } v_2 = [a, -b, a, -b]$$ I need more two vectors to complete the orthogonal basis $\{v_1, v_2, v_3, v_4\}$. Anybody can help me? Thanks...","['vector-spaces', 'linear-algebra']"
192634,Help solving this question on even and odd functions,"a) Suppose that $E(x)$ is an even function and that $O(x)$ is an odd function. Suppose furthermore
that $E(x) + O(x) = 0$. Show that for all $x$, $E(x) = 0$ and $O(x) = 0$. b) Use part a) to show that if $A\sin(ax)+B\cos(bx) = 0$ for all $x$, where $A,B,a,b$ are fixed real numbers, then $B = 0$ and one of either $A$ or $a$ is also equal to $0$.","['calculus', 'functions']"
