question_id,title,body,tags
4065824,Existence conditions of an expression with algebraic fractions,"I have to compute the existence conditions of the following expression: $$\{\frac{3a^2}{x+2a}+[x^2:(1-\frac{a}{(x+a)})+a^2:(1-\frac{x}{(x+a)})]:\frac{(x^2+2ax+a^2)}{(x-2a)}\}:(\frac{(x^2-a^2)}{x^2}:\frac{(x^2-4a^2)}{x^2})=$$ $$=\{\frac{3a^2}{\color{red}{x+2a}}+[x^2:(\frac{\color{pink}x}{\color{green}{x+a}})+a^2:(\frac{\color{brown}a}{\color{green}{x+a}})]:\frac{(\color{violet}{x^2+2ax+a^2})}{(x-2a)}\}:(\frac{(\color{lightblue}{x^2-a^2})}{\bbox[yellow]{x^2}}:\frac{(\color{orange}{x^2-4a^2})}{\bbox[yellow]{x^2}})$$ Since all the fractions that appear have sense iff the denominator is zero and since I have to do some divisions "":"", so I have thought: $$\begin{cases} \color{red}{x+2a}\neq 0\\ \color{green}{x+a}\neq 0\\ \color{pink}x\neq 0\\ \color{brown}a\neq 0\\ \color{violet}{x^2+2ax+a^2}\neq 0 \\ x-2a\neq 0\\ \bbox[yellow]{x^2}\neq 0\\ \color{lightblue}{x^2-a^2}\neq 0\\\color{orange}{x^2-4a^2}\neq 0  \\ (\frac{(\color{lightblue}{x^2-a^2})}{\bbox[yellow]{x^2}}:\frac{(\color{orange}{x^2-4a^2})}{\bbox[yellow]{x^2}})\neq 0\iff (\frac{(\color{lightblue}{x^2-a^2})}{\bbox[yellow]{x^2}}\cdot \frac{(\bbox[yellow]{x^2})}{\color{orange}{x^2-4a^2}})\iff \color{lightblue}{x^2-a^2}\neq 0
\end{cases}$$ And so $$ \begin{cases}x\neq -2a\\ x\neq -a\\ x\neq 0\\ a\neq 0\\ x\neq 2a\\ x\neq a\\\end{cases}$$ Do you think my work is well done? Please can you help me? I don't know where I can check my work...","['fractions', 'algebra-precalculus', 'solution-verification', 'polynomials']"
4065843,"Is there a name for $(x, f(x))$?","Given a function $f$ , and an $x$ from its domain, is there a name for the pair $(x, f(x))$ ? Is there a defined terminology for one (any) such pair? I think the set of all $(x, f(x))$ is called the graph of the function, but I am asking is there's a name for one (or any) point of the graph.","['functions', 'terminology']"
4065875,Applying mean value theorem to function of two variables,"If I am given a function $f$ of two variables, where partial derivatives exist on all of $\mathbb{R}^2$ . Can I apply the mean value theorem on an interval $[x_1,x_2]$ to $f(x,y)$ by fixing a $y_0$ and then apply the mean value theorem for functions of one variable to choose a $c \in (x_1,x_2)$ with $f(x_2,y_0)-f(x_1,y_0)=f'(c)(x_2-x_1)$ ?",['multivariable-calculus']
4065916,How do I find $P(1< Z <2)$ for given problem?,"Suppose  a value z of the continuous random variable Z is generated as follows:
First, a fair die is rolled.If the side of the die facing up has 1 or 2 dots, then z is drawn from a Unif(0,2) distribution;otherwise z is drawn from a Unif(1,4) distribution.
Now for such random variable Z how can you find a P(1<Z<2)??
I am just unable to comprehend what the Z random variable would even look like.","['statistics', 'uniform-distribution', 'random-variables']"
4065917,Find length BC of triangle with incircle and circumcircle,"Some thoughts... some chord theorem to get the angle between PQ and BC... AB and AC are tangent to the circle, there has to be another theorem about that, perhaps ADE is isosceles and that helps looking at the angled PDE and AEQ, and with all this one should be able to figure the angle at A, and once I have that probably I can use yet another theorem on chords to determine the length BC from the length PQ...idk","['trigonometry', 'geometry']"
4066028,One sided derivative of the moment generating function,"Let $Z$ be a random variable with one-sided heavy tailed distribution, that it, the moment generating function of $Z$ is infinite for every $t<0$ , but is finite on interval $[0,z)$ for some $z>0$ . In this case, does the moment generating function have one-sided derivative at $0$ ? If yes, does this derivative is equal to (possibly negative infinite) expectation of $Z$ ? If yes, reference to a book where this is rigorously proved would be appreciated.","['moment-generating-functions', 'calculus', 'probability-theory', 'probability']"
4066035,Step missing in the proof of $\mathbb{R}$ being uncountable.,"Today I saw the proof of the uncountability of $\mathbb{R}$ , where given  a list of all elements of $\mathbb{R}$ , we produce an element not in the list by requiring that its $n$ -th digit is different from the $n$ -th digit of the $n$ -th element of the list. Since it has different decimal expansion from every element in the list, it can't be on the list. I think this last statement is actually wrong since in $\mathbb{R}$ one number can have more than one decimal expansion. So even if the decimal expansion of the newly generated element differs from those of the elements on the list, this doesn't mean that the element is not in the list. Am I right? and if so, how can the argument be fixed?","['elementary-set-theory', 'proof-explanation', 'real-numbers']"
4066076,Are the central quotients of braid groups non-trivial free products?,"The braid group $B_3$ has the property that its central quotient (i.e., $B_3 / Z(B_3)$ ) is isomorphic to the modular group $\mathrm{PSL}(2,\mathbb{Z})$ . The modular group is known to be isomorphic to the free product of $(\mathbb{Z}/2\mathbb{Z}) \ast (\mathbb{Z}/3\mathbb{Z})$ . I'm curious about the extent to which this is true for braid groups $B_n$ for $n > 3$ . Question 1: For which $n > 3$ is it true that there exists two non-trivial groups $G$ and $H$ such that $B_n/Z(B_n)$ is isomorphic to $G \ast H$ ? I'm also curious about a weaker version of this statement where we allow amalgamation over some shared finite subgroup. Question 2: For $n > 3$ is it true that there are groups $G$ and $H$ with common finite proper subgroup $A$ such that $B_n/Z(B_n)$ is isomorphic to $G \ast_A H$ ?","['braid-groups', 'group-theory', 'free-product', 'reference-request']"
4066240,Where did I go wrong with my differentiation here?,"This question involves the product rule and power of a function rule for differentiation. I often make silly algebra errors, but here I cannot find them. The answer is supposed to be y'=22. Thanks! When $x=-1$ , $y=(2x+1)^5(3x+2)^4$ .
Hence, the derivative, $$y'=5(2x+1)^4 \cdot (2)(3x+2)^4 + (2x+1)^5 \cdot 4(3x+2)^3 \cdot 3$$ Plugging in $x=-1$ , $$y'= 5(2(-1)+1)^4 \cdot (2)(3(-1)+2)^4 + (2(-1)+1)^5 \cdot 4(3x+2)^3 \cdot 3\\
y' = 10-12\\
y' = -2$$","['calculus', 'derivatives']"
4066248,"How to summarize the rewards of a ""lottery"" sequence?","I play a game where we can collect a certain type of resource, let's say it is money. With a certain amount of money we can buy a sort of lottery ticket. The ticket either gives back some money or gives other types of resources with certain chances. So what we have is something like: B[money]      balance 
T[function]   ticket
   p[money]   the price of the ticket
   rm[money]  money reward
   cm[%]      chance of winning the money reward
   rx[x]      resource x reward
   cx[%]      chance of winning the resource x reward
   ry[y]      resource y reward
   cy[%]      chance of winning the resource y reward
   rz[z]      resource z reward
   cz[%]      chance of winning the resource z reward
   ... We can buy tickets until we run out of money and there are different types of tickets we can choose from. The goal is comparing tickets and choosing the right one for winning the most type ""x"" resources. It really depends on the players needs which resource is more important for them so for others ""y"" might be more useful. I want to compare tickets to be able to decide which one to choose for my needs. For a comparison I need to know how much rewards I can expect from them when I start with a certain amount of money. For now what I did is using a random number generator and buying tickets until I ran out of money. After that I start over, and I do this for example 10k times. I end up with a multi dimensional reward distribution: $$
T_p(B) = \{
		a_1 x + b_1 y + c_1 z + ...,
		a_2 x + b_2 y + c_2 z + ...,
		...
		a_{10000} x + b_{10000} y + c_{10000} z + ...
\}
$$ After that I calculate average and standard deviation for each resources and end up with a statistics something like the following with for example 68% confidence: $$S(T_p(B)) = (avg(a_i) \pm stdev(a_i))x + (avg(b_i) \pm stdev(b_i))y + (avg(c_i) \pm stdev(c_i))z + ...$$ I am not sure if standard deviation is valid here. Is it? With the average I can compare my chests so for example if ""x"" is the most important resource, then a comparison is something simple like: $$S(T_p).avg.x > S(T_q).avg.x$$ Which means ticket ""p"" gives more resource ""x"" than ticket ""q"", so I have to choose ticket ""p"" over ticket ""q"". What I want to do is figuring out the formula for the upper results. For certain tickets it is trivial to count the average, because they don't give back any money $r_m = 0, x_m = 0$ . $$S(T(B)).{avg} = B/p \cdot [ (r_x \cdot c_x)x + (r_y \cdot c_y)y + (r_z \cdot c_z)z + ... ]$$ Here the number of drawing lots is $L = B/p$ . It is possible to count this number for a ticket that gives back money too. We have a series there: $$L(B) = B/p + L(r_m \cdot c_m \cdot B/p)$$ $$L(B) = B/p \cdot [1 + (r_m \cdot c_m) / p + ((r_m \cdot c_m)/p)^2 + ((r_m \cdot c_m)/p)^3 + ... ]$$ $$L(B) = B/p \cdot \sum_{i=0}^\infty{((r_m \cdot c_m)/p)^i}$$ For this kind of series we can use the following solution: $$L(B) \cdot [1 - ((r_m \cdot c_m)/p)] = B/p \cdot [1 - ((r_m \cdot c_m)/p)^\infty]$$ $$0 < (r_m \cdot c_m)/p < 1$$ $$L(B) = \frac{B/p}{1 - (r_m \cdot c_m)/p} = \frac{B}{p - r_m \cdot c_m}$$ This works pretty well for the average number of drawing lots, but I am not sure how do I get the average for the rewards. Should I just multiply this with the chances and rewards like I did in the trivial case? $$S(T(B)).{avg} = \frac{B}{p - r_m \cdot c_m} \cdot [ (r_x \cdot c_x)x + (r_y \cdot c_y)y + (r_z \cdot c_z)z + ... ]$$ I guess this is right, so this is the easy question. The hard question is how do I get information about the distribution? So what kind of distribution do we have here and how can I describe it? The $0 < (r_m \cdot c_m)/p < 1$ is always true, but $r_m > p$ is possible in the case of some tickets, so it is possible to win more money than we spend on the ticket. Which means it is possible to buy certain tickets infinite times $L_{max}(B) = \infty$ with a zero chance, while there are tickets which can we win only a finite times $L_{max}(B) \neq \infty$ . The $L_{min}(B) = B/p$ is trivial again. I think I can calculate the probability for these corner cases, but I have no idea about how to calculate the probability for the $L(B)$ values that are not average, min or max. I can get the same L value in many possible ways and for me it is a little confusing to work through all of these permutations. Even if I manage to somehow calculate the probabilities for different $L(B)$ values, I have no idea how I can calculate the chance and reward distributions even for these corner cases. For me knowing the $S(T(B)).{avg}$ is enough and probably the formula I wrote for it is ok, I just want to know if it is possible to say anything about the distributions without doing a simulation and how?","['statistics', 'sequences-and-series']"
4066255,how to prove this trig inequality: $\cos x \cos y + z \sin x \sin y \geq \cos \left( \sqrt{x^2 + y^2 - 2 x y z} \right)$,"The following inequality has come up in my work. I'm trying to prove that it is true: $$
\begin{equation}
\cos x \cos y + z \sin x \sin y \geq \cos \left( \sqrt{x^2 + y^2 - 2 x y z} \right)
\end{equation}
$$ where $$
\begin{align}
-\pi \leq{} &x \leq \pi \\
-\pi \leq{} &y \leq \pi \\
-1 \leq{} &z \leq 1
\end{align}
$$ The LHS of the inequality is derived from the spherical law of cosines, the RHS is derived from the law of cosines, and $z$ represents the cosine of another variable. Note that the inequality holds with equality when $z=1$ . I have also put the inequality in the following form using the product-to-sum trig identity, and rearranging the RHS: $$
\begin{equation}
(1+z) \cos(x-y) + (1-z) \cos(x+y) \geq 
2 \cos \left( \sqrt{(x-y)^2 + 2 x y (1-z)} \right)
\end{equation}
$$ I have also tried other things like applying Cauchy-Schwarz to the LHS, and applying arccosine to both sides, but I can't seem to prove that the inequality is true. I am quite certain that the inequality holds because I have performed a Monte Carlo simulation (code shown below) which shows that the inequality holds for randomly sampled values. python Monte Carlo random sampling code import numpy as np

n = 10**6
x = np.random.uniform(-np.pi, np.pi, n)
y = np.random.uniform(-np.pi, np.pi, n)
z = np.random.uniform(-1, 1, n)
lhs = np.cos(x)*np.cos(y) + z*np.sin(x)*np.sin(y)
rhs = np.cos(np.sqrt(x**2 + y**2 - 2*x*y*z))
check = lhs>=rhs
print('inequality is true', np.sum(check), '/', n, 'times')","['trigonometry', 'inequality']"
4066340,Finding all matrices that satisfy a 'wrong property',"I was reminded of a very usual highschool algebra question of a 'wrong property' where students usually just 'distribute squares' like: $(x+y)^2 = x^2+y^2$ . Clearly this is wrong and that if we solve this equation anyway, then we arrive at $2xy = 0.$ This means that the solution set for which this 'wrong property' holds is when you have any real number $x$ and $y=0$ , or both are zero. Coming to linear algebra, we have a quite similar common misconception that $(\mathbf{A} + \mathbf{B})^{-1} = \mathbf{A}^{-1} + \mathbf{B}^{-1}$ . My question is, can we find all $2\times 2$ matrices that satisfy this equation? I tried solving this, but it is proving a bit difficult, so I made some assumptions like let $\mathbf{A}$ be the identity matrix $\mathbf{I}_2$ , can we find all $\mathbf{B}$ that satisfies this 'wrong property'?","['matrices', 'soft-question', 'linear-algebra', 'inverse']"
4066410,The sums of squares from standard deviation,"I am trying to figure out how to get a sum of squares from a standard deviation. The standard deviations I have are $11.04$ , $9.91$ and $9.43$ . How do I calculate the sum of squares associated with these standard deviation values? Thanks!","['statistics', 'standard-deviation']"
4066432,"Is there a bounded, increasing elementary function with unbounded derivative?","Is there an elementary function function $f(x)$ with the following properties: $f(x)$ is defined and infinitely differentiable on all of $\mathbb{R}$ $f(x)$ is bounded $f^\prime(x)$ is nonnegative and unbounded If we don't require $f(x)$ to be an elementary function, then we can take $$f(x)=\int_0^x\frac{t^2}{1+t^8\sin^2(\pi t)}\,dt$$ (the integrand is nonnegative, unbounded, but has finite area, desmos link ). This question can also be rephrased in terms of an unbounded probability mass function with elementary antiderivative.","['elementary-functions', 'calculus', 'derivatives']"
4066439,"Given a collection of curves, find the differential equation associated with them","The question is as follows: $$
\text { 1) } y=\frac{\sec x}{c_{1}+c_{2} \tan x} \quad ; \quad \underline{\text { The Answer is  }}: y y^{\prime \prime}-2 y^{\prime 2}-y^{2}=0
$$ My main problem with this question is the long algebraic process. Is there any fast way to solve this question? One possible way of solving this is to form a matrix involving y' , y'' , and y and try to make a system of equations with that matrix. Then because the equation should have a non-zero answer, we set the determinant to zero. This is algebraically time consuming and provides the possibility for mistakes.",['ordinary-differential-equations']
4066478,"Given $x^2 +px + q$ has roots -1 & 4, find the values for p & q.","Given $x^2 +px + q$ has roots $-1$ & $4$ , find the values for $p$ & $q$ . Attempt: $$
x = \frac{-p\pm\sqrt{p^2-4q}}{2}\\(p + 2x)^2 = p^2 - 4q\\
p^2 + 4px + 4x^2 = p^2 -4q
\\
q = -x^2 - px
\\
q = -(-1)^2 -p(-1)
\\
q = -1 - p
\\
q = -(4)^2-p(4)
\\
q = -16 - 4p
\\
-1 - p = - 16 - 4p
\\
3p = -15
\\
p = -5
\\
q = -1 - (-5)
\\
q = 4
$$ According to the book the answer should be $-3$ & $-4$",['algebra-precalculus']
4066488,How do you solve this problem from Kangaroo Math Competition 2016 Junior?,"Dates can be written in the form DD.MM.YY. For example, today's date is 17.03.2016. A date is called ""surprising"" if all 8 digits in its written form are different. In what month will the next surprising date occur? From what I understand, I think we need to make sure that the year does not have a 1 digit, a 0-digit, or a 2-digit, in order for us to be able to maximize the probability that the month is a number underneath 10. However, I do not know where to go from there. Any help? The answer is June, but I do not know why.",['algebra-precalculus']
4066512,Find $\sum_{j=0}^{n}\sum_{i=j}^{n} {n \choose i}{i \choose j}$.,Find $\sum_{j=0}^{n}\sum_{i=j}^{n} {n \choose i}{i \choose j}$ . I don't know how to double summations like this very well. Can someone expand this to show how the $i=j$ thing works? I tried the following: ${n \choose i}{i \choose j}={n \choose j}{n-j \choose i-j}$ $\sum_{j=0}^{n}\sum_{i=j}^{n} {n \choose i}{i \choose j}=\sum_{j=0}^{n}\sum_{i=j}^{n} {n \choose j}{n-j \choose i-j}=\sum_{j=0}^{n} {n \choose j}{n-j \choose 0}=2^n$ Where am I going wrong?,"['summation', 'binomial-coefficients', 'combinatorics']"
4066514,Quasi Coherent and Coherent sheaves on formal schemes.,"Let $A$ be a noetherian ring complete with respect to a principal ideal $(\pi)$ : $A\simeq\lim_\leftarrow A/(\pi^n)$ . Denote by $X$ the formal scheme $Spf(A)$ and by $X_{n-1}$ the scheme $Spec(A/(\pi^n)$ . Let $\cal F$ be a quasi coherent sheaf on $Spf(A)$ . Denote by $\cal F_n$ the restriction of $\cal F$ to $X_n$ . Question: Is it true that $\cal F$ is coherent if and only if $\cal F_0$ is coherent on $X_0$ ? Edit : Of course one direction is evident. I think that the other is also true because of the exact sequence, $$0\longrightarrow \cal F_0\otimes (\pi^n)/(\pi^{n-1})\longrightarrow\cal F_n\longrightarrow\cal F_{n-1}\longrightarrow 0$$ and induction on $n$ . But I didn't find the statement in the standard literature, thus I wonder if this argument is wrong for some reasons I do not see (and my misunderstanding of formal geometry).","['algebraic-geometry', 'coherent-sheaves', 'quasicoherent-sheaves']"
4066648,Confusion about equation of a plane,"This is a confusion that I've always had, that I've never quite gotten rid of. (I'm definitely making a foolish mistake somewhere, I know... Sorry) Suppose $x,v \in \mathbb{R}^3$ , and $c \in \mathbb{R}$ . The equation of a plane in $\mathbb{R}^3$ is given: $\{x: \langle x, v\rangle=c\}$ , where the inner product denotes the dot product. The reason why this is a plane is, for an $x_0$ such that $\langle x_0, v\rangle=c$ , we have $\langle x-x_0, v\rangle=0$ , so $x-x_0$ is a plane that is perpendicular to the vector $v$ . But alternately, using $x \cdot v = |x| |v| \cos (\theta)$ where $\theta$ is the angle between $x,v$ , shouldn't $\{x: \langle x, v\rangle=c\}$ look like a circle around the vector $v$ in mid air (i.e. away from the origin of $\mathbb{R}^3$ ), where the vector $x_0$ (defined as above) has been rotated around the vector $v$ ? Because rotating the vector $x_0$ around the vector $v$ , the angle between $x_0$ and $v$ stays equal, while there is no change in the length of the two vectors. But clearly this is wrong, as it must be a plane, not a circle.","['recreational-mathematics', 'linear-algebra', 'geometry']"
4066669,Proving that Gauss map $N: S \rightarrow \mathbb{S}^{2}$ is surjective,"I'm taking a course in elementary differential geometry, and there was the following problem. Let $S \subset \mathbb{R}^{3}$ be a non-empty, compact, and connected surface. Assume that (by the ""Jordan-Brouwer"" theorem) we can talk about ""inside and outside"" components of $S$ . Let $N(p)$ be the outward normal vector at $p \in S$ . Prove that the Gauss map $N: S \rightarrow \mathbb{S}^{2}$ is surjective. Solution: Fix a unit vector $v \in \mathbb{S}^{2},$ and consider the family of planes $$
P_{c}=\left\{x \in \mathbb{R}^{3} \mid\langle x, v\rangle=c\right\}, \quad c \in \mathbb{R}
$$ Since $S$ is compact, the function $x \mapsto\langle x, v\rangle$ on $S$ achieves its maximum value at some point $p \in S$ . Define $c_{0}=\langle p, v\rangle$ . Then $S \cap P_{c}$ is empty for all $c>c_{0}$ whereas $S \cap P_{c_{0}}$ is not empty. We claim that $v=N(p)$ . To see this, consider an arbitrary smooth curve $\alpha:(-\epsilon, \epsilon) \rightarrow S$ , with $\alpha(0)=p$ and $\alpha^{\prime}(0)=w \in T_{p} S$ . Since $f(t)=\langle\alpha(t), v\rangle$ is maximised at $t=0$ , we must have $0=f^{\prime}(0)=\langle w, v\rangle$ . Therefore, $v$ is orthogonal to any tangent vector to $S$ at $p$ . In fact, $v$ must be the outward unit normal vector, since all of $S$ lies in the half-space $\langle x, v\rangle \leq\langle p, v\rangle$ . As $v \in \mathbb{S}^{2}$ was arbitrary, the Gauss map $N: S \rightarrow \mathbb{S}^{2}$ must be surjective. I don't understand the line ""In fact, $v$ must be the outward unit normal vector, since all of $S$ lies in the half-space $\langle x, v\rangle \leq\langle p, v\rangle$ ."" Why is this? I can't understand this intuitively, nor can I understand it formally (with an actual proof). Does anyone know why this is?","['solution-verification', 'surfaces', 'differential-geometry']"
4066681,Proof by induction on two variables,"Suppose we have relation $T(n,k)=\begin{cases}
		T(n,k)=T(n-1,k-1)+T(n-1,k)+1, & \\
		1,\text{$k=0  \text{ or } n=k$} 
	\end{cases} 
$ . Now we relate above relation to $C(n,k)$ . Let $C(n,k)=T(n,k)+1$ then $C(n,k)=C(n-1,k-1)+C(n-1,k)$ this is exactly relation binomial coefficients. Now i want prove that $C(k,n)=2\binom{n}{k}$ , But when i use iduction on $k,n$ get stuck. How i can use induction on this problem? My attempt:(i read this post ) First i define $P(t)$ such that $t=k+n$ , and $0\leq k\leq n$ , and $C(n,k)=2\binom{n}{k}$ , now main problem is how i can relate $P(t+1)$ to $P(t)$ ? Any hint be appreciated.","['induction', 'discrete-mathematics']"
4066705,$L^1(\mathbb{P}) \neq L^1(\mathbb{Q})$ in general?,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $L^1(\mathbb{P})$ denote the collection of all random variables that are $\mathbb{P}$ -integrable. Now let $\mathbb{Q}$ be an absolutely continuous probability measure w.r.t $\mathbb{P}$ and denote its Radon-Nikodym derivative by $Z$ .  Denote the collection of random variables that are $\mathbb{Q}$ -integrable by $L^1(\mathbb{Q})$ .  We know that $X \in L^1(\mathbb{Q})$ if and only if $ZX \in L^1(\mathbb{P})$ . Is it true that if $Z \notin L^\infty$ , then there exists $X \in L^1(\mathbb{P})$ such that $\mathbb{E}[ZX] = \infty$ ? I am fairly sure this is true, but I am not sure how to prove it.","['expected-value', 'measure-theory', 'functional-analysis', 'random-variables']"
4066718,The derivation of the product in Sobolev space,"Let $f \in W^{1,\infty}(0,T)$ and $g \in W^{1,1}(0,T)$ $(0<T\leq\infty)$ . Is $(fg)'= f'g+fg'$ true? Thanks","['sobolev-spaces', 'functional-analysis']"
4066750,What is the sum of the coefficients?,"If $h(x) = x^4+ax^3+bx^2+cx+d$ then what is $a+b+c+d$ ? I try: \begin{align}
x=2: 2^4+2^3a+2^2b+2c+d = 3 &\implies 8a+4b+2c+d = -13 \label{I} \tag{I}\\
x=-2:-2^4-2^3a-2^2b-2c+d=3 &\implies  -8a+4b-2c+d = -13 \label{II} \tag{II}\\
\eqref{I} + \eqref{II} \colon 8b +2d = -26 &\implies \boxed{4b+d = -13} \ em \tag{I}\\
8a-13+2c=-13 &\implies 8a+2c = 0 \implies\boxed{4a+c = 0}
\end{align} I stop here..don't find another equation",['functions']
4066889,"Probability, dependent Events","I am trying to understand some of the tasks and would be happy if someone could check my solution and possibly point out any mistakes.
In advance, I am not asking for a solution, because I would like to work it out by myself. The purpose of this exercise is to check whether events A and B are independent of each other. Three dices are thrown.
The events are defined as follows: A: All dice have the same number of dots. B: The total sum of the dices is less than 5. Therefore is $A = \left \{ \left ( 1,1,1 \right ), (2,2,2), (3,3,3), (4,4,4), (5,5,5), (6,6,6) \right \}$ $B = \left \{ \left ( 1,1,1 \right ), (1,1,2), (1,2,1), (2,1,1) \right \}$ Some intermediate results: $P\left ( A \right ) = \frac{6}{216} = \frac{3}{108}$ $P\left ( not A \right ) = 1 - P(A) = 1 - \frac{3}{108} = \frac{35}{36}$ $P(B) = \frac{4}{216} = \frac{1}{54}$ $P(A\cap B) = \frac{1}{216}$ $P(notA\cap B) = \frac{3}{216}$ A and B are independent if $P(B|notA) = P(B|A)$ $
P(B|A) = \frac{P(A\cap B)}{P(A)} = \frac{\frac{1}{216}}{\frac{6}{216}} = \frac{1}{6}
$ $
P(B|notA) = \frac{P(notA\cap B)}{P(notA)} = \frac{\frac{3}{216}}{\frac{35}{36}} = \frac{1}{70}
$ Thus, the events A and B are dependent. Thank you in advance for your time.",['probability']
4066921,"Is $f(x,y,z)=x^2y^2z^2\sin(\frac{1}{xyz})$ when $xyz\neq 0$ and $0$ else differentiable everywhere?","Is $$f(x,y,z)=\begin{cases}
x^2y^2z^2\sin\left(\frac{1}{xyz}\right), & xyz\neq 0\\
0, &\text{else}\end{cases}$$ differentiable everywhere? Here is my proof. If $x,y,z\neq0$ then $f$ is differentiable as a composition of differentiable functions.
if $x=0$ and $y=u,z=v$ then: \begin{align*}
\lim_{(x,y,z)\to(0,u,v)} \left|\frac{x^2y^2z^2\sin(\frac{1}{xyz})}{\sqrt{x^2+(y-u)^2+(z-v)^2}}\right|&\leq \lim_{(x,y,z)\to(0,u,v)} |y^2z^2|\left|\frac{x^2}{\sqrt{x^2+(y-u)^2+(z-v)^2}}\right|\\[5pt]
&\leq u^2v^2 \lim_{(x,y,z)\to(0,u,v)} \left|\frac{x^2}{\sqrt{x^2}}\right|\\
&=0
\end{align*} and so $f=0+o(|(x,y,z)-(0,u,v)|)$ so $Df=0$ and $f$ is differentiable. In the same way we can show that if $x,y=0,z=u\neq0$ then $f$ is differentiable at $(0,0,u)$ with differential $0$ . Also at $(x,y,z)=(0,0,0)$ the function over $|(x,y,z)-(0,0,0)|$ is bounded by $C\cdot r^5$ and so its differentiable at $(0,0,0)$ ans all in all its differentiable everywhere. Is my solution or am I missing something? I think I am correct, although my multivariable calculus is a bit rusty hence the post.","['limits', 'multivariable-calculus', 'solution-verification', 'derivatives']"
4066937,How to use MVT to prove the following problem,"Let $f(x)$ be continuous on $[a,b]$ , differentiable on $(a,b)$ , and $f(a)=f(b),|f'(x)|\leqslant1$ . prove that for any $x_1,x_2\in[a,b]$ establish $$|f(x_1)-f(x_2)|\leqslant\frac{b-a}{2}.$$ I want to use MVT.But I don't know how did the $\frac{1}{2}$ .","['derivatives', 'real-analysis']"
4067069,How to find the expectation of $\log x$？,"Let $X_1,...,X_n$ be a random sample. The pdf is $f(x\mid\theta)=\theta x^{\theta-1},0<x<1,\theta>0$ .
I want to know $\mathbf{E}(\log x)$ . $$\int_0^1 \theta x^{\theta-1} \log x \;dx$$ I don't know how to solve this integral.","['integration', 'statistics', 'probability']"
4067114,Heron's Formula,"Heron's Formula gives the area of a triangle when the length of all three sides are known. There is no need to calculate angles or other distances in the triangle first to determine its area. The formula is given by $Area=\sqrt{p(p-a)(p-b)(p-c)}$ , where $p=\frac{a+b+c}{2}$ , $a, b, c$ are sides of the triangle and $p$ is the semi-perimeter of the triangle. The following is my concern: If one of the sides of the triangle is greater than $p$ , then the Area will not be a real number (which shouldn't be true). Example.  Let the sides of a triangle be 175 metre, 88 metre and 84 metre, then $p=173.5$ . Therefore, $Area=\sqrt{-1991498.0625}$ , which not a real value. Therefore, the following is my question: Why shouldn't the area be expressed as $Area=\sqrt{|p(p-a)(p-b)(p-c)|}$ ?","['triangles', 'area', 'geometry']"
4067140,"Solving $y'' - 2y' + y = \delta(t-2)$ for y(0) = 0, y'(0) = 0 by using Laplace Transforms. Need help finishing the problem.","So I'm working on this question and I've taken the Laplcace transforms for everything and separated it as $Y(s) = F(s)G(s)$ , and then I've put it into the convolution equation to get $y(t)$ . My problem is, I don't understand how to fully/properly integrate this when I have the $\delta(T-2)$ inside the integral. Can anyone explain what to do? I'm adding a picture of what I have until now that I am sure is correct so that there's somewhat of an explanation of my train of thought? (the u and v' at the bottom were if I was going to solve with integration by parts, which I also am not sure of how to use here).
But yeah, please help and tell me where I'm going wrong...","['integration', 'dirac-delta', 'ordinary-differential-equations', 'convolution', 'laplace-transform']"
4067148,Calculate limit of $\Gamma$ function for special values.,"I would like to calculate the limit without any software but have no idea how to do it. $$f(n) = \lim_{c \rightarrow 0} \frac{\Gamma(-n + c) + \Gamma(-n - c))}{2}$$ $$n = 0, 1, 2, ...$$ Wolfram in some way claculates it, for example: $$f(0) = - \gamma$$ $$f(1) = \gamma - 1$$ $$f(2) = \frac{3 - 2 \gamma}{4}$$ $$f(3) = \frac{6 \gamma - 11}{36}$$ $$(...)$$ It seems that the solutions will be somethink like that: $$f(n) = \frac{(a - \gamma)(-1)^{n}}{b}$$","['gamma-function', 'limits', 'convergence-divergence']"
4067196,Minimum number of subsets,"For some integer $n$ , consider $S=\{1, \dots, n\}$ . Let $S_1, \dots, S_k$ be subsets that satisfy the property that each $x\in S$ is in exactly 3 of the $S_i$ 's and so that the intersection of these three subsets is $x$ . What is the minimum value of $k$ (the number of subsets)? I thought that if each $x$ was in 2 of the sets, $k$ would be at least $2*\sqrt{n}$ , but was not sure how to proceed for the case of 3 sets.","['combinatorial-designs', 'combinatorics', 'extremal-combinatorics']"
4067210,Combinatorial identity on decreasing dice throws,"Suppose I repeatedly throw fair $n$ -sided dice until I throw a $1$ , at which point I stop. I want to know the probability $p(n)$ that my sequence of throws will be decreasing, such as $5-4-2-1$ or just $1$ immediately, but not $2-3-1$ which would count as a failure. The answer clearly depends on whether I am considering strictly decreasing sequences in which case $4-2-2-1$ would count as a failure, or weakly decreasing sequences in which case it would be a success. Allowing weakly decreasing sequences would increase the probability and would mean there is no bound on the potential length of successful sequences. For strictly decreasing sequences I have $$p_s(n)=\sum\limits_{k=1}^n {n-1 \choose k-1}\frac{1}{n^k} = \frac{(n+1)^{n-1}}{n^n}$$ For weakly decreasing sequences and $n>1$ I have $$p_w(n)=\sum\limits_{k=1}^\infty {n+k-3 \choose k-1}\frac{1}{n^k} = \frac{n^{n-2}}{(n-1)^{n-1}}$$ For example with $n=6$ , I get $p_s(6)=\frac{7^5}{6^6}\approx 0.36023$ and $p_w(6)=\frac{6^4}{5^5}\approx 0.41472$ . In general $$p_s(n)=p_w(n+1).$$ Is there a combinatorial argument that leads to this equality between the finite sum and the infinite sum?","['dice', 'combinatorics', 'combinatorial-proofs', 'probability']"
4067218,Test if coin is fair with significance/confidence of 95%,"Please take a look at the next $10$ mins of this lecture starting here: https://youtu.be/rYefUsYuEp0?t=1147 We are trying to find a number $\xi$ such that: $P(|S_n-n \cdot (1/2)| \le \xi) \approx 0.95$ The professor finds $\xi=31$ but he says that he ""pretends"" $S_n$ is approximately standard normal.
Why $S_n$ ? I apply the CLT literally and so I ""pretend"" that $$Z_n = \frac{(S_n - n/2)}{(1/4)\cdot\sqrt{n}}$$ is standard normal. By ""pretend"" I just mean the usual i.e. I get the right to use the standard normal tables (as justified by the CLT). In the standard normal table I looked for $0.975$ and I found the Z-score number $1.96$ . When I did all the computations I got $\xi = 15.495$ which is twice less. Why? I am interpreting it this way: if I make 1000 coin tosses and if the number of heads I observe is no more than 15 away from 500, then I conclude with certainty of about 95% that my coin is fair. Am I incorrect conceptually? Or did I mess up the calculations? Or is there something else here which I am not taking into account? A deviation/difference of 31 given 1000 coin tosses seems too much to me just intuitively. But intuition can lie. Also, not sure why he says $S_n$ is approximately standard normal. It should be $Z_n$ , right? Maybe the lecturer is oversimplifying just for presentation purposes, and that's why he gets 31 and not 15.49. Is it indeed so?","['statistical-inference', 'statistics', 'central-limit-theorem', 'probability']"
4067258,Transposition Distance between two permutations.,"I'm working on the following problem. Suppose that $A \subseteq S_n$ is a subset of at least $n!/2$ permutations, and let $A(t)$ be the set of permutations that can be obtained from starting at some element of $A$ , and then applying at most $t$ transpositions. Prove that there is some absolute constant $c > 0$ so that $$A(t) \geq (1-e^{-ct^2/n})n!$$ My first thoughts are that I want to use the Talagrand concentration theorem, but for that I need to write $S_n$ as a product space. Since I can write any permutation $\sigma$ as a product of transpositions, I thought maybe I could think of $S_n$ as the product of $m = \binom{n}{2}$ independent identically distributed random variables taking values either $0$ or $1$ , and a vector of $0$ 's and $1$ 's would correspond to whether or not the indicated transposition was in a minimal representation of $\sigma$ as a product of transpositions. This has some problems however. First of all, I doubt this is well defined since there are several ways we can write $\sigma$ as a product of transpositions. The second problem is that order matters, since $(12)(23)$ and $(23)(12)$ give different permutations. Is there any way I can use Talagrand concentration to approach this problem, probably with a different setup? Does anyone have any thoughts on a different approach?","['probabilistic-method', 'combinatorics', 'probability']"
4067277,Help finding partial derivative with chain rule,"I'm having trouble finding the partial derivative of $z$ with respect to $x$ of this function: $$z(x,y) = f(x + y) + f(x - y)$$ I saw this exercise online, but I can't figure it out. How can I solve it? Because the functions $f(x + y)$ and $f(x - y)$ only depend on one variable, but I don't understand why their input is an expression involving $x$ and $y$ .
Thank you!","['multivariable-calculus', 'calculus', 'derivatives', 'chain-rule']"
4067359,"Let $X, Y, Z \sim N(0, 1)$ and are independent. How to show that $\frac{X + ZY}{\sqrt{1 + Z^2}} \sim N(0, 1)$? [duplicate]","This question already has answers here : Finding distribution of $\frac{X_1+X_2 X_3}{\sqrt{1+X_3^2}}$ (2 answers) Closed 3 years ago . Let $X, Y, Z$ be i.i.d. random variables distributed as $N(0, 1)$ . How to show that $\dfrac{X + ZY}{\sqrt{1 + Z^2}} \sim N(0, 1)$ ? The only solution I see is to progressively find the distributions of First, $ZY$ Then $U := X + ZY$ Then $V := \sqrt{1 + Z^2}$ Then $\dfrac{U}{V}$ But finding these distributions appears to be a nightmare in terms of the number of calculations to be done. And this solution doesn't really explain the intuition behind this problem: how could this expression randomly end up being $N(0, 1)$ -distributed? That makes me wonder if there is a more nice solution. I also think, this is probably a well-known problem, but I couldn't find a solution anywhere. Any help would be greatly appreciated!","['normal-distribution', 'probability']"
4067446,How to prove that $\phi=f:S\rightarrow \mathbb{S}^2$ is a bijection without using $h$?,"If $f:\mathbb{R}^3\rightarrow \mathbb{R}$ given by $f(a,b,c)=e^{a^2}+e^{b^2}+e^{c^2}$ defining $h:\mathbb{R}\rightarrow \mathbb{R}$ by $h(t)= f(ta, tb, tc)$ , we have that $h'(t)>0$ give us all conditions to define a bijection (diffeomorphism) $\phi=f:S\rightarrow \mathbb{S}^2$ . Would someone explain this bijection please? And also help me to find another way to prove this? ( $S=\{(a, b, c)\in \mathbb{R}^3: f(a, b, c)=a\}\; \text{with}\; a>3$ )","['differential-topology', 'diffeomorphism', 'differential-geometry']"
4067471,Is there a Laplace transform for an unknown squared function?,"I was solving the differential equation $$y'-y = e^x y^2$$ I know that this is a simple differential equation, and I would solve it with a simple change of the variable, however, I was wondering if I could use Laplace transform to make it easier and more direct.
I asked my professor, and she said she didn't know. So is there a way to do $\mathscr{L}([y(x)]^2)$ ?","['laplace-transform', 'ordinary-differential-equations']"
4067479,Every closed ideal in $C(X)$ is the set of functions that vanish on some closed subset,"This is an exercise from Banach Algebra Techniques in Operator Theory by Douglas My attempt: I've seen a similar argument that shows that every maximal ideal is of the form $I_x = \{ f \in C_0(X) : f(x)= 0\}$ . I tried the same approach, by considering the evaluation map $\phi_x : C_0(X) \rightarrow \mathbb{C}$ , where $\phi_x(f) = f(x)$ for $x \in K$ . Then it seemed like that the same argument wouldn't work, because we are dealing with closed ideals. So I'm not sure how to proceed. Any help will be appreciated! Thank you!","['c-star-algebras', 'general-topology', 'functional-analysis', 'operator-algebras']"
4067482,"Better way to solve $\cos\left(\frac{\gamma'}{2}\right) = g_0$ and $e^{i\beta'} \sin\left(\frac{\gamma'}{2}\right) = g_1$ for $\gamma',\beta'$?","I'm trying to solve the two equations to solve for: $\gamma',\beta'$ : \begin{align}
\cos\left(\frac{\gamma'}{2}\right) = g_0\qquad e^{i\beta'}\sin\left(\frac{\gamma'}{2}\right) = g_1
\end{align} Where $g_0$ is real, and $g_1$ is some complex number. I tried \begin{align*}
\gamma'=2\cos^{-1}(g_0),\qquad\cos(\beta')\sin\left(\frac{\gamma'}{2}\right)=Re(g_1),\ \text{(or)}\ \sin(\beta')\sin\left(\frac{\gamma'}{2}\right)=Im(g_1)
\end{align*} Then for each $\gamma'$ , there should be two corresponding $\beta'$ s. However, it turned out that my solution doesn't quite work. I'm wondering is there another way I can solve this? Thanks!","['trigonometry', 'systems-of-equations', 'complex-numbers']"
4067498,Extensions of $\mathbb{Z}$ by $\mathbb{Z}$,"Given two groups $G$ and $H$ , an extension of $G$ by $H$ is a group $K$ with a normal subgroup $N$ isomorphic to $H$ such that the quotient group $K/N$ is isomorphic to $G$ (equivalently, $1 \to H \to K \to G \to 1$ is an exact sequence). So, up to isomorphism, how many (not necessarily abelian) extensions of $\mathbb{Z}$ by $\mathbb{Z}$ are there? One obvious extension is the direct product $\mathbb{Z} \times \mathbb{Z}$ . Another extension is the group with the same underlying set as $\mathbb{Z} \times \mathbb{Z}$ and $(a,b) \ast (c,d)$ still defined to be $(a+c,b+d)$ if $b$ is even, but it is defined to be $(a-c,b+d)$ if $b$ is odd (or simply, $(a+(-1)^bc,b+d)$ ). This nontrival extension is the semidirect product $\mathbb{Z} \rtimes \mathbb{Z}$ corresponding to the homomorphism $\mathbb{Z} \to \operatorname{Aut}(\mathbb{Z})$ where even integers act as the identity and odd integers act as negation. The answer would be $2$ if the direct product and the even/odd semidirect product were the only extensions up to isomorphism. Is this in fact the case?","['group-extensions', 'group-theory', 'exact-sequence']"
4067541,Optimal Strategy for a betting game.,"I shall present my question and then add some of the working I have tried, unfortunately I haven't had much luck so far. The game The game is played between $3$ players. You and $2$ opponents who we shall call $I$ and $R$ (for intelligent and random) You each select an integer from $1-100$ (inclusive) and then money is exchanged as follows: Whoever selected the Largest number is the looser, they must pay the two winners what they each selected. Example: You pick $42$ , $I$ picks $12$ and $R$ picks $51$ then $R$ must pay you $\$42$ and he must pay $I$ $\$12$ In the event of a two or more players selecting the largest number then a looser is selected uniformly between them. $R$ plays uniformly randomly, that is he selects his pick uniformly between the first $100$ integers. $I$ Plays perfectly to maximise their own E.V (all standard game theory assumptions) What should your strategy be to maximise your expected value? My workings so far: For what it is worth in the 2 player scenario where it is just you v.s $R$ then you should pick $33$ as $\mathbb{E}[\delta_x ] = \frac{100-x}{100}(x) - \frac{x-1}{100}(-\frac{x}{2})$ (where $\delta_x$ is the strategy of picking $x$ ) This function is maximised at $33$ from simple calculus. No the answer is not $1$ as picking $2$ performs much better when you know someone is picking $1$ I asked my teacher and they said a mixed strategy but I am struggling with formulating this. My idea was to determine $f(x,y) = \mathbb{E}[\delta_x | \text{other player is picking y } ]$ and then find the maxima of this function but I am struggling. Any help would be great :)","['statistics', 'expected-value', 'game-theory', 'optimization', 'probability']"
4067563,Does $G/\mathbb{Z} \cong \mathbb{Z}$ imply $G \cong \mathbb{Z}^2$? [duplicate],"This question already has answers here : Extensions of $\mathbb{Z}$ by $\mathbb{Z}$ (2 answers) Closed 3 years ago . Let $G$ be a group. If $G/\mathbb{Z} \cong \mathbb{Z}$ , does it follow that $G \cong \mathbb{Z}^2$ ? More generally: for a normal subgroup $H$ of $G$ , if $G/H \cong H$ , does it follow that $G \cong H\oplus H$ ?",['group-theory']
4067719,Suppose $f:X\to Y$ is continuous at $a$. Can I use $a$ in my $\epsilon-\delta$ proof?,"For example, is the following proof valid? Assume $f:\mathbb{R}\to\mathbb{R}$ is continuous everywhere. Let $a\in\mathbb{R}$ be a designated point of continuity. Let $\epsilon>0$ and find $\delta>0$ such that $|x-a|<\delta$ implies $|f(x)-f(a)|<\min(\epsilon,\frac{\epsilon}{\epsilon+2|f(a)|})$ , then \begin{align*}
|f(x)-f(a)|&<\frac{\epsilon}{|f(x)|+|f(a)|}\hspace{15 mm} b/c\hspace{5 mm} |f(x)|<\epsilon+|f(a)|\\
&\leq\frac{\epsilon}{|f(x)+f(a)|}
\end{align*} Therefore, $|f^2(x)-f^2(a)|<\epsilon$ and so $f^2$ is continuous on $\mathbb{R}$ . I believe this is good because $a$ is chosen arbitrarily from the outset. I just don't like it. If it is indeed valid, maybe you can help convince me it's not so bad?","['epsilon-delta', 'analysis', 'real-analysis', 'continuity', 'calculus']"
4067761,Dimensions of Orthogonal Group Representations,"I'm aware that the irreducible representations of the orthogonal group $O(n;\mathbb{C})$ are labeled by partitions $\lambda$ such that the sum of the first two columns of $\lambda$ is at most $n$ . Is there a way to determine the dimension of the $\lambda$ representation? Perhaps by counting some kind of tableau, similar to how we do for the symmetric group $S_n$ ?","['matrices', 'orthogonal-matrices', 'integer-partitions', 'representation-theory']"
4067791,Counting the number of partitions such that every part is divisible by $k$.,"I would like to do this using generating functions. I'm comfortable with the generating function for the number of partitions of $n$ : $$(1+x+x^2+\dots)(1+x^2+x^4+\dots)(1+x^3+x^6+\dots)\cdot\dots,$$ although I'm not entirely sure how to adapt it to deal with certain restrictions, such as asking that every part is divisible by $k$ , or divisible by some pair of numbers, say $k$ and $j$ . I was thinking something like $$(1+x^k+x^{2k}+\dots)(1+x^{2k}+x^{4k}+\dots)(1+x^{3k}+x^{6k}+\dots)\cdot\dots.$$ Any advice or hints to get be going would be greatly appreciated!","['integer-partitions', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
4067824,$b=a^p+1$ is a perfect square. Show that $p|(b-9)$,"$p$ is  a prime, and $a$ is a positive integer, $b=a^p+1$ is a perfect square. Show  that $p|(b-9)$ It seem very interesting problem.if let $a^p+1=x^2$ ,it is clear $p\neq 2$ I have prove : $x$ is odd proof:if $x$ is even number,then $(x+1,x-1)=1$ ,and note $a^p=(x+1)(x-1)$ ,then exist $r>s\ge 1\in N^{+}$ such $x+1=r^p,x-1=s^p$ so $$2=(x+1)-(x-1)=r^p-s^p=(r-s)(r^{p-1}+r^{p-2}s+\cdots+s^{p-1})
\ge p\ge 3$$ which is contradiction which is a pretty interesting and nice result. I wonder in which ways we may approach it.","['contest-math', 'number-theory']"
4067944,I'm trying to prove $ M \subset N \Rightarrow M \cup(N \setminus M) = N $,"I'm trying to prove: $$
M \subset N \Rightarrow M \cup(N \setminus M) = N
$$ My trial: $
\{x|x\in M \cup(N \setminus M)\} \Leftrightarrow \{x|x\notin \overline{M \cup(N \setminus M)}\}
$ using de Morgan $ \Leftrightarrow \{x|x\notin \overline{M} \cap \overline{(N \setminus M)}\}$ $ \Leftrightarrow \{x|x\notin \overline{M} \wedge x \notin \overline{(N \setminus M)}\}$ $ \Leftrightarrow \{x|x\notin \overline{M} \wedge x \in (N \setminus M)\}$ $ \Leftrightarrow \{x|x\notin \overline{M} \wedge x \in N \wedge x\notin M\}$ aand we got a problem here. $x$ cannot be both $x\notin \overline{M}$ and $x\notin M$ .
My steps seems logical to me. Can someone please spot my mistake. Thanks a lot!","['elementary-set-theory', 'proof-writing', 'solution-verification']"
4067945,Topology of the set of zeros of a family of polynomials,"My general question is very vague, so before let's look at the following example.
Fix $n\in\mathbb{N}$ and consider a family of polynomials $p_a (z) = (az+1)^n - \dfrac{z^{n+1}-1}{z-1}$ for $a\in\mathbb{R}$ and $z\in\mathbb{C}$ . Here we view $a$ as a parameter of a family. Let's fix $n\in\mathbb{N}$ large enough ( $n=50$ ) and draw the sets of roots of $p_a(z)$ for some $a$ 's. For $a=1$ we have For $a=\dfrac{10}9$ : For $a=\dfrac{12}9$ : For $a=\dfrac{15}9$ : For $a=2$ : First, when $a=1$ the roots lie near the circle and the $\Re =-\dfrac12$ line.
As $a$ increases the line transforms into another circle and finally the two circles merge.
For $a>2$ nothing new happens.
If one instead decreases $a$ then the second circle forms analogously.
The exact same pattern holds for any bigger $n$ . Now, in this particular example I do understand why any of this happens and my question is more general: Is there any theory that studies topology of zero sets for parametrized families of polynomials? I'm not really sure what I precisely mean by topology in this case as the set of roots is discrete. Maybe some approximation by removing all the balls from $\mathbb{C}$ of fixed radius that do not intersect the set of roots. By varying the radius of such balls we will get different approximation.","['complex-analysis', 'general-topology', 'geometry']"
4067964,In how many ways can a team be formed when some players can play multiple positions?,"I want to form a lineup where we have 1 goalkeeper, 2 defenders and 3 forwards. We have 3 goalkeepers, 7 defenders and 10 forwards available, as well as 4 players who can play as defender or forward. How many possible lineups are there? My approach was to separately consider the cases where $n$ of the 4 players (lets call them hybrid players) who can play as defender or forward are first chosen as defenders or forwards. If we first pick the 2 defenders, we can pick 0, 1 or 2 of the hybrid players as defenders, and then either 4, 3 or 2 of these players will be left available for forward. I tried calculating each case separately, and summing the combinations for each case together. However, if I calculate it such that we first choose the forwards, and we can choose 3, 2, 1 or 0 of the hybrid players to be forwards, I get a different result. I assume there is a smarter way to do this, but I can't seem to figure it out.","['combinations', 'combinatorics', 'discrete-mathematics']"
4067969,Show that probability of a biased coin returning heads more than half the time is less than a certain number,"Let X be the number of successes of a biased coin returning head $\frac{1}{4}$ of the time within $k$ tosses. Show that $P(X\geq\frac{k}{2})\leq\frac{1}{2^{k/5}}$ . So I know that $X$ is $B(k,\frac{1}{4})$ . And I was thinking about re-expressing $P(X\geq\frac{k}{2})$ as $\sum_{r=\lceil k/2\rceil}^k \binom{k}{r}(\frac{1}{4})^r(\frac{3}{4})^{k-r} =\sum_{r=\lceil k/2\rceil}^k \binom{k}{r}(\frac{3^{k-r}}{4^k})$ but I don't really know what to do afterwards. I was told I can use $\binom{2r}{r}\leq\frac{4^r}{2}$ but the only way I can think of is to let $\binom{k}{r}\leq\binom{k}{\frac{k}{2}}\leq2^{k-1}$ for all $r$ and after that I get a very high upper bound much larger than required. Would appreciate any help towards solving the question. Thank you. Edit: Made a typo should have been $P(X\geq\frac{k}{2})$ instead of $P(X>\frac{k}{2}).$ Edit 2: Fixed more typos","['binomial-distribution', 'probability-theory', 'probability', 'random-variables']"
4068031,A limit of a given sequence,"Let $(a_n)_{n\ge1}$ a sequence of real positive numbers such that $a_n+\frac{n}{a_{n+1}^2} \le a_{n+1} \le \frac{a_{n-1}^2}{a_n}+\frac{n+1}{a_n^2}$ for any $n \ge 1$ . Prove that $b_n = \frac{a_n}{\sqrt[3]{n^2}}$ is a convergent sequence and find its limit. First of all, it's clear that $a_n$ is a increasing sequence from the first inequality given. So $a_n$ has a limit and it is either a finite number or infinity. If we suppose that $a_n$ is convergent and has a finite limit (let it be $l$ ), by using limit in the first inequality we obtain: $l+\infty \le l$ , which is false and it means that $\lim_{n \to \infty} a_n = \infty$ , so we may apply Cesaro-Stolz for finding the limit of $b_n$ , but here I didn't know how to continue. Can you help me?","['limits', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
4068079,"Limit of $f:\mathbb{R}\to\mathbb{R}$ such that $f(x) = \frac1{q_n^5}$, if $x=\frac{p_n}{q_n}$ for $x \to \sqrt{2}$","Let $p_n$ and $q_n$ two successions of integer numbers such that $q_n > 0$ and such that $(p_n, q_n) = 1$ for all indexes $n$ . Define $f(x) := \begin{cases}\frac1{q_n^5} \quad x=\frac{p_n}{q_n} \\[6pt]
0 \quad x \in \mathbb{R}-\mathbb{Q}\end{cases}$ Prove that $\lim_{x \to \sqrt{2}} \frac{f(x)}{(x-\sqrt2)^2}$ exists. Can you compute it? If we know the limit exists, then we might be able to apply Heine's criteria for limits of functions using limits of sequences to find the limit by using a rational sequence $(x_n) \to \sqrt2$ and using the definition of the function. However, I don't know how to approach proving the existence of the limit. Also, we know that if a sequence $(\frac{p_n}{q_n})$ , where $(p_n, q_n) = 1, p_n,q_n \in \mathbb{Z}, q_n > 0$ converges to an irrational number, then $\lim_{n \to \infty} q_n = \infty$ . Can you help me with this?","['limits', 'sequences-and-series', 'real-analysis']"
4068098,Non-linear bijections preserving the relation $fg = f^2$,"Let $X$ and $Y$ be compact spaces and let $C(X)$ and $C(Y)$ be the corresponding spaces of continuous, real-valued functions. Suppose $T\colon C(X)\to C(Y)$ is a non-linear bijection such that $$fg = f^2 \iff (Tf)(Tg) = (Tf)^2\qquad (f,g\in C(X))$$ Once can deduce (see Lemma 3.1 here ) that (#) if $fg = 0$ , then $(Tf)(Tg) = 0$ and in this case $T(f+g) = Tf + Tg$ . Addendum : One can prove that the condition concerning preservation of the relation $fg = f^2$ in both ways is equivalent to $T$ and $T^{-1}$ satisfying (#), which may make the picture cleaner. Suppose that $(f-h)(g-h) = 0$ constantly. Do we have $(Tf-Th)(Tg-Th) = 0$ ? The motivation comes from the fact that I'd like to simplify/amend considerations in the linked preprint. Maps $T$ with this property need not be continuous, but I am happy to assume continuity, or something else, if that helps.","['continuity', 'general-topology', 'functional-equations', 'real-analysis']"
4068146,How to show $\prod_{n=1}^{\infty}\frac{1-x^{2 n}}{1-x^{n}} = \prod_{n=1}^{\infty}\frac{1}{1-x^{2 n-1}}$?,"I've tried many different ways of rearranging the expression $\frac{1-x^{2 n}}{1-x^{n}}=\frac{1}{1-x^{2 n-1}}$ , but I can not seem to prove that the left hand side equals the right hand side. Am I missing something? This is part of a larger formula in this paper on proving the Euler partition identity with generating functions. https://people.clas.ufl.edu/alladik/files/alladipaperpaule60-1.pdf","['power-series', 'algebra-precalculus', 'sequences-and-series']"
4068148,"If $\phi$ is in $\mathcal S$ and $\phi(0)=0$, is $\int_0^1 \nabla \phi(tx)dt$ in $\mathcal S$ too?","Let $\phi\in\mathcal S(\mathbb R^n)$ be a Schwartz function vanishing at $0$ . Then the FTC implies $$ \phi(x) = x\cdot \int_0^1 \nabla \phi (tx)\ dt.$$ Let this integral term be $\psi(x) := \int_0^1 \nabla \phi(tx)dt$ . Is it true that $\psi$ is (component-wise) a Schwartz function? It is at least $C^\infty$ . I tried for a while to come up with counterexamples and failed. I have proved it in dimension $1$ , but I need a replacement for division in higher dimensions? The result is false for arbitrary functions $p$ that solve $\phi(x)= x\cdot p(x)$ , even if $\phi$ is Schwartz ( $0 = \binom x y \cdot \binom {-y}x$ ). Also, $\psi$ is not Schwartz if the condition $\phi(0)=0$ is dropped, as then (in 1D) $\psi(x)= \frac{\phi(x)-\phi(0)}x\sim\frac{\phi(0)}x$ for large $x$ which is not enough decay. So a positive proof would need to use something about Schwartz functions and something about vanishing at zero (the two assumptions). I can provide a detailed attempt if wanted; in fact I have deleted many ""answers"" after noticing errors. In particular I have tried merely using the Schwartz seminorms to bound the integral, but it seems that either many factors of $t^{-1}$ appear which make the integral diverge, or (trying to treat $t\ll 1$ separately) I am unable to achieve large decay. Of course, as previously mentioned, the issue at $t=0$ should be somehow resolved with the vanishing at $x=0$ . This comes out of trying to understand what the correct fix for a typo in M Zworski's Semiclassical Analysis p.32 ( Screenshot , Google books link ), in a proof that the Fourier Transform is an automorphism of $\mathcal S$ . The online errata ( screenshot copy) says to set $\phi(0)=0$ , but I'm unsure if the preceeding paragraph is correct with this correction (and in any case, it is stated that $\psi$ may not be in $\mathcal S$ without proof.) Thoughts appreciated! Zworski, Maciej , Semiclassical analysis, Graduate Studies in Mathematics 138. Providence, RI: American Mathematical Society (AMS) (ISBN 978-0-8218-8320-4/hbk). xii, 431 p. (2012). ZBL1252.58001 .","['fourier-analysis', 'analysis', 'distribution-theory', 'real-analysis', 'schwartz-space']"
4068252,"A ""viscosity"" solution of ODE arising from switching systems","$\newcommand{\d}[1]{\underline{\mathrm{#1}}}$ $\color{red}{\d{Setting}}$ Let $f : \mathbb R \to \{0,1\}$ be a function and let $x_0 \in (0,1)$ . I have two fixed distinct real numbers $A_0,A_1$ and define $g(x) = A_{f(x)}x$ . Basically, $f$ assigns to each $x$ a number $A_0$ or $A_1$ , and then we get $g(x)$ by multiplying by $A$ . Consider the initial value problem $$
\dot{W}(x) = g(W(x)) \quad W(0) = x_0
$$ for what $f$ can I assert existence and uniqueness of $W$ as a ""solution"" for any initial point $x_0$ ? I'd like existence and uniqueness only till $f$ exists $[0,1]$ for the first time. $\color{blue}{\d{Motivation}}$ This arises in the notion of switching linear systems. Imagine a system where a particle is at a point initially, say the particle is a feather. At every point in the space, there is a fan, which blows in a certain direction, and dictates a local behaviour of the motion of the feather like a linear ODE. Now we find when the feather has a unique valid movement in this configuration. Apart from feathers in fans, my particular application is in epidemic theory, where the trajectory of a epidemic can be controlled with an on-off switch, with different linear dynamics in the on and off case. $\color{fuchsia}{\d{Example}}$ Of course, if $f$ is constant then the solution exists as a strong solution, and is unique given the initial condition. Let's take a first non-trivial example. Fix a $y \in (0,1)$ and let $f(x) = -1$ if $x < y$ and $f(x) = 1$ otherwise. Now, let $x_0$ be any point. Note that the Lipschitz continuity condition fails for $f$ at $y$ , in fact even continuity fails. So I'm not expecting a strong solution anyway : a solution to this won't even be differentiable, looking at the behaviour at $y$ . However, I'd like to think that a solution of some kind exists as follows : say for example that $x_0 < y$ . Then , by using the existence/uniqueness theorem for $(0,y)$ I can get the solution on this interval, which will be $W(z) = e^{-z} + (x_0-1)$ . This solution, by continuity of the weak solution, will fix a unique value at $y$ i.e. $W(y) = e^{-y} + (x_0-1)$ . Then, using the uniqueness/existence condition in $[y,1]$ we get an extension of the solution to $[0,1]$ , uniquely (I can write down the explicit answer but that's not important). We call this solution as $W$ . I read up the notion of a viscosity solution which matches heavily with my construction (For the definition, see here or see Fleming and Soner, chapter 2). I can't go for a weak solution, since that just neglects the role of $y$ in the above construction, and you can just work piecewise. I'd like the pieces to be ""joined together"" continuously, and a viscosity solution is ensured continuous by construction. $\color{green}{\d{Questions}}$ According to Wikipedia , a viscosity solution seems to be defined only for certain forms of PDE that arise from the HJB. I believe that this falls in that category of ""degenerate elliptic"" PDE because it is a first order PDE so the condition is vacuous, but I need confirmation on this one because the switching and discontinuity of $g$ is getting to me. Is the function I wrote above the unique viscosity solution of the ODE described? I'd like an easy way to see that it is, but the definitions are getting to me. Let me try : so the situation is $V(0) = x_0$ and $$F(x, V(x), \dot{V}(x)) = \begin{cases}
\dot{V}(x) - V(x) & x \geq y \\
\dot{V}(x) + V(x) & x < y
\end{cases} $$ To check that the $W$ constructed is a sub and super solution we only need to see the point $y$ since at the other points differentiability is present. If $\phi$ is differentiable at $y$ and $\phi \geq W$ in a neighbourhood of $y$ then $\phi(t) - \phi(y) \geq W(t) - W(y)$ for all $t$ in a neighbourhood of $y$ . Now we can divide by $y$ and let $t \to u$ from left and right and get that $|y| \geq \phi'(y)$ , so $W$ is a subsolution. We should get $W$ being a super solution symmetrically : if $\phi \leq W$ in a neighbourhood of $y$ then the inequalities reverse which basically leads to the reverse conclusion $|y| \leq \phi'(y)$ and we are done. (Kindly point out casual errors, I don't expect any) If $f$ has only finitely many points of discontinuity then I expect a unique viscosity solution to exist. How can I be expected to work if $f$ had infinitely many points of discontinuity? Or at a limit point of the discontinuities? Could the solution be definable in the viscous sense here and be unique? Essentially, I'm trying to find the largest class of $f$ for which I can find a viscosity solution. I need the class to be large enough because I want a minimizer of a certain functional of that class, which I can't really study unless I know something about this class.","['ordinary-differential-equations', 'optimal-control', 'control-theory', 'viscosity-solutions', 'partial-differential-equations']"
4068295,Value of $a+a^a+a^{a^a}+a^{a^{a^a}}+... $,"Is there any closed form expression of $a+a^a+a^{a^a}+a^{a^{a^a}}+...$ up to $n$ terms? I am mostly interested in $a=2$ My try: $a+a^a+a^{a^a}+a^{a^{a^a}}+... =a(1+a^{a-1}+a^{{a^a}-1}+a^{{a^{a^a}}-1}+... )$ , but I do not know how to continue.","['closed-form', 'recurrence-relations', 'sequences-and-series']"
4068333,Exercise on $\boldsymbol{\Delta}_2^0$ sets in the Baire space $\omega^\omega$,"I want to prove the following statement: Given a set $A\subseteq \omega^\omega$ , if there exists a continuous function $g: 2^\omega \rightarrow \omega^\omega$ s.t. $f(\{z \in 2^\omega \mid \exists n \forall m\ge n \ (z_m = 0)\}) \subseteq A$ and $f(\{z \in 2^\omega \mid \exists n \forall m\ge n \ (z_m = 1)\}) \cap A = \emptyset$ then $A$ is not $\boldsymbol{\Delta}_2^0$ I tried to prove that there exists a continuous reduction of $\{z \in 2^\omega \mid \exists n \forall m\ge n \ (z_m = 0)\}$ , which is $\boldsymbol{\Sigma}_2^0$ -complete, onto $A$ , but without much success. Any hint? Thanks","['borel-sets', 'general-topology', 'descriptive-set-theory']"
4068334,How many subsets of S contains A?,"Given a set $S$ of size $n$ and $A \subseteq S$ of size $k$ , how many subsets of $S$ contain $A$ ? I think it should be $2^{n} - 2^{n-k}$ ? Please tell is it correct or not ?",['elementary-set-theory']
4068354,Let $(a_d)_{d\in D}$ be a real net such that $\lim_{d\in D}a_d=∞$. Is there a cofinal set $D'\subset D$ such that $(a_d)_{d\in D'}$ is increasing?,"Let $(D, \geq)$ be a directed set, and let $(a_d)_{d\in D}$ be a real-valued net satisfying $$
\lim_{d\in D}a_d =+\infty.
$$ Can we find a cofinal subset $D'\subset D$ such that the restricted net $(a_d)_{d\in D'}$ is increasing, i.e., $a_{t}\geq a_d$ whenever $t,d\in D'$ and $t\geq d$ ? The result is easily proved under the additional assumption that there exists a cofinal sequence $(t_n)_{n\in \mathbb N}$ in $D$ , but I would like to avoid this assumption.","['limits', 'general-topology', 'nets']"
4068355,"Disc vs Shell Method, getting different answers AP calc","Can someone please check my work. $R$ is the region in the first quadrant bounded by $y=1/x$ , $y=1$ and $x=e$ Find the volume of the solid generated when $R$ is revolved about the line $y=1$ Disk: $$V= \int_{1}^{e} \pi \left(1-\frac{1}{x}\right)^2 \,dx=\pi \left(e-\frac{1}{e}-2\right)$$ Shell: \begin{align*}
V&=-2\pi \int_{1/e}^{1} -\left(1-\frac{1}{y}\right)\left(e-\frac{1}{y}\right)\, dy\\[5pt]
&=-2\pi\left[ey-(1+e)\ln(y)-\frac{1}{y}\right]\Bigg|_{1/e}^{1}\\[5pt]
&=-2\pi\bigl[(e-(1+e)\cdot 0-1)-(1-(1+e)(-1)-e)\bigr]\\[5pt]
&=-2\pi\bigl[(e-1)-2\bigr]\\[5pt]
&=-2\pi(e-3)
\end{align*}","['integration', 'calculus', 'solid-of-revolution']"
4068400,Contact form in Polar Coordinates,"While going through Etnyres Lectures on Contact Topology (which can be found here ) Example 2.8 two questions came up He uses cylindrcal coordinates $(r,\theta, z)$ to define a 1-form $\alpha_2 = dz +r^2d\theta$ on $\mathbb{R}^3$ and it is not clear to me how this is well defined. I would interpret this as follows: $\theta$ should be a function $\mathbb{R}^3\to\mathbb{R}$ sending a point $p$ to the angle of the projection onto the xy-plane of p with respect to the ray along the x-axis going out to + $\infty$ , $d\theta$ would then be the exterior derivative. However, $\theta$ does not  define a smooth map on all of $\mathbb{R}^3$ because of problems at the origin. My question is then, how should one interpret this definition of $\alpha_2$ . He claims that $\alpha_2$ defines a contact form, that is $\alpha_2\wedge d\alpha_2\neq 0$ ,
but his computation shows that $$\alpha_2\wedge d\alpha_2 = 2rdr\wedge d\theta\wedge dz$$ which gives the trivial form at the origin since $r(0,0,0) = 0$ . I thought the contact condition implies that the form is non-trivial at every point $p\in\mathbb{R}^3$ , or is it enough that the form is non-trivial at a single point?","['contact-geometry', 'differential-forms', 'differential-geometry']"
4068413,Automorphisms of affine space $\mathbb{A}^n$: degree of the polynomials defining the inverse morphism,"In the context of algebraic geometry over an algebraically closed field: Let $f:\mathbb{A}^n\to\mathbb{A}^n$ be a bijective regular map such that $g=f^{-1}$ is regular.
Write $f=(f_1,\dotsc,f_n)$ and $g=(g_1,\dotsc,g_n)$ , where $f_1,\dotsc,f_n,g_1,\dotsc,g_n$ are polynomials in $n$ variables. Let $d_f$ be the maximum among the degrees of $f_1,\dotsc,f_n$ .
Let $d_g$ be the maximum among the degrees of $g_1,\dotsc,g_n$ . Can we bound $d_g$ in terms of $d_f$ and $n$ ?","['algebraic-geometry', 'commutative-algebra']"
4068443,Why do we use divisors in algebraic geometry?,"In algebraic geometry there is a correspondence between Weil divisors, Cartier divisors and line bundles. Over an integral separated locally factorial noetherian scheme, the group of isomorphism classes of Weil divisors and the group of isomorphism classes of Cartier divisors are isomorphic. Moreover, in a general scheme, there is a bijection between Cartier divisors and invertible subsheaves of the sheaf of total quotient rings. In my (admittedly little) experience, it seems that in ""nice"" situations (when dealing with smooth varieties, for example) we prefer to use Weil divisors as it is more geometric and that we resort to Cartier divisors otherwise. I wonder why don't we always use line bundles (= invertible sheaves). Let me explain! Contrarily to Cartier divisors, line bundles are indeed very geometric objects. Perhaps as geometric as Weil divisors. As with Cartier divisors, we don't have to deal with the trouble of using orders to define principal divisors. The pullback works at the level of line bundles, where for Cartier divisors we have to use the ""moving lemma"" to define the pullback on the Picard group. What do we lose, or becomes harder, when using line bundles?",['algebraic-geometry']
4068459,$\operatorname{Spec} A$ as a colimit,"I was reading the lecture notes on algebraic geometry and came across with the following definition: Let $A$ be a commutative ring with unit, then $\operatorname{Spec} A$ is defined as the collection of all ring homomorphism $A\rightarrow K$ , where $K$ is some field, and where we identify two maps $f:A\rightarrow K$ and $f':A\rightarrow K'$ if there exists a field homomorphism $\alpha:K\rightarrow K'$ such that $f'=\alpha \circ f$ . And then the author went on: this is a rather categorical definition, and in fact we could rephrase it as $$\operatorname{Spec} A=\operatorname*{colim}_{K\in \mathfrak{Field}} \operatorname{Hom}_{\mathfrak{Ring}}(A,K).$$ where $\mathfrak{Field}$ is the category of fields and $\mathfrak{Ring}$ is the category of rings. I am trying to prove this but not sure if I am on the right track: Let $\mathfrak{C}$ be the subcategory of the coslice category of $\mathfrak{Ring}$ over $A$ where the objects are $f:A\rightarrow K$ and the morphisms are $\alpha: f\rightarrow f'$ such that $f'=\alpha \circ f$ . But then I don't see how to proceed from there. Is there any literature about this definition of spectrum of a ring rather than the usual definition as the set of all prime ideals of $A$ ? Thank you.","['algebraic-geometry', 'abstract-algebra', 'category-theory']"
4068498,Evaluate : $\int\limits_0^{\pi/2} \cot x \ln(\sec x) dx$,"I want to solve this integral : $$\int_0^{\pi/2} \cot x \ln(\sec x) dx$$ I tried the following substitution : $\ln(\sec x)=t$ which means $dt=\tan x dx$ $$I=\int_0^\infty \frac{\cot x}{\tan x}tdt=\int_0^\infty \frac{t}{\tan^2 x}dt$$ I'm really disturbed by the $\tan^2 x$ , I tried also to substitute $\sec x =t$ but it's not helpful either. Any helpful approach to solve this problem ?","['integration', 'trigonometry', 'trigonometric-integrals']"
4068558,Integration using digamma functions,"I'm trying to prove that for $x,y,r>0$ the following identity (gotten via CAS) holds: $$\int_0^x \frac{x^r}{x^r+y^r}\,dy=\frac{x}{2r}\left(\psi\left(\frac{1+r}{2r}\right)-\psi\left(\frac{1}{2r}\right)\right),$$ where $\psi(\cdot)=\frac{\Gamma'(\cdot)}{\Gamma(\cdot)}$ denotes the Digamma function. Does anyone has a clue, how integration can be done this way? As an additional information following identity, holds also to be true: $$\int_0^x \frac{y^r}{y^r+x^r}\,dy=\frac{x}{2r}\left(\psi\left(\frac{1}{2r}+1\right)-\psi\left(\frac{1}{2r}+\frac{1}{2}\right)\right),$$ Which was obtained using: $$\psi(x)=H_{x-1} - \gamma,$$ where $\gamma$ denotes the Euler-Mascheroni constant and $H_x$ denotes the $x^{th}$ harmonic number.","['integration', 'definite-integrals', 'digamma-function', 'gamma-function']"
4068561,Original reference by Esseen for Berry-Esseen theorem,"Does someone have an idea of where I can find an officially published text of the following seminal article by Esseen? ""Esseen, Carl-Gustav (1942). ""On the Liapunoff limit of error in the theory of probability"". Arkiv för Matematik, Astronomi och Fysik. A28: 1–19. ISSN 0365-4133"" I cannot find it. I can only find this short review by Feller. https://mathscinet.ams.org/mathscinet-getitem?mr=11909 It would be astounding to me if there were no way to access such an important paper.","['statistics', 'central-limit-theorem', 'large-deviation-theory']"
4068631,Understanding a local definition of the gradient,"In this topic , the tangential gradient on a submanifold $M \subset \mathbb{R}^d$ , embedded by a map $F: M\rightarrow \mathbb{R}^d$ , is defined as $$\nabla^M f = \nabla^i f \frac{\partial F}{\partial x_i} = g^{ij} \frac{\partial f}{\partial x_j} \frac{\partial F}{\partial x_i},$$ where $g_{ij}=\langle\frac{\partial F}{\partial x_i}, \frac{\partial F}{\partial x_j}\rangle$ . I'm stack in understanding the embedding $F$ and how to calculate $\frac{\partial F}{\partial x_i}$ even in the basic example of a sphere ( $d=3$ ). Any hint would really be helpful.","['surfaces', 'riemannian-geometry', 'differential-geometry']"
4068639,Regarding convex functions that attain infimum at infinity,"Let function $f: \mathbb{R}^n \to \mathbb{R}$ be continuously differentiable, lower-bounded and convex. Let $\nabla f$ be the gradient of $f$ , i.e., $\nabla f = \begin{bmatrix} \frac{\partial f}{\partial x_1} \dots \frac{\partial f}{\partial x_n} \end{bmatrix}$ . If $x^1,x^2,\dots$ is a sequence in $\mathbb{R}^n$ such that $$\lim_{n\to \infty} f(x^i) = \inf_{x \in \mathbb{R}^n} f(x)$$ then is the following true? $$\lim_{n\to \infty} \left\| \nabla f(x^i) \right\| = 0$$ where $\|\cdot\|$ is the usual Euclidean norm. If this is not true, what additional assumptions on $f$ can be added so that this is true? Thank you.","['convex-optimization', 'limits', 'multivariable-calculus', 'scalar-fields']"
4068665,Prove that $\underline{f}(C-D)=\underline{f}(C)-\underline{f}(D)$.,"Definition Let $f : A → B$ be a function; if $D$ is any subclass of $B$ , the inverse image of $D$ under $f$ , which we write $\underline{f}(D)$ , is the following subclass of $A$ : $$\underline{f}(D)=\{x\in A\mid f(x)\in D\}.$$ Suppose that $f : A → B$ is a function, $C ⊆ B$ and $D ⊆ B$ . Prove that $$\underline{f}(C-D)=\underline{f}(C)-\underline{f}(D)$$ what i tried is, $$\begin{align*}x\in \underline{f}(C-D)&\Leftrightarrow f(x)\in C-D\\ &\Leftrightarrow f(x)\in C\ \wedge\ f(x)\notin D\\ &\Leftrightarrow x\in \underline{f}(C)\ \wedge\ x\notin \underline{f}(D)\\ &\Leftrightarrow x\in \underline{f}(C)-\underline{f}(D).\end{align*}$$ Is right?",['elementary-set-theory']
4068667,Square root of a $3×3$ matrix,"I was trying to find square root of this $3×3$ matrix $$\begin{pmatrix}
12&8&31\\
7&14&28\\
9&35&6\\
\end{pmatrix}$$ I searched Wikipedia and some site for helpful information and also try to $${ \begin{pmatrix}
a&b&c\\
d&e&f\\
g&h&i\\
\end{pmatrix} }^3 = 
\begin{pmatrix}
12&8&31\\
7&14&28\\
9&35&6\\
\end{pmatrix}$$ Though I know that a similar question has been posted for a $2×2$ matrix, the workings are different so I'll need some help on this
Thanks","['matrices', 'linear-algebra']"
4068683,How to show that there is no positive rational number a such that $a^3$ = 2?,"I'm stuck on this one.
So far, I've tried this: \begin{align}
a^3 &= 2 \\
a &= \left(\frac mn\right) \\ 
a^3 &= \left(\frac mn\right)^3 = 2 \\
m^3 &= 2n^3 \\
m &= 2p \\
m^3 &= (2p)^3
\end{align} I'm really confused about what to do after this—the book answer says that $m^3$ becomes $m^3 = 2(4p)^3$ . And $2n^3 = 2(4p)^3$ . I'm super confused here and can't really understand what's going on here. Can someone tell what exactly is going on here and how should I prove this?",['algebra-precalculus']
4068689,Textbook with a comparative approach to discrete and continuous topology and their ramifications in analysis,"Topology is often described as the way to define the continuity of maps. But one can also define topologies over finite/discrete/countable spaces. Additionally, one can often draw analogies between ""discrete"" analysis (sequences, series, the derivative as $u_{n+1} - u_n$ , recurrence equations) and ""continuous"" analysis (functions, integrals, derivatives as $\lim_{h\to 0} \frac{f(x+h) - f(x)}{h}$ , differential equations). Finally, considering something like $\mathbb{Z}[i]$ , the Gaussian integers, there's definitely some graph theoretic concepts that could be of use to help define the notion of a ""discrete neighborhood"". So my questions are: does there exist a textbook which gives a thorough treatment of both ""discrete analysis"" and ""continuous analysis"" side-by-side, with examples; with topological grounding, preferably up to differential geometry ? Is there any textbook that's anywhere remotely in that vein ? Alternatively, is there a textbook that presents topology as a ""continuous graph theory"", where ""normal"" graph theory is understood to also include graphs with an infinite (countable) number of vertices, as well as graphs with $n$ -ary edges (hypergraphs) ? Is there a textbook that presents what ""continuity of a map"" would mean over discrete topological spaces, in depth, and its distinction (and relations) with ""normal"" topology ?","['analysis', 'reference-request', 'discrete-mathematics', 'general-topology', 'differential-geometry']"
4068690,Yamabe Positive iff Admits Metric of Positive Scalar Curvature,"I'm trying to prove that the Yamabe invariant of a compact manifold, that is the sigma constant, is positive iff $M$ admits a metric of positive scalar curvature. I will use $$Y_{[g]} = \underset{g \in [g]}{\inf} \mathcal{E}(g)$$ to be the Yamabe constant with $$\mathcal{E}(g) = {\frac{{\int_{M}S_g \Omega}}{\left({\int_{M} \Omega}\right)^{{\frac{n-2}{n}}}}}$$ One direction is straightforward. That is, assume $\sigma(M) > 0$ , then there exists some conformal class [g] such that $Y_{[g]} > 0$ . Then by the Yamabe problem there exists a metric $\tilde{g} \in [g]$ such that $(M,\tilde{g})$ has constant positive scalar curvature. I'm struggling with the other direction. Suppose $M$ admits a metric of positive scalar curvature $g_0$ , say. We want to show that $$\sigma(M) = \underset{[g]\in \mathcal{C}_M }{\sup} Y_{[g]} > 0$$ with $\mathcal{C}_{M}$ being the set of conformal classes on $M$ . So we just need to show there exists a conformal class giving a positive Yamabe constant. Given the information we have I would imagine that this supremum is achieved by $Y_{[g_0]}$ . But I'm having trouble showing that this is positive. What's stopping there being some other metric, say $\tilde{g_0} \in [g_0]$ such that $\mathcal{E}(\tilde{g_0}) \leq 0$ thus giving a non-positive value for $Y_{[g_0]}$ ?","['curvature', 'riemannian-geometry', 'differential-geometry']"
4068784,"The inequality $\,2+\sqrt{\frac p2}\leq\sum\limits_\text{cyc}\sqrt{\frac{a^2+pbc}{b^2+c^2}}\,$ where $0\leq p\leq 2$ is: Probably true! Provably true?","Let $p$ be a positive parameter in the range from $0$ to $2$ . Can one prove that $$2 +\sqrt{\frac p2} \;\leqslant\;\sqrt{\frac{a^2 + pbc}{b^2+c^2}}
 \,+\,\sqrt{\frac{b^2 +pca}{c^2+a^2}}\,+\,\sqrt{\frac{c^2 +pab}{a^2+b^2}}\quad?\tag{1}$$ Where $\,a,b,c\in\mathbb R^{\geqslant 0}\,$ and at most one variable equals zero. The inequality $(1)$ is homogeneous of degree zero with regard to $a,b,c$ . Equality occurs if two variables coincide and the third one is zero. To provide some plausibility to $(1)$ the two boundary cases $\,p=2\,$ and $\,p=0\,$ are
proved: $p=2$ is the harder bit. W.l.o.g. assume $\,a\geqslant b\geqslant c\,$ and $\,a,b>0$ . Let $u=\sqrt{\frac ab}\,+\,\sqrt{\frac ba}$ , then $2\leqslant u$ , and $u=2$ iff $a=b$ . I) $\:$ Let's show that $$u\:\leqslant\:\sqrt{\frac{a^2 + bc}{b^2+c^2}} \,+\,\sqrt{\frac{b^2 +ac}{a^2+c^2}}\:.\tag{2}$$ The following expression is positive: $$\begin{align}
 & \frac{a^2+bc}{b^2+c^2} -\frac ab & +\quad &\frac{b^2+ac}{a^2+c^2} -\frac ba\\[2ex]
=\;\; & \frac{ab(a-b)+b^2c-ac^2}{b(b^2+c^2)} & +\quad &\frac{-ab(a-b)+a^2c-bc^2}{a(a^2+c^2)}\tag{3}\\[2ex]
\geqslant\;\;  & \frac{ac(a-c)+bc(b-c)}{a(a^2+c^2)} \;\geqslant 0
\end{align}$$ The first summand in $(3)$ has been diminished by increasing the denominator, while
its numerator $\,ab(a-b) +b^2c -ac^2 =(a-b)(b-c)(a-c) + c(a-c)^2 + c^2(b-c)\,$ cannot get negative. $(2)$ now follows from $$\begin{split}
u^2\:=\:\frac ab + 2 +\frac ba \: & \leqslant\:\frac{a^2+bc}{b^2+c^2}
+ 2\,\underbrace{\sqrt{\frac{a^2+bc}{a^2+c^2}}}_{\geqslant 1}\;\underbrace{\sqrt{\frac{b^2+ac}{b^2+c^2}}}_{\geqslant 1}+ \frac{b^2+ac}{a^2+c^2}\\[2ex]
& =\:\left(\sqrt{\frac{a^2 + bc}{b^2+c^2}} +\sqrt{\frac{b^2 +ac}{a^2+c^2}}\:\right)^2
\end{split}$$ II) $\:$ The remaining square root summand in $(1)$ is also bounded below in terms of $u$ since one has $$\frac 1{u^2-2} \:=\:\frac{ab}{a^2+b^2}\quad\implies\quad
\sqrt{\frac 2{u^2-2}} \:\leqslant\: \sqrt{\frac{c^2 +2ab}{a^2+b^2}}$$ III) $\:$ Applying $3$ -AGM finally proves $(1)$ : $$\begin{split}\sum_\text{cyc}{\sqrt\frac{a^2 + 2bc}{b^2+c^2}} \;\geqslant\;
u+\sqrt{\frac 2{u^2-2}} &\:=\:\sqrt{\frac{u^2}4} +\sqrt{\frac{u^2}4} +\sqrt{\frac 2{u^2-2}}\\[2ex]
&\:\geqslant\:3\sqrt{\left(\frac{u^4}{8(u^2-2)}\right)^{1/3}} \:\geqslant\:3\end{split}$$ $p=0$ is more relaxing. Only $2$ -AGM in the form $\,a\sqrt{b^2+c^2}\leqslant\frac12\left(a^2+b^2+c^2\right)$ is needed: $$\frac a{\sqrt{b^2+c^2}} + \frac b{\sqrt{c^2+a^2}}+ \frac c{\sqrt{a^2+b^2}}
\;=\;\sum_\text{cyc}\frac{a^2}{a\sqrt{b^2+c^2}}
\;\geqslant\;\sum_\text{cyc}\frac{2a^2}{a^2+b^2+c^2} \;=\;2$$ $0<p<2$ returns to the question. With just some ideas how to catch the ""remaining"" $p$ -values: The above method for $p=2$ may possibly be stretched down until the $p=1$ instance: $$2 +\frac{\sqrt 2}{2} \;\leqslant\;\sum_\text{cyc}{\sqrt\frac{a^2+bc}{b^2+c^2}}$$ This has been detailed by mathlove in his answer. Interpolation with regard to $p$ (more a buzz word than substantial ...) A concavity argument as the two end points $p=0$ and $p=2$ are known: Could proving the second derivative with respect to $p$ being negative path a way towards a proof?","['uvw', 'summation', 'inequality', 'a.m.-g.m.-inequality', 'algebra-precalculus']"
4068854,"Given a set $A$, define relation $R$ on $\mathcal{P}(A)$ by $\{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon \dots \}$. Is $R$ transitive?","Given a set $A$ , define relation $R$ on $\mathcal{P}(A)$ by $$R = \{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon (U \cap V \neq \emptyset) \lor (U \cup V = \emptyset)\}.$$ I want to check if $R$ is a transitive relation. My scratch work so far: Let $A = \{a, b, c, d, e\}$ then $\mathcal{P}(A)=\{\{\emptyset\}, \{a\},\{b\},\{c\},\{d\},\{e\},\dots,\{a,b,c,d,e\}\}$ . So I know I want to prove that $URV \land VRW \Longrightarrow VRW$ for transitivity. If I let $(U,V)=(\{a\},\{a,b\})$ then $(U \cap V) = \{a\} \neq \emptyset$ , so that $URV$ , $(V,W)=(\{a,b\},\{b\})$ then $(V \cap W) = \{b\} \neq \emptyset$ , so that $VRW$ Then $(U \cap V)\cap(V \cap W) = \emptyset$ right? Which means $URV∧VRW⟹V\not RW$ .  Am I missing a key concept? Is this enough to prove it's not transitive? I know there exists subsets I can pull to show transitivity but if I show one isn't transitive, it should show the overall relation isn't transitive right? Any feedback on this is appreciated. Thanks.","['elementary-set-theory', 'relations']"
4068958,Evaluate $\int_{0}^{\pi/2}\cos^{2n}(x)\text{d}x$.,"I try this. Notice that, $$
\begin{split}
\cos^{2n}x &= \left(\frac{e^{ix}+e^{-ix}}{2}\right)^{2n} = \frac{1}{2^{2n}} \sum_{k=0}^{2n} \binom{2n}{k}e^{ikx}e^{-i(2n-k)x} \\ &= \frac{1}{2^{2n}} \sum_{k=0}^{2n} \binom{2n}{k}e^{i(2k-2n)x} \end{split}
$$ The terms with $k\ne n$ integrate to zero over $[0,\pi/2]$ , and we are left with $$
\int_0^{\pi/2}\cos^{2n}x \,dx = \int_0^{\pi/2}\frac{1}{2^{2n}}\binom{2n}{n} \,dx = \frac{\pi}{2^{2n+1}}\binom{2n}{n}
$$ I'm right or not?",['integration']
4068977,Halmos's proof of Schröder-Bernstein theorem,"In the first paragraph of Halmos's proof of the Schröder-Bernstein theorem, he states: It is convenient to assume that the sets $X$ and $Y$ have no elements in common; if that's not true, we can so easily make it true that the added assumption involves no loss of generality. I do not understand this point. How can we make it true? As another question on this same theorem, a number of proofs I have seen talk about  successively applying $f$ and $g$ , injections $A \to B$ and $B \to A$ , respectively, to get functions of the form $(f \circ g)^n$ . However, the Schröder-Bernstein theorem can apply to any sets, countable or not, so how is this not sacrificing generality and assuming that the infinities in question are countable? For example, this proof https://artofproblemsolving.com/wiki/index.php/Schroeder-Bernstein_Theorem from the Art of Problem Solving website defines an element $b_1 \in B$ as a descendant of $b_0 \in B$ if $b_1 = (f \circ g)^n (b_0)$ , but I may. have needed to apply $f$ and $g$ uncountably infinitely many times (can I even do that?) if there were uncountable many ""lonely"" points ( $b \in B$ so that there is no $a \in A$ with $f(a) = b$ .)","['elementary-set-theory', 'proof-explanation']"
4068992,Cyclic property of the root of a cubic polynomial,"Let $f(x) = x^3 - 3x + 1$ . Let $\alpha, \beta, \gamma \in \mathbb{R}$ be the roots of $f$ with $\alpha > \beta > \gamma$ . Let $g(x) = x^2 - 2$ . We see that $\beta = g(\alpha)$ , $\gamma = g(\beta)$ and $\alpha = g(\gamma)$ by calculation using $f$ . Why does this cyclic property hold? What is the relation between $f$ and $g$ ? Could you tell me its background or generalization?","['cubics', 'group-theory', 'polynomials']"
4069038,An ellipse inside a heptagon,"Can you provide a proof for the following claim: Claim. Construct a convex heptagon circumscribed about an ellipse. Intersection points of its non-adjacent longer diagonals lie on a common ellipse. GeoGebra applet that demonstrates this claim can be found here . I have noticed that principal diagonals of the hexagon defined by the points: $𝐺,FG \cap ED,𝐷,𝐶,𝐵,𝐴$ concur at the point $P$ . Similar is true for the points $Q,R,S,M,N,O$ as well . So I guess we should apply Brianchon's theorem somehow.","['projective-geometry', 'conic-sections', 'geometry', 'polygons']"
4069083,Are all open sets open intervals?,"Are all open sets open intervals? If not, provide an example. I think that all open intervals are open sets but not the other way around, but couldn't find an example.","['elementary-set-theory', 'calculus', 'analysis', 'real-analysis']"
4069094,Computing $\int_0^\infty \frac{\ln x}{(x^2+1)^2}dx$,"I'm trying to compute $$I=\int_0^\infty \frac{\ln x}{(x^2+1)^2}dx$$ The following is my effort, $$I(a)=\int_0^\infty\frac{\ln x}{x^2+a^2}dx$$ Let $x=a^2/y$ so that $dx=-(a^2/y^2)dy$ which leads to $$I(a)=\int_0^\infty \frac{\ln(a/y)}{a^2+y^2}dy=\int_0^\infty\frac{\ln a}{y^2+a^2}dy-I(a)$$ $$I(a)=\frac{1}{2}\int_0^\infty\frac{\ln a}{y^2+a^2}dy=\frac{1}{2}\frac{\ln a}{a}\arctan\left( \frac{y}{a}\right)_0^\infty=\frac{\ln a}{a}\frac{\pi }{4}$$ Differentiating with respect to $a$ then $$\frac{dI(a)}{a}=-2aI'(a)=\frac{\pi}{4}\left( \frac{1}{a^2}-\frac{\ln a}{a^2}\right)$$ where $$I'(a)=\int_0^\infty \frac{\ln y}{(y^2+a^2)^2}dx$$ $$I'(a)=\frac{\pi}{-8a}\left( \frac{1}{a^2}-\frac{\ln a}{a^2}\right)$$ $$I'(a=1)=-\frac{\pi}{8}$$ But the correct answer is $-\pi/4$ . Can you help me figure where I mistake? Please give some method if there is which is much better than what I have done?","['integration', 'definite-integrals']"
4069174,"Prove that if b is an undefined dot product, then there is a base of time vectors, another of light vectors, and another of space vectors","Prove that if b is an undefined dot product, then there is a base of time vectors, another of light vectors, and another of space vectors.
Taking into account that: Luminous implies $ b (v, v) = 0 $ Time implies $ b (v, v) <0 $ Spatially implies $ b (v, v)> 0 $ I think that one should start with the basis of orthonormal vectors. Since this is always possible because by definition a dot product is always non-degenerate. Then, from that orthonormal basis, it would be possible to build the required bases. But I wouldn't know how to do it","['geometry', 'analysis']"
4069187,Understanding higher order differentials and their properties,"In our course in calculus/real analysis we defined $n$ -th differential of multivariable function $f:\mathbb{R}^{m}\to\mathbb{R}$ as: $$d^{n}f(\vec{x},\vec{h})=\frac{d^{n}}{dt^{n}}f(\vec{x}+t\vec{h})\biggr\rvert_{t=0}   \text{    } (*)$$ There is an explicit formula for this differential in terms of partial derivatives which is quite similar to the multinomial theorem. Now we used this formula to find higher order partial derivatives all at once by finding higher order differentials. In order to find them we used the following properties: $$d(f+g)=df+dg$$ $$d(f\cdot g)=g\cdot df+f\cdot dg \text{ where $f$ and $g$ are differential expressions*}$$ $$d(dx)=0 \text{ where $x$ is an independent variable}$$ We used these properties to find higher-order differentials in the following way: Suppose we have $f(x,y)=xy$ . Then $df=y\cdot dx+x\cdot dy$ . Then we would find second-order differential: $$d^{2}f=d(df)=d(y\cdot dx+x\cdot dy)=d(y\cdot dx)+d(x\cdot dy)=dydx+yd(dx)+dxdy+xd(dy)=dxdy+y\cdot 0 + dxdy+ x\cdot0=2dxdy$$ We usually used this method to find all higher order partial derivatives at once by finding the differential of the same order. In the example above we can deduce that $\frac{\partial^2 f}{\partial x^2}=0$ , $\frac{\partial^2 f}{\partial y^2}=0$ and $\frac{\partial^2 f}{\partial x \partial y}=2/2=1$ While these properties were quite useful for finding higher-order differentials, we haven't proved them(moreover it was said that there is no textbook which covers such proof). And actually I can't imagine how is it possible to approach at proving this, because we haven't defined ""differential of a differential expression"". But after reading about higher order Frechet derivatives I realized that these differentials are just derivatives(which are multilinear functions) evaluated at the diagonal(i.e. $d^{n}f(\vec{x},\vec{h})=D^nf(\vec{x})(\vec{h},\vec{h},\dots,\vec{h})$ ). Is this the right way of viewing ""higher order differentials"" ? Is it possible to prove the properties mentinoned earlier using this definition ? What is the rigorous way of viewing this ""differential operator"" $d$ ? Is there some textbook which covers this topic in rigorous way ? *It was asked in the comments what ""differential expression"" actually means. We were not given a rigorous definition, but it seemed clear at the time that it meant something like ""sum of products of functions and $dx_i$ where $x_i$ is a variable"".","['multivariable-calculus', 'proof-writing', 'derivatives']"
4069206,Expected Value of Binomial Distribution,"What is the expected value of the absolute value of the difference between the number of incoming tails and the number of incoming heads  when a coin is tossed 5 times? Here is what I think : Let $X$ is random variable of number of incoming heads then $p=\frac{1}{2}$ and $n=5$ so $X\sim Binom(5,\frac{1}{2})$ $X$ and $Y=5-X$ ( $Y$ is random variable of number of incoming tails) then $E(K)=E(\left|X-(5-X)\right|)=E(\left|2X-5\right|)=E(2X-5)=2E(X)-5=2.\frac{5}{2}-5=0$ where $K=\left|X-Y\right|=\left|2X-5\right|$ and $E(X)=n.p=5.\frac{1}{2}=\frac{5}{2}$ But the right answer is $\frac{15}{8}$ . Where am I making a mistake? Any help will be appreciated.","['statistics', 'probability-distributions', 'binomial-distribution', 'probability-theory', 'probability']"
4069225,Closedness of second order PDE with complex coefficients.,"Is the following operator closed on $L^2(-1,1)$ ? \begin{equation}
Tu=(c u')',\quad \mathcal{D}(T)=\{u\in H^2(-1,1):u(-1)=u(1)=0\}
\end{equation} Here $c$ is a smooth complex-valued coefficient that is non-vanishing (bounded away from zero) on the interval. I'm aware the operator is closable but want to figure out if it closed and if not, what the domain of its closure is. Most texts I can find treat the case of real coefficients (where of course one can say a lot more). Really what I am after is a method of showing these kind of operators are closed (if they are!) or a nice counterexample. Something that can be extended to higher order (e.g. fourth) derivatives in divergence form as well.","['operator-theory', 'ordinary-differential-equations', 'partial-differential-equations']"
4069351,"$\forall\varepsilon>0$ there exists a subset $F$ of $[0,1]$ that is closed, contains only irrational numbers and $|F|>1-\varepsilon$","I have proved the following result and I would like to know if I have made any mistakes (in particular, I am not sure that the set $F$ I have built is necessarily closed). Thank you. ""Let $\varepsilon >0$ . Prove there exists a subset $F$ of $[0,1]$ such that $F$ is closed, every elements of $F$ is an irrational number and $|F|>1-\varepsilon$ "" (NOTE: $|\cdot|$ denotes the outer measure) Let $r_1,r_2,\dots $ be the sequence that contains every rational number in $[0,1]$ , $\varepsilon >0$ and consider the set $F:=[0,1]-\bigcup_{k=1}^{\infty}(r_k-\frac{\varepsilon}{4\cdot 2^k},r_k+\frac{\varepsilon}{4\cdot 2^k})$ . Then $F$ is closed, being the complement of the open set $\bigcup_{k=1}^{\infty}(r_k-\frac{\varepsilon}{4\cdot 2^k},r_k+\frac{\varepsilon}{4\cdot 2^k})$ in $[0,1]$ , contains only irrational number since we have taken away all the rational ones, and $|F|\geq |[0,1]|-|\bigcup_{k=1}^{\infty}(r_k-\frac{\varepsilon}{4\cdot 2^k},r_k+\frac{\varepsilon}{4\cdot 2^k})|\geq (1-0)-\frac{\varepsilon}{2}\sum_{k=1}^{\infty}\frac{1}{2^k}=1-\frac{\varepsilon}{2}>1-\varepsilon$ .","['measure-theory', 'solution-verification', 'outer-measure', 'real-analysis']"
4069423,Ask unbiased estimator of $\sigma ^2$ in normal distribution when either $\mu$ known or $\mu$ unknown？,"If $\mu$ is unknown, then $\frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2$ is the unbiased estimator of $\sigma ^2$ . However, if $\mu$ is known, then $\frac{1}{n}  \sum_{i=1}^n (X_i - \mu)^2$ is the unbiased estimator of $\sigma ^2$ . I am very confused. From introductory statistics class, I know that given any random population, $E(S^2)$ is always equal to $\sigma ^2$ . Hence, for a normal distribution, I think the sample variance = $\frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2$ should always be unbiased.","['statistics', 'probability-distributions', 'probability']"
4069442,What is the real analysis version of this complex analysis Weierstrass theorem?,"I'm reading Gong Sheng's Concise Complex Analysis , where it introduced a Weierstrass Theorem Theorem 3.1 (Weierstrass Theorem) Suppose $\{f_n(z)\}$ is a sequence
of functions where each $f_n(z)$ is defined and holomorphic in a
region $U\subseteq \mathbb C$ . Assume that $\sum_{n=1}^\infty f_n(z)$ converges uniformly to $f(z)$ on every  compact subset of $U$ .
Then $f(z)$ is holomorphic on $U$ and for every $k\in \mathbb N$ , $\sum_{n=1}^\infty f_n^{(k)}(z)$ converges uniformly to $f^{(k)}(z)$ on every compact subset of $U$ . Then it mentions: This is a profound result. The reader can compare it with the theorem
of  the derivative of function series in calculus. So what is the corresponding real analysis version of this complex analysis Weierstrass Theorem, and what is the difference? -- I suppose the difference would show some distinct properties in complex analysis.","['complex-analysis', 'real-analysis']"
4069487,Definition of a diffusion process is unclear,"The Wikipedia article of a diffusion process mentions: In probability theory and statistics, a diffusion process is a solution to a stochastic differential equation. It is a continuous-time Markov process with almost surely continuous sample paths. Are these two definitions equivalent?","['markov-process', 'stochastic-differential-equations', 'probability-theory']"
4069504,Let $A$ and $B$ be complex $n\times n$ matrices such that $AB−BA$ is invertible and such that $A^2+B^2=c(AB−BA)$ for some rational number $c$.,"Let $A$ and $B$ be complex $n\times n$ matrices such that $AB−BA$ is invertible and such that $A^2+B^2=c(AB−BA)$ for some rational number $c$ . Prove $c\in\{−1,0,1\}$ and show that $n$ is a multiple of $4$ when $c\neq0$ . Please give some hints for this problem. I could not find a way to proceed. I had taken determinant on both sides. But it does not helping much","['matrices', 'linear-algebra']"
4069530,Probability of rolling a 6 immediately after a 1 is rolled,"Question Ann and Bob take turns to roll a fair six-sided die. The winner is the first person to roll a six immediately after the other person has rolled a one. Ann will go first. Find the probability that Ann will win. Answer $\mathbb{P} (\mathrm {Ann\ wins}) = \frac {36} {73}$ I have thought long and hard about this question but I am unable to even start. I have tried considering cases, but got stuck along the way. For example, it is trivial to calculate the probability that Ann wins if there are only three rolls (which is the minimum number of rolls needed for Ann to win). However, the problem easily becomes very complicated when we consider five rolls and more. The suggested solution by my professor uses first-step decomposition, but it is a new concept to me and I am struggling to understand it. If anyone can provide a detailed and intuitive explanation as to how this problem should be solved, that will be greatly appreciated!","['conditional-probability', 'statistics', 'dice', 'probability']"
4069553,Probability of more than 13 balls remaining in the box after some selections,"Question A box contains 20 balls, of which exactly 8 are red and 12 are green. Two balls are randomly selected from the box, without replacement. Then, any red balls selected are put back into the box, while any green balls selected are thrown away. Finally, 5 balls are randomly selected from the box, without replacement. Suppose that, following this procedure, all 5 balls are green. Find the probability that there remains more than 13 balls in the box. My working Observe that the only case when there are less than 14 balls in the box is when the two balls that are selected initially are both green, so we have three cases to consider here. Case 1: Choose 2 red balls, put them back, then choose 5 green balls. Case 2: Choose 1 red ball, then 1 green ball. Put the red ball back, throw the green one away and then choose 5 green balls. Case 3: Choose 1 green ball, then 1 red ball. Put the red ball back, throw the green one away and then choose 5 green balls. $\mathbb{P} (\mathrm {Case\ 1}) = \frac 8 {20} * \frac 7 {19} * \frac {12} {20} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} = \frac {231} {30685}$ $\mathbb{P} (\mathrm {Case\ 2}) = \frac 8 {20} * \frac {12} {19} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} * \frac 7 {15} = \frac {308} {30685}$ $\mathbb{P} (\mathrm {Case\ 3}) = \mathbb{P} (\mathrm {Case\ 2})$ $\therefore \mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {231} {30685} + 2 * \frac {308} {30685} = \frac {847} {30685}$ Answer $\mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {154} {211}$ My answer is obviously off by a lot ): Am I missing cases, or is my thinking too naive etc.? I am not sure where I have gone wrong, so any intuitive explanations about my mistake(s) and also what the correct solution should be will be greatly appreciated! P.S. My professor did provide a solution, but I am unable to understand his way of thinking, so I thought posting the problem here and asking for ideas would be better.","['conditional-probability', 'statistics', 'probability']"
4069627,Expected value and variance from random variable,"Given the following $Y_1 \sim \mathcal{N}(μ, σ^2 )$ and $Y_2=α+βY_1+U \;where \; Y_1 \;and \;U\;is\;independent\;and\;U∼\mathcal{N}(0,v^2)$ Let $μ=350$ and $σ^2 =12365$ How would i calculate the expected value and variance from $Y_2$ ?
And how can i find the distribution of it?","['statistics', 'probability-distributions', 'expected-value', 'probability', 'random-variables']"
4069635,A inclusion property for relations,"Suppose that $R$ and $S$ are two well-defined relations,
then $$
(R \cap S)^{-1} \circ R^{-1} \subset (R \circ S)^{-1} ?
$$ Here, $M \circ N$ denotes the composition of the relations $M$ and $N$ and $L^{-1}$ the inverse of a relation $L$ . I try many counter-examples, but none works. For instance $A = \{ a,b\}, B = \{ a,d\}, C = \{ a,c\}$ and $D = \{ b,d\}$ for $R \subset A \times B$ and $S \subset C \times D$ . Also, the identity $(M \circ N)^{-1} = N^{-1} \circ M^{-1}$ does not seem to help.","['elementary-set-theory', 'proof-writing', 'logic', 'relations']"
4069644,Need a function that measure the proximity of a given value to a target value,"Like the title says, I'm looking for a function that take a given value, and returns a value between 0 and 1 which measures how much the given value is near to a target value. Ideally, the returned value should increase faster when the target value is almost reached. For example, if the target is 10: Input = 5; output = 0.5 Input = 8; output = 0.85 (more than 0.8 because we are near to the target) Input = 10; output = 1 (of course) Input = 15; output = 0.5 (because we have exceed the target) Any help? EDIT 1 The function only takes non negative numbers. The input number can be at most twice the target number EDIT 2 This is what have I done so far: if (amount <= target)
    return amount / target;
else if (amount >= 2 * target)
    return 0;
else
    return 1 - ( amount % target ) / target; It's very rudimental, and it doesn't implement the concept of ""speed"". EDIT 3 The goal is to use the function for an automatic optimizer. I have a set of features, and the idea behind is to assign a score to the value assigned to each feature. The more the assigned value is near to the target value, the merrier. I'm using a maximizer to maximize the sum of the scores.","['elementary-functions', 'functions']"
