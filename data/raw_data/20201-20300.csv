question_id,title,body,tags
170171,What is the volume of this 3d shape?,"I'm wondering if there is an equation that represents the volume of an arbitrary 3d primitive
matching this description: 1.) Point at center of sphere
2.) Each edge is the length of the radius
3.) 3 flat sides, 1 arc side Image: So it's kind of a sector of a sphere, but instead of a conical shape it's more of a tetrahedral shape, but with a curved end.","['geometry', 'solid-geometry']"
170181,How are these two equal?,Which of these terms is greater ? $2x-6y+1$ or $1$ if $x^4 + 3y^2=0$ According to the text they are equal ?How is that ?,['algebra-precalculus']
170183,Uncountable disjoint union of $\mathbb{R}$,"I'm doing 1.2 in Lee's Introduction to smooth manifolds: Prove that the disjoint union of uncountably many copies of $\mathbb{R}$ is not second countable. So first, let $I$ be the set over which we are unioning. Then I believe the disjoint union is just $\mathbb{R}\times I$. Then I believe that sets of the form $\cup_{x\in A}(x,i)$ is open if and only if $A\subset\mathbb{R}$ is open (I know the open sets are defined with the canonical injection though). At first I thought if I let $I=\mathbb{R}$, then $\mathbb{R}\times I=\mathbb{R^2}$, but now I am thinking maybe they just have the same elements, but the topology is different, and this is why $\mathbb{R}\times I$ is not second countable?","['general-topology', 'manifolds', 'differential-topology']"
170192,Solving the complex equation $\sin(z) = \cos(z)$,"To find the complex numbers z satisfying $\sin(z) = \cos(z)$, can I say:
$$\sin(z) = \frac{(e^{iz}-e^{-iz})}{2i}=\frac{(e^{iz}+e^{-iz})}{2}$$ and solve for z? So we then reduce this to $$-e^{-iz} = e^{-iz}$$ but this doesn't look right","['trigonometry', 'complex-analysis']"
170203,Nth derivative of $\tan^m x$,"$m$ is positive integer, $n$ is non-negative integer. $$f_n(x)=\frac {d^n}{dx^n} (\tan ^m(x))$$ $P_n(x)=f_n(\arctan(x))$ I would like to find the polynomials that are defined as above $P_0(x)=x^m$ $P_1(x)=mx^{m+1}+mx^{m-1}$ $P_2(x)=m(m+1)x^{m+2}+2m^2x^{m}+m(m-1)x^{m-2}$ $P_3(x)=(m^3+3m^2+2m)x^{m+3}+(3m^3+3m^2+2m)x^{m+1}+(3m^3-3m^2+2m)x^{m-1}+(m^3-3m^2+2m)x^{m-3}$ I wonder how to  find general formula of $P_n(x)$? I also wish to know if any orthogonal relation  can be found for that polynomials or not? Thanks for answers EDIT: I proved Robert Isreal's generating function. I would like to share it. $$ g(x,z) = \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} \tan^m(x)
= \tan^m(x+z)  $$ $$ \frac {d}{dz} (\tan^m(x+z))=m \tan^{m-1}(x+z)+m \tan^{m+1}(x+z)=m \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} \tan^{m-1}(x)+m \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} \tan^{m+1}(x)= \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} (m\tan^{m-1}(x)+m\tan^{m+1}(x))=\sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} (\dfrac{d}{dx}(\tan^{m}(x)))=\sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^{n+1}}{dx^{n+1}} (\tan^{m}(x))=\sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^{n+1}}{dx^{n+1}} (\tan^{m}(x))$$ $$ \frac {d}{dz} ( \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} \tan^m(x)
)= \sum_{n=1}^\infty \dfrac{z^{n-1}}{(n-1)!} \dfrac{d^n}{dx^n} \tan^m(x) = \sum_{n=1}^\infty \dfrac{z^{n-1}}{(n-1)!} \dfrac{d^n}{dx^n} \tan^m(x)=\sum_{k=0}^\infty \dfrac{z^{k}}{k!} \dfrac{d^{k+1}}{dx^{k+1}} \tan^m(x)$$ I also understood that it can be written for any function  as shown  below .(Thanks a lot to Robert Isreal) $$ \sum_{n=0}^\infty \dfrac{z^n}{n!} \dfrac{d^n}{dx^n} h^m(x)
= h^m(x+z)  $$ I also wrote $P_n(x)$ as the closed form shown below by using Robert Israel's  answer. $$P_n(x)=\frac{n!}{2 \pi i}\int_0^{2 \pi i} e^{nz}\left(\dfrac{x+\tan(e^{-z})}{1-x \tan(e^{-z})}\right)^m dz$$ I do not know next step how to find if any orthogonal relation exist between the polynomials or not. Maybe second order differential equation can be found  by using the relations above.  Thanks for advice.","['trigonometry', 'calculus', 'derivatives', 'polynomials']"
170207,Some method to solve $\int \frac{1}{\left(1+x^2\right)^{2}} dx$ and some doubts.,"First approach. $\int \frac{1}{1+x^2} dx=\frac{x}{1+x^2}+2\int \frac{x^2}{\left(1+x^2\right)^2} dx=\frac{x}{1+x^2}+2\int \frac{1}{1+x^2}dx-2\int \frac{1}{\left(1+x^2\right)^2}dx$ From this relationship, I get: $2\int \frac{1}{\left(1+x^2\right)^2}dx=\frac{x}{1+x^2}+\int \frac{1}{1+x^2}dx$ Then: $\int \frac{1}{\left(1+x^2\right)^2}dx=\frac{1}{2}\left[\frac{x}{1+x^2}+\arctan x\right]+C$ This is a recursive solution. Second approach. $x=\tan t$ in $t\in (- \pi/2, \pi/2)$, i.e. $t=\arctan x$, then $dx=(1+x^2) dt$. $\int \frac{1}{\left(1+x^2\right)^2}dx=\int \frac{1}{1+x^2}dt=\int \frac{\cos^2t}{\sin^2t+\cos^2t}dt=\int \cos^2t dt=\frac{1}{2}\int \left(1+\cos 2t \right) dt=\frac{t}{2}+\frac{1}{4}\sin 2t$ This result can be rewritten (using trigonometric formulas): $\frac{t}{2}+\frac{1}{4}\sin 2t=\frac{t}{2}+\frac{1}{2}\sin t \cos t$ From $\cos^2 t=\frac{1}{1+x^2}$, I have: $|\cos t|=\sqrt{\frac{1}{1+x^2}}$ but in $t\in (- \pi/2, \pi/2)$, $|\cos t|=\cos t$. So: $\cos t=\sqrt{\frac{1}{1+x^2}}$. Now I have a problem: $|\sin t|=\sqrt{\frac{1}{1+x^2}}$, but $|\sin t|\neq \sin t$ for $t\in (- \pi/2, \pi/2)$. Any suggestions, please? This integral can be solved in other ways? Thanks.","['calculus', 'integration']"
170215,"Solving ODEs: The Frobenius Method, worked examples","I find the Frobenius Method quite beautiful, and I would like to be able to apply it. In particular there are three questions in my text book that I have attempted. In each question my limited understanding has stopped me. Only one of these questions (the last) is assigned homework. The rest are examples I found interesting*. 1) $ L[y] =  xy'' + 2xy' +6e^xy = 0 $ (1) The wikipedia article begins by saying that the Frobenius method is a way to find solutions for ODEs of the form $ x^2y'' + xP(x) + Q(x)y = 0 $ To put (1) into that form I might multiply across by x, giving me $ x^2y'' + x[2x]y' + [6xe^x]y = 0 $ (2) But is that OK? The first step in the method seems to be dividing by $ x^2 $, so can't I just leave the equation in its original form? I'll assume I can. Now we let $ y_1 = \sum _{n=0}^{\infty} a_n x^{r+n} $ then, $ y_1' = \sum _{n=0}^{\infty} (r+n)a_nx^{r+n-1} $ and, $ y_1'' = \sum _{n=0}^{\infty} (r+n)(r+n-1)a_nx^{r+n-2} $ substituting into (2) we get, $ x\sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-2} + 2x\sum _{n=0}^{\infty}(r+n)a_nx^{r+n-1} + 6e^x\sum _{n=0}^{\infty}a_nx^{r+n} = 0 $ But now what? I am aware that $ 6e^x = 6\sum _{n=0}^{\infty}x^n/n! $, but my powers stop there. Can I multiply the two series together? I would have to multiply each term in one series by every term in the other, and I don't know how to deal with that. The text provides no worked examples in which P(x) or Q(x) are not polynomials... so for now my work stops here. 2) $ L[y] = x(x-1)y'' + 6x^2y' + 3y = 0 $ Again, I will leave the question in its original form, rather than try to get that x^2 in front (I realise I am not checking that the singular point is a regular singular point, but checking the answer in the back of the book, x = 1 and x = 0 are indeed regular points). With two regular singular points, I expect I will get 2 sets of answers: one near x = 1 and the other near x = 0. Is it enough to just proceed with one case and then the next? I will assume so, and begin with the case close to x = 0. Again, letting $ y_1 = \sum _{n=0}^{\infty} a_n x^{r+n} $, and taking the appropriate derivatives, we find by substitution, $ x(x-1)\sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-2} + 6x^2\sum _{n=0}^{\infty}(r+n)a_nx^{r+n-1} + 3\sum _{n=0}^{\infty}a_nx^{r+n} = 0 $ $ x^2\sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-2} - x\sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-2} + 6x^2\sum _{n=0}^{\infty}(r+n)a_nx^{r+n-1} + 3\sum _{n=0}^{\infty}a_nx^{r+n} = 0 $ $ \sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n} - \sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=0}^{\infty}6(r+n)a_nx^{r+n+1} + \sum _{n=0}^{\infty}3a_nx^{r+n} = 0 $ we shift the indexes of the above sums, so that everything will be in terms of the same power of x. $ \sum _{n=1}^{\infty}(r+n-1)(r+n-2)a_{n-1}x^{r+n-1} - \sum _{n=0}^{\infty}(r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=2}^{\infty}6(r+n-2)a_{n-2}x^{r+n-1} + \sum _{n=1}^{\infty}3a_{n-1}x^{r+n-1} = 0 $ we synchronise the indexes in order to group like terms, by extracting early terms from each series, $ r(r-1)a_0x^r + \sum _{n=2}^{\infty}(r+n-1)(r+n-2)a_{n-1}x^{r+n-1} - r(r-1)a_0x^{r-1} - r(r+1)a_1x^r - \sum _{n=2}^{\infty}(r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=2}^{\infty}6(r+n-2)a_{n-2}x^{r+n-1} + 3a_0x^{r-1} + \sum _{n=2}^{\infty}3a_{n-1}x^{r+n-1} = 0 $ rearranging, we get $ r(r-1)a_0x^r - r(r-1)a_0x^{r-1} - r(r+1)a_1x^r + 3a_0x^{r-1} + \sum _{n=2}^{\infty}(r+n-1)(r+n-2)a_{n-1}x^{r+n-1} - \sum _{n=2}^{\infty}(r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=2}^{\infty}6(r+n-2)a_{n-2}x^{r+n-1} + \sum _{n=2}^{\infty}3a_{n-1}x^{r+n-1} = 0 $ At this point I expect the indicial equation to emerge, and I expect it to be similar to an Euler Equation. That is, I expect a polynomial that I can solve to get two 'exponents at the singularity'. Unfortunately, I cannot see an indicial equation and am at a loss to know precisely why. 3) $ L[y] = xy'' + y = 0 $ Finally we come to the assigned question, which I have been able to manipulate into an almost final form. Again, letting $ y_1 = \sum _{n=0}^{\infty} a_n x^{r+n} $, taking derivatives, and substituting into L, we get $ x\sum _{n=0}^{\infty} (r+n)(r+n-1)a_nx^{r+n-2} + \sum _{n=0}^{\infty} a_n x^{r+n} = 0 $ $ \sum _{n=0}^{\infty} (r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=0}^{\infty} a_n x^{r+n} = 0 $ Now shifting indexes, $ \sum _{n=0}^{\infty} (r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=1}^{\infty} a_{n-1} x^{r+n-1} = 0 $ and extracting the $ 0^{th} $ term of the first sum, $ r(r-1)a_0x^{r-1} + \sum _{n=1}^{\infty} (r+n)(r+n-1)a_nx^{r+n-1} + \sum _{n=1}^{\infty} a_{n-1} x^{r+n-1} = 0 $ $ r(r-1)a_0x^{r-1} + \sum _{n=1}^{\infty}[(r+n)(r+n-1)a_n + a_{n-1}]x^{r+n-1} = 0 $ And voila! We have an indicial term with solutions $r_1 = 1$ and $r_2 = 0$, and a recurrence relation. From my text I expect that $y_1 = |x|^{r_1}[1+\sum _{n=0}^{\infty}a_nx^n]$ and since $ r_1 - r_2 \in \mathbb{Z} $, $y_2 = ay_1ln|x| + |x|^{r_2}[1 + \sum _{n=0}^{\infty}b_nx^n]$ to find $a_n$ we observe the recurrence relation with $ r = r_1 = 1 $, $ (r+n)(r+n-1)a_n + a_{n-1} $ $ a_n = -a_{n-1}/n(n+1) $ so, $ a_1 = -a_0/2*1 $ $ a_2 = -a_1/2*3 = a_0/3*2*1*2*1 = a_0/3!2! $ $ a_3 = -a_2/3*4 = -a_0/4!3! $ and in general, $ a_n = (-1)^na_0/n!(n+1)! $ so we have $ y_1 = |x| + \sum _{n=0}^{\infty} (-1)^na_0x^{n+1}/n!(n+1)! $ Not so easily done with r = r_2 = 0, I'm afraid... since the relation becomes $ a_n = -a_{n-1}/n(n-1) $, which means we can't have a_1 for fear of division by zero. Never the less, starting at n = 2 we get, $ a_2 = -a_1/2*1 $ $ a_3 = -a_2/2*3 = a_1/3*2*1*2*1 = a_1/3!2! $ $ a_4 = -a_3/3*4 = -a_1/4!3! $ and in general, $ a_n = (-1)^{n-1}a_1/n!(n-1)! $ so we have $ y_2 = ay_1ln|x| + 1 + \sum _{n=0}^{\infty} (-1)^{n-1}a_1x^{n+1}/n!(n-1)! $ Which I feel may not be correct... and even if it is, how should one man solve for a in a single lifetime? Thanks everyone for looking at this. I want to stress that I am not just a student looking for help in his homework: I would really like to understand this method because it appeals to me. I particularly like the way we extract the indicial expression from the sums, in order to synchronise them. That is so cool. And how you get 1 recurrence relation that you can use for both solutions: neat. PS sorry if my Latex is not perfect? I'm just getting started with it. questions taken from ""Elementary Differential Equations and Boundary Value Problems"" by William E. Boyce and Richard C. DiPrima (9th ed), from sectin 5.6 pp 290",['ordinary-differential-equations']
170226,Example of a function continuous at only one point. [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Find a function $f: \mathbb{R} \to \mathbb{R}$ that is continuous at precisely one point? I want to know some example of a continuous function which is continuous at exactly one point.
We know that $f(x)=\frac{1}{x}$ is continuous everywhere except at $x=0$. But i think this in reverse manner but i dont get any example. So please help me out!","['functions', 'continuity', 'real-analysis']"
170241,When is matrix multiplication commutative?,"I know that matrix multiplication in general is not commutative. So, in general: $A, B \in \mathbb{R}^{n \times n}: A \cdot B \neq B \cdot A$ But for some matrices, this equations holds, e.g. A = Identity or A = Null-matrix $\forall B \in \mathbb{R}^{n \times n}$. I think I remember that a group of special matrices (was it $O(n)$, the group of orthogonal matrices ?) exist, for which matrix multiplication is commutative. For which matrices $A, B \in \mathbb{R}^{n \times n}$ is $A\cdot B = B \cdot A$?","['matrices', 'linear-algebra']"
170255,A simple question : Is $g(z + \Delta z).g(z) = g(z)^2$?,"Is $g(z + \Delta z).g(z) = g(z)^2$ ? The full expression is a $\lim_{\Delta z \to 0} \frac {A}{G} $, where $G$ is the left-hand side of the above expression. It's a question about a solution to a problem that I'm going through, and I can't post it because I don't have enough reps. But the gist of it is that the above expression is taken to be true and thus he factors a $g(z)^2$ out of the limits in the denominator. I'd appreciate it if somebody explains how this is possible. Thanks!","['complex-analysis', 'limits']"
170257,"""Connection Space""","Can we distill the idea of ""connectivity"" away from their topological context and study abstract properties of ""connectivity""? I define a connective space to be a set $X$ together with a collection $\gamma$ of subsets of $X$, which we define as ""connected"". $\gamma$ contains every singleton subset of $X$, and for all $A, B \in \gamma$ such that $A \cap B \neq \emptyset$ we have $A \cup B \in \gamma$. It might be interesting to study functions between connective spaces that preserve connected sets. Or, more suggestively, perhaps functions such that every pre-image of a connected set is connected... Does this exist in literature?","['general-topology', 'reference-request']"
170274,Center of a ring isomorphic to endomorphism ring of identity functor,"I am having trouble verifying the following (this is self-study): There is an isomorphism between the center of a ring $A$ and the ring of endomorphisms of the identity functor of the category of (right) $A$-modules. The map $\Psi\ \colon Z(A) \to \mathrm{End}(1_{Mod\ A})$ sends
$a \in Z(A)$ to multiplication by $a$ (let's write $\Psi(a) = \theta^{a}$).
This poses no trouble. It seems reasonable to define the inverse map
$\Xi\ \colon \mathrm{End}(1_{Mod\ A}) \to Z(A)$ as sending
$ \eta \in \mathrm{End}(1_{Mod\ A})$ to $\eta_A(1)$, since
from this we readily get
$\Xi \circ \Psi (a) = \Xi(\theta^a)=\theta^{a}_{A}(1)=1a=a$. However I can't see why $\Psi \circ \Xi = 1_{\mathrm{End}(1_{Mod\ A})}$.
Unfolding, we have to prove that
$\Psi \circ \Xi (\eta) = \theta^{\eta_A(1)} = \eta$, that is, for any right $A$-module $L$, we need to have $\theta^{\eta_A(1)}_L = \eta_L$.
I'm at a loss on this. I tried to find the right components on which to use
naturality (that's how I succeeded to prove that $\eta_A(1)$ does lie in $Z(A)$,
which wasn't obvious to me from the outset), but to no avail. Some googling led me to this blog post by Q. Yuan (see the ""sub-example"") where the direction of the map $\Xi$ is deduced from the fact that $A$ is a generator of $\mathrm{Mod}\ A$. However I can't quite see explicitly why (in the perspective adopted there, I believe this is just rephrasing the issue I'm having) the lifting of a central element to an endomorphism of $1_{\mathrm{Mod}\ A}$ is inverse to the composition of the two isomorphisms with the natural injection $\mathrm{End}(1_{\mathrm{Mod}\ A}) \to Z(\mathrm{End}_A(A))$.","['ring-theory', 'category-theory', 'abstract-algebra']"
170280,Annihilators in matrix rings,Let $R$ be a finite commutative ring. For $n>1$ consider the full matrix ring $M_n(R)$. For a matrix $A\in M_n(R)$ is true that the cardinality of the  left annihilator (in $M_n(R)$) of $A$ equals the cardinality of the right annhilator?,"['matrices', 'finite-rings', 'abstract-algebra']"
170319,"How many triangles with integral side lengths are possible, provided their perimeter is $36$ units?","How many triangles with integral side lengths are possible, provided their perimeter is $36$ units? My approach: Let the side lengths be $a, b, c$; now, $$a + b + c = 36$$ Now, $1 \leq a, b, c \leq 18$. Applying multinomial theorem, I'm getting $187$ which is wrong. Please help.","['geometry', 'triangles', 'combinatorics']"
170329,"Sylow 2-subgroups of the group $\mathrm{PSL}(2,q)$","What is the number of Sylow 2-subgroups of the group $\mathrm{PSL}(2,q)$?",['group-theory']
170331,Why is $\int_{0}^{\infty} \frac {\ln x}{1+x^2} \mathrm{d}x =0$?,"We had our final exam yesterday and one of the questions was to find out the value of:
$$\int_{0}^{\infty} \frac {\ln x}{1+x^2} \mathrm{d}x $$
Interestingly enough, using the substitution $x=\frac{1}{t}$ we get - $$-\int_{0}^{1} \frac {\ln x}{1+x^2} \mathrm{d}x = \int_{1}^{\infty} \frac {\ln x}{1+x^2} \mathrm{d}x $$and therefore $\int_{0}^{\infty} \frac {\ln x}{1+x^2} \mathrm{d}x = 0 $ I was curious to know about the theory behind this interesting (surprising even!) example. Thank you.","['improper-integrals', 'calculus', 'integration']"
170335,Another question about the generated $\sigma$-field,"Suppose I have a probability space $(\Omega,\mathcal{F},P)$ and the set
$$\mathcal{C}:=\{F=\sum_{i=0}^nf_i\mathbf1_{(t_i,t_{i+1}]}|n\in\mathbb{N},f_i:\Omega\to\mathbb{R} \mbox{ measurable and bounded}\}$$
In fact the sets of all $F=f_0\mathbf1_{0}+f_1\mathbf1_{(0,t_1]}+\dots+f_n\mathbf1_{(t_{n-1},t_n]}$ for any $t\in (0,\infty)$ and any finite subdivison of $[0,t]$, i.e $\{0=t_0<t_1<\dots<t_n=t\}$. What is the generated $\sigma$-field of this set? It should be the product $\sigma$-field on $\Omega\times (0,\infty)$. How can I show this? thanks in advance hulik","['probability-theory', 'measure-theory']"
170337,Connectedness of the boundary,"My question is about the following claim: For $n \geq 2$, let $A\subset \mathbb R^n$ be a non-empty, open, bounded set. Assume $A$ and its complement are connected and $\text{int}(\text{cl}(A)) = A$. Then $\partial A$ is connected. Without the assumption $\text{int}(\text{cl}(A)) = A$, the statement is false (just take any open set and remove an interior point). This condition is not necessary but I think it is sufficient to get the claim. This seems a trivial matter, but I cant's find a proof using only basic topological tools. Does anyone know something about this ? Thank you very much.","['general-topology', 'connectedness']"
170343,Evaluation of $L^p$ function,"Functions in $L^p$ are only defined $Âµ$-almost everywhere, so for a given evaluation point $x$, $F(x)$, $f\in L^p$ can be changed to any value, so in general it would not be well-definied to just write $y=f(x)$.
(Every representant $f$ of the equivalence class $F$ can be evaluated, okay. But this doesn't help.) What is needed to have a well-defined evaluation mapping $(F,x) \mapsto F(x)$ , and how is this problem solved canonically ? 
It would be enough for example that F is piecewise continuous, then I could define the evualation at every continuous part. But isn't much less (for example piecewise one-sided continuity?) enough? And if you take for example Sobolev spaces, and consider the weak derivative of $F:x \mapsto |x|$. Does it follow from the definition of weak derivative in Sobolev spaces that we choose the continuous representant of $F'$ in $L^p$, and define the evaluation of the weak derivative only on the continuous part? How is this problem handled?","['sobolev-spaces', 'measure-theory', 'analysis']"
170349,Compute $\lim\limits_{n\to\infty} \int_{0}^{2\pi} \cos x \cos 2x\cdots \cos nx \space{dx}$,"Compute the following limit:
  $$\lim_{n \to \infty}\int_{0}^{2\pi}\cos\left(x\right)\cos\left(2x\right)\ldots
\cos\left(nx\right)\,{\rm d}x$$ Today I was working on a W. L. Putnam competition's problem containing this 
integral and wondered how I may compute its value when $n$ goes to $\infty$. So far I've found no answer. Could you give me some suggestions about the way I should go?","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'limits']"
170356,proving convergence of a sequence and then finding its limit,"For every $n$ in $\mathbb{N}$, let: $$a_{n}=n\sum_{k=n}^{\infty }\frac{1}{k^{2}}$$ Show that the sequence $\left \{ a_{n} \right \}$ is convergent and then calculate its limit. To prove it is convergent, I was thinking of using theorems like the monotone convergence theorem. Obviously, all the terms $a_{n}$ are positive. So, if I prove that the sequence is decreasing, then by the monotone convergence theorem it follows that the sequence itself is convergent. $a_{n+1}-a_{n}=-\frac{1}{n}+\sum_{k=n+1}^{\infty }\frac{1}{k^{2}}$. But, I can't tell from this that the difference $a_{n+1}-a_{n}$ is negative. If anybody knows how to solve this problem, please share.","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
170373,How do we know Taylor's Series works with complex numbers?,Euler famously used the Taylor's Series of $\exp$: $$\exp (x)=\sum_{n=0}^\infty \frac{x^n}{n!}$$ and made the substitution $x=i\theta$ to find $$\exp(i\theta) = \cos (\theta)+i\sin (\theta)$$ How do we know that Taylor's series even hold for complex numbers?  How can we justify the substitution of a complex number into the series?,"['trigonometry', 'sequences-and-series', 'complex-analysis', 'taylor-expansion']"
170393,Convergence of $a_{n}=\frac{1}{\sqrt{n}}\sum\limits_{k=1}^{n}\frac{1}{\sqrt{k}}$?,"For $n$ in $\mathbb{N}$, consider the sequence $\left \{ a_{n} \right \}$ defined by:
$$a_{n}=\frac{1}{\sqrt{n}}\sum_{k=1}^{n}\frac{1}{\sqrt{k}}$$ I would like to prove whether this sequence is convergent, and if so what its limit is. I can prove by induction that $\sum\limits_{k=1}^{n}\frac{1}{\sqrt{k}}\geqslant \sqrt{n}$ For any $n$ in $\mathbb{N}$. Hence, $a_{n}\geqslant 1$. I wanted to prove that the sequence is decreasing and then use the monotone convergence theorem to prove it is convergent. However, I couldn't come up with a proof for this part. Anyone know how to prove convergence and find the limit? I had another proof based on using Riemann sums, but I am looking for another proof using onne of the tricks used to prove convergence of sequences. Here is my proof: 
$$
a_{n}=\frac{1}{\sqrt{n}}\sum_{k=1}^{n}\frac{1}{\sqrt{k}}=\sum_{k=1}^{n}\frac{1}{n}\frac{1}{\sqrt{\frac{k}{n}}}.
$$
Hence, $$\lim_{n \to \infty }a_{n}=\int_{0}^{1}\frac{dx}{\sqrt{x}}=2$$","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
170403,Weak convergence and weak star convergence.,"If region $\Omega$ is bounded and $u_n$ has weak star convergence in $L^\infty ( \Omega)$ to some $u\in L^\infty(\Omega)$ , does it imply that $u_n$ converges weakly in any $L^p(\Omega) $ ? I think i got it : If $sup$ of a function is finite then integral over a bounded region is finite with any $p$ norm  . is it right ?","['measure-theory', 'functional-analysis']"
170420,derivative at a given point,"I often see the following: $$ \left. \frac{\partial q}{\partial \alpha} \right|_{\alpha = 0} $$ Where $q$ is a function $q(q', t, \alpha)$. Is that just the same as that? $$ \frac{\partial}{\partial \alpha} q(\alpha=0) $$ If they are the same, why do people write the first one? I find the second easier.","['notation', 'calculus', 'derivatives']"
170421,Holoedric isomorphism?,"While trying to read the following article Schottenfells, Ida May. Two Non-Isomorphic Simple Groups Of The Same Order 20,160 . I found the term ""holoedrically isomorphic"". In an abstract for the article, I also came across the claim that ""Holoedric isomorphism is the only isomorphism that can exist between two simple groups."" I haven't been able to find a definition for this term anywhere.  Presumably it is a stronger notion than that of a normal isomorphism of groups? What does it mean?",['group-theory']
170423,Simple application of Stone-Weierstrass,I was looking for a simple application of the Stone-Weierstrass theorem . First I thought that if $X$ is any compact measure space then Stone-Weierstrass implies that $C_c(X)$ is dense in $L^p$. But I have to assume that $X$ is compact otherwise I don't have $1$ in $C_c(X)$. That of course makes it a boring example since then $C_c(X) = C(X)$. Can someone show me a slightly more interesting but still simple example? Thank you.,"['normed-spaces', 'functional-analysis']"
170433,Why convolution of integrable function $f$ with some sequence tends to $f$ a.e.,"Let $g: \mathbb{R} \rightarrow \mathbb{R}$ be integrable with$\int_{\mathbb{R}}g(x)dx=1$ and $|g(x)| \leq \frac{C}{(1+|x|)^{1+h}}$ for $x \in \mathbb{R} $, where $C, h>0$ are constants. Let
$g_t(x)=\frac{1}{t} g(\frac{x}{t})$ for $x \in \mathbb{R}$, $t>0$. I want  to show that: If $f\in L^p$, where $1\leq p\leq \infty$, then $f*g_t(x) \rightarrow f(x)$ a.e. I have tried in this way: Let $x\in \mathbb{R}$ be the Lebesgue point of $f$, that is $lim_{r\rightarrow 0} \frac{1}{r} \int_{B(x,r)} |f(y)-f(x)|dx=0$, then $$
|f*g_t(x)-f(x)|\leq \int_{\mathbb{R}} g_t(x-y)|f(y)-f(x)|dy =I_1+I_2,
$$ where $I_1=\int_{B(x,t)} g_t(x-y)|f(y)-f(x)|dy \leq\frac{1}{t} \int_{B(x,t)} 
\frac{C}{(1+\|\frac{x-y}{t}\|)^{1+h}} |f(y)-f(x)|dy $ $ \leq C\frac{1}{t}\int_{B(x,t)} |f(y)-f(x)|dy \rightarrow 0 \ as \ t \rightarrow 0;$ $I_2=\int_{\mathbb{R}\setminus B(x,t)} g_t(x-y)|f(y)-f(x)|dy .$ I don't know how to estimate the integral $I_2$.",['real-analysis']
170438,Solving a Maximum Likelihood Estimation with an exponential distribution,"I need someone's insight on applying a MLE for an exponential distribution. In a finance paper, I have the following: $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ where $\epsilon_i$ is i.i.d. exponentially distributed with parameter $= 1$. and $i=1,\ldots,n$. $d_i$ are duration time values like time between two events. The $\epsilon$ are not observed. $\lambda_i$ are not observed and must be replaced with estimates from an optimal filter under a $2^k$ states where $k$ can take value $2 \ldots 10$. Conditional on $\lambda_i$ the $d_i$ have an exponential distribution of $\lambda_i$ with density $p(d_i|\lambda_i) = \lambda_i \exp[-\lambda_i d_i]$ The $\epsilon_i$ in $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ confuses me in the MLE application. First, is the $\epsilon_i$ relevant in the MLE computation? If yes, how does it influence the likelihood fucntion below: $$
\mathcal{L}(\lambda,d_1,\dots,d_n)=\prod_{i=1}^n f(d_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda d}=\lambda^ne^{-\lambda\sum_{i=1}^nd_i}
$$","['statistics', 'probability', 'economics']"
170439,contour integral computations,"Let $C$ be the boundary of the square whose vertices are $1+i$, $1-i$,
$-1 + i$ and $-1 -i$. Suppose that $C$ is oriented counterclockwise. How to compute a) $$\int_C \frac{e^z}{z-1/2} \, dz$$ b) $$\int_C \ln(z+3) \, dz$$ c) $$\int_C \bar{z} \, dz$$ I seee that we can use $f'(z)z'$ and maybe we can proceed this using a definition of Cauchy Riemann? Also, can we use the fundamental theorem of calculus on this?","['complex-analysis', 'contour-integration']"
170440,"In Taxicab Geometry, what is the solution to d(P, A) = 2 d(P, B) for two points, A and B?","Taxicab and Euclidean geometry differ a great deal, due to the modified metric function: $$d_T(A,B)=|x_a-x_b|+|y_a-y_b|$$ (Note that this means when measuring distance, it is not the length of the hypotenuse, but the sum of the legs of the same right triangle.) My Main Problem In Euclidean geometry, the answer to the question ""Find the locus of points $X$ such that: $d(X, A) = 2 * d(X, B)$"" yields a regular, Euclidean circle.  A little bit of algebra makes this very trivial. But what is the answer to the same problem, but for $d_T$? What I Know So Far This kind of geometry actually has a very interesting property, namely that as things rotate, their measures change.  Consider the cases where points share either one of their coordinates.  Many times, those situations yield the same answers as do their Euclidean counterparts. Some things are noticeably different, though.  For instance, a circle, as defined as the set of points a fixed distance from one point, actually comes out as a square, rotated 45 degrees.  It is also trivial to illustrate that. It did occur to me that the answer to this problem could be analogous to Euclidean geometry, and the solution may simply be a Taxicab circle (a square).  But this didn't seem to work out.  Plus, I worked out the solution for the points sharing an x or y coordinate, I end up with two mirror-image line segments.  But the general case, where the two points are corners of any rectangle still eludes me.  My second educated guess was that the solution could be a Euclidean circle, but this didn't work out either. Lastly, some constructions seemed to differ depending on whether the points I chose formed the opposite diagonal corners of a general rectangle, or a square.  E.g. (0,0) and (3, 3) seem to be a yet different type of exception. Any thoughts on this problem would be greatly appreciated!",['geometry']
170442,Differentiating the posterior distribution function,"I am learning about Bayesian statistics and I'm currently doing loss functions. Let $f(\theta | \mathbf{x} ) $ be a posterior pdf . Let $F(\theta | \mathbf{x} ) $ be the associated distribution function. I want to differentiate $F(a - D| \mathbf{x} )$ with respect to $D$. In this case $D$ is the ""decision"" which is to be optimised and $a$ is constant. I am having a problem here:
$$\frac{d}{d D}F(a - D| \mathbf{x} ) = \frac{d}{d D} \left( \int_{-\infty}^{a - D} f(\theta|\mathbf{x}) d \theta \right)$$
$$=f(a - D | \mathbf{x})$$ Is this correct ? I think it might be wrong. Should it be $=-f(a - D | \mathbf{x})$ because I have to apply the chain rule somewhere ?? Or is something else wrong ? I know there are some issues about integration under differentiation but my teacher said I don't need to worry about that now, and just use this:
$$\frac{d}{dy} \int_{-\infty}^y f(t) dt=f(y)$$ I'm doing self-study (with a bit of teacher guidance in his own time so I don't like to ask him too much) but I feel a bit out of depth now and school breaks up for the holidays next week !","['statistics', 'bayesian', 'derivatives']"
170455,Why can/do we multiply all terms of a divisor with polynomial long division?,"I'm trying to understand why polynomial long division works and I've hit a wall when trying to understand why we multiply all terms of the divisor by the partial quotient.  Consider: $$\frac{x^2 + 3x + 2}{x + 2}$$ During the first step we divide ${x^2}$ by ${x}$ giving us a partial quotient of ${x}$.  Next, we multiply the partial quotient by the first term of the divisor, giving us ${x^2}$.  So far so good, but this next step is what I don't understand: why do we then multiply the next term of the divisor by the partial quotient (i.e. ${x}$ * ${2}$)?  It seems as though we're testing to see if ${x}$ can be divided into the first term of the dividend, and if it can, then we distribute the result over the whole divisor which is then subtracted.  I don't understand how we can do that when we're only testing the divisibility of those first terms. I tried a slightly different example to see what happens which highlights what I mean: $$\frac{x^2}{x + 1}$$ First, we test the divisibilty of ${x^2}$ by ${x}$.  Obviously it goes ${x}$ times, but then I wanted to see if I could carry on and multiply ${x}$ * ${1}$.  I carried on and the quotient becomes ${x + \frac{1}{x + 1} - 1}$.  Checking $({x + 1})({x + \frac{1}{x + 1} - 1})$ does give the original dividend of ${x^2}$.  Having worked through that problem I just can't see why we're able to do the multiplication of the second term of the divisor, subtract it and get everything to hold true.  Essentially, if I subtract ${x^2}$ from ${x^2}$ I end up with nothing.  So the second multiplication, to me at least, seems unclear as to why it works and what the purpose is. I know I'm missing something simple here but I can't seem to make the connection.  Could someone explain this to me please?","['algebra-precalculus', 'polynomials']"
170456,$C_c(X)$ dense in $L^p$,"In class we proved that $C_c(X)$ is dense in  $L^p$ where $X$ is a locally compact, $\sigma$-compact Hausdorff space either equipped with a Radon measure or equipped with a locally finite measure $\mu$ on the Borel sigma algebra. The proofs, especially of the second variant are fairly long and I find it very hard to remember all the conditions (locally finite, $\sigma$-compact etc.). The first variant uses Lusin's theorem (among others). 
So I thought I might try to reduce this to a more specific case, the Lebesgue measure (which is Radon) and $X$ any subset of $\mathbb R$. (Do I need any assumption on $X$? Perhaps it needs to be measurable.) Can you tell me if this is correct? Thank you. Claim: $C_c(X)$ is dense in $L^p$ with the Lebesgue measure and $X \subset \mathbb R$. Proof: We know that simple functions are dense in $L^p$. So if we can construct a function in $C_c$ that is $\varepsilon$-close (in $\|\cdot\|_p$) to $\chi_M$, the characteristic function of a measurable set $M$ then we're done. We know that $\mu$ is inner and outer regular so for $\varepsilon > 0$ we can find a compact set $K \subset M$ such that $\mu(M - K ) \leq \varepsilon$. Also, we can find an open set $O$ containing $M$. Let $f : K \sqcup O^c \to \mathbb R$ be the function that is $1$ on $K$ and $0$ on $O^c$. Then using Tietze we can continuously extend it to all of $X$. Then its extension $F \in C_c(X)$ and 
$$ \|F - \chi_M \|_p^p =  \int_X |F - \chi_M|^p d \mu = 1 \cdot \mu(M -K)^p \leq \varepsilon^p$$ So I don't need Lusin's theorem. Right?","['normed-spaces', 'functional-analysis', 'banach-spaces']"
170469,Applications of complex variables beyond undergrad syllabus,"So complex numbers solve all polynomials, appear as eigenvalues, appear in intermediate calculations in solving cubics, relate trig to hyperbolic functions, can be used to contour integrate real functions more easily, can represent fourier series more compactly, describe calculations about wave phenomena, used in potential theory and conformal maps. But what are some unusual, not well known or just advanced applications of complex numbers that one would be unlikely to encounter in an undergraduate mathematics degree ?","['complex-numbers', 'big-list', 'complex-analysis']"
170473,Verify trigonometric equation $\frac{(\sec{A}-\csc{A})}{(\sec A+\csc A)}=\frac{(\tan A-1)}{(\tan A+1)}$,How Would I verify the following  identity. $$\frac{(\sec{A}-\csc{A})}{(\sec A+\csc A)}=\frac{(\tan A-1)}{(\tan A+1)}$$ I simplified it to $$\frac{(\sin{A}-\cos{A})}{(\sin{A} \cos{A})}\div\frac{(\sin{A}+\cos{A})}{(\sin{A}\cos{A})}$$,"['trigonometry', 'algebra-precalculus']"
170477,How  to verify this trigonometric identity?,I am having trouble doing this identity. $$\frac{\cos{A}\cot{A}-\sin{A}\tan{A}}{\csc{A}-\sec{A}} \equiv 1+\cos A\sin A$$ I am stuck I simplified it to. $$\frac{\cos^{2}{A}\div\sin{A} -\sin^{2}{A}\div\cos{A}}{1\div\sin{A}-1\div\cos{A}}$$ I am in trouble because I know not what to do.,"['trigonometry', 'algebra-precalculus']"
170481,Motivation to understand double dual space,"I am helping my brother with Linear Algebra.  I am not able to motivate him to understand what double dual space is.  Is there a nice way of explaining the concept?  Thanks for your advices, examples and theories.","['dual-spaces', 'linear-algebra', 'duality-theorems']"
170489,Finding the derivative of a function using the Product Rule,"I'm home teaching myself calculus because I'm 16 and therefore too young to take an actual class with a teacher, so I apologise if this seems simple. I understand the definition of the Product Rule and its formula: ""If a function $h(x)=f(x)\times g(x)$ is the product of two differentiable functions $f(x)$ and $g(x)$, then $h'(x) = f(x)\times g'(x)+f'(x)\times g(x)$ "". I did a question to find the derivative of $g(x) = (2x+1)(x+4)$ using the Product Rule. Now on the solutions sheet it says I must begin by writing: $g'(x)=(2x+1){\bf (1)}+{\bf (2)}(x+4)$ What confuses me are the terms that I have put in bold. (the terms $(1)$ and $(2)$). I believe the term $(1)$ is $g'(x)$ from the formula and the term $(2)$ is $f'(x)$ from the formula. How am I supposed to know these 2 terms? Am I supposed to find the derivative of $(2x+1)$ and $(x+4)$ before going on to the question? I also apologise if this is quite messy.","['calculus', 'derivatives', 'functions']"
170501,Compute: $\lim_{n\to\infty} n^{p+1} \int_{0}^{1} e^{-nx} \ln (1+x^p) \space dx $,"Find the following limit for any $p$ natural number: $$\lim_{n\to\infty} n^{p+1} \int_{0}^{1} e^{-nx} \ln (1+x^p) \space dx $$ If i'm not wrong, without much effort one may see that this integral may be rewritten as Gamma function and the limit is $p!$ . I'm just curious about more different ways one might go here.","['improper-integrals', 'calculus', 'integration', 'real-analysis', 'limits']"
170506,Does an arbitrary function preserve arbitrary intersections?,"Let $S,T$ be sets and let $\Lambda$ be an index-set. Let $f:S\to T$ and $\{A_\lambda\}_{\lambda\in\Lambda}$ be a collection of subsets in $S$ (i.e. $A\lambda\subset S$ for all $\lambda\in\Lambda$). Does $f$ satisfy $$f\left[\bigcap_{\lambda\in\Lambda} A_\lambda\right]\subset\bigcap_{\lambda\in\Lambda} f[A_\lambda]\text{ and }f\left[\bigcup_{\lambda\in\Lambda} A_\lambda\right]=\bigcup_{\lambda\in\Lambda} f[A_\lambda]?$$",['elementary-set-theory']
170522,the integral of a periodic function,"Consider $f:\mathbb{R}\to \mathbb{C}$ a bounded and $1$-periodic function, and $g \in L^1(R)$ then $$\lim_{n\to \infty} \int _{R}g(x)f(nx)dx=\int_0^1f(s)ds\int_R g(t)dt.$$ I think the fact that $f$ is complex valued as well $g$ is not a big deal but I couldn't solve it in any case.","['improper-integrals', 'measure-theory', 'real-analysis']"
170528,question involving Markov chain,"Let $S_{2m}$ be the group of all permutations $\pi$ of $\{1, 2, \ldots, 2m\}$. The following transition kernel $S$ generates the random transposition walk
$$
Ch(\pi, \pi')= \begin{cases}
\frac{1}{2m} & \pi'=\pi\\[10pt]
\frac{2}{(2m)^2} & \pi'=\tau \pi\  \text{ for some transposition $\tau$}\\[10pt]
0, & \text{otherwise}
\end{cases}
$$
It is known that with symmetric probability measure $\mu$, the pair $(Ch, \mu)$ defines a reversible Markov chain. Let $\tau=(I, J)$ be a random transposition, with $I, J$ chosen independentely and uniformly from $\{1, 2, \ldots, 2m\}$. Multiplication by $\tau$ results in taking a step in the chain defined by $Ch$. All this structure is given in  "" The Concentration of Measure Phenomenon "" by M. Ledoux. Let $c=(c_1, c_2, \ldots, c_{2m})$ be a vector in $R^{2m}$. Define function $f:S_{2m}\longrightarrow R$ as $f(\pi):=|\sum_{k=0}^mc_{\pi(k)}-\sum_{k=m+1}^{2m}c_{\pi(k)}|$. Question: Find the upper bound of $|f(\pi)-f(\tau \pi)|$. Thank you for your help.","['statistics', 'markov-chains', 'permutations', 'probability']"
170552,Convergence of $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$?,"I need to prove the convergence/divergence of the series $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ based on the convergence/divergence of the series $\sum_{n=1}^{\infty }a_{n}$. It is given that $a_{n}> 0$, $\forall n\in \mathbb{N}$ If the series $\sum_{n=1}^{\infty }a_{n}$ is convergent, then from $\frac{a_{n}}{1+na_{n}}< a_{n}$ and the comparison test, we conclude that $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ is convergent. However, if the series $\sum_{n=1}^{\infty }a_{n}$ is divergent, I have no idea how to prove the convergence/divergence of $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$. It is definitely divergent (just take $a_{n}=\frac{1}{n}$), but I have no clue how to prove it.","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
170553,The probabilty of a new arrangement of 52 cards deck?,"I just read this article , it claims that if you just shuffle a 52 card deck, you will mostly be creating an arrangement that no human have ever seen before. But this doesn't seem right since every time we create a new arrangement, this one is now a candidate to happen again, so every time we fail, the odds increase. How can we mathematically review this claim?","['card-games', 'recreational-mathematics', 'probability']"
170557,How to find all naturals $n$ such that $\sqrt{1 {\underbrace{4\cdots4}_{n\text{ times}}}}$ is an integer?,How to find all naturals $n$ such that $\sqrt{1\smash{\underbrace{4\cdots4}_{n\text{ times}}}}$ is an integer?,"['elementary-number-theory', 'combinatorics']"
170580,What role does $\mathfrak D$ play in the definition of the union and intersection of the complements of a collection of sets?,"I'm puzzled by something that might be complete silly. Halmos writes in his ""Naive Set Theory"": If $\mathcal C$ is a collection of subsets of a set $E$ (that is, $\mathcal C$ is a subcollection of $\mathcal P(E)$), then write $$\mathfrak D = \{X \in \mathcal P(E):X^\prime \in \mathcal C\}$$ It is customary to denote the union and intersection of $\mathfrak D$ by the symbols: $$\bigcup_{X \in \mathcal C}X' \;\;\text{  and  
 } \;\;\bigcap_{X \in \mathcal C}X'$$ He is defining the union and intersection of the complements of the sets $X \in \mathcal C$, which are subsets of the set $E$. $E$ is the ""everything"" set, which contains all sets considered in the current section. I'm a little confused by why he is considering the set $\mathfrak D$. Why not just consdier the set of complements? $\mathfrak D$ is apparently, as I understand, the set of all subsets of $E$ such that the complement of $X$, namely $X'$ is in the collection of subsets of $E$, $\mathcal C$. By definition of the powerset of $E$, $$\mathcal C \subset \mathcal P(E)$$ so $\mathfrak D$ is the set of subsets of $E$, $X$ such that $X'$ is also a subset of $E$. I still can't see how $\mathfrak D$ enters in the picture here.",['elementary-set-theory']
170583,What is the relation between the average rate of change and the derivative?,"A value in the range for any base polynomial function with a y-intercept of zero can be expressed as: $$f\left(x\right) = px$$ where $p$ is the average rate of change between $0$ and $x$. The average rate of change can be in turn expressed as $$p = \frac{ f'\left(0\right) + f'\left(x\right)}{2}$$ where $f'\left(0\right)$ is the instantaneous rate of change at $0$ (or in other words the derivative evaluated at zero) and $f'\left(x\right)$ is the instantaneous rate of change evaluated at $x$ (or in other words the derivative evaluated at the specific range value). In a base polynomial equation (or in other words a polynomial with one term of degree $d$ and leading coefficient $1$) with degree greater than 1 the derivative evaluated at zero can be further simplified to $0$. This leads to a final simplified equation: $$f(x) = \frac{f'(x)x}{2}$$ This final equation however fails to provide the range value for a polynomial above degree $2$. According to the power rule, if: $$f(x) = x^3$$ then: $$f'(x) = 3x^2$$ According to the above derived equation: $$f(3) = \frac{f'(3)(3)}{2} = \frac{(3(3)^2)3}{2} = \frac{81}{2}$$ which is clearly the wrong answer. What is the flaw in the equation relating the average change of rate and the derivative?","['calculus', 'derivatives']"
170615,Local boundedness of continuous functions on a Banach space,"Let $X$ be an infinite-dimensional Banach space and $f : X \to \mathbb{R}$ continuous (not necessarily linear). Can $f$ be unbounded on the unit ball? Of course, in a locally compact space these are impossible.  Since $X$ is not locally compact one would guess these are possible, but I cannot think of an example. Are such examples possible even when $X$ is, say, separable Hilbert space?","['general-topology', 'functional-analysis', 'real-analysis']"
170618,"Computing $\mathbb{C}[x,y]^G$ or $\mathbb{C}[x,y,z]^G$ where $G$ is a finite subgroup of $GL_n(\mathbb{C})$","My question is related to this link: Ring of Invariant $\mathbf{Question \;1}$. Let 
$$
A = \left( \begin{array}{cc}
0 & -1 \\
1& 0 \\ 
\end{array}
\right). 
$$
Then $C= \langle A\rangle$ is a cyclic, finite group of order $4$. Suppose $A$ acts on $\mathbb{C}[x,y]$ linearly. Then what is the subring $\mathbb{C}[x,y]^C$ of invariant functions in $\mathbb{C}[x,y]$? What is the basic strategy? Note that 
$$
C = \left\{ 
\left( \begin{array}{cc}
0 & -1 \\
1& 0 \\ 
\end{array}
\right), 
\left( \begin{array}{cc}
-1 & 0 \\
0& -1 \\ 
\end{array}
\right),
\left( \begin{array}{cc}
0 & 1 \\
-1& 0 \\ 
\end{array}
\right),
\left( \begin{array}{cc}
1 & 0 \\
0 & 1 \\ 
\end{array}
\right)
\right\}. 
$$ $\mathbf{Question \;2}$. Now, suppose the dihedral group $D_6 = \langle \rho, \psi : \rho^6 = \psi^2 =e,\psi \rho\psi^{-1}=\rho^{-1} \rangle$ acts on $\mathbb{C}[x,y,z]$, with the action defined by the matrices 
$$ 
\rho = \left( \begin{array}{ccc}
1/2 & -\sqrt{3}/2 & 0 \\ 
-\sqrt{3}/2 & 1/2 & 0 \\
0 & 0 & 1 \\
\end{array}
\right) 
 \mbox{ and }
\psi = \left( \begin{array}{ccc}  
1 & 0  & 0 \\
0 & -1 & -1 \\
0 & 0 & -1 \\
\end{array}\right). 
$$ Then what is $\mathbb{C}[x,y,z]^{D_6}$? $\mathbf{Question \;3}$. What is the general strategy, if we have something like the subgroup generated by $B$ and $-B$ in $GL_3(\mathbb{C})$ acting on a polynomial ring $\mathbb{C}[x,y]$ of only two variables, where 
  $$
B = \left( \begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & -1 \\ 
0 & 0& 1 \\ 
\end{array} \right)? 
$$","['matrices', 'finite-groups', 'group-theory', 'invariant-theory']"
170619,Working with phi function with larger numbers?,"I've been recently learning about Phi function(Euler's totient function).  I am attempting to efficiently find the $\phi(n)$ of higher numbers. What I wanted to asked about was, if I have say: $$\frac{30}{\phi(30)} = 3.75,$$ would I be able to now know that for every multiple of $30$? $$\frac{180}{\phi(180)} = 3.75,$$ $$\frac{999990}{\phi(999990)} = 3.75.$$ I have done some research but, with me being quite the novice I am still unsure?","['totient-function', 'number-theory']"
170650,"How to get upper-left, upper-right, lower-left and lower-right corners XY coordinates from a rectangle shape.","How can I get the get upper-left, upper-right, lower-left and lower-right corners given XY coordinates from a rectangle shape when I have the following data available to me? positionX 
positionY
width
height
rotation Is there an easy way of doing this? Clarification: The rectangle is being rotated at positionX and positionY, the upper-left corner when no rotation is applied (rotation=0).","['geometry', 'coordinate-systems']"
170680,"Suppose I have a function $y=x+1$, then is this function the same as $y=\frac{ x^2+x}{x } $?",Suppose I have a function $y=x+1$ Then is this funcion the same as $y=\frac{ x^2+x}{x } $ ? The domain of x in the first function is $R$ and in the second function is $x\neq 0$.,['functions']
170683,What is the rotation axis and rotation angle of the composition of two rotation matrix in $\mathbb{R}^{3}$,"I was told in class that a rotation matrix is defined by a rotation
angle and rotation axis, if we call the rotation axis $v$ and take
a basis of $\mathbb{R}^{3}=\{v\}\bigoplus\{v\}^{\perp}$ then the
matrix is similar by an orthogonal matrix to a matrix of the form
$$\begin{pmatrix}\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta\\
 &  & 1
\end{pmatrix}$$ I asked my self the following question: If I rotate in the $xy$ plain
(i.e. rotation axis is $z$) in angle $\theta$, and then rotate in
the $yz$ plain  (i.e. rotation axis is $x$) in angle $\varphi$
, what rotation matrix I get ? I tried multiplying the corresponding matrices but that did not produce
anything useful, I can't also thing of a vector $v\in\mathbb{R}^{3}$that
is invariant under the composition... What is the rotation axis, and the rotation angle of these two compositions
? Help is appreciated!","['matrices', 'geometry', 'rotations']"
170693,Are countable intersections of convex sets convex?,Let $X$ be a Banach space $\{C_n\colon n\in\mathbb N\}$ a collection ofconvex sets in $X$. Is the set $$C=\bigcap_{n\in\mathbb N}C_n$$ convex?,"['convex-analysis', 'functional-analysis', 'banach-spaces']"
170699,Invariant subspace under orthogonal matrix,"Let $V=\mathbb{R}^{n}$ and $T\,:V\to V$ be defined by $Tv=Av$ where
$A\in M_{n}(\mathbb{R})$ is an orthogonal matrix. My lecture wrote that if $W\subset V$ is a subspace of $V$ then
if $W$ is $A$ invariant then $W^{\perp}$ is also $A$ invariant. What I do know is that if $W$ is $A$ invariant then $W^{\perp}$
is also $A^*=A^{t}$ invariant, but I could not deduce from this that
it is also $A$ invariant. Is this 'fact' true ? I couldn't prove it (I tried writing a proof
similar to the case I know, using inner products and failed), help is appreciated!","['matrices', 'linear-algebra', 'inner-products']"
170710,Find a function that satisfies the following five conditions.,"My task is to find a function $h:[-1,1] \to \mathbb{R}$ so that (i) $h(-1) = h(1) = 0$ (ii) $h$ is continuously differentiable on $[-1,1]$ (iii) $h$ is twice differentiable on $(-1,0) \cup (0,1)$ (iv) $|h^{\prime\prime}(x)| < 1$ for all $x \in (-1,0)\cup(0,1)$ (v) $|h(x)| > \frac{1}{2}$ for some $x \in [-1,1]$ The source I have says to use the function $h(x) = \frac{3}{4}\left(1-x^{4/3}\right)$ which fails to satisfy condition (iv) so it is incorrect. I'm starting to doubt the validity of the problem statement because of this. So my question is does such a function exist? If not, why? Thanks!","['real-analysis', 'analysis']"
170724,Is there a simple method to prove that the square of the Sorgenfrey line is not normal?,Is there a simple method to prove that the square of the Sorgenfrey line is not normal? The method in the book is a little complex. Could someone help me?,"['general-topology', 'separation-axioms', 'sorgenfrey-line', 'product-space']"
170725,Do we have always $f(A \cap B) = f(A) \cap f(B)$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Suppose $A$ and $B$ are subsets of a topological space and $f$ is any function from $X$ to another topological space $Y$. Do we have always $f(A \cap B) = f(A) \cap f(B)$? Thanks in advance","['examples-counterexamples', 'elementary-set-theory', 'functions']"
170731,Shortest distance between two shapes,"This is the scenario of my problem. I have an image of two objects ( of arbitrary shape , not convex , not touching or crossing each other , kept a few space apart ). And I am supposed to find the shortest distance between these two shapes . First thing that came to my mind was to use bruteforce methods , ie find all the elements of shape A's perimeter (Let it be set X) and same for B's perimeter (Let it be Y ). Then find distance between all possible combinations ( excluding repetitions) of elements of X and Y and take the minimum value in it. But I am sure it will take a lot of time . Is there any other better way to do this ?","['optimization', 'geometry', 'algorithms']"
170737,About the inverse of the Jacobian matrix,"I have a doubt on Jacobian matrices. Consider the non linear transformation $$
\left[
\begin{array}{c}
x\\
y\\
z
\end{array}\right]
 = \mathbf{G}\left(
 \left[
\begin{array}{c}
\hat{x}\\
\hat{y}\\
\hat{z}
\end{array}\right]
\right) = 
 \left[
\begin{array}{c}
\hat{x}g(\hat{z})\\
\hat{y}g(\hat{z})\\
\hat{z}
\end{array}\right]
$$
whose Jacobian reads $$
\text{J} = 
\left[
\begin{array}{ccc}
g & 0 & \hat{x}g'\\
0 & g & \hat{y}g'\\
0 & 0 & 1
\end{array}
\right]
$$ If I invert this matrix I get $$
\text{J}^{-1} = 
\left[
\begin{array}{ccc}
1/g & 0 & -\hat{x}g'/g\\
0 & 1/g & -\hat{y}g'/g\\
0 & 0 & 1
\end{array}
\right]
$$
which I thought should be the same as the Jacobian of the inverse transformation. However, solving for $\hat{x}, \hat{y}, \hat{z}$ in the definition of the transformation, I get $$
\left[
\begin{array}{c}
\hat{x}\\
\hat{y}\\
\hat{z}
\end{array}\right]
 = \mathbf{G}^{-1}\left(
 \left[
\begin{array}{c}
x\\
y\\
z
\end{array}\right]
\right) = 
 \left[
\begin{array}{c}
x/g(z)\\
y/g(z)\\
z
\end{array}\right]
$$
whose Jacobian now reads $$
\text{J}^{-1} = 
\left[
\begin{array}{ccc}
1/g & 0 & -\hat{x}g'/g^2\\
0 & 1/g & -\hat{y}g'/g^2\\
0 & 0 & 1
\end{array}
\right]
$$
which is slightly different. My question is: which one is the correct Jacobian for the inverse? Weren't they supposed to be the same? If so, where's my mistake? Thank you in advance!",['multivariable-calculus']
170743,"Inclusion of $\mathbb{L}^p$ spaces, reloaded","I have a follow-up from this question . It was proved that, if $X$ is a linear subspace of $\mathbb{L}^1 (\mathbb{R})$ such that: $X$ is closed in $\mathbb{L}^1 (\mathbb{R})$; $X \subset \bigcup_{p > 1} \mathbb{L}^p (\mathbb{R})$, then $X \subset \mathbb{L}^p (\mathbb{R})$ for some $p>1$. I was wondering whether one could find a subspace $X$ satisfying these hypotheses and which is infinite-dimensional. It turns out this is possible. If one chooses a bump function, and considers the closure for the $\mathbb{L}^1 (\mathbb{R})$ norm of the space generated by the translates by integers of this bump function, one can emulate the $\ell^1$ space. The resulting $X$ will be closed, and included in $\mathbb{L}^p (\mathbb{R})$ for all $p>0$. To avoid this phenomenon, I'll restrict myself to smaller spaces. Is there a linear, closed, infinite-dimensional subspace $X$ of $\mathbb{L}^1 ([0,1])$ which is included in $\mathbb{L}^p ([0,1])$ for some $p>1$? The problem is that any obvious choice of countable basis will very easily generate all of $\mathbb{L}^1 ([0,1])$ (polynomials, trigonometric polynomials...), or $\mathbb{L}^1 (A)$ for some $A \subset [0,1]$, or at least one function which is in $\mathbb{L}^1$ but not in $\mathbb{L}^p$ for $p>1$...","['functional-analysis', 'banach-spaces']"
170746,Convention on non-negative singular values?,"In the literature I have on disposal it is stated that singular values are non-negative values, and that, for a symmetric matrix $A$, the SVD and EVD coincide. This would mean that singular values of $A$ are the eigenvalues of $A$, but the eigenvalues of $A$ can be negative, regardless of $A$ being symmetric. So, I wonder if the choice of singular values being exclusively positive is some kind of convention? If so, how degenerate that is given the above observation the equivalence of SVD and EVD for symmetric matrices?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
170747,"""Sum equals integral"" identities similar to $\int_0^1 \frac{dx}{x^x} = \sum_{n = 1}^{\infty} \frac{1}{n^n}$","It is quite a well known fact that: $$\int_0^{+\infty} \frac{\sin x}{x} \, dx = \frac{\pi}{2}$$ also the value of related series is very similiar: $$\sum_{n = 1}^{+\infty} \frac{\sin n}{n} = \frac{\pi - 1}{2}$$ Combining these two identities and using ${\rm sinc}$ function we get: $$\int_{-\infty}^{+\infty} {\rm sinc}\, x \, dx = \sum_{n = -\infty}^{+\infty} {\rm sinc}\, n = \pi$$ What is more interesting is the fact that the equality: $$\int_{-\infty}^{+\infty} {\rm sinc}^k\, x \, dx = \sum_{n = -\infty}^{+\infty} {\rm sinc}^k\, n$$ holds for $k = 1,2,\ldots, 6$ . There are some other nice identities with ${\rm sinc}$ where sum equals integral but moving on to other functions we have e.g.: $$\sum_{n = -\infty}^{+\infty} \binom{\alpha}{n} e^{int} = \int_{-\infty}^{+\infty} \binom{\alpha}{x} e^{itx} \, dx = (1+e^{it})^\alpha, \; \alpha  >-1$$ which is due to Pollard & Shisha. And finally the identity which is related to the famous Sophomore's Dream : $$\int_0^1 \frac{dx}{x^x} = \sum_{n = 1}^{+\infty} \frac{1}{n^n}$$ Unfortunately in this case the summation range is not even close to the interval of integration. Do you know any other interesting identities which show that ""sum = integral""?","['sequences-and-series', 'integration']"
170749,How to prove convergence of polynomials in $e$ (Euler's number),"These polynomials in $e$ converge to 2$$f(i)=e^i - i \sum_{k=1}^{i-1}\frac{(i-k)^{k-1}{e^{i-k}}{(-1)^{k+1}}}{k!}, \text{ where } i>1$$ This function goes to 2. I've calculated this with sage math tool . $$f(\infty) = 2$$
for example,
$$f(2)=e^2-2e=1.95249244... $$
$$f(3)=e^3-3e^2+\frac{3}2e=1.99579136... $$
$$f(4)=e^4-4e^3+4e^2-\frac{2}3e=2.000038... $$
$$...$$
$$f(10)=\newcommand{\Bold}[1]{\mathbf{#1}}-\frac{1}{36288} \, e + \frac{2}{63} \, e^{2} - \frac{81}{56} \, e^{3} + \frac{128}{9} \, e^{4} - \frac{625}{12} \, e^{5} + 90 \, e^{6} - \frac{245}{3} \, e^{7} + 40 \, e^{8} - 10 \, e^{9} + e^{10} = 2.00000000...$$ Isn't this interesting? These polynomials in e (2.71828182845904523536...) converge to 2. However , I have no idea how to mathematically prove this . I guess this would have been already proved, but I have no idea where I can find the proof. I would greatly appreciate it if you can give me some tips or the proof of this convergence. For more information, this function $f(i)$ is from a different function $h_i(x),\text{ when } x = 1$ of an original problem $$ f(i) = h_i(1)$$
so proving the convergence of the above polynominals will be the same as proving $h_\infty(1) = 2$ I have recently found that the general form of $h_i(x)$ function 
$$h_i(x) = (-1)^{i+1} e^x \left[\frac{1}{(i-1)!}{x}^{i-1} - \sum_{k=1}^{i-1}\left(Î±(k)\frac{{x}^{i-1-k}(-1)^{k+1}}{(i-1-k)!}\right)\right] - Î±(i-1),$$
where 
$$Î±(j) = \sum_{k=0}^{j-1}\frac{(j-k)^k}{k!}e^{j-k}(-1)^k$$ update list I have found this: $ f(i)=Î±(i)âÎ±(iâ1) $ I have found a new property of $Î±(i)$, when $i > 1$, 
$$ Î±(i) = \sum_{k=0}^{i-2} \left( e \space Î±(k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) + \frac{(-1)^{i+1} \space e}{(i-1)!},$$
where $Î±(1) = e$.","['power-series', 'convergence-divergence', 'sequences-and-series', 'proof-writing']"
170761,Counting zero-digits between 1 and 1 million,"I just remembered a problem I read years ago but never found an answer: Find how many 0-digits exist in natural numbers between 1 and 1 million. I am a programmer, so a quick brute-force would easily give me the answer, but I am more interested in a pen-and-paper solution.","['discrete-mathematics', 'combinatorics']"
170764,Geometric or intuitive proof of the symmetry of second partial derivatives,"What was given in my calc book is a ""consider the function"" proof. That is, the author gives a function out of the blue and would deduce all the nice properties from it. I'd prefer a proof which is motivated (perhaps, intuitive) - you see how the proof is crafted in the mind of the person. So my question is a geometric or intuitive proof of $$\frac{\partial ^2 f}{\partial x \, \partial y} = \frac{\partial^2 f}{\partial y \, \partial x}$$",['multivariable-calculus']
170765,A maximal system of hyperreal numbers,"Let $( \mathbb{R}^\mathbb{N}/\mathcal{U} )_{\mathcal{U}\in\beta\mathbb{N}}$ be the set of all the hyperreal number systems, does there exist a set $\mathbb{X}%$ and embeddings $i_{\mathcal{U}}: \mathbb{R}^\mathbb{N}/\mathcal{U} \hookrightarrow \mathbb{X}$ for all $\mathcal{U} \in \beta\mathbb{N}$ ? If so, does anybody know about the (topological, algebraic, analytic) structure of such a structure $\mathbb{X}$ ? Edit: Chris Eagle suggested to look at $\bigcup_{\mathcal{U}\in\beta\mathbb{N}} \mathbb{R}^\mathbb{N}/\mathcal{U}$. This set obviously has the properties I am so bluntly asking for, but I want some more structure. Something like the construction of the maximal exotic $\mathbb{R}^4$, in which every exotic one embeds, allthough this isn't a union of all the exotic $\mathbb{R}^4$'s (not that I am aware of). I am looking for a way, is essence, to ""ditch"" the ultrafilter in the definition, but I don't think this is so easy to get rid of, then.","['general-topology', 'set-theory', 'nonstandard-analysis', 'number-theory']"
170780,Does $\sum_{n\ge1} \sin (\pi \sqrt{n^2+1}) $ converge/diverge?,"How would you prove convergence/divergence of the following series? $$\sum_{n\ge1} \sin (\pi \sqrt{n^2+1}) $$ I'm interested in more ways of proving convergence/divergence for this series. Thanks. EDIT I'm going to post the solution I've found here: $$a_{n}= \sin (\pi \sqrt{n^2+1})=\sin (\pi (\sqrt{n^2+1}-n)+n\pi)=(-1)^n \sin (\pi (\sqrt{n^2+1}-n))=$$
$$ (-1)^n \sin \frac{\pi}{\sqrt{n^2+1}+n}$$
The sequence $b_{n} = \sin \frac{\pi}{\sqrt{n^2+1}+n}$ monotonically decreases to $0$. Since our series is an alternating series then it converges.","['sequences-and-series', 'calculus', 'convergence-divergence', 'trigonometry', 'real-analysis']"
170782,Exercise about expressing grad f(x) in another basis.,"I'm having difficulties with this exercise (from Elon LIMA's Curso de AnÃ¡lise , Vol. 2): $f:U\longrightarrow\mathbb{R}$ is function, differentiable on the open set $U\subset\mathbb{R}^n$. Let $\{v_1,...,v_n\}$ be an arbitrary basis of $\mathbb{R}^n$ and $g^{ij}:=\left<v_i,v_j\right>$. Show that grad$f(x)$ in this basis is $$\textrm{grad} f(x) = \sum_i(\sum_j g^{ij}\frac{\partial f}{\partial v_j})v_i$$ where $\frac{\partial f}{\partial v_j}$ is the directional derivative of $f$ along the vector $v_j$. I tried starting with the RHS with $\frac{\partial f}{\partial v_j}=\left<\textrm{grad}f(x),v_j\right>$ and arriving at $\sum_i \left<\textrm{grad}f(x),e_i\right>e_i $ which is the ""canonical"" (see Note below) expression for the grad; writing each $v_i$ as $v_i=\sum_j \left<v_i,e_j\right>$ I come down to a sum of the form $\sum_{i,j}\left<v_j,e_k\right>g^{ji}\left<v_i,e_l\right>$ which I don't recognize and doesn't seem to simplify. Am I approaching it incorrectly? How must this problem be tackled? I'm obviously missing something, or misinterpreting things. NOTE: In the textbook, grad$f(x)$ is defined as $\sum_i \frac{\partial f}{\partial x_i}(x)e_i$ where $\frac{\partial f}{\partial x_i}(x)$ is the usual i -th partial derivative at the point $x$.","['multivariable-calculus', 'calculus', 'linear-algebra', 'real-analysis', 'analysis']"
170788,Separated schemes and unicity of extension,"In point set topology, we have the following result, which is easily proved. Theorem. Let $Y$ be Hausdorff space and $f,g:X \to Y$ be continuous functions. If there exists a set $A\subset X$ such that $\bar{A} = X$ and $f|_A = g|_A$, then $f=g$. I was trying to understand what would be the natural generalization of this fact in the category of schemes. We know that the correct analogous of a Hausdorff space is a separated scheme. So I was thinking in a statement like this: ""Let $Y$ be a separated scheme and $f,g:X \to Y$ be morphisms of schemes. If there exists a set $A\subset X$ such that $\bar{A} = X$ and $f|_A = g|_A$, then $f=g$."" The first problem is that we must be careful with this restriction ""$f|_A$"", since $f$ is a morphism and I want to consider the morphism of sheaves also. Then I saw that Liu's book on Algebraic Geometry has the following statement: ""Let $Y$ be a separated scheme, $X$ a reduced scheme, and $f,g:X \to Y$ morphisms of schemes. If there exists a dense open subset $U$ such that $f|_U=g|_U$, then $f=g$."" Now this makes sense, since we are dealing with open subsets now. But I still find this result too restrictive. So I came up with this: ""Let $Y$ be a separated scheme, $X$ a reduced scheme, and $f,g:X \to Y$ morphisms of schemes. If there exists a morphism $\varphi:S \to X$ such that $\varphi(S)$ is dense in $X$ and $f\circ \varphi = g\circ \varphi$, then $f=g$."" It's easy to see that Liu's proof of the result concerning only the open set also applies to this context. Finally, let's go to the questions: Is this really the best generalization? Is there any other results in this direction that are at least slightly different? I can see where the ""reduced"" hypothesis enters in the proof, but I found it a little strange. Is it just a technical point or can be ""understanded"" in some sense? Maybe counterexamples of this fact when this hypothesis isn't valid would help to clarify , but I didn't think of any. P.S. Sorry for the bad english.","['algebraic-geometry', 'schemes']"
170798,Is every algebraic curve birational to a planar curve,"Let $X$ be an algebraic curve over an algebraically closed field $k$. Does there exist a polynomial $f\in k[x,y]$ such that $X$ is birational to the curve $\{f(x,y)=0\}$? I think I can prove this using Noether Normalization Lemma. Is this correct? If yes, is it too much? That is, is there an easier argument?","['riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
170800,Higher direct image and local cohomology.,"Let $X$ be an scheme, $Z \subset X$ a closed subscheme, and $\mathcal{F}$ a coherent sheaf then, $\mathcal{R}^{i-1}_{j_{*}}(\mathcal{F}|_{X-Z})\cong\mathcal{H}_{Z}^{i}(X,\mathcal{F})$ I would like to see this isomorphism explicitly. Since I dont really understand how to see the elements of $H^i_Z(X,F)$. If it is possible, how can I see them in terms of Cech Cohomology?",['algebraic-geometry']
170803,convergence of alternating series â weakening a hypothesis,"A comment below this answer inspires this question. Suppose $a_n\in\mathbb{R}$ for $n=1,2,3,\ldots$ and $|a_n|\to0$ as $n\to\infty$. Further suppose the terms alternate in sign. If moreover the sequence $\{|a_n|\}_{n=1}^\infty$ is decreasing , then $\displaystyle\sum_{n=1}^\infty a_n$ converges. How much can the hypothesis that it is decreasing be weakened while still being strong enough that the sum must converge?  And are there any interesting or useful weaker hypotheses?",['sequences-and-series']
170853,Why is the inradius of any triangle at most half its circumradius?,"Is there any geometrically simple reason why the inradius of a triangle should be at most half its circumradius? I end up wanting the fact for this answer . I know of two proofs of this fact. Proof 1: The radius of the nine-point circle is half the circumradius. Feuerbach's theorem states that the incircle is internally tangent to the nine-point circle, and hence has a smaller radius. Proof 2: The Steiner inellipse is the inconic with the largest area. The Steiner circumellipse is the circumconic with the smallest area, and has 4 times the area of the Steiner inellipse. Hence the circumcircle has at least 4 times the area of the incircle. These both feel kind of sledgehammerish to me; I'd be happier if there were some nice Euclidean-geometry proof (or a way to convince myself that no such thing is likely to exist, so the sledgehammer is necessary). EDIT for ease of future searching: The internet tells me this is often known as ""Euler's triangle inequality.""","['geometry', 'triangles', 'euclidean-geometry']"
170858,A sequence with infinitely many radicals: $a_{n}=\sqrt{1+\sqrt{a+\sqrt{a^2+\cdots+\sqrt{a^n}}}}$ [duplicate],"This question already has answers here : Definition of convergence of a nested radical $\sqrt{a_1 + \sqrt{a_2 + \sqrt{a_3 + \sqrt{a_4+\cdots}}}}$? (2 answers) Closed 1 year ago . Consider the sequence $\{a_{n}\}$, with $n\ge1$ and $a>0$, defined as: $$a_{n}=\sqrt{1+\sqrt{a+\sqrt{a^2+\cdots+\sqrt{a^n}}}}$$ I'm trying to prove here 2 things: a). the sequence is convergent; b). the sequence's limit when n goes to $\infty$. I may suppose that there must be a proof for this general case. I saw this problem with the case $a=2$ (where it was required to prove only the convergence), but this is just a particular case. The generalization seems to be much more interesting.","['sequences-and-series', 'calculus', 'real-analysis']"
170871,Sobolev Spaces and Weak Derivatives,"As you can probably guess, I'm currently studying about differential operators and functional analysis. 
We've studied the following theorem: A function $f \in L^2 (\Omega) $ lies in $ W^{1,2} ( \Omega) $ if and only if there exists a function $g \in L^2 ( \Omega ) $ such that:
  $$\int_\Omega f \left\{ b_0 (x) \phi(x) - \sum_{i=1}^n \frac{ \partial(b_i (x) \phi(x)}{\partial x_i} \right\} d^n x = \int_\Omega g(x) \phi(x) d^n x $$ for every choice of functions $b_i (x) \in C^\infty (\bar{\Omega} ) $, and $\phi \in C_c^\infty (\Omega ) $ . Can someone help me use this theorem in order to prove that the function $f(x)= \frac{x_1}{|x|} $ is in $W^{1,2}( \{ x \in \mathbb{R} ^n : |x| <1 \} ) $? What should be my $g$ and how can I prove it? I really need your help ! Thanks  !","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations', 'analysis']"
170875,supremum norm and submultiplicativity,"If $f$, $g \in C(S)$ where $S$ is a compact set in $\mathbb{R}^n$ then it is true that $$\lVert fg \rVert \leq \lVert f \rVert \lVert g \rVert$$
where the norm is the usual supremum norm. 
Why is this not true if $S$ is not compact? What other conditions can $S$ satisfy so that this is true?","['normed-spaces', 'analysis']"
170885,A little integration paradox,"The following integral can be obtained using the online Wolfram integrator : $$\int \frac{dx}{1+\cos^2 x} = \frac{\tan^{-1}(\frac{\tan x}{\sqrt{2}})}{\sqrt{2}}$$ Now assume we are performing this integration between $0$ and $2\pi$. Hence the result of the integration is zero. On the other hand when looking at the integrand, $\displaystyle \frac{1}{1+\cos^2 x}$, we see that it is a periodic function that is never negative. The fact that it is never negative guarantees that the result of the integration will never be zero (i.e., intuitively there is a positive area under the curve). What is going on here?","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
170891,Why doesn't $2\pi\int_{-1}^1\sqrt{1-x^2}dx$ give the surface area of a sphere of radius $1$? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Areas versus volumes of revolution For fun I decided to derive the surface area of a sphere of radius $1$ from the formula for the perimeter of a circle.  This integral is what I came up with: $$2\pi\int_{-1}^1\sqrt{1-x^2}dx = \pi^2$$ Unfortunately the desired value is $4\pi$.  My rationale was simply to stack infinitely thin 'hula-hoops' whose radii followed the curvature of the sphere.  I can't readily see where my conceptual misunderstandings are, can someone help elucidate them for me? Thanks.","['geometry', 'calculus']"
170896,Fourier Transform of a derivative + Bochner's theorem about positive definite functions,"I've been reading about Bochner's Theorem lately, but when I apply it to the derivative of a function, I seem to get a contradiction with the theorem. ""Bochner's theorem states that a
  positive definite function is the
  Fourier transform of a finite Borel
  measure. As well, an easy converse of
  this is that a Fourier transform must
  be positive definite. "" - source So consider $f(x) \in L^1 (\mathbb{R})$ where
$f(x) = \tfrac{1}{2} x^2$ if $-1 \leq x \leq 1$ and $0$ otherwise. Also consider $g(x) \in L^1 (\mathbb{R})$ where
$g(x) = 1$ if $-1\leq x \leq 1$ and $0$ otherwise. Now Bochner's theorem states that the Fourier transform of each of these functions should be positive definite. One well known property of Positive Definite functions $h(\xi)$ is that:
$h(0) \geq |h(x)|$
for all $x\in \mathbb{R}$. Now consider $\bar{g}$ and $\bar{f}$ the Fourier transforms of $g$ and $f$ respectively. 
Since $g(x)=f''(x)$ (a.e.) then
$\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$
implying 
$\bar{g}(0)=0$ By Bochner's Theorem we know $\bar{g}$ is positive definite, but then this implies that $\bar{g}$ is zero for all $\xi$. But one can see by the Fourier inversion theorem this would imply $g$ is zero a.e. Obviously this is a contradiction. I've been banging my head on this for days, can you let me know where the error in the reasoning is? I am wondering if there is a mistake in the statement '$\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$' or in my understanding of positive definite functions or in my use of Bochner's theorem. Thanks in advance! Note, I know my examples of f and g are discontinuous. If this is the problem, it isn't actually a problem in my situation, so if it helps, consider a smooth mollification of g and let f be the anti-derivative of its antiderivative. Thanks!","['complex-analysis', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
170907,The analogous generalization for the commutativity of unions.,"Let $\{I_j\}$ be a family of sets indexed by $J$ and let $$K=\bigcup_{j\in J}I_j$$ Then let $\{A_k\}$ be a family of sets indexed by $K$. The generalization of the associative law for unions is that $$\bigcup_{k\in K}A_k=\bigcup_{j\in J}\left(\bigcup_{i\in I_j}A_i \right)$$ What I interpret this as is: ""To take the union over $K$, pick an $I_j \in K$, perform the union of all $A_i$ such that $i\in I_j$, and for each $j\in J$ unite all this possible unions to get $\bigcup_{k\in K}A_k$. What this is saying is that the order in which the $j$ and thus the $I_j$ are picked is of no importance in the ultimate union. The above is a generalization of $$(A\cup B)\cup C=A\cup (B\cup C)$$ How can I find the analogous generalization for $$A \cup B=B \cup A?$$",['elementary-set-theory']
170925,Solving  $\cos^2 \theta + \cos \theta = 2$,Solve the following for $\theta$: $\cos^2 \theta + \cos \theta = 2$  [Hint: There is only one solution.] I started this out by changing $\cos^2\theta$ to $\dfrac{1+\cos(2\theta)}{2}+\cos\theta=2$ $1+\cos(2\theta)$ turns into $1+\cos^2\theta-\sin^2\theta$ which all becomes; $\dfrac{1+\cos^2\theta-\sin^2\theta}{2}+\cos\theta=2$ Not to sure what to do after this. I was going to try a power reducing rule for $\sin^2\theta$ but that would make $\dfrac{1+\cos^2\theta- \left(\frac{1-\cos(2\theta)}2 \right)}2+\cos\theta=2$. Please do help.,['trigonometry']
170931,Find a big-O estimate for $f(n)=2f(\sqrt{n})+\log n$,"While self-studying Discrete Mathematics, I found the following question in the book ""Discrete Mathematics and Its Applications"" from Rosen: Suppose the function $f$ satisfies the recurrence relation $f(n)=2f(\sqrt{n})+\log n$ whenever $n$ is a perfect square greater than 1 and $f(2)=1$ . Find a big-O estimate for $f(n)$ [ Hint : Make the substitution $m=\log n$ .] ( Note : here, $\log n$ stands for base 2 logarithm of $n$ .) In this solution, I am supposed to use the following variant of the Master Theorem: Master Theorem . Let $f$ be an increasing function that satisfies the recurrence relation $$f(n)=af(n/b)+cn^d$$ whenever $n=b^k$ , where $k$ is a positive integer, $a\geq 1$ , $b$ is an integer greater than 1, and $c$ and $d$ are real numbers with $c$ postive and $d$ nonnegative. Then $$\begin{align}f(n)&\text{is }\begin{cases} O(n^d)&\text{ if $a < b^d$,} \\ O(n^d\log n)&\text{ if $a = b^d$,} \\ O(n^{\log_b a})&\text{ if $a > b^d$.} \end{cases}\end{align}$$ I solved it as follows, but I'm not sure if this is correct: Following the hint given, I made the substitution $m = \log n$ . Then, $n=2^m$ . Rewriting the recurrence relation with this value for $n$ : $$f(2^m)=2f(\sqrt{2^m})+\log (2^m)\text{ with }f(2)=1$$ $$f(2^m)=2f(2^{m/2})+m\text{ with }f(2)=1$$ (because $\sqrt{2^m}=2^{m/2}$ and $\log (2^m)=m$ .) To simplify the analysis, I will rewrite the recurrence relation above for $T(m)=f(2^m)$ : $$T(m)=2T(\dfrac{m}{2})+m\text{ with }T(1)=1$$ Now I will apply the Master Theorem for $T(m)$ . In this case, $d=1$ , $b=2$ and $a=2$ , this recurrence relation meets the condition $a=b^d$ in the Master Theorem; therefore: $$T(m)\text{ is }O(m^d\log m)=O(m\log m)$$ Now I will rewrite the estimate above in terms of $f(n)$ , substituting $T(m)=f(2^m)=f(2^{\log n})=f(n)$ and $m=\log n$ : $$f(n)\text{ is } O(\log n\log \log n)$$ Is this solution correct? If yes, is there any way to simplify it further?","['asymptotics', 'recurrence-relations', 'discrete-mathematics']"
170933,Egoroff's theorem in Royden Fitzpatrick (comparison with lemma 10),"Hi math stackexchangers, I have a question about the difference between two math statements (for reference they can be found in Royden Fitzpatrick pages 64-65). Egoroff's Theorem: Assume $E$ has finite measure. Let $\{f_n\}$ be a sequence of measurable functions on $E$ that converges pointwise on $E$ to the real-valued function $f$. Then for each $\varepsilon > 0$, there is a closed set $F$ contained in $E$ for which
  $$\{f_n\} \to f\text{ uniformly on }F\text{ and }m(E \setminus F) < \varepsilon.$$ Lemma 10: Under the assumptions of Egoroff's Theorem, for each $\eta > 0$ and $\delta > 0$, there is a measurable subset $A$ of $E$ and an index $N$ for which
  $$|f_n - f| < \eta\text{ on }A\text{ for all }n \geq N
\text{ and }m(E \setminus A) < \delta.$$ My question is this. What is the difference between Egoroff's Theorem and Lemma 10? Am I misunderstanding uniform convergence? To me it looks like Lemma 10 provides uniform convergence. Is the difference that Egoroff's Theorem ensures that $F$ is closed but Lemma 10 doesn't ensure that $A$ is closed? Thanks",['measure-theory']
170936,Verifying some trigonometric identities: $\frac{\csc\theta}{\cot\theta}-\frac{\cot\theta}{\csc\theta}=\tan\theta\sin\theta$ [duplicate],"This question already has answers here : Proving that $\frac{\csc\theta}{\cot\theta}-\frac{\cot\theta}{\csc\theta}=\tan\theta\sin\theta$ (6 answers) Closed 7 years ago . Prove the following: 46. $\dfrac{\csc\theta}{\cot\theta}-\dfrac{\cot\theta}{\csc\theta}=\tan\theta\sin\theta$ I got as far as Right Side:   $\tan\theta\sin\theta$ to $\dfrac{\sin\theta}{\cos\theta}\dfrac{\sin\theta}{1}$ and then; $\dfrac{\sin^2\theta}{\cos\theta}$ Left Side: 
$$\begin{align*} 
 \dfrac{\csc\theta}{\cot\theta}-\dfrac{\cot\theta}{\csc\theta}
&= \dfrac{\frac{1}{\sin^2\theta}-{\frac{\cos^2\theta}{\sin^2\theta}}}{\frac{\cos\theta}{\sin\theta}-{\frac{1}{\sin^2\theta}}}\\
&= \dfrac{\frac{1-\cos^2\theta}{\sin^2\theta}}{\frac{\cos\theta}{\sin^2\theta}}\\
&= \dfrac{\frac{\sin^2\theta}{\sin^2\theta}}{\frac{\cos\theta}{\sin^2\theta}}\\  
&= \frac{1}{\frac{\cos\theta}{\sin^2\theta}}\\
&= \frac{\sin^2\theta}{\cos\theta}
\end{align*}$$
Thanks a lot!",['trigonometry']
170948,Why use the derivative and not the symmetric derivative?,"The symmetric derivative is always equal to the regular derivative when it exists, and still isn't defined for jump discontinuities. From what I can tell the only differences are that a symmetric derivative will give the 'expected slope' for removable discontinuities, and the average slope at cusps. These seem like extremely reasonable quantities to work with (especially the former), so I'm wondering why the 'typical' derivative isn't taken to be this one. What advantage is there to taking $\lim\limits_{h\to0}\frac{f(x+h)-f(x)} h$ as the main quantity of interest instead? Why would we want to use the one that's defined less often?","['calculus', 'derivatives', 'functions']"
170953,Nontrivial subring with unity different from the whole ring?,"Is there an example of a ring $R$ with unity and a nontrivial subring $J$, such that $1_J \ne 1_R$?","['ring-theory', 'abstract-algebra']"
170958,$(\sin\theta+\cos\theta)^2=1+\sin2\theta$,"49)  $(\sin\theta+\cos\theta)^2=1+\sin2\theta$ Left Side: \begin{align*}
 (\sin\theta+\cos\theta)^2=\sin^2\theta+2c\cos\theta\sin\theta+cos^2\theta=1+2\cos\theta\sin\theta  
\end{align*}
This can either be $1$ or I can power reduce it. I don't know. Right Side: \begin{align*}
 1+\sin2\theta=1+2\sin\theta\cos\theta  
\end{align*} Thank you!",['trigonometry']
170964,The number of geodesics of a complete Riemann manifold with non-positive sectional curvature,"There is a theorem of Cartan which states that if $M$ is a simply connected, complete Riemann manifold, and that the sectional curvature is everywhere $\leq 0$ , then any two points of M are joined by a unique geodesic. So if we consider a Riemann manifold $M$ which is not simply connected, but is complete and has sectional curvature $\leq 0$ , we could use the above theorem of Cartan to the universal covering space $\widetilde{M}$ of $M$ . It says in the book: For it is clear that $\widetilde{M}$ inherits a Riemannian metric from $M$ which is geodesically complete, and has sectioanl curvature $\leq 0$ . Given two points $p,q \in M$ , it follows that each homotopy class of paths from p to q contains precisely one geodesic. My question is: How does the second sectence deduced from the sentence above? I know that any two points of $\widetilde{M}$ are joined by only one geodesic, but for any two points $p,q \in M$ , there are many lifted points of $p,q$ in $\widetilde{M}$ . Thank you!","['riemannian-geometry', 'differential-geometry']"
170983,"How to find the area of green region in terms of yellow, blue and red region in the following figure?","How to find the area of green region in terms of yellow, blue and red region in the following figure? The triangle is any random triangle and an arbitrary point $P$ is taken where all the colored regions coincide. The answer given is  $$G = \frac{BY(Y + B + 2R)}{R^2 - BY}$$ But I'm not able to find out. Please help.","['geometry', 'triangles']"
170984,Are commutative C*-algebras really dual to locally compact Hausdorff spaces?,"Several online sources (e.g. Wikipedia , the nLab ) assert that the Gelfand representation defines a contravariant equivalence from the category of (non-unital) commutative $C^{\ast}$-algebras to the category of locally compact Hausdorff (LCH) spaces. This seems wrong to me. The naive choice is to take all continuous maps between LCH spaces. This doesn't work. For example, the constant map $\mathbb{R} \to \bullet$ does not come from a morphism $\mathbb{C} \to C_0(\mathbb{R})$, the problem being that composing with the map $\bullet \to \mathbb{C}$ sending $\bullet$ to $1$ gives a function on $\mathbb{R}$ which doesn't vanish at infinity. It is necessary for us to restrict our attention to proper maps . But this still doesn't work. If $A, B$ are any commutative $C^{\ast}$-algebras we can consider the morphism
$$A \ni a \mapsto (a, 0) \in A \times B.$$ This morphism does not define a map on Gelfand spectra; if $\lambda : A \times B \to \mathbb{C}$ is a character factoring through the projection $A \times B \to B$, then composing with the above morphism gives the zero map $A \to \mathbb{C}$. This contradicts the nLab's claim that taking Gelfand spectra gives a functor into locally compact Hausdorff spaces (if one requires that the morphisms are defined everywhere on the latter category). The correct statement appears to be that commutative $C^{\ast}$-algebras are contravariantly equivalent to the category $\text{CHaus}_{\bullet}$ of pointed compact Hausdorff spaces; the functor takes an algebra to the Gelfand spectrum of its unitization (we adjoin a unit whether or not the algebra already had one). There is an inclusion of the category of LCH spaces and proper maps into this category but it is not an equivalence because maps $(C, \bullet) \to (D, \bullet)$ in $\text{CHaus}_{\bullet}$ may send points other than the distinguished point of $C$ to the distinguished point of $D$. So do sources mean something else when they claim the equivalence with locally compact Hausdorff spaces?","['general-topology', 'operator-algebras', 'functional-analysis']"
170986,"Intuitively, why does $\lim_{n \to \infty} \frac16 (p_{n - 1} + p_{n - 2} ... + p_{n - 6}) = 2/7$?","Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 48, p 94. A fair die is rolled repeatedly, and a running total is kept (which is, at each time, the total of all the rolls up until that time). Let $p_n$ be the probability that the running total is ever exactly n (assume the die will always be rolled enough times so that the running total will eventually exceed n, but it may or may not ever equal n). (c) Give an intuitive explanation for the fact that $p_n \rightarrow  1/3.5 = 2/7 \quad as \quad n \rightarrow \infty$ . From p 17 in the publicly downloadable PDF of curbed solutions. (c)An intuitive explanation is as follows. The average number thrown by the die is (total of dots)/6, which is 21/6 = 7/2, so that every throw adds on an average of 7/2. We can therefore expect to land on 2 out of every 7 numbers, and the probability of landing on any particular number is 2/7. That's the line I don't get it, why we can transfer",['probability']
170994,Generating generalised Venn diagrams,"David McCandless of ""Information is Beautiful"" recently posted an image of the 7-set Venn diagram construction . What rules generate Venn diagrams for an arbitrary number of sets $k$?","['plane-curves', 'elementary-set-theory']"
171024,"How to evaluate $\int 1/(1+x^{2n})\,dx$ for an arbitrary positive integer $n$? [duplicate]","This question already has answers here : What is the primitive function of $\int 1/(x^{2n} +1)dx$? (3 answers) Closed last month . How to find $$\int\dfrac{dx}{1+x^{2n}}$$ where $n \in \mathbb N$ ? Remark When $n=1$ , the antiderivative is $\tan^{-1}x+C$ . But already with $n=2$ this is something much more complicated. Is there a general method?","['rational-functions', 'calculus', 'integration', 'indefinite-integrals']"
171073,"How to evaluate $\int_{-\infty}^\infty \frac{\cos x}{\cosh x}\,\mathrm dx$ by hand","How can I evaluate $$\int_{-\infty}^\infty \frac{\cos x}{\cosh x}\,\mathrm dx\quad\text{ and }\quad\int_0^\infty\frac{\sin x}{e^x-1}\,\mathrm dx\,?$$ Thanks in advance.","['improper-integrals', 'calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
171087,Prove that: $ \int_{0}^{1} \ln \sqrt{\frac{1+\cos x}{1-\sin x}}\le \ln 2$,"I plan to prove the following integral inequality: $$ \int_{0}^{1} \ln \sqrt{\frac{1+\cos x}{1-\sin x}}\le \ln 2$$ Since we have to deal with a convex function on this interval i thought of considering the area of the trapeze that can be formed if we unify the points $(0, f(0))$ and $(1, f(1))$, where the function $f(x) =\ln \sqrt{\frac{1+\cos x}{1-\sin x}}$,  but things are ugly even if the method itself isn't
complicated. So,
I'm looking for something better if possible.","['inequality', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
171096,If two sets have the same sum and xor are they necessarily the same?,"Let  $A = \{A_1, A_2, A_3, \cdots, A_n\}$  and $B = \{B_1, B_2, B_3,\cdots, B_n\}$.
where $A_i\in \mathbb{Z}$ and $B_i\in \mathbb{Z}$. Say, $$S_{1} = A_1 + A_2 + A_3 + \cdots + A_n = \sum_{i=1}^{n}{A_{i}} \\
     S_{2} = B_1 + B_2 + B_3 + \cdots + B_n = \sum_{i=1}^{n}{B_{i}}$$ And, $$X_1 = A_1 \oplus A_2 \oplus A_3 \oplus \cdots \oplus A_n = \bigoplus_{i=1}^{n}{A_{i}} \\
    X_2 = B_1 \oplus B_2 \oplus B_3 \oplus \cdots \oplus B_n = \bigoplus_{i=1}^{n}{B_{i}}$$ Where $\oplus$ is the XOR operator . If $S_{1} = S_{2}$ and $X_{1}=X_{2}$, does this imply that $A$ and $B$ contain the same set of integers?",['elementary-set-theory']
171113,"An homeomorphism between $\mathbb{R}-\mathbb{Q}$ and $(\mathbb{R}-\mathbb{Q})\cap (0,1)$?","Are $\mathbb{R}-\mathbb{Q}$ and $(\mathbb{R}-\mathbb{Q})\cap (0,1)$ homeomorphic? My claim is they are and I'm trying using this function:$$f:(\mathbb{R}-\mathbb{Q})\cap (0,1) \rightarrow (\mathbb{R}-\mathbb{Q})\cap (0,\infty)\;\;\;\; \;f(x)=\frac{1}{x}-1$$ which is a restriction of $g=1/x-1$. Proven this, then it would be easy to prove it for ($-\infty$,$+\infty$). So I think I now need to show that $f$ is well defined, which is true because $g$ transform rational numbers into rational and irrational into irrational. So $f$ is well defined, it's bijective, but is it continuous in the subspace topology? I believe it is using the same argument I exposed two lines above. Is my claim false, and/or the proof?",['general-topology']
171115,Why algebraic closures?,"Let me begin by summarizing the question: Why do we care about fields closed under rational exponentiation, and less about fields closed under other operations? Historically the solution for polynomials was important, and people were trying to find a good way to test when a certain polynomial has a root. This led to talking about algebraically closed fields, where polynomials have roots. I will particularly focus on the rationals from now on. How do we construct the rational numbers? We begin with $\{0,1\}$ and we say that if we add $1+1+\ldots+1$ we never have $0$ . We begin by closing this set under addition, then under subtraction and then under division. However we can consider the alternative, we iterate from $\{0,1\}$ and at every step we add solutions all four operations on the elements we have thus far, so the construction would go like: $\{0,1\}$ , we begin. Next we add additive inverse, a term for $1+1$ and multiplicative inverse for $1$ : $\{-1,0,1,2\}$ . Now we add the additive inverse for $2$ , the addition of $1+2$ , and multiplicative inverse for $2$ : $\{-2,-1,0,\frac12,1,2,3\}$ . Now we add the sums possible with the elements we have so far, the missing inverses, and so on: $\{-3,-2,-1\frac12,-1,-\frac12,0,\frac14,\frac13,\frac12,1,1\frac12,2\frac12,3,3\frac12,4,5\}$ . We continue ad infinitum. It is not very hard to see that any rational number is in this set, and that this set forms a field (indeed the rationals). Consider now the family of operations $\exp_q(x)=x^q$ defined for $x\geq 0$ and for a rational number $q$ . If we reiterate the above algorithm from $\mathbb Q$ and close it under $\exp_q(x)$ for positive $q$ we end up with a subfield of the real-closure of $\mathbb Q$ . The result, while not the entire real algebraic numbers, is radically closed. Any number in the field has a root of any rational order. If we only take closure under a limited collection $\exp_q$ functions we will get a subfield of this field (e.g. close only under $\exp_{0.5}$ ). Consider now the Sine-closure of $\mathbb Q$ : $Q_0=\mathbb Q$ , we begin with the rationals. $Q_1=Q_0\cup\{\sin(x)\mid x\in Q_0\}$ , the rationals were closed under field operations, so we only need to add $\sin$ 's. $Q_2$ is the collection of all sums and multiplication of pairs from $Q_1$ , adding additive and multiplicative inverses, and adding $\sin(x)$ for $x\in Q_1$ . $Q_3$ constructed the same. We finish by taking $\mathbb Q_{\sin}=\bigcup_{n=0}^\infty Q_n$ . This is a field which extends $\mathbb Q$ and is closed under the function $\sin$ . This field contains transcendental elements and is countable, so it is a non-algebraic subfield of $\mathbb R$ . So why are we mostly interested in algebraically closed fields, and not in fields like the Sine-closure of $\mathbb Q$ (or perhaps other construction similar to this one)? Is the reason historical, is it because algebra and analysis are somewhat disjoint in their purposes and analysis takes $\mathbb{R,C}$ to begin with?","['soft-question', 'abstract-algebra', 'field-theory']"
