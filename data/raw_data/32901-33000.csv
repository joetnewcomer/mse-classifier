question_id,title,body,tags
313169,How do I prove that a function is well defined?,"How do you in general prove that a function is well-defined? $$f:X\to Y:x\mapsto f(x)$$ I learned that I need to prove that every point has exactly one image. Does that mean that I need to prove the following two things: Every element in the domain maps to an element in the codomain: $$x\in X \implies f(x)\in Y$$ The same element in the domain maps to the same element in the codomain:
$$x=y\implies f(x)=f(y)$$ At the moment I'm trying to prove this function is well-defined: $$f:(\Bbb Z/12\mathbb Z)^∗→(\Bbb Z/4\Bbb Z)^∗:[x]_{12}↦[x]_4 ,$$ but I'm more interested in the general procedure.","['logic', 'proof-writing', 'functions']"
313195,How to construct pseudospherical surfaces from sine-Gordon solutions?,"Due to my not being very skilled in differential geometry, I want to ask if there is a reference (book, paper, etc.) that explicitly works out how one constructs the parametric equations of a pseudospherical surface from a given solution of the sine-Gordon equation (or Bäcklund transformations of those solutions). My searches are only turning up links between sine-Gordon solutions and pseudospherical surfaces, but I have not been able to find an explicit demonstration of how one derives the parametric equations from a soliton solution (or more likely it is my searching skills that are as sub-par as my differential geometry aptitude). As an example of what I want to see, consider the following form of SGE: $$w_{tu}=\sin w$$ One of the simplest solutions to this form of the SGE is $$w(t,u)=4\arctan\exp\left(at+\frac{u}{a}\right)$$ I am told that from this solution, one could obtain the parametric equations of either of the pseudosphere proper, or Dini's surface, depending on the value of the arbitrary constant $a$. I gather that the particular parametric equations for the Dini surface (formulas 1-3 here ) and the pseudosphere (formulas 5-7 here ) were obtained from the expression for $w$, but it is not immediately obvious to me how to go about the derivation. I will appreciate either being pointed to references, or if somebody might want to write out the explicit derivation for a non-expert like me. Thank you!","['surfaces', 'partial-differential-equations', 'differential-geometry']"
313215,"Deriving equations for the ""Bianchi-Pinkall torus""","I am trying to work out explicit parametric equations for the ""Bianchi-Pinkall flat torus"" as depicted in this note , but I seem to have gotten stuck in understanding the descriptions given in that note. Thus far, I figured that the parametric equations in $\mathbb R^4$ should look like this: $$\begin{align*}
x_1&=\cos(a+b\sin(2p v))\cos(u+v)\\
x_2&=\cos(a+b\sin(2p v))\sin(u+v)\\
x_3&=\sin(a+b\sin(2p v))\cos(u-v)\\
x_4&=\sin(a+b\sin(2p v))\sin(u-v)
\end{align*}$$ where I changed $aa$ in the note to $a$ here, and respectively $bb$ to $b$, and $ee$ to $p$. I have gotten stuck on the part that says that to obtain the $\mathbb R^3$ embedding, one should stereographically project this torus from the point $(\cos c\pi,0,\sin c\pi,0)$, as well as on the part about varying a parameter $ff$ from $0$ to $2\pi$, as this parameter is nowhere to be found in the parametric equations given. I am familiar with the usual ""north pole"" stereographic projection, $$\left(\frac{x_1}{1-x_4},\frac{x_2}{1-x_4},\frac{x_3}{1-x_4}\right)$$ but I do not know how to generalize this formula to the projection point given in the note. In particular I wanted to replicate the surface depicted here in another surface plotting program, but I have been unsuccessful in doing so. Thanks for any help.","['surfaces', 'differential-geometry']"
313225,An unusual combination lock problem,"Suppose there's a 4-digit combination padlock and you're asked to open it. But this lock has an unique defect in a way that the four digits need not be in the correct order for it to open. For example, if the right key is 0-1-2-3 , combinations such as 3-2-1-0 , 2-0-1-3 or any other orderings of 0, 1, 2, 3 are sufficient to crack it open. How many tries does it take to open this lock with brute force? What is the best strategy to ensure the least number of tries? (edit) Yes, let's assume repetition of digits is allowed.","['permutations', 'combinatorics']"
313227,Integration theory,"Any help with this problem is appreciated. Given the $f$ is measurable and finite a.e. on $[0,1]$. Then prove the following statements $$ \int_E f = 0 \text{ for all measurable $E \subset [0,1]$ with $\mu(E) = 1/2$ }\Rightarrow f = 0 \text{ a.e. on } [0,1]$$
$$ f > 0 \text{ a.e. } \Rightarrow \inf ~ \left\{\int_E f : \mu(E) \geq 1/2\right\} > 0 $$","['measure-theory', 'integration', 'real-analysis']"
313249,Showing that $(A_{ij})=\left(\frac1{1+x_i+x_j}\right)$ is positive semidefinite,"Consider the matrix $A$ whose coefficients are $A_{ij} = \frac{1}{1+x_i+x_j} $ where we have 
$ x_i \geq 0$ and $ x_j \geq 0$  for $ i,j=1,2,\dots,n$. 
How can I prove that this matrix is positive semidefinite for arbitrary $n$? Using first principal minors, I proved that this is positive semi-definite for $n=2$ but I could not generalize it.","['positive-definite', 'inner-products', 'matrices', 'linear-algebra', 'positive-semidefinite']"
313250,Retarded Functional Differential Equation,"I would like some help understanding the proof of lemma 6.1 given here , for the case of an autonomous Retarded Functional Differential Equation (RFDE). The problem for the autonomous case (In the proof of the book, drop the dependence on $t$ in the first component and suppose $\sigma=0$) is as follows. Background: Suppose $r$ is fixed. Let $C=C([-r,0],\mathbb{R})$. An autonomous RFDE is a differential equation of the form $$x'(t)=f(x_t)$$ where $x_t \in C$ defined by $x_t(\theta)=x(t+\theta)$ for $\theta \in [-r,0]$. $f$ is a continuous function from $C$ to $\mathbb R$. Given an initial function $\phi \in C$ suppose there exists a function $x \in C[-r,A)$ such that $x_0=\phi$ and $x$ satisfies the RFDE given above. Then $x$ is called a solution of the RFDE with initial function $\phi$. In such a case when there is a unique solution of the RFDE, define the solution map $T_t:C\to C$ by $T_t(\phi)=x_t$, where $x$ is the solution of the RFDE with initial function $\phi$. Question Show that $T_t$ is locally completely continuous. That is for every $\phi \in C$ there is a neighbourhood $V_t$ of $\phi$ such that $T_t(V_t)$ is contained in a compact set of $C$. What I don't understand in the proof is how they conclude that there is a nbd $V_t$ of $\phi$ and a constant $M$ such that $|T_\tau V_t|_C \leq M$ and $|f(T_\tau V_t)|<M$ for all $0 \leq \tau \leq t$ ? How does one get such $V_t$ and $M$ that is uniform for all $0 \leq \tau \leq t$. If someone with some experience in this area reads the question, I would appreciate it if you can suggest me some references to learn about Autonomous RFDE's.","['ordinary-differential-equations', 'functional-analysis']"
313252,Schwarz Reflection Principle -- Mapping across horizontal lines,"I am stuck on the following problem: Suppose an entire function maps two horizontal lines onto two other horizontal lines. Prove that its derivative is periodic. The author supplies a hint: Assume $f = u+iv$ maps the lines $y=y_1$ and $y=y_2$ onto $v=v_1$ and $v=v_2$ with $y_2-y_1 = c$ and $v_2-v_1 = d$. Show then that $f(z+2ci)+f(z)+2di$ for all $z$. I am trying to apply the Schwarz reflection principle to solve this problem. What I've done so far: If we let $\gamma$ be the analytic arc given by the first line, $x+iy_1$. Then, the reflection of $x+iy_2$ over $\gamma$ is $x+i(y_1-c)$, or $$w = \gamma(x+ic) = x+i(y_1+c) = x+iy_2 \\
w^* = \gamma(x-ic) = x+i(y_1-c).$$ Now, what we want is that $f(z+2ci) = f(z)+2di$. Take $z = w^*$, so $z+2ci = w$. Then, we have $f(z+2ci) = f(w) = f(w^*) + 2di$. Then, we need to compute $f(w^*)$ and show that it is equal to the reflection of the image of $w$ under $f$ over $\lambda := f(\gamma) = u+iv_1$. But I'm stuck on where to go from here. Is this even the right approach? I'm taking it for a specific $z$... clearly this can't work for all $z$...",['complex-analysis']
313259,Solve $x^2+x+7 \equiv 0\pmod{81}$,"Solve $x^2+x+7\equiv 0 \pmod{81}$ My work: Prime factorization $81 = 9^2 = 3^4$ Test the value $x\equiv0,1,2$ for $x^2+x+7\equiv0\mod{3}$ we have $x\equiv1\mod{3}$ works. Now life this to $\mod{3^2} = \mod{9}$ Let $x=1+3k$ for some integer$k$ $(1+3k)^2 + (1+3k) +7 \equiv0\mod{9}$ $1+6k+0+1+3k+7\equiv0\mod{9}$ $9+9k\equiv0\mod9$ $1+k\equiv0\mod9$ $k\equiv-1\mod9$ $k=-1+9m$ for some integer m Lift again to $\mod81$ $(-1+9m)^2 + (-1+9m)+7\equiv0\mod81$ $-9m+7\equiv0\mod81$ I cant continue... how can I make it work??? thanks!!","['modular-arithmetic', 'elementary-number-theory', 'number-theory']"
313284,Why is a matrix of indeterminates diagonalizable?,"Fix $n^2$ indeterminates $t_1,\dots, t_{n^2}$. Let $A$ be the algebraic closure of $\mathbb C(t_1,\dots, t_{n^2})$. Consider the $n\times n$ matrix over $A$ whose entries are precisely $t_1, t_2,\dots, t_{n^2}$. Why is this diagonalizable? I feel I am missing something obvious. My motivation for asking this question comes from a comment on this Mathoverflow answer , which gives a slick proof of the Cayley-Hamilton theorem. I will try to fill in the details; please alert me if there is a gap. If we know this is true, then since the Cayley-Hamilton theorem is easy to verify for diagonalizable operators, we know the matrix $M$ above annihilates its characteristic polynomial. If the characteristic polynomial over $A$ is $p(T)$, then we know that $P(M)=0$. In particular, each entry of $P(M)$ is $0$. But each entry is a polynomial in the indeterminates, which we just saw equals $0$. So no matter which values of $\mathbb C$ we put in for the $t_i$, each entry must vanish. This means every matrix over $\mathbb C$ annihilates its characteristic polynomial. Maybe there is a more elegant way to finish; my justification seems inadequate, but I can't quite put my finger on why. I would appreciate any comments on this, too. Thank you.","['linear-algebra', 'cayley-hamilton']"
313335,How to compute a matrix for rotating and centering rectangle in viewport?,"I have a rectangle given by 4 points. I'm trying to compute a transformation matrix such that the rectangle will appear straight and centered within my viewport. I'm not even sure where to begin. If we take the top left point to be $p0$, and work clockwise, $p1$ ... $p3$, then I think the angle of the rectangle can be computed with something like: $$
\theta = tan^{-1}(\frac{p1.y-p0.y}{p1.x-p0.x})
$$ Which I should then be able to use to rotate around the $z$ axis using this formula: But I'm still not sure how I get it to rotate around the center of the rectangle and then position and scale it correctly. In C# code, here's what I've got so far: var center = _drawingPoly.Aggregate((a, b) => a + b)/_drawingPoly.Count;

var r = _drawingPoly;
var rect = new SizeF(
    (_drawingPoly[1] - _drawingPoly[0]).Length,
    (_drawingPoly[0] - _drawingPoly[3]).Length
);

var cosT = (r[1].X - r[0].X) / rect.Width;
var sinT = (r[0].Y - r[1].Y) / rect.Width;

var R = new Matrix4(
    cosT, sinT, 0, 0,
    -sinT, cosT, 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1
);

var rectAspect = rect.Width / rect.Height;
var ctrlAspect = glControl.Width / (float)glControl.Height;

float sx, sy;

if (rectAspect < ctrlAspect)
{

    sy = -2f / rect.Height/1.1f;
    sx = -sy / ctrlAspect;
}
else
{
    sx = 2f / rect.Width/1.1f;
    sy = -sx * ctrlAspect;

}

float aspectRatio = glControl.Width / (float)glControl.Height;


var T = Matrix4.CreateTranslation(-center.X,-center.Y,0);
var S = Matrix4.Scale(sx, sy, 1);
var mat = T*R*S; This mostly works, but $p0$ always has to be the top left vertex otherwise the image will get rotated. Working on a solution for that. And here's a real life example. I'm trying to use the selection rectangle to orient this image:","['matrices', 'transformation']"
313341,A Question in Rudin PMA chapter 9,If $f$ is a differentiable mapping of a connected open set $E\subset \Bbb{R}^n$ into $\Bbb{R}^m$ and if $f'(x)=0$ for every $x\in E$ prove that $f$ is constant in E. How can this be done without using convexity? I'm trying to use that $f'(x)=0 \implies f$ is constant in open balls which are convex to show $A=E$ where $A=\{x\in E \mid f(x)=f(x_0\}$ where $x_0$ is fixed. Is there another way to do this with minimal use of connectedness or convexity?,"['multivariable-calculus', 'real-analysis']"
313345,Does Euclid lemma hold for GCD domains?,"Exercise $ 10 $ of Section $ 3 $ of Chapter III of Hungerford’s Algebra states that if $ R $ is a UFD and if $ a,b $ are relatively prime, then $ a | bc $ implies $ a | c $, something that is easy to prove using the uniqueness of factorization into irreducibles. So I want to ask whether this holds if $ R $ is just an integral domain (in order for divisibility to make sense) such that $ \gcd(a,b) $ exists for all $ a,b \in R $. I can prove this property if I could show that $\gcd(x,y)\gcd(x,z)=\gcd(x,zy)$ or showing that $\gcd(x,y)=1=\gcd(x,z)$ implies $\gcd(x,zy)=1$, this is the part where I've been stuck. Thanks.","['ring-theory', 'abstract-algebra']"
313355,"Prove that either $m$ divides $n$ or $n$ divides $m$ given that $\operatorname{lcm}(m,n) + \operatorname{gcd}(m,n) = m + n$?","We are given that $m$ and $n$ are positive integers such that $\operatorname{lcm}(m,n) + \operatorname{gcd}(m,n) = m + n$. We are looking to prove that one of numbers (either $m$ or $n$) must be divisible by the other.","['elementary-number-theory', 'divisibility', 'gcd-and-lcm', 'number-theory']"
313369,Diameter of Three Inscribed Circles,"What is the diameter of a circle in which are inscribed three smaller identical circles, two of which are on one side of a chord, the third on the other side?  This problem came up when cutting a log into billets for turning table legs.  I tried including a diagram but the reputation Nazis won't let me.",['geometry']
313377,$(\Bbb R \to \Bbb R : x\mapsto x^2)\equiv(\Bbb R \to \Bbb{R}_{\geq 0} : x \mapsto x^2) \not\equiv (\Bbb C \to \Bbb C:x\mapsto x^2)$,"Consider the following functions: $f:\Bbb R \to \Bbb R  : x\mapsto x^2$ $g:\Bbb R \to \Bbb{R}_{\geq 0} : x \mapsto x^2$ $h:\Bbb C \to \Bbb C:x\mapsto x^2$ I'm quite sure that $h$ is not equal to $f$ or $g$, but I'm not sure if $f$ and $g$ are equal or inequal. If you see $f$ and $g$ as subsets of $\Bbb R \times \Bbb R$, then I think both are equal. However, the codomain of $f$ is not the same as the codomain of $g$, therefor you could argue, $f$ and $g$ are not equal. If we would agree that $f=g$, I would not see the point of specifying the codomain. At university I learned this definition from "" Reading, Writing, and Proving: A Closer Look at Mathematics "": A function $f:X\to Y$ is a relation $f$ from $X$ to $Y$ satisfying: i). $\forall x\in X ,\exists y\in Y :(x,y)\in f $ ii). $\forall x\in X,\forall y_1,y_2 \in Y : (x,y_1),(x,y_2)\in f\implies y_1=y_2$ An function is often called an map or a mapping. The set is $X$ is
  called the domain and denoted by $\text{dom}(f)$, and the set $Y$ is
  called the codomain and denoted by $\text{cod}(f)$. When we know what
  these two sets are and the two conditions are satisfied, we say that
  $f$ is a well defined function. From this definition I would conclude that $f\not=g$. Is this correct ? Are there definitions in mathematics where $f=g$? Can somebody enlighten me a little bit here ?","['logic', 'functions', 'definition']"
313388,A limit without Taylor series or l'Hôpital's rule $¥lim_{n¥to¥infty}¥prod_{k=1}^{n}¥cos ¥frac{k}{n¥sqrt{n}}$,Computing without Taylor series or l'Hﾃｴpital's  rule $$¥lim_{n¥to¥infty}¥prod_{k=1}^{n}¥cos ¥frac{k}{n¥sqrt{n}}$$ What options would I have here? Thanks!,"['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
313390,probability density of the maximum of samples from a uniform distribution,"Suppose $$X_1, X_2, \dots, X_n\sim Unif(0, \theta), iid$$ and suppose $$\hat\theta = \max\{X_1, X_2, \dots, X_n\}$$ How would I find the probability density of $\hat\theta$ ?","['probability-theory', 'probability-distributions', 'probability', 'maxima-minima']"
313397,Using generating function to find number of ways to distribute $r$ objects,"Use generating function to find the number of ways to distribute $r$ beans among $8$ children if each child gets an even number of beans. So I know this is like a weak composition where some children can receive $0$ objects. But I don't know how to account for the even requirement. My guess for the generating function is $$ (1 + x^2 + x^4 + \ldots + x^{r-2} + x^r)^8. $$ But even still, I'm not sure how to determine the possible number of ways to distribute.","['generating-functions', 'combinatorics']"
313403,Help with a bilinear form,"Let $a,b\in\mathbb{F}_{2^{m}}$ (a field of characteristic $2$, m is odd) 
I need to prove that $B(a,b)=tr(\displaystyle\sum_{i=1}^{(m-1)/2}(a+b)^{1+2^{i}})-tr(\displaystyle\sum_{i=1}^{(m-1)/2}a^{1+2^{i}})-tr(\displaystyle\sum_{i=1}^{(m-1)/2}b^{1+2^{i}}),$ where $tr:\mathbb{F}_{2^{m}}\rightarrow\mathbb{F}_2$ is the trace function, is a bilinear form with full rank.","['finite-fields', 'algebraic-geometry', 'bilinear-form', 'field-theory']"
313415,Martingale and bounded stopping time,"A theorem of submartingale and bounded stopping time says: Theorem 5.4.1. If $X_n$ is a submartingale and $N$ is a stopping time with $\mathbb P (N \le 
k) = 1$ then $\mathbb EX_0 ≤ \mathbb EX_N ≤ \mathbb EX_k$. An exercise for this theorem is Example 5.4.1. Random walks. If we let $S_n = \xi_1 + · · · + \xi_n$ where the $ξ_m$
  are independent and have $\mathbb E \xi_m = 0$, $\sigma_m^2 = \mathbb E \xi_m^2 < \infty$. Suppose we have that $|\xi_m | \le K$ and let $s^2_n = \sum_{m \le n} \sigma^2_m$. Note that $S_n^2 − s^2_n$ is a martingale. Use this fact and Theorem 5.4.1 to conclude 
  $$\mathbb P \left(\max_{1 \le m \le n} |S_m| ≤ x \right) ≤ (x + K)^2/ \mathbb E(S_n^2)$$ Let $A = \{\max_{1 \le m \le n} |S_m| ≤ x\}$. Let $X_n = S^2_n - s^2_n$. Let $N = \inf\{m:|S_m| \ge x~\text{or}~n+1\}$. So $N$ is a bounded stopping time. Thus by the previous theorem we have
$$
0 = \mathbb E{X_1} = \mathbb E{X_N} = \mathbb E{X_{n+1}}.
$$
Since $X_{n+1} = X_N$ on $A^c$, we have $\mathbb E (X_{n+1} 1_A) = \mathbb E (X_N 1_A)$. Therefore, as long as we have $\mathbb E (X_N 1_A) \ge 0$, (which I don't know how to prove), we have $\mathbb E (X_{n+1} 1_A) \ge 0$. It follows that
$$
\mathbb E(s_n^2 1_A) \le \mathbb E(s_{n+1}^2 1_A) \le \mathbb E(S_{n+1}^2 1_A) \le (x + K)^2.
$$
But I have problem to show that $\mathbb E(X_N 1_A) \ge 0$. Am I on the right direction?","['probability-theory', 'martingales']"
313434,For what value is the local minimum the largest?,"If  $f(x)=e^x-kx$ for $k>0$, find the values of $k$ for which the local minimum at $x=\ln(k)$ is the largest. I found the derivative, which is $e^{x} - k$, and when I set that to $0$ I got $-e^{x}=k$. I'm not really sure if this is useful information and if it is, I am not sure how to use it to answer the questions, so I would appreciate any tips on where to go next! Thanks!","['calculus', 'derivatives']"
313437,Convergence of definite integral,"I have to find out the convergence of the next integral:
$$\int^{\pi/2}_0{\frac{\ln(\sin(x))}{\sqrt{x}}}dx$$
Any help? Thanks","['definite-integrals', 'convergence-divergence', 'calculus']"
313438,"Determine if the following is a partial order, and if so, is it a total order?","I'm having trouble figuring out how I can solve this... I've never been good with formal proofs. $$(\mathbb{R},\preceq), a\preceq b\iff a^{2}\leq b^{2}$$ I can easily see that it's Reflexive: $\forall a\in\mathbb{R}, a^{2}\leq a^{2}$ I'm not sure how to properly prove that it's transitive and anti-symmetric though. I get stuck here... \begin{align}
a\preceq b,\ b\preceq c&\Rightarrow a^{2}\leq b^{2},\ b^{2}\leq c^{2}\\
&\Rightarrow a^2+b^2\leq b^2+c^2
\end{align} And then anti-symmetric: \begin{align}
a^2\leq b^2\wedge b^2\leq a^2&\Rightarrow a^2=b^2 ??
\end{align} Can anybody give me any pointers on how to approach proving these things? Thanks.","['relations', 'elementary-set-theory', 'order-theory']"
313463,Mass Spring Oscillator Interpretation,"I’m having some trouble predicting the behavior of ODE’s using the mass-spring analogy. For example, consider the second order IVP listed below: 
$$y’’ – \space 6y’ + 8y = 0, \space \space \space \space y(0) = 2, \space \space y’(0) = -8$$
Now I believe that the initial condition of $y(0) = 2$ indicates that the original displacement of the spring from equilibrium is 2 units, but I could be wrong on that.  I have no idea what $y’(0) = -8$ means intuitively, so that’s the first thing I’m hoping to get cleared up (ie interpreting the initial conditions). Next, I understand that each coefficient means different things. From the equation above I see that there is an inertial mass of 1, a damping factor of -6, and a stiffness factor of +8. Since the damping factor is negative I think that the spring will not converge, but outside of that I’m not sure how to interpret the other coefficients. So as another question, how do you know when the solution will oscillate with increasing distance, or go off to positive/negative infinity, or simply oscillate, etc. I'm really seeking advice on interpreting what the behavior of the spring will be for all 8 different scenarios when the coefficients are positive and negative. I’m already planning to plug in some examples using wolfram alpha to see what’s going on, but getting some deeper understanding from the forum will definitely help. Any tips and help with this would be greatly appreciated. Edit:
More specifically, I'm interested in how the solution behaves graphically over time.","['ordinary-differential-equations', 'physics']"
313465,What does the completed graph of a function mean,"zab said: the Levy metric between two distribution functions $F$ and $G$ is simply the Hausdorff distance $d_C$ between the closures of the completed graphs of $F$ and $G$. I have difficulty in understanding the sentence. In particular, what does the completed graph of a function $F$ mean?  What are the two sets the Hausdorff distance is applied to? Is the Levy-Prokhorov metric also similar to Hausdorff metric in some ways?
I haven't figured out a way to  understand the L-P metric either, so If you would reply to the linked question or here, I would appreciate it too! Thanks and regards!","['measure-theory', 'elementary-set-theory']"
313470,How to construct non-square isometry matrix,"How can we construct a non-square isometry matrix $U\in \mathcal{M_{n,m}}$; that is, all columns of $U$ are orthonormal and $U U^T=I_{n,n}$?","['matrices', 'linear-algebra']"
313473,Ring of all continuous functions from reals into reals is not integral domain,Let $R$ be the ring of all continuous functions from the real numbers into the real numbers. Prove that $R$ is not an integral domain. I need help with this. I do not understand this at all and my book really doesn't give that much information.,"['ring-theory', 'abstract-algebra']"
313489,How many triangles are formed by $n$ chords of a circle? [duplicate],"This question already has an answer here : $n$ Lines in the Plane (1 answer) Closed 10 years ago . This is a homework problem I have to solve, and I think I might be misunderstanding it. I'm translating it from Polish word for word. $n$ points are placed on a circle, and all the chords whose endpoints they are are drawn. We assume that no three chords intersect at one point. a) How many parts do the chords dissect the disk? b) How many triangles are formed whose sides are the chords or their fragments? I think the answer to a) is $2^n$. But I couldn't find a way to approach b), so I calculated the values for small $n$ and asked OEIS about them. I got A006600 . And it appears that there is no known formula for all $n$. This page says that $\text{triangles}(n) = P(n) - T(n)$ where $P(n)$ is the number of triangles for a convex n-gon in general
  position. This means there are no three diagonal through one point
  (except on the boundary). (There are no degenarate corners.)
  This number is easy to calculate as: $$P(n) = {n\choose 3} + 4{n\choose 4} + 5{n\choose5} + {n\choose6}
       = {n(n-1)(n-2)(n^3 + 18 n^2 - 43 n + 60)\over720}$$ The four terms count the triangles in the following manner [CoE76]: $n\choose3$: Number of trianges with 3 corners at the border. $4{n\choose4}$: Number of trianges with 2 corners at the border. $5{n\choose5}$: Number of trianges with 1 corners at the border. $n\choose6$: Number of trianges with 0 corners at the border. $T(n)$ is the number of triple-crossings (this is the number of
  triples of diagonals which are concurrent) of the regular $n$-gon.
  It turns out that such concurrences cannot occur for n odd, and,
  except for obvious cases, can only occur for $n$ divisible by $6$.
  Among other interesting results, Bol [Bol36] finds values of n
  for which $4$, $5$, $6$, and $7$ diagonals are concurrent and shows that
  these are the only possibilities (with the center for exception). The function $T(n)$ for $n$ not divisible by $6$ is: $$T(n) = {1\over8}n(n-2)(n-7)[2|n] + {3\over4}n[4|n].$$ where $[k|n]$ is defined as $1$ if $k$ is a divisor of $n$ and otherwise $0$. The intersection points need not lie an any of lines of symmetry of
  the $2m$-gon, e. g. for $n=16$ the triple intersection of $(0,7),(1,12),(2,14)$. If I understand the text correctly, it doesn't give a general formula for $T(n)$. Also I've found a statement somewhere else that some mathematician wasn't able to give a general formula solving this problem. I haven't found a statement that it is still an open problem, but it looks like it to me. So am I just misunderstanding the problem, or misunderstanding what I've found on the web, or maybe it is indeed a very hard problem? It's the beginning of the semester, our first homework, and it really scares me.","['polygons', 'combinatorics']"
313499,Pennies on a checkerboard.,"Here is a question on pennies on checkerboard. It isnt a homework question. I saw it in a book. Pennies are placed on an 8 × 8 checkerboard in an alternating pattern of heads and
tails.

i. You are allowed to make moves where in each move you turn over exactly two pennies
   that lie next to each other in the same row or column. Can you take a sequence of
   moves that leaves just one penny face up?

ii. You are allowed to make moves where in each move you turn over exactly three
    neighboring pennies that lie in the same row or column of the checkerboard. Can you
    take a sequence of moves that leaves just one penny face up? I am able to do the first part using parity. The answer to the first part is ""NO"". But I cant figure out how to go about the second part. Please explain.
Thank you.","['contest-math', 'number-theory']"
313504,What is the intuitive meaning of the basis of a vector space and the span?,"The formal definition of basis is: A basis of a vector space $V$ is defined as a subset  $v_1, v_2, . . . , v_n$ of vectors in  that are linearly independent and span vector space $V$. The definition of spanning is: A set of vectors spans a space if their linear combinations fill the space. But what is the intuitive meaning of this, and the idea of a vector span? All I know how to do is the process of solving by putting a matrix into reduced row-echelon form. Separately, I""m not sure if I should put this in a new question, but could someone relate this to an intuitive explanation for the row space and column space? So a column space is all the linear combinations of each column of matrix $A$. So what? What does this imply? And a row space is, is it a linear combination of all the rows of $A$, because the book just says its the column space of $A^T$, which I hope means the same thing. So, sure, that's what the definitions of the row space and column space are, but how do all these concepts relate? I'm getting especially confused getting to the fundamental theorems of linear algebra part where we talk about row space, column space, and nullspaces all together.","['linear-algebra', 'intuition']"
313506,Show that $(1+ \frac{1}{n})^n$ and $(1- \frac{1}{n})^{-n}$ have the same limit,"Let $x$ be positive and
$$
 a_n = \left( 1 + \frac{x}{n} \right)^n \qquad b_n = \left( 1 - \frac{x}{n} \right)^{-n}.
$$
Show that a) The sequence $(a_n)$ and $(b_n)$ have the same limit $\xi =: \operatorname{Exp}(x)$. Use the following steps i) $a_n < b_n$ for all $n \in \mathbb{N}$ with $n > x$. ii) for $n > x$, $(a_n)$ is monotone increasing, and $(b_n)$ monotone decreasing. iii) $b_n - a_n \to 0$ for $n \to \infty$. b) For $y = -x < 0$
$$
 \lim_{n\to \infty}\left( 1 + \frac{y}{n} \right)^n = \frac{1}{Exp(x)}
$$ Item ii) is simple, because $0 < \frac{x}{n} < 1$, obvisouly $a_n$ increasing. But for the rest I have no idea...","['limits', 'sequences-and-series', 'analysis']"
313512,Limit of some integral,"My question is how to find: 
$\displaystyle  \lim_{n \rightarrow \infty} \int\limits_0^n \frac {1}{n+n^2\sin(xn^{-2})} dx $? I've tried with a dominated convergence theorem, but it didn't work. Now, I how absolutely no idea what I can do to solve it. Please, help me.","['calculus', 'integration', 'real-analysis']"
313515,How would you visualize Levy metric?,"From Wikipedia : Let $F, G : \mathbb{R} \to [0, 1]$ be two cumulative distribution functions. Define the Lévy distance between them to be
  :$$L(F, G) := \inf \{ \varepsilon > 0 | F(x - \varepsilon) - \varepsilon \leq G(x) \leq F(x + \varepsilon) + \varepsilon \mathrm{\,for\,all\,} x \in \mathbb{R} \}.$$ Intuitively, if between the graphs of $F$ and $G$ one inscribes squares with sides parallel to the coordinate axes (at points of discontinuity of a graph vertical segments are added), then the side-length of the largest such square is equal to $L$($F$, $G$). I was wondering how to picture ""between the graphs of $F$ and $G$ one inscribes squares with sides parallel to the coordinate axes (at points of discontinuity of a graph vertical segments are added)""? Why ""the side-length of the largest such square is equal to $L$($F$, $G$)""? How is the Levy metric a special case of the Lévy–Prokhorov metric ? Thanks and regards!","['probability-theory', 'measure-theory']"
313516,Does Riemann integrability on closed interval implies uniform boundedness?,"Does Riemann integrability on closed interval implies uniform boundedness? My thought process points to yes, because if f is Riemann integrable then it is bounded pointwise on [a,b]. I could be wrong, but I very vaguely remember from more elementary analysis that this implies uniform boundedness on that interval.","['integration', 'real-analysis', 'analysis']"
313524,"How to find a ""better description"" (e.g. recurrence relation) for this sequence?","My solution to a problem in Project Euler required to solve this subproblem: find values of $k\in\mathrm{N}$ such that $3k^2+4$ is a perfect square. As I was writing a computer program, I just tried all $k$ and checking if $3k^2+4$ is a perfect square. I solved the problem, but this is not efficient and it doesn't really answer the question. It turns out that this sequence is http://oeis.org/A052530 , there is an easy recurrence relation ($k_n = 4k_{n-1} - k_{n-2}$), and some closed-form formulas for $k_n$ (e.g. $k_n = \left((2+\sqrt{3})^n-(2-\sqrt{3})^n\right)/\sqrt{3}$). Now I know some answers, but I still don't see how to derive them from the definition. Also, I wasn't able to prove that the recurrence relation works (given that $k_{n-2}$ and $k_{n-1}$ are to consecutive terms of the sequence, prove that $4k_{n-1} - k_{n-2}$ is a term in the sequence, and that it is next term). So my question is: given the definition of the sequence ($k\in\mathrm{N}$ such that $3k^2+4=n^2$), how can I find a recurrence relation for this sequence? I will be very happy if can use the same procedure for other similar sequences.","['recurrence-relations', 'sequences-and-series', 'diophantine-equations']"
313544,Why does this matrix have 3 nonzero distinct eigenvalues,"Consider the $n \times n$ matrix $$A=\left[ 
\begin{array}{cccc}
0 & 1 & ... & 1 \\ 
1 & 0 &  & 0 \\ 
\vdots  &  & \ddots  &  \\ 
1 & 0 &  & 0%
\end{array}%
\right] $$ (A has $n-1$ ones in the first row, $n-1$ ones in the first column, and zeros anywhere else), and let $$G=A(I_n-\theta A)^{-1},$$ where $\theta$ is a scalar such that  $I_n-\theta A$ is positive definite. Let $W$ be a nontrivial subspace of $\mathbb{R}^{n}$ including the vector of all ones, and no eigenvectors of $A$. Let $M$ be the orthogonal projector onto the orthogonal complement of $W$. Let $$Q=G-\frac{1}{n}\mathrm{trace}(G) I_{n}.$$ Show that $$MQ+QM$$ has exactly 3 nonzero distinct eigenvalues (for any $n$, any $\theta$ such that  $I_n-\theta A$ is positive definite, any $W \subset \mathbb{R}^{n}$ including the vector of all ones).","['graph-theory', 'linear-algebra', 'eigenvalues-eigenvectors']"
313545,Negative exponents when multiplying polynomials,"$$(4-t)(1+t^2)^{-1}$$
I am supposed to find the derivative of this but I am not sure if it means $$\frac{1}{(4-t)(1+t^2)^{-1}}\quad\text{or}\quad\frac{(4-t)}{(1+t^2)}$$
I have tried to look online for help but couldn't find an example that looked like this. I am assuming that the second one is the correct one but I just wanted to make sure.","['rational-functions', 'calculus', 'derivatives']"
313548,The apex of parabolic motion forms an ellipse of constant ellipticity.,"I am not sure how well-known this is idea is, but here is a .gif illustrating it: Basically, the set of highest points of parabolic motion at constant initial velocity forms an ellipse, with eccentricity which is independent of both the initial velocity and gravitational acceleration. It's pretty easy to see that it's true, and I will work it out  here for completeness. The highest point of the ellipse (which will be the semi-minor axis $b$) is $h=2b=\frac{v^2}{2g}$ where $v$ is the initial velocity and $g$ is the gravitational acceleration. The semi-major axis will be the largest horizontal distance any path makes before it peaks, the time of which we can find with kinematic equations assuming the y-velocity goes to zero $v_y(t)=0=v\sin\theta -gt\rightarrow t=\frac{v}{g}\sin\theta$ Plug this into the kinematic equation for distance and minimize: $x(t)=v\cos\theta t=\frac{v^2}{g}\sin\theta\cos\theta$ This maximum occurs for $\theta=\pi/4$, so $a=\frac{v^2}{2g}$ and the eccentricity is $e=\sqrt{3}/2$, and does not depend on the initial velocity or the gravitational acceleration. Now, I think that's pretty amazing; at this point I've convinced myself there is no ellagant (""simple"") way of seeing this fact, but I am interested if it might be a special case of something else. For instance, my thought is that it is somehow related to the lengths of geodesics on a space of positive curvature, since we have curves from the origin of motion to critical points in a field of constant acceleration. Of course, it can't quite be that because the space actually seems to be more like a cylinder than a sphere, and I'm not sure what to do about the axes; I guess they would have to be measured with respect to a 3-space which my cylindrical surface is embedded. Anyway; does anyone know anything about this problem, or if it represents a specific case of some more interesting geometrical result? EDIT: Well, there has been very little interest in this question, and after ~5 years I am still fascinated by it. So what else can be said which might evoke some interest? This is 2D kinematic motion, which means each of the two directions of motion are described by a polynomial. The specific polynomials here are $$(x(t),y(t))=(v_{x0}t+x_0,-1/2gt^2+v_{y,0}t+y_0)$$ Of course, the answer did not depend on any of the parameters of this problem ($v_{x0},v_{y0},g,x_0,y_0$), but perhaps it depends on the order of the polynomials...at least, that's the only choice I'm left with. So, perhaps each particular combination of polynomial order $(n,m)$ (where $(n,m)=(1,2)$ for this case) results in a different value of the eccentricity? Does anyone know if it is possible to model ellipses with polynomials?","['mathematical-physics', 'geometry']"
313564,square root of a real matrix,"I want to compute the square root of a real symmetric positive definite matrix $S\in \mathcal{M}_{m,m}$ such that $S^{1/2}S^{1/2}=S$ and it's well known that this decomposition is unique. My question is if I have $S$ a real matrix will its square root be real too or it could be a complex matrix. In case that it could be complex then $S$ could have infinitely many square roots. Any comments?","['matrices', 'linear-algebra']"
313565,"prove , if $p,q$ be two primes with the property , $q$=$p$+1 then $p$=2 and $q$=3","prove , if $p,q$ are two primes with the property , $q$=$p$+1 then $p$=2 and $q$=3 how can we prove something like that ? my information in number theory is not big , and i have no idea about the method which we should follow to prove this statement . any ideas ? remark ! : this is Not homework , it's just a question .","['prime-numbers', 'elementary-number-theory', 'number-theory']"
313572,Describing image under $f(z)=e^{2\pi iz}$,"I want to describe the image of the strip {${z \in \mathbb C |-1/2 \leq x \leq 1/2}$ and $y \geq 1$} under the map $f(z)=e^{2\pi iz}$. My attempt, $e^{2\pi iz}=e^{-2\pi y}(cos2\pi x+isin2\pi x)$. Since $y \geq 1$ so the modulus of this number lies in $(0,e^{-2 \pi}]$ and since $|x|\leq1$ so we have $-1 \leq cos2\pi x \leq1$ and $-1 \leq sin2\pi x \leq1$. So I get the description of real and imaginary parts. What is this thing geometrically? Please help",['complex-analysis']
313618,two points of the longest distance in a convex curve will be the vertices?,"First we give the necessary definition:
A vertex of a curve $\gamma(r)$ in $\mathbb{R}^2$ is a point where its signed curvature $\boldsymbol{k}_{s}$ has a stationary point, i.e.,where $d\boldsymbol{k}_{s}/dt=0$. We have Four Vertex Theorem:
Every convex simple closed curve in $\mathbb{R}^2$ has at least four vertices. Now, I have a question：
For a convex curve on $\mathbb{R}^2$ plane, we define the distance of two points $(x_1,y_1),(x_2,y_2)$ on the curve is $L=\sqrt{(x_1-x_2)^2 +(y_1-y_2)^2}$.
If the distance of these two points is the longest on $\gamma(r)$, would these two points will be vertices? Obviously, it's true for the elipse.",['differential-geometry']
313624,Multinomial coefficient notation?,"How does one evaluate this $$\binom{5}{2, 2, 1}$$ would it be something like $\dfrac{5!}{2! \cdot 2! \cdot 1!}$ or does it evaluate differently then the usual 
$$\binom{n}{k} = \dfrac{n!}{k!(n-k)!}$$
can someone explain?","['discrete-mathematics', 'combinatorics']"
313676,Prove $\lim \limits_{x \to\infty } \frac{f(x)}{x}=0$ and $f$ differentiable implies $ \lim \limits_{x \to\infty } \inf |f'(x)|=0 $,"Given a differentiable function on $(a,+\infty)$ such as $\lim \limits_{x \to\infty } \frac{f(x)}{x}=0$ prove the following:
$$ \lim \limits_{x \to\infty } \inf |f'(x)|=0  $$ I just can't see how to do it...
(even after understanding How to show that $\lim\limits_{x \to \infty} f'(x) = 0$ implies $\lim\limits_{x \to \infty} \frac{f(x)}{x} = 0$? )","['derivatives', 'limits']"
313696,Tough goniometric inequality (different period),"I'm trying to solve this inequality:
$\dfrac{1 - 2 \sin(x)}{2 \cos(x / 2) + \sqrt{3}} \leq 0$ Using the standard method of setting $\text{numerator} > 0$ and $\text{denominator} > 0$ and then comparing the signs I get stuck, because the results have different periods ($2\pi$ vs $4\pi$) and I cannot draw them on a single circumference. Any hints?","['trigonometry', 'inequality']"
313702,questions on the completely accumulation,Could somebody help me to understand the definition of completely accumulation? And help me show that this claim: A space $X$ is compact iff every infinite set in $X$ has a point of complete accumulation. Thanks ahead:),"['general-topology', 'definition']"
313704,Derivative of the off-diagonal $L_1$ matrix norm,"We define the off-diagonal $L_1$ norm of a matrix as follows: for any $A\in \mathcal{M}_{n,n}$, $$\|A\|_1^{\text{off}} = \sum_{i\ne j}|a_{ij}|.$$
So what is $$\frac{\partial \|A\|_1^{\text{off}}}{\partial A}\;?$$","['matrices', 'matrix-calculus', 'derivatives']"
313713,Prime ideal decomposition in quadratic field extensions,"Once you have the character $\chi$ of a quadratic field extension and the corresponding modulus $N$, it is easy to see which prime ideals split, ramify and are inert by looking at their remainder $\mod N.$ But how do you determine what the ideal actually splits (or ramifies) into? Is this hard in general or is there an algorithm one can use? For example, in $\mathbb{Q}(\sqrt{3})$, I know that $p=2,3$ are the ramified primes, and $p$ is split if $p=1,11 \pmod{12}$ and inert if $p=5,7 \pmod{12}$. But, without running through all possible combinations of $a$ and $b$, how would I find the specific $a,b\in \mathbb{N}$ such that $2=(a+b\sqrt{3})(a-b\sqrt{3})$? If there is no general algorithm, would you be able to give an explanation for the case of $\mathbb{Q}(\sqrt{3})$?","['ideals', 'abstract-algebra', 'number-theory']"
313737,Status of the classification of non-finitely generated abelian groups.,"From the Wikipedia on abelian groups : By contrast, classification of general infinitely-generated abelian groups is far from complete. How far are we from a classification exactly?   It seems like divisible groups have been classified. Which cases are left which we haven't?  What is the nature of these unknown cases that makes them so hard to understand?  Do we have examples of really ""out there"" infinitely-generated groups that don't fit into any of the current categories?","['abelian-groups', 'abstract-algebra', 'reference-request', 'group-theory', 'open-problem']"
313752,Hartshorne book Proposition (II.5.13),"In Hartshorne book Proposition (II.5.13) is that Let $A$ be a ring ,let $S=A[x_0,\cdots,x_r]$ and let $X={\rm Proj}S$.
Then, $\Gamma_*(\mathcal{O}_X) \cong S$. In proof,
To give a setion $t \in \Gamma(X, \mathcal{O}_X(n))$ is the same as giving sections $t_i \in \mathcal{O}_X(n)(D_+(x_i))$ for each $i$ which agrees on the intersection $D_+(x_ix_j)$. I don't know meaning of following statement: Summing over all $n$, we see that $\Gamma(\mathcal(O)_X$ can be identified with the set $(r+1)$-tuples $(t_0,\cdots,t_r)$ where for each $i$, $t_i\in S_{x_i}$, and for each $i,j$, the image of $t_i$ and $t_j$ in $S_{x_ix_j}$ are the same.\ Help me.",['algebraic-geometry']
313775,$f$ is integrable but has no indefinite integral,"Let $$f(x)=\cases{0,& $x\ne0$\cr 1, &$x=0.$}$$ Then $f$ is clearly integrable, yet has no antiderivative, on any interval containing $0,$ since any such antiderivative would have a constant value on each side of $0$ and have slope $1$ at $0$ —an impossibility. So does this mean that $f$ has no indefinite integral? EDIT My understanding is that the indefinite integral of $f$ is the family of all the antiderivatives of $f,$ and conceptually requires some antiderivative to be defined on the entire domain. Is this correct?","['calculus', 'integration', 'real-analysis', 'analysis']"
313779,A question about laplacian of the second fundamental form,"Let $ f:M \rightarrow N $ be an immersed oriented hypersurface, $ e_{1}, \ldots e_{n},e_{n+1} $ be an orthonormal frame of $ N $ such that $ e_{1} \ldots e_{n} $ is an orthonormal frame of $ M $. Let $ h_{ij} $, $ i,j=1 \ldots n $ be the coefficients of its second fundamental form. In detail $ h_{ij}=h(e_{i},e_{j})=\langle B(e_{i},e_{j}),e_{n+1} \rangle $. In the article 'Estimates for minimal hypersurfaces' of Schoen Simon and Yau, at (1.16), it asserts that $ \Delta h_{ij} = \sum_k h_{ijkk} $ where $ h_{ijkk}= \nabla_{e_{k}}(\nabla h)(e_{i},e_{j},e_{k}) $ where $ \nabla h $ is the covariant derivative in $ M $ of the symmetric tensor $ h $. Why does this equality hold? Added : in the same article there is another assertion of the same type: $ |\nabla (h_{ij})|^2=\sum_{k}h_{ijk}^2 $ where $ h_{ijk}=(\nabla_{e_{k}}h)(e_{i},e_{j}) $ In both of this assertions it seems that the authors do not consider some terms: for example we note that $ h_{ijk}= e_{k}(h_{ij})-h(\nabla_{e_{k}}e_{i},e_{j})-h(\nabla_{e_{k}}e_{j},e_{i}) $ while $ |\nabla (h_{ij})|^2=\sum_{k}(e_{k}(h_{ij}))^2 $ So it seems that they assert: $ h_{ijk}=e_{k}(h_{ij}) $ . But this fact is false in a general context. An analougous assertion it seems to hold for the first equality in this post. Thanks","['riemannian-geometry', 'differential-geometry']"
313783,What are positive and negative curvature when working in non-Euclidean geometry?,Can you give me the sense I can find the difference between positive and negative curvature in non-Euclidean geometry better? I am asked today by my friend and I want to give her a good practical explanation. Thank you very much!,['geometry']
313795,Maximum principle for minimal hypersurfaces,"The well known local version of the maximum principle for minimal hypersurfaces asserts that if two minimal hypersurfaces $ M_1 $ and $ M_2 $ of $ R^n $ has a common point $ x_0 \in M_1 \cap M_2 $ where $ M_1 $ lies (locally) on one side of $ M_2 $ then $ M_1 = M_2 $ in a neighbourod of $ x_0 $. This result can be found for example in 'A course in minimal surfaces' of Colding Minicozzi. Now i want to prove that if one of them is complete, for example $ M_1 $, then $ M_2 \subset M_1 $. It is quite obvious to proceed in this way: if $ f_i:M_i \rightarrow R^n $, $ i=1,2 $, are the immersion maps, for the local version of the maximum principle there exist $ U_i \subset M_i $ such that $ f_i :U_i \rightarrow R^n $ is an embedding and $ f_1(U_1)=f_2(U_2) $. Now it is easy to check that $f_1^{-1} \circ f_2 : U_2 \rightarrow U_1 $ is an isometry. Now the most obviuos thing to do is an application of the unique continuation theorem since $ f_1 $ and $ f_2 $ are harmonic maps on the manifolds (unique continuation is suggested in Colding Minicozzi, but they do not give a proof). My problem is that i don't know how i can apply the unique continuation for elliptic operators? In fact $ f_1 $ and $ f_2 $ are defined on two hypersurfaces of $ R^n $ that a priori can be distinct.
Thank you","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry']"
313798,Find the standard matrix for a linear transformation,"If $T: \Bbb R^3→ \Bbb R^3$ is a linear transformation such that: $$
T \Bigg (\begin{bmatrix}-2 \\ 3 \\ -4 \\ \end{bmatrix} \Bigg) = \begin{bmatrix} 5\\ 3 \\ 14 \\ \end{bmatrix}$$ $$T \Bigg (\begin{bmatrix} 3 \\ -2 \\ 3 \\ \end{bmatrix} \Bigg) = \begin{bmatrix}-4 \\ 6 \\ -14 \\ \end{bmatrix}$$ $$  T\Bigg (\begin{bmatrix}-4 \\ -5 \\ 5 \\ \end{bmatrix} \Bigg) = \begin{bmatrix} -6\\ -40 \\ -2 \\ \end{bmatrix}
$$ Then the standard matrix for T is... I'm not exactly sure how to approach this problem.
Could anyone explain how to solve this problem?","['linear-transformations', 'matrices', 'linear-algebra']"
313802,Can every number be written as a small sum of sums of squares?,"In a practice for a programming competition, one problem asked us to find the smallest number of pyramids which can be built using exactly $n$ blocks, where pyramids have either $k\times k, (k-1)\times (k-1),\ldots,1\times 1$ blocks on each level or $2k\times 2k, 2(k-1)\times 2(k-1),\ldots,2\times 2$ blocks on each level. Note that the first type of pyramid has
$$\sum\limits_{i=1}^k i^2 = \frac{k(k+1)(2k+1)}{6}$$
blocks while the second has
$$\sum\limits_{i=1}^k (2i)^2 = \frac23 k(k+1)(2k+1).$$
Equivalently, we want to write $n$ as a sum of numbers of this form, using as few as possible. The official solution to this problem had an exponential runtime in the minimal number of pyramids, but noted that this was not problematic as the minimal number of pyramids is always at most $6$. I see no obvious reason for this, or even an obvious reason why the minimal number of pyramids should be bounded. Can someone provide a proof?","['algorithms', 'number-theory']"
313827,"integration of $\int_0^\infty\frac{(\log(x))^3}{x^3-1}\,\mathrm{d}x$","I have this integral to solve with complex analysis: $$\int_0^\infty\frac{(\log(x))^3}{x^3-1}\,\mathrm{d}x$$ My result is $$\frac{\pi^3}{54}$$ But I don't know if it is ok..and so I ask you if it is.
Thanks","['complex-analysis', 'analysis']"
313829,Prove $\left(\frac{n+1}{\text{e}}\right)^n<n!<\text{e}\left(\frac{n+1}{\text{e}}\right)^{n+1}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How to prove this inequality?
$$\left(\frac{n+1}{\text{e}}\right)^n<n!<\text{e}\left(\frac{n+1}{\text{e}}\right)^{n+1}$$","['inequality', 'calculus', 'real-analysis']"
313832,A combinatorial proof that the alternating sum of binomial coefficients is zero,"I came across the following problem in a book: Give a combinatorial proof of 
$$ {n \choose 0} + {n \choose 2} + {n \choose 4} + \, \, ... \, = {n \choose 1} + {n \choose 3} + {n \choose 5} + \, \, ...$$ using the ""weirdo"" method (i.e., where one of the elements is chosen as special and included-excluded -- I'm sure you get the idea). After days of repeated effort, the proof has failed to strike me. Because every time one of the elements is excluded, the term would be ${n-1 \choose k}$ and not $ {n \choose k}$, which is not the case in either of the sides of the equation.","['summation', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
313834,Prove $1+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+\dots+\frac{1}{\sqrt{n}} > 2\:(\sqrt{n+1} − 1)$,"Basically, I'm trying to prove (by induction) that: $$1+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+\dots+\frac{1}{\sqrt{n}} > 2\:(\sqrt{n+1} − 1)$$ I know to begin, we should use a base case.  In this case, I'll use $1$.  So we have: $$1 > 2\:(1+1-1) = 1>-2$$ Which works out. My problem is the next step.  What comes after this?  Thanks!","['discrete-mathematics', 'proof-writing']"
313837,Tietze extension theorem for complex valued functions,"Why is this theorem always only stated for real valued functions, and not for complex valued functions? Thanks.","['general-topology', 'real-analysis', 'analysis']"
313846,"Piecewise function $f(x,y)$ - Limits and Continuity","Consider the function $f : \Bbb R^2 \to \Bbb R$ given by: $$f(x, y) = \begin{cases} 0 &\text{if } x < 0,\\ x\cdot y &\text{if } x \geq 0 \text{ and }y \geq 0,\\-x &\text{if } x \geq 0 \text{ and }y < 0.\end{cases}$$ Describe the properties of this function in terms of limits and continuity. I am struggling to see which limits I should be taking and how to check if $f(x,y)$ is continuous. Any help would be appreciated, thank you.","['calculus', 'continuity', 'limits']"
313872,Tychonoff theorem (1/2),"I was trying to prove Tychonoff theorem. First I used (which I showed also): The following are equivalent (a) $X$ is compact (b) every filter of closed set $F$ on $X$ has non-empty intersection (c) every ultrafilter of closed set $F$ on  $X$  has non-empty
  intersection Then my proof is this: Let $F$ be a filter of closed sets on $X$. Then $\bigcap F \neq \varnothing$: Define $F_i = \{ Y \subseteq X_i \mid \pi^{-1}_i Y \in F \}$. Inverse maps preserve intersections and subsets and $\pi_i$ are continuous then $F_i$ is a filter of closed sets in $X_i$ and hence has non-empty intersection. Let $x_i \in \bigcap F_i$ and let $x = (x_i)_{i \in I}$. Then $x \in \bigcap F$: By contradiction assume $x \in (\bigcap F)^c = \bigcup F^c$. Then there is $S \in F^c$ with $x \in S$. Then $\pi_i x = x_i \in \pi_i S \subseteq X_i$ for all $i$. By how $S$ was chosen, $\pi_i S \notin F_i$. To see this, assume $\pi_i S \in F_i$. Then $\pi_i^{-1} \pi S \subseteq S \in F^c$. It means $\pi_i^{-1} \pi S$ is a subset of a complement of a set in $F$ and can therefore not be in $F$. But then $x_i \notin f$ for all $f \in F_i$ which is a contradiction to how $x$ was defined. Is this valid proof? Many thank you for help.","['general-topology', 'filters', 'compactness']"
313875,Can nonzero polynomials vanish identically?,I know that a nonzero single-variable polynomial over a finite field can vanish identically e.g. take the product $\prod_a(x-a)$ for every $a$ in the field. But I know that for an infinite field this cannot happen since a degree $d$ polynomial has at most $d$ roots. My questions are: Why does a nonzero two-variable or higher polynomial over $\mathbb{R}$ not vanish identically? (In this case I know they can't but I don't know why) What about nonzero multivariate polynomials over other infinite fields?,"['field-theory', 'abstract-algebra', 'polynomials']"
313904,Is analytic function on whole complex plane taking only integer values constant?,Let $f(z)$ be an analytic function on the whole complex plane such that it takes only integer values. Is $f(z)$ a constant function?,['complex-analysis']
313906,Compactness in subsets of $\mathbb{R}^2$ example,"I'm working on compactness in topological spaces and I wanted to check I am correctly understanding and implementing some theorems. So taking a common example, is $S =\{ (x,y) \in \mathbb{R}^2 : x^2 + y^2 =1 \}$ compact in
  $\mathbb{R}^2$? As stated in Sutherland's Introduction to Metric and Topological spaces p136 Exercise 13.4. (It doesn't state that topology being used so I will assume the standard Euclidean). This is the way I have approached the problem: Using the theorems that Any closed subset of a compact set is compact and (Heine-Borel) Any closed bounded subset of $\mathbb{R}^n$ is compact I have concluded that $C = [-1,1] \times [-1,1] \subset \mathbb{R}^2$ is compact and as the complement of $S$ in $C$ is open, $S$ is closed and thus compact in $C$. However I run into problems here because I have compactness in C and not $\mathbb{R}^2$, and I have a strong feeling that compactness in a set doesn't necessarily imply compactness in the superset. I would really appreciate your help in understanding the best way to approach this type of problem so I can feel confident in more complex examples. Thanks in advance. P.S Apologies if I have formatted or referenced anything incorrectly, I'm still very new here.","['general-topology', 'compactness']"
313927,Understanding the quotient ring $\mathbb{R}[x]/(x^3)$.,"I am having difficulty in understanding exactly the elements of the set $\mathbb{R}[x]/(x^3)$. I'll explain my thought process. The Quotient Ring is the set of additive cosets, so we have that $$\mathbb{R}[x]/(x^3) = \{f+(x^3) : f\in\mathbb{R}[x]\}.$$ So we have the relation $$f-g\equiv 0 \mbox{ mod } x^3,$$ hence $x^3|f-g$. Now, right now I understand this as a whole bunch of notation taken strictly from the definition. But what exactly are the elements of this quotient ring?","['ring-theory', 'ideals', 'abstract-algebra']"
313933,Calculating longitude degrees from distance?,"I need to calculate how many longitude degrees a certain distance from a point are, with the latitude held constant. Here's an illustration: Here x represents the longitude degrees, the new point can be on either side of the starting point. I'm using the haversine formula, which calculates the distance between two points on a sphere given a radius, $r$, and a pair of coordinates expressed in latiude, $\phi$, and longitude, $\lambda$, degrees: $d=2r\arcsin\left(\sqrt{\sin^2\left(\dfrac{\phi_{2}-\phi_{1}}{2}\right)+\cos(\phi_{1})\cos(\phi_{2})\sin^2\left(\dfrac{\lambda_{2}-\lambda_{1}}{2}\right)}\right)$ Which can be reduced to, because of the latitude held constant: $d=2r\arcsin\left(\sqrt{\cos^2(\phi_{1})\sin^2\left(\dfrac{\lambda_{2}-\lambda_{1}}{2}\right)}\right)$ I plugged it into WolframAlpha to isolate $\lambda_{2}$, and got these two solutions: $\lambda_{2}=\lambda_{1}-2\arcsin\left(\sec(\phi_{1})\sqrt{\sin\left(\dfrac{d}{2r}\right)}\right)$ $\lambda_{2}=2\arcsin\left(\sec(\phi_{1})\sqrt{\sin\left(\dfrac{d}{2r}\right)}\right)+\lambda_{1}$ Here's an example of why I'm confused about this. The distance between two points, $40° lat, 10° lng$ and $40° lat, 11° lng$ is (we assume an earth radius of $6371km$): $d=2*6371km*\arcsin\left(\sqrt{\cos^2(40°)\sin^2\left(\dfrac{11°-10°}{2}\right)}\right)=85.1798km$ Plugging those numbers into the 2nd of the two isolated formulas, we get: $\lambda_{2}=2\arcsin\left(\sec(40°)\sqrt{\sin\left(\dfrac{85.1798km}{2*6371km}\right)}\right)+10°=10.0282$ Which is obviously quite far from our desired $11°$, what am I doing wrong here?","['trigonometry', 'geodesy', 'spherical-coordinates']"
313938,What does positive definite matrix mean?,What do we mean by a matrix is positive or negative definite? Does it have any analogy with a positive real number?,"['matrices', 'linear-algebra']"
313940,Cohomology with Coefficients in the sheaf of distributions,It just occurred to me that one could form the sheaf of distributions $F$ on any manifold where for an open set $U$ we have $F(U)$ is the algebra of distributions on $U.$ What does cohomology with coefficients in $F$ represent? Is there a good interpretation using differential forms or differential operators?,"['functional-analysis', 'differential-geometry']"
313955,Asymptotic behaviour of sums of covariances of RVs with LRD,"Our assumptions are: $\left(X_t\right)_{t\geqslant 0}$ is a stationary sequence of standard normal random variables such that $\gamma _X (k)\sim L_{\gamma}(k)k^{2d-1}$ with $d \in (0,1/2)$, where $L_\gamma (k)$ is a slowly varying function. Let $Y_t:=G\left(X_t\right)$ with a real function $G$ such that $\mathbb{E}\left(G\left(X_1\right)\right)=0$ and $\mathbb{E}\left(G\left(X_1\right)^2\right)<\infty$. 
We know that for the ACF holds $$\gamma_Y (k)\sim\frac{J(m)^2}{m!}L_\gamma^m(k)k^{m(2d-1)}$$ for $k\rightarrow \infty$, where $m$ is the Hermite rank of $G$, $J(m):=\mathbb{E}\left[G(X)H_m(X)\right]$ and $H_m$ is the $m$-th Hermite polynomial.
What can we now say about the asymptotic behaviour of the sum of covariances $$\sum_{j=1}^{\ell}\sum_{k=\ell+1}^{n}\mathrm{Cov}\left(Y_{j}, Y_{k}\right)$$
for $n\rightarrow\infty$ and $\ell$ fixed?","['statistics', 'stochastic-processes', 'stationary-processes', 'covariance']"
313956,Tensor product of operators,"We know that if $T_1$ is a linear bounded operator on a Hilbert space $H_1$ and $T_2$ is a linear bounded operator on a Hilbert space $H_2$ there exists a unique linear bounded operator $T$ on $H_1 \otimes H_2$ such that
$$ T (x_1 \otimes x_2) = T_1x_1 \otimes T_2x_2$$ for all $x_1$ in $H_1$ and $x_2$ in $H_2$. This operator is called a tensor product of operators $T_1$ and $T_2$ and denoted by $T_1 \otimes T_2$. We can extend this to the arbitrary finite tensor product of Hilbert spaces and even infinite one which works with respect to some stabilising sequence. How about the converse? Is it true that if $T$ is a linear bounded operator on a Hilbert space $H_1 \otimes H_2$ (here of course $H_1$, $H_2$ also Hilbert spaces) then we can find operators (unique?) $T_1$ and $T_2$ on $H_1$, $H_2$ respectively, such that $Tu= (T_1 \otimes T_2)u$ for every $u \in H_1 \otimes H_2$. If not I would be grateful for any counterexamples. If it is true, how about the arbitrary tensor product and what about inifinite one? Thank you for the help. Any suggestions for good books are welcome.","['tensor-products', 'hilbert-spaces', 'functional-analysis']"
313970,"The ""it's not possible"" statement in math and the Axiom of Choice","This question actually consists 3 related pieces of text, which I've gathered under this title about which I would like your opinion (they rather contain the implicit question ""is this the right way to think about this issue""). I'm willing to offer bounty for this. $1.$ Consider the following theorem: There is no function $f:\mathcal{P}\left(\mathbb{R}\right)\rightarrow\left[0,\infty\right]$
that is translation-invariant and $\sigma$-additive such that $0<f\left(\left(0,1\right)\right) < \infty$. Its proof goes like this: We first define a equivalence relation $a\sim b:\Leftrightarrow a-b\in\mathbb{Q}$
on $\mathbb{R}$, then select a system $S$ of representatives from
it that lies in $\left(0,1\right)$. This $S$ is then the key to
prove the theorem. What I'm concerned with is how we obtain $S$. The proof I know says
""we have to use the axiom of choice to do that'': The
choice function picks member from every an equivalence class. As I
understand it the use of the axiom of choice comes from the fact that
we can't determine explicitly the form of the set all the equivalence
classes (if we have one representative we can easily get one that
lies in the open unit interval). Each equivalence class has to have the form $a+\mathbb{Q}$ for some
real $a$ and it is clear that the equivalence class of any rational
number is $\mathbb{Q}$. But the irrational numbers cause problem:
We have no means to explicitly describe all equivalence classes of
irrational numbers, since for a given $b,c\in\mathbb{R}\setminus\mathbb{Q}$,
we don't know if they are in the same equivalence class or not: $1+\sqrt{2}$
and $2+\sqrt{2}$ obviously are; but for $\pi$ and $e$ we don't
know, since currently it is unknown whether $\pi-e$ is rational or
not. Now the axiom of choice circumvents this issue. But the need
to use the axiom of choice seems to me to depend in this case only
on present state of research: Maybe in 100 years we will settle the
case for $\pi$ and $e$ and moreover devise some methods such that
for given $b,c\in\mathbb{R}\setminus\mathbb{Q}$ we know if they are
in the same equivalence class or not (for example if it turns out
that we can somehow classify them we can distinguish by cases). Therefore
saying we have to use the axiom of choice seems bad to me;
saying ""presently we cannot do without the axiom of choice""
seems better. $2.$ The above seems to me to be in contrast to saying ""we have to use the axiom of choice to exhibit a functions that picks an element from every subset of the reals"" since I read, that there there are strong model-theoretic arguments that imply that indeed no one will ever be able to explicitly construct such a function. But even in this case it seems to me, that the word ""have"" is too strong, since it implies that one can somehow prove that without the axiom of choice it is impossible to prove that statement. $3.$ Is proving, that a statement $T$ cannot be proven without the axiom of choice the same as proving that $T$ is equivalent to the axiom of choice ? Do you agree with me ?","['logic', 'measure-theory', 'axiom-of-choice']"
313983,Using A Venn Diagram To Illustrate Relationships,"The problem I am working on is: Use a Venn diagram to illustrate the relationship $A⊆B$ and $B⊆C$. From my understanding, I should be drawing several Venn diagrams, corresponding to the different situations that are possible. Since $A \subseteq B$ does not specify whether $A$ is a proper subset or not, we have two situations: $(1)$: $A=B$ $(2)$: $A \subset B$ The same two situations apply to $B \subseteq C$ (This part is just a side note, but I'd appreciate a corroboration of my reasoning)
Also, by the transitive law, since for x we find in A, it is true that we can find it in B ($A \subseteq B$); and since for every x in B, it is true that we can find it in C ($B \subseteq C$), we can say that $A \subseteq C$. This is reasonable, because all of A is contained in B, and all of B is contained in C, so all of A must be contained in C. Now, the different situations we have are as follows: $(1)$: $A=B$ and $B \subset C$ $(2)$: $A \subset C$ and $B \subset C$ $(3)$: $A=B$ and $B=C$ $(4)$: $A \subset C$ and $B=C$ So, I would have to make a Venn diagram for each situation?","['discrete-mathematics', 'elementary-set-theory']"
313986,Are vague convergence and weak convergence of measures both weak* convergence?,"For quite a long time, I have been confused about the definitions of weak convergence and vague convergence of measures among other modes of convergence that root from functional analysis, mainly due to many different definitions and theorems from probability books. I would appreiciate it if someone can clarify the terms and give a clear picture of the concepts. (Note that Did has answered some of my related questions before. Thank you, Did!) In Kallenberg's probability book, he defines weak convergence of a
sequence measures to be Consider any probability measures $\mu$ and $\mu_1, \mu_2, \dots$ on some metric space $(S, \rho)$ with Borel a-field $S$, and say
  that $\mu_n$ converges weakly to $\mu$, if $\int f d\mu_n \to \int f
d\mu$ for every $f \in C_b(S)$, the class of bounded, continuous
  functions $f: S \to \mathbb R$. Kallenberg defines vague convergence of a sequence of measures to be Consider the space $\mathcal M = \mathcal M(\mathbb R^d) $of locally finite mea- sures on $\mathbb R^d$. On $\mathcal M$ we may
  introduce the vague topology, generated by the mappings $\mu
\mapsto \int f d\mu$ for all $f \in C_K^+$, the class of continuous
  functions $f: \mathbb R^d \to  \mathbb R_+$ with compact support.
  In particular, $\mu_n$ is said to converge vaguely to $\mu$  if
  $\mu_n f \to \mu f$ for all $f \in C_K^+$. If the $\mu_n$ are
  probability measures, then clearly $\mu(\mathbb R^d) < 1$. Folland in his real ananlysis book defines vague topology and
therefore vague convergence for complex Radon measures on a locally compact
Hausdorff (LCH) space $X$ as weak* topology and weak* convergence wrt
$C_0(X)$. He says the term ""vague"" is common in probability theory,
and has the advantage of forming an adverb more gracefully than
""weak*"". The vague topology is sometimes called the weak topology,
but this terminology conflicts with his, since $C_0(X)$ is rarely
reflexive. In Kai Lai Chung's probability book, a sequence of subprobability
measures $\mu_n$ on $\mathbb R$ are defined to vaguely converge to
another subprobability measure $\mu$, if there exists a dense subset
$D$ of $\mathbb R$ s.t. $\forall a, b \in D, a < b, \mu_n((a,b]) \to
\mu((a,b])$. Next in Chung's, Theorem 4.4.1 says in case of subprobability measures, vague
convergence is equivalent to  weak* convergence wrt $C_0(\mathbb
R)$ and $C_K(\mathbb
R)$. Theorem 4.4.2 says in case of probability measures, vague
convergence is equivalent to  weak* convergence wrt $C_b(\mathbb
R)$. I was wondering if the above definitions of weak convergence and vague convergence are all weak* convergence, in the sense that the measures form (a subset of) the continuous dual of $C_b$, $C_K$, $C_K^+$, and $C_0$? When defining vague convergence and vague topology, why does kallenberg use $C_K^+$ instead of $C_K$, Folland use $C_0$, and Kai Lai Chung uses $C_K$, $C_0$ and $C_b$? Are their definitions of vague convergence consistent with each other? Among the convergences of measures wrt $C_b$, $C_K$, $C_K^+$, and $C_0$, when does which imply which? When is which equivalent to which? The last question is to see if there are some unifications of the above concepts. Can the above definitions be generalized to more general measures (probability measures, subprobability measures, locally finite measures are used in the definitions above), and to more general underlying spaces (metric space, $\mathbb R^d$ and $\mathbb R$ are used in the definitions above)? Thanks and regards!!","['probability-theory', 'measure-theory', 'functional-analysis']"
313991,Is it true that a subset that is closed in a closed subspace of a topological space is closed in the whole space?,"I have a non homework related question from a text and require a nice clear proof/disproof
please Is it true that a subset that is closed in a closed subspace of a topological
space is closed in the whole space? my ideas: if $H$ is the subset of the topological space $X$ if the subset is closed in the closed subspace, the complement is open in the subspace, which means the complement is of form $U\cap H$ for some $U$ open in $X$ if the subspace is closed the complement is open which means complement of $H=U$ for some open $U$ in $X$ kind thanks",['general-topology']
314001,"The space of continuous, bounded functions from a metric space $X$ to $\mathbb R$","Let $(X,d)$ be a metric space. We denote by $C_b(X;\mathbb{R})$ the space of continuous and
bounded functions from $X$ into $\mathbb{R}$, equipped with the sup-norm metric. We define a
mapping  $O: X \to C_b(X;\mathbb{R})$ as follows. Fix a point $x_0\in X$. Given $x\in X$, $O(x)$ is a function from $X$ into $\mathbb{R}$ such that
$O(x)(y) = d(y, x)-d(y, x_0)$:
Show the following. $(i)$ $C_b(X;\mathbb{R})$ is a complete metric space. $(ii)$ For each $x \in X$, the corresponding function $O(x): X \to \mathbb{R}$ is continuous and bounded. $(iii)$ Mapping $x \mapsto O(x)$ yields an isometric embedding of $X$ into $C_b(X,\mathbb{R})$.
Thus every metric space may be isometrically embedded into a complete metric space.","['general-topology', 'metric-spaces']"
314004,Connected components of a topological space,"Let X be a topological space. Define a binary relation $\sim$ in $X$ as follows: $x \sim y$ if there exists a connected subspace $C$ included in $X$ such that $x,y$ belong to $C$. Show the following. (i) $\sim$ is an equivalence relation. (ii) Each equivalence class is a maximal connected subspace of $X$. These equivalence
classes are called the connected components of $X$. (iii) Each connected component is a closed subset of $X$. To this end, show that the closure
of a connected set is connected.","['general-topology', 'connectedness']"
314020,Integral calculus proof,"If $f(x)$ is continuous in $[a,b]$, prove that $ \displaystyle \lim_{n \to \infty} \dfrac{b-a}{n} \displaystyle \sum^n _{k=1} f\left( a + \dfrac{k(b-a)}{n} \right) = \displaystyle \int_a ^ b f(x)dx$ This is my first time I'm exposed to these type of math problems (being a high schooler), so I don't really know how to tackle this. Can anyone point me in the right direction? What I tried: I just tried to see the logic behind the RHS. I see that $\dfrac{b-a}{n}$ divides the interval a,b into n rectangles. What I totally don't understand is why the height of these rectangles is given by the summation of $ f\left(a + \dfrac{k (b-a)}{n}\right)$","['proof-writing', 'integration']"
314041,What does continuity of inclusion means?,"If $A,B,C$ are three spaces such that $A\subset B\subset C$ and $A$ is dense in $C$. Now my teacher said that the inclusion between three spaces are continuous and so you can directly say that $B$ is dense in $C$ . When i asked  him why can't you directly conclude this, he said that the topologies are different and so you need the condition that the inclusions are continuous. I didn't understand what he meant by that?","['general-topology', 'continuity']"
314065,Differentiation under the double integral sign,"Working on three-body dispersion forces I got the following quantity:
$$\frac{\partial }
{{\partial \lambda }}\int\limits_\lambda ^{\pi  - \lambda } {d\theta } \int\limits_\lambda ^{\pi  - \lambda } {d\phi f\left( {\theta ,\phi } \right)} 
$$
where f is independent of $\lambda$. My question is: how can i take the derivative under the double integral sign? In one-dimensional case we have:
$$\frac{d}
{{dx}}\int\limits_{a\left( x \right)}^{b\left( x \right)} {f\left( {x,y} \right)} dy = f\left( {x,b\left( x \right)} \right)b'\left( x \right) - f\left( {x,a\left( x \right)} \right)a'\left( x \right) + \int\limits_{a\left( x \right)}^{b\left( x \right)} {f_x } \left( {x,y} \right)dy
$$
Is there an analogous formula for the two-dimensional case?","['calculus', 'integration', 'derivatives']"
314078,What are the densities of branches of the euclidean tree?,"The Euclidean algorithm shows how all coprime pairs of positive integers can be uniquely obtained from the pair $(1,1)$ by applying the two operations $(a,b) \to (a+b,b)$ and $(a,b) \to (a,a+b)$. (or speaking with rationals, all the positive rationals $x=b/a$ can be obtained from $1$ by applying the two operations $x \to x/(x+1)$ and $x \to x+1$). Furthermore, we know that the natural density of coprime pairs among the pairs of positive integers is $6/\pi^2$. This brings the question : do the set of all childrens of some pair $(a,b)$ have a natural density $d(a,b)$, and if so, what is it ? Allowing to start from any pair of positive reals, we have that $d(ka,kb) = d(a,b)/k$ if those exist, which suggests that we can simply look for a function $d(1,b/a) = f(b/a)$. We have, for symmetry reasons, $f(x) = f(1/x)/x$.
We also have from the tree construction, the functional equation $f(x) = f(x+1) + f(x/(x+1))/(x+1)$. Using the symmetry equation, we can rewrite this to get the nicer functional equation :
$f(x) + f(1/x) = f(1/(x+1)) + f(x/(x+1))$. So, is there anything interesting we can say about these functional equations ? How many continuous (or even, differentiable) solutions does the system have ? Does the density we started with have a nice closed-form expression ?","['functional-equations', 'number-theory']"
314083,How do I evaluate this limit,"$$ \displaystyle \lim_{n \to \infty} \dfrac{1}{n} \displaystyle \sum ^n _{k=1} \dfrac{k^2}{n^2}$$ How do I evaluate this? I have never actually learned how to work with infinite series like this one, so I have no idea.",['sequences-and-series']
314091,Banach-Steinhaus variant,"Let $T_n$ be a sequence of continuous linear operators from a Banach
  space $X$ to a normed linear space $Y$. Now, for all $x \in X$,
  $\lim_{n \rightarrow \infty} T_n(x)$ exists in $Y$. Define $T(x) = \lim_{n \rightarrow \infty} T_n (x)$ on $X$. Show that $$\|T\| \leq \liminf \|T_n\|.$$ Here's my proof: Convergence of $T_n(x)$ implies that for all $x \in X$, $\|T_n(x)\|\leq M_x$ for some $M_x$. The uniform boundedness principle implies $T_n$ is uniformly bounded, in particular, $\liminf  \|T_n\| < \infty.$ Now for all $z \in X$ with $\|z\|=1$, $$\|T(z)\|=\lim \|T_n(z)\| \leq \liminf  \|T_n\| \|z\| = \liminf  \|T_n\|.$$ I'm not too sure about that last line. How can I improve this proof?",['functional-analysis']
314098,Apparent patterns in ratios of consecutive primes,"I was plotting the values of $\frac{P(n+1)}{P(n)+2}$, where $P(n)$ is the nth prime number. I noticed very easily that the values seem to belong very nicely to a set of ""trajectories"". They clearly cannot have arbitrarily values. Of course all these trajectories are decreasing and tend to $1$, except the trajectory for twin primes, which is, of course, $1$. I also made a rough estimate that they can be estimated with functions of the form $1+a/x^b$, the first trajectory above constant $1$ is close to $1+1.1/x^{1.19}$. Is there more info on these trajectories? Given $n$ is smaller than some number, how many trajectories there are in total? By counting from the graph, I would say, if $n<10,000$, there are about 27 trajectories (ie.about 27 different curves where the values fit).","['prime-numbers', 'number-theory']"
314102,"If $f(x_0+x)=P(x)+O(x^n)$, is $f$ $m<n$ times differentiable at $x_0$?","Let $f : \mathbb{R} \to \mathbb{R}$ be a real function and $x_0 \in \mathbb{R}$ be a real number. Suppose that there exists a polynomial $P \in \mathbb{R}[X]$ such that $f(x_0+x)=P(x)+ \underset{x \to 0}{O} (x^n)$ with $n> \text{deg}(P)$. Is it true that for $m<n$, $f^{(m)}(x_0)$ exists? (Of course, it is obvious for $m=1$.) If so, we can notice that $f^{(m)}(x_0)=P^{(m)}(x_0)$.","['asymptotics', 'derivatives', 'real-analysis']"
314113,Dual space of $H^1$,"It holds that $W^{1,2}=H^1 \subset L^2 \subset H^{-1}$. This is clear since for every $v \in H^1(U)$, $u \mapsto (u,v)_{H^1}$ is an element of $H^{-1}$.
Moreover for every $v \in L^2(U)$, $u \mapsto (u,v)_{L^2}$ is an element of $H^{-1}$.
But I also know that $H^1$ is a Hilbert space and therefore it is isomorphic to its dual by the Riesz theorem. My question is: how can there be $H^1(U) \subset L^2(U) \subset H^{-1}$ as well as $H^{-1}$ can be identified with $H^1(U)$?","['sobolev-spaces', 'functional-analysis', 'real-analysis']"
314116,Are any two open connected subsets of $\Bbb{R}^n$ homeomorphic?,"Are any two open, connected subsets of $\Bbb{R}^n$ homeomorphic?  This seems intuitively true.",['general-topology']
314131,Picture of a 4D knot,A knot is a way to put a circle into 3-space $S^1 \to \mathbb R^3$ and these are often visualized as 2D knot diagrams. Can anyone show me a diagram of a nontrivial knotted sphere $S^2 \to \mathbb R^4$ (differentiable)?,"['geometry', 'knot-theory']"
314137,Demonstrate by induction the inequality: $\ln(1+n)\leq\sum_{i=1}^{n}\frac{1}{i}\leq1+\ln(n)$,"Kind of stuck in this one. I've tried substracting
$$\ln(1+(n+1))\leq\sum_{i=1}^{n}\frac{1}{i}+\frac{1}{n+1}\leq1+\ln(n+1)$$
at the original inequality and applying properties of the logarithms, but then I don't know how to keep going :/","['inequality', 'induction', 'sequences-and-series']"
314143,Green's representation as a classical solution of Poisson's equation,"If there exists Green's function $ G(x,y) $ and if we have $ u \in C^2(\Omega) $ such that $$ u(x) = \int_\Omega G(x,y)f(y)dy - 
\int_{\partial\Omega}\frac{\partial G}{\partial\nu}(x,y)g(y)dS(y) $$ then under what conditions of $\Omega, f$ and $g$ will $u$ be a solution of the problem
\begin{equation*}
 \begin{cases}
   -\Delta u = f & in\ \Omega  \\
   u = g & in\ \partial\Omega 
 \end{cases}
\end{equation*}
under usual conditions of $\Omega$ and for $ g \in C^1(\partial\Omega) $ it can be checked that $ u = g $ in $ \partial\Omega$ but how to calculate Laplacian of $u$ ?","['multivariable-calculus', 'partial-differential-equations']"
314159,How many different necklaces problem,"How many different necklaces can be made from 20 beads, each of a
  different color? If I think this problem too simple then, I would answer (20-1)!. However now I thought that for example assume that we have 3 beads: blue-yellow-green. Then the blue-green-yellow necklace seems to be the same with blue-yellow-green necklace. (When I turn the first necklace, I can get the second one.) So I am wondering, is the number of different necklaces can be obtained is always the half of the ring permutation number? I mean for this question, is the answer (20-1)!/2 ? Also, how could I do the math if for example 5 of those beads were to be the same color? Would ((20-1)! / 5!) / 2 be the right answer? Regards Xentius",['combinatorics']
314164,On Group of order $30$ and $60$.,"In this question on yahoo answers , 
the answer says , ""with $t = 6$, then there are 6 * (5 - 1) = 24 elements of order $5$ "" my question is , how did "" 6 * ( 5 - 1 ) "" come from ? Which theorem is used here ? The same question for "" with $s = 10$, there are at least 10 * (3-1) = 20 elements of order $3$"" Another question: In dummit and foote , 3rd ed , in page $145$ in prop $21$ which proves that if $G$ is a group of order 60 and  $G$ has more than one sylow 5-subgroup  then G is simple The proof says , suppose the oposite , let $H$ be a proper normal subgroup of $G$ 
if $5$ divides $ |H| $ 
then $H$ contains a sylow 5-subgroup of $G$ and since $H$ is normal then it contains all the conjugates of this sylow 5-subgroup , so , in particular 
$ |H|$ is bigger than or equal to $ ( 1+(6 . 4) ) = 25$ My question is , how did the calculation "" $ |H|$ is bigger than or equal to $ ( 1+(6 . 4) ) = 25$ "" come from ?","['simple-groups', 'abstract-algebra', 'sylow-theory', 'finite-groups', 'group-theory']"
314183,Is the series $\sum_{n=1}^\infty \frac{n^2}{2^{\sqrt n}}$ convergent?,"Is this series convergent?
$$\sum_{n=1}^\infty \frac{n^2}{2^{\sqrt n}}$$ Edit: I'm sorry I wrote a double negative. This is the series.
(thanks Brian M. Scott for editing)","['convergence-divergence', 'sequences-and-series']"
314199,What values of $a$ make the series $\displaystyle \sum_{n=0}^{\infty}\frac{n!2^n}{e^{an}n^n}$ convergent?,I would like to find what values of $a$ make the following series convergent $$\sum_{n=0}^{\infty}\frac{n!2^n}{e^{\large an}n^n}$$ I started applying $n$-root but i don't know how to solve $$\lim _{n\to +\infty}\frac{\sqrt[n]{n!}}{n}$$ If there are other ways to solve the problem i would be glad to know them too! Thank you very much! I do not want to use Stirling's formula,['sequences-and-series']
314215,Derivative/Jacobian of the matrix logarithm,"I need help finding the Jacobian of the matrix logarithm function, i.e. $\log{M} = R$ defined by $e^R = M = V\begin{bmatrix}e^{\lambda_1} & & \\ & \ddots & \\ & & e^{\lambda_n} \end{bmatrix}V^{-1}$ (where $V\begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix}V^{-1}$ is the eigendecomposition of $M$). Anyway, I've found some presentations like this one but found them totally impenetrable. If it helps, I don't need the derivative in a completely general situation. In my case $M$ is a $3 \times 3$ rotation matrix, and immediately after taking the logarithm I take the Frobenius norm, so I can shortcut those two operations with $||\log{M}||_F = 2\sqrt{\theta}$ as detailed on Wikipedia . However, I'm not sure if I can extend the shortcut to say $\frac{\partial}{\partial M}||\log{M}||_F = 2\theta^{-\frac{1}{2}}$. And anyway, the calculation of $\theta$ depends on arccosine which has nasty discontinuities so that is not an ideal method.","['matrices', 'calculus', 'multivariable-calculus', 'euclidean-geometry']"
314220,Variance of time to find first duplicate,"In repeated uniform sampling from $\{1,\dots,n\}$  the mean time $E(X)$ to find the first duplicate is asymptotically $\sqrt{n\pi/2}$. What about  the variance? The variance is $E(X^2) -E(X)^2$. $$E(X^2) = \sum_{x=1}^{\infty} P(X \geq \sqrt{x}) = \sum_{x=1}^{\infty} \prod_{\ell = 1}^{\lfloor \sqrt{x} \rfloor} \frac{n-\ell}{n}$$ $$ \sum_{x=1}^{\infty} \prod_{\ell = 1}^{\lfloor \sqrt{x} \rfloor} \frac{n-\ell}{n} \approx \int_{x=1}^{\infty} e^{\frac{-x}{2n}} \sim 2n$$ So $\mathrm{Var}(X) \sim \left(2-\frac{\pi}{2}\right)n \approx 0.43n$. Can we make this rigorous?","['birthday', 'probability']"
314239,"If $P_1 , P_2 $ are two $p$-sylow subgroups, prove that $ P_1 \bigcap $ $P_2$ = $ { 1 } $","If $P_1 , P_2 $ are two sylow $p$ -subgroups of the group $G$ prove that: $ P_1 \bigcap $ $P_2$ = $ { 1 } $ I tried to prove it by induction as follows: proved it when $P_1 , P_2$ have the order p for some prime p then supposed it is true when the sylow p-subgroup has the order $p^n$ and supposed that there is some element in the intersection ,
made $H$ = the subgroup generated by this element "" say , x "" I proved that H is normal subgroup of $P_1$ , $P_2$ , and made the factor group, $P_1$ mod $H $ = $Q_1$ and $P_2$ mod $H$ = $Q_2$ So by the induction, if $h$ $\in$ the intersection of $Q_1 , Q_2$ then $Q_1$ = $Q_2$ But, I couldn't determine the element which is in this intersection--I don't know if this element $h$ must be exist or not - I don't know what is the next step now; I need some hints to prove this statement: I found that the text - dummit and foote - use the fact that the intersection of two sylow p-subroup is the identity element, but it didn't prove this fact so I look for a proof.","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
314240,Matrix with rank $1$,"Let $A=(a_{ij})_n$ a symmetric matrix with positive coefficients. We suppose that there is $\alpha>0$ such that, for all permutation $\sigma$ of $\{1,\ldots,n\}$, we have
$$a_{1\sigma(1)}a_{2\sigma(2)}\cdots a_{n\sigma(n)}=\alpha.$$
How to prove that the rank of $A$ is $1$? Please any suggestions?","['matrices', 'linear-algebra']"
