question_id,title,body,tags
2727819,Prove that $E((X-a)^2)$ is minimized when $a=E(X)$,"$X$ is an arbitrary continuous random variable. I tried to do this by saying since $X-a$ is squared that means its lowest possible value is 0 and then I tried to solve for $a$ when the expression is $0$. $$
\begin{align}
E((X-a)^2)&=0\\
E(X^2)-2aE(X) +a^2&=0\\
a^2-2aE(X)+E(X)^2&=E(X)^2-E(X^2)\\
(a-E(X))^2&=E(X)^2-E(X^2)\\
a-E(X)&=\sqrt{(E(X))^2-E(X^2)}\\
a&=E(X) \pm\sqrt{(E(X))^2-E(X^2)}\\
\end{align}
$$ Now I don't know if there's some trick to say that $\sqrt{(E(X))^2-E(X^2)}=0$ or if I'm barking up the wrong tree with this approach.",['probability']
2727839,How does passing to ideals solve the problem of unique factorization?,"$A:=\mathbb{Z}[\sqrt{-5}]$ is not a UFD, because for instance
$$21 = 3 \cdot 7 = \left( 1+2\sqrt{-5}\right) \cdot  \left(1-2\sqrt{-5}\right).$$
But since $A$ is a Dedekind domain, we should have unique factorization of ideals into prime ideals (this is, after all, the whole point of introducing Dedekind domains). But is it not the case that the ideals $(3)$,$(7)$,$\left( 1+2\sqrt{-5}\right)$,$\left( 1-2\sqrt{-5}\right)$ are all different prime ideals and that 
$$(21) = (3) \cdot (7) = \left( 1+2\sqrt{-5}\right) \cdot  \left(1-2\sqrt{-5}\right)?$$
What am I missing?","['number-theory', 'dedekind-domain', 'algebraic-number-theory']"
2727905,ODE- Maximal interval,"I am working on the following problem from Gerald Teschl's book on ODE's and am at a loss of how to proceed. Consider a first-order autonomous equation in $\mathbb{R}^1$ with $f(x)$ Lipschitz. Suposse $f(0)=f(1)= 0$. Show that solutions starting in $[0,1]$ cannot leave this interval. What is the maximal interval of definition $(T_{-},T_{+})$ for solutions starting in $[0,1]$? Does such a solution have a limit as $t\rightarrow T_{+}$ or $t\rightarrow T_{-}$ ? Any help would be appreciated. Thanks!","['lipschitz-functions', 'ordinary-differential-equations']"
2727925,Kodaira dimension elliptic K3s,"I can't find a reference for this, so hopefully this isn't too trivial. By the classification of surfaces by Kodaira dimension, elliptic surfaces have $\kappa = 1$ while K3 surfaces fall into the category of $\kappa = 0$.  However, elliptic K3 surfaces exist.  What would the Kodaira dimension be for such a variety? I'm not sure if there is a distinction in the definition of an elliptic K3 compared to a general elliptic surface --- i.e., they are both defined to have an elliptic fibration.  An elliptic K3 doesn't seem to be ""more"" elliptic than it is a K3 surface, and conversely.","['complex-geometry', 'algebraic-geometry']"
2728006,Finding Geodesics on the Unit Cylinder,"I am currently working through a problem in Andrew Pressley's Elementary Differential Geometry. Question 9.2.1 Let $p$ , and $q$ be two distinct points on the unit cylinder. Show that there are either two or infinitely many geodesics whose end points are $p$ and $q$ . The first part of this question is quite easy. Suppose $p$ and $q$ lie on the same circular arc around the unit cylinder. Then there are exactly two geodesics joining $p$ and $q$ . But I can't seem to figure out how there are infinitely many geodesics if $p$ and $q$ don't lie on the same circular arc. The book says that there are infinitely many helices joining the points. That is easy enough to understand, but to be a geodesic don't the helices need to be locally length minimizing? How can this be? Any help would be greatly appreciated!","['differential-geometry', 'surfaces', 'geodesic']"
2728009,Divisibility property for sequence $a_{n+2}=-2(n-1)(n+3)a_n-(2n+3)a_{n+1}$,"Let $(a_n)$ be the sequence uniquely defined by $a_1=0,a_2=1$ and $$
a_{n+2}=-2(n-1)(n+3)a_n-(2n+3)a_{n+1}
$$ Can anybody show (or provide a counterexample) that $p|a_{p-2}$ and $p|a_{p-1}$ for any prime $p\geq 5$ ? I have checked this fact for $p\leq 200$ .","['recurrence-relations', 'modular-arithmetic', 'sequences-and-series']"
2728053,Suppose that $q: X\to Z$ and that $p: X\to Y$ are covering spaces. Suppose there is a continuous function $r: Y\to Z$ such that $r\circ p=q$.,"Let $X,Y,Z$ be arc-connected and locally arc-connected spaces. Suppose that $q: X\to Z$ and that $p: X\to Y$ are covering spaces. Suppose there is a continuous function $r: Y\to Z$ such that $r\circ p=q$. Prove that $r$ is also a covering space. We know that $r$ is continuous, so we can only verify that $r$ is surjective and that if $c\in Z$ then there is an open $U$ of $Z$ such that $r^{-1}(U)=\sqcup_{\alpha\in A}V_{\alpha}$ where $V_{\alpha}$ are open in $Y$ for all $\alpha\in A$ and $r|_{V_{\alpha}}: V_{\alpha}\to U$. To see the overjection, let's take $c\in Z$, therefore there is a $a\in X$ such that $q(a)=c$ since $q$ is surjective it because it is a covering function. Then $r(p(a))=c$ and as $p(a)\in Y$, then $p(a)$ is a preimage of $c$ and so $r$ is onto. Let $c\in Z$, since $q$ is a covering application, there is an open $U$ of $Z$ such that $c\in U$ and $q^{-1}(U)=\sqcup_{\alpha\in A}V_{\alpha}$ and $q|_{V_{\alpha}}: V_{\alpha}\to U$ is a homeomorphism. Consider the family $\{p(V_{\alpha})\}_{\alpha\in A}$, let's see that $r^{-1}(U)=\sqcup_{\alpha\in A}p(V_{\alpha})$ and that $r|_{p(V_{\alpha})}: p(V_{\alpha})\to U$ is a homeomorphism. In effect, as $r\circ q$, then $p(q^{-1}(U))=p(\sqcup_{\alpha\in A}V_{\alpha})=\sqcup_{\alpha\in A}p(V_{\alpha})$ but $r^{-1}(U)=p(q^{-1}(U))=\sqcup_{\alpha\in A}p(V_{\alpha})$. How do I prove that $r|_{p(V_{\alpha})}: p(V_{\alpha})\to U$ is a homeomorphism? Thank you very much.","['algebraic-topology', 'general-topology', 'proof-verification']"
2728065,How has this result been obtained??,"We have the quadratic equation $$ 2y^2 -(1+x)y + x = 0 $$ The author derives the following result from the above equation - $$ y' = \frac{y-1}{4y-1-x} = \frac{(x-3)y-x+1}{x^2-6x+1} $$ Now, I understand the first part. It has been obtained by simply differentiating w.r.t to $x$ and then solving for $y'$. But, I am unable to obtain the second part. I have tried lot of different substitutions, but haven't been able to arrive at the result. Please help!!","['quadratics', 'ordinary-differential-equations', 'proof-explanation']"
2728070,"Understanding Duhamel's principle, PDE","so i'm really having a problem with Duhamel's principle, i'll explain what i know and if possible could someone help me fix my lack of understanding. Thanks! so from my understanding of Duhamel's principle, if we have an inhomgenous PDE (for example the heat equation) such as (Current case is finite domain $(0,a)$ ) $$u_t = Du_{xx}+f(x,t),~~~ u(x,0)=\phi(x) \\ u(0,t)=h(t), ~~~~~~ u(a,t)=g(t)$$ my first issue, in the above we have inhomogenous boundry conditions, if we had homogenous boundry conditions can i still use Duhamel's principle?  (Despite the fact that i could solve it using Seperation of variables) or is the inhomogenous BC's the ""signal"" to use Duhamels principle? First we find $v(x,t)$ which satisfies an auxiliary question $$v_t=Dv_{xx},\\~~v(x,0) = 0 \\ v(0,t)= g(t), ~~~~~~~~~~~~~~~~ v(a,t) = h(t)$$ which basically comes down to finding an interpolation of h and g. (so long as its matchs the boundary conditions its all good). Second: we solve the problem $$w_t = Dw_{xx}+f(x,t), \\w(x,0)= \phi(x) \\ w(0,t)= w(a,t) = 0$$ with solution $$w(x,t) = \sum w_n(t) \sin{\frac{\pi n x}{a}}$$ $$\text{ where } w_n(t) = w_n(0)e^{\frac{-D \pi^2 n^2 t}{a^2}} + e^{\frac{-D \pi^2 n^2 t}{a^2}} \int_{0}^{t} e^{\frac{-D \pi^2 n^2 s}{a^2}} f_n(s)ds$$ $$w_n(0) = \frac{2}{a}\int_0^{a} \phi(x) \sin{\frac{\pi n x}{a}} dx$$ and $$f_n(x) = \frac{2}{a}\int_0^a f(x,t)\sin{\frac{\pi n x}{a}}$$ then the solution to our original problem is $$u(x,t) = v(x,t) + w(x,t)$$ step 1: Solve a shifted problem by finding $v(x,t)$ which satisfies the Boundary conditions from the general problem. step 2: solve the inhomogenous problem with homogeneous boundary conditions, whilst keeping the initial condition step 3: Sum the two. i believe this is the method to use the principle. In this instance (in terms of the heat equation) we have an external source which is adding values to the PDE. so the problem with solution v(x,t) is akin to shifting the initial amount of energy in the system by $\phi(x)$ and eliminating the external source. (this makes sense because if we dont have the external source then we should have zero initial energy also extending the principle to neumann conditions. are all we doing again defining v to solve the boundary conditions in terms of $v$ and $v_t$ ? in the next scenario we have 1 dimensional infinite domains so
our problem is $$u_t = Du_{xx}+f(x,t) \\ u(x,0) = \phi(x)$$ in this instance we dont have boundary conditions so we solve the following $$v_t=Dv_{xx}, \\v(x,0) = \phi(x)$$ ie we eliminate the source again and have a solution of $$v(x,t) = \int_{\mathbb{R}}\Phi(x-y)\phi(y)~dy$$ next we solve $$w_t = Dw_{xx}+f(x,t) \\ w(x,0) = 0$$ which again gives $$w(x,t) = \int_0^t \int_{\mathbb{R}}\Phi(x-y,t-s)f(y,s)~dyds$$ which are true due to the translational and diliational invariance of the heat equation. finally $u = v +w$ so to me it seems that practically we eliminate our initial condition and source term from our problem. solve the equation, then solve a new equation with the source term but no initial condition, and sum the two. intuitively i have no idea why. or whether my understanding of the procedure is correct (in fairness ive been going over this for the last few days, tried researching it and at this point just frazzled) any help guys and girls? thanks for the help. Update: after having let my brain deglaze a bit and then redoing some research on the subject i've built up a little bit more of an intuitive rationale why, again i would need people to help confirm. from my current understanding the arguement is that a non-homogenous system is akin to a homogenous one where at some time period s < t a source term starts adding in energy to the system, in that case what we're really doing is just kind of ""Psuedo"" scaling back time and since v and w both solve our ""basic"" version of the heat equation they can be considered particular solutions that correspond to the different set ups of the system, Ie one solves for the Boundary conditions and one solves for the source itself. am i on the right lines? update 2: ive found a pdf on the physics exchange which explains the procedure more accurately. A better explination of procedure than mine","['multivariable-calculus', 'heat-equation', 'partial-differential-equations']"
2728079,Special smooth non-analytic function,"Is there a smooth function $f:\mathbb{R} \rightarrow \mathbb{R}$ such that $f(x)=0 
$  $\forall x\leq 0$, $f(x)=1 $  $\forall x\geq 1$, and it is mononically increasing?","['real-analysis', 'analytic-functions', 'functions']"
2728114,Evaluating $\prod^{100}_{k=1}\left[1+2\cos \frac{2\pi \cdot 3^k}{3^{100}+1}\right]$,Evaluate$$\prod^{100}_{k=1}\left[1+2\cos \frac{2\pi \cdot 3^k}{3^{100}+1}\right]$$ My attempt: $$1+2\cos 2\theta= 1+2(1-2\sin^2\theta)=3-4\sin^2\theta$$ $$=\frac{3\sin \theta-4\sin^3\theta}{\sin \theta}=\frac{\sin 3\theta}{\sin \theta}$$ I did not understand how to solve after that. Help required.,['trigonometry']
2728124,What finite groups always have a square root for each element?,"If $G$ is an odd cyclic group of order $n$ , then each element $g$ of $G$ has another element $h$ such that $h^2=g$ . This is because $2 x = y \mod n$ is solvable for $x$ . (Note this is not the same as solving $x^2=y \mod n$ .) What other finite groups have this property?","['finite-groups', 'square-numbers', 'group-theory']"
2728168,Orbit/stabiliser of an action,"Question. Suppose $X=\{\heartsuit,\diamondsuit,\clubsuit,\spadesuit\}$ and $\pi$ is an action of $\mathcal{D}_8=\{1,r,r^2,r^3,s,rs,r^2s,r^3s\}$ satisfying $$\pi_r(\heartsuit)=\spadesuit,\quad\pi_r(\diamondsuit)=\clubsuit,\quad\pi_r(\spadesuit)=\heartsuit,\quad\pi_r(\clubsuit)=\diamondsuit,$$ $$\pi_s(\heartsuit)=\diamondsuit,\quad\pi_s(\diamondsuit)=\heartsuit,\quad\pi_s(\spadesuit)=\spadesuit,\quad\pi_s(\clubsuit)=\clubsuit.$$
Find the orbit and stabiliser of $\diamondsuit$. My initial thoughts was constructing $\pi_g$ for all $g\in\mathcal{D}_8$, for instance $$\pi_{rs}(\heartsuit)=\pi_r\circ\pi_s(\heartsuit)=\pi_r(\diamondsuit)=\clubsuit,$$ $$\pi_{rs}(\spadesuit)=\pi_r\circ\pi_s(\spadesuit)=\pi_r(\spadesuit)=\heartsuit,$$ $$\pi_{rs}(\diamondsuit)=\pi_r\circ\pi_s(\diamondsuit)=\pi_r(\heartsuit)=\spadesuit,$$ $$\pi_{rs}(\clubsuit)=\diamondsuit.$$ Incidentally, continuing this gives $$\pi_{r^2s}(\diamondsuit)=\heartsuit,\quad\pi_{r^2s}(\heartsuit)=\diamondsuit,\quad \pi_{r^2s}(\clubsuit)=\clubsuit,\quad\pi_{r^2s}(\spadesuit)=\spadesuit.$$ $$\pi_{r^2}(\diamondsuit)=\diamondsuit,\quad\pi_{r^2}(\heartsuit)=\heartsuit,\quad\pi_{r^2}(\spadesuit)=\spadesuit,\quad\pi_{r^2}(\clubsuit)=\clubsuit.$$ Should I find it strange that this coincides with $\pi_1(g)?$ $$\pi_{r^3}(\diamondsuit)=\clubsuit,\quad\pi_{r^3}(\heartsuit)=\spadesuit,\quad\pi_{r^3}(\spadesuit)=\heartsuit,\quad\pi_{r^3}(\clubsuit)=\diamondsuit.$$ $$\pi_{r^3s}(\diamondsuit)=\spadesuit,\quad\pi_{r^3s}(\spadesuit)=\heartsuit,\quad\pi_{r^3s}(\heartsuit)=\clubsuit,\quad\pi_{r^3s}(\clubsuit)=\diamondsuit.$$ $$\pi_1(\diamondsuit)=\diamondsuit,\quad\pi_1(\clubsuit),\quad\pi_1(\heartsuit)=\heartsuit,\quad\pi_1(\spadesuit)=\spadesuit.$$ So now, by definition, we have that the stabiliser of $x$ is the set of elements of $G$ that keep $x$ fixed under the action. From the above computations; we see $$\text{Stab}(\diamondsuit)=\{1, r^2\}.$$
Similarly, by definition, we have that the orbit of $x$ is the set of possible destinations $x$ goes to under the action. From the above computations; we see $$\text{Orb}(\diamondsuit)=\{\heartsuit, \spadesuit, \diamondsuit, \clubsuit\}.$$ I think my final answer is right; the Orbit-Stabiliser theorem seems to hold here. So, while I guess the way I did it wasn't too exhausting an approach; but I feel like my approach is quite naive and that there's a more savvy way to do this. I'd be very grateful for a pointer in the right direction for me to be better at this type of question in the future. Thanks in advance.","['group-actions', 'group-theory']"
2728171,The étale topos of a scheme is the classifying topos of...?,"By a theorem of Joyal and Tierney, every Grothendieck topos is the classifying topos of a localic groupoid. It has been proved (e.g. C. Butz. and I. Moerdijk. Representing topoi by topological grupoids. Journal of Pure and Applied Algebra 130, 223-235, 1998) that topoi ""with enough points"" admit actually a representation as classifying topoi of topological groupoids. Now my question is the following: take a well-known topos, as the étale topos for a scheme. This is the classifying topos of a localic groupoid, but which one? Do you know if someone has ever investigated that? Thank you in advance.","['algebraic-topology', 'groupoids', 'topos-theory', 'algebraic-geometry']"
2728202,"What are the ""fancy linear-algebra methods"" that would allow me to solve this physics problem without Kirchhoff's Rule?","This might be better suited for the Physics Stack Exchange, if that's the case feel free to migrate it there. I'm also not terribly familiar with the tagging here on the Mathematics SE so if I tagged incorrectly, I'd appreciate any improvements. I was studying for an upcoming undergraduate Physics exam when I found this slidedeck from another university. I don't attend Rochester, so I obviously wasn't at that lecture, but there's an interesting bit on Page 5 that notes that the system of equations used to solve the problem can be converted into a matrices to be solved using linear algebra. Now while my physics skills are pretty mediocre, I really enjoy linear algebra, so I was curious as to what the ""fancy linear-algebra methods"" mentioned on Slide 7 might be. The slides say that it would involve finding the inverse of the 6x6 matrix, which I assume would entail putting it in an augmented matrix with the 6x6 Identity Matrix and row reducing, and then left multiplying both sides. That doesn't sound too fancy to me, although it may have simply been sarcasm on the professor's part. Is there something I'm missing or is it just row reduction and left-multiplying?","['matrices', 'physics', 'linear-algebra']"
2728248,"Show every prime $p\equiv 1,3$ (mod 8) can be written as $p=x^2+2y^2$","Let $K=\mathbb{Q}(\sqrt{-2})$. Show that $\mathcal{O}(K)$ is a principal ideal domain. Deduce that every prime $p\equiv  1, 3$ (mod 8) can be written as $p = x^2 + 2y^2$ with $x, y \in \mathbb{Z}$. As $−2$ is squarefree $6\equiv 1$ (mod 4) we have $\mathcal{O}(K) = \mathbb{Z}[
\sqrt{2}$]. The
discriminant is $\Delta$ = −8. The degree $n = 2$. The signature is $(0, 2)$. Thus the Minkowski bound is $$ B_k = \frac{2!}{2^2}=\frac{4}{\pi}\times \sqrt{8} = \frac{4\sqrt{2}}{\pi}<2$$ Hence $Cl(K)$ is generated by the empty set of ideal classes and so $Cl(K) = \{1\}$. So this means $\mathcal{O}(K)$ is a principal ideal domain I believe... Ok, now if we let $p \equiv 1$ or $3$ (mod 8). By quadratic reciprocity, $−2 ≡ \alpha^2$
(mod p) for
some integer $\alpha$. Thus $$X^2 + 2 ≡ (X + \alpha)(X − \alpha) \quad\text{(mod}~~ p).$$ Ok, now I am slightly stuck, can we apply some theorem here? Not sure if what above is correct to get to the desired result","['number-theory', 'proof-verification']"
2728290,Function and its derivatives at infinity,Let $ f: \mathbb{R} \to \mathbb{R}$ be a doubly differentiable function. Suppose that $ lim_{x \to \infty} f(x) = 0 $ and $ lim_{x \to \infty} f''(x) = 0 $. Does this imply that $ lim_{x \to \infty} f'(x) = 0 $?,"['real-analysis', 'asymptotics', 'functions']"
2728309,"Representation of a sphere as $\left\{\theta \in [0,2\pi], \phi \in [0,\pi], R\in [0, r]\right\}$","In spherical coordinates, a sphere can be described as $S = \left\{\theta \in [0,2\pi], \phi \in [0,\pi], r\in [0, R]\right\}$ by letting  $x = r\sin \pi \cos \theta, ~ y= r \sin \phi \sin \theta,$ and $z= r\cos \phi$ in the equation $x^2+y^2+z^2 = R$. This apparently comes from the parametrisation after considering the top surface and bottom surface by drawing a picture. I've tried, but I'm honestly incapable of thinking geometrically. Question 1: Could someone explain how one can come to this representation algebraically? Question 2 : If we consider the region between the sphere $x^2+y^2+z^2 = R$ and the cone $z = \sqrt{x^2+y^2}$, the upper bound for $\phi$ changes and everything else stays the same:  we have $$S'=\left\{\theta \in [0,2\pi], \phi \in [0,\pi/4], r\in [0, R]\right\}$$ Why is that? I'm thinking because we're only considering a quarter of the sphere, but I'm not sure.",['multivariable-calculus']
2728317,What is lost when we move from reals to complex numbers? [duplicate],"This question already has answers here : What do we lose passing from the reals to the complex numbers? (2 answers) Closed 6 years ago . As I know when you move to ""bigger"" number systems (such as from complex to quaternions) you lose some properties (e.g. moving from complex to quaternions requires loss of commutativity), but does it hold when you move for example from naturals to integers or from reals to complex and what properties do you lose?","['abstract-algebra', 'complex-numbers']"
2728383,Proving the Harnack Inequality for Harmonic Functions,"I am putting together a proof for the Harnack inequality for harmonic functions defined on a balls. I would like to do this using the mean value property of Harmonic functions. I am thinking of doing this. Let us fix $x_0$, $y_0$ in some ball of radius $r$ centered around the origin. Now, we will construct two sub-balls around each of these balls. Specifically, let us take some arbitrarily small $\epsilon$ ball around $x_0$. Now, if we take $\epsilon$ small enough we can contain this sub-ball in a ball $B_{r_{y_0}} (y_0)$ around $y_0$ such that the ball around $y_0$ is a subset of our original ball $B_r$ on which the function is defined/harmonic. The mean value property then tells us that:
$$
C(\epsilon) \cdot u (x_0)  = \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x
$$
and moreover:
$$
C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y
$$
Moreover, because the domain of the $y$ integral contains the domain of the $x$ integral:
$$
C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y \geq \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x = C(\epsilon) \cdot u (x_0) 
$$
Hence:
$$
\frac{C(r_y)}{C(\epsilon)} u(y_0) \geq u(x_0)
$$
Now, my only issue with the above proof is dependencies. Specifically, it seems like my choice of constants determined is a function of the initial points I choose, which does not seem to be correct (through the general statement of the inequality). Could someone please help me verify if this is correct?","['real-analysis', 'harmonic-functions', 'partial-differential-equations', 'proof-verification', 'multivariable-calculus']"
2728401,Subgroup $H$ of $\mathrm{GL}_n(\mathbf{R})$ where elements are of $H$ are matrices with only positive entries,"Suppose $H$ is a subgroup of $\mathrm{GL}_n(\mathbf{R})$ with the property that any element $h$ of $H$ is represented as a matrix with non-negative entries. Two examples of $H$ I can think of include the group of diagonal matrices with positive entires and the group of permutation matrices. Let $K$ be the group generated by these two subgroups. Because the formula for the inverse of a 2x2 matrix is available, as the inverse of any element of $H$ must also be in $H$, I can show that any such $H$ must be a subgroup of $K$ in this case. My question is whether for $n \geq 3$ that $K$ contains any such $H$.","['representation-theory', 'group-theory']"
2728419,Recurrence relation without modulo,"So I have this function, $f(n)$. If $n$ is odd it equals $2$, if $n$ is even it equals $1$. For example, $f(1) = 2$ and $f(2) = 1$. I need to find a recurrence relation for this function. However, I can't figure out at all how to ""properly"" find one by calling $f(n-1)$. I could only find: $$f(n) = \mod(n,2) + 1$$ Is there a way to replace the mod operator to have a proper recurrence relation that returns the same results? EDIT: currently trying out your answers. Please post them as $$f(n) = something. Basically I want $$f(n) when n is greater or equal to 3.","['recurrence-relations', 'modular-arithmetic', 'discrete-mathematics']"
2728424,Evaluate $\int_1^\infty \left(\frac{\log x}{x}\right)^{2011}dx$.,Evaluate $\displaystyle \int_1^\infty \left(\frac{\log x}{x}\right)^{2011}dx$. I've tried to substitute $u$ but that approach hasn't been successful so far.  I've also tried integration by parts but I haven't made any progress so far.  Can someone start me off?  Thanks. EDIT: I've tried substituting $u=\log x$ but that yields only one $\frac1x$ as its derivative.  So the other $\left(\frac1x\right)^{2010}$ is still there.  I've tried integrating by parts by separating $(\log x)^{2011}$ and $\left(\frac1x\right)^{2011}$ and taking either one of them as the derivative of a function but both ended up being even more messy.,"['improper-integrals', 'integration', 'calculus']"
2728438,Show that f is continuous on x if and only if x is irrational,"Let $f : [0, 1] → R$ be given by the formula $f(x) = \frac{1}b$ if $x = \frac{a}b$ , where $a$ and $b$ have no common factor, $f(x) = 0$ if $x$ irrational. Show that $f$ is continuous at $x$ if and only if $x$ is irrational. (Hint: Use the
density properties of rationals and irrationals.) My attempt: Let $\epsilon > 0$ . Suppose $x$ is irrational, then $f(x) = 0$ . $|x-x| < \delta$ $|f(x) - x| = |-x| = x$ So we can choose $\delta = \epsilon$ so that $\epsilon > x$ (I'm unsure of this part). Suppose $x$ is rational, $f(x) = \frac{1}b$ . We want to show that is discontinuous. Suppose there is a $\delta$ that works for $|\frac{1}b-x| < \epsilon$ . Let $\epsilon = \frac{1}2$ . Let $x= \min(\delta, \frac{3}4)$ $|\frac{1}4 - \frac{3}4| = |-\frac{1}2| = \frac{1}2$ And $1/2$ is not greater than a $1/2$ . So it is a contradiction.","['continuity', 'real-analysis', 'functions', 'proof-verification']"
2728447,How do i find $e^{tA}$?,"I've been trying to solve the following system of linear differential equations $$\begin{aligned}
\dot x_1(t) &= 10 x_1(t) + 5 x_2(t) −  5 x_3(t)\\
\dot x_2(t) &= −5 x_1(t) −   x_2(t) +  6 x_3(t)\\
\dot x_3(t) &= −5 x_1(t) − 6 x_2(t) + 11 x_3(t)\\
\end{aligned}$$ with initial state $x (0) = (1,0,1)$ , and I found out that the solution should be $x(t) = e^{tA}x_0$ , where $$A = \begin{pmatrix}
      10 &  5 & -5 \\\
      -5 & -1 &  6 \\\
      -5 & -6 & 11
    \end{pmatrix}$$ How do I calculate the matrix exponential $e^{tA}$ ? I found that $f(A) = C f(J) C^{-1}$ but that still leaves me with the question of how to calculate $f(J)$ ?","['jordan-normal-form', 'matrices', 'matrix-exponential', 'ordinary-differential-equations', 'linear-algebra']"
2728472,Is this function (discontinuous at one point) integrable?,"Consider the function $f:[0,1] \to \mathbb{R}$ defined by $f(0)=0$ and
$$
f(x)=2x\sin\left(\frac{1}{x}\right)-\cos\left(\frac{1}{x}\right).
$$
Is $f$ integrable on $[0,1]$? Ps. Clearly $f$ is discontinuous at $0$ and it has primitive $F(x)=x^2 \sin\left(\frac{1}{x}\right)$. But I don't know whether $\int_0^1 f(x)dx=F(1)-F(0)=\sin 1$. Also, I would say that $f$ is integrable if and only if $g(x)=\cos(1/x)$ for $x>0$ and $g(0)=0$ is integrable on $[0,1]$ (since the remaining term is continuous on $[0,1]$).","['derivatives', 'integration', 'calculus']"
2728520,How many 6-letter strings contain neither the word 'bob' nor 'tim',"If I have a string that is 6-letters long and all lowercase letters, where letters can be repeated , how many strings contain neither the word bob nor tim ? Would I find the number of 6-letter strings that contain bob and the number of 6-letter strings contain tim separately then subtract their sum from the total number of strings possible?","['combinatorics', 'discrete-mathematics']"
2728526,General formula of a composite quadratic function,"I've already found a general formula to composite linear functions, i.e., if I have a function $f(x)=ax+b$, I can find a formula to $f^{(n)}(x)$ as function of the constants $a,b$ and $n$. I want to know if it's possible to find a formula to the n-composite function of $g(x)=ax^2+bx+c$.",['functions']
2728529,Show that $f_n$ is continuous at $0$,"The function in the Lemma $16.1$ is $$f(x)=\begin{cases}e^{-1/x}&\text{for }x > 0\\0&\text{for }x \leq 0\end{cases}$$ (a) To show that $a<e^a$ I have tried to look at the Taylor series of $e^x$ and thus come to the conclusion that $e^a=1+a+a^2/2!+a^3/3!+...$ and therefore $a<e^a$, is this fine? Using the help, we do $a=t/2n$ and so $\frac{t}{2n}<e^{t/2n}$ so $\frac{t^n}{(2n)^n}<e^{t/2}$ so $\frac{t^n}{e^t}<\frac{(2n)^n}{e^{t/2}}$, then, if $t=1/x$ then $\frac{1}{e^{1/x}x^n}< \frac{(2n)^n}{e^{1/2x}}$ and as $\frac{(2n)^n}{e^{1/2x}}\to 0$ if $x\to 0$ we conclude that $\lim_{x\to 0}f_n(x)=0=f_n(0)$. (b) $\lim_{x\to 0}\frac{f_n(x)-f_n(0)}{x}=\lim_{x\to 0}\frac{1}{e^{1/x}x^{n+1}}$, but I do not know how to calculate this limit, could I use what I did in (a)? ($\frac{1}{e^{1/x}x^n}< \frac{(2n)^n}{e^{1/2x}}$) (c) If $x\leq 0$ is clear, then consider $x>0$, from here we have that $f'_n(x)=\frac{x^{n-2}e^{-1/x}-e^{-1/x}nx^{n-1}}{x^{2n}}=x^{-n-2}e^{-1/x}-ne^{-1/x}x^{-n-1}=f_{n+2}(x)-nf_{n+1}(x)$ (d) How do I prove that $f$ is of class $C^{\infty}$? Can I use (c)? Thank you very much.","['real-analysis', 'calculus', 'proof-verification', 'multivariable-calculus', 'vector-analysis']"
2728548,Help with this trigonometric equation,"Here is the equation: $$\sin^5(x) = \frac {\cos(x)}4$$ The answers should be between: 0° and 360° I really tried and I dont even think it is possible to solve algebraically, maybe using numerical methods or other kind of black magic but that is very advanced for my grade. I am in high school.","['elementary-functions', 'trigonometry']"
2728576,"Expression of unitary group , the discrete subgroups and invariants","Let $$G=U(3),$$ be the unitary group. Here we consider $G$ in terms of the fundamental representation of U(3). Namely, all of $g \in G$ can be written as a rank-3 (3 by 3) matrices. What is the convenient way to parametrize the rank-3 matrix in terms of a 9 degrees of freedom (for 9 generators)? Can we find some subgroup of Lie group,  $$k \in K \subset G= U(3) $$  such that $$ 
k^T \{R_1, R_2\} k =\{R_1, R_2\} .
$$
  This means that set $\{R_1, R_2\}$ is invariant under the transformation by $k$. Namely, both cases are allowed:
  $$ 
k^T R_1  k =R_1,\;\;\;  k^T R_2 k =R_2 .
$$
  $$ 
k^T R_1  k =R_2,\;\;\; k^T R_1 k =R_2 .
$$ Here $k^T$ is the transpose of $k$.
What is the full subset (or subgroup) of $K$? Here we define: 
$$
R_1 =
\left(
\begin{array}{ccc}
 0 & 1 & 0 \\
 -1 & 0 & 0 \\
 0 & 0 & 0 \\
\end{array}
\right),\;\;\;\; R_2 =-R_1=
-\left(
\begin{array}{ccc}
 0 & 1 & 0 \\
 -1 & 0 & 0 \\
 0 & 0 & 0 \\
\end{array}
\right).$$ This means that $k^T R_a k=R_b$ which may transform $a$ to a different value $b$, where $a,b \in \{1,2 \}$. But overall the full set $ \{R_1, R_2\}$ is invariant under the transformation by $k$. There must be a trivial element $k=$ the rank-3 identity matrix. But what else can it allow? In particular, I can see an SU(2) and an additional $\mathbb{Z}_2 \times \mathbb{Z}_2$ structure in $K$. How could we determine the complete $K$? Edit: More clarifications. Simplified the problem.","['finite-groups', 'abstract-algebra', 'algebraic-topology', 'lie-algebras', 'lie-groups']"
2728577,Prove $x(t)\geq x(0)e^{\int_{0}^{t} y(s) ds}$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Given conditions on $x(t)$ and $y(t)$ $x(t)$ and $y(t)$ are both infinitely many times differentiable. $x(t)\geq0$ and $y(t)\geq0$ for all $t\geq0$. $x(t)\geq x(0) + $$\int_{0}^{t} y(s)x(s) ds$ Then I need to prove that     $x(t)\geq x(0)e^{\int_{0}^{t} y(s) ds}$ I am just confused how to start, anyone give me some ideas so that I could understand how to begin?","['ordinary-differential-equations', 'calculus']"
2728581,Any deeper insights for why $\int \frac{1}{x}dx = \ln|x|+C$?,"I have already learned that
$$\int x^\alpha \ dx = \cases{\frac{1}{\alpha+1}x^{\alpha+1}+C & if $\alpha\neq-1$ \\ \ln|x|+C & if $\alpha=-1$} \ . $$ I am just curious if there is any deeper insight to explain the abrupt jump from powers of $x$ to the natural logarithm $\ln|x|$ at $\alpha=-1$ , rather than just saying because the coefficient $1/(\alpha+1)$ is undefined when $\alpha=-1$. I have tried plotting things out using Desmos , and the 'jump' at $k=-1$ still doesn't go away. Here is what I did: I plotted a function
$$f_k(x) := x^k$$
with parameter $k$. As I adjust $k$, I can see all the $x^k$, but none of them are close to the plot of $\ln{x}$. My guess: I suspect we need function of two variables to visualize the 'jump'. I tried to construct $g(x, y) := x^y$ and observed what happen at $y=0$. It seems like there is some 'saddle line' parametrized by $(t,0,1)$ for all $t\in\mathbb{R}$. But I'm still not sure how $\ln{x}$ can come into play.","['multivariable-calculus', 'logarithms', 'derivatives']"
2728582,Proving that the cone is not a smooth manifold,"Show that the cone given by $C = \{(x, y, z) \in \mathbb{R}^3 \mid z = \sqrt{x^2 + y^2}\}$ is not a smooth manifold In the definition I'm using of a smooth manifold, each point $x \in M \subseteq \mathbb{R}^k$ (where $M$ inherits the subspace topology from $\mathbb{R}^k$ with the usual topology) has a neighborhood $U$ of $x$ in $M$ such that $U$ is diffeomorphic to some open set of $\mathbb{R}^n$ for some $n > 0$. (This is the definition I'm using from Guillemin and Pollack's Differential Topology book) Now to prove that $C$ is not a smooth manifold I'd have to show that there exists a point $x \in C$ such that any neighborhood $U$ of $x$ in $C$ is not diffeomorphic to any open set of $\mathbb{R}^2$. Now I recall reading that $C$ is a topological $2$-manifold, hence each point of $C$ would have a neighborhood in $C$ homeomorphic to an open subset of $\mathbb{R}^2$. So the smoothness of the homeomorphism must fail at some point in $C$. It seems that smoothness will fail at $x = 0 \in C$. I want to find out how to rigorously prove this. I'm guessing the proof outline will go something like this; Proof Outline: Let $U$ be a neighbourhood of $0$ in $C$ and suppose that there existed a diffeomorphism $f : U \to \widehat{U}$ where $\widehat{U}$ is an open subset of $\mathbb{R}^2$. We show that this results in a  contradiction, hence it will follow that no neighborhood of $0$ in $C$ is diffeomorphic to an open subset of $\mathbb{R}^2$ and hence $C$ consequently will not be a smooth manifold. However since I've picked an arbitrary diffeomorphism $f$, I don't know of any way to go about finding a contradiction. How can I go about proving this? Also in my proof outline I wrote above, the proof really only shows that $C$ is not a smooth $2$-manifold, wouldn't I need to show that $C$ is not a smooth manifold for any $n > 0$? In that case I'm guessing that $C$ wouldn't even be a topological manifold for any $n \neq 2$.","['differential-geometry', 'differential-topology']"
2728592,Example of a plane region with smooth boundary whose polar dual also has a smooth boundary,"I am looking for a concrete example of a compact convex subset $K$ of $\mathbb{R}^2$ with $(0,0)$ center of symmetry, with a smooth boundary ( a $C^{\infty}$ $1$ dimensional submanifold of $\mathbb{R}^2$), such that its polar dual $K^{\circ}$ also has smooth boundary. Even better if both have analytic boundaries. Moreover, $K$ should not be an ellipse. Comments: $K^{\circ}$, the convex dual is defined by 
$$K^{\circ} = \{ v \in \mathbb{R}^2\ | \ \langle v,u\rangle \le 1 \text{ for all } u \in K \}$$ 
(if we use $|\cdot |$ in the inequality we get the same thing). It is easy to see that $K^{\circ}$ is compact, convex and symmetric. Moreover, it is a fact (duality theorem) that $K^{\circ \circ} = K$. Examples: $K=\{(x,y)\ |\  \frac{x^2}{a^2} + \frac{y^2}{b^2}\le 1\}$. Then 
$K^{\circ} = \{(x,y)\ |\  a^2 x^2 +  b^2 y^2\le 1\}$. In general, if 
$K=\{(x,y)\ |\  \frac{|x|^p}{a^p} + \frac{|y|^p}{b^p}\le 1\}$ then $K^{\circ} = \{(x,y)\ | \ a^q |x|^q +  b^q |y|^q\le 1\}$ where $q$ is the Holder dual of $p$. In the above example with $p$, $q$, we see that we cannot make both $K$,$K^{\circ}$ with boundary $C^{2}$, unless $p=q=2$.","['convex-analysis', 'differential-geometry', 'geometry']"
2728646,Why is the integral defined as the limit of the sum $\int_a^b f(x) dx = \lim_{n\to\infty}\sum_{i=1}^n f(x_i^*)\Delta x$? [duplicate],"This question already has answers here : What's the ""limit"" in the definition of Riemann integrals? (5 answers) Closed 6 years ago . I am failing to understand why the integral is defined as: $$\int_a^b f(x) dx = \lim_{n\to\infty}\sum_{i=1}^n f(x_i^*)\Delta x$$ instead of: $$\int_a^b f(x)dx=\sum_{i=1}^\infty f(x_i^*)\Delta x$$ Is the former just popular preference or is there something I am not conceptually understanding here?","['riemann-integration', 'integration', 'calculus', 'limits']"
2728652,Does every circle in $\mathbb{R^2}$ contain a point with rational coordinates? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Is it true that any circle in $\mathbb{R^2}$ contains a point with rational coordinates? what about any simple closed curve? If it is, could you please help me with the proof?","['general-topology', 'real-analysis']"
2728738,"Writing an integrand as divergence, looking for geometric interpretations","Let $ u : \Omega\to \mathbb R$, where $\Omega$ is an open set in $\mathbb R^2$. Let $a\ge 0$. Consider the following integral: $$ \int_\Omega \frac{\det D^2 u}{(1+ |D u|^2)^a} \mathrm d x \mathrm d y.$$ In an answer to another question, it is shown that the above integral depends only on the value of $Du, D^2u$ on the boundary $\partial \Omega$. This is done using some simple argument in calculus of variations. This result is suggesting the following Question : Can the above integrand be (explicitly) written as divergence of something? When $a=0$ it is easy: $$\int_\Omega \det D^2 u \mathrm dx \mathrm dy = \int_\Omega (u_{xx}u_{yy} - u_{xy}^2 )\mathrm dx\mathrm dy = \int_\Omega \mathrm{div}\big( u_xu_{yy} , -u_x u_{yx}\big) \mathrm dx\mathrm dy.$$ When $a = 3/2$, the above integration can be written as 
$$ \int_\Omega K \mathrm dA,$$
where $K$, $\mathrm dA$ are respectively the Gaussian curvature and the area element of the graph $(x, y, u(x, y))$. Thus, again, the integrand can be written as $K\mathrm dA= \mathrm d\omega_{12}$, where $\omega_{12}$ is basically the Christoffel symbols given by $$ \nabla e_1 = \omega_{12} e_2,$$ where $\{e_1, e_2\}$ is an orthonormal frame on the surface (the graph). So $\{e_1, e_2\}$ and thus $\omega_{12}$ can be represented as partial derivatives of $u$ so it is sort of explicit. (Remark: in general for a surface, if the first fundamental form is diagonal $(F=0$), then 
$$K \mathrm dA= \mathrm{div}\bigg( \frac{\sqrt g}{E} \Gamma_{xx}^y \ , - \frac{\sqrt g}{G} \Gamma_{xy}^y\bigg) \mathrm dx\mathrm dy,$$
which is divergence of something. But for a graph $(x, y, u(x, y))$, the first fundamental form is in general not diagonal and it is extremely messy to write down explicitly, though doable). Thus the answer to the question is yes at least when $a = 0, 3/2$. What about the general situation? Also, if the answer is yes, are there any geometric interpretations? (I guess it would be no, since the curvature should be the only geometric invariance).","['riemannian-geometry', 'differential-geometry', 'curvature', 'partial-differential-equations']"
2728747,Union of two compact totally disconnected sets in $\mathbb{R}$ is totally disconnected,"I'm so stuck with the next problem. First, the definition that I have are the next: $X$ is totally disconnected if for all $x\in X$ we have that $C_x=\{x\}$ where $C_x$ is the connected component. Let $A,B\subseteq\mathbb{R}$ be a compact and totally disconnected sets. Prove that $A\cup B$ is also totally disconnected. We have two cases: 1) If $A\cap B=\emptyset$ then, take $x\in A\cup B$ and $C_x$ the connected component of $x$. Because $\mathbb{R}$ is normal and $A,B$ are two disjoint closed sets (they are compacts) then there exists $U,V\subseteq\mathbb{R}$ disjoint open sets such that $A\subseteq U$ and $B\subseteq V$. Therefore, without loss of generality, because $C_x$ is connected, $C_x\subseteq U$ and thus $C_x\subseteq A$. We conclude that $C_x=\{x\}$. 2) $A\cap B\neq\emptyset$. Here is where I'm stuck. Take $x\in A\cup B$ and suppose by contradiction that $|C_x|\geq 2$. Then, $C_x\not\subseteq A$ and $C_x\not\subseteq B$ (because the connected sets in $A$ and $B$ have only one point) but $C_x\cap A\neq\emptyset$ and $C_x\cap B\neq\emptyset$.  I don't know how can I conclude the proof. Any hint? I really appreciate any help you can provide.","['general-topology', 'connectedness']"
2728896,"Is a Frechet space separable, if its dual is?","It is known, and not too difficult to prove that if a dual of a normed space is separable, it is separable itself. Does the same hold for Frechet spaces? (By the dual I mean the dual endowed with the strong topology.)","['functional-analysis', 'general-topology', 'topological-vector-spaces']"
2728923,The image of $\emptyset$ under $f$ is empty.,"Let A= $\{ \emptyset,\{1\},\{2,\},...,\{n\} \}$ . Define $f\colon A \to \mathbb{N}$ such that $f(\emptyset)=0$ and $f(\{n\})=n$ . Is this a counterexample that the image of the $\emptyset$ under an arbitrary function $f$ is empty?","['general-topology', 'elementary-set-theory']"
2728935,Is there a countably additive set function $m$ on $\mathscr{P}(\mathbb{R})$ such that $m(I) = l(I)$ for every interval $I$?,"In the introduction to Chapter 3 (Lebesgue Measure) of H. L. Royden's Real Analysis , he motivates the definition of a measure by saying that we would like to construct a set function $m$ on a collection $\mathscr{M}$ of subsets of $\mathbb{R}$ that assigns a non-negative extended real number to each set $E$ in $\mathscr{M}$ in the following way. Ideally, we should like $m$ to have the following properties: $mE$ is defined for each set $E$ of real numbers; that is, $\mathscr{M} = \mathscr{P}(\mathbb{R})$. For an interval $I$, $mI = l(I)$, where $l(I)$ denotes the length of the interval. If $\{ E_n \}$ is a sequence of disjoint sets (for which $m$ is defined), $m(\cup_n E_n) = \sum_n E_n$. $m$ is translation invariant; that is, if $E$ is a set for which $m$ is defined and if $E + y$ is the set $\{ x + y : x \in E \}$, obtained by replacing each point $x$ in $E$ by the point $x + y$, then $$m(E+y)=mE.$$ He goes on to say that Unfortunately, . . . it is not known whether there is a set function satisfying the first three properties. Does this mean that this is an open problem in measure theory? Has there been any progress on this problem since the textbook was published? Royden does mention in a footnote that assuming the Continuum Hypothesis, one can show that no such function exists. This question asks for details regarding this case.","['real-analysis', 'set-theory', 'measure-theory']"
2728977,Compact embedding in weighted Sobolev spaces,"I have a question concerning Sobolev's embedding. Let (for simplicity) $\Omega=\left(  0,1\right)  $. Then it is well known by
Rellich's theorem that $H^{1}\left(  \Omega\right)  $ is compactly embedded in
$L^{2}\left(  \Omega\right)  $. The situation becomes unclear to me, if I consider a weighted $H^{1}\left(  \Omega\right)  $ space by introducing
the norm $\left\Vert u\right\Vert _{1,w}:=\left\Vert u\right\Vert
_{L^{2}\left(  \Omega\right)  }+\left\Vert xu^{\prime}\right\Vert
_{L^{2}\left(  \Omega\right)  }$ and letting $H_{w}^{1}\left(  \Omega\right)
$ be the closure of smooth and compactly support functions in $\Omega$. Question: Is $H_{w}^{1}\left(  \Omega\right)  $ compactly embedded in
$L^{2}\left(  \Omega\right)  $ or is the embedding only continuous?","['functional-analysis', 'sobolev-spaces']"
2729066,Is $n=13$ the only solution to this: $\pi\left(\sum_{i=1}^n\pi(i)\right)-1=n$.,"I was messing around with the prime counting function $\pi(n)$ because I was bored, but then I noticed something. The equation 
    $$\pi\left(\sum_{i=1}^{n}\pi(i)\right)-1=n,$$ 
    has the solution $n=13$. Are there any numbers like $13$ that satisfy this equation? Is there a way of finding like values? Has this been discovered before? If it can be proven that $13$ is the only number (let alone prime ) with this property, I will feel like Ulam after discovering upon the famous prime spiral. It is otherwise my conjecture as I am unaware of anyone else finding out this property.","['number-theory', 'summation', 'prime-numbers']"
2729117,Minimizing the probability of a draw in a democratic poll,"A group of $k$ people wants to choose democratically between $n$ possible options . They arrange a poll in which every person votes for $r$ out of the $n$ options without repetition , meaning there are $n \choose r$ possible choices per person. The highest scoring option will be the winning choice - unless there's a draw of course... Question: Assuming each person chooses $r$ out of $n$ options with uniform probability. What is the value of $r$ for which the probability of the poll ending in a draw is minimal? Hopefully the answer will be unique and in a closed form $r=f(k,n)$. Sadly beyond trivial remarks about the extreme cases (like $r=n$ implies draw will happen with full probability and $r,k << n$ implies draw will be pretty likely because of sparse voting) I have nothing valuable to say about my attempts so far. Edit: To anyone who downvotes this - please explain what you think is wrong with the question. To make things clear: This is not a homework problem! . Still, if you think this is a trivial problem please explain your solution - if not then please reconsider the downvote.","['combinatorics', 'voting-theory', 'probability']"
2729118,Continuous-time Markov Chain question,"Consider an immigration-death model $X = (X_t)_{t\geq0}$, i.e. a model where immigrants arrive
according to a Poisson process with rate $\lambda$ and individuals have independent $Exp(\mu)$
lifetimes. Suppose $\lambda > 0$. Suppose $X_0 = 0$. (i) Perform a one-step analysis to justify carefully that $\Phi(t) = \mathbb{E}[z^{X_t} ]$ satisfies 
$$\Phi(t)=e^{-\lambda t}+\int_0^t\lambda e^{-\lambda s}\Phi(t-s)(1-(1-z)e^{-\mu(t-s)})ds$$ (ii) Solve the integral equation to determine the distribution of $X_t$. This is an exam question but I can't seem to wrap my head around it: My attempt: $\mathbb{E}[z^{X_t}]=\int_0^{\infty}\mathbb{E}[z^{X_t}|T_1=s]\lambda e^{-\lambda s}ds=\int_0^t\mathbb{E}[z^{X_t}|T_1=s]\lambda e^{-\lambda s}ds+\int_t^{\infty}\mathbb{E}[z^{X_t}|T_1=s]\lambda e^{-\lambda s}ds=\int_0^t\mathbb{E}[z^{X_t}|T_1=s]\lambda e^{-\lambda s}ds+e^{-\lambda t}$ Now my idea is to apply the Markov property at the time $T_1=s$ which is a stopping time. However, I can't finish the proof since I don't get the extra multiplier $(1-(1-z)e^{-\mu(t-s)})ds$ For (ii) I did a standard multiplication and differentiation to get that the following holds: $$\Phi'(t)=-\lambda(1-z)e^{-\mu t}\Phi(t)$$ which after integrating gives $$\Phi(t)=Ce^{\frac{\lambda(1-z)}{\mu}e^{-\mu t}} \text{  for } \mu\neq 0$$ and $$\Phi(t)=Ce^{-\lambda(1-z)t} \text{  for } \mu=0$$ I can't associate this with any distribution and furthermore, I have a feeling I've messed up the calculations since $\Phi(0)$ should equal $0$. Any help is appreciated!","['probability-theory', 'probability-distributions', 'markov-chains', 'markov-process', 'probability']"
2729142,$S^3 \times S^1$ is not a symplectic manifold?,"I was trying to prove that $S^3 \times S^1$ is not a symplectic manifold but got stuck. I consider reasoning by contradiction as follows: Suppose that there is a symplectic form $\omega$ on $S^3 \times S^1$. That is, $\omega$ is a 2 form such that $\mathrm{d}\omega = 0$ and $\omega \wedge \omega \neq 0$. Now, I figure since $\omega \wedge \omega$ is a non-zero 4-form on $S^3 \times S^1$, it is a volume form, but I don't know how proceed, I was thinking I could try to do something along the lines of Proof that $S^4$ is not a symplectic manifold , by computing the de Rham cohomology using the Kunneth formula, but this didn't seem to simplify anything since it seems that that $H_{dR}^4(S^3 \times S^1) \neq \{ 0\} $ (If I have computed this properly). Are any of you able to provide me with a hint?
Thanks. Edit: (Question regarding comment)
I think that the Kunneth formula states that:
$$H^k(S^3 \times S^1) \cong \sum_{k=i+j}H^i(S^3) \otimes H^j(S^1) $$
Using:
$$H^i(S^n) \cong \begin{cases} \mathbb{R} & i=0,n \\ 0 & \mathrm{else} \end{cases} $$
I get:
$$H^2(S^3 \times S^1) \cong (\mathbb{R} \otimes 0) \oplus (0 \otimes \mathbb{R}) \oplus( 0 \otimes \mathbb{R}) $$
I this correct?","['homology-cohomology', 'differential-geometry', 'differential-topology']"
2729150,"CTMC: If the transition probability is >0 at one moment, then it is also >0 from that moment onwards","Assume that $\{X_t:t\geq0\}$ is a continuous-time Markov chain with values on a discrete (countable, but possibly not finite) set $S$. Notation: for $i,j\in S$ and $t\geq0$, $p_{ij}(t):=\mathrm{P}\{X_t=j|X_0=i\}$. I want to prove that, for fixed $i$ and $j$ in $S$, the existence of a $s>0$ so that $p_{ij}(s)>0$ implies $\forall t>s, p_{ij}(t)>0$. I've tried lots of things (within my limited knowledge on the subject) and researched as far as I could, but I can't figure it out and I'm extremely frustrated because it seems really easy. I'll greatly appreciate detailed answers, since I'm afraid of not understanding the intermediate steps. EDIT: As I predicted, it's actually quite simple, but I still want to understand all the details (see comments below).","['stochastic-processes', 'probability-theory', 'markov-chains', 'markov-process', 'statistics']"
2729171,The linear operator $T_A(B)=AB-BA$ defined on $\mathbb M_n(\mathbb C)$ has a null determinant,"Let $T_A:\mathbb{M_n(C)}\rightarrow\mathbb{M_n(C)}$ be a linear operator such that $T(B)=AB-BA$, were $\mathbb{M_n(C)}$ denote the space of matrix with order $n$ and complex inputs. Then $T_A$ has null determinant. Proof: Is sufficient to show that $T_A$ has not inverse, i.e., $T_A$ is not one-to-one. But this is inmediate because $T_A(I)=0$ so, $\ker(T_A)\neq\{0\}$. I have doubts about my proof. It is right?","['matrices', 'linear-algebra', 'proof-verification', 'determinant']"
2729223,Radon Nikodym derivative $\frac{\mathrm d(fλ)}{\mathrm d(gλ)}$,"Here is the question: Consider the space $X = [0,1]$ with Lebesgue measure $\lambda$. Let $\mu = f\lambda$ and $\nu = g\lambda$ with functions $f$ and $g$ nonnegative, be finite measures. Find a condition characterising the absolute continuity $\nu \ll \mu$ and find the Radon Nikodym derivative $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu}$. On the first task, $\forall A \in \mathcal L [0,1]$, we have: $$[\mu(A) = 0 \implies \nu(A) = 0] \iff \\
\big[\int_Afd\lambda = 0 \implies \int_Ag d\lambda = 0 \big] \iff\\
\big[f \chi_A = 0\ (\lambda.a.e)\implies g \chi_A = 0\ (\lambda.a.e) \big].$$ So on whichever sets $f$ is $0$ almost everywhere, g is also $0$ almost everywhere (w.r.t. $\lambda$).
Is this a good characterisation? Can you see a better one? On the second task: I can guess that we have $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu} = \dfrac gf$. We have established in lectures the chain rule$$
\frac{\mathrm{d}\nu}{\mathrm{d}\mu} = \frac{\mathrm{d}\nu}{\mathrm{d}\lambda} \frac{\mathrm{d}\lambda}{\mathrm{d}\mu} = g\frac{\mathrm{d}\lambda}{\mathrm{d}\mu}.
$$
Now I need an argument that justifies $\dfrac{d\lambda}{d\mu} = f^{-1}\ (\lambda. a.e.)$ ""wherever $g \neq 0$"". Not sure how to argue in this way.","['radon-nikodym', 'measure-theory']"
2729236,Let $G$ be a group and $p$ divide the order of G. Show that if $p^2$ divides the order of $G$ then $p$ divides the order of the automorphism group,"Let $G$ be a finite group and $p$ a prime divisor for the order of $G$. Show that if $p^{2}$ divides the order of G, then $p$ divides $|Aut(G)|$ . I know that $G$ has a subgroup of order $p$ and  I think that it would be a good idea to consider the following homomorphism to prove that $Aut(G)$ has a subgroup of order $p$ : $$ \phi :G \to Aut(G)$$ $$\phi(g) = C_{g}$$ where $C_{g}$ is the conjugation given by $g$. Also I know that $Ker(\phi)=Z(G)$ then $G/Z(G) \cong Im(\phi)=Inn(G)$, but I can't figure out how to use the fact that $p^{2}$ divides the order of $G$.",['abstract-algebra']
2729244,"$f$ convex, $g$ concave and increasing, $\int_0^1 f = \int_0^1 g$, then $\int_0^1(f)^2 \geq \int_0^1(g)^2$","Let $f,g:[0,1] \to [0, \infty)$ be two continuous functions such that $$f(0) = g(0) = 0,$$ $f$ is convex, $g$ is concave and increasing and $$\displaystyle \int_0^1f(x)dx = \int_0^1g(x)dx.$$ Prove that $$ \displaystyle \int_0^1\left(f(x) \right)^2dx \geq \int_0^1\left(g(x) \right)^2dx.$$ I don't quite know how to approach the problem. I thought about using Chebyshev's inequality due to the fact that $g$ is increasing, $F(x) = \int_0^xf(t)dt$ is increasing (since $f$ is convex) and $G(x) = \int_0^xg(t)dt$ is increasing (since $g$ is increasing and $g(0) = 0$), but it didn't help me. I also tried to obtain something by writing the convexity and concavity point-wise and using the fact that $\displaystyle h(x) = \frac{f(x)}{x}$ is increasing and $p(x) = \displaystyle \frac{g(x)}{x}$ is decreasing, but I got nothing.","['real-analysis', 'inequality', 'definite-integrals', 'integral-inequality']"
2729266,Isomorphisms of finite abelian groups,"I'm studying Hungerford's ""Abstract Algebra - An Introduction"". In its chapter 9.2 Hungerford gives an example of a characterization up to isomorphism of all finite groups of order 36. For this he uses the Fundamental Theorem of Finite Abelian Groups. The theorem states: ""Every finite abelian group $G$ is the direct sum of cyclic groups, each of prime power order"", where for a cyclic group with order $p^n$, we have that $p \vert m$, and $m$ is the order of $G$. The example I refer to is as follows: ""The number 36 can be written as a product of prime powers in just four ways: $36 = 2\cdot 2 \cdot 3 \cdot 3 = 2 \cdot 2 \cdot 3^2 = 2^2 \cdot 3 \cdot 3 = 2^2 \cdot 3^2$. Consequently, every abelian subgroup of order 36 must be isomorphic to one of the following groups: $\mathbb{Z}_2 \times \mathbb{Z}_2 \times \mathbb{Z}_3 \times \mathbb{Z}_3$, $\mathbb{Z}_2 \times \mathbb{Z}_2 \times \mathbb{Z}_9$, $\mathbb{Z}_4 \times \mathbb{Z}_3 \times \mathbb{Z}_3$, $\mathbb{Z}_4 \times \mathbb{Z}_9$ These are easily shown to not be isomorphic to each other by examining their elements. Furthermore, $\mathbb{Z}_{36}$ is isomorphic to $\mathbb{Z}_4 \times \mathbb{Z}_9$."" All this I understand. But Hungerford argues that this is a complete characterization of all finite abelian groups of order 36 up to isomorphism. This, I don't understand. How do we guarantee that no other isomorphisms exist? Thank you, and best regards, kasp9201. Edit: Here is a clarification of my question. I understand that a finite abelian group of order 36 is indeed isomorphic to the four direct products that I have listed. How do we guarantee that a finite abelian group of order 36 is not isomorphic to more than just these four? A finite abelian group $G$ can be written as the direct product of p-groups $G(p_1) \times G(p_2) \times ... \times G(p_n)$, where if $\vert G \vert = m$, then $p_i \vert m$ for all $i$. Each of these groups $G(p_i)$ can then be written as direct products of cyclic subgroups $(k)$, where $\vert k \vert = p_i^c$, if $k \in G(p_i)$. It seems to me that Hungerford's argument is that since a finite abelian group $G$ is isomorphic to the direct product of such cyclic subgroups, then it is only isomorphic to such cyclic subgroups. That is, if $G$ was to be isomorphic to any other group, then this group would be isomorphic to one of $G$'s direct products of cyclic subgroups. Is this what Hungerford (and lhf ) builds his argument on? If so, why is this true? Thank you again, and I apologize for any inconvenience","['finite-groups', 'abelian-groups', 'group-theory', 'group-isomorphism']"
2729287,Spectral radius of a pair of operators which commute,"Let $E$ be an infinite-dimensional complex Hilbert space. The spectral radius of a commuting multivariable operator $A = (A_1,\cdots,A_n)\in\mathcal{L}(E)^n$ is given by
 $$r_a(A_1,\cdots,A_n)=\displaystyle\lim_{m\to \infty}\left\|\displaystyle\sum_{|\alpha|=m}\frac{m!}{\alpha!}{A^*}^{\alpha}A^{\alpha}\right\|^{\frac{1}{2m}},$$
where $m\in\mathbb{N}^*,\;$ $\alpha = (\alpha_1, \alpha_2,...,\alpha_n) \in \mathbb{Z}_+^n;\;\alpha!: =\alpha_1!\cdots\alpha_n!,\;|\alpha|:=\displaystyle\sum_{j=1}^n|\alpha_j|$; $A^*=(A_1^*,\cdots,A_n^*)$ and $A^\alpha:=A_1^{\alpha_1} A_2^{\alpha_2}\cdots A_n^{\alpha_n}$. I claim that if $A_iA_j=A_jA_i$ for all $i,j$, then in general
  $$r_a(A_1,\cdots,A_n)\neq r_a(A_1^*,\cdots,A_n^*).$$
  I hope to find an explicit example which show that the claim is true. Note also that we have
\begin{align*}
r_a(A_1,\cdots,A_n)
 &=\sup\{\|\lambda\|_2,\;\;\lambda \in \sigma_{ap}(A)\},
\end{align*}
 where
$$\sigma_{ap}(A)=\bigg\{\lambda\in \mathbb{C}^n: \;\exists\;(x_k)_k\subset E;\,\,\|x_k\|=1\;\;\hbox{such that}\;\;\\\lim_{k\longrightarrow \infty}\sum_{1\leq j\leq n}\|(A_j-\lambda_j)x_k\|=0\bigg\}.$$","['matrices', 'linear-algebra', 'operator-theory']"
2729312,Inversion in a circle as radius goes to infinity.,"I am trying to show that the in the limit case as the circle gets very large, inversion in it is equivalent to reflection in a line. I have the transform $z \to c+ \frac{R^2}{ (\overline z -\overline c)} $ for inversion of $z$ in a circle radius $R$ centred at $c$. I am unsure how to go about taking a limit to get the result as limit as R goes to infinity does not too exist. As such I assume you need to take a limit less than infinity. How would you go about finding a suitable limit case?","['symmetry', 'mobius-transformation', 'geometry']"
2729329,Is there a way to simplify $\sum_{n=0}^L \binom{L}{n} e^{p^n q^{L-n}}$?,"I have a nasty sum I've been working with that can be reduced to the following form
$$ \sum_{n=0}^L \binom{L}{n} e^{-c p^n q^{L-n}}$$
where $c > 0$ is constant. However, I do not know any way to simplify/reduce this. Is there any nice way to do it, or do I need to start approximating the sum? Doing a bit of research suggests no, but I still have  hope for it. EDIT: Forgot to mention $p+q =1, 0<p<1.$","['summation', 'discrete-mathematics']"
2729356,"Given $z+x\ln(z)+xe^{xy}-1=0$ find the directional derivative at $P=(0,1)$ in the direction of $v= \langle 4 \sqrt{3} , 3 \sqrt{3} \rangle$","I am given the following exercise: Given $$z+x\ln(z)+xe^{xy}-1=0$$ find the directional derivative at $P=(0,1)$ in the direction of $$v= \langle 4 \sqrt{3} , 3 \sqrt{3} \rangle$$ There's no solution on the textbook so I would like to check my reasoning. Firstly I expressed the direction of the vector as being $v= \langle \frac{4}{5} , \frac{3}{5} \rangle$ so it is 1 unit long (I divided by its magnitude). After that, I proceeded evaluating the partial derivatives (that's the tricky part). Using the implicit differentiation theorem and substituting the point $(0,1)$ (when $x=0$ and $y=1$ then $z = 1$) \begin{align*}
F(x,y,z) &= z+x\ln(z)+xe^{xy}-1\\
\\
F_x(x,y,z) &= \ln(z) + e^{xy}+xye^{xy} = 1\\
F_y(x,y,z) &= x^2 \cdot e^{xy} = 0\\
F_z(x,y,z) &= 1+\frac{x}{z} = 1\\
\\
\frac{\partial z}{\partial x} &= - \frac{F_x}{F_z} = -1\\
\frac{\partial z}{\partial y} &= - \frac{F_y}{F_z} =  0
\end{align*} So the directional derivative is given by $$D_{\vec{v}} = \langle -1 , 0 \rangle \left\langle \frac{4}{5} , \frac{3}{5} \right\rangle = - \frac{4}{5}$$ Is my solution correct?
Thank you.","['multivariable-calculus', 'partial-derivative', 'proof-verification']"
2729364,Is there a way of proving that $\mathbb{Z}[i]$ and $\mathbb{Z}[\sqrt{-2}]$ are UFD s without showing that they are euclidian domains?,"What are direct methods for proving that a ring is a UFD in general without proving that it's a PID/Euclidean domain/field and using the fact that all those things are UFDs? As an example, we can take $\mathbb{Z}[i]$ or $\mathbb{Z}[\sqrt{-2}]$ or other rings you come up with.","['abstract-algebra', 'unique-factorization-domains']"
2729411,What does exterior algebra actually mean?,"This question may be too basic and even silly, but I am new to exterior algebra and reading Wikipedia . Given $e_1, e_2,\cdots, e_n$ is a standard basis for a vector space $V$, what does $e_1\wedge e_2\cdots \wedge e_n$ actually look like? It is said to be a basis. So, it is a set of vectors? What is its dimension? Is it just a constant with dimension $1$?","['hamel-basis', 'linear-algebra', 'exterior-algebra']"
2729413,Probability of pralines in a box,"Milk  and  Dark chocolate  pralines  are  randomly   placed  into  boxes  containing  a  total  of 25 pralines.
The colour of each praline is determined by a random mechanism so that on average, 60% of all pralines are dark. (a)  Let the random variable M denote the number of Milk Pralines in a box. What is the distribution of M? (b)  What is the probability that all chocolate pralines in one box are of the same type? (c)  How many boxes need to be selected to have a chance of >90% to have at least one box with at least 15 Milk Pralines? So far I believe I have managed to understand b). However a) and c) is a bit more difficult for me. What do they mean by asking the distribution? What i got till now: 25 Pralines total per Box, 60% are Dark Pralines. D= Number of Dark pralines/box 

       n=25                

       p=0.6 b) $P[D=25]+P[D=0]={25 \choose 25}p^{25}(1-p)^{0} +{25 \choose 0}p^{0}(1-p)^{25}$ c) $p'=P[M\ge15]= {15 \choose 15}p^{15}(1-p)^{0}= 1-P[M\le14]$ which equals to 0.000470184. Then $P[X\ge1]=1-P[X=0]= 1-{m \choose 0}p'^{0}(1-p')^{m}= 1-0.999529816^{m} $
Then I'd just use logarithm to find m $$1-0.999529816^{m}\gt0.9$$
$$0.1\gt0.999529816^{m}$$
$$ln0.1\gt mln0.999529816$$
$$\frac{ln0.1}{ln0.999529816}\lt m$$ The m= 4896.04, SO I'd have to go through 4896 boxes to 
get a box with at least 15 Milk Pralines? I think my answer is wrong, do I really have to go through 4896 boxes?
Have I been using the right methods? And I'd really appreciate it if someone could explain a) for me.","['probability-theory', 'probability-distributions', 'probability', 'discrete-mathematics']"
2729431,Why is it obvious that if the intersection of all sets is empty then its complements cover the whole space?,"I was watching Harvey Mudd's real analysis video talking about the finite intersection property. The first step of the proof relies using contradiction and thus starts by saying that the intersection of all the sets is empty: $$ \cap_{\alpha } K_{\alpha} = \emptyset $$ Then the professor says the following (perhaps paraphrased a little bit): If a point is in the intersection then it means that point is not in any of the complements. So if there is no point in any intersection then some point must be in some complement. The first part of the statement seems obvious to me, if one is in all the sets then thats the same as saying that point must be in every set simultaneously. If one is in all the sets simultaneously then you can't be in any one of the complements (since otherwise you'd not be in that set and thus can't be in all of them simultaneously). Basically this relies that being in a set means you can't be in the complement of that set and being in all the sets means you can't be in any one of the complements. Basically: $$ x \in \cap_{\alpha} K_{\alpha} \implies  x \not \in\cup_{\alpha} K^c_{\alpha} $$ or $$ \cap_{\alpha} K_{\alpha} = ( \cup_{\alpha} K^c_{\alpha} )^c $$ However, the argument proceeds to then say: So if there is no point in any intersection then some point must be in some complement. which is the part I am struggling to understand. I wish to understand it sort of in plain english. What they call sometimes ""intuitively"" because that second part of the conclusion is not something that would have occurred to me and it seems something that should have flowed naturally from a train of thoughts rather than some symbol crunching game. The reason I say not from a ""symbol crunching game"" is because its quite trivial to just start applying negations and complements until you force the answer out. e.g. $ \cap_{\alpha } K_{\alpha} = \emptyset $ using DeMorgan's $ (\cap_{\alpha } K_{\alpha})^c = \cup K^c_{\alpha}$ and complementing it we get: $ \cap_{\alpha } K_{\alpha} = (\cup K^c_{\alpha})^c = \emptyset$ then taking the complement of everything we get: $\cup K^c_{\alpha} = \emptyset^c = X$ i.e. the complement of nothing is everything and then we get the desired answer. The reason I don't like this reasoning is because it just feels like symbol crunching rather the way professor Su explained it seems there is a naturally flowing way to reach that conclusion from logic or just reasoning without requiring long winding manipulation of rules and symbols. So what is the simple logical way to understand that part of the reasoning? I think I've identified what confuses me the most. It seems that DeMorgan's law's talks about the equality of two sets in terms of what they have, but the fact that in the question premise we are dealing with the empty set itself (i.e. a set that has nothing) is what is confusing me and then making a jump to a set that has everything coupled with DeMorgan's, complements seems to confusing to deal with all at once. I think because the set has nothing and the proofs I have for those are in terms of things that I do have, is what is confusing me. Perhaps this can bias answers to address what seems to be the crux of my confusion.","['real-analysis', 'alternative-proof', 'elementary-set-theory']"
2729522,Continuity of the invariant measure of a perturbed Markov chain,"Consider an aperiodic and irreducible continuous-time Markov chain $X_\epsilon(t)$ on a countable state space $S$, where $\epsilon\ge 0$ is a ""perturbation"" parameter. Assume that the transition matrix $Q_\epsilon=[q_{i,j}(\epsilon)]$ is such that the $q_{i,j}(\epsilon)$'s are continuous in $\epsilon$. Let $\pi_\epsilon$ denote the invariant probability measure when the chain is perturbed by $\epsilon$. My question is whether or not $\lim_{\epsilon\downarrow 0} \pi_\epsilon(i)=\pi_0(i)$ for all $i\in S$. If not, under which conditions the previous limit holds true? This should be a classic question but I am not very successful in finding appropriate references. Any reference is highly appreciated.","['stochastic-processes', 'probability-theory', 'markov-chains', 'markov-process', 'probability']"
2729549,"Explaining $\int_{-1}^1\frac{1}{1+x^2}\,dx = \frac{\pi}{2}$.","How would you explain to a student that
$$ \int_{-1}^1\frac{1}{1+x^2}\,dx = \arctan(1) - \arctan(-1) = \frac{\pi}{2} $$
and not
$$ \int_{-1}^1\frac{1}{1+x^2}\,dx = \arctan(1) - \arctan(-1) \neq \frac{\pi}{4} - \frac{3\pi}{4} = -\frac{\pi}{2}$$
besides the obvious fact that $\arctan x$ cannot map to two distinct values?","['integration', 'calculus']"
2729561,Probability of an unordered sample under weighted sampling without replacement,"Imagine the following situation: An urn contains $K$ balls of different colours $\mathcal{U}=\{1,\ldots,K\}$, and with different weights $\mathbf{w}=(w_1,\ldots,w_K)$ (where $\sum_i w_i = 1$). You draw from the urn $m \leq K$ times without replacement, with probability of selecting each of the (remaining) balls proportional to their weight, and observed a sample $\mathcal{K} \subset \mathcal{U}$, $|\mathcal{K}|=m$. I want to compute the probability of such a (unordered) sample $\mathcal{K}$. For a particular ordered tuple $\mathbf{k}=(k_1,\ldots,k_m)$ of draws from the urn, the total remaining weight after $i$ draws is $1-w_{k_1}-\ldots-w_{k_i}$, and it follows that $$
  \mathbb{P}(\mathbf{k}) = \frac{w_{k_1}}{1}\frac{w_{k_2}}{1-w_{k_1}}\cdots\frac{w_{k_m}}{1-w_{k_1}-\ldots-w_{k_{m-1}}}.
$$
For an unordered sample $\mathcal{K}=\{k_1,\ldots,k_m\}$, we must sum over all possible permutations $S_m$ of the elements of $\mathcal{K}$, and the probability of observation is therefore $$
   \mathbb{P}(\mathcal{K}) = \sum_{\pi\in S_m} \prod_{i=1}^{m} \frac{w_{k_{\pi(i)}}}{1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i-1)}}},
$$
which can be (slightly) simplified to $$
   \mathbb{P}(\mathcal{K}) = w_{k_1}\cdots w_{k_m}\sum_{\pi\in S_m}\Bigg(\prod_{i=1}^{m-1} \big(1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i)}}\big)\Bigg)^{-1}.
$$ The last expression is, unfortunately, still computationally intractable even for samples containing about 100 elements -- yet I'd need this for samples of tens of thousands elements, selected from millions of colours initially present in the urn. Yet this is were I'm stuck : I can't see how to simplify this further. Thus my question(s): Does anyone have an idea how to simply the denominator and/or how to replace it by an approximation? Or can anyone point me at literature that deals with such a situation? My eventual goal is to estimate the weights $\mathbf{w}$ from many such (independently taken) samples $\mathcal{K}_1,\ldots,\mathcal{K}_N$ which different sizes $|\mathcal{K}_1|$, $\ldots$, $|\mathcal{K}_N|$, either by a ML or (preferrably) a Bayesian approach.","['sampling', 'bayesian', 'maximum-likelihood', 'probability', 'combinatorics']"
2729592,"""A Cubic Function From the Reals to the Reals is Always Injective"": False?","I heard an instructor say during a lecture that ""a cubic function from the reals to the reals is always injective"", but this is false, is it not? A cubic function is always surjective but not necessarily injective? I just want to make sure before I point out the error.","['algebra-precalculus', 'cubics', 'polynomials', 'functions']"
2729618,Is uniform continuity related to the rate of change of the function?,"I have been trying to understand how uniformly continuous functions differ from functions that are continuous but not uniformly continuous. Based on some examples and counter-examples, my feeling is that uniformly continuous functions cannot change ""rapidly"". Hopefully, the following examples will make it clear what I mean by that: $f(x) = 1/x$ is not uniformly continuous on $(0,1)$ because it ""blows up"" at $0$, that is, its slope becomes infinite very quickly. Similar functions would be $\log x$ on $(0,1)$ and $\tan x$ on $(0,\pi/2)$. $f(x) = x^2$ is not uniformly continuous on $(0,\infty)$ because it goes to infinity ""rapidly"" in the sense that the function's rate of change is greater than that of linear functions, for sufficiently large $x$. $f(x) = x^{1/3}$ is uniformly continuous on $(-1,1)$, because even though the slope does become infinite at $0$, it does not happen ""rapidly"" as in the previous two examples. $f(x) = \sin (1/x)$ is not uniformly continuous on $(0,1)$ because it oscillates ""rapidly"" as $x$ approaches $0$. $f(x) = x\sin(1/x)$ is uniformly continuous on $(-1,1)$ because, although the frequency of oscillation remains the same, the amplitude is ""small enough"" to make the function uniformly continuous; in some sense, the function is not changing rapidly enough for it to fail to be uniformly continuous. This is admittedly a very naive way of looking at uniform continuity, but does it have any merit? Is there a way to describe uniform continuity by rigorously formulating the notion of rate of change of the function? Some difficulties I already see are: There are continuous functions that are not differentiable, so the natural idea of rate of change is not applicable to them. There even exist continuous but nowhere differentiable functions on $\mathbb{R}$, and we know that any continuous function on a compact subset of $\mathbb{R}$ is uniformly continuous. So, the Weierstrass function restricted to $[0,1]$ is a uniformly continuous function. Surely, the function changes ""rapidly"" all over the place, but somehow it doesn't do so ""rapidly enough""? I have tagged this as a soft question because I know there is a lot of ambiguity in this post. It would be very helpful if anyone can give me insights about why this method of thinking of uniformly continuous functions (at least in the real one-variable case) can or cannot be fruitful. Also, this is a related post that I found useful, especially the most upvoted answer: Why did mathematicians introduce the concept of uniform continuity?","['intuition', 'real-analysis', 'soft-question', 'uniform-continuity']"
2729622,Proving that an analytic function $f$ on a region $\Omega$ has an analytic $n$-root,"I'm interested in providing a non-topological (i.e no covering theory) proof of the following fact: Let $\Omega$ be an open connected  subset of $\Bbb C$. Prove that $f\colon \Omega \to \Bbb C\setminus 0$ analytic has an analytic $n$-th root (i.e. an analytic function $g\colon  \Omega \to \Bbb C\setminus 0$ s.t. $g^n=f$) if and only if $$ \dfrac{1}{2\pi i}\int_{\gamma} \dfrac{f'}{f}dz \in n\Bbb Z$$ for every loop $\gamma$ in $\Omega$. the only if part is trivial, and I can provide a covering theory proof of the if part (basically one prove that $f$ lifts to the $n$-fold cover $\Bbb C\setminus 0 \xrightarrow{(\cdot)^n} \Bbb C \setminus 0$). I would like to see a more ""complex analysis"" flavoured proof. I tried working with local $n$-th roots (on simply connected domains in $\Omega$ and try to prove  whether they patch together but I can't see how to use the hypothesis. Can someone give me any advice?",['complex-analysis']
2729626,Finding a flaw in a proof that $(A\cup C)\times (B \cup D)\subseteq(A\times B)\cup(C\times D)$,The only problem I could see is that there should be two more cases: $x \in A$ and $y \in D$; and $x \in C$ and $y \in B$. Please suggest.,"['proof-explanation', 'elementary-set-theory', 'proof-verification']"
2729659,Choosing H0 and Ha in hypothesis testing,"There seems to be some ambiguity or contradiction in how to correctly choose the null and alternative hypotheses, both online and in my instructor's notes. I'm trying to figure out if this stems merely from my lack of understanding or if there actually is a disagreement in the scientific community at large.
I've seen the following two ideas on choosing H0 and Ha The null hypothesis is the status quo, the state of things already accepted and/or shown to be true by previous data. We assume it to be true and need convincing evidence to reject it. The alternative hypothesis is the one being proposed based on data from the experiment in question, and is assumed to be false unless the data supporting it can convincingly show otherwise. The null hypothesis is always the one that includes the equality, and the alternative hypothesis is the complement to it. It doesn't matter whether the equality is the status quo or is being claimed by the researcher, it is always H0. An example I made up myself for demonstrative purposes, I'm not looking for an actual solution. Only interested in the hypotheses: A researcher believes that children in economically disadvantages areas are more likely to be raised in single-parent homes. He surveys 1000 children from such an area and finds that 317 of them are raised in a single-parent home. Can we conclude with 95% confidence that 30% or more of the children in economically disadvantages areas are raised in single-parent homes? What would be the H0 and Ha in this case and why? My professor provided the correct answer (for an equivalent question but with different numbers) to be H0 : p >= 0.3; Ha : p < 0.3 With the rationale that H0 must include the equality, which in this case is greater or equal to 30% . Her solution then failed to reject the null hypothesis and concluded that the researcher's claim is therefore correct. To me this seems like assuming the claim to be true to begin with and giving it the benefit of the doubt, which is the opposite of what I thought was the correct approach. A professor in this related question Difference between ""at least"" and ""more than"" in hypothesis testing? seemingly took the same approach. I wish I could talk to my professor about this, but unfortunately there's a significant language barrier.","['statistics', 'hypothesis-testing']"
2729699,Let $A \subset \mathbb{R}$ be a Lebesgue measurable set with positive Lebesgue measure.,"Let $A \subset \mathbb{R}$ be a Lebesgue measurable set with positive Lebesgue measure. Show that for any $k\in\mathbb{N}$, there exists $a,t \in\mathbb{R}$ ($t\ne0$) such that \begin{align*} a,a+t,a+2t,\cdots,a+kt\in A\end{align*} I knew there exists $\delta>0$ s.t $(-\delta,\delta)\subset A-A$ because of $\mu(A)>0$. The problem seems to be similar with that. However, I hard to think how to prove that.. Any help is appreciated.. Thank you!","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2729703,Difference quotients uniformly bounded in Holder space,"I have trouble with proving the following: Let $u \in C^{k, \alpha}$. For each $h > 0$, denote the 
difference quotient of u in the $j$-direction as $\delta_{h, j}u$. That is, 
\begin{equation}
   \delta_{h, j} u (x) = \frac{u(x + h e_j) - u(x)}{h}.
\end{equation}
Suppose $| \delta_{h, j} u |_{k, \alpha} \leq M$ uniformly in $h$. 
Then $D_j u \in C^{k+1, \alpha}$ and $| D_j u |_{k+1, \alpha} \leq M$. The Sobolev space version of this argument is easy because we can take a weakly convergent subsequence and pair it with test functions to obtain existence of a higher derivative. However, in the Holder space case, we do not have any test functions to make our lives easy. So I suspect we have to use certain Arzela-Ascoli type compactness, but somehow I am stuck and cannot proceed.
I would really appreciate it if somebody could give me some idea or proof. 
Thank you!","['functional-analysis', 'real-analysis', 'analysis', 'partial-differential-equations']"
2729730,"On the flow of $v(x,y)=(x,y)$ and the Lefschetz number","Let $v$ be the vector field on $\mathbb R^2$ defined by $v(x,y)=(x,y)$. Show that the family of diffeomorphisms $h_t:\mathbb R^2\to \mathbb R^2$ defined by $h_t(z)=e^tz$ is the flow corresponding to $v$. That is, if we fix any $z$, then the curve $t\mapsto h_t(z)$ is always tangent to $v$; its tangent vector at any time $t$ equals $v(h_t(z))$. Draw a picture of $v$ and its flow curves. Compare $\operatorname{ind}_0(v)$ with $L_0(h_t)$. (Note that the original text defines $h_t(z)=tz$, but I used this errata list .) The first part is ""obvious"" from the picture. Formally, if $z$ is fixed, then the tangent vector of $t\mapsto e^tz$ at $t$ is the derivative of this map at $t$, which is again $h_t(z)$. But $v$ is the ""identity"" -- $v(z)=z$, so the tangent vector, which is $\frac{d}{dt}h_t(z)=h_t(z)$, is also $v(h_t(z))$. 
But I have a problem with showing that the curve $t\mapsto h_t(z)$ is always tangent to $v$. This means that $\frac{d}{dt}h_t(z)=v(z)$. But this isn't true. For the second part, $\operatorname{ind}_0(v)=1$ since the corresponding map is the identity. To compute $L_0(h_t)$, consider the map $z\mapsto \frac{h_t(z)}{|h_t(z)|}$ and compute its degree, which is $L_0(h_t)$. It seems this map is closely related to the map in the definition of the index of a (local) vector field (is it the same map?) and it seems the degree must be also 1. But how to show this rigorously?","['real-analysis', 'differential-topology', 'calculus', 'manifolds', 'ordinary-differential-equations']"
2729750,Solve $(1+x)y’=y$ by power series,Solve $(1+x)y’=y$ by power series. $$$$Start with $y$ and $y’$: $y=a_0+a_1x+a_2x^2+a_3x^3+...+a_nx^n$ $y’=a_1+2a_2x+3a_3x^2+...+na_nx^{n-1}$ Then $(1+x)y’=a_1(1+x)+2a_2(1+x)x+3a_3(1+x)x^2+...+na_n(1+x)x^{n-1}$ Then $(1+x)y’-y=[a_1(1+x)+2a_2(1+x)x+3a_3(1+x)x^2+...+na_n(1+x)x^{n-1}]-[a_0+a_1x+a_2x^2+a_3x^3+...+a_nx^n]=0$ $$$$$\implies [a_1+a_1x+2a_2x+2a_2x^2+3a_3x^2+3a_3x^3+...+(na_n+na_nx^n)]-[a_0+a_1x+a_2x^2+a_3x^3+...+a_nx^n]=0$$$$$$(a_1-a_0)+(a_1+2a+2-a_1)x+(2a_2+3a_3-a_2)x^2+(3a_3+a_3)x^3+...+=0$ I’m missing the trick when equating terms. Any help would be appreciated!,"['power-series', 'ordinary-differential-equations', 'sequences-and-series', 'calculus']"
2729782,Understanding the construction of Riemann surface for $\xi^3-z\xi^2-(a^2-1)\xi+za^2=0$.,"I am reading an article which defines a Riemann surface by the following equation ($a>1$):
$$\xi^3-z\xi^2-(a^2-1)\xi+za^2=0$$
The goal is to find the Riemann surface of $\xi(z)$. What I know/understand: The critical points satisfy $\frac{\partial z}{\partial \xi}=0$, which after some working out means that the branch points are $-z_1,-z_2,z_2,z_1$ ($0<z_2<z_1$) with
$$z_1,z_2=\sqrt{\frac{1}{2}+a^2\pm\frac{1}{2}\sqrt{1+8a^2}}\frac{\sqrt{1+8a^2} 
\pm 3}{\sqrt{1+8a^2}\pm 1}.$$ 
Also, the solutions of the first equation have the following behaviour:
$$\xi_1(z)=z-\frac{1}{z}+O\left(\frac{1}{z^3} \right),\xi_2(z)=a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right),\xi_3(z)=-a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right)$$
as $z\rightarrow \infty$. What I don't understand: Apparently, $\xi_1,\xi_2$ and $\xi_3$ can be analytically extended to $\mathbb{C}\backslash ([-z_1,-z_2]\cup [z_2,z_1])$, $\mathbb{C}\backslash  [z_2,z_1]$ and $\mathbb{C}\backslash [-z_1,-z_2]$ respectively. On the cuts, it holds that
$$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{2-}(x)=\overline{\xi_{2+}(x)},\quad z_2<x<z_1$$
and 
$$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{3-}(x)=\overline{\xi_{3+}(x)},\quad -z_1<x<-z_2$$
which determines the shape of the Riemann surface. I understand that this likely requires some tedious working out, so just the idea of how to start will help a lot.","['riemann-surfaces', 'complex-analysis']"
2729811,Find $\lim_{n \to \infty}(n - \frac{1}{2^n} \sum_{k=1}^{2^n}\log_{2}(k+2^{n-1}))$ using Riemann sums,"I need to examine whether the following limit exists or not. $$\lim_{n \to +\infty}(n - \frac{1}{2^n} \sum_{k=1}^{2^n}\log_{2}(k+2^{n-1}))$$ If it does, I need to calculate it's value. I think ""Riemann sums"" may be a good start. So, I'm trying to convert the expression
$$=\lim_{n \to +\infty} (n-\frac{1}{2^n} \sum_{k=1}^{2^n} (\log_2(\frac{k}{2^n}+\frac{1}{2})+\log_22^n))\\ 
= \lim_{n \to +\infty} (n(1-\frac{1}{2^n})-\frac{1}{2^n} \sum_{k=1}^{2^n} \log_2(\frac{k}{2^n}+\frac{1}{2}))\\ 
= - \lim_{n \to +\infty} (\frac{1}{2^n} \sum_{k=1}^{2^n} (\log_2({\frac{k}{2^n}+\frac{1}{2}}) - n(1-\frac{1}{2^n})))$$
but I don't know what to do next and how to finish it. Can anybody help me?","['limits', 'calculus', 'integration', 'riemann-sum', 'summation']"
2729836,"Showing the sequence converges $a_{1}=\frac{1}{2}$, $a_{n+1}=\frac{1}{2+a_{n}}$","Showing the sequence converges $a_{1}=\frac{1}{2}$,  $a_{n+1}=\frac{1}{2+a_{n}}$. I already know that if $(a_{n})$ converges then it does to  $\sqrt{2}-1$.But i dont't know how to prove that this sequence cenverges. EDIT I think that the subsequence $(a_{2n+1})$ is monotonic decreasing and the subsequence $(a_{2n})$ is monotonic increasing.","['sequences-and-series', 'calculus']"
2729886,Invariant measures can be determined by the iteration of the transformation,"Let $(M, \mathcal{B} , \mu)$ be a measure space and $f : M \to M$ be a measurable transformation. We say that the measure $\mu$ is invariant under $f$ if for every measurable set $ E \subset M$, 
$$\mu (E) = \mu (f^{-1}E).$$
There is a well-known theorem in ergodic theory which determine the invariant measures of $f$: Theorem: Let $ f : M \to M $ be a measurable transformation and $\mu$ be a measure on $M$. Then $f$ preserves $\mu$ if and only if  $$ \int \phi d\mu = \int \phi \circ f d\mu$$
  for every $\mu$-integrable function $\phi : M \to \mathbb R$. For the proof, see Proposition $1.1.1$ from Foundations of Ergodic Theory , by  Marcelo Viana and Krerley Oliveira. In the previous book, the authors have asked the following exercise: Prove that if $f : M \to M$ preserves a measure $\mu$ then, given any $k ≥ 2$,
  the iterate $f^k$ also preserves $\mu$. Is the converse true? The fact that $f^k$ for $k\ge 2$ preserves $\mu$ can be obtained by a simple induction from above theorem. For the converse, since $\mu$ is $f^2 $ and $f^3$-invariant, by the above theorem, for every $\mu$-integrable function $\phi : M \to \mathbb R$, $$ \int \phi d\mu = \int \phi \circ f^2 d\mu = \int \phi \circ f^3 d\mu.$$
Specially, for the function $ \phi \circ f : M \to \mathbb R$ we must have:
$$ \int \phi \circ f d\mu = \int (\phi \circ f)\circ f^2 d\mu = \int \phi \circ f^3 d\mu = \int \phi d\mu .$$ 
Again by above theorem, $\mu$ is $f$-invariant. I have doubt about my solution, since I used only the assumption that $f^2$ and $f^3$ preserves $\mu$. Did i missed something?","['dynamical-systems', 'ergodic-theory', 'measure-theory']"
2729911,Finding the x's for which f(x) is a whole number,"I'm trying to improve my math skills and I found this exercise in my book. We have the following function: $$f: \mathbb R\to \mathbb R$$  $$f(x) = \frac {4x+1}3$$ I've been asked to find out one value for $x$ such that $f(x)$ is a whole number. I found some solutions and afterwards I determined that for all $$x_n=\frac {3^{2n}-1}4$$  where n is a natural number different from 0 , $f(x_n)$ is a whole number. I'm not 100% sure this is correct but it seems to work for all positive even powers of 3. I've been trying to prove that this formula is corect, but I didn't succeed. Could anyone point me out on how to prove this kind of problems, and what to watch out for? Thanks.","['elementary-set-theory', 'functions']"
2729918,"$f(z)= \frac{z}{1-e^{-z}}$ $\Leftrightarrow$ $\forall n \ge 0$ and $n\in\mathbb{Z}$, coefficient of $z^n$ in $f^{n+1}(z)$ is $1$.","How to prove that if $f(z)$ is analytic in the region around origin, then $f(z)= \frac{z}{1-e^{-z}}$ $\Leftrightarrow$ $\forall n \ge 0$ and $n\in\mathbb{Z}$, coefficient of $z^n$ in $f^{n+1}(z)$ is $1$. I try to use the expansion of $f(z)= \sum_{n=0}^{\infty}a_n z^n$ , and calculate the coefficient of $z^n$ in $(\sum_{m=0}^{\infty}a_n z^m)^{n+1}$. By this way, we can explicitly compute the first few $a_n$. $n=0 \Rightarrow a_0=1$ $n=1 \Rightarrow 2 a_1 a_0 =1 \Rightarrow a_1=1/2$ $n=2 \Rightarrow 3 a_2 a_0^2 + 3 a_1^2 a_0  =1 \Rightarrow a_2=1/12$ $\cdots$ However it seems to involve a complicated partition and combination problem when $n$ is large.
That is,  firstly try to find the partition,  $\forall i, x_i\in \mathbb{Z}$ and $x_i\ge0$
$$x_1+x_2+\cdots +x_{n+1}=n\tag{1}$$
then solve the iteration function
$$\sum_{\{x_i\}} \prod_{i=1}^{n+1} a_{x_i}=1\tag{2}$$ 
with $\sum_{\{x_i\}}$ means sum over all configuration $\{x_1,\cdots, x_{n+1}\}$ such that $(1)$ holds. How to prove the solution of $a_n$ relates to Bernoulli numbers (i.e $a_n=(-1)^n B_n/n!$ since in this question , it proves that $f(-z)=\frac{z}{e^z-1}=\sum_{n=0}^\infty B_n z^n/{n!}$)? Or by other method to prove above claim?","['calculus', 'laurent-series', 'complex-analysis', 'combinatorics', 'power-series']"
2729987,How would i draw a graph given a specific degree sequence?,"For example, I have a degree sequence (4,3,3,1,1,1,1) and I want to draw its graph. I know that it will have 7 edges, put I can't seem to put the graw together. Thanks!",['discrete-mathematics']
2730010,Convergence in $L^1$ of ratio of random variables,"If the sequences ${X_n}$ and $Y_n$ converge both almost surely and in $L^1$ to the constants $a$ and $b \ne 0$, respectively, and $Y_n$ is deterministically bounded below by some constant $0 < c \le b$, does this imply that $\mathbb{E}\left[\frac{X_n}{Y_n}\right]$ converges to $\frac{a}{b}$, i.e. does the ratio of $X_n$ and $Y_n$ converge in $L^1$ to $\frac{a}{b}$? [Follow-up: does $\frac{X_n}{Y_n}$ converge almost surely to $\frac{a}{b}$? Edit: Yes, the latter is a trivial consequence of the continuous mapping theorem.] Of course, $\frac{X_n}{Y_n}$ converges in probability to $\frac{a}{b}$, but this does not imply convergence in $L^1$. Intuitively, I think that it should indeed converge in $L^1$, but I am having a tough time taking a crack at this. I've tried using indicator variables, etc., but that does not seem to be the right approach. I would love to know whether this is true, at least for ""nice"" sequences of $X_n$'s and $Y_n$'s [in particular, products and sums of independent Gaussians and finite integer higher powers of independent Gaussians]. I don't need the proof as long as someone can point me to a relevant resource, but if a proof is available I would of course love to see that as well.","['probability-theory', 'statistics', 'probability', 'measure-theory', 'convergence-divergence']"
2730021,Stopped process is $F_T$-measurable,"In the Protter's book, they want to show that for an adapted Cadlag process $X$, the stopped process $X_T$ is $\mathcal F_T$ measurable, where $$\mathscr F_T:=\{A\in \mathscr F \mid A\cap\{T<t\}\in\mathscr F_t, \text{all }t>0\}.$$ What they did is to construct $\varphi:\{T\leq t\}\rightarrow [0,\infty)\times\Omega$ by $\varphi(\omega)=(T(\omega),\omega)$. Then since $X$ is adapted and cadlag, we have $X_T=X\circ\varphi$ is a measurable mapping from $({T\leq t},\mathcal F_t\cap\{T\leq t\} )$ into $(\Bbb R, \mathcal B(\Bbb R))$. What I couldn't follow is the last argumentation: Why is the map $X_T$ measurable with respect to $\mathcal F_t\cap \{T\leq t\}$? Do I proof it via the composition map or directly? If I prove it as a composition map, I would require the $X_t$ to be progressively measurable since $\varphi$ is a mapping to the product space. However, is it given here? Why do we need the cadlag property of the process? I would appreciate for any hints.","['stochastic-processes', 'probability-theory', 'measure-theory', 'stopping-times']"
2730039,Counting matrices over a finite field.,"Let $ \mathcal{M}^{k \times n} = \{ A \in \mathbb{F}_q^{k \times n} \mid A \text{ is full rank and every } \; k \times k \; \text{submatrix of }\; A \;\text{is invertible}\}$. I want to know $|\mathcal{M}^{k \times n}| $. I know that since $\mathcal{M}^{k \times n}$ is subset of the full rank matrices then the number I'm looking for is less than $(q^n-1)(q^n-q)\cdots (q^n-q^{k-1})$ (the number of full rank matrices) but if you make the count for $ k=1$ this seems to be false: When $ k=1$ every sub matrix having determinant distinct to zero is equivalent to being full rank, so one has to count only the number of vectors with non zero entries: $ (q^n-1)^n > q^n-1$. I know that I might be wrong but I can't see how Thank you all in advance Edit I forgot to add that $n>k $, this will implie that in $k=1 $ being full rank only means not to be the zero vector i.e we are only looking for the vectors with non zero entries (there are $ (q^n-1)^n > q^n-1$ many of them ) but hte equivalence I state does not holds.","['matrices', 'combinatorics', 'finite-fields']"
2730077,Short mathematical notation for a sequence without the last element,"I have a sequence (with unique elements): $a = (1,4,9)$.
Is there a short notation for the same set, but without the last element: $b = (1,4)$? I came up with one solution, which simple removes the last item by index:
$$b =a \setminus \{ a_{|a|-1}\}$$ 
or by taking all except the last:
$$b = (a_0,...,a_{|a|-2})$$ However i am hoping to find something shorter, like $a_{-1}$ or something in that direction. Is there a standard way of doing this?","['notation', 'sequences-and-series', 'elementary-set-theory']"
2730111,Can a set of Hausdorff codimension 2 disconnect a connected open set?,"Consider a connected open set $U\subset \Bbb R^n$ (or a Riemannian manifold if you're ambitious), and $S\subset U$ closed and with Hausdorff dimension $\le n-2$. Is $U\setminus S$ connected? If not, does $\dim S\le n-3$ work? What is the optimal dimension? It seems surprisingly hard even in the case of $U=\Bbb R^2$. There exist uncountable zero-dimensional subsets of $\Bbb R^2$, so one cannot use this classical result . I think that if one proves it in the $n=2$ case one can do induction to higher $n$ via some sort of slicing argument (maybe using Fubini). Even more generally, consider $R\subset \Bbb R^n$ connected and $\dim R=k$. Can $S\subset R$, $\dim S=k-2$ (or maybe $k-3$) disconnect $R$?","['geometric-measure-theory', 'differential-geometry', 'riemannian-geometry', 'measure-theory']"
2730142,How awful is the awful magician?,"There is a magician (who is totally not me), who shuffles a standard deck of cards (52 cards, four suits). A volunteer from the crowds chooses a card at random, reinserts into the package, and reshuffles. The awful magician, being awful, starts from the top of the pack. ""Is this your card?"" ""No."" The next card, and the question repeats. On and on, until finally, the volunteer's card reveals itself. Much to the excitement of everyone, that they get to go home. In this scenario, which is totally not based on real life, what is the expected value of attempts by the awful magician before they manage to bedazzle their audience? Just to make things slightly more mathematical, the volunteer picks a card at random, then reshuffles the pack. So the question can be recast as given a number $n$ between $1$ and $52$ , and a permutation $\pi$ of $\{1,\dots,52\}$ , what is the expected value for $\pi^{-1}(n)$ ? (The questions comes from playing with a deck of cards, and thinking about Michael Stevens' Vsauce video regarding card tricks, where he cites Scott Czepiel about $52!$ .)","['probability', 'expected-value']"
2730185,Prisoners wearing infinite stack of hats,"There are N prisoners, each wearing an infinite stack of hats. Each hat was chosen at random to be black or white. Each prisoner can see all the others but not her own stack. Each prisoner must independently write down the index of a black hat in her own stack. The warden checks all the guesses, and if one or more are wrong the prisoners are killed. The day before, the prisoners were told the rules and allowed to agree on a strategy they would follow for guessing. What strategy should they adopt and what is the probability that they will survive? I have an ad hoc strategy that promises survival with probability 1/( N +1). Can one do better or prove that this is optimal?","['puzzle', 'combinatorics', 'recreational-mathematics', 'probability']"
2730218,"Computation of $P(3X+2Y < Z-W)$ when $W,X,Y,Z$ are independent normal variables","If you are given this following problem. $W,X,Y,Z$ are independent random variables with mean $= 1$ and standard deviation also equal to $1$. How would you compute this particular value: $P(3X+2Y < Z-W)$? Integration is easy, but I am having trouble setting up the computation.","['statistics', 'probability', 'normal-distribution', 'random-variables']"
2730251,Forgetting non-isomorphisms: does this category have a name?,"Let $\mathcal{C}$ be a category. I want to define another category $\mathcal{C}'$ putting ${\rm Obj}(\mathcal{C}') \doteq {\rm Obj}(\mathcal{C})$ and $${\rm Hom}_{\mathcal{C}'}(A,B) \doteq \{f \in {\rm Hom}_{\mathcal{C}}(A,B) \mid f \mbox{ is an isomorphism}\},$$for all $A,B \in {\rm Obj}(\mathcal{C}')$. Meaning I want to forget every morphism which is not an isomorphism. Does $\mathcal{C}'$ have a standard name or a standard notation, in terms of $\mathcal{C}$?","['category-theory', 'abstract-algebra', 'notation', 'terminology']"
2730326,Number theory and set theory problem,"Let $A$ be a finite set. For $0\leq i\leq 2$, let $a_i$ be the number of subsets $B$ of $A$ such that 
  $$|B|\equiv i \pmod{3}.$$
  Prove that $$|a_i - a_j| \leq 1,$$ for all $0\leq i,j\leq 2$. Firstly I assumed that $|A|=n$. Then $a_0 = {^nC_0} + {^nC_3} + {^nC_6} +\cdots$  and $a_1 = {^nC_1}+ {^nC_4}+{^nC_7}+\cdots$  and $a_2$ in a similar manner but I am unable to show the main part.
Could anyone give a hint!!","['combinatorics', 'elementary-number-theory']"
2730330,Permutation Representations and Group Actions,"Suppose we have a finite group $G$ acting on a finite set $X=\{ x_1, ..., x_n \}$. Then we can take the free Abelian group generated by elements of $X$ (which is of course isomorphic to $\mathbb{Z}^n$) and we get an induced action of $G$. My question is if it is possible to have two non-isomorphic $G$ actions on $X$ that induce isomorphic actions on $\mathbb{Z}^n$. Thanks!","['permutations', 'abstract-algebra', 'group-theory']"
2730350,[[complex]] Solutions of $x=\sqrt{\sin{x}}$,"I wanted to make one of those cool infinite recursive definitions for myself, and I chose one that I thought looked cool: $x=\sqrt{\sin{x}}=\sqrt{\sin{\sqrt{\sin{\sqrt{\sin{...}}}}}}$ for no other reason than because I thought it looked cool. Using my method* of finding solutions for these; start with a number e.g. 1, take sqrt(sin(1)), take sqrt(sin(that)) alot of times using Answer button until you find a good guess, then algebraically confirm said guess; I got as far as $0.8767262154$ on my TI-83 Plus and $0.87672621539$ on the calculator you get on http://www.google.com/search?q=calc and also don't forget $0$ courtesy of Mac Grapher.app, wolfram alpha roasted all with a massive $0.876726215395062445972118643142$ What my real question is, is how would I calculate (not just compute) or solve for all the real/complex solutions of this? Also, my complex question no pun intended is, wolframalpha also gave me $x=\frac{\sqrt{i\left(e^{-ix}-e^{ix}\right)}}{\sqrt{2}}$, how did they get this? [[What are the complex solutions of this equation?]] *I discovered this for myself when testing that $φ=1+\frac{1}{φ}$ but am aware that it may have already occured to people who know about Mandelbrot set and higher degree 2-dimensional polynomial equations for which algebraic methods of calculation hav yet to be developed","['radicals', 'complex-numbers', 'trigonometry', 'euler-mascheroni-constant', 'recursion']"
2730358,using points to create lines,"Tom was given a total of $9$ candies plus an infinite number of lines and he need to place them such that it follows the following condition: 1) when connecting two candies with a line, there must be three candies on that line or we cannot place it; 2) a candy can be on different lines Show the maximum number of lines that can be created following this rule. An image is provided below for having 5 points: This is an extension problem from the KSEA 2018 grade 11 math exam (a finished math contest held on 4/7) , and I really struggled with this. First of all I started with small examples: $3$ candy- $1$ lines $4$ candy- $1$ line $5$ candy- $2$ lines $6$ candy- $4$ lines Although I am pretty sure about these examples, I am really shaky to advance; I do not have a systematic method. One of my ideas is to argue by combinatorics; for each line generated, there will be a total of $3 \choose 2$ ways to connect two candies taken away. Then I tried this to disprove that 5 candies can generate 3 lines; but $5 \choose 2$- 3$3 \choose 2$ is not negative which shows my way doesnt work... I cannot really come up with a proper solution for this. Some suggestion will be greatly appreciated.","['combinatorics', 'logic', 'geometry']"
2730386,Equinumerosity of strings and natural numbers,"so I'm trying to show that there exists a bijection from the infinite set of finite strings composed of elements from $\{a, b\}$ to $\mathbb{N}$. So I was thinking about showing that $\mathbb{N}$ and the infinite set of finite binary sequences are equinumerous (each have a unique representation), and then constructing a bijection between $\{a, b\}$  and $\{0, 1\}$. Then by the transitive property of equinumerosity, I would be done with my goal. However, when you're writing something in binary, like 00001 (which would be equivalent to aaaab), and so I think this proof would exclude some cases? How else can I go about this?","['cardinals', 'elementary-set-theory']"
2730440,Second Derivatives Continuous but Mixed Partials not Equal,"I'm working on the following problem: Consider the $f:\mathbb{R}^2 \mapsto \mathbb{R}$ defined by $$f(x,y) = \frac{xy(x^2-y^2)}{x^2+y^2}$$ for everywhere outside the origin and $f(0,0)=0$ at the origin is. Show that the second derivative of $f$ exists but the mixed partials are not equal at the origin. My work: I'm getting for $\nabla f = <\frac{yx^4+4x^2y^3-y^5}{(x^2+y^2)^2},\frac{x^5-4x^3y^2-xy^4}{(x^2+y^2)^2}>$. My analysis show that the partials are continuous at zero and take the value $0$ at the origin. I'm having trouble analyzing the second derivative: $$ A = \begin{bmatrix}f_{xx}&f_{xy}\\f_{yx}&f_{yy}\end{bmatrix} =
\begin{bmatrix}\frac{-4xy^3(x^2-3y^2)}{(x^2+y^2)^3}&\frac{x^6+9x^4y^2-9x^2y^4-y^6}{(x^2+y^2)^3}\\\frac{x^6+9x^4y^2-9x^2y^4-y^6}{(x^2+y^2)^3}&\frac{4yx^3(y^2-3x^2)}{(x^2+y^2)^3}\end{bmatrix}
$$ $$\lim_{\|h\|\rightarrow 0} \frac{\nabla f((0,0)+h)-\nabla f((0,0))- A \cdot h\|}{\|h\|} \\ = \lim_{\|h\|\rightarrow 0} \frac{\|\nabla f(h)-\langle f_{xx}h_x+f_{xy}h_y,f_{yx}h_x+f_{yy}h_y\rangle\|}{\|h\|} \\= \lim_{\|h\|\rightarrow 0} \frac{\|\nabla f(h)-\langle\frac{-4xy^3(x^2-3y^2)}{(x^2+y^2)^3}h_x+\frac{x^6+9x^4y^2-9x^2y^4-y^6}{(x^2+y^2)^3}h_y,\frac{x^6+9x^4y^2-9x^2y^4-y^6}{(x^2+y^2)^3}h_x+\frac{4yx^3(y^2-3x^2)}{(x^2+y^2)^3}h_y\rangle\|}{\|h\|}$$ When I do a polar conversion on this thing and send $r \rightarrow 0$ (uniform for all $\theta$), I get all my $r$'s canceling out -- leaving a limit dependent on theta. But according to the problem, this ratio should go to zero though. Does anyone know what's going on? I've seen other problems like this that show partials are not continuous at the the origin. That's different though from just establishing existance of the total derivative, right?","['multivariable-calculus', 'partial-derivative', 'derivatives']"
2730443,Probability - Peculiar die,"A peculiar die has the following properties: on any roll the probability of rolling either a $4$ , a $6$ , or a $1$ is $1/2$ , just as it is with an ordinary die. Moreover, the probability of rolling either a $1$ , a $3$ , or a $2$ is again $1/2$ . However, the probability of rolling a $1$ is $5/16$ , not $1/6$ as one would expect of an ordinary fair die. From what you know about this peculiar die, compute the following: a.    The probability of rolling either a $5$ , a $3$ , or a $2$ ; b.    The probability of rolling a $5$ . My answer Given $P(1) = \frac{5}{16}$ , then $$P(2) + P(3) + P(1) = P(2) + P(3) + \frac{5}{16} = \frac{1}{2} \iff P(2) + P(3) = \frac{3}{16}$$ Similarly, using $P(4) + P(6) + P(1) = \frac{1}{2}$ , I find $$P(6) + P(4) = \frac{3}{16}$$ b. $P(5) = 1 - \left(\frac{5}{16} + \frac{3}{16} + \frac{3}{16}\right) = \frac{5}{16}$ a. $P(5) + P(3) + P(2) = \frac{5}{16} + \frac{3}{16} = \frac{1}{2}$ Are my calculations correct?","['probability-theory', 'dice', 'probability', 'statistics']"
2730448,Tangent Space Coincides with Null Space of Jacobian When Full Rank,"This is for an optimization class, but I think what I am trying to prove is erring towards differential geometry, if that tag is inappropriate please remove it. My professor left this claim asserted but not proven, I would like to prove it. I found a lower dimensional case here on page 24 that I am trying to adapt. Here is the background, and the problem. Let $$g: \mathbb{R}^n \to \mathbb{R}^m,$$ $$g(\mathbf{x}) = [ g_1(\mathbf{x}), \dots , g_m(\mathbf{x})]^{T}$$ where $n \geq m$ and each $g_i$ is a $C^{1}$ map $\mathbb{R}^n \to \mathbb{R}$. Set $k$ to be the codim $n-m$. Define $S$ to be the zero locus of $g$ and for $\mathbf{x}_0 \in S$ define the tangent space $T_{\mathbf{x}_0}S$ to be the set of vectors $\mathbf{v}$ such that there exists a curve $\gamma(t) \subset S$ with $\gamma(0) = \mathbf{x}_0$ and $\gamma'(0) = \mathbf{v}$. Let $Dg(\mathbf{x}_0)$ denote the $m$ x $n$ Jacobian of $g$ at $\mathbf{x}_0$ and assume it has full rank. I would like to prove that $$\mathrm{Nul}(Dg(\mathbf{x}_0)) \subseteq T_{\mathbf{x}_0} S.$$ Here is what I have so far (almost entirely adapted from the link provided above). Suppose $\mathbf{v} \in \mathrm{Nul}(Dg(\mathbf{x}_0))$, then in particular $\nabla g_i(\mathbf{x}_0) \cdot \mathbf{v} = \mathbf{0}$ and all of the $\nabla g_i(\mathbf{x}_0)$ are linearly independent. After a suitable reordering of the variables, we can apply the Implicit Function Theorem  (exactly as stated on the wiki page here , reordering the variables so that $m$ x $m$ matrix is invertible, invoking the full rank of the Jacobian). Now denote the point $\mathbf{x}_0 = (x_1,\dots,x_k,y_1,\dots,y_m)$. Let $\mathbf{a} = (x_1,\dots,x_k)$ and $\mathbf{b} = (y_1, \dots, y_k)$. By invoking the IFT we have some open set $U \subset \mathbb{R}^k$, $\mathbf{a} \in U$, and the existence of a $C^{1}$ map $\phi \colon U \to \mathbb{R}^m$ such that $\phi(\mathbf{a}) = \mathbf{b}$ and $g(\mathbf{x},\phi(\mathbf{x}) = 0$ for all $\mathbf{x} \in U$. I am attempting to use all of the above to start building a parameterization $\gamma(t)$, but this is where I am stuck. I would like to define $\gamma_i(t) = x_i + v_i t$ for $1 \leq i \leq k$. Since $U$ is open I should be able to choose $\epsilon$ sufficiently small so that, at least for these first $k$ coordinates $\gamma$ stays in $S$ for $t \in (-\epsilon, \epsilon)$. But I don't know how to finish the next $m$ entries of $\gamma$. My assumption is that when the parameterization works out, the derivative portion of the Implicit Function Theorem combined with my hypothesis will allow me to say $\gamma'(0) = \mathbf{v}$. Thanks!","['optimization', 'implicit-function-theorem', 'differential-geometry', 'manifolds']"
2730464,"If $X$ and $Y$ are compact subsets of $\mathbb R^n$, then $X+Y$ is compact.","If $X$ and $Y$ are compact subsets of $\mathbb R^n$, then $X+Y$ is compact. Is the statement true in NLS. ""Since $X$ and $Y$ are compact then $X\times Y\subseteq\mathbb{R}^{2n}$ is compact, and use the continuity of the function $(x,y)\mapsto x+y$ and the fact that continuous images of compact sets are compact, to conclude that $X+Y$ is compact."" Can this idea be used?","['general-topology', 'real-analysis', 'compactness']"
2730507,Is this a field?,"Let $S$ be the set of all the ordered pairs in the cartesian plane. That is: 
$$S=\{(x,y)|\ \ x, y \in \Bbb{R}\}$$
Then, If $a=(a_1, a_2)$ and $b=(b_1, b_2)$ are two arbitrary elements of $S$, the following operations are defined: 
$$a+b=(a_1+b_1, a_2+b_2)$$
$$a\times b=(a_1\cdot b_1, a_2 \cdot b_2)$$ Also, let's state that $a=b$ iif $a_1=b_1$ and $a_2=b_2$. 
Associativity and commutativity of the operations are straight forward to prove. The multiplicative neutral element is $u=(1,1)$ and the additive neutral element is $o=(0,0)$. It's trivial to show why thse two elements are the respective neutral elements. Now, on additive inverses. For the arbitrary element $a\in S$, we can take $-a=(-a_1, -a_2)$, therefore: $$a+(-a)=(a_1+(-a_1), a_2+(-a_2))=(0,0)=o$$
This proves there are additive inverses. On multiplicative inverses, let's consider $b\neq o$, then if we take $b^{-1}=(\frac{1}{b_1}, \frac{1}{b_2})$, then: $$b\times b^{-1}=\bigg(b_1\cdot\frac{1}{b_1}, b_2\cdot \frac{1}{b_2}\bigg)=(1,1)=u$$
which shows the existence of multiplicative inverses. Finally, the distributive property: 
Let $c=(c_1, c_2)$ an element of $S$. Then: $a\times (b+c)=(a_1,a_2)\times (b_1+c_1, b_2+c_2)=(a_1b_1+a_1c_1, a_2b_2+a_2c_2)$ On the other hand, $a\times b+ a\times c =(a_1b_1, a_2b_2)+(a_1c_1, a_2c_2)=(a_1b_1+a_1c_1, a_2b_2+a_2c_2)$. Which means that $a\times(b+c)=a\times b+a\times c$. Did I make a mistake or fail to notice something? On the other hand, I'd love some help with the writing or style.","['abstract-algebra', 'real-numbers', 'field-theory']"
2730584,Differentiability of $\cos{|x|}$ and $\sin{|x|}$ at $x=0$,"Define differentiability of  $\cos{|x|}$ and $\sin{|x|}$ at $x=0$ It is said that $\cos|x|$ is continuous and $\sin|x|$ is discontinuous at $x=0$.
$$
Lf'(0)=\lim_{h\to 0^-}\frac{\cos|0+h|-\cos|0|}{h}=\lim_{h\to{0}}\frac{\cos h-1}{h}=Rf'(0)
$$
Thus $\cos|x|$ is continuous. Fine, but applying chain rule, let $|x|=t$
$$
\frac{d}{dx}\cos|x|\bigg|_{x=0}=\frac{d}{dx}\cos t\bigg|_{x=0}=\frac{d(\cos t)}{dt}.\frac{dt}{dx}\bigg|_{x=0}=-\sin t.\frac{dt}{dx}\bigg|_{x=0}=-\sin t.\frac{d|x|}{dx}\bigg|_{x=0}
$$
As $|x|$ is not differentiable at $x$=$0$, how can we define the derivative of $\cos|x|$ at $x=0$ ?","['derivatives', 'calculus']"
