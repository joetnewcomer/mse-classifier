question_id,title,body,tags
1969229,Integration of $\sin51x\sin^{49}x$,"$$\int\sin51x\sin^{49}x\ dx$$
I have tried integration by parts but couldn't come to any conclusion. Powers and multiples have some type of correlation, I guess. Please provide a hint.","['indefinite-integrals', 'integration', 'calculus']"
1969244,Uncountably many probability measures with disjoint supports,"I am trying to construct a family of probability measures satisfying the following properties: $A$ is an uncountable index set; for each $\alpha\in A$, $\mathbb P_{\alpha}$ is a probability measure on the unit interval (endowed with the Borel $\sigma$-algebra); if $C$ is an countable subset of this interval, then $\mathbb P_{\alpha}(C)=0$ for each $\alpha\in A$; there exist pairwise disjoint (!) Borel sets $(S_{\alpha})_{\alpha\in A}$ such that $P_{\alpha}(S_{\alpha})=1$ for each $\alpha\in A$. Can such a construction be explicitly given? Or at least can its existence be proven non-constructively (via Zorn’s lemma, for example)? Any hints would be greatly appreciated.","['probability-theory', 'measure-theory']"
1969345,Find values of $a$ and $b$ that make matrix orthogonal,"Given the matrix $$A=\begin{bmatrix}1/2&a\\b&1/2\\ \end{bmatrix}$$ find the values of $a$ and $b$ that make it orthogonal. So far I have tried using dot product $$(1/2)a+(1/2)b=0$$ and we can conclude that $a=-b$ and $b=-a$. I also tried the following theorem $$A^T=A^{-1}$$ so $$\begin{bmatrix}1/2&b\\a&1/2\\ \end{bmatrix}=
\begin{bmatrix}
(2+\frac{4ab}{1-4ab})&\frac{-4a}{1-4ab}\\
\frac{-4b}{1-4ab}&\frac{2}{1-4ab}\\ \end{bmatrix}$$ Can someone tell if I'am on the right track and point me in the right direction? Thanks!","['matrices', 'orthogonal-matrices', 'orthogonality', 'linear-algebra']"
1969378,What is the value of the series $\sum_{n\geq 1}\frac{1}{n^2+1}$?,"What is the value of $$\sum_{n=1}^{\infty}\frac1{1+n^2}$$
I don't know how to solve it. I tried to solve it by power series, but I failed.","['sequences-and-series', 'analysis']"
1969399,Calculate limit involving $\sin$ function,"Calculate the following limit:
$$\lim_{x \rightarrow 0} \frac{x-\overbrace{\sin (\sin (...(\sin x)...))}^{150\ \text{times}\ \sin}}{x^3}$$ I tried applying L'Hospital's rule, but it got too messy. Thank you in advance!",['limits']
1969435,Proof that uniform topology on $R^J$ is coarser than the box topology,"I was reading Munkres ""Topology"" and in metric topology section I've encountered a proof on why uniform topology on $ R^J$ is coarser than box topology. The argument goes like this :
If $B$ is an $\epsilon$-ball centered at $x$, then the box neighborhood
$$
\prod (x_\alpha - \frac{1}{2}\epsilon , x_\alpha + \frac{1}{2}\epsilon)
$$
is contained in $B$. It was just unclear to me why did the author choose $\frac{1}{2}\epsilon$ and not any other multiplier. Can it also be $\frac{7}{8}\epsilon$ or any number $\gamma\epsilon$ where $|\gamma|<1$?","['general-topology', 'metric-spaces']"
1969436,Kähler differentials on a smooth projective plane curve,"Let $C = \{f=0\} \subset \mathbb{P}_k^2$ be a smooth plane curve of degree $d$. I'm trying to find an explicit basis for $H^0(C,\Omega^1_{C/k})$. I know it should be $\frac{(d-1)(d-2)}{2}$ - dimensional. What I'm trying to find is an explicit collection of rational 1-forms on $C$ (basically elements in $k(C) \large{\frac{dx}{\partial_y f}}$) which when restricted to $C$ give a basis for all 1-forms. Sadly most of what I tried didn't get me anywhere and so I have no interesting attempts to share. Help would be really appreciated.","['algebraic-curves', 'coherent-sheaves', 'algebraic-geometry']"
1969463,Is this block matrix also totally unimodular?,"Suppose  matrix $A\in \mathbb R^{m\times n}$ is totally unimodular (TUM). Is the following matrix also TUM? $$
        \begin{pmatrix}
        A & 0 & 0 \\
        0 & A & 0 \\
        0 & 0 & A\\
        I & I & I\\
        \end{pmatrix}
$$ Thanks.","['integer-programming', 'matrices', 'unimodular-matrices', 'total-unimodularity', 'combinatorics']"
1969505,How to show $\text{Real}(z\sinh(-R + it)) = - \text{Real}(z) \cos(t) \text{sinh}(R) - \text{Imag}(z) \sin(t) \cosh(R)$?,"I came across the following expression where $z$ is complex and $R$ and $t$ are real numbers:
$\text{Real}(z\sinh(-R + it)) = - \text{Real}(z) \cos(t) \text{sinh}(R) - \text{Imag}(z) \sin(t) \cosh(R)$ I have never seen an identity like this before, how was it derived?","['trigonometry', 'geometry']"
1969536,Number of subsets when each pair of distinct elements is contained in exactly one subset,"Let $E$ be a set of cardinality $n$. Suppose $M_1, M_2, .. , M_m$ are
   distinct proper subsets of $E$ such that for each pair of distinct elements $x_1, x_2\in E$, there is exactly one $M_i\supseteq\{x_1,x_2\}$. Prove that $m \ge n$. It's obvious $n$ has to be greater or equal to $3$. Also, for $n=3$, it's easy to prove it, but I have no idea how to extend it. I think a proof using induction by $n$ is possible.","['combinatorics', 'linear-algebra']"
1969542,Find a matrix with given row and column sums,"Please forgive my intrusion. I've been working for days on this problem and it's vexing me. It doesn't seem to have a solution and I could really use some help. I have a ""math square"" (not a magic square) that looks like this when filled in $$
\begin{array}{ccccc|c}
9 & 4 & 8 & 4 & 7 & 32 \\
7 & 9 & 15 & 7 & 5 & 43 \\
3 & 2 & 9 & 10 & 9 & 33 \\
5 & 3 & 5 & 6 & 4 & 23 \\
\hline
24 & 18 & 37 & 27 & 25 & 131 \\
\end{array}
$$ However, the puzzle when empty looks like this. $$
\begin{array}{ccccc|c}
x & x & x & x & x & 32 \\
x & x & x & x & x & 43 \\
x & x & x & x & x & 33 \\
x & x & x & x & x & 23 \\
\hline
24 & 18 & 37 & 27 & 25 & 131 \\
\end{array}
$$ I need an equation of some sort to fill in the unknowns ($X$'s) and recreate the missing values. There appears to be some symmetry with the puzzle as the columns and row all add up to be the same which in this case is $131$. If you separate them by every other row to perhaps break it down to make it easier to solve you get. You could also do this with the columns but for simplicity I haven't written it here. $$
\begin{array}{ccccc|c}
9 & 4 & 8 & 4 & 7 & 32 \\
3 & 2 & 9 & 10 & 9 & 33 \\
\hline
12 & 6 & 17 & 14 & 16 & 65 \\
\end{array}
\dots
\begin{array}{ccccc|c}
7 & 9 & 15 & 7 & 5 & 43 \\
5 & 3 & 5 & 6 & 4 & 23\\
\hline
12 & 12 & 20 & 13 & 9 & 86   \\
\end{array}
$$ using these givens in the puzzle is allowed, but not the $X$'s If it is indeed unsolvable I would like to know but if it can what missing component can be add to achieve that goal? Your help is very much appreciated and thank you! Regards, Tony p.s. sorry about the formatting.","['linear-algebra', 'linear-programming']"
1969547,"What is the linearity-like property $f(x, a + b) = f(f(x, a), b)$ called?","A function $f : S \times \mathbb{R} \rightarrow S$ could have the property $$ f(x, a + b) = f(f(x, a), b) .$$ For example, with $S = \mathbb{R}$ it is true of $f(x, a) = x + ka$ and $f(x, a) = xk^a$. What can this property be called? It seems like it should be something “… linear …” but I don't know exactly what. The particular case I am immediately interested in describing using this term is that the property almost holds for the function
$$f(x, a) = (1 + ka)x$$
in which case we find that
$$
\begin{align}
f(f(x, a), b)
&= (1 + kb)(1 + ka)x \\
&= (ka + kb + k^2ab + 1)x \\
&= (1 + k(a + b + kab))x \\
&= f(x, a + b + kab)
\end{align}
$$
and we can then consider whether the difference $kab$ is small enough that $f(f(x, a), b)$ is a suitable approximation for $f(x, a + b)$ in the particular application.","['terminology', 'linear-approximation', 'functions']"
1969577,"If $a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right)$, then $\lim_{n\to\infty}a_{n} = ?$","If $\displaystyle a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right),a_{n}>0$, then $\lim_{n\rightarrow \infty}a_{n} = ?$ My try: It seems that when $n \rightarrow \infty$ then we can write $a_{n}=a_{n+1}=a_{n+2} = l$ (finite number), but I did not understand how I can prove that the sequence is strictly increasing. Help required. Thanks.","['sequences-and-series', 'limits']"
1969592,Creating an inverse function,"I have this function $f(x) = x^2 + 5x + 6$ And I want to convert it to an inverse function, but I don't really know where to begin. What I have done: $y = x^2 + 5x + 6$ $y - 6 = x(x+5)$ But now I feel lost.","['inverse-function', 'functions']"
1969631,What is the probability that $\min\limits_{i}\max\limits_{j} M_{ij}\gt \max\limits_{j}\min\limits_{i} M_{ij}$,"Assume you have a $n\times n$ matrix $M$, each entry is filled with a number from $1$ to $n^2$ randomly, and no two entries are the same. There are $n$ rows, select the max number of each row, so there are $n$ numbers. $A$ is defined as the minimum number of these $n$ numbers. To clarify: $$
A:= \min_{i}\max_{j} M_{ij}\\
B:= \max_{j}\min_{i} M_{ij}.
$$ What is $\Pr[A>B]$? Edit 1: The computer run has the following result: $$
0.332877, 0.698953, 0.886191, 0.960409, 0.986796, 0.995996, 0.99876, 0.999604, 0.999892
$$ This is from $n=2$ to $n=10$ Edit 2: More hint:
Computer check for $\Pr[A\ge B]$
$$
1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
$$ Code: import numpy as np
N = 1000000
ratio = []
for n in range(2,11):
    count = 0
    for j in range(N):
        m = np.random.permutation(n**2).reshape(n,n)
        a = min([max(m[i,:]) for i in range(n)])
        b = max([min(m[:,i]) for i in range(n)])
        if(a>b):
            count += 1
    ratio.append(count/N)

print(ratio)",['probability']
1969646,Ordinal vs nominal variables,"Im studying data analysis and Im with a doubt between nominal and ordinal variables, because sometimes it seems difficult to understand really what kind a variable is. For example, about nominal variables there is no meaningful rank between the categories, for example color of the eyes, or gender. And ordinal data where there is a meaningful rank between the categories, for example satisfaction with a service ""Very unsatisfied,..,..,.., very satisfied"". But this is always like this? For example if I have a varialble ""errortype"" that can have one of this values: (200,404,403,500) this is nominal right? But its strange, because there is some kind of meaningful rank, for example code 200 is better then 404, and so on. Other example is, If Im analysing a dataset to compare the performance of some servers and I have a variable server that can be one of this values (serverX, serverY, serverZ) and one server can have more capacity then oher, tihs is also nominal? Or because there is some kind of order, one server is better than other its ordinal?",['statistics']
1969690,Concave + convex = affine?,"A function $f$ is concave on $[a,b]$ if $$f((1-\lambda)a+\lambda b) \ge (1-\lambda)f(a) + \lambda f(b),\quad \forall \lambda\in[0,1]$$ and similarly $f$ is convex if $$f((1-\lambda)a+\lambda b) \le (1-\lambda)f(a) + \lambda f(b),\quad \forall \lambda\in[0,1]$$ Then it's clear that $f$ is concave and convex if $$f((1-\lambda)a+\lambda b) = (1-\lambda)f(a) + \lambda f(b),\quad \forall \lambda\in[0,1]$$ But then I'm told that this is equivalent to $f$ being affine.  That is that $f(x) = \alpha + \beta x$ for some constants $\alpha, \beta$.  How can I prove this from the above? All I'm getting by setting $(1-\lambda)a+\lambda b=x$ in the equation above is $$f(x) = (1-\lambda)f(\frac{x-\lambda b}{1-\lambda})+\lambda f(\frac{x-(1-\lambda a)}{\lambda})$$  which I don't seem to be able to get into the form $\alpha +\beta x$.","['algebra-precalculus', 'affine-geometry', 'convex-analysis', 'functions']"
1969705,Is there a formula for the expansion coefficients of powers of an inner product?,"I would like to expand the following expression $$\left(\sum_{i,j=1}^N \,x_i A_{ij} x_j\right)^n$$ where $\mathbf A$ is a symmetric $N\times N$ matrix, $\mathbf {x}$ is an $N$-component vector, and $n$ is a non-negative integer power.  The expansion of this expression yields a homogeneous polynomial of order $2n$ in the $x_k$. What is the coefficient of the term $x_1^{p_1} x_2^{p_2} \cdots x_N^{p_N}$ for $p_1 + p_2 + \cdots + p_N = 2n$ in the expansion of this expression? Has the formula been worked out before?","['multinomial-theorem', 'symmetric-matrices', 'polynomials', 'linear-algebra']"
1969748,Can we approximate delayed-differential equations with higher-order-ordinary-differential-equations?,"I noticed that the most simple numerical approximation of a higher order-differential equation has the same form as the numerical approximation of a delayed first-order differential equation. This leads me to the following hypothesis: Hypothesis: Delayed first-order differential equations can be approximated by higher-order ordinary differential equations. I wanted to investigate to what extent this is true so I came up with a method to find approximations of delayed differential equations. However, my initial tests seem to indicate that this approach doesn't work. I hope someone can explain why, and if there is a better, similar approach. Here is my approach: Take the simple delayed first-order differential equation for arbitrary function $f$:
$$\dot x(t+1)=f(x(t))$$
By taking $\Delta x =1$, this is numerically approximated by the difference equation:
$$x_{t+2}-x_{t+1}=f(x_t)$$
adding to both sides $x_t-x_{t+1}$, gives:
$$x_{t+2}-2x_{t+1}+x_t=f(x_t) - (x_{t+1}-x_t)$$
Which, if we again take $\Delta x =1$, is the numerical approximation of 
$$\ddot x (t)=f(x(t))-\dot x(t)$$ Hence we might approximate a simple first-order delayed equation by a higher order non-delayed equation:  $$\dot x(t+1)=f(x(t)), \quad \text {is approximated by}\quad 
 \ddot x(t)+\dot x(t)=f(x(t)) $$
  By the same approach we could show that 
  $$\dot x(t+2)=f(x(t)), \quad \text {is approximated by}\quad 
 \dddot x(t)+2\ddot x(t) +\dot x(t)=f(x(t))$$
  $$\dot x(t+3)=f(x(t)), \quad \text {is approximated by}\quad 
 \ddddot x(t)+3\dddot x(t) -3\ddot x(t)+\dot x(t)=f(x(t))$$
  And so forth... However, I've been using $\Delta x =1$ here. If we take $\Delta x=1/n$, and gradually increment $n$ upwards, a similar pattern to the one for larger delays occurs:
$$\dot x(t+1)=f(x(t))$$
is approximated for $n=2$ by:
$$2\cdot (x(t+1+\frac {1}{2})-x(t+1))=f(x(t))$$
using the same approach as above, but $\Delta x = \frac{1}{2}$ instead of $\Delta x = 1$, and a lot of tedious algebra, one can show that this is equivalent to the approximation of $$2^{-2}\dddot x(t)+2^{-1}\cdot 2 \ddot x(t)+2^{-0}\dot x(t)$$ Hence we might approach a closer and closer approximation of $\dot x(t+1)=f(x(t))$, by taking increasingly larger $n$, and smaller $\Delta x=\frac{1}{n}$, as follows: using $n=2$ (resulting in $\Delta x=\frac {1}{2} $):
  $$\dot x(t+1)=f(x(t)), \quad \text {is approximated by}\quad 
 n^{-n}\cdot \dddot x(t)+n^{-n+1}\cdot 2 \ddot x(t)+n^{-n+2} \cdot \dot x(t)$$
  and using $n=3$:
  $$\dot x(t+1)=f(x(t)), \quad \text {is approximated by}\quad $$
   $$n^{-n}\cdot \ddddot x(t) +n^{-n+1}\cdot 3\dddot x(t)+n^{-n+2} \cdot 3\ddot x(t)+ n^{-n+3}\cdot \dot x(t)$$ And so forth... The form of this approximation is the same as for $\Delta x =1$, but with higher delays, except for the coefficients of $n$. The most important point I noticed about this approximation is that as we increase $n$, increasingly higher order derivatives are added, but the coefficients of those derivatives seem to decrease hyperexponentially (i.e. $n^{-n}$). This made me hope that perhaps the approximations would converge quickly to the delayed equation as $\Delta x$ decreases. However, I did some tests on the delayed equation $\dot x(t)=x(t-1)$, and $\dot x(t) = x^2(t-1)$, where my approach fails miserably. increasing $n$ actually deteriorates the approximation. On the one hand (in hindsight) this makes sense to me, since increasing the order of the derivative should increase the rate of growth of $x$ for large $t$, but it still bugs me that it doesn't work, despite the fact that the difference equations for the two are so similar. So my question is: Why doesn't my approach work, given that the difference-equation approximations of delayed-differential-equations, and higher-order-differential equations have the same form? and more importantly, is there a different but similar approach to approximate delayed-differential-equations?","['ordinary-differential-equations', 'delay-differential-equations']"
1969751,Is it possible to cover a $8 \times8$ board with $2 \times 1$ pieces?,"We have a $8\times 8$ board, colored with two colors like a typical
  chessboard. Now, we remove two squares of different colour. Is it
  possible to cover the new board with two-color pieces (i.e. domino
  pieces)? I think we can, as after the removal of the two squares, we are left with $64-2=62$ squares with $31$ squares of each colour, and - since the domino piece covers two colours - we can cover the new board with domino pieces. But how should one justify it mathematically?","['combinatorics', 'coloring', 'tiling']"
1969819,Representing any number using only 0 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 7 years ago . Improve this question I am afraid to even ask this question, but this is something that was asked over a breakfast table by a friend of mine. How do I represent a number, say 4, by using just zeros as a numeral in tandem with any function or mathematical operator(s)? Now one way to do this is by using a factorial , since $0!=1$:
$$0! + 0! + 0! + 0!$$
Another way uses $\cos 0=1$:
$$\cos 0+\cos 0+\cos 0+\cos 0$$
Also, the topmost  $1$ on Pascal’s Triangle is the zero$^{th}$ row, zero$^{th}$ entry, i.e.,  $0C$$_0$ = $1$. The Partition function , P(n) is , by convention , defined as $1$ for $n=0$, i.e. , $P(0) = 1$. Is there any other way I could possibly achieve this?I would be more interested to know the functions which when applied on zero produce non-zero results , like the ones mentioned earlier in the question, rather than semantic manipulations or visual representations.","['algebra-precalculus', 'recreational-mathematics']"
1969837,substitution to homogeneous equation,"By making substitution  $y=zx^n$ choosing a convenient value of n  show that the following differential equations can be transformed
into equations with separable variables, and thereby solve this:
$dy/dx=\frac{1-xy^2}{2x^2y}$ My attempt: $F=2x^2dy=(1-xy^2)dx$ $2x^2dy-(1-xy^2)dx=0$
Substitutions: $y=zx^n$ and $ dy=x^ndz$ $2x^{2+2n}zdz+(x^{2n+1}z^2-1)dx=0$ $F_{xy}=F_{yx}$ After taking derivative we get $n=-1/2$ Which is the correct answer 
My question is that  $dy/dx=\frac{1-xy^2}{2x^2y}$ the -1 and 2 are just before $xy^2$ and $x^2y$ is n related to them I mean for every problem do I have to go through my way to get that or by dividing them can i get that? 
Because in the other problems of my book it is still the case.. Problems are $y'=\frac{2+3xy^2}{4x^2y}$ $ n=3/4$ $y'=\frac{y-xy^2}{x+x^2y}$ $n=-1$",['ordinary-differential-equations']
1969853,measure theory for dummies,"Is there a book with simplest examples one can ever imagine? For example: ""Lets say we have ""tree"" ""apple"" ""1"" . . ."" What is sigma algebra of this set, what is sigma algebra generated by something in this set, what is borel sigma algebra etc. It would be awesome if book covered main topics in measure theory that are important to probability and stochastic processes. Do such books exist?
For Aduh: Books i have read on measure theory use notation like this below. I want author instead  to explain intuition in simple way.","['reference-request', 'measure-theory']"
1969879,"Which is bigger? $Ackermann(G_{64}, G_{64})$ or $G_{G_{64}}$ [duplicate]","This question already has an answer here : If I call the Ackermann Function with Graham's number as both of its arguments will it be less than $g_{65}$ (1 answer) Closed 6 years ago . I have been playing around with the Ackermann function a bit and realized that it gets very big very fast. (Im going to use $A$ for $Ackermann$ throughout this question) Already $A(5,1)$ is (according to WolframAlpha ) an integer too large to represent. It also presents me with a representation that looks like this: $$
A(5,1) = 2 \uparrow \uparrow \uparrow 4 - 3 = 2 \uparrow^{3} 4 - 3
$$ After playing around a little I found out that it always represents it like this: $$
A(n,m) = 2 \uparrow^{n-2} (m+3)-3
$$ After seeing this I started to wonder what would happen if you use Graham's number as the arguments. Since the value of it would uncomprehensible I tried to find something to compare it against. Remembering how the number is defined I asked myself if $G_{G_{64}}$ is bigger than $A(G_{64},G_{64})$? Or in other words: $$
A(G_{64},G_{64}) = 2 \uparrow^{G_{64} - 2} (G_{64} + 3) - 3
$$
vs
$$
G_{G_{64}} = 3 \uparrow^{G_{G_{64}} - 1} 3
$$ I personally supspect it is $G_{G_{64}}$ since it  has a lot more arrows but I'm not entirely sure.","['number-theory', 'big-numbers', 'ackermann-function']"
1969895,Can Evans's proof for the theorem regarding global approximation of Sobolev functions be significantly simplified?,"Here $U$ is an open subset of $\mathbb{R}^n$. Above is a theorem regarding approximation of Sobolev functions in Evans's Partial Differential Equations. When I tried to the recover the proof on my own, I found that the proof might be much shorter than the one in the book. But it looks too simple to be true and I'm wondering if there is a big gap there. Here is my argument. Suppose $u\in W^{k,p}(U)$. Then $u\in L^p(U)$ by definition and thus $u\in L^1(U)$ since $U$ is bounded. Now according to the answer and comments to the following questions: convolutions and mollification of functions in $L^1_{\text{loc}}(\Omega)$ Properties of mollification for integrable functions one can define the mollification $u^\epsilon=\eta_\epsilon*u$ on $U$ such that $u_\epsilon\in C^\infty(U)$. Moreover, since 
$$
D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u \quad\textrm{in  } U, 
$$
one has 
$$
\|u^\epsilon-u\|_{W^{k,p}(U)}^p=\sum \|D^\alpha u^\epsilon-D^\alpha u\|_{L^p(U)}^p\to 0.
$$ Could anyone identify if there is any serious mistake in the above argument? [ Added :]A possible naive analogy I make in the above argument is as the following. First of all, I have the following facts $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha$ in $\color{blue}{U_\epsilon}$, where the definition can be seen in the linked question. Also, $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(V)$ for any $V\Subset U$. Now that I can do mollification on the entire domain $U$ instead of just $U_\epsilon$, I just guess one might have $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u$ in $\color{blue}{U}$. and $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(U)$. For the original ""long"" proof of THEOREM 2 by Evans, see this question .","['functional-analysis', 'sobolev-spaces', 'partial-differential-equations']"
1969909,Convolution of Pareto Random Variables,"Define $X$ ~ Pareto($a$) and $Y$ ~ Pareto($b$), meaning $f_X (x) = ax^{-a + 1}$ for $x \geq 1$ and $f_Y (y) = by^{-b + 1}$ for $y \geq 1$. Assuming that $X$ and $Y$ are independent random variables, how would I find the density of $Z = X + Y$ and $W = Z - Y$.","['probability-theory', 'convolution', 'random-variables', 'probability-distributions']"
1969912,Reference Request: Good Introduction to Functional Calculus,"I would like to know if there is a standard reference on functional calculus. In particular I am interested in understanding how the resolvant integral $$f(T) = \frac{1}{2\pi i}\int_{C} f(\lambda)[\lambda - T]^{-1}d\lambda$$ is used to derive formulas like the polynomial formula for $N\times N$ diagonalizable operators, $$P(T) = \sum_{j=1}^NP(\lambda_j)\prod_{k\neq j}\frac{\lambda_k-T}{\lambda_k-\lambda_j}$$ and in particular to calculate arbitrary powers of $N\times N$ diagonalizable matrices.","['functional-analysis', 'reference-request', 'hilbert-spaces', 'functional-calculus']"
1969916,Ito's product rule: Three processes,"I stumbled upon the following problem, I want to compute the stochastic differential of the following 3 processes: $dX_t = \mu_{X,t}dt + \sigma_{X,t}dW_t$ $dY_t = \mu_{Y,t}dt + \sigma_{Y,t}dW_t$ $dZ_t = \mu_{Z,t}dt + \sigma_{Z,t}dW_t$ That is, I want to calculate $d(X_tY_tZ_t)$ using Ito's product rule Now from the aforementioned product rule I know that $d(X_tY_t) = X_tdY_t + Y_tdX_t + \sigma_{X,t}\sigma_{Y,t}dt$. I tried to write $P_t = X_tY_t$ and substitute to calculate $d(P_tZ_t)$. I obtained the process $d(X_tY_tZ_t) = X_tY_tdZ_t + X_tZ_tdY_t + Y_tZ_tdX_t + Z_t\sigma_{X,t}\sigma_{Y,t}dt + \sigma_{P,t}\sigma_{Z,t}dt$ but do not know how to work out the last volatility product. The correct process is apparently equal to $d(X_tY_tZ_t) = X_tY_tdZ_t + X_tZ_tdY_t + Y_tZ_tdX_t + Z_t\sigma_{X,t}\sigma_{Y,t}dt + X_t\sigma_{Y,t}\sigma_{Z,t}dt+Y_t\sigma_{X,t}\sigma_{Z,t}dt$ I was hoping if somebody could help me arriving at the above equation. Moreover, I am also curious to find out how to calculate the SDE $d(X_t/Y_t)$, given that the processes $X_t$ and $Y_t$ are the same as given above. If somebody knows how to tackle this one, I would be very grateful for your help. Many thanks in advance.","['ordinary-differential-equations', 'stochastic-calculus']"
1969930,Measure where every set is Measurable,"For the Lebesgue measure the Vitali set is a famous construction of a nonmeasurable set. I was wondering if we could define some non-trivial outer measure on $2^{\mathbb{R}}$ such that every set is measurable with respect to this measure, or if there always exist nonmeasurable sets with respect to nontrivial measures. (of course we can define the outer measure that is zero on all subsets of $\mathbb{R}$ but i was wondering if we could say something more interesting. If such a measure exists does it have any interesting properties, i.e. does there exist some measure with this property that is Borel-regular? or even Radon? (this seems highly unlikely to me but I'm interested in) I would also like to assume the axiom of choice here.","['real-analysis', 'measure-theory']"
1969934,How can we solve $\lim\limits_{n \to \infty} \left (1 + \frac{1}{n} \right)^n$? [duplicate],"This question already has answers here : How to prove $\lim\limits_{n \to \infty} (1+\frac1n)^n = e$? (4 answers) Closed 6 years ago . Taken from Wikipedia : The number $e$ is the limit $$e = \lim_{n \to \infty} \left (1 + \frac{1}{n} \right)^n$$ Graph of $f(x) = \left (1 + \dfrac{1}{x} \right)^x$ taken from here. Its evident from the graph that the limit actually approaches $e$ as $x$ approaches $\infty$. So I tried approaching the value algebraically. My attempt: $$\lim_{n \to \infty} \left (1 + \frac{1}{n} \right)^n$$
$$= \lim_{n \to \infty} \left(\frac{n + 1}{n}\right)^n$$
$$= \left(\lim_{n \to \infty} \left(\frac{n + 1}{n}\right) \right)^n$$
$$= 1^\infty$$ which is an indeterminate form. I cannot think of any other algebraic manipulation. My question is that how can I solve this limit algebraically?","['exponential-function', 'indeterminate-forms', 'limits']"
1969937,Find the remainder of a number when divided by $9$,"Find the remainder when the number $$1234567891011121314151617\ldots200820092010$$ is divided by $9$. Show your work. I don't even know where to begin. Is there an underlying trick in finding the remainder of a number after being divided by $9$? Morever, how do we even find the remainder when the number is this large... This was a challenge problem. Meaning I didn't learn this in class.",['algebra-precalculus']
1969939,The set of all absolute local maximums of $f$ is countable,"The function $f:\mathbb R \rightarrow \mathbb R$ has absolute local maximum in $c$ if  : There exists $\delta \gt 0 $ such that $ \forall x \space (0 \lt |x-c| \lt \delta) \implies f(x) \lt f(c)$ Prove that the set of all points in which $f$ has absolute local maximum is countable. Note 1 : Is this method right?  I believe that the set mentioned above, is a subset of all local maximum points of $f$. So, if i prove that ""the set of all local maximum points of $f$"" is countable, I'm done.  But, if that's true, How can i prove that? Note 2 : There is a similar question ( not the same ) to my question but it doesn't have a good answer.","['real-analysis', 'elementary-set-theory']"
1969999,Trigonometry and integrals,"related picture In my book it says $ \frac{x}{R} = \tan\theta$ 
ok, that is pretty obvious, but then it says that it implies that $$ \frac{dx}{r^2} = \frac{R\,d\theta}{r^2 \cos^2 \theta} = \frac{d\theta}{R}$$ I really cannot understand how $d\theta$ got involved at all. Can anyone please try to explain the connection?","['physics', 'integration', 'trigonometry']"
1970013,"Given $K(\alpha)/K$ and $K(\beta)/K$ disjoint extensions with at least one of them odd degree then $K(\alpha,\beta)=K(\alpha\beta)$","I have problems with this exercise Let be $K(\alpha)/K$ and $K(\beta)/K$ disjoint extensions with at least one of them odd degree. Prove that $\alpha\beta$ is a primitive element for the extension $K(\alpha,\beta)/K$. Some of my ideas were Prove that $K(\alpha,\beta) \subset  K(\alpha\beta)$ or that $K(\alpha) \subset K(\alpha\beta)$. Use that in this situation $K(\alpha)=K(\alpha^2)$. Tried to relate the irreducible polynomials from the extensions involved. I didn't find anything useful. Can you help me? Thank you in advance.","['abstract-algebra', 'extension-field', 'field-theory']"
1970016,Calculate $\int ^{\pi}_0\ln(1+\alpha \cos x) dx$,"Calculate $$\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$ for $|\alpha|<1$. I tried Let 
$$f(\alpha)=\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$ 
then
$$\frac{df}{d\alpha}=\int^{\pi}_0\frac{\cos x}{1+\alpha \cos x}dx$$
But it seems need some other tricks... Then I tried 
$$
\begin{align}
\int^{\pi}_0\ln(1+\alpha\cos x) dx &=\int^{\pi}_0[\ln(1+\alpha\cos x)-\ln1]dx\\
&=\int^{\pi}_0[\ln(1+y\cos x)]^{y=\alpha}_{y=0}dx\\
& =\int^{\pi}_0[\int^{\alpha}_0\frac{\cos x}{1+y\cos x}dy]dx
\end{align}
$$ Any help? Thanks~","['calculus', 'functions']"
1970079,Finding the lower bound using Chebyshev's theorem,"If the probability density of $X$ is given by
  $$f(x)= \begin{cases}
630x^4(1-x)^4&& \text{for } 0 <x<1\\ 
 0 && \text{elsewhere.}\\
\end{cases}$$
  Find the probability that it will take on a value within two standard deviations of the mean and compare this probability with the lower-bounded provided by Chebyshev's theorem. Let $\sigma$ be the standard deviation and $\mu$ be the mean. How does one find the variance? $\sigma^2$. I know one must use the formula $\sigma^2= \mu^{'}_{2}-\mu^{2}$ In order to solve this one must integrate. = $\int 630x^4(1-x)^4dx$ I cannot go any further than this as I do not know how to find the upper and lowerbounds. EDIT After doing some extensive math I figured out that $\mu = .5$ because $\mu = \int^{1}_{0} x\cdot630x^4(1-x)^4 dx = .5$ $\mu_{2} =\int_0^1 x^2\cdot630x^4(1-x)^4dx= \frac{3}{11}$ $\sigma^2= \mu_{2}-u^{2} = \frac{3}{11}-(\frac{1}{2})^2=.0227 \rightarrow \sqrt{.0227} =  .20 \text{ or } .15$ So $\int_{.20} 630x^4(1-x)^4$ Now in order to finish the problem we must find what the upperbound is and this where I am lost. Chebyshev’s Theorem If $\mu$ and $\sigma$ are the mean and the standard
deviation of a random variable X, then for any positive constant
k the probability is at least $1- \frac{1}{k^2}$ that X will take on a value within k standard deviations of the mean; symbolically $$P(|x-\mu|<k \sigma) \ge 1- \frac{1}{k^2}, \sigma \neq 0$$ Proof $$\sigma^2 = E[(X-\mu)^2] = \int^{\infty}_{-\infty} (x-\mu)^2f(x)dx$$ Diagram for Chebyshev’s theorem. Then dividing the integral into three parts as shown above $$\sigma^2 = \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+ \int^{\mu + k\sigma}_{\mu-k\sigma}(x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k\sigma} (x-\mu)^2f(x)dx$$ Since the integrand $(x-\mu)^2f(x)$ is nonnegative we can from the inequality $$\sigma^2 \ge \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k \sigma} (x-\mu)^2f(x)dx $$ by deleting the second integral. Therefore since $(x-\mu)^2 \ge k^2\sigma^2 \text{ for } x \le \mu -k\sigma \text{ or }  x \ge \mu+k\sigma \text{ it follows that }$ $$(\sigma)^2 \ge \int^{\mu-k\sigma}_{-\infty} k^2\sigma^2f(x)dx+\int^{\infty}_{\mu+k\sigma} k^2\sigma^2f(x)dx$$ and hence that $$\frac{1}{k^2} \ge \int^{\mu-k\sigma}_{-\infty} f(x)dx+ \int^{\infty}_{\mu+k\sigma}f(x)dx$$ provide $\sigma^2 \neq 0$ Since the sum of the two integrals on the right-hand side
is the probability that X will take on a value less than or equal to $\mu-k\sigma$
or greater than or equal to $\mu+k\sigma$, we have thus shown that $$P(|X-\mu| \ge k\sigma) \le \frac{1}{k^2}$$ and it follows that $$P(|X-\mu| \lt k\sigma) \ge 1 - \frac{1}{k^2}$$","['statistics', 'integration', 'probability', 'calculus']"
1970087,"Quick bijection between $\mathbb{Q}\cap (a,\ b)$ and $\mathbb{Q}$ [duplicate]","This question already has answers here : Is there a bijection between $(0,1)$ and $\mathbb{R}$ that preserves rationality? (4 answers) Closed 7 years ago . I need a really quick way of showing there's a bijection from $\mathbb{Q}\cap(a,\ b)$ to $\mathbb{Q}$ for any real numbers $a < b$. I attempted a few ways but I'm drawing a blank right now .Nothing I've worked on is fruitful (it either goes nowhere or is much too complicated) so I'm omitting it from the question. Any simple ideas? Mainly I'm looking for something that can be rigorously justified and explained in a matter of no more than three to four lines. Clarification: I don't need to construct a bijection, I just need to show that there is one. Clarification 2: The context I'm working in doesn't have a definition of ""countable"", so I can't just say both sets are countable unfortunately. Clarification 3: We know that there exists a bijection from $\mathbb{Q}$ to $\mathbb{N}$. Our construction was essentially that you can list all elements of $\mathbb{Q}$ in a grid and spiral outwards from the origin, ignoring duplicates, and assigning the next natural to the next unique rational in the spiral path.",['elementary-set-theory']
1970094,What is a nonnegative complex number?,"I'm reading Linear Algebra by Axler, and he states in page 225 that «a complex number is nonnegative iff it has a nonnegative square root». What does the author mean by this? Any help would be appreciated.","['linear-algebra', 'complex-numbers']"
1970123,"If $f(x)=0 \implies f'(x)>0$, is the zero set of $f$ a single point?","Let $f:\mathbb R \to \mathbb R$ be a real-valued differentiable function. Suppose that $f'(x)>0$ for every $x$ such that $f(x)=0$. Does it follow that the number of zeroes of $f$ is at most one? This sounds quite reasonable to me: it seems intuitive that if $x_1, x_2$ are two different zeroes of $f$, then a third zero with negative derivative should lie between them. I can't seem to adapt this argument to a solid proof though. Is there any way to prove (or disprove!) this fact in a quick fashion?","['derivatives', 'real-analysis', 'roots']"
1970162,Infinite sequences of integers is uncountable,"An example presented in my course notes is that the set of all infinite sequences of integers is uncountable . To prove this, my professor elected to assume that this set were countable, and provided a contradiction similar to Cantor's diagonalization argument, defining a sequence which could not be equal to some sequence in our denumerable set. Out of curiosity however I think I came up with another proof employing cardinal arithmetic, and wanted to know if it looks okay. My primary concern is whether it is correct and reasonable to simply state that this set is expressible by $\mathbb{N}^{Z}$. Proof : This set of infinite sequences is expressible via $\mathbb{N}^{\mathbb{Z}}$. Then 
$$
\left|\mathbb{N}^{\mathbb{Z}}\right| = \left|\mathbb{N}\right|^{|\mathbb{Z}|} = \aleph_{0}^{\aleph_{0}} \leq (2^{\aleph_{0}})^{\aleph_{0}} = 2^{(\aleph_{0}\cdot \aleph_{0})} = 2^{\aleph_{0}} \leq \aleph_{0}^{\aleph_{0}}
$$
shows that $\left|\mathbb{N}^{\mathbb{Z}}\right| = c$ and thus it is uncountable. $\square$","['cardinals', 'elementary-set-theory', 'proof-verification']"
1970180,Using a bicycle to calculate areas,"I'm organizing a maths divulgation thing on my school and I found this interesting talk on youtube where a mathematician uses a bicycle to calculate the area inside a closed curve. Here it is: https://youtu.be/hukIyIYjto4?t=2827 (it starts at 47:07, and, well ,it's in Portuguese) He walks the front wheel of the bicycle through the curve, and uses the distance traveled by the back wheel to calculate the area. We would like to replicate this experiment, but the video doesn't give enough details to do that, nor does it give any information on the mathematics behind it... can somebody here help us out on finding out more information on this thing?",['differential-geometry']
1970203,"Erratum for Billingsley’s $\textit{Probability and Measure}$, Problem 32.13","This is a verification request for a counterexample that I think I have found for Problem 32.13 on page 427 in Patrick Billingsley’s Probability and Measure textbook (third edition, but the problem appears unaltered in other editions, too). The result to be proven in this problem is quoted (almost) verbatim: Suppose that $\mu$ is a Borel probability measure on $\mathbb R$ , that $\nu$ is a $\sigma$ -finite Borel measure on $\mathbb R$ , and that $\nu\ll\mu$ (that is, $\nu$ is absolutely continuous with respect to $\mu$ ). Show that the Radon–Nikodym derivative $f$ satisfies $$\lim_{h\downarrow0}\frac{\nu(x-h,x+h]}{\mu(x-h,x+h]}=f(x)$$ on a set of $\mu$ -measure $1$ . I can prove this result if $\nu$ is assumed to be finite (using an earlier result presented in Problem 31.22 on page 419; the key condition is the $\mu$ -integrability of the Radon–Nikodym derivative), or even regular (that is, finite on compact sets—thanks to Dominique R.F. for pointing this out in a comment below). However, the assumption that $\nu$ is merely $\sigma$ -finite (but potentially irregular) does not seem to be strong enough to ensure that the current result holds. I present a counterexample below, for which I welcome any feedback. Let $p$ denote the point mass at the point $1/2$ . This is a probability measure that assigns each Borel subset $A$ of the line a value $p(A)\in\{0,1\}$ according as $1/2\in A$ or $1/2\notin A$ . Furthermore, let $\lambda$ denote the Lebesgue measure. Define, for each Borel set $A$ , $$\mu(A)\equiv\frac{1}{2}\lambda(A\cap(0,1))+\frac{1}{2}p(A).$$ It is easy to check that $\mu$ is a probability measure on $\mathbb R$ and is supported on $(0,1)$ . Furthermore, if $f:\mathbb R\to[0,\infty)$ is a real-valued, non-negative, Borel-measurable function, then it is not difficult to prove that $$\int f(t)\,\mathrm d\mu(t)=\frac{1}{2}\int_0^1f(t)\,\mathrm d t+\frac{1}{2}f\left(\frac{1}{2}\right),$$ where $\mathrm dt$ denotes simply integration with respect to the Lebesgue measure. Now consider the following function on $\mathbb R$ : \begin{align*}
f(x)\equiv\begin{cases}\dfrac{1}{x-\dfrac{1}{2}}&\text{if $x>\dfrac{1}{2}$,}\\\dfrac{1}{\dfrac{1}{2}-x}&\text{if $x<\dfrac{1}{2}$,}\\0&\text{if $x=\dfrac{1}{2}$.}\end{cases}
\end{align*} Clearly, $f$ is real-valued, non-negative, and Borel-measurable. Now define, for each Borel set $A$ , $$\nu(A)\equiv\int_Af(t)\,\mathrm d\mu(t).$$ Then, $\nu$ is a measure and it is $\sigma$ -finite, because letting $$A_n\equiv\{x\in\mathbb R\,|\,n-1\leq f(x)<n\}\quad\text{for each $n\in\mathbb N$},$$ it is easily seen that $$\mathbb R=\bigcup_{n\in\mathbb N} A_n$$ (given that $f$ never assumes infinite or negative values) and that $$\nu(A_n)=\int_{A_n}f(t)\,\mathrm d\mu(t)\leq\int_{A_n}n\,\mathrm d\mu(t)=n\mu(A_n)\leq n<\infty$$ for each $n\in\mathbb N$ . Furthermore, $\mu(A)=0$ implies that $\nu(A)=0$ for any Borel set $A$ , and $f$ is the Radon–Nikodym derivative of $\nu$ with respect to $\mu$ (almost unique with respect to $\mu$ ). Therefore, all the premises corresponding to Billingsley’s statement are satisfied. Letting $x=1/2$ and $h\in(0,1/2)$ , one can see that $$\nu\left(\frac{1}{2}-h,\frac{1}{2}+h\right]=\int_{\left(\frac{1}{2}-h,\frac{1}{2}+h\right]}f(t)\,\mathrm d\mu(t)=\frac{1}{2}\int_{\frac{1}{2}-h}^{\frac{1}{2}+h}f(t)\,\mathrm dt+\frac{1}{2}\underbrace{f\left(\frac{1}{2}\right)}_{=0}=\infty,$$ given how $f$ has been defined. On the other hand, $\mu\left(\frac{1}{2}-h,\frac{1}{2}+h\right]=h+\frac{1}{2}>0,$ so that $$\lim_{h\downarrow0}\dfrac{\nu\left(\dfrac{1}{2}-h,\dfrac{1}{2}+h\right]}{\mu\left(\dfrac{1}{2}-h,\dfrac{1}{2}+h\right]}=\infty\neq0=f\left(\frac{1}{2}\right).$$ Hence, the conclusion does not hold at $x=1/2$ , so it cannot hold almost everywhere with respect to $\mu$ given that $\mu(\{1/2\})=1/2>0$ . Clearly, $\nu$ in this counterexample is irregular; even though it is $\sigma$ -finite, an infinite mass “accumulates” in arbitrarily small neighborhoods around the point $1/2$ .","['probability-theory', 'measure-theory', 'solution-verification']"
1970278,"If $f''(x)+2f'(x)+3f(x)=0$, then $f$ is infinitely differentiable","I came across this problem: which of the following statements are true regarding differentiability. Is the following statement true? If $f$ is twice continuously differentiable in $(a,b)$ and if for all $x\in(a,b)$ , $$f''(x)+2f'(x)+3f(x)=0$$ , then $f$ is infinitely differentiable in $(a,b)$ . I understand the argument using induction. However, I am wondering if the following argument makes sense or not? My argument: Solve the differential equation $y''+2y'+3y=0$ , we get the general solution $$y=C_1 e^{-x}\sin{\sqrt{2}x}+C_2e^{-x}\cos{\sqrt{2}x}$$ , which is infinitely differentiable. My friend thinks that my argument is not correct, since I cannot guarantee that all possible $f$ has to be in form of the general solution. I am confused. Is my reasoning correct?","['real-analysis', 'ordinary-differential-equations', 'alternative-proof']"
1970337,Why is statistics considered a different discipline than mathematics rather than as a branch of mathematics?,"I see that all my understanding of statistics (& so of probability which is a branch of statistics) from high school came from the mathematics textbook and it all appears too mathematical to be accepted as a branch of mathematics but why then it isn't considered a branch of mathematics? Edit 1 The first two answers I've got are contradicting each other one is claiming that it (statistic) falls under the domain of measure theory which is a branch of mathematics. So, it's entirely mathematical. The other one is saying that they are different.","['probability-theory', 'learning', 'education', 'statistics']"
1970422,"find $\lim_{(x,y)\to (0,0)} \frac{x^2y^2}{x^4+y^4}$","if $$f(x,y)=\frac{x^2y^2}{x^4+y^4}$$ is a 2 variable function, find $$\lim_{(x,y)\to (0,0)} \frac{x^2y^2}{x^4+y^4}$$ I really don't understand 2 variable limits. I understand that if limits from 2 or more paths aren't the same, the limit doesn't exist, but I don't know how to find the limit since there is an infinite number of paths possible.","['multivariable-calculus', 'calculus', 'limits']"
1970425,What exactly is a matrix transformation?,"I'm confused on the notation for $\mathbb{R}^{m}$ and $\mathbb{R}^{n}$ and its relationship to linear transformations. We say that $\mathbb{R}^{m}$ is just the space of column vectors since there are n columns, right? If so, then what do we mean when we say T: $\mathbb{R}^{m} \mapsto \mathbb{R}^{n}$ is equivalent to $T_A(X) = AX$? I watched a video on linear algebra (essence of Linear Algebra) that (only if I'm remembering correctly) that all matrix multiplication was is the change of the standard basis vectors such as $\hat{\imath} \space \hat{\jmath}$ landed on different spots in the same dimension. What is exactly going on here? Can you have linear transformations that don't depend on the number of rows or columns to be the same? Geometrically, what is going on? It seems like I have no idea what is going on in a matrix at all.","['matrices', 'linear-algebra', 'linear-transformations']"
1970429,Pseudosphere covered by upper half-plane,"Consider the (half) pseudosphere (with radius 1), which is the surface of revolution in $\mathbb{R}^3$ generated by the tractrix parametrized by (for $t \geqslant 0$)
$$ t \mapsto (t -\operatorname{tanh} t, \operatorname{sech} t)~.$$ According to Wikipedia (see pseudosphere ), this surface is covered by the region $\{y \geqslant 1\}$ of the upper half-plane, with covering map given explicitely by:
$$(x,y)\mapsto \big(v(\operatorname{arcosh} y)\cos x, v(\operatorname{arcosh} y) \sin x, u(\operatorname{arcosh} y)\big)$$
where $t \mapsto (u(t),v(t))$ is the arclength parametrization of the tractrix above. Ok. So in particular, we should have
$$dX^2 + dY^2 + dZ^2 = \frac{dx^2 + dy^2}{y^2}~,$$
right? Here I have denoted of course
$$X = v(\operatorname{arcosh} y)\cos x \qquad Y = v(\operatorname{arcosh} y) \sin x \qquad Z = u(\operatorname{arcosh} y)~.$$ But without even bothering to compute the arclength parametrization, isn't it the case that:
$$dX^2 + dY^2 + dZ^2 = \big(v(\operatorname{arcosh} y)\big)^2 \, dx^2 \, + \, \frac{\big(u'(\operatorname{arcosh} y))^2 + \big(v'(\operatorname{arcosh} y)\big)^2}{y^2-1}dy^2$$
so in particular already the coefficient of $dy^2$, namely $\dfrac{1}{y^2-1}$, seems to be wrong. Am I going wrong somewhere, or is Wikipedia?","['riemannian-geometry', 'covering-spaces', 'curvature', 'hyperbolic-geometry', 'differential-geometry']"
1970441,can a set have elements and sets?,"I have couple of questions about set theory. 1) suppose that $$X=\{1,2 ,3 , \{1\}, \{2,3\}\}$$
So is $X$ a correct set? 
I know that there is a set of sets, but can a set be a collection of elements and sets? 2) let 
$$A=\{a │a \text{ is a proper subset of X},X=\{x\} \}$$ Is $A$ an empty set? 
My understanding to proper subset is that if $$ A ⊂ B $$ then $A$ has some of $B$ elements but not all of them. And since $X$ in the above has only one element, then $A$ should be empty. Please correct me if I'm wrong.",['elementary-set-theory']
1970443,What does it exactly mean if a morphism of sheaves is surjective?,"Assume that the sheaves below are sheaves of abelian groups based on a topological space $X$ as Hartshorne did in his Algebraic Geometry . So on page 64, Hartshorne introduces two notions: the sheaf $\mathscr F^+$ associated to the presheaf $\mathscr F$ and a morphism of sheaves being surjective, so a morphism $\varphi:\mathscr F\longrightarrow \mathscr G$ is surjective if im$\mathscr F$ = $\mathscr G$. However, as the definition on the same page, for any open set $U$ of $X$, im$\mathscr F(U)$ is the set of functions $s$ from $U$ to $\cup$ preim$\mathscr F_{p}$, but the sheaf $\mathscr G$ is just an abstract sheaf. What exactly does it mean that the maps in im$\mathscr F$ equal $\mathscr G$?","['sheaf-theory', 'algebraic-geometry']"
1970459,Linear regression: how does multicollinearity inflate variance of estimators,"Suppose I have a multiple linear regression model $Y_i = \beta_0 + \beta_1 * X_{i1} + ... \beta_p * X_{ip} + \epsilon_i$ where $\epsilon_i \sim N(0, \sigma^2)$ and $Cov(\epsilon_i, \epsilon_j) = 0$ for $i \neq j$. If two of the predictors are correlated, then that will inflate the variance of the coefficient estimates, leading to invalid inferences. In the MLR setting, the variance of the least squares estimator $\hat{\beta}$ is $\sigma^2(X'X)^{-1}$. Can someone give me some mathematical intuition as to why $\sigma^2(X'X)^{-1}$ will inflate/become unstable if there's multicollinearity?","['regression', 'statistics', 'variance', 'statistical-inference']"
1970479,Prove that a ring R having the property that every ﬁnitely generated R-module is free is either a ﬁeld or the zero ring.,"https://wj32.org/wp/wp-content/uploads/2012/12/advanced-linear-algebra.pdf https://www.physicsforums.com/threads/about-r-module.313248/ http://isites.harvard.edu/fs/docs/icb.topic256346.files/Set%207.pdf http://121.192.180.130:901/media/5225/homework13.pdf http://121.192.180.130:901/media/5252/2015-01-07abstract%20algebra32.pdf These are proofs that I can find so far. But among all of them, I cannot understand a point that: I think all of these proofs only shows that if $R/I$ is a free module over R, than R must be either a field or the zero ring. But I cannot see how does it imply the fact that: If every finitely generated R-module is free, then R must be either a field or the zero ring. Could someone tell me how to show that? Thank so much!","['modules', 'abstract-algebra', 'ring-theory', 'free-modules', 'proof-explanation']"
1970511,"If $\sin A+\sin B+\sin C=\cos A+\cos B+\cos C=0$, prove that:......","If $\sin A+\sin B+\sin C=\cos A+\cos B+\cos C=0$, prove that: $\cos 3A+\cos 3B+ \cos 3C=3\cos(A+B+C)$. My Attempt; Here, $$e^{iA}=\cos A+i\sin A$$
$$e^{iB}=\cos B+i\sin B$$
$$e^{iC}=\cos C+i\sin C$$ Then,
$$e^{iA}+e^{iB}+e^{iC}=0$$ Now, what should I do further. Please help.",['trigonometry']
1970524,Where can I find data on which to base mathematical modeling with differential equaitons?,"Where can I find data and models on which to base mathematical modeling with differential equations? We are building a community of colleagues interested in using modeling to motivate teaching differential equations and we seek good sources of data and models to offer colleagues. Any leads, examples, pointers, engagements, etc. would be appreciated. Brian Winkel, Director SIMIODE at www.simiode.org.  Thank you.",['ordinary-differential-equations']
1970552,How to solve $y'' + y = y^{-3}$,I am trying to solve a central force problem and came to an equation like this: $$\frac{d^2 y}{dx^2} + y = \frac{1}{y^3}$$ I can't find a decent method to solve it.,"['physics', 'ordinary-differential-equations']"
1970562,"""Strong"" translations are continuous for $L^p$?","Say $\Omega\subset\mathbb R^n$ is a bounded set. Let $p\in[1,\infty)$, and $f\in L^p(\Omega)$. It is well-known that
$$
\sup_{|h|\leq\rho}\Vert f(\cdot+h)-f\Vert_{L^p(\Omega)}\longrightarrow0
$$
as $\rho\searrow0$. My question is: what if one brings the supremum inside the integral? More precisely, is it the case that if $f\in L^p(\Omega)$, then
$$
\left(\int\limits_{\Omega}\text{ess}\sup_{|h|\leq\rho}|f(x+h)-f(x)|^p\,dx\right)^{\frac1p}\longrightarrow0\quad\text{as}\quad \rho\searrow0\quad?\tag1
$$ It is trivial to show (1) for $\phi\in C_c^\infty(\Omega)$ (or even just uniformly continuous functions on $\Omega$). Through some work (approximate through mollifiers), (1) can be shown for essentially bounded functions on $\Omega$. I have not thought yet of a counter-example in a more general case, and I'm not sure whether it is even true. My intuition tells me that it should be false, since putting the supremum inside is effectively an $L^\infty$-constraint. If a counter-example exists, it seems like it must be a function which blows up at every scale. In any case, any help is appreciated!","['real-analysis', 'lp-spaces', 'analysis']"
1970571,Integral of product of two inverse regularized incomplete beta functions,"I want to compute the integral of the product of two inverse regularized incomplete beta functions over $[0,1]$ in closed form, that is, to evaluate
  $$ J = \int_0^1 I_t^{-1}(a_1,b_1) \: I_t^{-1}(a_2,b_2) \: \mathrm{d}t $$
  in terms of parameters $a_1, b_1, a_2, b_2 > 0$. Let us first collect few useful facts: (Indefinite integral) $\displaystyle\int I_{t}^{-1}(a,b)\:\mathrm{d}t = \frac{\left(I_t^{-1}(a,b)\right)^{a+1}}{(a+1)\:B(a,b)}\:_2 F_1\left(a+1, 1-b; a+2; I_t^{-1}(a,b)\right) + \text{constant}$. (Derivative) $\displaystyle\frac{\mathrm{d}}{\mathrm{d}t}I_t^{-1}(a,b) = B(a,b)\:\left(I_t^{-1}(a,b)\right)^{1-a}\:\left(1-I_t^{-1}(a,b)\right)^{1-b}$. (Boundary evaluation) $I_0^{-1}(a,b) = 0, \quad I_1^{-1}(a,b)=1$. ( Gauss's Hypergeometric theorem ) $_2 F_{1}(p,q;r;1) = \dfrac{\Gamma(r) \:\Gamma(r-p-q)}{\Gamma(r-p)\:\Gamma(r-q)}$. (Complete Beta and Gamma functions) $B(a,b) = \dfrac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$. Integrating-by-parts the original integral $J$ by taking $I_t^{-1}(a_1,b_1)$ as the first function, and $I_t^{-1}(a_2,b_2)$ as the second, we are led to $J = J_1 - J_2$, with a simple expression for
\begin{align}
J_1 & = \left. \left[I_t^{-1}(a_1,b_1) \int I_t^{-1}(a_2,b_2) \: \mathrm{d}t \right] \right|_{t=0}^{t=1} \\[10pt]
& = \frac{a_2}{a_2 + b_2}, \quad \text{(using facts 1,3,4,5, and } \Gamma(z+1) = z\Gamma(z)),
\end{align}
and a complicated-looking expression for
\begin{align}
J_2 & = \int_0^1 \left(\frac{\mathrm{d}}{\mathrm{d}t}I_t^{-1}(a_1,b_1) \int I_t^{-1}(a_2,b_2)\:\mathrm{d}t\right)\:\mathrm{d}t \\[10pt]
& = \frac{B(a_1,b_1)}{(a_2+1) B(a_2,b_2)} \int_0^1 \left(I_t^{-1}(a_1, b_1)\right)^{1-a_1} \left(1 - I_t^{-1}(a_1,b_1)\right)^{1-b_1} \left(I_t^{-1}(a_2,b_2)\right)^{a_2+1}\:_2 F_1\left(a_2+1,1-b_2;a_2+2;I_t^{-1}(a_2,b_2)\right)\mathrm{d}t, \quad\text{(using facts 1,2)}
\end{align} Can $J_2$ be further simplified? Or perhaps there is a more elegant way to compute $J$ than my naive attempt via integration-by-parts? Any help, suggestions or ideas are welcome.","['hypergeometric-function', 'integration', 'definite-integrals', 'special-functions', 'beta-function']"
1970586,Abelian group of order 6 has exactly one element of order 2,"I am trying to prove that an abelian group of order 6 has exactly one element of order 2. I know there is at least one by Cauchy's Theorem, so I am trying to show there are no more than one by contradiction. Suppose there are $a,b, a \neq b$ such that $a^2 = b^2 = e$. Then also $ab$ has order $2$, so we have two remaining elements (aside from $e, a, b, ab$) of which at least one of them, say $c$, has order $3$ by Cauchy. Then $ac$ has order $6$, but also $bc$ has order $6$ and there is only one element of order 6 (since $e$ has order 1, $a, b, ab$ have order 2, and $c$ has order 3) so $ac = bc$ and therefore $a = b$. This is a contradiction. Is this proof correct? Is there a ""better"" proof? One without Cauchy's Theorem?",['group-theory']
1970602,"Any homeomorphism from $[0,1)\to [0,1)$ has a fixed point.","Show that Any homeomorphism from $[0,1)\to [0,1)$ has a fixed point. My try : Suppose that  $f(x)\neq x$ for all $x$,then either $f(x)>x$ or $f(x)<x$ for all $x$ otherwise if $f(a)>a$ and  $f(b)<b$ for some  $a,b\in [0,1)$ then by IVP $f(p)=p;p\in [a,b]\subset [0,1)$ which is false. Hence take WLOG ; $f(x)>x$ for all $x$ ; Also if $f^{-1}(x)>x$ then by above we have $f(f^{-1}(x))>f^{-1}(x)>x\implies x>x $ false .Hence $f^{-1}(x)\le x$ for some $x$ . But I can't complete the proof from here.Please give some hints so that I can take it forward.","['general-topology', 'real-analysis']"
1970621,Relation between function integral and sum of function values.,"Let $f:\mathbb{R} \to \mathbb{R}$ be a continuous function with period $T$,where $T$ is an irrational number,and the integral of $f$ over one period is $0$. Can we conclude that $\sum_{k=0}^N f(k)$ is bounded?","['functions', 'ergodic-theory', 'calculus', 'analysis']"
1970630,Find a line which is tangent to the curve $y=x^4-4x^3$ at 2 points,How can I solve this? Should I set the two points as $a^4-4a^3$ and $b^4-4b^3$?,"['algebra-precalculus', 'tangent-line', 'polynomials', 'analytic-geometry']"
1970634,Evaluating $\frac1{n^2+1^2}+\frac2{n^2+2^2}+\dots+\frac n{n^2+n^2}$ using Riemann sum [duplicate],"This question already has answers here : limit $\lim_{n\to \infty }\sum_{k=1}^{n}\frac{k}{k^2+n^2}$ [duplicate] (3 answers) Closed 7 years ago . Not sure how to get started on this question. Do I have to form the summation? If yes, how do I go about doing it? Any help will be really appreciated!","['riemann-sum', 'sequences-and-series', 'calculus', 'limits']"
1970665,Join of $S^1$ with $S^1$ gives $S^3$.,"Problem. I want to prove that $S^1*S^1$ is homeomorphic to $S^3$, that is, the join of two copies of $S^1$ is homeomorphic to $S^3$. (Writing $I$ to denote the closed unit interval, the join of two spaces $X$ and $Y$ is defined as $(X\times Y\times I)/\sim$, where $\sim$ is an equivalence relation which identifies $(x, y_1 0)$ with $(x, y_2, 0)$ and $(x_1, y, 1)$ with $(x_2, y, 1)$ for all $x_1, x_2\in X$ and $y_1, y_2\in Y$.) I tired the following. Think of $S^1$ as $I/\partial I$, and write $\pi:I\to S^1$ to denote the natural projection map. Then we have a map $f:(I\times I)\times I\to (S^1\times S^1)\times I$ which sends $(x, y, t)$ to $(\pi(x), \pi(y), t)$. Let $q:(S^1\times S^1)\times I\to S^1*S^1$ be the natural map coming from the equivalence relation $\sim$. Thus we have a surjective continuous map $q\circ f:(I\times I)\times I\to S^1*S^1$. Write $q\circ f$ as $g$. Since the domain of $g$ is compact, we know that if $\simeq_g$ is the equivalence relation on $I^3$ induced by $g$, then $I^3/\simeq_g$ is homeomorphic to $S^1*S^1$. I was sure that $\simeq_g$ would turn out to be such that it identifies all points of $\partial I^3$ and no point in the ""interior"" of $I^3$ with any other point. So that we would have $I^3/\simeq_g = I^3/\partial I^3$, which is homeomorphic to $S^3$. But to my surprise this is not the case! For example, consider the points $p:=(1/2, 1/2, 0)$ and $q:=(1/2, 1/2, 1)$ in $I^3$. Then $g(p)\neq g(q)$. What is weirder is that $\simeq_g$ does make $I^3/\simeq_g$ homeomorphic to $S^3$ nevertheless, despite the fact that equivalence classes induced on $I^3$ by $\simeq_g$ are finer that the equivalence classes on $I^3$ induced by identifying all points in $\partial I^3$ to one point. Can anybody please provide a proof and if possible comment on the (apparent) weird phenomenon happening above (or point out a mistake somewhere). Thank you.","['general-topology', 'quotient-spaces']"
1970688,"On Bourbaki's ""Integration"" - Why/What/How to read it","I have a question concerning the Bourbaki 's book on integration . Whenever I find them referenced (in answers on this site as well), it looks like they aged more than volumes of the same series on other topics. Also, it looks like they were criticised from the outset (e.g. see Halmos' comment from page 11 of this chapter ). Thus, the questions: why? Is there a problem in the entire approach to the topic? What was problematic in it? How sensible is to read them right now, beyond historical purposes? What should somebody have in mind when reading them? How shoud somebody read them? Given the answer to question (1), what should be taken, and what should be dismissed? Thank you as always for any feedback. PS: Moreover, right now, are there serious problems with the terminology? Is it outdated?","['math-history', 'integration', 'measure-theory']"
1970698,Interesting rectangles,"Any rectangle representing a sheet of A series paper has an interesting property, i.e. when bisected, the two resulting rectangles are similar to the original one. Generalizing the A series paper concept, any rectangle having area $A=k$, length $a=\sqrt[4]{n}\:k$ and width $b=\frac{k}{\sqrt[4]{n}}$ for $k\in \mathbb{R}^+,\:n\in\mathbb{Z}^+\setminus \left \{ 1 \right \}$ is interesting. Case $n=2$ corresponds to bisecting the rectangle and getting two rectangles similar to the original one, $n=3$ trisecting it  and getting three rectangles similar to the original one, etc. Another rectangle everybody knows is the golden rectangle as it is used in the simplest definition of the golden ratio $\varphi%$. What other oblong rectangles have nice or interesting mathematical properties?","['rectangles', 'geometry']"
1970702,What are the properties of eigenvalues of permutation matrices?,"Up till now, the only things I was able to come up/prove are the following properties: $\prod\lambda_i = \pm 1$ $ 0 \leq \sum \lambda_i \leq n$, where $n$ is the size of the matrix eigenvalues of the permutation matrix lie on the unit circle I am curious whether there exist some other interesting properties.","['eigenvalues-eigenvectors', 'permutation-cycles', 'permutation-matrices', 'matrices', 'linear-algebra']"
1970721,Is the Risch algorithm useful for calculating antiderivatives by hand?,"In a German forum, a user asked how the ""Feynman""-trick works. The example was $$f(x)=xe^x$$ Another user mentioned that the Risch algorithm should be taught. Therefore, I wonder whether the Risch algorithm is useful for calculating antiderivates by hand. My questions: Would the Risch algorithm be useful to find antiderivatives of, for example, $xe^x$ by hand? Does the Risch algorithm always find an antiderivative, if it exists ? A user of Math Stack Exchange claimed that the fact that the Risch algorithm might not always terminate is not important in practice. Does that mean, that it fails only in ""pathological"" cases (assuming that it can fail)? I already asked a question about the Risch algorithm, but I am looking for some details to have an idea of the power and usefulness of the algorithm in cases where the antiderivative can easily be found by integration by parts, substitution or other methods. And I also would like to know more about the decidability-status of the Risch algorithm.","['symbolic-computation', 'integration', 'soft-question', 'calculus']"
1970722,Why compact subsets (of metric spaces) are closed,"There is a proof of the above statement that I can't fully get my head around. It goes something like this. Let $Y$ be a subset of a metric space $X$. $Y$ is closed iff $Y^c$ (complement of $Y$) is open (for if $x$ is a limit point of $Y$, every neighbourhood of $x$ contains a point of $Y$ different from $x$, so that $x$ is not an interior point of $Y^c$. Since $Y^c$ is open, ie. it contains all its interior points, if follows that $x\in Y$. It follows that $Y$ is closed. Now let $p\in X, p\notin Y$ and let $q\in Y$. Let $V_q$ and $W_q$ be $\epsilon$-neighbourhoods (ie. open balls around) of $p$ and $q$, respectively, of radius less than $\frac{1}{2}d(p,q)$ (remember we are in a metric space). Since $Y$ is compact, there are finitely many pointds $q_{1:n}$ in $Y$ such that $Y\subset W_{q_1}\cup W_{q_2}\cup\ldots\cup W_{q_n}=W$.
Let $V=V_{q_1}\cap V_{q_2}\cap\ldots\cap V_{q_n}$ (intersection). And here is where I am puzzled. Because if we say $V$ is nonempty then we could say $V$ is the neighbourhood of some new $p$ which does not intersect $W$. Hence $V\subset Y^c$, so that $p$ is an interior point of $Y^c$. Since $p$ was not fixed, it follows that $Y^c$ is open. But: how can we be sure that $V$ is nonempty? Consider $X=\mathbb{R}$ and let $Y$ be the closed interval $[1,6]$. Let's say $q_1=2,p_1=0,q_2=5,p_2=7$. Let $B(x, r)$ denote an open ball centred at $x$ with radius $r$. Then we could have $W_{q_1}=B(2,1)=(1,3)$ (open interval $(1,3)$), $V_{q_1}=B(0,1)=(-1,1)$, $W_{q_2}=B(5,1)=(4,6)$ and $V_{q_2}=B(7,1)=(6,8)$. Off course we will need further $W$s to cover $Y$, but $V_{q_1}\cap V_{q_2}$ is already empty -> frustration! :) What am I missing? Also, how would the proof fail if $Y=(1,6)$ (the open interval $(1,6)$)? I've been thinking about it for a few days so any hints would be highly appreciated.","['general-topology', 'real-analysis', 'metric-spaces', 'compactness']"
1970748,"Triangle $ABC$, such that $\measuredangle A=120^{\circ}$. Find $\measuredangle BFC$.","Let triangle $ABC$, such that $\measuredangle A=120^{\circ}$ and $AB\not=AC$. $AL -$  bisector, $AK -$ median. The point $O -$ center of the circle circumscribed around the triangle, $OL\cap AK= F$. Find $\measuredangle BFC$. I made a drawing. I have a hypothesis that $\measuredangle BFC=60^{\circ}$. But I can not prove it.","['triangles', 'geometry']"
1970762,$\mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset \mathcal{L}_{\mathbb{R}^2}$,"The Borel $\sigma$ -algebra of $\mathbb{R}^n$ , $\mathcal{B}_{\mathbb{R}^n}$ , is defined as the smallest $\sigma$ -algebra of $\mathbb{R}^n$ containing the open sets of $\mathbb{R}^n$ for its usual topology. The Lebesgue $\sigma$ -algebra of $\mathbb{R}^n$ , $\mathcal{L}_{\mathbb{R}^n}$ , is characterized as the set of all subsets $A$ of $\mathbb{R}^n$ that can be written as $A = B \cup N$ , where $B$ is a Borel set and $N$ is a null-set (with respect to the Borel-Lebesgue measure). It is the completion of $\mathcal{B}_{\mathbb{R}^n}$ with respect to the Borel-Lebesgue measure : $\mathcal{L}_{\mathbb{R}^n} = \widehat{\mathcal{B}_{\mathbb{R}^n}}$ . I know that $\mathcal{B}_{\mathbb{R}^2} = \mathcal{B}_{\mathbb{R}} \otimes \mathcal{B}_{\mathbb{R}}$ . I want to show the following (clearly) equivalent assertions : $\mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset
 \mathcal{L}_{\mathbb{R}^2}$ $\widehat{\mathcal{B}_{\mathbb{R}}} \otimes
 \widehat{\mathcal{B}_{\mathbb{R}}} \subset
 \widehat{\mathcal{B}_{\mathbb{R}^2}}$ $\widehat{\mathcal{B}_{\mathbb{R}}} \otimes
 \widehat{\mathcal{B}_{\mathbb{R}}} \subset
 \widehat{\mathcal{B}_{\mathbb{R}} \otimes
 \mathcal{B}_{\mathbb{R}}}$ . I think that what I need to show is that if $B_1$ , $B_2$ are Borel sets of $\mathbb{R}$ and $N_1$ , $N_2$ null sets of $\mathbb{R}$ , then $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ is a null-set of $\mathbb{R}^2$ . Thanks. Edit : @G. Sassatelli : Thank you for pointing out this already existing topic . Nevertheless, they don't explain there why $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ is a null-set of $\mathbb{R}^2$ . So here is my new question : Let $B_1$ , $B_2$ be Borel sets of $\mathbb{R}$ and $N_1$ , $N_2$ be
  null sets of $\mathbb{R}$ . Why is $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ a null-set of $\mathbb{R}^2$ ?","['lebesgue-measure', 'measure-theory']"
1970786,To find $p$ such that max/min of $(\sin p+\cos p)^{10}$ occurs,To find max/min of $(\sin p+\cos p)^{10}$. I have to find value of $p$ such that the expression is max/min. I tried to manipulate expression so as to get rid of at least $\sin$ or $\cos$. Then I can put what is left over equals to $1$ to get the maximum. But I'm unable to do that.,"['algebra-precalculus', 'functions']"
1970812,Proving the limit of a given cubic function from the epsilon-delta definition of a limit,"Would anyone know how to prove the limit of this cubic equation using the epsilon delta definition? $\lim_{x \rightarrow 2} x^3 +2x^2 -x -1 = 13 
$
I really don't know where to start other than inputting the values of $a$, $L$ and $f(x)$ for this example into the definition of a limit: $0 < |x - 2| < d $ implies $|(x^3 +2x^2 -x -1) - 13| < \epsilon$","['epsilon-delta', 'polynomials', 'calculus', 'limits']"
1970822,Which of following is/are true?,"In expansion $(x^2+1+\frac{1}{x^2})^n$ , n $\in \mathbb{N}$ 1.number of terms is $2n+1$ 2.coefficient of constant term is $2^{n-1}$ 3.coefficient of $x^{2n-2}$ is $n$ 4.coefficient of $x^2$ is $n$ I tried by taking lcm and writing as $\frac{(1+x^2+x^4)^n}{x^{2n}}$. How do i proceed? thanks","['algebra-precalculus', 'binomial-theorem']"
1970825,Find the determinant of $I + A$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question What is the determinant of an $n \times n$ matrix $B=A+I$, where $I$ is the $n\times n$ identity matrix and $A$ is the $n\times n$ matrix 
$$
A=\begin{pmatrix}
a_1 & a_2 & \dots & a_n \\
a_1 & a_2 & \dots & a_n \\
\vdots & \vdots & \ddots & \vdots \\
a_1 & a_2 & \dots & a_n \\
\end{pmatrix}
$$","['matrices', 'linear-algebra', 'determinant']"
1970866,Are line integrals of conservative vector fields be path independent even if the vector field is not continuous?,"Stewart - Calculus The last line doesn't have 'continuous' in it, but 'continuous' is mentioned earlier. What's happening? Is the hypothesis necessary?","['line-integrals', 'calculus', 'multivariable-calculus', 'continuity', 'integration']"
1970890,"$\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r)) d\lambda (r)$","Let $\mu$ be a Radon measure on $\mathbb{R}^n$, and $\alpha \in ]0,n[$. Show that : $\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu
 (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r))
 d\lambda (r)$, where $B(x,r)$ is the open ball of center $x$ and radius $r$ in $\mathbb{R}^n$ and $\lambda$ is the Lebesgue measure on $\mathbb{R}$. I thought about using polar coordinates but I can't work it out. Moreover, I can't see why the condition of Radon measure is necessary here. Thanks in advance.","['integration', 'lebesgue-integral', 'measure-theory']"
1970912,Tiling a cylindrical piece of paper,"Imagine a piece of paper. It has a square grid of 1x1 on it, so that every square has an area of 1 cm(squared). That piece of paper was folded into the shape of an (empty, hollow) cylinder whose length is 50 cm and whose base circumference is also 50 cm (look at the picture below). Can you cover the area of that cylinder with the shape on picture b, which is made up of 4 squares and is also of dimensions 1x1?","['recreational-mathematics', 'tiling', 'geometry']"
1970959,Rank + nullity theorem,"Looking to give an example of a $4×5$ matrix A with $dim(Null(A)) = 3$. My thinking here is that by the $rank+null$ theorem, $rank+null= number of columns$. So the numbers of columns is $5$ so $ 5 = rank + 3 $. I got 3 from $dim(Null(A)) = 3$. So the rank of $A$ would be $2$. So this would just be a $4x5$ matrix with 2 leading 1's. Just wondering if my logic was correct. Can I get the null of the matrix from the statement $dim(Null(A)) = 3$ like I did?","['matrix-rank', 'linear-algebra']"
1970964,How to integrate Newton's law of cooling?,"I have been given the differential equation $T'(t)=k(T(t)-A)$, where $T$=temperature, $t$=time, $A$=the constant temperature of the surroundings and $k$ is constant. How do I find $T(t)$ expressed with $T_o$ = temperature when $t=0$,  $A$ and $k$. It says to use the substitution with $u(t)=T(t)-A$. Thanks :)","['ordinary-differential-equations', 'calculus']"
1971018,"Is any type of geometry $not$ ""infinitesimally Euclidean""?","Question: Is there any ( absolute) geometry which is not ""infinitesimally Euclidean""? Context: All of the geometries listed on the Wikipedia page "" Foundations of Geometry "" (describing axiomatic formulations of geometry) seem to correspond to special cases of absolute geometry, and it seems like any absolute geometry is either hyperbolic, elliptic, or Euclidean (parabolic?) according to the version of the parallel postulate used, perhaps equivalently according to the type of curvature of the underlying geometric space. These all seem to have realizations or models as Riemannian manifolds of some sort. Any geometry of (smooth) manifolds seems to be infinitesimally Euclidean, even for those without a Riemannian metric, since each neighborhood is (diffeomorphic) homeomorphic to Euclidean space. Hyperbolic geometry seems to be the study of Riemannian manifolds with negative curvature, elliptic geometry the study of Riemannian manifolds with positive curvature, and Euclidean geometry the special case where there is no curvature. But obviously every neighborhood of a Riemannian manifold is diffeomorphic Euclidean space, thus even the Riemannian geometry of spaces like the torus, which is neither strictly elliptic nor hyperbolic, is infinitesimally Euclidean. Thus it seems like to me that all of the elementary geometric axioms determine every aspect of the geometric space (e.g. that it must be a Riemannian manifold) except the curvature -- thus changes in the parallel postulate seem to correspond to different values of the curvature of the space. Am I understanding this correctly? I had thought previously that the term geometry could be applied to spaces so abstract that they could not be embedded in any Euclidean space, and in particular were not infinitesimally Euclidean, but now I am not so sure. Any clarification would be appreciated. The question stems in part from my reading of Agricola and Friedrich's ""Elementary Geometry"" (also of the original German version), so perhaps if you have read some of that book as well you might understand better the source of my misunderstanding.","['terminology', 'soft-question', 'geometry']"
1971022,Showing a complex polynomial is linear,"I've been stuck on the following exercise: Show that if $p(z)$ is a complex polynomial such that $p(z) \in \mathbb R$ if and only if $z\in \mathbb R$ then $p$ is linear. Here is what I have so far: Because $0$ is real it follows that the roots of $p$ are real. From this it is immediate that the coefficients of $p$ are real. So let $p$ be a polynomial with real coefficients of degree $n$. We can write $p(z) = u(x,y) + i v(x,y)$. Then $v(x,y) = 0$ if and only if $y=0$. Since $p$ is real we have $\overline{p(z)} = p(\overline{z})$ hence $$ u(x,y) = u(x,-y)$$ and $$ -v(x,y) = v(x,-y)$$ Can I use any of these observations to make a proof? Please could
  someone show me how to prove this?",['complex-analysis']
1971031,Is work path independent?,"Stewart - Calculus It does not appear that work being change of kinetic energy depends on $C$ or that $F$ being conservative is assumed for the result in the red box. Hence, work is path independent? Or are there some assumptions made that are too advanced for the basic calculus reader?","['physics', 'calculus', 'multivariable-calculus', 'integration', 'linear-algebra']"
1971049,Minimum possible value of n?,"There are $100$ countries participating in an olympiad. Suppose $n$ is a
  positive integer such that each of the $100$ countries is willing to
  communicate in exactly $n$ languages. If each set of $20$ countries can
  communicate in at least one common language, and no language is common
  to all $100$ countries, what is the minimum possible value of $n$? I tried thinking of various cases where we can get minimum value, but I am not sure and they are very different. My opinion- let 99 countries have a common language, so all the groups of 20 countries including the left out country will have to speak different language,so that the rule follows. So the n= (99C19) +1",['combinatorics']
1971054,Difference between an $L^p$ space on a bounded set and a periodic $L^p$ space?,"I'm confused about the concept periodic $L^p$ space. Let $\mathbb{T}$ be the quotient space $\mathbb{R}/\mathbb{Z}$. Here are my questions: What is the Lebesgue measure on $\mathbb{T}$? How do people assign measures on a quotient space? What exactly is the difference between $L^p(\mathbb{T})$ and $L^p([0,1])$? What I think is that $L^p([0,1])$ is the restriction of $L^p(\mathbb{R})$ functions on $[0,1]$; while $L^p(\mathbb{T})$ is the space of periodic functions (with period $1$) $f$ on $\mathbb{R}$ such that $f1_{[0,1]}\in L^p([0,1])$. Could anyone come up with references for detailed explanation?","['reference-request', 'real-analysis', 'measure-theory']"
1971096,How do I find the particular solution for $ y''' + y'' + y' + y = \cos t + e^{-t}$?,I tried solving it as $A\cos t + B\sin t + Ce^{-t}$ but I got $0$ in the end after I differentiate and substitute into the equation.,['ordinary-differential-equations']
1971110,Studying math at Grade 8 [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question I'm currently studying in Grade 8 and I took a huge interest in math. I'm still learning algebra and I was currently wondering if I could start at least the most basic concepts of calculus. I have not taken trigonometry and I was just wondering. Is it possible or is it too early for me?
PS: This is my first question here! Thank you!","['algebra-precalculus', 'reference-request', 'soft-question', 'calculus']"
1971154,Which functions are continuous but nowhere Holder continuous for 0<a<1?,"Can somebody provide an example of a function that is continuous on [0,1] but nowhere Holder continuous with degree $\alpha$ ? Why is the function continuous but nowhere Holder continuous? By nowhere Holder continuous, I mean that $\frac{|f(x + t_n) - f(x)|}{|t_n|^\alpha} \rightarrow +\infty$ where $t_n$ is a sequence which $\rightarrow 0 $ as $n\rightarrow +\infty$ .","['real-analysis', 'examples-counterexamples', 'functions', 'continuity', 'holder-spaces']"
1971166,Show that a nonabelian group must have at least five distinct elements [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Show that a nonabelian group must have at least five distinct elements. I just learn abstract algebra by self study. I want help to solve this problem.
Just give me a hint.","['abelian-groups', 'abstract-algebra', 'group-theory']"
1971184,Second derivative definition and osculating circle,"The definition of first derivative is $$f'(x) = \lim_{y \to x} \frac{f(y) - f(x)}{y-x}.$$ Iterating, we have for the second derivative $$f''(x) = \lim_{y \to x} \frac{f'(y) - f'(x)}{y-x}.$$ Combining the two, we have $$f''(x) = \lim_{y \to x} \frac{1}{y-x} \left[\lim_{z \to y} \frac{f(z)-f(y)}{z-y} - \lim_{w \to x} \frac{f(w)-f(x)}{w-x}\right].$$ This would imply that we need to fix four points, $x,y,z$ and $w$ and then take the above limits where all of them tend to the point $x$. However, from the geometric interpretation, we know that the second derivative describes the curvature (of the osculating circle) at a point $x$. But, to specify a circle, we need only three , and not four point. Therefore, there should be a way of writing the expression for the second derivative which has only three, and not four values of the independent variable. How to get this expression?","['derivatives', 'curves']"
1971187,Is $f: \mathbb{C} \to \mathbb{C}$ with $f(z) = z^2$ surjective?,"So I know that, the map is surjective if $$\forall b \in C, \exists a \in C \text{ such that } f(a) = b.$$ The problem I'm encountering is that normally I would try to find the $a$ by doing this
$$b = a^2 \text{ so } a = \sqrt{b}.$$
Then I would say: $$f(x) = f(\sqrt{b}) = (\sqrt{b})^2 = b.$$ So $\forall b. \exists a \text{ such that } f(a) = b$.
But I was taught that I couldn't take the square root of an imaginary number. So I don't what to do...? *PS: English is not the language I'm taught in, so I may have used the wrong words like 'map' or I may have used the terms the wrong way. In advance my apologies if I couldn't make myself clear.",['elementary-set-theory']
1971193,What is the volume of the $3$-dimensional elliptope?,"My question Compute the following double integral analytically $$\int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y$$ Background The $3$ -dimensional elliptope is the spectrahedron defined as follows $$\mathcal E_3 := \Bigg\{ (x_{12}, x_{13}, x_{23}) \in \mathbb R^3 : \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} \succeq 0 \Bigg\}$$ Using Sylvester's criterion for positive semidefiniteness (i.e., all $2^3-1 = 7$ principal minors are nonnegative), we obtain $1 \geq 0$ (three times), the three quadratic inequalities $$1 - x_{12}^2 \geq 0 \qquad \qquad \qquad 1 - x_{13}^2 \geq 0 \qquad \qquad \qquad 1 - x_{23}^2 \geq 0$$ and the cubic inequality. $$\det \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} = 1 + 2 x_{12} x_{13} x_{23} - x_{12}^2 - x_{13}^2 - x_{23}^2 \geq 0$$ Thus, $\mathcal E_3$ is contained in the cube $[-1,1]^3$ . Borrowing the pretty figure in Eisenberg-Nagy & Laurent & Varvitsiotis, here is an illustration of $\mathcal E_3$ What is the volume of $\mathcal E_3$ ? Motivation Why is $\mathcal E_3$ interesting? Why bother? Because $\mathcal E_3$ gives us the set of $3 \times 3$ correlation matrices . My work For convenience, $$x := x_{12} \qquad\qquad\qquad y := x_{13} \qquad\qquad\qquad z := x_{23}$$ I started with sheer brute force. Using Haskell, I discretized the cube $[-1,1]^3$ and counted the number of points inside the elliptope. I got an estimate of the volume of $\approx 4.92$ . I then focused on the cubic surface of the elliptope $$\det \begin{bmatrix} 1 & x & y\\ x & 1 & z\\ y & z & 1\end{bmatrix} = 1 + 2 x y z - x^2 - y^2 - z^2 = 0$$ which I rewrote as follows $$z^2 - (2 x y) z + (x^2 + y^2 - 1) = 0$$ Using the quadratic formula, I obtained $$z = x y \pm \sqrt{x^2 y^2 - x^2 - y^2 + 1}$$ Integrating using Wolfram Alpha , $$\int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y = \cdots \color{gray}{\text{(magic happens)}} \cdots = \color{blue}{\frac{\pi^2}{2} \approx 4.9348}$$ I still would like to compute the double integral analytically. I converted to cylindrical coordinates, but did not get anywhere. Other people's work This is the same value Johnson & Nævdal obtained in the 1990s: Thus, the volume is $$\left(\frac{\pi}{4}\right)^2 2^3 = \frac{\pi^2}{2}$$ However, I do not understand their work. I do not know what Schur parameters are. Haskell code Here's the script: -- discretization step
delta = 2**(-9)


-- discretize the cube [-1,1] x [-1,1] x [-1,1]
grid1D = [-1,-1+delta..1]
grid3D = [ (x,y,z) | x <- grid1D, y <- grid1D, z <- grid1D ]


-- find points inside the 3D elliptope
points = filter (\(x,y,z)->1+2*x*y*z-x**2-y**2-z**2>=0) grid3D


-- find percentage of points inside the elliptope
p = (fromIntegral (length points)) / (1 + (2 / delta))**3 After loading the script: *Main> delta
1.953125e-3
*Main> p
0.6149861105903861
*Main> p*(2**3)
4.919888884723089 Hence, approximately $61\%$ of the grid's points are inside the elliptope, which gives us a volume of approximately $4.92$ . A new Buffon's needle A symmetric $3 \times 3$ matrix with $1$ 's on the main diagonal realizations of the random variable whose PDF is uniform over $[-1,1]$ on the entries off the main diagonal is positive semidefinite (and, thus, a correlation matrix) with probability $\left(\frac{\pi}{4}\right)^2$ . Estimating the probability, we estimate $\pi$ . Using the estimate given by the Haskell script: *Main> 4 * sqrt 0.6149861105903861
3.1368420058151125 References Cynthia Vinzant, What is a... Spectrahedron? , Notices of the AMS, Volume 61, Number 5, May 2014. Grigoriy Blekherman, Pablo A. Parrilo, Rekha R. Thomas, Semidefinite Optimization and Convex Algebraic Geometry , SIAM, March 2013. Marianna Eisenberg-Nagy, Monique Laurent, Antonios Varvitsiotis, Complexity of the positive semidefinite matrix completion problem with a rank constraint , arXiv:1203.6602. C. R. Johnson, G. Nævdal, The probability that a (partial) matrix is positive semidefinite , in Recent Progress in Operator Theory , International Workshop on Operator Theory and Applications, IWOTA 95, Regensburg, July 31–August 4, 1995.","['semialgebraic-geometry', 'spectrahedra', 'volume', 'linear-matrix-inequality', 'integration']"
1971211,Pseudo-inverse of a matrix that is neither fat nor tall?,"Given a matrix $A\in\mathbb R^{m\times n}$, let us define: $A$ is a fat matrix if $m\le n$ and $\text{null}(A^T)=\{0\}$ $A$ is a tall matrix is $m\ge n$ and $\text{range}(A)=\mathbb R^n$ Using the finite rank lemma, we can find that: When $A$ is a fat matrix, its (right) pseudo-inverse is $A^\dagger = A^T(AA^T)^{-1}$ When $A$ is a tall matrix, its (left) pseudo-inverse is $A^\ddagger = (A^TA)^{-1}A^T$ My question is what is the pseudo-inverse when $A$ is neither fat nor tall (in the sense of the above definitions), i.e. it is a matrix such that $\text{null}(A^T)\ne \{0\}$ (i.e. the null space is non-trivial) and $\text{range}(A)\ne\mathbb R^n$? An example of such a matrix is: $$
A = \begin{bmatrix}
1 & 1 & 0 \\
0 & 2 & 0 \\
0 & 0 & 0 \\
0 & 3 & 0
\end{bmatrix}
$$ which clearly does not map to full $\mathbb R^4$ and whose null space is $\text{span}\left\{\begin{bmatrix}0 \\ 0 \\ 1\end{bmatrix}\right\}$.","['matrices', 'pseudoinverse', 'linear-algebra']"
1971225,"Given an exact differential; $df=yz\,dx+xz\,dy+(xy+a)\,dz$: Why must we integrate each term independently to find the parent function $f\,$?","In other words; Why can't I integrate the whole equation in one go like this? $$\begin{align}f=\int df&=\int yz\,dx +\int xz\,dy+\int xy\,dz+\int a\,dz\\&=xyz+xyz+xyz+az+C\\&=3xyz + az +C\end{align}$$ This is strangely remarkably close to the correct answer, which is $$f=xyz+az+C$$ I know that the differential
$$df=yz\,dx+xz\,dy+(xy+a)\,dz\tag{a}$$ 
can be written as 
$$df=\frac{\partial f}{\partial x}\,dx+\frac{\partial f}{\partial y}\,dy+\frac{\partial f}{\partial z}\,dz\tag{b}$$ Matching equations $(\mathrm{a})$ and $(\mathrm{b})$ leads to $3$ more equations, namely:
$$\frac{\partial f}{\partial x}=yz\tag{1}$$
$$\frac{\partial f}{\partial y}=xz\tag{2}$$
$$\frac{\partial f}{\partial z}=xy+a\tag{3}$$ Now integrating $(1)$, $(2)$, and $(3)$ with respect to their partial derivatives $$f=xyz + P\quad\text{from} \quad(1)\tag{A}$$
$$f=xyz + Q\quad\text{from} \quad(2)\tag{B}$$
$$f=xyz + az+R\quad\text{from} \quad(3)\tag{C}$$
where $\mathrm{P}$, $\mathrm{Q}$ and $\mathrm{R}$ are constants of integration. Now ' somehow ' we decide that equation $(\mathrm{C})$ best describes the parent function $f$ and is therefore the function we desire:
$$f=xyz + az+C$$
with $R$ replacing $C$, since they are both constants. So apart from the obvious ""because it gives the correct answer"", my question is as follows: Why do we have to integrate each term separately (independently) instead of the method I used at the beginning of this question (integrating the whole equation in one go)? Also; What is the precise logic behind choosing $(\mathrm{C})$ to represent $f$ instead of $(\mathrm{A})$ or $(\mathrm{B})$? Many thanks.","['derivatives', 'intuition', 'partial-derivative', 'indefinite-integrals', 'integration']"
1971232,Is this sum on power free number and Euler constant true?,"Let $p_{n,r}$ be $r$-th smallest $n$-power free number. For example $p_{2,7}$ is the $7$-th square free number and $p_{5,7}$ is the $7$-th smallest $5$-th power free number. Let $q_{n,r}$ be the $r$-th number which contains (or is divisible by) a $n$-th power. For example $q_{2,7}$ is the $7$-th smallest number which contains a square and $q_{5,7}$ is the $7$-th smallest number which contains a fifth power. We define $\alpha_n$ for $n \ge 2$ as the ratio of the sum of the $n$-th power free number to the sum of the $n$-th power containing numbers i.e. $$
\alpha_n = \lim_{r \to \infty}\frac{p_{n,1}+p_{n,2}+\ldots + p_{n,r}}{q_{n,1}+q_{n,2}+\ldots + q_{n,r}}.
$$ Question : Is it true that $$
\sum_{n = 2}^{\infty} \frac{\alpha_n}{n} = 1 - \gamma
$$ where $\gamma$ is the Euler-Mascheroni constant? Motivation : I ran a program and the sum seem to converge to 0.422785 which is close to $1-\gamma$.","['real-analysis', 'analytic-number-theory', 'divisibility', 'number-theory', 'elementary-number-theory']"
1971297,Centralizer in Symmetric Group of 7 elements.,"I'm currently working on trying to find the centralizer of the element $a=(123)(4567)$ in $S_7$ and my guess is that it is the group generated by a. The second inclusion is clear, but I'm have trouble showing that the centralizer is contained in the group generates by a.  Here is my idea: Given $b$ in the centralizer, it must be that $b^{-1}ab=a$, and so if 
$b^{-1}ab=c_1c_2$, where $c_1$ is a three cycle and $c_2$ is a four cycle, then
$$
c_1=(b(1),b(2),b(3))=(123)=(231)=(312)
$$
and
$$
c_2=(b(4),b(5),b(6),b(7))=(4567)=(5674)=(6745)=(7456).
$$ I'm not sure what to do from here. Any suggestions would he appreciated! 
$$","['group-actions', 'abstract-algebra', 'group-theory', 'symmetric-groups']"
1971328,Can the determinant of a matrix can be made $0$?,An entry of an $n \times n$ matrix with nonzero determinant is defined as interesting if by changing this entry (and only this entry) the determinant of the matrix can be made $0$. Is it true that each entry of every matrix with nonzero determinant is interesting? Is it true that there is an interesting entry in each row of a matrix with nonzero determinant?,"['matrices', 'determinant']"
1971494,"Understanding the difference between a Flat, a locally flat and an Euclidean space","Suppose a Riemannian manifold is such that the metric tensor in a coordinate system is given by $$g_{ij}=\delta_{ij}$$
so that $$ds^2=g_{ij}dx^i dx^j=(dx^1)^2+(dx^2)^2+(dx^3)^2$$ (i) Is this space called (a) flat or locally flat , (b) Euclidean or locally Euclidean ? (ii) Can we think of a simple space which is locally flat but not locally Euclidean or vice-versa? (iii) What is the difference between a flat space and an Euclidean space ? (iv) What is a space called, if it has a metric $g_{ij}=C_i\delta_{ij}$ (where $C_i$ are some constants independent of the coordinates)? Not-too-technical answer will be helpful because my understanding of differential geometry and manifolds is limited.","['coordinate-systems', 'differential-geometry', 'curvature']"
1971506,Prove $f$ is surjective or not,"For $\mathbb{R} \to \mathbb{R}$, prove/disprove $f(x) = x^2 + 4x + 9$ is surjective. I say it is not surjective. Let $y = 0$ then the discriminant of $f(x)$ is $16 - 36 < 0$, thus $x \not \in \mathbb{R}$. Is this the correct way to go about it?",['elementary-set-theory']
1971523,Tricky inequality no avail to AM-GM,"Let $a,b,c$ be 3 distinct positive real numbers such that abc = 1. Prove that $$\frac{a^3}{\left(a-b\right)\left(a-c\right)}\ +\frac{b^3}{\left(b-c\right)\left(b-a\right)}\ +\ \frac{c^3}{\left(c-a\right)\left(c-b\right)}\ \geq 3$$ I tried AM-GM in many different ways, but it doesn't work since one of the terms on the LHS inevitably becomes negative. Any help is greatly appreciated.","['inequality', 'a.m.-g.m.-inequality', 'factoring', 'algebra-precalculus', 'fractions']"
1971562,"Union of connected subsets$ X$,$Y$ is connected if $\overline{X}\cap Y \neq \varnothing$",I'm trying to prove the following : Let A be a topological space an let $X$ and $Y$ be to connected subsets with $\overline{X}\cap Y  \neq \varnothing$ with $\overline{X}$ the closure of $X$ . Show that $X\cup Y$ is connected. I first tried to look at the case $X\cap Y  \neq \varnothing$ and prove it by contradiction. If  $X\cup Y$ is disconnected it can be written as $U\cup V$ with $U$ and $V$ open and disjoint. So we have $X\cup Y = U\cup V$ $(X\cup Y)\cap Y = (U\cup V)\cap Y$ $(X\cap Y)\cup(Y\cap Y) = (U\cup V)\cap Y$ $Y =Y\cap (U\cup V)$ so $Y \subset (U\cup V)$ and $Y$ is disconnected. Since $X$ is connected $\overline{X}$ is also connected and I thought the proof could be modified but I didn't see how.,['general-topology']
1971626,What is the state of Carmichael's totient function conjecture?,I have been searching for information about that conjecture and it seems for me that noone has made any significant improvement on it in the last 30 years. Is that true? Does it remain unproven to be true? Has there been any important discovery about the problem in the last years? Thank you.,"['conjectures', 'totient-function', 'carmichael-function', 'number-theory', 'elementary-number-theory']"
