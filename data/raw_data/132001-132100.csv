question_id,title,body,tags
2066774,Generating correlated arbitrary random variables,"Suppose we have 2 random variables $X$ and $Y$ with (marginal) CDFs $F$ and $G$. Given any $\rho\in[-1,1]$, is there a general approach to construct a joint distribution of $X$ and $Y$ such that their marginals are $F$ and $G$ and their correlation is $\rho$? My interest is in simulation. For example, if $X\sim \chi^2(n)$ and $Y\sim\chi^2(m)$ then $F\equiv\frac{X/n}{Y/m}$ has the $F$ distribution $F(n,m)$ only if $X$ and $Y$ are independent. I would like to simulate $F$ to see how it behaves when $X$ and $Y$ are correlated. But I can't think of how to simulate such correlated $X$ and $Y$ besides starting from a joint distribution.","['probability-theory', 'statistics']"
2066803,Formula for smallest distance between two parabolas,"I have been struggling with this problem I came across: Create a general formula for finding the closest points between two
  parabolas. Given that the parabolas have opposing concavity and are not interesecting. I want to answer this problem in the simplest way possible so I can plug in any a, b, and c and get out a value that will give me the points  that are closest together in pair of parabolas. I have tried different approaches but I end up having to solve for x when x has exponents up to the power of three and I haven't been able to solve them correctly or efficiently. My closest attempt is the following (sorry to be wordy): The two parabolas $$f_1(x)=ax^2+bx+c$$$$f_2(x)=gx^2+hx+j$$ have the same slope at the closest distance between them.
 So I realized I needed a function that returned an x value based on a given slope (because the derivative of these parabolas are ax + b.) The functions are$$x_1(m)=\frac{m-b}{2a}$$ $$x_2(m)=\frac{m-h}{2g}$$
If I know that those are my x's and I know that at some m, the closest distance exists, then I can try to create a formula for finding the m that gives the closest distance. To do that we plug the 'x' functions into the distance formula.
$$d(m)=\sqrt{[x_1(m)-x_2(m)]^2+[f_1(x_1(m))-f_2(x_2(m))]^2}$$ and because this is a type of optimization problem, we can remove the square root (square both sides) before finding the derivative. We need to find the roots of the derivative to find our relative extrema of d(m). (for readability x 1 (m) -> x 1 and f 2 (m) -> f 2 etc.)
$$d'(m)=2(x_1-x_2)(x_1'-x_2')+2\Big[f_1(x_1)-f_2(x_2)\Big]\Big[f_1'(x_1)x_1'-f_2'(x_2)x_2'\Big]$$
divide both sides by two (remember, optimization) and expand the functions
$$d'(m)=(\frac{m-b}{2a}-\frac{m-h}{2g})(\frac{1}{2a}-\frac{1}{2g})+\Big[a(\frac{m-b}{2a})^2+b(\frac{m-b}{2a})+c-g(\frac{m-h}{2g})^2-h(\frac{m-h}{2g})-j\Big]\Big[a(\frac{m-b}{2a})(\frac{1}{2a})+b(\frac{1}{2a})-g(\frac{m-h}{2g})(\frac{1}{2g})-h(\frac{1}{2g})\Big]$$
But now here I am stuck. I don't know how to solve for m but I can see where m's roots are on a graphing calculator. TL;DR used distance formula on two parabolas but ended with cubic functions that I don't know how to solve for. Help me find a way to complete this problem. P.S. there are other questions covering this topic but they do not discuss a general formula for this.","['derivatives', 'optimization', 'calculus', 'cubics', 'conic-sections']"
2066847,Is unblurring an image possible,"I have been wondering if un-blurring an image is possible or not. Indeed, images produced by certain blurring algorithms are obviously irreversible if they remove information. I am more interested in this simple algorithm: For each pixel, set its value as the average of its neighbors and itself in the original image. To analyze it in an easier way, I have come up with an equivalent question for one dimensional images: An image is a sequence of numbers. Its neighbors are simply the pixel on the left and right of itself. Any pixels that are outside of the sequence have a value of zero. Blur is a function $f$ where it takes a sequence of numbers, apply the rules described above, and return another sequence of numbers with the same length. By my intuition I believed that the process is not reversible, therefore I tried to prove that $f$ is not a one to one function, such that more than one different images can lead to the same image. Assume we have an image $S=\{a, b, c\}$, therefore
$$
f(S) = \Big \{\frac{0+a+b}{3}, \frac{a+b+c}{3}, \frac{b+c+0}{3}\Big \}
$$ To create a different image that will produce the same resulting image, we will have $S' = \{a + n, \_, \_\}$. The second pixel has to have a value of $b-n$, or else the average would not be the same, and so we have $S'=\{a + n, b - n, \_\}$. $c$ cannot change for the same reason, but the last pixel would not be correct because $\frac{(b-n)+c+0}{c} \ne \frac{b+c+0}{3}$. It seems there does not exist any image that can produce the same image when blurred by this algorithm. Questions: Does this prove that the algorithm is reversible for all sequences with length 3 in one dimension? Does this also prove the same for all length in one dimension and two dimension? You can play with the algorithm here in this fiddle I made .","['algorithms', 'functions']"
2066849,Integral of a function's derivative does not equal the original function?,"I am struggling with assessing the validity of this statement. $$\int ^{x}_{a}f'\left( t\right) dt \neq f\left( x\right) $$ I can understand that the left side yields a class of functions $F(x)$ whose derivative is $f(x)$, but doesn't that mean that the left side evaluates to $f(x) + C$ and that constant pairs with whatever constant exists in the original $f(x)$? For example, if $f(x)=2x+6$ then the antiderivative is $2x + C$ but $C$ here is just $6$, right? So doesn't the equality hold?","['integration', 'calculus']"
2066915,Riemann Hypothesis and Prime summation,"In the OEIS page for the decimal expansion of $\pi$ there's the following curious comment: $$\pi = 3\prod_{\substack{t = \Im(r)\\r = (1/2+it) \\\zeta(r) = 0}}\frac{9+4t^2}{1+4t^2}\iff\text{RH is true}$$ Here, $\Im(r)$ denotes the imaginary part.  So, the product is over all the imaginary parts of the non-trivial zeros of the Riemann Zeta function. Does anyone have further information about this statement? Motivation: I found a series with prime arguments that converge to $\pi/3$ and want to discover a connection between the primes and the roots of the Riemann zeta function.",['number-theory']
2066924,Complete Riemannian manifold with fast volume growth,"I am wondering if there exists a complete Riemannian manifold (noncompact) such that
$$\lim\limits_{r\rightarrow \infty}\frac{vol(B(x,r))}{e^{r^3}}=\infty$$ where the denominator denotes the volume of a geodesic ball around $x$. Does anyone know an example? Best wishes","['differential-geometry', 'riemannian-geometry', 'measure-theory']"
2066932,"Infinitely $more$ algebraic numbers $\gamma$ and $\delta$ for $_2F_1\left(a,b;\tfrac12;\gamma\right)=\delta$?","Given the Elliptic integral singular value $K(k_m)$ , Dedekind eta $\eta(\tau)$ , j-function $j(\tau)$ , and hypergeometric $_2F_1\left(a,b;c;z\right)$ with $\color{brown}{a+b=c=\tfrac12}$ . Conjecture: ""The proposed equalities below hold for real $N>1$ , though for any integer $N>1$ , then the hypergeometric function $_2F_1(z)$ and its argument $z$ are algebraic numbers ."" I. For $a=\tfrac14$ and $\tau=N\sqrt{-\color{blue}4}$ $$\begin{aligned}\,_2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{(1+\sqrt2)}{4\sqrt2}\frac{_2F_1\left(\tfrac12,\tfrac12;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}4)}\\[2mm]
\end{aligned}\tag1$$ $$w=\frac{16}{16+\Big(\tfrac{\eta(\tau/4)}{\eta(\tau)}\Big)^8}$$ Example: If $N=2$ so $\tau=2\sqrt{-4}$ , then, $$_2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,\tfrac{9\,(1-2\sqrt2)^2}{(1+\sqrt2)^4}\right)=\tfrac{3}{4\sqrt2}(1+\sqrt2)$$ II. For $a=\tfrac16$ and $\tau=N\sqrt{-\color{blue}3}$ $$\begin{aligned}\,_2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{1}{27^{1/4}}\frac{_2F_1\left(\tfrac13,\tfrac23;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}3)}\\[2mm]
\end{aligned}\tag2$$ $$w=\frac{27}{27+\Big(\tfrac{\eta(\tau/3)}{\eta(\tau)}\Big)^{12}}$$ Example: If $N=2$ so $\tau=2\sqrt{-3}$ , then, $$_2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,\tfrac{25}{27}\right)=\tfrac{3\sqrt3}{4}$$ III. For $a=\tfrac18$ and $\tau=N\sqrt{-\color{blue}2}$ $$\begin{aligned}\,_2F_1\left(\tfrac18,\tfrac38;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{\sqrt{1+\sqrt2}}{128^{1/4}}\frac{_2F_1\left(\tfrac14,\tfrac34;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}2)}\\[2mm]
\end{aligned}\tag3$$ $$w=\frac{64}{64+\Big(\tfrac{\eta(\tau/2)}{\eta(\tau)}\Big)^{24}}$$ Example: If $N=3$ so $\tau=3\sqrt{-2}$ , then, $$_2F_1\left(\tfrac18,\tfrac38;\tfrac12;\tfrac{2400}{2401}\right)=\tfrac{2\sqrt7}{3}$$ IV. For $a=\tfrac1{12}$ and $\tau=N\sqrt{-\color{blue}1}$ $$\begin{aligned}\,_2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{1}{12^{1/4}}\frac{_2F_1\left(\tfrac16,\tfrac56;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}1)}\\[2mm]
\end{aligned}\tag4$$ $$\frac{12^3}{4w(1-w)} =j(\tau)$$ Example: If $N=2$ so $\tau=2\sqrt{-1}$ , then, $$_2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\tfrac{1323}{1331}\right)=\tfrac{3\,\sqrt[4]{11}}{4}$$ This is a highly compactified version of the results by Zucker and Joyce in "" Special values of the hypergeometric series II, III "" but I used a common form for the argument $z = (1-2w)^2$ as well as similar eta quotients to better illustrate their affinity. However, I only derived this empirically. Q: How do we rigorously prove the four conjectures?","['conjectures', 'radicals', 'calculus', 'hypergeometric-function', 'modular-forms']"
2066942,Lüroth's theorem for complex trigonometric polynomials,Is it true that a subfield $K$ of $C_t(s)$ (the quotient field of the ring of trigonometric polynomials with complex coefficients) containing a non-constant trigonometric polynomial satisfies that $K=\mathbb C(r)$ for some trigonometric polynomial $r$? (This is Lüroth's theorem for complex trigonometric polynomials.),"['abstract-algebra', 'polynomials', 'field-theory']"
2066955,solve for $x$ in inverse trignometry,"$$
\operatorname{arccot} x + \operatorname{arccot} (n^2-x + 1) = \operatorname{arccot }(n - 1)
$$
In this we have to solve for value of $x$ . I thought to convert arccot into arctan  . Then add using the identity . But its getting too long . Is there any short method to solve it.","['trigonometry', 'inverse-function']"
2066966,How do I maximize entropy?,"In the book on probability I am reading, I am asked to prove that the entropy of $X$ is maximized when $X$ is uniformly distributed. At first I came up empty and decided to check online. Most proofs made use of the AM-GM inequality which the book did not cover, so I was wondering if I could come up with a proof that relied on only things in the book. I try using the fact that 
$$\begin{align} \ln x \le x-1 <x&\Rightarrow -x\ln x > -x^2 \\ &\Rightarrow -\sum_i p_i\ln p_i >- \sum_i p_i^2 \\ &\Rightarrow H(X) >-  \sum_i p_i^2 \end{align}$$
To maximize $H(x)$ we should maximize $F(\mathbf {p} )=-\sum_i p_i^2$ subject to the constraint $g(\mathbf {p} )=\sum_i p_i=1$. Using the method of Lagrange multipliers, we get that $p_i=p_j \quad \forall i\ne j$. I would like to know if this argument is correct or if there are easier ways to prove the result given that the book assumes knowledge of differential equations, multivariable calculus and linear algebra. I was also wondering if I could apply the method of Lagrange Multipliers to the entropy itself.","['entropy', 'probability', 'proof-verification']"
2066975,The space $\omega_1$ with its order topology,"J. Van Mill in here http://www.sciencedirect.com/science/article/pii/S0166864107000193 shows that the space $\omega_1$ with its order topology satisfies the following condition: for any neighbourhood assignment $\{O_{\alpha}: \alpha < \omega_1\}$ of the space $\omega_1$, there exists a discrete subset $A$ of $\omega_1$ such that $\bigcup_{\alpha \in A} O_{\alpha} = \omega_1$. The proof as follows: Take any neighbourhood assignment $\{O_{\alpha}: \alpha < \omega_1\}$ of the space $\omega_1$. For any non-isolated point $\alpha \in \omega_1$, there is $f(\alpha) < \alpha$ such that $(f(\alpha), \alpha] \subset O_{\alpha}$. By pressing down lemma, we can find an uncountable $A\subset \omega_1$ and $\beta <\omega_1$ such that $f(\alpha) = \beta$ for any $\alpha \in A$. Note: A neighbourhood assignment in a space $X$ is a family $\{O_x: x \in X\}$ such that $x \in O_x \in \tau(X)$ for any $x \in X$. I do not understand this proof. Why is  $\bigcup_{\alpha \in A} O_{\alpha} = \omega_1$? and why is $A$ discrete? Please help me to understand this proof.","['general-topology', 'set-theory']"
2066998,$\displaystyle\sum_{n=1}^\infty\frac{(-1)^{n+1}}{n(n+1)}=2\ln 2-1$,"I have evaluated this sum and found that it is equal to $2\log2-1$. However, my friend found $\log2-1$. When we expanded, we got both the answers are same. So I am confused which one is correct answer. Thank you.","['real-analysis', 'limits', 'calculus', 'summation', 'sequences-and-series']"
2067032,"Number of nondecreasing functions from $\{1,2,\dots,n\}$ to $\{1,2,\dots,n\}$ [duplicate]","This question already has answers here : Number of non-decreasing functions? (4 answers) Closed 7 years ago . How many functions $$f: \{1,2,\dots,n\} \to \{1,2,\dots,n\}$$ are there such that for every $i \leq j$ we have $f(i) \leq f(j)$? The only way I could think of was removing all the ""bad"" cases from $n^n$, but that wouldn't be very effective. What better way could I use?","['combinatorics', 'functions', 'discrete-mathematics']"
2067042,$\dfrac{2}{\pi} = \dfrac{\sqrt 2}{2} \cdot \dfrac{\sqrt {2+\sqrt 2}}{2} \cdot\dfrac{\sqrt {2+\sqrt {2+\sqrt 2}}}{2} \cdots $,"One can  show inductively that
$$
\cos \frac{\pi}{2^{n+1}}\ = \frac{\sqrt {2+\sqrt {2+\sqrt {2+\sqrt {\cdots+\sqrt {2 }}}}}}{2},
$$
with $n$ square roots in the right side of the equation. The second part of the question was to deduct the following from the first part: $$\frac{2}{\pi} = \frac{\sqrt 2}{2} \cdot  \frac{\sqrt {2+\sqrt 2}}{2} \cdot\frac{\sqrt {2+\sqrt {2+\sqrt 2}}}{2} \cdot \cdots $$ with the hint to use the following limit: $$\lim_{n\to \infty}\cos\Big(\frac{t}{2}\Big)\cos\Big(\frac{t}{2^2}\Big)\cdots\cos\Big(\frac{t}{2^n}\Big) = \frac{\sin t}{t}.$$ A hint or some general intuition will be appreciated.","['infinite-product', 'limits', 'trigonometric-series', 'calculus', 'sequences-and-series']"
2067044,Solving system of equations with sums of odd power,"suppose we have given positive real numbers $a_1,...,a_n>0$. Consider the following system of equations: $$\sum_{i=1}^{n} (x_{i})^{2k-1} = a_k,\quad  k= 1,.....,n$$ with $x_1,...,x_n>0$. This system of equations does not have always solutions (see e.g. the answer of Leo163 below). But suppose $a_1,...,a_n$ are choosen in such a way that there exist a solution. The question is : How many solutions can this system have? By solutions I mean any multi set $\{ x_1,…,x_n \}$ such that the above equations are satisfied. Are there conditions such that the solution becomes unique? I would really appreciate any help. Best wishes","['polynomials', 'abstract-algebra', 'algebraic-geometry', 'analysis']"
2067063,"If $P$ and $Q$ are invertible matrices $PQ=-QP$, then which claim about their traces is true?","If $P$, $Q$ are invertible and $PQ=-QP$, then what can we say about traces of $P$ and $Q$. I faced this question in an exam but according to me this question is wrong as $Q=-P^{-1}QP$, which implies $\det(Q)=0$ and it implies $Q$ is not invertible? But it is given invertible in hypothesis. Options were both traces $0$, both $1$, $Tr(Q)\neq Tr(P)$ or $Tr(Q)=-Tr(P)$","['matrices', 'trace', 'linear-algebra']"
2067068,Detail of a proof of the ergodic theorem for Markov chains.,"I want to understand the proof of this ergodic theorem written here (page 3): Let $\{X_n\}_{n=1}^{\infty}$ be a positive recurrent, irreducible Markov chain, with state space $I$. Let $f:I\rightarrow\mathbb{R}$ be a bounded function. Then $$\lim_n\frac{1}{n}\sum_{k=0}^{n-1}f(X_k)=\sum_{i\in I}f(i)\pi_i\;\;\text{ a.s.},$$
  where $\pi=(\pi_i)_{i\in I}$ is the invariant distribution. I copy part of the proof (with more details): Dividing both sides of the equality by a bound for $f$, we may assume that $|f|\leq1$. Let $J$ be a finite subset of $I$. First of all, notice that $$\frac{1}{n}\sum_{k=0}^{n-1}f(X_k)=\frac{1}{n}\sum_{k=0}^{n-1}\sum_{i\in I}f(i)1_{\{X_k=i\}}=\frac{1}{n}\sum_{i\in I}f(i)\sum_{k=0}^{n-1}1_{\{X_k=i\}}=\frac{1}{n}\sum_{i\in I}f(i)V_i(n),$$
where $V_i(n)$ is the number of visits to state $i$ before time $n$. Then \begin{align*}\left|\frac{1}{n}\sum_{k=0}^{n-1}f(X_k)-\sum_{i\in I}\pi_if(i)\right|= {} & \left|\sum_{i\in I}\left(\frac{V_i(n)}{n}-\pi_i\right)f(i)\right|\\ \leq{} & \sum_{i\in J}\left|\frac{V_i(n)}{n}-\pi_i\right|+\sum_{i\notin J}\left(\frac{V_i(n)}{n}+\pi_i\right) \\
\stackrel{(*)}{\leq} {} & 2\sum_{i\in J}\left|\frac{V_i(n)}{n}-\pi_i\right|+2\sum_{i\notin J}\pi_i.\end{align*} Where does inequality $(*)$ come from?","['markov-chains', 'probability-theory']"
2067123,Material Derivative's advective non linear term,"I have read this question and the accompanying answers - Linear Vs Non Linear Differential Equation as well as the useful comments and my question is related. I am in fluid dynamics and I deal with the material derivative on a daily basis and I recently read that the advective term Here is the relevant text from the above link ""Note that the advection of momentum $(V · \nabla)V$ is non-linear and this is the term
that leads to much of the interesting behaviour in fluid mechanics."" i.e $$ \mathbf u.\nabla A $$ where u is the flow velocity and A is any vector field is non linear and as a result the whole material derivative is non linear due to the presence of a single non linear term. What exactly is the reason for the non linearity in the advective term of the material derivative ? Is it because of the product of a tensor ( $ \nabla A$) and a vector ?","['derivatives', 'partial-derivative', 'ordinary-differential-equations', 'nonlinear-system']"
2067136,Eigenvectors and eigenvalues in iterative methods,"I've been studying many iterative methods, like Jacobi, fixed-point, Newton's and the conjugate gradient methods. Currently, I'm studying the CG method, but it's not the first time where the eigenvectors (and eigenvalues) of the usual matrix involved are important in determining how the iterative method behaves, like what's the convergence of the method. In particular, I was reading the book ""A first course in numerical methods"" (by Greif, Ascher) and at a certain point (pp. 186-7) there's: If the eigenvalues of A are located in only a few narrow clusters, then the CG method requires only a few iterations to converge. Convergence is slower, though, if the eigenvalues are widely spread. which makes me wonder why, why if the eigenvalues of $A$ are located in an only a few narrow clusters the CG converges fast? This is not the first time that I see similar observations where the eigenvalues and eigenvectors of the matrix involved in the iterative method somehow determine the behavior or performance of the iterative method. My questions, apart from the specific case above, are: What are the relations between the eigenvectors and eigenvalues of the matrices involved in an iterative method and the behaviour of the iterative method (if this can be generalized)? What are the general behaviors of iterative methods that we can predict given the eigenvectors or eigenvalues? If this can't be generalized, either I could ask specific questions, or you could like list a few examples where eigenvectors and eigenvalues influence different iterative methods. Of course, an exhaustive list would be nice for everyone. Note: I know what are eigenvectors and eigenvalues, even though when I think about them I can't really make sense of why they are useful. You could argue that they are useful like in the example above, but I can't see the relation very well and clearly.","['eigenvalues-eigenvectors', 'numerical-methods', 'linear-algebra']"
2067152,Let $g:\mathbb{R}\to\mathbb{R}$ be a measurable function such that $g(x+y) =g(x)+g(y).$ Then $g(x) = g(1)x$ . [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $g:\mathbb{R}\to\mathbb{R}$ be a measurable function such that 
  $$g(x+y) =g(x)+g(y).$$
  How to prove that $g(x) = cx$ for some $c\in \mathbb{R}?$ The main thing to do here relies upon the fact that such function should be continuous and therefore by natural argument the answer will follow. Using this Additivity + Measurability $\implies$ Continuity Therefore I found out that there is nothing missing in this question.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
2067157,How to find the projection of $x^2+y^2+z^2+2xyz=1$ on $S^2$?,"The primary problem is to find the singular points of $g$ when $g$ defines on $S^2$ that $g:S^2 \rightarrow R^3,(x,y,z)\rightarrow(yz-x,zx-y,xy-z)$. $Note:$The singular point in the problem is the point when the rank of $dg_{p}：T_p S^2 \rightarrow T_{g(p)}R^3$ is less than 2. I tried to find the when the 3 determinant of 2-order minor of the Jacobian of $(y\sqrt{1-x^2-y^2}-x,\sqrt{1-x^2-y^2}-y,xy-\sqrt{1-x^2-y^2})$ are all $0$. The equation is hard to solve.So I turned to find the point in $R^3 \setminus (0,0,0)$ whose rank is  less than 3. It is equivalent to find when the determinat of matrix
$$
 \left[
 \begin{matrix}
   -1 & z & y \\
   z & -1 & x \\
   y & x & -1
  \end{matrix}
  \right] 
$$
is $0$. And I get the equation $x^2+y^2+z^2+2xyz=1$
The next,as I think, is to find the projection of $x^2+y^2+z^2+2xyz=1$ on$S^2$ through the map $(x,y,z)\rightarrow(\dfrac{x}{\sqrt{x^2+y^2+z^2}},\dfrac{y}{\sqrt{x^2+y^2+z^2}} ,\dfrac{z}{\sqrt{x^2+y^2+z^2}})$. The intersection of $x^2+y^2+z^2+2xyz=1$ and  $x^2+y^2+z^2=1$ is obvious a solution.
$x^2+y^2=1,z=0;y^2+z^2=1,x=0;x^2+z^2=1,y=0$ But I have no idea how to find the other projections.What should I do next?","['manifolds', 'differential-geometry', 'vector-analysis']"
2067160,Find all matrices in $\{\pm1\}^{n \times n}$ such that the sums of its rows and columns are zero,"Find all matrices in $\{\pm1\}^{n \times n}$ such that the sums of its rows and columns are zero. The question was for $n = 4$, which was easy to do with counting. For any $n$ how would we do it?","['matrices', 'combinatorics']"
2067201,Need help understanding the relation between Galois theory and a general quintic formula impossibility.,"Recently I have been studying a fair amount of Galois Theory and think I understand a lot of the ideas and theorems (at least intuitively) and how the things kind of come together and how Galois would have had motivation to look at certain topics. In particular I just finished looking at the Galois Correspondence theorem which provides us with a way to ""transform"" groups into fields and use one to understand problems in another. More specifically we have a correspondence between subgroups of $\text{Gal}(E/F)$ and intermediate fields of the Galois extension $E/F$. I want to understand (at least at a basic/intuitive level (I am not interested in getting bogged down in proofs yet I just want to straighten out the concepts involve and how they intertwine)) how this means that there is not a general forumla (using addition, subtraction, multiplication and nth roots) for polynomials of degree $5$ (I understand this can be extended to higher degrees but I'm not interested in that yet either.) I understand the reason for this is that there are $5$th degree polynomials whose Galois group is the whole of $S_5$ which is not a solvable group (since $A_5$ is not solvable and $A_5$ is the only intermediate normal subgroup of $S_5$). And we have a polynomial is solvable if and only if its Galois group is a solvable group. Hence for this reason we cannot find a general formula for quintics. There are several parts I don't understand about this and would be very appreciative if someone could clear these issues up for me so I can get more of an idea as to what is going on (as said I am less interested in proofs and rigour at the moment and want to get a feel for what is going on). I will try and summarise my main queries below: 1) What exactly is the relationship between the Galois group of a polynomial (the set of permutations of roots that will still satisfy any given polynomial that it satisfied before) and the $\text{Gal}(E/F)$? The correspondence talks about subgroups of $\text{Gal}(E/F)$ and subfields of $E/F$ and I understand we want to use the correspondence to switch from looking at a problem in fields to looking at the corresponding problem in group theory. But the relationship doesn't talk about the Galois group of a polynomial (presumably it does and the two ideas are linked I just don't see how). 2) How exactly is the Galois correspondence used to show there isn't forumlas for quintics? I outlined the rough argument as I understand it but it is not clear at all to me when it is applied. 3) When we talk about quintics having no formula are we talking about quintics with rational coefficients, real coefficients, complex coefficients or all of them? 4) What exactly is meant by the definition of the Galois group of a polynomial?
(We can shift roots and some equations won't notice we've done anything) which equations are we talking about? I see $x^2-2$ can't tell if we switch $\sqrt2 \mapsto -\sqrt2$ for instance. 5) We want to show there is a polynomial whose Galois group is $S_5$. To me this means we want to find a polynomial with roots that we can move around as much as possible. I know there is a theorem that says there is no formula (i.e. solutions in radicals) if the Galois group is not solvable like $S_5$ but why is this the case what is so special about the fact we can move around the roots so much and nothing is effected (presumably this has something to do with the Galois correspondence)? I think that is all I can think of asking for now. I have tried my best to make it clear as to where my understanding is letting me down. It's like I have all these pieces of information that I understand separately but I'm missing something very very important to see the bigger picture and bring everything together. (I kind of understand most of the Galois theory I have learned but I don't know how to apply it to the quintic problem basically.) I would very much appreciate if someone could explain in as basic a way as possible exactly what I am missing to tie this all together. Thanks for reading I appreciate your time. I know this post is long but I wanted to lay out all my thoughts to try and make it as easy for people to help me as possible. If you want to just answer parts that is fine but if someone would be able to write something that tries to clarify it all for me then I am patient and happy to wait. I look forward to your replies :)","['galois-theory', 'group-theory']"
2067233,Is it possible to have three real numbers that have both their sum and product equal to $1$?,"I have to solve $ x+y+z=1$  and $xyz=1$ for a set of $(x, y, z)$. Are there any such real numbers? Edit : What if $x+y+z=xyz=r$, $r$ being an arbitrary real number. Will it still be possible to find real $x$, $y$, $z$?","['algebra-precalculus', 'symmetric-polynomials', 'systems-of-equations']"
2067235,GCD of binomial coefficients,"Can the following be proved or disproved? $$\gcd\left(\binom{n}{1} , \binom{n}{2} , \binom{n}{3},...........,\binom{n}{\lfloor \frac n2 \rfloor}\right)$$ Where $n \ge 4$ and is a positive integer Is always a prime number or 1. It would be very helpful if the way to prove or disprove it may make use of the properties of Pascal's triangle.","['gcd-and-lcm', 'combinatorics', 'binomial-coefficients', 'elementary-number-theory']"
2067249,Question about sum of measure,"This could be very easy, but i don't get it. I have to state conditions for which, given a measurable extended real function $f$ on $X$ and two positive measure $m_1$ , $m_2$ on the same sigma algebra on $X$ it happens: $$\int_X f \, d(m_1 + m_2) = \int_X f \, dm_1 + \int_X f \, dm_2$$ I thought it is true for every measure. Because one can prove the risult for simple measurable and non negative functions. After that one can take $f$ to be non negative and take, thanks to simple aproximation theorem, a monotone sequence $s_n$ of simple measurable functions such that $s_n \rightarrow f$ . Thus by monotone convergence theorem, and what above we have: $$\int_X f \, d(m_1 + m_2) = \lim_n \int_X s_n \, d(m_1 + m_2) =\lim_n \left( \int_X s_n \, dm_1 + \int_X s_n \, dm_2 \right)$$ but by monotone convergence theorem $$ \lim_n \int_X s_n\, dm_1 =  \int_X f \, dm_1$$ and $$\lim_n \int_X s_n \,dm_2 =  \int_X f \, dm_2.$$ Thus the above limit is equal to the sum of the two. Thus the claim??","['real-analysis', 'measure-theory']"
2067277,"Prove that $ I_1, I_2, I_3, I_4 $ are concyclic","Problem : $ ABCD $ is  a tangential quadrilateral and $ P $ is a point such that $ PA=PC, PB=PD . $
  Let $ I_1, I_2, I_3, I_4 $ be the incenter of $ \triangle PDA, \triangle PAB, \triangle PBC, \triangle PCD $, respectively $ . $ Prove that $ I_1, I_2, I_3, I_4 $ are concyclic An interesting and similar problem can be found here, with solution: http://forumgeom.fau.edu/FG2011volume11/FG201108.pdf .","['circles', 'plane-geometry', 'euclidean-geometry', 'triangles', 'geometry']"
2067345,"7 distinct trucks are sent to 3 different cities A,B,C.what is the number of possibilities?","If exactly 2 trucks were sent to city A ,and exactly 4 trucks for city B and exactly 1 truck for city C here is my thought process ,i looked at city C first and said there is 7 different possibilities ,then i looked at A and said to my self there is C(6,2) different possibilities ,and then only C(4,4) for B.
so the final count should be 7*C(6,2)*C(4,4) ,is this correct?
if not can you advise me on how to approach these kind of problems?;
i'm new to combinatorics.","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2067350,"If $\mu $ is mutually singular with $\nu$ and absolutely continuous with respect to $\nu$, show that $\mu=0$","Here is a problem I want to confirm my answer to. Let $\mu $ and $\nu$ be two non-negative measures on a $\sigma$ - algebra $M$ . If $\mu$ is mutually singular with $\nu$ and absolutely continuous with respect to $\nu$ , show that $\mu=0$ My proof: Since $\mu$ is mutually singular with $\nu$ , that implies the support of $\mu$ and the support of $\nu$ have an empty intersection. Now, if $\mu$ is not identically $0$ , there exists an $A \in M$ such that $\mu(A)>0.$ But then $\nu(A)>0$ as well since, if $\nu(A)=0$ , then $\mu(A)=0$ . But then $A$ is a set for which both measures are positive, i.e. $A$ is in both the support of $\mu$ and the support of $\nu$ . But that's a contradiction since support of $\mu$ and support of $\nu$ have empty intersection. Thanks!","['measure-theory', 'analysis', 'solution-verification']"
2067369,Are there series/non-trivial integrals that converge to $e\pi$?,"I've tried for hours but I can't really find series representations without explicitly involving either $e$ or $\pi$ within the series expression. Edit: I am asking this for $e$ times $\pi$, and not for $e$ or $\pi$ like some edits have suggested.","['definite-integrals', 'sequences-and-series']"
2067372,"Is there a two-dimensional random variable whose CDF is continuous, but whose marginal CDFs are discontinuous? [duplicate]","This question already has answers here : If X and Y are continuous random variables, then the random vector (X,Y) is a continuous random vector? (2 answers) Closed 7 years ago . Is there a two-dimensional random variable $(X,Y)$, whose CDF is continuous, but whose marginal CDFs are discontinuous? My question differs from this one in that a random variable that has a continuous CDF, which is the condition stipulated in my question, is not necessarily a continuous random variable, which is the condition stipulated in the other question. Thus, my question is more general than the other one.",['probability-theory']
2067452,Tensor Products and a Basis of $\Bbb R^2 ⊗ \Bbb R^2$,"Let ${e_1, e_2}$ be the standard basis of $\Bbb R^2$.
 Show that $e_1⊗e_2+e_2⊗e_1$ cannot be written in the form $u ⊗ v$ with $u,v \in \Bbb R^2$. I am just being introduced to tensor spaces and I know that $e_1⊗e_1,e_1⊗e_2,e_2⊗e_1,e_2⊗e_2$ is a basis of $\Bbb R^2 ⊗ \Bbb R^2$ but I am not sure how to show a contradiction. Any hints appreciated. Edit: I also know that 
 $e_1⊗e_2+e_2⊗e_1 = (e_1+e_2⊗e_1+e_2)  - e_1⊗e_1 - e_2⊗e_2$","['tensor-products', 'linear-algebra']"
2067475,Convergence of random variables and Law of large numbers,"Let $A_1,A_2,\cdots$ and $B_1,B_2,\cdots$ be two independent sequences of i.i.d random variables according to probability density function $p(x)$ , with $\mathbb{E}[A_1]=\mathbb{E}[B_1]<\infty$ and $Var[A_1]=Var[B_1]<\infty$ . For a fixed constant $c>0$ , find the constant $k>0$ such that $$\lim\limits_{n \to \infty}\mathbb{P}\left(\frac{1}{n}\sum\limits_{i=1}^{i=n}A_i\geq \left(1-\frac{c}{\sqrt{n}}\right)\left(1-\frac{k}{\sqrt{n}}\right)\frac{1}{n+k\sqrt{n}}\sum\limits_{i=1}^{i=n+k\sqrt{n}}B_i \right)=1             $$ My approach: $\frac{1}{n}\sum\limits_{i=1}^{i=n}A_i$ is a random variable and weak law of large numbers yields $$\frac{1}{n}\sum\limits_{i=1}^{i=n}A_i\xrightarrow{p}\mathbb{E}(A_i)\,\,\,\,\,\,\,\,\,\,\,(1)$$ Similarly, $$ \frac{1}{n+k\sqrt{n}}\sum\limits_{i=1}^{i=n+k\sqrt{n}}B_i \xrightarrow{p}\mathbb{E}(B_i)=\mathbb{E}(A_i)\,\,\,\,\,\,\,\,\,\,\,(2)$$ [I am not sure about this step:] Therefore, for all $k$ $$\left(1-\frac{c}{\sqrt{n}}\right)\left(1-\frac{k}{\sqrt{n}}\right)\frac{1}{n+k\sqrt{n}}\sum\limits_{i=1}^{i=n+k\sqrt{n}}B_i \xrightarrow{p}\mathbb{E}(B_i)=\mathbb{E}(A_i)\,\,\,\,\,\,\,\,\,\,\,(3)$$ Now, by (1) and (3) $$\left[\frac{1}{n}\sum\limits_{i=1}^{i=n}A_i-\left(1-\frac{c}{\sqrt{n}}\right)\left(1-\frac{k}{\sqrt{n}}\right)\frac{1}{n+k\sqrt{n}}\sum\limits_{i=1}^{i=n+k\sqrt{n}}B_i \right]\xrightarrow{p}0$$ Thus, for all $k$ $$\lim\limits_{n \to \infty}\mathbb{P}\left(\frac{1}{n}\sum\limits_{i=1}^{i=n}A_i\geq \left(1-\frac{c}{\sqrt{n}}\right)\left(1-\frac{k}{\sqrt{n}}\right)\frac{1}{n+k\sqrt{n}}\sum\limits_{i=1}^{i=n+k\sqrt{n}}B_i \right)=1             $$ Is my approach correct? Is there a simpler precise method to prove? In the problem statement, if we had a function $f(n,c,k)$ instead of $\left(1-\frac{c}{\sqrt{n}}\right)\left(1-\frac{k}{\sqrt{n}}\right)$ , such that $\lim\limits_{n\to\infty}f(n,c,k)=1$ , could we use the same approach?","['stochastic-processes', 'probability-theory', 'probability', 'convergence-divergence', 'stochastic-calculus']"
2067491,"Matrices commuting with diagonal matrix, 3 distinct diagonal entries.","Hopefully I have the right idea? Let $A\in\mathbb{C}^{4\times 4}$ be a diagonal matrix with exactly 3 distinct entries on its main diagonal. What is the dimension of the vector space over $\mathbb{C}$ of matrices $B\in\mathbb{C}^{4\times4}$ such that $AB=BA$? If $B\in\mathbb{C}^{4\times4}$ is a diagonal matrix with exactly 3 distinct entries on its main diagonal, is $B$ similar to a polynomial in $A$? Another way to formulate this is to let $T_A\colon\mathbb{C}^4\to\mathbb{C}^4$ via $T_A(B) = AB-BA,$ and we wish to find the dimension of the null space $N$ of $T_A.$ For example, let's say $$A =
\left[\begin{array}{cc|cc}
a&&&\\
&a&&\\
\hline
&&b&\\
&&&c
\end{array}\right].$$ Then we need $B$ to commute with each $2\times 2$ block. In the upper left block, we have a scalar multiple of the identity, so everything commutes and this has dimension $4$. For the lower right block, we need $B$ to be diagonal there (dimension $2$). So then $\dim N = 6.$ As for the second question, I feel like the answer is no, but I am struggling to come up with a counterexample.",['linear-algebra']
2067507,Does it make sense to talk about eigenvalues in a 1x1 matrix?,"I am an Economics student and I am trying to apply the determinacy conditions as described in Blanchard, Kahn (1980) to check for the existence of a unique solution in a differential equation.
These conditions state that I need to have the number of eigenvalues of a matrix inside the unit circle equal to the number of jumpy variables in the system. Putting aside the economic meaning of that, I have a case in which I am dealing with a unique differential equation so that I do not have a matrix but a scalar, i.e. \begin{gather}
\pi_t=\frac{1}{1+\phi}\pi_{t+1}+\epsilon_t
\end{gather} Thus I am wondering if the eigenvalue in this context could be identified with the unique element of the 1x1 matrix made of $\frac{1}{1+\phi}$.","['eigenvalues-eigenvectors', 'ordinary-differential-equations']"
2067540,An injective immersion that is not a topological embedding,"On page 86 of John Lee's Introduction to smooth manifolds there is an example of an injective immersion that is not a topological embedding: $\beta : (-\pi, \pi) \to \mathbb{R}^2$, defined by $\beta(t) = (\sin{2t}, \sin{t})$, or pictorially: It is explained that, although $\beta$ is an injective immersion, it is not a smooth embedding since the image is compact while the domain is not.
My understanding is that the image, while bounded in $\mathbb{R}^2$, is an open subset of the plane, whereas the statement claims that it is not. Would anyone please explain why the image is compact? Thank you.","['general-topology', 'smooth-manifolds']"
2067556,I don't know what to call this in English! Constant Value? Lyapunov function?,"first of all let me apologise. I am English but I'm studying in Germany and haven't been able to find a translation of what this is called. I have been given the dynamic system $$\dot{x}=1$$ $$\dot{y}=-y$$ and told to find an Erhaltungsgröße . This will be a little difficult to explain because I don't understand it properly (hence being here). My understanding is that I need to find a function $E(x,y)$ such that for a solution curve $\begin{pmatrix}x(t)\\y(t)\end{pmatrix}$ $E(x(t), y(t))=const$. We've been given the starting point that $E(x,y)=X(x)\cdot Y(y)$ I've attempted to solve this (and not come very far) by:
$$0=\frac{d}{dt}E(x(t), y(t))=\frac{\partial E}{\partial x}\dot{x}+ \frac{\partial E}{\partial y}\dot{y}$$
$$\frac{d}{dt}E(x,y)=X´(x)\dot{x}+ Y´(y)\dot{y}=X´(x)+Y´(y)(-1)=0$$ I only came to this idea because of a similar problem we were given with the starting point $E(r,v)=R(r)+V(v)$ but I'm unsure if I can apply it here. So, what is this called in English (so that I can maybe look up some info on it)? And how do I proceed? Edit: Perhaps a little more explanation may help. Anything which is conserved is an Erhaltungsgröße - such as energy. Edit II: I'm taking Differential Equations for Engineers so we aren't going too deeply into most of these problems. The wiki page for a Lyapunov function seems to be in the right direction but there is also a lot on there I don't recognise or understand.",['ordinary-differential-equations']
2067564,Mathieu functions calculation,"I am currently working in MATLAB (this is not relevant to the question, though), and MATLAB doesn't have built-in Mathieu functions (such as the Mathieu cosine and sine). In principle this is just fine, because I can generate them with a RK or predictor corrector method. However, this calculates all the points in the function up to a certain $x$, and that is not very efficient if I'm only interested in one specific $f(x_i)$, for a given $x_i$. Could you provide references with explicit algorithms to calculate the Mathieu sine and cosine functions? Any other comments or suggestions are of course also welcome. Edit : to clarify, I'm looking to generate the functions as defined here or here (where they are referred as basic solutions). I'm not looking for the periodic solutions, but the (normalized) odd and even fundamental solutions of the equation
$$
\ddot{x} + (a - 2q\cos 2 \tau)x = 0
$$
and also the characteristic exponent $\nu(a,q)$","['special-functions', 'reference-request', 'ordinary-differential-equations']"
2067647,Evaluate the integral $ \int_0^\infty r^2 e^{-r^2/2\sigma^2} dr$,"I'm trying to evaluate the integral $$ \int_0^\infty r^2 e^{-r^2/2\sigma^2} dr$$ Wolfram Alpha gives the answer $$ \frac{\sqrt{\frac{\pi}{2}}}{(\frac{1}{\sigma^2})^{3/2}} $$ However, when I evaluated the integral it's undefined. Let $u = r^2$ and $dv = e^{-r^2/2\sigma^2} dr$. Then $du = 2r \ dr$ and $v = - \frac{\sigma^2}{r} e^{-r^2/2\sigma^2}$. $$ \int_0^\infty r^2 e^{-r^2/2\sigma^2} dr = \int_0^\infty u \ dv = u v\Big|^\infty_0 - \int_0^\infty v \ du $$ $$= \Big{[}- \sigma^2 r e^{-r^2/2\sigma^2} \Big{]}^\infty_0 + \int_0^\infty 2 \sigma^2 e^{-r^2/2\sigma^2} dr $$ For the first term, $$ \lim_{r \to \infty} - \sigma^2 r e^{-r^2/2\sigma^2} = \lim_{r \to \infty} \frac{- \sigma^2 r }{e^{r^2/2\sigma^2}}$$ Since the numerator and denominator both tend to infinity, by l'Hospital's Rule, $$ \stackrel{H}{=} \lim_{r \to \infty} \frac{- \sigma^2 }{\frac{r}{\sigma^2}e^{r^2/2\sigma^2}} = 0$$ For the other limit of the first term, $$ \lim_{r \to 0} - \sigma^2 r e^{-r^2/2\sigma^2} = - \sigma^2 (0) (1) = 0 $$ So the first term is zero which means $$ \int_0^\infty r^2 e^{-r^2/2\sigma^2} dr = \int_0^\infty 2 \sigma^2 e^{-r^2/2\sigma^2} dr = 2 \sigma^2 \Big{[}\frac{-\sigma^2}{r}e^{-r^2/2\sigma^2}\Big{]}^\infty_0$$ $$ = 2 \sigma^2 \Big{[}\lim_{r \to \infty}\frac{-\sigma^2}{r e^{r^2/2\sigma^2}} + \lim_{r \to 0}\frac{\sigma^2}{r e^{r^2/2\sigma^2}} \Big{]} = 2 \sigma^2 [0 \pm \infty]. $$ Any help is appreciated.","['integration', 'definite-integrals', 'limits']"
2067655,Show a set E is measurable iff its characteristic function is measurable.,"I am trying to show that a set $E$ is measurable iff its characteristic function is measurable. I saw a proof online that someone wrote as a homework solution, however it doesn't make sense to me. They wrote: Suppose $E$ is a measurable set in a measure space $X$. If $\alpha \leq 0$, then $\{x:\chi_E(x) < \alpha\}=\varnothing$, a measurable set. If $\alpha >1$ then $\{x:\chi_E(x)<\alpha\}=X$, a measurable set. Finally, if $0<\alpha \leq 1$, then $\{x:\chi_E(x)<\alpha\}=X-E$, a measurable set. We conclude that $\chi_E$ is a measurable function. Conversely, suppose that $\chi_E$ is a measurable function. Then $E=X-\{x:\chi_E(x)<1/2\}$ is a measurable set. There is so much I do not understand about this proof. 1) I dont understand why when $0<\alpha \leq 1$ the set is equal to $X-E$, since the characteristic function will never take on values that are strictly greater than 0 and less than 1, will it? 2) I dont understand why in the first direction showing that $\{x:\chi_E(x)<\alpha\}$= a measurable set shows that $\chi_E$ is measurable. 3) I dont understand the converse direction. Can someone either help me understand or suggest a more understandable proof? The way I thought I would need to prove it was by using what we know about measurable sets (using that a set, $E$, is measurable if $\mu^*(A)=\mu^*(A\cap E)+\mu^*(A-E)$ for all $A\in X$).","['characteristic-functions', 'measure-theory']"
2067668,Counting $T$-invariant subspaces over finite field,"I have some explicit questions regarding the following problems. Additional critiques/suggestions are more than welcome. Let $F$ be a finite field with $p$ elements, let $V$ be a $3$-dimensional vector space over $F$ and let $T\colon V\to V$ be a linear operator that has minimal polynomial $x^2.$ How many $1$-dimensional $T$-invariant subspaces does $V$ have? Let's view $V$ as an $F[x]$-module with $x\alpha = T\alpha.$ Since $p(x) = x^2$ is the minimal polynomial and $\dim V = 3,$ we have that $f(x) = x^3$ is the characteristic polynomial. Thus $$V\cong \frac{F[x]}{(x)}\oplus\frac{F[x]}{(x^2)},$$
and there exits $\alpha_1,\alpha_2\in V$ such that $\{\alpha_1,\alpha_2,x\alpha_2\}$ is a basis for $V$. If we are looking for a $1$-dimensional subspace generated by $\beta = c_1\alpha_1+c_2\alpha_2+c_3x\alpha_2,$ then $x\beta = 0,$ which implies $c_2=0.$ Since $|F|=p,$ there are $p^2-1$ choices for $c_1,c_3$ since both can't be $0$. I think we also want to divide this by $p-1$ to give $p+1$ $1$-dimensional $T$-invariant subspaces. I know it has to do with the number of generators and that there are $p-1$ numbers relatively prime to $p$, but I'm not sure how to say that precisely. Also, how does this guarantee that the subspace is $T$-invariant? How many $1$-dimensional $T$-invariant subspaces $W$ of $V$ are direct summands of $V,$ i.e., are such that $V = W\oplus W',$ where $W'$ is a $T$-invariant subspace of $V$? These have to come from the first factor, so there are $p$ such subspaces since there is a unique $1$-dimensional subspace of $\frac{F[x]}{(x^2)},$ namely
$$\frac{xF[x]}{(x^2)}.$$ How many $2$-dimensional $T$-invariant subspaces does $V$ have? I have the same question about $T$-invariant-ness, but here we want $x\beta\ne0,$ but $x^2\beta=0$ (where $\beta = c_1\alpha_1+c_2\alpha_2+c_3x\alpha_2$). Then necessarily $c_2\ne0$. Then there are $p^2(p-1)$ vectors $\beta$ such that $x^2\beta=0$ (and $x\beta\ne0$). If the subspace is cyclic then for $\gamma\in\left<\beta\right>,$ $\gamma = d_1\beta+d_2x\beta$ and $\left<\gamma\right> = \left<\beta\right>$ if and only if $d_1\ne 0$. So there are $p(p-1)$ generators. Thus there are 
$$\frac{p^2(p-1)}{p(p-1)}=p$$
$2$-dimensional cyclic subspaces. But we could also come from 
$$\frac{F[x]}{(x)}\oplus\frac{xF[x]}{(x^2)}.$$
But how many would that be? How many $2$-dimensional $T$-invariant subspaces are direct summands of $V$? I believe it should just be $p$, the number of cyclic $2$-dimensional subspaces.",['linear-algebra']
2067673,Decomposition of an idempotent matrix,"Let $A$ be an $n\times n$ idempotent matrix i.e. $A^2=A$. Suppose that $A=A_1+A_2$ and $rank(A)=rank(A_1)+rank(A_2)$. Show that $A_1,A_2$ are both idempotent and $A_1A_2=A_2A_1=0$. Without confusion, I'd like to identify the matrices and their corresponding linear transformations. Then we have $\text{Im}A\subset\text{Im}A_1+\text{Im}A_2$. Hence we have $\dim\text{Im}A\leq\dim(\text{Im}A_1+\text{Im}A_2)\leq\dim\text{Im}A_1+\dim\text{Im}A_2$. However, the dimension of the image space is the same as the rank of the corresponding matrix. Hence the equality holds. In other words, we have $\dim\text{Im}A=\dim(\text{Im}A_1+\text{Im}A_2)=\dim\text{Im}A_1+\dim\text{Im}A_2$. In particular, $\text{Im}A=\text{Im}A_1+\text{Im}A_2$. So we deduce that $\text{Im}A=\text{Im}A_1\oplus\text{Im}A_2$. But I don't know what can I do next. Could anyone help me complete the proof?","['matrices', 'idempotents', 'linear-transformations']"
2067687,Lacunary series - Finding a limit,"Let, $f$ be the function defined on the open unit disk:
\begin{equation*}
f(x)=\sum_{n=0}^{+ \infty} x^{n^2}
\end{equation*} The aim of the exercise is to find the limit of $f(x)$ as $x$ approaches $-1$.
I tried considering the function $g$ defined by $g(x)=f(-x)$ and separating the positive and then negative terms... but I am not making any progress. Does anyone have an idea? I don't know if this is useful but I have proved that : \begin{equation*}
f(x) \sim \frac{\sqrt{\pi}}{2\sqrt{1-x}} \quad \text{as $x$ approaches $1$}
\end{equation*}","['real-analysis', 'lacunary-series', 'limits']"
2067715,Undo a convolution involving an inverse Laplace transform and definite integral,"While asking my previous question , I wanted to solve $(1)$ that is stated below this sentence: $$\mathcal{L}_\text{s}^{-1}\left[\frac{1}{1+\text{L}\cdot\text{C}_2\cdot\text{s}^2}\cdot\mathcal{L}_t\left[\left|\sin\left(\omega t+\theta\right)\right|\right]_{\left(\text{s}\right)}\right]_{\left(t\right)}\tag1$$ Using the answer of #msm , I was able to get (using convolution theorem and where $*$ is the convolution of the two functions): $$\left\{\frac{1}{\sqrt{\text{L}\cdot\text{C}_2}}\cdot\sin\left(\frac{1}{\sqrt{\text{L}\cdot\text{C}_2}}\cdot t\right)\right\}\space*\space\left|\sin\left(\omega t+\theta\right)\right|\tag2$$ Now, to undo the convolution, I have to solve the integral (posted in red under this sentence): $$\color{red}{\mathcal{I}=\frac{1}{\sqrt{\text{L}\cdot\text{C}_2}}\cdot\int_0^t\sin\left(\frac{t-\tau}{\sqrt{\text{L}\cdot\text{C}_2}}\right)\cdot\left|\sin\left(\omega\tau+\theta\right)\right|\space\text{d}\tau}\tag3$$ Where I was thinking of expanding function: $\left|\sin\left(\omega\tau+\theta\right)\right|$ into its $\cos$ Fourier series like this: $$\mathcal{I}=\frac{1}{\sqrt{\text{L}\cdot\text{C}_2}}\cdot\int_0^t\sin\left(\frac{t-\tau}{\sqrt{\text{L}\cdot\text{C}_2}}\right)\cdot\left\{\frac{2}{\pi}-\frac{4}{\pi}\sum_{\text{n}\ge1}\frac{\cos\left(2\text{n}\left(\omega\tau+\theta\right)\right)}{4\text{n}^2-1}\right\}\space\text{d}\tau$$","['laplace-transform', 'trigonometry', 'definite-integrals', 'absolute-value', 'sequences-and-series']"
2067736,Show that $m(A)=n(A)$ whenever $A\in\mathcal B$?,"I'm trying complete this problem from Bass' Real Analysis book: Let $\mathcal B$ be the Borel $\sigma$-algebra on $\Bbb{R}$, and suppose that $m,n$ are measures on $(\Bbb{R},\cal B)$ such that $m(a,b)=n(a,b)<\infty$ whenever $-\infty<a<b<\infty$. Show that $m(A)=n(A)$ for all $A\in\cal B$. I'm not really sure what the best way to proceed is. Obviously the result is true if $A$ is open, because then it's just a countable union of disjoint open intervals. However, I'm not sure how to classify what ""every"" element of $\cal B$ looks like; of course, it includes all closed intervals, and intervals of the form $[a,\infty)$, and so on... a proof by cases seems like it would make sense but I don't know how to be sure I've gotten every case. Just to be clear, I'd prefer an insightful hint rather than somebody giving me the full solution.","['real-analysis', 'measure-theory']"
2067742,Why is $\mathbb{Z}$ not a well-ordered set?,"Definition (Well Ordered Set) A set $B$ with an order relation $<$ is well-ordered if every nonempty subset of $B$ has a smallest element We know that $\mathbb{Z_+}$ is a well-ordered set. But it doesn't seem clear to me why $\mathbb{Z}$ is not a well-ordered set as to me it seems that for every nonempty subset we can always find a smallest element. I'll just illustrate with a few examples, (here $a, b, c \in \mathbb{Z_+}$ ) $\min [a, b] = a$ $\min (a, c) = b$ where $ a < b < c$ , for if there was no $b \in\mathbb{Z}$ between $a$ and $c$ , then $(a, c) = \emptyset$ $\min \{-a, a\} = -a$ $\min [-a, b] = -a$ $\min [-a, -b] = -a$ I just can't seem to think of an example where a nonempty subset of $\mathbb{Z_+}$ doesn't have a smallest element. This is obviously not true for $\mathbb{R}$ though as $(a, b) \subset \mathbb{R}$ doesn't have any smallest element, given the usual order relation on $\mathbb{R}$ So why is $\mathbb{Z}$ not a well-ordered set?","['relations', 'well-orders', 'elementary-set-theory']"
2067750,"If $g \circ f $ is injective, why must $f$ be injective but not $g$?","I'm trying to prove that if $g \circ f$ is injective, then f must also be injective. I have written a proof, which I believe has a bad step in it, and I would like feedback. Assume $g \circ f$ is injective. Now suppose $g\circ f(x) = g\circ f(y)$ for some $x, y$ in the domain of $f$ (call it $X$). Because the composition is injective, $x = y$. Now suppose $f$ were not injective. Then for some $x', y' \in X, ~f(x') = f(y')$ but $x' \neq y'$. Thus $g \circ f(x') = g \circ f(y')$ but  $y' \ne x'$ This implies $g \circ f$ is not injective, which is a contradiction. Therefore $f$ must be injective. $\Box $ This seems spurious to me, because it implies that $g$ itself needs to be injective (I feel but cannot state rigorously that this is implicit in the step that derives the contradiction) and I know that $g$ need not be injective itself (though again, I know this heuristically and cannot think of an example). Here is another question that is identical ( Composition of functions injective implies one of them is injective? ) but it seems like the same assumption is being made; which is that the fact that $~f(x') = f(y') \Rightarrow g \circ f(x') = g \circ f(y')$ and that this contradicts the injectivity of $g$ as $x' \ne y'$ Can anyone help clarify my thinking here?","['function-and-relation-composition', 'functions']"
2067785,Connected topological space such that the removal of any of its points disconnects it into exactly $3$ connected components?,$\mathbb R$ has the property of being a connected space which is divided into $2$ connected components by the removal of any of its points. I'm trying to generalize this property by constructing a connected (otherwise a $4$ elements set with the discrete topology will work) topological space such that removing any of its points leaves you with exactly $3$ connected components or by showing that such a space cannot exist. Are there spaces with this property? If so how well behaved can they be in terms of first and second countability and separation axioms?,"['general-topology', 'examples-counterexamples', 'connectedness']"
2067809,"What should I try to learn from Polya's ""How to Solve It""?","I have just started this book and arrived at the point where the students are trying to find the diagonal of a parallelipepid (Page 11). My question is, what exactly should I be trying to remember or from this book, and how should I go about doing it? Should I try to memorize the questions from the list, or specific applications of the questions/techniques and explicitly apply them? Should I try to solve every exercise that appears in the dialogue, or should I read it very casually? Polya's book is written in such a way (repeating these questions over and over for example) that it feels very easy to just read straight through it very fast. I'm just wondering where I should slow down to make sure I am getting the most out of the book.","['reference-request', 'problem-solving', 'calculus', 'algebra-precalculus', 'soft-question']"
2067827,Alternative ways to prove that $\int_0^{2\pi} \cos(\sin{x})e^{\cos{x}} dx=2\pi$ without complex analysis?,"$$\int_0^{2\pi} \cos(\sin{x})e^{\cos{x}} dx=2\pi$$ I derived this rather incredible result via Cauchy's theorem as I was working through some simple contour integrals. I was wondering if this integral can be solved without complex analysis, and if so how? I can't see any obvious substitutions that can be possible, nor any parametrisations that could simplify the integral through Feynman's method.",['integration']
2067849,Why does $\lim_{n\to\infty}(1+\frac{1}{n})^n = e$ instead of $1$? [duplicate],"This question already has answers here : Why $\lim\limits_{n\to \infty}\left(1+\frac{1}{n}\right)^n$ doesn't evaluate to 1? (6 answers) Closed 7 years ago . On Wikipedia, it says that $\lim_{n\to\infty}(1+\frac{1}{n})^n = e$ : It [e] is approximately equal to 2.71828,[1] and is the limit of (1 + 1/n)n as n approaches infinity, ... ( Source ) When I evaluate $(1+\frac{1}{n})^n$ for $n = 10^8$, I get approximately $2.718281798347$ which indeed is pretty close to $e$. But when I try to ""solve"" the limit using the laws of limits, I get $$\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n = \left(\lim_{n\to\infty}\left(1+\frac{1}{n}\right)\right)^n$$ because of the power law $$ = \left(\lim_{n\to\infty}(1)+\lim_{n\to\infty}\left(\frac{1}{n}\right)\right)^n$$ because of the addition law $$=\left(1+0\right)^n = 1$$ but that would mean that $e=1$, which is obviously not true. What am I missing / doing wrong? Thanks in advance.","['exponential-function', 'sequences-and-series', 'calculus', 'limits']"
2067866,Can the product of two nonsymmetric matrices be symmetric?,I was wondering if the product of two nonsymmetric matrices can ever be a symmetric matrix. Honestly I would not know how to tackle this problem.,"['matrices', 'symmetric-matrices', 'linear-algebra']"
2067883,Understanding when a vector is parallel vs. perpendicular?,"I am having some difficulty with this concept. I am studying a problem: Find an equation for the plane that passes through the point $P = (1, 2, 3)$
  and contains the line $L$ given by the parametric equation
  $x(t) = 1 − 3t,\, y(t) = 3$, and $z(t) = 6 + 2t$. The solution states that $v = \left< 3, 0, −2 \right>$ is parallel to $L$ and hence the plane. $Q = (1, 3, 6)$ is in the plane and
hence $PQ = \left< 0, 1, 3 \right>$ is parallel to the plane.
$n = v \times PQ = \left< −2, 9, −3 \right>$ is perpendicular to the plane.
Therefore, the plane is $−2x + 9y − 3z = −2 \cdot 1 + 9 \cdot 2 − 3 \cdot 3 = 7$. Could someone help me with this reasoning? I understand $v$ is parallel to $L$ because it is a scaled version of the normal to $L$, where the normal is $\left< -3, 0, 2 \right>$. I understand why $Q$ is in the plane. Why is $PQ$ parallel to the plane? Why do we know that $v \times PQ$ will be perpendicular to the plane? Is this because the cross product of two vectors parallel to a plane will be perpendicular to the plane? Thank you for any clarification or help in advance! Just trying to get a better hold on this concept.","['multivariable-calculus', 'plane-geometry', 'vectors', 'vector-analysis']"
2067911,Review of my T-shirt design [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question I'm a graphics guy and a wanna-be mathematician. Is the T-shirt design below okay? Or if there's a bone headed error, I'd appreciate a heads up. `","['summation', 'sequences-and-series', 'pi']"
2067929,Sard's Lemma in one dimmension,"Sard's lemma in one dimmension: Let $f: \mathbb{R} \to \mathbb{R}$ be of class $C^1$. Let $$C=\{x\in \mathbb{R} : f'(x)=0\}$$ be the set of critical points of $f$. Then $f(C)$ has measure $0$. I believe I have found a proof but I'm not sure if its correct. I would appreciate if someone could point out any flaws. The basic idea is this: If $a$ is a critical point of $f$, then if $x$ is close to $a$, $f'(x)$ is close to $f'(a)=0$, so $f(x)$ varies by a small amount if $x$ stays close to $a$. Our goal is to cover $\mathbb{R}$ by countably many intervals $I_k$ and make the $I_k$ small enough so that if $I_k$ contains a critical point $a$, then $f(I_k)$ will be an interval whose size is small. Then $f(C)$ will be contained in the union of countably many small intervals, which is a rough way of saying $f(C)$ has measure zero. Now more rigorously: Step I: Since a $\mathbb{R}$ is a countable union of intervals of the type $[n,n+1]$ for $n \in \mathbb{Z}$, and a countable union of measure-zero sets is measure-zero, it suffices to show that $f(C) \cap [n,n+1]$ is measure-zero for all $n \in \mathbb{Z}$. It suffices to take the case $n=0$. Step II: Let $S=\{x \in [0,1] : f'(x)=0\}$. Let $a \in S$. Let's fix $\delta>0$ . Since $f'$ is continuous the closed, bounded interval $[0,1]$ it is uniformly continuous on $[0,1]$ by Heine-Cantor, and thus there exists $\epsilon_0>0$ such that $\forall x,y \in [0,1]$, $|x-y|<\epsilon_0 \implies |f'(x)-f'(y)|<\delta$. Hence $\forall x \in [0,1]$, $|x-a|<\epsilon_0 \implies |f'(x)|<\delta$ By Cauchy's mean value theorem, if $\epsilon>0$ then for all $x\neq a$ such that $|x-a|<\epsilon$, there exists $c$ such that $|c-a|<\epsilon$ and $[f(x)-f(a)]/[x-a]=f'(c)$. Choosing $\epsilon<\epsilon_0$, we have $|f'(c)|<\delta$ and thus $|f(x)-f(a)|<\delta|x-a|<\delta\epsilon$. In summary, for all $x \in [0,1]$, for all $\epsilon<\epsilon_0$, we have: $|x-a|<\epsilon \implies |f(x)-f(a)|<\delta\epsilon$. (***) Step III: Now, lets choose $N \in \mathbb{N}$ such that $1/N<\epsilon_0$. Then since $[0,1]=\bigcup_{0 \le k<N}[\frac{k}{N},\frac{k+1}{N}]$, $f(S)=\bigcup_{0 \le k<N}f(S \cap[\frac{k}{N},\frac{k+1}{N}])$ If $S\cap[\frac{k}{N},\frac{k+1}{N}]=\emptyset$, then its image is empty. Otherwise $[\frac{k}{N},\frac{k+1}{N}]$ contains a critical point $a$ and since $\forall x\in [\frac{k}{N},\frac{k+1}{N}]$, $|x-a|\le 1/N$, applying (***) we get $\forall x \in [\frac{k}{N},\frac{k+1}{N}]$, $|f(x)-f(a)|<\delta/N$. Thus $f([\frac{k}{N},\frac{k+1}{N}])$ is a closed interval of length at most $2\delta/N$. Finally, since $f(S \cap[\frac{k}{N},\frac{k+1}{N}]) \subset f([\frac{k}{N},\frac{k+1}{N}])$ we have $f(S)$ is contained in the union of at most $N$ closed intervals each of whose length is at most $2\delta/N$.Thus the sum of their lengths is at most $2\delta$. In conclusion, for any $\delta>0$, we can cover $f(S)$ by finitely many closed intervals whose total length is at most $2\delta$. Thus $f(S)$ has measure zero, and we're done.","['general-topology', 'real-analysis', 'continuity']"
2067944,Variational formulation of a PDE with a Dirac's Delta?,"I have the following boundary value problem 
$$	\begin{cases}
		-u'' = \delta_{0}  \quad \text{in }(-1,1)  \subset \mathbb{R}   \\[2ex]
		u(-1) = 0, \quad u(1) = 0
	\end{cases}\tag{A}
$$
where $ \delta_{0} \in \mathscr{D}^{''}(-1,1) $ is the Dirac delta in $0$. The goal is to obtain a variational formulation of (A), to demonstrate that there is a unique solution $ u \in H_{0}^{1}(-1,1) $ and to derive the analitic expression of the solution $u$. I note that $ H_{0}^{1}(-1,1) \subset C([-1,1]) $, so that $ v \in H_{0}^{1} $. The following should hold: $ \langle \delta_{0}, v \rangle = v(0) $, and $ \lvert\langle \delta_{0}, v \rangle\rvert = \lvert v(0) \rvert \leq \displaystyle \max_{x \in [-1,1]} \lvert v(x) \rvert = \lVert v \rVert_{C([-1,1])} \leq M\lVert v \rVert_{H_{0}^{1}(-1,1)} $, where M is a constant. This should help, but here it is where I'm really stuck. Although I guess this is not a difficult problem, I'm getting stuck with some basic issues. This is a homework problem, and I have very few skills with Hilbert spaces and the application of functional analysis to PDEs. Any guide will be much appreciatted.","['functional-analysis', 'dirac-delta', 'hilbert-spaces', 'partial-differential-equations']"
2068005,Is $0.a_{1}a_{2}a_{3}\cdots a_{n}\cdots$ with $a_{n}\equiv \lfloor n\sin{n}\rfloor\pmod {10}$ a rational number? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $a_{i}\in\{0,1,2,3,4,5,6,7,8,9\}, (i=1,2,\cdots,n,\cdots)$, and such that
$$a_{n}\equiv \lfloor n\sin{n}\rfloor\pmod {10}$$ I conjecture :
$\qquad   0.a_{1}a_{2}a_{3}\cdots a_{n}\cdots$ is rational number?","['number-theory', 'decimal-expansion', 'rationality-testing']"
2068032,Determinant of Skew-Symmetric Matrices,"Let $M \subset M_n(\mathbb C)$ be the set of $n \times n$ skew-symmetric matrices. 1) If $n$ is odd their determinant is equal to $0$. 2) If $n$ is even their determinant is a polynomial (in several variables) which is NOT irreducible as an element of $\mathbb C[x_1, \dots,x_r]$. Partial Solution: 1) $A=-^TA \implies \det(A)=(-1)^n\det(^TA) \implies \det(A)=0$. 2) When n=2 $$ \left( \begin{array}{ccc}
0 & x_1  \\
-x_1 & 0  \end{array} \right) $$ we get $p(x_1)=x_1^2$. If $n=4$ $$ \left( \begin{array}{ccc}
0 & a & b & c\\
-a & 0 & d & e\\
-b & -d & 0 & f\\
-c & -e & -f & 0\end{array} \right) $$ we get $p(a,b,c,d,e,f)=(be)^2 - (af+cd)^2=(be+af+cd)(be-af-cd)$. I tried to use $2\times 2$ block matrices or to compute $\det$ along a raw with no success in the general case.","['matrices', 'linear-algebra', 'algebraic-geometry']"
2068044,"Combinatorial number theory, what is $\lim_{n \to \infty} {\ln f(n)\over \ln n}$?","Let $\textbf{Z}_n$ be the set $\{0, 1, \ldots, n - 1\}$ with addition mod $n$. Consider subsets $S_n$ of $\textbf{Z}_n$ such that $(S_n + k) \cap S_n$ is nonempty for every $k$ in $\textbf{Z}_n$. Let $f(n)$ denote the minimal number of elements in such a subset. What is$$\lim_{n \to \infty} {\ln f(n) \over \ln n} \text{ ?}$$","['number-theory', 'combinatorics', 'analytic-number-theory', 'combinatorial-number-theory']"
2068057,"Show that $\int_0^\infty e^{-x^2/2}\cos(ax)\,dx=\frac 1 2 \sqrt{2 \pi} e^{-a^2/2}$ for $a\in \mathbb{R}$.","In my course of complex analysis I am asked to solve the following exercise: Show that $\displaystyle \int_0^\infty e^{-x^2/2}\cos(ax) \, dx = \frac 1 2 \sqrt{2 \pi} e^{-a^2/2}$ for $a\in \mathbb{R} $. I have tried using the integration methods by means of integration contours but I make many errors and I can not get the result.","['complex-analysis', 'complex-integration']"
2068074,find limit when x is infinity [duplicate],"This question already has answers here : Prove that $\lim_{x\to \infty}\left(x-\ln\cosh x\right)=\ln 2$ (6 answers) Closed 7 years ago . How can we find the following limit.
$$\lim_{x\to\infty}(x-\ln\cosh x)$$
where $$\cosh t=\frac{e^t+e^{-t}}{2}.$$ I thought about it alot but didn't get any start","['calculus', 'limits']"
2068080,Are the domain and range of a function and its inverse always exactly swapped?,"The function
$
f(x)=\sqrt{x+4}
$
has domain $[-4,\infty)$ and range $[0,\infty)$. Its inverse function
$
f^{-1}(x)=x^2-4
$ by itself seems to have domain $\Bbb{R}$ and range $[-4,\infty)$. However, we learned in school that a function and its inverse always have swapped domain and ranges, so should I say its ""actual"" domain is $[0,\infty)$?","['algebra-precalculus', 'functions']"
2068098,Computing $\lim_{x\to0} \frac 8 {x^8} \left[ 1 - \cos\frac{x^2} 2 - \cos\frac{x^2}4 + \cos\frac{x^2}2\cos\frac{x^2}4 \right]$ without using L'Hospital,We have to find the following limit. $$\lim_{x\to0} \frac 8 {x^8} \left[ 1 - \cos\frac{x^2} 2 - \cos\frac{x^2}4 + \cos\frac{x^2}2\cos\frac{x^2}4 \right]$$ In this I thought to use Lhopital . But using that it will become too long . Is there ny short method .,"['limits-without-lhopital', 'calculus', 'limits']"
2068101,Good book for convergence of series,"Can anybody please suggest me a good book for convergence of series where I could find good questions on sum of series, sum of alternating series etc. I already have solved standard books like Tom apostol's calculus. Knopp's theory etc. Basically I'm looking for a book having more questions and less chit-chat. I want to solve as much problems as I can.","['reference-request', 'book-recommendation', 'sequences-and-series', 'convergence-divergence']"
2068102,Quadratic equation has integral roots,"Find all positive numbers $p$ for which the equation $x^2+px+3p = 0$ has integral roots. We have by the quadratic formula $$x = \dfrac{-p \pm \sqrt{p^2-12p}}{2}.$$ Thus, $p^2-12p = p(p-12)$ must be a perfect square. How do we continue?",['number-theory']
2068122,Natural number which can be expressed as sum of two perfect squares in two different ways?,Ramanujan's number is $1729$ which is the least natural number which can be expressed as the sum of two perfect cubes in two different ways. But can we find a number which can be expressed as the sum of two perfect squares in two different ways. One example I got is $50$ which is $49+1$ and $25+25$. But here second pair contains same numbers. Does any one have other examples ?,"['number-theory', 'sums-of-squares', 'elementary-number-theory']"
2068147,Solve $\left(\sqrt{\sqrt{x^2-5x+8}+\sqrt{x^2-5x+6}} \right)^x + \left(\sqrt{\sqrt{x^2-5x+8}-\sqrt{x^2-5x+6}} \right)^x = 2^{\frac{x+4}{4}} $,"Solve $$\left(\sqrt{\sqrt{x^2-5x+8}+\sqrt{x^2-5x+6}} \right)^x + \left(\sqrt{\sqrt{x^2-5x+8}-\sqrt{x^2-5x+6}} \right)^x = 2^{\frac{x+4}{4}} $$ Preface; I think there should be an algebraic method of solving this equation for $x$ since graphing these two graphs We get whole number solutions such as $x=0,2,3$ So I think there is someway of manipulating this equation into a disguised quadratic somehow! So my attempt is this: $$\left(\sqrt{\sqrt{x^2-5x+8}+\sqrt{x^2-5x+6}} \right)^x + \left(\sqrt{\sqrt{x^2-5x+8}-\sqrt{x^2-5x+6}} \right)^x = 2^{\frac{x+4}{4}} $$ Let $u=x^2-5x+8$ and $u-2=x^2-5x+6$ which means we can rewrite our equation as $$\left(\sqrt{\sqrt{u}+\sqrt{u-2}} \right)^x + \left(\sqrt{\sqrt{u}-\sqrt{u-2}} \right)^x = 2^{\frac{x+4}{4}} $$ Squaring both sides we get $$ \left( \sqrt{u} + \sqrt{u-2}\right)^x + 2\left(\sqrt{\sqrt{u}+\sqrt{u-2}} \right)^x\left(\sqrt{\sqrt{u}-\sqrt{u-2}} \right)^x+ \left( \sqrt{u} - \sqrt{u-2}\right)^x = 2^{\frac{x+4}{2}}$$ $$\left( \sqrt{u} + \sqrt{u-2}\right)^x +\left( \sqrt{u} - \sqrt{u-2}\right)^x+ 2(\sqrt{2})^x+  = 2^{\frac{x+4}{2}}$$ Now some little algebra $2^{\frac{x+4}{2}}-2(\sqrt{2})^x=2^{\frac{x}{2}} \cdot 2^2 - 2 \cdot 2^{\frac{x}{2}}=2^{\frac{x}{2}} \cdot 2=2^{\frac{x+2}{2}}$ $$ \left( \sqrt{u} + \sqrt{u-2}\right)^x +\left( \sqrt{u} - \sqrt{u-2}\right)^x = 2^{\frac{x+2}{2}} $$ Square both sides again $$ \left( \sqrt{u} + \sqrt{u-2}\right)^{2x} +\left( \sqrt{u} - \sqrt{u-2}\right)^{2x}+2\left( \sqrt{u} + \sqrt{u-2}\right)^x\left( \sqrt{u} - \sqrt{u-2}\right)^x   = 2^{x+2} $$ $$ \left( \sqrt{u} + \sqrt{u-2}\right)^{2x} +\left( \sqrt{u} - \sqrt{u-2}\right)^{2x}+2(2^x)    = 2^{x+2} $$ $$ \left( \sqrt{u} + \sqrt{u-2}\right)^{2x} +\left( \sqrt{u} - \sqrt{u-2}\right)^{2x}  = 2^{x+1} $$ Now I've hit a roadblock.. :(",['algebra-precalculus']
2068156,Let $f$ be a function with measurable domain $D$. show that$ f$ is mble iff the function $g$ is measurable,"I am working through some problems in Real Analysis (Royden) and I came across this one. Let $f$ be a function with  measurable domain $D$. Show that $f$ is measurable if and only if the function $g:\mathbb{R}\to \mathbb{R}$,  defined by $g(x)=f(x)$ for $x \in D$ and $g(x)=0, $ for $x\notin D$, is measurable. I realized that in one direction, if $g$ is measurable then
$$\{x \in D : f(x)>c\}=\{x \in \mathbb{R}:g(x)>c \}\cap D$$
since  $g(x)=f(x)$ for $x \in D$.  Because the sets $D$ and $\{x \in \mathbb{R}:g(x)>c \}$ are measurable , $f$ is measurable. On the other hand if $f$ is measurable, then 
$$\{x\in\mathbb{R}:g(x)>c\}=
\begin{cases}
\{x\in D:f(x)>c\}, &\mbox{ if }x\in D\\
D^c, &\mbox{ if }x\notin D \mbox{ and } c<0\\
\varnothing, &\mbox{ if }x\notin D \mbox{ and } c\geq0.
\end{cases}
$$
Because $\{x\in D:f(x)>c\}$, $D^c$, and $\varnothing$ are meas sets, it follows that $g$ is measurable. This illustration is almost clear to me except the part where we consider the cases where $c \ge $ 0 and $c<0$. I don't understand why we do that.
Can someone explain to me or give me a similar one.","['real-analysis', 'measure-theory']"
2068159,Clarification on the meaning of dx in the integral and differential setting,"I have some questions regarding differential forms, notation, and integrals. i would like to point out that I read the other post in this forums regarding this issue with no succes. I have always been working with expressions such as :
\begin{align}
\int fdx
\end{align}
Considering $dx$ as a placeholder and an indication on the variable for which f need to be integrated.
the riemannian integral says that taking the limite of a defined sum turns $\Delta x$ Into $dx$. This definition never satisfied me.
So I turned into lebesgue integral where $d\mu$ represent the measure that will provide a volume of the domain for which f need to be integrated. I was a little more happy with this ( despite the fact that lebesgue is a nice generalisation of riemann ) Then I was introduced to differential geometry and read that the infamous $dx$ represent the differential of the coordinate function x. Then I learned how to integrate differential form where the integral of a form is defined to be:
\begin{align}
\int \omega = \int f dx\wedge dy = \int f dx dy
\end{align}
( i wrote the case of 2 forms to display the transition between the integral of the form and the integral it translate to )
 At that point I was completly lost. My exposure to differential was that $df$ is a functional that takes a vector and return a scalar:
\begin{align}
df(X) = Xf
\end{align} Then I read that differential can be interpreted as infinitesimals which doesn't really make sense to me. I see the operation $Xf$ as the directional derivative of the function f in the X direction. $df$ if mainly for me a change of perspective where instead of varying the function $f$ we vary the vector $X$ for the directial derivative. I also studied n-forms which made the whole buisness more confusing as my introduction to n-forms was that it an element of the antisymmetric tensor product space. So basically an n-form is for me a (0-n) tensor that is antisymmetric. Finally I have been exposed to interpreting $dx$ as the differential of the coordinate function on a manifold. Which is a form that happen to be a basis member of the cotangent space. So here are my questions : 1) How should we interpret $dx$ in the riemannian integral. As a placeholder ? A differential ? Something else ? 2) If it is ok to treat it as a differential, why do we do this ? What the differential is supposed to represent in the framework of integration since for me it is just a change of perspective on the directional derivative or an element of the tensor product space. 3) are they any relation between the measure used in lebesgue integration and differential forms ? 4) My main problem here is to reconcile all of the things I learned about integration and differential forms. I want to be able to glance at $dx$ in any situation without being afraid of the meaning of it. Thank you for any pointers or answers.","['smooth-manifolds', 'differential-forms', 'integration', 'lebesgue-integral', 'differential-geometry']"
2068160,Determining the number of ways a number can be written as sum of three squares,"I was going through Erich Friedman's ""What's Special About This Number?"" and there some numbers are classified based on the number of ways we can write them as sum of squares. I want to prove the following claim by Friedman: 129 is the smallest number that can be written as the sum of 3 squares
in 4 ways. Indeed, as given in Wikipedia , $$11^2+2^2+2^2 = 10^2+5^2+2^2 = 8^2+8^2+1^2 = 8^2+7^2+4^2 = 129$$ So what remains to prove is that this is the smallest such number. Is it possible to write a proof for this fact using some insights
along with brute force/cases? How can we solve this problem using only brute-force? Also, since I know the proof of Legendre's three-square theorem . I am also curious to know: How can we determine the number of ways we can write a non-negative
integer which satisfies Legendre's three-square theorem as sum of
three squares? Edit1: Related discussions on MathOverflow: Is there a simple way to compute the number of ways to write a positive integer as the sum of three squares? : Note that this is not answer of my question since $r_k(n)$ counts the number of representations of $n$ by $k$ squares, allowing zeros and distinguishing signs and order. Efficient computation of integer representation as sum of three squares Edit2: Related discussions on ComputerScience.SE Listing integers as the sum of three squares $m=x^2+y^2+z^2$ Edit3: Related discussions on Mathematics.SE When is a rational number a sum of three squares? Why can't this number be written as a sum of three squares of rationals? Sum of one, two, and three squares","['sums-of-squares', 'number-theory', 'computational-mathematics', 'recreational-mathematics', 'elementary-number-theory']"
2068179,How to calculate the determinant of a $4 \times 4$ matrix with multiple variables?,What is the determinant: $$ \begin{vmatrix}1& a & a^2 & a^4 \\ 1 & b & b^2 & b^4 \\ 1 & c & c^2 & c^4 \\1 & d & d^2 &d^4 \end{vmatrix} $$ Someone gave me the following hint Replace $d$ by a variable $x$; make use of the fact that the sum of the roots of a fourth-degree polynomial is equal to the coefficient of $x^3$ but I didn't get that.,"['matrices', 'linear-algebra', 'determinant']"
2068204,"Why is $\#\{s_\alpha,s_\alpha^{-1}hs_\alpha\in H\} = \frac{|C_G(h)|}{|C_{N_G(H)}(h)|}$?","In one literature, I encountered the following problem. Suppose $G$ is a group and $H$ is its subgroup. $N_G(H)$ is the normalizer of $H$ in $G$. A number $c(h)$ is defined for every $h$ in $H$ this way: we first decompose $G$ using coset of $N_G(H)$: $G=\bigcup_{\alpha}s_\alpha N_G(H)$, $c(h)$ is defined to be $c(h)=\#\{s_\alpha,s_\alpha^{-1}hs_\alpha\in H\}$, where $\#$ means number of elements in a set. Then, it is claimed that $$c(h)=\frac{|G|}{\#[h]_G}/\frac{|N_{G}(H)|}{\#[h]_{N_G(H)}}=\frac{|C_G(h)|}{|C_{N_G(H)}(h)|},$$ where $C_G(h)$ ($C_{N_G(H)}(h)$) is centralizer of $h$ in $G$ ($N_G(H)$) and $[h]_G$ ($[h]_{N_G(H)}$) is conjugate class in $G$ ($N_G(H)$) containing $h$. I cannot prove that these two numbers are equal and cannot find a counter example. Can anyone help me on this?",['group-theory']
2068217,Do the series representations of the trigonometric functions depend on the definition of radian?,"Suppose I were to define the notion of angle using the unit circle. By elementary geometry, I realise I could use the unit circle's area, which is an intrinsic part of the circle, as my ""new"" measure of angle. Thus, ""a whole turn"" would correspond to $\pi$ (the area of my unit circle), half a turn would be $\frac{\pi}{2}$, and so on. Here comes the problem: according to my angle definition, $\sin(x+\pi)=\sin(x)$. But the infinite series of $\sin$, where $\sin(x) = x - \frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!} +\ ...$, doesn't agree with my angle definition. Does this mean that the infinite series of the trigonometric functions were defined on the basis of measuring angles using arclengths of the unit circle?",['trigonometry']
2068232,A question about differentiation,"$g(x)=\sin(1/x)  ,  g(0)=0$ Define $G(x)=\int _{0}^{x}g\left( t\right) dt$ Show $G'(0)=g(0)$ I use the definition $$G'(0) = \lim _{h\rightarrow 0}\dfrac {G\left( h\right) -G\left( 0\right) } {h}$$ $$=\lim _{h\rightarrow 0}\dfrac {\int _{0}^{h}g\left( t\right) dt} {h}$$ $$=\lim _{h\rightarrow 0}\dfrac {\int _{0}^{h}\sin(1/t) dt} {h}$$ I have no idea about next step Can you give me some hint Thank you!!!","['derivatives', 'calculus']"
2068266,If $K[X]/I \cong K[X]/J$ with $I \subset J$ then $I=J$? [duplicate],"This question already has an answer here : If $A/I \cong A/J$ as rings and $I\subseteq J,$ then $I=J.$ [duplicate] (1 answer) Closed 7 years ago . Let $K$ be a field and $I,J$ are ideals of $K[X].$ Then if $K[X]/I \cong K[X]/J$     with $I \subset J$ then can one say that $I=J$ ?","['abstract-algebra', 'ideals']"
2068303,Range of function $y=x^2 + \frac{4}{x^2+9}$,"Please don't give the solution, I already got the answer by a different method. I want to know why the method in the picture is wrong? Why cannot we simple add inequalities like that to get the interval of range and then find the minimum value from that range? The correct answer to this question is : 4/9 ( minimum value)","['calculus', 'functions']"
2068325,Prove that $\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum\limits_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n)$,"Show that $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n)$$ (where $\eta(n)$ is the Dirichlet eta function, and A is the Glaisher-Kinkelin constant). I try: $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)-\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We use this series $$\ln{{\pi\over 2}}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)$$ to simplify to $$-\ln{\left({A^6\over 2^{1\over6}\sqrt{\pi}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We have $$\ln{\left[\prod_{k=1}^{\infty}\left({k\over k+1}\right)^{(-1)^{k+1}}\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over n}$$ We can't use this to apply on the above series. I just wonder, is there an infinite product for $$\ln{\left[F(k)\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over 1+n}$$ Can anyone please give a hand here? Thank you.","['infinite-product', 'sequences-and-series', 'calculus', 'closed-form']"
2068329,A.P. terms in a Quadratic equation.,"The terms $a,b,c$ of quadratic equation $ax^{2}+bx+c=0$ are in A.P. and positive. Let this equation have integral root $\alpha,\ \beta$. Then find the value of $\alpha+ \beta + \alpha \cdot \beta$ ? please point where I'm wrong: Let common difference be $d$ $\implies \alpha+ \beta + \alpha \cdot \beta=\dfrac{c-b}{a}=\dfrac{d}{a} \implies a|d \ \ \ \ \longrightarrow  \ \ \ \ \              \because (b=a+d$, $c=a+2d)$ Also
, $ax^{2}+(a+d)x+(a+2d)=0$. $\implies$ $\alpha,\ \beta=\dfrac{-(a+d) \pm \sqrt{(a+d)^{2}-4\cdot a \cdot (a+2d)}}{2a}$. For this to be integer $\sqrt{(a+d)^{2}-4\cdot a \cdot (a+2d)}$ must be perfect square. $\implies$ ${(a+d)^{2}-4\cdot a \cdot (a+2d)}=p^{2}$ for some $p$. $\implies -3a^{2}+d^{2}-6ad=p^{2}$ $\implies -3a^{2}+a^{2}q^{2}-6a^{2}q=p^{2}$ $\because$ $a|d \implies aq=d$ for some $q$. $\implies a^{2}(-3+q^{2}-6q)=p^{2}$ $\implies -3+q^{2}-6q\ $  has to be perfect square. By trial $q=7$ But I need to get this without trial, please help.","['algebra-precalculus', 'arithmetic-progressions', 'quadratics']"
2068350,Probability of making it across a path of $n$ tiles through random walk,"The problem Imagine someone moving across a path laid out on a 2D grid: The white tiles are the path; the surrounding red tiles are, say, deadly lava. They repeatedly move randomly north , east , south , or west , with equal probability, and have to make it from the Start tile to the End tile without stepping onto the lava. What is the probability $p(n)$ that they succeed on an $n$-square-long path ($n=5$ is shown above)? What I’ve tried Number the tiles $1, \dots, n$, so that we’re walking from $1$ to $n$. Call $a_k$ the probability we succeed when starting at the $k$-th tile. Clearly, $a_n = 1$, and we’re interested in the value of $a_1$. From the $k$-the tile, there’s a 25% chance we move back to tile $k-1$, a 25% chance we move forward to tile $k+1$, and a 50% chance we step north or south onto a red tile and lose. So $a_k = \frac 14 \left( a_{k-1} + a_{k+1} \right)$, where $a_0 = 0$. Putting the equations for $a_1, \dots, a_{n}$ in a matrix system gets us: \begin{equation}
\newcommand{\mof}{-1/4}
\begin{bmatrix}
1 & \mof & 0 & \dots & 0 & 0 & 0 \\
\mof & 1 & \mof & \dots & 0 & 0 & 0 \\
0 & \mof & 1 & \dots & 0 & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & \mof & 0 \\
0 & 0 & 0 & \dots & \mof & 1 & \mof \\
0 & 0 & 0 & \dots & 0 & \color{red}0 & 1 \\
\end{bmatrix}
\begin{bmatrix}
a_1 \\ a_2 \\ a_3 \\ \vdots \\ a_{n-2} \\ a_{n-1} \\ a_n
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 0 \\ 1
\end{bmatrix}
\tag{1}
\end{equation} I wrote some Mathematica code to solve this system for a given $n$ and give the value of $a_1$: p[n_] :=
  LinearSolve[
    Table[If[x == y, 1,
            If[y == n, If[x == n,1,0],
              If[Abs[x - y] == 1, -1/4, 0]]],
          {y, 1, n}, {x, 1, n}],
    Table[If[x == n, 1, 0], {x, 1, n}]
  ][[1]] The first few values $p(1), p(2), \dots$ are
$$
\frac11, \frac1{4}, \frac1{15}, \frac1{56}, \frac1{209}, \frac1{780}, \dots,
$$
the inverses of A001353 in the OEIS, which suggests a closed form: $$p(n) = \frac{2 \sqrt{3}}{\left( 2 + \sqrt{3} \right)^n - \left( 2 - \sqrt{3} \right)^n}$$ But I’m not sure how to get there. I doubt there’s a nice way to solve a system like $(1)$ by hand. Maybe a combinatoric approach yields this formula without taking a detour through solving a system.","['systems-of-equations', 'random-walk', 'probability', 'combinatorics', 'linear-algebra']"
2068455,Solve $2\cdot \sin x \cdot \sin (50°+2x)=\sin (50°)$,"I am trying to find a solution for the problem: $$2\cdot\sin x \cdot \sin (50°+2x)=\sin (50°), \quad x\in \left[0,\frac{\pi}{2}\right]$$ Approach: I can check, by inspection, that $x=50°$ is a solution. I have tried open $\sin(50º+2x)$ but it didn't work. I also tried sum product relation but I got nothing interesting. Any hint? P.S: I'm trying to solve using standard approach because the problem is in a high school level. That means I'm not using calculus.",['trigonometry']
2068462,Question related to monotonicity of a function,"Question: Let $S$ be the non-empty set containing all ' $a$ ' for which $f(x)=\frac{4a-7}{3}x^3+(a-3)x^2+x+5$ is monotonic for all $x\in \mathbb R$ . Find $S$ . Answer: $a \in [2,8]$ My try: As $S$ contains all $a$ , $\implies$ all values of $a$ will constitute $S$ . As the given function is monotonous, $\implies$ it will be either increasing or decreasing. $\therefore f'(x)$ will be either $\ge$ or $\le$ to $0$ . If we take $f'(x)\ge0$ , then on simplifying, we get $a\ge \frac{7x^2+6x-1}{4x^2+2x}$ . On differentiating $\frac{7x^2+6x-1}{4x^2+2x}$ and putting it equal to $0$ , I got $x=1,-1/5$ . This gives the value of $\frac{7x^2+6x-1}{4x^2+2x}$ to be $2,8$ respectively. I don't know how to go any further.","['derivatives', 'calculus', 'functions']"
2068499,Applications of the CLT for the Sample Mean,"Related to Confusion of central limit theory , and the fact that I just finished my first course in (Master's-level) graduate-level probability, which relates to this material. The Central Limit Theorem states that if you have an iid sample $X_1, \dots, X_n$ with mean $\mu$ and variance $\sigma^2<\infty$, denoting $\bar{X}_n = \dfrac{1}{n}\sum_{i=1}^{n}X_i$, we have $$\sqrt{n}(\bar{X}_n - \mu) \overset{d}{\to}\mathcal{N}(0, \sigma^2)$$
as $n \to \infty$. By Slutsky's theorem, since $\sigma = \sqrt{\sigma^2}$ is constant (let's assume in addition $\sigma \neq 0$), obviously $\sigma \overset{p}{\to}\sigma$, hence 
$$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}\overset{d}{\to}\dfrac{1}{\sigma}\cdot\mathcal{N}(0, \sigma^2) = \mathcal{N}(0, 1)$$
as $n \to \infty$. This justifies (to me) what is commonly what is done in intro stats classes: basically, if $n \geq 30$, if you want to, say, find 
$$\mathbb{P}(a \leq \bar{X}_n \leq b)$$
where $a$ and $b$ are usually finite, the idea is that when you standardize it as follows:
$$\mathbb{P}(a \leq \bar{X}_n \leq b)\approx\mathbb{P}\left(\dfrac{a-\mu}{\sigma/\sqrt{n}} \leq \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \leq \dfrac{b-\mu}{\sigma/\sqrt{n}}\right)$$
you can approximate $$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$$ to be a $\mathcal{N}(0, 1)$ random variable if $n$ is ""large enough;"" the standard usually being $30$. Now the question I have: this implies, then, that we can't necessarily assume
$$\bar{X}_n\overset{d}{\to}\mathcal{N}\left(\mu, \dfrac{\sigma^2}{n}\right)$$
as $n \to \infty$. Is it correct that this isn't true? For one thing, this makes no sense, as $n$ is still showing up in the normal distribution (in the variance) as $n \to \infty$. Obviously, Slutsky's theorem will not work (as far as I can tell). But this seems to be contradicted by a select few websites: https://onlinecourses.science.psu.edu/stat800/node/36 http://onlinestatbook.com/2/sampling_distributions/samp_dist_mean.html What am I missing? Edit : The reason why I believe Slutsky's Theorem will not work is as follows: denote $Y_n = \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ and let $F_{Z}$ denote the CDF of $Z \sim \mathcal{N}(0, 1)$. Then for all $y \in \mathbb{R}$ for which $F_{Y_n}$ is continuous (notice, particularly, that $y$ is a constant),
$$\lim_{n \to \infty}F_{Y_n}(y) = F_{Z}(y)$$
but
$$F_{\bar{X}_n}(x) = \mathbb{P}(\bar{X}_n \leq x) = \mathbb{P}\left(\dfrac{\sigma Y_n}{\sqrt{n}}+\mu \leq x\right) = \mathbb{P}\left(Y_n\leq\dfrac{x-\mu}{\sigma/\sqrt{n}}\right) = F_{Y_n}\left(\dfrac{x-\mu}{\sigma/\sqrt{n}}\right)\text{.}$$
Unfortunately, the argument $\dfrac{x-\mu}{\sigma/\sqrt{n}}$ is dependent on $n$, so Slutsky's Theorem won't help.","['probability-theory', 'probability', 'statistics', 'central-limit-theorem']"
2068518,Integration by substitution gone wrong,"I've noticed that using integration by substitution blindly could lead to some strange results.  For example: with $u = x^2$, we might naively follow the usual procedure to find
$$
\int_{-1}^1 x^4\,dx = \int_{-1}^{1} x^3 \,x\,dx = \int_{u(-1)}^{u(1)} u^{3/2}\,du = \int_1^1 u^{3/2}\,du
 =0 
$$
The incorrect step here is writing $x = u^{1/2}$, since we would have $x = -u^{-1/2}$ over $[-1,0)$.  If we split the original integral into one over $[-1,0]$ and another over $[0,1]$, we of course get the correct answer.  However, it seems impossible to make this particular substitution in this particular problem.  Certainly, there is no function $f$ such that $\int_{u(-1)}^{u(1)}f(u)\,du$ produces the correct result.  Interestingly, this does produce the correct result if the integrand is an odd power of $x$. In a more advanced course , one might account for this by saying that substitution will only work correctly if the substitution map is injective (one to one) over the domain of interest.  However, having been a student and teacher of integral calculus, I've never seen this addressed (in the context of intro calculus) by a teacher or textbook.  That leads me to the following questions: Why doesn't this come up more often?  Is there a conspiracy to avoid problems where this situation arises, or is this a problem that only comes up in ""pathological cases""? Why, from a pedagogical standpoint, is this not addressed? Is it a coincidence that in my toy example, we get the correct answer when the integrand is $x^n$ with $n$ odd? EDIT: So apparently, some teachers/texts do choose to address the issue, which I guess is not all that surprising.  Still, I would be interested in hearing an argument that ""skipping it is not such a big deal"". Then again, perhaps that's a better question for the math-ed SE.","['substitution', 'integration', 'calculus']"
2068535,"If $p$ is a prime number,show that $2(p-3)!+1$ is a multiple of $p$.","I have got a question which is as follows: If $p$ is a prime number, show that $2(p-3)!+1$ is a multiple of $p$. I know that this question can be solved using Wilson theorem which is the only thing I apply in such situations, but I don't know how can I use it here. Please help.","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2068538,Differential Operator Issue,"Let us consider the differential operator $H:= x \frac{d}{dx}$ and let us define
\begin{equation}
\hat{\mathcal{O}_n}= \frac{1}{n!}(H+n)(H+n-1)\cdots(H+2)(H+1).
\end{equation} I proved - by induction - that 
\begin{equation}
\hat{\mathcal{O}_n}\left ( \frac{\log x}{x} \right )=\frac{1}{nx}
\end{equation} I notice that something similar happens with the following:
\begin{gather*}
\frac{\log(x)}{x^2}; \\
\frac{\log(x)}{x^3}.
\end{gather*}
In particular:
\begin{equation}
\hat{\mathcal{O}_n}\left ( \frac{\log x}{x^2} \right )=-\frac{1}{n(n-1)x^2}
\end{equation}
for $n \ge 2$, and
\begin{equation}
\hat{\mathcal{O}_n}\left ( \frac{\log x}{x^3} \right )=\frac{2}{n(n-1)(n-2)x^3}
\end{equation} So I think that, generally, the following statement is TRUE. Statement (Conjecture). Let us consider the differential operator $\hat{\mathcal{O}_n}$, then
\begin{equation}
\hat{\mathcal{O}_n}\left ( \frac{\log x}{x^m} \right )=(-1)^{m+1}\frac{(m-1)!}{n(n-1)(n-2) \cdots (n-m+1)x^m}
\end{equation}
with $n \in \mathbb{N}$, $n \ge m$. Anyone have any idea how it can be proved?","['derivatives', 'induction', 'differential-operators', 'proof-verification']"
2068553,Linear transformation in Lebesgue measure (not integration!): Change of variable,"Here's a problem that I'm stuck with for a while. If $E \subset \mathbb{R}^d$ is Lebesgue measurable, and $T:\mathbb{R}^d \to \mathbb{R}^d$ is a linear transformation, then: $(i)$ Show that $T(E)$ is Lebesgue measurable $(ii)$ Show that $m(T(E))=~|\mbox{det}(T)| \times m(E)$ $(iii)$ Give a counter example that if $T:\mathbb{R}^d \to \mathbb{R}^{d'}$ is a linear map to a space $\mathbb{R}^d$ of strictly smaller dimension than $\mathbb{R}^d$, then $T(E)$ need not be Lebesgue measurable. I think that the problem can be solved without involving the Lebesgue integration as the book I'm following introduced Lebesgue integration after the section on Lebesgue measure (and hence, this exercise). So to avoid any kind of circularity, I'm looking for a solution without relying on Lebesgue integration . Any help would be greatly appreciated!","['real-analysis', 'lebesgue-measure', 'measure-theory', 'linear-transformations', 'change-of-variable']"
2068567,Independence and Order-Statistics [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $X_1,...,X_n$ be a random sample from a uniform $U(0,\theta)$ distribution, where $\theta>0$. Are $X_{(n)}$  and $\left(\frac{X_{(n)}}{X_{(n-1)}},\frac{X_{(n-1)}}{X_{(n-2)}},...,\frac{X_{(2)}}{X_{(1)}}\right)$ independent?","['independence', 'probability-theory', 'statistics', 'uniform-distribution', 'order-statistics']"
2068574,copy of a random variable X,"If we have a random variable X, What does mean by X′ denotes an independent copy of X. by simple example. thanks","['probability-theory', 'probability', 'statistical-inference', 'probability-distributions']"
2068594,cut-off functions and irregular domains,"I'm trying to ensure existence of 'decent' cut-off functions for sets of low regularity. Suppose that $B$ is a Lebesgue measurable set in some $\mathbb{R}^n$. I'm wondering if there exists a cut-off function $\phi \in W^{1, \infty}(\mathbb{R}^n; [0,1])$ such that $| \{ \phi = 1\} \cap B| \geq (1-2\epsilon) |B|$ and $|\{\phi \not= 0 \} \cap B^c| \leq \epsilon$, i.e. I want $\phi$ to be equal to $1$ on a large portion of $B$ and $0$ outside of $B$, up to a set of measure $\epsilon$. The reason I'm asking is that I'd normally see cut-offs in the setting when you have a compact subset of some open set and you want your cut-off to be $1$ on the compact and $0$ outside the open - in this case it's quite easy to do using distance functions and what not, but what about more general sets? A reference would be a perfectly good answer. I'd very much like to keep the $W^{1, \infty}$ regularity, but if that's not possible then perhaps $W^{1,p}$ might do if there's a way of ensuring $p$ large enough. If that helps then the way I want to use that is to take two measurable sets $B_1, B_2$ and construct cut-offs $\phi_1, \phi_2$ that are equal to $1$ on large portions of the respective $B_i$'s and interacting only on a small set (i.e. $\{ \phi_1 \phi_2 \not= 0\} \cap (B_1 \cup B_2)$ should have small measure). The problem here is that I only know that $B_1 \cap B_2 = \emptyset$, they are not necessarily a positive distance apart, in which case that would be trivial. Edit: okay, shortly after posting I've realized that I can reduce the problem to the standard compact-open setting by using regularity of the Lebesgue measure on $\mathbb{R}^n$ and that solves the problem, sorry for posting in a rush, should've thought about it a bit more. I guess the question can be closed now.","['functional-analysis', 'sobolev-spaces', 'measure-theory', 'partial-differential-equations']"
2068602,Radius of convergence for $\sum_{n=1}^{\infty}a_{n}z^n $ and $ \sum_{n=1}^{\infty}\frac{1}{a_{n}}z^n $ is the same .,"Suppose that an $a_{n} \neq 0$ for all $n \in \mathbb{N} $. If $R$ is the radius of convergence of both the series : $$ \sum_{n=1}^{\infty}a_{n}z^n \ \text{ and } \ \sum_{n=1}^{\infty}\frac{1}{a_{n}}z^n$$
Then show that $R=1$.
One way to prove this is by contradiction Suppose that $R > 1$ then :
$$\sum_{n=1}^{\infty}a_{n} \ \text{ and } \sum_{n=1}^{\infty}\frac{1}{a_{n}} \ \text{ converges }$$
which implies that :
$$\lim_{n\to\infty} a_{n} = 0 , \  \lim_{n\to\infty}{\frac{1}{a_{n}}=0 }$$which gives contradiction the same argument will fail for $R < 1$.
The second way is let $$
 \limsup_{n\to\infty} \sqrt[n]{|a_{n}|}=\ell=\frac{1}{R}$$
And $$\frac{1}{\liminf\limits_{n\to\infty} \sqrt[n]{|a_{n}|}}=\frac{1}{\ell'}$$
So $\ell' \leq \ell $ and $\frac{1}{\ell'}=\ell$ if $\ell'<\ell<1 \ $then $\frac{1}{\ell'}>1>\ell$contradiction similarly for the other cases . The counter example is: $a_{n}= 2^n  $ if $n$ is even and $\frac{1}{2^n} $ if $n$ is odd. Note : this is not my idea .",['complex-analysis']
2068603,Difference between magnitude of gradient vs directional derivative of gradient,"I've read that the directional derivative is the rate of change of a function $f$ in a given direction $\mathbf{v}$, given as $\nabla f\cdot \mathbf{v}$. I've also read (perhaps incorrectly) that the magnitude of the gradient also tells us the rate of change. If so, what does the directional derivative of the gradient, i.e. $\nabla f\cdot \nabla f$ tell us?",['multivariable-calculus']
2068611,"R is a partial order on A, and $B\subseteq A$, prove that R is also a partial order on B","R is a partial order on A, and $B\subseteq A$, prove that R is also a partial order on B I've been doing exercises on relations and it bothers me a lot if this holds, hence my question. Reflexivity:
Let $x$ be an arbitrary element of B. But if so $x$ is also in A; and since R is reflexive on A, i.e. $\forall x\in A$ $xRx$, R is also reflexive on B. Anti-symmetric:
Let $x$ and $y$ be arbitrary elements of B, and assume $xRy$ and $yRz$. Since R is anti-symmetric on A, and $x$ and $y$ are in A in virtue of the subset property, we can utilise our assumption and this fact to deduce $x=y$. Transitivity:
Let $x$, $y$ and $z$ be arbitrary elements of B and assume $xRy$ and $yRz$. Again by the same approach, in virtue of the subset property and R being transitive on A, we can apply our assumptions to get $xRz$. I know it's a ridiculously simple question, but could anyone just confirm if my workings are right please? Thank you so much!","['relations', 'elementary-set-theory', 'proof-verification']"
2068640,Integration of a Periodic Function,"Problem: $f : \mathbb{R} \to  \mathbb{R}$  is a continuous and periodic function with period $T>0.$ Prove that: $$\lim_{n\to +\infty} \int_{a}^{b} f(nx) dx =\frac{b-a}{T} \int_{0}^{T} f(x) dx$$ I tried substituting $nx=t$, but it gave me $\frac{1}{n} \int_{na}^{nb} f(t)dt$, and I don't know what to do. Can anyone give me hints to solve this? Or is there another way to solve this problem?","['periodic-functions', 'integration', 'definite-integrals', 'limits']"
2068641,Multiplicative inverse of $2x + 3 + I$ in $\mathbb{Z}_5[x]/I $?,"In $\mathbb{Z}_5[x]$, let $ I = \langle x^2 + x + 2\rangle$. Find the multiplicative inverse of $2x + 3 + I$ in $\mathbb{Z}_5[x]/I$. The answer is supposed to be $3x + 1 + I$. But I don't understand how you find this. I divided $x^2 + x + 2$ by $2x+3$ to get $$ x^2 + x + 2 = (2x + 3)(3x + 1) + 4.$$ But I'm not sure how this will help me. I know that the elements of $\mathbb{Z}_5[x]/I$ are of the form $ax + b$, with $a, b \in \mathbb{Z}_5$. So I want $$ 1 + I = (ax + b)(2x+3) + I = (2ax^2 + (3a+2b)x + 3b) + I. $$ I want to find the coefficients $a, b$ from this. We must have $3b = 1$, and the coefficients by $x$ and $x^2$ must vanish. Since $\mathbb{Z}_5$ is a field, the relation $3b = 1$ means $b$ is the multiplicative inverse of $3$. So $b = 2$. From the coefficients of $x$, I get also $3a = -2b$. I multiply this with $2$ to get $a = 6a = -4b = -8 = 2$. So I would say the inverse is $2x + 2$, in contradiction with the answer at the back of my book. So where is the mistake in my reasoning, and how to find correct answer?","['abstract-algebra', 'ring-theory', 'ideals']"
2068643,Why the limit is $\frac{x}{1+x}$ and not 1,"I'm solving a problem about a plug flow reactor and I have this limit to compute. Just to control my result I asked Wolfram and I'm confuse can you explain me the result please. I precise $x$ is a fixed value . $$\lim_{R \to +\infty} \frac{1-\exp\left(\frac{x}{R+1}\right)}{\frac{R}{R+1}-\exp\left(\frac{x}{R+1}\right)}$$ When I made my reasonning I said, when $R$ goes to the infinity then the exponential terms both go to zero then the limit is the limit of $(1+R)/R$ which goes to $1$ when $R$ goes to the infinity. So I bet my reasonning is false but don't know why. Please don't answer me with the L'Hopital theorem I dislike it. Thank you in advance for your answer.","['limits-without-lhopital', 'calculus', 'limits']"
2068717,Prove without induction that $\sum_{r=1}^n {n\choose r}(-1)^{r+1}\frac1r=\sum_{r=1}^n \frac1r$ [duplicate],"This question already has answers here : Proving Binomial Identity without calculus (6 answers) A proof of $\sum_{i=1}^{n}(-1)^{i-1}\binom{n}{i}\frac{1}{i}=\frac{1}{1}+\frac{1}{2}+....+\frac{1}{n}$ [duplicate] (2 answers) Closed 7 years ago . Prove without induction that $$\sum_{r=1}^n {n\choose r}(-1)^{r+1}\dfrac{1}{r}=\sum_{r=1}^n \dfrac{1}{r}$$ for $n\geq1$. I have shown the above using induction. However, I am interested in knowing if we can show it directly without using induction. This is not entirely trivial, I think, if one is armed only with the very basic ideas of combinatorial identities. This can be proved in at least two different ways: one using induction and the other is by evaluating an integral. However, regarding the second approach, I am quite certain that if not known beforehand which integral to compute to get this equality, it is a hard exercise. EDIT: In the link claiming to be a duplicate of my question, induction was allowed. I am looking for approaches that use no induction or calculus. So this question is different.","['binomial-coefficients', 'combinatorics', 'summation', 'harmonic-numbers', 'discrete-mathematics']"
2068730,Independent increments in the Poisson process.,"Let $(N_t)_{t\geq0}$ be a Poisson process. For me, the definition is the following: $N_t=\max\{n\geq0:T_n\leq t\}$, where $T_0=0$ and $T_n=S_1+\ldots+S_n$, where $S_1,\ldots,S_n$ are independent exponential random variables of parameter $\lambda$ for all $n\geq1$. Hence, $N_t$ is Poisson$(\lambda t)$. I was able to prove that $N_{t+s}-N_s$ is independent of $N_s$ and that $N_{t+s}-N_s\sim\text{Poisson}(\lambda t)$, for $s,t\geq0$. From the information I wrote, is there a relatively easy way to prove that $N_{t+s}-N_s$ is independent from $(N_{s_1},\ldots,N_{s_m})$ for all $0\leq s_1\leq \ldots\leq s_m\leq s$ and $m\geq1$?","['independence', 'poisson-process', 'probability-theory', 'poisson-distribution']"
2068740,Morphism of algebraic groups defined over $\overline{\mathbb{Q}}$,"My question is about the general theory of algebraic groups, on which I'm still far from comfortable. I want to understand a sentence in Milne's ""Shimura varieties"" http://www.jmilne.org/math/xnotes/svi.pdf , bottom of page 60. We consider a reductive group $G$ defined over $\mathbb{Q}$, for which Milne defined a weight homomorphsm (cf. page 54 for a definition) $w_X:\mathbb{G}_m\rightarrow \mathbb{G}_{\mathbb{R}}$.
The sentence I'm not getting is:
""The weight homomorphism $w_X$ is a homomorphism $\mathbb{G}_m\rightarrow \mathbb{G}_{\mathbb{R}}$ over $\mathbb{R}$ of algebraic groups that are defined over $\mathbb{Q}$. It is therefore defined over $\overline{\mathbb{Q}}$"" Why can we reduce to $\overline{\mathbb{Q}}$? I guess it is because one works here only with algebraic tori (the image of $\mathbb{G}_m$ lies in the center $Z$ of $G$). 
Because for a general morphism between algebraic groups, this doesn't seem to be true: take $\mathbb{G}_{a,\mathbb{R}}=\mathrm{Spec}$ $\mathbb{R}[T]$, the additive group over $\mathbb{R}$, and the morphism $\mathbb{G}_{a,\mathbb{R}}\rightarrow \mathbb{G}_{a,\mathbb{R}}$ to be given by $T\mapsto \pi T$, which doesn't seem to be defined over $\overline{\mathbb{Q}}$. I thank you for your help ! Yoël.",['algebraic-geometry']
2068766,Find a sequence such that this tower of of exponent is convergent,"Context We already know that if we take a sequence $(x_n)\in{\mathbb R_+^*}^{\mathbb N}$ such that $$x_n=O\left(\frac 1{n^2}\right)$$ then $$\sum_{n=0}^\infty x_n <+\infty.$$ We also now that if we take for instance for all $n\in \mathbb N^*$ $$x_n=1+\frac 1{n^2}$$ then $$\prod_{n=0}^\infty x_n <+\infty.$$ Can we find a sequence $(x_n)\in(1,\infty)^{\mathbb N}$ such that $${{x_0}^{{x_1}^{{x_2}^{x_3}}}}^{\dots} = {{x_0}^{\left({x_1}^{\left({x_2}^{x_3^\cdots}\right)}\right)}}$$ is convergent? I think the answer is yes if we take $(x_n)$ such that $\lim_{n\to\infty} x_n=1$ and $(x_n)$ converges to $1$ really fast. But I don't know how to exhibit such a sequence.","['tetration', 'sequences-and-series', 'exponentiation']"
2068777,Is there a commonly used name for functions formed as products of rational powers?,"Let $q = (q_1, q_2, \dots, q_n)\in\mathbb Q^n$ and $c\in\mathbb R$, and let $f:\Omega\to\mathbb R$ be defined by
$$
  f(x) = c \cdot x_1^{q_1}x_2^{q_2}\cdots x_n^{q_n}
$$
where $\Omega\subset \mathbb R^n$ is chosen to exclude any points at which $f$ is singular.  Is there a commonly accepted name used for such a function $f$? I'm tempted to use something like ""rational monomial"" or ""rational power monomial,"" but I hesitate to do so since as I understand it, the word ""monomial"" is typically reserved for the case in which all powers are non-negative integers, so modifying that term by simply adding an adjective doesn't seem kosher.","['terminology', 'functions']"
