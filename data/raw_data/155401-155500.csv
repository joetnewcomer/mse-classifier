question_id,title,body,tags
2630801,"let $x,y ,z \in \mathbb{R^+}$ such that $x \geq y \geq z$ and $x^2+y^2+z^2 \geq 2xy+2xz+2yz$ now find the $\text{min}(\dfrac{x}{z})=?$","Let $x,y ,z \in \mathbb{R^+}$ such that $x \geq y \geq z$ and $x^2+y^2+z^2 \geq 2xy+2xz+2yz$. Find $\text{min}\bigg(\dfrac{x}{z}\bigg)= \ ?$ I found $(x-y+z-2\sqrt{xz})(x-y+z+\sqrt{xz})\geq 0$ 
but now what do I do?","['algebra-precalculus', 'factoring', 'maxima-minima']"
2630846,Find the area of curve,"The folium of descartes is defined by $$x^3+y^3-3xy=0$$ (cartesian) $$r=\frac{3\sec \theta \tan \theta}{1+\tan^3 \theta}$$ (polar) or $$x=\frac{3at}{1+t^3}, y=\frac{3at^2}{1+t^3}$$ (parametric). It looks like this and has the slant asymptote $y=-x-1$ . I'm trying to show that the area between the asymptote and the infinite branches of the curve is the same as the area of the loop. I already know the area of the loop, it is $1.5$ units. I managed to show that the area between the asymptote and the branches is also $1.5$ units, but the method I used was last-resort inelegant** (I, or more specifically wolfram-alpha, solved the cartesian equation for $y$ and then the resultant integral). Are there different ways to show that the asymptote-branches area is 1.5 units? Showing that its area is the same as the area of the loop is fine as well, but probably harder/needing a special trick. Thank you! ** The problem source says about this problem: ""Use a CAS to evaluate the resultant integral"" so I didn't feel too guilty about making WA do it. The problem source is James Stewart Calculus, in the polar and parametric equations chapter.","['integration', 'curves', 'calculus', 'area']"
2630847,Why the limit can only be $0$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question In my book it says if the limit $\lim\limits_{n \to \infty}\prod\limits_{i=1}^n(1+\varepsilon_it)$exsist ,it can only be $0$where $0<t<1,\varepsilon_i=1\ \mbox{or}\ -1$. Why it can only be zero",['limits']
2630854,"$R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b) $ [duplicate]","This question already has answers here : Proving that $\mathbb{Z}_m\oplus \mathbb{Z}_n \cong \mathbb{Z}_d\oplus \mathbb{Z}_l $ as groups, where $l=\mathrm{lcm}(m,n)$ and $d=\gcd(m,n)$ (2 answers) Closed 3 years ago . Let $R$ be a PID. How can one show that for all non zero $a,b \in R$ we have $R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b) $ . I have no idea how to define such an isomorphism. What I tried is to define $f([x],[y])=([\gcd(x,y)], [\operatorname{lcm}(x,y)])$ . I didn't get anywhere with that my map is probably not even well defined I got lost in the calculations. So does anyone know how to find the desired isomorphism. Thanks in advance","['abstract-algebra', 'principal-ideal-domains']"
2630872,Number of real roots of a quintic polynomial,"Obtain the number of real roots of the following quintic polynomial $$f(x)= x^5+x^3-2x+1$$ My approach: First, on seeing the polynomial, it should be clear that it is continuous. Also, $f(-\infty)=-\infty$ and $f(\infty)=\infty$. Hence, the function has at least one root. Now, the derivative is calculated as: $$f'(x)=5x^4+3x^2-2$$ which gives the two solutions as $\pm\sqrt{\frac25}$. Now, we need to test for the roots in each of the intervals. In the first Interval, the value of function is negative at $-\infty$ and positive at $-\sqrt{\frac25}$. Hence, function will have one root in this interval. Then, in the second Interval function decreases but never touches $x$-axis as it takes positive value at $\sqrt{\frac25}$. Also, the function again start to increase in the third Interval and is positive at $\infty$. Hence, it has only one root. Is my approach correct? My textbook gives the answer 3 using Rolle's theorem. It says that since the $f'(x)$ has two roots, then $f(x)$ will have three roots using Rolle's theorem. Thanks.","['derivatives', 'polynomials', 'roots', 'rolles-theorem', 'calculus']"
2630896,Find the general solution of linear system of equations (homework assignement),"Assuming that $\lambda$ is any number, does below set of equations have a solution? If it has, find the general solution for this system.
$$\lambda x_1+x_2+x_3=1$$
$$x_1+\lambda x_2+x_3=\lambda$$
$$x_1+x_2+\lambda x_3=\lambda^2$$
I understand how this problem should be solved, however when transform this set to a matrix and then row reduce it to an echolon form I get:
$$B=\left(\begin{array}{ccc|c}
1 & 1 & \lambda & \lambda\\
0 & \lambda-1 & 1-\lambda & \lambda-\lambda^2\\
0 & 0 & (\lambda-1)(\lambda+2) & \lambda^3+\lambda^2-\lambda-1\end{array}\right)$$
But from this point I start to struggle, don't really know where I'm making mistake.","['matrices', 'linear-algebra', 'vectors', 'systems-of-equations']"
2630911,Checking the differentiability of the following function,"Check the differentiability of the following function $$f(x)=(x+1)|x^2-1|$$ at points $x=1$ and $x=-1$. My approach I have written the function in the following form: $$f(x)=\begin{cases}
x^3-x+x^2-1 & \text{ if } x\leq-1,x\geq1 \\ 
x-x^3+1-x^2 & \text{ if } -1<x<1 
\end{cases}$$ Now, taking derivative: $$f'(x)=\begin{cases}
3x^2-1+2x & \text{ if } x\leq-1,x\geq1 \\ 
1-3x^2-2x & \text{ if } -1<x<1 
\end{cases}$$ Clearly, the above derivative is continuous at $x=-1$ and discontinuous at $x=1$, hence function will be differentiable at $x=-1$ and $x=1$. Did I do everything correctly? I am not sure about this and answer has not been provided in the answer manual.","['derivatives', 'calculus', 'proof-verification']"
2630920,Independence of sigma algebra generated by union of sigma algebra,"Let $\mathcal{F}_n \subseteq \mathcal{F}$ for n=1,2,3,..... be independent sequence of $\sigma$-algebra. Define- $$\mathcal{T}_n = \sigma( \bigcup\limits_{m=n}^{\infty}\mathcal{F}_n) $$ Is there a way to say that $\mathcal{F}_x$ is independent of $\mathcal{T}_n$ for x < n where x = 1,2,3.... and  n = 2,3..... Remark- Similar thing comes somewhere in the middle of the proof of Kolmogorov's 0-1 law.","['real-analysis', 'measure-theory', 'elementary-set-theory']"
2630932,"Prove $\{(\omega,y) \in \Omega \times [0,\infty) \ | \ y \leqslant f(\omega) \}$ is in the product $\sigma$-algebra $\mathcal{A} \otimes \mathcal{B}$","We have a $\sigma$-finite measure space $(\Omega,\mathcal{A},\mu)$, a measurable nonnegative function $f:\Omega \to \mathbb{R}$ and \begin{equation}
    G_f := \{(\omega,y) \in \Omega \times [0,\infty) \ | \ y \leqslant f(\omega) \}.
\end{equation} The Borel $\sigma$-algebra on $[0,\infty)$ is denoted by $\mathcal{B}$. The aim is to prove that \begin{equation}
    G_f \in \mathcal{A} \otimes  \mathcal{B} \quad \text{(the product $\sigma$-algebra of $\mathcal{A}$ and $\mathcal{B}$).}
\end{equation} My current approach: Since $f$ is measurable, it follows that ${G_f}^y := \{\omega \in \Omega \ | \ f(\omega) \geqslant y\} \in \mathcal{A}$ since $f$ is measurable (this follows from an elementary theorem we are allowed to use). Moreover, since $\{y\}$ is closed for any $y\in[0,\infty)$, we also have that $\{y\}\in\mathcal{B}$, since $\mathcal{B}$ is generated by all closed subsets of $[0,\infty)$. Consequently, \begin{equation}
    {G_f}^y \times \{y\} \in \mathcal{A} \otimes \mathcal{B} \quad \text{for each } y\in [0,\infty).
\end{equation} Now since \begin{equation}
    G_f = \bigcup_{y\in[0,\infty)}{G_f}^y \times \{y\},
\end{equation} it would be tempting to conclude that also $G_f\in \mathcal{A} \otimes \mathcal{B}$. However, this union is not countable, hence it is not guaranteed that it is included in $\mathcal{A} \otimes \mathcal{B}$. I am kind of stuck at this point, any help would be much appreciated!","['measure-theory', 'product-measure']"
2630956,Let $I\subset \mathbb{R}$ be an open interval and let > $f(x):I\to\mathbb{R}$ be a twice differentiable function in $a\in I$ s.a $f''(a)>0$.,"Let $I\subset \mathbb{R}$ be an open interval and let $f(x):I\to\mathbb{R}$ be a twice differentiable function in $a\in I$ s.a $f''(a)>0$ . Prove there exist $x_1,x_2\in I$ , $x_1<a<x_2$ s.a: $f'(a)=\frac{f(x_2)-f(x_1)}{x_2-x_1}$ Attempt :
I tried to use MVT but I need to prove it for a specific $a$ and not just for some $x_1<c<x_2$","['derivatives', 'real-analysis', 'calculus', 'functions']"
2630959,"Recurrence relation and initial conditions for the number of ways to tile a road (of length $n$ cm) , using blue, red and green tiles such that:","Find the recurrence relation and initial conditions for the number of ways to tile a road of length $n$ cm, using blue, red and green tiles such that the length of each blue tile is 2 cm, green one is 1 cm, red one is 3 cm, and green & blue tiles must not be adjacent. Hey all. So I defined $a_n$- The requested solution. $b_n$- number of ways such that the first tile is not blue. $c_n$- number of ways such that the first tile is not green.  I would like to find the recurrence relation using these definitions, but am quite clueless on how to continue from here.
Thanks in advance :)","['recurrence-relations', 'discrete-mathematics']"
2630997,Apostol Calculus I-14.19 exercise 16(missiles problem),"Problem: Due to a mechanical failure,a ground crew has lost control of a missile recently fired.It is known tha the missile will proceed at a constant speed on a straight course of unknown direction.When the missile is 4 miles away,it is sighted for an instant and lost again.Immediately an anti-missile missile is fired with a constant speed three times that of the first missile.What should be the course of the second missile for it to overtake the first one? The book's solution is that using the positive x-axis the line from position sighted four miles away to the ground crew.Proceed three miles along this line(in case the missile is returning to base)and then follow the spiral $ r=e^{θ/\sqrt8}$ (polar coordinates)(assume both missiles move on the same plane). I am trying to figure out why we use that spiral,my thoughts are that since $r(θ)=e^{θ/\sqrt8}$ then $log r=θ/\sqrt8$ and $\frac{dr}{dθ}/r=\frac{1}{\sqrt8}$ where r the length of the possition vector of the anti-missile and θ its angle with x-axis.Suppose $0\le \alpha\le π$ the angle between the velocity vector and the position vector of the anti-missile then I know that(from previous exercise) $\cot\alpha=\frac{dr}{dθ}/r$ so i try to prove that $cot\alpha = 1/\sqrt8$ in any possible position of impact. I also think that if $ φ$ the angle between the velocity vectors of the two missiles in a possition of impact then $α=π-φ$ .
Any hint would be helpfull.Thank you!","['vectors', 'linear-algebra', 'calculus']"
2631016,Why noetherian ring satisfies the maximal condition?,"""maximal condition"" means if any non-empty collection of ideals in R has a maximal element (under set inclusion). And we define noetherian ring to be a ring such that any ascending chain of ideals is finite. I don't see why the definition implies the maximal condition. Let's suppose $S=\{\mathfrak{A}_1, \mathfrak{A}_2\}$ such that $\mathfrak{A}_1\bigcap\mathfrak{A}_2=\{0_R\}$ and none of them is  unit ideal. Then there is no such maximal element. There is no need for an ideal properly contains in another ideal if it is not a maximal element. Can anyone point out what's the problem here? Thanks in advance Edit: What I am confusing is what will be the maximal element in my example. My definition for maximal element is: given $(S, R)$ a poset and $T\subset S$, then $s\in S$ a maximal element of $T$ if $sRy$ with $y\in S$ implies $s=y$. And I proved ""noetherian ring satisfies the maximal condition"" in this way: Since any non-empty collection of ideals is a poset, let $S$ be one and $T$ be a chain of $S$. As R is noetherian, there must be an ""end"" for the chain, namely $\mathfrak{A}\in T$. Then it is an upper bound of $T$ and hence $S$ is inductive and the result follow from Zorn's Lemma. But then I found I can't tell what is the maximal element in my example. So either my proof is false or something else goes wrong","['abstract-algebra', 'ring-theory', 'noetherian']"
2631051,Calculate $\lim_{x \rightarrow 0^+} \frac{\arctan (\log (1+\sqrt x)) \sin^3(x^{3/4})}{(e^{\tan(x)}-1)(1-\sin^2(x))}$,"I'm trying to calculate the following limit: $$\lim_{x \rightarrow 0^+} \frac{\displaystyle\arctan (\log (1+\sqrt x)) \sin^3(x^\frac34)}{\displaystyle (e^{\tan(x)}-1)(1-\sin^2(x))}$$ For WolframAlpha the result is: $0$. I did those steps, using Mac-Laurin : $$e^{\tan(x)}=1+x+\frac{x^2}{2}+ o(x^2)$$
$$\sin^2(x)=x^2+ o(x^2)$$
Hence, the denominator became: $$x+ \frac{x^2}{2}+ o(x^2)$$
Then, I'm having issues with numerator:
$$\arctan (\log (1+\sqrt x)) = \sqrt x - \frac {x}{2} + o(x^2)$$
$$\sin^3(x^\frac34)=x^{\frac94}+ o(x^3)$$ Someone could say me how to deal with the Numerator, o give me a hint for solve it? Thank you.","['wolfram-alpha', 'taylor-expansion', 'limits', 'trigonometry', 'calculus']"
2631055,"Multivariate Taylor theorem with small o notation (Not continuous, only differentiable)","I want to know whether the following is true. Let $n\in \mathbb{Z}$, $n\geq 2$, and $f:\mathbb{R}^n \rightarrow \mathbb{R}$ be $k$ times differentiable at a point $p\in\mathbb{R}^n$. Then
$f(p+v)=f(p)+Df(p)(v)+\frac{1}{2!}D^2f(p)v^{(2)}+\cdots+\frac{1}{k!}D^kf(p)v^{(k)}+o(||v||^k)$ When $n=1$, I know the above statement is true, and it can be proved using L'Hospital's theorem or other methods( Taylor's Theorem with Peano's Form of Remainder ). However, when $n\geq 2$, I have tried to prove but I cannot prove the above statement. Note that the above condition of the function $f$ is NOT $k$ times continuously differentiable, ONLY $k$ times differentiable. (It can be easily proved when $f$ is $\mathcal{C}^k$, then $f(p+v)=f(p)+Df(p)(v)+\frac{1}{2!}D^2f(p)v^{(2)}+\cdots+\frac{1}{k!}D^kf(p^*)v^{(k)}$ for some $p^*$, where $p^*$ is on the line segment between $p$ and $p+v$, therefore $f(p+v)-f(p)-Df(p)(v)-\frac{1}{2!}D^2f(p)v^{(2)}-\cdots-\frac{1}{k!}D^kf(p)v^{(k)}=\frac{1}{k!}\{D^kf(p^*)-D^kf(p)\}v^{(k)}$ , and the continuity of $D^kf$ now implies $o(||v||^k)$) Without the continuity of $D^kf$, I guess the above statement is false, but I cannot find any counterexamples. Can someone have some idea and give me any hints? (c.f. $D^mf:\mathbb{R}^n \rightarrow \mathcal{L}^m(\mathbb{R}^n,\mathbb{R})$ and $\mathcal{L}^m(\mathbb{R}^n,\mathbb{R})$ is the set of $m$-multilinear maps of $\mathbb{R}^n$ to $\mathbb{R}$, so $D^mf(p)v^{(m)}:=D^mf(p)(v,v,\cdots,v).$)","['multivariable-calculus', 'taylor-expansion']"
2631059,Dimension sum formula for subspaces of a infinite dimensional vector space,"Let $ \, K \, $ be a field, $X \, $ a $ \, K$-vector space and $ \, V \, $ and $ \, W \, $ subspaces of $ \, X$. I wonder if the (Hamel - algebraic) dimension formula of the sum $ \ V+W \ $ still holds for infinite dimensional case. Namely $dim_K (V+W) + dim_K (V \cap W) = dim_K(V) + dim_K(W) \ . $ Specifically, let $ \, B \, $ be a basis for $ \ V \cap W$, $B_V \ $ be a basis for $ \, V$, $B_W \ $ be a basis for $ \, W \, $ and $ \, \overline{B_V} \, $ and $ \, \overline{B_W} \, $ be basis for $ \ V+W \ $ such that $$B \subset B_V \subset \overline{B_V} \qquad \text{and} \qquad B \subset B_W \subset \overline{B_W} \ \ \ . $$ I would like to find a bijection $$\overline{B_V} \sqcup B \to B_V \sqcup B_W \ \ , $$ if this is possible. If not, then a counterexample would help. But I would still want to know if at least the inequality $$dim_K (V+W) \leq dim_K(V) + dim_K(W)$$ is valid. That is, find an injection $$\overline{B_V} \to B_V \sqcup B_W$$ or a surjection $$B_V \sqcup B_W \twoheadrightarrow \overline{B_V} \ \ . $$ Thanks in advance.","['functional-analysis', 'linear-algebra']"
2631105,Extension of Luzin N-property of absolutely continuous functions and measure preserving mappings,"We know that absolutely continuous functions $g\in {\rm W}^{1,1}(0,1)$ have the Lusin N-property: if $E\subseteq (0,1)$ is a set of measure zero, then $g(E)$ is also a set of measure zero. My question is do absolutely continuous functions allow stronger properties, and if they do not, what smaller class of functions allows such properties? Here are extensions of Luzin N-property I am interested in: Consider $g\in {\rm W}^{1,1}(0,1)\cap {\rm C}^1(0,1)\cap {\rm C}[0,1]$. Which of the following assertions is true, and for which class of functions (for instance, if one of the assertions is not true for absolutely continuous functions, it could be true for locally Lipschitz functions): If $F\subseteq (0,1)$ is a set of full measure in $(0,1)$, then $g(F)$ is a set of full measure in ${\rm Im}(g)$ (Remark: here ${\rm Im}(g):=\{g(s):s\in [0,1]\}$, and so, by uniform continuity of $g$, it holds that ${\rm Im}(g)=[m,M]$ for some $m,M\in\mathbf{R}$ such that $m\leq M$) For every sequence of measurable subsets $(E_n)$ in $(0,1)$ such that $\lim_{n\rightarrow+\infty}\lambda(E_n)=0$ it holds that 
$\lim_{n\rightarrow+\infty}\lambda(g(E_n))=0$. For every $\varepsilon>0$ there exists $\delta>0$ such that: for every countable family of non-overlapping intervals $([a_k,b_k])_{k=1}^{+\infty}$ 
such that $\sum_{k=1}^{+\infty}|b_k-a_k|\leq\delta$ we have $\sum_{k=1}^{+\infty}|g(b_k)-g(a_k)|\leq\varepsilon$. Remark. We know that a weaker property, namely when choice is restricted to finitely many intervals as above provides that $g$ is (locally) absolutely continuous. If we allow finitely many overlapping intervals, then $g$ is locally Lipschitz, i.e., $g\in {\rm W}^{1,\infty}_{loc}(0,1)$; these remarks can be found in G. Leoni's book: A First Course in Sobolev Spaces. For every $\varepsilon>0$ there exists $\delta>0$ such that: for every countable family of (possibly overlapping) intervals $([a_k,b_k])_{k=1}^{+\infty}$ 
such that $\sum_{k=1}^{+\infty}|b_k-a_k|\leq\delta$ we have $\sum_{k=1}^{+\infty}|g(b_k)-g(a_k)|\leq\varepsilon$. For every $\varepsilon>0$ there exists $\delta>0$ such that: for every measurable set $E\subset (0,1)$ such that $\lambda(E)\leq\delta$ we have $\lambda(g(E))\leq\varepsilon$. Remark. We know that $\lambda(E)\leq\delta$ implies $\int_{E}|g(s)|ds\leq\varepsilon$, this is so-called equi-integrability property of $g\in {\rm W}^{1,1}(0,1)$. If  $(K_m)$ is an increasing sequence of compact sets in $(0,1)$ such that $\lim_{m\rightarrow+\infty}\lambda((0,1)\backslash K_m)=0$, then $\lim_{m\rightarrow+\infty}\lambda\{\xi\in\mathbf{R}: (g_{\vert K_m})^{\leftarrow}(\xi)\neq\emptyset\}=\lambda({\rm Im}(g))$, where, as before, ${\rm Im} (g):=g([0,1])=[m,M]$. Measure preserving mapping: for every $0<\theta<1$ there exists $0<\varphi_{\theta}<1$ such that we have: for every measurable $E\subseteq (0,1)$ such that $\lambda(E)=\theta$, it holds that $\lambda(g(E))=\varphi_{\theta}\lambda({\rm Im}(g))$. I tried to sort the assertions in an descending order so as to introduce stronger and stronger requirements on $g$. So, I guess, property 1. should be easy to prove for absolutely continuous functions, and it is not to restrictive, while property 7. is rather restrictive and probably holds only for (a sub-class of) locally Lipschitz functions (property 7. holds, for instance, if $g$ is an affine function).","['real-analysis', 'sobolev-spaces', 'measure-theory', 'absolute-continuity']"
2631135,$3\times3$ matrix of distinct positive primes with determinant $0$,"Is there a $3\times3$ matrix of distinct positive primes whose determinant is $0$? I came across this while attempting a partial answer to a question here (which I forgot to favorite). However, I've made no headway on it.","['matrices', 'number-theory', 'prime-numbers', 'elementary-number-theory']"
2631229,What substitution would I make to integrate this?,"Problem: The integral is gonna be: $$\int^{1}_{0}\int^{1}_{0}4xy\sqrt{x^2+y^2} dy \, dx$$ But I'm quite rusty with my calculus, and this is mainly for a statistics course. I know that $x$ and $y$ are bounded within a unit square region in the $xy$-plane, and I was considering making some sort of $\cos$ or $\sin$ substitution to get rid of that pesky square root, but then I'm not sure what limits to use, and I suspect the $dy dx$ would just become $d\theta d\theta$, which doesn't make sense. Any help or guidance is appreciated. Please try to keep your explanation simple, and don't assume I understand things. It's been a while since my last calculus course :) Thank you!","['statistics', 'integration', 'definite-integrals', 'probability-distributions']"
2631230,"Show that for each $k\in\Bbb{N}$, $\Bbb{N}_k$ is finite","So, I'm studying mathematics on my own and I took a book about Proofs in Abstract Mathematics with the following exercise: For each $k\in\Bbb{N}$ we have that $\Bbb{N}_k$ is finite Just to give some context on what theorems and definitions we can use: Definition: $\Bbb{N}_k = \{1, 2, ..., k \} $ Definition: A set $S$ is infinite iff there exists a one-to-one but not onto $\ f:S\to S$ Definition: $A\sim B$ means $A$ is equipotent to (or same cardinality of) $B$ Theorem: if $A$ is infinite and $A\sim B$, then $B$ is infinite Theorem: if $A$ is infinite and $f:A\to B$ is one-to-one, then $B$ is infinite Theorem: Let $\ f:A \to B$ be one-to-one and $C\subseteq A$ then $\ g:C \to B$, $\ g(x)=f(x)\ $ for any $\ x\in C$, is also one-to-one Lemma: Let $k\in\Bbb{N}$, then $\Bbb{N}_k- \{x\} \sim \Bbb{N}_{k-1}$ for any $x\in \Bbb{N}_k$ What I did was: Suppose that $\Bbb{N}_K$ is not finite for every $k\in\Bbb{N}$, then by the Well-Ordering Principle, there is a smallest element $k\in\Bbb{N}$ such that $\Bbb{N}_k$ is infinite. Let $x_0\in\Bbb{N}_k\ $ be the smallest element of $\Bbb{N}_k$ and define $C=\Bbb{N}_k - \{x_0\}$. Let $f:\Bbb{N}_k \to C\ $ be $\ f(n)=n+1$. 
We will prove that $f$ is one-to-one. Let $x_1,x_2\in\Bbb{N}_k$ such that $f(x_1)=f(x_2)$, then $x_1+1=x_2+1$. Hence $x_1=x_2$, what proves that $f$ is one-to-one. Thus we have that $C$ is infinite. Then $C\sim \Bbb{N}_{k-1}$ and thus we must have that $\Bbb{N}_{k-1}$ is infinite. However this contradicts our hypothesis that $k$ is the least element such that $\Bbb{N}_k$ is infinite. Thus it must be that for each $k\in \Bbb{N}$ we have $\Bbb{N}_k$ is finite. My question is if the proof above, especially when creating the function $f:\Bbb{N}_k\to C$ has any flaw. The book explicitly says we should use the 6th theorem listed above, but I didn't find any explicitly use of it. Maybe is there another way to prove it? Edited: As some of you commented, the proof above was wrong. The function I created was not defined to $k+1$. I think this one is correct: If $\Bbb{N}_k$ is not finite for every $k \in \Bbb{N}$, then by the Well-Ordering principle there exists a least element $k \in \Bbb{N}$ such that $\Bbb{N}_k$ is infinite. By definition, there exists $f:\Bbb{N}_k \to \Bbb{N}_k$ such that $f$ is one-to-one but not onto. Then, because $f$ is not onto, there exists $y\in\Bbb{N}_k$ such that $y\neq f(x)$ for every $x\in \Bbb{N}_k$. Pick $x_0\neq y$ and define $A=\Bbb{N}_k-\{x_0\}$. Let $g:A\to A$ be defined as:
$$g(x)=
\begin{cases}
f(x) \ if \ f(x)\neq x_0 \\
f(x_0) \ if \ f(x) = x_0
\end{cases}$$ We will prove that $g$ is one-to-one but not onto. First we show $g$ is one-to-one. Let $x_1,x_2 \in A$ such that $x_1\neq x_2$. Since $f$ is one-to-one, $f(x_1)\neq f(x_2)$. If $f(x_1)=x_0$, then  $f(x_2)\neq x_0$. Hence $g(x_1)=f(x_0)$ and $g(x_2)=f(x_2)$. Since $x_0\neq x_2$, then $f(x_0)\neq f(x_2)$ and thus $g(x_1)\neq g(x_2)$. Without loss of generality, if $f(x_2)=x_0$, then $g(x_1)\neq g(x_2)$. If $f(x_1)\neq x_0$ and $f(x_1)\neq x_0$, then $g(x_1)=f(x_1)$ and $g(x_2)=f(x_2)$. Hence $g(x_1)\neq g(x_2)$. We have that $g$ is one-to-one. We now show that $g$ is not onto. Note that, because $x_0\neq y$, such that $y\neq f(x)$ for all $x\in\Bbb{N}_k$, we have $y\in A=\Bbb{N}_k-\{x_0\}$. Let $x\in A$. If $f(x)=x_0$, then $g(x)=f(x_0)\neq y$. If $f(x)\neq x_0$, then $g(x)=f(x)\neq y$. Hence there exists $y \in A$ such that for any $x \in A$ we have $g(x)\neq y$. Thus, $g$ is not onto. We have demonstrated that $g:A\to A$ is one-to-one, but not onto, hence A is infinite by definition. Giving that $A=\Bbb{N}_k-\{x_0\}$ and our lemma, we have that $\Bbb{N}_{k-1}$ is also infinite. However this contradicts our hypothesis that $k$ is the smallest element such that $\Bbb{N}_k$ is infinite. Hence it must be that for every $k\in\Bbb{N}$ we have $\Bbb{N}_k$ is finite. Sorry if my proof writing is bad in anyway. If you have any stylistic suggestion, or any suggestion at all, I would gladly read it :)","['cardinals', 'elementary-set-theory', 'proof-verification']"
2631263,Is the product of primes less than $3\log_2{n}$ always at least $n$?,"Consider the product of all primes less than $3 \log_2{n}$.  Is it true that this product is always at least $n$ for all positive integers $n$? In general, what is the smallest $x_n$ so that the product of all
  primes less than $x_n$ is always at least $n$?  Here $x_n$ is a function of
  $n$. I plotted $\frac{n}{\text{product of all primes less than $3 \log_2{n}$}}$ to support the conjecture.  Here it is for for $n$ from $2$ to $100$. I computed the values for $n$ up to one million and the ratio gets smaller and smaller, supporting the conjecture. I then repeated the same experiment but with $\frac{n}{\text{product of all primes less than $2 \log_2{n}$}}$.  Here it is for for $n$ from $3$ to $200$. So it seems that the product of all primes less than $2 \log_2{n}$ might also work. I also tried it with  $\frac{n}{\text{product of all primes less than $ \log_2{n}$}}$. The conjecture  no longer holds for small $n$ and it seems it might not even hold if you restrict it to large $n$.","['number-theory', 'prime-numbers', 'distribution-of-primes']"
2631284,Find all $n \in \mathbb{N}$ such that $(n+2) \mid (n^2+5)$,"I'm trying to find all $n \in \mathbb{N}$ such that $(n+2) \mid (n^2+5)$ as the title says, I've tried numbers up to $20$ and found that $1, 7$ are solutions and I suspect that those are the only $2$ solutions, however I have no idea how to show that. I've done nothing but basic transformations: $(n+2) \mid (n^2+5)$ $\iff n^2+5 = k(n+2)$ $\iff n^2+5 \mod(n+2) = 0$ $\iff (n^2 \mod(n+2) + 5 \mod(n+2)) \mod(n+2) = 0$ Now I suspect the next step is to find all possible solutions for $n^2 \mod(n+2)$, which I have no idea how to do.","['number-theory', 'divisibility']"
2631343,Find the limit of $\lim\limits_{x\to0^+}\frac{1}{e} \frac{e- e^ \frac{\ln (1+x)}{x}}{x}$ as $x$,"Find the limit of $\frac{1}{e} \frac{e- e^ \frac{\ln (1+x)}{x}}{x}$ as $x$ approaches right of zero. The answer is $\frac{1}{2}$ but I keep getting 1. Here's what I have: Since $\lim_{x\to0^+} \frac{\ln (1+x)}{x}$ is of indeterminate form (0/0), we can apply L Hôpitals. So now I have 
$\lim_{x\to0^+}\frac{1}{e} \frac{e- e^ \frac{1}{1+x}}{x}$, which is also of indeterminate form (0/0). So by L Hôpitals, $\lim_{x\to0^+}\frac{1}{e} \frac{{- e^ \frac{1}{1+x} \frac{-1}{(1+x)^2}}}{x}$ which is equal to 1. But as I said, the answer is $\frac12$. Can you tell me where did I go wrong? Thanks!","['real-analysis', 'limits', 'calculus', 'limits-without-lhopital', 'analysis']"
2631407,Obtain an explicit function from an implicit expression,"Let $y=y(x)$ be a function implicitly defined as $$xy+\ln(xy)=1$$ near a point $P(1,1)$. I have to find the explicit expression $y(x)$ as well as the values $y'(1)$ and $dy(1)$. I've tried applying the exponential to both sides but I could not find a solution: $$  e^{xy}xy=e  $$  doesn't seem to be very helpful. Also, using implicit differentiation didn't help me that much with obtaining $y'(1)$. If I am not mistaking, by implicit differentiation one obtains 
$$y+xy'+\frac{1}{x}+\frac{y'}{y}=0$$ But I still can't see how I can obtain the value $y'(1)$ from this. As for $dy(1)$: I have no idea how I could obtain that! Any help/suggestions would be appreciated.","['real-analysis', 'ordinary-differential-equations', 'calculus']"
2631444,Another summation identity with binomial coefficients,"Recently I have encountered on this page a rather nice identity:
$$
\sum_{k=0}^m4^k\frac{\binom{n}{k}\binom{m}{k}}{\binom{2n}{2k}\binom{2k}{k}}=\frac{2n+1}{2n-2m+1},
$$
which however is valid only for $n\ge m$. This motivated me to try finding out a more symmetric expression with the aim to get $\frac{1}{2n+2m+1}$ on the RHS. Simple negation of $m$ did not help until the expression $\binom{2n}{2k}$ in the denominator was replaced with that one involving $m$:
$$
\sum_{k=0}^{n}(-4)^k\frac{\binom{n}{k}\binom{m+k}{k}}{\binom{2m+2k+1}{2k}\binom{2k}{k}}=\frac{2m+1}{2n+2m+1}.
$$ After swapping $n$ and $m$ the aim was achieved:
$$
\sum_{k=0}^{\infty}\frac{(-4)^k}{\binom{2k}{k}}\left[\frac{\binom{n}{k}\binom{m+k}{k}}{\binom{2m+2k+1}{2k}}+\frac{\binom{n+k}{k}\binom{m}{k}}{\binom{2n+2k+1}{2k}}\right]=1+\frac{1}{2n+2m+1}.
$$
But I am still not quite satisfied. Is there a suitable decomposition of 1 which could help to simplify the expression? Or maybe some different approach can better clarify the origin of the identity? I would appreciate any hint.","['combinatorics', 'binomial-coefficients']"
2631500,Cotangent domain error?,"Some time ago I was wondering about the definition of cotangent; namely, that it is both defined as $\frac{\cos x}{\sin x}$ and as $\frac{1}{\tan x}$. However, $\cot(90°)$ and $\cot(270°)$ are equal to 0. Through the first definition I listed of cotangent, this is equal to $$\cot(90°) =\frac{\cos(90°)}{\sin(90°)} = \frac{0}{1} = 0$$ With the second definition, this is equal to
$$\cot(90°) = \frac{1}{\tan(90°)} = \frac{1}{undefined} =\ ?$$ While I know that at $\tan(90°)$ there is an asymptote which, from the right goes to $-\infty$ and from the left goes to $\infty$. While I understand that in this case, the limit $\lim_{x\to \frac{\pi}{2}}\frac{1}{\tan x} = 0$, wouldn't this constitute a domain error in the function $\cot x$ since $\frac{1}{\infty}$ technically doesn't equal $0$? Thanks for reading.",['trigonometry']
2631515,A first order non-homogeneous initial value problem,"Does $\frac{\text{d}y}{\text{d}x}=-y+\sin(x^2)$ has a unique and well defined solution in $y\in[0,\infty)$ for any $y(0)\in\mathbb{R}$? For a unique solution to exists, do we need $\sin(x^2)$ to be locally Lebesgue integrable on $[0,\infty)$?","['real-analysis', 'dynamical-systems', 'calculus', 'ordinary-differential-equations', 'initial-value-problems']"
2631575,How to count the number of 5 card hands possible from a double deck?,"I'm an undergraduate taking my first-ever upper division math class. It's Combinatorics, which is pretty There are $\binom{52}{5}$ different hands possible in a single poker deck. In a double deck, however, there are more than that, because some cards can be repeated. The way that I've been attempting to enumerate this is by going through the different possibilities, abcde aabcd aabbc and trying to enumerate the number of different combinations of cards that can be rearranged to those specific permutations. So, for example, aa-bcd has $\binom{52}{1}$ possibilities for the ""aa"" pair, and a further $\binom{52-1}{3}$ possibilities for the ""bcd"" part of the hand. So would there be $$\binom{52}{1} \binom{51}{3}$$ possiblities? By this logic, I come up with the summation $$\binom{52}{5} + \binom{52}{1}\binom{51}{3} + \binom{52}{2}\binom{50}{1}$$, ( Edit: Slight mistake, the last one should be $\binom{50}{1}$ not $51$. Pointed out by Long, below.) but since I can't find a hard answer, I'm finding it difficult to double-check my work. What do you think? Is this the right way to ""think through"" the problem? Have I made an important mistake (likely)? Edit: Thank you for all of your help. I took the confirmation and generating function technique I learned here to write an extension to this, on how to count the number of 5 card hands from a double, triple, and quadruple deck .","['combinatorics', 'poker', 'discrete-mathematics']"
2631577,$\sin x$ shifts by $\frac{\pi}{2}$ are equivalent to its derivatives?,"An interesting thing in trigonometry that I noticed is that $$\sin(x + \pi/2) = \cos x \\ \sin(x +\pi) = \cos(x + \pi/2) = -\sin x \\ \sin (x + 3\pi/2) = -\sin(x+ \pi/2) = -\cos x$$ However, upon learning calculus (basic derivatives), I noticed that this pattern is exhibited in the derivatives of $\sin x$ as well:
$$\frac{d}{dx}[\sin x] = \cos x \\ \frac{d}{dx}[\cos x] = -\sin x \\ \frac{d}{dx}[-\sin x] = -\cos x$$ What is the reason for this? How is the shift of $\sin x$ by $\pi/2$ related to the derivatives of $\sin x$? Of course this would also imply that a shift of $-\pi/2$ would give the integral of the function from which it is shifted. Thanks for reading.","['derivatives', 'trigonometry', 'calculus']"
2631633,How to solve this (maybe) combinatorics problem?,"There are $n$ people, and we are allowed to divide them into 2 or more teams (at most $k$,  $k \leq n$). It is allowed for a team to consist of only one people. After dividing them, two people will fight if they are from different team. We want to maximize the number of fight, how to best divide those $n$ people? Example: $n = 6$, $k = 3$ then the optimal way is to divide them into $3$ team each consisting of $2$ people, which will result in $12$ fights. After some brute force experiment I think the best way is to distribute them into as many team as possible, and each team has member distributed as equally as possible (basically divide them and distribute the result and remainder to all $k$ teams), but I don't know how to prove this.","['combinatorics', 'graph-theory']"
2631662,Prove that $\lim_{n \to \infty} \frac{1}{2^n}\sum_{k=0}^n(-1)^k {n\choose k}f\left(\frac{k}{n} \right)=0$,"Let $f:[0,1] \to \mathbb{R}$ be a continuous function. Prove that
  $$\lim_{n \to \infty} \frac{1}{2^n}\sum_{k=0}^n(-1)^k {n\choose k}f\left(\frac{k}{n} \right)=0$$ I know that $f$ is uniformly continuous and I tried to get some inequalities for the terms $f\left(\frac{k}{n} \right)$. For all $\epsilon>0$, we have $|f(0)-f\left(\frac{1}{n} \right)|<\epsilon, \dots, |f\left(\frac{n-1}{n} \right)-f(1)|<\epsilon$ when $n$ is large enough. Then I tried to apply these for the sum in the statement and squeeze it to $0$, but I only got to prove it is less than $\frac{n}{2},$ which doesn't go to $0$.","['continuity', 'uniform-continuity', 'functions', 'limits']"
2631688,Does every representation of the harmonic oscillator Lie algebra necessarily admit a basis of eigenfunctions?,"It is well-known in quantum mechanics that the harmonic oscillator Hamiltonian given by $\mathcal{H} = -\frac{1}{2}\frac{d^2}{dx^2} + \frac{1}{2}x^2 - \frac{1}{2}$ admits a basis of eigenfunctions on $L^2(\Bbb R,dx)$. There are many proofs of this ranging from hard analysis (brute force proving density) to Bargmann transform techniques to showing that the resolvent is compact. An important part of the analysis is that the Gaussian $e^{-\frac{x^2}{2}}$ is an eigenfunction with eigenvalue $0$. Associated to this system is a very nice Lie algebra. Define the operator $a$ by $$a = \frac{1}{\sqrt{2}}\left(\frac{d}{dx}+x\right)$$ and its (formal - I'm not going through the awful nitty gritty details of domains of definition, etc) adjoint $$a^* = \frac{1}{\sqrt{2}}\left(-\frac{d}{dx}+x\right).$$ $\mathcal{H}$ has the following representation: $$\mathcal{H} = a^*a.$$ Moreover, this triple of operators satisfies (on sufficiently nice functions): $$[\mathcal{H},a^*] = a^*, \qquad [\mathcal{H},a] = -a, \qquad [a,a^*] = -1.$$ The quadruplet $\mathcal{H},a^*,a,1$ generates a Lie algebra. Because of these relations, applying $a^*$ repeatedly to the Gaussian leads to successive eigenfunctions (that they are in $L^2$ needs to be checked, but it is straightforward by induction) and indeed these eigenfunctions form a basis. My question is this: does a representation of the Lie algebra $$[a^*a, a^*] = a^*, \qquad [a^*a, a] = -a, \qquad [a,a^*] = -1$$ on an abstract separable Hilbert space $\mathfrak{H}$ (not necessarily $L^2(\Bbb R,dx)$) necessarily admit a basis of eigenfunctions for $a^*a$ assuming that $\ker a\neq \{0\}$? That is, if $\{\psi_i:i\in I\}$ denotes a basis for the kernel of $a$, does $\{(a^*)^m\psi_i:m\in\Bbb N_0,i\in I\}$ form a basis for $\mathfrak{H}$? Or is this somehow a happy accident of working on $\Bbb R$ (or, as we know, more generally $\Bbb R^n$)?","['functional-analysis', 'eigenfunctions', 'lie-algebras']"
2631825,"Is the ""composition"" of two dense subsets of functions dense?","Given $F \subseteq C_C(\mathbb{R}^d, \mathbb{R}^p)$, $F$ is dense in $C_C(\mathbb{R}^d, \mathbb{R}^p)$ in the supremum norm $\|\cdot\|_\infty$. Also given $G \subseteq C_C(\mathbb{R}^p, \mathbb{R}^s)$, $G$ is dense in $C_C(\mathbb{R}^p, \mathbb{R}^s)$ in $\|\cdot\|_\infty$. Is the set $G \circ F := \{g \circ f: g \in G, f \in F, g \circ f \in C_C(\mathbb{R}^d, \mathbb{R}^s)\}$ dense in $C_C(\mathbb{R}^d, \mathbb{R}^s)$? Note that $d, p, s\in \mathbb{N}$ are not necessarily equal. Any help would be much appreciated. Thanks!","['functional-analysis', 'analysis']"
2631831,Is there a way to describe these compactifications algebraically?,"There is a well known correspondence between locally compact Hausdorff spaces and commutative C* algebras, in which the homoemorphism class of spaces is mapped one-to-one to the isomorphism class of commutative C* algebras via $X\mapsto C_0(X)$. Compact spaces correspond to unital algebras, and compactification procedures like one-point compactification or Stone-Cech compactification to unitisation procedures like the adjoining of unit $A\mapsto A\oplus\Bbb C1$ and passing to the multiplier algebra. Suppose one has a bounded and open subset $U$ of some $\Bbb R^n$. The closure $\overline{U}$ will then be a compactification of $U$, and for that reason $C(\overline U)$ will be a unitisation. Is there a way to describe how this unitisation works on the algebra level? Specifically how one can distinguish it from unitisations that do not allow an embedding into $\Bbb R^n$? As an example with $U=(0,1)$ the closure $[0,1]$ is a two-point compactification and we adjoin two elements to the algebra, which we can view for example as the positive functions $x$ and $1-x$, adding them together gives unit.","['functional-analysis', 'general-topology', 'c-star-algebras', 'compactification']"
2631860,"Relationship between $t$ and $x$ in $x'=f(t,x)$?","I'm a couple weeks into a course on differential equations. I've been told that it's more accurate to think of a differential equation $x'=f(t,x)$ as being determined by two separate variables, $t$ and $x$. So, my understanding is that while it is true that for a particular solution of the DE, say $x(t)$, the dependence of $x$ on $t$ is evident, it is more accurate to view $x'=f(t,x)$ as a statement about two separate variables. Okay! So I'm holding $t$ and $x$ as distinct in my mind, and I go to solve a basic differential equation:
$$x'=-2tx^2$$
$$-\frac{x'}{x^2}=2t$$
And it's at this point that I suddenly remember a fortuitous fact: There is an implicit dependence of $x$ on $t$, after all! This allows me to integrate with respect to $t$, appealing to the chain rule and the FTC I: If $F(x)$ is an antiderivative of $-\frac{1}{x^2},$ then $\frac{d}{dt}(F(x(t)))=-\frac{x'}{x^2}$ by the chain rule, and $\int{-\frac{x'}{x^2}dt}=\int{\frac{d}{dt}F(x(t))}=F(x(t))$ by FTC I (since $\frac{1}{x^2}$ is continuous everywhere it is defined). So,
$$\int{-\frac{x'}{x^2}dt}=\int{2t dt}$$
$$\frac{1}{x}=t^2+C$$
$$x(t)=\frac{1}{t^2+C}.$$ It's only the very real dependence of $x$ on $t$ that allows me to use the chain rule and the FTC I to justify all that integrating. So, is the $x$ in $x'=f(t,x)$ truly a second variable? Another question is, Does it even matter? Like anyone, I can sometimes make mountains of molehills when I'm learning something new, and create difficulties for myself where none exists (as if things weren't difficult enough!). Is that what I'm doing here? Does it truly matter how I think of the relationship between $t$ and $x$ in the statement $x'=f(t,x)$?",['ordinary-differential-equations']
2631885,Is there a quicker way to evaluate the following definite integral?,"Evaluate the following definite integral $$\int_{0}^{1} \frac{x}{(x^2+x+4)\sqrt{4x^2+4x+5}}\,dx.$$ My steps: Separating the integral gives
$$\int_{0}^{1}\left(\frac{8x+4}{8(x^2+x+4)\sqrt{4x^2+4x+5}}-\frac1{2(x^2+x+4)\sqrt{4x^2+4x+5}}\right)dx.$$
For the first integral, letting $$u=\sqrt{4x^2+4x+5}$$
$$du=\frac{8x+4}{2\sqrt{4x^2+4x+5}}\ dx$$
gives
$$\int_{0}^{1}\frac{8x+4}{8(x^2+x+4)\sqrt{4x^2+4x+5}}\ dx = \frac14\int_{\sqrt5}^{\sqrt{13}} \frac1{x^2+x+4}du$$
$$$$Knowing that $$x^2+x+4=\frac{u^2+11}4$$
The integral in terms of $u$ becomes:
$$\int_{\sqrt5}^{\sqrt{13}}\frac1{u^2+11}\ du=\frac{\sqrt{11}}{11}\int_{\sqrt5}^{\sqrt{13}}\frac1{\sqrt{11}\left(\left(\frac{u}{\sqrt{11}}\right)^2+1\right)}\,du$$
Evaluating the indefinite integral, we get:
$$\frac1{\sqrt{11}}\arctan\left(\sqrt{\frac{4x^2+4x+5}{11}}\right)+C$$
For the second integral, let:$$u=\frac{8x+4}{\sqrt{4x^2+4x+5}}$$ $$du=\frac{32}{\sqrt{(4x^2+4x+5)^3}}\ dx$$
Thus: $$-\int_0^1\frac1{2(x^2+x+4)\sqrt{4x^2+4x+5}}\,dx=-\frac1{64}\int_{4/\sqrt5}^{12/\sqrt{13}}\frac{4x^2+4x+5}{x^2+x+4}\,du$$
To write the integrand in terms of $u$, we need to find values for $a$ and $b$ such that:
$$\frac{x^2+x+4}{4x^2+4x+5}=a\cdot u^2+b\Leftrightarrow\frac{x^2+x+4}{4x^2+4x+5}=a\cdot\frac{64x^2+64x+16}{4x^2+4x+5}+b\cdot\frac{4x^2+4x+5}{4x^2+4x+5}$$
$$\Leftrightarrow x^2+x+4=(64a+4b)x^2+(64a+4b)x+(16a+5b)$$
$$$$By solving a system of linear equations for $a$ and $b$ for the relations:
$$\begin{cases}
64a+4b=1 \\
16a+5b=4
\end{cases}$$
we find that: $$ a=-\frac{11}{256}\quad \wedge  \quad b=\frac{15}{16}.$$
Therefore, the integral in terms of $u$ becomes:
$$-\frac1{64}\int_{4/\sqrt5}^{12/\sqrt{13}}\frac{4x^2+4x+5}{x^2+x+4}\ du=-4\int_{4/\sqrt5}^{12/\sqrt{13}}\frac{1}{240-11u^2}\,du=$$
$$=-\frac1{60}\int_{4/\sqrt5}^{12/\sqrt{13}}\frac{1}{1-\left(\frac{\sqrt{11}u}{4\sqrt{15}}\right)^2}\,du$$
Letting: $$s=\frac{\sqrt{11}}{4\sqrt{15}}u$$ $$ds=\frac{\sqrt{11}}{4\sqrt{15}}du$$
and subsequently substituting for $s$, obtaining:
$$\displaystyle-\frac1{\sqrt{165}}\int_{\sqrt{11/75}}^{\sqrt{33/65}}\frac{1}{1-s^2}\ ds$$
$$$$Evaluating the indefinite integral, we get:
$$-\frac1{\sqrt{165}}\tanh^{-1}\left(\frac{\sqrt{11}(2x+1)}{\sqrt{15(4x^2+4x+5)}}\right)+C$$
$$$$Now we can evaluate the integral from $0$ to $1$:
$$\int_{0}^{1} \frac{x}{(x^2+x+4)\sqrt{4x^2+4x+5}}\ dx=$$ $$=\left[\frac1{\sqrt{11}}\arctan\left(\sqrt{\frac{4x^2+4x+5}{11}}\right)-\frac1{\sqrt{165}}\tanh^{-1}\left(\frac{\sqrt{11}(2x+1)}{\sqrt{15(4x^2+4x+5)}}\right)\right]_0^1=$$
$$\boxed{\frac1{\sqrt{11}}\arctan\left(\sqrt{\frac{13}{11}}\right)-\frac1{\sqrt{165}}\tanh^{-1}\left(\sqrt{\frac{33}{65}}\right)-\\\frac1{\sqrt{11}}\arctan\left(\sqrt{\frac{5}{11}}\right)+\frac1{\sqrt{165}}\tanh^{-1}\left(\sqrt{\frac{11}{75}}\right)}$$ Question: Is this procedure correct? Also, is there a quicker way to evaluate the integral?","['real-analysis', 'integration', 'definite-integrals']"
2631895,Proving Monge's Theorem using Menelaus',"Monge's theorem states that for any three circles in a plane, none of which is completely inside one of the others, the intersection points of each of the three pairs of external tangent lines are collinear. The article goes on to say that this can be proved easily using Menelaus' theorem. I understand Menelaus' theorem but don't quite understand how to apply here. Do we consider the triangle $ABC$ formed by joining the centers of the three circles? Then we can consider the three points of intersection $A', B', C'$, each one on the side opposite the respective vertex. It's easy to see that the sign of the product $\frac{AC'}{C'B}\cdot \frac{BA'}{A'C}\cdot \frac{CB'}{B'A}$ is negative. But how to prove that its magnitude is $1$ in order to establish the result?","['affine-geometry', 'euclidean-geometry', 'geometry']"
2631909,Counterexample to Leibniz criterion for alternating series,"I have this statement and I need to say if it is true or false: Let $\{a_n\}$ be a real sequence. $$\lim_{n\to +\infty} a_n = 0 \quad \implies \quad \sum_{n=1}^{\infty}(-1)^na_n \quad \text{converges}$$ I know, from the Leibniz criterion that: If $a_n \to 0$, $a_n$ is decreasing and positive then $\sum_{n=1}^{\infty}(-1)^na_n$ converges From this fact I believe that the statement is false but I couldn't come up with an infinitesimal sequence that isn't decreasing and for that reason is divergent. I tried some function with $sin(\frac{1}{n})$ without any luck. Any help would be very appreciated, thank you!","['real-analysis', 'sequences-and-series']"
2631988,Find joint distribution of minimum and maximum of iid random variables,"$(X_n)$ sequence of iid random variables with uniform distribution $U([0,1])$ . $m=\min(X_1,...X_n), M=\max(X_1,...X_n)$ . I want to find $f_{m,M}(s,t)$ . $$
\begin{split}
P(m<s,M<t)
 &= P(m<s)P(M<t)1_{m\ne M}+P(X_1<\min(s,t))1_{m=M} \\
 &= (1-(1-s))^nt^n1_{m \ne M}+\min(s,t)1_{m=M} \\
 &=((st)^n+s)1_{s<t}+((st)^n+t)1_{s \ge t}
\end{split}
$$ When I differentiate it, I get $f_{m,M}(s,t)=n^2t^{n-1}s^{n-1}$ . Is this okay? And does it mean that $M$ and $m$ are independent and $f_{m,M}(s,t)=f_m(s)f_M(t)$ ?","['uniform-distribution', 'probability', 'probability-distributions']"
2632072,"""Discovering"" the hyperbolic functions $\cosh(x)$ and $\sinh(x)$","I'm trying to derive the definitions of hyperbolic functions with this image in mind, where $a := \cosh u$, $b := \sinh u$, and $u = 2A$. I have 
$$2A = 2\int_{0}^b \sqrt{1+y^2} \ \mathrm{d}y = b\sqrt{b^2 + 1} + \log\left(b + \sqrt{b^2 + 1}\right)$$
and therefore 
$$\begin{align}
\cosh u &= \cosh\left(\;b\sqrt{b^2 + 1} + \log\left(b + \sqrt{b^2 + 1}\right)\;\right) = \sqrt{b^2 + 1} \\
\sinh u &= \sinh\left(\;b\sqrt{b^2 + 1} + \log\left(b + \sqrt{b^2 + 1}\right)\;\right) = b
\end{align}$$ The goal here is to solve for $u$ in terms of $b$ and then derive the usual formulas, but that's proven to be impossible (unless I made a mistake, which I think might be the case here). Where can I go from here? Also, I'm using the derivation shown in this guide . EDIT: The correct integral is
$$2A = 2\int_{0}^b \left( \sqrt{1+y^2} - \frac{a}{b}y \ \mathrm{d}y \right)  = \log\left(b + \sqrt{b^2 + 1}\right)$$
so 
$$b = \cfrac{e^{2u} - 1}{2e^u}$$ 
and from here the rest follows trivially.","['hyperbolic-functions', 'calculus', 'geometry']"
2632086,Complex analysis: prove that $ |\int_{\gamma} f(z) dz| \leq M \ell (\gamma) $,"$f$ is a continuous function and $|f(z)| \leq M$. I need to prove $ \Big|\int_{\gamma} f(z) dz \Big| \leq M \ell (\gamma) $
where $\ell (\gamma) = \int_{0}^1 |\gamma'(t)| dt$. Here is my attempt:
$ \Big|\int_{\gamma} f(z) dz \Big|= \Big|\int_{0}^1 f(\gamma(t))\gamma'(t) dt\Big |\leq\int_{0}^1 \Big|f(\gamma(t))\Big |\Big |\gamma'(t)\Big | dt\leq \int_{0}^1 M\Big |\gamma'(t)\Big | dt =M\int_{0}^1 |\gamma'(t)| dt=M \ell (\gamma) $ Is this straightforward prove right? Thanks!","['complex-analysis', 'proof-verification']"
2632108,Prove that $f(x) = 0$ for all $x \in \mathbb{R}$ (Analysis),"Let $f: \mathbb{R} \to \mathbb{R}$ be a function such that $f(x) = f^{(4)}(x)$ with $f(0) = f’(0) = f’’(0) = f’’’(0) = 0.$ Prove $f(x) = 0$ for all $x \in \mathbb{R}$ My Attempts: Suppose $x \in \mathbb{R}$. Note that $\displaystyle f'(0) = \lim_{x\to 0} \frac{f(x)-f(0)}{x-0} = \lim_{x\to 0} \frac{f(x)}{x} = \lim_{x\to 0} \frac{f'(x)}{1}=0$. (L'Hôpital's Rule was used in the second to last limit due to the form $\frac{0}{0}$). With this approach, I am not necessarily finding if $x = 0$ on the whole real line. This led me to a different approach: Suppose $x \in [0,b]$. By Mean Value Theorem, there exists  $c \in (0,b)$ so that $\displaystyle \frac{f(b)-f(0)}{b-0} = f'(c)$. This approach doesn't bring me anywhere either, even if I repeatedly use Mean Value Theorem. Any suggestions on how to proceed and conclude? (I am currently reading/finishing the chapter on Differentiation in baby Rudin.)",['real-analysis']
2632188,Path to quantum geometry for mathematicians?,I am looking for an introduction of Quantum Geometry (math-subject) for mathematicians. This paper presents a survey however I am looking for something with more mathematical depth and motivation (for a no-physicist). Something like the book Quantum Geometry: A Framework for Quantum General Relativity but for mathematicians. Just to be clear: I am aware of the these questions on quantum physics for mathematicians and this question on quantum mechanics. I am asking for a specific kind of geometry (quantum geometry) from the perspective of geometry (mathematics). This is not a general question asking about the geometry used in quantum physics.,"['self-learning', 'reference-request', 'mathematical-physics', 'soft-question', 'geometry']"
2632197,Real-valued functions on complex numbers,"Suppose $f$ is a real-valued function of a complex variable that is differentiable at every $z \in \mathbb{C}$. Show that $f'(z)=0$ for all $z \in \mathbb{C}.$ My approach: Since $f$ is a real-valued function of a complex variable that is differentiable at all $z \in \mathbb{C}$, we can write that: $$f'(z)=\lim_{\lambda\to0} \frac{f(z+\lambda)-f(z)}{\lambda}=
L$$ for some real function $L$. If this is true, then $f(z+\lambda) - f(z) = \lambda L + g(\lambda)$ such that $\lim_{\lambda\to0} \frac{g(\lambda)}{\lambda}=0$, where $g(\lambda)$ is a real valued function. However, if L is real, that implies $\lambda L$ is complex and arises from the subtraction of two real-valued functions. Since this is not possible, $\lambda L$ has to be real, which implies $L = 0$ or $L=c\bar{\lambda}$, where $c$ is some constant. But since L is real, L cannot be $\bar{\lambda}$. Hence, L has to be zero. This implies $f'(z) = 0$. Is this proof correct? If not, how should I correct it?",['complex-analysis']
2632225,Conditioning of the linear systems in the inverse or Rayleigh quotient iteration algorithms,"I'm working through the book Numerical Linear Algebra by Trefethen and Bau.  In Lecture 27 (and exercise 27.5), the following claim is made about the inverse iteration algorithm: Let $ A $ be a real, symmetric matrix.  Solving the system $ (A - \mu I) w = v^{(k-1)} $ at step $ k $ is poorly conditioned if $ \mu $ is approximately an eigenvalue of $ A $.  However, this does not cause an issue for the inverse iteration algorithm if it is solved with a backward stable algorithm which outputs $ \tilde{w} $ such that $ (A - \mu I + \delta M) \tilde{w} = v^{(k-1)}$ where $ \frac{\|\delta M\|}{\|M\|} = O(\epsilon_\text{machine}) $.  The reason is that even though $ w $ and $ \tilde{w} $ are not close, $ \frac{w}{\|w\|} $ and $ \frac{\tilde{w}}{\|\tilde{w}\|} $ are. The same issue occurs in the Rayleigh quotient iteration where at each step $ \mu $ is updated with a more accurate estimate of an eigenvalue of $ A $. I completely understand why the system is poorly conditioned when $ \mu $ is approximately an eigenvalue of $ A $.  I am attempting to prove the remainder of the claim or at least understand why it should be true.  Applying the definitions of backward stability and the condition of the problem don't lead anywhere beyond the usual bound for the accuracy: $ \frac{\|w - \tilde{w} \|}{\|w\|} = O(\kappa(A - \mu I) \epsilon_\text{machine}) = O(1) $ for $ \mu $ near an eigenvalue of $ A $.  I suspect that I need to use the fact that $ A $ is normal to move forward, but I don't see how. Any help is appreciated.  Thanks! Links to Wikipedia articles on 1. Inverse iteration 2. Rayleigh quotient iteration","['numerical-linear-algebra', 'linear-algebra', 'floating-point']"
2632234,A reference for ring examples,"I'm currently reading ""Introduction to Ring Theory"" by Paul Cohn https://www.amazon.com/Introduction-Theory-Springer-Undergraduate-Mathematics/dp/1852332069/ref=sr_1_3?ie=UTF8&qid=1517544148&sr=8-3&keywords=cohn+ring As I'm working through it, I'm realizing I'm really deficient in having examples of various properties at the ready, and it makes it hard to establish a mental picture of what's happening as I read - for instance, a theorem may have the hypotheses ""Let $R$ be a simple ring"" or ""Let $R$ be an Artinian ring"" - and I have difficulty conjuring examples to use as I try to understand what the theorem is saying. This is especially difficult because most of the rings that come to mind are fields or at least commutative, and these cases tend to trivialize many of the theorems in the book. How does one start building up a collection of rings with various properties to use as examples when those properties are invoked? Are there references that exist for this already? EDIT: I've decided to include some of my background - I'm an undergraduate student (nearly graduated) in math, with a relatively heavy algebra background - I've taken 4 semesters of algebra classes, two of which were at the graduate level. I'm familiar with introductory modern algebra, I'm just lacking in the ""canonical example of structure X with property P"" department.","['abstract-algebra', 'ring-theory', 'examples-counterexamples', 'reference-request']"
2632270,Almost Stirling's Approximation,"I need to prove the following bound $$n! \le e \sqrt n \left( \frac n e \right)^n$$ I can bound $\ln 1 + \ln 2 + \dots + \ln n$ as a Riemann sum with the function $\ln(n+1)$ and the trapezoidal rule: $$(\ln 1)/2 + \sum_{i=2}^n \ln i \ + (\ln(n+1))/2 < \int_0^n \ln (x+1) dx $$ Integrating I get the bound $$n! < \left( \frac{n+1}{e} \right)^n \sqrt{n+1}$$ As $n$ goes to infinity, my bound and the required bound get arbitrarily close (for $n=1$, the error is about $4\%$), but the one I need to prove is slightly tighter. How can I modify my bound to get the required bound?","['factorial', 'integration', 'upper-lower-bounds', 'approximation']"
2632333,how to compute the vector derivative of this matrix equation,"How to compute the derivative of the latent factor where $u_n$, $v_n$ are column vectors. How did he take derivative and obtain the below equation? I was reading probabilistic matrix factorization where I came across this equation. I don't know how to take vector derivative of another vector. To learn about vector derivatives in general can you point a source?","['multivariable-calculus', 'probability', 'calculus', 'vector-analysis']"
2632391,Partition the rationals with respect to a multivariate polynomial which sends classes to classes,"Let $R$ be a commutative ring and let $f\in R[x_1,x_2,\cdots,x_{n-1}],n\geq 2$ be a polynomial. Definition: We say $f$ is $n$-severable over $R$ if there exists a partition (of set) $$R=\coprod_{i=1}^n R_i,R_i\neq \varnothing$$
  such that for any sequence $\mathbf{a}=(a_{i_1},\cdots,a_{i_{n-1}}), a_{i_j}\in R_{i_j}$, $f(\mathbf{a})$ lies in $R_{i_n}$. Here $(i_1,\cdots,i_n)$ is a rearrangement of $(1,\cdots,n)$. Let me give a somewhat trivial example. Put $R=\Bbb{Z}$ and $n=2$, one can easily show that $f(x)=x+1$ is $2$-severable with partition $\Bbb{Z}=$ {odd numbers} $\cup$ {even numbers}. On the other hand, $f(x)=2x+1$ is not $2$-severable, since it possesses a fixed point $-1$. In general, one has following result, whose proof is straightforward. Claim: For any $R$ and $f\in R[x]$, $f$ is $2$-severable if and only if there is no periodic element in $R$ of odd period under the iteration $f$. To be honest, I haven't tried much beyond the above examples, and I feel that it is hopeless to obtain an explicit criterion for the severability of a general polynomial. So to narrow down the question, here is what I mainly interest in: Question: Is there any $n$-severable polynomial $f$ over $\Bbb{Q}$ with $n\geq3$? For the case $n=3$, I only calculated a few linear functions $f=ax_1+bx_2$ and didn't find any satisfied one yet. Also, for any $n\geq 2$, there is an $n$-severable polynomial $n(n-1)/2-(x_1+\cdots+x_{n-1})$ over $\Bbb{Z}/n\Bbb{Z}$, so it induces a collection of $n$-severable polynomials over $\Bbb{Z}$, but I've no idea whether any of them is severable over $\Bbb{Q}$. Any advise or guidance would be appreciated. Update: I also posted it on MO .","['number-theory', 'abstract-algebra', 'polynomials', 'dynamical-systems']"
2632395,Dimension of the Marsden-Weinstein reduction of a coadjoint orbit in the dual of the Lie algebra of the gauge group (Atiyah-Bott context),"Let $P\to \Sigma$ be a $\mathrm{SU}(2)$-principal bundle over a smooth orientable closed genus $g$ real surface $\Sigma$. Let $\mathcal{A}$ be the space of connexions over $P$ and let $\mathcal{G}$ be the gauge group. Let $\Omega^k:=\Omega^k(\Sigma;\mathrm{Ad}P)$ be the space of $\mathrm{Ad}P$-valued differential $k$-forms on $\Sigma$ (here $\mathrm{Ad}P=P\times_\mathrm{Ad}\mathfrak{su}(2)$ is the adjoint bundle). On $\mathcal{A}$ lives not only a pretty canonical symplectic form but also Atiyah-Bott's moment map
$$
F : \mathcal{A}\to \mathrm{Lie}(\mathcal{G})^* \; ; \quad A\mapsto F_A
$$
whose hamiltonian action is the $\mathcal{G}$ action on $\mathcal{A}$ acting by pull-backs. Here $F_A\in \Omega^2<\mathrm{Lie}(\mathcal{G})^*$ is $A$'s curvature form. The Marsden-Weinstein reduction
$$
\mathcal{M}^{\mathrm{fl}} := \mathcal{A}^{\mathrm{fl}}/\mathcal{G} = F^{-1}(0) \; /\!/ \; \mathcal{G}
$$
is the so-called moduli space of flat connections over $\Sigma$. It is a symplectic orbifold whose irreducible part is smooth. If $\Sigma$ has genus $g\geq 2$, this irreducible part has dimension $6g-6$. Consider now $\mathcal{O}\ne\{0\}$ be some coadjoint orbit inside $\mathrm{Lie}(\mathcal{G})^*$. Again, we can consider a Marsden-Weinstein reduction :
$$
\mathcal{M}^{\mathcal{O}} := F^{-1}(\mathcal{O}) \; /\!/ \; \mathcal{G}
$$ Question : What is the dimension of (the irreducible part of) $\mathcal{M}^{\mathcal{O}}$ ? Is it finite ? Remark 1 : If my calculations are right, for $A$ irreducible I think we have the isomorphism
$$
T_{[A]}\mathcal{M}^\mathcal{O}\cong\frac{\{\tau\in \Omega^1 | \mathrm{d}_A \tau\in \mathrm{im}(\mathrm{d}_A^2:\Omega^0\to\Omega^2)\}}{\mathrm{im}(\mathrm{d}_A:\Omega^0\to\Omega^1)}
$$
(if $A$ is flat we recover the usual $T_{[A]}\mathcal{M}^{\mathrm{fl}}$). So the dimension I'm looking for should correspond to the dimension of that space. I just don't know how to compute it. Remark 2 : According to the answer I got to this related question , the "" Remark 1 "" can be reformulated as :
$$
T_{[A]}\mathcal{M}^\mathcal{O}\cong \frac{\ker(\pi_A\circ\mathrm{d}_A|_{\Omega^1})}{\mathrm{im}(\mathrm{d}_A|_{\Omega^0})}
$$
where $\pi_A$ is this quotient projection :
$$
\pi_A : \Omega^2 \to \frac{\Omega^2}{\mathrm{im}(\mathrm{d}_A^2 : \Omega^0\to\Omega^2)}
$$ Remark 3 : By giving $\Sigma$ a Riemannian metric and considering $\delta_A:\Omega^k\to\Omega^{k-1}$ the $L^2$-adjoint operator of $\mathrm{d}_A$ (i.e. the covariant coderivative) and the Laplacian $\Delta_A:=\mathrm{d}_A\delta_A+\delta_A \mathrm{d}_A:\Omega^k\to\Omega^k$, I also get that :
$$
\ker(\Delta_A|_{\Omega^1}) < T_{[A]}\mathcal{M}^\mathcal{O}
$$
But I'm not sure how ""bigger"" is $T_{[A]}\mathcal{M}^\mathcal{O}$ compared to the space $\ker(\Delta_A|_{\Omega^1})$ of harmonic $\mathrm{Ad}P$-valued differential 1-forms. Remark 4 : the projection $\pi_A$ can be reformulated as
$$
\pi_A : \Omega^2 \to \ker(\delta_A^2:\Omega^2\to \Omega^0)
$$ 2018-02-16 update : meanwhile I found that $T_{[A]}\mathcal{M}^{\mathcal{O}}_\Sigma \cong \ker(\Delta_{A}|_{\Omega^1})$. Now, my question becomes : for $A$ irreducible, does the dimension of $\ker(\Delta_{A}|_{\Omega^1})$ change if one takes a non-flat connection $A$ instead of a flat one ?","['symplectic-geometry', 'gauge-theory', 'differential-geometry']"
2632400,A limit that involves two variables,"I'm trying to compute this limit $\lim_{(x,y) \to (0,0)}2x\sin^2(\frac{1}{y})$, but WolframAlpha says that it does not exist. I'm not quite sure why. I do understand that there are oscillations coming from the $\sin(1/y)$. However, $x \to 0$ as well. Shouldn't that crush the function to zero? Also, I know that $\lim_{x \to 0} x \sin(\frac{1}{x}) = 0$. Isn't that pretty much the same idea as the limit in question?",['limits']
2632426,Showing that the composition of maps of constant rank does not have to be of constant rank,This is an exercise from p.79 of John Lee's Introduction to Smooth Manifolds. I am trying to search the smooth maps of the Euclidean space but cannot find a counterexample... Could anyone please suggest me one?,"['manifolds', 'examples-counterexamples', 'smooth-manifolds', 'differential-geometry']"
2632453,Infinite series with harmonic numbers related to elliptic integrals,"It is known that the following functions are elliptic integrals $$
\, _2F_1\left({a,1-a\atop 1};x\right),\quad a=\tfrac12,\tfrac13,\tfrac14,\tfrac16,\tag{1}
$$ $$
\, _2F_1\left({\tfrac{1}{3},\tfrac{2}{3}\atop \tfrac{4}{3}};x\right),\, _2F_1\left({\tfrac{1}{2},b\atop b+1};x\right),\quad b=\tfrac14,\tfrac16.\tag{2}
$$ It was proved in the arxiv preprint by Martin Nicholson that the generating function $$
\sum_{n=1}^\infty \frac{(a)_n(1-a)_n}{(n!)^2}H_nx^n,\quad a=\tfrac12,\tfrac13,\tfrac14,\tfrac16\tag{3}
$$ has closed form in terms of elliptic integrals $(1)$ [here $H_n$ is $n$ -th Harmonic number] . The formulas for $a=\tfrac12$ can be found in this question . However no similar series with harmonic numbers are known for $(2)$ . Now consider the series of Kummer's and Pfaff's transformations of hypergeometric function $$
\, _2F_1\left({\tfrac{1}{2},b\atop b+1};4 x (1-x)\right)=\, _2F_1\left({1,2b\atop b+1};x\right)=\frac{1}{1-x}\, _2F_1\left({1,1-b\atop b+1};\frac{x}{1-x}\right).
$$ We see that the series $$
\, _2F_1\left({1,\tfrac34\atop \tfrac54};x\right)=\sum_{n=0}^\infty\frac{(\tfrac34)_n}{(\tfrac54)_n}x^n
$$ is related to elliptic integral $(2)$ with $b=\tfrac14$ . It follows from Theorem $4$ of the preprint mentioned above that there is the following strange evaluation of a sum with harmonic numbers \begin{equation}
\sum_{n=1}^\infty\frac{(\tfrac34)_n}{(\tfrac54)_n}\frac{\tfrac14-(-1)^n}{2n+1}H_n=\frac{\Gamma^4(\tfrac14)}{64\pi}\ln 2.\tag{4}
\end{equation} We see that two series with different 'arguments' $x=1$ and $x=-1$ conspire to have a closed from. However attempts to find closed form for each sum $$
\sum_{n=1}^\infty\frac{(\tfrac34)_n}{(\tfrac54)_n}\frac{H_n}{2n+1},~\sum_{n=1}^\infty\frac{(\tfrac34)_n}{(\tfrac54)_n}\frac{(-1)^nH_n}{2n+1}\tag{5}
$$ separately, including the method outlined in the preprint, was not successful so far. Q1: Do the series $(5)$ have closed form? Q2: Does the series $$
\sum_{n=1}^\infty\frac{(\tfrac34)_n}{(\tfrac54)_n}\frac{H_n}{2n+1}\left(2(-x)^n-\frac{(4x)^n}{(1+x)^{2n+1}}\right)\tag{6}
$$ have closed form for all $~|x|\le 1$ ? Of course $(6)$ is not a generating function, but at least the sum with $x=1$ in $(6)$ can be calculated according to $(4)$ .","['generating-functions', 'elliptic-integrals', 'special-functions', 'harmonic-numbers', 'sequences-and-series']"
2632487,An integral inequality (one variable),"Anyone has an idea to prove the following inequality? Let $g:\left(0,1\right)\rightarrow\mathbb{R}$ be twice differentiable
and $r\in\left(0,1\right)$ such that 
$$
r\left(g""\left(x\right)+\dfrac{g'\left(x\right)}{x}\right)\geq\left(g'\left(x\right)\right)^{2},\forall x\in\left(0,1\right).
$$
Prove that 
$$
\left(\intop_{0}^{1}e^{-g\left(x\right)}xdx\right)\left(\intop_{0}^{1}e^{g\left(x\right)}xdx\right)\leq\dfrac{1}{4\left(1-r\right)},\quad\quad {(\star)}
$$
provided the LHS is finite. Further comment: This inequality comes from a contest for undergraduate students in my university. If we take the function 
$$
g\left(x\right)=-r\ln\left(-\ln\left(x\right)\right)
$$
 then we have 
$$
r\left(g""\left(x\right)+\dfrac{g'\left(x\right)}{x}\right)=\left(g'\left(x\right)\right)^{2},\forall x\in\left(0,1\right).
$$
By using Mathematica, we can see that for this function
$$
\left(\intop_{0}^{1}e^{-g\left(x\right)}xdx\right)\left(\intop_{0}^{1}e^{g\left(x\right)}xdx\right)=\dfrac{1}{4}\Gamma\left(1-r\right)\Gamma\left(1+r\right).
$$
Moreover, we also can check that 
$$
\dfrac{1}{4}\Gamma\left(1-r\right)\Gamma\left(1+r\right)\leq\dfrac{1}{4\left(1-r\right)},\forall r\in\left(0,1\right).
$$","['real-analysis', 'inequality', 'integral-inequality']"
2632501,"For any countable ordinal $\alpha$, there is some closed set of reals whose Cantor-Bendixson rank is $\alpha$","I want to prove that for any countable ordinal $\alpha$, there is some closed set $C\subset \mathbb R$ such that the Cantor-Bendixson rank of $C$ is $\alpha$. I have not been able to create a successful construction and am out of ideas right now, but I still believe this should be true. Could anybody give a proof (or counterexample)?","['descriptive-set-theory', 'general-topology', 'set-theory', 'ordinals']"
2632512,A confusion about the definition of Jordan measurable set,"In the book of Mathematical Anaylsis II by Zorich, at page 122, it is given that Definition: A set E is Jordan-measurable if it is bounded and its
  boundary has Jordan measure zero. Remark: As Remark 2 shows, the class of Jordan-measurable subsets is precisely
  the class of admissible sets introduced in Definition 1. However, in order for Jordan measure to be defined on a set $E$, we only need its boundary to be Lebesgue measure zero, not Jordan measure zero, so I'm little confused about the definition. To clarify, if a set is admissible, by definition of Jordan measure, we can define the Jordan measure of that set. Similarly, if $E$ is bounded and its boundary is Lebesgue measure zero, by definition, $E$ is admissible, so I do not understand behind the motivation for using Jordan measure zero instead of Lebesgue measure zero in the definition of Jordan measurable sets.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2632517,To what value does the following series converge to? [duplicate],"This question already has answers here : Sum of $1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{6}+\frac{1}{8}+\frac{1}{9}+\frac{1}{12}+\cdots$ [duplicate] (3 answers) Closed 6 years ago . I am asked to sum the series
$$1+\frac1{2}+\frac1{3}+\frac1{4}+\frac1{6}+\frac1{8}+\frac1{9}+\frac1{12}+\cdots$$
where the terms are the reciprocals of all positive integers whose only prime factors are two and threes.
What I tried so far is: $$\frac1{2^03^0}+\frac1{2^13^0}+\frac1{2^03^1}+\frac1{2^23^0}+\frac1{2^13^1}+\frac1{2^33^0}+\frac1{2^03^2}+\frac1{2^23^1}+\cdot\cdot\cdot$$
The equence is in the form: $$\frac1{2^n3^m}$$
but what do I do know? I am stuck!","['convergence-divergence', 'sequences-and-series', 'calculus']"
2632563,Improper integral related to Gamma function,"I found the following integral which seems an extension of the gamma function $$
\int_{0}^{\infty}\left[1 -
\mathrm{e}^{-\left(\large ux^{a} + vx^{b}\right)}\right]
x^{-1 - c}\,\mathrm{d}x,
$$ where $u,v,a,b,c$ are all positive constant such that $c \in \left(0,1\right)$ and $a > b > c$ . In the case of $v = 0$ , I evaluated the integral thanks to the change of variable $y = x^{a}$ in terms of the Gamma function, but, when both $u$ and $v$ are strictly positive, I can not make the exponent linear in $x$ when $a \ne b$ . I also try to use the series representation of $1 - \mathrm{e}^{-\left(ux^{a} + vx^{b}\right)}$ but it does not work. Do you have any suggestions or know some noteworthy extensions of the Gamma function that can help me? Thanks a lot! P.S.
I'm new to ""mathematics"", so I also appreciate suggestions on how to ask questions effectively here :)","['special-functions', 'integration', 'gamma-function', 'calculus']"
2632611,Calculate floor of $\frac{1}{x_1 + 1} + \frac{1}{x_2 + 1} + ... + \frac{1}{x_{100} + 1}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question There is a recurrence sequence $x_1 = \frac{1}{2}$, $x_{n+1} = x_n^2 + x_n$. How much is floor of $\frac{1}{x_1 + 1} + \frac{1}{x_2 + 1} + ... + \frac{1}{x_{100} + 1}$? Floor is an integer part of a real number.","['number-theory', 'recurrence-relations', 'ceiling-and-floor-functions']"
2632633,How to prove $\tan\Big[\frac{1}{2}\sin^{-1}\frac{3}{4}\Big]=\frac{4-\sqrt{7}}{3}$,"Prove $$
\tan\Big[\frac{1}{2}\sin^{-1}\frac{3}{4}\Big]=\frac{4-\sqrt{7}}{3}
$$
  and justify why $\frac{4+\sqrt{7}}{3}$ is ignored. My Attempt: $$
\tan x=\frac{2\tan\frac{x}{2}}{1-\tan^2\frac{x}{2}}\implies\tan x-\tan x\tan^2\frac{x}{2}=2\tan\frac{x}{2}\\
\implies \tan^2\frac{x}{2}(\tan x)+2\tan\frac{x}{2}-\tan x=0\\
\implies \tan\frac{x}{2}=\frac{-2\pm2\sec x}{2\tan x}=\frac{-1\pm\sec x}{\tan x}
$$
Using this,
$$
\tan\bigg[\frac{\sin^{-1}\frac{3}{4}}{2}\bigg]=\frac{-1\pm\frac{4}{\sqrt{7}}}{\frac{3}{\sqrt{7}}}=\frac{-\sqrt{7}\pm4}{3}
$$
As $0\leq\frac{\sin^{-1}3/4}{2}\leq\frac{\pi}{4}\implies0\leq\tan(\frac{\sin^{-1}3/4}{2})\leq1$
$$
\implies \tan\bigg[\frac{\sin^{-1}\frac{3}{4}}{2}\bigg]=\frac{-\sqrt{7}+4}{3}
$$
Is my attempt correct and where is the value $\frac{4+\sqrt{7}}{3}$ to be excluded ?","['trigonometry', 'inverse-function']"
2632653,"In GAP, How can I check whether a given group is a direct product?","I'm working with GAP and I want to make some check through all small group up to given size. For direct product groups the result is depend on the groups it composed of, so I don't want to waste time on such groups. Is there a built-in option to check whether a group is a (not trivial) direct product?","['direct-product', 'group-theory', 'gap']"
2632668,Is this $\binom{n}{p}$ for $p>n$ make a sense in mathematics or it is $0$ by convention?,"It is well known that gamma function is not defined at negative integers , but my question is to know how i take the value of   $\binom{n}{p}$ for  $p>n$ then is this  make a sense or it is  $0$ by convention ?","['binomial-coefficients', 'probability', 'convention', 'definition']"
2632733,Show that $1439^2 | \sum_{k=1}^{1439}k^{1439}$,"I couldn't show that
$1439^2 | \sum_{k=1}^{1439}k^{1439}$
But i showed that $1439 | \sum_{k=1}^{1439}k^{1439}$ maybe it can help. We can easily prove that 1439 is a prime number . According to Fermat's little theorem : $k^{1439}\equiv k\pmod{1439}$ Then , $\sum_{k=1}^{1439}k^{1439}\equiv \sum_{k=1}^{1439}k\pmod{1439}$ And it is commonly known that $\sum_{k=1}^{1439}k=\frac{1439\cdot 1440}{2}$ We can deduce that $\sum_{k=1}^{1439}k^{1439}\equiv 0 \pmod{1439}$ I hope so gonna help me out !","['number-theory', 'prime-numbers', 'modular-arithmetic']"
2632761,Proof verification: why this formula holds?,"For $A= (A_1,\cdots,A_d)\in {\cal L}(E)^d$  such that $A_iA_j=A_jA_i$ for all $i,j$. Why
  $$\sum_{f\in F(n,d)} A_{f}^*LA_{f}=\displaystyle\sum_{|\alpha|=n}\frac{n!}{\alpha!}{A^*}^{\alpha}LA^{\alpha},\,\;\forall\, L\in\mathcal{L}(E)?$$
  Note that $F(n,d)$ denotes the set of all functions from $\{1,\cdots,n\}$ into  $\{1,\cdots,d\}$ and $A_f:=A_{f(1)}\cdots A_{f(n)}$, for $f\in F(n,d)$. Also $\alpha = (\alpha_1, \alpha_2,...,\alpha_d) \in \mathbb{Z}_+^d;\;\alpha!: =\alpha_1!\cdots\alpha_d!,\;|\alpha|:=\displaystyle\sum_{j=1}^d|\alpha_j|$; $A^*=(A_1^*,\cdots,A_d^*)$ and $A^\alpha:=A_1^{\alpha_1} A_2^{\alpha_2}\cdots A_d^{\alpha_d}$. I'm facing dificulties to understand the following proof: Proof $$\sum_{f\in F(n,d)} A_{f}^*LA_{f}=\displaystyle\sum_{|\alpha|=n}{n\choose \alpha}\ {A^*}^{\alpha}LA^{\alpha}\ .$$
It is just an instance of the expansion of the $n$-power of the sum of  $d$ commuting objects in a ring, $$(X_1+\dots X_d)^n=\sum_{\alpha\in\mathbb{N}^d\atop |a|=n} {n\choose \alpha}X^\alpha, $$ with $X:=X_1^{\alpha_1}X_2^{\alpha_2}\dots X_d^{\alpha_d}.$
So  if $X_j$ is the linear operator on $\mathcal{L}(H)$ defined by $L\mapsto A_j^*LA_j$ , we get the  desired  formula.","['functional-analysis', 'multinomial-coefficients', 'proof-verification']"
2632771,Calculate domain $f(x)=x^{\frac{x+1}{x+2}}$,"I have the following function:
$$f(x)=x^{\frac{x+1}{x+2}}$$
I tried to calculate the domain, which seems easy, and my result is: $D(f)=(0,\infty)$. When I tried to calculate it, by using Wolfram-Alpha, I obtain: $D(f)=[0,\infty)$. Can someone explain me the reason, or if it is just a Wolfram's error? I proceed in this way:
$$f(x)=x^{\frac{x+1}{x+2}} = e^{\frac{x+1}{x+2} \log(x)}$$
$$
\left\{ 
\begin{array}{c}
x+2\ne0 \ \Rightarrow\ x\ne -2 \\ 
x>0
\end{array}
\right. 
$$
Hence: $D(f)=(0,\infty)$.","['wolfram-alpha', 'exponential-function', 'calculus', 'functions', 'functional-analysis']"
2632818,Help with basic inequality (complex numbers),"I want to prove \begin{align}
\lvert z\rvert &\geq \Re\{z\} \tag{1}\\
\lvert z\rvert &\geq \Im\{z\} \tag{2}
\end{align} I start with $z=x+iy$ so 
$$
\lvert z\rvert=\sqrt{x^2+y^2}\tag{3}
$$ With the following (I guess it's valid for complex numbers?)
$$
\lvert z\rvert =\sqrt{z^2} \iff \lvert z\rvert^2 =z^2 \tag{4}
$$ I can write 
\begin{gather}
\lvert z\rvert^2=x^2+y^2 \tag{5}
\end{gather} Using
\begin{gather}
\Re\{z\}=x \iff \Re\{z\}^2=x^2 \tag{6}
\\
\Im\{z\}=y \iff \Im\{z\}^2=y^2 \tag{7}
\end{gather}
I can now write
\begin{gather}
\lvert z \rvert ^2=\Re\{z\}^2 +\Im\{z\}^2 \tag{8}
\end{gather} I'm stuck here. What is the next step? Or should I stop here and conclude something from $(8)$? Thanks! Update: I not sure, but shouldn't we have absolute values in $(1)$ and $(2)$, i.e. $\lvert z\rvert \geq \lvert \Re\{z\}\rvert$
and $\lvert z\rvert \geq \lvert\Im\{z\}\rvert$?","['algebra-precalculus', 'complex-analysis', 'complex-numbers', 'proof-verification']"
2632843,Expectation on the number of geometric variables needed for their sum to exceed a threshold,"Let $X_1, X_2, \ldots,$ be a series of independent random variables such that $X_i\sim Geo(p_i)$, and let $T\in\mathbb N$ be a constant positive integer. Next, define $N\triangleq \min\{{n\in\mathbb N}\mid \sum\limits_{i=1}^nX_i\ge T\}$. How can we find $\mathbb E[N]$? (An upper bound would also work). This seems like a somewhat inverse version of the general version of Wald's equation . Intuitively, I'd like to say that $\mathbb E[N]\approx\min\{{n\in\mathbb N}\mid \sum\limits_{i=1}^n \mathbb E[X_i]\ge T\} = \min\{{n\in\mathbb N}\mid \sum\limits_{i=1}^n 1/p_i \ge T\}$, but I'm looking for a formal argument. If this helps, we can assume that $0.01\ge p_1\ge p_2\ge p_3\ge\ldots$ In his answer, Ian gave a solution that handles two extreme cases - one where $\min\{{n\in\mathbb N}\mid \sum\limits_{i=1}^n 1/p_i \ge T\} = \Theta(T)$ and one where the $p_i$'s decrease exponentially and we can just look for the $i$ such that $p_i^{-1}\approx T$ as a good approximation. However, this approach doesn't seem to work well for what I think are the interesting cases. As we have $p=\prod_{i=1}^d(1-p_i)^{x_i-1}\le \prod_{i=1}^d(1-p_d)^{x_i-1}=(1-p_d)^{T-d}$, this fails in the following example.
If we have $p_i = \Theta(1/i)$, then Ian's approach would give an a bound of $\mathbb E[N]\le T/\log T$ (after optimizing $d$), while we can expect $N$ to be of the order of $\sqrt T$. This is a near quadratic gap that this method cannot address.","['expectation', 'random', 'probability-distributions', 'probability', 'random-variables']"
2632884,Alternate proof for Viète's infinite product of nested radicals [duplicate],This question already has answers here : Calculate $\sqrt{\frac{1}{2}} \times \sqrt{\frac{1}{2} + \frac{1}{2}\sqrt{\frac{1}{2}}} \times \ldots $ (2 answers) Closed 2 years ago . I am looking for alternate proof for Viete's infinite product of nested radicals. ( Reference - Wikipedia ) Basically we need to find $\lim_{n\to \infty}\prod_{k=1}^{n} T_k$ where $$T_{k+1} = \sqrt{\left(\frac{T_k + 1}{2}\right)}$$ and $T_1 = \sqrt{\frac{1}{2}}$. Series looks like $$\sqrt{\frac{1}{2}} \cdot \sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{\frac{1}{2}}} \cdot \sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{\frac{1}{2}}}}...$$ Miss gave a solution treating $\cos(\theta) = \frac{1}{\sqrt2}$ that is $\theta = 45^\circ$. The series result is given easily using the identity $\cos(\theta) + 1 = 2 \cos^2(\theta/2)$ and using $\sin(2\theta) = 2\sin(\theta)\cos(\theta)$. The final result is $\frac{\sin(2\theta)}{2\theta} = \frac{2}{\pi}$. I look for alternate ways to get to this! I am open to calculus methods.,"['infinite-product', 'limits', 'calculus', 'nested-radicals', 'sequences-and-series']"
2632922,Point in triangle,"Inside a random triangle, consider a point P and its distances PM, PN and PQ to the 3 sides a, b and c. 
For which location of the point P the below sum gets minimal?
$$\frac{a}{PM} + \frac{b}{PN} + \frac{c}{PQ}$$ I think it is the incenter but how do we prove it?",['geometry']
2632935,"Given $\triangle ABC$ with $\angle C = 60^\circ$, show $a^2+b^2-ab=c^2$ without trigonometry","I have the following problem: In $\triangle ABC$, the angle at vertex $C$ is $60^{\circ}$. Prove that $a^2+b^2-ab=c^2$. Of course, it is easy if you use cosine rule. I believe there exists a beautiful proof as well without using trigonometry. Anyone?","['euclidean-geometry', 'triangles', 'geometry']"
2633020,Finding the center of function in general,"Let $f(x)$ be a function . How we can find the center of $f(x)$ (i.e. center of symmetry ) if it exist ? (And also prove it doesn't have center . ) For example consider $\log_{10} \frac{x-2}{x-1}$ . If we graph the function , it seems $\omega(1.5 , 0)$ is the center but I don't know how to show it .","['algebra-precalculus', 'symmetry', 'functions']"
2633026,How to tell if this integral converges?,"$$\int_{0}^{\infty} \frac{\sqrt{1-x+x^2}}{1-x^2+x^4} dx$$ What's the method for determining if this integral converges or diverges? The integral seems to converge if I put it into Wolfram Alpha. But do we assume it's similar to $$\int_{0}^{\infty} \frac{1}{x^4} dx$$ Because if so I can't get that one to converge since it's $-\frac{1}{3x^3}$ where $x=\infty$ and $x=0$ (I don't know how to write the ""right bar"" notation for integrals) which goes to $-0 + \infty$ which is divergent. So I am not sure what is right.","['improper-integrals', 'integration', 'convergence-divergence', 'calculus']"
2633058,Differential equation $y''=y^2$ [duplicate],"This question already has answers here : Solve $y''=y^2$ (5 answers) Closed 4 months ago . I must solve the differential equation $y''=y^2$. Clearly, the function $y=0$ is a solution. So, assume that $y$ is not identically zero. Unless I'm not mistaken, there is a trick to solve equations of this kind. If I multiply for $2y'$, the left-hand member is $2y'y''$, that is the derivative of $(y')^2$, while the right-hand member is $2y^2 y'$. At this point, how can I continue this exercise?",['ordinary-differential-equations']
2633073,What is the difference between a log of a price and a log of two prices?,"So I  understand that to calculate the continuously compounded return between 2 prices, all you have to do is log the fraction of the 2 prices.  For example: log(price1/price2) What I don't get is how come if you take a log of just one price, it gives you a return or percent change as well?  I don't know how the interpret the 2. I am confused because let's say I am working with the CAPM model, which is: (Excess Stock Return) = Beta0 + Beta1 * (Excess Market Return) and am given a series of 100 stock prices and want to regress it against the market returns so I can get the Betas.  To get the stock returns, I would take the log(price1/price2) and end up with 99 observations.  Cool everything makes sense so far. Now let's say I had two vectors of data, which are price and sales of a product.  If I want the elasticity of sales with respect to price, that is, if I want to calculate how much a 1% change in price would affect a ?% change in sales, I would do the log-log regression, i.e. take the log of both price and sales and do a regression.  My Beta1 would be the elasticity. Let's say I have 100 observations of price and 100 observations of sales and I take the log of vectors.  I still end up with 100 observations of each. I don't get how log(price1) and log(price1/price2) both give me a return or % change?  What's the difference between these 2?  I get that that log(price1/price2) tells me the continuously compounded return going from price 2 to price 1.  So log(3/2) = .405 means that the continuously compounded return is 40.5%.  So what does log(price1) tell me aka just log(3) ?","['regression', 'logarithms', 'calculus', 'statistics', 'finance']"
2633081,Evaluating $\lim_{x\to0}\frac{x\sin{(\sin{x})}-\sin^2{x}}{x^6}$ [duplicate],"This question already has answers here : A limit problem $\lim\limits_{x \to 0}\frac{x\sin(\sin x) - \sin^{2}x}{x^{6}}$ (7 answers) Closed 6 years ago . Evaluate:
  $$\lim_{x\to0}\frac{x\sin{(\sin{x})}-\sin^2{x}}{x^6}$$ I have been trying to solve this for $15$ minutes but sin(sin(x)) part has me stuck. My attempt: I tried multiplying with $x$ inside the $\sin$ as $\sin{(\frac{x\sin{x}}{x})}$. No leads.","['taylor-expansion', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2633087,Condition for a function $\widetilde \phi:\mathbb{H}\rightarrow \mathbb{H}$ to descend to $S_g$,"Let $S_g$ be a closed and oriented surface of genus $g\ge 2$ and fix any universal cover $\pi:\mathbb{H}\rightarrow S_g$. The group $\pi_1(X)$ acts on $\mathbb{H}$ through the monodromy action. 
Given $\widetilde x\in \mathbb{H}$ and $[\gamma]\in \pi_1(X)$ then $[\gamma]\cdot \widetilde x=\widetilde \gamma(1)\in \mathbb{H}$: one first considers any representative $\gamma$ of $[\gamma]$ with base point in $\pi(\widetilde x)$, then $\widetilde \gamma$ is the lifting of $\gamma$ to $\mathbb{H}$ such that $\widetilde \gamma(0)=\widetilde x$. I am trying to completely understand universal covers, liftings and homotopy, so I would like to know if my following statements are true: It is my understanding that any continuous function $\widetilde \phi:\mathbb{H}\rightarrow \mathbb{H}$ descends to a function $ \phi:S_g\rightarrow S_g$ if there is an endomorphism $\phi_*:\pi_1(X)\rightarrow \pi_1(X)$ such that it results $\widetilde\phi([\gamma]\cdot x)=\phi_*([\gamma])\cdot \widetilde\phi(x)$. Then $\phi_*$ is the map induced by $\phi$ on $\pi_1(X)$. In particular any continuous function $\widetilde f:\mathbb{H}\rightarrow \mathbb{H}$ such that $\widetilde f([\gamma]\cdot x)=[\gamma]\cdot \widetilde f(x)$ for every $x\in \mathbb{H}$ and $[\gamma]\in \pi_1(X)$ descends to a function $f:S_g\rightarrow S_g$ such that $f_*=Id$. This is my proof: given any continuous function $\psi:S_g\rightarrow S_g$ one has the following commuting diagram
$$\begin{array}
$\mathbb{H} & \stackrel{\widetilde \psi}{\longrightarrow} & \mathbb{H}\\
\downarrow{\pi} & & \downarrow{\pi} \\
S_g & \stackrel{\psi}{\longrightarrow} & S_g  
\end{array}
$$
and consequently one has $\psi(\gamma)=\pi(\widetilde \psi(\widetilde \gamma))$ (where as before $\widetilde \gamma$ is the lifting such that $\widetilde \gamma(0)=\widetilde x$). This implies 
$$\widetilde{\psi(\gamma)}(1)=\widetilde \psi(\widetilde \gamma(1))$$
where $\widetilde{\psi(\gamma)}$ is the lifting of $\psi(\gamma)$ such that $\widetilde{\psi(\gamma)}(0)=\widetilde \psi(\widetilde x)$. Finally, one notes $\widetilde \psi(\widetilde \gamma(1))=\widetilde \psi(\gamma\cdot \widetilde x)$ and $\widetilde{\psi(\gamma)}(1)=[\psi(\gamma)]\cdot \widetilde \psi(\widetilde x)=\psi_*[(\gamma)]\cdot \widetilde \psi(\widetilde x)$. Consequently, any continuous function $\widetilde \phi:\mathbb{H}\rightarrow \mathbb{H}$ with such property will descend to $S_g$. Is my reasoning correct? If not, which additional conditions must a continuous function $\widetilde \phi:\mathbb{H}\rightarrow \mathbb{H}$ satisfy in order to descend to a function $\phi:S_g\rightarrow S_g$? And in particular to a function such that $\phi_*=Id$?","['algebraic-topology', 'general-topology', 'proof-verification']"
2633150,"Set theory: how is $\left\lbrace 1, 1 \right\rbrace$ different from $\left\lbrace 1 \right\rbrace$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What set theory differentiate  sets: $\left\lbrace 1, 1 \right\rbrace$ from $\left\lbrace  1 \right\rbrace$; order does not matter? Thank you in advance. Addition/clarification: Thank you very much, everybody, for the providing idea of multi sets - I have found few papers and I hope it will be useful. I am from microscopy/Imaging field without formal mathematical education, and I try to find the most basic mathematical object which can represent image. I was thinking that set would be the most basic/universal. It works well for just one measurement (or pixel), e.g. {1}; if we have two measurements (pixels), we can have two identical values {1, 1} from set of rational numbers. In classical set theory, it immediately collapses to {1}, so I lose my information. Practically it can happen if I measure number of photons from fixed point inside my object (cell) and I do not care about order of the measurements. The idea of set is quite attractive as I can embed it in other sets, form universes, etc. On other side, I feel that image always requires some sort of order - except from the very basic measurements I have mentioned before. It can be ordered pair of set of rational numbers and structures, e.g. Cumulative hierarchy which represent pixels (or measurements) and order of the image. I am not sure how easy I can work with them. Meanwhile I appreciate all your answers, comments and suggestions.",['elementary-set-theory']
2633183,Putnam 2016 Question A5 Finite Group Theory,"I was looking at the Putnam 2016 competition and saw question A5, as stated: Suppose that $G$ is a finite group generated by the two elements $g$ and $h$, where the order of $g$ is odd. Show that every element of G can be written in the form $g^{m_1}h^{n_1}g^{m_2}h^{n_2}...g^{m_r}h^{n_r}$ with $1\le{r}\le{|G|}$ and $m_1,n_1,m_2,n_2,...,m_r,n_r\in{(-1,1)}$. Now I can prove the existence that every element of G can be written in this form however I struggle with showing that $1\le{r}\le{|G|}$. Following the Putnam solution on http://kskedlaya.org/putnam-archive/2016s.pdf I can follow the whole proof, apart from the part 'since $r>|G|$ by hypothesis, by the pigeonhole principle there must exist indices $0\le{i}<j\le{r-1}$ such that $s_i=s_j$.' I don't understand how the logic follows from the pigeonhole principle and would be very grateful to anyone who could show me why. Thank you","['finite-groups', 'contest-math', 'combinatorial-group-theory', 'group-theory']"
2633217,"Is there a ""standard"" name for $n \times n$-matrices whose square is $-1$ times the identity matrix?","I have seen the name “skew involution” in a problem in at least one book but none of my colleagues who work in abstract algebra, geometry or linear algebra have ever heard of this name, although they agree it is a reasonable name.  I have used the term “imaginary unit” for such matrices and my colleagues agree that is also a reasonable name, but I wonder if there is a standard name in the literature.","['matrices', 'linear-algebra', 'algebraic-geometry', 'geometry']"
2633273,What's the expected number of times I have to roll two die until they both sum $7$?,"Here is my guess: the probability of summing $7$ on two rolls is $\frac 16$. This means if I repeat the experiment many times I'll roll $7$ one sixth of them (approximately). Hence, $$N \cdot \bigg(\cfrac 16\bigg) \cdot 7 = 7$$ where $N$ is the total number of rolls. That gives me a total number of $6$ rolls on average to sum $7$. I'm not quite sure so I'm all open to suggestions! Thanks in advance.","['expectation', 'probability', 'dice']"
2633277,Characterization of solutions to $f' = f(1-f)$,"The sigmoid function $f(x) = \frac{1}{1+e^{-x}}$ has the property that $$f'(x) = f(x)(1-f(x))~~~ and ~~~f(0) = \frac 12$$ My question: is $f$ the unique function from $\mathbb R$ to $(0,1)$, perhaps up to some kind of scaling, that satisfies $f' = f(1-f)$? I don't have much experience with differential equations so a nonlinear one like this is beyond anything I've done before. In case it helps, my motivation for this is that this property makes the log likelihood a lot easier in a logistic regression, and I'm wondering if assuming that the inverse link function satisfies this property is equivalent to just taking it to be $f$.","['real-analysis', 'ordinary-differential-equations']"
2633286,Exponentiation of a symmetric $2 \times 2$ matrix,Why does the following hold? $$\left[\begin{matrix}a & b\\b & a\end{matrix}\right]^k=\frac{1}{2}\left[\begin{matrix}\left(a - b\right)^{k} + \left(a + b\right)^{k} & - \left(a - b\right)^{k} + \left(a + b\right)^{k}\\- \left(a - b\right)^{k} + \left(a + b\right)^{k} & \left(a - b\right)^{k} + \left(a + b\right)^{k}\end{matrix}\right]$$,"['matrices', 'symmetric-matrices', 'exponentiation']"
2633456,Given is markov chain - Determine the probability $f_1(n)$,"Given is markov chain $\left\{X_n\right\}_{n \in \mathbb{N}}$ with
  transition probabilities $$M= \begin{pmatrix} 
1/2   &   1/2   &   0   &   0   &   0   &   0   \\  
1/4   &   3/4   &   0   &   0   &   0   &   0   \\  
1/4   &   1/4   &   1/4 &   1/4 &   0   &   0   \\  
1/4   &     0   &   1/4 &   1/4 &   0   &   1/4 \\  
0     &     0   &   0   &   0   &   1/2 &   1/2 \\ 
0     &     0   &   0   &   0   &   1/2 &   1/2 
\end{pmatrix}$$ Determine the probability $f_1(n)$ where you return to state $1$ after
  $n$ steps  (for the first time). I'm not sure how you can solve this because if I understood it correctly, we have $n$ steps and we are looking for a probability, so we have two unknowns... Anyway, I think the correct way of calculating it is (don't miss the little exponent $n$ of that huge matrix!) $$f_1(n) = \begin{pmatrix} 
1/2   &   1/2   &   0   &   0   &   0   &   0   \\  
1/4   &   3/4   &   0   &   0   &   0   &   0   \\  
1/4   &   1/4   &   1/4 &   1/4 &   0   &   0   \\  
1/4   &     0   &   1/4 &   1/4 &   0   &   1/4 \\  
0     &     0   &   0   &   0   &   1/2 &   1/2 \\ 
0     &     0   &   0   &   0   &   1/2 &   1/2 
\end{pmatrix}^n \cdot 
\begin{pmatrix}
1\\ 
0\\ 
0\\ 
0\\ 
0\\
0
\end{pmatrix}$$ Here I'm stuck again for the same reason, I see no way of calculating the probability...? : /","['matrices', 'probability-theory', 'markov-chains', 'statistics', 'probability']"
2633470,Unbiased estimator in Laplace distribution [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $X\sim f_X(x\mid\theta)=\frac{1}{2\theta}e^{-|x|/\theta}$, $x\in\mathbb{R}$, and $\theta>0,$ find an unbiased estimator of $(1+\theta)^{-1}$ of least variation. I have tried using the fact that $|X|\sim \exp(1/\theta)$ and so $T=\sum_{i=1}^n |X_i| \sim \operatorname{gamma}(n,1/\theta)$ . I calculate that $E[1/T]=\frac{1}{(n-1)\theta}$ but I can't calculate something like $E[1/(1+T)]$.","['statistics', 'parameter-estimation']"
2633549,How to view 'dx' in an Integral? [duplicate],"This question already has answers here : What does $dx$ mean? (6 answers) Closed 6 years ago . For Example: $\int x^2 dx$ This is a very simple integral yet I have trouble grasping the meaning of various notations. Does the placement of '$dx$' next to $x^2$ mean multiplying $dx$ by the object of integration which is $x^2$? If it did, then this would be solved by taking the integral of $x^2$ (this equals $\frac{x^3}{3}$) and multiplying it by the derivative of $x^2$ , the derivative of $x^2$ is $2x$. $\frac{x^3}{3}$ $*$ $2x$ = $\frac{2x^4}{3}$ This is not correct. Instead when we have $\int x^2 dx$ we use the power rule and come to the result: $\frac{x^3}{3}$ In my mind this seems to ignore 'dx', so why do we even include it in the first place? Why is the integral not written as: $\int x^2 $","['derivatives', 'integration', 'notation', 'calculus']"
2633554,Algebra - twice as much as other two combined,"$12$ tonnes of cement must be distributed among $3$ factories such that the first factory receives twice as much as other $2$ factories combined. How much cement does the first factory receive? For this, I have come up with algebraic equation . $x+y+z = 12$ $2(y+z)+y+z = 12$ (as per the statement above) As the question did not say anything about other $2$ factories, we cannot assume that each of the other factories get equal amount of cement. Hence, I used independent values for the same. and I know the answer for $x = 8$, so that $2(2+2) + 2 + 2 = 12$ through mental calculation. But I don't know how to derive it mathematically. Can someone help me with this?","['algebra-precalculus', 'systems-of-equations']"
2633648,Problem with $\sin 90^\circ =1$,"We know 
$$\sin\theta = \frac{\text{perpendicular}}{\text{hypotenuse}}$$
then $\sin 90^\circ = 1$ refers in this case perpendicular = hypotenuse. But, then, the base becomes $0$ according to the Pythagorean triplet law. How is this possible?",['trigonometry']
2633653,"Formal definition of a graph? $ \{ (x,f(x)) \mid x \in A \} $","working my way through the first few pages of James Stewart's' Essential Calculus and came across some notation I'm trying to decode in plain English. In this section he talks about ordered pairs and graphs: “ If $f$ is a function with domain $A$, then its graph is the set of ordered pairs
$$ \{ (x,f(x)) \mid x \in A \} ” $$ So I'm trying to decode that into plain English. I know the { } indicate a set and that
 $ \{ x\mid \ldots \} \to$ The set of all $x$ such that... My take is that the original line is: If $f$ is a function with domain $A$, then its graph is, The set of all $x$, $f(x)$ pairs such that $x$ is an element of $A$ ? Is that correct? Does anyone have a better way of saying this?","['calculus', 'functions']"
2633661,Solving pair of differential equations involving two functions,"$$\frac{d^2h(x)}{dx^2} = f(x)\sin(h(x))$$ $$\frac{d^2f(x)}{dx^2} = \cos(h(x))$$ Is it even possible to solve the equations for $f(x)$ and $h(x)$? If so, how would one solve them?",['ordinary-differential-equations']
2633674,Limit of integral/expectation,"Let $\xi_1,\xi_2,\ldots,\xi_n$ be an independent sample of Exp($1$) random variables with joint density, $f(x_1,\ldots,x_n) = e^{-(x_1+\cdots+x_n)}$. If $g$ is a bounded continuous function, compute the following limit, $$ \lim\limits_{n\rightarrow\infty} \int_{\mathbb{R}^n_+}g \left( \frac{x_1+ \cdots +x_n}{n} \right)f(x_1,\ldots,x_n) \, dx_1\cdots dx_n $$ where $\mathbb{R}_+^n = (0,\infty)^n$. My guess is that it will converge to $g(1)$. My reasoning is that we can view the integral as the expectation, $\operatorname{E}[g(\bar{X}_n)]$. By the strong law of large numbers and the coninuous mapping theorem, $\bar{X}_n \xrightarrow{\text{a.s.}} 1$ and $g(\bar{X}_n) \xrightarrow{\text{a.s.}} g(1)$. Since $g$ is bounded, we are permitted to bring the limit inside the integral, $$ \lim_{n\rightarrow\infty} \operatorname{E}[g(\bar{X}_n)] = \operatorname{E} \left[ \lim_{n\rightarrow\infty} g(\bar{X}_n) \right] = g(1) $$ This is very handwavy, and probably not true though. Can someone lead me in the right direction?","['probability-theory', 'lebesgue-integral', 'expectation', 'limits']"
2633684,"If $f$ is continuous with irrational period $\xi$ and $\int_0^\xi f(x)\,dx = 0$, is it possible that $f(1)+f(2)+f(3)+\cdots=\infty$?","If $f:\mathbb R\to\mathbb R$ is continuous with irrational period $\xi$ and $\int_0^\xi f(x)\,dx = 0$, is it possible that the series $f(1)+f(2)+f(3)+\cdots$ diverges to $\infty$? (This does not happen for, say, $f(x) = \sin x$, as the partial sums of $\sin 1+\sin 2+\sin 3+\cdots$ are bounded.)","['periodic-functions', 'sequences-and-series']"
2633712,The map $p : S^1 → S^1$ given by $p(z) = z^2$ is a covering map. Generalize to $p(z) = z^n$.,"Show that the map $p : S^1 → S^1$ given by $p(z) = z^2$ is a covering map. Generalize to the map $p(z) = z^n$. I know that there are already several posts offering an answer to this question as here and here , but my question is so that someone can explain an answer to the problem I found out there, the solution is the following: There are several things that I do not understand, I know that in order to prove that a function is a covering map, we have to take a point in $S^1$ and show that there is a neighborhood of this point that when taking the inverse image can be written as a union of open sets of $S^1$ and disjoint I think that in the problem take the $z$ and the neighborhood to prove that there is $U$, now I guess the problem is to show that $p^{-1}(U)$ can be expressed as a union of disjoint openings of $S^1$, but I do not understand why $U$ is an open semicircle centered on $z$, could someone explain to me why? And what follows of the test I do not understand either. Thank you very much.","['algebraic-topology', 'general-topology', 'covering-spaces']"
2633720,Prove by induction that $(k + 2)^{k + 1} \leq (k+1)^{k +2}$,"Prove by induction that $$ (k + 2)^{k + 1} \leq (k+1)^{k +2}$$ for $ k > 3 .$ I have been trying to solve this, but I am not getting the sufficient insight. For example,  $(k + 2)^{k + 1} = (k +2)^k (k +2) , (k+1)^{k +2}= (k+1)^k(k +1)^2.$ $(k +2) < (k +1)^2 $ but  $(k+1)^k < (k +2)^k$ so what I want would clearly not be immediate from using something like If  $ 0 < a < b, 0<c<d $ then $0 < ac < bd $. THe formula is valid for n = 4, So if it is valid for $n = k$ I would have to use $ (k + 2)^{k + 1} \leq (k+1)^{k +2} $ somewhere in order to get that $ (k + 3)^{k + 2} \leq (k+2)^{k +3} $ is also valid. This seems tricky. I also tried expanding  $(k +2)^k $ using the binomial formula and multiplying this by $(k + 2)$, and I expanded $(k+1)^k$ and multiplied it by $(k + 1)^2 $ term by term. I tried to compare these sums, but it also gets tricky. I would appreaciate a hint for this problem, thanks.","['inequality', 'exponential-function', 'calculus', 'induction', 'discrete-mathematics']"
2633725,Constant vector and differential geometry,"I have been asked to solve the following problem for my differential geometry class: Let u ( t ) = ($u_1$( t ), $u_2$ ( t ), $u_3$ ( t )) and v ( t ) = ( $v_1$ ( t ), $v_2$ ( t ), $v_3$ ( t )) be differentiable maps from the
interval ( a , b ) into $\mathbb{R}^3$.
If the derivatives u'(t) and v'(t) satisfy the conditions:
$$u'(t) = au(t) +bv(t) $$
$$ v'(t) = cu(t) - av(t) $$ where a, b, and c are constants, show that u ( t ) ∧ v ( t ) is a constant vector. I am having some issues with this problem. I think part of that comes from the fact that I don't really understand what the constant vector. If anybody could answer that and offer some advice on how to begin that would be great. I guess I also don't really understand why we would need to the derivative condition as well.","['multivariable-calculus', 'cross-product', 'differential-geometry']"
2633730,Properties of generalized eigenvalue problem when hermitian,"This Wikipedia page says that, for the generalized eigenvalue problem 
$$\boldsymbol{A}\boldsymbol{v}=\lambda\boldsymbol{B}\boldsymbol{v},$$
if $\boldsymbol{A}$ and $\boldsymbol{B}$ are hermitian and $\boldsymbol{B}$ is positive-definite, then (1) eigenvalues $\lambda$ are real; (2) eigenvectors $\boldsymbol{v}_1$ and $\boldsymbol{v}_2$ with distinct eigenvalues are $\boldsymbol{B}$-orthogonal ($\boldsymbol{v}_1^*\boldsymbol{B}\boldsymbol{v}_2=0$). How to prove (2)? I found the proof of (1) like this , but I can't find the proof of (2). The reference of this property on the Wikipedia page doesn't give the proof either.",['linear-algebra']
2633742,Construct a global invariant measure,"Given a (Hamiltonian) flow $\phi^t:\mathbb{R} \times D \rightarrow D$ on some compact set $D\subset \mathbb{R}^n$ ($D$ can be seen as some level set of the Hamiltonian), and let $\{U_\alpha\}$ be a finite cover of $D$. Suppose on each $U_\alpha$, there exists a measure $\mu_\alpha$ which is invariant under the flow, i.e.  given $A\subset U_\alpha$ and $T$ that are small enough, we have $ |t|\leq T,\; \phi^t(A) \subset U_\alpha$ and 
$$\quad  \mu_\alpha(A) = \mu_\alpha(\phi^t(A)).$$ Is there a way to define a global invariant measure on $D$? If not, what additional information I will need to do this?","['manifolds', 'dynamical-systems', 'real-analysis', 'measure-theory']"
2633754,If $\text{tr}(M^3)=\text{tr}(M^2)=\text{tr}(M)=1$ then $M=\mathbf{uu}^\dagger$ for some unit vector $\mathbf{u}$,"Consider an $n \times n$ complex Hermitian matrix $M$ which has trace one. I'm trying to show that if $$\text{tr}(M^3)=\text{tr}(M^2)=\text{tr}(M)=1$$ then $M=\mathbf{uu}^\dagger$ for some column vector $\mathbf {u} \in \mathbb C^n$ of unit length. I think it is enough to show that one of the eigenvalues of $M$ is $1$ and the rest are $0$, as $\mathbf {uu}^\dagger$ is a rank one projection matrix. From the trace relations we have $$\sum_i \lambda_i^3=\sum_i \lambda_i^2=\sum_i \lambda_i=1$$ where $\{\lambda_i\}$ are the (real) eigenvalues of $M$, but I'm struggling to show that this implies a single nonzero eigenvalue.","['matrices', 'linear-algebra', 'vector-spaces']"
2633755,Dense subspaces of $L^\infty(\Omega\times\Omega)$,"Let $\Omega\subset\mathbb R$ be open and bounded.  For continuous functions $C(\Omega\times\Omega)$, the Stone-Weierstrass theorem shows that the products $a(x)b(y)$ of univariate continuous functions in $C(\Omega)$ span a dense subspace.  However, for bounded functions in $L^\infty(\Omega\times\Omega)$, the only subspace I can think of is spanned by the indicator functions $\chi_A(x,y)$, where $A\subset\Omega\times\Omega$ is measurable. My question: is there a more convenient dense subspace of $L^\infty(\Omega\times\Omega)$?  In particular, do the products $a(x)b(y)$ of $L^\infty(\Omega)$ functions span a dense subspace? Motivation: I am considering the $L^2$ continuity of pseudo-differential operators with $L^\infty$ symbols $a$:
$$
Au(x)=\int e^{i(x-y)\cdot\xi}a(x,y,\xi)u(y)dyd\xi.
$$
If $a(x,y,\xi)\sim \sum a(x)b(y)c(\xi)$, such as if $a(x,y,\xi)$ is bounded and continuous, then $L^2$ continuity follows immediately from the properties of $L^\infty$ multiplier operators.  But without this product structure, I am not sure where to go.","['real-analysis', 'functional-analysis', 'product-space', 'lp-spaces', 'pseudo-differential-operators']"
2633765,à la Shafarevich conjecture for the moduli space of Calabi-Yau manifolds,"Suppose that $\pi: X \to C$
is a family of polarized Calabi-Yau manifolds over a Riemann surfaces $C$. Suppose that
the family of fibers $\pi$ contains a point $τ_0 \in C$ such that around it the monodromy
operator $T$ has large complex structure limit, i.e maximal index of unipotency, i.e.
$(T^N − id)^{n+1} = 0$ and $(T^N − id)^n\neq 0$. 
Then the family is rigid . Now assume that $\pi: X \to B$
is a family of polarized Calabi-Yau manifolds over a compact Kahler manifold $B$ of dimension bigger than one, then under which condition we can get rigidity?","['complex-geometry', 'kahler-manifolds', 'differential-geometry', 'algebraic-geometry']"
2633813,Area of Weird Shapes,"Start with a circle that has a regular polygon inscribed inside of it. Place it on top of a line so that one of the polygon's vertices is touching the line. Then imagine the circle rolling on the line until the next vertice is touching. What is the area of the region between the line and rotated edge of the polygon, the region not passed over by the edge? What if a 2-gon, the diameter of the circle?","['area', 'geometry']"
