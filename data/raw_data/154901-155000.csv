question_id,title,body,tags
2617773,Stochastic processes as Banach or Hilbert-space-valued random variables,"I'm having a hard time rectifying the following two concepts in my head. A real-valued stochastic process is typically first described as a function $$
X:\Omega\times T\rightarrow\Bbb{R}
$$ where $(\Omega,\mathcal{F},\Bbb{P})$ is a probability space and $T$ is a parameter set, typically taken as a subset of $\Bbb{R}^d$ (though, for generalized processes, $T$ is a set of test functions).   The probability measure $\Bbb{P}$ induces a probability measure $\Bbb{P}_X$ on the cylinder sets of $\Bbb{R}^T$ through the pushfoward.   However, it is usually stated that this probability measure is fairly useless because the sigma algebra on $\Bbb{R}^T$ is somehow not 'rich' enough to ask interesting questions (for instance, the set of continuous functions is not measurable). In other contexts - mainly engineering and in the field of uncertainty quantification - I see stochastic processes introduced in the following way.  Fix a Banach or Hilbert space $\mathcal{Y}$ of functions on $T$ (such as $L^2(T)$ with $T\subset\Bbb{R}^d$) and make it into a measurable space by giving it the Borel sigma algebra; a 'stochastic process' is then assumed to be a $\mathcal{Y}$-valued random variable, that is, $$
X:\Omega\rightarrow \mathcal{Y}
$$  Now, we have that the law of $X$ is a Borel probability measure, which has (perhaps) nicer properties than in the $\Bbb{R}^T$ picture. How can I connect these two pictures?  Under what conditions can a stochastic process be assumed without loss of generality to be a Banach-space valued random variable? I've browsed through several books and find discussions of both pictures, but nothing that really discusses the connection.  Am I looking in the wrong place, or just being thick? Edit: to rephrase, what I'm asking is this: are there any nice, general conditions under which the realizations of a classical or generalized random process $X$ (which are functions of $t\in T$, where $T$ might be a subset of $\Bbb{R}^d$ or a space of test functions) are almost surely in the specified Banach space $\mathcal{Y}$?  It's very easy to find sufficient condition cases where it is easy to prove such a thing, for instance if $X$ has a continuous modification and $T$ is compact, then certainly $X_t \in L^p(T)$. But I'm interested in more general processes and random fields that might have discontinuous realizations and so forth, so I don't really care about sample path continuity, only sample path integrability.","['stochastic-processes', 'probability-theory']"
2617857,Mysterious Characterization of $A_5$ inside $S_5$,"When I was trying to explain a combinatorial curiosity using permutation groups, I finally ended up with another curiosity about the alternating group $A_5$. For any permutation $\pi \in S_5$, let $\chi(\pi)$ denote the number of fixed points of $\pi$. Furthermore, as usual, let $[\pi,\sigma] := \pi^{-1}\sigma^{-1}\pi\sigma$ denote the commutator of two permutations $\pi, \sigma$. Now I found out that the following holds: Let $\sigma \in S_5$ be an arbitrary cycle of length 5. Then we have $$A_5 = \{ \pi \in S_5 : \chi([\sigma, \pi]) + \chi(\sigma^2 [\sigma, \pi]) \in \{2,5\} \}. $$ Isn't that strange!? I verified that equation with a computer, but I have absolutely no idea how to prove it. Even proving the original combinatorial problem wouldn't help immediately, because the group theoretical statement is stronger. Is there any chance to prove that characterization of $A_5$ by group theory?","['finite-groups', 'abstract-algebra', 'permutations', 'combinatorics', 'group-theory']"
2617874,"If $y=\ln(\frac{1}{3}(1+e^{-2x}))$, show that $\frac{dy}{dx}=\frac{2}{3}(e^{-y}-3)$.","I don't understand why there is only the $y$ variable in the derivative. I have differentiated it directly and I got $\frac{dy}{dx}=\frac{-2e^{-2x}}{1+e^{-2x}}$, but I don't really see how I can get to the final answer. Any guidance please?",['derivatives']
2617878,"How many number with 4 digits, beginning with $1$ and have exactly two identical digits?","The numbers $1447$, $1005$, and $1231$ have something in common. Each is a four-digit number beginning with $1$ that has exactly two identical digits. How many such numbers are there? I have check all the possible cases satisfying the require condition  are $$11xy,\qquad 1x1y,\qquad1xy1\qquad 1xxy,\qquad1xyx,\qquad1yxx.$$ maybe I am missing something. Can anyone help from here?",['combinatorics']
2617884,"$\frac{f'(x)}{f(x}\le \frac{g'(x)}{g(x)} \Rightarrow f(x)\le g(x) \,\forall\,x\in[a,b]$","Let $\,f,g:\,[a,b]\rightarrow \mathbb R$ be differentiable, postive functions with $f(a)=g(a)$ and $\frac{f'(x)}{f(x)}\le \frac{g'(x)}{g(x)}\,\forall\,x\in[a,b]$ $$Prove,\,that:
\frac{f'(x)}{f(x)}\le \frac{g'(x)}{g(x)} \Rightarrow f(x)\le g(x) \,\forall\,x\in[a,b]$$ I suppose it has something to do with Rolles Theorem and/or the mean value theorem for differential equations, but I have no idea how I can constructively approach this problem. Thank you in advance for any help! coltrane","['real-analysis', 'analysis']"
2617917,Prove the fact that two integrals are equal,"How can I prove that the following two integrals are equal (when they converge of course): $$\int\limits_0^\infty\frac{x^\frac{1}{2n}}{1+x^2}\space\text{d}x=\Gamma\left(\frac{1}{2n}\right)\cdot\int\limits_0^\infty\frac{\cos\left(x\right)}{x^\frac{1}{2n}}\space\text{d}x\tag1$$ My first option was to use Laplace transform, but I do not exactly see how I can use that, so any approach is welcome.","['trigonometry', 'calculus', 'proof-writing', 'definite-integrals', 'gamma-function']"
2617954,Why is the inverse of the derivative of f not the actual derivative of the inverse of f?,"So, I've explored this a little, but it is still confusing. When you calculate the inverse of a function, f, that is one-to-one, the points switch: a point (2,8) on f would be (8,2) on the inverse. So, one would assume that the derivatives of the functions would also constitute the reversal of points. However, that is not the case. For example, you have: $f (x) = 5x^2 \phantom{=}\text{ for  $x\geq0$}$ $f '(x) = 10x$ and $(f^{-1}) (x) = \sqrt{\frac{x}{5}}$ Here is my question: Why is finding the inverse of the derivative of $f$, $f '(x)$, and taking its inverse not the real derivative of the inverse? I would think $(f^{-1}) '(x) = \frac{x}{10}$, but that is not the case. The real inverse would be taking the derivative of $(f^{-1}) (x)$ and finding $(f^{-1}) '(x) = (\frac{1}{10\sqrt{x/5}})$. In my mind, both of these seem like they could be the derivatives of the inverse, yet only the latter is true. Why is this? Also, maybe I missed out in class, but is there some sort of quick relationship between (besides the formula) $f '(x)$ and $(f^{-1}) '(x)$ similar to how points switch between $f (x)$ and $(f^{-1}) (x)$. Thanks.","['derivatives', 'inverse-function', 'calculus', 'inverse']"
2617970,The definition of integral equations (beginner question),"The Fredholm equation of the first kind is 
$$
f(x)=\int_a^b K(x,t)\phi(t)\, dt \tag 1
$$ Q1: Does it mean $x$ is a scalar $x\in \mathbb R$? Or is it a function $x:\mathbb R\rightarrow \mathbb R$, i.e. $x(t)$, so explicit we have
$$
f(x(t))=\int_a^b K(x(t),t)\phi(t)\, dt \quad ? \tag 2
$$ Q2: And the same question for the Volterra equation of the first kind. Is it 
$$
f(x)=\int_a^x K(x,t)\phi(t)\, dt \tag 3
$$
Or 
$$
f(x(t))=\int_a^{x(t)} K(x(t),t)\phi(t)\, dt \quad ?\tag 4
$$ Q3: What about the Fredholm equation of the second kind and the Volterra equation of the second kind?","['functional-analysis', 'real-analysis', 'calculus', 'analysis']"
2618002,Evaluate the limit containing $\arctan{x}$ and $\arcsin{x}$,"Evaluate: $$\lim_{x\to{0}}\bigg(\frac{2}{x^3}.(\arcsin{x}-\arctan{x})\bigg)^{2/x^2}$$ I can just expand $\arcsin{x}$ and $\arctan{x}$ using their taylor expansions, but is there any other method?","['limits-without-lhopital', 'limits']"
2618017,Geometric interpretation of ramification of prime ideals.,"I am trying to understand geometrically the ramification of primes in a finite separable field extension. Let $A$ be a Dedekind domain with fraction field $K$ and $L/K$ a finite separable field extension of degree $n$, and let $B$ be the integral closure of $A$ in $L$, which is then also a Dedekind domain. Let $X=\text{Spec}(B)$ and $Y=\text{Spec}(A)$, and consider the projection $X\to Y$ which sends a prime $\mathfrak{q}\in X$ over $\mathfrak{p}\in Y$ to $\mathfrak{p}$ (i.e., the map of affine schemes corresponding to the inclusion $A\to B$). Let $\mathfrak{p}\in Y$ be a non-zero prime ideal in $A$. The fiber over $\mathfrak{p}$ is then the set of prime ideals $\mathfrak{q}_{i}\in X$ such that
$$ \mathfrak{p}B=\mathfrak{q}_{1}^{e_{1}}\cdots \mathfrak{q}_{g}^{e_{g}}$$
is the corresponding prime factorization in $B$ (uniquely determined, because $B$ is a Dedekind domain). Let $f_{i}=[\kappa(\mathfrak{q}_{i}):\kappa(\mathfrak{p})]$ be the corresponding residue degrees. Then: $$\sum_{i=1}^{g}f_{i}e_{i}=n$$ We say that $\mathfrak{q}_{i}$ is ramified above $\mathfrak{p}$ if the ramification index $e_{i}$ is strictly greater than 1, and unramified if $e_{i}=1$. We say that $\mathfrak{p}$ is unramified in $B$ if all $e_{i}=1$; that $\mathfrak{p}$ splits in $B$ if all $e_{i}=f_{i}=1$; and we say that $\mathfrak{p}$ is inert in $B$ if $g=e_{1}=1$. We can picture both $X$ and $Y$ as algebraic curves and $X$ as a ramified cover of $Y$. I am trying to understand the precise geometric meaning of all the previous definitions in terms of this geometric picture. My professor said that ramified primes above $\mathfrak{p}$ are those points $\mathfrak{q}_{i}\in X$ where the fiber over $\mathfrak{p}$ meets $X$ in a tangent point (I understand that by fiber he means the vertical line above $\mathfrak{p}$ when we picture $Y$ as a straight line). I tried to match this interpretation with the example of $A=\mathbb{Z}$ and $B=\mathbb{Z}[i]$, based on the picture of $\text{Spec}(\mathbb{Z}[X])$ of Mumford: Prime ideals in $\mathbb{Z}[i]=\mathbb{Z}[X]/(X^{2}+1)$ should correspond to prime ideals containing $(X^{2}+1)$. That is, they should correspond to points in the curve $V(X^{2}+1)$ drawn in the picture. The picture above $(2)$ matches this interpretation perfectly, since $(2)$ ramifies in $\mathbb{Z}[i]$. And so does the picture above $(5)$, since $(5)$ splits into two primes in $\mathbb{Z}[i]$. But now I have a problem with the picture above $(3)$. There should be only one point, namely $(3,X^{2}+1)\in X$, but I guess Mumford just doesn't draw it. But even if he did, how would he draw this point without creating a singularity on the curve? Because, being the spectrum of a Dedekind domain, $X$ should be a regular curve, right? So how would we draw this point? But if you draw this point in the naive way, introducing a singularity, suddenly the residue degree seems to make some geometric sense to me: it seems to be the number of parameters that we need to describe the curve around the corresponding point. How much of this naive impression is true? Is this just a coincidence? Because algebraically this doesn't make much sense to me. One should be able to describe the curve locally with a single parameter, because all the local rings are DVR. I will try to summarize all these doubts in the following question: What is the precise geometric meaning of the ramification index and the residue degree? Finally, if possible, I would like to hear some clarification comments on the source that started all these doubts (initially I was naively happy with my professor's interpretation): Neukirch's Algebraic Number Theory . In chpater I, Section 13 (One-dimensional Schemes) he draws this ramification situation: I have several problems with this picture. Shouldn't $X$ be a regular curve? Why aren't the ramification points tangent, as my professor claimed them to be? If this is really the picture, how do we distinguish geometrically between inert points and ramification points? For example, the point on the right. Is it inert or is it ramified? Neukirch says that this picture is only a fair rendering of the algebraic situation when the residue fields in $A$ are algebraically closed, but this doesn't help much to answer the previous questions. Thanks for the spending the time to read this long question. I am quite confused with this issue and I wanted to express my doubts as clear as possible.","['algebraic-geometry', 'algebraic-number-theory', 'number-theory', 'algebraic-curves', 'ramification']"
2618019,Hidden variable resultant for solution of a system of polynomial equations,"I am trying to implement a method from as paper that solves a practical problem. The core part is solving of a system of polynomial equations of same total degree. We have a system of 10 polynomial equations on $x, y, z$ of degrees 3 
$$F_1(x, y,z)=F_2(x,y,z)=...=F_{10}(x,y,z)=0$$ The hidden variable method mentioned in the paper suggests next representation: $$F_i = f_{i1}(z)x^3 + f_{i2}(z)y^3 + f_{i3}(z)x^2y + f_{i4}(z)xy^2 + ... +  f_{i8}(z)x + f_{i9}(z)y + f_{i10}(z)1$$ where $f_{ij}$ is a polynomial of z of correspondent degree from 0 ($f_{i1}$ for example) to 3 ($f_{i10}$). Now we can look write our system of equations as 
$$A(z)X=0$$
where $A(z)={f_{ij}(z)}$, $X=\begin{bmatrix}x^3 & y^3 & x^2y & xy^2 & x^2 & y^2 & xy & x & y & 1\end{bmatrix}^T$ From linear algebra we know that this system can have a nontrivial solution only if $det(A(z))=0$ So writing down $det(A(z))$ as a function of will give us a single-variable polynomial on $z$. Its $k$ roots ${z_k}$ will give us possible values of $z$ that a solution of the system can have. The part above is clear for me, but next steps are not. It is said that eigenvectors of $A(z_k)$  are solutions for the system! So we have to find an eigenvector, take its 8th and 9th components (which correspond to $x$ and $y$ in $X$ vector) and we'll get a valid solution for the whole system. That sounds like a magic for me. Is this guaranteed? Will, for example, 7th component of the vector (it corresponds to $xy$) be a product of 8th and 9th? What gives such guarantees etc. It's also mentioned that it's true due to the fact that $X$ has all bivariate monomials of $x$ and $y$ of degrees up to 3 and I have no idea why it's so. I tried to check if this method works on a system of 3 quadratic equations on $x$ and $y$. For example, consider the system $$x^2 + 2xy + 3y^2 + 4x + 5y + 6 = 0$$
$$6x^2 + 3xy + 2y^2 + x + 5y + 4 = 0$$
$$3x^2 + 2xy + 6y^2 + 4x + y + 5 = 0$$ It can be rewritten as $A(y)X = 0$ where 
$$A = \begin{bmatrix}1 & 2y + 4 & 3y^2 + 5y + 6 \\ 6 & 3y + 1 & 2y^2 + 5y + 4 \\ 3 & 2y + 4 & 6y^2 + y + 5 \end{bmatrix}$$ 
and 
$$X = \begin{bmatrix}x^2 \\ x \\ 1 \end{bmatrix}$$ Determinant of such matrix is a polynomial:
$$det(A(y)) = -37y^3 - 33y^2 + 111y + 43$$ The roots of this polynomial are:
$$y_1 \approx -2.069961\\ y_2 \approx -0.364067 \\y_3 \approx 1.5421368$$ Now take for example $y_1$ and substitute it to $A(y)$ $A(y_1) = \begin{bmatrix} 1.00000 & -0.13992 & 8.50441 \\ 6.00000 & -5.20988 &   2.21967 \\ 3.00000 & -0.13992 & 28.63848 \end{bmatrix}$ Using SVD decomposition we get an eigenvector correspondent to zero eigenvalue $p = \begin{bmatrix} 0.668080 \\ 0.741125 \\ -0.066363 \end{bmatrix} $. Normalizing $p$ by dividing it by -0.066363 we should get an answer (a valid $x$ such that $(x, y_1)$ satisfy our system), but it's not a valid answer. So no magic happened! :( Neither it did for nullspace vector for $A(y_2)$ and $A(y_3)$. Now let's consider a system that has solutions. For example, 
$$ x + 2y = 5 \\ 3x + 4y = 6$$ Can be rewritten as 
$$A(y)X = 0$$ where $$A(y) = \begin{bmatrix} 1 & 2y-5 \\ 3 & 4y - 6 \end{bmatrix}$$
and
$$X = \begin{bmatrix} x \\ 1 \end{bmatrix}$$ Then $det(A(y))$ is a polynomial $-2y + 9$ with a root $y_1 = -4.5$ Substituting it back gives us $A(y_1) = \begin{bmatrix} 1 & 4 \\ 3 & 12 \end{bmatrix}$ with a basis vector of its nullspace $p = \begin{bmatrix} -0.97014 & 0.24254 \end{bmatrix}$, dividing it by its last component gives a correct answer $x = -4$, the magic did happen indeed. I understand that these questions are answered by algebraic geometry so I started studying it (Cox, Little, O'Shea, Using Algebraic Geometry) but things go really slowly. Due to my working schedule, it seems I'll be able to go through it in a year or more. But I hate using methods that I don't get at least at some intuitive level. Is the amount of theory needed to be understood can be worked in a, say, a week? Any advices on books or maybe some intuitions or explanations would be really-really helpful.","['polynomials', 'algebraic-geometry', 'systems-of-equations', 'resultant', 'linear-algebra']"
2618032,Intuition on Complex Analysis,"I'm currently studying complex analysis via Stein's book, but I feel  that, despite I understand the proofs, I'm still lacking of intuition on why the results are true.
For example, it's still not natural to me why a function be holomorphic or analytic  or have a primitive are all equivalent concepts, and this lack of analytic and geometric meaning makes me forget  the proofs and the important results.  I mean, what is behind complex function's regularity? Can anyone help me?","['complex-analysis', 'soft-question']"
2618094,Why the square root of any decimal number between 0 and 1 always come out to be greater than the number itself?,"Why the square root of any decimal number between 0 and 1 always come out to be greater than the number itself? Whereas if we take the square root of say 25 we are left with 5, which is less than the number 25.","['algebra-precalculus', 'decimal-expansion', 'real-numbers']"
2618100,Calculate $\sum_{k=1}^{10}k{{10}\choose{k}}{{20}\choose{10-k}}$,"I've been given the task of calculating: $$\sum_{k=1}^{10}k{{10}\choose{k}}{{20}\choose{10-k}}$$ I've tried to start with what I'm familiar with - $\sum_{k=0}^{10}{{10}\choose{k}}{{20}\choose{10-k}}$. I've tried adding the value of $k=0$ to the sum, which is $0{{10}\choose{0}}{{20}\choose{10}} = 0$ and then subtracting it to get the equality: $$\sum_{k=1}^{10}{{10}\choose{k}}{{20}\choose{10-k}} = \sum_{k=0}^{10}{{10}\choose{k}}{{20}\choose{10-k}} - 0$$ Combinatorically, this is equal to ${30}\choose{10}$. However, I'm stuck with that $k$ which is in the beginning of each value of the sum: $\sum_{k=1}^{10}\color{red}{k}{{10}\choose{k}}{{20}\choose{10-k}}$. I just can't seem to find a way to solve this algebraically, or combinatorically. I feel like I'm missing something really basic here but I can't point the finger to what it may be. Suggestions are greatly appreciated!","['combinatorics', 'summation', 'discrete-mathematics']"
2618122,How is $\operatorname{Gal}(K^{nr}/K)$ isomorphic to $\operatorname{Gal}(\bar{k}/k)$?,"Let $K$ be a local field complete with a discrete valuation.
In a book I am reading it states that $\operatorname{Gal}(K^{nr}/K)$ is isomorphic to $\operatorname{Gal}(\bar{k}/k)$ , but I wasn't sure how this was true. How does one see this? I would greatly appreciate any comments and suggestions. Thank you.","['galois-theory', 'galois-extensions', 'local-field', 'algebraic-number-theory', 'number-theory']"
2618140,Hard Combinatorical Geometric Problem on Intersecting Circles,"There's a problem I've heard a few years ago, which neither I nor any of my colleagues were able to solve, and much time has passed so we do not even know its source, even trying to google it. I'd much appreciate if someone can point at a solution to this. On a plane there are $n$ circles with the following conditions: All circles have the same radius Each circle intersects at least one other circle No two circles are tangent Given the above, prove that there are at least $n$ unique intersection points. I have only succeeded in proving that there are at least $\sqrt{2n}$ unique intersection points. Edit: ""Unique"" intersection points means disregarding multiplicities.","['circles', 'combinatorics', 'geometry']"
2618149,Extending a valuation of a local field,"I am trying to verify this fact that I am sure it is true (maybe not), but all the material online is just making me quite confused, and I would greatly appreciate some assistance. I have a local field $K$ complete with respect to a discrete valuation $v$. 
Let $L$ be a finite extension of $K$. I want to say that there is a unique discrete valuation $w$ on $L$ such that $w|_K = v$. Is this true? Thank you.","['number-theory', 'algebraic-number-theory', 'local-field']"
2618156,Integrating both sides of equation,"I'm given that -> $$\frac{dy(x)}{dx}=x$$
I integrate both sides ->
$$\int \frac{dy(x)}{dx}dx=\int x\,dx$$ Would it be correct if i canceled out the $dx$s and wrote ->
$$\int dy=\int x\, dx$$ therefore $$y= \frac{x^2}{2}+C,$$ where $C\in \mathbb{R}$",['integration']
2618158,$\mathbb{R}G$-modules with the same characters,Let $G$ be a finite group. I'm looking for two nonisomorphic $\mathbb{R}G$-modules $U$ and $V$ with the same characters. Could someone provide an example?,"['finite-groups', 'representation-theory', 'group-theory']"
2618174,Calculate segment distance to cover before turning via a pivot,"I'm building a visualisation where I have a body that is moving along-a-path, which is comprised of multiple segments, each with an arbitrary angle. The body is moving along the path and: When the body's centre reaches the end of each segment it stops. It then rotates around it's centre to align itself with the next segment . It starts moving again along the next segment. I can get this working just fine when the rotation point is the body's centre . Here's an animation of the body rotating by it's centre (blue dot): However now I'd like to rotate the body from a pivot point . How can I calculate the distance I should cover in each segment before I stop and start turning around my pivot, so when the rotation ends my body's centre lies exactly in the centre of the next segment? In short, when the body is moving it's centre must always lie on the segment line it moves on. Here's an animation of the body rotating by it's pivot point (red dots): In the above example the body overshoots the position on each segment where it should stop and start rotating, thus when it starts moving again - it's centre doesn't lie on the path. FWIW I've got some code for this working in a browser sandbox, available here","['trigonometry', 'geometry']"
2618282,"Dilogarithmic fashion: the case $(p,q)=(3,4)$ of $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$","Today I met on Facebook the following integral
$$\int_{0}^{1}\frac{\text{Li}_3(x)\,\text{Li}_4(x)}{x^2}\,dx$$
which I proved to be equal to
$$\frac{10 \pi ^2}{3}-\frac{17 \pi ^4}{180}-\frac{\pi ^6}{540}-10\, \zeta(3)-\frac{\pi^2}{3}\,\zeta(3)-\frac{\pi^4}{90}\,\zeta(3)-\zeta(3)^2-2\,\zeta(5).$$
The trick I used is pretty nice: by integration by parts, the computation of $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$ boils down to the computation of $\int_{0}^{1}\frac{\text{Li}_{p-1}(x)\,\text{Li}_q(x)}{x^2}\,dx$ and $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_{q-1}(x)}{x^2}\,dx$. It follows that through many steps of integration by parts the evaluation of the generalized $(p,q)$-integral boils down to the evaluation of $$ \int_{0}^{1}\frac{-\log(1-x)\,\text{Li}_r(x)}{x^2}\,dx =\zeta(2)+\sum_{n\geq 2}\frac{H_{n-1}}{(n-1)n^r},$$
where by partial fraction decomposition the RHS only depends on standard Euler sums $\sum_{n\geq 1}\frac{H_n}{n^s}$, always expressible in terms of values of the $\zeta$ function. See, for instance, Flajolet and Salvy , Theorem 2.2. I would use this question for collecting alternative/shorter/slicker solutions, both for the starting integral or for the generalized one $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$.","['special-functions', 'integration', 'alternative-proof']"
2618283,Solving a symmetric pair of differential equations,"Looking at graphical solutions of \begin{align}
\dot{x} &= - x + cy \\
\dot{y} &= - cy + x,
\end{align} which for example describe how a two-level toy system approaches thermal equilibrium: plot created with Octave (1) one might be tempted to think that \begin{align}
x(t) &= x_\infty (1-e^{-t/\tau}) + x_0e^{-t/\tau} \\
y(t) &= y_\infty (1-e^{-t/\tau}) + y_0e^{-t/\tau},
\end{align} would be canonical solutions – provided that $x_\infty + y_\infty = x_0 + y_0$. Then one might want to find out how $\tau$ depends on $c$ . But unfortunately, it seems not to be true: $$\dot{x} = -\frac{x_\infty-x_0}{\tau}e^{-t/\tau} \neq - x + cy$$ My questions are: Did I make a mistake, and it is a solution? If not so: What are the canonical solutions to the pair of equations above? Is there a closed form? How do I derive it? (1) Octave code: function dx = f(x,t,c)
   dx(1) = - x(1) + c * x(2);
   dx(2) = -c * x(2) + x(1);
endfunction
g = @(x,t) f(x, t, 5);
xs = lsode(g,[1,2],0:0.01:1);
plot(xs);","['ordinary-differential-equations', 'statistical-mechanics']"
2618322,Equivalent horizontal and vertical transformations of functions,"I have been investigating equivalent transformations of functions, particularly those relating horizontal scaling to vertical scaling. For example, $f(x) = a\sqrt {bx} = a\sqrt{b}\sqrt{x}$, so horizontally scaling the function $g(x) = a \sqrt{x}$ by a factor of $\frac{1}{|b|}$ is the same as vertically scaling the function by a factor of $\sqrt{b}$. We can clearly derive similar equivalent transformations for $y=a(bx)^2$, $y = \frac{a}{bx}$, etc. However, I have not been able to apply similar reasoning for functions like $y=a\sin{bx}$ or $y = a2^{bx}$. Of course, it is sometimes possible using identities ($y = \sin{2x} = 2\sin{x}\cos{x}$ and $y = \log{bx} = \log{x} + \log{b}$), but I am interested in a more general conclusion, particularly one relating horizontal and vertical scaling. Is there such a result, and does it reveal anything fundamental or interesting about functions? Or, is there a reason that such a result would not exist or would be trivial? Perhaps there is another way to view this problem?","['algebra-precalculus', 'functions']"
2618355,Fubini's theorem for multiple Riemann integrals,"I'm working through Analysis on Manifolds by Munkres on my own. He proves a version of Fubini's theorem for multivariable Riemann integrals that goes like: If $Q= A \times B \subset \mathbb{R}^n \times \mathbb{R}^m$ is a closed bounded rectangle and the Riemann integral $\int_Q f$ exists then $$\int_Q f = \int_A \underline{\int}_B f(x,y) dy dx = \int_A \overline{\int}_B f(x,y) dy dx $$ The lower and upper integrals are needed here when, fixing $x$, $f(x,\cdot):B \to \mathbb{R}$ is bounded but not Riemann integrable over $B$.   So if $f(x, \cdot)$ is integrable then we get Fubini's theorem where $$\int_Q f = \int_A \int_B f(x,y) dy dx = \int_B \int_A f(x,y) dy dx $$ I think this could happen if $f$ is not absolutely integrable, otherwise Fubini's theorem for Lebesgue integrals applies. My question is what are some examples where $\int_Q f$ exists but $\int_Bf(x,y)dy$ does not?  More than one is welcome. EDIT To clarify, I mean I am looking for examples where $\int_Bf(x,y) dy$ is not Riemann integrable almost everywhere over $A$, but still $f$ is Riemann integrable over $Q$, so that $$\int_Q f \neq \int_A \int_B f(x,y) dy dx$$","['multivariable-calculus', 'multiple-integral', 'real-analysis', 'riemann-integration']"
2618382,Prove that an isometry f maps the circle c with center P and radius r onto the circle c' with center f(P) and radius r.,"I know proving an isometry maps circles into circles. However, proving an isometry maps circles onto circles is somewhat similar to the proof of circles into circles. Any hints on how to start this proof? Also, if possible, can I assume the inverse of f, knowing that a bijection is into and onto and then apply what I am trying to claim isometry maps circles onto circles?","['discrete-mathematics', 'geometry']"
2618384,"If $f(a,b)=f(a,c)f(c,b)$ for all $a,b,c$, when can we conclude $f(a,b)=g(a)/g(b)$ for some $g$?","Suppose an unknown function $f:\mathbb{R}^2\rightarrow\mathbb{R}$ satisfies $$f(a,b)=f(a,c)f(c,b),$$ for all $a,b,c\in\mathbb{R}$. Under what conditions can we rigorously conclude that $f$ must be some quotient $$f(a,b)=\frac{g(a)}{g(b)},$$ for an unknown function $g$? What assumptions do we have to make about $f$, does it need to be analytic, or just continuous? A physics text I am reading states this as obvious, but I am wondering if there is a way to prove it rigorously.","['functional-equations', 'calculus', 'functions']"
2618436,Got stuck doing a proof with logical equivalences,I have to show that $(p\lor q)\land (\neg p\lor r)\rightarrow (q\lor r)$ is a tautology. I have : $(p \lor q) \land (\neg p \lor r) \to (q \lor r) \equiv \neg((p \lor q) \land (\neg p \lor r)) \lor (q \lor r)$ implication proof $\equiv \neg(p \lor q) \lor \neg(\neg p \lor r) \lor (q \lor r)$ De Morgan $\equiv (\neg p \land \neg q) \lor (p \land \neg r) \lor (q \lor r)$ De Morgan I don't know how to proceed from here. Can anybody check and see if I messed up or point me to a right step? Thanks!,"['propositional-calculus', 'discrete-mathematics']"
2618439,Simple Probability problem with circle and triangle,"A clock is hanging on the wall and has diameter 6cm. An isosceles triangle is inscribed with the vertices touching the rim of the clock at 9:00, 12:00, and 3:00. If a dart is thrown at the clock, assuming it's equally as likely to hit anywhere in the clock and it will definitely hit the clock, what's the probability it lands inside the triangle? I've found that the area of the circle is 9pi and that of the triangle is 9.
Therefore the Probability to be in the triangle is 1/pi and the probability it lands outside the triangle is 1-1/pi. 
Can somebody confirm that I have it right?","['probability', 'elementary-set-theory']"
2618459,Transform Logistic/Sigmoid function,"Please excuse any incorrect terminology. I want to adjust the curve of a logistic function to make it more or less steep while still reaching the asymptote points at the same value of x. Here is a standard logistic function $f(x) = \frac{L-a}{1+e^{-k(x-x_0)}}+a$ where L=1, a=0, k=1, $x_0=0$: standard logistic function I know that I can change the steepness by changing k. For example, if k=0.5 I get the line shown in red: logistic function with k=0.5 I can change the minimum and maximum values of f(x) by changing a and L, respectively. I can change the x value where f(x) hits the midpoint between a and L by changing $x_0$. My goal is to have a function such as this: $$
g(x) = 
\begin{cases}
0 & \quad \text {if } x<-5 \\
f(x) & \quad \text {if } -5\geq x\leq 5\\
1 & \quad \text {if } x>5
\end{cases}
\
$$ Where f(x) looks like the line shown here in yellow as given by $f(x)= \frac{1.1-(-0.9)}{1+e^{-0.05(x-0)}}+-0.9$: goal function in yellow This yellow line has the 'steepness' of the function where k=0.5 (red line) but has approximately the same minimum and maximum (x, f(x)) points as the standard logistic function (blue line). I arrived at the current yellow line by manually adjusting a and L values until the line looked correct. My questions are: Is there some other transformation I can use on the logistic function to make it look like the yellow line (without manually guessing values for L and a)? Is there a different/better formula than the logistic function I can use to get a curve that looks like this yellow line?","['normal-distribution', 'probability', 'functions', 'probability-distributions']"
2618462,Proving complex series $1 + \cos\theta + \cos2\theta +... + \cos n\theta $,So I have this result $1 + z + z^2 + ... + z^n = \frac{z^{n+1}-1}{z-1}$ which I proved already. Now I am supposed to use that result and De Moivre's formula to establish this identity $1 + \cos\theta + \cos2\theta +... + \cos n\theta = \frac{1}{2} + \frac{\sin[(n+\frac{1}{2})\theta]}{2\sin(\frac{\theta}{2})}$ Can anyone help me?,"['complex-analysis', 'complex-numbers']"
2618488,Taylor Series of Gamma Function,"I have always wondered whether the Taylor Series of Gamma Function exists or not. I tried to find it, but in vain. I googled for it, but couldn't find it. Has anyone ever found its Taylor Series?","['gamma-function', 'taylor-expansion', 'soft-question', 'calculus']"
2618490,"How do you invert this function $f(x,y)=\left( \frac{x}{x^2+y^2},\frac{y}{x^2+y^2}\right)$?","Does there exist an inverse of the following function with given domain? $$f(x,y)=\left( \frac{x}{x^2+y^2},\frac{y}{x^2+y^2}\right), \quad (x,y)  \in \mathbb{R}^2$$ $$(\mathbb{R}^2= \{ (x,y):x,y \text{   are real numbers}, \text{ excluding } (x,y)=(0,0) \})$$ I know when the function is of a single variable its inverse can be visualised flipping around the $x=f(x)$ line in the $(x,f(x))$ plane, but how would you interpret the inverse of a function as above (more dimensions)?",['multivariable-calculus']
2618527,"Converting from Yaw,Pitch,Roll to Vector","I am currently trying to construct a vector in space given yaw, pitch, and roll with the assumption that my ray originates from (0,0,0). I started by breaking up the problem into 3 sets of triangles by slicing space in 3 ways: In the X-Y plane, I concluded that x = sin(yaw) and y = cos(yaw) In the Y-Z plane, I determined that y = cos(pitch) and z = sin(pitch) In the X-Z plane, I found that x = cos(pitch) and z = sin(pitch) From this, I arrived at However, this doesn't seem to satisfy basic tests, such as <1,1,1>, where the Yaw = Pi/4 and the Pitch should be Pi/4, but the formula yields 0.5, 0.5, 0.7, which has a direction vector different than <1,1,1>. Can anyone spot where I messed up? I've been banging my head at this for a while, and I can't seem to resolve where I made an error.","['angle', '3d', 'trigonometry', 'vectors']"
2618534,Evaluating: $\int \frac {1+\sin (x)}{1+\cos (x)} dx$,"Evaluate: $\int \dfrac {1+\sin (x)}{1+\cos (x)} dx$ My Attempt:
$$=\int \dfrac {1+\sin (x)}{1+\cos (x)} dx$$
$$=\int \dfrac {(\sin (\dfrac {x}{2}) + \cos (\dfrac {x}{2}))^2}{2\cos^2 (\dfrac {x}{2})} dx$$
$$=\dfrac {1}{2} \int (\dfrac {\sin (\dfrac {x}{2}) + \cos (\dfrac {x}{2})}{\cos (\dfrac {x}{2})})^2 dx$$
$$=\dfrac {1}{2} \int (\tan (\dfrac {x}{2}) +1)^2 dx$$ How do I continue?","['trigonometry', 'calculus', 'indefinite-integrals', 'integration', 'analysis']"
2618537,Do right-to-left readers also reverse mathematical concepts like number line?,"I come from a culture which uses left-to-right language. In my mind, the following is true: On number line, negative numbers are to the left of 0, positive are to the right. In Cartesian coordinate system, X axis points to the right (same as number line). Limit from the left is '-' and limit from the right is '+'. Does the same hold true for mathematicians who come from cultures using right-to-left languages?","['number-line', 'limits']"
2618560,Is it true for the symmetric matrices?,Suppose there are two symmetric matrices $A$ and $B$. Then can we write $$\frac{tr(AB)}{B}=A$$ Any help in this regard will be much appreciated. The reason for question: I am trying to understand an example from appendix A of convex optimization book (by Stephen Boyd). On page 642 it is written that $f(Z)\simeq f(X)+tr(X^{-1}(Z-X))$. Now the gradient of $f(X)$ is then shown to be $X^{-1}$. If I put $f(Z)$ in Equation A.4 then I have $$\frac{||f(Z)-f(X)-Df(X)(Z-X)||_{2}}{||Z-X||_2}=0$$ which results in $$tr(X^{-1}(Z-X))=Df(X)(Z-X)$$ Now if $tr(X^{-1}(Z-X))=X^{-1}(Z-X)$ then I can understand but I am not sure whether it is true or not. So any help in this regard will be much appreciated. Thanks in advance.,"['matrices', 'optimization', 'derivatives']"
2618579,a limit about exponential function [duplicate],"This question already has answers here : Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ (9 answers) Closed 6 years ago . $\lim_{n\rightarrow\infty}\frac{1+\frac{n}{1!}+\cdot+\frac{n^n}{n!}}{e^n}=\frac12$ Taking the first $n$ terms of the Taylor series of $e^n$ as the numerator, the limit is true or false? How to prove?","['estimation', 'limits']"
2618584,How many unique subsets of size 3 can there be from a 5 element set?,"I'm solving a problem that uses Combinations and it's driving me crazy. The question requires the number of unique subsets (order does not matter) from 5 elements. I believe the answer should just be C(5, 3) correct? $\frac{5!}{3!(5-3)!}$ that is. However, as I manually list out all these sets. I am only getting 9, as my answer, not 10.... C(5, 3) = 10. $(A, B, C, D, E)\\
(A, B, C)\\
(A, B, D)\\
(A, B, E)\\
(A, C, D)\\
(A, C, E)\\
(A, D, E)\\
(B, C, D)\\
(B, D, E)\\
(C, D, E)\\
$ The question requires that there cannot be any duplicate element sets, so the order does not matter. Hence the set (A, B, C) = (B, A, C).
Is this not a combination or am I just missing one of the subsets? Thanks.","['combinations', 'combinatorics']"
2618608,How to check if the columns of a given vector spans Rn,"Q1: In this question, find out if the given vectors $\{v_1,v_2,v_3\}$ span $R^4$. Vectors $v_1,v_2,v_3$ Q2: Given this matrix Matrix $B$ . Find out if the columns of this matrix span $R^4$. I came across several solutions for these two questions. In all of those augmented matrix was made and checked for pivot columns.
My question is why are we creating augmented matrix to check the span ? 
We should rather be making an equation like $[A]X = b$, where $A$ is the given matrix in the question, and then check for consistency.","['matrices', 'linear-algebra']"
2618643,Spin Bundle and Connection on $R^3$?,"What is the spin connection on the spin bundle $S$ over $R^3$? Let metric be $dx_1^2+dx_2^2+dx_3^2$ with orientation $dx_1 \wedge dx_2 \wedge dx_3$. From my understanding, the spin bundle over $R^3$ is a trivial rank 4 bundle equipped with anticommuting involutions I, J e.g. $I=\begin{pmatrix} 0 & 1 &0 &0 \\ -1 &0 &0 &0 \\ 0 & 0 &0 &1 \\0 &0 &-1&0\end{pmatrix}, J=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. We need a representation $\Gamma$ of the Clifford algebra of $TR^3$ onto the space $R^4$ that commutes with I,J. Let $\frac{\partial}{\partial x_1}, \frac{\partial}{\partial x_2}, \frac{\partial}{\partial x_3}$ be frame of $TR^3$. I suppose $\Gamma$ could be given by 
$\Gamma(\frac{\partial}{\partial x_1})=\begin{pmatrix} 0 & 1 & 0 & 0 \\ -1 & 0 & 0 & 0 \\ 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \end{pmatrix}$,  $\Gamma(\frac{\partial}{\partial x_2})=\begin{pmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ -1 & 0 & 0 & 0 \\ 0 & -1 & 0 & 0\end{pmatrix}$, $\Gamma(\frac{\partial}{\partial x_3})=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \\ 0 & -1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. Then what remains is to define a connection on $S$ that is both compatiable with the Levi-Civita connection on $R^3$ and with the inner product on $R^4$, i.e.
if $s,s'$ are sections of $S$ then $\nabla_X(\Gamma(Y)s)= \Gamma(Y) \nabla_X s + \Gamma(\nabla_X Y) s$ for all vector fields $X,Y$ on $R^3$ and $X<s,s'>=<\nabla_X s,s'>+<s,\nabla_X s'>$ For our spin connection, I believe there are 4x4x3=48 Christoffel symbols to calculate. Are we to use compatability conditions to generate 48 equations and solve for the Christoffel symbols? How does one get the spin connection? I am looking for explicit form of this connection and calculation, not abstract definition of this connection like ""unique lift of Levi-Civita connection"" etc.","['spin-geometry', 'riemannian-geometry', 'differential-geometry']"
2618680,How can the following be false based on the information about continuous functions?,"Let $f\colon\mathbb{R}\to [0,\infty)$ be a continuous function. Then, what is the rationale behind saying that the following are false statements: There exists $x\in\mathbb{R}$ such that  $f(x)=\int_{-1}^{1}f(t)dt$. There exists $x\in\mathbb{R}$ such that  $f(x)=\frac{f(0)+f(1)}{2}$. I think the second statement should be true due to the intermediate value theorem but I am not certain about the first statement. But  my solution manual says both statements are false. What should be the rationale behind this reasoning?","['continuity', 'real-analysis', 'definite-integrals']"
2618688,"if $n^2+1$ is composite, then $n!+n^2+1$ is composite","Prove if $n^2+1$ is composite, then $n!+n^2+1$ is composite
I try to let $n^2+1$ = ad for some a,d $\in$ Z, but I find it doesn't work 
Just want to know the main idea for this problem","['number-theory', 'elementary-number-theory']"
2618738,Symmetrization argument for dependent variables,"A standard argument in empirical process theory leads to the following inequality: let $Z_1, \dots, Z_n$ be i.i.d random variables and let $g$ be a convex function. Then it holds that $$
\mathbb{E}\left[g\left( \sum_{i=1}^n Z_i  - \mathbb{E}[Z_i] \right)\right] \leq
2 \mathbb{E} \left[ g\left( \sum_{i=1}^n \varepsilon_i Z_i \right) \right]
$$ where $\varepsilon_1, \dots \varepsilon_n$ are i.i.d Rademacher variables. Question : is there a version of this argument when $Z_i$ are identically distributed but not necessarily independent?","['inequality', 'expectation', 'reference-request', 'empirical-processes', 'probability']"
2618778,Are there any ways to turn natural density into a measure?,"Natural density measures how fat a subset of natural numbers is. The definition can be seen in https://en.wikipedia.org/wiki/Natural_density#Definition . However, natural density is only a outer measure. Is there any ways to make it a measure? For example, would it be a measure under some domain restriction?","['number-theory', 'measure-theory']"
2618848,A Probability question: last ball in the bag,"Players are pulled up to pick a ball out of a hat containing $14$ red and $1$ blue. If the odds of drawing the blue ball are $1/15$ what are the odds of every person not drawing the blue ball and leaving it for the last person to draw? Initially I thought you would multiply the probability of not drawing the blue ball for each person and multiplying them together so i did $$\dfrac{14}{15} \times \dfrac{13}{14} \times \dfrac{12}{13} \times \cdots$$ But when I roughly calculate that, I get the same as $1/15$. Is this correct?",['probability']
2618856,A question regarding a central idempotent in a ring $R$,"I am trying to solve the problem: Question: In a ring $R$ with identity, if every idempotent is central, then prove that for $a, b \in R$, $$ab =1 \implies ba=1$$ I have done in the following manner:
$$ab=1\\
\implies b(ab)=b\\
\implies (ba)b-b=0\\
\implies (ba-1)b=0$$ Case 1: If $R$ contains no divisor of Zero then as $b \ne 0$ ,we get $$ba-1=0 \implies ba=1$$ Case 2: If $R$ contains divisor of Zeros then we may have $$ba-1\ne0\\
\implies ba\ne1\\
\implies (ab)a\ne a$$
But $ab=1$ hence $a\ne a$, an absurd condition. So $ba-1=0$ or $ba=1$. I think I have solved the problem but I haven't used the given conditions ""Every idempotent is central"". So I think there is something wrong which I have done but can't find out! Please rectify my mistake if I am wrong and provide any hint to solve it.","['abstract-algebra', 'ring-theory']"
2618886,Limit involving an arithmetic progression,"I have the following problem: Let $(a_n)_{n\geq1}$ be an arithmetic progression such that $0<a_1<a_2$. Find the limit of the sequence $$y_n=\frac{a_1}{a_2}\cdot\frac{a_3}{a_4}\cdot...\cdot\frac{a_{2n-1}}{a_{2n}}$$ It is not complicated to see that $y_n$ is decreasing and bounded, so it is convergent, but I can't find it's limit. It is clearly less than $\frac{a_1}{a_2}$. I tried using the AM-GM inequality but I obtained something trivial.","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2618905,Weighted average intuition,"Recently I came across the weighed average. I get how it works on a technical level. Maybe I'm a bit thick, but somehow I can't get a ""feel"" for it on an intuitive level. Let's just say we have two points on a line: |-----*-----------*--------->
0     A           B Now, we want to put a point $M$ somewhere between $A, B$ inclusive. If we want to put it at exactly at $A$, we can say $M = 1 \times A + 0 \times B$ If we want to put it at exactly at $B$, we can say $M = 0 \times A + 1 \times B$ That seems kind of obvious. What seems to somehow surprise me is, that for example, if we want to put it exactly between $A, B$, we can say $M = 0.5 \times A + 0.5 \times B$ Somehow I have a hard time grokking that this will put the point $M$ at the middle.","['intuition', 'statistics']"
2618920,Find the range of $x$ for the convergence of the series $\sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}$,"Question: Find the range of $x$ for the convergence of the series$$\sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}$$ MY Approach: By $n$th term divergence test,
$$\lim_{n\rightarrow\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}=0 \Longleftrightarrow |4x-12|<1\Longleftrightarrow\frac{11}{4}<x<\frac{13}{4},$$
not in the options. Edit","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2618951,An almost reverse triangle inequality involving two complex numbers,"Given two complex numbers $u$ and $v$, numerically it seems that
$$1+\vert u\vert +\vert v\vert\le \vert 1+u\vert +\vert 1+v\vert+\vert u+v\vert+\vert 1+u+v\vert\tag{$*$}$$
with equality holding for example when $(u=v=-1)$ Or $(u=\exp(\frac{2i\pi}{3}),v=\exp(\frac{4i\pi}{3}))$    but these are not the only cases. This inequality does not follow in a clear way to me from Hlawka's inequality, but it looks some how similar to a difficult inequality 
$$\vert u\vert +\vert v\vert\le \vert 1+u\vert +\vert 1+v\vert+\vert1+uv\vert$$
which was proved in this paper . I would appreciate any idea or help in proving $(*)$.","['complex-analysis', 'inequality']"
2618956,Proving that $\lim_{n\to\infty}\left ( \frac{2n-1}{2n+3} \right )^n=e^{-2}$ without using de l‘Hôspital,$$\lim_{n\to\infty}\left ( \frac{2n-1}{2n+3} \right )^n=\frac{1}{e^2}.$$ But how do I prove this without using de l'Hôspital twice?,"['real-analysis', 'limits-without-lhopital', 'limits']"
2618969,Is the total variation norm of a measure equal to its norm as a bounded functional?,"Let $X$ be a topological space and let $\mu$ be a Borel, regular measure, with finite total variation $\| \mu \| _{TV}$. One may view $\mu$ as a bounded linear functional on the Banach space $C_b (X)$ of the bounded continuous functions on $X$; as such, it has a norm given by $\| \mu \| = \sup _{\| f \| = 1} \left| \int _X f \ \mathrm d \mu \right|$. Are the two norms of $\mu$ equal? (In particular, an affirmative answer would clarify why the total variation norm has this slightly unintuitive definition.)","['functional-analysis', 'normed-spaces', 'banach-spaces', 'measure-theory']"
2618981,Meaning of notation $f(x)$ in set theory,"In my book, a function $f$ is defined as a binary relation such that if $(x,y),(x,z)\in f$ then $y=z$. Moreover, as it is usual, author denotes $(x,y)\in f$ by $$
y=f(x) .
\tag{1}
$$ So, from this notation, I understand $f(x)$ as the second component of the ordered pair $(x,y)\in f$, i.e $(x,f(x))$. Nevertheless, below, the author says that $f(x)=\bigcap\{y:(x,y)\in f\}$. But I think this notation is different from (1), since $$
\bigcap\{y:(x,y)\in f\} = \{z: \forall y:(x,y)\in f \Longrightarrow z\in y\} ,
$$ I mean, $\bigcap\{y:(x,y)\in f\}$ is a set of elements of the class $y$, not such a $y$. And, moreover, some other authors, as Herbert Enderton, define also $f(x)$ as the class $$
f(x)=\bigcup\{y:(x,y)\in f\} .
$$ How can be all these notations/definitions compatibles?","['elementary-set-theory', 'functions']"
2619017,Can find common principal open subsets in the intersection of two open affine subschemes,"Let $X$ be a scheme and let $U$ and $V$ be open affine subschemes, meaning that $(U,\mathcal{O}_X|_U) \cong (\mathrm{Spec}A, \mathcal{O}_{\mathrm{Spec}A})$ and $(V,\mathcal{O}_X|_V) \cong (\mathrm{Spec}B, \mathcal{O}_{\mathrm{Spec}B})$ for some rings $A$ and $B$. Assume that the intersection $U \cap V$ is not empty, hence it is an open subscheme of $U,V$ and $X$ (not necessarily affine). Is it possible to say that we can find principal open subsets $D(f) = \tilde{D}(g) \subseteq U \cap V$ that cover $U\cap V$ and that are both principal for $A$ (which means that $D(f) \cong \mathrm{Spec}A_f$) and at the same time for $B$ (hence $\tilde{D}(g) \cong \mathrm{Spec}B_g$)? It is certainly the case that we can do both things, but I fail to see why they can be done ""simultaneously"". (This argument is used, for instance, in the proof of proposition 3.2.2, page 88 of Q. Liu's ""Algebraic geometry and arithmetic curves"").","['affine-schemes', 'algebraic-geometry']"
2619021,Why is $\underbrace {i^{i^{i^{.^{.^{.^{i}}}}}}}_{n \ times}$ converging? [duplicate],"This question already has answers here : Convergence properties of $z^{z^{z^{...}}}$ and is it ""chaotic"" (3 answers) Closed 6 years ago . Introduction: Recently I found out that $i^i \approx 0.20788$ has no imaginary part. I got interested and then wanted to know whether there are other $n$ for which $\underbrace {i^{i^{i^{.^{.^{.^{i}}}}}}}_{n \ times}$ has no inaginary part. So I wrote this python script (I'm a beginner at python, could be very bad code :) which plots what I call the $i-Tower\ up\ to\ n = 100$. It looks like this: Question: Let's use this convention: ${}^ni = \underbrace{i^{i^{i^{.^{.^{.^{i}}}}}}}_{n \ times}$. Why is the sequence ${}^ni\ |\ n \in \mathbb{N}$ converging? ${}^{20}i \approx 0.48770 + 0.41217i$ ${}^{60}i \approx 0.437584 + 0.360535i$ ${}^{100}i \approx 0.43829+ 0.36059i$ What I already noticed is that the angle between the lines you can draw from ${}^ni$ over ${}^{n+1}i$ to ${}^{n+2}i$ is $<90°$. Is that angle equal for all $n$? Is there a way to give the exact value of $x = {}^ni \ $with$\ {n \rightarrow \infty}$? What is the connection between $i$ and $x$. Is $x$ a special complex number that is maybe already known or comes up in other places?","['tetration', 'sequences-and-series', 'complex-numbers']"
2619022,Why can the determinant be assumed to be 0?,"I'm trying to work through how to calculate eigenvalues and eigenvectors. I start with $$Ax=\lambda x$$ Where $A$ is a $p \times p$ matrix, $\lambda$ is the eigenvalue and $x$ is the eigenvector. This is the same as: $$Ax=I\lambda x$$ $$Ax-I\lambda x=0$$ $$(A-I\lambda) x=0$$ We define the matrix $A$ as a $2 \times 2$ matrix: $\begin{bmatrix}4 & -2\\-3 & 6\end{bmatrix}$ Thus this -$I\lambda$ equals $\begin{bmatrix}4-\lambda & -2\\-3 & 6-\lambda\end{bmatrix}$ $$Det(A-I\lambda)=(4-\lambda(6-\lambda)-(-3)*-2)$$ $$Det(A-I\lambda)=24-10\lambda +\lambda^2 -6$$
$$Det(A-I\lambda)=18 - 10\lambda + \lambda^2 $$ Then, out of the blue my textbook claims that $$0=30 - 10\lambda + \lambda^2 $$ How do I justify setting the determinant to $0$? (I do ""not"" have an advanced knowledge in linear algebraic analysis, I only know how the determinant is used to calculate the inverse matrix)","['eigenvalues-eigenvectors', 'statistics', 'linear-algebra', 'determinant']"
2619050,Question on whether the Lebesgue measure of this set is strictly positive,"Let $\;f:\mathbb R \times \mathbb R^{n-1} \to \mathbb R^m\;$ be a continuous function and consider some bounded, non-closed and with compact closure set  $\;\mathcal A\subset L^2(\mathbb R;\mathbb R^m)\;$ which consists of continuous functions $\;g:\mathbb R \to \mathbb R^m\;$. We denote $\;d(f(\cdot,y),\mathcal A)=inf_{\;g\in \mathcal A\;} {\vert \vert
 f(x,y)-g(x) \vert \vert}_{L^2}\;$ and $\;B^{n-1}_R(y_0)\;$ stands for a ball in
 $\;\mathbb R^{n-1}\;$ of centre $\;y_0\;$ and radius $\;R\;$ Question: if $\;d(f(\cdot,y_0),\mathcal A)\gt 0\;$ for some $\;y_0 \in \mathbb R^{n-1}\;$ then is it true to claim that $\;\mathcal L^{n-1}(B^{n-1}_R(y_0) \cap \{y: d(f(\cdot,y),\mathcal A) \ge C \gt 0\})\gt 0\;$? My Attempt: Since $\;\exists y_0 \in \mathbb R^{n-1}\;$ such that $\;d(f(\cdot,y_0),\mathcal A) \gt 0\;$ the set $\;B^{n-1}_R(y_0) \cap \{y: d(f(\cdot,y),\mathcal A) \ge C \gt 0\}\;$ must be non-empty. In addition, due to continuity of $\;f\;$, there should be a neighborhood of $\;y_0\;$(let me denote it as $\;\mathcal N(y_0)\;$) in which $\;d(f(\cdot,y),\mathcal A) \ge C \gt 0\;,\forall y \in \mathcal N(y_0)\;$ Hence, if I could claim that $\;\mathcal N(y_0):=B^{n-1}_R(y_0) \cap \{y: d(f(\cdot,y),\mathcal A) \ge C \gt 0\}\;$, the question would be answered immediately taking this into account. However as I know, a neighborhood is an open set so I'm a bit unsure if I can claim the above since I can't see whether $\;B^{n-1}_R(y_0) \cap \{y: d(f(\cdot,y),\mathcal A) \ge C \gt 0\}\;$ is a Borel one. It's been a really long time since I had my Measure Theory course so I apologize in advance if my question is quite elementary. I would appreciate if somebody could help me understand what I'm missing here. Thanks a lot!","['real-analysis', 'lebesgue-measure', 'functional-analysis', 'measure-theory', 'general-topology']"
2619070,Positive-definiteness of the Schur Complement,"Let $M$ to be a real-valued symmetric and positive-definite (PD) matrix (also sparse and banded if it helps) $$
M=
\begin{bmatrix}
A & B\\ B^T & D
\end{bmatrix}
$$ Under what conditions the Schur complement of $M$ ( $S=D-B^T A^{-1} B$) is PD? As far as I found, it holds if $M$ and $A$ are both PD. If this is true, how can say if $A$ is PD?","['matrices', 'positive-definite', 'linear-algebra', 'schur-complement']"
2619101,Variance of sum of $10$ random variables.,"Find the variance of sum of $10$ random variables if each has variance $5$ and if each pair has a correlation coefficient $.5$ Let $Y=X_1+X_2+X_3+\ldots+X_{10}$ I tried this problem by calculating variance of first $10$  random variables.
$V(Y)=50$. Then there will be $45$ pairs of covariance terms. Correlation coefficient $\rho=.5$ $Cov(X_i,X_j)=2.5 $ Which  gives variance $V(Y)=50+2.5=52.5$ Did i do everything right, please someone tell me.","['statistics', 'probability']"
2619116,Motivation behind the Krull Dimension of a ring,"I have been studying the Krull Dimensions of rings and have a couple of questions: Why is the concept of Krull dimensions important within algebraic geometry? I have also been proving the result that the Krull dimension of the polynomial ring $K[X_1,...,X_n]$ is equal to $n$ when $K$ is a field. Why is this result in particularly important? In other words, why do we care about this result? If anyone has any information/references on this, I would find it very interesting. Note: Not references on the proof as I have been able to complete this! Thanks, Johan","['algebraic-geometry', 'abstract-algebra', 'krull-dimension', 'ring-theory', 'commutative-algebra']"
2619131,How can one prove that this polynomial is non-negative?,How one can prove the following inequality? $$58x^{10}-42x^9+11x^8+42x^7+53x^6-160x^5+118x^4+22x^3-56x^2-20x+74\geq 0$$ I plotted the graph on Wolfram Alpha and found that the inequality seems to hold. I was unable to represent the polynomial as a sum of squares. It looks quite boring to approximate the derivative to be zero and use some numerical methods to show that values near local minimums proves that the inequality really holds everywhere.,"['inequality', 'polynomials', 'real-algebraic-geometry', 'algebra-precalculus', 'sum-of-squares-method']"
2619155,Adjunction isomorphism in algebraic geometry,"Let $C$ be a nonsingular curve over a field $k$, and let $\delta: C\to C\times C$ be the diagonal (closed) embedding whose image is: $$\Delta:=\{(x,x)\colon x\in C\}\,.$$ Now $\Delta$ is a divisor in $C\times C$ so we have the line bundle $\mathscr O_{C\times C}(-\Delta)$. I don't understand the following isomorphism of invertible sheaves on $C$: $$\Omega^1_C\cong \delta^\ast(\mathscr O_{C\times C}(-\Delta))$$ By the theory of differentials we know that  $\Omega^1_C\cong \delta^\ast(\mathcal I/\mathcal I^2)$ where $\mathcal I$ is the kernel of the canonical map 
$$\delta^\#:\mathscr O_{C\times C}\to \delta_\ast \mathscr O_C\,.$$
Now I really don't get why we have the isomorphism $\delta^\ast(\mathscr O_{C\times C}(-\Delta))\cong\delta^\ast(\mathcal I/\mathcal I^2)$.","['algebraic-curves', 'coherent-sheaves', 'schemes', 'algebraic-geometry']"
2619173,A flow of a parallel vector field preserves the connection?,"Let $M$ be a closed manifold equipped with an affine connection $\nabla$.
Let $X \in \Gamma(TM)$, and suppose $X$ is a parallel vector field, i.e. $\nabla X=0$. Is it true that the flow of $X$ preserves the connection? i.e. let $\phi_t$ be the flow of $X$. Is it true that $\phi_t^* \nabla=\nabla$? Here, for a given diffeomorphism $\phi:M \to M$, I define $\phi^* \nabla$ by requiring $$ \phi_*\big((\phi^* \nabla)_XY\big)= \nabla_{\phi_* X}\phi_* Y,$$
where $\phi_*$ is the pushforward operation. (I think this is the 'right' definition). What about the converse, that is suppose that $\phi_t^* \nabla=\nabla$. Is $X$ parallel? I am not sure how to compute the 'variational derivative' $\frac{d}{dt}|_{t=0}\phi_t^* \nabla$.","['riemannian-geometry', 'differential-geometry', 'calculus-of-variations', 'vector-bundles', 'connections']"
2619176,Chern-Weil homomorphism and Chern/Pontryagin/Euler class,"I am reading Chapter on characteristic classes from Foundations of Differential geometry by Kobayashi and Nomizu. This chapter starts with concept of Chern-Weil homomorphism. Given a Lie algebra $G$ with $\mathfrak{g}$ as its Lie algebra and a principal $G$ bundle $P(M,G)$ chern Weil homomorphism is a map from $I(G)\rightarrow H^*(M,\mathbb{R})$ where $I(G)$ is the algebra of symmetric multilinear mappings on $\mathfrak{g}$ invariant by $G$ and $H^*(M;\mathbb{R})$ is the deRham cohomology algebra on $M$.  This they define fixing a connection and then proves this map is independent of choice of connection. I am able to understand this. Can some one help me to understand how this Chern-Weil homomorphism is involved in understanding about chern/Pontryagin/Euler classes? Any reference that explains motivation on these characteristic classes is also welcome. I am aware of Milnor’s book.","['characteristic-classes', 'de-rham-cohomology', 'differential-geometry']"
2619196,Solving a differential equation with a complex number as a coefficient,"I am trying to solve the following differential equation;
\begin{equation}
y'' - iy = 0
\end{equation}
By following the usual method of solving, I get my characteristic equation $\lambda^{2} - i = 0$, which then gives me the general solution of 
\begin{equation}
y = cos(\sqrt{i}x) + sin(\sqrt{i}x)
\end{equation}
I want to know if there is any way I can remove the $i$ term from inside the brackets as to get real solutions. I have tried using an expression for $e^{ix}$ but cannot cancel out the $i$ and the $\sqrt{i}$ I also tried this with a similar ODE, as shown below,
\begin{equation}
y'' + iy = 0
\end{equation}
Where I got a characteristic equation of $\lambda^{2} + i = 0$, giving me a general solution of
\begin{equation}
y=e^{i\sqrt{i}x} + e^{-i\sqrt{i}x}
\end{equation}
However, I am still not sure how to cancel this out so that in cos/sin form I have no complex term inside the brackets. Boundary conditions do not affect the problem at this stage - I'm simply interested in removing the complex term from the brackets. I hope this is clear enough - any help would be appreciated.","['ordinary-differential-equations', 'complex-numbers']"
2619204,Almost sure convergence of posterior distribution to parameter,"I'm trying to solve an exercise form Rick Durrett's book on probability, following  a section on almost sure convergence of martingales: Let $Z_1,Z_2,...$ be i.i.d standard normal random variables, let $\theta$ be an independent random variable with finite mean, and let $Y_i:=Z_i+\theta$. $\;$ Show that $\mathbb{E}[\theta \vert Y_1,...,Y_n] \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I know that $\mathbb{E}\Big[ \frac{1}{n} \sum_{i=1}^n Y_i \Big \vert Y_1,...,Y_n \Big]=  \frac{1}{n} \sum_{i=1}^nY_i$, and that by the strong law of large numbers we know that $\frac{1}{n} \sum_{i=1}^nY_i \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I'm unsure as to how best to proceed from here, or in fact how to use the independence of $\theta$. $\;$ I would appreciate any help or hints.","['conditional-expectation', 'probability', 'martingales']"
2619240,Show that $\hat{\theta}$ is not minimax.,"Let $\hat{\theta}$ be an unbiased estimator of an unknown parameter $\theta\in\mathbb{R}$. Assuming $\theta\neq 0$ we have the following loss function $$L(\theta,a) = \dfrac{(a - \theta)^2}{\theta^2}$$ Exercise: Assume that $0\leq R(\theta,T) <\infty$ for any estimator $T$. Show that $\hat{\theta}$ is not minimax. Given solution: We consider an estimator $T = c\hat{\theta}$. In this case the risk function is given by $$R(\theta, c\hat\theta) = \operatorname{E}_\theta\bigg[\dfrac{(c\hat\theta - \theta)^2}{\theta^2}\bigg]  \\= (1-c)^2 + c^2R(\theta,\hat\theta)$$ where the second term vanishes because $R(\theta, \hat\theta) = 0$, as $\hat\theta$ is unbiased. We look for a constant $c$ such that $$\sup_{\theta \in \mathbb{R}}R(\theta, c\hat\theta) < \sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta),$$ which is equivalent to \begin{equation}\sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta) > \dfrac{(1-c)^2}{1-c^2} = \dfrac{1-c}{1+c} =:g(c).\tag{1}\end{equation} Since $g:[0,1]\to[0,1]$ is continuous and decreasing, $(1)$ holds for all $c\in(0,1)$ if $\sup_\theta R(\theta,\hat\theta_n) > 1.$ If $\sup_\theta R(\theta,\hat\theta_n) \leq 1$, then there exists a $c^{*}$ such that $(1)$ holds for all $c\geq c^{*}$. What I don't understand about this solution: We have that $R(\theta, \hat\theta) = 0$ since $\hat\theta$ is unbiased, and $(R,c\hat\theta) = c^2 - 2c + 1$, as is indicated in the solution. Now, $c^2 -2c + 1 \geq 0,$ so there is no $c^{*}$ such that $R(\theta, c\hat\theta) < R(\theta, \hat\theta).$ Obviously I'm missing something, as I don't understand the subscript $n$ that is used in the last few lines in the solution. It seems to me that since in this solution $R(\theta,\hat\theta)$ can be larger than zero, $R(\theta,\hat\theta)$ depends on $\theta$. Question: Is the given solution correct? If so; what's wrong with my reasoning? How can $R(\theta, \hat\theta)> 0$? Thanks!","['statistical-inference', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2619251,Wave equation with Robin and Neumann boundary conditions,"What are the periodic solutions of the following problem: Governing equation (wave equation): $u_{tt} - c^2 u_{xx} = 0 $, $\forall x\in[0;L]$, $\forall t\geq 0$ Robin boundary conditions at $x=0$: $u_x(0,t) = k u(0,t)$, $\forall t\geq 0$ Neumann boundary conditions at $x=L$: $u_x(L,t)=0$, $\forall t\geq 0$ where $k$ is a constant and $c=\sqrt{E/\rho}$.","['wave-equation', 'ordinary-differential-equations', 'partial-differential-equations']"
2619258,"Why is that if every row of a matrix sums to 1, then the rows of the inverse matrix sums to 1 too?","Why is that if every row of a matrix sums to $1$ then the rows of its inverse matrix sum to $1$ too? For example, consider $$A=\begin{pmatrix}
1/3 & 2/3 \\
3/4 & 1/4
\end{pmatrix}$$ then its inverse is $$A^{-1}=\begin{pmatrix}
-3/5 & 8/5 \\
9/5 & -4/5
\end{pmatrix},$$ which satisfies the condition. Is it true for every such matrix?","['matrices', 'linear-algebra', 'inverse']"
2619345,The even-index reciprocal Lucas constant and $\sum_{n=1}^\infty \frac1{x_1^{2n}+x_2^{2n}}$,"The sum of reciprocals of even index Lucas numbers has a nice closed-form in terms of theta functions,
$$\begin{aligned}S_e 
&= \sum_{n=1}^\infty \frac1{L_{2n}}\\
&= \sum_{n=1}^\infty \frac1{\phi^{2n}+\phi^{-2n}}\\
&= \tfrac14\Big(\vartheta_3^2(\phi^{-2})-1\Big)\\
&= 0.56617\dots
\end{aligned}$$ with golden ratio $\phi$ and Jacobi theta function $\vartheta_3(q)$. However, it seems this is just a special case. Given the root $x_1>0$ and $x_2<0$ of the quadratic,
$$x^2+bx-1=0$$ Is it true that,
  $$\sum_{n=1}^\infty \frac1{x_1^{2kn}+x_2^{2kn}} = \tfrac14\Big(\vartheta_3^2(x_1^{-2k})-1\Big) $$
  for any integer $k>0$, and where the Lucas numbers was just $b=-1$?","['theta-functions', 'golden-ratio', 'sequences-and-series']"
2619437,Proving the relation $xy=m^2$ is an equivalence relation,"The question states that $R$ is a relation on $\mathbb{N}$ (excluding $0$) if and only if $xy = m^2$ with $m \in \mathbb{N}$. It asks to prove that it is an equivalence relation. I showed that it is reflexive as $xx=x^2$ and we know that $x \in \mathbb{N}$. I showed symmetry by using the fact that multiplication is commutative so $xy=yx$ thus if $xy$ is in the relation so is $yx$. I'm having some trouble with showing that it is transitive.
I know that to show if a relation is transitive then $(x,y) \in R \land(y,z) \in R \implies (x,z) \in R$. How do i show this for this example?","['relations', 'discrete-mathematics']"
2619481,Is a vector field a mathematical field?,"I would like to ask if a vector field is  mathematical field which is defined to be  a set on which addition, subtraction, multiplication, and division are defined, and behave as when they are applied to rational and real numbers. I can see that a vector field satisfies addition, subtraction, multiplication but I am not sure about division. Is this just terminology or is a vector field a field in the mathematical sense?","['vector-fields', 'field-theory', 'differential-geometry', 'definition']"
2619509,Looking for complex roots of unity which also happen to be complex primes,"Can someone point me to resources that could either give examples of complex roots of unity which also happen to be complex primes (Eisenstein primes, Gauss primes, or any other type if they exist) or a proof that such complex numbers can’t exist? Have searched google but couldn’t find information on such intersection of the two types of complex numbers. Thanks!","['complex-numbers', 'prime-factorization', 'number-theory', 'complex-analysis', 'prime-numbers']"
2619530,"How many solutions in integers are there to the equation $𝑋_1+𝑋_2+⋯+𝑋_{500}=340$ , such that for every $𝑖: 0≤𝑋_𝑖≤1$?","How many solutions in integers are there to the equation $𝑋_1+𝑋_2+⋯+𝑋_{500}=340$ , such that for every $𝑖: 0≤𝑋_𝑖≤1$? At first I tried using the inclusion exclusion principle, as in: 340 balls spreaded into 500 compartments s.t every compartment can get zero or one balls. Not sure how to proceed from here..","['combinatorics', 'discrete-mathematics']"
2619541,Does the absence of explicit probability space hinder the empirical application of statistical theory based on measure theory?,"To motivate my question, I start off with a very simple example of prediction problem. Let's say Mike is interested in predicting the crime rate, which we denote as the random variable $y$, in the cities. And Mike identifies an array of available variables in play, which we denote as the random vector $\mathbf{x}$. Then we proceed by imposing various assumptions or using various approximation strategies to find a good approximation of the conditional expectation function $\mathbb{E}[y\mid\mathbf{x}]$. It all seems to be a legitimate way to model the problem of predicting the crime rate in cities as a mathematical problem. However, one important definition is left unspecified, that is, what exactly is $y$ and $\mathbf{x}$. Sure, they are functions from the sample space $\Omega$ to the set of reals $\mathbb{R}$. But what is this $\Omega$? Most literature in statistical theory and econometrics theory does not attempt to explicitly specify them. The only times the sample space is specified is when we are doing toy examples like infinite coin tossing for learning purposes. But of course, I understand in order to transform real world problems to mathematical models, we need to make assumptions. And in this case, we should in fact just assume the existence of a probability space where everything that any random variables that will ever come into play are measurable. And use real world data as realizations of these random variables to make inferences on certain relationships between random variables defined on this probability space. However, not being able to get a glimpse into the sample space and working with functions whose domain we don't even know make me feel like I am not on a solid footing here. I have asked some people who seem to suggest in this case the $\Omega$ can be defined as the set of all possible states of a city. But how can one describe precisely the meaning of ""possible states"" here? How large is this set? I mean, we can't even describe an element of that set in precise language. There are also similar issues with defining our $\sigma$-algebra. Should we define it as the $\sigma-$algebra generated by all random variables? But then how many and what random variables should we even include as the generating set of random variables? With all these in mind, what are some of the philosophical or mathematical reasons we assume such an appropriate probability space exist except mathematical convenience, and does the absence of a explicit probability space hinder the philosophical or mathematical soundness of empirical application of statistical theory based on measure theory? Finally, are there alternative theories of estimation and prediction that tries to address this issue of not being explicit (if this is an issue)?","['probability-theory', 'statistics']"
2619558,Calculating standard deviation without a data set.,"I know how to calculate SD when given data points by using: $ \displaystyle \mathrm{SD} = \sqrt{\sum(x^2 - \text{mean}^2) / n} $. I have been given just the sum of $x$ and sum of $x^2$. How do I calculate SD from this?! An example question I am stuck on:
Sum of $x = 1303$ Sum of $x^2 = 123557.$ There are 14 years for which the data is given - I would assume this is n...","['means', 'statistics', 'standard-deviation']"
2619560,"Setting up bounds for the integral $(\int_{U}|f(x,y)|^{2}dxdy)^{\frac{1}{2}}$?","In the text ""Functions of a Complex Variable"" by Robert E.Grenne and Steven G. Knartz I'm having the trouble with figuring out a method of attack for $\text{Proposition (1.1)}$ specifically getting the integral $(\int_{U}|f(x,y)|dxdy)^{\frac{1}{2}}$ into a more manageable form, may I have a hint to achieve this ? $\text{Proposition (1.1)}$ Let $U \subset \mathbb{C}$ be an open set and let $K$ be a compact subset $U$. Show that there is a constant $C$ $\text{(depending on U and K)}$ such that if $f$ is holomorphic on $U$, then in $(1.2)$ $(1.2)$ $$\sup_{K}|f| \leq C \cdot \big(\int_{U}|f(x,y)|^{2}dxdy \big)^{\frac{1}{2}}$$",['complex-analysis']
2619568,$\exists c>0$ such that $ (z-x)\int_z^y{f(t)dt} - (y-z)\int_x^z{f(t)dt \geq c(z-x)(y-z)}$,"Let $f:[a,b] \to \mathbb{R}$ be a strictly increasing function. Prove that, $\forall x, y \in [a,b], x \leq y, \exists c > 0$ such that $$ \displaystyle{(z-x)\int_z^y{f(t)dt} - (y-z)\int_x^z{f(t)dt \geq c(z-x)(y-z)}},$$ $ \forall z \in [x,y]. $ The inequality is equivalent with $ \displaystyle{\frac{\int_z^y{f(t)dt}}{y-z} - \frac{\int_x^z{f(t)dt}}{z-x} \geq c, \forall z \in [x,y]. }$ My assumption is that $\displaystyle{c = \inf_{z \in [x,y]} {\frac{\int_z^y{f(t)dt}}{y-z} - \frac{\int_x^z{f(t)dt}}{z-x}}}$, but I don't know how to prove that this infimum is not $0$. I also tried using Riemann sums for the intervals $[x,z]$ and $[z,y]$, but I didn't manage to solve the problem.","['real-analysis', 'integration', 'definite-integrals', 'integral-inequality']"
2619583,Evaluate a determinant with $\sin$,"Evaluate $$\begin{vmatrix} \sin x_1 & \sin x_2 & \dots & \sin x_n \\
\sin 2x_1 & \sin 2x_2 & \dots & \sin 2x_n \\
\vdots & \vdots & & \vdots \\
\sin nx_1 & \sin nx_2 & \dots & \sin nx_n
\end{vmatrix}$$
  where $x_1,x_2,\dots,x_n \in \mathbb{R}$. I tried to somehow expand $\sin kx_i$ in terms of $\sin x_i$ and $\cos x_i$, but things got really complicated and I couldn't go further. Also, I tried substracting the first column from the others, but nothing came out of it.","['matrices', 'linear-algebra', 'determinant']"
2619591,Are all disjoint events dependent?,"This is a basic question about probability theory. My reasoning goes as follows: If $A$ and $B$ are independent events, the probability they both happen is their multiplication: 
$$\Pr(A \text{ and } B) = \Pr(A) \times \Pr(B)$$ If their marginal probability is not impossible, also their product is non-zero:
$$\Pr(A) > 0,\, \Pr(B) > 0 \implies \Pr(A \text{ and } B) > 0$$ Hence, independent events cannot be disjoint Hence, only dependent events can be disjoint Hence, all disjoint events are dependent. Can you help me point out the error in my argument?","['probability-theory', 'probability']"
2619629,Solving of enhanced Hull-White $dX_t = \frac{e^t-X_t}{t-2}dt + tdW_t$,"I have the following SDE and I would like to check if the solution ,  i.e. the explicit form for $X_t$ that I gave is either wrong or false.
$$dX_t = \frac{e^t-X_t}{t-2}dt + tdW_t$$ with $t \in [0,2] $ and $X_0 = 0$ and $W_t$ is a brownian motion. I supppose it is a modified SDE of Hull-White but with a coefficient on $X_t$ depending on time. For my own readability I wrote the equation as follow, hoping it would be easy to plug the coefficients of each term in the solution for the general Linear SDE :
$$ dX_t =\bigg( \frac{-X_t}{t-2} + \frac{e^t}{t-2} \bigg)dt + tdW_t$$ I tried to start with the process $Y_t =  e^{\int_0^t \frac{-1}{s-2}ds}X_t$ and apply Ito to it.
Solving the integral in the exponential I get: 
$$Y_t  =e^{-log(|2-t|)+log(|2|)}X_t = \frac{2}{2-t}X_t \tag{1}$$ I calculate its differential by applying Ito's lemma:
$dY_t = \bigg( \frac{\partial f}{\partial t} + \frac{\partial f}{\partial x} \mu_X+ \frac{1}{2}\frac{\partial ^2f}{\partial x^2}\sigma^2_X \bigg)dt + \bigg( \frac{\partial f}{\partial x}\sigma_X \bigg)$ with $ \mu_X$ and $ \sigma_X$  defined in : $dX_t = \mu_X dt + \sigma_X dW_t $ From the relation $(1)$ the  partial derivatives are : 
$\frac{\partial f}{\partial t} = \frac{-2}{(2-t)^2}, \frac{\partial f}{\partial x} = \frac{2}{2-t} , \frac{\partial ^2f}{\partial x^2} = 0$ Finally : $$dY_t = \frac{-2}{(2-t)^2} X_tdt + \frac{2}{2-t} \bigg[ \big( \frac{-X_t}{t-2} + \frac{e^{t}}{t-2} \big)dt  \bigg]+ \frac{2}{2-t}tdW_t$$ The terms in $X_t$ simplify each other and so integrating both LHS and RHS is feasible :
$$Y_t - Y_0 = \int_0^t \frac{2}{2-s} \frac{e^{s}}{s-2}ds + \int_0^t \frac{2}{2-s}sdW_s$$ From $ (1) $ and the initial $X_0 = 0$ we know that $Y_0 = 0$ and replacing $Y_t$ by its value in $(1)$ :
$$X_t = \int_0^t \frac{2}{2-s} \frac{e^{s}}{s-2}ds + \int_0^t \frac{2}{2-s}sdW_s$$ And now I don't know what I can do to see if it is a correct solution. 
N.B. : Also I feel like I miss some perspective here, so any comments on form   or context is still appreciated.","['probability-theory', 'stochastic-integrals', 'brownian-motion', 'stochastic-calculus', 'stochastic-differential-equations']"
2619637,Why does my textbook give this solution of $\cos^{-1}$ when it should be $\sin^{-1}$?,"In my textbook we are trying to solve this separation of variables equation: $$\int {dz\over \sqrt{B^2-z^2}} = \int d\theta$$ Without any explanation the solution is: $$\cos^{-1}\Big( {z\over B} \Big)=\theta-\theta_0$$ But shouldn't it be $\sin^{-1}?$ All of this is going towards trying to find the equation for gravitational potential, the rest of the work I understand but this part is confusing to me. I know that $\cos^{-1}={\pi\over 2}-\sin^{-1}$, but I don't see how they applied it here. Seeing as this is a physics textbook and not a math one I'm not surprised they don't give any explanation, but even Wolfram gives me a different answer which uses $\tan^{-1}$. Is this the right answer? If so, how did the authors get it? Edit: The book does give a value for $B$: $$\Big( {mE\over L^2} \Big){\sqrt{1-{{2\beta L^2\over mE^2}}}} $$ So according to the book $B$ is not negative or an absolute value. Using this information makes it hard for me to find a way to make the integral negative so I can use $\cos^{-1}$","['multivariable-calculus', 'ordinary-differential-equations', 'calculus']"
2619665,If $f$ is bounded then solutions of ODE are defined for all time?,"Let's say we have the following Cauchy Problem: $x' = f(t,x)$ $x(t_0) = x_0$ Is this statement true? If $\exists$ $K$ such that $||f(t,x)|| \leq K$ for all $(t,x) \in R \times R^n$ $\implies $ The solution is defined for all time",['ordinary-differential-equations']
2619740,Zeta regularization vs Dirichlet series,"Suppose you have a sequence of real numbers, denoted $a_n$. Then the sum of the sequence is $\sum_n a_n$ If this is divergent, we can use zeta regularization to get a sum. We can do this by defining the function $\zeta_A(s) = \sum_n a_n^{-s}$ and then analytically continue to the case where $s=-1$. A different approach is to define the Dirichlet series $A(s) = \sum_n \frac{a_n}{n^s}$ and then analytically continue to the case where $s=0$. $Questions:$ When these two approaches are both defined, are they guaranteed to agree on the result? If not, for which sequences do they agree? If they are compatible, is the second summation method strictly stronger than the first? For instance, it is clear that the first method can't do anything for the series $1+1+1+1+1+...$, whereas the second method yields -1/2, so it is at least as strong as the first.","['dirichlet-series', 'summation-method', 'zeta-functions', 'regularization', 'sequences-and-series']"
2619741,"How do you show $f(x,y)=\left( \frac{x}{x^2+y^2},\frac{y}{x^2+y^2}\right)$ is a diffeomorphism?","Given this mapping:$$f(x,y)=\left( \frac{x}{x^2+y^2},\frac{y}{x^2+y^2}\right), \quad (x,y)  \in \mathbb{R}^2$$ $$(\mathbb{R}^2= \{ (x,y):x,y \text{   are real numbers}, \text{ excluding } (x,y)=(0,0) \})$$ How do you check if it is a diffeomorphism? I would say $f$ is continuous on the given domain... now to how would you check for differentiability? Is it true to say that if the determinant of the Jacobian matrix is non-zero for all $(x,y)$ in the given domain then f is differentiable and therefore a diffeomorphism? This is a specific function that is its own inverse but considering a function that wasn't its own inverse does the fact that the determinant of the Jacobian matrix being non-zero (and existing) for the whole domain show that the inverse function exists without restricting the domain?","['multivariable-calculus', 'real-analysis', 'differential-geometry', 'analysis']"
2619773,What's the fastest growing function known to contain infinitely many primes?,"I know that Dirichlet's Theorem says that for every $a,b\in\mathbb{N}$ with $\gcd(a,b)=1$ and $a\ge 1$ the function
\begin{align*}
f:\mathbb{N}&\to\mathbb{N}\\
n&\mapsto an+b
\end{align*}
evaluates to a prime number for infinitely many $n\in\mathbb{N}$. However, we don't know whether there are any quadratic polynomials containing infinitely many prime numbers. This made me wonder: What is the fastest growing non-decreasing function $f:\mathbb{N}\to\mathbb{N}$, for which $f(n)$ is computable in $O(\log n)$ and $\{f(n):n\in\mathbb{N}\}$ is known to contain infinitely many primes?","['number-theory', 'reference-request', 'prime-numbers', 'elementary-number-theory']"
2619787,$\int\limits_{-\infty}^\infty \frac{1}{e^{x^{2}}+1}dx$,"I am trying to solve $$\int\limits_{-\infty}^\infty \frac{1}{e^{x^{2}}+1}dx$$ Process: First define a contour $\Gamma$ as a semi-circle with radius $R$. So $$\int_{\Gamma}\frac{1}{e^{x^{2}}+1}dx=\int_{Arc}\frac{1}{e^{x^{2}}+1}dx+\int_{-\infty}^\infty\frac{1}{e^{x^{2}}+1}dx$$ $$\int_{Arc}\frac{1}{e^{x^{2}}+1}dx=\int_{0}^\pi \frac{iRe^{i\theta}}{e^{{Re^{i\theta}}^{2}}+1}d\theta$$ As $R\to\infty$,  $\int_{Arc}\to0$. $$\int_{\Gamma}\frac{1}{e^{x^{2}}+1}dx=\int_{-\infty}^\infty\frac{1}{e^{x^{2}}+1}dx$$ $$\int_{\Gamma}\frac{1}{e^{x^{2}}+1}dx=2\pi i\sum \rm Res$$ $\frac{1}{e^{x^{2}}+1}$ has first order poles at $\sqrt{\pm (2n+1)\pi i}$ so using L'Hopital's the residues become $$-\frac{1}{2\sqrt{\pm (2n+1)\pi i}}$$ So
$$\int_{-\infty}^\infty\frac{1}{e^{x^{2}}+1}dx=-\sqrt{\pi i}\sum\frac{1}{\sqrt{\pm (2n+1)}}$$ However, this is where I run into a problem since I get a complex answer whereas the integral should be a real value. If anyone can tell me where I went wrong and the actual value of the integral I would greatly appreciate it.","['residue-calculus', 'calculus', 'complex-analysis', 'improper-integrals', 'contour-integration']"
2619815,Why an ordered pair gives a torus?,"I saw a video ( Who cares about topology ) that explained the inscribed square problem.  The problem say's that you have a simple closed loop in the plane, prove that there's at least one square such that all vertices are in the loop. But I didn't understand a part of it. In the video they say that if you take an ordered pair of points that are in the loop, you can map it to a specific point in a torus. Then he show's that the same can be say for unordered pairs, but in a Möbius strip. But, by that logic, Isn't possible to just glue two mobius strips (A and B) by their side, such that the pair of points (a,b) is in A, and (b,a) is on B. What's the problem with that? Why a torus and not a Klein bottle?","['general-topology', 'klein-bottle']"
2619817,Prove Brownian Bridge is Sampling Without Replacement,"Let's say we have a bowl containing $n$ many $+1$ 's and $n$ many $-1$ 's. You sample numbers from the bowl randomly without replacing. Let $k_1^{(n)}, k_2^{(n)}, ..., k_{2n}^{(n)}$ denote the random sequence of numbers from the process of sampling. Let the partial sum process: $$S_0=0 \; , \; S_a=\sum_{i=1}^a k_i^{(n)} \; , \; 1\leq a\leq 2n$$ We can define a sequence of continuous processes by scaling time and space via Donsker's theorem $$X_{\frac{a}{2n}}^{(n)} = \frac{S_a}{\sqrt{n}} \; , \; a=0,1,2,...,2n$$ by linearly interpolating we get $$X_{t}^{(n)} = X^{(n)}_{\frac{\lfloor 2nt\rfloor}{n}} + \frac{nt-\lfloor nt\rfloor}{\sqrt{n}} k_{\lfloor 2nt\rfloor+1}^{(n)} \; , \; 0 \leq t\leq1$$ How can we prove that the process $X^{(n)}$ converges weakly to a constant multiple of the standard Brownian bridge?","['probability-theory', 'functional-analysis', 'weak-convergence', 'measure-theory', 'brownian-motion']"
2619854,Does every polynomial with a Perron root have a primitive matrix representation?,Let $p(x)=x^6-13x^4-20x^3+x^2-x+2$ and $C$ be the companion matrix of $p(x)$. How can I find a primitive matrix similar to $C$ ? Is there a general method  to transform the companion matrix with a Perron root into a primitive matrix?,"['polynomials', 'matrices', 'similar-matrices', 'companion-matrices', 'linear-algebra']"
2619892,"Chern classes, cohomology classes with real/integer coefficients","I was searching for online sources on chern classes. One version is that given a vector bundle $E$ over space $M$, $i^{th}$ chern class is an element of cohomology $H^{2i}(M,\mathbb{Z})$. Another version is that given a vector bundle $E$ over space $M$, $i^{th}$ chern class is an element of cohomology $H^{2i}(M,\mathbb{R})$. I got confused sufficiently and came to a conclusion that in first case $M$ was just a topological space(manifold) in which case there is only one obvious notation of cohomology that is singular cohomology with standard choice of coefficients, integers. In second case they are considering smooth manifolds. So, there is a notion of differential forms and deRham cohomology and they are considering deRham cohomology. But then this Wikipedia article https://en.m.wikipedia.org/wiki/Chern_Weil_homomorphism in subsection chern classes and chern characters says chern class is an element of $H^{2i}(M;\mathbb{Z})$. Moreover it says it is an element in image of chern Weil homomorphism where as chern Weil homomorphism has its codimain as deRham cohomology ring. Can some one help me to clarify this confusion.","['homology-cohomology', 'characteristic-classes', 'algebraic-topology', 'vector-bundles', 'differential-geometry']"
2619907,Permutation induced by a partition,"Let $\lambda$ be a partition of length $n$ and suppose its largest diagonal block, the Durfee square of $\lambda$, has size $r$. By this I mean that $\lambda = (\lambda_1,\ldots,\lambda_n)$ is a non-increasing sequence of numbers, which I depict by the following diagram \begin{align*}
&\square \cdots \square \square \quad (\lambda_1 \text{ squares })\\
&\square  \cdots \square \quad (\lambda_2 \text{ squares }) \\
&\quad\vdots \\
&\square \quad(\lambda_n \text{ squares })
\end{align*} and the largest $i\times i$ block one can fit to the topmost left is of size $r\times r$. The conjugate partition $\lambda'$ is given by reflecting the drawing above along the diagonal. If $\alpha_i$ and $\beta_i$ denote the
sequence of numbers of blocks to the right of the diagonal in the $i$th row, and below the diagonal in the $i$th column, we write $\lambda = (\alpha_1,\ldots,\alpha_r\mid \beta_1,\ldots,\beta_r)$. For example, for the partition $(5,4,2,1,1)$ has diagram
$$
\begin{align}
&\blacksquare\square\square\square\square\\
&\square\blacksquare\square\square\\
&\square\square\\
&\square\\
&\square
\end{align}
$$ and its conjugate is $(5,3,2,2,1)$. Its diagonal has length $2$, and in Frobenius notation we have $\lambda = (4,2\mid 4,1)$. How can one show that the numbers $\lambda_1',\lambda_2'-1,\ldots,\lambda_r'-r+1,r+1-\lambda_{r+1},\ldots,n-\lambda_n$ form a permutation of $1,\ldots,n$? If $\lambda = (\alpha\mid \beta)$ in Frobenius notation, this is equivalent to the identity
$$\sum_{i=1}^n t^i (1-t^{-\lambda_i}) = \sum_{j=1}^r (t^{\beta_j+1}-t^{-\alpha_j})$$
which is Example 4 in page 11 of MacDonald's Symmetric Functions and Hall Polynomials , which he states without proof, so presumably this is easy. Continuing with the example, we compute that the sequence for $\lambda = (5,4,2,1,1)$ is
$$5,3-1,3-2,4-1,5-1=5,2,1,3,4$$
a permutation of $1,2,3,4,5$. 
In $(1.7)$ MacDonald proves that if we take $m\geqslant \lambda_1$ and $n\geqslant\lambda_1'$ then the numbers
$$\lambda_i+n-i,1\leqslant i\leqslant n,\quad n-1+j-\lambda_j',1\leqslant j\leqslant m$$ are a permutation of $0,\ldots,m+n-1$ by labelling the vertical and horizontal edge-lines on the diagram of $\lambda$ fitted inside the diagram of $(m^n)$, but I haven't been able to come up with a proof similar to this.","['combinatorics', 'integer-partitions']"
2619920,What symbol gives the count of elements in a set?,"What symbol describes the count of elements in a set? For instance, average can be given as: $A = \{1, 4, 2, 6, 3\}$ $$\operatorname{average}(A) = \frac{\operatorname{sum}(A)}{\operatorname{count}(A)}$$ I know that $\sum$ is the symbol for $\operatorname{sum}()$.  What would I use for $\operatorname{count}()$?","['notation', 'elementary-set-theory']"
2619944,Show that $\mu(A)=\sup \left\{\mu_1(B)+\mu_2(A \setminus B) : B \subset A \right\}$ is measure.,"Let $(X ,\mathfrak{m})$-measurable space.
Let $\mu_1$ and $\mu_2$ will be measures. For $A \in \mathfrak{m}$ define :
$\mu(A)=\sup \left\{\mu_1(B)+\mu_2(A \setminus B) : B \subset A \right\} $
Show that $\mu$ is measure. 1.$\mu(\emptyset)=0$ This is obvious. 2.$\mu(\bigcup_{n=1}^{\infty} A_n)=\sum_{n=1}^{\infty}\mu(A_n)$ If $B=\emptyset$ (obvious). What, if $B \neq \emptyset$ ?",['measure-theory']
2619990,There is some general meaning of angle in geometry?,"The other day I discovered the concept of hyperbolic angle to denote angles in hyperbolic geometry, as the half of the area between the hyperbola defined by $x^2-y^2=1$ and the $x$-axis. To be honest I dont know very much about the general concept of geometry in mathematics, so I cant grasp the meaning of the above, if it have some intuitive meaning more than an analogy to the angle and the circle $x^2+y^2=1$. Where I can understand something is in the realm of analysis or linear algebra. My questions: There is a general concept of angle in mathematics? Not only applicable to euclidean-geometries if not to any other kind of geometries. If so, it can be defined in analytical terms? There is a good reference about this topic understandable to someone with (some) background on analysis or linear algebra?","['terminology', 'reference-request', 'analysis', 'geometry']"
2620004,Can $n! $ divide $ n! + \frac{n!}{2} + \dots + \frac{n!}{n} $?,"How to disprove that
$$n! \mid \left(n! + \frac{n!}{2} + \dots +  \frac{n!}{n} \right)$$
This should not be true, since it would imply that there is some $n$ such that the $n$-th partial sum of the harmonic series reaches an integer. Here is what I tried: Since $n > 2 $ (Otherwise this would me trivial), then:
$$ 2 \mid n!   \\
2 \mid \frac{n!}{2} $$
So that $n > 4 $ (Note that $n$ can't be $4$). Then, by the same reasoning:
$$ 4 \mid n!   \\
4 \mid \frac{n!}{4} $$
So that $n > 6 $ But then I get stuck here since $ 6 \mid \frac{n!}{6} $ doesn't necessaily make $n$ larger than 6.",['number-theory']
2620010,Proof that a factorization domain is a unique factorization domain if and only if every irreducible element is prime.,"Today in algebra class my professor proved, among other things, that a factorization domain is a unique factorization domain if and only if every irreducible element is prime. I had a hard time following his proof, because he was explicitly juggling with units and their inverses all over the place. After class, I came up with a completely unit-free proof, given below. My question is: Are there any advantages to explicitly manipulating units, compared to my treatment? Preliminaries: Let $D$ be a domain. Let $\sim$ be the association relation, i.e., the largest equivalence relation that implies divisibility. Definition: A factorization for $n \in D$ is a finite multiset $S$ of irreducible elements such that $n \sim \prod S$. Definition: Two factorizations $S$ and $T$ for $n \in D$ are equivalent if there exists a bijection $f : S \to T$ such that $p \sim f(p)$ for every $p \in S$. Definition: A factorization domain is a domain such that every nonzero element admits a factorization. Definition: A unique factorization domain is a domain such that every nonzero element admits a unique factorization up to equivalence. Theorem: A factorization domain $D$ is a unique factorization domain if and only if every irreducible element is prime. Proof: Assume $D$ is a unique factorization domain. Take nonzero elements $p,a,b \in D$ such that $p$ is irreducible and $p \mid ab$. There exists a nonzero element $h \in D$ such that $hp = ab$. Let $H,A,B$ be factorizations for $h,a,b$, respectively. Hence $\prod H \cdot p \sim \prod A \cdot \prod B$. By the unique factorization property there exists a bijection $f : H \sqcup \{p\} \to A \sqcup B$ such that $q \sim f(q)$ are associates for every $q \in H \sqcup \{p\}$. In particular, either $f(p) \in A$ or $f(p) \in B$. In the former case, $p \sim f(p) \mid \prod A \sim a$. In the latter case, $p \sim f(p) \mid \prod B \sim b$. Hence $p$ is prime. Conversely, assume every irreducible element of $D$ is prime. Let $S$ and $T$ be factorizations of a common element. By induction on the cardinality of $S$, we have two cases: If $S = \emptyset$, then $\prod S = 1$, hence $\prod T \in D^*$, hence $T = \emptyset$. If $p \in S$, then $p \mid \prod T$. Since $p$ is prime, there exists $q \in T$ such that $p \mid q$. Since $q$ is irreducible, $p \sim q$. Let $S' = S \setminus \{p\}$ and $T' = T \setminus \{q\}$. Then $p \cdot \prod S' \sim q \cdot \prod T'$. By the inductive hypothesis, $S'$ and $T'$ are equivalent, hence so are $S$ and $T$.","['abstract-algebra', 'ring-theory', 'proof-writing']"
2620018,Variance of $T_n = \min_i \{ X_i \} + \max_i \{ X_i \}$,"Let $X$ be a random variable with distribution $\operatorname{Unif}(0, \theta)$. Draw IID $X_1, X_2, \ldots, X_n$ and calculate the moment method estimator. Compare it with $T_n = \min_i \{ X_i \}   + \max_i \{ X_i \}$. Attempt : We easily find $$\theta' = \frac {2(X_1 + \cdots + X_n)}{n}. $$
I received the broad question as ""compare the variances of the two estimators"" at finite or at least asymptotically, but I can't compute $V(T_n)$. Is it possible? I can say $V(T_n) > V(\max_i \{ X_i \})$ because $\min_i \{ X_i \}$ and $\max_i \{ X_i \}$ should be positively correlated, and I'm able to find the distribution of $\max_i \{ X_i \}$ and compute its variance. Thanks!","['statistical-inference', 'variance', 'statistics', 'probability', 'uniform-distribution']"
2620059,Connexion between the number of poles of a function and the degree of the associated projection map,"I have this question after reading Andrew Bridy's recent paper, Automatic Sequences and Curves Over Finite Fields . I would like to understand the following relationships used in the proof of Corollary 3.10: $$ \deg \pi_x = \deg (x)_\infty \text { and } \deg \pi_y = \deg (y)_\infty. \tag{$*$}$$ Background: Let $k$ be a perfect field of positive characteristic. Let $y \in k((x))$ be a Laurent series which is algebraic over $k(x)$. Let $X$ be the normalization of the projective closure of the curve defined by the minimal polynomial of $y$. Let $\pi_x, \pi_y : X \to \mathbf{P}^1$ be the projections of $X$ onto the $x$ and $y$ coordinates respectively. (These are dual to the inclusions of $k(x)$ and $k(y)$ into $k(X)$.) For $f \in k(X)$, the symbol $(f)_\infty$ denotes the divisor corresponding to the poles of $f$, i.e. $$ (f)_\infty = \sum_{\substack{P \in X \\ v_P(f) < 0}} -v_{P}(f) \cdot P. $$ Bridy claims the identity $(*)$ in Corollary 3.10. I know that $\deg (f)_\infty$ is just the sum of the orders of the poles of $f$ and I know that if $g(x)$ is a polynomial then $g$ has a pole of order $\deg g$ at $\infty$, which I suspect is related. What I would like is for a more precise explanation. I know basic properties of schemes, projective varieties and divisors but I'm far from an expert.","['divisors-algebraic-geometry', 'algebraic-geometry']"
2620115,Find $f(x)$ if $f\left(\frac{x+y}{3}\right)=\frac{2+f(x)+f(y)}{3}$,"$f : \mathbb{R} \to \mathbb{R}$ is a differentiable function satisfying $$f\left(\frac{x+y}{3}\right)=\frac{2+f(x)+f(y)}{3}$$ if $f'(0)=2$, find the function My Try: we have $$f\left(\frac{x+y}{3}\right)-\frac{f(y)}{3}=\frac{2+f(x)}{3}$$ $\implies$ $$\frac{f\left(\frac{x+y}{3}\right)-\frac{f(y)}{3}}{\frac{x}{3}}=\frac{2+f(x)}{x}$$ Now taking Limit $x \to 0$ we have $$\lim_{x \to 0}\frac{f\left(\frac{x+y}{3}\right)-\frac{f(y)}{3}}{\frac{x}{3}}=\lim_{x \to 0}\frac{2+f(x)}{x}$$ $\implies$ $$f'\left(\frac{y}{3}\right)=\lim_{x \to 0}\frac{2+f(x)}{x}$$ Now since LHS to be finite , we need $0/0$ form in RHS, hence $f(0)=-2$ Now by L'Hopital's Rule we get $$f'\left(\frac{y}{3}\right)=f'(0)=2$$ Integrating we get $$3f\left(\frac{y}{3}\right)=2y+c$$ Putting $y=0$ we get $c=-6$ So $$3f\left(\frac{y}{3}\right)=2y-6$$ So $$f(y)=2y-2$$ Hence $$f(x)=2x-2$$ But this function is not satisfying given functional equation. What went wrong?","['algebra-precalculus', 'real-analysis', 'functions', 'functional-equations']"
