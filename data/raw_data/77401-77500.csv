question_id,title,body,tags
982985,Part of simple proof of nontrivial center in p-group,"I'm trying to understand the proof of a Burnside theorem (as stated in Beachy's Abstract Algebra p. 328): Let $p$ be prime number. The center of any $p$-group is nontrivial. Now, In the proof they say that if we let $G$ be a $p$-group, then in the class equation $$|G| = |Z(G)|+\sum [G:C(x)]$$
for all $x$ that is not in the center and represent a conjugacy class, we see that every term in $\sum [G:C(x)]$ is divisible by $p$ since $x\not\in Z(G) \implies [G:C(x)]>1$. This last statement is what I do not understand, how do we know that $p \mid [G:C(x)]$ for any conjugacy class? I know that the elements in the conjugacy class of $x$ is in bijection with the cosets of $C(x)$, i.e. $[G:C(x)]$, but how can we be certain that the number of elements in a conjugacy class of $x$/cosets of the centralizer of $x$ is divisible by $p$? Best regards.","['finite-groups', 'group-theory', 'p-groups']"
983044,"Integral: $\int_0^{\pi/12} \ln(\tan x)\,dx$","I am trying to evaluate:
$$\int_0^{\pi/12} \ln(\tan x)\,dx$$ I think the integral is quite simple but I am having a hard time evaluating it. I started with the result:
$$\int_0^{\pi/4} \ln(\tan x)\,dx= -G$$
where $G$ is the Catalan's constant. With the change of variables $x\rightarrow 3x$ and using the fact that $\tan(3x)=\tan x\tan\left(\frac{\pi}{3}+x\right)\tan\left(\frac{\pi}{3}-x\right)$, the integral is:
$$\int_0^{\pi/12}\ln(\tan x)\,dx+\int_0^{\pi/12}\ln \tan\left(\frac{\pi}{3}+x\right)\,dx+\int_0^{\pi/12}\ln \tan\left(\frac{\pi}{3}-x\right)\,dx=-\frac{G}{3}$$
$$\Rightarrow \int_0^{\pi/12}\ln(\tan x)\,dx+\int_{-\pi/12}^{\pi/12}\ln \tan\left(\frac{\pi}{3}+x\right)\,dx=-\frac{G}{3}$$
But I do not see how to proceed. Help is appreciated. Thanks!","['definite-integrals', 'calculus', 'integration']"
983051,Proof by induction with two variables,"Giving proof by induction is normally very straight forward: $n+1$ and such. But how do you deal with two variables $m$ and $n$?
Given this problem, how do I ensure that I'm proving for $n+1$ and $m+1$? (If that's needed) Give a direct proof that if $n$ and $m$ are even integers, then $n + m$ is an even
integer is true.","['induction', 'discrete-mathematics', 'number-theory']"
983101,Find a polynomial $f(Z)$ of degree less than 2 such that $e^{tA}=f(A)$,Let $A=\begin{pmatrix}3&-2\\2&-2\end{pmatrix}$. As the question says I need a polynomial $f(Z)$ of degree less than 2 such that $e^{tA}=f(A)$. Should my polynomial just be the first 2 terms of the exponential summation? i.e. $I_2+tA$ or does it mean something else? I've already worked out that $e^{tA}=-\frac{1}{3}\begin{pmatrix}e^{-t}-4e^{2t}&-2e^{-t}+2e^{2t}\\2e^{-t}-2e^{2t}&-4e^{-t}+e^{2t}\end{pmatrix}$ I just don't know what polynomial it wants. Edit: Diagonalising $A$ gives $\begin{pmatrix}-1&0\\0&2\end{pmatrix}$ doesn't it? But what do I do with that to get the polynomial it asks for? Edit 2: So I've worked out $c_0(t)=\frac{1}{3}(e^{2t}+2e^{-t})$ and $c_1(t)=\frac{1}{3}(e^{2t}-e^{-t})$. Are they like the coefficients for the polynomial? Or is there something else?,"['matrices', 'linear-algebra']"
983105,Predicting profit with price variation,"I am currently working on a high school project that aims to predict profit from X amount of items to Y amount of profit based off a deviated sale price. For instance: I sale 10 cookies for 10 dollars, but on another sale I am able to sell for a higher price per cookie and achieve to sell 10 cookies for 20 dollars. Now say I sell a bulk order for 200 cookies and sale them for 400 dollars, but someone else makes the same order and I sell it to them for only 300 dollars. Essentially the price per cookie deviates in a range of a couple dollars or so, but when trying to use linear regression, the predictions are not even close to accurate. What is the best way to make an averaged prediction when using this type of business model? ` What is the best regression model in order to achieve this? Thanks in advance for the help.","['statistics', 'regression', 'data-analysis', 'mathematical-modeling']"
983119,"Prove $\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta = \int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta$","While doing some mathematical modelling of planetary orbits I have come up with two definite integrals $D_1$ and $D_2$ which appear to produce the same result when I test (using www.WolframAlpha.com) for various values of $a$  where $0<a<1$.
$$
D_1
\, =\,
\int_0^{2\pi}f_1\,\mathrm{d}\theta
\, =\,
\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta
\,=\,
\frac{3a\pi}{(1-a^2)^{5/2}}
\, =\,R
$$
and
$$
D_2
\, =\,
\int_0^{2\pi}f_2\,\mathrm{d}\theta
\, =\,
\int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta
\, =\,
\frac{3a\pi}{(1-a^2)^{5/2}}
\, =\,R
$$ How could I go about proving:- (1) $D_1$ = $D_2$, (SOLVED, I think, by my two answers below, but using WolframAlpha to obtain integral solutions)
$$$$ (2) $D_1$ = $R$ or $D_2$ = $R$. (MOVED to a separate question: Prove $\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}$ or $\int_0^{2\pi}\frac{\cos\theta}{(1-a\cos\theta)^3}=\frac{3a\pi}{(1-a^2)^{5/2}}$ ). UPDATE 1 You can see how WolframAlpha produces these results by inputting the following input texts:- For Eqtn 1 with a=0.1 input: integrate (3*0.1(sinx)^2)/((1-0.1*cosx)^4) from x=0 to 2*pi For Eqtn 2 with a=0.1 input: integrate (cosx)/((1-0.1*cosx)^3) from x=0 to 2*pi for Result with a=0.1 input: evaluate 3 0.1 pi/(1-0.1^2)^(5/2) UPDATE 2 WolframAlpha also computes expressions for the indefinite integrals as follows:-
$$I_1
\, =\,
\int\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta
\,=\,
$$
$$constant1 + \frac
{a\,\sqrt{a^2-1}\sin\theta\,[-(2a^3+a)\cos^2\theta+3(a^2+1)cos\theta+a(2a^2-5)]}
{2(a^2-1)^{5/2}(a\cos\theta-1)^3}
$$ $$-\frac
{6a\,(a\cos\theta-1)^3\,\tanh^-1
\left(
\frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}}
\right)
}
{(2(a^2-1)^{5/2}\,(a\cos\theta-1)^3}
$$
$$$$
$$$$ $$I_2
\, =\,
\int\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta
\, =\,
$$
$$constant2 -
\frac
{2a^2\sin\theta-sin\theta}
{2(a^2-1)^2(a\cos\theta-1)}
-\frac
{\sin\theta}
{2(a^2-1)(a\cos\theta-1)^2}
$$ $$
-\frac
{3a\tanh^-1\left(\frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}}\right)}
{(a^2-1)^{5/2}}
$$
Note that the final terms of each expression are equivalent to each other.  This could be useful. For example we can define a difference function $f_3 = f_1-f_2$ whose indefinite integral $I_3 = I_1-I_2$ will exclude the common awkward third term. Let us assume that $f_3$ is continuously integrable over the range $0,2\pi$ (we cannot be sure by inspection alone, but it can be shown, see my answer below).  Then, if $D_1=D_2$ over the range $0,2\pi$ then $D_1-D_2=0$ and so $D_3$ (=$\int_0^{2\pi}f_3\,d\theta$) should have value zero.  This is expanded on in my answer below.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
983125,"PRIMES is in P, page 4: Why is $(X+a)^{\frac{n}{p}} \equiv X^{\frac{n}{p}}+a$ implied?","PRIMES is in P , page 4, equation (5) Edit: I should probably add that $p$ is a prime factor of some $n$. $a$ is any number from 1 to some irrelevant limit. $r$ also shouldn't matter because as far as I can see nothing we know about it is relevant. Edit 5: It is also given that $gcd(r,p)=1$, which I use in the answer below. We are in $\mathbb{Z}[X]/(X^r-1,p)$. The authors claim $$(X+a)^{n} \equiv X^{n}+a~~~(3)$$ together with $$(X+a)^{p} \equiv X^{p}+a~~~(4)$$ implies $$(X+a)^{\frac{n}{p}} \equiv X^{\frac{n}{p}}+a~~~(5)$$ I tried to prove it and even without using (3) or (4), all I got was a contradiction. Where is my mistake and what is the correct proof? My attempt: Suppose (5) holds, then: $$X^{\frac{n}{p}}+a \equiv (X+a)^{\frac{n}{p}} \equiv \sum_{k=0}^{n/p} \binom{n/p}{k}X^{\frac{n}{p}-k}a^{k}$$ $$\implies \binom{n/p}{k}X^{\frac{n}{p}-k}a^{k} \equiv 0~~~\forall 0 < k < \frac{n}{k}$$ Let $k=1, p \not | a, p^2 \not| n$:
$$\implies \binom{n/p}{1}X^{\frac{n}{p}-1}a^{1} \equiv \frac{n}{p}X^{\frac{n}{p}-1}a \not \equiv 0 \text{ - contradiction to the previous line}$$ Edit2: I want to add that this clearly holds for any number $c$ that we plug into the polynomial, since the value of $(c+a)^{\frac{n}{p}} \equiv (c+a)^{p\frac{n}{p}} \equiv (c+a)^n \equiv c^n+a \equiv c^{p\frac{n}{p}}+a \equiv c^{\frac{n}{p}}+a$. But the statement is that the polynomials are equal. That's also clearly what is meant by the authors because otherwise (4) would be trivial. Edit3: The claim can also easily be proven for $X^p$ instead of $X$, but I am not sure if that's of any use: Left side of (3): $$(X+a)^{n} \equiv (X+a)^{p \frac{n}{p}} \equiv (X^p+a)^{\frac{n}{p}}$$
Right side of (3): $$X^n+a \equiv X^{p \frac{n}{p}}$$
And together:
$$\implies (X^p+a)^{\frac{n}{p}} \equiv X^{p \frac{n}{p}} \text{ in } \mathbb{Z}[X]/(X^r-1,p)$$
Now if $r$ was a multiple of $p$ (which it is not), we could substitute $X^p$ with $X$, which would give us (5) in $\mathbb{Z}[X]/(X^{r/p}-1,p)$, which should imply (5) in our original ring $\mathbb{Z}[X]/(X^r-1,p)$ since $X^{r/p}=1 \implies (X^{r/p})^{p}=1$. But maybe this is going in the right direction? Edit4: It can also be proven that both sides of (5) are equal when being raised to the power of $p$. This seems the closest to the actual claim, but I can't think of an argument why it would imply (5). Left side of (3):
$$(X+a)^n \equiv ((X+a)^{\frac{n}{p}})^p$$ Right side of (3):
$$X^n+a \equiv X^{p \frac{n}{p}}+a^p \equiv (X^{\frac{n}{p}}+a)^p$$ Together:
$$\implies ((X+a)^{\frac{n}{p}})^p \equiv (X^{\frac{n}{p}}+a)^p$$","['primality-test', 'abstract-algebra', 'polynomials']"
983151,Homeomorphism between plane with different topologies,"How would you show that spaces $(\mathbb{R^2},\cal{T}_r)$ and $(\mathbb{R}^2,\cal{T}_b)$, where $\cal{T}_r$ is a topology generated by jungle river metric ( here ) and equivalently $\cal{T}_b$ is generated by the British Rail metric ( 3.15 second one ), are not homeomorphic? I tried to think of any elementary topological property, with which I can characterize only one of those spaces, but they seem to be so alike... Yet not homeomorphic. Why?",['general-topology']
983198,Is the number 0.2343434343434.. rational? [duplicate],"This question already has answers here : Proof that every repeating decimal is rational (10 answers) Closed 9 years ago . Consider the following number: $$x=0.23434343434\dots$$ My question is whether this number  is rational or irrational, and how can I make sure that a specific number is rational if it was written in decimal form. Also, is $0.234$ rational or irrational?","['algebra-precalculus', 'rational-numbers']"
983251,Permutation modules and their vector space dimensions,"I'm given a field $k$, a finite group $G$ and a set $S$ which $G$ acts on transitively. I'm then told to consider the permutation module $M = kS$. My first problem is understanding what the permutation module actually is? My guess is that it is the module with basis $\{b_s : s \in S\}$ and then multiplication coming from $G$ where $g.b_s = b_{gs}$ which is then extended linearly. But then I'm not sure how $k$ plays a part in this? I'm then told to consider the subsets: $M_1 = k (\sum b_s)$ where the sum is over all $s \in S$ $M_2 = \big\{\sum \lambda_s b_s : \sum \lambda_s = 0$ Now the question asks me to determine the vector space dimensions of $M_1$ and $M_2$, however if I consider these as $k$-vector spaces which is my guess? Then the dimension of $M_1$ is just 1 because it has $\sum b_s$ is a basis and then dimension of $M_2$ is $|S|-1$ because all but one of the scalars are free by the condition on their sum. I'm really not sure if this is the right interpretation of these objects and would appreciate some help in the right direction. I'm particularly skeptical because I am later asked to determine the corresponding representations to $M_1$ and $M/M_2$ but then these things are both 1 dimensional and then I would get that both the representations are trivial? (Just because say for $M_1$ I would have $p: G \to \operatorname{End}_k(M_1)$ would be given by $p(g) (v) = p(g) (\lambda \sum b_s) = \lambda \sum b_gs = \lambda \sum b_g$ because G acts transitively) Apologies for the long post, but I've struggled to find any good references on this topic and am having difficulty understanding some of these ideas. I appreciate any help!","['modules', 'representation-theory', 'group-theory']"
983255,"Eulers totient function divided by $n$, counting numbers in the set [1,m] that are coprime to n","If we divide Euler's totient function $\omega(n)$ by $n$, we obtain a fraction. If we multiply this fraction by any natural number $m$ which gives us another natural number $p$, is it true that $p$ is the number of natural numbers in $[1,m]$ that are coprime to $n$?","['prime-numbers', 'totient-function', 'elementary-number-theory', 'number-theory']"
983259,"The ideal $\langle x,y \rangle$ in $F[x,y]$ is not principal. [duplicate]","This question already has answers here : The ideal $I= \langle x,y \rangle\subset k[x,y]$ is not principal [closed] (6 answers) Closed 9 years ago . Let $F$ be a field. Apparently we know that $\langle x,y \rangle \neq \langle g(x,y) \rangle$ for any $g \in F[x,y]$. Why is this the case?","['ideals', 'abstract-algebra']"
983262,The Laplacian of the composition of a function with an orthogonal transformation,"Define a ""rotation of u"" by $R_{A}u\doteq u\circ A $ with A an orthogonal $n\times n$ matrix and ""$\circ$"" means composition. Show that $\Delta (u\circ A )=(\Delta u)\circ A$. (Note: $u(x)\in C^{m\geqslant 2} (\mathbb{R}^{n}) $) I tried to treat u as merely a number in $\mathbb{R}^{n}$ and then take the Laplacian to each entry of the matrix. Then I compared the LHS and the RHS and found they are equal. Is this correct? I felt this way is kind of trivial as you don't use the condition ""orthogonal"".","['multivariable-calculus', 'linear-algebra', 'laplacian']"
983282,How many binary sequences of length n are there that contain exactly m occurrences of the pattern 01?,"I thought there were n-1 places between the first and last digit. In these places I hypothesized there are switches that change (from 0->1 or 1->0) For {First,Last}={00,01,10,11} -> 4 ways I ask an answer for the first case mostly (I think the rest will be similar) Since there are m patterns of 01 how many switches are there? And how many ways are there to pick out of n-1?","['discrete-mathematics', 'binary', 'combinatorics']"
983289,"Two surfaces are not isometries of each other, but have the same Gaussian Curvature","How can you show that two surfaces are not isometries of each other, but have the same Gaussian Curvature. For example, I see that: the helicoid given by X = (ucosv, usinv, v) & the surface Y = (ucosv, usinv, ln(u)) have the same Gaussian curvature. I computed the first and second fundamental forms and noticed that K = -1/(1+u^2)^2 for both the helicoid (X) and the other surface (Y). I know that they are not isometries, but I am not sure how to show that there is no local
reparametrization of X that has the first fundamental form equal to Y's first fundamental form. Any hints would be greatly appreciated! 
Thank you!","['surfaces', 'riemann-surfaces', 'curvature', 'differential-geometry']"
983296,Likelyhood of Poisson Distribution,"The number of accidents in a week follows a poisson distribution with mean $\lambda$. Likelyhood is given as $$L(\lambda)=\frac{ \lambda^{\sum_1^n x_i } e^{-n\lambda}} { \prod x_i!}$$ However only a proportion p, are reported and each accident is reported with probability p, independent of all others. How would you modify the likelyhood function to take account of this?","['statistics', 'poissons-equation', 'probability']"
983309,Inverting a function,"I am stuck with the following problem I am supposed to find the inverse of the function $g$ with $2$ variables, where $$\begin{align*}g&: R^2\to R^2 \\ g&(x,y)=(2ye^{2x}, xe^y)\end{align*}$$ I do not know even how to do it, the book does not give an example. Could you please tell me of a general method of how to invert this function? Thanks in advance!","['multivariable-calculus', 'real-analysis', 'analysis']"
983315,How to visualise Bollobas' 1965 theorem?,"Theorem $[n]=\{1,\ldots,n\}$ . Let $\lbrace (R_i, S_i), i \in I \rbrace, R_i, S_i \subset [n]$ be such that $R_i \cap S_i = \emptyset, R_i \cap S_j \ne \emptyset (i \ne j)$ . Then $$\sum_{i \in I} \frac{1}{{{r_i+s_i}\choose{s_i}}}\le 1.$$ Question : I am happy with the proof below of Bollobas' Theorem, but it seems very bashy. Is there a: More elegant way to prove the theorem, and, more importantly Is there a way to visualise the proof? By this I mean construct a picture on the $n$ -cube or similar object that makes the proof somewhat obvious. An example of this is Sperner's Theorem for antichains, visualised by drawing chains on the $n$ -cube. I've already seen one probabilistic proof, which is elegant but I cannot visualise it. Proof For $n=1$ it is trivial as $I= \lbrace 1 \rbrace$ . We remove an element $x\in [n]$ from the construction to achieve a construction with $n-1$ , which we can induct on. For each $x \in \lbrace 1,...,n \rbrace$ let $I_x= \lbrace i\in I: x \notin R_i \rbrace$ , and $S_i^x = S_i \setminus \lbrace x \rbrace$ . $\lbrace (R_i, S_i^x, i \in I_x \rbrace$ we cannot have $R_i \cap S^x_j = \emptyset$ , as if $x$ was the only element in common between $R_i$ and $S_j$ , that $R_i$ was thrown out as it contained $x$ . Anyway, $$\sum_{i \in I_x} \frac{1}{{{r_i+s^x_i}\choose{s^x_i}}}\le 1.$$ Let us vary $x$ , and fix $i, R_i, S_i$ . Given each $i \in I$ , $i \in I_x$ (i.e. $x \notin R_i$ ) for $n-r_i$ values of $x$ . Now, if $i \in I_x$ ( $x \notin R_i$ ), then for $s_i$ values of $x$ we have $s^x_i=s_i-1$ (i.e. $x \in S_i$ ), and for $n-r_i-s_i$ values of $x$ we have $s_i^x=s_i$ . Hence $$n \ge \sum_{x \in [n]} \sum_{i \in I_x}\frac{1}{{{r_i+s^x_i}\choose{s^x_i}}}= \sum_{i \in I} \frac{n-r_i-s_i}{{{r_i+s_i}\choose{s_i}}}+\frac{s_i}{{{r_i+s_i-1}\choose{s_i-1}}}$$ $$n \ge \sum_{i \in I} \frac{(n-r_i-s_i)(s_i)! (r_i)!}{(s_i+r_i)!}+\frac{s_i (s_i-1)!(r_i)!}{(r_i+s_i-1)!}= n\sum_{i \in I} \frac{1}{{{r_i+s_i}\choose{s_i}}}.$$ Proof 2 (elegant, but still no visualisation) Randomly order the elements of $[n]$ , then $\frac{1}{{{ri+s_i}\choose{s_i}}}$ is the probability that all elements of $R_i$ are greater than those of $S_i$ (written $R_i>S_i$ ), as only one of the unordered partitions of $[n]$ into $r_i, s_i$ elements satisfies the condition. For all $i$ these events are mutually exclusive. Thus $$P \left( \bigvee_{i \in I} (R_i>S_i) \right)\le 1.$$","['visualization', 'combinatorics']"
983336,Why existence of Lyapunov function implies Lyapunov stability at the equilibrium point,"Why existence of Lyapunov function (locally positive definite and the time derivative of the Lyapunov-candidate-function is locally negative semidefinite)  implies Lyapunov stability (i.e for any $\epsilon >0$, there exist $\delta >0$ such that any trajectory initiated at the delta neighbourhood of the equilibrium point remains in the $\epsilon$ neighbourhood)  at the equilibrium point ?",['ordinary-differential-equations']
983358,"Question on the paper Donal F. Connon, ""Some integrals involving the Stieltjes constants""","I'm reading Donal F. Connon, Some integrals involving the Stieltjes constants . It gives a definition of the generalized Stieltjes constants $\gamma_n(u)$ as coefficients in the Laurent series expansion of the Hurwitz zeta function (formula $(2.3)$ on page $7$):
$$\zeta(s,u)=\sum_{n=0}^\infty\frac1{(n+u)^s}=\frac1{s-1}+\sum_{n=0}^\infty\frac{(-1)^n}{n!}\gamma_n(u)\,(s-1)^n$$ It also gives the following integral representation (formula $(2.4)$ on page $7$):
$$\int_0^1\left[\frac1{1-y}+\frac1{\log y}\right]y^{u-1}\log\left|\log y\right|dy=-2\gamma_1(u)-\gamma\,\gamma_0(u)-\log^2u-\gamma\log u$$
Recall that $\gamma_0(u)$ in the second term is just a negation of the digamma function : $\gamma_0(u)=-\psi(u)$. The given integral representation does not check numerically for me, e.g. for $u=1$ the integral on the left is $$-0.26036207832404194945778976048034290752168080191529...$$
but the numeric value of the right hand side is
$$-0.18754623284036522459720338460544158838394446358095...$$
Further numeric calculations suggest that the right hand side should instead be
$$-\gamma_1(u)-\gamma\,\gamma_0(u)-\frac{\log^2u}2-\gamma\log u$$ Is it an error in the paper, or I just misunderstand something?","['calculus', 'zeta-functions', 'special-functions', 'definite-integrals', 'stieltjes-constants']"
983361,"What is $\bigcup_{n=1}^{\infty}[0,1-\frac{1}{n}]$? [duplicate]","This question already has answers here : What is $\bigcup\limits_{n=1}^\infty [0,1-\frac{1}{n}]$? (4 answers) Closed 7 months ago . I often read that: $\bigcup_{n=1}^{\infty}[0,1-\frac{1}{n}]=[0,1)$. But why? My intuition would say that the result would be $[0,1]$ because $\lim_{n\rightarrow \infty}[0,1-\frac{1}{n}]=[0,1]$",['elementary-set-theory']
983370,bounded operator $T$ is not compact then there exists an orthonormal sequence $e_n$ and $d>0$ such that $\|T(e_n)\|>d$ for all $n\in\Bbb{N}$?,"I want to prove that if a bounded operator $T$ is not compact then there exists an orthonormal sequence $e_n$ and $d>0$ such that $\|T(e_n)\|>d$ for all $n\in\Bbb{N}$. Could someone helps me? I think that the fact that T is not compact implies that there exists an arbitrary sequence in H that doesn't contain convergent subsequence, not for a orthonormal sequence. Moreover, we know that if T is a compact operator and en an orthonormal sequence then ||T(en)|| converges strongly to 0 but not the inverse. We want to show this.",['functional-analysis']
983439,Using recursion tree to solve recurrence $T(n) = 3T(n/2)+n$,"I am trying to solve the recurrence $T(n) = 3T(n/2)+n$ where $T(1) = 1$ and show its time complexity. $n$ can be assumed to be a power of $2$. So basically, I drew out the tree and found that: the number of levels in the tree will be $h = \log_2 n+1$. The number of leaves in the tree will then be $3^{h-1} = 3^{\log_2 (n) } = n^{\log_2 3}$ Now we can write the time formula.. $$T(n) = cn + c(3n/2) + c(9n/4) +\dots + cn(3^{h-2}/2(h-2)) + \Theta(n^{\log_2 3})$$ [stuck here, how should I formulate the summation? The summation diverges at infinity..] $$T(n) = \Theta (n^{\log_2 3})$$ I can tell that the summation of the number of leaves is $n$ times some constant but I am not sure how to show that step.","['asymptotics', 'recurrence-relations', 'discrete-mathematics', 'algorithms']"
983480,Commutator subgroup of rank-2 free group is not finitely generated.,"I'm having trouble with this exercise: Let $G$ be the free group generated by $a$ and $b$. Prove that the commutator subgroup $G'$ is not finitely generated. I found a suggestion that says to prove $G'$ is generated by the collection $\{[x^m,y^n]\mid m,n\in\mathbb{Z}\}$. I don't know how to prove this, and how it helps. If you could please provide me with some hints... Thanks!","['free-groups', 'group-theory', 'abstract-algebra']"
983530,Evaluating $(\frac{\cos x}{1-\sin x})^2$,$(\dfrac{\cos x}{1-\sin x})^2$ $f\;'(x)= 2(\dfrac{\cos x}{1-\sin x}) \times (\dfrac{-\sin x+\sin^2x-\cos^2x}{(1-\sin x)^2})$ Does $\sin^2x-\cos^2=1$? or $-1$?  Then it could factor with the bottom and the answer would be $\dfrac{2\cos x}{(1-\sin x)^2}$. Is this right?,"['calculus', 'derivatives']"
983568,How to show $P^1\times P^1$ (as projective variety by Segre embedding) is not isomorphic to $P^2$?,"I am a beginner. This is an exercise from Hartshorne Chapter 1, 4.5. By his hint, it seems this can be argued that there are two curves in image of Segre embedding that do not intersect with each other while in $P^2$ any two curves intersect. I feel this solution is very special. I would like to know more.
Is there any invariant to detect whether two birational equivalent varieties are iso or not? Thanks!","['projective-space', 'algebraic-geometry']"
983573,Question regarding character varieties on a torus with compact gauge group,"Let $G$ be a compact, connected Lie group. Let $x, y \in G$ be an arbitrary pair of commuting elements. Is there necessarily a torus $T \leq G$ containing $x$ and $y$? Apparently not: Commutativity and Maximal Tori in Connected, Compact Lie Groups The issue arises due to discrete abelian subgroups. Consider the $SO_3(\mathbb{R})$ example from the link. Thinking geometrically, a maximal torus can be described as the circle subgroup of rotations fixing a particular direction in $\mathbb{R}^3$. Consider two orthogonal directions. Then rotation by $\pi$ radians about these two axes will commute, but they certainly do not live in a common maximal torus. My concern comes from trying to compute the following character variety on a torus: $\chi_G(\Sigma_1)=\{\rho: \pi_1(\Sigma_1) \to G \ \vert \rho \ \text{is a group homomorphism}\}/\text{conjugation by} \ G$ where $\Sigma_1 \cong S^1 \times S^1$ is a torus. Since $\pi_1(\Sigma_1)$ is free abelian of rank 2, it follows that such a homomorphism is determined by a choice of commuting elements $x, y \in G$. What should I make of the following argument, particularly the part characterizing a flat connection on $S^1 \times S^1$? [Edit: The link has been updated to reflect this issue] http://ncatlab.org/nlab/show/moduli+space+of+connections#FlatConnectionsOverATorus It seems that there are oddball homomorphisms not fitting into this general setup for some compact groups. I would appreciate more examples (in other compact, connected gauge groups) of commuting elements that fail to live in a common maximal torus. Of course, $SO_3(\mathbb{R})$ is not simply connected, but the gauge groups I am working with all are. I don't know enough about discrete abelian subgroups of compact Lie groups. Can this issue be avoided by further assuming that the gauge group is simply connected?","['topological-groups', 'differential-geometry', 'algebraic-topology', 'abstract-algebra', 'lie-groups']"
983588,How to prove a subset is an ideal,"I just started learning about Ring Theory today and I am having some trouble truly understanding and being able to apply certain concepts. The first concept I am having trouble understanding is an ideal. I know the formal definition: Let $R$ be a ring. A nonempty subset $I$ of $R$ is called an ideal (only dealing with two-sided as of this point) of $R$ if: (a) $I$ is an additive subgroup of $R$ (b) Given $r \in R$, $a\in I$, then $ra \in I$ and $ar \in I$ However, I am having trouble applying this to the first (and easiest) problem: If $R$ is a commutative ring and $a \in R$, let $L(a) = \{x \in R | xa = 0\}$. Prove $L(a)$ is an ideal of $R$. My first approach was to first prove $L(a)$ is an additive subgroup, then that $ar,ra \in I$ but I had trouble with the second part. I then tried to find a homomorphism with kernel $L(a)$ but also got stuck. Could someone please walk me through the way I should approach this problem? I looked at several posts on here and I am nervous as my question almost seems too easy. Please keep in mind I am learning algebra entirely on my own so a very simple explanation would be immensely helpful. Thank you.","['ring-theory', 'ideals', 'abstract-algebra']"
983596,How to visualize the $d$-uple embedding?,"Given positive integers $n$ and $d$, let $\{M_i\}_{i \in \{0 \dotsc N\}}$ be the collection of all $N+1$ monomials in $n+1$ variables of degree $d$. Then given a point $a = [a_0 : \dotsb : a_n]$ we can define the map 
  \begin{align*}
   \boldsymbol{P}^{n} &\to \boldsymbol{P}^{N}
   \\
   [a_0 : \dotsb : a_n] &\mapsto [M_1(a) : \dotsb : M_N(a)]
   \,.
\end{align*}
  This map is called the $d$-uple embedding of $\boldsymbol{P}^{n}$ into $\boldsymbol{P}^{N}$. Is there any good way to visualize what this $d$-uple embedding looks like? What is the motivation for this construction?","['projective-space', 'algebraic-geometry']"
983604,Find $\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\dotsb+\sqrt{6}}}}}_{n\text{ square root signs}}$,"We have the following representation of pi:
$$\pi=\lim_{n\to\infty}2^n \underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\dotsb+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2}}}}}}}}}}_{n\text{ square root signs}}$$
which can be proven using the identity $\sin\left(\dfrac\pi{2^{n+1}}\right)=\dfrac12\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dotsb+\sqrt{2}}}}}_{n\text{ square root signs}}$. (There's similar one for $\cos$, except without the minus sign.) This made me wonder: Is there a closed form for:
$$\lim_{n\to\infty}3^n \underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}$$
(Note that $\sqrt{6+\sqrt{6+\sqrt{\dots}}}=3$, so this question is of the form $\infty\times0$.) EDIT: It seems like that doesn't converge, but this does:
$$\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}\approx4.49377$$","['pi', 'arithmetic', 'calculus', 'limits']"
983625,Layman's Question on Schemes,"I am reading Jordan Ellenberg's article on Arithmetic Geometry in the Princeton Companion to Mathematics. I have forgotten most of the algebra I learned since passing my qualifying exams more than 30 years ago. The article is beautifully written and I followed almost everything he said and how schemes is a way to associate a geometric object with any ring in Section 3.3 on page 377. In section 3.4, he gave the example of $\text{Spec } \mathbb Z$ and that each point $n$ of $\mathbb Z$ can be consider as a map from $\text{Spec } \mathbb Z$ to $\mathbb C$ using $n\mod p$. Great. It works. My question is how is this done in general for an arbitrary ring $R$? (The only way I can think of is to use the quotient for each prime ideal $(p)$ and send $(p)$ to $n+(p)$. However, this would mean that the range of map changes with the argument $(p)$. The problem I have with that is that for a fixed $n\in R$, the range of $n$ considered as a map changes with the argument $(p)$.) Another question: what is a good reference to read a little more on the topic without trying to become an expert in the area.","['algebraic-geometry', 'schemes']"
983685,Unit Disk Regular Surface?,"I am having trouble proving these two problems: 1) is $\{(x,y,z)\in \mathbb{R}|z=0, x^2+y^2\leq1\}$ a regular surface?  I say no because the closed unit disk is a closed surface, so we cannot differentiate on the edges.  But how can I define a function to prove this or is this enough explanation? 2) is $\{(x,y,z)\in \mathbb{R}|z=0, x^2+y^2<1\}$ a regular surface?  I say yes because it is an open interval, so we can differentiate everywhere. But how can I define a function to prove this?  Perhaps $f(x,y)=x^2+y^2$ as a level curve at $f=1$ and show that its gradient is nonzero?  Also, saying $f=1$ wouldn't give me the correct closed interval, because it would contain points like (1,0) and (0,1), for example.  Help!",['differential-geometry']
983689,Looking for modern equivalent of Whittaker and Watson.,"I am looking for a modern treatment of transcendental functions with an emphasis on difficult calculations similar to the classic text by Whittaker and Watson (now over 100 years old) http://en.wikipedia.org/wiki/Whittaker_and_Watson I have trouble following their exposition and I think a text written in the last 30-40 years  would be useful.  Unfortunately I have trouble finding one that puts as much emphasis on actually doing difficult calculations.  My interests are in mathematical physics and I would like much deeper treatment of Orthogonal Polynomials, Bessel Functions, Gamma Function, Zeta Function, etc. from a calculational viewpoint than what is provided in standard math for physics texts like Boas, etc.","['book-recommendation', 'analysis']"
983708,"If $f'(x)=f(x)+\int_{0}^{1}f(x)\,dx$ and $f(0) = 1,\,$ then what is the value of $\, \int_0^1 f(x)\,dx=$?","If $\displaystyle f'(x)=f(x)+\int_{0}^{1}f(x)\,dx\,$ and $\,f(0) = 1.$ Then what is value of $\displaystyle \int f(x)\,dx\,?$ $\bf{My\; Try.}$ Let $\displaystyle \int_{0}^{1}f(x)\,dx = A\;,$ Then $f'(x) = f(x)+A$ Now Diff. both side w. r.to $x\;,$ we Get $f''(x) = f(x).$ Now We will solve the differential equation,we will multiply both side by $f'(x)$ and Integrate it $\displaystyle \int f''(x)\cdot f'(x)dx = \int f(x)\cdot f'(x)dx\Rightarrow \frac{(f'(x))^2}{2} = \frac{(f(x))^2}{2}+\frac{\mathcal{C}}{2}$ So $\displaystyle f'(x)=\pm \sqrt{f(x)+\mathcal{C}}\Rightarrow \int \frac{f^{'}(x)}{\sqrt{f(x)+\mathcal{C}}}dx=\pm \int 1dx$ Now I did not understand how can i solve it. Help me Thanks","['ordinary-differential-equations', 'calculus', 'integration', 'analysis']"
983722,Total complex homology exact sequence,"I'm been trying to do this problem (Problem 5.1.1) from Weibel's Introduction to Homological Algebra but I can't really see how to finish it. The statement of the problem is summarized as follows: Suppose that we have a double complex $E$ consists of only two columns $p$ and $p-1$. Let $T_n = Tot(E)$ be the total complex then show that there is an exact sequence
\begin{equation}
0 \rightarrow E^2_{p - 1,q + 1} \rightarrow H_{p + q} (T) \rightarrow E^2_{p,q} \rightarrow 0
\end{equation} So what I've tried so far is attempting to calculate each of the object in the sequence and show that 
\begin{equation}
E^2_{p,q} \cong H_{p+q}(T)/E^2_{p-1,q+1}
\end{equation}
or something. So I did the calculation and I got
\begin{equation}
E^2_{p-1,q+1} \cong \mbox{ker} (d^v_{p-1, q+1})/\mbox{im}(d^h_{p, q+1}) \\
H_{p + q}(T) \cong \frac{(\mbox{ker}(d^h_{p, q}) \cap \mbox{ker}(d^v_{p,q})) \oplus \mbox{ker} (d^v_{p-1,q+1})}{\mbox{im} (d^v_{p,q+1}) \oplus (\mbox{im} (d^h_{p,q+1}) + \mbox{im} (d^v_{p-1,q+2}))} \\
E^2_{p,q} \cong \mbox{ker} ({d^h_{p,q}}_{\star})
\end{equation}
Where ${d^h_{p,q}}_{\star}: E^1_{p,q} \rightarrow E^1_{p-1,q}$ is the induced horizontal differential map after taking the vertical homology. However, 
\begin{equation}
H_{p+q}(T)/E^2_{p-1,q+1} \cong \frac{(\mbox{ker}(d^h_{p, q}) \cap \mbox{ker}(d^v_{p,q}))}{\mbox{im} (d^v_{p,q+1})} \stackrel{?}{\cong} \mbox{ker} ({d^h_{p,q}}_{\star})
\end{equation}
and I can't convince myself that the second equality is true.
Am I on the right track (or close to)? If someone could point out the mistake or guide me to the right direction that would be great. Thank you.","['spectral-sequences', 'homological-algebra', 'abstract-algebra']"
983745,Number of Rotations of a unit cube,"Let $C $ be the unit cube $[-1,1]^3 \subseteq \mathbb R^3$.How many rotations are there in $\mathbb R^3$ which take $\mathbb C$ to itself? Please help me to visualize this.",['geometry']
983753,Proof of $p_n<n^2$ by Elementary Means,"Is there any proof of the inequality $p_n<n^2$ (for all sufficiently large $n$) by elementary means and without using Prime Number Theorem? I searched in google but in vain. The results that I have found (and from which the inequality can be proved) are mostly results that arises as a consequence of PNT. So, is there any such proof? If so, then please include a link of the paper in your answer (or comment).","['prime-numbers', 'inequality', 'reference-request', 'number-theory']"
983774,Limit of solution of linear system of ODEs as $t\to \infty$,"I am completely stuck on the following problem: Consider the linear system: $x'(t)=A(t)x(t)$ where $A(t)$ is an $n$ by $n$ matrix. Assume that $\lim_{t\to \infty}A(t)=B$. Suppose that each eigenvalue of $B$ has strictly negative real part. Let $y(t)$ be a solution to the linear system. Does anyone how to show: $\lim_{t\to \infty}|y(t)|=0$ I know that if $y(t)$ is a solution to the linear system and all eigenvalues of $A$ have  strictly negative real parts, then $y(t)\to 0$ as $t\to \infty$. However, this is true when $A$ is independent of $t$. The issue for this problem is that $A$ is dependent on $t$, and it's the limiting matrix $B$ that has eigenvalues with strictly negative real parts. I don't know how to approach this problem. Thanks to anyone who help me out!","['linear-algebra', 'ordinary-differential-equations', 'real-analysis', 'analysis']"
983815,Vandermonde identity corollary $\sum_{v=0}^{n}\frac{(2n)!}{(v!)^2(n-v)!^2}={2n \choose n}^2$,"I am trying to prove this identity: 
$$\sum_{v=0}^{n}\frac{(2n)!}{(v!)^2(n-v)!^2}={2n \choose n}^2$$
I think this identity (corollary of Vandermonde identity):
$${n\choose 0}^2+{n\choose 1}^2+{n\choose 2}^2+\cdots+{n\choose n}^2={2n \choose n}$$ is applicable for solving it. Please give me some hints. thank you",['combinatorics']
983829,"checking slope = $0$ at a point for a function using $\epsilon $, $\delta $ definition","From the continuity definition, a function is continuous at a point $a$ if  : $$\forall \epsilon \gt 0 \exists \delta \gt 0  : |x-a| \lt \delta \implies |f(x)-f(a)|\lt \epsilon$$ If I change the order of quantifiers like below do I get a definition for checking slope = $0$ at $x = a$ ? 
$$\exists \delta \gt 0   \forall \epsilon \gt 0 : |x-a| \lt \delta \implies |f(x)-f(a)|\lt \epsilon$$ If my interpretation of second quantifier order is flawed, could you please tell me how to interpret it correctly in this context ? I realized that order matters by going through other mse posts already.","['calculus', 'real-analysis', 'analysis']"
983830,Closed form of $\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx$,"I'm looking for a closed-form expression for the value of this integral: $$I=\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx$$ The graph of the integrand looks like this: $\hskip 2.4 in$ Numerically, the area is $0.875044...$ for which the Inverse Symbolic Calculator doesn't produce anything promising. My CAS finds neither an antiderivative nor a closed form for the definite integral, and my own manipulations haven't really got me anywhere either.","['definite-integrals', 'closed-form', 'integration']"
983849,Group theory: subset of a finite group,"Given $G$ be a finite group $X$ is a subset of group $G$ $|X| > \frac{|G|}{2}$ I noticed that any element in $G$ can be expressed as the product of 2 elements in $X$. Is there a valid way to prove this？ If the third condition was $|X| = \frac{|G|}{2}$ instead, does the above statement still hold? Thank you.",['group-theory']
983869,Number theory / Group theory: consecutive integers divisible by at least n prime numbers,"Claim: There exist 15,251 successive positive integers $a_1, a_2\dots,a_{15251}$  such that
each $a_i$ where ($1\le i\le 15251$) is divisible by at least 251 different prime numbers Is there a neat way to prove the above claim? All help is greatly appreciated.","['group-theory', 'number-theory']"
983875,Equation of a curved line that passes through 3 points?,"I have a screen wherein the upper-leftmost part is at x,y coordinate (0,0). Then I have a curved line that passes through 3 points: (132, 201), (295, 661) and (644, 1085). Now, say I want to find 7 points within that curved line so that the line will be equally divided into 6 segments. How do I go about computing the coordinates of these 7 points?","['geometry', 'linear-algebra', 'algebraic-geometry']"
983878,Why is $V(x)\cup(\mathbb{A}^2\setminus V(y))$ not quasi-affine?,"I'm having trouble understanding the following situation. Apparently it's not difficult to see the union $V(x)\cup(\mathbb{A}^2\setminus V(y))$ is not a quasi-affine set. Everything is being done over an algebraically closed field, and the $V(-)$ are the closed sets. So I think I have
$$
V(x)=\{(a_1,a_2)\in\mathbb{A}^2:f(a_1,a_2)=0\}
$$
where $f(x,y)=x$. So $V(x)=\{(0,b)\in\mathbb{A}^2\}$, the $y$-axis. Likewise $V(y)$ is the $x$-axis. So I think $V(x)\cup(\mathbb{A}^2\setminus V(y))$ is geometrically the plane with the $x$-axis removed, except for the origin. Is it somehow clear this is not quasi-affine? If this could be expressed as the set theoretic difference of closed sets, I believe it would have to be something like $\mathbb{A}^2\setminus Z$ where $Z$ is the $x$-axis except for the origin. It doesn't seem likely that there is a family of functions vanishing only there, is there a nice way to see it more rigourously?","['general-topology', 'algebraic-geometry']"
983885,Can a Power Series tell when to stop?,"The naive description of the radius of convergence of a complex power series is as the largest radius so that the ball avoids poles and branch cuts. This makes sense in a world where analytic functions are at worst meromorphic on $\mathbb{C}$ or involve the complex logarithm, but is patently false when you consider things like $$f(z) = \sum_{n=0}^\infty \frac{z^{n!+1}}{n!+1}$$ which is continuous on the boundary $|z|=1$ but has $\mathbb{D}$ as its full domain. A better way of talking about power series is to say that a power series terminates when it encounters a singular point: a point that the function cannot be analytically continued through. Question: Is there a sufficient way of looking at properties of a function within its domain to tell if you are ""getting close"" (in some sense or another) to a singular point? Can this be done while avoiding statements about points on the boundary explicitly, perhaps by talking exclusively about the behavior of the function or its derivatives? This is to say, can a power series tell when it's time to stop? Consider these examples. When $f$ has a pole at an isolated point in its domain, then clearly the power series cannot extend beyond such a point. This follows from a simple argument about the modulus of $|z|$ in the power series as we near a point where $|f(z)| \to \infty$. Specifically, we have a sequence of values $z_k$ in the domain approaching the singular point with $\lim_k |f(z_k)| = \infty$. On the other hand, $|f(z)|$ might be bounded on a domain and still cause the power series to fail. One example of a bounded function on $\mathbb{D}$ with natural boundary $\partial \mathbb{D}$ is a Blaschke product whose zeros accumulate at every point on the boundary. Here we can understand the failure of the power series for $f$ as arising from the data of $f$ itself, since $f$ cannot have its zeros accumulating. This is to say, there is a sequence $z_k$ in the domain approaching the singular point(s) with $|f(z_k)|=0$. We can consider lacunary series like the one mentioned above. One way of explaining the failure of the power series of $f$ in this case is to think of it as being constructed as the Fourier decomposition of $f(Re^{i\theta})$ for some $\{|z|=R\}$ contained in the domain of $f$. In this case we have $$f(z) = \int_\gamma \frac{f(w)}{w-z}dw = \sum_{n=0}^\infty\left(\frac1{2\pi}\int_{-\pi}^\pi f(Re^{i\theta}) e^{-in\theta} d\theta\right) \frac{z^n}{R^n}$$ Take, for example, $\sum_{n=0}^\infty \frac{z^{2^n}}{n^2}$. When $|z| =r < 1$ then the geomtric decay of $z^n$ smooths out the Fourier series for $f(re^{i\theta})$, but as we approach the boundary $\partial \mathbb{D}$ we begin to see the lacunary Fourier series $\sum_{n=0}^\infty \frac1{n^2}e^{i2^n \theta}$. If fast decaying Fourier coefficients represent smooth functions, these incredibly slow decaying Fourier coefficients emphasize the fact that the graph of this Fourier series is fractal, and so it can't possibly be used to continue the function. In this situation, radial limits of $f$ exist ($f$ is in $H^2(\mathbb{D})$), but points approaching the boundary don't depend on each other smoothly enough. One last perspective. Constructing functions that are continuous on $\overline{\mathbb{D}}$ but have $\partial\mathbb{D}$ as their natural boundary usually involves taking lacunary series and adding in decaying coefficients. If the coefficients are in $\ell^2(\mathbb{N})$ then the function is in $H^2(\mathbb{D})$ and has radial boundary values almost everywhere on $\partial\mathbb{D}$. On the other hand, if the gaps are big enough then the coefficients of the derivative(s) will be wild (this is essentially the statement of Ostrowski–Hadamard). If the power series ends because of a point that $f$ extends to continuously along a radial line, we can think of trying to analytically continue the function along that line. In this case we get something like the following picture of $$f(z) = \sum_{n=0}^\infty \frac{z^{n!}}{n^2+1}$$ with real part plotted over the line going from 0 to $i$. $\hskip1in$ Final Comments: I have decided against removing any of these points in case there are students who find them interesting. I suppose a reformulation of my question might be: Is there a more geometric way of explaining when a power series decides to stop, in contrast to simply looking at successive derivative operations applied to the coefficients (which is more or less how we actually compute the radius of convergence)?","['power-series', 'soft-question', 'complex-analysis']"
983893,How can I calculate $\lim_{x \to 0}\left(\frac{\sin{x}-\ln({\text{e}^{x}}\cos{x})}{x\sin{x}}\right)$ limit without using L'Hopital's rule?,$$\lim_{x \to 0}\left(\frac{\sin{x}-\ln({\text{e}^{x}}\cos{x})}{x\sin{x}}\right)$$ Can this limit be calculated without using L'Hopital's rule?,"['limits-without-lhopital', 'calculus', 'real-analysis', 'analysis', 'limits']"
983923,Intersection of inverse images [duplicate],"This question already has answers here : how to prove $f^{-1}(B_1 \cap B_2) = f^{-1}(B_1) \cap f^{-1}(B_2)$ (2 answers) Closed 7 years ago . Given $A$ and $B$ is the subset of $C$ and $f:C\mapsto D$,
$$f(A\cap B)\subseteq f(A) \cap f(B)$$ and the equality holds if the function is injective. But why for the inverse, suppose that $E$ and $F$ is the subset of $D$,
$$f^{-1}(E \cap F) = f^{-1}(E) \cap f^{-1}(F)$$
without saying that the inverse function is injective. So if 
$$x\in f^{-1}(E) \cap f^{-1}(F)$$
$$x\in f^{-1}(E) \text{ and } x\in f^{-1}(F)$$
This means that there exists elements $y_1 \in E$ and $y_2 \in F$.
So here how do we know that these two elements are equal. I am independent learner so I hope I can get an explaination in more details.","['elementary-set-theory', 'functions']"
983946,Domain of $\frac{1}{\frac{1}{x}}$,"Let $f(x)=\frac{1}{x}$, then we have $f^{-1}(x)=\frac{1}{x}$. So $f(f^{-1})=\frac{1}{\frac{1}{x}}=x$. My question is, what is the domain of $f(f^{-1})(x)$? is it everything? or everything but zero? Then if we plot the graph of $\frac{1}{\frac{1}{x}}$ how will it look like? Will it look just like $y=x$ or $y=x$ with the origin excluded? I tried to plot using google, the result looks exactly like $y=x$ without the origin removed. But why? I think according to the rule when we compose two functions in this case, the origin must be removed. Thanks for clarifying my confusion.","['graphing-functions', 'functions']"
983954,Critical points for undefined fraction on closed interval,"I am told to find the absolute extrema of $$h(x) = \frac{8+x}{8-x},[4,6]$$ So I obtain the derivative of $$\frac{16}{(8-x)^2}$$ The trouble I am having is trying to determine the critical points. I know that a critical point is found where the derivative is equal to zero or does not exist. So my assumption would be that the critical point is $\frac{16}{(8-8)^2}$, i.e. x = 8 Looking for someone to shed some light on this. Would there be no critical points because the function is discontinuous (I think) and therefore I would just test the endpoints? Thank you for any help!","['calculus', 'derivatives']"
983986,Is shunting-yard algorithm needed if there is no parenthesis?,"I am trying to find a permutation (with replacement) of operators(such as addition and multiplication) that makes numbers 1 2 3 , ..., 9 result in to some numbers. My guess is to find all possible permutation with Cartesian products (8 times) of {operator set}, and append them after the numbers (e.g. 1 2 3 , ..., 9 + * + + * * ...) and evaluate them. The question is, if I am not using parentheses, i.e. there is nothing like 1 + 2 * (3 + 4), am I safe to attach an array of 8 binary operators after the 9 numbers? Or even in that case should I first construct the expression in in-fix, and convert it into Reverse Polish notation using Shunting-yard algorithm? Also, will there be any further optimization or better algorithms that I could make use of? Thanks.","['algebra-precalculus', 'algorithms', 'discrete-mathematics']"
984004,"Relationship ""finite mean"" <-> ""absolutely integrable","What is the relationship between the property of a random variable (i.e. a measurable function defined on some probability space) being absolutely integrable, i.e. $$\mathbb{E}|X|<\infty$$and having finite mean, i.e.$$\mathbb{E}X<\infty\quad ?$$Obviously the first implies the second, but does the converse hold too ?","['probability-theory', 'probability']"
984008,Making a piecewise function continuous and differentiable at point,"Problem: Let $f(x) = \left\{
  \begin{array}{lr}
    \frac{\arctan(x)}{(1+x)^2} & : x \geq 0\\
    Ae^x + B & : x < 0
  \end{array}
\right.
$ Find $A$ and $B$ such that the function is continuous and differentiable at $x=0$. My attempt: To ensure continuity at $x = 0$ I figured $A = B = 0$ would be the only option. But this, of course, seems very wrong, and in any case, it wouldn't cause differentiability at $x=0$. As far as I could tell, the derivative of $\frac{\arctan(x)}{(1+x)^2}$ at $x=0$ would be $1$. While the second piece's derivative evaluates trivially to $0$.","['calculus', 'derivatives', 'functions']"
984026,Inverse Trigonometric Integrals,"How to calculate the value of the integrals
$$\int_0^1\left(\frac{\arctan x}{x}\right)^2\,dx,$$ $$\int_0^1\left(\frac{\arctan x}{x}\right)^3\,dx
$$ and $$\int_0^1\frac{\arctan^2 x\ln x}{x}\,dx?$$","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
984044,Improper integral : $\int_0^{+\infty}\frac{x\sin x}{x^2+1}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How to evaluate the following improper integral : $$\int_0^{+\infty}\frac{x\sin x}{x^2+1}\,dx$$
I have tried integration by parts and variable substitution, but it didn't work.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
984081,Why limit $\sqrt{\frac{\sin(x)}{x}}$ as $x \rightarrow \infty$ is not a real number?,"Let 
$f(x)=\sqrt{\frac{\sin(x)}{x}}$. Why isn't the $\lim\limits_{x\rightarrow \infty} f(x)$ equals to some $l \in \mathbb{R}$? The definition of a finite limit at inifinity is: $$\forall \epsilon>0, \exists X \in \mathbb{R}, \forall x \ge X,|f(x)-l| <\epsilon  \tag{1}$$ It looks to me that $l=0$ meets the above definition... I know that the negation of the definition of a finite limit at infinity is:
$\exists \epsilon >0 , \forall X \in \mathbb{R}, \exists x \in \mathbb{R}, x\ge X \Rightarrow  |f(x)-l| >=\epsilon \tag{2}$ Is $(2)$ true because, for any $X\in \mathbb{R}$, there will be an $x\ge X$ and $f(x)$ is undefined (i.e. the points where $\frac{\sin(x)}{x} < 0$) and we say the distance between $f(x)$ at these points and any $l\in\mathbb{R}$ is undefined and hence considered as greater than or equal to any $\epsilon > 0$? If yes, how do I write this out using the delta-epsilon proof? Otherwise, please tell me how to prove $(2)$ EDIT: The definition for a finite limit and infinity according to my text is: We say that $f(x)\rightarrow l$ as $x\rightarrow \infty$ for some real number,$l$, if: for any $\epsilon>0$, there is an $X$ such that, for all $x\ge X$, $|f(x)-l|<\epsilon$","['definition', 'epsilon-delta', 'calculus', 'limits']"
984111,Differentiating with respect to the limit of integration,"I'm confused about problems involving differentiation with respect to the limit of an integral, I just want to check that my understanding is correct. For example, are the following statements correct? : $$
\frac{d}{dx}\int_0^xs^2ds=x^2
$$ $$
\frac{d}{ds}\int_0^xs^2ds=\int_0^x2s~ds
$$ and by the product rule:
$$
\frac{d}{dx}\int_0^x~x~s^2ds=\int_0^xs^2~ds+x^3
$$","['calculus', 'integration', 'derivatives']"
984131,"Different Definitions of Tensor product, Halmos, Formal Sums, Universal Property","In the classic Finite-Dimensional Vector Spaces by P. Halmos he defines the Tensor product as The tensor product $U \otimes V$ of two finite-dimensional vector spaces $U$ and $V$ (over the same field) is the dual of the vector space of all bilinear forms on $U \oplus V$ [remark, by this he means all bilinear maps $\omega : U \times V \to \mathbb F$]. For each pair $x$ and $y$, with $x$ in $U$ and $y$ in $V$, the tensor product $z = x \otimes y$ of $x$ and $y$ is the element of $U \oplus V$ defined by $z(w) = w(x,y)$ for every bilinear form $w$. Another construction, for example here or on Wikipedia , the tensor product is defined as the set of all formal sums on $U \times V$ modulo certain (''bilinear'') identities. This is equivalent to the set of all formal sums on $\{ u_i \}_{i\in I} \times \{ v_j \}_{j \in J}$ for bases $u_i$ and $v_j$ of $U$ and $V$. According to my first reference , the set of all multilinear maps $V_1 \times \ldots \times V_k \to \mathbb F$ could be identified with $V_1^* \otimes \ldots \otimes V_k^*$, this seems always possible (not requiring finite dimensions), so in particular the set of all bilinear maps $U \times V \to \mathbb F$ could be identified with $V^* \otimes U^*$, so in Halmos definition the tensor product equals $(V^* \otimes U^*)^*$, where the tensor product is defined as the set of formals sums as above. But to make sense, this definition must equal the definition by formal sums, so we must have $(V^* \otimes U^*)^* \cong V \otimes U$ to bring Halmos definition and the definition by formal sums in harmony. But I guess here seems to be some sort of reflexivity involved, so he might used the finite-dimensionality of the vector spaces, or could Halmos definiton further extended, does I got it right? Still another construction I found is by the following universal property (see also Wikipedia ), i.e. the tensor product of two vector spaces $U$ and $V$ is such that for each bilinear map $U \times V \to W$ there exists exactly one linear map $U \otimes V \to W$, and this correspondence is linear, i.e. we have
$$
 \mbox{Bil}(U, V; W) \cong \mbox{Hom}(U\otimes V, W).
$$
In our case $W = \mathbb F$ the ground field, then
$$
 \mbox{Bil}(U, V; \mathbb F) \cong (U\otimes V)^*
$$
But by Halmos definition the tensor product equals $\mbox{Bil}(U, V; \mathbb F)^*$, so again this seems require some sort of reflexivity, i.e. $((U \otimes V)^*)^* \cong (U\otimes V)$. But here the property to bring the definitions together reads still a little bit different, to make them all the same we need $(U^* \otimes V^*) \cong (U\otimes V)^*$, but this holds in general vector spaces, as $(U^* \otimes V^*) \cong \mbox{Bil}(U, V; F) \cong (U \otimes V)^*$. So my questions again: 1) does I got everything right?, 2) am I right that Halmos definition is limited, and how far could we go with it, is reflexivity the right property to demand?","['tensor-products', 'linear-algebra', 'multilinear-algebra', 'differential-geometry']"
984135,Why is the sine and cosine always between $-1$ and $1$?,"Why is the sine and cosine always between $-1$ and $1$? If I would have circle with a radius other than $1$, then it wouldn't be between $-1$ and $1$ anymore, would it? This also ties in with another thing I'm getting confused about: the $x$ and $y$-coordinates of a point on a circle are defined by $\cos\theta$ and $\sin\theta$. But what if the radius would be defined as anything other than having a length of $1$ unit? Would you still be able to find the $(x, y)$ coordinate of the point on the circle?",['trigonometry']
984150,Implications of some sort of $l^2$/uniform convergence,"Sorry about the title, but I couldn't really figure out how to describe my problem in one sentence... I'm having some problems with real limits: For $f,g : \mathbb{N} \to \mathbb{R}$ let $\mathcal{F}(f,g) := \sum\limits_{k=1}^{\infty} (f(k) - f(k+1))(g(k)-g(k+1))$ and let $D := \left\lbrace f : \mathbb{N} \to \mathbb{R}~ | ~ \mathcal{F}(f,f) < \infty \right\rbrace$. For $v \in \mathbb{N}$ set $o_v(f,g) := f(v)g(v)$. Then $\mathcal{F} + o_v$ provides a complete inner product on $D$. So far so good. Now fix $v \in \mathbb N$ and suppose we have some fixed function $f$ and a sequence of functions $f_n$ converging in $D$, i.e. $\mathcal{F}(f_n - f) + o_v(f_n -f)\to 0$ as $n \to \infty$. Obviously, it follows that $f_n \to f$ point-wise and even
$$\sup\limits_{x \in \mathbb{N}} |f_n(x)-f_n(x+1) - (f(x)-f(x+1))| \to 0$$
i.e. we have some sort of uniform convergence. My question is: Can I produce some statement along the lines of $f_n(n) \to \lim\limits_{x \to \infty} f(x)$? Thoughts, help and hints are greatly appreciated :)","['convergence-divergence', 'calculus', 'real-analysis', 'functional-analysis', 'limits']"
984151,Proof that the tensor product is the coproduct in the category of R-algebras,"Given the category of commutative R- or k-Algebras, it is often mentioned that the coproduct is the same as the tensor product. I'm interested in the proof of this statement. One idea would be to proof some unique property, but I'm not sure how to do this (or if this is actually the right way). An elaborative explanation would be much appreciated.","['tensor-products', 'category-theory', 'abstract-algebra']"
984176,Schur's Lemma: Is the isormorphism between two irreducible spaces unique?,Suppose $V_1 \neq V_2$ are two irreducible representations of the finite group G. Then Schur's Lemma says that any G-invariant map between them is either 0 or an Isormorphism. I understand that if $V_1 = V_2 = V$ then any automorphism is a scalar multiple and it is proved by considering eigen spaces. QHowever if these two vector spaces are not the same then what can I say about the isomorphism between them? Is it unique upto a scalar multiple? How does one prove this since I cannot consider eigen spaces.,"['linear-algebra', 'finite-groups', 'group-theory', 'representation-theory']"
984179,How to compute $ \int e^{-st} \sin(2t) dt $,"Wolfram Alpha shows me the result of $ \int  e^{-st} \sin(2t) dt $ .
However it doesn't let me see the step to step solution. Then I tried to do this by hand as the solution didn't look ""too difficult"", however couldn't do it. 
So can someone show me how to do it?",['integration']
984185,Can you cancel out a term if equal to zero?,"quick question here: In my proofs class we had a problem that after a little work we end up with:
$x(x-y)=(x+y)(x-y)$ where $ x = y $. Now, I know this is pretty basic, but my teacher said that for the next step, one cannot cancel out $(x-y)$ from both sides as $(x-y) = 0 $. 
Can someone explain the logic and/or the reasoning behind this? I'm pretty sure this falls under some obscure basic algebra rule that I've forgotten over the years but I cannot find anything about this on the internet. Edit: To clear up some confusion here, I am not looking for how to solve this problem, but rather the why this particular rule is so. The problem I am working on gives a proof. I am supposed to mark the errors in the proof. For this problem, the error was that they cancelled out $(x-y)$ and I am trying to understand why that's an error.",['algebra-precalculus']
984189,Average order of Eulers totient function squared,"I was wondering if one has a nice asymptotic formula for the sum
$$\sum_{n\le x} \phi(n)^2$$
and if so, how does one calculate it. I know that one has $\sum_{n\le x} \phi(n) = \frac{3}{\pi^2}x^2+O(x\log x)$, but I can't seem to find similar results for other powers of $\phi$.",['number-theory']
984216,Condition for trigonometric inequality,"I want to prove the following statement: Suppose $\frac{1}{4}(\cos(\theta_1)+\cos(\theta_2))^2+\lambda^2(a\sin(\theta_1)+b\sin(\theta_2))^2\leq 1$ holds for all $\theta_1,\theta_2\in[-\pi,\pi]$, then we should have $\lambda^2(a^2+b^2)\leq \frac{1}{2}$. This problem appears when I want to find the stability condition for a numerical scheme. I tried to use Lagrange multiplier, but it turns out to be very complicated. I have also tried to find some specific $\theta_1,\theta_2$, so that the first inequality can imply the second, but I failed to do so.","['optimization', 'trigonometry', 'inequality', 'numerical-methods']"
984254,Fundamental solution of heat equation on a compact Riemannian manifold,"Let $(M,g)$ be a compact Riemannian manifold of $m$ dimensional. 
Then there exists a sequence $(\phi_i, \lambda_i)_{i\in\mathbb{N}}\subset C^\infty(M)\times\mathbb{R}_{\geq0}$ such that 
\begin{eqnarray}
0=\lambda_0<\lambda_1\leq\lambda_2\leq\cdots\to\infty\\
\Delta\phi_i+\lambda_i\phi_i=0\\
\end{eqnarray}
and $(\phi_i)_i$ forms a complete orthonormal system of $L^2(M)$. Then, my textbook says that
\begin{equation}
H(x,y,t):=\sum_{i=0}^\infty e^{-\lambda_it}\phi_i(x)\phi_i(y)
\end{equation}
is the fundamental solution of the heat equation $\Delta u-\dfrac{\partial u}{\partial t}=0$. I cannot understand what the sum means. Does the sum converge in $L^2(M\times M)$ for all $t$? Or does it converge pointwise on $M\times M\times (0,\infty)$? I want to know the mean of the $H$ as a function.","['partial-differential-equations', 'differential-geometry', 'analysis']"
984284,"What exactly does ""differential forms are coordinate free"" mean?","Most introductory texts on differential forms praise their property of allowing for a ""coordinate free formulation"". What exactly does this mean? What would be a concrete example for which a coordinate free formulation is superior to choosing a coordinate system? I am aware that expressing calculations in differential geometry in local parametrizations can be a mess, but aren't we also always choosing a basis for differential forms in writing something like $$\omega = \sum_{k=1}^n a_i dx_i,$$ where $\{dx_1,\dots, dx_n\}$ is a basis of $T_p \mathbb{R}^n = \mathbb{R}^n$ for some point $p \in \mathbb{R}^n$?","['differential-forms', 'differential-geometry']"
984290,Converting plane equation from $ax+by+cz=d$ to $r=a+\lambda b+\mu c$,"The equation of the plane Π is
  $$2x + 3y + 4z= 48$$ Obtain a vector equation of Π in the form
  $r = a + λb + μc$,
  where a, b and c are of the form pi , qi + rj and si + tk respectively, and where $p, q, r, s, t$ are integers My Attempt: $a=(p,0,0)$ $2p+3(0)+4(0)=48 \implies p=24$ Then for the other variables I wrote down two equations: (1) $(2,3,4) \cdot (x,y,z)= (24+\lambda q+ μ s, \lambda r, μ t)$ (2) Cross product of $b$ and $c$ is equal to $(2,3,4)$ This gives $(rt,-qt,rs)=(2,3,4)$ It seems impossible to me. Too many  variables that my mind can't process. Please help.","['multivariable-calculus', 'vectors']"
984293,Is log-general type an intrinsic property of a variety,"Let $X$ be a smooth quasi-projective variety over $\mathbb C$. Let us say that $X$ is of log-general type if for some choice of smooth compactification $\bar X$ with normal crossings boundary divisor $D = \bar X \setminus X$, we have that the pair $(\bar X, D)$ is of log-general type. The latter means that $K_{\bar X} + D$ is big. Is this an intrinsic property? That is, is it independent of the choice of $\bar X$ and $D$? Also, suppose now that $X$ is only a normal quasi-projective variety. I would like to say $X$ is of log-general type if some desingularization of $X$ is of log-general type. Is this well-defined? That is, is this independent of the chosen desingularization of $X$?","['birational-geometry', 'compact-manifolds', 'algebraic-geometry', 'complex-geometry']"
984303,Twisted logarithm power series,"I recently encountered a power series similar to the one of the $\log(1-x)$ of the form $$
F(x)= \sum_{n=1}^\infty \frac{\psi(n)x^n}{n},
$$
where $\psi$ is some Dirichlet character. Has anyone here seen a function like this? Here are some observations I have made: 1) The radius of convergence is the same as for $\log(1-x)$, so the power series converges for $|x| < 1$. 2) If $\psi(n)$ is the trivial characer mod $N$ then $F(x) = \sum_{n=1}^\infty \frac{x^n}{n}-\frac{x^{Nn}}{Nn}=-\log\left(\frac{1-x}{1-x^N}\right)$. The next interesting case would be when $\psi$ is a quadratic character. I'd be happy about any reference or further observation on these functions.","['power-series', 'number-theory']"
984313,Is an ideal also a normal subgroup?,"The book I have first goes over group theory. Once it gets to rings and starts discussing subrings along with cosets and factor rings it leaves out some details for brevity and to not repeat what has already been said in the group theory portion. But in this instance, it left something out or perhaps it can be easily derived. It defines an ideal as a subring $H$ of a ring $R$ such that $\forall a \in R$ it is the case that $aH, Ha \subset H$, and it then states this is the analogue of the definition of normal subgroup in the context of group theory and implies a factor ring $R/H$ is created by the existence of some natural homomorphism. Here is where I'm confused. It makes no mentions that the criterion for being a normal subgroup also has to be satisfied in order for this factor ring to be well-defined. Am I correct that the criteron for being a normal subgroup has to also be satsified in order to a (1) be an ideal and (2) in order that a factor ring can be formed?",['abstract-algebra']
984318,Why does Givens rotation avoid iteration and Jacobi rotation doesn't in case of reducing a symmetric matrix to tridiagonal?,"I am currently implementing symmetric matrix reduction to tridiagonal.
I read that Givens rotation avoids iteration when it is used for reducing a matrix to tridiagonal whereas Jacobi rotation is iterative. Givens rotation try to annihilate the element $a_{i-1j}$ by a rotation in $ij-$plane and Jacobi rotation try to annihilate the element $a_{ij}$ by a rotation in $ij-$plane. But just because of that, how can Givens rotation avoid iteration as both use same equations? $a^{'}_{rp}=ca_{rp} - sa_{rq}$ $ a^{'}_{rq}=ca_{rp} + sa_{rq}$ $ a^{'}_{pp}=c^{2}a_{pp}+s^{2}a_{qq}-2sca_{pq}$ $a^{'}_qq=s^{2}a_{pp}+c^{2}a_{qq}+2sca_{pq}$ $a^{'}_{pq}=(c^{2}-s^{2})a_{pq}+sc(a_{pp}-a_{qq})$ Now in Jacobi rotation , they try to zero out $a^{'}_{pq}$ and in Givens rotation they try to zero out $a^{'}_{p-1q}$ i.e.,$ a^{'}_{rq}$.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
984390,"Compute a multiple integral$\iint_{[0,1]^2} (xy)^{xy} dxdy$","$$\text{Compute} :\iint_{[0,1]^2} (xy)^{xy} dxdy$$ I am thinking about changing the variable, $x=u,y={v \over u}$.But it doesn't work. I just found that the answer is$\int_0^1 t^t dt$.Maybe my idea is right?","['multivariable-calculus', 'integration']"
984391,Solve the following ODE,Solve the following ODE $$(y-x)\left(1+x^2 \right)^{\frac{1}{2}}\dfrac{\mathrm{d}y}{\mathrm{d}x}=n\left(1+y^2 \right)^{\frac{3}{2}}$$ I have tried substituting $y=\tan \theta$ and $x=\tan \phi$ but can't do it. Any help is appreciated.,['ordinary-differential-equations']
984392,closed but not exact,"I saw several times that $\frac{-y}{x^2+y^2}dx+\frac{x}{x^2+y^2}dy$ is closed but not exact. Closed, is obvious but I can't prove non exactness, can one please help me ? My attempt, let $f\in \omega^{0}(U)$ and $df=\frac{-y}{x^2+y^2}dx+\frac{x}{x^2+y^2}dy=\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y} dy$ and so $\frac{\partial f}{\partial x}(x,y)=\frac{-y}{x^2+y^2},\frac{\partial f}{\partial y}(x,y)=\frac{x}{x^2+y^2}$. Now let $g(\theta)=f(\cos \theta,\sin \theta)$ so $g'(\theta)=1 \implies g(\theta)=\theta+C$. Now i'm not getting any contradiction.",['differential-geometry']
984399,Fundamental solution of Laplacian on manifold,"I'm looking for a reference for the result that there exists a fundamental solution for the Laplacian on a flat torus
$$\Delta \Gamma(x-y) = \delta(x-y), \quad x,y \in \mathbb T^2.$$
and that, locally, one can write $\Gamma(x-y) = c\log(|x-y|) + h(x,y)$, where $h(x,y)$ is harmonic in $x$. I think one could prove this in a quite simple way by fixing a cut-off function $\rho \in C^\infty(\mathbb R^2)$, supported close to $(0,0)$; $\rho$ can also be interpreted as a function on the torus, or rather, we can consider the periodization $\rho^{(p)}(x) = \sum_{k\in \mathbb Z^2} \rho(x-k) \in C^\infty(\mathbb T^2)$ (which I won't do below). Let $\psi \in C^\infty(\mathbb T^2)$ be solution to 
$$\Delta \psi = -c[2\nabla \rho(x-y)\cdot \nabla \log(|x-y|) + (\Delta \rho(x-y))\,\log(|x-y|)].$$ By construction, the function $\Gamma(x,y) = \rho(x-y) \log(|x-y|) + \psi(x,y)$ solves $\Delta \Gamma = \delta(x-y)$; and it has the claimed form, locally. However, I'd like to have a reference for this. Does anyone know of a good reference?","['differential-geometry', 'laplacian', 'partial-differential-equations', 'riemannian-geometry', 'reference-request']"
984418,Pell's Equation and the Pigeon Hole Principle,David Speyer gave a beautiful application of the pigeon hole principle here to show that Pell's equation $$x^2-Dy^2=1$$ has infinitely many integral solutions. I was wondering if anybody knows the history/origin of this argument...In particular was this the original argument used by Lagrange?  Or was it Dirichlet?  Or is this argument an original due to Speyer?  Thanks! PS I am not looking for alternative proofs of the solvability of Pell's equation...just comments on the proof given above.,"['pell-type-equations', 'math-history', 'number-theory']"
984436,Probability Assignment to Intervals in $\mathbb{R}^{n}$.,"Given a random variable $\bf{X}$ distributed on $\mathbb{R}^{n}$, let $F_{X}(t)$ be its distribution function. Suppose we want to find $P\left(\textbf{X} \in (\textbf{a}, \textbf{b}]\right)$. I was taught that $$P_{X}(\textbf{a}, \textbf{b}] = \sum_{s \in S} (-1)^{N_{a}(\textbf{s})} F_{X}(\textbf{s})$$ provided $\textbf{a} \leq \textbf{b}$. Here, $S = \{\textbf{x} \in \mathbb{R}^{n} : x_{i} = a_{i} \text{ or } x_{i} = b_{i} \text{ for all } i\}$ and $N_{a}(\textbf{s})$ counts the number of times that $s_{i} = a_{i}$ for $i = 1, \dots, n$. In view of the alternating sum of the corners of a box (which is what $S$ is), is there anything like Stoke's Theorem at work here? It seems that all you really need to compute the probability is knowledge of $2^{n}$ points; this isn't quite the boundary of the box, so I'm not sure that this is the case. What motivates this approach of summing the corners of the box determined by $(\textbf{a}, \textbf{b}]$? How is it justified? Are there any textbooks where I may find this sort of definition and a corresponding discussion/construction?","['statistics', 'measure-theory', 'probability', 'probability-theory']"
984473,Basis of the matrices with only non diagonalizable matrices,"Is it possible to find a basis of $M_n(\mathbb{R})$ that only has non diagonalisable matrices ? I'm looking for a rather easy example, or a proof of the (non-)existence.","['matrices', 'linear-algebra', 'diagonalization']"
984490,Notation for non-empty subset,"To denote non-empty subsets, I repeatedly find myself writing $A\subset S, A\neq \emptyset$. Is there any established shorthand for this, you know, like $A\subset S$ can be seen as a shorthand for $A\subseteq S, A\neq S$?","['notation', 'elementary-set-theory']"
984493,Composition of projections has a fixed point in a Hilbert space,"Let Let H be a Hilbert space with an  inner product ⟨⋅,⋅⟩ : H×H→R, and induced norm $∥⋅∥ : H→R_+$ Let $C_1$ and $C_2$ be closed, convex, nonempty, disjoint subsets of $H$ with at least one of them compact. And $P_X:H→X$ the metric projection onto X, i.e., $P_X(x):=argmin_{y∈X}∥x−y∥$ for convex compact nonempty subsets of H and $x \in H$. Let $P: C_1 → C_1$ be given by $P(x) = (P_{C_1} \circ P_{C_2})(x) $ for $x \in C_1$ I want to prove the following: Let $x \in C_1$ fixed, then the succession $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point. I tried (unsuccessfully) to prove that it $(P^n(x))^{\infty}_{n=1}$ is a Cauchy succession and so it converges to a point in $C_1$, I know that $P_x$ is firmly non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \langle x-y, P_X(x) - P_X(y) \rangle$ and hence non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \left\| x-y\right\|^2$ I also proved previously that if x is a fixed point of P then x minimizes the distance between $C_1$ and $C_2$. I also tried to prove that $P(x)$ strictly metric i.e. the inequality is strict for every two different points.  So I could use some modification of the contraction mapping theorem. I also believe that P is continuous, because it is a composition of continuous functions, and so there exist a fixed point (either $C_1$ or $C_2$ is compact and convex). Also I've read that any non-expansive function from a closed convex bounded set onto itself has at least one  fixed point. However, how can I prove that  $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point? Any advice would be greatly appreciated. I really think that the key is to prove that  $(P^n(x))^{\infty}_{n=1}$ is Cauchy, however I haven't been able to prove that.","['fixed-point-theorems', 'convex-analysis', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
984587,Beautiful little geometry problem about sines,"Given triangles ABC and $A_1B_1C_1$ such that $\sin A = \cos A_1, \sin B = \cos B_1, \sin C = \cos C_1$. What are the possible values for the biggest of these 6 angles? I tried some stuff like sine theorem but can't derive from it? How do we do this one? Assume the closest to the smallest angle?","['geometry', 'triangles']"
984594,"Explain $x^{x^{x^{{\cdots}}}} = \,\,3$","$$x^{x^{x^{\cdot^{\cdot^{\cdot}}}}} =\quad 2$$ This equation has the answer $\sqrt{2}$ by taking $\log$ to both side. This answer is correct because I'd proven it by replacing $x$ with $\sqrt{2}$ then computed the expression repeatedly and the answer is close to $2$ . But now consider, $$x^{x^{x^{\cdot^{\cdot^{\cdot}}}}} =\quad 3$$ I tried using the same solving method and it gave me that $\sqrt[3]{3}$ is the answer but when I tried proving the answer by replacing $x$ with $\sqrt[3]{3}$ and computed it repeatedly, the answer is closer to $2.478052680288297$ and not $3$ I don't know why this happens, could someone explain the answer to $x^{x^{x^{\cdot^{\cdot^{\cdot}}}}} = 3$ ? I don't think it's $\sqrt[3]{3}$ The first equation problem came from brilliant.org","['power-towers', 'algebra-precalculus', 'tetration', 'limits']"
984633,Converting an ODE in polar form,"Convert the ODE system
    $$
\dot{x}=\begin{pmatrix}a(t) & b(t)\\c(t) & d(t)\end{pmatrix}x
$$
    into polar form. You should get two equations
    $$
\frac{d}{dt}\Phi(t)=...\\ \frac{d}{dt}\ln r(t)=....
$$ I set
$$
x_1:=r(t)\cos\Phi(t)\\ x_2:=r(t)\sin\Phi(t)
$$
and got
$$
\frac{d}{dt}\Phi(t)=b(t)+\frac{\frac{d}{dt}r(t)\cos\Phi(t)}{r(t)\sin\Phi(t)}-\frac{a(t)\cos\Phi(t)}{\sin\Phi(t)}\\ \frac{d}{dt}\ln r(t)=d(t)+\frac{c(t)\cos\Phi(t)}{\sin\Phi(t)}-\frac{\cos\Phi(t)\frac{d}{dt}\Phi(t)}{\sin\Phi(t)}
$$ Would like to know if this is right. With greetings",['ordinary-differential-equations']
984678,Using descartes rule of sign,"Use Descartes' rules of signs to discuss the possibilities for the roots of each equation. Do not solve equation.
  $$p(x)= x^3+5x^2+7x+1=0$$ $p(x)$ I saw no sign change $p(-x)$ I saw 2 sign changes because $-x^3+5x^2-7x+1=0$.
I am stuck how is the answer $3$ negative roots for $p(x)$ and how do I get $1$ negative and $2$ imaginary roots for $p(x)$?","['algebra-precalculus', 'roots', 'polynomials']"
984711,Efficiently solving algebraic equation,"I would like to solve following equation: $$15 (x+2)^{-4} = 11(x+2)^{-2} +4$$
I would first remove the negative power by adding $(x+2)^4$ Then I get 
$$15 = 11(x+2)^2 + 4(x+2)^4\\
11(x+2)^2 + 4(x+2)^4 -15 = 0$$
should I do now a quadratic equation where $d=(x+2)^2$ $$11d + 4d^2 -15 =0$$
But this would be very much work
The other way is to expand them and factorize them. but this is even more work.
Isnt there are simple way?",['algebra-precalculus']
984725,"Closed-form of $\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx$","Inspired by this question , is there a closed-form of $$\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx\,?$$ Here $n \in \mathbb{N_+}$. In the answers to the question above we could find proofs of cases $n=2,3$. I state here some specific cases. $$\begin{align}
\int_0^1\frac{\arctan x}{x}\,dx & = G, \\
\int_0^1\left(\frac{\arctan x}{x}\right)^2\,dx & =G-\frac{\pi^2}{16}+\frac{\pi}{4}\ln2,\\
\int_0^1\left(\frac{\arctan x}{x}\right)^3\,dx & = \frac{3G}{2}-\frac{\pi^3}{64}-\frac{3\pi^2}{32}+\frac{3\pi}{8}\ln2.\\
\end{align}$$ Furtheremore I've evaluated $n=4,5$ cases. $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^4dx$$ equals to $$2G-\frac{3\pi^4}{256}-\frac{\pi^3}{48}-\frac{\pi^2}{8}-\frac{\pi^2G}{8}+\frac{‌​3\pi}{64}\zeta(3)-\frac{\pi^3}{96} \ln2+\frac{\pi}{2} \ln2+\frac{1}{768}\psi_3\left(\frac{1}{4}\right),$$ and $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^5dx$$ equals to $$\frac{5G}{2}-\frac{25\pi^4}{512}-\frac{5\pi^3}{192}-\frac{5\pi^2}{32}-\frac{5\pi^2 G}{8}+\frac{15\pi}{64}\zeta(3)-\frac{5\pi^3}{96}\ln 2+\frac{5\pi}{8}\ln 2 + \frac{5}{768}\psi_3\left(\frac{1}{4}\right).$$ Here $G$ is Catalan's constant , $\zeta$ is the Riemann zeta function , $\psi_3$ is the polygamma function of order $3$, and $\pi$ is also a famous constant . Note that the problem is related to Dirichlet beta function , since $$\begin{align}
\beta(2) & = G \\
\beta(3) & = \frac{\pi^3}{32} \\
\beta(4) & = \frac{1}{768}\left(\psi_3\left(\frac{1}{4}\right)-8\pi^4\right).
\end{align}$$","['closed-form', 'calculus', 'integration', 'special-functions', 'definite-integrals']"
984772,Find the Laurent series of $f(z) = \frac{1}{z-2} + \frac{1}{z-3}$ for $2 < |z| < 3$ and for $|z| > 3$,"Find the Laurent series of $f(z) = \frac{1}{z-2} + \frac{1}{z-3}$ for $2 < |z| < 3$ and for $|z| > 3$. Is the first step here to notice that
$$ \frac{1}{z-2} + \frac{1}{z-3} = \frac{2z-5}{(z-2)(z-3)}$$
and compute the Laurent series as a single term rather than in two parts?","['convergence-divergence', 'sequences-and-series', 'laurent-series', 'analysis', 'complex-analysis']"
984785,Integration of $F(\sum_k x_k)$ over positive orthant,"Problem Suppose we integrate some function $F\left(\sum\limits_{k=1}^n x_k\right)$ over the positive orthant $[0,\infty)^n$. Show that this this is proportional to the integral $\int\limits_0^\infty s^{n-1}F(s)\,ds$. What is the constant of proportionality? If this is a well-known result, a reference would be appreciated. Motivation Suppose I want to solve the inhomogeneous 1st-order ODE $(1-D)f(x)=g(x)$. Then $$D(e^{-x} f)=e^{-x}(f(x)-f'(x))=e^{-x}(1-D)f(x)=e^{-x}g(x),$$ so if I integrate both sides over $[x,\infty)$ (and assume that $e^{-x}f(x)$ vanishes at infinity) I can obtain the integral representation $$f(x)=(1-D)^{-1}g(x)=\int_{x}^\infty dx'\,e^{-(x'-x)}g(x')=\int_{0}^\infty ds\,e^{-s}g(s+x) \quad\quad(x'=s+x).$$ If I instead have the 2nd-order ODE $(1-D)^2 f(x)=g(x)$, then I will instead obtain the double-integral representation \begin{align}
f(x)&=(1-D)^{-2}g(x)\\&=(1-D)^{-1}\int_{0}^\infty ds\,e^{-s}g(s+x)\\&=\int_{0}^\infty \int_{0}^\infty ds' ds\,e^{-(s+s')}g(s+s'+x)
\end{align} To make this more convenient, I can map $(s,s')\mapsto(\frac{s+s'}{2},\frac{s-s'}{2})$ and modify the bounds of integration accordingly to obtain $$f(x)=(1-D)^{-2}g(x)=\frac{1}{2}\int_0^\infty ds\,e^{-s}g(s+x)\int_{-s}^{s} ds'=\int_0^\infty ds\,se^{-s}g(s+x).$$ So acting twice with $(1-D)^{-1}$ merely introduces a linear factor into the integration over $s$. This surely generalizes to $n$ applications of $(1-D)^{-1}$ (presumably by introducing a factor of $s^{n-1}$ instead) but I'm unfamiliar with such an identity. Can anyone supply a proof/reference?","['multivariable-calculus', 'calculus', 'integration']"
984799,Closed-form of $\sum_{k=1}^{\infty }\left(\psi_1(k)\right)^n$,"Inspired by answers to this question , for which $n$ values could we specify a closed-form of $$S(n)=\sum_{k=1}^{\infty }\left(\psi_1(k)\right)^n\,?$$ Here $\psi_1$ is the trigamma function , and $n\geq2$ is an integer. I think for small $n$ values there is a closed-form. From the answers above we know that $S(2)=3\zeta(3)$. I think there is a generalization of Olivier Oloa's approach using techniques from Pedro Freitas' paper . Note that there is a known error in the paper. Furthermore I think robjohn's answer has a generalization using results from the paper by Philippe Flajolet and Bruno Salvy . Question. Is there a closed-form of $S(n)$ for $2\leq n \leq 7\,?$","['special-functions', 'sequences-and-series', 'closed-form', 'calculus']"
984802,Equivalent definitions of the trace of a Hilbert-Schmidt operator,"I am currently reading the book Spectral Methods in Automorphic Forms , and Iwaniec defines the trace operator in a different way than I am accustomed to. Throughout, assume that everything converges spectacularly - that's not important here. In particular, if $K: F \times F \longrightarrow \mathbb{C}$ is a $C_0^\infty$ (that is, smooth and bounded) function and $L$ is the integral operator having $K$ as its kernel, i.e.
$$ (Lf)(z) = \int_F K(z,w)f(w) d w,$$
then Iwaniec defines the trace of $L$ as the integral across the diagonal, 
$$ \text{Tr} L = \int_F K(z,z)dz. \tag{1}$$ I'm familiar with the trace of a more generic (linear operator $A$ over a Hilbert space by $$ \text{Tr} A = \sum_j \langle Ae_j, e_j \rangle,\tag{2}$$ where the $e_j$ form an orthonormal basis of functions. Do these definitions agree?  If we suppose in addition that the $e_j$ are eigenfunctions with eigenvalues $\lambda_j$, then I can see the equivalence in the following ""wrong"" way. Taking the spectral decomposition for $K(z,w)$,
$$K(z,w) = \sum_j \lambda_j e_j(z) \overline{e_j(w)},$$
then since the $e_j$ are orthonormal, we have that
$$\int_F K(z,z)dz = \sum_j \lambda_j \int_F e_j(z)\overline{e_j(z)}dz = \sum_j \lambda_j.$$
And Lidskii's Theorem says that
$$\text{Tr} A = \sum_j \lambda_j,$$
where $\text{Tr} A$ is as in $(2)$. So I can conclude that $(1)$ and $(2)$ should agree, but I would like to see in a more fundamental, less roundabout way that they do actually agree.","['trace', 'compact-operators', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
984804,Why does gradient descent make sense?,"Suppose I define two functions of $x$ in terms of a convex function $f$ with a unique minimum $x_0$: $$f_1(x) = 1 \times f(x)$$ $$f_2(x) = 2 \times f(x)$$ Suppose I wanted to minimize each of these functions numerically. Clearly, the minima of both occur at the same $x_0$. But if I tried to do gradient descent, I would be performing the updates $$x \gets x - \lambda \nabla f_k(x)$$ and therefore step sizes would be larger for $f_2$ than $f_1$. To me, this doesn't make sense. The step sizes should not depend on the scaling factor! It therefore seems to imply that gradient descent should be normalized such that the step sizes have constant magnitude regardless of the gradient's magnitude. So what justification is there for having the step size increase with the magnitude of the gradient when it's obvious that scaling the original function will change the gradient but not the location of its extrema?","['optimization', 'gradient-descent', 'numerical-optimization', 'convex-optimization', 'derivatives']"
984837,Limits with squares,"I have problem with finding such limits: a) $\displaystyle \lim_{n \to \infty}\frac{n^2}{7^{\sqrt{n}}}$ b) $\displaystyle \lim_{n \to \infty}\frac{3^{\sqrt{n}}}{2^n} $ I think the method of solving this two is similar but I don't know what tool to use. 
I tried using the fact that if $\displaystyle\lim_{n \to \infty}\frac{|a_{n+1}|}{|a_{n}|}<1$ then $\displaystyle\lim_{n \to \infty} a_n=0$ but it dosn't work","['calculus', 'limits']"
984873,(If exists) a set of all ordinals that set is an ordinal?,"In set theory (ZF) an ordinal is a transitive set of transitive sets. Thus
(if exists) a set of all ordinals gives a contradiction therefore there is
no set of all ordinals. But what is wrong with the following:
An ordinal is not only a transitive set of transitive sets, but also an ordinal is a limit ordinal or there is a 'greatest' ordinal belonging to
that ordinal, but not both. Thus, (if exists) a set of all ordinals then that set is not a limit-ordinal
      otherwise the successor of that limit-ordinal gives a contradiction,
therefore 
      if the set of all ordinals exists and is an ordinal then there is a 'greatest'
      ordinal belonging to that set of all ordinals,
      but that is impossible because there is no 'greatest' ordinal. Therefore if exists a set of all ordinals then that set is not an ordinal. Thank you for your attention, Doeko Homan","['ordinals', 'elementary-set-theory']"
984897,Proving (a part of) Hoeffding's lemma,"Hoeffding lemma goes like this: *Let $X$ be a scalar variable taking values in an interval $[a,b]$. Then for any $t>0$ $$\mathbb{E} e^{tX}\leq e^{t\mathbb{E} (X)}(1+O(t^2\mathbb{V}(X)\exp(O(t(b-a)))).$$In particular $$\mathbb{E} e^{tX}\leq e^{t\mathbb{E} (X)}\exp(O(t^2(b-a)^2).$$(This version is taken from T. Taos book on Random matrices - it's on pp. 61 Lemma 2.1.2 from the draft from his website) My question is: How can one get the second inequality from the first ? Tao gives as a hint $ $$\mathbb{V}(X)\leq(b-a)^2$.","['probability-theory', 'inequality']"
984910,prove weak induction implies strong induction,"So trying to prove: i) $[t(n_0)\wedge \forall_n[t(n)\rightarrow t(n+1)]\Rightarrow \forall_{n_0\le n}t(n)]$ $\Rightarrow$ ii) $[s(n_0)\wedge s(n_1)\wedge\cdots \wedge s(n_k)\wedge\forall_n[s(n-k)\wedge s(n-k+1)\wedge\cdots \wedge s(n-1)\wedge s(n)\rightarrow s(n+1)]\Rightarrow \forall_{n_0\le n}s(n)]$ $1.)$ Let function $t(n) = s(n)\wedge s(n+1)\wedge\cdots \wedge s(n+k-1)\wedge s(n+k)$ $2.)$ assume $s(n_0)\wedge s(n_1)\wedge\cdots \wedge s(n_k)$ $3.)$ $\therefore t(n_0)$ $\space\space\space\space 1)$ and $2)$ $4.)$ assume $\forall_n[s(n-k)\wedge s(n-k+1)\wedge\cdots \wedge s(n-1)\wedge s(n)\rightarrow s(n+1)]$ $5.)$ for sbac $q\in Z$, $s(q-k)\wedge s(q-k+1)\wedge\cdots \wedge s(q-1)\wedge s(q)\rightarrow s(q+1)$ $\space\space\space\space 4)$ and Rule of Universal Specification $6.)$ $\therefore s(q)\wedge s(q+1)\wedge\cdots \wedge s(q+k-1)\wedge s(q+k)\rightarrow s(q+k+1)$ $\space\space\space\space5)$ $7.)$ $s(q)\wedge s(q+1)\wedge\cdots \wedge s(q+k-1)\wedge s(q+k)\rightarrow s(q)\wedge s(q+1)\wedge\cdots \wedge s(q+k-1)\wedge s(q+k)$ $8.)$ ($(a\rightarrow b\wedge a\rightarrow c)\Rightarrow a\rightarrow b\wedge c$ established via truth table - omitted) $10.)$ $s(q)\wedge s(q+1)\wedge\cdots \wedge s(q+k-1)\wedge s(q+k)\rightarrow s(q)\wedge s(q+1)\wedge\cdots \wedge s(q+k-1)\wedge s(q+k)\wedge s(q+k+1)$ $\space\space\space\space 6),7),8)$, Rule of Conjunction $11.)$ $\forall_n[s(n)\wedge s(n+1)\wedge\cdots \wedge s(n+k-1)\wedge s(n+k)\rightarrow s(n)\wedge s(n+1)\wedge\cdots \wedge s(n+k-1)\wedge s(n+k)\wedge s(n+k+1)]$ $\space\space\space\space 10)$ and Rule of Universal Generalization $12.)$ $\forall_n[t(n)\rightarrow t(n+1)]$ $\space\space\space\space 1)$ and $11)$ $13.)$ $\forall_{n_0\le n}t(n)$ $\space\space\space\space 3)$ and $12)$ and i)* $14.)$ $\therefore \forall_{n_0\le n}s(n)$ $\space\space\space\space 1)$ and $13)$","['induction', 'discrete-mathematics']"
984914,Fermat's Little Theorem: group and multiplication modulo,"$p$ is a prime number . $G$ is a group of integers $\{1,2,\dots,p-1\}$ under
multiplication mod $p$. $d$ is a divisor of $(p-1)$ Is it possible to prove that the number of elements $a$ in $G$ such that $a^d\equiv1$ (mod $p$) is exactly $d$? The Fermat's little theorem $a^{p-1} \equiv1$ should come in handy somewhere.","['group-theory', 'number-theory']"
984918,Is every connected subset of the Sierpiński triangle arcwise connected?,"I think this should be true. If it's indeed the case, it seems like this should be a  known result, so references are welcome. I managed to prove that (assuming $S$ is the connected subset) $S$ minus one of the three small triangles (but don't remove the two points which connect the small triangle to the rest) is also connected. This can be stated more generally for connected subsets in three spaces cyclically connected by three points. (basically, if $S$ restricted to one of them fails to be connected, then the restriction to the other ones has to be connected) I'm not sure how to continue. Additionally, $S$ doesn't have to be closed, which causes further problems. Any ideas are also welcome.","['general-topology', 'connectedness', 'metric-spaces']"
984919,Probability a product of $n$ randomly chosen numbers from 1-9 is divisible by 10.,"I'm working on a problem where each number is chosen randomly from 1-9. Given $n$ numbers chosen in this manner, we multiply all of these together. I'm looking for the probability that this product is divisible by 10. I reasoned that we only get a multiple of 10 when we multiply 5 and an even number together. So if either all $n$ numbers are odd or if none of the $n$ numbers is 5, then the product will not be divisible by 10, and we can take 1 - P(Not Divisible by 10). From here, I'm not sure how to come up with a numerical answer when there is an ambiguous number of $n$ randomly chosen numbers. Is there some way to get there? Or is this reasoning flawed?","['probability', 'random', 'divisibility']"
