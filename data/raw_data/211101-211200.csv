question_id,title,body,tags
4246048,Basic set theory question,"As I understand it, Cantor defined two sets as having the same cardinality iff their members can be paired 1-to-1.  He applied this to infinite sets, so ostensibly the integers (Z) and the even integers (E) have the same cardinality because we can pair each element of Z with exactly one element of E. For infinite sets, this definition seems problematic no matter which direction we come at it from:  We don't know up front that two infinite sets have the same cardinality, so we cannot conclude that their elements can be exactly paired.  And we do not know up front that two infinite sets' elements can be paired up exactly (because we don't know with certainty what happens beyond the finite cases we can verify).  So we cannot conclude that their cardinalities are the same.  The definition above therefore seems useless, since we cannot start from either side of the ""iff"". It might be argued that if we state it as follows:  ""For each element e of E, pair it with element e/2 of Z,"" then we have expressed the general case symbolically, and it works.  But we can only verify that for finite values of E and Z.  We can't know what happens beyond finite elements of those sets.  So expressing it symbolically does not seem to help. Why is Cantor's definition not circular and therefore useless for deciding the question of infinite set cardinalities?",['elementary-set-theory']
4246052,Does there exist a non-finite subset X of $\Bbb Q^2$ such that every real valued continuous function on X is bounded.,"I think so. Because if we think of a non-finite subset X of $\Bbb Q$ such that every real valued continuous function on X is bounded. We can take X to be $\{1/n\} \cup\{0\}$ . Since the function is continuous at 0, it is bounded around $0$ . And the set of all other points is finite, so it is bounded. In a similar manner we can do for $\Bbb Q^2$ . Is my proof okay?
If not please explain or give a simple proof","['continuity', 'functions', 'real-analysis']"
4246056,Show that $AΔB=C$ if and only if $A=BΔC$.,"Show that $AΔB=C$ if and only if $A=BΔC$ . I read this answer : Here's the long messy way. We want to show $A\triangle B = C \iff A = B\triangle C$ $\Rightarrow$ : Assume $C = A\triangle B$ Recall $A\triangle B = (A\cup B) - (A\cap B) = (B-A)\cup(A-B)$ $$\begin{align}
(B\cup C) - (B\cap C) &= (B\cup [(A - B) \cup (B - A)]) - (B\cap [(A\cup B) - (A\cap B)]) \\
&= ([B\cup (A- B)] \cup (B - A)) - ([B\cap (A\cup B)] - [B\cap (A\cap B)]) \\
&= ((A\cup B) \cup (B - A)) - \color{red}{(B - (A\cap B))}\\
&= ((A\cup B) \cup (B - A)) - \color{red}{(B - A)}\\
&= (A\cup B) - (B - A)\\
&= A
\end{align}$$ $\Leftarrow$ is, dare is say, symmetric. My question is in the part highlighted in red. Why is $A \cap B = A$ ?",['elementary-set-theory']
4246066,Hoeffding’s inequality for a modified concentration,"The Hoeffding's inequality is $$P(S_n - E[S_n] \geq \epsilon) \leq e^{-2\epsilon^2/k'},$$ where $S_n = \sum_{i=1}^{n} X_i$ , $X_i$ 's are independent bounded random variables, and $k'$ depends on the bounded ness of those random variables. My question: Can we get a similar high probability result as follows? $$P(\sqrt{S_n} - \sqrt{E[S_n]} \geq \epsilon) \leq e^{-2\epsilon^2/k'’}.$$ My try so far: Using variations of the fact $\sqrt{a+b} \leq \sqrt{a} + \sqrt{b}$ for $a,b \geq 0$ , we get $$P(\sqrt{S_n} - \sqrt{E[S_n]} \geq \epsilon) \leq e^{-2\epsilon^4/k'’}.$$ Although this is quite loose compared to $e^{-\epsilon^2}$ . :( Or, is this expected for the problem I am looking at?
Is $\sqrt{E[S_n]}$ a bad approximation of $\sqrt{S_n}$ ? Ofcourse it is a biased approximation. Any help/pointers is appreciated! :) Edit 1: Lemma 2.1 in this note might have some insightful algebra that is required to show a tighter bound, although I am successful in doing so yet. :( Edit 2: Also, notice that naturally the question is intended to work for the symmetrical version as well: $$P(|\sqrt{S_n} - \sqrt{E[S_n]}| \geq \epsilon) \leq e^{-2\epsilon^2/k'’}.$$","['inequality', 'probability-distributions', 'probability-theory', 'concentration-of-measure']"
4246099,Covariant derivative for higher rank tensors,"Recently i have started to study tensors, but i have a problem with covariant differentiation. In every textbook i have read so far, there is a formula like $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ to calculate covariant derivative for a tensor with two contravariant ranks, but none of them has explained the way which results in such formula. Now suppose we have a two dimensional space with basis vectors $\vec{e}_1$ and $\vec{e}_2$. As you know we can build a tensor with two contravarint ranks which can be written in component form as $T = T^{11}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{12}(\vec{e}_1 \bigotimes \vec{e}_2)+T^{21}(\vec{e}_2 \bigotimes \vec{e}_1)+T^{22}(\vec{e}_2 \bigotimes \vec{e}_2)$. Is there any way to reach from component form of a tensor to $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ ? In other words, is this possible to differentiate like $\frac{\partial{T^{ij}(\vec{e}_i \bigotimes \vec{e}_j)}}{\partial{x^k}}=\frac{\partial{T^{ij}}}{\partial{x^k}}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{ij}(\frac{\partial{\vec{e}_i}}{\partial{x^k}} \bigotimes \vec{e}_j)+T^{ij}(\vec{e}_i \bigotimes \frac{\partial{\vec{e}_j}}{\partial{x^k}})$ ?",['tensors']
4246136,derivative of trace of (XAX) w.r.t X when X is symmetric?,"I wonder if there is any formula of $\frac{d tr(XAX)}{d X}$ when $X$ is symmetric? I understand that when $X$ is not symmetric, we have $$\frac{d tr(XAX^T)}{dX} = XA^T+XA,$$ and when $X$ is symmetric, we have $$\frac{d tr(AX)}{dX} = A+A^T-A\circ I,$$ where $\circ$ means elementwise product. However, I am not able to find $\frac{d tr(XAX)}{d X}$ when $X$ is given to be symmetric. Or any hint on the derivative of this formula is appreciated.","['trace', 'matrix-calculus', 'derivatives']"
4246144,How can I solve $\frac{(1-x)(x+3)}{(x+1)(2-x)}\leq0$ and express solution in interval notation?,"The inequality I need to solve is $$\frac{(1-x)(x+3)}{(x+1)(2-x)}\leq0$$ My attempt: Case I: $x<2$ Then we have $(1-x)(x+3)\leq0$ $x\leq-3, x\geq1$ We reject $x\leq-3$ (not sure why exactly, I just looked at the graph on desmos and it shows that $x\geq1$ Case II: $x<-1$ Then we have $(1-x)(x+3)\geq0$ $x\geq-3, x\leq-1$ Reject $x\leq-1$ (again, not sure exactly why aside from the graph I saw on desmos) So the final solution is $x\in[-3,-1) \cup [1,2)$ I know that my final solution is correct, however I am a little confused on why I reject certain values.","['algebra-precalculus', 'inequality']"
4246194,Need help understanding ∃x∀y vs ∀x∃y,"My understanding is that for ∃x∀y, there can only be one x value that is true for every single y value. Meaning theres only one x value (which cannot be changed) for every single different y value. The statement ∃x∀y(p(x,y)) is true when there is one x value (lets say x=0) that is true for y=-2,-1,0,1,2,... (for every single y). Correct me if I am wrong but this is my understanding of this notation. And now my understanding for the second notation ∀x∃y(p(x,y)) is that for every x value, there exists a y such that p(x,y). Meaning for every x value (x=-2,-1,0,1,2,...) there can be a different y value for each x value so that the statement is true. I dont really know how to explain this well but I'll try to summarize my understanding. If the notation is ∃x∀y then theres only one x that cannot be changed that is true for every y. If the notation is ∀x∃y then the y value doesnt have to be the same y value for every x value. Meaning for every x value there can be a y value that is different than another y value for another x value. If my thinking is correct then please say so otherwise please try and help me understand this.","['first-order-logic', 'logic', 'discrete-mathematics']"
4246206,Gröbner bases method to solve system of polynomial equations,"I am new to the theory of solving systems of polynomial equations using Gröbner bases and I am confused about the terminology. I will appreciate any help to clarify my confusion. Some sources are stating that in order to solve the system of polynomial equations one needs to compute Gröbner bases (multiple bases) with respect to degree reversed lexicographical ordering, then change the orderings of Gröbner bases (again multiple bases) to lexicographical ordering, and then  transform Gröbner bases to either triangular sets or rational univariate representations. Other sources talk about a Gröbner basis. We compute a Gröbner basis (single) w.r.t. to degree reversed lexicographical ordering, then change the ordering of a Gröbner basis (again single basis) to lexicographical ordering... If I have a system of $m$ polynomials $f_1, \cdots, f_m \in \mathbb{F}_p[x_1, \dots, x_n]$ and want to find roots of this system of polynomials using Gröbner bases theory, then I first generate an ideal $I = \langle f_1, \cdots, f_m \rangle$ . Then for this ideal with respect to the term order do I need to compute a Gröbner basis or multiple Gröbner bases? Thank you.","['algebraic-geometry', 'abstract-algebra', 'polynomials', 'groebner-basis']"
4246209,"Evaluate the integral $\iint_De^{-x^2}\,dx\,dy$","Find $\iint_De^{-x^2}\,dx\,dy$ , where $D$ is the triangle formed by points $O(0,0), A(1,0), B(1,1)$ I'm totally lost on this one. I only have experience with circle functions, and converting them to polar and finding the bounds in $π$ and $r$ , but here its just points. Can anyone help me understand this? Do i just bound $x$ to $[0,1]$ and $y$ to $[0.1]$ ?","['multivariable-calculus', 'calculus', 'multiple-integral']"
4246210,Factor quadratic functions into weighted sum of squares,"I am working to reproduce results from a paper [links directly to page 17, equations 3.4 on some browsers] on a finite-volume method reconstruction method called WENO which I'm using in one dimension. Part of the method involves calculating a so-called smoothness indicator $\beta$ for cell average values $\bar{u}_i$ in a stencil which consists of a small number of cells, in my case three. For uniform meshes the paper gives explicit formulae for $\beta$ in terms of the cell average values. For example, a result they give for a stencil three cells wide is, $$\beta_1 = \frac{13}{12}\left(\bar{u}_{i - 2} - 2\bar{u}_{i - 1} + \bar{u}_i\right)^2 + \frac{1}{4}\left(\bar{u}_{i-2} - 4\bar{u}_{i - 1} + 3\bar{u}_i\right)^2$$ The other formulae they give for various shifts of stencils of three cells all have this same form, albeit with different coefficients for the cell average terms within the parentheses. [Does this form have a name? If so, I'd like to improve the question title.] The software I have written, which uses the computer algebra system Sympy to perform the necessary calculus to get to this point, produces the following expression which is equivalent to the above, and so correct, $$\beta_1 = \frac{10}{3}{\bar{u}_i}^2 - \frac{31}{3}\bar{u}_{i}\bar{u}_{i-1} + \frac{11}{3}\bar{u}_{i}\bar{u}_{i-2} + \frac{25}{3}{\bar{u}_{i-1}}^2 - \frac{19}{3}\bar{u}_{i-1}\bar{u}_{i-2} + \frac{4}{3}{\bar{u}_{i-2}}^2$$ What method or steps can I follow to rearrange my result to the one given in the paper? Ideally I'm looking for a method with generalises to the other equations in the paper which have a similar structure.","['algebra-precalculus', 'finite-volume-method']"
4246217,"Does a ""3-cone"" have intrinsic curvature?","A common intro to intrinsic curvature is to show that a standard cone has no curvature outside the vertex because it can be unrolled into a subset of the plane.  Also, in polar coordinates, the cone has metric $g_{rr} = c \qquad g_{\theta\theta} = r^2$ with the constant $c$ corresponding to the slant of the cone.  But when I tried calculating the Riemann tensor components for a spherically symmetric 3-space of the form $g_{rr} = a(r) \qquad g_{\theta\theta} = r^2 \qquad g_{\phi\phi} = r^2\sin^2\theta$ two of them came out looking funny: ${R^{\phi}}_{\theta\phi\theta} = 1 - \frac{1}{a} \qquad\qquad {R^{\theta}}_{\phi\theta\phi} = (1 - \frac{1}{a})\sin^2\theta$ They do vanish when $a(r) = 1$ which is reassuring since that's just Euclidean space.  But they don't for any other constant.  However, a constant other than 1 should just be the 3D version of a cone.  Now it is also reassuring that the radial curvature remains zero, since the $r$ coordinate lines are the geodesics and these clearly are not deviating.  But this tangential behavior is shaking my confidence in my calculation.  It even gives a non-zero Ricci scalar: $R = \frac{2}{ar}(\frac{a'}{a} + \frac{a-1}{r})$ Did I mess up or is that really how it is?  If so, is there an intuitive way to understand why?  And is it in any way related to the fact that all 2-spheres have the same total curvature but 3-spheres do not?","['3d', 'riemannian-geometry', 'tensors', 'curvature', 'differential-geometry']"
4246282,Differential forms on $ \mathcal{M} = G×_KM$.,"In page 40 of this article Equivariant cohomology with generalized coefficients ""  we find the following Let $G$ be a lie group and $K$ is a closed subgroup of it. Let $M$ be a $K$ -manifold. Consider the product manifold $G×M$ . The group $K$ acts freely on the right on $G×M$ by $(g,m)k= (gk, k^{-1}m)$ . Consider the fiber space $\mathcal{M} = G×_KM$ (over $G/K$ ) of orbits of the K-action. The group $G$ acts on the left on $\mathcal{M}$ .
If $\alpha \in \mathcal{A}(\mathcal{M}) \subset \mathcal{A}(G×M)$ , and $g \in G$ , then $ \alpha (g)$ is an element of ${(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K} $ , where $\mathfrak{g}^*$ is identified with left invariant 1-forms on $G$ .
Thus $$ \mathcal{A}(\mathcal{M})= C^\infty (G, {{(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K})}^K.....(*)$$ How can we obtain the formula $ {(*)}$ ? I'm aware of the result which says that  If $P \rightarrow M$ is a $G$ -principal bundle and $E$ is a $G$ -space and $P×_GE$ is an associated bundle on $M$ then $\mathcal{A}^q(M, P×_GE)$ is isomorphic to ${\mathcal{A}^q(P, E)}_{bas}$ , but I don't know how to use it to get the formula ${ (*)}$ ! Your help would be greatly appreciated! Thank you.","['differential-forms', 'differential-geometry']"
4246283,Confusion about thinking about a (flat) torus as a quotient,"I feel slightly embarrassed to ask this, but I've managed to thoroughly confuse myself about the following. Consider $\mathbb{R}^2$ together with the lattice $\Lambda=\{(n,m): n,m\in \mathbb{Z}\}$ . Clearly, the torus $\mathbb{T}^2=\mathbb{R}^2/\Lambda$ admits the obvious flat metric that makes it a square torus.  Geometrically, this corresponds to taking the fundamental domain $[0,1]\times [0,1]$ with the metric $dx^2+dy^2$ and identifying the appropriate sides. My confusion is that one could also think of the domain given by the parallelogram $\{(x,y): 0\leq y \leq 1, y\leq x \leq y+1\}$ (i.e. determined by the elements $(1,0)$ and $(1,1)$ that also generate the lattice).  If I understand things correctly, on this domain the metric $dx^2+dy^2$ would induce a different metric on the quotient given by identifying the appropriate sides than the metric you would get by taking the appropriate quotient metric (which here would correspond to $dx^2-dxdy-dydx+2dy^2$ ). This is causing me some confusion and doubt about how well I actually understand the situation. I guess for a concrete question: Is there something special about the square as a fundamental domain that makes the quotient metric given by identifying opposite sides agree with the quotient metric of the lattice?  Or am I misunderstanding things?",['geometry']
4246285,"Finding $x^8+y^8+z^8$, given $x+y+z=0$, $\;xy +xz+yz=-1$, $\;xyz=-1$","The system says $$x+y+z=0$$ $$xy +xz+yz=-1$$ $$xyz=-1$$ Find $$x^8+y^8+z^8$$ With the first equation I squared and I found that $$x^2+y^2+z^2 =2$$ trying with $$(x + y + z)^3 = 
 x^3 + y^3 + z^3 +  3 x^2 y + 3 x y^2 + 3 x^2 z++ 3 y^2 z + 3 x z^2 + 
  3 y z^2 + 6 x y z$$ taking advantage of the fact that there is an $xyz=-1$ in the equation, but I'm not getting anywhere, someone less myopic than me.how to solve it? Thanks Edit : Will there be any university way to solve this problem , they posed it to a high school friend and told him it was just manipulations of remarkable products.
His answers I understand to some extent but I don't think my friend understands all of it.","['systems-of-equations', 'roots', 'calculus', 'symmetric-polynomials', 'algebra-precalculus']"
4246289,Equivalence between notions of dynamical coupling as defined by Villani's book Optimal Transportation: Old and New,"In Villani's book he presents the following notions of dynamical couplings: Let $(X,d)$ be a Polish space. A dynamical transference plan $\Pi$ is a probability measure on the space $C([0,1]; X)$ . A dynamical coupling of two probabilities measures $\mu_0$ , $\mu_1 \in P(X)$ is a random curve $\gamma : [0,1]\to X$ such that $law (\gamma_0) = \mu_0$ , $law(\gamma_1) = \mu_1$ . If I'm not mistaken, I understood the ""random curve"" part as being equivalent to the following sentence: There exist a measure space $(\Omega, \mathbb{P})$ measurable map $\gamma : [0,1]\times \Omega \to X$ such that $\gamma$ is continuous in $[0,1]$ and $(e_i\circ\gamma)_*(\mathbb{P}) = \mu_i$ , $i = 0,1$ , where $e_t$ is the evaluation map. We have the usual notion o coupling of measures as: Couplings by means of random elements: Let $(E_i, \mu_i)_{i\in I}$ be a family of measures spaces, where $I$ is an index set. A coupling of the measures $\mu_i$ is a family of random elements $X_i : (\Omega, \mathbb{P}) \to E_i$ such that $(X_i)_*(\mathbb{P}) = \mu_i$ . Couplings by means of the product space: Let $(E_i, \mu_i)_{i\in I}$ as before, with $\mathcal{A}_i$ being the $\sigma$ -algebra of $E_i$ . A coupling of the measures is a measure $\pi$ in the product space $(\prod_{i\in I}E_i, \bigotimes_{i\in I} \mathcal{A}_i)$ , such that $(proj_i)_*(\pi) = \mu_i$ , where $proj_i$ is the projection in $E_i$ , and $\bigotimes_{i\in I} \mathcal{A}_i$ is the analogous to the product topology, but for $\sigma$ -algebras. It can be shown that these two definition are equivalent by taking the map $\Gamma : (\Omega,\mathbb{P}) \to (\prod_{i\in I}E_i, \bigotimes_{i\in I} \mathcal{A}_i)$ , $\Gamma(\omega) = (X_i(\omega))_{i \in I}$ and defining $\pi : = \gamma_*(\mathbb{P})$ . (The other way is trivial by construction) I want to prove something similar for the case of dynamical couplings. We can follow the same construction above and take the interval $[0,1]$ as the index set $I$ . This way we obtain the map $\Gamma(\omega) : = e_\omega(\gamma)$ , where $e_\omega$ is the evaluation on the second coordinate. It's clear that the image of $\Gamma$ lies in $C(I,X)$ . The problem is to show that $\Gamma$ is measurable with respect to $\mathcal{B}(C(I,X))$ (with respect to the uniform topology). We just have the measurability of with repect to $\bigotimes_{t\in I} (\mathcal{B}(X))$ . So, how to conclude? Did I do anything wrong here? Alternatives ways are also welcomed. Thank you very much.","['measurable-functions', 'measure-theory', 'probability-theory', 'analysis']"
4246296,Mollification of Functions of bounded variation,"Let $\eta_{\epsilon}$ be a standard mollifier. For $f\in L^{\infty}(\mathbb{R})$ we have $|f^{\epsilon}(x)|\leq \int\limits_{R}|f(x-y)|\eta_{\epsilon}(y)dy \leq ||f||_{\infty},$ which implies $||f^{\epsilon}||_{\infty} \leq ||f||_{\infty}.$ Thus convolution does not increase the $L^{\infty}$ norm. Similarly, if $TV(f)<\infty$ do we have $TV(f^{\epsilon}) \leq TV(f)?$ If not, can we  get $TV(f^{\epsilon}) \leq C TV(f)?$ for some $C$ independent of $\epsilon?$ Defintion: Total variaton and Functions of bounded variation Let $f: \mathbb{R} \rightarrow \mathbb{R}$ and
Let $
\mathcal{P} =\left\{P=\{ x_0, \dots , x_{n_P}\} \mid P\text{ is a partition of }  \mathbb{R} \text{ satisfying } x_i\leq x_{i+1}\text{ for } 0\leq i\leq n_P-1 \right\} $ Total variation of $f$ is defined by $TV(f)=\sup_{P \in \mathcal{P}} \sum_{i=0}^{n_{P}-1} | f(x_{i+1})-f(x_i) |.$ A function $f$ is called function of bounded variation if $TV(f)<\infty.$","['measure-theory', 'convolution', 'bounded-variation', 'real-analysis', 'total-variation']"
4246313,"If $H, K, L$ are subgroups of a group $G$ and $LH = HL$ and $LK = KL$, is it true that $L(H \cap K) = (H \cap K) L$?","Title says it all: if $H, K, L$ are subgroups of a group $G$ and $LH = HL$ and $LK = KL$ , is it true that $L(H \cap K) = (H \cap K) L$ ? This seems similar in flavor to this problem , but without any constraints on containment.  I'd thought one might be able to use the fact that $LHK = HKL$ together with some form of second-isomorphism-theorem argument, but wasn't able to make it stick.",['group-theory']
4246320,"If Alice gives Bob $m$ candies, then he'll have $n$ times her candies; if Bob gives Alice $n$ candies, then she'll have $m$ times his candies.","I came up with a seemingly innocent problem of recreational mathematics by myself. It goes likes this. Alice and Bob have some different amount of candies ( $>1$ each). If Alice gives Bob $m$ candies, then Bob has $n$ times the candies remaining to Alice, and if Bob gives Alice $n$ candies, then Alice has $m$ times the candies remaining to Bob. How many candies have Alice and Bob? I expected infinite solutions, but running a simple Python code (up to 200 iterations) gave me only 4 answers: $$\begin{array}{cccc}
\text{A} & \text{B} & m & n \\
\hline
7 & 5 & 3 & 2 \\ 
14 & 4 & 8 & 2 \\
11 & 5 & 7 &3 \\
11 & 7 & 8 & 5
\end{array}$$ Apparently the highest amount of candies that Alice/Bob can have is 14. Does this limit actually exist? If so, how can I prove that?","['number-theory', 'recreational-mathematics', 'integers', 'discrete-mathematics']"
4246336,Is there a formula for $\int_0^1 x\uparrow\uparrow n dx$,"$$\int_0^1  x\uparrow\uparrow n dx$$ I was working on an answer to this question on integrating $x^{x^x}$ and I was thinking is there a particular formula/rule/pattern in integration if $x\uparrow\uparrow n$ ( $x$ to the power of $x \ n$ times) from $0$ to $1$ . Integrating $x^x$ we use the Taylor series to arrive a $$\int_0^1 x^xdx=\int_0^1 e^{x\ln(x)}dx =\int_0^1 \sum^\infty_{n=0}\frac{x^n\ln^n(x)}{n!}dx=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n^n}=0.78343\ldots
$$ similarly integrating $x^{x^x}$ the taylor series would be $$x^{x^x}=\sum^\infty_{n=0}\frac{\ln^n(x)}{n!}x^{x^n}=\sum^\infty_{n=0}\frac{\ln^n(x)}{n!}\Bigg(\sum_{k=0}^\infty\frac{x^k\ln^k(x)}{k!}\Bigg)^n$$ and integrating $x\uparrow\uparrow 3$ the series would be $$x^{x^{x^x}}=\sum^\infty_{n=0}\frac{\ln^n(x)}{n!}x^{x^{x^n}}=\sum^\infty_{n=0}\frac{\ln^n(x)}{n!}\Bigg(\sum_{k=0}^\infty\frac{\ln^k(x)}{k!}x^{x^k}\Bigg)^n=
\sum^\infty_{n=0}\frac{\ln^n(x)}{n!}\Bigg(\sum_{k=0}^\infty\frac{\ln^k(x)}{k!}\Big(\sum^\infty_{m=0}\frac{x^m\ln^m(x)}{m!}\Big)^k\Bigg)^n
$$ So is there a solution to the integral? $$\int_0^1  x\uparrow\uparrow n dx$$ Can it be simplified? Can one find series solutions for all $n$ ? What if $n\not\in \mathbb{N}$ ? I have been interested in this function for quite a long time so thank you for your time","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'taylor-expansion']"
4246370,The triangle inequality holds... $50\%$ of the time? Or is this problem asking for something else?,"Here's a question from my probability textbook: If three numbers be named at random it is just as likely as not that every two of them will be greater than the third. I don't understand what this problem is even asking, it's not clear what this means. Could anyone help? One interpretation is just if I randomly select three numbers $a > b > c$ , we want to show that the probability that $b + c > a$ is ${1\over2}$ . I guess that's true, but I'm not sure since infinities are weird. EDIT: Using Mike Earnest's answer of ${1\over2} + {1\over{2n^2}}$ to my previous question here : Three different persons have each to name an integer not greater than $n$ . Find the chance that the integers named will be such that every two are together greater than the third. We take the limit as $n \to \infty$ , and get ${1\over2}$ . Does that work? EDIT 2: This textbook was written in the 19th century, maybe explaining the lack of rigorous formulation on its part.",['probability']
4246388,What is the Range of the function?,"Q: Find the range and domain of the function $$f(x) = \sqrt{1-e^{x+2}}?$$ I've found the domain, which is $x \le -2$ by solving the inequality $1-e^{x+2} \ge 0$ . I've tried to find the range by taking the inverse of $f$ , which gives me $f^{-1} = \ln(1-x^2)-2$ . Then, since for $\ln(1-x^2)$ to be defined, $1-x^2>0$ , so solving this inequality gives the interval $x \in (-1,1)$ , which I thought is the range of $f$ . However, graphing it out on desmos shows that the range is only $[0,1)$ . What am I doing wrong?",['functions']
4246399,Subring of a commutative ring with unity implies ring is an integral domain,"Let $R$ be a commutative ring with unity. If a subring $S$ of $R$ is an integral domain containing the unity of $R$ (that isn’t $\{0,1\}$ ), does this imply that $R$ is too an integral domain? I tried to find a counterexample but I did not find one: I figured maybe the subring of $Z_{10}$ , $(2)$ , would work since I figured it would be isomorphic to $Z_5$ (and thus an integral domain), but then I realized it has no multiplicative identity so that’s a no. Any help would be appreciated.","['ring-theory', 'abstract-algebra', 'integral-domain']"
4246411,What does the additive subgroup of $\mathbb{R}^3$ generated by the vertices of a regular polyhedron look like?,"Let $\{v_1,\dots,v_n\} \subset \mathbb{R}^3$ be the vertices of one of the regular polyhedra centered at the origin and let $G = \sum_{k=1}^n v_k \mathbb{Z}$ , the additive subgroup of $\mathbb{R}^3$ generated by these vertices. In some cases, like for a tetrahedron, cube, or octahedron, $G$ is a lattice. Is it always the case or are there some regular polyhedra that will yield a group dense-in-itself ? Clearly if one of these two results is true for a polyhedron, then it also applies to its dual. I don't have any intuition of the answer for the regular dodecahedron or icosahedron though, and even less for the non-convex regular polyhedra.","['group-theory', 'polyhedra']"
4246490,How to obtain the relation between the function and its derivative?,"Let $f: \big[0, \frac{1}{2} \big] \to \mathbb R, e^{-2x}f(x)$ is twice differentiable function having local minima at $x=\dfrac{1}{4}$ and $$\dfrac{d^2}{dx^2}\bigg(e^{-2x}f(x) \bigg) \gt0, \qquad \forall x \in \big( 0,\frac{1}{2} \big)$$ If $f(0)=f\bigg(\dfrac{1}{2}\bigg)=0$ , then prove that $$\dfrac{f'\bigg(\dfrac{3}{8}\bigg)}{f\bigg(\dfrac{3}{8}\bigg)} \gt 2$$ $$\dfrac{f'\bigg(\dfrac{1}{8}\bigg)}{f\bigg(\dfrac{1}{8}\bigg)} \lt 2$$ My Attempt: Let $g(x)=e^{-2x}f(x)$ . Now according to the given conditions, I thought of the curve as a parabola with a minima at $x=\dfrac{1}{4}$ and $g(x)=0$ at $x=0,\dfrac{1}{2}$ . Also, because the graph always has an upwards concavity in the given range. $g(x)=ax^2-\dfrac{ax}{2}, a\gt 0$ but now the range does not satisfy. I also don't know which equation to apply for obtaining the respective proving conditions now. Also what can be some alternate methods? The answer key states that given condition is false and the opposite inequality of both is correct. Thank You","['calculus', 'derivatives', 'algebra-precalculus']"
4246494,Finding the gradient of the restricted function in terms of the gradient of the original function,"The following question showed up as part of a proof that I am doing for my research thesis. If we have a differentiable function $f: \mathbb{R}^n \to \mathbb{R}$ and then set $n-d$ coordinates to zero we get a new differentiable function $g: \mathbb{R}^d \to \mathbb{R}$ . Now, given the gradient $\nabla_x f(x)$ , how one can get $\nabla_y g(y)$ ? My try Let $x \in \mathbb{R}^n$ and $S \subset \{1,\dots,n\}$ such that $|S|=d$ where $|\cdot|$ is the cardinality of the set. Let $U_S$ be a restricted identity matrix such that the $j$ -th entry of the diagonal matrix is maintained if $j \in S$ otherwise it is set to zero. Also, let $I_S$ be the restriction of $U_S$ where we keep nonzero columns and remove zero columns. Hence, $$
g(y)=f(U_Sx)
$$ where $y=I_S^{\top}x$ . The above is the translation of what I stated in terms of functions $f$ and $g$ . From this point things are a little bit unclear. I think the answer should be $\nabla_y g(y)=I_S^{\top} \nabla_x f(x)$ but I do not know how to get it. Also, I know using the chain rule $J_x f(U_S x)=J_{W} f(W)J_x W= J_{W} f(W)U_S$ where $J$ is the Jacobian and $W=U_S x$ . In addition, $\nabla^{\top}_x f(U_Sx) = J_x f(U_S x)=J_{W} f(W)U_S$ . I do not know how to put things together.","['partial-derivative', 'multivariable-calculus', 'derivatives', 'scalar-fields']"
4246506,Pythagoras Theorem or Trigonometry?,"I had this question in my test:- Authority wants to construct a slide in a city park for children. Authority prefers the top of the slide at a height of 4m above the ground and inclined at an angle of 30° with the ground. So one of the subparts of this question was:-
If AB + BC = 25m and AC = 5m, then the value of BC is:-
(A) 25m      (B) 15m
(C) 10m      (D) 12m Actual solution: So the solution was by assuming BC = x and AB = 25 - x. Then by applying Pythagoras Theroem we have: $(25-x)^2 = x^2 + 5^2$ and then after solving for x we get x = BC = 12m My Approach: I applied sine for angle B : $\sin(B) = \sin(30°) = \dfrac{1}{2} = \dfrac{AC}{AB} = \dfrac{5}{AB} \\ \implies AB = 10m$ Then by using the relation: $AB + BC = 25m$ , I got $BC = 15m.$ My Problems: Why do the two answers differ? In the way I solved, the sides are: 5, 10 and 15, which is not a Pythagoream Triplet. How is this possible since the slide should be perpendicular to the ground, and even more, trigonometric ratios exist for right triangles only. In my answer why is the side BC which is a leg has more length than the hypotenuse AB","['trigonometry', 'pythagorean-triples']"
4246515,Evaluate $\lim_{x \to -2} \frac{x + 2}{\sin(\frac{\pi x}{2})}$ using continuity (without L'Hospital),"A little background: I am TAing for a Calculus I class (mostly non-math majors), and this problem showed up on the worksheet for tomorrow. We have fully developed limits, including the squeeze theorem, and continuity, but we have not covered L'Hospital's rule yet. I am not sure how the students are supposed to approach this one. Perhaps I am missing something. Here is the problem: Use continuity to evaluate the limit. Explain your answer (especially why you can use continuity). $$
\lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)}.
$$ We see that this function is not continuous (has a hole) at $-2$ and, for that matter, at all values of $x$ that make $\sin\big(\frac{\pi x}{2}\big) = 0$ . We will get $\frac{0}{0}$ if we do all the steps to get down to the point at which we can just plug in $-2$ . We cannot use L'Hospital's rule. The best direction I see is something like this: \begin{align*}
\lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)} &= \lim_{x \to -2} \frac{x}{\sin\big(\frac{\pi x}{2}\big)} + \lim_{x \to -2} \frac{2}{\sin\big(\frac{\pi x}{2}\big)}\\
&= \frac{2}{\pi}\lim_{x \to -2} \frac{\frac{\pi x}{2}}{\sin\big(\frac{\pi x}{2}\big)} + 2\lim_{x \to -2} \frac{1}{\sin\big(\frac{\pi x}{2}\big)}
\end{align*} From there, we might be able to do some $\frac{\sin(x)}{x}$ -type thing with the left term, but I am not quite sure what to do with the right term.","['limits', 'calculus', 'limits-without-lhopital', 'continuity']"
4246531,"$C[0,1]$ and $C^1[0,1]$ continuous bijections in either direction","I am trying to find two non homeomorphic topologies with continuous bijections in both directions. I know there are solutions for this online, but I would much rather someone tell me whether I'm thinking along the right lines to solve this well known problem. Please do not post spoilers. Consider $C[0,1]$ and $C^1[0,1]$ with $f(0)=0$ and the uniform norm. $C^1$ denotes the continuously differentiable functions. $C^1$ is not complete but $C$ is so they are not homeomorphic.
I think that the maps $F[f]=\frac{d}{dx}f$ and $G[f]=\int_0^xf$ are bijections in either direction and $F[G[f]]=f$ so one of them must not be continuous. This is a shame, I'm considering modifying $F$ , for instance $F[f]=\frac{d}{dx} (xf)$ , maybe that smoothes things out. If I change to another norm I know (Sobolev norm maybe), I lose the nice guarantee that they are nonhomeomorphic. Am I wasting my time or is this going somewhere?","['metric-spaces', 'analysis', 'continuity', 'general-topology', 'derivatives']"
4246549,"Points of discontinuity of $\left[\frac{f(x)}3\right], f(x)=\lim_{n\to\infty}\ln(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}...\sqrt{e^{(2n+1)\cos x}}}})$","Let $f(x)=\lim_{n\to\infty}\ln\left(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}\sqrt{e^{5\cos x}...\sqrt{e^{(2n+1)\cos x}}}}}\right)$ and if $g(x)=\left[\frac{f(x)}3\right]$ , then the number of points in $[0,2\pi]$ where $g(x)$ is discontinuous, is/are (where $[*]$ represents greatest integer function)... $\cos x$ varies from $-1$ to $1$ . If $\cos x=-1$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=0$ If $\cos x=0$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=1$ If $\cos x=\infty$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=\infty$ Also, since $\cos x$ is changing these values in continuous manner, can we use that to comment about the continuity of $f(x)$ ? But before that, I would need to solve the limit. Not able to do so. Can you give any pointers? Thanks. EDIT: $f(x)=\lim_{n\to\infty}\ln\left(e^{\left(\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\right)\cos x}\right)$ Let $$S=\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\\\frac S2=\frac1{2^2}+\frac3{2^3}+\frac5{2^4}+...+\frac{(2n+1)}{2^{n+2}}$$ Subtracting, $$\frac S2=\frac12+\frac12+...\text{(n+1) times}-\frac{2n+1}{2^{n+2}}=\frac {n+1}2-\frac{2n+1}{2^{n+2}}\\\implies S=n+1-\frac{2n+1}{2^{n+1}}$$ I think my $S$ is coming out to be $\infty$ . Can you point out the mistake? Thanks. EDIT $2$ : After reading the comments, I reworked and found $S=3$ . Thus, $f(x)=3\cos x\implies\left[\frac{f(x)}3\right]=[\cos x]$ Thus, there are $4$ points of discontinuity $\{0,\frac\pi2,\frac{3\pi}2,2\pi\}$ .","['calculus', 'functions', 'limits', 'trigonometry', 'exponential-function']"
4246585,Gambler's Ruin with unfair coin,"I was solving this famous problem which reads: You start with N Dollars.
Each turn, you toss a coin for each dollar you have and you double it if you win, otherwise, you lose it. You go on like this.
What is the probability of losing all of your money? You solve the problem in the following way: You notice that, $$P(\text{Ruin having N dollars}) = (P(\text{ruin having 1 dollar}))^N$$ calling $ e:= P(\text{ruin having 1 dollar}) $ you set the recursive expression $$
e = p_l + p_w e^2 
$$ in which $p_l$ is the probability of losing and $p_w$ is the probability of winning (so that, you have now two coins and you have to lose both of them). Setting $p_l = p_w = 1/2$ one has $e = 1$ , which means that if you play this game forever you will lose eventually. This is a standard problem and it is pretty famous. I wanted to generalize the problem for unfair coins. In particular, I wanted to find the value of $p_w$ for which the probability $e$ is not zero.
So, I solved the equation for general $p_w$ and $p_l = 1 - p_w$ and what you get is that you always have two solutions, namely: $$
e_1 = \frac{p_l}{p_w};  \quad e_2 = 1
$$ When $p_w <1/2$ , $e_1$ is larger than $1$ : we can exclude this solution because it is not in $(0,1)$ , the valid range for probability. We still have $1$ as a solution, which implies that we will always lose for all of our money. But when $p_w > 1/2$ , $e_1$ is in (0,1), meaning that it is an acceptable solution. In fact, for $p_w=1$ you got $e_1=0$ , according with the intuition. The trouble is that $e_2$ is still a valid solution. Is this correct? And should we interpret the fact that we have two valid solutions in that regime, one of which leads to certain ruin?","['stochastic-processes', 'probability-theory', 'probability']"
4246600,"How do I evaluate the $(1,3)$-curvature tensor $R(X,Y)Z$ when $X,Y,Z$ are vector fields along a one-parameter family of curves?","Let $(M,g)$ be a Riemannian or pseudo-Riemannian manifold and denote the space of smooth vector fields on $M$ by $\mathfrak{X}(M)$ . Following Lee's book on Riemannian manifolds, we define the $(1,3)$ -curvature tensor $R:\mathfrak{X}(M)\times\mathfrak{X}(M)\times\mathfrak{X}(M)\to\mathfrak{X}(M)$ by $$R(X,Y)Z=\nabla_X\nabla_Y Z-\nabla_Y\nabla_X Z-\nabla_{[X,Y]}Z.$$ The definition of $R$ is as simple as it appears, before we introduce vector fields along a one-parameter family of curves. Let $I,J$ be intervals in the real line. A one-parameter family of curves in $M$ is a map $\Gamma:J\times I\to M$ , since it defines two collections of curves in $M$ : the main curves $\Gamma_s(t):=\Gamma(s,t)$ and the transverse curves $\Gamma^{(t)}(s):=\Gamma(s,t)$ . If $\Gamma$ is smooth, we denote the velocity vectors of the main and transverse curves by $$\partial_t\Gamma(s_0,t_0)=\Gamma_{s_0}'(t_0)\text{ and }\partial_s\Gamma(s_0,t_0)=\Gamma^{(t_0)}\ '(s_0).$$ Each of these is an example of a vector field along $\Gamma$ , which is a map $V:J\times I\to TM$ such that $V(s,t)\in T_{\Gamma(s,t)}M$ for each $(s,t)\in J\times I$ . Now, there is a proposition that involves feeding $R$ with such vector fields. Proposition 7.5. Suppose $(M,g)$ is a smooth Riemannian or pseudo-Riemannian manifold and $\Gamma:J\times I\to M$ is a smooth one-parameter family of curves in $M$ . Then for every smooth vector field $V$ along $\Gamma$ , $$D_s D_t V-D_t D_s V=R(\partial_s\Gamma,\partial_t\Gamma)V.\tag{7.5}$$ I don't know what the RHS of (7.5) stands for: the input vector fields are not from $\mathfrak{X}(M)$ . What am I supposed to do with it? Thank you. Note: For those who deem this question to be a duplicate, I know $R$ is a tensor field. Actually, after giving the definition of $R$ , Lee showed in a proposition that $R$ is $C^\infty(M)$ -linear in each argument and is thus induced by a $(1,3)$ -tensor field. Epilogue: For those who are struggling with the same question, my advisor told me it could be an abuse of notation. The author might have been implicitly using the pullback bundle $\Gamma^*(TM)$ , a subtle agent that played an important role in the computation. The symbol $R$ here is actually the pullback of the original $(1,3)$ -curvature tensor. For more information, please see Pullback bundle - Wikipedia . Finally, I'd like thank all of the people who contributed an idea. Thank you.","['riemannian-geometry', 'differential-geometry']"
4246601,Multiplication of (pluri-)canonical ring,"Let $X$ be a smooth projective variety. One uses the so-called (pluri-)canonical ring $R(X) = \bigoplus_{m \geq 0} H^0(X,\omega_X^{\otimes m})$ to define the canonical model $X^{\text{can}}$ of $X$ . Just because of the resemblence with the tensor algebra, I had always thought that the multiplication on $R(X)$ was given by $$ \left( \sum_i s_i \right) \cdot \left( \sum_j t_j\right ) = \sum_n \sum_{i+j= n} (s_i \cdot t_j),$$ where the multiplication $s_i \cdot t_j$ is induced by the tensor product. Since that would not result in a commutative ring, I was certainly mistaken and am now looking for the actual multiplication. I checked several sources (including Mumford's original paper where he first defines this ring), but all these sources never spell out the multiplication or just claim that it has an obvious one. While I will probably agree a posteriori that there was an obvious multiplication that I seem to overlook, I just do not see it at the moment and would therefore be grateful for someone to clarify this little problem.","['algebraic-geometry', 'birational-geometry']"
4246643,Checking Differentiability Of g(x) Using Information Of f(x) (unsolved),"Let $$f(x)=e^{x+1}-1, g(x)=p|f(x)|-\sum_{k=1}^n|f(x^k)|, n \in \mathbb N$$ It is given that $g(x)$ is a differentiable function over the complete real numbers. If value of $p=100$ , then sum of possible values of $n$ is $\dots$ I basically couldn't think of any way to start with this problem, Clearly $|f(x)|$ is not differentiable at $1$ point whereas in even powers ( $f(x^{2n}))$ of $f(x)$ , the function is differentiable at all points. Simply speaking, for odd values of $k$ , function will not be differentiable but for even values of $k$ , the function is differentiable at all points. But I have no clue on how to apply this concept in this question. The series is getting too long with none satisfactory results nor any hint for approaching this problem. EDIT: Can somebody please elaborate Ashish Ahuja's answer more? For checking differentiability at $x=-1$ (as suggested by below answer), how can we proceed? I suppose we can calculate the answer ( $n=19,20$ ) from here, but how? Also have a look at my answer below and kindly spot my mistake please. How can we confirm that the problem only occurs at $x=-1$ and not other numbers? Thank You","['calculus', 'derivatives']"
4246647,A conjectural infinite series for $\frac{\pi}{2}$,"Can you provide a proof for the claim given below? In this Wikipedia article the constant $\pi$ is represented by the following infinite series: $$\pi=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\epsilon(n)}}{n}$$ where $\epsilon(n)$ is the number of prime factors of the form $p \equiv 1 \pmod{4}$ of $n$ . (Euler, 1748) Similarly, we can formulate the following claim: $$\frac{\pi}{2}=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\kappa(n)}}{n}$$ where $\kappa(n)$ is the number of prime factors of the form $p \equiv 3 \pmod{4}$ of $n$ . The SageMath cell that demonstrates this claim can be found here . Now, I don't know how to start the proof. Any hints or references are welcomed.","['elementary-number-theory', 'real-analysis', 'pi', 'sequences-and-series', 'prime-numbers']"
4246656,Composition of flow maps of Hamiltonian systems,"Given a pair of autonomous Hamiltonian vector fields $X_H,X_K\in\mathfrak{X}(M)$ , with flow maps which are respectively $\Phi^t,\Psi^s$ , is $\Phi^t\circ \Psi^s$ the $(t+s)-$ flow map of some Hamiltonian system? I think this is the case, possibly with the final map being the flow of a time-dependent Hamiltonian system. I know that the composition map is a symplectomorphism. However, since not all the functions in this space are flows of Hamiltonian systems, I am not sure of the answer to this question. Here is an additional explanation of what I am interested in. I do not mean that for any $t$ and $s$ , the Hamiltonian of the resulting vector field remains unchanged. More precisely, here are some settings which, for my interest, are not counterexamples: $$ \Phi^t\circ \Psi^s = \varphi_{X_L}^{t+s} $$ $$ \Psi^t\circ \Phi^s = \alpha_{X_R}^{t+s} $$ $$ \Phi^u\circ \Psi^v = \varphi_{X_W}^{u+v}, $$ where $L,R,W$ are three Hamiltonian functions which possibly do not coincide. This means that, when we fix $t$ and $s$ , there is a Hamiltonian vector field $X_{U}$ so that its $(t+s)-$ flow is the same map as $\Phi^t\circ \Psi^s$ .","['vector-fields', 'dynamical-systems', 'hamilton-equations', 'differential-geometry']"
4246681,concave function in context of matrices,"Consider $A \in \mathbb{R}^{n \times k} $ and $x \in \mathbb{R}^n$ . $(AA^T)^{-1}$ is assumed to exist.
Define $f(x)= -xAA^T x$ Why is $f$ a concave function? Computing the hessian matrix yields: $ -AA^T$ . At this point I cannot say anything about definiteness. Is there an alternative way of approaching this?","['functions', 'derivatives', 'analysis', 'real-analysis']"
4246704,"Are $a=3, b=7$ the only solutions to $\sqrt{3}+\sqrt[3]{7}=\sqrt{a}+\sqrt[3]{b}$ for $a,b \in \mathbb{Q}$?","So I had a lesson about calculating surds e.g. $\sqrt{5+2\sqrt{6}}$ , then the teacher wrote the steps like that: For some $a,b\in\mathbb{Q}_{\ge 0}$ $$\sqrt{5+2\sqrt{6}}=\sqrt{a}+\sqrt{b} \\ 
5+2\sqrt{6}=a+b+2\sqrt{ab} \\
$$ which directly implies $\begin{cases} a+b=5 \\ ab=6\end{cases}$ . The teacher didn't know the proof and I eventually found a proof of it: Rewrite the equation, we get: $$5-a-b+2\sqrt{6}=2\sqrt{ab}$$ Then let $2c=5-a-b$ , where $c$ should be rational. Then we continue the equation: $$ 2c+2\sqrt{6}=2\sqrt{ab} \\ c+\sqrt{6}=\sqrt{ab} \\ (c+\sqrt{6})^2=ab \\ c^2+6-ab=-2c\sqrt{6}$$ As $c^2+6-ab$ is rational, $-2c\sqrt{6}$ is also rational, which implies $c=0$ , i.e. $a+b=5$ . Substituting it back to the original equation, we get $ab=6$ . Q.E.D. He found the proof quite interesting and asked a question as follows: For rational numbers $a,b$ , is $(3,7)$ the only solution to the equation $\sqrt{a}+\sqrt[3]{b}=\sqrt{3}+\sqrt[3]{7}$ ? I try to prove this but it is harder than it looks. The cubic root is one of the annoying part of proving this. What I am able to prove is that $\sqrt{3}+\sqrt[3]{7}$ is irrational. Other than that, I have no idea. To prove this, I think it may probably consist of algebraic fields, which I totally have no idea. I would like to know if there are any ways to solve this as this problem is quite interesting. If you guys have any ideas, please feel free to send it out. Thanks :)","['algebraic-number-theory', 'abstract-algebra', 'diophantine-equations']"
4246707,Derivative of $Y \mapsto Y^T Y$,"Is this derivative done correctly? I've did not find the solution in the matrix cookbook, but followed the similar examples: $$\frac{\delta Y^TY}{\delta Y} =  ?$$ $$X=Y^TY$$ $$\delta X=(\delta Y^T)Y + Y^T(\delta Y)$$ $$\mathrm{vec}(\delta X)=\mathrm{vec}(\delta Y^TY) + \mathrm{vec}(Y^T\delta Y)$$ $$\mathrm{vec}(\delta X)=(I\otimes Y)\,\mathrm{vec}(\delta Y^T) + (I \otimes Y^T)\,\mathrm{vec}(\delta Y)$$ $$\frac{\delta X}{\delta Y} =  2(I \otimes Y^T)$$","['matrices', 'matrix-calculus', 'derivatives']"
4246712,Finding Constant C in ODE with Initial Condition,At some point we get: $$te^ty=te^t-e^t+C$$ Given the initial condition: $$y\log 2=1$$ How do we get $C$ from here? The lecture note writes: $$2\log 2 - 2 + C = 2\log 2$$ which I do not understand...,['ordinary-differential-equations']
4246899,"Does the notion of ""percentages"" extend to countably infinite and uncountably infinite sets?","In the case of finite sets, e.g. $A=\{1,2,3,4\}$ , if some asked me, ""What percentage of the numbers are even in $A$ ?"" , I would respond with $50 \%$ . If asked for a proof, I'd demonstrate that two of the four elements in the set are even. Now, consider the set $B=\mathbb N$ , which is countably infinite. If someone asked me, ""What percentage of the numbers are even in $B$ ?"" , intuitively, I would think the answer is $50 \%$ . However, I'm not sure how I would go about proving this. Finally, consider the set $C = \mathbb R \setminus \{0\}$ , which is uncountably infinite. If someone asked me, ""What percentage of numbers are greater than $0$ in $C$ ?"" , I would think the answer is $50 \%$ . Once again, I'm unsure of how I could demonstrate this must be true. So as the title of this post states, does the notion of ""percentages"" extend to countably infinite and uncountably infinite sets?","['probability-theory', 'percentages']"
4246900,cardinality of some subsets of the power sets of $\mathbb Z$ and $\mathbb R$,"What is the cardinal number of these sets : $X:= \left\{ A \in P(\mathbb Z) \mid \sum_{a \in A} |a| \text{ is finite} \right\}$ $Y:= \left\{ B \in P(\mathbb R) \mid(\mathbb {R}\setminus B) \space \text {is countable} \right\}$ $Z:= \left\{ C \in P(\mathbb R) \mid|C| = \mathfrak{c}  \right\}$ My solutions: $1.$ Define $ f : \left\{x\in P(\mathbb Z) | \text {x is finite subset}\right\}  \to \mathbb N$ $\space \text{defined by :} \begin{cases}  
  P_{lastdigit7}  \space ,  & \text{if $y\in x>0$} \\
  P_{lastdigit3},  & \text{if $y\in x<0$} \\\end{cases} $ so $f(X) = P_{y1}*P_{y2}* \cdots * P_{yn}$ $Py:=$ the prime number in the y place  , $P_1 = 2 , P_2=3$ and so on.. $P_{lastdigit7}:=$ the prime number in the y place  when last digit is 7 $P_1 = 7 , P_2=17$ ... $P_{lastdigit3}:=$ the prime number in the y place  when last digit is 3 $P_1 = 3 
  , P_2=13$ ... I think its a bijection and its prove that is countable , $\aleph_0$ . 2.We want $(\mathbb {R}\setminus B)$ to be countable so $B$ must be
uncountable . so lets find cardinality of countable sets. High limit : $|\mathbb R ^{\mathbb N}| = \mathfrak{c}.$ Low limit: $| \left\{0,1 \right\} ^{\mathbb N}| = \mathfrak{c}$ . So $|Y|=\mathfrak{c}$ . $P(\mathbb R)=\left\{ Countable \space subsets \right\} \bigcup  \left\{ 
  Uncountable \space subsets \right\} \implies $ $2^\mathfrak{c}=|P(\mathbb R)|=|\left\{ Countable \space subsets 
  \right\}| +  |\left\{ Uncountable \space subsets \right\}| = $ $\mathfrak{c} + |\left\{ Uncountable \space subsets \right\}| \implies 
  |\left\{ Uncountable \space subsets \right\}|=2^\mathfrak{c}. $ $|Y|=2^\mathfrak{c}.$ $3.$ In excercise 2 we show that $|C|=2^\mathfrak{c}.$ Is my proofs correct ?","['elementary-set-theory', 'cardinals', 'solution-verification']"
4246925,Converse of path test for multivariable limits. [duplicate],"This question already has answers here : If the limit along all continuous paths is $0$ for $f(x,y)$, must the limit actually be $0$? (2 answers) Closed 2 years ago . I'm familiar with the fact that, if $\lim_{(x,y)\to (x_0,y_0)} f(x,y)$ exists and is equal to some scalar $L$ and $r:\mathbb{R}\to \mathbb{R}^2$ is a function such that $\lim_{t\to 1} r(t) = (x_0,y_0)$ , then the limit $\lim_{t\to 1} f(r(t))$ also exists and is equal to $L$ . It can be easily proven with the $\varepsilon -\delta$ definition of limits. This allows to show the non-existence of $\lim_{(x,y)\to (x_0,y_0)} f(x,y)$ by showing the limit respect some path does not exist, or by showing that two paths lead to different limits. My question is: is the converse true? If $\lim_{t\to 1} f(r(t))=L$ for all paths $r:\mathbb{R}\to \mathbb{R}^2$ such that $\lim_{t\to 1} r(t) = (x_0,y_0)$ , can I conclude the existence of the multivariable limit $\lim_{(x,y)\to (x_0,y_0)} f(x,y)$ ? If so, how could I prove it?","['multivariable-calculus', 'calculus', 'real-analysis']"
4246926,Variation of exercise $1.1.1$ from Tao’s measure theory book,"Let $R$ and $S$ be $n-$ dimensional boxes. That is $R = I_1 \times I_2 \cdots \times I_n$ and $S = J_1 \times J_2 \cdots \times J_n$ .  Show that the difference $R \setminus S$ is a finite union of $n$ -dimensional boxes. This is a slight modification of from Tao’s measure theory book from exercise $1.1.1$ where instead of the elementary set we’re looking at the elements of it. I cannot find any properties for the difference of the products $\prod_k I_k \setminus \prod_k J_k$ . The only one I found was ( https://proofwiki.org/wiki/Set_Difference_of_Cartesian_Products ), which isn’t of much help. Is there a way to manipulate $\prod_k I_k \setminus \prod_k J_k$ somehow?","['measure-theory', 'real-analysis']"
4246927,Lyapunov equation with semidefinite right-hand side,Consider the Lyapunov equation $$A^TX+XA=-Q$$ with Hurwitz matrix $A$ and positive semi-definite matrix $Q\succeq0$ . When is its solution $X$ strictly positive definite?,"['lyapunov-functions', 'matrices', 'linear-algebra', 'linear-control', 'matrix-equations']"
4246953,Showing that the set is non-empty and bounded above,"I have the following exercise: Let $A$ and $B$ be two non-empty and bounded subsets of $\mathbb{R}$ ,
we define the set $E$ by $E=\{x=a+b: a \in A, b \in B\}$ Show that $E$ is non-empty and non-bounded I solved it but I felt like it is too trivial so I am hesitant about my solution, hence why this is in the solution verification tag. My solution: Assume that $E$ is empty, this implies that $a+b$ is undefined $\forall a,b \in A,B$ , the only way this could happen is $\nexists a,b \in A,B$ which would imply the set is empty, contradiction with what we are given. If $A$ is bounded then $\exists x,$ such that $x\geq a$ $\forall a \in A$ and if $B$ is bounded then $\exists y,$ such that $y\geq a$ $\forall b \in B$ Let $z=x+y$ then we have $z \geq e$ $\forall e \in E$ since $e=a+b$ and $x\geq a, y\geq b$ which means $E$ is bounded. Note: For the first part, I am not sure saying "" $a+b$ is undefined"" would be mathematically correct but I didn't find another way of putting it as even saying $a+b=\{\}$ or $a+b=\emptyset$ wouldn't make $E$ an empty set, any correction here would be appreciated.","['elementary-set-theory', 'solution-verification']"
4246957,"Definite Integral $\int_{1-\sqrt{a}}^{1+\sqrt{a}} \ln(1-z t^2)\frac{\sqrt{4a-(t^2-1-a)^2}}{t}\, dt$","Suppose $z<\frac{1}{(1+\sqrt{a})^2}$ , $0<a<1$ . I need to compute the following integral as function of z: $$
I(z)= \int_{1-\sqrt{a}}^{1+\sqrt{a}} \ln(1-z t^2)\frac{\sqrt{4a-(t^2-1-a)^2}}{t}\, dt
$$ So far, following the trick in this question I defined $$
J'(p)=\int_{1-\sqrt{a}}^{1+\sqrt{a}} \frac{t}{p t^2 -1}\sqrt{4a-(t^2-1-a)^2}\, dt
$$ With the change of variable $t^2-1-a = x$ , $$
J'(p)=\frac{1}{2} \int_{-2\sqrt{a}}^{2\sqrt{a}} \frac{\sqrt{4a-x^2}}{px + p(a+1)-1}\, dx
$$ Doing the Euler substitution $x = 2\sqrt{a}\frac{t^2-1}{t^2+1}$ , we have (using Mathematica) $$
J'(p) = 16 a \int_0^{\infty}\frac{t^2}{(t^2+1)^2 \bigg( \Big[p\big(\sqrt{a}+1\big)^2-1\Big]t^2+p\big(\sqrt{a}-1)^2-1\bigg)} \, dt
$$ \begin{equation}
\begin{split}
J'(p) &= 16 a \int_0^{\infty}\frac{t^2}{(t^2+1)^2 \bigg( \Big[p\big(\sqrt{a}+1\big)^2-1\Big]t^2+p\big(\sqrt{a}-1)^2-1\bigg)} \, dt \\
&= \frac{\pi}{2} \frac{-1+p(a+1)+\Big(1-\big(\sqrt{a}-1\big)^2p\Big)\sqrt{\frac{-1+\big(\sqrt{a}+1\big)^2p}{-1+\big(\sqrt{a}-1\big)^2p}}}{p^2}
\end{split}
\end{equation} Now, to find $I(z) = \int_0^z J'(p) \, dp$ , there is a problem that in the $J'(p)$ there is a logarithm of $p$ which makes it undefined at 0.","['integration', 'improper-integrals', 'definite-integrals']"
4246960,Motivation behind Borel $\sigma$ Algebras,"I understand what a Borel sigma algebra is, I am just not sure why we have the motivation to find such a sigma algebra. It seems clear to me that the power set would satisfy everything I have learned about thus far. At the moment I try to gather some intuition from topology. If we look at the box topology and the product topology on an infinite set. It turns out that the box topology simply has too many open sets in it for it to describe anything in a useful way. I assume that somehow the power set simply has too many open sets in it for it be useful. To borrow a term from topology the Borel sigma algebra is defined in such a way that it is the coarsest sigma algebra that contains the things we are interested in studying my question is WHY do we need it.","['measure-theory', 'analysis']"
4246994,Counting positive integer solutions to $x_1 + x_2 + x_3 = 3n$,"Let's say I'm using stars-and-bars to count the number of nonnegative integer solutions to $$x_1 + x_2 + x_3 = 3n.$$ Clearly, it's going to be $\binom{3n + 2}{2}$ . And now let's say we want to count the number of positive integer solutions to the same equation. I'm able to calculate without stars and bars by subtracting from $\binom{3n + 2}{2}$ (1) the number of solutions where one $x_i$ is zero, and (2) the number of solutions where two $x_i$ are zero. We have $$\binom{3n+2}{2} - 3(3n-1) - 3 = \binom{3n-1}{2},$$ which is the correct answer. However, when I try to apply stars-and-bars to the solving for the number of positive integer solutions of the equation $$x_1 + x_2 + x_3 = 3n,$$ I add $3$ to both sides to account for the fact that each of the three $x_i$ has to now be greater than or equal to $1$ and not $0$ , and so I end up getting $\binom{3n + 5}{2}$ , which is clearly wrong. I don't understand why I would have to subtract $3$ from both sides of $$x_1 + x_2 + x_3 = 3n$$ to perform stars-and-bars for the positive integer solutions case instead of adding $3$ , in order to get the correct answer of $\binom{3n-1}{2}$ . Any help would be well-appreciated.","['algebra-precalculus', 'binomial-coefficients', 'combinatorics']"
4247005,"Topology of $\mathbb{R}^{n+1}$ versus $\mathbb{R}^{n,1}$","What are the topology of these two noncompact manifolds $M_1=\mathbb{R}^{n+1}$ versus $M_2=\mathbb{R}^{n,1}$ , their differences? The inner product of the vectors for $M_1$ relies on the Euclidean metric: $$
g_{ab}=\delta_{ab}, \quad a,b \in 1,2,...,n+1.
$$ The inner product of the vectors for $M_2$ relies on the (pseudo) Minkowski metric: $$
g_{1,1}=-1, \quad g_{ab}=+\delta_{mn}, \quad a,b \in 2,...,n+1.
$$ All off diagonal components are zeros. Homotopy group: I believe both have the $\pi_0(M_1)=\pi_0(M_2)=0$ . So only one piece. I believe both have the $\pi_1(M_1)=\pi_1(M_2)=0$ . So only contractible cycles. how about higher homotopy groups $\pi_k(M_1)$ , or $\pi_k(M_2)$ ? Homology groups: how about higher homotopy groups $H_k(M_1)$ , or $H_k(M_2)$ ? Are there some topology ways to distinguish $\mathbb{R}^{n+1}$ versus $\mathbb{R}^{n,1}$ ? What are those topological differences between the $M_1=\mathbb{R}^{n+1}$ versus $M_2=\mathbb{R}^{n,1}$ ?","['homotopy-theory', 'differential-topology', 'homology-cohomology', 'algebraic-topology', 'differential-geometry']"
4247019,Properly Discontinuous Action and Covering Spaces,"Out of interest, I have been trying my hand at the following problem that is relevant to covering spaces: Let $X$ be a locally compact and simply connected Riemann surface and let $G$ be a discrete subgroup of the group of automorphisms of $Aut(X)$ (here discrete is taken to mean that the identity element is an isolated point of $G$ within the Lie group $Aut(X)$ ). If $G$ acts freely on $X$ , then the action of $G$ is properly discontinuous, that is, the set $$\{g \in G \ | \ K \cap g(K) \neq \emptyset\}$$ is finite for every compact subset $K \subset X$ . I have tried a sequence argument to no avail (unless I am missing something crucial) and I have tried searching the many questions relating to properly discontinuous actions that can be found on this site. However, I have yet to find an answer that is specific to this question so I decided to ask it myself. It would be greatly appreciated if I could be pointed in the right direction on this particular problem, or even directed to a highly similar question (specifically with this definition of properly discontinuous) that I have overlooked. Thanks! Edit: It was made apparent to me in the comments that my original question might not end up being true, so I have imposed a further assumption that $X$ is a Riemann surface. If even now my question is not true, I would appreciate seeing either a counter-example or an explanation to how this is false. Thanks again!","['general-topology', 'topological-groups', 'covering-spaces']"
4247022,Functional derivative of KL divergence in paper,"I have been reading the following paper Black-Box Variational Inference as Distilled Langevin Dynamics . Very early on in the paper is equation one, which considers a base probability density $q_0 : \mathbb{R}^m\to\mathbb{R}_+$ that is transformed according to the change-of-variables formula under a smooth, invertible transformation $g:\mathbb{R}^m\to\mathbb{R}^m$ . Namely, let $q_{g}(\theta) = q(g^{-1}(\theta)) \vert\mathrm{det}(\nabla g^{-1}(\theta))\vert$ be the pushforward density of $q_0$ under the transformation $g$ . Let $p:\mathbb{R}^m\to\mathbb{R}_+$ be another probability density and consider the KL divergence between $q_{g}$ and $p$ : \begin{align}
\mathrm{KL}(q_g\Vert p) &= \int q_g(x)\log\frac{q_g(x)}{p(x)}~\mathrm{d}x \\
&= \int q_0(\epsilon) \log \frac{q_g(g(\epsilon))}{p(g(\epsilon))} ~\mathrm{d}\epsilon \\
&= \int q_0(\epsilon) \log \frac{q_0(\epsilon) / \vert \mathrm{det}(\nabla g(\epsilon))\vert}{p(g(\epsilon))} ~\mathrm{d}\epsilon.
\end{align} The paper claims that the functional derivative of the KL divergence with respect to the smooth transformation $g$ is $\frac{\delta}{\delta g}\mathrm{KL}(q_g\Vert p) = \nabla \log q_g(g(\cdot)) - \nabla \log p(g(\cdot))$ . I am having trouble deriving this and am looking for some help. Let's write the KL divergence as, \begin{align}
\mathrm{KL}(q_g\Vert p) = \int q_0(\epsilon) \log q_0(\epsilon) ~\mathrm{d}\epsilon - \int q_0(\epsilon) \log \vert \mathrm{det}(\nabla g(\epsilon))\vert ~\mathrm{d}\epsilon - \int q_0(\epsilon) \log p(g(\epsilon)).
\end{align} The first term has no dependency on $g$ and can therefore be ignored. Let's examine the third term and try to compute its functional derivative \begin{align}
-\frac{\delta}{\delta g}\int q_0(\epsilon) \log p(g(\epsilon)) ~\mathrm{d}\epsilon = -q_0(\epsilon) \nabla \log p(g(\epsilon)).
\end{align} This is nearly the same as the last term in the claimed functional derivative except that there is a factor of $q_0(\epsilon)$ present. This already makes me think I'm not proceeding along the correct path for the derivation.","['derivatives', 'functional-analysis', 'information-theory']"
4247041,Evaluate $\lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x}$,"How do you evaluate the following limit? $$
\lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x}
$$ I tried to make it approach the shape of the euler limit $$
\lim_{x\to\infty}\left(1+\frac{1}{f(x)}\right)^{f(x)}
$$ I added and subtracted 1, so that we get ""1 + a function"", I inverted this function, making 1 / (1 / f (x)). then to the exponent I multiplied and divided by the function, in order to obtain a limit like that of euler, raised to another function
but I realized that it was not the solution, because f (x) did not go to infinity when x went to infinity. Then I gave up and asked here.","['limits', 'calculus', 'limits-without-lhopital']"
4247085,How can we interpret the equality in the following example from stochastic calculus?,"We know from Itô's lemma that: $$\int_0^T w_t \, dw_t=\frac{w_T^2}{2}-\frac{T}{2},$$ where $w$ is a Wiener process. I don't know how we can interpret the equality!? It is equal for all $\omega\in\Omega$ ? Or in distribution? Or how? I would say it is true for (almost?) every $\omega$ , because the left side of the equation is $$\int_0^T w_t \, dw_t \overset{\circ}{=} \lim_{n\rightarrow\infty}^p \sum_k w_{t_k} \left[w_{t_{k+1}}-w_{t_k}\right],$$ by definition, where $0=t_0\leq t_1\leq t_2\leq\ldots\leq t_n=T$ , and in this definition we use the same Wiener process, just like in the right side of the first equation. So is it true if $\omega=\bar{\omega}$ is fixed, then $$\left(\int_0^T w_t \, dw_t \right) \left(\bar{\omega}\right) = \frac{w_T^2 \left(\bar{\omega}\right)}{2}-\frac{T}{2}\text{?}$$ There are some definitions about the equality of stochastic processes, what can we say about theme in this case? It is just an example, but I am rather interested in how we can interpret the equality in Itô's lemma!? (I hope I ask the same question and it is a relevant example.) Another train of thought motivated the previous question: Let the following series of random variables be: $$\xi_1,\xi_2,\xi_3,\ldots$$ which is convergent in stochastic convergence. It also means that there exists a $\xi$ random variable, where $$\mathbf{P}\left(\omega:\left|\xi_k-\xi \right| > \varepsilon \right) \longrightarrow 0$$ as $k\rightarrow\infty$ . But what is that $\xi$ ? Of course, if we have a conjecture about $\xi$ and we want to know that $\xi$ is a proper limit: $\lim_{k\rightarrow\infty}^p \xi_k = \xi$ , then we should check if the previous $\mathbf{P}\left(\omega:\left|\xi_k-\xi\right| > \varepsilon\right) \longrightarrow 0$ property holds.
But if we only know that $(\xi_k)_k$ is convergent in the stochastic way, then how can we ""construct"" this $\xi$ ? What can we say if $\xi$ is a random process? The convergence should hold for every $t\in[0,T]$ where the process is defined? Sorry for the lot of questions, but I think they belong to the same topic.","['measure-theory', 'stochastic-processes', 'limits', 'brownian-motion', 'stochastic-calculus']"
4247110,"""Ultimate"" Weak Law of Large Numbers","I am confused about a proof involving in what my professor calls the ultimate WLLN. The statement goes as follows: Let $X_1,X_2,\ldots$ be iid, and $S_n = X_1 + X_2 + \cdots + X_n$ , then the following are equivalent: $\lim_{t\to\infty} tP(\left\lvert X_1\right\rvert > t) = 0$ . $\exists \{\mu_n\}_{n\geq 1}\subset \mathbb{R}$ such that $\frac{S_n}{n}-\mu_n \to 0$ in probability. I understand the direction $(1\implies 2)$ , but i don't understand the symmetrization argument the professor used to prove $(2\implies 1)$ . It goes something like this: Let $X_1',X_2',\ldots$ be another iid sequence distributed like $X_1$ , and $S_n'=X_1' + \cdots + X_n'$ , then it also holds that $\frac{S_n'}{n} - \mu_n \to 0$ in probability. This implies that $\frac{S_n}{n}- \frac{S_n'}{n} \to 0$ in probability. Now, we have that $S_n - S_n' = \sum_{i=1}^{n}(X_i - X_i')$ . Let $Z_i = X_i - X_i'$ , then $Z_1,Z_2,\ldots$ are iid with $Z_i =^d -Z_i$ . The professor then goes on to show that statement $(1)$ is true for the Z's and that somehow, this implies the property for the X's. I don't understand how showing property (1) for the Z's implies it for the X's. Also, if you know an alternative proof of this, you are more than welcome to share it. Edit: Corrected the statement. There was a 1/n missing.","['measure-theory', 'probability-limit-theorems', 'probability-theory', 'law-of-large-numbers']"
4247132,"Suppose $\{v,Av,\cdots,A^{n-1}v\}$ is linearly independent. Prove that if $B$ is any matrix which commutes with $A$, then $B$ is a polynomial in $A$.","Question: Let $A$ be an $n\times n$ square matrix and $v$ a column vector.  Suppose $\{v,Av,\cdots,A^{n-1}v\}$ is linearly independent.  Prove that if $B$ is any matrix which commutes with $A$ , then $B$ is a polynomial in $A$ . Thoughts: Let $A$ be $n\times n$ .  Wouldn't the matricies that commute with $A$ be a subspace of $\{v,Av,\cdots,A^{n-1}v\}$ (not sure how to formally prove this)?  And since $\{v,Av,\cdots,A^{n-1}v\}$ is linearly independent, then if $B$ were a polynomial in $A$ , it would have degree $\leq n-1$ , but I am a bit lost in seeing the details of the proof.  Any help is greatly appreciated!  Also, this is not a homework problem of mine, I have just been recently going over some old linear algebra stuff, and I just want to make sure I am seeing the details to better understand some of this stuff :)","['abstract-algebra', 'linear-algebra', 'vector-spaces']"
4247163,How to solve $\sin(2\theta)$ questions,"Given that: $\sin\theta=\displaystyle{}\frac{12}{13}$ and $0<\theta<\displaystyle{}\frac{\pi}{2}$ the value of $\sin(2\theta)$ is: I figured out a way to solve it, though I'm not sure if it is the best solution. Here we will combine two different trigonemtric identities. First: $\begin{align}
\sin(2\theta) & = 2\sin\theta\cos\theta \\
& = 2\cdot\frac{12}{13}\cdot\cos\theta \\
& = \frac{24}{13}\cdot\cos\theta
\end{align}$ Also: $\begin{align}
1 & = \cos^2\theta+\sin^2\theta \\
1 & = \cos^2\theta+\Bigg(\frac{12}{13}\Bigg)^2 \\
1 & = \cos^2\theta+\frac{144}{169} \\
1-\frac{144}{169} & = \cos^2\theta \\
\frac{25}{169} & = \cos^2\theta \\
\sqrt\frac{25}{169} & = \sqrt{\cos^2\theta} \\
\frac{5}{13} & = \cos\theta \\
\end{align}$ Then we insert this into the previous equation: $\begin{align}
\sin(2\theta) & = \frac{24}{13}\cdot\cos\theta \\
& = \frac{24}{13}\cdot\frac{5}{13} \\
& = \frac{120}{169}
\end{align}$ And I believe this is the correct answer. I'm just not sure if this was a super round about way of solving it or if there is something better.","['algebra-precalculus', 'trigonometry']"
4247195,What is an Affine Span?,"According to this definition of affine spans from wikipedia , ""In mathematics, the affine hull or affine span of a set S in Euclidean space Rn is the smallest affine set containing S, or equivalently, the intersection of all affine sets containing S."" They give the definition that it is the set of all affine combinations of elements of S. I am a little confused by this for two reasons. For each affine combination, they require $$\displaystyle \sum_{i=0}^n \alpha_i = 1$$ Why is this? Just as affine spaces are translations of a vector space, can I think of affine combinations as a translation of a vector? Any clarification or further details would be appreciated!","['linear-algebra', 'affine-geometry']"
4247208,Recurrence on partial orders,"Let $P_n$ denote the number of partial orders on $n$ elements. A partial order is a relation that is reflexive, anti-symmetric and transitive. $P_n$ is known for $n; 0\leq n\leq 18$ . See On-line Encyclopedia of Integer Sequences .
I have seen other combinatorial sequences which can be computed recursively from previous terms. For example this somewhat related sequence . Is there a way to do this with the number of partial orders? Can I get $P_{19}$ from the available values of $P_n$ ? How?","['order-theory', 'combinatorics']"
4247219,How can we mechanically rotate a branch-cut of a complex function?,"I'm looking for an algorithmic and mechanical way to define the branch cuts of an arbitrary (or not-so arbitrary, depending on how doable this is) complex function.  Given a function $f(z)$ that has a branch cut along, say, $[1,\infty)$ along the real line, is there a way to algebraically generate a function whose branch cut runs along $1+ci$ (for $c>0$ ), for instance?  The purpose of this question is to be able to plot arbitrary complex functions with arbitrary choices of branch cut in a computer algebra system like Mathematica , but I believe that this is a math question.  Implementing the answer in Mathematica would be straight-forward once I know how to do this. As a simple example, can we algebraically transform the function $$
\sqrt{z^2+1} = \sqrt{|z^2+1|}\exp\left(\frac{1}{2} \operatorname{Arg}({z^2+1}) \right),
$$ which has branch cuts that are rays from $\pm i$ going vertically to infinity, to one that has branch cuts that are rays from $\pm i$ going horizontally to infinity.  I think if I can figure this one out, I'll have what I need. By way of expaning on my ideas, let's consider the following two situations. Branch cuts of $f(z) = \sqrt{z^2+1}$ via a Möbius transformation Two standard ways to define the branch cut of this function are to take the finite segment $[-i,i]$ (defined as the straight-line segment joining $-i$ and $i$ ) or to take the rays $[i,i\infty)$ and $(-i\infty,-i]$ (defined as the rays going vertically). If we define this function via the complex logarithm as $$
f(z) = \exp\left(\frac{1}{2}\log\left(z^2+1\right)\right),
$$ and take the standard choice of brach cut for the logarithm, i.e., $$
\log(z) = \ln(|z|)+i \operatorname{Arg}(z),
$$ where $-\pi\leq \operatorname{Arg}(z) < \pi$ , then this corresponds to the latter choice of  branch cuts ( $[i,\infty)$ and $(-\infty,-i]$ ). As explained in this answer , we can use a Möbius transformation $$
z\mapsto \frac{z+i}{z-i},
$$ under which the branch cuts are essentially transformed into each other, and define the function $$
g(z)=(z-i)\exp\left(\frac{1}{2}\log\left(\frac{z+i}{z-i}\right)\right),
$$ which matches $f(z)$ for $\operatorname{Re}(z)>0$ .  We can verify this with Mathematica by plotting these functions (below). As far as I've been able to work out, this is the only Möbius transformation that works for this case, i.e., it's the only such transformation that makes $f$ and $g$ both be ""square roots"" of $z^2+1$ . Branch cuts of $\sqrt{z}$ implemented in Mathematica In Mathematica , $sqrt(z)$ is implemented with a branch cut along the negative real axis, consistent with the choice of branch cut for the logarithm mentioned above.  Indeed, defining a function f[z_] = Sqrt[Abs[z]] Exp[I*Arg[z]/2] yields the same results as Sqrt[z] , since Mathematica 's Arg function restricts its output to be between $-\pi$ and $\pi$ .  It is straight-forward to write our own function that rotates the branch cut, as seen here : sqrt[z_, s_] := Sqrt[Abs[z]] Exp[I/2 Arg[z Exp[-I (s + π)]] + s + π] This subtracts a phase from the argument $z$ , evaluates the Arg function, and then adds the phase back in. Here's an example where we rotate the branch cut by $\pi/4$ (plotting the real part of the function): Attempt at transforming $\sqrt{z^2+1}$ The same trick doesn't work here.  First of all, we can define this function via the square root function with the different branch cut in the following way.  Define the square root with a rotated branch cut rotated by $\sigma$ as $$
\operatorname{sqrt}(z) = \sqrt{|z|}\exp\left(
\frac{i}{2}\left(\operatorname{Arg}(ze^{-i(\sigma+\pi)}) + \sigma + \pi\right)
\right).
$$ Then, we can just define $$
g(z) = \operatorname{sqrt}(z^2+1)
$$ in order to change the branch cut.  Unfortunately, this doesn't rotate the branch cut but rather deforms it, as can be seen in the following plot of the real parts of $\sqrt{z^2+1}$ and $g(z)$ with $\sigma=3\pi/4$ (it starts off linear in the vicinity of the branch point, but then curves away): So instead, I tried to do something similar to what we did with the square root function directly.  Basically, since $$
\sqrt{z^2+1} = \sqrt{|z^2+1|}\exp\left(\frac{i}{2}\operatorname{Arg}(z^2+1)\right),
$$ it seems like we should be able to redefine the argument directly in such a way that the branch cut becomes linear in some arbitrary direction by doing something like $$
\operatorname{Arg}(z^2+1) = \operatorname{Arg}\left(\left(ze^{-i(\sigma+\pi)}\right)^2+1\right) + (?),
$$ but I cannot figure out what $\sigma$ should be. Is there a general recipe for this?","['complex-analysis', 'branch-cuts']"
4247264,Treating Relations as Sets,"I've been learning about relations and so far and I think I understand the basics just fine. If $R$ is a relation from $A$ to $B$ , then $R \subseteq A \times B$ . The ordered pairs in $R$ define a relation between the objects in A and B, so $a \in A$ is related to $b \in B$ by $R$ if $(a, b) \in R$ . I'm also fine with notions such as 'relations on a set', where $R \subseteq A \times A$ . I'm also fine with concepts such as reflexive, symmetric and transitive relations. I can wrap my head around treating the symbol $\leq$ as a set. For example, we define $\mathbb{N} = \{0, 1, 2, ...\}$ , and we define conditions under which $x \leq y$ , for all $x, y \in \mathbb{N}$ . I suppose it'd be something like: $\leq \, = \{ (x, y) \in \mathbb{N} \times \mathbb{N} \text{ | } y = x + d \text{ for some } d \in \mathbb{N} \}$ We can then construct $\mathbb{Z}$ and overload the $\leq$ symbol for the ordering relation in the set of integers, and the process repeats for $\mathbb{Q}$ and $\mathbb{R}$ . We can then show $\leq$ is reflexive, anti-symmetric and transitive, and everything works out just fine. The process above is what I'm comfortable with. However, I'm having a bit of trouble wrapping my head around $\subseteq$ , $\in$ and $=$ . Relations like $\leq$ make sense for me because we start from sets, and then we define the reals, and then further define $\leq \, \subseteq \mathbb{R} \times \mathbb{R}$ (depending on the construction method $\leq$ might be defined differently but the end result is still the same). After the stage is set, we just proceed using $\leq$ as I was taught in secondary school with no trouble. However, for $\subseteq$ , I see books are referring to this symbol as a relation, but it seems like the situation is entirely different. If the domain of $\leq$ is the set of reals, then what is the domain of $\subseteq$ ? The set of all sets? Isn't this set not allowed to exist in ZF? If the domain is not the set of all sets, then do we literally have to define a new domain based on the sets we are comparing every time we use $\subseteq$ ? It's not like it's impossible, and it's not like these concerns will affect the actual process of doing math, but I just find that technically such a cumbersome process is required when we use $\subseteq$ is a bit unsatisfying. My concerns for $\in$ and $=$ are also similar. It seems like this problem arises because $\subseteq$ , $\in$ and $=$ are used to express relationships between sets, unlike $\leq$ which is designed to operate in the little pocket universe of $\mathbb{R}$ which we have defined for ourselves. (Thanks in advance for taking the time to go through my long question. I'm a physics student who has recently acquired a taste for more rigorous mathematics, and so far I know about mathematical logic, sets and things like the Peano axioms at the level of an introductory course for undergraduates. At this point, I think I understand the ZF axioms so I should be able to comprehend any answer that might touch upon these concepts. I am currently reading Mathematical Proofs: A Transition to Advanced Mathematics and a bit of Tao's Analysis I.)",['elementary-set-theory']
4247266,How to show that $\displaystyle\lim_{x\rightarrow0}\dfrac{a^{2x}-2}{x^x}=-1$,"I tried like this: Let $y=a^{2x}-2\Rightarrow a^{2x}=y+2\Rightarrow 2x\ln a=\ln\left(y+2\right)\Rightarrow x=\dfrac{\ln\left(y+2\right)}{2\ln a}$ Also if $x\longrightarrow0,$ then $y\longrightarrow a^{2(0)}-2=-1.$ But we I put each and every this assumption in the given expression, then I get hanged due to $x^x.$ How to use algebra or any other easy procedure to show that $\displaystyle\lim_{x\rightarrow0}\dfrac{a^{2x}-2}{x^x}=-1$ .","['limits', 'calculus', 'limits-without-lhopital', 'algebra-precalculus']"
4247268,If $f\left(x\right)=-\frac{x\left|x\right|}{1+x^{2}}$ then find $f^{-1}\left(x\right)$,"Q: If $f\left(x\right)=-\frac{x\left|x\right|}{1+x^{2}}$ then find $f^{-1}\left(x\right)$ My approach: Dividing the cases when $x\ge0$ and when $x\le0$ to break free of modulus. Re-arranging the terms to get the expression of x in terms of y. Here's what I got: When $x\ge0$ : $$x=\sqrt{\frac{-y}{1+y}}$$ $$\to\ y\ ∈\ \left(-1,0\right] Now, y\to x$$ so, $f^{-1}\left(x\right)=\sqrt{-\frac{x}{1+x}}$ when $x\le0$ When $x\le0$ : $$x=-\sqrt{\frac{y}{1-y}}$$ when $y\ ∈\ \left[0.1\right)$ Now replacing $y\to x$ We get, $f^{-1}\left(x\right)=-\sqrt{\frac{x}{1-x}}\ ;\ x\ge0$ But I have to show that the inverse function $f^{-1}\left(x\right)$ = $\operatorname{sgn}\left(-x\right)\sqrt{\frac{\left|x\right|}{1-\left|x\right|}}$ This is where I'm getting stuck. I am unable to convert my answer into this form, mainly because I'm not able to convert the cases into this expression. Is there any step-by-step systematic way in which I can do the same? Any help or guide will be greatly appreciated. Edit: Since we got $f^{-1}\left(x\right)$ and the cases,: $f^{-1}\left(x\right)=-\sqrt{\frac{x}{1-x}}\ ;\ x\ge0$ and $f^{-1}\left(x\right)=\sqrt{-\frac{x}{1+x}}$ when $x\le0$ , to write it in given form we need something that will give - sign when $x>0$ so we will use sgn(-x), and rest is just use of modulus so that we can make the general answer.","['algebra-precalculus', 'functions', 'inverse', 'inverse-function']"
4247295,"Let $f(x)=\left\{\begin{array}{l}x^3-1, x<2\\x^2+3,x\geq2\\\end{array}\right.$. Find $f^{-1}(x)$","This question seems quite straightforward, but it isn't. Let $f^{-1}(x)=g(x)$ $f(x)=\left\{\begin{array}{l}x^3-1, x<2\\x^2+3,x\geq2\\\end{array}\right.$ $f(g(x))=x$ If $x<2,(g(x)) ^3=x+1 \implies g(x)=(x+1)^{1/3}, x<2$ Similarly, if $x\geq2, g(x)=(x-3)^{1/2}$ . We know that $f(x)$ is one one function, so it passes the horizontal line test. However my book says $g(x)=\left\{\begin{array}{l}(x+1)^{1/3}, x<7\\(x-3)^{1/2},x\geq7\\\end{array}\right.$ Edit 1: The strange thing is that when I substitute values, the answer given in my books seems correct, even though it doesn't make sense mathematically. Edit 2: Since we have to consider the domain of another variable $y$ is it appropriate to write the inverse as a function of $x$ . How did this happen?","['functions', 'inverse-function']"
4247346,The Frenet frame is orthogonal,"I have proved $P'=AP$ where $$P= \begin{pmatrix} T \\ N \\B \end{pmatrix}$$ $$A=   \begin{pmatrix}
    0 & \kappa & 0 \\
    -\kappa & 0 & \tau \\
    0 & -\tau & 0 \\
    \end{pmatrix}
$$ . I am trying to show $P$ is orthogonal by this fact. I try to differentiate $PP^t$ , then $P'(P^t)+P(P^t)'=APP^t-PP^tA$ since $A$ is skew-symmetric. But I am stuck here, I am wondering if it is true that $APP^t=PP^tA$ .","['curves', 'frenet-frame', 'ordinary-differential-equations', 'differential-geometry']"
4247363,How to evaluate$J(k) = \int_{0}^{1} \frac{\ln^2x\ln\left ( \frac{1-x}{1+x} \right ) }{(x-1)^2-k^2(x+1)^2}\text{d}x$,"I am trying evaluating this $$J(k) = \int_{0}^{1} \frac{\ln^2x\ln\left ( \frac{1-x}{1+x}  \right ) }{(x-1)^2-k^2(x+1)^2}\ \text{d}x.$$ For $k=1$ , there has $$J(1)=\frac{\pi^4}{96}.$$ Maybe $J(k)$ doesn't have an explicit closed-form. An integral relation: $$\int_{0}^{\infty} \frac{\arctan^3x}{1+k^2x^2} \text{d}x
=-\frac{3}{2}J(k)+\frac{\pi^2}{8k} 
\left ( \operatorname{Li}_2\left ( \frac{1}{k}  \right ) 
-\operatorname{Li}_2\left ( -\frac{1}{k}  \right )  \right )
+\frac{\ln k}{8k}  \ln^3\left ( \frac{k-1}{k+1}  \right ),\qquad (k>1).$$ With some calculations, we followed that $$\int_{0}^{\infty} \frac{\arctan^3x}{1+k^2x^2} \text{d}x
=\frac{\pi^4}{64k} 
+\frac{3}{4k}\left ( \operatorname{Li}_4\left ( \frac{k-1}{k+1}  \right )
-\operatorname{Li}_4\left (- \frac{k-1}{k+1}  \right )
  \right ) +\frac{3\pi^2}{8k} \operatorname{Li}_2\left (- \frac{k-1}{k+1}  \right ),\qquad(k>1).$$ Then the final result of $J(k)$ is $${\color{Green}{J(k)
=\frac{\pi^2}{12k} 
\left ( \operatorname{Li}_2\left ( \frac{1}{k}  \right ) 
-\operatorname{Li}_2\left ( -\frac{1}{k}  \right )  \right )
+\frac{\ln k}{12k}  \ln^3\left ( \frac{k-1}{k+1}  \right )
-\frac{\pi^4}{96k} -\frac{1}{2k}\left ( \operatorname{Li}_4\left ( \frac{k-1}{k+1}  \right )
-\operatorname{Li}_4\left (- \frac{k-1}{k+1}  \right )
  \right ) -\frac{\pi^2}{4k} \operatorname{Li}_2\left (- \frac{k-1}{k+1}  \right ),\qquad (k>1).}}$$","['integration', 'definite-integrals', 'logarithms', 'contour-integration', 'polylogarithm']"
4247387,Simplify: $[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n ] \cup \dotsb \cup [ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) ]$,"I've just started studying Measure Theory. I was a little bit stuck on simplifying a set theoretic expression when I tried to prove a little problem from my reference book. Here I pose my problem in a general set theoretic manner: Given two finite families of indexed sets $\{A_k\}_{k=1}^n$ and $\{B_k\}_{k=1}^n$ , for some $n \in \mathbb{N}$ . Can we simplify $$ \tag{1}
\Big[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n \Big] \cup \dotsb \cup
\Big[ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) \Big] 
$$ into a form of large union operation? Here is my attempt: I directly put the large union operation into the following expression: $$ \tag{2}
\bigcup_{k=1}^n \left[ \left( \prod_{\alpha=1}^{k - 1} A_\alpha \right) \times \big( A_k
\cap B_k \big) \times \left( \prod_{\beta = k + 1}^{n} A_\beta \right) \right]
$$ My concern is, when $k = 1$ , we have $$ \tag{3}
\left( \prod_{\alpha = 1}^0 A_\alpha \right) \times (A_1 \cap B_1) \times
\left( \prod_{\beta = 2}^n A_\beta \right)
$$ and when $k = n$ we have $$ \tag{4}
\left( \prod_{\alpha = 1}^{n-1} A_\alpha \right) \times (A_n \cap B_n) \times
\left( \prod_{\beta = n+1}^n A_\beta \right)
$$ within the square braces, each of which is syntactically error. I presume $$ \tag{5}
\prod_{\alpha = 1}^0 A_\alpha = \prod_{\varnothing} A_\alpha
$$ and $$ \tag{6}
\prod_{\beta = n+1}^n A_\beta = \prod_{\varnothing} A_\beta
$$ and hence expression $(2)$ is precisely equal to expression $(1)$ . My big question is: $\textbf{are these presumptions allowed?}$ If it's not the case, then is there any better solution instead of writing down expression $(1)$ ? Any help is highly appreciated. Thank you.","['elementary-set-theory', 'measure-theory']"
4247397,Any non-zero solution of some second-order differential equation is not $2\pi$-period,"Suppose $$\frac {{d^2}y}{dx^2}+P(x)y = 0$$ where $P(x)$ is continuous and satisfying $n^2<P(x)<(n+1)^2$ where $n$ is a non-negative integer. Prove that any non-zero solution of the above second-order differential equation is not $2\pi$ -periodic. There are two facts I know that may be useful to the proof: $y''+Q(x)y=0$ where $Q(x)$ is continuous on $[a,+\infty]$ and satisfying $Q(x)\geq m>0$ , then the distance between any two immediate zeros of non-zero solution of it is less than $\frac {\pi}{\sqrt{m}}$ . $y''+Q(x)y=0$ where $Q(x)$ is continuous on $[a,+\infty]$ and satisfying $Q(x)\leq M \ (M>0)$ , then the distance between any two immediate zeros of non-zero solution of it is larger than $\frac {\pi}{\sqrt{M}}$ . From this, I can't get a contradiction since if there is such a solution, with $x_0$ and $x_0+2\pi$ two zeros, then there can be $2n$ zeros between them with each of adjacent distance $d_j$ satisfying $\frac {\pi}{n+1}< d_j < \frac {\pi}{n}$ . Does anyone know how to prove the result? Thank you",['ordinary-differential-equations']
4247411,Is exercise 2.22 (iii) in Rotman's Homological Algebra book wrong?,"I believe that the statement of exercise 2.22 in Rotman's Introduction to Homological Algebra is wrong. It states that if $R$ is an integral domain, $M$ is an $R$ -module, and $\textrm{Hom}_{R}(M,R/I) = 0$ for all non-zero ideals $I$ of $R$ , then $\textrm{Hom}_R(M,R) = 0$ . If $R$ is a field, then the only non-zero ideal is $(1)$ and $\textrm{Hom}_{R}(M,R/(1))$ is trivially zero, but $\textrm{Hom}_R(M,R)$ need not be. Am I right that the exercise is mistaken? I did not find a correction in the errata. Edit: Thank you metalspringpro for your answer. The exercise is correct when we exclude the possibility that $R$ is a field. To see this one can use the following statement: If the intersection of all non-zero ideals of an integral domain R is non-zero, show that R is a field.","['homological-algebra', 'abstract-algebra', 'commutative-algebra']"
4247430,"If $f(x) + 3x^2 = 2f(1-x)$ and $\lim _{x\to 1}f(x) =7$, find $\lim _{x\to 0} f(x)$.","If $f(x) + 3x^2 = 2f(1-x)$ and $\lim _{x\to 1}f(x) =7$ , find $\lim _{x\to 0} f(x)$ . I tried to solve this problem with this method: $$\lim_{x\to 1}f(x)= \lim_{x\to 1}2f(1-x)-\lim_{x\to 1}3x^2$$ $$7= \lim _{x\to 1}2f(1-x) - 3 \Rightarrow 5=\lim_{x\to 1}f(1-x)$$ Putting $u=1-x $ $$\lim_{x\to 1}(1-x)=0$$ $$\lim_{u\to 0}f(u)=\lim_{x\to 0}f(x)=5$$ Apperently this method is incorrect so could you point out the mistake for me? The correct answer is $\lim_{x\to 0} f(x)=14$ .","['limits', 'calculus', 'solution-verification', 'functional-equations']"
4247450,Proving every Cauchy sequence in $\mathbb{R}$ is convergent. Does the following proof work?,"I tried to prove this but my proof did not match with my book's. So I want to verify whether my proof is correct or not. Theorem: Every Cauchy sequence in $\mathbb R$ has a limit. Let us assume the contrary that there is a sequence $(a_n)$ which is Cauchy but not convergent. 1.Since the sequence is not convergent,for all real $a$ , there must be an $\epsilon$ such that for all $n \in \mathbb N$ , $\exists n_0 \geq n$ such that $|a_{n_0}-a|\geq \epsilon$ . 2.Since $(a_n)$ is Cauchy, we can show that that particular $\epsilon$ we talked above,there is a natural $N$ such that for all $n,m\geq N$ , $|a_n-a_m|<\epsilon$ . 3.Go and look $(1)$ . I can thus find $m_0 \geq N$ such that $|a_{m_0}-a| \geq \epsilon >|a_{m_0}-a_n|$ for all $n \geq N$ . Since $a$ is arbitrary, putting $a=a_n$ ,we get contradiction.Thus, the proof.","['cauchy-sequences', 'real-analysis', 'solution-verification', 'limits', 'convergence-divergence']"
4247522,"Is it true that if $A$ and $B$ are nowhere dense subsets of $[0,1]$ then the Minkowski sum $A+B=\{a+b:\ a\in A, b\in B\}$ is nowhere dense in $[0,2]$?","This is one of my weird ""isolated problems"" that I just think up by myself. Question $1:\ $ Is it true that if $A$ and $B$ are nowhere dense subsets of $[0,1]$ then the Minkowski sum $A+B = \{a+b:\ a\in A, b\in B\}$ is nowhere dense in $[0,2]$ ? Question $2:\ $ Is it true that if $A$ and $B$ are nowhere dense subsets of $[0,1]$ then the ""multiplication product"" $AB = \{ab:\ a\in A, b\in B\}$ is nowhere dense in $[0,1]$ ? For the first question to have negative result, we need to show that, if $\ I\ $ is an interval inside $\ [0,2],\ $ then $\ \exists x\in I\ $ such that $\ x\ $ is not a limit point of $A+B.$ But I don't know how to go about doing this. Alternatively, maybe the first question has positive result, which might arise if our sets $A$ and $B$ were Cantor sets, although my intuition on Cantor sets is limited. In particular, I find it hard to picture the properties of $A+B$ if $A$ and $B$ are Cantor sets.","['general-topology', 'cantor-set', 'problem-solving', 'real-analysis']"
4247524,Finding the probability that at least 8 houses in a row are of same colour.,"There are 400 houses in a row. Each house is to be coloured with any of the following five colours: red, blue, green, yellow, and white. The colour of each house is to be chosen randomly from among these five colours and independent of any other selection. Now, what is the probability that at least 8 houses in a row will have the same colour? My idea is to first calculate the number of ways in which there are at least 8 red-coloured houses in a row. Then do the same for green, then blue, yellow and white ( ${R}\to{G}\to{B}\to{Y}\to{W}$ ). Suppose, $ n(R) $ denotes the number of ways that there are 8 red-coloured houses in a row. So, $$n(R) = (number\ of\ ways\ to\ choose\ one\ row\ of\ 8\ houses\ from\ 400\ houses)\times(number\ of\ ways\ rest\ of\ the\ houses\ can\ be\ painted) = \mathrm{393}\!\cdot\!\mathrm{5^{392}} $$ Now, $$ n(R) = n(G) = n(B) = n(Y) = n(W)$$ Initially I was careless to conclude that the required probility will be, $$ p = \frac{n(R) + n(G) + n(B) + n(Y) + n(W)}{5^{400}}$$ But a few moments later I realised that there is a lot of double-counting in this solution. (For example, when calculating $n(R)$ , you can take 1st 8 houses to be red, and the rest the 392 houses are randomly coloured. This will include the case that last 8 houses in a row are red. So, when you come to choose last 8 houses to be red, there will be an occasion when first 8 houses become red-coloured. Similarly there are so many ways that double counting is happening.) What should be done?","['combinations', 'combinatorics', 'probability']"
4247536,Property of a kite inscribed in a square,"A friend of mine presented the following problem to me: Say you have a square $ABCD$ and a kite $BCEF$ (a kite is a quadrilateral object such that $\overline{BC}$ and $\overline{BF}$ have the same size, $\overline{CE}$ and $\overline{EF}$ have the same size and $\overline{BE}$ and $\overline{CF}$ are perpendicular), much like in the picture bellow (also, sorry for the picture, I cannot figure out how to make such image in the latex editor of the site). If you prolong the segments $\overline{BE}$ and $\overline{AD}$ , they should meet in some point $H$ . Likewise, the prolongation of $\overline{BF}$ meet with $\overline{AD}$ in $G$ . The problem: Show that $a + b = c$ . I cannot enphasize how mad I am at this problem. I know that the triangles $DEH$ , $BCE$ and $BEF$ are equivalent, and I've spent some time walking in circles, nothing really that useful. If someone could point out what I am not seeing, I would be deeply grateful.","['euclidean-geometry', 'triangles', 'geometry']"
4247566,Integral of the shark function,"Messing around with functions is my hobby, I am asking this for fun, and maybe as a little challenge. I gave this style of function the name ""Shark function"" because it looks like the shark's dorsal fin. The function is of the form: $$ f(x) = \frac{1}{\left(\sum_{i=0}^{n} x^i\right)^2 + 1}$$ And I wanted to ask if there is a formula for the integral: $$ \lim_{n \to \infty} \int_{-\infty}^{\infty} f(x) \text{dx}$$ from first impression, it looks like it should be more than $1$ , because the picture is way more than a $1 \times 1$ square. Any ideas? :)","['integration', 'calculus', 'summation']"
4247588,"Caculate $\iint_D \frac{x^2+y^2}{\sqrt{4-(x^2+y^2)^2}}dxdy$, with D:$\frac{x^2}{2}+y^2\leq1$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I found some difficulty with this exercise: Calculate $$\iint_D \frac{x^2+y^2}{\sqrt{4-(x^2+y^2)^2}}dxdy$$ with $D := \left\{(x,y)\in\mathbb{R}^{2}\mid \dfrac{x^2}{2}+y^2\leq1\right\}$ I use change of Variables in Polar Coordinates, but the integral become so hard to calculate. I think maybe we change variables $u = x^2 + y^2$ , the integral will be easier, but I can't find $v(x,y$ ) to have the Jacobi easy to calculate.","['multivariable-calculus', 'multiple-integral']"
4247616,Which first-order theories have models uniquely determined by their automorphism groups?,"Which first-order theories have models uniquely determined (up to isomorphism) by their automorphism groups? For the purposes of this question, I'm assuming that a model cannot be empty. I will nonstandardly call a ring that is not necessarily commutative an ordinary ring . I was wondering the other day whether models of Peano Arithmetic are uniquely determined by their automorphisms. The standard model of arithmetic has no nontrivial automorphisms (because zero and all of its successors are fixed), but the other models have nonstandard elements that seem less nailed down at first glance. It turns out that this is not true by the argument in this answer and there are many nonstandard models of arithmetic with no nontrivial automorphisms. Then I thought about theories where models are uniquely determined (up to isomorphism) by their automorphism group and came up with the empty theory $T = \varnothing$ . A model of the empty theory is essentially just a set, and two sets are isomorphic iff they have the same cardinality. Their automorphism groups are the symmetric groups, which are also isomorphic iff they have the same cardinality. Groups are not uniquely determined by their automorphism groups, by the argument in this answer . Ordinary rings are not uniquely determined by their automorphism groups. By the argument in this answer there is a non-commutative ring with a trivial automorphism group. The ordinary ring $\{0, 1\}$ also has a trivial automorphism group.","['automorphism-group', 'group-theory', 'first-order-logic', 'model-theory']"
4247698,Coin Flipping Riddle,"2 criminals A and B, were recently captured and brought to prison. They were then locked in two separate rooms. Known for being exceedingly smart, the prison warden set a test for them. They flip a fair coin an infinite number of times and told outcomes of odd trials to A and even trials to B. Now A and B are separately told to pick a trial whose outcome they don't know, i.e., A is supposed to pick an even number, and B is supposed to pick an odd number. If the outcomes of the trials A and B picked are the same, the prison warden will release them. If they are different, they will spend life in jail. The Warden told them what they were going to do and let them agree upon a common strategy in advance but after that they can't communicate. Find a strategy such that the chance of winning is higher than $0.5$ . I recently tried this problem in university and I am interested to see other people's solutions, and perhaps the optimal solution. Edit: My strategy is that both players agree that as soon as they see 2 tails in a row for themselves, they pick the number in the middle, i.e. A sees a tail on coin flip 2 and 4 so he picks 3, B does the same. After running this on a computer simulation I get a 60% winrate. Although I don't fully understand why. Edit: a 70% chance of winning has been found on my Puzzling StackExchange duplicate post! Strategies so Far 70% chance of winning by @Jaap Scherphuis 2/3 probability of winning by @Mike Earnest 62.5% chance of winning by @Teo Miklethun","['puzzle', 'probability']"
4247722,Is it possible to compute $\int_{0}^{\infty} \frac{1}{x^a + 1} dx$ without the residue theorem or Euler's reflection formula.,"I've been trying to find a way to compute the integral $$\int_{0}^{\infty}\frac{1}{x^a + 1} dx, \quad a > 1$$ without having to resort to the heavy machinery of complex analysis. I've found two methods to compute this integral but they both use complex. One way is just to use contour integration on the slice of pie with angle $2\pi/a$ and apply the residue theorem, the other method uses u-substitution to turn this integral into the beta function $$\frac{1}{a}B\left(1/a,1-1/a\right) = \frac{1}{a}\Gamma(1/a)\Gamma(1-1/a)$$ and from here you can use Euler's reflection formula to get the solution. Is there any way to analyze this integral without referencing either the residue theorem or Euler's reflection formula?","['integration', 'complex-analysis', 'real-analysis']"
4247749,Show that there exists a finite disjoint collection $\{E_k\}_{k=1}^M$ of boxes such that $\bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k$.,"Let $\{R_i\}_{i=1}^N$ be finite collection of $n-$ dimensional boxes formed by the cartesian products of intervals of $\Bbb R$ . Show that there exists a finite disjoint collection $\{E_k\}_{k=1}^M$ of boxes such that $\bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k$ . I’ve been stuck with this for a good while now. From wikipedia the definition for $\bigsqcup_{k=1}^M E_k $ seems to be that $\bigsqcup_{k=1}^M E_k = \bigcup_{k=1}^M \{(x,k) : x \in E_k \}$ , which I don’t really understand. I tought that I could approach this by elementary set theory just by looking at the elements of either set individually, but I didn’t get anywhere. If I pick $R_i \in \bigcup_{i}^N R_i $ , then $R_i = I_1 \times I_2 \times \cdots$ , but I don’t see how I can show that this $R_i \in \bigsqcup_{k=1}^M E_k $ ?","['elementary-set-theory', 'real-analysis']"
4247797,Do the canonical commutation relations determine the position and momentum operator?,"Consider the position and momentum operator on $L^2(\mathbb{R})$ defined on a dense domain, say $D(X) = D(P)=\mathscr{S}(\mathbb{R})$ with the position operator being defined as $$
X\phi=x\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
$$ and the momentum operator is defined by $$
P\phi=-i \frac{d}{dx}\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
$$ Then we have the canonical commutation relations $$
[X,P]\phi=i\phi \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
\tag{1}$$ For any unitary operator $U$ (for example the Fourier transform), it is easy to see that $U^{\dagger}PU$ and $U^{\dagger}XU$ satisfy the same commutation relations. Question: If $2$ self-adjoint, densely defined linear operators satisfy (1), are they unitarily equivalent to the position and momentum operator? In other words: Do the canonical commutation relations already determine position and momentum operator up to unitary equvialence? I am asking this question out of curiousity, since it stuck in my head for quite some time. I have thought about (formally) taking operator exponentials, since $\exp(-iX)\phi=e^{ix}\phi(x)$ and $\exp(iaP)\phi=\phi(x+a)$ and then use the Stone-von Neumann theorem for the Heisenberg group, however, the issue with the domain remains and also taking operators exponential is non-trivial for this reason. Feel free to modify my domain to e.g. $D(\cdot)=W^{1,2}(\mathbb{R}),C_c^{\infty}(\mathbb{R}),..$ or whatever you see fit. I am somewhat familiar with the basic spectral theory for unbounded operators and I have already encountered the concept of a rigged Hilbert space, so feel free to use them without elaborating every detail.","['hilbert-spaces', 'functional-analysis', 'mathematical-physics']"
4247810,"Suppose $G$ is a group of order $pqr$ with $p<q<r$ and $q\nmid r-1$ for primes $p,q,r$. Prove that there is only one subgroup of order $q$.","Suppose $G$ is a group of order $pqr$ where $p,q,r$ are prime numbers such that $p<q<r$ . If $q\nmid r-1$ prove that there is only one subgroup of order $q$ . By the Sylow theorems we know that the number of Sylow $q$ -subgroups of $G$ is in the form of $qk+1$ and has to be one of $\{1,p,r,pr\}$ but since $p<q$ and $q\nmid r-1$ it can only be $1$ or $pr$ . How do I show that $pr$ is not possible?","['group-theory', 'abstract-algebra', 'sylow-theory']"
4247832,Urn with $4$ Different Colored Balls that is Drawn $4$ Times with Replacement,"There is an urn that contains $1$ Green ball, $1$ Red ball, $1$ White ball, and $1$ Yellow ball. The urn is drawn 4 times with replacement. So I am trying to calculate: the probability of the the 4 draws yielding exactly 2 pairs of colors (e.g. GGRR) and the probability of the 4 draws yielding 1 single pair of color and 2 single / different colors (e.g. GGRW) For the 2 pairs, my thinking is such that ${4\choose2}$ represents the numbers of ways a paired color combo can be drawn / arranged ${4\choose1}$ is for the 1st color of the paired color combo ${3\choose1}$ is for the 2nd color of the paired color combo ${16\choose4}$ is for the total number of possible slots (_ _ _ _, each _ being a possible of 4 colors) $$\frac{{4\choose2}{4\choose1}{3\choose1}}{16\choose4}$$ I am not sure if this is right, but I think I am at least somewhat on the right track For the 1 pair + 2 singles, in all honesty, I am bit lost about how to begin. I am not sure whether I should use the nCk formula or go by counting and then adjust for slot placement. Thank you in advance","['statistics', 'combinatorics', 'probability']"
4247874,Using mappings and bijections for a simple looking probability problem.,"I came across this simple problem today: Show that the probability of rolling a $14$ is the same whether we use $3$ or $5$ fair dice. It is very easy (but tedious)  to solve with basic probability but I wanted to use something a bit more flash (and hopefully cleaner) Before begging on this puzzle I would like to show you a similar looking puzzle with the method I would like to use to attack the first one. Warm up problem: $A$ rolls three $6$ sided dice and $B$ rolls one $20$ sided die. Show that the probability $A's$ rolls sum greater than $B$ 's roll is equal to the probability $B$ rolls greater than $A$ . We will construct a bijective mapping, $\phi: \mathbb{N}^3 \times \mathbb{N} \to  \mathbb{N}^3 \times \mathbb{N}$ , between winning combinations for $A$ , denoted the set $W_A$ into winning combinations for $B$ , $W_B,$ and thus show the finite sets have the same size. Let $X_1 = \{a_1, a_2, a_3 \} \times\{b_1 \} \in W_A$ denote the rolls that occurred in $A$ winning. In other words: $a_1+a_2+a_3 > b_1$ . Now consider turning over all four dice, (applying $\phi$ )  we now see $ \phi(X_1) = \{7-a_1, 7 -a_2, 7-a_3 \} \times \{ 21-b_1\}  \in W_B$ as $7-a_1 + 7-a_2 + 7 -a_3 = 21 - (a_1+a_2+a_3) < 21 - b_1$ And so there is a one-to-one mapping from $W_A \to W_B$ and $W_B \to W_A$ and so they have equal size and we are done. My problem I cannot help but wonder that there is a very similar method for my puzzle above. Denoting $S_n \subset \mathbb{N}^n$ as combinations of $n$ rolls that sum to $14$ ,I envision it as follows: Let $\{x_1,x_2,x_3 \} \in S_3$ be a combination of rolls that sum to $14$ . We need to show there are $36$ as many rolls in $S_5$ i.e for any $\{x_1,x_2,x_3 \}$ and any $2$ rolls of a dice we can construct a unique element of $S_5$ . I initially had it like this: $\phi: \mathbb{N}^3 \times \mathbb{N}^2 \to \mathbb{N}^5$ by ""absorbing the final two rolls into earlier states"" as required: Consider $S_3 \ni \{6,5,3 \}$ $\times \{2,3 \} \to \{6,2,1,2,3 \}$ as we pushed right to left by taking $2$ from $3$ to give $1$ and then $3$ from $5$ to give $2$ This fails to work however as it is not injective nor subjective. Consider $\{x_1,x_2,x_3\} \times \{6,5\}$ . $\phi$ will always take it to $\{1,1,1,6,5 \}$ . Also $\{6,6\}$ will never be a suitable input for the $\mathbb{N}^2$ part. Can someone think of a nice way to do this?","['functions', 'probability']"
4247888,$A=B$ if $A\cos(\omega_1t+\phi_1)=B\cos(\omega_2t+\phi_2)$ for every $t∈ℝ_{≥0}$,"I'm having a lot of trouble about an apparently simple task. I have the following trigonometric equation: $A\cos(\omega_1t+\phi_1)=B\cos(\omega_2t+\phi_2)$ which holds for every $t \in [0,+\infty)$ , where $\omega_1,\omega_2,\phi_1,\phi_2 \in \mathbb{R}$ are fixed, with $\omega_1 \neq 0$ and $\omega_2 \neq 0$ . With $A$ and $B$ positive, I need to show that $A=B$ , but I'm really stuck. I tried to find a value of $t$ such that $\omega_1t+\phi_1=\pi$ and so on, but after a lot of calculation I can't conclude anything. Any help or hint would be really appreciated!","['algebra-precalculus', 'functions', 'trigonometry']"
4247950,What are the algebraic features and the geometric interpretation of the symmetric algebra?,"The exterior algebra is a quotient of the tensor algebra that gives an anti symmetric product. The symmetric algebra is similar except that the product is symmetric. The objects in both algebras are not tensors. I know that the exterior algebra consists of oriented plane segments, but what are the algebraic features and the geometric interpretation of the symmetric algebra?","['algebraic-geometry', 'vector-bundles', 'abstract-algebra', 'symmetric-algebra']"
4247996,Approximating step functions with polynomials,"Let $t_1 < t_2 < \cdots <t_m$ be real, and $X = \cup_{i=1}^{m-1} (t_i, t_{i+1})$ be a union of real open intervals.  Let $f:X \rightarrow \{-1, 1\}$ be any piecewise constant function of form $$
f(x) = 
    \begin{cases} 
      a_1 & \text{ if } t_1 < x < t_2 \\
      a_2 & \text{ if }t_2 < x < t_3 \\
      \vdots \\
a_{m-2} & \text{ if } t_{m-2} < x < t_{m-1} \\ 
      a_{m-1} & \text{ if } t_{m-1} < x < t_m 
   \end{cases}
$$ Where $a_i \in \{-1, 1\}$ , and $a_{i} = -a_{i+1}$ for $i = 1, ..., m-1$ . I have a number of questions regarding polynomial approximations of such a function $f$ : Can we always find a sequence of polynomials $(p_n)$ so that $(p_n)$ converge pointwise to $f$ , AND we have some fixed (not arbitrary) global error bound, say $1$ , such that $|p_n(x) - f(x)| \leq 1$ for all $x \in X$ and $n \in \mathbb{N}$ ? If so, are such polynomials easy to find? How quickly do we get convergence? I am aware that, upon picking a suitable inner product, we can use any collection of orthonormal polynomials to make approximations of functions.  For example I know the Chebyshev, Bernstein, Jacobi etc. polynomials can be used to approximate continuous functions on bounded intervals, but I have found no theorem that says we can use these to construct approximations for arbitrary piecewise constant functions like the one given above. Indeed, it is easy to find a polynomial approximation for the Heaviside Step function for example, however it is unclear how, or if this an be done for more complicated step functions.","['approximation', 'numerical-methods', 'polynomials', 'real-analysis']"
4248000,"Integrate $\int^{\pi}_{0}\left\{\frac{\tan^2\left(\frac{x}{2}\right)}{\sin^2(x)\cdot\,\cos^2(x)}\right\}^{\frac{1}{9}}\,dx$","$\displaystyle\int^{\pi}_{0}\left\{\dfrac{\tan^2\left(\dfrac{x}{2}\right)}{\sin^2(x)\cdot\,\cos^2(x)}\right\}^{\frac{1}{9}}\,dx$ $\sf{\color{blue}{My\,\,approach\,}:}$ $=\displaystyle\int^{\pi}_{0}\left\{\dfrac{\tan^2\left(\dfrac{x}{2}\right)}{\dfrac{4\,\tan^2(\frac{x}{2})}{\sec^4(\frac{x}{2})}\cdot\,\dfrac{(1-\tan^2(\frac{x}{2}))^2}{\sec^4(\frac{x}{2})}}\right\}^{\frac{1}{9}}\,dx$ $=\displaystyle\int^{\pi}_{0}\left\{\dfrac{\sec^8\left(\dfrac{x}{2}\right)}{4\cdot\,\left(1-\tan^2\left(\dfrac{x}{2}\right)\right)^2}\right\}^{\frac{1}{9}}\,dx$ $=\displaystyle\int^{\pi}_{0}\dfrac{\sec^{\frac{8}{9}}\left(\dfrac{x}{2}\right)}{2^{\frac{2}{9}}\cdot\,\left(1-\tan^2\left(\dfrac{x}{2}\right)\right)^{\frac{2}{9}}}\,dx$ $=\displaystyle\int^{\pi}_{0}\dfrac{\sec^{\frac{-10}{9}}\left(\dfrac{x}{2}\right)\cdot\dfrac{1}{2}\sec^2\left(\dfrac{x}{2}\right)dx}{2^{\frac{-7}{9}}\cdot\,\left(1-\tan^2\left(\dfrac{x}{2}\right)\right)^{\frac{2}{9}}}$ If I substitute $\color{orange}{\tan\left(\dfrac{x}{2}\right)=t,}$ a weird expression occurs..
Help me to figure out this","['integration', 'calculus', 'definite-integrals', 'trigonometry']"
4248014,$5y''+6y'=x^2+5x +3$ What is the $ y_p$ here? How to derive $y_p$?,"$5y''+6y'=x^2+5x +3$ What is the $ y_p$ here? So I tried the usual. when the right hand side is polynomial degree of 2, my $ y_p = Ax^2 + Bx + C$ . I then differentiate once and twice and sub them back in. But this time it doesn't work. I think it is because the left hand side is missing a constant term. So for example in general, $ay'' + by'= \sum _{i=0}^n\:\beta _i\:x^i$ Can someone help out? I don't want the answer. I just want to know how do you get the functional form of $y_p$ ? How do you derive it? Can someone prove it (ie what y_p) is  or link a proof to me? Also, how do you mathematically express ""some polynomial""?",['ordinary-differential-equations']
4248074,Doubt on Interpreting Conditional Probability,"I have a doubt about interpreting this question. I will post the question and my attempt. I get two different answers. ""A box contains $3$ red balls, $4$ blue balls, and $5$ white balls. Three balls are drawn at random from the box, one by one, without replacement. Find the probability that the second red ball appears on the third draw."" Hence we have $3$ red and $9$ non-red balls. If I interpret it as an unconditional probability problem, we obtain $$P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3) 
\\~\\ = P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3)
\\~\\  = \frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10} = \frac{9}{110} $$ where $R_i$ is the event of drawing a red and $R_i'$ is the event of not drawing a red on the $i$ 'th draw. If I interpret it as a conditional probability problem I get $$ P\left(R_3 ~\mid~  \left( R_1~R_2' ~\cup~ R_1'~R_2  \right) \right)
\\~\\
= \frac{P(R_3~ \cap ~\left( R_1~R_2' ~\cup~ R_1'~R_2  \right) ) }{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)} 
\\~\\ = \frac{P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3)}{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)} 
\\~\\ = \frac{P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3)}{P(R_1 ~R_2')  + P(R_1' ~R_2) }  
\\~\\ = \frac{\frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10}}{\frac{3}{12}\cdot \frac{9}{11}+  \frac{9}{12}\cdot \frac{3}{11} } = \frac{1}{5}
$$","['conditional-probability', 'probability']"
4248158,How to prove that $\cos n \phi - \cos n \theta = 2^{n-1}\prod_{k=0}^{n-1}\left(\cos \phi - \cos\left(\theta - \frac{2k\pi}{n}\right)\right)$,"Prove that $$\cos n \phi - \cos n \theta = 2^{n-1}\prod_{k=0}^{n-1}\left(\cos \phi - \cos\left(\theta - \frac{2k\pi}{n}\right)\right)$$ where $n \in \mathbb{Z^+} $ and $k \in \{0, 1, \dots ,n - 1\}$ My first instinct is to multiply both sides by $2$ to make $2^{n-1}$ on RHS to be $2^n$ and distribute it inside the product. However, I can't simplify it further after reaching $2(\cos n\phi - \cos n\theta) = \prod_{k=0}^{n-1} 4\sin\frac{\phi-\theta-\frac{2k\pi}{n}} {2}\sin\frac{\phi+\theta+\frac{2k\pi}{n}}{2}$ . I think that De Moivre's theorem would be useful here. However, I don't see how I could use that in the first place. How should I solve this question? Thanks in advance.","['trigonometry', 'complex-numbers', 'products']"
4248182,Least squares in polynomial space?,"Problem. Use linear algebra to find $f(x) \in \mathcal{P}_2(\mathbb{R}) = \{ f \in \mathbb{R}[x] \mid \text{deg}(f) \leq 2\}$ such that $f'(0) = 0$ and $f(x)$ minimizes $$\int_0^1 (2x - f(x))^2 dx.$$ This problem came up on my qualifying exam, and I would like to understand it. It looks suspiciously like a least squares problem, wherein we attempt to minimize $\| b - Ax \|$ for some overdetermined system of equations $A$ . Driving my suspicion is the fact that I recognize that the integral is the $L^2$ norm. So $2x$ could be serving the role of $b$ , and $f(x)$ would be serving the role of $Ax$ . One more fact I think I have gathered is that the condition $f'(0) = 0$ means that $f(x)$ will be of the form $f(x) = ax^2 + 0x + b$ . If this is a least squares problem, then I think the solution is found by simply solving $A^* b = 0$ , though I will need to do more research to be sure. So if all of the above is correct, then I am struggling to understand what $A$ and $x$ are in this problem. In particular, how does $f(x) = ax^2 + b$ represent an overdetermined system of equations $A$ multiplied by some vector $x$ ?","['least-squares', 'linear-algebra', 'functional-analysis']"
4248226,Relation problem,"Let $A = \{1,2,3,4\}$ and let $f: \mathcal{P}(A)\to\mathbb{N}$ be the function defined by saying that $f(X)$ is the sum of elements of $X$ , for each $X\in \mathcal{P}(A)$ . (If $X = \emptyset$ , then by convention we say that $f(X)=0$ ). Define the relation $\sim$ on $\mathcal{P}(A)$ as follows: $X\sim Y$ if and only if $f(X) > f(Y)$ or $X = Y$ . Write down whether $\sim$ is reflexive, symmetric, antisymmetric, transitive. The part where I am struggling is to prove reflexivity. Reflexive: $a\sim a$ for all $a$ . So that means $f(X) > f(Y)$ is false, since $f(X) > f(X)$ is false. But $X = Y$ part is true since, $X = X$ for all $X \in\mathcal P(A)$ .","['relations', 'solution-verification', 'discrete-mathematics']"
4248289,Almost surely infinite random variable,"I have three random variables, $X, Y$ and $Z$ that are related as follows. $$X = Y + Z$$ $X \sim Z$ whereas $Y$ and $Z$ are independent and $Y$ is std normal. $X\geq 0$ a.s. I want to show that $X = \infty$ a.s. (equivalent to saying $Z = \infty$ obviously). Intuitively, if adding a normal r.v. to another r.v. does not change its distribution, then that r.v. cannot be finite with positive probability. But I want to make this formal. From the above relations I can deduce that the characteristic function of $X$ is zero everywhere maybe except at zero. I don’t see where to go from here. I tried the inversion formula as well.","['characteristic-functions', 'probability-theory']"
4248304,Why is $\cos(-x)$ always $\cos(x)$?,"While converting angles in trigonometric function I was taught (or I understood) the following We take coordinate axes and a ray which has it’s pivot at the origin. Like so So considering an angle, we rotate the ray in the anti clockwise direction. And we see if the particular trigonometric function is positive or negative in the quadrant that we get after rotation. This decides the sign of the trigonometric function that we are converting it into. My question is, if we don’t know if $x$ is an acute angle or not, we shouldn’t be able to say where the rotating ray will end up in. It could be in the fourth quadrant for an angle of $-30°$ , or in the third quadrant for an angle of $-120°$ . $\cos$ is positive in 4th quadrant and negative in the third. So it should be $\cos 30°$ in the first case and $-\cos(120°)$ in the second. But still $\cos(-x)=\cos x$ seems to be universal since $\cos$ is an even function. Why is it so?",['trigonometry']
4248325,A set with volume zero can be covered by finitely many open boxes,"A set $X\subseteq\mathbb{R}^n$ is said to have $n$ -dimensional volume zero iff for any $\epsilon>0$ , there exist finitely many closed $n$ -boxes $R_1,\cdots,R_s$ such that $X\subseteq \bigcup_i R_i$ and $\sum_{i} \text{vol}(R_i)<\epsilon$ . Given a set $X$ with volume zero, I would like to show that for any $\epsilon>0$ , there exists such a cover where each point in $X$ is an interior point of the cover and its volume is less than $\epsilon$ . In other words, is it possible to cover $X$ with open boxes instead (with total volume less than $\epsilon$ )? I encountered this problem in the proof of Proposition 7.1.8 in Multivariable Mathematics: Linear Algebra, Multivariable Calculus, and Manifolds by T. Shifrin. The proposition asserts that if the set $X$ of discontinuities of a bounded function $f:R\to\mathbb{R}$ has volume zero, then $f$ is integrable on $R$ . In the proof, $X$ is covered in the manner mentioned in the previous paragraph so that the closure of the complement of the covered portion does not contain any discontinuity point. However, the author did not provide a proof for why such a cover exists. This is intuitive to me, but I struggle to produce a rigorous proof.","['multivariable-calculus', 'general-topology', 'riemann-integration']"
4248361,Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$. Then find $f(x)$,Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$ . Then find $f(x)$ Teacher's Method: He differentiated the whole function with respect to $x$ as follow $f^{\prime}(x)+f^{\prime}(y) \cdot \frac{dy}{dx}=f^{\prime}(\frac {x+y}{1-xy}) \cdot \biggl(\frac{\big(1-xy\big)\big(1+\frac{dy}{dx}\big)+\big(x+y\big)\big(x\frac{dy}{dx}+y\big)}{\big(1-xy\bigl)^2}\biggl)$ And he put $\frac{dy}{dx}=0$ stating that $x$ and $y$ are independent and finally he obtained the result $f(x)=5\tan^{-1}(x)$ My Doubt: why $x$ and $y$ are independent? finally we are obtaining the result $y=5\tan^{-1}(x)$ $\;$ then how can they be independent? My second Doubt: why above method is not working for $f(x+y)=f(x)+f(y)$ I know what is the other method to solve this Question but my doubt is as mentioned above.,"['integration', 'inverse-function', 'calculus', 'partial-derivative', 'derivatives']"
4248366,"Grassmannian $\hbox{Gr}(2,\mathbb{C}^5)$ is homeomorphic to $\hbox{Gr}(3,\mathbb{C}^5)$","How to show that $\hbox{Gr}(2,\mathbb{C}^5)$ is homeomorphic to $\hbox{Gr}(3,\mathbb{C}^5)$ by showing that they are given by the same Plücker relations? I'm trying to understand Grassmannian and Plücker relationship and I'm having trouble grasping the basic idea.","['grassmannian', 'homogeneous-spaces', 'algebraic-geometry', 'representation-theory']"
4248381,Question in Simplicity of $A_5$ using Conjugacy classes argument,"There is a proof on wikipedia : https://groupprops.subwiki.org/wiki/A5_is_simple I was searching of proofs that $A_5$ is simple using conjugacy classes argument as I have recently read the chapter on sylow theorems and simple groups which have theory on conjugacy classes. But I am unable to follow the proof given in the link: Why the conjugacy classes size is only $1,12, 20, 15$ . I think as $\mbox{cl}(a)$ divides $|G|$ , where $\mbox{cl}(a)$ is conjugacy class of $a$ on $G$ . It can be $1,2,3,4,5,6,10,12,15,20,30,60$ . Am I wrong ? ""A normal subgroup must contain the conjugacy class of size $1$ , and one or more other conjugacy classes"" Is the statement written just above due to following reason?:  If $N$ is a normal subgroup and let $n\in \mathbb N$ be any of it's elementa then $gng^{-1}$ ( $g \in  G$ ) lies in $N$ but it is not necessarily $n$ itself (One of the elements it is true when $g = e$ (identity)). ""Thus, the order of any normal subgroup must be a sum of some of these numbers, including the $1$ . By Lagrange's theorem, the order must also divide the order of the group."" I understand the statement written just above. ""But no such sum among these numbers divides $60$ , other than $1$ and $60$ themselves."" I don't understand it this line. Can you please help with the questions in above proof ?","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
4248462,How to integrate $\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx$,"I've been stuck on trying to integrate $\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx$ I initially thought this could be solved in similar fashion to solving $\int^{\infty}_{-\infty} e^{-x^{2}}e^{ix}dx$ where we define $F(t) = \int^{\infty}_{-\infty} e^{-x^{2}}e^{itx}dx$ and recognize is at as a Fourier transform of $f(x)=e^{-x^{2}}$ and then use the properties of the Fourier transform, namely that $\frac{d}{dt}(\mathcal{F}f)(t) = \mathcal{F}(ixf)(t)$ , to show that $F$ satisfies the differential equation $F'(t)=\frac{t}{2}F(t)$ . See here for more details. So I tried to adjust this by defining a transform as $\mathcal{F}_{c}f(t)=\int^{\infty}_{-\infty} f(x)e^{itx^{3}}dx$ and I saw that I actually get a similar property that $\frac{d}{dt}(\mathcal{F}_{c}f)(t) = \mathcal{F}(3ix^{2}f)(t)$ but I got stuck trying to apply this property in similar fashion to see what $F'(t)$ (in this case $F(t)$ is defined with the new transform instead of Fourier transform) was but ended up with the integral $$\int^{\infty}_{-\infty} (3ix^{2})e^{-x^{2}}e^{ix^{3}t}$$ and am stuck from here.... Anyways, I was looking for either help with my approach or another way entirely to evaluate the integral. I would be very happy either way!","['complex-analysis', 'improper-integrals', 'fourier-analysis', 'analysis']"
