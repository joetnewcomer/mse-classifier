question_id,title,body,tags
2999964,"Looking for a terminology for ""sameness"" of functions","Consider the situation described in the following diagram, namely: $A$ , $A'$ , $B$ , and $B'$ are sets. $\alpha:A\rightarrow A'$ and $\beta:B\rightarrow B'$ are bijections. $f:A\rightarrow B$ and $\ f':A'\rightarrow B'$ . The following equations are satisfied. $$
f = \beta^{-1} \circ f' \circ \alpha\\
f' = \beta\circ f \circ \alpha^{-1}
$$ In a sense $f$ and $f'$ are the same function, in that each can be computed in terms of the other, with no information being lost or gained. Is there an accepted terminology for this sameness of $f$ and $f'$ ?","['functions', 'category-theory', 'terminology']"
2999970,Concentration inequality applied for robust estimation of the mean,"Problem: (Page 19 in ""Vershynin, Roman (2018). High-Dimensional Probability. Cambridge University Press. ISBN 9781108415194."") Suppose we want to estimate the mean µ of a random variable $X$ from a
  sample $X_1 , \dots , X_N$ drawn independently from the distribution
  of $X$ . We want an $\varepsilon$ -accurate estimate, i.e. one that
  falls in the interval $(\mu − \varepsilon, \mu + \varepsilon)$ . Show that a sample of size $N = O( \log (\delta^{−1} )\, \sigma^2 / \varepsilon^2 )$ is sufficient to compute an $\varepsilon$ -accurate
  estimate with probability at least $1 −\delta$ . Hint: Use the median of $O(log(\delta^{−1}))$ weak estimates. It is easy to use Chebyshev's inequality to find a weak estimate of $N = O(  \sigma^2 / (\delta \varepsilon^2) )$ . However, I do not how to find inequality about their median. The wikipedia of median ( https://en.wikipedia.org/wiki/Median#The_sample_median ) says sample median asymptotically normal but this does not give a bound for specific $N$ . Any suggestion is welcome.","['statistics', 'median', 'probability']"
2999998,Am I the only one constantly forgetting the Eisenstein criterion? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question Do you guys have tricks to remember the Eisenstein criterion? I constantly forget it and I am looking for some logic in it to never forget it again.","['mnemonic', 'abstract-algebra', 'intuition']"
3000001,Regular polygons with common side,"Given a segment $AB$ in the plane, draw all possible regular polygons having $AB$ as a side. Is it true that if a line contains infinitely many vertices of those polygons, then   that line contains either $A$ , or $B$ , or the midpoint of $AB$ ?",['geometry']
3000024,Can area of rectangle be greater than the square of its diagonal?,"Q: A wall, rectangular in shape, has a perimeter of 72 m. If the length of its diagonal is 18 m, what is the area of the wall ? The answer given to me is area of 486 m 2 . This is the explanation given to me Is it possible to have a rectangle of diagonal 18 m and area greater than the area of a square of side 18 m ?","['area', 'geometry']"
3000083,Why does this vector field approach zero near the north pole?,"In this question, Raziel's answer builds a vector field over $S^2$ . The vector field is built from the push forward of the stereographic projection on $N$ . Let $p \in S^2 \setminus \{N\}$ , and let's say that $X_p = U_p \partial_u + V_p \partial_v$ . I understant that as $p$ approaches the north pole, by the change of coordinates given in the other post, it can be seen that $X_p$ approaches zero (and thus can be extended at $N$ with zero). However, I don't understand it at an intuitive level. (I want to understand why this happens.) If we fix $f \in C^{\infty}(S^2)$ , should I understand that $X_p f$ approaches zero as $p \to N$ because you are deriving $f$ respect to a larger vector, or is that nonsense? I think that expressing $X_p$ in function of $\partial_x$ and $\partial_y$ would help me, but I'm not sure how to compute that.","['manifolds', 'spheres', 'vector-fields', 'differential-geometry']"
3000110,Finding the roots of a characteristic polynomial,"Main aim is to find the lowest order equation with the solution: $$y(x)= 2 \cosh(x) + 3 e^{-2x} \sin(x)$$ Now, I am trying to find the roots to form the characteristic polynomial from which I get the lowest order equation. However, am stuck with the second expression as the first can be easily expressed as $e^x - e^{-x}$ so I deduce $\lambda_{1}=1,\lambda_{1} = -1   $ but the other expression I am not quite sure whether it is $-2\pm i  $ or something else as there is an exponential and a trigonometric function at the same time ? Any advice greatly appreciated!","['reduction-of-order-ode', 'ordinary-differential-equations']"
3000260,Simple proof that an operator is compact,"Let $\phi$ be a compactly supported smooth function on $\mathbb{R}$ . I'm looking for a simple proof that the operator $$\left(-\frac{d^2}{dx^2}+x^2\right)^{-1}\phi$$ (where $x$ denotes multiplication by $x$ ) is a compact operator $H^1(\mathbb{R})\rightarrow L^2(\mathbb{R})$ . Added after: Is it true that $\left(-\frac{d^2}{dx^2}+x^2\right)^{-1}$ is a bounded operator $L^2(\mathbb{R})\rightarrow H^1(\mathbb{R})$ ? How to prove this? Remark: I believe one can show this by some clever means, like using a special basis for $L^2(\mathbb{R})$ defined using Hermite polynomials, but I'm looking for something more down-to-earth, coming straight out of functional analysis.","['operator-theory', 'functional-analysis', 'analysis']"
3000316,How many connected components could the intersection of $\{A \in M_n(\mathbb R): \rho(A) < 1\}$ and an affine subspace in $M_n(\mathbb R)$ have?,"Let $\mathcal E = \{A \in M_n(\mathbb R): \rho(A) < 1\}$ where $\rho(\cdot)$ is the spectral radius and $\mathcal U$ be an affine space in $M_n(\mathbb R)$ . If we assume $\mathcal E \cap \mathcal U \neq \emptyset$ , how many connected components could the intersection have? In proving $\mathcal E$ is connected, I know we can use a path $(1-t)A + t 0$ but if $B$ is in the intersection, $(1-t)B$ could not be guaranteed in the intersection.","['path-connected', 'operator-theory', 'linear-algebra', 'functional-analysis', 'general-topology']"
3000326,"Are Jordan ""Formable"" matrices closed under multiplication?","After learning about Jordan Canonical Form, I began thinking about if you have two matrices $A, B \in M_n(\mathbb{R}),$ whether or not their product $AB$ will also have a Jordan Canonical Form. Trivially, if we consider polynomials in $ M_n(\mathbb{C})$ then our polynomial will always have roots in the field. So, from what I understand, this is equivalent to asking whether or not the characteristic polynomial of $AB$ will have real roots. I began playing around with the $2 \times 2$ case and if we have that $AB$ has a negative determinant then we can't have that the eigenvalues of $AB$ are in $\mathbb{C},$ since they must multiply to the determinant, but since the complex eigenvalues always come in a conjugate pair, that would mean that their product is always positive. I am not sure how I can break down the case if the determinant is positive. Finally, my own intuition says matrices which have Jordan form will be closed under multiplication. This is because if we think about what matrices with strictly, real eigenvalues do, they simply reflect and stretch space. So I don't believe it is possible to find two matrices whose product matrix will be a rotation in the plane. Also, I couldn't find this question asked elsewhere, but if it has an answer, I'd be happy to read it.","['abstract-algebra', 'linear-algebra']"
3000327,Separation of variables for nonhomogeneous PDE,"I need to solve the equation below using separation of variables. $$\frac{\partial f(x,y)}{\partial x} - \frac{\partial f(x,y)}{\partial y} = 2$$ The thing is, i've always done with $0$ after the equal sign. I'm really stuck with that $2$ ; when doing the separation I get $X'Y-XY'=2$ and can't separate X and Y after that.","['ordinary-differential-equations', 'partial-differential-equations']"
3000336,Help calculating $\lim_{x \to \infty} \left( \sqrt{x + \sqrt{x}} - \sqrt{x - \sqrt{x}} \right)$,I need some help calculating this limit: $$\lim_{x \to \infty} \left( \sqrt{x + \sqrt{x}} - \sqrt{x - \sqrt{x}} \right)$$ I know it's equal to 1 but I have no idea how to get there. Can anyone give me a tip? I can't use l'Hopital. Thanks a lot.,"['limits', 'radicals', 'limits-without-lhopital']"
3000378,Does Fermat's Last Theorem imply the modularity theorem?,"The Wikipedia article on the proof of Fermat's Last Theorem has this sentence If the link identified by Frey could be proven, then in turn, it would mean that a proof or disproof of either of Fermat's Last Theorem or the Taniyama–Shimura–Weil conjecture would simultaneously prove or disprove the other. This suggests FLT and the modularity theorem are equivalent. While the fact that the modularity theorem implies FLT was a rather important part of Wiles' proof, I wasn't aware the reverse implication was true. Is it?","['number-theory', 'elliptic-curves']"
3000416,"holomorphic functions, roots of unity and harmonic numbers","If $f$ is a non-constant holomorphic function such that, for all $z \in \mathbb{C}$ , exists a $c \in \mathbb{C}$ where $f(cz) = f(z),$ then $c$ must be a $n$ -th root of unity, or there exists some counterexample? Furthermore, there exists $f$ holomorphic function and $n \in \mathbb{N}$ such that $$f(z\mathcal{H}(n)) = f(z), \forall z \in \mathbb{C}?$$ In this case, $\mathcal{H}(n)$ denotes the $n$ -th harmonic number: $$
\mathcal{H}(n) = \sum\limits_{k = 1}^n \frac{1}{k}
$$","['complex-analysis', 'holomorphic-functions', 'roots-of-unity', 'harmonic-numbers']"
3000437,$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!} = \frac{1}{2}$ - basic methods,"Prove that $$\lim\limits_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!} = \frac{1}{2}$$ This problem appeared on MSE many times, but each time it was solved using Poisson distribution or lots of integrals. I am wondering, is there any way to prove it using some basic properties of limits (their arithmetics, squeeze theorem etc.), definition of $e^x$ as $\lim\limits_{n\to\infty}(1+\frac{x}{n})^n$ , basic limits with $e$ , binomial expansion and logarithms, but without using integrals, series, Stirling formula, asymptotics, Taylor series? This problem was given to me by my mathematical analysis teacher, but it's not a homework, just additional problem to think on. My teacher claims it can be solved with knowledge introduced on lectures so far, which is not much, mainly things mentioned above. Of course, I can use theorems not mentioned on the lectures, but then I have to prove them, and again, with the baisc knowledge. I've been thinking about it for a few days and couldn't do any major progress in my attempts.","['limits', 'calculus', 'real-analysis']"
3000438,"Evaluate $\lim \limits_{n \to \infty\ } \Biggl( \frac{2,7}{(1+\frac{1}{n})^n}\Biggr)^n=0?$","$\lim \limits_{n \to \infty\ } \Biggl( \frac{2,7}{(1+\frac{1}{n})^n}\Biggr)^n$ I would like to replace $(1+\frac{1}{n})^n$ by $e$ , and then $\frac{2,7}{e}<1$ , so $\lim \limits_{n \to \infty\ } \Biggl( \frac{2,7}{(1+\frac{1}{n})^n}\Biggr)^n=0$ , and I will get correct result, but I think this replacement is inadmissible. I'm looking for the easiest way ( without advanced tools)","['limits', 'limits-without-lhopital', 'real-analysis']"
3000468,"$f(x) = 1 - |1 - 2x|$, $a_{n+1} = f(a_n)$, prove convergence of subsequences","Let $f(x) = 1 - |1 - 2x|$ , $a_1 = a$ , $a_{n+1} = f(a_n)$ . Prove there exists $a \in [0, 1]$ such that for every $x \in [0, 1]$ there exists a subsequence of $a_n$ convergent to $x$ . I've tried to analyze the graph of this function, but couldn't spot anything useful.","['limits', 'calculus', 'real-analysis']"
3000534,Asymptotic behaviour of the sequence of the number of groups of order $n$,"Let $f(n) = \text{# of groups of order} \ n$ . I want to study the asymptotic behaviour of this sequence as $n \to \infty$ . Clearly $\lim \inf f(n) = 1$ and $\lim \sup f(n) = \infty$ , so the sequence is jumping around. I'm wondering if there exists a ""nice"" function $g$ such that $$0<\limsup_{n \to +\infty} \frac{f(n)}{g(n)}<+\infty$$",['group-theory']
3000603,Let $f:\mathbb{I} \to \mathbb{R}$ continuous function such that $f(0)=f(1)$.,"$\mathbb{I} = [0,1]$ Let $f:\mathbb{I} \to \mathbb{R}$ continuous function such that $f(0)=f(1)$ . Prove that for all $n \in \mathbb{N} $ there $ x \in \mathbb{I}$ such that $ x + \frac{1}{n} \in \mathbb{I}$ and $f( x + \frac{1}{n})=f(x)$ Could you help me by giving me an idea of ​​how to do it?","['continuity', 'general-topology', 'functions', 'real-analysis']"
3000710,Real Grassmann manifold and orthonormal groups,"I'm trying to prove that the Grassmann manifold $$G_k(\mathbb{R}^n) = \{E = {\rm {\it k} - dimensional\ subspace\ of\ } \mathbb{R}^n\}$$ is equivalent to: $$G_k(\mathbb{R}^n) = \frac{O(n)}{O(k)\times O(n - k)}  \tag1$$ Where $O(n)$ is the orthonormal group of $n\times n$ matrices. From my research I've seen that Eq. (1) is due to the idea of splitting the original $n$ -dimensional subspace into a $k$ -dimensional one and its orthonormal complement of $n - k$ dimension; but I don't get how this Grassmann manifold, which is made of vectors ( $(k\times 1)$ -dimensional matrices - column vectors), is related to $n\times n$ matrices since the quotient in Eq. (1) is the following set, as usual: $$\frac{O(n)}{O(k)\times O(n - k)} = \{M_n\cdot (O(k)\times O(n - k))\ |\ M_n \in O(n)\}    \tag2$$ Can anyone explain me this relation and the prove of Eq. (1)? Thanks in advace! ;)","['grassmannian', 'quotient-spaces', 'group-theory', 'lie-groups', 'differential-geometry']"
3000733,Solving $\int_{0}^{\infty} \frac{\sin(x)}{x^3}dx$,"In my attempt to solve the this improper integral, I employed a well known improper integral (part of the Borwein family of integrals): $$ \int_{0}^{\infty} \frac{\sin\left(\frac{x}{1}\right)\sin\left(\frac{x}{3}\right)\sin\left(\frac{x}{5}\right)}{\left(\frac{x}{1}\right)\left(\frac{x}{3}\right)\left(\frac{x}{5}\right)} \: dx = \frac{\pi}{2}$$ To begin with, I made a simple rearrangement $$ \int_{0}^{\infty} \frac{\sin\left(\frac{x}{1}\right)\sin\left(\frac{x}{3}\right)\sin\left(\frac{x}{5}\right)}{x^3} \: dx = \frac{\pi}{30}$$ From here I used the Sine/Cosine Identities $$ \int_{0}^{\infty} \frac{\frac{1}{4}\left(-\sin\left(\frac{7}{15}x\right)+ \sin\left(\frac{13}{15}x\right) + \sin\left(\frac{17}{15}x\right) -\sin\left(\frac{23}{15}x\right) \right)}{x^3} \: dx = \frac{\pi}{30}$$ Which when expanded becomes $$ -\int_{0}^{\infty} \frac{\sin\left(\frac{7}{15}x\right)}{x^3}\:dx + \int_{0}^{\infty} \frac{\sin\left(\frac{13}{15}x\right)}{x^3}\:dx +
\int_{0}^{\infty} \frac{\sin\left(\frac{17}{15}x\right)}{x^3}\:dx -
\int_{0}^{\infty} \frac{\sin\left(\frac{23}{15}x\right)}{x^3}\:dx
= \frac{2\pi}{15}$$ Using the property $$\int_{0}^{\infty}\frac{\sin(ax)}{x^3}\:dx = a^2 \int_{0}^{\infty}\frac{\sin(x)}{x^3}\:dx$$ We can reduce our expression to $$\left[ -\left(\frac{7}{15}\right)^2 + \left(\frac{13}{15}\right)^2 + \left(\frac{17}{15}\right)^2 - \left(\frac{23}{15}\right)^2\right] \int_{0}^{\infty} \frac{\sin(x)}{x^3}\:dx = \frac{2\pi}{15}$$ Which simplifies to $$ -\frac{120}{15^2}\int_{0}^{\infty} \frac{\sin(x)}{x^3}\:dx = \frac{2\pi}{15}$$ And from which we arrive at $$\int_{0}^{\infty} \frac{\sin(x)}{x^3}\:dx = -\frac{\pi}{4}$$ Is this correct? I'm not sure but when I plug into Wolframalpha it keeps timing out...","['integration', 'improper-integrals']"
3000753,Subsemigroup of a finite semigroup,"Let $S$ be a finite semigroup and $T \subseteq S$ which satisfy the following property: For $x, y \in T$ , we have $x, y \in \langle z \rangle$ for some $z \in S$ . If $H \subseteq S$ satisfy the above property and $T \subseteq H$ , then $H = T$ . Is $T$ forms a subsemigroup of $S$ . I have tried to find out the counter example of a semigroup $S$ and a subset $T$ of $S$ which satisfies these two properties but it does not form a subsemigroup of $S$ . But I am unable to find this. After that, I have tried to prove $T$ forms a subsemigroup. It is sufficient to prove for any $a, b, c \in T$ , there exist $d \in S$ such that $ab, c \in  \langle d \rangle.$ From the given hhypothesis, there exist $x, y, z \in S$ such that $a,b \in \langle x \rangle$ , $a, c  \in \langle y \rangle$ , $b,c \in \langle z \rangle$ . I am stuck here. Thanks for your any kind of help.","['group-theory', 'abstract-algebra', 'semigroups']"
3000819,Turning a Biased Coin into an Unbiased one Deterministically,"Non-deterministic Exact Algorithm There is a simple algorithm to turn a biased coin into a fair one: Flip the coin twice. Identify HT with H and TH with T. Discard cases HH and TT. This algorithm produces a perfectly fair coin, but it is non-deterministic. Deterministic Approximation I also know it is possible to approximate a fair coin with a deterministic algorithm: Let $C_0$ be the biased coin and define $C_1$ by flipping $C_0$ twice. $C_1$ is H if $C_0$ was HH or TT, and $C_1$ is T if $C_0$ was HT or TH. We can see that if the probability that $C_0$ was heads is $p$ , then the probability that $C_1$ is heads is $p_1 = 1 - 2p(1 - p)$ . This is a parabola connecting $(0,1), (.5,.5)$ , and $(1,1)$ and we can see that if we assume $0<p<1$ then the function has a fixed point at $0.5$ . Since $0.5 < p_1 < p$ if $p>0.5$ and $0.5<p_1<1$ if $p<0.5$ , then we can see that a fixed point iteration with $0<p<1$ will always converge to $0.5$ . Therefore, we can find a deterministic $C_i$ that is arbitrarily fair (defined by flipping $C_{i-1}$ twice). My Problem I am trying to find out if, given some biased coin with rational probability of heads $p$ , we can construct an algorithm to solve this problem that is both deterministic and exact. Does anyone have any insights? (Note that the algorithm only has to work for a fixed probability $p$ , since as pointed out in the comments and answer, there are some $p$ , e.g., $p = 1/3$ for which there is no such algorithm.)","['combinatorics', 'probability', 'algorithms']"
3000828,The definition of Affine Invariant Riemannian Metric (AIRM),"For any two symmetric positive definite (SPD) matrices $A$ and $B$ , the Affine Invariant Riemannian Metric (AIRM) between them is defined as [1], [2]: $d(A,B)=||\log (A^{-1/2}B A^{-1/2}) ||_F$ , where $\log(A)$ is the matrix logrithm of $A$ , and $||A||_F$ is the Frobenius norm of $A$ . On the other hand, it is also shown that (e.g., see [3]) $d(A,B)=||\log (A^{-1/2}B A^{-1/2}) ||_F = ||\log (A^{-1}B) ||_F$ . However, when I used Matlab function logm , I found that $||\log (A^{-1/2}B A^{-1/2}) ||_F \ne ||\log (A^{-1}B) ||_F$ at all (but their eigenvalues are the same). I was wondering if there is anything wrong with my understanding the definition of AIRM? Thanks very much! [1] R. Bhatia, Positive Definite Matrices. Princeton University Press, 2009. [2] X. Pennec, P. Fillard, and N. Ayache, “A Riemannian framework for tensor computing,” International Journal of Computer Vision, vol. 66, no. 1, pp. 41–66, 2006. [3] M. Moakher, “A differential geometric approach to the geometric mean of symmetric Positive-Definite matrices,” SIAM J. Matrix Anal. Appl., vol. 26, no. 3, pp. 735–747, 2005. [4] I. Horev, F. Yger, and M. Sugiyama, “Geometry-aware principal component analysis for symmetric positive definite matrices,” Machine Learning, 2017.","['matrices', 'riemannian-geometry']"
3000830,Attempt at sequence proof $\frac{n+3}{n^2 -3}$ converges to $0$,"Prove convergence of the following sequence: $$\frac{n+3}{n^2 -3} \rightarrow 0$$ Proof discussion: Notice that since whenever $n>3$ ,  we have $n^2 -3 >0$ , we also know that $n+3 >0$ , so $\frac{n+3}{n^2 -3}>0$ . This means we can drop the absolute value signs in: $$  \left|\frac{n+3}{n^2 -3}-0\right|=\frac{n+3}{n^2 -3} $$ We now notice that for $n>3$ also $n^2 -9>0$ and $n^2 -3 > n^2 -9$ so $\frac{1}{n^2 -3}< \frac{1}{n^2 -9}$ we can thus write: $$\frac{n+3}{n^2 -3}<\frac{n+3}{n^2 -9}=\frac{(n+3)}{(n+3)(n-3)}=\frac{1}{n-3} $$ To be able to complete this proof we want that $\frac{1}{n-3}<\epsilon$ , we write $n-3>\frac{1}{\epsilon}$ or $n> \frac{1}{\epsilon} +3$ . If we pick $n_0 =\lceil\frac{1}{\epsilon} +3\rceil$ , it will also be automatically larger than $3$ . We can now write our proof: Proof: For all $\epsilon>0$ , we let $n_0=\lceil{\frac{1}{\epsilon}+3 }\rceil$ then for all $n>n_0$ , we know that: $$|a_n-0|=\left|\frac{n+3}{n^2-3} \right|<\frac{n+3}{n^2-9}=\frac{1}{n-3}< \frac{1}{\frac{1}{\epsilon}+3-3}=\epsilon$$ And hence our sequence converges to $0$ $\square$ . Is my proof okay?","['epsilon-delta', 'proof-verification', 'sequences-and-series', 'real-analysis']"
3000861,Open sets and intersections,"Suppose $G$ is an open subset of the real number that is not upper bounded. Is there a real number $x > 0$ such that the set of all integer multiples of $x$ intersects $G$ at infinitely many points? That is, is it true that $\exists x \in \mathbb{R}$ such that $\{mx\mid m\in \mathbb{Z}\}\bigcap G$ is infinite? My intuition tells me yes, since the fact that $G$ is not upper bounded seems to be a major factor here, but I can’t seem to prove it.",['real-analysis']
3000878,Does $a_{n}/a_{n-1}$ converge to the golden ratio for all Fibonacci-like sequences?,"Yesterday a friend challenged me to prove that $$\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\varphi\; ,$$ where $\varphi$ is the golden ratio, for the Fibonacci series. I started rewriting the limit as $$\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\lim_{n\rightarrow\infty}\frac{a_{n-1}+a_{n-2}}{a_{n-1}}=\lim_{n\rightarrow\infty}1+\frac{a_{n-2}}{a_{n-1}}\; .$$ If the sequence $b_n=\frac{a_n}{a_{n-1}}$ is convergent , $$\lim_{n\rightarrow\infty}\frac{a_{n-2}}{a_{n-1}}=\left(\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}\right)^{-1}\; .$$ Renaming the desired limit $x$ , we obtain the quadratic equation $$x=1+\frac{1}{x}$$ $$x^2-x-1=0$$ if $x\neq 0$ . Therefore, if $b_n$ is convergent, it must be equal to $\frac{1+\sqrt{5}}{2}$ or $\frac{1-\sqrt{5}}{2}$ . Since $a_n>0$ , $b_n>0, \forall n$ , so the limit must be equal to $\varphi=\frac{1+\sqrt{5}}{2}$ . This proof made me think that I didn't make use of the initial values of the sequence, so it must hold true for any sequence where $a_{n}=a_{n-1}+a_{n-2}$ . The first question is, is $a_{n}/a_{n-1}$ convergent for all Fibonacci-like sequences? The second and most intriguing for me is, is there any Fibonacci-like sequence where the limit is $\frac{1-\sqrt{5}}{2}$ ? Since this solution is negative, $a_n$ should change its sing with each $n$ , but I couldn't find any values for $a_0$ and $a_1$ , which would lead me to this case. If the answer to this question is no, what mathematical sense does this negative solution have?","['golden-ratio', 'limits', 'fibonacci-numbers', 'proof-explanation']"
3000971,Find measure of angle $x$,"Can you help me about the title? I don't know what's appropriate for a geometry problem! In the following figure find measure of angle $x$ . I wrote sin law two times. One in ABC like $$\frac{8+BD}{\sin 120}=\frac{4}{\sin x}$$ and one in ABD like this $$\frac{BD}{\sin 30}=\frac{4}{\sin (\angle{BDA})}$$ Now if you eliminate $BD$ and use $\angle{BDA}=90+x$ , a trigonometric equation comes out. Solving gives $x=20$ degrees. I feel that there is a neat way around of doing this. Can you help?",['geometry']
3001005,Proof of a technical fact in the book of Schapire and Freund on boosting,"I am currently looking at Exercise 10.3, Chapter 10 of the book on Boosting by Schapire and Freund. More precisely, in the middle of the exercise they propose to use, without proof, the technical fact summarized below. Obviously, since it can be used without proof, I am now curious to know how to prove it! To summarize the problem, let $\mathcal{H}$ bet a set of functions $h : \mathcal{X} \times \mathcal{\bar{Y}} \rightarrow [-1,1]$ . Define $\text{co}(\mathcal{H})$ as \begin{align*}
\text{co}(\mathcal{H}) = \left\lbrace f : x,\bar{y} \mapsto \sum_{t=1}^T a_t h_t(x,\bar{y}) \left| a_1,\ldots,a_T \geq 0; \sum_{t=1}^Ta_t = 1; h_1,\ldots h_T \in \mathcal{H}; T\geq 1 \right.  \right\rbrace\text{.}
\end{align*} Notice that $f : \mathcal{X} \times \mathcal{\bar{Y}} \rightarrow [-1,1]$ . For $f \in \text{co}\left(\mathcal{H}\right)$ , $\eta > 0$ , $\bar{K} = |\mathcal{\bar{Y}}|$ , and $(x,y) \in \mathcal{X} \times \mathcal{Y}$ , let \begin{align*}
\nu_{f,\eta}(x,y) = - \frac{1}{\eta} \ln\left(\frac{1}{\bar{K}} \sum_{\bar{y} \in \mathcal{\bar{Y}}} \exp\Big(-\eta \Omega(y,\bar{y}) f(x,\bar{y})\Big)\right)
\end{align*} where $\Omega(y,\bar{y}) = 1$ if $\bar{y} \in \Omega(y)$ and $-1$ otherwise. $\Omega(y)$ associates each element from $\mathcal{Y}$ to a subset of $\mathcal{\bar{Y}}$ . Notice that $\nu_{f,\eta} : \mathcal{X} \times \mathcal{Y} \rightarrow [-1,1]$ . The technical fact is as follows. Let $1 \geq \theta > 0$ and define the grid: \begin{align*}
\varepsilon_\theta = \left\lbrace \frac{4\ln\bar{K}}{i\theta} : i = 1, \ldots, \left\lceil \frac{8\ln\bar{K}}{\theta^2} \right\rceil \right\rbrace\text{.}
\end{align*} For any $\eta > 0$ , let $\hat{\eta}$ be the closest value in $\varepsilon_\theta$ to $\eta$ . Then for all $f \in \text{co}(\mathcal{H})$ and for all $(x,y) \in \mathcal{X} \times \mathcal{Y}$ , \begin{align*}
\left| \nu_{f,\eta}(x,y) - \nu_{f,\hat{\eta}}(x,y) \right| \leq \frac{\theta}{4}\text{.}
\end{align*} So far, I proved the statement when $\eta > \frac{4\ln\bar{K}}{\theta}$ (using the properties of the LogSumExp function). Furthermore, using the grid, I showed that \begin{align*}
&& \left| \eta - \hat{\eta} \right| \leq \frac{\ln \bar{K}}{\theta} \\
&\Rightarrow& \left| \eta\nu_{f,\eta}(x,y) - \hat{\eta}\nu_{f,\hat{\eta}}(x,y) \right| \leq \frac{\ln \bar{K}}{\theta}\text{.}
\end{align*} However, I did not manage to go further than that. Am I going in the right direction? If yes, what would be the trick for the last step? If no, what method should I consider to prove this statement? Note that I am not asking for a full proof, but rather some hints on how to proceed to show the result.","['statistics', 'inequality', 'real-analysis']"
3001032,Prove the comparability theorem for well ordered sets using transfinite induction,"My question is about the same proof discussed here , but I am confused about more than this question addresses. In Naive Set Theory , Halmos phrases the comparability theorem as follows: The assertion is that if $\langle X, \leqslant_X \rangle$ and $\langle Y, \leqslant_Y \rangle$ are well ordered sets, then either $X$ and $Y$ are similar, or one of them is similar to an initial segment of the other. My questions are about the following proof: We assume that $X$ and $Y$ are non-empty well ordered sets such that neither is similar to an initial segment of the other; we proceed to prove that under these circumstances $X$ must be similar to $Y$ . Suppose that $a \in X$ and that $t$ is a sequence of type $a$ in $Y$ ; in other words $t$ is a function from $s(a)$ into $Y$ . Let $f(t)$ be the least of the proper upper bounds of the range of $t$ in $Y$ , if there are any; in the contrary case, let $f(t)$ be the least element of $Y$ . In the terminology of the transfinite recursion theorem, the function $f$ thereby determined is a sequence function of type $X$ in $Y$ . Let $U$ be the function that the transfinite recursion theorem associates with this situation. An easy argument (by transfinite induction) shows that, for each $a \in X$ , the function $U$ maps the initial segment determined by $a$ in $X$ one-to-one onto the initial segment determined by $U(a)$ in $Y$ . This implies $U$ is a similarity, and the proof is complete. Where the statement of the transfinite recursion theorem is: If $W$ is a well ordered set, and if $f$ is a sequence function of type $W$ in a set $X$ , then there exists a unique function $U$ from $W$ into $X$ such that $U(a) = f(U|_{s(a)})$ for each $a$ in $W$ . and $s(a)$ is the initial segment of $a$ . I don't understand how to complete the proof given this outline. My questions are: How do I show that, for each $a \in X$ , the function $U$ maps the initial segment determined by $a$ in $X$ one-to-one onto the initial segment determined by $U(a)$ in $Y$ I can figure out how to set up the beginning of the transfinite induction proof (I think), but can't prove the induction step: Let $S$ be the set of all $a \in X$ such that $U$ maps the initial segment determined by $a$ in $X$ one-to-one onto the initial segment determined by $U(a)$ in $Y$ . Assume by the hypothesis of transfinite induction that the initial segment $s(a) \subseteq S$ . How do I show that $a \in S$ ? Finally, given (1), Why is U 1-1? Why is U onto? Why is it the case that $\forall a, b \in X, a \leqslant_X b \iff U(a) \leqslant_Y U(b)$ ? I'm really not sure where to even start with these last three. I can write down the definitions of 1-1 and onto and stare at them, and stare at their contrapositives, but I can't figure out how to make progress.","['elementary-set-theory', 'proof-explanation', 'well-orders']"
3001057,What manifold is produced if all similar triangles in the plane are identified?,"Consider Euclidean space $\mathbb{R}^6$ , we can consider this as the $x$ and $y$ coordinates of the $3$ points of a triangle in $\mathbb{R}^2$ . If we identify all points in $\mathbb{R}^6$ whose triangles have the same 3 angles, what manifold do we get under the quotient topology?","['general-topology', 'algebraic-topology']"
3001059,Construction of surfaces with Kodaira dimension 1,"I am trying to find examples of surfaces with Kodaira dimension 1, but find it difficult to get. Can somebody help me come up with examples? Thanks.","['algebraic-geometry', 'minimal-surfaces']"
3001070,Behavior of $\sum_{n=1}^\infty \frac{1}{n} z^{n!}$ on the unit circle [duplicate],"This question already has answers here : Series with radius of convergence 1 that diverges on roots of unity, converges elsewhere on the circle. (2 answers) Closed 5 years ago . I'm trying to understand the behavior of $\sum_{n=1}^\infty \frac{1}{n} z^{n!}$ on the unit circle. Since for each $m$ th root of unity $\zeta_m$ $$\sum_{n=1}^\infty \frac{1}{n} \zeta_m^{n!} = C + \sum_{n=m}^\infty \frac{1}{n} = \infty$$ holds for some $C \in \mathbb{C}$ , the series diverges for all $e^{\varphi \pi i}$ with $\varphi \in \mathbb{Q}$ . But what happens for $\varphi \in \mathbb{R} \setminus \mathbb{Q}$ ? Does the series diverge everywhere, or are there points where it is convergent?","['complex-analysis', 'calculus']"
3001103,How to find the number of ways to seat $n$ married couples around a table if men and women alternate,"Its my first time posting here, so if I am doing something wrong please inform me. My question: Find the number of ways to seat $n$ married couples around a table if men and women alternate. I seen the solution where you seat $n$ men first and then the women.
but I don't get why my solution is incorrect: First we seat them in a row in the following way:
we put a man in the first seat ( $n$ ways), then a woman in the second ( $n$ ways) and so on and we get $n!\times n!$ . Now there are $2n$ people on the row, to turn it into a table sitting
we divide by $2n$ and we get $\dfrac{n!(n-1)!}{2}$ which is an incorrect answer. I would like to understand where I made a mistake The correct answer: $n!(n-1)!$ Edit: Just wanted to thank all of you! you really helped me there.
If anybody have anything to add/more approaches to solving the problem - please do, I will gladly read it.",['combinatorics']
3001120,Prime number between $\sqrt{n}-n^{1/3}$ and $\sqrt{n}$,"Can anyone give me a proof or a reference for a proof that there exists a prime number between $\sqrt{n}-n^{1/3}$ and $\sqrt{n}$ , for $n$ sufficiently large? I am reading a lecture where the professor uses this fact but does not provide any reference. Thank you!","['number-theory', 'prime-numbers']"
3001136,"$0<|\sqrt a-\sqrt[3]b|<\epsilon$ for $a,b\in\Bbb Z_+$","I'm trying to solve the following problem: Given $\epsilon>0$ , are there positive integers $a,b$ such that $0<|\sqrt a-\sqrt[3]b|<\epsilon$ ? My solution : given $n\in\Bbb N$ , $$|\sqrt{n^2}-\sqrt[3]{n^3+1}|=\sqrt[3]{n^3+1}-n=\frac1{\sqrt[3]{(n^3+1)^2}+n\sqrt[3]{n^3+1}+n^2}<\frac1{3n}\to 0$$ Thus, the answer is yes. But I was trying to find an ""optimal"" solution. That is, now the problem becomes Given $\epsilon>0$ , find the least $b\in \Bbb Z_+$ such that there exists $a\in\Bbb Z_+$ such that $0<|\sqrt a-\sqrt[3]b|<\epsilon$ and now I'm totally lost. Is there some theory about this? Perhaps has it to do with the diophantine equation $a^3-b^2=\pm1$ , and hence, to Catalan's conjecture? Remark : Please note the ' $0<$ ' in the inequality. I'm aware that $\sqrt 1=\sqrt[3]1$ .","['approximation', 'diophantine-approximation', 'number-theory', 'diophantine-equations', 'reference-request']"
3001160,Let $a_k\gt 0$ and $a_0\gt \sum_{k=1}^n a_k$ . Show that $\int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k$,Let $a_k\gt 0$ and $a_0\gt \sum_{k=1}^n a_k$ . Show that $$\int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k$$ I saw this question on the internet somewhere a few days back and thought to give it a try. The question looks so absurd due to the arbitrary inputs in the sines and their products. I tried giving it a shot using Laplace and Mellin transforms but realized they were turning to dead end. i also tried using a little complex analysis by writing sines in terms of $e$ but to no avail. One method which seemed quite promising was the Feynman's technique because one peculiar thing about RHS is that it is independent of $a_0$ and also a point to note is the constraint on $a_0$ ( It is greater than sum of other $a_k$ 's). Differentiating both sides w.r.t $a_0$ would give a $0$ on RHS while some integral on LHS which we need to prove is $0$ . But couldn't much continue with this thought. The place where I saw this question also had an answer but it used principle of induction which I pretty don't like much so it would be very much better if I could get methods without involving any type of induction. Thanks!!!!,"['integration', 'definite-integrals', 'improper-integrals', 'complex-analysis', 'calculus']"
3001172,Prove that $2005|\underbrace{55 \ldots5}_{800\text{ digits}}$,"Prove that $2005|\underbrace{55 \ldots 5}_{800\text{ digits}}$ I know that $2005=5\cdot 401$ since $55 \ldots 5$ is divisibility with $5$ i only need to prove that $55 \ldots 5$ is divisibility with 401. $55 \ldots 5=5(10^{799}+10^{798}+\cdots+10+1)$ , then I can find a remainder for example $10^3\equiv198 \pmod {401}$ for $10^5\equiv151 \pmod {401}$ , and put in sum and prove that sum $(10^{799}+10^{798}+\cdots+10+1)$ is divisibility with number $401$ but I it seem like bad idea, do you have something?","['divisibility', 'modular-arithmetic', 'discrete-mathematics']"
3001190,How to calculate this limit without L'Hopital rule?,"I want to evaluate the following limit without using the L'Hopital rule : $$ \lim\limits_{x\rightarrow 0^+}\frac{e^{x\ln(x)}-1}{x}$$ I know the answer is $-\infty$ .
I can demonstrate that graphically and by using the L'Hopital rule.
Any hint would be appreciated and thanks.","['limits', 'calculus', 'limits-without-lhopital']"
3001194,$Av=\lambda v \Rightarrow A^*v=\bar \lambda v$ (general case),"Suppose $V$ is a finite-dimensional complex inner product space and $v_1,v_2,...,v_3$ is an orthonormal basis of $V$ .
Define $A:V \to V$ by $Av_i=\lambda_i v_i$ for some $\lambda_i \in \mathbb{C}.$ Show that $A^*v_i=\bar \lambda v_i.$ My attempt: $(Av_i,v_i)=(\lambda_iv_i,v_i)=(v_i,\bar\lambda_i v_i)=(v_i,A^*v_i)$ $\Rightarrow(v_i,(A^*-\bar \lambda_i)v_i)=0 \Rightarrow (A^*-\bar \lambda_i)v_i \perp v_i $ How to show that $(A^*-\bar\lambda_i)v_i=0$ ?","['matrices', 'adjoint-operators', 'linear-algebra']"
3001204,Problem on Do Carmo's definition of manifold,"In the book Riemannian Geometry , Do Carmo gave his definition of manifold without metionning to the topology on the set M. However, the usual way to define manifold is always to supposing M is a topological space with some restrictions on the topology, such as $A_{2}$ or $T_{2}$ . Later, he made a remark on this. As he said, we can induce a natural topology on M using the differential structure. My question is that: What happened if the topology induced in this way may not be $T_{2}$ or $A_{2}$ ? Do Carmo metioned this problem but he didn't give an answer. I am in a mess now...Help, thanks in advance.","['manifolds', 'smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3001238,Locus problem on circle and parabola,"Circles are drawn through the vertex of a parabola $y^2 = 4ax$ to cut the parabola orthogonally at the other point. Find the locus of the centers of the circles. What I did: The tangent must surely be the diameter of the circle. Also, the line through the vertex perpendicular to the line joining the vertex to the point on parabola must intersect the circle at the other end of the diameter i.e. where the tangent meets the circle again. The center of the circle must be their midpoint So, I take a parametric point $P(at^2, 2at)$ on the parabola. The equation of the line perpendicular to $VP$ going through $V$ is $2y = -tx$ . It meets the tangent $ty = x + at^2$ at $G$ which is the other diametric end. The coordinates of $G$ are $\Large(\frac{-2at^2}{t^2+2}, \frac{at^3}{t^2+2})$ .Now the midpoint of $GP$ is the center $L$ which comes out to be, $$\large x = \frac{at^4}{2(t^2+2)}$$ $$\large y = \frac{3at^3+4at}{2(t^2+2)}$$ Now, I am not able to eliminate $t$ from these equations. How do I proceed? Note: This problem is from SL Loney Co-ordinate geometry which was first printed a 100 years ago. So, there surely must be a shorter solution.","['analytic-geometry', 'algebra-precalculus', 'conic-sections']"
3001258,A matrix involving distances of $n$ points in $\mathbb{R}^3$,"Let $x_1,\ldots ,x_n$ be $n$ distinct points in $\mathbb{R}^3$ . Consider the $n\times n$ real symmetric matrix $A$ defined by $A_{ij}:=|x_i-x_j|$ . I would like to show that $$Ker\,A\;\cap\,\{v\in\mathbb{R}^n\,:\, v_1+v_2 +\ldots +v_n=0\}=\{0\}$$ Thank you for any suggestions.","['matrices', 'linear-algebra']"
3001284,Prove that number $\underbrace{11 \ldots1}_{100} \underbrace{22 \ldots2}_{100}$ is product of two consecutive numbers,Prove that number $\underbrace{11 \ldots1}_{100}$$\underbrace{22 \ldots2}_{100}$ is product of  two consecutive numbers $\begin{align}\underbrace{11 \ldots1}_{100} \underbrace{22 \ldots2}_{100}&=10^{199}+10^{198}+\ldots+10^{100}+2(10^{99}+10^{98}+\ldots+10+1)\\&=(10^{100}+2)(10^{99}+10^{98}+\ldots+10+1)=(10^{100}+2)\frac{10^{100}-1}{10-1}\end{align}$ . Is this good path or not?,['discrete-mathematics']
3001335,Is complex residue related to the word residue?,"I know little formal math terminology and don't understand much of anything about complex analysis. Also, if this isn't a good starting point for complex integration feel free to say (I'm learning about it partly for Cauchy's residue theorem). My first and intuitive idea of residue has to do with remainder, subtraction, division, etc., But more generally something that's leftover, extra, or unused by an operation or something. Do these ideas tie together?",['complex-analysis']
3001341,Set-Builder notation for flattening a nested set,"Assume we have a set of sets $\textbf{P}=\{ \textbf{P}_j \}_{j=1}^{n}$ where $\textbf{P}_j=\{P_j^i \}_{i=1}^{m_j}$ for every $\textbf{P}_j \in \textbf{P}$ . Now, we want to build a set of $P_j^i$ for every $(i,j) \in j \times m_j$ for every $j\in n$ from $\textbf{P}$ . In plain words, we are flattening an unaligned nested set, or an unaligned matrix. Here is expression [1]: $$\{p\in\textbf{P}_j|\textbf{P}_j \in \textbf{P} \} $$ where the condition is actually on the member's domain. And another expression [2]: $$\bigcup_{j=1}^n \{ p|p \in \textbf{P}_j \}, where\ \textbf{P}_j \in \textbf{P}$$ Which expression makes more sense and why? Are there any other expressions for this case?",['elementary-set-theory']
3001368,Characteristic polynomial modulo 12,"Consider the vector space $V =\left\{a_0+a_1x+\cdots+a_{11}x^{11},\;a_i\in\mathbb{R}\right\}$ . Define a linear operator $A$ on $V$ by $A(x^i) = x^{i+4}$ where $i + 4$ is taken modulo $12$ . Find $(a)$ the minimal polynomial of $A$ and $(b)$ the characteristic polynomial of $A$ . My try: I coulnot find another way so I tried the brute force method. $\:$ I found the matrix representation of the operator is $$A=\begin{bmatrix} 0&0&0&0&0&0&0&0&1&0&0&0\\0&0&0&0&0&0&0&0&0&1&0&0\\0&0&0&0&0&0&0&0&0&0&1&0\\0&0&0&0&0&0&0&0&0&0&0&1\\1&0&0&0&0&0&0&0&0&0&0&0\\0&1&0&0&0&0&0&0&0&0&0&0\\0&0&1&0&0&0&0&0&0&0&0&0\\0&0&0&1&0&0&0&0&0&0&0&0\\0&0&0&0&1&0&0&0&0&0&0&0\\0&0&0&0&0&1&0&0&0&0&0&0\\0&0&0&0&0&0&1&0&0&0&0&0\\0&0&0&0&0&0&0&1&0&0&0&0\\\end{bmatrix}.$$ The characteristic polynomial I found to be $\lambda^{12}-4\lambda^9+6\lambda^6-4\lambda^3+1$ . $\:$ (It took me almost 40 minutes. $\:$ Is there another way to do this problem? Provide hints or suggestions please. $\rule{17cm}{1pt}$ Taking forward the answer provided by $\textbf{Servaes}$ ""The minimal polynomial of $A|_{U_i}$ is still $X^3−1$ ."" Taking $U_1=span\{x_1,x_5,x_9\}$ we see $A(x)=x^5,\:A^2(x)=x^9,\:A^3(x)=x\implies (A^3-I)=0$ and since it factors into linear irredeucible factors, we have the minimal polynomial of $A|_{U_i}$ is $X^3−1$ . Completing the proof: We show that characteristic polynomial of $A$ is the product of characteristic polynomials of $A|_{U_i}$ where $V=\oplus U_i$ . We have seen that minimal polynomial of $A|_{U_i}$ is $X^3−1$ which is precisely the characteristic polynomial. So let $p_i(\lambda)$ is characteristic polynomial corresponding to eigenvalue $\lambda_i$ and invariant subspace $U_i$ and $p(\lambda)$ is the characteristic polynomial of A. Then $\displaystyle p(\lambda_i)=0 \:\forall\;i  \implies p_i(\lambda)|p(\lambda) \:\forall\;i \implies p(\lambda)=\prod_ip_i(\lambda)$ . $\Big($$p(\lambda)$ is atleast $\displaystyle\prod_ip_i(\lambda)$ . If $\exists\lambda\neq\lambda_i \forall\: i$ such that $p(\lambda)=0$ then $V$ is not $\oplus U_i$ $\Big)$ $\rule{17cm}{1pt}$ Minimal polynomial : $X^3-1\qquad$ Characteristic polynomial : $(X^3-1)^4$ .","['matrices', 'minimal-polynomials', 'linear-algebra']"
3001469,Shift Operator and Invariant Subspace,"Let $V$ be the set of all infinite real sequences and let $S$ be the Shift Operator for the set of all infinite sequences $(a_n)_{n \in \mathbb N}$ such that $S((a_n)_{n \in \mathbb N})=(a_{n+1})_{n \in \mathbb N}$ . Define a Subspace $W$ of $V$ such that: $$W = \{(a_n)_{n \in \mathbb N} \in V:  a_{n+3} = 2a_{n+2} + a_{n+1} -2a_n\}$$ I need to show that $W$ is $S$ -Invariant, that is $S((a_n)_{n \in \mathbb N}) \in W$ , however, I am really not sure how to start with this question. I only understood that after the transformation, the first term of the sequence is removed and I will then need to show that the remaining sequence is still in $W$ . Intuitively $W$ seems to be $S$ -invariant but I am not sure on how to prove this. Any help and advice will be really appreciated!","['elementary-set-theory', 'linear-algebra', 'linear-transformations', 'sequences-and-series']"
3001485,How to evaluate the limit $\lim_{m\to\infty}m\left({(\sum_{n=1}^{m}\frac{1}{n^2})}^{\pi^2/6}-{(\pi^2/6)}^{\sum_{n=1}^{m}\frac{1}{n^2}}\right)$,"How to evaluate the following limit? $$
\lim_{m\to\infty}m\left[
\left(\sum_{n=1}^{m}\frac{1}{n^2}\right)^{\pi^2/6}-{(\pi^2/6)}^{\sum_{n=1}^{m}\frac{1}{n^2}}
\right]
$$ This limit is of the form $\infty \cdot 0$ . I generally solve such problem by taking the term that equals $0$ to the denominator and then using l'Hôpital rule. However, that won't work here.","['limits', 'calculus', 'sequences-and-series']"
3001543,Why integral curves cannot be tangent to each other?,"I am watching Lecture 1 of the differential equation course on MIT OpenCourseWare.
The teacher said, for $y'= f(x,y)$ , if $f(x,y)$ is continuous around a point $(x0,y0)$ , it would guarantee at least one solution, and if $\frac{\partial f(x,y)}{\partial {y}}$ is continuous, it would ensure uniqueness of the solution, i.e. there would be only one integral curve passing through $(x0,y0)$ , meaning two integral curves could not be tangent to each other at $(x0,y0)$ . Can anyone explain why there would be only one integral curve passing through $(x0,y0)$ , i.e. two integral curves could not be tangent to each other at $(x0,y0)$ , if $\frac{\partial f(x,y)}{\partial {y}}$ is continuous at $(x0,y0)$ ? 
If 2 integral curves are tangent to each other at $(x0,y0)$ , then they should have the same derivative at $(x0,y0)$ , which is equal to $f(x0,y0)$ , right? How would this make $\frac{\partial f(x,y)}{\partial {y}}$ discontinuous at $(x0,y0)$ ? Thanks!",['ordinary-differential-equations']
3001658,What Are the Irreducible Representations of the Rational Rotation C$^{*}$-algebra?,"Let $m$ and $n$ be integers, with $n>0$ and $\gcd(m,n)=1$ . Let $\theta=m/n$ and let $A_{\theta}$ be the rational rotation C $^{*}$ -algebra generated by two unitaries $u$ and $v$ , satisfying the relation $vu=e^{2\pi i \theta}uv$ . I am working on an exercise in Davidson's C $^{*}$ -algebra and my goal is to Find all irreducible representations of $A_{\theta}$ and show that they lie in $M_{n}(\mathbb{C})$ . I was able to show that $u^{n}$ and $v^{n}$ lie in the center of $A_{\theta}$ . Thus, if $\pi\colon A_{\theta}\to B(H)$ is an irreducible representation of $A_{\theta}$ , it must be that $\pi(u^{n})$ and $\pi(v^{n})$ are scalar multiples of the identity. Using this I can show that the set $S=\{\pi(u)^{j}\pi(v)^{k}:0\leq j,k\leq n-1\}$ linearly spans $\pi(A_{\theta})$ . Thus, $\dim(\pi)\leq n$ . But I don't know how to rule out the case that $\dim(\pi)< n$ or how to go about finding all of the irreps.","['c-star-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras']"
3001662,Packing densities in grid world,"Suppose there is a $25\times 50$ grid world with $1250$ grid cells. Suppose some of them are colored black (full) and some are white (empty). We are interested in quantifying the packing of this grid world. If there are $x$ black cells then the most naive measure of packing is $\frac{x}{1250}$ but this is not too informative because according to it the two packings shown below would be equivalent. But clearly, the first one is relatively more packed than the second one because the second one allows the filled cells to be more spread out. What are some good quantitative indicators to capture the packing of a grid world? Closed-form formula would be preferred if possible.","['discrete-geometry', 'packing-problem', 'discrete-mathematics', 'algorithms']"
3001668,Any hyperplanes is covered by non-Lefschetz pencils?,"Let $X\subset \mathbb P^n$ be a smooth hypersurface over base field $\mathbb C$ . A pencil of hyperplanes is just a projective line $(X_t)$ in $\mathbb P^{n*}$ . It is called a Lefschetz pencil if it satisfies the following: (I followed the definition in SGA) (i) The axis (intersection of $X_t$ 's) intersects with $X$ transversally. (ii) Almost all (enough for one) $X_t$ intersects with $X$ transversally. (iii) The non-transversal intersection in (ii) contains one node. And on SGA it also proves that almost all pencils are Lefschetz. Now I want to know how many are those non-Lefschetz pencils, more precisely: Does there exist some $X$ , on which all the non-Lefschetz pencils cover the $\mathbb P^{n*}$ ? i.e. for any hyperplane section $H$ , we can find non-Lefschetz pencil $(X_t)$ pass through it. I guess it does not exist, but have no idea how to prove it. Any hints or references would be helpful. Remark I should remove the condition (i) otherwise it is trivial.","['complex-geometry', 'algebraic-geometry', 'intersection-theory']"
3001673,"$\dfrac{\partial^2 f}{\partial x \partial y} = 0 \nRightarrow f(x,y) = g(x) + h(y)$","I am working through Ted Shifrin's book Multivariable Mathematics. There is an exercise problem that is meant to demonstrate that one can have $\dfrac{\partial^2 f}{\partial x \partial y} = 0$ but $ f(x,y) \neq  g(x) + h(y)$ . The question (3.6.11) is as follows: $$ \mathrm{Given} \; f(x, y) = \begin{cases} 0, \; x < 0\; \mathrm{or} \; y < 0 \\x^3, \; x \geq 0 \; \mathrm{and} \; y > 0 \end{cases} $$ Show that $f$ is $C^2$ Show that $\dfrac{\partial^2 f}{\partial x \partial y} = 0$ Show that $f(x,y)$ cannot be written as $g(x) + h(y)$ for appropriate functions $g, h$ . I see that the domain is the entire plane except the x-axis, that is $\mathbb{R}^2 -\{y=0\}$ .
The function is then 0 in all quadrants except the first, where it is $x^3$ . I could show 1. and 2. above, but I am puzzled by two things. Q1 What's wrong with writing $f(x,y) = g(x) + h(y)$ piecewise in each quadrant ? Q2. Will anything change if the domain allows the line $y=0$ also ? Q3. What is the takeaway from this problem ? I do not  understand that.","['partial-derivative', 'multivariable-calculus', 'derivatives', 'real-analysis']"
3001692,Why is the argument principle called the argument principle?,"The Argument principle:
If $f$ is meromorphic in an open connected set $\Omega$ , with zeros $a_j$ and poles $b_k$ then $$\frac{1}{2 \pi i}\int_{\gamma}\frac{f'(z)}{f(z)} dz = \sum_j n(\gamma , a_j) - \sum_k n(\gamma , b_k)$$ Where the sums include multiplicities and $\gamma$ is a cycle homologous to zero in $\Omega$ and does not pass through any of the poles and zeros. Here is am quite confused by the naming of the theorem. The proof does not seem to give me light on the naming either. Thank you for the insight!","['complex-analysis', 'self-learning', 'intuition']"
3001715,Find the number of non-negative integer solutions to linear systems,"For instance with two variables: $ax + by = c$ , where x and y are variables. I found these two threads [ 1 , 2 ], where the solution is equal to $\binom{n+p-1}{p-1}$ , where n is the desired sum and p is the number of variables, so for the case above it would be $\binom{c+2-1}{2-1}$ . This is then divided by the product of the numbers multiplying the variables, so in this case by $a*b$ . If the result is not an integer, it's rounded down. All in all: $\lfloor\frac{\binom{c+2-1}{2-1}}{ab}\rfloor$ . This works for many equations, but I have found one where it doesn't, and I have no idea why and how to solve it. The problematic equation is the following: $$54x+177y=81630.$$ Here the number of solutions should be 26, the solution above however gives 8. How do I get to 26?","['elementary-number-theory', 'linear-diophantine-equations', 'discrete-mathematics', 'diophantine-equations']"
3001802,Proof that two definitions of a point of inflection are equivalent,"I have seen that many online sources (including other math stack exchange questions) say that the following are equivalent definitions of a point of inflection: If $f$ is differentiable on $I$ we say that $f$ has a point of inflection at $a$ if $f'$ has an isolated local extremum at $a$ . We say that $f$ has a point of inflection at $a$ if $f$ changes concavity at $a$ . This definition is somewhat ambiguous to me, so I decided that it would mean that $\exists \delta>0$ such that $f$ is strictly convex on $[a-\delta,a]$ and strictly concave $[a,a+\delta]$ or $f$ is strictly concave on $[a-\delta,a]$ and strictly convex $[a,a+\delta]$ . I want to prove that these definitions are equivalent (I know that this might require clarifying definition 2. in a different way than I have). I was able to prove that 2. implies 1.
This is my proof: Suppose that $\exists \delta>0$ such that $f$ is strictly convex on $[a-\delta,a]$ and strictly concave $[a,a+\delta]$ .
Then $f'$ is strictly increasing on $[a-\delta,a]$ and $f'$ is strictly decreasing on $[a,a+\delta]$ , so $f'$ has an isolated local maximum at $a$ . The case when $f$ is strictly concave on $[a-\delta,a]$ and strictly convex $[a,a+\delta]$ is similar. Now I want to show that 1. implies 2. Suppose that $f'$ has a isolated relative extremum. Without loss of generality, suppose that $f'$ has a isolated relative minimum. I need to show that $f'$ is strictly increasing on $[a-\delta,a]$ and $f'$ is strictly decreasing on $[a,a+\delta]$ (which is equivalent to showing that $f$ is convex on $[a-\delta,a]$ and concave on $[a,a+\delta]$ ). I know that this is not true for a general function $g$ that if $g$ has an isolated extremum at $g$ , $g$ is strictly monotone on either side of $a$ . (for example, if the g has a jump discontinuity, which I know is not possible for $f'$ ). Why is true for $f'$ ?","['convex-analysis', 'derivatives', 'real-analysis']"
3001824,A differentiation/derivative/calculus problem,"The question is as follows: $$y=x^2/(x+1)$$ The normal to this curve at $x=1$ meets the $x$ -axis at point $M$ . The tangent to the curve at $x=-2$ meets the $y$ -axis at point $N$ . Find the area of triangle $MNO$ , where $O$ is the origin. PS- this is not a school h.w  so don't worry. And I  did try....for  a good 100  min...not even joking EDIT - The drawing is NOT EXACT, it is just to give an idea.","['calculus', 'derivatives']"
3001902,Finite dimensional irreducible representations of a semisimple Lie Algebra separate points of the universal enveloping algebra.,"Let $\mathfrak{g}$ be a semisimple Lie Algebra, and $U(\mathfrak g)$ the universal enveloping algebra . We know that for every representation $\rho: \mathfrak g \to \mathfrak{gl}(V)$ , there exists a representation $\tilde{\rho} : U(\mathfrak g) \to \mathfrak{gl}(V)$ , such that $\rho = \tilde{\rho} \circ \iota$ , where $\iota: \mathfrak g \to U(\mathfrak g)$ is the natural inclusion. Besides that, using the standard notations, $\tilde{\rho}(X_1 \cdot \ldots\cdot X_n) = \rho(X_1) \ldots \rho(X_n).$ I'm very stuck in this problem Question: Show that the finite dimensional irreducible representations of a semisimple Lie Algebra $\mathfrak g$ separate points of the universal algebra $U(\mathfrak g)$ , i.e; if $a \in U(\mathfrak g)$ satisfies $\tilde{\rho}(a) =0$ , for every irreducible  representation $\rho: \mathfrak g \to \mathfrak{gl}(V)$ , then $a=0$ . Can anyone help me?","['semisimple-lie-algebras', 'abstract-algebra', 'lie-algebras']"
3001959,"Draw bipartite graph with degree sequence (5,5,5,5,4,4,4,4,4,4,4,4,4,4)?","I was wondering that since (5,5,5,5,4,4,4,4,4,4,4,4,4,4) can be split into a first set (5,5,4,4,4,4,4) and 2nd set (5,5,4,4,4,4,4). It satisfies the condition that the degrees of the first set = degrees of 2nd set, but i still cant draw a bipartite graph with this. So my general question is that if a graph is bipartite then the sum of degrees in one vertex set = sum of degrees in the other vertex set. But the reverse is not true ? If the reverse is not true, is there a method to know if you can construct a bi partite graph from the degree sequence without actually trying to draw it out ?","['graph-theory', 'bipartite-graphs', 'discrete-mathematics']"
3002022,linear combination of two coprime polynomials such that the roots are disctinct?,"Let $a = (a_0, \dots, a_{n-1})^T \in \mathbb R^n$ and $b = (b_0, \dots, b_{n-1})^T \in \mathbb R^n$ . We define two polynomials by \begin{align*}
f_a(x) &= x^n + a_{n-1} x^{n-1} + \cdots + a_0 \\
f_b(x) &= b_{n-1} x^{n-1} + \cdots +b_0.
\end{align*} Suppose we require $f_a$ and $f_b$ are coprime in $\mathbb C$ . Can we find a scalar $s \in \mathbb R$ such that $f_a(x) + s f_b(x)$ has distinct roots in $\mathbb C$ ? If $f_a(x) + s f_b(x) = x^n + (a_{n-1} + s b_{n-1})x^{n-1} + \cdots + (a_0 + sb_0)$ has multiple roots for all $s \in \mathbb R$ , this would imply the discriminant which is a polynomial in $s$ would be identically $0$ for $s \in \mathbb R$ . I don't think this can happen but could not figure out how to argue this part. To not cause confusion, this sentence is crossed out. This should be a separate question. The coprime condition just conveniently comes out of my situation. I am not sure this is necessary. Intuitively, I would think $b \neq 0$ should enough.","['abstract-algebra', 'linear-algebra', 'polynomials']"
3002031,"Let $f,g : X\to X$ be real continuous functions such that $f(X)\cap g(X) = \emptyset$ and $f(X)\cup g(X) = X$. Which sets cannot be equal to $X$?","Let $X \subset \mathbb{R}$ and let $f,g : X\rightarrow X$ be continuous functions such that $f(X)\cap g(X) = \emptyset$ and $f(X)\cup g(X) = X$ . Which one of the following sets cannot be equal to $X$ ? A. $[0, 1]$ B. $(0, 1)$ C. $[0, 1)$ D. $\mathbb{R}$ Please explain all options. My approach: Simply we can see the conditions imply that $X$ is disconnected. Continuity implies that $f([0,1])$ and $g([0,1])$ are compact. From the above conditions. Compact set would not be connected so $X\ne [0,1]$ .","['continuity', 'general-topology', 'real-analysis']"
3002099,Is polynomial in general the same as polynomial function?,"The algebra text book says, a polynomial in one variable over $\mathbb{R}$ is given by, $$f(x)= a_n x^n + a_{n-1} x^{n-1} + \cdots + a_1x + a_0$$ Where $x$ is an unknown quantity which commutes with real numbers, called ""indeterminate"". So I have a few question, Is polynomial always a function? If not then what is a polynomial in general? And what's up with the ""indeterminate"" thingy? Is it wrong to simply call it a variable? What exactly is the $x$ in the expression? A number? A matrix? Or… some other object? Why does it have to ""commute"" with real numbers?","['definition', 'functions', 'polynomials']"
3002105,Using the root test when the limit does not exist,"I used the root test for the series $$
\sum_{n=1}^{\infty} \left(\frac{\cos n}{2}\right)^n.
$$ I showed that $$
0 \le \left|\frac{\cos(n)}{2}\right| \le \frac{1}{2} \implies \lim_{n\to\infty}\left|\frac{\cos(n)}{2}\right| \le \frac{1}{2} < 1.
$$ By the root test, the series converges absolutely. My professor told me that the flaw here is that the limit above does not exist. I agree the limit does not exist because $\lvert\frac{\cos n}{2}\rvert$ oscillates between $0$ and $\frac{1}{2}$ . However, I fail to see why my argument does not work here. She suggested that I use the comparison test and compare the series with $\sum_{n=1}^{\infty} \left(\frac{1}{2}\right)^n$ . By the comparison test, the original series converges absolutely. Is it a coincidence that the ""pseudo"" root test I used yielded the same answer as the comparison test? Can we say that if $\lvert a_n\rvert^{\frac{1}{n}}<1$ , then $\sum_{n=1}^{\infty} a_n$ converges absolutely?
I appreciate any help on this.","['limits', 'calculus', 'convergence-divergence', 'absolute-convergence']"
3002114,Prove that $\binom{n}{1}^2+2\binom{n}{2}^2+\cdots +n\binom{n}{n}^2=n\binom{2n-1}{n-1}$,"Prove that $$
\binom{n}{1}^2+2\binom{n}{2}^2+\cdots + n\binom{n}{n}^2
= n \binom{2n-1}{n-1}.
$$ So $$
\sum_{k=1}^n k \binom{n}{k}^2
= \sum_{k=1}^n k \binom{n}{k}\binom{n}{k}
= \sum_{k=1}^n n \binom{n-1}{k-1} \binom{n}{k}
= n \sum_{k=0}^{n-1} \frac{(n-1)!n!}{(n-k-1)!k!(n-k-1)!(k+1)!}
= n^2 \sum_{k=0}^{n-1} \frac{(n-1)!^2}{(n-k-1)!^2k!^2(k+1)}
=n^2 \sum_{k=0}^{n-1} \binom{n-1}{k}^2\frac{1}{k+1}.
$$ I do not know what to do with $\frac{1}{k+1}$ , how to get rid of that.","['binomial-coefficients', 'discrete-mathematics']"
3002131,Calculate $\sum_{k=1}^n (-1)^{k+1} \binom{n}{k}\frac{1}{k}$ [duplicate],"This question already has answers here : Proof $\sum_{k=1}^n (-1)^{k+1} \binom{n}{k}\frac{1}{k} = H_n$ by induction [duplicate] (3 answers) Closed 4 years ago . Calculate $\sum_{k=1}^n (-1)^{k+1} \binom{n}{k}\frac{1}{k}$ , I do not know hot get rid of that $k$ , for me it is similar like $\binom{n}{k}=\frac{k}{n} \binom{n-1}{k-1}$ , do you have some idea?","['binomial-coefficients', 'discrete-mathematics']"
3002134,Proof of $f(A)=f(A-B)+f(B)$ when $f$ is a injective map,"I want to prove the following proposition: Let $A$ be a set, $B$ be a subset of $A$ , and $f: A\to B$ be a injective map, then $f(A) = f(A-B) + f(B).$ Could you check my proof below? Assume $f(A-B)\cap f(B) \neq \emptyset$ . For $x\in f(A-B)\cap f(B)$ there exist $a\in A$ which satisfies $f(a)=x$ and $b\in A-B$ which satisfies $f(b)=x$ . However, this contradicts the original assumption that $f$ is injective: $\forall a, b \in A, f(a)=f(b)\Rightarrow a=b$ , thus the above is impossible. Thus, $f(A-B)\cap f(B)=\emptyset$ and hence $f(A)=f(A-B)+f(B)$ .","['elementary-set-theory', 'proof-verification']"
3002193,Is $\cos(\frac x6) \cdot \cos( \frac {x \cdot \pi}{6})$ periodic?,"Aim : To obtain the period of $\cos(x/6)\cos(x\pi/6)$ , if it exists What I've done as of now : $$\cos\left(\frac x6\right)\cos\left(\frac {x\pi}{6}\right)
= \frac{1}{2} \cdot \left[\cos\left(\frac {x(\pi+1)}{6}\right) + \cos\left(\frac {x \cdot (\pi-1)}{6}\right)\right].$$ And since both, $\cos(x)$ components are in summation therefore individually calculating the periods and then taking LCM of them should do the trick.
However, the main issue comes over here. If I use the $2{\pi}k$ thing, then the period for the first component comes out to be $\frac{12\pi}{\pi + 1}$ for the first one and $\frac{12\pi}{\pi - 1}$ for the second component. Thus making the function look non-periodic. The above picture to me appears to be periodic. Issue : I'm still in a state of confusion because of the result that I calculated above and the graph obtained below. How to resolve this discrepancy?","['periodic-functions', 'trigonometry', 'real-analysis']"
3002207,Do not understand L'Hopital Rule,"I have just started learning L'Hopital rule, and so far I thought I understood everything until I stumbled upon this question $$\lim_{x\to 0}  \frac{\ln(\cos(ax))}{\ln(\cos(bx))}.$$ To this, eventually got $$\lim_{x\to 0}  \frac{a \sin(ax) \cos(bx)}{b \sin(bx)\cos(ax)}$$ From my knowledge, $\sin(0)$ is 0!! and the whole thing will be '' $\frac{0}{0}$ '', however the answer key I was given does not continue the implementation of the L'Hopital rule, but instead obtains the answer $\frac{a^2}{b^2}$ . Is there some important concept I'm missing out? Or is the differentiation supposed to continue and the answer key just skipped the steps?","['limits', 'calculus', 'derivatives', 'real-analysis']"
3002217,Circumradius of a perturbed equilateral triangle,"Consider an equilateral triangle $ABC$ with side lengths 1, on the picture with its circumcircle outlined. Its circumradius will be $1/\sqrt{3}$ . Now imagine we allow each vertex to move within a disc of radius $\rho$ centered at that vertex. We end up with a new triangle $A'B'C'$ , where e.g. $A' \in B(A,\rho)$ , the disc with center $A$ and radius $\rho$ . The question is simple: What is the maximum circumradius of the perturbed triangle $A'B'C'$ ? According to Existence of Gibbsian point processes with geometry-dependent interactions (though I wouldn't recommend looking through the paper for any insights, as it deals with a completely different topic and gives no details on this problem) the maximum circumradius, for $\rho \leq \sqrt 3 /6$ , is $$1/\sqrt{3} + \rho$$ Which is a very simple solution, but though it intuitively makes some sense to me, I can't really convince myself of it or prove it. It also leads to a secondary question What happens at $\rho = \sqrt3/6$ ? How does the solution change for $\rho > \sqrt3 / 6$ ? Intuitively what I think happens is that for small enough $\rho$ the solution is still an equilateral triangle but after a certain point (probably $\rho = \sqrt 3/6$ ) this is no longer the case, as moving the points closer to collinearity will yield a greater circumradius, until finally at $\rho = \sqrt3/4$ the points can become collinear.","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
3002272,Voronoi cell volume inside the ball,"I have the following problem: Let us denote a ball with center $C$ and radius $R$ in $\mathbb{R}^d$ as $B(C, R)$ . Given a unit ball $B(0, 1)$ and vector $u$ has a uniform distribution inside the ball: $u \sim U(B(0, 1))$ . Then we sample $M$ points $v_1, \dots, v_M$ that are uniformly distributed in the ball $B(0, 1)$ and the distance between $u$ and $v_i$ is not greater than $r$ , that is $v_i$ are i.i.d. in $B(0, 1) \cap B(u, r)$ . How to estimate the volume of the Voronoi cell of $u$ inside the ball $B(0, 1)$ ? I need an upper bound here. I can obtain only very rough estimates which do not depend on the dimension of the space $d$ and radius $r$ . It is clear that the desired values are growing monotonically as $r$ growing and if we put $r \ge 2$ , then $v_1, \dots, v_M$ are uniformly distributed inside the ball $B(0, 1)$ . So, $u, v_1, \dots, v_M$ are i.i.d. and uniformly distributed in $B(0, 1)$ . The rigorous definition of the value that I need to estimate (up to a scaling factor of the volume of unit ball): $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) $$ It is clear that $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}$ = $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_i | q \sim U(B(0,1))\}$ , so the expectations of all volumes are equal and the sum of all volumes is equal to $1$ . Hence $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) = \frac{1}{M+1}$$ It remains only to multiply it by the volume of unit ball. But as $r$ becomes less than $2$ the volume decreases, so would like to obtain estimates which take it into account. Moreover, I performed numerical experiments which shows that the estimation also should depends on the dimension of the space $d$ . Here is normal and log scale plots ( $M = 10$ ): In the more general case when $r < 2$ we still have that $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_j | q \sim U(B(0,1))\}$ = $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_k | q \sim U(B(0,1))\}$ and the sum of such probabilities for $u$ and $v_1, \dots, v_M$ is equal to $1$ , so we have: $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) + M \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_1 | q \sim U(B(0,1))\}) = 1$$ If we were able to find another equation or estimation on the ratio of volumes, then the problem would be solved. I would very appreciate any your help, ideas, papers, books and so on. Thank you for your help! UPD: Also it is possible to directly write down the required value as an integral. It is easy to see that the probability $\mathbb{P}(\rho(q, u) < \rho(q, v_i))$ correspond to the volume of spherical cap , it only remains to find the height of this spherical cap. My calculations showed that if $\|u\| \le \|v\|$ then $$ h = 1 - \dfrac{\|v\|^2 - \|u\|^2}{2\|v-u\|} $$ $$ \mathbb{P} = 1 - \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2}) $$ and if $\|u\| \ge \|v\|$ then $$ h = 1 - \dfrac{\|u\|^2 - \|v\|^2}{2\|v-u\|} $$ $$ \mathbb{P} = \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2}) $$ where $I_x(a, b)$ is incomplete regularized beta function . One more observation is: $$\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u\} = \mathbb{P}(\rho(q, u) < \rho(q, v_i), i=1,\dots,M) = \prod\limits_{i=1}^{M}\mathbb{P}(\rho(q, u) < \rho(q, v_i)) = (\mathbb{P}(\rho(q, u) < \rho(q, v)))^M$$ since $v_1,\dots,v_M$ are i.i.d. So now we can integrate for $u$ and $v$ and obtain the desired value: $$ \frac{1}{Vol(B(0,1))} \int\limits_{u \in B(0,1)} \Big( \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \le \|u\|} (\frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv + \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \ge \|u\|} (1 - \frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv \Big) du,$$ where $h = 1 - \frac{| \|v\|^2 - \|u\|^2 |}{2\|v-u\|}$ The first summand here is about $\frac{1}{2^M}$ since regularized incomplete beta function is bounded by $1$ , so it remains only to estimate the second summand. If I was able to estimate the asymptotics of this integral, it would solve my problem!","['geometric-probability', 'stochastic-analysis', 'geometry', 'voronoi-diagram', 'probability']"
3002281,"What is the correct notation for the set of rational numbers $\frac{n}{m}$ with the constraint that $1\le n,m \le5$?","I have set that I want to neatly write down/present with set notation. The set contains: All the rational numbers $\frac{n}{m}$ with the constraint that $1\le n,m \le5, n,m\in \mathbb{Z}$ . I have come up with a few ways to write it down but I am not sure which one (if any) is correct. $$\begin{align}
   \left\{ \frac{m}{n} \vert n,m\in \mathbb{Z} \land1\le n\le5 \land1\le m\le5\right\} \tag 1\\
   \left\{ \frac{m}{n} \in \mathbb{Q}\vert n,m\in \mathbb{Z} \land1\le n\le5 \land1\le m\le5\right\} \tag 2\\
  \left\{\frac{n}{m}\in \mathbb{Q}\vert n,m \in \mathbb{Z}, 1\le n,m\le 5\right\} \tag 3
\end{align}$$",['elementary-set-theory']
3002335,What is the domain of $x^{2x}$,"What is the domain of $f(x)=x^{2x}$ ? If $f(x)=(x^2)^x $ then $f$ is defined for every real number but if $f(x)=(x^x)^2$ then $f$ is only defined and ""nice"" (excluding the negative $-p/q$ fractions) for positive real numbers. Should we say $f(x)=e^{2x\log(x)}$ is only defined for positive $x$ ? Thanks","['calculus', 'functions']"
3002337,"If $\mathbb{R}^{2n} = X \times X$, must $X$ be homeomorphic to $\mathbb{R}^n$?","By invoking the Künneth formula for cohomology, one can argue that among the Euclidean spaces only the even-dimensional ones can be the square of some space. Clearly these are indeed squares, as $\mathbb{R}^n \times \mathbb{R}^n \cong \mathbb{R}^{2n}$ . This does not guarantee that there are no other decompositions. Fox showed in 1947 that non-homeomorphic spaces can have homeomorphic squares, and subsequently quite reasonable examples of such spaces have been found. Question. If $\mathbb{R}^{2n} = X \times X$ , must $X$ be homeomorphic to $\mathbb{R}^n$ ? As a follow-up question, one might consider any decomposition of $\mathbb{R}^N$ as a product $X_1 \times \cdots \times X_k$ and ask whether the $X_i$ must be Euclidean.","['general-topology', 'geometry', 'algebraic-topology']"
3002340,"Showing $\int_{\mathbb R} \mid F(x)-G(x)\mid dx = \int_0^1 \mid F^{-1}(u)-G^{-1}(u)\mid du$ with $F$, $G$ CDF functions","Let's $X$ and $Y$ have CDF functions admitting moment of order $1$ .
Let's be $F$ cdf of $X$ and $G$ cdf of $Y$ . I want to show that $$\int_{\mathbb R} \mid F(x)-G(x)\mid dx = \int_{0}^{1} \mid F^{-1}(u)-G^{-1}(u)\mid du\,.$$","['definite-integrals', 'probability-distributions', 'inverse-function', 'probability-theory', 'probability']"
3002350,Is there a set in which division of 0 by 0 is defined?,"The reason I ask this is that I've discovered that, even though they don't satisfy all field axioms, there are sets called projectively extended real number line and Riemann sphere, which are ℝ∪{∞} and ℂ∪{∞} where division of every nonzero number of the set by 0 is defined as ∞. However, the two sets' arithmetic operations aren't total and some operations are left undefined. These include: ∞+∞, ∞-∞, ∞·0, 0·∞, ∞/∞, and 0/0. My question is that if there is, or could be a field-like set that can also define the results of these operations. And could there be a logical definition for those operations, especially 0/0?","['field-theory', 'binary-operations', 'infinity', 'analysis']"
3002408,Why does the derivative of $\sin^2x$ need the chain rule? Isn't it just $2\sin x$ by the power rule?,"It's probably something obvious and I'm gonna slap myself in the face again, but Why is the first derivative of $\sin^2(x)$ calculated via the chain rule? Isn't it just a standard $x^a$ (power rule) case, and therefore just $2\sin(x)$ ?","['calculus', 'functions', 'trigonometry']"
3002455,What is the infinite product series for $\exp(\sin(x))-1$?,$e^{\sin(x)}-1$ has the same roots as $\sin(x)$ . What is the difference between infinite product series expansions of $\sin(x)$ and $e^{\sin(x)}-1$ if they both have same infinite roots ?,['calculus']
3002457,The Maximimum Monochromatic k-Cliques for Complete Graph,"Show: 
For a complete graph $K_{n}$ , there is a coloring of the edges with $2$ colors, such that the number of monochromatic $k$ -Cliques is a maximum of $\binom{n}{k}2^{1-\binom{k}{2}}$ . I do not know where to begin on this exercise. As a hint, our professor gave us the following pre-exercise, which I have been able to solve: Let $n \in \mathbb N$ , and $\mathcal{K}$ be the set of permutations
  possible for a set $\{1,...,n\}$ . Let $\sigma \in \mathcal{K}, $ such
  that $\sigma: [n] \to [n]$ is a randomly selected permutation. Find
  the probability space, define random variable $X$ as the number of
  fixed points and find $\mathbb E[X]$ . How do the two questions fit together? I am lost.","['permutations', 'stochastic-processes', 'probability']"
3002546,"Equivalence of two statements on an arbitrary partially ordered set $(A, <)$","Let $(A, <)$ a arbitrary partially ordered set. ( $<$ is irreflexive and transitive) These two statements are equivalent: Every nonempty subset of $A$ that is bounded from above has a supremum in $A$ Every nonempty subset of $A$ that is bounded from below has an infimum in $A$ My attempt : Let the first statement be true and I will try to prove the second follows.(I suspect the second direction will be pretty much the same) Let $C\subset A$ be an arbitrary subset of $A$ that is bounded from below.
Let $D$ denote the set of all lower bounds of $C$ . So we have $\forall c \in C, \forall d \in D, d < c$ . I have to prove that $D$ has the biggest element(definition of infimum). 
I know that $D$ is a set that is bounded from above, then it follows that $D$ has a supremum, let's denote it by $S$ . Now, I know, $(\forall d \in D)( d < S \lor d = S)$ . But I don't know how to prove that $S\in D$ . Because if $S \notin D$ then $S$ doesn't have to be comparable to any $c \in C$ since the set is partially ordered, then $S$ is definitely not the infimum of $C$ which I think it should be. Thanks in advance!","['elementary-set-theory', 'order-theory']"
3002581,"Prove that the Cantor set is homeomorphic to $(X,\mathscr T)$.","For each $n\in \mathbb N$ , let $X_n=\{0,2\}$ and let $\mathscr T_n $ be the discrete topology on $X_n$ . Let $X=\prod_{n=1}^\infty X_n,$ and $\mathscr T$ be the product topology on $X$ . Prove that the Cantor set is homeomorphic to $(X,\mathscr T)$ . Proof. Let $C$ be the Cantor set, Let $(C,\mathscr U_C)$ be the subspace topological space of usual topology on $\mathbb R$ . Let the map $\psi:(C,\mathscr U_A)\to (X,\mathscr T)$ be defined as $\psi(x)=(x_1,x_2,...,x_n,....),$ where $x\in C$ and $x=\sum_{i=1}^\infty \frac{x_i}{3^i},x_i=0$ or $2$ . $\psi$ is well defined if we take the ternary expansion of $1/3,1/9$ ,...etc with $0$ and $2$ s. We can easily prove that $\psi$ is injective. How do I prove that $\psi$ is surjective? What is the guarentee that, If $y\in X$ , $\exists x\in C$ : $f(x)=y$ ? For continuity of $\psi$ , Let $\mathscr B$ be the basis of the product topology on $X$ . It is enough to show that $\psi^{-1}(B)\in \mathscr U_C$ for every $B\in \mathscr B$ . Let $B \in \mathscr B$ , $B=\prod_{i=1}^n B_i$ , $B_i \in \mathscr T_i$ , $B_i=X_i$ for all but finitely many $i$ . I want to prove $\exists$ some open interval ( $I$ (say) in $\mathbb R$ ) such that $\psi^{-1}(B)=C\cap I$ . How do I prove the existence of $I$ ? For completing the proof of homeomorphism, I need to prove that $\psi $ is open. Let $U\in \mathscr U_C$ , then $U=C\cap J$ for some interval $J$ in $\mathbb R$ . then $\psi(U)=\psi(C\cap J)=\psi(C)\cap\psi(J)=X\cap \psi(J).$ How do I complete the proof. Please help me.","['alternative-proof', 'general-topology', 'cantor-set']"
3002601,trace and operator norm of $\exp^A$,"If $A$ is an n by n complex matrix,
1.How to compute $tr(\exp^A)$ .Can we use the Taylor expansion as following: $\exp^A=\sum_{k=0}^{\infty}\frac{A^k}{k!},$ then $tr(\exp^A)=\sum_{k=0}^{\infty}tr(\frac{A^k}{k!})$ . 2.How to compute the operator norm of $\exp^A$ ?","['c-star-algebras', 'operator-algebras', 'operator-theory', 'complex-analysis', 'linear-algebra']"
3002692,Uniform convergence of $\int_{a}^{\infty}{\frac{\sin x}{x^s}}dx$ for $\Re(s)>0$?,"For $a>0$ , does $$f_b(s)=\int_{a}^{b}{\frac{\sin x}{x^s}}dx$$ converge uniformly for all compact subsets of $\{s\in\mathbb C|\Re(s)>0\}$ when $b\to\infty$ ? For $\Re(s)>1$ the integral converges absolutely, and since $g_s(z)=\frac{\sin z}{z^s}$ is holomorphic on $\{x\in\mathbb R|x>0\}$ , by applying the Weierstrass theorem (which states that for a family of holomorphic functions converging uniformly, the family of derivative of those functions converges uniformly and equals the derivative of the converging function of the given family) it is not difficult to prove. However, for $0<\Re(s)\leq 1$ the integral only seems to converge conditionally at best, which makes it more difficult. Any good ways of proving convergence?(or maybe divergence?)","['complex-analysis', 'uniform-convergence']"
3002705,Rhombus in a cyclic quadrilateral,"Let $ABCD$ be a cyclic quadrilateral whose opposite sides are not parallel. The lines $AB$ and $CD$ intersect at point $P$ . The lines $AD$ and $BC$ intersect in point $Q$ . The bisector of the angle $\angle DPA$ cuts the line segment $BC$ and $DA$ in the points $E$ and $G$ , respectively.  The bisector of the angle $\angle AQB$ cuts the line segments $AB$ and $CD$ in the points $H$ and $F$ . Now it seems as if the quadrilateral $EFGH$ is a always a rhombus. I intend to prove this. Maybe anyone has a checklist or any idea to begin with.","['euclidean-geometry', 'quadrilateral', 'proof-writing', 'circles', 'geometry']"
3002755,$(\mathbb Z/p \mathbb Z \rtimes \mathbb Z/q \mathbb Z) \times \mathbb Z/q \mathbb Z \cong\mathbb Z/p \mathbb Z \rtimes (\mathbb Z/q \mathbb Z)^2$?,"Given : Let $p$ and $q$ be prime numbers such that $q$ divides $p-1$ . It is well-know that there is a monomorphism $\varphi: \mathbb Z/q \mathbb Z \to Aut(\mathbb Z/p \mathbb Z)$ . Define homomorphisms $\varsigma: (\mathbb Z/q \mathbb Z)^2 \to \mathbb Z/ q \mathbb Z$ where $(a,b) \mapsto a-b$ and $\vartheta: (\mathbb Z/q \mathbb Z)^2 \to Aut(\mathbb Z/p \mathbb Z)$ via $\vartheta = \varphi \circ \varsigma$ . Note that composition of maps is evaluated from right to left. Question : If we consider the semi-direct products $G := (\mathbb Z/p \mathbb Z \rtimes_\varphi \mathbb Z/q \mathbb Z) \times \mathbb Z/q \mathbb Z$ and $H := \mathbb Z/p \mathbb Z \rtimes_\vartheta (\mathbb Z/q \mathbb Z)^2$ , are these groups isomorphic? Thoughts : My intuition says: No, $G$ and $H$ are not isomorphic. But I am unsure how to prove this hypothesis. I tried to evaluate the centers $Z(G)$ and $Z(H)$ of $G$ and $H$ , respectively, which gave me $Z(G) = \{(0,0)\} \times \mathbb Z/q \mathbb Z$ and $\{(0,r,r): r \in \mathbb Z/q \mathbb Z\} \subseteq Z(H)$ . Makes this line of attack sense? Or is the required argument quite obvious? Thank you very much for your insights! Context : I stumbled upon this question while reading a collection of problems about group theory which interested me as a layperson.","['semidirect-product', 'group-theory', 'group-isomorphism', 'finite-groups']"
3002761,Maximum value of $x$ when equality is given,$$ x + y = \sqrt{x} + \sqrt{y} $$ Find maximum value of $x$ . $x$ and $y$ are reals.,['algebra-precalculus']
3002766,How do geometric properties of sine and cosine follow from their power series definition?,"If you define $\cos$ and $\sin$ using their power series, or as the real and imaginary part of the power series of $e^{ix}$ , how can you prove that they are periodic? Also, how do you prove that period is $\pi$ ? And how do you prove that the points $(\cos(x), \ \sin(x))$ for $x \in [0, 2\pi]$ form a circle? I believe the last question can be proven if you use the continuity of $\cos$ and $\sin$ , which follows from their power series definition, and from the fact that $\cos^2(x) + \sin^2(x) = 1$ , but using only these two properties is not enough for proving they form a full circle I believe. I think you also need to find their derivatives on the intervals $[0, \ \pi/2]$ , $[\pi/2, \ \pi]$ , $[\pi, \ 3\pi/2]$ and $[3\pi/2, \ 2\pi]$ , is this correct? If so, how can this be done?","['power-series', 'calculus', 'trigonometry', 'analysis']"
3002807,Variance of the Euclidean norm under finite moment assumptions,"Let $X = (X_1,X_2 \cdots X_n)$ be random vector in $R^n$ with independent coordinate $X_i$ that satisfy $E[X_i^2]=1$ and $E[X_i^4] \leq K^4$ . Then show that $$\operatorname{Var}(\| X\|_2) \leq CK^4$$ where $C$ is a absolute  constant and $\|   \ \|_2$ denotes euclidian norm. Here is my attempt: $$\begin{align*}   E(\|X\|_2^2 -n)^2 &= E[(\sum_{i=1}^n X_i^2)^2 ]-n^2 \\
&=E[\sum_{i=1}^n X_i^4]+E[\sum_{i<j}X_i^2X_j^2]  -n^2 \\
&\leq nK^4 +  2{{n}\choose {2}}-n^2 \\
&\leq n(K^4-1) \\
& \leq nk^4
\end{align*}$$ since $$ E(\|X\|_2^2 -n)^2 \leq nk^4 \rightarrow E\left(\frac{\|X\|_2^2}{n} -1\right)^2 \leq \frac{K^4}{n}$$ and  since $$(\forall z \geq 0 \ \ |z-1|\leq |z^2-1|) \rightarrow
  E(\frac{\|X\|_2}{\sqrt n} -1)^2\leq E(\frac{\|X\|_2^2}{n} -1)^2 $$ thus: $$E(\frac{\|X\|_2}{\sqrt n} -1)^2 \leq K^4/n  \rightarrow E(\|X\|_2-\sqrt n)^2\leq K^4$$ by Jensen inequality: $$(E[\|X\|_2] - \sqrt n)^2 \leq K^4 $$ which is equivalence to $$ |E[\|X\|_2] - \sqrt n)| \leq K^2$$ then when I am trying to bound $Var(\| X\|_2)$ I meet some problem : $$\operatorname{Var}(\| X\|_2)=E[\|X\|_2^2] -(E[\|X\|_2])^2 \leq n- (K^2-\sqrt n)^2 \leq -K^4+2K^2\sqrt n$$ which is not bound by constant , how can I bound that?","['concentration-of-measure', 'variance', 'normed-spaces', 'probability', 'random-variables']"
3002825,Applications of the lack of compactness of the closed unit ball in infinite-dimensional Banach spaces,"I am writing a paper on the compactness of closed balls in Banach spaces, with particular attention paid to the following theorem Let $V$ be a Banach space over $\mathbb R$ or $\mathbb C$ . The closed unit ball in $V$ is compact if and only if $V$ is finite-dimensional. I am looking for some consequences or applications of this theorem (probably mostly related to the part which asserts that: if $V$ is infinite-dimensional, then the closed unit ball is not compact). I do prove the immediate corollary of this theorem, which is basically replacing ""the closed unit ball"" with ""the closed ball of radius $r>0$ around $x_0\in V$ "" in the statement of the theorem. I have also been looking at the notion of weak convergence, and how this can allow for compactness (in the weak sense) in infinite-dimensional spaces. Other than those two, I am looking for some other applications of this theorem. In particular, are there any specific interesting examples one can look at that follow from this theorem? Any feedback is appreciated.","['vector-spaces', 'examples-counterexamples', 'analysis', 'functional-analysis', 'compactness']"
3002832,How to Solve this Differential Calculus Problem,"If the equation of the normal line to the curve $y = ax + b/x$ at the point $(2,7)$ is $y+ 2x = 11$ , find the value of $a$ and $b$ . Given that this normal line meets the curve again at $P$ , find the coordinates of $P$ . I found the tangent equation to be $y= 1/2 x + 6$ . I inegrated that to get $y = x^2 /4 + 6x + c$ . Then I found c by putting the values of the point  in as 6. (I am unsure from here forward) I think $ax + b/x$ would be $ax^2 + yx + b$ , meaning $a$ would be $1/4$ and $b$ would be -7. I do not know what to do to find the other intersection of the normal, given that I am unsure that my answers for $a$ and $b$ are accurate","['integration', 'calculus', 'ordinary-differential-equations']"
3002834,Equivalent finite sets have the same number of elements (odd proof),"I am working through Rudin's POMA and in Chapter 2 on Basic Topology he gives the following definition of one-to-one correspondence: If there exists a 1-1 mapping of $A$ onto $B$ , we say that $A$ and $B$ can be put in 1-1 correspondence , or that $A$ and $B$ have the same cardinal number , or, briefly, that $A$ and $B$ are equivalent , and we write $A\sim B$ . This relation clearly has the following properties: It is reflexive: $A\sim A$ . It is symmetric: If $A\sim B$ , then $B\sim A$ . It is transitive: If $A\sim B$ and $B\sim C$ , then $A\sim C$ . Rudin later goes on to say, ""For two finite sets $A$ and $B$ , we evidently have $A\sim B$ if and only if $A$ and $B$ contain the same number of elements."" Rudin never defines what cardinal or ordinal numbers are (even though he says $A\sim B$ for finite sets means $A$ and $B$ have the same cardinal number...he never defines a cardinal number) and does not go into set theory in any real depth. Curiosity: I was thinking about Rudin's statement about finite sets and was wondering how one might prove that. I read an alleged proof in Raffi Grinberg's Real Analysis Lifesaver book (a book I really do not like to be honest), and I'm really questioning whether or not it is accurate. It is reproduced below: Raffi's proof: Let $A$ and $B$ be finite sets. We claim that $A\sim B$ if and only if $A$ and $B$ have the same number of elements. If $A\sim B$ , then there exists a function that maps every element of $A$ (since $f$ is a well-defined function) to at most one element of $B$ (since $f$ is injective), and every element of $B$ is mapped to by some element of $A$ (since $f$ is surjective). So for every element of $A$ there is a corresponding element of $B$ , and all elements of $B$ are covered by this correspondence, so $A$ and $B$ must have the same number of elements. If $A$ and $B$ have the same number $n$ of elements, then we can write the sets as $A=\{a_1,a_2,\ldots,a_n\}$ and $B=\{b_1,b_2,\ldots,b_n\}$ . Let $f\colon A\to B$ be defined as $f\colon a_i\mapsto b_i$ , for every $1\leq i\leq n$ . Then $f$ is a one-to-one, onto function, so $f$ is a bijection. We have found a bijection $A\to B$ , so $A\sim B$ . Question: Is this proof really correct? It seems hand-wavy at best, especially the first part (the forward direction)---the finiteness of $A$ and $B$ do not seem to matter. The same argument would seem to work in the case of infinite sets $\mathbb N$ and $\mathbb Z$ , where $\mathbb N\sim\mathbb Z$ , but we do not think of these sets as having the same number of elements in the manner argued above (do we?). More concerning, since Grinberg admits in the introduction/preface that his book is basically based on Rudin's, I wonder how he proposes to prove something about cardinal numbers (i.e., that equivalent finite sets have the same cardinal number) when they have not actually been defined (in his book or in Rudin's). I was reading in Enderton's Elements of Set Theory that, ""Now it turns out that there is no way of defining $\operatorname{card} A$ that is really simple"" (p. 136). He later gives the definition: ""For any set $A$ , define the cardinal number of $A$ ( $\operatorname{card} A$ ) to be the least ordinal equinumerous to $A$ "" (p. 197). Ultimately, there seems to be a fair amount going on here (to a novice like me at least), but I did not find Grinberg's proof very convincing. Am I wrong to feel that way? Is there an easy fix? Any thoughts?","['elementary-set-theory', 'cardinals', 'real-analysis']"
3002854,Inequality relation between sines of angles in a triangle.,"Question : Given ${CD}^2=AD.BD$ , then prove that, $\sin A.\sin B \le \sin^2{C\over2}$ . I got 2 approaches to the question. Both landing nowhere. (i) Using sine rule I got that $\sin A.\sin B=\sin \alpha.\sin \beta$ but can't proceed. (ii) On extending $CD$ further to $D'$ such that $CD=DD'={CD'\over2}$ which makes $ABCD'$ a cyclic quadrilateral again ending where the first step ends. Help me please. Thanks for any hints or solution. Hope that question is decently put.","['trigonometry', 'triangles']"
3002874,"$\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1$","I found this limit in a book, without any explanation: $$\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1$$ where $H_{k,2}:=\sum_{j=1}^k\frac1{j^2}$ . However Im unable to find the value of this limit from myself. After some work I get the equivalent expression $$\lim_{n\to\infty}\sum_{k=0}^{n-1}\sum_{j=k}^\infty\frac1{(j+1)^2(j+2)}$$ but anyway Im stuck here. Can someone show me a way to compute this limit? Thank you. UPDATE: Wolfram Mathematica computed it value perfectly, so I guess there is some integral or algebraic identity from where to calculate it.","['limits', 'calculus', 'special-functions']"
3002931,Is the characteristic polynomial of a matrix $\det(\lambda I-A)$ or$ \det(A-\lambda I)$?,"I haven't been able to get a very clear answer on this. In the exercise that I performed to find the Characteristic Polynomial of a given Matrix, I used the determinant of $(\lambda I-A)$ to find the answer. I don't actually attend any courses or do anything that requires me to solve these problems, or even presents them to me regularly. My solving this problem is a result of me asking my friend who is in a college math course for his homework, because I'm personally interested in learning more about math. As such, I have to study the problems he gives me on my own, and can only use the internet, for the most part, in order to get the knowledge I need to solve them. While looking for the definition of 'Characteristic Polynomial', this website defines a Characteristic Polynomial as ""If $A$ is an $n\times n$ matrix, then the Characteristic Polynomial of $A$ is the function $f(\lambda )=\det(\lambda I−A)$ "". A few other resources I found also say this, while others say that it is the determinant of $(A-\lambda I)$ . I solved the problem, which, yes, did use an $n\times n$ Matrix ( $3\times 3$ to be specific), using the former equation of $(\lambda I-A)$ , and I presented the solution to my friend. He concurred, and we decided that was our answer, however when he entered it into whatever website assigns him his homework, it said that we were incorrect. We thought about it for a while, and even looked to see if the issue was that we hadn't simplified the problem properly, but everything checked out (I initially read $[\lambda I-A]$ as the correct determinant, so in my head, I didn't realize that some other websites used the inverse, and didn't think to try that). Eventually, we both gave up, and I used an online calculator to solve it, and was presented with an answer achieved by using $(A-\lambda I)$ . We put that in to the website, and sure enough it was correct. This causes some concern with me. Is $(A-\lambda I)$ always used to find the Characteristic Polynomial? How am I to remember that it is this way, and not the other? Why do we choose to define the Characteristic Polynomial as one determinant over the other? Is the website that I cited outright incorrect, and thus should be considered disreputed, or is there something unique that I fail to understand regarding certain Matrices and their polynomials?",['matrices']
3002951,"Using basic arithmetic, how do I count constrained partitions of a set?","On my 9-year-old daughter’s recent test over multiplication and grouping that included questions about the total number items in m groups of n and converting between multiplication sentences and models, one particular question asked how many ways one can display 18 stamps in groups of either 3, 6, or 9. Her answer was three: 3 × 6, 6 × 3, and 9 × 2. I made three false starts of my own trying to explain to her how to approach the problem. Counting Method The first approach that came to mind was what Mark Jason Dominus on pages 131-132 of his book Higher Order Perl called the counting method , which he generalizes to manage a generator for permutations. What is the pattern here? It turns out that getting from one pattern to the next is rather simple: Scan the numbers in the pattern from right to left. If you can legally increment the current number, do so, and halt. Otherwise, change the current number to 0 and continue. If you fall off the left end, then the sequence was the last one. This algorithm should sound familiar, because you learned it a long time ago. It’s exactly the same as the algorithm you use to count . I suggested that we try a simple rule of using the lowest available number (of 3, 6, or 9) that we hadn’t yet used in each column but soon realized it was going to be problematic. 3 3 3 3 3 3 3 3 3 3 6 3 3 3 6 3 The second and third partitions are the same, but getting into combinations versus permutations seemed like it’d be a bit much. I figured we could come back afterward to throw out duplicates. But also, we reused 3 in the fifth column, so we had to modify the mechanical rule to using the lowest available number not yet used at that point (in the sense of a decision tree). She seemed to grasp the concept and turned the crank for a total of 13 rows. I took advantage of a good teaching moment to suggest that when it seems like an approach isn’t gaining much ground, that’s a sign that it’s time to take a step back and consider a different approach. Dynamic Programming “Let’s try starting from a simple case and building up. What if there were only three stamps? How many possible displays would there be?” She correctly answered one. “Now what if there were six stamps?” Looking back at the first two rows of the previous attempt and from our discussion then, she saw that the answer was two. “Okay, how about for nine stamps?” With her table, she enumerated the three possibilities. From there, I wasn’t sure whether she’d more easily follow the jump to 12 or 18 next. Hmm. But in her table, she made a tree with no explicit edges to show that 3 and 3 combine to make 6, so … Tree Traversal Earlier, she preferred starting with smaller numbers and working her way up. I suggested splitting numbers starting from 18 instead to give 18
     /    \
    9      9
   / \    / \
  6   3  6   3
 / \    / \
3   3  3   3 I began a discussion of leaf and internal nodes, and she asked if she could go play with her friend across the street. Brute Force Maybe the answer derived from brute force would reveal an obvious pattern. Simulating nondeterminism with import Control.Monad
import Data.List
import qualified Data.Set as S

groups = do
  a <- [9,6,3,0]
  b <- [9,6,3,0]
  c <- [9,6,3,0]
  d <- [9,6,3,0]
  e <- [9,6,3,0]
  f <- [9,6,3,0]
  guard $ a+b+c+d+e+f == 18
  return [a,b,c,d,e,f]

main =
  mapM_ print $
  S.toList $ S.fromList $
  map (reverse . sort) groups yielded [3,3,3,3,3,3]
[6,3,3,3,3,0]
[6,6,3,3,0,0]
[6,6,6,0,0,0]
[9,3,3,3,0,0]
[9,6,3,0,0,0]
[9,9,0,0,0,0] Talking through how the groups of 3 combined to make groups of 6 and then regrouping from three groups of 6 to (9, 3, 3, 3) seems a little handwavy, and how would I convince her that we hadn’t skipped any possible displays? Likewise, from the dynamic programming approach, she identified three ways of displaying nine stamps, so we double that and also add (6, 6, 6), but that would seem like producing it from thin air and might also make her wonder what other combinations we hadn’t considered. Using the mathematical tools available to a bright but young student, how does dear old Dad make the airtight case for her?","['combinatorics', 'set-partition']"
3002963,Proof that limit in a Hausdorff space is unique,"This proof is likely quite trivial, but I was hoping someone could look it over regardless. There is one particular step I am confused on. Theorem. The limit of a convergent sequence in a Hausdorff space is unique. Proof. Let $a_n$ be a convergent sequence in a Hausdorf space. Suppose, for a contradiction, that it converges to two different points, $x$ and $y$ . Thus, it follows from converges to $x$ that \begin{align*}
\forall \epsilon > 0, \exists N, \forall n > N, |a_n - x | < \epsilon,
\end{align*} which is otherwise stated that for all $n > N$ , elements of the sequence lie in some open ball around $x$ with radius $\epsilon$ . From convergence to $y$ , it follows that \begin{align*}
\forall \epsilon > 0, \exists N, \forall n > N, |a_n - y| < \epsilon,
\end{align*} otherwise stated that for all $n > N$ , elements of the sequence lie in an open ball around $x$ with radius $\epsilon$ . Here is where my confusion comes in. From here, I know I need to draw on the definition of Hausdorff space. These are distinct points, and so there exist open sets around them containing the points, $x$ and $y$ , where these sets are disjoint. This does not imply that every open set containing these points is disjoint. So, it seems that I need to say something to the effect that the definition of convergence allows me to create an open ball (I am using this interchangeable with open set, which I hope isn't incorrect; please correct me, if so) of any radius I want around 
the points, and thus it clearly captures all such open sets. Thus, I can pick two separate $N$ 's for each of these sets to form open balls of radius $\epsilon_1$ and $\epsilon_2$ around these points such that the sets are disjoint, which I know I can do via the definition of Hausdorff space. Since this would be true for an infinite number of $n$ past some arbitrary point $N$ , it would not be possible to get ""back inside"" the opening ball around the other point. That's clearly a contradiction to the definition of convergence. Thus, if $a_n$ converges to $x$ , it cannot converge to $y$ , and if it converges to $y$ , it cannot converge to $x$ , so there is only a single possible limit point, which is unique. How does this argument sound? Is there a better way to state it, or have I made an errors in logic? Thanks in advance.","['general-topology', 'proof-verification', 'convergence-divergence', 'sequences-and-series']"
3002970,Show the Polar Factor is the Closest Unitary Matrix Using the Spectral Norm,"For a square matrix $A \in \mathbb{C}^{n \times n}$ with the singular value decomposition $A = U\Sigma V^*$ , I want to show that $$\|A - P \|_{2} \leq \|A -W \|_{2}$$ Where $P = UV^{*}$ and $W$ is an arbitrary unitary matrix. It is immediately clear to me that $$\|A - P \|_{2} = \|U\Sigma V^* - UV^{*}\|_2 = \|\Sigma - I \|_2 $$ I also know that the singular values of all unitary matrices are all one. However, I don't know how to combine this fact with properties of the spectral norm to get a proof, if this is indeed the right way.","['matrices', 'normed-spaces', 'linear-algebra']"
3002989,What is the proof for the Vortex vector field equation?,"I'm Struggling to understand why the vortex vector field is given by: Vortex vector field equation $\vec F(x,y) = (\frac{-y}{x^2+y^2}, \frac{x}{x^2+y^2})$ If anyone could explain why this is, I would be very grateful. Thank you.","['multivariable-calculus', 'vectors', 'vector-analysis']"
3003007,Finding the definite integral $\int_1^e \frac{dx}{x\sqrt{1+\ln^2x}}$,So I have the following problem: $$\int_1^{e} \frac{1}{x\sqrt{1+\ln^2x}}dx $$ Can somebody comfirm that the integral of this is $$\ln|\sqrt{1+\ln^2x}+ \ln x|+C$$ and I that the anwser is $$\ln |\sqrt{2}+1|$$ that is aproximately 0.8814 Does anyone else got the same anwser?,"['integration', 'calculus', 'definite-integrals', 'closed-form']"
3003011,Eigenvalues of $A+v_1d^T$ where $Av_1 = \lambda_1 v_1$ (shift of first eigenvalue),"I have trouble to solve the following problem: Let $A\in \mathbf{R}^{n\times n}$ , $\lambda_1,\ldots,\lambda_n$ are eigenvalues of $A$ , and $A v_1=\lambda_1v_1$ . Let $d\in \mathbf{R}^n$ , then the eigenvalues of $A+v_1d^T$ are $\lambda_1+d^Tv_1, \lambda_2,\ldots,\lambda_n$ . Note: $A$ may not be diagonalizable. I know the following facts: $v_1d^T$ is of rank $1$ . eigenvalues of $v_1d^T$ are $v_1^Td, 0,\ldots, 0$ . But I still have no idea to prove this theorem. Please help me, thanks!","['matrices', 'eigenvalues-eigenvectors']"
