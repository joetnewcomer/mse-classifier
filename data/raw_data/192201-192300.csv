question_id,title,body,tags
3657873,Can $\pi$ be defined using Dedekind cuts?,"I have read that Dedekind cuts allow you to define the real numbers from the rationals. For example, $\sqrt{2}$ can be defined in the following way: Partition the rational numbers into two sets $A$ and $B$ , such that all of the elements of $A$ are less than the elements of $B$ $A=\{a \in \mathbb{Q}:x<0 \text{ or } x^2 < 2$ } $B=\{b \in \mathbb{Q}: x > 0  \text{ and } x^2 \geq 2$ } Because $B$ has no lower bound, there is a 'gap' in the number line We define $\sqrt{2}$ to fill this gap: $\sqrt{2}$ is the unique number such that $x^2=2, x>0$ . $\sqrt{2}$ sits on the partition line that we previously drew (hence why we say $\sqrt{2}$ is that cut) Hopefully, I understand Dedekind cuts well enough to ask this question. It seems to me that because $\pi$ is transcendental, it cannot fill a gap in the same way that $\sqrt{2}$ does. There is no polynomial equation that $\pi$ helps solve. By contrast, $\sqrt{2}$ solves the equation $x^2=2, x \geq 0$ . Nevertheless, $\pi$ is a real number, and Dedekind cuts define the real numbers. So, can $\pi$ be defined using Dedekind cuts, or is more work needed? Moreover, does the usual geometric definiton of $\pi$ have a well-defined mathematical meaning if you have not constructed the real numbers from the rationals?","['elementary-set-theory', 'real-numbers', 'transcendental-numbers', 'real-analysis']"
3657930,"$A$ are the even numbers, is there a non-computable set $B$ such that $A\nleq_1 B$?","Assume $A,B\subseteq \omega$ , we say $A\leq_1 B$ (1-reducible) if there is a injective computable function $f$ such that, for all $x$ , $$x\in A \Leftrightarrow f(x)\in B.$$ Now assume $A$ are the even numbers. I want to construct a non-computable set $B$ such that $A\nleq_1 B$ . I know the intution behind $m$ -reducibility, which is the same as above but without the injectivity of $f$ , $B$ is more ""complicated"" than $A$ if $A\leq_m B$ . I don't really have an intuition behind non-comparable sets with respect to $\leq_m$ or $\leq_1$ . I could show that non-computable c.e. sets are incomparable with respect to $\leq_m$ .","['computational-complexity', 'logic', 'discrete-mathematics', 'computability']"
3657933,Prove $\tan 84^{\circ}=\tan 78^{\circ}+\tan 72^{\circ}+\tan 60^{\circ}$,"Prove that: $$\tan 84^{\circ}=\tan 78^{\circ}+\tan 72^{\circ}+\tan 60^{\circ}$$ First I simplified $\tan 78^{\circ}+\tan 72^{\circ}$ and then I simplified $\tan 84^{\circ}-\tan 60^{\circ}$ . 
Both turned out to be $$\frac{1}{2\cos 72^{\circ}\cos 78^{\circ}}$$ Just usual formulae bashing.
Is there a more elegant way.","['algebra-precalculus', 'trigonometry']"
3657987,Does $ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}} $ converge?,"I am trying to determine whether the series $ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}} $ converges or not. The difficulty is in that every now and then $\sin(n)$ will be very close to zero making the corresponding term in the series close to $\pm 1$ . If I could show that these outlier terms eventually get much smaller than $1$ , or if there are about as many positive such terms as negative ones then the series would converge, but I'm not sure how to approach that. Any help is appreciated.",['sequences-and-series']
3658019,How To Solve The Following Counting Problem By Casework,"I am trying to solve the following problem by casework: However, my solution 85 is incorrect. The correct solution is 165. I would like to figure 2 things out: why my method is incorrect, and how to actually solve this problem using casework (in other words, how to solve this problem by breaking it into 4 cases: when it has 4 colours, 3 colours, 2 colours and 1 colour). I would appreciate any help on this. Case where there are 4 colours: There are $5C4$ ways to choose 4 colours, and $4!$ ways to arrange these colours. However, because the square can be rotated 4 times, there are $5C4  * 3!$ ways. Case where there are 3 colours: There are $5C3$ ways to choose 4 colours. There are 2 ways to arrange the colours: by placing the two identical colours diagonal to each other, or adjacent to each other. In the first case, there is only unique way to place all the colours. In the second case, there are 2 ways: we can swap the positions of the two unique colours. So we have $5C3  * (2+1)$ ways. Case where there are 2 colours: There are $5C2$ ways to choose 2 colours. There are 2 ways to arrange the colours: by placing each pair diagonal to each other, or adjacent to each other. So we have $5C2  * (2)$ ways. Case where there is 1 colour: There are 5 ways. So we have a total of 85 ways. Given this, could someone explain where I have gone wrong, and what's the correct way to solve this with casework? Thanks in advance.","['combinations', 'combinatorics', 'discrete-mathematics']"
3658066,Prove $\cos 20^\circ \cos 40^\circ \cos 80^\circ= \frac18$ geometrically,"I understand the wizardry that $\cos 20^\circ \cos 40^\circ  \cos 80^\circ=\dfrac18$ Proving it isn't that hard. Taking the left hand side and multiplying it up and down by $\sin 20$ yields: \begin{align} 
& \dfrac{\sin 20^\circ}{\sin 20^\circ} \cdot \cos 20^\circ \cos 40^\circ \cos 80^\circ \\ 
=&\dfrac{\sin 40^\circ}{2\sin 20^\circ} \cdot  \cos 40^\circ \cos 80^\circ \\ =& \dfrac{\sin 80^\circ}{4\sin 20^\circ} \cdot \cos 80^\circ \\ =& \dfrac{\sin 160^\circ}{8\sin 20^\circ}=\dfrac{\sin 20^\circ}{8\sin 20^\circ}=\boxed{\dfrac{1}{8}}
 \end{align} My question is, is there a geometric proof of this, or the corollary $\sin 10 \sin 50 \sin 70^\circ$ ? Inspired by the possibility from this other indentity I'm hoping that it's possible. I tried doing a similar construction as in the link that didn't go so well, mainly because of my repeated use of the cosine rule. Is my quest achievable? Thanks for any guidance and advice.","['trigonometry', 'geometry']"
3658075,Critical points of $f(x)=\int_{x}^{x^2} e^{-{t^2}}dt$?,I understand that you need to take derivative of $f(x)$ and $f'(x)$ needs to be either equal to zero or undefined to find $f(x)$ 's critical points. However what happens if $f(x)$ is given as an integral as in the title? $$\frac{d}{dx} \int_{x}^{x^2} e^{-{t^2}}dt = F'(x^2)2x - F'(x)$$ $$F'(x^2)2x - F'(x)= 2xe^{-{x^4}} - e^{-{x^2}}$$ Is the calculation above correct for the question on the title? What should I do next? Thank you.,"['integration', 'derivatives']"
3658082,An explicit formula for conditional expectations via differentiation theorem,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. Let $Z:\Omega\to[0,\infty)$ be a bounded random variable. Let $(\mathcal{W},d)$ be a metric space and $W:\Omega \to \mathcal{W}$ be a random variable. Suppose that the differentiation theorem holds w.r.t. each measurable bounded $\varphi: \mathcal{W}\to[0,+\infty)$ and $\mathbb{P}_W$ , i.e. for $\mathbb{P}_W$ -a.e. $w \in \mathcal{W}$ it holds that $\forall r>0$ , $\mathbb{P}_W(\bar{B}_r(w))>0$ ; $\frac{1}{\mathbb{P}_W \big(\bar{B}_r (w)\big)} \int_{\bar{B}_r (w)} \varphi \operatorname{d}\mathbb{P}_W \to \varphi(w), r \to 0^+$ for $\mathbb{P}_W$ -a.e. $w \in \mathcal{W}$ ; where, for each measurable $A \subset \mathcal{W}$ , $\mathbb{P}_W$ is the probability measure defined on the Borel subsets of $(\mathcal{W},d)$ , whose value at $A$ is $\mathbb{P}(W\in A)$ , and $\bar{B}_r(w)$ is the closed ball of radius $r$ centered in $w$ . Is it true that \begin{equation*}
\lim_{r\to 0^+} \frac{\mathbb{E}_{\mathbb{P}}[Z \cdot \mathbb{I}_{\bar{B}_r(w)}(W)]}{\mathbb{P}_W(\bar{B}_r(w))}
\end{equation*} exists for $\mathbb{P}_W$ -a.e. $w \in \mathcal{W}$ and that \begin{equation*}
\Bigg(w\mapsto \lim_{r\to 0^+} \frac{\mathbb{E}_{\mathbb{P}}[Z \cdot \mathbb{I}_{\bar{B}_r(w)}(W)]}{\mathbb{P}_W(\bar{B}_r(w))}\Bigg) \circ W = \mathbb{E}_{\mathbb{P}}[Z|W]?
\end{equation*} I proved that the results holds true if we can find a measurable space $(\mathcal{V},\mathcal{F}_{\mathcal{V}})$ and a random variable $V: \Omega \to \mathcal{V}$ such that $V$ and $W$ are $\mathbb{P}$ -independent and there exists a measurable $f:\mathcal{V}\times \mathcal{W} \to [0,+\infty)$ such that $Z = f(V,W)$ . However, there exist cases where this type of factorization isn't possible, so... what about the general case?","['conditional-probability', 'conditional-expectation', 'probability-theory', 'geometric-measure-theory']"
3658087,If continuity condition is necessary for Miklós Schweitzer 2015 Problem 8,"Update : The continuity condition is necessary, according to Ian Morris's comment in https://mathoverflow.net/questions/269064/for-a-continuous-function-f-mathbbr-to-mathbbr-does-fx-fy . Miklós Schweitzer Competition 2015 Problem 8: Problem 1 : Prove that all continuous solutions of the functional equation $$[f(x) - f(y)]\left(f(\tfrac{x+y}{2}) - f(\sqrt{xy})\right) = 0, \forall x, y \in (0, +\infty)$$ are the constant functions. http://www.math.u-szeged.hu/~mmaroti/schweitzer/schweitzer-2015-eng.pdf https://artofproblemsolving.com/community/c6h1224690p6149915 https://mathoverflow.net/questions/269064/for-a-continuous-function-f-mathbbr-to-mathbbr-does-fx-fy To make the domain and range of $f$ clear ( Thank @Calvin Lin for his valuable comments ), I rephrased the problem above as follows. Problem 1 (rephrased) : Let $f : \ (0, \infty) \to \mathbb{R}$ be a continuous function satisfying $$[f(x) - f(y)]\left(f(\tfrac{x+y}{2}) - f(\sqrt{xy})\right) = 0, \forall x, y \in (0, +\infty).$$ Prove that $f$ is the constant function. My question : If the continuity condition on $(0, \infty)$ is necessary? Any comments are welcome and appreciated. The solutions in the 2nd link above use the continuity condition.
Terry Tao's proof in the 3rd link above also use the continuity condition.
My solution (at the end) requires the continuity condition as well. On the other hand, the continuity condition is not necessary
for the following problem (from a math exam): Problem 2 : Let $f : (0, \infty) \to (0, \infty)$ be a continuous function satisfying $f(\tfrac{x+y}{2}) - f(\sqrt{xy}) = 0,\ \forall x, y > 0$ .
Find all $f$ . Solution for Problem 2 : $f$ is the constant function. For any $0 < b < a$ , let $x = a + \sqrt{a^2 - b^2}$ and $y = a - \sqrt{a^2 - b^2}$ .
We have $f(a)=f(b)$ . [Remark: We do not use the continuity condition in the proof.] My solution for Problem 1 : Assume, for the sake of contradiction, that $f$ is not the constant function.
WLOG, assume there exist two real numbers $0 < A < C$ with $f(A) < f(C)$ .
Since $f$ is continuous, there exists $A < B \le C$ such that $f(x) < f(B)$ for all $x$ in $[A, B)$ . Consider the sequence $$x_1 = \sqrt{AB}; \ x_{k+1} = \frac{x_k^2 + B^2}{2B}, \ k\ge 1.$$ By using Mathematical Induction, it is easy to prove that $x_k < x_{k+1} < B$ for all $k \ge 1$ . Thus, $\lim_{k\to \infty} x_k$ exists.
Let $L = \lim_{k\to \infty} x_k$ . Then, $L = \frac{L^2 + B^2}{2B}$ and $L = B$ . Thus, $\lim_{k\to \infty} x_k = B$ . Denote $a = x_{k+1}, b = x_k$ ( $k\ge 1$ ).
Let $X = a - \sqrt{a^2 - b^2}$ and $Y = a + \sqrt{a^2 - b^2}$ .
It is easy to verify that $X < Y$ , $Y = B$ , $\frac{X+Y}{2} = a$ , and $\sqrt{XY} = b$ .
Thus, $X = \frac{b^2}{Y} \ge \frac{x_1^2}{B} = A$ .
Thus, $f(X) - f(Y) \ne 0$ . From $[f(X) - f(Y)] [f(\frac{X+Y}{2}) - f(\sqrt{XY})] = 0$ ,
we have $f(a) = f(b)$ , i.e., $f(x_k) = f(x_{k+1})$ for all $k \ge 1$ .
Thus, $f(x_k) = f(x_1) = f(\sqrt{AB})$ for all $k \ge 1$ . Since $f$ is continuous, we have $f(B) = f(\lim_{k\to \infty} x_k) = \lim_{k\to \infty} f(x_k) 
= f(\sqrt{AB})$ . Contradiction.","['contest-math', 'functional-equations', 'real-analysis']"
3658106,Is this function involving square root smooth?,"Let $\psi:[0,1] \to \mathbb{R}$ be a concave, smooth, strictly increasing function satisfying $\psi(0) = 0$ , $\psi(1) = 1$ and $\psi'(0)>1$ . Assume further that $\psi$ is linear in a neighbourhood of zero , and set $c = 2\psi'(0)$ . Note that the assumptions $\psi'(0)>1,\psi(1)=1$ imply that $\psi$ cannot be linear up to $r=1$ -it must become strictly concave at some point. Set $t_0=\sup\{ \psi'(r)+\frac{\psi(r)}{r}=c\}$ . Question: Is $f(r)=\sqrt{c^2-(\psi'(r)+\frac{\psi(r)}{r})^2}$ infinitely differentiable at $t_0$ ? As I explain below, $f(r)=0$ for every $r\le t_0$ . So, this is equivalent to asking whether all the right the derivatives of $f(r)$ exist and are equal to zero at $t_0$ . Here are the details: First, we note that the function $g(r)= \psi'(r)+\frac{\psi(r)}{r}$ is non-increasing, due to the concavity of $\psi$ (see a proof at the end). Also, $\lim_{r \to 0}g(r)=2\psi'(0)=c$ . These facts implies that $g(r) \le c $ for every $r>0$ , and that $g(r)=c$ on $[0,t_0]$ . Equivalently, $\psi|_{[0,t_0]}$ is the solution to the ODE $y(r)'+y(r)/r=c$ which implies that $\psi(r)$ is linear on $[0,t_0]$ . The fact that $g(r)$ is non-increasing implies that $g(r)<c$ for every $r>t_0$ . As explained in this partial answer , the smoothness of $\psi$ implies that $$\sqrt{c^2 - \left(\psi'(t_0+h) + \frac{\psi(t_0+h)}{t_0+h}\right)^2} = o(h^n),$$ for any $n>1$ . However, unfortunately, this fact alone does not imply that this creature is smooth at $t=t_0$ . A proof that $g(r)$ is non-increasing: $$
g'(r)=\psi''(r)+\frac{1}{r}(\psi'(r)-\frac{\psi(r)}{r}),
$$ and both summands are non-positive. $\psi'' \le 0$ by concavity. Since $\psi(r)=\int_0^r \psi'(t)dt \ge \int_0^r \psi'(r)dt=r\psi'(r)$ , the second summand is also non-positive.","['singularity', 'real-analysis', 'calculus', 'derivatives', 'convex-analysis']"
3658187,Results on $2^{p-1}\equiv1\pmod{p^4}$,https://en.wikipedia.org/wiki/Wieferich_prime says: H. S. Vandiver proved that $2^{p−1}\equiv1\pmod{p^3}$ if and only if $$1+\frac 13+\cdots+\frac1{p-2}\equiv0\pmod{p^2}.$$ Is there a similar result for $2^{p−1}\equiv1\pmod{p^4}$ ?,['number-theory']
3658196,"Show that two open balls with respect to different metrics (and different radii) on $[0,1)$ coincide","Let $e$ be the Euclidian metric on $\mathbb{R}$ . That is, $$e(x,y):=|x-y|.$$ We define another metric $d$ on $[0,1)$ by $$d(x,y):=\inf_{k\in\mathbb{Z}}|x-y+k|.$$ For $N\in\mathbb{N}$ we can define a map $f\colon[0,1)\to[0,1)$ by $$f_{N}(x):=Nx-\lfloor Nx\rfloor.$$ I want to compare orbits of points in $[0,1)$ with respect to $d$ . For $x,y\in[0,1)$ we can compare their orbit segments $$\{x,f_{N}(x),f_{N}^{2}(x),\ldots,f_{N}^{n}(x)\}\qquad\text{and}\qquad\{y,f_{N}(y),f_{N}^{2}(y),\ldots,f_{N}^{n}(y)\}$$ of length $n\in\mathbb{N}\cup\{0\}$ with another metric $d_{n}$ on $[0,1)$ defined by $$d_{n}(x,y):=\max_{0\leq i\leq n}d(f_{N}^{i}(x),f_{N}^{i}(y)).$$ Suppose that $0<\delta\leq1$ . I want to prove that for all $x\in [0,1)$ , $$B_{d_{n}}(x,\delta)=B_{e}(x,\delta/2N^{n})\mod1.$$ Here $B_{\text{metric}}(\text{point},\text{radius})$ denotes an open ball with respect to the metric in the subscript. I was hoping to prove "" $\supset$ "" with one of my previous posts , but I didn't really succeed. I'm really struggling with the infimum in the definition of $d$ . Any help would be greatly appreciated. Thanks in advance!","['epsilon-delta', 'metric-spaces', 'geometry', 'real-analysis', 'general-topology']"
3658214,"Does every number base have at least one ""Baseless number""?","Definition & questions Every number $a\in\mathbb N$ can be written in some integer number base $b\ge 2$ using $d$ -digits: $$\begin{align}
a
&=\overline{(a_1,a_2,\dots ,a_{d-1},a_{d})}_b\\
&=a_1b^{d-1}+a_2b^{d-2}+a_3b^{d-3}+\dots+a_{d-2}b^2+a_{d-1}b^1+a_{d}b^0\\
&=(((\dots(((a_1)b+a_2)b+a_3)b+\dots)b+a_{d-2})b+a_{d-1})b+a_{d}
\end{align}$$ If we multiply the last expression by $b$ , then replace all $b$ 's with $a_1,\dots,a_d$ , we get $f_b(a)$ . (We replaced the multiplications with the $\text{base}$ , with multiplications with the $\text{digits}$ .) If it holds $a=f_b(a)$ , then we call number $a$ an "" Baseless number (in base $b$ )"". For example, $8385$ is a $4$ -digit Baseless number in base $10$ (decimal number base), because: $$
8385=((((8)\color{red}{10}+3)\color{red}{10}+8)\color{red}{10}+5)=((((8)\color{blue}{8}+3)\color{blue}{3}+8)\color{blue}{8}+5)\color{blue}{5}=f_{10}(8385)
$$ From now on, assume $a\ge2$ because $1$ is trivially baseless in all number bases. I have two questions. Firstly and mainly, $1.$ Existence : Does every number base $b\ge 4$ contain at least one Baseless number? Status: Currently $b=107$ is the smallest base with no known examples. Secondly and supplementary, $2.$ Solving decimal base : Is number $8385$ the only decimal Baseless number? Solved: This was now proven to be true by an exhaustive search. $2.$ Baseless numbers in decimal number base Is number $8385$ the only decimal Baseless number? I've checked this up to $10^{10}$ so far, and found no other examples. Scatter-plotting the ""error"" $E_{10}(a)=(a-f_{10}(a))$ for $a\in[1, 10^6]$ we have: A graph filled with Waterfall structures. Can we prove that $E_{10}(a)\ne 0$ for all $a\ge 2$ other than $a=8385$ ? I have looked at which point will $E(a)\gt 0$ for all $a\gt a_0$ for some $a_0$ : We know that $f_{b}(a)$ of a $d$ -digit number is at most $u_b(d)=\sum_{i=1}^{d+1}(b-1)^{i}$ , the case when all digits are set to $(b-1)$ , the largest base $b$ digit. We also know that a $d$ -digit number is at least $l_b(d)=b^{d-1}$ . But notice that we can't have a zero digit in the number $a$ because then $f_b(a)$ automatically has less digits than $a$ , so we can improve the lower bound to $l_b(d)=\sum_{i=1}^{d}b^{d-i}$ . Hence, we try to find all $d$ for which $u_b\lt l_b$ . For $b=10$ we have: $$\frac98 (-1 + 9^{d+1})\lt\frac19 (-1 + 10^d) \space\space\text{ if }\space\space d\gt 42.8266$$ That is, we know that if $a$ has $d\ge43$ digits, then $f_{10}(a)$ has less than $d$ digits. In other words, we have $f_{10}(a)\lt a$ , implying $E_{10}(a)\gt 0$ for all $a\ge 10^{42}$ . This means if there is a second solution for the decimal number base, it must be $a \lt 10^{42}$ . That is, so far I have that if there is a second example, it is $a\in[10^{10},10^{42}]$ . Can we somehow lower this bound or remove significant families of numbers from it? Update: Turns out an exhaustive computer search is possible on small bases. All number bases $b\le 13$ are solved now. I've posted this result as my own partial answer. $1.$ Existence in other number bases It is not hard to see that $b=2$ has no examples, and for $b=3$ we can prove there are no examples by checking all numbers up to $10^5$ . (Following the bound given in the previous section, larger numbers than this have $E_3(a)\gt 0$ ). Hence from now on, assume $b\ge 4$ . Does every number base $b\ge 4$ contain at least one Baseless number? It appears every base has a very small amount in total, if any. Generally, to solve for all $d$ digit examples in base $b$ , we have the Diophantine equation: $$
a=\sum_{i=1}^{d} a_{i}b^{d-i} = \sum_{i=1}^{d}a_i^2\prod_{j=i+1}^da_j = f_b(a)\tag{$\star$}
$$ In digits $0\lt a_1,\dots,a_d\lt b$ . The question is now, is it true that: For all $b\ge 4$ there exists $d\ge 2$ such that $(\star)$ has at least one solution for the digits? For example, if the number base is a perfect square $b=r^2$ , then we have a trivial $2$ -digit example: $$
a=\overline{(1,\sqrt{b})}_b=((1) b+\sqrt{b})=((1) 1 + \sqrt{b})\sqrt{b}=f_b(a)
$$ This is because if we set $d=2$ in $(\star)$ we get $a_1b + a_2 = a_1^2a_2+a_2^2$ . Now specially for $a_1=1$ it reduces to $a_2^2=b$ implying that if $b$ is a perfect square, then the number $\overline{(1,\sqrt{b})}_b=b+\sqrt{b}$ is a Baseless number in the base $b$ . If we look at $d=2$ in general, all solutions below base $100$ are in this pastebin table $(d=2)$ . If we look at $d=3$ , almost all bases below $100$ have one or more $3$ -digit Baseless number examples. You can see the list of all solutions in this pastebin table $(d=3)$ . And so on. But does every base $b\ge 4$ have at least one solution for at least one $d\ge 2$ ? I started searching for ""smallest example per number base"". The record bases with next largest smallest example are: (Thank you nickgard .) base    example         digits in base
4       6               [  1,  2  ]
5       12              [  2,  2  ]
6       160             [  4,  2,  4  ]
7       324             [  6,  4,  2  ]
8       405             [  6,  2,  5  ]
10      8385            [  8,  3,  8,  5  ]
18      25215           [  4,  5,  14, 15 ]
24      323844          [  23, 10, 5,  12 ]
32      1038448         [  31, 22, 3,  16 ]
43      1593074855      [  10, 35, 41, 39, 11, 19 ]
73      25683204625     [  12, 28, 28, 56, 52, 65 ]
107     ?               ? The smallest example for base $107$ is $a \gt 107^{6}\gt 1.5\cdot 10^{12}$ , so far. Other bases below $500$ that do not have any examples below $10^{10}$ are: 191,227,307,331,373,386,398,411,421,431,467,471,485 For bases below $500$ with known smallest solutions, see this pastebin table . Is it possible to optimize the search for the smallest Baseless number in some base $b$ ?","['number-theory', 'examples-counterexamples', 'diophantine-equations', 'number-systems', 'recreational-mathematics']"
3658251,Existence of Borel measurable argmax-function given semicontinuity,"Let $\mathcal{S}$ and $\mathcal{A}$ be standard Borel (that is, a Polish space endowed with the sigma algebra generated by the open sets its metric topology), and $\mathcal{A}$ be compact. Suppose $f : \mathcal{S} \times \mathcal{A} \to \mathbb{R}$ is upper semicontinuous. Then the set $A_s = \mathrm{argmax}_{a \in \mathcal{A}} f(s, a) \neq \emptyset$ is non-empty for any $s \in \mathcal{S}$ . Q : Does there exist a measurable function $\phi : \mathcal{S} \to \mathcal{A}$ such that $\phi(s) \in A_s$ for all $s \in \mathcal{S}$ ? By axiom of choice one may pick at least one function $\psi : \mathcal{S} \to \mathcal{A}$ with $\psi(s) \in A_s, \;\forall s \in \mathcal{S}$ .
However I am lost as to how to know if any such function can be chosen to be measurable.","['continuity', 'measure-theory']"
3658375,Chow group of a DVR,"I need a sanity check on the following: If $A$ is a DVR then $CH_0(A) = 0$ . The proof is simple. A 0-dimensional cycle is of the form $Z= n \cdot [s]$ , where s is the closed point of $\operatorname{Spec} A$ . Let $\pi$ be a uniformizer of $A$ . Then $div(\pi^n) = length_A(A/(\pi^n))\cdot [s] = n \cdot [s]$ . Hence $CH_0(A) = Z_0(A)/R_0(A) = 0$ . Is this correct?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3658398,Prove that $A^{(\omega)}\nleq_T A^{(n)}$,"I am trying to solve Exercise 7.1.24 (i) of Computability Theory by Rebecca Weber . $A^{(n)}$ denotes the $n$ -th Turing jump and $A^{(\omega)}=\{\langle x,n\rangle: x\in A^{(n)}\}$ the $\omega$ -jump. I am able to prove that $A^{(n)}\leq_T A^{(\omega)}$ . Since $x\in A^{(n)}\Leftrightarrow \langle x,n\rangle\in A^{(\omega)}$ we get that $\chi_{A^{(n)}}(x)=\chi_{A^{(\omega)}}(x,n)$ , which is computable. Hence, $A^{(n)}$ is $A^{(\omega)}$ -computable, i.e. $A^{(n)}\leq_T A^{(\omega)}$ . I now want to show that $A^{(\omega)}\nleq_T A^{(n)}$ . My idea was to use the Jumping Theorem which says that $A^{(n+1)}\nleq_T A^{(n)}$ but I couldn't find a way to do so.","['turing-machines', 'logic', 'discrete-mathematics', 'computability']"
3658404,If $f(z)=\sum c_nz^n$ is an entire function of finite genus $\mu$ then $\lim_{n\to\infty}c_n(n!)^{1/(\mu+1)}=0$,"If $f(z)=\sum c_nz^n$ is an entire function of finite genus $\mu$ then prove that $$\lim_{n\to\infty}c_n(n!)^{1/(\mu+1)}=0.$$ I know that if $f$ is an entire function of finite genus $\mu$ , then $f$ is of finite order $\lambda\leq\mu+1$ . In particular, I have $|f(z)|\lt \exp(|z|^{\beta})$ holds for all large enough $|z|$ , where $\beta=\mu+1$ . Now, using a previous estimate , I get $$|c_n|\leq \Bigl(\frac{e\beta}{n}\Bigl)^{n/\beta}$$ for all large enough $n$ . Thus, $$\begin{align*}
|c_n|(n!)^{1/\beta}
&\leq \Bigl(\frac{e\beta}{n}\Bigl)^{n/\beta}(n!)^{1/\beta}\\
&\sim \Bigl(\frac{e\beta}{n}\Bigl)^{n/\beta}\Bigl(\sqrt{2 \pi n} \left(\frac{n}{e}\right)^n\Bigl)^{1/\beta}\\
&=\beta^{n/\beta}(2 \pi n)^{1/2\beta}.
\end{align*}$$ However, this doesn't help much. I don't think $\beta^{n/\beta}(2 \pi n)^{1/2\beta}$ converges to $0$ . Now, if I just use the Cauchy's estimate, I have \begin{align*}
|c_n|(n!)^{1/\beta}&\leq \frac{\exp(n^{\beta})}{n^n} (n!)^{1/\beta}\\
&\sim \frac{\exp(n^{\beta})}{n^n}\Bigl(\sqrt{2 \pi n} \left(\frac{n}{e}\right)^n\Bigl)^{1/\beta}\\
&=(2 \pi)^{1/2\beta}\exp(n^{\beta}-n/\beta)n^{n/\beta+1/2\beta-n}.
\end{align*} I don't have much experience in computing estimates. Can someone help me out to complete any of the arguments? This is Exercise $2.1$ from Chapter ${\rm XI}$ of Conway's functions of one complex variable . The hint given is to use the Cauchy's estimates . I found this AoPS post using approach0 , however, they mistook the genus for the order. Also, the definition of the ""genus""(order) mentioned in the above post comes only after this exercise in Conway(Exercise $2.5$ ). Here's the definition of the order Conway uses: Definition. An entire function $f$ is of finite order if there is a positive constant $a$ and an $r_0\gt0$ such that $|f(z)|\lt \exp(|z|^a)$ for $|z|\gt r_0$ . If $f$ is of finite order, then $$\lambda=\inf\{a\mid |f(z)|\lt \exp(|z|^a)\,\text{for $|z|$ sufficiently large}\}$$ is called the order of $f$ . Equivalently, $$\lambda=\limsup_{r\to\infty}\frac{\log\log M(r)}{\log r},$$ where $M(r)=\max\{|f(z)|\mid|z|=r\}$ . Of course, all three are equivalent, but I would like to see a proof using the hint and the above two definitions.","['complex-analysis', 'entire-functions', 'asymptotics']"
3658435,Can the image of a cardinality function be a set?,"Let a function f(x)=|x|, where the domain is that x is an element of the power set of {2, 3, 4, 5}. Since any input into the function could result in a cardinality from 1-4, could you say that the range/image of function f(x) is {1, 2, 3, 4} since the only possible cardinalities are from 1-4?","['cardinals', 'functions']"
3658583,"$h:[0,1] \to\mathbb{R}$ continuous, and ivt","The question is as follows: $$ \text{Supposd } h:[0,1] \rightarrow \mathbb{R} \text{ is continuous. Show that there exist } w \in [0,1] \text{ such that}
\\h(w)= \frac{w+1}{2}h(0)+\frac{2w+2}{9}h(\frac{1}{2})+\frac{w+1}{12}h(1)$$ I know that I have to use Intermediate Value Theorem and I have to show $h(w)$ lies between $h(0)$ and $h(1)$ , but I have no idea how to prove it. I have tried to separate $h(w)$ into $\frac{w+1}{2}h(0)+\frac{w+1}{9}h(\frac12)+\frac{w+1}{9}h(\frac12)+\frac{w+1}{12}h(1)$ and then use IVT twice on the interval $[0,\frac12]$ and $[\frac12,1]$ but it seems not working. I have also tried to see if $h$ is an interpolation of 3 points but it also fails.","['continuity', 'calculus', 'analysis', 'real-analysis']"
3658590,Understanding Epsilon-Delta Proof,"I'm trying to understand the proof of the following limit using epsilon-delta definition. $$\lim _{x\to3} x^2 = 9$$ In Stewart Calculus, the proof goes like this: I'm confused at the following points: 1) How the author arrives at this result: $|x-3| < \varepsilon/C = \delta$ ? Specifically, how, $$|(x+3)(x-3)| < \varepsilon$$ and $$|(x+3)(x-3)| < C|(x-3)|$$ leads to $$|x-3| < \varepsilon/C = \delta.$$ This is the part I've trouble understanding. 2) What's the role played by $\delta=\min(1, \varepsilon/7)$ ? I am trying to understand this epsilon-delta proofs for a week but to no avail.","['limits', 'calculus', 'proof-explanation', 'epsilon-delta']"
3658659,Effect of adding a matrix to both numerator and denominator of a ratio between determinants of two matrices,"Assume matrix $A$ is symmetric and positive definite, and matrices $B$ and $C$ are symmetric and positive semi-definite. Originally I have ratio between determinants $$\frac{\det(A+B)}{\det(A)}$$ which is obviously greater than or equal to 1. How would this ratio change (increase or decrease) when I add another matrix $C$ inside the determinant on both numerator and determinator, as follows? $$\frac{\det(A+B+C)}{\det(A+C)}$$ My intuition is that $$\frac{\det(A+B+C)}{\det(A+C)} \leq \frac{\det(A+B)}{\det(A)}$$ but I haven't been able to prove this. Any insight on this is appreciated!","['matrices', 'determinant', 'linear-algebra', 'eigenvalues-eigenvectors']"
3658685,Is Geometric Algebra/Geometric Calculus all that it's hyped up to be? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question There appears to be a cult following of geometric algebra/geometric calculus (GA/GC) as developed by David Hestenes. Many questions on stack exchange regarding this. I wanted to make this question different than others, this question hopes to bring together many mathematicians whom can contribute to the discussion of the validity of the claims and soundness of GA/GC. I want to ask the mathematicians here on stack exchange what they know and what they think about GA/GC. The claims are always as follows, GA/GC provides a unified formalism for physics and mathematics. It provides a framework which unifies many of the concepts in fields of mathematics such as differential geometry, algebra and many more.... Why are theoretical physicists/mathematicians not rushing into this field? If it was so universal and apparently simpler to learn (also as claimed), then why is it not as widespread? Now most textbooks and articles on this subject give the answer that Clifford developed this formalism concurrently with Gibbs standard formalism for vector calculus. Gibbs was a famous physicists/mathematician and worked at Princeton and so it is the reason his approach was so widespread and Cliffords approach was swept under the rug. Not until David Hestenes revived it, and now there are many descendants/followers of his whom repeat what I just said in the introduction or preface to their book or article. A prolific follower and firm believer of GA/GC is Alan MacDonald a professor of mathematics at Luther College in Decorah, IA. He wrote the following article (there are MANY more by other authors). https://www.astro.umd.edu/~jph/GAandGC.pdf Just read the introduction paragraph and this is generally the type of introduction which comes from most articles and books on GA/GC. It is basically a rephrasing of what Hestenes said in his pioneering work and books on GA/GC, such as his book Space-Time Algebra. I need honest opinions from reputable mathematicians all over. It is important for us to get feedback from mathematicians outside the field of GA/GC because it seems the only people HIGHLY RECOMMENDING using GA/GC are only those who are using it exclusively. It would be good to get many opinions from mathematicians in fields related to GA/GC, such as Differential Geometry, Mathematical Physicists who make extensive use of Differential Geometry, Modern Algebraic Geometers, algebraists.... I know it is difficult for someone to comment on other mathematicians work, but when something makes such big claims as Unifying much of mathematics and physics, it is important for the community to discuss this, so that opinions and ideas are shared and cult following is either justified or unjustly spreading. I am not against GA/GC, I am curious and want to know what other professional mathematicians think of this field and their claims. Please spread this article around so that others can make their comments and we can either begin to embrace GA/GC or refute its claims. Thank you.","['multilinear-algebra', 'abstract-algebra', 'geometric-algebras', 'mathematical-physics', 'differential-geometry']"
3658810,Total internal solid angle of a convex polyhedron,The total internal angle of a convex polygon with n sides is $(n-2)\pi$ . Is there an analogous formula for the total solid angle of a convex polyhedron?,['geometry']
3658830,Existence theorem for the SIR epidemic differential equations,"Well these days, everybody is talking about the epidemic model SIR
which is given by the following differential equation: $$
\begin{cases}
S'(t)=-aS(t)I(t)\\
I'(t)=aS(t)I(t)-bI(t)\\
R'(t)=bI(t)\\
S(0)>0,I(0)>0
\end{cases}
$$ We can see that $S'(t)+I'(t)+R'(t)=0$ , so $S(t)+I(t)+R(t)=N$ is
a constant. Thus this model reduces to two differential equations: $$
\begin{cases}
S'(t)=-aS(t)I(t)\\
I'(t)=aS(t)I(t)-bI(t)\\
S(0)>0,I(0)>0
\end{cases}
$$ All the studies I saw start with the fact that a solution of this
model is global (defined on $[0,\infty)$ ) and positive. So I wanted
to prove that this differential equation has a global solution. However
I see that this cannot be done by the global Lipschitz Picard-Lindelöf/contraction
theorem, since the function $$
f(x,y)=\left(-axy,axy-by\right)
$$ is not globally Lipschitz. How can we prove the existence of a global
solution and its positivity?","['lipschitz-functions', 'ordinary-differential-equations', 'real-analysis']"
3658881,Lipschitz function and uniform convergence,"I am struggling with the proof of the following theorem: 
Let $(f_n)$ be a sequence of differentiable functions in a closed and bounded set $[a,b]$ s.t. $(f_n(x))$ is convergent for each $x\in [a,b]$ and, for a constant $M\geq0$ , we have $|f_n^{'}(x)|\leq M$ $\qquad$ $\forall n\in\Bbb{N}$ , $\forall x\in [a,b]$ Prove that $(f_n)$ is uniformly convergent in $[a,b]$ ... I tried with this: as a consequence of the Lagrange Theorem we have that if $f_n$ is continuous and differentiable in a closed and bounded set and $f_n'$ is bounded then $f_n$ is Lipschitz.
Then $|f_n(x_1)-f_n(x_2)|\leq |f_n^{'}(x) ||x_1-x_2|\leq M(x_1-x_2)<\epsilon$ $\quad$ whenever $|x_1-x_2|<\delta$ . 
Thus $(f_n)$ is uniformly continuous. Is this right? and from this how can I prove that $f_n$ is uniformly convergent?","['lipschitz-functions', 'derivatives', 'uniform-convergence', 'real-analysis']"
3658916,Why does the solution to our system imply the origin is a nonlinear center?,"Can someone please tell me why our solution implies the origin is a nonlinear center? Thank you for your time and help! Consider the system $$x'=-y-x^2$$ $$y'=x.$$ Find a reversor $S$ , identify Fix $(S)$ and show that the origin is a nonlinear center. $\textbf{Solution:}$ $S(x,y) = \begin{pmatrix} -x \\ y \end{pmatrix}$ is a reversor for our system. Sending $x\to -x, y\to y,$ and $t\to -t$ we get $-(-x') = -y-(-x)^2 \implies x' = -y - x^2$ and $-y' = -x \implies y'=x.$ If $\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} -x \\ y \end{pmatrix}$ then $\begin{pmatrix} x \\ y \end{pmatrix} \in$ Fix $(S)$ . So, Fix $(S)$ $$= \left \{\begin{pmatrix} 0 \\ y \end{pmatrix}\colon y \in \mathbb{R} \right\}.$$","['nonlinear-system', 'manifolds', 'ordinary-differential-equations', 'dynamical-systems']"
3658930,Mixing logical and mathematical notation when negating statements,"Working through Hammack's Book of Proof I have come at an impasse. Exercise 3 of Section 2.10 requires that you negate proposition (1). The answer that naturally follows and is confirmed by the book's solutions is proposition (2). (1) For every prime number $p$ , there is another prime number $q$ with $q > p$ . (2) There is a prime number $p$ such that for every prime number $q$ , $q \leq p$ . This makes sense given the notation given by the book up to now. Assuming a set of all the prime numbers, $P$ , the negation of $$\forall p, p \in P, \exists q, q \in P, q > p$$ is simply $$\exists q, q \in P, \forall p, p \in P, q \leq p$$ As if the negation proceeded as follows: $$\neg (\forall p, p \in P, \exists q, q \in P, q > p)$$ $$\exists p, p \in P, \neg(\exists q, q \in P, q > p)$$ $$\exists q, q \in P, \forall p, p \in P, \neg (q > p)$$ $$\exists q, q \in P, \forall p, p \in P, q \leq p$$ I say ""as if"" because here comes my question: I also want to express these two propositions using nothing but logical operators. However I cannot seem to do it in a satisfactory way. Take the above sentences, using the glossary: $P(x)$ : $x$ is a prime number $L(x, y)$ : $x$ is larger than $y$ The two sentences look like they should have the similar translations, as apart from the negated quantifiers and the negated last predicate, they both share the same shape. However I cannot find a good translation that suits this constraint. For example, if (1) is taken to mean $$\forall p \exists q ((P(p) \land P(q)) \rightarrow L(p, q))$$ then (2) should be $$\exists p \forall q ((P(p) \land P(q)) \rightarrow \neg L(p, q))$$ but this cannot be as the negation of (1): $$\exists p \forall q ((P(p) \land P(q)) \land \neg L(p, q))$$ is not the same as (2). If (1) is taken to mean $$\forall p \exists q (P(p) \land P(q) \land L(p, q))$$ then (2) should be $$\exists p \forall q (P(p) \land P(q) \land \neg L(p, q))$$ which is not the same as the negation of (1) which is $$\exists p \forall q (\neg P(p) \lor \neg P(q) \lor \neg L(p, q))$$ and so on. What am I missing?","['elementary-set-theory', 'translation-request', 'first-order-logic', 'logic-translation']"
3658968,Differential of a linear map between matrix spaces,"This bit of text comes from Lee's Introduction to Smooth Manifolds. I don't see why (8.15) holds. Note first of all that Lee assumes the Einstein summation convention, while I will not in my formulation. I would think that we have $$
A^L\vert_X=\sum_{i=1}^n\sum_{j=1}^n X^i_j A^i_j\frac\partial{\partial X^i_j}\bigg\vert_X,
$$ instead of $$
A^L\vert_X=\sum_{k=1}^n\sum_{i=1}^n\sum_{j=1}^n X^i_j A^j_k\frac\partial{\partial X^i_k}\bigg\vert_X,
$$ since I think it holds that $$
d(L_X)_{I_n}\left(\frac\partial{\partial X^i_j}\bigg\vert_{I_n}\right)=X^i_j\frac\partial{\partial X^i_j}\bigg\vert_X.
$$ I argued this using the coordinate reprsentation of the differential, which is given for an arbitrary smooth map $F\colon M\to N$ by $$
dF_p\left(\frac\partial{\partial x^i}\bigg\vert_p\right)=\frac{\partial\hat F^i}{\partial x^j}\bigg\vert_{\hat p}\frac\partial{\partial y^j}\bigg\vert_{F(p)},
$$ where $(x^i)$ are local coordinates for some open $U\ni p$ , and $(y^i)$ are local coordinates for some open $V\ni F(p)$ . Hence, if we take $(E^i_j)$ as our basis for $\operatorname M_n(\mathbb R)$ , then $E^i_j$ is mapped by $L_X$ to $X^j_i$ . And therefore $$
\frac{\partial(L_X)^i_j}{\partial x^k_l}=\delta_{ik}\delta_{jl} X^j_i.
$$ Note that also here, I don't assume Einstein summation convention. So I don't see why (8.15) holds... could someone clarify?",['differential-geometry']
3658977,Infinite bit strings with property,"For an element $x \in \{0,1\}^{\mathbb{Z}}$ , define $S(x) = \{ (x(i),x(i+1), \dots , x(i+r)) : i \in \mathbb{Z} , r \in \mathbb{N} \}$ , where $x(i)$ is the $i^{th}$ coordinate. $S(x)$ denotes arbitrary $\{0,1\}$ $r$ -tuples such that it matches a segment of $x$ . Find a sequence $\{ y_{n} \} \subseteq \{0,1\}^{\mathbb{Z}}$ such that $S(y_{1}) \supsetneq S(y_{2}) \supsetneq \dots \supsetneq S(y_{i}) \supsetneq S(y_{i+1}) \supsetneq \dots$ The idea I had was to consider $y_{1}$ such that $y_{1}$ only contains streaks of $1$ 's with prime length. Then I could define $y_{2}$ such that it avoids a particular prime length.",['discrete-mathematics']
3659124,Applications of fpqc descent of quasicoherent sheaves,"I have been learning about fibered categories and stacks from Vistoli's notes. One of the main results in the notes is the statement that the fibered category of quasicoherent sheaves over a scheme $X$ is a stack in the fpqc topology on the category of $X$ -schemes. I can appreciate that this is a surprising result, as quasicoherent sheaves are a priori constructed as a Zariski stack, and the fpqc topology is strictly finer than the Zariski topology. Incidentally, I also think the proof presented in the notes is good practice with the concepts he introduces. I am wondering about applications of this result, as they are not really mentioned in the notes. I am not familiar with descent theory outside of what is discussed in Vistoli, so I'm partly asking this to get a feel for the topic - a sort of ""what's next?"" The question: What are some examples of interesting results in which in some way use the fact that the fibered category of quasicoherent sheaves over a scheme is a stack in the fpqc topology?","['descent', 'algebraic-geometry', 'soft-question', 'quasicoherent-sheaves']"
3659146,Cohomology Groups of Projective Space and Sphere,"I am stuck on the following question from Switzer’s Algebraic Topology: Homotopy & Homology: Describe the cohomology groups of $\mathbb{R}P^2 \times \mathbb{R}P^2$ and $\mathbb{S}^m \times \mathbb{C}P^n$ for any integers $m,n$ greater than or equal to 1. I have been thinking hard about it since last two days, but I cannot think about cohomology groups of the product space of 2-dimensional real projective spaces nor the product of m-dimensional sphere and complex projective space...Could you help me out?","['geometric-topology', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
3659170,When an irreducible representation is an induced representation,"So I've been trying to answer this exercise to much of my frustration: Let $G$ be a finite group and $S$ a normal subgroup. Let $\rho$ be an irreducible representation of $G$ over $\mathbb{C}$ . Prove that either the restriction of $\rho$ to $S$ has all its irreducible components $S$ -isomorphic to each other, or there exists a proper subgroup $H$ of $G$ containing $S$ and an irreducible representation $\theta$ of $H$ such that $\rho \simeq \text{ind}_H^G(\theta)$ . Here is my progress so far: Let $E$ be a representation space for $\rho$ and $\chi_\rho$ the character. We also have the restriction $\text{res}_S^G(\rho)$ of our representation $\rho$ to $S$ . $\text{res}_S^G(E)$ is the representation space for this restriction. We pick a simple $S$ -submodule $F$ of $\text{res}_S^G(E)$ and realize that because $E$ is a simple $G$ -module, \begin{equation}
\text{res}_S^G(E)=\sum_i \gamma_i F
\end{equation} where $\{\gamma_i\}$ is a set of left coset representatives for $G/S$ . Also note that $S\trianglelefteq G$ implies that $\gamma_i F$ is an irreducible $S$ -submodule of $\text{res}_S^G(E)$ . If these submodules are $S$ -isomorphic to each other, then we have the first case. Now suppose otherwise. I am guessing that we are able to find a subgroup $S\subseteq H\subsetneq G$ and an irreducible character $\chi_\theta$ in the character decomposition of $\chi_{\text{res}_H^G(\rho)}$ such that $\text{ind}_H^G(\chi_\theta)$ is simple. We would then have \begin{equation}
\langle\text{res}_H^G \chi_\rho,\chi_\theta\rangle=\langle\chi_{\text{res}_H^G(\rho)},\chi_\theta\rangle\geq 1.
\end{equation} By Frobenius reciprocity, we would have $\langle \chi_\rho,\text{ind}_H^G(\theta) \rangle \geq 1$ , which implies $\langle \chi_\rho,\text{ind}_H^G(\chi_\theta) \rangle = 1$ since both characters are irreducible. If $\theta$ is a representation corresponding to $\chi_\theta$ , then $\rho\simeq \theta$ . Now it remains to find this subgroup $H$ . I have a hunch that $H=\{\sigma\in G: \sigma F \simeq F\text{ as an $S$-representation space}\}$ . It can be easily shown that $H\subsetneq G$ is a proper subgroup. However, I am not sure how to find such an irreducible character $\chi_\theta$ with our desired properties. Any hints are appreciated!","['abstract-algebra', 'representation-theory']"
3659204,Functional equation: $ f : \mathbb R ^ * \to \mathbb R $ with $ \frac 1 x f ( - x ) + f \left( \frac 1 x \right) = x $,"I tried to solve this problem: Determine all function $ f : \mathbb R ^ * \to \mathbb R $ such that $ \forall x \in \mathbb R ^ * $ $$ \frac 1 x f ( - x ) + f \left( \frac 1 x \right) = x \text . $$ Basically I tried the classical way to substitute so I got this : Let $ P ( x ) $ be the assertion above. $ P ( 1 ) $ : we obtain $ f ( - 1 ) + f ( 1 ) = 1 $ . All what I know about this function is this information!
I don't know if there's another technique to simplify it or reduce it. Some help please!","['functional-equations', 'functions']"
3659215,Why are homogeneous polynomials sections of $\mathcal{O}(k)$,Trying to understand the following statements in Huybrecht's complex geometry: Why does the restriction to $\mathcal{O}(-k)$ provide a holomorphic section of $\mathcal{O}(k)$ ?,"['complex-geometry', 'algebraic-geometry']"
3659240,Question about proof the harmonic series diverges,"The usual proof that the harmonic series diverges that I have seen involves group together terms that sum to $\frac{1}{2}$ . It may take the form: $$\sum\limits_{n=1}^{\infty} \frac{1}{n} \ge 1 + \frac{1}{2} + \left(\frac{1}{4} + \frac{1}{4}\right) + \left(\frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8}\right) + \ldots$$ Here is my question: why can I even write that down (or can I write that down?) when we don't have an associative law for an infinite sum? If the series converges absolutely, I should be allowed to rearrange and regroup terms, but for a divergent series, why can I invoke associativity? (I suppose the proof is technically possible even if I didn't group terms just by acknowledging that if I sum them in this way, I get $\frac{1}{2}$ each time. If that is the point, and the ""grouping"" is nothing more than a way for us to see the pattern, I am fine with this.)",['sequences-and-series']
3659296,Limit of given fraction approaching to zero [duplicate],"This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 4 years ago . Show that $\lim_{(x,y) \to (0,0)} f(x,y) = \frac{x^3(y^3 + \pi)}{x^2+y^2}$ is equal to zero. My progress: I have two ideas related to this problem. Initially, I thought about using polar coordinates, but quite uncertain whether it is right approach for this problem or not. Alternatively, I am thinking about squeeze theorem: by AM-GM and triangle inequality, I managed to find a function larger than given $f$ with variables $x,y$ only. Does that imply limit of $f$ will be zero?",['multivariable-calculus']
3659385,Möbius inversion on the partition lattice,"For some $n \in \mathbb N$ , let $(\Pi_n, \le)$ be the poset of partitions of the set $\{1, 2, \dots, n\}$ , where two partitions $\pi, \rho \in \Pi_n$ have the relation $\pi \le \rho$ if $\pi$ is a refinement of $\rho$ , i.e., if every block in $\pi$ is contained within a block in $\rho$ . Möbius inversion on this poset is a fairly standard result in combinatorics: given two functions $f, g: \Pi_n \to \mathbb R$ , it is the case that $$
f(\pi) = \sum_{\rho \le \pi} g(\rho), \qquad \forall \pi \in \Pi_n
$$ and $$
g(\pi) = \sum_{\rho \le \pi} (-1)^{|\rho| - 1}(|\rho| - 1)! f(\rho), \qquad \forall \pi \in \Pi_n
$$ are equivalent. But this result is for lower sums. What is the Möbius inversion formula for upper sums? I.e., if $$
f(\pi) = \sum_{\rho \ge \pi} g(\rho), \qquad \forall \pi \in \Pi_n
$$ then what is $g(\pi)$ ? UPDATE: I believe I have pieced together an answer, with some help from Martin Aigner's text Combinatorial Theory and some small examples. Given some $\rho = \{C_1, C_2, \dots, C_q\} \in \Pi_n$ , there is a one-to-one correspondence between refinements of $\rho$ and the product of partition lattices $\Pi_{|C_1|} \Pi_{|C_2|} \cdots \Pi_{|C_q|}$ , since refinements of $\rho$ are obtained by partitioning each block. In other words, we refine $\rho$ by applying a tuple of partitions $(\sigma_1, \sigma_2, \dots, \sigma_q)$ to the blocks $(C_1, C_2, \dots, C_q)$ , where $\sigma_C \in \Pi_{|C|}$ . Let us use the notation $\hat 1$ to represent the coarsest (1-block) partition in a lattice $\Pi_k$ , and similarly, $\hat 0$ represents the finest ( $k$ -block) partition. For each block $C \in \rho$ , observe that the interval $[\sigma_C, \; \hat 1]$ in $\Pi_{|C|}$ is isomorphic to the interval $[\hat 0, \hat 1]$ in $\Pi_{|\sigma_C|}$ . Furthermore, Möbius functions are multiplicative. Combining these observations, we have $$
\mu(\pi, \rho) = \prod_{C \in \rho} \mu_{\Pi_{|\sigma_C|}}(\hat 0, \hat 1)
= \prod_{C \in \rho} (-1)^{|\sigma_C| - 1} (|\sigma_C| - 1)!
= (-1)^{|\pi| - |\rho|} \prod_{C \in \rho} (|\sigma_C| - 1)!
$$ where $(\sigma_1, \sigma_2, \dots, \sigma_q)$ are the partitions that refine $\rho$ down to $\pi$ . Then $$
g(\pi) = \sum_{\rho \ge \pi} \mu(\pi, \rho) f(\rho)
$$","['mobius-function', 'combinatorics', 'mobius-inversion']"
3659398,First uses of the Ping-Pong Lemma,"I am interested in knowing the origins of this useful result, but I haven't been able to precisely pinpoint the context of its first use. Most texts seem to indicate the result originally comes from Felix Klein, though the lemma is sometimes referred as Schottky's criterion.  I would also like to know what the original formulation looks like, if anyone knows it. Thank you so much for your help! Edit: this was crossposted to History of Science and Mathematics Stackexchange.","['geometric-group-theory', 'group-theory', 'math-history', 'hyperbolic-geometry']"
3659431,Number of ways to stack LEGO bricks,"One of the most surprising combinatorial formulas I know of counts the number of LEGO towers built from $n$ "" $1 \times 2$ "" blocks subject to four rules: The bricks lie in a single plane. Each brick is offset by 1 stud (as in a brick wall). The bottom layer is contiguous. Each brick has at least one brick below it (apart from the bottom layer). Example Formula On page 26 of Miklós Bóna's Handbook of Enumerative Combinatorics , the author states the combinatorial formula (!!): Remarkably there are $3^{n-1}$ domino towers consisting of $n$ bricks. Equally remarkably, no simple bijection is known. The formula was first proven in 1988 by Gouyou-Beauchamps and Viennot . Question While writing up a short essay on this fact, I became interested in what happens when you relax some of the rules. In particular, for the small values I checked on the computer, removing the second rule (""Each brick is offset by 1 stud"") appears to result in $4^{n-1}$ towers with $n$ bricks. I imagine this result exists in the literature, and I was hoping MSE could help me find it. If it hasn't been written down anywhere, I was hoping for insight for how to adapt Bóna's proof into this new setting.","['discrete-geometry', 'reference-request', 'combinatorics', 'statistical-mechanics', 'recreational-mathematics']"
3659461,On the notion of set equality.,"I should start by providing some context. I want to understand the foundations of mathematics and in doing so have been looking at different texts involving ZF set theory and category theory. I understand that set theory takes the view that every mathematical object is to be described as a set. I don't have a problem with that, but I've seen in the past that when others (usually as new to the subject as me) try to ask questions on the foundations of set theory and look for alternatives to doing mathematics, the questions are often met with a response of the form 'why would one want to get rid of set theory?'. That's not my intention. I just want to see if there are precise descriptions of terms like 'object', 'rule' and 'equality' outside of it that one can talk about rigorously without using sets to define them. I'm currently looking at the notions of equality in set theory. We define sets to be equal when they have the same elements. Basically, we can say that $A = B$ if and only if for every $x \in A$ we have $x \in B$ and for every $x \in B$ we have $x \in A$ . Now we are using $x$ as a symbol representing arbitrary elements of $A$ and $B$ , so suppose that the definition holds true and $A$ and $B$ are equal but using set notation we have $A = \{a, b, c\}$ and $B =\{d,e,f\}$ . In order for you to be able to say that $A$ and $B$ are equal, you have to be able to provide some means through which you can say things like $a = d$ . In other words, it seems to me that you need rules which say the objects themselves are equal prior to being able to define notions of set equality. It seems to me that if you say, $a$ and $d$ are sets, then you can continue asking about how equality is defined for the elements of $a$ and $d$ indefinitely until you run into some kind of object that isn't a set or the empty set. My question therefore is this: do we have a way of talking about mathematics that deals with 'rules' on 'mathematical objects' directly in order to define some form of equality? And can such a way of talking about mathematics be used at the foundations in a rigorous way alongside the notion of sets? For a simple example, maybe the rule is addition and the objects are numbers. Only in the context of such a rule can we say the set $\{2 + 2, 3 + 4\}$ is equal to the set $\{4,7\}$ . However, without such a rule, they must be treated as different sets. The idea of numbers and addition being sets themselves doesn't have to be removed, but I would rather treat them as 'examples' of objects with a 'number-like' property and an 'addition-like' property that has been defined prior to constructing them with sets.","['elementary-set-theory', 'foundations']"
3659509,Absolutely continuous and almost everywhere solution of a controlled dynamical system,"This is a doubt i had while reading the first chapter form the book Mathematical Control Theory, Jerzy Zabczyk , in the first chapter, page $11$ the author talks about solution for a class of differential equations: Consider the system of differential equations $$\frac{dq}{dt}=A(t)q(t)+a(t),~~q(t_0)=q_0 \in \mathbb{R}^n$$ on a fixed interval $[0,T]$ ; $t_0 \in [0,T]$ where $A \in M(n,n)$ i.e space of all $n \times n$ matrices over $\mathbb{R}$ , $A(t)=[a_{ij}, i=1,\ldots,n,j=1,\ldots,m]$ , $a(t) \in \mathbb{R}^n$ defined as $a(t)=(a_i(t),i=1,\ldots,n)$ , whete $t \in [0,T]$ . Now he states the theorem Theorem : Assume the elements of the function $A(\cdot)$ are locally integrable. Then there exists exactly one function $S(t)~,~t\in [0,T]$ with values in $M(n,n)$ and with absolutely continuous elements such that $$\begin{align}\frac{d}{dt}S(t)&=A(t)S(t)~~,~~\text{for almost all}~t\in [0,T] \\S(0)&=I \end{align}$$ In addition, a matrix $S(t)$ is invertible for an arbitrary $t \in [0,T]$ , and the unique solution of the equation $(1)$ is of the form $$q(t)=S(t)S^{-1}(t_0)q_0+\int_{t_0}^tS(t)S^{-1}(s)a(s)ds,~t\in[0,T]$$ The proof is not that hard to follow, he uses Banach's Fixed point theorem for the firt part , and the second part need some work but doable. But what confuses me are the parts Almost everywhere and absolutely continuous in the statement of the theorem, what does these terms mean actually in this context, i'm not able to follow these two definitions. Will be thankful if someone provides a easy definition for these. Thank you !","['almost-everywhere', 'control-theory', 'ordinary-differential-equations', 'dynamical-systems']"
3659542,Could an $n$-dimensional creature scan an $(n-1)$-dimensional QR code without any problem?,"I was thinking about ""How much data could be squeezed into the $2$ D QR code"", then it stroke me, that if it were a $3$ D cube, probably inner voxels would be hidden from the outside observer/scanner. So there will be little usefulness of such codes. The questions, that I find hard to answer are: If I was an $n$ -dimensional creature, would I be able to scan a $n-1$ -dimensional ""QR""-code without any problem, as we do with $2$ D
  version? or rather, would I still be struggling to read even $3$ dimensional version?","['soft-question', 'geometry']"
3659604,Is the natural map $f^* f_* \mathcal{F} \to \mathcal{F}$ surjective?,"I'm trying to solve Exercise III 12.4 from Hartshorne's Algebraic geometry . There is a flat projective morphism $f: X \to Y$ of schemes of finite type over an algebraically closed field $k$ . Also $Y$ is assumed to be integral, and all fibers are integral schemes. Now suppose $\mathcal{F}$ is an invertible sheaf on $X$ , that is trivial on each fiber $X_y$ . I was able to show that $f_*\mathcal{F}$ is an invertible sheaf on $Y$ (this is essentially Cor 12.9), and now I would like to show that the natural map $f^*f_* \mathcal{F} \to \mathcal{F}$ is an isomorphism, for which it is enough to show that it is surjective, because both sheaves are locally free.",['algebraic-geometry']
3659625,"Mathematical Explanation of the Difference between SQL Joins: Inner, Outer, Left, Right","Question This question calls for a mathematically sound & intuitive explanation of SQL joins that clearly shows the difference between the following: Inner Join Left Join Right Join Full Outer Join The explanation of joins should not misuse Venn diagrams. This is key. It should also be as accessible as possible to a computer programmer or mathematical beginner. We don't want to scare programmers away from mathematical concepts by using too much jargon. Of course, a little bit of maths is always necessary. Motivation The internet is rife with usages of Venn diagrams to explain SQL joins. As pointed out in the following articles, this leads to a grave misunderstanding of either Venn diagrams, SQL joins or both: https://towardsdatascience.com/can-we-stop-with-the-sql-joins-venn-diagrams-insanity-16791d9250c3 https://blog.jooq.org/2016/07/05/say-no-to-venn-diagrams-when-explaining-joins/ As a website that many students of mathematics and computer science consult as a source of truth, it is our responsibility as a community to try everything in our power to propagate truth. Unfortunately, Venn diagram usage to explain a concept which is really Cartesian product at its core is all to rife. Our own sister site, StackOverflow, is unfortunately part of this problem: https://stackoverflow.com/questions/38549/what-is-the-difference-between-inner-join-and-outer-join/38578#38578 . While there are many amazing answers under that question, the prevailing belief on that site appears to be that joins are intersections/unions and Venn diagrams are appropriate to explain them. The top ranked and accepted answer uses Venn diagrams and intersection/union to explain joins. While there may be some cases where join coincides with intersections and unions, it is not in general the case. I fear that people are simply seeing the special case and accepting the Venn diagram explanation. I fear they are then walking away with improper understanding of SQL joins and set theory. I am hoping that by posting a question here, even a small percentage of people might be directed here instead of to another site that has SQL joins incorrectly explained using Venn diagrams. I am hoping that at least one of the Stack Exchange websites can have an accepted answer explaining SQL joins that is mathematically accurate, and potentially many other good alternative answers alongside it to provide different perspectives. To be clear: I think I understand SQL joins myself. The purpose of this question is to create visibility and a source of truth for those new students of computer science and mathematics who might not understand them fully. Related Is Cartesian Product same as SQL Full Outer Join?","['discrete-mathematics', 'computer-science']"
3659681,Is there a matrix $X$ that conserves orthgonality through this function $f_X$?,"Let $\mathcal{M}_2(\mathbb{C})$ be the set of square matrices of dimension 2, and $\mathcal{S}_2(\mathbb{C})$ the subset of self-adjoint matrices. The function $f_X: \mathcal{S}_2(\mathbb{C}) \rightarrow \mathcal{S}_2(\mathbb{C})$ is defined by $$ f_X(A) = \sum_{n=0}^\infty X^n A (X^\dagger)^n $$ where $X \in \mathcal{M}_2(\mathbb{C})$ , and where $X^\dagger$ is the Hermitian adjoint of $X$ . The problem is the following: Is there a non-trivial matrix $X$ such that, $\forall A, B \in \mathcal{S}_2(\mathbb{C})$ , if $\mathrm{Tr}\left[AB\right] = 0$ , then $\mathrm{Tr}\left[f_X(A)f_X(B)\right] =0$ ? Any hint would be appreciated! EDIT: As mentionned in the comments, $X=0$ and $X = cI$ with $|c| < 1$ are obvious solutions. Also, if $X^d = cI$ , then $f_X(A) = \sum_{n=0}^\infty c^n \sum_{m=0}^{d-1} X^m A (X^\dagger)^m = \frac{1}{1-c} \sum_{m=0}^{d-1} X^m A (X^\dagger)^m$ . Furthermore, the eigenvalues $\lambda_i$ of $X$ are such that $\lambda_i^d = c$ , so one can diagonalize $X = PDP^{-1}$ but I did not manage to go further when substituting in the trace.","['matrices', 'linear-algebra']"
3659744,Spectrum of restriction to invariant subspace,"Let $H$ be a separable Hilbert space and let $\mathcal{B}(H)$ denote the algebra of linear bounded operators on $H$ . Let $T \in \mathcal{B}(H)$ and let $M$ be a non-trivial closed invariant subspace for $T$ . In general, you cannot expect $\sigma(T\mid_M) \subset \sigma(T)$ . For example, see the first answer in Spectra of restrictions of bounded operators . The spectrum of the operator of this example is the unit circle, but the spectrum of the restriction is the whole closed unit disk. I've been looking for examples of this kind and everything I found satisfies $\sigma(T\mid_M) \subset \eta(\sigma(T)),$ where $\eta(\sigma(T))$ is the full spectrum, id est, $\sigma(T)$ together with the ""holes"" of $\sigma(T)$ . Is it true that $\sigma(T\mid_M) \subset \eta(\sigma(T))$ for every operator $T \in \mathcal{B}(H)$ ? In particular, we would have $\sigma(T\mid_M) \subset \sigma(T)$ whenever $\sigma(T)$ is simply connected. If this is true, I would like to have a good reference to read the proof. If it is false, I would like to see a counterexample. Thank you very much!","['banach-spaces', 'operator-theory', 'hilbert-spaces', 'functional-analysis', 'spectral-theory']"
3659815,Is a continuous function with zero “Taylor approximation” smooth?,"Let $f:[0,\infty) \to [0,\infty)$ be a continuous, non-decreasing function, satisfying $f(0)=0$ and $f(x)=o(x^n)$ for any $n \ge 1$ . Suppose also that $f(x)>0$ for every $x>0$ . I also know that $f$ is smooth on the open interval $(0,\infty)$ . Must $f$ be infinitely (right) differentiable at zero? Comments: The Taylor series of $f$ does not have to converge to $f$ , e.g. in the famous example of $$
f(x) =\begin{cases}e^{-1/x^2} \text{ for } x >0 \\
0 \text{    for } x = 0\end{cases}
$$ In general, the existence of a polynomial approximation by itself does not imply differentiabiliy; in fact it does not even imply continuity (at $x>0$ ), as the following examples show: $f(x)=\chi_{\mathbb Q}(x)x^n$ or even $\chi_{\mathbb Q}(x)e^{-1/x^2}$ which also satisfies $f(x)=o(x^n)$ for any $n \ge 1$ .","['calculus', 'singularity', 'derivatives', 'real-analysis']"
3659836,N Circle touching x-axis and fixed point,"If a circle $C_0$ , with radius $1$ unit touches both the axes and as well as line ( $ L_1
$ ) through $P(0,4)$ , $L_1$ cut the $x$ -axis at $(x_1 ,0)$ . Again a circle $C_1$ is drawn touching $x$ -axis, line $L_1$ and another line $L_2$ through point $P$ . $L_2$ intersects $x$ -axis at $(  x_2,0)$ and this process is repeated $n$ times. Then the value of : $$\lim_{n\to \infty }\frac{x_n}{2^n} $$ is I am only able to find $C_1$ which is $(x-1)^2+(y-1)^2=1$ and $L_1$ which is $3x+4y=12$ but not able to proceed forward","['limits', 'conic-sections']"
3659856,ODE with nested boundary layers,"Problem: Consider the equation $$\varepsilon^3 \frac{d^2y}{dx^2} + 2x^3 \frac{dy}{dx} - 4\varepsilon y = 2x^3 \qquad \qquad y(0) = a \;, \; y(1)=b$$ in the limit as $\varepsilon \rightarrow 0^+$ , where $0<a<b-1$ . Assuming that there are nested boundary layers at $x=0$ , determine the thickness of the boundary layers and the leading-order additive composite solution. Question: My attempt is shown below. Basically, I don't understand how you are meant to match the different solutions in the various domains. Would be grateful if someone could explain this to me, or give me some hints. Attempt: Firstly, the leading term $y_0$ of the outer solution satisfies $$2x^3 \frac{dy_0}{dx} =2x^3 \qquad \qquad y_0(1)=b$$ This is easily solved to give $\color{red}{y_0(x) = x+b-1}$ . Now suppose we scale the equation with $x=\varepsilon ^\alpha X$ where $\alpha>0$ and $X = \mathcal O(1)$ . The equation becomes $$\varepsilon^{3-2\alpha} \frac{d^2y}{dX^2} + 2\varepsilon^{2\alpha}X^3 \frac{dy}{dX} - 4\varepsilon y = 2\varepsilon^{3\alpha}X^3$$ The possible leading order balances come from $\alpha = 1$ and $\alpha = 1/2$ . When $\alpha = 1/2$ (i.e. $x = \varepsilon^{1/2} X$ ), the leading order term $Y_0$ in this layer should satisfy $$2X^3 \frac{dY_0}{dX} - 4Y_0 = 0 \qquad \qquad Y_0(X=0) = a$$ The general solution is $\color{red}{Y_0(X) = A\exp (-1/X^2)}$ , which cannot satisfy the boundary condition, since $a>0$ . So I suppose this is why we need another boundary layer. Scaling instead with $x = \varepsilon \tilde X$ , the leading order solution $\tilde Y_0$ in this layer satisfies $$\frac{d^2\tilde Y_0}{d\tilde X^2} - 4\tilde Y_0=0\qquad \qquad \tilde Y_0(\tilde X = 0) = a$$ The solution is $\color{red}{\tilde Y_0(\tilde X) = \tilde A\sinh(2\tilde X)} \color{green}{+a\cosh(2\tilde X)}$ . $\color{blue}{\text{Now the problem is, how do I match these three solutions?}}$ From what I have learnt, I need to do something like $$\lim_{x\rightarrow 0^+} y_0(x) = \lim_{X\rightarrow +\infty}Y_0(X)$$ to obtain $\color{blue}{A= b-1?}$ But if I similarly try to do $$\lim_{X\rightarrow 0^+}Y_0(X) = \lim_{\tilde X\rightarrow +\infty}\tilde Y_0(\tilde X)$$ it doesn't work, because $\tilde Y_0$ is not bounded??","['asymptotics', 'boundary-layer', 'ordinary-differential-equations', 'perturbation-theory']"
3659859,Chinese Olympiad 2019 Round 2 Question 3,"I came across this question and the AOPS website has two response: one is written in Chinese  which I have no clue about and there's another approach which I'm not familiar with. Can anyone suggest any other way to approach this question? I have tried attempting this question but my method is not making any sense. Thanks in advance! Let $m$ be an integer where $|m|\ge 2$ . Let $a_1,a_2,\cdots$ be a sequence of integers such that $a_1,a_2$ are not both zero, and for any positive integer $n$ , $a_{n+2}=a_{n+1}-ma_n$ . Prove that if positive integers $r>s\ge 2$ satisfy $a_r=a_s=a_1$ , then $r-s\ge |m|$","['contest-math', 'number-theory']"
3659894,Reference request for equivalence of reducibility of $\ell$-adic Galois representation and isogeny of degree $\ell$ on elliptic curve,"Let $E$ be an elliptic curve over $\mathbb{Q}$ . For each prime $\ell$ , the action of $\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q})$ on $E[\ell]$ (the group of $\ell$ -division points of $E$ ) defines a representation $$\rho=\rho_\ell:\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q}) \longrightarrow \mathrm{GL}(2,\mathbb{F}_\ell). $$ Where can I read the proof of: $\rho$ is reducible if and only if $E$ admits an isogeny of degree $\ell$","['galois-representations', 'elliptic-curves', 'galois-theory', 'algebraic-geometry', 'galois-extensions']"
3659903,Is this monotonicity property equivalent to convexity?,"This is a follow-up of this question . Let $\psi:[0,\infty) \to [0,\infty)$ be a strictly increasing $C^2$ (or $C^{\infty}$ ) function, satisfying $\psi(0)=0$ . Suppose that the function $f(r)=\psi'(r)+\frac{\psi(r)}{r}$ is non-increasing. Must $\psi$ be concave? The converse statement is true, i.e. $\psi$ concave implies $f$ non-increasing: Indeed, $$
f'(r)=\psi''(r)+\frac{1}{r}(\psi'(r)-\frac{\psi(r)}{r}),
$$ $\psi'' \le 0$ by concavity, and since $\psi(r)=\int_0^r \psi'(t)dt \ge \int_0^r \psi'(r)dt=r\psi'(r)$ , the term $\frac{1}{r}(\psi'(r)-\frac{\psi(r)}{r})$ is also non-positive. Edit: Here is a partial result-I can prove that $\psi''(0) \le 0$ . By our assumption $$
0 \ge f'(r)=\psi''(r)+\frac{1}{r}(\psi'(r)-\frac{\psi(r)}{r}),
$$ for every $r>0$ . Using the mean value theorem (twice), we can rewrite this as $$
f'(r)=\psi''(r)+\psi''(s(r)) \le 0, \tag{1}
$$ where $s(r)$ is some point in $(0,r)$ . In particular, taking the limit when $r \to 0$ , we deduce that $\psi''(0) \le 0$ .","['functional-inequalities', 'real-analysis', 'calculus', 'convex-analysis', 'convexity-inequality']"
3659907,"Homework Problem, Power Series Limit","I am looking to find the solution for: $$\lim_{x\rightarrow 0} {5^{tan^2(x) + 1} - 5 \over 1 - cos^2(x)}$$ A hint was provided: transform: ${5^{tan^2(x) + 1} - 5 \over 1 - cos^2(x)}$ to $5y{5^{y-1} - 1 \over y-1}, y = {1\over cos^s(x)} \rightarrow 1$ The transformation is straigt forward: $tan^2(x) + 1 = {1\over cos^2(x)}  = y \text{ and } \\1-cos^2(x) = ycos^2(x) - cos^2(x) = cos^2(x)(y-1)$ combined we have: $$5y{(5^{y-1} - 1) \over y-1}$$ as $y \rightarrow 1$ $5y{(5^{y-1} - 1) \over y-1}$ is not defined. Since both, nominator and denominator are $0$ I tried L'Hopital but ended at: $5 5^{y-1} + 5y(y-1)5^{y-2}-5$ with $\lim_{y \rightarrow 1} = 5 + 0 - 5 = 0$ and $(y-1)' = 1$ Here I have to stop with no solution. I have also tried to use the quotient rule to differentiate the expression which did not get me anywhere.","['power-series', 'limits', 'real-analysis']"
3659919,Why is $\lvert \tanh x\rvert < 1$?,"In the solutions to my exercises, it says that it is easy to see that $\lvert \tanh x\rvert < 1$ . Sadly, this doesn't really help me. I know that $$\lvert \tanh x\rvert = \left\lvert \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} \right\rvert = \left\lvert \frac{1-e^{-2x}}{1 + e^{-2x}} \right\rvert$$ However, I don't see how this would imply or even help me show $\lvert \tanh x\rvert < 1$ .","['trigonometry', 'exponential-function', 'real-analysis']"
3659957,Does $\sum_i A_i=I$ with $A_i$ positive imply $\{A_i\}_i$ are mutually diagonalisable?,"As discussed in this other question , if $A$ and $B$ are matrices such that $A+B=I$ , then trivially they commute, and thus if they are both diagonalisable they are also mutually diagonalisable. The same argument doesn't, however, apply when summing more than two such matrices. Suppose then that $$\sum_{i=1}^n A_i = I.$$ The case of $A_i\ge0$ is the one I'm most interested about, but if positivity turns out to not be relevant for this, as it might very well be the case, feel free to weaken this constraint (to maybe consider Hermitian, normal, or just diagonalisable matrices). If $\sum_i A_i=I$ then I can say that, for example, $[A_1,A_2+...+A_n]=0$ , and thus $A_1$ and $\sum_{i>1} A_i$ are mutually diagonalisable. But then I cannot iterate the argument by splitting $A_2$ from $A_3+...+A_n$ , as now they sum to a diagonal matrix (in their common eigenbasis), but not to the identity. So does the result about mutual diagonalisability only work for $n=2$ ? A counterexample of three or more non-mutually-diagonalisable matrices summing to the identity would be a good answer.","['matrices', 'linear-algebra', 'positive-definite', 'eigenvalues-eigenvectors']"
3660098,Notation for argsort,"I writing up a paper and I need a clear description of numpy's argsort. If we take set $X = \{x_1,\ldots,x_n\}$ could we describe argsort as $$
\underset{i}{\text{argsort}X} = |\{x_j \mid  x_j \lt x_i, x_j \in X \}|
$$ ?","['elementary-set-theory', 'order-theory', 'notation']"
3660101,determine whether or not infinite series $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n} $ converge,"I want to determine if the series $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n} $ converge/diverge. the sequence in the denominator is not monotinic, so I cant use Dirichlet's or Abel's tests. My intuition is that this series converge, becuase its looks close to $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{n} $ but im not sure how to prove. Any ideas will help, thanks.","['limits', 'calculus', 'sequences-and-series']"
3660125,Probability about lifetime of 100 bulbs (exponential distribution),"I have some doubts about the following problem: I have 100 bulbs with a lifetime represented by an exponential distribution, with an expected value of 1000 hours. Find the probability that, at least one bulb, blown down after at most 500 hours. I have calculated the probability about one bulb with this method: $P(X \leq 500)=\int_{0}^{500}\lambda e^{-\lambda x}dx = 1-e^{\frac{1}{2}} = 0.394$ now, how can I extend this method for all the 100 bulbs? A step-by-step solution is really appreciated, I'm really newbie about statistics/probability arguments. Thank you so much and best regards. EDIT: $\frac{1}{\lambda}=1000$ hours so $ \lambda = \frac{1}{1000} $","['statistics', 'exponential-distribution', 'probability', 'random-variables']"
3660155,Is it necessary for a Lyapunov Candidate to be Differentiable at an Equilibrium Point?,"For example, given a general nonlinear system where we want to show that the error system is stable $e=x-x_d$ is it necessary for the Lyapunov candidate to be continuously differentiable at the equilibrium point since we are only concerned about what happens around the equilibrium point? At the end of the day I would like to show that $\vert\vert e\vert\vert$ is a valid Lyapunov candidate. However, this is not differentiable at $e=0$ since the derivative is $\frac{e^{T}\dot{e}}{\vert\vert e\vert\vert}$ . My current digging into this topic has found the following paper: Vector Norms as Lyapunov Functions for Linear Systems by Kiendl. However, this paper is restricted to linear systems (plus other restrictions). Note: this is a follow up to a question I asked yesterday but I believe this is better said and is more direct. Thanks for your input","['lyapunov-functions', 'ordinary-differential-equations']"
3660162,Show that a function maps open saturated sets into open sets,"i'm struggling with the following problem: Let $f:\mathbb{C}\setminus\{0\}\to\mathbb{R}_+$ , $(x,y)\mapsto\sqrt{x^2+y^2}$ . Show that $f$ is open for saturated sets $A$ under the assumption, that $\mathbb{C}\setminus\{0\}$ and $\mathbb{R}_+$ are equipped with the subspace topology of the euclidean topology. i know a set $A$ is saturated iff $A=f^{-1}(f(A))$ , but i dont know where this comes to use. my attempt: i want to show that for $z\in A\subseteq\mathbb{C}\setminus\{0\}$ the set $f(A)$ is a neighborhood of $f(z)$ , but how do i compute $f(A)$ ? since the euclidean topology is just intervals $(x,y)$ i guess i could write $A$ as the product of such intervals, but then i'm stuck.","['complex-analysis', 'general-topology', 'analysis']"
3660177,"Is the function, $f(z)=iz\bar{z}$ analytic?","Question: Is the function, $f(z)=iz\bar{z}$ analytic? My approach: We know that for any $z\in\mathbb{C}$ , $z\bar{z}=|z|^2.$ Thus $f(z)=i|z|^2, \forall z.$ Now let $z=x+iy\implies f(z)=f(x+iy)=i(x^2+y^2).$ Thus we have $u(x,y)=0$ and $v(x,y)=x^2+y^2$ , $\forall x,y\in\mathbb{R}$ . Now observe that both $u$ and $v$ are continuous functions in $x$ and $y$ , $\forall x,y\in\mathbb{R}.$ Now $$\frac{\partial{u}}{\partial{x}}=0, \frac{\partial{u}}{\partial{y}}=0,\frac{\partial{v}}{\partial{x}}=2x,\frac{\partial{v}}{\partial{y}}=2y, \forall x,y\in\mathbb{R}.$$ Thus the functions $\frac{\partial{u}}{\partial{x}},\frac{\partial{u}}{\partial{y}},\frac{\partial{v}}{\partial{x}},\frac{\partial{v}}{\partial{y}}$ are continuous $\forall x,y\in\mathbb{R}.$ Now we move forward to analyze if the Cauchy-Riemann conditions are satisfied or not. Observe that since $$\frac{\partial{u}}{\partial{x}}=0 \text{ and } \frac{\partial{v}}{\partial{y}}=2y, \text{ therefore } \frac{\partial{u}}{\partial{x}}=\frac{\partial{v}}{\partial{y}}\iff 2y=0\iff y=0.$$ Again since, $$\frac{\partial{u}}{\partial{y}}=0 \text{ and } -\frac{\partial{v}}{\partial{x}}=-2x, \text{ therefore } \frac{\partial{u}}{\partial{y}}=-\frac{\partial{v}}{\partial{x}}\iff -2x=0\iff x=0.$$ Thus the Cauchy-Riemann conditions are satisfied only at the point $(x,y)=(0,0)$ , i.e., at the point $z=0$ . Thus we can conclude that $f$ is analytic only at the point $z=0$ . I have read in the book ""Advanced Engineering Mathematics"" by Erwin Kreyszig that: A function $f(z)$ is said to be analytic at a point $z=z_0$ in a domain $D$ if $f(z)$ is analytic in a neighborhood of $z_0$ . But, here we see that $f(z)$ is analytic only at the point $z=0$ , and not in any $\delta$ neighborhood of $z=0$ . So, can we still conclude that $f(z)$ is analytic at the point $z=0$ ? And, obviously $f(z)$ is not a analytic function, since it is not differentiable at every point in some domain.",['complex-analysis']
3660210,Number theory in Wu formula,"I want to prove the Wu formula, and I have managed to understand that it is equivalent to the following fact: For any integer $m>k>0$ the number $\sum\limits_{j=0}^{k}{{m-j-1}\choose{k-j}}{{k+m}\choose{j}}$ is even. I've wasted a lot of time trying to prove it. Can anyone help?","['number-theory', 'combinatorics', 'algebraic-topology', 'elementary-number-theory']"
3660242,"A subring may have a different identity,why? [duplicate]","This question already has answers here : Nontrivial subring with unity different from the whole ring? (7 answers) Closed 4 years ago . Let $R$ be a ring with unity $1_R$ . Suppose $S$ is a subring but it does not contain $1_R$ . But still it may contain a subring unity $1_S$ . For example $R=M_2(\mathbb R)$ and $S$ be the set of all matrices with first entry in $\mathbb R$ and the rest three $0$ . Then the element with first entry $1$ and rest three zero is identity of $S$ . Why is this happening?It seems a bit weird to me. We can also take the example of $\mathbb Z_6$ and its subring $\{0,3\}$ . I have searched for the answer to this question in stack exchange but the answers, although they have no problem, is out of my scope of understanding as I am a beginner of Ring theory.","['ring-theory', 'abstract-algebra', 'inverse']"
3660275,Structure sheaf of a locally ringed space can be pulled back from an open cover,"If I am not mistaken, if $X$ is an algebraic variety and $(U_i)_{i=1}^n$ is an open cover of $X$ , to give a regular function $X \to \mathbb{A}^1$ is the same as giving regular functions on the $U_i$ that agree on the intersections. But on the other hand, a regular function on $X$ is just an element of $\mathcal{O}_X(X)$ . So does this mean that $X$ as a locally ringed space is equal to the fibered product of the locally ringed spaces $U_i$ along their intersections? Is this fact true in general for (locally) ringed spaces? And why is that so? What would go wrong if I for instance defined $\mathcal{O}_X(X)$ to be smaller (so that not every function that is regular on each $U_i$ belongs to $\mathcal{O}_X(X)$ ), could I not still get a locally ringed space?",['algebraic-geometry']
3660285,"Find all strictly monotone $f:(0,+\infty) \to (0, +\infty)$ such that $f(\frac{x^2}{f(x)})=x.$","Find all strictly monotone functions $f:(0,+\infty) \to (0,+\infty)$ such that $$f\left(\frac{x^2}{f(x)}\right)=x.$$ My try: it is clear that $f$ is surjective. And because it is monotone it must also be injective. Therefore we can take $f^{-1}$ from both sides: $x^2 = f(x) \cdot f^{-1}(x)$ .
We can take $x = f(y)$ (because of surjectivity) and get that: $\frac{f(y)}{y} = \frac{f(f(y))}{f(y)}$ .
So, if we define $g(x) = \frac{f(x)}{x}$ we have that $g(y) = g\big(f(y)\big)$ and I was hoping to prove that $g$ is injective so we would have $f(x) = x$ only. But I couldn't figure that last step. There may be a better way to deal with this problem. EDIT: There is another solution on AOPS, problem 312 .","['functional-equations', 'functions', 'real-analysis']"
3660332,Derivatives of exponential functions and number $e$,"How to prove that this thing $ e = (1 + h)^\frac{1}{h}, h \rightarrow 0 \iff (1 + \frac n)^n, n \rightarrow \infty$ goes to some exact value? Is there a proof of this, and if possible, intuition? (#) If we want to find solution of equation $\frac{d}{dx} [a^x] = a^x$ we would easly see that solution is limit above, namely $e.$ But why is that? Is there intuitive reason why that golden value is, on a first sight, jut random irrational number? It's obvious that this 1 in limit is base-value, when time equals 0 ( $e^0 = 1$ ). But I don't see conection in the rest of the formula (limit) :( Also, I looked why $e^x = (1 + \frac{x}{n})^n, n \rightarrow \infty,$ (##) and here goes reasoning (I will always suppose that n goest to infinity):
Wee see that $e^{\frac{x}{n}} = 1.$ But also $1 + \frac{x}{n} = 1.$ Therefore, we get (##). Of course, this is just wrong: same ""reasoning"" can be done with any positive base. I must say that now I am confused: for very small $h$ we would have, for example when base is 3, $3^h = 1 + h$ ?? (###) Can you prove (explain) questions above: (#), (###) and can you give me intuitive and clear picture of why we got that strange limit. I can get that number with algebra , but just can't with imagination and logic.","['real-analysis', 'calculus', 'limits', 'algebra-precalculus', 'derivatives']"
3660337,If $\sigma_n^2<\infty$ and $E[X_n]\ne0$ then $\frac{\sigma_n^2}{E[X_n]^2}\to0$ implies $\frac{X_n}{E[X_n]}\overset{P}\longrightarrow1$,"Problem: Suppose that the random variables $X_1,X_2,\dots$ have finite variances and nonzero means. Show the following statement: $$\text{if }\lim\limits_{n\to\infty}\frac{\sigma_n^2}{E[X_n]^2}=0\text{ then }\frac{X_n}{E[X_n]}\overset{P}\longrightarrow1.$$ Attempt: Fix $\varepsilon>0$ . An application of Chebyshev's inequality yields $$P\left(\left\vert \frac{X_n}{E[X_n]}-1\right\vert\geq\varepsilon\right)=P\left(\left\vert X_n-E[X_n]\right\vert\geq\varepsilon \vert E[X_n]\vert\right)\leq\frac{\sigma_n^2}{\varepsilon^2 E[X_n]^2}\overset{n\to\infty}\longrightarrow0,$$ where in the last step we used the assumption that $\lim\limits_{n\to\infty}\frac{\sigma_n^2}{E[X_n]^2}=0.$ Since $\varepsilon>0$ was arbitrary it follows that $\frac{X_n}{E[X_n]}\overset{P}\longrightarrow1$ as $n\to\infty.$ Do you agree with my attempt at a proof of the above exercise? Any feedback is much welcomed and appreciated. Thank you for your time.","['solution-verification', 'probability-theory', 'probability']"
3660347,Density of the first $k$ coordinates of a uniform random variable,"Suppose that $X$ is distributed uniformly in the $n$ -sphere $\sqrt{n}\mathbf{S}^{n-1} \subset \mathbf{R}^n$ . Then apparently the distribution of $(X_1, \dots, X_k)$ , the first $k < n$ coordinates of $X$ has density $p(x_1, \dots, x_k)$ with respect to Lebesgue measure in $\mathbf{R}^k$ , moreover if $r^2 = x_1^2 + \cdots + x_k^2$ , then it is proportional to $$
\left(1 - \frac{r^2}{n}\right)^{(n-k)/2 - 1}, \quad \text{if}~0 \leq r^2 \leq n,
$$ and otherwise is 0. I tried to compute this using the fact that $(X_1, \dots, X_k) \stackrel{\rm d}{=} \sqrt{n} (g_1, \dots, g_k)/\sqrt{g_1^2 + \cdots + g_n^2}$ , when $g_i$ are iid standard normal variables, but was unable to simplify the integrals. Does anyone know/can point me to a place where this density is derived?","['uniform-distribution', 'geometric-probability', 'probability-theory', 'probability', 'density-function']"
3660356,Is there a system of mathematics where $4>2$ is false?,"A recent question on propositional logic posted on Philosophy Stack Exchange yielded an answer which states, in part, that, The fact that $4$ is greater than $2$ is not a ""logical fact"" but and [sic] arithmetical one: it depends on the axioms of arithmetic. The context of the question was a cited proposition from a book on logic for which the author claims that knowing that a creature has four legs is not enough to prove that it has more than two legs. Is there a set of mathematical axioms or form of mathematics in which $4>2$ is meaningful but false? Some commenters mentioned the possibility of modular (modulo) arithmetic, but admitted that $4>2$ in those systems would either be true or meaningless.","['axioms', 'number-comparison', 'integers', 'logic', 'discrete-mathematics']"
3660375,Existence of limit of $f(x)=\frac{x_1}{\Vert x\Vert_2}$ at ${0 \choose 0}$,"We are given the function: $f: M\subset\mathbb{R}^2 \to \mathbb{R}$ , where $f(x)=\frac{x_1}{\Vert x\Vert_2}$ and $M:=\{x={x_1 \choose x_2}\in\mathbb{R}^2~:~x_1>\sqrt{|x_2|}\}$ . Show that the limit at ${0 \choose 0}$ exists. I already figured out that the limit must be $1$ . As the domain is restricted to specific points I could not properly use zero-sequences to show the existence of the limit. So I tried to apply th $\epsilon$ - $\delta$ -criterion for limits. However, I could not find an upper boundary for $\left|\frac{x_1}{\Vert x\Vert_2}-1\right|$ such that for all $x \in M$ with $\Vert x - 0\Vert <\delta$ we get: $\left|\frac{x_1}{\Vert x\Vert_2}-1\right|\leq....<\epsilon$ . At the begining I was optimistic to get such an upper boundary if I incorporate the condition of $M$ but it didn't get me anywhere... Maybe there is some secret trick... As this is homework I would appreciate if you just provide me a little hint and not the full solution unless you hide it.","['limits', 'multivariable-calculus', 'analysis']"
3660420,Understanding the definition of a limit point.,"I am trying to understand the following definition of a limit point: A point $x$ is a limit point of a set $A$ if every $\epsilon$ -neighborhood $V_\epsilon(x)$ of $x$ intersects the set $A$ at some point other than $x$ . I am trying to understand what ""other than $x$ "" means. I know that a limit point $x$ need not be in $A$ . So, suppose we know somehow that $x \notin A$ . Then, would it be valid to modify the definition of a limit point as follows? A point $x$ is a limit point of a set $A$ if every $\epsilon$ -neighborhood $V_\epsilon(x)$ of $x$ intersects the set $A$ at some point in $A$ . EDIT : I found a different definition of a limit point: A point $x$ is a limit point of a set $A$ iff $x = \lim a_n$ for some $(a_n) \subseteq A$ satisfying $a_n \neq x$ $\forall n \in \mathbb{N}$ Does this definition fail when it comes to the sequence $(a, a, \dots)$ whose limit point clearly is $a$ ?","['limits', 'definition', 'real-analysis']"
3660477,Is there an example of $\mathbb{R} \to \mathbb{R}$ function that produces only rationally independent numbers?,"Is there a function $f(x): \mathbb{R} \to \mathbb{R}$ such that $$nf(x) \neq mf(y) \quad  \forall\  x,y \in \mathbb{R},\ n,m \in \mathbb{Z},\ x\neq y ?$$","['irrational-numbers', 'functions']"
3660521,Orthogonal Projections Are Symmetric - Geometric Intuition,"Let us denote the projection matrix onto the column space of $A$ by $\pi_A = A(A^T A)^{-1} A^T$ . I am looking for geometric intuition as to why it is symmetric. It is very clear to me due to plenty of algebraic reasons (taking transpose, showing $\left \langle \pi_A u,v \right \rangle=\left \langle u,\pi_A v \right \rangle$ and so on...), but I am looking for something of the sort of ""proof without words"" which could be explained with pictures. For example, it is clear to me that $\pi_A^2=\pi_A$ , since projecting a vector which is already in $\text{col}(A)$ onto $\text{col}(A)$ , is itself. Same goes to show $\pi_A A = A$ . I saw many posts addressing this problem, however all the explanations I read resorted to over-killing with calculations.","['orthogonality', 'geometry', 'linear-algebra', 'intuition', 'projection-matrices']"
3660523,"Higher derivatives of the map $I:T \mapsto T^{-1}$, where $T \in \mathcal B(X)$.","Let $X$ be a Banach space, $\mathcal B(X;Y)$ denotes the set of bounded linear operators $X\to Y$ . Consider the inverting map $I:U\subset\mathcal B(Y;X)\to \mathcal B(X;Y)$ defined by $I(T) = T^{-1}$ , where $U$ is the set where this makes sense. It is known, e.g. here , that $I$ is (Frechet) differentiable and $$
I'(T)[A] = -T^{-1}AT^{-1}, 
$$ here $I'(T)$ is viewed as an element of $\mathcal B(\mathcal B(Y;X);\mathcal B(X;Y))$ . How do we prove that the $k^{\text{th}}$ -derivative of $I$ is the $k$ -multilinear map $$
(A_1,\dots,A_k) \mapsto (-1)^{k} \sum_{\sigma\in S_k} T^{-1}A_{\sigma(1)}T^{-1}\dots T^{-1}A_{\sigma(k)} T^{-1},
$$ where the sum is over all permutations $\sigma$ of $\{1,\dots,k\}$ ? This formula is given in a book by Hormander without a proof (as usual). It looks like a symmetrization of the higher order terms in the Taylor expansion of $I$ (some details are seen in this thread ). To obtain higher order derivatives, I tried to differentiate $I'$ by writing $I' = -M\circ I$ , where $M(T)[A] = TAT$ , and repeatedly apply chain rule. However, the higher derivatives of $M$ gets ugly really fast (or that I don't know a clean way to write it down). Is there a nice way to prove this result?","['operator-theory', 'real-analysis', 'complex-analysis', 'linear-algebra', 'functional-analysis']"
3660625,"If $X_1,X_2\dots$ are i.i.d. Bernoulli$(1/2)$ then $\sum_{k=1}^n\frac{X_k}{2^k}$ converges in distribution to $Y\thicksim\text{Unif}(0,1)$","Problem: Let $X_1,X_2,\dots$ be i.i.d. $\text{Bernoulli}(1/2)$ random variables. $\textbf{(a)}$ Show that the sequence $Y_n=\displaystyle\sum_{k=1}^n\frac{X_k}{2^k}$ converges with probability one. $\textbf{(b)}$ Let $Y=\lim\limits_{n\to\infty}Y_n.$ Show that $Y\thicksim\text{Unif}(0,1)$ by computing $P\left(Y\leq\frac{k}{2^n}\right)$ for $0\leq k\leq2^n$ , and then using the density of the dyadic rationals. Attempt: We begin with part (a). Fix $\omega\in\Omega$ . Then $X_k(\omega)=0$ or $X_k(\omega)=1$ for any $k\in\mathbb N$ . Therefore, $$Y_n(\omega)=\sum_{k=1}^n\frac{X_k(\omega)}{2^k}\leq\sum_{k=1}^\infty\frac{1}{2^k}<\infty.$$ Since $Y_n(\omega)$ is a uniformly bounded nondecreasing sum of positive real numbers, it must converge to a limit. Since $\omega\in\Omega$ was arbitrary it follows that $Y_n$ converges with probability one. For part (b), I found an approach using moment generating functions, in the question https://math.stackexchange.com/a/1269084/595519 , but I am having problems coming to grips with the approach indicated above for finding the limiting CDF. Could someone give me a heads-up on how to approach the problem in part (b)? Any thoughts on part (a) are also much welcomed. Thank you very much for your time.","['probability-theory', 'probability']"
3660670,Catalan triangle created by $[t^{n+1}](\frac{1-\sqrt{1-4t}}{2})^{k+1}=\frac{k+1}{n+1}{2n-k \choose n-k}$?,"I tried to get the catalan triangle from its Riordan array. I failed at $d_{n,k}=[t^{n+1}](\frac{1-\sqrt{1-4t}}{2})^{k+1}=\frac{k+1}{n+1}{2n-k \choose n-k}$ . How do I get there?","['catalan-numbers', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3660699,prove that $ \sin(x+y)=\sin{x} \cdot \cos{y} +\sin{y} \cdot \cos{x} $ using power series (without trigonometric identities),"as we know $ S\left(x\right)=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}x^{2n+1} $ and $ C\left(x\right)=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n\right)!}x^{2n} $ the power series of sinx and cosx. I want to prove that : $ S\left(x+y\right)=S\left(x\right)C\left(y\right)+S\left(y\right)C\left(x\right) $ What ive done: let $ x,y \in \mathbb{R} $ So $ S\left(x+y\right)=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}\left(x+y\right)^{2n+1}=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}\sum_{k=0}^{2n+1}\binom{2n+1}{k}x^{k}y^{2n-k+1}=\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{2n+1}\frac{\left(2n+1\right)!x^{k}y^{2n-k+1}}{\left(2n+1\right)!\left(k!\right)\left(2n-k+1\right)!}\right)=\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{n}\frac{x^{k}y^{2n-k+1}}{k!\left(2n-k+1\right)!}+\sum_{k=n+1}^{2n+1}\frac{x^{k}y^{2n-k+1}}{k!\left(2n-k+1\right)!}\right) $ and also $ S\left(x\right)C\left(y\right)+S\left(y\right)C\left(x\right)=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}x^{2n+1}\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n\right)!}y^{2n}+\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}y^{2n+1}\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n\right)!}x^{2n} $ we know that the series absolutely converge, so we can use cauchy's product. so $ \sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}x^{2n+1}\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n\right)!}y^{2n}=\sum_{n=0}^{\infty}\sum_{k=0}^{n}\frac{\left(-1\right)^{k}}{\left(2k+1\right)!}x^{2k+1}\frac{\left(-1\right)^{n-k}}{\left(2n-2k\right)!}y^{2n-2k}=\sum_{n=0}^{\infty}\sum_{k=0}^{n}\frac{\left(-1\right)^{n}}{\left(2k+1\right)!\left(2n-2k\right)!}x^{2k+1}y^{2n-2k} $ and $ \sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n+1\right)!}y^{2n+1}\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{\left(2n\right)!}x^{2n}=\sum_{n=0}^{\infty}\sum_{k=0}^{n}\frac{\left(-1\right)^{k}}{\left(2k\right)!}x^{2k}\frac{\left(-1\right)^{n-k}}{\left(2n-2k+1\right)!}y^{2n-2k+1}=\sum_{n=0}^{\infty}\sum_{k=0}^{n}\frac{\left(-1\right)^{n}}{\left(2k\right)!\left(2n-2k+1\right)!}x^{2k}y^{2n-2k+1} $ if we sum the last 2 equations we get: $ \sum_{n=0}^{\infty}\sum_{k=0}^{n}\left(\frac{\left(-1\right)^{n}}{\left(2k+1\right)!\left(2n-2k\right)!}x^{2k+1}y^{2n-2k}+\frac{\left(-1\right)^{n}}{\left(2k\right)!\left(2n-2k+1\right)!}x^{2k}y^{2n-2k+1}\right)==\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{n}\frac{1}{\left(2k+1\right)!\left(2n-2k\right)!}x^{2k+1}y^{2n-2k}+\sum_{k=0}^{n}\frac{1}{\left(2k\right)!\left(2n-2k+1\right)!}x^{2k}y^{2n-2k+1}\right)= $ now i want to change the summation index to make it closer to the expression of $ S(x+y) $ so: $ \sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{n}\frac{1}{\left(2k+1\right)!\left(2n-2k\right)!}x^{2k+1}y^{2n-2k}+\sum_{k=n+1}^{2n+1}\frac{1}{\left(2\left(k-n-1\right)\right)!\left(2n-2\left(k-n-1\right)+1\right)!}x^{2\left(k-n-1\right)}y^{2n-2\left(k-n-1\right)+1}\right)=\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{n}\frac{1}{\left(2k+1\right)!\left(2n-2k\right)!}x^{2k+1}y^{2n-2k}+\sum_{k=n+1}^{2n+1}\frac{1}{\left(2k-2n-2\right)!\left(4n-2k+3\right)!}x^{2k-2n-2}y^{4n-2k+3}\right)=\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\sum_{k=0}^{n}\frac{x^{k}y^{2n-k+1}}{\left(k!\right)\left(2n-k+1\right)!}\cdot\frac{x^{k+1}\left(k!\right)\left(2n-k+1\right)!}{y^{k+1}\left(2k+1\right)!\left(2n-2k\right)!}+\sum_{k=n+1}^{2n+1}\frac{x^{k}y^{2n-k+1}}{\left(k!\right)\left(2n-k+1\right)!}\cdot\frac{x^{k}y^{2n+2}\left(k!\right)\left(2n-k+1\right)!}{x^{2n+2}y^{k}\left(2k-2n-2\right)!\left(4n-2k+3\right)!}\right)$ Now im stuck. i dont know how to continue. Any ideas will help, thanks.","['trigonometric-series', 'calculus', 'sequences-and-series', 'power-series', 'limits']"
3660709,The 5 dimensional irreducible representation of $A_5$,"Hello I am trying to construct the 5 dimensional irreducible representation of $A_5$ . Here is my attempt: Take the irreducible character $\phi$ of $A_4$ that has the values: $\phi(1)=1, \phi(1,2)=1, \phi((1,2),(3,4))=\omega$ and $\phi(1,2,3,4)=\omega^2$ . Consider $\text{Ind}(\phi)$ . It is 5-dimensional, since $[A_5:A_4]=5$ . By Forbenius Reciprocity we have $$\langle \text{Ind}(\phi),\text{Ind}(\phi) \rangle_{A_5} =\langle \phi,\text{Res(Ind)}(\phi) \rangle_{A_4}=\langle \phi,\phi \rangle_{A_4}=1,$$ by the irreducibility of $\phi$ . Hence, $\text{Ind}(\phi)$ is a 5-dimensional irreducible representation of $A_5$ . Is this correct?","['lie-algebras', 'representation-theory', 'symmetric-groups', 'group-theory', 'lie-groups']"
3660751,A set with positive Lebesgue Measure and not Borel measurable,I know that Lebesgue measure is completion of Borel measure and there is zero Lebesgue measured set that is not Borel measurable. However I could not be sure that is there any set with positive Lebesgue measure which is not Borel measurable. I appreciate for any explanation or suggest etc.,"['measure-theory', 'lebesgue-measure', 'borel-measures']"
3660862,Scale-invariant functions and the case of the logarithm,"I just read the paper in Wikipedia [1] on scale invariance of some functions or curves $f(x)$ . I have a few questions on the mathematics related to this. In ref. [1], $f(x)$ is said to be scale invariant when $f(\lambda x) = \lambda^{\Delta} f(x),  \ \ \ \ \ \ \ \ \ \ \ \ Eq. [1]$ where $\lambda$ is a scale factor, and $\Delta$ an arbitrary exponent (they didn't provide the definition domains of such constants). 1) Is it the most formal definition of a scale-invariant function ? What are the definition domains of $\lambda$ and $\Delta$ ? I understand why the the monomials $f(x)=x^n$ is scale invariant but what about 2) the logarithmic function $f(x) = \mathrm{ln}(x)$ ? 3) And the spiral logarithmic function defined as $\theta = \frac{1}{b} \mathrm{ln}(r/a)$ ? I have some difficulties to prove that the above functions are scale-invariant according to Eq. [1], typically because of Eq. [1], I have a sum of logs and I can not factorize. I am probably missing a property on logarithmic functions that could help... [1] https://en.wikipedia.org/wiki/Scale_invariance","['definition', 'functions', 'analysis', 'real-analysis']"
3660876,Multivariable implicit function theorem proof,"I am trying to understand the proof of the implicit function theorem for multivariable functions. If I have a function $F(x,y,z) = 0$ with the assumption that $z = f(x,y)$ and we want to find $\frac{\partial z}{\partial x}$ , then taking the derivative with respect to x (partial derivative must be used because F is a multivariable function) on both sides gives: $$\frac{\partial F}{\partial x} = 0 \tag{1}\label{1}$$ The left side can be evaluated using the chain rule: $$\frac{\partial F}{\partial x} + \frac{\partial F}{\partial z} \frac{\partial z}{\partial x} = 0 \tag{2}\label{2}$$ The thing that I am having trouble understanding is that the term $\frac{\partial F}{\partial x}$ appears in both equations (1) and (2), so if I write something like $$\frac{\partial F}{\partial x} = \frac{\partial F}{\partial x} + \frac{\partial F}{\partial z} \frac{\partial z}{\partial x} = 0 \tag{3}\label{3}$$ Subtracting $\frac{\partial F}{\partial x}$ from each side gives: $$\frac{\partial F}{\partial z} \frac{\partial z}{\partial x} = 0$$ which is incorrect. Which step am I messing up?","['multivariable-calculus', 'calculus', 'implicit-function-theorem']"
3660919,contest problem related to divisor function,"Prove or disprove that there is only a finite set  of numbers which cannot be written as n + $\sigma(n)$ , where sigma(n) - number of divisors of n.
I know that $\sigma (p_1^{\alpha_1}\cdot...\cdot p_n^{\alpha_n}) = \prod(1+\alpha_i)$ i've tried to construct an infinite sequence and thought about numbers like $((2^2)^2)...^2$ but it all didn't worked out. i will appreciate any kind of hints.","['contest-math', 'number-theory']"
3660989,Integral $\int_0^1(1-x^3+x^5-x^8+x^{10}-x^{13}+\dots)dx$,$$\int_0^1(1-x^3+x^5-x^8+x^{10}-x^{13}+\dots)dx$$ Here's my attempts but I'm not sure that I'm doing well : $$\text{The integral gives :} 1-\frac1 4+\frac1 6-\frac1 9+ \frac{1}{11}-\frac{1}{14}+\dots$$ This series is : $$ S=\sum_{k=0}^\infty \frac{3}{(5k+1)(5k+4)}$$ Using Wolfram alpha I got : $$S=\frac1 5\sqrt{1+\frac{2}{\sqrt{5}}}\pi$$ So If what I did is true the integral must give us this value.,"['integration', 'definite-integrals', 'sequences-and-series']"
3661037,How do we compute the order of the Monster group?,"How do we compute the order of the Monster group? The answer is quoted in many places, but when I trace back the references, I can't find any place where it's computed, or even a sketch of the computation. They mostly point back to some article by Griess which is listed as ""to appear"" or ""in preparation"" but I can't find anywhere the article actually appeared. For example, in Griess' article ""The Friendly Giant"" , he writes in Section 15 (p. 96): Many properties of this hypothetical simple group [this refers to the Monster group] were derived, including ... a correct guess of its order, using the result of Frobenius which says that the cardinality of $\{g \in G: g^n = 1\}$ is divisible by $n$ , for any finite group $G$ and integer dividing $|G|$ (a proof that its order is the number of Sect. 1 was written down by Griess [36]). [36] is listed as ""The Structure of the Friendly Giant"", in preparation. It is not clear to me how one would use that theorem to compute, or even to guess, the order of the Monster. Elsewhere in the same article, in Lemma 2.16 (p. 11), Griess quotes a theorem of Steve Smith (from a paper entitled ""Large extraspecial groups of width 4 and 6"") saying that the order of a hypothetical group satisfying certain conditions is the order of the Monster. But Smith's article cites another article of Griess ""The Structure of the Monster Simple Group"" (which could be the article referenced above as [36] under a changed name, but in any case it doesn't contain the calculation mentioned), and that article cites another article of Griess listed as ""to appear"": ""On the subgroup structure of the group of order $2^{46} 3^{20} \ldots$ "" [the actual citation gives the full prime factorization of the Monster order]. I haven't been able to find that article, if it has appeared. Wikipedia mentions that the Thompson order formula is used (and a similar comment is made on p. 183 of the non-technical account ""Symmetry and the Monster"" by Mark Ronan), without giving more details.  This seems plausible because the order of the centralizers of the two involution classes were known, but it is not clear how one would compute the other terms in the Thompson order formula. Another article by Griess is ""Schur multipliers of some sporadic simple groups"" where in the introduction (p. 446), Griess says that there is ""strong evidence that a simple group ... of order $2^{46} 3^{20} \dots$ exists"" [again, the full factorization is given in the article]. But this is followed by 3 citations which are not accessible: a lecture by Fischer in 1973, the ""to appear"" article above ""On the subgroup structure of..."", and some unpublished work by Thompson. So how do we compute the order the Monster? Even if we don't know exactly how it was originally done, how would we do it now?  I'm looking for even a sketch of a proof of a theorem that says if a group satisfies some simple conditions that force it to be the Monster (like having two involution classes of the known centralizers, and maybe some other conditions that are needed), then its order is the order of the Monster. Is it too much to expect that one could compute the order directly by some counting argument using the construction by Griess, Conway, or any subsequent construction?","['group-theory', 'simple-groups', 'finite-groups']"
3661049,Explanation of notation used in chain rule,"Let $U\subseteq\mathbb{R}^{n}$ and $V\subseteq\mathbb{R}^{m}$ be open. Let $f:U\subseteq\mathbb{R}^{n}\to\mathbb{R}$ and $g_{1},g_{2},\dotsc,g_{n}\colon V\subseteq\mathbb{R}^{m}\to\mathbb{R}$ be $n$ functions such that: \begin{equation*}
    (g_{1}(x),g_{2}(x),\dotsc,g_{n}(x))\in U, \quad\forall\, x\in V.
\end{equation*} Furthermore let $x_{0}\in V$ , and let $j$ be a number in $\{1,\dotsc,n\}$ . Assume that $f$ is differentiable at $y_{0}=(g_{1}(x_{0}),g_{2}(x_{0}),\dotsc,g_{n}(x_{0}))$ and that the partial derivative $\frac{\partial g_{i}}{\partial x_{j}}(x_{0})$ exists for all $i=1,\dotsc,n$ . Then, the partial derivative of $f\circ (g_{1},g_{2},\dotsc,g_{n})$ exists w.r.t. the $j$ th coordinate of $x$ , and: \begin{equation*}
    \frac{\partial (f\circ g)}{\partial x_{j}}(x_{0})=\sum_{i=1}^{n}\frac{\partial f}{\partial y_{i}}(y_{0})\frac{\partial g_{i}}{\partial x_{j}}(x_{0}). 
\end{equation*} My question : Is it true that $y_{i}=g_{i}(x_{0})$ ? I know that it is a dumb question, but I am just curious. Thanks in advance.","['real-analysis', 'notation', 'multivariable-calculus', 'partial-derivative', 'chain-rule']"
3661146,Prove the Uniform Convergence of a Certain Series on Any Compact Subset of C,"$D \subset C$ is a connected open set. $a \in D$ , $f \in H(D)$ , the series $\sum_{n=0}^\infty f^{(n)}(a)$ converges. Prove that: $f$ can be extended to an analytic function on $C$ . $\sum_{n=0}^\infty f^{(n)}(z)$ converges uniformly on every compact subset of $C$ . (I am stuck on question 2. After achieving this series $\sum_{n=0}^\infty f^{(n)}(z)=\sum_{n=0}^\infty \sum_{m=0}^\infty f^{(m+n)}{(a)}\frac{(z-a)^m}{m!}$ , I wonder if a limit interchange can be justified.)","['complex-analysis', 'uniform-convergence', 'sequences-and-series']"
3661157,What's the connection between persistent homology and tensor networks?,Tensor networks are mathematical representations of quantum many-body systems. Persistent homology is a method for computing topological features. Are these two related? It has at least two implications that I could think of in the context of renormalization groups and quantum computing & quantum complexity theory.,"['tensors', 'group-theory', 'topological-data-analysis', 'mathematical-physics', 'computer-science']"
3661192,"If unique subgroups of order $m$ and $n$ exist, is subgroup of order $nm$ unique if it exists?","Suppose that $G$ is a group and has two unique subgroups of order $m$ and $n$ respectively, where $m$ and $n$ are different and greater than $1$ .  If there exists a subgroup of order $mn$ , then does it has to be unique? It seems that the statement is true when $G$ is abelian: $G$ can be represented by the direct product of $\mathbb{Z}_n$ and uniqueness of group of order $mn$ can be shown if it exists.
And I thought it would be false when $G$ is not abelian so tried to find a counterexample, but couldn't have found any. Is there any counterexample for this statement? Or could you help me with proving this?","['group-theory', 'abstract-algebra']"
3661209,From Riemann tensor to Ricci tensor and vice versa,"Is it possible to find the Riemann tensor using the Ricci tensor and also to switch from Riemann $(0,4)$ to Riemann $(1,3)$ ? I am not clear if these operations can only be carried out in one sense, I will explain better with these two questions. 1) $g^{bd}R_{abcd}=R_{ac}$ , where $R_{abcd}$ it is Riemann $(0,4)$ and $R_{ac}$ it is the Ricci tensor, is it now possible to get the Riemann tensor $(0,4)$ again this way: $R_{ac} g_{bd}=R_{abcd}$ ? 2) $g_{ae}R^a_{bcd}=R_{ebcd}$ , where $R^a_{bcd}$ it ise the Riemann $(1,3)$ and $R_{ebcd}$ it is the Riemann $(0,4)$ , is it now possible to get the Riemann tensor $(1,3)$ again this way: $g^{ae}R_{ebcd}=R^a_{bcd}$ ?","['curvature', 'tensors', 'riemannian-geometry', 'differential-geometry']"
3661213,Longest Sequence of Ones and Borel-Cantelli Lemma,"Problem: Let $X_1,X_2,\dots$ be an i.i.d. sequence of $\text{Bernoulli}$ random variables. Let $L_n$ be the length of the longest consecutive  sequence of ones among $X_1,\dots,X_n$ . Show that $$P\left(\limsup\limits_{n\to\infty}\frac{L_n}{\log_2(n)}\leq1\right)=1.$$ Attempt: In a hint to the problem it has been suggested that it suffices to show that for any $\varepsilon>0$ we have $P(L_n>(1+\varepsilon)\log_2(n)\text{ i.o})=0$ . Further, it has been pointed that to prove the above we can use the Borel-Cantelli lemma  with the events $$A_n=\left\{X_n=X_{n-1}=\cdots=X_{n-\lfloor(1+\varepsilon)\log_2(n)\rfloor}=1\right\}.$$ Therefore, we need to compute the probability of the event $A_n$ above. Using independence we have $$P(A_n)=P(X_n=1)\cdot P(X_{n-1}=1)\cdots P(X_{n-\lfloor(1+\varepsilon)\log_2(n)\rfloor}=1)=\frac{1}{2\cdot2^{\lfloor(1+\varepsilon)\log_2(n)\rfloor}}.$$ Then we have $$\sum_{n=1}^\infty P(A_n)\leq\sum_{n=1}^\infty \frac{1}{2\cdot2^{(1+\varepsilon)\log_2(n)}}=\frac{1}{2}\sum_{n=1}^\infty\frac{1}{n^{1+\varepsilon}}<\infty,$$ where in the last step we used the fact that $\sum_{n=1}^\infty\frac{1}{n^p}<\infty$ whenever $p>1.$ It follows from the Borel-Cantelli lemma that $$P(\omega\,:\,\omega\in A_n\text{ for infinitely many }n)=0.$$ This implies that $$P(L_n>(1+\varepsilon)\log_2(n)\text{ i.o.})=0.$$ This in turn implies that $$P\left(\frac{L_n}{\log_2(n)}\leq(1+\varepsilon)\text{ for all but finitely many }n\right)=1.$$ Taking the limit superior for all such $\omega$ in the event above we have that $$P\left(\limsup\limits_{n\to\infty}\frac{L_n}{\log_2(n)}\leq(1+\varepsilon)\right)=1,$$ and since $\varepsilon>0$ was arbitrary, we have that $$P\left(\limsup\limits_{n\to\infty}\frac{L_n}{\log_2(n)}\leq1\right)=1.$$ Could anyone help me verify the correctness of my approach and execution? Thank you very much for your time and valuable feedback.","['solution-verification', 'probability-theory', 'probability']"
3661269,Total disconnection and zero-dimension in Polish spaces,"First of all Polish spaces are completely-metrizable, separable topological space and by zero-dimensional Polish space I mean that the Polish space has a (countable) basis made of clopen sets. It is clear that a zero-dimensional Polish space is totally disconnected, I was wondering whether also the convers holds true. If we have a totally disconnected Polish space, is it also zero-dimensional (i.e. has a countable basis of clopen sets)? If not, is there a counter-example? I think it would suffice to prove that every open set in the space includes a clopen set (clopen w.r.t the overall space). Total disconnection implies that every non-empty open set (not singleton) is disconnected, hence it contains a clopen set w.r.t the open set (i.e. its relative topology), which is not, in general, clopen w.r.t the overall space. Since I've read it in my professor's notes, I'm prone to think that the thesis is true, but I'm having some problems in proving it. Some help? Thanks","['general-topology', 'descriptive-set-theory', 'polish-spaces']"
3661301,Evaluation of an integral of the form $C({\bf r})=\int\frac{{\rm d}^dk}{(2\pi)^d}\frac{{\rm e}^{{\rm i}{\bf k}\cdot{\bf r}}}{|{\bf k}|^2+m^2}$,"Consider a momentum-integral of the form in $d$ spatial dimensions: $$C({\bf r})=\int\frac{{\rm d}^dk}{(2\pi)^d}\frac{{\rm e}^{{\rm i}{\bf k}\cdot{\bf r}}}{|{\bf k}|^2+m^2}$$ where ${\bf r}=(x_1,x_2,\cdots,x_d)$ , ${\bf k}=(k_1,k_2,\cdots,k_d)$ and $m^2$ is a real number, could be positive, negative or zero. (Despite my notation, $m^2$ is any constant and has nothing to do with mass) See Eq. $(4.9)$ of this lecture note . Question Is this integral doable? I am interested in an exact analytical formula for extracting the results for different spatial dimensions $d$ (namely, $1,2$ and $3$ ). Update The existing answer by @DinosaurEgg, tells how to compute $C(\bf r)$ for $m^2>0$ . I would appreciate if someone can ameliorate expand on his answer by addressing how to handle the case $m^2<0$ .","['multivariable-calculus', 'definite-integrals', 'mathematical-physics']"
3661361,Find the closed path of given system of ordinary differential equation,"Consider the system of ordinary differential equations: $$\begin{cases}\frac{dx}{dt}=4x^3y^2-x^5y^4\\
\frac{dy}{dt}=x^4y^5+2x^2y^3\end{cases}$$ Then for this system there exist $1).$ A closed path in $\left \{(x,y) \in \mathbb{R^2}|x^2+y^2 \leq 5  \right \}$ $2).$ A closed path in $\left \{(x,y) \in \mathbb{R^2}|5<x^2+y^2 \leq 10  \right \}$ $3). $ A closed path in $\left \{(x,y) \in \mathbb{R^2}|x^2+y^2 >10 \right \}$ $4). $ No closed Path in $\mathbb{R^2}$ solution i tried - I first find out the $\frac{dy}{dx}$ $$\frac{dy}{dx}=\frac{x^2y^3+2y}{4x-x^3y^2}$$ it will become $$-(x^2y^2+2)ydx+(4-x^2y^2)xdy=0\;\;\;\;\;\;\;\
....................1$$ which is of from $$f_1(xy)ydx+f_2(xy)xdy$$ after that i find the $I.F$ of $1$ which comes out $$\frac{-1}{6xy}$$ now by multiplying this with $1$ i get $$\frac{1}{6} \left ( xy^2+\frac{2}{x} \right )  dx-\frac{1}{6} \left ( \frac{4}{y}+x^2y \right )dy=0$$ after solving this i get answer $$\frac{x^2y^2}{12}-\frac{1}{3}\log (\frac{x}{y^2})=c$$ but there is noting related to given option ,where i am making mistake please help Thank you","['solution-verification', 'ordinary-differential-equations']"
3661500,The Euler characteristic of a cubic Fermat surface,"Let $F$ denote the cubic Fermat surface in $\mathbf{P}^3$ (everything is over the complex numbers): $$ F = \{ X^3 + Y^3 + Z^3 + W^3  = 0\}\subseteq \mathbf{P}^3.$$ I wish to compute the Euler characteristic of this variety. (It is known to be 9, but I'm more interested in the method.) The approach I want to take is using complex Morse theory via Lefschetz pencils, as outlined by e.g. Lamotke or Nicolaescu. For a given pencil of hyperplanes in $\mathbf{P}^N$ and $X$ a (smooth) variety of dimension $n$ in $\mathbf{P}^N$ , then we have a formula $$ \chi (X) = 2\chi(X_b) - \chi(B) + (-1)^n r$$ where $X_b$ is a generic hyperplane section, $B$ is the base locus (i.e., the intersection of all hyperplanes in the pencil with $X$ ), and $r$ is the number of singular sections of the pencil (i.e., the number of hyperplanes in the pencil which do not intersect $X$ in a smooth variety). I apply this to the pencil $$ \{ H_{[\lambda:\mu]}\}_{[\lambda:\mu]\in\mathbf{P}^1}, \qquad \text{where}\quad H_{[\lambda:\mu]} := \{ \lambda X + \mu Y = 0\}.$$ This is a Lefschetz pencil in the sense of Lamotke, and it is not difficult to see that $B$ is a discrete set of three points. A generic hyperplane section is just an elliptic curve, so that the above formula reduces to $$\chi(F) = r - 3.$$ So we are left to find the number of hyperplanes that intersect $F$ in a singular variety, and it is here that I end up making a mistake. Let me outline my approach. It is easy to see that $H_{[1:0]}$ is not one of the singular sections, so without loss of generality we may put $\mu=1$ . The intersection $F \cap H_{[\lambda:1]}$ then becomes $$ \{X^3 + Y^3 + Z^3 + W^3  = 0,\ \lambda X + Y = 0 \}.$$ The hyperplane $H_{[\lambda:1]}$ determines an embedding $\mathbf{P}^2 \to \mathbf{P}^3$ with image this hyperplane. This is an isomorphism onto its image, so studying this intersection is the same as studying the pullback of $F$ along this map, which is the variety $$ \{(1 -\lambda^3) X^3 + Z^3 + W^3  = 0\}\subseteq \mathbf{P}^2$$ where I have chosen to use coordinates $(X,Z,W)$ on $\mathbf{P}^2$ for obvious reasons.
This is singular precisely when $\lambda^3 = 1$ , i.e., when $\lambda$ is a third root of unity.
This would yield $r=3$ , so that $\chi(F) = 0$ , which is impossible.
(Even if one doesn't know the Euler characteristic, one can easily compute all but the second homology groups of $F$ , and deduce that $\chi(F)$ must be at least 3.) Which singular sections am I missing?","['complex-geometry', 'algebraic-geometry', 'morse-theory']"
3661618,Sum of multinomial coefficients with bounded indices,"I want to know if there's a closed formula for $$
f_{k}(n_{1}, \dots, n_{k}) = \sum_{i_{1} = 0}^{n_{1}} \cdots \sum_{i_{k} = 0}^{n_{k}} \frac{(i_{1} + \cdots + i_{k})!}{i_{1}!\cdots i_{k}!}
$$ for $k\geq 1$ and nonnegative integers $n_{1}, \dots, n_{k}$ . 
It isn't that hard to show that $$
f_{1}(n_{1}) = n_{1} + 1
$$ and $$
f_{2}(n_{1}, n_{2}) = \binom{n_{1} + n_{2} + 2}{n_{1} + 1} - 1
$$ but I can't find any closed form formula for general $k$ . Can anyone help?","['summation', 'combinatorics', 'multinomial-coefficients']"
3661645,Variant of Parseval equality in Hilbert space,"We know that if $(x_n)_{n\in\mathbb{N}}$ is a sequence of element in a Hilbert space $(\mathcal{H}, \langle\cdot,\cdot\rangle)$ such that for $n\neq m$ , $x_n\perp x_m$ . Then the series $\sum_{n\in\mathbb{N}} x_n$ converges if and only if the series $\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2$ converges, and in that case, we have $$
\Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 = \sum_{n\in\mathbb{N}}\Vert x_n\Vert^2
$$ Now, if we take another sequence $(x_n)_{n\in\mathbb{N}}$ in $\mathcal{H}$ such that there exists $N_0\geqslant 1$ such that if $\vert n-m\vert\geqslant N_0$ , then $x_n\perp x_m$ . We also suppose that $\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2$ exists (i.e. is finite).
Prove that the series $\sum_{n\in\mathbb{N}}x_n$ is convergent and that there exists a constant $C$ which only depends on $N_0$ , such that $$
\Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 \leqslant C\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2
$$ My try:
Like in the Parseval equality proof, I try to prove that $S_q=\sum_{n\leqslant q}x_n$ is a Cauchy sequence: $$
\begin{align}
\Vert S_{q+q'}-S_q\Vert^2
&=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j=q+1}^{q'}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\
&=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j\in I_n}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\
&\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\sum_{j\in I_n}\vert\langle x_n,x_j\rangle\vert\\
&\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\Vert x_n\Vert\sum_{j\in I_n}\Vert x_j\Vert
\end{align}
$$ where $I_n=\{j:\vert n-j\vert\leqslant N_0\}$ . I know that $\vert I_n\vert\leqslant N_0$ , but I can only seem to have $$
\sum_{j\in I_n}\Vert x_j\Vert\leqslant N_0\sup_{j\in I_n}\Vert x_j\Vert
$$ I cannot seem to go further than that. 
I am able to bound $\sup_{j\in I_n}\Vert x_j\Vert$ by $C_j\Vert x_q\Vert^2$ if $x_q\neq 0$ with $C_j\in\mathbb{R}$ but this does not seem to be sharp enough, as the sequence $(C_j)_{j\in\mathbb{N}}$ is not easily bounded. The same happens if I consider $\Vert S_q\Vert$ when trying to prove the inequality.
Note that $N_0=1$ is the same case as in the Parseval equality. Any help would be appreciated, thanks!","['inner-products', 'sequences-and-series']"
3661815,log|x| is a tempered distribution,"How do I prove that $\log|x|$ is a tempered distribution on $\mathcal{S}(\mathbb{R}^n)$ , ie., I need to prove that the linear functional $$\phi \in \mathcal{S}(\mathbb{R}^n) \mapsto \int_{\mathbb{R}^n} \phi(x)\log|x|dx	$$ is continuous. It's suficcient to prove that $\phi_k \rightarrow 0$ in $\mathcal{S}(\mathbb{R}^n)$ implies that $\int_{\mathbb{R}^n} \phi_k(x)\log|x| \rightarrow 0$ as $k \rightarrow \infty$ , but I don't know estimate $\phi_k(x)\log|x|$ by an integrable function, so I could use dominated convergence theorem, or estimate it by a sum seminorms $\|\phi_k\|_{\alpha,\beta}$ . (this is the Example 2.3.5 (7) from Grafakos's Book - Classical Fourier Analysis - third edition)","['fourier-analysis', 'functional-analysis', 'real-analysis']"
3661817,showing that $S=\{A\in M_{n}; x'=Ax \ \text{is hyperbolic}\}$ is open,"I tried to show that the complement is closed, $S^c=\{A\in M_n, \text{real part of eigenvalues is 0}\}$ . So i tried to show that this set is closed by $(\{0\}\times \mathbb{R})$ in the fuction: \begin{align}
F:M_n&\to \{\text{eigenvalues of M_n}\}\subset \mathbb{C} \\
\end{align} where $F(M)$ is where the eigenvalues is. 
Is this function continuous? Is there another way to do this?","['linear-algebra', 'ordinary-differential-equations', 'analysis']"
3661872,"If $\nu \ll \mu$, there exists $E \in \cal F$ and $n \geq 1$ such that $\nu(E) >0$ and $n^{-1} \mu(A) \leq \nu(A) \leq n\mu(A)$ for all $A \subset E$.","I'm thinking about the following question from an old prelim: Let $(X, \cal{F})$ be a measure space with $\sigma$ -finite measures $\mu$ and $\nu$ (it does not say whether these are signed measures). If $\nu \ll \mu$ and $\nu \neq 0$ , then there exists $E \in \cal F$ and $n\in \mathbb{N}$ such that $\nu(E) >0$ and $n^{-1} \mu(A) \leq \nu(A) \leq n\mu(A)$ for all $A \in \cal{F}$ with $A \subset E$ . Let's assume that these are positive measures. Since both are $\sigma$ -finite and $\nu \ll \mu$ , we can choose and extended $\mu$ -integrable function $f:X \to \mathbb{R}$ such that $d\nu = fd\mu$ . Then we hope to find $n\geq 1$ and $E \in \cal{F}$ such that $$
n^{-1} \mu(A) \leq \int_A f d\mu \leq n\mu(A)
$$ for all measurable $A \subset E$ . Since $n \mu(A) = \int_A n d\mu$ and $n^{-1}\mu(A) = \int_A n^{-1} d\mu$ , I thought about looking at the set $E_n= \{ x \in X: n^{-1} \leq f(x) \leq n\}$ for appropriately chosen $n$ , but I'm not sure if this is the right idea.","['measure-theory', 'analysis']"
3661889,"Find a Borel measure $\mu$ such that $\int_0^1 f(t) d\mu(t)=\Lambda f, \forall f\in C[0,1]$","I'm working through a problem set for my functional analysis course and one of the problems requires me to find a Borel measure such that $\int_0^1 f(t) d\mu(t)=\Lambda f, \forall f\in C[0,1]$ , where $\Lambda:C[0,1]\to \mathbb{R}$ is the linear functional $$\Lambda f = \lim_{n\to+\infty} (n+1)\int_0^1 t^n f(t) dt.$$ I've determined that $\Lambda x^k=1, \forall k\in\mathbb{N}$ and, since $\{x^k\}$ is a fundamental set in $C[0,1]$ , I'm thinking it would be enough to determine the measure from the condition $\int_0^1 t^n d\mu(t)=1$ , but that's where I'm stuck now. I would love an idea of how to continue solving this or another idea of how to approach this problem.","['measure-theory', 'operator-theory', 'functional-analysis', 'borel-measures']"
