question_id,title,body,tags
1582849,Find $\int_{0}^{\infty} \frac{\ln(x)}{1+x^2}dx$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Find $\displaystyle \int_{0}^{\infty} \dfrac{\ln(x)}{1+x^2}dx$. How should I change the limits of integration to evaluate this?","['integration', 'calculus']"
1582922,Integral Property: $\int^a_{0}f(x)dx=\int^a_{0}f(a-x)dx$ [Proof by definition of Riemann Sums],"This link: Why $\int_0^af(x)dx=\int_0^af(a-x)dx$? addresses this question but I do not follow the proofs in the answers: Each proof starts off with variable $x$ but ends the right hand side with a different variable. How does that work? I can't find this discussed anywhere else on the internet. For example, how do we get from 
$\int_0^a f(x)dx$ to $\int_a^0 f(a-x)(-dx)$?(I apology if I'm overlooking some silly thing but for some reason I am stuck): Does anyone know the proof or where else I can find it? Also are there any special conditions on it? $$\int^a_{0}f(x)dx=\int^a_{0}f(a-x)dx$$","['integration', 'calculus']"
1582927,Meaure-theoretic induction: Why dyadic approximation?,In measure-theoretic induction proofs we always use the dyadic approximation of a non-negative measurable function $Y$ as $$Y_n = \sum_{k=0}^{n2^n-1} k/2^n 1\left(\frac{k}{2^n} \leq Y < \frac{k+1}{2^n}\right) + n1\left(n \leq Y\right)$$ Can you tell me why this is correct and why some other approximation would not work  (or would it?) Thank you very much.,"['measure-theory', 'approximation']"
1582930,standard deviation for regression,"The first slide is the denifition of simple linear regression model, the second slides is an example I have two questions:
 1.Did I get the right calculation of the standard deviation? 
2.I still have difficulties in understanding Confidence interval for mean and Confidence interval and Prediction interval. For the example above, if I was correct,the standard deviation would be 0.0634 then y3 would be :y3~(10,0.0634^2), so we can say we are 95% sure y3 would be from 10-2*0.0634 to 10+2*0.0634, why we still need Confidence interval for mean and and Prediction interval?","['regression', 'statistics']"
1582932,"If $\small {x+\sqrt { (x+1)(x+2) } +\sqrt { (x+2)(x+3) } +\sqrt { (x+3)(x+1) } = 4}$, solve for $x$.","I came across this olympiad algebra problem, asking to solve for $x$: $x\ +\ \sqrt { (x+1)(x+2) } \ +\ \sqrt { (x+2)(x+3) } +\ \sqrt { (x+3)(x+1) } =\ 4$ Here was my try: If $$x\ +\ \sqrt { (x+1)(x+2) } \ +\ \sqrt { (x+2)(x+3) } +\ \sqrt { (x+3)(x+1) } =\ 4$$ Then $\quad \sqrt { (x+1)(x+2) } +\sqrt { (x+2)(x+3) } +\sqrt { (x+3)(x+1) } =4-x$. Further, I tried squaring the equation on both sides, but that doesn't seem to solve my problem. Please help. Thank you.","['algebra-precalculus', 'contest-math']"
1582943,Integral $\int_0^\infty\frac{\tanh^2(x)}{x^2}dx$,"It appears that
$$\int_0^\infty\frac{\tanh^2(x)}{x^2}dx\stackrel{\color{gray}?}=\frac{14\,\zeta(3)}{\pi^2}.\tag1$$
(so far I have about $1000$ decimal digits to confirm that).
After changing variable $x=-\tfrac12\ln z$, it takes an equivalent form
$$\int_0^1\frac{(1-z)^2}{z\,(1+z)^2 \ln^2z}dz\stackrel{\color{gray}?}=\frac{7\,\zeta(3)}{\pi^2}.\tag2$$
Quick lookup in Gradshteynâ€”Ryzhik and Prudnikov et al. did not find this integral, and it also is returned unevaluated by Mathematica and Maple . How can we prove this result? Am I overlooking anything trivial? Further questions: Is it possible to generalize it and find a closed form of 
$$\mathcal A(a)=\int_0^\infty\frac{\tanh(x)\tanh(ax)}{x^2}dx,\tag3$$
or at least of a particular case with $a=2$? Can we generalize it to higher powers
$$\mathcal B(n)=\int_0^\infty\left(\frac{\tanh(x)}x\right)^ndx?\tag4$$ Thanks to nospoon 's comment below, we know that 
$$\mathcal B(3)=\frac{186\,\zeta(5)}{\pi^4}-\frac{7\,\zeta(3)}{\pi^2}\tag5$$
I checked higher powers for this pattern, and, indeed, it appears that
$$\begin{align}&\mathcal B(4)\stackrel{\color{gray}?}=-\frac{496\,\zeta(5)}{3\,\pi^4}+\frac{2540\,\zeta(7)}{\pi^6}\\
&\mathcal B(5)\stackrel{\color{gray}?}=\frac{31\,\zeta(5)}{\pi^4}-\frac{3175\,\zeta(7)}{\pi^6}+\frac{35770\,\zeta(9)}{\pi^8}\\
&\mathcal B(6)\stackrel{\color{gray}?}=\frac{5842\,\zeta(7)}{5\,\pi^6}-\frac{57232\,\zeta(9)}{\pi^8}+\frac{515844\,\zeta(11)}{\pi^{10}}\end{align}\tag6$$","['hyperbolic-functions', 'calculus', 'closed-form', 'integration', 'definite-integrals']"
1582959,Determinant of a $2n$ square block matrix in which all blocks commute,"Problem: Let $A , B , C , D$ be commuting $n$-square matrices. Consider the $2n$-square block matrix 
$$M=\begin{pmatrix}  A & B  \\  C & D\end{pmatrix}$$ 
Prove that $|M|= |A||D| - |B||C|$, where $|M|$ means the determinant. I should also state that this from a beginning Linear Algebra book, so I have not studied any fancy determinant formulas yet. My problem here is that everything I can try involves multiplication but there is a minus sign on the right hand side which I cannot presently handle. Note: (this is not the same question as has been asked before here on this site as the formula here is quite different.)","['matrices', 'linear-algebra', 'determinant']"
1582964,Differentiating $x=1$ with respect to $x$,"Sorry this may sound like a silly question and I know that this does't meet the quality standards of Math S.E, I found this in one of the Math-Jokes websites and found it interesting, $$x=1$$
    $$\frac{d}{dx} x=\frac{d}{dx} 1$$
  $$1=0$$ What I think is the problem is that it is not differentiable, saying $x=1$ is equivalent to saying $y=\delta(x-1)$, which as we know is not continuous at $x=1$, and so it is not differentiable. is this right? or is there some other reason to resolve the paradox?","['derivatives', 'calculus']"
1582967,How can we define the infinite sum of $1$ and $-1$?,"$1-1+1-1+1-1+1-1+1-1......$ it seems first that this is equal to $0$ but we re-arrange this sum $1+(1-1)+(1-1)..... $ so the sum is $1$ In this case, do we say that this sum is undefined?","['real-analysis', 'sequences-and-series', 'discrete-mathematics']"
1582969,"If $0\lt y \le 1$, prove that there exists a unique positive real number $x$ such that $x^2=y$","I'm stumped. I don't want an entire solution, just a hint. If $0\lt y \le 1$, prove that there exists a unique positive real number $x$ such that $x^2=y$ The section in the book I'm on is the least upper bound property","['real-analysis', 'proof-writing', 'analysis']"
1582983,Uniform limit of one-to-one analytic functions is either constant or one-to-one,"Let $U$ be a complex domain, and $(f_n)_{n\in \mathbb{N}}$ be a sequence on one-to-one analytic functions defined on $U$ . Suppose that $f_n$ converges to $f$ uniformly on every compact subset of $U$ . Prove that $f$ is either constant or one-to-one on $U$ . Here's my proof. I would appreciate if you guys point out any possible mistakes, or maybe give a different proof that uses different techniques. We may assume that the zeros of $f$ have no accumulation point in $U$ , otherwise, $f$ is identically zero. Now we proceed by contradiction; suppose, WLOG, that $f$ has two zeros in $U$ ; say $f(a)=f(b)=0$ . There exists $\delta >0$ such that $a$ and $b$ are the only zeroes of $f$ in $B(a,\delta)$ and $B(b,\delta)$ , respectively. Moreover, the Maximum Modulus Principle implies that $|f(z)|>0$ on the boundaries of the two balls above; say $$|f(z)|>m>0\, \text{ for all }\, z\in \partial B(a,\delta)\cup \partial B(b,\delta).$$ Since $f_n \rightarrow f$ uniformly on compact sets, then for $n$ large enough, we have $$|f_n (z)-f(z)|<m<|f(z)| \, \text { for all } \,z\in \partial B(a,\delta)\cup \partial B(b,\delta).$$ By Rouche's Theorem, $f_n$ and $f$ have the same number of zeroes in $B(a,\delta)$ and $B(b,\delta)$ , namely one in each ball (not counting multiplicities). But this contradicts the assumption that $f_n$ is one-to-one.","['complex-analysis', 'proof-verification']"
1583004,why $ 1 - \cos^2x = \sin^2x $? [duplicate],"This question already has answers here : Prove $\sin^2\theta + \cos^2\theta = 1$ (16 answers) Closed 8 years ago . I'm trying to prove this result $$\lim_{x\to 0} \frac{1 - \cos(x)}{x} = 0$$ In this process I have come across an identity $1-\cos^2x=\sin^2x$. Why should this hold ? Here are a few steps of my working:
\begin{array}\\
 \lim_{x\to 0} \dfrac{1 - \cos(x)}{x}\\ = \lim_{x\to 0} \left[\dfrac{1 - \cos(x)}{x} \times    \dfrac{1 + \cos(x)}{1 + \cos(x)}\right] \\
=\lim_{x\to 0} \left[\dfrac{1 - \cos^2(x)}{x(1+\cos(x))}\right]  \\
=\lim_{x\to 0} \left[\dfrac{\sin^2(x)}{x(1+\cos(x))}\right]
\end{array}","['trigonometry', 'limits']"
1583017,Does sample-path continuity imply mean square continuity?,"Let $(X_t)_{t>0}$ be a square-integrable stochastic process on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. I'm well aware that in general almost sure convergence does not imply mean square convergence, unless some additional conditions (such as the ones of the dominated convergence theorem) are met. I've also come across this related question where the OP is interested in the case of (the weaker) almost sure continuity at a given time. However, in the stronger case of sample path continuity (i.e. $\forall \omega \in \Omega, t \to X(t, \omega)$ is a continuous function) I am curious as to whether the process would also be mean square continuous. If so, I'd appreciate any pointer to the proof. If not, can you please provide a counter-example? The counter-example provided in the question above does not have continuous paths. Please note that these lecture notes , more specifically the remark following Definition 72, seem to suggest that not only is it true in general, but the proof is also obvious. Thanks,","['stochastic-processes', 'probability-theory', 'convergence-divergence']"
1583056,How to solve $y'=e^{\frac{xy'}y}$?,How to solve the following equation? $$y'=e^{\frac{xy'}y}$$ We must find a common solution.,"['integration', 'ordinary-differential-equations']"
1583089,Solving functional equation $f(x+y)^2=f(x)^2+f(y)^2$,"I need to solve the following functional equation:$$f(x+y)^2=f(x)^2+f(y)^2$$
I'm familiar with simpler ones such as $f(x)+f\left(\frac{1}{1-x}\right)=x$ (I use substitutions), but here I cannot find any reasonable substitution.","['functions', 'functional-equations']"
1583103,Tablecloth & table problem,"Friday night we threw an house warming party and invited quite a number of fellow students. To fit everybody around the table we had to enlarge it, pulling out two sort of shelves from the short sides, but unfortunately our tablecloth was too small. Being a bunch of smart engineering students we started to discuss how to lay out the tablecloth on the table, whether an optimum existed and how to find it. Luckily enough beer and wine let us rapidly change the subject, but did not kill the curiosity. Here is some (sorta) math jargon, finally: you have a table of known dimensions $a$ and $b$ you have a tablecloth of known dimensions $c$ and $d$ $a>c>d>b$ holds$^*$ Thickness is not a problem, i.e. the tablecloth might hang how much you want and the table sides must not necessarily be covered. This is a problem on the plane . Your goal is to maximize the covered surface of the table, your knobs are three real numbers, the tablecloth position and its angle with respect to the table. I am afraid that the optimum depends on how the inequality holds, i.e. the solution changes dramatically if the tablecloth short side is, say, 100 times the table short side. If this is the case please stick to ""reasonable"" values, i.e. the difference between the various dimensions is within the $10\%$ range. And I also believe the solution is symmetrical, i.e. the tablecloth is centered on the table, but I am not entirely sure of it. Folding the tablecloth is not permitted, mainly because the problem gets heavily dependent on the ratio $\frac{d}{b}$. The question is: How can I prove there is an optimum and find it? $^*$this means that the tablecloth short side is longer than the table short side, and the table long side is longer than the tablecloth long side. Plus both the table and the tablecloth are rectangular.","['puzzle', 'optimization', 'geometry']"
1583128,"For what $r,s$ exist unbiased estimation of $f(p) = p^{r}(1 - p)^{s}$ for binomial distribution?","We have sample $x_1, ..., x_n$ generated by independent binomial random variables $\xi_1, ..., \xi_n$. We know parameter $k$ but don't know probability $p$. k is number of tests: $\xi_i \sim Binomial(k,p)$ The task is to find numbers $r,s$, that there is exist unbiased estimation for $$f(p) = p^{r}(1 - p)^{s}$$ The problem is that I don't understand the general approach how to test existence of unbiased estimation. Could you help me please?","['statistics', 'estimation', 'probability', 'binomial-distribution']"
1583133,Sets with Hausdorff-Measure 0,"The $\alpha$-Dimensional Hausdorff-Measure of a Set A is defined as $H^\alpha (A)=\inf_{A\text{ is countable covering}}\sum_{A'\in A} diam(A')^\alpha$. It is easy to show, that for every set $E\subseteq\mathbb{R}^d$ there exists a unique $\beta\in \mathbb{R}$, so that $H^\alpha(E)=0$ for $\alpha>\beta$ and $H^\alpha(E)=\infty$ for $\alpha < \beta$. This $\beta$ is called the Hausdorff-Dimension $dim(E)$ of E. It is easy to show, that $dim(\mathbb{R}^d)=d$ and $H^d(\mathbb{R}^d)=\infty$. I  wonder if there is any Set A with $dim(A)=\alpha$ and $H^\alpha(A)=0$.
Does anybody have an idea how to approach this?","['dimension-theory-analysis', 'measure-theory']"
1583137,Olympiad Trigonometric Inequality,"Let $R$ and $r$ be the circumradius and inradius of $\triangle ABC$.
  Prove that $$\frac { \cos { A }  }{ { \sin   }^{ 2 }A } +\frac { \cos { B }  }{ { \sin   }^{ 2 }B } +\frac { \cos { C }  }{ { \sin   }^{ 2 }C } \ge \frac { R }{ r }$$ I am not able to get a solution to this inequality. Any help would be  appreciated. Thank you.","['contest-math', 'inequality', 'trigonometry', 'triangles']"
1583149,How to describe the points of a quotient stack?,"Let $G$ be a finite algebraic group acting on a projective complex variety $X$. Then a quotient $Y=X/G$ exists as a scheme and, if $G$ acts freely, $Y$ is an orbit space and the natural map $$\eta:[X/G]\to X/G=Y$$ is an isomorphism.
I am trying to figure out how this isomorphism works at the level of points . The $\mathbb C$-points of $Y$ are the orbits of the action. These must correspond to the $\mathbb C$-points of the stack $[X/G]$, which are $G$-equivariant maps $G\to X$. I am trying to see how this correspondence works. I would say that a $G$-orbit $\textrm{Orb}(x)\subset X$ should correspond to the $G$-equivariant map $\alpha_x:G\to X$ sending $g\mapsto g\cdot x$. The orbit is just the image of this map. But conversely, if I have a $G$-invariant map $G\to X$, is it obvious that its image is an orbit? Let now $S$ be any scheme over $\mathbb C$. The $S$-points of the stack $[X/G]$ are couples $(P,f)$ where $P\to S$ is a principal $G$-bundle and $f:P\to X$ is a $G$-equivariant map. I cannot describe explicitly the $S$-points of $Y=X/G$. Question . Is it true, at least Ã©tale locally, that the $S$ points of $Y$ are the orbits of the action of $G(S)$ on $X(S)$? How do the
  $S$-points of $Y$ compare to those of $[X/G]$? Thanks!","['group-actions', 'algebraic-stacks', 'algebraic-geometry']"
1583160,When is a mobius transformation its own inverse?,"I was puzzeling  trying to find the inverse of the mobius transformation $$ f(z) \ = \  \frac{z + i}{iz+1} $$ 
and if I am correct (I can be wrong here) it is its own inverse $( f(f(z)) = z )$ Are there general rules to check if any  mobius transformation is its own inverse ? something like $$
f(z) \  = \  \frac{az+b}{cz+d}
$$
Is its own inverse iff:","['mobius-transformation', 'complex-numbers', 'geometry']"
1583164,Finding the number of sub-grids of a matrix,"I am trying to find the number of $M\times M$ sub-grids given an $N\times N$ matrix, where $M \leq N$ . For any concrete example it is easy to find the correct answer:
Eg: $$\left( \begin{array}{ccc}
4 & 3 & 8\\
9 & 5 & 1\\ 
2 & 7 & 6\\
\end{array} \right)$$ This is a $3 \times 3$ matrix:
The number of $1 \times 1$ sub-grids is 9;
the number of $2 \times 2$ sub-grids is 4;
and the number of $3 \times 3$ sub-grids is 1. I am trying to find a general formula to find the number of sub-grids.
So far I have been looking at the dimensions of each: A $4 \times 4$ matrix will have: $$16 \quad (1 \times 1)$$ $$9 \quad (2 \times 2)$$ $$4 \quad (3 \times 3)$$ $$1 \quad (4 \times 4)$$ sub-grids. By trial I have concluded that the number of sub-grids can be calculated by: $$({N-M+1})^2$$ Could someone please confirm that this is a correct conclusion and maybe give some intuition to why is so? (e.g. the number of shifts it is possible to make with the sub-grids in the matrix)",['matrices']
1583211,Proportion of nonabelian $2$-groups of a certain order whose exponent is $4$,"Let $$\displaystyle A(n)=\frac{\text{number of nonabelian 2-groups of order $n$ whose exponent is }4}{\text{total number of nonabelian 2-groups of order $n$}}.$$ Using GAP, I could observe the following: $$A(16)=\frac{5}{9}=0.5556, A(32)=\frac{21}{44}=0.4773,
A(64)=\frac{93}{256}=0.3633, A(128)=\frac{820}{2313}=0.3545, A(256)=\frac{30446}{56070}=0.5430 \text{   and } A(512)=\frac{8791058}{10494183}=0.8377.$$ Can one prove that if $n>4$, then $A(n)>\frac{1}{3}$?","['2-groups', 'finite-groups', 'abstract-algebra', 'groups-enumeration', 'gap']"
1583214,Calculating the expectation of $X=$ the number of failures until the $r^{th}$ success,"I need to calculate the expectation of $X=$ the number of failures until the $r$-th success in an infinite series of Bernoulli experiments with $p$ the probability of success. ($q=1-p$ the probability of failure) My solution: I figured $$P(X=x)={x+r \choose x}q^xp^r$$ (is this correct?) and $x\geq 0$ (In other words, $X\sim Bin(x+r,q)$. So by definition, $\Bbb EX=\sum_{x=0}^\infty x{x+r \choose x}q^xp^r$. Trying to simplify this, I got to
\begin{align*}
\frac{qp^r}{r!}\sum_{x=0}^\infty (x+r)(x+r-1) \ldots (x+1)xq^{x-1} & =\frac{qp^r}{r!}\left(\sum_{x=0}^\infty q^{x+r}\right)^{(r+1)}\\ & =\frac{qp^r}{r!}\left(q^r\sum_{x=0}^\infty q^{x}\right)^{(r+1)}\\ & =\frac{qp^r}{r!}(\frac{q^r}{1-q})^{(r+1)}
\end{align*} $(r+1)$ denotes taking the $(r+1)^{th}$ derivative in respect to $q$. Now what? How can I simplify that further? Is there a simpler way?","['probability-theory', 'probability', 'expectation']"
1583271,Partitions of the odd integers,"Understanding the nature of the odd integers is a necessity to prepare oneself to work on the unsolved problems in number theory, such as the Collatz $3n+1$ problem.     I hope to demonstrate how the odd integers can be represented as a sequence of sets which fit together like a glove with infinite fingers.  First, some definitions are required. Define a sequence $(A_k)$ of ordered sets by: $$ A_0 = \{3, 7, 11\} $$ $$ A_1 = \{1, 9, 17\} $$ $$ A_2 = \{13,29,45\} $$
$$ A_3 = \{5, 37, 69\} $$   and
$$ A_{k+2} = A_k + 4 ( A_k â€“ A_{k-2}) \forall k>1, $$ Note that the operations implied are matrix addition, subtraction and scalar multiplication on the $1 \times 3$ matrices formed from sets $A_k.$ For example, when  $k=2$ we have:
$$ A_2 = \{13,29,45\}, \mbox{ in matrix form is }\begin{pmatrix}13 \\29 \\45\end{pmatrix} $$
$$ A_0 = \{3, 7, 11\}, \mbox{ in matrix form is }\begin{pmatrix}3\\ 7\\ 11\end{pmatrix} $$ By definition: $$A_4 = A_2 + 4 ( A_2 - A_0) $$ 
$$ A_4 = \begin{pmatrix}13\\ 29\\ 45\end{pmatrix} + 4\left(\begin{pmatrix}13\\ 29\\ 45\end{pmatrix} - \begin{pmatrix}3\\ 7\\ 11\end{pmatrix}\right)$$
$$ A_4 = \begin{pmatrix}13\\ 29\\ 45\end{pmatrix} + 4\begin{pmatrix}10\\ 22\\ 34\end{pmatrix} $$
$$ A_4 = \begin{pmatrix}13\\ 29\\ 45\end{pmatrix} + \begin{pmatrix}40\\ 88\\ 136\end{pmatrix} $$
$$ A_4 = \begin{pmatrix}53\\ 117\\ 181\end{pmatrix} $$ Converting back to set notation gives: 
$$ A_4 = \{53, 117, 181\} $$ The next step is to extend the finite sets $\,A_k\,$ to infinite sets $\,M_k\,$ as follows: Define: $$ M_k = \left\{p \in \mathcal{N}, p \equiv 1 \pmod 2 : \exists a \in A_k, p\equiv a\pmod {3\left(2^{k+2}\right)} \right\} $$ By definition of $M_0$: if $(a \in A_0)$, then
$$ a + 12i \in M_0, \forall i \in \mathcal{N},$$ By definition of $M_k$: if $ (a \in A_k)$ then 
$$ a+3i(2^{k+2}) \in M_k, \forall i \in \mathcal{N}. $$ Assertion: 
$$ \forall n \in \mathcal{N}, n\equiv 1\pmod 2,\,\exists k \in \mathcal{N}, k\geq0 \text { such that } n \in M_k $$ Since this analysis was developed informally, is there a better way to express the assertion in order to search for prior solutions?","['number-theory', 'collatz-conjecture']"
1583282,Number of non-negative integers solutions of $x_1 + x_2 + x_3 + x_4 + x_5 = 10$ when $x_1 = x_2$ and when $x_1 > x_2$,$X_1 + X_2 + X_3 + X_4 + X_5 = 10$. (i) How many non-negative integer solutions are there? this is the easy part (ii) How many non-negative integer solutions are there such that $X_1 = X_2$? Do i just divide the answer in $1$ by $2$? (iii) How many non-negative integer solutions are there such that $X_1 > X_2$? I am not sure how to begin Thanks in advance,"['combinatorics', 'discrete-mathematics']"
1583309,Double annihilator of subspace of $X'$ is its weak*-closure,"Let $X$ be a Banach space with dual space $X'$. Let $N$ be a subspace of $X'$. Can anyone show me why the double annihilator of $N$ is its weak*-closure? By double annihilator I mean: annihilator $N^{\perp}=\{x\in X:\lambda(x)=0, \forall \lambda \in N\}$ double annihilator $(N^{\perp})^{\perp}=\{\lambda\in X':\lambda(x)=0, \forall x \in N^{\perp}\}$ Thank you in advance!","['functional-analysis', 'banach-spaces']"
1583320,Neron-Severi group as the image of first Chern class,"Let $X$ be a smooth projective variety over $\mathbb{C}$, then the Neron-Severi group $NS(X)$ of $X$ is defined to be the Picard group of $X$ modulo algebraically equivalent relations. On the other hand, by the exponential sequence, there is a first Chern class map $$c_1: {\rm Pic}(X) \to H^2(X, \mathbb{Z}).$$ It is claimed that the image of $c_1$ coincides with $NS(X)$. I want to know why this is true. Any suggestion or reference is greatly welcome!","['reference-request', 'complex-geometry', 'algebraic-geometry']"
1583326,Normal bundle of twisted cubic.,"Let $C$ be a twisted cubic in $\mathbb P^3$. I'd like to compute the splitting type of normal bundle $N_{C/\mathbb P^3}$? I understood that $T_{\mathbb P^3}|_C=\mathcal O(4)^{\oplus 3}.$ So we have an short exact sequence $$
0 \to \mathcal O(2) \to \mathcal O(4)^{\oplus 3} \to N_{C/\mathbb P^3} \to 0.
$$
So $N_{C/\mathbb P^3} =\mathcal O(4) \oplus \mathcal O(6)$ or $N_{C/\mathbb P^3} =\mathcal O(5)^{\oplus 2}.$ But I don't know how to prove that this normal bundle is actually $\mathcal O(5)^{\oplus 2}$.","['algebraic-curves', 'coherent-sheaves', 'algebraic-geometry']"
1583385,Eigenvalue problem of S-L DE $y''-2xy'+\lambda y=0$.,"Suppose we have a Sturm-Liouville differential equation $$y''-2xy'+\lambda y=0.$$ The equation has a polynomial solution in the case $\lambda =4$. So if we write the equation in self-adjoint form, we get: $$\frac{d}{dx}\bigg(e^{-x^2}\frac{dy}{dx}\bigg)+4e^{-x^2}y=0. \qquad(2)$$ This implies that the polynomial solution and $\lambda=4$ are the eigenfunction and eigenvalue of the corresponding eigenvalue problem, $$\hat{L}[y]=4\omega(x)y. \qquad(3)$$ My question is about the implication, I do not understand how from equation $(2)$ we can imply that equation $(2)$ is actually the eigenfunction of equation $(3)$. I would appreciate any help or suggestion. Thank you.","['sturm-liouville', 'ordinary-differential-equations']"
1583397,summation of determinants of $3\times3$ matrices,"I have an algebra problem but no idea how to solve it. The problem is: ""you can create 9! matrices the elements of which lie in a set $ \{1,2,3,...,9\} \subset \mathbb N$ so that their elements do not repeat, i.e. e.g.
$$
\begin{pmatrix}1&2&9\\3&5&7\\6&4&8 \end{pmatrix}
$$
Find the sum of the determinants of all these matrices.""
Could you give me a hint how to solve it? Thank you.","['matrices', 'algebra-precalculus']"
1583425,"Finding an ""inverse function"" symmetrical to y=2x not y=x","Hello I'm very inexperienced in math (I know a little about derivation/integrals etc but nothing on university level) so my terminology will not be on point (as well due to english not being my native language). I have a function $$
y=\sqrt2*\sqrt x  
$$ graph 1 and 2 and I want to find the symmetrical function by the function $y=2x$
like this: [in previous file on the right] as far as I know the inverse function is always symmetrical by the function $y=x$. so I dont know how to call this. Expected result: graph 3 and 4 I'm doing this because I wanna to ""connect"" these function so I can ""draw"" this [in previous file on the right] I can only post 2 links so I have combined graph 1 and 2 into one image and 3 and 4 into another one. Thank you in advance for responding! <3","['functions', 'inverse']"
1583434,Christoffel symbols for the PoincarÃ© ball model,The metric tensor $g_{ij}$ of the PoincarÃ© ball model is $$ g_{ij} = \frac{\delta_{ij}}{(1 - x_k x^k)^2} $$ where $\delta_{ij}$ is the Kronecker delta and $x^k$ are the ambient Cartesian coordinates. Hence the partial derivative of the metric tensor with respect to a coordinate $x^l$ is $$ \partial_l g_{ij} = \partial_l \frac{\delta_{ij}}{(1 - x_k x^k)^2} = \delta_{ij} \partial_l (1 - x_k x^k)^{-2} = -2 \delta_{ij} (1 - x_k x^k)^{-3} \partial_l (1 - x_k x^k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \partial_l x^k + x^k \partial_l x_k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) $$ In summary $$ \partial_l g_{ij} = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) = 4 \delta_{ij} (1 - x_k x^k)^{-3} x_l $$ The Christoffel symbols are defined in terms of the partial derivatives of the metric tensor as $$ \Gamma^i_{jk} = \frac{1}{2} g^{il} (\partial_j g_{lk} + \partial_k g_{lj} - \partial_l g_{jk}) $$ Hence we substitute our expression for $ \partial_l g_{ij} $ with the right indices. Is this correct? I have not been able to find an online source to verify that these are the correct Christoffel symbols for the PoincarÃ© ball model.,"['connections', 'riemannian-geometry', 'tensors', 'hyperbolic-geometry', 'differential-geometry']"
1583470,Expected value of probability of intersection.,"let's assume we choose at random two subsets $A$ and $B$ of a finite set $X$ (i.e. $|X|=n$). By randomness I mean that $Pr[x\in A] = \frac1{n}$ for each $x\in X$, the same for $B$. What will be the average size of their intersection? More formally, I would like to compute: $$E[|A \cap B|\ |\ |A|, |B|]$$ I tried to write it as a sum of expected values with additional condition about the size of $A\cap B$, but it leads me to a result which is not necessarily less than $1$, so either I've made a mistake or my whole reasoning has been wrong. Is there any tricky computation of this expression?","['conditional-expectation', 'probability']"
1583474,Can a class test scores with a bimodal distribution provide statistical evidence for cheating?,"I know the normal distribution can represent many things in nature. Most items are normally distributed . I recently watched a video of a professor who claims that biomodal distributions provide evidence of cheating . He states that biomodal distribution "" when external forces are applied to a data set that creates a systematic bias to a data set "" aka cheating. He compares this information to previous grade distributions of students given the same test in other years when he gave the test and estimated that 1/3 of his students have cheated . My question is does a bimodal distribution really provide statistical evidence of cheating? Can't it be that some students do very poorly and some students do really well, leaving a peak that is low and a peak that is high? Do biomodal distribution really mean there is a higher probability of ""when external forces are applied to a data set that creates a systematic bias to a data set?"" The link to the video is: https://www.youtube.com/watch?v=rbzJTTDO9f4 Yes, I get some students admitted to cheating, but that doesn't answer my question. My question is can a teacher really provide statistical evidence of someone cheating without them admitting it? I know statistics is all about probability, so can a teacher claim that the probability of this is really lower than a certain threshold and say because of this there exist a statistical significance of them cheating? And how can they approximate 1/3 of there students cheated just by comparing the bimodal distribution to a normal distribution. To me, it seems that the teacher is just trying to use scare tactics with his ""statistics"" and guilt students into admitting to cheating rather than have any evidence of them cheating. PS: I know cheating is wrong, but I know there must be a lot of innocent students in his class that were also accused of cheating, so that is why I asked this question. (I don't actually go to that university)","['statistics', 'statistical-inference', 'normal-distribution', 'probability-distributions']"
1583483,What does $E(X)$ minimises $E(X-A)^2$ mean?,"Theorem: The mean,  $E(X)$,  minimises $E(X-A)^2$ with respect to $A$. I have no idea what this Theorem is trying to tell me. What does ""minimises"" mean in this context? Thank you","['probability-theory', 'statistics']"
1583504,Absolute convergence in Banach space,"Let $X$ be a Banach space. Show that, if $\sum_{n\ge 1}x_{n}$ is absolutely convergent then $\sum_{n\ge 1}x_{n}$ is convergent and 
$$\left\|\sum_{n\ge 1}x_{n}\right\|\le \sum_{n\ge 1}\|x_{n}\|$$ I have tried this :
Let $\sum_{n\ge1}x_{n}$ be absolutely convergent, this is $\sum_{n\ge1}
	  \|x_{n}\|$ converges. So put $s_{n}=\sum_{k=1}^{n}x_{n}$ and 
      $p_{n}=\sum_{k=1}^{n}\|x_{n}\|$. We want to proof that $s_{n}$ is a 
      Cauchy sequence, and as $X$ is a Banach space it will follow  that 
      $s_{n}$ is convergent. But this is straight forward, because as $p_{n}$ is convergent we know that 
      $$\sum_{n\ge k}\|x_{n}\|\rightarrow 0\mbox{ when } k\rightarrow\infty, $$
      or more precisely given any $\varepsilon>0$ there exists an $N\in\mathbb{N}$ 
      such that 
      $$\sum_{n\ge k}\|x_{n}\|<\varepsilon,~\forall n\ge N$$ and so
      $$\|s_{n}-s_{m}\|=\left\|\sum_{k=\min\{m,n\}}^{\max\{m,n\}}x_{k}\right\|
	  \le \sum_{k\ge\min\{m,n\}}\|x_{k}\|<\varepsilon, \forall ~m,n\ge N.$$
      This proves that $s_{n}$ is convergent because any Banach space is complete. As for any integer $k$ 
      $$\left\| \sum_{n=1}^{k}x_{n}\right\|\le \sum_{n=1}^{k}\|x_{n}\|$$
      and the norm $\|\cdot\|$ is continuous, as $k\rightarrow\infty$ we get 
      $$\left\|\sum_{n\ge 1}x_{n}\right\|\le \sum_{n\ge 1}\|x_{n}\|.$$
Can anyone say if my solution is correct?","['functional-analysis', 'convergence-divergence', 'proof-verification']"
1583514,What kind of object is the push forward of a vector field?,"I was actually not sure about asking this question since I think I know what the answer is, but here it goes: Let $M$ and $N$ be two smooth manifolds and $\mathbf{X}$ a vector field defined on $M$. As a function, $\mathbf{X}$ is defined on $M$ and at $p \in M$ it can take values on $T_p M$; in fancier terms, it is a cross section of the tangent bundle of $M$. Now let $\phi: M \to N$ be a smooth function (not necessarily a diffeomorphism) and $\phi_*$ its differential. What kind of object is $\phi_* \mathbf{X}$? Here are my thoughts: it's not really a vector field on $M$ or on $N$; rather, it's defined on $M$, but at $p \in M$ it takes values in $T_{\phi(p)} N$. Therefore, it's a cross section of a vector bundle with base space $M$ and tangent spaces on $N$ as fibres. At each point $p$ of $M$ we would place the tangent space $T_{\phi(p)}N$. Is this correct? I have a feeling my definition of the vector bundle is not very rigorous; how can it be made more precise? Is there a neater way to define this vector bundle?","['vector-bundles', 'differential-geometry', 'differential-topology']"
1583533,"Minimal c satisfying $x+y-(xy)^c \geq 0$ for all $x,y\in [0,1]$","What is the minimal real $c$ satisfying $x+y-(xy)^c \geq 0$ for all $x,y \in [0,1]$? Experimentally (though my experiments weren't necessarily accurate enough) I reached as low as $c=\tfrac{13}{32}$, where $c=\tfrac{12}{32}$ violates it.","['multivariable-calculus', 'calculus']"
1583536,Find $\lim\limits_{x\to 0}\frac{e^{x^2}-\cos x^{\sqrt{2}}}{x^2}$,"Find $\lim\limits_{x\to 0}\frac{e^{x^2}-\cos x^{\sqrt{2}}}{x^2}$ Using Taylor series:
$$\lim\limits_{x\to 0}\frac{e^{x^2}-\cos x^{\sqrt{2}}}{x^2}=\lim\limits_{x\to 0}\frac{(1+x^2+O(x^{2n}))-(1-\frac{x^{2\sqrt{2}}}{2}+O(x^{\sqrt{2}(2n+1)})}{x^2}=\lim\limits_{x\to 0}\frac{\frac{2x^2+x^{2\sqrt{2}}}{2}}{x^2}=\lim\limits_{x\to 0}\frac{2x^2+x^{2\sqrt{2}}}{2x^2}$$ How to evaluate this limit?","['convergence-divergence', 'calculus', 'limits']"
1583540,One-sided inverse of a function,Is it possible to find an example of an one-sided inverse of a function?  other than matrix? I am trying to find such an example but having no luck. Anybody got an idea about it?,"['elementary-set-theory', 'real-analysis', 'functions']"
1583565,Stick passing through glass leaves a possibly parabolic hole,"I am trying to understand what happens in this gif video: Source: http://9gag.com/gag/aAVp4V9/is-this-even-possible It is quite interesting because at a first look, it was very counter-intuitive. Assuming that the yellow glass is the $xy-$plane, at first I thought that this is the projection map: $\mathbb R^3 \to \mathbb R^2$. However, the projection of a line in $\mathbb R^3$ onto a plane must still be a line, but not a paralobic (or maybe hyperbolic or trigonometric) curve. So, this ""thing"" is not a projection, but something else. What can be a function describing this situation? And what is the type (parabola, hyperbola, sine, circle etc.) of the curve on the glass?","['euclidean-geometry', 'geometry']"
1583568,Counterexample for the stronger statement of Riesz's lemma,"Here is a counterexample for the stronger statement of Riesz's lemma and I don't understand it. Why for all $x$ , such that $||x||=1$ , there exists $y \in Y$ , such that $d(x,y)<1$ ?","['functional-analysis', 'normed-spaces', 'vector-spaces']"
1583577,Why isn't $\frac{0^{0!}}{0!^0}$ not undefined?,"I got into a big argument with my teacher about this. I am saying that it is undefined because every time I work it out, I end up getting $\frac{0}{0}$ which I know to be undefined.",['algebra-precalculus']
1583582,Find $\lim\limits_{x\to \infty}\frac{\ln(1+4^x)}{\ln(1+3^x)}$,"Find $\lim\limits_{x\to \infty}\frac{\ln(1+4^x)}{\ln(1+3^x)}$ Using Taylor series:
$$\ln(1+4^x)=\frac{2\cdot 4^x-4^{2x}}{2}+O(4^{2x}),\ln(1+3^x)=\frac{2\cdot 3^x-3^{2x}}{2}+O(3^{2x})\Rightarrow$$ $$\lim\limits_{x\to \infty}\frac{\ln(1+4^x)}{\ln(1+3^x)}=\lim\limits_{x\to \infty}\frac{2\cdot 4^x-4^{2x}}{2\cdot 3^x-3^{2x}}=\infty$$ The limit should be $0$. Could someone point out what is wrong?","['calculus', 'limits']"
1583588,Roots of the Chebyshev polynomials of the second kind.,"It is known that the roots of the Chebyshev polynomials of the second kind , denote it by $U_n(x)$, are in the interval $(-1,1)$ and they are simple (of multiplicity one). I have noticed that the roots of $U_n{(x)}+U_{n-1}(x)$ (by looking at the law ranks of $n$) also lies in $(-1,1)$, I also noticed that  for $(1-x)U_n{(x)}+U_{n-1}(x)$ the roots lie in  $(-2,2)$. But I don't have any idea how to prove that in general, I wonder, first, if these claims are true? and how can I start proving them?","['roots', 'chebyshev-polynomials', 'analysis', 'orthogonal-polynomials']"
1583589,Is this set in $\Bbb{C}^3$ compact?,"Is $\{(x,y,z) \in \Bbb{C^3} | z_1^2+z_2^2+z_3^2=1\}$ in the Euclidean topology compact? We know in $\Bbb{R}^n$ compact iff closed and bounded , but is it true for complex also?","['complex-analysis', 'general-topology']"
1583609,The four runner problem/conjecture,"I've recently read here the following problem, called Â« four-runner problem Â» : Suppose four runners (represented by labeled spheres) run around a circular track. Their speeds are constant positive rationals $v_1<v_2<v_3<v_4$. At time $0$, all the runners are together at the starting gate; shortly after, they are arranged in the order $\{1, 2, 3, 4\}$, counting from the starting gate. The order changes to $\{4, 1, 2, 3\}$ when runner 4 passes the starting gate. Then either runner 3 passes the starting gate, runner 4 laps runner 1, or the two events happen at the same time, giving possible orders $\{3, 4, 1, 2\}$, $\{1, 4, 2, 3\}$, or $\{3, 1, 2, 4\}$.
  [â€¦] The answer to this question is unknown: which rates generate all 24 possible orders? For three runners, all six orders are achieved if and only if the two slower rates do not add up to the fast rate. For instance, I found that the rates $0.1 < 0.2 < 0.61 < 0.9$ generate the 24 possible combinations. I would like to know where to find more information on that problem. Are there some research articles about it? I didn't find anything, even for the case with 3 runners (which does not seem obvious to me). Thank you in advance!","['number-theory', 'reference-request', 'conjectures', 'open-problem']"
1583633,Using the Central Limit Theorem to work out the approximate distribution of $\frac{1}{n}\sum_{i=1}^nX_i^2$,"Suppose $X_1,X_2,\ldots,X_n$ are I.I.D $N(0,1)$. Then, what is the approximate distribution of $\frac{1}{n}\sum_{i=1}^n X_i^2\,$? I have the solution but none of it is making any sense to me. Thank you for your help!",['statistics']
1583663,Convergence to normal distribution,"Consider the probability distribution of the simple symmetric walk.  That is the random variable $X_i$ equals $c$ or $-c$ with equal probability and all $X_i$ are independent and $c\geq1$.  We are interested in $$S_n = X_1 + X_2 + \dots + X_n.$$ We know from the central limit theorem that $S_n/\sqrt{n}$ converges in distribution to the normal distribution $N(0,c^2)$. We also know that the entropy of the normal distribution $N(0,c^2)$ is $\frac{1}{2}\ln(2\pi e c^2)$. It is clear we can't tell derive the entropy of $S_n$ as $n \rightarrow \infty$ directly from this formula for the normal distribution. This is because the entropy of $S_n$ is invariant to $c$ but the entropy of the normal distribution is not. The differential entropy wikipedia page gives a correction term but I can't understand how to apply it. How exactly do you apply the correction term to $\frac{1}{2}\ln(2\pi e
 \sigma^2)$ in this example to get the correct entropy for $S_n$ as $n
 \to \infty$?","['information-theory', 'entropy', 'probability']"
1583715,Einstein Summation with Del Operator,Can someone show explicitly me why $2B_k\nabla B_k = \nabla B^2$ ? Is $B_k\nabla B_k$ just $B_x\nabla B_x+B_y\nabla B_y+B_z\nabla B_z$? But then I end up with nine terms on the LHS and I can't match it with the RHS.,"['multivariable-calculus', 'summation', 'vectors', 'vector-analysis']"
1583718,Domain of convergence of $f_n(x)= { {nx^{n-1}} \over {1+x^{2n}} }$,"What is the domain of convergence of the real functions sequence: $$f_n(x)=
 { {nx^{n-1}} \over {1+x^{2n}} }$$ I thought about looking at the numerator and denominator and take the intersection of their convergence domain, so I got $\{x<-1 \ or \ -1<x<1 \ or \ x>1\}$. But how do I justify such thing? Or prove it in better way?","['convergence-divergence', 'sequences-and-series', 'functions']"
1583727,$\sum\frac {a_n}{(1+a_1).... (1+a_n)}=1$ iff $\sum a_n $ diverges,"Show if $a_n $ are positive, then
$\sum\frac {a_n}{(1+a_1).... (1+a_n)}=1$ iff  $\sum a_n $ diverges.
I got right to lest side, by bounding by n from below so I got the later series divegres, but could not get the other side. I would love to see an idea please.","['real-analysis', 'sequences-and-series', 'calculus']"
1583733,Proof containing pairwise disjoint sets,"I came across the following question while studying. Let $A,B,C,D$ be pairwise disjoint sets. Prove that if $|A| = |B|$ and $|C| = |D|$ then $|A \cup C| = |B \cup D|$. I thought of the fact that they intersections are obviously empty but this doesn't help with the progression to a solution. I also tried to find any properties of the pairwise disjoint union that might help but I am stuck. Can anyone offer some suggestions/solutions?","['proof-writing', 'elementary-set-theory', 'discrete-mathematics']"
1583743,Finding and classifying all groups of order 12,"I was working on classifying all the groups of order 12. I dug around at some of the previous questions here and while they address the idea, none of them were entirely satisfactory: Classifying groups of order 12. (doesn't explain how classification is derived) Group of order 12 (doesn't address how to generate classification) Nonisomorphic groups of order 12. (shows they aren't isomorphic, but doesn't actually show the derivation for the 4 groups listed) So I wanted to ask, the specific question not yet presented, of how to derive that there must be 5 non isomorphic groups of order 12, and which groups those are. Work So Far: To begin with we have $|G|=12= 2^2 \times 3$ for any group of order 12. Let $n_3$ be the number of sylow-3 subgroups and let $n_2$ be the number of sylow 2 subgroups. We have by the third sylow theorem that $$n_3 | 4, n_3 \equiv 1 \mod 3$$
$$n_2 | 3, n_2 \equiv 1 \mod 2$$ So the groups can have either 1 or 4 sylow 3 subgroups of order 3, and either 1 or 3 sylow 2 subgroups of order 4. Furthermore coprime sylow-p groups only share the identity element in common, so we can rule out 4 sylow-3 groups and 3 sylow-2 groups, as the presence of either rules out the existence of a single copy of the other. Now we have established our groups must have a SINGLE sylow 2 subgroup, and a SINGLE sylow 3 subgroup, and that means that each is a normal subgroup of the entire group. The sylow-2 subgroup can be either $\Bbb{Z}_2 \times \Bbb{Z}_2$ or $\Bbb{Z}_4$. And the sylow-3 subgroup has a single contender $\Bbb{Z}_3$. Naturally then we can list out two groups $$\Bbb{Z}_2 \times \Bbb{Z}_2 \times \Bbb{Z}_3$$
$$\Bbb{Z}_4 \times \Bbb{Z}_3$$ But now the question remains, how to discover any remaining groups, and show that the remaining set covers all possible groups.a","['finite-groups', 'abstract-algebra', 'group-theory', 'sylow-theory']"
1583744,Absolutely continuous function on R,"What is the definition of absolute continuity in whole  $\mathbb{R}$.
I know the definition on an interval $[a, b]$. I have a trouble with understanding the definition of absolute continuity in whole $\mathbb{R}$.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'analysis', 'definition']"
1583768,"Need help with $\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx$","Please help me to evaluate this integral
$$\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx$$
I tried a change of variable $x=\tanh z$, that transforms it into the form
$$\int_0^\infty\frac{4z}{\left(1+\log^2\tanh z\right)\sinh2z}\,dz,$$
but I do not know what to do next.","['hyperbolic-functions', 'integration', 'definite-integrals', 'calculus']"
1583774,Analytic function with vanishing derivatives.,"A function that is analytic in the whole plane and which vanishes along with all its derivatives at any one point in the plane is identical to $0$. Now consider a function $f(z)$, which is supposedly analytic everywhere such that $$\lim_{z\rightarrow\infty}f^{(n)}(z)=0$$ for $n=0, 1, 2...$ Is the conclusion that $f(z)$ is identical to $0$ the only possibility?",['complex-analysis']
1583779,Find a matrix $A$ such that $\operatorname{proj}_W(x) = Ax$ for every $x \in \Bbb R^3$,"Let $W = \operatorname{Span}\{(1, -1, 0), (1, 1, 0)\}$. Find a matrix $A$ such that $\operatorname{proj}_W(x) = Ax$ for every $x \in \Bbb R^3$. I'm not sure how to solve this. What I tried doing is using y = $A(A^TA)^{-1}$ $A^T$ $\vec x$
where A was the matrix \begin{bmatrix}1&1\\-1&1\\0&0\end{bmatrix} Then, solving, I got  \begin{bmatrix}0&1&0\\0&1&0\\0&0&0\end{bmatrix} Is this the way to go about this question or am I completely off? I don't fully understand it.","['matrices', 'linear-algebra']"
1583806,"Conjecture $\int_0^1\ln\ln\left(\frac{1+x}{1-x}\right)\frac{\ln x}{1-x^2}\,dx\stackrel?=\frac{\pi^2}{24}\,\ln\left(\frac{A^{36}}{16\,\pi^3}\right)$","I did some numeric experiments with integrals involving double logarithms (because they received much interest both on this site and in published papers, sometimes under names of Malmstenâ€”Vardiâ€”Adamchik integrals). It appears that
$${\large\int}_0^1\ln\ln\left(\frac{1+x}{1-x}\right)\cdot\frac{\ln x}{1-x^2}\,dx\stackrel{\color{gray}?}=\frac{\pi^2}{24}\,\ln\left(\frac{A^{36}}{16\,\pi^3}\right),$$
where $A=\exp\left(\frac1{12}-\zeta'(-1)\right)$ is the Glaisherâ€”Kinkelin constant (I have more than $1000$ decimal digits confirming this conjecture). How can we prove it?","['logarithms', 'integration', 'riemann-zeta', 'definite-integrals', 'experimental-mathematics']"
1583821,Examine the convergence of $\sum_{n=1}^{\infty} \frac{\cos {\frac{n \pi}3}}n$,"Is that series convergent? How to prove is it or not? I got no idea how to check convergence of series with trygonometrical functions:
$$\sum_{n=1}^{\infty} \frac{\cos {\frac{n \pi}{3}}}{n}$$","['convergence-divergence', 'sequences-and-series', 'calculus', 'analysis']"
1583822,"Let $A(t), (a_{ij}): \Bbb R\to \Bbb R$ be a periodic matrix with period $1$. Prove a solution to $x'=Ax$ is bounded.","Question Let $A(t), (a_{ij}): \Bbb R\to \Bbb R$ be a periodic $n\times n$ matrix with period $1$. Prove that if $x(t)$ is a solution to $$x'(t)=A(t)x(t)\tag 1$$ defined on $\Bbb R$, witch satisfies $x(1)=-x(0)$, then $x$ is bounded. Attempt I had no idea on how to face this so I just tried the first thing that came to mind. I thought evaluating the equation at $t\mapsto t+1$, we see that $x_1(t)=x(t+1)$ is a solution to $(1)$, and $x_1(0)=x(1)$. Suppose that $x(t+n)$ is a solution to $(1)$, thus
$$
x(t+n)=A(t)x(t+n)
$$ By induction, setting $t\mapsto t+1$, we get that $x_n(t)=x(t+n)$ is a solution to $(1)$ for all $n$, and that $x_n(0)=x(n)$. I got stuck there, and I don't think I'll get anywhere this way... Could someone give me some hints?",['ordinary-differential-equations']
1583826,Sequence of analytic function with range in $\mathbb{H}$ converges locally uniformly,Let $G$ be a region and let $h_n :G\rightarrow \mathbb{C}$ be analyic maps such that $h_n (G) \subset \{\Im z >0\}$. Assume there is a $z_0 \in G$ such that $h_n (z_0) \rightarrow 0$. Prove that $h_n$ converges uniformly in compact subsets of $G$ to $0$. Any hint here is appreciated. I am not exactly sure how to use what we know about $z_0$. My guess is that the limit being $0$ and $0$ being on $\partial \mathbb{H}$ are related. Is this possibly a Schwarz reflection problem?,['complex-analysis']
1583832,Contour integral.,"Consider the function $y(x)$ defined by $$y(x)=e^{x^2}\int_{C_1'}\frac{e^{-u^2}}{(u-x)^{n+1}}du$$where $C_1'$ is as shown The Author makes following claims regarding the behavior of $y(x)$ in the limit of large $x$ (It is assumed that $n>-\frac{1}{2}$, but not integral). 1) As $x\rightarrow+\infty$, the whole path of integration $C_1'$ moves to infinity, and the integral in the above expression tends to zero as $e^{-x^2}$. 2) As $x\rightarrow-\infty$, however, the path of integration extends along the whole of real axis, and the integral in the expression does not tend $\boldsymbol{exponentially}$  to zero, so the function $y(x)$ becomes infinite essentially as $e^{x^2}$. In regard to the second claim, I can see that the integrals on the parts of the contour above and below the real axis will not cancel since $n+1$ is not integral. I understand these estimates are correct but have not been able to exactly see how. Any indication in the right direction would be very useful. Thanks.",['complex-analysis']
1583841,Are two dot products of a random variable vector independent?,"Let $w,v$ be two different vectors in the finite vector space $Z_p^m$ over $Z_p$ where $p$ is prime. Let $u$ be a vector chosen uniformly at random from $Z_p^m$. Are the random variables $u \cdot w$ and $u \cdot v$ independent (the dot product calculated over $Z_p$)? If not, can we estimate their covariance somehow? Thank you for your help.","['finite-fields', 'independence', 'probability-theory', 'linear-algebra', 'vectors']"
1583855,"Can the complex square root of $z\sin z$ be defined in a neighborhood of the origin? (I.e., including the origin)","Edit: on a second thought, I don't think it's possible since $$ f(z) = \sqrt {z\sin z} = e^{\large \frac{1}{2} \log z}e^{\large \frac{1}{2} \log\sin z}$$ $$e^{\large \frac{1}{2} (\ln|z| + iArg(z))}e^{\large \frac{1}{2} (\ln|\sin(z)| +iArg(sin(z))}$$ is undefined at the origin -- we'd get a $ln|sin(0)| = ln|0|$ factor.  What do you think?  Thanks, The problem statement is: Consider the function $ f(z) = \sqrt {z\sin z}$ . Can $f(z)$ be defined near the origin as a single valued analytic function? What will be the radius of convergence of the power series expansion of $f$ around $z=0$? My thoughts: It is tempting to say ""no"", since $z=0$ seems like a branch point of $f(z)$. But a closer look at the function $$ f(z) = \sqrt {z\sin z} = e^{\large \frac{1}{2} \log z}e^{\large \frac{1}{2} \log\sin z}$$ shows that we need to pick two branch cuts.  And if we choose both cuts to  be $\mathbb R^- \cup \{0\}$, i.e., choose the principal branch of the logarithm for both factors, then each factor is discontinuous and not defined on the negative real axis (plus the origin), and each jumps by a factor of $e^{\frac{1}{2} 2 \pi i} = e^{i\pi} = -1$. However, considering both factors together, we get a total ""jump"" of $e^{2\pi i} =1$, and I think that now $f(z)$ has been made single-valued and analytic on the negative real axis, including the origin, and thus we get an analytic continuation onto the negative axis and the origin, so that $f(z)$ can in fact be defined near the origin as a single-valued analytic function. What do you think? This seems a bit too generous, though.  I feel like I have claimed that this function is entire , which I am almost certain cannot be true...because of the complex logarithm used to define $f(z)$. Any ideas are welcome. Thanks,","['logarithms', 'complex-analysis', 'analyticity']"
1583878,Calculate SE from a Given Margin of Error,"I have data from the Census bureau that has means and margins of error that are defined at 90% confidence.  For example, a zip-code population estimate of 17042 with a 90% moe of 278.  I'd like to do some inference based off of this data, but I need to reverse engineer to get the standard error of the estimate.  Given the mean and this margin of error, how can I come up with a standard error?",['statistics']
1583883,How Do I Compute the Eigenvalues of a Small Matrix?,"If I have a $2\times 2$ or $3\times 3$ matrix, how should I go about computing the eigenvalues and eigenvectors of the matrix? NB: I am making this question to provide a unified answer to questions about eigenvalues of small matrices so that all of the specific examples that come up can be marked as duplicates of this post. See here .","['matrices', 'eigenvalues-eigenvectors', 'faq', 'linear-algebra']"
1583890,Changing order of sum,"We know that 
$$\sum_{n=1}^{\infty}a_n = \mbox{convergent}$$
Does that imply that 
$$a_3 + a_1 + a_2 + a_6 + a_4 + a_5 + \cdots = \mbox{convergent?}$$
We don't know whether our series is absolutely convergent.","['real-analysis', 'sequences-and-series', 'analysis']"
1583891,Tangent identity given $a + b + c = \pi$,"Given that $a + b + c = \pi$, that is, three angles in a triangle - then prove that $$\tan a + \tan b + \tan c = \tan a \tan b \tan c$$ Is my solution below completely rigorous? Can I justify taking the tangent of both sides of my equation (I think not, since tangent isn't an injective function).","['trigonometry', 'alternative-proof']"
1583917,Examples of Second Isomorphism Theorem for Groups,"I was wondering if there were any standard insightful applications of the second isomorphism for groups: THM: Let $ G $ be a group with $ H, N $ as subgroups and $ N $ normal in $G$. Then $ H \cap N $ is normal in $ H $ and $ \frac{HN}{N} \cong \frac{H}{H\cap N} $. I have read through some helpful posts on the intuition of the theorem and feel that I grasp it now, but am still having trouble concocting a clear example. Any solid examples would be appreciated.","['abstract-algebra', 'group-theory', 'group-isomorphism']"
1583954,Random Variable: Ordered List of ints.,"You are given an ordered list of integers : 1, 2, ...100. You then randomly permute (reorder) the integers. a.) Define a random variable that indicates whether or not a pair of integers in the list is permuted. 
    What distribution should the random variable have if this reordering is to be completely random? b.) How many such random variables should you define for this list? c.) What is the expected # of permutations of 2 particular integers in the list? d.) Define the random variable that describes the total number of permutations in this list. 
    What is the probability mass function if you assume that each individual permutation is independent of each other? e.) What is the expected number of permutations in this list. Justify your answer. f.) What is the standard deviation of the number of permutations in the list? g.) You observe 1000 pairs. Is that a very likely outcome? Justify your answer. I'm confused about the phrasing of this question. Specifically for part a, when it says ""whether or not a pair of integers in the list is permuted"", does it just mean if either a or b is not in the correct spot? Also just general guidance to solving this would be great.","['probability', 'random-variables', 'discrete-mathematics']"
1583985,Is Kaplansky's theorem for hereditary rings a characterization?,"This question came up during a first course on rings and modules I TA'd at. Kaplansky's Theorem for hereditary rings states that If $A$ is a hereditary ring, and $F$ is a free left $A$-module, then every submodule $M \subset F$ is isomorphic to a direct sum $\bigoplus_{i \in I} J_i$, where every $J_i$ is a left ideal of $A$. See for example Lam's Lectures on modules and rings , (2.24). Recently a student asked me for an example of a submodule of a free module that was not a direct sum of ideals, and the best I could come up with was the following: Let $A = \mathbb Z_4[X]/(X^2)$, and let $M = \langle (2,X) \rangle \subset A^2$; then $M$ is not isomorphic to a direct sum of ideals. My proof is long and tedious, and besides $A$ is very very far from being hereditary, since it has infinite global dimension. Hence the question: Can we find a simpler example of a submodule of a free module that is not isomorphic to a direct sum of ideals (say, over $\mathbb Z[X]$)? In fact, I was wondering if there are examples for all non-hereditary rings. is the converse of Kaplansky's theorem true? if a ring $A$ is such that all submodules of a free module are isomorphic to a direct sum of ideals, does it follow that $A$ is hereditary?","['abstract-algebra', 'ring-theory']"
1583989,"$g(x)=\arctan|x|-\text{arccot}|x|$,$f(x)=\frac{[x]}{[x+1]}\left\{x\right\}$,$h(x)=|g(f(x))|$,find domain of $h(x)$","Let $g(x)=\arctan|x|-\text{arccot}|x|$,$f(x)=\frac{[x]}{[x+1]}\left\{x\right\}$,$h(x)=|g(f(x))|$ where $\left\{x\right\}$ and $[x]$ denotes fractional part and integer part of $x$ respectively,then find the domain of $h(x).$ I found the domain of $g(x)$ is $R$(the set of all real numbers). I found the domain of $f(x)$ is $R-[-1,0)$(the set of all real numbers except the interval $[-1,0)$ Now i am stuck here,and cannot solve further. Please help me.Thanks.","['real-analysis', 'functions']"
1584000,A linear but intractable PDE,"I have a PDE of the following form, from a physics problem:
$$
y \left(\alpha \frac{\partial }{\partial y}+x \frac{\partial^2 }{\partial x \partial y} \right)f(x,y) = \left( z_1 + z_2 x^\alpha y^{-2} \right) f(x,y)
$$ Function $f(x,y)$ is a real-space real-valued function and 
$z_{1,2},\alpha$ are real numbers, generally irrational.   The latter, specifically the $z_2$ coefficient term, seems to make all of the textbook methods (characteristics, Froebnius, Fourier transform) fail.   Does any one know weather a method exists to solve this?  Apologies if this is a simple question but, well, I am a theoretical physicist and it is not simple for me.",['ordinary-differential-equations']
1584037,A use of Implicit Function Theorem,"Honestly, I don't understand the question well. As a try, I defined a function $G:\mathbb{R}^{2+1}\rightarrow \mathbb{R}^2$ where $G(x,y,z)=(f_1(x,y,z),f_2(x,y,z))$ so that $f_1(x,y,z)=x-y$ and $f_2(x,y,z)=y-z$. Then, to satisfy the condition of Implicit function theorem, we need $G(a,b,c)=(0,0)$ for some $(a,b,c)\in \mathbb{R}^2$. That happens when $a=b=c$. So, I think I am done for the first part but not sure. Am I correct? Secondly, how may I derive those explicit formulas? Any help is appreciated.","['multivariable-calculus', 'real-analysis', 'implicit-function-theorem']"
1584043,How to describe a statistical dataset more precisely?,"I am a newbie in stat and I need to be able to do this for a GIS application: Say I have the following dataset of only two possible values $0$ and $1$: $0,0,0,1,1,1,0,1$ The mean would equal $\frac{4}{8}=0.5$ Thus to find out how many $1$'s were in the intial dataset, we would simply multiply the mean by the total number of values and get $4$. Now consider a dataset with $\it three$ distinct values, $0,0.5$ and $1$ $0,0.5,0.5,1,1,1,0,0$ The mean would again equal $\frac{4}{8}=0.5$. In this case, would there be a way of determining how many values of $0.5$ and how many values of $1$ were in the dataset? Perhaps using the standard deviation, sum, median, or range?","['statistics', 'probability', 'data-analysis']"
1584064,Example of finite measure and infinite measure,"Give an example of infinite measure $\nu$ and finite measure $\mu$ on reals such that $\nu â‰ª \mu$, and for each $Î´ > 0$ there is an interval $I âŠ‚ R$
satisfying $\mu(I) < \delta$ and $\nu(I) â‰¥ 1$ My attempt: $d\mu = f dx, d\nu = g dx$ with different positive $f, g$. This was given as a hint but I do not know how to proceed with this. I know such an example is impossible if $\nu$ is finite from Theorem 3.5 in Folland's real analysis.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
1584068,What is $\max{(1/\alpha+1/\beta+|1/\gamma|+|1/\delta|)}$?,"Consider a polynomial $(\alpha ,\beta >0)$,$f(x)=x^3/\alpha+x^2/\beta+x/\gamma+1/\delta$. If $|f(x)|\leq 1$ for $|x|\leq 1$ then $\max{(1/\alpha+1/\beta+|1/\gamma|+|1/\delta|)}$ is what? Intuitively it seems that the value should be within the range $1$ to $10$....just plugged in random values.But I'm not able to solve it....","['algebra-precalculus', 'inequality', 'polynomials']"
1584086,Lebesgue measure on a continuous function,"Let $f(x)$ be a continuous function on [âˆ’1, 1]. Show that there exists a constant $c$ such that the Lebesgue measures
$\mu (\{x âˆˆ [âˆ’1, 1] : f(x) â‰¥ c\}) â‰¥ 1$,$\quad$ $\mu (\{x âˆˆ [âˆ’1, 1] : f(x) â‰¤ c\}) â‰¥ 1$. I can do the trivial case choosing $c$ to be the supremum and infimum of $f$ over the interval. But I think this is not a kosher proof.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
1584089,Functional equation $f(x + y) = f(x)^m + f(y)^{m + 1}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $m \in \mathbb{N}$. How i can find all functions $f$ such that $f(x + y) = f(x)^m + f(y)^{m + 1} \forall x,y \in R$? Thank you in advance.","['functions', 'functional-equations']"
1584098,Generalization of integrating factor?,"For example, if we have $y'+p(x)y=q(x)$, we can obtain $\mu(x)=e^{\int p(x)dx}$ as integrating factor. My question is: exist a generalization of this? ie, if I have $y^{(n)}+p_{n-1}(x)y^{(n-1)}+...+p_0(x)y=q(x)$, exist a ""integrating factor"" for this?",['ordinary-differential-equations']
1584115,Bundle notation used in defining Cartan connection,"I have been trying to understand Cartan connections based on the Wikipedia article , and I am confused about the following paragraph (here $P$ is a principal $H$-bundle with $H$ a Lie group): The pair $(\omega, \theta)$ (a principal connection and a solder form:   $\hspace{2pt}\omega:TP \to \mathfrak h$, $\theta: TP \to R^n$)
  defines a 1-form $\eta$ on $P$, with values in the Lie algebra
  $\mathfrak g$ of the semidirect product $G$ of $H$ with $R^n$, which
  provides an isomorphism of each tangent space $T_p P$ with 
  $\mathfrak g$. It induces a principal connection $\alpha$ on the associated
  principal $G$-bundle $P\times_{H}G$. This is a Cartan connection. (Note: the above is part of the article that serves to motivate Cartan connections; it is not the full, general definition). What does the $H$ subscript in $P\times_{H}G$ in the last line mean? My guess from the context is that $P\times_{H}G$ means to swap out the fibers of $P$ with $G/H$. But if this were correct, then the action of $G$ on the resulting fibers would not be free, and hence $P\times_{H}G$ would not be a principal $G$-bundle, whereas the last line refers to it as such.","['cartan-geometry', 'differential-geometry']"
1584120,Solve the functional equation $f (2x)=f (x)\cos x$,"Find all $f: \mathbb R\longrightarrow \mathbb R $ 
such that $f $ is a continuous  function at $0$ and satisfies 
$$\;\forall \:x \in \mathbb R,\; f\left(2x\right) = f\left(x\right)\cos x $$ My try: I just found the $f (x)$ is periodic,  i.e.
$f (2\pi / 2)= f (\pi/2) \cos (\pi /2) $ And$ f (\pi)=f (3\pi)$ ... and so on,
Best I came up with is
$$f (2^n x) = f (x) \cos (x) \cos (2x) ... \cos (2^{n-1} x)$$","['recursion', 'functions', 'functional-equations']"
1584131,How to construct such a harmonic function on the upper half plane of $\mathbb{C}$ satisfying the following condition?,"(1)Let u be a bounded harmonic function on the upper half plane of $\mathbb{C}$. Show that $\forall y$ we have $u(x+iy)=\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{y\cdot u(t)}{(t-x)^2+y^2}dt$ for $x,y\in \mathbb{R}$. (2)find a harmonic function on the upper half plane with lim$_{(y\to 0^+)}u(x+iy)=0,\ \text{if}\ x<0$ and lim$_{(y\to 0^+)}u(x+iy)=1,\ \text{if}\ x>0$ I have worked out the first part but I have no idea to construct such a function.","['complex-analysis', 'harmonic-functions']"
1584132,Derangements with extra chairs,"This was a question on my combinatorics final. Suppose $m$ people are sitting in a room with $n$ chairs. If everyone leaves and comes back, how many ways can they sit down such that no one gets their original chair? If $m=n$, we simply get the derangement numbers. As another example, if person $A$ is in chair $1$, $B$ is in $2$, and no one is in $3$, then there are $3$ possible arrangements. Obviously $m\le n$ in general. The question seems pretty simple, but I had a hard time getting a simple answer (I ended up with a pretty complicated recursion which I'm pretty sure was either wrong or not the best answer). You are allowed to use derangement numbers, $d_i$, in the answer. Also a hint provided said that the answer would be a sum. I'm looking for some thoughts on this. I guess I should add that the final is over; I'm asking out of curiosity since I probably won't get the exam back, at least for several weeks.",['combinatorics']
1584134,Ways of characterizing sufficient statistics,"I've been reading a little about the Fisher-Neyman factorization theorem on my own, and I think I understand intuitively what a sufficient statistic is, but I am wondering what the convention is for formally defining it. Is it true that, for a given collection of iid samples ($\vec{x}$) from a distribution $X$, the maximum likelihood estimate of the parameter $\theta \in \mathbb{R}^t$ depends exclusively on $T(\vec{x})$ and not on other factors such as the number of elements in the sample? If that is the case, does it make sense to take the following as a definition of sufficiency. (Maximum likelihood estimates given $\vec{x}$ and $\vec{y}$ are equal iff $T(\vec{x}) = T(\vec{y})$). $$
\forall
{
     \vec{x}, \vec{y} \in \text{Seq}[\mathbb{R}]:
} 
     \left( 
          \max_{\theta_x \in \mathbb{R}^t}
                \prod_{x \in \vec{x}} p(x;\theta_x) 
     \right)
=
     \left(
          \max_{\theta_y \in \mathbb{R}^t} 
               \prod_{y \in \vec{y}} p(y;\theta_y)
     \right)
 \Longleftrightarrow
      T(\vec{x}) = T(\vec{y})
$$ So this definition, while closer to right, is also wrong. Based on the comments below, the above definition inappropriately rejects all sufficient statistics except for the maximum likelihood estimate itself. For instance, the sum is a sufficient statistic for the mean in a normal distribution with standard deviation 1: $\mathcal{N}(\mu, 1)$. Amending the formula above gives us:
$$
\forall
{
     \vec{x}, \vec{y} \in \mathbb{R}^n:
} 
     \left( 
          \max_{\theta_x \in \mathbb{R}^t}
                \prod_{x \in \vec{x}} p(x;\theta_x) 
     \right)
=
     \left(
          \max_{\theta_y \in \mathbb{R}^t} 
               \prod_{y \in \vec{y}} p(y;\theta_y)
     \right)
 \Longleftrightarrow
      T(\vec{x}) = T(\vec{y})
$$ with $n$ being the length of the sample.",['statistics']
1584139,"If $\int_0^1 e^{- \frac{nx}{1-x}} f(x) \; dx =0$ for $n \geq 0$, then $f=0$ on $[0,1]$","Suppose that $f$ is continuous on $[0,1]$. If
$$
\int_0^1 e^{- \frac{nx}{1-x}} f(x) \; dx =0
$$
for $n \geq 0$, show that $f(x)=0$ on $[0,1]$. I am unsure what I should be hoping to do to show this. I know $e^{-nx/(1-x)}$ converges pointwise to 0 on $[0,1]$. But this does not help - so I think. In the case where $n=0$, we have $\int_0^1 f(x) \; dx=0$. But this shows $f(x)=0$ only where $f(x)$ is nonnegative or nonpositive. Stone-Weierstrass only seems to complicate the matter. What should I start thinking about to solve this problems?","['real-analysis', 'uniform-convergence']"
1584177,"If $B$ is an abelian group, then is $B{\otimes}_{\mathbb Z}{\mathbb Z}_p$ isomorphic to ${\varprojlim}B/p^{n}B$?",I could get the easy map from $B{\otimes}_{\mathbb Z}{\mathbb Z}_p$ to ${\varprojlim}B/p^{n}B$ but I could not find the map in the opposite direction. Please help me. Thank you!!,"['abstract-algebra', 'group-theory', 'p-adic-number-theory']"
1584181,Derivative of position [duplicate],"This question already has answers here : Are Position and Velocity (or Velocity and Acceleration) Vectors Always Parallel? (3 answers) Closed 8 years ago . [Beginning calculus question.] I saw in a calculus lecture online that for a position vector $\boldsymbol{r}$ $$\left|\frac{d\boldsymbol r}{dt}\right| \neq 
\frac{d\left| \boldsymbol r \right|}{dt}$$ but I don't understand exactly how to parse this. It's my understanding that: $\frac{d\boldsymbol r}{dt}$ refers to the rate of change in the
position over time (speed?) $|\boldsymbol r|$ refers to the magnitude of the position, i.e. the distance (from what to what?) $\frac{d\left| \boldsymbol r \right|}{dt}$ refers to the rate of change in distance traveled over time, (a different kind of speed?) Is there a good way to understand what both of these expressions mean?","['multivariable-calculus', 'vectors']"
1584191,Does an isomorphism of groups that can be written as a direct product induce isomorphisms on the factors?,"An answer to question Isomorphism of Direct Product of Groups says if you have two  (or more) group isomorphisms
$ \phi_1:A_1 \rightarrow X_1 $ and $ \phi_2:A_2 \rightarrow X_2 $ then it follows that $ A_1 \times A_2 \cong X_1 \times X_2 $ under the isomorphism $\phi(a_1,a_2)=(\phi_1(a_1),\phi_2 (a_2) )$ I am interested in whether the converse of this statement is true. If $\phi: A_1 \times A_2 \rightarrow X_1 \times X_2 $ is an isomorphism, is it true that $A_1 \cong  X_1 $ under an isomorphism  $ \phi_1 $ and $ A_2 \cong X_2 $ under an isomorphism $\phi_2$ such that $ \phi(a_1,a_2)= (\phi_1 (a_1), \phi (a_2)) $?","['abstract-algebra', 'group-theory', 'group-isomorphism']"
1584197,Examples of a Banach space with an algebra structure having only left continuity,"There is a theorem (see for example, Rudin's Functional Analysis , theorem 10.2 ) that if $A$ is a Banach space with an algebra structure, such that both left and right multiplication are continuous, then $A$ has a renorming such that $A$ is a Banach algebra. He also provides an example where the lack of completeness causes this to fail. I'm looking to construct an example where $A$ is an algebra, as well as a Banach space, such that only left multiplication is continuous. Any thoughts? Is this possible?","['functional-analysis', 'banach-algebras']"
1584198,"Given a function $f(x)$ defined for all real $x$,and is such that $f(x+h)-f(x)<6h^2$ for all real $h$ and $x.$Show that $f(x)$ is constant","Given a function $f(x)$ defined for all real $x$,and is such that $$f(x+h)-f(x)<6h^2$$ for all real $h$ and $x.$Show that $f(x)$ is constant. To prove $f(x)$ as constant i need to prove that $f'(x)=0.$ $f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}<\lim_{h\to 0} 6h$ $f'(x)<0$ I am not able to prove $f'(x)$ equal to zero.Please help me.Thanks.","['derivatives', 'real-analysis', 'calculus']"
1584202,A conjecture about prime numbers based on $\sigma_1(n)$ and the Highly Abundant Numbers,"I am trying to find the smallest expression $E(n)$ , whose distances between the value of the expression and the next prime closer to the expression, $\mathcal{N}(E(n))$ , and from the expression to the previous closer prime, $\mathcal{P}(E(n))$ , are both prime numbers or $1$ . (1) $\mathcal{N}(E(n))-E(n)\ \in \{1,\Bbb P\}$ . (2) $E(n)-\mathcal{P}(E(n))\ \in \{1,\Bbb P\}$ . It is based in the same idea as the Fortunate Numbers , to know more about the reasons why I did the test please check here (longer explanation).
I tried several combinations, but the following one seems to work properly so far and is not related with factorials or primorials, so I believe it would be easier to test: $E(n)$ ={ $m$ whose $\sigma_1(m)$ value is the $n^{th}$ element of the Record value sequence of $\sigma_1(m)$ (sum of divisors of m) ( A034885 )}$ ""Record values"" are defined as the subset of values $\sigma_1(m)$ of the set of sum of divisors of $m \in \Bbb N$ who are bigger than any previous values of the set, up to that value $m$ , so it provides a strictly increasing set of values of $\sigma_1(m)$ . Those are exactly the values of OEIS A034885 $(1,3,4,7,12,15,18,28,31,39,42...)$ . And they are exactly (thanks to @Ivan Neretin for the suggestion in the answers!) the Highly Abundant Numbers sequence (OEIS A002093 ): $\{1,2,3,4,6,8,10,12,16,18,20,24,30,36,42,48...\}$ The point is that tested almost up to $10^{27}$ both the distances of those elements $E(n)$ to the previous and following closer primes (when there is a previous positive prime) is also a prime number or $1$ . Here is a sample PARI/GP code able to check easily up to $10^9$ : testlimit = 10^9;n=1;exitval=0;prevsumdiv=0;while((n<testlimit) && (exitval==0),dj=divisors(n);sum_div=0;for(t=1,length(dj),sum_div=sum_div+dj[t]);while(sum_div<=prevsumdiv,sum_div=0;n=n+1;dj=divisors(n);for(t=1,length(dj),sum_div=sum_div+dj[t]));prevsumdiv = sum_div;np=nextprime(n+1);npmn=np-n;pp=precprime(n-1);nmpp=n-pp;if((nmpp==1 || isprime(nmpp)) && (npmn==1 || isprime(npmn)), print(""n= "",n,"" sigma1(n)= "",sum_div,"" N(n)= "",np,"" N(n)-n= "", npmn ,"" P(n)= "",pp,"" n-P(n)= "", nmpp);,exitval=1;)); After that point, I have been able to reduce the expression. It is possible to use instead of $\sigma_1(m)$ a reduced version of the sum of divisors, I will call it $\sigma_e(m)$ defined as the sum of the even composite divisors of $m$ not including $m$ itself in case of being even. In other words, it is the sum of divisors not including the sum of the prime numbers that are divisors, odd divisors, $1$ and $m$ itself. $E(n)$ is: $E(n)$ ={ $m$ whose $\sigma_e(m)$ value is the $n^{th}$ element of the Record value sequence of $\sigma_e(m)$ (sum of composite even divisors of m not including m in case of being even)}$ So it is not required to use A034885 anymore. Apart from this expression, I tried also using the sum of the prime divisors of $m$ , and other combinations of partial sums of the divisors of $m$ , including $1$ and $m$ itself, but those ones did not work. The even divisors seem to be the key. This is an example including the interval [1,99]. Please I would like to ask the following questions: Why does it happen? I can not imagine which possible reason is behind that property. Some insights would be very welcomed! Are there similar expressions based on other non-factorial functions? so far I have tried using the totient function and some sums of divisors of even numbers instead of $\sigma_e(n)$ , all of them unsuccessfully. I did not find any reference to this property, if it was already tested please I would like to know about it.
Thank you! Last update 2016/01/05 : amazingly $\forall h \in $ {Highly Abundant Numbers}, $h\gt3$ ,tested up to $10^{27}$ no counterexamples found, the closest prime number $p \lt h$ located to a distance $d=(h-p) \gt 1$ is also always at a prime distance, so $d \in \Bbb P$ . If the test is not wrong, these would mean that the even Highly Abundant Numbers greater than $2$ have always at least a Goldbach pair of primes. $h=p+d, p,d\in\Bbb P$","['conjectures', 'divisor-sum', 'prime-numbers', 'sequences-and-series', 'elementary-number-theory']"
1584207,$ S_{n}=\frac{x}{x+1}+\frac{x^2}{(x+1)(x^2+1)}+...........+\frac{x^{2^{n}}}{(x+1)(x^2+1)...(x^{2^{n}}+1)}$,"If $\displaystyle S_{n}=\frac{x}{x+1}+\frac{x^2}{(x+1)(x^2+1)}+\frac{x^{2^{2}}}{(x+1)(x^2+1)(x^{2^2}+1)}+...........+\frac{x^{2^{n}}}{(x+1)(x^2+1)...(x^{2^{n}}+1)}$ Then $\displaystyle \lim_{n\rightarrow \infty}S_{n} = \;,$ Where $x>1$ $\bf{My\; Try::}$ First we will calculate $\bf{r^{th}}$ term of the sequence. So $$\displaystyle \bf{T_{r}} = \frac{x^{2^{r}}}{(x+1)(x^2+1)............(x^{2^{n}}+1)} = \frac{x^{2^{r}}(x-1)}{x^{2^{r+1}}-1}$$ So We get $$\displaystyle \bf{T_{r}} = \frac{x^{2^{r}}(x-1)}{(x^{2^r}-1)(x^{2^{r}}+1)}$$ Now I did not Understand How can I convert into Telescopic Sum. Help me Thanks",['sequences-and-series']
1584220,Let $f: \Bbb R \to \Bbb R$ be a differentiable function such that $\sup_{x \in \Bbb R}|f'(x)| \lt \infty$. Then,"(UGC CSIR-2015, DECEMEMBER, MATHEMATICAL SCIENCES) $f$ maps a bounded sequence to a bounded sequence. $f$ maps a Cauchy sequence to a Cauchy sequence. $f$ maps a convergent sequence to a convergent sequence. $f$ is uniformly continuous. I choose all of the options as possible answers because the condition $\sup_{x\in \Bbb R}|f'(x)| \lt \infty$ forces $f$ to be uniformly continuous.(Because $f$ becomes Lipschitz and Lipschitz condition implies uniform continuity) i.e. $\frac {|f(x)-f(y)|}{|x-y|} \le \sup_{x\in \Bbb R}|f'(x)|$
$ \forall x,y$. Hence all other options are bound to be true. Am I correct?","['real-analysis', 'cauchy-sequences', 'functions', 'uniform-continuity', 'convergence-divergence']"
1584221,Even + Odd Function,"How can we express $f(x) = \ln x, x>0$ as a sum of even and odd function? We know that every function can be written as a sum of even and odd function. What about this one here? Somebody help.","['real-analysis', 'calculus', 'functions']"
1584239,expectation of a nonlinear function of a Gaussian random variable [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am reading a book on Monte Carlo Simulation and I want to know where the formula below come from. $$E\left[ X^4\right] {\text{ }} = 3\sigma _x^4 + 6\sigma _x^2\mu _x^2 + \mu _x^4$$ Suppose $X$ is a Gaussian random variable: $X \sim N\left({\mu_x},\sigma _x^2\right)$. 
Thanks.","['statistics', 'expectation', 'random-variables']"
1584311,"What are the possible limits of the iteration $x_{n+1}=\sqrt{x_n+3}$, $x_0=0$?","Let $f(x)=\sqrt{x+3}$ for $x\ge -3$.
Consider the iteration $$x_{n+1}=f(x_n),x_0=0;n\ge 0$$ 
The possible limits of the iteration are -1 3 0 $\sqrt{3+\sqrt{3+\sqrt{3+\cdots}}}$ I think only option 4. is correct as it the only one satisfying $x^2-x-3=0$","['recurrence-relations', 'real-analysis', 'sequences-and-series', 'limits']"
1584319,"What is known about the 'Double log Eulers constant', $\lim_{n \to \infty}{\sum_{k=2}^n\frac{1}{k\ln{k}}-\ln\ln{n}}$?","The Euler constant is defined as $$\gamma = \lim_{n \to \infty}{\sum_{k=1}^n\frac{1}{k}-\ln{n}}$$
Let $$q = \lim_{n \to \infty}{\sum_{k=2}^n\frac{1}{k\ln{k}}-\ln\ln{n}}$$
I managed to prove that $$\frac{1}{3\ln{3}}+\frac{1}{2\ln{2}}-\ln\ln{3} \geq q \geq \frac{1}{2\ln{2}}-\ln\ln{3}$$
Is there something known about the constant $q$? For instance, is $q$ expressible in terms of $\gamma$?","['analytic-number-theory', 'limits', 'asymptotics', 'euler-mascheroni-constant', 'constants']"
