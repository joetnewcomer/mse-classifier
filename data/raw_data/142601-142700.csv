question_id,title,body,tags
2313592,How many points must the arc intersect?,"Let's say we have some number of points $\{x_i\}$, which lie on a circle. We wish to position an arc somewhere on the circle, which has an arc length equal to $\frac1c$ of the circle's circumference, such that we minimise the number of the $\{x_i\}$ that lie on the arc. Can we always position the arc such that at most $\frac1c$ of the points lie on it? Note: when $c$ is an integer, we can do this by the pigeonhole principle: we cover the circle in $c$ of the arcs, and so one of them must have $\frac1c$ or fewer of the $\{x_i\}$ lying on it.","['circles', 'geometry']"
2313597,Transform a recurrence with fraction into a linear recurrence,"How can you transform this recursive formluar into a linear recurrence (in order to get a closed formular and calculate a (closed) function)? $t(n) = 2 * \frac{(t(n-1))^3}{(t(n-2))^2}$ and $t(0) = t(1) = 2$ I would know how to countine if I had a linear recursive formular, but unfortunately the fraction makes things quite a bit tricky.","['recursion', 'discrete-mathematics']"
2313632,"What is the origin of the term ""moments"" in the study of random variables?","I understand what the moments are, I just want to know who picked the term ""moment"" and why? How is the word ""moment"" related to different but related ways to describe the shape of a random variable?","['statistics', 'math-history', 'moment-generating-functions']"
2313638,Show that $f$ & $g$ is a solution to the below differential equation!,"$\frac{dy}{dx}+P(x)y=0$ Show that if f and g are solutions to the differential equation where $c_1$ and $c_2$ are arbitrary constants then $c_1f$ & $c_2g$ are also solution to the differential equation My attempt 
Since this equation is separable therefore, $P(x)dx+\frac{dy}{y}=0$ By This differential equation must be exact! $\frac{\partial P(x)}{\partial y}=\frac{\partial y^{-1}}{\partial x}=0$ $\int_{} P(x)=f+g+c_1$ $\int_{}  \frac{1} {y} =lny+c_2$ I know this is lousy. Can someone guide me?","['proof-writing', 'ordinary-differential-equations']"
2313659,Equally many cards between aces,"What is the probability that in a set of $52$ cards, there will be equally many cards between each ace? I tried this problem, but I am stuck. I know that there are $52!$ possible cases. If there are $k$ cards between each ace, than this would be likely event $\{A,k,A,k,A,k,A\}$. There is $4!$ ways to permute these aces, and cards between them $k!\cdot k!\cdot k!\cdot 3$, so that is $3\cdot 4!\cdot (k!)^3$ likely events. Another likely case would be $\{m,A,k,A,k,A,k,A\}$. Here it would be $4!\cdot (48-m)!\cdot 3$. Total number of likely events would be  $$\frac{3\cdot 4!\cdot (k!)^3+4!\cdot (48-m)!\cdot 3}{52!}$$ Of course, this cannot be right, because I have m and k in expression so it is not good. Where am I making mistake? And if there is some easier approach could you explain it in detail so I could really understand what is happening? Thanks","['combinatorics', 'probability', 'discrete-mathematics']"
2313671,Help understand Taylor's theorem - “when” does a function becomes linear?,"It is known that for relatively small intervals around some value (say $a$), any (any?) continuous and differentiable function $f$ can be approximated (in the region of the interval) to a linear function via Taylor's theorem with: $f(x) = f(a) + f'(a)*(x-a) + h_k(x)(x-a)$ How is this notion defined more precisely? For example, say that I take the function $x^2$, and I am interested in a region around $x=1$, how can I say how close my function is to linear, as the region around 1 becomes smaller?",['limits']
2313700,Showing that $\bar{\mathbb{B}}^n$ is a manifold with boundary (Lee ITM Probelm 3-4),"""Show that every closed ball in $\mathbb{R}^n$ is an $n$-dimensional manifold with boundary, as is the complement of every open ball. Assuming the theorem on the
invariance of the boundary, show that the manifold boundary of each is equal
to its topological boundary as a subset of $\mathbb{R}^n$, namely a sphere. Hint: for the unit ball in Rn, consider the map  $\pi \circ \sigma^{-1}: \mathbb{R}^n \rightarrow \mathbb{R}^n$, where $\sigma$ is the stereographic projection and $\pi$ is a projection from $\mathbb{R}^{n + 1}$ to $\mathbb{R}^n$ that omits some
coordinate other than the last."" So, I've got (the first part, anyways) of the question done, but my technique was a little different than what Prof. Lee suggested: I considered the ball as infinitely many foliated spheres, mapped each one to a plane using the stereographic projection, and then put the last coordinate as a function of the distance from the north/south pole. However, my solution seemed to neatly avoid any use of $\pi$ as mentioned, and I'm curious if anyone knows how that solution runs.","['smooth-manifolds', 'manifolds', 'general-topology', 'differential-geometry', 'manifolds-with-boundary']"
2313726,Can we Smoothly Choose a Line Fixed by a Smoothly Rotating Rigid Body?,"$\newcommand{\R}{\mathbf R}$ The question below is motivated by the fact that each non-identity member of $SO(3)$ fixes exactly one line pointwise in $\R^3$. Let $f:\R\to SO(3)$ be a smooth map (which models a smoothly rotating pivoted rigid body in $\R^3$). Question. Does there necessarily exist a smooth map $g:\R\to \mathbf RP^2$ such that $f(t)$ fixes $g(t)$ pointwise for each $t$. The question above has negative answer if we do not require $f$ to be smooth but only continuous. For then we can take $f$ to be as follows: for $t\in [0, 1]$ we define $f(t)$ as rotation about the $z$-axis by $2\pi t$, and for $t\in [1, 2]$ we deifne $f(t)$ as rotation about the $x$-axis by $2\pi (t-1)$. For all other $t$ we define $f(t)=I$. Now if there exists a continuous $g:\R\to \R P^2$ such that $f(t)$ fixes $g(t)$, then for $t\in (0, 1)$ we must have $g(t)$ is the $z$-axis, and for $t\in (1, 2)$, $g(t)$ equals the $x$-axis. Thus $g(1)$ cannot take any value without destroying continuity. Of course, this counterexample does not work for smooth case.","['physics', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2313748,Can We Smoothly Choose an Eigenvector of a Smoothly Parameterized Self-Adjoint Linear Map,"$\newcommand{\R}{\mathbf R}$ Let $V$ be a finite dimensional real inner product vector space, and let $f:\R\to L(V)$ be a smooth map, where $L(V)$ denotes the space of all linear maps mapping $V$ into $V$. Assume that for each $t\in \R$, $f(t)$ is self-adjoint. Thus for each $t$ we know that $f(t)$ has a basis consisting of eigenvectors. Question. Does there necessarily exist a smooth map $g:\R\to V\setminus\{0\}$ such that $g(t)$ is an eigenvector of $f(t)$ for each $t$? If at $t_0\in \R$ we have $f(t_0)$ has $\dim V$ distinct eigenvalues, then by the proof of the LEMMA in this post we know that there is a smooth $\alpha:(t_0-\epsilon, t_0+\epsilon)\to \R$ such that $\alpha(t)$ is an eigenvalue of $f(t)$ for each $t\in (t_0-\epsilon, t_0+\epsilon)$, where $\epsilon$ is sufficiently small. Thus what we want to know, as a special case of the above question, is whether the map $(t_0-\epsilon, t_0+\epsilon)\to \mathbb P(V)$ given by $t\mapsto \ker(f(t)-\alpha(t) I)$ smooth or not.","['smooth-manifolds', 'differential-geometry', 'differential-topology']"
2313753,Generalized Jacobi Equation for Minimal Surface Deviation,"For background, recall that the Jacobi equation (also known as the equation of geodesic deviation) determines the evolution of the Jacobi field, interpreted as a deviation vector between two ""infinitesimally nearby"" geodesics.  Specifically, let $u^a$ be the tangent vector to a geodesic and let $\eta^a$ be a Jacobi field along it.  Then the Jacobi equation says that
$$
u^a\nabla_a (u^b \nabla_b \eta^c) + R_{abd}^{\phantom{abd}c} u^a u^d \eta^b = 0,
$$
where $R_{abcd}$ is the Riemann tensor of the ambient space. My question is the following: since a geodesic is just a special case of a minimal surface, is there some analogous equation for the deviation vector field between two ""infinitesimally nearby"" minimal (or more generally, extremal) surfaces?  That is, let $\Sigma$ be a minimal surface (of any dimension and codimension) and let $\eta^a$ be a deviation vector field on $\Sigma$ to some infinitesimally nearby minimal surface (more rigorously: let $\Sigma_t$ be a one-parameter family of minimal surfaces with $\Sigma = \Sigma_0$; then define $\eta^a = (\partial_t)^a$).  Is there an equation of the form
$$
D^2 \eta^a + R_{bcd}^{\phantom{bcd}a} h^{bd} \eta^c = \mathrm{stuff},
$$
where $D^2$ is the Laplacian on $\Sigma$, $h^{ab}$ is the (inverse) induced metric on $\Sigma$, and the ""stuff"" terms are linear in $\eta^a$ and can contain things like the curvatures (intrinsic and extrinsic) of $\Sigma$? I've only been able to find partial answers to this question.  I think the equation I want may be related to the so-called Jacobi or stability operator of a minimal surface, related to the formula for the second variation of the area (as mentioned here ), but as far as I can tell that Jacobi operator is defined to act on functions (not vectors, as I want), and most references I see refer to embedded surfaces in Riemannian 3-manifolds (i.e. they don't seem to refer to completely general dimensions).  Moreover, the sources I've seen derive integral equations for the second derivative of the area under some perturbation, whereas I want a differential equation for the Jacobi field. I have also found this reference (specifically section 5.1) which does seem to do things in general dimensions, but runs into the same problem that it only obtains an integrated expression. (As you may be able to tell, I was trained in general relativity so I'm used to a different sort of notation than is usual in the math literature; it may be that I found what I wanted but couldn't translate it into familiar language!)","['minimal-surfaces', 'differential-geometry']"
2313797,Is the space of $C^k$ submanifolds a Banach manifold,"Let $M$ and $N$ be (finite-dimensional) smooth manifolds without boundary. For simplicity, assume $M$ is compact. This post concerns spaces of ""copies of $M$ in $N$"". To the best of my knowledge, the following are true: Fact 1: Let $\mathcal{I}^\infty$ denote the space of $C^\infty$ embeddings $M\hookrightarrow N$. Then $\mathcal{I}^\infty$ is a smooth Fréchet manifold. For an embedding $i\in\mathcal{I}^\infty$, the tangent space $T_i\mathcal{I}^\infty$ can be thought of as the space of $C^\infty$ vector fields along $i$, which is indeed a Fréchet space. Fact 2: Let $\mathcal{S}^\infty$ denote the space of smooth submanifolds of $N$ diffeomorphic to $M$. Then $\mathcal{S}^\infty$ is also a smooth Fréchet manifold. For a submanifold $S\in\mathcal{S}^\infty$, the tangent space $T_S\mathcal{S}^\infty$ can be thought of as the space of $C^\infty$ sections of the normal bundle. Fact 3: Let $k$ be a positive integer, and let $\mathcal{I}^k$ denote the space of $C^k$ embeddings $M\hookrightarrow N$. Then $\mathcal{I}^k$ is a smooth Banach manifold. A tangent space $T_i\mathcal{I}^k$ can be thought of as the space of $C^k$ vector fields along $i$. This space is Banach. And finally, My question: Let $\mathcal{S}^k$ denote the space of $C^k$ submanifolds of $N$ which are ($C^k$) diffeomorphic to $M$. Is $\mathcal{S}^k$ a smooth Banach manifold? If not, is it a $C^l$ Banach manifold for some $l$? I can't think of any reason why $\mathcal{S}^k$ shouldn't be a Banach manifold. At least on the tangent-space level, everything seems to work well. Indeed, let $S\in\mathcal{S}^k$. Then the space of $C^k$ vector fields on $S$ is a closed subspace of the space of $C^k$ vector fields along the inclusion $S\hookrightarrow N$, which is Banach. So, the space of $C^k$ sections of the normal bundle is also Banach (as the quotient of a Banach space by a closed subspace) and seems to be a reasonable model for the tangent space $T_S\mathcal{S}^k$. However, this is certainly not a sufficient answer to the question. Furthermore, I know that in some cases, arguments which work perfectly for smooth maps fail to hold for $C^k$ maps. Therefore, I wouldn't be surprised to hear that $\mathcal{S}^k$ does not have a natural smooth structure. I will be grateful for any insight, as well as a reference to a text containing a clear discussion of this matter.","['banach-spaces', 'differential-geometry', 'differential-topology']"
2313839,How should I be avoiding this mistake? (To avoid missing solutions),"First of all, I am sorry if this is a question too simple or stupid. Consider the equation: $$
\log((x+2)^2) = 2 \log(5)
$$ If I apply the logarithm law $ \log_a(b^c) = c \log_a(b) $ $$
\begin{align}
2 \log(x+2) & = 2 \log(5) \\
\log(x+2) &= \log(5) \\
x+2 &= 5 \\
x &= 3
\end{align}
$$ But I can see that I am missing a solution, $x = -7$.
I noticed that $$
\begin{align}
\log((x+2)^2) &= 2 \log(5) \\
\Updownarrow \\
2 \log(x+2) &= 2 \log(5)
\end{align}
$$ Is NOT true. The domain of the first equation is $x \in \mathbb{R}$ but the second equation's is $x \geq -2$. I know the correct solution. So I understand that this is not an equivalent transformation of the equation. What I don't know is how I should avoid this. Is there something to keep in mind that would help me evade this mistake? Naturally, I wouldn't have noticed the missing solution, unless I checked the domain of the second equation, which I wouldn't really have had a reason for...","['algebra-precalculus', 'logarithms', 'relations']"
2313870,Solving an ODE for the Green function using Fourier transform,"I'm trying to reproduce the results of a paper, I'll insert here what is important and then explain what I cannot understand. We have this equation for the Green function $\mathcal{G}$:
  $$\left( D_y \frac{\partial^2}{\partial y^2}-v_y\frac{\partial}{\partial y} -\delta(y)D_xk_x^2-ik_xv_x-s \right) \mathcal{G} (k_x,y,\overline{y};s)=\delta (y- \overline{y}),$$
  subjected to the boundary conditions $\mathcal{G}(k_x, \pm\infty, \overline{y};s)=0$. This equation can be solved by a Fourier transform with respect to $y$ (in the ""physicist form"": $\mathcal{F} [f(y)](k_y)=\int_{-\infty}^{\infty} dye^{-ik_y y}f(y)$ and $\mathcal{F}^{-1}[f(k_y)](y)=\frac{1}{2\pi} \int_{-\infty}^{\infty}dk_ye^{ik_yy}$ ):
  $$\mathcal{G} (k_x,k_y,\overline{y};s)=- \frac{e^{-ik_y\overline{y}}}{D_yk_y^2 +ik_yv_y+ik_xv_x+s}-\frac{D_xk_x^2}{D_yk_y^2 +ik_yv_y+ik_xv_x+s} \mathcal{G}(k_x,0,\overline{y};s).$$ The last term has the presence of the Green function at $y=0$, which after some calculation it is possible to show that is given by
  $$\mathcal{G}(k_x,0,\overline{y};s)=-\frac{e^{-\frac{v_y}{2 D_y}\overline{y}} e^{-\sqrt{\frac{\beta}{D_y}}\vert\overline{y}\vert }}{2\sqrt{D_y \beta} +D_xk_x^2},$$
  where $\beta=s+ik_xv_x+v_y^2/(4D_y)$. I can't reproduce these ""some calculations"" that give the expression for $\mathcal{G}(k_x,0,\overline{y};s)$. Maybe I have to solve the first equation and then apply $y=0$, because when he says ""$y=0$"" implies that it should be done before the Fourier transform; but I don't know how to do it. PS: $D_y$, $D_x$, $v_y$ and $v_x$ are real constants.","['greens-function', 'ordinary-differential-equations', 'fourier-transform']"
2313878,existence of random variables having a specific joint law,"Let us fix a probability space $(\Omega, \mathcal F, \mathbb P)$ supporting a random variable $X$, where the $\sigma$-filed $\mathcal F=\sigma(X)$.   For a sub-$\sigma$-filed $\mathcal G\subset\mathcal F$, we can define a new random vairable $Y=\mathbb E(X|\mathcal G)$. The joint law of $(X,Y)$, denoted $\pi$, would be a probability measure on $\mathbb R^2$, which satisfies $\int_{\mathbb R^2} f(x) d\pi(x,y)=\int_{\mathbb R} f(x)d\mu(x)$ for all bounded measurable function $f$, where $\mu$ is the law of $X$, and $\int_{\mathbb R^2} g(y)(y-x)d\pi(x,y)=0$ for all bounded measurable function $g$. Condition (1) says that the 1st marginal of $\pi$ is $\mu$, while condition (2) is equivalent to saying that the 1st and 2nd marginal of $\pi$ are related by a conditional expectation relation: $\mathbb E(X|Y)=Y$. What I want wo know is whether the converse of the above is true : if a probability measure $\pi$ on $\mathbb R^2$ satisfying (1) and (2) is given, can I find a random variable $Y$ s.t. $(X,Y)$ has joint distribution $\pi$?","['probability-theory', 'random-variables', 'probability-distributions']"
2313895,Laplace and Fourier transform,"I have a doubt about the equivalence between Fourier Transform and Laplace Transform. It was told me that if I have a function such that: $f(t)=0$ if t<0 $f\in L^1(R) \bigcap L^2(R)$ I can define $F[f(t)]=\int_{0}^{\infty}f(t) e^{-j\omega t}dt$ $L[f(t)]=\int_{0}^{\infty}f(t) e^{-s t}dt$ I can look at the Fourier transform as the Laplace Transform evaluated in $s=j\omega$ IF AND ONLY if the abscisse of convergence is strictly less than zero. (I.e. if the region of convergence includes the imaginary axis. If the abscisse of congence is $\gamma=0$, then (it was told me), I can have poles on the real axes, and I have to define the Fourier transform with indentations in a proper manner. In the Papoulis's book there is written ""if $\gamma=0, $ the Laplace transform has at least one of the singular points on the imaginary axes. So, I think that the situation should be like this: Then, if I extend the frequency in the complex plane, I can consider that -regarding the Fourier transform- the axes are rotated with respect to the axis of the s-plane: So I should have: Finally, I think that these two last steps could explain the word ""real"" related to the poles at the beginning of the question... Please, tell me If the reasoning is wrong and where.. many thanks","['complex-analysis', 'fourier-transform', 'laplace-transform']"
2313898,A question about gradient field,"Let $\vec{F}=(xy,x^2+y^2)$ be a vector field. 
Is there exist a function $f(x,y)$ such that $\vec{\nabla}f=\vec{F}$? My attempt: if $f_x=xy$ and $f_y=x^2+y^2$, then $f(x,y)=\frac{x^2y}{2}+g(y)$. Therefore $f_y=\frac{x^2}{2}+g'(y)$. Hence $\frac{x^2}{2}+g'(y)=x^2+y^2$, so $g'(y)=\frac{x^2}{2}+y^2$. But $g(y)$ is a function of $y$,  a contradiction. On the other hand, if you take any circle $C(t)=(R\cos t,R\sin t)$, $t\in[0,2\pi]$ then 
$$
\oint_{C}f\cdot d\vec{l}=\int_{0}^{2\pi}(R^2\cos t\sin t,R^2)\cdot(-R\sin t,R\cos t)\,dt=R^3\int_{0}^{2\pi}\cos^3t\,dt=0
$$
 Why this does not contradict the first claim? Thanks",['multivariable-calculus']
2313913,Question on entire functions,"Can I find non-constant entire functions $f$ and $g$, and complex numbers $a$ and $b$, such that, for any $z\in\mathbb{C}$: $$
  ze^{f(z)}=e^{g(z)}+az+b
$$ I think it is not possible, but I could not prove it or disprove it.","['complex-analysis', 'complex-numbers']"
2313922,Partial Order Relation and Equivalence Relations,"R is a partial order relation on some set A. Which of the following statements are correct? a) $R\cup R^{-1}$ is an equivalence relation b) $R^{2}$ is a partial order relation c) $R\cap R^{-1}$ is an equivalence relation I've tried solving this. For (a), I think this is true, but the answer I got say false. My logic was: for every x, $xRx$ since R is reflexive. R is also ant-symmetric, so for every pair $xRy$, we will have $yRx$ because of the union, and so $R\cup R^{-1}$ is symmetric. Now I tried thinking on transitive, I took an example: $R={(1,1),(2,2),(3,3),(1,2),(2,3),)(1,3)}$ If you do $R\cup R^{-1}$ you get a transitive relation. I can't find an example to break it. What am I doing wrong ? For (b) I tried a similar example and go $R^{2}=R$ which shows it's true, but it must have been a private case. How can you explain the fact that (b) is true ? (I am not looking for a formal proof). For (c), if I use intersection, I get only ""reflexive"" couples, so this is true. Am I correct on this one at least ? Thank you.","['relations', 'elementary-set-theory']"
2313925,"How to evaluate closed form of $\int_{0}^{\pi}\sin(x)\ln^n\left(k\cos\left({x\over 2}\right)\right)\mathrm dx=F(n,k)?$","How can we evaluate the closed form for this integral $$\int_{0}^{\pi}\sin(x)\ln^n\left(k\cos\left({x\over 2}\right)\right)\mathrm dx=F(n,k)\color{red}?\tag1$$ Where $n\ge0$ and $k>0$ Given that the first few values of $F(n,k)$ are:
$$F(0,k)=2$$ $$F(1,k)=2\ln(k)-1$$ $$F(2,k)=2\ln^2(k)-2\ln(k)+1$$ $$F(3,k)=2\ln^3(k)-3\ln^2(k)+3\ln(k)-{3\over 2}$$ $$F(4,k)=2\ln^4(k)-4\ln^3(k)+6\ln^2(k)-6\ln(k)+3$$ It may take the closed form of: $$F(n,k)=\sum_{j=0}^{n}(-1)^ja_j\ln^j(k)$$ $u={x\over 2}\implies 2du=dx$ $$2\int_{0}^{\pi/2}\sin(2u)\ln^n(k\cos(u))\mathrm du\tag2$$ $v=k\cos(u)\implies du=-{dv\over k\sin(u)}$ $${4\over k^2}\int_{0}^{k}v\ln^n(v)\mathrm dv\tag3$$ $$I_n=\int v\ln^n(v)\mathrm dv={v^2\over 2}\ln^n(v)-{n\over 2}\int v\ln^{n-1}(v)\mathrm dv\tag4$$ $$I_n={v^2\over 2}\ln^n(v)-{n\over 2}I_{n-1}\tag5$$","['integration', 'calculus', 'closed-form']"
2313963,Motivation for learning about fundamental groups and covering spaces,"I am about to give a seminar presentation in an algebra seminar (undergraduate level) about the Hopf fibration $SU(2) \longrightarrow SO(3)$ for which I will use an algebraic-topological approach using the more topological representations $SU(2) \cong S^3$ as well as $SO(3) \cong \mathbb{R}P^3$. For this, I want to introduce the concepts of universal coverings and fundamental groups. My question now is, how can I give some motivation for math-undergraduates (especially those possible 'only' interested in Algebra) to learn about fundamental groups/universal coverings? For me, it's just an interesting concept, but that's not very convincing, I suppose... Hence: What are good reasons to learn about fundamental groups (and universal coverings?) when you're an undergraduate, (possibly mainly) interested in Algebra and not necessarily interested in algebraic topology?","['algebraic-topology', 'abstract-algebra', 'advice', 'fundamental-groups']"
2313971,How can I find a resolution of $\Omega^i_X$ for a projective smooth complete intersection $X$?,"Given a projective smooth complete intersection $i:X \to \mathbb{P}^n$ defined by polynomials $(\underline{f}) = (f_1,\ldots,f_k)$ the koszul complex $K^\bullet(\underline{f})$ can be used to compute the sheaf cohomology $H^k(X,\mathcal{O}_X)$. This is because
$$
H^k(X,\mathcal{O}_X) = H^k(\mathbb{P}^n,i_*\mathcal{O}_X)
$$
and the second term can be computed using the spectral sequence
$$
E_1^{p,q} = H^q(\mathbb{P}^n,K^{p}) 
$$
Does there exist a ""nice"" flat resolution of $\Omega_X^k$ which gives a similar type of spectral sequence?","['sheaf-cohomology', 'algebraic-geometry']"
2313973,Probability that a random binary matrix is invertible - what is going on?,"This is a follow-up to this question: Probability that a random binary matrix is invertible? The answer says that the probability of a random $\{0,1\}$, $n \times n$ matrix to be invertible is: $$p(n)=\prod_{k=1}^{n}(1-2^{-k})\;,$$ For a $32\times32$, that's about 0.288. But, when I generate a random matrix in Matlab, and check its rank, it's always 32! The code is: A=randi([0 1],32,32);rank(A) . You can even try it online here . Is the answer wrong? Is Matlab/Octave wrong? Please help me solve the mystery. Thanks!","['matrices', 'random-matrices', 'probability', 'linear-algebra']"
2314030,Conservative Systems and The Hamilton-Jacobi Equation,"I am trying to understand geometrically the relation between a conservative classical system described by the hamiltonian $H$ for which the trajectories of particles are given by
$$\dot{x} = \nabla_p H(x,p) \qquad \dot{p} = - \nabla_x H(x,p)$$
and that of the Hamilton-Jacobi equation
$$u_t - H(x,\nabla u) = 0.$$ Namely: the trajectories of particles with hamiltonian $H$ are constrained to level sets of that hamiltonian. Are these level sets related to the characteristic curves given by the corresponding Hamilton-Jacobi equation? Is there a direct way to go between the level sets to the characteristic curves or vice versa? You may restrict the problem to 1 space dimension if necessary. Thank you!","['dynamical-systems', 'partial-differential-equations', 'classical-mechanics', 'ordinary-differential-equations', 'differential-geometry']"
2314042,Adjunctions are Kan Extensions.,"I have been trying to understand the statement of the title but seems that I am getting stuck on something in the very last of its proof. To start with, assume that we have the adjunction $\mathsf{C} \overset{\mathcal{F}} {\underset{\mathcal{G}}\rightleftarrows} \mathsf{D}$, $\mathcal{F} \dashv \mathcal{G}$. Our statement, is that we have the following diagram
\begin{array}{cc}
\,\,\,\,\,\,\,\mathsf{C} \\
\\
\mathcal{F} \downarrow & \,\,\,\,\,\,\,\searrow \,{id_{\mathsf{C}}} \\
\\
\mathsf{D} & \xrightarrow{\mathcal{G} \cong Lan_{\mathcal{F}}id_{\mathsf{C}}}  & \mathsf{C},
\end{array}
In other words, that $\mathcal{G}$, is the left Kan Extension of the identity functor $id_{\mathsf{C}}$ along $\mathcal{F}$. In order to prove that, we have to prove that $\mathcal{G}$, fulfils the universality of left Kan extensions. Where is my problem: Apparently, due to the adjunction we can define the natural transformation $ \eta : id_{\mathsf{C}} \rightarrow \mathcal{G \circ F}$, to be the unit of the adjunction. Then we assume that another functor $\mathcal{H}: \mathsf{D} \rightarrow \mathsf{C}$ along with a natural transformation $\gamma : id_{\mathsf{C}} \rightarrow \mathcal{H \circ F}$, exists and then we have to find a unique natural transformation $\delta : \mathcal{G} \rightarrow \mathcal{H}$, such that $ \delta_{\mathcal{F}} \circ \eta_{\mathcal{F}}= \gamma_{\mathcal{F}}.$ However, to find out $\delta$, it's kind of simple, since due to the adjunction again, we have the following adjunction too $ \mathsf{C}^{\mathsf{C}} \overset{\mathcal{G}^{*}} {\underset{\mathcal{F}^{*}} \leftrightarrows} \mathsf{C}^{\mathsf{D}}$. Therefore the uniqueness of transformation follows. What I cannot prove is why we end up having the composition $ \delta_{\mathcal{F}} \circ \eta_{\mathcal{F}}= \gamma_{\mathcal{F}}$. Could you please help me out? Thank you.","['category-theory', 'abstract-algebra', 'adjoint-functors']"
2314059,Uniqueness of point placement with the knowledge of interdistances,"I was wondering if anybody can help in this seemingly weird problem. Consider a set of points $x_1, \ldots, x_n$ such that $x_1 = -a$, $x_n=a$, and $-a<x_i<a$ for $i \in \{2,3,\ldots,n-1\}$. Given a set of numbers $\mathcal{D} = \{ |x_i - x_j|, \forall i\neq j\}$ that is the set of interdistances between all the points. Notes to clarify more on $\mathcal{D}$: We only have the numbers in $\mathcal{D}$, we do not know which number corresponds to the distance of which two points. The maximum distance in $\mathcal{D}$ is always $2a$, which is the distance between the extremes $x_1$ and $x_n$. For each point $x_i, i \in \{2,..,n-1\}$, there will exist two numbers in $\mathcal{D}$ which will add up to $2a$, those are the distances from this point to the extremes. The cardinality of $\mathcal{D}$ is always $^nC_2$, which means that all distances between the points are distinct. Suppose that we could find a placement (the values) for the points $x_2, \ldots, x_{n-1}$ for which the interdistances form the set $\mathcal{D}$, it is obvious that $-x_2, \ldots, -x_{n-1}$ will result in the same set $\mathcal{D}$. The objective is to prove (or disprove) that there are no other set of values for $x_2,\ldots, x_{n-1}$ for which their set of interdistances (call it $\mathcal{D}_2$) is equivalent to $\mathcal{D}$. In other words, given the set of interdistances between some points on a line (between $-a$ and $a$), can we uniquely determine the values of these points, up to the ambiguity of reflection? This is a little similar to the point placement problem in computer science, except that the distances are all known exactly, but not known to which pairs they belong.","['algorithms', 'computer-science', 'geometry']"
2314112,Proof or Counterexample for Sequence Convergence Conjecture,"Recently I came up with a number sequence defined as: $$
a_{i} = \begin{cases}
N & \text{if } i = 0 \\
S(a_{i-1})  & \text{if } i > 0
\end{cases}
$$ Where: $$
S(N) = \begin{cases}
\sum \text{Prime Factors of N} & \text{if N is composite} \\
N + P_{next} &\text{if N is prime}
\end{cases}
$$ And $P_{next}$ is defined as the next prime after N. (i.e. If N is 7, $P_{next}$ is 11) It can be shown the sequence will loop on: (N=5): {5, 12, 7, 18, 8, 6, 5, ...} (N=4): {4, 4, ...} (N=3): {3, 8, 6, 5, 12, 7, 18, 8, 6, 5, ...} (N=2): {2, 5, 12, 7, 18, 8, 6, 5, ...} For clarity's sake, $\sum \text{Prime Factors of N}$, refers to the summation of ALL prime factors with respect to their multiplicities.
For example: S(18) = 8 because 18 is composite, and its prime factors are {2,3,3}. Since 2 + 3 + 3 = 8, S(18) = 8. For $N\geq2$ and $N\leq10,000,000$, with the exception of N = 4, all sequences converge on 5, which as shown above is a looping sequence. My conjecture is that for all $N\geq2$, with the excepton of N = 4, the sequence will converge to 5. Is it possible to prove this conjecture? Or conversely, disprove it through a counterexample? As stated above, I have tested the conjecture for $2\leq N\leq 10,000,000$. Thanks in advance.","['prime-numbers', 'sequences-and-series', 'convergence-divergence', 'discrete-mathematics']"
2314121,Prove or disprove that the left inverse of a function $f: X \mapsto X$ if it exists is unique [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove or disprove that the left inverse of a function $f: X \to X$ if it exists is unique. Similarly prove or disprove the right inverse of a function $f: X \to X$ if it exists is unique.","['proof-writing', 'elementary-set-theory']"
2314123,Are there nontrivial equations for hyperoperations above exponentiation?,"A similar question was asked in comments elsewhere . A paper by Roberto Di Cosmo and Thomas Dufour ( ""The Equational Theory of 〈ℕ, 0, 1, + , ×, ↑〉 Is Decidable, but Not Finitely Axiomatisable"" ) asserts in footnote 2 (p.3) that it has been shown ""that there are no nontrivial equations for $⟨\mathbb{N}, \mathrm{Ack}(n, \_, \_)⟩$ if $n > 2.$"" References make it clear that $\mathrm{Ack}(n,x,y)=H_{n+1}(x,y)$ in the hyperoperation sequence , so the assertion is as follows: $\text{There are no nontrivial equations for the binary function }(\_\uparrow^y\_)\text{ if }y>1\\ \text{ (i.e., for hyperoperations above exponentiation)}\tag{*}.$ (For this, the above paper cites Charles F. Martin, ""Axiomatic bases for equational theories of natural numbers"", Notices
of the Am. Math. Soc., 19(7):778, 1972, which I have not found online.) Q.1 : What, precisely, is meant by a ""nontrivial equation"" here? (The defining recursion $$x\uparrow^{y+1}(z+1)=x\uparrow^y (x\uparrow^{y+1}z),$$ which certainly holds for $y>1$, is evidently considered trivial.) Q.2 : Is the following a valid proof based on assertion $(*)$? ... Claim : If $x,y,z$ are integers $\gt 1$, then the value of $\ x\uparrow^y z\ $ uniquely determines $x,y,z$; i.e., 
$$x\uparrow^y z = x'\uparrow^{y'} z' \quad\implies\quad x=x',\ y=y',\ z=z'.\quad \tag{1}$$ (The purpose of restricting the domain to integers $>1$ is to remove obvious counterexamples that arise from equations like $x\uparrow (a\cdot z) = (x\uparrow a)\uparrow z\ \ $ or $\ \ 2\uparrow^y 2=4\uparrow^{y'} 1\ \ $ or $\ \ 1\uparrow^y z=1\uparrow^{y'} z'.$) Proof : Suppose, for the sake of contradiction, that there is a counterexample to $(1)$, in which the LHS of the implication holds but not the RHS. Then the LHS is a nontrivial equation for some hyperoperation(s) beyond exponentiation, which is impossible as per $(*)$. QED","['abstract-algebra', 'big-numbers', 'universal-algebra', 'logic', 'hyperoperation']"
2314174,How to prove derivative of $\cos x$ is $-\sin x$ using power series?,"How to prove derivative of $\cos x$ is $-\sin x$ using power series? So $\sin x=\sum \limits_{n=0}^\infty\dfrac{(-1)^nx^{2n+1}}{(2n+1)!}$ and $\cos x=\sum \limits_{n=0}^\infty\dfrac{(-1)^nx^{2n}}{(2n)!}$ Then $\cos'(x)=\sum \limits_{n=0}^\infty\left(\dfrac{(-1)^nx^{2n}}{(2n)!}\right)'=\sum \limits_{n=0}^\infty\dfrac{(-1)^nx^{2n-1}}{(2n-1)!}=...$ Then I don't to how to go to $\sin x$, could someone help?","['derivatives', 'power-series', 'calculus']"
2314195,Calculate $\int_{0}^{\infty}\frac{\cos(x)}{x^2+x+1}dx $,"How to calculate integral $$\int_{0}^{\infty}\frac{\cos(x)}{x^2+x+1}dx $$ It's rather easy to find when the limits of integration are $[-\infty, \infty],$
but with lower limit being zero? Is it at all computable with some basic knowledge of complex analysis? Thanks in advance.","['complex-analysis', 'integration']"
2314223,"How can we show that for $\epsilon>0$, $\mathbb{P}([-N,N)^c)<\epsilon$?","I have the following question: i have been reading the wonderful book ""Probability Theory"" by A.A. Borovkov and on page 35, the author, after defining the probability measure $\mathbb{P}$ of some real line interval $[a_i,b_i)$ as the sum of the the distribution function evaluated at the interval's endpoints, that is, $\mathbb{P}(A)=\sum_{i=1}^n(F(b_i)-F(a_i))$ for $A=\cup_{i=1}^n[a_i,b_i)$, he then proceed to prove the continuity of $\mathbb{P}$. At some point he claims that for interval $C_N=[-N,N)$ and for any $\epsilon>0$, we can choose an $N$ such that $\mathbb{P}(C_N^c)<\epsilon$. I am not sure about how to explicitly show this. That is, if the real line $\mathbb{R}$ is the whole sample space, then $\mathbb{P}(C_N^c)=\mathbb{P}((-\infty,-N)\cup[N,\infty))$ $=F(\infty)-F(N)+F(-N)-F(-\infty)$ $=1-F(N)+F(-N)$. If we let $N\rightarrow\infty$, this probability approaches zero by the properties of the distribution function $F$. But then, how can I use the $\epsilon$ argument and the choice of $N$? Many thanks in advance, Christos Mix.",['probability-theory']
2314224,Definition of a non-linear first order Partial differential equation,"Actually I am a little bit confused about the definition. I have read two three articles but I could not find out what type of equations are called a non-linear partial differential equation. Articles are following. https://en.wikiversity.org/wiki/Partial_differential_equations https://www.slideshare.net/jayanshugundaniya9/advanced-engineering-mathematics-first-order-nonlinear-partial-differential-equation-its-applications https://mat.iitm.ac.in/home/sryedida/public_html/caimna/pde/forth/forth.html $pq = 0$ will be a first order non linear Partial differential equation? p,q are usual notation in PDE. Please don' downvote. I know it is a silly question. But I am really confused. Please help me. I am looking forward to ur reply.","['partial-derivative', 'ordinary-differential-equations', 'partial-differential-equations']"
2314330,The rectangular equation of the curve given parametrically by $x(t)=\tan (t)$ and $y(t)=\cos^2(t)$ is what?,The rectangular equation of the curve given parametrically by $x(t)=\tan (t)$ and $y(t)=\cos^2(t)$ is what? In a normal situation I would have set $t$ equal to something but in this case it becomes very messy I had set $\arctan(x)=t$ and plugged that into the other to get $y(t)=\cos^2(\arctan(x))$ but that got me no where and I was wondering if there was any better way of doing this? edit: new steps So I have developed other methods which is listed below: set $\cos(t)=\sqrt{y}$ and then we have $\frac{\sin(t)}{\sqrt{y}}=x$ but I still got no where,"['algebra-precalculus', 'parametric', 'trigonometry']"
2314351,Which real points are in the boundary of the Mandelbrot set?,"Recall: the Mandelbrot set $M$ is defined to be the set of points $c\in \mathbb{C}$ such that the sequence of complex numbers $\{c, c^2+c, (c^2+c)^2 + c, \ldots  \}$ is bounded in magnitude.
(Recursively, the sequence is defined by $z_1 = c$ and $z_{k+1} = z_k^2 + c$ .) The Wikipedia page on the Mandelbrot set states that the intersection of $M$ with the real axis is precisely the closed interval $[-2,1/4]$ . What if we instead intersect the boundary $\partial M$ of the Mandelbrot set with the real axis?
The figure here seems to suggest this intersection may be a discrete set of points, and that this  is related to the logistic map. However I did not find the answer to this on either Wikipedia page, after browsing briefly. To summarize, I am wondering: Can we say exactly what real points are in the boundary $\partial M$ ? Is the intersection $\mathbb{R}\cap \partial M$ a discrete set of points? If it is not discrete, is it dense in any open interval of $\mathbb{R}$ ?","['complex-analysis', 'complex-dynamics', 'dynamical-systems']"
2314353,"Find all the values of $c$, if any, for which $f(f(x))=x$.","Extracted from The Eleventh W.J. BLUNDON Contest, Consider the function $f(x)=\frac{cx}{2x+3},x\ne-\frac{3}{2}$. Find all the values of $c$, if any, for which $f(f(x))=x$. My attempt, $$\frac{c(\frac{cx}{2x+3})}{\frac{2cx}{2x+3}+3}=x$$ $$\frac{c^2x}{2cx+3(2x+3)}=x$$ $$c^2x=2cx^2+3x(2x+3)$$ $$c^2x=2cx^2+6x^2+9x$$ By comparing the coefficients, $$c^2=9 \space \text{and} \space 2c+6=0$$ So, $$c=-3$$ But the given answer is 3. Why? What's wrong with my solution?","['algebra-precalculus', 'functions']"
2314386,"$\mu\approx \nu$ and $\lim_{n\to \infty}\|u_n\|_{L^2(X,\mu)}=0$ imply $\lim_{n\to \infty}\|u_n\|_{L^2(X,\nu)}=0$ ??","Let $(X,d)$ be a bounded metric space, $\mu$ be a positive finite measure on $(X,d)$. Assume that $\mathcal F$ is a linear subspace of $L^2(X,\mu)\bigcap L^2(X,\nu)$ containing an orthonormal basis $\{\phi_i\}_{i=1}^\infty$ of $L^2(X,\mu)$,  where $d\nu:=W\,d\mu$ with $1<W\in L^\alpha(X,\mu)$ for some $\alpha>1$. Can we prove that $\mathcal F$ is dense in $L^2(X,\nu)$? If it is wrong, then can you give an example? Thank you! We observe that $\mathcal F$ is dense in $L^2(X,\mu)$, $\mu$ is equivalent to $\nu$ and $L^2(X,\nu)\subseteq L^2(X,\mu)$. It is well-known that:
 Let $u_n, u\in L^2(X, \mu)$. Since $\mu(X)<\infty$, we have $\|u_n-u\|_{L^2(X,\mu)}\to 0$ as $n\to\infty$ if and only if $u_n$ converges to $u$ in $\mu$-measure, and $\{|u_n|^2\}$ is uniformly integrable with respect to $\mu$, i.e., for any $\epsilon>0$, there exists $\delta>0$ such that
 $$
 \int_E|u_n|^2\,d\mu<\epsilon
 $$ for all $n\ge 1$ and any measurable subset $E\subseteq X$ such that $\mu(E)<\delta$.","['functional-analysis', 'normed-spaces', 'real-analysis', 'measure-theory']"
2314395,Probability of first complete set from a standard 52 card deck,"Suppose we have a standard, $52$-card deck that's been shuffled using a strong RNG and an unbiased shuffling algorithm. We draw one card at a time, without replacement, and stop as soon as we observe all four Aces. Given $k$, what is the probability that we observe all four Aces before we observe four of any other rank on the $k$th card, where $k = 4, 5, \ldots, 40$? In other words, and for example, if $k = 20$, what is the probability that the first $20$ cards contain exactly four Aces, with the fourth Ace being drawn on the $20th$ card and that the remaining sixteen cards are not four of any other rank? For $k = 4, 5, 6, 7$ this looks to be straightforward. But for $k \geq 8$ this feels increasingly headache-y. Thoughts on an approach For the $k = 20$ case from above, it seems like I have to, among other things, count the number of ways to partition $16$ [the remaining cards] with $12$ objects [the remaining ranks] where each object can get no more than three of a copy and then weighting each of these partitions. For example, I could observe a partition like $3 + 3 + 3 + 3 + 3 + 1$ as permutations of KKKQQQJJJTTT9998AAAA where one of the As is always at the end. Then I would weight each partition of $16$ from $12$ by the number of permutations and number of ways of choosing similar ranks. I can always simulate this, but for fun, I'm trying to see if there is a practical, exact approach. EDIT 6/9/2017 I seem to have caused some confusion with my example and original wording. Here is (hopefully) better wording of what I'm after. Fix $k$. The sample space is the set of permutations in which the fourth ace is drawn on the $k$th card. What proportion of those permutations contain only three or fewer occurrences of all other ranks in the first $k$ cards?","['combinatorics', 'probability']"
2314414,Does this probability paradox have a name? [duplicate],"This question already has answers here : Multiple-choice question about the probability of a random answer to itself being correct (6 answers) Closed 7 years ago . I stumbled over a probability paradox on the internet: If you choose an answer to this question at random, what is the chance that you will be correct? A) 25% B) 50% C) 60% D) 25% Given that ""at random"" means choosing each option with equal probability, each option had a chance of 25% to be correct. But since there are 2 options with 25% as the solution, we get 50% of being correct. In this case, B) would be correct. But then again, the probability of choosing B) at random would be 25%. And so on. Does this paradox have a name?
Is there something I can read on it?","['probability', 'paradoxes']"
2314415,"Suppose $M_n \rightarrow M$ in $L^1$ norm, then $\mathbb{E}[\mathbb{E}[M_X(t)^{M_n} | M_n]] \rightarrow \mathbb{E}[\mathbb{E}[M_X(t)^{M} | M]]$?","Suppose we have two r.v. $M, X$ and some sequence of r.v. $(M_n)_n$ s.t. $M_n \rightarrow M$ in $L^1$ norm, i.e. $\mathbb{E}[|M_n - M|] \rightarrow 0$. I would now like to show that we also have:
$$
\mathbb{E}[\mathbb{E}[M_X(t)^{M_n} | M_n]] \rightarrow \mathbb{E}[\mathbb{E}[M_X(t)^{M} | M]],
$$
here $M_X(t)$ denotes the moment generating function of $X$ at $t$. I would guess that we can replace $M_X(t)$ by any value $x$ so we would like to show that for arbitrary $a$ we have:
$$
\mathbb{E}[\mathbb{E}[a^{M_n} | M_n]] \rightarrow \mathbb{E}[\mathbb{E}[a^{M} | M]],
$$
and we need to find a good bound on
$$
\mathbb{E}[\mathbb{E}[a^{M_n} | M_n] - \mathbb{E}[a^{M} | M]]
$$
which does not seem too hard, but I don't really know how to get started.","['probability-theory', 'conditional-expectation']"
2314426,Finite group acting on a curve and a line bundle with $G$ action,"Let $C$ be a smooth projective curve over $\mathbb{C}$ and $G$ be a finite group acting on $C$. Consider the quotient $f:C\rightarrow C'=C/G$. Suppose that $C'$ is smooth (I think this will be true, since the quotient by a finite group is normal, and hence non-singular for curves). Consider a line bundle $L$ on $C$ with a $G$-action. It is possible that $L$ descends to $C'$, that is, there is a line bundle $L'$ in $C'$ such that $f^*L'=L$. Suppose it doesn't consider the maximal subsheaf of $L$ which descends, say $L^G\subset L$. This has to either zero or a rank one sheaf. 1) Is $L^G$ locally free. Can it be a line bundle not equal to $L$. For example, this will be ruled out if $L/L^G$ is locally free. 2)We can similarly talk about $V^G$ for a vector bundle $G$. Will $V^G$ be a direct summand of $V$? I would be grateful for some direction.",['algebraic-geometry']
2314467,On the regularity of the alternating sum of prime numbers,"Let's define $(p_n)_{n\in \mathbb N}$ the ordered list of prime numbers ($p_0=2$, $p_1=3$, $p_2=5$...). I am interested in the following sum: $$S_n:=\sum_{k=1}^n (-1)^kp_k$$ Since the sequence $(S_n)$ is related to the gaps between prime numbers, I would expect it to be quite irregular. But if we plot $(S_n)_{1\leqslant n\leqslant N}$ for $N\in \{50,10^3,10^5,10^6,10^7\}$, we obtain the following: We can observe a great regularity. So my questions are: Why is there so much regularity? Can we find the equations of the two lines forming $(S_n)$? Is there a proof that it will continue to be that regular forever? Any contribution, even partial, will be greatly appreciated. Updates. Thanks to mixedmath and Daniel Fischer , here is more curves: in blue, you have $S_n$; in red, you have $\displaystyle 2^{1/6}\displaystyle \sum (-1)^k k\log k$; in green, you have $\displaystyle \sum (-1)^k k\log k$; in purple, you have $\displaystyle \sum (-1)^k k(\log k+\log\log k)$; in yellow, you have $\displaystyle \sum (-1)^k k(\log k+\log\log k-1)$. My question seems quite related to this one .","['number-theory', 'prime-gaps', 'prime-numbers', 'arithmetic']"
2314470,How to solve $\ln x^n=0$?,"Consider the equation $\ln x^n=0$ , where $n$ is any positive integer. I use two method to solve it, but it gives different answer. Method 1: $$\ln x^n=0$$ $$x^n=1$$ By De Moivre's Theorem, we get $$x=\cos\frac{2k\pi}{n}+i\sin\frac{2k\pi}{n}$$ where $ k= 0, 1 ,2 ,3 ,... , n-1$ So there are total $n$ roots in this equation. Method 2: Using $ \ln a^b = b \ln a$, $$\ln x^n=0$$ $$n\ln x=0$$ $$\ln x=0$$ $$x=1$$ Which is only one root. Which method is correct and what goes wrong?","['algebra-precalculus', 'complex-numbers']"
2314483,"Solve the initial value problem $1+y\sinh(x)+(1+\cosh(x))y'=0,y(0)=\frac{1}{2}$","The question asks to solve the initial value problem:
$$1+y\sinh(x)+(1+\cosh(x))y'=0,y(0)=\frac{1}{2}$$
I have tried substituting $1=\frac{\sinh(x)}{\sinh(x)}$ and $1=\frac{\cosh(x)}{\cosh(x)}$ but can't seem to find a workable form to start finding $y_h$","['hyperbolic-functions', 'ordinary-differential-equations', 'initial-value-problems']"
2314487,Convergence in distribution to the standard normal using Cramer-Rao,"Given is a a random sample $X_1,\ldots,X_n$ from a distribution with a pdf $f(x;\theta) = 2\theta^{-1} x^{(2/\theta)-1}$ for $0<x<1$, zero otherwise. We know that maximum likelihood estimator is $\hat{\theta} = -\dfrac 2 n \sum_i \log X_i$. Determine $c$ such that $c\left(\dfrac{n}{-2\sum_i \log X_i} - \dfrac{1}{\theta}\right) \xrightarrow{\text{d}} Z  \sim N(0,1)$, i.e. converges in distribution. So in the correction sheet it says the answer is $\dfrac{1}{\sqrt{CRLB}}$ where CRLB stands for the Cramer Rao Lower Bound. I don't really understand this. I have found in my book that for large $n$ $\hat{\theta}_n \sim N(\theta, CRLB)$, but how can we normalise this result to a $N(0,1)$?","['statistics', 'normal-distribution', 'probability-distributions']"
2314539,variance/confidence interval of development patterns,"I was wondering if there is a technique to calculate the variance of developments. eg. I have paired data eg: 100 110, 200 225, 78 92, 33 20... This means the developments are: 1.1, 1.125, 1.18, 0.6... I was wondering if there is a technique to calculate a confidence interval around this. And I was also wondering if there is a way to weight this as well (eg. instead of assuming each development is equal, weigh the 200-225 development twice as much as the 100-110 one.","['statistics', 'probability']"
2314589,Trouble applying the fundamental theorem of Calculus,"Let $\psi(t)=\phi(t_0)*\exp(\int_{t_0}^t b(r)dr) + \int_{t_0}^t a(s) \exp(\int_{s}^t b(r)dr)ds$ Now I know already ( because this is from a differential equation example in a book ) that $$\psi'(t)= a(t)+ b(t)*\psi(t)$$ but I can't seem to differentiate correctly. If I differentiate $\psi(t)$  I should get 
$$\psi'(t)=\phi(t_0)*\exp(\int_{t_0}^t b(r)dr)* b(t)+ \frac{d}{dt}\int_{t_0}^t a(s) \exp(\int_{s}^t b(r)dr)ds$$
and then use FTC for the last summand, but ""plugging in"" $t$ for every $s$ is wrong here because of the $t$ in the last integral and it surely gives me a wrong result if I tried to. I think I have to use some kind of chain rule here, but I need some help with the details! How do I differentiate the last summand?","['real-analysis', 'ordinary-differential-equations', 'calculus']"
2314702,"""Manifolds are not Gorenstein""","I recently heard someone say that manifolds are not Gorenstein.
To me being Gorenstein means that the canonical divisor is Cartier. So I don't understand why manifolds aren't Gorenstein, since on a smooth variety all divisors are Cartier.","['gorenstein', 'algebraic-geometry']"
2314743,$G$-invariant tangent bundle,"We are given a Lie group $G$ and a smooth manifold $M$ equipped with a smooth group action $\Phi : G \times M \to M$, where we denote $\Phi_g := \Phi(g, \cdot)$ for $g \in G$. Consider the following equivalence relation on the tangent bundle $TM$: For $X_x \in T_x M$ and $Y_y \in T_y M$, define
$$
X_x \sim Y_y : \iff \exists g \in G : X_x = T_y \Phi_g Y_y,
$$
denoting by $T_y \Phi_g : T_y M \to T_ {\Phi_g(y)} M$ the usual tangent map. Then, define $TM_G := TM/ \sim$ as some kind of reduction of the tangent bundle. We can equip this with a surjective map $\pi : TM_G \to M/G$ by setting $\pi([X_x]) = [x]$, and we find a vector space structure on every preimage $\pi^{-1}([x])$.
Also, since $T\Phi : G \times TM \to TM$ can be regarded as a group action on the manifold $TM$, if we have a free and proper $\Phi$, we also have a free and proper $T \Phi$, and as such a smooth manifold structure on both $M/G$ and $TM_G$ (I'm not 100% certain whether properness of $\Phi$ implies properness of $T \Phi$, this I still need to check in detail, but my gut tells me it will work out). My question now is: Does this structure end up being a vector bundle over $M/G$ if we assume free and proper $\Phi$? Or do we need stronger conditions? With what I've got, I can't seem to write down meaningful local trivializations. Or is there a simpler construction for this bundle where the vector bundle structure comes more naturally? This thing we constructed here is in some sense ""larger"" than the usual tangent bundle: If well defined, every fiber in $T(M/G)$ is of dimension $\dim M - \dim G$, and every fiber in $TM_G$ is of dimension $\dim M$, so this is definitely something different from $T(M/G)$. I hope the question and the setting are clear, it might be that the whole idea is bollocks, but it seemed like a very natural structure to me. All help appreciated!","['group-actions', 'vector-bundles', 'differential-geometry']"
2314779,Prove that $n=\frac{5^{125}-1}{5^{25}-1}$ is a composite number [duplicate],"This question already has answers here : Prove that $\frac{ 5^{125}-1}{ 5^{25}-1}$ is a composite number (4 answers) Closed 4 years ago . Prove that $n=\dfrac{5^{125}-1}{5^{25}-1}$ is a composite number My attempt , Let $x=5^{25}$, so that $5^{125}-1=x^5-1=(x-1)(x^4+x^3+x^2+x+1)$ $=(x^4+9x^2+1+6x^3+6x+2x^2-5x^3-10x^2-5x)(x-1)$ $=((x^2+3x+1)^2-5x(x+1)^2)(x-1)$ I'm stuck at this point and don't know how to continue anymore. Hope someone can provide a detailed solution. Thanks a lot.","['algebra-precalculus', 'elementary-number-theory']"
2314783,Final step of exercise 11.7 from Atiyah-Macdonald ($\dim A[x]=\dim A+1$),"Ex. 11.7 from Atiyah-Macdonald is basically to prove $\dim A[x]=\dim A+1$ for $A$ noetherian. From exercise 11.6, we get $\dim A[x]\geq\dim A+1$, so we are left to prove ""$\leq$"". I've followed the hint and proved that $\text{ht}(p[x])=\text{ht}(p)$ for every $p\subset A$ prime, but I'm still not sure why this implies $\dim A[x]\leq\dim A+1$. Here is what I've thought so far: if $P_1\subsetneq...\subsetneq P_k$ is a maximal chain in $A[x]$, then $P_k$ is maximal and $k=\dim A[x]$. Suppose that $m:=P_k\cap A$ is a maximal ideal of $A$. That way, $A/m$ is a field and $A[x]/m[x]\simeq A/m[x]$ is a P.I.D. Since $P_k$ is maximal, $\overline{P_k}\in A[x]/m[x]$ is maximal, so $\text{ht}(\overline{P_k})=1$, which means $P_k$ is minimal prime of $m[x]$. That way, $k=\text{ht}(P_k)=\text{ht}(m[x])+1=\text{ht}(m)+1\leq\dim A+1$. The problem with what I did is that it depends on $P_k\cap A$ being maximal. Is this necessarily the case? I feel like this is crucial, otherwise the hint wouldn't work. How do I prove that? If it isn't true, how can I conclude that $\dim A[x]\leq\dim A+1$?","['abstract-algebra', 'krull-dimension', 'commutative-algebra', 'ring-theory', 'dimension-theory-algebra']"
2314798,"Approximating a decimal with a fraction (32-bit fixed point to two 23-bit numbers). Think binary, ease of computation.","I have a 32-bit fixed-width decimal number between 0 and 1.0 (actually its guaranteed to be between 0.001 and 0.02, so loss of range is acceptable in the approximation). The binary representation is defined as most-significant-bit representing 1/2, bit after that 1/4, and so on to 32 bits. I must represent this number as a ratio of two 23-bit numbers (actually one of them is 23 and one is 18 bits but let's simplify for the sake of discussion). It does not matter what the 2 numbers are as long as each of them fits in 23 bits. Another way to think about this problem is I have a fraction with a 32-bit numerator and a known constant denominator of 2^32. I must approximate this fraction as another fraction with 23-bit numerator and 23-bit denominator, such that an error of no more than 1/(2^32) is acceptable. Is there a reasonably efficient algorithm that would allow me to do this without doing a brute force guess-and-check? Some form of ""bit twiddling"" trick would be ideal as this must be done on a fairly small microcontroller. Barring that, the next best thing would be integer arithmetic. I understand that since I am repacking 32 bits of information into a total 46 bits of information, theoretically it is possible. A brute force solution of guessing and checking until some pair of number works is pretty trivial. What I am looking for is some more efficient algorithm or at least a way of figuring out a good starting point for guess-and-check. Ideally, there would be a defined time bound for the execution of this algorithm. For example, my input (A) is 0.005777551792562008. If we take the binary representation of this 0b 0000 0001 0111 1010  1010 0011 0011 1100 , it can be reinterpreted as the 32-bit unsigned integer 24,814,396. This number can be represented as the ratio (N/D) $$ 0.005777551792562008 =  \frac{24814396}{2^{32}} \approx  \frac{41572}{7195435} = 0.005777552017355449 $$. In this case, the error of the approximation is 2.248e-10 which is smaller than 1/(2^32)=2.328e-10 . The situation described in this question is pretty specific because it's based on a real world scenario. However, please feel free to generalize, even if your generalization makes the answer not fit the specific situation I describe. The point of this question is to get some ideas about where to start and hopefully leave something that is applicable in more situations. Computing a ""close enough"" fractional approximation of a decimal is a pretty general problem, but one I have not seen addressed specifically in the context of computers and binary representation.","['number-theory', 'computational-mathematics', 'fractions']"
2314859,Difference of the floor of a product and the product of floors,Is there any way the following can be simplified? $$\lfloor f(x)\cdot g(x) \rfloor - \lfloor f(x) \rfloor  \cdot \lfloor g(x) \rfloor$$,['ceiling-and-floor-functions']
2314872,Find the possible value of $x$ such that $f(x)=K$,"Let $f(x)=\lfloor\{\sqrt{x}\}.10^{18}\rfloor$ where $\{x\}=x-\lfloor x\rfloor$ i.e. the fractional part of x, meaning the values after the decimal dot. For example $\sqrt 3 = 1.7320508075688772935274...$ and $f(3) = 732050807568877293$ Given the value of $f(x)=K$, how can I find any possible value of $x=x_0$ so that $f(x_0)=K$ and $x_0$ is an INTEGER less than $10^{18}$.",['number-theory']
2314924,"Computing the Integral $\int\tanh[b(x-a)]\cos\beta x\,dx$","$1$. Recently, I encountered the following integral in a physical problem $$I(a,b,\beta)=\int\tanh[b(x-a)]\cos\beta x\,dx,$$ where $a,\,b,\,\beta$ are some real numbers. Mathematica gives this results which looks really complicated. I want to know how the result of mathematica can be obtained? Also, the Re and FullSimplify commands in Mathematica didn't make any further simplification. Can the result of mathematica be put in terms of real numbers? The imaginary $i$ seating there makes me un-comfortable for further use. I should substitute this result into many other equations I am hopeful to get a simpler form for the anti-derivative as I believe that humans do much better than machines and programs (see this post as a proof!) :) My thought was to write a Taylor expansion for $\cos\beta x$ and then going through. In that case we encounter the following integrals $$J_{2n}(a,b,\beta)=\int x^{2n}\tanh[b(x-a)]\,dx,\qquad n=0,1,2,\dots$$ which I couldn't manage to get a nice closed form for them. $2$. If there is no way to get a simpler anti-derivative then I am interested to obtain a simple form for the following definite integral $$I=\int_{-l}^{l}\tanh[b(x-a)]\cos\beta x\,dx,$$ where $\beta=\frac{n\pi}{l}$ and $n$ is a positive integer so obviously $\cos\beta l=(-1)^n,\,\sin\beta l=0$. Any help or hint is appreciated. :)","['calculus', 'indefinite-integrals', 'hypergeometric-function', 'integration', 'definite-integrals']"
2314930,Finding all $23$rd roots of a given element of $S_{10}$,"Given the permutation 
  $$\sigma = 
\begin{pmatrix} 
1 &2 &3 &4 &5 &6 &7 &8 &9 &10\\
1 &2 &3 &7 &5 &6 &4 &8 &9 &10
\end{pmatrix}$$
  solve the equation $$\gamma^{23} = \sigma ,$$
  where $\sigma,\gamma \in S_{10}$ What I did: $\sigma $ in cycle notation is $(47)$ i.e a transposition.The order of $\sigma$ is 2 because the length of the cycle is 2, so that means $\sigma$ his it's own inverse (I think) i.e $\sigma \circ\sigma = e$. Taking the equation $\gamma^{23} = \sigma$ and multiplying on the right by $\sigma$ I get  $\gamma^{23} \circ \sigma = e$ , so that means that $\gamma^{23}$ and $\sigma$ are inverses , that implies that $\gamma$ must be  equal to $\sigma$ since the order of $\sigma$ is 2 and $\gamma^{22} = \gamma^{24} = e$ since 22 and 24 are divided by the order of $\sigma$ , so the only option is $\gamma = \sigma$. Is that correct?Is there another way of solving this type of equations? I doubt it's right.","['permutations', 'abstract-algebra', 'group-theory']"
2314942,"Finding the nth derivative of functions, in particular y=tan(x)","For $y=\cos2x$ Since $\frac{d y}{d x} = -2 \sin2x$, and $\frac{d^2 y}{d x^2} = -4 \cos2x$, then $\frac{d^2 y}{d x^2} = -4y$, so $\frac{d^3 y}{d x^3} = -4\frac{d y}{d x}$, $\frac{d^4 y}{d x^4} = -4\frac{d^2 y}{d x^2}$, etc. Therefore, the nth differential of $y=\cos2x$ is $\frac{d^n y}{d x^n} = -4 \frac{d^{n-2} y}{d x^{n-2}}, n\geq 2$ For $y=\ln(x)$ Same as above, but this time the differentials are expressed in terms of $x$, not each other. $ y=\ln(x) \Rightarrow \frac{d y}{d x} = x^{-1} \Rightarrow \frac{d^2 y}{d x^2} = -x^{-2}$, etc. So for $y=\ln(x)$, $\frac{d^n y}{d x^n} = (n-1)!(-1)^{n-1}x^{-n}, n\geq 2$ For $y=\tan(x)$ So the question is, does an equation such as that exist for $y=\tan(x)$? I have tried two approaches: Differentials of $\tan(x)$ in terms of $y$ and $\frac{dy}{dx}$: \begin{array}{c}
 \frac{d y}{d x} & = & 1+y^2 \\ 
 \frac{d^2 y}{d x^2} & = & 2y\frac{d y}{d x} \\ 
 \frac{d^3 y}{d x^3} & = & 4(\frac{d y}{d x})^2 & - & 2\frac{d y}{d x} \\ 
 \frac{d^4 y}{d x^4} & = & 20y(\frac{d y}{d x})^2 & - & 4y\frac{d y}{d x} \\
 \frac{d^5 y}{d x^5} & = & 20(\frac{d y}{d x})^3 & + & 68(\frac{d y}{d x})^2 & - & 72 \frac{d y}{d x} \\
\end{array} There are some patterns you can spot but it didn't seem very promising so I moved on. Differentials of $\tan(x)$ in terms of other differentials: \begin{array}{c} 
 \frac{d y}{d x} & = & 1+y^2\\ 
 \frac{d^2 y}{d x^2}& = & 2y\frac{d y}{d x}\\ 
 \frac{d^3 y}{d x^3}& = & 2y\frac{d^2 y}{d x^2} & + & 2(\frac{d y}{d x})^2\\ 
 \frac{d^4 y}{d x^4}& = & 2y\frac{d^3 y}{d x^3} & + & 6\frac{d^2 y}{d x^2}\frac{d^2 y}{d x^2}\\
 \frac{d^5 y}{d x^5}& = & 2y\frac{d^4 y}{d x^4} & + & 8\frac{d^3 y}{d x^3}\frac{d y}{d x} & + & 6(\frac{d^2 y}{d x^2})^2\\
 \frac{d^6 y}{d x^6}& = & 2y\frac{d^5 y}{d x^5} & + & 10\frac{d^4 y}{d x^4}\frac{d y}{d x} & + & 20\frac{d^3 y}{d x^3}\frac{d^2 y}{d x^2}\\
 \frac{d^7 y}{d x^7}& = & 2y\frac{d^6 y}{d x^6} & + & 12\frac{d^5 y}{d x^5}\frac{d y}{d x} & + & 30\frac{d^4 y}{d x^4}\frac{d^2 y}{d x^2} & + & 20(\frac{d^3 y}{d x^3})^2\\
 \frac{d^8 y}{d x^8}& = & 2y\frac{d^7 y}{d x^7} & + & 14\frac{d^6 y}{d x^6}\frac{d y}{d x} & + & 42\frac{d^5 y}{d x^5}\frac{d^2 y}{d x^2} & + & 70\frac{d^4 y}{d x^4}\frac{d^3 y}{d x^3}\\
 \frac{d^9 y}{d x^9}& = & 2y\frac{d^8 y}{d x^8} & + & 16\frac{d^7 y}{d x^7}\frac{d^1 y}{d x^1} & + & 56\frac{d^6 y}{d x^6}\frac{d^2 y}{d x^2} & + & 112\frac{d^5 y}{d x^5}\frac{d^3 y}{d x^3} & + & 70(\frac{d^4 y}{d x^4})^2\\
\end{array} Table of coefficients expressed in terms of prime factors: \begin{array}{c|c c c c c }
&1&2&3&4&5\\\hline
2&2\\
3&2&(2)\\
4&2&2\times3\\
5&2&2\times2\times2&(2\times3)\\
6&2&2\times5&2\times2\times5\\
7&2&2\times2\times3&2\times3\times5&(2\times2\times5)\\
8&2&2\times7&2\times3\times7&2\times5\times7\\
9&2&2\times2\times2\times2&2\times2\times2\times7&2\times2\times2\times2\times7&(2\times5\times7)\\
\end{array} This is much more exciting. I have worked out formulae up to the third term: \begin{array}{ c c|c c c}
&term& 1 & 2 & 3 & m & last\\
&& 2y\frac{d^{n-1} y}{d x^{n-1}} & 2(n-1)\frac{d^{n-2} y}{d x^{n-2}}\frac{d y}{d x} & (n-1)(n-2)\frac{d^{n-3} y}{d x^{n-3}}\frac{d^2 y}{d x^2} & (?)\frac{d^{n-m} y}{d x^{n-m}}\frac{d^{m-1} y}{d x^{m-1}}*^1 & 2(?)\frac{d^{\frac{n-1}{2}} y}{d x^{\frac{n-1}{2}}}*^2\\
\end{array} $*^1$ Note : $(n-m)$ and $(m-1)$ add up to $n-1$, i.e. one less than the differential that is being calculated. $*^2$ Only appears when $\frac{n-1}{2}$ is a whole number, i.e. for $n$ odd. The problem I am encountering is that there doesn't seem to be an expression that works for every terms of every differential. Then again I have only calculated up to the 3rd term. Any ideas? (Also I'd be very interested if you found any other nth differentials of this sort.)","['recurrence-relations', 'sequences-and-series']"
2314967,simplify :$\frac{1}{f_5}+\frac{1}{f_6}+\frac{1}{f_{12}}+\frac{1}{f_{20}}$,"let : $$f_n=\sqrt[4]{2}+\sqrt[n]{4} \ \ \ n\geq2 \in \mathbb{N}$$ then simplify : $$\dfrac{1}{f_5}+\dfrac{1}{f_6}+\dfrac{1}{f_{12}}+\dfrac{1}{f_{20}}=?$$ MyTry : $$f_5=\sqrt[4]{2}+\sqrt[5]{4} \ \ \ , \  \ f_6=\sqrt[4]{2}+\sqrt[6]{4} \ \ , \ \ f_{20}=\sqrt[4]{2}+\sqrt[20]{4}$$ $$\dfrac{1}{\sqrt[4]{2}+\sqrt[5]{4}}+\dfrac{1}{\sqrt[4]{2}+\sqrt[6]{4}}+\dfrac{1}{\sqrt[4]{2}+\sqrt[12]{4}}+\dfrac{1}{{\sqrt[4]{2}+\sqrt[20]{4}}}=?$$ Now : $$\dfrac{1}{\sqrt[4]{2}+\sqrt[5]{4}}+\dfrac{1}{\sqrt[4]{2}+\sqrt[6]{4}}=\dfrac{\sqrt[4]{2}+\sqrt[6]{4}+\sqrt[4]{2}+\sqrt[5]{4}}{(\sqrt[4]{2}+\sqrt[5]{4})(\sqrt[4]{2}+\sqrt[6]{4})}$$ And : $$\dfrac{1}{\sqrt[4]{2}+\sqrt[12]{4}}+\dfrac{1}{\sqrt[4]{2}+\sqrt[20]{4}}=\dfrac{\sqrt[4]{2}+\sqrt[20]{4}+\sqrt[4]{2}+\sqrt[12]{4}}{(\sqrt[4]{2}+\sqrt[12]{4})(\sqrt[4]{2}+\sqrt[20]{4})}$$ now what ?",['algebra-precalculus']
2314973,find the limit of $ (1/\sin\ (x)-1/x)^x$,"I am trying to find the limit of $\lim_{x \downarrow 0} (\frac{1}{sinx}- \frac{1}{x})^x$. My current progress: $\lim_{x \downarrow 0} (\frac{1}{\sin x}- \frac{1}{x})^x = \lim_{x \downarrow 0} (\frac{x-\sin x}{x\sin x})^x = \lim_{x \downarrow 0} e^{xln(\frac{x-\sin x}{x \sin x})} = e^{\lim_{x \downarrow 0}xln(\frac{x-\sin x}{x \sin x})} = e^{\lim_{x \downarrow 0}\frac{ln(\frac{x-\sin x}{x \sin x})}{1/x}}$ This is where I used l'Hospital, but after 2 iterations of l'Hospital it doesn't look like I'll get anywhere with it. Expression after first l'Hospital:
(I'll not write the e as the base, so that the limit is easier to read) $\lim_{x \downarrow 0}\frac{-x^3\sin x\cos x - x \sin^3x}{x\sin^2x - \sin^3x} = \lim_{x \downarrow 0}\frac{-x^3\cos x - x \sin^2x}{x\sin x - \sin^2x}$ Am I missing something or is it just tedious to find the limit of this expression? After the second iteration of l'Hospital, I've got this term: $\lim_{x \downarrow 0}\frac{-3x^2\cos x + x^3\sin x - \sin^2x -2x\sin x\cos x}{x\cos x + \sin x -2\sin x\cos x} = ""\frac{0}{0}""$ is that term correct? If so, I'll try to apply l'Hospital a third time.",['limits']
2315011,How should one prepare for graduate studies in probability?,"I have an undergraduate degree in Probability and Statistics and am contemplating joining a graduate program for PhD. I believe I am reasonably strong in probability theory and would like to do research in the area. However, I am a bit confused about where the current research in probability is going. I went through some reputed journals in Probability like the Annals of Probability and Journal of Theoretical Probability. I was a bit disappointed to see that currently research in probability constitutes either combinatorics or differential equations. There are lots of models, primarily from Statistical Physics literature. I like probability and mathematical statistics. I do not really want to be in combinatorics -- never really liked the field. But from what probabilists are currently interested in, it seems that finding expected cluster sizes in random graphs and doing triangulations and stuff are all that are happening. Where did the research similar to that of Stein go? In my university I am doing courses like Brownian motion, Empirical Processes, Martingale theory, etc. However I don't find any article on these. Are these too outdated? Has the market been completely occupied by triangles and graphs? Is probability too immersed in ""models""? One of my professors said, ""Everything is a model!"" Then where is the identity of a subject? Everybody who seems to do probability and is sufficiently famous seems to be doing these! I think it is time to really understand where the research in probability is going at present. I have been long disappointed to see no big program in probability, like Perfectoid spaces or Langland's program in Number Theory. There is no big theory which people try to understand. How does a prospective graduate student understand what is the aim of probability? What are the non-combinatorial areas of probability? How active are they? What are some resources or influential papers on these? What should one learn in order to attack modern problems in probability? As I said, in other subjects there are things to learn. There are interconnections between Algebraic Geometry and Algebraic K Theory. I understand such theories are not there in probability since it is too young. Eve if they exist, are they really active areas?","['probability-theory', 'soft-question']"
2315029,Meaning of a bifurcation? Meaning of bifurcation diagrams?,"So it seems like in the literature there are two separate meanings for what a bifurcation is. One meaning is that a bifurcation is the point at which an equilibrium changes behavior. The other meaning is that a bifurcation is when an equilibrium point splits into two. Now here is my confusion. I am trying to study the dimensionless generalized version of Chua Circuit Equations
$$\dot{x}=a(y-\phi(x))$$$$\dot{y}=x-y+z$$
$$\dot{z}=-by$$
$$\phi(x) = \frac{1}{16}x^3 - \frac{1}{6}$$ and I'm supposed to study bifurcations in this context using $a$ as bifurcation parameter. Now the equilibria in this case are not dependent on the bifurcation parameter $a$. So in this context the equilibria might change behavior but they will not change position or split as a function of $a$. So what is a bifurcation exactly? Is it a splitting, moving of equilibria or it is a change in behaviour of equilibrium points? Or both? Also with regards to bifurcation diagrams, I came across the bifurcation diagram in this paper: https://pdfs.semanticscholar.org/5a3c/fa3a66da70f9b6af8510ec7abdeca443fdbb.pdf This is a bifurcation diagram of Chua Equations using the parameter $a$. I don't understand why the equilibrium points are moving and splitting since they aren't a function of $a$? I don't really understand what is going on in this diagram.","['bifurcation', 'ordinary-differential-equations', 'dynamical-systems']"
2315056,The given relation is not equivalence,"A relation $R$ is defined on the set of integers as follows: 
$$(a,b)\in R\iff a^b=b^a$$ Clearly, it is reflexive and symmetric. But I am unable to give a counter example that it is not transitive. Thanks.","['equivalence-relations', 'elementary-set-theory']"
2315093,Another formulation of existence theorem for smooth bump functions,"Let $M$ be a smooth manifold (at least Hausdorff). Most of the times, as an application of the existence of partitions of unity on $M$, the existence of smooth bump functions is shown (see for example Lee or Warner). It is stated like this: For any closed subset $A \subseteq M$ and any open subset $U$ containing $A$, there exists a smooth bump function for $A$ supported in $U$, i.e. the bump function is identically equal to $1$ on $A$. However, it is often usefull to have the following restatement (as far as I can tell from a few proofs): For any $p \in M$ and any open set $U$ there exists a bump function supported in $U$ and identically equal to $1$ on a neighbourhood of $p$. So I tried to proof the second statement assuming the first. The proof goes like this: $p$ lies in the domain of a chart, say $(V,\varphi)$. Then $\varphi(U \cap V)$ is open in $\mathbb{R}^n$ and thus contains an open ball $B$. Now we can find a closed ball $K \subseteq B$, centered at $\varphi(p)$, and another open ball $B' \subseteq K \subseteq B$ centered also at $\varphi(p)$. Now we find a smooth bump function supported in $U$ which is identically equal to $1$ in $\varphi^{-1}(K)$, so it is in $\varphi^{-1}(B')$. Is my proof right? Is there any simpler proof?",['differential-geometry']
2315121,Geometric Interpretation of the Permanent,"The Permanent of a square matrix M = ($m_{i,j}$) is defined as follows: $Perm(M) = \sum_{\sigma\in S_n}\prod_{i=1}^{n} m_{i,\sigma(i)}$ The Permanent is quite similar to the Determinant of a square matrix, defined as follows: $Det(M) = \sum_{\sigma\in S_n}sign(\sigma)\prod_{i=1}^{n} m_{i,\sigma(i)}$ The Determinant has an intuitive geometric interpretation. Is anything similar known about the Permanent? If not, why does the signed sum of the permutations lend itself to a geometric interpretation and the unsigned sum does not?","['linear-algebra', 'permanent', 'determinant']"
2315242,Combining sum of floor functions,"Consider a simple sum of floor functions:
$$S = c\left\lfloor \frac{x}{a}\right\rfloor + d\left\lfloor \frac{x}{b} \right\rfloor$$ Can we combine these two terms into a single function?  I am trying to simplify something like this to avoid successive divisions in a computer program. My question, in general, is: can we combine the following $k$ terms to avoid performing $k$ divisions and multiplications of $x$:
$$S(x,k)=\sum_{i=0}^{k}c_i\left\lfloor \frac{x}{a_i}\right\rfloor$$","['algebra-precalculus', 'number-theory', 'summation', 'ceiling-and-floor-functions']"
2315317,Find the locus of centres of circles,"I have to find the locus of centres of circles that pass through the point $(8,0)$ and tangent to circle $x^2+y^2=100$ $(x_0, y_0)$ - centres we are looking for I decided to try something with distances, so I made a the equation $(x_0^2-8)^2+y_0^2=r^2$ It is the distance from center to point Also I found the equation for tangent for our big circle $x_1x+y_1y-100=0$, where $x_1, y_1$ a point on the circle Equatation for distance from center to tangent is $\frac {(x_1x_0+y_1y_0-100)^2}
{x_1^2+y_1^2} =r^2$ But I dont have any results","['analytic-geometry', 'conic-sections', 'circles', 'geometry']"
2315374,How can I improve my problem solving/critical thinking skills and learn higher math?,"I'm a rising sophomore in high school. So far, I've taken Algebra One, Two, and Geometry in school. I want to learn higher math such as precalculus/trigonometry, calculus, linear algebra, and more, so I can go into topics such as cryptography, advanced computer science, and possibly take the AMC and other olympiad tests (I'm not too interested in that). The only problem, though, is that my abilities in problem solving and other stuff in math aren't that good. I do pretty well in my classes (high As) but that doesn't mean anything. The U.S. system doesn't seem too good in actually teaching math. For example, I can do whatever is on my homework or tests. But, if I'm given a more difficult problem than usual concerning a topic I learned (say logarithms or something), I can't solve it. I feel like this is going to be a hindrance to me learning higher math, doing well in more difficult subjects like calculus and linear algebra, doing well on olympiad tests, and going into math-heavy fields like computer science and cryptography. So, how can I change all of this and improve my skills? Are there any books that teach problem-solving, mathematical thinking, and higher math (or something like precalculus)? Again, I want to better these skills so I can do well not only in math, but other fields. Any help is really appreciated.","['algebra-precalculus', 'self-learning', 'problem-solving', 'soft-question']"
2315375,Variation of Donsker's Invariance principle,"Let $X_{1},X_{2},\ldots$ be i.i.d. with mean 0 and variance 1. What can be said about the functional limit of $W^{n}_{t}:=\frac{1}{\sqrt{l_{n}}}\sum_{j=[\alpha_{n}t]-l_{n}+1}^{[\alpha_{n}t]}X_{j}$, $0\leq t\leq 1$, for any monotone sequence $\alpha_{n}$? Of course, $l_{n}$ is an increasing sequence tending to $+\infty$. I think Donsker's theorem should be the right tool for that type of question. But I am not able to write it down rigorously.","['stochastic-processes', 'probability-theory']"
2315381,Components and connectedness,"I was hoping to get a hint for the following problem (4.48 from Mathematical Analysis by T. Apostol which I'm trying to self-study).  If $S$ is an open connected set in $\mathbb{R}^n$ and $T$ is a component of $(\mathbb{R}^n-S),$  I'm to show that $(\mathbb{R}^n - T)$ is connected. I don't have much, just some observations: If I argue, towards contradiction, that $(\mathbb{R}^n - T)$ is disconnected, then $(\mathbb{R}^n - T) = A \cup B$ for $A,B$ disjoint and open in $(\mathbb{R}^n - T)$. Now, we cannot have both $S \cap A$ and $S \cap B$ nonempty, for otherwise $S = (S \cap A) \cup (S \cap B)$ would be disconnected. So I can take $S \subset A$. Since $S$ is open, $(\mathbb{R}^n - S)$ is closed. Here is one other thought that comes to mind: I'm sure there must be something special about $\mathbb{R}^n$ here, but I'm not seeing it.  For example, for $n=1$, $S$ is an open interval.  Therefore, $(\mathbb{R}-S)$ is either one or two intervals closed at one end and infinite at the other.  Then $T$ is all of $(\mathbb{R}-S)$ in the former situation, or exactly one of these halves in the latter.  Regardless, this leaves $(\mathbb{R}-T)$ an open interval, which is connected in $\mathbb{R}$.  So $n=1$ is reasonably clear, but general $n$ is not obvious to me.","['general-topology', 'real-analysis', 'metric-spaces', 'connectedness']"
2315431,Numerical Solution to system of ODEs coupled to a PDE,"In a nutshell:  I want to numerically (and maybe efficiently) solve a system of ODEs that are coupled to a PDE. I want to do a simulation of a pulse of light entering a collection of atoms which can be coupled by two sets of differential equations, the Maxwell-Schrodinger equations with the optical Bloch equations. The Optical-Bloch equations are a system of complex differential equations (describing how the energy levels of the atoms change as they are hit by laser light). The Maxwell-Schrodinger equations are simply the wave-equation with the approximation that the envelope varies slowly. Here is what one such system of ODEs looks like: 
\begin{align*}
\dot p_{11} &= E_p p_{13} - E_p p_{31} \\
\dot p_{12} &= E_p p_{13} - E_p p_{32} - p_{12} (\Delta_{31}-\Delta_{32}) \\
\dot p_{13} &= E_p p_{11} + E_c p_{12} - E_p p_{33} + p_{13} \Delta_{31} \\
\dot p_{21} &= E_p p_{23} - E_c p_{31} + p_{21}(-\Delta_{31} + \Delta_{32}) \\
\dot p_{22} &= E_c p_{23} - E_c p_{32} \\
\dot p_{23} &= E_p p_{21} + E_c p_{22} - E_c p_{33} + p_{23} \Delta_{31} + p_{23} (-\Delta_{31} + \Delta_{32}) \\
\dot p_{31} &= - E_p p_{11} - E_c p_{21} + E_p p_{33} - p_{31} \Delta_{31} \\
\dot p_{32} &= - E_p p_{21} - E_c p_{22} - E_c p_{33} + p_{23} \Delta_{31} + p_{23} (-\Delta_{31} + \Delta_{32}) \\
\dot p_{33} &= E_p p_{13} - E_c p_{23} + E_p p_{31} + E_c p_{32}
\end{align*} where $p_{i j}(t, z)$ represents the populations of atoms at different energy levels. The initial condition assumes $p_{11}(0, z) = 1$ and all other $p_{ij}(0, z)=0$. $\Delta_{ij}$ (for all ij) and $E_c$ are constants.  (i is the imaginary number, c is the speed of light, and k is a constant) $E_p(t, z)$ is a function of t and z, and evolves according to the PDE called the Maxwell-Schrodinger equation (it represents the laser light that is cycling the population of the atom's energy levels):
$$
\frac{\partial E_p}{\partial z } + \frac{1}{c} \frac{\partial E_p}{\partial t } = i k  p_{13}(t, z)
$$ We apply the boundary condition $E(0, t) = e^{-(t-t_0)^2} $, which implies that our wave starts as an unobstructed gaussian pulse that then enters the medium over time. Typically these solutions are solved by analytically solving them at steadystate (taking their time derivatives equal to zero and simply plugging them in). I'm interested in understanding what different methods can be used to solve such a dynamical system. (and when such methods break down). The standard method for solving the Optical Bloch Equations (the system of linear equations) is simply putting these equations in matrix form $\dot P = MP$ and then recognizing that the solution simply has the form $P_0 e^{M*t}$. With the inclusion of the slowly-varying Maxwell equation (the PDE), it's not obvious to me that there is a simple solution like before. In fact, things seem to be much more complicated, because if one tries to make the PDE into a set of ODEs, then we identify that the previous ODEs now are nonlinear ODEs since there are terms proportional to $E_p p_{13}$. Are there any obvious tricks that can be used here for finding a numerical solution? Is it necessary to rewrite the PDE as an ODE and try to numerically solve the nonlinear system of ODEs?","['numerical-methods', 'ordinary-differential-equations', 'partial-differential-equations']"
2315443,Restriction of a scheme morphism to a closed subset,"I've been working through a proof of Chevalley's theorem for the special case of morphisms of finite type between Noetherian schemes as outlined in Görtz-Wedhorn Theorems 10.19 and 10.20 on page 248. The claim of Theorem 10.19 is: If $f:X\rightarrow Y$ is a dominant morphism of finite type between Noetherian schemes, then $f(X)$ contains a dense open subset of $Y$. The first portion of the proof deals with the case where $Y$ is assumed to be irreducible, and everything seems clear to me there. However, it then continues into the case $Y$ is reducible by decomposing $Y = Y_1\cup\ldots\cup Y_n$ as a union of irreducible components (using that $Y$ is Noetherian) and then concludes by applying the previous case to the restricted morphisms $f^{-1}(Y_i)\rightarrow Y_i$. I'm concerned in that I seem to be unsure how these natural restricted maps should be defined! It's clear to me how to define the restriction of a scheme morphism to an open set using the natural open subscheme structures for the open set and its inverse image. However, I don't see a good way to do this for closed subsets. If the schemes are affine, say $X = \text{Spec}(B)$, $Y = \text{Spec}(A)$, then if $Z\subseteq Y$ is closed, the scheme $\text{Spec}(A/a)$ would have the same underlying topological space as $Z$ for some ideal $a\subseteq A$. Then $f^{-1}(Z)$ would be the underlying topological space of the scheme $\text{Spec}(B/a^e)$, where $a^e$ is the extension of $a$ by the ring homomorphism corresponding to $f$. There is an induced ring homomorphism $A/a\rightarrow B/a^e$, which corresponds to a scheme morphism $\text{Spec}(B/a^e)\rightarrow \text{Spec}(A/a)$ compatible with $f$. However, I don't see why this morphism need be dominant. Specifically, my questions are: If $f:X\rightarrow Y$ is a scheme morphism, and $Z\subseteq Y$ a closed subset, is there a canonical way to define a restricted map $f^{-1}(Z)\rightarrow Z$? Can we do this using the reduced induced closed subscheme structures of $f^{-1}(Z), Z$? If so, what would the map of sheaves look like? Finally, if such a map is defined, is it dominant and of finite type so that the proof of the theorem may use it? I apologize if these are silly questions; it feels that I'm missing something obvious. However, I haven't had any luck so far finding a reference describing this construction explicitly and as far as I can tell such restricted maps aren't mentioned earlier in G&W. This idea of restricting to a closed subset is also used in the proof of Theorem 10.20. Thanks very much!","['schemes', 'algebraic-geometry']"
2315485,Show that $\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}?$,How may we show that $$\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}\color{red}?\tag1$$ $u={x\over 2}\implies 2du=dx$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\coth(\pi u)\mathrm du\tag2$$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\cdot{e^{2u}+1\over e^{2u}-1}\mathrm du\tag3$$ $v=4u^2\implies du={dv\over 8u}$ $${1\over 2}\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot{\mathrm dv\over (1+v)^2}\tag4$$ $${1\over 2}\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot v^k \mathrm dv\tag5$$ $e^{\sqrt{v}}=t\implies dv=2\sqrt{v}e^{\sqrt{v}}dt$ $$\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{1}^{\infty}t\cdot{t+1\over t-1}\cdot \ln^{2k+1}(t) \mathrm dt\tag6$$ I don't what to do next ...,"['integration', 'calculus']"
2315487,Number of units in the ring of matrices,"I want to know about the number of units in the ring of all matrices of order $n\times n$ over the field of order $p$,
where $p$ is a prime. I read in one my book that the order of $\mathit{GL}(n,\mathbb Z_p)$ is $(p^n-1)(p^n-p)(p^n-p^2)\dots (p^n-p^{n-1})$.
I think this is the required number of units in the group $M_n(\mathbb Z_p)$.
But I can't deduce it. Also I have a question what will be the result if p is not prime i.e composite.?
Hope to get help.
Thanks. Edit: My question for prime modulus $p$ is already been discussed here. So I would like to know about the case when the modulus is composite.","['matrices', 'ring-theory', 'linear-algebra']"
2315513,Is a proper morphism between projective schemes projective morphism？,"That is if $f :P^n_ {X} \rightarrow P^m_{Y}$ is a proper morphism, then it is a projective morphism.
Projective morphism means that it factors through projective scheme of last term and the first component is a closed immersion.",['algebraic-geometry']
2315527,"Determine whether $d_s(p,q)= \sin |p-q|$ is a metric on $[0,\pi/2).$","The following problem is taken from 'Real Mathematical Analysis' by Pugh $2$nd edition, page $125,$ exercise $6.$ For $p,q \in [0,\pi/2)$ let    $$d_s(p,q)= \sin |p-q|.$$  Use your
  calculus talent to decide whether $d_s$ is a metric. My attempt: Clearly for any $p,q \in [0,\pi/2),$ $d_s(p,q) \geq 0.$ If $p=q,$ then we have $d_s(p,q) = \sin |p - p| = 0.$ If $d_s(p,q) = 0,$ then $\sin |p-q| = 0.$
As sine function is injective on $[0,\pi/2),$ we have $|p - q| = 0,$ which implies that $p = q.$ For any $p,q \in \in [0,\pi/2),$ we have $d_s(p,q) = \sin |p - q| = \sin |q - p| = d_s(q,p).$ Let $p,q,r \in [0,\pi/2).$ 
Since $d_s(p,q) = d_s(q,p),$ without loss of generality, we assume that $p \geq q \geq r.$
Observe that $$d_s(p,r) \leq d_s(p,q) + d_s(q,r)$$
$$\Leftrightarrow \sin(p-r) \leq \sin(p-q) + \sin(q-r)$$
$$\Leftrightarrow 2 \sin \left( \frac{p-r}{2} \right) \cos \left( \frac{p-r}{2} \right) \leq 2 \sin \left( \frac{p-r}{2} \right) \cos \left( \frac{p-2q +r}{2} \right)$$ 
    $$\Leftrightarrow \cos \left( \frac{p-r}{2} \right) \leq \cos \left( \frac{p- 2q + r}{2} \right)$$ 
Since cosine function is decreasing and $\frac{p-r}{2}, \frac{p-2q+r}{2} \in [0,\pi/4),$  we have
    $$\Leftrightarrow \frac{p-r}{2} \geq \frac{p-2q+r}{2}$$
    $$\Leftrightarrow q \geq r.$$
    Since the last inequality holds, we have $d_s(p,r) \leq d_s(p,q) + d_s(q,r).$ Hence, $d_s$ is a metric. I am not very sure about triangle inequality part. Can anyone check my proof? Thanks.","['real-analysis', 'trigonometry', 'proof-verification', 'metric-spaces', 'definition']"
2315531,How to show a power series is defined?,"One way I can think of is using radius of convergence. Since inside the interval of convergence, the series converges, i.e. not diverges to $\pm\infty$ For example I have $\cos x=\sum^{\infty}_{n=0}\frac{(-1)^n}{(2n)!}x^{2n}$, so $a_{2k}=\frac{(-1)^k}{(2k)!}$ when $n$ is even, then $R=\lim|\frac{a_{n}}{a_{n+1}}|=\lim (2n+2)(2n+1)=\infty$, so $\cos x$ is convergent for all real numbers and therefore defined everywhere. Is my logic correct?","['power-series', 'convergence-divergence', 'limits']"
2315542,Considering a fundamental group of $\mathbb{R}^4-\Pi_1-\Pi_2$ in terms of two-convexity,"We will consider $$ \pi_1 X,\ X:=\mathbb{R}^4-P_1-P_2$$ in terms of two-convexity notion (which will be addressed in the following question), where $$P_1=\{(x,y,0,0)\in\mathbb{R}^4\},\ P_2=\{(0,0,z,t)\in\mathbb{R}^4\}$$ are coordinate planes. Question : If $P$ is any plane in $\mathbb{R}^4$ and $c$ is a closed curve in $P\cap X$, and if $[c]$ is $0$ in $\pi_1(X)$, then $[c]$ may not be $0$ in $\pi_1(P\cap X)$. Hence $X$ is not two convex Proof : Note $\pi_1X=\pi_1(S^3-S_1-S_2)$ where $S_i$ are disjoint great circles in $S^3$. Assume that $P\cap S^3$ is a circle $c$. Nontrivial case is the case where $c$ and $S_1$ are linked. But I can not proceed any more. Thank you in advance. [Add] There is interpretation of two-convexity : If $U$ is $r$-tubular neighborhood of
 $P_1\cup P_2$, i.e. set of points whose distance from $P_1\cup P_2$
 is less than $r$, then consider $\partial U$. If we perturb
 $\partial U$, then we have a smooth 3-dimensional submanifold $S$. EXE : Two-convexity iff at most one principle curvature is negative. Rough Proof : $\Leftarrow$ : If $P$ is a plane, then $P\cap S$ is a closed curve $c=\partial D$
  where $D\subset S$ is two dimensional disk. If $c$ is not
  homologous to a point in $P\cap S$, then there are two negative
  principle curvatures on $S$.","['algebraic-topology', 'riemannian-geometry', 'differential-geometry']"
2315548,Maximization of multivariable function $ M = \frac{a+1}{a^{2}+ 2a+2} + \frac{b+1}{b^{2}+ 2b+2} + \frac{c+1}{c^{2}+ 2c+2}$ subject to constraint,"This is purely out of curiosity. I have this set of a high school entrance Math exam in Vietnam (a special high school for gifted kids, the exam was held 3 days ago, maybe 4, taking into account the time zone). Here's one question that I've been stuck with: With $a, b, c$ $\in \mathbb{R}^{+}$ such that $ab + bc + ca + abc =2$, find the max of $ M = \frac{a+1}{a^{2}+ 2a+2} + \frac{b+1}{b^{2}+ 2b+2} + \frac{c+1}{c^{2}+ 2c+2}$ I'm just curious what kind(s) of techniques these junior high students can use, since as far as I remember when I was at that age, calculus and derivatives aren't taught until high school.","['algebra-precalculus', 'substitution', 'optimization', 'sum-of-squares-method']"
2315609,Derivative of absolute value of complex-valued function,"I was wondering whether there was a nice formula for something like $$ \dfrac{\partial}{\partial x} \left| e^x + (1+i)e^{-x} \right|. $$ (Note that the function is chosen on purpose to have no discontinuities in the derivative, as the argument to the absolute value function never passes through zero.) So I typed into WolframAlpha: D[|exp(x) + (1+i)*exp(-x)|, x] and it said: Huh!? What imaginary component?","['derivatives', 'complex-numbers', 'absolute-value']"
2315624,Isomorphic image of a centre of a group,"Let $G$ and $G'$ be groups. Let $\phi: G \to G'$ be an isomorphism. Is it true that $\phi(Z(G))= Z(\phi(G))$. Let $x \in Z(G)$. Then for any $g\in G$ we have 
$\phi(x)\phi(g) = \phi(xg) = \phi(gx) = \phi(g)\phi(x)$. Hence $\phi(Z(G)) \subseteq Z(\phi(G))$ Let $x \in Z(\phi(G))$. Then $x = \phi(a)$ for some $a\in G$. For any $\phi(g) \in \phi(G)$, we have $\phi(a)\phi(g) = \phi(g)\phi(a)$. Thus $\phi(ag) = \phi(ga)$. As $\phi$ is injective $ag =ga$. Hence $a \in Z(G)$. Thus $x = \phi(a) \in \phi(Z(G))$. Is this proof correct? I'm not sure about the second inclusion","['group-theory', 'proof-verification']"
2315628,Characteristics of parallel parabola (offset curve) and the formula to find the equation,What are the characteristics of parallel parabola? And is there any formula to find the equation of parallel parabola if we know the equation of one parabola?,['functions']
2315642,Compute $\sum\limits_n(-1)^{n-1}\frac{2^{n+1}}{2^{2n}-1}$ in terms of $\sum\limits_n\frac1{2^n-1}$ and $\sum\limits_n\frac1{2^n+1}$,"Question : let  $$\sum_{n=1}^{+\infty}\dfrac{1}{2^n-1}=E,\sum_{n=1}^{+\infty}\dfrac{1}{2^n+1}=F$$ where $E,F$ are constant,(in fact,$E$ is Erdős-Borwein Constant ),Find the sum
  $$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\dfrac{2^{n+1}}{2^{2n}-1}$$ I tried this which I found in my texbook which seems relative, but Im not sure how to apply it to the problem:
$$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\left(\dfrac{1}{2^n+1}+\dfrac{1}{2^n-1}\right)=\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n-1}+\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n+1}$$ following can't try","['summation', 'sequences-and-series']"
2315666,Limit question - L'Hopital's rule doesn't seem to work,"I have been recently trying to solve this limit problem. First of all, I used L'Hopital's rule but it doesn't seem to work (because I thought that this limit is of form $\frac{\infty}{\infty}$). Am I doing it correctly? I don't seem to understand where am I wrong. $$\lim_{x \to \infty} \left(\frac{x+\sin^3x}{5x+6}\right)$$","['real-analysis', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2315673,Proof verification : $f$ is continuous at $c$ $\Leftrightarrow$ $f$ has zero-jump at $c$ for increasing $f$,"The Problem : Let $J \subseteq \mathbb{R}$ be an interval and $f : J \to \mathbb{R}$ be increasing. Define the jump at the point $c$ as follows: $j_f(c)=\lim_{x \to c+}f(x)-\lim_{x \to c-}f(x)$ if $c \in J$ is not an end-point of $J.$ $j_f(c)=\lim_{x \to c+}f(x)-f(c)$ if $c \in J$ is the left end-point of $J.$ $j_f(c)=f(c)-\lim_{x \to c-}f(x)$ if $c \in J$ is the right end-point of $J.$ To show that $f$ is continuous at $c \in J$ iff $j_f(c)=0.$ I'm attaching my solution (A few pieces of argument is marked as informal as they are similar to the previous line of argument and hence not elaborated). Please notify if there's any gap/flaws in the arguments, also whether it could be made shorter by any other technique. Any comment/suggestion regarding this proof, or maybe in general context (style of proof-writing etc), would be greatly appreciated. Thank you. My Solution : $(\Rightarrow)$ part : Suppose $c$ is not an end-point of $J$. Given $f$ is continuous at $c.$ Fix $\epsilon > 0.$ Then $\exists \delta > 0$ such that $x \in (c-\delta,c+\delta) \cap J \Rightarrow |f(x)-f(c)| < \epsilon.$ Hence $$x \in (c-\delta,c) \cap J \Rightarrow |f(x)-f(c)| < \epsilon \tag 1$$
$$x \in (c,c+\delta) \cap J \Rightarrow |f(x)-f(c)| < \epsilon \tag 2$$ Since $\epsilon > 0$ is arbitrary, we conclude from $(1)$ that $\lim_{x \to c-}f(x)=f(c)$ and from $(2)$ that $\lim_{x \to c+}f(x)=f(c).$ Hence $j_f(c)=\lim_{x \to c+}f(x)-\lim_{x \to c-}f(x)=f(c)-f(c)=0.$ Now suppose $c$ is the left end-point of $J$. Given $f$ is continuous at $c.$ Then $\exists \delta > 0$ such that $x \in (c-\delta,c+\delta) \cap J = [c,c+\delta) \cap J \Rightarrow |f(x)-f(c)| < \epsilon.$ So, $x \in (c,c+\delta) \cap J \Rightarrow |f(x)-f(c)| < \epsilon.$ Thus $\lim_{x \to c+}f(x)=f(c),$ and hence $j_f(c)=0.$ Informal : Similarly, if $c$ is the right-end point of $J,$ we obtain $j_f(c)=0.$ Note : We did not need the fact that $f$ is an increasing function to establish this side of the equivalence. $(\Leftarrow)$ part : Suppose $c$ is not an end-point of $J.$ Now $j_f(c)=0 \Leftrightarrow \lim_{x \to c-}f(x)=\lim_{x \to c+}f(x)=l$ $($let$).$ Thus $\exists \delta_1>0$ and $\delta_2>0$ such that $$x \in (c-\delta_1, c) \cap J \setminus \{c\} \Rightarrow |f(x)-l|<\epsilon$$
$$x \in (c, c+\delta_2) \cap J \setminus \{c\} \Rightarrow |f(x)-l|<\epsilon$$
Let $\delta=min\{\delta_1, \delta_2\}>0$. Then
$$x \in (c-\delta, c+\delta) \cap J \setminus \{c\} \Rightarrow |f(x)-l|<\epsilon \tag 3$$ Claim : $l=f(c).$ We prove the claim by contradiction. First we assume $l<f(c).$ Choose $\epsilon = \frac{f(c)-l}{2}>0.$ Then $\exists \delta_3>0$ such that
$x \in (c-\delta_3,c+\delta_3) \cap J \setminus \{c\} \Rightarrow |f(x)-l|<\epsilon,$ in particular $f(c+\frac{\delta_3}{2})<l+\epsilon=\frac{l+f(c)}{2}<f(c),$ which is a contradiction since $f$ is increasing. Informal : If otherwise, let $l>f(c),$ we similarly choose $\epsilon=\frac{l-f(c)}{2}>0$ and a corresponding $\delta_4>0.$ Check that $f(c-\frac{\delta_4}{2})>f(c),$ contradicting the fact that $f$ is increasing. Hence we conclude (by trichotomy law of real numbers) that $l=f(c).$ Now, putting $l=f(c)$ in $(3)$ and noting that $x=c \Rightarrow |f(x)-f(c)|=0<\epsilon,$ we obtain $$x \in (c-\delta, c+\delta) \cap J \Rightarrow |f(x)-f(c)|<\epsilon \tag 4$$ Since $\epsilon>0$ is arbitrary, we conclude that $f$ is continuous at $c.$ Now suppose $c$ is the left end-point of $J.$ Then $j_f(c)=0 \Leftrightarrow \lim_{x \to c+}f(x)=f(c),$ i.e. given $\epsilon>0, \exists \delta > 0,$ such that $x \in (c, c+\delta) \cap J \Rightarrow |f(x)-f(c)|<\epsilon.$ At $x=c,$ obviously $|f(x)-f(c)|=0<\epsilon.$ Thus $x \in (c-\delta, c+\delta) \cap J \Rightarrow |f(x)-f(c)|<\epsilon,$ and hence $f$ is continuous at $c.$ Informal : Similarly if $c$ is the right end-point of $J,$ we have $j_f(c)=0 \Rightarrow$ $f$ is continuous at $c.$ This completes the proof. $\square$","['real-analysis', 'monotone-functions', 'limits', 'proof-verification', 'continuity']"
2315693,Prove or disprove convergence of a series,"Assume  $\sum_{n=k}^{\infty} a_n$ converges.
Then $\sum_{n=k}^{\infty} a_n \cdot a_{n+2}$ converges? I think I should disprove it, because $\sum_{n=k}^{\infty} a_{n+2}$ might diverge but I can't find a disproof.","['sequences-and-series', 'convergence-divergence']"
2315801,Maximum Likelihood Estimator of two independent random variables that share a mean,"How do I find the MLE of a pair of normal variables $X = N(\bar{x}, \sigma_{X})$, $Y = N(\bar{x}, \sigma_{Y})$? I've found solutions for doing so when sigma is the common variable, but I haven't been able to follow the same process with the mean.","['statistics', 'parameter-estimation']"
2315812,Uniform integrability of Doob's process,"Let $Z,Y_0,Y_1,\cdots$ be joint random variables with $\Bbb E[|Z|]<\infty$. Doob's martingale process is defined by $X_n=\Bbb E[Z\mid Y_0,\cdots,Y_n]$ for $n\geq 0$. In Karlin and Taylor's A First Course in Stochastic Processes (p. 296), the authors prove that the martingale is uniformly integrable as follows: \begin{align*} |\Bbb E[X_nI\{X_n>c\}]|&\leq \Bbb E[I\{X_n>c\}\Bbb E[|Z|\mid Y_0,\cdots,Y_n]]\\
& \leq \Bbb E[|Z|I\{|X_n|>c\}]\\
& \leq \Bbb E[|Z|I\{U>c\}]\rightarrow 0
\end{align*}
as $c\rightarrow \infty$. (Here, $U=\sup_{k\geq 0} |X_k|$ and $I\{\cdot\}$ is the indicator function.) I understand all the steps except the second inequality; why does it hold?","['stochastic-processes', 'probability-theory', 'martingales']"
2315816,"Stability by $T$ of a sequence defined by $\ker T^r$ if spectrum(T)=$\{0,\lambda\}$","Suppose that the only eigenvalues of T are 0 and λ, where λ $\neq$ 0.
Let $W = T^r(V )$, r satisfies ker $T^r$=ker $T^{r+1}$. Show that $T(W) ⊆ W$, and that the restriction of T to W has $λ$ as its only eigenvalue. Let S denote the restriction of $(T − λI)$ to W. Show that 0 is the only eigenvalue of S. I can show $T(W) ⊆ W$, but how to show the two only eigenvalues? Can anyone give a hint?","['matrices', 'eigenvalues-eigenvectors']"
2315854,Global Injectivity Of A Multi Variable Function,"Let $f:A\subseteq \Bbb R^n\to\Bbb R^n$ be differentiable and $Df(x)$ denote the Jacobian of $f$ at $x$. If, $$Df(x)\neq 0,\;\;\;\forall x\in \Bbb R^n-------(*)$$ Then by Inverse Function Theorem we can conclude that, $\forall x \in \Bbb R^n \;\;\exists $ a neighborhood of $x$ in which $f$ is invertible, also $f$ is injective therein. My question is- Does $(*)\implies$ $f$ is injective on $A$? In general how do we check whether $f$ is injective or surjective on $A$
? Are we supposed to simply use the definitions of injectivity and surjectivity or can we make use of the values of Jacobian to conclude something?","['derivatives', 'calculus', 'jacobian']"
2315932,Injectivity and Range of a function,"Let, $A=\{(x,y)\in \Bbb R^2:x+y\neq -1\}$ Define, $f:A\to \Bbb R^2$ by $f(x,y)=\left(\displaystyle \frac{x}{1+x+y},\frac{y}{1+x+y}\right)$ $(1)$Is $f$ injective on $A$? $(2)$What is the Range of $f$? I started with $f(x,y)=f(u,v)$, then tried to show $(x,y)=(u,v)$. But I could not do it. Can someone help me out for this. Secondly for computing the range, $$\begin{align}
f(x,y)=(a,b)\\
 \implies \displaystyle \frac{x}{1+x+y}=a,\displaystyle \frac{y}{1+x+y}=b\\
\implies (1-a)x-ay=a\\
-bx+(1-b)y=b\\
\implies x=\displaystyle \frac{a}{1-(a+b)},y=\displaystyle \frac{b}{1-(a+b)}
\end{align}$$ So, $f(A)=\Bbb R^2-\{(a,b)\in \Bbb R^2:a+b=1\}$ Is the range correct? If yec can it be obtained in some other way?","['multivariable-calculus', 'analysis']"
2315943,How to evaluate $\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n}$?,Find$$\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n}$$ is there some trick in this questions. seems it must simplify to something but I am unable to solve it.,"['calculus', 'limits']"
2315961,Erdős-Kac and moments,"One way to prove  Erdős-Kac is by proving that for each non-negative integer $k$, the $k$-th moment
$$M_k(x):=
\frac{1}{x}\sum_{1 \leq n \leq x} \left(\frac{\omega(n)-\log \log x}{\sqrt{\log \log x}}\right)^k
$$ converges as $x\to+\infty$ to the $k$-th moment of the standard normal distribution. I was wondering whether the following weak converse is true, i.e. given
the Erdős-Kac theorem can we prove that $M_k(x)=O_k(1)$ without number theory arguments?","['number-theory', 'analytic-number-theory', 'prime-numbers']"
2315962,Extension of Poincaré inequality: $\|u\|_{L^2(\Omega)}\leq C\|\nabla u\|_{L^2(\Omega)}$ when $u$ vanishes in $\Gamma\subseteq\partial\Omega$.,"Recall Poincaré inequality: Let $\Omega$ be a bounded open set in $\mathbb{R}^n$. Then there is a $C=C(\Omega,n)>0$ such that  $\|u\|_{L^2(\Omega)}\leq C\|\nabla u\|_{L^2(\Omega)}$ for all $u\in C_c^1(\Omega)$ (or $u\in H_0^1(\Omega)$). I want to prove the following version: Let $\Omega$ be a bounded connected open set in $\mathbb{R}^n$ with smooth boundary $\partial\Omega$. Let $\Gamma\subseteq\partial\Omega$ be a relatively open set. Then there is a $C=C(\Omega,n,\Gamma)>0$ such that $\|u\|_{L^2(\Omega)}\leq C\|\nabla u\|_{L^2(\Omega)}$ for all $u\in C^1(\bar{\Omega})$ with $u=0$ on $\Gamma$. This can be proved by contradiction and using Rellich compactness theorem in $H^1(\Omega)$. But I am more interested on a proof giving some idea of a possible $C$ (not necessarily the optimal one, just a $C$). Here is my attempt for a convex $\Omega$. I was not able to finish the proof. Maybe the whole idea is wrong, I do not know... Given $z\in\Gamma$ and $\sigma\in \mathbb{S}^{n-1}$, let $g(r)=u^2(z+r\sigma)$ defined on $A_{z,\sigma}=\{r>0:\,z+r\sigma\in\Omega\}$. For all $\bar{r}\in A_{z,\sigma}$
$$ u^2(z+\bar{r}\sigma)=g(\bar{r})=\underbrace{g(0)}_{=0}+\int_0^{\bar{r}}g'(r)\,dr=2\int_0^{\bar{r}}u(z+r\sigma)\,\nabla u(z+r\sigma)\cdot\sigma\,dr.$$ Then $$u^2(z+\bar{r}\sigma)\leq 2\int_0^{\bar{r}}|u(z+r\sigma)|\,|\nabla u(z+r\sigma)|\,dr\leq 2\int_{A_{z,\sigma}}|u(z+r\sigma)|\,|\nabla u(z+r\sigma)|\,dr,$$ so 
\begin{align*}\int_{A_{z,\sigma}}u^2(z+r\sigma)\,dr \leq {} & 2|A_{z,\sigma}|\int_{A_{z,\sigma}}|u(z+r\sigma)|\,|\nabla u(z+r\sigma)|\,dr\\
\leq {} &  2\,\text{diam}(\Omega)\int_{A_{z,\sigma}}|u(z+r\sigma)|\,|\nabla u(z+r\sigma)|\,dr. \end{align*} Now use the well-known inequality $2ab\leq a^2/\epsilon+b^2\epsilon$ with $a=|u(z+r\sigma)|$, $b=|\nabla u(z+r\sigma)|$ and $\epsilon=2\,\text{diam}(\Omega)$, so that $$\int_{A_{z,\sigma}}u^2(z+r\sigma)\,dr\leq 4\,\text{diam}(\Omega)^2\int_{A_{z,\sigma}}|\nabla u(z+r\sigma)|^2\,dr.$$ Integrating on $\mathbb{S}^{n-1}$ with respect to $d\sigma$ and using $r^{n-1}\,dr\,d\sigma=dy$,
\begin{align*}\int_\Omega u^2(y)\,\frac{1}{|y-z|^{n-1}}\,dy= {} &\int_{\mathbb{S}^{n-1}}\int_{A_{z,\sigma}}u^2(z+r\sigma)\,dr\,d\sigma \\ \leq {} &  4\,\text{diam}(\Omega)^2\int_{\mathbb{S}^{n-1}}\int_{A_{z,\sigma}}|\nabla u(z+r\sigma)|^2\,dr\,d\sigma \\= {} & 4\,\text{diam}(\Omega)^2\int_\Omega |\nabla u(y)|^2\,\frac{1}{|y-z|^{n-1}}\,dy. \end{align*}
Since $|y-z|\leq \text{diam}(\Omega)$, $$\int_\Omega u^2(y)\,dy\leq 4\,\text{diam}(\Omega)^{n+1}\int_\Omega |\nabla u(y)|^2\,\frac{1}{|y-z|^{n-1}}\,dy,$$ for every $z\in\Gamma$. My problem : I would like to get rid of $1/|y-z|^{n-1}$. I thought of integrating on $\Gamma$ with respect to $d\sigma$ at both sides, and to bound $$\int_\Gamma \frac{1}{|y-z|^{n-1}}\,d\sigma(z).$$ If this integral were a Lebesgue integral, since $n-1<n$ we would have the boundedness of the integral. But we are dealing with a surface integral. As $\Gamma$ is relatively open and $\partial\Omega$ is smooth, there is a relatively open subset $V\subseteq\Gamma$ such that $V$ is the graph of a function $\varphi:W\subseteq\mathbb{R}^{n-1}\rightarrow\mathbb{R}$, so (denote $y=(y',y_n)$):
$$\int_V\frac{1}{|y-z|^{n-1}}\,d\sigma(z)=\int_W\frac{\sqrt{1+|\nabla \varphi(z')|^2}}{(|y'-z'|^2+|y_n-\varphi(z')|^2)^{\frac{n-1}{2}}}\,dz'\leq C\int_W \frac{1}{|y'-z'|^{n-1}}\,dz',$$ but this last integral may not be finite. EDIT : Another (unsuccessful) attempt of proof is the following, with no need of using radius $r$ or angles $\sigma$. It uses the idea of an answer below to prove that Poincaré inequality holds when the hypothesis is that the mean of the function over the domain is $0$. If $x\in\Omega$ and $z\in\Gamma$, then 
$$ u(x)=u(x)-u(z)=\int_0^1 \nabla u((1-t)z+tx)\,dt\cdot (x-z),$$ so $$|u(x)|\leq\text{diam}(\Omega) \int_0^1|\nabla u((1-t)z+tx)|\,dt,$$ and by Jensen's inequality $$u(x)^2\leq\text{diam}(\Omega)^2 \int_0^1|\nabla u((1-t)z+tx)|^2\,dt.$$ Integration over $\Gamma$ and $\Omega$,
\begin{align*}
\|u\|_{L^2(\Omega)}\leq {} & \frac{\text{diam}(\Omega)^2}{|\Gamma|}\int_{\Omega}\int_\Gamma\int_0^1 |\nabla u((1-t)z+tx)|^2\,dt\,d\sigma(z)\,dx \\
= {} & \frac{\text{diam}(\Omega)^2}{|\Gamma|}\bigg[\underbrace{\int_\Gamma\int_{1/2}^1\int_\Omega |\nabla u((1-t)z+tx)|^2\,dx\,dt\,d\sigma(z)}_{(I)} + \\
+ {} & \underbrace{\int_\Omega\int_{0}^{1/2}\int_\Gamma |\nabla u((1-t)z+tx)|^2\,d\sigma(z)\,dt\,dx}_{(II)}\bigg].\end{align*}
For (I), make the change $(1-t)z+tx=y$, $dx=dy/t^n$, so that $$(I)=|\Gamma|\left(\int_{1/2}^1 \frac{1}{t^n}\,dy\right)\|\nabla u\|_{L^2(\Omega)}^2\leq |\Gamma|2^n \|\nabla u\|_{L^2(\Omega)}^2.$$ For (II) one could try to do a similar thing, but I do not know how to make the change of variable in $\Gamma$.","['real-analysis', 'partial-differential-equations', 'surface-integrals', 'sobolev-spaces', 'vector-analysis']"
2316013,Bernoulli estimation under different parameter representation,"Suppose that $Y_1,\ldots,Y_n\stackrel{\text{iid}}{\sim} \text{Ber}(p)$. I would like to estimate $c = g(p) = (1-p)/p$. Naively one can derive 
$$\tilde{c}_\text{mle} = g(\tilde{p}_\text{mle}) = g\left(\frac{1}{n} \sum_i Y_i \right) = \frac{n-\sum_i Y_i}{\sum_i Y_i}$$
and in order for that to make any sense I set
$$\tilde{c} = \mathbf{1}_{\{\sum_i Y_i > 0\}}\frac{n-\sum_i Y_i}{\sum_i Y_i}.$$
Now I'm interested in bounding $\mathbb{E}|c-\tilde{c}|$ from above, but things like Hoeffding's Inequality don't seem to work. One other thing I was thinking about was to write out $\mathbb{E}|c-\tilde{c}|$ as a sum since $\tilde{c}$ can only be a finite amount of distinct values but I don't see this expression making it easier. Another difficulty is that $g'(p)$ isn't bounded, so approaches similar to the Delta Method won't work as well. I thought there would be a bit more literature about such issues, but I haven't managed to find any of it. Is anyone familiar with such problems? Pointers are also appreciated!","['parameter-estimation', 'statistics', 'probability-distributions']"
2316026,If $f$ is an automorphism and $|\{a: f(a) = a^{-1}\}| = 3/4 |G|$ then $G$ has an abelian subgroup of index $2$,I edited the question to remove the first part as it is already answered here. Let $G$ be a finite group and $f$ an automorphism of $G$ and $A = \{a\in G: f(a) = a^{-1}\}$ . Prove that if $|A| = 3/4 |G|$ then $G$ has an abelian subgroup of index $2$ . Here's something (very) related. Hints or solutions much appreciated.,"['finite-groups', 'abstract-algebra', 'group-theory']"
2316073,What is the cardinality of the set of all ultrafilters containing a Fréchet filter?,"Let $\mathfrak{F}$ be the Fréchet filter on an infinite set $X$. $~$What is the cardinality of the set of all ultrafilters containing $\mathfrak{F}\,$? $~$Is it equal to the cardinality $2^{2^{|X|}}$ of the set of all ultrafilters on the set $X\,$?","['filters', 'cardinals', 'elementary-set-theory']"
2316145,differential equation with linear coefficients other answer than in book,"I have a differential equation:
$$ (x+2y-4)dx +(-2x+4y)dy = 0 $$ Since the coefficients of $dx$ and $dy$ are assumed to define line in the plain, so: $$ 7y -3 = 0 $$
$$ 2x+1 = 0 $$ Point od the intersection of these lines is:$ (x,y) = (2,1)  $ Next, I'm trying to move origin of the plain to the intesection point. We know that relations between coordinates are: $$ x = \bar{x} +2  $$
$$ y = \bar{y} +1 $$ where  $\bar{x}$, $\bar{y}$ are coordinates measured from point $ (2,1)$ After substitution these relations, equation simplifices to form: $$ (\bar{x} + 2 \bar{y})d\bar{x} + (-2\bar{x}+4\bar{y})d\bar{y} =0  $$ Now I'm trying to do substitution: $$ \bar{x} = u \bar{y}, d\bar{x} = u d\bar{y} + \bar{y}du $$ So after substitution and simplifications I'm obtaining: $$ (u^{2} + 4) \bar{y}d\bar{y} + (u+2)\bar{y}^2 du  = 0$$ Now, I'm dividing equation both sides by $(u^2+4)(\bar{y}^2)$ and I'm obtaining equation with separable variables: $$ \frac{d\bar{y}}{\bar{y}} + \frac{u+2}{u^2+4}du = 0 $$ Because: 
$$ \int \frac{u+2}{u^2+4} = arctan(\frac{u}{2}) + \frac{1}{2} ln|4+u^2| + C$$ So, I have a solution: $$ ln|\bar{y}| + arctan(\frac{u}{2})+ \frac{1}{2}ln|(4+u^2)| = C  $$ After substitution relationship between $\bar{x},x$ and $\bar{y},y$ and simplifications, I'm obtaining: $$   ln|4(y-1)^{2} + (x-2)^2| + 2 arctan(\frac{x-2}{2y-2}) = C  $$ Now I have a problem because answer from book to this exercise is: $$   ln|4(y-1)^{2} + (x-2)^2| -2  arctan(\frac{2y-2}{x-2})+= C  $$ I've check that this solutions we may obtain with substitution: $$ \bar{y} = u\bar{x}, d\bar{y} = u d \bar{x} + \bar{x}du $$ Is my answer wrong?
I would be grateful for explaining.
Best regards","['homogeneous-equation', 'ordinary-differential-equations']"
2316148,Limit of simple functions,"I'm studying measure theory this semester and my professor put this question on the exam. I didn't know even how to start it, can someone give me a hint? Let $(X,\mathcal{B}, \mu)$ be a measure space and $f: X \rightarrow \overline{\mathbb{R}}$ a positive measurable function. Consider $(a_n)_{n \in \mathbb{N}}$ a sequence of positive real numbers such that $a_n \rightarrow 0$ and $\sum_{n=1}^\infty a_n = \infty$. So there exists $\{A_n\}_{n \in \mathbb{N}} \in \mathcal{B}$ such that \begin{equation}
f(x) = \sum_{n=1}^\infty a_n\chi_{A_n} \;\;\; \forall x \in X
\end{equation}","['real-analysis', 'measure-theory']"
2316166,"Compute the conditional expectation $E(X^2|XY)$ when $(X,Y)$ is standard normal","Let $(X,Y)$ be a 2-dimensional standard normal random vector. Is there a specific trick to compute $E(X^2|XY)$?","['probability-theory', 'conditional-expectation', 'normal-distribution']"
2316185,Example of a Covariance Matrix?,"Can someone provide an example of a covariance matrix for any set of data? For example, if given: 2 3 4 5 1 8 9 7 6 how would I take this 3x3 matrix and convert it to the covariance matrix? I see the formula involves taking the means, but I'm not quite sure how that works in this case...","['matrices', 'statistics', 'covariance']"
2316190,Behaviour of a function at 0,"Given a function $g:(0,1) \to (0,\infty)$ such that $\lim\limits_{x \to 0}{\frac{g(x)-1}{x}}=0$, I try to show that this implies $\lim\limits_{k\to\infty}{g(x2^{-k})^{2k}}=1$. Using Taylor-Expansion is no alternative, since I don't know anything about differentiability . I've tried using $ g(x)=o(x)+1$ and applying the logarithm as well as rewriting $g(x2^{-k})$ by adding ones, but it doesn't quite work out. Does anyone know some easy trick to show this?","['stochastic-analysis', 'analysis']"
