question_id,title,body,tags
1295542,Show the following including triple statement,"How do I show \begin{equation*}
\sum \limits_{n=0}^{\infty} z^n=\prod \limits_{m=0}^{\infty}(1+ z^{2^m}) = (1-z)^{-1}?
\end{equation*} The very left side is obvious because it is the geometric series,but I could not relate the middle one.",['number-theory']
1295552,How to avoid stupid mistakes in calculus exams without checking the whole process?,"Few days ago I failed my Calculus exams. And again it was mostly due to simple mistakes such as forgetting about minus in front of fraction, switching y coordinates of two points etc. The assignments are pretty simple, for example calculating area defined by N curves or analyzing a function. But we have only ten minutes for each, so there is almost no time left to check the results. My question is: How to avoid such mistakes without checking everything?","['arithmetic', 'calculus', 'soft-question']"
1295572,Elementary question in Group Theory with less prerequisite,"Here I am posing a problem, which my beginning students of algebra were discussing for long time. Question: Without using theorem of Cauchy or Sylow, can we show that a group of order $15$ contains elements of order $3$ and $5$? One can use Lagrange's theorem here. I know the solution using Cauchy theorem. But these things I have not yet taught in the class.",['group-theory']
1295586,Find the range of a $4$th-degree function,"For the function $y=(x-1)(x-2)(x-3)(x-4)$, I see graphically that the range is $\ge-1$.  But I cannot find a way to determine the range algebraically?",['algebra-precalculus']
1295591,"Can a field extension still have ""non-separability"" above its maximal purely inseparable subextension?","Question 1 Let $E/F$ be an algebraic field extension. Let $K$ be the set of all elements of $E$ that are purely inseparable over $F$ . Then, $E/K/F$ is a tower of fields, and $K/F$ is purely inseparable. In this case, is $E/K$ always separable? If not, what is a counterexample? Moreover, let $K^s$ and $F^s$ be the separable closures in $E$ . Then, $E/K^s$ is purely inseparable. How different are $K^s$ and $F^s$ as fields? That is, how much nicer is the extension $K^s/K$ compared to $F^s/F$ ? Question 2 Let $E/F$ be a normal field extension. Let $E^G$ denote the fixed field of $\operatorname{Aut}(E/F)$ . Then, $E/E^G$ is separable and $E^G/F$ is purely inseperable. Is $E^G$ the unique such subextension? That is, is there a subextension $K$ of $F$ such that $E/K$ is separable and $K/F$ is purely inseparable, but $K\neq E^G$ ?","['extension-field', 'field-theory', 'abstract-algebra', 'separable-extension', 'examples-counterexamples']"
1295628,Probability when cutting the stick twice,"Given a stick of length $l$. We cut the stick twice. Let $X$ be the random variable defined by the length of the stick after the first cut, and $Y$ be the random variable defined by the length of the stick after the second cut. What is the probability for $Y>\frac{l}{4}$? First, the PDF of $X$ is uniform, thus $f_{X}(x)=\frac{1}{l}$ (since $0\le X\le l$). $Y$ is uniform in $[0,X]$, then $f_{Y|X}(y|x)=\frac{1}{x}$. Then the probability of $Y>\frac{l}{4}$ is $$\int_{l/4}^{x}\frac{1}{x}dy=1-\frac{l}{4x}$$ On the other hand, we have $$f_{X,Y}=f_Xf_{Y|X}=\frac{1}{lx}$$ 
We write the probability of $Y>\frac{l}{4}$ as follow: $$P\left(\frac{l}{4}<Y<x|\frac{l}{4}\le X \le l\right)=\frac{P(l/4<Y<x,l/4\le X \le l)}{P(l/4\le X\le l)}=\frac{\int_{l/4}^{x}\int_{l/4}^{l} \frac{1}{lx}dxdy}{\frac{1}{l}}$$ which leads to a different result from $1-\frac{l}{4x}$. My question is which of the solution is correct, and what's wrong with the incorrect solution? Thanks in advance.",['probability']
1295637,multivariate convergence in distribution for Skorohod topology,"If $X_n$ is a $R^d$-valued sequence of stochastic processes and $X$ is a $R^d$-valued the limiting process, all having Cadlag paths. I know what it means by
$X_n \Rightarrow X$,
i.e. $X_n$ converges weakly to $X$ in Skorohod topology. However, if $Y$ is another a $R^m$-valued stochastic process, how should I understand the convergence
$(Y,X_n) \Rightarrow (Y,X)$? By definition, it should mean that the joint law of $(Y,X_n)$ weakly converges
to the joint law $(Y,X)$ in the space $\mathbb{D}^{m\times d }$. But one should note that it's well known that $\mathbb{D}^m \times \mathbb{D}^d$ is not topologically the same as $\mathbb{D}^{m\times d }$.","['probability-theory', 'weak-convergence']"
1295638,Understanding why $a+b\sqrt {2}\neq \sqrt {3} $,"I want to intuitively understand why $a+b\sqrt {2}\neq \sqrt {3} $ for $a, b \in \mathbb Q $ I really have no intuition regarding this matter, and have to deal with similar concepts regularly while studying field extensions. Please do not give algebraic proofs like the squaring of both sides and arriving upon a contradiction. I'm looking for something that involves logic/geometry/anything else that would hone my intuition in such matters.","['intuition', 'algebra-precalculus']"
1295663,weird trig problem $\tan(\theta)=-\sqrt{2}\sin(\theta)$ on the interval $0 \leq \theta \leq 2\pi$,"$\tan(\theta)=-\sqrt{2}\sin(\theta)$ on the interval $0 \leq \theta \lt 2\pi$ I  started off with  $[(\sin(\theta)/\cos(\theta)] \times (1/\sin(\theta) )= - \sqrt 2$, then after simplification i got $(1/\cos(\theta))=-\sqrt 2$ and then i've got $$\cos(\theta)= -(\sqrt{2}/2)$$ and   i got $\theta = 3\pi/4,5\pi/4$ but the right answer is  $\theta=0,\pi,3\pi/4,5\pi/4$. I do not understand where did $0$ and $\pi$ came from? I mean at $0$ and $\pi$ $\theta$ is not equal to $-\sqrt{2}/2$ why is then $0$ and $\pi$ included?? I would appreciate if you could explain that.","['trigonometric-series', 'algebra-precalculus', 'trigonometry']"
1295701,Understanding a step in Yi Fang's Lectures on Minimal Surfaces,"In Yi Fang's Lectures on Minimal Surfaces, page $94$, there's a step that I didn't understand, and that perhaps is wrong. I'll estabilish some notation first. We have that $X$ is a minimal surface, $X(t)$ is a variation (understand here that $X(0) = X$), $g_{ij}(t)$ is the first fundamental form, $g^{ij}(t)$ is its inverse, and $h_{ij}(t)$ is the second fundamental form. We have the variational field $$E(t) = \frac{\partial X(t)}{\partial t},$$ and $E(0) \equiv E = \alpha X_1 + \beta X_2 + \gamma N$. We also assume isothermal coordinates $g_{ij} = \Lambda^2 \delta_{ij}$. This implies that $g^{ij} = \Lambda^{-2}\delta_{ij}$. He states that: $$\frac{{\rm d}g^{ij}(t)}{{\rm d}t}\Bigg|_{t=0} = -\Lambda^{-4}(E_i \cdot X_j + E_j \cdot X_i),$$ ok. Then he says: Using $h_{11} = -h_{22}$ and $X_{11}\cdot X_1 = \frac{1}{2}\Lambda_1^2$, $X_{11}\cdot X_2 = -\frac{1}{2}\Lambda_2^2$, etc, we have: $$\frac{1}{2}\sum_{i,j}\frac{{\rm d}g^{ij}(t)}{{\rm d}t}\Bigg|_{t=0}h_{ij} = \gamma \Lambda^{-4}\sum_{i,j}h_{ij}^2 - \Lambda^{-2}(\alpha_1h_{11}+(\alpha_2+\beta_1)h_{12}+\beta_2h_{22})$$ I just don't follow that. We could say that: $$X_1 \cdot X_1 = \Lambda^2 \implies 2 X_{11}\cdot X_1 = 2\Lambda_1\Lambda \implies X_{11}\cdot X_1 = \Lambda_1\Lambda,$$ and I don't see how he got that expression. Can someone explain to me how to get the highlighted expression please? If you need me to explain some more of the notation please say it.","['differential-geometry', 'minimal-surfaces', 'multivariable-calculus']"
1295703,Origin of the term dual space?,"Basically, why is a dual vector space called as such? Is the reason for the term ""dual"" simply because the two vector spaces are related by a one-to-one mapping, or is there something more to it? Sorry for such a basic question, but I've never been able to find a definitive answer so far.","['terminology', 'linear-algebra']"
1295732,"If $f$ and $g$ are both functions from $X$ to $X$ and $f\circ g$ is the identity function, does $g\circ f$ also have to be the identity map?","If $f$ and $g$ are both functions from the set $X$ to $X$ and $f\circ g$ is the identity function, does $g\circ f$ also have to be the identity map? How (if at all) does your answer change if $X$ is finite? I know I probably have to do some reasoning involving injective/surjective functions but I am struggling to picture what's going on.",['functions']
1295751,Proof of an identity of $n!$,"I came up (numerically) with an identity concerning n! and I was wondering about a proof of it. Here it is: \begin{align}
  \ n! &= \sum_{r=0}^{n} { \binom{n}{r} (-1)^r(k-r)^n  } \quad \forall n \in  \mathbb{Z}^+ \quad \forall k \in \mathbb{R} \\\\
\end{align}
(one line edit) I apologise for first accidentally writing $(-n)^n$ instead of $(-r)^n$, as I should have. For simplicity, k can be set to 0 to yield: \begin{align}
  \ n! &= \sum_{r=0}^{n} { \binom{n}{r} (-1)^r(-r)^n  } \\\\
\end{align} I derived this equation based on that it seems to be the case that nth difference of a polynomial in the form \begin{align} y &= x^n \end{align} always ends up being n!. The origin of k is that it is the initial position from which I started taking the difference, but I left in as I thought it interesting that it cancels out completely. I know Calculus suggests it, but is there a way to prove it without calculus (my goal was to do it while keeping the difference in x constant, ie (x+d)^n - x^n, where d stays 1 preferrably)? So far my attempts yield nested sums. I am not anything close to a mathematician, so I apologise if this is extremely trivial. Thank you.","['summation', 'polynomials', 'combinatorics', 'finite-differences', 'factorial']"
1295763,how to show that all solutions tend to zero?,"Here is our nonlinear first order ode:
\begin{equation*}
y'(t) +2y(t)+y^3(t)=e^{-t} .
\end{equation*}
We want to show that all solutions tend to zero as $t$ goes to infinity. Attempt:
Multiply both side by $y$. Then we will have:
\begin{equation*}
(1/2)(y^2)'=-2y^2-y^4+ye^{-t}, \\
(1/2)(y^2)'\le ye^{-t}.
\end{equation*}
After this, I think Grönwall's inequality may help but we are not sure of $y\le y^2$. If this was the case:
\begin{equation*}
(1/2)(y^2)'\le y^2e^{-t}
\end{equation*}
then by Grönwall: $y=0$. However $y=0$ also does not satisfy the ode anyway.",['ordinary-differential-equations']
1295789,Probabilistic interpretation for representation of unity using the zeta function,"There's a cute identity, I believe due to Borwein, Bradley and Crandall (Section 4): $$1=\sum_{n=2}^\infty (\zeta(n)-1).$$ There are some generalizations in the linked paper as well. Question: Is there an interesting probabilistic interpretation of this that comes up somewhere? In other words, a random variable $X$ such that $P(X=n)=\zeta(n)-1$, for $n\geq 2$. Note that $\zeta(n)>1$ for all $n>1$, and $0<\zeta(n)-1<1$ for all $n\geq 2$.","['probability-theory', 'probability', 'real-analysis', 'riemann-zeta']"
1295795,Are closed simple curves with that property necessarily circles?,"This is a more interesting follow-up to the question Are closed simple curves with this property necessarily circles? Let $\gamma:[0,1]\to \mathbb R^2 $ be a closed simple $C^1$ convex curve and $\Gamma$ be the region enclosed by $\gamma$ . Let $O$ be the center of mass of $\Gamma$ . Suppose that any two perpendicular lines that go through $O$ split $\gamma$ into four regions with equal areas. Is $\gamma$ a circle ? Again, I'd say the answer is yes, but I'm looking for a rigorous proof.","['plane-curves', 'geometry', 'area', 'differential-geometry']"
1295842,Unit ball separable $\Longrightarrow$ Space separable,"Given a normed space $X$ and assume it is also a locally convex space in some other topology (e.g. weak or weak* if it's a dual). Assume that the unit ball $B_X$ is separable in this topology. Is it then true that the $X$ is separable in this topology? I think that this is true. Let $D\subset B_X$ be dense. Then $\bigcup_{n\in\mathbb{N}} n D $ is dense in $X$, right? My attempt for the proof: Given $x\in X$, then $\frac{1}{N} x \in B_X$ for some $N$ large enough. Now there exists a sequence $(y_n)_n \subset D$ such that $y_n \to \frac{1}{N}x$ as $n\to\infty$. Hence $N y_n \to x$ and clearly $Ny_n \in N D$. Remark: In my definition of a LCS, the topology is also Hausdorff.","['weak-convergence', 'banach-spaces', 'functional-analysis', 'normed-spaces']"
1295853,How do I calculate $\lim_{n \to \infty} n^\frac{1}{n} (n+1)^\frac{1}{n+1} ...... (2n)^\frac{1}{2n}$,"How do I calculate the limit of the following sequence?
 $$\lim_{n \to \infty} n^{\frac{1}{n}} (n+1)^\frac{1}{n+1} ...... (2n)^\frac{1}{2n}$$","['sequences-and-series', 'calculus', 'real-analysis']"
1295858,Ratios and percents,"Mrs. Smith has 80 birds: geese, hens and ducks.
The ratio of geese to hens is 1:3. 
60% of the birds are ducks. How many geese does Mrs. Smith have? a) 16
b) 8
c) 12
d) 11 I know that if 60% if the birds are ducks, 40% are geese and hens. Now I have to find 40% of 80 so in order to do this I change 40% into a decimal, which is 0.4, and then multiply this by 80. The result of this is 32 which means there are 32 birds not including the ducks. I am sure I got this part of the question correct but after this I am not sure what to do. I started off by creating a chart because for every one geese there are three hens, so for every two geese there are six hens (multiples of three) and so on. Since this does not go evenly into 32, I know I am probably doing something wrong. I was told the answer is 8 but I do not understand why. I just know you add the 1 and the 3 and then divide this by 32 which gives you 8, but why do you do this? I understand it now. Thanks.","['ratio', 'algebra-precalculus']"
1295861,Show $f(z)$ can be analytically continued and $F(z+4)=F(z)$ for resulting entire function,"I'm working on some past qualifying exam problems in complex analysis and I'm quite stuck on this one: Let $f(z)$ be analytic in $\{z\in\mathbb{C}\,:\,|\text{Re }z|<1\}$ and continuous on the closure of that domain. Suppose that $f(z)$ is real on the lines $\text{Re }z=\pm 1$. Prove that then $f(z)$ can be analytically continued to the whole plane and that the resulting entire function satisfies $F(z+4)=F(z)$ for all $z\in\mathbb{C}$. Here are my thoughts: the problem is clearly (I think) calling for the Schwarz Reflection
Principle but I don't quite see how the $F(z+4)=F(z)$ comes out. I assume it will have to do since it can be infinitely reflected left and right throughout the plane, With my understanding of the Schwarz reflection principle, I believe $f$ would extend to $\{z\in\mathbb{C}\,:\,-1<\text{Re }z<3\}$ with $\overline{F(\overline{1-z}+1)}=F(z)$ (since $z\mapsto \overline{1-z}+1$ is the reflection about the line $\text{Re }z=1$ and $z\mapsto\overline{z}$ is the usual reflection about the real axis) TL;DR I understand how it can be analytically continued to an entire function, just not that the resulting entire function satisfies $F(z+4)=F(z)$. Any help is greatly appreciated. Thanks in advance.",['complex-analysis']
1295866,Sum of F Ratio distributed random variables,"Where $X$ follows an F Ratio distribution F$(1,\alpha)$ with pdf:
$$
f(x)= \frac{\alpha ^{\alpha /2} (\alpha +x)^{\frac{1}{2} (-\alpha -1)}}{\sqrt{x} B\left(\frac{1}{2},\frac{\alpha }{2}\right)},\;  x\in [0,\infty).$$
Looking for the distribution of the $n$-summed independent F Ratio-distributed variables $Y= \sum_{1 \leq i \leq n}X_i$, with $\alpha>2$.
I tried to work with the $n$-convoluted characteristic function:
$$\chi_n(t)=\left( \frac{\Gamma \left(\frac{\alpha +1}{2}\right) U\left(\frac{1}{2},1-\frac{\alpha }{2},-i t \alpha \right)}{\Gamma \left(\frac{\alpha }{2}\right)}\right)^n$$ 
(where $U(.,.,.)$ is the confluent hypergeometric function with integral representation $U(a,b,z)=\frac{1}{a \Gamma }\int _0^{\infty } t^{a-1} (t+1)^{-a+b-1} e^{t (-z)} \mathrm{d} t$ ) and was unable to go anywhere. I can pull the moments from $\chi(t)$ (which turn out to be rapidly infinite at higher orders) but I am interested in the density. With gratitude.","['probability-theory', 'probability-distributions', 'characteristic-functions', 'integration', 'hypergeometric-function']"
1295900,How to determine generalized eigenvectors of $\begin {bmatrix} 2 & 1 & 0 & 0 \\ 0 & 2 & 0 & 0 \\ 0 & 0 & 2 &1 \\ 0 & 0 & 0 & 2 \end{bmatrix}$,"I want to calculate the general solution of this DE-system: $$ \frac{d \vec x}{d t}= A \vec x,\text{ with }A = \begin {bmatrix} 2 & 1 & 0 & 0 \\ 0 & 2 & 0 & 0 \\ 0 & 0 & 2 &1 \\ 0 & 0 & 0 & 2 \end{bmatrix}$$ $\lambda=2$ is eigenvalue with algebraic multiplicity $4$. Calculating Eigenvectors: $$\begin {bmatrix} 2-2 & 1 & 0 & 0 \\ 0 & 2-2 & 0 & 0 \\ 0 & 0 & 2-2 &1 \\ 0 & 0 & 0 & 2-2 \end{bmatrix} = \begin {bmatrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 &1 \\ 0 & 0 & 0 & 0 \end{bmatrix}$$ So eigenvectors are obviously $$\vec v_1 = \begin {bmatrix} 1  \\ 0 \\ 0 \\ 0 \end{bmatrix}\text{ and }\vec v_2= \begin {bmatrix} 0  \\ 0 \\ 1 \\ 0 \end{bmatrix}.$$ My question is, how to calculate generalized eigenvectors $\vec v_3$ and $\vec v_4$  in this case. Would it be correct, to solve the following to two linear system? (1) $(A-\lambda I)\vec v_3 = \vec v_1$ (2) $(A-\lambda I)\vec v_4 = \vec v_2$","['eigenvalues-eigenvectors', 'ordinary-differential-equations']"
1295901,"In $\mathbb Q_p$, proving every open ball is the disjoint union of more than one open ball","I'm reading the Foundations chapter of Gouvea's p-adic Numbers: An Introduction , and I'm trying to solve the following problem he poses to the reader: Take the $p-$adic absolute value on $\mathbb Q$. Show that with respect to this absolute value, every open ball is the disjoint union of [more than one open ball]. In the hints, he suggests that the reader use ""scaling and translating"" of results from earlier problems about $\mathbb Q_p$: First, the problem of showing that the closed ball $\overline B(0,1)$ is the disjoint union of open balls
$$
\overline B(0,1) = B(0,1)\cup B(1,1)\cup B(2,1)\cup \cdots\cup B(p-1,1),
$$
and second, the problem of showing that the open ball of radius $1$ about $0$ is equivalent to the closed ball of radius $1/p$ about $0$. The first problem can be solved by supposing $x\in \overline B(0,1)$, noting that in lowest terms $x = a/b$ with $p\nmid b$, and then showing that the terms
$$
a, a-b, a-2b, \ldots, a-(p-1)b
$$
are all unequal modulo $p$. The second problem can be solved simply by noting that the $p-$adic absolute value can only take values of the form $p^n$, $n\in\mathbb Z$, and thus there are no elements of $\mathbb Q_p$ with absolute values strictly between $1/p$ and $1$. What I'm having trouble doing is ""scaling and translating"" the above two solutions to the general cases required to solve the present problem. My work so far for each part is as follows: For the first part: Let $x\in \overline B(x_0, \varepsilon)$. Then $|x-x_0| \leq \varepsilon$. Write $x-x_0$ in lowest terms as $a/b$ and suppose that the $p-$adic valuation $v_p(a/b)\geq 0$, so that $p\nmid b$. Now consider the $p$ terms
$$
a, a-b, a-2b, \ldots, a-(p-1)b.
$$
If any pair of these were congruent modulo $p$, then we would have their difference being divisible by $p$, so $p|(kb)$ where $0 < k < p$, and then $p|b$, a contradiction. Thus, $p$ divides precisely one of these terms, $a - jb$. Then $v_p(\frac{a-jb}{b}) > 0$, so $|\frac{a-jb}{b}| < 1$, that is, $|\frac{a}{b} - j| < 1$, so $x-x_0 = a/b \in B(j,1)$. However, I think I'm supposed to end up with $x$ being in some sort of open ball, rather than $x-x_0$ being in the open ball, so I'm stuck. I am intending to look at the case of $v_p(a/b) < 0$ separately, once I get past this point. For the second part, I know that given $B(x_0,\varepsilon)$, if I let $n$ be the largest integer strictly less than $\log_p \varepsilon$, then $\overline B(x_0, p^n) = B(x_0,\varepsilon)$, and then since every closed ball is the disjoint union of open balls from the preceding part, I am done.","['p-adic-number-theory', 'metric-spaces', 'general-topology']"
1295905,Is parallel transport injective?,"For a vector bundle $E\to X$ with a given connection $\nabla$. We say that a section $s$ of $E$ is parallel to a vector space $V$ if $\nabla_V s=0$. If $\gamma:[0,1]\to X$ is a smooth path, we say that $s$ is a parallel transport of $v$ along $\gamma$ provided that $s(\gamma(0))=v$ and $\nabla_{\dot{\gamma}}s=0$ (to be precise, one considers an extension of $\dot{\gamma}$ to a local vector field). When $E$ has a metric and $\nabla$ is compatible with this metric, then the metric compatibility definition implies that parallel transport defines an isometry (abusing notation a bit, metric compatibility gives $d/dt\langle s_1,s_2 \rangle=\langle \nabla_{t}s_1,s_2\rangle + \langle s_1,  \nabla_{t}s_2\rangle = 0$ along $\gamma$ for parallel sections). But if we do not have a metric. Can we prove that parallel transport is an injective map?",['differential-geometry']
1295917,"Differential Equations: Stable, Semi-Stable, and Unstable","I am trying to identify the stable, unstable, and semistable critical points for the following differential equation: $\dfrac{dy}{dt} = 4y^2 (4 - y^2)$. If I understand the definition of stable and unstable critical points, then it seems to me that the semi-stable point is at $y = 0$ since in a neighborhood around $y=0$ we have the slope as positive. It also seems that $y = -2,2$ is a stable critical point since points around its neighborhood are negative for decreasing values and positive for increasing values. So it appears there are no unstable critical points. Am I on the right track here? I also need to find $k$ for $y(t) \rightarrow k$ given $y(0) = 1.4$ and $k$ for $y(t) \rightarrow k$ given $y(0) = -3.2$. Any help anyone can provide is appreciated.",['ordinary-differential-equations']
1295926,Trigonometric equation $\sec(3\theta/2) = -2$ - brain dead,"Find $\theta$ with $\sec(3\theta/2)=-2$ on the interval $[0, 2\pi]$. I started off with $\cos(3 \theta/2)=-1/2$, thus $3\theta/2 = 2\pi/3$, but I don't know what to do afterwards, the answer should be a huge list of $\theta$s, which I cannot seem to get.","['algebra-precalculus', 'trigonometry']"
1295950,Reflect on y axis in 3D Matrix?,"I have a question saying ""Define a 3D Matrix that performs a reflection in the y axis"" but I don't know how to solve it. So if we have a 2D matrix and we say 'reflection on the y axis' we mean that x becomes -x. So a point (x,y) will be (-x, y). But what about in 3D? If we are reflecting on y, are both x and z negated? I tried to look for solutions and found this website http://www.idomaths.com/linear_transformation_3d.php on which I can see it's talking about xy, xz and yz planes. Does 'reflect on the y axis' mean the same thing as 'reflect against the xz plane'? Thanks","['linear-transformations', 'linear-algebra', 'matrices']"
1295951,Verify solution to ODE,"I am given the ODE $$\left(f''(x)+\frac{f'(x)}{x} \right) \left(1+f'(x)^2 \right) = f'(x)^2f''(x)$$ and I already know that the solution to this ODE is given by
$$f(x)= c  \cdot arcosh \left( \frac{r}{c} \right) + d$$
where $|c|<r$ and $d \in \mathbb{R}.$ The problem is I want to show that this is an actual solution by direct integration (so I want to derive it) and not just verify it by plugging it in. Does anybody know how this can be done? After rearraging as Daniel Fischer proposed, I end up with $$f''(r) = -\frac{(f'(r)^3+f'(r))}{r}$$","['analysis', 'real-analysis', 'ordinary-differential-equations', 'integration']"
1295967,"Is there a ""ping-pong lemma proof"" that $\langle x \mapsto x+1,x \mapsto x^3 \rangle$ is a free group of rank 2?","Let $f,g\colon \mathbb R \to \mathbb R$ be the permutations defined by $f\colon x \mapsto x+1$ and $g\colon x \mapsto x^3$, or maybe even have $g\colon x \mapsto x^p$, $p$ an odd prime. In the book, by Pierre de la Harpe, Topics in Geometric Group Theory section $\textrm{II.B.40}$, as a research problem, it asks to find an appropriate ""ping-pong"" action to show that the group, under function composition, $G=\langle f,g \rangle$  is a free group of rank two. Is there such a proof? That is, is there a proof where the key insight is having that group act in such a way to apply the ping-pong lemma(table-tennis lemma)? I have not been able to find such a proof either by working on it, or in the literature. Maybe we don't have such a proof but do we have a proof that $G$ contains a free subgroup of rank two, akin to proofs for torsion-free hyperbolic group , or the Tits alternative . I am not sure how obvious it is that $G$ is hyperbolic, or linear. I am guessing it is not obvious that it is linear since I would suspect a ping-pong proof would come out of that pretty quickly. Note that there are proofs of this theorem, but as far as I know, they do not use the ping-pong lemma. The only proofs of the result(and more general things) I know of are in : Free groups from fields by Stephen D. Cohen and A.M.W. Glass The group generated by $x \mapsto x+1$ and $x \mapsto x^p$ is free. by Samuel White Arithmetic permutations by S.A. Adeleke and A.M.W. Glass","['group-theory', 'group-actions', 'geometric-group-theory', 'reference-request']"
1295973,How can I calculate $\lim_{n \to \infty} (1 + \frac{1}{n!})^n$ and $\lim_{n \to \infty} (1 + \frac{1}{n!})^{n^n}$?,"How do you calculate the following limits? $$\lim_{n \to \infty} \left(1 + \frac{1}{n!}\right)^n$$ $$\lim_{n \to \infty} \left(1
 + \frac{1}{n!}\right)^{n^n}.$$ I really don't have any clue about how to proceed: I know the famous limit that defines $e$ ($\lim_{n \to \infty} \left(1 + \frac{1}{n}\right)^n=e$), but the factorials (and the exponent of the second one) here throw me off. Any ideas?","['calculus', 'limits', 'real-analysis', 'exponential-function', 'sequences-and-series']"
1295977,Square roots of Complex Number. [duplicate],"This question already has answers here : How do I get the square root of a complex number? (13 answers) Closed 9 years ago . Calculate, in the form $a+ib$, where $a,b\in \Bbb R$, the square roots of $16-30i$. My attempt with $(a+ib)^2 =16-30i$ makes me get $a^2+b^2=16$ and $2ab=−30$. Is this correct?","['complex-numbers', 'algebra-precalculus']"
1295986,Is the Cartesian product of two uncountable sets uncountable? [duplicate],"This question already has answers here : Is the set of all pairs of real numbers uncountable? (2 answers) Closed 9 years ago . Is Cartesian product of two uncountable sets uncountable?
Suppose we have a set of real numbers $R$, Can't it be shown that $R$ is uncountable by Cantor's diagonalization method, so it follows that the Cartesian product of two sets of real numbers in uncountable?",['elementary-set-theory']
1296049,About negligible terms in a limit,"When is it valid to deal with a term as a ""negligible"" one in a limit? I am asking this question because I usually do not take limits very seriously, and I can do a lot of ""illegal"" moves just to evaluate and get back to the important thing. This is a very broad question, that is why I'll just give two examples and ask about them instead. Example $1$: $$\lim_{n \to \infty} \frac{e^n + n^{2015} + 1}{e^\sqrt{n^2 + \sin(n) + \ln(n)}}$$ I would usually say: the numerator is asymptotic to $e^n$, and the denominator is as well, because $n^2 + \sin(n) + \ln(n)$ is asymptotic to $n^2$. The limit eventually becomes $1$. Had I done an invalid move? Example $2.1$: $$\lim_{n \to \infty} \frac{n+1}{n} \times |x|^{n} = \lim_{n \to \infty} |x|^{n}$$ Example $2.2$: $$\lim_{n \to 0} \frac{n + 1}{n + 2} \times \frac{\ln(n)}{e^n} = \frac12 \lim_{n \to 0} \frac{\ln(n)}{e^n}$$ Was my writing in $2.1$ and $2.2$ valid? Please elaborate, and if possible, warn me about some common misconceptions regarding these things. Thanks a lot.",['limits']
1296054,"Prove $ \lim\limits_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x) \, dx $ [duplicate]","This question already has answers here : Putnam 1967 problem, integration (3 answers) Closed 9 years ago . Let $f$ and $g$ be a real valued continuous functions on $\mathbb{R}$ such that $f(x+1)=f(x)$ and $g(x+1)=g(x)$ for all $x\in \mathbb{R}$. Prove that
$$
\lim_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x)\,dx.
$$","['limits', 'real-analysis', 'definite-integrals', 'integration', 'analysis']"
1296062,Positivity of alternating series,"Let $\{a_n\}_{n=0}^{\infty}$ be a sequence of positive real numbers such that $\limsup_n \frac{1}{n}\log a_n=-\infty$. Then
$$
	f(x)=\sum_{n\geq 0}a_n x^n
$$
converges absolutely for all $x$. Under what conditions on $\{a_n\}$ will we have $f(x)\geq 0$ for all $x\leq 0$?","['sequences-and-series', 'convergence-divergence', 'real-analysis']"
1296074,I think I see mysterious lines inside triangles—how to prove their existence?,"Lately I've been fooling around with points inside a triangle and the sum of their distances from all sides. This was when I noticed a weird behaviour: For each point I chose there always seemed to be a straight line going through my chosen point and the entire triangle where every point had the same sum of distances from all sides! And as if that's not enough, if I select a different point the line through this point looks parallel to all the other lines created in the same manner but through other points. So is there a way to prove my observation? Question: Do all points inside a triangle that have the same sum of distances from all sides lie on a line and is there a way to give a mathematical equation for said line? (Disregarding equilateral triangles) Because I used numerical means to find this pattern I am not sure whether it even exists. Any kind of help will be appreciated!","['geometry', 'triangles']"
1296075,Find the probability that the final score is 4 in a dice game with two throws,"A game uses an unbiased die with faces numbered 1 to 6. The die is thrown once. If it shows 4 or 5 or 6 then this number is the final score. If it shows 1 or 2 or 3 then die is thrown again and the final score is the sum of the numbers shown on both throws. i. Find the probability that the final score is 4. ii. Given the die is thrown only once, find the probability that the final score is 4. iii. Given the die is thrown twice, find the probability that the final score is 4. I have managed to solve part i and ii and would share the solution below. I am unable to work out part iii and would appreciate help. My solution: i. $P(4) + P(1,3) + P(2,2) + P(3,1) = \dfrac{1}{6} + \dfrac{1}{36} \cdot 3 = \dfrac{1}{4}$ ii. We know that the die is thrown only once and that can happen only when the score is 4, 5 or 6. The sample space is 3. So $P(4)$ now is $1/3$. iii. My guess: $P(1,3) + P(2,2) + P(3,1) = 1/12$ --> Apparently this answer is incorrect and I really can't work out why this is wrong and what the correct approach would be. Reference: OCR Jan 2009 Probability & Statistics 1 (4732)","['dice', 'probability']"
1296086,Characterize magic matrices in terms of their eigenvalues. A Magic Matrix over a field $F$ is a square matrix whose row and colums sums $c\in F$.,"A Magic Matrix over a field $F$ is a square matrix whose row and colums sums $c\in F$ . Characterize magic matrices in terms of their eigenvalues. (Exercise 705 from Golan, The Linear Algebra a Beginning Graduate Student Ought to Know .) I know that $c$ is an eigenvalue and $[1,...,1]^{\sf{T}}$ is an eigenvector, but that is a ""property"", so how can I define all the magic matrices by their eigenvalues? Thanks!","['eigenvalues-eigenvectors', 'magic-square', 'linear-algebra', 'matrices']"
1296107,Does there exist a surjective continuous map $D^2 \to S^1$?,"By considering the induced homomorphism on the fundamental groups, we know that there is no retract $D^2 \to S^1$. But is there any continuous surjection from $D^2$ to its boundary? It seems unlikely intuitively. How might we show this? Idea: If there did, every loop $\gamma$ in $D^2$ would have to be such that $f \circ \gamma$ is contractible in $S^1$. So given a surjective map, perhaps we could find a ""preimage loop"" that must map to a nontrivial loop in $S^1$?","['algebraic-topology', 'general-topology']"
1296115,Prove that $X \subset Y \implies f^{-1}(X) \subset f^{-1}(Y)$,"Let E and F be two sets and $f: E \to F $ be a function, and $X, Y \subset F$. Prove that $X \subset Y \implies f^{-1}(X) \subset f^{-1}(Y)$ My answer: Let $y \in X$, then $f^{-1}(y) \in f^{-1}(X)$. Since $X \subset Y$, then $y \in Y$. If $y \in Y$, then $f^{-1}(y) \in f^{-1}(Y)$. So, $f^{-1}(y) \in f^{-1}(X)$ and $f^{-1}(y) \in f^{-1}(Y)$, then $f^{-1}(X) \subset f^{-1}(Y)$. Is this proof ok?","['inverse', 'proof-writing', 'functions']"
1296182,The limit is that which is neither too big nor too small to be the limit.,"Proposed definition: $$
\lim_{x\to a} f(x) = L
$$
means $L$ is the only number that is neither too big nor too small to be the limit.  This can make sense only if one says precisely what ""too big"" and ""too small"" mean.  Is there some published definition that does that and that is simpler than the usual $\varepsilon$-$\delta$ definition (but logically equivalent to it)?","['reference-request', 'limits', 'epsilon-delta']"
1296187,"A UCLA Qualifying Complex Analyis Problem , possibly related to Phragmén-Lindelöf Theorem","Let $f$ be a bounded analytic function on the open right half plane such that $f(x) \to 0, x\to 0$ along the positive real axis. Suppose $0<\phi<\pi/2$. Prove that $f(z) \to 0, z \to 0$ uniformly in the sector $|\arg z|\le|\phi|$. Remark: I guess it cannot be proved just by Montel's theorem as in one of the answer.
 I am reading Chapter VI GTM 11, Functions of a Complex Variable. And a corollary of Phragmén-Lindelöf Theorem (cf page 139) is similar to my question. The corollary states that Corollary Suppose f is analytic on $G=\{z:|\arg z|\le\pi/2a\}$ and there is a constant such that $\limsup_{z\to w}|f(z)|\le M$ for all $w\in \partial G$. If there are positive constants $P$ and $b<a$ such that $$|f(z)|\le P \exp(|z|^b)$$ then $|f(z)|\le M$ on $G$. The proof of the corollary is just using the Phragmén-Lindelöf Theorem with $\phi(z)=\exp(-z^c)$.",['complex-analysis']
1296188,Probability of co-occurence,"Of total $N$ people, $m$ people are good at mathematics and $c$ people are good at computer science. What is the expected number of people good at both mathematics and computer science? Or what is the probability that $r$ people are good at both mathematics and computer science. 
The formula I have derived is $$P(r)= C(N,r)*C(N-r , m-r) * C(N-m, c-r) / ( C(N,m) * C(N,n))  $$ $N$=Total people $m$=number of people good at math $c$=number of people good at computer $r$= number of people good at both But it contains $n!$, $p!$, $c!$ etc which is difficult to compute for large values (my real problem has large values for all of these). I am looking for a neat workable formula, I am hoping it exist since it is such a basic problem. Note: I am interested in the case where peoples are fixed and get used up. So it's basically like pushing peoples around in a given number of position.","['probability', 'statistics']"
1296203,"Suppose $a_n>0$ and $\sum_{n=1}^{\infty}{a_n}$ diverges. Determine convergence of $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$, where $s_n=\sum^n a_n$.","Suppose $a_n>0$ and $\sum_{n=1}^{\infty}{a_n}$ diverges. Determine whether $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges, where $s_n=a_1+a_2+ \cdots + a_n$. My attempt: By testing a few examples, the series $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges. We proceed to prove it. Note that $$\frac{a_n}{s_n^2} \leq \frac{a_n}{n^2(a_1a_2\cdots a_n)}$$ Now if I manage to prove that $a_1a_2\cdots a_n \geq 1$, then the inequality above becomes $$\frac{a_n}{s_n^2} \leq \frac{1}{n^2}$$. My guess is that it should have something to do with the divergent series $\sum_{n=1}^{\infty}{a_n}$. Then by the Comparison test, we are done. However, I have difficulty to prove the claim. Can anyone give some hint? UPDATE: So I made some mistake in my working. Here is my another 'promising' claim: $$a_n \leq (\frac{a_1+...+a_n}{n})^2$$ It seems to work for any series satisfying the question. But I am unable o prove it.","['contest-math', 'sequences-and-series', 'real-analysis']"
1296207,Every nontrivial linear functional is open [duplicate],"This question already has answers here : Nonconstant linear functional on a topological vector space is an open mapping (4 answers) Closed 3 years ago . Let $X$ be a normed linear space and let $f:X\to \mathbb K$ be a nontrivial linear functional. I want to prove that $f$ is open. I tried as follows: Let $E$ be an open set in $X$ and let $y\in f(E)$. Then there is $x\in E$ such that $y=f(x)$. Since $E$ is open there exists $r>0$ such that $B_r(x)\subset E$. Let $z\in B_1(0)$ such that $f(z)=\delta>0$. If I can show that $(-\delta,\delta)\subset f(B_1(0))$, then I am through. But I could not show this. Please help me  to resolve this.","['functional-analysis', 'general-topology', 'linear-transformations']"
1296223,Confidence Interval Question - Confused on Approaching the Problem,"My question is almost exactly the same as another one here on math stack exchange, but it isn't as explanatory as I'd like it to be with some parts. I was unsure of whether or not it'd be ""okay"" to repost the question, especially since the other one was asked about three years ago. Question is: An electric scale gives a reading equal to the true weight plus a random error that is normally distributed with mean 0 mg and standard deviation = 0.1 mg. Suppose that the results of five successive weighings (in mg) of the same object are as follows:
    3.142, 3.163, 3.155, 3.150, 3.141. a) Compute a 95 percent confidence interval estimate of the true weight.

b) Compute a 99 percent confidence interval estimate of the true weight. Based on the answer that was given, we first find the sample mean, which is just:
$(3.142+3.163+3.155+3.150+3.141)/5.$ Then, we find the standard deviation, which is where I get some confusion. We're supposed to use the ""other"" standard deviation, but I don't know what the differences would be. The apparent ""new"" standard deviation would be: std deviation = $(1/\sqrt5) * .1$ Then, we multiply that by plus or minus 1.96. However, I am completely confused as to how 1.96 is obtained. There is a table we can consult, but it seems that there are different tables depending on whether or not the confidence interval is two-sided - in which case, how would we know if the CI is two-sided? I hope I'm being clear enough here, a slow explanation would be very helpful.",['statistics']
1296225,Ito isometry for bounded Ito integral,"Let $(W_t)_{t \in [0, T]}$ be a Brownian motion and $T$ be a finite time.
If $\int^T_0 \beta_t d W_t$ is bounded and $\{ \beta_t \}_{t \in [0，T]}$ is locally integrable, I am curious whether the following assertions are true or not: ${\mbox E} [ \int^T_0 \beta_t d W_t ] = 0$; ${\mbox E} [ \int^T_0 |\beta_t|^2 d t ] < \infty$; ${\mbox E} [ \int^T_0 |\beta_t|^2 d t ] = {\mbox E} [ |\int^T_0 \beta_t d W_t|^2 ]$. I understand that the Ito isometry, i.e. Assertion 3, holds if $(\beta_t)_{t \in [0, T]}$ is square integrable. I am not sure whether the Ito isometry still holds not or when we only have that $\int^T_0 \beta_t d W_t$ is bounded.","['probability-theory', 'stochastic-calculus', 'stochastic-processes', 'probability', 'stochastic-analysis']"
1296228,"What is $\operatorname{Hom}((S^1)^k , (S^1)^n)$?","I am trying to find $\operatorname{Hom}_{\rm gp}((S^1)^k , (S^1)^n)$ , which is the set of continuous group homomorphisms from the $k$ dimensional torus to the $n$ dimensional torus where $1 \leqslant k \leqslant n$. This is the hint I was given - first show that when $k = n = 1$, $\operatorname{Hom}_{\rm gp}(S^1,S^1) \cong \mathbb{Z}$ Here is what I have managed to do - Now, for a fixed $m \in \mathbb{Z}$  one can define a map $f : S^1 \rightarrow S^1$ by $ f(z) = z^m$, but I don't know how to show that any homomorphism from $S^1$ to $S^1$ is of this form. Assuming $\operatorname{Hom}_{\rm gp}(S^1,S^1) \cong \mathbb{Z}$ I have shown that $\operatorname{Hom}_{\rm gp}(S^1,(S^1)^n) \cong \mathbb{Z}^n$, that is, I have shown that  any homomorphism from $S^1$ to $(S^1)^n$ is of the form $z \mapsto (z^{h_1}, \dots ,z^{h_n})$ for some $n$ tuple $(h_1, \dots, h_n)$ and viceversa. My guess is that $\operatorname{Hom}_{\rm gp}((S^1)^k,(S^1)^n) \cong \mathbb{Z}^{\left( \begin{array}{c} n \\ k \end{array} \right)}$, but assuming this guess is correct I have no idea how to proceed. Please help.","['group-homomorphism', 'group-theory', 'continuous-homomorphisms']"
1296257,Determinant of block matrix with commuting blocks,"I know that given a $2N \times 2N$ block matrix with $N \times N$ blocks like $$\mathbf{S} = \begin{pmatrix}
A & B\\ 
C & D
\end{pmatrix}$$ we can calculate $$\det(\mathbf{S})=\det(AD-BD^{-1}CD)$$ and so clearly if $D$ and $C$ commute this reduces to $\det(AD-BC)$ , which is a very nice property. My question is, for a general $nN\times nN$ matrix with $N\times N$ blocks where all of the blocks commute with each other, can we find the determinant in a similar way? That is, by first finding the determinant treating the blocks like scalars and then taking the determinant of the resulting $N\times N$ matrix. Thanks in advance!","['determinant', 'block-matrices', 'matrices']"
1296270,Interpretation of composite of random variable,"Let  $~f:[0,1] \to[0,\infty]$ be a measurable function bounded by $c \in \mathbb R$. Let $X_1,X_2,..,X_n \sim i.i.d ~\text{uniform}(0,1)$. How do I interpret the following statement:
$$
Var(f \circ X_1)\le c^2
$$
Does it just mean that $Var (f(X_1)) \le c^2$? and how is this true anyway? Is it proved in the following:
\begin{equation*}
f(x) \le c \implies f^2(x) \le c^2
\end{equation*}
and so 
\begin{equation*}
E(f^2(x)) \le E[c^2]=c^2 \implies Var(f(x) )=E[f^2(x)]-E[f(x)]^2 \le c^2
\end{equation*}","['probability-theory', 'notation', 'expectation']"
1296293,Show that $X_n/n$ does not converge almost surely,"I am generally able to prove that a sequence of random variables $X_n$ converge almost surely to a random variable $X$ by using the following strategy: Take any typical sample point $\omega\in\Omega-A$ where $A$ is the union of all possible null sets. Then for this selected $\omega$, $X_n(\omega)$ and $X(\omega)$ are real numbers, so we just have to show that $X_n(\omega)\to X(\omega)$ by usual laws of real analysis i.e. given $\varepsilon>0$ there exists $N\in\mathbb N$ such that $\forall n\geq N$, $|X_n(\omega)-X(\omega)|<\varepsilon$. However, I am confused as to how one can show that a sequence of random variables DOES NOT converge to a random variable almost surely. In particular, consider the following question: Let $\{X_n\}$ be a sequence of independent random variables such that $P(X_n=n)=P(X_n=-n)=\dfrac{1}{2\sqrt{n}}$ and $P(X_n=0)=1-\dfrac{1}{\sqrt{n}}$. Show that $\{\dfrac{X_n}{n}\}$ does not converge almost surely to $0$. I am aware that if $Y_n$ are independent random variables then $$\sum_{n=1}^\infty P(|Y_n|\geq \epsilon)<\infty\space\space\forall\epsilon>0\iff P(Y_n\to 0)=1$$ So in this question, for any $\epsilon>0$ $$P(\dfrac{|X_n|}{n}\geq\epsilon)=P(X_n\neq0)=\dfrac{1}{\sqrt{n}}$$ Since $$\sum_{n=1}^\infty \dfrac{1}{\sqrt{n}}=\infty$$ we have that $X_n/n$ cannot converge almost surely to $0$. However, I spent a lot of time trying to show that $X_n/n$ does not converge a.s. to $0$ using the definition of a.s. convergence. That is, I wanted to show that there exists $A=\{\omega: X_n(\omega)/n$ does not converge to $0\}$ with $P(A)>0$. Somehow I find this quite hard to do. What is the general method to show that a sequence does not converge almost surely from the definitions only?","['probability-theory', 'convergence-divergence', 'random-variables']"
1296295,"If an entire function $f$ satisfies $|f(z)| \le |\log z|,$ what can we say about $f$?","Let $f$ be an entire function. Define $\Omega=\mathbb{C}-(-\infty,0]$, the complex plane with the ray $(-\infty,0]$ removed. Suppose that for all $z \in \Omega$ , $|f(z)| \le |\log z|$, where $\log z$ is the principal branch of the logarithm. What can one conclude about the function $f$? My try: I am tempted to use Cauchy's Integral formula and use the given bound. Since $f$ is entire , $f(z)$ can be represented as $$f(z)=f(0)+zf'(0)+...$$ Now $$f^n(0)=\frac{n!}{2\pi i}\int_{\gamma}\frac{f(z)}{z^{n+1}}dz$$, where $\gamma: |z|=r$     . Then taking modulus on both the sides and using the inequality we arrive at $$|f^n(0)| \le \frac{n!}{2\pi}\int_{0}^{2\pi}\frac{|f(re^{i\theta})|}{r^{n+1}}r d\theta$$   . Everything is fine till now. Now when I try to use the given inequality, I am stuck. I believe I simply can't use $|f(re^{i\theta})| \le |\log (re^{i\theta})|$ everywhere in the contour since the branch of logarithm doesn't exist at the point $(-r,0)$. Even if I am able to do that (something tells me I should be but don't know what) , I will end up with $f(z)$ being a constant. Then $f(1)=0$ would give $f$ to be identically $0$ everywhere. My question is why should I be able to use the inequality through out the contour(if at all it is possible)?? If not, then what are the other ways of proceeding?? Thanks for the help!!",['complex-analysis']
1296342,In how many ways can the integers from $1$ to $n$ be divided into two groups with the same sum?,"In how many ways can the integers $1,2,\ldots,n$ be divided into two groups with the same sum? I have tried calculating some of these values for small $n$, but cannot seem to find a pattern. Any help is appreciated! :)","['summation', 'integers', 'combinatorics']"
1296344,Intersection of ample and effective divisors,"I believe it is something silly, but I'm a newbie, so why on a surface the intersection of an effective divisor and a divisor from ample bundle is non-negative? In fact, I need that an intersection of an effective divisor with a hyperplane section is non-negative.",['algebraic-geometry']
1296367,A necessary condition to $F'(x)=f(x)$ for a continuous function $f$,"Theorem: Consider , $$F(x)=\int_a^xf(t)\,dt$$ If the function $f:[a,b]\to \mathbb R$ is continuous then , $F(x)$ is differentiable and $F'(x)=f(x).$ I know that the continuity condition of $f$ is sufficient condition. That means there exists a discontinuous function $f$ for which this $F'(x)=f(x)$ . My Question: Does there exist a necessary condition for this ? $$OR$$ After imposing which extra condition on $f$ it is necessary that $F'(x)=f(x)$ ?","['analysis', 'real-analysis', 'integration']"
1296369,"What is $HC_0(\operatorname{Spec} k[x,y]/(xy))$?","Does anybody know how to compute $HC_0(\operatorname{Spec} k[x,y]/(xy))$? Here $HC_0(-)$ is the zeroth cyclic homology group. I'm curious since $\operatorname{Spec} k[x,y]/(xy)$ can be viewed as the union of affine lines.","['algebraic-geometry', 'homology-cohomology', 'commutative-algebra']"
1296376,Establishing a trigonometric identity for $n\in\mathbb{N}$,"The original problem was showing that this infinite sum converges to $\tan\theta$:
$$\sum_{n=1}^\infty \frac{\tan\dfrac{\theta}{2^n}}{\cos\dfrac{\theta}{2^{n-1}}}$$
One hint was given: the series telescopes. I figured this meant I could factorize the denominator if I just apply some identities, and indeed it does:
$$\frac{\tan\dfrac{\theta}{2^n}}{\cos\dfrac{\theta}{2^{n-1}}}=\frac{\sec\dfrac{\theta}{2^n}}{\cos\dfrac{\theta}{2^n}-\sin\dfrac{\theta}{2^n}}-\frac{\sec\dfrac{\theta}{2^n}}{\cos\dfrac{\theta}{2^n}+\sin\dfrac{\theta}{2^n}}$$
I plugged in the first few $n$ to see if a pattern emerges, and indeed it does. Mathematica gives me this output: This gives me the identity,
$$\dfrac{1}{\cos\dfrac{\theta}{2^n}-\sin\dfrac{\theta}{2^n}}+\dfrac{1}{\cos\dfrac{\theta}{2^n}+\sin\dfrac{\theta}{2^n}}=\dfrac{\sin\left(1-\dfrac{1}{2^n}\right)\theta}{\cos \dfrac{\theta}{2^n}}$$
where $x=\theta$, and this converges to $\tan \theta$ as $k\to\infty$. So I'm curious, how would I come to derive something like this? A simpler approach was expected, I'll have to check to see if I still remember it. Something to do with a tangent identity, if I recall correctly. If I find it, I'll include it in an edit.","['contest-math', 'sequences-and-series', 'trigonometry']"
1296382,Questions about a topological proof of the FTA,"I'm a high school student, curious about proofs of the Fundamental Theorem of Algebra. Specifically, I've been thinking about one of the topological proofs of the theorem, given in Courant's book, ""What is Mathematics"". Here are my questions: But the order $φ(t)$ depends continuously on $t$, since $f(z)$ is a continuous function of $z$. Hence we shall have a contradiction, for the function $φ(t)$ can assume only integral values and therefore cannot pass continuously from the value $0$ to the value $n$. I don't get this part. What is it trying to say? I know that $f(z)$ is a continuous function, and that $φ(t)$ changes 'smoothly' with $t$ (in my mind I have a picture of a closed curve shrinking 'smoothly' when the circle that $z$ traces also shrinks in the same way, hence, at every value of $t$, there exists a unique order. However, I also know that the order must have integral values, because there can't be $3.14$ turns.) But is this correct? I think I'm getting these concepts in a muddle. I also can't see how this contradiction serves to show that our initial assumption about $f(z)$ not having a root is absurd. Since the expression on the left is the distance between the two points $z^n$ and $f(z)$, while the last expression on the right is the distance of the point $z^n$ from the origin, we see that the straight line segment joining the two points $f(z)$ and $z^n$ cannot pass through the origin so long as z is on the circle of radius $t$ about the origin. What does this really imply? In my mind I think that whenever z traces out a circle with a radius $t$ $\neq$ $0$, the rest of the terms in $f(z)$ will never be $0$. But how does this help with proving that when t is large,  $f(z)$ behaves like $z^n$? This being so, we may continuously deform the curve traced out by $f(z)$ into the curve traced out by $z^n$ without ever passing through the origin, simply by pushing each point $f(z)$ along the segment joining it to $z^n$. Since the order of the origin will vary continuously and can assume only integral values during this deformation, it must be the same for both curves. Since the order for $z^n$ is $n$, the order for $f(z)$ must also be $n$. What does ""deforming $f(z)$ into $z^n$ mean, and why do we want to do this? How can the order vary continuously if it can only assume integral values? How does this show that the orders of $z^n$ and $f(z)$ are the same? Thanks, this is my first time posting here and I'm not well-versed with a lot of the terms in Mathematics (I'll be finishing high school in six months) so forgive my sloppy way of explaining things.","['polynomials', 'general-topology', 'winding-number']"
1296393,Maximizing profit function given cost and demand functions,I am given the demand function $$D(x)=10x^2 + 50x$$ and a total cost of $$C(x) = x^3 + 10x$$ where $x$ is the number of units demanded. I am asked to maximize the profit so what I did is I used the formula $$P(x) = R(x) - C(x)$$ where $R(x) = x D(x)$. Then I took the derivative of $P(x)$ and equated to 0. But I got a negative value of x more so a value less than 1 since $$P'(x) = 27x^2 + 100x -10$$ Am I right or did I do something wrong in between my process? I don't think it's logical to have a quantity which is negative and less than 1 for this kind of problem. Please help.,"['calculus', 'proof-verification', 'economics', 'optimization', 'derivatives']"
1296420,An example of a group such that $G \cong G \times G$,"I was trying to find an example such that $G \cong G \times G$, but I am not getting anywhere. Obviously no finite group satisfies it. What is such group?","['abstract-algebra', 'group-theory', 'group-isomorphism']"
1296429,Finding local max of analytic function,Given a function $f=z^2+iz+3-i$. I need to find the the maximum of $|f(z)|$ in the domain $|z|\leq 1$ I know that the maximimum should be on $|z|=1$ but when I tried to put $z=e^{i\theta} $ in the function I got lost in the calculations. Thanks,"['calculus', 'complex-analysis', 'complex-numbers']"
1296450,Does proper map $f$ take discrete sets to discrete sets?,"Suppose $f:X \to Y$ is a continuous proper map between locally compact Hausdorff spaces. Are the following results true? $1$. The map $f$ takes discrete sets to discrete sets. $2$. If $f$ is injective, then $f$ must be a homeomorphism onto its image. Edit 1:Let $A$ be discrete in $X$ and let $K$ be compact in $Y$ then $f(A) \cap K=f(A \cap f^{-1}(K))$,is finite since $A \cap f^{-1}(K)$ is finite.Hence $f(A)$ is discrete.
As there is a counterexample in answer below so can someone please point out the error in my proof?","['compactness', 'general-topology', 'functions']"
1296456,Does a weaker form of the mean value property already imply harmonicity for continuous functions?,"If $u:\mathbb{C}\to \mathbb{R}$ is continuous and satisfies $u(z)=\frac{1}{2\pi}\int_0 ^{2\pi}u(z+\frac{e^{i\theta}}{n})d\theta$ for all $n\in \mathbb{N}$ and $z\in \mathbb{C}$, is $u$ harmonic? What I know: If for each $P\in \mathbb{C}$ there exists $r_P$ such that for $0<r<r_P$, $u(P)=\frac{1}{2\pi}\int_0 ^{2\pi } u(P+re^{i\theta})d\theta$ then $u$ is harmonic, but in the proof I need the fact that the equation holds for all $0<r<r_P$. I tried showing that $u$ is a limit of holomorphic functions satisfying the integral equation for $0<r<r_P$, and I considered looking for a counterexample but I don't know where to start.","['harmonic-functions', 'complex-analysis']"
1296522,"Let $p_1, p_2,\dots,p_n$ be polynomials of $k$ variables $x_1,\dots,x_k$ and $p_1^2 + \dots +p_n^2=x_1^2 + \dots + x_k^2$ Prove that $n \geq k$.","Let $p_1, p_2,...,p_n$ be real polynomials of $k$ variables $x_1,...,x_k$ and assume that 
$$p_1^2 + \dots +p_n^2=x_1^2 + \dots + x_k^2$$ Prove that $n \geq k$. Out of so many questions that I have attempted, this is the first question that I have absolutely no idea how to start (I am ashamed of myself). Can anyone give some hint?","['contest-math', 'polynomials', 'algebra-precalculus']"
1296527,Is it true that $\sum_{n=1}^\infty \dfrac{Var(Y_n)}{n}<\infty$?,"Suppose that $\{X_n\}$ is an i.i.d. sequence of random variables with $E|X_1|<\infty$.Define $Y_n=X_nI_{\{|X_n|<n\}}$ for all $n\geq1$. Is it true that $\sum_{n=1}^\infty \dfrac{Var(Y_n)}{n}<\infty$? I believe NO is the answer. Intuitively, as $n\to\infty$, $Var(Y_n)\to Var(X_1)=\sigma^2$ so basically after some $n$ we would be having the series as $\sum_{k=n}^\infty\dfrac{\sigma^2}{n}=\infty$. I also checked on Wolfram Alpha taking $X_n$ to be a standard normal randm variable. $Var(Y_n)=2.5063$ for all $n\geq10$ which proves divergence.","['probability-theory', 'sequences-and-series', 'convergence-divergence']"
1296619,How to determine whether a set is a vector space or not?,"I'm currently learning Vector Spaces and although I understand the definition of what a vector space is, I can't seem to be able to find the correct answers when doing some questions. I would even say that I'm getting some answers right by pure luck and that's defeats the purpose of mathematics. My problem is that I don't know the correct approach to solve these questions. Here are a few questions which I'm trying to do but I'm not sure how to arrive to my answers: In the questions below, I should determine whether each of the sets given is a vector space or not: $V = \{(x,y,z)\in \mathbb{R}^3 : x-y+2z = 3\}$ $V = \{p\in P_{4}[x] : p(0) + p(1) = 0\}$ $V = \{A\in M_{3*3} : A = A^{t}\}$ $V = \{A\in M_{3*3} : AA^{t} = -I\}$ Now, all of the answers are yes except for number $4$, is a vector space.
I got $1$ wrong and $4$ wrong. I got numbers $2$ and $3$ right but I'm not sure if my way of finding the answer is right. I normally just use the definition of a Vector Space but it doesn't work all the time. Edit: I'm not simply looking for the final answer( I already have them) but I'm more interested in understanding how to approach such questions to reach the final answer. Edit 2:
The answers given in the memo are as follows: 1. Vector Space
2. Vector Space
3. Vector Space
4. Not a  Vector Space Could anyone please explain how to get the answer in detail and if there is a trick to quickly find the answers? Thanks.","['vector-spaces', 'linear-algebra']"
1296634,"Prob. 5, Sec. 27 in Munkres' TOPOLOGY, 2nd ed: Every compact Hausdorff space is a Baire space","Here is Prob. 5, Sec. 27, in the book Topology by James R. Munkres, 2nd edition: Let $X$ be a compact Hausdorff space; let $\left\{  A_n  \right\}$ be a countable collection of closed sets of $X$ . If each set $A_n$ has empty interior in $X$ , then the union $\bigcup  A_n$ has empty interior in $X$ . How to show this fact? What if we have an uncountable collection of closed sets, each set having empty interior? Does the conclusion still hold? My effort: First a preliminary result: Let $X$ be a compact Hausdorff space, and let $A$ be a closed subset of $X$ . If $U$ is a non-empty open set in $X$ such that $U \not\subset A$ , then there is a non-empty open set $V$ in $X$ such that $\overline{V} \subset U-A$ , that is, $\overline{V} \subset U$ and $\overline{V} \cap A = \emptyset$ . Am I right? Proof: Since $U \not\subset A$ , the set $U - A$ is non-empty. Let $x \in U-A$ . Let us put $$ B \colon= A \cup (X-U). \tag{Definition 0} $$ Then $B$ is closed in $X$ , and also $x \not\in B$ . Now since $X$ is compact and since $B$ is closed in $X$ , therefore $B$ is also compact (as a subspace of $X$ ), by virtue of Theorem 26.2 in Munkres. Since $X$ is a Hausdorff space, since $x \in X$ , and since $B$ is a compact subspace of $X$ such that $x \not\in B$ , therefore by Lemma 26.4 in Munkres there are open sets $V$ and $W$ in $X$ such that $$ x \in V, \qquad B \subset W, \qquad \mbox{ and } \qquad V \cap W = \emptyset. \tag{1} $$ Therefore we have $$
\begin{align}
X- W &\subset X-B \qquad \mbox{ [because $B \subset W \subset X$] } \\
&= X - \big( A \cup (X-U) \big) \qquad \mbox{ [by (Definition 0) above ] } \\
&= (X-A)\cap \big( X-(X-U) \big) \qquad \mbox{ [a DeMorgan's law] } \\
&= (X-A) \cap U \\ 
& \qquad \mbox{ [the compelement of the complement set $U\subset X$ equals $U$ itself] }\\
&= U-A \qquad \mbox{ [a set-theoretic identity] },
\end{align}
$$ that is, $$ X-W \subset U-A; \tag{2} $$ and also from (1) we have $$ V \subset X-W.  $$ Moreover, since $X-W$ is closed in $X$ and since $V \subset X - W$ , therefore we can also conclude that $$ \overline{V} \subset X-W. \tag{3} $$ Thus from (1), (2), and (3) above we obtain $$ x \in V \subset \overline{V} \subset X-W \subset U-A. $$ That is, $V$ is a non-empty open set in $X$ and $\overline{V} \subset U-A$ , 
  as required. Is this proof correct? Now for the main proof: Let us put $$ A \colon= \bigcup A_n . \tag{A} $$ We show that $A$ has empty interior. For this, we show that there is no non-empty open set $U$ in $X$ such that $U \subset A$ . Let $U$ be any non-empty open set in $X$ . Let us put $$V_0 \colon= U. \tag{0} $$ This is just for notational convenience. Then since $A_1$ has empty interior in $X$ and since $V_0$ is a non-empty open set in $X$ , therefore the set $V_0$ is not contained in $A_1$ . So there exists a non-empty open set $V_1$ in $X$ such that $$\overline{V_1} \subset V_0 -A_1. \tag{1} $$ Again as the set $A_2$ has empty interior in $X$ and as $V_1$ is a non-empty open set in $X$ , so the set $V_1 \not\subset A_2$ , and thus there exists a non-empty open set $V_2$ in $X$ such that $$ \overline{V_2} \subset V_1 - A_2. \tag{2} $$ Now suppose that the non-empty open sets $V_1, \ldots,  V_{n-1}$ (for $ n= 3, 4, 5, \ldots$ ) have been chosen such that $$ \overline{V_k} \subset V_{k-1} - A_k \ \mbox{ for each } \ k = 1, 2, \ldots, n-1. \tag{3} $$ Now as the set $A_n$ has empty interior in $X$ and as the set $V_{n-1}$ is a non-empty open set in $X$ , so $V_{n-1} \not\subset A_n$ , which implies that there exists a non-empty open set $V_n$ in $X$ such that $$ \overline{V_n} \subset V_{n-1} - A_n. \tag{4} $$ From (1) we note that $$ \overline{V_1} \subset V_0 \subset \overline{V_0} \qquad \mbox{ and also } \qquad \overline{V_1} \cap A_1 = \emptyset. $$ From (2) we find that $$ \overline{V_2} \subset V_1 \subset \overline{V_1} \qquad \mbox{ and also } \qquad \overline{V_2} \cap A_2 = \emptyset. $$ And so on, from (4) we find that $$ \overline{V_n} \subset V_{n-1} \subset \overline{V_{n-1}} \qquad \mbox{ and also } \qquad \overline{V_n} \cap A_n = \emptyset $$ for all $n \in \mathbb{N}$ such that $n > 1$ . Thus we have a sequence $$ \overline{V_0}, \overline{V_1}, \overline{V_2}, \overline{V_3}, \ldots $$ of non-empty closed sets in $X$ such that, for each $n = 1, 2, 3, \ldots$ , we have $$ \overline{V_n} \subset \overline{V_{n-1}} \qquad \mbox{ and } \qquad \overline{V_n} \cap A_n = \emptyset. \tag{5} $$ In particular, $\overline{V_1} \subset U$ , by virtue of (1) and (0) above. And, if $\overline{V_{n_1}}, \ldots, \overline{V_{n_k}}$ are any finitely many of these sets, then we have $$ \bigcap_{i=1}^k \overline{V_{n_i}} = \overline{V_{n_0}} ,$$ where $$ n_0 \colon= \max\left\{ n_1, \ldots, n_k \right\}, $$ and so $\bigcap_{i=1}^k \overline{V_{n_i}}$ is non-empty. Thus the nested sequence $\left( \overline{V_n} \right)_{n \in \mathbb{N}}$ of non-empty closed sets of $X$ has the finite intersection property, and as $X$ is compact, so by Theorem 26.9 in Munkres these sets have a non-empty intersection. That is, $$ \bigcap  \overline{V_n} \neq \emptyset. $$ Suppose $x \in \bigcap \overline{V_n}$ . Then $x$ is in each set $\overline{V_n}$ , which implies that $x \in U$ and also that $x$ is not in any set $A_n$ , and so $x \not\in A$ , refer to Def. (A) above. Thus $x \in U - A$ and therefore $U \not\subset A$ . But $U$ was any arbitrarily chosen non-empty open set in $X$ . Hence $A = \bigcup A_n$ has empty interior. Is my proof correct? If so, is it clear enough in each and every detail? If not, then where is it in need of improvement / correction?","['solution-verification', 'baire-category', 'general-topology', 'compactness']"
1296665,The group $(1+p\mathbb Z_p)/(1+p^{n}\mathbb Z_p)$,"I want know some information about the group 
\begin{equation*}
\frac{(1+p\mathbb Z_p)}{(1+p^{n}\mathbb Z_p)}
\end{equation*}
(the Quotient group). What is the order of this group? I guess $p^{n-1}$ But how can I prove this? How does an element of this group look like? $\mathbb Z_p$ is the ring of the p-adic integers.","['abstract-algebra', 'p-adic-number-theory']"
1296690,"The lines $x+2y+3=0$ , $x+2y-7=0$ and $2x-y+4=0$ are sides of a square. Equation of the remaining side is?",I found out the area between parallel lines as $ \frac{10}{\sqrt{5}} $ and then I used $ \frac{|\lambda - 4|}{\sqrt{5}} = \frac{10}{\sqrt{5}} $ to get the values as $-6$ and $14$ . I   am getting the final equations as $2x-y-6=0$ and $2x-y+14=0$ but this answer is wrong. According to my book the correct equations are $2x-y+6=0$ and $2x-y-14=0$. Please tell me where I am wrong!,"['geometry', 'analytic-geometry']"
1296698,A really basic integration question concerning differentials,"I'm really, really confused with this. Please, please help me.
$$$$
My Calculus teacher taught me that the integral symbol and the differential with respect to which we are integrating are like parenthesis. He told us to think of the integral sign as an “open parenthesis” and the $dt$ as a “close parenthesis”. If we were to integrate any function of $t$, say $v(t)$, we have to put the integral sign on the left of $v(t)$, and the differential $dt$ on the right of $v(t)$ ie $\int v(t) dt$ $$$$
In physics, while while deriving equations of motion, our physics teacher did this: since v is a linear function of t, $$dv(t)/dt=a(constant)$$ $$\Rightarrow dv= a dt$$
She then simply put an integral sign on LHS and RHS to integrate and then got $$\int dv= \int a dt$$
$$v=at+C$$
But this does not fit into what my Calculus teacher had taught us. As per what he has taught: 
$$ dv= a dt$$
We now have to add an integral sign and another differential on either side of the expressions in LHS and RHS respectively. Only then can we integrate.$$$$
Could somebody please explain this idea of the integral sign as an “open parenthesis” and the $dt$ as a “close parenthesis”? Please could you explain how this is applied to the physics example?","['derivatives', 'calculus', 'indefinite-integrals', 'integration']"
1296736,"Extreme value theorem, without Heine Borel.","I was wondering, if there are any mistakes, in this proof of the extreme value theorem: Theorem . Let $X$ be a compact set and $f:X\rightarrow\mathbb{R}$, s.t. $f$ is continuous. Then there exists $x\in X$, s.t. for all $y\in X$, $f(y)\leq f(x)$. Proof . Let $\epsilon>0$, $x\in X$ and $U_x=f^{-1}(-\infty,f(x)+\epsilon)$. As $f$ is continuous, $U_x$ is open. Also, $x\in U_x$. Then $\{U_x\}_{x\in X}$ is an open cover of $X$. As $X$ is compact, there exists $x_1,\dots,x_n\in X$, s.t. that $\{U_{x_k}\}_{1\leq k\leq n}$ is an open cover of $X$. Let $1\leq m\leq n$, such that $f(x_m)=\max_{1\leq k\leq n}f(x_k)$ and $y\in X$. Then, there exists $1\leq k\leq n$, s.t. that $y\in U_{x_k}$. Then $f(y)<f(x_k)+\epsilon\leq f(x_m)+\epsilon$. As $\epsilon$ was arbitrary, $f(y)\leq f(x_m)$. Somehow, I am sceptic about this proof, as it seems too simple. Any thoughts?","['alternative-proof', 'compactness', 'continuity', 'functions', 'general-topology']"
1296755,What is mathematical structure?,"When we have an isomorphism, between $2$ groups or vector spaces let us say, then it is said to be structure preserving. An isomorphism exists when there is at least one mutually invertible morphism between sets (and this is arbitrary when a set is mapped on to itself). What do we mean intuitively, and perhaps somewhat analytically, when we say structure preserving? What structure do these sets, groups, vector spaces, etc . . . come with? This is a question I'm looking for more intuition on than anything else but specific examples are very helpful. Here is are related threads What does structure preserving mean? Mathematical Structures Preserving Structures Isomorphisms: preserve structure, operation, or order? I sought the answer throughout the forum but I never really found the questions asked/answer in a satisfactory way. Thanks everyone! edit:
For example, if we have sets $A = \{a, b, c\}$ and $B = \{1, 2, 3\}$ and we have a bijection $f$ between them such that $f(a) = 1$ $f(b) = 2$ $f(c) = 3$ Is structure preserved or does that require an operation of some kind to also be present? If structure is preserved, what is it?","['vector-spaces', 'soft-question', 'abstract-algebra', 'group-theory', 'linear-algebra']"
1296766,find all possible solutions,"The set of all $x$ in the interval $[0,\pi]$ for which $2\sin^2x-3\sin x+1 \geq 0$, is _________________. I have tried by factoring it first and then comparing it with the inequality.
My final step was $(\sin x-1)(2\sin x-1) \geq 0$.",['trigonometry']
1296833,"If I know the order of every element in a group, do I know the group? [duplicate]","This question already has answers here : Is a finite group uniquely determined by the orders of its elements? (3 answers) Closed 4 years ago . Suppose $G$ is a finite group and I know for every $k \leq |G|$ that exactly $n_k$ elements in $G$ have order $k$. Do I know what the group is? Is there a counterexample where two groups $G$ and $H$ have the same number of elements for each order, but $G$ is not isomorphic to $H$? I suspect that there is, but I haven't thought of one.","['abstract-algebra', 'group-theory', 'examples-counterexamples', 'finite-groups']"
1296846,"$a,b,N$ are integers. Prove $x=x_0+\cdots$, $\ \ y=y_0+\cdots $ are solutions to $ax+by=N$","I'm asked to prove that if $a,b,N$ are integers, then in the equation: $$ax+by=N$$ I must prove that the integers $$x=x_0+\frac{b}{d}t,\ y=y_0-\frac{a}{d}t$$
are solutions to the equation. where $d=gcd(a,b)$ This is easy to prove, since if we substitute $x,y$ in the equation we get: $$a(x_0+\frac{b}{d}t)+b(y_0-\frac{a}{d}t)=N\implies ax_0 + by_0=N$$ So $x_0$ and $y_0$ are solutions. Then I'm asked to prove the converse: let $x$ and $y$ be integer solutions to the equation. Then, they have the form $$x=x_0+\frac{b}{d}t,\ y=y_0-\frac{a}{d}t$$. First of all, I don't know how to start. Also, I don't know what this exercise is trying to make me see. Maybe a useful theorem?
Does someone know how to start with the equation $$ax+by=N$$ where $a,b,N$ are integers, and then intuitively find that the solutions are in the form presented by the exercise?
I think it has something to do with Bezout's identity, it kinda looks like it.","['number-theory', 'abstract-algebra', 'group-theory']"
1296859,Measurability of an integral,"Let $\{X_t\}_{t\ge 0}$ be an adapted $\mathbb{R}$-valued stochastic process on some filtered probability space $(\Omega,\mathcal{F},\{\mathcal{F}_t\}_{t\ge 0},\mathbb{P}\}$ such that for each $\omega\in\Omega$ and $t\ge 0$ the integral $\int_0^t X_s(\omega)ds$ exists (Lebesgue integration). Why is this integral $\mathcal{F}$-$\mathfrak{B}(\mathbb{R})$-measurable (as a function in $\omega$) if the process $X$ is progressively measurable? Does someone know how to prove this? Thank you!","['probability-theory', 'measure-theory', 'stochastic-calculus', 'stochastic-processes', 'stochastic-analysis']"
1296880,How to prove this identity involving characteristic polynomials on both sides?,"Suppose $A\in \Bbb C^{m\times n},B\in \Bbb C^{n\times m},m\ge n$, prove:
$$\det(\lambda I_m-AB)=\lambda^{m-n}\det(\lambda I_n-BA)$$
I don't want to get into nasty determinant calculation. Instead, I think comparing the polynomial factors on both sides might help.  My attempt so far shows that $AB$ and $BA$ share the same non-zero eigenvalues, and that if $BA$ has 0 as eigenvalue, so does $AB$. I guess I'm on the right track but I can't proceed.  The multiplicities of $(\lambda-\lambda_i)$s on both sides seem to be big trouble. I cannot prove they are equal.  Can you help me? Thanks in advance.","['eigenvalues-eigenvectors', 'polynomials', 'linear-algebra', 'matrices']"
1296885,Find extremum of functional,"I want to find the extremum of $$J(y)= \int_1^2 \frac{\sqrt{1+y'^2}}{x}dx, \ y(1)=0, \ \ y(2)=1$$ I thought to use the following theorem: If $y$ is a local extremum for the functional $J(y)= \int_a^b L(x,y,y') dx$ with $y \in C^2([a,b]), \ y(a)=y_0, \ y(b)=y_1$ then the extremum $y$ satifies the ordinary differential equation of second order: $$L_y(x,y,y')- \frac{d}{dx} L_{y'}(x,y,y')=0 (\text{ Euler's equation})$$ That's what I have tried so far: $$L(x,y,y')= \frac{\sqrt{1+y'^2}}{x}$$ $$L_y(x,y,y')=0$$ $$L_{y'}(x,y,y')= \frac{2y'}{2x \sqrt{1+y'^2}}$$ So Euler's equation for this problem is: $$- \frac{d}{dx} \left( \frac{2y'}{2x \sqrt{1+y'^2}} \right)=0 \Rightarrow \frac{y'}{x \sqrt{1+y'^2}}=c \Rightarrow y'=cx \sqrt{1+y'^2} \\ \Rightarrow y'^2=c^2 x^2 (1+y'^2) \Rightarrow \left( \frac{dy}{dx}\right)^2=c^2x^2+ c^2 x^2 \left( \frac{dy}{dx} \right)^2 \\ \Rightarrow \left( 1-c^2x^2 \right) \left( \frac{dy}{dx}\right)^2=c^2 x^2 \Rightarrow \left( \frac{dy}{dx} \right)^2=\frac{c^2 x^2}{1-c^2 x^2} \\ \Rightarrow \frac{dy}{dx}= \pm  c \frac{x}{\sqrt{1-c^2 x^2}}$$ We set $\pm c= C$ Then: $\frac{dy}{dx}= \frac{Cx}{\sqrt{1-C^2 x^2}} \Rightarrow dy= \frac{Cx}{\sqrt{1-C^2 x^2}} dx \Rightarrow y(x)=- \frac{1}{c} \sqrt{1-c^2x^2}+k$ $$y(1)=0 \Rightarrow - \frac{1}{c} \sqrt{1-c^2}+k=0 \ (1)$$ $$y(2)=1 \Rightarrow -\frac{1}{c} \sqrt{1-4c^2}+k=1 \ (2)$$ Is it right so far? How could we continue? EDIT : $$(2)-(1) \Rightarrow \frac{1}{c} \sqrt{1-c^2}- \frac{1}{c} \sqrt{1-4c^2}=1 \Rightarrow \sqrt{1-c^2}-  \sqrt{1-4c^2}=c \Rightarrow (\sqrt{1-c^2}-  \sqrt{1-4c^2})^2= c^2 \Rightarrow \dots \Rightarrow 1-6c^2+9c^4=1-4c^2-c^2+4c^4 \Rightarrow 5c^4=5c^2 \Rightarrow c^2(c^2-1)=0 \Rightarrow c=0 \text{ or } c= \pm 1$$ EDIT 2 : We reject $c=0$ since we dicide by $c$. But from the relation $-\frac{1}{c} \sqrt{1-4c^2}+k=1$ we have also the restriction $1-4c^2 \geq 0 \Rightarrow 1 \geq 4c^2 \Rightarrow c^2 \leq \frac{1}{4} \Rightarrow - \frac{1}{2} \leq c \leq \frac{1}{2}$. So $c$ can't take the values $\pm 1$. So does this mean that there is no extremum? Or have I done something wrong? EDIT 3 : I must have done something wrong with the calculations. I retried them and I got $c= \frac{1}{\sqrt{5}}$. So we get $k=\frac{1}{c} \sqrt{1-c^2}=\sqrt{5}\sqrt{1-\frac{1}{5}}=\sqrt{5} \sqrt{\frac{4}{5}}=\sqrt{4}=2$ So we deduce that $y(x)= - \sqrt{5} \sqrt{1-\frac{x^2}{5}}+2$ is a local minimum. Or am I wrong?","['optimization', 'calculus-of-variations', 'ordinary-differential-equations']"
1296889,Fields of arbitrary cardinality,"So I took an introductory abstract algebra course a few semesters ago, and we were shown that groups and rings can both be made into products, i.e. if I have some group $G$ (resp. ring $R$) and some indexing set $I$, then I can make a group $G^{I}$ (resp. ring $R^{I}$) with the appropriate cardinality. However, it was also demonstrated that for fields, you cannot keep the multiplicative inverse under a product structure, i.e. if I have fields $F_{1}, F_{2}$, then $F_{1} \times F_{2}$ will still be a ring, but you will not (not just ""not in general"", but won't) have multiplicative inverses for all non-zero (i.e. not $(0, 0)$) elements, as you could pick $(0, x)$, where $x \neq 0$. According to Wikipedia, an ultraproduct will preserve field structure, but I'm not sure what the cardinality of $\prod_{i \in I} F_{i} / \mathscr{U}$ would be in general. I saw another post that said you could make a field of arbitrarily large cardinality by extending a given field through throwing in a whole bunch of ""transcendental"" elements. The example given was that if I had $\mathbb{Q}$, I could start by dumping in the complexes, but then I suppose after that I'd just start throwing in dogs and cats or something; I'm really not sure what that responder meant, and ceteris paribus, my dogs tend to stay inside, so I'd rather keep them out of my fields, particularly the large ones the thread was interested in. Moreover, the thread mentioned earlier seemed more concerned with just making the fields big. My question is a bit more nuanced: Given any cardinality $\kappa > 1$, can I generally construct a field $F$ of a cardinality $\kappa$? Moreover, how vague do I have to be about it (i.e. do I have to use some really choicy methods, or can I make it a bit more straightforward)? Thanks. EDIT: Sorry. I am aware that for finite fields, you are limited to powers of primes. I meant for infinite cardinals.","['abstract-algebra', 'field-theory']"
1296896,"With the aid of series, show that if $f(z)=\frac{\operatorname{cos}z}{z^2-(\pi/2)^2}$, then $f$ is an entire function.","Prove that if $$f(z)=
\begin{cases}
\frac{\operatorname{cos}z}{z^2-(\pi/2)^2}, & \text{when} \; z\neq \pm \pi/2, \\
-\frac{1}{\pi}, & \text{when} \; z=\pm \pi/2,
\end{cases}
$$ then $f$ is an entire function. The general method of proving such results from the book is by using the fact that if a function has a power series representation, then it is analytic in the circle of convergence. Hence, using this method, I first need to find the power series of $f$ when $z\neq \pm \pi/2$, and the proof is complete if I show that this series at $z=\pm \pi/2$, equals $-\frac{1}{\pi}$. So I start with the Taylor series of the entire function $\operatorname{cos}z$, however, I'm having trouble dealing with the denominator $z^2-(\pi/2)^2$. How can I find the power series representation of this function? I would greatly appreciate some help.","['power-series', 'analysis', 'sequences-and-series', 'complex-analysis']"
1296908,"What does ""2- place real function"" mean?","What does ""2-place real function"" mean? This comes up in the context of copulas, as here .","['terminology', 'statistics', 'functions']"
1296932,$f(x) = x \tan^{-1}(x\ln(x))$ find $f'(e)$,$f(x) = x \tan^{-1}(x\ln(x))$ find $f'(e)$ my work $f'(x)=\tan^{-1}(x\ln(x)) *1 + x$ ---> stack here I know $\tan^{-1}(x)'=  \frac{1}{1+x^2}$ so $\tan^{-1}(x\ln(x)) = ???$ I need help to solve that question please,"['calculus', 'ordinary-differential-equations']"
1296935,Aut(G) is abelian,I've heard of this (open?) problem: Classify groups G such that Aut(G) is abelian. What I discovered: Any characteristic  abelian subgroup is cyclic. Center is cyclic. Commutators are cyclic. What do true mathematicians know?,"['group-theory', 'finite-groups']"
1296951,Confusion about the sample mean and random variables,"As I understand the sample mean you just add a bunch of random variables that constitute a sample from their common distribution and divide by the number of those same random variables. When I apply it in actual problems I get specific numbers from the population and take their mean. This confuses me as I thought that when you add random variables it represents adding all the possible outcomes of those random variables. So my understanding of adding random variables is that if you had random variables $X$ and $Y$, that could take on the values $1$ and $2$, $X + Y$ represents $1+1$, $1+2$, $2+1$, $2+2$. Thus I feel that the definition of a sample mean clashes with it's application where you just take specific values from the population and add them up. I hope that makes sense.","['statistics', 'random-variables']"
1297035,What mistake have I made when trying to evaluate the limit $\lim \limits _ {n \to \infty}n - \sqrt{n+a} \sqrt{n+b}$?,"Suppose $a$ and $b$ are positive constants. $$\lim \limits _ {n \to \infty}n - \sqrt{n+a} \sqrt{n+b} = ?$$ What I did first: I rearranged $\sqrt{n+a} \sqrt{n+b} = n \sqrt{1+ \frac{a}{n}} \sqrt{1+ \frac{b}{n}}$ and so: $$\lim \limits _ {n \to \infty} n - n \sqrt{1+ \frac{a}{n}} \sqrt{1+ \frac{b}{n}} = 0$$
Because both $\frac{a}{n}$ and $\frac{b}{n}$ tend to $0$. What would give a correct answer: Plotting the function $$f(x) = x - \sqrt{x+a} \sqrt{x+b}$$
Clearly indicates that it has an asymptote in $- \frac{a+b}{2}$. This result can be obtained multiplying the numerator and the denominator by $n + \sqrt{n+a} \sqrt{n+b}$:
$$\lim \limits _ {n \to \infty}n - \sqrt{n+a} \sqrt{n+b} = $$
$$-\lim \limits _{n \to \infty} \frac {n(a+b)}{n + \sqrt{n+a} \sqrt{n+b}} - \lim \limits _{n \to \infty} \frac {ab}{n + \sqrt{n+a} \sqrt{n+b}}$$
The second limit is clearly $0$ and the first one gives the correct answer (dividing the numerator and denominator by $n$). Why the first way I tried is wrong? I might have done something silly but I cannot find it.","['sequences-and-series', 'calculus', 'limits']"
1297079,Proving that a trigonometric sum is in $L^2$,"How can I use Parseval's identity to prove that
$$f(x)=\sum_{k=1}^\infty \frac{\sin(kx)}{1+k}$$ is in $L^2(0,\pi)$? Thank you!","['summation', 'fourier-analysis', 'fourier-series', 'analysis', 'lebesgue-integral']"
1297096,Gaussian integral with a shift in the complex plane,"$$ \int_{-\infty}^\infty e^{-(x+ia)^2} \text{d}x $$ 
where $a\in \mathbb{R}$. I don't know where to start but have reasons to believe the answer is $\sqrt{\pi}$. Namely $\int_{-\infty}^\infty e^{-x^2} \text{d}x$. Problem is I feel insecure performing changes of variables when suddenly the variables range in $\mathbb{C}$. I don't even know if this can be done properly, least of all how.","['complex-analysis', 'complex-integration']"
1297100,Proving that matrix in equation is invertible,"The $2 \times 2$ matrix ${A}$ satisfies
${A}^2 - 4 {A} - 7 {I} = {0}$
where ${I}$ is the $2 \times 2$ identity matrix. Prove that ${A}$ is invertible. I have tried to solve it like a quadratic, but that doesn't work.  Any help is appreciated!","['algebra-precalculus', 'matrices']"
1297109,"If $f(0)=f(1)=f(2)=0$, $\forall x, \exists c, f(x)=\frac{1}{6}x(x-1)(x-2)f'''(c)$","Let $f:[0,2]\to \mathbb R$ be a $C^3$ function such that $f(0)=f(1)=f(2)=0$ Prove that $\forall x\in[0,2], \exists c\in[0,2], f(x)=\frac{1}{6}x(x-1)(x-2)f'''(c)$ This problem got me stuck. I guess one has to use the mean value theorem at some point. Using Rolle, there exists $0<\xi_1<\eta<\xi_2$ such that $f'(\xi_1)=f'(\xi_2)=0$ and $f''(\eta)=0$ .","['real-analysis', 'derivatives']"
1297123,Feynman Integration Problem,"$$ I = \frac{\pi^2}{8} - \int_0^1 \frac{\arctan(x)}{\sqrt{1-x^2}} \,dx $$
  Evaluate $I$ $$ I = \frac{\pi^2}{8} - \int_0^1 \frac{\arctan(x)}{\sqrt{1-x^2}} \,dx$$
$$f(a) = \int_0^1 \frac{\arctan(ax)}{\sqrt{1-x^2}} \,dx$$
After differentiating and integrating,
$$ f'(a) = \frac{\ln(a+\sqrt{1+a^2})}{a\sqrt{1+a^2}} $$
The final answer that we get is: $$ f(1) = \frac{\pi^2}{8} - \frac{\ln^2(1+\sqrt{2})}{2} $$
Could somebody please show me how this was done? $$$$ Also, how do we know how and where to introduce another variable (say $n$) to perform Feynman Integration? For example, in this case, how do we know that we should rewrite $$f(x) = \int_0^1 \frac{\arctan(x)}{\sqrt{1-x^2}} \,dx$$ as $$f(x,a) = \int_0^1 \frac{\arctan(ax)}{\sqrt{1-x^2}} \,dx$$ $$$$Please do help me!","['derivatives', 'calculus', 'definite-integrals', 'integration']"
1297163,The set of points in $A_n$ for infinitely many $n$ is measurable.,"This is part of an exercise from ""Real analysis for graduate students"" by Richard Bass: Let $m$ be a Lebesgue measure. Suppose for each $n$, $A_n$ is a Lebesgue measurable subset of $[0,1]$. Let $B$ consist of those points $x$ that are in infinitely many of the $A_n$. Show that $B$ is Lebesgue measurable. I'm in general undecided about what to use to prove that something is Lebesgue measurable. Is it a good way to use outer measure definition and try to show $m^*(E)=m^*(E\cap B)+ m(E\cap B^c)$, for instance. It seemed hard to prove this way for me, and I was wondering what is the best way. Thanks!","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1297189,Calculate tangent points of two circles.,"I have 2 circles with given center coordinates and radius.
And now I need to find the coordinates of all 8 tangent points to those circles? I found this site explaining exactly what I want do to: ""The points of tangency t_1 and t_2 for the four lines tangent to two circles with centers x_1 and x_2 and radii r_1 and r_2 are given by solving the simultaneous equations"" That makes sense to me. But I can't solve that analytically.
Can you help me with that?","['systems-of-equations', 'geometry']"
1297194,For which values of $x$ is the following series convergent: $\sum_0^\infty \frac{1}{n^x}\arctan\Bigl(\bigl(\frac{x-4}{x-1}\bigr)^n\Bigr)$,For which values of $x$ is the following series convergent? $$\sum_{n=1}^{\infty} \frac{1}{n^x}\arctan\Biggl(\biggl(\frac{x-4}{x-1}\biggr)^n\Biggr)$$,"['analysis', 'sequences-and-series', 'calculus', 'real-analysis']"
1297229,Calculate $\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n}$ [duplicate],"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 4 years ago . How can I calculate the following limit? I was thinking of applying Cesaro's theorem, but I'm getting nowhere. What should I do? $$\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n}$$","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
1297298,Explicit homeomorphism between open and closed rational intervals?,"Sierpiński's theorem states that every countable metric space without isolated points is homeomorphic to $\mathbb{Q}$. (A proof can be found here and a discussion here ). An immediate corollary is that the rational intervals $[0,1],(0,1),[0,1)$ are homeomorphic. However, the theorem's proof is not very constructive and in fact quite complicated. (It's not a trivial theorem). Is there a way to construct an explicit homeomorphism between these intervals?","['general-topology', 'constructive-mathematics']"
1297299,Skellam CDF Increasing vs Decreasing in a parameter,"I'm working with the following Poisson difference distribution:
$$\text{Prob}\{X_1-X_2 \geq 0\} $$
where $X_1 \sim$ Poisson $(\mu_1)$ is independent from $X_2 \sim$ Poisson $(\mu_2)$.
I need to understand the behavior of: 
$$\frac{\partial}{\partial \mu_1}\text{Prob}\{X_1-X_2 \geq 0\} $$ My intuition is that the CDF is increasing in $\mu_1$. However, my intuition proved to be wrong in many occasions : ) The Poisson difference distribution (Skellam distribution) has not a convenient closed form distribution, in particular, its PMF includes a BesselI function and it is not straightforward to take the derivative. Therefore, exploiting the fact that $X_1$ and $X_2$ are independent ""we can write"" (this is my claim): $$ 
\text{Prob}\{X_1-X_2 \geq 0\} = \sum_{k=1}^{\infty}\text{Prob}\{X_1=k\}\text{Prob}\{X_2\leq k\} 
$$ $$=\sum_{k=0}^{\infty}\text{Prob}\{X_1=k\} \sum_{h=0}^k\text{Prob}\{X_2=h\}  $$ For a generic $k$ $$e^{-\mu_1}\frac{\mu_1^k}{k!} e^{-\mu_2}\sum_{h=0}^k \frac{\mu_2^h}{h!} $$ In my particular case I have that $\mu_2 = v-\mu_1$. To be more specific, 
$\mu_1 = vx $ where $v >1$ and $x \in (0,1)$. So I have 
$$\frac{e^{-v}}{k!} \mu_1^k \sum_{h=0}^k \frac{\mu_2^h}{h!} $$ Forgetting the constant term I can show that the expression is increasing in $x$. 
Taking the derivative with respect to $x$ and studying the sign I get $$vk\mu_1^{k-1}\sum_{h=0}^k \frac{(1-\mu_1^h)}{h!} -v\mu_1^k\sum_{h=0}^k \frac{(1-\mu_1)^h}{h!} >0   $$ If and only if $$\frac{k}{v}>x $$ or $k > \mu_1$ if we just consider the mean. However, this contrasts the simulations I made using the ""proper"" CDF of the Skellam distribution; so I do not know how to approach the problem or where my fault is","['statistics', 'probability', 'calculus', 'probability-distributions']"
1297304,"examples of linear map $f:V \rightarrow V$, which is injective but not surjective","I am trying to find a linear map $f:V \rightarrow V$, which is injective but not surjective. I always thought that if the dimension of the domain and codomain are equal and the map is injective it implies that a map is surjective. Maybe we need an infinite basis of the vector space $V$? What can be an example of that? Thank you!","['vector-spaces', 'linear-algebra', 'functional-analysis', 'linear-transformations']"
1297309,"6 people are holding a show, one at a time, such that person $x$ has to go after person $y$ and person $z$. How many ways could the show be held?","Let's say the people are called $a$, $b$, $c$, $x$, $y$, $z$ My initial thinking was to go by fixing ""$x$"" in a certain position, so: $\underline {} \underline {} \underline {}\underline {}\underline {}\underline {x}$ Now for this configuration we have 5! combinations $\underline {}\underline {}\underline {}\underline {}\underline {x}\underline {}$ For this one, after the $x$, only $a$, $b$ and $c$ can go, so that's $3 \cdot 4!$. Similarly, I continued and got an answer in the $300$'s, which is not a possible given answer I have. What's wrong with my method?",['combinatorics']
1297320,Structure of the group $\{1+p\mathbb Z_p \}$,"In preparation for algebraic number theory I am reading Serre : A course in Arithmetic. I stuck in understanding a proof (p.17): Notation: $U_n=1+p^n\mathbb Z_p$ Actually there are many things which I don't understand... Why it holds that $(\alpha_n)^{p^{n-2}}\neq 1$ and $(\alpha_n)^{p^{n-1}}= 1$? Why $\phi_{n,\alpha}$ is an isomorphism? I see that is is an homomorphism, but  proving that its also bijective is not that easy for me, because its hard for me to imagine the group $U_1$/$U_n$ I also dont understand the last tree lines I know that I did understand only few things. In my opinion this book leaves out many arguments, so i hope that someone can make this clear for me. Thanks in advance!","['abstract-algebra', 'group-theory', 'p-adic-number-theory']"
1297330,the series: compute $ \sum_{n=1}^{\infty}\frac{1}{(4n^2-1)^4} $,"Compute
$$
\sum_{n=1}^{\infty}\frac{1}{(4n^2-1)^4}
$$ the result is $\frac{\pi^4+30\pi^2-384}{768}$, so I'm sure the sums $\sum\frac{1}{n^2}$ and $\sum\frac{1}{n^4}$ should appear in the solution. The standard method $\frac{1}{4n^2-1}=\frac{1}{2}(\frac{1}{2n-1}-\frac{1}{2n+1})$ allows to compute $\sum_{n=1}^{\infty}\frac{1}{4n^2-1}=\frac{1}{2}$ and $\sum_{n=1}^{\infty}\frac{1}{(4n^2-1)^2}=\frac{\pi^2-8}{16}$, what about higher powers?","['sequences-and-series', 'real-analysis']"
