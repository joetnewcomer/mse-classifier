question_id,title,body,tags
3314663,Alternative way of defining a topology,"tl;dr : In trying to come up with a way to characterize topologies in terms of neighborhoods (rather than open sets) I run into a weird, not-quite-equivalent-to-topology structure. I wonder if I can fix my definition to give actual topologies, or else what can be said about the structure I have defined. Definition : Given a set $X$ , an n-topology $\tau$ on a set $X$ assigns to each $x \in X$ a set $\tau_x \subseteq \mathcal P(X)$ satisfying the following constraints: $X \in \tau_x$ If $N \in \tau_x$ then $x \in N$ If $N \in \tau_x$ and $N' \supseteq N$ then $N' \in \tau_x$ If $N, N' \in \tau_x$ , then $N \cap N' \in \tau_x$ . We call the sets in $\tau_x$ the neighborhoods of $x$ . Clearly, given a topology on a set $X$ we get an n-topology: we take the sets $\tau_x$ to be the neighborhoods of $x \in X$ in the topological sense, as all sets which contain an open set which contains $x$ . Conversely, given an n-topology, we obtain a topology by declaring a set open if it is a neighborhood of all of its elements. Furthermore, we can define continuous functions on n-topological spaces by saying that $f : (X, \tau) \to (Y, \sigma)$ is n-continuous if $$
N \in \sigma_{f(x)} \implies f^{-1}(N) \in \tau_x.
$$ It appears that this notion coincides with our usual notion of continuous. Going from topology to n-topology to topology, we recover the original topology. However, going from n-topology to topology to n-topology, we might lose information. For example, we can define an n-topology on $\omega$ by stating that $\tau_0$ contains all cofinite sets containing 0, while $\tau_n$ for $n > 0$ contains only $\omega$ itself. This clearly satisfies the above conditions. If we turn it into a topology, we just get the indiscrete topology $\{\emptyset, \omega\}$ on $\omega$ , which we could also have gotten by taking $\tau_n = \{\omega\}$ for each $n \in \omega$ . Question : Can I add a condition to this notion of ""n-topology"" to make it an equivalent definition to ordinary topologies? Is the thing I call an n-topology something interesting -- has anyone else used it, and if so under what name?","['general-topology', 'definition']"
3314667,How to prove X = A $\cup$ B given subset conditions?,"Problem Given sets $\mathcal A$ , $\mathcal B$ , $\mathcal Y$ , let $\mathcal X$ be a set with the following properties: $\mathcal X$ $\supset$ $\mathcal A$ and $\mathcal X$ $\supset$ $\mathcal B$ , if $\mathcal Y$ $\supset$ $\mathcal A$ and $\mathcal Y$ $\supset$ $\mathcal B$ , then $\mathcal Y$ $\supset$ $\mathcal X$ Prove that $\mathcal X$ = $\mathcal A$ $\cup$ $\mathcal B$ . My work Let $\mathcal x$ be an element of set $\mathcal X$ and $\mathcal y$ be an element of set $\mathcal Y$ . If $\mathcal X \supset\mathcal A$ , then $\mathcal x$ $\in$ $\mathcal A$ , then $\mathcal x$ $\in$ $\mathcal X$ . 
 If $\mathcal X \supset\mathcal B$ , then $\mathcal y$ $\in$ $\mathcal B$ , then $\mathcal y$ $\in$ $\mathcal Y$ . If $\forall$ $\ x$ $\in$ $\mathcal A$ , $\ x$ $\in$ $\mathcal X$ ; and $\forall$ $\ y$ $\in$ $\mathcal B$ , $\ y$ $\in$ $\mathcal Y$ , then $\mathcal X = \mathcal A \cup \mathcal B$ . This is an introductory problem in a Real Analysis course I'm doing on my own. I'm an Engineer trying to acquire a deeper mathematical maturity. The book I'm following doesn't bring answers, ergo, the question. But more than a ""Right or Wrong"" answer, I'd like an evaluation concerning the rigor - or the lack thereof - of the answer I provided.",['elementary-set-theory']
3314669,Weak derivative under the integral sign,"Let $\Omega$ be a bounded and regular open subset $\Omega$ of $\mathbb{R}^N$ and $u:[0,\infty)\times \Omega\to \mathbb{R}$ be a smooth function (for example a smooth solution to a PDE). Thus the function $w=\min(0,u)$ has weak time derivative given by $w_t=u_t.1_{\{u \leq 0 \}}$ . Does the following ""weak differentiation under the integral sign"" holds? $$\frac{d}{dt}\int_\Omega w(t,x)dx=\int_\Omega \frac{\partial}{\partial t}w(t,x)dx,$$ for almost all $t\geq 0$ . We know that differentiation under the integral sign holds for $u$ because it is smooth. But I am wondering if it also holds for a function like $w=\min(0,u)$ which only has a weak derivative. My guess is that since $w$ has a weak derivative in time (real line), then it must be differentiable for almost all $t\geq 0$ (which is not necessarily true in higher dimension, for example differentiation with respect to space $x$ ). So $\int_\Omega w(t,x)dx$ must also be differentiable for almost all $t\geq 0$ and so we can use some kind of dominated convergence theorem.","['lebesgue-integral', 'real-analysis', 'partial-differential-equations', 'partial-derivative', 'weak-derivatives']"
3314670,"$7$ nouns, $5$ verbs and $2$ adjectives are written on blackboard.","$7$ nouns, $5$ verbs, and $2$ adjectives are written on a blackboard. We can form a sentence by choosing $1$ from each available set in any order. Without caring it makes sense or not, what is the number of ways of doing this? If we use a permutation and just do $7 \cdot 5 \cdot 2$ , it gives us $70$ . But the problem states that the sentence can be in any order. I am confused exactly how I am supposed to figure out the number of possibilities. Would you multiply $70$ by the number of possible arrangements? If so, what is that number?","['permutations', 'combinatorics']"
3314701,Find a two digit number $15$ more than $4$ times its reverse.,"Find a two digit number 15 more than 4 times its reverse. I acknowledge the answer is 91 since the reverse of 91 is 19, 4 times 19 is 76, which is 15 less than 91. I used trial and error, but I believe there is a more algebraically method to model this problem. I have developed something that looks as follows: $x = $ first digit $y = $ second digit $10x + y = 15 + 4 * (10y + x)$ $= 15 + 4(y * 10) + 4x$ $= 15 + 40y + 4x$ $10x = 15 + 39y + 4x$ $6x = 15 + 39y$ I'm not sure if i am heading in the correct direction. I am confused how i can change the last expression into anything else.",['algebra-precalculus']
3314711,Find if an ordinary differential equation is linear,"So my course shows me three differential equations: $$\dot x + x^2 = t$$ $$\dot x = (t^2+1)(x-1)$$ $$\dot x + x = t^2$$ The first one is not a linear ordinary differential equation (ODE) apparently, the other two are. Unfortunately, they don't show a clear way how to find out if an ODE is linear or not. So how we can find out if an ODE is linear? For the second one, I thought I bring it into standard form somehow: $$\dot x = (t^2+1)(x-1) = xt^2 + x - t^2 -1 = x(t^2+1)-t^2-1$$ If we say we let $p(t)=t^2+1$ and $q(t)=1+t^2$ , then we could say: $$\dot x = xp(t) - q(t) = ...$$ And so on, to simplify until we reach standard form of a linear ODE (or not). Is that the way to go? Or is there some other way to check if a ODE is linear?","['calculus', 'ordinary-differential-equations']"
3314742,Expectation of nonnegative random variable when passed through nonnegative increasing differentiable function,"I am having trouble proving the following result: Let $X$ be a nonnegative random variable and $g:\mathbb{R}\rightarrow\mathbb{R}$ a nonnegative strictly increasing differentiable function. Then $$\mathbb{E}g(X)=g(0)+\int_{0}^{\infty}g^{\prime}(x)\mathbb{P}(X>x)dx$$ I know that it should follow using integration by parts, but using integration by parts in the more abstract setting of probability is a bit confusing to me. Details would be appreciated.","['integration', 'expected-value', 'probability-theory', 'random-variables']"
3314810,The eigenvalue of Lie bracket,"Set $R = M_n(\mathbb{C})$ and let $f_A : R \to R$ be a $\mathbb{C}$ -linear map such that $$
f_A(X) = [X,A] = XA - AX.
$$ Obvious fact: Note that there are $a_{ij} \in \mathbb{C}$ such that $$
f_A^n (X) = \sum_{i+j=n} a_{ij} A^i X A^j.
$$ Thus if $A$ is nilpotent then $f_A$ is nilpotent, obviously. But the assumption "" $A$ is nilpotent"" is too strong. I want to extend this fact. My prediction: Assume that $f_A$ has a non-zero eigenvalue $\lambda \in \mathbb{C}$ . Then there are $\beta,\gamma \in \mathbb{C}$ which are eigenvalues of $A$ such that $\beta - \gamma = \lambda$ My effort Assume that $n=2$ . Let $X$ be a non-zero element of $E(\lambda,f_A)$ . Then $X^k \in E(k\lambda, f_A)$ . So we get $X$ is nilpotent. So there is a $P \in GL_2(\mathbb{C})$ such that $$
\Lambda := PXP^{-1} =  \begin{pmatrix} 0 &1 \\ 0& 0 \end{pmatrix}.
$$ Set $$
B=PAP^{-1} = \begin{pmatrix} a & b \\ c & d \end{pmatrix}.
$$ Then $[\Lambda, B] = \lambda \Lambda$ implies that $c=0$ and $d-a = \lambda$ . So we obtain $$
\Phi_A(x) = \Phi_B(x) = (x-a)(x-a-\lambda).
$$ My question: What is a proper extension of the ""obvious fact""? Is my prediction true? If so, how to prove ?","['proof-writing', 'linear-algebra', 'eigenvalues-eigenvectors']"
3314824,"Given a set (universal set) $Ω = \{1,2,3,4\}$, the smallest possible σ-algebra on $\Omega$ is this set $S = \{\{1,2,3,4\},\emptyset\}$, is it?","wiki gives this definition of sigma-algebra Let X be some set, and let ${\mathcal {P}}(X)$ represent its power set. Then a subset ${\displaystyle \Sigma \subseteq {\mathcal {P}}(X)}$ is called a σ-algebra if it satisfies the following three properties: X is in Σ, and X is considered to be the universal set in the following context. Σ is closed under complementation: If A is in Σ, then so is its complement, X \ A. Σ is closed under countable unions: If $A_1, A_2, A_3, ...$ are in Σ, then so is $A = A_1 ∪ A_2 ∪ A_3 ∪ …$ . since {X, ∅} satisfies condition (3), it follows that {X, ∅} is the smallest possible σ-algebra on X. Given this set (universal set) $\Omega = \{1,2,3,4\}$ , and then its power set \begin{equation*} 
{\mathcal {P}}(\Omega)=
\left\{\emptyset, \left\{1\right\}, \left\{2\right\}, \left\{3\right\}, \left\{4\right\}, \left\{1, 2\right\}, \left\{1, 3\right\}, \left\{1, 4\right\}, \left\{2, 3\right\}, \left\{2, 4\right\}, \left\{3, 4\right\}, \left\{1, 2, 3\right\}, \left\{1, 2, 4\right\}, \left\{1, 3, 4\right\}, \left\{2, 3, 4\right\}, \left\{1, 2, 3, 4\right\}\right\}
\end{equation*} so, the smallest possible σ-algebra on $\Omega$ is this set $S = \{\{1,2,3,4\},\emptyset\}$ , which has only 2 elements , is my understanding right?",['measure-theory']
3314864,Could *I* have come up with the definition of Compactness (and Connectedness)?,"Ok, buckle up for a rather long question. I've spent a large portion of today learning about compactness, stemming mainly from this wikipedia article about point-set topology. The article mentions three main things: continuity, connectedness, and compactness. I will address each in turn, but my question is mainly about the last one. Continuity: At least having gone through high school calculus and basic university analysis, I think people have a great intuitive understanding of continuity (and also differentiability I guess): smooth = yay!, jagged = fine-ish, holes/jumps = really bad :(. The wiki article describes this as ""taking nearby points to nearby points"", which I understand well enough that I think given a decade or something I could eventually have come up with the formal epsilon-delta definition for continuity: $$\forall \varepsilon >0, \exists \delta, \text{ s.t. } |x-x_{0}|<\delta \Rightarrow |f(x)-f(x_{0})|<\varepsilon $$ Connectedness: Similarly, I think people have a great intuition for connectedness (at least path connectedness), which the wiki article summarizes nicely as ""sets that cannot be divided into two pieces that are far apart"". Again, I think that given a decade or two I could have gone in the right direction at least for the formal definition of connectedness: a set that can't be represented as the union of two or more disjoint non-empty open subsets . First (Minor) Question: could we have a useful definition for connectedness being: ""a set that can't be represented as the union of two or more disjoint non-empty closed subsets""? Similarly, I feel like I could reasonably develop definitions for open sets (based on intuitions from number lines and basic high-school algebra/set theory), and completeness (basically the Least Upper Bound axiom/Cauchy sequences). However, there's one thing missing. Compactness. Never in a million years do I think I could have thought up of the definition that a set that can be ""can be covered by finitely many sets of arbitrarily small size."" I've looked at these five sites and some links therein: Why is compactness so important? What should be the intuition when working with compactness? https://www.math.ucla.edu/~tao/preprints/compactness.pdf https://www.reddit.com/r/math/comments/47h6hg/what_really_is_a_compact_set/ https://arxiv.org/abs/1006.4131 but none of them so far has really clicked with me. Many people emphasized that it's a generalized version of finiteness with ""fat blurry points"", and I also understand that by the Heine-Borel Theorem compactness is equivalent to ""closed and bounded"" in Euclidean space, but those two things seem so far apart that it just seems like a black-magic coincidence that they describe the same phenomenon. How would you motivate and explain the definition and concept of compactness to your students in such a way that they feel like they could have come up with it themselves, naturally, given a decade or two? If you start with ""it's a generalized version of finiteness"" it seems like a complete and utter coincidence that it happens to be equivalent to ""closed and bounded"". I mean of all the possible ""generalized finiteness formulations"", how did ours get it right? If you start with ""it's just another way of saying closed and bounded"", then students will feel that it's just more arbitrary confusion redefining things they already know (namely that of closed-ness and boundedness); furthermore, even if they did accept this explanation, they would have never figured out on their own that ""every open cover has a finite subcover $\iff$ closed and bounded"". ""Finite subcover"" just seems so out-of-left-field. And finally if you go the sequential compactness route (referring to Tao's paper here) students will just say ""ahh yes, the Bolzano-Weierstrass Theorem! Why need to give it a new name of compactness?"" Maybe I've missed something in my searches, but I hope this question isn't just a badly rehashed old question. I don't think my question is answered in the ""Pedagogical History of Compactness"" mainly because I don't want the convoluted history, but rather the simplest motivation and explanation based off modern curriculum and notation . -> Also, thank you to those who've commented/left an answer. I hope that this page and all the differing pedagogical interpretations presented will serve as a relatively complete and comprehensive guide for beginners learning compactness in the future. Please upvote answers you think are particularly insightful; as a novice, I would appreciate some expert judgement on the explanatory power of these answers.","['connectedness', 'motivation', 'general-topology', 'soft-question', 'compactness']"
3314884,Finding fundamental period of $f(x)=\sec($sin(x)$)$,"Find the fundamental period of $f(x)=\sec($ sin(x) $)$ . Choose the correct option. (A) $\frac{\pi}{2}$ (B) $2\pi$ (C) $\pi$ (D)Aperiodic We know the fundamental period of $\sin(x)$ is $2\pi$ . Since $\sec(x)$ is an even function, both negative and positive values of x having same magnitude give same value of $\sec(x)$ . Since | $\sin(x)$ | has a period $\pi$ , I concluded the fundamental period of $f(x)$ is $\pi$ . The answer is correct. Is there any other disciplined way to approach this question, since I used some logic to solve this problem.","['periodic-functions', 'trigonometry', 'functions']"
3314885,Limit of composite function at isolated points,"Paul's Online Notes ( link ) writes: I have some doubts about the above claim. In particular, I'm not sure if it's correct if $b$ is an isolated point of the domain of $f$ . I have tried to come up with the counterexample below. Is my counterexample mistaken? And if it isn't, how can we fix the above claim so that it becomes correct? Counterexample. Define $f:\left\{ 2\right\} \rightarrow\mathbb{R}$ by $f\left(2\right)=3$ . Define $g:\mathbb{R}\rightarrow\mathbb{R}$ by $g\left(x\right)=x+1$ Then $\lim_{x\rightarrow1}g\left(x\right)=2$ $f\left(x\right)$ is continuous at $2$ (because $2$ is an isolated point of the domain of $f$ ) $f\left(\lim_{x\rightarrow1}g\left(x\right)\right)=f\left(2\right)=3$ . However, $\lim_{x\rightarrow1}f\left(g\left(x\right)\right)$ does
not exist. (The composite function $f\circ g$ is not defined for any $x\neq 1$ .) And so, contrary to the above claim, $$\lim_{x\rightarrow1}f\left(g\left(x\right)\right)\neq f\left(\lim_{x\rightarrow1}g\left(x\right)\right).$$ In response to Hyperion and Rick's comments, here is a screenshot from Abbott (2015, p. 122, Understanding Analysis ). See especially the highlighted paragraph:","['limits', 'calculus', 'continuity', 'real-analysis']"
3314893,fair die is rolled until a number that has been obtained before is repeated,"A fair die is rolled until a number that has been obtained before is repeated. Let the random variable X denote the number of rolls. Compute the probability
mass function of X. Here's how I tackled this problem. Could you please check if this true? If it is not could you please hint We have that supp(X) is {2,3,4,5,6,7} Then P(X=2)=(6/6)(1/6)= 1/6 because we have 1/6 choices that we obtain the previous number. P(X=3)=(5/6)(2/6)=10/36. Because 5/6 is the second roll where it is the probability that we do not land the first value of the roll and 2/6 is the probability that we land the first two values of the rolls. P(X=4)=(5.4.3)/6^3 P(X=5)=(5.4.3.4)/6^4 P(X=6)=(5.4.3.2.5)/6^5 P(X=7)=(5.4.3.2.1.6)/6^6","['dice', 'probability']"
3314897,Can we approximate uniformly a function defined on a subset with smooth functions?,"Let $\mathbb{D}^n \subseteq \mathbb{R}^n$ be the closed $n$ -dimensional unit ball. Suppose we are given an open subset $U \subseteq \mathbb{D}^n$ of full measure in $\mathbb{D}^n$ , and a smooth bounded function $f:U \to \mathbb{R}$ . Do there exist smooth functions $f_k:\mathbb{D}^n \to \mathbb{R}$ which converge uniformly to $f$ ? Note that that the derivatives of the original $f$ may explode when we approach $\partial U$ . In my specific case $U$ has Hausdorff dimension $\le n-1$ , but I am not sure if it matters.","['approximation', 'singularity', 'real-analysis', 'multivariable-calculus', 'uniform-convergence']"
3314967,What is the probability of a biased coin coming up heads given that a liar is claiming that the coin came up heads?,"A biased coin is tossed. Probability of Head - $\frac{1}{8}$ Probability of Tail - $\frac{7}{8}$ A liar watches the coin toss. Probability of his lying is $\frac{3}{4}$ and telling the truth is $\frac{1}{4}$ . He says that that the outcome is Head. What is the probability that the coin has truly turned Head? My Attempt : I used the formula: $$P(A \mid B) = \frac{P(A\cap B)}{P(B)}$$ $\ \ \ \ \ \ $ P(it is head GIVEN liar said it's head) = P(it's head AND liar said it's head) / P(liar said it's head) or, P(it is head GIVEN liar said it's head) = $\frac{ \frac{1}{8} \frac{1}{4} }{ \frac{7}{8}\frac{3}{4} + \frac{1}{8}\frac{1}{4} }$ [using a probability tree will be helpful here] or, P(it is head GIVEN liar said it's head) = $\frac{1}{22}$ The Question: Is the method I used wrong in any way? Some others I have talked to are saying the answer will be $\frac{1}{4}$ . Their reasoning is this: since the liar lies 3 times out of 4 and he said it is head, then the probability of it being head is 1/4. So who is right? What will be the answer?","['conditional-probability', 'probability']"
3314994,Prove $\lim_{n \to \infty} ( \frac{\psi(-1/2+n i )- \psi(-1/2-n i)}{2i}- \frac{n}{n^2+1/4} ) = \frac{\pi}{2}$,"Consider the sequence: $$A_n=  \frac{\psi(-1/2+n i )- \psi(-1/2-n i)}{2i}- \frac{n}{n^2+1/4} $$ How would you prove that: $$\lim_{n \to \infty} A_n= \frac{\pi}{2}$$ This sequence converges extremely fast, in fact for $n=10$ we have: $$\left( \frac{\psi(-1/2+10 i )- \psi(-1/2-10 i)}{2i}- \frac{10}{100+1/4} \right)=  \\ = 1.57079632679489661923132169 \ldots$$ Where all the digits shown are the same as for $\pi/2$ . I have found this limit by considering the usual integral $\int_0^1 \frac{dx}{1+x^2}$ , using the midpoint rule to derive a Riemann sum, then finding its explicit hypergeometric form, which simplified to the difference of digammas. I was quite surprised by the accuracy of this method, because it only takes $10$ points to get $25$ correct digits, so my questions are: What other proofs can you offer for the limit? Why does it converge so fast? Is it because the midpoint rule is very accurate and the integrated function is very nice? The motivation for this question is of course, generalization of this result, because any integral of the form: $$\int_a^b \frac{P(x)}{Q(x)} c^x dx$$ where $P,Q$ are polynomials, can be approximated by a hypergeometric Riemann sum.","['limits', 'riemann-sum', 'digamma-function']"
3315010,"Prove that if $v$ is an eigenvector for A, than $v$ is also and eigenvector for $adj(A)$.","Let $A$ be a complex square matrix and $\operatorname{adj}(A)$ its adjugate (so the entries of $\operatorname{adj}A$ are minors of $A$ , up to sign).
Prove that if $v$ is an eigenvector for $A$ , than $v$ is also an eigenvector for $\operatorname{adj}(A)$ .","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3315050,Uniqueness of solutions of a Cauchy problem,"Consider the Cauchy problem $$\begin{cases}y'(x)=\sqrt{y(x)}\\ y(0)=0\end{cases}$$ Clearly $y'(x)=\sqrt{y(x)}$ is a differential equation that can be solved with the separation of the variables, in fact: $y'(x)=a(x)b(y(x))$ where $a(x)=1$ is continuous on $I=\mathbb{R}$ , while $b(y(x))=\sqrt{y(x)}$ is continuous on $J=[0,+\infty)$ , but it's not a lipschitzian function in a neighborhood of $0.$ .. I can't use Picard–Lindelöf theorem. The uniqueness is not guaranteed. Now the question: can I use the separation of variables, if I can't find a neighborhood of $0$ such that $b(y)\ne 0$ ?","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3315086,Detailed computations of geodesic equation (using Langrangian or not),"Given a manifold and a path $\gamma$ on this manifold, I want to know if this path is actually a geodesic. From what I read, I should compute the geodesic equation with that path, then check if it equals zero. I should hence compute : ${d^2 x^\mu \over ds^2}+\Gamma^\mu {}_{\alpha \beta}{d x^\alpha \over ds}{d x^\beta \over ds}$ Where, if I understand correctly, $s$ is the variable that parametrises $\gamma$ , and $x^\mu$ are the components of $\gamma$ in some generalised coordinate system. Still understanding Christoffel symbols is really hard to me, and I might not be ready using these yet. I read there is another (probably simpler) formulation using a Lagrangian, which would need me to compute, if I'm right : $\frac{\partial \dot{\gamma}}{\partial x^\mu}
- \frac{\mathrm d}{\mathrm ds} \left(\frac{\partial \dot{\gamma}}{\partial \dot{x}^\mu}\right)$ Again, I am failing manipulating such expressions. I would like you to help me with this simple example : in $\mathbb{R}^3$ , let the manifold be the sphere of radius $1$ and center $O$ and we consider : $\gamma : s \mapsto \begin{pmatrix}\cos s \\ \sin s \\ 0\end{pmatrix}$ This obviously parametrises a great circle of the sphere, and hence is a geodesic. So I already know our computations should give us $0$ , yet and I am failing getting it. We suppose we have euclidean metric. Computing $\dot{\gamma} : s \mapsto \begin{pmatrix}-\sin s \\ \cos s \\ 0\end{pmatrix}$ is not what poses a problem. To my understanding, we have $x^1 = \cos s$ , so what does $\frac{\partial (-\sin s)}{\cos s}$ worth ? Does it mean I should express $-{\sin s}$ from $\cos s$ , which would give something like $-{\sin s} = \pm \sqrt{1 - (\cos s)^2}$ ? Some tips about me : I understand Einstein summation convention ; I should be familiar with Leibniz differential notations, though detailing steps does not harm ; I have been initiated to tensors, but can not pretend mastering them ; I know some vector differential operator, but would rather avoid using nabla notation ; I know the Lagrangian is somehow a ""potential"" we want to minimise, but I have no intuition about it. Thanks for your attention.","['differential', 'geodesic', 'euler-lagrange-equation', 'differential-geometry']"
3315113,Which polytopes are $01$-polytopes?,"Are there some basic criteria by which to check whether a polytope $P\subset\Bbb R^n$ is a $01$ -polytope, that is, can be rotated and scaled to have vertices in $\{0,1\}^n$ , maybe even by using higher-dimensional space? I am especially interested in necessary conditions. In particuar, which of the regular or uniform polytopes is a $01$ -polytopes?  Here are some examples for which I know that they are: simplices (and also hyper-simplices ) . $n$ -cubes (and also demi-cubes ). $n$ -crosspolytopes . cartesian products of $01$ -polytopes (e.g. certain prisms, duo-prisms , ...). I know that polytopes with a 5-fold rotational symmetry are not $01$ -polytopes, e.g. the regular dodecahedron or 600-cell, since they do not have an embedding with purely rational vertex-coordinates. I also read that the cuboctahedron is not a $01$ -polytope, but I have no argument for that. What about the 24-cell ?","['polytopes', 'geometry', 'reference-request', 'combinatorics', 'symmetry']"
3315129,"If $\sin32^{\circ}=k$ and $\cos x=1-2k^2, \alpha$ and $\beta$ are the two values of $x$ between $0^{\circ}$ and $360^{\circ}$ with $\alpha<\beta$","A) $\alpha+\beta=180^{\circ}$ B) $\beta-\alpha=200^{\circ}$ C) $\beta=4\alpha+40^{\circ}$ D) $\beta=5\alpha-20^{\circ}$ I solved it by taking $$\cos x=1-2\sin^232^{\circ}$$ Therefore $x=64$ So the two values of $x$ can be $64$ and $334$ , so B) should be the right answer, but the answer is actually c. Where am I going wrong?",['trigonometry']
3315131,Non existing limit,"I was having some fun with limits, until I encountered this: $$ \lim_{x\to0} \frac{\log(\vert x \vert (1+x^2)^{1/3}-\sin{x})}{\log(\vert x \vert)} $$ To me the limit in this case does not exists, so I tried computing it from right and left. Let's start from right. $$ \lim_{x\to0^+} \frac{\log(x (1+x^2)^{1/3}-\sin{x})}{\log(x)} $$ Here I would try to use Hopital theorem, but I want to avoid that if possible. I tried using Taylor polynomial, and I simplify everything getting to the following limit: $$ \lim_{x\to0} \frac{\log(\frac{x^3}{2})}{\log(x)}$$ Applying Hopital I get that this limit is $3$ , however I do not find the same using Taylor expansion. Is it right that this limit is $3$ ?","['limits', 'proof-verification']"
3315160,$\epsilon - N$ proof of $\sqrt{4n^2+n} - 2n \rightarrow \frac{1}{4}$,"I have the following proof for $\lim_{n\rightarrow\infty} \sqrt{4n^2+n} - 2n = \frac{1}{4}$ and was wondering if it was correct. Note that $\sqrt{4n^2+n} - 2n = \frac{n}{\sqrt{4n^2+n} + 2n}$ . $$\left|\frac{n}{\sqrt{4n^2+n} + 2n} - \frac{1}{4}\right| \\
= \left|\frac{2n - \sqrt{4n^2+n}}{4(\sqrt{4n^2+n} + 2n)}\right|=\left|\frac{\sqrt{4n^2+n} - 2n}{4(\sqrt{4n^2+n} + 2n)}\right|\\
 = \left|\frac{n}{4(\sqrt{4n^2+n} + 2n)^2}\right| \leq \left|\frac{n}{4(4n)^2}\right| = \left|\frac{n}{64n^2}\right| \\
= \left|\frac{1}{64n}\right| < \epsilon \\
\implies n>\frac{1}{64\epsilon}$$","['limits', 'proof-verification', 'sequences-and-series']"
3315165,Lottery numbers and chaos/quantum theory,"Please settle an argument if you would be so kind. In a group chat, one person took the position 1,2,3,4,5,6 has as much chance of coming out in the lottery as any other six numbers you define, e.g. 3,11,23,33,34,46. A second person took the position that this was untrue because: Those numbers include the randomness of chaos theory, but a perfect sequential number doesn't have that so its chances become slimmer. If you drill down to the mathematics of it at least. Person two also went to go on to discuss quantum theory as well. So from a pure statistics point of view, I believe, the first person is correct. My question for you good folks is in two parts (mostly the second part): Is the first quote correct? Even if the first person is correct, are there any theory/basis for the second quote when it comes to the real-world execution of a lottery? Ideally something I can look up and read more about. It's entirely possible they're remembering something valid, but are not quoting it properly.","['chaos-theory', 'statistics']"
3315193,Which one of these ways to solve a simple Trig equation is more correct?,"So I'm looking at two different textbooks here and in the beginner practice questions there's simple stuff like $\sin(2x)=-1/2$ with a standard domain of $0$ to $3\pi$ . In one of the textbooks the results for X are simply $x=7\pi/12$ and $x=11\pi/12$ . In the other one the domain gets multiplied by $2$ , because of $2x$ and is now $0$ to $2x$ to $6\pi$ and the results for X are now $7\pi/12$ , $11\pi/12$ , $19\pi/12$ , $23\pi/12$ , $31\pi/12$ and $35\pi/12$ . Which one should I use? First or second one? Thanks in advance.","['calculus', 'trigonometry']"
3315324,Prove that $\sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k$ converges using a comparison,"I have been asked to prove that \begin{align*}
\sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k
\end{align*} converges. I beleive that I was able to do it using a logarithm test with two applications of L'Hopital, but I have been given a hint that it can be done easily with a comparison. However, I am at a loss for which what I can compare it to. Any help would be greatly appreciated.","['sequences-and-series', 'real-analysis']"
3315327,Find Uniform Minimum Variance Unbiased estimator (UMVU) using Lehmann Scheffé - showing statistic is complete,"Let $X_1,...,X_n$ be independent copies of a real-valued random variable $X$ where $X$ has Lebesgue density \begin{align*}
p_\theta(x) = \begin{cases} \exp(\theta-x),\quad x>\theta  \\ 
0, \quad\quad\quad\quad\;\ x\leq \theta, \end{cases}
\end{align*} where $\theta\in \mathbb{R}$ is an unknown parameter.
Let $S:=\min(X_1,...,X_n)$ . Find the Uniform Minimum Variance Unbiased (UMVU) estimator of $\theta$ . I already know that $S$ is sufficient for $\theta$ and that $T:=S-1/n$ is an unbiased estimator of $\theta.$ My idea is to apply the Lehmann-Scheffé thm. since then the UMVU is given by \begin{align*}
\mathbb{E}[T|S]=\mathbb{E}[S-1/n|S]=S-1/n.
\end{align*} Is this the correct approach?
If yes, for applying Lehmann-Scheffé, I would also need that S is a complete statistic. How do I show this properly? Edit : I tried to show completeness by definition, i.e. I setup the equation $\mathbb{E}_\theta[g(S)]=0 \;\forall \theta$ for some function $g$ and now want to show that $g(S)=0 \; \mathbb{P}_\theta$ -a.s. for all $\theta$ .
Since the $X_i$ are iid it is easy to see that the cdf is $F_S(x)=1-(1-P_\theta(x))^n$ , where $P_\theta(x)$ is the cdf of $X_i$ . By taking the derivative we get the pdf for $S$ : $f_S(x)=n\cdot p_\theta(x)(1-P_\theta (x))^{n-1}$ . $P_\theta (x)$ can be easily calculated and we get \begin{align*}
f_S(x)=n\cdot e^{n(\theta-x)}.
\end{align*} Hence, $\mathbb{E}_\theta[g(S)]=\int_\theta^\infty g(x)ne^{n(\theta-x)}dx$ has to be $0$ . Is it now enough to say that $g(S)=0 \; \mathbb{P}_\theta$ -a.s. for all $\theta$ , since the exponential function is always positive? Or is there a more rigorous way to show it?","['statistical-inference', 'statistics', 'parameter-estimation', 'exponential-distribution']"
3315330,Why are processes with stationary independent increments nonstationary?,"This answer states that any process with stationary independent increments is nonstationary. Why?  Specifically: Let $X(t-s) = N(t) - N(s)$ have distribution $F(t-s)$ for all $s\leq t$ [increments are stationary] and $\{X(t_i-s_i) : i\in{1,\dots,n}\}$ are independent whenever the $[s_i,t_i]$ overlap only at endpoints if at all. The claim then is that it's impossible that $$N(t_1)=y_1, N(t_2)=y_2,\ldots,N(t_m)=y_m$$ and $$N(t_1+h)=y_1, N(t_2+h)=y_2,\ldots,N(t_m+h)=y_m$$ must have the same distribution.
I don't see why that must be the case. I suspect that this has been answered previously, but I haven't managed to find it.  Perhaps there is something obvious that I'm just not seeing.","['levy-processes', 'stochastic-processes', 'stationary-processes', 'probability-theory']"
3315333,Showing $\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} $,"Show that $$\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} $$ I tried to find a polynomial that had its roots, but the degree grows too fast and I'm getting lost.","['calculus', 'trigonometry']"
3315358,"Show $f(f(b))-f(f(a))=(f'(c))^2(b-a)$ for some $c \in (a, b)$","Let $f:[a,b]\rightarrow [a,b]$ be a differentiable function with continuous and positive first derivative. Prove that there exists $c\in(a,b)$ ,such that $$f(f(b))-f(f(a))=(f'(c))^2(b-a).$$ My Attempt: I approached the LHS in following manner: $$\left(\frac{f(f(b))-f(f(a))}{f(b)-f(a)}\right)\left(\frac{f(b)-f(a)}{b-a}\right)=(f'(c))^2$$ But I am not able to decide which function to use so that LMVT may be applied","['derivatives', 'real-analysis']"
3315420,Grothendieck Residue,"In the article: Residues Of Codimension one Singular Holomorphic Distribution,  the author : Takeshi Izawa, states that: Theorem: Let $X$ an $n$ -dimensional compact complex manifold and $\mathcal{G}$ a rank-one locally-free subsheaf of $\Omega_{X}$ . We assume that the singular supports of $\Omega_{X}/ \mathcal{G}$ are all isolated. Then we have: $$ \int_{X}c_{n}(\Omega_{X} \otimes \mathcal{G}^{\vee}) = \displaystyle \sum_{j = 1}^{k}\text{Res}_{p_{j}}  \left[
\begin{array}{cccc}
df_{1}^{(j)} \wedge & \cdots & \wedge \,\, df_{n}^{(j)}\\
f_{1}^{(j)} \wedge & \cdots & \wedge f_{n}^{(j)}
\end{array}
\right] $$ where above there is the Grothendieck residue. In this article, the author provides no example of how to calculate this residue. The Distribution $\mathscr{F}$ of codimension one on $\mathbb{P}^{3}$ induced by: $$\omega = (z_{0}^{2} + z_{1}^{2} + z_{2}^{2})dz_{3} - (z_{3}z_{0} +  z_{2}z_{1})dz_{0} + (z_{2}z_{0} - z_{3}z_{1})dz_{1} - z_{3}z_{2}dz_{2}$$ It has as singular scheme : $\lbrace 2[i : -1 : 0 : 0], 2[i : 1 : 0 : 0], [0 : 0 : 0 : 1] \rbrace$ . Frankly, I don't know how to calculate the Grothendieck residue for singular points for the above distribution.  References on this subject and examples will be greatly appreciated. Thanks a lot.","['complex-analysis', 'residue-calculus', 'algebraic-geometry']"
3315531,"If an angle $\theta$ is not constructable, then $\cos\theta$ is not constructable.","Claim: if an angle $\theta$ is not constructable, then $\cos\theta$ is not constructable. I am at the very end of a proof, and I suspect this claim is true and it would help me very much in this proof. Does anyone have any insight on this? I've been trying for a bit, drawing it out, and I cannot think of a method to prove it. Any guidance is appreciated. Edit:
I have since tried something that seems to make sense to me. I use a previous result that the square roots of positive constructable numbers are constructable and that the constructable numbers form a number field. So I instead prove the contrapositive. I assume $\cos\theta$ is constructable. I draw a line and mark $\cos\theta$ on it. Since $\cos\theta$ is constructable, it follows that $\sqrt{1 - \cos^2\theta}$ is constructable. I construct a bisector at one end of $\cos\theta$ and mark $\sqrt{1 - \cos^2\theta}$ on it so that they are end-to-end. Then, using straightedge, connect their opposite ends. So the non-right angle which is next to $\cos\theta$ must be $\theta$ . Edit: Thanks for the help. I understand now.","['elementary-set-theory', 'geometric-construction']"
3315558,Solving $(xy)y'= x^2+3y^2$,"I am having a very frustrating time with the back book that says my answer is way off but to me everything looks fine: \begin{align*}
(xy)y'&= x^2+3y^2\\
y' &= \frac{x^2}{xy} + \frac{3y^2}{xy}\\
y' &= \frac{x}{y} + \frac{3y}{x}\\
y' &= \frac{1}{v} + 3v\\
y' &= \frac{1 + 3v^2}{v}\\
v+\frac{dv}{dx}x &= \frac{1+3v^2}{v}\\
\frac{dv}{dx}x&= \frac{1+3v^2-v^2}{v}\\
\frac{dv}{dx}x &= \frac{1+2v^2}{v}\\
\int \frac{v}{2v^2+1}\,dv &= \int\frac{1}{x}\,dx\\
u &= 2v^2+1\\
du &= 4v\,dv\\
dv &= \frac{1}{4v}\,du\\
\int \frac{v}{u} \frac{1}{4v}\,du &= \int \frac{1}{x} \,dx\\
\int \frac{1}{4u}\,du &= \ln|x| + c\\
\frac{1}{4} \int \frac{1}{u}\,du &= \ln|x| +c\\
\frac{1}{4} \ln|2v^2 + 1| &= \ln |x| + c\\
\ln|2v^2 + 1|&= 4\ln|x|+c\\
2v^2 + 1 &= e^{4\ln|x|}e^c\\
2v^2 + 1 &= Cx^4\\
2v^2 &= Cx^4\\
v^2 &= Cx^4\\
\frac{y}{x} &= \sqrt{Cx^4}\\
y &= x\sqrt{Cx^4}
\end{align*} However the book says the answer is $x^2 + 2y^2 = Cx^6.$ I am fairly sure there are no mistakes.",['ordinary-differential-equations']
3315564,Deriving governing equation for heat transfer: why are $\Delta y$ and $\Delta z$ included?,"My textbook preliminarily describes the governing equation for heat transfer as follows: $$\text{Energy In - Energy Out + Energy Generated = Energy Stored}$$ It then goes on to derive the heat transfer equation by only considering heat flow in the $x$ -direction: $$\text{Energy in during time $\Delta t$} = (q''_x \Delta y \Delta z + [u \Delta y \Delta z \rho c_p(T - T_R)]_x) \Delta t$$ $$\text{Energy out during time $\Delta t$} = (q''_{x + \Delta x} \Delta y \Delta z + [u \Delta y \Delta z \rho c_p(T - T_R)]_{x + \Delta x}) \Delta t$$ $$\text{Energy generated during time $\Delta t$} = Q \Delta x \Delta y \Delta z \Delta t$$ $$\text{Energy stored during time $\Delta t$} = \Delta x \Delta y \Delta z \rho c_p \Delta T$$ If we are only considering heat flow in the $x$ -direction, then why are all $\Delta y$ and $\Delta z$ included in these equations? What purpose do they serve? I would greatly appreciate it if people could please take the time to clarify this.","['multivariable-calculus', 'mathematical-modeling', 'heat-equation', 'partial-differential-equations']"
3315571,An intriguing recursion,"Let $x(1) = 1, x(k+1) = ax(k)+ bk, y(k) = -1 +a^{-k}x(k)$ . This recursion seems quite intractable, but it has some interesting features and it is much more friendly than it looks at first glance. Here $a, b$ are two positive parameters, with $a>1$ . Let $g(a,b) =\lim_{k\rightarrow\infty} y(k)$ . It is probably easy to establish that $g(a, b) = b f(a)$ where $f(a)$ is a smooth function. Values of $f(a)$ for various $a$ 's are pictured below. It is possible that if $a$ is a rational number, then $f(a)$ is also a rational number? This happens frequently. More specifically, my questions are: Questions Find a good approximation for $f(a)$ . Or can you find an exact formula for $f(a)$ ? Is $f(8)$ a rational number? The last question is very, very important to me as it has potential applications in finding a standard mathematical constant which is a normal number. My wish is that $f(8)$ is not a rational number, though it seems at first glance that the contrary should be true, unfortunately.","['number-theory', 'irrational-numbers', 'recurrence-relations', 'sequences-and-series', 'convergence-divergence']"
3315592,Which of the following relations is an equivalence relation? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I'm struggling a bit with this question. 
Here are the choices R1:={(a,b)∈Z×Z | 8 divides (a−b)} R2:={(a,b)∈Z×Z | 8 divides (a+b)}. R3:={(a,b)∈Z×Z | a⋅b is divisible by 25 but a,b are not}. R4={(a,b)∈Z×Z | a⋅b is divisible by 36 but a,b are not} R5={(a,b)∈Z×Z | |a−b| is a prime number} Thanks for the feedback. I've edited the original question below: I know that equivalence relations are reflexive, symmetric and transitive. 
This I went through each option and followed these 3 types of relations. For R1
I considered a - b such that I get a multiple of 8. For example (24, 16) (16,8) (8,8). these seem to work so I assumed it's equivalence. For R2
I followed the same approach. And found that it, too, was an equivalence relationship. I followed the same process for the rest of the options. And found them to be equivalent except for the last one (which is not) For R5
aRb would not work for a reflexive relationship since if a-b then 0, which is not prime. MY CONFUSION:
I get confused because it seems that there are certain pairs inside each relationship that follow the properties for equivalence and some that don't. For a relation to be an equivalence relation do all pairs have to meet the criteria or just some? Thanks,
K","['equivalence-relations', 'discrete-mathematics']"
3315606,Find every $n$: $n^2 + 340 = m^2$,"Let $n$ , $m \in N$ . The problem asks to find every natural number $ n $ such that: $ n^2 + 340 = m^2 $ I tried to solve the equation like this: $ n^2 - m^2 = 340 $ $ (n + m)(n - m) = 2^2 * 5 * 17 $ I listed all possible pairs of dividers of 340: $(1, 340), (2, 170), (4, 85), (5, 68), (10, 34), (20, 17)$ I set up six linear systems; only two gave me integers. $$
\left\{ 
\begin{array}{c}
m+n=170 \\
m-n=2   \\
\end{array}
\right. 
$$ $m = 86, n = 84$ $$
\left\{ 
\begin{array}{c}
m+n=34 \\ 
m-n=10 \\ 
\end{array}
\right. 
$$ $m = 22, n = 12$ I posted this problem because I don't have the solution. Did I make any mistake? Could the problem be solved in a quicker way? Thanks.","['contest-math', 'recreational-mathematics', 'discrete-mathematics']"
3315619,meromorphic function with period one on the upper half plane,"Let $H$ be the upper half complex plane and $f$ be a meromorphic function on $H$ . I wonder how to show that if $f$ satisfies $f(z+1)=f(z)$ for all $z\in H$ , then $f$ can be written as $$f(z)=\tilde{f}(e^{2\pi i z}),$$ where $\tilde{f}$ is meromorphic in the unit disk with the origin removed. I think here we are supposed to take something like $\tilde{f}=f\circ \log$ but I don't know how to prove it formally and use the condition $f(z+1)=f(z)$ . The original of this question is from Serre's a course in arithmetic, page 80",['complex-analysis']
3315641,Name of functions that are similar to atan2,There was a grouping I saw once of functions that are similar to atan2 where the Y result can only ever be below 1 and over -1 and the closer the value is to the maximum or minimum the longer it takes to reach it on the X axis (until infinity). Does anyone know the name of these functions?,['trigonometry']
3315693,Using entropy to determine if a sentence is likely to be valid English,"During my course of study for a cryptography class, I had to develop a simple Python script that would ""bruteforce"" the ciphertext for a Caesar Cipher. As an additional exercise, I wanted the script to also automatically determine which of the 26 outputs is most likely to be the correct answer. To do this, I decided to calculate the bits of entropy for each calculated string to see if I can use this to highlight the correct answer. The specific equation being: $H(X) = -\sum p_c \times log_2(p_c)$ , where $p_c$ is the probability of a letter appearing in an English word according to a letter frequency chart. (i.e. http://pi.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.html ) This approach appears to have worked. In all of my test cases, the correct answer was the one with the highest entropy. For example: Ciphertext: QNYYQJ UNLLD BJSY YT YMJ RFWPJY
Most Likely Plaintext (ROT 5): LITTLE PIGGY WENT TO THE MARKET (H = 6.365)
----------------------
ROT 0:  QNYYQJ UNLLD BJSY YT YMJ RFWPJY (H = 3.399)
ROT 1:  PMXXPI TMKKC AIRX XS XLI QEVOIX (H = 3.946)
ROT 2:  OLWWOH SLJJB ZHQW WR WKH PDUNHW (H = 3.993)
ROT 3:  NKVVNG RKIIA YGPV VQ VJG OCTMGV (H = 3.734)
ROT 4:  MJUUMF QJHHZ XFOU UP UIF NBSLFU (H = 3.655)
ROT 5:  LITTLE PIGGY WENT TO THE MARKET (H = 6.365)
ROT 6:  KHSSKD OHFFX VDMS SN SGD LZQJDS (H = 4.224)
...snip...
ROT 24: SPAASL WPNNF DLUA AV AOL THYRLA (H = 5.611)
ROT 25: ROZZRK VOMME CKTZ ZU ZNK SGXQKZ (H = 3.275) So it appears to work, at least for these few test cases. What I'm confused about is, why does it work and what exactly am I measuring? I initially assumed that the correct answer would have the lowest entropy since it ""would be the least random"". But it turned out to be the one with the highest. Did I happen to use the entropy formula to calculate something that appears to be useful but isn't actually entropy at all? Edit: The function in question. # Calculate the bits of entropy for the given string based on English letter frequencies
def entropy(input_string):
    # Letter Frequency Chart for English
    freq = { 'E': 0.1202, 'T': 0.091, ...snip... }

    # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:
    # H = -sum of (p(x) * log[p(x)]_2)
    total_entropy = 0
    for letter in input_string:
        total_entropy += freq[letter] * math.log(freq[letter], 2)

    return -(total_entropy) Example Output: >>> entropy(""LITTLE PIGGY WENT TO THE MARKET"")
6.365324803946881
>>> entropy(""QNYYQJ UNLLD BJSY YT YMJ RFWPJY"")
3.398563530183954 Final Edit: Just adding the final function for any future students who may stumble across this question. def entropy(s):
    # Letter Frequency Chart for English
    freq = { 
        'E': 0.1202, 'T': 0.091, 'A': 0.0812, 'O': 0.0768, 'I': 0.0731,
        'N': 0.0695, 'S': 0.0628, 'R': 0.0602, 'H': 0.0592, 'D': 0.0432, 
        'L': 0.0398, 'U': 0.0288, 'C': .0271, 'M': 0.0261, 'F': 0.023, 
        'Y': 0.0211, 'W': 0.0209, 'G': 0.0203, 'P': 0.0182, 'B': 0.0149, 
        'V': 0.0111, 'K': 0.0069, 'X': 0.0017, 'Q': 0.0011, 'J': 0.001, 
        'Z': 0.0007 
    }
    ascii_range = (65, 90)

    # Ensure the string's case matches the dictionary keys
    s = s.upper()

    # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:
    # H = [sum of (-log[p(x)]_2)] / len(s)
    total_entropy = 0
    for c in s:
        if(ord(c) >= ascii_range[0] and ord(c) <= ascii_range[1]): # Only compute for values of A-Z
            total_entropy += -math.log(freq[c], 2)

    total_entropy = total_entropy / len(s)

    return total_entropy Example Output: >>> entropy(""TEST"")
3.491390529605717
>>> entropy(""ZLYZ"")
7.794603966207939","['python', 'entropy', 'probability']"
3315717,Calculating value of series by taking the difference,Apologies if this is a basic question! I'm trying to understand a solution to a problem I was solving. The author suggests a trick to calculate expected value by multiplying the expected value series by 0.5 (line 2) and taking the difference (line 3): $E(X) = 0.5^1 + 2 \cdot0.5^2 + 3\cdot 0.5^3...\\$ $0.5E(X) = 0.5^2 + 2 \cdot0.5^3 + 3\cdot 0.5^4...\\$ $0.5E(X) = 0.5^1 + 0.5^2 + 0.5^3...$ My question: how did he calculate the difference on line 3? Thanks for your help.,"['algebra-precalculus', 'sequences-and-series']"
3315718,Does there exist an area-preserving map from the hyperbolic plane to the Euclidean plane? [duplicate],"This question already has an answer here : Existence of area-preserving diffeomorphism between two sets in $\mathbb{R}^2$ (1 answer) Closed 4 years ago . Fairly simple question: does there exist an area-preserving map from the hyperbolic plane to the Euclidean plane? If not, does there exist an area-preserving map from an arbitrarily large subset of the hyperbolic plane, to an arbitrarily large subset of the Euclidean plane? If so, what does the map look like? It would basically be similar to the ""Mollweide projection.""","['hyperbolic-geometry', 'area', 'geometry', 'riemannian-geometry']"
3315817,Finite index of centralizer $C_H(g)$ in $C_G(g)$,"Let $H$ be a subgroup of finite index in group $G$ and let $g \in G$ . Question: Is it true, that $C_H(g)$ has finite index in $C_G(g)$ for all $g \in G$ ? Here $C_H(g) := \{ h \in H\mid gh = hg\}$ denotes the centralizer of $g$ in $H$ . I know that the statement is true for $g \in H$ . In this case it is a byproduct of the theory of ranks of projective modules over group rings. For, there one shows that for each conjugacy class $[h]$ of $H$ there is an integer $n_h$ such that for each projective $\mathbb{Z}G$ -module $P$ the Hattori-Stallings rank satisfies: $$R_H(P) = \sum_h n_h R_G(P)(h)\cdot [h]$$ where $h$ runs over a system of representatives of the conjugacy classes of $H$ . Moreover, one can show $n_h = (C_G(h):C_H(h))$ (cf. Kenneth S. Brown: Cohomology of Groups, IX, Prop. 4.1 and Exercise 2).",['group-theory']
3315823,Show The Jordan Normal Form Of $\varphi$.,"Fix a nonnegative integer $n$ , and consider the linear space $$\mathbb{R}_n\left [x,y \right ] := \left\{ 
\sum_{\substack{
 i_1,i_2;\\
i_1+i_2\leq n}}a_{i_1i_2}x^{i_1}y^{i_2}\quad\Big|{}_{\quad}a_{i_1i_2}\in \mathbb{R} ; \ i_1,i_2 \text{ are non-negative integers}\right \}$$ over $\mathbb{R}$ where two
  operations, addition and scalar multiplication , are defined as usual. $\\$ A linear map $\varphi$ from $\mathbb{R}_n\left [x,y \right ]$ to $\mathbb{R}_n\left[x,y \right ]$ defined as following: $$\forall f(x,y)\in \mathbb{R}_n\left [x,y \right ],\quad\varphi(f):=2\frac{\partial f }{\partial x}+ \frac{\partial f }{\partial y}.\quad$$ $\\$ Show  the  jordan normal form of $\varphi$ . When $n=1,$ $$span\{2,x,-\frac{1}{2}x+y\}=\mathbb{R}_1\left [x,y \right ], $$ $$\varphi(2,x,-\frac{1}{2}x+y)=(2,x,-\frac{1}{2}x+y)\left(\begin{array}{cc|cc} 
0 &  1& 0\\ 
 0&  0& 0\\ 
 \hline 0&  0& 0
\end{array}\right).$$ When $n=2,$ $$span\{1,x,y,xy,x^2,y^2\}=\mathbb{R}_2\left [x,y \right ], $$ it is not difficult to calculate the  jordan normal form of $\varphi$ is $$\left(\begin{array}{ccc|cc|c} 0& 1& 0& 0& 0& 0\\ 0&  0&  1&  0&  0& 0\\ 0&  0&  0&  0&  0& 0\\ \hline0&  0& 0 &  0&  1& 0\\  0&  0& 0 &  0&  0& 0\\  \hline 0&  0& 0 &  0&  0& 0\\ 
\end{array}\right).$$ But how to generalize it to  any  integer $n$ and  prove the generalization is  correct ？","['matrices', 'jordan-normal-form', 'linear-algebra', 'partial-differential-equations']"
3315853,"Finding $\int_0^1\int_0^1\ldots\int_0^1\frac{1}{1-\prod_{i=1}^{n}\ln(x_i)}\,dx_1dx_2\ldots dx_n$","I am interested in finding $$f(n) = \int_0^1\int_0^1\ldots\int_0^1\frac{1}{1-\prod_{i=1}^{n}\ln(x_i)}\,dx_1dx_2\ldots dx_n$$ for positive integer $n$ . For example, $$f(2)=\int_0^1\int_0^1\frac{1}{1-\ln(x_1)\ln(x_2)}\,dx_1dx_2$$ I found $f(1) = e \cdot E_1(1) \approx 0.596$ , $f(2)$ diverges, $f(3) \approx 0.724$ . $$$$ My questions How can I find $f(n)$ for positive integer $n$ ? If that is not possible, what is an approximation? I know for sure that if $n$ is odd, $f(n)$ converges. This is because $\frac{1}{1-\prod_{i=1}^{n}\ln(x_i)}$ will converge for $0 \le x_i \le 1$ . I also suspect that if $n$ is even, $f(n)$ diverges.","['integration', 'multiple-integral', 'definite-integrals', 'logarithms']"
3315857,The $|\cdot|_{p}$ norm will become the maximum norm when $p \to \infty$,"I'm trying to prove the $|\cdot|_{p}$ norm will become the maximum norm when $p \to \infty$ . Let $\mathbb K$ denote $\mathbb R$ or $\mathbb C$ , and $x= (x_1, \ldots, x_m) \in \mathbb K^m$ . Then $$\lim_{p \to \infty} \left ( \sum_{i=1}^m |x_i|^p \right )^{1/p} = \max _{1 \leq i\leq m} |x_{i}|$$ Could you please verify whether my attempt is fine or contains logical gaps/errors? Any suggestion is greatly appreciated! My attempt: It suffices to prove the statement in case $x \in \mathbb {(R^+)}^{m}$ , where it becomes $$\lim_{p \to \infty} \left ( \sum_{i=1}^m (x_i)^p \right )^{1/p} = \max _{1 \leq i\leq m} x_{i}$$ Let $l:= \max _{1 \leq i\leq m} x_{i}$ . We have $$l = (l^p)^{1/p} \le \left ( \sum_{i=1}^m (x_i)^p \right )^{1/p} \le (ml^p)^{1/p} = m^{1/p}l$$ Then $$l = \lim_{p \to \infty} l \le \lim_{p \to \infty} \left ( \sum_{i=1}^m (x_i)^p \right )^{1/p} \le \lim_{p \to \infty} (m^{1/p}l) = l$$ and thus by squeeze theorem $$\lim_{p \to \infty} \left ( \sum_{i=1}^m (x_i)^p \right )^{1/p} = l$$ This completes the proof.","['proof-verification', 'normed-spaces', 'real-analysis']"
3315862,Maximizing the Distance Traveled by a Projectile by Applying Chain Rule to the Fundamental Theorem of Calculus,"I'm having some difficulty reconciling my understanding of the fundamental theorem of calculus with a particular problem from Stewart Calculus. The question asks what value of the angle of elevation $\alpha$ maximizes the total distance traveled by the projectile with a position at time $t$ given by the parametric equations $x=(v\cos{\alpha})t$ , $y=(v\sin{\alpha})t-\frac{1}{2}gt^2$ , where $v$ is the initial speed of the projectile and $g$ is the gravitational constant. The projectile is launched at $t=0$ and necessarily returns to Earth at $t=\frac{2v\sin{\alpha}}{g}$ (as can be shown by setting $y=0$ and solving for $t$ ). It follows that the arc length of the parabola traced out by the projectile (as a function of the chosen angle of elevation) is $$L(\alpha)=\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{\left(\frac{dx}{dt}\right)^2+\left(\frac{dy}{dt}\right)^2}\,dt}=\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{(v\cos{\alpha})^2+\left(v\sin{\alpha}-gt\right)^2}\,dt}=\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{v^2\cos^2{\alpha}+v^2\sin^2{\alpha}-2vg(\sin{\alpha})t+g^2t^2}\,dt}=\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{v^2-2vg(\sin{\alpha})t+g^2t^2}\,dt}$$ From here, I see two possible ways to determine the $\alpha$ value that maximizes this function. The first solves the integral directly by factoring out $g$ from the square root to produce $$L(\alpha)=\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{(v\cos{\alpha})^2+\left(v\sin{\alpha}-gt\right)^2}\,dt}=\int_0^\frac{2v\sin{\alpha}}{g}{{g}\sqrt{\left(t-\frac{v}{g}\sin{\alpha}\right)^2+\frac{v^2}{g^2}\cos^2{\alpha}}\,dt}$$ and then uses the identity $$\int{\sqrt{a^2+u^2}\,du}=\frac{u}{2}\sqrt{a^2+u^2}+\frac{a^2}{2}\ln{\left(u+\sqrt{a^2+u^2}\right)}+C$$ to eventually express $L$ as $$L(\alpha)=\frac{v^2}{g}\sin{\alpha}+\frac{v^2}{2g}\cos^2{\alpha}\ln{\left(\frac{1+\sin{\alpha}}{1-\sin{\alpha}}\right)}$$ At this point, $\frac{dL}{d\alpha}=\frac{v^2}{g}\cos{\alpha}\left[2-\sin{\alpha}\ln{\left(\frac{1+\sin{\alpha}}{1-\sin{\alpha}}\right)}\right]$ can be set equal to $0$ to determine the critical points of $L(\alpha)$ on the interval $0<\alpha<\frac{\pi}{2}$ , the only one being at $\alpha\approx56°$ . According to the textbook solutions manual, this is the correct answer. However, I also feel that it should be possible to take advantage of the fundamental theorem of calculus and the chain rule to avoid having to find that nasty integral altogether. Since $$\frac{d}{dx}\int_a^{g(x)}{f(t)\,dt}=\frac{d}{dx}\left(F(g(x))-F(a)\right)=f(g(x))\frac{d}{dx}g(x)$$ shouldn't it be that $$\frac{dL}{d\alpha}=\frac{d}{d\alpha}\int_0^\frac{2v\sin{\alpha}}{g}{\sqrt{v^2-2vg(\sin{\alpha})t+g^2t^2}\,dt}=\sqrt{v^2-2vg(\sin{\alpha})\left(\frac{2v\sin{\alpha}}{g}\right)+g^2\left(\frac{2v\sin{\alpha}}{g}\right)^2}\,\frac{d}{d\alpha}\left(\frac{2v\sin{\alpha}}{g}\right)=\sqrt{v^2-4v^2\sin^2{\alpha}+g^2\left(\frac{4v^2\sin^2{\alpha}}{g^2}\right)}\,\left(\frac{2v\cos{\alpha}}{g}\right)=\sqrt{v^2}\,\frac{2v\cos{\alpha}}{g}=\frac{2v^2\cos{\alpha}}{g}$$ for which there is no critical value on the interval $0<\alpha<\frac{\pi}{2}$ . Where am I going wrong?","['integration', 'multivariable-calculus', 'calculus', 'derivatives']"
3315885,"Knowing that $a_m = 2a_{m - 1}(a_{m - 1} + 1)$, find $n$ such that $a_1^2 + a_2^2 + \cdots + a_{m - 1}^2 + a_m^2 + n^2$ is a square number.","Knowing that $$\large a_0 \in \mathbb Z \mid a_m = 2a_{m - 1}(a_{m - 1} + 1), \forall m \in \mathbb Z^+$$ , find $n$ such that $$\large a_1^2 + a_2^2 + \cdots + a_{m - 1}^2 + a_m^2 + n^2$$ is a square number for $\forall m \in \mathbb Z^+$ . I'm not sure how to solve this problem. The solution might include mathematical induction and I don't know about it.","['number-theory', 'induction']"
3315920,What are all the functions that satisfy $f(x)/f(y) = f(kx)/f(ky)$?,"Find all continuous functions defined over real numbers that satisfy $\frac{f(x)}{f(y)} = \frac{f(kx)}{f(ky)}$ , for any $x$ and $y$ . It is possible to show that the above condition holds for $f(x) = ax^b$ since $\frac{ax^b}{ay^b} = \frac{ak^bx^b}{ak^by^b}$ . Do functions that satisfy this property have a specific name?","['functional-equations', 'functions']"
3315935,Notation confusion about multivariable derivative,"First of all I'd like to say that English is not my native language but I hope I've translated most of the concepts correctly. So I'm going over my multivariable calculus textbook (also not in English, obviously) and most of the stuff I've understood. All the concepts are presented with functions of two variables. They've defined partial derivatives with the following notations: $$f^{'}_{x}(x_0, y_0) = \lim_{h\to0}\frac{f(x_0+h, y_0)-f(x_0, y_0)}{h}$$ $$f^{'}_{y}(x_0, y_0) = \lim_{h\to0}\frac{f(x_0, y_0+h)-f(x_0, y_0)}{h}$$ So far so good. Then for the differentiability in general, they defined it as follows: The function $f$ is differentiable at some point $\mathbf{x_0} = (x_0, y_0)$ if there is a linear mapping $L: \mathbb{R^2} \rightarrow \mathbb{R}$ such that $f(\mathbf{x_0} + \mathbf{h}) = f(\mathbf{x_0})
+ L\mathbf{h} + o(\mathbf{h})$ when $\mathbf{h} \to \mathbf{0}$ . I don't want to get into the whole deal but essentially they write everything in coordinates, using $\mathbf{h} = (h, k)$ and the linear mapping then becomes $L(h, k) = ah + bk$ where we later prove that $a$ and $b$ are partial derivatives: $$a = f^{'}_{x}(x_0, y_0), \quad b = f^{'}_{y}(x_0, y_0) $$ And from there we got $L(h, k) = f^{'}_{x}(x_0, y_0)h + f^{'}_{y}(x_0, y_0)k $ Then comes the following paragraph which confuses me completely: The linear mapping $L$ for which we've seen is of form $L(h, k) = f^{'}_{x}(x_0, y_0)h + f^{'}_{y}(x_0, y_0)k $ is called the differential or the derivative of the function f at the point $(x_0, y_0)$ and we use the notation $df(x_0, y_0)$ . Here's the confusing sentence: If we mark linear mappings $(x, y) \to x$ and $(x, y) \to y$ as $dx$ and $dy$ respectively we get $df(x_0, y_0) = f^{'}_{x}(x_0, y_0)dx +
 f^{'}_{y}(x_0, y_0)dy $ Where did that come from? Why do we even introduce those two mappings? Where did the $h$ and $k$ go? Thanks in advance.","['multivariable-calculus', 'derivatives']"
3315946,Books similar to Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller,"I find the book Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller . I would like to solve more probability problems whose levels are similar to book above. 
Does anyone have good suggestions?","['book-recommendation', 'probability', 'reference-request']"
3316051,Exercise 7.3.J in Ravi Vakil's FOAG,"Let $A\rightarrow R$ be a homomorphism of commutative rings with identity. Define the $\mathbb{Z}^{\geq 0}$ graded ring $$S=A\oplus R \oplus R \oplus R \oplus...$$ with multiplication defined in the only sensible way. It is claimed that $$Proj ~S\simeq Spec ~ R.$$ How to prove that? For $r\in R$ let me write $[r]_k$ for the element of the k'th-degree summand of $S$ .  Since $$Proj ~ S = \cup_{f\in R}D([f]_1)$$ It seemed to me that the logical thing to do was define local maps (for each $f\in R$ ) by $$D([f]_1)=Spec ~(S_{[f]_1})_0\rightarrow Spec ~R$$ $$R~\rightarrow (S_{[f]_1})_0$$ by $$r\mapsto \frac{[rf]_1}{[f]_1}.$$ These indeed seem to patch together and to factor through local isomorphisms $$R_f~\rightarrow (S_{[f]_1})_0.  $$ The problem is that then we have in particular $$R =R_1 \simeq (S_{[1]_1})_0$$ but we needn't have $$D([1]_1)= Proj~S.$$ So that when $D([1]_1)\neq Proj~S$ the underlying map of points for the proposed isomorphism will not be bijective. 
What am I doing wrong?","['algebraic-geometry', 'schemes']"
3316053,Why does the transformation in the scope of the cumulative distribution function work?,"I am reading some probability courses on the https://www.probabilitycourse.com/chapter4/4_1_3_functions_continuous_var.php . It says the following : Let X be a Uniform(0,1) random variable, and let $Y=e^X$ I would like to ask why the following equation is correct: $$P(e^X \leq y)=P(X \leq \ln y)$$ Intuitively, we can apply the ln operator in the first CDF to get the second CDF. However, I am confused when I expand these 2 cumulative distribution functions into the integral format. $$P(Y \leq y) = P(e^X \leq y)=\int_{{-\infty}}^{y} f_y(y) dy=\int_{{-\infty}}^{y} f_y(e^x) dy=\int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx$$ $$P(X \leq \ln y)=\int_{{-\infty}}^{\ln y} f_x(x) dx$$ $f_x$ and $f_y$ are the corresponding pdfs. I can not see directly that the equation $\int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx = \int_{{-\infty}}^{\ln y} f_x(x) dx$ can really hold . So I would like to ask why the transformation in the scope of  the cumulative distribution function works ? Did I miss some axiom ? I guess it should be a basic question but I can not get it from google. Thank you I agree with @Grada Gukovi's comment, and I find the Method of Transformation will produce the equation $ f_y(e^x) e^x = f_y(y) e^x = f_x(x) $ . What I think in this problem is that , the statement of $P(e^X \leq y)=P(X \leq \ln y)$ should not be a simple transformation without evidence. Because $P(e^X \leq y)$ is the integral for random variable y and $P(X \leq \ln y)$ is the integral for random variable x. This equation is not easy to be derived and gives me lots of worrys.  From my thinking, we can only get this equation after using the Method of Transformation. I guess we can not say $P(e^X \leq y) = P(X \leq \ln y) $ if $(e^X \leq y) = (X \leq \ln y) $ simply.","['statistics', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
3316075,Challenging integral: Evaluate $\int_0^1\frac{\ln^3(1-x)\operatorname{Li}_3(x)}{x}dx$,"How to evaluate $$I=\int_0^1\frac{\ln^3(1-x)\operatorname{Li}_3(x)}{x}dx\ ?$$ I came across this integral $I$ while I was trying to compute two advanced sums of weight 7. The problem with my approach is that when I tried to evaluate $I_5$ (shown below), the main integral $I$ appeared there which cancels out from both sides, so any idea how to evaluate $I_5$ or $I$ ? Thanks. Here is my trial: Using the two generalized integral expressions of the polylogrithmic function which can be found in the book (Almost) Impossible Integrals, Sums and series page 4. $$\int_0^1\frac{x\ln^n(u)}{1-xu}du=(-1)^n n!\operatorname{Li}_{n+1}
(x)\Longrightarrow \operatorname{Li}_{3}(x)=\frac12\int_0^1\frac{x\ln^2(u)}{1-xu}du\tag{1}$$ $$\small{u\int_0^1\frac{\ln^n(x)}{1-u+ux}dx=(-1)^{n-1}n!\operatorname{Li}_{n+1}\left(\frac{u}{u-1}\right)\Longrightarrow\int_0^1\frac{\ln^3x}{1-u+ux}dx=\frac6u\operatorname{Li}_{3}\left(\frac{u}{u-1}\right)}\tag{2}$$ We have \begin{align}
I&=\int_0^1\frac{\ln^3(1-x)\operatorname{Li}_3(x)}{x}dx\overset{\text{use} (1)}{=}\frac12\int_0^1\frac{\ln^3(1-x)}{x}\left(\int_0^1\frac{x\ln^2u}{1-xu}du\right)dx\\
&=\frac12\int_0^1\ln^2u\left(\frac{\ln^3(1-x)}{1-xu}dx\right)\ du\overset{1-x\ \mapsto\ x}{=}\frac12\int_0^1\ln^2u\left(\int_0^1\frac{\ln^3x}{1-u+ux}dx\right)\ du\\
&\overset{\text{use}\ (2)}{=}3\int_0^1\frac{\ln^2u}{u}\operatorname{Li}_4\left(\frac{u}{u-1}\right)du\overset{IBP}{=}-\int_0^1\frac{\ln^3u}{u(1-u)}\operatorname{Li}_3\left(\frac{u}{u-1}\right)du
\end{align} Now we need the trilogarithmic identity: $$\operatorname{Li}_3\left(\frac{x-1}{x}\right)=\zeta(2)\ln x-\frac12\ln^2x\ln(1-x)+\frac16\ln^3x-\operatorname{Li}_3(1-x)-\operatorname{Li}_3(x)+\zeta(3)$$ set $1-x=u$ to get $$\small{\operatorname{Li}_3\left(\frac{u}{u-1}\right)=\zeta(2)\ln(1-u)-\frac12\ln^2(1-u)\ln u+\frac16\ln^3(1-u)-\operatorname{Li}_3(u)-\operatorname{Li}_3(1-u)+\zeta(3)}$$ Going back to our integral \begin{align}
I&=\small{-\int_0^1\frac{\ln^3u}{u(1-u)}\left(\zeta(2)\ln(1-u)-\frac12\ln^2(1-u)\ln x+\frac16\ln^3(1-u)-\operatorname{Li}_3(u)-\operatorname{Li}_3(1-u)+\zeta(3)\right)du}\\
&=-\zeta(2)\underbrace{\int_0^1\frac{\ln^3u\ln(1-u)}{u(1-u)}du}_{\Large I_1}+\frac12\underbrace{\int_0^1\frac{\ln^4u\ln^2(1-u)}{u(1-u)}du}_{\Large I_2}-\frac16\underbrace{\int_0^1\frac{\ln^3u\ln^3(1-u)}{u(1-u)}du}_{\Large I_3}\\
&\quad+\underbrace{\int_0^1\frac{\ln^3u\operatorname{Li}_3(u)}{u(1-u)}\ du}_{\Large I_4}+\underbrace{\int_0^1\frac{\ln^3u}{u(1-u)}\left(\operatorname{Li}_3(1-u)-\zeta(3)\right)du}_{\Large I_5}
\end{align} \begin{align}
I_1=\int_0^1\frac{\ln^3u\ln(1-u)}{u(1-u)}du=-\sum_{n=1}^\infty H_n\int_0^1 u^{n-1}\ln^3udu=6\sum_{n=1}^\infty\frac{H_n}{n^4}
\end{align} . \begin{align}
I_2&=\int_0^1\frac{\ln^4u\ln^2(1-u)}{u(1-u)}du=\sum_{n=1}^\infty\left(H_n^2-H_n^{(2)}\right)\int_0^1 u^{n-1}\ln^4udu\\
&=24\sum_{n=1}^\infty\frac{H_n^2-H_n^{(2)}}{n^5}=24\sum_{n=1}^\infty\frac{H_n^2}{n^5}-24\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^5}
\end{align} \begin{align}
I_3&=\int_0^1\frac{\ln^3u\ln^3(1-u)}{u(1-u)}du=\int_0^1\frac{\ln^3u\ln^3(1-u)}{u}du+\underbrace{\int_0^1\frac{\ln^3u\ln^3(1-u)}{1-u}du}_{1-x\ \mapsto\ x}\\
&=2\int_0^1\frac{\ln^3u\ln^3(1-u)}{u}\ du\overset{IBP}{=}\frac32\int_0^1\frac{\ln^4u\ln^2(1-u)}{1-u}du\\
&=\frac32\sum_{n=1}^\infty\left(H_n^2-H_n^{(2)}\right)\int_0^1 u^n\ln^4udu, \quad \text{reindex}\\
&=\frac32\sum_{n=1}^\infty\left(H_n^2-H_n^{(2)}-\frac{2H_n}{n}+\frac2{n^2}\right)\int_0^1 u^{n-1}\ln^4u du\\
&=\frac32\sum_{n=1}^\infty\left(H_n^2-H_n^{(2)}-\frac{2H_n}{n}+\frac2{n^2}\right)\left(\frac{24}{n^5}\right)\\
&=36\sum_{n=1}^\infty\frac{H_n^2}{n^5}-36\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^5}-72\sum_{n=1}^\infty\frac{H_n}{n^6}+72\zeta(7)
\end{align} . \begin{align}
I_4&=\int_0^1\frac{\ln^3u\operatorname{Li}_3(u)}{u(1-u)}du=\sum_{n=1}^\infty H_n^{(3)}\int_0^1 u^{n-1}\ln^3u du=-6\sum_{n=1}^\infty\frac{H_n^{(3)}}{n^4}
\end{align} \begin{align}
I_5&=\int_0^1\frac{\ln^3u}{u(1-u)}\left(\operatorname{Li}_3(1-u)-\zeta(3)\right)du\\
&=\underbrace{\int_0^1\frac{\ln^3u}{u}\left(\operatorname{Li}_3(1-u)-\zeta(3)\right)du}_{IBP}+\underbrace{\int_0^1\frac{\ln^3u}{1-u}\left(\operatorname{Li}_3(1-u)-\zeta(3)\right)\ du}_{1-u\ \mapsto\ u}\\
&=\frac14\int_0^1\frac{\ln^4u\operatorname{Li}_2(1-u)}{1-u}du+\underbrace{\int_0^1\frac{\ln^3(1-u)\operatorname{Li}_3(u)}{u}du}_{\large \text{our main integral}}-\zeta(3)\int_0^1\frac{\ln^3u}{1-u}du\\
&=\frac14\int_0^1\frac{\ln^4u\operatorname{Li}_2(1-u)}{1-u}du+I+6\zeta(3)\zeta(4)
\end{align} In my solution here I came across the remaining integral and here is the result: $$\frac14\int_0^1\frac{\ln^4u\operatorname{Li}_2(1-u)}{1-u}du=6\zeta(2)\zeta(5)+36\zeta(7)-30\sum_{n=1}^\infty\frac{H_n}{n^6}-6\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^5}$$ Then $$I_5=I+6\zeta(3)\zeta(4)+6\zeta(2)\zeta(5)+36\zeta(7)-30\sum_{n=1}^\infty\frac{H_n}{n^6}-6\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^5}$$ . Note: We can not use the two sums $\sum_{n=1}^\infty\frac{H_n^3}{n^4}$ and $\sum_{n=1}^\infty\frac{H_nH_n^{(2)}} {n^4}$ in our solution because the integral $I$ is the key to evaluate these two sums.","['integration', 'definite-integrals', 'real-analysis', 'harmonic-numbers', 'calculus']"
3316091,"Localization of the coordinate ring $K[V]$, $K$ not necessarily algebraically closed.","In his first chapter of ""The Arithmetic of Elliptic Curves"", Silverman develops some necessary background in algebraic geometry. He works over ground fields $K$ , which are perfect but not necessarily algebraically closed. For example, we get the coordinate ring of $V/K$ : $$
K[V] = \frac{K[X_1, \dots, X_n]}{I(V/K)}.
$$ I am then wondering why Silverman defines the maximal ideal $M_P = \{f \in \bar{K}[V] : f(P) = 0\}$ and the corresponding local ring $\bar{K}[V]_{M_P}$ only for algebraically closed fields? It seems to me that (for $P$ a $K$ -rational point) we could define a maximal ideal $m_P = \{f \in K[V] : f(P) = 0\}$ and a corresponding local ring $K[V]_{m_P}$ — although I am not sure if this is still a DVR?","['affine-varieties', 'algebraic-geometry']"
3316092,"Can $\frac{1}{2a}\left(-b+\sqrt{b^2-4ac}\right)$ be rational if $a=3n_1$, $b=-3n_1^2$, $c=n_1^3-n_2^3$, for positive rational $n_i$ with $n_1<n_2$?","Let $n_{1}$ and $n_{2}$ be positive rational numbers such that $n_{1}<n_{2}$ . Let $a=3n_{1}$ , $b=-3n_{1}^2$ , $c=n_{1}^3-n_{2}^3$ . Can $$\frac{-b+\sqrt{b^2-4ac}}{2a}$$ be a rational number? In my problem , see Parcly Taxel answer , I want $h_{w_1},h_{w_2}$ and $h$ all to be positive rational numbers with $(h_{w_1}<h_{w_2})$ . Is that possible?","['number-theory', 'irrational-numbers', 'elementary-number-theory', 'quadratics', 'rational-numbers']"
3316102,"Binary classification, Bayes classifier, Bayes decision boundary","I have recently come across this problem from a friend I help with stats occasionally. This however stumped me completely. I have looked online on basically every single website you can find but what I did find either I did not fully understand or I didn't fully understand well enough to explain to my friend. In my last resort I have made an account here hoping for some help. From what I have read and understood I know the Bayes boundary is a kind of squiggly line you find which separates between classifying an observation on either end. However I don't understand how one comes to finding how to get one. Furthermore, bayesian stats is very new to me so I am struggling and therefore my friend is too. Thank you for reading and I hope someone who understands this well can explain it to me in a simple concise and easy way Consider a binary classification problem $Y \in \{0, 1\}$ with one predictor $X$ .
The prior probability of being in class 0 is $Pr(Y = 0) = \pi_0= 0.69$ and the density
function for $X$ in class 0 is a standard normal $$f_0(x) = Normal(0, 1) = (1/\sqrt{2\pi})\exp(-0.5x^2).$$ The density function for $X$ in class 1 is also normal, but with $\mu = 1$ and $\sigma^2 = 0.5$ , i.e. $$f_1(x) = Normal(0, 1) = (1/\sqrt{\pi})\exp(-(x-1)^2).$$ (a) Plot $\pi_0f_0(x)$ and $\pi_1f_1(x)$ in the same figure. (b) Find the Bayes decision boundary. (c) Using Bayes classifier, classify the observation $X = 3$ . Justify your prediction. (d) What is the probability that an observation with $X = 2$ is in class 1? Any help at all would be greatly appreciated!","['empirical-bayes', 'statistics', 'bayesian', 'probability']"
3316127,Constant function given an inequality [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $f:\mathbb{R}\rightarrow\mathbb{R}$ that satisfies $f(x + y)\leq yf(x) + f(f(x))$ for all $x,y\in\mathbb{R}$ .
Show that $f(x)=0$ for all $x\leq0$ . I tried setting y = 0 in an attempt to prove it but i couldn't and there is nothing else","['contest-math', 'functions']"
3316139,Irreducible Components of a Fiber in Irreducible Scheme,"I have two question abouts some steps in the proof of Proposition 4.4.16 from Liu's ""Algebraic Geometry and Arithmetic Curves"" (page 155): Denote $f:X \to S$ the morphism from above. Let $X_s=f^{-1}(s) \neq \varnothing$ the fiber of certain point $s \in S$ of Dedekind scheme $S$ . Then we take an irreducible component $F$ of $X_s$ . Here my first question/understanding problem: Liu makes following strange step: He replaces $X$ by open affine subscheme $U \subset X$ with the property that $U$ meets $F$ (therefore $U \cap F \neq \varnothing$ ) but not other components of $X_s$ . The question is why the assumption that $X$ is irreducible implies that such $U$ with desired properties exist and the proof can be reduced to the case $X=U$ ? Why such reduction step would fail /be not allowed in the proof if $X$ would be not irreducible? My considerations: By definition irreducible implies that any open set of $X$ is dense and so contain the (unique) generic point of $X$ and therefore any open is also irreducible. So naively replacing $X$ by $U$ doesn't change the initial conditions of the proposition. Is this exactly the main reason for this reduction step? Futhermore the fiber $X_s$ has subspace topology induced by $X$ (since $X_s \subset X$ ) and by general property of induced subspace topology any open subset $V$ of $X_s$ arises from an open $U \subset X$ via $V=U \cap X_s $ (schematically $U \cap X_s \cong U \times_S X_s$ ). So naively one can always ""avoid"" other irreducible components of $X_s$ by open sets from $X$ pure topologically. Or am I wrong? So where does here play role the assumption on $X$ that it is irreducible? Second Question: Why $K(X_{\eta})=K(X)$ ? We know that ""birational"" isn't stable under base change so I don't see an argument for the equality above?","['proof-explanation', 'algebraic-geometry', 'schemes']"
3316182,Definition of quotient of sigma algebras,"Let $(\Omega,\mathcal{A},\mu)$ a measure space. Let $I$ be some $\sigma$ -ideal in $(\Omega,\mathcal{A})$ , i.e. it contains the empty set and contains subsets and countable unions of its elements. How do you define $\Omega/ I$ ? And what are the equivalence classes defined as? I am just familiar with quotient space of vector spaces, but not with that general case. Any literature is welcome aswell.","['measure-theory', 'notation', 'definition', 'abstract-algebra', 'ideals']"
3316218,Problem involving the square root of a trigonometric term,"I was trying to find the shaded area in this figure: And no, it isn't homework. I just chanced upon it on Facebook and had a go at it. I managed to find it using a very simple method. I now want to verify that my answer is correct with calculus. Specifically, I want to verify my answer with integration on an area bounded between two curves which are the smaller and larger circle. To do this, I did the following to frame the problem more simply: Rearranging the larger circle to make it simpler down the line Then, as you can see in the image, the two polar equations of the circles were constructed. I actually had no idea how to do it for circles that are not centered on the origin or on any part of the x or y axes, so I referred to this link to get the equation for that: Plotting polar equations of circles not centered at (0, 0) The next step is to equate the two equations so as to find out where they intersect. This is what I got: $5\sqrt2\cos(\theta-\frac{\pi}{4}) + \sqrt{5^2-50\sin^2(\theta-\frac{\pi}{4})} = 10$ $5\sqrt2\cos(\theta-\frac{\pi}{4}) + 5\sqrt{1-2\sin^2(\theta-\frac{\pi}{4})} = 10$ $5\sqrt2\cos(\theta-\frac{\pi}{4}) + 5\sqrt{\cos(2(\theta-\frac{\pi}{4}))} = 10$ $\sqrt2\cos(\theta-\frac{\pi}{4}) + \sqrt{\cos(2(\theta-\frac{\pi}{4}))} = 2$ And I am stuck here pretty much. I did a bit of thinking and realized that I am not really sure how to solve this type of equation. Checking on Wolfram Alpha, I could find the value of theta. They are as follows: https://www.wolframalpha.com/input/?i=10+%3D+sqrt(50)cos(theta+-+pi%2F4)+%2B+sqrt(25+-+50(sin(theta+-+pi%2F4))%5E2) https://www.wolframalpha.com/input/?i=sqrt(2)cos(theta+-+pi%2F4)+%2B+sqrt(cos(2(theta+-+pi%2F4)))+%3D+2 I did try solving it in Cartesian form then converting it to Polar coordinates later but I didn't manage to solve that either: $(x-5)^2 + (y-5)^2 = 5^2$ $x^2 + y^2 = 10^2$ With some simple substitution I ended up with: $x + \sqrt{10^2-x^2} - 5 = 0$ which I also don't know how to solve analytically. I can easily solve any of these numerically but I want to know how one would go about them analytically, preferably without converting them to complex form. In any case, once the intersections are found, I can perform the necessary integration to obtain the area. That I know I can do. Thank you! EDIT: Okay I must admit I am very tired and this has affected my basic mathematical skills such as rearranging equations /facepalm. This problem is so simple it is not even worth asking. Apologies for the waste of server space. The trick is to bring the root term to one side and everything else to the other side. Square it and voila, everything becomes easy.","['calculus', 'area', 'trigonometry']"
3316279,How can one prove a recognized modulo pattern?,"Suppose you need to know what the possible unit digits are for integers written on the form $4n^2$ for some integer $n$ . Me myself have always just relayed on numerical investigation, i.e. compute the answer for the first few values of $n$ and assume that the observed pattern (if found) goes on for ever. For example. The first few values of $4n^2$ : $[4, 16, 36, 64, 100, 144, 196, 256, 324, 400]$ Computing modulo $10$ of above numbers yields: $[4, 6, 6, 4, 0, 4, 6, 6, 4, 0]$ And so I would just assume that the unit digit follow the pattern $(4, 6, 6, 4, 0,...)$ and deduce that the only possible unit digit values are $0,4,6$ . But so far this is just an observation and one must prove that this pattern goes on forever if one is to be certain that the only unit digits possible are indeed $0,4,6$ . How can you prove this or rather, what is the general approach for proving that patterns recognized modulo $m$ repeats to infinity? That is, don't get stuck on the fact that we are  talking unit digits above. Another example would be $n^2 (mod 8)$ which gives the recognizeable pattern to prove: $[1, 4, 1, 0, 1, 4, 1, 0, 1, 4, 1, 0, 1, 4]$ So to clarify, what I'm asking is: Do there exist a general approach or some tricks that are commonly used to prove that such modulo patterns continue forever? Or is it very ""case specific"" depending on the expression that you are working with, whereas sometimes you have to factor and other times use famous theorems etc.? Thanks.","['number-theory', 'pattern-recognition', 'modular-arithmetic', 'elementary-number-theory']"
3316287,Proof that $\arctan z+\arctan \frac{1}{z}$ does not depend on $\operatorname{Im}z$ when $\operatorname{Re}z\ne 0$ and $\operatorname{Im}z\ne 0$,"I proved that $$\begin{align*}\arctan z+\arctan \frac{1}{z}&=\frac{\pi}{2} \, \text{if} \, z\gt 0\\&=-\frac{\pi}{2} \, \text{if} \, z\lt 0\end{align*}$$ using the fact that $$\frac{d}{dz}\left(\arctan z+\arctan \frac{1}{z}\right)=0, \, \operatorname{Re}z\ne 0, \, \operatorname{Im}z\ne 0.$$ I suspect that $$\begin{align*}\arctan z+\arctan \frac{1}{z}&=\frac{\pi}{2} \, \text{if} \, \operatorname{Re}z\gt 0\\&=-\frac{\pi}{2} \, \text{if} \, \operatorname{Re}z\lt 0.\end{align*}$$ Therefore, when $\operatorname{Re}z\ne 0$ and $\operatorname{Im}z\ne 0$ , $\arctan z+\arctan \frac{1}{z}$ does not depend on $\operatorname{Im}z$ . If this is true, how can I prove it?","['complex-analysis', 'trigonometry', 'complex-numbers']"
3316295,Need a Intuitive thinking for the proof of Mean value theorem for scalar field,"Ok so the proof is laid out on my book but I'm genuinely struggling to have a geometrical/Intuitive thinking to this particular proof. I badly need help with it. So here is the statement of the proof (PLEASE NOTE THAT $D_u$ in this case implies directional derivative in the direction of the unit vector $u$ ): Let $f: S\to \mathbb R$ be a scalar field. Let $a\in S$ and where $S\subseteq \mathbb R^n$ So let $u$ be a unit vector and $u\in\mathbb{R}^n$ and $a + ut \in S$ for all $0\leq t \leq 1.$ Suppose $D_uf(a)$ exists for all $a + ut$ where $0 \leq t \leq 1$ then there exist a $\theta$ such that $0<\theta<1$ and $$f(a+u)-f(a) = D_uf(z), \text{where }z= a + u\theta$$ Now I'm not gonna write the proof that is written in my book because I fairly understood the steps well. I don't understand where this $z= a + u\theta$ came or what does it even imply or how it looks geometrically.","['partial-derivative', 'calculus', 'derivatives']"
3316301,Martingale / local martingale : some confusion,"For me, a stochastic $(M_t)_{t\in [0,T]}$ is a martingale (w.r.t. $(\Omega ,(\mathcal F_t)_t,\mathbb P)$ ) if $M_t$ is $\mathcal F_t$ adapted and $$\mathbb E[M_t\mid \mathcal F_s]=M_s,\quad s\leq t.$$ A local martingale is a stochastic process $(M_t)_t$ s.t. there are stoping times $(\tau_n)$ almost increasing s.t. $\tau_n\to \infty$ a.s. and s.t. $(M_{t\wedge \tau_n})_{t\geq 0}$ is a martingale for all $n$ . Q1) So at the end, if $(M_t)_{t\in [0,T]}$ is a martingale for all $T>0$ , then $(M_t)_{t\geq 0}$ is a local Martingale, right ? Q2) If $(M_t)_{t\in [0,T]}$ is not a martingale, can it be a local martingale in the sense that there are stopping time $(\tau_n)_n$ that are a.s. increasing s.t. $\tau_n\to t$ and $(M_{t\wedge \tau_n})_{t\geq 0}$ or not really ?","['martingales', 'probability']"
3316327,"Is there a geometric construction that finds the intersection of two conics, given only five points on each?","The question: Five points define a conic, so let points $A,B,C,D,E$ and $F,G,H,I,J$ define two conics $c$ and $d$ .  Is there a geometric construction that identifies the common points of $c$ and $d$ ? (It's easy enough to do it in Geogebra, or algebraically.  What I'm asking for here is a ruler and compass construction.) Background and context Given, say, an ellipse $c$ it is not too difficult to construct tangents from a point $P$ to $c$ using just a straightedge.  But this assumes that the ellipse has been drawn as a given.  If only the points $A,B,C,D,E$ on $c$ have been given, you can easily construct the polar of $P$ but then have to construct the intersection of the polar and the ellipse.  This is less straightforward but the construction is described in several 19th century projective geometry texts (e.g. Cremona or Russell ),and requires a reference conic (or compass) in addition to a straightedge. What I haven't been able to find is a construction for the intersection of two ellipses/conics that are not pre-drawn but given only as two sets of five points each.  Hence my question.  It came up in following a certain construction for ""imaginary"" chords that involved finding the common points of two conical loci ( Russell, XXVII 6. ). Update : Given two or three points of intersection it is possible to construct the remaining points of intersection . Update 2 : This problem is discussed in Veblen and Young, Projective Geometry, Vol I , $\S102$ .","['projective-geometry', 'conic-sections', 'geometry', 'geometric-construction']"
3316444,Why ReLU function is not differentiable at 0?,"I'm kind of rusty in calculus. Why is the ReLU function not differentiable at $f(0)$ ? $$
f(x) = 
\begin{cases}
0 & \text{if $x \leq 0$} \\ 
x & \text{if $x > 0$}.
\end{cases}
$$",['calculus']
3316459,Compute 100th derivative [duplicate],"This question already has an answer here : The $100$th derivative of $(x^2 + 1)/(x^3 - x)$ (1 answer) Closed 4 years ago . A friend suggested me a rather tricky problem, namely find the $100^{th}$ derivative of $$
f(x)=\frac{x^2+1}{x^3-x}.
$$ I have computed the zeroth derivative $$
\frac{x^2+1}{x^3-x}
$$ and the first derivative $$
\frac{2x(x^3-x)-(3x^2-1)(x^2+1)}{(x^3-x)^2}=\frac{1-x^4-4x^2}{(x^3-x)^2}
$$ but I don't see any obvious structure.","['calculus', 'derivatives', 'partial-fractions']"
3316470,"For the 3D rotation operation $R^{-1}(R(\omega_0)*R(\omega))$, how can we compute the derivative wrt $\omega$?","How can we compute the Jacobian derivative of the function: $$f(\omega) = R^{-1}(R(\omega_0) R(w))$$ with respect to $\omega$ , where $\omega_0 \in \mathbb{R}^3$ is some fixed/constant vector, the function: $$R(\omega) \triangleq \exp \big( [\omega]_{\times} \big) \triangleq \exp 
\left( 
\begin{bmatrix}
 0    & -w_z  &  w_y \\
 w_z  &  0    & -w_x \\
-w_y  &  w_x  &  0 \\
\end{bmatrix}
\right),
$$ is the Rodrigues-vector-to-rotation mapping , and $R^{-1}(\cdot)$ is the corresponding inverse function? For the sake of this question, we are primarily interested in taking the derivative about the point $\omega=0$ , since other values of $\omega$ can be absorbed into the constant $\omega_0$ with a little extra effort. So everything should be expressible in terms of $\omega_0$ . Edit: Using some dirty empirical methods, I was able to get the first few coefficients of the Taylor expansion as: $$
\frac{d f}{d \omega} = Z^0 + \frac{1}{2!} Z^1+ \frac{1}{2 (3!)}Z^2 - \frac{1}{6 (5!)}Z^4 + \frac{1}{6 (7!)} Z^6 - (...)
$$ where $Z=[\omega_0]_{\times}$ . (Evidently, there no higher order odd terms beyond the first.) So this appears to have a similar form to Rodrigues, as: $$\frac{d f}{d \omega} = I + \frac{1}{2} Z + \beta(\omega_0) Z^2$$ but getting a functional form for $\beta$ seems nontrivial. (I'd venture a guess than $\beta$ is purely a function of $\|\omega_0\|$ .)","['matrix-calculus', 'rotations', 'matrix-exponential', 'differential-geometry']"
3316488,Intuition behind ramification index of a map between smooth curves.,"I'm studying from The Arithmetic of Elliptic Curves (Silverman) and I'm having a hard time understanding the intuition behind the $\textit{ramification index}$ concept. In the book, we let $\phi:C_1 \longrightarrow C_2$ a non constant map of smooth curves and we let $P\in C_1$ . Then we define the ramification index of $\phi$ at $P$ , denoted by $e_\phi(P)$ as $$e_\phi(P)=\text{ord}_P(\phi^{*}t_{\phi(P)}) \text{ ,}$$ where $t_{\phi(P)}\in K(C_2)$ is a uniformizer at $\phi(P)$ . I'm trying to break it down into parts. First of all, $\phi^{*}t_{\phi(P)}$ = $t_{\phi(P)} \circ \phi$ Now, $\text{ord}_P(\phi^{*}t_{\phi(P)})$ is the max $d$ for which $\phi^{*}t_{\phi(P)} \in M_p^d$ , meaning the max $d$ for which we can express $(t_{\phi(P)} \circ \phi)$ as a product of maps $f_1...f_d$ such that $f_i(P)=0$ for all $i$ , meaning that $P$ would be a zero of multiplicity $d$ for $(t_{\phi(P)} \circ \phi)$ . It's good to see that $(t_{\phi(P)} \circ \phi)(P)=0$ and then, necessarily $(t_{\phi(P)} \circ \phi)\in M_p^d$ for $d \geq 1$ . The book defines $\phi:C_1 \longrightarrow C_2$ to be unramified at $P$ if $e_\phi(P)=1$ , which means that $(t_{\phi(P)} \circ \phi) \in M_p^1$ , in other words, we can't express $(t_{\phi(P)} \circ \phi)$ as a product of maps with $P$ being a zero for said maps. All in all, what I understand from this is that $P$ is a zero of multiplicity $1$ for $(t_{\phi(P)} \circ \phi)$ . If $e_\phi (P)>1$ we said that $\phi$ ramifies at $P$ , meaning we can split $(t_{\phi(P)} \circ \phi)$ as the product of maps, each of them having $P$ as a zero. My question is, what does all of it means? Is there any geometric intuition for this definition? I ""understand"" the technicalities behind the definition, but I don't understand why do we define this concept and why do we define it this way. The book goes with an example, considering the map $\phi :\mathbb{P}^1 \longrightarrow \mathbb{P}^1$ , $\phi([X,Y])=[X^3(X-Y)^2,Y^5]$ , it says that $\phi$ is ramified at the points $[0,1]$ and $[1,1]$ , but I am not sure what that really means. If anybody could explain what is the intuition behind this definition, I would be really thankful.","['number-theory', 'algebraic-geometry', 'elliptic-curves', 'arithmetic-geometry']"
3316497,Length of a union of intervals,"Let $X$ be a subset of $[0,1]$ with length (Lebesgue measure) $1$ . For each $x\in X$ , there is some $\epsilon_x > 0$ . Define $I_x$ as the open interval $(x, x+\epsilon_x)$ . I am interested in the union of all these intervals: $$U := \bigcup_{x\in X} I_x$$ Initially I thought that $U$ contains the entire unit interval, but this is not true. For example, it is possible that for each $x<0.5$ , $\epsilon_X := (0.5 - x)/2$ . Then, $0.5 \not \in U$ . My quesion is: is the length of $U$ always at least $1$ ?","['measure-theory', 'real-analysis']"
3316545,Analytic Continuation of Complex Function,"I am triyng to solve the following problem in Brown and Churchill's complex variables textbook. Show that the function $f_2 (z) = 1/z^2$ ( $z \neq 0$ ) is the analytic continuation of the function \begin{align*}
f_1 (z) = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n \ \ \ (|z+1| < 1)
\end{align*} into the domain consisting of all points in the $z$ plane except $z = 0$ . As a first note, I am having difficulty mapping the definition of analytic continuation to this problem. The definition in the textbook is that if we have two domains, say $D_1$ and $D_2$ , where some function $f_1$ is analytic on $D_1$ , some function $f_2$ is analytic on $D_2$ , and $f_1 (z) = f_2 (z)$ on $D_1 \cap D_2$ , where this intersection is nonempty, then $f_2$ is the analytic continuation of $f_1$ into $D_2$ . Assuming that I have not misstated that (please tell me if I have), we have: \begin{align*}
D_1 = \{z \in \mathbb{C} : |z + 1| < 1\}, \ \ \ D_2 = \{z \in \mathbb{C} : z \neq 0\}.
\end{align*} So we have \begin{align*}
D_1 \cap D_2 = \{z \in \mathbb{C} : |z + 1| < 1 \text{ and } z \neq 0\}.
\end{align*} From here, I am stuck. I know I need to prove that $\frac{1}{z^2} = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n$ for any $z \in D_1 \cap D_2$ . I don't know if I should try to demonstrate that the moduli are equal or expand $\frac{1}{z^2}$ in a power series and hope that these results will match, subject to the given constraint. Any help would be greatly appreciated. EDIT: I do not believe this question is a duplicate. I looked through the link below, and it does not address this problem, nor does it seem to deal with concepts in complex analysis.","['complex-analysis', 'analytic-functions']"
3316550,Name of property: $a \circ (a \circ b) = b$,"How do you describe an operation like this? $$ a \circ (a \circ b) = b $$ For example, XOR is like this: $$ a \oplus a \oplus b = b $$","['functions', 'terminology']"
3316558,Classifying Solutions to $f^n(x) = x$,"Let $f: \mathbb{R} \to \mathbb{R}$ be continuous everywhere in $\mathbb{R}$ except on some finite set. Suppose we also have $f^n(x) = x$ for all $x$ where $f$ is defined. Note that by $f^n(x)$ I mean the $n$ th composition of $f$ with itself.
Given a fixed $n$ , how do you classify all solutions to this? For $n=1,2$ this is easy enough. But when $n=3$ we have for example, $f(x) = \frac{1}{1-x}$ . It's not obvious how to find all the solutions to $f^3(x) = x$ .","['functional-equations', 'real-analysis']"
3316605,A problem on measurability of a function,"let $f$ be a real valued finction.
  If for each $k \gt 0, \ f^{-1}((-k,k))$ is a measurable set, then $f$ is a measurable function. Is this statement true? I think it is true but i cannot find a proof.","['measure-theory', 'real-analysis']"
3316621,one-one and onto proofs,"Prove that if $f$ takes the $[-1,1]$ onto $[-1,1]$ , then $$f^{-1}(f(\{ 0 \})) = \{ 0 \}$$ Proof : Let the domain $= X$ which is the set $[-1,1]$ Let the co-domain $=Y$ which is the set $[-1,1]$ . $f$ onto implies that there exists an inverse function $g: Y \to X$ called the inverse S.T. $g(f(x))= x$ and $f(g(y))=y$ . Since $0 \in X$ and $0 \in Y$ it follows directly that $g(f(0))=0$ and $f(g(y))=y$ which proves the claim. Let $X,Y$ be sets and $f: X \to Y$ . Prove that : $$f(A\setminus B) = f(A)\setminus f(B)$$ TO be honest I am not even sure what this question is asking. It is very hard to imagine functions as cartesian products..","['elementary-set-theory', 'functions', 'proof-verification']"
3316623,How many possible different weekly schedules are there if an employee works five full days and two half-days?,"A firm works $7$ days a week.
Every employee must work exactly $5$ full days and $2$ half-days each week.
A half-day can be either morning or afternoon, and two half-days cannot be held on the same day.
How many possible different weekly schedules are there? I have tried $5{7\choose5}+2{7\choose2}$ but i am still getting the incorrect answer.
The correct answer is $84$ . Can someone explain what I am doing wrong in my working out?
Thanks",['combinatorics']
3316638,Special function related to a nonlinear ODE,"I am interested in finding a special function solution of the following ODE $ (r S)^{\prime \prime} = - 2 r S^2 $ with initial conditions $ S(0)=1, S^\prime(0) = 0 $ . The method of Frobenius gives the infinite series $
S= 
1 -\frac{{{r}^{2}}}{3}+\frac{{{r}^{4}}}{15}-\frac{11 {{r}^{6}}}{945}+\frac{16 {{r}^{8}}}{8505}-\frac{97 {{r}^{10}}}{334125} +\frac{914 {{r}^{12}}}{21049875} +H.O.T
$ and the following recursion among the coefficients: $ a_n= - \frac{2}{n (n+1)}\sum\limits_{j=0}^{n-2}{\left. a_j a_{n-j-2} \right.}$ The question is: is this function related to the generalized hypergeometric functions? If yes - what is the relationship?","['frobenius-method', 'special-functions', 'ordinary-differential-equations', 'hypergeometric-function']"
3316657,How to show that $\int_{0}^{\frac{\pi}{4}}\ln(\sqrt{\tan x}+\sqrt{\cot x} -\sqrt{2})\ dx=0$,"How can I show that $$\int_{0}^{\frac{\pi}{4}}\ln(\sqrt{\tan x}+\sqrt{\cot x} -\sqrt{2})\ dx=0$$ I saw this integral on AoPS, and one person provides a solution: Let $$I:=\int_0^\frac{\pi}{4} \ln(\sqrt{\tan x}+\sqrt{\cot x}-\sqrt 2 ) \ dx, \ \ \ \ \ J:=\int_0^\frac{\pi}{4} \ln(\sqrt{\tan x}+\sqrt{\cot x}+\sqrt 2 ) \ dx.$$ I show that $$I=0, \ \ \ \ \ J=\frac{\pi}{2}\ln 2. \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1)$$ We have $$I+J=\int_0^{\pi/4}\ln(\tan x+\cot x) \ dx=\int_0^{\pi/4}(\ln 2-\ln(\sin(2x)) \ dx=\frac{1}{2}\int_0^{\pi/2}(\ln 2-\ln(\sin x)) \ dx$$ $$=\frac{\pi}{4}\ln 2-\frac{1}{2}\int_0^{\pi/2}\ln(\sin x) \ dx=\frac{\pi}{2}\ln 2. \ \ \ \ \ \ \ \ \ \ \ \ \ (2)$$ Next is to compute $I-J.$ To avoid the mess, as much as we can, we put $\tan x = t^2$ to get $$I=\int_0^1\ln\left(t+\frac{1}{t}-\sqrt{2}\right)\frac{2t}{t^4+1} \ dt, \ \ \ \ \ J=\int_0^1\ln\left(t+\frac{1}{t}+\sqrt{2}\right)\frac{2t}{t^4+1} \ dt$$ and changing $t$ to $1/t$ gives $$I=\int_1^{\infty}\ln\left(t+\frac{1}{t}-\sqrt{2}\right)\frac{2t}{t^4+1} \ dt, \ \ \ \ \ \ J=\int_1^{\infty}\ln\left(t+\frac{1}{t}+\sqrt{2}\right)\frac{2t}{t^4+1} \ dt.$$ Thus $$I=\int_0^{\infty}\ln\left(t+\frac{1}{t}-\sqrt{2}\right)\frac{t}{t^4+1} \ dt, \ \ \ \ \ \ J=\int_0^{\infty}\ln\left(t+\frac{1}{t}+\sqrt{2}\right)\frac{t}{t^4+1} \ dt$$ and hence, since $\int_0^{\infty} \frac{t\ln t}{t^4+1} \ dt=0$ (just change $t$ to $1/t$ to see that), we get $$I=\int_0^{\infty}\frac{t\ln(t^2-\sqrt{2}t+1)}{t^4+1} \ dt, \ \ \ \ \ J=\int_0^{\infty}\frac{t\ln(t^2+\sqrt{2}t+1)}{t^4+1} \ dt.$$ Therefore $$I-J=\int_0^{\infty}\frac{t}{t^4+1}(\ln(t^2-\sqrt{2}t+1)-\ln(t^2+\sqrt{2}t+1)) \ dt. \ \ \ \ \ \ \ \ \ \ \ (3)$$ We now use integration by parts with $\frac{t}{t^4+1} \ dt=dv, \ \ \ \ln(t^2-\sqrt{2}t+1)-\ln(t^2+\sqrt{2}t+1)=u.$ Then $$v=\frac{1}{2}\tan^{-1}(t^2), \ \ \ du=\frac{2\sqrt{2}(t^2-1)}{t^4+1} \ dt$$ and so $(3)$ becomes $$I-J=-\sqrt{2}\int_0^{\infty}\frac{t^2-1}{t^4+1}\tan^{-1}(t^2) \ dt=-\sqrt{2}\int_0^{\infty}\frac{t^2-1}{t^4+1}\int_0^1\frac{t^2}{s^2t^4+1} \ ds \ dt=-\sqrt{2}\int_0^1\int_0^{\infty}\frac{t^2(t^2-1)}{(t^4+1)(s^2t^4+1)} \ dt \ ds$$ $$=-\sqrt{2}\int_0^1\frac{1}{1-s^2}\left(\int_0^{\infty}\frac{s^2t^2+1}{s^2t^4+1} \ dt-\int_0^{\infty}\frac{t^2+1}{t^4+1} \ dt \right)ds.$$ So changing $t$ to $t/\sqrt{s}$ in $\int_0^{\infty}\frac{s^2t^2+1}{s^2t^4+1} \ dt$ gives $$I-J=-\sqrt{2}\int_0^1\frac{1}{1-s^2}\left((\sqrt{s}-1)\int_0^{\infty}\frac{t^2}{t^4+1} \ dt+\left(\frac{1}{\sqrt{s}}-1\right)\int_0^{\infty} \frac{dt}{t^4+1}\right)ds$$ $$=-\frac{\pi}{2}\int_0^1\frac{1}{1-s^2}\left(\sqrt{s}+\frac{1}{\sqrt{s}}-2\right)ds=-\frac{\pi}{2}\ln 2. \ \ \ \ \ \ \ \ \ \ \ (4)$$ Now $(1)$ follows from $(2)$ and $(4).$ This is an elegant solution, but I wonder if there are other ways to solve the integral.","['integration', 'calculus', 'trigonometry']"
3316660,How to reliably lay out continuous unfolded diagrams of 3D shapes,"This is a bit of an interdisciplinary question, but I suppose here is the best place to put it. I am designing a 3D printed plastic toy with LEDs and knobs in Blender using Python. The LEDs are soldered to a long strip of flexible circuit board, which is weaved through the plastic structure. The 3D shape in question is produced as follows. Take a unit 4D cube, and on all 8 of its faces, place the following 3D object: a 3x3x3 grid of rhombicuboctahedra, joined by square prisms. Project this 4D object to 3D using fisheye projection. But for simplicity, let's focus only on one of the faces, ideally one of the more distorted ones. The model can be downloaded here: STL File . Now, I want an LED on every triangle face of every rhombicuboctahedron of that face, all of them connected with a single strip of flexible circuit board. Constraints The circuit board must touch the 3D surface the circuit board may not intersect itself when spread flat The circuit may not cross itself once folded onto the 3D body The strip may not go over the thin faces of the distorted prism. My question is, how to reliably and efficiently design the shape of the flexible circuit board? I can usually get about 12 rhombicuboctahedra covered, but then as they become used up and the path within the grid becomes more and more constrained, I struggle to not run into the self-intersection problem.",['geometry']
3316686,Expected Value Problem with 100 side dice and 100 doors,"One hundred doors, one dollar behind each door. Roll a  one-hundred dice for one hundred times. You can take the dollar after the door whose number is rolled out but the dollar is not replaced. What's the expectation? What I tried: I tried to write a general formula taking ideas from the Coupon collector problem. I found that the E[X]= (N-n)/N where N is the total number of doors and n is the amount we've opened but I don't think that works. Any advice would be appreciated.","['expected-value', 'probability']"
3316689,Find joint distribution of same-mean normal variables,"Suppose I have a variable $C$ and a set of $N$ variables $L_1, L_2, ..., L_N$ that are distributed according to: $$\begin{aligned}
C &\sim \mathcal N \left(\mu, \delta^2 \right) \\
\forall i. L_i | C=c &\sim \mathcal N\left(c, \sigma_i^2 \right)
\end{aligned}$$ That is, conditional on knowing the value of $C$ , the $L_i$ are normally independently distributed with mean $c$ and variance $\sigma_i^2$ . This implies that the vector $\vec L = (L_1, ..., L_N)^T$ is distributed according to a N-dimensional multivariate normal with mean vector $\vec \mu$ and covariance matrix $\mathbf \Sigma$ . When $N=1$ , it is straightforward to see that $L_1 \sim \mathcal N \left(\mu, \delta^2 + \sigma_1^2 \right)$ . It seems to me like this should imply that $\vec \mu = (\mu, ..., \mu)^T$ , and that the diagonal elements of $\mathbf \Sigma$ should be $\delta^2 + \sigma_i^2$ . The off-diagonal elements of the covariance matrix are, of course, not zero, since the variables $L_i$ are not independent when I'm not conditioning on $C$ . Is this true, though? Is there a way for me to prove this in a less tedious way than algebraically working everything out? What are the values of the off-diagonal elements?","['statistics', 'probability-distributions', 'bayesian', 'normal-distribution', 'probability-theory']"
3316706,Cannot solve $ y = xy'+x^3(y')^2 $,"I'm trying to solve the following differential equation: $$ y = xy'+x^3(y')^2 $$ I have tried almost every method for solving first order differential equations, and did many substitutions $ y=u(x)p(x) $ , using various functions as $ u(x) $ . However, I still cannot find its general solution. I would appreciate any hint.",['ordinary-differential-equations']
3316717,Linear equation $ax=b$ that holds for all $x$.,"If the solution of the linear equation $$4x+k(2x-8)=16$$ is all numbers, find the value of $k$ . What I have tried: \begin{align}
  4x+k(2x-8) &= 16 \\
  4x+2kx-8k &= 16 \\
  (4+2k)x &= 16+8k \\
  x &= \frac{16+8k}{4+2k} \\
  &= 4+4k
\end{align} I am struggling please help!",['algebra-precalculus']
3316729,Approximate embeddings of the hyperbolic plane in $\Bbb R^3$,"It is known that there is no isometric embedding of the hyperbolic plane into $\Bbb R^3$ that is $C^2$ or higher. (The Nash-Kuiper theorem guarantees the existence of an exact $C^1$ embedding.) How does this situation change if we look at approximate embeddings, in which the embedded geodesic distance is always within some arbitrarily small $\epsilon$ of the true hyperbolic distance? Are $C^\infty$ approximate embeddings guaranteed to exist for any arbitrarily small $\epsilon$ ? If not, what is the smallest such $\epsilon$ , and how does this change if we look at $C^2$ instead? Formally, let's assume there is some map, call it $f$ , which maps from $\Bbb H^2$ to $\Bbb R^3$ , and that this mapping is suitably smooth (at least $C^2$ , preferably $C^\infty$ ). Let's say that $d(a,b)$ is the distance between any two points in the hyperbolic plane, and $d_f(a,b)$ is the geodesic distance on the embedded surface in $\Bbb R^3$ . Then an "" $\epsilon$ -approximate embedding"" is one in which $|d_f(a,b) - d(a,b)| < \epsilon$ , for all $a, b$ . Then the question is, what is the largest $n$ such that a $C^n$ approximate embedding of $\Bbb H^2 \to \Bbb R^3$ exists for all arbitrarily small $\epsilon$ ? And if such embeddings don't exist, are there any lower bounds on how small $\epsilon$ can be?","['isometry', 'hyperbolic-geometry', 'approximation', 'differential-geometry']"
3316742,"What is wrong in my ""proof"" that $\cup_{k=N}^{\infty} E_k - \cap_{k=N}^{\infty} E_k = \emptyset$","I was doing a problem involving limits of sets, and I wanted to figure out what $$\bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k$$ is. I got that it is empty, which is obviously false (for instance, $E_k = \{k \}$ is a counterexample). The following is my ""proof."" Could you please take a look and point out the mistake? Thanks. We begin with the original: $$\bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k.$$ Definition of set difference $$\left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left( \bigcap_{k=N}^{\infty} E_k\right)^c$$ DeMorgan's Law $$\left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c \right) $$ Distribution Law $$\bigcup_{k=N}^{\infty} \left[ E_k \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c   \right) \right] $$ Distribution Law again $$\bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} E_k \cap E_k^c\right]$$ $$=\bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} \emptyset\right] $$ $$= \emptyset$$","['elementary-set-theory', 'analysis', 'real-analysis']"
3316749,Trouble with the Proof of a Multi-variable Integration Theorem,"One of my classes has online notes containing theorems.  One of the theorems is ""Assume that $R=[a,b]\times[c,d]$ is a rectangle in the $xy$ plane.  Let $f$ be a function on $R$ , and assume that $f$ is integrable on $R$ , and for every $y\in[c,d]$ , the function $f_y:[a,b]\to\mathbb{R}$ defined by $f_y:=f(x,y)$ is integrable on $[a,b]$ .  Then the function $g:[c,d]\to\mathbb{R}$ defined by $g(y):=\int^b_af(x,y)dx$ is integrable on $[c,d]$ , and $$\int\int_RfdA=\int^d_cg(y)dy=\int^d_c\left(\int^b_af(x,y)dx\right)dy.""$$ They say the proof is left as an exercise, but I don't know how to do it. A hint was that I could first show that for every $k\in\{1,\dots,K\}$ and for every $y\in[y_{k-1},y_k]$ , we have that $$g(y)\geq\sum^J_{j=1}m_{jk}(f)(x_j-x_{j-1}).$$ Thanks in advance!","['integration', 'multivariable-calculus', 'integer-partitions', 'real-analysis']"
3316765,Looking for a book on a 1st differential equations course [duplicate],"This question already has answers here : Could you recommend some classic textbooks on ordinary/partial differential equation? (6 answers) Closed 4 years ago . I'm currently taking differential equations but the guide book (Elementary differential equations and boundary value problems) is aimed for engineers (much like the calculus one from Stewart). I'm looking for a book with the classic mathematical format (definition, theorem, corollary...) and not too much talk or applications. Thanks","['book-recommendation', 'ordinary-differential-equations', 'reference-request']"
3316787,"Distribution of X/(XY-WZ) when all RVs are distributed (iid) U(0,1)","Assume that we have four random variates $W, X, Y, Z$ such that $W, X, Y, Z\overset{iid}{\sim} U(0,1)$ . I wish to determine the distribution of the following: \begin{equation}
 Q = \frac{X}{XY-WZ}
\end{equation} From prior questions , we can determine the distribution of $XY$ and $WZ$ , however, I am not quite sure how to handle the rest. If anyone could assist, I would be very thankful. BTW - This is not for a course. I am just rusty at my mathematical statistics.",['statistics']
3316798,Can we show that the determinant of this matrix is non-zero?,"Consider the following symmetric matrix $M=
  \begin{bmatrix}
    f(x) & f(2x) & \dots & f(nx)\\
    f(2x) & f(4x) & \dots & f(2nx)\\ 
    \vdots & \vdots & \dots & \vdots\\ 
    f(nx) & f(2nx) & \dots & f(n^2x)
  \end{bmatrix}$ , where $f(x): \mathbb{R} \rightarrow \mathbb{R}$ is a continuous, nonlinear, and strictly increasing that satisfies the following properties: $f(0) = 0$ and $f(x \neq 0) \neq 0$ If $a,b,c,d \neq 0$ and $ab = cd$ and $a+b > c+d \Rightarrow f(a)f(b) < f(c)f(d)$ . Can we show that there exists an $x \in \mathbb{R}$ such that the determinant of $M$ is non-zero? Proof for $n=1$ is trivial. For $n=2$ we have $det(M) = f(x)f(4x) - f(2x)f(2x)$ , which is less than 0 for $x > 0$ and greater than 0 for $x < 0$ based on assumption 2. Can we prove this for a general $n$ ? EDIT:
I simulated matrix $M$ for different values of $n$ and the determinant is non-zero for almost every $x$ . Is it possible to perhaps prove this by contradiction? EDIT2: Another way to look at this problem is to show that $f(mx)$ are linearly independent functions. In other words, if $k_1 f(x) + k_2 f(2x) + \dots k_n f(nx) = 0$ , for all $x \in \mathbb{R}$ , then $k_1 = k_2 = \dots = k_n = 0$ . Under what conditions on $f$ , $f(mx)$ are linearly independent?","['determinant', 'vectors', 'functional-inequalities', 'vector-spaces', 'matrices']"
3316816,Formula for $n^{th}$ derivative of $1/(x^2 +1)$,"I am completely done with this problem. I transformed $x^2+1$ to $(x+i)(x-i)$ , also used standard form of $n^{th}$ derivative of $\arctan(x)$ , again gone negative binomial expansion but nothing is working. If anyone can make it I will be very glad. The question is: Show that the $n^{th}$ derivative of $1/(x^2+1)$ is equal to $$
\frac{(-1)^n \cdot n!}{(x^2+1)^{n+1}} \cdot \left[(n+1)x^n - \,{}^{n+1}C_3 \,x^{n-2} +\,{}^{n+1}C_5\,x^{n-4} - \cdots \right]
$$","['induction', 'derivatives', 'analysis']"
3316821,Positive derivative implies increasing without Mean Value Theorem,"The result below is usually proven by using the Mean Value Theorem (see e.g. ProofWiki ). But can we also prove it more directly (and fairly elegantly) without resort to the MVT? Suppose $f:[a,b]\rightarrow \mathbb{R}$ is differentiable. If $f'(x)\geq0$ for all $x\in[a,b]$ , then $f$ is increasing on $[a,b]$ . If $f'(x)>0$ for all $x\in[a,b]$ , then $f$ is strictly increasing on $[a,b]$ . If $f'(x)\leq0$ for all $x\in[a,b]$ , then $f$ is decreasing on $[a,b]$ . If $f'(x)<0$ for all $x\in[a,b]$ , then $f$ is strictly decreasing on $[a,b]$ .","['calculus', 'derivatives', 'monotone-functions', 'real-analysis']"
3316872,Help with the model theoretic proof of the Nullstellensatz?,"Am struggling a bit with a step of the model theoretic proof of the Nullstellensatz. The proof essentially runs as follows:
Take $I\subset J\subset K[x_1, ..., x_n]$ radical ideals of some algebraically closed field $k$ , and let $f\in J\setminus I$ . By a simple lemma we may find a prime ideal $P\subset K[x_1, ..., x_n]$ containing $I$ but not $f$ . Then $K[x_1, ..., x_n]/P$ is an integral domain, so let $L$ be the algebraic closure of its fraction field. Then, if $f_1, ..., f_m$ generate $I$ , and $\phi$ is the sentence expressing that there exists $(y_1, ..., y_n)$ a mutual root of $f_1, ..., f_m$ and not a root of $f$ , $L\models \phi$ (seen by taking $y_i=x_i/P\in L)$ . Now, so the argument runs, by model-completeness of the theory of algebraically closed fields we must also have $K\models \phi$ , and so there exists some element of $K^n$ that is a root of $f_1, ..., f_n$ but not $f$ . Hence $V(J)\neq V(I)$ and so we are done. Almost all of this is clear to me; the one thing that's tripping me up is in the application of the model-completeness of ACF. In particular, we have to show that there an embedding of $K$ into $L$ for the result to apply, and this isn't entirely obvious to me. Will someone tell me if the following argument is correct? : Of course $K$ can be interpreted as the constant subfield of $K[x_1, ..., x_n]$ , and so can we identify each $r\in K$ with the coset $r/P\in L$ . The only necessary thing is to show injectivity of this identification; if $P$ does not contain a unit, then injectivity is clear. If $P$ does contain a unit, then $P=K[x_1, ..., x_n]$ , a contradiction as we supposed that $f\notin P$ .","['model-theory', 'logic', 'field-theory', 'algebraic-geometry', 'commutative-algebra']"
3316878,Determining the range of $6^n+ 6^{-n} +3^n +3^{-n}+2$,"I have to solve for range of the function $$6^n+ 6^{-n} +3^n +3^{-n}+2$$ The textbook solves it as $$\left(\sqrt{6^n} -\sqrt{ 6^{-n}} \right)^2 + \left(\sqrt{3^n} -\sqrt{ 3^{-n}} \right)^2 +6 \tag{1}$$ i.e., $$(a-b)^2+(a-b)^2$$ which will always be greater than $6$ , so the range is $(6,\infty)$ (since other two terms are squared). But, if we take $$\left(\sqrt{6^n} +\sqrt{ 6^{-n}} \right)^2 + \left(\sqrt{3^n} +\sqrt{ 3^{-n}} \right)^2 +2 \tag{2}$$ or $$\left(\sqrt{6^n} +\sqrt{ 6^{-n}} \right)^2 + \left(\sqrt{3^n} +\sqrt{ 3^{-n}} \right)^2 +2 \tag{3}$$ instead of $(1)$ , we get that the range is $(-2,\infty)$ or $( 2,\infty)$ , respectively. So, how do we know what range is correct?","['functions', 'relations']"
3316883,A stick is broken and its left part is discarded.Probability that one of them $>1$ [duplicate],"This question already has answers here : Broken stick probability problem (3 answers) Closed 4 years ago . A stick of length $2$ m is made of uniformly dense material. A point is chosen randomly on the stick and the stick is broken at that point. The left portion of the stick is discarded and now again another point is chosen randomly on the remaining right portion of the stick and the stick is broken again at that point and the left part is again discarded.The process is continued indefinitely.What is the probability that one of the discarded left parts has length $>1$ m? Formulating this problem we basically have a sequence of random variables { $X_n$ } where $X_1 \sim U(0,2)$ , $X_2|X_1 \sim U(0,2-X_1)$ , $X_3|X_1,X_2 \sim U(0,2-X_1-X_2)$ and so on.
The probability that any one of the discarded parts is more than $1$ m is equivalent to say that it is $1-P(\cap$ { $ X_i<1$ })
But I cannot find the probability explicitly as it is dependent on $X_1$ .
Help!","['statistics', 'uniform-distribution', 'probability-distributions', 'probability-theory', 'probability']"
3316896,"What is the geometric intuition for the $\bar \partial$-Poincare lemma, or for $\bar \partial$ more generally?","The one variable $\bar \partial$ -Poincare lemma is proven in Huybrechts and Forster  and so on in essentially the same way: one shows that for a local form $f d \bar z$ , with $$g(z) := \frac{1}{2\pi i} \int_{B_\varepsilon} \frac{f(w)}{w-z} dw \wedge d\bar w$$ we have $\bar \partial g = fd\bar z$ . I can follow the proof on a formal, line by line level, but the manipulations used to obtain the result really don't have any geometric meaning to me, partially because I really don't understand how I should think of $\bar \partial$ except as ""some operator with kernel the holomorphic functions, and which we really really want to be locally exact so that we can use sheaf cohomology.""  My questions here are: is there any intuitive reason the lemma would be true at all, and why should this integral, which suspiciously resembles that of the Cauchy integral formula, be the correct $g$ , and is there more geometric intuition for the $\bar \partial$ operator generally than 'it kills holomorphic functions'?","['complex-geometry', 'complex-analysis', 'intuition', 'complex-integration', 'homology-cohomology']"
3316961,linear differential equation word problem (salt problem),The question is as follows: I am confused because of intial and after 30 mins concentration dont know how to split that. Still here is what i tried: concentration initially = $2\times 2 = 4000g/min$ after 30 min = $2\times 1 = 2000g/min$ Inflow rate : $di/dt = 2000$ after 30 mins outflow rate : $do/dt = 2 l/min$ Now not sure how to implement $y(t)$ here after 30 mins will it be ? $$4000-\frac{y}{10}=y'$$ ?,"['ordinary-differential-equations', 'word-problem', 'calculus', 'algebra-precalculus', 'derivatives']"
3316965,The structure sheaf can be computed as the intersection of stalks,"Let $X$ be an integral scheme. Let $U\subset X$ be a non-empty open set. There is a canonical identification $\mathcal{O}_{U, \eta}\approx \mathcal{O}_{X, \eta}$ where $\eta$ is the generic point. Are the subrings $\mathcal{O}_X(U)\subseteq\mathcal{O}_{X, \eta}$ and $\bigcap_{p\in U}\mathcal{O}_{X, p}\subseteq\mathcal{O}_{X, \eta}$ equal? If $X$ is affine it holds for $U=X$ ( An integral domain $A$ is exactly the intersection of the localisations of $A$ at each maximal ideal ). In the case $X=\mathrm{Spec}\:R$ where $R$ is a DVR it is true for $U=\{\eta\}$ because $\mathcal{O}_X(U)$ is the fraction field.",['algebraic-geometry']
3316977,"For $f:\mathbb{N}\to\mathbb{N}$ with $f(1)=1$, $f(2n)=f(n)$, $f(2n+1)=f(n)+f(n+1)$, show that the range of $f$ is $\mathbb{N}$","Question: A function $f : ℕ \rightarrow ℕ$ is defined by $f(1)=1$ , and for all $n\geq 1$ , $$f(2n)=f(n)$$ $$f(2n+1)=f(n)+f(n+1)$$ Prove that the range of $f$ is $ℕ$ . Thoughts: I was first thinking to prove this by showing that the first function will always yield a positive integer because f(2) = 1 and it is only defined by f(1)=1, meaning if it is a negative number of decimal, it won't work. Also, I was guessing that the first function was for even numbers. But... I got a little stuck on proving the range for the second function. Using the same logic as before, I presumed that the second function was meant for odd numbers as any odd number can be represented by 2n+1. However, I don't know how to properly show that the range is only restricted to natural numbers as I'm guessing I can't simply say that it is not defined when it is anything but a natural number. Am I going in the wrong direction with my thinking? Any help would be extremely appreciated!","['alternative-proof', 'proof-explanation', 'functions']"
3316991,Prove $\sin(a) < a < \tan(a)$ when $0 < a < \pi/2$,"It is easy to prove that $\sin(a) < \tan(a)$ when $0 < a < \pi/2$ , but how can I prove that $\sin(a) < a < \tan(a)$ when $0 < a < \pi/2?$",['trigonometry']
