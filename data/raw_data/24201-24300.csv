question_id,title,body,tags
213851,How to find the min and max of $y = x \sin(\ln|x|)$?,"I'm trying to find the minimum and maximum points of the following equation: $y = x \sin(\ln|x|)$ where $x > 0$ which, when graphed, looks something like this: I tried deriving the equation using the chain rule: $$\begin{align}\frac{dy}{dx} &= \frac{d}{dx}\left(x \cdot \sin(\ln|x|)) \right) \\
& = \sin(\ln|x|) + x \cos(\ln|x|) \frac{1}{x} \\
& = \sin(\ln|x|) + \cos(\ln|x|)
\end{align}$$ ...and setting it equal to zero: $$0 = \sin(\ln|x|) + \cos(\ln|x|)$$ I set $\ln|x|$ equal to $\frac{3\pi}{4}$ or $\frac{7\pi}{4}$ (because using the unit circle, using those two should cause the sin and cos to cancel out), so that $x = e^{{3\pi}/{4}}$ or $x = e^{{7\pi}/{4}}$, but both of those are clearly far more higher then the x-coordinates of the min and max points in the graph. How can I find the min and max x-coordinates of this equation? This is a homework problem I've been puzzling over for some time, so either hints or full answers would be appreciated.","['calculus', 'derivatives']"
213872,"Why are half-open intervals $(a,b]$ ""special"" in probability theory?","I'm learning probability theory and I see the half-open intervals $(a,b]$ appear many times. One of theorems about Borel $\sigma$-algebra is that The Borel $\sigma$-algebra of ${\mathbb R}$ is generated by inervals of the form $(-\infty,a]$, where $a\in{\mathbb Q}$. Also, the distribution function induced by a probability $P$ on $({\mathbb R},{\mathcal B})$ is defined as
$$
F(x)=P((-\infty,x])
$$ Is it because for some theoretical convenience that the half-open intervals are used often in probability theory or are they of special interest?","['probability-theory', 'soft-question']"
213879,What is the curvature 2-form on the associated vector bundle?,"Consider a principal bundle $P\rightarrow M$ and the associated vector bundle $P\times_{\rho}V$ over $M$ such that $(p,v)=(pg^{-1},\rho(g)v)$. The connection on the principal bundle $A$ defines a covariant derivative on $P\times_{\rho}V$ as follows. View a section $s$ on $P\times_{\rho}V$ as a $G$-equivariant map $s^{P}:P\rightarrow V$. This means $S^{P}(pg^{-1})=\rho(g)s^{P}(p)$. This defines a $G$-equivariant homomorphism $s^{P}_{*}$ from $TP$ to $V$. Let $x\in M$ and $v\in TM_{x}$, $H_{A}$ be the horizontal vector bundle in $TP$ defined by $A$. Then for any $p$ be the inverse image of $x$, there is a unique horizontal vector $v_{A}\in H_{A}|_{p}$ being the horizontal lift of $v$ such that $\pi_{*}v_{A}=v$. The covariant derivative $\nabla_{A}$ sends section $v$ to the equivalence of the pair $(p,s^{P}_{*}v_{A})$. A routine exercise showed this is not dependent on the choice of $p$. Taubes claim in his book Differential Geometry that locally we can write the covariderive $\nabla_{A}$ on $P\times_{\rho}V$ as $$x\rightarrow (x,ds_{U}+\rho_{*}(a_{U})s_{U})$$where $\rho_{*}:\mathcal{G}\rightarrow End(V)$ is the differential of $\rho$ at the identity. I do not understand how he derived this identity given the above definition of $\nabla_{A}$. Even if we use the canonical identification $$\phi_{U}^{*}H_{A}=(x,-g^{-1}a_{U}(v)g)\in TU\oplus \mathcal{G}$$ where $\phi_{U}^{*}$ is the local trivialization. I still do not know how to derive the desired identity. Note in particular the connection 1-form on $P$ is given by $$g^{-1}dg+g^{-1}a_{U}g$$ where $a_{U}:U\rightarrow \mathcal{G}\otimes T^{*}M$. However I do not know how to put all these formulas together.",['differential-geometry']
213904,"How to prove the sequence $a_0, a_1, \ldots$ converges iff $a_0, a, a_1, a \ldots$ converges?","Problem Prove that the sequence $a_0, a_1, a_2, \ldots$ converges to $a$ if and only if the 
  sequence $a_0, a, a_1, a, a_2, a, a_3, \ldots$ converges. Here is my approach: $\Rightarrow$: Since $a_0, a_1, a_2, \ldots$ converges to $a$, by definition of limit,
            for every $\epsilon > 0$, $\exists N \in \mathbb{N}$ such that for all 
            $n > N$, then $|a_n - a| < \epsilon$. Now consider the subsequence
            $$a, a, a, a, \ldots$$
            We have that $|a - a| < \epsilon, \, \, \forall \epsilon > 0$, thus
            $a, a, a, a \ldots$ also converges to $a$. Hence,
            $a_0, a, a_1, a, a_2, a, a_3, \ldots$ converges. $\Leftarrow$: Suppose that $a_0, a, a_1, a, a_2, a, a_3, \ldots$ converges to $L$, 
            $L \neq \pm \infty$, by definition of limit, for every $\epsilon > 0$, $\exists N \in \mathbb{N}$ 
            such that for all $n > N$, then $|a_n - a| < \epsilon$, thus there must be a sequence
            $$a_{N+1}, a, a_{N+2}, a, a_{N+3}, a, a_{N+4}, \ldots$$
            that is getting closer and closer to $L$. But there is always an alternating 
            $a$ between each $a_i$ and $a_{i+1}$, so $L = a$ otherwise $|a_n - L| < \epsilon$ would
            make no sense. Therefore $a_0, a_1, a_2, \ldots$ converges to $a$. However I still feel it's not complete because all my reasons were based on the definition of infinite sequence. I think there must be a way to give a strong argument for this problem. I wonder if anyone could give me a hint/suggestion on my solution? Thanks.","['limits', 'sequences-and-series', 'analysis']"
213906,"Does the following function on $ \mathbb{R}^{4} $ iterate to $ (0,0,0,0) $ after infinitely many steps?","Define $ f: \mathbb{R}^{4} \rightarrow \mathbb{R}^{4} $ by
\begin{equation}
\forall (a,b,c,d) \in \mathbb{R}^{4}: \quad f(a,b,c,d) \stackrel{\text{def}}{=} (|a - b|,|b - c|,|c - d|,|d - a|).
\end{equation} For many of the 'obvious' $ (a,b,c,d) \in \mathbb{R}^{4} $ that you start with, you will obtain $ {f^{n}}(a,b,c,d) = (0,0,0,0) $ for all $ n \in \mathbb{N} $ large enough. There is also an example where $ {f^{n}}(a,b,c,d) \neq (0,0,0,0) $ for all $ n \in \mathbb{N} $ but still $ \displaystyle \lim_{n \rightarrow \infty} {f^{n}}(a,b,c,d) = (0,0,0,0) $. The example is constructed as follows. Let $ \alpha $ be the real root of the quartic polynomial $ x^{4} - 2 x^{3} + 1 = 0 $ that lies in the interval $ (1,2) $. Then
\begin{align}
f(1,\alpha,\alpha^{2},\alpha^{3}) &= (|1 - \alpha|,|\alpha - \alpha^{2}|,|\alpha^{2} - \alpha^{3}|,|\alpha^{3} - 1|) \\
&= (\alpha - 1,\alpha^{2} - \alpha,\alpha^{3} - \alpha^{2},\alpha^{3} - 1) \\
&= (\alpha - 1) \cdot (1,\alpha,\alpha^{2},\alpha^{3}),
\end{align}
where the last equality is obtained by observing that $ (\alpha - 1) \alpha^{3} = \alpha^{3} - 1 $, which, in turn, is obtained from the quartic polynomial above. It follows that $ {f^{n}}(1,\alpha,\alpha^{2},\alpha^{3}) = (\alpha - 1)^{n} \cdot (1,\alpha,\alpha^{2},\alpha^{3}) $ for all $ n \in \mathbb{N} $. As $ \alpha - 1 \in (0,1) $, we see that $ \displaystyle \lim_{n \rightarrow \infty} {f^{n}}(1,\alpha,\alpha^{2},\alpha^{3}) = (0,0,0,0) $, but clearly, no term is equal to $ (0,0,0,0) $. Is there an example where $ {f^{n}}(a,b,c,d) $ does not converge to $ (0,0,0,0) $? Thanks!",['functions']
213912,"Comparing probability and dimension forumulas, concidence?","So we know that if given two finite vector spaces $V,W$ then the $\dim(V+ W)=\dim(V)+\dim(W)-\dim(V\cap W)$ This curiously corresponds with the Probability formula of, given two probabilities $P(A\cup B)=P(A)+P(B)-P(A\cap B)$ Question, is this a mere coincidence or is there something deeper going on? Probabilities are always numbers between 0 and 1, the dimension of a vector space is, I assume, always a natural number. So anything special going on?","['probability-theory', 'linear-algebra']"
213928,What is $\cot(\pi/2)$?,"Base on the unit circle, I know $
\begin{align}
&\cot\left(\frac{\pi}{2}\right) \\
=&\frac{0}{1}\\
=&0
\end{align}
$ But it is also $
\begin{align}
&\cot\left(\frac{\pi}{2}\right) \\
=&\frac{1}{\tan\left(\frac{\pi}{2}\right)}\\
=&\frac{1}{\frac{1}{0}}\\
=&undefined
\end{align}
$ And Google gives me this answer: $6.12303177 × 10^{-17}$ I am really confused now. Although I know it is $0$, I don't see why the other ones are wrong.","['geometry', 'trigonometry']"
213936,Prove: Convergent sequences are bounded,"I don't understand this one part in the proof for convergent sequences are bounded. Proof: Let $s_n$ be a convergent sequence, and let $\lim s_n = s$ . Then taking $\epsilon = 1$ we have: $n > N \implies |s_n - s| < 1$ From the triangle inequality we see that: $ n > N \implies|s_n| - |s| < 1 \iff |s_n| < |s| + 1$ . Define $M= \max\{|s|+1, |s_1|, |s_2|, ..., |s_N|\}$ . Then we have $|s_n| \leq M$ for all $n \in N$ . I do not understand the defining $M$ part. Why not just take $|s| + 1$ as the bound, since for $n > N \implies |s_n| < |s| + 1$ ?","['sequences-and-series', 'real-analysis']"
213951,parallel vectors along a curve,"What does it mean for a vector field X(t) to be parallel along a curve, gamma(t)? and how can we show that if X(t) is parallel along gamma(t), then |X(t)| is constant? Thanks",['differential-geometry']
213958,Generating Functions: Partitions of Integers,"I'm somewhat stuck on a problem involving using generating functions to determine the number of possible solutions to an equation.  I've attempted to solve the problem by following an example in my textbook, however I am unsure still if I have correctly answered the problem. The problem follows: Find the generating function for the number of integer solutions of: a) $2w + 3x +5y + 7z = n$ where $0 \leq w, x, y, z$ b) $2w + 3x + 5y + 7z = n$ where $ 0 \leq w, 4 \leq x, y, 5 \leq z$ Now, the work I've so far attempted to do is to assign the following functions to each of the terms: $2w = 1+a^2+a^4+a^6+ ..$ $3x = 1 + a^3 + a^6 + a^9+..$ $5y = 1 + a^5 + a^{10} +a^{15} +..$ $7z = 1+a^7+a^{14}+a^{21}+..$ Again, I've only just followed the example in the textbook as I am unsure of what to do.  Could anyone explain what this means? (if it is correct?) Then, I've come up with the generating function by multiplying these values together: $$f(x)=(1+a^2+a^4+..)(1+a^3+a^6+..)(1+a^5+a^10+..)(1+a^7+a^14+..) $$ Now as far as I know, this is a valid generating function.  However, my textbook takes one more step, and I've followed suit: $$f(x)=\frac{1}{1-x^2}*\frac{1}{1-x^3}*\frac{1}{1-x^5}*\frac{1}{1-x^7}$$ I don't understand the step that is taken here, but this is what I have come up with for my final answer to a) . Now for b) , I've taken the equations that I lined out and simply eliminated the earlier terms according to the restrictions on $w,x,y,z$ $2w = 1+a^2+a^4+a^6+ ..$ $3x = a^9+a^{12}+..$ $5y = a^{15} + a^{20}+..$ $7z = a^{28}+a^{35}+..$ If anyone can offer any insight here I would greatly appreciate it.  I'm having quite a bit of trouble with my combinatorics class.. Cheers everyone","['generating-functions', 'combinatorics']"
213963,A Problem in Shafarevich's book,"I have encountered a problem in Shafarevich's book and I have no clue: Let $X$ be a hypersurface given by the equation $f_{m-1}(x_1,\cdots, x_n) + f_m(x_1,\cdots, x_n) = 0$  where $f_{m-1}$ and $f_m$ are non-zero homogeneous polynomials of degrees $m-1$ and $m$, respectively. Prove that if $X$ is irreducible, it is rational. (Shafarevich, Problem I.3.5.)",['algebraic-geometry']
213974,norm of power of matrix ---recursive formula,"I have a question concerning matrix analysis. let $A$ be the following $n \times n$-matrix with non-negative integer entries. $$\begin{pmatrix}0&k_2&k_3&\dots&k_n\\
k_1&0&k_3&\dots&k_n\\
k_1&k_2&0&\dots&k_n\\
\vdots&\vdots&\vdots&\vdots&\vdots\\
k_1&k_2&k_3&\dots&0\end{pmatrix}$$ i.e. the $j$-th row of $A$ is $(k_1,k_2,\dots k_n)-(0,0,...,k_j,0,0)$ How to express the norm of $A^n$ in terms of $k_1, k_2,\dots, k_n$ and the entries of $A^{(n-1)}$???","['matrices', 'linear-algebra']"
213978,Shift operator on locally compact groups,"Assume $f:G\rightarrow H$ is a measurable function between two locally compact abelian groups and let $T^h(f) = f\circ T^h$, where $T^h(x) = x-h$ (group operations in G and H are written additively). If $x\mapsto f(x-h)-f(x)$ is continuous for a.e. h, then I expect that $f$ is a.e. equal to a continuous function. Is that true? Thanks","['measure-theory', 'abelian-groups']"
214010,Prove $\lim _{x \to 0} \sin(\frac{1}{x}) \ne 0$,Prove $$\lim _{x \to 0} \sin\left(\frac{1}{x}\right) \ne 0.$$ I am unsure of how to prove this problem. I will ask questions if I have doubt on the proof. Thank you!,"['proof-writing', 'real-analysis', 'limits']"
214038,Closed bounded subset of $\mathbb{R}$.,"Let $X$ be a closed and bounded subset of $\mathbb{R}$. Is it true that $X$ is a finite union of closed intervals in $\mathbb{R}$? (*) I think that if we choose $X$ is a Cantor set, then $X$ doesn't satisfy (*). How can I prove this?","['general-topology', 'analysis']"
214045,What are the epimorphisms in the category of Hausdorff spaces?,"It appears to be the case that the epimorphisms in $\text{Haus}$ are precisely the maps with dense image. This is claimed in various places, but a comment on my blog has made me doubt the source I got my proof from (Borceux). Borceux's argument crucially uses the following result: If $A \subset X$ is a closed subspace of a Hausdorff space $X$, then the quotient $X/A$ is Hausdorff. This appears to be false. As far as I can tell, if $X/A$ is Hausdorff, then $A$ and points in $X$ not in $A$ must be separated by open neighborhoods in $X$. But if this is true for every closed subspace $A$ of $X$, then $X$ is necessarily regular, and there are examples of Hausdorff spaces that aren't regular. So: is it still true that the epimorphisms are precisely the maps with dense image? If so, what is a correct proof of this?","['general-topology', 'category-theory']"
214054,Relationship between rate of convergence and order of convergence,"What is the difference between rate of convergence and order of convergence? Have they any relationship to each other? For example could i have two sequences with the same rates of convergence but different orders of convergence, and vice versa?","['numerical-methods', 'sequences-and-series', 'analysis']"
214057,Proving a property of an ellipse and a tangent line of the ellipse,"Suppose that there is line $l$ that is tangent to an ellipse $A$ at point $\,P\,$. The ellipse has the foci $F'$ and $F$. One then creates two lines - each from each focus to the tangency point $\,P\,$ . What I want to prove is that the acute degree formed at $P$ between $l$ and the line segment $F'P$ equals the acute degree formed between $l$ and the line segment $FP$ . How would I be able to prove this? (ellipse has a horizontal axis as a major axis.) Edit: line $l$ and the corresponding $\,P\,$ can be set arbitrarily (they just need to meet the aforementioned condition), so what I want to prove is for all possible cases.","['geometry', 'conic-sections']"
214065,Proving q-binomial identities,"I was wondering if anyone could show me how to prove q-binomial identities? I do not have a single example in my notes, and I can't seem to find any online. For example, consider:
${a + 1 + b \brack b}_q = \sum\limits_{j=0}^{b} q^{(a+1)(b-j)}{a+j \brack j}_q$ I haven't made much progress on this one, but here's one that I have managed to get something out of:
${2n \brack n}_q = \sum\limits_{k=0}^{n} q^{k^{2}}{n \brack k}_q$ Using the q-binomial theorem from my notes, which is as follows:
$(1+qx)(1+q^{2}x)...(1+q^{n}x) = \sum\limits_{k=0}^{n} q^{k(k+1)/2}{n \brack k}_q x^{k}$, I have managed to show that the coefficient of $x^{n}$ is equal to: $\sum\limits_{k=0}^{n} q^{(2k^{2} - 2nk + n^{2} + n)/2} {n \brack k}_q {n \brack n-k}_q$, which is when I was working on the right hand side of the identity. In order to get here, I considered the product of $(1+qx)...(1+q^{n}x)(1+qx)...(1+q^{n}x)$, then tried obtaining the coefficient of $x^n$, as one would in the ordinary binomial proof. I've been trying to mimic the proofs of the regular binomial counterparts of these identities but without much luck. Help would be appreciated, as I have a midterm exam coming up soon.
Thanks :)","['q-series', 'binomial-coefficients', 'q-analogs', 'combinatorics']"
214067,Triangle inequality for subtraction? [duplicate],This question already has answers here : Prove that $||x|-|y||\le |x-y|$ (7 answers) Closed 3 years ago . Why is $|a - b| \geq|a| - |b|$ ?,"['triangles', 'inequality', 'real-analysis']"
214071,Is the identity map a diffeomorphism?,"Unfortunately, googling this question leads to conflicting answers. According to this source , the identity map on any smooth manifold is a diffeomorphism,
 but it's not according to this .   I appreciate it if someone gave a definitive answer.",['differential-geometry']
214076,Find the limit without l'Hôpital's rule,"Find the limit
$$\lim_{x\to 1}\frac{(x^2-1)\sin(3x-3)}{\cos(x^3-1)\tan^2(x^2-x)}.$$
I'm a little rusty with limits, can somebody please give me some pointers on how to solve this one? Also, l'Hôpital's rule isn't allowed in case you were thinking of using it. Thanks in advance.","['trigonometry', 'limits']"
214078,find a point on ellipse closest to origin,"Find the points on the ellipse $2x^2 + 4xy + 5y^2 = 30$ closest and farthest from origin. How to do this problem? I know how to find a closest point if $z = f(x,y)$ is given, however, this is 2 dimensional.",['multivariable-calculus']
214080,Closure of $l_1$ in $l_\infty$,Suppose we have a set $A$ which is the set of all sequences that satisfy $|x_n|\xrightarrow{} 0$. If we consider $l_1$ to be a subset of $l_\infty$. Show that the closure of $l_1$ in $l_\infty$ equals $A$. I started by showing $l_1$ is closed since it is complete (even stronger condition is that it is compact in $l_\infty$ since it is closed in $l_\infty$). Then I can see why $l_1  \subseteq$ $l_\infty$ since this is a condition on converging (absolutely) series. This doesn't seem to make sense in the other direction... I think I'm seeing this wrong.,"['sequences-and-series', 'functional-analysis', 'lp-spaces', 'metric-spaces']"
214092,Generously Feasible?,"In my machine learning class I have been provided a weight vector that has the property that it is generously feasible ? Formally, what does generously feasible mean?  I can't seem to find a definition?","['statistics', 'terminology']"
214102,Basics of Haar measure,"Suppose $G$ is a locally compact group.  Then $G$ has a left-invariant
measure $dg$ , say, which means that $$\int f (hg) dg = \int f(g) fg$$ for any test function integrable on $G$ .  The left-invariant measure is
unique up to a positive constant multiple; therefore, $$\int f (hg) dg = \delta(h) \int f(g) fg,$$ where $\delta(h) > 0$ depends only on $h$ because $dgh^{-1}$ is another left-invariant
measure. The factor $\delta(h)$ is called the modular function of $G$ .  Clearly $\delta : G \to \mathbb{R}^+$ is a group homomorphism, and one also shows.... I feel totally confused about the sentence ""therefore, ... because $dgh^{-1}$ is another left-invariant measure."" What is the reason for ""therefore""? Why is $dgh$ a left -invariant measure? (It seems right multiplication...) Also confused about why $dgh^{-1}$ is a left -invariant measure and why because of this fact, $\delta(h)>0$ depends only on $h$ . Hope someone could explain it in details. Thanks a lot!","['topological-groups', 'measure-theory', 'harmonic-analysis']"
214125,"Start with a topological group, take the meet of the two uniformities, and take the topology. Is the result again a topological group?","And what else can be said, if so? In more detail: Say $(G,\mathscr{T})$ is a topological group. It has a left uniformity $\mathscr{L}$ and a right uniformity $\mathscr{R}$.  (It also has a two-sided uniformity $\mathscr{U}$, which is the join of the two.) Now, uniformities on a given set form a complete lattice, so we can also consider the meet of the two, $\mathscr{V}$.  However, the meet of two uniformities that yield the same topology does not necessarily again yield the same topology, so it's possible that $\mathscr{T}'$, the topology coming from $\mathscr{V}$, is coarser than our original topology $\mathscr{T}$. (Obviously, this does not happen if the group is balanced, i.e. $\mathscr{L}=\mathscr{R}$; it also does not happen if $\mathscr{T}$ is locally compact, since the meet of two uniformities yielding the same locally compact topology does again yield the same topology. I think it also can't happen if $G$ embeds in a locally compact group, but I didn't work out all the details there .  Actually, I don't know an actual case where this does happen, so I guess a first question I can ask is, are there any actual examples of this?) So my question is, is $(G,\mathscr{T}')$ again a topological group?  Obviously inversion is continuous, since $\mathscr{V}$ makes inversion uniformly continuous, but it's not clear what would happen with multiplication. If it is a topological group, then we can ask things like, how does $\mathscr{V}$ compare to $\mathscr{L}'$, $\mathscr{R}'$, $\mathscr{U}'$, and $\mathscr{V'}$?  (Well, obviously it's coarser than the last of these.)  And considering $\mathscr{T} \mapsto \mathscr{T}'$ as an operation on group topologies on $G$, what happens when we iterate it?  When we iterate it transfinitely?","['general-topology', 'topological-groups', 'group-theory', 'uniform-spaces']"
214126,Inequality concerning inverses of positive definite matrices,"I don't find a way to prove this: given $A$, $B$, symmetric and positive definite: $$A>B \Rightarrow A^{-1} < B^{-1},$$
where $A>B$ means that $A-B$ is positive definite.","['matrices', 'inequality']"
214141,Improper Integral using Residue Theory.,"I want to evaluate the improper integral $\int\limits_{0}^{\infty}\frac{x^{1/4}}{1+x^3}\, dx$ via residue theorem but something odd is happening. When I use the key-hole contour where I integrate above/below the postive real axis, I end up getting that the real and imaginary part of the integral is $-\int\limits_{0}^{\infty}\frac{t^{1/4}}{1+t^3}dt + \int\limits_{0}^{\infty}\frac{t^{1/4}}{1+t^3}dt*i $ When I compute the contour via residues I get answers that not only do not match up to numerical calculation but I but have different real and imaginary scaler values. The 3 roots of $1+z^3$ are $-1, 1/2+\frac{\sqrt{3}}{2i}, 1/2-\frac{\sqrt{3}}{2}*i $ And residue values computed at each are: for $-1$, $\frac{\sqrt{2}}{6}(1+i)$ for $1/2 + \sqrt(3)/2i$, $\frac{-(\sqrt{3}-1)\sqrt{2}}{12} - \frac{(\sqrt{3}+1)\sqrt{2}}{12}i$ for $1/2 - \sqrt(3)/2i$, $\frac{-(\sqrt{3}-1)\sqrt{2}}{12} + \frac{(\sqrt{3}+1)\sqrt{2}}{12}i$ Now clearly the sum of these multiplied by $2\pi*i$ will not have real and imaginary parts which are scaler multiples of each other. What did I do wrong?",['complex-analysis']
214170,1 sample space with 2 probability example?,"I am a freshman here with the following question, sorry for my gramar I don't know the exact matematical probability terms in english. So, if I have a sample space, can I define in this space 2 probability? I know that, the probability function fit 3 condition. $P(a) \ge 0$ $P(\Omega) = 1$ $P\left(\bigcup_{j\in J}A_j\right) =\sum_{j\in J}P(A_j)$ The following probabilities function fit the conditions: probability as geometrie, probability as counting, probability as algebra. 
Example: probability as counting P(event) = of successful outcomes / of total outcomes So can I define a 2 function on the same sample space? If not why, how to prove it? If anyone can give me examples, I would be very grateful. I want to understand this with 100% percent. Thank you very much.","['statistics', 'probability', 'functions']"
214177,How many ways to merge N companies into one big company: Bell or Catalan?,"There's a famous interview question variously credited to Microsoft, Google and Yahoo: Suppose you have given N companies, and we want to eventually merge
  them into one big company. How many ways are there to merge them? Assuming you can merge as many companies as you like in a single step, I thought this boils down to ""find the number of partitions of a set with N elements"", in which case the answer is the Bell number $B_{n}$.  This can be computed with this handy recursion cribbed shamelessly from Wikipedia: $B_{n+1}=\sum_{k=0}^{n}{{n \choose k}B_k}$ $1, 1, 2, 5, 15, 52, 203...$ And you have to substract one since you're already starting from one of the possible sets:  $B_{2}=2$, but there's only one way to combine A and B into AB. However, there are a lot of sources on the net which claim that the correct solution is the Catalan number : $C_n = \frac{1}{n+1}{2n\choose n} = \frac{(2n)!}{(n+1)!\,n!} = \prod\limits_{k=2}^{n}\frac{n+k}{k} \qquad\mbox{ for }n\ge 0$ $1, 1, 2, 5, 14, 42, 132...$ Which is correct, and why?  Or are they both correct depending on the assumptions you make about the somewhat vague problem statement?","['elementary-set-theory', 'set-partition', 'combinatorics']"
214187,Point on the left or right side of a plane in 3D space,"I have an alpha plane determined by 3 points in space. How can I check if another point in space is on the left side of the plane or on the right side of it? For example if the plane is determined by points $A(0,0,0)$, $B(0,1,0)$ and $C(0,0,1)$ then point $X(-1, 0, 0)$ is on the left side of the plane and point $Y(1,0,0)$ is on the right side of the plane. I need a fast solution for plug-in development for a 3D application and I'm not very good at math.","['vector-spaces', 'geometry', '3d']"
214212,Intuition behind Jacobian of the SVD,"I'm having a little trouble understanding the meaning behind the Jacobian of an SVD. I understand what the Jacobian is, but I don't see how you can derive a Jacobian from the SVD. To me, the SVD is just USV_transpose - I don't see how a matrix can be differentiated, since they don't really seem to be functions of anything. http://www.ics.forth.gr/_publications/2000_eccv_SVD_jacobian.pdf I've been looking at the above pdf just to get a better understanding, but equation (7) (the differentiation of the singular values) is really where I get lost.",['linear-algebra']
214218,"Uniform convergence of derivatives, Tao 14.2.7.","This is ex. 14.2.7. from Terence Tao's Analysis II book. Let $I:=[a,b]$ be an interval and $f_n:I \rightarrow \mathbb R$ differentiable functions with $f_n'$ converges uniform to a function $g:I \rightarrow \mathbb R$. Suppose $\exists x_0 \in I: \lim \limits_{n \rightarrow \infty} f_n(x_0) = L \in \mathbb R$. Then the $f_n$ converge uniformly to a differentiable function $f:I \rightarrow \mathbb R$ with $f' = g$. We are not given that the $f_n'$ are continuous but he gives the hint that
$$
d_{\infty}(f_n',f_m') \leq \epsilon \Rightarrow |(f_n(x)-f_m(x))-(f_n(x_0)-f_m(x_0))| \leq \epsilon |x-x_0|
$$ This can be shown by the mean value theorem. My question is : How does this help me to prove the theorem ?","['convergence-divergence', 'real-analysis', 'uniform-convergence']"
214227,Coordinate transformation to get even function,"Suppose I have the function $$f(y)=2y^4-5y^3+3y^2,$$ with zeroes $y=0$ (2x), $y=1$, $y=3/2$, which I only need on the part of the domain $0\le y\le 1$. Is there a transformation $y\rightarrow y'$, such that $f(y')$ is even The transformation is invertible on the specified domain The transformation of the derivative $\frac{d^2f}{dy^2}$ still looks 'nice' $0$ and $1$ get mapped to $y'_0$ and $-y'_0$ or vice versa. I am aware that my third requirement is a bit vague, but I don't know a better formulation for now. I tried some transformations that first maps $3/2$ and $1$ to the same value, but it will not be invertible for sure.","['transformation', 'algebra-precalculus', 'functions']"
214251,Representation of $S^{3}$ as the union of two solid tori,"Well, I'm trying to prove that you can express the 3-dimensional sphere $S^{3}$ as the union of two solid tori. I tried first use that a solid tori is homeomorphic to $S^{1}$$\times$$D^{2}$ and use this to obtain some quotient space which would be homeomorphic to $S^{3}$, but I couldn't go any further. Is this the way or I need a little more to prove that? Thanks in advance.","['general-topology', 'low-dimensional-topology', 'algebraic-topology']"
214278,Help with proof of closedness of a set,"Let $u_n$ be a sequence in Hilbert space such that $\|u_n\|=1$ for all $n$, and $\langle u_n|u_m\rangle=0$ whenever $n\neq m$.
Why is the following set closed: $\{0\}\cup \{u_n \mid n\geq 1\}$?
Thanks for the help!","['general-topology', 'hilbert-spaces']"
214284,A differential equation of Buckling Rod.,"I tried to solve a differential equation, but unfortunately got stuck at some point. The problem is to solve the differentail equation of hard clamped on both ends rod. 
And the force compresses the rod at both ends. 
the solution $v(x)$ is the value of bending I need. I assuming, that the differential equation of buckling rod is 
$$ EI_{x}v''''+Pv''=0$$
where $P$ is a force.
and $EI_x$ is inflexibility. Then I find the solution for the diffierential equation:
$$v(x) = \frac{c_1\cos(x\sqrt{P})+c_2\sin(x\sqrt{P})}{P}+c_4 x+c_3$$
The boundary conditions: $$v(0)=v(l)=0=v'(0)=v'(l)$$ gives the trivial solution for $c_{1},c_{2},c_{3},c_{4}$ but I need non-trivial ones. Could you please help me to find the mistake or explain what's wrong in my equation?","['mathematical-physics', 'classical-mechanics', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
214303,Known algebraic geometry's results in Characteristic $p$,"What are the most well known results in classical (à la Weil) algebraic geometry in characteristic $p$, which are thought to be true (but not yet proved) in characteristic 0? Thanks","['algebraic-geometry', 'big-list']"
214315,Norm of integral operator in $L^1$,"What is the norm of the operator 
$$
T\colon L^1[0,1] \to L^1[0,1]: f\mapsto \left(t\mapsto \int_0^t f(s)ds\right)
$$
?","['operator-theory', 'normed-spaces', 'functional-analysis']"
214317,Prove that $(X\times Y)\setminus (A\times B)$ is connected,"I'm reading topology of Munkres and I have a problem that stuck me for a while. I'm so greatful if anyone can help me with this. Let $A$ be a proper subset of $X$, and let $B$ is a proper subset of $Y$. If $X$ and $Y$ are connected, show that $$(X\times Y) \setminus (A\times B)$$ is connected. Thanks so much for your consideration ^^","['general-topology', 'connectedness']"
214319,When is $\left\lfloor \frac {7^n}{2^n} \right\rfloor \bmod {2^n} \ne 0\;$?,"Is $$\left\lfloor \frac {7^n}{2^n} \right\rfloor \bmod{2^n} \ne 0\;$$ always true when $n \ge 3$. Baker's theorem on transcendental numbers that provide bounds for diophantine equations may be useful, but I will leave that to the experts.","['diophantine-equations', 'open-problem', 'number-theory']"
214322,Haar Measure: Unimodular Locally Compact Groups,"I have the following problem: ""Let $G$ be a locally compact group, all of whose normal subgroups are contained in $Z(G)$. Prove that $G$ is unimodular."" My attempt at attacking the problem was to consider the homomorphism $\Delta:G \rightarrow \mathbb{R}^{\times}_+$ defined by
\begin{equation*}
\int_G f(yx)d_rx = \Delta(y)\int_Gf(x)d_rx
\end{equation*}
where $d_rx$ is a right Haar measure on $G$. Then $G$ will be unimodular if and only if $\Delta = 1$. However, I am having some difficulty showing that this holds. Any advice is appreciated.","['measure-theory', 'functional-analysis']"
214326,Identity for convolution of central binomial coefficients: $\sum\limits_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}=2^{2n}$,"It's not difficult to show that $$(1-z^2)^{-1/2}=\sum_{n=0}^\infty \binom{2n}{n}2^{-2n}z^{2n}$$ On the other hand, we have $(1-z^2)^{-1}=\sum z^{2n}$.  Squaring the first power series and comparing terms gives us $$\sum_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}2^{-2n}=1$$ that is, $$\sum_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}=2^{2n}$$ My question: is there a more direct, combinatorial proof of this identity?  I've been racking my brains trying to come up with one but I'm not having much success.","['convolution', 'combinatorial-proofs', 'summation', 'binomial-coefficients', 'combinatorics']"
214327,"strange metric $d(x,y) = ||x|| + ||y||$ if $x\ne y$, $d(x,y) = 0$ if $x = y$.","Let $d : \mathbb{R}^n \times \mathbb{R}^n \to [0, \infty]$ be defined by
$$
 d(x,y) = \left\{ \begin{array}{ll} 0 & : ~ x = y \\ ||x|| + ||y|| & : ~ x \ne y \end{array} \right.
$$
where $||\cdot ||$ denotes the usual norm of $\mathbb{R}^n$. Show that $d$ is a metric. Draw the $\varepsilon$-Spheres $B_{\varepsilon}(x_0) := \{ x \in \mathbb{R}^2 ~|~ d(x,x_0) < \varepsilon \}$ for $x_0 = (0,0)$ and $x_0 = (1,1)$ and $\varepsilon = \frac{1}{2}, 1, \frac{3}{2}$. Characterize the open, closed and compact sets with respect to this metric. Is $(\mathbb{R}^n, d)$ complete? Number 1) is simple, for 2) I got: If $x_0 = (0,0)$ then
$$
d(x,x_0)= \left\{ \begin{array}{ll} 
0 & \textrm{ for } x = (0,0) \\
\sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right. 
$$
and if $x_0 = (1,1)$ then
$$
  d(x,x_0) =  \left\{ \begin{array}{ll} 
0 & \textrm{ for } x = (1,1) \\
\sqrt{2} + \sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right. 
$$
and the pictures are simple spheres with the point $x_0$ in the sphere ($x_0 = (0,0)$) or isolated outside ($x_0 = (1,1)$). But with 3) I have my problems, i conjecture that 
$$
 B_{\varepsilon}(x) \quad \textrm{ is open iff } \quad ||x|| - \varepsilon > 0
$$
and going on I know that finite intersections of open sets are open, but then had I got all open sets by this construction? And what about the other properties, how can I characterize them, do you have any hints?","['functional-analysis', 'analysis']"
214336,Infinite Sets and Injective Maps,"Let $A$ be infinite, meaning that there is no injection from $A$ to $\{1,...,n\}$ for all $n\in \mathbb{N}$ and assume there exists $f:A\rightarrow \mathbb{N}$ which is injective. I am trying to show there must be an bijection from $A$ to $\mathbb{N}$. My train of thought so far has been: Assume there is no bijection from $A$ to $\mathbb{N}$. Then $f$ is not surjective. Let $i \in \mathbb{N}$ be the smallest element of $\mathbb{N}$ which is not mapped to $\mathbb{N}$ by $f$. This gives rise to an injective map $f_i:A \rightarrow \mathbb{N}\setminus \{i\}$. If $f_i$ were surjective this means for all $j \in \mathbb{N}\setminus \{i\}$ there exists some $a_j$ in $A$ such that $f_i(a_j)=j$. Define $g:\mathbb{N}\setminus \{i\} \rightarrow \mathbb{N}$ by $g(n)=n$ for $i<n$ and $g(n)=n-1$ for $n>i$. $g$ is a bijection, and so $g\circ f_i: A \rightarrow \mathbb{N}$ is a bijection, contradiction our assumption no such function exists. Thus $f_i$ cannot be surjective. Repeating this process shows that there is no bijective map $$f_P:A \rightarrow \mathbb{N}\setminus \{P\},$$ where $P$ is a finite set of elements of $\mathbb{N}$. I really don't know if this is going anywhere though. Is this train of thought correct, and (if so) is there a way to extend it to a proof? If not, how would one show this? Note : this is not homework,at least not my homework. I found it in some lecture notes I was reading.",['elementary-set-theory']
214353,trouble with this integral,"Could anyone help me to do this integral ? $$\int_{\,0}^\infty \; \frac{\exp \left( -\frac{1}{x} -x\right)}{\sqrt{x}}  \, dx = \sqrt{\pi}e^{-2} $$ I think you start with completing the square in the exponent, but what substitution do you make then ? $u=\sqrt{x}$ didn't seem to get me far.",['integration']
214369,homotopy type of the closure of a subset,Let $X$ be a topological space and $N$ a subset of $X$. Is it true that the closure of $N$ in $X$ is homotopy equivalent to $N$. I think it is not. take for example $N=\mathbb  Q\subset \mathbb R=X$. Then $\bar Q=\mathbb R$ is contractible while $\mathbb Q$ is not even connected. This question came to my mind when i read that a submanifold with boundary keeps its homotopy type after removing its boundary. Are there conditions where the closure of a subset has the homotopy type of the subset? Thank you in advance.,"['general-topology', 'homotopy-theory', 'algebraic-topology']"
214392,Proof of $\sigma(A^n)\supset\sigma\bigg(\sigma (A)^n\bigg)$?,"Let ${\mathcal B}_n$ be the Borel $\sigma$-algebra on ${\mathbb R}^n$. Then it's not hard to show that 
$$
{\mathcal B}_n=\sigma(A^n)
$$
where
$$
A=\{(-\infty,a]: a\in{\mathbb Q}\}.
$$
Let ${\mathcal B}={\mathcal B}_1$. I want to show that ${\mathcal B}_n=\sigma({\mathcal B}^n)$. In other words 
$$
\sigma(A^n)=\sigma\bigg(\sigma (A)^n\bigg).
$$
It's not hard to see that 
$$
\sigma(A^n)\subset\sigma\bigg(\sigma (A)^n\bigg)
$$
since L.H. is the smallest $\sigma$-algebra containing $A^n$ while R.H. is a $\sigma$-algebra containing $A^n$. How can I go on to show
$$
\sigma(A^n)\supset\sigma\bigg(\sigma (A)^n\bigg)?
$$","['probability-theory', 'measure-theory']"
214399,"Summing (0,1) uniform random variables up to 1 [duplicate]","This question already has answers here : Closed 11 years ago . Possible Duplicate: choose a random number between 0 and 1 and record its value. and keep doing it until the sum of the numbers exceeds 1. how many tries? So I'm reading a book about simulation, and in one of the chapters about random numbers generation I found the following exercise: For uniform $(0,1)$ random independent variables $U_1, U_2, \dots$ define $$
N = \min \bigg \{ n : \sum_{i=1}^n U_i > 1 \bigg \} 
$$ Give an estimate for the value of $E[N]$. That is: $N$ is equal to the number of random numbers uniformly distributed in $(0,1)$ that must be summed to exceed $1$. What's the expected value of $N$? I wrote some code and I saw that the expected value of $N$  goes to $e = 2.71\dots$ The book does not ask for a formal proof of this fact, but now I'm curious! So I would like to ask for A (possibily) simple (= undergraduate level) analytic proof of this fact An intuitive explanation for this fact or both.","['random-variables', 'probability', 'random']"
214401,A non-negative matrix has a non-negative inverse. What other properties does it have?,"This is homework for my mathematical optimization class. Here is the exact question: Element-wise nonnegative matrix and inverse. Suppose a matrix $A \in\Bbb R^{n\times n}$
  , and its inverse $B$, have all their elements nonnegative, i.e., $A_{ij}\geq 0$, $B_{ij}\geq 0$, for $i,j = 1,\dots,n$. What can you say must be true of
  $A$ and $B$? Please give your answer first, and then the justification.
  Your solution (which includes what you can say about $A$ and $B$, as well
  as your justification) must be short. I have no idea what they are looking for; so far, I've got just the basic facts stemming from the fact that an inverse exists (it's square, the determinant is non-zero etc.). What can I deduce from the ""non-negative"" property?","['matrices', 'linear-algebra']"
214408,The real numbers and the axiom of foundation,I am having a bit of confusion about the real numbers and ZF set theory (I asked a question about it a few days ago). I am a bit unsure as to why the real numbers can be in any model of ZF as they seem to contradict the axiom of foundation (regularity) i.e. that for every set $X$ and $Y\subseteq X$ $\exists a\in Y:\forall b\in Y ((b\neq a)\ b<a)$ Thanks very much for any help,"['logic', 'axioms', 'elementary-set-theory']"
214418,Let $G$ be any abelian group and $a\in{G}$. Show there exists a homomorphism $f:G\rightarrow{\mathbb{Q}/\mathbb{Z}}$ such that $f(a)\neq{0}$.,"Let $G$ be any abelian group and $a\in{G}$. Show there exists a homomorphism $f:G\rightarrow{\mathbb{Q}/\mathbb{Z}}$ such that $f(a)\neq{0}$. I can prove this question (I think) if I use the fact that $\mathbb{Q}/\mathbb{Z}$ is an injective abelian group: just define $f$ on the cyclic subgroup generated by $a$ and extend to $G$ via injectivity. However, I feel there should be a more 'elementary' way to prove this result, I just can't see one yet. One of my friends suggested using Zorn's Lemma, but I haven't done much with this information yet.","['homological-algebra', 'abstract-algebra']"
214434,Example for an open set in $\mathbb R$,What would be your example of an open proper subset $S \subsetneq \mathbb R$ such that $\mathbb{Q} \subsetneq S$?,"['general-topology', 'real-analysis']"
214441,Orthonormal basis for Sobolev Spaces,Sobolev spaces of order 2 are known to form a Hilbert space. Consider such a Sobolev space of (order 2) functions on the domain $f:\mathbb{R}\rightarrow \mathbb{R}$. What is an example for the basis of such a Sobolev space.,"['functional-analysis', 'sobolev-spaces', 'real-analysis', 'hilbert-spaces', 'orthonormal']"
214452,Trigonometry Inequality,"This is the first time I'm posting here. If you can also tell me how to format this like a pro, I'll be very grateful. 1st question: Prove the following inequality:
$$0^{\circ} < a, b, c < 180^{\circ}$$ $$\sin a \times \sin b \times \sin c \le \sin\left(\frac{a+b}{2}\right) \times \sin\left(\frac{a+c}{2}\right) \times \sin\left(\frac{a+b}{2}\right)$$ 2nd question: Prove the following inequality:
$$a + b + c = 90^{\circ}$$ $$\sin a \times \sin b \times \sin c  \le \frac{1}{8}$$",['trigonometry']
214453,Need help understanding proof about critical values of the determinant map.,"In , problem 5 the author shows that the differential of the determinant map $d(\det)_A$ for an invertible matrix $A$ is nonsingular by only showing that $d(\det)_A(A) \ne 0$.  I don't really see why this shows that $d(\det)_A$ is nonsingular. I would like some further clarification on this point.","['differential-topology', 'multivariable-calculus']"
214454,"""Algorithmic"" proofs in linear algebra","Although I am new to linear algebra, I want to study it with as much rigor as possible. After searching around, I picked up Halmos' Finite Dimensional Vector Spaces and Axler's Linear Algebra Done Right . I've noticed that they state theorems which they prove by a method which I would describe as ""algorithmic"". For example, verbatim from Axler (although Halmos is very similar): Theorem: In a finite-dimensional vector space, the length of every lin. ind. tuple is $\leq$ to the length of every spanning tuple
  of vectors. Proof : Suppose that ($u_1$, ... $u_m$) is lin. ind. in $\mathcal{V}$ and ($w_1$, ... $w_n$) spans $\mathcal{V}$. We need to prove $m \leq n$. We do so through
  the multi-step process described below.... Step 1 : The tuple $(w_1, ... w_n)$ spans $\mathcal{V}$, and thus adjoining any vector produces a linearly dependent tuple. In particular, the tuple $(u_1, w_1, ... w_n)$ is linearly independent. Thus, by the linear dependence lemma, we can remove one of the $w$'s so that the n -tuple B consisting of $u_1$ and the remaining $w$'s spans $\mathcal{V}$. Step j : The n -tuple B from step $j-1$ spans $\mathcal{V}$, and thus adjoining any vector to it produces a linearly dependent tuple. In particular, the $(n+1)$-tuple obtained by adjoining $u_j$ to B , placing it just after $u_1,...u_{j-1},$ is linearly dependent. By the linear dependence lemma (2.4), one of the vectors in this tuple is in the span of the previous ones.... We can remove that $w$ from $B$ so that the new $n$-tuple $B$ consisting of $u_1, ... u_j$ and the remaining $w$'s spans $\mathcal{V}$. After step $m$, we have added all the $u$'s and the process stops. If at any step we added a $u$ and had no more $w$'s to remove, then we would have a contradiction. Thus there must be at least as many $w$'s as $u$'s. I take issue with the level of rigor of ""algorithmic"" proof. Although I think these proofs might be amenable to treatment by induction, I'm not sure how to carry it out. As they stand, although I get the intuition, they don't really convince me. If I had to be precise about what bothers me, I'd say that the actual sets resulting from each step of the operation aren't stated explicitly, and I'm not sure how these sets are being ordered/indexed (they play fast and loose there). (Disclosure: I am generally not thrilled with ...'s, unless I can see a clear way to come up with an argument which doesn't rely on imagining ""what's going on in there"", so dealing with about ten of these arguments at one sitting is irritating for me.) Is there a way to make these arguments - in particular, this one - more precise?","['vector-spaces', 'linear-algebra', 'proof-writing']"
214455,any idea what fractal algorithm might generate this shape?,"I Found this image around, and i'm curious what algorithm generates this kind of shape In particular, i'm curious how the flow lines are generated, since usually the Mandelbrot iteration just generates different regions depending on the steps required to get into divergence","['algorithms', 'fractals', 'complex-analysis', 'image-processing']"
214461,What is wrong with my proof (set theory),"$f:A\to B$ is given, $C_1$ and $C_2$ are subsets of $A$. Is it true that $f(C_1 \cap C_2) = f(C_1) \cap f(C_2)$? I can give an example to prove it wrong: if we take $C_1=[-1,0]\,,\, C_2=[0,1]$ , and if $f(x)=x^2$ , then, I know that $[0,1]≠\{0\}$ therefore the statement is wrong. However, I tried to prove it and: From left to right: $$x\in f(C_1 \cap C_2) \Rightarrow f^{-1}(x) \in C_1 \cap C_2 \Rightarrow  f^{-1}(x) \in C_1\;\; \text{and}\;\; f^{-1}(x) \in C_2 \Rightarrow $$ $$ x\in f(C_1) \;\;\text{and}\;\; x\in f(C_2) \Rightarrow  x\in f(C_1)\cap f(C_2)$$ Therefore it is true. Let's check from right to left: $$x∈f(C_1)\cap f(C_2) \Rightarrow  x∈f(C1)\;\;\text{ and}\;\; x∈f(C_2) \Rightarrow  f^{-1}(x)∈C_1\;\; \text{and}\;\; f^{-1}(x)∈C_2$$ $$ \Rightarrow  f^{-1}(x)∈C_1\cap C_2 \Rightarrow  x∈f(C_1\cap C_2)$$ This seems true also. However it should not be. What is wrong can you see?","['elementary-set-theory', 'functions']"
214507,Constructing a sequence to show that the set is countable,"I am studying for my exam and could not understand why my tutor constructed such sequences to show that the following sets are countable: for example: to show that N×N = {(n,m):n∈N, m∈N} is countable, he constructed the following sequence: (1,1), (1,2), (1,3), ...
(2,1), (2,2), (2,3), ...
(3,1), (3,2), (3,3), ...               
........................
........................ Construct a sequence diagonally: (1,1),(2,1),(1,2),(3,1),(2,2),(1,3),... Another example: If $A_k$, $k=1,2,\dots$, $k\in N$ are countable sets, then $A= \bigcup\limits_{k=1}^\infty A_k$ is also countable. Method he used: a11, a12, a13, a14, ...         => Contains all elements of A1
a21, a22, a23, a24, ...         => Contains all elements of A2
a31, a32, a33, a34, ...         => Contains all elements of A3
.......................         
....................... Again construct a sequence diagonally: a11, a21, a12, a31,a22,a13,... I know that a set A is countable if  there exists a surjection $f : N \to A$. However, is it really necessary to construct a sequence in such manner (diagonally) to show that those sets are countable? For the second question, if I construct a sequence like:  a11,a22,a13,...,a1n,a21,a22,...,a2n,.... would not it also show that my set is countable? Because it seems like still there exists a surjective function f from N to A. Am I wrong? Could you please give me some tips, method suggestions to how to figure out if a set (infinite or finite) is countable or not?","['sequences-and-series', 'elementary-set-theory']"
214520,"Are these sets in $\mathbb{R}$ open and/or closed: $\{\frac{1}{n} : n \in \mathbb{N}\}$, $\{0\}\cup \{\frac{1}{n} : n \in \mathbb{N}\}$ and $[0,1)$.","In $\mathbb{R}$, are these sets open? Are they closed? $A = \{\frac{1}{n} : n \in \mathbb{N}\}$ $B = A \cup \{0\} $ $[0, 1)$ My thoughts: $A$ is not open as if we have an open ball with $r > 0$  at any point $x$ in $A$ it will contain points that are not in $A$. $A$ is not closed as the complement of $A$ is not open. That is, any open ball at $0$ will contain points from both $A$ and the complement of $A$, namely, 0 is a boundary point. $B$ is not open as if we have an open ball with $r > 0$ at any point $x$ in $B$ it will contain points that are not in $B$. $B$ is closed as it's complement is a union of open intervals so the complement is open and hence $B$ is closed. $[0, 1)$ is not open as an open ball with $r > 0$ at 0 will contain points not in the set. It's complement is not open so it is not closed. How does that look, have I got these correct?","['general-topology', 'metric-spaces', 'proof-verification', 'analysis']"
214528,Solving a limit approaching zero with a complex denominator,"We've been given the definition of a derivative as: $$f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ We are asked to use this to find the derivative of the function $f(x)=\frac{1}{1-x}$
showing every step. I can get to here:
$$f'(x)=\lim_{h\to0}\frac{1}{h-hx-h^2}-\frac{1}{h-hx}$$ When I try using online equation solvers they just jump straight to the answer and I can't figure out how. Wolfram Alpha's step-by-step solution also doesn't give me any intermediate steps between this and the solution: $$\frac{1}{(x-1)^2}$$ So, my question is, how do I solve a limit like the one above where every value in the denominator approaches 0? (I'm guessing I'm just missing some algebraic tricks)","['calculus', 'limits']"
214545,Neat series convergence result,"This is a nice problem on series convergence that I recently stumbled upon. Given a non-negative sequence of real numbers $(a_n)$ such that $$\sum_{n=1}^\infty a_n < \infty,$$ show that there exists a non-decreasing sequence of non-negative numbers $b_n$ such that $$b_n \to \infty \quad\text{ and } \quad \sum_{n=1}^\infty a_n b_n < \infty.$$ In other words, for every convergent series with non-negative terms, there is another convergent series with ""substantially larger"" terms. I have a solution (see below), but maybe someone else has a different, simpler, and/or more elegant solution.","['sequences-and-series', 'calculus', 'real-analysis']"
214552,Relation betweeen Hoeffding inequality and Chernoff bound?,"If I am correct, both Hoeffding inequality and Chernoff bound are about bounds on the probability of sample mean deviates from the true mean. Besides that, I wonder how Hoeffding inequality and Cernoff bound are related? Is the conditioning Hoeffding inequality more restricted than Chernoff bound's? Is the bound in Hoeffding inequality tighter than Chernoff bound's? Is one the special case of the other? I.e. one can be derived from the other? Thanks!","['inequality', 'probability', 'random-variables']"
214556,"If $\{a_n\}$ is not summable, neither is $\left\{ {\frac{{{a_n}}}{{1 + {a_n}}}} \right\}$","Let $\{a_n\}$ be a sequence. We say $\{a_n\}$ is summable if the sequence $\{s_n\}$ defined by $$s_1=a_1\\s_{n+1}=s_n+a_{n+1}$$ converges to $\ell\in\Bbb R$, and write $$\sum\limits_{n = 1}^\infty  {{a_n}}  = \ell $$ $(1)$ Suppose  $\{a_n\}$ is of non-negative terms, and that it is not summable, that is $\lim {s_n}$ fails to exist. Show that $$\left\{ {\frac{{{a_n}}}{{1 + {a_n}}}} \right\}$$ is not summable either. Now, since $$0 \leqslant \frac{{{a_n}}}{{1 + {a_n}}} \leqslant {a_n}$$ for each $n$, $\{a_n\}$ being summable implies $\left\{ {\dfrac{{{a_n}}}{{1 + {a_n}}}} \right\}$ also is (monotone convergence). I need to show the converse of this, but I can see no way to prove it. Since $a_n\geq0$, the partial sums $${s_N} = \sum\limits_{n = 1}^N {{a_n}} $$can be made as large as we want.",['sequences-and-series']
214563,What is the relationship between variance and energy,"I was speaking with someone today who told me that variance, in the sense of probability theory, is equivalent mathematically to energy in physics. Can anyone elaborate on this relationship?","['probability-theory', 'physics', 'probability', 'soft-question']"
214572,"What hexahedra have faces with areas of exactly 1, 2, 3, 4, 5, and 6 units?","I tried for a while, not  very hard, to construct a polyhedron with exactly six faces, whose areas were respectively 1, 2, 3, 4, 5, and 6 units. I  did not meet with any success. Still, it seems that it should exist, because the space of possibilities is so large and so weakly constrained. Perhaps you could make one by chopping off two of the vertices of a tetrahedron. To be more specific, I do not care whether the hexahedron is regular or whether its faces are regular, or the same shape.  I would prefer that it be convex.","['geometry', 'recreational-mathematics', 'polyhedra', 'solid-geometry']"
214578,Any simplification of $\log_e{(1+e^x)}?$,Is there any simplification or other interesting transformation of: $$\log_e{(1+e^x)}$$ (where $x \in \mathbb{R}$) ?,['algebra-precalculus']
214612,Understanding the cartesian product of complex projective lines.,"I am trying to understand the space obtained by taking the cartesian product $\mathbb{C}\mathbb{P}^1\times \mathbb{C}\mathbb{P}^1$ and identifying some of its points by the rule $(x,y)\sim (y,x)$. Viewing $\mathbb{C}\mathbb{P}^1$ as a CW complex with one 0-cell and one 2-cell I computed the homology of $\mathbb{C}\mathbb{P}^1\times \mathbb{C}\mathbb{P}^1/\sim$ which matches that of $\mathbb{C}\mathbb{P}^2$ but I can't seem to visualize an ""obvious"" homeomorphism between the two spaces. My question is the following: is $\mathbb{C}\mathbb{P}^1\times \mathbb{C}\mathbb{P}^1/\sim$ homeomorphic to $\mathbb{C}\mathbb{P}^2$ and, if so, how?","['general-topology', 'homology-cohomology', 'algebraic-topology']"
214624,Trigonometric bounds,"Is there a nice way to show: $\sin(x) + \sin(y) + \sin(z) \geq 2$ for all $x,y,z$ such that $0 \leq x,y,z \leq \frac{\pi}{2}$ and $x + y + z = \pi$?","['trigonometry', 'triangles']"
214628,$|\frac{\sin(nx)}{n\sin(x)}|\le1\forall x\in\mathbb{R}-\{\pi k: k\in\mathbb{Z}\}$,Find all real number $n$ such that  $|\frac{\sin(nx)}{n\sin(x)}|\le1\forall x\in\mathbb{R}-\{\pi k: k\in\mathbb{Z}\}$.,"['trigonometry', 'inequality']"
214636,"If $f$ is a positive, monotone decreasing function, prove that $\int_0^1xf(x)^2dx \int_0^1f(x)dx\le \int_0^1f(x)^2dx \int_0^1xf(x)dx$","If $f$ is a positive, monotone decreasing function, prove that $\int_0^1xf(x)^2dx \int_0^1f(x)dx\le \int_0^1f(x)^2dx \int_0^1xf(x)dx$","['inequality', 'calculus', 'integration', 'real-analysis']"
214655,Separation in dual space,"Let $X$ be a real Banach space and $X^*$ its dual space.
Let $C^*$ be a weak$^*$ closed and convex subset in $X^*$ 
and $x^*\notin C^*$. Then there exists $x\in X$ such that
$$
\langle x^*, x\rangle > \sup_{f\in C^*}\langle f, x\rangle.
$$
I would like to ask whether the statement is true? How can we prove?",['functional-analysis']
214660,A set is open if its complement is closed.,"I was shown this statement to be a definition.  However, I think that the actual statement would be. A set is open iff its complement is closed. This way it's a biconditional and it's also true- this is my proof, with C being a continuum that is nonempty, has no first or last point and has an ordering (<): Suppose $U$ is open.  Let $x$ be a limit point of $C \setminus U$.  It should follow that if $C \setminus U$ is closed, then $x \in (C \setminus U)$.  Now we know that $\forall$ regions $R$ containing $x$, there is a nonempty intersection with $C \setminus U$.  Also, $x$ cannot be a point of the interior of $U$ because any intersection with a region containing it would be empty, which wouldn't be in accordance to our assumption that $x$ is a limit point of $C \setminus U$.  So $x$ is not in the interior of $U$ or $x \notin U$.  This would mean that $x \in (C \setminus U)$ and thus $C \setminus U$ is closed. I was wondering if this proof was reasonable, if there were any gaps in logic, and if this modification of the definition I presented was viable and justified.",['general-topology']
214661,Circle Least Squares Fit,"So my question is this: Find the equation of the circle that gives the best least squares circle fit to the points $(-1,-2), (0,2.4), (1.1,-4),$ and $(2.4,-1.6).$ So far I have this general equation: $2xc_1+2yc_2+(r^2-c_1^2-c_2^2)=x^2+y^2$ where $r^2-c_1^2-c_2^2 = c_3$ So then I think I create matrix: $\begin{pmatrix} 2x_1 & 2y_1 & 1 \\ . & . & . \\ 2x_n & 2y_n & 1 \end{pmatrix} \begin{pmatrix} c_1 \\ c_2 \\ c_3\end{pmatrix} - \begin{pmatrix} x_1^2+y_1^2 \\ ... \\ x_n^2+y_n^2\end{pmatrix}$ and after replacing $x_1 = -1$ and $y_1 = -2$ until $x_4$ and $y_4$, I have this matrix: $\begin{pmatrix} -2 & -4 & 1 \\ 0 & 4.8 & 1 \\ 2.2 & -8 & 1 \\ 4.8 & -3.2 & 1 \end{pmatrix} \begin{pmatrix} c_1 \\ c_2 \\ c_3\end{pmatrix} - \begin{pmatrix} 5 \\ 5.76 \\ 17.21 \\ 8.32\end{pmatrix}$ Which i guess I try to solve by setting equal to 0, then moving the last matrix to the other side and make it look like this: $\begin{pmatrix} -2 & -4 & 1 \\ 0 & 4.8 & 1 \\ 2.2 & -8 & 1 \\ 4.8 & -3.2 & 1 \end{pmatrix} \begin{pmatrix} c_1 \\ c_2 \\ c_3\end{pmatrix} = \begin{pmatrix} 5 \\ 5.76 \\ 17.21 \\ 8.32\end{pmatrix}$ And finally solve for $c_1$, $c_2$, $c_3$. But this system has no solution as shown here . Am I missing something huge here or what am I doing wrong?","['matrices', 'linear-algebra']"
214719,What is an example of a group G where $|G|=|\text{Stabilizer(G)}||\text{Orbital(G)}|$,"I am trying to construct an example of the stabilizer orbital theorem and trying to make sense as to why group actions are important. As I understand it, the stabilizer is also the centralizer. Could someone explain to me what the $|\text{Stabilzer}(\mathbb{Z_6})|$ and what the $|\text{Orbital}(\mathbb{Z_6})|$? I couldn't quite unravel the definitions to make them seem less abstract. I have an upcoming test and I just want to understand these materials to feel more confident.","['group-theory', 'abstract-algebra']"
214724,Kähler–Einstein metric on Calabi–Yau manifold,"I am reading ""Complex geometry"" by D. Huybrecht. On p.223 the books says that ""If $c_{1}(X)=0$, e.g. if the canonical bundle $K_{X}$ is trivial, and $g$ is Kähler–Einstein metric, then $\operatorname{Ric}(X,g)=0$. Indeed in this case the scalar factor $\lambda$ is necessarily trivial and hence $\operatorname{Ric}(X,g)=\lambda\omega=0$, i.e. the Kähler metric $g$ is Ricci-flat."" Remember that we say a metric $g$ is Kähler–Einstein if $\operatorname{Ric}(X,g)=\lambda \omega$ for some constant $\lambda\in \mathbb{R}$. Here $\omega$ is the Kähler form associated to $g$. My question is, why does Kähler–Einstein mean $\lambda=0$ in $c_{1}(X)=0$ case? If this is true, any Kähler–Einstein metric on Calabi–Yau manifold is Ricci-flat?","['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'algebraic-geometry', 'complex-analysis']"
214753,"What does ""spherical convex fuction"" mean","Let $M$ be a riemannian manifold. A function $f: M \mapsto \mathbb{R} $ is called spherical convex , if 
\begin{equation} \sin(\lvert xz \rvert) f(y) \leq \sin(\lvert xy\rvert) f(z) + \sin( \lvert yz\rvert ) f(x) \end{equation}
For every 2 points $x,z$ and every third point $y$ lying on a shortest path between $x$ and $z$. For a regular convex function one can say: A function $f$ is convex iff its graph is below the straight line connecting 2 points on the graph of $f$. Is there a similar way to describe spherical convex functions?","['geometry', 'differential-geometry', 'metric-geometry']"
214779,Fulton and Harris A.23,"I am reading the appendix of Fulton and Harris pg. 459 and am trying to understand the following setup. Suppose $\lambda : \lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_k \geq 0$ is a partition of a positive integer $d$ into at most $k$ parts. Suppose $P$ is a symmetric polynomial of degree $d$ in $k$ variables. Write $$\omega_\lambda(P) = [\Delta \cdot P]_l$$ where $\Delta$ is the discriminant $\prod_{1 \leq i < j \leq k} (x_i - x_j)$ and $[\Delta\cdot P]_l$ denotes the coefficient of the monomial $X^l = x_1^{l_1}x_2^{l_2} \ldots x_k^{l_k}$ in $\Delta\cdot P$. The tuple $l = (l_1,\ldots,l_k)$ has entries $$l_1 = \lambda_1 + k-1, \hspace{2mm} l_2 =\lambda_2 + k -2,\hspace{2mm}, \ldots \hspace{2mm}, l_k = \lambda_k.$$ Now Fulton and Harris claim the identity $$P = \sum_{\lambda \hspace{2mm} \text{a partition of $d$ into at most $k$ parts}} \omega_\lambda(P) s_\lambda$$ where $s_\lambda$ is the Schur polynomial $$s_\lambda = \frac{ \left|\begin{array}{cccc}x_1^{l_1} & x_2^{l_1} &\ldots & x_k^{l_1} \\
x_1^{l_2} & x_2^{l_2} &\ldots & x_k^{l_2} \\ 
&&\vdots\\
x_1^{l_k} & x_2^{l_k} & \ldots & x_k^{l_k}\end{array}\right|}{\Delta}.$$ Why should this be the case? They claim it is easy to see but I have been starring at this for several days now and don't understand how this claim comes. Am I missing something or is this another proof in Fulton and Harris that they just glance over? Thanks.","['representation-theory', 'combinatorics']"
214807,Non-existence of a Surjective Function from a Set to Its Subsets (Cantor's theorem),"Show that: Let A be a set and let $P(A)$ be the set of all subsets of $A$. Then there is no surjection $f: A→P(A)$. Here is what I thought: if $A=\{a,b\}$ then it has only two elements where $P(A)=\{∅,\{a\},\{b\},\{a,b\}\}$ has 4 elements. Therefore $f:A→P(A)$ cannot be surjective. But I have some problems: 1) How is it possible that any $f$ function to take $\{a\}$ from set $A$ to $\{a,b\}$? Maybe because I am thinking mainly about functions with real values like $f(x)=2x$, I find it a little bit strange that a function to take an element of a set to another set which has more elements. Is it possible? edit: Now I thought that if $f(x)$ is $\sqrt{x}$, then $f(4)=±2$ which means it took an element from a set to a set which has 2 elements. But still I find it kind of strange to denote $f(\{a\})=\{a,b,c,...\}$ 2) How can I construct a explicit proof for this question? Regards",['elementary-set-theory']
214828,"Limits using epsilon delta definition $f(x,y)=xy$ for functions of two variables","Prove: using $\epsilon$-$\delta$ definition, the limit of both $f$ and $g$ as $(x,y)\to (0,0)$ is $0$. $f(x,y)=xy$ $g(x,y)=\frac{xy}{x^2 +y^2+1}$ Also, for Q2 can I convert $g(x,y)$ to $m(x,y)/n(x,y)=g(x,y)$ using arithmetic of limits, then prove using $\epsilon$-$\delta$ definition the limit of function $m$ and $n$ separately; then combine the two? Thanks :) I wonder if this is correct:
$|xy-0|<\epsilon$ given $|x-0|< \delta $ and $|y-0|< \delta $ $|xy-0|< |x-0||y-0|<\delta^2=\epsilon$ therefore: $\delta<\epsilon^{1/2}$","['multivariable-calculus', 'limits']"
214863,Are finite sets discrete by definition?,"Are finite sets countable by definition? I was first wondering about whether a discrete set was countable by definition, but this page states that a discrete set has to be either finite or countable. And although it's easy to come up with cases for sets that are finite and countable, infinite and countable, and infinite and uncountable, it seems strange to me that a set could be finite and still uncountable. I hope that this level of questions is allowed here, it's the first time I post here, so I'm not sure about this yet.",['elementary-set-theory']
214865,How to solve the differential equation $u_k(z)=-2\cfrac{\partial}{\partial z }(\cfrac{u_{k+1}(z)}{z})$?,"$$e^{z\sqrt{1-t}}=\sum \limits_{k=0}^\infty \frac{u_k(z)t^k}{k!}$$ $$\frac{\partial}{\partial t }(e^{z\sqrt{1-t}})=\frac{\partial}{\partial t }(\sum \limits_{k=0}^\infty \frac{u_k(z)t^k}{k!})$$ $$\frac{-z}{2\sqrt{1-t} }e^{z\sqrt{1-t}}=\sum \limits_{k=1}^\infty \frac{u_k(z)t^{k-1}}{{(k-1)}!}=\sum \limits_{k=0}^\infty \frac{u_{k+1}(z)t^{k}}{{k}!}$$ $$\frac{-1}{2\sqrt{1-t} }e^{z\sqrt{1-t}}=\sum \limits_{k=0}^\infty \frac{u_{k+1}(z)}{z}\frac{t^{k}}{{k}!}$$ $$\frac{\partial}{\partial z }(\frac{-1}{2\sqrt{1-t} }e^{z\sqrt{1-t}})=\frac{\partial}{\partial z }(\sum \limits_{k=0}^\infty \frac{u_{k+1}(z)}{z}\frac{t^{k}}{{k}!})$$ $$\frac{-e^{z\sqrt{1-t}}}{2}=\sum \limits_{k=0}^\infty \frac{\partial}{\partial z }(\frac{u_{k+1}(z)}{z})\frac{t^{k}}{{k}!}$$ $$\sum \limits_{k=0}^\infty \frac{u_k(z)t^k}{k!}=-2\sum \limits_{k=0}^\infty \frac{\partial}{\partial z }(\frac{u_{k+1}(z)}{z})\frac{t^{k}}{{k}!}$$ $$u_k(z)=-2\frac{\partial}{\partial z }(\frac{u_{k+1}(z)}{z})$$ for $t=0$,$u_0(z)=e^z$ How to find the general formula of $u_k(z)$ ? I would like to learn the methods to solve such differential equations. Thanks a lot for answers. EDIT: We can find $u_1(z)$ as shown below $$\frac{\partial}{\partial t }(e^{z\sqrt{1-t}})=\frac{-z}{2\sqrt{1-t} }e^{z\sqrt{1-t}}=\sum \limits_{k=1}^\infty \frac{u_k(z)t^{k-1}}{{(k-1)}!}$$ for $t=0$,
$u_1(z)=\cfrac{-ze^{z}}{2} $ If we continue to derivate in such way, we can find all $u_k(z)$ but it seems long method. I am looking for easier method.","['generating-functions', 'ordinary-differential-equations', 'recurrence-relations']"
214905,Something behind the substitution $h^0=\frac{1}{|G|}\sum_{t\in G}\rho^2_{t^{-1}}h\rho^2_{t}$?,"I am quite new to representation theory and I reading Serre's Linear Representation of Finite Groups . 
In the first and second chapter, one trick he uses quite often is the substitution \begin{equation}
h^0=\frac{1}{|G|}\sum_{t\in G}\rho^2_{t^{-1}}h\rho^1_{t},
\end{equation} 
where $\rho^j:G\to GL(V^j)$ are representations on $V^j$, $h:V_1\to V_2$ is linear, and $|G|$ is the order of the group.
For instance he uses this when proving every representation is the direct sum of irreducible representations, and when proving Schur's lemma. I wonder whether there is something behind this powerful trick. To me it seems like a method to gauge the torsion/ tension between the two representations, and then averaging over $G$, but I am not sure. Thanks!","['finite-groups', 'intuition', 'representation-theory', 'group-theory']"
214911,Topological vector space generated by weak topology,"Q1. Let $(X, \|.\|)$ be a real Banach space and $\tau$ is the weak topology on $X$. I would like to ask whether $(X,\tau)$ is a topological vector space? Q2. Let $(X, \|.\|)$ be a real Banach space and its dual space $X^*$. Let $\tau^*$ is the weak$^*$ topology on $X^*$. I would like to ask whether $(X^*,\tau^*)$ is a topological vector space? Thank you for all construction and helping.","['general-topology', 'vector-spaces', 'functional-analysis']"
214912,Derivative of the sine function when the argument is measured in degrees,"I'm trying to show that the derivative of $\sin\theta$ is equal to $\pi/180 \cos\theta$ if $\theta$ is measured in degrees. The main idea is that we need to convert $\theta$ to radians to be able to apply the identity $d/dx \sin x = \cos x $. So we need to express
$
\sin \theta$ 
as 
$$
\sin_{deg} \theta = \sin(\pi \theta /180),
$$
where $\sin_{deg}$ is the $\sin$ function that takes degrees as input. Then applying the chain rule yields 
$$
d/d\theta [ \sin(\pi\theta/180)] = \cos(\pi \theta/180) \pi/180 = \frac{\pi}{180}\cos_{deg}\theta.
$$
Is this derivation formally correct?",['calculus']
214937,Uniqueness of symmetric positive definite matrix decomposition,"We know that any symmetric positive semi-definite matrix $K$ can be written as $K= AA^T$, where $A$ has real components. 
One way to get to $A$ is to compute eigen value decomposition of $K= P^T DP$ and define $A= P^T \sqrt{D}$, where $\sqrt{D}$ simply computes the square roots of diagonal elements. Now, I wonder to what extent such a decomposition is unique. Of course if $AA^T=K$ then $-A$ also works. My questions are: Up to what transformation the above matrix decomposition is unique. Is positive definiteness (PD) and positive-semi definiteness (PSD) of $K$ makes difference in uniqueness of this decomposition? To have a unique solution, do we need to fix the number of columns of $A$ (for a PSD or PD matrix)? Is the decomposition unique only if we are given this dimension? $A$ is different from square root of $K$, right? Because square root does not have to be symmetric?! Answering any part will be useful for me. Specially part 2.","['machine-learning', 'matrices', 'linear-algebra', 'numerical-linear-algebra', 'hilbert-spaces']"
214948,What's the algorithm of finding the convex combination of permutation matrices for a doubly stochastic matrix?,"According to Birkhoff, $n$ -by- $n$ stochastic matrices form a convex polytope whose extreme points are precisely the permutation matrices. It implies that any doubly stochastic matrix can be written as a convex combination of finitely many permutation matrices. Given a doubly stochastic matrix, is there an algorithm to compute the coefficients of a convex combination? For example, given $$A = \begin{bmatrix} 0.5&0.2&0.3\\ 0.1&0.6&0.3\\ 0.4&0.2&0.4\end{bmatrix},$$ how do you know the following? $$A=0.4\left[\begin{matrix}1&0&0\\0&1&0\\0&0&1\end{matrix}\right]+0.2\left[\begin{matrix}0&1&0\\0&0&1\\1&0&0\end{matrix}\right]+0.1\left[\begin{matrix}0&0&1\\1&0&0\\0&1&0\end{matrix}\right]+0.1\left[\begin{matrix}1&0&0\\0&0&1\\0&1&0\end{matrix}\right]+0.2\left[\begin{matrix}0&0&1\\0&1&0\\1&0&0\end{matrix}\right]$$ Please do briefly prove the correctness of the algorithm.","['permutation-matrices', 'stochastic-matrices', 'birkhoff-polytopes', 'matrices', 'polytopes']"
214959,Does the Riemann integral come from a measure?,"Can we approach the Riemann integral with measure theory? That is: can we find a measure $\mu$ defined on a $\sigma$-algebra of $\mathbb{R}$ such that a function is $\mu$-integrable if and only if it is Riemann integrable, and that the integral $\int f d\mu$ is equal to the corresponding Riemann integral. If so can we extend this to improper Riemann integrals? What about Riemann integration in $\mathbb{R}^n$?","['measure-theory', 'real-analysis']"
214984,Uncountability of basis of $\mathbb R^{\mathbb N}$,Given vector space $V$ over $\mathbb R$ such that the elements of $V$ are infinite-tuples. How to show that any basis of it is uncountable?,"['hamel-basis', 'linear-algebra']"
214987,A question regarding the absolute continuity of the distribution of infinite coin flips,"Here's the question I'm hopelessly on: Let $X_1, X_2, \dots$ be an $iid$ sequence of Bernoulli random variables on $(\Omega,\mathcal{F},\mathbb{P})$ with $\mathbb{P}(X_i = 1)=1/2$. Let $$X = 3\sum_{k=1}^\infty 4^{-k}X_k.$$ Show that the distribution function $F(x)$ of $X$ is not absolutely continuous w.r.t the lebesgue measure. I've compared this to the cantor function, which shares many of the same properties. What I'm trying to show is that $F$ only changes values on a set of Lebesgue measure zero, but without success. Trying to find a set with lebesgue measure zero but positive probability hasn't bourne fruit either.",['probability-theory']
214988,"Why for any doubly stochastic matrix, there exist a permutation $\pi$, such that $A_{[i,\pi(i)]}\ne 0$?","Or put it simply, for any $n$-by-$n$ doubly stochastic matrix $A$, you can always find $n$ non-zero entries in $A$, none of them lies in the same row or column. Why is that?",['matrices']
214990,Infimum of the spectrum of an unbounded selfadjoint operator,"Let $A$ be an unbounded selfadjouint operator in the Hilbert space $H$, having domain
$D(A)$. Denoting by $\sigma_A$ the spectrum of $A$, we have $\inf \sigma_A   \ = \ \inf_{u\in D(A),\|u\|=1}   \ \langle u, A u\rangle$ My question is: is this still true if I take the infimum only over a dense subset 
( EDIT : here I mean a subspace, not just a subset) $C$ of $D(A)$ instead of the whole $D(A)$? If $A$ was bounded this should be ok by continuity, but in the unbounded case? EDIT : After some more reflection it seems to me that it is ok also in the unbounded case if $C$ is a core for $A$  (i.e. A is the closure of its restriction to $C$). If $C$ is not a core I start to doubt seriously that it is true in general (I'm thinking of Laplacian on bounded domain, the bottom of the spectrum is different in the Neumann
and Dirichlet case...). Still I am not completely sure how to make this precise, and help is still appreciated.","['spectral-theory', 'functional-analysis']"
214996,unimodal distribution as a product with a uniform variable,"There is a theorem (Khinchin/Khintchine 1938) stating that a distribution is unimodal with mode at zero iff it is the distribution function of the product of two independent random variables one of which is uniform on (0,1). I am looking for a corresponding result for a unimodal distribution with mode at c > 0. This is not a homework. Thanks a lot in advance",['probability-theory']
214997,Normal Subgroups in a p-group,How can one prove the following claim: Elementary abelian $p$- group of order $p^n$   have the maximal number of normal subgroups among all  $p$-groups of the same order. Is is indeed true? Thanks in advance,"['finite-groups', 'group-theory', 'p-groups']"
215003,Prove that $\lim \limits _{k\rightarrow \infty} \int \limits _E f_k = \int \limits _E f$,"Show that if $f : E \rightarrow [0,\infty]$, $\lim \limits _{k\rightarrow \infty} f_k = f$ on $E$, and $f_k \leq f$ on $E$ for each $k \in N$, then $\lim \limits _{k\rightarrow \infty} \int \limits _E f_k = \int \limits _E f$ An idea was to show that $\lim \limits _{k\rightarrow \infty} \int \limits _E f_k \leq \int \limits _E f$ and $\lim \limits _{k\rightarrow \infty} \int \limits _E f_k \geq \int \limits _E f$. I am able to prove $\lim \limits _{k\rightarrow \infty} \int \limits _E f_k \leq \int \limits _E f$ but am struggling to prove the second condition. My idea was to use fatou's lemma to get 
$$
\int \limits _E \liminf \limits _{k\rightarrow \infty} f_k = \int \limits _E \lim \limits _{k\rightarrow \infty} f_k = \int \limits _E f \leq \liminf \limits _{k\rightarrow \infty} \int \limits _E f_k = \lim \limits _{k\rightarrow \infty} \int \limits _E f_k
$$
but I don't know how to show $\liminf \limits _{k\rightarrow \infty} f_k = \lim \limits _{k\rightarrow \infty} f_k$, besides showing $\liminf \limits _{k\rightarrow \infty} f_k = \limsup \limits _{k\rightarrow \infty} f_k$ . Any ideas on how I could finish this? Also, is my approach wrong? Could I do it a better way?",['real-analysis']
215018,Direct limit of $\mathbb{Z}$-homomorphisms,"What is the direct limit of the following sequence of $\mathbb{Z}$-homomorphisms (as groups)? $$ \mathbb{Z} \xrightarrow{2} \mathbb{Z} \xrightarrow{3} \mathbb{Z}\xrightarrow{5} \mathbb{Z}\xrightarrow{7} \mathbb{Z}\xrightarrow{11} \mathbb{Z}\xrightarrow{13}\cdots $$ Here the label $p$ indicates multiplication by $p$, and the sequence is just the sequence of primes. Is there an easy description of this limit? Would we get a different limit if we take a subsequence of the primes, or the sequence of primes squared?","['group-theory', 'abstract-algebra', 'abelian-groups']"
215034,"rate of convergence of mean ,variance & skewness estimators","We are asked a question which of mean,variance or skewness converges faster. At first I thought it was straight forward answer: mean->variance->skewness. But I am not sure anymore because I read somewhere standard error of the mean estimator is only slightly smaller.
std_error_of_mean=sigma/sqrt(n) std_error_of_varaince=sqrt(2) * (sigma^2)/sqrt(n) So it is only sqrt(2) times better ? I am not a statician, so can some one please explain what the general pattern is for standard error of higher order moments. Also are there equations for the rate of convergence of moments, so that I could compare with observation.
Thank you","['statistics', 'stochastic-processes', 'probability', 'standard-deviation']"
215038,Why this topological space is not a topological manifold?,"I'm having troubles to prove that the following space is not a topological manifold: Let $r:S^1\to S^1$ be a rotation of $\frac{2\pi}{3}$, i. e., $r(\cos\theta,\sin\theta)=\left(\cos\theta+\frac{2\pi}{3},\sin\theta+\frac{2\pi}{3}\right)$, such that $X=B^2/\sim$, where the partition is given by
$P=\{x\}$ if $|x|\lt1$ and $P=\{x,r(x),r^2(x)\}$ if $|x|=1$. So this is my attempt: Let $x\in X$ be a point in the boundary of $B^2$, the neighborhood of $x$ in $B^2$ is an open set $U$ of $B^2$ with $r(U)$ and $r^2 (U)$.
My strategy is to prove that this neighborhood is not homeomorphic to an open subset of $\mathbb R^n$, anyone can help me in this part? Thanks","['general-topology', 'manifolds', 'algebraic-topology']"
