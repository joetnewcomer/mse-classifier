question_id,title,body,tags
2208608,Plotting phase plane in Matlab for SIR model,"I want to plot the phase plane of the SIR model, I used the method describe in here This is the code that I wrote, function SIREquilibrium()
S0=0.8;
I0=0.2;
R=1-S0-I0;
beta=1;
gamma=1/10;
mu=5e-4;

f=@(t,y)[mu-beta*y(1)*y(2)-mu*y(1);beta*y(1)*y(2)-gamma*y(2)-mu*y(2);gamma*y(2)-mu*y(3)];

y1=linspace(0,1,20);
y2=linspace(0,1,20);
[x,y]=meshgrid(y1,y2);
u=zeros(size(x));
v=zeros(size(y));
t=0;
for i=1:numel(x)
    Yprime=f(t,[x(i);y(i)]);
    u(i)=Yprime(1);
    v(i)=Yprime(2);
end
quiver(x,y,u,v,'r') But I get an error as index exceeds matrix dimensions.

Error in SIREquilibrium>@(t,y)[mu-beta*y(1)*y(2)-mu*y(1);beta*y(1)*y(2)-gamma*y(2)-mu*y(2);gamma*y(2)-mu*y(3)] (line 16)
f=@(t,y)[mu-beta*y(1)*y(2)-mu*y(1);beta*y(1)*y(2)-gamma*y(2)-mu*y(2);gamma*y(2)-mu*y(3)];

Error in SIREquilibrium (line 25)
    Yprime=f(t,[x(i);y(i)]); I infact do not understand what Yprime=f(t,[x(i);y(i)]); does in this Can someone please tell me how I can plot the phase plane of this SIR model After making the changes to the code as f=@(t,y)[mu-beta*y(1)*y(2)-mu*y(1);beta*y(1)*y(2)-gamma*y(2)-mu*y(2)]; the phase plane I get is But, I think it should be Can you suggest me what I am doing wrong to get a phase plane like that. I changed the linspace to see why the spiraling in behavior couldn't be seen. And this is the phase plot that I get. function SIREquilibrium()
if nargin==0
   S0=0.8;
   I0=0.2;
   beta=0.3;
   gamma=1/10;
   mu=5e-5;
end


f=@(t,y)[mu-beta*y(1)*y(2)-mu*y(1);beta*y(1)*y(2)-gamma*y(2)-mu*y(2)];

y1=linspace(0,1,20);
y2=linspace(0,1,20);
[x,y]=meshgrid(y1,y2);
u=zeros(size(x));
v=zeros(size(y));
t=0;
for i=1:numel(x)

    Yprime=f(t,[x(i);y(i)]);
    Yprime=Yprime/norm(Yprime);
    u(i)=Yprime(1);
    v(i)=Yprime(2);

end
quiver(x,y,u,v,'r')
axis tight equal
hold on

for y10=[0:0.2:1]
    for y20=[0:0.2:1]
    options=odeset('MaxStep',0.1);
    [ts,ys]=ode45(f,[0,4000],[y10,y20],options);
    plot(ys(:,1),ys(:,2))
    end
end
hold off","['matlab', 'ordinary-differential-equations', 'dynamical-systems']"
2208612,How does one obtain $P\implies Q$ truth table?,"I am trying to get an intuition (ohh, the irony) about the logical truth tables. In particular, I am looking at the basic conditional $P\implies Q$ with the following truth table: $$\begin{array}{c|c|c}
P & Q & P\implies Q \\ \hline
\text{T} & \text{T} & \text{T} \\ \hline
\text{F} & \text{T} & \text{T} \\ \hline
\text{T} & \text{F} & \text{F} \\ \hline
\text{F} & \text{F} & \text{T}
\end{array}$$ How does one obtain this truth table? If it is an axiom, what is the motivation behind this particular form?","['axioms', 'logic', 'discrete-mathematics']"
2208618,"In a set of $n$ integers where no proper nonempty subset sums to a multiple of $n$, all elements are congruent","I want to prove the following: Let $A$ be a set of $n$ positive integers such that for any subset $M$, $M$ neither empty nor equal to $A$, the sum of elements of $M$ is not divisible by $n$. Prove that the elements of $A$ are all congruent $\pmod n.$ The $n=2$ case is obvious (both numbers must be odd). For $n=3$, the only possible residues are 1,2, and it is obvious that if both residues are present then their sum is divisible by 3, contradiction. 
$n=4$ is again easily provable by casework (since you can't have both 1 and 3 as residues in the same set.) However, i do not know how one would generalize this. For starters, if $r$ is a residue $\pmod n$, you cannot include both $r$ and $n-r$ as residues in the same set, thus obtaining that such a set has at most $\left \lfloor \dfrac{n+1}{2} \right \rfloor$ distinct residues.( $\lfloor a\rfloor$ is the integer part of $a$) How can I finish the proof?","['combinatorics', 'pigeonhole-principle', 'elementary-number-theory']"
2208631,What is needed to define a geometry?,"I'm not quite sure whether what I am asking is a valid question, however I have come across two different 'geometries': Euclidean and Minkowski (I have also heard of differential geometry, Riemannian geometry, elliptical geometry but I don't know much about these). In Euclidean geometry, we don't involve time whereas in Minkowski we do. In Minkowski we also have a different distance measurement... I am not sure whether I am perhaps mixing up a 'geometry' with 'a list of properties of spacetime' in the last part... And I apologise that my question seems to be based in physics; I am interested in geometries in general , but am just a first year general science undergraduate so my examples are simple physics-based ones.","['algebraic-geometry', 'euclidean-geometry', 'geometry', 'differential-geometry', 'definition']"
2208634,Pointwise convergence equivalent to convergence in pointwise topology,"Let $A$ be an index set, $X$ a topological space. Define $X^A$ to be the product $\displaystyle\prod_{\alpha \in A}X_\alpha$ where $X_\alpha = X, \forall \alpha \in A$. We can think the elements of $X^A$ as functions $f$ so that $f: A \to X$, $f(\alpha)=\pi_\alpha(f)$. Now I have the following theorem: Theorem .$f_n,f \in X^A$ and $f_n \to f$ in the product topology $\iff$ $f_n,f: A \to X$ and $f_n\to f$ pointwise. I could not start, how should I think the pointwise convergence here?","['product-space', 'general-topology', 'pointwise-convergence']"
2208669,Prove that $A-B=A$ implies and implied by $A\cap B=\emptyset $,"My work Let $x$ be any arbitrary element of $A-B$
$$A-B=\{x: x\in A,\; x\notin B\}$$
$$=\{x: x\in A,\;  x\in B'\}$$
$$=\{x:x\in A\cap B\}$$ How do I proceed further?",['elementary-set-theory']
2208703,On a pair of equalities between contour integrals.,"I was looking at this lovely answer to finding the characteristic function of a standard normal random variable. Unfortunately I am stuck on a pair of equalities, the first one is the following: $$ \int_{-L}^L \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{1}{2} \left( x - j \omega \right)^2 } \mathrm{d} x = \int_{-L-j \omega}^{L-j \omega} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z $$ I understand that a change of variable has took place. But I have only ever proven the change of variable formula with real numbers so it's not completely obvious to me why this should work. Is it because the reals are just a subset of the complex field? Moreover the fact that we can write the limits of the complex integral as two points in the complex plane is because the integrand function is holomorphic so we don't care for the path that connects the point, correct? The second one is: $$  \left(\int_{-L-j \omega}^{L-j \omega} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z - \int_{-L}^{L} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z\right) \\ = -\int_\mathcal{C} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z - \int_{L}^{L-j \omega} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z - \int_{-L-j \omega}^{-L} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-\frac{z^2}{2}  } \mathrm{d} z $$ Where the contour $\mathcal{C}$ is given by $-L \to L \to L - j \omega \to -L - j \omega \to -L$ Here I am quite lost, I don't understand how the contour is defined an neither how the equality is achieved. Maybe an extra step in-between the two equalities could help me.","['complex-analysis', 'integration', 'complex-integration']"
2208755,How to solve an equation of the form $f(x)=f(a)$ for a fixed real a.,"I got stuck on this question: find all solutions $x$ for $a\in R$: $$\frac{(x^2-x+1)^3}{x^2(x-1)^2}=\frac{(a^2-a+1)^3}{a^2(a-1)^2}$$ I see that if we simplify we get: $$\frac{(x^2-x+1)^3}{x^2(x-1)^2}=\frac{[(x-{\frac 12})^2+{\frac 34}]^3}{[(x-{\frac 12})^2-{\frac 14}]^2}$$ From the expression $(x-{\frac 12})^2$, I see that if $x=x_1$ is a solution, then $x=1-x_1$ is also a solution. But in the solution to this exercise, it was stated that $x=\frac{1}{x_1}$ must also be a solution, and I don't see how. [EDIT] Ok, thx for the help guys. What do you think of this solution (doesn't involve any above precalculus math, and needs no long calculations)? From the above we know that if $x_1=a$ is a solution, then $x_2=1-a$ is also a solution. Also, from here: $$\require{cancel}\frac{(x^2-x+1)^3}{x^2(x-1)^2}=\frac{\cancel{x^3}(x+{\frac 1x}-1)^3}{\cancel{x^3}(x+{\frac 1x}-2)}$$ in the expression $x+{\frac 1x}$ we see that if $x=x_1$ is a solution, then $x=\frac{1}{x_1}$ is also a solution, so $x_3=\frac{1}{a}$. With these two rules we can now keep generating roots until we have 6 total. If $x=x_2$ is a solution, then $x=\frac{1}{x_2}$ is also a solution, so $x_4=\frac{1}{1-a}$. If $x=x_3$ is a solution, then $x=1-x_3$ is also a solution, so $x_5=\frac{a-1}{a}$. Finally, if $x=x_5$ is a solution, then $x=\frac{1}{x_5}$ is also a solution, so $x_6=\frac{a}{a-1}$ The 6 obtained values are distinct, so they cover all the roots. [EDIT2] I guess this is answered. No sure whose particular answer to actually select as the right one since they're all correct, so I'll just leave it like this.",['real-analysis']
2208773,Confusion - The probability of the sum of two dice is $\frac{b-a+1}{36}$,"So the problem is: The solution writes: I understood all the steps except the step where I highlighted. Why is the probability of the $Y$, which is the sum of the two values $\frac{b-a+1}{36}$? I acknowledged that the $b-a+1$ is the total number of the discrete values from $b$ to $a$, but I thought if $x=k$ is from $a$ to $b$, then $Y$ should be $2(b-a+1)$ since it is the sum of two dice.","['expectation', 'probability-theory', 'markov-chains', 'statistics', 'probability']"
2208776,A smooth function $f(x)$ has a unique local and global minimum. What happens to its location as $f(x)$ varies smoothly in time?,"Let $f(x,t)$ be a smooth function $\mathbb R^2\to\mathbb R$ such that
  $F_t(x):=f(x,t)$ has a unique local minimum in $x$ for every fixed
  $t\in[0,1]$. Further assume that this local minimum of $F_t(x)$ is also the unique global minimum of $F_t(x)$. How regularly does the location of this unique minimum vary with
  respect to $t$? In other words, if $x=\chi(t)$ is the $x$-value where
  $F_t(x)$ attains its unique minimum, can we say that $\chi(t)$ is a
  smooth function of $t$? If not, is $\chi(t)$ differentiable or
  continuous? I asked a similar version of this question here . The answer was correct and very clever, but I was wondering what happens if we insist that the unique global minimum was also a unique local minimum.","['maxima-minima', 'real-analysis']"
2208777,The tip of the lotus plant was $6$ cm above the.,"The tip of the lotus plant was $6$ cm above the lake but forced by the wind it gradually advance and submerged into the distance of $10$ cm. Now find the depth of the pond
I couldn't get any idea regarding how to solve. But I have made a figure (if that is correct)","['algebra-precalculus', 'trigonometry']"
2208779,"Normal and Uniform Distribution, calculate $P(Y>X\mid X=x)$","Let $X$ and $Y$ be independent random variables distributed as $X \sim N(0,1)$ and $Y \sim \operatorname{Unif}(0,1)$. (a) Find $P(Y > X\mid X = x)$. (b) Use your answer in part (a) to compute $P(Y > X)$ I'm not sure where to start... I think the joint density is $$
f(x,y) = \frac{1}{\sqrt{2π}}e^{-x^2/2},  \quad
0<x<1, 0<y<1
$$ And do I just integrate that? If so from where, 0 to 1 on both integrals? I'm pretty lost with this and any help would be so appreciated. Apologies if it's not formatted correctly or if my attempt at an answer is plain stupid. I don't even really understand what part (a) means...","['normal-distribution', 'probability-distributions', 'statistics', 'probability', 'uniform-distribution']"
2208790,"Let $A\subset [-\pi, \pi]$ be a measurable set. Show that $\lim_{k\to \infty}\int_A \cos(kt) \text{d}t=0. $","This is a homework problem, however I don't know how to start with. Let $A\subset [-\pi, \pi]$ be a measurable set. Show that $$\lim_{k\to \infty}\int_A \cos(kt) \text{d}t=0. $$ I was thinking theorems like dominated convergence theorem etc. but don't know how to apply them. I read somewhere that this can be shown with Riemann-Lebesgue lemma, but we haven't proved that in class. What we recently proved was that the functions $\{\frac{1}{\sqrt{2\pi}}e^{ikt}:k\in\mathbb{Z}\}$ form a Hilbert basis in the space of square-integrable $2\pi$ -periodic functions $L^2_{2\pi, \mathbb{C}}([-\pi, \pi])$ . Any hints or help is appreciated.","['functional-analysis', 'lebesgue-integral', 'measure-theory']"
2208801,Curiosity on function maxima,"I was recently working with an equation of the form:
$$
\frac{\sqrt{x}}{a+bx+c\sqrt{x}}
$$
And I realized that the maxima (only considering positive real numbers) would always be at the point where:
$$
x=\frac ab 
$$
This is straightforward to prove by finding where the first derivative equals 0. Given this 'easy' result, I tried to find the logic behind it, which should probably be something easy, but I do not find it (I'm evidently no expert in mathematics, just curious). My question is, should it be evident that the function has a maxima at that point without having to calculate the derivative? In the case it should, could someone explain me the reasoning behind it? Thank you in advance.
Kind regards,
J.","['derivatives', 'maxima-minima']"
2208802,finding joint distribution and poisson process [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Two copy editors read a $300$-page manuscript. The first found $100$ typos, the second
  found $120$, and their lists contain $80$ errors in common. Suppose that the author's
  typos follow a Poisson process with some unknown rate $\lambda$ per page, while the two
  copy editors catch errors with unknown probabilities of success $p_1$ and $p_2$. Let $X_0$
  be the number of typos that neither found. Let $X_1$ and $X_2$ be the number of typos
  found only by $1$ or only by $2$, and let $X_3$ be the number of typos found by both. (a) Find the joint distribution of ($X_0;X_1;X_2;X_3$), expressed in $\lambda$, $p_1$, $p_2$. (b) Use the answer to (a) to find an estimates of $p_1$, $p_2$ and then the number of
  undiscovered typos.
  (Hint: Let N(s) be the Poisson process, with $T_i$ being the ""time"" when the i-th
  typo occurs, and the ""time"" variable is the page number.) Will appreciate it if someone can help me with this question. I don really know how to interpret this question.","['stochastic-processes', 'poisson-process', 'statistics', 'poisson-distribution']"
2208821,stochastic recurrence relation,"I'm interested in dealing with limit values for a linear recurrence relation, which is complicated slightly by stochastic transformations. Here is the specific question. For $n<0$, let $a_n=a_n^{\ast}=0$. Let $a_0=a_0^{\ast}=a_1=a_1^{\ast}=1$. Then for $n\geq 1$ define: $$a_{n+1}= a^{\ast}_{n}+\sum_{j\geq 1}4ja^{\ast}_{n-j} = a^{\ast}_n +4a^{\ast}_{n-1}+8a^{\ast}_{n-2} + 12 a^{\ast}_{n-3} \dots $$ Then $a_{n+1}^{\ast}$ is defined to be the value of a Poisson random variable with mean $a_{n+1}$. We are interested in the values $a_{n}^{\ast}$ for large $n$. Okay, so in the absence of the stochastic element, if it were simply the case that $a_{n}^{\ast}=a_n$ and this was a standard recurrence relation,
since we would then have $a_n=a_{n-1}+\sum_{j\geq 1}4ja_{n-j-1}$ we could rewrite, for $n>0$: $$a_{n+1}= 2a_n + 3n_{n-1} + 4\sum_{j\geq 2}a_{n-j}.$$ Given that $a_{n-2}=2a_{n-3}+3a_{n-4}+4\sum_{j\geq 2} a_{n-j-3}$, this in turn then gives, for $n>0$: $$a_{n+1}= 2a_n + 3a_{n-1} + 5a_{n-2}+2a_{n-3}+a_{n-4}.$$ Since the characteristic polynomial $x^5-2x^4-3x^3-5x^2-2x-1=0$ 
has a largest root $\alpha \approx 3.38298$, it follows that for some constant $\rho>0$: 
$$ \lim_{n\to \infty} \frac{a_n}{\rho\cdot \alpha^n} = 1. $$ OKAY.. so.. for the stochastic version, what I suppose happens is that with probability 1, we have $a^{\ast}_n/\alpha^n$ tending to a limit. 
One could presumably go in and prove it from first principles, but I expect this follows fairly directly from known theorems? Many thanks!","['stochastic-processes', 'recurrence-relations', 'probability']"
2208837,Visualizing Groups Software,"I'd like to have something that alouds to visualize groups. I found a software called "" group explorer "" but it's quite dated and visually not really appealing. I'm wondering if there's some other more recent but still simple software like that one. 
Thanks in advance","['abstract-algebra', 'group-theory', 'math-software']"
2208850,Distinguishing powers of finite functions,"For each $n \in \mathbb{N}$, let $F_n$ be a finite set with $n$ elements. For any function $f : F_n \to F_n$ and $k \in \mathbb{N}$, $f^k$ is the result of composing $f$ with itself $k$ times. Say that $n$ distinguishes powers $i$ and $j$ iff there is some function $f : F_n \to F_n$ such that $f^i \neq f^j$. For example, 2 distinguishes each odd power from each even power (because of the order-2 rotation), but does not distinguish any odd powers. But every number greater than 2 distinguishes 1 and 3. Conjecture. For all numbers $0 < m < n$, there exist powers $i$ and $j$ that $m$ does not distinguish but $n$ does distinguish. Is this conjecture true? How can I prove it?","['semigroups', 'monoid', 'elementary-set-theory', 'discrete-mathematics']"
2208879,Find the value of $\sin (\frac{\pi}{10})$ geometrically.,"The title says it. I had the idea to use the $2\theta$ and $5\theta$ formulae but they are not geometric... 
The question asks for an algebraic solution as well. Any ideas?",['trigonometry']
2208898,Schur's Theorem: In $\ell^1$ weak convergence of $x_n$ is the same as convergence in the norm,"I'm having a really hard time with nearly every part of this proof, any help would be appreciated. Schur's Theorem: In $\ell^1$ weak convergence of $x_n$ is the same as convergence in the norm. Definition : For $x_n \in \ell^1$ convergence in the norm:
$$ x_n \to x \iff \|\ x_n - x \|_{\ell^1}  \to 0.$$ Definition : For $x_n \in \ell^1$, weak convergence:
$$x_n \rightharpoonup x \iff \phi x_n \to \phi x \hspace{1cm} \forall x_n \in \ell^1 , \space\ \space\ \forall \phi \in \ell^{1*}.$$ This problem is from Muscat's ""Functional Analysis"" text. It breaks Schur's Theorem up into the following parts: 1) If the statement were false there would be unit $x_n = (a_{ni}) \in \ell^1$ such that $x_n \rightharpoonup 0$ Proof: Taking a unit $(a_{ni}) \in \ell^1$ we have that $\sum_{i=1}^{\infty} |a_{ni}| = 1$. Then, for some $\phi \in \ell^{1*}$ we (somehow?) obtain that $\phi x_n \to \phi x = 0$. 2)  For each $n$ there is an $N_n$, such that $\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5}$. Proof: Since $(a_{ni})$ is convergent in $\ell^1$ as a unit, we have that 
$$\sum_{i=1}^{\infty} |a_{ni}| = 1 \hspace{1cm} \forall n$$
as a requirement for convergent series is that their tail sequence goes to $0$, so that for $\epsilon > 0$ there exists some $N \in \mathbb{N}$ where 
$$\sum_{i=N}^{\infty} |a_{ni}| < \epsilon.$$
Hence, it follows that we may find an $N_n$ where 
$$\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5} \hspace{1cm} \forall n$$ 3) Each coefficient converges to $0$ as $n \to \infty$, so $\forall k , \exists M, n \geq M \Rightarrow \sum_{i < k} |a_{ni} | < \frac{1}{5}$. Proof: Mirroring what we did above in part (2) and choosing $\epsilon = \frac{1}{5}$. 4) A subsequence of $\left\{ x_n \right\}$ exists with 
  $$\sum_{i < N_n - 1} |a_{ni}| < \dfrac{1}{5} , \sum_{i=N_{n-1}}^{N_n} |a_{ni} | > \dfrac{3}{5}, \sum_{i > N_n} |a_{ni} | < \dfrac{1}{5} .$$ Proof: 5) Let $y := (|a_{ni}| / a_{ni}) \in \ell^{\infty}$ where for each $i$, $n$ is such that $N_{n-1} \leq i < N_n$. Show $|y \cdot x_n | \geq \frac{1}{5}$ to obtain a contradiction. Proof:","['functional-analysis', 'lp-spaces', 'weak-convergence']"
2208913,"Entire function bounded on every horizontal and vertical line , then is it bounded on every horizontal and vertical strip?","Let $f:\mathbb C \to \mathbb C$ be an entire function such that $f$ is bounded on every horizontal and every vertical line , then is it true that $f$ is bounded on any set of the form $V_{[a,b]}:=\{x+iy : y\in \mathbb R , a \le x \le b\}$ and any set of the form $H_{[a,b]}:=\{x+iy : x\in \mathbb R , a \le y \le b\}$ ?","['complex-analysis', 'holomorphic-functions', 'entire-functions']"
2208936,Parametric solution of the Brachistochrone problem,"In my attempt to find the parametric solution to the Brachistochrone problem
I write the differential equation resulting from the calculus of variations treatment as
$$y(1+y'^2) = k^2 \Rightarrow y' = \sqrt{\frac{k^2 - y}{y}}$$
Then attempt a parameterization of the form
$$\tan\phi = \frac{\mathrm{d}y}{\mathrm{d}x} = y' = \frac{\sqrt{k^2-y}}{\sqrt{y}}$$
and so
$$\cos\phi = \frac{\sqrt{y}}{k} \Rightarrow y = k^2\cos^2\phi \Rightarrow \frac{\mathrm{d}y}{\mathrm{d}\phi} = -2k^2\cos\phi\sin\phi,$$
and
$$\frac{\mathrm{d}x}{\mathrm{d}\phi} = \frac{\mathrm{d}x}{\mathrm{d}y}\frac{\mathrm{d}y}{\mathrm{d}\phi} = \cot\phi\cdot(-2k^2\cos\phi\sin\phi) = -k^2(\cos 2\phi + 1)$$
which I integrate to
$$
x = -k^2(\frac{1}{2}\sin 2\phi + \phi) + A.
$$
Now I'm stuck because this doesn't look like the equation of a cycloid that I recognise, and I don't know what range of values $\phi$ should take.
The substitution $\theta = -2\phi$ almost works:
$$
x = \frac{k^2}{2}(\sin\theta + \theta + A), y = \frac{k^2}{2}(1+\cos\theta),
$$
but how do I find $A$ given the start and end points $P_1 = (0,0)$ and $P_2 = (x_2, y_2)$?","['parametric', 'ordinary-differential-equations', 'calculus']"
2208942,Simple proof of Cauchy Integral formula for derivatives,"While going through the different texts on Complex analysis, I encountered several ways to prove the formula $\displaystyle f'(a)=\frac{1}{2\pi i}\oint_C \frac{f(z)}{(z-a)^2}dz$ where $f(z)$ is analytic within and on simple closed curve $C$ and $a$ is any point inside $C$ . In every proof of this in different texts, I found one thing common that is obviously the Cauchy first formula $f(a)=\frac{1}{2πi}\oint_C \frac{f(z)}{z-a}\,dz$ .....(1) and an estimation for the absolute value of an integral which must go to zero (estimation theorem) in order to prove it. I wonder whether or not my following proof is correct? $\displaystyle f'(a)=\lim_{\Delta z\to0} \frac{f(a+\Delta z)-f(a)}{\Delta z}$ . Now using (1) and on simplification gives $f'(a)=\lim_{\Delta z\to 0}\frac{1}{2\pi i}\oint_C\frac{f(z)}{(z-a-\Delta z)(z-a)}\,dz$ which gives the required value as $\Delta z→0$ . Is there any estimation really needed?","['cauchy-integral-formula', 'complex-analysis']"
2208943,Motivation for the rigour of real analysis,"I am about to finish my first year of studying mathematics at university and have completed the basic linear algebra/calculus sequence. I have started to look at some real analysis and have really enjoyed it so far. One thing I feel I am lacking in is motivation. That is, the difference in rigour between the usual introduction to calculus class and real analysis seems to be quite strong. While I appreciate rigour for aesthetic reasons, I have trouble understanding why the transition from the  18th century Euler style calculus to the rigorous ""delta-epsilon"" formulation of calculus was necessary. Is there a book that provides some historical motivation for the rigorous developement of calculus? Perhaps something that gives several counterexamples that occur when one is only equipped with a non-rigorous (i.e. first year undergraduate) formulation of calculus. For example, were there results that were thought to be true but turned out to be false when the foundations of calculus were strengthened? I suppose if anyone knows good counterexamples themselves they could list them here as well.","['real-analysis', 'big-list', 'calculus', 'soft-question', 'motivation']"
2208975,Using the Hartman-Grobman theorem on a polar system,"I have a system of differential equations, in polar form. It is quite simple this way, but rather ugly if I transform it into Cartesian coordinates. Is there any way to apply the Hartman-Grobman theorem without having to change coordinates? The equation is $$r' = r^3-r$$ $$\theta' = \sin(\theta)^2-\mu$$ Please DO NOT SOLVE THE PROBLEM FOR ME. I am just giving it so you know what kind of equation I am talking about. The goal is to analyze the five equilibria using Hartman-Grobman without changing coordinates.
Please just give me hint(s).",['ordinary-differential-equations']
2208989,The relation between a polynomial's multiplicity and that of its derivative.,"Say a polynomial $p(x)$ has $n$ real roots with a multiplicity of $k$. It can be shown that $p'(x)$ has a multiplicity of $k-1$. $$ p(x) = (x-a)^k\cdot h(x) $$
$$ p'(x) = k\cdot (x-a)^{k-1}\cdot h(x) + (x-a)^k\cdot h'(x)$$
$$ p'(x) = (x-a)^{k-1}(k\cdot h(x) + (x-a)\cdot h'(x))$$ Is it true in reverse? If I show that the derivative of a function $f(x)$ has a multiplicity of $k-1$, does this mean that $f(x)$ having multiplicity of $k$ is true?","['algebra-precalculus', 'calculus', 'derivatives']"
2209013,$n^{n-1}-1$ is a multiple of $k$,"Find the number of integers $k$ with $2 \leq k \leq 1000$ satisfying the following property: For every positive integer $n$ relatively prime to $k$ , $n^{n-1}-1$ is a multiple of $k$ . Let $k = 2^{\alpha_1}3^{\alpha_2} \cdots p_n^{\alpha_n}$ be the prime decomposition of $k$ . Then by the Chinese Remainder Theorem $n^{n-1} \equiv 1 \pmod{k}$ for all $n$ such that $\gcd(n,k) = 1$ if and only if \begin{align*}n^{n-1} &\equiv 1 \pmod{2^{\alpha_1}}\\n^{n-1} &\equiv 1 \pmod{3^{\alpha_2}}\\&\vdots\\n^{n-1} &\equiv 1 \pmod{p_n^{\alpha_n}}\end{align*} for all $n$ such that $\gcd(n,k) = 1$ . How can we continue?",['number-theory']
2209034,"Finding $\sum_{k=0}^{n-1}\frac{\alpha_k}{2-\alpha_k}$, where $\alpha_k$ are the $n$-th roots of unity","The question asks to compute: $$\sum_{k=0}^{n-1}\dfrac{\alpha_k}{2-\alpha_k}$$ where $\alpha_0, \alpha_1, \ldots, \alpha_{n-1}$ are the $n$ -th roots of unity. I started off by simplifiyng and got it as: $$=-n+2\left(\sum_{k=0}^{n-1} \dfrac{1}{2-\alpha_k}\right)$$ Now I was stuck. I can rationalise the denominator, but we know $\alpha_k$ has both real and complex components, so it can't be simplified by rationalising. What else can be done?","['algebra-precalculus', 'summation', 'complex-numbers']"
2209047,Isomorphism $M/IM\simeq A/I\otimes_A M$,"I'm trying to prove that $M/IM\simeq A/I\otimes_A M$. I defined $\varphi:M\to A/I\otimes_A M$ with $\varphi(m)=[1]\otimes m$. I've already proven that $\varphi$ is $A$-linear and also surjective. But I'm having trouble to prove that $\ker(\varphi)=IM$. The inclusion $IM\subset \ker(\varphi)$ is clear. On the other hand, if $m\in \ker(\varphi)$, then $[1]\otimes m=0$. If $m=0$, then $m\in IM$, and we are done. On the other hand, if $m\neq 0$, then I must prove that there are $i\in I$, $n\in M$ such that $m=in$. I really don't know how to prove that. What is the trick?","['abstract-algebra', 'tensor-products', 'commutative-algebra']"
2209073,Is the zero set of Brownian motion homeomorphic to Cantor space?,"Let $(B_t)_{t\in[0,1]}$ be a standard Brownian motion and let $Z=\{t\in [0,1]\colon B_t=0\}$ denote its zero set. $Z$ is a topological space when given the induced topology from $[0,1]$. Let $C=\{0,1\}^{\mathbb N}$ denote the space of infinite binary sequences, equipped with the product topology. Does there exist a homeomorphism from $Z$ to $C$ with probability $1$? By considering ternary expansions of real numbers, it is easy to show that $C$ is homeomorphic to the standard ternary Cantor set. Also, $Z$ can be constructed in a manner roughly similar to the ternary Cantor set, by successively removing open intervals from $[0,1]$ with an increasing level of precision. On the other hand, $Z$ has Hausdorff dimension $1/2$ while the ternary Cantor set has Hausdorff dimension $\log_3 2$.","['hausdorff-measure', 'probability', 'brownian-motion', 'general-topology', 'cantor-set']"
2209074,"Differentiable functions $f:\Bbb R \rightarrow \Bbb R^n$ satisfying the differential equation $f' = Af$, where $A\in \Bbb R^{n,n}$","Let $A \in \Bbb R^{n,n}$. I want to find all differentiable functions $f:\Bbb R \rightarrow \Bbb R^n$ satisfying the differential equation $f' = Af$. Please can anyone lend a hand here?","['matrices', 'ordinary-differential-equations', 'linear-algebra']"
2209080,Geometric intuition behind the derivative of $\sin^2(x)$ being $\sin(2x)$.,"If you take the derivative of $\sin^2(x)$ and remember your double-angle formulas, you see that
$$
  \frac{\operatorname{d}}{\operatorname{d}\!x}\; \sin^2(x)
  = 2\sin(x)\cos(x) 
  = \sin(2x)\,.
$$
This looks surprisingly clean. You can say the rate of change of $\sin^2$ at a value is given by the $\sin$ of twice that value. Is this just a happy accident? Or is there some nice geometric/trigonometric intuition behind this that I'm not seeing?","['derivatives', 'intuition', 'trigonometry', 'calculus']"
2209135,A matrix to the power of zero gives identity matrix even if it doesn't have an inverse?,"If one matrix whose determinant is equal to 0 which means it doesn't have an inverse. Then how is possible to find the value of the matrix to the power of 0 equal to identity matrix when multiplying the original matrix with something undefined? Is it a math fluke, or I am missing some important information?",['matrices']
2209141,When do solutions exist to variational problems in classical mechanics?,"Suppose I have a configuration space $ M $ and a lagrangian $ L: TM \rightarrow \mathbb{R} $. The action functional is defined as
$$
\mathcal{S}[q(t)] = \int_0^T L(\dot q(t) ) \ dt ,
$$
The principle of least action states that the trajectory starting from $ q_i $ at time $ t_i $ and arriving at $ q_f $ at time $ t_f $ is the path minimizing the action subject to the boundary conditions $ q(t_i) = q_i $ and $ q(t_f) = q_f $. My question is: when do solutions to the principle of least action exist?  What conditions on $ M $ and $ L$ ensure that solutions exist for all boundary conditions $ (q_i, t_i) , (q_f, t_f) $?","['classical-mechanics', 'ordinary-differential-equations', 'mathematical-physics']"
2209178,Who came up with the identity $a^3+b^3+c^3-3abc=(a+b+c)\left[a^2+b^2+c^2-ab-bc-ca\right]$,Though we can prove this it is not something that comes up intutively. Our ancestors must have been interested in factorising $a^3+b^3+c^3$ but why find it for $a^3+b^3+c^3-3abc$ ?,"['algebra-precalculus', 'math-history']"
2209196,"If $g\circ f$ is one-to-one, is it true that $f$ is onto or $g$ is onto?","Let $S,T$ and $U$ be nonempty sets, and let $f:S\to T$ and $g:T\to U$ be functions such that the function $g\circ f: S\to U$ is one-to-one (injective). Is it true that $f$ is onto or $g$ is onto? Can anyone please help. I can't solve this problem.","['elementary-set-theory', 'functions', 'gre-exam']"
2209219,Summing $\frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots$,"This question comes from temperature at sphere center . I think it's a good idea to extract the essence and post a pure mathematical question to attract more thoughts. It is a physical problem and interested readers can go to the original post to find details. Anyway, after simplification the wanted value is $2 f(x)$ $$
f(x)= - \sum_{n=1}^{\infty}(-1)^n e^{-x n^2} 
$$
Letting $x = \pi^2 D t /a^2$ gives the answer to the original question. If we further let $e^{x} = a$, we have a summation problem: $$
S=-\sum_{n=1}^{\infty}(-1)^n a^{-n^2} = \frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots
$$ $a > 1$ so $S$ converges, but I don't now how to sum it. Any suggestions?","['summation', 'asymptotics', 'sequences-and-series']"
2209224,Global differential form arising from an hermitian line bundle,"Let $X$ be a compact, connected Riemann surface and let $(L,h)$ be an hermitian line bundle on $X$. Suppose that $s$ is a nonzero meromorphic section of $L$. I've learned that the $(1,1)$-form 
$$\omega_s:=\partial\bar\partial \log (h(s,s))$$
is very important for the study of the geometry of $X$, but there are a couple of things that I don't understand: Why is $\omega_s$ defined on the whole $X$? I mean, $h(s,s)$ is well defined only out from the poles and the zeroes of $s$. Let's
  denote this open set with $U$, then $\omega_s$ is a $(1,1)$-form on
  $U$ and there should be a way to extend it uniquely to $X$. Assuming that $1.$ is proved, I want to understand why if $t$ is another meromorphic section of $L$, then $\omega_s=\omega_t$. Could you please give a proof of these facts? Edit: Clearly by $h$ I mean a smooth collection of hermitian products $h_x$ on the complex vector spaces $L_x$, for $x\in X$.","['riemann-surfaces', 'differential-forms', 'line-bundles', 'differential-geometry']"
2209264,Why do we need functions with compact support?,"My question is simply, why do we need functions with compact support? Are they a ntaural consequence of including Urysohn's lemma or Tietze extension theorem-which implies the Urysohn's lemma-? I just want to understand where do they come from so the theorems including them will be more familiar to me.","['functional-analysis', 'general-topology', 'compactness']"
2209324,Closed form of an integral involving Lambert function,"I'm trying to compute the following integral explicitly. $$I=\int_{0}^{+\infty} dx \left(1+\frac{1}{x}\right) \frac{\sqrt{x}}{e^{-1}+xe^x}$$ The best I managed to do is to do a change of variable $x=W(y)$, where W is the Lambert function. The integral is then given by $$I=\int_{0}^{+\infty} \frac{dy}{y}  \frac{\sqrt{W(y)}}{e^{-1}+y}$$ Maybe there could be a way to deform the contour of integration in the complex plane and use a residue formula with the new contour as we could have a pole at $y=-e^{-1}$? I guess we could do the transformation $y=e^x$ and obtain $$I=\int_{-\infty}^{+\infty} dx  \frac{\sqrt{W(e^x)}}{e^{-1}+e^x}$$ The poles would be located at $x=-1\pm i \pi$ but I do not know which contour to choose... I computed numerically the integral on mathematica which gives $I\simeq 3.9965$","['lambert-w', 'residue-calculus', 'calculus', 'closed-form', 'integration']"
2209344,Graph theory cycle proof,"Let $k \geq 2$, let $G$ be a graph.  Prove that if every vertex at least $k$, then $G$ contains a cycle of length atleast $k+1$. I thought about proving this with a contradiction but I can't find a proof that proves that there exists no such cycle with length atleast $k+1$. I know there's a proof stating that if every vertex has degree at least $2$ then there exists some cycle, is this related to that proof in any way?","['graph-theory', 'discrete-mathematics']"
2209363,"Induction: If $a+1/a$ is an integer, then so is $a^t+1/a^t$ for $t\in\mathbb N$","$a$ is in $\mathbb{R}$ but not equal to $0$, and $a+\dfrac{1}{a}$ is integer, $a^t+\dfrac{1}{a^t}$ is also an integer for all $t\in\mathbb N$. If $\displaystyle a+\frac1a$ is an integer then $\displaystyle \left(a+\frac1a\right)^2,\left(a+\frac1a\right)^3, \ldots $ are integers. Maybe induction on $$a^{t+1} + \frac1{a^{t+1}} = \left(a^t+\frac1{a^t}\right)\left(a+\frac1a\right) - \left(a^{t-1}+\frac1{a^{t-1}}\right)$$ I'm having a problem doing the induction for this problem, any help will be appreciated.","['induction', 'proof-writing', 'discrete-mathematics']"
2209430,Computing line integral (Stokes Theorem),"Given that $\textbf{F} =  \langle z,x,y \rangle$, The plane $ z=2x+2y-1$ and the paraboloid $ z= x^2 +y^2$ intersect in a closed curve. I'm trying to use stokes theorem to find the line integral. Attempt: We know that Stokes Theorem is given by:
$\iint_S (\nabla \times \textbf{F}) \cdot \textbf{N}\: d\textbf{S} $ $\nabla \times \textbf{F} = \vec{\imath} + \vec{\jmath} + \vec{k}  = \langle 1 , 1, 1\rangle$ Now, the problem I have is parameterizing. This is what I did. $$\vec{r} = \langle x,y,2x+2y-1\rangle$$
$R_x \times R_y = 2\vec{\imath} - 2\vec{\jmath} + 0\vec{k} $ Now,
$\iint_S \langle 1 , 1, 1\rangle \cdot \langle 2 , -2, 0\rangle \: d\textbf{S} = 0 $. But this is not right! Perhaps what I'm struggling most is getting the parameterization right for the surface. Also would I have to convert to polar coordinates to complete the integral? Any help would be appreciated! Thank you","['multivariable-calculus', 'stokes-theorem', 'parametrization', 'calculus']"
2209438,Limit of $\frac{1}{x^4}\int_{\sin x}^{x} \arctan t dt$,"I am trying to find this limit, $$\lim_{x \rightarrow 0} \frac{1}{x^4} \int_{\sin{x}}^{x} \arctan{t}dt$$ Using the fundamental theorem of calculus, part 1,
$\arctan$ is a continuous function, so
$$F(x):=\int_0^x \arctan{t}dt$$
and I can change the limit to
$$\lim_{x \rightarrow 0} \frac{F(x)-F(\sin x)}{x^4}$$ I keep getting $+\infty$, but when I actually integrate $\arctan$ (integration by parts) and plot the function inside the limit, the graph tends to $-\infty$ as $x \rightarrow 0+$. I tried using l'Hospital's rule, but the calculation gets tedious. Can anyone give me hints? EDIT I kept thinking about the problem, and I thought of power series and solved it, returned to the site and found 3 great answers. Thank You!",['limits']
2209472,Graph with many automorphisms,"Let $G(V,E)$ be an undirected graph, potentially with loops and multi-edges. Assume the following two properties hold: $\forall a \in V, \exists f \in \operatorname{Aut}(G), f(a) \ne a$ $\forall f\in \operatorname{Aut}(G), \exists a \in V, f(a) = a $ Prove: $10 \le |V| $","['combinatorics', 'graph-theory', 'automorphism-group']"
2209523,Prove By Induction $1 + 1/2 + 1/3 + ... + 1/(2^n) ≥ 1 + n/2$,$1 + 1/2 + 1/3 + ... + 1/(2^n) ≥ 1 + n/2$ I'm trying to prove by induction. But i can't really figure out the basis step. if $n = 1$ what would the inequality simplify into? $1 ≥ 1 + 1/2$? I can't really figure out the pattern here.,"['induction', 'discrete-mathematics']"
2209553,Solve $2\cos(x)^2 - 5\sin(x) - 4 = 0$ on the interval $0 \leq x \leq 2\pi$,This is homework. I got it down to either $\sin(x) = -2$ or $\sin(x) = -1/2$ but I have absolutely no idea where to go from here.,"['problem-solving', 'trigonometry', 'quadratics']"
2209565,If $A$ & $B$ are $4\times 4$ matrices with $\det(A)=-5$ & $\det(B)=10$ then evaluate...,"If $A$ & $B$ are $4\times 4$ matrices with $\det(A)=-5 $ & $\det(B)=10$ then evaluate... a) $\det\left(A+\operatorname{adj}\left(A^{-1}\right)\right)$ b) $\det(A+B)$ Yes, those are meant to be addition signs. I wouldn't be asking if it were multiplication. ANS for a) is $-256/125.$","['matrices', 'linear-algebra']"
2209592,Can an idempotent matrix be complex?,A matrix $A$ is called idempotent if $A^2 = A$. I am just wondering if such matrix can be complex. Anyone can help give an example or proof that it has to be real? Thanks!,['linear-algebra']
2209594,Solving the differential equation $y'= 2 xy + 4 x$ using power series.,This differential equation can be solved using a Power Series Method: $$f'(x) = 2 x f(x) + 4 x$$ I found $f'(x)$ and substituted it back into the equation but i do not understand where to go from there. How would i be able to find the power series which satisfies this differential equation?,"['power-series', 'ordinary-differential-equations', 'sequences-and-series']"
2209628,"Proving convergence of the series $\sum_{n=1}^{\infty}\frac {1}{1000n^2 + 25n - 5}$ with comparison test, what can you jump to","I'm just going to make up a series as an example. $$\sum_{n=1}^{\infty}\frac {1}{1000n^2 + 25n - 5}$$ Not sure if it is a valid series or not, but that's not my question. So if I had to go and prove a series converges by using the comparison test. Say I wanted to compare it to $$\sum_{n=1}^{\infty}\frac {1}{n^2}$$ which I know converges. Would it be too far fetched to compare these two series? If this was a valid series, then my proof would look like this: $$\sum_{n=1}^{\infty}\frac {1}{1000n^2 + 25n - 5}$$ $\le$ $$\sum_{n=1}^{\infty}\frac {1}{n^2}$$ Since p > 1, this series in particular converges by p-test, and by comparison test, the original series converges as well. So yeah, main question, can I jump straight to $$\sum_{n=1}^{\infty}\frac {1}{n^2}$$ from the original series? If not how would I go about doing so?","['convergence-divergence', 'sequences-and-series', 'analysis']"
2209643,are there any matrices that act like the identity matrix but are totally different?,"Given any matrix $A$ or vector $v$, can you find a matrix $B \neq I$ and also not resembling $I$ (having entries in places other than diagonal) such that $B*A$ and $B*v$ are approximately $A$ and approximately $v$? For me the answer is should obviously be yes.  Also I am aware that $I$ is unique, so the matrix $B$ will never have the same effect as $I$ unless it is equal to $I$ itself.",['linear-algebra']
2209671,Evaluating $\int_{-\infty}^\infty \frac{1}{(4+x^2)^2}\mathrm dx $,"I wish to evaluate the integral $\int_{-\infty}^\infty  \frac{1}{(4+x^2)^2}\mathrm dx $ . This is a complex analysis exercise so expecting that some sort of complex analysis technique is required, my first instinct was to split the integrand into partial fractions, making use of the fact that $(4+x^2)^2=(x+2i)^2(x-2i)^2$ but the Cauchy Integral Formula does not seem to work here so I got stuck. Then I went back to using substitution, say $x = \tan u$ but that didn't really work out as well, though I am not sure if I missed any technical details.","['complex-analysis', 'integration', 'calculus']"
2209684,Sum of Divergent and Convergent Series,"$\sum_{n=1}^{\infty}x_n$ is a convergent series and $\sum_{n=1}^{\infty}y_n$ is a divergent series. Prove their sum diverges. My attempt: Suppose $\sum_{n=1}^{\infty}x_n + y_n$ converges. Since $\sum_{n=1}^{\infty}-x_n = -\sum_{n=1}^{\infty}x_n$ converges,  $\sum_{n=1}^{\infty}x_n + y_n - \sum_{n=1}^{\infty}x_n = \sum_{n=1}^{\infty}y_n$ This implies that $\sum_{n=1}^{\infty}y_n$ converges, which is a contradiction. Therefore $\sum_{n=1}^{\infty}x_n + y_n$ diverges. How is this proof?","['calculus', 'analysis']"
2209705,Differential equations and categorical logic,"In categorical logic, we usually think of each theory as being category $\mathbf{T}$. A model of $\mathbf{T}$ is then a functor $\mathbf{T} \rightarrow \mathbf{Set}$ satisfying some appropriate conditions. And, we can change $\mathbf{Set}$ to other sufficiently-nice categories to get other notions of model. I was wondering whether or not something similar can be done for differential equations/IVP's/integral equations (etc.); can we think of these as some kind of object such that morphisms out of this object ""are"" solutions to the problem?","['logic', 'initial-value-problems', 'category-theory', 'ordinary-differential-equations', 'differential-geometry']"
2209716,How many different combinations of a six sided die rolls equals n,"Say I want to roll a six-sided-die until all the rolls I have made added together equal X (for example a number like 812). How do I calculate how many different possible combinations of dice rolls add up to X? for example:
say I want to find the different roll combinations that equal 6:
6
51
15
42
24
33
123
312
213
114
411
141
1113
3111
1311
1131
11112
21111
12111
11211
11121
and so on... I have found that this approach does not work for larger numbers. Thanks Thanks","['combinations', 'discrete-mathematics']"
2209795,Collineations of the unit disk,"I've been reading a proof that all models of Lobachevskian geometry are isomorphic. As part of the proof, the following statement was made, but no proof or reference was given. (The proof can actually be fixed relatively easily so that it doesn't rely on the statement, but I find the statement interesting in its own right.) Any bijection of the disk $x^2 + y^2 < 1$ onto itself that maps chords to chords is projective. This can be restated as follows, viewing the disk as the Klein model of the hyperbolic plane. Any bijection of the hyperbolic plane onto itself that preserves alignment is an isometry. The first statement refers of course to the ordinary Euclidean unit disk. A projective mapping means any mapping of the form $x' = (ax + by + c)/(gx + hy + i), y' = (dx + ey + f)/(gx + hy + i)$. If the unit disk is replaced with the whole plane, then the statement is equivalent to the so-called ""fundamental theorem of affine geometry."" Without loss of generality, we may assume that the origin is fixed (since it can be shown that projective mappings of the required kind exist that take any point to any point) and that the line $y = 0$ is invariant (applying a rotation). In that case, the problem is to show that only four mappings are possible, namely, the identity mapping, reflections with respect to the coordinate axes, and central symmetry with respect to the origin. Really, I'd be happier with a reference than with a proof given here, particularly if the proof is long. A reference in another European language would probably be okay.","['reference-request', 'noneuclidean-geometry', 'projective-geometry', 'euclidean-geometry', 'geometry']"
2209808,Product of two consecutive integers.,"I have a small algebra problem If the sum of two consecutive integers is $x$, what would be their product? I've made equation.$$n+(n+1)=x$$
But, don't understand how to find their sum.","['algebra-precalculus', 'linear-algebra']"
2209823,When can you take the derivative of both sides of an equation?,"I know in general you cannot take the derivative of an equation to solve it because the derivative at a point depends on neighboring points of a function. However, lots of the proofs done in my probability course, for example finding the variance of a geometric random variable is done by differentiating both sides. Why is this allowed?","['derivatives', 'probability', 'calculus']"
2209891,"Let be $a,b$ positive real numbers; $a+\frac {b} {a+\frac {b} {a+\frac {b} {\ddots }}}$ how can we prove whether this has a limit or not?","Let, given example is like this $$3+\dfrac {4} {3+\dfrac {4} {3+\dfrac {4} {\ddots }}}=?$$ I wonder if it has a limit or not, but I have a idea, If we show that this sequence monotonous and has a bound, we can say that this has a limit. Therefore,firstly, we need to write sequence form; $$3+\dfrac4{x_n}=x_{n+1}$$ If we assume that this sequence has a limit, we can apply convergence of subsequences theorem, with respect to this theorem we can do the following conclusion.Let assume $x$ equals to limit of the sequence>$$3+\dfrac4{x}=x$$
$x_1=4$ and $x_2=-1$, limit should be positive, so $x=4$.That is;
$$3+\dfrac {4} {3+\dfrac {4} {3+\dfrac {4} {\ddots }}}=4$$ My intuition says me that the sequence is increasing and has a upperbound but I couldn't show, so above proof is not valid for now. How we can that this is a monotonous and has a bound?","['sequences-and-series', 'limits']"
2209895,Expected absolute difference between two iid variables,"Suppose $X$ and $Y$ are iid random variables taking values in $[0,1]$, and let $\alpha > 0$. What is the maximum possible value of $\mathbb{E}|X-Y|^\alpha$? I have already asked this question for $\alpha = 1$ here : one can show that $\mathbb{E}|X-Y| \leq 1/2$ by integrating directly, and using some clever calculations. Basically, one has the useful identity $|X-Y| = \max{X,Y} - \min{X,Y}$, which allows a direct calculation. There is an easier argument to show $\mathbb{E}|X - Y|^2 \leq 1/2$. In both cases, the maximum is attained when the distribution is Bernoulli 1/2, i.e. $\mathbb{P}(X = 0) = \mathbb{P}(X = 1) = 1/2$. I suspect that this solution achieves the maximum for all $\alpha$ (it is always 1/2), but I have no ideas about how to try and prove this. Edit 1: @Shalop points out an easy proof for $\alpha > 1$, using the case $\alpha = 1$. Since $|x-y|^\alpha \leq |x-y|$ when $\alpha > 1$ and $x,y \in [0,1]$, $E|X-Y|^\alpha \leq E|X-Y| \leq 1/2$. So it only remains to deal with the case when $\alpha \in (0,1)$.","['real-analysis', 'probability', 'random-variables']"
2209935,Distribution of the index of the variable which achieves the minimum of exponential random variables,"I am reading Exponential distribution from Wiki, and it is said that the index of the variable which achieves the minimum is distributed according to the law
$$P(k|X_k=min\{X_1,X_2,...,X_n\})=\frac{\lambda_k}{\lambda_1+...+\lambda_n}$$ I don't know how to prove this property. I try the case $n=2$ in different ways. First, I find $P(X_1\le X_2)=\frac{\lambda_1}{\lambda_1+\lambda_2}$, but I can't change this to the conditional probability formally. Second, I try to prove this through pdf. Let $Y=min\{X_1,X_2\}$, I want to calculate $f_{X_1|Y}(x_1,y)$. However I find that there should be infinite value of $f_{X_1|Y}(x_1,y)$ at $x_1=y$ , since the conditional probability is actually a discrete distribution. I don't know how to obtain the discrete distribution from continuous pdf. Please tell me how can I continue my proof or give another formal proof, Thanks!!","['probability', 'probability-distributions']"
2209954,Possibilities Hexagon Coloring,"we colored vertices of a hexagon convex  by three different colors ; such that every color appears exactly only two times in the vertices .
Find the number of possibilities in order to get every vertice of this hexagon colored such that any two neighboring points have distinct colors. The answer must be either 4 or 5. Can we generalize the solution to a problem like this? we colored vertices of a 2n -gon convex  by n different colors ; such that every color appears exactly only two times in the vertices .
Find the number of possibilities in order to get every vertice of this convex colored such that any two neighboring points have distinct colors. please post some hints. I don't want actually a full solution.","['combinatorics', 'discrete-mathematics']"
2209977,"Number of paths between two lines , Catalan Numbers","Find the number of paths with length of 14 between (0,0)  and (7,7) which do not go above the line $y=x+1$ and do not go beneath the line $y=x-3$ ?
every step in the path is either right or up. In order to find the number of the paths from (0,0) to (7,7) which don't go above the line $y=x+1$ I used the reflection Lemma, I did the same for the paths which 
don't go beneath the line $y=x-3$:
I thought about using inclusion-exclusion.
let F be the amount of the paths from (0,0) to (7,7) which means:
$7+7 \choose 7 $ =3432 Let $F_1$ be the number of paths from (0,0) to (7,7) which GO above the line $y=x+1$ which means:
$5+9 \choose 5$ and finally, Let $F_2$ be the number of paths from (0,0) to (7,7) which GO beneath the line $y=x-3$ which means:
$11+3 \choose 3$ Now, I need to calculate:
$F-(F_1+F_2-F_1\cap F_2$). 
I can't figure out how to find the intersection between the two. Thanks in advance.","['combinatorics', 'catalan-numbers', 'discrete-mathematics']"
2209987,A consequence of the Fundamental Theorem of Arithmetic.,"The book said that:""If $S={1,2,3,.....,200}$, then for each $x \in S$, we may write $x=2^{k}y$, with $k \geq 0$, and gcd(2,y)=1."" and the book added that this result follows from the Fundamental Theorem of Arithmetic, but I do not know how? could anyone explain this for me?","['number-theory', 'combinatorics', 'discrete-mathematics']"
2210028,"Solving the matrix differential equation $\frac{d M} {dt} = \kappa \hspace{1mm} \max(0,(M_1-M) -\gamma I )$","I have a weird equation that I want to solve, $$\frac{d M} {dt} = \kappa  \hspace{1mm} \max(0,(M_1-M) -\gamma I )$$ where, $M, M_1, I$ are all $2 \times 2$ matrices. With the $\max$ function I want to make sure the matrix $M$ does not shrink or become smaller, so the $\max$ condition I am imagining is that the condition for the argument matrix to be positive definite.","['matrix-calculus', 'ordinary-differential-equations', 'linear-algebra']"
2210077,Why the sigma algebra generated by a function of a random variable is a subset of the sigma algebra generated by the random variable itself?,"Could you help me to understand why the sigma algebra generated by a function of a random variable is a subset of the sigma algebra generated by the random variable itself? I think I am missing something about measurability. Consider the probability space $(\Omega, \mathcal{F}, P)$ and the measurable space $(\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))$ where $\mathcal{B}(\cdot)$ denotes the Borel sigma algebra. 
Let $X:\Omega\rightarrow \mathbb{R}^d$ be a $(\mathcal{F},\mathcal{B}(\mathbb{R}^d))$-measurable random vector. Let $f(X):\Omega\rightarrow \mathbb{R}^p$ be a $(\mathcal{F},\mathcal{B}(\mathbb{R}^p))$-measurable random vector. Consider the sigma algebra generated by $X$
$$
\sigma(X):=\{X^{-1}(B) \text{ } \forall B\in \mathcal{B}(\mathbb{R}^d)\}=\{\omega \in \Omega \text{ s.t. } X(\omega)\in B \text{ } \forall B\in \mathcal{B}(\mathbb{R}^d)\}
$$
Consider the sigma algebra generated by $f(X)$ $$
\sigma(f(X)):=\{f(X)^{-1}(C) \text{  }\forall C\in \mathcal{B}(\mathbb{R}^p)\}=\{\omega \in \Omega \text{ s.t.} f(X(\omega))\in C \text{ } \forall C \in \mathcal{B}(\mathbb{R}^p)\}
$$ (1) Why $\sigma(f(X))\subseteq \sigma(X)$? (2) Consider another real-valued random variable $Y$. Does it follow that $E(Y|X)=E(Y|f(X))$ if and only if $\sigma(X)=\sigma(f(X))$?","['measurable-functions', 'measure-theory']"
2210123,Non-negative function with non-negative compactly supported Fourier transform,"In a paper I'm trying to understand, the author claimed (without proof) the existence of a Schwartz function $\varphi \colon \mathbb{R} \rightarrow \mathbb{R}$ with the following properties: $0 \leq \varphi(x) \leq 2$ for every $x \in \mathbb{R}$, $\varphi(x) \geq 1$ for every $x \in [0,1]$, $\widehat{\varphi} (\xi) \geq 0$ for every $\xi \in \mathbb{R}$, $\widehat{\varphi}(\xi)$ is compactly supported on (say) $[-10,10]$. I tried two methods to prove this, but in both cases there's been a small thing I've been unable to show. Firstly, I took an appropriately scaled Gaussian $G$ that satisfied properties 1 and 2 (with a little leeway) in real space, and considered its Fourier transform $\widehat{G}$, which is another Gaussian. I then added a smooth ""remainder"" term $\widehat{r}$, defined by
$$\widehat{r}(\xi) = \begin{cases} 0 & |\xi| \leq 9\\ \textrm{smooth in-between} \\ -\widehat{G}(\xi) & |\xi|> 10\end{cases}$$ and defined $\widehat{\varphi} = \widehat{G} + \widehat{r}$, hence $\varphi = G + r$. Since the $L^\infty$ norm of $r$ is bounded by the $L^1$ norm of $\widehat{r}$ (which we know to be very small), we know that $\varphi$ satisfies properties 2, 3, and 4, and that $\varphi\leq 2$. However, I can't seem to show that $\varphi\geq0$ (and I'm not 100% convinced that it's the case anyway). The second approach I tried was to take a smooth, non-negative, even function in Fourier space, $\widehat{\eta}$, that is supported on $[-5,5]$, so that $\widehat{F} = \widehat{\eta}\ast\widehat{\eta}$ is supported on $[-10,10]$. Then $F = \eta^2 \geq 0$, and by scaling $\widehat{F}$ appropriately, we have $F\leq 2$. Then, assuming that the maximum of $F$ occurs at $x=0$, we can ""stretch"" $F$ horizontally such that it is greater than 1 on the interval $[0,1]$. However, I'm not sure how to show that the maximum is indeed at $x=0$, or whether that is even the case. Any ideas on how to plug the hole in either of these proofs, or alternative proofs, would be most welcome.","['real-analysis', 'fourier-analysis', 'fourier-transform']"
2210189,Geometric notion of addition for the real projective line,"The real projective line $\mathbb{RP}^1 = \mathbb{R} \cup {\infty}$ is usually identified with (or defined as) the set of lines passing through the origin in $\mathbb{R}^2$. Thus, the number $m\in \mathbb{R}$ corresponds to the unique line with finite slope $m$, and $\infty$ corresponds to the unique vertical line. Algebraically, we can define the usual extensions of addition, multiplication, negatives and reciprocals from $\mathbb{R}$ to $\mathbb{RP}^1$, with a few cases left undefined. My goal is to find a good geometric interpretation of these operations. Geometrically, given a line $a \in \mathbb{RP}^1$, the additive inverse $-a$ and reciprocal $\frac{1}{a}$ can be clearly constructed as respective reflections over the lines $0$ and $1$. On a similar way, multiplication of projectively extended real numbers is just composition of the underlying linear relations, and can be computed geometrically by passing to $\mathbb{R}^3$. To construct $a\cdot b$, one first extends the line $a$ in XY perpendicularly to a plane, then does the same with the line $b$ in YZ, and finally projects the intersection of these two planes onto XZ to find the desired product: This allows one to find, for example, a consistent meaning to the expression $0 \cdot \infty$ by including the elements of the two trivial Grassmannians $\bot \in \mathrm{Gr}(0, 2)$ and $\top \in \mathrm{Gr}(2, 2)$ among the possible outcomes of multiplication, as is pointed out here . In fact, the composition of any two functions or relations $\mathbb{R} \to \mathbb{R}$ can be performed in this way using their graphs in $\mathbb{R}^2$. On the other hand, so far I haven't been able to find any geometric interpretation of addition in the projective line. So my question is: How can we construct the sum of two lines in $\mathbb{RP}^1$ geometrically? To be more specific, by ""geometrically"" I mean in the sense of classical compass-and-straightedge constructions and their obvious generalization to higher dimensions (for example, one is allowed to construct a plane passing through three nonaligned points, a sphere given a point and a radius, take intersections, etc.). Alternatively, since the three notions above are still valid if we replace lines with the graphs of arbitrary relations, it could be interesting to look for an answer that is generalizable in this sense (if it exists). In any case, an acceptable construction should be able to reproduce the addition of real numbers, and the identities $\infty + a = a + \infty = \infty$ for any $a \neq \infty$. What I've tried The first thing that came to my mind is to use an auxiliary vertical line at a nonzero distance from the origin: Unfortunately this approach breaks down for vertical lines. The definition of addition for linear relations given the link above seems to suggest a three-dimensional construction like in the case of multiplication, but I've failed to find something that works.","['geometric-construction', 'projective-space', 'geometry']"
2210207,Solve $\cos(z)=\frac 34+\frac i4$,"How can I proceed to solve $$\cos(z)=\frac 34+\frac i4$$ I'm not very good in complex variable... But I know the definition of the complex functions, can you help me?","['complex-analysis', 'complex-numbers']"
2210215,Linear Regression: units of intecepts given $x$ and $y$ as log function?,"Given a line $y = ax + b$, where $x = log(w)$ and $y = log(l)$. To me, the units of $b$ should be unitless as $y$ will be unitless. Is this right?","['regression', 'statistics']"
2210228,Tangent to a fiber bundle,"I am trying to prove that the kernel of a push-forward is the fiber. Let $π : E → M $ be a fiber be bundle with a fiber $F$ . What is the meaning of a tangent space to a bundle? Does it means that if we have a vector, $X$ tangent to curve $\lambda$, that curve must pass to all points of the fiber or in just one point of the bundle?",['differential-geometry']
2210251,Mean distance between alternatively jumping frogs,"Consider a bounded line in $\mathbb Z$, with the indices $a$ and $b$ as its end-points (with $|a-b| \geq 3$). We place two frogs on the line, starting at $i$ and $j$. At each time step $n$ (discrete) the frogs must alternatively (one jump per time step) make a random jump to one of their neighbours (so either +1 or -1 with equal probability, unless one neighbour is an end-point or the other frog, in which case the frog jumps to its only neighbour with probability one [1]). The only rule is: the frogs can never occupy the same position at the same time. So intuitively this implies that either frog at any given time is only able to explore a small span of the whole line, namely, from one end-point upto the position of the other frog. [1]: small caveat, it can happen that the frog to jump has no empty neighbour, e.g. when next to an end-point with the other frog blocking its other side), in this case only the other frog can make a jump Is it possible to determine the mean distance between the two frogs as a function of number of steps and size of the line? Can we establish whether that distance converges towards a stationary value? I'm mainly interested in learning about the methodology to tackle such probability theory questions. So any hints or sources (of similar problems) are welcome.","['random-walk', 'markov-chains', 'probability-theory', 'probabilistic-method']"
2210289,Method to prove limit in $\mathbb{R}^2$,"Given is the following limit $\lim_{(x,y)\to(0,0)}\frac{x^3y}{x^4+y^2}$. Now, it holds that
$0\leq\left\vert\frac{x^3y}{x^4+y^2}\right\vert\leq \frac{x^3y}{y^2}=\left\vert\frac{x^3}{y}\right\vert$. It is clear that $(x,y)\mapsto\frac{x^3}{y}$ is homogeneous on $\mathbb{R^2}\setminus\{\vec0\}$. This implies that $\lim_{(x,y)\to(0,0)}\frac{x^3}{y}=0$. The squeeze lemma would now imply that
$\lim_{(x,y)\to(0,0)}\frac{x^3y}{x^4+y^2}=0$. Where does it go wrong?","['real-analysis', 'calculus', 'analysis']"
2210292,A triple integral problem,"I am having difficulty trying to solve this triple integral problem:
$$\iiint_V \sqrt {x^2+y^2} \sin(z^2)\,dx\,dy\,dz$$
where 
$$V= \left\lbrace (x,y,z)\,\Big|\,\sqrt {x^2+y^2} \le z \le 3\right\rbrace.$$
I am thinking of making $z\,dz$ appear in the integral but cannot figure out how to do it. Could anyone help me?
Thanks in advance!","['multivariable-calculus', 'integration']"
2210295,Volume of the intersection of two cylinders $x^2+y^2=1$ and $y^2+z^2=1$.,"Consider two intersecting cylinders. I know the regular way to do this is: $$ \int_{-1}^{1} \left(2\sqrt{1-2x^2}\right)^2\,dx = \frac{16}{3} $$ This methods integrates the square sides of the solid that you get However, is it just as viable to flip the picture 90° (have the yellow tube going up) and trying to integrate then? You will get discs where the front and back are circular but the interior is square (integrate along the yellow face on the right side image) e.g. $$ \int_{-1}^{1} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} 2\sqrt{1-y^2}\,dy\,dx $$ Should these two integrals be equal or am I doing something wrong?","['multivariable-calculus', 'integration', 'geometry']"
2210300,Distribution of number of non-zero counts of a multinomial distributed set,"The multinomial count distribution for a set of $M$ categories is $P((n_1, \dots,n_M)|N)=\left(\frac{N!}{n_1!\dots n_m!}\prod_{i=1}^Mp_i^{n_i}\right)\delta\left( \sum_{i=1}^M n_i-N\right)\;,$ where category $i=1, \dots, m$ appears $n_i$ times, and the Dirac $\delta$ -function appears to enforce the sum constraint that $\sum_{i=1}^M n_i=N$ . What is the distribution, $P(m)$ , of the number of observed categories , i.e. the number of categories with non-zero counts, $m=\sum_{i=1}^M\mathrm{sgn}[n_i]$ , where $\mathrm{sgn}(x)=1$ for $x>0$ and $0$ for $x=0$ . I couldn't find anything in a quick internet search, but I am still hoping there may be a closed form solution, even for the case where the $p_i$ are all distinct. One approach is to focus instead on the distribution, $P_0(m_0)$ , of zero counts, $m_0$ , from which I think $P(m)=1-P_0(M-m)$ . A specific subset of $m_0$ categories is denoted $\alpha=\{\alpha_1, \dots, \alpha_{m_0}\}$ , where $\alpha_i\in\{1, \dots, M\}$ . There are $\binom{M}{m_0}$ distinct $\alpha$ subsets. For a given $\alpha$ , the probability to obtain one of the $\alpha$ categories in a single count sample is $p_\alpha=\sum_{i=1}^{m_0}p_{\alpha_i}$ . Thus, the probability to obtain something other than the $\alpha$ categories across $N$ samples is $(1-p_\alpha)^N$ . This representation ignores permutations of the $\alpha$ subset. There are $m_0!$ such permutations. If someone knows a solution, please share. In lieu of a solution, I could use help in the combinatorics in the sum of $(1-p_\alpha)^N$ over subsets $\alpha$ and their orderings.","['combinatorics', 'multinomial-coefficients', 'probability-distributions']"
2210359,"Expand $\cos^n (x)$ in terms of $\cos{kx}$, $k=1,\dots,n$.","Is it possible to expand $\cos^n(x)$ as a function of $\cos(kx)$? i.e. if $\cos^n (x)$ can be expanded as the following series $$
\cos^n (x) = \sum_{k=0}^{n} a_k \cos{kx}
$$ then what are the constants $a_k$? If not, is there any way to recover $a_0$ for any $n$?",['trigonometry']
2210367,Is the product of two derivative functions still a derivative function?,"Is the product of two derivative functions still a derivative function? I.e., given two differentiable functions $f$ and $g$, is there always a differentiable function $k$ with $f'g'= k'$  ?","['derivatives', 'calculus']"
2210398,"Why ""A line integral of a scalar field is thus a line integral of a vector field where the vectors are always tangential to the line""?","I was reading about line integrals of a scalar field and line integrals of a vector field on Wikipedia. You can find the links here: line integral for a scalar field and line integral for a vector field . In the second link the sentence: ""A line integral of a scalar field is thus a line integral of a vector field where the vectors are always tangential to the line."" However I don't really understand why this is true. Also, because the scalar field outputs scalars whereas the vector field outputs vectors. How do we explain the sentence above and more in general, what is the relationship between a line integral of a vector field and the line integral of a scalar field?","['vector-fields', 'multivariable-calculus', 'integration', 'general-topology', 'vector-analysis']"
2210409,Prove integral limit exists $\lim\limits_{t\to 0^+}\int\limits_0^1\frac{dx}{(x^4+t^4)^{1/4}}+\ln t$,"Prove integral limit exists $$\lim\limits_{t\to 0^+}\left(\int\limits_0^1\frac{dx}{(x^4+t^4)^{1/4}}+\ln t\right)$$
I try to change variable $u=1/x$ then $\displaystyle\int\limits_0^1\frac{dx}{(x^4+t^4)^{1/4}}=\frac{1}{4}\int\limits_1^\infty\frac{4u^3du}{u^4(1+u^4x^4)^{1/4}}$. But I have no idea to continue.","['improper-integrals', 'definite-integrals', 'limits']"
2210483,Writing a given differential operator in terms of another given differential operator with kernel a subset of the first,"Suppose I have two differential operators $S, T$ with the property that $\ker S \subseteq \ker T$. Is it possible to exploit this property to write $T$ in terms of $S$ in some compact way? I would be happy with an answer just for this specific example: Let $S$ be the Schwartzian derivative, $$S[f] := \frac{f'''}{f'} - \frac{3}{2}\left(\frac{f''}{f'}\right)^2,$$
and $T$ the operator
$$T[f] := \frac{f''''}{f''} - \frac{4}{3} \left(\frac{f'''}{f''}\right)^2 .$$
The kernel of $T$ consists of the rational functions of the form
$$x \mapsto \frac{a_2 x^2 + a_1 x + a_0}{b_1 x + b_0}$$
and the kernel of $S$ famously consists of the fractional linear transformations, i.e., the rational functions of the above form with $a_2 = 0$. How can one write $T[f]$ in terms of $S[f]$ in a way that exploits the containment $\ker S \subset \ker T$?",['ordinary-differential-equations']
2210495,Why are manifolds defined with open sets?,"First a small disclaimer that I have been introduced to manifolds but I am not extremely comfortable with them in the general case yet, however I am taking a course on curves and surfaces (which is almost over) and thus am quite familiar with them (i.e. I know what manifolds are, but I am more used to working with curves and surfaces in $\mathbb R^3$ and $\mathbb R^2$). My question is why is must we restrict ourselves to defining manifolds as homeomorphic to open subsets of $\mathbb R^n$. Allowing us to use closed sets would allow us, for example to cover $S^2$ with a single surface patch, as opposed to two, which seems like an attractive property. I'm going to go on to study more advanced differential geometry very soon and I would love to have a good motivation for this property. Thanks in advance!","['surfaces', 'differential-geometry', 'soft-question']"
2210497,Prove that $\operatorname{SL}_4(2)$ does not contain an element of order $35$,"Given $\operatorname{SL}_4(2)$, whose order is $2^6 \cdot 3^2 \cdot 5 \cdot 7$, I am interested in finding out if this group contains elements of a given order to use this to compute the structure of the subgroups, for example $35$ or $15$. I have done the case $\operatorname{SL}_3(2)$ by explicit computation (made easier by the isomorphism with $\operatorname{PSL}_2(7)$), and I have been trying to find a general technique to solve this problem without much success I have been trying to develop a general technique to solve problems like the one in the title, but without much success. All my successful approaches seem to be ""ad hoc"" for the particular group I am considering in that moment.","['finite-groups', 'group-theory']"
2210541,"How have I computed the integral $\int \sin^{3}(3x)\cos(3x)\,dx$ incorrectly?","$\displaystyle \int \sin^{3}(3x)\cos(3x)\,dx $ $u = 3x  $ $du = 3\,dx  $ $3\displaystyle\int \sin^{3}(u)\cos(u)\,du$ $3\displaystyle\int \sin^{2}(u)\sin(u)\cos(u)\,du$ $3\displaystyle\int (1 - \cos^{2}(u))\sin(u)\cos(u)\,du$ $v = \cos(u)$ $dv = -\sin(u)\,du  $ $3\displaystyle\int (1 - v^{2})(-1)v\,dv$ $ 3\displaystyle\int (-v + v^{3})\,dv$ $ 3\left[-\frac{v^{2}}{2} + \frac{v^{4}}{4}\right]$ $3\left[ -\frac{\cos^{3}{3x}}{2} + \frac{\cos^{4}(3x)}{4}\right] $ $= -3 \frac{\cos^{2}(3x)}{2} + 3\frac{\cos^{4}(3x)}{4} + C$ wolfram states this as incorrect, what have I done wrong?
Thank you","['integration', 'trigonometry', 'calculus']"
2210558,Is this normed linear space a Banach space? [duplicate],This question already has an answer here : Is $L^{p}$ space with alternate norm Banach? (1 answer) Closed 7 years ago . Let $E$ be a measurable set of finite measure and $1 < p_1 < p_2 < \infty$. Consider the linear space $L^{p_2} (E)$ normed by $||.||_{p_1}$ . Is this normed linear space a Banach space?,"['banach-spaces', 'functional-analysis', 'integration', 'lp-spaces', 'measure-theory']"
2210560,"Orders, Partial Orders, Strict Partial Orders, Total Orders, Strict Total Orders, and Strict Orders","As I understand it, partial orders are binary relations that are: Reflexive Anti-symmetric Transitive An example would be $\subseteq$ for sets And if we add totality to this, we get a total (or linear) order, so a total order is Reflexive (this one is implied by totality, so can be removed from definition) Anti-symmetric Transitive Total An example would be $\leq$ for numbers But we also have strict linear orders , which are: Irreflexive (implied by asymmetry) Asymmetric (implied by transitivity + irreflexivity) Transitive Connex (for any $a \not = b$: either $aRb$ or $bRa$) An example would be $<$ for numbers So (first question), is there likewise something called a strict partial order , that would be: Irreflexive (implied by asymmetry) Asymmetric (implied by transitivity + irreflexivity) Transitive an example of which would be $\subset$ for sets? I can't find any reference for a such a term ... But this also leads me to my second and main question.  I do see references that say that 'order' is just short-hand for 'partial order' and that, as such, could be a total order.  But if an 'order' has to be a partial order, then it has to be reflexive, and hence cannot be a strict total order. ... which is weird, because you'd think a strict total order would still be considered some kind of 'order' ... I know there is such a thing as a 'preorder' which is reflexive and transitive, but without it being anti-symmetric or assymmetric, doesn;t really feel like an 'order'. In fact, if symmetric, this would be an equivalence relation, which doesn't feel like it has any 'ordering' at all. Indeed, as the name implies, a 'preorder' seems to fall short of it being an 'order'. OK, but isn't there an obvious candidate for defining an 'order' (whether partial or linear/total) as any binary relation that is: Anti-symmetric Transitive Interestingly, if we want to make this a 'strict order' by changing anti-symmetry into the stronger asymmetry: Asymmetric (and thus also anti-symmetric) Transitive we obtain the 'strict partial order' from earlier, since asymmetry and transitivity imply irreflexivity. But the more general 'order' is not the same as a partial order, as an 'order' would not insist on reflexivity ... nor irreflexivity ... indeed it would merely indicate that there is an 'ordering' between the different objects, i.e. how an object relates to itself a general 'order' wouldn't care about. So, is there anyone that does this? Or are we implicitly doing this (but then: what about the references that say 'order' means 'partial order'?).  Or is there a good reason not to do this?","['order-theory', 'relations', 'discrete-mathematics']"
2210575,Wasserstein-like measure for disconnected spaces,"Does there exist a Wasserstein-like measure for difference between probability distributions, where the space on which the probabilities are defined is not connected? E.g. a distribution over six states; three of these have defined distances with respect to one another (such as [0 1 2;1 0 1;2 1 0]); and the other three as well; but the two sets of three do not have distances defined with respect to one another. Is there some Wasserstein-something-else hybrid that has been explored (or something else) that addresses this situation? thank you!","['information-geometry', 'probability-theory', 'probability-distributions', 'information-theory', 'metric-spaces']"
2210644,"There is no inclusion between $L^p[0,+\infty)$ and $L^q[0,+\infty)$","I want to show that there is no inclusion between $L^p[0,+\infty)$ and $L^q[0,+\infty)$, for any $1\le p <q<+\infty$. I know the intuition behind this: I must find a function which decays very fast but must almost blow up somewhere: that function is in $L^p[0,+\infty)$ but not in $L^q[0,+\infty)$. I also want a fuction which does not blow up at all anywhere but which decays slowly, so that it is in  $L^p[0,+\infty)$ but not in $L^q[0,+\infty)$. However, I am having a hard time finding two such examples.",['functional-analysis']
2210649,"Proof by induction, dont know how to represent range","The question asks for me to prove the following through induction: $1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{2^n} \geq 1 + \frac{n}{2}$ This is my proof thus far: Proving true for $n = 1$
\begin{align*}
1 + \frac{1}{2} &\geq 1 + \frac{1}{2}\\
\end{align*}
Assuming true for $n = k$
\begin{align*}
1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{2^k} \geq 1 + \frac{k}{2}
\end{align*}
Proving true for $n = k + 1$
\begin{align*}
1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{2^k} + \frac{1}{2^{k+1}} &\geq 1 + \frac{k}{2} + \frac{1}{2}\\
(1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{2^k}) + \frac{1}{2^{k+1}} &\geq (1 + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{2^k}) + \frac{1}{2}\\
\frac{1}{2^{k+1}} &\geq \frac{1}{2}\\
\end{align*} I realized at the last statement that something was off, because the last statement contradicts the thing I'm trying to prove. I then realized that it was because the difference between $\frac{1}{2^k}$ and $\frac{1}{2^{k + 1}}$ sets was not simply the addition of $\frac{1}{2^{k + 1}}$, but rather, all numbers between $\frac{1}{2^k}$ and $\frac{1}{2^{k + 1}}$. For example n = 1 is $1 + \frac{1}{2}$, but $n = 2$ is $1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}$. (note the addition of $\frac{1}{3}$.) So how can I represent this range? I believe my proof works except for the fact that $\frac{1}{2^{k + 1}}$ needs to be replaced with something else, I just don't know what that is.","['induction', 'proof-verification', 'discrete-mathematics']"
2210658,Is exponentiation open?,"Already for $2\times 2$ matrices the exponential map is not open . However, the diagonalization trick does not work for algebras of functions. Hence the question Is the map $f\mapsto \exp(f)$ open on the complex space $C[0,1]$?","['general-topology', 'open-map', 'exponential-function', 'banach-algebras']"
2210685,Sums of squares in characteristic 3,"Suppose $K=\mathbb{F}_q$ is a finite field of characteristic 3. Suppose $q > 3$, then is it true that for all $x \in K$ there exists $a,b,c \in K^{\times}$ such that $x = a^2 + b^2 + c^2$ i.e, is every element the sum of 3 non-zero squares? My [wrong] idea is: fix $x \in K$. Note that since $q > 3$, there exists $\gamma \in K$ such that $\gamma^2 = -1$. Case 1, if $x = k^2$ for some $k \in K$ then $x = k^2 + \gamma^2 + 1^2$. Case 2, if $x$ is not a square then I'd like to say that either $x + 1$ or $x-1$ is a square and so $x = k^2 + \gamma^2 + \gamma^2$ or $x = k^2 + 1^2 + 1^2$ for some $k \in K$. But I'm not sure if it's true that, given $x \in K$, one of $x, x+1, x-1$ is a square. Just realised my idea is nonsense since such a $\gamma$ needn't exist. Take $K = \mathbb{F}_{27}$","['finite-fields', 'abstract-algebra', 'additive-combinatorics', 'field-theory']"
2210693,Dimension of the solution of a second order homogenous ODE,"So I have a 2nd order homogenous ODE $$x^2y''-4xy'+6y=0$$ over any interval containing $0$. This is a standard Cauchy-Euler equation with the roots of the auxiliary equation being 2 and 3. Pretty simple, right? But here's the twist. Consider the solution of the form $x^2|x|$. It's twice differentiable over $R$ and it satisfies the ODE. What's more, it's linearly independent from $x^2$ and $x^3$. So the basis contains three elements and so the dimension is 3. What did I miss? I remember my professor teaching us that a linear Nth order ODE has a vector space of dimension $N$.","['ordinary-differential-equations', 'vector-spaces']"
2210702,How to show a space is not reflexive?,"I am studying functional analysis and I was asked to prove that $c_0$ is not reflexive. The point is I have no idea how to prove this. I don't even know how to show that a space is reflexive. What must I do on the practice? I think it is hard to solve this kind of problem just looking for the canonical embedding and trying to discover it is surjective since several times we don't have any idea of which space is the bidual to our space. My question is, what are useful theorems and techniques in order to show a space is/or not is, reflexive? Thanks",['functional-analysis']
2210721,Necas inequality on unit ball,"I want to show the inequality of Necas on the unit ball, knowing that
 I proved it for $\mathbb R^d$ using Fourier transform, here it is: Let $B$ be the unit ball of $\mathbb R^d$. Then there is $C>0$ that  depends      only on $B$ such that: 
     $$\left \| P \right \| _{L_2(B)} \leqslant  C \left \| P \right \| _{\chi(B)}  \quad\forall P \in L_2^{0}(B). $$ with the notation $\\ L_2^{0}(B)=\{P\in L^2(B;\; \int_{B}^{}P(x)dx=0\}$ $\chi(B):=\{P \in H^{-1} ,\nabla P \in (H^{-1}(B))^N\}$ and $\left \| P \right \| _{\chi(B)} = \left \| P \right \|_{H^{-1}(B)}+\left \| \nabla P \right \| _{(H^{-1}(B))^N}$ . There is the idea: let $\eta \in \mathcal D (B)$ be such that $\eta(x) = 1$ for $|x| \leq 1/3$ and $\eta(x) = 0$ for $|x| \geq  1/2$.
Then:
$$\left \| \eta P \right \| _{L_2(B)} = \left \| \eta P \right \| _{L_2(\mathbb R^d)}\leqslant  C \left \| \eta P \right \| _{\chi(\mathbb R^d)},\;\;\forall P \in L_2^{0}(B).$$ My question is: How can I prove that: $\left \| \eta P \right \| _{\chi(\mathbb R^d)}\leqslant\left \| \eta P \right \| _{\chi(B)}$? thank you for your help.","['real-analysis', 'inequality', 'partial-differential-equations', 'sobolev-spaces', 'analysis']"
2210752,"Are $\Bbb R^2\setminus \Bbb Q^2$ and $\Bbb R^2\setminus \Bbb Q^2\cup \{(0,0)\}$ homeomorphic?","As the title says I was wondering (being vaguely inspired by a question from Hatcher asking about the fundamental group of the first space) whether $\Bbb R^2\setminus \Bbb Q^2$ and $\Bbb R^2\setminus \Bbb Q^2\cup \{(0,0)\}$ are homeomorphic. My gut feeling is that they are, they have the same properties as far as connectedness, compactness and separation axioms are concerned, supporting this feeling, but I haven't been able to prove (or disprove) this fact.",['general-topology']
2210754,Find a basis for the set of solutions of the given system of differential equations,"Here is what is given: $$ x' =  \begin{bmatrix}1&0 \\2&1\end{bmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix}$$ As the title says, we need to find a basis for the set of solutions of this differential equation. Here is my attempt: I set up this system $$\begin{cases} x_1' = x_1 \\ x_2' = 2x_1 + x_2 \end{cases}$$ I then assumed these substitutions were made $y = x_1$ and therefore $y' = x_2$ From this, I saw that $y'' = 2y + y'$ . Therefore: $$y'' - y' - 2y = 0$$ I solved this characteristic equation and got these: $$\begin{cases} y_1 = e^{-t} \\ y_2 = e^{2t} \end{cases}$$ So for my basis I got these: $$\hat {x^1}  = \begin{bmatrix}e^{-t}\\-e^{-t}\end{bmatrix}$$ And: $$\hat {x^2} = \begin{bmatrix}e^{2t} \\ 2e^{2t} \end{bmatrix}$$ I then selected $t_0 = 0$ as a convenient value of t and then took the determinant of this matrix: $$\begin{bmatrix} 1 & 1 \\ -1 & 2 \end{bmatrix}$$ The determinant is equal to $3$ which means that $\hat {x^1}$ and $\hat {x^2}$ are linearly independent and therefore form a basis for the given differential equation. However, the answer in the back of my book is different (I can post it if anyone needs it). Is my method the wrong way to approach this problem? Did I make a logical or mathematical error? Any help is appreciated.","['ordinary-differential-equations', 'linear-algebra']"
2210762,Curve shortening flow of a $C^1$ curve,"I am reading something which says that a closed and embedded $C^1$ curve immediately becomes smooth under the curve shortening flow. I am familiar with this result for $C^2$ curves, but was under the impression curve shortening flow isn't necessarily even defined for $C^1$ curves, since the curvature may not be continuous. Could someone perhaps cite this result for $C^1$ curves, or explain what I've misunderstood? Thanks","['mean-curvature-flows', 'plane-curves', 'partial-differential-equations', 'reference-request', 'differential-geometry']"
2210789,Is the pseudoinverse matrix the solution to the least squares problem?,"I'm trying to verify that, given a matrix M, the pseudo-inverse $$M^{+}=(M^TM)^{-1}M^T$$
is the solution for the least squares.. but something went wrong and I can't undestand why... $$e=\frac{1}{2}||y-Mx||=\frac{1}{2}(y-Mx)^T(y-Mx)\\
=\frac{1}{2}(y^Ty-y^TMx-x^TM^Ty+x^TM^TMx)=\\
=\frac{1}{2}(y^Ty-2y^TMx+x^TM^TMx)
$$ so
$$\frac{de}{dx}=\frac{1}{2}(-2y^TM+x^TM^TM)=0\\ x^TM^TM=2y^TM\\M^TMx=2M^Ty\\x=2(M^TM)^{-1}M^Ty$$ why can't I cancel the factor '2'?","['least-squares', 'matrices', 'inverse', 'pseudoinverse', 'linear-algebra']"
2210838,Vector Perpendicular to a Line,"I need to find a vector that is perpendicular to the line $3x-4y=6$. I started with calculating slope of the line which I get $3/4$. A perpendicular line/vector would have a negative reciprocal slope if $-4/3$. I also know that a perpendicular vector has an equation of ac+bd=0 but I wasn't sure if I needed the equation as well. My thought was to find two points on the line $(2,0)$ and $(10,6)$ which form a vector but I didn't know where to go from there.",['geometry']
