question_id,title,body,tags
3828013,A counterexample to Junghenn's Principles of Analysis $4.29$(d),"Problem: The following is Exercise $4.29$ (d) in Hugo Junghenn's Principles of Analysis: Use Jensen's inequality to verify the following for a probability measure $\mu:$ $$\|f\|_1\log(\|f\|_1)\leq\log(\|f\log(f)\|_1\quad\text{where }f>0.$$ I tried the problem for a while and now I think that the claim is incorrect. I have cooked up the following counterexample. Consider the probability space $((0,1),\mathcal B,\mu)$ , where $\mathcal B$ is the Borel $\sigma$ -field of $(0,1)$ and $\mu$ is the Lebesgue measure. Next, let $f(x)=x^2$ for $x\in(0,1)$ . Then $f>0$ everywhere and we have $$\|f\|_1\log(\|f\|_1)=\frac{1}{3}\log\left(\frac{1}{3}\right).$$ On the other hand, using integration by parts and the fact that $x^3\log(x)\to0$ as $x\searrow0$ , we see that $$\|f\log(f)\|_1=\int_0^1 x^2|\log(x^2)|\,dx=2\int_0^1x^2|\log(x)|\,dx=\frac{2}{9}.$$ But then $\log(2/9)<3^{-1}\log(3^{-1})$ , hence the inequality does not hold. However, I do believe that the author meant to ask to prove $$\|f\|_1\log(\|f\|_1)\leq\|f\log(f)\|_1,$$ which is an easy consequence of Jensen's inequality taking the convex function to be $x\log(x).$ My Question: Do you agree with my counterexample above? If not, I would like to ask if I am wrong and the inequality does hold, or if there is another, this time correct, counterexample. Thank you very much for your time and appreciate all the feedback and help.","['integration', 'measure-theory', 'examples-counterexamples', 'real-analysis', 'solution-verification']"
3828030,An application of Fubini's theorem and cake layer integration.,"This problem is motivated by recent reemergence of interest in the well known identity $$
\begin{align}
\int |f|^p\,d\mu = \int^\infty_0 p\,t^{p-1}\,\mu(|f|>t)\,dt\tag{0}\label{fubini0}
\end{align}
$$ and a the so called cake layer integration. I am posting this as a problem because of its multiple applications in analysis, statistics and probability. Suppose $\nu$ is a positive Radon measure on $[0,\infty)$ . Let $(X,\mathscr{F},\mu)$ be a measure space. If $f$ is a nonnegative $\mathscr{F}$ -measurable function whose carrier $\{f\neq0\}$ is $\mu$ $\sigma$ -finite. Show that $$
\begin{align}
\int_X\nu([0,f(x))\,\mu(dx) = \int^\infty_0\mu(\{f>t\})\,\nu(dt)\tag{1}\label{fubini1}
\end{align}
$$ In particular, if $\phi$ is absolutely continuous on any contact subintervals of $[0,\infty)$ , $\phi(0)=0$ and $\nu(dt)=\phi'(t)\,dt$ , $$
\begin{align}
\int_X (\phi\circ f)\,d\mu = \int^\infty_0 \mu(\{f>t\})\,\phi'(t)\,dt\tag{3}\label{fubini2}
\end{align}
$$ The most common example: $\phi(t)=t^p$ which leads to $\eqref{fubini0}$ . This case has been asked many times, for example here and more recently here , A related question that deals with $\eqref{fubini2}$ is here .","['measure-theory', 'lebesgue-integral']"
3828034,Taylor polynomial with remainder for solving limit,"I was asked to solve the following limit using the nth Taylor polynomial with remainder. $$
\displaystyle{\lim_{x \to 0}}\frac{\log{(1+x^2)}}{2x}.
$$ I couldn't find the remainder term because I couldn't generalize a formula for the nth derivative so I use the infinite series expansion $$
-\sum_{k=1}^{\infty}\frac{(-1)^k(x^{2})^k}{k}.
$$ What would be the way to do it with the remainder?","['limits', 'calculus', 'taylor-expansion', 'sequences-and-series']"
3828143,relation of supp of form $\omega$ and $d\omega$,"Given $n$ dimension smooth manifold,and smooth $k$ (where $k\le n-1$ ) form $\omega$ . Assume we know $\text{supp}\ \omega \subset U$ where $U$ is open subset of $M$ Can we say anything about support for $\omega$ and $d\omega$ ,for example the proporsitions below is true or false: $\text{supp} (d\omega) = \text{supp}(\omega)$ $\text{supp}(d\omega) \subset \text{supp}(\omega)$ (I try to show for example when $\omega$ is 0-form,and $\text{supp}(d\omega)\subset \text{supp}\omega\ $ i.e. denote $Z(\omega) = \{p:\omega_p \ne 0\}$ it's sufficient to show $Z(d\omega) \subset Z(\omega)$ but we can't say if $\omega_p =0$ then $(d\omega)_p = 0$ ?since $(d\omega)_p(X_p)$ is determined by the neighborhood value of $\omega$ around $p$ not only a single point?","['differential-forms', 'differential-geometry']"
3828168,"Show that $f(x,y) = \sin( x )|y|$ is differentible at $(0,0)$.","Show that $$f(x,y) = \sin( x )|y|$$ is differentible at $(0,0)$ . Trying to find the partial derivatives, I found out that $$f'_y = \sin(x)\frac{|y|}{y}$$ is not defined at $(0,0)$ . However, if the partial derivative does not exist then we cannot say $f$ is differentible since the function is differentible at some point iff all partial derivatives exist and are continuous. Any help is appreciated.","['multivariable-calculus', 'calculus', 'real-analysis']"
3828182,Find stopping time of train given the speed with and without stopping,"Without stopping for passengers, a train travels a certain distance with an average speed of 60 km/h, and when it stops, it covers the same distance with an average speed of 40 km/h. On average, how many minutes per hour does the train stop during the journey? My approach: average speed = total distance/ total time; Here it is given that the first train's speed is $60$ km/h. $\therefore 60 = \frac{x}{t_1}$ where $x$ is the total distance and $t_1$ is total time. Now average speed is 40 km/hr. $\therefore 40 = \frac{x}{t_2}$ where $x$ is the total distance and $t_2$ is total time. Now solving this I get $3t_1= 2t_2$ but I don't understand how to approach the solution from here.","['word-problem', 'algebra-precalculus']"
3828212,A Hard Number Theory Problem $f(n+1)=f(n)+2^{f(n)}$,"Define a function $f:\mathbb N\to\mathbb N\quad$ by $\begin{cases}f(1)=1\\f(n+1)=f(n)+2^{f(n)}\ \text{ for every integer }n\end{cases}$ Prove that $f(1),f(2),\cdots,f(3^{2013})$ leave distinct remainders when divided by $3^{2013}$ I got this problem from a telegram group posted by someone who did not reveal the source of the problem. My approach : After seeing this problem I tried to make a list of values but coudn't proceed for much longer as soon it reaches higher for large values of 2^n . But one thing is clear that this function is clearly increasing for positive. Finding the closed form for the recurrence seems not possible. So after this I dont have any ideas. I request a help in this problem.",['number-theory']
3828223,Is the group of translations on a spherical topology tied to the group of rotations of that sphere?,"Is the group of translations on a spherical topology tied to the group of rotations of that sphere? More concretely, suppose we define some set of orthonormal basis $e^{i}$ where i runs from 1 to n on a sphere $S^{n}$ (yes, I realize n=1, 3, and 7 are the only parellizable cases). For example suppose we consider $S^{3}$ , we can then translate some point (consider perhaps a vector) around on the three-sphere. However, we could have just rotated the sphere itself and achieved the same thing. Now I get that this all seems rather evident but I'm interested in something a bit more. We can say that the principle bundle of (oriented now) orthonormal frames is $P_{OF}(S^{3})=S^{3}\times SO(4)$ (which is a trivial bundle). Due to a special isomorphism we know $S^{3}=SU(2)$ , so we have $P_{OF}(S^{3})=SU(2)\times SO(4)$ . Back to our orthonormal basis, each $e^{i}$ can be chosen to identify with a generator of the Lie algebra $su(2)$ . Of course the lie algebra of $su(2)$ is the same as that of $so(3)$ (the former being the double cover of the latter). Contrast this with the topology $\mathbb{R}^{3}$ , whose principle oriented orthonormal frame bundle is $P_{OF}(\mathbb{R}^{3})=\mathbb{R}^{3}\times SO(3)$ . In this latter case, the two (frame translations and rotations) are entirely divorced from one another, yet in the former a translation on the three sphere is representable by rotations of the three-sphere. I find myself wondering if the two are “soldered” in some fashion? It seems like a translation on the surface of the sphere is equivalent to a rotation in the fiber of the frame bundle of that sphere. For instance, if we consider the 1-forms dual to our basis, we call these the soldering forms. Are these then tied to our rotations in the fibers? Put another way, are the horizontal and vertical sub-bundles tied to one another? can someone please elaborate?","['principal-bundles', 'lie-groups', 'differential-geometry']"
3828225,"Prove all finite disjoint unions of intervals in a collection of all $(a, b],(-\infty, b]$or $(a,\infty)$ ,$-\infty<a<b<\infty$ forms a field","Define $\mathcal{C}_{\mathcal{I}} \equiv\{\text { all intervals }(a, b],(-\infty, b], \text { or }(a, \infty):-\infty<a<b<\infty\}$ $\mathcal{C}_{F} \equiv\left\{\right.$ all finite disjoint unions of intervals in $\left.\mathcal{C}_{I}\right\}$ . Show that $\mathcal{C}_{F}$ is a field. I didn't study any mathematical courses rigorously at the college level due to my curriculum design so so it is very challenging to study probability course founded on measure theory. I tried to prove this statement using the definition of a set but I am not sure if my proof is correct. Here's my proof: $ \mathcal{C}_F$ is the set of all finite disjoint unions of intervals, that is $$
\left(a_{1}, b_{1}\right] \cup \cdots \cup\left(a_{n}, b_{n}\right]
$$ $\emptyset\in \mathcal{C}_F$ because it is the disjoint zero interval in $ \mathcal{C}_I$ . $A\equiv \bigcup^\infty (a_n,b_n]$ where $b_i\leq a_{i+1},i\in N$ , allowing for $a=-\infty,b=\infty$ , it is easily seen $\Omega \in \mathcal{C}_F$ . Suppose $A'=(a,b]$ ,then $A'^c=(-\infty,a]\bigcup(b,\infty)$ , $(-\infty,a] = \bigcup^\infty (a_n,b_n], b_1=a,b_{i+1}=a_i$ , $(b,\infty)$ can also be expressed as the union of disjoint finite interval in similar fashion. if $A_1,...A_n$ are finite disjoint unions of interval, let $A'_1=A_1,A'_2=A_2\backslash A_1, .... A_n=A_n\backslash \cup^{n-1}A'_n$ , $A'_i$ can be still expressed as the union of disjoint finite intervals, and by constructions, $\cup^\infty A_n=\cup^\infty A'_n \in \mathcal{C_F}$ . I messed up the definition of a field and a definition of a $\sigma$ -field, as pointed by @YuvalFilmus. Following what was suggested I changed my proof: Suppose $A=(a,b]$ ,then $A^c=(-\infty,a]\bigcup(b,\infty)$ . $(-\infty,a] = \bigcup(a_n,b_n],n\in \mathbb{N}$ , where $b_1=a,b_{i+1}=a_i$ , $(b,\infty)= \bigcup(a_n,b_n],n\in \mathbb{N}$ , where $a_1=b,a_{i+1}=b_i$ . Therefore, $A^c\in \mathcal{C_F}$ . Let $A,B \in \mathcal{C_F}$ , 1) $A \cap B=\emptyset, A\cup B\in \mathcal{C_F}$ ; 2) $A\cap B=A$ or $B, A \cup B\in \mathcal{C_F}$ ; 3) Let $A=(a_1,b_1], B=(a_2,b_2]$ , if $ a_1<a_2<b_1<b_2$ , then $A\cup B=(a_1,a_2]\cup (a_2,b_1] \cup (b_1,b_2]\in \mathcal{C_F}$ ; similarly, if $a_2<a_1<b_2<b_1$ , $A \cup B\in \mathcal{C_F}$ . Since $ \mathcal{C_F}$ is closed under finite union, it must also be closed under finite interval by DeMorgan's Law, hence $A \cap A^c=\emptyset\in \mathcal{C_F}$ . $\Omega=\emptyset^c\in \mathcal{C_F}$ . Two additional questions: If indeed my proof is correct are there ways to prove the statement more concisely? To my knowledge $\emptyset$ is always in a set but why is it the case? Is it by definition? When I prove $ \mathcal{C_F}$ is a field I think of the infinite many unions are still in $ \mathcal{C_F}$ and it is very convincing to me. But being a field means the infinite intersections are also in the field, that implies that $ \mathcal{C_F}$ also includes every single point $\{x\}, x\in\mathbb{R}$ . But I don't quite get how can a single point be in $ \mathcal{C_F}$ ? Could someone please express a point as a finite disjoint union of interval?","['elementary-set-theory', 'measure-theory', 'probability-theory']"
3828253,contact of hypersurface and curve,"Could anyone explain the following fact in detail? Suppose $f:\mathbb{R}^n\rightarrow\mathbb{R}$ is smooth and $\nabla f\neq 0$ on the level set $M = \{f=0\}$ , so that $M$ is a smooth hypersurface. A smooth regular curve $\phi:(-\epsilon,\epsilon)\rightarrow\mathbb{R}^n$ has m-order contact with the hypersurface $M$ at $\phi(0) \iff (f\circ \phi)^{(i)}(0) = 0, 0\leq i \leq m$ . Currently, I am a little confused about how to choose the curve $\psi$ in M s.t. $$\phi^{(i)}(0) = \psi^{(i)}(0), 0\leq i\leq m$$ in $\impliedby$ case.","['curves', 'submanifold', 'differential-geometry']"
3828287,Is every finite group the outer automorphism group of a finite group?,"This question is inspired by this recent question, which essentially asks if we can realise every finite group $Q$ as the automorphism group of some group $G_Q$ . The answer is well-known to be no , with the counter-examples being cyclic groups of odd order. On the other hand, it is a theorem of Matumoto that every group $Q$ is the outer automorphism group of some group $G_Q$ [1]. It seems to be a research theme to place restrictions on the groups involved. For example, Bumagin and Wise proved that if we restrict $Q$ to be countable then we may take $G_Q$ to be finitely generated [2], and more recently Logan proved that if we restrict $Q$ to be finitely generated and residually finite group then we may take $G_Q$ to be residually finite [3, Corollary D] (this paper also cites quite a few other papers which play this game). However, all the results I have found always produce infinite groups $G_Q$ , even when the ""input"" groups $Q$ are finite. For example, Matumoto's groups $G_Q$ are fundamental groups of graphs of groups (so are always infinite), Bumagin and Wise use a variant of Rips' construction (so (as $Q$ is finite) their groups $G_Q$ have finite index in metric small cancellation groups, so are infinite), and Logan's groups $G_Q$ are HNN-extensions of hyperbolic triangle groups (so again are infinite). So we have a question: Does every finite group $Q$ occur as the outer automorphism group of some finite group $G_Q$ ? [1] Matumoto, Takao. ""Any group is represented by an outerautomorphism group."" Hiroshima Mathematical Journal 19.1 (1989): 209-219. ( Project Euclid ) [2] Bumagin, Inna, and Daniel T. Wise. ""Every group is an outer automorphism group of a finitely generated group."" Journal of Pure and Applied Algebra 200.1-2 (2005): 137-147. ( doi ) [3] Logan, Alan D. ""Every group is the outer automorphism group of an HNN-extension of a fixed triangle group."" Advances in Mathematics 353 (2019): 116-152. ( doi , arXiv )",['group-theory']
3828300,For which $f(x)$ does the solution exist for an arbitrary $c>0$?,"We have the problem $$y''+4y=f(x), \ y(0)=0, y(c \pi )=0$$ with $c>0$ and $f(x)$ an arbitrary smooth function. For which values of the parameter $c$ has the problem always an unique solution? For which $f(x)$ does the solution exist for an arbitrary $c>0$ ? For the first part we have to check when the corresponding homogeneous problem has only the trivial solution. The homogeneous problem is $y''+4y=0, \ y(0)=0, y(c \pi )=0$ . The general solution is $y(x)=a\cos (2x)+b\sin (2x)$ . From $y(0)=0$ we get $a=0$ . So we get $y(x)=b\sin (2x)$ . From $y(c \pi )=0$ we get $b\sin (2c \pi)=0$ . To get the trivial solution we have to get $b=0$ and so $\sin (2c \pi)$ must be different from $0$ , so we have $$\sin (2c \pi)\neq 0 \iff 2c\pi \neq n\pi, \ n \in \mathbb{N} \ \iff c\neq \frac{n}{2}, \ n\in \mathbb{N}$$ Is that correct? Could you give me a hint for the second part?",['ordinary-differential-equations']
3828410,Trouble understanding Weyl's unitary trick,"Given a representation of a finite group: $\rho : G \to \text{GL}(V)$ , there exists a unitary representation $\tau$ which is isomorphic to $\rho$ . I came across Weyl's trick, where you redefine the inner product as follows $$\langle v,w \rangle = \frac1{|G|}\sum_{g \in G} \langle \rho(g)v, \rho(g)w \rangle_0,$$ where $\langle\ ,\rangle_0$ is the usual inner product. I see the idea of this trick since this new inner product is preserved under $\rho$ i.e. $\langle v,w \rangle = \langle \rho(g')v,\rho(g')w \rangle$ for all $g'\in G$ . I am not familiar with the idea of changing the definition of the inner product to achieve unitarity. As I understand Weyl's trick, the matrices in the set $\{\rho(g):g\in G\}$ and $\{\tau(g):g\in G\}$ are actually identical but the inner product definition is what makes the $\tau(g)$ matrices unitary? Is there a way to translate this back to the usual picture where I use the standard inner product (and therefore a fixed definition of unitarity) and the matrices of the different representations are not identical? Sorry if there is some vagueness/incorrectness in the question - I am new to group theory.","['unitary-matrices', 'representation-theory', 'group-theory', 'linear-algebra']"
3828420,Trouble in using finite difference method to solve a boundary value problem (attempts and pictures included),"I want to numerically solve (using FDM) $$-y''(t)+2y'(t)=1, t\in (0,1)\\y(0)=1, y(1)=3$$ First, I check with symbolab that the analytic solution would be $1-\frac{3}{2\left(-1+e^2\right)}+\frac{3}{2\left(-1+e^2\right)}e^{2t}+\frac{t}{2}$ : $\frac{d}{dt}\left(1-\frac{3}{2\left(-1+e^2\right)}+\frac{3}{2\left(-1+e^2\right)}e^{2t}+\frac{t}{2}\right) = \frac{3}{e^2-1}e^{2t}+\frac{1}{2}$ , and $\frac{d^2}{dt^2}\left(1-\frac{3}{2\left(-1+e^2\right)}+\frac{3}{2\left(-1+e^2\right)}e^{2t}+\frac{t}{2}\right) = \frac{6}{e^2-1}e^{2t}$ , and we can easily check that the boundary conditions are satisfied. Now, I attempt this problem numerically:
Using the centered difference approximations for the first and second derivative, I get two equations: $D^2y_j = (y_{j-1}-2y_j+y_{j+1})/h^2\\Dy_j = (y_{j-1}+y_{j+1})/2h$ . I use the second order equation of the problem to derive the relation $(\frac{-1}{h^2} + \frac{1}{h})y_{j-1}+\frac{2}{h^2}y_j+(\frac{-1}{h^2} + \frac{1}{h})y_{j+1}$ . For example, if we take a mesh size of $.25$ , we would have to solve 3 unknowns at $.25, .5, .75$ , and our matrix equation would look like $$\begin{pmatrix}32&-12&0\\ -12&32&-12\\ 0&-12&32\end{pmatrix}v = \begin{pmatrix}1+12\\ \:\:1\\ \:\:1+12\cdot 3\end{pmatrix} = \begin{pmatrix}13\\ 1\\ 37\end{pmatrix}\\v= \begin{pmatrix}y_{.25}\\ \:\:y_{.5}\\ y_{.75}\end{pmatrix}$$ But if we solve this $\begin{pmatrix}y_{.25}\\ \:\:y_{.5}\\ y_{.75}\end{pmatrix} = \begin{pmatrix}\frac{67}{92}\\ \frac{79}{92}\\ \frac{34}{23}\end{pmatrix}$ , and plot it, it looks off from the analytic solution. One would think that increasing the number of nodes between 0 and 1 would be better, but increasing the unknown to 500 only made it worse: Now, I may have made the program incorrectly, but the matrix vector equations seem to come out fine. I will upload the code if anyone is interested, but I think that my problem comes from a misunderstanding of the algorithm of the finite difference method. Any help would be lovely.","['ordinary-differential-equations', 'matrices', 'finite-element-method', 'numerical-methods', 'finite-differences']"
3828453,$	\lim_{x \to 0}x \tan (xa+ \arctan \frac{b}{x})$,"I have to evaluate the following limit $$	\lim_{x \to  0}x \tan (xa+ \arctan \frac{b}{x})$$ I tried to divide tan in $\frac{sin}{cos}$ or with Hopital but I can't understand where I'm making mistakes.
The final result is: $\frac{b}{1-ab}$ if $ab \ne 1$ $- \infty$ if $ab=1$ and $a>0$ $+ \infty$ if $ab=1$ and $a<0$",['limits']
3828486,Prove that union of disjoint finite sets is finite,"Let $A$ and $B$ be two disjoint sets which are finite. I am proving that $A\cup B$ is also finite. If either $A$ or $B$ is an empty set $\varnothing$ , then $A \cup B$ is either $A$ or $B$ . And so $A\cup B$ is a finite set. So, we will assume that $A \ne \varnothing$ and $B \ne \varnothing$ . Since $A$ and $B$ are finite sets, there are bijections $f : A \to I_m$ and $g : B \to I_n$ . Where, $I_m = \{ i \in \mathbb{Z}^+ \, |\, i \leq m \} $ and $I_n = \{ i \in \mathbb{Z}^+ \, | \,i \leq n \} $ . Now, I need to prove that $A\cup B$ is also finite. So, I need to come up a bijection from $A\cup B$ to $I_{m+n}$ . Now, consider the following binary relation $h$ from $A\cup B$ to $I_{m+n}$ . $$  (x, f(x)) \in h  \, \text{ if } x \in A \\
    (x, m + g(x)) \in h \, \text{ if } x \in B $$ Now, I will prove that this is a function. Let $x \in A \cup B$ be arbitrary. Since they are disjoint, this means that we have two cases. If $x \in A$ , we have some $1 \leqslant k_1 \leqslant m$ in $I_m$ such that $f(x) = k_1$ . And , if $x \in B$ , we have some $1 \leqslant k_2 \leqslant n$ in $I_n$ such that $g(x) = k_2$ . So, $m + g(x) = m + k_2$ . Now, we have $ k_1 \in I_{m+n}$ and $m + k_2 \in I_{m+n}$ . So, it follows that if $x \in A$ , then $(x , k_1) \in h$ and if $x \in B$ , then $m + k_2 \in h$ . So, we proved the existence of some element $y$ in $I_{m+n}$ such that $(x,y) \in h$ . Now, suppose there are two such elements $y_1$ and $y_2$ . So, we have $(x,y_1) \in h$ and $(x,y_2) \in h$ . Now, here if $x \in A$ , then $y_1 = f(x)$ and $y_2 = f(x)$ . It follows that $y_1 = y_2$ . If, $x \in B$ , then $y_1 = m + g(x)$ and $y_2 = m + g(x)$ . Again, it follows that $y_1 = y_2$ . So, now we proved the uniqueness. So, this proves that $h$ is a function. So, we have $$ h: A\cup B \to I_{m+n} $$ $$ h(x) = 
\begin{cases} 
f(x)  & \text{if $x \in A$} \\
m + g(x) & \text{if $x \in B$} 
\end{cases}
$$ Now, the task is to prove that this function is a bijection. Consider $h(x_1) = h(x_2)$ . Now, there are three cases to consider. Case 1) $x_1, x_2 \in A$ In this case, we have $f(x_1) = f(x_2)$ and since $f$ is a bijection, we have $x_1 = x_2$ . Case 2) $x_1 \in A$ and $x_2 \in B$ In this case, $f(x_1) = m + g(x_2)$ . But $1 \leqslant f(x_1) \leqslant m$ and $1 \leqslant g(x_2) \leqslant n$ . It follows that $m < m + 1 \leqslant m + g(x_2) \leqslant m+n$ . This means that $f(x_1) \leqslant m < m + g(x_2) = f(x_1)$ . This is $f(x_1) < f(x_1)$ . This is a contradiction. So, this case is never possible. Case 3) $x_1, x_2 \in B$ Here, we have $m + g(x_1) = m + g(x_2)$ . Cancelling $m$ and noting that $g$ is a bijection, we get that $x_1 = x_2$ . So, it is proven that $h: A\cup B \to I_{m+n}$ is a one to one function. Now, we will prove that its also an onto function. Let $k \in I_{m+n}$ be some arbitrary element. $ 1 \leqslant k \leqslant m+n $ . We will consider two cases here. Case 1) $ 1 \leqslant k \leqslant m $ Here $k \in I_m$ . Since $f$ is an onto function, we have some $x \in A$ such that $f(x) = k$ . So, we have $f(x) \in I_{m+n}$ and $ x \in A \cup B$ . Using the definition of function $h$ , we have $h(x) = f(x) = k$ . So, there is some element $x \in A \cup B$ such that $h(x) = k$ . Case 2) $m + 1 \leqslant k \leqslant m+n$ It follows that $ 1 \leqslant k-m \leqslant n$ . So, $ k-m \in I_n$ and since function $g$ is an onto function, there is some $x \in B$ such that $g(x) = k-m $ . So, $ m + g(x) = k $ . Since $ k \in I_{m+n}$ , we have $ m + g(x) \in I_{m+n}$ and since $x \in B$ , we have $x \in A \cup B$ . So using the definition of function $h$ , we have $h(x) = k$ . So, in both cases, it follows that there is some element $y$ in $A\cup B$ such that $h(x) = y$ . Which means that function $h: A\cup B \to I_{m+n}$ is an onto function. This means that the function $h: A\cup B \to I_{m+n}$ is a bijection. We have $ A\cup B \thicksim I_{m+n}$ and so $A \cup B$ is a finite set. Is this a good proof ? Thanks","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3828500,Very fundamental doubt in integration,"Let $f$ be a function of two variables $(x, y)$ . Now I want to integrate $\frac{df(x,y)}{dx}$ with respect to x, i.e $$\int_a^b \frac{df(x,y)}{dx} dx$$ If y isn't a function of x then this is straight forward and the answer is $$\int_a^b \frac{\partial f(x,y)}{\partial x} dx = f(b,y)-f(a,y)$$ But if $y$ is a function of $x$ , then $$\frac{df(x,y)}{dx}= \frac{\partial f(x,y)}{\partial x} + \frac{\partial f(x,y)}{\partial y} \frac{dy}{dx}$$ hence, $$\int_a^b \frac{df(x,y)}{dx} dx=  \int_a^b \frac{\partial f(x,y)}{\partial x}dx +\int_a^b \frac{\partial f(x,y)}{\partial y} \frac{dy}{dx}dx$$ $$\int_a^b \frac{df(x,y)}{dx} dx= f(b,y)-f(a,y)+ \int_{y(a)}^{y(b)} \frac{\partial f(x,y)}{\partial y} dy$$ $$\int_a^b \frac{df(x,y)}{dx} dx= f(b,y)-f(a,y)+ f(x,y(b))-f(x,y(a))$$ After this step it has become very confusing as RHS shouldn't come out to be a function of $x$ and also if instead of solving like this I simply consider that $$\int_a^b \frac{df(x,y)}{dx} dx = \int_{f(a,y(a))}^{f(b,y(b))}df(x,y)$$ then the answer comes out to be totally different. Please tell me where I am wrong. This has made me embarrass a lot.","['integration', 'multivariable-calculus', 'definite-integrals']"
3828544,Rate of convergence for a sequence (Preferably without Taylor series),"I am trying to solve the following problem: Knowing that the sequence $(a_{n})$ with: $$a_{n+1}=\frac{1}{2}(a_{n}+\frac{3}{a_{n}})$$ converges to $\sqrt{3}$ , find it's rate of convergence. After doing some searching, I found this formula from wikipedia : $$\lim\limits_{n \to \infty} \frac{|a_{n+1}-L|}{|a_{n}-L|} = μ$$ And I think that our L is $\sqrt{3}$ .
Do I need to find the value of $a_{n}$ to find the rate of convergence (μ)? And how do I find $a_{n}$ ? UPDATE: I can simply use the formula above but I need to make my limit approach to $\sqrt{3}$ because we have $a_{n} \to \sqrt{3}$ : $$\lim\limits_{x \to \sqrt{3}} \frac{|\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}|}{|x-\sqrt{3}|}$$ But my problem is that this limit is resulting in a indeterminate form because of $\frac{0}{0}$ How can I solve this limit without expanding series? UPDATE 2 - ANSWER: Using @ user 's approach we can write our limit as: $$\lim\limits_{x \to \sqrt{3}} \frac{\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}}{x-\sqrt{3}}=\frac{x^2-2\sqrt 3x+3}{2x(x-\sqrt{3})}=\frac{(x-\sqrt{3})^2}{2x(x-\sqrt{3})}=\frac{x-\sqrt{3}}{2x}\to 0$$ and then the sequence converges Q-superlinearly to $\sqrt 3$ . Look at here .","['limits', 'convergence-divergence', 'sequences-and-series']"
3828590,What is a 100th percentile?,"I am really confused behind the mathematical meaning of a 100th percentile. What does that mean mathematically? Does it mean that a data point in a sample space is greater in some metric and that is also greater than itself? That makes no sense. AFAIK, there can be no such thing as the 100th percentile, because the maximum data point considered is still part of the sample space. For example, when a student scores the highest marks, he/she can be the 99.999th percentile, but what is the meaning of 100th percentile ?",['statistics']
3828663,"Showing that a topological space is connected iff for every two points, there is a connected subspace that contains them.","Here is my attempted proof of the proposition provided below. My question is: is this proof attempt valid, and furthermore, can it be improved? Proposition. A topological space $X$ is connected iff for any two points $x, y \in X$ , there exists a connected subspace $U \subseteq X$ such that $x \in U$ and $y \in U$ . I will take the following fact as given. Lemma 1 . A topological space $X$ is connected iff it has no non-trivial clopen subsets i.e. a clopen subset of $X$ is either empty $\emptyset$ or $X$ . Proof attempt. The forwards direction is trivial: given any connected space $X$ , $X$ is a connected subspace of itself that contains any two points $x, y \in X$ . For the converse, let $X$ be a space such that for any $x, y \in X$ , there exists a connected subspace $U \subseteq X$ such that $x \in U$ and $y \in U$ . We need to show that $X$ is connected. By Lemma 1 , it suffices to show that no subset of $X$ is non-trivial and clopen. Suppose towards a contradiction that there exists some $A \subseteq X$ that is non-trivial and clopen. As $A$ is non-trivial, both $A$ and $A^c$ must be inhabited i.e. there must exist some \begin{equation*}
  x \in A \qquad \text{and} \qquad y \in A^c.
\end{equation*} Notice that there must exist a connected subspace $U \subseteq X$ such that $x \in U$ and $y \in U$ . As $U$ is a connected subspace, it must have no non-trivial clopen subsets (by Lemma 1 ). Consider, however, the set $A \cap U$ which must be clopen (in the subspace topology): it must be open as it is the intersection of an open set of $X$ with $U$ and it must be closed as its complement (with respect to $U$ ), $A^c \cap U$ , is open as $A^c$ is open. We know that $A \cap U$ is also a non-trivial subset of $U$ since $x \in A \cap U$ (as $x \in A$ and $x \in U$ ) and $y \notin A \cap U$ (as $y \in A^c$ ).","['general-topology', 'solution-verification']"
3828686,"$23$ odd subsets of $\{1,2,...26\}$ such that intersection of every two is even. Can we find another odd set...","We are given a list of 23 subsets, each with an odd number of elements such that any two subsets have an even number of elements in common. There are 26 elements in the set. Prove that you can add a new subset with an odd number of elements that has even number of elements with each of the other subsets. Proof: Let $\vec{v}_1,\vec{v}_2,...\vec{v}_{23}$ be a characteristic (indicator) vectors for given sets. So we have 23 vectors in $\mathbb{Z}_2^{26}$ such that $\vec{v}_i^2 =1$ and $\vec{v}_i\cdot \vec{v}_j =0$ for each $i\ne j$ . Clearly they are independent so $V:=$ span $\{\vec{v}_1,\vec{v}_2,...\vec{v}_{23}\}$ has dimension $23$ . Let $\{\vec{u}_1,\vec{u}_2,\vec{u}_3\}$ be a basis for $V^{\bot}$ . Then clearly $u_i\cdot v_j = 0$ and we have to prove that for at least one $i$ we have $u^2_i=1$ . Suppose we have $u^2_i=0$ for each $i$ . Let $\vec{1} = (1,1,. . . 1)$ then we have some scalars $m_1, m_2,. . . m_{23}, n_1, n_2, n_3$ such that $$\vec{1} = m_1\vec{v}_1 + m_2\vec{v}_2 + . . . + n_3\vec{u}_3$$ By multiplying this equation with each $\vec{v}_i$ we get $m_1=m_2 = ...= m_{23}=1$ , and if we multiply it with $\vec{1} $ we get $$ 0 = 1+1+...+1+n_1\cdot 0 + n_2\cdot 0 +n_3\cdot 0 = 1$$ wich is a nosense, so we are done. Is this proof correct?","['contest-math', 'solution-verification', 'linear-algebra', 'combinatorics']"
3828763,"Clarification of relation between $SL(2,\mathbb{R})$ and $Sp(2,\mathbb{R})$","I have been reading up about the homomorphism between $SO^+(2,1)$ (i.e. the proper-orthochronus Lorentz group in 2+1 dimensions), and $SL(2,\mathbb{R})$ . As part of this, I was further introduced to the symplectic group $Sp(2,\mathbb{R})$ , and this is where my confusion arises. From what I've read, it is claimed that $Sp(2,\mathbb{R})$ and $SL(2,\mathbb{R})$ are isomorphic, i.e. $Sp(2,\mathbb{R})\cong SL(2,\mathbb{R})$ , however, as fair as I can tell, from their group structures, they seem to be not just isomorphic, but identical . By this, I mean that the isomorphism between them seems to be trivial. Am I missing something here, or is it just a quirk of the $n=2$ case, that the two groups are trivially related? If I am correct, then they essentially seem to be the same group in this case (rather than there existing a one-to-one mapping between them), and so why do people even distinguish them? If I am incorrect, can someone please enlighten me, and also detail the actual isomorphism? To caveat this question, I am approaching this from a physicist's perspective, so apologies for any lack of mathematical rigour, and/or discrepancies in notation/conventions.","['group-homomorphism', 'group-theory', 'group-isomorphism', 'lie-groups']"
3828767,Question about sets (Rings in probability theory),"Let $\Omega$ be our sample space, we define a ring as $R\subset P(\Omega)$ verifying: $R\neq\emptyset$ , $R$ is closed under finite intersections, and closed under symmetric difference. Prove that $R$ is a ring iff $R$ is closed under finite intersections, finite unions and $\emptyset\in R$ My try: $\Rightarrow$ We just need to show that $\emptyset\in R$ and $R$ is closed under finite unions. Let $A\in R$ then $A\triangle A=\emptyset\in R$ Then $A\cup B = A\triangle (B\backslash A)\in R$ $\Leftarrow$ I'm struggling with this implication (Let me know if the post title fits my problem)","['elementary-set-theory', 'probability']"
3828775,"The ""elements"" of a real number","This question is essentially a paraphrase of a separate (deleted) question, which talks about a comment by Asaf Karagila about the ""elements of $\pi$ "". I'm aware of how natural numbers can be viewed as sets , so for example $3$ may be viewed as the set $\{\:\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\}$ , so has elements $\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}$ . This seems pretty concrete and natural. I can see that we can adapt this to deal with the integers, by for example adding in a second empty set as a ""marker"" element (so $-3$ corresponds to $\{\:\emptyset, \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\}$ ). I can also see that we can adapt this ""marker"" idea to deal with the rational numbers (which are pairs of integers, and we ""mark"" the top one and the bottom one in a certain way). However, I am already getting nervous here as this seems much more synthetic than how we viewed the natural numbers. Anyway. It not clear to me how a number like $\pi$ or $e$ can have elements. One way might be to view these numbers as limits of sequences, and so as lists of rational numbers. However, this seems suspicious as these numbers are limits of multiples sequences, so this does not give me a canonical set which represents these numbers, but instead a family of sets. Is this OK, or is my reasoning broken? So what I want to ask is: What are the elements of $e$ ? Or, more subtly, does this question make sense, or should we remove the word ""the"" from it?",['elementary-set-theory']
3828808,"Elliptic curve: Type of reduction mod 2, how can I show the curve has a cusp?","I want to know what type of reduction the curve $E : y^2 = x^3 + 7x$ has at $p=2$ . From online search, I obtain that it has additive/cuspidal reduction. But this disagrees with my own computation, which means I must be doing something wrong. My own computation is this: Modulo 2, the curve becomes $y^2 = x^3 + x$ . This has a double root at $(1, 0)$ . So I make the change of coordinates $x' = x-1$ to shift the singular point to $(0, 0)$ , and the curve in the new coords (after relabelling $x'$ back to $x$ ) is $y^2 = x^3 + x^2$ . Rearranging, this is $$ x^3 + x^2 - y^2 = 0 $$ This can be viewed as the Taylor expansion of my curve at $(0, 0)$ , and so there is a double point, and the tangent lines are given by factorizing $(x^2 - y^2) = (x-y)(x+y)$ . From this, I conclude that there is split multiplicative reduction. What am I doing wrong? Does it have something to do with how over $\mathbb{F}_2$ , the tangent lines $(x-y)$ and $(x+y)$ are actually the same lines? I would really appreciate if you could tell me where I am wrong in this 'proof'. show me how to do it correctly. bonus helpfulness if you could direct me a good resource to understand this concept of computing the type of singular point properly/efficiently. Thank you very much!","['multivariable-calculus', 'algebraic-geometry', 'projective-geometry', 'elliptic-curves']"
3828830,"In a triangle ABC, $\begin {vmatrix} a&b&c \\b&c&a \\c&a&b \end {vmatrix}=0$, then find $\sin A\sin B+\sin B\sin C+\sin C\sin A$","From the given determinant, $$a^3+b^3+c^3-3abc=0$$ Which implies $a+b+c=0$ or $a^2+b^2+c^2 -ab-bc-ac=0$ Since the former isn’t possible, $$a^2+b^2+c^2=ab+bc+ac$$ $$\sin A\sin B+\sin B\sin C +\sin C\sin A=\sin^2A +\sin^2B+\sin ^2C$$ The answer for this is either $\cos^2A+\cos^2 B+\cos^2C$ or one of numbers $0, 1, \frac 94$ How do I proceed from here?","['trigonometry', 'triangles']"
3828838,Showing there is no smooth structure such that the inclusion is an immersion,"I am trying to do the following exericse : Let $A=\{(x,|x|):x\in \mathbb{R}\}\subset \mathbb{R}^2$ . Show that there is no smooth structure on $A$ such that $i:A\rightarrow \mathbb{R}^2$ is an immersion. Now trying to prove this I had two ideas, going by contradiction, one using the constant rank theorem and another using the differential itself, and in both of them I try to focus on the point $0$ since this seems this will be give some trouble due to the fact that we have the function $|x|$ in there. So using the constant rank theorem we know that there will be local coordinates $(U,\phi)$ and $(V,\psi)$ such that $\psi\circ i\circ \phi^{-1}(x)=(x,0)$ . With this I tried to use some homeomorphism argument between spaces to obtain a contradiction but got nowhere. Now for the differential we know that for a point $p$ , $d_pi(\frac{\partial}{\partial x})=\sum_{j=1}^{2}\frac{\partial(i\circ \phi^{-1})^j}{\partial x}\frac{\partial}{\partial y_j}$ , but I can't seem to know anything about those derivatives itself to obtain that this will not be injective . So any hint or suggestion on how to prove this is aprecciated, just trying to know if I am going in the right direction . Thanks in advance. New edit : Started thinking about this again , and now my idea is well since we are in $\mathbb{R}^2$ we can make the canonical identification of the tangent space and the differential will simply be derivative of the function $(x,|x|)$ , and at $0$ we will have the problem that this is not an immersion . Intuitively this works for me , but it is not a rigorous way to prove the statement.","['smooth-manifolds', 'differential-geometry']"
3828908,Is Grönwall's Lemma true only for non-negative functions?,"For instance, in this article of Wikipédia a statement is made for Differential form of the Grönwall's Lema for a $\beta, u:I:=[a,b]\subset \mathbb{R} \longrightarrow \mathbb{R}$ continuous functions and $u$ differentiable in the interior $I^{\circ}$ of $I$ . That is, $ u $ and $ \beta $ are not necessarily non-negatives. Where, $$u'(t) \leq \beta(t)u(t) , \; \forall \;  t \in I^{\circ}\Rightarrow u(t) \leq u(a)e^{\int_{a}^{t}\beta(s)}ds, \; \forall \; t \in I.$$ The versions of the Grönwall's Lema that I know of require that the functions be non-negative. Is that what's on Wikipedia right? If so, is there a reference that contains this result? In the statement of the article, quoted above, an observation is made: There are no assumptions on the signs of the functions $\beta$ and $u$ . I did not see error in the proof presented there.","['continuity', 'inequality', 'derivatives', 'real-analysis']"
3828913,Showing $S^1$ is submanifold,"I'm trying to show that $S^1=\{ (x,y) \in \mathbb{R}^2: x^2+y^2=1\}$ is a submanifold of $\mathbb{R}^2$ using the following definition: A subset $M \subset \mathbb{R}^n$ is called a smooth k-dimensional submanifold of $\mathbb{R}^n$ , $k \leq n$ , if any point $z \in M$ has a neighborhood $O_z$ in $\mathbb{R}^n$ and there exists a smooth vector-function $$\Phi:O_z \to O_0 \subset \mathbb{R}^{n},$$ onto a neighborhood of the origin $0 \in O_0 \subset \mathbb{R}^n$ with $$\text{  } \operatorname{rank} \frac{d \Phi}{dz}\bigg|_z=n $$ such that $ \Phi(O_z \cap M)= \mathbb{R}^k \cap O_0$ . I know the idea is to make the circle straight locally, but I can't explain $\Phi$ , my initial proposal would be ( $z=(x,y) \in S^1$ ) $O_z = B_{\frac{1}{4}}(z)$ and $O_0=B_0(1)$ , $\Phi(x,y)=(\frac{x}{\sqrt{x^2+y^2}+1}, \frac{y}{\sqrt{x^2+y^2}+1})$ , but $\Phi(O_z \cap M) \neq \mathbb{R}^k \cap O_0$ . How can I write to $\Phi?$","['submanifold', 'smooth-manifolds', 'differential-geometry']"
3828922,$s$-finite vs. $\sigma$-finite measures,"Many results in measure theory are first proven for finite measures and then extended to $\sigma$ -finite ones. Here are some examples: $\pi\text{-}\lambda$ theorem approach to proving two measures are the same. Fubini-Tonelli. Lebesgue decomposition. Radon-Nikodym theorem. Other results (e.g. Duality $(L^1(\mu))^*\simeq L^\infty(\mu)$ . for $\sigma$ -finite measures $\mu$ ) are stated directly in terms of $\sigma$ -finite measures. In the theory of random measures $s$ -finite measures seem to be preferred over $\sigma$ -finite ones, providing a more flexible theoretical framework presumably. Recall that a measure $\mu$ is $s$ -finite if there are finite measures $\mu_n$ , $n\in\Bbb{N}$ , with $\mu=\sum_0^\infty\mu_n$ . Question 1. Which results valid for $\sigma$ -finite measures remain true for $s$ -finite measures? It seems pretty clear that the Fubini-Tonelli Theorem remains valid for $s$ -finite measures since if $\mu=\sum_0^\infty\mu_n$ and $\nu=\sum_0^\infty\nu_n$ one ought to have $\mu\otimes\nu=\sum_{m,n=0}^\infty\mu_m\otimes\nu_n$ , and this question was already raised elsewhere . Using the $\pi\text{-}\lambda$ theorem approach to proving two measures are the same ought to be transposable to $s$ -finite measures if one can do it ``one $\mu_n/\nu_n$ at a time''. I don't believe that the Radon-Nikodym Theorem remains true, for instance if we take $\mu$ the counting measure on $\Bbb{N}$ and $\nu$ the measure $$\nu(A)=\begin{cases}A=\emptyset:&0\\A\neq\emptyset:&+\infty\end{cases}$$ We have $\mu\ll\nu$ but there can't be a function $f$ with $\mu=f\cdot \nu$ . What about Lebesgue decomposition ? Quesstion 2. When should one work with $\sigma$ -finite measures / when with $s$ -finite measures? To explain a little more in detail: it seems to me that $\sigma$ -finite measures are interesting when one is interested in actually using a measure to do integration. To wit, I never heard of $s$ -finite measures before reading up on point processes. On the other hand, $s$ -finite measures seem to be the right concept when one is interested in measure valued processes, i.e. random measures, but doesn't really care to apply results from measure theory to and perform actual integration using these measures. Is that impression correct?","['measure-theory', 'fubini-tonelli-theorems']"
3828931,What is the advantage of using an indexing set?,"For countable sets, what is the advantage of using an indexing set, such as $i \in I$ , compared to just using the naturals and the normal enumeration of $1, 2, 3, \ldots$ ? To me it seems they equivalent unless the sets are uncountable, in which you cannot use something like $\mathbb{N}$ to index your set.","['elementary-set-theory', 'notation', 'infinite-product', 'infinity']"
3829029,Least triangular convex polygon,"(This question is based on a question posed in a math riddle post on Reddit .) Let $P$ be a convex polygon. Let the non-triangularity of $P$ be the minimum area of the symmetric difference (shown with infix operator $\oplus$ ) over all triangles and $P$ , normalized to the volume of $P$ : $$
  \inf_{T \subset \mathbb{R}^2,\text{ a triangle}} \left\{ \frac{\operatorname{area}(P \oplus T)}{\operatorname{area}(P)} \right\}
$$ In the picture below, the polygon $P$ is a rectangle, and we're trying to choose a triangle $T$ such that the area in orange is minimized. Triangles have a non-triangularity of $0$ , by ""approximating"" the triangle by itself. It's easy to construct an $n$ -gon with very small non-triangularity: just make all but three of the sides arbitrarily small. Also, all polygons $P$ have a triangularity less than $1$ , just take a triangle $T$ in the interior, so that $\operatorname{area}(P \oplus T) = \operatorname{area}(P) - \operatorname{area}(T) < \operatorname{area}(P)$ . Question What is the most non-triangular convex polygon? (Or, in the limit, the most non-triangular convex set ?) Or if this question is too hard, what are some non-trivial bounds on how non-triangular a convex polygon can be? (Perhaps constructive lower bounds would be useful to see, for example, computing the non-triangularity of the square or the circle.) If this question is too easy, what is the most non-triangular $n$ -gon for each $n$ ?","['area', 'extremal-combinatorics', 'geometry', 'polygons', 'triangles']"
3829061,Proving that the function $f(x)=\sum_n\frac{1}{10^n}\{10^nx\}$ is everywhere continuous but nowhere differentiable.,"Theorem: The function $f(x)=\sum_{n=1}^{\infty}\frac{1}{10^n}\{10^nx\}$ is everywhere continuous but nowhere differentiable, where $\{.\} $ represents distance from nearest integer. This theorem has been taken from chapter $23$ of Spivak's Calculus book. By Weirstrauss M test, $f$ is uniformly continuous. In the book, the theorem is proven by showing that the limit $L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}$ does not exist when $h_m\to 0$ , where $a\in (0,1]$ . Let $a=0.a_1a_2\cdots$ Let $h_m=10^{-m}$ if $a_m\ne 4,9$ and $h_m=-10^{-m}$ if $a_m=4,9$ . $\tag{1}$ No. of terms in summation in the above limit $L$ is finite as if $n\ge m, 10^nh_m$ is integer and hence numerator of the summations becomes zero. So for $n\lt m$ , $\{10^na\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots a_m\cdots $ and $10^n \{a+h_m\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots (a_m\pm1)\cdots$ and this representation into decimals is correct as $h_m=-10^{-m}$ if $m=9$ . ** Then, Spivak makes a statement that if $0.a_{n+1}a_{n+2}\cdots
 a_m\cdots \le 0.5$ , then we also have $0.a_{n+1}a_{n+2}\cdots (a_m\pm
 1)\cdots \le 0.5$ as $h_m=-10^{-m}$ if $a_m=4$ . ** And I think that this is not true at all because in the special case $m=n+1$ , if $a_m=5$ then clearly $0.a_m\le 0.5$ but $0.(a_m\pm 1)\le 0.5$ is not true! and hence condition on $h_m$ should be $h_m=-10^{-m}$ when $a_m=5,9$ and $h_m=10^{-m}$ when $a_m\ne 5,9$ . Is my understanding correct? Another doubt that I have is: Is the following alternative way correct? Let's choose $h_m=10^{-m}$ if $a_m\ne 9$ and $h_m=-10^{-m}$ if $a_m=9$ . Then it's clear by writing decimal representation that, $\{10^n(a+h_m)\}-\{10^na\}=\pm 10^{n-m}$ and then $L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}=\lim_{m\to \infty}\sum_{n=1}^{m-1}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}\lim_{m\to \infty}\sum_{n=1}^{m-1}\pm 1=\lim_{m\to \infty}\pm (m-1)$ , which doesn't exist. Hence proved. Please help. Thanks.","['calculus', 'solution-verification', 'sequences-and-series', 'real-analysis']"
3829062,Archimedean Clayton copula entropy,"Question I would like to derive the entropy of Archimedean parametric copulas  (Clayton, Frank, or Gumbel), focusing here on the Clayton copula. Link to similar question on the t-copula . The bivariate copula function , $C$ , for the Clayton copula, with transformed marginals $u$ and $v$ , and dependence parameter $\theta\in \mathbb{R}_{\geq 0}$ , is $$ C(u, v) = \bigg[ u^{-\theta} + v^{-\theta} -1 \bigg]^{-1/\theta} $$ Its copula density is the second mixed partial derivative of $C(u,v)$ : \begin{align}
c\left(u,v ; \theta\right) = (1+\theta)(u \cdot v)^{-1-\theta}(u^{-\theta}+v^{-\theta}-1)^{-\frac{1}{\theta}-2}
\end{align} The differential entropy of a univariate variable's pdf, $f(x)$ , is typically $$H(X)=-\int_{-\infty} ^{\infty} f(x) \ln f(x) dx$$ while any copula entropy can be estimated as $$H(c(u,v))=-\int_{[0,1]^2} c(u,v) \ln c(u,v) \hspace{1mm} du \hspace{1mm} dv $$ How can we derive a closed-form analytical solution for the entropy of the Clayton copula density $c(u,v)$ ? First attempt \begin{align}
H(c(u,v)) =&  -\iint_{[0,1]^2} c\left(u, v ; \theta\right) \ln c\left(u, v ; \theta\right) \mathrm{d}u \, \mathrm{d}v \\
= &  -\iint_{[0,1]^2} (1+\theta)\left(u v\right)^{-1-\theta}\left(u^{-\theta}+v^{-\theta}-1\right)^{-\frac{1}{\theta}-2}\\
\times & \ln\left[(1+\theta)\left(u v\right)^{-1-\theta}\left(u^{-\theta}+v^{-\theta}-1\right)^{-\frac{1}{\theta}-2}\right] \mathrm{d}u \, \mathrm{d}v \\
= &  -(1+\theta) \iint_{[0,1]^2} \left(u v\right)^{-1-\theta}\left(u^{-\theta}+v^{-\theta}-1\right)^{-\frac{1}{\theta}-2}\\
\times & \left[\ln(1+\theta) - (1+\theta)\ln\left(u v\right) -\left(\frac{1}{\theta}+2\right)\ln\left(u^{-\theta}+v^{-\theta}-1\right)\right] \mathrm{d}u \, \mathrm{d}v \\
= &  -(1+\theta) \iint_{[0,1]^2} \bigg[\ln(1+\theta) c - (1+\theta)\ln\left(u v\right) c -\left(\frac{1}{\theta}+2\right)\ln\left(u^{-\theta}+v^{-\theta}-1\right) c \bigg] \ \mathrm{d}u \, \mathrm{d}v \\
= &  -(1+\theta) \ln(1+\theta) \iint_{[0,1]^2}  c \ \mathrm{d}u \, \mathrm{d}v + (1+\theta)^2\iint_{[0,1]^2} c \ln\left(u v\right)  \ \mathrm{d}u \, \mathrm{d}v \\
+ & (1+\theta) \left(\frac{1}{\theta}+2\right) \iint_{[0,1]^2} c \ln\left(u^{-\theta}+v^{-\theta}-1\right) \ \mathrm{d}u \, \mathrm{d}v \\
\stackrel{\dagger}{=} &  -(1+\theta) \ln(1+\theta) \int_0^1  c  \bigg|_{v=0}^{v=1} \ \mathrm{d}u + (1+\theta)^2 \int_0^1 c \ln\left(u v\right) \bigg|_{v=0}^{v=1} \ \mathrm{d}u\\
+ & (1+\theta) \left(\frac{1}{\theta}+2\right) \int_0^1 c \ln\left(u^{-\theta}+v^{-\theta}-1\right) \bigg|_{v=0}^{v=1} \ \mathrm{d}u  \\
= & ?
\end{align} where $c = \left(u v\right)^{-1-\theta}\left(u^{-\theta}+v^{-\theta}-1\right)^{-\frac{1}{\theta}-2} $ , and $\dagger$ is due to treating the double integrals as an iterated integral , $$\iint_{[0,1]^2}  c(u,v) \ \mathrm{d}u \, \mathrm{d}v  = \int_0^1  c(u,v)   \bigg|_{v=0}^{v=1} \mathrm{d}u $$ Why do I think an analytical solution of copula entropy can be found? Because there is one for the entropy of the Normal distribution's pdf, derived here .","['statistics', 'entropy', 'probability-theory', 'closed-form', 'copula']"
3829161,Discontinuous functionals on infinite dimensional topological vector space [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question Using the Axiom of choice, one can show that (see here ) every infinite dimensional normed vector space has discontinuous functionals. My question is: Is this also true for a general topological vector spaces?","['continuity', 'banach-spaces', 'topological-vector-spaces', 'functional-analysis']"
3829225,Why is a matrix called an operator?,"I heard my math teacher mentioning that a matrix is an operator. This confused me, so I looked up what an operator was. In simple terms, it is a function that maps from one space to another space. Examples I can think up are as follows: \begin{equation}
  f(x) = x^{2}
\end{equation} This function takes some number in the set of all complex numbers, and outputs another number in the set of all complex numbers, and is thus an operator. \begin{equation}
  \frac{\mathrm{d}}{\mathrm{d}x} f(x) = \frac{\mathrm{d}}{\mathrm{d}x} (x^{2} + 2x + 3)
\end{equation} The $\mathrm{d}/\mathrm{d}x$ here is an operator as it takes a function from a set of functions that may have complex coefficients, and outputs another function that may have complex coefficients. So I understand why both of these are ""operators"". But let's take a look at a matrix: \begin{equation}
  \mathbb{M} = 
    \begin{pmatrix}
      3 & 2 \\
      4 & 1
    \end{pmatrix}
\end{equation} How can this be called an operator? It's not taking any element from a set and then outputting an element from another set. I think of it as similar to a scalar, like $3$ —is it not an operator, but you can use an operator, such as addition or multiplication on scalars, and the addition or multiplication can be considered an operator. Why would a matrix such as $\mathbb{M}$ be called an operator? Can any $n$ -rank tensor then be called an operator as well if a matrix is an operator?","['matrices', 'linear-algebra', 'terminology']"
3829256,"Show that the interval $\left[ \frac{-1+\sqrt{1+8m}}{2}, \frac{1+\sqrt{-7+8m}}{2} \right]$ contains exactly one integer","Question: Given any integer $m\geq 1$ , is it true that the interval $$\left[ \frac{-1+\sqrt{1+8m}}{2}, \frac{1+\sqrt{-7+8m}}{2} \right]$$ contains exactly one integer only? From graphing , this seems to be true.
However, I do not know how to prove it.","['recreational-mathematics', 'algebra-precalculus', 'discrete-mathematics', 'real-analysis']"
3829267,Evaluating $\sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}}$,"I've looked into WolframAlpha and deduced from some examples that: $$ \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}}  = \frac{k}{k-1} ~~~~ \text{where} ~~~ k \in \mathbb{N} \setminus \{1\}$$ But why is that? The only thing I could pull of is this: $$ \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}} = \sum_{n=k}^{\infty} \frac{k! (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{ (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{1}{(n-k+1) \cdot (n-k+2)\dots \cdot n}$$ Which then got me into a dead-end (for my knowledge) ... I am curious as why is that and but this actually mean ""combinatorically"" / ""statistically"" and how to actually evaluate this. Thanks!","['calculus', 'combinatorics', 'summation']"
3829296,"$\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0$","How to show that $$\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0,$$ where $x,y,z>0$ . My attempt: $$||(x,y,z)|| < \delta \implies |x|, |y|, |z| < \delta$$ $$\left | \frac{xyz}{x^2+y^2+z^2} \right | < \left | \frac{xyz}{x^2}\right | < \frac{\delta^3}{x^2}.$$ Now, I do not know how to proceed, and I think my attempt might be wrong.",['multivariable-calculus']
3829333,An intuitive proof of Prokhorov’s theorem,I just want to understand why tightness condition implies that the measure sequence would admit a converging subsequence. I wonder if someone can explain to me how Prokhorov's theorem is proved intuitively without too much analysis formalism. Why not being able to escape to infinity warrants convergence?,"['stochastic-processes', 'measure-theory', 'probability-theory', 'real-analysis']"
3829403,"Question about principal generator of max ideals in $\mathbb{R}[X,Y]/(X^2+Y^2+1)$ [Liu Exercise 2.1.3]","Exercise 2.1.3 from Qing Liu's (excellent) algebraic geometry text. Let $k = \mathbb{R}$ be the field of real numbers. Let $A = k[X,Y]/(X^2+Y^2+1)$ . We wish to describe Spec $A$ . Let $x,y$ be the respective images of $X,Y$ in $A$ . (a) Let $\mathfrak{m}$ be a maximal ideal of $A$ . Show that there exist $a,b,c,d \in k$ such that $x^2+ax+b, y^2+cy+d \in \mathfrak{m}$ . Using the relation $x^2+y^2+1=0$ , show that $\mathfrak{m}$ contains an element $f=\alpha x+\beta y+ \gamma$ with $(\alpha,\beta) \neq (0,0)$ . Deduce from this that $\mathfrak{m} = fA$ . If such an $f$ exists, then we must have $fA = \mathfrak{m}$ as $$\frac{A}{fA} \cong \frac{k[X,Y]}{(X^2+Y^2+1,\alpha X + \beta Y + \gamma)} \cong \frac{k[X]}{((\alpha^2+1)X^2 -2 \alpha\gamma X + \gamma^2 +1)},$$ and that last polynomial is irreducible. To show that such an $f$ exists, one can show that there are only several cases of $\mathfrak{m}$ to consider, one of which is $\mathfrak{m} = (x^2+b, y^2+d)$ , where $b,d > 0$ . In this case, we can't simply add the two generating polynomials to obtain $f$ as we could in the unstated cases. As it turns out, $x^2+y^2+1 = 0 \Rightarrow b+d=1$ and $y^2+d = -x^2-(1-d)$ , so $\mathfrak{m} = (x^2+b)$ is principal (no surprise as $A$ is a UFD and a Dedekind domain). Furthermore, it factors as $x^2+b = (\sqrt{d}x+\sqrt{b}y)(\sqrt{d}x-\sqrt{b}y)$ , and, since $\mathfrak{m}$ is prime, one of those linear factors is contained in, and therefore generates, $\mathfrak{m}$ . My problem: This is one of those, ""even if it's true, I have to see it with my own eyes"" deals. Choosing $b=3/4, d=1/4$ , we get that $\mathfrak{m} = (x^2+3/4)$ and I cannot for the life of me find a $g(x,y)$ such that $g(x,y)\cdot(x^2+3/4) = 1/2x \pm \sqrt{3}/2y$ . I can see how it might be possible by higher order terms and mixed quadratic terms canceling, and the identity $1 = -x^2-y^2$ canceling out pure quadratic terms, but I'm definitely not confident. I think Groebner bases are useful here, but if so I don't know enough to use them, and Sage hasn't been too helpful. In fact, if, say, $(x^2+3/4) = (1/2x - \sqrt{3}/2y)$ , then wouldn't they be associates and $1/2x + \sqrt{3}/2y$ necessarily a unit? I don't think either of the factors is a unit, though. At this point I'm just spinning my own wheels and could use some help finding an error in the proof (read: sketch) above, or help finding a $g(x,y)$ for the example  above.","['algebraic-geometry', 'commutative-algebra']"
3829409,"Can I solve $\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2}$ by converting to polar coordinates?","Is it correct to solve this problem like this? $$\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2} $$ $$\lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}}$$ $$\frac{x^2+y^2}{x^2y^2}=\lim_{r\to\ 0} \frac{1}{r^2\cos^2\theta\sin^2\theta}=\infty\implies \lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}}=0$$","['limits', 'multivariable-calculus', 'limits-without-lhopital', 'polar-coordinates']"
3829452,The interior of open set in a convex set is not empty,"Definition The upper half-space $H^n$ in $\Bbb R^n$ is the set of those $x\in\Bbb R^n$ such that $x_n\ge 0$ . So I ask if it is true that any not empty and open set $U$ in $H^n$ has interior (in $\Bbb R^n$ ) not empty. Probably this is a consequence that the interior of open set in a convex set is not empty? Is my this last statement true? So could someone help me, please?",['general-topology']
3829525,Why is the fractional Sobolev space defined like this?,"I was reading Fractional Sobolev space topic. $s\in (0,1)$ , $p\in [1,\infty)$ , $$
W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{n/p+s}}\in L^p(\Omega\times \Omega)\right\}
$$ . But I do know why there is extra term of $n/p$ come in power. Natural extension of integer Sobolev space should be $$
W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{s}}\in L^p(\Omega\times \Omega)\right\}
$$ . Please any one through some light on such definition of Sobolev space. Edit: I though may be this because of integrability possible iff $(n/p+s)p>n$ . But I am not sure. Any Help will be appreciated.","['definition', 'fractional-sobolev-spaces', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3829622,Derivative of the Heaviside step function,"The Heaviside step function is defined as $$H(x) = \begin{cases} 0 & \text{if }x<0 \\ 1 & \text{if }x\geq0\end{cases}$$ Set also $K(x)=H(2x)$ for all $x\in\mathbb R$ . Now it is well known (and can be easily proven) that the derivative of $H$ in the sense of distributions is the Dirac delta $\delta_0\,$ : $$H' = \delta_0 \;.$$ Using standard calculus rules I would then expect $$K' = 2\,H' = 2\,\delta_0 $$ but this is of course not true since $K=H$ . I'd like to understand why I cannot use standard calculus rules and which rules fail (and which do not) when dealing with distributional derivatives.","['dirac-delta', 'probability-distributions', 'distribution-theory', 'calculus', 'probability-theory']"
3829672,Can someone help me solve this problem with sets and power sets?,"Let $A$ and $B$ be sets, and let $f : A \rightarrow B$ be a function. We define
a function $f_P : \mathcal P(A) \rightarrow \mathcal P(B)$ , where $\mathcal P(A)$ is the power set of $A$ (i.e. the collection of all subsets of $A$ ), by $f_P(S) = \{f(s) | s \in S\}$ . We proved that if $f$ is a
bijection, then $f_P$ is also a bijection.
Assume that $f : A \rightarrow B$ is surjective but not necessarily injective. Is $f_P$ also
surjective? Prove or provide a counterexample.",['elementary-set-theory']
3829712,Why uniform distribution is not memoryless?,"The exponential and geometric distributions have the memoryless property, meaning that the distribution of the waiting times between the events does not depend on how much time has elapsed already. But I'm trying to intuitively understand why uniform distribution is not memoryless. Can someone please help me with that? Maybe this example will explain what is my concern: Scenario 1: We have a room, to which $k$ identical people arrived (the arrived at different times). Each person stayed in the room a random amount of time $x$ , where $x$ is from exponential distribution. Now, I observe one person leaving - the probability that this person is the same one who entered the room first, is the same as the probability it was the second one, the third one etc. So, the person leaving the room can be with equal chances any of the $k$ people. Scenario 2: I have the same story, but now the people do not wait random exponential time. Instead, when the people enter the room one person is picked uniformly at random to leave the room. Then the next one, and the next one. So, given the uniform distribution is not memoryless, in the second scenario can I somehow tell which of the incoming persons is no leaving? If not, how is this different from the memoryless property?","['probability-distributions', 'uniform-distribution', 'exponential-distribution', 'probability']"
3829760,Applying squeeze/sandwich theorem to find $\lim_\limits{n\to\infty} \frac{1}{n^2} \sum_\limits{k=n}^{5n} k$,"$$\lim_{n\to\infty}\Bigl( \frac{n}{n^2}+\frac{n+1}{n^2}+\cdots+\frac{5n}{n^2}\Bigr)$$ I know how to directly compute it, but I am required to use squeeze theorem. Let $S_n$ be the sequence concerned.
I tried $(4n+1)\frac{n}{n^2}<S_n<(4n+1)\frac{5n}{n^2}$ , but it gives me $4<\lim S_n<20$ . What should I do to get appropriate bounds so that squeeze theorem can be applied?","['limits', 'sequences-and-series', 'real-analysis']"
3829807,Extensions of diffeomorphisms from $R^3$ to $S^3$.,"Is there a convenient theorem about which diffeomorphisms $f: \mathbb R^3\rightarrow\mathbb  R^3$ can be extended to diffeomorphisms $\overline{f}: S^3\rightarrow S^3$ ? That is, given a diffeomorphism $f:\mathbb R^3\rightarrow\mathbb R^3$ , when does there exist an inclusion $i:\mathbb R^3\rightarrow S^3$ inducing a homeomorphism between $R^3$ and $i(\mathbb R^3)$ such that the map $\overline{f}: S^3\rightarrow S^3$ which fixes the point at infinity and is equal to $i\circ f\circ i^{-1}(x)$ for every other $x\in S^3$ is a diffeomorphism?",['differential-geometry']
3829815,$\frac{\partial F}{\partial y}\neq0\implies$ continuous contour line? (Implicit Function Theorem),"I have a function $F(x,y)=z$ and two points $(x_1,y_1),(x_2,y_2)$ s.t. $F(x_1,y_1)=F(x_2,y_2)=c$ , $x_1<x_2$ . I know that $\frac{\partial F}{\partial y}<0$ in $ [x_1,x_2]\times\mathbb{R}$ . I'd like to prove that there is a continuous contour line between the two points. I know that there's a rectangle $V\times W $ that contains $(x_1,y_1)$ s.t. $F^{-1}(c)\cap V\times W $ is the graphic of a function, i.e., I have in there a continuous contour line. I'd like to know if the fact that I have $\frac{\partial F}{\partial y}<0$ in the entire interval $[x_1,x_2]$ allows that I consider $V=[x_1,x_2]$ and $W=\mathbb{R}$ , so I can prove the statement. Many thanks! ========== Edit for comment on 12/26 Edit for new comments","['partial-derivative', 'continuity', 'multivariable-calculus', 'implicit-function-theorem']"
3829830,"Proof by contrapositive: Prove for all $x,y\in\mathbb{R},$ if $x$ is rational and $y$ is irrational then $x+y$ is irrational.","I read some answers on here, but I wanted some input on what happens if I try a proof and get a weird outcome. I tried proving this by taking the contrapositive which is: if x+y is rational then $x$ is irrational or $y$ is rational Let $x+y=\frac{P}{Q}$ for some integers $P,Q$ $$x = \frac{P}{Q} - y$$ $$x = \frac{Py-PQ}{Q}$$ (this shows that $x$ is actually rational - which contradicts my contrapositive statement?) What does it mean when I find a contradiction when trying to prove the contrapositive statement? How should I proceed from here? Any tips would be appreciated $-$ I'm pretty new to proofs.","['proof-explanation', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
3829837,If $P(A \cup B) = 1$ then does $B = A^c$?,"Let A and B be two arbitrary events in a sample space S. Prove the following or provide a counterexample: If $P(A \cup B) =  1$ then $B = A^c$ This is my original answer: Since both $A, B \in S$ and $P(A \cup B) = 1$ then by definition $A \cup B = S$ : $$S = A \cup B$$ $$S \cap B^c = A \cup B \cap B^c$$ $$B^c = A$$ $$B = A^c$$ But I now realize that $P(A \cup B) = 1$ does not necessarily imply that $A \cup B = S$ so my proof doesn't work.","['probability-theory', 'probability']"
3829883,"Suppose each $x_{n+1} \le \left(\sum_{i=1}^n x_i \right)^{-c}$ for some $c \in (0,1)$. How quickly can $\sum_{i=1}^n x_i $ grow?","Suppose we have a sequence $x_1,x_2,\ldots \in [0,1]$ that satisfies $x_{n+1} \le \left(\sum_{i=1}^n x_i \right)^{-c}$ for each $n$ and some $c \in (0,1)$ . The relation comes from deciding stepsizes for a recursive algorithm. I suspect it forces the sum to grow slowly but am unsure how to prove it. I can show for example that we cannot have $x_n \ge \Omega(n^{-a})$ for some $a \le 1-\frac{1}{c+1}$ . For if this happens then $\sum_{i=1}^n x_i \ge \Omega(n^{1-a })$ and so $x_{n+1} \le O(n^{(a-1)c})$ . Thus we must have $-a \le (a-1)c$ which simplifies to $a \ge 1-\frac{1}{c+1}$ . This leads me to guess $x_n \le O(n^{\frac{1}{c+1}-1})$ and the sum is $O(n^{1/(c+1)})$ . Is there a way to prove this directly? Ideally without resort to clumsy asymptotic notation?","['recursive-algorithms', 'recurrence-relations', 'asymptotics', 'upper-lower-bounds', 'sequences-and-series']"
3829913,"If the complex sequence $u_{n+1}=f(u_n)$ has only one limit point, then it converges","I would like to prove that if $f:\mathbb{C}\to\mathbb{C}$ is continuous and if a sequence $u$ defined by : $\forall n\in\mathbb{N},\,u_{n+1}=f(u_n)$ has only one limit point (not sure of the translation of ""valeur d'adhérence"" in french), then this sequence does converge. I guess that it's wise to look after a proof that $u$ is a bounded sequence (it is well known that any bounded complex sequence possessing only one limit point is indeed convergent). EDIT : we suppose, that for some $u_0\in\mathbb{C}$ - (and not for all of them) - the sequence $(u_n)$ has exactly one limit point.","['fixed-point-theorems', 'sequences-and-series', 'convergence-divergence', 'complex-numbers', 'dynamical-systems']"
3829923,Combinatoric meaning to $1+2+\dots+n=\frac{n(n+1)}{2}= {n+1 \choose 2}$ [duplicate],"This question already has answers here : Is there a combinatorial interpretation of the triangular numbers? (5 answers) Closed 3 years ago . It is well known that $$ \sum_{k=1}^{n} k = \frac{n(n+1)}{2} .$$ As the story goes, Gauss notices that there are $n/2$ pairs of numbers that add up to $n+1$ , hence the formula above. But obviously the right hand side is ${n+1 \choose 2}$ , namely $$ \sum_{k=1}^{n} k = {n+1 \choose 2} .$$ Is there a ""combinatorial proof"" of this second equation? I am trying to see the connection between the sum (and Gauss' method) to the problem of choosing $2$ objects from $n+1$ objects.","['combinatorics', 'combinatorial-proofs']"
3829982,coding length bound for coding of certain binary trees,"the problem is this: Consider all binary trees with roots where the vertices are not labeled and inner vertices have exactly 2 children. (See below for example trees with 3 and 5 vertices.) Give a coding $f: \text{trees} \rightarrow \{0,1\}^*$ of the trees such that $ \mid f \mid \in O(n), $ where $n$ ist the number of vertices of the tree; that is, the length of the coding is bounded by some linear function in $n$ . Attempted solution: Consider the following coding: $f(t)=a_1a_2...a_n$ , where $ a_i =$ $ \\ 
\begin{cases} 1, \text{if $v_i$ has 2 children} \\
0, \text{if $v_i$ has no children.} \end{cases} $ Here, $v_i$ is simply the ith vertex in the graph, counting normally from the upper left corner to the lower right corner. Here are examples: (Sorry for having really ugly graphs..)
The code for the first, second, and third graph are:
100, 11000 and 10100. Appearently the size of the coding is $n$ in the case of $n$ vertices. It seems more of less convincing to me, but I have a feeling as if something is missing here, isn't this too easy? Do I need to prove something else? Thanks for any suggestions...","['graph-theory', 'trees', 'discrete-mathematics']"
3830006,What is ${\cal P}(A ) \cap A$?,"I need some clarification
I am not sure but what is : ${\cal P}(A ) \cap  A$ equal to the empty set? For any $A$ ? If not how can we prove it ?
Dir example $A=\{1,2\}$ , ${\cal P}(A) = \{ \{1\},\{2\},\{1,2\}, \emptyset \}$ .
Then ${\cal P}(A) \cap A = A$ ?","['elementary-set-theory', 'probability']"
3830101,"If $\sigma(\mathcal B)=\sigma(\mathcal T)$ for every basis $\mathcal B$ of topological space $(X,\mathcal T)$, must $T$ be hereditarily Lindelöf?","In the comments of this answer, someone claims: If topological space $(X,\mathcal T)$ is hereditarily Lindelöf, then $\sigma(\mathcal B)=\sigma(\mathcal T)$ for every basis $\mathcal B$ . Can this theorem be strengthened to read ""if and only if""? To clarify after some discussion in the comments, I'm introducing this terminology: A basis $\mathcal B$ for topology $\mathcal T$ has the ""Borel property"" if $\sigma(\mathcal B)=\sigma(\mathcal T)$ . A topology $\mathcal T$ has the ""strong Borel property"" if every basis for the topology has the Borel property. The conjecture then becomes: ""A topological space $(X,\mathcal T)$ is hereditarily Lindelöf if and only if $\mathcal T$ has the strong Borel property.""","['borel-sets', 'general-topology', 'measure-theory']"
3830112,"Translation of a set: a set plus a vector $\{0,2\}+1=\{1,3\}$?","I think the following operations make sense: $\{0,2\}+1=\{1,3\}$ $[0,2]+1=[1,3]$ $\{(0,0),(2,1)\}+(1,0)=\{(1,0),(3,1)\}$ But, is it formally defined in any text? Has a mathematician defined that $\{0,2\}\leq\{1,3\}$ because $\{0,2\}+1=\{1,3\}$ ? Motivation: We compare two sets: $A,B\in\mathbb R$ ; which one is greater? A common definition is called ""Strong Set Order"": Define the binary relation $\leq_{s}$ as follows: $A \leq_{s} B \quad $ if for any $a \in A$ and $ b \in B$ , $min\{a,b\} \in A$ and $max\{a,b\} \in B$ For instance, see the following picture, the first example $A\leq_s B$ while in the second case this is not true. However, intuitively, it makes sense to also define that $\{0,2\}\leq\{1,3\}$ (although this is not true by the strong set order), because if we translate the set $\{0,2\}$ one unit to the right, then we get $\{1,3\}$ .","['elementary-set-theory', 'order-theory', 'convex-analysis', 'real-analysis']"
3830142,How to differentiate $ABA^T$ with respect to $A$?,"I don't see how to differentiate $ABA^T$ with respect to $A$ where $A$ and $B$ are $n\times n$ matrices. I know it's going to be a rank-4 tensor, but what exactly will it be? The inspiration for this comes from having to find the derivative of the covariance matrix $\operatorname{Cov}(TX)$ with respect to $T$ . So I'll tell you all what I've done so far and maybe you can help. I was working with the squared Bures distance $d_H^2(Cov(TX),\Sigma_v) = tr(Cov(TX) + \Sigma_v - 2(Cov(TX))^{1/2}\Sigma_v Cov(TX)^{1/2})^{1/2})$ . First I computed the derivative of $d_H^2(A,B)$ for positive matrices $A$ and $B$ , which turned out to be $tr(I-A_{\#}B^{-1})$ . Here we define $A_{\#}B=(AB^{-1})^{1/2}B.$ So now I was using the chain rule to compute the derivative of $d_H^2(Cov(TX),\Sigma_v)$ . But in order to do that, I need to differentiate $Cov(TX)$ w.r.t. $T$ . That's where I'm stuck. ========= Ultimately, I'm looking to find the gradient with respect to $T$ of $$
\lambda \left\|TX-X\right\|^2 + \left\|T\right\|_{HS} + d_H^2(Cov(TX),\Sigma_v).
$$ and calculate its roots. Assuming I didn't make any mistakes, the derivatives of the first two terms are $2(TX-X)X^T$ and $T/\left\|T\right\|_{HS}$ respectively -- feel free to correct me if I'm wrong here. So the last term is what's causing problems for me when I differentiate.","['matrices', 'matrix-calculus', 'derivatives', 'tensors']"
3830231,How to prove the ‘covariance inequality’ for discrete random variables?,"I’m trying to prove the following ‘covariance inequality’ $$
|\operatorname{Cov}(x,y)|\le\sqrt{\operatorname{Var}(x)}\sqrt{\operatorname{Var}(y)}\,,
$$ where covariance and variance are defined using discrete values, \begin{align}
\operatorname{Cov}(x,y) &= \frac{1}{n-1}\sum_{i=1}^n \big[(x_i-\bar x)(y_i-\bar y)\big]\,, \\
\operatorname{Var}(x) &= \frac{\displaystyle\sum_{i=1}^n(x_i-\bar x)^2}{n-1}\,, \\
\operatorname{Var}(y) &= \dfrac{\displaystyle\sum_{i=1}^n(y_i-\bar y)^2}{n-1}\,.
\end{align} There are plenty of proofs of to be found online (such as this one ). However, they all either seem to be for continuous random variables, or just refer me to the Cauchy-Schwarz inequality, which I am aware of, but not sure how to apply to this particular proof. Basically, I am wondering if there is a way to prove this inequality using those above definitions. I’ve tried substituting these definitions into the inequality above, but after expanding these summations and getting rid of the $1/(n-1)$ on both sides, I’m left with a mess (as you can imagine) with summation terms on both sides, some in the absolute value, and some in the square root. I’m not sure if there’s some algebraic mistake I’m making, some summation property I’m missing, or if substitution is just the wrong way to go about this proof.","['covariance', 'variance', 'cauchy-schwarz-inequality', 'inequality', 'probability']"
3830278,"$M$ subset of $L^2[0,1]$ that is closed and convex","Let $M = \{ f \in L^2[0,1]: f([0,1]) \subset [0,1] \hspace{2mm}a.e.\}$ .
Show that $M$ is a closed and convex set. My idea for it to be closed is similar to that of sequences, so I say: Let $f \in \overline M$ and let's see what $f \in M$ . Since $f \in \overline M$ there is a sequence $(f_k)^{\infty}_{k=1}$ such that $f_k \to f$ , when $k \to \infty$ , and every $f_k \in M$ . Now, we have that $\forall \epsilon > 0$ , $ \exists N(\epsilon) > 0$ such that $k> N \to \displaystyle\int^1_0 |f_k - f|^2 d\mu < \frac{\epsilon^2}{\sqrt{3}}$ . Finally by triangular inequality and $\phi(t) = |t|^2$ is increasing $$
\displaystyle\int^1_0 |f_k - f_l|^2 d\mu \le \displaystyle\int^1_0 |f_k - f^{(N)}_k|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_k - f^{(N)}_l|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_l - f_l|^2 d\mu < \epsilon^2
$$ Is my proof ok? also I do not know if convexity is inherited from what $\phi(t) = |t|^2$ is convex and increasing","['measure-theory', 'functional-analysis']"
3830315,Solve $\frac{\sin (10^\circ) \sin (30^\circ)}{\sin 40^\circ \sin (80^\circ-x^\circ)} = \frac{\sin 20^\circ}{\sin x}$,"The context to this is trivial I think, I was solving a geometry problem using the trigonometric version of Ceva, I got here and I was stuck, I tried using the sum-difference, product to sums, sums to products identities but my attempts failed and was rather tedious.",['trigonometry']
3830357,"Boundedness of $\log(\|A^{-1}\|)/\log(\|A\|)$ as $A$ ranges over $SL(n,\mathbb R)$","I wonder if the quantity $\frac{\log(\|A^{-1}\|)}{\log(\|A\|)}$ is bounded by a constant number that only depends on the size $n$ of the matrix as $A$ ranges over $SL(n,\mathbb R)$ (the determinant one matrices). I couldn't find a counterexample, nor can I prove it. Here I require $\|\cdot \|$ as the operator norm of the matrix w.r.t the 2-norm of the Euclidean spaces. I am not sure if the answer is the same regardless of the norm of the matrix. Please let me know.","['matrix-calculus', 'functional-analysis']"
3830367,Some probabilistic reasoning in graphs.,"I’m reading the following scenario: $\bullet$ Let $G$ be an $n$ -vertex graph. $\bullet$ Sample $s$ vertices from $V(G)$ independently, with repetition. Let $S$ be the set of vertices selected. $\bullet$ Let $B = \{v \in V(G): \forall s \in S, \{v,s\} \in E(G)\}$ $\bullet$ Let $T$ be a set of $t$ vertices with at most $m$ common neighbours. $\bullet$ To have $T \subset B$ , need to select $S$ from these common neighbours. $\bullet \Rightarrow \mathbb{P}(T \subset B) \leq \left( \frac{m}{n} \right)^s$ The way the last statement comes about, from my understanding, is that, given the set of common neighbours of size $m$ , any vertex in the graph has at most $\frac{m}{n}$ a chance of being in this set. $S$ has $s$ members, hence the number $\left( \frac{m}{n} \right)^s$ . But how about this line of reasoning? We have $\mathbb{P}(T \subset B) = \mathbb{P}(\text{ the $m$ given vertices} \in S)$ . Each of those $m$ vertices has at most $\frac{s}{n}$ a chance to be in $S$ . The set has $m$ members, hence $\left(\frac{s}{n}\right)^m$ . Is this equivalent to the above? If not, why? Also please correct me if any of the above sentences doesn’t make sense.","['graph-theory', 'probabilistic-method', 'solution-verification', 'probability']"
3830449,Should one learn the proofs of theorems which have highly complicated proofs?,"Lately, I have been reading a really dense real analysis textbook and I came across different theorems which have exceedingly long proofs (for instance, the dominated/bounded convergence theorem or many other theorems that involve interchanging the order of integration/differentiation). I wonder if it is worth learning such proofs, because, for instance, I have known the DCT for a while and I have used it extensively to compute different limits, but I can't see why it would be useful to know how to prove it. I would like to add that I am mostly self-learnt at this level, because I have just finished high school. As a result, I don't know if, for instance, in a college level real analysis course the lecturer would prove such a result. I chose the DCT as an example because I have found it quite useful in different problems, but there are many other theorems which fit into this category.","['self-learning', 'soft-question', 'education', 'real-analysis']"
3830500,Does this recursive sequence converge (non monotonic)?,"Let $\{a_n\}$ be a sequence such that $a_1=4$ and $a_{n+1}=\dfrac{5 a_n -6}{a_n -2},\, \forall n\geq 2$ . Show that it converges and find its limit. The only thing that I managed to show is that if it is convergent, the limit is either 1 or 6. I used Mathematica to see the behavior of the sequence, and I noticed that it converges to 6 and also that it is not monotonic. I have come across some recursive sequences like this in various posts here in math.SE, but all of them where bounded and monotonic.","['recursion', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
3830501,How to prove that UMVUE does not exist for non-constant function?,"This is problem 1.9 of chapter 2 from Lehmann and Casella: Let $X_1, \dots, X_n$ be a sample (assuming i.i.d.) from a discrete distribution which assigns probability $1/3$ to each of the points $\theta-1, \theta, \theta+1$ . $\theta$ ranges over all integers. Prove that no non-constant function of $\theta$ has a UMVUE. My approach: Assume the simplest case $n=1$ . We can use the relationship between UMVUE and unbiased estimator of zero to tackle this issue. Suppose $T(x)$ is a UMVUE for $g(\theta)$ for some function $g$ . Then for an unbiased estimator of zero $U(x)$ , we have $$
E_\theta U = 1/3(U(\theta-1) + U(\theta) + U(\theta+1)) = 0, \ \forall \theta \in \mathbb{Z},
$$ i.e., $$
U(\theta-1) + U(\theta) + U(\theta+1) = 0, \ \forall \theta \in \mathbb{Z}.
$$ Then we have $$
U(\theta-1) = U(\theta + 2), \ \forall \theta \in \mathbb{Z}.
$$ Now we use the fact that if $T$ is UMVUE, then for any $U$ that is an unbiased estimator of zero, we have $$
E_\theta[TU] = 0.
$$ This implies that $TU$ is also an unbiased estimator of zero. Hence, for any unbiased estimator of zero $U$ : $$
T(\theta-1)U(\theta-1) = T(\theta + 2)U(\theta+2), \ \forall \theta \in \mathbb{Z}.
$$ This means that $$
T(\theta-1) = T(\theta+2), \ \forall \theta \in \mathbb{Z}.
$$ This gives us $$
1/3(T(\theta-1) + T(\theta) + T(\theta+1)) = 1/3(T(\theta) + T(\theta+1) + T(\theta+2)), \ \forall \theta \in \mathbb{Z}.
$$ Now the RHS is $g(\theta)$ while the LHS is $g(\theta+1)$ . Therefore, $$
g(\theta) = g(\theta + 1), \ \forall \theta \in \mathbb{Z}.
$$ This shows that $g$ is a constant function of $\theta$ . That is, UMVUE does not exist for non-constant function of $\theta$ . Now the part I am stuck at is how do I prove this for $n > 1$ ? I don't see an immediate induction-type argument or something else and carrying out direct derivation through brute force seems extremely complicated. Any hint would be helpful. Thank you very much!","['statistics', 'parameter-estimation', 'estimation']"
3830512,"How to show that $T_{(1,0)}\mathbb S^1 \cong \operatorname{span}(\{e_2\})$?","I want to show that $T_{(1,0)}\mathbb S^1 \cong \operatorname{span}(\{e_2\})$ using the stereographic chart and using the definition that $T_xM$ is the set of velocity vectors $v$ where each vector $v$ is the equivalence class of curves that goes through point $x$ and tangent to each other. I got so far the following: Since $\varphi:U\to\mathbb{R}$ is given by $\varphi(x,y)=\frac{x}{1-y}$ and $v=\frac{d}{dt}(\varphi\circ \gamma)(t)\Big|_{t=0}$ for some $\gamma:I\to \mathbb S^1$ with $\gamma(0)=x=(1,0)$ , we can compute that \begin{align}
v& =\frac{d}{dt}(\varphi\circ \gamma)(t)\Big|_{t=0}\\
&=\frac{d}{dt}\Big(\frac{x(t)}{1-y(t)}\Big)\Big|_{t=0}\\
&=\frac{x^{\prime}(t)(1-y(t))-x(t)(-y^{\prime}(t))}{(1-y(t))^2}\Big|_{t=0}\\
&=\frac{x^{\prime}(0)(1-y(0))+x(0)y^{\prime}(0))}{(1-y(0))^2}\\
&=x^{\prime}(0)+y^{\prime}(0).
\end{align} I don't know how to interprete that and how to actually show that $T_{(0,0)}\mathbb S^1$ should be a span of $e_2$ . I know that if $i:\mathbb S^1\to\mathbb{R}^2$ is an inclusion, then $$di_x:T_x \mathbb S^1\to T_{i(x)}\mathbb{R}^2\text{ is 
 injective}.$$ So, we need somehow show $di_x(v)=\operatorname{span}(\{e_2\})$ . What should I do?","['manifolds', 'tangent-spaces', 'differential-geometry']"
3830556,Is the field $\mathbb{Q}(\pi)$ elementarily equivalent to $\mathbb{Q}$?,"In model theory, we say that two structures are elementarily equivalent if they satisfy the same first-order sentences. For instance, in the language $\mathcal{L}=\{+,\cdot\}$ , the fields $(\mathbb{Q},+,\cdot)$ and $(\mathbb{Q}(\sqrt{2}),+,\cdot)$ are not elementarily equivalent because the $\mathcal{L}$ -sentence $$\sigma:  \exists y\,\exists z\,\forall x\,(x\cdot z=x \wedge y\cdot y=z+z.)$$ holds in the second field, but not in the first. (Basically, the sentence states that ""there is an element whose square is equal to $1+1$ "") However, is there an easy way to show that $(\mathbb{Q},+,\cdot)$ and $(\mathbb{Q}(\pi),+,\cdot)$ are (or are not) elementarily equivalent?","['model-theory', 'abstract-algebra', 'logic']"
3830574,What's the dimension of a Lie algebra generated by transpositions on $n$ objects?,"Define a Lie bracket on the group algebra of the permutation group $S_n$ in the following way: $$[\sigma, \tau] = \sigma\circ\tau - \tau\circ\sigma,$$ where $\sigma, \tau \in S_n$ , and the multiplication on permutations is defined as composition. My question is, what is the dimension of the Lie subalgebra generated by transpositions, i.e. $(ij)$ ? My conjecture is that the dimension is given by $C_n - \lfloor \frac{n}{2} \rfloor$ , where $C_n$ is the Catalan number. Is this correct and what is the proof? For example, when $n=3$ , using the cycle notation, we have $$
[(12),(23)] = (132) - (123) \\
[(23),(31)] = (132) - (123) \\
[(31),(12)] = (132) - (123) \\
$$ and $$
[(12), (132) - (123)] = 2((23) - (13)), \text{etc.}
$$ Therefore this algebra is $4 = C_3 - 1$ dimensional.","['permutations', 'catalan-numbers', 'combinatorics', 'lie-algebras']"
3830577,volume of solid obtained by rotating the curve about $x=2$ line,"Finding volume of solid obtained by rotating the regin enclosed by $y=x^3, y=0, x=1$ about $x=2$ line is What i try:: Volume of solid $$V=\pi\int^{8}_{0}\bigg[(2-x)^2-1\bigg]dy$$ $$V=\pi\int^{8}_{0}\bigg[(2-y^{\frac{1}{3}})^2-1\bigg]dy=-\frac{24\pi}{5}$$ Whats wrong with my solution, please Help me. Thanks","['multivariable-calculus', 'solid-of-revolution']"
3830617,Proving the decomposition is independent of the choice of chart.,"Let $M$ be a manifold with boundary, and let $p\in \partial M.$ So there is a decomposition of $T_pM$ as follows: For a chart $\phi : U\to \tilde{U} \subset \mathbb{H}^n,$ with coordinate functions $(x^1,\dots, x^n),$ we say that $X\in T_pM$ points into $M$ if $Xx^n > 0,$ out of $M$ if $Xx^n<0,$ and parallel to $\partial M$ if $Xx^n = 0.$ How do I prove this decomposition is independent of the choice of chart? And that the set of vectors that point parallel to $\partial M$ form an $n-1$ -dimensional subspace of $T_pM?$ Can someone please help me with this? Thank you","['manifolds', 'submanifold', 'smooth-manifolds', 'differential-geometry']"
3830626,Functions on a group. Functions of the inverse element.,"Consider a Lie group $G$ and a Hilbert space $\mathbb{V}$ equipped with a dot product $~~\langle~,~\rangle$ . Let ${^G{\cal{L}}}$ be a space of square-integrable functions mapping $G$ to $\mathbb{V}$ : $$
 {^G{\cal{L}}}=\left\{ f:~~ G\longrightarrow\mathbb{V}\qquad\Big{|}\quad  \int dg \langle f(g), f(g)\rangle < \infty     \right\}.
 $$ We can map each $ f$ to a function of the inverse argument: $$
 f(x)\longmapsto\varphi(x)\equiv f(x^{-1})~,\quad x\in G \qquad\qquad\qquad\qquad (*)
 $$ or, in short: $$
 f\longmapsto\varphi\equiv f\circ\hat{\zeta}~,
 $$ where $$
 \hat{\zeta} x\,=\,x^{-1}
 $$ is the inversion operation on $G$ . Doing this for all $f$ , we obtain a new space of functions: $$
 {\cal{L}}^{G}=\left\{~\varphi:~G\longrightarrow{\mathbb{V}}~~\Big{|}~~\varphi= f\circ\hat{\zeta}~,~~f\in{^G{\cal{L}}}
 \right\}~. \qquad\qquad\qquad (**)
 $$ To examine if $~^{G}{\cal{L}}$ and ${\cal{L}}^{G}$ are copies of the same functional space, check the square-integrability of the new functions: $$
  \int dg \langle \varphi(g),\varphi(g)\rangle=\int d(g^{-1}) \langle \varphi(g^{-1}) , \varphi(g^{-1})\rangle=
  \int d(g^{-1}) \langle f(g),f(g)\rangle
 $$ For unimodular groups, the measure is invariant and $d(g^{-1}) = dg $ , wherefrom $$
  \int dg \langle \varphi(g),\varphi(g)\rangle=
  \int dg \langle f(g),f(g)\rangle < \infty~,
 $$ so the spaces $^{G}{\cal{L}}$ and ${\cal{L}}^{G}$ coincide. For what nonunimodular groups would this outcome stay valid? Say, for compact ones? For locally compact ones? PS. I understand that, by Haar's theorem, if a group is locally compact (i.e. if its identity element has a compact neighborhood), then it admits a unique left-invariant and a unique right-invariant measure (unique -- up to multiplication by a positive constant). Under the transformation $g\to g^{-1}$ , a left-invariant measure transforms into a right-invariant one, and vice versa. Can this fact be somehow employed here?","['group-theory', 'lie-groups', 'measure-theory']"
3830682,Proof the Inclusion-exclusion principle with a characteristic function,"I'm trying to solve this exercise which consists of two proofs. In my attempt to solve it, I notice that the part [a.] and [b.] are related, since I think that both express the Inclusion-exclusion principle. I'm having trouble with [a.] and as far as I understand, that proof will be useful in solving [b]. Let $(\Omega,F,\textit{P})$ be a probability space and $A_{1}.A_{2},...,A_{n}\in F$ , then $$ A:=\bigcup_{k=1}^{n}A_{k} $$ [a.]Prove that $$ \mathcal{X}_{A} = 1-
 \prod_{k=1}^{n}(1-\mathcal{X}_{A_{k}}) $$ [b.] Prove that $$	 P(A)=\sum_{j=1}^{n}P(A_{k})-\sum_{i<j}P(A_{i}\cap
 A_{j})+\sum_{i<j<k}P(A_{i}\cap A_{j}\cap A_{k})-...+(-1)^{n-1}P\left(
 \bigcap_{j=1}^{n}A_{j}\right) $$ In my attempt I'm considering that $A=\bigcup_{k=1}^{n}A_{k}\subseteq \Omega$ , then due to $\mathcal{X}_{A}$ is an indicator function, every $\mathcal{X}_{A_{k}}$ in [a] should be equal to $1$ , since $$
\mathcal{X}_{A_{k}} = \begin{cases}
	1 & \text{ if } \omega \in A_{k}\\
	0 & \text{ if } \omega \notin A_{k} 
	\end{cases}
$$ Evaluating [a] for n=2 I obtained \begin{align*}
\mathcal{X}_{A} &= 1-((1-\mathcal{X}_{A_{1}})(1-\mathcal{X}_{A_{2}})) \\
	&=\mathcal{X}_{A_{1}}+\mathcal{X}_{A_{2}}-\mathcal{X}_{A_{1}}\mathcal{X}_{A_{2}}
\end{align*} And for n=3 \begin{align*}
\mathcal{X}_{A}=\mathcal{X}_{A_{1}}+\mathcal{X}_{A_{2}}-\mathcal{X}_{A_{1}}\mathcal{X}_{A_{2}}+\mathcal{X}_{A_{3}}-\mathcal{X}_{A_{1}}\mathcal{X}_{A_{3}}-\mathcal{X}_{A_{2}}\mathcal{X}_{A_{3}}+\mathcal{X}_{A_{1}}\mathcal{X}_{A_{2}}\mathcal{X}_{A_{3}}
\end{align*} I think this is similar to the proof Inclusion-exclusion principle in [b] but I'm stuck here because I don't know how to generalize [a] to prove it.
Thank you.","['measure-theory', 'characteristic-functions', 'inclusion-exclusion', 'elementary-set-theory', 'probability']"
3830689,Dunce hat with a vertex point removed is homotopy equivalent to $S^1 \vee S^1$,"Define $T = \{(x,y) \in \mathbb{R}^2 | x,y\geq 0, x + y \leq 1 \}$ and let $(x,0) \sim (0,x)$ and $(x, 0) \sim (x, 1-x)$ be an equivalence relation on $T$ . Then $D := T/ \sim $ , is our standard dunce hat . Show that $D \setminus \{[(0,0]\}$ is homotopy equivalent to $S^1 \vee S^1$ . Here $\vee$ is the wedge sum, and $S^1 \vee S^1$ looks like the figure ""8"". How do I show this? In fact I'm not even sure why this is true. I can't make the deformation in my head (the dunce hat is hard to imagine to begin with. Not sure what it looks like with a point removed). I can guess that the meeting point in the two circles in $S^1 \vee S^1$ will be the identified with $[(1,0)]$ but that's about it.","['general-topology', 'homotopy-theory', 'algebraic-topology']"
3830702,"How to find the supremum of the sequence $(x_n)$, where $x_n = \frac{2n}{6n+3}$ without using any calculus.","My professor gets upset when we use Calculus to solve problems in his Introduction to Abstract Math course. I have taken Linear Algebra, Discrete Math, and Calculus I. I have no idea how to find the supremum of the sequence $(x_n)$ with $x_n = \frac{2n}{6n+3}$ for $n \geq 1$ and $n \in \mathbb{Z}^+$ without using a limit. I know that the limit of $x_n$ as $n$ approaches infinity is $\frac{1}{3}$ , which would be the supremum, but I do not know how to show that without doing a limit. How would I go about finding that?","['limits', 'sequences-and-series', 'real-analysis']"
3830707,Are endpoints critical points?,"In the function $f(x)=\max\{\sin (x),\cos (x)\}$ for all $x$ belonging to $(0,2π)$ , can we count end points of the domain as critical points, since a function is not differentiable at endpoints?","['maxima-minima', 'calculus', 'derivatives', 'domain-theory']"
3830721,Proof by mathematical induction for matrices,"Let $N=((n_{ij}))$ be a $n\times n$ matrix with entries $n_{ij}= 1$ for all $1\le i, j\le n$ . $(i)$ Show that $N^2 = nN$ . I would like to use mathematical induction for the proof. For my base case, I let the square matrices to be $2 \times 2$ , and then I assume it is true for all square $n \times n$ matrices. However, when I am going to prove it is also true for all square matrices $(n+1)\times (n+1)$ , I was stuck in presenting my proof, like how can I present my proof without drawing completely the square matrices $(n+1) \times (n+1)$ out?","['matrices', 'induction', 'proof-writing', 'linear-algebra']"
3830737,When do total and partial derivatives commute?,"In Classical Mechanics, the Lagrangian is a function of a generalized coordinate $q$ , the corresponding generalized velocity $\dot{q}$ , and time $t$ . For the Lagrangian, $$\dfrac{d}{dt}\frac{\partial L}{\partial \dot{q}} \neq \frac{\partial \dot{L}}{\partial \dot{q}},$$ that is, the two derivatives do not commute. However, what if $L$ were a function only of $q$ and $t$ ? Then would the total derivative in $t$ and the partial derivative in $q$ always commute? Also, for $L(q, t)$ ,  is $\frac{\partial \dot{L}}{\partial \dot{q}}$ always equal to $\frac{\partial L}{\partial q}$ ?","['partial-derivative', 'multivariable-calculus', 'derivatives']"
3830806,Does the equality coefficients of linear regression of X onto Y and Y onto X imply coincidence of the lines?,"Let's assume that we consider the model without an intercept $\hat{y_i} = x_i\hat{\beta}$ . So, the formula for $\hat{\beta}$ is $\frac{ \sum\limits_{i=1}^n x_i y_i}{\sum\limits_{j=1}^n x_j^2}$ . I know that $\hat{\beta}_{XY}$ = $\hat{\beta}_{XY}$ if and only if $ \sum\limits_{j=1}^n x_j^2 = \sum\limits_{j=1}^n y_j^2$ (Here, $\beta_{XY}$ means regression coefficient of $X$ onto $Y$ ). If some of the squares indeed equal, we have that $\hat{\beta}_{XY}$ = $\hat{\beta}_{XY}$ , however I don't understand whether it implies  the coincidence of the lines.","['linear-regression', 'calculus', 'parameter-estimation', 'statistics']"
3830826,"Find $\iint_{D} y^{3}\,dx\,dy$","$$\iint_{D} y^{3}\,dx\,dy$$ where $D$ is the domain between $x^2 + y^2 = 6$ circle and the parabola $y=x^2$ Edit: Also, I got the intersection of the curves $(\sqrt2,2)$ and $(\sqrt-3, -3)$ I draw the curves but I got confused at the bounds of the integrals.","['integration', 'multivariable-calculus', 'multiple-integral']"
3830873,Proving the map $\Psi: \mathcal{V}_pM\to T_pM$ defined by $\Psi[\gamma] = \gamma'(0)$ is well defined and bijective.,I am reading Professor Lee's Intro to Smooth Manifolds book and one of the problems asks the following. How would you approach a proof to this? Also do I need to prove it is well defined? Or is that just a byproduct? Thank you for your time and help! Let $M$ be a smooth manifold with or without boundary and $p\in M.$ Let $\mathcal{V}_pM$ denote the set of equivalence classes of smooth curves starting at $p$ under the relation $\gamma_1 \sim \gamma_2$ if $(f\circ \gamma_1)'(0) = (f\circ \gamma_2)'(0)$ for every smooth real-valued function $f$ defined in a neighborhood of $p.$ Show that the map $\Psi: \mathcal{V}_pM\to T_pM$ defined by $\Psi[\gamma] = \gamma'(0)$ is well defined and bijective.,"['tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
3830914,Is the formula for standard error for the slope of a linear regression with intercept the same as without?,If we are given sets $X$ and $Y$ . The standart error formula for $\alpha$ coefficient of the regrssion $\hat{y} = \alpha x + \beta$ is $$ \frac{\sum{(y_i -\hat{y})^2}/(n-2)}{\sqrt{\sum(x_i-\bar{x})^2}}$$ How the formula for $S.E(\alpha)$ would change if we considered $\hat{y} = \alpha x$,"['linear-regression', 'statistics', 'parameter-estimation']"
3830933,Proving $\frac{1+\cos\theta}{\sec\theta-\tan\ \theta}+\frac{\cos\theta-1}{\sec\theta+\tan\ \theta}=2+2\tan\ \theta$,Prove this trigonometric identity: $$\frac{1+\cos\theta}{\sec\theta-\tan\ \theta}+\frac{\cos\theta-1}{\sec\theta+\tan\ \theta}=2+2\tan\ \theta$$ I've simplified it until $$\frac{2\cos^2\theta}{1-\sin\theta}$$ but couldn't get $2+2\tan\theta$ from it.,['trigonometry']
3830971,Why $\cot^{-1}x$ is an odd function in Mathematica,"The function $f(x)=\cot^{-1} x$ is well known to be neither even nor odd because $\cot^{-1}(-x)=\pi-\cot^{-1} x$ . it's domain is $(-\infty, \infty)$ and range is $(0, \pi)$ . Today, I was surprised to notice that Mathematica treats it as an odd function, and yields its plot as given below: How to reconcile this ? I welcome your comments. Edit: I used: Plot[ArcCot[x], {x, -3, 3}] there to plot","['even-and-odd-functions', 'algebra-precalculus', 'trigonometry']"
3831023,"Can a function have partial derivatives, be continuous but not be differentiable?","I have a function: $$    
f(x,y)=
    \begin{cases}
      \dfrac{2x^2y+y^3}{x^2+y^2} & \text{if $(x,y) \neq (0,0)$}\\
      0 & \text{if $(x,y) = (0,0)$}\\
    \end{cases}
$$ which I think I managed to show: a) continuity at $(0,0)$ by $\lim_{(x,y) \to (0,0)} f(x,y) = 0$ b) has partial derivatives at $(0,0)$ by the definition of derivatives and found $f'_x(0,0) = 0, f'_y(0,0) =1$ . Still not 100% sure if did this correctly. c) not differentiable at $(0,0)$ by definition of differentiable functions and that a limit didn't exist. However, I feel like because of this I can tell more about the function. I'd like it if someone can confirm this. I assumed, that because
it wasn't differentiable, the partial derivatives might not be continuous around $(0,0)$ . $$\frac{\partial f}{\partial x} = \frac{2y^3x}{\left(x^2+y^2\right)^2}$$ $$\frac{\partial f}{\partial y} =   \frac{y^4+y^2x^2+2x^4}{\left(x^2+y^2\right)^2}$$ Is that the case? I checked the limits $$\lim_{(x,y) \to (0,0)} \frac{\partial f}{\partial x} \quad \text{and} \quad \lim_{(x,y) \to (0,0)} \frac{\partial f}{\partial y}$$ and they don't seem to exist. What would happen if one existed but not the other? Is this possible? What would happen if the limit was something else than $0$ and $1$ I calculated in b)? Just not being continuous? I am just worried if the function really has partial derivatives in $(0,0)$ . Thank you in advance!","['partial-derivative', 'continuity', 'multivariable-calculus', 'derivatives']"
3831071,"Consider $f:\{1,\cdots,n\} \to \{1,\cdots, m\}$ How many different functions f exist?","Could someone please help me understand the question that I recently received in one of my courses at Uni: Q:
Consider $f:\{1,\cdots,n\} \to \{1,\cdots,m\}$ . That is for all $x ∈ \{1,\cdots,n \}$ a function value $f(x) ∈ \{1,\cdots,m\}$ is defined (note, both are discrete sets). How many different functions $f$ exist? I nether understand the question, nor do I grasp the concept of functions and relations in regards to sets. When I think about functions, I think about polynomials and trigonometric functions. Therefore, for me, functions consist of a domain, a range, and a rule that explains how each element in the domain gets mapped to an element in the range. If I apply this reasoning to the problem given to me I would assume that at most there exists $n$ to the $m$ amount of functions, if there exists a function for each association between the input and the output. However, at the same time, it could be that each association between the input and the output is due to one function e.g. $\sin(x)$ . How many different functions exist? What am I not understanding?","['elementary-set-theory', 'functions']"
3831142,Can someone please prove this limit via the squeeze theorem,"Can someone please prove that this limit exists using squeeze theorem? $$\lim_{x,y\to 0,0}\frac{5x^2y}{x^2+8y^2}.$$ Another question I've to ask is for $$y = x^2$$ can we not prove that the limit does not exist? If the case is true then the limit becomes: $$\lim_{x\to 0}\frac{5x^4}{x^2+8x^4}.$$ .
Can't that limit be solved using L'Hospital's rule and get a value that is not 0?
(Just for reference when we approach from both the axis, the limit is 0). I'm sorry if my framing of the question is messy but TLDR: I saw this question somewhere which shows that a limit exists but when I tried to use different methods of approaching the limit it gave me different answers.",['limits']
3831191,How can I prove that $y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0$ when $x>0$ and $1<y<1.5$?,"I would like to prove that $$y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0$$ for all real numbers $x > 0$ and $1 < y < 1.5$ . This seems true when plotted on WolframAlpha, but I don't know how to prove it. I tried replacing some of the terms using the given inequalities to obtain a simpler function, but any perturbation I make seems to render the inequality untrue. How would you approach this problem?","['multivariable-calculus', 'inequality', 'real-analysis']"
3831196,Prove that $(1\ 2\ 3)$ cannot be a cube of any element in the symmetric group $S_n.$,"Prove that $(1\ 2\ 3)$ cannot be a cube of any element in the symmetric group $S_n.$ If such an element do exist say $a$ then $a^3 = (1\ 2\ 3).$ Let $\text {ord}\ (a) = m.$ So we have $$3 = \text {ord}\ ((1\ 2\ 3)) = \text {ord}\ \left (a^3 \right ) = \frac {m} {\text {gcd}\ (3,m)}.$$ Then it is clear from the above equality that $3\ \mid\ m.$ But this shows that $\text {gcd}\ (3,m) = 3.$ So we have $\text {ord}\ (a) = m = 9.$ This means if $a$ is written as a product of disjoint cycles in $S_n$ then one of the cycles has to be a $9$ -cycle. Certainly $a$ is not a $9$ -cycle for otherwise $a^3$ is the product of three disjoint $3$ -cycles, a contradiction to the given hypothesis. How do I analyze all the other possibilities that may arise here? Any help in this regard will be highly appreciated. Thanks in advance.","['symmetric-groups', 'group-theory', 'abstract-algebra']"
3831257,Does an injective map stay injective under small smooth perturbations?,"Let $M,N$ be smooth two-dimensional connected, oriented, compact Riemannian manifolds with boundaries, and let $f:M \to N$ be smooth and injective . Let $f_t:M \to N$ be a smooth variation of $f$ . Is $f_t$ injective for sufficiently small $t$ ? If that matters, I am fine with assuming that $\det(df)>0$ and $f(\partial M) \subseteq \partial N$ . (although I am not sure if it's needed.) Here is a naive attempt: Suppose that this is not so; then we have $t_n \to 0$ , $x_n \neq y_n 
\in M$ such that $f_{t_n}(x_n)=f_{t_n}(y_n)$ . Since $M$ is compact we have $x_n \to x,y_n \to y$ (modulue subsequences). Thus $f(x)=f(y)$ . Since $f$ is injective, this forces $x=y$ . So, $x_n \neq y_n, x_n,y_n \to x$ and $f_{t_n}(x_n)=f_{t_n}(y_n)$ . Now, if $x \in N^o$ , then $f(x) \in M^o$ (since $df_x$ is non-singular), so by the inverse function theorem, applied to $f_t|_{M^o}:M^o \to N^o$ at $x$ , $f_t$ is injective in a neighbourhood of $x$ . This might be contradictory with $x_n,y_n \to x$ , if we can quantify the size of the neighbourhood where the IFT gives us injectivity, independently of $t$ for small $t$ . (see e.g. here ). A similar argument should work when $x \in \partial M$ . Can this approach work? Are there other approaches? Or is there a counter-example?","['differential-topology', 'smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3831268,Area as a complex number?,"So I was trying to solve the following integral - $$I=\int_{2006}^{2020} \frac{\ln^{i}(\psi^{i})}{\psi} d\psi$$ Wasn't that bad actually (you can find the question and it's solution here ). But I wasn't expecting the answer to be a complex number ( $I \approx 0.00064 + 0.0013i$ ). So my question is : Can the area under a graph be interpreted as a complex number? If so, how? Is this something common for functions that involve complex numbers? (imaginary powers for example) Finally, is this even an area?","['integration', 'intuition', 'calculus', 'complex-numbers']"
3831286,Proof that $\mathbb R$ excluding countable set is bijective to all reals,I need to prove that $\mathbb{R}\setminus C\sim\mathbb{R}$ where $C$ is a countable set. I have done the proof for $\mathbb{R}\sim\mathbb{R}\cup C$ but am running into issues where natural numbers may be finite in either of the sets for the first one.,"['elementary-set-theory', 'real-analysis']"
3831287,Asymptotic behaviour of integral. How should I proceed?,"Let us consider the following SDE: $$dY_t=b(Y_t)dt+\sigma(Y_t)dW_t\tag{1}$$ with $b, \sigma: (l, r)\to\mathbb{R}$ , $−\infty \leq l < r \leq \infty$ bounded functions on compact intervals of $(l, r)$ . In particular, $$b(Y_t)=(u-(u+i)Y_t)$$ $$\sigma(Y_t)=o\sqrt{(Y_t)(1-Y_t)}$$ with $u$ , $i$ and $o$ arbitrary parameters. Hence, focus will be on the following SDE: $$dY_t=(u-(u+i)Y_t)dt+o\sqrt{(Y_t)(1-Y_t)}dW_t\tag{2}$$ I must check whether the process $\{X_t\}$ remains within the interval $(l,r)$ or not for each $0\leq t\leq T$ . To this, I use the Feller test for explosions . Such a test requires that the following two integrals must be defined and computed: $$p(x)=\int_c^x \exp\bigg\{-2\int_c^{\xi}\frac{b(\zeta)}{\sigma^2(\zeta)}d\zeta\bigg\}d\xi\tag{3}$$ $$v(x)=\int_c^x\frac{2(p(x)-p(y))}{p\hspace{0.1cm}'(y)\sigma^2(y)}dy\tag{4}$$ with $c\in(l,r)$ . According to Feller test, probability that the process at least touches the bounds of interval $I$ equals $1$ or is less than $1$ according to whether $v(l+)=v(r-)=\infty$ or not. Let us fix $(l,r)=(0,1)$ and $c=\frac{1}{2}$ . I would like to study the asymptotic behaviour of the integral $(4)$ with $c=\frac{1}{2}$ at bounds $l=0$ and $r=1$ , but I have not any experience with analyses like that. Is there a good standard method or is it just a matter of manipulation? Could you please help me understand how could I study asymptotic behaviour of $(4)$ ?","['integration', 'asymptotics', 'real-analysis', 'stochastic-differential-equations', 'stochastic-calculus']"
3831387,"Why are the random variables $X+Y$ and $X-Y$ independent when $X$ and $Y$ are i.i.d $N(0,1)$?","$X,Y\sim N(0,1)$ and are independent, consider $X+Y$ and $X-Y$ . I can see why $X+Y$ and $X-Y$ are independent based on the fact that their joint distribution is equal to the product of their marginal distributions. Just, I'm having trouble understanding intuitively why this is so. This is how I see it :  When you look at $X+Y=u$ , the set $\{(x,u-x)|x\in\mathbb{R}\}$ is the list of possibilities for $X$ and $Y$ . And intuitively, I understand independence of two random variables $A$ and $B$ as, the probability of the event $A=a$ being completely unaffected by the event $B=b$ happening. But when you look at $X+Y=u$ given that $X-Y=v$ , the set of possibilities has only one value $(\frac{u+v}{2},\frac{u-v}{2})$ . So, $\mathbb{P}(X+Y=u|X-Y=v)\neq \mathbb{P}(X+Y=u)$ . Doesn't this mean that $X+Y$ is affected by the occurrance of $X-Y$ ?
So, they would have to be dependent?
I'm sorry if this comes off as really stupid, it has been driving me crazy, even though I am sure that they are independent, it just doesn't feel right. Thank you.","['independence', 'normal-distribution', 'probability']"
3831451,H. Cartan - Differential Calculus. Query?,"In H. Cartan - Differential Calculus (1971) p. 29 he investigates differentiating a bi-linear function $f: E_1 \times E_2 \to F$ where $E_1, E_2, F$ are Banach spaces and $E_1 \times E_2$ the product (presumably Cartesian). He claims $E_1 \times E_2$ to be a Banach space with the obvious rules of addition and scalar multiplication. I think this might be OK if $E_1, E_2$ are one-dimensional, but not otherwise. To be algebraically complete mustn't he instead use the tensor product $E_1 \otimes E_2$ ? Since for $E_1, E_2$ at least two dimensional with bases $\{u_1, u_2\}, \{v_1, v_2\}$ there is a very clear counterexample.... $(u_1, v_1), (u_2, v_1), (u_1, v_2), (u_2, v_2) $ are elements of $E_1 \times E_2$ .
But then $(u_2, v_1) + (u_1, v_2) + (u_2, v_2) $ is not of the form $(u, v)$ and so not in $E_1 \times E_2$ , i.e. $E_1 \times E_2$ is not algebraically closed under addition. I may have mixed up some concepts in the above. It seems that $E_1 \times E_2$ with addition and scalar multiplication as noted by @JohnHughes is the direct sum of $E_1, E_2$ and nothing to do with the tensor product. And then as noted by @JoonasIlmavirta $(u_2, v_1) + (u_1, v_2) + (u_2, v_2) = (u_1 + 2.u_2, v_1 + 2.v_2)$ .","['tensor-products', 'banach-spaces', 'bilinear-form', 'functional-analysis']"
3831483,Another upper bound for the Stirling numbers of the first kind,"It is shown in this question that $${n \brack n-k}\leq\frac{n^{2k}}{2^kk!}.$$ But a sharper bound seems to be $${n \brack n-k}\leq\frac{n^{k}}{2^k}{n-1 \choose k}.$$ I don't see how to derive this inequality.  Any idea? Hereafter is some numerical evidence:  this is a representation of the natural logarithm of $f(n,k)$ as a function of $k$ in the range $1\le k \le n-1$ , for $n=30$ . The red dots are for $f(n,k)={n \brack n-k}$ , the black dots for $f(n,k)=\frac{n^{2k}}{2^kk!}$ and the blue dots for $f(n,k)=\frac{n^{k}}{2^k}{n-1 \choose k}$ .","['inequality', 'binomial-coefficients', 'combinatorics', 'stirling-numbers']"
3831511,Does $SL_2(K) \simeq SL_2(L)$ imply $K\simeq L$?,"Let $K$ and $L$ be two fields. Assume characteristics are not 2. I can show in a quite elementary way that if the statement $SL_2(K) \simeq SL_2(L) \implies K \simeq L$ holds, then for $n \geq 2$ , the statement $SL_n(K) \simeq SL_n(L) \implies K \simeq L$ holds. But I do not know how to prove this for $n=2$ in its full generality. We can of course assume the groups i.e. the fields are infinite, otherwise counting the number of elements should be enough. On the other hand by using any non-central diagonal element as a parameter, one can define the field $K$ in the group $SL_2(K)$ as follows. Let $t_0$ be one such element. Let $T=C_{SL_2(K)}(t_0) \simeq K^*$ (torus). We may regard $T$ as the group of diagonal matrices with determinant 1. There are exactly two abelian subgroups $H$ of $SL_2(K)$ of the form $\langle h^T\cup\{1\} \rangle$ for any $1\neq h \in H$ and with the property that $H \cap Z(SL_2(K))=1$ , the strictly upper and lower triangular matrices, say $U$ and $V$ (unipotent) respectively. (Because $x = (1+x/2)^2 - 1^2 - (x/2)^2$ for any $x\in K$ , see below.) They are both isomorphic to the addive group of $K$ . Choose one of them, say $U$ . The choice does not matter as the automorphism ""transpose inverse"" interchanges them fixing $T$ . Denote the elements of $T$ by $t(x)$ where $x\in K^*$ and elements of $U$ by $u(y)$ where $y\in K$ . Then $T$ acts on $U$ as follows $u(y)^{t(x)} = u(x^2y)$ . Thus we get the subfield of $K$ generated by the squares. But since $x = (1+x/2)^2 - 1^2 - (x/2)^2$ for any $x\in K$ , the subfield generated by the squares is $K$ itself. Thus the field $K$ is definable with one parameter, namely $t_0$ . (Except that the group does not know the unit element 1 of the field, we only get an affine version of a field; to fix 1 of the field $K$ we need one more parameter,  but this is irrelevant to us).
It follows that in the group $SL_2(L)$ both fields $K$ and $L$ are definable. In particular if the automorphism takes a non-central diagonalizable element of $SL_2(K)$ to a non-central diagonalizable element of $SL_2(L)$ , then we will necessarily have $K\simeq L$ . This will be so if we can distinguish diagonalizable elements of $SL_2(K)$ from its non-diagonalizable semisimple elements (i.e. diagonalizable in the algebraic closure) in a group theoretic way. If $K$ and $L$ are algebraically closed, all the semisimple elements will be diagonalizable, so there will be no problem, in this case $K$ will be isomorphic to $L$ .","['group-theory', 'linear-algebra', 'classical-groups']"
3831583,How do we need to apply the chain rule to obtain this identity for the material derivative?,"Let $\tau>0$ , $d\in\mathbb N$ , $v:\mathbb R^d\to\mathbb R^d$ be Lipschitz continuous, $X^x\in C^0([-\tau,\tau],\mathbb R^d)$ be the solution of $$X^x(t)=x+\int_0^tv(X^x(s))\:{\rm d}s\;\;\;\text{for }t\in[-\tau,\tau]\tag1$$ for $x\in\mathbb R^d$ , $$T_t(x):=X^x(t)\;\;\;\text{for }x\in\mathbb R^d$$ for $t\in[-\tau,\tau]$ , $\Omega$ be a $d$ -dimensional properly embedded $C^1$ -submanifold of $\mathbb R^d$ with boundary, $$\Omega_t:=T_t(\Omega)\;\;\;\text{for }t\in[-\tau,\tau],$$ $y_t:\Omega_t\to\mathbb R$ for $t\in[-\tau,\tau]$ . Assume $${\rm d}y_0(\Omega;v):=\left.\frac{\rm d}{{\rm d}t}y_t(T_t(x))\right|_{t=0}\tag2$$ exists and $y_0$ is $C^1$ -differentiable. Let $x\in\bigcap_{t\in[-\tau,\:\tau]}\Omega_t$ . How can we show that $$\left.\frac{\rm d}{{\rm d}t}y_t(x)\right|_{t=0}={\rm d}y_0(\Omega;v)-T_x(y_0)v(x)\tag3,$$ where $T_x(y_0)v(x)$ denotes the pushforward of $v(x)$ by $y(\Omega)$ at $x$ . I think the trick is to write $$y_t(x)-y_0(x)=y_t(x)-y_0(T^{-1}(x))-(y_0(x)-y_0(T^{-1}(x)))\tag4$$ and we may note that $$T_t^{-1}=T_{-t}\;\;\;\text{for all }t\in[0,\tau]\tag5,$$ but I don't know how to conclude.","['diffeomorphism', 'ordinary-differential-equations', 'pushforward', 'smooth-manifolds', 'differential-geometry']"
