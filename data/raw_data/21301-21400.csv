question_id,title,body,tags
180647,Strategy for a game of breaking sticks,"Two persons have 2 uniform sticks with equal length which can be cut at any point. Each person will cut the stick into $n$ parts ($n$ is an odd number). And each person's $n$ parts will be permuted randomly, and be compared with the other person's sticks one by one. When one's stick is longer than the other person's, he will get one point. The person with more points will win the game. How to maximize the probability of winning the game for one of the person. What is the best strategy to cut the stick.","['game-theory', 'probability']"
180694,Relationship between moments of a random variable,"Let $X$ be a random variable with continuous density $\rho(x)$. Assume that $X$ is symmetric and $\vert X\vert<L$. Since it has a bounded support, all moments of $X$ are well-defined. Let $m_i$ denote the moment $i$ of $X$, i.e.
$$
m_i = \int_{-L}^{L} x^i \rho(x) dx.
$$ Is there anyone knows if the following statement is true or not?
$$
\frac{m_2}{2!}\times \frac{m_{4k}}{4k!}\geq \frac{m_{4k+2}}{(4k+2)!}.
$$
for $k\geq 1$. Note that one may rewrite the above equation as
$$
{4k+2\choose 2} m_2m_{4k}\geq m_{4k+2}.
$$
The Above recursion is true for some common distributions such as uniform distribution and Gaussian distribution (even though it does not have a bounded support) but can we say in general if it is true? If not, what are the necessary conditions to make it true? For example, if $m_2>L^2/15$ then it is true. But is there any other condition available with less restriction?","['probability-theory', 'generating-functions', 'probability-distributions']"
180698,Easy way to find roots of the form $qi$ of a polynomial,"Let $p$ be a polynomial over $\mathbb{Z}$, we know that there is an easy way to check if $p$ have rational roots (using the rational root theorem ). Is there an easy way to check if $p$ have any roots of the form $qi$ where $q\in\mathbb{Q}$ (or at least $q\in\mathbb{Z}$) ? ($i\in\mathbb{C}$) ?","['algebra-precalculus', 'roots', 'polynomials']"
180708,Subspaces of separable normed spaces,"Let $X$ be a separable normed space. Is it true that every subspace is separable?
If it was Hilbert space I would take the dense set and then their projections. 
It sounds trivial but I cannot prove or disprove it... Thank you.","['general-topology', 'normed-spaces', 'functional-analysis']"
180715,Understanding an Outer Automorphism of $S_6$,"In an article (paper) , there is a description of an outer automorphism of $S_6$. There are six pentagons, arranged with a rule, with vertices $1,2,3,4,5$. Any permutation of these vertices will permute the six pentagons, hence giving a map (homomorphism) from $S_5$ into $S_6$. I understood this map as follows: if we interchange the vertices, the pentagons will be permuted. Consider permutation $(2 \,3)$, and its effect on the first pentagone a in the note . (1) In a , vertices $2,3$ are not joined by a ""continuous edge"", hence after permuting $2,3$ there should not be continuous edge between $2,3$. Hence image of a after this permutation will be either a,d or f (am I correct?). Also, 5 is joined to both $2,3$ before permutation, hence after permuting $2,3$, vertex $5$ should be adjcent to them. We can conclude that a is mapped to a by permutation $(2\,3)$. (2) The other way, in a , $2,3$ are not joined by continuous edge before permutation $(2\,3)$. Hence after permuting $2,3$, a would be mapped into 
either a,d or f . Also, $4$ is joined to $2$ but not $3$ before permuting $2,3$; after permuting $2,3$, the vertex $4$ will be  joined to $3$ but not $2$; hence image of a by permutation $(2\,3)$ should be d . I couldn't find my mistake in understanding, if any. Can one explain the action of $S_5$ on the six pentagons in the article?",['group-theory']
180723,Same Morse coordinates for different Morse functions,"Let $f,g\in C^\infty(\mathbb R^n;\mathbb R)$ be two Morse functions having both a critical point at $0$. Is it always possible to find local coordinates around $0$ such that both $f $ and $g$ become quadratic in the new coordinates? After the comment of Matt, I realized that i forgot an important assumption: $0$ is a critical point of index $0$ of $f$.","['multivariable-calculus', 'linear-algebra', 'analysis']"
180727,What will be the minimum value of $\frac{p^2}{\tan9^\circ} + \frac{q^2}{\tan27^\circ} + \frac{r^2}{\tan63^\circ} + \frac{s^2}{\tan81^\circ}$?,"What will be the minimum value of
$$\frac{p^2}{\tan9^\circ} + \frac{q^2}{\tan27^\circ} + \frac{r^2}{\tan63^\circ} + \frac{s^2}{\tan81^\circ}$$ if 
$$p+q+r+s=5$$ where $p, q, r, s$ are positive reals?
I tried applying AM-GM inequality but it didn't help.","['trigonometry', 'algebra-precalculus']"
180728,"Prove that a finite set of points $z_1,z_2,......,z_n$ cannot have any accumulation points.","How can I prove a finite set of points $z_1,z_2,......,z_n$ on the complex plane cannot have any accumulation points.please give me some hints.","['complex-numbers', 'complex-analysis']"
180730,Markov property w.r.t. a countable state space,"Background Let $\left(X_t\right)_{t \in I}$ ($I\subseteq\mathbb R$) be an $E$-valued stochastic process ($E$ being a Polish space with the Borel $\sigma$-algebra $\mathcal{B}\left(E\right)$) equipped with the filtration generated by $X$, $\left(\mathcal F_t\right)_{t\in I}=\left(\sigma\left(X_s\space:\space s\leq t\right)\right)_{t\in I}$. Suppose $E$ is countable. Question Why is it the case (as claimed in Klenke , Remark 17.2 ) that if for all $n\in\mathbb N$, all $s_1<\cdots<s_n<t$ and all $i_1,\dots,i_n,i\in E$ with $\mathbb{P}\left[X_{s_1}=i_1,\dots,X_{s_n}=i_n\right]>0$ we have $$\mathbb{P}\left[\left.X_t=i\space\right|\space X_{s_1}=i_1,\dots,X_{s_n}=i_n\right]=\mathbb{P}\left[\left.X_t=i\space\right|\space X_{s_n}=i_n\right]$$ then the Markov property applies, namely $$\forall s\leq t\in I\bullet\mathbb{P}\left[\left.X_t\in A\space\right|\space\mathcal{F}_s\right]=\mathbb{P}\left[\left.X_t\in A\space\right|\space X_s\right]$$","['probability-theory', 'stochastic-processes', 'markov-process']"
180732,Why some differential equation can be solved while similar difference equations cannot?,Take an equation $$w'+w-w^2-1=0$$ Its solution is $$w(x)=\frac{\sqrt{3}}{2} \tan \left( \frac{\sqrt{3}}2 C+\frac{\sqrt{3}}2 x\right)+\frac12$$ I wonder why a similar difference equation $$\Delta w+w-w^2-1=0$$ cannot be solved?,"['ordinary-differential-equations', 'finite-differences', 'recurrence-relations']"
180740,What are the requirements for separability inheritance,"Suppose we have an arbitrary separable topological space $X$. What are some (possibly nonequivalent) minimal requirements to put on $X$ to ensure that every subspace of $X$ is separable? This is not true for arbitrary spaces, as witnessed by the the space $X$ which is uncountable, where open sets are precisely the sets containing some special point $x_0$. It is separable (because $\lbrace x_0\rbrace$ is dense), but $X\setminus \lbrace x_0\rbrace$ is uncountable and discrete, so not separable. However, this space is not even $T_1$ (though it is $T_0$). It is clearly true for second-countable spaces (because weight is not smaller than density, and is inherited), but that is not necessary, as shown by an example similar to the above, but with $X$ countable. Analogous question could be asked replacing $\aleph_0$ with arbitrary infinite cardinal $\kappa$: suppose we have a space $X$ with a dense subset of cardinality at most $\kappa$, what should we require of $X$ for this to be inherited? In this case we can perform the analysis which is exactly analogous to the above, but perhaps some more concrete results will be harder to arrive at with uncountable $\kappa$... So I really have two somewhat related questions. In terms of cardinal invariants density $d$ and hereditary density $hd$, what requirements do we have to put on $X$ to have some of the following: (Only for $X$ separable) $hd(X)\leq\aleph_0$ $d(X)= hd(X)$ By analysis similar to the above we know that 2. is not true in general, as well as that $d(X)=w(X)$ implies 2, but is not necessary. I would appreciate some conditions which would imply either one, or some nice counterexamples which satisfy some stronger separation axioms than just $T_0$ (if there are any, I think there should be...), or a proof that there are none. Edit: 
Sam L. suggested the example of Niemytzki plane, which shows that even somewhat strong separation axioms are not sufficient: it is completely regular and separable and of countable character, but has an uncountable discrete subspace. It is not hard to see that by taking a suitable subspace, we can strengthen it to $w(X)=\aleph_1$ (regardless of CH), and itself is a counterexample for all $\kappa<\mathfrak c$. Edit 2:
As per Arthur Fischer's suggestion, if we take an arbitrary nontrivial second-countable compact Hausdorff space $X$ (such as $2$ with discrete topology or $[0,1]$), $X^\mathfrak c$ will be separable (because product of at most $\mathfrak c$ separable spaces is separable), as well as Hausdorff and compact, and hence normal, but it has a discrete subspace of cardinality $\mathfrak c$.  This shows that no usual separation axioms will suffice, not even augmented by compactness.","['general-topology', 'examples-counterexamples', 'separable-spaces', 'reference-request']"
180741,Groups quasi-isometric to $\mathbb{Z}^n$,"I am interested by the following result: A group quasi-isometric to $\mathbb{Z}^n$ is virtually $\mathbb{Z}^n$ . I know the article Harmonic analysis, cohomology, and the large-scale geometry of amenable groups by Yehuda Shalom, but currently I don't have any access to it. Do you know another document on this subject?","['reference-request', 'geometric-group-theory', 'group-theory']"
180742,How to do a regression with only integer values and a fixed intercept?,"I need to write some code for an application that takes in a series of 2D points whose values are integers, and determines a polynomial regression that passes through the origin. I know how to do this via a CAS, but is anyone familiar with the math behind a regression of this type?","['statistics', 'regression']"
180744,Compute $\int \frac{\sin(x)}{\sin(x)+\cos(x)}\mathrm dx$,"I'm having trouble computing the integral:
$$\int \frac{\sin(x)}{\sin(x)+\cos(x)}\mathrm dx.$$
I hope that it can be expressed in terms of elementary functions. I've tried simple substitutions such as $u=\sin(x)$ and $u=\cos(x)$, but it was not very effective. Any suggestions are welcome. Thanks.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
180760,When to read of the degree of a variety from its defining polynomials,"The question concerns algebraic varieties. I just read the question The degree of an algebraic curve in higher dimensions and great answer by user M P. One of the thing he says is that if a curve in $\mathbb{P}^n$ is given by $n-1$ equations (which is often not the case of course), then its degree is in fact the product of the degree of the polynomials defining it. I expect this not to hold if there are more than $n-1$ polynomials necessary to define the curve. Could someone tell me if this is true, and why? I do expect it to hold for general varieties. If a variety in $\mathbb{P}^n$ is of codimension $r$, and also given by exactly $n-r$ polynomials, is its degree in fact the product of the degrees of the polynomials defining it? Could you tell me if this is the case, and more importantly: why? By the way, degree as in generic number of intersection points with a variety of complementary dimension.. Thanks a lot in advance,
Joachim P.S. Georges E. i owe you one for your effort on my question on étale morphisms. I know this is not the place to say such things, but i'm doing it anyway.","['intersection-theory', 'algebraic-geometry', 'algebraic-curves']"
180764,Pick out the true statements complex analysis,"Pick out the true statements: (a) There exists an analytic function $f$ on $\mathbb{C}$ such that $f(2i) = 0$, $f(0) = 2i$
and $|f(z)|\le 2$ for all $z\in\mathbb{C}$ .
(b) There exists an analytic function $f$ in the open unit disc $\{z\in\mathbb{C} : |z| < 1\}$
such that $f(1/2) = 1$ and $f(1/2^n ) = 0$ for all integers $n\ge 2
$. (c) There exists an analytic function  whose real part is given by
$u(x, y) = x^2 + y^2$, where $z = x + iy$.",['complex-analysis']
180765,Determine whether a $3\times3$ matrix has a positive eigenvalue?,Given a $3\times3$ matrix is there a criterion capable of telling whether the matrix has a positive eigenvalue?,"['matrices', 'eigenvalues-eigenvectors']"
180781,Find $f(x)$ from $f(3x + 1)$,"The problem that I have to solve is: If the following function is valid for every value of $x$ $$f(3x + 1) = 9x^2 + 3x$$ find the function $f(x)$ and prove that for every $x\in\mathbb R$ the following is valid: 
$$f(2x) - 4f(x) = 2x$$",['algebra-precalculus']
180783,Implicit function theorem,"Suppose I have the curve $\gamma: \mathbb{R} \rightarrow \mathbb{R}^2$ given by $\gamma: t \mapsto (\gamma_1(t),\gamma_2(t)) =(t^2,t)$. If I want to apply the implicit function theorem to this to see if  $\gamma_1$ can be expressed in $\gamma_2$ at $t=0$ then I need to show that $d \gamma_2 / d \gamma_1$ is non-zero. However, $d \gamma_2 / d \gamma_1 \rightarrow \infty $ for  $t \rightarrow 0$. So in these cases you cannot apply the implicit function theorem? Or can I just compactify the plane by ""adding the point at infinity"" and then apply the implicit function theorem.",['differential-geometry']
180807,Fundamental and the anti-fundamental representation of $U(n)$,"I guess that conventionally one thinks of the fundamental representation and the anti-fundamental representation of $U(n)$ as the complex $n-$dimensional representation and its complex conjugate. But $U(n)$ being a rank $n$ group shouldn't there be $n$ fundamental representations of it corresponding to the $n$ fundamental weights of it (dual to its $n$ simple roots)? In the fundamental representation I think of the Cartan of ${\cal u}(n)$ to be spanned by the $n$ diagonal matrices of ${\cal u}(n)$ which have all $0$s except a $1$ then I guess the $n$ vectors $(0,..,1,..0)$  (the $1$ shifting through the $n$ positions) can be thought of as the $n$ weight-vectors of the representation? And the same vectors with the $1$ replaced by $-1$ be thought of as the weight vectors of the anti-fundamental representation? (since conjugate transpose of any element of ${\cal u}(n)$ is negative of it?) Naively the above does seem to depend on whether I think of the Lie algebra of $U(n)$ to be $n\times n$ Hermitian or skew-Hermitian matrices depending on whether or not I have an ""$i$"" while taking the exponentiation from the Lie algebra. It would be helpful if someone can help disentangle this (possibly there is being a mix of what is an intrinsic property of the group and what is convention) Is there an analogoue of the above construction for $U(n)$?","['lie-algebras', 'representation-theory', 'mathematical-physics', 'lie-groups', 'group-theory']"
180826,In which topological spaces is every singleton set a zero set?,"The title question says it all: if $X$ is a topological space, then a subset $Z$ of $X$ is a zero set if there is a continuous function $f: X \rightarrow \mathbb{R}$ with $Z = f^{-1}(0)$ . Now I know the following: Every zero set is a closed subset. Every closed subset is a zero set iff $X$ is perfectly normal , e.g. if $X$ is metrizable. Every closed subset is an intersection of zero sets iff $X$ is Tychonoff. What I want to know is whether there is a similarly clean characterization of topological spaces $X$ such that for every point $x \in X$ , there is a continuous function $f: X \rightarrow \mathbb{R}$ vanishing only at $x$ .  In particular, is there a compact (Hausdorff!) space that does not have this property? Added : Having gotten some nice answers, maybe I should say a little more about my ulterior motive (which is sort of a motive in a teapot).  I was mulling over a recent note of B. Sury in which he shows that in the ring $C([0,1])$ of continuous functions $f: X \rightarrow [0,1]$ , for any $c \in [0,1]$ , the maximal ideal $\mathfrak{m}_c$ of all functions vanishing at $c$ is not only infinitely generated (as is standard: I think this was a question on a qualifying exam I took as a graduate student!) but uncountably generated.  I was thinking of generalizations to rings of continuous functions on other spaces $X$ . There is, it seems to me, a very small gap in his proof: about the function $f$ he constructs, he writes ""since $f$ vanishes only at $c$ "".  He hasn't argued for this, and depending on the choices of the sequence $\{f_n\}$ , $f$ might vanish at other points.  But no problem: if $\mathfrak{m}_c = \langle f_1,\ldots,f_n,\ldots \rangle$ , since there is obviously some continuous function on $[0,1]$ which vanishes only on $c$ (e.g. $I(x) = |x-c|$ ), if $\bigcap_{n=1}^{\infty} f_n^{-1}(0) \supsetneq \{c\}$ then these functions cannot generate $\mathfrak{m}_c$ . If I am not mistaken, the following is a straightforward generalization of Sury's result. Theorem: Let $X$ be a compact (Hausdorff!) space, and let $c \in X$ .  Suppose that there is a continuous function $I: X \rightarrow \mathbb{R}$ such that $I^{-1}(0) = \{c\}$ .  Then the following are equivalent: (i) The point $c$ is isolated in $X$ . (ii) The ideal $\mathfrak{m}_c$ is principal. (iii) The ideal $\mathfrak{m}_c$ is finitely generated. (iv) The ideal $\mathfrak{m}_c$ is countably generated. Well, this would be a better result without the weird hypothesis about the existence of $I$ .  Hence the question.  (Maybe someone can see a better way to get around this hypothesis or replace it with something more natural...) By the way, compactness also feels a little too strong here.  This is being used to ensure that $C(X)$ is a Banach space under the supremum norm, but maybe there's a way around this as well.",['general-topology']
180832,To find the closed form of $ f^{-1}(x)$ if $3f(x)=e^{x}+e^{\alpha x}+e^{\alpha^2 x}$,"$$3f(x)=e^{x}+e^{\alpha x}+e^{\alpha^2 x}$$  where $\alpha=e^{\frac{2\pi i}{3} }$ I would like to find a closed form of $ f^{-1}(x)$ $$f(x)=\sum \limits_{k=0}^\infty \frac{x^{3k}}{(3k)!}$$ We can see easily that $f'''(x)=f(x)$ $$f(x)=f(\alpha x)=f(\alpha^2 x)=\frac{e^{x}+2e^{-\frac{x}{2}} \cos{\frac{x\sqrt{3}}{2}}}{3}=$$ $\alpha^3=1$ $\alpha^2+\alpha+1=0$ $\alpha=e^{\frac{2\pi i}{3} }=-\frac{1}{2}+i\frac{\sqrt{3}}{2}$ My first attempt to find $f^{-1}(x)$: $$3x=e^{f^{-1}(x)}+e^{\alpha f^{-1}(x)}+e^{\alpha^2 f^{-1}(x)}$$ $$p(x)=e^{f^{-1}(x)}$$ $p+p^{\alpha }+p^{\alpha^2 }=3x$ $$p'(p+(-\frac{1}{2}+i\frac{\sqrt{3}}{2}) p^{\alpha}+(-\frac{1}{2}-i\frac{\sqrt{3}}{2})p^{\alpha^2 })=3p$$ $$p'(p+(-\frac{1}{2}+i\frac{\sqrt{3}}{2}) p^{\alpha}+(-\frac{1}{2}-i\frac{\sqrt{3}}{2})p^{\alpha^2 })=3p$$ $$p'(p -\frac{1}{2}(p^{\alpha }+p^{\alpha^2 })+i\frac{\sqrt{3}}{2} (p^{\alpha}-p^{\alpha^2 })=3p$$ $$i\frac{\sqrt{3}}{2} (p^{\alpha}-p^{\alpha^2 })=\frac{3p}{p'}+\frac{3x}{2}-\frac{3p}{2}$$ $$-\frac{3}{4} (p^{2\alpha}+p^{2\alpha^2 }-2p^{-1})=(\frac{3p}{p'}+\frac{3x}{2}-\frac{3p}{2})^2$$ $-\frac{3}{4} ((3x-p)^2-4p^{-1})=(\frac{3p}{p'}+\frac{3x}{2}-\frac{3p}{2})^2$ After here ,I am not sure that there is an easy solution. Maybe someone can give hint what to do for next step. My second attempt to find $f^{-1}(x)$: $f(g(x))=x$  ---> where $g(x)=f^{-1}(x)$ $$f'(g(x))g'(x)=1$$ $$f'(g(x))=\frac{1}{g'(x)}$$ $$f''(g(x))g'(x)=(\frac{1}{g'(x)})'$$ $$f''(g(x))=\frac{1}{g'(x)}(\frac{1}{g'(x)})'$$ $$f'''(g(x))g'(x)=(\frac{1}{g'(x)}(\frac{1}{g'(x)})')'$$ $$f(g(x))g'(x)=(\frac{1}{g'(x)}(\frac{1}{g'(x)})')'$$ $$f(g(x))=x=\frac{1}{g'(x)}(\frac{1}{g'(x)}(\frac{1}{g'(x)})')'$$ $$\frac{1}{g'(x)}=u(x)$$ $$u[uu']'=x$$ $$u u'^2+u^2u''=x$$ if $u=z^{1/2}$ then $$z^{1/2}z''=2x$$ Here again, I do not know how to solve that differential equation. Any hint to solve it? I also would like to share  some interesting property of that function. $9f^2(x)=(e^{x}+e^{\alpha x}+e^{\alpha^2 x})^2=e^{2x}+e^{\alpha 2x}+e^{\alpha^2 2x}+2(e^{-x}+e^{-\alpha x}+e^{-\alpha^2 x})$ $$3f^2(x)=f(2x)+2f(-x)$$ 
$$f(2x)=3f^2(x)-2f(-x)$$ Could you please advice a method to find $f^{-1}(x)$ in closed form such as integral expression of elementary functions. (Actually, I am looking for an expression that it is similiar to $\arcsin(x)=\int\frac{1}{\sqrt{1-x^2}}dx$, if possible) Thank you for hints and for answers.","['ordinary-differential-equations', 'special-functions', 'functions']"
180847,Calculating a Multivariable derivative.,"I'm trying to work through Spivak's Calculus on Manifolds and I've arrived at Differentiation.  While I can usually follow his steps, I find myself lost or stuck when I try to do something on my own.  So I decided to work through one of his first examples using $Df$ notation instead of $f'$ notation. My main point, I have confused myself.  My question is clearly asked only at the very bottom of this post. As for the example, I need to calculate the derivative of $f:\mathbb{R}^{2}\to \mathbb{R}$,
where
$$f(x,y) = \sin(xy^2).$$ The following rules are available to me: 1) For a point $a$ in the domain of $f$ such that $f(a)$ is in the domain of $g$,
$$D(g\circ f)(a) = Dg(f(a))\circ Df(a).$$ 2) For two functions $f,g:\mathbb{R}^{n}\to \mathbb{R}$, 
$$D(fg)(a) = g(a)Df(a) + f(a)Dg(a)$$ and $$D(f+g)(a) = Df(a) + Dg(a).$$ If I have stated either of these rules even slightly incorrectly please be brutally in my face about it. I'm trying to carefully apply this rules to my function. If I let $p,s:\mathbb{R}^{2}\to \mathbb{R}$ denote the product function and $s:\mathbb{R}\to \mathbb{R}$ represent the squaring function, I can write: $f = \sin\circ p\circ (\pi_{1}, s\circ \pi_{2})$, where $\pi_{1}$ and $\pi_{2}$ are the coordinate functions. Now my derivative of $f$, denoted $Df$, should be a map from $\mathbb{R}^{2}\to \mathbb{R}$, just like $f$ is. So at a point $(a,b)\in \mathbb{R}^{2}$, I can write \begin{align*}
Df(a,b) &= D\left(\sin\circ p\circ (\pi_{1}, s\circ \pi_{2})\right)(a,b)\\
        &= D(\sin)(p\circ (\pi_{1}, s\circ \pi_{2})(a,b))\circ Dp((\pi_{1}, s\circ \pi_{2})(a,b))\circ D(\pi_{1}, s\circ \pi_{2})(a,b)
\end{align*} So I try to calculate this in separate blocks: \begin{align*}
D(\sin)(p\circ (\pi_{1}, s\circ \pi_{2})(a,b)) &=  \cos(p\circ (\pi_{1}, s\circ \pi_{2})(a,b))\\
&= \cos(p\circ (\pi_{1}(a,b), [s\circ \pi_{2}](a,b)))\\
&= \cos(p\circ (a, s(b)))\\
&= \cos(p\circ (a, b^2)))\\
&= \cos(ab^2).
\end{align*} But this brings me to my first (among several) points of confusion. In the equation:
$$Df(a,b) = D(\sin)(p\circ (\pi_{1}, s\circ \pi_{2})(a,b))\circ Dp((\pi_{1}, s\circ \pi_{2})(a,b))\circ D(\pi_{1}, s\circ \pi_{2})(a,b)$$
it appears $D(\sin)(p\circ (\pi_{1}, s\circ \pi_{2})(a,b))$ should be a function, not a number.  Can someone point out what my error in thinking is? (answered below) Continuing on to compute the 3rd block, \begin{align*}
D(\pi_{1}, s\circ \pi_{2})(a,b) &= (D\pi_{1}(a,b), D(s\circ \pi_{2})(a,b))\\
&= (\pi_{1}(a,b), Ds(\pi_{2}(a,b))\circ D\pi_{2}(a,b))\\
&= (a, Ds(b)\circ \pi_{2}(a,b))\\
&= (a, 2b\circ b)\\
&= (a, 2b^2)
\end{align*} Now the middle one: \begin{align*}
Dp((\pi_{1}, s\circ\pi_{2})(a,b)) &= Dp((\pi_{1}(a,b), (s\circ \pi_{2})(a,b))\\
&= Dp(a, b^2)
\end{align*} Now substituting these smaller calculations, the whole thing simplifies down to:
\begin{align*}
Df(a,b) &= D(\sin)(p\circ (\pi_{1}, s\circ \pi_{2})(a,b))\circ Dp((\pi_{1}, s\circ \pi_{2})(a,b))\circ D(\pi_{1}, s\circ \pi_{2})(a,b)\\
&= \cos(ab^2)\circ \underbrace{Dp(a, b^2)\circ (a, 2b^2)}_{= a\cdot 2b^2 + b^2\cdot a}\\
&= \cos(ab^2)(3ab^2)
\end{align*} Now I will insist that I have something wrong.  $Df(a,b)$ should be a map from $\mathbb{R}^{2}\to \mathbb{R}$. But it has collapsed into a single real number. Spivak calculates the derivative using Jacobian notation, arriving at the conclusion that
$f'(a,b) = (b^2\cdot\cos(ab^2), 2ab\cdot \cos(ab^2))$, which naturally is the transformation matrix for a map $\mathbb{R}^{2}\to \mathbb{R}$. Sorry this problem is so long winded, but I wanted to show all my steps so as to be able to identify the one that went awry.","['multivariable-calculus', 'derivatives', 'differential-geometry']"
180849,Why is the complex number $z=a+bi$ equivalent to the matrix form $\left(\begin{smallmatrix}a &-b\\b&a\end{smallmatrix}\right)$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Relation of this antisymmetric matrix $r = \!\left(\begin{smallmatrix}0 &1\\-1 & 0\end{smallmatrix}\right)$ to $i$ On Wikipedia, it says that: Matrix representation of complex numbers Complex numbers $z=a+ib$ can also be represented by $2\times2$ matrices that have the following form: $$\pmatrix{a&-b\\b&a}$$ I don't understand why they can be represented by these matrices or where these matrices come from.","['matrices', 'complex-numbers', 'linear-algebra', 'quaternions']"
180860,Proving $\sin A + \sin B + \sin C = 4 \cos \frac{A}{2} \cos \frac{B}{2} \cos \frac{C}{2}$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove that $\sin(2A)+\sin(2B)+\sin(2C)=4\sin(A)\sin(B)\sin(C)$ when $A,B,C$ are angles of a triangle Prove trigonometry identity? If $A$, $B$, and $C$ are to be taken as the angles of a triangle, then I beg someone to help me the proof of
$$\sin A + \sin B + \sin C = 4 \cos \frac{A}{2} \cos \frac{B}{2} \cos \frac{C}{2}.$$
Thanks!",['trigonometry']
180874,Convert angle (radians) to a heading vector?,"I have been looking everywhere trying to find out how to convert an angle in radians (expressed as -Pi to Pi) to a heading vector. The only [x,y] answer I have found is, [cos(angle), sin(angle)] , however, this doesn't work! Or am I missing something? I just want a vector pointing at a direction of a specified angle, and for it to have a magnitude of 1, such is called a ""heading vector"" I believe. At least it is in the various game code I look at. CLARIFICATION: A heading vector is a vector with a magnitude of 1 with the start at 0, and the end (the arrowhead) at some value within a unit circle. A heading vector is a way of showing direction as a vector. I want to take an angle and express it as a vector, however, people seem to just be telling me how to do unit conversions. I appreciate you trying to be helpful, however, hopefully these clarifications will guide others to giving more fitting responses. Thanks.","['trigonometry', 'algebra-precalculus', 'vectors']"
180880,Varieties as schemes,"Some questions about schemes and varieties, one really basic. I follow the definitions as given in Hartshorne. Firstly, my main question. I understood that Grothendiecks introduction of schemes revolutionized the subject. Just out of curiosity, could you give me some examples of theorems of techniques about varieties that would be hard or impossible to prove without the language of schemes? Then some more basic questions. I learned about schemes first and then about varieties (which is really weird, i know), so i kind of missed the natural process of seeing it as an enlargement of the category. Of course affine varieties are given as schemes by the Spec functor. Now for a first question, am i correct in the following reasoning? Take a projective variety $V \subset \mathbb{P}^n$, given by an ideal $I(V) \subset k[x_0,\ldots, x_n]$, then the corresponding scheme is $\text{Proj}(k[x_0,\ldots, x_n]/I(V))$, right? It seems right to me but it feels kind of slippery. So if somebody could say yes or no with some short explanation or background that would be great. By the way i did notice that unlike the affine case where there is an equivalence between varieties and rings, here rings that are not isomorphic can give isomorphic projective varieties, right? ($\mathbb{C}[x,y]$ and $\mathbb{C}[x,y,z]/(xz - y^2)$ i guess, certainly not isomorphic rings, but every plane conic is isomorphic to $\mathbb{P}_{\mathbb{C}}^1$) Now assuming this to be true, Spec and Proj basically give all varieties, because the quasi affine and quasi projective varieties are just open subschemes. So i was wondering if we could in fact get all schemes this way, by allowing general rings in the above. But this is probably hopelessly naive. I was thinking of an example, and it seemed that the affine line with two origins (say over an algebraically closed field), derived by gluing two copies of $\mathbb{A}^1$ to each other everywhere except at the origin is a nice one. I cannot imagine this being embedded in some affine or projective space. To put this into a question: given a generic scheme, could you give an intuitive ""probability"" of whether the scheme is actually the Spec or Proj of some ring/graded ring? As in, how ""large"" is this subset of schemes? (i guess its either almost everything or almost nothing..) Also, there's the question: if the affine line is a scheme derived by gluing, why don't we allow such schemes to be varieties? In other words, why don't we define varieties as locally ringed spaces that are locally isomorphic to affine varieties? I recall reading that Weil actually defined them like this. Is there an obvious reason why Hartshorne did not follow this approach? It's probably a matter of taste, but it seems weird to me to define schemes by some ""locally affine"" property, while not following the same approach in the subcategory of varieties! In fact the approach for varieties is the opposite of local, there's always some ambient space! I must say i did not read every page of Hartshorne at all, so i might have missed something. As you must have noticed by now, my questions mostly concern motivation and background, except the one of Proj of a ring. Any help would be greatly appreciated! Edit: Since it's quite a long story, i'll summarize the questions unanswered so far. Is it in fact true that a projective variety with ideal $I$ is given as a scheme by $\text{Proj}(k[x_0,\ldots, x_n]/I)$? So from this it follows that every variety is either Proj of Spec of some ring, or an open subscheme of a scheme obtained in this way? To what extent does the same hold for schemes, as in ""how many"" schemes are either Proj or Spec of some ring, or an open subscheme of one of those? (of course i just require an intuitive answer and expect no rigorous math) Or can we actually characterize those schemes, are they for example always separated? It seems weird to me to define a scheme by a local property (locally affine), but a variety in the old language as a subset of some ambient space. Is there a good reason to do so, or is it done differenlty somewhere else and to do you have a reference for this? Joachim","['algebraic-geometry', 'math-history', 'schemes', 'soft-question']"
180882,"Functions that generate ""easy"" matrices of full rank","While explaining how to invert matrices I once used this ill-fated example 
$A=\begin{pmatrix} 1&2&3\\4&5&6 \\7&8&9 \end{pmatrix}$ which can not be inverted ($\det(A)=0$). That got me thinking, given a matrix of size $N$, what are some good functions that map to the elements such that: The elements are integers The elements are ""small"" (for hand calculation) The matrix is always invertible (optional) the function has a random component, but still satisfies (3) Let $A_{ij} = f(j + (i-1)N)$. In the example above $f(n) = n$.","['matrices', 'linear-algebra', 'education']"
180885,Prove : $\frac{\cos(x_1) +\cos(x_2) +\cdots+\cos(x_{10})}{\sin(x_1) +\sin(x_2) +\cdots+\sin(x_{10})} \ge 3$,"If we assume that: $0\le x_1,x_2,\ldots,x_{10}\le\frac{\pi}{2} $ such that: $$\sin^2 (x_1) +\sin^2 (x_2)+\cdots+\sin^2(x_{10})=1$$
 How to prove that: $$\frac{\cos(x_1) +\cos(x_2) +\cdots+\cos(x_{10})}{\sin(x_1) +\sin(x_2) +\cdots+\sin(x_{10})} \ge 3$$","['trigonometry', 'inequality']"
180891,Matrices with elements that are a distinct set of prime numbers: always invertible?,"Inspired by a previous question , given a square non-symmetric matrix whose elements are all prime but distinct from each other, does this guarantee that the matrix is invertible? It's easy to see $N=2$ this holds, a counter-example would imply that there must be four distinct primes such that $p_1 p_2 = p_3 p_4$.","['prime-numbers', 'matrices', 'linear-algebra']"
180895,Subgroup criterion.,"I've been reading some stuff about algebra in my free time, and I think I understand most of the stuff but I'm having trouble with the exercises. Specifically, the following: Prove that a nonempty subset $H$ of a group $G$ is a subgroup if for
  all $x, y \in H$, the element $xy^{-1}$ is also in H. Proving that the identity is in $H$ is easy: just take $x=y$, so $x x^{-1} = 1 \in H$. However, I'm having trouble showing that multiplication is closed and that each element in $H$ has an inverse. Can anyone give some hints?",['group-theory']
180903,My proof that a harmonic series diverges..,Suppose $\sum_{n=1}^\infty \frac{1}{n} = S$ where $S$ is finite.  Then $$S =\sum_{n=1}^\infty \frac{1}{n}= \sum_{n=1}^\infty \frac{1}{2n-1} + \frac{1}{2n} > \sum_{n=1}^\infty \frac{1}{2n} + \frac{1}{2n} = S$$ which is a contradiction.  Is this valid?,"['sequences-and-series', 'calculus']"
180907,The height of a principal prime ideal,"A formal consequence of Krull's principal ideal theorem is the following: If $A$ is a Noetherian ring, and $I$ is an ideal generated by $r$ elements, then any prime ideal which is minimal among those that contain $I$ has height at most $r$. This statement implies that for Noetherian rings, principal prime ideals have height at most $1$. My question is if this is true for any ring, i.e., is a principal prime ideal of a ring always of height at most $1$? The above question is clearly true if the following statement is true: If every maximal ideal of a ring is finitely generated, then the ring is Noetherian. (Note that this statement is true if we replace maximal ideals by prime ideals) However, I am not sure if this latter assertion is true, although I do not have a counterexample for it.","['commutative-algebra', 'dimension-theory-algebra', 'abstract-algebra']"
180928,"Symmetry, reflexivity and transitivity in set relations","I am really having a difficult time applying the definitions of the above three set relations terms. For the following problem $R = \{(x,y)|xy \geq 1, x, y \in Z\}$ I have to determine whether the expression is reflexive, symmetric, antisymmetric and/or transitive. According to the book's answer, it is not reflexive because, for $(a, a) \in Z$ where $a = 0$, $0 \times 0 \ngeq 1$. However, it states that the expression is symmetric, i.e. $(a,b) \in R \to (b,a) \in R$ for $a \neq b$. But I don't understand how this could hold, because if either $a$ or $b$ are zero then clearly the expression would be false. I also don't understand how to apply the rule of transitivity to this expression; though the definition states $(a,b) \in R \land (b,c) \in R \to (a,c) \in R$, I don't have a variable $z$ in the expression to work with. I know I am not understanding this or doing this correctly, but the book pretty much just gives definitions without many examples, as if it should be obvious (well it is not, for thick-headed folk like me).","['relations', 'discrete-mathematics', 'elementary-set-theory']"
180931,"Prove $\lim_{x \to +\infty} \frac{f(x)}{(1 + x^2)}\ = 0$ for all $f(x)$ uniformly continuous on $[0, \infty)$.","This question is from a bank of past master's exams. Here is my initial, albeit handwavy, intuition. In essence, I try to show that the uniform continuity condition on $f(x)$ prevents it from growing faster than the denominator. Let $g(x) = x^2 + 1$. Let $\epsilon > 0$ be given. $f$ is uniformly continuous on $[0, \infty)$, so there exists a $\delta_\epsilon$ such that $$|f(x) - f(y)| < \epsilon$$ when $$|x - y| < \delta_\epsilon$$ for all $x, y\in [0, \infty)$. Turning our attention now to the denominator, let $x = y + \frac{\delta_\epsilon}{2}$. Then $|x - y| < \delta_\epsilon$, but $$|(x^2 - 1) - (y^2 - 1)| =$$ $$|x^2 - y^2| =$$ $$|x -y||x + y| <$$ $$\delta_\epsilon |x + y| =$$ $$\delta_\epsilon|2y + \frac{\delta_\epsilon}{2}| =$$ $$\delta_\epsilon(2y + \frac{\delta_\epsilon}{2}), $$ since $y, \delta_\epsilon > 0$. Now, this last expression is greater than $\epsilon$ when $y > \frac{2\epsilon - \delta_\epsilon^2}{4\delta_\epsilon}$. Let $\Delta_{x,y} g = |g(x) - g(y)|$ and $\Delta_{x,y} f = |f(x) - f(y)|$. We have shown that, for the values of $x$ and $y$ chosen above, $$\Delta_{x,y} f < \Delta_{x,y} g.$$ Recall that this inequality only holds because we chose a certain value of $y$, one dependent exclusively on $\epsilon$. But, since $\epsilon$ was arbitrary and $x$ was chosen to be some function of $y$, we have that $\Delta_{x,y} f < \Delta_{x,y} g$ on every interval $[x, y]$ (this is one part that I'm unsure of). And, presto changeo, this implies the desired limit. Is this intuition correct? Is there a better way?","['real-analysis', 'limits']"
180936,Complex towers: $i^{i^{i^{...}}}$,"If $w = z^{z^{z^{...}}}$ converges, we can determine its value by solving $w = z^{w}$, which leads to $w = -W(-\log z))/\log z$.  To be specific here, let's use $u^v = \exp(v \log u)$ for complex $u$ and $v$. Two questions: How do we determine analytically if the tower converges?  (I have
seen the interval of convergence for real towers.) Both the logarithm and Lambert W functions are multivalued.  How do we know which branch to use? In particular $i^{i^{i^{...}}}$ numerically seems to converge to one value of $i2W(-i\pi/2)/\pi$.  How do we establish this convergence analytically? (Yes, I have searched the 'net, including the tetration forum.  I haven't been able to locate the answer to this readily.)","['complex-numbers', 'tetration', 'multivalued-functions', 'complex-analysis']"
180948,"A funny question, about the source of complex number.","As the video on http://www.youtube.com/watch?v=2kbM96Jr4nk It says that:  $1\cdot(-1)=-1$ can represent as $1$ rotated $180^{\circ}$ around the Origin to get $-1$ $$1\cdot(-1)\mapsto 1\quad\text{Rotate}(180 ^{\circ})$$
so it must be: $$1\cdot\sqrt{-1}\mapsto 1\quad\text{Rotate}(90 ^{\circ})$$ but how to map:
$$(-1\rightarrow\sqrt{-1}\ )\mapsto (180 ^{\circ}\rightarrow90^{\circ}) $$
Is there any principles to map the two transforms, or it's just a basic define as $1+1=2$.","['complex-numbers', 'functions']"
180965,Is an exterior algebra a skew group ring?,"Can an exterior algebra 
$$
k\langle x_{1},\dots,x_{n} \rangle/(x_{1}x_{2}-x_{2}x_{1},\dots,x_{1}^{2},\dots)
$$
can be seen as a skew group algebra? A skew group ring is defined for example in the introduction of this paper . I read this fact(?) somewhere but I cannot find a group action $G \rightarrow \mathrm{Aut}(k)$ that cooks up the exterior algebra.","['group-theory', 'abstract-algebra']"
180980,Equivalence of norms on the space of smooth functions,"Let $E, F$ be Banach spaces, $A$ be an open set in $E$ and $C^2(A,F)$ be the space of all functions $f:A\to F,$ which are twice continuously differentiable and bounded with all derivatives. The question is when following two norms in $C^2(A,F)$ are equivalent:
$$
\|f\|_{1}=\sup_{x\in A}\sum^2_{k=0}\|f^{(k)}(x)\|, \ \|f\|_{2}=\sup_{x\in A}(\|f(x)\|+\|f^{(2)}(x)\|).
$$
In the case $A=E$ they are equivalent. One can prove it in the following way. To bound $\|f^{(1)}(x)h\|$ consider a line $g(t)=f(x+th)$ through $x$ in the direction $h$ and use inequality
$$
\sup_{t\in \mathbb{R}}\|g^{(1)}(t)\|\leq\sqrt{2\sup_{t\in \mathbb{R}}\|g(t)\|\sup_{t\in \mathbb{R}}\|g^{(2)}(t)\|}.
$$
The case when $A$ is an open ball is unknown to me. Of course, one can try to consider not lines but segments. But the problem is the length of segment can't be bounded from below and inequalitites I know can't be applied.",['analysis']
180998,Evaluating this integral for different values of a constant,"As you helped me so well last time, I might as well ask a final question!
Today I'm trying to prove this: $$
\int_0^\infty \frac{x^{p}}{ 1+x^{2}}dx = \frac{\pi}{2}\cos\left(p\frac{\pi}{2}\right)
$$ For $-1 < p < 1$. I have no idea how to handle the varying $p$. I've been able to prove the relationship in the case  $p = 0$. So now I could try showing this for $-1 < p < 0$ and $0 < p < 1$ but both of those seem to be tricky. Any tips on dealing with the non-constant $p$?
There are poles at $x = i$ and $x = -i$, and if $p < 0$ also at $x = 0$. I think the best approach would be a semicircle in the top half, maybe with a small inner radius as well in the case $p<0$?
Or should I not be trying to prove the relationship for these separate parts but is there a general way to do it?",['complex-analysis']
181000,Uniqueness of conjugates of a subgroup.,"This question is partly influenced by the question: Are two subgroups that contain a common element conjugate iff they are conjugate under the normalizer? If we have an arbitrary finite group $G$ and radical $p$-subgroups $A,B\leq G$ (so $A=O_{p}(N_{G}(A),p)$, $B=O_{p}(N_{G}(B),p)$ and the normalizers of $A$ and $B$ in $G$ are thus parabolic subgroups) such that $A\leq B\leq N_{G}(B)\leq N_{G}(A)\leq G$ (where $p\in\pi(G)$), is it the case that there is a unique conjugate of $A$ contained in $B$? Clearly $A$ is normal in $B$, but I cannot seem to prove that there cannot be an elemnet $g\in G\setminus N_{G}(A)$ such that $A^{g}\ne A$ and $A^{g}\leq B$. Equally I have not found an example where uniqueness does not hold. Any hints would be greatly appreciated. Edit: Initially the question did not state that $A$ and $B$ were radical subgroups, as a greater understanding of the more general situation as deemed to be desirable.","['finite-groups', 'group-theory', 'combinatorics']"
181012,Are there n-th roots of differential operators?,"In analogy to a Dirac operator, it seems to me that formally, the equation $$\frac{\partial^n}{\partial x^n}f(x,y)=D_yf(x,y)$$ is solved by $$f(x,y)=\exp{(x \sqrt[n]{D_y})}\ g(y).$$ Is there a theory surronding the $\sqrt[n]{D_y}$-idea?","['differential-geometry', 'operator-theory', 'partial-differential-equations', 'spectral-theory', 'differential-operators']"
181021,Operator norm of the sum of a finite collection of bounded linear operator,"I recently got some difficulty with my homework question. The question is: Let $T_1,\dots,T_N$ be a finite collection of bounded linear operators on a hilbert space $H$ , each of operator norm $\le 1$ . Suppose that $T_kT_j^\ast = T_k^\ast T_j = 0$ whenever $j \neq k$ . Show that $\displaystyle \sum_{i=1}^N T_i$ satisfies $\|T\| \le 1$ . For the condition $T_k^\ast T_j= 0$ , $j \neq k$ , I can show $T_k$ and $T_j$ have orthogonal ranges: since $T_k^\ast T_j= 0$ , $T_k^\ast T_j f= 0$ for any $f \in H$ , so it follows $(T_k^\ast T_j f,g)= 0$ for any $g$ . But $(T_k^\ast T_j f,g)=(T_jf,T_kg)=0$ , so $T_j$ and $T_k$ should have orthogonal ranges. However, I cant do anything for condition $T_kT_j^\ast= 0$ . But the hint says for $T_kT_j^\ast = 0$ , $j \neq k$ ，introduce the orthogonal projection $P_i$ onto the closure of the range $T_i^\ast$ , and show that $T_i f$ = $T_i P_i f$ . I dont quite understand the hint and I need some help with this question. Beside, the question has a part 1, which is to show if $P_1$ and $P_2$ are two orthogonal projections, with orthogonal ranges, then $P_1 + P_2$ is also an orthogonal projection. I've done this part 1, but I guess this conclusion is helpful for solving this latter part.","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'analysis']"
181047,Continuous function on unit circle has fixed point,"The question I have is: Let $f: S^1 \rightarrow S^1$ be a continuous function, where $S^1$ is the unit circle. Prove that if $f$ is not onto, then $f$ must have a fixed point.","['fixed-point-theorems', 'functions', 'analysis']"
181048,Inverse function requirements,"Let f be an injective function, that is: $f : X \rightarrow Y$ $f(a) = f(b) \implies a = b$ Now, my question is, does the following need to hold in order for function to be injective: $(\forall x \in X)(\exists y \in Y) (x,y) \in f$ (if we consider function to be a set of ordered pairs) (denote this statement by $(*)$ ) 1st case If it does, then in order for function to be bijective, it needs also to be injective. For example in this case the function $f(x) = \frac 1 x$ is not injective, because it is not defined for x = 0 and $(*)$ does not hold; therefore it's also not bijective and inverse function does not exist. But $f^{-1}(x) = \frac 1 x$ . 2nd case If statement $(*)$ is not required for function to be injective, then the definition of bijective function to be one-to-one correspondence does not hold, since there can be elements in domain that are not paired with any elements in range. So if we wanted to keep the definition of injective function without $(*)$ , we would than have to redefine or rather extend bijective function not only as injective and surjective, but also satisfying $(*)$ . It seems to me to be intuitive paradox, but I'm sure I have made a mistake somewhere and I'd be greatful if someone explained it to me :D","['inverse', 'elementary-set-theory', 'functions']"
181084,A question about operator norm,"I hope this is not an obviously stupid question, I'm quite tired and hence extra slow today. I don't understand the following proof: Given the context I think $X = L^2 (\mathbb T)$, so $T_n : L^2 (\mathbb T) \to \mathbb R$. (The context is: Fourier series and uniform boundedness principle) I don't see how we get the last line from the penultimate one. The operator norm is the $\sup$ over $f$ with norm equal to $1$. But the domain is $L^2$ so it comes with the $L^2$ norm. I'm aware that $\|f\|_1 \leq \|f\|_2$ and that I can apply Hölder to either get $\|T_n\| \leq \|f\|_2 \|D_n\|_2 = \|D_n\|_2$ or $\|T_n\| \leq \|f\|_\infty \|D_n\|_1$. But I want $\|T_n\| \leq \|D_n\|_1$. Thanks for your help.","['measure-theory', 'functional-analysis']"
181092,How many positive values of $a$ are possible in $2^{3}\le a\lfloor a\rfloor \le 4^{2} + 1$,"How many positive values of $a$ are possible in the following case?
$$2^{3}\le a\lfloor a\rfloor \le 4^{2} + 1$$
where $a\lfloor a\rfloor$ such that $a[a]$ is an integer.",['algebra-precalculus']
181093,Singular-value inequalities,"This is my question: Is the following statement true ? Let $H$ be a real or complex Hilbertspace and $R,S:H \to H$ compact operators.
For every $n\in\mathbb{N}$ the following inequality holds: $$\sum_{j=1}^n s_j(RS) \leq \sum_{j=1}^n s_j(R)s_j(S)$$ Note : $s_j(R)$ denotes the j-th singular value of the opeartor $R$.
The sequence of the singular values falls monotonically to zero. With best regards,
mat Edit : I found out, that the statement is true for products instead of sums. By that I mean: Let $H$ be a $\mathbb{K}$-Hilbertspace and $R,S: H \to H$ compact operators.
For every $n\in\mathbb{N}$ we have: $$\Pi_{j=1}^n s_j(RS) \leq \Pi_{j=1}^n s_j(R)s_j(S)$$ Is it possible to derive the statement for sums from this?","['inequality', 'operator-theory', 'linear-algebra', 'spectral-theory', 'functional-analysis']"
181110,The shortest distance between any two distinct points is the line segment joining them.How can I see why this is true?,"On a euclidean plane, the shortest distance between any two distinct points is the line segment joining them. How can I see why this is true?","['geometry', 'calculus', 'general-topology', 'analytic-geometry', 'euclidean-geometry']"
181127,The continuity of multivariable function,"$F$ is a function on $\mathbb R^n$ such that for every smooth curve $\gamma:[0,1] \rightarrow \mathbb R^n, \gamma(0)=0 $, we have $\mathop {\lim }\limits_{t \to 0} F(\gamma (t)) = 0$, is it necessary that $\mathop {\lim }\limits_{\left| x \right| \to 0} F(x) = 0$ ?","['calculus', 'differential-geometry']"
181147,Uniform convergence of infinite series,"Suppose $f$ is a holomorphic function (not necessarily bounded) on $\mathbb{D}$ such that $f(0) = 0$. Prove the the infinite series $\sum_{n=1}^\infty f(z^n)$ converges uniformly on compact subsets of $\mathbb{D}$. I met this problem on today's qual. Here is what I have so far, since $f(0) = 0$, we can write $f(z) = z^m h(z)$ for some integer $m$. Then $f(z^n) = z^{nm}h(z^n)$. We might then use Cauchy's criterion for uniform convergence to finish the proof.","['convergence-divergence', 'sequences-and-series', 'complex-analysis']"
181149,"Prove that $(\mathbb{Z},d)$ is a metric space","I got this from Mendelson: Let   $\mathbb {Z}$  be the set of integers.Let $p$ be a positive prime integer. Given distinct integers $m$, $n$ there´s a unique integer $t=t(m,n)$ such that: $$ m-n=p^tk $$ where $k$ is an integer not divisible by $p$. Define a function $d:\mathbb {Z} \times \mathbb {Z}\rightarrow \mathbb {R}$ by the correspondence $$d(m,m)=0$$ and $$d(m,n)=\frac{1}{p^t}$$ from $m \neq n.$ Prove that $(\mathbb {Z,d})$ is a metric space. I would appreciate a better explanation to this question. I didn´t get the $t(m,n)$. This is also a distance,right?","['general-topology', 'metric-spaces']"
181153,"Define integral for $\gamma,\zeta(i) i\in\mathbb{N}$ and Stirling numbers of the first kind","Consider the integral $$\int\limits_0^{\infty}e^{-x}x^k\ln(x)^n\dfrac{dx}x$$ For $n=3$ we have $$(-\gamma^2-2\zeta(3)-3\zeta(2)\gamma)\genfrac{[}{]}{0pt}{}{k}{1}+3(\gamma^2+\zeta(2))\genfrac{[}{]}{0pt}{}{k}{2}-6\gamma\genfrac{[}{]}{0pt}{}{k}{3}+6\genfrac{[}{]}{0pt}{}{k}{4}$$ where $\genfrac{[}{]}{0pt}{}{n}{k}$ is Stirling number of the first kind. For different n there are simmilar formulas. In the general case $$\int\limits_0^{\infty}e^{-x}x^k\ln(x)^n\dfrac{dx}x\in\bigoplus_{j=1}^{n+1}\genfrac{[}{]}{0pt}{}{k}{j}\mathbb{Z}[\gamma,\zeta(i)]_{n+1-j}$$ where $$\mathbb{Z}[\gamma,\zeta(i)]=\bigoplus_{j=0}^{\infty}\mathbb{Z}[\gamma,\zeta(i)]_{j}$$ is graded ring. Is ir possible to generalize this formula to multiple zeta values?","['sequences-and-series', 'riemann-zeta', 'number-theory', 'euler-mascheroni-constant', 'analysis']"
181155,Showing $f(x)=\sum_{n=1}^{\infty}{\sin\left(\frac{x}{n^2}\right)}$ is continuous.,"Let 
$$f(x)=\sum_{n=1}^{\infty}{\sin\left(\frac{x}{n^2}\right)}.$$ a) Show that the series converges for $x\in [0,\pi/2]$. b) Show that $f$ is monotone and continuous on this interval. This is what I have for (a). Is it right? I am stuck on continuity for part (b). For (a), I showed that since 
$$\frac{x^n}{n!}>\frac{x^{n+2}}{(n+2)!},$$ 
we get that for $x\in[0,\pi/2]$, 
$$0\leq \sin x = x-\sum_{n\in I}{\frac{x^n}{n!} - \frac{x^{n+2}}{(n+2)!}}$$ where $I=\{3,7,11,\ldots\}$. Since the last term is negative or zero, $\sin x\leq x$ for $x\in [0,\pi/2]$. Thus, 
$$\sum_{n=1}^{\infty}{\left|\sin\left(\frac{x}{n^2}\right)\right|} \leq \sum_{n=1}^{\infty}{\frac{x}{n^2}}$$ 
which converges. So the series converges. b) I was able to show $f$ is monotone. Is there a nice way to show $f$ is continuous?","['convergence-divergence', 'sequences-and-series', 'trigonometry', 'real-analysis', 'analysis']"
181158,Compactness of $\mathcal K$ in the Hausdorff distance [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: The Class of Non-empty Compact Subsets of a Compact Metric Space is Compact Let $(M,d)$ be a metric space and let $\mathcal K(M)$ denote the set of all non-empty compact subsets of $M$. This collection is a metric space when equipped with the Hausdorff distance $h$. I want to prove$$(M,d)\mbox{ is compact}\implies(\mathcal K,h)\mbox{ is compact}.$$ The statement is true according to the book [V. I. Istratescu, Fixed Point Theory: An Introduction ], but the proof is omitted. I have already shown that $M$ is complete implies that $\mathcal K$ is complete.","['metric-spaces', 'functional-analysis', 'real-analysis', 'compactness']"
181171,"Let $M$ be a maximal ideal in $R$ such that for all $x\in M$, $x+1$ is a unit. Show that $R$ is a local ring with maximal ideal $M$","So I'm trying to prove that if $M$ is a maximal ideal in $R$ such that for all $x\in M$, $x+1$ is a unit, then $R$ is a local ring with maximal ideal $M$, that is to say $R$ has a unique maximal ideal. I've been at this one for a day now and I just can't figure it out.  I have that $R$ being a local ring is equivalent to there being a proper ideal $I$ of $R$ which contains all non-units of $R$, and also equivalent to the set of non-units of $R$ being an ideal. The set of $x+1$ for $x\in M$ is itself multiplicative, but I'm not sure where to go with that since inverting that set just gives back $M$ (since they're all units).  I haven't been successful at proving anything about elements of $R$ which are not either in $M$ nor of the form $x+1$ for $x\in M$. I also tried just assuming there was some other maximal ideal $N$ and then trying to draw out a contradiction by looking at the ideal $M+N$, clearly if $M+N$ doesn't contain $1$ then I've got my contradiction, but I don't seem to have enough information to pursue that path. Can anyone give me some guidance?  Thanks.","['commutative-algebra', 'abstract-algebra']"
181195,A type of local minimum,"Data: $\Omega \subset \mathbb{R}^{n}$ is an open connected (may be unbounded) set, and locally $\partial \Omega$ is aLipschitz graph. $S \subset \partial \Omega$ is measurabel and $H^{n-1}(S)>0.$ The Dirichlet data on $S$ are given by non-negative function $u^0 \in ^{1}_{Loc}(\Omega)$ with $\nabla u^0 \in L^{2}(\Omega)$. The given force function $Q$ is non-negative and measurable. Consider the convex set 
\begin{equation}
K:=\{ v \in L^{1}_{Loc}(\Omega): \nabla v \in L^{2}(\Omega) \quad \mbox{and} \quad v=u^0 \quad \mbox{on} S\}.
\end{equation}
We are looking for an absolute minimum of the functional
\begin{equation}
J(v):= \int_{\Omega}(|\nabla v|^{2} + \chi(\{v>0\})Q^2)
\end{equation}
in the class $K$. Definition: We call $u \in K$ a local minimum if for some smal $\varepsilon>0$ we have $J(u)\le J(v)$ for every $v \in K$ with
  \begin{equation}
\|\nabla (u-v)\|_{L^{2}(\Omega)} + \| \chi(\{v>0\}) -\chi(\{u>0\})\|_{L^{1}(\Omega)} \le \varepsilon.
\end{equation} Lemma: If $u$ is a minimum local, then $u$ is subharmonic, hence we can assume that 
  \begin{equation}
u(x) = \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega,
\end{equation}
  where $\oint $ denotes the mean value. Proof: For non-negative functions $\xi \in C^{\infty}_{0}(\Omega)$ we have \begin{equation}
0 \le \limsup_{\varepsilon\downarrow 0} \dfrac{1}{2\varepsilon} (J(u- \varepsilon \xi) - J(u)) \le - \int_{\Omega} \nabla \xi \nabla u,
\end{equation}
that is, $u$ is subharmonic. Then the limit in the assertuion exists for every $x \in \Omega$, and coincides with $u(x)$ for almost all $x$. Lemma: If $u$ is a minimum local, then $0\le u\le\sup_{\Omega}u^0$. Proof:For $|\varepsilon|\le 1$ use $u_\varepsilon:=u-\varepsilon \min (u,0)$ and $u_\varepsilon:=u+\varepsilon \min (\sup_{\Omega}u^0-u,0)$ as a first variation. The lemma suggests that $u$ is subharmonic if for all non-negative $\xi \in C^{\infty}_{0}(\Omega)$ we have 
\begin{equation}
\int_{\Omega} \nabla \xi \nabla u \le 0
\end{equation}
I'd like to know what the relation between this definition of subharmoninic and others. For example, by trudinger, if $u$ is subharmonic we have
\begin{equation}
u(x) \le \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega.
\end{equation}
Please, correct me if I am wrong. In the last lemma, What is a first variariation? 3.\begin{eqnarray}
\limsup_{\varepsilon \downarrow 0}\dfrac{1}{2\varepsilon} (J(u- \varepsilon \xi) - J(u))&=& \limsup_{\varepsilon \downarrow 0}\left  \{\dfrac{1}{2\varepsilon}( \int_{\Omega} -2 \varepsilon \nabla \xi \nabla u + \varepsilon^2 \nabla \xi + \chi(\{u-\varepsilon \xi> 0\}) - \chi(\{u>0\}))\right \} \\
&\le & \limsup_{\varepsilon \downarrow 0}\left  \{\dfrac{1}{2\varepsilon}( \int_{\Omega} -2 \varepsilon \nabla \xi \nabla u + \varepsilon^2 \nabla \xi \right \}\\
& & + \limsup_{\varepsilon \downarrow 0}\left  \{ \chi(\{u-\varepsilon \xi>0\}) - \chi(\{u>0\}))\right \} \\
&\le& \int_{\Omega} -\nabla \xi \nabla u + \limsup_{\varepsilon \downarrow 0}\dfrac{1}{2\varepsilon}\left  \{ \chi(\{u-\varepsilon \xi>0\}) - \chi(\{u>0\}))\right \}
\end{eqnarray}
Am I right here? Why $\limsup_{\varepsilon \downarrow 0}\dfrac{1}{2\varepsilon}\left  \{ \chi(\{u-\varepsilon \xi>0\}) - \chi(\{u>0\}))\right \} \le 0$? If you want the details can be found in the article Alt, H. M. and Caffarelli, L. A. Existence and regularity for a minimum problem with free boundary. J. Reine Angew. Math., 325, (1981), 105–144. . I thank any hint.","['measure-theory', 'partial-differential-equations', 'analysis']"
181220,What kind of work do modern day algebraists do?,"Often times in my studies I get the impression that algebra is just a tool to help with other branches of mathematics, like algebraic geometry, algebraic number theory, algebraic topology, etc. How true this is, I am not sure. So I suppose I want to ask, what sort of work do modern day algebraists do? What are currently some of the more active areas of modern algebra? What types of problems do algebraists deal with? I'm kicking around the idea of pursuing graduate study one day, possibly in some sort of algebraic field, i.e., ring theory or something. What sort of research and problems are open to your average graduate student in algebra (of any sort, not just ring theory)? This is partially inspired by the question What do modern-day analysts actually do? Thank you for your responses.","['ring-theory', 'abstract-algebra', 'soft-question', 'group-theory', 'field-theory']"
181236,'Quantum' approach to classical probability,"Quantum mechanics defines a state of a system as a superposition of 'classical' states with complex coefficients, thus reducing many problems to linear algebra. Can classical statistics be approached to that way? Is this approach useful?","['quantum-mechanics', 'probability']"
181237,What is the structure of invariant matrix polynomials?,"Let the field $\mathbb F$ be either $\mathbb R$ or $\mathbb C$ and $M_n(\mathbb F)$ all $n \times n$ matrixes. We denote by $I_n(\mathbb F)$ the space of all functions: $$P : M_n(\mathbb F) \rightarrow \mathbb F$$ which are polynomial (in the sense that $P(A)$ is a polynomial in the entries of $A$ ), and which are invariant under the conjugation, i.e. $P(gAg^{-1}) = P(A)$ for all $g \in GL_n(\mathbb F)$ . For each $p \ge  0$ , we define $\Sigma_p \in I_n(\mathbb F)$ as $\Sigma_p(A)=\mathrm{Tr}(A^p)$ . Then do we have an isomorphism of algebras $I_n(\mathbb F) \cong \mathbb F[\Sigma_0,\Sigma_1,\dots,\Sigma_n]$ ?","['matrices', 'linear-algebra', 'abstract-algebra']"
181239,Solving $|a| < |b|$,"I apologize if this question in general, but I've been having trouble finding solutions as Google discards absolute value signs and inequality symbols. I am looking for a way to eliminate absolute value functions in $|a| < |b|$. I can solve $|a| < b$ and $|a| > b$, but I am unsure what method / combination of methods to use to eliminate absolute value signs from both sides. Thank you! An example problem: $$|x + 2| < |x - 4|$$","['inequality', 'absolute-value', 'algebra-precalculus']"
181255,Summation of divergent series of Euler: $0!-1!+2!-3!+\cdots$,"Consider the series $$\sum\limits_{k=0}^\infty (-1)^kk!x^k\in\mathbb{R}[[x]]$$ Let $s_n(x)$ be partial sum, and let $\omega_{k,n}=(k!^2(n-k)!)^{-1}$. Prove that $$\lim\limits_{n\to\infty}\dfrac{s_0\omega_{0,n}+\cdots + s_n\omega_{n,n} }{\omega_{0,n}+\dots+\omega_{n,n}}=\int\limits_0^\infty\dfrac{e^{-t}}{xt+1}dt$$","['approximation', 'divergent-series', 'sequences-and-series', 'real-analysis']"
181258,A basic question related with the positive definite matrix,"I have a one doubt related with positive definite matrices. Suppose that we have an arbitrary non zero matrix $A$ . Can we find such matrix $B$ which may depend on $A $such that product $AB$ is always a positive definite matrix irrespective of the nature of matrix $A$? 
I need help with this. Thanks","['matrices', 'linear-algebra']"
181270,Equivalent form of definition of manifolds.,"I am studying topology on my own, and I am having trouble proving the following. For a Hausdorff, connected, locally euclidean paracompact space $X$, there exists a countable basis for $X$. I think if I possibly get any countable open cover of $X$ which consists of coordinate balls (that is, homeomorphic to open ball in euclidean space) since each coordinate balls are second countable. However, I cannot get a clue of how to find them. Am I doing right?","['general-topology', 'manifolds']"
181277,Order of a set $X$ acted upon transitively by the Symmetric Group,"Suppose the symmetric group $S_n$ acts transitively on a set $X$, i.e. for every $x, y \in X$, $\exists g \in S_n$ such that $gx = y$. Show that either $|X| \le 2$ or $|X| \ge n$. Small steps towards the solution: As $S_n$ acts transitively on a set $X$, the whole of $X$ is one single orbit under the action of $S_n$. By the Orbit-Stabilizer Theorem, then, $|X|$ = $|S_n : \text{Stabilizer of }x|$ for any $x \in X$. We also know that the Stabilizer of any $x \in X$ is a subgroup of $S_n$. When $|X| = 2$, the Stabilizer of $x$ is the alternating group $A_n$. I'm halfway but can't get the final result. Any help would be much appreciated, as always. Thank you.","['representation-theory', 'abstract-algebra', 'finite-groups', 'symmetric-groups', 'group-theory']"
181288,There exists a finite set of natural numbers which isn't a proper subset of any other finite set of natural numbers?,"Here's a proof: Let $A$ be a family of all finite sets of natural numbers partially ordered by set inclusion. Let $A' = \{A_k\}$ ($k \in K$) be any totally/simply ordered subset of $A$. Consider the set $B = \bigcup A_k$ (union of all sets in $A'$). Note that for every $k \in K$, $A_k \subset B$; hence $B$ is a upper bound of $A'$. Since every totally/simply ordered subset of $A$ has an upper bound, by Zorn's Lemma, $A$ has a maximal element, i.e. a finite set which isn't a proper subset of any other finite set. Since the statement 'proved' is obviously false, which step in the proof is incorrect? I'm guessing $B$ isn't finite so couldn't be an upper bound for $A'$ because the upper bound needs to be finite so Zorn's lemma can't really be applied but I can't see how I could go about proving this. Maybe I'm wrong...",['elementary-set-theory']
181304,What is infinity divided by infinity?,"This should be a simple question but I just want to make sure. I know $\infty/\infty$ is undefined. However, if we have 2 equal infinities divided by each other, would it be 1? And if we have an infinity divided by another half-as-big infinity, would we get 2? For example $\frac{1+1+1+\ldots}{2+2+2+\ldots}=\frac12$?","['sequences-and-series', 'calculus', 'infinity', 'nonstandard-analysis']"
181311,Holomorphic function mapping a set onto a straight line,"I wonder if this is correct: there is a holomorphic function on an open connected subset $G$ of $\mathbb{C}$ which maps $G$ onto a subset of a straight line, and I have to show that the function is constant. I thought I can suppose that the straight line is the real axis (otherwise I can find a rotation and a traslation that will do so) and so using the Cauchy-Riemann equations I find that the function is constant since its imaginary part is zero. Is that correct? Thank you",['complex-analysis']
181331,General solution of constant-coefficient second-order linear ODE,"I am trying to look a bit deeper into the mathematics the equation of motion used in physics and engineering. I have some specific questions at the end, but please correct me if I make a mistake in 
my statement. I have an ordinary, second-order, linear, homogeneous differential equation: $$
M \ddot{y} + C \dot{y} + K y  = 0
$$ where $M$, $C$ and $K$ are real valued. I am familiar with an Ad-hoc method of solving this equation. Namely, I assume a solution 
takes form of $$
y_k(t) = Y_k e^{\omega_k t}
$$ substitute the form into the ODE, $$
\left( M \omega_k^2 + C \omega_k + K\right) y_k  = 0,
$$ and solve for $\omega_k$ such that $y_k \neq 0$. If $y$ is in dimension $N$, 
we generally have $2N$ solutions, where for each $k$, $\omega_k$ and its complex
conjugate $\tilde{\omega}_k$ are solutions. 
Since our ODE is linear, the general solution is a combination of the individual solutions $$
y(t) = \sum_{k = 1}^N Y_k e^{\omega_k t} + \tilde{Y}_k e^{\tilde{\omega}_k t}
$$ The values of $Y_k$ and $\tilde{Y}_k$ are determined from initial values, i.e. $y(0) = y_0$, 
and further restrictions common in physics, such as $y(t)$ must be real for all $t \geq 0$. Now here are my questions: 1 - If we select the form $y_k(t) = Y_k e^{ \mathbf{i}\omega_k t}$, am I correct to say that the roots $\omega_k$ and $\tilde{\omega}_k$ are no longer complex conjugates, but $-1$ times their complex conjugates? 2 - How do we know that the general solution cannot contain terms which are not representable by the exponential form? In other words, is our general solution truly general?",['ordinary-differential-equations']
181360,Listing down the Galois group,"This is a common exercise: Sketch the lattice of subfields of $F = \mathbb{Q} ( \mathbb{e^{\frac{2 \pi i}{p}}})$ be a cyclotomic extension over $\mathbb{Q}$ (where $p$ is an odd prime). It got me wondering, what's the easiest way of writing/listing down the elements of the Galois group $Aut_{\mathbb{Q}} F$?",['abstract-algebra']
181367,Pseudocompactness does not imply compactness,"It is well known that compactness implies pseudocompactness; this follows from the Heine–Borel theorem . I know that the converse does not hold, but what is a counterexample? (A pseudocompact space is a topological space $S = \langle X,{\mathfrak I}\rangle$ such that every continuous function $f:S\to\Bbb R$ has bounded range.)","['general-topology', 'examples-counterexamples', 'compactness']"
181376,Cantor Bendixson Theorem,"Cantor Bendixson Theorem: Every closed set in a separable metric space is the union of a (possibly empty) perfect set and a set which is at most countable. This definition differs a bit from that in wikipedia. I have proved that 'If $X$ is a separable metric space and $E$ is a uncountable subset and $P$ is the set of all condensation points of $E$, then $P$ is perfect and $P^c \cap E$ is at most countable'. Then, you can see that 'every uncountable set in a separable metric space is the union of a nonempty perfect set and a set which is at most countable, and sets are disjoint' (Since $E= P\cup (P^c \cap E)$) Here, i didn't use the condition 'closed' at all!
Where did i go wrong?",['general-topology']
181397,"Continuity of $f:X\to [0,1]$ where $X$ is homeomorphic to the Cantor set.","This is an exercise from Mendelson's Introduction to Topology , page 101. THEOREM For each $n\in \Bbb N$, let $X_n$ be the discrete two-point topological space $\{0,2\}$. Define the product space $X=\prod\limits_{n\in \mathbb N}X_n\;$. Let $f:X\to [0,1]$ be defined as $$f(x)=\sum_{n=1}^\infty \frac{x(n)}{3^n}$$ Then $f$ is one-one and continuous. PROOF (Revised) We first prove $f$ is one-one. To this end, suppose we had $$\sum_{k\geqslant 1}\frac{x_n}{3^n}=0$$ with $x_n\in\{0,-2,2\}$. I claim first there cannot be any $K$ with $x_K=-2$. Indeed, let $K$ be the least index with $x_K=-2$. I claim that $x_k=0$ if $k<K$. Indeed, because $$ - \sum\limits_{k = K}^\infty  {\frac{2}{{{3^k}}}}  =  - \frac{1}{{{3^K}}}\sum\limits_{k = K}^\infty  {\frac{2}{{{3^{k - K}}}}}  =  - \frac{2}{{{3^K}}}\sum\limits_{k = 0}^\infty  {\frac{1}{{{3^k}}}}  =  - \frac{1}{{{3^K}}}$$ there is no way the sum would equal zero if some $x_k$ with $k<K$ was nonzero. But with this out of the way, it is impossible the sum is zero. By the same token, in the extreme case we have  $$ - \frac{2}{{{3^K}}} + \sum\limits_{k = K + 1}^\infty  {\frac{2}{{{3^k}}}}  =  - \frac{2}{{{3^K}}} + \frac{1}{{{3^{K + 1}}}} < 0$$ This means there cannot exist $k$ with $x_K=-2$. Thus $x_k\in \{0,2\}$. Since the sum is zero, all nonnegative terms must be zero, so the sequence is identically zero. We now prove $f$ is continuous. Let $a\in X$ and $\epsilon >0$ be given. The claim is that given the open ball $B(f(a);\epsilon)$, we can choose $k$ so that $$\tag 1 P_k=\bigcap_{i=1}^k p_i^{-1}(a(i))\subset f^{-1}(B)$$ where $p_i:X\to \{0,2\}$ is the projection to the $i$th coordinate. Since $f$ is one-one, $(1)$ is the same as $$f(P_k)\subset B$$ Note that for any point $x\in P_k$, the difference $|f(x)-f(a)|$ is at most $3^{-k}$, precisely when $x(n)=2$ and $a(n)=0$ for $n\geq k+1$ (or viceversa): $$\sum\limits_{n = k + 1}^{ + \infty } {\frac{2}{{{3^n}}}}  = \frac{1}{{{3^k}}}$$ Thus we may choose $k$ such that $3^{-k}<\epsilon$. It will follow that $f(P_k)\subset B$, and $f$ will be continuous.",['general-topology']
181413,Defining the width of a Gaussian function,"I have the following Gaussian function: $$\rho(r) = q_i (\alpha/\pi)^{3/2} \exp(-\alpha r^2)$$ Qualitatively, the ""width"" of this Gaussian is related to $\frac{1}{\alpha}$: the larger the value of $\alpha$, the smaller the ""width"" of the Gaussian. This Wikipedia article uses this definition of a Gaussian function: $$f(x) = a\exp \left(-\frac{(x-b)^2}{2c^2}\right)$$ and says that one way to define the width is to consider the full width at half maximum: $$\text{FWHM} = 2 \sqrt{2 \ln 2} c \approx 2.35482c$$ In other words, the width of $f(x)$ is proportional to $c$.  But, in my function $\rho(r)$, $\alpha$ appears in two places:  in the exponential and as a coefficient of the exponential.  How should I define the width of $\rho(r)$?","['normal-distribution', 'exponential-function', 'algebra-precalculus', 'functions']"
181416,Minimal projections vs maximal left ideals,"I've seen in some papers a statement (which is referred to a very old book of Dixmier in French which I have no access to / can't read anyway) saying that maximal left ideals of a (unital) C*-algebra $A$ are in one-to-one correspondence with minimal projections in the algebra $zA^{**}$, where $z$ is the central projection being the supremum over all minimal projections in $A^{**}$. Could one please sketch how does this correspondence work? EDIT: One way: take a maximal left ideal $L$. Then its bipolar $L^{\circ\circ}$ is a $\sigma$-closed maximal left ideal of $A^{**}$. Consequently, there is a minimal projection $e$ in $A^{**}$ such that $L^{\circ\circ}=A^{**}(1-e)$. The other way round: Take a minimal projection $e$ in $zA^{**}$ and consider the left ideal $A^{**}(1-e)$. It seems that $A\cap A^{**}(1-e)$ is a maximal left ideal of $A$.","['c-star-algebras', 'operator-algebras', 'von-neumann-algebras', 'functional-analysis']"
181426,Irreducible minimal polynomial implies every invariant subspace has an invariant complement,"Full version of the problem is following: Let T be a linear transformation on a finite dimensional vector space $V$ over a field $\mathbb{F}$. If the minimal polynomial $p_t$ of T is irreducible, then every T invariant subspace $W$ has a T-invariant complement $W'$ I used Cyclic decomposition Theorem which states that ""The finite dimensional vector space V can be expressed a s a decomposition of T-cyclic subspaces $Z(\alpha_1;T)\oplus Z(\alpha_2;T)\oplus...\oplus Z(\alpha_k;T)$ and their annihilators $p_1,...p_k$ have properties;
 (1) $p_k|...|p_1$, (2)$p_T=p_1, f_T=p_1\cdot p_2\cdot ...\cdot p_k$ where $f_T$ is the characteristic polynomial of T."" Can I say this? Since $p_T$ is irreducible, there is a cyclic vector $\alpha$ such that $V=Z(\alpha;T)$
and V=W and $W'=\{0\}$. 
Therefore $W'$ for each W is T-invariant. Is my way correct? Thank you in advance.",['linear-algebra']
181427,Class of manifolds is a set?,"Is the class of all 2-countable manifolds a set? I think so: each such space is a countable union of sets of cardinality $|\mathbb{R}^n|\!=\!|\mathbb{R}|$, i.e. a manifold has cardinality continuum, and there are less than $\mathbb{R}^\mathbb{R}$ ways of gluing it together. Why then is this set still called a class?","['set-theory', 'manifolds', 'terminology', 'differential-geometry']"
181430,"If $V_0$ is the subspace of matrices of the form $C=AB-BA$ for some $A,B$ in a vector space $V$ then $V_0=\{A\in V|\operatorname{Trace} (A)=0\}$","If $V_0$ is the subspace consisting of matrices of the form $C=AB-BA$ for some $A,B$ in a vector space $V$ then $V_0=\{A\in V|\operatorname{Trace}(A)=0\}$. The problem above is one of the past qualifying exam problems. I can prove that  $V_0\subset\{A\in V|\operatorname{Trace}(A)=0\}$ but I do not know what to do with converse. Thank you in advance.",['linear-algebra']
181431,Geometric meaning of a nondegenerate critical point,"Let $f\!:M\!\rightarrow\!\mathbb{R}$ be a smooth function on a manifold and $p\!\in\!M$. Is there any way to geometrically/visually characterize the conditions $p$ is a critical point (i.e. $D(f)_p\!=\!0$) and $p$ is a nondegenerate critical point (i.e. $\det D^2(f)_p\!\neq\!0$)? If $f(x)=\langle x,a\rangle$ is a height function on a surface, then $f$ is linear, so $D(f)_p\!=\!f\!:\, T_pM\rightarrow T_p\mathbb{R}\!=\!\mathbb{R}$. Thus $f$ is the zero map at those $p$ for which $T_pM$ is perpendicular to $a$, i.e. the critical points of $f$ are those points at which $T_pM=a^\bot$. But what about higher dimensions and different $f$s? And what about nondegeneracy?","['differential-topology', 'manifolds', 'differential-geometry']"
181446,Range of identity plus compact operator is closed,Suppose $K:H\to H$ is a compact linear operator on a Hilbert space $H$. How do I show that the range of $I+K$ is closed in $H$? I believe this is equivalent to showing that $\{x_n\}\subset H$ and $(I+K)x_n\to y\in H \implies \exists x\in H$ such that $(I+K)x=y$.,"['hilbert-spaces', 'functional-analysis']"
181448,"Evaluate $\int_0^\infty (u\log(a^2+u^2))/(e^u-1)\, du$","Does the following definite integral have a known ""closed form"" value? $$\int_0^\infty\frac{u\log(a^2+u^2)}{e^u-1}~du,$$ or can anyone see a way to integrate it?","['definite-integrals', 'integration']"
181471,Stronger Liouville theorem,"""Every bounded function that is holomorphic on $A$ is is constant."" For which $A\subseteq\mathbb{C}$ is this true? Are there well-known examples of unbounded sets $A\subseteq\mathbb{C}$ on which there are non-constant bounded holomorphic functions? Later edit: My striking through the second question was meant only to de-emphasize it.  Feel free to post further on it if you wish.  Some of the examples posted in response to it were already well known to me; I'd have thought of them if my attention had been on the second question rather than the first. I'm envisioning a couple of possibilities: (1) Various other sorts of sets $A$ will be mentioned in answers; and (2) An answer will say that some nice theorem says this is true of a set $A$ if and only if whatever, where ""whatever"" is something non-trivially different from a tautologous ""if and only if every bounded holomorphic function on $A$ is constant"", and maybe ""whatever"" is somehow elegant or at least simple.",['complex-analysis']
181490,Solving inequality $x^3-4x>0$,"I was sort of finding the roots by doing $x^3-4x>0=x(x^2-4)$ $x = 0, x = -2,x = 2$ for $$x(x-2)(x+2)>0$$ Then I stopped and thought; maybe I shouldn't be doing that? I am doubting myself! Can anyone confirm if I am doing the right thing to solve the equality?","['inequality', 'algebra-precalculus']"
181492,"Let X and Y be random variables with joint pdf $f(x,y)=x+y$ for $0<x<1$ and $0<y<1$. Are X and Y independent? My heart says yes but my math says no.","I am using the fact that $X$ and $Y$ are independent if and only if $f_X(x)f_Y(y)=f(x,y)$. So I have $$f_{X}
(x)=\int_{0}^{1}f(x,y)dy\\=\int_{0}^{1}x+ydy\\=[xy+\frac{y^{2}}{2}]_{y=0}^{y=1}\\=x+\frac{1}{2}$$ and by basically exactly the same math, $f_Y(y)=y+\frac{1}{2}$. Then $$f_X(x)f_y(y)=(x+\frac{1}{2})(y+\frac{1}{2})=xy+\frac{1}{2}(x+y)+\frac{1}{4}\ne f(x,y)$$ And hence they are not independent. But can that be right? Why would the value of X have anything to do with the value of Y? It's not like one is a function of the other. Or have I made a simple mistake? I looked through a couple of times and I'm pretty sure my math is right...",['probability']
181499,"How come in classical mechanics we can get away with writing $a=v(dv/dx)$, treating $v$ as a function of $x$?","In classical mechanics we often use the relation $a=v(dv/dx)$ to help solve differential equations. I assume when we write $dv/dx$, we really mean $dV/dx$, where $V$ is a function defined so that $V(x(t))=v(t)$. But then $V$ is not really a well defined function, because a particle can pass through a point more than once, with a different velocity each time. I assume the answer has something to do with the implicit function theorem, which I haven't really studied, but I understand that we can locally treat $V$ as a function of $x$. But then why don't we run into issues treating this as a ""global"" expression? Edit: I understand the heuristic use of the chain rule: $a=(dv/dx)(dx/dt)$. But it seems to me that the term $dv/dx$ only makes sense ""locally."" Yet when we use $a=(dv/dx)(dx/dt)$ to solve, say, the equation of motion of the simple pendulum as an elliptic integral, we end up with an expression valid for all $t$, not just ""locally"". Why does everything work out?","['ordinary-differential-equations', 'calculus', 'physics']"
181520,Fundamental theorem Galois Theory,"From time to time, I try to give my non-mathematician scientist friends descriptions of important theorems that I come across. One friend, watched a video on Galois and now I'm at a loss on how to state to her the Fundamental Theorem of Galois Theory in an intuitive yet mathematically correct manner.","['galois-theory', 'education', 'abstract-algebra']"
181521,Metric Of A Graph,"The following is question 6 from page 99 of Walter Rudin's Principles Of Mathematical Analysis .  I'm having trouble understanding what the metric of the graph might be (which, as far as I can tell, is not defined in the text or the problem)... If f is defined on E , the graph of f is the set of points
  $(x,f(x))$, for $x \in E$.  In particular, if E is a set of real
  numbers, and f is real-valued, the graph of f is a subset of the
  plane. Suppose E is compact, and prove that f is continuous on E if and
  only if its graph is compact. I think I've been able to prove the forward result.  Suppose that E is compact.  Rudin proves a theorem in the text that states the image of a compact metric space under a continuous function is also compact.  Therefore, we know that $f(E)$ is compact.  Now suppose that $\lbrace G_\alpha \rbrace, \alpha \in A$ is an open cover of the graph, where $G_i = B_i \times C_i$ and $B_i \in E, C_i \in f(E)$.  Then $\lbrace A_\alpha \rbrace$ and $\lbrace B_\alpha \rbrace$ are open covers for E and $f(E)$, respectively.  Because these sets are compact, their open covers contain finite subcovers, $\lbrace A^\prime_\beta \rbrace$ and $\lbrace B^\prime_\gamma \rbrace$, respectively.  Thus, the set of all combinations of $(A^\prime_\beta, B^\prime_\gamma)$ forms a finite open subcover of the graph, proving that the graph is compact. Actually, I'm really confused at this point, because it's just occured to me while typing the above that I cannot assume that each set $G_i$ can be represented as a set $\lbrace (x,y) \mid x \in A_i, y\in B_i \rbrace$ for open sets $A_i \subseteq E$ and $B_i \subseteq f(E)$. So at this point, I'm not sure what to do, since I am unable to figure out what the distance metric might be in the metric space containing the graph.  Is there a convention for this sort of problem?  Did Rudin want the reader to only consider real-valued functions for f ?","['metric-spaces', 'continuity', 'analysis']"
181555,Number of elements in a finite $\sigma$-algebra,"I have been asked to prove that the number of elements in a finite sigma algebra over a set $X$ is $2^n$ for some integer $n$. How do I go about this problem? I have no idea where to start. Thanks in advance for any ideas. Do I need to prove that given a set $F$, $\sigma(F)$ is actually a power set of some set say $S$?","['measure-theory', 'real-analysis']"
181562,Orbits of $\mathbb{Z}/n\mathbb{Z}$ under automorphism subgroup action,"Let $A\leq \rm{Aut}(\mathbb{Z}/n\mathbb{Z})$. I am interested in the orbits of $\mathbb{Z}/n\mathbb{Z}$ under the action of $A$, i.e. the sets $$\{\sigma i : \sigma \in A\},$$ where $i\in \mathbb{Z}/n\mathbb{Z}$. If $\sigma i = j$, then there exists a corresponding unit $u\in (\mathbb{Z}/n\mathbb{Z})^\times$ such that $ui\equiv j\bmod{n}$, whence $(i,n)=(j,n)$. Thus, to describe the behavior of the orbits of the group, it suffices to fix a divisor $d$ of $n$ and consider orbits of the set $$R_d:=\{i\in\mathbb{Z}/n\mathbb{Z} : (i,n)=\tfrac{n}{d}\},$$ which has $\varphi(d)$ elements. Is anything known about how an arbitrary automorphism subgroup of $\mathbb{Z}/n\mathbb{Z}$ partitions $R_d$ into orbits? In particular, can anything be said about their size and number? Edit: Perhaps I should clarify. The fact that $\rm{Aut}(\mathbb{Z}/n\mathbb{Z})\cong (\mathbb{Z}/n\mathbb{Z})^\times$ was used above to deduce that each orbit of $\mathbb{Z}/n\mathbb{Z}$ is contained in some $R_d$. I am interested in the explicit nature of the orbits. For example, if $A$ is cyclic, then I have shown that $A$ partitions $R_n$ into $|A|$ orbits of size $\varphi(n)/|A|$. It would be nice to generalize this sort of result to include cases where $d< n$ and $A$ is not cyclic.","['cyclic-groups', 'group-theory', 'group-actions']"
181566,Mysterious number $6174$,"Kaprekar discovered the Kaprekar constant or $6174$ in $1949$. He showed that $6174$ is reached in the limit as one repeatedly subtracts the highest and lowest numbers that can be constructed from a set of four digits that are not all identical. e.g. starting with $1234$, we have
$4321 − 1234$ = $3087$, then
$8730 − 0378$ = $8352$, and
$8532 − 2358$ = $6174$. But, Why we reach to $6174$ through this process ?
 I think, subtraction is always divisible by $3$....(not sure)",['number-theory']
181579,How to prove $x^{n}$ is not uniformly continuous,"How to prove $x^{n}$ is not uniformly continuous on the interval $[0, +\infty)$ for $n \in \mathbb{N}$ and $n>1$ ?","['calculus', 'real-analysis', 'uniform-continuity']"
181592,"If $f$ is nonnegative and continuous on $[a,b]$, then $\left(\int_a^b f(x)^n \ dx\right)^{1/n}\to\max\limits_{[a,b]} f$ [duplicate]","This question already has answers here : limit of Holder norms: $\sup\limits_{x\in [a,b]} f(x) = \lim\limits_{n\rightarrow\infty} \left(\int_a^b (f(x))^n \;dx\right)^{\frac{1}{n}}$ [duplicate] (1 answer) If $f(x)$ is continuous on $[a,b]$ and $M=\max \; |f(x)|$, is $M=\lim \limits_{n\to\infty} \left(\int_a^b|f(x)|^n\,\mathrm dx\right)^{1/n}$? (2 answers) Closed 6 years ago . I've been working on the following problem: Show that if $f\in C[a, b]$ , $f\ge 0$ on $[a, b]$, then $\left(\int_a^b f(x)^n \,dx\right)^{1/n}$ converges when $n\to\infty$ and the limit is $\max_If$ with $I=[a, b]$. This is my solution: For  Weierstrass $f$ has maximum, $\exists \  \xi : f(\xi)=M$; and as $f$ is defined on $[a,b]$, $f$ is U.C., then: $\forall \epsilon >0  \ \exists \delta >0: \forall x,y \in [a,b]: |x-y|< \delta \Rightarrow |f(x)-f(y)|< \epsilon$ Let $[a,b]=\bigcup_{k=1}^m I_k$, with $mis(I_k)<\delta$, and $M_k=max_{\bar(I_k)}  f(x)$
$(\int_a^b f(x)^n \  dx)^{1/n}=(\sum_{k=1}^m M_h^n mis(I_k))^{1/n}=(M_1^n mis(I_1)+...+M^n mis(I_j)+...M_m^n mis(I_m))^{1/n}=$
=$M ((M_1/M)^n mis(I_1)+...+mis(I_j)+...+(M_m/M)^n mis(I_m))^{1/n}$ Then: $(\int_a^b f(x)^n \  dx)^{1/n} \ge M$ $(\int_a^b f(x)^n \  dx)^{1/n} \le M(b-a)^{1/n}$ $\Rightarrow \exists \  \lim_n \ (\int_a^b f(x)^n \  dx)^{1/n}=M=\max_I \ f$","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'analysis']"
181621,Question about definition of Sobolev spaces,"I'm trying to understand the following definition: which can also be found here on page 136. Question 1: Closure with respect to what norm? It's not given in the definition. Question 2: Do I have this right: I can view $C^\infty$ as a dense subspace of $H^k$ via the map (embedding) $f \mapsto (D^\alpha f)_\alpha$ where the tuple $f$ is mapped to consists of all derivatives $D^\alpha f$ such that $|\alpha| \leq k$. Then this is cool because if we have this we can extend any linear operator $T: C^\infty \to C^n$ continuously to all of $H^k$ so that anything we can do to smooth functions we can also do to Sobolev functions. That is, even if the functions don't have a strong $\alpha$-th derivative we can treat them as if they did. Thanks for your help.","['sobolev-spaces', 'functional-analysis']"
181624,Is there any significance in the order in which group axioms are presented?,"I know books have slightly different ways of presenting the axioms, but I think they tend to go like this:
Group is a set with a law of composition with closure that satisfies the following properties
(i) associativity, i.e. a(bc) = (ab)c
(ii) identity, i.e. 1a = a1 = a
(iii) inverse, i.e. every element a has an inverse such that ab = ba = 1. Michael Artin's ""Algebra"" made no mention of this, but Fraleigh's ""A First Course in Abstract Algebra"" implied that it was important that the axioms were in that specific order, and wouldn't work any other way. Why is this? Thanks in advance.",['abstract-algebra']
181632,Three finite groups with the same numbers of elements of each order,"There exist pairs of finite groups $G$ and $H$ such that $G$ and $H$ are not isomorphic, yet they have the same number of elements of each order.  For example, if $p$ is an odd prime, then the group $$H_{p} = \left\{\begin{pmatrix} 1 & a & b \\ 0 & 1 & c \\ 0 & 0 & 1\end{pmatrix} : a,b,c\in\mathbb{Z}_{p}\right\}$$
 and the group $\mathbb{Z}_{p}^{3}$ both have exponent equal to $p$ and order $p^{3}$.  Also, for any such pair $G$ and $H$, at least one of $G$ and $H$ must be non-commutative.  My question is this: Do there exist three groups $A$, $B$ and $C$, of the same finite order, such that no two of them are isomorphic and such that all three of $A$, $B$ and $C$ have the same number of elements of each order? Ideally, I'd like a nice, concrete description of any examples that might exist (preferably, the smallest such), or a reference to a proof that there is no such example.","['reference-request', 'finite-groups', 'group-theory']"
181641,Every open set in $\mathbb{R}$ is the union of an at most countable collection of disjoint segments,"Let $E$ be an open set in $\mathbb{R}$.
Fix $x\in E$. I have proved that statement is true when $\{y\in \mathbb{R}|(x,y)\subset E\}$ is bounded above and $\{z\in \mathbb{R}|(z,x)\subset E\}$ is bounded below. If at least one of those above are not bounded, $E$ must be equal to one of; 1.$\mathbb{R}$ 2.$\{r\in \mathbb{R}|r<k\}$for some $k\in \mathbb{R}$ 3.$\{r\in \mathbb{R}|k<r\}$for some $k\in \mathbb{R}$ Are these sets can be the union of an at most countable collection of disjoint 'segments'?",['general-topology']
181647,"What is the formula for this exponentially growing ""stairs""?","I'm looking for a formula that, given a linear $x$ input, would yield values of $y$ in a ""stairs"" shape so to speak, in such a way that as the value of $x$ grows higher, the difference between each step is bigger, and it also takes longer to reach the next the step, as this graph (hopefully) illustrates: As you have probably guessed by now I'm not a mathematician, but I'm fairly sure this has an easy solution. I've been playing around with modulus and powers but I couldn't quite get the graph above so far. Edit: Graph updated.","['graphing-functions', 'algebra-precalculus', 'functions']"
181669,Surface integral - need a bit of explaining,"I'm going through some old calculus, and I'm struggling a bit with surface integrals. Here's the problem: Compute the integral $$\iint\limits_{\sigma} (x-y-z)d\sigma$$ where $\sigma$ is the plane $x+y=1$ in the first octant, limited by $z=0$ and $z=1$. So, what I've done so far is to convert the equation for sigma as a function of $y$, i.e. $y = 1-x$ $\therefore\quad\frac{\partial y}{\partial x} = -1,\quad\frac{\partial y}{\partial z} = 0\\
\therefore\quad\sqrt{(\frac{\partial y}{\partial x})^2 + (\frac{\partial y}{\partial z})^2+1} = \sqrt{2}\\
\therefore\quad\displaystyle{\iint\limits_{\sigma}} (x-y-z)d\sigma = \sqrt{2} \displaystyle{\iint\limits_{R}} (x-(1-x)-z)dxdz $ where $R$ is the projection of the given region $\sigma$ on the $xz$ plane. Simplifying: $$\sqrt{2}\iint\limits_{R}(2x-1-z)dxdz$$ So, it seems that the projection is a right triangle, with vertices at $(0,0,0), (0,0,1), (1,0,0)$. Am I on the right track, and, how do I proceed from here? I full worked out example would help me a lot.",['multivariable-calculus']
181676,How to see $\sin x + \cos x$,"$$\sin x + \cos x = \sqrt{2}  \sin(x + \pi/4)$$ Is there an easy way to visualize this identity or to convert the left-hand side to the right-hand side? In general, can $p \sin x + q \cos x$ for some integers $p$ and $q$ be easily expressed as $\sin($something$)$ or $\cos($something$)$? If so, how can that be done?",['trigonometry']
181682,Showing $\lim_{n \to +\infty} \log(n!)/(n\log n) = 1$ without using Stirling approximation,"As a passage of a bigger limit I have to show that $$ \lim_{ n \to \infty } \frac{\log(n!)}{n\log(n)} = 1. $$
I think it could be done using Stirling approximation, but I'm wondering if there's a way without that formula.","['factorial', 'logarithms', 'calculus', 'limits']"
