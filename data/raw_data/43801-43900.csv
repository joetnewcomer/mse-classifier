question_id,title,body,tags
435614,Fundamental Theorem of Calculus in Multivariate Case,"From the FTC we have, for continuously differentiable $f: \mathbb{R} \to \mathbb{R}$, 
$$
f(a) - f(b) = \int_b^a \frac{d}{dx} f(x) dx
$$ I'm trying to write the difference between a vector function in similar terms, that is, given $g : \mathbb{R}^d \to \mathbb{R}^d$, having known Jacobian $J_f(x)$, what can we say about
$$
g(x_1) - g(x_2) = ? 
$$","['multivariable-calculus', 'calculus', 'integration']"
435621,Show that the operator norm is submultiplicative,"We had in our lecture on numerical analysis the following:
Let $\mathrm{Lin}(X,Y)$ be the set of all linear maps $X\rightarrow Y$ . Let $A\in\mathrm{Lin}(\mathbb R^l,\mathbb R^n)$ and $B\in\mathrm{Lin}(\mathbb R^n,\mathbb R^m)$ and $\|C\|_{op}:=\max_{\|x\|\leq1}\|C(x)\|$ . Then our lecturer followed $\|A\circ B\|_{op}\leq\|A\|_{op}\cdot\|B\|_{op}$ . So he didn't prove it and so I've tried it by my own. My attempt: $$\begin{aligned} \|A\circ B\|_{\mathrm{op}} &= \max_{\|x\| < 1}\|(A \circ B)(x)\| \\ & \leq \max_{\|x\| < 1} \|A\|_{\mathrm{op}} \|B(x)\| \\ &= \|A\|_{\mathrm{op}} \max_{\|x\|\leq1}\|B(x)\|\\ &= \|A\|_{\mathrm{op}}\|B\|_{\mathrm{op}} \end{aligned}$$ But this seems too easy. I am really interested in a nice proof so anybody could help? Thanks a lot!","['inequality', 'matrix-norms', 'linear-transformations', 'normed-spaces', 'real-analysis']"
435634,How to know the flattening factor for a ellipse?,"I want to know how can I get the flattening factor for a ellipse by knowing its semi-major and semi-minor axes ? Actually I tried this formula: $f=\left(\frac{a}{b}-1\right)$ While $f$ is the flattening factor, $a is the semi\,major\,axes$, $b is the semi\,minor\,axes$. I think it's true because when I try it with circle it gives me $\left(\,f=0.0\,0\right)$ . but I don't have any source for this formula and I'm not sure if it's true ! So if any one know what is the exact formula for finding the flattening factor for a ellipse ?","['geometry', 'conic-sections', 'differential-geometry']"
435644,Why such function does not exist?,"I could not prove the following: A function $f \in \mathscr{C}^2([0, \pi])$ , such that $$f(0) = f(\pi) = 0,\\
\int_0^{\pi} (f'(x))^2dx = 1,\\
\text{and }\int_0^{\pi} (f(x))^2dx = 2$$ Then such function does not exist. I think that I have to use the Rayleigh quotient and have a contradiction for the eigenvalue $\frac{1}{2}$ . Thanks in advance.","['partial-differential-equations', 'analysis']"
435663,A baby version of the Stein-Cotlar almost-orthogonality lemma,"The following is an exercise from Stein and Shakarchi's Real Analysis . Suppose $\{T_k\}$ is a collection of bounded operators on a Hilbert space $H$, each with norm at most $1$. Suppose also that $$T_kT^*_j = T^*_k T_j =0$$ for $k\neq j$. Let $S_n(f)=\sum_{k=1}^n T_k(f)$. The problem asks to show that $\lim_{N\rightarrow \infty} S_n(f)$ converges for every $f$ and that the the resulting operator $S$ has norm at most $1$. Is the sketch written in the spoiler box below correct? I am mostly worried about the construction in the second and third sentences. Any alternative slick solutions are also welcome. Consider first the case of a finite number of operators. Since the operators have mutually orthogonal ranges, the closures of their ranges are also mutually orthogonal. This allows us to decompose the space into $B\oplus_1^n V_k$, where the $V_k$ are the closures of the ranges and $B$ is what is left over after taking the direct sum of all the $V_k$. Let $f=\sum v_k$ denote the decomposition of a function $f$ into these spaces. Then, recalling the ranges are orthogonal, $\|S_n(f)\|\le \sum_1^n \|T_k(f)\|\le \sum |T_k (v_k)|\le \sum_1^n |v_k|\le |f|.$ This shows the sequence is absolutely convergent, so it is convergent, since we are in a complete space. It also immediately shows the limit is an operator and that this operator has norm at most 1.","['proof-verification', 'hilbert-spaces', 'functional-analysis', 'real-analysis']"
435666,Proving that an algebraic expression cannot be a square,"Say that I have an expression in several variables, like $zxy+z^5x^2y^2 + xy + 24z$. To prove that it's not a perfect square, I write it in terms of one of the variables, say $x$. This makes it  a polynomial of degree $2$. Now expand out $(a+bx)^2$ and match up the corresponding coefficients, and if the coefficients are impossible given what I know about the other variables, does this prove that the expression cannot be a perfect square? Thanks.",['algebra-precalculus']
435669,How can I transform this equation in a conical?,"In this equation $$2x²+y²-4x-6y+11=0$$ I got the result $(1,3)$ completing squares $2(x - 1)² + (y - 3)² = 0$ But on my list exercises, demanded that determine the foci, straight guideline
asymptote, vertex, center, radius, minor axis and major axis (if there were any of them according to the data items) of the following equations of conics. So, how can I get the result of a conical? Thank you.","['conic-sections', 'calculus', 'algebra-precalculus', 'limits']"
435671,Validity of my proof for a Cartesian Product in Tao's book,"Before all, I'm apologize if my question is too common here. I'm only want to know if my proof is correct or need some adjustments. I'm reading the Terence Tao's Analysis book as I mentioned in my other question. The problem in the book says: *My approach for the first part, was: Let I be the set of all the natural numbers between 1 and n: $$ I:= \left \{  i \in N : 1 \leq i\leq n \right \} $$ (=>) So, if we assume that the both ordered n-tuple are equal: 
$$ \left (x_{i} \right)_{i\in I} = \left (y_{i} \right)_{i\in I} $$ As the two functions are equal (by hypothesis). So for each i in I, we have that both are equal (using the definition of equality of function given in previous chapter by the author). Therefore:  $$  \left (\forall i \in I \right) \left (  x \left ( i \right)= y \left ( i \right) \right) $$ (<=) On the other hand, if we assume that: $$  \left (\forall i \in I \right) \left (  x_{i}= y_{i} \right) $$
As both function have the same domain and range that means both are equal:
$$ \left (x_{i} \right)_{i\in I} = \left (y_{i} \right)_{i\in I} $$ *For the second part, I have some troubles but here is my approach: First we write the Cartesian product as the author do: $$ \prod_{i\in I} X_{i} := \left \{ \left (x_{i}  \right )_{i \in I}:\left(\forall i \in I \right) \left (x_{i} \in X_{i} \right)   \right \} $$ I form the set of all the functions from the set of natural numbers called I to a target set X, which I defined in the next way: $$ X^{I} \text{ where } X:= \bigcup_{i \in I} X_{i} $$ Then, using the axiom schema of specification we can form the set: $$ g\in \left \{ f\in  X^{I}  : \left (\forall i \in I \right) \left (f \left ( i \right) \in X_{i} \right)  \right \} \leftrightarrow \\ \left(\text{$g: I \rightarrow X$ is a mapping and } \left (\left (\forall i \in I \right) \left (f \left ( i \right) \in X_{i} \right)  \right ) \right ) $$ So, using the definition given by the author only we need to show that g is onto which means that define an ordered n-tuple (right?). $$ x \in X \leftrightarrow  x \in \bigcup_{i \in I} X_{i}\leftrightarrow \left (\exists i \in I   \right )\left ( x \in  X_{i} \right )  $$ g is surjective because for each x in the target set always we can find a i in the domain. Then, g is an ordered n-tuple. And that means g lies in collection of all n-tuples defined at the first place. On the other hand: $$ x\in \prod_{i\in I} X_{i}\leftrightarrow \left (x = \left (x_{i}  \right )_{i \in I}  \right )\text{ and } \left(\forall i \in I \right) \left (x_{i} \in X_{i} \right) $$ So, that means $x$ is an n-tuple and by hypothesis, $x$ is a surjective function from the set $I$ to $X$. Then, $x$ lies in set formed above. Hence, the Cartesian product is a set. (I'm sorry for my grammatical mistakes, English is not my first language).",['elementary-set-theory']
435675,Covergence of $\frac{1}{4} + \frac{1\cdot 9}{4 \cdot 16} + \frac{1\cdot9\cdot25}{4\cdot16\cdot36} + \dotsb$,"I am investigating the convergence of the following series: $$\frac{1}{4} + \frac{1\cdot 9}{4 \cdot 16} + \frac{1\cdot9\cdot25}{4\cdot16\cdot36} + \frac{1\cdot9\cdot25\cdot36}{4\cdot16\cdot36\cdot64} + \dotsb$$ This is similar to the series $$\frac{1}{4} + \frac{1\cdot 3}{4 \cdot 6} + \frac{1\cdot3\cdot5}{4\cdot6\cdot8} + \dotsb,$$which one can show is convergent by Raabe's test, as follows: $$\frac{a_{n+1}}{a_n}= \frac{2n-1}{2n+2}= \frac{2n + 2 - 3}{2n+2}=1 - \frac{3}{2(n+1)}.$$ However, in the series I am looking at, $\frac{a_{n+1}}{a_n}=\frac{(2n-1)^2}{(2n)^2}= 1 - \frac{4n-1}{4n^2}$, so Raabe's test doesn't work (this calculation also happens to show that the ratio and root tests will not work). Any ideas for this one? It seems the only thing left is comparison...","['sequences-and-series', 'calculus']"
435680,Quaternions vs Axis angle,Whats the use of representing rotation with quaternions compared to normal axis angle representation? I've been trying to learn quaternions and they make enough sense but as far as I can tell quaternions are just axis angle with a transformed axis and angle of rotation. How exactly does transforming the axis and angle of rotation affect the matrix instead of just representing it normally through axis angle?,"['motivation', 'rotations', 'matrices', 'quaternions', 'linear-algebra']"
435686,Primes inert in quadratic field of class number one,"Let $K = \mathbb{Q}(\sqrt{-d})$ be an imaginary quadratic field of class number one (i.e. every ideal in $\mathcal{O}_K$ is principal, i.e. $\mathcal{O}_K$ is a principal ideal domain). Let $d_K$ be the discriminant of $K$. How does one prove that all primes less than $\frac{1 + |d_K|}{4}$ are inert in $K$?","['algebraic-number-theory', 'abstract-algebra']"
435693,"For polynomial $f$, does $f$(rational) = rational$^2$ always imply that $f(x) = g(x)^2$?","If $f(x)$ is a polynomial with rational coefficients such that for every rational number $r$, $f(r)$ is the square of a rational number, can we conclude that $f(x) = g(x)^2$ for some other polynomial $g(x)$ with rational coefficients? I proved the quadratic case in my answer to this question , and am guessing that the general case is true, but don't know how to proceed. Does this extend to polynomials in several variables? What about in different fields of fractions? Note: this is not true for complex numbers, since every complex value is the square of a complex number, but linear polynomials are not perfect squares It seems like the proper formulation of this question is that if $f(x_1, x_2, \ldots x_n)$ is a polynomial with integer coefficients such that every integer specialization of $x_1, x_2, \ldots, x_n$ is a perfect $p$th power, then $f$ is a perfect $p$th power polynomial. A proof is available here , which further shows that it only needs to hold for some $|x_i| < C$ (though it's a humongous $C$). Theorem 4 answers the question above and is similar to that presented by Franklin. The multi-variable case is dealt with via induction.","['abstract-algebra', 'polynomials']"
435703,Find an example of a complete bounded metric space which is not compact.,"I think the infinite dimensional sphere satisfies the following criteria.  However, I was hoping that someone could come up with a more elementary example.  Thanks. Find an example of a complete bounded metric space which is not compact.",['general-topology']
435705,Prove that $\frac{1}{(1+a)^2}+\frac{1}{(1+b)^2}+\frac{1}{(1+c)^2}+\frac{1}{(1+d)^2}\geq 1$,"Let $abcd=1$ and $a,b,c$ and $d$ are all positive. Prove that
$\dfrac{1}{(1+a)^2}+\dfrac{1}{(1+b)^2}+\dfrac{1}{(1+c)^2}+\dfrac{1}{(1+d)^2}\geq 1$ I am probably able to do this by assuming $a\geq b\geq c\geq d$
and by using derivative show that $\dfrac{1}{(1+a)^2}+\dfrac{1}{(1+b)^2}\geq \dfrac{2}{(1+\sqrt{ab})^2}$ In this way I reduce the number of variables.
However this approach seems to be tedious. Is there any other methods of proving this inequality?
I hope to learn the proof of the inequality in the title.","['inequality', 'algebra-precalculus']"
435715,Prove that $(\sup\{y\in\Bbb R^{\ge0}:y^2\le x\})^2=x$,"This question is a simple one from foundations of analysis, regarding the definition of the square root function. We begin by defining $$\sqrt x:=\sup\{y\in\Bbb R^{\ge0}:y^2\le x\}:=\sup S(x)$$ for $x\ge0$, and now we wish to show that it satisfies its defining property, namely $\sqrt x^2=x$. By dividing into cases $x\le1$ (where $1$ is an upper bound for $S(x)$) and $x\ge1$ (where $x$ is an upper bound for $S(x)$), we know $S(x)$ is upper bounded and hence the function is well-defined for all $x\ge0$. It follows from the intermediate value theorem applied to $f(y)=y^2$ on $[0,\max(1,x)]$ that $\sqrt x^2=x$, if we can prove that $f(y)$ is continuous, but suffice it to say that I would like to prove the IVT later in generality, when I will have the definition $|x|=\sqrt{xx^*}$ (which is used in the definition of continuity), so I hit a circularity problem. Thus I need a ""bootstrap"" version of the IVT for this particular case, i.e. I can't just invoke this theorem. What is the cleanest way to get to the goal here? Assume I don't have any theorems to work from except basic algebra.","['foundations', 'elementary-set-theory', 'real-analysis']"
435722,"$(X,\mathscr T)$ is compact $\iff$ every infinite subset of $X$ has a complete limit point in $X$.","Let $(X,\mathscr T)$ be a topological space. Given $A\subseteq X$, we say that $x$ is a complete limit point of $A$ if for every nbhd $N$ of $x$, $|N\cap A|=|A|$. I want to prove Suppose $(X,\mathscr T)$ is compact. Then every infinite subset $A$ of $X$ has a complete limit point in $X$. PROOF Assume the contrary. Then there exists an infinite subset $A$ of $X$ such that for any $x\in X$, there is a nbhd $N_x$ such that $|N_x\cap A|<|A|$. The collection $\{N_x:x\in X\}$ covers $X$. By compactness, there exists a finite subcover $\{N_{x_1},\ldots, N_{x_n}\}$. Then $A=\bigcup_{i=1}^n A\cap N_{x_i}$. But this is impossible, since $A$ is infinite, and $\bigcup_{i=1}^n A\cap N_{x_i}$ is a finite union of sets strictly smaller than $A$. Is this correct? The problem is in "" Introductory Real Analysis "" by Kolmogorov. Also, is a proof of the converse too complicated? Kolmogorov gives a reference as ""P.S. Alexandroff, Einführung in die Mengenlehre und die Theorie der Reellen Funktionen (1956), pp. 250-251; J.L. Kelley, General Topology (1955), pp. 163-164"" but I have no idea what this means. I am honestly clueless on how to approach it. Could you provide hints? I wouldn't mind a complete answer, if you think it is requires something too advanced.","['general-topology', 'compactness']"
435729,$f(x)=x^{x}$ what happens when $x$ is a negative irrational number?,"Just looking at negative numbers, $x^{x}$ is defined for all rational numbers (on the real plane) in all instances except whenever $x=\large \frac {2a+1}{2b}$ where $(a, b)$ are integers . However, what happens when $x$ takes a negative irrational value, such as $- \pi$? Is $f(x)$  defined there? I don't even think it can be defined as the limit as $x$ approaches those values since I think the function is discontinuous on the negative $x$ axis because of the $x=\large \frac {2a+1}{2b}$ exception.","['calculus', 'algebra-precalculus']"
435746,Geometric distribution with unequal probabilities for trials,"I am researching an engineering problem in which I want to model the probability distribution of the number X of independent trials needed to get one success. If the probability of success at each trial is a constant p, the solution clearly reduces to the simple geometric distribution. However, in this particular case, the probability varies with each trial in a way that I can predict. I feel sure there must already be a body of work on this type of problem that I can refer to, but I have been unable to find it. I have come across the Poisson Binomial distribution which models the probability distribution of the number of successes in a sequence of X independent yes/no experiments with different success probabilities. So I naturally searched for the Poisson Geometric or Geometric Poisson distribution, but this in fact refers to something quite different (a variation on the Poisson rather than Geometric distribution). Can anyone help with the name of the distribution I am looking for?","['statistics', 'probability-distributions', 'probability-theory']"
435750,On a proposition of Engelking's General Topology,"Let $\mathcal{F}$ and $\mathcal{F'}$ be filters on a set.
We say that $\mathcal{F'}$ is finer than $\mathcal{F}$ if $\mathcal{F'} \supset \mathcal{F}$. A point $x$ of a topological space $X$ is called a cluster point of a filter $\mathcal{F}$ if $x$ belongs to the closure of every member of $\mathcal{F}$. Is the following assertion in Engelking's book General Topology (1989) p.52 true? (Part of)Proposition 1.6.8 If $x$ is a cluster point of a filter $\mathcal{F}$, then $x$ is a limit of a filter $\mathcal{F'}$ that is finer than $\mathcal{F}$.","['general-topology', 'filters']"
435761,Differentiability of projection,"Where $\pi_i:\Bbb R^n\rightarrow\Bbb R$ is projection onto the $i$th coordinate, the differentiability of $\pi_i$ at $X$ is given by: $$\pi_i(X+H)-\pi_i(X)=\textrm{grad}\ \pi_i(X)\cdot H+||H||g(H)$$ Where $g$ tends to $0$ as its argument does. We deduce: $$g(H)=\frac{h_i}{||H||}(1-x_i)$$ Where $h_i$ and $x_i$ are the $i$th coordinates of $H$ and $X$ respectively. But how can this tend to zero? What if $H$ is approaching along the $i$th axis? Then $||H||=|h_i|$ and the limit either doesn't exist or is equal to $1-x_i$.","['multivariable-calculus', 'calculus']"
435771,How to get maximum sums from groups of numbers without exceeding a total?,"This is an abstract computer code application that I'm trying to solve, but I think the following real life example kind of helps to illustrate the type of problem I'm working with. In this example, the first group contains railroad passenger cars. Each object (a passenger car) in this group has 2 properties: weight, and length. The second group contains railroad cattle cars. Each object in this group also has the same 2 properties: weight, and length. The third group might contain luggage cars, and all have the weight and length properties. etc. etc... (there need to be 7 groups total, but I think you get the idea). The weight and length for each car in each group can be different. Now, there is a locomotive, which can pull 7 cars, and 1 car must come from each group. Moreover, the combined weight of the 7 cars cannot exceed x , and the combined length of the 7 cars cannot exceed y . What's the mathematical process for determining which 7 cars will get as close to the weight and length limits as possible without exceeding them?",['discrete-mathematics']
435790,a subclass of quasi metric spaces with properties almost identical to metric spaces,"It is well known that passing from metric spaces to quasi-metric spaces (i.e., dropping the requirement that the metric function $d:X\times X\to \mathbb R$ satisfies $d(x,y)=d(y,x)$) carries with it immediate consequences to the general theory. For instance, uniqueness of limit of a sequence does not necessarily hold, bifurcations in the meaning of Cauchy sequences etc. There are however, two classes of quasi metric spaces where things look very much like the symmetric case. Some definition: Let $(X,d)$ be a quasi metric space. Say that $X$ has vanishing asymmetry at $x\in X$ if for all $\epsilon >0$ there exists $ \delta >0$ such that $d(x,y)\le \delta$ implies $d(y,x)\le \epsilon$. Say that $X$ is of vanishing asymmetry if it has vanishing asymmetry at each $x\in X$. Say that $X$ is of uniformly vanishing asymmetry if for all $\epsilon > 0$ there exists $\delta >0$ such that for all $x,y\in X$ if $d(x,y)\le \delta $ then $d(y,x)\le \epsilon $. Another way to view these conditions is as follows. Let $QMet$ be the category of all quasi metric spaces (with non-expanding maps). There is then a functor $QMet\to QUnif$, to quasi uniform spaces, sending a quasi metric space $X$ to the quasi uniformity generated by the entourages $\{(x,y)\in X\times X)\mid d(x,y)\le \epsilon\}$ (where $\epsilon >0$ ranges). Similarly, there is another functor  $QMet\to QUnif$ sending $X$ to the quasi uniformity generated by the entourages $\{(x,y)\in X\times X)\mid d(y,x)\le \epsilon\}$. The equalizer of these two functors is the full subcategory of $QMet$ spanned by those spaces satisfying uniformly vanishing asymmetry. Similarly, there are two functors $QMet\to Top$ and the equalizer of these is the full subcategory of $QMet$ spanned by the spaces of vanishing asymmetry. My question is, are these classes of quasi metric spaces known and if so, what is the common terminology. Any references are welcome.","['general-topology', 'metric-spaces', 'terminology', 'uniform-spaces']"
435800,"Can we rearrange the integers, such that the arithmetic average of any two numbers does not appear between them?","Can we rearrange the integers, such that the arithmetic average of any two numbers does not appear between them? In other words : Can we have a sequence $\{a_n\}_{n\in \mathbb{Z}}$, where all integers appear once and only once , such that $a_j\ne (a_i+a_k)/2,\forall i<j<k$? I've noticed the questions here and here . But the first one only applies to arbitrarily long finite segments. The second does not contain a solution in itself, and unfortunately I can not access the reference (for free). Also, the second question is much more general than this one, so I am wondering if this one can be solved somewhat more easily.","['number-theory', 'combinatorics']"
435801,Calculate the Lie Derivative,"In trying to get to grips with Lie derivatives I'm completely lost, just completely lost :(
Is there anyone who could provide an example of calculating the Lie derivative of the most basic function you can, i.e. like in showing someone how to calculate the derivative you'd pick something like $f(x) \ = \ x^2$, by using all possible formuations of the lie derivative, simply as a means to illustrate the idea. Thus we could calculate it on $f(x) \ = \ x^2$ & $\vec{v}(x,y) \ = \ x^2i \ + \ 2y^2j$, I cannot find one simple calculation of this thing anywhere :(",['differential-geometry']
435806,Orthogonal Coordinate Systems Intuition,"I'd really love it if you could give some intuition on how to derive the $x$, $y$ & $z$ coordinates from all/any of the orthogonal coordinate systems in this list , how you think about, say, bipolar coordinates if you had to re-derive the coordinate system on a desert island etc... Apart from spherical & cylindrical I have no idea how to remember the others, these two I remember because I can think of the picture & re-derive how to express $x$, $y$ & $z$ in terms of $r$, $θ$ & $z$ etc... but the others are completely crazy geometrically & I have no intuition on them, & I need to at least learn how to represent $x$, $y$ & $z$ in terms of each system (so I can get grad, div, curl etc...) along with intuition on when to use them. One interesting example of what I'm hoping for is with toroidal coordinates whose wiki is incomprehensible yet apparently there is an insanely simply way (page 114, also in this link ) to derive a weak version of this coordinate system via a picture, any intuition on the rest of them? The most important example, however, is confocal ellipsoidal coordinates (the easiest mathematical derivation of which, is given here ). This aspect of the question has also been asked in this post , and it sets the tone for this question. The closest thing to a geometric interpretation for this system is given in Hobson , again though, no picture, merely a special case of what I asked for in my post and the pictures in my post as also special cases of the general case. Mathematically ellipsoidal coordinates are the most important because one can derive all the other coordinates from these by simple substitutions (a link to these substitutions in Morse and Feshbach is in the ""in this post"" link), ideally the goal will be to give geometric interpretations for all these substitutions as well (so we'd have two ways of getting all the coordinate systems!). So: a) Draw a picture, b) Draw the projections determining the coordinates, analogous to this:","['coordinate-systems', 'intuition', 'differential-geometry']"
435812,A die is rolled until a 6 comes up. Should the sample space of this experiment contain the set of all infinite sequences which do not contain a 6?,"Is there a standard way to view this? The problem is, In an experiment, die is rolled continually until a 6 appears, at which point the experiment stops. What is the sample space of this experiment? My first instinct was to say that it was the set of all finite sequences with exactly one 6, which is in the final position. But this neglects the (zero-probability) event that a 6 never comes up. Should this be in the sample space? Does it matter?",['probability']
435813,Laplace equation upper plane using conformal mapping,"Find a solution $u(x,y)$ of Laplace’s equation on the domain
$-\infty< x < \infty$  and $0 <y<$ $\infty$ for which $u(x,0)=x^{1/2}$ for $0<x< \infty$. What is $u(x,0)$ for $-\infty <x< 0$? I am solving older qualifying on Applied, complex part. And we study the conformal mapping has application for Laplace equation. Usually intersection between two circles with constant boundaries condition that we send to a strip with conformal mapping and we can see that the solution does not depend of one of the variables so.. you get the solution has linear form $cx+d$ and then you use the boundaries condition and get the answer. But here... The condition is not constant, and it is only on some part of the boundary.
So... My question is , if I send it to a strip too with a $\ln z$ I only have the boundary condition for $y=0$ that is $x^{1/2}$ and I need to find an answer for the region and for the boundary $y= \pi$. Or what could be another region I can send it? The idea is use the less PDE theory, so I do not want to send it to the circle and use Poisson. (Since this for people who has no PDE courses too) Should be the other part of the boundary condition $u(x,0)= -(-x)^{1/2}$ for $-\infty <x< 0$ ?","['partial-differential-equations', 'complex-analysis']"
435819,Trigonometry - Finding the range of the function,"Problem : $$f(\theta)=(2\sqrt{3}+4)\sin\theta +4\cos \theta $$ I have studied if the function is in the form : $f(\theta)=a\cos\theta + b\sin\theta$ then the range of this function can be given as $$[-\sqrt{a^2+b^2} ,\sqrt{a^2+b^2}]$$ So, here  the range will be [-$44+16\sqrt{3} , 44+16\sqrt{3}]$ But this is the wrong answer.. please guide.. thanks..","['trigonometry', 'calculus', 'functions']"
435820,Proving The Average Value of a Function with Infinite Length,"This is the given: One can extend the definition of the average value of a continuous function $f(x)$ to the interval $[a,\infty)$ of infinite length as follows: $$f_{\text{ave}}=\lim_{t\rightarrow\infty}\frac1{t-a}\int_a^tf(x)dx$$ Suppose that $f(x)$ is an arbitrary continuous function. Assume that $f(x) \ge 0$ in the interval $[a,\infty)$ and that the integral $\int_0^{\infty}f(x) \ dx$ is divergent. Prove that $f_{ave}=\lim_{x\rightarrow\infty}f(x)$ if this limit exists. My work: $$f_{\text{ave}}=\lim_{t\rightarrow\infty}\frac1{t-a}\int_a^tf(x)dx = \lim_{t\rightarrow\infty}\frac{F(t)-F(a)}{t-a},~~~ \text{F is an antiderivative of}\ f$$ After this, I'm sort of stuck. What I'm thinking is: $f(x) \ge 0 \Rightarrow F(x)$ is increasing. So we can continue like so: $$ = \lim_{t\rightarrow\infty}(f(t)-f(a))$$ by L'Hospital. It seems close but there's still $f(a)$ which leads me to believe that I made a wrong assumption/calculation somewhere. Can someone point me to the right direction?","['average', 'calculus', 'integration', 'functions']"
435831,"If $A$ and $B$ are positive definite, then is $B^{-1} - A^{-1}$ positive semidefinite?","I've found this while googling some properties of positive semidefinite matrices. (Unfortunately, I cannot remember where I've discovered it.) If this is true, it'll greatly save my time in my work. Is it true? How can you prove it? Let's say I have two real symmetric and positive definite matrices $\mathbf A$ and $\mathbf B$ of the same size. Also, assume that $\mathbf A - \mathbf B$ is positive semidefinite too. Then, $\mathbf B^{-1} - \mathbf A^{-1}$ is also positive semidefinite.",['linear-algebra']
435846,Notation of random variables,"I am really confused about capitalization of variable names in statistics.
When should a random variable be presented by uppercase letter, and when lower case? For a probability $P(X \leq x)$, what do $x$ and $X$ mean here?","['statistics', 'probability', 'notation']"
435880,"If $AA^T$ is the zero matrix, then $A$ is the zero matrix","Let $A$ be a $4 \times 4$ matrix. Show that if $A^TA$ or $AA^T$ is the zero matrix, then $A$ is the zero matrix. I feel very close to solving the problem so far. I have said that $$[0]_{ij}=\sum_{k=1}^4 [A]_{ik}[A^T]_{kj} =\sum_{k=1}^4 [A]_{ik}[A]_{jk} \qquad \text{for all }i,j \in \{1,2,3,4\} $$ and proven for the case if $i=j$. However, I cannot seem to find a good way to prove it to be true if $i\neq j$.","['matrices', 'linear-algebra']"
435886,Does every absorbing set of a Banach space contain a neighborhood of origin?,Let $X$ be a Banach space and $A$ be any absorbing subset of $X$. Does $A$ contain a neighborhood of the origin?,['functional-analysis']
435906,$|\mathbb{R}^\mathbb{R}|$ vs $|P(\mathbb{R})|$ Which is bigger?,$|\mathbb{R}^\mathbb{R}|$ vs $|P(\mathbb{R})|$ where $\mathbb{R}^\mathbb{R} =\{f | f:\mathbb{R} \rightarrow \mathbb{R}\}$ Are they equal? Which is bigger? How can I prove it?,"['cardinals', 'elementary-set-theory']"
435912,Definition of formal neighbourhood,"Consider the scheme $\mathbb{P}^1$, and the point $0 \in \mathbb{P}^1$. What is the formal neighbourhood of $0$ in $\mathbb{P}^1$? Or if you know a good reference, that would be helpful.",['algebraic-geometry']
435915,Is the divergence of a gradient field the trace of the Hessian?,"Given a $C^2$ multivariate function $f : \mathbb{R}^d \to \mathbb{R}$, the gradient defines a vector field, the divergence of this vector field, then, should be the trace of the Hessian matrix, right?  I'm not entirely sure because the simplified version of divergence is only ever given for $d=3$.",['multivariable-calculus']
435935,what does it mean when $\operatorname{E}[X^2]$ diverges?,"is it possible for a random variable $X$, such that the expected value of $X^2$, $\operatorname{E}[X^2]$ is a divergent integral? If it is impossible, does that mean the probability density function of $X$ is wrong? (the integral of the probability density function over the support does not equal to $1$) Also, since $\operatorname{Var}[X] = \operatorname{E}[X^2] - \operatorname{E}[X] ^ 2$, does $\operatorname{Var}[X]$ still exist in this case?","['statistics', 'probability']"
435950,Understanding differentials,"What is a good reference to learn about differentials and related topics.  Some of my questions are: Why is it possible to split $dy/dx$ into individual terms $dx$ and $dy$? In a separated differential equation such as $F(x)dx + G(y)dy = 0$, what is the physical intuition behind ""$F(x)dx$""? When integrating the latter equation, what variable is integrated over?  Usually, if $f(x) = 0$, then we can integrate over $x$, like $\int f(x)\,dx=c$. But how de we arrive at $\int F(x)dx + \int G(y)dy = c$? A detailed, but introductory-level reference is sought.  As a bonus, feel free to shed light on any of the above questions.","['ordinary-differential-equations', 'calculus', 'reference-request', 'derivatives']"
435952,Probability that two randomly chosen permutations will generate $S_n$.,"Every undergraduate learns a fact about the symmetric group that $(1\,2)$ and $(1\,2\,\cdots\,n)$ generate $S_n$. Also, it is interesting to know that for a prime $p$, any 2-cycle and any $p$-cycle generates $S_p$, but an arbitrary $2$-cycle and arbirtary $n$-cycle may not generate $S_n$. There is a criteria for the later: Theorem: For $1\leq i<j\leq n$, $\langle (1\,2\,\cdots\,n), (i\,j)\rangle=S_n$ if and only if $(n,j-i)=1$. With these interesting facts, I would like to ask two questions: Q.1 If $\sigma,\tau\in S_n$ are cycles then what is the necessary and / or sufficient condition on $\sigma,\tau,n$ so that $\langle \sigma,\tau\rangle=S_n$? Q.2 What is the totality of subsets $ S\subseteq S_n$ such that $|S|=2$ and $\langle S\rangle=S_n$? (Answers to the both questions will involve combinatorics, and this will be a good place to see how combinatorics is useful to study finite groups; in fact, a part of answer will also involve nice combinatorial arguments. The second question may be hard!)","['finite-groups', 'group-theory', 'symmetric-groups', 'combinatorics']"
435956,Evaluating $\sum_{n=1}^{\infty} {(-1)^n \cdot \frac{2^{2n-1}}{(2n+1)\cdot 3^{2n-1}}}$,"Calculate the summation $\sum_{n=1}^{\infty} {(-1)^n \cdot \frac{2^{2n-1}}{(2n+1)\cdot 3^{2n-1}}}$. So I said: Mark $x = \frac{2}{3}$. Therefore our summation is $\sum_{n=1}^{\infty} {(-1)^n \cdot \frac{x^{2n-1}}{(2n+1)}}$. But how do I exactly get rid of the $(-1)^n$? Also I notice it is a summation of the odd powers of $x$, how can I convert it to a full sum? (I know I should subtract from the full sum) but the signs of this summation is different than the signs of the full sum",['calculus']
435965,Equality of a supremum of two Expectation,"I got stuck to prove an equality in a detailed way and I hope, someone could tell to me, how to fix it. Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $\mathcal{K}$ be the set of all probability measure $Q$, which are absolutely continuous with respect to $P$. We are given a r.v. $X$. Suppose there is a $N\in\mathbb{N}$ such that for all $n\ge N$ we have $$\inf_{Q\in\mathcal{K}}Q(X\ge n)=0$$ I want to verify (in detailed way) the following equality: $$\sup_{Q\in\mathcal{K}}E_Q[-(X\wedge n)]=\sup_{Q\in\mathcal{K}}E_Q[-(X\wedge N)]\ge -N$$ The inequality is clear, since $-(a\wedge b)=-a\vee -b\ge -b,-a.$ We can rewrite the equality as: $$\inf_{Q\in\mathcal{K}}E_Q[X\wedge n]=\inf_{Q\in\mathcal{K}}E_Q[X\wedge N]$$ My idea was: $E_Q[X\wedge n]=E_Q[X\wedge n(\mathbf1_{X\ge n}+\mathbf1_{X< n})]=nQ(X\ge n)+E[(X\wedge n)\mathbf1_{X<n}]$. The inf over the first term is zero, but at the end I did not get the RHS. So how can I prove this in a detailed way? The equality is stated in this paper , see proof of Theorem 5.4 the direction $3)\Rightarrow 1)$.",['probability-theory']
436005,"Find maximum and minimum of $f(x,y) = x^2 y^2 - 2x - 2y$ in $0 \leq x \leq y \leq 5$.","Find maximum and minimum of $f(x,y) = x^2 y^2 - 2x - 2y$ in $0 \leq x \leq y \leq 5$. So first we need to check inside the domain, I got only one point $A(1,1)$ where $f(1,1) = -3$. and after further checking it is a saddle point. Now we want to check on the edges, we have 3 edges: $(1) x=y, 0\leq x\leq y \leq 5$ and $(2) y=5, 0 \leq x \leq 5$ and $(3) x=0, 0\leq y \leq 5$. So I started with each of them, using Lagrange. I started with the first and got: $l(x,y,\lambda) = x^2y^2 - 2x - 2y + \lambda (x-y)$. $l_x(x,y) = 2xy^2 - 2 + \lambda = 0$ $l_y(x,y) = 2x^2y - 2 - \lambda = 0 $ $x-y = 0 \rightarrow x=y$. But then what to do ? I always get $x,y = \sqrt[3]{1+ 0.5\lambda}$, which gets me nowhere. Any help would be appreciated","['optimization', 'multivariable-calculus', 'calculus']"
436006,A step in the proof of the Riemann Mapping Theorem,"Let $\Omega \subsetneq \Bbb C$ be open and simply connected. Let $\overline{\Bbb C}$ denote the Riemann sphere and assume without loss of generality that $0 \in \overline{\Bbb C} \backslash \Omega$. Is there some result that allows us to conclude that $\exists$ a path $\gamma$ in $\overline{\Bbb C} \backslash \Omega$ between $0$ and $\infty$? I am positive that this is true but I am unaware of what allows us to conclude this. An explanation from the view-point of point-set topology will be particularly appreciated but if such does not exist, any relatively understandable explanation will do. Please recall that you cannot quote the Riemann Mapping Theorem as this is what we are trying to prove.","['differential-geometry', 'general-topology', 'connectedness', 'complex-numbers', 'complex-analysis']"
436027,Comparison Statement,"I'm looking for a statement like this (and for a proof too): Let $\gamma_1,\gamma_2:\mathbb R\to (M,g)$ two curves (parametrized by arclength) in a Riemannian manifold $(M,g)$ and let $\gamma_1(0)=\gamma_2(0)$ and $\gamma_1'(0)=\gamma_2'(0)$. Now the claim is as follows: Let $|D_t\gamma_1'(t)|>|D_t\gamma_2'(t)|$ for all $t$ and let $s_1$ respectively $s_2$ be the times, when $\gamma_1$ respectively $\gamma_2$ leave the geodesic ball of radius say $r$ centered at $\gamma_i(0)$ for the first time ($r$ can be small, I'm interested in a local statement). Then $s_1>s_2$. The statement seems to be obvious but I can't come up with a proof... Thanks for any ideas.","['riemannian-geometry', 'differential-geometry']"
436047,Spectrum of Lyapunov exponents of a linear system,"Question : How to show that the eigenvalues of matrices $\mathbf{A}$ and
$
\mathbf{L} = \log \lim_{t \to \infty} \left((e^{\mathbf{A}t}e^{\mathbf{A^T}t})^{\frac{1}{2t}}\right)
$
have equal real parts? Motivation : Consider a system
$$
\dot{\mathbf{x}} = \mathbf{Ax}
$$
where $\mathbf{A}$ is some constant matrx and $\mathbf{M}(t) := e^{\mathbf{A}t}$ is the evolution operator. The Lyapunov exponents of this system are then given by the eigenvalues of $$
\mathbf{L} :=
\log \lim_{t \to \infty} \left((\mathbf{M}(t)\mathbf{M^T}(t))^{\frac{1}{2t}}\right) = 
\log \lim_{t \to \infty} \left((e^{\mathbf{A}t}e^{\mathbf{A^T}t})^{\frac{1}{2t}}\right)
$$ Now, on the other hand, the rate of expansion for a system above is constant and is also given by the real parts of $\mathbf{A}$'s eigenvalues. Therefore, eigenvalues of $\mathbf{L}$ are equal to real parts of eigenvalues of $\mathbf{A}$. I have checked it numerically and it also makes sense intuitively, but I don't see why, technically, the relation holds.","['matrices', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
436049,Determining the angle degree of an arc in ellipse?,"Is it possible to determine the angle in degree of an arc in ellipse by knowing the arc length, ellipse semi-major and semi-minor axis ?
If I have an arc length at the first quarter of an ellipse and I want to know the angle of it, what is the data that I will need it to use it and what is the exact method to use it? Please take a look at this picture: Actually I know how to determine the arc length of a ellipse here . but I want to do the obverse.","['geometry', 'conic-sections', 'circles', 'differential-geometry']"
436062,Complex analysis book for Algebraic Geometers,I know that there exist many questions on this site on complex analysis books but my question is more specific than that. I am looking for recommendations for a concise complex analysis book but with a view towards algebraic geometry/ complex manifolds . I have studied smooth manifold theory before and it would be interesting to see it combined with complex analysis in the complex setting (all manifolds that I'd studied before were real manifolds). Any recommendations for such a book?,"['algebraic-geometry', 'reference-request', 'complex-analysis']"
436122,Limits and exponents and e exponent form,"So I know that $\underset{n\rightarrow \infty}{\text{lim}}\left(1+\frac {1}{n}\right)^n=e$ 
and that we're not allowed to see it as $1^\infty$ because that'd be incorrect. 
Why is then that we can do the same thing with (for example): $$\lim_{n\rightarrow \infty} \left(1+\sin\left(\frac {1}{n}\right)\right)^{n\cos\left(\frac {1}{n}\right)}= \lim_{n\rightarrow \infty} \left(\left(1+\sin\left(\frac {1}{n}\right)\right)^\frac {1}{\sin\left(\frac {1}{n}\right)} \right)^{n\cdot\cos\left(\frac {1}{n}\right)\sin\left(\frac{1}{n}\right)}$$ What I mean by that is that in the example of $e$ we can't say it'  $\lim \left(1+\frac {1}{n}\right)^{\lim  (n)}=1^\infty$ While in the second example that's exactly what we do (we say that the limit of the base is $e$ while the limit of the exponent is 1 which is why the entire expression is equal to $e$. Can anyone explain to me the difference between the two?","['sequences-and-series', 'calculus', 'limits']"
436134,Testing $\sin\theta$ and $\cos\theta$ without referring to the trigonometric functions,"This is very much not my area so apologies if this is an obvious no. Suppose values have been calculated for $\sin\theta$ and $\cos\theta$. Is it possible to test their correctness, without referring to the trigonometric functions, imaginary numbers, or performing an infinite number of operations?",['trigonometry']
436136,Solve the following differential equations by converting to Clairaut's form through suitable substitutions.,"The question comprises of three subparts which need to be converted to Clairaut's form through suitable substitutions and then solved : (a) x p 2 - 2yp + x + 2y = 0 (b) x 2 p 2 + yp (2x + y) + y 2 = 0 (c) (x 2 +y 2 )(1+p) 2 -2(x+y)(1+p)(x+yp)+(x+yp) 2 =0 Note : p = dy/dx I understand that Reducing to Clairaut's form involves suitable substitution so as to bring it in the form of V = P U + f(P) but i am unable to form any intuition about what such substitutions might be , as the above equations seem complicated with more than one combination of variables and 'p'. I have added three sub-parts to get a better understanding of the intuition involved in such substitutions. Help would be greatly appreciated. Thanks.","['multivariable-calculus', 'ordinary-differential-equations', 'calculus']"
436153,Integral of $\int \frac{dx}{\sqrt{x^2 -9}}$,"$$\int \frac{dx}{\sqrt{x^2 -9}}$$ $x = 3 \sec \theta \implies dx = 3 \sec\theta \tan\theta d\theta$ $$\begin{align} \int \frac{dx}{\sqrt{x^2 -9}} & = \frac{1}{3}\int \frac{3 \sec\theta \tan\theta d\theta}{\tan\theta} \\ \\ & = \int  \sec\theta d\theta \\ \\ & = \ln | \sec\theta + \tan\theta| + c\end{align}$$ $x = 3\sec \theta  \implies \sec\theta = \frac {x}{3}$ $\tan\theta = \frac{\sqrt{x^2 - 9}}{x}$ I have have confused x with 3 but I cannot get the proper answer which is $$\ln | x +  \sqrt{x^2 - 9}| + c$$ I always get $\dfrac{x}{3}$ or $\dfrac{\sqrt{x^2 - 9}}{x}$ or some variation of that, I can't eliminate them to get their answer.","['calculus', 'integration']"
436163,Topological degree and homology,"Let $f : \mathbb{S}^n \to \mathbb{S}^n$ be a continuous function. From homology, the degree $\deg_1(f)$ of $f$ can be defined as the integer $n$ such that $f_* : x \mapsto n \cdot x$, where $f$ induces the morphism $f_* : \mathbb{Z} \simeq H_n(\mathbb{S}^n) \to \mathbb{Z} \simeq H_n(\mathbb{S}^n)$. From topological degree, the degree $\deg_2(f)$ of $f$ can be defined as $\deg(\tilde{f},B^{n+1},0)$, where $\deg$ is the Brouwer degree as defined in the book Topological Degree Theory and Applications or in the paper An Elementary Analytic Theory of the Degree of Mapping in n-Dimensional Space and $\tilde{f} : \overline{B}^{n+1} \to \mathbb{R}^{n+1}$ is a continuous extension of $f$ on the unit closed ball of $\mathbb{R}^{n+1}$. (The integer $\deg_2(f)$ does not depend on the choice of $\tilde{f}$.) Question: Do $\deg_1$ and $\deg_2$ coincide? I think it is true, but probably I do not have enough knowledge about homology theory to find a rigorous proof... Added: Let $\Omega \subset \mathbb{R}^n$ be a bounded open set, $f : \overline{\Omega} \to \mathbb{R}^n$ be a continuous function $C^1$ on $\Omega$ and $p \notin f(\partial \Omega)$ a regular value of $f$. The Brouwer degree of $f$ is defined by $$\deg(f,\Omega,p)= \sum\limits_{x \in f^{-1}(p)} \mathrm{sign}(J_f(x))$$ where $J_f$ is the Jacobian determinant of $f$. It can be shown that $\deg(g,\Omega,q)=\deg(f,\Omega,p)$ if $q$ is a regular value of a function $g \in C^1(\overline{\Omega})$ such that $\sup\limits_{x \in \overline{\Omega}} \|f(x)-g(x)\|$ and $\|p-q\|$ are sufficiently small. Using Sard theorem and Stone-Weierstrass approximation theorem, we can define the Brouwer degree of a continuous function $f: \overline{\Omega} \to \mathbb{R}^n$ with respect to a bounded open set $\Omega \subset \mathbb{R}^n$ and a point $p \notin f(\partial \Omega)$ by $$ \deg(f,\Omega,p)=\lim\limits_{n \to + \infty} \deg(f_n,\Omega,p_n)$$ where $(f_n)$ is a sequence in $C^1(\overline{\Omega})$ converging uniformly to $f$ and $p_n$ is a regular value of $f_n$ for each $n$.","['general-topology', 'homology-cohomology', 'algebraic-topology']"
436168,Interchanging limit and integration when bounds of integration depend on a parameter,"This is yet another question on when it is permissible to interchange limits and integrals. I am interested in the situation when bounds of integration depend on some parameter, and then the limit is taken with respect to that parameter. Suppose one has a function $f(x,t)$ where $t$ is some parameter. Functions $a(t)$ and $b(t)$ give the bounds of integration. Let $a(t) \to a$ and $b(t) \to b$ as $t \to T$. I am interested in sufficient conditions that justify claiming that
$$
\lim_{t \to T} \int_{a(t)}^{b(t)} f(x, t) \, \mathrm{d}x= \int_a^b f(x,T) \, \mathrm{d} x.
$$ Well-known versions of the recipes for interchanging limit and integral (Monotone Convergence and Dominated Convergence Theorems) seem to assume that the region of integration is constant, i.e. $a(t) = a$ and $b(t) = b$ for all $t$.","['calculus', 'integration', 'limits']"
436213,"Does ""maximal submodule <=> simple quotient module"" generalize to abelian categories?","Does the statement ""If $A$, $B$ are modules over a commutative ring $R$, then $B$ is a maximal submodule of $A$ if and only if $A/B$ is a simple module"" generalize to the setting of abelian categories?  That is, is it true to say ""If C is an abelian category and $A, B \in$ C , then $B$ is a maximal subobject of $A$ if and only if $A/B$ is a simple object?"" My hunch is that this statement does generalize, since I've seen it stated that the Jordan-Holder theorem for abelian categories is a ""straightforward generalization"" of the version for modules (wherein this fact is used), but I've had a lot of trouble finding anything on maximal subobjects at all and I haven't figured out the details yet.","['modules', 'category-theory', 'abstract-algebra', 'abelian-categories']"
436218,A bounded holomorphic function,"If $\Omega$ is a region which is dense in $\mathbb{C}$, $f\in H(\Omega)$ and is continuous on $\mathbb{C}$, moreover $f$ is bounded on $\mathbb{C}$, can we claim that $f$ is a constant?",['complex-analysis']
436222,Trying to understand open (closed) subfunctors,"I am trying to read about functor of points and I am struggling with the definition of open subfunctor. The definition is the following. A subfunctor $\alpha\colon G\to F$, where $F,G\in \mathsf{Fct}(\mathsf{Rings},\mathsf{Sets})$ is called open (closed) if for any $\psi\colon h_{\mathrm{Spec}(R)}\to F$ the fibered product $G_\psi=G\times_F h_{\mathrm{Spec}(R)}$ yields a map $G_\psi\to h_{\mathrm{Spec}(R)}$ isomorphic to injection from the functor represented by some open (closed) subscheme of $\mathrm{Spec}(R)$. Can you, please, explain why is it true that open subfunctors of $F=h_{\mathrm{Spec}(S)}$ are exactly the functors $G$ of the form $G(T)=\{\phi\in F(T)\mid \phi^*(I)T=T\}$ for some ideal $I\subset S$? This is the exercise $VI.6$ in Eisenbud-Harris "" Geometry of Schemes "". Can you, please, explain how to think about these subfunctors? Thank you very much!",['algebraic-geometry']
436225,Uses of the incidence matrix of a graph,The incidence matrix of a graph is a way to represent the graph. Why go through the trouble of creating this representation of a graph? In other words what are the applications of the incidence matrix or some interesting properties it reveals about its graph?,"['graph-theory', 'applications', 'combinatorics']"
436255,Finding the maximum number of subspaces of a vector space over finite field that satisfy these relations,"I have a question and I am stuck. I was wondering if anyone has a thought, before I start a brute-force search. For $q$ a prime number and $n =6$, let $\mathbb {F}_{q}^{n}$ be an $n$-dimensional vector space over $\mathbb{F}_{q}$.
  Furthermore, let $ U_1, \dots, U_m$ be a family of $2$-dimensional subspaces of $\mathbb{F}_{q}^n$ such that $U_i \cap U_j = \{0\}$ and $\langle U_i, U_j \rangle \cap U_k = \{0\}$, for all $i, j, k \in \{1,\dots, n\}$, $i\neq j \neq k$. What is the biggest possible $m$? Thanks in advance.","['vector-spaces', 'finite-fields', 'linear-algebra', 'finite-groups', 'combinatorics']"
436285,"If $N$ and $G/N$ are virtually solvable, then $G$ is virtually solvable?","(""Virtually solvable"" means there's a solvable subgroup of finite index.) I know this statement holds if ""virtually solvable"" is replaced by ""solvable"", but I want to knock it down to the finite-index subgroup case. I'm pretty sure this is a true statement, although you might have to add a ""sub-exponential growth"" hypothesis. Probably not though. My line of attack is the same as in the proof of ""$N$, $G/N$ solvable $\implies$ $G$ solvable"". First, since $G/N$ is solvable, it has a subgroup $H/N$ of finite index and $H/N$ is solvable. Apply the correspondence theorem: $[G : H]  = [G/N : H/N] < \infty$, and a solvable series for $H/N$ corresponds to a chain of subgroups $ H = H_0 \geq H_1 \geq \cdots \geq H_{m-1} \geq H_m = N $ where $H_k/H_{k+1}$ is abelian. Next, $N$ has a subgroup $N_0$ with $[N : N_0] < \infty$ and $N_0$ is solvable. Then $[G:N_0] = [G : H][H:N][N:N_0]$ and since $[G:H], [N:N_0] < \infty$ it suffices to show that $[H:N]<\infty$. I'm stuck here. Is this the right direction to go with this? It doesn't seem like the above chain of subgroups $H_0,\ldots,H_m$ helps at all.","['solvable-groups', 'group-theory']"
436293,What does δA mean in differentiation?,"To be more specific, I met this when doing analytical mechanics involving the principle of least action:","['multivariable-calculus', 'partial-derivative', 'calculus', 'physics']"
436304,What can be said about $E[1_A\mid\mathcal F]$?,"It is known that $E[X\mid 1_A]$ is of particularly nice form. What can be said about the form of $E[1_A\mid\mathcal{F}]$ for ""general"" $\mathcal{F}$? Is it true that $E[1_A\mid\mathcal{F}]=1_B$ for some $B\in \mathcal{F}$?","['probability-theory', 'probability', 'conditional-probability']"
436309,Using trig substitution to evaluate $\int \frac{dt}{( t^2 + 9)^2}$,"$$\int \frac{\mathrm{d}t}{( t^2 + 9)^2} = \frac {1}{81} \int \frac{\mathrm{d}t}{\left( \frac{t^2}{9} + 1\right)^2}$$ $t = 3\tan\theta\;\implies \; dt = 3 \sec^2 \theta \, \mathrm{d}\theta$ $$\frac {1}{81} \int \frac{3\sec^2\theta \mathrm{ d}\theta}{ \sec^4\theta} = \frac {1}{27} \int \frac{ \mathrm{ d}\theta}{ \sec^2\theta} = \dfrac 1{27}\int \cos^2 \theta\mathrm{ d}\theta $$ $$ =\frac 1{27}\left( \frac{1}{2} \theta + 2(\cos\theta \sin\theta)\right) + C$$ $\arctan \frac{t}{3} = \theta \;\implies$ $$\frac{1}{27}\left(\frac{1}{2} \arctan \frac{t}{3} + 2 \left(\frac{\sqrt{9 - x^2}}{3} \frac{t}{3}\right)\right) + C$$ This is a mess, and it is also the wrong answer. I have done it four times, where am I going wrong?","['calculus', 'integration']"
436318,Adjoint matrix eigenvalues and eigenvectors,"I just wanted to make sure that the following statement is true: Let $A$ be a normal matrix with eigenvalues $\lambda_1,...,\lambda_n$ and eigenvectors $v_1,...,v_n$. Then $A^*$ has the same eigenvectors with eigenvalues $\bar{\lambda_1},..,\bar{\lambda_n}$, correct?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'functional-analysis']"
436320,The indefinite integral $\int{\frac{\mathrm dx}{\sqrt{1+x^2}}}$,"I need to solve this integral: $$\int{\frac{\mathrm dx}{\sqrt{1+x^2}}}$$ First I thought it was easy, so I tried integration by parts with $g(x)=x$ and $g'(x)=1$: $$\int{ \frac{x^2}{(1+x^2)^{\frac{3}{2}} }}\,\mathrm dx $$ But I've made it even more complicated than before, and if I want to solve it again by parts I'll have $g(x)= \frac{x^3}{3}$ , and I will never end integrating. How should I solve it? Edit Trying this way: $x= tg(t)$, then I get: $$ \int{ \frac{1+tg^2(t)}{ \sqrt{1+ tg^2(t)} } dt}= \int{ \sqrt{ 1 + tg^2(t) } dt } $$ But it doesn't remind me anything, I still can't solve it.","['integration', 'indefinite-integrals']"
436352,what does project away mean?,"I realise I should know this but I have no idea what people mean when they say ""we project away from this point"" (or replace point with line, plane or whatever in projective space). What does this mean?","['algebraic-geometry', 'terminology', 'projective-geometry']"
436360,Probability solution verification,"On a statistics trial exam I encountered the following tricky exercise: Assume that there are two types of car drivers in a country. Safe drivers constitute $70$% of the population and they have a yearly accident probability of $10$%, and unsafe drivers constitute $30$% of the population with a yearly accident probability of $50$%. An insurance company computes the price for risk insurance as follows: 400 times the probability of an accident in the next year. A new costumer wishes to get a risk insurance, and all that is known is that he had an accident in the previous year. What price should he pay for the insurance? My solution I used Bayes theorem and conditional probabilities. Given is that: $P(\text{Accident Last Year} \mid \text{Group 1}) = 0.1$ $P(\text{ALY} \mid \text{Group 2}) = 0.5$ $P(\text{Group 1}) = 0.7$ $P(\text{Group 2}) = 0.3$ By Applying Bayes Theorem we want to check what the probability is that the person is in each of these groups. So 
$$P(\text{Group 1} \mid \text{ALY}) = \frac{P(\text{ALY} \mid \text{Group 1})P(\text{Group 1})}{P(\text{ALY}\mid\text{Group 2})P(\text{Group 2})+P(\text{ALY}\mid\text{Group 1})P(\text{Group 1})} = \frac{0.1\cdot 0.7}{0.1\cdot 0.7+0.5\cdot 0.3} = \frac{7}{22}$$ and $$P(\text{Group 2}\mid\text{ALY}) = \frac{P(\text{ALY}\mid\text{Group 2})P(\text{Group 2})}{P(\text{ALY}\mid\text{Group 2})P(\text{Group 2})+P(\text{ALY}\mid\text{Group 1})P(\text{Group 1})} = \frac{15}{22}$$ Where ALY = Accident Last Year. Hence we get for the total cost: $0.5\cdot\frac{15}{22}\cdot 400 + 0.1 \cdot\frac{7}{22}\cdot 400 = 149$ If I did something wrong can someone please give me feedback and correct me :-)","['probability-theory', 'solution-verification']"
436366,Elementary questions on ample invertible sheaves,"Let $X$ be a quasi-compact scheme. Let $\mathcal L$ be an invertible sheaf on $X$. We say $\mathcal L$ is ample if for any finitely generated quasi-coherent sheaf $\mathcal F$ on $X$, there exists some $N\ge 1$ such that $\mathcal F\otimes \mathcal L^{\otimes n}$ is generated by its global sections for all $n\ge N$. I have three questions. $1.$ Both $\mathcal F$ and $\mathcal L$ are finitely generated. Using the quasi-compactness hypothesis, it seems we should be able to show that ""generated by global sections"" in the above statement can be replaced by ""generated by a finite number of global sections."" Is this true, and if so, how does one prove it? I apologize if this is very easy -- I am getting tangled up in the definitions. Here is my attempt: Suppose $\mathcal F\otimes \mathcal L^{\otimes n}$ is generated by its
  global sections for some $n$. Let this set be $\{s_\alpha\}$. Then for
  each open affine $U$, $\mathcal F\otimes \mathcal L^{\otimes n}|_U$ is
  generated by its global sections $\{s_\alpha|_U\}$. So it suffices to
  reduce to a finite affine cover, because if we show it for this cover,
  we can collect their respective finite generating sets into one large,
  but finite, set. Since $\mathcal F$ and $\mathcal L$ are finitely generated, so is
  $\mathcal F\otimes \mathcal L^{\otimes n}$. So we may take a finite
  open cover by affine open subsets $U_i$ that are finitely generated as
  $\mathcal O_X$ modules, using quasi-compactness. Then, since the
  $\mathcal F\otimes \mathcal L^{\otimes n}(U_i)$ are finitely
  generated, a finite number of $\{s_\alpha|_{U_i}\}$ suffice to
  generate all the stalks. The last sentence is just a guess. I don't think it's correct, but it also seems like the only way to proceed. $2.$ Consider the following theorem Let $f:X\rightarrow Y$ be a proper morphism of locally Noetherian
  schemes. Let $\mathcal L$ be an invertible sheaf on $X$. Let us fix a
  point $y\in Y$ and let $\phi: X \times _Y \operatorname{Spec} \mathcal
 O_{Y,y} \rightarrow X$ be the canonical morphism. Then if $\phi^*
 \mathcal L$ is ample, there exists an open neighborhood $V$ of $y$
   such that $\mathcal L_{f^{-1}(V)}$ is ample. The proof begins by saying that if we replace $\mathcal L$ by a tensor power, we may assume $\phi^*\mathcal L$ is very ample and generated by its global sections. Why is this? (A very ample sheaf is a sheaf that is the pullback under some immersion $i:X\rightarrow  \mathbb P^d_A$ of $\mathcal O_{P^d_A}(1).$) $3.$ It was shown earlier that some tensor power of $\mathcal L$ is very ample. Is it true that every very ample sheaf is generated by its global sections? Wikipedia says this is true, but it is not transparent from the description in my book.","['sheaf-theory', 'quasicoherent-sheaves', 'algebraic-geometry', 'schemes']"
436380,Writing Integrals using Differential Forms,"Consider some smooth curve $C \subset \mathbb{R^n}$ and $\gamma:[a,b] \subset\mathbb{R}\rightarrow C$ a parametrisation of $C$ and a continuous vector field $K:\mathbb{R^n} \rightarrow \mathbb{R^n}$ . Let $\omega = K_{1}dx^{1}+...+K_{n} dx^{n}$ where $K_{1},...,K_{n}$ are the components of $K$ with respect to the standard basis of $\mathbb{R^n}$ . Now the following holds: $$\int_{c}\vec{K}\cdot\vec{ds} = \int_{c}\vec{K}\cdot\hat{n}\space ds:=\int_{a}^{b}\langle K(\gamma(t)),\dot{\gamma}(t)\rangle \space dt =\int_{a}^{b}\sum_{i=1}^{n}K_{i}(\gamma(t))\space\dot{\gamma_{i}}(t)\space dt$$ where $\langle.,.\rangle$ is the standard inner product. One can also write the same integral using a differential form: $$\int_{\gamma}\omega:=\int_{a}^{b}\gamma^{*}\omega=\int_{a}^{b}\omega(\gamma(t))\space \dot{\gamma}(t)\space dt =\int_{a}^{b}\sum_{i=1}^{n}K_{i}(\gamma(t))\space\dot{\gamma_{i}}(t)\space dt$$ Similarly let $S \subset \mathbb{R^3}$ be a smooth surface (2-dim submanifold) and $\phi:U\subset\mathbb{R^2}\rightarrow S$ a parametrisation of $S$ . $\space F:\mathbb{R^3}\rightarrow\mathbb{R^3}$ a continuous vectorfield. Let $\eta = F_{1}\space dx\wedge dy -F_{2}\space dx \wedge dz +F_{3}\space dy \wedge dz$ where $F_{1},F_{2},F_{3}$ are the components of F with respect to the standard basis of $\mathbb{R^3}$ .
Now the following holds: $$\int_{S}\vec{F}\cdot \vec{dA} = \int_{S}\vec{F}\cdot\hat{n}\space dA :=\int_{U}\langle F,\frac{\partial\phi}{\partial u}\times\frac{\partial\phi}{\partial v}\rangle\space d\mu(u,v)$$ And the same Integral using the differential form: $$\int_{S}\eta:=\int_{U}\phi^{*}\eta= \int_{U}\langle F,\frac{\partial\phi}{\partial u}\times\frac{\partial\phi}{\partial v}\rangle\space d\mu(u,v)$$ My Question is: How do I express the following integrals using differential forms? Let $\space f:\mathbb{R^n}\rightarrow\mathbb{R}$ and $g:\mathbb{R^3}\rightarrow \mathbb{R}$ be continuous functions. $$\int_{c}f\space ds := \int_{a}^{b}f(\gamma(t))\space\lVert\dot{\gamma}(t)\rVert\space dt$$ $$\int_{S}g\space dA := \int_{U} g(\phi(u,v)) \space\left\|\frac{\partial\phi}{\partial u}\times\frac{\partial\phi}{\partial v}\right\|\space d\mu(u,v)$$ Help is greatly appreciated. Vincent Pfenninger","['multivariable-calculus', 'differential-forms', 'integration', 'real-analysis']"
436382,"For non-negative $f$ such that $\int_1^\infty |f'(t)|dt < \infty$, $\sum f(k)$ and $\int_1^\infty f(t)dt$ converge or diverge together","Suppose that $f\in C^1([1, \infty))$, $f>0$, and $\int_{1}^\infty |f'(t)|dt < \infty$. I want to show that $\sum_1^\infty f(k)$ and $\int_1^\infty f(t)dt$ are either both convergent or both divergent. One approach might be to try to show that  $\lim_{n\to \infty}(\sum_1^n f(k) - \int_1^n f(t)dt)< \infty$, which is true under the additional hypothesis that $f$ is monotonically decreasing. But I haven't gotten anywhere in proving this, and I suspect it isn't true. One thing I have come up with is that $\forall \epsilon >0$, $f$ is eventually Lipschitz with Lipschitz constant $\epsilon$, which we can see as follows: take $x_{\epsilon}$ such that $\forall x > x_{\epsilon}$ $|f'(x)|<\epsilon$. Then $\forall x,y > x_{\epsilon}$ we have $|f(x) - f(y)| = |\int_{y}^{x}f'(t)dt| \leq \int_x^y|f'(t)|dt \leq |y-x|\varepsilon$. But I'm having trouble leveraging this information into a solution. Any ideas?","['sequences-and-series', 'calculus', 'derivatives']"
436385,"If $\sum a_k^2 /k$ converges, then $1/N \sum_1^{N}a_k \to 0$","I want to show that if $\sum a_k^2 / k$ converges, then $1/N \sum_{1}^Na_k \to 0$. Now, if $a_n \to 0$, then the result follows. But of course $a_n\to 0$ is not a necessary condition for $\sum a_{n}^2/n$ to converge. We might want to use Cauchy-Schwarz to say that $a_k^2/k \leq a_k^4 + 1/k^2$, but of course the inequality is pointing the wrong way. Any ideas?","['sequences-and-series', 'calculus']"
436392,Separability requirement for Measurable distance?,"I was looking up Egorov's Theorem on Wikipedia. https://en.wikipedia.org/wiki/Egorov%27s_theorem One of the conditions is that the functions attain values in a separable metric space M, and in the ""Discussion of assumptions"" section following the theorem, the following is stated: ""The separability of the metric space is needed to make sure that for M-valued, measurable functions f and g, the distance d(f(x), g(x)) is again a measurable real-valued function of x."" Can someone explain how to prove the boldfaced statement? [EDIT]To be precise, I want to know how to prove ""If the metric space M is separable, and the functions f and g are measurable functions attaining values in M, then the distance function d(f(x),g(x)) is measurable."" Thanks!",['measure-theory']
436395,Independence of Path and Fundamental Theorem of Calculus?,"a) Show that the given line integral is independent of path. How would you show this? Does this require assigning $C_1$ and $C_2$ two the two legs of the line? b) Then, evaluate the line integral I by finding a potential function f and applying the Fundamental Theorem of Line Integrals.     $$I= \int_{(0, 0)}^{(1, 2)} (x+y dx) + (x-y)dy$$ For b) my final answer was 5/2, but I'm not quite sure. Is this correct? If not, can you please show me how. Thank you in advance!",['multivariable-calculus']
436400,"Solve $x\sqrt{10} = \prod\limits_{k = 1}^{90} \sin(k), x\in \mathbb Q$.","Can someone help me with this question? I've found a solution but it's not a very nice one. I used 6 times the relation $\sin(2\theta) = 2\sin(\theta)\cos(\theta)$. There's got to be a better way. $x\sqrt{10} = \prod\limits_{k = 1}^{90} \sin(k)$, k in degrees.","['trigonometry', 'trigonometric-series']"
436411,Proving a complex sum equals factorial,"I have just stumbled across the equality that:
$$
\sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n} \binom{n}{j} = n!
$$
How would I go about proving this equality?
Also, what is the left hand side equal to if the power of j is increased:
$$
\sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n+k} \binom{n}{j} = ?
$$
where k=1,2,3... Thanks!","['factorial', 'calculus']"
436416,Derivative of matrix involving trace and log,"I'm stuck on this problem.
Let $X\in\mathbb{R}^{n\times n}$, compute the following matrix derivatives
$$\frac{\partial}{\partial X}\mathrm{tr}(\log(XA)\log(XA)^\top),$$
$$\frac{\partial}{\partial X}\mathrm{tr}(B\log(XA)), $$
where $\log(\cdot)$ is the matrix logarithm (not element-wise) and $A,B\in\mathbb{R}^{n\times n}$ are constant matrices. Thanks in advance for your suggestions!","['matrices', 'matrix-calculus', 'calculus', 'derivatives']"
436437,"If $a+\sqrt{b}=c+\sqrt{d}$, is it true that $a=c$ and $b=d$?","Assume that $a,b,c,d$ are all positive integers. If $a+\sqrt{b}=c+\sqrt{d}$ , is it true that $a=c$ and $b=d$ ? I am grading some problems and I don't think this true, but all of a sudden I am doubting myself.","['radicals', 'arithmetic', 'algebra-precalculus']"
436452,"Use of Multiple ""if and only if"" statements","I apologize in advance if this question is too basic to warrant a post. I just ran into the following question: Let $f: A \to B$. If $A$ and $B$ are finite sets with the same number of elements, then $f: A \to B$ is bijective if and only if $f$ is injective if and only if $f$ is surjective. The use of two ""if and only if"" statements has confused me; I am not exactly sure what I am trying to prove. I understand the function concepts being presented in the question, but I'm just not sure what I need to show. Therefore, I ask not for hints toward the solution of the question, but only the meaning of the question. Thanks!","['logic', 'functions']"
436459,Linearity of conditional expectation (proof for n joint random variables),"Linearity of conditional expectation: I want to prove $$E\left(\sum_{i=1}^n a_i X_i|Y=y\right)=\sum_{i=1}^n a_i~ E(X_i|Y=y)$$ where $X_i, Y$ are random variables and $a_i \in \mathbb{R}$. I tried using induction (the usual, assume it's true for n=k, and prove it for n=k+1), so
I get, in the continuous case, $$E\left(\sum_{i=1}^{k+1} a_i X_i|Y=y\right)\\=E\left(\sum_{i=1}^{k} a_i X_i+a_{k+1}X_{k+1}|Y=y\right)\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k+a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k)~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\+\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1} $$
On the last step I separated the $(k+1)^{\text{th}}$ ""term"" since I'm trying to find a way to use the induction hypothesis... but I need to do something to get rid of the $(k+1)^{\text{th}}$ integral, as well the $(k+1)^{\text{th}}$ random variable in the underlying conditional distribution I know this is very long to write, I'm just hoping that I can get some hints on how to proceed further (or if there's perhaps a simpler method).","['probability-theory', 'probability']"
436462,Differential equation of a mass on a spring,"I have the following differential equation which is motivated by the dynamics of a mass on a spring:
\begin{equation}
my'' - ky = 0
\end{equation} I split this into a system of equations by letting $x_1=y$  and $x_2=y'$ \begin{equation}
x' = \begin{pmatrix} 0&1\\\dfrac{k}{m}& 0\end{pmatrix}x
\end{equation} Find an Eigenvalue:
\begin{align}
\det(A-\lambda I) =& 0 \\
\det\begin{pmatrix} -\lambda&1\\\dfrac{k}{m}&-\lambda\end{pmatrix} =& 0 \\
\lambda^2 - \dfrac{k}{m} =& 0 \\
\lambda = \pm\sqrt{\dfrac{k}{m}}
\end{align} Find the matching eigenvector: \begin{align}
(A-\lambda I)x =& 0 \\
\begin{pmatrix} -\sqrt{\frac{k}{m}}&1\\\dfrac{k}{m}&-\sqrt{\frac{k}{m}}\end{pmatrix}x =& 0
\end{align} This matrix is similar to: \begin{equation}
\begin{pmatrix}-\sqrt{\frac{k}{m}}&1\\0&0\end{pmatrix}x = 0
\end{equation} $x_2$ is free so let $x_2$ = 1. We have:
\begin{align}
-\sqrt{\frac{k}{m}}x_1 + 1 =& 0 \\
x_1 =& \dfrac{1}{\sqrt{\dfrac{k}{m}}}
\end{align} So the corresponding eigenvector is 
$\begin{pmatrix}\dfrac{1}{\sqrt{\dfrac{k}{m}}}\\1\end{pmatrix}$.
Any solution to the vector differential equation $x'=Ax$ is $x = e^{\lambda t}x_0$ where $\lambda$ is an eigenvalue and $x_0$ is the corresponding eigenvector.
Our solution is then 
\begin{equation}
e^{\sqrt{\frac{k}{m}} t}\begin{pmatrix}\dfrac{1}{\sqrt{\dfrac{k}{m}}}\\1\end{pmatrix}
\end{equation} I am just using technique I learned in a differential equations book. This doesn't make sense from a physics stand point where solutions should be periodic and thus would have solutions in terms of sines and cosine. Perhaps I did not setup the system correctly, because if I got imaginary eigenvalues then I could have had sines and cosine in my solution. I want to know what I did wrong, let me know what you think.","['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
436467,Proving that all the sets in a sequence are different,"This is an example that seems to be pretty obvious but I have no idea on how to write a proof: Prove that the sets $\emptyset, \{\emptyset\}, \{\{\emptyset\}\}, \{\{\{\emptyset\}\}\},..., \{...\{ \emptyset\}...\}$ are all different. This is my try : since $\emptyset$ have no elements and the others have exactly one, then $\emptyset$ is different from any of them. Since $\{\emptyset\}=\{\{\}\}$ have exactly a pair of brackets and the others, exept the first one, have more than one set of brackets then this set is different from the rest, etc. Continuing in this way untill reaching the last set we will eventually show that every set is defferent from all of the others. Note 1: I dont' know if this argument is valid or too informal. If it's wrong  I'd like to know. If it's informal I'd like to know how to make it formal. Note 2: What about this slight modification: Prove that the sets $\emptyset, \{\emptyset\}, \{\{\emptyset\}\}, \{\{\{\emptyset\}\}\},..., \{...\{ \emptyset\}...\}...$ are all different.","['proof-writing', 'elementary-set-theory']"
436468,When a value of a polynomial over $\mathbb Z$ is a perfect square,"For which values of $x\in\mathbb{Z}$ the polynomial $16x^3-24x+9$ is a perfect square? I don't know if this question has a solution, but Wolfram Alpha says that the answer is $x=0$ ( click ), even if $x=1$ is a solution too. Does Wolfram just give some solutions and not all? Anyway, if Wolfram can give some solutions, I think there is a general method to manage this kind of problem (at least with a third degree polynomial). So, the main question of this message is: For which values of $x\in\mathbb{Z}$ the polynomial $p(x)\in\mathbb{Z}[x]$ is a perfect square? Obviously there is not a general answer to the question, but I would like to know which techniques may be usefull to approach the problem. For example, if $\deg p(x)=2$ sometimes we can solve a Pell's equation, or if $2\mid\deg p(x)$ sometimes the ""put between two squares"" method may work. Any other methods?","['polynomials', 'algebraic-geometry', 'elementary-number-theory', 'number-theory']"
436516,Sturm-Liouville Questions,"In thinking about Sturm-Liouville theory a bit I see I have no actual idea what is going on. The first issue I have is that my book began with the statement that given $$L[y] = a(x)y'' + b(x)y' + c(x)y = f(x)$$ the problem $L[y] \ = \ f$ can be re-cast in the form $L[y] \ = \ \lambda y$. Now it could be a typo on their part but I see no justification for the way you can just do that! More importantly though is the motivation for Sturm-Liouville theory in the first place. The story as I know it is as follows: Given a linear second order ode $$F(x,y,y',y'') = L[y] = a(x)y'' + b(x)y' + c(x)y = f(x)$$ it is an exact equation if it is derivable from a differential equation of one order lower, i.e. $$F(x,y,y',y'') = \frac{d}{dx}g(x,y,y').$$ The equation is exact iff $$a''(x) - b'(x) + c(x) = 0. $$ If $F$ is not exact it can be made exact on multiplication by a suitable integrating factor $\alpha(x)$. This equation is exact iff $$(\alpha(x)a(x))'' - (\alpha(x)b(x))' + \alpha(x)c(x) = 0 $$ If you expand this out you get the Adjoint operator $$L^*[\alpha(x)] \ = \ (\alpha(x)a(x))'' \ - \ (\alpha(x)b(x))' \ + \ \alpha(x)c(x) \ = 0 $$ If you expand $L^*$ you see that we can satisfy $L \ = \ L^*$ if $a'(x) \ = \ b(x)$ & $a''(x) \ = \ b'(x)$ which then turns $L[y]$ into something of the form $$L[y] \ = \ \frac{d}{dx}[a(x)y'] \ + \ c(x)y \ = \ f(x).$$ Thus we seek an integratiing factor $\alpha(x)$ so that we can satisfy this & the condition this will hold is that $\alpha(x) \ = \ \frac{1}{a(x)}e^{\int\frac{b(x)}{a(x)}dx}$ Then we're dealing with: $$\frac{d}{dx}[\alpha(x)a(x)y'] \ + \ \alpha(x)c(x)y \ = \ \alpha(x)f(x)$$ But again, by what my book said they magically re-cast this problem as $$\frac{d}{dx}[\alpha(x)a(x)y'] \ + \ \alpha(x)c(x)y \ = \ \lambda \alpha(x) y(x)$$ Then calling $$\frac{d}{dx}[\alpha(x)a(x)y'] \ + \ ( \alpha(x)c(x)y \ - \ \lambda \alpha(x) )y(x) \ = \ 0$$ a Sturm-Liouville problem. My question is, how can I make sense of everything I wrote above? How can I clean it up & interpret it, like at one stage I thought we were turning our 2nd order ode into something so that it reduces to the derivative of a first order ode so we can easily find first integrals then the next moment we're pulling out eigenvalues & finding full solutions - what's going on? I want to be able to look at $a(x)y'' \ + \ b(x)y' \ + \ c(x)y \ = \ f(x)$ & know how & why we're turning this into a Sturm-Liouville problem in a way that makes sense of exactness & integrating factors, thanks for reading!",['ordinary-differential-equations']
436523,Special biholomorphic mapping from $ \mathbb{C} \setminus \{z : z \le 0\}$ to the unit disk,"I was looking at a previous post ( A bounded holomorphic function ). I'm asking this in a separate post, because I didn't want to interrupt the flow of the comments following the answer with what's likely to be a misunderstanding on my part. There was an argument which seemed to me to involve using a special biholomorphic map taking the slit plane region $\Omega = \mathbb{C} \setminus \{z : z \le 0\}$  to the unit disk $\Delta$ in a way that allowed it to be composed with an even function on the disk, in order to produce a continuous function on all of $\mathbb{C}$. My question is: Is there a biholomorphic map $f:\Delta \to \Omega$ with $\lim \limits _{z \to a} f(z) = \lim \limits _{z \to a} f(-z)$ for all $|a| = 1$? Is there a biholomorphic map $F:\Omega \to \Delta$ with $\lim \limits _{t \to 0} F(x + it) = - \lim \limits _{t \to 0} F(x - it)$ when $x \le 0$? Thanks in advance for any thoughts!",['complex-analysis']
436524,Some questions on the basics of invertible sheaves,"Let $X$ be a scheme. A $\mathcal O_X$-module $\mathcal L$ is called invertible if, for every point $x\in X$, there is an open neighborhood $U$ of $x$ and an isomorphism of $U$-modules $\mathcal O_X|_U \cong \mathcal L|_U$. I am struggling with the basics of sheaf theory, and I have the following questions. $1.$ Why is the tensor product of two invertible sheaves invertible? $2$. Why is the pullback of an invertible sheaf by a morphism an invertible sheaf? $3.$ Why is the twist $\mathcal O_X(k)$ on $X=\operatorname{Proj} B$ for a graded ring $B$ invertible, where $k$ is any integer, possibly negative? I have a few jumbled thoughts. For $1$, recall that the tensor product of two sheaves takes the presheaf that assigns to an open set $U$ the module $ \mathcal L_1(U) \otimes_{\mathcal O_{X}|_U} \mathcal L_2(U)$ and sheafifies it. If we pick open sets $U_i$ such that 
the sheaf $\mathcal L_i$ is trivialized on $U_i$, then on $U_1\cap U_2$ they both have trivializations, and their tensor product on this open set is isomorphic to 
$\mathcal O_X(U) \otimes_{$\mathcal O_X(U)} \mathcal O_X(U)=\mathcal O_X(U)$, which gives the desired result on the presheaf . I do not see why this still holds after sheafificaiton. For $2$, I tried using the local tensor product definition of the pullback sheaf, but I could not simply it. For $3$, it suffices to show it for $k=\pm 1$ and use $1$, because $\mathcal O_X(n) \otimes_{\mathcal O_X} \mathcal O_X(m)=\mathcal O_X(n+m)$.","['sheaf-theory', 'algebraic-geometry', 'schemes']"
436529,"Vectors Angles from $[0,2\pi]$","Given two vectors $V_1 = (x_1, y_1)$ and $V_2 = (x_2, y_2)$. How to calculate the angles between them in the range of $[0, 2\pi]$? I know the $\cos\theta$ similarity equation could present a $\theta$ in the range of $[0, \pi]$.","['vector-spaces', 'geometry', 'matlab', 'computer-science']"
436536,Simple Groups and Conjugacy Classes,"Simple groups can be characterised by following property: A group $G$ is simple if and only if for any $1\neq x\in G$, the conjugacy class of $x$ in $G$ generates the whole group $G$. The question I am interested is natural one related to above fact? Q. If $G$ is a group such that for any $x\in G$, the conjugacy class of $x$ in $G$ generates a proper subgroup, what can we say about $G$? (nilpotent, solvable, supersolvable, or else?) Is there characterization (or classification) of such groups? Example: Let $G$ be any non-abelian finite $p$-group. Then for $x\in G$, there is a maximal subgroup $M$ of $G$ containing $x$; then the subgroup generated by the conjugacy class of $x$ is contained in $M$, hence it is proper.","['group-theory', 'simple-groups']"
436543,interval of convergence of $\sum n \exp (-x \sqrt n)$,"$$\sum^{\infty}_{n=1} n \exp (-x \sqrt n)$$ How to find the interval of convergence? Obviously, 0 is not in the interval because the series becomes divergent. could you help me?","['multivariable-calculus', 'sequences-and-series']"
436544,Why do these two constructions of a sheaf associated to a module on a projective scheme agree?,"Let $B$ be a graded ring an $M$ be a $\mathbb Z$-graded $B$-module. We can associate to $M$ a sheaf of modules on $\operatorname{Proj} B$ by defining the sheaf on the principal open sets $D_+(f)$ to be $(M_{(f)})^\sim$ (where this is the associated module in the affine case) and checking that these agree on overlaps. However, there is a second construction, which appears on page $165$ of Qing Liu's Algebraic Geometry and Arithmetic Curves . Consider the canonical injection $f:\operatorname{Proj B}\rightarrow \operatorname{Spec} B$. This is continuous. Consider the sheaf $\mathcal F = M^\sim$ on $\operatorname{Spec} B$ (again, this is the associated sheaf in the affine case). We can take the subsheaf of $f^{-1}\mathcal F$ consisting of all degree 0 elements to be the sheaf associated to $M$ on $\operatorname{Proj} B$. (As @Hanno notes in the comments, there is an issue here. There doesn't seem to be a way to turn this into a sheaf of modules, because $f$ is a merely a continuous map, not a morphism. I would also appreciate comments on this issue.) I would like to know why these constructions agree. I know that $(f^{-1} \mathcal F)_{\mathfrak p} = M_\mathfrak p$, so taking the homogeneous elements, we see that the two sheafs have the same stalks. But I am rather uncomfortable with the inverse image construction, and do not see how to construct an isomorphism.","['sheaf-theory', 'algebraic-geometry', 'schemes', 'projective-schemes']"
436549,Stalk of the sheaf of regular functions on a subvariety,"Suppose $Y$ is a subvariety of a variety $X$ (according to Hartshorne this means if $X$ is quasi-affine or quasi projective then $Y$ is a locally closed subset of $X$, c.f. exercise 3.10, chapter 1).  Now given $i : Y \to X$ the inclusion map, I am trying to figure out what the stalk at $x \in Y$ of $i_\ast(\mathcal{O}_Y) $ is. Now if I unwind the definitions, firstly for any open set $U \subseteq X$ we have $i_\ast(\mathcal{O}_Y)(U) = \mathcal{O}_Y(U \cap Y)$. I guess that the stalk at $x$ of $i_\ast (\mathcal{O}_Y) $ should consist of pairs $\langle U \cap Y,f \rangle$ where $f$ is a regular function on $U \cap Y$. However why should it be the case that on stalks the map induced from restriction $(\mathcal{O}_X)_x \to (i_\ast \mathcal{O}_Y)_x$ is surjective? This seems to be saying to me that any regular function on an open subset $U \cap Y$ of $Y$ is the restriction of some regular function on an open subset of $X$, but is this true?",['algebraic-geometry']
436559,A natural proof of the Cauchy-Schwarz inequality,"Most of the proofs of the Cauchy-Schwarz inequality on a pre-Hilbert space use a fact that if a quadratic polynomial with real coefficients takes positive values everywhere on the real line, then its discriminant is negative(e.g. Conway: A course in functional analysis).
I think this is somewhat tricky.
Moreover I often forget its proof when the pre-Hilbert space is defined over the field of complex numbers.
Is there a more natural proof (hence it's easy to remember) which is based on a completely different idea?","['inequality', 'functional-analysis']"
436574,Intuition about whether to switch in box problem,"I ran across an apparent paradox which I then located in the paper The Box Problem: To Switch or Not to Switch as such: Imagine that you are shown two identical boxes. You know that one of
  them contains. \$b and the other \$2b. Picking one at random and opening
  it, you must decide whether to keep it (and its contents), or exchange
  it for the other box. In short, when you find $x dollars in a box, the expected value of the other box is .5*.5x + .5*2x = 1.25x, meaning that it's always better to switch. This appears to violate the symmetry of the problem and the fact that you still know nothing meaningful about either box. The paper goes another direction with it, talking about how having prior knowledge of expected values gives a more meaningful analysis (along with other discussions). However, what if there's no prior knowledge, and we have the original problem as stated. Can anyone give me some intuition to make sense of this? EDIT: Someone found this question which asks a slightly different formulation, but an identical problem. The accepted answer there just points to a paper , and I'm having difficulty understanding the paper. It explains away the paradox by noting the expectation is based on an infinite sum, and the value depends on the order the sum is evaluated. I'm not familiar with how the order of a sum can change a value, and I also don't see talking about a different way to evaluate the expectation explains the strange result outlined above. My math understanding is primarily based on reading textbooks as a hobby, and I haven't yet worked up to fully understanding math academic papers, so a simpler explanation would be helpful.","['probability', 'paradoxes']"
436629,$\mathbb{Z}$ as a free product of two groups,"My question is that can the group $(\mathbb{Z},+)$ be written as a free product of two (non-trivial) groups? Thanks",['group-theory']
436630,"{0,1,2,.....9} are randomly assigned to the vertices ${x_0,x_1,...x_9}$ of a decagon.Prove there are 3 consecutive vertices whose sum is at least 14.","This is a homework Question and has to do with Pigeonhole principle. Could use a hint. Q. The numbers ${0,1,2,.....9}$ are randomly assigned to the vertices ${x_0,x_1,...x_9}$ of a decagon. Show that there are 3 consecutive vertices whose sum is at least 14. (hint given by Prof: Consider the numbers $S_0=x_0+x_1+x_2,$ $S_1=x_1+x_2+x_3,$ $ ...,$ $S_9=x_9+x_0+x_1$) I would like to solve it but I don't even have a sense of direction on how to start with this.","['pigeonhole-principle', 'discrete-mathematics']"
436631,Snell envelope and optimal stopping time,"Suppose $(G_n)_{0\leq n\leq N}$ is a process adapted to a filteing $(\mathcal{F}_n)_{0\leq n\leq N}$. The Snell envelope of $(G_n)$ is the smallest supermatingale dominates $(G_n)$. It's defined as follows:$$S_N=G_N,S_{n}=\max\{G_n,E[S_{n+1}|\mathcal{F}_n]\},n=N-1,\ldots,0.$$ The stopping time $\tau=\inf_k\{0\leq k\leq N:S_k=G_k\}$ is the optimal stopping time to maximize the gain $EX_\tau$. It can also be shown that $S_{n\wedge\tau}$ is a martingale, my question is, what is the significance of this result? We have already find the optimal rule( $\tau$), and we can compute the optimal gain $EX_\tau=ES_0$, so what can we say about the conclusion that $S_{n\wedge \tau}$ is a martingale?",['probability-theory']
436654,"Logic Question : $C \rightarrow(B\wedge A) = F , A\longleftrightarrow(B\wedge C) = T$ Find $B\rightarrow (\neg C) $","I have  the following statements:
$$C \rightarrow(B\wedge A) = F , A\longleftrightarrow(B\wedge C) = T$$
I want to find the value of :
 $$B\rightarrow (\neg C) $$ 1) I need to do truth table? 2) there is another way to do it? I can see that from  $C \rightarrow(B\wedge A) = F$ , $C=1 ,(B\wedge A)=0$ its mean that there is 3 options for  $(B\wedge A)=0$ right? now how I can continue from here? Thanks!","['logic', 'discrete-mathematics']"
436671,Question about a separation theorem,"This theorem is called the Kreps-Yan theorem. I have just a small question about the proof. We have a probability space given. The statement is: Let $p\in [1,\infty]$, $q$ the conjugate. Suppose $C\subset L^p$ a convex cone, which is closed in the weak topology (for $p=\infty$ it is the weak-star topology), $C\supset-L^p_+:=\{f\in L^p:f\ge 0\}$ and $C\cap L^p_+=\{0\}$. Then there exists a equivalent measure $Q$ with density $\frac{dQ}{dP}\in L^q$ such that $E_Q[f]\le 0\forall f\in C$. Outline of the proof is: for every $x\in L^p_+\backslash \{0\}$ we can separate this from $C$, i.e. it exists a $z_x\in L^q$ such that $$E[z_x x]\ge a > b\ge E[z_xf]$$
for all $f\in C$. Using cone property one can prove that $b=0$ and $E[z_x]>0$. Using Halmos-Savage theorem, on can prove that there is a countable collection $(z_{x_i})$ such that $P[\cup\{z_{x_i}>0\}]=1$. Then one defines $$z:=\sum_{i\ge 1}2^{-i}z_{x_i}$$ W.l.o.g we can assume $\|z_{x_i}\|_q=1$, hence $z\in L^q$. But why is $E[z]=1$, which is needed. Or how can I modify the $z_{x_i}'s$ to guarantee that?","['probability-theory', 'functional-analysis']"
436676,Prove that a continuous function on a closed interval attains a maximum,"As the title indicates, I'd like to prove the following: If $f:\mathbb R\to\mathbb R$ is a continuous function on $[a,b]$, then $f$ attains its maximum. Now, I do have a working proof: $[a,b]$ is a connected, compact space, which means that because $f$ is continuous, $f([a,b])$ is compact and connected as well.  Therefore, $f([a,b])$ is a closed interval, which means it has both a minimum and, as desired, a maximum. What I would like, however, is a proof that doesn't require such general or sophisticated framework.  In particular, I'd like to know if there's a proof that is understandable to somebody beginning calculus, one that (at the very least) doesn't invoke compactness.  Any comments, hints, or solutions are welcome and apreciated.","['alternative-proof', 'calculus', 'real-analysis']"
436681,How to prove positive semi-definiteness using eigenvalues,"I'm reading a very short paper by Peter G. Casazza but I cannot understand the proof in page 2. Suppose $\mathbf A$ is a positive semi-definite matrix with rank $k$; that is, some of its eigenvalues $\lambda_i$ may be zero, but all the positive eigenvalues are larger than $b$ and $b'$. This is what we want to prove: $$(\mathbf A - b\mathbf I)^{-1} - (\mathbf A - b'\mathbf I)^{-1} \succeq
\frac{\delta}{2}(\mathbf A - b'\mathbf I)^{-2}$$ where $b' = b-\delta > \delta > 0$ and $\mathbf X \succeq \mathbf Y$ means $\mathbf X - \mathbf Y$ is positive semi-definite. He finished his proof by showing the following two things: $$\frac{-1}{b} - \frac{-1}{b'} = \frac{b-b'}{bb'} = 
\frac{\delta}{b'(b'+\delta)} \geq \frac{\delta}{2(b')^2}$$ and $$\frac{1}{\lambda_i - b} - \frac{1}{\lambda_i-b'}
= \frac{b-b'}{(\lambda_i - b)(\lambda_i - b')}
\geq \frac{\delta}{(\lambda_i - b')^2}.$$ My question is: To prove $\mathbf X - \mathbf Y \succeq \mathbf Z$, is it enough to check their eigenvalues and find some relation between them? Can anyone explain why those two things above are enough to show the desired positive semi-definiteness?","['matrices', 'linear-algebra']"
436685,Schur decomposition,"If $A$ is real and nonsymmetric with Schur decomposition $UTU^H$, then what types of matrices are $U$ and $T$? How are the eigenvalues of $A$ related to $U$ and $T$?","['matrix-decomposition', 'matrices', 'linear-algebra', 'schur-decomposition']"
436710,When $f^{(n)}\to g$ uniformly?,"Let $f\in C^\infty([0,1])$ and consider the sequence $$f_n=f^{(n)}$$ where $f^{(n)}$ denote the derivative of order $n$ of $f$. My question is: What is a necessary condition to impose on $f$, such that $f_n$ converges uniformly to some $g\in C([0,1])$, i.e. $\|f_n-g\|_\infty\to 0$? I could find some examples that maybe can help. I - If $f$ is a polynomious, then $f_n\to 0$, II - If $f(x)=e^{\lambda x}$, then $f_n\to 0$ if $\lambda\in [0,1)$ and $f_n\to f$ if $\lambda =1$. Thank you","['uniform-convergence', 'analysis']"
