question_id,title,body,tags
2306893,Can I manipulate a function (with a parameter) to show it converges to another function?,"Please bear with me. So, for example the limit for $a$ in this hyperbola: $$\lim_{a \to 0^+} (y^2 -x^2 = a) \, ,\,\,\, \, y \ge 0 \tag{A}$$ This appears to make the equation go to: 
$$y^2 = x^2 \, ,\,\,\, \, y \ge 0 \tag{B}$$
$$y = |x| \tag{C}$$ So, is $(A)$ a valid mathematical definition of the absolute value? And furthermore, is $(A)$ differentiable? Because if it was, that immediately means that it's differentiable as $a$ is aribitrarily close to $0$ which is the same thing as $(C)$, but we know $(C)$ is not differentiable at $0$. In short, I'm wondering if (and maybe the above is a bad example) we can show, via a parameter, that one function converges to another in this type of limiting process and, if so, why would it lose it's differentiability (if that even makes sense)? Here's a Desmos link link to the action I'm talking about.","['derivatives', 'parametric', 'functions', 'limits']"
2306931,On a certain sequence,"Let $\{y_n\}$ be a sequence defined by $y_n=x_n-\ln n$ , where $\{x_n\}$ is defined by $x_1=1 ; x_{n+1}=x_n + e^{-x_n} , \forall n\in \mathbb N$ . Then is $\{y_n\} $ bounded ? Is $\{y_n\}$ convergent ? I know that $\{x_n\}$ is strictly increasing and unbounded ; but I am unable to say anything about $\{y_n\}$ . Please help  .Thanks in advance","['recurrence-relations', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
2306949,Finding $f$ such that $f'(x)=A(x)$,"The problem is the following: Let $U\subset \Bbb R^m$ open and simply connected and $A: U \to \mathcal{L}(\Bbb R^m; \Bbb R^n)$ a differentiable application. Show that there exists $f:U\to\Bbb R^n$ twice differentiable satisfying $f'(x)=A(x)$ for all $x\in U$ if and only if $A$ satisfies $\big( A'(x) v \big) w = \big( A'(x) w \big) v$ for all $v, w\in\Bbb R^m$. The first part is easy and follows from the Schwarz Theorem for applications, since $A'(x)=f''(x)$. I aim to show the converse, but couldn't find a candidate for $f$. Any hints?  Further, why do we need the simply connected hypothesis?","['derivatives', 'real-analysis', 'multivariable-calculus', 'linear-transformations', 'analysis']"
2306988,Verifying a Series Solution to Dirichlet's Problem via separation of variables,"In Stein's Fourier Analysis i'm having trouble attempting to verify the series solution given in the problem in $(1.)$ $(1.)$ The Dirchlet problem is the annulus defined by ${{(r, \theta): p < r < 1}}$, where $0 \leq p \leq 1$ in the inner radius. The problem to solve: $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = 0$$ subject to the boundary conditions: $${
     \begin{align} 
       u(1,\theta) = f(\theta) \\
       u(p,\theta) = g(\theta). 
     \end{align}
 }$$
Stein's intial argument was to write solutions for the Dirchlet Problem as he did previously in the following form: $$u(r,\theta)= \sum_{}^{}c_{n}(r)e^{in\theta}$$ with $c_{n}(r) = A_{n}r^{n} + B_{n}r^{-n}, n \neq 0$ Set: 
$$f(\theta) \sim \sum_{}^{} a_{n}e^{in\theta}$$ and $$g(\theta) \sim \sum_{}^{}b_{n}e^{in\theta}$$ This leads to the solution $$u(r,\theta) = \sum_{n \leq 0} (\frac{1}{p^{n}-p^{-n}})((p/r)^{n} - (r/p)^{n})a_{n} + (r^{n} - r^{-n})b_{n}]e^{in\theta} + a_{o} + (b_{o} - a_{o}\frac{logr}{logp}$$ From looking what was done in Chapter 1 as a prior example,  and comparing the problem in $(1.)$the series the solution was obtained via Sepration of Variables. My initial attack can be followed in $(2.)$ $(2.)$ $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = \Delta{u}$$
$$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}} +  r\frac{\partial{u}}{\partial{r}} = -\frac{\partial^{2}u}{\partial{\theta}^{2}}$$ Plugging in our solution product: $(u(r,\theta))=F(r)G(\theta))$
$$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) +  r\frac{\partial{u}}{\partial{r}}F(r)G(\theta)= -\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)$$ Now dividing by our Solution Product:
 $$\frac{r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) + r\frac{\partial{u}}{\partial{r}}F(r)G(\theta) } {F{(r)}} = \frac{-\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)}{G{(\theta)}} $$ Finally one can observe in a more convenient form  that we have the following: $$\frac{r^{2}F(r)G''(\theta)+r(G(\theta))F'(r)}{F(r)} = \frac{F(r)-G''(\theta)}{G(\theta)}$$ $$
  \left\{
     \begin{align} 
        r^2G''(\theta) + r(G(\theta)F'(r)) = 0 \\ 
        F(r) - \dfrac{F(r) - G''(\theta)}{G(\theta)} = 0
     \end{align} 
  \right. 
$$ $$   \left\{
     \begin{align}
        r^{2}G''(\theta)+r(G(\theta))F'(r)\lambda F(r)=0 \\
        F(r) - \lambda \frac{G''(\theta)}{G''(\theta)} = 0
     \end{align} 
  \right. 
$$
From the previous result above I'm stuck on working out a series solution to the above ODE's is their any fundamental observations I'm missing towards the problem ?","['proof-explanation', 'ordinary-differential-equations', 'sequences-and-series', 'partial-differential-equations']"
2307011,Eigenvalues of the linear system $XA +A^T X = 0$,"I am following a proof of the next theorem, rephrased from Theorem 8.5 of the book ""Introduction to the theory of differential inclusions"" by Georgi V. Smirnov. Let $\{\lambda_1,\dots,\lambda_n\}$ be eigenvalues of a constant matrix $A \in \mathbb{R}^{n\times n}$ and $X \in \mathbb{R}^{n\times n}$ be a variable in the set of symmetric matrices. Consider a linear system $XA + A^TX = 0$. It is equivalent to $Bx = 0$ where $x = (X_{11},X_{12},X_{22},\dots,X_{1n},\dots,X_{nn}) \in \mathbb{R}^{n(n+1)/2}$. Define
  \begin{align}
C &= \{\text{all eigenvalues of $B$}\}, \\
D &= \{m_1\lambda_1 + \cdots + m_n\lambda_n \mid m_i \in \{0,1,2\},\,m_1 + \cdots + m_n = 2\}.
\end{align}
  Then, C = D. I understood the part $D \subset C$ but I am stuck in the part $C\subset D$. If $|D| = n(n+1)/2$, then it is obvious but in the case $|D| < n(n+1)/2$ the book says only ""In the general case the result can be obtained taking the limit"". Would you give me any hint or reference how to use the limit? Edit I hope this is a correct proof of the part $C \subset D$ that uses the limit. Since $D\subset C$ and $|C|$ is at most $n(n+1)/2$, if $|D| = n(n+1)/2$, then $D = C$. Suppose $|D| < n(n+1)/2$. Consider a linear system $X(A + dA) + (A + dA)^TX = 0$ where $dA \in \mathbb{R}^{n\times n}$. It is equivalent to $(B + dB)x = 0$ and $\|dA\| \to 0 \Leftrightarrow \|dB\| \to 0$. Let $\{\lambda_1'(dA),\dots,\lambda_n'(dA)\}$ and $C = \{\rho_1,\dots,\rho_{n(n+1)/2}\}$ be eigenvalues of $A + dA$ and $B$, respectively. Define
  \begin{align}
C' &= \{\rho_1'(dB),\dots,\rho_{n(n+1)/2}'(dB)\} = \{\text{all eigenvalues of $B + dB$}\}, \\
D' &= \{m_1\lambda_1'(dA) + \cdots + m_n\lambda_n'(dA) \mid m_i \in \{0,1,2\},\,m_1 + \cdots + m_n = 2\}.
\end{align}
  Solutions of the characteristic equations $\det(A + dA - \lambda I) = 0$ and $\det(B + dB - \rho I) = 0$ are continuous functions with respect to parameters. So, for all $\varepsilon > 0$, there exists $\delta > 0$ such that $\max_i |\lambda_i'(dA) - \lambda_i| < \varepsilon$ and $\max_i|\rho_i'(dB) - \rho_i| < \varepsilon$ if $\|dA\| < \delta$ and $\|dB\|< \delta$; we assume that eigenvalues are properly listed. Also, there exists $\|dA\| < \delta$ such that all eigenvalues of $A + dA$ are distinct. Furthermore, there exists $\|dA\| < \delta$ satisfying $|D'| = n(n+1)/2$. Let $\rho \in C$. There exists $\rho' = m_1\lambda_1(dA) + \cdots + m_n\lambda_n(dA) \in C'$ such that
  \begin{equation}
|\rho - (m_1\lambda_1 + \cdots + m_n\lambda_n)| \le |\rho - \rho'| + |\rho' - (m_1\lambda_1 + \cdots + m_n\lambda_n)| < (1 + 2n)\varepsilon.
\end{equation}
  Since $\varepsilon$ is arbitrary, $\rho = m_1\lambda_1 + \cdots + m_n\lambda_n \in D$.",['linear-algebra']
2307021,Confusing differentials problem - Electrical resistance $ R = \frac{k}{r^2} $ with $ dr = 5\% $,"I am struggling with a confusing differentials' problem. It seems like there is a key piece of information missing: The problem: The electrical resistance $ R $ of a copper wire is given by $  R = \frac{k}{r^2} $ where $ k $ is a constant and $ r $ is the radius of the wire. Suppose that the radius has an error of $  \pm 5\% $, find the $\%$ error of $ R $. My solution: \begin{align*}
R &= \frac{k}{r^2}\\
\frac{dR}{dr} &= k \cdot (-2) \cdot r^{-3} \quad \therefore \quad dR = \frac{-2k \cdot 0.05}{r^3} = \frac{-0.1k}{r^3}\\
\end{align*} So the percentage error is given by \begin{align*}
E_\% = \frac{\frac{-0.1k}{r^3}}{\frac{k}{r^2}} = - \frac{0.1}{r}
\end{align*} My question: Am I missing something? Should I have arrived in a real value (not a function of $ r $ )? Is there information missing on the problem? Thank you.","['derivatives', 'physics', 'calculus']"
2307039,Calculate $\mathbb{E}(\tau^2)$ for an exit time $\tau$ of Brownian motion,"I'm doing an exercise of Advanced Probability and I have some problem. Given $a,b \in \mathbb{R}$ and let be $(B_t)_{t \ge 0}$ a Brownian motion, and let be $\tau$ the first time of exit of $B_t$ from $[-a,b]$
  Show that $\mathbb{E}[\tau^2]=\frac13ab(a^2+3ab+b^2)$ I showed that $$ (B^3_t-3tB_t)_{t \ge 0}, \hspace{1cm} (B^4_t-6tB^2_t+3t^2)_{t \ge 0}$$
are martingales, and I obtain a form of $\mathbb{E}[\tau^2]$ from the second one martingale but i don't know how to continue. Could someone help me please? Thanks.","['means', 'probability-theory', 'stopping-times', 'martingales', 'brownian-motion']"
2307041,How to show that $\int_{0}^{\pi/2}{\arctan(\tan^2 x)\over \sin^2 x\sqrt{\tan x}}\cdot(3\pm\tan x)\mathrm dx=2\pi\sqrt{2\pm \sqrt{2}}?$,A bit of messy integral but seem to yield a simple closed form Given that: $$\int_{0}^{\pi/2}{\arctan(\tan^2 x)\over \sin^2 x\sqrt{\tan x}}\cdot(3\pm\tan x)\mathrm dx=2\pi\sqrt{2\pm \sqrt{2}}\tag1$$ Simplifying this part doesn't yield a simple from. $${3+\tan x\over \sin^2 x\sqrt{\tan x}}$$ Else we can split the integral $(1)\implies$ $$3\int_{0}^{\pi/2}{\arctan(\tan^2 x)\over \sin^2 x\sqrt{\tan x}}\mathrm dx+\int_{0}^{\pi/2}{\sqrt{\tan x}\arctan(\tan^2 x)\over \sin^2 x}\mathrm dx=I+J\tag2$$ $$2\sin^2x=1-{1-\tan^2 x\over 1+\tan^2 x}$$ $$\sin^2x={\tan^2x\over 1+\tan^2x}$$ $$I=3\int_{0}^{\pi/2}{1+\tan^2x\over \tan^2x}\cdot{\arctan(\tan^2 x)\over \sqrt{\tan x}}\mathrm dx$$ $$J=\int_{0}^{\pi/2}{1+\tan^2x\over \tan^2x}\cdot{\sqrt{\tan x}\arctan(\tan^2 x)}\mathrm dx$$ $$u=\tan^2x\implies du=2\tan x\sec^2xdx=2u^{1/2}+2u^{3/2}$$ $I+J\implies$ $${3\over 2}\int_{0}^{\infty}{1+u\over u^{7/4}+u^{11/4}}\arctan(u)\mathrm du+{1\over 2}\int_{0}^{\infty}{1+u\over u^{5/4}+u^{9/4}}\arctan(u)\tag3$$ simplify to $${3\over 2}\int_{0}^{\infty}{1\over u^{7/4}}\arctan(u)\mathrm du+{1\over 2}\int_{0}^{\infty}{1\over u^{5/4}}\arctan(u)\tag4$$ $${1\over 2}\int_{0}^{\infty}(3+u^{1/2}){\arctan(u)\over u^{7/4}}\mathrm du\tag5$$ $$u=v^4\implies du=4v^3dv$$ $$2\int_{0}^{\infty}(3+v^2){\arctan(v^4)\over v^4}\cdot{\mathrm dv}\tag6$$ Q: How can we prove $(1)?$,"['integration', 'definite-integrals', 'calculus']"
2307051,The prime ideals of a quotient ring,"Let R be a ring and A be an ideal of R. We say that an ideal B is prime in R if and only if B/A is prime in the quotient ring R/A. I do not understand why the set of prime ideals of the quotient ring R/A is the set of ideals P/A where P is an ideal of R containing A? May you help me, please?
Thank you in advance.","['abstract-algebra', 'maximal-and-prime-ideals', 'commutative-algebra']"
2307069,Integrate form $\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n$ on $S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\}$,"Integrate form $\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n$ on $S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\}$. $i,j$ are constant. Doing it from definition doesn't seem workable. Any hint would be greatly appreciated. Orientation is external. I do not know Stoke's theorem yet. I know only basic facts connected with differential forms and some thorems about it working up to $\mathbb{R^3}$.","['differential-forms', 'orientation', 'integration', 'differential-geometry']"
2307118,Proving equality of mean between ANOVA with 2 levels and t-test,"I want to prove that there is an equality of the ANOVA with 2 levels and t-test. So: From the t-test we know that: $$t=\frac{\overline{x}_1-\overline{x}_2}{\sqrt{\frac{S_1^2}{n_1}-\frac{S_1^2}{n_1}}} \sim t(n_1+n_2-2)$$
And we know for a fact that if a statistic is t-distributed => $\mu=0$. Now for ANOVA with 2 levels we should have a null hypothesis:
$$H_0:\mu_0=\mu_1$$ And I guess from this hypothesis we should get something out but I have no idea. Can someone please show me a prove that this statement is true ?","['fisher-information', 'statistics', 'hypothesis-testing']"
2307134,Bijection between the sets $ \ A=\{x^{2}: 0<x<1 \} \text{ and }B=\{x^{3}: 1<x<2 \} \ $,"Consider the sets $$ \ A=\{x^{2}: 0<x<1 \} \text{ and }B=\{x^{3}: 1<x<2 \} \ $$ Show that there is a one-one function and onto map between them. Let $ \ f : A \rightarrow B $ be a map defined by $$ \ f(x)= x^{\frac{3}{2}} , \ \ \forall \ x \in (0,1) $$ Then this map is clearly one-one. But how to show it is onto? Also is the map well defined? Any help would be appreciated ?",['functions']
2307142,Angle formed by summing $n$ unit vectors,"I'm interested in the angle formed by the sum of $n$ unit vectors. Said angle must be a function of the angles of the $n$ unit vectors. Specifically, suppose that the $i$-th unit vector's angle is $\theta_i$. Then the angle of the sum is $$f(\theta_1,\dots,\theta_n) = \tan^{-1}\Big(\frac{\sin(\theta_1) + \cdots + \sin(\theta_n)}{\cos(\theta_1) + \cdots + \cos(\theta_n)}\Big)$$ which is easy to solve for $n=1,2$ $$f(\theta_1) = \theta_1$$ $$f(\theta_1,\theta_2) = \frac{1}{2}(\theta_1 + \theta_2)$$ Can anyone solve for $n=3$? When $$f(\theta_1,\theta_2,\theta_3) = \tan^{-1}\Big(\frac{\sin(\theta_1) + \sin(\theta_2) + \sin(\theta_3)}{\cos(\theta_1) + \cos(\theta_2) + \cos(\theta_3)}\Big)$$ Here's a graphical representation for $n=3$ (except the vectors are each about 40 units long) where an expression for the angle of the red line is desired. And can one solve for $n$ in general?","['angle', 'summation', 'trigonometry']"
2307147,Evaluation of an integral involving sign function,"Let $w>0$, $\lbrace k_{ij} \rbrace_{i,j\in [1,n]}$ be numbers taking either $0$ or $1$ as value and $i$ the usual complex number. I am trying to prove the following identity. $$\int_{]-\infty,0]^n}dx_1\dots dx_n\, \prod_{j<l}\left[\mathrm{sgn}(x_l-x_j)\right]^{k_{jl}}\prod_{l=1}^n e^{(ia_{l}+w)x_l}=\prod_{l=1}^n\frac{1}{ia_l +w}\prod_{j<l}\left(\frac{i\, a_l-i\, a_j}{ia_l+ia_j+2w}\right)^{k_{jl}}$$ In the case where all $k_{ij}$ are equal to $0$, the integral is trivial because we can integrate each variable independently. But whenever a $k_{ij}$ is non zero, the variables are coupled through the sign function and it seems way harder.",['integration']
2307168,SVD in the language of linear operators?,"I noticed that Axler's Linear Algebra Done Right has an explanation of SVD in a matrix free way. The statement of the theorem is the following Given $T\in L(V)$ there are orthonormal basis $(e_1,\ldots,e_n)$ and $(f_1,\ldots,f_n)$ of $V$ such that $Tv = s_1\langle v,e_1\rangle f_1+\ldots+s_n\langle v,e_n\rangle f_n$, where $s_1,\ldots,s_n$ are the singular values of $T$. This is easy to prove by just letting $(e_1,\ldots,e_n)$ the an orthonormal basis for $T^*T$, which is guaranteed to have such a basis being self-adjoint. We then apply the polar composition by writing $T=S\sqrt{T^*T}$, where $S$ is an isometry, so it preserves orthonormality of vectors and we can set $f_i = Sf_i$ and seeing that $Tv$ has the required form is then a trivial computation. My question is the following: In most applications of SVD, where we do some form of dimensionality reduction, we do not have a square matrix, so the assumption $T\in L(V)$ doesn't hold and we would instead need to generalize this to the setting $T\in L(V,W)$, where $V$ and $W$ are vector spaces of possible different dimensions. Is there a nice formulation of the SVD in this setting comparable to the one above?","['svd', 'linear-algebra']"
2307169,De Rham differential is a derivation of wedge product?,"Let $M$ be a smooth manifold and $k$ a positive integer. Let us define $$\Omega^k(M)=\left\{\begin{array}{lcl}C^\infty(M) & \textrm{if}& k=0\\
\mathsf{Alt}^k_{C^\infty(M)}(\mathfrak{X}(M), C^\infty(M)) & \textrm{if} & k>0 \end{array}\right.$$ where $\mathfrak{X}(M)$ is the $C^\infty(M)$-module of vector fields on $M$ (derivations of the algebra $C^\infty(M)$) and $\mathsf{Alt}^k_{C^\infty(M)}(\mathfrak{X}(M), C^\infty(M))$ is the $C^\infty(M)$-module of $C^\infty(M)$-multilinear skew-symmetric maps $$\omega:\underbrace{\mathfrak{X}(M)\times \ldots \times \mathfrak{X}(M)}_{k}\longrightarrow C^\infty(M).$$ The De Rham differential is the operator $$d:\Omega^k(M)\longrightarrow \Omega^{k+1}(M)$$ defined by $$(d\omega)(X_0, \ldots, X_k)=\sum_{j=0}^k (-1)^j X_j(\omega(X_0, \ldots, \widehat{X_j}, \ldots, X_k))+\sum_{i<j} (-1)^{i+j} \omega([X_i, X_j], X_0, \ldots, \widehat{X_i}, \ldots, \widehat{X_j}, \ldots, X_k)$$ where $\widehat{}$ means omit. We have a product $$\wedge:\Omega^i(M)\times \Omega^j(M)\longrightarrow \Omega^{i+j}(M)$$ defined by $$(\omega\wedge \tau)(X_1, \ldots, X_{i+j})=\frac{1}{i!j!} \sum_{\sigma\in\mathsf{S}_{i+j}} \mathsf{sgn}(\sigma)\omega(X_{\sigma(1)}, \ldots, X_{\sigma(i)})\tau(X_{\sigma(i+1)}, \ldots, X_{\sigma(i+j)}),$$ where $\mathsf{S}_{i+j}$ is the set of permutations of $i+j$ (that is, bijections of the set $\{1, \ldots, i+j\}$) and where $\mathsf{sgn}(\sigma)$ is the sign of $\sigma$. Does anyone know to prove or where to find the proof of the identity $$d(\omega\wedge \tau)=d\omega\wedge \tau+(-1)^{|\omega|}\omega\wedge d\tau?$$ I know this is a classical result but I need a proof using the above definitions and the explicit computations (not by induction). Thanks.","['manifolds', 'differential-geometry']"
2307203,Is This Sum Obviously Equal to $8$.,"Question: I write: \begin{align} \lambda_1 & = {\sqrt[3]{\frac{1}{2}\bigg(9 + i
 \sqrt{687}\bigg)}\above 1.5 pt 3^{2/3}} + {4 \above 1.5pt
 {\sqrt[3]{\frac{3}{2} \bigg (9 + i \sqrt{687}\bigg)}}}\\  \lambda_2 &
 = -{\bigg(1-i\sqrt{3}\bigg)\sqrt[3]{\frac{1}{2}\bigg(9 + i \sqrt{687}\bigg)}\above 1.5 pt 2\times 3^{2/3}} -
{2(1+i\sqrt{3})\above 1.5pt {\sqrt[3]{\frac{3}{2} \bigg (9 + i
\sqrt{687}\bigg)}}} \\   \lambda_3 & =
 -{\bigg(1+i\sqrt{3}\bigg)\sqrt[3]{\frac{1}{2}\bigg(9 + i \sqrt{687}\bigg)}\above 1.5 pt 2\times 3^{2/3}} -
{2(1-i\sqrt{3})\above 1.5pt {\sqrt[3]{\frac{3}{2} \bigg (9 + i
\sqrt{687}\bigg)}}}\\ \end{align}
  Is it obviously true that $$|\lambda_1|^2+|\lambda_2|^2+|\lambda_3|^2
 =8$$ 
  ? This question is driven entirely by curiosity and fun. Unless I am missing the obvious it seems if you were to work this out by hand it would be demonstrably difficult ? Here is the origin of the problem and my attempted solution: Let $A(n)$ be a finite square $n \times n$ matrix with entries $a_{i,j}=1$ if $i+j$ is a perfect power; otherwise equals to $0$. Let $\chi_{A(n)}(X)$ be the characteristic polynomial of $A(n)$. By the fundamental theorem of algebra $\chi_{A(n)}(X)$ has $n$ roots (=eigenvalues). Denote the $n$ eigenvalues by $\lambda_i$ with $1 \leq i \leq n$. Note $A(n)=A(n)^t$ where $^t$ is the matrix transpose and in particular $A(n)$ is a real symmetric matrix consequently it is normal. I bring Schur's Inequality into play: $$\sum_{i=1}^n |\lambda_i|^2 = \sum_{i=1}^n \sum_{j=1}^n  |a_{ij}|^2$$ Immediately this tells me that the number of $1$'s in $A(n)$ is completely determined by its eigenvalues. Now consider $A(6)$. $$A(6)= \text{ }\begin{pmatrix}
0&0&1&0&0&0\\
0&1&0&0&0&1\\
1&0&0&0&1&1\\
0&0&0&1&1&0\\
0&0&1&1&0&0\\
0&1&1&0&0&0\\
\end{pmatrix}$$ I have that $$\chi_{A(6)}(X)=X^6-2X^5-4X^4+8X^3+2X^2-4X-1$$ and that can be factored into $$(X^3-4X-1)(X^2-X-1)(X-1)$$ $A(6)$ has 6 eigenvalues which can be written (courtesy of WOLFRAM ALPHA) \begin{align}
\lambda_1 & = {\sqrt[3]{\frac{1}{2}\bigg(9 + i \sqrt{687}\bigg)}\above 1.5 pt 3^{2/3}} + {4 \above 1.5pt {\sqrt[3]{\frac{3}{2} \bigg (9 + i \sqrt{687}\bigg)}}}\\
 \lambda_2 & = -{\bigg(1-i\sqrt{3}\bigg)\sqrt[3]{\frac{1}{2}\bigg(9 + i \sqrt{687}\bigg)}\above 1.5 pt 2\times 3^{2/3}} - {2(1+i\sqrt{3})\above 1.5pt {\sqrt[3]{\frac{3}{2} \bigg (9 + i \sqrt{687}\bigg)}}} \\ 
 \lambda_3 & = -{\bigg(1+i\sqrt{3}\bigg)\sqrt[3]{\frac{1}{2}\bigg(9 + i \sqrt{687}\bigg)}\above 1.5 pt 2\times 3^{2/3}} - {2(1-i\sqrt{3})\above 1.5pt {\sqrt[3]{\frac{3}{2} \bigg (9 + i \sqrt{687}\bigg)}}}\\
\lambda_4 & = -{1\above 1.5 pt \phi}\\
\lambda_5 & = \phi\\
\lambda_6 & = 1
\end{align} where $\phi= {1+ \sqrt{5}\above 1.5pt 2}$ and is called the golden ratio. Note $\sum_{j=1}^6  a_{ij}=12$ and according to our first equation I can write $$1+|\lambda_1|^2+|\lambda_2|^2+|\lambda_3|^2+ |-{1\above 1.5 pt \phi}|^2 +|\phi|^2 =12$$ I can show that $$|-{1\above 1.5 pt \phi}|^2 +|\phi|^2=3$$ Cancelling out terms and regrouping yields $$|\lambda_1|^2+|\lambda_2|^2+|\lambda_3|^2 =8$$ and we are done. Outside of hand calculations which I am too lazy to do to I am not aware of any other approach that will obviously and for that matter quickly show the sum equals $8$.","['algebra-precalculus', 'radicals', 'eigenvalues-eigenvectors', 'summation']"
2307213,Reducing system of differential equations to first order.,"I have to solve following system of equations:
$$
x''=-x-z+e^{-t},z'=-2x-2z+3e^{-t}
$$
I would like to have formula for $x'$ in order to find fundamental matrix and so on. So from above quations I obtain $z'-2x''=e^{-t}$, integrate sides and have $2x'=z+e^{-t}$. So I have system of two first-order differential equations $$2x'=z+e^{-t}, z'=-2x-2z+3e^{-t}$$ Is it correct?",['ordinary-differential-equations']
2307217,Relationships between 2 matrices yielding values of determinants,"I got some homework in my school about matrix. These questions are seem so easy to solve but I always get stuck. Here they are: Let $A,B \in \mathbb{R}^{2017\times2017}$ matrices which satisfy the following equation.
  $$A^{-1} = (A+B)^{-1}-B^{-1}$$
  and $\det(A^{-1})=2017.$ Find $\det(B)$. My attempt: \begin{equation*}
\begin{split}
(A+B)A^{-1} &= (A+B)\left[(A+B)^{-1}-B^{-1}\right] \quad \quad \text{multiplying both sides by (A+B)} \\
A^{-1}A +BA^{-1} &= (A+B)(A+B)^{-1}-(A+B)B^{-1} \\
I+BA^{-1} &= I - AB^{-1}-I\\
I+BA^{-1} &=-AB^{-1}\\
BA^{-1} +AB^{-1} +I&= O
\end{split}
\end{equation*}
then I don't know how to continue. 2.Let $A,B\in \mathbb{R}^{2017 \times 2017}$ matrices which satisfy the equation
  $$AB^{2}-2BAB+B^{2}A=O$$ What is the largest eigenvalue of $AB-BA?$ $ABB+BBA=2BAB$ $ABB+BBA=BAB+BAB$ $ABB-BAB=BAB-BBA$ $(AB-BA)B=B(AB-BA)$ what is this means?
I really need your thoughts, thanks in advance.","['matrices', 'eigenvalues-eigenvectors', 'determinant']"
2307219,ANOVA test real-life application,"What are the real-life application of ANOVA test ?I used to solve question during my college day and never understood the real life application. Thanks,",['statistics']
2307231,Primes in Congruence Classes,"Let $\pi_1(x)$ denote the number of primes $p$ less than $x$ such that $p \equiv 1 \bmod 4$ and $\pi_3(x)$ the number of primes $p$ less than $x$ such that $p \equiv 3 \bmod 4$. How does one approach $$\lim_{x\to \infty}\frac{\pi_1(x)}{\pi_3(x)}$$ I remember seeing a theorem addressing this problem, but cannot remember its name...","['number-theory', 'congruences', 'prime-numbers', 'elementary-number-theory']"
2307297,Discrete theta functions and periodicity,"I'm doing quantum mechanics and I have an eigenfunction which is a theta function. I then discretised it, since I want see if I can find the eigenvalues for the discrete case by finding the eigenfunctions for the continuum and discretising them then applying translation operators for derivatives. I have a theta function of the form $$\theta_3(z|\tau)$$ where $$z=\frac{ivL}{N}-\frac{ik_1}{N}+\frac{k_2}{N};$$ $$\tau=\frac{i}{N},$$ and $k_1$, $k_2=0,1,..., N-1$ with $v$ and $L$ being constants. Using the periodicity of the theta function $$\theta_3(z+\tau|\tau)=\exp(-\pi i\tau-2\pi iz)\theta_3(z|\tau);$$
and 
$$\theta_3(z-\tau|\tau)=\exp(-\pi i\tau+2\pi iz)\theta_3(z|\tau)$$
where the above condition come from $k_1\mapsto k_1\pm 1$. My question is thus: for the other translation I acquire the resulting theta functions
$$\theta_3(z\pm i\tau|\tau),$$
is there a rule for this such that
$$\theta_3(z\pm i\tau|\tau)=A(z,\tau_\pm)\theta_3(z|\tau)?$$ I've tried looking at the series representation and computing it explicitly, but no luck. Am I just being hopeful, when in fact, there is no way to find the neat form of the $z\pm i\tau$ periodicity condition? This leads to another question: how does one use an eigenfunction which is theta function in the Schrödinger equation to find eigenvalues? The derivatives aren't defined since it creates a sum like $\sum_{m\in\mathbb{Z}}\alpha m\hspace{1mm}\mathrm{e}^{\hspace{1mm}\beta m^2+m\gamma}$ where $\alpha$, $\beta$ and $\gamma$ are constants, which as far as I know can't be computed...","['theta-functions', 'eigenfunctions', 'discrete-mathematics']"
2307331,Does the Legendre Symbol/quadratic reciprocity generalize to higher degrees?,"The Legendre symbol is a tool for measuring whether or not
$$
x^2 \equiv a \text{ } (p)
$$
has a solution in $\mathbb{F}_p$ for some fixed integer $a$. Does the Legendre symbol generalize to higher degrees? For example, can I define a law
$$
\left( \frac{\cdot}{p} \right)_k:\mathbb{F}_p^* \to ???
$$
telling me whether or not
$$
\frac{\mathbb{F}_p[x]}{(x^k - a)}
$$
is a field, and if it is not, how far is it from being a field? Also, if there is such a rule, are there reciprocity laws which can be found?","['number-theory', 'legendre-symbol', 'algebraic-number-theory', 'elementary-number-theory']"
2307337,The discriminant of cyclotomic polynomial $\Phi_n(x)$,"Let $\Phi_n(x)$ be a cyclotomic polynomial, $n\in \mathbb{N}$ . Prove that $\mathrm{Disc}(\Phi_n(x)) = (-1)^{\frac {\phi(n)}{2}}n^{\phi(n)}\prod_{p\mid n,\, p\text{ prime}} {p}^{\frac {\phi(n)}{1-p}}$ I've found a solution for prime $n$ .
For arbitrary $n$ we have $D(\Phi_n(x))=\prod_{\substack{1\le j<k\le n\\\gcd(j,n)=\gcd(k,n)=1}}(e^{\frac{2k\pi i}{n}}-e^{\frac{2j\pi i}{n}})^2$ . Also we have $\Phi_n(X) = \frac{x^n-1}{\prod_{d|n, d<n} \Phi_d(x)}$ . What can I get from that?","['cyclotomic-polynomials', 'abstract-algebra', 'discriminant', 'polynomials']"
2307370,Investigate on convergence and absolute convergence,"How to investigate on convergence and absolute convergence the following integral: $$\int \limits_0^1 \frac{\sin(1/x)}{(\sqrt{x} - x)^n}$$ for all real values of $n$? I've tried to make a comparison test. In order to do this I needed some upper bound, but I didn't know how to pick it. UPD As @zhw. pointed I made substitution $x = 1/y$ and got $$\int \limits_1^{\pi/2} \frac{\sin y \cdot y^{n - 2}}{(\sqrt{y} - 1)^n}dy + \int \limits_{\pi/2}^{\infty} \frac{\sin y \cdot y^{n - 2}}{(\sqrt{y} - 1)^n}dy$$ For the first integral I want to use Taylor expansion for $\sqrt{y}$ at $y = 1$ and also the numerator can be bounded by some constant: $$\int \limits_1^{\pi/2} \frac{\sin y \cdot y^{n - 2}}{(\sqrt{y} - 1)^n}dy < \int \limits_1^{\pi/2} \frac{c}{(\sqrt{y} - 1)^n}dy \sim \int \limits_1^{\pi/2} \frac{c}{(1+ \frac{y - 1}{2} + O((y - 1)^2) - 1)^n}dy = \int \limits_1^{\pi/2} \frac{c}{(\frac{y - 1}{2} + O((y - 1)^2))^n}dy$$ . I don't really know how to proceed further. And also I don't like the jump with equivalence. For the right integral I probably could say that as $y \to \infty \Rightarrow (\sqrt{y} - 1)^n \sim y^{n/2}$, but again I want to be fully correct with this step. It seems like it is converge for $n < 1$. I can't say anything about absolute convergence.","['real-analysis', 'calculus', 'integration', 'definite-integrals', 'convergence-divergence']"
2307399,Solve summation $\sum_{i=1}^n \lfloor e\cdot i \rfloor $,"How to solve $$\sum_{i=1}^n \lfloor e\cdot i \rfloor $$ 
  For a given $n$. For example, if $n=3$, then the answer is $15$, and it's doable by hand. But for larger $n$ (Such as $10^{1000}$) it gets complicated . Is there a way to calculate this summation?","['summation', 'sequences-and-series', 'ceiling-and-floor-functions']"
2307402,Using Taylor Expansion to evaluate limits,"I am going through some lecture notes and I came across this limit: $$\lim_{x\to 0}\frac{\sinh x^4-x^4}{(x-\sin x)^4} $$ In the notes, it says (after introducing L'Hopital's Rule) that this would be difficult to evaluate using L'Hopital's Rule but can be done on sight using Taylor's Theorem. After reading the section on Taylor's Theorem, I don't understand how this can be done in sight. Would one need to calculate its Taylor expansion? If so, how would one go about doing that as its derivatives aren't defined at 0? I have used Wolfram to see the Taylor expansion is $216+O(x^2)$ which means the limit is equal to 216, but how does one calculate this Taylor expansion?","['taylor-expansion', 'limits-without-lhopital', 'limits']"
2307409,variance bounds of functionals,"$X_1,\ldots,X_n$ are i.i.d standard random variables. $a_1,\ldots, a_n$ are constants such that $\min_i a_i > 0$ and $\max_i a_i < \infty$ $\hat c$ is given as the solution to the equation: $$\sum_{i=1}^n \frac{c -X_i^2}{(c+a_i)^2}=0. $$ Can we prove that $$ \operatorname{Variance} (\hat c)=O(n^{-1}) \text{ as } n \to \infty.$$ Note that the above can be easily proved when all $a_i$' s are equal. What will happen in the general case?","['statistical-inference', 'probability-theory', 'asymptotics', 'statistics', 'probability']"
2307435,"Ramification, integrally closed domains","Let $L/K$ be a finite (I need only Galois, but I doubt this extra condition is really needed) extension where $K$ is of transcedence degree $1$ over $F$, where $F$ a number field. Let $O_K$ be a Dedekind subring of $K$ and $O_L$ the integral closure of $O_K$ in $L$. Is it true that only finitely many primes of $O_K$ are ramified in $O_L$ ? Is it true if $K$ is ring of functions of some projective variety over $F$ ?","['ramification', 'dedekind-domain', 'algebraic-number-theory', 'algebraic-geometry']"
2307449,How to check if a polynomial map surjects onto a given zero locus,"I have a polynomial map $f:\mathbb{Z}^n\rightarrow\mathbb{Z}^r$ (i.e. $f$ is given by $r$ polynomials, each polynomial in $n$ variables and with integer coefficients). I also have finite sets $L\subset\mathbb{Z}[T_1,\dotsc,T_n]$ and $S\subset\mathbb{Z}[X_1,\dotsc,X_r]$. Let $X\subset\mathbb{Z}^n$ be the set of common zeros of $L$ and $Y\subset\mathbb{Z}^r$ the set of common zeros of $S$. Assume that $f(X)\subset Y$. Is there an effective way to check if $f(X)=Y$?","['polynomials', 'algebraic-geometry']"
2307461,Asymptotic Distribution of Prime Gaps in Residue Classes,"Define $\pi_{n,a}(x)$ as the number of primes $p$ less than $x$ such that $p\equiv a\bmod n$ for coprime $n,a$ . This function can be asymptotically approximated by $$\pi_{n,a}(x)=\frac{\operatorname{Li}(x)}{\varphi(n)}$$ This allows for the conclusion that, as $x$ tends to infinity, $\pi_{4,1}(x)\sim\pi_{4,3}(x)$ . In other words, there are as many primes congruent to $1 \bmod 4$ as there are congruent to $3 \bmod 4$ . Can this theorem be extended to prime gaps? In other words, can it (or any other theorem, for that matter) be used to describe the distribution or density of prime gaps in specific residue classes? Update : Let $\gamma_{n,a}(x)$ denote the number of prime gaps $g=p_i-p_{i-1}$ for $p_i\leq x$ such that $g\equiv a \bmod n$ . It is quite straightforward to show that, as $x$ tends to infinity, $\gamma_{6,2}(x)\sim\gamma_{6,4}(x)$ and $\gamma_{4,0}(x)\sim\gamma_{4,2}(x)$ . However, I am unable to properly estimate $\gamma_{6,0}(x)$ (unlike $\pi_{n,a}$ , it seems that $\gamma_{n,a}$ does depend on $a$ ), or any other value of $a$ and $n$ for that matter.","['number-theory', 'prime-gaps', 'prime-numbers', 'modular-arithmetic']"
2307462,Trouble understanding this Equality of Complex number question.,"I have this question here $$(3-2j)(x+yj)=4+j^9$$ I know that $a + bj$ and $x + yj$ are equal when $a = x$ and $b = y$. This question is confusing me because I have had three different answers but they are all wrong. What feels like my closest attempt was:
$$(3-2j)(x+yj)=4+j^9.$$ $x + yj = (-3+2j)(4-j)$ $= -12 + 3j + 8j -2j^2$ $= -12 + 11j -2(-1)$ $= -12 + 11j + 2$ $= -10 + 11j \:\: \Rightarrow$ $x = -10$ $y = 11$ But the answer is supposed to be $x = 10/13$ $y = 11/13$ I am just looking for some guidance on how to properly solve this and figure out where I went wrong. Thank you!","['complex-geometry', 'complex-analysis', 'complex-numbers']"
2307491,"if $\sum_{n=0}^\infty na_n$ converges, does $\sum_{n=0}^\infty na_{n+1}$ converge?","If the sum :$$\sum_{n=0}^\infty n\, a_n$$ converges does it mean that : $$\sum_{n=0}^\infty n\, a_{n+1}$$ converges too? (Note that $a_n$ can be negative)","['summation', 'calculus']"
2307496,A function whose first and second derivatives have zero expectation but not the third derivative,"I came across this interesting problem through a friend and I am trying to find a solution to it. Let $X \sim \mathcal{N}(0,1)$ be the standard Gaussian random variable. The goal is to find a function (can assume all nice properties ) $f: \mathbb{R} \to \mathbb{R}$ such that 
$$
E[f'(X)]=0, E[f''(X)]=0, \text{ and } E[f'''(X)] \neq 0 .
$$ Does there exist any such $f$ satisfying the above properties? It's not sure if it's true or not. I feel this problem is closely related to Hermite polynomials but not sure. Can anyone suggest a method to solve this? The approach that I am currently using is through Taylor expansion. Suppose $f(x)=\sum_{i} \alpha_i x^i$. Then the above conditions imply that
$$
\sum_k \alpha_{2k+1} \cdot (2k+1)!!=0, \\
\sum_k \alpha_{2k+2} \cdot (2k+2) \cdot (2k+1)!!=0,\\
\sum_k \alpha_{2k+3} \cdot (2k+3) \cdot (2k+2) \cdot (2k+1)!! \neq 0,
$$
where $!!$ is the double factorial. This doesn't shed much light on how the coeffecients $\alpha_i$ should be.","['probability-theory', 'probability', 'functions', 'random-variables']"
2307514,Submodularity for Cartesian product,"We define a set function $f:2^E \rightarrow \mathbb{R}$ to be submodular if for every $ S,T\subseteq E $ with $ S\subseteq T $ and for every $ x\in E\setminus T : f(S\cup \{x\})-f(S)\geq f(T\cup\{x\}) - f(T) $. How could I extend this concept to a Cartesian product of two sets? For example, would the following definition make sense? We define a set function $f:2^{E_1 \times E_2} \rightarrow \mathbb{R}$ to be submodular if for every $ S_1,T_1\subseteq E_1 $ with $ S_1\subseteq T_1 $ and $ S_2,T_2\subseteq E_2 $ with $ S_2\subseteq T_2 $ for every $ p\in E_1\setminus T_1$ and $q\in E_2\setminus T_2 $, it holds that $f((S_1\cup \{p\}) \times (S_2\cup \{q\}))-f(S_1 \times S_2)\geq f((T_1\cup \{p\}) \times (T_2\cup \{q\})) - f(T_1 \times T_2) $. If yes, then how can I prove this holds if submodularity holds for individual set functions $f_1:2^{E_1} \rightarrow \mathbb{R}$ and $f_2:2^{E_2} \rightarrow \mathbb{R}$? Any help and hints will be greatly appreciated.","['combinatorics', 'matroids', 'discrete-mathematics']"
2307519,Is mathematics done in an arbitrary model of ZFC?,"Following up a previous thread I posted, I have tried to refine my questions. I would be happy with answers simply confirming that I have understood matters correctly, but of course I would also be happy to read longer and more elaborate answers! Suppose I want ZFC (as formulated in first-order logic) to be my foundations of mathematics, i.e. I want it to be possible to formalise all of my reasoning about for example number theory as consequences in first-order logic of the ZFC axioms. These are my questions: When I consider a ""set"", for example $\mathbb{N}$, when doing mathematics, is it reasonable to view $\mathbb{N}$ as living in a fixed model of ZFC? So if I wanted to be very pedantic, I would refer to $\mathbb{N}$ as $\mathbb{N}^\mathcal{A}$ where $\mathcal{A}$ is my fixed model of ZFC? Suppose I am doing mathematics and discussing properties of $\mathbb{N}$ with a friend of mine. Can any ""problems"" arise from me (implicitly) thinking of $\mathbb{N}$ as being $\mathbb{N}^\mathcal{A}$ living in my ZFC-model $\mathcal{A}$, while my friend thinks of $\mathbb{N}$ as being  $\mathbb{N}^\mathcal{B}$ where $\mathcal{B}$ is his ZFC-model? I suppose since all assumptions we have made about $\mathcal{A}$ and $\mathcal{B}$ is that they are ZFC-models, no ""substantial"" problems can arise, so my friend and I can therefore safely agree to ease notation by referring to $\mathbb{N}^\mathcal{A}$ and $\mathbb{N}^\mathcal{B}$ as simply $\mathbb{N}$? Given that my understanding of the above questions is correct, it seems reasonable to view mathematics in a ""semantic"" way as ""being done in an arbitrary model of ZFC""? Alternatively, if I insist on first-order logic ZFC to be my foundations, I could view doing mathematics as a sort of informal natural deduction, i.e. I could have a ""syntactic"" view on mathematics. The soundness and completeness theorems ensure that the ""semantic"" and ""syntactic"" views in some sense are the same, but perhaps one of the approaches has some philosophical advantages? I obviously find the semantic view more pleasing, since the semantic view is ""consistent"" with my view of a sets as living in models of ZFC... Thanks in advance! Edit: I realise that perhaps ""the standard model of ZFC"" might be relevant to my questions. That is, I should perhaps view $\mathbb{N}$ as always referring specifically to $\mathbb{N}^\mathcal{S}$ where $\mathcal{S}$ denotes the standard model of ZFC? Similarly, I should perhaps also view mathematics as being done specifically in the standard model of ZFC. If we disregard problems with even defining which model of ZFC is the standard one, this view also seems to give us problems with translating our informal mathematical proofs to natural deduction: If mathematics is done in a very specific model of ZFC, we can no longer rely on completeness of first-order logic to guarantee existence of a derivation in natural deduction. To summarise my edit: If the standard model of ZFC is relevant to my questions, please illuminate how. I do not think the standard model is relevant for my questions in any other way than being an ""intuitive model"" when thinking of ZFC.","['foundations', 'elementary-set-theory', 'philosophy']"
2307527,How to prove that the series $\sum _{n=1}^{\infty } \left( {F_{n+1}} \right) ^{- {F_n}} \approx 1.619141630$,"Suppose that $F_n$ is the $n$th term of Fibonacci numbers. By numerical calculation I see that 
$$
\sum _{n=1}^{\infty } \left(  {F_{n+1}} \right) ^{- {F_n}} 
\approx 1.619141630
$$
The rate of convergence of the above series is too high. I mean, if we compute with 50 digits, for $n\geq 8$ the values of series is constant and is as follows 
$$
\sum _{n=1}^{n\geq8} \left(  {F_{n+1}} \right) ^{- {F_n}} 
\approx 1.6191416299151308574250170831329152667545274408795
$$
Now my question: How to proof that the above series is converge to $1.619141630$. Thanks for any suggestion.","['fibonacci-numbers', 'sequences-and-series', 'convergence-divergence']"
2307561,How To Calculate Length Of Screw Thread?,"I'm having a tough time searching for the answer to this as most of the results are in the realm of mechanical engineering and appear to be unrelated, I apologize if this is a really obvious question. Say there is a circular arc in $2$ dimensions covering $90$ degrees at a radius of $21$. I know the length of the arc would be $\frac{21}{2}\pi$ or about $32.99$, but what if it were then stretched through the third dimension by some number $x$?  How do you calculate the screw thread length?",['geometry']
2307591,Derivative of orthogonal matrix - Generalization of Frenet frame equations,"I was studying Differential Geometry and the Frenet Frame equations $\begin{pmatrix}
T'\\ 
N'\\ 
B'
\end{pmatrix}
=
\begin{pmatrix}
0 & k & 0\\ 
-k & 0 & \tau\\ 
0 & -\tau & 0
\end{pmatrix}
\begin{pmatrix}
T\\ 
N\\ 
B
\end{pmatrix}$ made me think about the general case: Statement: If $A(s), \space s\in I$ is an orthogonal $n \times n$ matrix with $C^{\infty}$ coefficients, then there exists an antisymmetric matrix $R(s)$ such that $A'(s)=R(s)A(s) \space \forall s \in I$. Proof: $A$ orthogonal $\Leftrightarrow$ $AA^t=I_n$ If we differentiate the above equation, Leibniz rule gives $A'A^t+A(A^t)'= \mathbf{0} \Rightarrow A'=(-A(A^t)')A.$ We set $R:=-A(A^t)'$ and we show that it is antisymmetrical: $R^t=[-A(A^t)']^t=[-A(A')^t]^t=-A'A^t \Rightarrow $ $R+R^t = -(A(A^t)'+A'A^t) = -(AA^t)'=-(I_n)'=\mathbf{0} \space \square$ Is this proof complete? Have I missed something? Something bugs me about how we define $R$. Is it okay that $A'$ hides in there? I believe that as long as it is an existence problem, we don't care about the calculation of $R$, we just have to show that it exists, but I'm not entirely sure. Thank you in advance!","['frenet-frame', 'differential-geometry', 'linear-algebra']"
2307660,How do I solve this statistics question on approximation of distribution? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Suppose that $U_i\sim \operatorname{iid} \operatorname{Unif} [-1,1]$ and consider $$\ X = \frac{U_1 + U_2 + \cdots + U_n} {\sqrt{U_1^2 + U_2^2 + \cdots + U_n^2}}$$
for large $n.$ What is the probability that $X > 1.$ Justify any approximation you use. How large $n$ should be?","['probability-limit-theorems', 'statistics', 'statistical-inference']"
2307661,Sending one broken taxi each to three different airports.,"Suppose we have $9$ taxis, and three airports, aiport $A$, airport $B$, and airport $C$. We want to send $3$ taxis to airport $A$, $5$ taxis to airport $B$, and $1$ taxi to airport $C$. If exactly three of the taxis are in need of repair, what is the probability
  that every airport receives one of the taxis requiring repairs? I'm struggling to solve this problem. There is a theorem that I want to use, listed below: THEOREM : The number of ways of partitioning $n$ distinct objects into $k$ distinct groups containing $n_1, n_2, \ldots , n_k$ objects, respectively, where each object appears in exactly one group and $\sum_{i=1}^k n_i = n$, is $$N = {n\choose n_1 \;n_2 \;\cdots\; n_k} = {n!\over n_1!\;n_2!\;\cdots\;n_k!}.$$ The following is a solution I found here on page 83 for this problem. SOLUTION : Using the theorem, there are $${9\choose 3\;5\;1} = {9!\over 3!\;5!\;1!} = 504\text{ ways}$$ to send the taxis to all the airports. Let $W$ denote the event that the $3$ taxis that are in need of repair are sent to each airport. The number of ways we can send each of the $3$ broken taxis to the three airports is given by $${3\choose 1\;1\;1} = 3! = 6. \tag{Why is this important?}$$ Also, the number of ways we can send the remaining $6$ taxis to the three airports is given by $${6\choose 2\;4\;0} = {6!\over2!\;4!} = 15$$ (since each of the three broken taxis are already taking up a spot). So, by the $mn$-rule, the number of points in the sample space for $W$ is given by $$N_W = \underbrace{6\times15}_\text{Why?} = 90.$$ Thus the probability that each of the three airports receives a broken taxi is $$P(\text{broken taxi to each } A,B,C) = {N_W\over N} = {90\over504}.$$ Can someone please explain the two Why s? I thought that by holding each of the three broken taxis constant that we would only need to consider the remaining $6$, and I originally thought the probability would be $15\over504$. However, this probability seems unusually low . Thus, I went and found the solution written above. However, I was not able to comprehend the logic behind the solution. Here's what I'm thinking is wrong with my logic process and how we get the correct logic: Holding each of the broken taxis to a particular airport is where the logic is incorrect. We also want to be able to permute the broken taxis among the three airports. This is why we need the ${3\choose1\;1\;1}$. We can then permute the remaining $6$ taxis among the three airports, giving us the ${6\choose 2\;4\;0}$. Is this correct thinking? An earlier problem asked us to find the probability that exactly one broken taxi is sent to airport $C$. I did the following approach: If we're sending $1$ broken taxi to airport $C$, then we can permute the remaining $8$ like so $${8\choose 3 \; 5\; 0} = 56,$$ which this answer was correct according to the back of the book. However, I applied the same principle to the problem at-hand and only received $15$ ways. Is the ""correct"" way to use the theorem and the $mn$-rule to say: There is $${1\choose 0\;0\;1} = 1$$ way to send $1$ broken taxi to airport $C$, and $56$ ways to distinctly send the other $8$ to airports $B$ and $C$. So, by the $mn$-rule, there are $1\times56$ sample points such that a broken taxi gets sent to airport $C$. This makes sense to me, but I might just be making up a solution that yields the correct answer, but is not logically correct.","['permutations', 'probability-theory', 'statistics', 'proof-verification']"
2307669,Find a basis for orthogonal complement in R⁴,"How do I approach part 2? I found the projection of 1. to be (6,-2,2,-2) but what do I do now?","['orthogonality', 'linear-algebra']"
2307673,"How to calculate $\int{\frac {x^2}{ ( x\cos x -\sin x ) ^2}}\,{\rm d}x$?","When I want to calculate
$$\int{\frac {x^2}{ ( x\cos x -\sin x ) ^2}}\,{\rm d}x$$
I have tested with software and get
$${\frac {x\sin \left( x \right) +\cos \left( x \right) }{x\cos \left( x
 \right) -\sin \left( x \right) }}$$ But I can not come to this conclusion, neither using integration by parts, nor using trigonometric identities, nor multiplying by their conjugate, Even by rational trigonometric substitution. I do not know what else to try. Could you give me any suggestions?","['indefinite-integrals', 'trigonometric-integrals', 'calculus']"
2307689,For $\Delta ABC$ right-angled triangle at $A$ have $AB=AC$. Calculate the ratio of $MA: MB: MC$,"For $\Delta ABC$ right-angled triangle at $A$ have $AB=AC$, uppose in the triangle that the point M satisfies $\widehat{MBA}=\widehat{MAC}=\widehat{MCB}$. Calculate the ratio of $MA: MB: MC$ Let D,E sequence are center circumsribed circle ABM, CAM $\widehat{MAC} =\widehat{MBA}$ =>AC is tangent of the circle (D) =>CA_|_ DA=> $D\in AB$ So $DA =DB$  =>D midpoint of AB Have $\widehat{MCB} =\widehat{MAC}$ =>BC is tangent of d and midperpendicular of AC (D) cut BC at F =>AF_|_BC and F midpoint  BC Have $\widehat{MBA} =\widehat{MCB}$ and $\widehat{MAB} =\widehat{MFC}$ (AMFB cyclic quadrilateral) =>$\triangle MAB \sim\triangle MFC$=>$\frac{MA}{MB} =\frac{MF}{MC}(1)$ Have $FA=\frac{BC}{2}=FC$ =>FE is midperpendicular AC FE cut AC at G. Have $\widehat{AGF} =\widehat{CGE}, \widehat{AFG} =\widehat{CEG}$; $GA;GC$ =>$\triangle AGF =\triangle CGE$ ............. blah blah $$\Rightarrow MA:MB:MC=1:2:\sqrt{2}$$ This is my try, it's very long and difficult, because i need new method","['triangles', 'geometry']"
2307710,Solving Pell's equation $x^2-5y^2=\pm4$ using elementary methods.,"Solve Pell's equation $x^2-5y^2=\pm4$. This equation arises when I tried to prove that the units of $\mathbb{Z}[\varphi]$, where $\varphi=\frac{1+\sqrt{5}}{2}$ is the golden ratio, are of the form $\pm\varphi^n$. I found that $x+\varphi y$ is a unit iff $x^2+xy-y^2=\pm1$, i.e. $(2x+y)^2-5y^2=\pm4$. Yet I am unable to solve this equation. I saw here a solution using algebraic number theory, but I am interested in how to solve this equation using elementary methods, without using results from algebraic number theory. Thanks in advance!","['number-theory', 'pell-type-equations']"
2307713,"What does an unfinished parentheses set mean? $\left(y\ln y - e^{-xy}\right)dx + \left( \frac{1}{y} + x\ln y\right.\,\, dy = 0$","I am currently taking a differential equations course and this homework equation popped up $$\left(y\ln y - e^{-xy}\right)dx + \left( \frac{1}{y} + x\ln y\right.\,\, dy = 0$$ As the title suggests, I am asking for the meaning of farthest left parentheses to the right. It seems unfinished, but it probably means something. For clarification, it's the $\left(\frac{1}{y}\right.$ part. All help is appreciated and thank you in advance. Note: I apologize if the equation turns out improperly formatted, it is my first post. Please bear with me! Homework pic",['ordinary-differential-equations']
2307731,Solution to the differential equation $G'(x) = G(\pi x)$,"In this answer , I came across the differential equation
$$
G'(x) = G(\pi x)
$$
Despite its apparent simplicity, I couldn't think of an elementary solution to it. Does this have a known solution?",['ordinary-differential-equations']
2307752,Sampling from the space of positive definite matrices,"Is there a way to sample from a probability distribution on the space of positive definite $3\times3$ matrices with some constraints? I'm looking for any examples of such schemes. In particular, I'd be interested in looking at matrices with $\alpha_1 < \det(M) < \alpha_2$ and $ \beta_1 < \text{tr}(M) < \beta_2 $, where $\alpha_i,\beta_i >0$. 
I am aware these may not be sufficient to bound the space. It would be nice to not only have a uniform distribution on such a space, but also have a Gaussian-like distribution (where I would have some matrix $M$ set as the mean of the distribution, such that one could sample around it). But any thoughts/literature on the topic would be nice. I suspect it might be easier if $M$ were symmetric. Initial ideas: since 
$ \text{tr}(M) = \sum_i\lambda_i $ and $\det(M)= \prod_i\lambda_i$, I was thinking of drawing random eigenvalues such that the constraints are satisfied.
Another constraint may need to be added (3 constraints for 3 eigenvalues).
Then I would sample $P$ as an orthogonal matrix and take $P\,\text{diag}(\lambda)P^{-1}$ (not sure this is the right thing to do).
However, I have no idea how ""uniform"" such a distribution would be in the space of PD matrices, nor does this seem very efficient.
Further, whether it covers the whole space is not clear. Edit 1: the ""Related"" questions bar suggested this question , which is similar but restricted to symmetric matrices. It links to the Wishart distribution , which led me to the matrix Gamma distribution and inverse matrix Gamma distribution .
It would be nice to find something allowing sampling from asymmetric PD matrices. On the other hand, a matrix $M$ is PD iff its symmetrized version $M+M^T$ is PD.
(e.g. here ). (Maybe this can come in handy? E.g. if one specifies the eigenvalues, could one generate an SPD matrix, and then perturb it in a principled way).","['random-matrices', 'matrices', 'positive-definite', 'sampling', 'statistics']"
2307753,What is $e^{-\int \tan(t)dt}$?,"I know that $-\int \tan(t)dt$ = $\ln |\cos t|$ (letting $C=0$). So I would think that $e^{-\int \tan(t)dt}$ would be equal to $e^{\ln |\cos t|} = |\cos t|$. However, my math textbook and Wolfram Alpha both say that $e^{-\int \tan(t)dt}=e^{\ln (\cos t)} = \cos t$. Why can the absolute value be ignored when taking the indefinite integral in this case? Context: Finding an integrating factor for $x' = x\tan(t) + \sin(t)$. But Wolfram Alpha also gave me this answer without any differential equations context.","['integration', 'ordinary-differential-equations', 'calculus']"
2307776,When the contraction of maximal ideals is an injective open mapping,"Let $A$ and $B$ be two commutative rings with identity and let $f: A → B$ be a homomorphism of rings.
If $q$ is a prime ideal of $B$, $f^{-1}(q)$ is a prime ideal of $A$. Therefore we obtain a map
 $f' :  Spec(B) → Spec(A)$, where $f'(q) =f^{-1}(q)$. Now is there any condition on $A$ or $B$ or $f$ such that 
 $f'(Max(B))\subseteq Max(A)$, $f'$ is injective and $f'$ is open mapping? (Spec(R) is the set of all prime ideals of $R$ and Max(R) is the set of all maximal ideals of $R$)","['sheaf-theory', 'algebraic-geometry', 'schemes', 'maximal-and-prime-ideals', 'commutative-algebra']"
2307777,The duad-syntheme-total construction for higher values of $n$,"Let $X=\{1,\cdots,2n\}$. Call a $2$-subset of $X$ a duad . Let $D$ be the collection of all $X$'s duads. Call a partition of $X$ into duads a syntheme . Call a partition of $D$ into (necessarily $2n-1$) synthemes a ""synthematical total,"" or simply total for short. So for example with $n=2$, $\{1,2\}$ would be a duad, $\{\{1,2\},\{3,4\}\}$ a syntheme and $$\{~\{\{1,2\},\{3,4\}\},~\{\{1,3\},\{2,4\}\},~\{\{1,4\},\{2,3\}\}~\}$$ is the only synthematic total for $n=2$, and includes all of  the synthemes. Note the action of $S_4$ on this total gives us the exceptional homomorphism $S_4\to S_3$. In general, $S_{2n}$ acts transitively on the set of synthemes with point-stabilizer an internal wreath product $\mathbb{Z}_2\wr S_n$, which means the number of synthemes will be $(2n)!/(2^n n!)$. Question I . What is the number $t(n)$ of synthematic totals as a function of $n$? (The terms duad, syntheme and total come from Sylvester IIRC.) We see $t(1)=1$ and $t(2)=1$ by inspection. One can derive $t(3)=6$ with some geometric reasoning; see John Baez's webpage write-up or Peter Cameron's blog post . The story behind $t(3)=6$ is that of the construction of the (unique) outer automorphism of $S_6$. (The action of $S_6$ induces an action on the set of $6$ totals, which as an automorphism $S_6\to S_6$ is outer.) So: Question II : How does $S_{2n}$ act on the set of totals? Recall every $G$-set is a disjoint union of orbits, and the isomorphism type (as a $G$-set) of an orbit is determined by the conjugacy class of its point-stabilizers, which allows us to completely (if abstractly) characterize a group action. The $n=3$ case also gives rise to the so-called Tutte-Coxeter graph, so: Bonus question I : Do higher values of $n$ yield additional exotic incidence structures? And might as well stick this in: Bonus question II : Does anything similarly interesting happen with $k$-subsets for $k>2$? In the case of $n=4$, one of the orbits is in bijection with the set of distinct Fano planes. Under the regular representation of $\mathbb{Z}_2^3$, each vector induces a translation map which, as a permutation of the underlying set is a product of four $2$-cycles or equivalently a syntheme. The set of vectors thus corresponds to a set of synthemes which happens to be a synthematic total. The totals that can be achieved in this way correspond to the conjugacy class of this copy of $\mathbb{F}_2^3$ sitting inside $S_8$. In this orbit, the stabilizer will be the normalizer inside $S_8$, which will be the affine group $\mathrm{Aff}(3,2)=\mathbb{F}_2^3\rtimes\mathrm{GL}(2,3)$. If we pick an element of $\{1,\cdots,8\}$ to be the ""origin,"" we have an isomorphism of $S_7$-sets $$ S_8/\mathrm{Aff}(2,3)\cong S_7/\mathrm{GL}(2,3) $$ since $S_8$ is the knit product (aka Zappa–Szép product) of $S_7$ and the internal copy of $\mathbb{F}_2^3$. pjs36 in the comments raises the question if $S_{2n}$ always acts transitively on the set of synthematic totals. Unfortunately, I can't think of a good reason for that to be the case.","['combinatorial-designs', 'graph-theory', 'abstract-algebra', 'exceptional-isomorphisms', 'combinatorics']"
2307778,Relationship between sets $G_{\delta\sigma}$ and $G_{\delta}$,"Let $(X,d)$ compact. If $A\subset X$ is $G_{\delta}$ in $X$ and $B\subset X$ is $G_{\delta\sigma}$ in $X$, that is $B=\bigcup_{i\in\mathbb{N}}B_i$ where $B_i$ is $G_{\delta}$ of $X$. If $B\subset A$, then what is the relationship between $A$ and $B$ ? It could be said that $B$ is $G_{\delta\sigma}$ in $A$ ?","['general-topology', 'real-analysis', 'elementary-set-theory']"
2307784,Show that every prime $p$ in $\textbf Z[i]$ divides some rational prime,"Show that every prime $p$ in $\textbf Z[i]$ divides some rational prime. If $p \equiv 1 \pmod 4$ which is a prime, $p$ can be expressed as a sum of two squares, like, $p = a^2 + b^2$ where $a + bi$ and $a - bi$ are rational primes
and $p$ divides one of them. What if $p \equiv 3 \pmod 4$ which is prime?","['number-theory', 'prime-numbers', 'algebraic-number-theory']"
2307815,Is there any way to simplify the product of cosines? [duplicate],"This question already has answers here : Product of cosines: $ \prod_{r=1}^{7} \cos \left(\frac{r\pi}{15}\right) $ (7 answers) Closed 7 years ago . I recently saw a problem: Estimate the following: $cos(\frac{\pi}{15})cos(\frac{2\pi}{15})\ldots cos(\frac{7\pi}{15})$, and the options were between different consecutive power of ten. How would I do this, no calculator of course, and is there's any way to shorten any general products of sines or cosines or other trig functions?",['trigonometry']
2307834,Which of the following cannot be the class equation of a group G of order 10?,"Which of the following cannot be the class equation of a group G of order 10? 1)1+1+1+2+5. 2)1+2+3+4. 3)1+2+2+5. 4)1+1+2+2+2+2. Reasoning (1) is not the required class equation because if it is then the order of centre of G will be not possible due to Lagrange's theorem. (4) is not the class equation because if it is so then the index of centre of G
 in G will be 2 which implies G to be abelian leading to the class equation 10.Which is not possible. In answer key correct options are (1),(2),(4) .I'm not getting why (2) is not the class equation. In my class notes it is told that $S_3$ is the largest group with each conjugacy class of distict sizes.But,G is a group of order 10 with each conjugacy class of distict size in (2). Is there any other reason why (2) is not the class equation?","['finite-groups', 'abstract-algebra', 'group-theory']"
2307858,"Is a visual proof to $\varphi = 1 + \tfrac{1}{{1 + \tfrac{1}{{1 + \tfrac{1}{{1 + \,\ddots\,}}}}}}$?","Every body knows some thing about $\phi$ golden ratio One of definition for $\phi $ is like below 
$$\varphi  = 1 + \cfrac{1}{{1 + \cfrac{1}{{1 + \cfrac{1}{{1 + \,\ddots \,}}}}}}$$ 
My question is about this definition , Is there a visual proof for this formula? In general, can we bring some visual sense for continued fractions? I am thankful about you hint in advance. (I looked for this object on the Internet,but I can't find ...)","['algebra-precalculus', 'golden-ratio', 'continued-fractions', 'fractions']"
2307865,Why chess $960$ is known so?,"Here in this video it is saying that because we have $960$ distinct starting positions therefore it is known as chess $960$. I tried to solve this problem by myself but I failed. I have two rooks, two bishops, two knights, a queen and the king. Using this I have to fill all the eight squares on the first rank of the chess board. In addition there are two constraints that, (i) both the bishops must be placed on different colors and (ii) the king will sit between the rooks. Starting with the queen, queen can take any of the eigth positions and both the knights can take any of the seven and six positions respectively. Now definitely one of the bishops have three possible positions to take and the other bishop has two possible positions to take. So so far we  have $8\times 7\times 6\times3 \times 2=2016$ and this is more than $960$. Surely I'm making a mistake. As always combinatorics is a headache for me. Please help me out.","['combinatorics', 'chessboard']"
2307944,Count of near matching sequences,"Consider all pairs of binary strings $P$ and $T$. Let the length of $P$ be $n$ and the length of $T$ be $2n-1$.  For each such pair, we can compute the Hamming distance between $P$ and each of the $n$ substrings of $T$ in order from left to right and output a sequence representing these results. For example: $$P = 11011, T = 110011001$$ gives an output sequence: $$1,1,4,4,1.$$ For my problem I just want to record where the Hamming distance is at most 1. We write a $Y$ where this is the case and an $N$ otherwise.  So in this case I  would get: $$Y,Y,N,N,Y$$ where $Y$ represents Hamming distance at most $1$ and $N$ represents Hamming distance greater than $1$ If we iterate over all possible pairs $P$, $T$ we can count how many distinct sequences of $Y$s and $N$s we get from the outputs.  For $n = 1, \dots, 9$ we get the following interesting result: $$1 ,4, 8, 16, 32, 63, 120, 216, 368$$ Is it possible to give a closed form formula for the number of distinct sequences of $Y$s and $N$s? Related In Count number of exact matching sequences a very nice solution is given  by Smylic which corresponds to this problem with a Hamming distance bound of $0$ rather $1$.",['combinatorics']
2307945,To prove there are no Matrices $A$ and $B$ such that $AB-BA=kI$,"Prove that there are no Matrices $A$ and $B$ such that $AB-BA=kI$ where $k \ne 0$ Now since the products $AB$ and $BA$ are both defined and a subtraction exists between them so obviously both are square matrices of same order. Actually i have proved this by considering generic $2\times 2$ matrices. Letting $$A=\begin{bmatrix}
a & b\\ 
 c& d
\end{bmatrix}$$ Letting $$B=\begin{bmatrix}
p & q\\ 
 r& s
\end{bmatrix}$$ Now $$AB-BA=\begin{bmatrix}
br-qc & q(a-d)+b(s-p)\\ 
 c(p-s)+r(d-a)& cq-br
\end{bmatrix}=\begin{bmatrix}
k & o\\ 
 0& k
\end{bmatrix}$$ $\implies$ $$br-qc=k$$ and $$br-qc=-k$$ which is not valid unless $k =0$ is there a formal proof?","['matrices', 'linear-algebra', 'systems-of-equations']"
2307986,problem : conditions of similar matrices,"Could you please check my solution? Q. State all conditions that make A and B similar. $$A=
        \begin{pmatrix}
        0 & 4 \\
        a & 4 \\
      \end{pmatrix}
$$ $$B=
        \begin{pmatrix}
        2 & b \\
        0 & c \\
      \end{pmatrix}
$$ My solution : 
Since similar matrices have the same eigenvalues, trA=4=trB. so C=2. DetB=4=DetA so a=-1 Since both the sum and the product of the two eigenvalues are 4, the eigenvalues of A and B are 2,2 (multiplicity 2) $$B-2I=
        \begin{pmatrix}
        0 & b \\
        0 & 0 \\
      \end{pmatrix}
$$
$$(B-2I)v=
        \begin{pmatrix}
        0 & b \\
        0 & 0 \\
      \end{pmatrix}\begin{pmatrix}
        x  \\
        y \\
      \end{pmatrix}=\begin{pmatrix}
        by  \\
        0\\
      \end{pmatrix}=\begin{pmatrix}
        0  \\
        0 \\
      \end{pmatrix}
$$, where $$v=\begin{pmatrix}
        x  \\
        y \\
      \end{pmatrix}$$ is an eigenvector of B The value of $by$ must always be 0. So b is 0. So the answer is a=-1 and b=0 and c=2","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2308044,"How many ways are there to give 20 different presents to 4 different children, so that no child gets exactly 6 presents. All presents are different.","Prompt: How many ways are there to give 20 different presents to 4 different children, so that no child gets exactly 6 presents. All presents are different. Here's what I tried doing Since there are 20 presents to be distributed among 4 children, $$C_1 + C_2 + C_3 + C_4 = 20$$ By bars and stars, $$\binom{ 20 + 4-1 }{ 4-1 } = \binom{ 23 }{ 3 } = 1771$$ $C_2 + C_3 + C_4 = 14 $ (after giving 6 presents to $C_1$ ) Assuming $C_1$ gets 6 present = $\binom{ 14 + 3 - 1 }{ 3 - 1 } =  \binom{ 16 }{ 2 } = 120$ Assuming $C_2$ gets 6 presents = $\binom{ 14 + 3 - 1 }{ 3 - 1 } =  \binom{ 16 }{ 2 } = 120$ Assuming $C_3$ gets 6 presents = $\binom{ 14 + 3 - 1 }{ 3 - 1 } =  \binom{ 16 }{ 2 } = 120$ Assuming $C_4$ gets 6 presents = $\binom{ 14 + 3 - 1 }{ 3 - 1 } =  \binom{ 16 }{ 2 } = 120$ No one gets exactly 6 presents = Total - Everyone gets 6 presents = $\binom{ 23 }{ 3 } - \binom{ 4 }{ 1 }\binom{ 16 }{ 2 } = 1771 - 480 = 1291$ I am new to combinatorics and not sure if I'm on the right path any help would be appreciated.","['inclusion-exclusion', 'combinatorics', 'solution-verification', 'discrete-mathematics']"
2308064,BMO2 2017 Question 4 - Bobby's Safe,"Bobby’s booby-trapped safe requires a $3$-digit code to unlock it. Alex
has a probe which can test combinations without typing them on
the safe. The probe responds Fail if no individual digit is correct.
Otherwise it responds Close , including when all digits are correct. For
example, if the correct code is $014$, then the responses to $099$ and $014$
are both Close , but the response to $140$ is Fail . If Alex is following an optimal strategy, what is the smallest number of attempts needed to
guarantee that he knows the correct code, whatever it is? I think the optimal number is $13$ (start by trying $000$, $111$, $\ldots$, $999$), but it's hard to find bounds here. Any help?","['combinatorics', 'contest-math', 'optimization', 'combinatorial-game-theory']"
2308185,"Find a recursive formula for $J_n = \int_0^{\infty} x^{2n+1}e^{-x^2} \, \mathrm{d}x$","Given
  $$ J_n\stackrel{\text{def}}{=}\int_{0}^{+\infty}x^{2n+1}e^{-x^2}\,dx $$
  compute $J_0$, $J_1$ and find a recursion formula for $J_n$. I have computed $J_0$ and $J_1$ but I am clueless about the recursion formula, may I ask for some help? By integration by parts I got
$$ J_0 = \frac{1}{2},\qquad J_1 = \frac{1}{2}.$$","['improper-integrals', 'integration', 'definite-integrals', 'recursion']"
2308195,Example of how set-theoretic foundations might illuminate applications,"If possible, please give an example of how set-theoretic mathematical foundations might illuminate an engineer's work. By engineer, I mean a physical engineer (civil, mining, mechanical, chemical, electrical, etc.) rather than, say, a software engineer. To clarify: I do not imply that set-theoretic mathematical foundations ought (or ought not) to illuminate an engineer's work, but am merely asking for an example, in case they do happen to illuminate it. BACKGROUND The above is my question.  The below merely gives background, if relevant. I happen to be an electrical engineer with a master's degree in my late 40s.  My professional work is in building construction but my master's study focused on electromagnetics.  Thus, my mathematical applications include vector calculus, special functions, Green's functions, eigenfunctions, contour integrations and so on. I know what an analytic function is in an engineering context, can compute a divergence in parabolic coordinates, and might (with difficulty) exercise differentiable manifolds in the context of surface-borne electric currents; but can barely read logic notation, nor do I have any idea who Galois is or what his theory might be for. So, recently, to broaden my perspective, I have been reading Richard A. Silverman's 1973 English translation of Georgi E. Shilov's Elementary Real and Complex Analysis. Shilov is an engaging writer and I am enjoying his book, but maybe at my age the brain just grows too inflexible. I believe that there is a point to, say, Cantor's theorem of the uncountable continuum, but I don't seem to be getting the point. In 1925, Hermann Weyl wrote: [A set-theoretic approach] contradicts the essence of the continuum, which by its very nature cannot be battered into a set of separated elements.  Not the relationship of an element to a set, but that of a part to a whole should serve as the basis.... Whether Weyl or Cantor is the more right is not for me to say, nor is that the question I am asking; but I can say that Weyl's sentiment makes sense to me. So far, Cantor's sentiments do not make sense to me (unless Cantor's principal sentiment is just that Kant is right and Plato is wrong, in which case I should stop reading Cantorian books, for a merely metaphysical dispute between Cantor and Plato is not a thing I would wish to pursue). Obviously, Cantor's sentiments make sense to a lot of very smart mathematicians, though; so, if there existed an example to bridge Cantor's mental world to the world of an engineer's experience, this would help to motivate my further reading. As matters stand, I am having a hard time understanding how Cantor and friends are talking about anything at all other than abstract games played with arbitrary definitions. So, indeed, an example would help. Hilbert's grand hotel? Sure, very funny, I suppose: a most ingenious paradox. I should spend the night at Hilbert's grand hotel, sometime. One hears that the hotel's cuisine is transcendental. Meanwhile, I admit that I just don't really get the point. I believe that there is a point; I just haven't gotten it, yet. To clarify: I am not requesting a general defense of mathematical foundations, but merely a pertinent example, relevant to an engineer, that illuminates the mathematician's interest in mathematical foundations.","['applications', 'real-analysis', 'foundations', 'cantor-set']"
2308199,Residues of $\frac{1}{1-az} e^{-\frac{i t}{2}\left(z+z^{-1}\right)}$,"I have been fighting with a contour integral with the following integrand \begin{align*}
f(z)=\frac{1}{1-az} e^{-\frac{i t}{2}\left(z+z^{-1}\right)}
\end{align*}
for $a,t>0$ real constants. I think this has a simple pole at $z=a^{-1}$ and two essential essential singularities at $z=0$ and $z=\infty$. I find the residue for the simple pole to be
\begin{align*}
\text{Res}\left(f(z),z=a^{-1}\right) = -\frac{1}{a} e^{-\frac{i t}{2}\left(a+a^{-1}\right)}
\end{align*}
For the essential singularity at $z=0$, I use the Laurent series
\begin{align*}
e^{-\frac{i t}{2}\left(z+z^{-1}\right)} = \sum\limits_{n\in\mathbb{Z}} z^n I_{n}(-it) = \sum\limits_{n=0}^{\infty} \left(z^n +\frac{1}{z^n}\right) I_{n}(-it) - I_{0}(-it)
\end{align*}
Where in the second equality I used $I_{-n}(t)=I_{n}(t)$ and subtracted the double counting. Similarly, around $z=0$ I use
\begin{align*}
(1-az)^{-1} = \sum\limits_{n=0}^{\infty} a^n z^n 
\end{align*}
And so,
\begin{align*}
\frac{1}{1-az} e^{-\frac{i t}{2}\left(z+z^{-1}\right)} = \sum\limits_{n=0}^{\infty} \sum\limits_{k=0}^{\infty}\left(z^{2n-k}+z^{-k}\right) a^{n-k}I_{n}(-it) -I_{0}(-it)\sum\limits_{n=0}^{\infty}a^n z^n 
\end{align*}
And the term with power $z^{-1}$ comes from $k=1$,
\begin{align*}
\text{Res}\left(f(z),z=0\right) = \sum\limits_{n=0}^{\infty} a^{n-1}I_{n}(-it) = \sum\limits_{n=0}^{\infty} a^{n-1}I_{n}(-it)
\end{align*}
Is this sensible? I am unsure about the convergence and about the product of the series. In the neighbourhood of $\infty$, the Laurent series of the exponential remains the same (symmetry under $z\to z^{-1}$), while $(1-ax)^{-1} = -\sum (a z)^{-(n+1)}$?","['laurent-series', 'complex-analysis', 'residue-calculus']"
2308202,Evaluate the series $\sum _{n=1}^{\infty} \frac{n}{5^n}$ [duplicate],"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 7 years ago . $$\sum _{n=1}^{\infty}\frac{n}{5^n}$$ I tried to plug in $n=1,2,3,4,...$ but I can't use common ratio to solve problem.
I think there is another way like using differentiation or integral but I don't no exactly what to do.","['summation', 'sequences-and-series']"
2308213,Basis vectors in information geometry,"A basis vector in the tangent space at a point of a smooth manifold is given by a differential operator such as $\partial_{i}=\cfrac{\partial }{\partial \xi^{i}}$. On the other hand, in a statistical manifold consisting of probability distributions $p(x; \pmb{\xi})$ the basis vectors can be considered to be $\partial_{i} \log{p}$ which are not differential operators. Vector fields are defined to be linear maps that satisfy the product rule. How come $X^{i}\partial_{i}\log{p}$ is considered to be a vector field on a statistical manifold? How do we reconcile the defining properties of a vector field with the choice of $\partial_{i} \log{p}$ as basis vectors?","['vector-fields', 'information-geometry', 'differential-geometry']"
2308236,Process properties of the maximum of two independent linear Brownian motions,"Consider two independent linear Brownian motions $B'=(B'_t)_{t\geqslant0}$ and $B''=(B''_t)_{t\geqslant0}$, starting from $B'_0=B''_0=0$, and the process $X=(X_t)_{t\geqslant0}$ defined by $$X_t=\max\{B'_t,B''_t\}$$ What is known about the distribution of the process $X$? The question is admittedly a little vague, hence we present a few remarks to help narrow it. 1. For each positive $t$, the PDF $f_t$ of $X_t$ is $$f_t(x)=2\varphi_t(x)\Phi_t(x)$$ where $\varphi_t$ and $\Phi_t$ are the centered normal PDF and CDF with variance $t$. Equivalently, $$f_t(x)=\frac2{\sqrt{t}}\varphi\left(\frac{x}{\sqrt{t}}\right)\Phi\left(\frac{x}{\sqrt{t}}\right)$$ where $\varphi$ and $\Phi$ are the standard normal PDF and CDF. In particular, $X$ is not a Brownian motion. 2. The process $X$ is a submartingale . To show this in an elementary way, introduce the notations $B=(B',B'')$, and $\mathcal F^Y_t=\sigma(Y_s;s\leqslant t)$ for every time $t$ and every process $Y=(Y_t)_{t\geqslant0}$. Then, $X_t\geqslant B'_t$ almost surely hence, for every fixed $s<t$, $$E(X_t\mid \mathcal F^B_s)\geqslant E(B'_t\mid \mathcal F^B_s)=E(B'_t\mid \mathcal F^{B'}_s)=B'_s$$ By symmetry, $E(X_t\mid \mathcal F^B_s)\geqslant B''_s$ hence $E(X_t\mid \mathcal F^B_s)\geqslant X_s$. Finally, $\mathcal F^X_s\subseteq\mathcal F^B_s$ hence $$E(X_t\mid \mathcal F^X_s)=E(E(X_t\mid \mathcal F^B_s)\mid\mathcal F^X_s)\geqslant X_s$$ as desired. 3. The process $X$ is recurrent, in the sense that, for every $s$, almost surely, $$\sup_{t\geqslant s}X_t=+\infty\qquad\inf_{t\geqslant s}X_t=-\infty$$ Note that this implies that, for every nonnegative time $s$ and real number $x$, the sets of times $\{t\geqslant s\mid X_t=x\}$, $\{t\geqslant s\mid X_t\geqslant x\}$ and $\{t\geqslant s\mid X_t\leqslant x\}$ are all almost surely unbounded. 4. The process $X$ is (most probably) not Markov. We did not write a full proof of this but the idea is that considering a (many-to-one) functional of a Markov process (these are often called hidden Markov models) usually destroys the Markov property. But one should beware that counterexamples exist, for example, $|B'|$ is Markov... So, to begin with a precise question: What would be a simple argument that $X$ is not a Markov process?","['stochastic-processes', 'probability-theory', 'hidden-markov-models', 'markov-process', 'brownian-motion']"
2308259,Proof of: $\int_0^\infty x^{m-1}e^{-ax} \cos bx \ dx = \frac{\Gamma(m)}{(a^{2} + b^{2})^{m/2}}\cos\left(m\tan^{-1}\left(\frac{b}{a}\right)\right)$,"Where can I find a proof or how do you prove the following: 
$$\int_0^\infty x^{m-1}e^{-ax} \cos bx  \ dx = \frac{\Gamma(m)}{(a^{2} + b^{2})^{m/2}}\cos\left(m\tan^{-1}\left(\frac{b}{a}\right)\right)$$ Edit: 
I think I see the identity now
For a cascade of integration by parts let
$$\int e^{-ax}\sin(bx)=\frac{1}{a^2+b^2}e^{-ax}(-a\sin(bx)-b\cos(bx))$$
$$\int e^{-ax}\cos(bx)dx=\frac{1}{a^2+b^2}e^{-ax}(b\sin(bx)-a\cos(bx))$$",['calculus']
2308311,$\frac1{2\pi\rho^n}\int_{-\pi}^{\pi}\exp\left(\frac{2+\rho\cos\theta}{4+4\rho\cos\theta+\rho^2}\right)\cos\beta_nd\theta$ does not depend on $\rho$.,Let $$\beta_n=\frac{\rho\sin\theta}{4+4\rho\cos\theta+\rho^2}+n\theta$$ where $0<\rho<2$. Could anyone give me some hints to prove analytically that $$\frac1{2\pi\rho^n}\int_{-\pi}^{\pi}\exp\left(\frac{2+\rho\cos\theta}{4+4\rho\cos\theta+\rho^2}\right)\cos\beta_nd\theta$$ does not depend on $\rho$?,"['real-analysis', 'trigonometry', 'calculus', 'multivariable-calculus', 'complex-analysis']"
2308326,Are $<$ and $\leqq$ acceptable symbols to use for a strict weak ordering and its associated total preorder?,"Exercise 1.1 in Davey & Priestley, Introduction to Lattices and Order (1st edition) reads: Let $P$ be a set on which a binary relation $<$ is defined such that, for all $x, y, z \in P,$ (a) $x < x$ is false, (b) $x < y$ and $y < z$ imply $x < z.$ Prove that if $\leqslant$ is defined by $$x \leqslant y \iff (x < y \text{ or } x = y),$$
  then $\leqslant$ is an order on $P,$ and moreover every order on $P$ arises from a relation $<$ on $P$ satisfying (a) and (b). [A binary relation satisfying (a) and (b) is called a strict order .] A strict weak ordering on $P$ satisfies (a) and (b) together with: (c) If $x < z$ then ($x < y$ or $y < z$). I wish to define the associated total preorder on $P$ by: $$x \leqq y \iff\lnot(y < x),$$ and the associated equivalence relation on $P$ by: $$x \cong y \iff\lnot(x < y \text{ or } y < x) \iff (x \leqq y \text{ and } y \leqq x).$$ (This is because I prefer to avoid the ugly use of ""wavy"" symbols such as $\lesssim$.) But might my proposed use of notation be confusing, even though it avoids the confusion that would certainly result - at least if Davey & Priestley's book is anything to go by - from the use of $\leqslant$ or $\leq$?","['order-theory', 'notation', 'elementary-set-theory']"
2308336,finite dimensional function space,"I'm studying Arzela-Ascoli (particularly as a generalization of Bolzano-Weierstrass) and am wondering how to think of functions as generalizations of points in $\mathbb{R}^k$. Specifically, I'm looking for intuition motivated by basic linear algebra ideas (bases, relations between different dimensions of the space). So if I'm building toward understanding infinite dimensional function spaces, can you first describe how we move from $\mathbb{R}^k$ to finite dimensional function spaces as an intermediate step (particularly emphasizing the role of equicontinuity)?","['functional-analysis', 'linear-algebra']"
2308364,Unable to proceed with this limit [duplicate],"This question already has answers here : Limit as $x$ approaches $0$ for a function. (3 answers) Closed 3 months ago . Find the limit $$\lim_{\alpha\to0}\frac{\sin(\alpha ^n)}{(\sin\alpha)^m}$$ (m and n are positive integers) What I've tried so far-
$$\frac{\sin(\alpha ^n)}{\alpha^n}\frac{\alpha^n}{\frac{(\sin\alpha)^m\alpha^m}{\alpha^m}}$$ $$\lim_{\alpha\to0}\frac{\alpha^n}{\alpha^m}$$","['functions', 'calculus', 'limits']"
2308368,Sphere on top of a cone. Maximum volume?,"I received an interesting problem which I can not figure how to solve. It follows: An ice cream has the shape of a sphere and a cone like the image below. What is the maximum volume that the sphere can occupy out of the cone? Note that $M$ is the center of the sphere, not the center of the circle of the base of the cone. I hope you understand my phrasing. A rephrasing of the problem statement would be, I believe: Say you have an arbitrary cone, and you are going to place a sphere on it with radius $r$, what is the maximum volume of the cone the sphere can occupy, provided some part of the sphere-cap is allowed to be above the circular cone base? This is my drawing of the problem: Attempt so far: I know that $\bigtriangleup AEM\sim\bigtriangleup ACG$. Denote $AM=x$, $GH=h$, then $GM=h-r.$ By the Pythagoran theorem on $\bigtriangleup ACG$ I get that $$AC=\sqrt{(x+h-r)^2+R^2}.$$ Since $R/AC=k$ is a constant, by similar triangles I obtain $$\frac{r}{x}=\frac{R}{AC}=k \Leftrightarrow r=kx$$ The volume of the cone is $$V_{cone}=\frac{R^2\pi(x+h-r)}{3}=\frac{R^2\pi(x+h-kx)}{3}.$$ Using the formula for a spherical cap , I get that the volume of the sphere that is below the cone base is $$V_{s.cap}=\frac{\pi h^2(3r-h)}{3}.$$ Thus the ratio is $$f(x)=\frac{V_{s.cap}}{V_{cone}}=\frac{\frac{\pi h^2(3r-h)}{3}}{\frac{R^2\pi(x+h-kx)}{3}} = \frac{h^2(3r-h)}{R^2(h+(1-k)x)}.$$ But this does not work.","['calculus', 'geometry']"
2308400,Is the L2 norm always positive?,"Is $$\int_{a}^{b} u^2(x,t) \, dx \, , \,\, 0\le t \le T$$ defined as the $L^2$-norm: $$|| u^2||_{2,[a,b]}^{2} $$ Always positive (or equal to zero)? If not what restrictions do I need to make it so? Or does that just depend on the function $u$","['multivariable-calculus', 'normed-spaces', 'real-analysis', 'fluid-dynamics']"
2308409,Operational details (Implementation) of Kneser's method of fractional iteration of function $\exp(x)$?,"For a long time (a couple of years) I'm following the Q&A's about ""half-iterate of $\exp(x)$"" etc. where there exists a $\mathbb C \to \mathbb C$ due to Schröder's method, but also a $\mathbb R \to \mathbb R$ for fractional heights $h$ due to Hellmuth Kneser. I would like to understand the latter method of Kneser; after reading of several papers (including the original one of Kneser) I still have no real clue how this is done.(See some explanations for instance Tetration-forum thread 1 thread 2 ) One menetekel for me is the so-called ""Riemann-mapping"" for which I find on many places proofs (that it exists) but no idea how to practically implement this for such a case like iteration of the $\exp()$-function (for instance citizendium , and the linked article). Could someone step in and explain that Kneser method in detail? (Note that there seem to be an asymptotic approximation of the Kneser's results using square-roots of the Carleman-matrix for the $\exp()$ )","['riemann-surfaces', 'complex-analysis', 'function-and-relation-composition', 'tetration']"
2308416,What's the probability of getting 1000 heads in a row?,"I'm reading The Master Algorithm by Pedro Domingos and I'm having a hard time understanding something he wrote on page 74: ""If you do a million runs of a thousand coin flips, it's practically certain that at least one run will come up all heads."" My intuition tells me this is false. My understanding of probability would indicate that the chance of encountering $1000$ heads in a row after trying $1000000$ times is: $$\frac{1}{2^{1000}} *1000000$$ which is minuscule and hardly ""practically certain."" Is my understanding correct, or am I missing something?",['probability']
2308428,Number of $5$-letter words that use letters from a $4$-letter set in which exactly one letter is missing,"This is a fairly straightforward problem. We can break this problem into $4$ cases: the words that don't contain either of $A, B, C, D$. For example, the words that don't contain $D$ are $AAABC, ABBCC,\ldots$ There are $3 \cdot \binom{5}{1, 2, 2} + 3 \cdot \binom{5}{1, 3, 1} = 150$ of those. In total there are $4 \cdot 150 = 600$ words with the given property. I am supposed to solve this problem using the formula $N_1 = |X| + |Y| + |Z| - 2|X \cap Y| +3|X \cap Y \cap Z|$. The answer is supposed to be $972 - 384 + 12 = 600.$ I'd like to see how they came up with that. But I am having difficulty defining $X, Y, Z.$ I'd be thankful if someone could explain how they defined these sets. edit: I guessed the formula from the answer so the actual formula they have used might have been different. I think I made a mistake there. edit 1: the actual formula might have been either of $|X| + |Y| + |Z| - 2(|X \cap Y| + |X \cap Z| + |Y \cap Z| + 3(|X \cap Y \cap Z|)$ $|X| + |Y| + |Z| + |W| - 2(|X \cap Y| + |X \cap Z| + |X \cap W| + |Y \cap W| + |Y \cap Z| + |Z \cap W|) + 3(|X \cap Y \cap Z| + |X \cap Y \cap W| + |Y \cap Z \cap W| + |X \cap Z \cap W|) – 4(|X \cap Y \cap Z \cap W|)$","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
2308431,Where am I making a mistake in following delta function integral?,"If the given integral is $$\int_{-\infty}^{+\infty} dx \delta (x-x^{'})f(x)$$ The answer is $f(x')$. However if we make a transformation$$x\rightarrow\alpha x=y$$and $$x^{'}\rightarrow\alpha x^{'}=y^{'}$$ substituting this into the above equation I get$$\alpha dx= dy$$ so the integral becomes, $$\frac{1}{\alpha}\int dy \delta (\frac{y}{\alpha}-\frac{y^{'}}{\alpha})f(\frac{y}{\alpha} )$$ Hence the answer is $$\frac{1}{\alpha}f(\frac{y^{'}}{\alpha})$$ If we go back to the old variables $x$ by making an inverse transformation $$y^{'}=\alpha x^{'}$$ I am getting $$\frac{1}{\alpha}f(x^{'})$$ However the solution is not just $$f(x^{'})$$
Where am I going wrong in the following transformation ?","['dirac-delta', 'distribution-theory', 'real-analysis', 'integration']"
2308507,Equivalent way to write existential quantifier?,"Let $L(x,y)$ be the statement, ""$x$ loves $y$."" If the universe U is the set of all people, can the statement, ""There is exactly one person whom everybody loves."" or, equivalently (according to my textbook):     $∃x[∀y(L(y,x))  ∧  ∀z(∀y(L(y,z) → z=x)]$ be written as (my answer): [($∃x∀yL(y,x)) ∧ (∀z∃y¬L(y,z))]     \mbox∣~  x≠z, z∈U$     ? The original statement is the answer from my textbook, which I think seems pretty weird.  That's why I'm trying to rewrite it. So, if my answer is not a 'better' way to write ""There is exactly one person whom everybody loves."", what is the most logical way to write this statement?","['quantifiers', 'logic', 'discrete-mathematics']"
2308528,Where is the sine function transcendental? [duplicate],"This question already has answers here : When is $\sin x$ an algebraic number and when is it non-algebraic? (2 answers) Closed 7 years ago . Most if the the values of the sine function that I am familiar with are irrational, like $\sin(\pi/3)$ or $\sin(\pi/6)$, or even rational like $\sin(\pi)$ or $\sin(0)$.
Surely the sine function must give transcendental values somewhere, so my question is this: is there a way to determine whether the sine function will be transcendental or not? And if so, how?","['trigonometry', 'transcendental-numbers']"
2308532,Prove the series $\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}}$ converge,"How to prove this serie $$\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}}$$ converge? I can't do a comparison test with the Leibniz formula for $\pi$ because the series are not $>0$ for all $n$. I can't do a ratio test because I can't compute the limit, the alternating series test can't be applied, the absolute serie is not convergent. I'm out of ideas. Any clues?","['convergence-divergence', 'sequences-and-series', 'calculus']"
2308602,Integration of $\frac{1}{x\ln(x)}$ by parts,"I tried to solve $\int \frac{dx}{x\ln(x)}$ by parts. I have done it as usual:
$$\int \frac{dx}{x\ln(x)}=\begin{bmatrix}
f(x)=\frac{1}{\ln x} & g'(x)=\frac{1}{x}\\ 
f'(x)=-\frac{1}{x\ln^2x} & g(x)=\ln x
\end{bmatrix} = \frac{1}{\ln x} \ln x - \int \left(-\frac{1}{x\ln^2x}\ln x\right)dx=$$ 
$$
=1+\int \left(\frac{dx}{x\ln x}\right)
$$ 
So, taking most left and right part we get:
$$
\int \frac{dx}{x\ln(x)}=1+\int \left(\frac{dx}{x\ln x}\right)
$$
By subtracting integral from both sides, we get:
$$
0=1
$$
I know that $\int \frac{dx}{x\ln(x)}=\ln(\ln x)+C$. However, I often use integration by parts and I wonder what is wrong here, and what should I do to avoid it (here it's plainly wrong, but what if the mistake was more subtle?). I guess may be something connected with constants, but I used to add them at the very end(wrongly?).","['indefinite-integrals', 'integration', 'calculus']"
2308610,"If $(a_n)$ is any real sequence , then $(\frac{a_n}{1+|a_n|})$ has a convergent subsequence","Consider the following two statements : $S_1$: If $(a_n)$ is any real sequence , then $(\frac{a_n}{1+|a_n|})$ has a convergent subsequence . $S_2$ : If every subseqeunce of $(a_n) $ has convergent subsequence , then $(a_n)$ is bounded . Which is of the follwoing statement is true ? (A) Both $S_1$ and $S_2$ are true . (B) Both $S_1$ and $S_2$ are false . (c) $S_1 $ is false but $S_2$ is true . (D) $S_2$ is false and $S_1$ is true . My work : $1+|a_n|\geq 1+a_n>a_n$ . So $|(\frac{a_n}{1+|a_n|})|\leq 1$
. So it is a bounded sequence and via Bolzano-wietrass theorem it has a convergent subsequence . $a_{2n}$ and $a_{2n-1}$ are convergent . So they are bounded . Let the bounds be $M $ and $L$ respectively . Hence $a_n \leq M+L $ .So $a_n$ is bounded . So both $S_1$ and $S_2$ are true .","['real-analysis', 'proof-verification', 'calculus', 'sequences-and-series', 'analysis']"
2308676,Finding solutions of $Ax(t)= x'(t)$ by linear algebra,"Consider a system of $n$ first-order homogenous differential equations with real coefficients. We can write solutions in vector form: $Ax(t)= x'(t)$ where $A$ is the $n \times n$ coefficient matrix. Suppose $\lambda$ is an eigenvalue of $A$ with $\dim E_\lambda =1$ and the algebraic multiplicity of $\lambda$ equal to $2$. Let's guess that $y(t) =te^{\lambda t}u +e^{\lambda t}v$ is a solution to the system. I am asked to show that $u$ is an eigenvector of $A$ corresponding to $\lambda$ and that $v$ satisfies $(A-\lambda I)v=u$. Then I am asked to show that it's possible to solve for $v$. I know that $\dim G_\lambda =2$, where $G_\lambda$ is the generalized eigenspace of $A$ corresponding to $\lambda$. But I really have no idea how to proceed. (Even the wording of the problem confuses me.) I would appreciate some help understanding how to prove what I want.","['ordinary-differential-equations', 'linear-algebra']"
2308690,How can I prove this equality and general derivative?,"$$ f_{n}(x) = \underbrace{\sqrt{x+\sqrt{x+ ...+ \sqrt{x}}}}_{n}  \quad \quad \lim_{n\to\infty} \sum^{n}_{r=1}\frac{1}{2^{r}}\prod^{r-1}_{i=0}\frac{1}{f_{n-i}(x)} = \frac{1}{2f_{\infty}(x)-1} $$ I produced the left hand side by examining the pattern of the derivatives of $\, f_{n}(x)$ and the right hand side by using the property of $\, f_{\infty}(x)$ that: $\, f_{\infty}(x)=\sqrt{x + f_{\infty}(x)}$ and differentiating. I have no idea how to prove such a thing, nor do I know how to prove the general formula of the derivate (EDIT: I have now proved the general formula of the derivative but am still stumped by the limit problem!): $$_{m}f_{n}(x) = \underbrace{\sqrt[m]{x+\sqrt[m]{x+ ... + \sqrt[m]{x}}}}_{n}  \quad \quad
_{m}f_{n}'(x) = \sum^{n}_{r=1}\frac{1}{m^{r}} \prod^{r-1}_{i=0} (f_{n-i}(x))^{1-m}$$ Obviously given my second formula,  I could generalise the first equality but, I thought the case $m=2$ came out quite nicely. One last thing, is there any nicer notation I can use for the function rather than writing it out with the underbrace and whatnot? Edit: Just realised I didn't mention it at all in the original post, the right-hand side is the infinite sum of a geometric progression: $$\sum^{\infty}_{r=1}\bigg(\frac{1}{2f_{\infty}(x)}\bigg)^{r} = \frac{1}{2f_{\infty}(x)-1} $$ So the question can be rephrased as proving: $$\lim_{n\to\infty} \sum^{n}_{r=1}\frac{1}{2^{r}}\prod^{r-1}_{i=0}\frac{1}{f_{n-i}(x)} = \sum^{\infty}_{r=1}\bigg(\frac{1}{2f_{\infty}(x)}\bigg)^{r}$$ Which seems intuitively true but, I do not know how to prove it rigorously.","['limits', 'functions', 'calculus', 'infinity', 'nested-radicals']"
2308691,Maximal ideal contained in an ideal,"There is probably a simple answer to this but I can't for the life of me figure it out. Every ring in this question has a unit but isn't necessarily commutative. Let $R$ be a ring and let $I$ be a left ideal of $R$. In Basic Algebra II , Jacobson defines
$$(I:R)=\{ b \in R \mid bR \subseteq I\}.$$
This is an ideal because it equals, $\text{ann}_R R/I$, the annihilator of the left $R$-module $R/I$. Because $R$ has a $1$ it follows that $(I:R)$ is contained in $I$. The author goes on to claim that $(I:R)$ contains every left ideal of $R$ properly contained in $I$, but I'm not seeing it. If $J$ is a left ideal of $R$ contained in $I$ why should it be that $J \subseteq (I:R)$? The ""obvious"" thing would be to say that that since $J$ is an ideal $JR \subseteq J \subseteq I$, but the rings here aren't necessarily commutative and $J$ is only a left ideal so this doesn't work. Is there any sort of reason this actually works given that $J$ is properly contained in $I$?","['abstract-algebra', 'ring-theory', 'ideals']"
2308709,Show that the derivative of this function is positive,"Suppose that $n>1$, $g\in(0,1)$ and $f(g)\in(0,1)$. Suppose that 
  $\frac{df(g)}{dg}\geq0$. Define $B(g,n)$ as: $B(g,n)=\sum _{k=1}^n \frac{n!}{k!(n-k)!}g^{n-k}(1-g)^{k-1}(1-(1-f(g))^k)$ Show that: $\frac{dB(g,n)}{dg}>0$. Some of these assumptions can be relaxed (for example the $\frac{df(g)}{dg}\geq0$ I suspect), but I am not especially interested in that. What I have done: I have shown that this is the case for $n=2$, $n=3$ and $n=4$, but did not find any pattern that helped me generalize to $n$. I took the derivative with Mathematica and obtained that little monster:
$
\frac{dB(g,n)}{dg}=-\frac{g^n \left(-n \left(\frac{(g-1) f(g)+1}{g}\right)^{n-1} \left(\frac{(g-1) f'(g)+f(g)}{g}-\frac{(g-1) f(g)+1}{g^2}\right)-n \left(\frac{1}{g}\right)^{n+1}\right)}{g-1}-\frac{n g^{n-1} \left(\left(\frac{1}{g}\right)^n-\left(\frac{(g-1) f(g)+1}{g}\right)^n\right)}{g-1}+\frac{g^n \left(\left(\frac{1}{g}\right)^n-\left(\frac{(g-1) f(g)+1}{g}\right)^n\right)}{(g-1)^2}$. (Here I might be wrong) I think that the problem can be slightly simplified by assuming that $\frac{df(g)}{dg}=0$. Because assuming $\frac{df(g)}{dg}>0$ only ""helps us"" in proving the that the derivative is positive, then it suffices to show that our desired result holds when $\frac{df(g)}{dg}=0$. Thanks in advance!","['derivatives', 'real-analysis', 'binomial-distribution']"
2308728,Cohen-Macaulay/Gorenstein passing from associated graded to general fiber,Let $R$ be a filtered commutative ring over a field $k$. Let $A$ denote the Rees algebra and $A_0:=\operatorname{gr}_F(R)$ be the associated graded ring.  $\operatorname{Spec}(A)$ gives rise to a flat family over $\mathbb{A}^1$ with fiber over zero $\operatorname{Spec}(A_0)$ and general fiber $\operatorname{Spec}(R)$. Assume that $A$(and hence $R$ and $A_0$) is finitely generated. Question 1) Is it true that $\operatorname{Spec}(A_0)$ being Cohen-Macaulay implies that $\operatorname{Spec}(R)$ is Cohen-Macaulay? Question 2) Is there a nice condition for when $A_0$ being Gorenstein implies that $R$ is Gorenstein? How about in the case when the filtration is associated to some ideal I?,"['algebraic-geometry', 'commutative-algebra']"
2308748,When does a sequence of rotated-and-circumscribed rectangles converge to a square?,"Recently I came up with an algebra problem with a nice geometric representation. Basically, I would like to know what happens if we repeatedly circumscribe a rectangle by another rectangle which is rotated by $\alpha \in \left( 0, \frac {\pi} {4}\right)$ radians. Use this picture as reference: In particular, do the resulting rectangles converge to a square? It is rather easy to show that the rectangles do converge to a square if $\alpha$ is constant throughout the process. However, if we make it more general by defineing a sequence $\left(\alpha_n\right)_{n=1}^{\infty}$ of angles and use $\alpha_i$ in the $i$'th operation, then the answer seems to depend on the chosen sequence. So, for which sequences $\left(\alpha_n\right)_{n=1}^{\infty}$ do the rectangles converge to a square? Algebraically this problem can be defined like this: Define two real sequences by $A_0=a, B_0=b, a \neq b, a,b \in R_{\gt0}$ and $A_{n+1}=B_n\sin\alpha_n + A_n\cos\alpha_n, B_{n+1}=A_n\sin\alpha_n + B_n\cos\alpha_n \forall n \in N_{\gt 0}$, where $\alpha_i \in \left( 0, \frac {\pi} {4}\right) \forall i \in N_{\ge 0}$. Is it true that $\lim_{n \to \infty}\frac{A_n}{B_n}=1$? I tried out a few sequences in C++ to notice some patterns. Interestingly, rectangles seem to converge to a square if and only if $\lim_{n \to \infty} \left( \sum_{i=0}^n \alpha_i \right) = \infty$. In particular, for $\alpha_n = \frac{1}{n}$ the convergence is really slow, however, it still seems to be converging. Also, I believe that showing $\lim_{n \to \infty}\left(A_n-B_n\right)=1$ would be an even stronger result for this problem. Does such a replacement have any influence on the result? For the record, I am still a high school student, so I have no idea how hard this problem might actually be. Any help would be highly appreciated. P.S. This is my first question on the site, so please don't judge my wording and style too much. Feel free to ask questions if anything is unclear.","['sequences-and-series', 'convergence-divergence']"
2308756,Coordinate independent definition of Fisher metric on statistical manifolds,"Is there a manifestly coordinate independent definition of the Fisher metric? I was reading Methods of Information Geometry by Amari and Nagaoka and Information Geometry and Its Applications by Amari, and also searched the web. All I could find was the definition with respect to the basis $\partial_{i}\log{p}$. Also, I found it odd that $X^{i}\partial_{i}\log{p}$ are interpreted as vector fields despite not being differential operators. So, I thought about a possible treatment. What if we consider the vector fields of a statistical manifold to be just what the general definition states, with $\partial_{i} = \frac{\partial}{\partial \xi^{i}}$ as basis vectors and then define the Fisher metric to be $$g(U,V)=\int p(x) U(\log{p(x)})V(\log{p}(x))dx$$  where $U, V$ are vector fields and $\log{p(x)} : M \rightarrow R$ is a $C^{\infty}(M)$ mapping defined as $\log{p(x)}(\xi)=\log{p(x;\xi)}$. $g_{ij}$ is then the same as in the usual treatment. Has anyone seen this approach somewhere? It seems pretty straightforward to have not been done. Also, it connects better to differential geometry as we don't have to consider $X^{i}\partial_{i}\log{p}$ as vector fields despite not satisfying the definition.","['fisher-information', 'information-geometry', 'differential-geometry']"
2308758,Is $z^{-1}(e^z-1)$ surjective?,"Is the entire function $$
   f(z)=\frac{1}{z}(e^z-1)
$$
surjective? I tried to argue like in the question below, but it does not seem to work in a similar way. $z\exp(z)$ surjectivity with the Little Picard Theorem","['complex-analysis', 'complex-numbers']"
2308778,Where $x=y^d$ how do I express $d$?,"Given: $$
x = y^d
$$ How do I express $d$? I was tempted to think that $d$ is equal to the $y$ root of $x$ but that is false.",['algebra-precalculus']
2308811,Find all positive integers $n$ such that $3^n+5^n = x^3$,"Find all positive integers $n$ such that $3^n+5^n = x^3$ for some positive integer $x$. One solution is $n = 1, x = 2$. We have $1 < 3^n+5^n \leq 8^n$, so $1 < 3^n+5^n \leq 2^{3n}$. Thus $1 < x \leq 2^n$. How can we continue from here?",['number-theory']
2308818,Finding the PDF of a Second Order Statistic,"Suppose that $Y_1,Y_2 ~ i.i.d$ Expo(b) Find the pdf of the second order statistic, $U_2 =max(Y_1,Y_2)$ $F_{U_2}(u)= P(U_2<u) = P\{Max(Y_1,Y_2)<u\}= P(Y_1<u,Y_2<u)=P(Y_1<u)P(Y_2<u)= P(Y_1<u)^2 =(1-e^{-u/b})^2$ Then you do some differentiation and get the answer. The problem is that I am confused about how we go from $P\{Max(Y_1,Y_2)<u\}$ to $P(Y_1<u,Y_2<u)$ and from $P(Y_1<u)P(Y_2<u)$ to $P(Y_1<u)^2$ 
could someone please explain?","['probability-theory', 'probability-distributions', 'statistics', 'probability', 'order-statistics']"
2308843,show that $\sum_{i=1}^n i^2$ is $O(n^3)$,"To start, am I on the right track? $\sum_{i=1}^n i^2$ = $1^2 + 2^2 + 3^2 + ... + n^2 \le n^2 + n^2 + n^2 + ... + n^2$ Where would I go from here?","['asymptotics', 'discrete-mathematics']"
2308857,Show that $\lim_{n\to \infty}\cos\frac{a}{n\sqrt n}\cos\frac{2a}{n\sqrt n}\cdots \cos\frac{na}{n\sqrt n} = e^{-a^2/6}$ for any constant $a$,"For any constant $a$, find the value of $$\lim_{n\to \infty}\cos{\left(\frac{a}{n\sqrt{n}}\right)}\cos{\left(\frac{2a}{n\sqrt{n}}\right)} \dotsm \cos{\left(\frac{na}{n\sqrt{n}}\right)}$$ I figured out that limit of the sequence is $e^{-a^2/6}$    However, I still couldn't solve this question.. please help me I didn't know whether it would help or not, but it might relative to $\ln$ ..","['trigonometry', 'sequences-and-series', 'limits']"
2308901,Clarification on proof for the product form of a sum on a completely multiplicative function,"I am working my way through the theorem on ProofWiki , the theorem states the following: Let $f$ be a completely multiplicative arithmetic function. Let $\sum_{n=1}^{\infty} f(n)$ be absolutely convergent. Then: $$\sum_{n=1}^\infty f(n) = \prod_p \frac1{1-f(p)}$$ where $p$ ranges over the primes. In the proof of this, they begin by using the complete multiplicative property of $f$ to say: $f(p^k) = f(p)^k$ for all primes $p$ , which implies $f(p) < 1$ for all primes $p$ . I don't see the implication. Could anyone elaborate this for me? It is obvious that $f(p) < 1$ for all but finitely many primes, but this follows from the convergence of the series, not the multiplicative property. What am I missing? Thanks!","['number-theory', 'analytic-number-theory', 'functions']"
2308914,"in a geometric sequence, the second term is $\frac{-4}{5}$ sum of first three terms :$\frac{38}{25}$ . What is the first term?","In a geometric sequence, the second term is $\frac{-4}{5}$
    and the sum of the first three terms is $\frac{38}{25}$ . What is the value of the sequence's first term? for some reason I keep getting a decimal as my answer which I'm pretty sure it can't be because it was a math homework problem: My Steps if we call the first term to be the number $n$ and $r$ to be the multiplyer we have the following: $n+nr+nr^2=\frac{38}{25}$ and then we multiply r on both sides to get the following $nr+nr^2+nr^3=\frac{38r}{25}$ and then we substitute nr with $\frac{-4}{5}$ and we get the following: $\frac{-4}{5}+\frac{-4r}{5}+\frac{-4r^2}{5}=\frac{38r}{25}$ but then when solving for the number $r$ I do not get a pretty number and I am sure that I am making some sort of mistake. I was wondering what I was doing wrong? Also I understand that because this is a quadratic, I was wondering which ""answer"" to choose from the zero's?","['sequences-and-series', 'calculus']"
2308926,Poisson process and probabilities,"Let $\{X(t); t\ge 0\}$ be a Poisson process with rate $\lambda =2$. Find the probability $\Pr\{X(1)=1, X(2)=3\}$ And here is my solution: As there is a Poisson process then the intervals are independent random variables thus $\Pr\{X(1)=1, X(2)=3\}$=$\Pr\{X(1)=1\}$$\Pr\{ X(2)=3\}$=$\frac{2e^{-2}}{1!} \frac{[2(2)]^3e^{-4}}{3!} =\frac{e^{-6}4^3}{3}$ But the book's answer is $4e^{-4}$. I don't see where is my mistake.
Can someone tell me?","['stochastic-processes', 'statistics', 'probability', 'poisson-distribution']"
