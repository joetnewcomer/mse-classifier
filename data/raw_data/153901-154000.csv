question_id,title,body,tags
2592601,Characterization of sets of differentiability,"If $f : \mathbb{R} \to \mathbb{R}$, define $C(f) = \{ x : f \text{ is continuous at } x \}$ and $D(f) = \{ x : f \text{ is differentiable at } x \}$. I have seen it proved that: $C(f)$ is a $G_\delta$ set. For any $G_\delta$ set $A \subset \mathbb{R}$, there exists a function $f : \mathbb{R} \to \mathbb{R}$ such that $C(f)=A$. I suspect there is a related characterization for $D(f)$. I see that a related question was asked at Continuous functions are differentiable on a measurable set? , where the accepted answer implies that $D(f)$ is a $G_{\delta \sigma \delta}$ set. Is this optimal, that is, does there exist $f$ such that $D(f)$ is $G_{\delta \sigma \delta}$ and not $G_{\delta \sigma}$? If so, can an example be given? Conversely, given any $G_{\delta \sigma \delta}$ set $A \subset \mathbb{R}$, does there exist $f$ such that $D(f)=A$?",['real-analysis']
2592604,Determine the sum of $12 + 12 + 12 + \cdots + 12$ (there are n+1 terms) by using OGF,"I bet all of this problem viewers know that the answer is $12 (n+1)$, but it wants us to use ordinary generating function to calculate the summation. I try to change the series into sequence
$ (a_n) = (12, 24, 36, \cdots) $ 
and then substitute it to the P (x) as the OGF of the sequence,  which $a_n = 12 (n+1)$ and that is it the coefficient of $x^n$ is the sum of the series. But that seems doesn't right. 
So, do you have any idea?","['generating-functions', 'discrete-mathematics']"
2592611,"Neighbourhood of Linearly Independent Vector Fields $(X_1,\dots,X_n)$","Actually, this is a piece of some argument i need to prove some proposition. I've been thinking this all day so i hope someone can help me with this. Suppose that we have smooth vector fields $(X_1,\dots,X_n)$ defined on some open subset $U\subset M$. At a point $p \in U$ we know that $(X_1|_p,\dots,X_n|_p)$ are linear independent, hence basis for $T_pM$. Can i find some neighbourhood $V $of $p$ in $U$ such that the $(X_1,\dots,X_n)$ are linear independent for all points in $V$ ? My idea is to use the determinant argument. That at $p$ the determinant matrix with entries consist of components of $X_i$'s at $p$, that is $det (X_1|_p,\dots,X_n|_p) = det (X^i_j(p))$ is not zero, so we have an open neighbourhood of $p$ such that $X_1,\dots,X_n$ are l.i there. Is this correct ? Any other idea to find such neighbourhood ? Thank you. $\textbf{Update : }$ After a while, i think this is true. This also can be proved using contradiction too. Pretty much by the same route. Only this time we assume on the contrary that, there is no such neighbourhood for $p$ and then deriving a contradiction. $\textbf{Proof }$ : Suppose $M$ is an $n$-dimensional smooth manifold and $(X_1,\dots,X_n)$ are smooth vector fields defined on some open subset $U\subseteq M$ such that for a point $p \in U$, $X_1(p),\dots,X_n(p)$ are linearly independent. We claim that there are no neighbourhood $V$ of $p$ such that for any point $x \in V$, then vectors $X_1(x),\dots,X_n(x)$ are linearly independent. Stated it differently, every neighbourhood of $p$ contain a point where the vectors $X_i$ are linearly dependent. This will lead to contradiction as follows : Choose a  smooth charts $(U',x^i)$ contain $p$. By shrinking $U'$, assume that $U'\subseteq U$. In this chart, the value of vector fields $X_i$ at any point $x \in U'$ is
$$
X_i(x) = X_i^j(x) \frac{\partial}{\partial x^j}\bigg|_x.
$$ Define a map from $m : U' \to M(n\times n,\mathbb{R} )$  defined by 
$$
m : x \mapsto 
\begin{pmatrix}
    X_1^1(x) & \cdots & X_n^1(x) \\
    \vdots & \ddots & \vdots \\
    X_1^n(x) & \cdots & X_n^n(x)
\end{pmatrix} \in M(n\times n,\mathbb{R} ).
$$
This is a smooth map since the entries are smooth functions on $U'$. By composing this with determinant map $\text{det} : M(n\times n, \mathbb{R}) \to \mathbb{R}$, we have a smooth function $f = \text{det} \circ m : U' \to \mathbb{R}$. This function is also smooth and at $p \in U'$, $f(p) \neq 0$ since $X_1(p),\dots,X_n(p)$ are linearly independent vectors. Now, by assumption, any neighbourhood $V_1 \subseteq U'$ of $p$ contain a point $p_1$ such that $X_1(p_1),\cdots,X_n(p_1)$ are linearly dependent. Therefore $f(p_1) = 0$. By doing this repeatly, we have a sequence $(p_k)_{k=1}^{\infty}$ in $U'$ converging to $p$ such that $f(p_k) =0$ for all $k$. Since $f$ is smooth (hence continous), then as $p_k \to p$, then $f(p_k) \to f(p)$. But this is not happen since $f(p_k)= 0$ is a constant sequence and $f(p) \neq 0$. Therefore $f$ is not continous. Contradiction.","['vector-fields', 'smooth-manifolds', 'differential-geometry']"
2592612,Advanced Integral Regarding Logarithmic Functions,"I have been trying to solve this integral to face varying success: [The Original Problem]$$\int_{0}^{1/4}\frac{1}{x\sqrt{1-4x}}\ln\left(\frac{1+\sqrt{1-4x}}{2\sqrt{1-4x}}\right)dx$$ Although I could reduce the integral down to $$\int_{0}^12\frac{\ln(1+u)-\ln(2u)}{1-u^2}du$$ I could not expand the denominator in a geometric series, and I have tried some alternatives to little success.","['integration', 'calculus']"
2592624,Connection compatible with a volume form,"Let $M$ be a smooth, orientable $n$-manifold and $\eta$ a volume form on $M$. Does there exist a connection $A$ on $TM$ such that 
$$\tag{$*$}D\eta=0,$$
where $D$ is the appropriate covariant derivative associated to $A$ on $\Omega^n(M)$? Can one assume $A$ to be symmetric? I have a feeling that if one writes $(*)$ plus the torsion equation and then applies the Frobenius theorem, some local result can be obtained. But that doesn't give global conditions (on $M$ nor $\eta$). A reasonable assumption would be $M$ parallelizable.","['riemannian-geometry', 'differential-geometry']"
2592699,Something strange about prime gaps and $p-q =999999999999182774421592902$,"Coming across the post First 100s place without a prime , I went to the informative link "" First occurrence prime gaps "" suggested by Jack D'Aurizio. The main list of $999$ prime $p$  covers the smallest $p$ for each even gap $\leq1998$. I. But I noticed something a bit strange. Let $p,q$ be primes in the list. Example 1 . Given $p,q$ such that the next prime is $p+1886$ and $q+1902$, $$p=4521777371028957272039263763\\q=3521777371029774497617670861\\p-q =999999999999182774421592902$$ Example 2 . Given $p,q$ such that the next prime is $p+1896$ and $q+1968$, $$p=17817006514740891827868262213 \\q=16817006514738017659250207459 \\p-q =1000000000002874168618054754$$ Example 3 . Given $p,q$ such that the next prime is $p+1774$ and $q+1818$, $$p=161023337028376633976274427 \\q=361023337029228675738125911\\|p-q| =200000000000852041761851484$$ and so on. Given two random primes $p_1,p_2$ of about the same size but not in the list , what are the odds that their difference will be similar to the examples above? But $p,q$ are NOT random: they are the smallest primes for two given gaps. Quite a lot of the $999$ primes in the list can be paired in such a manner, if they are about the same size. I have chosen only the most spectacular. Q1: What is the reason for such behavior, the zeros and nines? II. Some primes in the list do need not a difference, the zeros are in the prime. $$\begin{array}{|c|l|} 
\hline
\text{Gap} & \hskip0.9in \text{Prime}\\
\hline
1832 & {7500230000000254312587886349}\\
1836 & {7500230000004410741095419811}\\
1838 & 7051230000020674054592576303\\
1846 & {7500230000005824418875087691}\\
1848 & 2644230000031218882264673171\\
1856 & 5851230000021967795781669357\\
1882 & 8511230000017373935165665319\\
1884 & 5844230000028765302725127593\\
1888 & {7500230000005019060037933673}\\
1920 & 2844230000030892453360363713\\
1944 & 3044230000030128405583745033\\
1980 & 8051230000019922137852468729\\
1982 & {7500230000011523034496281371}\\
1996 & 85982514713000000005643994785767\\
\hline\end{array}$$ Q2: What is the reason for that as well?","['number-theory', 'prime-gaps', 'prime-numbers']"
2592705,Proving weak convergence without Vitali's convergence theorem.,"Problem: Let $(f_{n})_{n=1}^{\infty}$ be sequence in $L^{2}([0,1])$ such that uniformly bounded, i.e., $\sup_{n \in \mathbb{N}}||f_{n}||_{L^{2}} =M < +\infty$ and $f_{n} \to f$ in measure. Then show that $f_{n} \to f$ weakly in $L^{2}$. I think I solve this problem without using Vitali's convergence theorem, however, hint of this problem says use the Vitali's theorem. Could you check that my attempt is okay? Please let me know this argument is right or wrong. My attempt: Since $L^{2}$ is reflexive (actually Hilbert space), it suffices to show that $\forall g \in L^{2}$, $\int f_{n}g \to \int fg$ as $n \to \infty$. Let $f_{n_{j}}$ be any subsequence of $f_{n}$. Then it also coverges in measure. So it has a subsequence $f_{n_{j_{k}}}$ converges to $f$ pointwise a.e. Also, by the Holder's inequality,
  $$ \int|f_{n_{j_{k}}}g| \leq ||f_{n_{j_{k}}}||_{L^{2}}||g||_{L^{2}} \leq M||g||_{L^{2}} < +\infty. $$
  Hence, by the Dominated Convergence theorem, $\lim_{k \to \infty}\int f_{n_{j_{k}}}g = \int fg.$ This shows that every subsequence of  $\int f_{n}g$ has convergent sub-subsequence to $\int fg$. Hence, $f_{n} \to f$ weakly in $L^{2}$.","['functional-analysis', 'real-analysis', 'lp-spaces']"
2592728,What are the applications of sequence of functions?,"This might be a ""silly"" question, but before starting my studies, I need a motivation. In Analysis books, there are the subjects such as ""sequence of functions, uniform convergence etc."" which deals with basically the sequence of functions, but up to now [I'm a 2. year physics & mathematics student], I haven't seen any real application of the concept of sequence of functions. I mean, for example, I have seen lots of application of sequences in defining continuity, compactness etc. (our instructor does the whole analysis based on sequences), but this is not the case for the sequence of function. Therefore, my question is that what are the applications of the concept of ""sequence of function"" in both mathematics and physics ?","['complex-analysis', 'real-analysis', 'sequences-and-series', 'uniform-convergence']"
2592748,How many ways to roll n with any number of dice,"For example, if I want to roll n=6, with 1 die it can be thrown in $$\binom {5} {0} = 1$$ way, with
2 dice $$\binom {5} {1} = 5$$ 
3 dice $$\binom {5} {2} = 10$$ 
4 dice $$\binom {5} {3} = 10$$ 
5 dice $$\binom {5} {4} = 5$$ 
6 dice $$\binom {5} {5} = 1$$ 
The sum of these is 32 - the correct answer, I believe. I thought that the answer for any number n (where the number of dice is d) is
$$\sum_{d=1}^{d=n} \binom {n-1} {d-1}$$
It seems that this isn't working, though. For example the correct answer for n=8 is 125, but this equation gives me 128. Where am I going wrong? Thanks in advance.","['combinatorics', 'binomial-coefficients', 'dice']"
2592753,"Bijective proof that $8+1=9$, or really $3^2-1=2^3$","Catalan's conjecture states that $8$ and $9$ are the only consecutive powers. This suggests to me that the identity $3^2-1=2^3$ might be purely ""accidental"". So here's the challenge: Is there any natural bijection between a set of $3^2-1$ things and a set of $2^3$ things? As examples of what I'm looking for, here are some structures that don't seem to work: The field $\mathbb F_9$ has $3^2-1$ nonzero elements. They form a group isomorphic to $\mathbb Z/8\mathbb Z$. If this group were isomorphic to $(\mathbb Z/2\mathbb Z)^3$ instead, it would be a good answer. Gluons , which carry the force between $SU(3)$-charged particles, come in $3^2-1$ colors. I don't know how to see that there are $2^3$ of them. Is there a better example, along the same lines, that witnesses $3^2-1=2^3$ or $2^3+1=3^2$?","['combinatorial-proofs', 'number-theory', 'representation-theory', 'combinatorics', 'combinatorial-number-theory']"
2592755,Do All Conic Sections come with a natural Arithmetic?,"I was looking to classify non trivial, commutative, associative, group structures on $\mathbb{R}$ (minus a countable number of point) starting with the trivial ones $$ (\mathbb{R} , + )$$ 
$$ (\mathbb{R} - \lbrace 0 \rbrace, \times)  $$
and then came across the following operation $$ \mu (a,b ) = a + b + ab $$ $\mu$ is commutative, associative, has identity $0$, and every element is invertible with $a^{-1_\mu} = - \frac{a}{1+a}$ $$ (\mathbb{R} - \lbrace -1 \rbrace , \mu) $$ Then also forms a group. I then noticed the following rather odd observation: $$ x  +y = 0 $$
$$ xy = 1$$
$$ x + y + xy = 0$$ All form hyperbolas (the first being a degenerate case) when graphed as implicit relations. And that got me wondering, does every hyperbola come equipped with a natural arithmetic (and given that all ellipses are complex hyperbolas) do all non-parabolic conic sections come equipped with a natural arithmetic?",['algebraic-geometry']
2592762,Differentiation of the Newtonian potential of a function (Sandro Salsa's PDE book),"I am studying the PDE book Partial Differential Equations in Action, From Modelling to Theory , by Sandro Salsa. I would like to ask two questions about the differentiation of the Newtonian potential of a function $f$,
$$ u(x)=\int_{\mathbb{R}^3} \Phi(x-y) f(y)\,\mathrm{d}y=(\Phi\ast f)(x), $$
where $$\Phi(x)=\frac{1}{4\pi}\frac{1}{|x|}$$ is the fundamental solution of the Poisson equation $-\Delta u=\delta_0$. In a footnote in page 130, it is stated the following: if $g\in C^1(\mathbb{R}^3)$ and $|g(x)|\leq M/|x|^{2+\epsilon}$, then 
$$ \frac{\partial}{\partial x_j}\int_{\mathbb{R}^3}\frac{1}{|x-y|}g(y)\,\mathrm{d}y=\int_{\mathbb{R}^3}\frac{1}{|x-y|}\frac{\partial g}{\partial y_j}(y)\,\mathrm{d}y. $$
Usually, results on differentiation under the integral sign requiere bounds on the derivative, so that the Dominated Convergence Theorem can be applied. I do not know how to proceed in this case. In Theorem 3.9, it is said that if $f\in C_c^2(\mathbb{R}^3)$ (i.e., $C^2$ with compact support), then its Newtonian potential $u=\Phi\ast f$ is $C^2(\mathbb{R}^3)$ and $-\Delta u=f$. The fact that $f$ is $0$ outside a ball and $1/|x|$ is locally integrable allows differentiating under the integral sign. But, in Remark 3.6, it is said that the theorem holds when $f\in C^1(\mathbb{R}^3)$ and $|f(x)|\leq M/|x|^{2+\epsilon}$. Any idea or reference on why this statement is true?","['poissons-equation', 'partial-differential-equations', 'convolution', 'lebesgue-integral', 'analysis']"
2592845,Show that $\bigcup\limits_{n=1}^\infty A_n \in \mathcal{A}$.,"Exercise: Let $\lambda$ be the Lebesgue measure restricted to measure space $((a,b],\mathcal{B}(a,b])$, called $S$. Let $\mathcal{F}_{(a,b]}$ be the collection of finite unions of half-open intervals in $S$. Let $$\mathcal{A} = \{A\in\mathcal{B}((a,b]):\forall\epsilon >0\exists F\in \mathcal{F_{(a,b]}\text{ such that }\lambda(A\triangle F)<\epsilon\}}$$ Assume that $(A_n)_{n\geq 1}$ is a disjoint sequence in $\mathcal{A}$. Use the fact that if $\bigcup\limits_{n=1}^\infty A_n = A$ and $\bigcup\limits_{n=1}^\infty B_n=B$ then $A\triangle B \subseteq \bigcup\limits_{n=1}^\infty (A_n \triangle B_n)$, to show that $\bigcup\limits_{n=1}^\infty A_n \in \mathcal{A}$. Question: How do I solve this exercise? Isn't it trivial that $\bigcup\limits_{n=1}^\infty A_n \in \mathcal{A}$, if $(A_n)_{n\geq 1}$ is a disjoint sequence in $\mathcal{A}$? Thanks in advance!","['borel-sets', 'elementary-set-theory']"
2592895,What is the 'Algebraic' Dimension of $l^2(\mathbb{N})$?,"Let  $l^2(\mathbb{N})$ be the space of all complex sequences that are square-summable. Clearly this is a Hilbert space, and it has a maximal orthonormal system which is equipotent to $\mathbb{N}$. Hence, its 'Hilbert dimension' is $\aleph_0$ (please tell me if other termiology is used). But what is the 'algebraic' dimension of this space? That is, what is the cardinality of its Hamel basis? Is there a way to compute it using only cardinal arithmetic, or does one have to know much more about its algebraic structure? I was reading this article explaining Halmos' counterexample of an inner product space NOT having any complete, orthonormal subset. It is stated there (implicitly, I guess) that the algebraic dimension of $l^2(\mathbb{N})$ is the cardinality of the continuum, but I don't see why that has to be the case; this seems highly non-trivial to me. Could someone please explain this to me?","['cardinals', 'linear-algebra', 'hilbert-spaces', 'inner-products']"
2592943,Generating functions - coefficient of $x^{27}$,"What is the coefficient of $x^{27}$ for $f(x) = \Big(\dfrac{1+x^{10}}{(1-x)^5}\Big)^{2}$ ? So i can work the math a little bit to get - $f(x) =  \Big(\dfrac{1+2x^{10} + x^{20}}{(1-x)^{10}}\Big)$  $\iff f(x) = (1+2x^{10} + x^{20}) \cdot (\sum_\limits{n=0}^{\infty}\binom{10+n-1}{n}x^n)$ So i want to sum $1$ for the left with $x^{27}$ for the right, $2x^{10}$ for the left with $x^{17}$ from the right and $x^{20}$ from the left with $x^7$ from the right. $ = 1 \cdot \binom{36}{27} + 2\cdot\binom{26}{17} + 1\cdot\binom{16}{7}$ Is it done right ?","['generating-functions', 'discrete-mathematics']"
2592983,Find $f\in \mathbb{Z}_{p}\left[X\right]$ such that $f\left(X^{m}\right)$ is divisible by $\Phi_{p-1}$.,"Let $p$  be a prime natural number, let $m\in\left\{ 2,\,\ldots,\,p-2\right\}$ 
  and let $\Phi_{p-1}\in \mathbb{Z}_{p}\left[X\right]$ the cyclotomic polynomial corresponding to $p-1$. Find the polynomials $f\in \mathbb{Z}_{p}\left[X\right]$ such that $f\left(X^{m}\right)$ is divisible by $\Phi_{p-1}$.","['number-theory', 'cyclotomic-polynomials', 'polynomial-congruences']"
2592999,Prove that $\lim_{x \to 2} x^3 = 8$ by using epsilon-delta,"Prove that $$\lim_{x \to 2} x^3 = 8$$ My attempt, Given $\epsilon>0$, $\exists \space \delta>0$ such that if $$|x^3-8|<\epsilon \space \text{if}  \space 0<|x-2|<\delta$$ $$|(x-2)(x^2+2x+4)|<\epsilon$$ I'm stuck here. Hope someone could continue the solution and explain it for me. Thanks in advance.","['epsilon-delta', 'proof-verification', 'limits']"
2593005,How to prove that $\exp(x_1+x_2)=\exp(x_1)\exp(x_2)$?,"In my analysis class, we covered the properties of the exponential function (as of now we use $\exp$ instead of $e$). One of the properties of $e$ is that $\exp(x_1+x_2)=\exp(x_1)\exp(x_2)$. In high school this was just assumed knowledge but now we have to prove that this statement is indeed true, which is proving to be quite difficult. I assume that one would need to work out the derivatives of both side and see if they are equal. Then if $f(0)=1$ we can assume that both sides of the equation are true.","['real-analysis', 'exponential-function', 'proof-explanation']"
2593016,"injection $(\mathbb{N}\to\{0,1,2\})\to\ (\mathbb{N}\to\{0,1\})$ [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question It is also possible to find a surjection in the other direction - I am trying to prove the cardinality of $$\mathbb{N}\to\{0,1,2\}$$ is less than or equal to $$\mathbb{N}\to\{0,1\}$$","['elementary-set-theory', 'discrete-mathematics']"
2593038,Compute $\lim_{x \to \infty} \frac{e^x}{x^a}$,"How can I compute $\lim_{x \to \infty} \frac{e^x}{x^a}$ for some $a \in \mathbb R$ with $x^a := e^{a \log(x)}$? I want to use only the basic properties of limits, i.e. the linearity, multiplicativity, monotonicity and the Sandwich property (no L'Hospital). Can you give me a hint?","['real-analysis', 'limits-without-lhopital', 'limits']"
2593047,Checking if a function is injective and surjective,"I am doing past paper question and came across the following question: For each of the following functions, decide whether it is injective
  and surjective. Justify your answer. $f: $ {$-1, 0, 1$} $\to$ {$-1, 0, 1$} $f(x) = x^3$ $g: $ {$0, 1$} $\to$ {$0, 1, 2, 3, 4, 5$} $g(x) = 3x + 1$ I have only recently started studying functions, so hoped to check my answers here, because I do not have access to a marking scheme. My answers and reasoning: $f$ is not injective, because $\pm x \neq \pm x$ $f$ is surjective because the co-domain {$-1, 0 ,1$} $=$ the range {$-1, 0 ,1$} $g$ is injective, because $x = x$ $g$ is not surjective, because the co-domain {$0, 1, 2, 3, 4, 5$} $\neq$ the range {$1, 4$} Please let me know if I have made any errors in my answers or reasoning. Thank you.",['functions']
2593048,"Motivation for the term ""trace"" in linear algebra","I'm wondering what could be the motivation behind the term ""trace"", especially in the simple case of a trace of a matrix. Looking through some geometric interpretations and bearing in mind the traditional meanings of the word ""trace"" , I could not conceive a satisfactory answer.","['math-history', 'matrices', 'terminology', 'trace', 'linear-algebra']"
2593066,How to prove :$\sqrt{1!\sqrt{2!\sqrt{3!\sqrt{\cdots\sqrt{n!}}}}} <3$,"In  fact initially I wanted to prove that $$\sqrt{1!\sqrt{2!\sqrt{3!\sqrt{\cdots\sqrt{n!}}}}} <2$$ Which by the accepted answer here fails to be true. @Barry Cipra advised me to ask this question in a different post:
How can I now prove that: $$\sqrt{1!\sqrt{2!\sqrt{3!\sqrt{\cdots\sqrt{n!}}}}} <3$$ Note that the answers here do not provide an estimate of this sequence Can anyone have any idea?","['real-analysis', 'inequality', 'real-numbers', 'calculus', 'sequences-and-series']"
2593094,$xe^x$ even or odd?,"I have this simple function: $$xe^x$$ Is it an even or odd function? How can I prove it? For even functions, we have: $$f(x)=f(-x)$$ For odd functions, we have: $$-f(x)=f(-x)$$ I have only got the hint that it is an even function but my logic says odd.","['logarithms', 'even-and-odd-functions', 'functions']"
2593124,What is the value of $\arctan \left(\frac xy\right) +\arctan \left(\frac yx\right)?$,I was playing about with some numbers when I came up with this fun question. What is the value of $\arctan \left(\frac xy\right) +\arctan \left(\frac yx\right)?$ Here is my method: As is clearly evident from the triangle: $a = \arctan \left(\frac yx\right)$ and $b = \arctan \left(\frac xy\right)$ $\therefore \arctan \left(\frac xy\right) +\arctan \left(\frac yx\right) = a + b = 90^{\circ} = \frac {\pi}2 ^c$ Was my method right? Or can it be improved? I would appreciate any help in the comments or through answers. Thanks in advance!,"['recreational-mathematics', 'trigonometry', 'soft-question']"
2593137,Is there an algorithm to determine if a power series is periodic?,"We know that the sine function is periodic by its geometric definition. The Taylor/MacLaurin series expansion about 0 which is the basis of actual mechanisms for computing it is:
$$\sin(x) = \sum_{n=0}^\infty  \frac{(-1)^n}{(2n+1)!}x^{2n+1}$$ This series manages to be periodic with period $2\pi$ because it has an alternating sign. Is there a way to tell if an arbitrary power series is periodic? More informally, if someone gave us the above summation for $\sin$ without telling us it was a trigonometric function, is there a procedure for discovering that it is periodic and finding the period? Amendment: As pointed out in the answers, there is clearly no algorithm if the coefficients are allowed to be arbitrary, thus containing an unbounded amount of information. I should have asked ""Under what limitations to a function defining the coefficients of a power series does there an exist algorithm for determining if the power series is periodic?"" In particular, if $f(n)$ is limited to a rational expression that would be accepted as a ""closed-form"" expression, as it is in the case of $\sin(x)$, does such an algorithm exist? If $f(n)$ is limited to being a simple arithmetic computation from $n$, can we determine if the function is periodic?","['taylor-expansion', 'turing-machines', 'algorithms', 'power-series', 'analysis']"
2593182,Uniform integrability of stopped submartingales,"The following is well-known and useful : Lemma. Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probabiliy space, and let $\mathcal{X}=(X_i)_{i\in I}\in L^1(\mathbb{P})^I$ be a uniformly integrable family . Then the family of all conditional expectations of $\mathcal{X}$ :
  $$\Big(\mathbf{E}(X_i\mid\mathcal{G})\Big)_{i\in I,~\mathcal{G}~\equiv~\text{sigma-subalgebras of }\mathcal{F}}$$
  is uniformly integrable. Hence, if $(\mathcal{F}_t)_{t\geq 0}$ is a (complete, right continuous) filtration, it follows from the stopping time theorem that for any right continuous, uniformly integrable martingale  $(M_t)_{t\geq 0}$, the family
$$(M_T)_{\,T~\equiv~\text{stopping time}}$$
is uniformly integrable. Indeed, for any stopping time $T$, $M_T=\mathbf{E}(X_\infty\mid\mathcal{F}_T)$, where $X_\infty$ is the almost sure and $L^1$ limit of $X_t$, $t\to+\infty$. Question : Suppose $(S_t)_{t\geq 0}$ is a right continuous, uniformly integrable sub martingale. Is
$$(S_T)_{\,T~\equiv~\text{stopping time}}$$
uniformly integrable ?","['uniform-integrability', 'probability-theory', 'stopping-times', 'martingales', 'conditional-expectation']"
2593256,"Show that $\lim_{k\to\infty} \int_0^1 f(x) \sin(kx) \, dx = 0$","I'm working through some old test problems in preparation for a Real Analysis exam. I got stuck on the following problem: Show that if $f$ is (Lebesgue) integrable on $[0,1]$, then $$\lim_{k\to\infty} \int_0^1 f(x) \sin(kx) \, dx = 0$$ It seems to me that the idea is to move the limit inside the integral. I know that $f(x)\sin(kx)$ is bounded by $f(x)$ which is integrable, so I thought maybe the bounded or dominated convergence theorems might be useful. However, I don't have a sequence of integrable functions converging point-wise to $0$. How can I proceed, or am I approaching this incorrectly?","['real-analysis', 'lebesgue-integral']"
2593280,First Chern class of the tangent bundle of the sphere starting from a Riemannian metric,"I'm trying to obtain the first Chern class of the tangent bundle of $S^2$ by starting with its Riemannian metric. So, since we have $$ds^2 = r^2 \left(d \theta^2 + \sin(\theta)^2 d \phi^2    \right)\,,$$ setting $\omega^\theta = r d\theta$, $\omega^\phi = r \sin(\theta) d \phi$ and applying Cartan's structure equations yields $\omega_\theta^\phi = \cos(\theta) d\theta$ and $\Omega_\theta^\phi = - \sin(\theta) d \theta \wedge d \phi = - \Omega_\phi^\theta$. My aim now, if I understand it correctly, is to complexify the connection described by the 1-form $\omega^a_b$ so that I may obtain a new curvature $\widetilde{\Omega}$ which is the one that enters the expression of the Chern class: $$c_1 \left( TS^2\right) = \frac{1}{2\pi i} \left[  \mathrm{tr}\left( \widetilde{\Omega} \right) \right]\,.$$ My issue, however, is that I don't understand how I can determine this complexified connection, therefore any hints on how to proceed would be much appreciated.","['characteristic-classes', 'connections', 'differential-geometry']"
2593296,Why is probability on Lie groups nice?,The question may sound weird. I am a probabilist who has heard of works connecting probability with (compact) Lie groups. What is the motivation? Is it generalisation just for the sake of generalisation? Applebaum’s book is the classic but I am firstly interested to know why doing probability on Lie groups is a worthwhile effort. I know little lie theory from a differential geometric point of view. Is it enough for reading about connections between Lie groups and probability?,"['probability-theory', 'lie-groups']"
2593305,Integral of $x\log(\sin x)$,This is from an old S level paper. I am struggling with part (ii). Any hints?,['integration']
2593324,Layman's proof that the area of a circle of radius $r$ equals $\pi r^2$.,"There are many, many clear and simple proofs of basic but nontrivial facts in high-school mathematics, such as Pythagoras' theorem or the identities $$\sum_{k=1}^nk=\binom{n}{2}\qquad\text{ and }\qquad\sum_{k=1}^n(2k-1)=n^2,$$ that are accessible to the lay person, having no mathematical knowledge beyond perhaps the most basic high-school curriculum, or perhaps even elementary school.
See the answers to this question for many such proofs. I'm surprised I can't find such a proof for the fact that the area of a circle of radius $r$ equals $\pi r^2$ that is thoroughly convincing . Let me explain what I find unconvcing about two popular visual proofs. Parallellogram proof The proof I see most often is the parallellogram proof , cutting the circle radially into ever smaller wedges and joining them together to approximate a parallellogram: It leaves the question of convergence open; do these approximations of parallellograms converge to a rectangle with side lengths $r$ and $\pi r$ as we take ever smaller wedges? It turns out that they do and the argument can be made rigorous, but to the critical lay person this need not be clear from the picture. Triangle proof Another proof I have seen quite often is the triangle proof , cutting the circle into ever thinner concentric rings and unwrapping them to approximate a right triangle: Again this leaves the question of convergence; do these approximations of right triangles converge to a right triangle of height $r$ and base $2\pi r$ ? Again it turns out that they do and the argument can be made rigorous, but again to the critical lay person this need not be clear from the picture. Other proofs either require techniques beyond the most basic high-school curriculum, such as calculus for the onion proof , or are computationally involved such as Archimedes' proof or variations thereof. I do assume that the layman is familiar with the fact that the circumference of a circle of radius $r$ equals $2\pi r$ . TL;DR Given that the circumference of a circle of radius $r$ equals $2\pi r$ , is there a simple proof of the fact that its area equals $\pi r^2$ , using nothing but the most elementary mathematical techniques (certainly no calculus)?","['circles', 'area', 'alternative-proof', 'geometry']"
2593354,Let $A$ and $B$ be square real matrices such that $A+iB$ is non-singular. Show that there exists $t\in \mathbb{R}$ such that $A+tB$ is non-singular.,"Let $A$ and $B$ be square real matrices such that $A+iB$ is non-singular. Show that there exists $t\in \mathbb{R}$ such that $A+tB$ is non-singular. My Attempt: I thought about considering the polynomial over $\mathbb{C}$. Let $$f(t)=|A+tB|.$$ Then $f(i)\not =0.$ This shows that $f\not \equiv 0$ and since $f$ has a finite number of roots of which let $\{t_1,t_2,...,t_k\}$ be the real roots. Then we can easily, find $t\in \mathbb{R}$ such that $f(t)=|A+tB|\not =0$ and hence $A+tB$ will be non-singular. Is this correct reasoning?",['linear-algebra']
2593365,Defining the range and domain of Composite functions as well as plotting graphs of composite functions,"Consider a function $$f(x)=\vert{\vert {x-3} \vert -2}\vert$$ for $0\le x\le 4$ And $$g(x)= 4-\vert {2-x}\vert$$ for $-1\le x\le 3$ Where $\vert .\vert$ represents modulus function. Now the problem is that I want to draw the graph of $f(g(x))$. Now I could make cases by the finding the critical points of the modulus functions and then plot the graph. But this seems to be a very tedious task. I want to know if there is any other way to plot the graph of such composite functions without taking so much of cases.  Any help would be greatly appreciated. $\mathbf {Edit :} $ CY Aries' method seems to be very appropriate for this question but what if the question asks for some cubic or quadratic function. e. g. 
$$f(x) =
\begin{cases}
1+x^3,  & \text{$x\le 0$} \\
x^2-1, & \text{$x\ge 0$}
\end{cases}$$ and $$g(x) =
\begin{cases}
(x-1)^{\frac{1}{3}},  & \text{$x\le 0$} \\
(x+1)^{\frac{1}{2}}, & \text{$x\ge 0$}
\end{cases}$$ Then plot $g(f(x))$. Now that method won't work here. I am also supposed to define the non-uniform function $g(f(x))$","['functional-analysis', 'functions', 'graphing-functions']"
2593369,"Eigenvector, eigenvalue and matrix of $(\mathbf A+\mathbf I)^{-1}$ where $\mathbf A=\mathbf{vv}^\top$","Given $\mathbf v=\begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}$ and $\mathbf A=\mathbf{vv}^\top$, find the matrix $(\mathbf A+\mathbf I)^{-1}$ and its eigenvectors and eigenvalues. This is a follow up of questions of the previous one . Previous example told us $\mathbf A+\mathbf I$ has eigenvalue $\lambda_1=(\|\mathbf v\|^2+1)$ with corresponding eigenvector $\mathbf v_1=\mathbf v$. And eigenvalue $1$ with multiplicity $n-1$. We also know that if a matrix $\mathbf B$ has eigenvector $\mathbf v$ and eigenvalue $\lambda$, then the inverse matrix $\mathbf B^{-1}$ will have same eigenvector $\mathbf v$ and eigenvalue $\frac1\lambda$. Based on the above knowledge, we can easily to get eigenvalue of $(\mathbf A+\mathbf I)^{-1}$ will be $1$ with multiplicty $n-1$ and $\frac1{(\|\mathbf v\|^2+1)}$. They share the same eigenvectors. Now, I want to know how does the matrix  $(\mathbf A+\mathbf I)^{-1}$ look like by using minimal polynomial. I am guessing I can use the same techniques here . First, I find out the characteristic polynomial for $(\mathbf A+\mathbf I)$. $f(\lambda)=(\lambda-1)^{n-1}(\lambda-1-\|\mathbf v\|^2)$ Then we know the possible candidate for minimal polynomial will be $(\lambda-1)^{k}(\lambda-1-\|\mathbf v\|^2)$ where $k \ge 1$. How do I know the $k$ for minimal polynomial from here? Is minimal polynomial a good starting point to find the inverse of the matrix?","['eigenvalues-eigenvectors', 'matrices', 'minimal-polynomials', 'inverse', 'linear-algebra']"
2593371,"If $\sum_{i=1}^\infty i^2\mathbb{P}(i\leq X_n<i+1)\leq C\leq \infty$, prove $\mathbb{P}(X_n \geq n\ i.o.) = 0$","I am studying probability theory myself, so I have been asking questions a lot recently. Please help. This question comes from Rosenthal's 3.6.13 Let $X_1, X_2,\dots$ be defined jointly on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$, with $\sum_{i=1}^\infty i^2\mathbb{P}(i\leq X_n<i+1)\leq C\leq \infty$ for all $n$. Prove that $\mathbb{P}(X_n \geq n\  i.o.) = 0$ I am thinking if I can prove $\sum_{n=1}^\infty \mathbb{P}(X_n \geq n) < \infty$, then Borel-Cantelli Lemma can apply, but got no luck. What I got are: \begin{align}
\sum_{i=1}^\infty i^2\mathbb{P}(i\leq X_n<i+1) &= \mathbb{P}(X_n \geq 1) - \mathbb{P}(X_n\geq 2) + 2^2 \mathbb{P}(X_n \geq 2) - \mathbb{P}(X_n\geq 3) + \dots \\
&= \sum_{i=1}^\infty (2i-1)\mathbb{P}(X_n \geq i) \\
\mathbb{P}(X_n \geq n) & = \sum_{i=n}^\infty \mathbb{P}(i\leq X_n<i+1)
\end{align} However, none of these lead me to an answer. If it requires the Kolmogorov Zero-One Law, please explain me a little. I am confused about the definition of ""tail field"".",['probability-theory']
2593380,Ex 10.2.1 in Klenke's Probability Theory textbook,Have been puzzled by this innocent-looking exercise from the book by Klenke. Would really appreciate any hint/comment/solution. Here it is... And here are some related (basic) concepts...,"['probability-theory', 'martingales']"
2593408,What's this equation?,"first post here. I'm an economist and I'm a bit rusty with my math. Would someone help out? I've done my homework and searched but couldn't find answers. Question: what is this equation for? $$\frac{\Delta y_{t}}{y_{t}}=s_{t}\frac{\Delta k_{t}}{k_{t}}+\Delta s_{t}\left(\log k_{t}+\frac{\Delta B(s_{t})}{B(s_{t})}\right)$$ sorry for my notations. $\Delta x/x$ is a growth rate over time, $s_{t}\in[0,1]$ is some parameter that varies over time and $B(s_{t})$ is some polynomial in $s_{t}$. clearly the first part relates the growth rate of $y_{t}$ to the growth rate of $k_{t}$ in a linear way with (time-varying) slope $s_{t}$. But I don't want to dismiss the rest of the equation as noise. I suspect some kind of circular movement or oscillations . But I may be wrong. What would a plot look like? Any help is appreciated!!!","['ordinary-differential-equations', 'graphing-functions']"
2593442,"Distribution of $X+\frac{2}{X}$ when $X\sim\mathcal U(1,2)$","I have the following question:
If $X$ is a continuous random variable that is uniformly distributed on the interval $(1,2)$ what is the distribution function of $Y=X+\frac{2}{X}?$\
I have tried to calculate the inverse of the function $f(x)=x+\frac{2}{x}$ but didn't manage to complete the calculation. Any ideas?","['probability', 'probability-distributions']"
2593460,"$X \sim U(0,\theta)$. Find the distribution of $X_1\mid \max (X_i)$","The problem is to find the distribution of $X_1\mid M$ where $M$ is the maximum of the i.i.d. random variables $X \sim U(0,\theta)$. I have a complete solution but am having trouble justifying one step. We use Bayes' Theorem for CDF's to get started: $$ P(X_1 < x_1 \mid M < m) = \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} $$ The cdf's for $M$ and $X_1$ are $(m/\theta)^n$, by independence, and $x_1/\theta$. The cdf for $M\mid X_1$ is $(m/\theta)^{n-1} {\bf 1} [x_1 \leq m]$. The justification I have is that if the observed value $x_1$ is greater than $m$, then $m$ cannot be the maximum. So, I threw the indicator on the cdf in order to justify that $M\mid X_1$ is just the distribution of the maximum excluding $X_1$. So, $$ \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} = \frac{(x_1/\theta) (m/\theta)^{n-1}}{(m/\theta)^n} = \frac{x_1}{m} $$ It follows that $X_1\mid M \sim U(0,m)$. Is my justification for the distribution of $M\mid X_1$ correct? I believe my final answer is intuitive.","['statistics', 'probability', 'order-statistics']"
2593481,Prove that there exists a positive integer $a$ such that $n|a^2-a$,Let $n$ be a positive integer with $k$ distinct prime divisors. Prove that there exists a positive integer $a$ with $1<a<\frac{n}k+1$ such that $n|a^2-a$ I can't solve it. Could someone help me?,['number-theory']
2593485,How to solve this limit when direct substitution fails. Why do this work?,"Say I am trying to solve this limit: $\lim_{x \to 1} \frac{x^2-1}{x-1}$ I know the answer is 2 because: $\lim_{x \to 1} \frac{x^2-1}{x-1} = $ $\lim_{x \to 1} \frac{(x+1)(x-1)}{x-1} = $ $\lim_{x \to 1} x+1 = $ But on a high level, what is going on here? We can't use direct substitution because at 1, the function is not defined. But why does cancellation help? Why does the common factor cause problems? Why does cancelling the common factor fix our problem (whatever it is)?",['limits']
2593489,Behavior of the derivative of a function,"I am a physics student and would apologize if in advance if you find my way of asking the question inapproperiate. I have the following function $F(x)=2f(x) - f(2x).$ Given that $\frac{d}{dx}f(x) > 1$, what can one say about $\frac{d}{dx}F(x)$ ? Since $\frac{d}{dx}F(x) = 2\frac{d}{dx}f(x) - \frac{d}{dx}f(2x)$. The first term, $2\frac{d}{dx}f(x)$, is greater than 2. How about the second term and hence the overall derivative $\frac{d}{dx}F(x)$?",['functions']
2593490,Lower bound for a trace of a matrix product,"Let $A$ and $B$ be positive definite Hermitian matrices. They need not necessarily commute. Let $a_m$ be the minimum eigenvalue of $A$. Is it true that 
$$
\text{Tr} (AB) \geq a_m \text{Tr} (B) 
$$ My attempt: let $a_i$ and $b_i$ be the eigenvalues (which are all real and positive) of $A$ and $B$. If $A$ and $B$ are simultaneously diagonalizable by a similarity transformation then $
\text{Tr} (AB) = \sum_i a_i b_i \geq  a_m \sum_i b_i = a_m \text{Tr} (B) 
$. But is this generalizable to arbitrary $A$ and $B$ as laid out above?","['spectral-theory', 'linear-algebra']"
2593531,Confusion over what indices to contract when deriving Ricci curvature from the curvature tensor?,"My question here is just an example of a more general problem I'm having of working in local coordinates, so any help would be appreciated. I am told that $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, where $R_{iklj}$ are the components of the curvature tensor $R$. Here $R$ is considered as a $(0,4)$-tensor, related to $R$ considered as a $(1,3)$-tensor by \begin{equation}R(X,Y,Z,W)=g(R(X,Y)Z,W)\end{equation} I am slightly confused as to how to obtain $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, given the definition of Ricci curvature I've been given:
\begin{equation}
\mathrm{Ric}(v,w)=\mathrm{trace}(x\mapsto R(x,v)w).
\end{equation}
It seems to me that first I want to convert $R$ from its $(0,4)$ form to its $(1,3)$ form, but with $R=R_{iklj}\sigma^i\otimes\sigma^k\otimes\sigma^l\otimes\sigma^j$ I'm not sure which of the factors I should be converting? Suppose for instance I take the second factor, so
\begin{equation}
\sigma^k\rightarrow g^{ks} E_s 
\end{equation}
(this is by the usual isomorphism between $TM$ and $T^*M$ on a Riemannian manifold, where $E_i$ is our frame and $\sigma^i$ our coframe). Thus we obtain a $(1,3)$-tensor 
\begin{equation}
\begin{split}
R & = g^{ks}R_{iklj}\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j \\ &= {R_i^{~~s}}_{lj}\,\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j
\end{split}
\end{equation} Even if this is the correct choice to make, in order to obtain the Ricci tensor (considered as a $(0,2)$-tensor) I must now contract the $E_s$ factor with one of the $\sigma$ factors. Again, I am not sure which factor I should be contracting with to obtain the Ricci tensor. Choosing the $\sigma^l$ factor I obtain \begin{equation}
	S = S_{ij}\sigma^i\otimes \sigma^j
	\end{equation}
    where $S_{ij} = {R_i^{~~s}}_{sj}$. Is this tensor $S$ the Ricci tensor? Does $S_{ij}=g^{kl}R_{iklj}$? How am I to know what choices to make (when working in coordinates as above) when changing tensor types/performing contractions, from the definitions I've been given that are not in coordinates? Thanks in advance.","['tensor-products', 'riemannian-geometry', 'tensors', 'curvature', 'differential-geometry']"
2593554,Where to use Poisson point process/ Uniform distribution,"When modeling the random locations of points in a one by one square, I am free to either model them by Poisson point process or Uniform distribution: 1) $N$ points are located in a one by one square according to a uniform distribution
2) points are located in a one by one square according to a Poisson point process with mean $N$ After modeling, I discuss the problem for large $N$, ($N \to \infty$). When should I choose Poisson and when should I choose uniform? I know it depends on the problem I am considering, and I have to see to which of the distributions (Poisson vs Uniform) is the real problem is close to. But, if I know nothing about the real problem and have the freedom to choose either Poisson or Uniform, how should I choose?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2593565,Stars and bars approach.,"In how many ways can $b$ identical blue balls and $r$ identical red balls be distributed in $n$ distinct boxes ? Here the answer given is :- $\frac {(n+b-1)! (n+r-1)!}{(n-1)! (n-1)! b! r!}$ I understand how this answer is derived using stars and bars approach where we find the number of ways for each color and then multiply them. However, I am not able to understand why the below answer is wrong ? $\frac {(n+ (b+r) - 1)!} {(n-1)! b! r!}$. In my second approach, I initially have $b+r$ identical balls and then divide them into $n$ distinct boxes. Why is this approach wrong?","['permutations', 'combinatorics']"
2593613,Let $A$ be a real $4\times4$ matrix such that $A^2+A+I = 0$. Can $A$ be orthogonal?,"I'm struggling on the third point of this exercise: Let $A$ be a $4 \times 4$ matrix such that $A^2 + A + I=0$. Are this statements true or false? $A$ is invertible $A$ can be skew-symmetric $A$ can be orthogonal This is what i have done so far: $A^2 + A = -I \Rightarrow det(A^2+A)=det(A) \cdot det(A+I) = 1$ hence $det(A) \neq 0$ so the first statement is true. For the second i noticed that $-1$ is an eigenvalue for $A^2+A$ and its geometric multiplicity is $4$ so also the algebraic multiplicity is $4$. Hence $-1$ is the only eigenvalue of $A^2+A$. Now let $\lambda$ be an eigenvalue of $A$ and $v \neq 0$ be a $\lambda$-eigenvector: $$(A^2+A)v = A^2v+Av=\lambda^2v+\lambda v = (\lambda^2 +\lambda)v$$ 
hence $\lambda^2+\lambda$ is an eigenvalue of $A^2+A$ so $\lambda^2+\lambda=-1 \Rightarrow \lambda = -\displaystyle\frac{1}{2} \pm \frac{\sqrt3}{2}i $. Since skew-symmetric matrices has only pure imaginary eigenvalues the second statement is false. For the third point i have seen that $det(A) = \left(-\displaystyle\frac{1}{2} + \frac{\sqrt3}{2}i\right)\left(-\displaystyle\frac{1}{2} - \frac{\sqrt3}{2}i\right) = 1$ and also that $\mid\lambda\mid = 1$ thus i believe that the third is true but i can't find an example of an orthogonal matrix. Am i missing something? Have i made any mistake in my reasoning? Thank you very much in advance!","['matrices', 'orthogonality', 'linear-algebra', 'proof-verification']"
2593619,Minimise $|z_az_b + z_cz_d|$ where $\{z\}$ are the roots of $x^4 + 14x^3 + 52x^2 + 56x + 16$,"Let $f(x) = x^4 + 14x^3 + 52x^2 + 56x + 16.$ Let  $z_1, z_2, z_3, z_4$ be the four roots of $f$. Find the smallest possible value of $|z_az_b + z_cz_d|$ where ${a, b, c, d} = {1, 2, 3, 4}.$ So I have tried Vieta, but it is try too complex and plugging in a simple value to try to find a root failed, so I think this is going to be much harder than finding the four roots-- I wonder if there are more involved techniques to solve this problem.","['algebra-precalculus', 'contest-math', 'polynomials']"
2593627,I have a line. I want to move the line a certain distance away parallelly.,"I struggle to find the language to express what I am trying to do. So I made a diagram. So my original line is the red line. From (2.5,2.5) to (7.5,7.5). I want to shift the line away from itself a certain distance but maintaining the original angle of the line(so move it a certain distance away at a 90 degree angle). So after the shifting the line by the distance of +1 it would become the blue line or by -1 it would be come the yellow line. I don't know a lot of the maths terminology so if anybody could manage an explanation in layman terms it would be appreciated. Thanks,
C",['geometry']
2593637,how many monotonically increasing functions are in $\Omega = \{ \space f \mid f: A \rightarrow B\space \}$,"Given $A=\{1,2,3..,n\}$,  $B=\{1,2,3,..,m\},$$\space \space $while $5<m,n$ $\space$ and $\space \Omega = \{ \space f \mid f: A \rightarrow B\space \}$ How many functions are monotonically increasing in $\Omega$ while $m>n$? My answer is $m-n+1$. Basic example is $A=\{1,2,3,4,5\}$ and $B=\{1,2,3,4,5,6\}$.
hence:
$$f_1(1) = 1, \space \space f_1(2) = 2, \space \space f_1(3) = 3, \space \space f_1(4) = 4, \space \space f_1(5) = 5$$
$$f_2(1) = 2, \space \space f_2(2) = 3, \space \space f_2(3) = 4, \space \space f_2(4) = 5, \space \space f_2(5) = 6$$ So we get 2 functions, and while the diffrence between $m$ and $n$ getting bigger, the result's getting bigger.
Am I missing somthing?","['combinatorics', 'discrete-mathematics']"
2593654,Simplify an Expression with Indices,"I'm on a chapter about simplifying expression that have indices. This example has gotten me stumped: $$\frac{15a^5b^2}{3a^2b^3}= \frac{15}{3} \times \frac{a^5}{a^2} \times \frac{b^2}{b^3} = \frac{5a\frac{1}{3}}{b}$$ I thought the answer would be: $$\frac{5a^3}{b^{-1}}$$ I should add that I'm coming back to math in life after school, it seems there are things missing from memory. Thanks.",['algebra-precalculus']
2593662,Decomposing a particular fraction,"I am working on Problem I.4.7 in Lang's Complex Analysis. It asks to find the convergence of 
\begin{equation}\sum_\limits{n=1}^\infty \frac{z^{n-1}}{(1-z^n)(1-z^{n+1})}.\end{equation} The hint says to multiply and divide each term by $1-z$ and do a partial fraction decomposition to get a telescoping sum. I tried this and got 
\begin{equation}\frac{A}{(1-z^n)(1-z)} + \frac{B}{(1-z^{n+1})(1-z)} + \frac{C}{(1-z^n)(1-z^{n+1})} = \frac{z^{n-1}-z^n}{(1-z^n)(1-z^{n+1})(1-z)}.\end{equation} By inspection, I found that \begin{equation}
\begin{split}
A&= 0\\
B&=-\frac{1}{z}+1 \\
C&= \frac{1}{z}
\end{split}
\end{equation} is a solution. This however, does not give me a telescoping sum. The resources I have found only talk about partial fraction decomposition after reducing to irreducible quadratics, which does not seem tenable here. Are there any more general techniques to partial fraction decomposition might help here? Edit: Here is the decomposition the above obtains, in case it is useful: \begin{equation}
\frac{z^{n-1}}{(1-z^n)(1-z^{n+1})}=\frac{1}{(1-z^{n+1})(1-z)} - \frac{1}{z(1-z^{n+1})(1-z)} + \frac{1}{z(1-z^{n+1})(1-z^n)}
\end{equation}","['complex-analysis', 'partial-fractions']"
2593696,How to Determine a clamped B-spline curve passes through a given point q,"Let P be a clamped B-spline curve of degree two defined by the control
points, The control points are :    $\binom{-2}{-2},\binom{-2}{0},\binom{0}{2},\binom{2}{2},\binom{2}{0},\binom{0}{-2} $ and over the knot vector of $\tau$ := $ (0, 0, 0, \frac{1}{4},\frac{1}{2} ,\frac{3}{4}, 1, 1, 1)$. Does P pass through the point  $q := \Biggl(\begin{smallmatrix}
    \frac{-1}{2} \\ \frac{1}{2} \end{smallmatrix} \Biggr)$  ? Could we get different results for other clamped (possibly non-uniform) knot vectors instead of $\tau $?","['curves', 'spline', 'bezier-curve', 'differential-geometry']"
2593701,Sufficient and necessary conditions for order relations describing a certain system of sets,"I call a system of precedences $U$ a set of nonempty subsets of some poset. I will denote $A<B \Leftrightarrow \forall a\in A, b\in B: a<b$ for sets $A,B\in U$. Find sufficient and necessary restrictions on binary relations $<$ and $\subseteq$ such that there exists a system $U$ of precedences such that they are exactly (up to isomorphism) $<$ and $\subseteq$ on $U$. (I wrote my conditions for these operations for a system of precedences in https://cs.stackexchange.com/q/85951/39512 but I'm not sure if these conditions are right.) The proposed conditions in that answer can be written as the following: $\subseteq$ is a non-strict partial order relation and $<$ is a strict partial order relation. $\forall a,b,a_1,b_1\in U:(a<b \wedge a_1\subseteq a \wedge b_1\subseteq b \Rightarrow a_1<b_1)$. (Not relevant to the question, just where the questions appeared from) Systems of precedences origin from subsets of $U$ being sets of operations, where operations with higher precedences should be applies before operations of lower precedences.) You may assume that all sets in consideration are finite.","['relations', 'logic', 'elementary-set-theory', 'order-theory']"
2593711,Fixed point theorems and their applications in Measure Theory,We know that there are many versions for the fixed point theorem and they have many applications. I would like to know whether there is one has an application in Measure Theory. And I would be grateful if I was informed good references about it.,"['fixed-point-theorems', 'reference-request', 'measure-theory']"
2593718,"If $Ax \in \langle x \rangle=\{ax:a\in \mathbb{R}\}$ for every vector $x$, then $A$ is square and diagonal.","I'm asked to prove or disprove the title statement. I'm looking for verification/critique of my proof. This is false. This statement is claiming that if every vector $x$ is an eigenvector for $A$ corresponding to a real eigenvalue, then $A$ must be square and diagonal. Symbolically, $\forall x \exists a\in\mathbb{R}$ s.t. $(A-aI)x=0\Rightarrow A$ is square and diagonal. It is true that $A$ is square, as $A-aI$ is only defined for square $A$. However, it is not required that $A$ be diagonal. Consider, for counterexample, $A_{2\times2}=J_{2\times2}$, the $2\times2$ matrix of all 1's, and let $x=[x_1,x_2]^T$. Solving the system of equations $(J-aI)x=0$, we get that $-ax_1+ax_2=0$. Thus, $A_{2\times2}=J_{2\times2}$ has every vector $x$ as an eigenvector corresponding to the eigenvalue 0.","['matrices', 'proof-writing', 'linear-algebra', 'proof-verification']"
2593739,"Prove: For $\triangle ABC$, if $\sin^2A + \sin^2B = 5\sin^2C$, then $\sin C \leq \frac{3}{5}$.","We have a triangle $ABC$. It is given that $\sin^2A + \sin^2B = 5\sin^2C$. Prove that $\sin C \leq \frac{3}{5}$. Let's say that $BC = a$, $AC=b$, $AB=c$. According to the sine law, $$\frac{a}{\sin A} = \frac{b}{\sin B} = \frac{c}{\sin C} = 2R,$$ then $\sin A = \frac{a}{2R}\implies \sin^2A = \frac{a^2}{4R^2}$ $\sin B = \frac{b}{2R}\implies \sin^2B = \frac{b^2}{4R^2}$ $\sin C = \frac{c}{2R}\implies \sin^2C = \frac{c^2}{4R^2}$ Then we get: $$\frac{a^2}{4R^2} + \frac{b^2}{4R^2} = 5\frac{c^2}{4R^2}.$$ Since $4R^2 > 0$, we get that $a^2 + b^2 = 5c^2$ Guys, is that correct? Even if it is, do you have any ideas what shall I do next?","['inequality', 'trigonometry', 'proof-verification', 'triangles', 'geometry']"
2593758,"Is Conway's ""Look and Say Sequence"" strictly increasing?","I have a straightforward question about Conway's ""Look and Say Sequence ( A005150 ): The integer sequence beginning with a single digit in which the next term is obtained by describing the previous term. Starting with 1, the sequence would be defined by ""1, one 1, two 1s, one 2 one 1,"" etc., and the result is 1, 11, 21, 1211, 111221, .... Source: http://mathworld.wolfram.com/LookandSaySequence.html Question: Is this sequence strictly increasing? It is known that, asymptotically, the number of digits in each term grows by a little more than 30%: if $L_n$ is the number of digits in the $n$ -th term in the sequence, then $\lambda := \displaystyle{\lim_{n\to\infty}\frac{L_{n+1}}{L_n} = 1.303577269\dots}$ where $\lambda$ is the unique positive real root of the following degree-71 polynomial: [...] Source: http://www.nathanieljohnston.com/2010/10/a-derivation-of-conways-degree-71-look-and-say-polynomial/ However, is this growth monotonic everywhere in the sequence, or do there exist a finite number of pathological examples where the $(n+1)$ -th term is smaller than the $n$ -th term? Surely, this depends on the initial seed of the sequence. For example, under the ""look and say"" operation, $111222\to 3132$ decreases. Is it known whether there are any instances of behavior like this in the sequence where the seed is 1?","['number-theory', 'oeis', 'recreational-mathematics', 'sequences-and-series']"
2593807,"Function notation (domain ""maps to"" range) for a parameterized function","I have a function $f(x; a)$. Note that $x \in \mathbb{R}$ and $a \in \mathbb{R}$. For simplicity, let's say the function is $f(x; a) = ax$. For my use case, it is more convenient to think about $f$ as a function of $x$ that is parameterized by $a$ (as opposed to a function of $x$ and $a$). I'd like to express $f$ using the ""maps to"" function notation. My question is, is it more appropriate to express it as $f : \mathbb{R} \mapsto \mathbb{R}$ or as $f : \mathbb{R^2} \mapsto \mathbb{R}$? I can't find any examples of this notation for a function that also uses ""parameterized by"" notation. My guess is the former, as $f$ is viewed as a function of one variable (that just so happens to be parameterized). However, given discussion in Why do we say function ""parameterized by"" vs just function of (x,y,z,...)? , there is no mathematical difference between writing $f$ as $f(x; a)$ and $f(x, a)$. However, in the latter case one would surely use the function notation $f : \mathbb{R^2} \mapsto \mathbb{R}$. This is the source of my doubt.","['notation', 'functions']"
2593825,Existence of sequence converges in L1 to $f$ but converges to $0$ pointwisely a.e.,"Problem: Show that there a sequence of measurable function $(f_{n})$ such that $f_{n}\geq 0,$ and $f_{n} \to 0$ pointwise a.e., and $\forall f \in C[0,1]$, $$ \lim_{n \to \infty}\int_{0}^{1}f(x)f_{n}(x)dx = \int_{0}^{1}f(x)dx$$ Actually, what I found is that $\int_{0}^{1}f_{n} \to 1$ as $n \to \infty$. Also since $C[0,1]=C_{c}[0,1]$ is dense in $L^{1}$, the above limit holds for every $L_{1}$ function. However, I cannot proceed further. If you have some hint of this question, it will be greatly helpful for my thinking.","['functional-analysis', 'real-analysis']"
2593836,Convergence (rate) of a three term recurrence,"Suppose we have following recurrence relation for a positive real sequence $\{a_n\}$
\begin{align*}
a_{n+1} \le \left(q+\frac {c_1} {n+1}\right) a_n + \frac{c_2}{n} a_{n-1},
\end{align*}
where $c_1$ and $c_2$ are some positive constants and $0 < q < 1$. Will the sequence $\{a_n\}_{n=1}^{\infty}$ stay bounded (or better, converging to $0$)? My intuition is: since there are only finitely many $n$ with $q+c_1/(n+1) > 1$, eventually the sequence will decrease and so converge to $0$. But I haven't come up a rigorous proof. I did some simulation by making the inequality to be equality, it seems like the sequence converges to $0$ even with $q=0.999$. UPDATE: Thanks to @Michael. I got one solution which is based on the observation pointed out by @Michael. He also gave another way to proceed based on this observation (see his answer.) We observe for every $1 > r >0$, for sufficiently large $n$, the recurrence is equivalent to
\begin{align*}
a_{n+1} \le \frac{1+q}{2} a_n + r a_{n-1}.
\end{align*}
Without loss of generality, we may assume for all $n$, above relation holds. Now if we can find some parameters $0<q'<1$ and $c >0$ such that
\begin{align*}
a_{n+1} + c a_n \le q'(a_n + c a_{n-1}),
\end{align*}
it is clear $a_n \to 0$ since the sequence is positive. One choice is putting $q' = \frac{3+q} 4$ and $c=\frac{1-q} 4$. In this case, we can take $r = \frac{(1-q)(3+q)} {16}$. The remaining question is whether it is possible to estimate the rate of convergence. Any comments are welcome. Thanks. UPDATE on convergence rate:
@Michael pointed out some convergence rate when $c_1, c_2$ are sufficiently small. I think if using my method, we could give a convergence rate related to $\varepsilon > 0$. For any $1-q>\varepsilon >0$, there exists $N$ such that $n \ge N$, 
\begin{align*}
a_{n+1} + c a_n \le (q+ \varepsilon) (a_n + c a_{n-1}).
\end{align*}
Let $N'$ be the smallest integer such that $c_1/N' \le \varepsilon$ and $M = \max_{j \le N'} (a_j + c a_{j-1})$.
Then $a_{n+1} \le a_{n+1} + ca_n \le (q+\varepsilon)^{n-N'} M$. Looks like some pseudo linear rate. Could we do better? Any comments will be helpful. Thanks.","['asymptotics', 'optimization', 'analysis', 'upper-lower-bounds']"
2593851,"Representation theory on $\mathbb{Z}^d $, classifying invariant sub-lattices","Suppose that we have a lattice $\mathbb{Z}^d$ and a subgroup $\Gamma$ of $\operatorname{SL}_d (\mathbb{Z})$ acting on it. Assuming the action on $\mathbb{R}^d$ is irreducible, does this tell us anything about the invariant sub-lattices of $\mathbb{Z}^d$ ? In particular, are they all of the form $k\mathbb{Z}^d$ for integers $k$?","['number-theory', 'modules', 'representation-theory']"
2593877,Definition of the generating set of a ring,"I'm currently working my way through the foundations of ring theory (Dummit & Foote), and I am somewhat confused on how to think about the notion of a generating set for a ring. For a group $(\mathcal{G},+,-,0)$ the notion is clear; a subset $G\subseteq\mathcal{G}$ is a generating set for $\mathcal{G}$ iff every element of $\mathcal{G}$ can be expressed as a finite composition of the members of $G$ under addition and negation. This notion still exists canonically in a ring $(\mathcal{R},+,-,\times,0,1)$, however it seems that we may want to consider a second notion as well which specifically leverages the existence of multiplication when trying to simplify the structure of a ring. Specifically, it seems like we can define a generating set for $\mathcal{R}$ as a subset $R\subseteq\mathcal{R}$ such that every element of $\mathcal{R}$ can be expressed as a finite composition of members of $R$ under addition, multiplication and negation. My question is this: Is the latter definition of a generating set for a ring well-known, and if so where can I find some literature on it? In general, the second definition yields a smaller set in order type or sometimes cardinality, and seems like it should still contain much of the information we care about for generating sets. This is easier to see when considering an example: Let $n$ be a natural number, and consider the Grothendieck ring of the limit ordinal $\omega^{\omega^n}$ under natural addition and multiplication, denoted $\mathfrak{G}(\omega^{\omega^n})$, as constructed here [if we set $n=0$ we obtain $\mathfrak{G}(\omega)=\mathbb{Z}$]. Then $$G=\{\omega^\beta\}_{\beta<\omega^n}$$ is a countable generating set for $\mathfrak{G}(\omega^{\omega^n})$ if we only use the group operations $+$ and $-$, however $$R=\{1\}\cup\{\omega^{\omega^\beta}\}_{\beta<n}$$ is a finite generating set for $\mathfrak{G}(\omega^{\omega^n})$ if we allow the usage of $\times$. In the simplest non-trivial case where $n=1$, we have $$G=\{\omega^m\}_{m<\omega},$$ $$R=\{1,\omega\}$$ as the generating sets for $\mathfrak{G}(\omega^\omega)$. When $n=2$ we have $$G=\{\omega^m\}_{m<\omega^2},$$ $$R=\{1,\omega,\omega^\omega\},$$ etc. In each situation it seems that $R$ is much simpler than $G$ and obviously recaptures its members under multiplication, since $$\omega^n\times\omega^m=\omega^{n+m},$$ $$\omega^{m\omega}\times\omega^{n\omega}=\omega^{n\omega+m\omega}=\omega^{(n+m)\omega},$$ and in general the algebraic expressions factor in the expected fashion. This seems to imply that, so long as we know that we have access to a multiplicative structure to work with, the second notion of a generating set is easier to work with than the first.","['abstract-algebra', 'ring-theory', 'reference-request', 'ordinals']"
2593902,"Is the function defined by $f(x+1)=f(x)+f(1), f(2)=1$ just $f(x)=\frac{x}{2}$?","Is the function defined by $f(x+1)=f(x)+f(1), f(2)=1$ just $f(x)=\frac{x}{2}$? I was solving this exercise:
A function $f$ of real variable satisfies $f(x+1)=f(x)+f(1), f(2)=1$ for any $x$. Determine $f(5)$. Well, since $f(2)=f(1)+f(1)=2f(1)$, then $f(1)=\frac{1}{2}$. $f(3)=3f(1)$, then $f(4)=4f(1)$, then $f(5)=5f(1)=\frac{5}{2}$ Then I began wondering if the function was just $f(x)=\frac{x}{2}$.
For the naturals and integers I can prove by induction, since:
$f(1)=\frac{1}{2}$, assuming $f(k)=\frac{k}{2}$, then $f(k+1)=f(k)+\frac{1}{2}=\frac{k}{2}+\frac{1}{2}=\frac{k+1}{2}$. Since $f(-1)=-f(1)$, follows similarly to the integers. But can I prove to the non-integer reals? I don't know how...","['induction', 'functions']"
2593927,Prove that there is only one $y=h(x)$ so that $y+x^2y^3+x+y^5x^4=1$,"Prove that $\forall x\in \mathbb{R}$ there is only one $y=h(x)$ so that 
$$y+x^2y^3+x+y^5x^4=1$$ I am currenty studying multi-variable calculus on my own and I have no clue how to solve this problem. Which results of multi-variable calculus do I have to study to solve it? I would appreciate if someone could solve it or share similiar problems to this one.",['multivariable-calculus']
2593929,$\lim_{n\to\infty} f(t/n)=0$ for every $t$ implies $\lim_{t\to0^+}f(t)=0$ (???),"The question was this: Suppose $f$ is continuous on $(0,\infty)$ and for every $t>0$ $$\lim_{n\to\infty}f(t/n)=0.$$Does it follow that $f(t)\to0$ as $t\to0$ from above? (Evidently it doesn't go without saying: The question is whether the limit exists - of course it equals $0$ if so.) I couldn't believe I didn't know the answer. Of course if $f$ is not continuous one could concoct a counterexample, but. I believe the answer is yes. So the remaining questions are vague: Is this obvious to someone for some reason I don't see? Is it something everybody knows? Edit: Maybe it's not trivial; assuming just $f(t/n)\to0$ for almost every $t$ is not enough. Here's a proof, I think. Suppose not. Then since $f$ is continuous there exist $\epsilon>0$, $t_k\to0$ and $\delta_k>0$ such that $$|f(t)|\ge\epsilon\quad(|t-t_k|<\delta_k).$$ Let $I_k=(t_k-\delta_k,t_k+\delta_k)$ and $$B_k=\bigcup_{n=1}^\infty nI_k,$$where $nS=\{ns:s\in S\}$. Note that if $0<a<b$ and $t_k<b-a$ then $$[a,b]\cap B_k\ne\emptyset.$$ This allows you to find a nested sequence of intervals $[a_n,b_n]$ such that every element of $[a_n,b_n]$ lies in $B_k$ for at least $n$ values of $k$. So by compactness there exists $t$ such that $t$ lies in infinitely many $B_k$; hence $f(t/k)$ does not tend to $0$. Chuckle: An example showing that assuming $f(t/n)\to0$ for almost every $t$ is not enough: Say $t_k\to0$. Choose $\delta_k>0$ so that the $I_k$ are pairwise disjoint and also $$\sum_km((0,A)\cap B_k)<\infty$$for every $A>0$. Let $f$ be a continuous function on $(0,\infty)$ such that $f=0$ everywhere except on $I_k$, where $f$ has a spike of height $1$. Almost every $t$ lies in only finitely many $B_k$, and for every such $t$ we have $f(t/n)\to0$.","['real-analysis', 'calculus']"
2593931,Optimizing a function,"I'm optimizing the sum rate of two users in a communication system.
The problem can be formulated as follows: $\begin{array}{l}
\mathop {\max }\limits_{\alpha ,\rho } {\rm{    }}\left( {1 + \frac{{\left( {1 - \rho } \right)\alpha P{g_1}}}{{\left( {1 - \rho  + \mu } \right){N_0}}}} \right)\left( {1 + \frac{{\left( {1 - \alpha } \right)P{g_2}}}{{\alpha P{g_2} + \left( {1 + \mu } \right){N_0}}} + \frac{{\rho \eta P{g_1}{g_3}}}{{\left( {1 + \mu } \right){N_0}}}} \right)\\
\text{subject to}\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \frac{{\left( {1 - \rho } \right)\left( {1 - \alpha } \right)P{g_1}}}{{\left( {1 - \rho } \right)\alpha P{g_1} + \left( {1 - \rho  + \mu } \right){N_0}}} \ge {T_2} \;\;\;\;\;\;\;\;\;\;\;\; (C1) \\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \frac{{\left( {1 - \rho } \right)\alpha P{g_1}}}{{\left( {1 - \rho  + \mu } \right){N_0}}} \ge {T_1} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; (C2) \\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\ \frac{{\left( {1 - \alpha } \right)P{g_2}}}{{\alpha P{g_2} + \left( {1 + \mu } \right){N_0}}} + \frac{{\rho \eta P{g_1}{g_3}}}{{\left( {1 + \mu } \right){N_0}}} \ge {T_2} \;\;\;\;\;\;\; (C3)\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\ 0 \le \alpha  \le 0.5 \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; (C4)\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\ 0 \le \rho  \le 1 \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; (C5)
\end{array}$ where $P$ is transmitted power, $N_0$ is noise power, ${g_i} = {\left| {{h_i}} \right|^2}$ with $h_i$ is the channel gain, $\mu$, $T_1$, $T_2$ are constants. Without the constraints (C1)-(C3), we can prove that the objective function is maximized at $\alpha = 0$ or 0.5. Then, at $\alpha = 0$, $\rho$ will be 1. In addition, when $\alpha = 0.5$, the objective is a quadratic function, and thus, we can also find the solution analytically. However, with the constraints (C1)-(C3), $\alpha$ and $\rho$ are coupled with each other in new constraints. This makes the problem much more difficult, and we are struggling to solve it. Do you have any suggestions? Thank you very much.","['complex-analysis', 'nonlinear-optimization', 'optimization']"
2593938,How one can prove $\prod_{k=1}^{n-1} (\cos\theta-\cos(k\pi/n)) = 2^{1-n}\sin(n\theta)\csc\theta$?,"Can somebody help me to prove this identity? $$\prod_{k=1}^{n-1} \left(\;\cos\theta-\cos\frac{k\pi}{n}\;\right) = 2^{1-n}\sin(n\theta)\csc\theta$$ I was thinking of using the properties of the complex numbers and the binomial theorem, because I found this problem in the Complex Variables book from Schaum's, but it did not solve my problem. Does anyone have an idea? Thanks in advance!","['complex-analysis', 'trigonometry', 'complex-numbers', 'products']"
2593941,"$n$th Term of the sequence $1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots$ [duplicate]","This question already has answers here : Formula for the $n$th term of $1, 2, 2, 3, 3, 3, 4, 4 ,4, 4, 5, ...$ (4 answers) Closed 6 years ago . Prove that $n$th Term of the sequence $1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots$ is given by $$T_n =\left[\sqrt{2n+\frac{1}{2}}\right]$$ where $[.]$ is Floor function My Try: Its clear that $1$st Term is $1$, $3$rd Term is $2$, $6$th term is $3$ and so on We have Triangular numbers as $1,3,6,10,...$ whose $m$th term is given by $\frac{m(m+1)}{2}$ Hence for the given sequence $$T_{\frac{m(m+1)}{2}}=m$$ Letting $$\frac{m(m+1)}{2}=n$$ we get Quadratic in $m$ as $$m^2+m-2n=0$$ So $m$ takes $\frac{-1\pm \sqrt{1+8n}}{2}$ and since $m$ is a positive integer we have $$m=\frac{-1+\sqrt{1+8n}}{2}$$ hence $$T_n=\frac{-1+\sqrt{1+8n}}{2}$$ how to proceed further?","['algebra-precalculus', 'radicals', 'sequences-and-series', 'ceiling-and-floor-functions']"
2593950,Period of Fibonacci sequence and Lucas number mod p,"Let $p$ be an odd prime and $L_n$ be the $n$th Lucas number. Can anyone prove this?
$$\frac{L_1}{1}+\frac{L_3}{3}+\frac{L_5}{5}+\cdots+\frac{L_{p-2}}{p-2}\neq0\pmod{p}$$
Please help me! I am thinking about the period of Fibonacci sequence. The purpose is to prove that (the period mod $p$) $\neq$ (the period mod $p^2$). It is known that the period mod $p$ divides $p-1$ or $2p+2\ (p\neq5)$. So, I tried to prove $F^{p^2-1}\neq I\ \pmod{p^2}$, where $F$ is the Fibonacci matrix, then I got this inequality. If $p\neq5$, this question is equivalent to prove that
$$\frac{\phi}{1}+\frac{\phi^2}{2}+\frac{\phi^3}{3}+\cdots+\frac{\phi^{p-1}}{p-1}\neq0\pmod{p}.$$
Here, $\phi$ is a root of $x^2-x-1$. See this page . I have showed that
$$\frac{\phi}{1}+\frac{\phi^2}{2}+\frac{\phi^3}{3}+\cdots+\frac{\phi^{p-1}}{p-1}\equiv\sum_{k=1}^{\frac{p-1}{2}} \frac{{(-1)}^k}{2k} {{2k}\choose{k}}\pmod{p}.$$","['number-theory', 'lucas-numbers', 'fibonacci-numbers', 'modular-arithmetic']"
2594006,What's the difference between time-dependent flow (isotopy) and time-independent flow?,"Regarding the fact that both time-independent and time-dependent vector fields correspond with family of diffeomorphisms, i.e. $\{\phi_t | t\in\Re, \phi_t: M\to M\}$, what's the difference between these two families, i.e, time-independent and time-dependent flows (isotopy)?","['manifolds', 'vector-fields', 'differential-geometry']"
2594012,"Prove that $|x-y||z| = |y-z||x| + |z-x||y|$ holds iff $x,y,z,0$ are contained on a circle such that the pairs $x,y$ and $z,0$ seperate each other","In the book of Linear Algebra by Werner Greub, at page 191 Q.3, it is asked that, Prove that $|x-y||z| = |y-z||x| + |z-x||y|$ holds iff  $x,y,z,0$ are
  contained on a circle such that the pairs $x,y$ and $z,0$ seperate
  each other I basically couldn't do much thing but the question is really interesting, and I'm sure that there will be good answers both geometrically and axiomatically. Edit: Note that this is a direct result of Ptolemy-inequality , but still can't see the result. Edit2: Our vector space is a real inner product space.","['normed-spaces', 'inner-products', 'linear-algebra', 'geometry']"
2594022,Convolution of a sequence of L1 function has uniformly convergence.,"Problem: Let $f: \mathbb{R} \to \mathbb{R}$ be bounded uniformly continuous function. And $(K_{n})_{n=1}^{\infty}$ is a sequence of $L^{1}(\mathbb{R})$ function such that $\left\|K_{n}\right\|_{L^{1}} \leq M < +\infty$ $\int_{-\infty}^{\infty}K_{n}(x)dx \to 1$ as $n \to \infty$ $\int_{x:|x|> \delta} |K_{n}(x)| \to 0$ as $n \to \infty$. Then, $K_{n} *f \to f$ uniformly, where $*$ means a convolution. I think I solved this problem, however, I didn't use all conditions I have, especially the condition that $\left\|K_{n}\right\|_{L^{1}}$ is uniformly bounded. Could you check that whether my attempt is right or not? My attempt: Suppose $f\geq 0$. And $||f||_{\infty} <+\infty$ Note that for any $\delta >0$ and any $n \in \mathbb{N}$, $$\int_{-\infty}^{\infty}K_{n}(x)dx = \int_{|x|\leq \delta}K_{n}(x)dx+\int_{x:|x|> \delta} K_{n}(x) $$
  and from the fact $|\int_{x:|x|> \delta} K_{n}(x)| \leq \int_{x:|x|> \delta} |K_{n}(x)|,$ $\int_{x:|x|> \delta} K_{n}(x)$ also converges to $0$, hence
  $$\int_{|x|\leq \delta}K_{n}(x)dx \to 1 \textrm{ as } n \to \infty , \forall \delta>0. $$
  Now from uniform continuity of $f$ and $f\geq 0$, for given $\epsilon>0$, $\exists \delta>0$ such that $$|x-y|<\delta \implies |f(y)-f(x)|<\epsilon \implies -\epsilon +f(x) < f(y) < \epsilon +f(x).$$
  Also, take $N_{1}$ such that $\forall n > N_{1}$, 
   $$\left|\int_{|x|\leq \delta}K_{n}(x)dx - 1\right|< \epsilon \implies 1-\epsilon< \int_{|x|\leq \delta}K_{n}(x)dx<1+\epsilon.$$
  Also, take $N_{2}$ such that $\forall n > N_{2}$,
   $$\left|\int_{x:|x|> \delta} K_{n}(x)\right|< \epsilon.$$
  Now let $N = \max(N_{1}, N_{2})$ Then, for any $x \in \mathbb{R}$ and $\forall n>N$,
  \begin{align*}
|K_{n}*f(x) - f(x)| &=  \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dy+\int_{y:|y|> \delta} K_{n}(y)dy - f(x)\right| \\
& \leq \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dx - f(x)\right| + \left|\int_{y:|y|> \delta} K_{n}(y)dy\right| \\
& \leq \left|(f(x)+\epsilon)(1+\epsilon) - f(x)\right| + \epsilon \\
& \leq \left|\epsilon f(x)+\epsilon(1+\epsilon)\right| + \epsilon \\
& \leq \epsilon(||f||_{\infty}+2+\epsilon)
\end{align*}
  Hence, by letting $\epsilon \to 0$, we can conclude that $K_{n}*f \to f$ uniformly. For general $f$, consider $f=f^{+}-f^{-}$, then each $f^{+}, f^{-}$ is also bounded uniformly continuous function, with the triangle inequality 
$$|K_{n}*f - f| \leq|K_{n}*f^{+} - f^{+}|+|K_{n}*f^{-} - f^{-}| $$
gives the desired result.","['functional-analysis', 'real-analysis', 'convolution']"
2594033,Prove that every edge in a tree is bridge,"I have found this link Which apparently ask same question like me right now.  But, the answers don't provide me information to solve the problem.  Once again, I have read many times about what was discussed in the comments,  but still I don't understand. This one:
@JAEMTO Ok. Suppose there is an edge AB which is not a bridge. Then after removing it there is a path from A to B. That path cannot involve the edge AB because you have just removed it. So how does that give you a contradiction? The theorem may be simple to solve, but somehow I can't proceed how to  prove it. Please help me.  Regards.","['graph-theory', 'discrete-mathematics']"
2594050,How to find the limit:$\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right)$,How to find the limit:$$\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right)$$ I can't think of any way of this problem Can someone to evaluate this? Thank you.,"['summation', 'limits', 'calculus', 'analysis']"
2594060,Prove that a group of order 42 must have a subgroup of order 6,"Prove that a group of order 42 must have a subgroup of order 6. Firstly, I use Sylow's theorem to show there must exist a subgroup of order 7 . What about 6?","['finite-groups', 'group-theory']"
2594085,Criteria of the holomorphic subbundle,"Note that $\mathcal{E} = (E, \bar{\partial}_{\mathcal{E}})$ is a holomorphic vector bundle over complex manifold $X$, where $\bar{\partial}_{\mathcal{E}}$ is a integrable Dolbeault operator on $E$.
Now, I consider a $h_0$-orthogonal projection $\pi \in C^{\infty}(End(E))$, that is $\pi^\ast = \pi = \pi^2$, where $h_0$ is a Hermitian metric on $\mathcal{E}$.
Why the following statement is true: if $\pi$ satisfies 
$$(Id_{\mathcal{E}} - \pi) \circ \bar{\partial}_{\mathcal{E}} \circ \pi = 0,$$
then $F := im(\pi)$ is a holomorphic subbundle on $\mathcal{E}$?","['complex-geometry', 'complex-analysis', 'differential-geometry']"
2594103,A curious Hankel determinant,"Define the sequence  $a_{n}$ by $a_{n}=1$ if $n+1=2^k$ for some $k$ and $a_{n}=0$ else. Computer experiments suggest that the determinant of the Hankel matrix 
$$H_{n+1}:=\begin{pmatrix}
	a_{0} & a_{1} & \dots & a_{n}\\
	a_{1} & a_{2} & \dots & a_{n+1}\\
	\vdots & \vdots & \ddots & \vdots\\
	a_{n} & a_{n+1} & \dots & a_{2n}
      \end{pmatrix}$$
satisfies $$\det{H_{n+1}}=(-1)^\binom{n+1}{2}.$$
Is there a simple way to prove this? Edit: Let $H_{n}=(h(i,j)).$ 
For each $n$  there is a unique permutation of ${(0,1,\dots,n-1)}$ such that the determinant of $H_{n}$ equals $h_{0,p(0)}h_{1,p(1)}\dots h_{n-1,p(n-1)}.$ Let me show this in the following example where for clarity I have set $a(n)=x(n)$ if $n+1$ is a power of $2.$
$$H_{9}=\begin{pmatrix}
	x(0) & x(1) & 0 & x(3) & 0 & 0 & 0 & x(7)& 0\\
	x(1) & 0 & x(3) & 0 & 0 & 0 & x(7) & 0& 0\\
    0 & x(3) & 0 & 0 & 0 & x(7) & 0 & 0& 0\\
    x(3) & 0 & 0 & 0 & x(7) & 0 & 0 & 0& 0\\
	0&0&0&x(7)&0&0&0&0&0\\
0&0&x(7)&0&0&0&0&0&0\\0&x(7)&0&0&0&0&0&0&0\\
    x(7) & 0 & 0 & 0 & 0 & 0 & 0 & 0&x(15)\\
	0 & 0 & 0 & 0 & 0 & 0 & 0 & x(15)& 0
      \end{pmatrix}$$
If we  go from right to left we see that $p(8)=7,p(7)=8.$ Then $p(6)=1,p(5)=2,p(4)=3,p(3)=4,p(2)=5,p(1)=6.$ There remains $p(0)=0.$ In general the same procedure works.
Thus my question reduces to a proof of the fact that the sign of this permutation is $(-1)^\binom{n}{2}.$","['combinatorics', 'determinant']"
2594205,Kullback-Leibler divergence of two Laplace distributions with different parameters,"Let the Kullback-Leibler (KL) divergence of two distributions $p(x)$ and $q(x)$ be defined as $D(P||Q) = E_p(\log p(x) - \log q(x))$ Let $p(x) \sim \text{Laplace}(\mu_1, b_1)$ and $q(x) \sim \text{Laplace}(\mu_2, b_2)$ then $
\begin{align}
D(P||Q) &= E_p(\log p(x) - \log q(x)) \\
&= E_p\left( \log \frac{b_2}{b_1} - \frac{|x-\mu_1|}{b_1} + \frac{|x-\mu_2|}{b_2}\right)\\
&= \log \frac{b_2}{b_1} 
- \frac{1}{b_1}E_p|x-\mu_1|
+ \frac{1}{b_2}E_p|x-\mu_2|\\
\end{align}
$ The first term is a constant. The second term is the median divided by $b_1$ ( IM NOT SURE ABOUT THIS STEP ) The third term is given by $b_1/b_2$, because if $X\sim\text{Laplace}(\mu_1,b_1)$ then $X-c\sim\text{Laplace}(\mu_1-c,b_1)$ from which follows that $|X-c|\sim\text{exp}(b_1^{-1})$ Hence the Kullback-Leibler divergence of two Laplace distributions is given by $
\begin{align}
D(P||Q) &= E_p(\log p(x) - \log q(x)) \\
&= \log \frac{b_2}{b_1} 
- 1
+ \frac{b_1}{b_2}
\end{align}
$ I couldnt find the correct answer anywhere online so I was wondering if anyone here knows the right answer.",['statistics']
2594235,Count the integer solutions of $x_1+x_2-x_3+x_4-x_5=3$,"I am asking for help with solving this exercise: Find the count of possible integer solutions for equation: $$x_1+x_2-x_3+x_4-x_5=3$$ There are restrictions for possible values of $x$: $$
\begin{aligned}
&0 < x_1 \le 6\\
-&8 \le x_2 < -2\\
&x_3 \le 1\\
&3 < x_4\\
&2 \le x_5 \le 8
\end{aligned}
$$ Note: We should be able to find the count of solutions by using permutations and Inclusion-Exclusion principle.","['combinations', 'combinatorics', 'inclusion-exclusion']"
2594277,intuition behind cyclicality of the trace?,"The trace of a matrix product is ""commutative"" (i.e. cyclical):
$$\operatorname{trace}(AB)=\operatorname{trace}(BA)$$ I know how to prove this. I was wondering, are there any intuitive ways to understand why this must be true? One reason why I don't see it intuitively is that I don't really understand intuitively what the trace represents (e.g. geometrically).","['matrices', 'intuition']"
2594357,"A closed convex set in a separable normed space is an intersection of closed regions, defined by hyperplanes","Let $X$ be a separable normed space and $K$ closed convex subset of $X$. Prove that for some $(x_n^{\star})\subset X^\star$ and $(\lambda_n)\subset \mathbb{R}$ we have $\displaystyle K=\bigcap_{n=1}^{\infty}L_n$, where $L_n=\{x\in X: x_n^\star(x)\leq \lambda_n\}.$ Attempt. Since X is separable and $X\setminus K$ is open, we have 
$X\setminus K=\bigcup_{n=1}^{\infty}B(x_n,\epsilon_n)$ for some $x_n\in X,~\epsilon_n>0.$ By the separation theorem, for all $n$ we have $$\sup_{x\in K}x_n^\star(x)\leq \inf_{x\in B(x_n,\epsilon_n)}x_n^\star(x)$$
for some $x_n^\star\in X^\star$ and set $\displaystyle \lambda_n=\inf_{x\in B(x_n,\epsilon_n)}x_n^\star(x)$. Then for $L_n=\{x\in X: x_n^\star(x)\leq \lambda_n\}$, if $x\in K$ then $\displaystyle x_n^\star(x)\leq \sup_{x\in K}x_n^\star(x)\leq\lambda_n$ and $x\in L_n$ for all $n$. If $x\notin K$, then $x\in  B(x_n,\epsilon_n)$ for some 
$n$ and $x_n^\star(x)\geq \lambda_n$. This is where I am stuck : we would like to have $x_n^\star(x)>\lambda_n$, so $x\notin L_n$ for this $n$. But i don't seem to able to prove this. Thanks in advance for the help.","['functional-analysis', 'real-analysis', 'separation-axioms']"
2594373,The following set is connected or not?,"Let $E$ be a complex Hilbert space and $S\in \mathcal{L}(E)^+$ (i.e.$S^*=S$ and $\langle Sx\;, \;x\rangle\geq0$ for all $x\in E$). Let $U=\{x\in E; \langle Sx\;, \;x\rangle=1\}$. Is $U$ a connected set? Thank you.","['functional-analysis', 'general-topology', 'hilbert-spaces']"
2594409,Is the function T $\mathbb R$-linear?,"Let $T:\mathbb R^2\to \mathbb R^2$ be a mapping such that $T(C)$ is a convex set in $\mathbb R^2$ whenever $C$ is convex set in $\mathbb R^2$ and $T(0,0)=(0,0).$ Is $T$ $\mathbb R$-linear? We have to show here that $T(ax+by)=aT(x)+bT(y)$ for all $a,b\in \mathbb R$ and $x,y\in \mathbb R^2.$ Any help is appreciated. Thank you.",['linear-algebra']
2594431,What is the point of non-commutative probability?,"I read this article by Terry Tao about non-commutative probability. I honestly don't really get it. Apparently, we can generalize Kolmogorov's system of probability theory, in such a way that it is no longer ""commutative"" (I wasn't even aware that probability theory is ""commutative"", and I'm not sure why it is. Does it mean that for two random variables $X$ and $Y$, $E(XY)=E(YX)$?). Could you explain what the point is of non-commutative probability? What makes Kolmogorov's system commutative, and what makes non-commutative probability non-commutative? Why would we want to drop commutativity? Are there simple examples of things we can understand with non-commutative probability theory, that we cannot understand with Kolmogorov's system? Edit: here is another article on the topic , one I also don't really get as it goes into quantum mechanics. But it makes the confusing but enticing statement that: ""Although noncommutative spaces don’t have a good notion of point, quantum probability spaces suggest that they have a good notion of measure (which we can think of as a “smeared-out” point"", and talks about "" random algebra's "".","['probability-theory', 'noncommutative-algebra']"
2594442,Find the range of $f(x)=11\cos^2x+3\sin^2x+6\sin x\cos x+5$,I'm trying to solve this problem. Find the range of $f(x)=11\cos^2x+3\sin^2x+6\sin x\cos x+5$ I have simplified this problem to $$f(x)= 8\cos^2x+6\sin x\cos x+8$$ and tried working with $g(x)= 8\cos^2x+6\sin x\cos x$. I factored out the $2\cos x$ and rewrote the other factor as a linear combination of cosine. It reduces down to $$g(x)=10\cos x\cos\left(x-\tan^{-1}\frac{3}{4}\right)$$ But then I'm stuck here. Please help me. Perhaps there's a different way to approach this?,"['maxima-minima', 'trigonometry', 'functions']"
2594563,Infinite geometric sum (asking for insight on an easier solution),"Let the sequence $F$ be defined as: $F_1=F_2=1$ and $F_n=2F_{n-1}+F_{n-2}$, for $n>2$. Evaluate $\sum_{n=1}^{\infty}\frac{F_n}{10^n}$. The obvious solution involves solving for the explicit formula for $F$ (using the standard linear recurrence technique): $F_n=(\frac{\sqrt{2}-1}{2})(1+\sqrt{2})^n-(\frac{\sqrt{2}+1}{2})(1-\sqrt{2})^n$. Then we can just split the sum into two infinite geometric series. The computation is annoying, but nonetheless straightforward. I was wondering if there is any easier solution than solving for an explicit formula for $F$. Maybe there is one that only needs the recursive definition? Any comments are appreciated.","['generating-functions', 'contest-math', 'summation', 'sequences-and-series']"
2594588,How did they get this equation comparing three ratios?,"I was reading from an old maths textbook. It was giving some examples on how to solve ratios. I stumbled upon this example and felt perplexed after reading only part of it. We're given this equation. $$\frac{x}{l(mb+nc-la)} = \frac{y}{m(nc+la-mb)} = \frac{z}{n(la + mb - nc)}$$ And asked to prove that $$\frac{l}{x(by + cz - ax)} = \frac{m}{y(cz+ax-by)} = \frac{n}{z(ax + by -cz)}$$ He starts by doing this: $$\frac{\frac{x}{l}}{mb + nc - la} = \frac{\frac{y}{m}}{nc + la - mb} = \frac{\frac{z}{n}}{la + mb -nc}$$ Which I understand. Then, he goes on to say this: We have $$\frac{\frac{x}{l}}{mb + nc - la} = \frac{\frac{y}{m}}{nc + la - mb} = \frac{\frac{z}{n}}{la + mb -nc}$$ $$= \frac{\frac{y}{m} + \frac{z}{n}}{2la}$$ These are similar expressions. $$\therefore  \frac{ny + mz}{a} = \frac{lz + nx}{b} = \frac{mx + ly}{c}$$ This is the portion of the proof that I don't understand. How did he go from $= \frac{\frac{y}{m} + \frac{z}{n}}{2la}$ to $\frac{ny + mz}{a} = \frac{lz + nx}{b} = \frac{mx + ly}{c}$ ? And, also, what does he mean by these are ""similar expressions."" The textbook I'm reading is called Higher Algebra a Sequel to Elementary Algebra for Schools by Henry Sinclair and Samuel Ratcliff Knight. Thanks for the help.","['algebra-precalculus', 'ratio']"
2594625,Is there a rule for $\cos^{-1}(\cos(a)\cos(b))$,"When working with spherical coordinates I have come across
$$\cos^{-1}(\cos(a)\times \cos(b))$$
and was wondering if there was some kind of identity for this that I could use instead of computing the inside of the acrccos function first.",['trigonometry']
2594633,The integer part of a sequence,"I was trying to solve the following sum: $$a_1=\sqrt[3]{24}$$ $$a_{n+1}=\sqrt[3]{(a_n+24)},n\ge1$$ $Find\,the\,integer\,part\,of\,a_{100}$ Source: ISI B Math 2012 paper I proceeded in this manner: $$a_1^3=24$$ $$a_2=\sqrt[3]{a_1+a_1^3}$$ $$a_2^3=a_1+a_1^3$$ similarly, $$a_3^3=a_2+a_1^3=a_1+2a_1^3$$ $$a_4^3=a_1+3a_1^3$$ $$\ldots$$ $$a_{100}^3=a_1+99a_1^3$$ Which should give me the answer,
But I am encountering a dilemma in the part where I have to bring down the number to its third root before applying the greatest integer function.
Would appreciate a bit of help with this/ a new method of doing the same.",['sequences-and-series']
2594653,Applications of the Binomial transform.,"I have recently encountered the Binomial transform: The binomial transform, $T$, of a sequence, ${a_n}$, is the sequence ${s_n}$ defined by $$   s_{n}=\sum _{k=0}^{n}(-1)^{k}{n \choose k}a_{k}  $$ This transformation has the neat property that it's self inverse. I am now trying to find some simple applications or exercise on this particular tool. Can it be used à la Fourier Transform applying it to both sides of an equation to simplify calculations and then inverting it back one finds the solution? Or really any application would be interesting to me.","['real-analysis', 'sequences-and-series']"
2594739,Why does $\lim_{k\to\infty} \sqrt[k] {\big | \frac{k^{1/k}-1}{2^k}\big |} = 1/2$?,"$$\lim_{k\to\infty} \sqrt[k] {\left | \frac{k^{1/k}-1}{2^k}\right |} = \frac12$$ according to a solution I have, but I get the limit to equal zero. How come it goes to $\frac12$?","['sequences-and-series', 'calculus', 'limits']"
2594785,Prove that the square of any odd number is equal to a multiple of $8$ plus $1$,"Given the following problem: Prove that the square any odd number is equal to a multiple of $8$ plus $1$: Using congruence. Applying the division algorithm. I believe that the square of an odd number would be represented by $(2k_1-1)^2$ and based on the problem, it appears to be stating that; $(8k_2+1)$ divides $(2k_1-1)^2$. Therefore, for the first part of the problem ( 1. ), would it be $(2k_1-1)^2\equiv0\mod{(8k_2+1)}$? If not how can I interpret and solve this problem including the second part?","['congruence-relations', 'discrete-mathematics']"
2594831,"How to evaluate $\int_{13}^\infty \frac{x+1}{x^3+x} \, dx$","I have to calculate this integral: $$\int_{13}^\infty \frac{x+1}{x^3+x} \, dx$$ Now the indefinite integral of the integral above: $$\arctan(x)+\ln(x)-\frac{1}{2}\ln(x^2+1)+C$$ which I have to calculate, so I could calculate the definite integral, is correct. I checked it on Wolfram Alpha. However Wolfram is also telling me that the value of the my definite integral is around: 0.07972. And that's the problem. More below. Here is the indefinite integral, modified so I can just put the values 13 and $\infty$ in and get the result: $$\lim_{x\to \infty}\left(\arctan(x)+\ln(x)-\frac{1}{2}\ln(x^2+1)\right)-\left(\arctan(13)+\ln(13)-\frac{1}{2}\ln(13^2+1)\right)$$ However In the left part of the integral above (the one with limit), when I put infinity into both logarithms there, I'll get $$\ln(\infty) - \frac{1}{2}\ln(\infty^2+1)=\infty - \infty.$$ But from what I know from school, that is undefined expression. I also noticed, that if I'll ignore the infinities created by logarithms in the integral below, I'll get the exact same number, that is acording to Wolfram, the value of my integral. So is this some special case, where I can says that $\infty - \infty = 0$ or is there more to it? Thanks for answers. And sorry if you had hard time reading this, English isn't my mother tongue.","['improper-integrals', 'integration', 'infinity', 'analysis']"
2594859,Completing the square in $N$ dimensions,"This is very important for Bayesian methods in statistics, but I haven't been able to find a reference which specifically touches on my situation. Assume all matrices and vectors below are matrices and vectors with all real entries. All boldface lowercase letters are column vectors, and boldface uppercase letters are matrices (including the lowercase and uppercase Greek letters). In the below, $\mathbf{y}$,  $\boldsymbol\theta$ (with any subscripts), and $\boldsymbol\mu$ are column vectors; $\mathbf{X}$,  $\boldsymbol\Sigma$ (with any subscripts) are matrices; and $c$ is a scalar in $\mathbb{R}$. $\mathbf{X}^{\prime}$ denotes the transpose of a matrix $\mathbf{X}$. I have a sum of two quadratic forms
  $$(\mathbf{y}-\mathbf{X}\boldsymbol\theta)^{\prime}\boldsymbol\Sigma_{\boldsymbol\eta}^{-1}(\mathbf{y}-\mathbf{X}\boldsymbol\theta)
 + (\boldsymbol\theta-\boldsymbol\theta_0)^{\prime}\boldsymbol\Sigma^{-1}_0(\boldsymbol\theta-\boldsymbol\theta_0)\tag{1}$$
  which I would like to write in the form 
  $$(\boldsymbol\theta-\boldsymbol\mu)^{\prime}\boldsymbol\Sigma^{-1}(\boldsymbol\theta-\boldsymbol\mu)
 + c\tag{2}$$ I don't care what $c$ is. What I'm mainly interested in is what $\boldsymbol\mu$ and $\boldsymbol\Sigma$ are. After a lot of work, I was able to write the parts of $(1)$ which depend on $\boldsymbol\theta$ in the following form (remember, I don't care about $c$): 
$$\boldsymbol\theta^{\prime}(\mathbf{X}^{\prime}\boldsymbol\Sigma^{-1}_{\boldsymbol\eta}\mathbf{X}+\boldsymbol\Sigma_0^{-1})\boldsymbol\theta-\boldsymbol\theta^{\prime}(\mathbf{X}^{\prime}\boldsymbol\Sigma_{\boldsymbol\eta}^{-1}\mathbf{y}+\boldsymbol\Sigma_0^{-1}\boldsymbol\theta_0)-(\mathbf{y}^{\prime}\boldsymbol\Sigma_{\boldsymbol\eta}^{-1}\mathbf{X}+\boldsymbol\theta_0^{\prime}\boldsymbol\Sigma_0^{-1})\boldsymbol\theta\tag{3}$$
You should assume that all $\boldsymbol\Sigma$ matrices, regardless of the subscript, are symmetric and positive definite. How can I write $(3)$ in the form $(2)$? I would really appreciate an explanation of how the procedure works in general.","['matrices', 'bayesian', 'linear-algebra', 'completing-the-square']"
2594875,Solve $y^{(4)}-2y^{(3)}+2y'-y=xe^x.$,"Solve $y^{(4)}-2y^{(3)}+2y'-y=xe^x.$ The characteristic equation is $(r-1)^3(r+1)\Rightarrow y_h=(C_1+C_2x+C_3x^2)e^x+C_4e^{-x}.$ The problem is the particular equation. Why doesn't it work with the ansatz $$y=(ax+b)e^x?$$ I get \begin{array}{lcl}
y        & = & e^x(ax+b) \\
y'       & = & e^x(a(x+1)+b)\\
y''      & = & e^x(a(x+2)+b)  \\
y^{(3)}  & = & e^x(a(x+3)+b)  \\
y^{(4)}  & = & e^x(a(x+4)+b)
\end{array} Setting these in i get $$e^x[((a(x+4)+b))-2((a(x+3)+b))+2(e^x(a(x+1)+b))-(e^x(ax+b))] = e^x\cdot 0=0.$$ So this doesn't work. Is it because I already have corresponding powers of $x$
in the homogenous solution? How can i fix my ansatz?","['ordinary-differential-equations', 'calculus']"
2594884,Elementary proof of transformations of domino tilings.,"There is a theorem that says you can transform one tiling by dominoes of a figure without holes to another by a sequence of flips (rotating pairs of dominoes that share a long edge.) The usual proof (see for example this question ) uses ""height functions"" and some algebra; I am trying to construct a proof without using those tools, and I am nearly there. The last bit that remains is to prove that every closed path of cells without holes on a square lattice has four consecutive cells that form a square, called a knob . This seems very obvious, but I cannot come up with a proof of this fact. In this figure, there are two knobs (marked yellow and pink). My question is: how can I prove every path without holes has a knob? Edit: My original idea was to use the idea of a knob to get a way to do induction on certain types of paths. However, the proof we came up with is itself an induction proof, and I could use the method directly instead of needing to use knobs. I also discovered a few problems with my original proof plan (although the overall strategy stayed in tack. I removed some of the details I had here originally (mostly because they are wrong and not very insightful otherwise). To see how this fits into my proof, here is a sketch. A strip polyomino is a polyomino whose cells form a path. A closed strip is a strip polyomino whose cells form a closed path. A closed strip has at least two tilings ($\{c_1, c_2\}, \{c_3, c_4\}$, etc. and $\{c_n, c_1\}, \{c_2, c_3\}$,  etc.). If we have a tiled figure, and a subfigure which is a tiled closed strip, then replacing the closed strip's tiling with the dual tiling is called a strip rotation . (A flip is a special case of a strip rotation). 1. We can get one tiling of any figure from another by strip rotations. Pick any cell $c_1$ covered by dominoes in different ways in the two tilings, and construct a closed strip by picking a neighbor $c_2$ in the same domino in the one tiling, then a neighbor $c_3$ of $c_2$ within the same domino in the other tiling, etc. This must end when the next neighbor is $c_1$. (It's always possible to pick a next cell, and we can never pick a next cell again before picking $c_1$, and the figure is finite.) Now performing a strip rotation on this strip makes all the tiles match the second tiling. We repeat the process until the transformed tiling matches the second tiling completely. (Notice that in constructing the strip we never pick patches where dominoes in the two tilings match, so we will never ""undo"" dominoes already in place.) 2. A strip rotation of a strip without holes is equivalent to a sequence of flips. This is the part that requires induction. The idea is to show it for paths that correspond to a flip (rotating two dominoes) as the base case, and then to show that a path always contains a smaller path, and that with a flip of the rest and a rotation on the smaller path, we get a rotation on the bigger path. (There are a few cases here to consider.) 3. A strip rotation of a closed strip with a filled interior is equivalent to a series of flips. The idea here is to inductively add dominoes of the path's interior to the path, at times doing flips, and at times shedding dominoes from the path, until we are left with a bunch of paths that correspond to strip polyominoes without holes. Here is a simple example: We then perform strip rotations on some of these (some may already be ""in position""), which we already proved is equivalent to flips, to get the original path rotated, but potentially part of its interior too. We then rotate the interior (or each path thereof), so that the interior is back the way it started. We are left with only the outer path rotated. By combining 1 and 3, we arrive at the result: One tiling of a figure without holes can be transformed to another with a sequence of flips .","['discrete-geometry', 'general-topology', 'tiling']"
2594887,Show that any normal subgroup is of form $Ker \chi$ for some $\chi \in Char(G)$.,"$\textbf{The question is as follows:}$ Let $G$ be a finite group and $N$ a normal subgroup of $G$. $\rm a)$ Show that $N$ is of the form $ker \xi$ for some $\xi \in Char(G)$. $\rm b)$ In $a)$, can one always take $\xi$ to be irreducible? $\textbf{Some attempt:}$ $\rm a)$ Let $G$ be a finite group and $N \unlhd G.$ Consider then the quotient group $\frac{G}{N}$ and its associated group algebra $A(\frac{G}{N})$. We define then $\rho : G \to A(\frac{G}{N})$ by $(\rho_g(f))(hN) : = f(hNgN)= f(hgN) $. This is a representation since 
$$(\rho_{g_1 g_2 }(f))(hN) = f(hNg_1 g_2 N) = f(hg_1 g_2 N)$$
$\hspace{10.44cm} =f(h g_1 N g_2 N)$ $\hspace{10.44cm} = \rho_{g_2} (f) (hg_1 N)$ $\hspace{10.44cm} = \rho_{g_2} (f) (h N g_1 N)$ $\hspace{10.44cm} = (\rho_{g_1} (\rho_{g_2} (f)))(hN) $ Moreover, it's evident that $N \subseteq Ker \rho$ and moreover if $g \in Ker \rho$, one has then $\rho_g(\delta_N) = \delta_N$ and so in particular $1 = \delta_N (N) = \delta_N(gN)$ and so $N = gN$ and this implies that $g \in N$. It follows that if $\chi_{\rho}$ is the associated character of $\rho$ then $Ker \chi = N.$ So there exists some character $\chi$ of $G$ for which $N = Ker \chi$. $\rm b)$ About this I think not necessarily. But I am not sure! Can someone please let me know if I am wrong and to give me a precise answer?(And even I am not sure about $a)$ also!) Thanks!","['finite-groups', 'abstract-algebra', 'group-theory']"
2594895,How to evaluate sums in the form $\sum_{k=-\infty}^\infty e^{-\pi n k^2}$,"Online, one may find the values of the following sums:
$$\sum_{k=-\infty}^\infty e^{-\pi k^2}=\frac{\pi^{1/4}}{\Gamma(3/4)}$$
$$\sum_{k=-\infty}^\infty e^{-2\pi k^2}=\frac{\pi^{1/4}(6+4\sqrt 2)^{1/4}}{2\Gamma(3/4)}$$
$$\sum_{k=-\infty}^\infty e^{-3\pi k^2}=\frac{\pi^{1/4}(27+18\sqrt 3)^{1/4}}{3\Gamma(3/4)}$$
Can someone show me how to prove at least one of these? I've already tried using the reside theorem but had no luck with that.","['summation', 'sequences-and-series', 'theta-functions']"
