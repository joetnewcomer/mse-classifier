question_id,title,body,tags
108270,What is the equation of an ellipse that is not aligned with the axis?,"I have the an ellipse with its semi-minor axis length $x$, and semi major axis $4x$.  However, it is oriented $45$ degrees from the axis (but is still centred at the origin).  I want to do some work with such a shape, but don't know how to express it algebraically.  What is the equation for this ellipse?","['geometry', 'conic-sections']"
108271,"Eigenvalues and eigenfunctions for the Fredholm integral operator $K(g) = \int_0^1 e^{x t} g(t) \, dt$.","I would like to compute the eigenvalues and eigenfunctions for the Fredholm integral operator $$K(g) = \int_0^1 e^{xt} g(t) \,dt.$$ The sources I've checked* seem to say that the process is fairly involved.  Has anything been published on this kernel?  Or, if not, am I correct that it's going to be a hard thing to do? * See, e.g., equations (12) and on here: https://www.encyclopediaofmath.org/index.php/Fredholm_equation","['functional-analysis', 'integral-equations', 'analysis']"
108273,Convergent sequence of sets,"How to show that $\{E_n\}$ is a convergent sequence if and only if there is no point $x\in X$ such that $x\in E_n$, $x\in X - E_m$ hold for infinitely many $n$ and infinitely many $m$.","['convergence-divergence', 'elementary-set-theory']"
108284,Example of a closed subspace of a Banach space which is not complemented?,"In this post, all vector spaces are assumed to be real or complex. Let $(X, ||\cdot||)$ be a Banach space, $Y \subset X$ a closed subspace. $Y$ is called $\underline{\mathrm{complemented}}$, if there is a closed subspace $Z \subset X$ such that $X =Y \oplus Z$ as topological vector spaces. If $H$ is a Hilbert space every closed subspace $Y$ is complemented; the orthogonal complement $Y^{\bot}$ is a closed subspace of $H$ and we have $H=Y \oplus Y^{\bot}$. A famous theorem of Lindenstrauß and Tzafriri (which can be found in their article ""On the complemented subspaces problem"", Isreal Journal of Mathematics, Vol. 9, No.2, pp. 263-269) asserts that the converse is true as well. More precisely, if $(X, ||\cdot||)$ is a Banach space such that every closed subspace is complemented then $||\cdot||$ is induced by a scalarproduct, i.e. $(X,||\cdot||)$ is a Hilbert space. Now to my question. Can you give me an example of a Banach space $(X,||\cdot||)$, which is not a Hilbert space, and of a closed subspace $Y \subset X$ which is not complemented? It is easily seen that $Y$ must be both infinite-dimensional and infinite-codimensional, for every finite-dimensional and every (closed) finite-codimensional subspace is complemented. I thought about something like $c_{0} \subset (\ell^{\infty}, ||\cdot||_{\infty})$ the closed subspace of null sequences in the Banach space of bounded sequences but couldn't produce a proof that no closed complement exists in that case. Can you help me either proving that $c_{0}$ is not complemented (if that's true at all) or by giving me a different example?","['functional-analysis', 'banach-spaces']"
108288,"Infinite tetration, convergence radius","I got this problem from my teacher as a optional challenge. I am open about this being a given problem, however it is not homework. The problem is stated as follows. Assume we have an infinite tetration as follows $$x^{x^{x^{.^{.^.}}}} \, = \, a$$ With a given $a$ find $x$ . The next part of the problem was to discuss the convergence radius of a. If a is too big or too small the tetration does not converge. Below is my humble stab at the problem. My friend said you would have to treat the tetration as a infinite series, and therefore could not perform algebraic manipulations on it before it is know whether it converges or diverges. However my attempt is to first do some algebraic steps, then discuss the convergence radius. I) Initial discussion At the start it is obvious that the tetration converges when $a=1$ (just set $x=1$ )
Now after some computer hardwork it seems that the tetration fails to converge when a is roughly larger than 3. II) Algebraic manipulation $$ x^{x^{x^{.^{.^.}}}} \, = \, a$$ This is the same as $$ x^a \, = \, a$$ $$ \log_a(x^a) \, = \, \log_a(a)$$ $$ \log_a(x) \, = \, \frac{1}{a}$$ $$ x \, = \, a^{\frac{1}{a}}$$ Now, if we let $a=2$ then $x = \sqrt{2}$ . After some more computational work, this seems to be correct, which makes me believe this formula is correct. III) Discsussion about convergence By looking at the derivative of $ \displaystyle \large a^{\frac{1}{a}} $ we see that the maxima occurs when $a=e$ , which also seems to correspond to the inital computational work.
Now I think, that the minima of $\displaystyle \large a^{1/a}$ is zero by looking at its graph, studying its derivative and the endpoints. So that my ""guess"" or work shows that it converges when $$ a \in [0 \, , \,  1/e] $$ VI) My questions Can my algebraic manipulations be justified? They seem rather sketchy
taking the a`th logarithm and so on . (Although they seem to ""magically""
give out the right answer) By looking at Wikipedia it seems that the tetration converge when $$ a \in \left[ 1/e \, , \, e \right] $$ This is almost what I have, why is my lower bound wrong? How can  I find the correct lower bound?","['exponentiation', 'convergence-divergence', 'real-analysis', 'tetration']"
108290,Dimension of its irreducible components in Elimination Theory.,"There is a small result I don't understand. To preface, for an algebraic variety $V\subset\mathbb{A}^n$ over some field $F$, one defines $\dim V=\operatorname{trdeg}(F(x)/F)$ for a generic point $(x)$ of $V$. Also, I denote by $V(f_1,\dots,f_r)$ the set of zeroes in $\mathbb{A}^n$  of some homogeneous forms $f_i$ in $F[X]$. As an algebraic set, we know $V(f_1,\dots,f_r)$ can be written as a finite union of irreducible components without inclusion relations. Now let $M(f_1,\dots,f_r)$ be the maximum of the dimensions of the irreducible components. Apparently for any nonnegative $d$, the set of points $(f_1,\dots,f_r):=(w)_f$ where $M(f_1,\dots,f_r)>d$ is also an algebraic set. I identify the points $(f_1,\dots,f_r)$ as a subset of $\mathbb{A}^n$ in the following way. For a finite set of forms $(f)=(f_1,\dots,f_r)$, let $d_1,\dots,d_r$ be the degrees, with $d_i\geq 1$ for all $i$. Each $f_i$ can be written as
$$
f_i=\sum w_{i,(v)}M_{(v)}(X)
$$
where $M_{(v)}(X)$ is a monomial in some set of indeterminates $(X)$ of degree $d_i$, and $w_{i,(v)}$ is a coefficient. Let $(w)=(w)_f$ be the point obtained by arranging the coefficients $w_{i,(v)}$ in some definite order, and consider this point in some affine space $\mathbb{A}^n$, where $n$ is the number of coefficients, determined by the degrees $d_1,\dots,d_r$. So given such degrees, the set of all forms $(f)=(f_1,\dots,f_r)$ with these degrees is in bijection with the points of $\mathbb{A}^n$. So if given a fixed $d\geq 0$, then why is the set of $(f_1,\dots,f_r):=(w)_f$ such that $M(f_1,\dots,f_r)>d$ an algebraic set? So given $d\geq 0$, I want to find all sets of forms $f_1,\dots,f_r$ such that the maximum dimension of the irreducible components of their set of zeroes in $\mathbb{A}^n$ has degree greater than that fixed $d$. Then for each possible set of forms meeting that condition, I identify with a point in $\mathbb{A}^n$ as described above. Why are those points in $\mathbb{A}^n$ an algebraic set?","['commutative-algebra', 'algebraic-geometry']"
108296,Polynomial in $\mathbb{Q}[x]$ sending integers to integers?,"We can view the binomial coefficient $\binom{x}{k}$ has a polynomial in $x$ with degree $k$. So taking some $f\in\mathbb{Q}[x]$, why is $f(n)\in\mathbb{Z}$ for all $n\in\mathbb{Z}$, precisely when the coefficients of $f$ are integers with respect to the basis $\{\binom{x}{k}\mid k\in\mathbb{N}\}$? The reverse direction seems clear, so I wonder why the opposite implication is also true. I did notice that all the roots of $\binom{x}{k}$ are just $0,\dots,k-1$. Can we factor the polynomial is some nice way to reveal the opposite conclusion? Thanks.","['polynomials', 'binomial-coefficients', 'combinatorics']"
108302,Are functions of uncorrelated random variables still uncorrelated?,"Suppose $X$ and $Y$ are real-valued random variables, and $f$ and $g$ are Borel measurable real-valued functions defined on $\mathbb{R}$. If $X$ and $Y$ are independent, then I know that $f(X)$ and $g(Y)$ are also independent. If $X$ and $Y$ are uncorrelated, are $f(X)$ and $g(Y)$ also uncorrelated? Thanks and regards!",['probability-theory']
108306,Being isomorphic as representations of a group G,"Let $G$ be a finite group. What is meant by two finite dimensional vector spaces (over $\mathbb{C}$) $V$ and $W$ being ""isomorphic as representations of $G$""? To show that we have such an isomorphism, wouldn't it suffice to just show that $\dim V = \dim W$?","['linear-algebra', 'representation-theory', 'terminology']"
108308,Apostol proof divides by zero?,"The following is a proof from Apostol's linear algebra book that $\{1,t,t^{2},...\}$ is independent. To my eye, he's dividing by zero repeatedly. Is this really as huge an error as it seems, or are there missing details that would make this rigorous? It suffices to show that for each $n$ the $n+1$ polynomials $1,t,...,t^{n}$
are independent. If these polynomials span the zero polynomial we
have $$\sum_{k=0}^{n}c_{k}t^{k}=0$$ for all real $t$. Putting $t=0$ we see that $c_{0}=0$. Now divide
by $t$ and put $t=0$ again to find $c_{1}=0$. Repeating the process
we find every $c_{k}$ is $0$, so $1,t,...,t^{n}$ are independent. Edit : I'm treating ""polynomial"" as a garden-variety function from $\mathbb{R}$ to $\mathbb{R}$, and it seems like that may be part of my problem.",['linear-algebra']
108325,Is $\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x)$? [unsolved (even though we earlier thought it was)],"Fix the algebraic closure of $\mathbb{Q}((x))$ for this question to make sense. I know that $\mathbb{Q}((x)) \cap \overline{\mathbb{Q}(x)}$ has elements that are not in $\mathbb{Q}(x)$ (in analogy to the ""algebraic p-adics""). So I wondered, if we intersect with something even smaller, $\bar{\mathbb{Q}}(x)$, would then the result be $\mathbb{Q}(x)$? More neatly, does $\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x)$?","['field-theory', 'abstract-algebra', 'number-theory']"
108331,Are the logarithms in number theory natural?,"I find the frequent emergence of logarithms and even nested logarithms in number theory, especially the prime number counting business , somewhat unsettling. What is the reason for them? Has it maybe to do with the series expansion of the logarithm? Or is there something inherently exponential in any of the relevant number distributions, like in complexity theory or combinatorical problems? I think maybe in how you can construct bigger integers out of smaller ones.","['prime-numbers', 'logarithms', 'number-theory', 'combinatorics']"
108343,Limit for gamma function,"How can I prove that $$\displaystyle \Gamma(z)=\lim_{n \to \infty} \displaystyle \int_0^n \left( 1-\frac{t}{n}\right)^n  t^{z-1}\ \text{d} t\;=\displaystyle \int_0^{\infty} e^{-t}  t^{z-1}\ \text{d} t\;$$ Issue is how can I prove that the order of the limit and the integral can be changed. I know about the dominated convergence theorem and the monotone convergence theorem, but the additional problem here is that the integration limit itself depends on n.","['gamma-function', 'special-functions', 'analysis']"
108346,"Does the subgroup $\{g\in G\,|\,o(\operatorname{Cl}(g))<\infty\}$ of $G$ have a name?","Let $G$ be a group. We can define $$F(G)=\{g\in G\,|\,o(\operatorname{Cl}(g))<\infty\},$$ where $o(\operatorname{Cl}(g))$ is the order (cardinality) of the conjugacy class of $g$ in $G$. This set is a subgroup of $G$ because 1) $o(\operatorname{Cl}(1))=1<\infty;$ 2) we have $g(xy)g^{-1}=(gxg^{-1})(gyg^{-1}),$ so $\operatorname{Cl}(xy)\subseteq\operatorname{Cl}(x)\operatorname{Cl}(y).$ Therefore, if $$o(\operatorname{Cl}(x))<\infty\text{ and }o(\operatorname{Cl}(y))<\infty,$$ then $o(\operatorname{Cl}(xy))<\infty.$ $F(G)$ is a characteristic subgroup of $G.$ Indeed, let $\alpha$ be an automorphism of $G$. Then $$\alpha(g)\alpha(x)(\alpha(g))^{-1}=\alpha(gxg^{-1})$$ for all $g,x\in G.$ We have $o(\alpha(\operatorname{Cl}(x)))=o(\operatorname{Cl}(x))$ because $\alpha$ is a bijection and so, since $\{\alpha(g)\,|\,g\in G\}=G,$ we obtain $$o(\operatorname{Cl}(\alpha(g)))<\infty,$$ and therefore $$\alpha(g)\in F(G).$$ I would like to ask if there is a name for this characteristic subgroup. Also, since $F(G)$ is a piece of ad hoc notation, I'd be grateful if you could tell me what the common notation is. Is the group $G/F(G)$ important? What is it called? And finally, where can I read about it?","['reference-request', 'group-theory', 'terminology']"
108352,Intersection of algebraic sets not equal to $\{0\}$?,"I was hoping to ask a small follow up to the question I asked here . Suppose $V$ is an algebraic variety over arbitrary field $k$. (For this situation, I'll take the definition $\dim\ V=\deg_k(k(x))$, where $(x)=(x_1,\dots,x_n)\in V$ is a generic point, and by $\deg$ I mean the transcendence degree.) As usual, $V(f_1,\dots,f_s)$ is the set of zeroes of the homogeneous forms $f_1,\dots,f_s$ in the affine space. Now say you take $U$ to be an algebraic set $x_1=\cdots=x_p=0$, (so $U$ is the algebraic set with associated ideal $(x_1,\dots,x_p)$) that is the algebraic set of coordinates in $\mathbb{A}^n$ where the first $p$ coordinates are $0$, and where $p<\dim\ V$. Is it now the case that $U\cap V\neq\{0\}$? Many thanks.","['commutative-algebra', 'algebraic-geometry']"
108388,"Function which is continuous everywhere in its domain, but differentiable only at one point","I am new in this forum. 
My question:
Suppose a real valued function $f: \mathbb{R} \rightarrow \mathbb{R}$ is continuous everywhere. Is it possible to construct $f$ that is differentiable at only one point? If possible, please give an example. Note: 
I am aware that there is a function which is differentiable at a single point but discontinuous elsewhere. I also know about Weierstrass function that continuous everywhere but nowhere differentiable. But is there a function which is continuous but only differentiable in one point? In fact, I found this discussion but unfortunately it still does not give a definitive answer. Moreover they consider only in an interval, whereas my problem is for the entire domain. Thank you very much",['calculus']
108405,Explicit descriptions of groups of order 45,"I know that there are two groups of order 45, and obviously one of them (up to isomorphism) is $\mathbb{Z}_{45}$.  I'm trying to understand explicitly what the structure of the other is like. By Cauchy's Theorem and Sylow's First Theorem, it has a subgroup of order 3, one of order 5, and one of order 9.  What this second group of order 45 doesn't have, unlike $\mathbb{Z}_{45}$, is a subgroup of order 15.  This rules out an element of order 15, which would generate a cyclic subgroup.  I know the group is abelian since we can write it as a product of normal subgroups.  Otherwise I'm unsure of what consequences this has, and what the structure of the non-cyclic group of order 45 is. So basically my question is...how do we obtain an explicit description of the the non-cyclic group of order 45?","['finite-groups', 'group-theory']"
108408,Confusion from a textbook comment about induction,"I am teaching myself discrete math from this text: http://www.amazon.com/Discrete-Mathematics-Applications-Susanna-Epp/dp/0495391328/ In chapter 5 there is an example of mathematical induction, and then a comment about what NOT to do, but it seems to me that what is described as bad is exactly what was done in the good example.  What am I missing?  Here is the ""good"" example first: Note that this is not the complete induction process, only the ""basis step.""  Later, an example is given of the ""wrong"" way to solve that same basis step: It seems to me that in the first example, both the LHS and the RHS were reduced to 1, to show that 1 = 1.  In the second example, i.e. what not to do... the same process was undertaken.  What is the difference? Thanks!","['induction', 'discrete-mathematics']"
108414,Examples of Calculations using Lebesgue Dominated Convergence,"I came across the following problem in my self-study, and wanted to know how to use Lebesgue Dominated Convergence to compute any of the following limits: (a) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $(1+(x/n))^{-n} \sin (x/n)dx$ (b) $\lim\limits_{n \rightarrow \infty}$ $\int_0^1$ $(1+nx^{2})(1+x^2)^{-n}dx$ (c) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $n \sin (x/n) [x(1+x^2)]^{-1}dx$ Any help is greatly appreciated. Update: I think I have successfully worked out arguments for each of (a) and (b), so I am less concerned about answers/strategies to those parts. However, (c) seems more tricky than the others, so if anyone visiting today sees how to handle (c) (in particular, a nice-enough dominating function!), let me know as it would be greatly appreciated.",['measure-theory']
108415,what is the relationship between ZFC and first-order logic?,"In Wikipedia, it says that ZFC is a one-sorted theory in first-order logic. However, I was not really able to comprehend the later parts that seem to elaborate on that point. Can anyone explain the relationship between ZFC and first-order logic? Thanks.","['axioms', 'elementary-set-theory']"
108422,How to show that the nth power of a $n \times n$ nilpotent matrix equals to zero $A^n=0$,"$A$ is a $n\times n$ matrix such that $ A^m = 0 $ for some positive integer $m$ .
  Show that $A^n = 0$ . My attempt: For $n > m$ , it's obvious since matrix multiplication is associative. For $n < m$ , $A^n\times A^{m-n} = 0$ ; not sure what to do next.
Also I know that $\det A = 0$ .","['matrices', 'nilpotence', 'linear-algebra']"
108457,List all subgroups of the symmetry group of $n$-gon,"List all subgroups of the symmetry group of the regular $n$-gon. If $n$ is prime, there are only $n+1$ subgroups: subgroup of all rotations and $n$ subgroups with $2$ elements (one reflection and rotation by zero degrees). But if $n$ is composite, there are additional subgroups in the group of rotations, namely rotations by angle $\frac{\pi}{k},\ k|n$. Also there are subgroups containing rotations and reflections, number of which I can't found. I know that $s_\alpha s_\beta=r_{2(\alpha-\beta)}$, where $s_\alpha$ is a reflection by the line inlcined at an angle $\alpha$ to the horizontal axis. So if a subgroup contains $r_\alpha$ and $s_\beta$, it contains their product $s_{\beta - \frac{\alpha}{2}}$. What is the best way to count all subgroups for each $n$? Update: I have found an group-theoretic answer at http://ysharifi.wordpress.com/2011/02/17/subgroups-of-dihedral-groups-1/ Later I will post the answer below.","['group-theory', 'abstract-algebra']"
108475,Question about perfect pairings,Suppose we had a bilinear map $V \otimes W \rightarrow \mathbb{C}$. What is meant by the fact that this map is a perfect pairing? How does one go about and show that something is a perfect pairing?,"['tensor-products', 'abstract-algebra']"
108478,"If a normal finite extension $K/F$ has no intermediate extensions, then $[K : F]$ is prime","Let $K$ be a finite normal extension of $F$ such that there are no proper intermediate extensions of $K/F$. Show that $[K:F]$ is
prime. Give a conterexample if $K$ is not normal over $F$.","['galois-theory', 'abstract-algebra', 'field-theory']"
108482,What function should I use to solve this? Simple question ;),"I need to write a simple function to be implemented in a computer program. It should have as imput a number from 2 to 9 and gives as output a number from 1 to 5. When the input is higher 6-7-8-9 the output should be lower 1-2. The opposite when the input is lower. I can implement a random function inside it. No need to satisfy any other particular requests. The important is that when I input 9 i got more low numbers as output then when I input 8 and so on. Thanks!
Sorry if this is a little bit vague!",['functions']
108486,"$S(x)=\sum_{n=1}^{\infty}a_n \sin(nx) $, $a_n$ is monotonic decreasing $a_n\to 0$: Show uniformly converges within $[\epsilon, 2\pi - \epsilon]$","$S(x)=\sum_{n=1}^{\infty}a_n \sin(nx) $, $a_n$ is monotonic decreasing $a_n\to 0$, when ${n \to \infty}$. I need to prove that for every $\epsilon >0$, the series is uniformly converges within $[\epsilon, 2\pi - \epsilon]$. Can I use Dirichlet and say that $\sum_{0}^{M} \sin (nx)< M$ for every x in the interval and since $a_n$ is uniformly converges to 0 ( uniformity since it does not depend on $x$), so the series is uniform convergent in this range? In addition I need to prove that if $\sum_{n=1}^{\infty} a_n^2 = \infty$  so the series is not uniform convergent in $[0, 2 \pi]$, Since I know that from $n_0$ and on $a_n^2< a_n$ I used an inequality, again I'm not sure of that. In the other hand, maybe I need to use Fourier series somehow. Thanks for the help!","['sequences-and-series', 'fourier-series', 'calculus']"
108489,Is an integer in the interval $\left[\small {3^n+1 \over 2^n+1}\lt {3^n \over 2^n} \lt{3^n-1 \over 2^n-1}\right] $ for some $\small n>1$?,"Consider the expression $$ f_n(j)= {3^n+j \over 2^n+j} $$ where we select some fixed  $n \gt 1$ and let j vary over the reals from +1 to -1 . I'm concerned with the problem, whether in the interval $\small f_n(+1).. f_n(-1) $ or
 $$ {3^n+1 \over 2^n+1} \le x \le  {3^n-1 \over 2^n-1} $$ 
an x can be integer (In the original version of this question I asked for a ""crossing of an integer value"" in $\small f_n(+1) \ldots f_n(-1) $ which seemed to be somehow obfuscating). Obviously this interval is roughly centered around the noninteger number $ {3^n \over 2^n}$ and the question can be reformulated whether for all $n \gt 1$
 $$ \left\lfloor {3^n \over 2^n} \right\rfloor \lt {3^n+1 \over 2^n+1} \le {3^n \over 2^n} \le  {3^n-1 \over 2^n-1} \lt \left\lceil {3^n \over 2^n} \right\rceil $$ 
Or one could ask whether in the interval $\small f_n(1)<x=f_n(j)<f_n(-1) $ there is an integer x for some j where  $ -1 \le j \le 1 $. Empirically we'll find an integer only for $\small n \in \{1,4,7\}  $ and moreover, such an integer for some negative j only at n=1 . Remarks: It's worth to note that 
 $${3^n+ \frac12 (\frac43)^n \over 2^n+\frac12 (\frac43)^n}
     \ldots {3^n- \frac12 (\frac43)^n \over 2^n-\frac12 (\frac43)^n } $$
defines an interval which increases with $\small n \ge 1$ from width 0.375 up to $\small 1 $ (not including). 
Thus it can contain at most one integer number and the interval here in question
 $\small f(1) \ldots f(-1) $ or $ {3^n+ 1 \over 2^n+1} \ldots  {3^n- 1 \over 2^n-1} $
is always enclosed within. The problem (to prove this for n>7 ) is related to the disproof of the so-called ""1-cycles"" in the collatz-problem (the proof of that Collatz-detail due to Ray Steiner in 1977 is based on the proof, that $\small g_n(k)_{for k>1} \notin \{2^m\} $ for n>1 which is a much sharper requirement and could be solved using results of transcendental number theory) is also related to a detail in the Waring-problem which is unsolved due to Eric Weissstein at mathworld-wolfram.com and has also a relation to the problem of z-numbers which were introduced by Kurt Mahler to solve a problem which was formulated quite similar. so I don't expect a solution here. But that problem ""took me"" quite a long time in the last years and I'm still curious in its relevant aspects, and I was just re-reading some of my older notes on it. So my question is, whether I can find more interesting discussions around this problem, may be in other formulations or with other focus just to possibly widen my horizon here (there is no nice general convention how to use numerical expressions in search-strings, so I ask here with the more verbal environment). P.s. perhaps there might be some more appropriate tag for this question?","['diophantine-approximation', 'reference-request', 'number-theory']"
108502,finding the limits of integration. joint probability,"A candy company distributes boxes of chocolates
with a mixture of creams, toffees, and cordials.
Suppose that the weight of each box is 1 kilogram, but
the individual weights of the creams, toffees, and cordials
vary from box to box. For a randomly selected
box, let X and Y represent the weights of the creams
and the toffees, respectively, and suppose that the joint
density function of these variables is
f(x, y) =

24xy, 0 ≤ x ≤ 1, 0 ≤ y ≤ 1, x+ y ≤ 1,
0, elsewhere.
(a) Find the probability that in a given box the cordials
account for more than 1/2 of the weight. In letter a, it means x+y < 1/2, now how can we find the limits of the double integral? proper approach to solve this problem? thanks PS: there would be no problem if the limits can be easily deciphered. but for this one its asking P(X + Y < 1/2)","['statistics', 'probability']"
108503,$\operatorname{Spec} (A)$ as a topological space satisfying the $T_0$ axiom,"I have been spending a few days now proving the last bit of the following problem of Atiyah Macdonald: Prove that $X = \operatorname{Spec}(A)$ as a topological space with the Zariski Topology is $T_0$. Now since the Zariski Topology is specified in terms of closed sets, I thought it might be easier to prove that given $x,y \in X$ such that $x \neq y$, there exists a closed set $U$ such that $x \in U$, $y \notin U$, or else there exists a closed set $V$ such that $y \in V$, $x \notin V$. So I tried to follow my nose by explicitly producing such a closed set, namely $$\overline{\{x\}} = V(\mathfrak{p}_x)$$ following the notation of Atiyah Macdonald. Now one of the things I tried from here was to use the fact that closed subsets of compact sets are compact. Hence $V(\mathfrak{p}_x)$ is compact but this approach did not work out. I realised while typing this problem that if I were actually able to prove it like this, then switching the roles of $x$ and $y$ I would have proved $T_1 - $ ness. However this cannot be possible for the finite point set $\{x\}$ is not closed when $\mathfrak{p}_x$ is not a maximal ideal. What should I look at now to try to solve the problem? Please do not post complete solutions. Thanks.","['general-topology', 'commutative-algebra', 'algebraic-geometry']"
108528,What's wrong with this limit?,"Let's say we have this limit:
$$\lim\limits_{x\to \infty} \frac{1}{x}$$
which is clearly 
$$\lim\limits_{x\to \infty} \frac{1}{x} = 0.$$
From there, to prove it we should:
$$\left\lvert \frac{1}{x} - 0 \right\rvert < \epsilon$$ 
(with $\epsilon > 0$ and small). To solve that inequality we should deal with a system of:
$$\begin{align*}
\frac{1}{x} &\lt \epsilon&&\text{(for }\frac{1}{x} \gt 0\text{)}\\
\frac{1}{x} &\gt -\epsilon&&\text{(for }\frac{1}{x}\lt 0\text{)}
\end{align*}$$
Then from the () we have that the first inequality is for $x < 0$ and the second is for $x > 0$. Is this right?",['limits']
108540,Symmetry group of the dodecahedron and its subsets,"Let $G$ be the symmetry group of the dodecahedron. Indicate subsets of the dodecahedron on which $G$ acts by all possible permutations. I know that $G \simeq A_5 \times \mathbb{Z}_2$. Its order is $120=2^3\cdot3\cdot5$, so there may be $2,3,4$ or $5$ subsets on which $G$ acts by all permutations. I don't see any possibilites other than $5$ Kepler's cubes which are inscribed in the dodecahedron. How can this problem be solved rigorously?","['geometry', 'symmetric-groups']"
108544,Differential equations notation,"I've always wondered why does the differential equation notation for linear equations differ from the standard terminology of vector spaces. We all know that the equation $y'' + p(x) y' + q(x)y = g(x)$ for some function $g$ is called linear and that the associated equation $y'' + p(x)y' + q(x) y = 0$ is called homogeneous . But why is that? WHY should mathematicians explicitly cause confusion with the rest of the theory of vector spaces? What I mean by that is : Why not call the equation $y'' + p(x)y' + q(x)y = g(x)$ an affine equation and call $y' + p(x) y' + q(x) y = 0$ a linear equation? Because linear equations (in the sense of differential equations) are not linear in the sense of vector spaces unless they're homogeneous ; and linear equations (in the sense of differential equations) remind me more of a linear system of the form $Ax = b$ (which is called an affine equation in vector space theory) than of a linear equation at all. Just so that I made myself clear ; I perfectly know the difference between linear equations in linear algebra and linear equations in differential equations theory ; I'm asking for some reason of ""why the name"". Thanks in advance,","['notation', 'ordinary-differential-equations']"
108547,Why are $\log$ and $\ln$ being used interchangeably?,A definition for complex logarithm that I am looking at in a book is as follows - $\log z = \ln r + i(\theta + 2n\pi)$ Why is it $\log z = \ldots$ and not $\ln z = \ldots$? Surely the base of the log will make a difference to the answer. It also says a few lines later $e^{\log z} = z$. Yet again I don't see how this makes sense. Why isn't $\ln$ used instead of $\log$?,"['notation', 'logarithms', 'complex-analysis']"
108549,Constructing a countable family of seminorms in a metrizable LCS.,"Here's some context before my question. Let $\mathbb{V}$ be a topological vector space, which is Hausdorff and such that its topology is generated by some arbitrary family of seminorms $\{\rho_{\alpha}\}_{\alpha \in I}$; this means that $\mathbb{V}$ is locally convex. Now, if $I$ turns out to be countable (or if we can reduce the family $\{\rho_{\alpha}\}_{\alpha \in I}$ to a countable one, while keeping the same topology in $\mathbb{V}$), we can define a metric in $\mathbb{V}$ by
$$d(u, v) = \sum_{i = 1}^{\infty} \frac{1}{2^i} \frac{\rho_i(u - v)}{1 + \rho_i(u - v)},$$
where $\{\rho_i\}_{i \in \mathbb{N}}$ is some enumeration of $\{\rho_{\alpha}\}_{\alpha \in I}$, so that its topology is metrizable. I've been told that the converse is also true, which leads to my question. QUESTION : Let $\mathbb{V}$ be a topological vector space having a metrizable topology, generated by some metric $d$. How can I prove that $\mathbb{V}$ admits a countable family of seminorms generating its topology? Also, do I need to impose the condition that $d$ is translation invariant (since this happens in the above construction)? Thanks.","['topological-vector-spaces', 'locally-convex-spaces', 'functional-analysis']"
108559,Proof of the duality of the dominance order on partitions,"Could anyone provide me with a nice proof that the dominance order $\leq$ on partitions of an integer $n$ satisfies the following: if $\lambda, \tau$ are 2 partitions of $n$, then $\lambda \leq \tau \Longleftrightarrow \tau ' \leq \lambda '$, where $\lambda'$ is the conjugate partition of $\lambda$ (i.e. the transpose of the set of 'dots' which $\lambda$ represents). I feel like there must be a nice clever and concise/intuitive proof of this, but all I can come up with is an ugly brute force approach based on the definition of sums of the components $\lambda_i$. Could anyone suggest a particularly nice way to obtain this result? Many thanks.","['alternative-proof', 'integer-partitions', 'combinatorics']"
108566,Writing a function $f$ when $x$ and $f(x)$ are known,"I'm trying to write a function. For each possible input, I know what I want for output. The domain of possible inputs is small: $$\begin{vmatrix}
    x &f(x)\\
    0      & 2\\
    1      & 0\\
    2      & 0\\
    3       &0\\
    4       &0\\
    5       &0\\
    6       &1\\
\end{vmatrix}$$
My thought is to start with a function $g(x)$ that transforms $x$ to a value from which I can subtract a function $h(g(x))$ and receive my desired $f(x)$:
$$\begin{vmatrix}
    x &g(x)& h(g(x)) &f(x)\\

    0 &   7&       5  &  2\\
    6 &   6 &      5 &   1\\
    5  &  5  &     5&    0\\
    4   & 4   &    4   & 0\\
    3 &   3    &   3  &  0\\
    2  &  2     &  2 &   0\\
    1   & 1      & 1&    0
\end{vmatrix}$$
But I'm not sure where to go from there, or even whether I'm heading in the right direction. How should I approach creating this function? Is there a methodical way to go about it, or is it trial and error (and knowledge)? Feel free to suggest modifications to how I'm stating my problem, too. Thanks.","['algebra-precalculus', 'functions']"
108567,General solution using Euclidean Algorithm,I was able to come up with the integer solution that they also have in the textbook using the same method they used but I am really puzzled how they come up with a solution for all the possible integer combinations...how do they come up with that notation/equation that represents all the integer solutions ? I am talking about the very last line.,"['algebra-precalculus', 'discrete-mathematics']"
108569,Is there a better bound than $(n^2)^{n^3}$ for the order of the commutator subgroup of a group whose center has index $n?$,"Let $G$ be a group and $[G:Z(G)]=n<\infty,$ where $Z(G)$ is the center of $G$. A theorem says that in this case $$o([G,G])\leq(n^2)^{n^3}, $$ where $o(\cdot)$ denotes order and $[G,G]=G'$ is the commutator subgroup of $G$. The bounds from the proof seem crude and I would like to ask if we can improve upon the result. Of course, the theorem is valuable with any bound because it implies that $G'$ is finite. Proof. We have exactly $n$ cosets $\{x_iZ(G)\}_{i=1}^n$. We will be using the representatives $x_i.$ Let $$c_{ij}=[x_i,x_j]=x_i^{-1}x_j^{-1}x_ix_j.$$ First, we note the following Lemma 1. $$\{c_{ij}\,|\,i,j=1,...,n\}=\{[x,y]\,|\,x,y\in G\}.$$ Proof of lemma. For $x,y\in G$ we have some $i,j\in\{1,...,n\}$ and $z_1,z_2\in Z(G)$ such that $$x=x_iz_1\text{ and }y=x_jz_2.$$ Then $$
\begin{eqnarray}
[x,y]&=&x^{-1}y^{-1}xy=z_1^{-1}x_i^{-1}z_2^{-1}x_j^{-1}x_iz_1x_jz_2\\
&=& (x_i^{-1}x_j^{-1}x_ix_j)(z_1^{-1}z_1z_2^{-1}z_2)\\
&=& x_i^{-1}x_j^{-1}x_ix_j\\
&=& [x_i,x_j].
\end{eqnarray}
$$ Lemma 2. For $x,y\in G$ we have $$[x,y]^{n+1}=[x,y^2][y^{-1}xy,y]^{n-1}.$$ Proof of lemma. Since $G/Z(G)$ has order $n$, we have $[x,y]^n\in Z(G)$. Therefore $$
\begin{eqnarray}
[x,y]^{n+1}&=&x^{-1}y^{-1}xy[x,y]^n\\
&=& x^{-1}y^{-1}x[x,y]^ny\\
&=& x^{-1}y^{-1}x(x^{-1}y^{-1}xy)[x,y]^{n-1}y\\
&=& (x^{-1}y^{-2}xy^2)y^{-1}[x,y]^{n-1}y\\
&=& [x,y^2][y^{-1}xy,y^{-1}yy]^{n-1}\\
&=& [x,y^2][y^{-1}xy,y]^{n-1}
\end{eqnarray}
$$ Proof cont'd. Let $g\in G'.$ It is a product of a a finite number $m$ of elements $c_{ij}$ (with possible repetitions) because $[x,y]^{-1}=[y,x]$ and so we do not need to consider inverses. Suppose $m>n^3$. We have $$\operatorname{card}(\{c_{ij}\,|\,i,j=1,...,n\})\leq n^2$$ so some element $c_{ij},$ say $c=[x,y],$ must appear at least $n+1$ times in the product. There is no reason to believe however that $c^{n+1}$ occurs in the product since the occurances of $c$ may be scattered. We fix it by noting that for any $x',y'\in G$ we have $$[x',y'][x,y]=[x,y]c^{-1}[x',y']c=[x,y][c^{-1}x'c,c^{-1}yc].\tag1$$ This allows us to rewrite $g$ as a product of commutators which begins with $[x,y]^{n+1}:$ $$g=[x,y]^{n+1}c_{n+1}c_{n+1}...c_{m}.$$ But this equals $$[x,y^2][y^{-1}xy,y]^{n-1}c_{n+1}c_{n+1}...c_{m},$$ which is a product of $m-1$ commutators. Repeating this procedure, we can decrease the number of factors to $n^3.$ Therefore we can write any element of $G'$ as a product of at most $n^3$ commutators. We recall that there can be at most $n^2$ distinct commutators in $G$ and therefore there are at most $(n^2)^{n^3}$ elements in $G'.$ EDIT I have laid my hands on a copy of Passman's book on group rings and I see that the theorem and the proof come from it. The author attributes the theorem to Schur.","['inequality', 'group-theory', 'combinatorics']"
108576,Dirac measure and counting measure,"Let $X$ be a nonempty set. I would like hints in showing the following: (a) every extended real valued function on $X$ is measurable with respect to the measurable space  $(X,2^X)$. (b) Let $x\in X$. Let $\delta_x$ be the Dirac measure at $x$ on $2^X$. Then two functions on $X$ are equal almost everywhere $[\delta_x]$ if and only if they take the same value at $x$. (c) Let $\alpha$ be the counting measure on $2^X$. Then two functions on $X$ are equal almost everywhere $[\alpha]$ if and only if they take the same value at every point in $X$. Following Davide's hints, (a) Let $\mathcal{B}=2^X$. Then $2^X$ is a sigma algebra and by definition the if $(X,2^X)$ is a measure space, then $f:X\to \overline{\mathbb{R}}$ is measurable since the the set $\{x\in X : f(x) < c\} \in 2^X$ for every $c\in \mathbb{R}$. (b) Here, it suffices to show that the sets which have measure zero are the sets which does not contain $x$. So suppose $f=g$ a.e. then there is a set $N$ with measure zero such that $A=\{x\in X : f(x)\ne g(x)\} \subset N$. But these are precisely those  points which don't contain $x$. So $f(x)=g(x)$ on $N^c$. (c) By definition of the counting measure , the empty set is the only set with counting measure zero. So $f=g$ a.e. $\Leftrightarrow f(x)=g(x)$ at every point in $X$.","['measure-theory', 'real-analysis']"
108577,A question about the Lebesgue-Stieltjes measure of the Cantor function,"This question is a follow-up to the post ""Calculating a Lebesgue integral involving the Cantor Function."" Let $\varphi: [0,1] \rightarrow [0,1]$ be the Cantor (ternary) function, and let $m_\varphi$ be the Lebesgue-Stieltjes measure associated to it. Attached is an excerpt from the answer received on this post: Notice that $\varphi(1-x) = 1 - \varphi(x)$.  From this, it is easy to show that the Cantor measure $m_\varphi$ is invariant under the transformation $x \mapsto 1-x$. I know very little about this type of measure, and hence have had trouble seeing why the above is easy to show. I tried to ask the responder about this point, but to no avail. Hence, I am posting this to see if anyone visiting would be up for either explaining this point about invariance, or giving me a push in the right direction to proving it. Also: the responder changed the notation in the integral from $dm_\varphi$ to $m_\varphi dx$, and I would be grateful for any clarification as to the relationship of these two notations. Thank you in advance for any response!",['measure-theory']
108593,How to prove that the normalizer of diagonal matrices in $GL_n$ is the subgroup of generalized permutation matrices?,"I'm trying to prove that de normalizer $N(T)$ of the subgroup $T\subset GL_n$ of diagonal matrices is the subgroup $P\in GL_n$ of generalized permutation matrices. I guess my biggest problem is that I don't really know how diagonal and permutation matrices (don't) commute. Because it is not true that $DM=MD$ when $D\in T$ and $M\in P$ since the permutation is either horizontal or vertical, but sometimes it seems like you can do something like it. So far, I have proved that $P\subset N(T)$, in the following way. Let $M_\sigma\in P$. Then $M_\sigma=VS_\sigma$, with $V\in T$ and $S_\sigma$ a permutation matrix. So $M_\sigma DM^{-1}=VS_\sigma D S_\sigma^T V^{-1}$. Thus if we prove that $S_\sigma D S_\sigma^T$ is diagonal we are done. This is true since $S_\sigma D S_\sigma^T=(x_1 e_{\sigma(1)} \dots x_n e_{\sigma(n)}) (e_{\sigma^{-1}(1)} \dots e_{\sigma^{-1}(n)})=(x_{\sigma^{-1}(1)}e_1 \dots x_{\sigma^{-1}(n)}e_n)$, where $e_i$ are the standard basis vectors. Even this is hopelessly written out. I'm trying to find a way to see what the product $S_\sigma D S_\sigma^T$ is without writing it in vectors. For the other way around I don't really know what to do. I'm having a hard time rewriting matrix products in a useful way. Perhaps there is a way of proving this using something completely different? Maybe you can prove it using $N(T)/T\simeq S_n$, but this actually what I want to use my question for. When I just write what I know about a matrix $M\in N(T)$ I just get a big system of equations that isn't really handy.","['matrices', 'group-theory']"
108600,Determine the values of $k$ for which the equation $x^3-12x+k = 0$ will have three different roots.,"Determine the values of $k$ for which the equation $x^3-12x+k = 0$ will have three different roots. I can do this with calculus, I was just wondering what could be the pure algebraic approach to solve this?","['algebra-precalculus', 'polynomials']"
108611,Algorithm for finding the discriminant of algebraic number fields,"I am reading J.S. Milne's Algebraic Number Theory notes, http://jmilne.org/math/CourseNotes/ANT.pdf . I am quite confused with the section ""Algorithm for finding the ring of integers"". There is an efficient way to find the discriminant of polynomials, and there is also an algorithm to find the ring of integers. Is there an efficient algorithm for finding the discriminant of algebraic number fields, i.e. disc($\mathcal{O}_K/Z)$? Of course, once we find out the ring of integers, it is not hard to find the discriminant of the algebraic number fields. But is there a more direct way? Besides, generally speaking, given $\alpha$ a root of an irreducible polynomial $f$, if we have got disc$(f)$, how could we find disc($\mathcal{O}_{\mathbb{Z}[\alpha]}/\mathbb{Z}$)? If disc$(f)$ is square-free, then it is automatically the discriminant of the algebraic number field. But what if it is not square free? I am a beginner in algebraic number theory, these questions might be silly, and I am even not quite sure whether the terms I use are accurate. So I would appreciate it if you could help me to edit the questions. Thank you.","['algebraic-number-theory', 'number-theory']"
108612,Determining the left inverse of a non-square matrix,"I understand that non-square matrices do not have an inverse, that is, both a left inverse and a right inverse. Yet, I am fairly certain that it is possible for a non-square matrix to have either a left inverse or (exclusively) right inverse. Take the example where, I want to determine the matrix P for which, $$P
\left[
\begin{array}{cc}
1 & 1 \\
1 & i \\
0 & 1+i \\
\end{array}
\right]
\left[
\begin{array}{c}
\lambda_{1} \\
\lambda_{2} \\
\end{array}
\right] =
\left[
\begin{array}{c}
1 \\
0 \\
i \\
\end{array}
\right]$$ It is clear that $P$ must be a $3 \times 3$ matrix, since the column matrix on the right side is $3 \times 1$. How can I determine what this matrix $P$, the left inverse of $\left[
\begin{array}{cc}
1 & 1 \\
1 & i \\
0 & 1+i \\
\end{array}
\right]$, is? The standard methods I know for inverting an $n \times n$ (square) matrix seem not to be working. Thank you.","['matrices', 'linear-algebra']"
108621,Sobolev space and equivalence of norms,"I'm considering the space $W\{n,p\}[0,1]$ of functions with $n-1$ continuous derivatives $f^{(n-1)}$ is absolutely continuous and $f^{(n)}$ is in $L^p[0,1]$. The usual norm is the sum of the $p$-norms of each derivative from $1$ to $n$ and the $p$ norm of the function. Now just consider the $p$ norm of the function + $p$ norm of the $n^{th}$ derivative, i.e.$(\int |f(x)|^p)^{1/p}$ + $(\int |f^{(n)}|^p)^{1/p}$  I want to show that this is equivalent to the usual norm defined above. This requires finding positive constants and sandwiching this new norm. In one direction it's obvious since the new norm is less than the usual norm for every $x$, say $\|x\|_2 \leq \|x\|_1$. I'm not sure how to show the other direction.","['sobolev-spaces', 'functional-analysis', 'absolute-continuity']"
108630,Showing that a function is the sine function,"How can I prove the following: If $ f:  \mathbb{R} \rightarrow \mathbb{C} $ is a $2\pi$-periodic function of class $C^{\infty}$ such that $f'(0)=1$ and that for any $n\in \mathbb{N}, x\in\mathbb{R}$, $ \vert f^{(n)}(x) \vert \leq 1 $, then $f$ is the sine function?","['fourier-analysis', 'analysis']"
108633,Fourier transform of gaussian times polynomial to a high power,"Anybody know of a clever way of finding the Fourier transform of 
$$ F(x)  =  P(x)^n e^{-\pi x^2}$$
very $n$ is fairly large integer. It is to be used as part of a computation, so I would rather not multiply out the polynomial and then find the Fourier transform of each of the terms individually, hence I thought perhaps there is a way to use that my polynomial has few roots with high multiplicity to get a closed expression where $n$ features in an manageble way - perhaps something akin to the way factorials occur when $P(x)=x^n$. Any thoughts will be welcome. EDIT: The polynomial $P$ can be assumed to be either linear or quadratic - in case that simplifies.","['calculus', 'functions']"
108637,Convergence of a sequence of partial binomial sums,"I have a sequence $$a_n = (1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k.$$ I want to show that $a_n\to 0$ when $n\to\infty$ if $0\le p < \frac{1}{2}$. Here's a plot of the sequence for $p=\frac{1}{3}$: Failed attempt: $$\begin{align}
(1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k <& (1-p)^n \sum_{0 \le k \le n} \binom{n}{k}\left(\frac{p}{1-p}\right)^k \text{ for } n\ge 1\\
=& (1-p)^n \left(1+\frac{p}{1-p}\right)^n = 1.
\end{align}$$ My hope here was to end up with something like $0.99^n$ in that last step so I could argue that since $a_n<0.99^n$ and $0.99^n\to 0$ as $n\to\infty$, $a_n\to\infty$. Unfortunately it came out to 1, not $0.99^n$.","['discrete-mathematics', 'binomial-coefficients', 'real-analysis']"
108638,How to interpret the little-$o$ notation in this definition of the Poisson process?,"In the book Probability and Random Processes by Grimmett and Stirzaker, a Poisson process is defined to be any process $(N(t))_{t\in[0,\infty)}$ with values in $\mathbb{N}_0$ satisfying following three properties: $\hspace{20pt}$(a) $N(0) = 0$ and $s<t\Rightarrow N(s)\leq N(t)$ $\hspace{20pt}$(b) $\mathbb{P}\left(N(t+h)=n+m|\hbox{ }N(t) =n\right) =\begin{cases}
o(h) & \text{if } m>1,\\
\lambda h + o(h) &\text{if } m=1,\\
1 - \lambda h + o(h) & \text{if }m=0\\
\end{cases}$ $\hspace{20pt}$(c) if $s<t$ then $N(t)-N(s)$ is independent of the times of emissions on $[0,s]$. I am having problems with understanding the meaning $o(h)$ in (b), so my question is: How do we interpret $o(h)$ in this definition? I know $o(h)$ in the classical sense is supposed to be just a function such that $\lim_{h\to 0}\frac{o(h)}h=0$. But here, $o$ is used three times and I suspect it has a different meaning each time. (Since otherwise, we would necessarily have $o\equiv0$.) So, I did some thinking and reinterpreted (b) to read: $\hspace{20pt}$(b') There exist functions $o_1, o_2, o_3$, such that for $i=1,2,3$:$$\lim_{h\to 0}\frac{o_i(h)}h=0$$
$\hspace{38pt}$and
$$\mathbb{P}\left(N(t+h)=n+m|\hbox{ }N(t) =n\right) =\begin{cases}
o_1(h) & \text{if } m>1,\\
\lambda h + o_2(h) &\text{if } m=1,\\
1 - \lambda h + o_3(h) & \text{if }m=0.\\
\end{cases}$$ But I am completely confused about the order of quantifiers in this statement (which is why I left this rewording a bit vague). Should the functions $o_1,o_2,o_3$ be the same for all $t,n$ and $m>1$? (That is: should we take a separate function $o_m$ for each m? Or even a separate function $o_{t,n,m}$ for each triple $(t,n,m)$?) Does this even matter or are these definitions miraculously equivalent? I would really like to know what exactly it is this definition is trying to define. Thanks in advance for any helpful suggestions.","['notation', 'asymptotics', 'probability']"
108643,$\sum \frac{z^{2n}}{1-z^{n}}$ normally convergent in $\mathbb{E}$,"I tried to solve this exercise (Remmert Theory of Complex Functions, p. 107, exercise 1 ), but I didn't get very far: Proposition: $$\sum \frac{z^{2n}}{1-z^{n}}$$ is normally convergent in $\mathbb{E}$ What does $\mathbb{E}=\{z\in \mathbb{C} | |z|<1 \}$ stand for? For normal convergence, it suffices if one finds a majorant series whose absolute value is less than infinity? so (most likely it is $|z|<1$ for all $z\in \mathbb{C})$  : $$\left|\sum \frac{z^{2n}}{1-z^{n}} \right| \le \sum \left| \frac{r^{2n}}{1-r^{n}}\right| \le \sum |r^{n}| < \infty$$ Does anybody see if this is right?","['complex-analysis', 'analysis']"
108657,Continuity of the Characteristic Function of a RV,"Defining the Characteristic Function $ \quad  \phi(t) := \mathbb{E} \left[ e^{itx} \right] $ for a random variable with distribution function $F(x)$ in order to show it is  uniformly continuous I say $$
|\phi(t+u) - \phi(t)| = \left |\int e^{itx}(e^{iux} - 1) dF(x) \right| \le \\ \int 1 \cdot|e^{iux} -1|dF(x) \to 0 \quad as  \quad u\to0
$$ Now my question is, does the convergence I state in the last line follow directly, or do I need to be a little carful before I conclude it is true ? (i.e. can I directly use that $|e^{itu} -1| \to 0 ? )$","['convergence-divergence', 'fourier-analysis', 'probability-theory', 'analysis', 'probability']"
108660,Measure zero of the graph of a continuous function,"If $A$ is a rectangle in $\mathbb{R}^n$ and if we let $f$ be continuous,
then how can we show that the graph of $f$ has measure zero in $\mathbb{R}^{n+1}$? We may define that $A$ is a subset of $\mathbb{R}^n$ and the graph of $f: A\to \mathbb R$ is the set given $\mbox{graph}(f) := \{(x,y) \in \mathbb{R}^{n+1} : f(x) = y\}$.","['measure-theory', 'real-analysis']"
108678,Alternate expression for the following function,"So if the following function is evaluated with the floating-point arithmetic, we get poor results for certain range of values of $x$. Therefore, I need to provide an alternate function that can be used for those values of $x$. 
The function is: $ f(x)= \sqrt{1+x}-\sqrt{1-x} $ I have found the range for this and it is: $-\sqrt{2} \le y \le \sqrt{2}$ So how would I make an alternate expression or function for this. Do I just multiply by its conjugate.","['computer-science', 'calculus', 'functions']"
108682,Optimal approximation of square area with identical circles,"There are 86 pages on this site alone under a search for: area, square, circle, convergent, approximation. I found one that arguably asks the same question here , but I am not sure. The question is, if we are trying to approximate the area of a square with identical circles, does the sequence of approximations converge (and does it converge to the area of the square)? Because for 1,4,9,16, and 25 circles, the ratio r of the area of the approximating circles to that of the square is the same ($\frac{\pi}{4}$), I thought that this pattern surely continued. So my original question was whether, if we remove the square-numbered approximations, we get a convergent sequence. I see that this is related to the problem of packing circles into a square, and having looked at the sequence of ratios (given here ) I see that after 25 the ""best"" packing is not a nice military arrangement but something else, something that allows the circles to swell a bit. So the ""best"" packing improves for square numbers as well. And so it does appear that we have a non-monotone sequence of approximations that might or might not converge to a ratio r = 1. But appearances can be deceiving. I did a quick review of the literature (at the link above) but it is addressed primarily at the question of optimal packing for given numbers of circles, and not convergence, which I hope is much simpler. Thanks for any insight.","['geometry', 'calculus', 'packing-problem']"
108691,"If $\overline{A}=\overline{B}$, is it true that $\overline{f(A)}=\overline{f(B)}$?","For a continuous function $f:X\longrightarrow Y$ of topological spaces with subsets $A$ and $B$ of $X$ satisfying $\overline{A}=\overline{B}$, is it true that $\overline{f(A)}=\overline{f(B)}$? Intuitively it seems so, but if someone could walk me through how this could be proved, I would be very grateful, regards.",['general-topology']
108709,"Is the graph $G_f=\{(x,f(x)) \in X \times Y\ : x \in X \}$ a closed subset of $X \times Y$?","I'm thinking about Hausdorff spaces, and how mappings to Hausdorff spaces behave. Suppose I have an arbitrary (continuous) function $f:X \longrightarrow Y$, where $Y$ is a Hausdorff space (I think it is irrelevant for my question whether $X$ is Hausdorff or not, so I just consider it to be a topological space - if this is incorrect, please correct me!). Can we say that the graph $$G_f=\{(x,f(x)) \in X \times Y\ : x \in X \}$$ is a closed subset of $X \times Y$? It seems quite obvious that it is the case, but I cannot see how to prove it. If anyone can offer a proof I'd be very interested. Regards. EDIT 1 In response to Hennning Makholm: I wasn't really aware of any variation in 'definition'; I guess I'm considering closed sets to be those with an open complement (though naturally this definition gives rise to other definitions, such as the subset equalling its closure etc.). For continuity of such a map, I would normally consider continuity to mean that $f^{-1}(V)$ is closed in $X$ whenever $V$ is closed in $Y$, though again definitions involving convergence of sequences and the notion that $f$ is continuous iff $f(\overline{A}) \subset \overline{f(A)}$ for every $A \subset X$ are also known to me.","['general-topology', 'analysis']"
108710,About $t$-analogue of the Eulerian polynomials.,"A certain way to define the $t$ -analogue of the Eulerian polynomials $C_n(x)$ is by $$
C_n(x,t)=\sum_{\pi\in S_n}x^{\text{des}(\pi)+1}t^{\text{maj}(\pi)}
$$ where $des(\pi)$ is the descents in $\pi$ , and $maj(\pi)$ is the major index of $\pi$ . Based on this, how can one derive the general formula $$
\sum_k (k)_t^nx^k=\frac{C_n(x,t)}{(1-x)(1-tx)\cdots(1-t^nx)}?
$$ Thank you. I thought it would be more approachable to rewrite as $$
\sum_k (k)_t^nx^k(1-x)(1-tx)\cdots(1-t^nx)=C_n(x,t)
$$ and compare coefficients. With two variables and an unwieldy product of terms, I couldn't find a nice form for the coefficients of the left hand side above.","['polynomials', 'eulerian-numbers', 'q-analogs', 'combinatorics']"
108730,Does every continuous time minimal Markov chain have the Feller property?,"Consider a Q-matrix on a countable state space. (A Q-matrix is a matrix whose rows sum up to $0$, with nonpositive finite diagonal entries and nonnegative off-diagonal entries.) As explained for example in the book of Norris on Markov chains, every Q-matrix (without any further assumptions) defines a transition function (given by the minimal nonnegative solution of the corresponding backward equation). Is the  the semigroup associated to this minimal transition function always Feller?
(definition of Feller: functions vanishing at infinity are mapped into functions vanishing at infinity). I know that in general, not every continuous time Markov chain is Feller, but I guess that
for these minimal chains it is always true without further assumptions on $Q$. 
Though I didn't find a statement like this in the books I consulted. Does anybody have a reference/proof/counterexample?","['stochastic-processes', 'markov-chains', 'reference-request', 'semigroups', 'probability']"
108731,Nowhere continuous real valued function which has an antiderivative,"My question: Is there a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that nowhere continuous on its domain, but has an antiderivative? If there is no such a function,  is it true to conclude that: to have an antiderivative, $f$ is necessary to be continuous at least at one point on its domain? Any comments/ inputs are highly appreciated. Thanks in advance.",['real-analysis']
108740,Conditional probability and the disintegration theorem,"I was wondering how conditional probability and the disintegration theorem are related? How is the conditional probability given by the disintegration theorem? I don't quite understand what Wikipedia says: The disintegration theorem can be applied to give a rigorous treatment
  of conditioning probability distributions in statistics, while
  avoiding purely abstract formulations of conditional probability. The linked paper Chang, J.T.; Pollard, D. (1997). "" Conditioning as disintegration "". STATISTICA NEERLANDICA 51 (3) has 30 pages and is somehow overwhelming to me now. Following is a scenario I am considering (but it may be over-complicated and misleading, I am not sure): Suppose $(\Omega, \mathcal{M},P)$ is a probability space. $(S, \mathcal{S})$ is a measurable space. and $Y:\Omega \to S$  is a measurable mapping. 
The conditional probability $P(\cdot | Y)$ is a mapping $\mathcal{M} \times S \to [0,1]$. I guess it is only when the conditional probability is regular, i.e. $\forall s \in S$, $P(\cdot | Y)(s)$ is a probability measure, that the conditional probability can be given by the disintegration theorem? 
Then, how is the conditional probability given by the disintegration theorem? Note: I think I have got the idea of the disintegration theorem. My source is also Wikipedia . I also appreciate it if you could let me know about some accessible relevant texts. Thanks and regards!","['probability-theory', 'measure-theory', 'reference-request']"
108766,Lüroth's Theorem,"I have just begun to read Shafarevich's Basic Algebraic Geometry . In the first section of the first chapter, he quotes Lüroth's theorem, which states that any subfield of $k(x)$ that is not just $k$ is isomorphic to $k(x)$, i.e. is generated as a field over $k$ by a single rational function of $x$. I have been trying to find a proof. I am stuck, and would appreciate any hints to fill in the argument. (I have consulted Wikipedia, Wolfram Mathworld, and this MathOverflow question , but so far haven't been able to satisfy myself.) I have thought about two approaches so far. My question would be answered by a suggestion about how to complete either one of these ideas. Here they are: Let $k\subset L \subset k(x)$ be an intermediate field not equal to $k$. Approach #1: Any element of $k(x)$ not in $k$ is transcendental over $k$; meanwhile, $k(x)$ has transcendence degree 1 over $k$; it follows that $L$ has transcendence degree 1 over $k$. Thus $k(x)$ is algebraic over $L$. Let $p(t)$ be the minimal polynomial of $x$ over $L$. $$p(t)=t^n+l_1t^{n-1}+\dots+l_n$$ where $l_1,\dots,l_n\in L$ (and are thus rational functions of $x$). Now if the theorem is really true, $L=k(f)$ for some $f\in k(x)$; and $f=r/s$, with $r,s\in k[x]$. Then $p(t)=r(t)-fs(t)$. This is degree $n=\max(\deg r,\deg s)$ in $t$. Any coefficient of any power of $t$ in $p(t)$ is actually either in $k$ (if this power of $t$ does not appear in $s$), or else it is a linear function of $f$ and thus a field generator for $L$ and degree $n$ as a rational function of $x$. Thus I expect to be able to prove that, with $p(t)$ defined as above, actually any of the coefficients $l_1,\dots,l_n$ not contained in $k$, i.e. any of them (say $l_i$) that is a nonconstant function of $x$, is degree $n$ as a function of $x$ and is thus a field generator for $L$. (It would be sufficient to prove that it is degree $n$ as a function of $x$, because then $k(x)\supset L \supset k(l_i)$, but $[k(x):L]=[k(x):k(l_i)]=n$.) One internet source I found suggested that this is the right approach, but I can't seem to fill it in. Here's what I've got: $p(t)$ is divisible by $t-x$ over $k(x)$ (since $x$ is a root), and over $k(l_1,\dots,l_n)$ it is irreducible (since this field is contained in $L$). I can't see that there is anything else I know about it for sure. It must be that irreducibility over $k(l_1,\dots,l_n)$ implies that $l_1,\dots,l_n$ are all either degree $n$ or else in $k$; but I haven't figured out how. From examples I have worked out (in which I chose $l_1,\dots,l_n$ semi-arbitrarily to fulfill $(t-x)\mid p(t)$), this seems to be true; if I make any of them different in degree from $0$ or $n$, then usually I can also get $x$ as a rational function of them, thus in these examples $k(l_1,\dots,l_n)=k(x)$ and $p(t)$ is divisible by $t-x$ over $k(l_1,\dots,l_n)$. Of course I assume it can also happen that I choose $l_1,\dots,l_n$ so that $k(l_1,\dots,l_n)\neq k(x)$, but $p(x)$ will still factor over $k(l_1,\dots,l_n)$ as long as any of the $l_i$ not in $k$ differ in degree from $n$. In any case all the calculations have felt ad-hoc and I haven't so far seen a reason for what is happening. So any hints here would be appreciated. Approach #2: Because the theorem reminds me of the result that $k[x]$ is a p.i.d., I have also been unable to escape the following thought: let $f\in L$ be an element of $L$ of minimal degree as a function of $x$, and suppose that there is some other element $g\in L$ not in $k(f)$. Can I construct some element of $L$ using $f$ and $g$ (i.e. an element of $k(f,g)$) that contradicts $f$'s minimality in degree? I have not given this approach as much thought as the above, but again, so far I have not seen how to carry out the construction. The Euclidean-algorithm trick that proves $k[x]$ is a p.i.d. is unavailable here because I can't multiply $f$ or $g$ by anything that is not a rational function of one or the other of them. (In particular I can't see how to pass to a polynomial ring in $x$ but make sure I've stayed inside $k(f,g)$.) $g$ does have a minimal polynomial over $k(f)$, and if $g\notin k(f)$ then its degree is $>1$, so this could be a starting point for trying to construct the lower-degree element of $k(f,g)$, but again I haven't seen how to make this work. So here again, I would appreciate any thought that could be used to complete the argument. Thanks in advance!","['rational-functions', 'algebraic-geometry', 'abstract-algebra', 'field-theory']"
108768,Intersection of a line with an Elliptic Curve,"I am trying to show that if a line given by $y = mx + b$ intersects an Elliptic Curve given by $E(\mathbb{K}): y^2 = x^3 + Ax + B$ in three points then the line is not tangent to the curve. Given that char$(\mathbb{K}) \neq 2,3$ and $\mathbb{K}$ is algebraically closed. Also that if they intersect in two points, the line is tangent to the curve. And if they intersect in one point, the intersection is an inflection point. I have tried to characterize the points of intersections and compare the slope of the line and curve at those points but I'm not getting anywhere. any help is deeply appreciated.","['geometry', 'algebraic-geometry', 'elliptic-curves', 'cryptography']"
108769,How does the Artin symbol generalize Legendre and Hilbert symbols?,"I am currently going through a course in Class Field theory and have read that the Artin symbol generalizes the Legendre and Hilbert symbols. I was wondering what field extensions to consider to see this. I define the Artin and Hilbert maps below for the convenience of users who might not have seen it. For a cyclic extension $L$ of a number field $K$, define the Artin symbol for an unramified prime $\mathfrak p$, $\displaystyle\left(\frac{L/K}{\mathfrak p}\right)$ to be that element of the Galois group $G$ of $L/K$ that raises an element of $L$ to its $\text{Norm}(\mathfrak p)$-th power. Extend this definition by multiplicativity (in $G$) to all ideals not containing any ramified prime. For elements $a$ and $b$ in a local field $K$, define the Hilbert symbol $(a,b)$ to be 1 if the equation $z^2 = a x^2 + b y^2$ has a solution $(x,y,z)\in K^3\backslash(0,0,0)$ and -1 otherwise.","['algebraic-number-theory', 'number-theory']"
108782,differentiability/partial derivatives,"This is a problem from a previous graduate preliminary exam in multivariable analysis/calculus that I am trying to solve for my own practice: Problem: Let $f:\mathbb{R}^{2}\rightarrow \mathbb{R}$ be a twice continuously differentiable function satisfying: $f\left ( 0,y \right )=0$ for all $y\in \mathbb{R}$. 1- Prove that $f\left ( x,y \right )=x.g\left ( x,y \right )$ for all $\left ( x,y \right )\in \mathbb{R}^{2}$, where:  $g\left ( x,y \right )=\int_{0}^{1}\frac{\partial f\left ( tx,y \right )}{\partial x}dt$. 2- Show that $g$ is continuously differentiable, and that for all $x$ in $\mathbb{R}$: $g\left ( 0,y \right )=\frac{\partial f}{\partial x}\left ( 0,y \right )$ and $\frac{\partial g}{\partial y}\left ( 0,y \right )=\frac{\partial ^{2}f}{\partial x\partial y}\left ( 0,y \right )$ For the first part: The only thing I could do so far is the following: I am basically trying to start from the right hand side to reach the left hand side. Note that: $g\left ( x,y \right )=\int_{0}^{1}\frac{\partial f\left ( tx,y \right )}{\partial x}dt=\int_{0}^{1}t\frac{\partial f\left ( u,y \right )}{\partial u}dt$ where $u=tx$. Then, I have no idea how to go forward? Any help is appreciated.","['multivariable-calculus', 'real-analysis', 'analysis']"
108789,group of order 28 is not simple,"I have a proof from notes but I don't quite understand the bold part: Abelian case: $a \in G / \{1\}$. If $\langle a\rangle \neq G$, then we are done. If $\langle a\rangle = G$, then $\langle a^4\rangle $ is a proper normal subgroup of $G$. General case: WLOG we can assume $G \neq Z(G)$. $\langle 1\rangle \neq Z(G)$ which is a proper normal subgroup of $G$. Done. Otherwise $|Z(G)|= 1$. 
$$
28 = 1 + \sum_{**}\frac{|G|}{|C_G(x)|}
$$
There must be some $a\in G$ such that 7 does not divide
$$
\frac{|G|}{|C_G(a)|}
$$
It follows that
$\frac{|G|}{|C_G(a)|} = 2 $ or $4$ $\Rightarrow [G:C_G(a)] = 2$ or $4$ $\Rightarrow 28 \mid2!$ or $28\mid4!$. Therefore group of order 28 is not simple. Why are they true?",['group-theory']
108795,Conditions for the disintegration theorem to hold,"The disintegration theorem says that under certain conditions, a probability measure $\mu$ on a measurable space $$ the existence of Let $Y$ and $X$ be two Radon spaces (i.e. separable
  metric spaces on which every probability measure is a Radon measure).
  Let $μ ∈ P(Y)$, let $π : Y → X$ be a Borel-measurable function, and
  let $ν ∈ P(X)$ be the pushforward measure from $Y$ to $X$ by $π$. Then
  there exists a $ν$-almost everywhere uniquely determined family of
  probability measures $\{μ_x\}_{x∈X} ⊆ P(Y)$ such that the function $x \mapsto \mu_{x}$ is Borel measurable, in the sense    that $x \mapsto \mu_{x} (B)$ is a Borel-measurable function for each Borel-measurable set $B ⊆ Y$; $μ_x$ lives on the fiber $π^{-1}(x)$: for $ν$-almost all $x ∈ X$, $$\mu_{x} \left( Y \setminus \pi^{-1} (x) \right) = 0,$$ and so
  $\mu_x(E) = \mu_x(E \cap \pi^{-1}(x));$ for every Borel-measurable function $f : Y → [0, +∞]$,
     $$\int_{Y} f(y) \, \mathrm{d} \mu (y) = \int_{X} \int_{\pi^{-1} (x)}    f(y) \, \mathrm{d} \mu_{x} (y) \mathrm{d} \nu (x).$$ I was wondering if the probability measures can be relaxed to
measures in the disintegration theorem? when $Y = X_1 × X_2$ and $π_i : Y → X_i$ is the natural
projection , we can apply the disintegration theorem, and get the
result each fibre $π_1^{-1}(x1)$ can be canonically identified with $X_2$ and
  there exists a Borel family of probability measures $\{ \mu_{x_{1}}  \}_{x_{1} \in X_{1}}$ in $P(X_2)$ (which is
  $(π_1)∗(μ)$-almost
  everywhere uniquely determined) such that $$  \mu = \int_{X_{1}} \mu_{x_{1}} \, \mu \left(\pi_1^{-1}(\mathrm d x_1) \right)=
    \int_{X_{1}} \mu_{x_{1}} \, \mathrm{d} (\pi_{1})_{*}  (\mu) (x_{1}),
    $$ I wonder if this result is still true if $Y$, $X_i$ are not required
to be Radon spaces but just general measure spaces as long as $Y =
    X_1 × X_2$ and $π_i : Y → X_i$ is the natural projection? In other words, given two measurable spaces $X_1$ and $X_2$ and a measure on the product measurable space $X_1 \times X_2$ , what are some necessary and/or sufficient conditions for the measure on $X_1 \times X_2$ to be the composition of some measure on $X_1$  and some transition measure  from $X_1$ to $X_2$? Thanks and regards!","['probability-theory', 'measure-theory']"
108809,Suggestions for a Global Analysis book,"can somebody tell me some good books or lecture notes in ""global analysis"" ? 
I am a newcomer in this subject. 
thanks in advance. greetings
trito","['ordinary-differential-equations', 'differential-geometry', 'reference-request', 'real-analysis', 'complex-analysis']"
108810,Does a injective function $f: A \to B$ and surjective function $g : A\to B$ imply a bijective function exists? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Proof of a Cantor-Bernstein-like theorem If $A, B$ are sets and there exists an injective function $f : A \to B$ and a surjective function $g: A \to B$, does this imply there is a bijective function $h : A \to B$? If not is there a simple counter example? I was wondering because while reading about Cantor's Theorem, it seems like an injective function existing is like saying $|A| \le |B|$, and surjective function existing says $|A| \ge |B|$. So when they both exist I would expect a bijection to exist too. Am I correct in my reasoning? Thanks.","['cardinals', 'elementary-set-theory']"
108822,I need to factor this function so it is entirely dependent on x- semicircle displacement.,"In the attached image are three functions. The first is a displacement function which takes angle $t$, and returns a radius. The third one is a semicircle and the second one is a semicircle with the displacement function $d()$ applied. Note that the second function includes $y$ in the right hand side (inside $\text{atan2}$). I need to factor this equation so that it is entirely dependent on $x$, and there is no $y$ variable on the right hand side of the equation. Reproduced here, the equation is: $y=\sqrt{ d(\text{atan2}( y, x ) )^2 - x^2 }$ I need to get this ^ y moved to the left. edit: bigger picture, I'm trying to do raycasting of a sphere with a displacement map using an orthographic camera. This is why I only care about the greatest y, because lower y are not visible to the camera due to occlusion.  My thought was that if I could scan across with a single x, on a 2 dimension version of the problem I'd be closer to solving the 3 dimensional version. edit: let me ask this a different way. Given a line, how can I find the location of a the points which this line intersects with the equation? edit again: it seems the answer is binary search. http://http.developer.nvidia.com/GPUGems3/gpugems3_ch21.html",['trigonometry']
108834,Use Fourier series for computing $\sum_{n=1}^{\infty}\frac{1}{(2n-1)^2}$,"I need to compute Fourier series for the following function: $f(x)=\frac{-\pi}{4}
$ for $-\pi \leq x <0$, and $\frac{\pi}{4} $ for $ 0 \leq x \leq \pi$, and then to use it and compute $\sum_{n=1}^{\infty}\frac{1}{(2n-1)^2}$ I tried to use Parseval equality: $$\widehat{f(n)}=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)e^{-inx}=\frac{1}{4in}-\frac{(-1)^n}{4in}, \sum_{-\infty}^{\infty}|\widehat{f(n)}|^2=\frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^2.$$ $$\sum_{-\infty}^{\infty}|\frac{1}{4in}-\frac{(-1)^n}{4in}|=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)=\frac{\pi^2}{16}.$$ Does someone see how can I compute form that the requsted sum? Thanks!","['sequences-and-series', 'fourier-series', 'calculus']"
108843,Handling Cross ratios ( Fractional linear transformations ),"According to remmert there is  a relationship between the crossratios: $$C(z,u,v,w) = \frac{(z-v)(u-w)}{(z-w)(u-v)} \text{ and } C(z,v,u,w)= \frac{(z-u)(v-w)}{(z-w)(v-u)}$$ where $z,u,v,w \in \mathbb{C}$ I have tried multiplying things out to see a relationship, but I don't see anything. What could be meant with ""relationship""? Another question deals with the value of the crossratio: On which of the three arcs through $u,v,w$ must z lie so that $0 < C(z,u,v,w) < 1$? How does one see that there must be three arcs through u,v,w without plotting and how can we characterize the cross ratio without plotting? Thanks for every suggestion.","['complex-analysis', 'analysis']"
108844,Möbius transform which completely preserves circles (how to map a circle?),"(remmert theory of complex function) I am trying to solve this exercise, however it seems impossible because I don't know how to map a circle, and I will be very thankful if somebody points out to me: Given a Circle $C$, is it possible to show that for $a_{1},b_{1}\in \mathbb{C}\backslash C $ there exists a Möbius transformation $$M(z)= \frac{az+b}{cz+d}$$ which fulfills: $$M(C)=C ; M(a_{1})=b_{1}$$ So we can write conditions: $M(a)=b \Rightarrow aa_{1}+b= b(ca_{1}+d)$ How does one map a circle? I thought that a circle in $\mathbb{C}$ needs 3 points to be uniquely determined , so we can put: $z_{1},z_{2},z_{3} \in C$ and the condition is the same as for the a to b mapping: $$az_{k}+b=z_{k}(cz_{k}+d), k=1,2,3 \in \mathbb{N}$$ It seems that there isn't much more one can do with this approach, so I think it is not the right one. What is the right approach?","['complex-analysis', 'analysis']"
108853,"$(0,1)\to\mathbb{R}^2$ injective, continuous, not a homeomorphism on the image","Consider the map $$\gamma\colon (0,1)\to\mathbb{R}^2,\ t\mapsto (\cos(2\pi t),\sin(2\pi t)).$$ This is an example of a map which is continuous and injective but not a homeomorphism onto the image, since the inverse could not be continuous.
In fact, two points arbitrarily close to each other in a small neighbourhood of $(1,0)$ would go far apart in the preimage.
By definition, a function is continuous if the preimage of every open set is open in the domain. How could I find an open set in the support of this curve which is sent to a non-open set in the interval?","['general-topology', 'examples-counterexamples']"
108862,How to determine injectivity and surjectivity for a map $\mathbb{Z}_n \to \mathbb{Z}_{n}$?,"I know how to determine injectivity and surjectivity for maps between regular sets, but in this case I've got some problems. How can I solve this? Given the following map $\psi:\overline{x} \in
 \mathbb{Z}_{16}\mapsto \overline{7}\overline{x}\in\mathbb{Z}_{16}$.
  Without calculating a single element's image, and just using the properties
  of $\overline{7}$ in $\mathbb{Z}_{16}$, decide if $\psi$ is injective,
  surjective or both. If possible, find the inverse of
  $\psi$.",['abstract-algebra']
108865,How to find out if two solutions are equivalent or different?,"Given 5 different numbers ($\in \mathbb N$) in a specific brackets pattern like: $$\left(\left(\left(x_1 + x_2 \right) - x_3\right) \times x_4 \right) / x_5 = 
\text{result}$$ Only the brackets are fixed, the numbers and the operators can be permutated at will. And there must be all the four operators. Does someone knows how could I find out if a permutation of the numbers and of the operators that gives the same result is an equivalent solution under the distributive, associative and/or commutative law or is a different solution that ""just happens"" to give the same result For example: $\left(\left(\left(6 - 3 \right) \times 2\right) / 1 \right) + 5 = 11 $ is equivalent to: $\left(\left(\left(6 - 3 \right) / 1\right) \times 2\right) + 5 = 11 $ but it's different from: $\left(\left(\left(3 - 2 \right) \times 6\right) / 1 \right) + 5 = 11 $ that gives the same result only with this particular choice of numbers: 2,3 and 6.","['algorithms', 'algebra-precalculus', 'abstract-algebra']"
108870,Notation: Set of all functions with finite number of variables from $A$ to $B$?,"The setting here is basic set theory. We denote by $B^A$ the set of all functions from $A$ to $B$. Also, to describe a function with $n$ variables, such that the variables come from $A$ and the function takes values in $B$, we can use $A^n$, the set of all $n$-tuples taking values in $A$ (formally - The set of all functions from $\{1,2,\dots,n\}$ to $A$). So $B^{A^n}$ is the set of all functions of artity $n$ from $A$ to $B$. The question: what is the standard notation (or notations) for the set $\bigcup_{n=1}^\infty B^{A^n}$, the set of all functions of arity at least 1 from $A$ to $B$? Arity of at least 0 is also good (maybe $B^{A^*}$ is used in this case?)","['notation', 'elementary-set-theory']"
108880,"Terminology: center (of a group, of a ring, ...)","What is the etymology of the word ""center"" as used in abstract algebra, e.g. the center of a group, or of an algebra? My best guess is that it might've come from matrix algebras, where often the center just consists of (scalar) diagonal matrices, whose nonzero coefficients appear in the ""center"" of the matrix.","['math-history', 'terminology', 'abstract-algebra']"
108890,Fibonacci numbers with largest prime factor appearing more than once,$F_6=2^3$ and $F_{12}=2^43^2$. Is there an $n>12$ such that $F_n=p^2k$ with $p$ prime and $k$ is $p$-smooth?,"['fibonacci-numbers', 'number-theory']"
108892,Direct way to show: $\operatorname{Spec}(A)$ is $T_1$ $\Rightarrow$ $\operatorname{Spec}(A)$ is Hausdorff,"In the book of Atiyah and MacDonald, I was doing exercise 3.11. One has to show that for a ring $A$, the following are equivalent: $A/\mathfrak{N}$ is absolute flat, where $\mathfrak{N}$ is the nilradical of $A$. Every prime ideal of $A$ is maximal. $\operatorname{Spec}(A)$ is $T_1$. $\operatorname{Spec}(A)$ is Hausdorff. I already proved this by doing 1 $\Leftrightarrow$ 2, 2 $\Leftrightarrow$ 3, 4 $\Rightarrow$ 3, and 1 $\Rightarrow$ 4. Then I wondered: is there a direct way of showing that $X=\operatorname{Spec}(A)$ has the Hausdorff property when it already is $T_1$? I don't see any ""canonical"" disjoint open subsets of $X$ that I could construct, given $x,y\in X$ distinct points. Googling for a solution which takes this approach led me here (again), where he shows 2 $\Rightarrow$ 4, which should be nearly the same as 3 $\Rightarrow$ 4. But I don't know the notation $X_{\mathfrak{p}}$ he uses. I guess it means $X\smallsetminus V(\mathfrak{p})$, analogous to the notation $X_f$ for basic open subsets of the Zariski topology. But why are $X_{\mathfrak{p}}$ and $X_{\mathfrak{q}}$ disjoint there? Assuming 2 (resp., 3), we have $V(\mathfrak{p})=\{\mathfrak{p}\}$, thus $X_{\mathfrak{p}}=X\smallsetminus\{\mathfrak{p}\}$, $X_{\mathfrak{q}}=X\smallsetminus\{\mathfrak{q}\}$, and hence the intersection would contain all points different from $\mathfrak{p}$ and $\mathfrak{q}$. Did I misinterpret the notation, or am I maybe just not getting what the author is doing here? Thanks in advance!","['commutative-algebra', 'algebraic-geometry']"
108899,How close are these events?,"I'm a computer programmer and we're running into a weird error on our website. We have a large number users who do a certain task.  Between the entire set of users, this task happens about once every 20 seconds, but of course each user is unique. We're seeing a strange problem about once every four hours that may be caused by users doing the task at the exact same time as another. I tried to find this answer on my own, and got as far as the Poisson distribution, but I haven't dealt with statistics beyond basic Poker strategy since my stats class in college 15 years ago.  So, my question: Given a large number of independent events that happen every 20 seconds, what is the exact level of unusual closeness that I would expect to see every four hours?",['statistics']
108923,Upper bounds on the size of $\operatorname{Aut}(G)$,"Any automorphism of a group $G$ is a bijection that fixes the identity, so an easy upper bound for the size of $\operatorname{Aut}(G)$ for a finite group $G$ is given by \begin{align*}\lvert\operatorname{Aut}(G)\rvert \leq (|G| - 1)! \end{align*} This inequality is an equality for cyclic groups of orders $1$ , $2$ and $3$ and also the Klein four-group $\mathbb{Z}_2 \times \mathbb{Z_2}$ . I think it's reasonable to believe that they are the only groups with this property. The factorial $(|G| - 1)!$ is eventually huge. I searched through groups of order less than $100$ with GAP and found no other examples. The problem can be reduced to the abelian case. We can check the groups of order $< 6$ by hand. Then if $|G| \geq 6$ and the equality holds, we have $\operatorname{Aut}(G) \cong S_{|G|-1}$ . Now $\operatorname{Inn}(G)$ is a normal subgroup of $\operatorname{Aut(G)}$ , and is thus isomorphic to $\{(1)\}$ , $A_{|G|-1}$ or $S_{|G|-1}$ . This is because $A_n$ is the only proper nontrivial normal subgroup of $S_n$ when $n \geq 5$ . We can see that $(|G| - 1)!/2 > |G|$ and thus $\operatorname{Inn}(G) \cong G/Z(G)$ is trivial. How to prove that there are no other groups for which the equality $\lvert\operatorname{Aut}(G)\rvert = (|G| - 1)!$ holds? Are any better upper bounds known for larger groups?","['automorphism-group', 'finite-groups', 'group-theory']"
108941,Traversing the infinite square grid,"Suppose we start at $(0.5,0.5)$ in an infinite unit square grid, and our goal is to traverse every square on the board. At move $n$ one must take $a_n$ steps in one of the directions, north,south, east or west. And every square we walk over is marked as visited, we are not allowed to walk over a visited square twice. Is there a sequence of directions, such that we can visit every square of the board exactly once if $a_n=n$? Is there such a sequence if we are allowed to walk in diagonal directions aswell? Is there a general algorithm to check, given $a_n$, if a path exists? Is there a path in any of the above cases for $a_n=n^2$?","['geometry', 'number-theory', 'combinatorial-game-theory', 'graph-theory', 'combinatorics']"
108951,Is the centralizer of a semisimple element in a connected algebraic group always connected,"There is an exercise on page 142 of Humphreys' Linear Algebraic Groups : Ex.1 Let $G$ be a connected algebraic group, $x \in G$ is semisimple. Must $C_G(x)$ be connected? When $G$ is solvable, I think of another fact whose correctedness is proved on the book: Let $H$ be a subgroup (not necessarily closed) of a connected solvable group $G$, $H$ consisting of semisimple elements. Then $C_G(H) = N_G(H)$ is connected. So, suppose that $G$ is solvable, set $H = \langle x \rangle$. It appears that $C_G(x)$ is connected. I think the general case could be reduced to the solvable case if for any $y \in C_G(x)$, I can find a Borel subgroup of $G$ containing both $x$ and $y$. (Then $y$ must be in $C_B(x)$ which is connected.) I think the Borel subgroup could be found, may be through the method of Borel variety. But I have difficulty in this. Another exercise on the same page is: Ex.2 Let $G$ be a connected algebraic group. If $x \in G$ has semisimple part $x_s$, then $x$ is contained in the identity component of $C_G(x_s)$. If the answer to Ex.1 is affirmative, then Ex.2 would be obvious, since $x \in C_G(x_s)$. But I am not sure. So, would you please tell me the answer to Ex.1 , or help me with the proof or counterexample? If the centralizer could be not connected, how can I give Ex.2 a proof? Sincere thanks.","['algebraic-geometry', 'algebraic-groups']"
108952,"If $[G:H]=n$, then $g^{n!}\in H$ for all $g\in G$.","I have the following question: Let $G$ be a group and let $H$ be a subgroup of finite index of $G$ . Let $|G:H|=n$ Then this holds: $g^{n!}\in H$ for all $g\in G$ . Why is this true? I think, that's not very difficult, but I have no idea at the moment. Thanks!","['group-theory', 'abstract-algebra']"
108953,An application of Vandermonde determinant,"Let $\lambda_1,\ldots,\lambda_n$ be complex numbers such that for each positive integer $k\geq 0$,
$$\sum_{i=1}^n \lambda_i^k=0.$$
Here I am supposed to show that $\lambda_i=0$ for each $i\in 1,\ldots,n$. One of my friends said it sounds that I should use Vandermonde determinant. I tried to find an appropriate version of Vandermonde determinant that I may apply here, but I could not.
I appreciate if you let me know a suitable version.","['matrices', 'complex-numbers', 'polynomials']"
108962,"Steps to solve this system of equations: $\sqrt{x}+y=7$, $\sqrt{y}+x=11$","I want to solve this system of equations, I have been out of Maths for a long!! $$\sqrt{x}+y=7$$ $$\sqrt{y}+x=11$$ Just wondering easiest step to find values for $x$ and $y$ from the above equations?","['radicals', 'algebra-precalculus', 'systems-of-equations']"
108973,Inclusion Exclusion vs. Generating Functions,"To what extent are the Inclusion Exclusion principle and Generating Functions interchangeable?  Is there a general principle?  For instance, I asked the following question, Number of 5 letter words over a 4 letter group using each letter at least once .  Could it be solved with generating functions? In general, what classes of problems solvable by inclusion exclusion are solvable by generating functions?","['inclusion-exclusion', 'generating-functions', 'combinatorics']"
108982,How can I prove this inequation $\Pr\{X+Y<t\} \le \Pr\{X<t\} \Pr\{Y<t\}$,"Could you please help me to prove the inequality probability as follows:
$\Pr\{X+Y<t\} \le \Pr\{X<t\} \Pr\{Y<t\}$
where $X$ and $Y$ are non-negative independent random variables with common distribution.
Many thanks for your helps","['statistics', 'probability-distributions', 'inequality', 'probability-theory']"
108987,Tensor Decomposition,"Consider a tensor product $$ V^{\otimes n} = \underbrace{V\otimes\cdots\otimes V}_{n} $$ where $V$ is a vector space over $\mathbb R$, $\dim V = m$ , hence $\dim V^{\otimes n} = m^n$ . So every $A \in V^{\otimes n}$ can be represented as $$A = \sum_{i=1}^r a^i_1 \otimes a^i_2 \ldots \otimes a^i_n, \;\;\; a_i \in V $$ in a non-unique way. Taking $R$ to be minimum $r$ among all the possible decompositions of A. $$R = \min \left \{ r : A = \sum_{i=1}^r a^i_1 \otimes a^i_2 \ldots \otimes a^i_n, \;\;\; a_i \in V \right \}$$ How many tensors have certain $R$ ? How many tensors have $R=1$? Or $R = m^n$ ? What is the typical $R$ (mean, median mean, the most probable), what is the distribution? IMPORTANT How should I imagine (picture) tensors for which $R$ is (near) maximum? What hinders them from decomposition? Maybe there are some experimental data. I'm mostly interested in high $m$'s and $n$'s, though every answer is welcome.","['tensor-products', 'linear-algebra', 'multilinear-algebra']"
108998,Parametric Equations for a $2$-torus,"I know that for a torus (with one hole) the parametric equations describing it are $x= (c + a\cos v)\cos u, y= (c + a\cos v)\sin u, z= a\sin v$, where $c$ is the radius from the center of the hole to the center of the torus tube and $a$ is the radius of the tube. My question is what would be the corresponding parametric equations describing a $2$-torus, i.e. a torus with $2$ holes. How about an $n$-torus?","['general-topology', 'surfaces', 'differential-geometry']"
109015,Shrinking Map and Fixed Point via Iteration Method,"Let $T$ be a map from a compact metric space $X$ into itself satisfying $ d(Tx,Ty) < d(x,y)$ for all distinct $x,y$ in $X$. It is true that $T$ has a unique fixed point. Fix $x_0 \in X$ any point, and define the recursive sequence $\{ x_n \}$ by $Tx_0 = x_1$, and $T^{n} x_0 = x_n $. If this sequence converges, it is true that it converges to the unique fixed point in $X$. However, I am having trouble showing that the sequence does converge, i.e., is Cauchy. I can show the sequence is Cauchy if the mapping had been a contraction, but the technique there doesn't generalize well. Edit: I came up with a simpler proof than from anything else I could find online, but it's not quite complete. Suppose for the sake of contradiction that $\{T^nx_0\}$ did not converge to the fixed point $\alpha$. Then $\exists \epsilon$ and a subseq $\{ T^{n(k)} x_0 \}$ s.t. for each $n(k)$, $d(T^{n(k)} x_0 , \alpha ) > \epsilon $. By compactness, $ \{ T^{n(k)} x_0 \}$ admits a convergent subseq. I want to say this subseq, say $\{ T^{n_k(m)} x_0\}_{m \in \mathbb{N}}$ and converging to $\beta$, must actually converge to $\alpha$ by continuity of $T$, but can can this be done? It's true that $T(T^{n_k(m))} x_0) \rightarrow T(\beta)$, but can I say $T^{n_k(m) + 1} x_0 \rightarrow \beta $, so that $\beta$ is actually the fixed point $\alpha$?",['analysis']
109023,A weird subset of $\mathbb R^2$,"Is there a path-connected subset of $\mathbb R^2$ such that any path connecting 2 distinct points in that subset has infinite length? I am told that there is such a set, but I don't know what it is. Thank you.","['general-topology', 'metric-spaces']"
109029,Convergence/Divergence of infinite series $\sum_{n=1}^{\infty} \frac{(\sin n+2)^n}{n3^n}$,"$$ \sum_{n=1}^{\infty} \frac{(\sin n+2)^n}{n3^n}$$ Does it converge or diverge? Can we have a rigorous proof that is not probabilistic? For reference, this question is supposedly a mix of real analysis and calculus.","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis']"
109032,Singing Bird Problem,"For my algorithms class, the professor has this question as extra credit: The Phicitlius Bauber bird is believed to never sing the same song twice. Its songs are always 10 seconds in length and consist of a series of notes that are either high or low pitched and are either 1 or 2 seconds long. How many different songs can the Bauber bird sing? This strikes me as a combinatorial problem, but I'm having trouble figuring out the exact formula to use to fit the included variables of 10 seconds length, 2 notes and 2 note periods. At first, I thought that $\binom{10}{2}*\binom{10}{2}$ can be a solution, since it fits finding all combinations of both and multiplies the total. My issue is this results in a total of 2025 possible songs, and this just seems a little on the low side. Any assistance is appreciated.",['combinatorics']
109034,Showing this integral from complex analysis is an integer without residues,"I've already proven that the winding number is an integer, now I want to show that, given the following assumptions: The function $f$ is holomorphic on the domain $D$ $\gamma$ is a piecewise-smooth, closed curve in $D$ $f$ does not vanish on $\gamma$ It's true that $$ \frac{1}{2\pi i}\int_{\gamma}\frac{f '(\xi)}{f(\xi)}d\xi \in \mathbb{Z}.$$ Here's what I'm thinking, although it's not at all a rigorous proof: $$\frac{1}{2\pi i}\int_{\gamma}\frac{f '(\xi)}{f(\xi)}d\xi=\frac{1}{2\pi i}\int_{\gamma}\frac{d}{d\xi}\log_{R}(f(\xi))d\xi=\frac{1}{2\pi i}\{\log_{R}(f(\xi_1))-\log_{R}(f(\xi_2))\}$$ where $\log_{R}$ is the logarithm function defined on the riemann surface from the wikipedia page on complex logarithms wiki page and $\xi_1,\xi_2$ are two points which are the same when considered as points of $\mathbb{C}$ (because $\gamma$ is closed) but which have different arguments, differing by  $k2\pi i$ for $k \in \mathbb{Z}$, when considered as points on the Riemann surface $R$. I think you probably get that idea that I've got. IT could be totally off, but this is what I was led to in thinking about it. Trouble is, we haven't really discussed this Riemann surface, so I doubt it's what is expected. Any comments or suggestions?",['complex-analysis']
109037,Weaker version of Cauchy sequence criteria [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Why doesn't $d(x_n,x_{n+1})\rightarrow 0$ as $n\rightarrow\infty$ imply ${x_n}$ is Cauchy? my question is this: The following definition is weaker than the definition of Cauchy sequences: $\forall \; \epsilon > 0, \;\exists N \in \mathbb{N} \;s.t.\; \forall\; n \geq N, \; |a_{n+1}-a_n | < \epsilon.$ Show that this is not equivalent to $(a_n)$ being a Cauchy sequence. The definition of Cauchy sequence is: A sequence $(s_n)$ is Cauchy if (and only if) for each $\epsilon > 0$ there exists an integer $N$ with the property that $|s_n-s_m| < \epsilon$ whenever $n\geq N$ and $m \geq N$. Note that a sequence (of real numbers) is convergent if and only if it is Cauchy. So I see an (the?) obvious difference between these two in that the Cauchy criteria demands that all values in a sequence above a certain index ($N$) are within a prescribed tolerance of each other, whether adjacent or not. This is where the question is weaker, in that it only requires the immediately adjacent values of the sequence to be within a tolerance of $\epsilon$. This would then allow, by taking successive differences of adjacent values, to accumulate a difference greater than $\epsilon$. This is seen as, $$\left| \sum_{i=1}^{n+1}\,a_i - \sum_{i=1}^{n}\,a_i\right| < \epsilon,\quad
\left|\sum_{i=1}^{n+2}\,a_i - \sum_{i=1}^{n+1}\,a_i\right| < \epsilon,\quad
\left| \sum_{i=1}^{n+3}\,a_i - \sum_{i=1}^{n+2}\,a_i\right| < \epsilon,$$
and summing each side of the inequalities gives (after reverting to sequence-notation and employing the triangle inequality),
$$
\left(|a_{n+1}-a_n| + |a_{n+2}-a_{n+1}| + |a_{n+3}-a_{n+2}| + \cdots + |a_{K} - a_{K-1}| \right) \leq \left( \epsilon_{1,2} + \epsilon_{2,3} + \epsilon_{3,4} + \cdots + \epsilon_{K-1,K} \right)
$$
which implies
$$\left( \epsilon_{1,2} + \epsilon_{2,3} + \epsilon_{3,4} + \cdots + \epsilon_{K-1,K} \right)_{\textrm{ by weaker criteria }}   \geq |a_n - a_{n+K}|_{\textrm{ by Cauchy criteria }}$$ If I understand these differences correctly, then my main problem is putting these into a formal mathematical proof. Unless this would qualify? Thanks much for the help and the site!","['sequences-and-series', 'real-analysis']"
109061,Why solve polynomial equations?,"Most people learn in linear algebra that its possible to calculate the eigenvalues of a matrix by finding the roots of its characteristic polynomial. However, this method is actually very slow, and while its easy to remember and its possible for a person to use this method by hand, there are many better techniques available (which do not rely on factoring a polynomial). So I was wondering, why on earth is it actually important to have techniques available to solve polynomial equations? (to be specific, I mean solving over $\mathbb{C}$) I actually used to be fairly interested in how to do it, and I know a lot of the different methods that people use. I was just thinking about it though, and I'm actually not sure what sort of applications there are for those techniques.","['polynomials', 'linear-algebra', 'analysis']"
109062,Linear transformations in infinite dimensional vector spaces,"If we look at an $n$ - dimensional vector space $V$ and a linear transformation 
\begin{equation}
T : V \to V, \quad x \mapsto Tx \quad \forall \, x \in V
\end{equation}
then given a choice of basis for $V$ one can represent $T$ in terms of a $n \times n$ matrix $A_T = A_T(i,j)$ Is this also the case for linear transformations on infinite - dimensional vector spaces, where we replace the matrix $A_T$ by an integral ? In particular, since differentiation is a linear map, that would mean differentiation can be written in the form of an integral ... I realize this is either a dumb question (because it is obviously wrong) or it is some classic result I haven't found yet. In both cases it would be great to get some reference where I can learn more about it, many thanks!","['operator-theory', 'functional-analysis', 'differential-operators']"
109069,Stolz-Cesàro Theorem,"Recently I've been trying to find a satisfactory proof of the Stolz-Cesàro Theorem but I havent found any. As I remember the claim is as follows: Let $${\left\{ {{b_n}} \right\}_{n \in {\Bbb N}}}$$ be a sequence such that $${b_{k + 1}} - {b_k} > 0  $$ and $$ \mathop {\lim }\limits_{k \to \infty }\sum_{n=0}^{k} {b_n} = \infty   $$ Then if $${\left\{ {{a_n}} \right\}_{n \in {\Bbb N}}}$$ is another sequence and the limit $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_{n + 1}} - {a_n}}}{{{b_{n + 1}} - {b_n}}} = \ell_1 $$ exists, then $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_n}}}{{{b_n}}} = {\ell _2}$$ exists too and $${\ell _1} = {\ell _2}$$","['sequences-and-series', 'limits']"
109070,Integration analog of automatic differentiation,"I was recently looking at automatic differentiation. Does something like automatic differentiation exist for integration? Would the integral be equivalent to something like Euler's method? (or am I thinking about it wrong?) edit:
I am looking at some inherited code that includes https://projects.coin-or.org/ADOL-C as a black box.","['calculus', 'integration']"
