question_id,title,body,tags
1364776,How can $p^{q+1}+q^{p+1}$ be a perfect square?,"How can one find all primes $(p,q)$  such that $p^{q+1}+q^{p+1}$ is a perfect square I considered it $\mod 2$ and found a trival solution . Im curious about an eventual answer Diophantine equations are extremely hard.
This seems harder than IMO Q2 of this year . edit1: I think one should consider it $\mod 4$ .","['prime-numbers', 'number-theory', 'diophantine-equations']"
1364781,Can we have $x\in A$ and $x\in A\times B$?,"Is it possible, for sets $A$ and $B$, to have $x\in A$ and $x\in A\times B$? It seems unlikely to me, but maybe some degenerate case? $x=\emptyset$?",['elementary-set-theory']
1364788,Prove that $\cos^2(\theta) + \cos^2(\theta +120^{\circ}) + \cos^2(\theta-120^{\circ})=3/2$,"Prove that $$\cos^2(\theta) + \cos^2(\theta +120^{\circ}) + \cos^2(\theta-120^{\circ})=\frac{3}{2}$$ I thought of rewriting $$\cos^2(\theta +120^{\circ}) + \cos^2(\theta-120^{\circ})$$ as $$\cos^2(90^{\circ}+ (\theta +30^{\circ})) + \cos^2(90^{\circ}-(\theta-30^{\circ}))$$ However I don't seem to get anywhere with this.
Unfortunately I don't know how to solve this question. I would be really grateful for any help or suggestions. Many thanks in advance!","['geometry', 'trigonometry']"
1364821,Verify that $\binom{n+1}{4} = \frac{\left(\substack{\binom{n}{2}\\{\displaystyle2}}\right)}{3}$ for $n \geq 4$,"Verify that for $n \geq 4$ $$\dbinom{n+1}{4} = \frac{\left(\substack{\binom{n}{2}\\{\displaystyle2}}\right)}{3}$$ Now present a combinatoric argument for the above. First, by verify does it mean check for some n > 3? if so, then n = 4 gives both sides value 5. I have tried expanding both sides and It just gets messy, but i'm sure that would be attempting to prove it? I cant quite move ahead with this one, I have said that $\left(\substack{\binom{n}{2}\\{\displaystyle2}}\right)$ is the number of ways of choosing 2 pairs of objects from n objects. my reasoning for this is that $\dbinom{n}{2}$ is the number of ways of choosing 2 objects from n and hence $\left(\substack{\binom{n}{2}\\{\displaystyle2}}\right)$ is the number of ways of choosing 2 of these ways... What i am struggling to do is understand how the three comes into it.",['combinatorics']
1364850,Exchange of Limit and Integral with Nets [duplicate],"This question already has answers here : A net version of dominated convergence? (2 answers) Closed 6 years ago . In topology, we have seen that there are examples of nets so that monotone and dominated convergence do not hold anymore. In particular, we worked with the net $\mathfrak{F}$ containing finite subsets of $[0,1]$ ordered by inclusion. We used the Lebesgue-measure $\lambda$ restricted to $[0,1]$. The net $(\chi_F)_{F \in \mathfrak{F}}$ is monotonically increasing and is dominated by $\chi_{[0,1]}$. $(\chi_F)_{F \in \mathfrak{F}}$ converges pointwise to $\chi_{[0,1]}$ as well. But $\lim_{F \in \mathfrak{F}} \int \chi_F d\lambda ≠ \int \chi_{[0,1]} d\lambda$. Are there properties/constraints of the net itself (except the ones elaborated by David C. Ullrich below) or of the measure that expand the exchangeability of limit and integral to nets? Some of my thoughts on monotone convergence: The problem is that we cannot sort the functions we have in order to make it monotonous as one is used to when dealing with natural numbers as an index. But we do have a directed set at least. Do you have any ideas how to constrain the functions in the net in order to get a behavior that is similar to monotonicity? I have the impression it is, because monotonous functions only have countable points of discontinuity calling them $(a_n)_{n \in \mathbb{N}}$, at least in $\mathbb{R}$, which might be used for collecting some functions of the net. Defining a set: $\{]a_i, \infty[;$$a_i$ point of discontinouity$\}$ and taking a look at its $\sigma$-Algebra, introducing an ordering there via inverse inclusion ($ A ≤ B \Leftrightarrow A  	\supseteq B$). Adding ${\infty}$ to this set, we might find a directed set. (just some thoughts... to be continued)","['nets', 'general-topology', 'measure-theory']"
1364864,Probability versus intuition problem: coins,"You are playing with some friends this summer. The game is simple: a fair coin is picked and tossed. Before each toss, you and your friends bet on either heads or tails coming up. Say you begin playing at 8 in the afternoon, and time flies till 12 while playing and chatting. However something interesting happened in those 4 hours. You tossed the coin around 200 times, and out of those 200 times, heads came up 180 times, surprisingly, but possible. Once again, one friend is an engineer and he certified the coin as fair. In the $201$st round, just before going home, everyone decides to do an all-in for the last toss. You need to decide where to put all your money, or how to win as much as possible. Which side should you trust? In the analysis I didn't the result did convince me, but in the end the coin tosses should obey a $X \sim Bi(n=201 , p=\frac{1}{2})$, and we have to find $P(X=181 \mid X \ge 180)$ so the probability should be $$
P(Y_{201}=heads)=
\frac{P(X=181)}{P(X \ge 180)}=
\frac{\binom{201}{181}\frac{1}{2}^{201}}{1-F(180)}=
.8908
$$ But shouldn't the last toss be independent of the of history of the game? If another friend arrived just for the last toss, he sees the probability as one half. I'm not sure of how to interpret this situation! Maybe I did something wrong with the binomial or missed some concept.","['probability-theory', 'soft-question']"
1364887,Number of abelian groups of order 108 [duplicate],"This question already has answers here : Computing the number of nonisomorphic finite abelian groups of order $n$ (2 answers) Closed 8 years ago . What is the number  of  abelian groups of  order 108 upto isomorphism ? To answer  this I wrote explicitly the possible abelian groups of order 108 as follows : $$\Bbb Z_{108}$$ $$\Bbb Z_{4}\times\Bbb Z_{3}\times\Bbb Z_{9}$$ $$\Bbb Z_{2}\times\Bbb Z_{2}\times\Bbb Z_{27}$$ $$\Bbb Z_{4}\times\Bbb Z_{3}\times\Bbb Z_{3}\times\Bbb Z_{3}$$
  $$\Bbb Z_{2}\times\Bbb Z_{2}\times\Bbb Z_{3}\times\Bbb Z_{9}$$ $$\Bbb Z_{2}\times\Bbb Z_{2}\times\Bbb Z_{3}\times\Bbb Z_{3}\times\Bbb Z_{3}$$ And I  found  the  answer  to be 6. But  my problem  is  that  what  if  I  was  given  a much bigger  number? Is this  the  only  way  to  find  abelian  groups  of  a  certain  order? If there  are  better  ways  to find  the  exact  answer  to  such  question please  let  me  know.",['abstract-algebra']
1364925,Eigenvalues and eigenspaces of AB,"Problem: Consider two matrices $A, B \in \mathbb{R}^{3 \times 3}$. Suppose $A$ has three distinct real eigenvalues $\lambda_1, \lambda_2$ and $\lambda_3$ with respective eigenspaces $E_{\lambda_1}, E_{\lambda_2}$ and $E_{\lambda_3}$. Suppose furthermore that $B$ has two distinct real eigenvalues $\mu_1$ and $\mu_2$ with respective eigenspaces $E_{\mu_1} = \text{span}(E_{\lambda_1}, E_{\lambda_2})$ (the space spanned by $E_{\lambda_1}$ and $E_{\lambda_2}$) and $E_{\mu_2} = E_{\lambda_3}$. 1) Determine the eigenvalues and corresponding eigenspaces of $AB$. 2) Show that $AB = BA$. Attempt at solution: I have no idea how to do this. I tried writing $\det(A - x \mathbb{I}_3) = (-1)^3 (x- \lambda_1) (x- \lambda_2) (x- \lambda_3)$ and then using the fact that $\det(AB) = \det(A) \det(B)$. But then I figured that the characteristic equation doesn't necessarily have to split like that ?","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1364948,Difference between generator and the sigma algebra generated by this generator,"Suppose $X$ is any set and $\mathcal{F} \subseteq 2^X $. By definition, I have learnt that $\sigma( \mathcal{F} ) $ is the smallest $\sigma$-algebra that contains $\mathcal{F} $. I am trying to understand the difference between $\sigma( \mathcal{F} ) $ and $\mathcal{F} $. With specific example, suppose $\mathcal{F} = \{ f(A) : A \in \mathcal{G} \} $ where $\mathcal{G} $ is a $\sigma$-algebra. I am trying to understand $\sigma( \mathcal{F} ) $ and $f$ is a real-valued function defined on $X$. Obviously, $\sigma( \mathcal{F} ) $ contains all the $f(A) $ for $A \in \mathcal{G} $. What else does it contain? Because we don't have $\sigma( \mathcal{F} ) = \mathcal{F} $.","['real-analysis', 'measure-theory']"
1364970,Help with proving that $\pi$ is irrational,"I was trying to prove that $\pi$ is irrational, just to see if I could do it. So far, I've tried to do this by using the fact that the sum $$S=\sum\limits_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$$ and arguing that $S$ is irrational instead, and thus implying that $\pi$ is also irrational. To do this, I thought I could use partial sums $S_n$ of $S$: $$S_n=\sum\limits_{k=1}^n \frac{1}{k^2}=\frac{A_n}{B_n}$$
where the fraction $A_n/B_n$ is written in lowest terms. We can note that the sequence $\lbrace S_n \rbrace$ is a strictly increasing sequence, with $\pi^2/6$ as its lowest upper bound, so I thought that maybe the sequences $\lbrace A_n \rbrace$ and $\lbrace B_n \rbrace$ both have no upper bound, and the sequences would tend to infinity, and if I were able to prove this, I thought I could use it to argue that $S$ is an irrational number, using the fact that every rational number can be written as the quotient between two finite integers. We note that $A_n\geq B_n$ for all natural $n$, as $S_n\geq 1$, so all we would really need to prove in that case is that $\lbrace B_n \rbrace \rightarrow \infty$(if this assertion is even correct). At first I thought that both $\lbrace A_n \rbrace$ and $\lbrace B_n \rbrace$ would be increasing sequences, but after checking with Maple I noticed that they weren't, sadly enough($S_9=\frac{9778141}{6350400}$ and $S_{10}=\frac{1968329}{1270080}$). However, they do indeed seem to get very large very quickly, so I'm thinking that my hypothesis about $\lbrace A_n \rbrace$ and $\lbrace B_n \rbrace$ is correct. But I have trouble proving my hypothesis, and I'm kind of stuck, no knowing what to do. Is there a way to prove that $\lbrace B_n \rbrace \rightarrow \infty$? And of course, is this approach to prove that $\pi$ is irrational logically sound, or is it fundamentally flawed in some important aspect? In the latter case, what idea should I try next?","['number-theory', 'pi']"
1364979,Asymptotic behavior of the generalized polygamma function,"The generalized polygamma function $^{[1]}$ $\!^{[2]}$ is defined as
$$\psi^{(\nu)}(z)=e^{-\gamma\!\;\nu}\;\partial_\nu\!\left(\frac{e^{\gamma\!\;\nu}\;\zeta(\nu+1,z)}{\Gamma(-\nu)}\right),\tag1$$
where the order $\nu$ can be an arbitrary complex number. For a nonnegative integer order we have to take a limit $\nu\to n$, and then we get the usual polygamma function
$$\psi^{(n)}(z)=\partial_z^{n+1}\ln\Gamma(z),\quad n\in\mathbb N.\tag2$$
I am trying to understand asymptotic behavior of the generalized polygamma function for large imaginary orders. Based on numerical calculations I conjecture that
$$\lim\limits_{x\to\infty}\frac{\ln\left|\psi^{(ix)}(1)\right|}x\stackrel?=\frac\pi2.\tag3$$
Could you suggest and ideas how to prove (or refute) this conjecture? Some sources $^{[3]}$ use a different generalization of the usual polygamma function to complex orders :
$$\begin{align}\pmb\psi^{(\nu)}(z)&=\frac{1+z\,\psi^{(0)}(z)+\nu\,(\ln z-\psi^{(0)}(-\nu)-\gamma)}{z^{1+\nu}\,\Gamma(1-\nu)}\\&+\frac{\nu\,z^{1-\nu}}{\Gamma(2-\nu)}\,\sum_{k=1}^\infty\frac{{_2F_1}\left(\begin{array}{c}1,\,1\\2-\nu\end{array}\middle|-\!{\Large\frac z k}\right)}{k\,(k+z)}.\end{align}\tag4$$
For example, this is how PolyGamma is implemented in Mathematica . Again, for non-negative integer orders we have to take a limit, and it also gives us back the usual polygamma function. But for other (fractional and complex) orders this generalization behaves differently. Still, it seems that for large imaginary orders it has a similar behavior and I conjecture that
$$\lim\limits_{x\to\infty}\frac{\ln\left|\pmb\psi^{(ix)}(1)\right|}x\stackrel?=\frac\pi2.\tag5$$ Update: There is an equivalent definition for $\pmb\psi^{(\nu)}(z)$ using an integral representation that looks somewhat simpler than formula $(4)$ above, but is valid only for $\Re(\nu)<0$; it can be extended to $\Re(\nu)\ge0$ using analytic continuation:
$$\pmb\psi^{(\nu)}(z)=\frac1{\Gamma(-\nu)\,z^\nu}\left(\frac{\psi^{(0)}(-\nu)+\gamma-\ln z}{z}+\int_0^1\frac{\psi^{(0)}(1+x\!\;z)}{(1-x)^{1+\nu}}\,dx\right).\tag6$$","['polygamma', 'limits', 'special-functions', 'zeta-functions', 'complex-analysis']"
1364986,Evaluating $\sum_{n=0}^{\infty } 2^{-n} \tanh (2^{-n})$,"Reading in some tables pages I found 
$$\sum _{n=0}^{\infty } 2^{-n} \tanh \left(2^{-n}\right)=\tanh (1) \left(1+\coth ^2(1)-\coth (1)\right)$$ 
I try to split in two sum using the roots of the $\tanh$ but I could not to get the correct answer.","['closed-form', 'sequences-and-series', 'calculus', 'hyperbolic-functions']"
1364987,Evaluating an integral and differentiation,"I'm trying to understand the math in a journal paper, but I'm stuck on figuring out one of the integrals. 
Here is the paper called, ""Simultaneous optimization of the material properties and the topology of functionally graded structures"" http://www.sciencedirect.com/science/article/pii/S0010448508000249 Here is the problem equation part
$$
\alpha*\int_{\Omega} \left|\nabla w(x)\right|^2dx \tag 1
$$
where the omega and dx indicate an area integral over a domain. Then the equation is differentiated with respect to omega
Then the authors say they integrate by parts to get $$
-\int_{\Omega} \alpha \Delta\omega dx + \int_{\Gamma}\nabla\omega(x)*nds \tag 2 
$$ I'm not sure how they got the equation. When I differentiate the first equation, I get this, but I'm not sure how integration by parts makes it simplier. It looks like they used the divergence theorem in there somewhere, but I'm not sure. $$
2*\nabla(w)*\frac{d\nabla(w)} {dw} \tag 3
$$ Thanks for the help. It is equation 15 and 17 in the paper, if that helps. Anthony","['derivatives', 'integration']"
1364999,Completeness of the vector field $e^{-x} \frac{\partial}{\partial x} + \frac{\partial}{\partial y}$,"I just want to bounce this off of the smart people on MSE to make sure I understand what's going on when we discuss complete vector fields. Consider the following field. $X = e^{-x} \frac{\partial}{\partial x} + \frac{\partial}{\partial y}$. We would like to determine if this vector field is complete. To do so, we solve the system of ODEs defined by it, and check to see if all the integral curves are defined for all $t$. The system of ODEs is $\frac{dx}{dt} = e^{-x}$, and $\frac{dy}{dt} = 1$. 
Solving the second equation first it is easy to observe that $y=t+k$. On the other hand, the first equation implies that $e^x dx = dt$ and hence that $e^x = t +c$, or that $x = \ln (t+c)$. But this is not defined for some $t$. Am I correct in interpreting this to say that the integral curves can be thought of as tracing out the paths $e^x +c$ (of course the rate at which these curves are traced out goes down with $t)$? I believe that this vector field is not complete because this notion does not make sense for negative $t$ as we observed before. If I'm completely off base, how should I think about completness of vector fields, and how to check it? edit: corrected some typos as pointed out in comments/answers.","['vector-fields', 'differential-geometry', 'ordinary-differential-equations']"
1365004,Find a non injective function between a set of integers and itself,"Say we have a set of integers:
$ A = \left\{1,2,6,8\right\}$ is there any way to find a non-injective function that when fed any of the numbers in $A$ gives another number in $A$ (Basically a non-injective surjection between $A$ and itself) EDIT: To clarify, set $A$ is an example. I want to know a general algorithm for determining a function to do this with any set.",['elementary-set-theory']
1365018,Why is the polar triangle useful in spherical geometry?,We can solve many problems in spherical geometry by using the polar triangle. I am looking for an intuition why (and when) this is easier than working in the original triangle.,"['spherical-geometry', 'geometry']"
1365019,"How exactly does one define the ""spectral measure"" of an operator?","I am seeing kind of different definitions of ""spectral measure"" at different places and its not clear to me as to what is the universal idea. It would be great to get some ""standard"" definition. In my zone of studies now, I am seeing this occur frequently : that given a self-adjoint (possibly unbounded) operator $A$ on a separable Hilbert space and a $\phi \in \cal{H}_{-1}(A)$ then the ""spectral measure"" associated to possibly this pair $(A,\phi)$ is that unique $\mu$ such that for all $\lambda$ (may be one wants to restrict to $\lambda \in \mathbb{C} \backslash \mathbb{R}$ for some reason) the following holds, $<(A -\lambda I  )^{-1}\phi,\phi > = \int_{\mathbb{R}} \frac{ d\mu(x)}{x - \lambda }$ (0) Does this have some standard name which I can look up in some textbook? (1) I am not sure what is the innerproduct used in the LHS. (2) Can someone give an example of how this might actually be calculated? (3) Can one use $(A-\lambda I)^{-2}$ here to define something analogous?","['spectral-theory', 'operator-theory', 'real-analysis', 'functional-analysis']"
1365034,Solving the functional equation $2f(x)-f(1/x)=3x$,If $$2f(x)-f(1/x)=3x$$ how would I find $f(x)$? I have tried various linear and other functions but I do not know how to start this,"['analysis', 'functional-equations', 'functions']"
1365053,Local isometries preserve geodesics?,"Question: It is well known that if $\varphi:M\to \tilde{M}$ is an isometry between Riemannian manifolds, then $\varphi$ maps geodesics of $M$ to geodesics of $\tilde{M}$. I am wondering if it is sufficient that $\varphi$ is only a local isometry. To prove the case of global isometries, one first prove that if $\gamma$ is a smooth curve on $M$ and $V$ is a vector field along $\gamma$ (denoted $V\in\mathscr{T}(\gamma)$), then
$$\varphi_\ast D_tV=\tilde{D}_t(\varphi_\ast V),$$
where $D_t$ and $\tilde{D}_t$ are the covariant derivatives of $\gamma$ and $\varphi\circ\gamma$, respectively. Does this formula also holds for local isometries? I managed to reduce the problem to the following result (I think), but I am not sure how to prove it. Let $\gamma:I\to M$ be a curve, $U\subseteq M$ and open set, and $J\subseteq I$ a subinterval such that $\gamma(J)\subseteq U$. Let $\bar{\gamma}=\gamma|_J$. Then, $\bar{\gamma}$ is a curve in the open submanifold $U$, so it has a covariant derivative $\bar{D}_t$ in $U$. Now, I want to show that if $V$ is a vector field along $\gamma$, and $\bar{V}:J\to TU$ its restriction as a vector field along $\bar{\gamma}$ in $U$, then
$$\iota_\ast(\bar{D}_t\bar{V}(t))=D_tV(t),\quad\forall t\in J,$$
where $\iota:U\to M$ is inclusion. How do I prove this? If the above is true then we have the following proof. Let $\gamma:I\to M$ be a geodesic, and let $\tilde{\gamma}=\varphi\circ\gamma$. We want to show that $\tilde{D}_t\dot{\tilde{\gamma}}(t_0)=0$ for all $t_0\in I$. Fix $t_0\in I$ and let $U\subseteq M$ be a neighbourhood of $\gamma(t_0)$ such that $\varphi$ restricts to an isometry $\bar{\varphi}:U\to \tilde{U}$, where $\tilde{U}\subseteq\tilde{M}$ is open. Now, $\gamma^{-1}(U)$ is an open set containing $t_0$, so let $J\subseteq I$ be its connected component containing $t_0$. We then have a curve $\bar{\gamma}:J\to U$ in $U$. Now, note that
$$\bar{\dot{\tilde{\gamma}}}=\overline{\varphi_\ast\dot{\gamma}}=\bar{\varphi}_\ast\dot{\bar{\gamma}},$$
so by the above result
$$
\begin{align}
\tilde{D}_t\dot{\tilde{\gamma}}(t_0) &= \iota_\ast(\bar{\tilde{D}}_t(\bar{\varphi}_\ast\dot{\bar{\gamma}})(t_0)) \\
&= \iota_\ast\bar{\varphi}_\ast\bar{D}_t\dot{\bar{\gamma}}(t_0)\\
&=0
\end{align}
$$
since
$$
\iota_\ast\bar{D}_t\dot{\bar{\gamma}}(t_0)=D_t\dot{\gamma}(t_0)=0,
$$
and $\iota_\ast$ is injective.","['smooth-manifolds', 'differential-geometry', 'manifolds', 'riemannian-geometry']"
1365064,Maths Puzzle: Partitioning a set into two disjoint sets,"Le $X$ be the set of all non-empty subsets of $\{a,b,c,d,e,f\}$. So $X=\{a,b,c,d,e,f,ab,ac,ad,ae,af,bc,bd,be,bf,cd,ce,cf,de,df,ef,abc,\cdots,abcdef\}$; i.e., $|X|=63$. We want to partition $X$ into two disjoint sets $Y$ and $Z$ such that:
(i) $|Y|=13$;
(ii) Given any element $z \in Z$, $\exists ~ y_1,y_2 \in Y$ such that $y_1y_2=z$;
(iii) If $x_1,x_2 \in Y$, then $x_1x_2 \notin Y$. Note the following: (1.) $(X,\cdot)$ is commutative: Given $ x=ab,y=cd\in X$, then $x \cdot y=(ab)(cd)=abcd=adbc=dcba=\cdots=cdab=y \cdot x$; (2.) Two same letters cancels themselves: $(ab)(ac)=aabc=bc$. My target is to find $Y$. I have tried many things to no avail. For instance, $Y$ cannot consist of all words of lengths $1$, $5$ and $6$ since this cannot yield all the words of length $3$ or $4$. Any help in solving for $Y$ will be highly appreciated.","['combinatorial-game-theory', 'elementary-set-theory', 'puzzle', 'combinatorics']"
1365076,Laplace transform of the logarithmic integral function,"What is the Laplace transform of the logarithmic integral function $\text{li}(t)$. Meaning, how to compute the integral :
$$\int_{0}^{\infty}\text{li}(t)e^{-st}dt$$","['laplace-transform', 'complex-analysis', 'special-functions']"
1365079,The product of two positive definite matrices has real and positive eigenvalues? [duplicate],"This question already has answers here : Is the product of symmetric positive semidefinite matrices positive definite? (4 answers) Closed 3 years ago . Given two real positive definite (and therefore, symmetric) matrices $A$ and $B$, are all the eigenvalues of $AB$ real and positive? Wikipedia says $AB$ is positive definite if $A$ and $B$ are positive definite and commute, but I don't need $AB$ to be symmetric. Between the lines of this question the asking user somehow prove that yes, ""the eigenvalues of $AB$  are hence real and strictly positive"" but I couldn't understand if that is confirmed in the answer.","['eigenvalues-eigenvectors', 'positive-definite', 'linear-algebra', 'matrices']"
1365090,"Do ""point of accumulation"" and ""boundary point"" mean the same thing?","In my text it says, if a set $\Omega$ contains all points of accumulation $\{c\}$, then $\Omega$ is closed. I was surprised because people usually use ""boundary point"" in this context. And further defines points of accumulation as: $c$ is a point of accumulation for $\mathbb{K}$ if every neighborhood of $c$ contains at least one point of $\mathbb{K}$ distinct from $c$.",['general-topology']
1365096,Does anyone know the Burnside Matrices?,"For $G$ a fine group with conjugacy classes $C_1,\dots C_k$ we introduced the Burnside Matrices $A_r$ where $1<r<k$ with entries: $$A_r := \Big(\sqrt{\frac{|C_t|}{|C_s|}}a_{rst}\Big)_{1\leq s,t\leq k} $$ where $$a_{rst} = \frac{1}{|C_t|} |\{(x,y) \in C_r\times C_s\ |\ xy\in C_t\}|$$ Has anyone ever heard of them? I've been trying to find more Information on these matrices. I even checked then collected works of William Burnside. They have very interesting properties, mainly they are simulatiously diaganalizable by a unitary matrix $V$. Calling the column vectors $v_s$ and defining: $$ \chi_s (g) = \sqrt{|G| } \sum_{j=1}^k\frac{v_{sj}}{\sqrt{|C_j|}} \delta_{C_j}(g)\ 1\leq s\leq k $$ where g is an element of $G$ and the delta is $1$ for $g\in C_j$ and else zero. then the matrix: $$\big(\chi_s(C_t)\big)_{1\leq s,t\leq k}$$ is exactly the character table of all irreducible representations of $G$.","['representation-theory', 'matrices', 'characters', 'group-theory', 'finite-groups']"
1365104,Fibonacci $\equiv -1 \mod p^2$,"Is there a prime $p > 3$ such that the Fibonacci number $F_{np} \equiv -1 \mod p^2$ for some natural number $n$?  I know none of the first $1000$ primes $> 3$ qualify. EDIT: In response to Calvin Lin's comment: 
Suppose $n$ is the period mod $p$. Of course the period mod $p^2$ is a multiple of $n$. If $M = \pmatrix{1 & 1\cr 1 & 0\cr}$, so that $M^k = \pmatrix{F_{k+1} & F_k\cr F_k & F_{k-1}\cr}$, that says 
$M^n \equiv I \mod p$, so $M^n \equiv I + p A \mod p^2$ for some matrix $A$
with entries in $\mathbb Z_p$.  Then $M^{kn} \equiv I + k p A \mod p^2$.  If $A = 0$, the period mod $p^2$ is $n$, otherwise it is $pn$. Note that $n$ divides $p-1$ (if $p \equiv \pm 4 \mod 5$) or $2p+2$ (if $p \equiv \pm 3 \mod 5$), and in either case is coprime to $p$.  Thus if the period mod $p^2$ is not $pn$, $p$ must be
a Fibonacci-Wieferich prime (see Noam Elkies' answer).","['prime-numbers', 'number-theory', 'modular-arithmetic', 'fibonacci-numbers', 'elementary-number-theory']"
1365107,Continuity of multiplication of operators in the strong operator topology - find an error,"I need help in finding the mistake in the following reasoning. I proved that if dimension of Banach space $X$ is infinite, then multiplication of bounded operators is separately continuous but not continuous in strong operator topology. This fact can be found in many sources, e.g. Halmos or Simon & Reed so I know it is true. It is also claimed (e.g. in Halmos) that multiplication is sequentially continuous. Problem is that I think proof I came up with also works for nets, which would contradict statement above. I present it below. I need help with finding error. Suppose $A_i \to A$ and $B_i \to B$ strongly. Then both nets are bounded by uniform boundedness principle. In particular $\| A_i \| \leq M$. Furthermore we have: $AB-A_iB_i=(A-A_i)B+A_i(B-B_i)$ Therefore: $\|(AB-A_iB_i)x\| \leq\|(A-A_i)Bx\|+\|A_i\|\|(B-B_i)x\|$ Which converges to zero, so $A_i B_i \to AB$.","['operator-theory', 'banach-spaces', 'functional-analysis']"
1365126,Integrability of $(x+y) ^{-3}$.,"I'm asked to determine for what positive values of $\alpha$ is $(x+y)^{-3}$ integrable in the region where $0<x<1$ and $0<y<x^\alpha$. I've found that the function is integrable when $\alpha \geq 3$, but I'm not sure about the case when $0<\alpha<3.$",['analysis']
1365205,Prove continuity of averaging function for integrable $f$,"I want to prove the following statement which is part of a lemma in my textbook: Suppose $f$ is integrable on $\mathbb{R}^n$ and $x$ be a lebesgue point of $f$.
Let $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy$$ for $r>0$ Show $M(r)$ is a continuous function for $r>0$ My try: By changing of variable, $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy=\int_{|z|\le 1} |f(x+rz)-f(x)| \, dz$$ Hence fixing $r_1>0$, I get
$$
|M(r_2)-M(r_1)|\le \int_{|z|\le 1} |f(x+r_2z)-f(x+r_1z)| \, dz
$$ If $f$ is continuous, let $r_2$ closed enough to $r_1$, I get uniform continuous then the conclusion follows. For integrable $f$ , I think I need to use Lusin theorem to approximate $f$ be a continuous function and use absolute continuity of $f$, which follows from the inegrability of $f$. But I am not sure how to argue it.","['lebesgue-measure', 'measure-theory', 'continuity', 'real-analysis', 'lebesgue-integral']"
1365208,Definition of the Limit of a Function for the Extended Reals,"Definition 4.33 of Rudin's Principles of Real Analysis : Let $f$ be a real function defined on $E \subset R$. We say that $f(t) \rightarrow A$ as $t \rightarrow x$ where $A$ and $x$ are in the extended real number system, if for every neighborhood $U$ of $A$ there is a neighborhood $V$ of $x$ such that $V \cap E$ is not empty, and such that $f(t) \in U$ for all $t \in V \cap E$, $t \neq x$. Rudin then goes on to say this definition coincides with the epsilon-delta definition for when $A$ and $x$ are confined to $\mathbb{R}$. However for the epsilon-delta definition $x$ must be a limit point of $E$, whereas for Definition 4.33 this need not be the case. For example: Let $E \equiv \{1\}$ and $f(1) \equiv 5$. Then $f(t) \rightarrow 5$ as $t \rightarrow 2$ since, for any neighborhood $U$ of $5$, $V \equiv (0, 4)$ is a neighborhood of $2$ for which $V \cap E = \{1\} \neq \emptyset$ and $f(1) = 5 \in U$. Clearly $x = 2$ is not a limit point of $E = \{1\}$. It seems like this confusion could be avoided if, like in the epsilon-delta definition, Definition 4.33 required $x$ to be a limit point of $E$. My question is: Is there a reason $x$ is not required to be a limit point in definition 4.33? Edit: My feeling is that the definition is only useful if $x$ is a limit point of $E$ and so there is no point in stipulating it. Therefore when Rudin states the definitions coincide (for real values) he implicitly considers $x$ a limit point of $E$.","['limits', 'real-analysis']"
1365230,Regarding differentiability at $x =0$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f : \Bbb R \to \Bbb R$ be defined by
$f(x) =
\begin{cases}
x^2 \text{ if $x$ is rational}\\
x^4 \text{ if $x$ is irrational}
\end{cases}$ Is $f$ differentiable at $x = 0$? How do I begin ?","['real-analysis', 'derivatives']"
1365237,Understanding of non-degeneracy and inner product,"My class version of the non-degeneracy definition states: Let $V$ be a vector space over a field $\Bbb F$, equipped with a symmetric bilinear form $b : V \times V → \Bbb F$ . Then $b$ is a non-degenerate bilinear form if $~∀\,u∈V,\ b(v,u)=0 \implies v=0$. I find myself confused when I try to apply it to proving all inner products are non-degenerate, and here is my confusion: Given an inner product $b$. I let $u \in V$ and assume $b(v,u)=0$ and I am trying to show $v=0$. I saw on a few texts that we are allowed to pick $v$ so that $v=u$ and thus we get $v=0$ from positivity. Why are we allowed to choose the value for $v$? I thought $v$ could just be any arbitrary vector and it doesn't have to happen to be $u$. To make it clearer, it doesn't make sense to me that $b(v,u)=0\Rightarrow v=u$ whatsoever. In my mind $v$ is fixed and does not vary with $u$. Could someone kindly explain what is wrong with my reasoning?","['linear-algebra', 'inner-products']"
1365252,Probability: bakery distributes pies,"I'm working through a mathematical statistics textbook, and I can't get a question right. It is a follow-up to this question: At the end of the day, a bakery gives everything that is unsold to food banks for the needy. If it has 12 apple pies left at the end of a given day, in how many different ways can it distribute these pies among six food banks for the needy? I think maybe I got this one right (please tell me if it's wrong). Here's what I did: Every pie can ""choose"" where to go out of 6 bakeries, with no restrictions, so there are 12 steps each with 6 options, so the total is $6^{12}$. Then this is the question I can't answer : With reference to the previous exercise, in how many different ways can the bakery distribute the 12 apple pies if each of the six food banks is to receive at least one pie? I thought that I could fix 6 of the pies (so one goes to each bakery) and then distribute the other 6 freely, so the total should be $6^6$ (because there are 6 steps, each with 6 options), but this is wrong. The book has 462 as the answer and I can't figure out why. Help?","['probability', 'statistics']"
1365262,"Show that $\left(1 + \frac{x}{n}\right)^{-n} \le 2^{-x}$, when $x,n \ge 0$, $x \le n$","Show that $\left(1 + \frac{x}{n}\right)^{-n} \le 2^{-x}$, when $x,n \ge 0$, $x \le n$. This is driving me crazy... I have plotted the graphs to be sure that the inequality is true, and it is, but I can't seem to show it. Here is what I have so far: $$\left(1 + \frac{x}{n}\right)^{-n} \le \left(1 + \frac{x}{n}\right)^{-x}$$
since $n \ge x$. I want to then use the fact that $1 + \dfrac{x}{n} \le 2$, but that gives me a $\ge$, not a $\le$, so my first step must be wrong... I don't know what else to do, instead.","['algebra-precalculus', 'inequality']"
1365304,Compactum of Banach algebra,"I need an example of Banach algebra $A$ and a left non-trivial closed ideal $I$ with all of following properties: There exists a bounded approximate identity in $I$ for $I$ i.e., a net $\{e_\alpha\}\subset I$ such that $$ae_\alpha\to a,\quad e_\alpha a\to a,\quad a\in I.$$ For all of the $a\in A$ with $Ia=\{0\}$ or $aI=\{0\}$ we get to $a=0$. There exists an element $x\in A$ with $x\not\in I$ and $xA_1x=\overline{\{xax:a\in A, \|a\|\leq1\}}^{\|.\|}$ is compact.","['banach-algebras', 'operator-algebras', 'ideals', 'functional-analysis', 'harmonic-analysis']"
1365327,What function satisfies $F'(x) = F(2x)$?,"The exponential generating function counting the number of graphs on $n$ labeled vertices satisfies (and is defined by) the equations
$$
F'(x) = F(2x) \; \; ; \; \; F(0) = 1
$$
Is there some closed form or other nice description of this function?
Does it have a name? Of course, the series itself does not converge for any nonzero $x$, but like the Lambert W function (counting trees) it has combinatorial meaning. And the Lambert W function has a nice description as the inverse of $x e^x$; maybe there is a similar description of $F$?","['reference-request', 'generating-functions', 'combinatorics', 'delay-differential-equations']"
1365341,Showing pre-image under entire function is simply connected.,"I am currently working on the following problem and have run into a bit of trouble: Consider an entire function $f$ s.t. $\overline{B_1(0)}\subset f(\mathbb{C}).$
  Show that V, a component of $f^{-1}(B_1(0)),$ is simply connected. I figure the best way to achieve this result was by showing that any two curves with the same endpoints are homotopic. So I considered two parametrized closed curves $\gamma(t)$ and $\kappa(t)$ where $t\in[0,1]$ s.t. $$\gamma(0)=a=\kappa(0) \ \textrm{  and  } \ \gamma(1)=b=\kappa(1).$$ 
Now $f(\gamma(t))$ and $f(\kappa(t))$ are parameterizations of closed curves joining the points $f(a)$ and $f(b).$ Now we can deform these to one another via the family of functions $$d_s(t)=(1-s)f(\gamma(t))+sf(\kappa(t)), \textrm{ where} \ s\in[0,1].$$ The problem is from here I have no where to go, because I am not guaranteed anything about $f^{-1}(d_s(t))$ since I only have that $f$ is entire. In an effort to fix this I thought I could apply the inverse function theorem to get some local inverses, but I still don't believe I have enough information to obtain the result I want. After this didn't pan out, I thought maybe I could show that the integral over any closed curve in $V$ with respect to $f(z)$ was 0, but I haven't had any luck with that either. I know that there are several equivalencies to the statement ''V is simply connected,'' but I don't see how the others would work out in this case. I also saw on one website a comment that said this follows from the Maximum Modulus Principle, but I don't see how. Any helpful hints are appreciated. Thanks Note: I was also wondering if a component needs to be connected, because if not I don't see how the case of $f$ being constant would work. Progress Update: So I may have gotten a tad closer to the solution. I know that $f'$ can only have countably many isolated singularities (otherwise it would be 0 implying $f\equiv0$). So choose $z_0\in V\setminus Z[f']$ and use the inverse function theorem to guarantee that $f$ is invertible in a small neighborhood, and so this neighborhood would be simply connected. Since we have this for every point except those in $Z[f']$ I feel like it would give us the result.","['connectedness', 'complex-analysis']"
1365401,A limit of a sequence statistifying $S_{n} = \frac{1}{2}(a_{n}+\frac{1}{a_{n}})=a_1+a_2+...+a_n$,Sequence $\{a_n\}$ is a positive sequence and satisfies $S_{n} = \frac{1}{2}(a_{n}+\frac{1}{a_{n}})$ where $S_n = a_1+a_2+...+a_n$. Find $\lim_{n\to \infty} S_{n+1}*(S_{n}-S_{n-1})$,"['sequences-and-series', 'calculus', 'limits']"
1365411,"Sampling distribution of $Y = \frac{\ln U_1}{\ln U_1 + \ln (1 - U_2)}$, where $U_i \sim U(0,1), \forall i$","For this problem I have used the fact, $-2 \ln U \sim \chi^2_{(2)}$. But I have doubt on the independence of numerator and the denominator which are $\ln U_1$ and $\ln U_1 + \ln (1 - U_2)$. If they are independent, then resultant statistic boils down to $F_{2,4}$ statistic.
Please help.","['statistics', 'probability-distributions', 'sampling']"
1365416,Trigonometric Integrals $\int \frac{1}{1+\sin^2(x)}\mathrm{d}x$ and $\int \frac{1-\tan(x)}{1+\tan(x)} \mathrm{d}x$,"Any idea of calculating this two integrals $\int \frac{1}{1+\sin^2(x)}\,dx$ and $\int \frac{1-\tan(x)}{1+\tan(x)} \mathrm{d}x$? I found a solution online for the first one but it requires complex numbers which have not been taught by the professor.","['trigonometry', 'integration']"
1365419,How to show two varieties are NOT birationally equivalent?,"This is an exercise from Ideals, Varieties and Algorithms by Cox et al. Some backgroud It comes from a problem showing that $Q=V(x^2+y^2-z^2-1)$, a hyperboloid, and $W=V(x+1)$, a plane, are birationally equivalent by two rational maps that define a one-to-one correspondence between $Q-V_Q(x+1)=Q-V$ and $W-V_W(y^2-z^2+4)=W-H$. The two rational maps are 
$$\phi: Q-V \rightarrow W-H, \quad (x,y,z)\mapsto (-1, \frac{-2y}{x-1}, \frac{-2z}{x-1})\\
\psi: W-H \rightarrow Q-V, \quad (-1, a,b)\mapsto (\frac{a^2-b^2-4}{z^2-b^2+4},\frac{4a}{a^2-b^2+4},\frac{4b}{a^2-b^2+4})$$ Then it asks to show that although $Q$ and $W$ are birationally equivalent, the excluded part from the map $V$ and $H$, as varieties, are neither isomorphic nor birationally equivalent. My attempt It is equivalent to show that the two varieties $V=\{(x,y)\in \mathbb{R}^2| x=\pm y\}$ and $H=\{(a,b)\in \mathbb{R}^2 | a^2-b^2+4=0\}$ are not birationally equivalent. Suppose there exists rationally mappings $\phi: H\rightarrow V$ and $\psi: V\rightarrow H$ such that they are inverse of each other. My question: I then defined them and set up the equations by the definition of the varieties. It makes it more complicated and I don't know where to go. I also noticed one of them is two lines intersecting with each other, the other is two branches of a hyperbola. I wonder if that tells anything, because the author didn't mention how to identify equivalence using geometry. Any help would be appreciated!","['algebraic-geometry', 'birational-geometry']"
1365430,When the sum of independent Markov chains is a Markov chain?,"I try to find as much as possible cases, when the chain $Z(t) = |X_1(t)-X_2(t)|$ is Markov, where $X_1(t)$ and $X_2(t)$ are independent, discrete-time and space, preferably non-homogeneous Markov chains.
I started to search for the sum of independent Markov chains and I found this statement in Stoyanov J. - Counterexamples in Probability (2ed., Wiley, 1997)(p.229, one can google it and find in google books): ... the sum of two Markov processes need not be a Markov process. Note, however, that that the sum of two independent Markov processes preserves this property. That seems very strange to me and I wish to find the proof or at least the statement elsewhere. EDIT: The way of thinking how it may look like for a sum of two independent Markov chains (If I want to prove that the sum of two independent Markov chains is again a Markov chain): Let $Y(n) = X_1(n)+X_2(n)$. Then $P(Y(n+1) = i_{n+1} \ | \ Y(n) = i_n, ..., Y(0)=i_0) =$ $= P(X_1(n+1)+X_2(n+1)=i_{n+1}\ | \ X_1(n)+X_2(n)=i_n,...,X_1(0)+X_2(0)=i_0)=$ $=/ (?) / = \sum_{j+k=i_{n+1}}P(X_1(n+1)=j,X_2(n+1)=k \ | \ \cdot)=$ $=/\text{X's are independent}/ = \sum_{j+k=i_{n+1}}P(X_1(n+1)=j \ | \ \cdot)\cdot P(X_2(n+1)=k \ | \ \cdot) = $ $= /\text{Markov property + (??) } / =  \sum_{j+k=i_{n+1}}P(X_1(n+1)=j \ | \ X_1(n)+X_2(n)=i_n)\cdot P(X_2(n+1)=k \ | \ X_1(n)+X_2(n)=i_n)=$ $=P(X_1(n+1)+X_2(n+1)=i_{n+1} \ | \ X_1(n)+X_2(n)=i_n) = P(Y(n+1)=i_{n+1}\ | \ Y(n)=i_n)$. Here I am uncertain about (?) and (??) steps.","['probability-theory', 'probability', 'examples-counterexamples', 'markov-chains']"
1365441,Tangent to the curve,"What is the equation of the tangent to the curve $$y = x^{1/3}$$ at the point $(0,0)$ ? This is a homework question. I tried solving it. The derivative comes out to be infinite at the given point. So, the equation should be $x=0$. Am I doing it the right way?","['curves', 'calculus', 'derivatives']"
1365457,How do I prove that $R^n\setminus R^k$ is homeomorphic to $S^{n-k-1}\times R^{k+1}$?,"Let $k,n$ be positive integers such that $k<n$. How do I prove that $\mathbb{R}^n\setminus \mathbb{R}^k$ is homeomorphic to $S^{n-k-1}\times \mathbb{R}^{k+1}$? I tried to put specific integers in $k,n$ to visualize the problem. However, I even have a trouble with this. The case $k=2,n=3$ is clear. Consider the case $k=1,n=3$. Using deformation retractions, it's clear that $\pi_1(\mathbb{R}^3\setminus\mathbb{R})$ is isomorphic to $\pi_1(S^1)$. Hence, this approach does not help prove the statement.. How do I prove it?","['algebraic-topology', 'general-topology']"
1365460,Prove that $f$ is a polynomial,"If $f(z)$ is an entire function and $|f(z)|\ge1$ for all $z$ with $|z|\ge \pi$ then show that $f$ is a polynomial. I tried to apply Lioville's theorem on $f$. For $|z|\le \pi$ , $|f(z)|\le k$ for positive constant. But it does not help. I've also tried with Taylor's series expansion as , $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$where, $$a_n=\frac{1}{2\pi i}\int_{|z|=R}\frac{f(z)}{z^n}\, \mathrm{d}z$$ Then I wanted to find that $a_n=0$ for $n>p$ for some $p$ , but I failed to do so.",['complex-analysis']
1365523,"Find the relation between $a,b $ and $c$ in quadratic equation.","If the roots of the equation $a(b-c)x^2+b(c-a)x+c(a-b)=0,\ \ \{a,b,c,x\}\in \mathbb{R}$ are equal, then $a,b,c$ are in Options $a.)\ AP\\
b.)\ GP\\
\color{green}{c.)\ HP}\\
d.)\ \text{cannot be determined}\\$ by using discriminant property $[b(c-a)]^2-4ac(b-c)(a-b)=0$ I cannot reach any conclusion and is also cumbersome , though I don't know how wolfram reached this $[b(c-a)]^2-4ac(b-c)(a-b)=0\ \Longleftrightarrow \dfrac{2}{b}=\dfrac{1}{a}+\dfrac{1}{c}$ I look for a short and simple way . I have studied maths up to $12$th grade.","['quadratics', 'harmonic-numbers', 'algebra-precalculus']"
1365533,General closed form solution to $f'(x) = P(f(x))/P(x)$,"Does there exist a general closed form solution (in terms of elementary or special functions) to the differential equation: $$ \frac{df(x)}{dx} = \frac{P(f(x))}{P(x)} $$ when $P(x)$ is a polynomial of degree higher than 3? (excluding the trivial case $f(x)=x$). Context: I'm trying to find the action of a certain class of composition operators $$C_f(x,\frac{d}{dx}) = e^{P(x) \frac{d}{dx}} $$ where $P(x)$ is a polynomial in $\mathbb{C}$ of degree $n \geq 3$, such that for a complex function $g$ $$C_f(g) = g \circ f$$ After some manipulations, one arrives at the Abel equation $$ f(x) = \alpha^{-1}(\alpha(x) + 1) $$ where $$ \alpha(x) = \int^x \frac{dt}{P(t)} $$ Differentiating this last expression, one obtains a differential equation that all the family of iterations of $f$ (even fractional ones) must satisfy: $$ \frac{df(x)}{dx} = \frac{P(f(x))}{P(x)} $$ I already know the basic properties of this function, and I know how to calculate it numerically. What I'm trying to find is whether there exists a general closed form expression for $f$ when $\deg P \geq 3$ (in the case $n \leq 2$, $f(x)$ is a Möbius transformation). There are some special cases I've checked manually, such as the case $P(x) = ax^n$, whose solution is a combination of a rational function and radicals, but I don't know if this holds in general, or how to prove it.","['function-and-relation-composition', 'ordinary-differential-equations']"
1365546,Understanding Rudin's proof that a Riemann integrable function is measurable,"In the book ""Principles of Mathematical Analysis"" by Walter Rudin, he proves the following theorem (slightly reworded), Theorem. If $f$ is Riemann integrable on $[a,b],$ then $f$ is Lebesgue integrable on $[a,b]$ with respect to the Lebesgue measure $m$ and
  $$ \int_a^b f \ dx = \mathscr{R} \int_a^b f \ dx $$
  Where $\mathscr{R} \int$ denotes the Riemann integral, while $\int$ denotes the Lebesgue integral. Proof Suupose $f$ is bounded. Then there exists a sequence $\{P_k\}$ of partitions of $[a,b]$ such that $P_{k+1}$ is a refinement of $P_k$ for each $k$ and
  $$ \lim_{k\rightarrow\infty} L(P_k,f) = \mathscr{R}\underline{\int_a^b} f \ dx, \quad \lim_{k\rightarrow\infty} U(P_k,f) = \mathscr{R}\overline{\int_a^b} f \ dx. $$
  Where $L(P_k), U(P_k)$ are the upper and lower sums respectively. If $P_k=\{a=x_0<x_1<\dots<x_n=b\},$ these are defined as,
  $$ L(P_k,f) = \sum_{i=1}^n (x_i-x_{i-1})m_i, \quad U(P_k,f) = \sum_{i=1}^n (x_i-x_{i-1})M_i,$$
  where $M_i = \sup_{x\in[x_{i-1},x_i]} f(x)$ and $m_i = \inf_{x\in[x_{i-1},x_i]} f(x).$ We then define functions $U,L$ as $U_k(a)=L_k(a)=f(a)$ and for each $x \in(x_{i-1},x_i],$ $1\leq i \leq n,$ $U_k(x)=M_i$ and $L_k(x)=m_i.$ Then for all $x\in [a,b],$
  $$ L(P_k,f) = \int_a^b L_k \ dx, \quad U(P_k,f) = \int_a^b U_k \ dx, $$
  and $$L_1(x) \leq L_2(x) \leq \dots \leq f(x) \leq \dots \leq U_2(x) \leq U_1(x). $$
  There the sequence of functions $L_k, U_k$ converge point-wise on $[a,b],$ so let $L, U$ be the limit functions respectively. Then $L$ and $U$ are bounded measurable functions on $[a,b]$ and for any $x \in [a,b],$
  $$ L(x) \leq f(x) \leq U(x), $$
  and by the monotone convergence theorem,
  $$ \int_a^b L(x) \ dx = \mathscr{R} \underline{\int_a^b} f \ dx, \quad \int_a^b U(x) \ dx = \mathscr{R} \overline{\int_a^b} f \ dx. $$
  Since $f$ is Riemann integrable, the upper and lower Riemann integrals are equal. Since $L(x) \leq U(x),$ it follows that $L(x) = U(x)$ almost everywhere on [a,b]. Then $L(x) = f(x) = U(x)$ almost everywhere on $[a,b],$ so $f$ is measurable and the result follows. I've understood the proof up until the last sentence, but I don't understand how you can conclude that $f$ is measurable (the part I bolded). I know it is a standard result that working with the Lebesgue measure on $[a,b],$ if $f$ is measurable and $f(x)=g(x)$ almost everywhere on, then $g$ is also measurable (and that this result also holds more generally). However when trying to prove this, I needed to show that a subset of a measure zero set is measurable.  While I know this is true for the Lebesgue measure, I'm struggling to prove it using the definition of measurable sets provided by Rudin. To be brief, Rudin defines a set to be finitely $\mu$-measurable if there exists a sequence of elementary sets which converges to it, in the sense that the outer measure of the symmetric difference converges to $0.$ A set if *$\mu$-measurable if there exists a sequence of finitely $\mu$-measurable sets that converge to it. I'm also wondering if there's an easier way to prove this assertion, rather than referring to the more general result. Edit in response to hardmath's response: To prove that $f$ is measurable using the fact that $L$ is and $f=L$ almost everywhere, I initially thought to do the following, Let $E = \{ x \mid f(x) \neq L(x) \},$ then $E$ is measurable and $m(E) = 0,$ where $m$ is the Lebesgue measure. We wish to show that for every $c \in \Bbb R,$ the set $\{ x \mid f(x)>c\}$ is measurable (this is how Rudin defines measurable functions). So given an arbitrary $c,$ we have,
$$ f^{-1}((c,\infty]) = \left(f^{-1}((c,\infty]) \cap E \right) \ \cup \ \left(L^{-1}((c,\infty]) \cap E^C \right), $$
since $f$ and $L$ agree on $E.$ The second term is measurable, but I'm not sure how to one can conclude that the first is.","['real-analysis', 'measure-theory', 'integration']"
1365587,"Finding $F(x)$ from $F(kx),$ where $F(x)$ is the antiderivative of the function $f(x)$.","I have that $F(e^{x}x) = e^{x}x^{2} - e^{x}x + e^{x} - 1$, and I would like to find $F(x)$. Attempt Since $F(e^{x}x) = e^{x}x^{2} - e^{x}x + e^{x} - 1,$ $F(t) = \alpha_{1}t^{\beta_{1}} + \alpha_{2}t^{\beta_{2}} + \alpha_{3}t^{\beta_{3}} + \alpha_{4}t^{\beta_{4}}.$ Let $t = e^{x}x,$ which means that $F(t) = \alpha_{1}(e^{x}x)^{\beta_{1}} + \alpha_{2}(e^{x}x)^{\beta_{2}} + \alpha_{3}(e^{x}x)^{\beta_{3}} + \alpha_{4}(e^{x}x)^{\beta_{4}} = e^{x}x^{2} - e^{x}x + e^{x} - 1.$ Therefore, $\alpha_{2} = -1, \alpha_{4} = -1, \beta_{2} = 1,$ and $\beta_{4} = 0.$ $F(t) = \alpha_{1}t^{\beta_{1}} - t + \alpha_{3}t^{\beta_{3}} - 1 = e^{x}x^{2} - e^{x}x + e^{x} - 1.$","['calculus', 'functions', 'integration']"
1365612,How to find this kind of function?,"I am trying to find a function $f(x,y)$ with $f:\mathbb{R}^{2} \rightarrow [a, b]$ where $[a, b]$ is equal to $[-1, 1]$, $[0, 1]$, or some other small interval (open intervals are fine as well). The partial derivative $\displaystyle\frac{\partial}{\partial x} f(x,y)$ should be $x$ and the partial derivative $\displaystyle\frac{\partial}{\partial y} f(x,y)$ should be $y$. The function $f(x,y)=\frac{1}{2}x^2+\frac{1}{2}y^2$ would have the partial derivatives I want but $\lim_{x\rightarrow\infty} f(x,y) = \infty$ (and the same for $y$) so it does not have the bounds I want. Is it possible to find such function? If it helps it is possible to restrict $x>0$ and $y>0$.","['calculus', 'limits', 'partial-derivative', 'functions', 'multivariable-calculus']"
1365619,Find the value of $2xy$ .,"If  $13x+17y=643$ ,$\{x,y\}\in \mathbb{N}$, then what is the value of two times the product of 
  $x$ and $y$ ? Options $a.)\ 744\quad \quad \quad \quad \quad 
b.)\ 844\\
\color{green}{c.)\ 924}\quad \quad \quad \quad \quad 
d.)\ 884\\$ I tried, $13x+17y \pmod{13}\equiv 0\\
\implies 2y  \pmod{13}\equiv 3 \\
\implies y=8
\implies y=8, x=39$ $2xy=624$ I look for a short and simple way . I have studied maths up to $12$th grade.","['number-theory', 'linear-diophantine-equations', 'algebra-precalculus']"
1365635,Area form and surface area,"I know how one can define the surface area via the charts of a surface in $\mathbb{R}^3.$ click here for instance Now, I read that the canonical surface area form for such a surface with surface normal $n$ is given by $\omega( \xi,\eta ) = \det(n,\xi,\eta).$ My question is now: How can I see that both definitions coincide? So why does the integral over $\int_{A} \omega$ the surface area now? The thing is that I am completely new to differential forms and maybe it is more or less the definition, but my problem is that I don't know how it follows now. If anything is unclear, please let me know.","['area', 'real-analysis', 'manifolds', 'integration', 'differential-geometry']"
1365641,Why is pi/2 the angle associated with orthogonality in euclidean geometry?,"This is sort of a weird question, but I am trying to understand why 90 degrees or pi/2 radians is the angle that corresponds to orthogonality in 3-d (or really any dimension of) Euclidean space.  Said another way, what's so special about 1/4 of a complete rotation? Why is that the amount of rotation needed to end up in an orthogonal direction to where you started? I think this must have a connection to the symmetries of the space but I can't put my finger on how to express it.",['geometry']
1365652,Stanford math qual: Abelian groups $G$ satisfying $0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0$,"I am studying for my qualifying exams and came across the following question: Find all abelian groups $G$ that fit into an exact sequence $0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0$. From another question on this site, I know I can make a diagram  of the form $$\require{AMScd}
\begin{CD}
0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\
@. @VVV @VVV @VV V @. \\
0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}/3\mathbb{Z} @>>> 0.
\end{CD}
$$
Let us call the three vertical maps, from left to right respectively $f$, $g$ and $h$. By the Snake Lemma, I can extend the diagram above to one that looks like \begin{CD}
 @. 0 @>>>0  @>>>0 @. \\
@. @VVV @VVV @VV V @. \\
0 @>>> \ker f @>>> \ker g @>>> \ker h @>>> 0 \\
@. @VVV @VVV @VV V @. \\
0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\
@. @VVV @VVV @VV V @. \\
0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}3\mathbb{Z} @>>> 0\\
@. @VVV @VVV @VV V @. \\
 @. 0 @>>>0  @>>>0 @. \\
\end{CD} Question 1: Since $\ker f = \ker h = \Bbb{Z}$, and $\Bbb{Z}$ is projective I know that the top non-zero row splits, and so $\ker g \cong \Bbb{Z}^2$. Can I say that $\ker f \hookrightarrow \ker g$ is inclusion into the first factor, and $\ker g\to \ker h$ is projection onto the second? If this is true, then I can present $G$ as the cokernel of the relations matrix $$\left(\begin{array}{cc}  0 & a \\ 3 & b \\ 0 & 0 \\ 0 & 3  \end{array}\right)$$
for some integers $a,b\in\Bbb{Z}.$ This comes from analyzing the far top right and top left squares, and of course the assumption that question 1 is true. Question 2: How can I simplify this matrix to give me nice information on what $G$ should be? Edit 1: From the statement of the splitting lemma on pg. 147 of Hatcher , it looks as if I can basically arrange so that what I want in question 1 is true.","['exact-sequence', 'abstract-algebra', 'group-theory']"
1365657,What is $H_0^1$ space?,"I'm reading a book and it says that the $H_0^1(\Omega)$ space is defined as ""the completion of $C_0^\infty(\Omega)$ w.r.t the Sobolev norm $\| \cdot \|_1$, where $C_0^\infty(\Omega)$ is the space of infinitely differentiable functions which are nonzero only on a compact subset of $\Omega$"". Can I simply understand the $H_0^1(\Omega)$ space as the space of all functions $u$ in $H^1(\Omega)$ whose value on the boundary of $\Omega$ is $0$ ($u\big |_{\partial\Omega}=0$)?",['functional-analysis']
1365662,"Why do Topologies get ""finer""?","Why are topologies with many elements called ""fine"" and topologies with few elements called ""coarse""? It seems as though the finer a topology is, the more likely it is for a function defined from that topology to be continuous, and conversely with coarse ones - for example, every function from the discrete topology is continuous, and every function to the coarse topology is continuous. Is there some intuition that explains this choice of words?","['continuity', 'definition', 'general-topology']"
1365664,Stokes' theorem and symplectic geometry,"Let $V = \mathbb{R}^2,$ as a vector space then the Poincaré invariant is an integral $\int_{\gamma} \theta$ where $\theta = p dx $ is the symplectic 1-form and $\gamma$ a closed curve. Now, it is interesting that in the 2d-case, that by Stokes' theorem $\gamma$ natually defines an area $A$ with $\partial A = \gamma$ and $\int_{\gamma} \theta = \int_{A} d \theta = \int_{A} dp \wedge dx.$ So what this invariant actually defines is the phase space volume. The situation gets more difficult when we are dealing with higher-dimensional spaces Let $V = \mathbb{R}^{2n}$ with $n>1$, then we can still define $\int_{\gamma} \sum_{i} p_i dx_i.$ Now, I started wondering: Can we still identify this with some area or interpret what this quantity actually tells us? A natural thing to do would be to assume $\int_{\gamma} \sum_{i} p_i dx_i = \int_{A} \sum_{i} dp_i \wedge dx_i.$ This basically means that we are summing up the area of the projection down to each $x_i,p_i$ plane, but now I don't know whether $\gamma$ naturally defines such an $A$ so that we can apply Stokes' theorem? But even if you cannot make any sense out of my last equation, it would be interesting for me to know whether we can interpret what $\int_{\gamma} \sum_i p_i dx_i $ actually tells us? If anything is unclear, please let me know.","['differential-forms', 'real-analysis', 'integration', 'differential-geometry', 'symplectic-geometry']"
1365665,About 'Marcinkiewicz–Zygmund inequality',"Marcinkiewicz–Zygmund inequality gives gives relations between moments of a collection of independent random variables . The statement of this inequality can be seen in Wiki https://en.wikipedia.org/wiki/Marcinkiewicz%E2%80%93Zygmund_inequality However, another better form can be  seen among the top six lines on the left column in Page 5 of http://arxiv.org/pdf/1312.4626v1.pdf . However, the related citation Burkholder, D. L. Sharp inequalities for martingales
and stochastic integrals can not be easily accessed on Internet. Could anyone rigorously restate the details of this form of Marcinkiewicz–Zygmund inequality?","['probability-theory', 'calculus', 'random-variables', 'statistics', 'probability']"
1365678,Is an $L^p$ function in an annulus $L^p$ restricted to almost all planes?,"Let $n\geq3$ and consider the annulus-like domain $A=B(0,1)\setminus B(0,r)\subset\mathbb R^n$.
Take any number $p\in[1,\infty]$. If $f\in L^p(A)$, is it true that $f|_{P\cap A}\in L^p(P\cap A)$ for almost every two dimensional subspace $P$ of $\mathbb R^n$? Note that all the spaces $P$ go through the origin, so we are not slicing the domain with parallel planes.
If $A$ is replaced with the ball $B(0,1)$, the claim is false in general because the function can be concentrated near the origin.
For example, the function $f(x)=|x|^{-n+1/2}$ is in $L^1$ but it is not $L^1$ restricted to any proper subspace (intersected with the ball).
The Grassmannian of two dimensional subspaces of $\mathbb R^n$ is a compact, smooth manifold and we can equip it with any Riemannian metric; null sets don't depend on the choice of the metric. Here are some incomplete ideas of mine for proving this, but I feel there should be a more direct proof or at least some theorems that I could use to justify my arguments: It seems possible that this could be done sphere by sphere.
For a function $f\in L^p(A)$ we have $f|_{S_r}\in L^p(S_r)$, where $S_r=\partial B(0,r)$ is the sphere, for almost every $r$ (a proof can be found in this MSE question ).
It should be enough if we can answer the original question with $A$ replaced with the sphere $S_1$: If we have an $L^p$ function on the sphere, is its restriction to almost every great circle in $L^p$?
Let $T_1S_1$ be the unit tangent bundle of $S_1$, and denote the projection by $\pi:T_1S_1\to S_1$.
For $f\in L^p(S_1)$ we have $\pi^*f\in L^p(T_1S_1)$ (the bundle is locally a product so measurability of $f$ implies that of $\pi^*f$).
The space $T_1S_1$ is nicely foliated by great circles with unit speed parametrization, so a Fubini-type theorem should give the desired result. For a continuous function $f:\bar A\to\mathbb R$ we have
$$
\int_A |f|^p=\int_G\left(\int_P K|f|^p\right)dP,
$$
where $G$ denotes the Grassmannian of two-planes and $K:A\to(0,\infty)$ is the radial function $K(x)=c|x|^{n-1}$.
The constant $c\in(0,\infty)$ could be calculated explicitly, but it is irrelevant for the argument.
If one can argue that the same identity must hold for $f\in L^p$ as well, the desired conclusion follows.","['measure-theory', 'almost-everywhere', 'functional-analysis', 'lp-spaces', 'geometric-measure-theory']"
1365692,Computing $\lim_{\epsilon \rightarrow 0} \int_0^\infty \frac{\sin x}{x} \arctan{\frac{x}{\epsilon}}dx$,"I'm not exactly sure how to get started computing the limit of the improper Riemann integral $$\lim_{\epsilon \rightarrow 0} \int_0^\infty \frac{\sin x}{x} \arctan\left(\frac{x}{\epsilon}\right)dx.$$ Using the result that $\int_0^\infty \frac{\sin x}{x} dx = \pi/2$, is there a way to interchange the limit and the integral to get $\pi^2/4$?","['real-analysis', 'improper-integrals']"
1365698,How many ways to arrange the flags?,"There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$. This is a tricky problem to be honest. Let $|$ distinguish the two flagpoles. I tried arranging it as: $$G B GBGBGB | BGBGBGBGBGB$$ $$G G G GB | BGGGGGB$$ There are:  $\binom{12}{3} = 220$ to arrange the blue/green. Then multiply by $11$ because of the divider of the poles. $$= 220(11) = 2420$$ And this multiplication by $11$ takes care of the at least one flag on pole condition. Then why is this the wrong answer?","['contest-math', 'algebra-precalculus', 'elementary-number-theory', 'combinatorics', 'probability']"
1365712,Prove that there exist infinitely many integers $(n^{2015}+1)\mid n!$,"I conjecture that there exist infinitely many integers $n$ such
  that $$(n^{2015}+1)\mid n!.$$ I have seen a simpler problem that there exist infinitely many integers $n$ such that $(n^2+1)\mid n!$. Alternatively, I considered the Pell equation
$n^2+1=5m^2$, $2m<n$, but for $2015$ I can't figure it out.","['factorial', 'conjectures', 'number-theory', 'divisibility']"
1365713,birthday problem - which solution for expected value of collisions is correct?,"I am trying to understand the difference of the two solutions for the expected value of collisions for the birthday problem: https://math.stackexchange.com/a/35798/254705 derives the following solution: ... so the expected number of people who share birthdays with somebody is $n\left(1-(1-1/N)^{n-1}\right)$. whereas https://math.stackexchange.com/a/952272/254705 gives This leads to an expectation value $\lambda$ (date collisions in terms of the lambda distribution) of $\lambda = \frac{n(n-1)}{2m}$ For $2^{32}$ ""days"" and $10^6$ people, results in $E_1 = 232.8033$ and results in $E_2 =  116.4152$ It looks like that $\frac{E_1}{E_2} \approx 2$. As $E_2$ gives the number of collision pairs instead of number of people involved in collisions, this seems reasonable to me. Which of the solutions is correct? Is $E_2$ just an approximation?","['birthday', 'probability']"
1365715,Could Euclid have proven that real number multiplication is commutative?,"In Euclid's day, the modern notion of real number did not exist; Euclid did not believe that the length of a line segment was a quantity measurable by number.  But he did think it made sense to talk about the ratio of two lengths.  In fact, he devotes Book V of his Elements to the study of such ratios, using the so-called Eudoxian theory of proportions.  Here's how it works. Let $w$ and $x$ be two magnitudes of the same kind (for instance two length), and let $y$ and $z$ be two magnitudes of the same kind (for instance two areas). Then according to Euclid, the ratio of $w$ to $x$ is said to be equal to the ratio of $y$ to $z$ if for all positive integers $m$ and $n$, if $nw$ is greater, equal, or less than $mx$, then $ny$ is greater, equal, or less than $mz$, respectively.  Or to put it in more modern language, $w/x = y/z$ if the same rational numbers $m/n$ are less than both, the same rational numbers are equal to both, and the same rational numbers are greater than both. In other words, a ratio is defined by the classes of rational numbers which are less than, equal to, and greater than it.  If you've studied real analysis; this should look familiar to you: it is how the real number system is constructed using Dedekind cuts!  In fact, Dedekind took the Eudoxian theory of proportions in Euclid's book V as the inspiration for his Dedekind cut construction.  So to sum up, while Euclid wouldn't have thought of them as numbers, his notion of ""ratios"" corresponds to our notion of ""positive real numbers"". Now with that background, I would like to try to prove using Euclid's system that multiplication of real numbers is commutative.  First let me explain how the product of two ratios is defined.  (Euclid uses the product in a few propositions including this one .)  We say that the product of $w/x$ and $y/z$ is equal to $u/v$ if there exist magnitudes $r,s,$ and $t$ such that $w/x = r/s$, $y/z = s/t$, and $r/t = u/v$. So in order to prove the commutativity of multiplication, we would need to prove the following: Suppose that $b/c = e/f$ and $a/b = f/g$.  Then $a/c =e/g$. If we could prove that, then that would mean that the product of $b/c$ and $a/b$ is equal to the product of $a/b$ and $b/c$, which would immediately imply the commutativity of multiplication in general. So how would I go about proving that?  Euclid's Book V contains a lot of theorems about ratios that are potentially relevant, but I'm not sure how to proceed. EDIT:  I just posted a follow-up question on the distributive property.","['euclidean-geometry', 'real-numbers', 'math-history', 'real-analysis', 'geometry']"
1365746,Length of hypotenuse v/s change in height of the opposite,"I have always struggled to understand mathematical concepts, and have a very different way of thinking about problems.  I suspect this is a very simple problem, but its confusing me a great deal. I made a right triangle where the ""opposite"" side was $10$ and the ""adjacent side"" was $60$.  I then kept increasing the height of the opposite side by $10$ and measuring the length of the hypotenuse.  This rate of change in the hypotenuse length is not constant and reminds me of a sine wave because of its non-linear acceleration. However, the rate of change appears to become linear as the graph progresses. I just want to have an intuition for why the rate of change the length of the hypotenuse is not linear, and if there is one or several different ways I could visualize this to have a better intuition for whats going on. Graph & Triangle:",['trigonometry']
1365750,Integrating $\frac{\sec^2\theta}{1+\tan^2\theta \cos^2(2\alpha)}$ with respect to $\theta$,"I'm having some issues with the following integral $$\int_{\frac{-\pi}{2}}^\frac{\pi}{2}\frac{\sec^2\theta}{1+\tan^2\theta \cos^2(2\alpha)}d\theta$$ My attempt is as follows, substitute $u=\tan\theta$(but this gives infinite bounds) So $d\theta=\frac{1}{\sec^2\theta}du$, substituting both $\theta$ and $d\theta$ gives $$\int_{\tan(\frac{-\pi}{2})}^{\tan(\frac{\pi}{2})}\frac{1}{1+u^2 \cos^2(2\alpha)}du$$ This time substituting $v=u\cos(2\alpha)$, $du=\frac{1}{\cos(2\alpha)}dv$, which gives $$\int_{\tan(\frac{-\pi}{2})\cos(2\alpha)}^{\tan(\frac{\pi}{2})\cos(2\alpha)}\frac{1}{1+v^2}dv=\bigg{[} \arctan (v)\bigg{]}_{\tan(\frac{-\pi}{2})\cos(2\alpha)}^{\tan(\frac{\pi}{2})\cos(2\alpha)}$$ I don't think I've made any mistakes in my substitutions, but I'm still wondering how to get past the infinite bounds, since $\tan(\pi/2)=\infty$ and $\tan(-\pi/2)=-\infty$","['calculus', 'improper-integrals', 'definite-integrals', 'trigonometry', 'integration']"
1365758,Strong and weak laws of large numbers,"Let $X_1,X_2,\ldots$ be a sequence of random variables. Weak (strong) law of large numbers states that: If $X_1,X_2,\ldots$ are i.i.d. RVs and they have finite
  expectation $m$, then $\frac{X_1+\dots+X_n}{n}\rightarrow m$
  stochastically (almost surely). I wonder if those laws hold without assumption about independence/identical distribution or if we can exchange one assumption with some other one. Thanks for any input.","['probability-theory', 'probability', 'law-of-large-numbers']"
1365812,"Solve $2^{a+3}=4^{a+2}-48,\ a\in \mathbb{R}$","Solve $2^{a+3}=4^{a+2}-48,\ a\in \mathbb{R}$ I tried to simplify it , $2^{a+3}=4^{a+2}-48\\
2^{a+3}=2^{2(a+2)}-2^4\cdot 3\\
2^{2a}-2^{a-1}- 3=0\\
$ I don't know how to go from here. This question is from chapter quadratic equations, so i think there must be hidden quadratic idea in it. I look for a short and simple way. I have studied maths up to $12$th grade.","['quadratics', 'algebra-precalculus']"
1365819,A question about equivalence of norms involving infimum,"Let $I$ be a Banach space with norm $\lVert\cdot\rVert_I$. The norm
$$\inf\{\lVert(G_i(u_i))_i\rVert_{\ell^2}\mid u=\sum_{I \geq 0}u_i\}\qquad\text{is equivalent to}\qquad \lVert{u}\rVert_{I}$$
where the series converges in a separable Hilbert space $X_0$ where $I \subset X_0$ continuously. Here $G_i$ are some given function. I have seen in papers, that this implies: $$\lVert(G(v_i))_i\rVert_{\ell^2} \leq C\lVert u\rVert_I$$
where $v_i = (u,\phi_i)_{X_0}\phi_i$ wth $\phi_i$ the o.n. eigenbasis of $X_0$. Why is this true? The inequality is the wrong way for picking a particular function in the infimum, so there must be another way to see this. For example I saw this in http://arxiv.org/pdf/1404.6195v3.pdf , on section 3.1.3, near the bottom, where they use Theorem 8.2 in that paper.","['hilbert-spaces', 'banach-spaces', 'functional-analysis']"
1365822,Why are rational numbers required in cusps of congruence subgroups?,"While we consider the action of congruence subgroups on $\mathbb{H}$ (the upper half plane), we compactify using an additional point at infinity, that is fine. But why do we add even all rational numbers? I am talking about how cusps are defined. And in particular, if $f$ is modular form, what does $f(q)$ (where $q \in \mathbb{Q}$) mean?","['modular-forms', 'number-theory', 'complex-analysis', 'analytic-number-theory']"
1365829,Why are these following variance and expected value computations legitimate?,"I spent over an hour of my exam's given time to calculate the variances and expected values as given here: Let $p,q\in (0,1)$. The number of costumers entering a supermarket is a r.v. $X$ with geometric distribution with parameter $q$. Every costumer buys a product with probability $p$ or buys nothing, with $1-p$. Let $Y$ be the number of products purchased (or bought? Is there a difference?). What is $E[Y]$? $V[Y]$? The problematic part is that after a long computation, I arrived at $p\over q$. The formal answers simply argued: $E(Y)=E(Y|X)=\color{green}{E(pX)}=pE(X)={p\over q}$, where the green part is an argument never have I ever encountered. I couldn't compute the second one for it became too intricate(That is a really long multiple choice test.), but the formal answers used that again: 
$V(Y)=E(V(Y|X))+V(E(Y|X))=\color{green}{E(p(1-p)X)+V(pX)}$, and I wonder, why is $E(X|Y)=E(E(X)Y)$? I would appreciate your help. Okay I am under the impression that suggesting free points is unorthodox or illegitimate here. I will wait as long as it enables me, for an answer to be given, and share my points with the answer I happen to see as best in my view.","['probability', 'statistics']"
1365842,Significance of homothety mapping incircle to circumcircle,Are there any special properties of the homothety mapping the incircle of a triangle to the circumcircle? For example are the centers of this homothety triangle centers?,"['geometry', 'transformation']"
1365847,Are all measure zero sets measurable?,"Definition of Lebesgue Outer Measure : Given a set $E$ of $\mathbb R$, we define the Lebesgue Outer Measure of $E$ by, $$m^*(E) = \inf \left\{\sum_{n=1}^{+\infty} \ell(I_n): E \subset \bigcup_{n=1}^{+\infty}I_n \right\}$$ where $\ell(I_n)$ denotes the length of interval (bounded and nonempty interval). Definition of measurable set : A set $E$ measurable if $$m^*(T) = m^*(T \cap E) + m^*(T \cap E^c)$$ for every subset of $T$ of $\mathbb R$. If $E \subset \mathbb R$ with $m^*(E) = 0$ and $\exists$ finite interval $I,$ such that $E \subset I, $, then is $E$ measurable? If $E \subset \mathbb R$ with $m^*(E) = 0$, then is $E$ measurable?","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1365851,Could Euclid have proven that multiplication of real numbers distributes over addition?,"In Euclid's day, the modern notion of real number did not exist; Euclid did not believe that the length of a line segment was a quantity measurable by number.  But he did think it made sense to talk about the ratio of two lengths.  In fact, he devotes Book V of his Elements to the study of such ratios, using the so-called Eudoxian theory of proportions.  Here's how it works. Let $w$ and $x$ be two magnitudes of the same kind (for instance two length), and let $y$ and $z$ be two magnitudes of the same kind (for instance two areas). Then according to Euclid, the ratio of $w$ to $x$ is said to be equal to the ratio of $y$ to $z$ if for all positive integers $m$ and $n$, if $nw$ is greater, equal, or less than $mx$, then $ny$ is greater, equal, or less than $mz$, respectively.  Or to put it in modern language, $w/x = y/z$ if the same rational numbers $m/n$ are less than both, the same rational numbers are equal to both, and the same rational numbers are greater than both. In other words, a ratio is defined by the classes of rational numbers which are less than, equal to, and greater than it.  If you've studied real analysis; this should look familiar to you: it is how the real number system is constructed using Dedekind cuts!  In fact, Dedekind took the Eudoxian theory of proportions in Euclid's Book V as the inspiration for his Dedekind cut construction.  So to sum up, while Euclid wouldn't have thought of them as numbers, his notion of ""ratios"" basically corresponds to our notion of ""positive real numbers"". Now with that background, in this question I wanted to try to prove that real number multiplication is commutative, but it turned out that Euclid had beat me to the punch.  Now I'd like to prove that multiplication of real numbers distributes over addition.  First let me explain how the sum and product of two ratios is defined.  We say that the sum of $w/x$ and $y/z$ is equal to $u/v$ if there exist magnitudes $r,s,$ and $t$ such that $w/x = r/t$, $y/z = s/t$, and $(r+s)/t = u/v$. And we say that the product of $w/x$ and $y/z$ is equal to $u/v$ if there exist magnitudes $r,s,$ and $t$ such that $w/x = r/s$, $y/z = s/t$, and $r/t = u/v$. So in order to establish that multiplication distributes over addition, we need to prove the following: Suppose that the product of $a/b$ and $c/e$ is $f/h$, and the product of $a/b$ and $d/e$ is $g/h$.  Then the product of $a/b$ and $(c+d)/e$ is $(f+g)/h$ So how would I go about proving that?  Euclid's Book V contains a lot of theorems about ratios that are potentially relevant, but I'm not sure how to proceed. Note that there are other kinds of distributive properties proved in Euclid's Elements, including this one , this one , and this one , but they're not relevant here.","['euclidean-geometry', 'real-numbers', 'math-history', 'real-analysis', 'geometry']"
1365892,Transformation behavior of connection on vector bundle.,"Using the notation from Jost's various books on geometry, let
$$
D=d+A
$$
be a connection on a vector bundle $\pi:E\rightarrow M$ with structure group $GL(n,\mathbb{R})$.  Also let $\{U_\alpha\}$ be an open covering for $M$ that yields local trivialisations with transition maps
$$
\varphi_{\alpha\beta}:U_\alpha\cap U_\beta\rightarrow GL(n,\mathbb{R}).
$$
Then $D$ defines a $T^*M$-valued matrix $A_\alpha$ on $U_\alpha$.  Let a section $s$ be given locally on $U_\alpha$ by $s_\alpha=s^i_\alpha\mu_i$, where $\{\mu_1,...,\mu_n\}$ is a frame for $E_{|_U}=\pi^{-1}(U)$. Question I :  Why does it hold that
$$
s_\beta=\varphi_{\beta\alpha}s_\alpha\qquad\text{on $U_\alpha\cap U_\beta$}?
$$ Question II :  Why does it follow that
$$
\varphi_{\beta\alpha}(d+A_\alpha)s_\alpha=(d+A_\beta)s_\beta\qquad\text{on $U_\alpha\cap U_\beta$}?
$$
(He does give an ""indication"" of how this holds, but I don't see what he means.) Question III :  How do we then conclude that
$$
A_\alpha=\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}+\varphi_{\beta\alpha}^{-1}A_\beta\varphi_{\beta\alpha}?
$$ Remark :  Jost states this in each of his books on geometry, but I have never been able to find an elaboration.  I would also be grateful for some other references that explain in more detail what is going on here.","['principal-bundles', 'smooth-manifolds', 'vector-bundles', 'connections', 'differential-geometry']"
1365893,Help evaluating residue with simple poles,"I am having a bit of trouble evaluating $$\sum_{k=1}^3{
\rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)$$ where $z_1=2e^{i\pi}$, $z_2=2e^{i\pi/3}$ and $z_3=2e^{i5\pi/3}$. I know that each $z_k$ is a simple pole and, therefore, the residue should be equal to $$\sum_{k=1}^3\frac{\log(z_k)}{3z_k^{2}}$$ However, I can't seem to get the desired answer of $-\frac{\sqrt{3}\pi}{18}$. Help would be greatly appreciated! Note: The back of my textbook says $${\rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)=\frac{-z_k\log(z_k)}{24}$$ Still, I don't see where this comes from.","['complex-analysis', 'residue-calculus']"
1365928,"A nicer closed form? $\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx$","Mathematica doesn't return a nice result for the integral below, maybe because such one doesn't exist, or it exists but it depends much on a certain way of tackling things. What do you think?
$$\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx$$ $$=\frac{2 i \log ^3(2)}{3 \sqrt{7}}+\frac{i \log \left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}+\frac{2 i \log \left(3-i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}-\frac{2 i \log \left(3+i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{\pi  \log ^2(2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(i-\sqrt{7}\right) \log (2)}{3 \sqrt{7}}+\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(i-\sqrt{7}\right) \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log (2)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log (2)}{\sqrt{7}}-\frac{i \log (16) \log \left(i+\sqrt{3}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{\pi  \log (64) \log (2)}{3 \sqrt{7}}-\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{3 \sqrt{7}}-\frac{2 \pi  \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{3 \sqrt{7}}+\frac{503 \pi ^3}{648 \sqrt{7}}+\frac{i \log ^3\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{i \log (4) \log ^2\left(-i-\sqrt{3}\right)}{\sqrt{7}}+\frac{i \log (64) \log ^2\left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log (8) \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{\pi  \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{2 i \pi ^2 \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log (4) \log (64) \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{2 \sqrt{7}}+\frac{5 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{13 i \pi ^2 \log \left(i-\sqrt{7}\right)}{18 \sqrt{7}}+\frac{2 \pi  \log (32) \log \left(i-\sqrt{7}\right)}{3 \sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{\sqrt{7}}+\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log (64) \log \left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{3 \sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7-i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(\frac{1}{448} \left(7-i \sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i-\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i+\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log \left(-(-1)^{2/3} \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(-i-\sqrt{3}\right) \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^3\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \log ^3\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(i+\sqrt{3}\right)}{3 \sqrt{7}}-\frac{5 \pi  \log \left(i-\sqrt{7}\right) \log \left(\left(-1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{\pi  \log \left(i-\sqrt{7}\right) \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{5 \pi  \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{6 \sqrt{7}}-\frac{4 i \pi ^2 \log \left(\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)\right)}{9 \sqrt{7}}-\frac{i \pi ^2 \log (45671926166590716193865151022383844364247891968)}{36 \sqrt{7}} ...\text{and so on (that means many other terms)}$$","['calculus', 'real-analysis', 'definite-integrals', 'integration']"
1365929,Integrating using half angle formula,"I am reading through my textbook and there is a part of the solution to an example that I do not understand... $$\int\sin^4x\cos^2x\,dx = \int(\sin^2x)^2\cos^2x\,dx$$
$$=\int\left(\frac{1-\cos2x}{2}\right)^2\left(\frac{1+\cos2x}{2}\right)\,dx$$
$$=\frac18\int[1-\cos2x-\cos^22x+\cos^32x]\,dx$$
$$=\frac18\int\left[1-\cos2x-\left(\frac{1+\cos4x}{2}\right)+(1-\sin^22x)\cos2x\right]\,dx$$
$$=\frac18\int\left[\frac12-\cos2x-\frac12\cos4x+(1-\sin^22x)\cos2x\right]\,dx$$
$$=\frac18\int\left[\frac12-\frac12\cos4x-\sin^22x\cos2x\right]\,dx$$ I really don't understand what they did after the 5th equation, for example how the $1$ became $\frac12$. If anyone can explain the algebra to me from the 5th part that would be great... thanks.. EDIT: I don't care about the final answer.. just wondering how they transitioned to the next few steps","['trigonometry', 'calculus', 'integration']"
1365939,why isn't the counting principle giving the right answer?,"Note : This is not homework, it is self-study. An employer interviews eight people for four openings in the company. Three of the eight people are women. If all eight are qualified, in how many ways could the employer fill the four positions if 
  a)the selection is random
  and
  b)exactly two are women? Part a) is already taken care of, now for part b). My reasoning goes like this: There must be $2$ women chosen, so imagine that for the first position we choose a woman. There's $3$ ways to choose. For the second position we choose another woman, there's $2$ ways to choose. For the third position we choose a man, there's $5$ ways to choose. For the fourth position we choose another man, there's $4$ ways to choose. Then we multiply: $3\cdot2\cdot5\cdot4=120$. 
But the answer in the book is $30$.","['algebra-precalculus', 'combinatorics']"
1365949,Proving that an orthonormal system close to a basis is also a basis,"Let $\mathcal{H}$ be a Hilbert space and $(e_n)_{n \in \mathbb{N}} \subseteq\mathcal{H}$ be an orthonormal basis and $f_n$ be an orthonormal system such that 
$(f_n)_{n \in \mathbb{N}} \subseteq\mathcal{H}$ and $$\sum_{n \in \mathbb{N}}\|e_n-f_n\|^2 <1.$$ Prove that $f_n$ is also a basis. I am kind of stuck and can't figure out how to prove that $(f_n)_{n \in \mathbb{N}}$ is a basis.
I tried to prove by contradiction that if $(f_n)_{n \in \mathbb{N}}$ is not  a basis then $\exists   x \neq0 \in \mathcal{H}$ such that $\langle x,f_n \rangle=0 \forall n \in \mathbb{N}$. I also know that $\|e_n-f_n\|^2 \to 0 \implies Re(\langle e_n,f_n \rangle) \to 1$ I then tried to write $x=\sum_{n=1}^{\infty} \langle x,e_n \rangle e_n$ from which I get that $\sum_{k=1}^{\infty} \overline{ \langle x,e_k \rangle} \langle e_k,f_n \rangle \forall n \in \mathbb{N}$ But I do not know how to proceed. Any hints would be highly appreciated","['orthonormal', 'hilbert-spaces', 'functional-analysis']"
1365959,"Lie bracket is part of the intrinsic ""geometry""? But I have seen it defined without a metric...?","I have seen two definitions of the Lie Bracket for a Riemannian manifold $(M,g)$. One is this : $[X,Y] = D_X Y - D_Y X$, where $D$ stands for covariant differentiation. When written out, this seems to involve the Christoffel symbols. (This is in Thorpe's Elementary Topics in Differential Geometry.) The other is this: $[X,Y] = XY - YX$ with $(XY - YX)(f) = (X(Y(f)) - Y(X(f))$. (And the thing about differentiation of Y along the flow of X.) (For instance, in Warner's Differential Manifolds.) So my confusion is this: one expression seems to involve the metric, the other does not. How can I reconcile this?","['differential-geometry', 'riemannian-geometry']"
1365964,Epsilon-delta proof of $\lim_{x\to\infty}\left(\sqrt{(x+a)(x+b)}-x\right)=\frac{a+b}{2}$,"I have been doing $\varepsilon$-$\delta$ proofs for fun and I challenged myself to prove $$\displaystyle\lim_{x\to\infty}\left(\sqrt{(x+a)(x+b)}-x\right)=\frac{a+b}{2},\quad a,b\in\mathbb{R}$$ The definition says: We say that $\displaystyle\lim_{x\to\infty}f(x)=l$ if for any positive number $\varepsilon$ we can find a positive number $N$ (depending on $\varepsilon$ in general) such that $|f(x)-l|<\varepsilon$ whenever $x>N$. So I started with: $\left|\sqrt{(x+a)(x+b)}-x-\dfrac{a+b}{2}\right|<\varepsilon$ whenever $x>N$. Manipulating the first inequatlity \begin{gather*}
-\varepsilon<\sqrt{(x+a)(x+b)}-x-\dfrac{a+b}{2}<\varepsilon\\
-\varepsilon+\dfrac{a+b}{2}<\sqrt{(x+a)(x+b)}-x<\varepsilon+\frac{a+b}{2}
\end{gather*} At this point I thought about adding $x$, squaring the expressions and then expanding them. I did it and I got: $$\frac{a^2}{4}+\frac{ab}{2}+\frac{b^2}{4}+ax+bx+x^2-a\varepsilon-b\varepsilon-2x\varepsilon+\varepsilon^2<x^2+ax+bx+ab<\frac{a^2}{4}+\frac{ab}{2}+\frac{b^2}{4}+ax+bx+x^2+a\varepsilon+b\varepsilon+2x\varepsilon+\varepsilon^2$$ And here I'm not sure how to proceed. Am I on the right track? Thanks for any help / hints. Note : There might be other ways to prove this, but I'd like to do it using just algebra if possible, even if it's not the best method.","['limits', 'epsilon-delta']"
1365969,"An evenly divided $k$ coloring of an $(n,d,\lambda)$ graph leaves one vertex adjacent to all $k$ colors, given $k\lambda \leq d$.","(This is problem 9.2 from Alon and Spencer's The Probabilistic Method ) Let $G = (V,E)$ be an $(n,d,\lambda)$-graph, suppose $n$ is divisible by $k$, and let $C:V \to \{1,2,\ldots,k\}$ be a coloring of $V$ by $k$ colors, so that each color appears precisely $n/k$ times.  Prove that there is a vertex of $G$ which has a neighbor of each of the $k$ colors, provided $k\lambda \leq d$. The Notation :
Just to interpret some notation: an $(n,d,\lambda)$-graph means that $G$ has $n$ vertices with degree $d$---i.e. every vertex has exactly $d$ neighbors.  The $\lambda$ part means that the adjacency matrix for $G$ has second-largest eigenvalue equal to $\lambda$; since $G$ is a regular graph, the vector $(1,1,\ldots,1)^T$ is an eigenvector corresponding to $d$, the largest eigenvalue.  Thus, the second-largest eigenvalue characterizes the graph more than the largest does (once we know the degree). Discussion : 
Let $A$ be the adjacency matrix for $G$; if we order the vertices so that the colors are blocked together, then we can write $A$ as $$ A = \left( \begin{array}{c|c|c|c} 
A_{11} & A_{12} & \cdots & A_{1k}  \\ \hline
A_{21} & A_{22} & \cdots & A_{2k} \\ \hline 
\vdots & \vdots & \ddots & \vdots \\ \hline 
A_{k1} & A_{k2} & \cdots & A_{kk}
\end{array}\right) $$ 
i.e. to break it up into submatrices of size $n/k \times n/k$, where the first $n/k$ rows correspond to vertices of the first color, and so on.  The problem asks to prove that once column (or row) has at least one $1$ in every block.  The typical approach to these kind of problems is to let $v = (1,1\ldots, 1)^T$; now, cleverly choose some vector $x$ s.t. $\langle v,x \rangle = 0$.  Then we have $\langle Ax, Ax \rangle \leq \lambda^2 \langle x, x\rangle$; if $x$ is chosen well, then this inequality gives the desired result.  I haven't been able to choose such an $x$ well. I haven't made any progress on this problem, despite spending quite a bit of time on it.  Any help, or hints, would be greatly appreciated.  Since this can be thought of strictly as a linear algebra problem, I have also tagged it as such.","['probabilistic-method', 'graph-theory', 'linear-algebra', 'combinatorics']"
1365973,convergence of step functions in $L^1$ norm,"Let $f \in L^1 (m)$. For $k=1,2,3,...$, let $f_k$ be the step function defined by
   $$
f_k (x) = k\int_{j/k}^{\frac{j+1}{k}} f(t)dt \  \text{  for  $\frac{j}{k}<x<\frac{j+1}{k}$, $j=0,\pm1,\cdots$.}
$$
  Show that $f_k$ converges to $f$ in $L_1$ norm. This one seems more direct but when I do the $\|f_n - f\|_1$, I have trouble switching the two integrals.",['measure-theory']
1365982,Subgroups of $S_n$ with exactly one fixed point for each element all have the same fixed point.,"Let $G$ be a subgroup of $S_n$ (where $n$ is a positive integer) such that each non identity element $g\in G$ has exactly one fixed point. Prove there is an element of $[n]$ that is fixed by every permutation of $G$. What I am trying to do is prove it by contrapositive, showing that if for every $k\in [n]$ there is a permutation that moves $k$ then there is a permutation with no fixed points, but it is not clear to me how I can do this.","['contest-math', 'group-theory', 'combinatorics', 'group-actions', 'symmetric-groups']"
1366003,Derivative Of $\ln(x)$,"It is required to find the derivative of the natural logarithm of $x$: $\frac {d}{dx}\ln(x)$ My solution: Let $f(x)=\ln(x) $ then $f'(x)=\frac {d}{dx}\ln(x)    $ By definition:$$f'(x)= \lim_{h\to 0}\frac{f(x+h)- f(x)}{h} $$
By substitution:$$f'(x) = \lim_{h\to 0}\frac{\ln(x+h)- \ln(x)}{h} $$
Since $\ln(a)-\ln(b)=\ln(\frac ab)$, then:
$$f'(x) = \lim_{h\to 0}\frac{\ln(\frac{x+h}x)}{h}$$
Since $a\times \ln(b) = \ln(a^b)$, then:
$$f'(x) = \lim_{h\to 0}\ln((\frac{x+h}x)^\frac 1h)$$
Then:$$f'(x) = \lim_{h\to 0}\ln((1+\frac hx)^\frac 1h)$$
How to continue? Are there any other ways to find the derivative? Thanks in advance! Note: It is not allowed to use the fact that: $(e^x)'=e^x$ $$ e=\lim\limits_{n\to\infty} \left(1+\frac1n\right)^n$$","['logarithms', 'derivatives']"
1366005,Arranging the letters of INCONVENIENCE so that no C is adjacent to an N,"As the title indicates, I would like to find the number of ways to arrange the letters of INCONVENIENCE so that no C is adjacent to an N. This is a problem I just made up, and I am interested in finding the easiest way to solve problems like this. (I think the answer is 2,187,360; but I'm not sure.)","['discrete-mathematics', 'combinatorics']"
1366021,Every normal subgroup is the kernel of some homomorphism,"Clearly the kernel of a group homomorphism is normal ( proof ), but I often hear my professor mention that any normal subgroup is the kernel of some homomorphism. This feels correct but isn't entirely obvious to me. One thought I had is that for any normal subgroup $N$ of $G$ , we could define the quotient homomorphism $\pi:G\to G/N$ since $G/N$ is a group. I was imagining that we could consider $\pi^{-1}:G/N\to G$ , whose kernel would then be $N$ . However, $\pi^{-1}$ doesn't exist since $\pi$ is not a bijection in general. So my question is this: is there an obvious way to define a homomorphism whose kernel is an arbitrary normal subgroup of $G$ ? Or does it depend on the particular group whether you can define such a homomorphism?","['abstract-algebra', 'group-homomorphism', 'group-theory', 'normal-subgroups']"
1366023,"If $f$ has an essential singularity at $0$, there is a sequence $z_n \to 0$ such that $z_n^n f(z_n) \to \infty$","Here's a problem I was just working on: Let $f$ have an essential singularity at $0$.  Show that there is a sequence of points $z_n \to 0$ such that $z_n^n f(z_n)$ tends to infinity. I know already that there exists a sequence $z_n \to 0$ such that $f(z_n)$ tends to any complex number I want, hence I can get a sequence that tends to infinity.  The problem is that I need this sequence to tend to infinity really fast. What I did so far was look at the function $g_n(z) := z^n f(z)$, $n \geq 1$.  This obviously also has an essential singularity at $0$, so I can find a sequence $z_{n1}, z_{n2}, ...$ such that $\lim\limits_k g_n(z_{nk}) = \infty$.  Do you think it's possible to extract from the array $z_{nk}, (n,k) \in \mathbb{N}^2$ a subsequence $z_l$ such that $g_l(w_l) \to \infty$ as $l \to \infty$?  I tried for awhile but I'm just not very good at these kinds of arguments.",['complex-analysis']
1366029,Is $A=\{x \in \ell^2 \mid \sum_{n=1}^{\infty} \frac{x_n}{n}=0 \}$ dense in $\ell^2$,"I think that the answer is no I thought quite a bit about this problem. My idea was to build a sequence $(y_n)_{n \in \mathbb{N}} \subset A$ such that given  a $x \in \ell^2$ we pick the first N components of $y \in A$ as $(y_1,y_2, \dots, y_N)=(x_1, \dots, x_N)$ and try to make $\|x-y\|  < \varepsilon$.
$$ \|x-y\|^2=\sum_{n=1}^\infty |x_n-y_n|^2=\sum_{n=N+1}^\infty |x_n-y_n|^2 \leq 2\sum_{n=N+1}^\infty x_n^2+y_n^2$$ Now as $y \in A$ it also has to satisfy the condition $\sum_{n=1}^\infty \frac{y_n}{n}=0$ But from Cauchy-Schwarz inequality (as both $y \in \ell^2$ and $\frac{1}{n} \in \ell^2$ we have that $\sum_{n=1}^\infty \frac{y_n}{n} \leq (\sum_{n=1}^\infty y_n^2)^{\frac{1}{2}} (\sum_{n=1}^\infty \frac{1}{n^2})^{\frac{1}{2}}$ and therefore if $\sum_{n=1}^{N}\frac{y_n} {n}=-a$ $\implies$ $\sum_{n=N+1}^\infty \frac{y_n} {n}=a$ And it therefore follows that $a \leq (\sum_{n=N+1}^\infty y_n^2)^{\frac{1}{2}} \pi/{\sqrt{6}}$ Now as $y \in \ell^2 \implies \lim_{n\ \to \infty} y_n =0$ and if $a$ is large enough we cannot approximate $x$ by $y$ because I need both $\sum_{n=N+1}^{\infty} x_n^2 <\epsilon/4$ and $\sum_{n=N+1}^{\infty} y_n^2 <\epsilon/4$. In the case of $(x_n)_n$ we can always choose an $N$ large enough but because of the aforementioned argument , we cannot ensure that such a $y \in A$ exists. Is the idea of the proof correct? What is bothering me is that there could be another way of constructing the sequence $(y_n)_n$ which could work.
Thanks","['lp-spaces', 'functional-analysis']"
1366038,"Let $f_1,f_2,\ldots, f_n$ be linear functionals on $X$. Show $f=\sum_{i=1}^n\lambda_i f_i$ iff $\bigcap \ker f_i \subset \ker f$","Problem Let $f_1,f_2,\ldots, f_n$ be linear functionals on a vector space $X$. Show that there exist constants $\lambda_1,\ldots,\lambda_n$ satisfying $$f=\sum_{i=1}^n\lambda_i f_i$$ if and only if  $\bigcap_{i=1}^n \ker f_i \subset \ker f$. Attempt If there exist constants $\lambda_1,\ldots,\lambda_n$ satisfying $$f=\sum_{i=1}^n\lambda_i f_i,$$
then $x\in \bigcap_{i=1}^n \ker f_i$ gives $\sum_{i=1}^n\lambda_i f_i=0$. On the other hand, define $$V=\{y\in\mathbb{R}^n:\exists x\in X \textrm{ such that } y=\left(f_1(x),\ldots,f_n(x)\right)\},$$ and 
$g:V \rightarrow \mathbb{R}$ by $$g\left(\left(f_1(x),\ldots,f_n(x)\right)\right)=f(x).$$ $V$ is seen to be a vector subspace of $\mathbb{R}^n$.
If $\left(f_1(x),\ldots,f_n(x)\right)=\left(f_1(y),\ldots,f_n(y)\right)$ Then  $f_i(x-y)=0$ so $(x-y) \in \ker f_i$ for all $i$. By assumption, $(x-y)\in \ker f$ so $f(x)=f(y)$. Hence $g$ is well defined. Clearly $g$ is linear. Denote by $g^*$ a linear extention of $g$ to all of $\mathbb{R}^n$. Then there exist $\lambda_1,\ldots,\lambda_n$ such that $g^*(z_1,\ldots,z_n)=\sum_{i=1}^n\lambda_i z_i$. $\ ^{(1)}$ In particular, $(z_1,\ldots,z_n)=(f_1(x),\ldots,f_n(x))$ give the desired result. Question I am having trouble justifying $(1)$. That is, why can we say $g^*(z_1,\ldots z_n)=\sum_{i=1}^n \lambda_i z_i$?",['functional-analysis']
1366039,Help with the integral $\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx$,"Referring to a previous question , i want help with the integral : $$\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx$$ Where $n,m$ are positive integers, and $t$ is a real variable. I have tried repeated integration by parts, but it becomes very confusing after a couple of steps. Hints: $$\int\frac{\log(1+ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}dx=\frac{4\pi in}{t}\left(e^{-2\pi n/t}\text{Ei}\left(\log(1+ix)+\frac{2\pi n}{t}\right)-e^{2\pi n/t}\text{Ei}\left(\log(1+ix)-\frac{2\pi n}{t}\right) \right )+\frac{4x-4i}{t^{2}}$$ $$\int \text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)dx=(x-i)\text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)+ie^{\mp 2\pi n/t}\text{Ei}\left(2\log(1+ix)\pm\frac{4\pi n}{t}\right)$$ EDIT We notice that: $$\frac{\log(1+ ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}=\frac{4\log(1+ix)}{t^{2}}\int_{0}^{\infty}\sinh\left(\frac{2\pi ny}{t} \right )(1+ix)^{-y}dy$$ So we need to evaluate : $$f(y,m)=\int_{0}^{\infty}\log(1+ix)(1+ix)^{-y}e^{-2\pi m x}dx$$ And : $$\frac{4}{t^{2}}\int_{0}^{\infty}f(y,m)\sinh\left(\frac{2\pi ny}{t} \right )dy$$ But : $$f(y,m)=-\frac{d}{dy}\left[\int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi m x}dx\right]$$ And the problem reduces to this last integral ! EDIT 2 $$(1+ix)^{-y}=\sum_{k=0}^{\infty}i^{k}x^{k}\frac{\Gamma(1-y)}{k!\Gamma(1-k-y)}$$ Thus : $$\int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi mx}dx=\sum_{k=0}^{\infty}i^{k}\frac{\Gamma(1-y)}{\Gamma(1-k-y)}\frac{1}{(2\pi m)^{k+1}}$$ $$=i(-2\pi i m)^{y-1}\Gamma(1-y,-2\pi i m )$$","['complex-analysis', 'special-functions', 'integration']"
1366049,Iterated Integral and Sign Change in Answer,"Given the iterated integral $\int_0^1\int_x^{2-x}(x^2-y) \, dy \, dx$, the value for the type I integral is, \begin{align*}
& \int_0^1\int_x^{2-x}(x^2-y)\,dy\,dx \\
= {} & \int_0^1 x^2y\Big|_x^{2-x} \, dx - \int_0^1 \left.\frac{y^2}{2}\right|_x^{2-x} \, dx \\
= {} & \int_0^1 x^2(2-2x) \, dx - \int_0^1(2-2x) \, dx \\
= {} & \int_0^1 2x^2 \, dx - \int_0^1 2x^3 \, dx - \int_0^1 2 \, dx + \int_0^1 2x \, dx \\
= {} & 2 \left.\frac{1}{3}x^3\right|_0^1 - \left.2 \frac{x^4}{4}\right|_0^1 - 2x\Big|_0^1 + 2\frac{1}{2} x^2\Big|_0^1 \\
= {} & \frac{2}{3} - \frac{1}{2} -2 + 1 \\
= {} & \frac{2}{3} - \frac{3}{2} = -\frac{5}{6}
\end{align*} We then calculate the type II integral, thus,
$$
\int_0^1\int_y^{2-y}(x^2-y) \, dx \, dy = \frac{5}{6}
$$ The two integrals differ by the presence of a negative sign. Does this mean that these integrals are not iterated? EDIT: It would seem that the issue has to deal with the order of the integration limits. Why are the limits reversed when you take the iterated integral with respect to $dx \, dy$? Thank you for your time.","['multivariable-calculus', 'definite-integrals', 'integration']"
1366050,Computing residues of $\cot(\pi z)/z(z+1)$ with symmetries,"I would like to know if there is a quick way of computing the residues of $$f(z) = \frac{\cot \pi z}{z(z+1)}$$at the points $z = 0$ and $z = -1$. They are double poles. Expanding this in Laurent series I have: \begin{align} \frac{\cot \pi z}{z(z+1)} &= \frac{1}{z}\left(\frac{1}{\pi z}-\frac{\pi z}{3}-\frac{\pi^3z^3}{45}+\cdots\right)(1-z+z^2-z^3+z^4+\cdots) \\ &= \frac{1}{\pi z^2}-\frac{1}{\pi z}+\frac{1}{\pi}-\frac{\pi}{3}+\cdots\end{align}
which gives: $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)}, 0\right) = -\frac
1\pi.$$ My calculation above seemed quick, but computing Laurent series for $\cot$ is a pain. Also, Wolfram Alpha gives:  $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)},-1\right) = -\frac
1\pi,$$too, which makes me think that there is some symmetry to be explored here. At first I thought about some symmetry around the $x = -1/2$ axis, and the following plot suggests that it might be the case. However, we don't have quite a straight line, so I don't know how to apply this.","['complex-analysis', 'residue-calculus']"
1366065,How to compute an expected value in shorter ways (when taking all possibilities into account isn't plausible.),"There is this question on which I have been spending a lot of time, trying to understand how to compute an expected value in a comprehensive way, as sorting out all the possibilities doesn't seem like that right thing to do, nor does it even seem possible. The question states: Dan tosses infinitely many standard, independent coins. The coins are tossed one by one. What is the expected number of tosses it will take Dan to arrive at two consecutive heads? The answer says it is 6, and I didn't understand what to do. This is my attempt: Firstly, I need to arrive at the first head. That for itself would have a geometric distribution with $\frac12$ , which requires at least $2$ expected steps to be made. Now, I either get another head and I am done, or I get tail, count one step, and then make 2 more expected steps. Now I am in my 6th move and how do I know I am expected to arrive at head? Is that because last time I arrived at tail? I feel like I am in the right direction, but I don't fully comprehend the properties of expected value.",['probability']
1366084,A question regarding the constant of integration,"Consider the indefinite integral $\int\sin(2x) dx$. There appear to be three seemingly different answers once this integral is evaluated. These are $\frac{-1}{2} \cos(2x) + C$, $\sin^2(x) + C$ and $-\cos^2(x) + C$. This is because all three functions differ only by a constant and thus differentiating them yields $\sin(2x)$. Is it therefore simply a matter of convention which one we decide to choose? In a somewhat more artificial sense, one could say $\int\ 2x dx = (x+n)(x-n) + C$ for any $n \in  \mathbb{R}$. Why this is invalid makes more sense because we expand it and add $-n^2$ to $C$ which will give the accepted answer of $x^2 + C$ (the new $C$ is different, of course). Is this simply done for convenience? Can this rule be generalized/formalized in some way such that more tricky functions, in which the extra constant isn't quite as conspicuous as it is with basic polynomials, can be tackled?","['calculus', 'integration']"
1366118,Finding a recurrence for a sum,"I am trying to implement the following sum using a programming language:
$$\sum_{i=1}^N a^i i^r$$
where $N$, $a$ and $r$ are integers. The problem is, I cannot find a suitable way to do this. Considering $S_r$ as the above sum, I found the following recurrence:
$$S_r=\frac{a^{N+1}(N+1)^r-a\left(1+\displaystyle \sum_{j=0}^{r-1} {r\choose j}S_j\right)}{a-1}$$ But if I use the above recurrence, I cannot evaluate the sum under the given time constraints. So I need to find another recurrence that could help me solve the task but I don't know how to find it. I think that the term:
$$\sum_{j=0}^{r-1} {r\choose j}S_j$$
can be simplified. To clarify a bit, I am looking for a way to evaluate $S_r$ in $O(r)$ time complexity, the current time complexity is $O(r^2)$. Any help is appreciated. Thanks!","['summation', 'recurrence-relations', 'algebra-precalculus', 'sequences-and-series', 'algorithms']"
1366121,"Prove that rational numbers $a,b$ are integers if $a+b$ and $ab$ are integers","I have been trying to prove this via divisibility, assuming that $a=\frac{n}{m}$ and $b=\frac{r}{q}$ for some $n,m,r,q$ in Ints($m$,$q$ not $0$), but I'm completely stuck here. Any help?","['divisibility', 'discrete-mathematics']"
1366138,"$1,2,...,n(n+1)/2$ placed at random in bottom-heavy nxn triang. array. Prob. that largest num in every row is smaller than largest in any row below?","From the 1990 Canada National Olympiad: $\dfrac{n(n+1)}{2}$ distinct numbers are arranged at random into $n$ rows. The first row has
  $1$ number, the second has $2$ numbers, the third has $3$ numbers and so on. Find
  the probability that the largest number in each row is smaller than the largest
  number in each row with more numbers. The conclusions I have reached so far: it is almost impossible to start from the top of the array, without knowing something about the distribution of numbers below (it is possible to meet the conditions for the first row even if it contains a number as large as $n$, whereas it is certain if it contains $1$) working from the bottom up, one can see that the last row must contain the number $\dfrac{n(n+1)}{2}$ if the condition is to be met","['contest-math', 'combinatorics']"
1366163,Problem using trigonometric substitution $x = a \sec θ$ and domain of $\theta$,"I'm studying calculus from Rogawski's Calculus. In trigonometric substitution $x=a\sec \theta$ , he made a note: In the substitution $x = a \sec θ$ , we choose $0\le  θ \le \frac π 2$ if $x \ge a$ and $π \le θ < \frac{3π}2$ if $x \le −a$ . With these choices, $a \tan \theta$ is the
positive square root $\sqrt{x^2 − a^2}$ . When I work on the integral: $$\int \frac {\mathrm{d}x}{x\sqrt{x^2-9}}$$ Using the substitution of $x=3\sec\theta$ with the domain of $\theta$ shown above, the integration will be : $$\int \frac {dx}{x\sqrt{x^2-9}}= \int \frac {3\sec\theta\tan\theta d\theta}{(3\sec\theta)\sqrt{9\sec^2-9}}=\int \frac {\tan\theta d\theta}{3\sqrt{\tan^2 \theta}}\\= \int \frac{d\theta}{3}= \frac\theta 3+ \mathrm{C}= \frac 13 \sec^{-1}\left(\frac x3\right)+ \mathrm{C}$$ which is very wrong in the negative part of the domain of $x$ , as shown in the graph below. The slope of the blue function in the negative domain should be positive not negative!. There are 2 thoughts with this substitution: $1)$ The problem with the domain of $\theta \in (\pi,\frac{3\pi}2) $ is that inverse-substitution cannot be done, because $\theta =\sec^{-1}x\notin  (\pi,\frac{3\pi}2) $ . $2)$ Given the problem in (1), we should choose $\theta \in (0,\pi)-\{\frac\pi 2\}$ which makes $\sqrt{\tan^2 \theta}=|\tan \theta|$ . The integral is then re-written as a piecewise function: $$\int \frac {dx}{x\sqrt{x^2-9}}= \int \frac {3\sec\theta\tan\theta d\theta}{(3\sec\theta)\sqrt{9\sec^2-9}}$$ $$\int \frac {\tan\theta d\theta}{3\sqrt{\tan^2 \theta}} = \begin{cases} = \int \frac {d\theta}{3} = \frac 13 \sec^{-1}(\frac x3)+ C & \text{if $\theta \in (0,\frac \pi 2)$} \equiv x>3 \\= \int \frac {-d\theta}{3} = \frac {-1}3 \sec^{-1}(\frac x3)+ C & \text{if $\theta \in (\frac \pi 2,\pi)$}\equiv x<-3 \end{cases}$$ My questions : Is above thinking right? Is there a mistake in choosing the domain of $\theta$ , as mentioned in the boom? Mathematica gives the answer of $-\dfrac {1}{3} \tan^{-1} \frac{3}{\sqrt{x^2-9}}+\mathrm{C}$ , which is right when graphed. But, how do I derive this result? Thanks for help.","['substitution', 'integration']"
1366164,How to show that $S^1$ with one point removed is still connected?,"$S^1:= \{x \in \mathbb{R^2}: \|x\| = 1 \}$ Suppose $y_0 \in S^1$. Prove $(S^1-\{y_0\}, \mathcal{T}_{S^1- \{y_0\}})$ is connected. where $\mathcal{T}_{S^1- \{y_0\}}$ is the subspace topology coming from the topology on $S^1$. My thought: I show $$f: \mathbb{R} \to S^1, f(x) = (\cos(x),\sin(x))$$ continuous. The I restrict the codomain $S^1$ to $S^1- \{y_0\}$. I meant to use the fact, continuous function $f: X \to Y$, $f(X)$ connected if $X$ connected. The issue here is that, I also have to restrict the domain of $\mathbb{R}$ to $\mathbb{R} - \{x_0\}$, since for all $y_0 \in S^1, \exists x_0 : y_0 = (\cos(x_0), \sin(x_0)) $. This restriction of domain makes the new domain no longer connected. Hence, I can't use the theorem I want to. Any help?",['general-topology']
