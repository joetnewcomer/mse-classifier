question_id,title,body,tags
658535,Weak* continuity,"Let $B$ be the open unit ball in $\mathbb{R}^2$ and $\mathcal{M}^+$ the set of nonnegative Radon measures on $B$ and $\mathcal{M}^2$ the set of $\mathbb{R}^2 \text{-valued}$ Radon measures on $B.$ I am struggling to see that the map $I \colon \mathcal{M}^+ \times \mathcal{M}^2 \to \mathbb{R}, \quad 
(\alpha, \mu) \mapsto \int_B (1-f) \, d\alpha + \int_B g \cdot d\mu$ is weakly* continuous, where $f \in C_c(B)$ and $g \in [C_c(B)]^2.$ How do I approach that? Or more general, how do I show that a function $h \colon X \to \mathbb{R}$ is weakly* continuous for a normed vectorspace $(X,\| \cdot \|)?$ Thanks for any kind of help","['topological-vector-spaces', 'normed-spaces', 'measure-theory', 'functional-analysis']"
658538,Set problem trying to reduce a messy set equation,"Prove that any set equation involving one unknown set X whose RHS is ∅ can be
rewritten as (A ∩ X) ∪ (B ∩ X') = ∅ where neither A nor B involve X . (Assume that the equation is written using only ∩ , ∪ , and complement. Notice also by the second proof in part a that this means that this equation is equivalent to two
simultaneous equations A ∩ X = ∅ and B ∩ X' = ∅.) I have attempted many solutions. But, I just don't seem to find out how to start with this here. This is partly because it could be any set equation! It is obvious that A is disjunct to X and B is disjunct with X'. However, I do not know how to start off with a completely unknown equation and lead to something, which looks like (A ∩ X) ∪ (B ∩ X') = ∅. I have asked around, but no one seems to be able to find a solution for this. Any suggestions?",['elementary-set-theory']
658550,Simplify $\frac yx-\frac xy \over \frac 1y- \frac 1x$,"$$\frac yx-\frac xy \over \frac 1y- \frac 1x$$ I am trying to solve this, I start with the top, multiply the left side by Y and the right side by x to get: $$\frac{y^2-x^2}{xy}$$ then I go to the bottom and  multiply the left side by x and the right side by y to get: $$\frac{y-x}{xy}$$ so that gives me: $${(y-x)(y+x) \over xy} \over{x-y \over xy}$$ I then multiply the top by the inverse of the bottom, which should cancel out the xy and then I am left with : $$(y-x)(y+x) \over{x-y}$$ I assume I should factor out a -1 from the bottom but the answer states ""-(x+y)"" I'm missing something.",['algebra-precalculus']
658589,"If $A$ is reduced, Spec $A$ has no embedded points","I've partly solved the following exercise of Vakil's FOAG, but I am not sure I got the last part right. Could some take a look? 5.5.C. EXERCISE (ASSUMING (A)). Show that if $A$ is reduced, Spec $A$ has no embedded points. Hints: (i) first deal with the case where $A$ is integral, i.e., where
  Spec $A$ is irreducible. (ii) Then deal with the general case. If $f$ is a nonzero function on a reduced affine scheme, show that $\operatorname{Supp}f = \overline{D(f)}$: the support is the closure of the locus where $f$ doesn’t vanish. Show that $\overline{D(f)}$ is the union of the irreducible components meeting $D(f)$, using (i). My solution goes as follows: (i) Since $A$ is integral, an embedded point is given by a non-unit $f$ such that $\operatorname{Supp}f \not \supset V(f)$. This is because Supp $f\supset D(f)$, so that if it also contained $V(f)$, it would contain everything. On the other hand, if $\operatorname{Supp} f\not \supset V(f)$, then Supp $f$ can't be an irreducible component of Spec $A$ and must be the closure of a union of embedded points. But Supp $f\not \supset V(f)$ means that $\exists \mathfrak p \ni f$ with $f_\mathfrak p =0 \iff f\cdot a =0$ for some $a\not \in \mathfrak p$. But this is not possible because $A$ was assumed to be a domain. (ii) In this post is a proof of $\operatorname{Supp}f = \overline{D(f)}$ with the above conditions. I claim that, since there are only finitely many minimal primes (noetherianness is a standing assumption in this chapter), we can cover Spec $A$ by finitely many clopen $D(g_i)$, each one of which corresponding to the closure of a minimal prime. It follows that $(g_i) = A$, and we can write $$\overline{D(f)}=\overline{D(fA)}=\overline{D(f(g_i))}=\overline{D((fg_i))}=\bigcup\overline{D(fg_i)}$$ Now $\overline{D(fg_i)}$ is the $\operatorname{Supp} f \cap \operatorname{Spec} A_{g_i}$, which is the spectrum of an integral domain. By (i) this cannot correspond to a proper irreducible subset of $\operatorname{Spec} A_{g_i}$, so (ii) follows. The claim can be proven by induction, and I show the case where $A$ has three minimal primes $\mathfrak p, \mathfrak q, \xi$. By symmetry, it suffices to show that we can pick an element in $\mathfrak p$ that is not in $\mathfrak q, \xi$. So pick $p_1, p_2 \in \mathfrak p$ such that $p_1 \not \in \mathfrak q$ and $p_2 \not \in \xi$. If either one of the $p_i$ is not in the other two primes, we are done. Otherwise $p_1+p_2$ does the job.","['commutative-algebra', 'algebraic-geometry']"
658600,"Necessary and sufficient conditions for $H$ to be abelian, given a homomorphism from an abelian $G$ into $H$","It's trivial to show that if $ G\cong H$, then $G$ is abelian iff $H$ is abelian. However (Possibly trivial as well :), given that $G$ is abelian and there exists a homomrphism $\varphi:G \rightarrow H$, what additional conditions are necessary and sufficient for $H$ to be abelian as well? Currently, for me, it seems it is necessary for $\varphi$ to be surjective. Is this correct?","['group-theory', 'abstract-algebra', 'abelian-groups']"
658615,Solve $f(x)=\int_{x-1}^{x+1} f(t) \text{d}t$,"Solve $f(x)=\int_{x-1}^{x+1} f(t) \text{d}t$. We know that $f(x)=0$ is a solution, are there any other solutions? I suppose I can start with $f(x)=\frac{dg(x)}{dx}$, and then: $$\begin{align*}
\frac{dg(x)}{dx}&=\int_{x-1}^{x+1} \frac{dg(t)}{dt} dt \\
\frac{dg(x)}{dx}&=g(x+1)-g(x-1) \\
\end{align*}$$ But then I'm stuck.","['calculus', 'integration']"
658627,Proving the convergence of limit and series,"Let be the sequence $a_{n+1}=\ln{(1+a_n)}, n\ge1, a_1=1$. Show that $\lim_{n\to\infty}{a_n}=0$ and the series $\sum_{n=1}^{\infty}{a_n^2}$ converges. My try: I assumed that $a_n$ is monotonic (decreasing) and lower bounded by $0$ (intuitively). I denoted $L=\lim_{n\to\infty}{a_n}$, so $L=\ln(1+L)$ which gives $L=0$. If there exists mistakes, please tell me. How do I prove that the series converges?
$$\sum_{n=1}^{\infty}{a_n^2}=\sum_{n=1}^{\infty}{\ln^2(1+\ln^2(1+\dots+\ln^2(1+1)))}$$ Thank you!","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
658637,Integrating $\int_0^\infty\frac{1}{1+x^6}dx$,$$I=\int_0^\infty\frac{1}{1+x^6}dx$$ How do I evaluate this?,"['definite-integrals', 'improper-integrals', 'integration']"
658660,Multivariate differentiability verification,"I have tried an attempt on the following: Let $F:U\in \Bbb{R}^n\to \Bbb{R}$ and $f:\Bbb{R}\to \Bbb{R}$ where $f$ is an even function. Now $F(\mathbf{x})=f(|\mathbf{x}|)$, where $|\ . |$ is the Euclidean norm.
Given $f$ is $C^r$, I have to show that $F$ is $C^r$. My attempt was to argument by induction. I showed that $F$ is $C^1$, basically using univariate chain rule on $\frac{\partial f\left(\sqrt{x_1^2+\dots+x_n^2}\right)}{\partial x_1}$ and arguing that it would be continuous using the fact that $f$ is $C^r$. Since the argument works for all $x_i$, it establishes first-differntiability for $F$ and continuity of the operator $DF(\mathbf{x})$. Then I moved on to show $F$ is $C^r$ assuming $F$ is $C^{r-1}$ and $f$ is $C^r$. Now what I did was partially differentiate: $$
{\partial \over \partial x_2} \left[\frac{\partial ^{k-1}f}{\partial x_1^{k-1}}\right] = \underbrace{{\partial \over \partial |\mathbf{x}|} \left[\frac{\partial ^{k-1}f}{\partial x_1^{k-1}}\right]}_{(1)} . \underbrace{{\partial |\mathbf{x}| \over \partial x_2}}_{(2)}
$$ My argument runs as follows: this partial derivative is continuous since $f$ is $C^r$ and hence $(1)$ is continuous. Continuity of $(2)$ is establishd in a similar manner, since $\sqrt{\mathbf{x}}$ is $C^r$ if $\mathbf{x} \neq \mathbf{0}$. Then the product would be continuous. I am uneasy on multivariate arguments and dont know if my approach is completely off track. I didnt use the even function property, so I am sure I might me missing something. Any hints and references would be welcome. Thanks!","['multivariable-calculus', 'calculus']"
658680,Del Pezzo surface of degree $4$,"I'd like to show that the del Pezzo surface $S_4\subset\mathbb{P}^4$ (i.e. the complete intersection of two quadrics) is rational. I've got two possibilities: 1- I show that is the blow-up of $\mathbb{P}^2$ at 5 points. 2- I use Castelnuovo's rationality criterion, so i prove that both $q(S_4)=h^1(\mathcal{O}_{S_4})=0$ and $P_2=h^0(\mathcal{O}_{S_4}(2K))=0$, where $K$ is the canonical divisor on $S_4$. I'd like to do it ""by hand"" (for example i don't want to use theorems like the Kodaira vanishing theorem in the second case). Is there anyone that could give me any hints?","['birational-geometry', 'algebraic-geometry', 'surfaces']"
658687,Brute Force Algebraic Geometry: interpretation of algebraic extensions of field of rational functions,"I am trying to affirm the following (without use of dimension theory): Let $V_{1},V_{2}$ be the zero-loci of prime ideals $I_{1},I_{2}<\mathbb{K}[x_{1},\ldots,x_{d}]=:R$ such that $V_{2}\subsetneqq V_{1}$, i.e.: $$\{z\in\mathbb{K}^{d};f(z)=0\forall f\in I_{2}\}\subsetneqq\{z\in\mathbb{K}^{d};f(z)=0\forall f\in I_{2}\}$$ then the transcendence degree of $\mathbb{K}(V_{2})$, the field of fractions of $\mathbb{K}[V_{2}]:=R/I_{2}$, over $\mathbb{K}$ is strictly smaller than the transcendence degree of $\mathbb{K}(V_{1})$, the field of fractions of $\mathbb{K}[V_{1}]:=R/I_{1}$, over $\mathbb{K}$. What have I done? As $I_{2}\subseteq I_{1}$, we note that $\mathbb{K}[V_{2}]$ is a quotient of $\mathbb{K}[V_{1}]$ and hence the transcendence degree of $\mathbb{K}(V_{2})$ is at most the transcendence degree of $\mathbb{K}(V_{1})$ (I skipped a few details but it follows basically from both being finitely generated over $\mathbb{K}$). Assume now that the transcendence degrees are equal, then both rings $\mathbb{K}[V_{1}]$ and $\mathbb[V_{2}]$ are integral extensions of the ring $\mathbb{K}[t_{1},\ldots,t_{r}]$, where $r$ is the transcendence degree, by the Noether normalization lemma. So we have $\mathbb{K}[V_{1}]$ and $\mathbb{K}[V_{2}]$ are finitely generated $\mathbb{K}[t_{1},\ldots,t_{r}]$-modules, which induces an additive isomorphism with $\mathbb{K}[t_{1},\ldots,t_{r}]^{n}$ for respective $n\in\mathbb{N}$. In particular we get:
$$I_{2}/I_{1}\cong\bigoplus_{i=1}^{n} S(f_{i}+I_{1})$$
as $S$-modules, where the $f_{i}$s are elements in $I_{2}$ and $S$ is the preimage of $\mathbb{K}[t_{1},\ldots,t_{r}]$ in $\mathbb{K}[V_{1}]$ under the isomorphism $$\mathbb{K}[V_{1}]\cong\mathbb{K}[t_{1},\ldots,t_{r}][\alpha_{1},\ldots,\alpha_{s}]$$ with $\alpha_{1},\ldots,\alpha_{s}$ integral over $\mathbb{K}[t_{1},\ldots,t_{r}]$. Question: Can I deduce a contradiction from this? May I even be able to show that $I_{j}$ being prime implies that $\mathbb{K}[V_{j}]=\mathbb{K}[t_{1},\ldots,t_{r}]$? What was the idea? The integral extension adds finitely many copies of $\mathbb{K}[t_{1},\ldots,t_{r}]$ (thinking of finite algebraic extensions of fields) which seem to me to act like constants. This should not contain any interesting information about the variety. Truth be told: it is a bit more complicated than that but this was the idea I had when I decided to proceed like that. Another idea was that the layers corresponded to different components of the variety, which is excluded by the ideals being prime. Anyway: it would be interesting to give an interpretation to $\mathbb{K}(V)$ being an algebraic extension of $\mathbb{K}(t_{1},\ldots,t_{r})$. Edit: Just as a piece of information: I am going through that because I need dimension in a context, which is in fact not so much concerned with algebraic geometry. One can extract Noether normalization quite explicitely with not a much too evolved commutative algebra background (see Hungerford's Algebra book). So it would be nice if one could finish it in the rather explicit setting I am in.
The goal is to have a minimal set of knowledge about algebraic groups available in order to discuss orbits of certain algebraic groups on homogeneous spaces. The latter by itself is a lot to discuss and by requiring formal algebraic geometry, any discussion becomes tremendeously huge.","['commutative-algebra', 'algebraic-geometry']"
658693,"Are there any examples of vector spaces over non-numerical fields? If not, why not?","By non-numerical vector spaces I mean vector spaces that do not have as their scalars some sort of easily discernible numerical fields (e.g. complex numbers, functions are usually maps from one numerical space to another, etc.). Are there any examples of non-numerical vector spaces? If not, why not? I know that this question asked for something similar , but its accepted answer gave ""numerical vector spaces"", and more importantly the motivation behind the question was pedagogical. I on the other hand, am asking in order to determine if there would be any drawbacks to building an algebra that assumes its scalars are all reals, and that complex numbers, quarternions, etc. are built into its higher dimension forms (e.g. geometric algebra/Clifford algebra), as such an algebra might perhaps not be able to capture a useful vector space over a non-numerical field.","['vector-spaces', 'abstract-algebra']"
658724,Inverse image of $\sigma$-algebra,"Is this proof correct? Let $f$ be a function mapping $\Omega$ to $E$ with $\mathcal E$ a $\sigma$-algebra on $E$. Show that $\mathcal A=\{f^{-1}(B):B\in \mathcal E\}$ is a $\sigma$-algebra on $\Omega$. Pf. Let $A\in\mathcal A$; then $A=f^{-1}(B)$ for some $B\in\mathcal E$. $A^c=(f^{-1}(B))^c=f^{-1}(B^c)$ which is $\in \mathcal A$ because $B^c\in \mathcal E$. Let $(A_i)_{i\in I}$ be a countable family of elements of $\mathcal A$ and consider the union $\bigcup A_i$. $A_i=f^{-1}(B_i)$ for all $i\in I$. So: $$\bigcup A_i=\bigcup f^{-1}(B_i)=f^{-1}(\bigcup B_i)$$
which is $\in \mathcal A$ because $\bigcup B_i\in \mathcal E$. It remains to show that $\Omega \in \mathcal A$.Since $E\in \mathcal E$, we have: $$\Omega=f^{-1}(E)\in\mathcal A$$","['measure-theory', 'proof-verification']"
658734,How to improve mathematical thinking? [duplicate],"This question already has answers here : How to Improve Mathematical Thinking and General Problem Solving Skills? (6 answers) Closed 10 years ago . I am a sophomore in high school. When I approach a math problem or concept, I normally try to determine a formula or systematic method of solving all similar problems. However, since I entered precalculus, I have found that this approach does not work. I really love math and find it interesting and exciting, but I find that I am unable to solve the kinds of conceptual problems that I have been doing more recently. For example, when I try to do a counting problem, it is often unclear how to approach it. How can I improve my problem-solving and critical thinking skills? Also, how can I approach problems logically to solve ones that are not clear at first?","['algebra-precalculus', 'soft-question']"
658736,Simplify the surd expression.,Simplify the surd. $(2\sqrt 3 + 3\sqrt 2)^2$ I know I should us this formula: $(a^2+2ab+b^2)$ But this gets complicated later. Please explain. :(,['algebra-precalculus']
658738,Regular and singular points in a second order differential equation.,"For a linear homogeneous second order differential equation $$y'' + p(x)y'+q(x)y=0$$ A point $x_0$ is regular point of the equation if the functions $p,q$ are analytic at $x_0$, and a singular point if they are not. If the functions $p,q$ satisfy:
$$\lim_{x\to x_0} (x-x_0)p(x) <\infty$$
$$\lim_{x\to x_0} (x-x_0)^2 q(x)<\infty$$
then the singularity is said to be regular, otherwise it's irregular. Two questions: Firstly, what motives this particular bound on the order of growth (linear, quadratic) of the functions? Secondly, I am wondering how (or indeed, if) those definitions can be adapted to the general case, where we drop linearity and homogeneity, so the equation is of the form: $$y''=f(x,y,y')$$",['ordinary-differential-equations']
658757,When does a dual of a compound proposition equal itself?,"So I am studying computer science and right now I am stuck on a problem. When does s∗ = s, where s is a compound proposition? So far the only thing I can come up with is: s* = s when the compound proposition is composed only of the same           propositions. (ex. p ∧ p = p ∨ p) The book defines duality as: The dual of a compound proposition that contains only the logical operators ∨, ∧, and ¬ is the compound proposition obtained by replacing each ∨ by ∧, each ∧ by ∨, each T by F, and each F by T. The dual of s is denoted by s∗.
(Discrete Mathematics and its Applications, Rosen, 7e) Any help would be great, this is a tricky one.",['discrete-mathematics']
658777,PDE uniqueness by energy method contradicts non-uniqueness???,"Consider 
$$u_t - \Delta u + u = 0$$
$$\frac{\partial u}{\partial \nu} = 0$$
$$u(T) = u(0)$$
on a domain $\Omega$ (the BC is obviously on $\partial\Omega$. If $u$ solves this PDE, clearly as does $\lambda u $ for any constant $\lambda.$ So uniqueness is not there. Suppose we have two solutions $u$ and $v$. Their difference $d = u-v$ satisfies
$$d_t - \Delta d + d = 0$$
$$\frac{\partial d}{\partial \nu} = 0$$
$$d(T) = d(0)$$ Multiplying the equation by $d$ and integrating by parts we get
$$\frac{1}{2}\frac{d}{dt}\int_{\Omega} d^2(t) + \int_{\Omega} |\nabla d(t)|^2 + \int_{\Omega} d^2(t) = 0$$
Now integrating by time
$$\frac{1}{2}|d(T)|_{L^2} - \frac{1}{2}|d(0)|_{L^2} + \int_{0}^T |\nabla d(t)|_{L^2}^2 + \int_0^2 |d(t)|_{L^2}^2 = 0$$
but the first two terms cancel each other out, and we get $d=0$ in $H^1$. So this shows that there is a unique solution. What am I doing wrong???!?! Edit : maybe $0$ is the only solution to this problem? How to prove this if so? What happens in nonhomogenous case?","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
658794,statistics and probability. Homework,"I've been given the following problem:
if I have 8 red and 10 blue marbles what is the probability that from 4 marbles that I took fom tha bag 2 are red? I missed some lessons. Any help would be appreciated.","['statistics', 'probability']"
658815,Remembering the Portmanteau Theorem,"I'm looking for a good way to remember/understand part of the Portmanteau theorem . Specifically, let $X$ be a metric space. The part of the Portmanteau theorem I'm asking about says that for a sequence $\mu_n$ of Borel probability measures on $X$ and another such measure $\mu$ , the following are equivalent: $\int f\, d\mu_{n} \to \int f\, d\mu$ for every bounded, continuous, real-valued $f$ ; $\limsup \mu_n(C) \leq \mu(C)$ for every closed $C \subset X$ ; $\liminf \mu_n(U) \geq \mu(U)$ for every open $U \subset X$ . I have trouble remembering if the $\limsup$ goes with the closed or open sets and which way the inequalities go. Is there an easy way to see why, for example, 1. isn't equivalent to $\liminf \mu_n(U) \leq \mu(U)$ for every open $U\subset X$ ?",['probability-theory']
658823,Solving a recurrence involving floor and square root (Concrete Mathematics 3.28),"I'm working through Concrete Mathematics and having trouble understanding an answer to a problem (as well as what I could've done to come up with the answer). Problem 3.28 asks: Solve the recurrence
$$a_0 = 1$$
$$a_n = a_{n-1} + \lfloor \sqrt{a_{n-1}}\rfloor (\text{for }n >0)$$ I'm really not sure what to do with this. Chapter 3.3 talks about ""Floor/Ceiling Recurrences"", but it doesn't really give any general tools or strategies for dealing with them. It just provides two specific examples of problems involving floor/ceiling recurrences. Looking at the answer at the end it says:
""The key observation is that $a_n=m^{2}$ implies $a_{n+2k+1} = (m + k)^2 + m-k$ and $a_{n+2k+2} = (m+k)^2 + 2m$, for $0 \le k \le m$; hence $a_{n+2m+1}=(2m)^2$. The solution can be written in a nice form discovered by Carl Witty:
$$a_{n-1}=2^l + \lfloor (\frac{n-l}{2})^2 \rfloor$$
when $2^l + l \le n \lt 2^{l+1} +l+1$ What strategy could I have taken that would've allowed me to make that ""key observation""? Furthermore, how does $a_n=m^2$ actually imply that? If I use the recurrence on $a_{n+2k+1}$, I get
$$a_{n+2k} + \lfloor \sqrt{a_{n+2k}} \rfloor$$ I can then keep expanding the terms until I get an $a_{n}$ term, and substitute that with $m^2$, but I'm not sure what the other parts of the equation would look like when it has been expanded that much. ...so I can't really come up with a strategy for putting that in terms of m and k (I can't find any techniques the book mentions for doing that), and I haven't really seen something like this in reading the chapters or doing other problems so I don't have an intuitive sense of what to do next.","['recurrence-relations', 'discrete-mathematics', 'ceiling-and-floor-functions']"
658871,Perfectly centered break of a perfectly aligned pool ball rack,"This question is asked on Physics SE and MathOverflow by somebody else. I don't think it belongs there, but rather here (for reasons given there in my comments there; edit: now self-removed). Imagine the beginning of a game of pool, you have 16 balls, 15 of them in a triangle <| and 1 of them being the cue ball off to the left of that triangle. Imagine that the rack (the 15 balls in a triangle) has every ball equally spaced apart and all balls touching all other appropriate balls. All balls are perfectly round. Now, imagine that the cue ball was hit along a friction free surface on the center axis for this triangle O-------<| and hits the far left ball of the rack dead center on this axis. How would the rack react? I would imagine this would be an extension of newtons cradle and only the 5 balls on the far end would move at all. But in what way would they move? Thanks","['dynamical-systems', 'trigonometry', 'billiards', 'physics']"
658878,Typo on Wikipedia's entry on Hoeffding's inequality?,"In Wikipedia's entry on Hoeffding's inequality , they state that if $\overline{X} := \frac 1 n \sum_{i=1}^n X_i$, then
$$ P(\overline{X}-E[\overline{X}] \ge t) \le \exp (-2n^2 t^2)$$
if we assume for simplicity that $a_i=0$ and $b_i=1$ for all $i$. This is my first encounter with Hoeffding's inequality, so I am unfamiliar with all the different manifestations of this theorem, but regardless, all the other sources I have seen have something along the lines of $\exp (-2nt^2)$ instead. Is Wikipedia's entry a typo? Remark: I believe that the version of the inequality where we consider $Y := \sum_{i=1}^n X_i$ instead of the average $\overline{X}$ has the bound $\exp(-2t^2)$. But, nowhere else have I seen $\exp(-2n^2 t^2)$ besides the Wikipedia entry. Thanks!","['probability-theory', 'inequality']"
658915,A question about inner product and Gram-Schmidt process,"Let there be the following bilinear form: $\int_0^1f(x)g(x)x\,dx$, which acts on the polynomials with degree $\leq2$.  I needed to prove it's an inner product and then find an orthonormal basis. I needed to use Gram-Schmidt proccess. So, when I make the vectors I find to be of length one, what's the inner product I use? Lets say some vector for basis if $h$, then the normal of the vectors is $\sqrt{\int_0^1h(x)h(x)x\,dx}$, or is it the 'standard' inner product $\sqrt{\int_0^1h(x)h(x)\,dx}$? In other words, when a basis is orthnormal, it is orthogonal and of length one with accordance to some specific inner product and not necessarily others? Thanks in advance!",['linear-algebra']
658937,Smallest constant in exponent so that limit of sum is $0$,I am trying to work out the smallest constant $c>0$ so that $$\lim_{n \to \infty} \sum_{a=1}^n \sum_{b=0}^n {n \choose a} {n-a \choose b} \left({a+b \choose a} 2^{-a-b}\right)^{c n/\ln{n}} =0 .$$ If $c =3$ I can see that it certainly does and if $c=2$ it appears not to. How can you work out the constant exactly? My current guess from a crude use of Stirling's approximation is that $c> 6/e$ is necessary and sufficient.,"['binomial-coefficients', 'limits']"
658961,Solve the following differential equation: $ty' + 2y = \sin(t)$,"An exercise from the book: Solve the following differential equation: $ty' + 2y = \sin(t)$ This is the first time I approch a differential equation, and the book doesn't provide an example how to solve an differential equation, So I need your help to show me how to solve this differential equation. It's not a homework. Thanks in advance!",['ordinary-differential-equations']
658992,Proving the geometric sum formula by induction,$$\sum_{k=0}^nq^k = \frac{1-q^{n+1}}{1-q}$$ I want to prove this by induction. Here's what I have. $$\frac{1-q^{n+1}}{1-q} + q^{n+1} = \frac{1-q^{n+1}+q^{n+1}(1-q)}{1-q}$$ I wanted to factor a $q^{n+1}$ out of the second expression but that 1- is screwing it up...,"['geometric-progressions', 'induction', 'summation', 'algebra-precalculus']"
659000,How to find the inverse function?,"For the function $f:\mathbb{N}\to\mathbb{N}$ the descrete derivative for $f$ in $n\in \mathbb{N}$ is defined as follows: $$f'(n) := f(n+1)-f(n)$$ Find the chain rule for the descrete derivative. Given that $f:\mathbb{N} \to \mathbb{N}$ is bijective. Is it possible to create a rule for descrete derivative of the inverse function of $f$? Hello, could someone give me a reasonable solution and explain the approach...thx","['calculus', 'real-analysis', 'analysis']"
659001,Proving taylor coefficients of $\tan {\pi z \over 2}$ follow $\lim \limits_{n\to\infty} a_{2n+1}={4\over\pi}$.,"I've stumbled upon the following question while studying for a test in complex analysis: Given the following Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$ Prove that: $\lim \limits_{n\to\infty} a_{2n+1}={4\over\pi}$. I've tried using Cauchy's integral formula for the $n^{th}$ derivative of $\tan {\pi z \over 2}$, but didn't get much progress. If it helps, this is the third part of the question. The two others are: Find all the singularity points of $\tan {\pi z \over 2}$, classify them and find the residues. (There are singularities at $\{1 + 2k; k \in \Bbb Z\}$, all are simple poles with  residue $-{2\over\pi}$) What is the radius of convergence of the Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$? (It's 1 because $\tan {\pi z \over 2}$ has singularities in -1, 1) I'm struggling with this question for several hours, so any help would be appreciated.",['complex-analysis']
659020,Prove by induction $6\cdot 7^n -2\cdot 3^n$ is divisible by $4$ for $n\ge 1$,Prove by induction $6\cdot 7^n -2\cdot 3^n$ is divisible by $4$ for $n\ge 1$. I am struggling on this problem very much. So far I have Basis case = $6\cdot 7^1 - 2\cdot3^1 = 36$ which is divisible by $4$ Assume for a $n$ that $6\cdot 7^n-2\cdot3^n$ is divisible by $4$. After that I am not sure what to do.,['discrete-mathematics']
659023,Existence of an infinite set included in a circle with rational coordinates.,"I am trying the following exercise: Let $\mathcal {C}$ the set of points of a circle with center $O$ and radius $1$ with rational coordinates. Show that there exists a infinite set $\mathcal{D} \subsetneq \mathcal{C}$ ($\subsetneq \mathbb{Q}^2 \subsetneq \mathbb{R}^2$...) such that for any pair of points $\mathcal{D}$ the distance between these two points is irrational. However I don't really have ideas to start. Edit: Let $(\frac{p}{q},\frac{u}{v})\in \mathcal{C}$ such that $(pv)^2+(uq)^2=(qv)^2$, then $(pv,uq,qv)$ is a Pythagorean triple.
and reciprocally if we have a Pythagorean triple $(a,b,c)$, then $(\frac{a}{c},\frac{b}{c}) \in \mathcal{C}$. Therefore,
$$\mathcal{C} = \{(\frac{2uv}{u^2+v^2},\frac{u^2-v^2}{u^2+v^2}), (u,v) \in \mathbb{Z}^2 \} \bigcup \{(\frac{u^2-v^2}{u^2+v^2},\frac{2uv}{u^2+v^2}), (u,v) \in \mathbb{Z}^2 \}$$ Edit 2 Between two rational numbers there is always an irrational number Proof. Let $(r,r')\in \mathbb{Q^2}$ with $r<r'$ and $x=r+\frac{\sqrt{2}}2(r'-r)$; Then $x\in ]r,r'[$ (because $0<\frac{\sqrt{2}}2<1$). T
herefore $\sqrt{2}(\frac{r-r'}2)\notin \mathbb{Q}$ so that $x\notin \mathbb{Q}$. We consider the Euclidean plane. Let $n\geq 3$ an integer, there exist n points such that the distance between any two of these points is irrational. Proof. Let $A_n$ a point with coordinates $(n,n^2)$ the distance between $A_n$ et $A_m$ is $$\sqrt{(n-m)^2+(n^2-m^2)^2}=\vert n-m \vert\sqrt{(n+m)^2+1}$$
if $n \neq m$ then $\vert n-m \vert \neq 0$ and $n+m\geq 1$ wich implies $(n+m)^2+1$ is not a square number . Therefore $\vert n-m \vert\sqrt{(n+m)^2+1}$ is an irrational number. Now I know that the distance between two points in the unit circle is : $$2\vert \sin( \frac{\widehat{AOB}}2) \vert$$ Thank you in advance,","['geometry', 'elementary-set-theory', 'number-theory']"
659036,Shelving identical books,"Suppose that we have $5$ red, $5$ black and $3$ white books that are indistinguishable to place onto a) $1$ shelf, b) $3$ shelves, so that no adjacent books have the same colour. How many different ways are there to place the books? Does my solution for the a) case include all possible ways? We line up all red books: _R_R_R_R_R_ and now have $6$ free spots. We choose $5$ of them for black books. There are $2$ cases. There are either $2$ black books both at the leftmost and the rightmost spot, or only at $1$ of them. First case looks like this: BR_R_R_R_RB. We choose $3$ more spots for blacks and put one of the white books in the remaining spot. Then we have something like this: BRWRBRBRBRB. For the remaining $2$ white books we have $10$ spots to choose from: _B_RWR_B_R_B_R_B_R_B_ $$\binom43 \cdot \binom{10}2$$ As for the second case, we have $2$ ways to put the black books. Either BRBRBRBRBR or RBRBRBRBRB. We have then $11$ spots to choose from. $$2 \cdot \binom{11}3$$ The answer I found thus is $180+330=510$ Is there a better or a generic method that I can use for such problems, i.e permuting repeated identical items such that no adjacent items are same? And nevertheless, I still need help for the b) case if my solution were right.",['combinatorics']
659037,Limit $\lim\limits_{x\to0}\frac1{\ln(x+1)}-\frac1x$,The limit is $$\lim\limits_{x\to0}\frac1{\ln(x+1)}-\frac1x$$ The problem is I don't know if I can calculate it normally like with a change of variables or not. Keep in mind that I'm not allowed to use L'Hôpital's rule nor the $\mathcal O$-notation.,"['logarithms', 'calculus', 'algebra-precalculus', 'limits']"
659096,Is $\mathbb{Z}[x] / \langle (x^2 + 1)^2 \rangle$ isomorphic to a familiar ring?,"The quotient ring $\mathbb{Z}[x] / \langle (x^2 + 1)^2 \rangle$ was brought up in class today to contrast it with $\mathbb{Z}[x] / \langle x^2 + 1 \rangle$ after a discussion about adjoining elements to rings.  That is, the second quotient ring given here is of course isomorphic to $\mathbb{Z}[i]$.  We are adjoining $i$ to $\mathbb{Z}$ because $i$ satisfies $x^2 + 1 = 0$.  However, $i$ also satisfies $(x^2 + 1)^2 = 0$.  But surely $\mathbb{Z}[x] / \langle (x^2 + 1)^2 \rangle \not\cong \mathbb{Z}[x] / \langle x^2 + 1 \rangle$.  So is $\mathbb{Z}[x] / \langle (x^2 + 1)^2 \rangle$ isomorphic to some familiar ring? I've tried to think of some homomorphisms from $\mathbb{Z}[x]$ to other rings (e.g. $\mathbb{Z}[i] \times \mathbb{Z}[i]$) trying to get a kernel of $\langle (x^2 + 1)^2 \rangle$, but no luck.  Intuitively, it seems like we are ""adjoining $i$ twice"", to get a sort of $4$ dimensional structure, as compared to $\mathbb{Z}[i]$ which is like a $2$ dimensional structure. EDIT:  A thought: perhaps the quotient is isomorphic to the Lipschitz quaternions?  I can't seem to prove this claim.","['ring-theory', 'abstract-algebra']"
659104,$n$th derivative of $e^x \sin x$,"Can someone check this for me, please? The exercise is just to find a expression to the nth derivative of $f(x) = e^x \cdot \sin x$. I have done the following: Write $\sin x = \dfrac{e^{ix} - e^{-ix}}{2i}$, then we have $f(x) = \dfrac{1}{2i} \cdot (e^{(1+i)x} - e^{(1-i)x})$. Taking the derivatives: $f^{(n)}(x) = \dfrac{1}{2i} \cdot ((1+i)^n e^{(1+i)x} - (1-i)^n e^{(1-i)x})$ Now, I use that: $$ (1+i)^n = {\sqrt{2}}^n \cdot \left(\cos\dfrac{n \pi}{4} + i \sin\dfrac{n \pi}{4}\right) \\(1 - i)^n = \sqrt{2}^n \cdot \left( \cos \dfrac{-n \pi}{4} + i \sin \dfrac{-n \pi}{4} \right)$$ Plugging that mess, I get: $$f^{(n)}(x) = \dfrac{e^x}{2i} \sqrt{2}^n \cdot \left(\left(\cos \dfrac{n \pi}{4} + i \sin \dfrac{n \pi}{4}\right) e^{ix} - \left(\cos \dfrac{-n \pi}{4} + i \sin \dfrac{- n \pi}{4}\right) e^{-ix} \right)$$ But, $e^{ix} = \cos x + i \sin x$, and using Moivre's theorem, that makes: $$f^{(n)}(x) = \dfrac{e^x}{2i} \sqrt{2}^n \cdot \left(\cos \left( x + \frac{n \pi}{4}\right) + i \sin \left( x + \frac{n \pi}{4}\right) - \left(\cos \left( - x  - \frac{n \pi}{4}\right) + i \sin \left( -x -\frac{ n \pi}{4}\right)\right)\right)$$ and since $\cos$ is an even function, and $\sin$ is odd, we get: $$f^{(n)}(x) = \dfrac{e^x}{2i} \sqrt{2}^n \cdot 2i \sin \left(x + \dfrac{n \pi}{4}\right)$$ Simplifying, the answer would be $f^{(n)}(x) = e^x \cdot \sqrt{2}^n \cdot \sin\left(x + \dfrac{n \pi}{4}\right)$. I'm almost positive that this is it, but I just want to be sure. Thank you in advance!","['complex-numbers', 'calculus', 'derivatives']"
659119,Please Explain Boundary Terms in Integration by Parts,"I just learned that when a function does not have compact support, you might need to introduce something called ""boundary terms"" when integrating it by parts. I've scoured the internet trying to learn about them, and I can't find anything about them that doesn't assume that you already know what they are! Could somebody please explain to me (in a very basic way) 1) what boundary terms are; 2) how a function not having support necessitates them. If this is too involved, can you suggest a book or website where I could learn about them?","['ordinary-differential-equations', 'integration', 'partial-differential-equations']"
659128,Set Addition vs. Set Union,"Given two sets $A$ and $B$, what is the difference between $A + B$ and $A \cup B$? For example, if $A = \left\{ a, b, c \right\}$ and $B = \left\{ d, e, f \right\}$, what are $A + B$ and $A \cup B$, respectively?","['arithmetic', 'elementary-set-theory']"
659165,"If $A,B \triangleleft G$ where $G/A$ is perfect and $G/B$ is solvable, then $AB=G$","I'm having trouble proving the following and would appreciate a hint to nudge me in the right direction. Let $A \triangleleft G$ and $B \triangleleft G$, where $G/A$ is perfect and $G/B$ is solvable.  Show that $AB=G$. As a hint, I am told to show that $G/AB$ is both perfect and solvable.  I do see that this implies that $G/AB$ is trivial and therefore $AB=G$.  But, I have not been able to prove it. I figure there are several ways we could conceivably show this.  One would be to somehow construct $G/AB$ from $G/A$ and $G/B$ and show that the desired properties transfer over.  However, I do not see a good way to do this as $G/A$ and $G/B$ are larger than $G/AB$, and I couldn't figure out how to anything with the intersection either. My other idea was to use the properties of $G/A$ and $G/B$ to work backwards and find properties of $A$ and $B$, then try to combine those properties into $AB$, then try to transfer them to the quotient.  I also can't find a way to do this, and I'm not so sure this is a good route to take.  For example: since abelian groups are solvable, $B$ could be as general as any normal subgroup of prime or prime-squared index. I know that if $\phi: G \to H$ is a surjective homomorphism, then $\phi(G^{(n)})=H^{(n)}$.  Take the canonical homomorphism $\pi: G \to G/A$.  Then since $(G/A)'=G/A$ we have $\pi(G')=G/A$ but since $\pi(G')=G'/A$, this seems to imply (to me) $|G'/A|=|G/A|$ and $G=G'$.  Is this correct? Again, I'd appreciate some help to get me going in the correct direction.  Thanks.","['group-theory', 'abstract-algebra']"
659179,Two answers for the same limit,"I have a limit: $$\lim_{x \to \infty} \left(\sqrt{x^4+5x^2+1} - x^2\right)$$ I know the answer is $\frac{5}{2}$, and you can get it by multiplying and dividing both sides by the conjugate ($\sqrt{x^4+5x^2+1} + x^2$) to get $$ \lim_{x \to \infty} \left(\frac{x^4+5x^2+1-x^4}{\sqrt{x^4+5x^2+1} + x^2}\right) = \lim_{x \to \infty} \left(\frac{5x^2+1}{x^2 \sqrt{1+\frac{5}{x^2}+\frac{1}{x^4}} + x^2}\right) $$ It is then pretty easy to see that the stuff under the square root in the denominator will go to 1, and we will get $\frac{5x^2}{2x^2}$ = $\frac{5}{2}$.  This seems to be the correct answer according to WolframAlpha as well.  However, I got to thinking that there seems to be another completely legitimate way to do this limit, as follows: $$ \lim_{x \to \infty} \left(\sqrt{x^4+5x^2+1} - x^2\right) = \lim_{x \to \infty} \left(x^2 \left(\sqrt{1+\frac{5}{x^2}+\frac{1}{x^4}}\right) - x^2\right) $$ Again, the stuff inside the square root will go to 1, so we will get $$ = \lim_{x \to \infty} \left( x^2 - x^2\right )  = 0$$ Obviously this second way is wrong, but can someone explain why?","['calculus', 'limits']"
659180,Convergence of $\frac{\sqrt{a_{n}}}{n}$ [duplicate],"This question already has answers here : If $\sum_{n=1}^{\infty} a_n^{2}$ converges, then so does $\sum_{n=1}^{\infty} \frac {a_n}{n}$ (6 answers) Closed 3 years ago . Can anyone help me with the following question. If $a_{n} \geq 0$ and $\sum a_{n}$ converges then how to prove $\sum \frac{\sqrt{a_{n}}}{n}$ converges. Any idea where to start. My idea was to try using comparison test since $\sqrt{a_{n}} \leq a_{n}$ but it appears that it wouldn't work if $0 \leq a_{n} <1$.",['sequences-and-series']
659193,Family of GCDs all equal to $2$,"Is it true that
$$\gcd\left(5^{2^n} + 1, 13^{2^n} + 1\right) = 2$$
for all $n \in \mathbf{Z}_{\geq 0}$? I'm continually stumped with this and verifying it numerically is quite expensive very quickly (around $n = 20$). I have previously blogged about the origins of the problem and included a proof of an easier version, but this continues to stump me. Letting $F_n = 5^{2^n} + 1$ and $T_n = 13^{2^n} + 1$ it's clear both satisfy the recurrence:
$$f(n) \left(f(n) - 2\right) = f(n + 1) - 2$$
but as of yet, I've been unable to utilize this. However, it may be useful in reducing the amount of computation for attacking it numerically. Concretely, starting from a known output from the Euclidean algorithm
$$a_n F_n + b_n T_n = 2$$
the recurrence may be useful in determining $a_{n + 1}, b_{n + 1}$ in less expensive ways. (Of course we need to define these in such a way that they are unique, e.g. $0 \leq b_n < F_n$.) [ UPDATE ]: I have verified @Zander 's answer that both $F_{2206}$ and $T_{2206}$ are divisible by the value $p = 3 \cdot 2^{2208} + 1$ with the short snippet of Python below. This clearly shows the gcd is not $2$. I was also able to show that $p$ is prime (though this is not necessary) by using Proth's theorem and $a = 11$ as a witness to primality. Finally, I remain unclear on how such an $n$ (and with it a $p$) could be found. n = 2206
modulus = 3 * (2 ** (n + 2)) + 1

f_residue = 5**(2**0) + 1
t_residue = 13**(2**0) + 1

for _ in xrange(n):
  f_updated = f_residue * (f_residue - 2) + 2
  f_residue = f_updated % modulus

  t_updated = t_residue * (t_residue - 2) + 2
  t_residue = t_updated % modulus

print '(5^(2^2206) + 1) MODULO (2^(2208) + 1):'
print f_residue
print '(13^(2^2206) + 1) MODULO (2^(2208) + 1):'
print t_residue","['recurrence-relations', 'divisibility', 'number-theory']"
659200,"Hartshorne Page 150, Theorem 7.1","Theorem 7.1 (a) says that- If $\phi$: $X \rightarrow \mathbb P_A^n $ is an $A$- morphism, then $\phi^*(\mathcal O(1)) $ is an invertible sheaf on $X$, which is generated by the global sections $s_i=\phi^*(x_i) $, $i$=0,1,...,n. I do not know how to prove that the  global sections $s_i$ generate $ \phi ^*(\mathcal O(1)) $. Also I have one more question in the proof of 7.1 (b)-
 While giving the ring homomorphism $A[y_0,...,y_n]$ $\rightarrow$ $\Gamma$($X_i$, $\mathcal   O_X{_i} $), I do not undrstand what is $ s_i / s_j $ . Here $s_i $ and $s_j$ are two global sections of an $ \mathcal O_X $- module. How to undersatnd that their quotient(?) is an element  of $\Gamma$ ($X_i$, $\mathcal O_X{_i}$). Can anyone please explain these things.",['algebraic-geometry']
659207,"Given any nine integers show that it is possible to choose, from among them, four integers a, b, c, d such that a + b − c − d is divisible by 20.","Given any nine integers show that it is possible to choose,
from among them, four
integers
a, b, c, d
such that
a
+
b
−
c
−
d
is divisible by 20. Further show that such a
selection is not possible if we start with eight integers instead of nine. i cant prove it in all cases",['combinatorics']
659222,Let $\sigma$ be the $m$-cycle (1 2 $\ldots m)$. Prove that $\sigma ^i$ is also an $m$-cycle if and only if $i$ is relatively prime to $m$,"I have consulted some other sources, and think that I have some handle on the basic ideas behind the proof, but am having trouble articulating them. I understand that $\sigma$ sends $a_k$ to $a_{k} + 1$ (mod m). Moreover, $\sigma (a_k +1) = a_k +2$ (mod m) That is to say $\sigma ^2 $ sends $a_k$ to $a_k + 2$. One can repeat this indefinitely and can easily show that for any $i \in \mathbb{Z}$$ \sigma^i (a_k) = a_k +i$ (mod m) Is this the right direction or am I dead wrong?","['cyclic-groups', 'permutations', 'abstract-algebra']"
659230,Why is the Laplacian important in Riemannian geometry?,"As I've learned more Riemannian geometry, many of my teachers have said that studying the Laplacian (and its eigenvalues) is very important.  But I must admit, I've never fully understood why. Fundamentally, I would like to know why the Laplacian is important among all differential operators on a Riemannian manifold.  I would also like to know what geometric information the Laplacian is supposed to encode. That being said, I have spent a little time thinking about all this, and my current understanding is as follows: I've heard that the Laplacian is the ""simplest"" isometrically-invariant ""scalar differential operator"" on a Riemannian manifold.  If true, this statement would convince me of its importance. However, I don't know to what extent this is true. An isometric immersion $f \colon S \to M$ is harmonic iff it is a minimal submanifold of $M$.  In particular, an isometrically immersed submanifold of $\mathbb{R}^n$ is minimal iff its coordinate functions are harmonic. The Euler-Lagrange equation for the Dirichlet energy is $\Delta f = 0$.  (But why we care about minimzing energy is also somewhat mysterious to me.) Weitzenböck formulas comparing two elliptic second-order differential operators (and especially Laplacians) give Bochner-type vanishing theorems. I should point out that I'm aware that harmonic functions satisfy many of the nice properties that complex-analytic functions do (by virtue of elliptic regularity and maximum principle magic).  Still, this doesn't quite tell me why I should care about the Laplace operator itself. Note: I'm aware of this related question on the eigenvalues of the Laplacian.  But again, my interest is in Riemannian geometry; matters of applied mathematics (while interesting) are not my focus right now.","['soft-question', 'riemannian-geometry', 'partial-differential-equations', 'differential-geometry']"
659247,probability summation for an infinite sequence,"Very simple case, but don't know how to prove say function $rand$ returns a uniformly sampled value in $(0,1)$ $x_0 = 1$ $x_1 = rand * x_0$ $x_2 = rand * x_1$ ... $x_n = rand * x_{n-1}$ Now the summation $S(n) = \sum_{i=0}^n x_i$ Is $\lim_{n\to\infty} S(n)$ finite? It must be, but how to show ?",['probability']
659249,The Heine-Borel Theorem for the real line,"Hi everyone I'd like to know if the following argument is correct and also I'm very interested in a constructive approach for (2)$\Rightarrow$(1) (a link or a hint it will sufficient for me) I was thinking for a while but I cannot figure out some way to do it. Thanks in advance. Definitions : A subset $X$ of the real line is bounded if we have $X\subset [-M, M]$ for some real number $M>0$. Let $X\subset \mathbb{R}$ and let $x'\in \mathbb{R}$, $x'$ is an adherent point of $X$ iff $\,\forall\varepsilon>0\, ,\exists x\in X \text{ s.t.} \; d(x',x)\le \varepsilon$. We say that $\overline{X}$ is the closure of $X$ if contain all the adherent points of $X$. Theorem (The Heine-Borel Theorem for the line): Let $X$ be a subset of $\mathbb{R}$. Then the following two statements are equivalent: (1) $X$ is closed and bounded (2) Given any sequence $(a_n)$ of real numbers which takes values from $X$ (i.e., $a_n\in X$ for all natural numbers), there exists a subsequence ($a_{n_j}$) which converges to some number $L$ in $X$. Proof: (1)$\Rightarrow$(2) Let $(a_n)_{n=0}^\infty$ be a sequence where $a_n\in X$ for all the natural numbers. Since $X$ is bounded, $|a_n|\le M$  for all $n$, where $M$ is an upper bound for $X$. Then by the Bolzano–Weierstrass theorem there exist a convergent subsequence  $(a_{n_j})$. Let $L=\lim_j a_{n_j},$ then it follows that $L$ is an adherent point of $X$ and since is closed by hypothesis, $L$ is in $X$ as desired. (2)$\Rightarrow$(1) Suppose for the sake of contradiction that either $X$ is not closed or is unbounded. If $X$ is unbounded, let define $X_n=\{y\in X: |y|>n\}$ (each one is non-empty). Then we can find using the AC a sequence $(x_n)$ such that $x_n \in X_n$ for each positive integer. By hypothesis we know that there is a subsequence  $(x_{n_j})$ which converges to some $L$ in $X$. But $|a_n|>L+1$ for all $n\ge L+1$ so, for $j\ge L+1$ we have $|a_{n_j}|>L+1$, a contradiction. Now if $X$ is not closed then it has at least one adherent point $x$ which is not in the set. Since $x$ is adherent there is a sequence $(a_n)$ of terms in $X$ which converges to $x$, i.e., $a_n\rightarrow x$ and $a_n\in X$ for all $n$. Since any subsequence of a convergent sequence converges to the same value, so $x$ must be in $X$, a contradiction. It follows that $X$ must be closed and bounded. $\Box$","['alternative-proof', 'self-learning', 'proof-verification', 'real-analysis']"
659253,Symmetry of the Riemannian curvature tensor,"The Riemannian curvature tensor, in local coordinates, $R_{ijkl}$, has the following symmetries:
$$R_{ijkl}+R_{jikl}=0;$$
$$R_{ijkl}+R_{ijlk}=0;$$
$$R_{ijkl}=R_{klij};$$
$$R_{ijkl}+R_{jkil}+R_{kijl}=0.$$
These algebraic identities give the degree of the freedom of curvature to be $\frac{1}{12}n^2(n^2-1)$. where $n$ is the dimension of manifold. I believe, but have trouble to show, that these identities completely describe the pointwise symmetries of the curvature tensor, i.e. given any $\frac{1}{12}n^2(n^2-1)$ numbers, we can find a Riemannian manifold such that the curvature tensor $R_{ijkl}$ evaluated at certain point, in some local coordinate, is of these particular numbers.","['tensors', 'ordinary-differential-equations', 'riemannian-geometry']"
659254,"product distribution of two uniform distribution, what about 3 or more","Say $X_1, X_2, \ldots, X_n$ are independent and identically distributed uniform random variables on the interval $(0,1)$. What is the product distribution of two of such random variables, e.g.,
$Z_2 = X_1 \cdot X_2$? What if there are 3; $Z_3 = X_1 \cdot X_2 \cdot X_3$? What if there are $n$ of such uniform variables?
$Z_n = X_1 \cdot X_2 \cdot \ldots \cdot X_n$?","['uniform-distribution', 'probability']"
659258,Contour integration of a meromorphic function,Given a meromorphic function $f$ which is uniformly bounded on the upper half plane. Assume that $\int_{-\infty}^{+\infty} f(x)dx$ is absolutely integrable. Then Cauchy's integral theorem suggests $\int_{-\infty}^{+\infty}f(x)dx=0$ except there is some tricky business around infinity. Can someone give me a counterexample or a supporting argument?,"['complex-analysis', 'contour-integration']"
659302,How to prove that $\mathbb{Q}$ ( the rationals) is a countable set,"I want to prove that $\mathbb{Q}$ is countable. So basically, I could find a bijection from $\mathbb{Q}$ to $\mathbb{N}$. But I have also recently proved that $\mathbb{Z}$ is countable, so is it equivalent to find a bijection from $\mathbb{Q}$ to $\mathbb{Z}$?","['elementary-set-theory', 'real-analysis']"
659303,Have action/predicate systems (or similar) been considered in the literature?,"Question. Has the following concept, or anything similar, been considered in the literature? Definition. An action/predicate system consists of sets $A$ (the actions) and $X$ (the predicates) such that the following hold. $A$ forms a monoid $X$ forms a Boolean lattice There is a monoid action $A \times X \rightarrow X$ denoted $ax$, such that for all $a \in A$ we have that the function $x \in X \mapsto ax \in X$ is an endomorphism of $X$. Intuitively, $ax$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ brings about $x$."" There is a function $\sim \,: A \times A \rightarrow X$ subject to the following axioms. Intuitively, $a \sim b$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ has the same effect as $b$."" Reflexivity.   $\forall a \in A : \top \leq (a \sim a)$ Symmetry.      $\forall a,b \in A : (a \sim b) \leq (b \sim a)$ Transitivity.  $\forall a,b,c \in A : (a \sim b) \wedge (b \sim c) \leq (a \sim c)$ Compatibility I. $$\forall a,b,c \in A : (a \sim b) \leq (ac \sim bc),\quad \forall a,b,c \in A : (a \sim b) \leq (ca \sim cb)$$ Compatibility II. $\forall a,b \in A,\;\forall x \in X : (a \sim b) \leq (ax \leftrightarrow bx)$ Reiteration of Question. Has this been considered in the literature? And if so, what is the correct terminology for such structures, and where can I learn more? Intuition. Firstly, we can think of actions as being ""commands"" in a programming language; they move the machine to a new state, depending on its current state. The unit $1 \in A$ is the command that does nothing; furthermore, if $a$ and $b$ are commands, then $ab$ is the result of first performing $a$, then $b$. Secondly, we can think of predicates as being... well, predicates; in the sense of returning true/false depending on the current state of the machine. Furthermore, if $a$ is an action and $x$ is a predicate, then $ax$ can be thought of as the predicate that returns $\mathtt{true}$ for precisely those states in which the action $a$, if performed, would bring about $x$. Thus we may read ""$ax""$ as ""$a$ brings about $x$."" Thirdly, the stipulation that the aforementioned action be a homomorphism of boolean algebras can be motivated by the observation that the following statements ought to be equivalent. We're in a state such that performing $a$ would bring about $x \vee y$. We're in a state such that either performing $a$ would bring about $x$, or performing $a$ would bring about $y$. This corresponds to the axiom $a(x \vee y) = ax \vee ay$. Similar linguistic reasoning can motivate the remainder of the homomorphism stipulation. Fourthly and finally, the function $\sim : A \times A \rightarrow X$ can be given the following interpretation. If $a,b \in A$ are actions, then $a \sim b$ is the predicate that returns $\mathtt{true}$ for precisely those states in which enacting $a$ would change the machine to the same state as would enacting $b$. The axioms associated with $\sim$ are motivated on this basis. A bit more motivation. Here's some basic stuff that we can express in this language. In any state where $x$ holds, we have that $a$ brings about $y$. $$x \leq ay$$ In general, the action $a$ brings about that $x$ implies $y$. $$\top \leq a(x \rightarrow y)$$ In any state where $x$ holds, $a$ has the same effect as $b$. $$x \leq (a \sim b)$$","['automata', 'abstract-algebra', 'computer-science', 'reference-request', 'terminology']"
659312,Countable subset bounded in uncountable set,"Let $(B, \prec)$ be a well ordered set with the ordinal $\omega_1$. Show that every countable subset of B is bounded in $(B, \prec)$.
Let A be such a subset. A is a subset of a well ordered set and such have a least element and it's will be the lower bound. I would like a hint on how to approach the upper bound element.","['ordinals', 'elementary-set-theory']"
659320,Trying to show that $z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R})$ is complex differentiable where $f_z(x) = e^{-(x+z)^2}$,"Let $g$ be the entire function $g(z) = e^{-z^2}$. Note $g$ is integrable along every horizontal line. For each complex number $z \in \mathbb{C}$, define $f_z : \mathbb{R} \to \mathbb{C}$ by $f_z(x) = g(z+x)$.  I am trying to show that the map $z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R})$ is complex differentiable in the sense that, for all $z \in \mathbb{C}$,
$$\frac{f_{z +h} - f_z}{h} \to (f_z)'$$
in $L^1$ as the complex variable $h \to 0$. In other words, I want to show that, for all $z \in \mathbb{C}$,
$$ \int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| \ dx \to 0$$
as $h \to 0$. There is no harm in assuming $z$ is pure imaginary above since the integral is translation invariant in the real direction. So far I have had the idea to write
$$g(z+h+x) -g(z+x) = \int_0^1 g'(z+th +x) \ d(th) = h \int_0^1 g'(z+th+x) \ dt$$ and
$$ g'(x+x) = \int_0^1 g'(z+x) \ dt$$
so that
$$\frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) = \int_0^1 \left( g'(z+th + x) - g'(z+x) \right) \ dt,$$
which is bounded in magnitude by the largest variation in $g'$ over the line from $z+x$ to $z+h+x$. This, would seem to mean, perhaps, that there is an estimate of
$$\int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| $$
related to an area integral of $|g''|$ over on the strip bounded between the lines $\{z+x:x + \mathbb{R}\}$ and $\{z+x+h:x \in \mathbb{R}\}$? Anyhow, I'm beginning to get muddled. Help would be appreciated.","['functional-analysis', 'complex-analysis']"
659356,Problems with limits of functions of two variables,"I have the following function: $$f(x,y):=\begin{cases}\frac{x^3y}{x^6+y^2}&,\;\;(x,y)\neq (0,0)\\{}\\0&,\;\;(x,y)=(0,0)\end{cases}$$ I'm asked about continuity at the origin and the limit of function there. Now, the limit doesn't exist since $$\begin{align*}y=x^3&\implies f(x,x^3)=\frac{x^6}{x^6+x^6}=\frac12\xrightarrow [x\to 0]{}\frac12\;,\;\;\text{whereas}\\y=x&\implies f(x,x)=\frac{x^4}{x^6+x^2}=\frac{x^2}{x^4+1}\xrightarrow[x\to 0]{}0\end{align*}$$ My problem is: if I try to apply what's been shown in several questions in this site, namely polar coordinates, I get $$\begin{cases}x=r\cos t\\y=r\sin t\end{cases}\implies f(r,t)=\frac{r^2\cos^3t\sin t}{r^4\cos^6t+\sin^2t}$$ and now I argue: if $\;\sin t=0\;$ then $\;x=0\;$ and clearly $\;f(0,y)=0\;$ , otherwise $$\lim_{r\to 0}\frac{r^2\cos^3t\sin t}{r^4\cos^6t+\sin^2t}=\frac 0{0+\sin t}=0$$ and thus the limit is zero...where am I going wrong?! Thanks.",['multivariable-calculus']
659399,algebra generated by a countable set is countable,How to prove that algebra generated by a countable set is countable. Hint enough. I know that algebra generated by any set $A$ is of the form $\cup_{i=1}^{m}\cap_{j=1}^{n_i} A_{ij}$ where $A_{ij}$ or $A_{ij}^c$ is in $A$.,"['probability-theory', 'measure-theory']"
659406,Weak derivative of one parameter group and the domain of its generator,"Let $U(t)=\exp(i t A)$ be a one parameter group generated by self-adjoint (unbounded) operator A. It is well-known that if
$$
 \lim_{t\rightarrow 0} \frac{U(t)\psi-\psi}{t}
$$
exists then $\psi$ belongs to the domain of $A$ (see e.g. Reed and Simon 'Methods of Modern Mathematical Physics I', theorem VIII.7). I would like to replace the condition with the following one:
$$
 \forall_{\phi\in\mathcal{H}}\lim_{t\rightarrow 0} \frac{(\phi|U(t)\psi-\psi)}{t}
~~~~~~\textrm{and}~~~~~
 \forall_{\phi\in\mathcal{H}} \lim_{t\rightarrow 0} \frac{(\phi|U(t)\psi+U(-t)\psi-2\psi)}{t^2}
$$
exist. Does it imply that $\psi$ is in the domain of $A$? Intuitively the first condition guarantees the existence of the weak derivative, and the second one tells us that the norm is continuous. Am I right? Note that for $\psi \in \operatorname{Dom}(A)$ we have
$$
 \forall_{\phi\in\mathcal{H}}\lim_{t\rightarrow 0} \frac{(\phi|U(t)\psi-\psi)}{t}=(\phi|A\psi)
~~~~~~\textrm{and}~~~~~
 \lim_{t\rightarrow 0} \frac{(\psi|U(t)\psi+U(-t)\psi-2\psi)}{t^2}=(A\psi,A\psi).
$$","['weak-convergence', 'operator-theory', 'hilbert-spaces', 'functional-analysis', 'derivatives']"
659409,Diagonalizable properties of triangular matrix,How to show that an upper triangular matrix with identical diagonal entries is diagonalizable iff it is already diagonal?,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
659428,Limit involving $(\cos x)^{1/x^4}$,"I am having trouble calculating the following limit. $$\lim_{x \to 0}(\cos x)^{1/x^4}$$ In Problems in mathematical analysis by Demidovich there is a hint that in case of $1^{\infty}$ indeterminate symbol in certain limit, one can add a term $a(x)$ which for given limit approaches zero and then after manipulation with exponents, it's easy to obtain a result of $e^{p}$, $p \in \mathbb{R}$. My computations in this way lead to the result of $e^{0} = 1$, but WolframAlpha says this limit equals $0$. If anyone could give me at least hints or solution for this problem, I would be very grateful.","['trigonometry', 'limits', 'calculus', 'analysis']"
659431,Showing that a nonnegative integer-valued random variable is NOT a stopping time,"Suppose that $\left(A_n\right)$ is an adapted process, and that $B\in\mathcal{B}$ . Let $L = \sup\left\{n:n\leq10;A_n\in B\right\}$ , $\sup\left(\emptyset\right)=0$ . Convince yourself that $L$ is NOT a stopping time (unless $A$ is freaky). Williams, ""Probability with Martingales"", Ch. 10 ""Martingales"", Example in section 10.8 ""Stopping time"" I can easily come up with a counter-example (e.g. a symmetric random walk), but is it possible to prove that under general conditions it is always the case that $L$ is not a stopping time? If so, how to prove it?","['probability-theory', 'stochastic-processes', 'stopping-times', 'martingales']"
659434,Does the limit $e^{H_{n+1}}$-$e^{H_n}$ exists when $n\to\infty$?,"$$\lim_{n\to\infty}{e^{1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n+1}}-e^{1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}}}$$ I see that it's an indeterminate form ($\infty-\infty$). I tried to factor and I got:
$$\lim_{n\to\infty}{\frac{e^{\frac{2}{n+1}}-1}{e^{\frac{1}{n+1}}+1}\cdot e^{1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}}}$$ Now it's $0\cdot \infty$. How can we approach this type of problem? Thank you!","['calculus', 'real-analysis', 'limits']"
659496,The maximal ideal of a point of a variety is a principal ideal.,"Suppose $X\subset k^n$ is a quasi-affine variety and $p\in X$ is a point in $X$. Denote by $m_p\subset O_p$ the maximal ideal of the local coordinate ring $O_p$ of $p$. Finally, assume the Zariski tangent space at that point is one-dimensional. Why is $m_p$ a principal ideal? Is there a general result towards connecting the dimension of a variety to the dimension of its Zariski tangent space to some point?","['commutative-algebra', 'algebraic-geometry']"
659506,VC dimension for Rotatable Rectangles,"It can be shown that VC dimension of rotatable rectangles is 7 . The problem is I cannot understand how to approach the solution. So far I used bruteforce to solve this kind of problem, I was drawing points in different shapes and check whenever the hypothesis shatters the points. In this case the heptagon is the key. In solution it's mentioned that it's easy to show that 0,1,2,6,7 points can be shattered, except for bruteforce ""drawing"" I don't know any other way to show this. And the case with 3 is considered separately. I would appreciate if someone could explain why case with  0,1,2,6,7 can be shown easily and 3 needs special treating. Is there are any reason why 8 doesn't work here.","['statistics', 'computational-geometry', 'probability', 'machine-learning']"
659545,Radius of convergence of Taylor series of holomorphic function,"I try to prove: If $f$ is analytic on an open disk $B(0, R) \subseteq \mathbb C$ where $R>0$ then the radius of convergence of its Taylor series is $\ge R$. But I stuck with my proof. Please can someone help me? Here is what I have so far: Let $f:B(0,R) \to \mathbb C$ be analytic on $B(0,R)$ and let $T_0(x) = \sum_{n = 0}^\infty c_n z^n$ denote its Taylor series at $0$. The radius of convergence is given by 
$$ r = {1 \over \lim \sup \sqrt[n]{|c_n|}}$$
where 
$$ c_n = {1 \over 2 \pi i} \int_\gamma {f(w) \over w^{n+1}}dw$$
where $\gamma$ is a counterclockwise curve around $0$ and contained in $B(0,R)$. Now how to show $r \ge R$? If $\sqrt[n]{|c_n|} < {1\over R}$ it would be useful but how? Because $f(w)$ can be arbitrary.",['complex-analysis']
659546,What is the correct approach for $\int\frac{x^{4}+1}{x^{6}+1}dx$?,"I was looking for tricky integrals to give something more challenging a try, and I stumbled upon [this] (Ignoring the definite part since I'm just interested in solving the integral): $$\int\frac{x^{4}+1}{x^{6}+1}dx$$ My first reaction was to try substituting $[t=x^{2}; \frac{dx}{dt}=\frac{1}{2\sqrt{t}}]$, and everything went off the rails from there: $$\int\frac{t^2}{t^3+1}\frac{1}{2\sqrt{t}}dt+\int\frac{1}{t^3+1}\frac{1}{2\sqrt{t}}dt$$ after that I tried getting $3t^2$ in the first integral, but it's pointless since it's a product and not an addition. I have also tried integration by parts, but I get things like $-\frac{2}{(2\sqrt{t})^3}$, which make everything way worse than it was before. There are no trigonometric identities involved, and I'm not sure I can apply rational integration since $x^6+1$ doesn't actually have any roots as far as I know. I have also tried other substitutions, like $[t=x^3]$, but I haven't been able to go further with those. I'm totally out of ideas, I've checked all the books I have available for clues or methods I could have missed, but I didn't find a thing. What am I missing? There is obviously an approach I have missed, I really don't think that substitution was the way to go. Any clues about what method to use? (I'm not looking for the solution)","['calculus', 'integration', 'indefinite-integrals']"
659560,Why does this recurrence relation generate a sinusoidal curve?,"I came across the following coupled recurrence relation while watching this
video called Media for Thinking the Unthinkable : $a_{n+1} = a_n - 0.069\cdot b_n$ $b_{n+1} = b_n + 0.069\cdot a_{n+1}$ This (with an initial condition $a_0 = 1$, $b_0 = 10$) seems to generate a sinusoidal curve: A plot of $b_n$ vs. $a_n$ looks like a circle with an approximate radius of 10
units: Is there a general solution to this recurrence relation?","['trigonometry', 'recurrence-relations']"
659579,How prove this $x_{2^n}\ge 2^n-n+1$,"the sequence $ (x_n)_{n\ge 1}$, $ x_n$ being
the exponent of 2 in the decomposition of the numerator of
$$\dfrac{2}{1}+\dfrac{2^2}{2}+\cdots+\dfrac{2^n}{n}$$
 goes to infinity as $ n\to\infty$.
Even more, prove that $$x_{2^n}\ge 2^n-n+1$$ My idea: maybe
$$\dfrac{2}{1}+\dfrac{2^2}{2}+\cdots+\dfrac{2^n}{n}=\dfrac{2^n}{n}\cdot M'?$$
where $M'$ is postive numbers. so we after we replacing $n$ by $2^n$, then
$$\dfrac{2}{1}+\cdots+\dfrac{2^{2^n}}{2^n}=\dfrac{2^{2^n}}{2^n}M''=2^{2^n-n}M''$$
then I can't,Thank you for your help",['number-theory']
659593,Connection between rational functions and matrices,"$$
y = \frac{ax+b}{cx+d} \Longleftrightarrow x = \frac{dy-b}{-cy+a}, ad-bc \ne 0
$$
on the other hand
$$
\left( \begin{array}{cc}
a & b  \\
c & d  \\
 \end{array} \right)^{-1} = \frac{1}{ad-bc}
\left( \begin{array}{cc}
d & -b  \\
-c & a  \\
 \end{array} \right), ad-bc \ne 0
$$
This looks amazing to me. Is there any meaning to this connection between rational functions and matrices? Can it be generalized for matrices of higher ranks?","['matrices', 'rational-functions']"
659601,Diameter of a set.,"Suppose $A$ is a nonempty set in a metric space $(X, d)$. Define $$ \delta(A) = \sup_{x,y \in A} d(x,y) $$ Is it true that if $A \subseteq B$, then $\delta(A) \leq \delta(B) $??","['general-topology', 'calculus', 'real-analysis']"
659606,Why is the set of formal propositions enumerable?,"Thanks for your reading, A set S is recursively enumerable if one can write a program such that, once the program is launched, it will print a list of elements of S and, for all elements s ∈ S , the program will eventually print out the element s . Which of the following are recursively enumerable sets? A. N (where N means nature numbers) B. N×N (where N means nature numbers) C. The power set P(N) of subsets of N. D. The set of formal propositions. E. The set of rational numbers Q . The answer is ""A,B,D,E"" I'm confused about the choice ""D. The set of formal propositions"" Thanks indeed! PS: ""formal propositions"" means ""the proposition made up of specific symbol rather than English words"" (for instance, ョx∈N, x<5) ========== I have already posted this on stack-overflow by my mistake but get some answer: Reference: https://stackoverflow.com/questions/21499731/why-is-the-set-of-formal-propositions-enumerable ""Formal propositions are recursively enumerable only if we assume that we are only interested in the ""writable"" ones (such, which have finite length in terms of symbols from some finite/enumerable vocablurary). In such case we can write the program, which given pair (A,B) writes A'th proposition of length B, and than use our program for writing down NxN to write them down. The existance of the first program is based on assumption that: we use some finite set of symbols to write them down (or at least enumerable); our propositions are finite in terms of length (our program has to be able to print them out)."" ==> If I can do with this technique, why ""C. The power set P(N) of subsets of N."" is not the answer to this question?","['computability', 'elementary-set-theory']"
659610,Definite integral involving trigonometric functions and absolute values,"Solve the following integral: 
$$
\int_{0}^{4\pi}\frac{x|\sin x|dx}{1 + |\cos x|}
$$ I tried variable substitution, but nothing seemed to work. Could you give me some clues?","['definite-integrals', 'trigonometry', 'calculus']"
659613,Existence of holomorphic function under conditions,"I have to answer this question: Is there a holomorphic function $f:\Omega =\{z\in \mathbb{C} \mid |z|<2\} \rightarrow \mathbb{C}$ such that For all  $n \in \mathbb{N}\backslash\{0\}: f\left(\frac1n\right)=e^{-n}$ For all  $n \in \mathbb{N}\backslash\{0\}: f\left(\frac1n\right)=\sin(\frac{\pi n}{2})$ My first try: If $f(z):= e^{-\frac1z} \, \Rightarrow \forall \ n:  f\left(\frac1n\right) = e^{-\frac{1}{1/n}} = e^{-n}$ but $f$ has an essential singularity at $z=0$ hence is not holomorphic in $\Omega$ If $f(z):= \sin \frac{\pi}{2z} \, \Rightarrow \forall \ n:  f\left(\frac1n\right) = \sin \frac{\pi}{2\frac{1}{n}} = \sin \frac{\pi n}{2}$ but $f$ has an essential singularity at $z=0$ hence is not holomorphic in $\Omega$ My second try: $f(z):= \sum_{l=0}^{\infty} a_l z^l$ The condition is 
$f\left(\frac1n\right)= \sum_{l=0}^{\infty} a_l \left(\frac1n\right)^l \overset{!}{=} \sum_{l=0}^{\infty} \frac{(-n)^l}{l!} = e^{-n}$ which gives my the following: $$f(z) = \sum_{l=0}^{\infty}\frac{(-1)^l z^{-l}}{l!}$$
Such a function has an essential singularity in 0 hence is not holomorphic in $\Omega$ The condition is 
$$f\left(\frac1n\right)= \sum_{l=0}^{\infty} a_l \left(\frac1n\right)^l \overset{!}{=} \sum_{l=0}^{\infty} \frac{(-1)^l\left(\frac{\pi n}{2}\right)^{2l+1}}{(2l+1)!} = \sin \frac{\pi n}{2}$$ which gives my the following: $$f(z) = \sum_{l=0}^{\infty}\frac{(-1)^l \left(\frac{\pi}{2}\right)^{2l+1}}{(2l+1)!}z^{-(2l+1)}$$
Such a function has an essential singularity in 0 hence is not holomorphic in $\Omega$ Please check my answer because I really think I'm missing something","['proof-verification', 'complex-analysis']"
659655,An exercise in complex analysis,"Consider the following question: Let $f: \mathbb C \rightarrow \mathbb C$ be a function such that it's real and imaginary part is differentiable at $z = 0$ in the sense of $\mathbb R^2$, assume further 
$$
      L =   \lim_{z \rightarrow 0} \biggr| \frac{  f(z)  }{  z  } \biggr|
$$
exists. Prove that either $f(z)$ or $\overline{f(z)}$ is holomorphic at $z = 0$. I am asking is there a better solution rather then the following brutal force one I will present. Since $u_x, u_y, v_x, v_y$ exists, we know $f(z) = u(x, y) + i v(x, y)$ is a continuous function. So
$$
	|f(0) | = \lim_{z \rightarrow 0 } | f(z) | = \lim_{z \rightarrow 0} |z | \biggr| \frac{ f(z ) }{ z } \biggr| = \lim_{z \rightarrow 0} | z | \cdot \lim_{z \rightarrow 0} \biggr| \frac{ f(z) }{ z } \biggr| = 0 \cdot L = 0
$$
So, $f(0) = 0 \Longrightarrow u(0, 0) = v(0 , 0) = 0$. We split the case for $L = 0$ and $L \ne 0$. If $L = 0$, we have
$$
	\lim_{z \rightarrow 0} \biggr| \frac{ f(z + 0) - f(0) }{z} - 0  \biggr|  = \lim_{z \rightarrow 0} \biggr| \frac{ f(z) }{ z } \biggr| = 0 \Longrightarrow \lim_{z \rightarrow 0} \frac{ f(z + 0) - f(0) }{z } = 0 
$$
In this case $f$ is holomorphic at $z = 0$ and $f'(0) = 0$. Now, assume $L \ne 0$, from the assumption, we know $u, v: \mathbb R^2 \rightarrow \mathbb R$ are differentiable function at $(x, y) = (0, 0)$ in the $\mathbb R^2$ sense. So $f(z) = f(x, y) = (u(x, y), v(x, y))$ when viewed as function from $\mathbb R^2$ to itself is also differentiable at the origin. From definition, there exists a linear map $A: \mathbb R^2 \rightarrow \mathbb R^2$ such that for $h \in \mathbb R^2$ sufficiently close to $(0, 0)$ we have
$$
	f(h) = f(0) + A \cdot h + \epsilon(h) \text{ where } \lim_{h \rightarrow 0} \frac{ | \epsilon( h) | }{ | h| } = 0 \tag{$\ast$}
$$
It follows from $(\ast)$ that 
$$
	\frac{ | f(h) | }{ | h| } = \frac{ | A \cdot h + \epsilon (h) | }{ | h| }
$$
By triangle inequality, 
$$
	\biggr| \frac{ | A \cdot h | }{ | h | } - \frac{ | \epsilon (h) | }{ | h| } \biggr| \leq \frac{ | f(h) | }{ | h | } \leq \frac{ | A \cdot h | }{ | h | } + \frac{ | \epsilon(h) | }{ | h| }
$$
Take limit as $h$ approach to the origin on both sides of above inequality, we have
$$
	\biggr| \lim_{h \rightarrow 0 }  \frac{ | A \cdot h | }{ | h | } - \lim_{h \rightarrow 0 } \frac{ | \epsilon (h) | }{ | h| } \biggr| \leq L \leq \lim_{h \rightarrow 0 } \frac{ | A \cdot h | }{ | h | } + \lim_{h \rightarrow 0 } \frac{ | \epsilon (h) | }{ | h | }
$$
because $\lim_{z \rightarrow 0 } | f(z) | / | z | = L$ from assumption. Next, we put $\lim_{h \rightarrow 0 } | \epsilon (h) | / | h | = 0$ obtained in $(\ast)$ to above inequality 
$$
	\biggr| \lim_{h \rightarrow 0 }  \frac{ | A \cdot h | }{ | h | } - 0 \biggr| \leq L \leq \lim_{h \rightarrow 0 } \frac{ | A \cdot h | }{ | h | } + 0 \Longrightarrow \lim_{h \rightarrow 0} \frac{ | Ah | }{ | h | } = L \in \mathbb R_+
$$
So $| A h | / | h | \rightarrow L \in \mathbb R_+$ for any vector which approaches to the origin from any direction. Let 
$$
	A = 
	\begin{pmatrix}
		a & b \\
		c & d
	\end{pmatrix}
	\text{ where } a, b, c, d \in \mathbb R
$$
Take $h = (-tb, ta) \in \mathbb R^2$. By calculation, $A h = (0, (ad -bc)t )$, it follows that $| h| = \sqrt{a^2 + b^2} |t |, | Ah | = | ad - bc | \cdot |t |$, 
$$
	\lim_{h \rightarrow 0} \frac{ | Ah | }{ | h | } = \lim_{t \rightarrow 0} \frac{ | (ad - bc) t | }{ \sqrt{a^2 + b^2} |t | } =  \frac{ | ad - bc | }{\sqrt{a^2 + b^2} }
$$
Since $L \ne 0$, we have $L = | ad - bc | / \sqrt{a^2 + b^2}  = \det A / \sqrt{a^2 + b^2} \ne 0 \Rightarrow | \det A | \ne 0 \Longrightarrow A$ is invertible. Now, take $h = (t, 0)$ then $Ah = (at, ct), | h | = | t |, | Ah | = \sqrt{a^2 + c^2} | t |$, it follows that
$$
	L = \lim_{h \rightarrow 0 } \frac{ |A h | }{ | h | } = \lim_{t \rightarrow 0} \frac{ \sqrt{a^2 + c^2 } | t | }{ | t | } = \sqrt{a^2 + c^2}
$$
Similarly, direct calculation can show
$$
	L = 
	\begin{cases}
		\sqrt{b^2 + d^2 }							&\text{ when we take $h = (0, t)$} \\
		\sqrt{ (a + b)^2 + (c + d)^2 } / \sqrt{2}				&\text{ when we take $h = (t, t)$} \\
		\sqrt{ (a - b)^2 + (c - d)^2 }  / \sqrt{2}				&\text{ when we take $h = (t, -t)$} 		
	\end{cases}
$$
Observe 
$$
	\frac{ \sqrt{(a + b)^2 + (c + d)^2 } }{ \sqrt{2} } = \frac{ \sqrt{ (a - b)^2 + (c - d )^2 }}{ \sqrt{2} } \Longrightarrow ab + cd = 0 \tag{7.1}
$$
Since $L^2 = a^2 + c^2 = b^2 + d^2$, we deduce $a^2 - b^2 = d^2 - c^2$, square both sides we have
$$
	(a^2 - b^2)^2 = (d^2 - c^2)^2 \iff a^4 + b^4 - 2a^2b^2 = c^4 + d^4 - 2c^2d^2
$$
It follows from above that $a^4 + b^4 = c^4 + d^4$ for $ab + cd = 0 \rightarrow ab = -cd \rightarrow a^2b^2 = c^2d^2$. So
$$
	a^4 + b^4 = c^4 + d^4 \Longrightarrow a^4 - c^4 = d^4 - b^4 \Longrightarrow (a^2 + c^2)(a^2 - c^2) = (d^2 + b^2)(d^2 - b^2)
$$
Because $L^2 = a^2 + c^2 = b^2 + d^2 > 0$, $(a^2 + c^2)(a^2 - c^2) = (d^2 + b^2)(d^2 - b^2) \rightarrow L^2(a^2 - c^2) = L^2(d^2 - b^2) \rightarrow a^2 - c^2 = d^2 - b^2$. Together with $a^2 + c^2 = b^2 + d^2$, we get
$$
	a^2 = \frac{a^2 + c^2 }{2} + \frac{a^2 - c^2}{2} = \frac{b^2 + d^2}{2} + \frac{d^2 - b^2}{2} = d^2, c^2 = b^2 + d^2 - a^2 = b^2
$$
So, $d = \pm a, b = \pm c$. Hence we have to consider the following four cases
$$
	(1) \, d = a, b = c; (2)\, d = -a, b = c; (3)\, d = a, b = -c; (4) \, d= -a, b = -c \tag{7.2}
$$
Recall if $f(z)$ or $\overline{f(z)}$ is holomorphic at $z = 0$, then the Jacobian matrix of $f(z) $ and $\overline{ f(z) }$ 
$$
	J(f(z) ) = 
	\begin{pmatrix}
		u_x & u_y \\
		v_x & v_y 
	\end{pmatrix} \;
	J (\overline{f(z) } ) = 
	\begin{pmatrix}
		u_x & -u_y \\
		v_x & -v_y 
	\end{pmatrix}
	\text{ is of the form}
	\begin{pmatrix}
	 	p & -q \\
		q & p
	\end{pmatrix}
	\tag{$\ast \ast$}
$$
We want to show in any of the cases from $(7.2)$, the linear map $A$ when treated as the Jacobian for $f(z)$ or $\overline{f(z) }$ satisfies condition $(\ast \ast)$. That is either $a = d, c = -b$ or $a = -d, c = b$. For the first case, since $ab + cd = 2ac = 0 \Rightarrow a =0$ or $c = 0$. Since $\det A = a^2 - c^2 \ne 0$, if $a = 0$ then $c \ne 0 \Rightarrow a = 0 = -d, b = c$. If $c = 0$ then $a \ne 0 \Rightarrow a = d, c = 0 = -b$ both satisfies $(\ast \ast)$. For the second case, $d = -a \iff a = -d$ together with $c = b$ they automatically satisfies condition $(\ast)$. For the third case, same result follows because $b = -c \iff c = -b$. Last but not least, for $d = -a, b = -c$, we deduce $ab + cd = a(-c) + c(-a) = -2ac = 0 \Rightarrow ac = 0 \Rightarrow a = 0$ or $c = 0$. Since $\det A = ad - bc = a(-a) - (-c)c = c^2 - a^2 \ne 0$, in this case we have either $a = 0, c \ne 0$ or $a \ne 0, c =0$. If $a = 0, c \ne 0$, $a = 0 = d, b = -c$. If $c = 0, a \ne 0$, $a = -d, c = 0 = b$ both also satisfy condition $(\ast \ast)$. Hence, we have checked all possible cases for $A$ which implies either $f(z)$ or $\overline{f(z) }$ satisfies Cauchy-Riemann conditions at $z = 0$. Therefore either $f(z)$ or $\overline{f(z) }$ is holomorphic at $z = 0$.",['complex-analysis']
659656,"Let $f:[a,b]\rightarrow \mathbb{R} $ be differentiable with $f'(a) = f'(b)$. There exist a $c\in(a,b)$ such that $f'(c) = \frac{f(c) - f(a) }{c -a}$.","Can someone help me with the following problem? Let $f:[a,b]\rightarrow \mathbb{R} $ be differentiable and suppose that $f'(a) = f'(b)$. Show that there exist a $c\in(a,b)$ such that $f'(c) = \frac{f(c) - f(a) }{c -a}$. My idea is to take first the case $f'(a) = f'(b) = 0$. In this case, consider 
$$\phi(x) = \frac{f(x)-f(a)}{x-a}, \quad \forall x \in (a,b],$$
and $\phi(a) = 0$. Is obvious that $\phi$ is continuous in $(a,b]$. While in $a$, the continuity of $\phi(a)$ follows from the fact $$\lim_{x\to a^{+}} \phi(x) = f'(a) = 0 = \phi(a).$$ Therefore, $\phi$ is continuous in $[a,b]$. So, $\phi$ attains its maximum and its minimum in $[a,b]$. If one of them is in $(a,b)$, let $c$ be this point. So, since $\phi$ is differentiable in $(a,b)$, I know that we must have $\phi'(c) = 0$. But
$$\phi'(x) = \frac{f'(x)}{x-a} - \frac{f(x)-f(a)}{(x-a)^2}.$$
So
$$\phi'(c) = 0 \Rightarrow f'(c) = \frac{f(c) - f(a) }{c -a}.$$ The problem is that I can't ensure that a point of maximum or minimum must be in $(a,b)$. Note that, once I solve this case ($f'(a) = 0$), the general case is solved just considering $g(x) = f(x) - f'(a) x$. Because $g'(a) = g'(b) = 0$. And then if there exists a $c\in(a,b)$ with 
$$ g'(c) = \frac{g(c)-g(a)}{c-a},$$
then
$$f'(c) - f'(a) = \frac{f(c) - f'(a)c -f(a) + f'(a)a}{c-a} = \frac{f(c) -f(a)}{c-a} - f'(a).$$
Therefore,
$$f'(c) = \frac{f(c) - f(a) }{c -a}.$$","['calculus', 'real-analysis']"
659664,Proof of Schur's lemma,Can someone give me a simplified proof of Schur's lemma in group theory. Sorry if the question looks a standard textbook proof. But I find the proof complicated in books. It would be helpful if someone can provide a link that proves Schur's lemma in a simpler way.,"['representation-theory', 'group-theory']"
659668,Megaminx parity,"I have an old 12-colored Megaminx that I put all new stickers on because the old ones were falling off. This Megaminx was in more of a state of disrepair than I originally thought, though, and when I was solving it 2 of the pieces (1 edge and 1 corner) popped out and fell on the floor. I wasn't paying attention to those particular pieces, so I had no idea which way they were facing when they popped out. I plugged them back into the puzzle. I had no idea if they had the correct orientation or not though. Surprisingly, I was still able to complete the puzzle without disassembling it. I know that a Rubik's Cube has parity ; only $\frac{1}{12}$ of the ways to assemble its cubelets results in solvable cubes. My intuition tells me that the Megaminx obeys the same parity rules (when I first got my Megaminx back in high school I was able to solve it using only the algorithms that come with a Rubik's Cube, with a few minor tweaks); however, I lack the mathematics background to verify this. My question: If I were to completely disassemble a Megaminx and reassemble it at random, what are the odds that the resulting state would be solvable?","['recreational-mathematics', 'group-theory', 'algorithms']"
659699,An example of almost periodic function,""" I need a continuous almost periodic function $f(x)$ such that $\lim_{x\to\infty}f(x)$ exists. But this function should not be constant, which is a trivial example ."" Definition of almost periodic function: http://mathworld.wolfram.com/AlmostPeriodicFunction.html We take the standard metric on $\mathbb{R}$ , i.e., $d(x,y)=|x-y|$ . Examples of almost periodic functions: (but $\lim_{t\to\infty}f(t)$ does not exist) $$f(t)=\frac{\cos t}{2+\cos\sqrt2t}\ ,\quad f(t)=\sin2\pi t+ \sin2\pi t\sqrt2 ~.$$ On the other hand, page 69, paragraph 4 of the article http://projecteuclid.org/download/pdf_1/euclid.pjm/1102812425 says the following: ""Once Bohr established his fundamental theorem, he was able to
show that any continuous almost periodic function is the limit of a
uniformly convergent sequence of trigonometric polynomials. This is
the main result of his second paper. The converse of this result was also true."" Since we know that for every non-constant periodic function $g(x)$ (or trigonometric function), $g(x)$ does not exist as $x$ tends to infinity, can we conclude (from uniform convergence) that almost periodic functions also have the same property? Thanks your help.","['analysis', 'special-functions', 'almost-periodic-functions', 'limits']"
659712,Derivative on Hilbert space,"Please, on a Hilbert space what is the  derivative of  $\displaystyle\frac{x}{||x||}$ ? I know that it's equal to $\displaystyle \frac{1}{||x||}-\frac{\langle x,\cdot\rangle}{||x||^3} x$ but can I write it as $\displaystyle\frac{1}{||x||}-\frac{\langle x,x\rangle}{||x||^3}$? thank you","['hilbert-spaces', 'derivatives']"
659739,"Rationalize the denominator of the surd, giving your answer in the simplest form.","Rationalize the denominator of the surd, giving your answer in the simplest form. $\frac {3}{\sqrt2+5} $ Please help me... It must be like this right? $\frac {3}{\sqrt2+5} * \frac{\sqrt2-5}{\sqrt2-5}$",['algebra-precalculus']
659757,Quadric surface as a $\mathbb{F}_n$ surface,"The minimal models for rational projective smooth surfaces are $\mathbb{P}^2$ or the surfaces $\mathbb{F}_n$ for $n\neq 1$, where
$$\mathbb{F_n}=\mathbb{P}_{\mathbb{P}^1}(\mathcal{O}_{\mathbb{P}^1}\oplus\mathcal{O}_{\mathbb{P}^1}(n)).$$
The right member of the equality is the projective bundle associated to the rank 2 vector bundle $\mathcal{O}_{\mathbb{P}^1}\oplus\mathcal{O}_{\mathbb{P}^1}(n)$ on $\mathbb{P}^1$. The smooth quadric $\mathit{Q}\subset\mathbb{P}^3$ is a rational minimal surface since it does not contain exceptional curves. My question is: am i right if i say that $\mathit{Q}\cong\mathbb{F}_0$ (birationally isomorphic)?","['minimal-surfaces', 'algebraic-geometry', 'quadrics', 'surfaces']"
659805,"Integral $\int_{C(0,3/2)} \frac{z^3}{1-\cos(\pi iz^2)}\,dz$ using residue theorem.","I'm stuck with this exam problem. It says : Resolve the following integral $$\int_{C(0,3/2)} \frac{z^3}{1-\cos(\pi iz^2)}\,dz$$ Through the circumference $C(0,3/2)$ I asume we have to use the residue theorem. The poles are the $z=\sqrt{2ki}$ for any integer $k$. The ones that matters,i.e. the $z_j$ with $\operatorname{ind}\left(z_j\right)=1$ are these: 
$$z_1=0,z_2=1+i,z_3=1-i,z_4=-1+i,z_5=-1-i$$
Thank you",['complex-analysis']
659827,Chebychev to get at least 90 %,"Im am given a list of integers and asked to give the interval that contains at least 90 % of my values. Values : 
$62,56,72,83,66,77,62,71,50,58,
74,81,76,67,70,70,69,67,80,81,
74,53,73,55,66,88,73,61,63,70,
72,63,75,68,78,75,61,69,80,82,
87,57,74,74,85,68,75,63,81,73$ At First, I found the following values : $ avg = 70.56 $ $ variance = 80.55 $ $ standard deviation = 8.97 $ Now the part I am not sure.
Chebychev inequality is $1 - \frac{1}{k^2}$ k * std var. being how far from the mean  the numbers are. I figured that with a k of 4, i get $15/16$ which is about $93 %$ Is that ok or do I have to figure out some fraction of k to get exactly 90 % that is asked ? How do I figure out precisely that fraction ? Using a k of 4, I multiplied my std var by 4, and that gives me a minimum of 34.68 and maximum of 106.44 Looking at my numbers, the min and max seems a bit off... So for now, my answer is : the interval is $[34.68,106.44]$ covers at least 93.75 %","['statistics', 'standard-deviation']"
659830,Equality of stalks implies equality on a neighborhood,"Let $X$ be a scheme, $Z$ be a closed subscheme of $X$ and $z$ be a point of $Z$. In the following notes : http://web.mit.edu/~holden1/www/coursework/math/18.787/main.pdf , page 43, claim 6.3 I believe that it is said that to show that $z$ is contained in a open subset of $X$ contained in $Z$ it is enough to show that $\mathscr{O}_{X,z} \cong \mathscr{O}_{Z,z}$. Is that true and if so why ? Or maybe did I not understand the notes correctly ? In that case what does he mean ?",['algebraic-geometry']
659843,"Analytic function $f$ in $\overline{\mathbb{D}}$ satisfying $\left\lvert\,f'(\tfrac{1}{2})\,\right \rvert\leq 8.$","Let $f$ be an analytic function on the closed unit disk $\overline{\mathbb{D}}$.
On its boundary $\partial \mathbb{D}$ it holds that $\lvert\,f(z) -z\rvert < \lvert z\rvert$. I now have to show that 
$$
\left\lvert\,\, f'\left(\frac{1}{2}\right)\right\rvert \leq 8.
$$ I already figured out, that there cannot be a $\,z_0 \in \partial \mathbb{D}$, such that $\,f(z_0) =0,\,$ since that would mean that $\lvert 0-z_0\rvert < \lvert z_0\rvert\,$ 
which produces a contradiction, since the inequality is strict. I also know, that $f$ takes its maximum on $\partial \mathbb{D}$ according to the maximum modulus principle. My assumption is that i should get $\,\lvert\,f'(z)\rvert < \lvert z^{-3}\rvert\,$ by looking at the numbers, which seem a bit random to me. But now I'm stuck. Any help would be greatly appreciated!","['complex-integration', 'analyticity', 'complex-analysis', 'analysis']"
659847,"What is the slope of the tangent at $(0,0)$ on the curve $x^2 y^2 = 4 x^5 + y^3$","This question is arising from the answer to another one: How find this equation integer solution: $x^2y^2=4x^5+y^3$ .
For $x < 27$ and $y > -243$ , the basic equation $x^2 y^2 = 4 x^5 + y^3$ is a function.
By implicit differentiation we have found that:
$$
y'(x) = \frac{20 x^4 - 2 x y^2}{2 y x^2 - 3 y^2} \quad \Longrightarrow \quad y'(0) = \; ?
$$
From the picture it is suspected that: $y'(0) = 0$ , i.e. the slope of the tangent in $(x,y) = (0,0)$ may be zero. But I could not prove or disprove it. Any ideas? Update. When solving for $y$ (with help of MAPLE) we find something that looks like
a decent function, within a prescribed range e.g. $-1 < x < +2$ ; see picture.
(Bonus: integer solutions original question at red spots)
$$
y(x) = \left[\frac{\left(-54 x^2 + x^3 + 6 \sqrt{81 x^4 - 3 x^5}\right)^{1/3}}{3}
     + \frac{x^2}{3\left(-54 x^2 + x^3 + 6 \sqrt{81 x^4 - 3 x^5}\right)^{1/3}} 
     + \frac{x}{3}\right] x
$$
So it's still not clear to me why the derivative $y'(0)$ would be somehow undefined. A rather extreme close-up , namely $-1/10 < x < 1/10$ : picture on the right , doesn't reveal any other slope than zero at $(0,0)$ . Whiter means that the function $f(x,y) = 4 x^5 + y^3 - x^2 y^2\;$ is closer to zero; it is seen that $\;f(x,y)\;$ is very close to zero indeed in the neighborhood of $(0,0)$ , thus suggesting that the tangent may be ambiguous there. But is it? My try. Draw a circle with radius $r > 0$ and $(0,0)$ as its midpoint:
$$ x = r \cos(\phi) \qquad y = r \sin(\phi) $$ 
Substitute this into the basic equation $\;x^2 y ^2 = 4 x^5 + y^3\;$ and divide by $r^3$ :
$$
   4 \cos^5(\phi)\, r^2 - \cos^2(\phi) \sin^2(\phi)\, r + \sin^3(\phi) = 0
$$
If $\;r \rightarrow 0\;$ i.e. becomes very small, then function values in the neighborhood of $\;(0,0)\;$ only depend on the last term $\;\sin^3(\phi)$ . Meaning that $\phi \approx 0$ or $\phi \approx \pi$ . The tangent through these two points has slope zero. Don't know if this counts as a proof.","['implicit-differentiation', 'plane-curves', 'limits']"
659853,"Localization of $R = k[X,Y]/(Y^2 - X^2 + X)$ is a DVR","Let $R = k[X,Y]/(Y^2 - X^2 + X)$ where $k$ is a field (say of characteristic different from 2 and 3) and $m = (X,Y)$ an ideal. Show that the localization of $R$ at $m$ , $R_m$ is a discrete valuation ring. I can show that $R_m$ is a local Noetherian ring of dimension 1. So it also suffices to show that $R_m$ is a PID (equivalently, the unique maximal ideal is principal), normal, or regular. Any ideas on how to proceed from here is greatly appreciated.","['commutative-algebra', 'algebraic-geometry']"
659854,Prove limit of n-th root,"This is the one: $$\lim\limits_{n\to \infty}\sqrt[n]{n} = 1$$ With $\varepsilon > 0$ the Archimedean Property of Reals yields an $n_0 \in \mathbb{N}$ with $$n_0 > 1 + \dfrac{2}{\varepsilon^2}$$ (I really don't get how the Archimedean Property yields this. I know it as ""for each $a,b$ of $\mathbb{R}$ there is an $n$ such that $na>b$ "". Simple. But how does it yield the above?) Then we have $n \in \mathbb{N}$ with $n \ge n_0$ and especially $ \ge 2$ . The Binomial theorem yields: $$\begin{align*}n = \left(\sqrt[n]{n}\right)^n = (1 + (\sqrt[n]{n} -1))^n &= \sum\limits_{k =0}^n {n \choose k} (\sqrt[n]{n}-1)^k  \\&\ge {n \choose 2}(\sqrt[n]{n}-1)^2 \\&= \dfrac{n(n-1)}{2}\cdot \left(\sqrt[n]{n}-1\right)^2
\end{align*}$$ Hence: $$(\sqrt[n]{n}-1)^2 \le \dfrac{2}{n-1} \quad \text{ and }\quad 0 < \sqrt[n]{n}-1\le \sqrt{\dfrac{2}{n-1}}\le \sqrt{\dfrac{2}{n_0-1}}< \sqrt{\varepsilon^2}=\varepsilon$$ I'm confused. How does this result from the step before? And finally $$\vert\sqrt[n]{n}-1\vert = \sqrt[n]{n}-1 < \varepsilon.$$ which is supposed to prove the limit. Again, I don't get how it is derived.",['sequences-and-series']
659855,"Prove that the average of $D_wD_wf(x_0,y_0)$ over all unit vectors $w$ is equal to $\frac{1}{2} \Delta f(x_0,y_0)$ for any smooth function $f$.","Here is a challenge problem from my math professor: Let $w$ be a unit vector in $\mathbb{R}^2$, and let $D_w$ denote the directional derivative with respect to $w$.  Prove that for any smooth function $f$ on $\mathbb{R}^2$ and any point $(x_0, y_0) \in \mathbb{R}^2$, the average of $D_w D_w f(x_0, y_0)$ over all unit vectors $w$ is equal to $\frac{1}{2}\Delta f(x_0, y_0)$.  This fact (which generalizes to higher dimensions) helps to explain why the Laplacian $\Delta$ is a ""natural"" differential operator that appears in many important PDEs. My Attempt Assuming that $f$ is any smooth function, we see that their partial derivatives exist.  For my workout, I set the unit vector to be $w = (a,b)$.  I tried to prove this statement via computation as follows: For the left-hand side... $$\begin{aligned}
D_wD_w f(x,y) &= D_w((a,b) \cdot (f_x, f_y))\\
&= D_w(af_x + bf_y)\\
&= (a,b) \cdot (af_{xx} + bf_{yx}, af_{xy} + bf_{yy})\\
&= a^2f_{xx} + 2abf_{xy} + b^2f_{yy}\\
&= a^2f_{xx} + b^2f_{yy}
\end{aligned}$$ For the right-hand side... $$\begin{aligned}
\dfrac{1}{2}\Delta f(x,y) = \dfrac{1}{2}(f_{xx} + f_{yy})
\end{aligned}$$ So at the point $(x_0, y_0) \in \mathbb{R}^2$, $$\begin{aligned}
D_wD_w f(x_0,y_0) &= a^2f_{xx}(x_0, y_0) + b^2f_{yy}(x_0, y_0)\\
\dfrac{1}{2}\Delta f(x_0,y_0) &= \dfrac{1}{2}(f_{xx}(x_0, y_0) + f_{yy}(x_0, y_0))
\end{aligned}$$ I'm stuck here since I am not sure how to approach this problem because of ""average of directional derivatives over the unit vectors"". Any advices or suggestions?","['partial-derivative', 'ordinary-differential-equations', 'derivatives', 'partial-differential-equations']"
659862,Remainder of Taylor series,The Taylor series of the function $$f(x) = \int_{1}^{\sqrt{x}} \ln(xy)+ y^{3x} dy + e^{2x}$$ at the point $x = 1$ is $$e^2 + (x-1)\left(2e^2+\frac{1}{2}\right) + \frac{(x-1)^2}{2}\left(4e^2+\frac{7}{4}\right)$$ which I calculated using the Leibniz rule. How can I estimate the remainder term of second order for f(2) ? (The second derivate is already very complicated). Is there a method to calculate higher derivatives of parameter integrals easier than simply applying the Leibniz rule repeatedly?,"['taylor-expansion', 'analysis']"
659928,Matrix Multiplication: only one solution?,"Let $A=\begin{bmatrix}6 & 5\\-7 & 9\end{bmatrix}$ and $C=\begin{bmatrix}1 & -2\\4 & -8\end{bmatrix}$ .  Find all matrices $B$ such that $AC=BC$ . $\begin{bmatrix}6&5\\-7&9\end{bmatrix} \times \begin{bmatrix}1&-2\\4&-8\end{bmatrix}$ $= \begin{bmatrix}6 \times 1 + 5 \times 4 & 6 \times (-2) + 5 \times (-8) \\ (-7) \times 1 + 9 \times 4 & (-7) \times (-2) + 9 \times (-8)\end{bmatrix}$ $= \begin{bmatrix}26 & -52 \\ 29 & -58\end{bmatrix}$ $\begin{bmatrix}6&5\\-7&9\end{bmatrix} \times \begin{bmatrix}b_1&b_2\\b_3&b_4\end{bmatrix} = \begin{bmatrix}26 & -52 \\ 29 & -58\end{bmatrix}$ $\begin{bmatrix}6b_1 + 5b_3 & 6b_2 + 5b_4 \\ -7b_1 + 9b_3 & -7b_2 + 9b_4 \end{bmatrix} = \begin{bmatrix}26 & -52 \\ 29 & -58\end{bmatrix}$ Equations: $6b_1 + 5b_3 = 26$ $-7b_1 + 9b_3 = 29$ Eliminate $b_1$ : $42b_1 + 35b_3 = 182$ $-42b_1 + 54b_3 = 174\implies 89b_3 = 356 \implies b_3 = 4$ $6b_1 + 20 = 26 \implies b_1 = 1$ $6b_2 + 5b_4 = -52$ $-7b_2 + 9b_4 = -58$ Eliminate $b_2$ : $42b_2 + 35b_4 = -364$ $-42b_2 + 54b_4 = -348\implies89b_4 = -712 \implies b_4 = -8$ $6b_2 + 5(-8) = -52 \implies b_2 = -2$ Therefore, is it true that the only solution is when $A = B$ ? Or am I missing something? EDIT: Cameron Williams You mentioned this, but it is not without problems. $\begin{bmatrix}1&-2\\4&-8\end{bmatrix} \times \begin{bmatrix}b_1&b_2\\b_3&b_4\end{bmatrix} = \begin{bmatrix}26&-52\\29&-58\end{bmatrix}$ $\begin{bmatrix}b_1-2b_3 & b_2 - 2b_4 \\ 4b_1 - 8b_3 & 4b_2 - 8b_4\end{bmatrix} = \begin{bmatrix}26&-52\\29&-58\end{bmatrix}$ New equations: $b_1 - 2b_3 = 26$ $4b_1 - 8b_3 = 29$ Eliminate $b_1$ and $b_3$ and make an invalid equation: $(4b_1 - 8b_3) - 4(b_1 - 2b_3) = 29 - 104$ $0 = -75$ What does this mean? I do not think I need to use the other 2 equations, but I do not understand what this invalid equality is supposed to mean.",['matrices']
659944,"Prove that if $\phi'(x) = \phi(x)$ and $\phi(0)=0$, then $\phi(x)\equiv 0$. Use this to prove the identity $e^{a+b} = e^a e^b$.",I am given the following. hint Consider $f(x)=e^{-x} \phi(x)$. I am unsure how to approach this problem.,"['ordinary-differential-equations', 'exponential-function', 'real-analysis', 'analysis']"
659949,Finding the roots of $x^3 - 93x - 308$ extremely quickly?,"I was at a quiz bowl competition and one of the questions was to find the roots of this polynomial. In one or two seconds after reading the question, somebody on the other team buzzed and got the right answer $(-4, -7, 11)$. How is this possible? What did he use to get the answer? This is a high school competition. One way I suppose he could've done it is to realize that, since there is no $x^2$ term, the sum of the roots is 0, then find three integers $a, b, c$ such that $abc = 308$, but doing all of that in  1 or 2 seconds? is that possible? Okay, so from the comments I see that it was just some really fast mental math, not some kind of advanced formula that I'm not aware of. Thanks for the help!","['algebra-precalculus', 'polynomials']"
659957,Working out the overall download speed of two sessions with different speeds,"I would like to confirm that what I have done with this basic problem is fine. It says: 540 GB are downloaded during a forenoon at 1900 MB/min. In the afternoon, the same amount of data took twice the time. What was the average data download during the whole day? My solution: Forenoon -> 1900 MB/min -> (540*1024)/1900 ≈ 291 min Afternoon -> 800 MB/min -> 291 * 2 = 582 min 540 GB = 552960 MB Average speed: 552960/(291+582) ≈ 633.40 MB/min Did I miss something?","['algebra-precalculus', 'solution-verification']"
659958,Find the differential of an n-variable function,"The problem goes like this: If $f:\mathbb{R}^n\to\mathbb{R}, f(x)=\arctan||x||^4$, prove that $Df(x)(x)=\displaystyle\frac{4||x||^4}{1+||x||^8}$ Now, I've calculated each of the partial differentials (if that's the right word) and applied that $1\times n$ matrix to a vector $(x_1, ... ,x_n)$ and I get this: $4(\displaystyle\frac{x_1^4}{1+x_1^8}+...+\frac{x_n^4}{1+x_n^8})$ Now, the similarity between those terms and the final solution is obvious but I just can't seem to get the sum to become the above. Am I going about this the wrong way or am I just missing something? ($||\cdot||$ is the Euclidian norm)",['multivariable-calculus']
659988,Example of $\sigma$-algebra,"I understood the definition of a $\sigma$-algebra, that its elements are closed under complementation and countable union, but as I am not very good at maths, I could not visualize  or understand the intuition behind the meaning of ""closed under complementation and countable union"". If we consider the set X to be a finite set, then what would be a good real life example of a $\sigma$-algebra, for a noob to understand.","['measure-theory', 'elementary-set-theory']"
660016,Ideal of the fiber of the thickening of a point,"Let $\phi : A \to B$ be a morphism of rings and let $f : X \to S$ be the corresponding morphism of schemes. let $\mathfrak{q}$ be a prime ideal of $A$ corresponding to a point $s$ of $S$. Let $T = Spec(\mathscr{O}_{S,s}/\mathfrak{m}_s^n)$ be a thickening of $s$ (we have a natural morphism $T \to S$). I would like to understand $f^{-1}(T) = X \times_S T$ in terms of commutative algebra. In this mathoverflow answer ( https://mathoverflow.net/questions/86048/verifying-claims-in-the-proof-of-the-rigidity-lemma-mumford-git ) they say that $f^{-1}(t)$ corresponds to the ideal $Q = \phi(\mathfrak{q})B$ of $B$ and I think they say that $f^{-1}(T)$ corresponds to $Q^n$ but i'm not to sure how to see this (and I feel they probably use some hypothesis on f).",['algebraic-geometry']
660032,Proof of Dickson's Lemma,"One form of Dickson's Lemma states: For every infinite set of $n$-tuples of natural numbers, there exist two tuples $(a_1,\ldots,a_n),(b_1,\ldots,b_n)$ such that $a_i\leq b_i$ for all $i$. I've tried to prove it by induction on $n$. The case $n=1$ is clear. Assume the result for $n-1$. Suppose there exists $x$ such that the $n$-th coordinate equals $x$ for infinitely many tuples. Then the inductive hypothesis applies. So, assume that for any $x$, there are only finitely many tuples with last coordinate $x$. So we may choose an infinite list $(a_{1,1},\ldots,a_{1,n}), (a_{2,1},\ldots,a_{2,n}),\ldots$ such that $a_{1,n}<a_{2,n}<\cdots$. If we can find $i<j$ such that $a_{i,k}\leq a_{j,k}$ for $k=1,\ldots,n-1$, we'll be done. How can we find them?",['combinatorics']
660034,Is there a general pattern behind the decimal expansion of $\frac{1}{7}$ being $.14+.0028+.000056+.00000112+...=.\overline{142857}$?,"I wondered if all decimal expansions of $\frac{1}{n}$ could be thought of in such a way, but clearly for $n=6$, $$.12+.0024+.000048+.00000096+.0000000192+...\neq.1\bar{6}$$ Why does it work for 7 but not 6? Is there only one such number per base, i.e. 7 in base 10? If so what is the general formula?",['number-theory']
660038,Example when triangle inequality fails in weak $L^p$ spaces,"Let's consider the quasi-norm on the weak $L^p(X,m)$ spaces: $$[f]_p=\sup_{t>0}\left\{t\, m\big(\{x:|f(x)|>t\}\big)^{1/p}\right\}.$$ We know that it is not a norm since the triangle inequality fails. Can you give me an example? For simplicity we can just consider the case $p=2$.","['measure-theory', 'lebesgue-measure', 'functional-analysis']"
660041,Is there a general product formula for $\sum\limits_{k=1}^{n} k^p$ [duplicate],"This question already has answers here : How is Faulhaber's formula derived? (5 answers) Closed 8 years ago . I'm familiar with Faulhaber's formula to express this sum as a much simpler one, but it appears that for any $p$ there's a product formula in $n$ for the sum e.g.: $$\begin{align}
& \sum\limits_{k=1}^{n} k^1=\frac{n(n+1)}{2} \\
& \sum\limits_{k=1}^{n} k^2=\frac{n(n+1)(2n+1)}{6} \\
& \sum\limits_{k=1}^{n} k^3=\frac{n^2(n+1)^2}{4}
\end{align}$$ ...and so forth. Is there a general product formula in $p$ and $n$ for this sum?","['summation', 'sequences-and-series', 'algebra-precalculus']"
