question_id,title,body,tags
362011,fancy about some properties of kernel functions at infinity,"Consider the two common types of kernel functions $\sum\limits_{t=a}^bf(t)K(x,t)$ and $\int_a^bf(t)K(x,t)~dt$ , prove whether the following properties are correct or not: $1.$ If $K(x,t)$ is bounded but not converge with respect to positive (or negative) $x$ , then $\lim\limits_{x\to+\infty}\sum\limits_{t=a}^bf(t)K(x,t)$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\sum\limits_{t=a}^bf(t)K(x,t)\biggr)$ and $\lim\limits_{x\to+\infty}\int_a^bf(t)K(x,t)~dt$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\int_a^bf(t)K(x,t)~dt\biggr)$ should be indeterminate. $2.$ If $\lim\limits_{x\to+\infty}K(x,t)=0$ $\biggl(\text{or}\lim\limits_{x\to-\infty}K(x,t)=0\biggr)$ , then $\lim\limits_{x\to+\infty}\sum\limits_{t=a}^bf(t)K(x,t)$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\sum\limits_{t=a}^bf(t)K(x,t)\biggr)$ and $\lim\limits_{x\to+\infty}\int_a^bf(t)K(x,t)~dt$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\int_a^bf(t)K(x,t)~dt\biggr)$ should equal to $0$ . $3.$ If $\lim\limits_{x\to+\infty}K(x,t)=\infty$ $\biggl(\text{or}\lim\limits_{x\to-\infty}K(x,t)=\infty\biggr)$ , then $\lim\limits_{x\to+\infty}\sum\limits_{t=a}^bf(t)K(x,t)$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\sum\limits_{t=a}^bf(t)K(x,t)\biggr)$ and $\lim\limits_{x\to+\infty}\int_a^bf(t)K(x,t)~dt$ $\biggl(\text{or}\lim\limits_{x\to-\infty}\int_a^bf(t)K(x,t)~dt\biggr)$ should tend to $\infty$ .","['definite-integrals', 'integral-transforms', 'analysis']"
362015,Integral of bivariate normal distribution function with respect to itself,"Define $F: \mathbb{R}^2 \rightarrow \mathbb{R}$ by 
\begin{align*}
F(x,y)=\int_{-\infty}^{x} \int_{-\infty}^y \frac{1}{2\pi \sqrt{1-\rho^2}}  
exp\left(\frac{-u^2-v^2+2\rho uv}{2(1-\rho^2)}\right) dudv,
\end{align*}
where $\rho$ is a constant with $-1\leq \rho \leq 1$. Could you help me to prove that $\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} F(x,y) dF(x,y)=F(0,0)$. I'm trying to solve this by substitution $dF(x,y)= \frac{1}{2\pi \sqrt{1-\rho^2}}  
exp\left(\frac{-x^2-y^2+2\rho xy}{2(1-\rho^2)}\right) dxdy$, separating $x$ and $y$ variable and doing integration by part but couldn't work.","['statistics', 'integration', 'probability-theory']"
362042,One-to-one correspondence between infinite sets,What does it mean to have one-to-one correspondence between infinite sets. How would you solve them?,"['elementary-set-theory', 'functions']"
362044,Is $\cot(z)-\frac1z$ bounded on a given circle?,I am getting stuck with the problem given from the book Schaum's outlines p.240 Q.110 Given $f(z)=\cot(z)-\frac1z$ where $z$ lies on a circle of radius $R=(N+\frac12)\pi$ and centered at the origin. Prove that $|f(z)|\le M$ where $M$ is independent of $N$.,['complex-analysis']
362047,"Suppose $f: \Bbb R \to \Bbb R$, where $f$ is continuous on $(-\infty, 0)$ and on $(0, \infty)$. Show that $f$ is measurable?","Prove that: Suppose $f \colon \Bbb R \rightarrow  \Bbb R $, where $f$ is continuous on $(-\infty, 0)$  and on $(0,\infty)$. Show that $f$ is measurable. Can someone please help me with this proof? My TA told me not to look at it in my self study class because we are not going to cover this. I am trying to understand this although my TA told me not to. Can someone please give a proof for this. This seems like a good proof to know about continuous and measurbale functions which I might learn later on in another class.","['measure-theory', 'group-theory', 'real-analysis']"
362060,Blowing up a point in projective n-space $\mathbb{P}^n$,"I have clearly understood the blowing up of $\mathbb{A}^n$ at the origin and it is the zero locus of the polynomials $x_{i}y_{j} = x_{j}y_{i}$ in the mixed product space $\mathbb{A}^n \times \mathbb{P}^{n-1}$ where $(x_1,...x_n) \in \mathbb{A}^n$ and $(y_0,...,y_{n-1})\in \mathbb{P}^{n-1}$ . Please help me to understand the blowing up $\mathbb{P}^n$ at a point, say $p$ . Let me try: The blow up of a point should be a closed subset of the product space $\mathbb{P}^n \times \mathbb{P}^{n-1}$ . If we blowup $\mathbb{P}^n$ in two points, then the blowup will be a closed subset of the product space $\mathbb{P}^n \times \mathbb{P}^{n-1} \times  \mathbb{P}^{n-1}$ . I don't know whether it is correct or not.
Is it difficult to construct the blowup of $\mathbb{P}^n$ at a point explicitly when $n > 2$ ?","['blowup', 'algebraic-geometry']"
362063,Prove $(abc)^4+abc(a^3c^2+b^3a^2+c^3b^2)\le 4$ for $a + b + c = 3$,"let $a,b,c>0$ ,and such that $a+b+c=3$ ,prove that $$(abc)^4+abc(a^3c^2+b^3a^2+c^3b^2)\le 4$$ I first consider $$abc\le\left(\dfrac{a+b+c}{3}\right)^3=1$$ so it suffices to show that $$a^3c^2+b^3a^2+c^3b^2\le 3$$ But I find this not true.","['inequality', 'algebra-precalculus']"
362084,"In a group of $265$ persons, $200$ like singing,.....","I came across the following problem : In a group of $265$ persons, $200$ like singing,$110$ like dancing and $55$ like painting. If $60$ persons like both singing and dancing,$30$ like both singing and painting and $10$ like all three activities,Then what is the number of persons who like only dancing and painting? My Attempt: Let us denote by $s,d,p$ for singing, dancing and painting respectively. Then the Venn diagram is as follows: Here, $x$ is the number of persons who like only dancing and painting.  Since the total no. of persons is $265,$  we see from the diagram that $265=\{120+50+10+20\}+\{50-x+x+25-x\} \implies 265=275-x$ which gives $x=10.$ Am I going in the right direction?",['elementary-set-theory']
362089,Power Series Solution for $e^xy''+xy=0$,"$$e^xy''+xy=0$$ How do I find the power series solution to this equation, or rather, how should I go about dealing with the $e^x$? Thanks!",['ordinary-differential-equations']
362098,simple explanation of gaussian mixture model,"I need some help understanding Gaussian mixture models. In particular, I am trying to find the relationship between GMMs and K means. What is the basic algorithm for GMM? I am not sure where the ""clustering"" comes in. Can someone give me a basic example as to how this actually works?","['statistics', 'probability']"
362138,Statistics and Probabilities- Distributions,"A quality control engineer tests the quality of produced computers. Suppose that 5% of computers have defects and defects occur independently of each other. I need to find the probability that the engineer has to test at least 5 computers in order to find 2 defective ones. I thought of it and came up with a solution though I'm not sure whether it's correct or not. The probability of finding $2$ defective is $p= 0.05*0.05=0.025$
  $P(T\geq 5)= 1- [ P(T=4)+P(T=3)+(T=2)]= \\ 1-[0.025*(0.975)^3+0.025*(0.975)^2+0.025*(0.975)^1]=\\
1-[0.025*0.975(1+0.975+(0.975)^2)= 0.9300442$","['statistics', 'probability-distributions', 'probability']"
362139,How to prove the distributive property of cross product,"That is, how to prove the following identity:
$$a \times (b+c) = a \times b + a \times c$$ where the $\times$ represents cross product of two vectors in 3-dimensional Euclidean space.",['linear-algebra']
362148,Linear algebra on Fibonacci number,"Consider the sequence $\{a_n\}_{n\ge 0}$ given by the recurrence relation
$$a_0=1,\ a_1=-1,\ a_{n+1}=3a_n+10a_{n-1}\ \ \text{for } n\ge2$$
And I am asked to work out the closed form expression for an in the same fashion as the proof for Fibonacci numbers by using linear algebra way Thanks all for the help!",['linear-algebra']
362154,"Using the integral equation, find the eigenvalues and eigenfucntions","The integral equation:
$$
\int_{-\frac{T}{2}}^{\frac{T}{2}}dt' \phi (t')e^{\Gamma\left | t-t' \right |}  =\lambda  \phi(t)
$$ for  $(-\frac{1}{2}T< t < \frac{1}{2}T)$ is useful in photon counting statistics theory. Show that the eigenvalues $\lambda_k$ of the above equation are given by
$$
\Gamma \lambda_k  =  \frac{2}{1+u^{2}_k}
$$ where the $u_k$ are the roots of the transcendental equation $$
tan(\Gamma T u_k) = \frac{2 u_k}{u^{2}_k - 1}
$$ Using this solve for the eigenfunctions associated The $\Gamma$ here is a constant.  I can see that the kernel is an exponential.  I've worked this numerous times using Fredholms technique but repeatidly hit a brick wall.  Am I missing something?","['mathematical-physics', 'multivariable-calculus', 'integral-equations', 'physics']"
362175,Difference between upper and lower tails of multiplicative Chernoff bounds,"I'm struggling with the intuition behind why Chernoff bounds differ in the upper and lower tails. That is, for the lower tail we have: $$
    Pr(X \le (1 - \delta)\mu)\ \ \le\ \ e^{-\frac{\mu\delta^2}{2}}
$$ Whereas for the upper tail: $$
    Pr(X \ge (1 + \delta)\mu)\ \ \le\ \ e^{-\frac{\mu\delta^2}{3}}
$$ Both bounds are found in roughly the same manner, so at a high level, why would they differ in value when we don't know that the distribution is necessarily asymmetric?","['distribution-tails', 'probability']"
362185,Find the minimum value of $(\sin^{-1}x)^3+(\cos^{-1}x)^3$.,The minimum value of $(\sin^{-1}x)^3+(\cos^{-1}x)^3$ is equal to ( following options) a) $\displaystyle \frac{\pi^3}{32}$ b) $\displaystyle\frac{5\pi^3}{32}$ c) $\displaystyle\frac{9\pi^3}{32}$ d) $\displaystyle\frac{11\pi^3}{32}$ Can we go like this : $$ -\frac{\pi}{2} \leq \sin^{-1}x \leq \frac{\pi}{2}$$ Therefore the minimum value of $(\sin^{-1}x)^3$ is $$(\frac{-\pi}{2})^3= -\frac{\pi}{8}$$ Please guide..,"['trigonometry', 'algebra-precalculus', 'maxima-minima']"
362189,Can we inverse the mean values theorem?,"The mean values theorem says that there exists a $c∈(u,v)$ such that $$f(v)-f(u)=f′(c)(v-u)$$ My question is: Can we inverse this situation, i.e., given the function $f$ and the real $c$, can we find $u,v$ such that $$f(v)-f(u)=f′(c)(v-u)$$ holds true?","['derivatives', 'real-analysis']"
362202,Quotient theorem for tensors,"Can somebody please explain to me how the following statement is true? The Riemann curvature tensor $R^c_{dab}$ is given by the Ricci identity $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V^c\equiv R^c_{dab}V^d$$ where $\nabla_a$ denotes the covariant derivative. It is linear in $V^c$, hence may be shown by the Quotient theorem to be a tensor. Now, I can see that the $R^c_{dab}$ is a tensor by construction -- based on the LHS of the Ricci identity. However, I don't understand how the linearity in $V^d$ comes to play. Also, it is  given that for covectors, the Ricci identity takes the form $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c\equiv -R^d_{cab}V_d$$ How does this follow from the Ricci identity for (contravariant) vectors? If I write $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c=(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)$$ and in GR, the Levi-Civita connection has that the metric is covariantly constant, we have 
$$(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)=g_{cd}(\nabla_a\nabla_b-\nabla_b\nabla_a)V^d\\=g_{cd}R^d_{eab}V^e=R_{ceab}V^e=R^d_{cab}V_d$$ 
 Where has my minus sign gone? I have read that you can  the Ricci identity for covectors by arguing using the fact that the Levi-Civita connection is symmetric, but I don't know how they mean. Thanks in advance for any help!","['tensors', 'riemannian-geometry', 'differential-geometry']"
362203,How to factorise $x^6 + 1$?,How do I factorise this? I already said that $$x^6 + 1 = 0 \implies (x^3)^2 + 1 = 0$$ so we then get $$(x^3)^2 = - 1$$ and then there are no real roots. Similar thing happens if I try it as $(x^2)^3$. How would I then go about factorising this? I know its possible as $$(x^6 + 1) = (x^2 + 1)(x^4 - x^2 + 1).$$,"['factoring', 'algebra-precalculus', 'polynomials']"
362231,Question about sample autocovariance function,"I'm reading a time series analysis book and the formula for sample autocovariance is defined in the book as: $\widehat{\gamma}(h) = n^{-1}\displaystyle\sum_{t=1}^{n-h}(x_{t+h}-\bar{x})(x_t-\bar{x})$ with $\widehat{\gamma}(-h) = \widehat{\gamma}(h)\;$ for $\;h = 0,1, ..., n-1$. $\bar{x}$ is the mean. Can someone explain intuitively why we divide the sum by $n$ and not by $n-h$? The book explains the reason is, because the formula above is a non-negative definite function and so dividing by $n$ is preferred, but this doesn't explain this to me clear enough. Can someone maybe prove this or show example or something. I'm a bit confused x) To me the intuitive thing at first would be to divide by $n-h$. Is this an unbiased or biased estimator of autocovariance? Thank you for any help =)","['statistics', 'time-series', 'probability']"
362279,Is this a consequence of the uncountability of a set?,"Just a random curiosity I developed now: Does the uncountability of a set mean that we can't find numbers $a$ and $b$ in $a<x<b$ being $a<b$ for which $x$ doesn't exist? For example, in a countable set ($\mathbb{N}$ for example), there is $a=2$ and $b=3$, $x$ does not exist. But for $\mathbb{R}$, I guess it's impossible to find $a$'s and $b$'s for which $x$ wouldn't exist. I just had the idea when I was looking at some properties of the reals in an analysis book, could it be a plausible definition for a uncontable set of numbers? Perhaps it's true and it may be obvious but in the near past I made some mistakes by presuming something as obvious - I'm afraid of assuming this.",['elementary-set-theory']
362312,Number of bases of an n-dimensional vector space over q-element field.,"If I have an n-dimensional vector space over a field with q elements, how can I find the number of bases of this vector space?",['linear-algebra']
362323,Help understanding Dedekind cuts,"I have an exam this tuesday and our prof gave us these problems to practice. Me and my friend were trying to do it. but I really never understood the concept or if its right. These are the questions: 1) Let $A_1$ be the set of rational numbers $x$ such that $x^2 < 3$, and $A_2$ be the set of rational numbers $x$ such that $x^2 > 3$. Is $(A_1, A_2)$ a dedekind cut? Prove your answer. 2) Let $(A_1, A_2)$ and $(B_1, B_2)$ be dedekind cuts representing real numbers $\alpha$ and $\beta$. Define what $\alpha < \beta$ means in terms of the Dedekind cuts. 3) Give an example of two Dedekind cuts $(A_1, A_2)$ and $(B_1, B_2)$ be dedekind cuts representing real numbers $\alpha$ and $\beta$ such that $A_1$ strictly contains $B_1$ but $\alpha$ is not strictly larger than $\beta$. 4) Give an example of two ""unessentially different"" Dedekind cuts. 5) Is it true that a rational number can be represented by two ""unesentially different"" Dedekind cuts? Explain Our answers: 1) for this one the teacher told us that is $A_1 = \{x \in \mathbb{Q} | x^2 <3\}$ and $A_2 = \{x \in \mathbb{Q} | x^2 >3\}$ she said is $0 \in A_1$ and $-100 \in A_2$ and that implies its not a dedekind cut. Am I missing something here? like where did she get 0 and -100 from. 2) and 3) we didnt get any help on this would be appreciated. 4) So if we let $(A_1 = (\mathbb{Q} \cap (-\infty , 2], A_2 = (2, \infty) \cap \mathbb{Q})$ and if $(B_1 = (\mathbb{Q} \cap (-\infty , 2), B_2 = [2, \infty) \cap \mathbb{Q})$. I dont know if that is right. please help out. and need help on 5) Any help on this would be greatly appreciated. Thank you very much",['analysis']
362338,Unexpected hanging paradox maxmin strategies,"I have a question about strategies of the players of Unexpected hanging paradox (I am very sorry for a long topic,  topic exist already for a while, during this time I try to develop idea how to solve the problem, recently I decided to seek solution in the field of probability, therefore I ask for anyone who has experience in solving problems in probability to take a look. For understanding essential is reading the Version of the Paradox paradox, Question , and may be few last addendums). Version of the Paradox : Let's consider a slightly specific version of the paradox, where the players take actions in rounds (in terms of paradox rounds can be days). On every specific round (day) judges can take action $A$ - the prisoner will be hanged today, $B$ - the prisoner will not be hanged today, and the prisoner can have few guesses $A$ - I will be hanged today, $B$ - I will not be hanged today. The game is played simultaneously. If $A$ is played by one of the players then the judges win, if both players play $A$ simultaneously than  the prisoner win, and if both of them play $B$ game goes to the next round. If as a result of four rounds the prisoner is not hanged than the prisoner win. Question: what is max-min strategy for the judges and for the prisoner. If there are any solution concept (Nash equilibrium). The following is a few I hope useful ideas to approach the solution. The game should be represented in extensive from but with simultaneous play. Let's start from judges. There is no dominant strategy for the judges and it looks like there is no a pure Nash equlibrium. What it's known is that the chances to win when judges play $A$ is 50% and the chances to win when judges play B is $>50%$. But every next round the chances to win by choosing $B$ is getting lower, however the prisoner should prefer $B$ when the number of rounds is getting higher. In addition, we can try to do a backward induction, the last round is similar to the Matching pennies game , that has a mixed Nash equilibrium, with actions takes on probability of 50 %. On the second backward induction step (using the fact that on the last step the mixed Nash equilibrium is 50/50 between playing A and B for both players), therefore judges would prefer playing $B$ on the second step with probability 75 % and A with 25%, however the prisoner would prefer playing $A$ with 75% and B with 25%. Unfortunately I didn't get any closer to maxmin strategies, but at least I've shared few ideas. Addendum: Instead of playing 4 rounds, let's try to play 2 rounds, when the last round is similar to the matching pennies game, we can try to convert the 2 round game to normal form (4 by 4 actions for prisoner and judges of the form {AA,AB,BA,BB}) and it will be apparent that the most effective strategy for judges is two columns (judges is column player, at the same time is the worsen strategies for the prisoner ) - B(don't hang) -B(don't hang); B(don't hang)-A(hang) for the prisoner the win strategy is the strategy of the judges(BA when judges played BA, and BB when judges played BB), then maxmin of the prisoner is to play B for the tree rounds and on the last round play A or B with probability 50%. The worsen strategies for the judges is AA and AB (they actually don't yield the second turn because judges decide to hang on the first round, therefore consider only strategy A, in the normal form it's represent like AA and AB, maybe I get it wrong), therefore playing A is maxmin strategy of the judges. Addendum: we can try to looks at the problem from the probability point of view. Let's consider few ideas. Idea 1. Judges throughout the game should make five principal decisions, following is the decision with the probabilities. $Pr(j_1=$hand the prisoner on the first day$) = 0.2, ..., Pr(j_4=$hand the prisoner on the last (4'th) day$) = 0.2, Pr(j_5=$don't hang the prisoner at all$) = 0.2$ the same for the prisoner, $Pr(p_1=$I will be hanged on the first day$) = 0.2,..,Pr(p_4=$I will be hanged on the fourth day$) = 0.2, Pr(p_5=$I will not be hanged at all$) = 0.2$ $P($judges win$) = \sum_{1 \leq i \leq 4}^{} p_1(1-s_1)=0.8$ The above approach for me looks like not correct, just because taking an action on round $i$ depends on the decision on round $i-1$, therefore all the probabilities are not independent. Idea 2 We can try to represent all the probabilities of the game in this form $Pr(p_1=$prisoner wins on the first round$) = 0.5($prisoner:I will be hanged on the first day$) \cdot 0.5($judges : hang the prisoner on the first day$)$ $Pr(p_2=$prisoner wins on the second round$) = 0.5($prisoner:I will no be hanged on the first day$) \cdot 0.5($judges : don't hang the the prisoner on the first day$) \cdot 0.5($prisoner:I will be hanged on the second day$) \cdot 0.5($judges : hang the prisoner on the second day$).$ $Pr(p_4=$prisoner wins on the last round$) = (0.5 \cdot 0.5)^3 ($judges didn't hang the prisoner on the three previous round and the prisoner didn't make guess that he will be hanged during first three days$) \cdot (0.25($judges: hang on the last day, prisoner: I will be hanged today$) \cdot 0.25($judges: don't hang at all, prisoner: I will not be hanged at all$))$. $Pr($prisoner wins the game$) = p_1+p_2+p_3+p_4 =0.25+0.25^2+0.25^3+0.25^3 \cdot 0.5 = 0.3359375$ We get some result, I don't really know what to do with it, and don't know if it's correct, if we consider the probabilities for the victory like in Idea 2, it's obvious that the prisoner should make decision as soon as possible because on the first round he has the maximum probability to win and it goes less with every consecutive round. If we consider probability like in Idea 1 in independent manner, the maximal probability to win is on the round 4. What is the right way I still don't know.","['algorithmic-game-theory', 'game-theory', 'nash-equilibrium', 'probability', 'maximum-principle']"
362343,Orthogonality of eigenfunctions of a linear operator.,"Suppose I have a linear operator
$$
\frac{\mathrm{d}^2}{\mathrm{d}r^2}+\frac{1}{r}\frac{\mathrm{d}}{\mathrm{d}r}
$$
and I want to find its eigenfunctions, that is, to solve the ODE
$$
\frac{\mathrm{d}^2R}{\mathrm{d}r^2}+\frac{1}{r}\frac{\mathrm{d}R}{\mathrm{d}r}=\lambda R.
$$
Suppose, further, that I have boundary conditions $R(0)\neq\pm\infty$ and $R(a)=0$, then the solutions are Bessel's functions of the first kind $R=J_0\left(\frac{j_n}{a}r\right)$, where $j_i$'s are the roots of $J_0$. I want to show directly that these functions are orthogonal with respect to a weight function. Notice that
$$ rR''+R'=\lambda rR =\frac{\mathrm{d}}{\mathrm{d}r}(rR')$$
and suppose that $R_m$ and $R_n$ are eigenfunctions with distinct corresponding eigenvalues $\lambda_m,\lambda_n$, so
$$
(rR'_m)'=\lambda_m rR_m \\
(rR'_n)'=\lambda_n rR_n
$$
Hence, multiplying by $R_n$ and $R_m$ and subtracting, one gets
$$
(\lambda_m-\lambda_n)rR_mR_n=((rR'_m)'R_n-(rR'_n)'R_m)
$$ 
At this stage, it seems that $r$ is the weight function and I need to integrate w.r.t. $r$ from $0$ to $a$
$$
(\lambda_m-\lambda_n)\int^a_0 rR_mR_n\:\mathrm{d}r=\int^a_0 ((rR'_m)'R_n-(rR'_n)'R_m)\:\mathrm{d}r
$$
It seems that the integral on the RHS should be equal to zero, but I do not see how.","['ordinary-differential-equations', 'calculus']"
362350,Useful approximation of the pdf,"Good day to everyone.
In my research work I came out with a function, which looks like this (it is the pdf of some random variable):
$$f(x,\rho,\psi)=\frac{2}{\pi }+\sqrt{\frac{2}{\pi }} e^{-\frac{\rho ^2}{4}} \rho  \sum _{k=1}^{\infty } \cos  (2 k x ) \cos  (2 k \psi )\left(I_{k+\frac{1}{2}}\left(\frac{\rho ^2}{4}\right)+I_{k-\frac{1}{2}}\left(\frac{\rho ^2}{4}\right)\right) $$
where $\rho >0, 0<\psi<\frac{\pi}{2}, 0<x<\frac{\pi}{2}$ and $I_k(x)$ - modified Bessel function of the first kind and the summation is over all odd  indices. The thing is that the series converges slowly (because of the cosine terms). So it is hard to use this representation in practice. At first I tried to sum up the series but at last gave up. But I know that in similar problems the pdf is usually assumed to be the Von Mises or wrapped normal . So at first I noticed that 
that the factor before the sum compensates the increment of the Bessel functions $\lim_{\rho \to \infty }\sqrt{\frac{2}{\pi }} e^{-\frac{\rho ^2}{4}} \rho  \left(I_{k+\frac{1}{2}}\left(\frac{\rho ^2}{4}\right)+I_{k-\frac{1}{2}}\left(\frac{\rho ^2}{4}\right)\right)  =\frac{4}{\pi }$ . And then, manipulating the Von Mises pdf obtained:
$$f_1(x,\rho,\psi)=\frac{e^{\frac{1}{4} \rho^2  \cos  (2 (x -\psi ))}+e^{\frac{1}{4} \rho^2  \cos  (2 (x +\psi ))}}{\pi  I_0\left(\frac{\rho ^2}{4}\right)}$$ The same with wrapped normal. $$f_2(x,\rho,\psi)=\frac{\vartheta _3\left(x -\psi ,e^{-\frac{2}{\rho ^2}}\right)+\vartheta _3\left(x +\psi ,e^{-\frac{2}{\rho ^2}}\right)}{\pi }$$
where $\vartheta _3$ is the Jacobi theta function.
Well, but this is just ""manipulating"". May be you can give me a hint how to show it analytically? After that I tried to compare those approximations. There are a lot of criteria to define how close those distributions are, and they all come down to computational procedure with different parameter $\rho, \psi$, which is not vary nice/descriptive. What I really want to find is a strict enough proof that this or that approximation (in analytic form) is superior for different $\rho, \psi$ in application to those pdf's. Do you think it is possible?","['special-functions', 'multivariable-calculus', 'approximation', 'probability-distributions']"
362356,"Evaluating tetration to infinite heights (e.g., $2^{2^{2^{2^{.^{.^.}}}}}$)","The Problem How can you evaluate (i.e., get a value for) Tetration (i.e., iterated exponentiation) to infinite heights ? For example, what would be the value of this expression? $$ 2^{2^{2^{2^{2^{.^{.^.}}}}}} $$ My (pathetic) Attempts I tried equating it to $x$ and substituting it on the RHS, but no luck: $$ x = 2^{2^{2^{2^{2^{.^{.^.}}}}}} $$
$$ x = 2^x $$
$$ x = \log_{2}{x} $$ What I think we need to do is have the RHS as a polynomial with one variable and the RHS a constant so we can solve for $x$. I tried drawing the equation on Wolfram Alpha but the lines on the graph don't touch, so no luck there either. Novice mathematician here. Thanks. Edit Sorry, I am a dolt :( I didn't realize this was a diverging series. What confused me is my math sir told me it could be done. What he actually meant was that it could be said like this: $$ \frac{\log{x}}{x} = \log{2} $$ but I somehow assumed there would be a numerical answer. Alternative Questions @Clayton's answer suggested an similar question which was a convergent series. While that wasn't what my sir meant, it practically could've been: $$ \sqrt{2}^{\sqrt{2}^{\sqrt{2}^{.^{.^.}}}} $$ Another one I can think of would be: $$ \sqrt{2*\sqrt{2*\sqrt{2*\sqrt{2*\sqrt{...}}}}} $$ Anyway, interesting question this has turned out to be...","['exponentiation', 'sequences-and-series', 'recursion']"
362360,$\sigma$-Algebra generated,"I have a question : Let $Z=\lbrace 0,1\rbrace ^{\mathbb{N}}$. Why does the sets $E_1,E_2,...$, where $E_k=\lbrace (n_i)\in Z; n_k=1 \rbrace $ generate $\mathcal{B}(Z)$? How can I prove it? I find that they use : $\quad$ Proposition $\mathbf{8.1.5.}$ $\quad$Let $X_1$, $X_2$, $\ldots$ be a finite or infinite sequence of separable metrizable spaces. Then $\mathscr{B}(\Pi_nX_n)=\Pi_n\mathscr{B}(X_n)$. but I don't understand why ? Thank you",['measure-theory']
362361,Prove the inequality $4S \sqrt{3}\le a^2+b^2+c^2$,"Let a,b,c be the lengths of a triangle, S - the area of the triangle. Prove that $$4S \sqrt{3}\le a^2+b^2+c^2$$","['geometry', 'inequality']"
362405,"Is this correct? $\sin'(z) = \cos(z),~\cos'(z) = -\sin(z)$","I just want you guys to double check if I'm on the right track. so to prove $\sin '(z)$ = $ \cos (z)$ I did this:
$\sin (z)$ = $\frac {e^{iz} - e^{-iz}}{2i}$ $\sin '(z)$ = $\frac {i(e^{iz} + e^{-iz})}{2i}$ = $\frac {e^{iz} + e^{-iz}}{2}$ = $\cos (z)$ is that correct? and for $\cos '(z)$ = $-\sin (z)$ I did something similar. $\cos (z)$ = $\frac {e^{iz} + e^{-iz}}{2}$ $\cos '(z)$ = $\frac {i(e^{iz} - e^{-iz})}{2}$ = $\frac {i(e^{iz} - e^{-iz})}{2}* \frac{i}{i}$ = $\frac {i^2(e^{iz} - e^{-iz})}{2i}$ = $\frac {-e^{iz} + e^{-iz}}{2i}$ = $-\sin (z)$ or using the Cauchy-Riemann formula/equation: $f '(z_0)= \frac{du}{dx} (x_0, y_0) - i \frac{du}{dy} (x_0,y_0)$ where $\frac{du}{dx} (x_0,y_0) = \frac{dv}{dy} (x_0,y_0)$ and $\frac{du}{dy} (x_0,y_0) = -\frac{dv}{dx} (x_0,y_0)$ so $\cos z = \cos x\cosh y - i\sin x\sinh y$ using the formula/equations we get: $\cos '(z) = -\sin x\cosh y - i\cos x\sinh y$. I believe this is the correct way. but please correct me if I'm wrong. Thank you!","['derivatives', 'complex-analysis', 'solution-verification']"
362423,Why 4 is not a primitive root modulo p for any prime p?,"I wonder why 4 is not a primitive root for any prime p ? I've been trying to find an answer with no success so far. Any suggestion would be very helpful,
thanks in advance !","['prime-numbers', 'elementary-number-theory', 'number-theory']"
362446,Nice examples of groups which are not obviously groups,"I am searching for some groups, where it is not so obvious that they are groups. In the lecture's script there are only examples like $\mathbb{Z}$ under addition and other things like that. I don't think that these examples are helpful to understand the real properties of a group, when only looking to such trivial examples. I am searching for some more exotic examples, like the power set of a set together with the symmetric difference, or an elliptic curve with its group law.","['examples-counterexamples', 'group-theory', 'abstract-algebra', 'big-list']"
362457,Existence of dominating measure for weak*-compact set of measures,"Let $(\Omega,\mathcal F)$ be a measurable space and $\mathcal P$ a weak*-compact set of the set of all probability measures $\mathcal M_1(\Omega)$. Does there always exist a probability measure $\mathbb Q\in\mathcal M_1(\Omega)$ such that every $\mathbb P\in\mathcal P$ is absolutely continuous to $\mathbb Q$, i.e. such that $\mathbb Q$ dominates all measures in $\mathcal P$?","['probability-theory', 'measure-theory', 'functional-analysis']"
362465,Why is the Monster group the largest sporadic finite simple group? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question I do know that there is a ""long proof"" (I have read that it is +1000pages) that the Monster group is the largest sporadic simple group. My question is: Why can we be sure that there is no other bigger group out there? Beyond that long proof, is there any alternative ""proof"" of why the Monster group is the largest simple group? After all, the full set of sporadic simple groups seems to have some unexplained and yet mysterious relationships between some of them.","['finite-groups', 'group-theory', 'simple-groups']"
362482,Logarithm of a Gram matrix,"Given a Gram matrix $K$, we are interested in calculating its matrix logarithm $\log(K)$, and in particular, to relate minus this logarithm to the Laplacian of a graph. We have noticed that $-\log(K)$ always has positive diagonal entries. Which is a good thing, but we would like to prove it. Any ideas?","['matrices', 'logarithms']"
362486,What curve is this?,"This is my earring (see the image please) and my question is: Does this curve have a name? If it does, which one? Regards! And thank you.","['geometry', 'surfaces']"
362490,Derivative of $(Y-HX)^\top C(Y-HX)$ by $X$,"I'm trying to derive an expression for $$\nabla_X(Y-HX)^\top C(Y-HX).$$ $Y$ and $X$ are column vectors of size $N \! \times 1$. $H$ and $C$ are matrices of size $N \! \times N$. I have checked this Wikipedia page , but there wasn't an exactly matching identity there.","['matrices', 'derivatives']"
362502,Finitely generated subgroups of direct limits of groups,"Let $G$ be a direct limit of groups $G_n$ for $n\in \mathbb{N}$ (or perhaps even for $n$ in some other directed set, but in my case I only need $\mathbb{N}$). Is it true that every finitely generated subgroup of $G$ is isomorphic to a subgroup of some $G_n$? [EDIT:  I'm adding the category-theory tag in case it helps.  I think category-theorists don't like the term 'direct limit' these days, so please read 'colimit' instead.)","['category-theory', 'group-theory']"
362522,Finding the solution to this specific recurrence relation,"What would be the solution to $a_n = 7a_{n−2} + 6a_{n−3}$ with $a_0 = 9$,
$a_1 = 10$, and $a_2 = 32$ I can find it for a specific value of (n), but not for just a general solution.  Thanks!","['discrete-mathematics', 'proof-writing']"
362532,Relationship between Lebesgue–Stieltjes measure and regular Borel measure,"From http://en.wikipedia.org/wiki/Lebesgue%E2%80%93Stieltjes_integration : The Lebesgue–Stieltjes measure is a regular Borel measure, and conversely every regular Borel measure on the real line is of this kind. As far as I know, a Lebesgue-Stieltjes measure is a regular Borel measure. But I can't find any proof for the reversed side. Could anyone help me?","['measure-theory', 'stieltjes-integral']"
362554,Integral $\int \frac{\tan x}{x} dx$,"Evaluate the integral:
  $$\int \frac{\tan x}{x} dx$$ I tried integration by parts, got stuck. Ideas/ suggestions please.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
362556,Classrooms and students puzzle,"My school has many classes. Any two students share exactly one class. Any two classes share exactly one student. A class must have at minimum $3$ students, and there is at least one class with $17$ students. How many students attend my school? How do I approach this question? How do I determine whether or not this question has an exact numerical answer? This is difficult... help would be much appreciated.","['puzzle', 'combinatorics']"
362559,Show that every ideal of the matrix ring $M_n(R)$ is of the form $M_n(I)$ where $I$ is an ideal of $R$ [duplicate],This question already has answers here : What are the left and right ideals of matrix ring? How about the two sided ideals? (2 answers) Closed 11 years ago . Suppose $R$ is a commutative ring. Show that every ideal of $M_n(R)$ is of the form $M_n(I)$  where $I$ is an ideal of $R$. I have spent 30 minutes on this question and I still got nowhere. Can anyone give some hints ?,"['matrices', 'ring-theory', 'abstract-algebra']"
362578,Show that anecessary and sufficient condition for $x_{p}$ to be tangent to $S^{n}$ at $p$,"Please help me! How do I solve this problem? I didnt produce any idea because I didnt understand this topic properly. Thus, please can you explain the solution explicitly? Thank you for help:)","['multivariable-calculus', 'vector-analysis', 'differential-geometry']"
362591,"If a tensor product is free, what can we say about the tensor factors?","Here is what I'd like to prove: Let $R$ be a commutative, noetherian ring, and let $M$ and $N$ be finitely generated $R$-modules.  Suppose $M\otimes_RN\cong R$.  Does it follow that $M\cong N\cong R?$ Whether or not this is true, I'm wondering what conditions are necessary for something like it to be true, that is, what conditions $\star_R$, $\star_M$, and $\star_N$ make the following statement true: Let $R$ be a ring satisfying $\star_R$, and let $M$ be a right $R$-module satisfying $\star_M$ and let $N$ be a left $R$-module satisfying $\star_N$.  If $M\otimes_RN\cong R$, then $M\cong N\cong R$. Also, what about higher ranks, that is, what can be said in the case $M\otimes_RN\cong\bigoplus_{i=1}^nR$?  I'd appreciate proofs in the affirmative and/or counter examples.  Thanks! Edit: In light of Martin's and Qiaochu's responses, is $\text{Pic}(\text{Spec } R)$ trivial when $R$ is local?","['modules', 'tensor-products', 'ring-theory', 'abstract-algebra']"
362616,"Can we conclude $\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}$ in ZFC?","In complex analysis, there is a function called Euler's Gamma function . Whenever given a positive integer $n+1$, it will return $n!=\prod_{i=1}^{i < n+1}i$. I'm not sure if there is similar function for infinite cardinals such that $$\Gamma(\aleph_\alpha)=\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa$$,
but at least we can evaluate the value of that production. So my question : Is $\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}$?","['cardinals', 'elementary-set-theory']"
362624,Compact space and Hausdorff space,A continuous map from a compact space to a Hausdorff space is closed. Why this is true? Help me please I want to learn why this is correct.,"['general-topology', 'compactness']"
362634,Infinite series of Hypergeometric function,"Any ideas how to find a closed form for the sum given by:
$$
\sum^\infty_{n=0}
\frac{1}{n!} 
\frac{a^n b^{n+m}}{(m+n)^2 \Gamma(m+n)}
{}_2F_2 \left(m+n,m+n;m+n+1,m+n+1;-b\right)
$$ Given that both $a$ and $b$ are positive real numbers, and $m$ is a nonzero positive integer.","['special-functions', 'sequences-and-series', 'hypergeometric-function']"
362643,Probability of an even number,"I have been having problems solving the following problem. Two real numbers $x$ and $y$ are chosen uniformly at random in the interval $(0,1)$. What is the probability that the closest integer to $x/y$ is even? I wrote a computer program to estimate the answer but I can't see how to solve it without one.",['probability']
362667,"Nicolas Boubarki, Algebra I, Chapter 1, § 2, Ex. 12","Nicolas Boubarki, Algebra I, Chapter 1, § 2, Ex. 12: ($E$ is a Semigroup with associative law (represented multiplicatively), $\gamma_a(x)=ax$.) Under a multiplicative law on $E$, let $ a \in E $  be such that $\gamma_a $ is surjective. (a) Show that, if there exists $u$ such that $ua=a$, then $ux=x$ for all $x\in E$. (b) For an element $b\in E$ to be such that $ba$ is left cancellable, it is necessary and sufficient that $\gamma_a$ be surjective and that $b$ be left cancellable. For those interested in part (a), simple proof is that for every $x\in E$ there exists $x^\prime \in E$ such that $ax^\prime=x$, consequently $ua=a \Rightarrow uax^\prime=ax^\prime \Rightarrow ux=x$. In (b), surjectivity of $\gamma_a$ and left cancellability of $b$ is required. However, I am concerned with ""sufficiency"" portion of part (b). When $E$ is infinite set there can always be a surjective function $\gamma_a$ which need not be injective, and left translation by $b$ is cancellable, however $ba$ need not be left cancellable.",['abstract-algebra']
362680,Principal connection & curvature,"Let $(P, \pi, B)$ be a principal $G$-bundle over $B$ and $\omega$ a principal connection. Then the curvature is defined as 
$$ \Omega_\omega = d \omega + \frac{1}{2} \omega \wedge \omega$$
With the d being the standard differentiation. Let $p \in P$ and $\alpha, \beta \in T_p P $ be horizontal vectors (ie $\omega(v)=0$). Let $\hat{\alpha},\hat{\beta}$ be horizontal vector fields extending $\alpha, \beta$ near $p$. Then 
$$ \Omega_\omega(\alpha,\beta)_p = \omega([\hat{\alpha}, \hat{\beta} ])_p $$
How do we show this? I'm pretty sure I'm getting tripped up on something easy.","['algebraic-topology', 'differential-geometry']"
362684,Reference request: Chern classes in algebraic geometry,"I have encountered Chern classes numerous times, but so far i have been able to work my way around them. However, the time has come to actually learn what they mean. I am looking for a reference that treats Chern classes in algebraic geometry over $\mathbb{C}$. It is no problem if only varieties are treated and not general schemes. I will be requiring only basic knowledge: definitions and some way to calculate them. Thanks!","['vector-bundles', 'algebraic-geometry', 'reference-request', 'complex-geometry']"
362692,Trouble visualizing sin and cos,"I'm working on building tetris now in Java and am at the point of rotations... I originally hardcoded all of the rotations, but found that linear algebra was the better way to go. I'm trying to use a rotation matrix to rotate my pieces, and found I need a good understanding of trigonometry. That being said, the way I visualize sin and cos is on the bottom part of the picture... a circle drawn on a graph... but images online show the sin cos relationship as the above picture... two waves that are ""90 degrees"" away from each other... So, my questions are: 1) I can't seem to visualize how they are 90 degree apart. I can't see how those angles are formed in the above graph from sin and cos. 2) It's said that the relationship is Sin X = Cos (90 - x) , and that sin is opposite/hypotenuse and cos = adjacent/hypotenuse... but what exactly does that mean? What do the quotients of these mean in relation to an angle? Let's say x = 45 degrees, adjacent = 5 inches, hypotenuse = 5 inches, and opposite = 4 inches... so sin would be 5""/9"" = .55 inches... What does this .55 inches mean in relation to the angle? How is it helpful? Thank you!!",['trigonometry']
362722,Differential equation must satisfy its edge conditions.,"I have this variation problem $$\text{Minimize} \; \int_0^1 \left( 12xt- \dot{x}^2-2 \dot{x} \right) \; dt$$ With the edge conditions $x(0)=0$ and $x(1)$ is ""free"". And from here solve it: $$x(t)\to -t^3 +c_1t+c_2$$ From here it should've been correctly. Now I must solve the equation and compute $c_1$ and $c_2$ However I'm not aware of the edge condition $x(1)$ as free. How do I solve this, and what does it exactly mean by ""free""? Result: $c_1$ should be $2$ and $c_2$ should be $0$. (Ps. If you can show it with Mathematica It would be great!)","['ordinary-differential-equations', 'partial-differential-equations']"
362765,"Let $f>0$ differentiable in $[0,\infty)$. Assume $\lim \limits_{x \to \infty} (\log\circ f)^\prime(x) < 0$. Show that $\int_0^\infty f$ converges.","So what I gathered from the givens about $f$, since $(\log\circ f)^\prime(x)=\frac{f^\prime(x)}{f(x)}$ it would mean that far enough, $f^\prime(x)<0$. I don't know how to go about this from here. Another question in the same kind of area that I'm currently struggling with fruitlessly, assuming that $f$ is still positive and differentiable in $[0,\infty)$ - now the givens are different: Assume that $\int_0^\infty f$ exists, and that $f^\prime$ is bounded. Show that $\lim \limits_{x\to\infty} f(x)=0$. About this question I'm thinking about Lagrange's theorem, and using Cauchy's criterion for the convergence of improper integrals to show (somehow) that $f(x)$ can be made arbitrarily small far enough. That didn't get me very far, and frustration quickly ensued. I appreciate any thoughts and hints, I feel like I'm missing something rather obvious.. Thank you!","['improper-integrals', 'integration', 'limits']"
362779,Differentiability of convolution,"First let me say that I have used the search bar and looked through all the ""differentiability of convolution"" questions that I saw, but none of them seem to cover this case. (If one of them did and I missed it, of course please post the link and I will look more closely). Suppose $h\in L^\infty(\mathbb{R})$. How nice does $g$ have to be in order to guarantee that $h * g \in C^1(\mathbb{R})$? In my particular situation $g$ is a Schwartz function, infinitely differentiable and all of its derivatives decay faster than any polynomial, and $h$ is continuous and bounded. I know that if $h \in L^p$ for $p<\infty$ then $f *g \in C^\infty$, and I know it works if $g$ is compactly supported, but in my case neither of these two hold. All I have is that $h$ is continuous and bounded, and $g$ is Schwartz. EDIT: $h*g$ being differentiable almost everywhere would actually suffice for my purposes. EDIT2: More specifically,  $g(x) = e^{-x^2}$.","['convolution', 'measure-theory']"
362782,Am I doing this partial derivative correctly so far?,"If $u=\arctan(xy+z)$, where $$x=s^2+t^2,\;y=9re^{st},\;z=r^2st,$$ find the value of $\frac{\partial u}{\partial s}$ when $r=2,s=1,t=0$. Is my attempt so far correct? $$\frac { ∂u }{ ∂s } =\frac { ∂\tan^{ -1 }(xy+z) }{ ∂s } \\[12pt] =\frac { ∂\tan^{ -1 }(xy+z) }{ ∂(xy+z) } \frac { ∂(xy+z) }{ ∂s } \\[12pt] =\frac { 1 }{ 1+{ (xy+z) }^{ 2 } } \frac { ∂(xy+z) }{ ∂s } $$ Simplifying the factor on the right: $$\frac { ∂(xy+z) }{ ∂s } \\[12pt] =\frac { ∂(xy+z) }{ ∂x } \frac { ∂x }{ ∂s } +\frac { ∂(xy+z) }{ ∂y } \frac { ∂y }{ ∂s } +\frac { ∂(xy+z) }{ ∂z } \frac { ∂z }{ ∂s } $$ Continuation of attempt: http://s16.postimg.org/4lk9voaxx/IMG_20130415_173718.jpg Sorry for poor quality.",['multivariable-calculus']
362817,Show polynomial is a Lipschitz function,"If $A\subseteq \mathbb{R}$ is a bounded set and $p$ is a polynomial, then show that $p:A\to \mathbb{R}$ is a Lipschitz function.","['holder-spaces', 'real-analysis', 'polynomials']"
362827,Are vector bundles on $\mathbb{P}_{\mathbb{C}}^n$ of any rank completely classified? (main interest $n=3$),"It is very well known that the group of line bundles on $\mathbb{P}_{\mathbb{C}}^n$ is exactly $\mathbb{Z}$. Are bundles of higher rank classified as well? If so, could anyone provide a nice reference, listing (some of) their invariants? If not, what are the incomplete results? Edit: I learned that this is a hard open problem. Therefore i would like to restrict the question to the case $n=3$, i.e. ""What are the (possibly incomplete) results on classification of vector bundles on $\mathbb{P}_{\mathbb{C}}^3$?"" Thanks!","['vector-bundles', 'algebraic-geometry', 'reference-request', 'complex-geometry']"
362834,"Numbers $\le120$ that are divisible by 2, 3, or 5","So I am given the following question: For natural numbers less than or equal to 120, how many are divisible by 2, 3, or 5? I solved it by inclusion-exclusion principle and by using the least common multiple by having it as (2, 3, 5)=120 which is equal to 30. Are these the right way to solve them or is there other ways?","['inclusion-exclusion', 'elementary-number-theory', 'discrete-mathematics']"
362842,C* algebra of bounded Borel functions,"Let $T\in B(H)$ is normal, and $B(\sigma(T))$ denote the $C^*$ algebra of all bounded Borel functions on $\sigma(T)$. Then is it true that $B(\sigma(T))$ is a closed $C^*$ algebra under the sup. norm ? Actually I try to prove the Spectral representation Theorem of a normal operator in case the representation of $C^*(T)$ over $H$ is cyclic, i.e there exists $x\in H$ such that $\{\phi(T)x:T \in C^*(T)\}$ is dense in $H$. We have $E$ is the the spectral measure of $T$, and $\mu$ is the positive regular Borel measure $\langle E(\cdot)x,x\rangle$ . So I define the following map $$ U\colon \{F(T)x: F\in B(\sigma(T))\}\rightarrow L_{2}(\mu) $$ by $U(F(T)x)=F$. I proved that the map $U$ is well defined and isometric. I want to prove that it has a dense range and can be extended to a unitary map on $H$. To prove the fist assertion I said that the $S$:the set of all simple functions on $\sigma(T)$ is contained in $B(\sigma(T))$, and hence the closure of $S$ under the sup. norm is contained in the closure of $B(\sigma(T))$. Hence the $C(\sigma(T))\subset  B(\sigma(T))$, but $C(\sigma(T))$ is dense in $L_{2}(\mu)$, which proves that $U$ has a dense range? Is that correct? I'm stuck with the second assertion , so can you help me please! Thank you.","['c-star-algebras', 'operator-algebras', 'measure-theory', 'banach-algebras']"
362843,Bias/Nonbiased Probability Puzzle Question,I got this puzzle that I need help on.  I hope its not too easy because I really don't understand it. A bag contains 100 coins.  99 of them are fair and will give heads or tails with an equal probability.  1 biased coin will always yield heads.  I pull a coin out randomly from the bag and toss it up 3 times.  In each of the 3 times it lands on heads. What is the probability that I pulled out the biased coin?,['probability']
362844,Prove a set is measurable,"Let $n_1 < n_2 < \cdots$ be an infinite strictly increasing sequence of positive integers. Show that $\{x \in [0, 2\pi]: \{\cos(n_kx)\}_k^\infty \text{ converges}\}$ is measurable. I honestly have no idea how to approach this. Should I use the definition of measurable sets? Should I use the fact that $\cos$ is a measurable function? Should I somehow reduce the problem to a bunch of open sets? Or something else? In general, how would one go about proving that a set is measurable? Thank you very much!","['measure-theory', 'real-analysis']"
362856,"$\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0$","I'm ashamed to have to ask this question... After poring over a few measure theory text books for the last couple of hours I still cannot figure out which theorem of ""standard"" measure theory, out of the bazillion theorems that these books give, justifies this stupefyingly obvious fact: $$\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0$$ Of course, I expect that some restrictions will need to be placed on the function $f$, and possibly on the measure $\mu$.  In fact, my interest in finding a formal statement of the theorem is to get some idea of how generally the above implication holds. (I figure that the above implication has to be true, at least for most functions $f$ one could care about, if for no other reason that any theory of measure for which this wasn't the case would be pretty worthless.  Therefore, I expect the above implication would lie very close to the basic definitions of the theory.  But the books on measure theory I have on hand use such elaborate apparatus to develop the theory, that it is impossible for me to discern through all the machinery the really fundamental facts like this one.)",['measure-theory']
362862,How to deal with Homeomorphisms?,"I have one doubt that may be too general, I don't know, so sorry if this is not a good place to ask it. I've also seem many other people with the same problem that I have, so I think that if this question fits this site, it'll help other people to. I've been studying multivariable analysis, metric spaces and manifolds, and in all of them I find the same problem: although I already understood the main definitions and results I find myself a little lost when it comes to construct and to prove homeomorphisms. For instance, in linear algebra when it comes to prove isomorphism of vector spaces I know a ""procedure"", I have a line of thought that even though can be dificult in some cases, will end up giving what I was seeking for. One point of this ""procedure"" is that we now that once we have the map it suffices to show that it's linear (a simple check of a property), show that it's kernel is just the null vector and to show surjectivity we look at the dimensions. However, when it comes to construct and prove homeomorphism it seems like ""the only way is to make a good guess"", without some procedure and something like that. For example, it's not intuitive, at least to me that to show that the open ball is homeomorphic to $\mathbb{R}^n$ we would need to take the map $f(x) = x/(1+|x|)$. It's just that I look to this map and I think: ""I would never have thought of it"". Anyway, if finding the map seems a problem, proving that the map indeed is homeomorphism seems even worse, because the most common way: find an $\epsilon$ also seems like depending on ""good guesses"". Even for simple function on the real line I look at the $\epsilon$'s that usually are used to prove continuity and I think: ""I would never have thought of such a thing"". My question is: there is a systematic way of attacking those problems? Is there a procedure to find and prove hoemorphisms like there's in linear algebra to find and prove isomorphisms? Is there a way to make this less dependent on guesses? In the real line people often draw the small intervals, however, this kind of thing seems not too good, since we won't have this ""graphical resource"" to find a way to prove homeomorphisms between higher dimensional manifolds. Where can I really learn those things? My interest is really the study of manifolds, and I'm working with Spivak's ""A Comprehensive Introduction to Differential Geometry Vol. 1"", however I'm feeling the need to better understand these questions about how to construct and how to prove homeomorphisms, since all the charts for the manifolds must be construct as homeomorphisms. Thanks in advance for your help.","['general-topology', 'soft-question', 'manifolds', 'real-analysis']"
362865,delta functions $e^{x}\delta (x)=\delta (x)$,"How would you prove that;
$$e^{x} \delta (x)= \delta (x)$$ Is it anything to do with the following relationship;
$$ \int_{-\infty}^{\infty} g'(x)h(x)\,dx =  \int_{-\infty}^{\infty} g(x)h'(x)\,dx.$$ Thanks in advance","['distribution-theory', 'calculus', 'partial-differential-equations']"
362873,"Is there any meaning to an ""infinite derivative""?","I've been thinking about this: say you have an infinitely differentiable function. Then you can form a sequence $f(x), f'(x), f''(x), \cdots, f^{(n)}(x), \cdots$ and attempt to take its limit. For some functions this is easy: for $e^x$ the limit will be itself, $\sin x$ and $\cos x$ won't have a limit, every polynomial will eventually be $0$, etc. I was wondering, does this have any use? Is there any interesting interpretation of the infinite derivative, and does it existing or not tell us anything about the function?","['calculus', 'derivatives']"
362895,Help with proof that $\mathbb Z[i]/\langle 1 - i \rangle$ is a field.,"I have been having a lot of trouble teaching myself rings, so much so that even ""simple"" proofs are really difficult for me. I think I am finally starting to get it, but just to be sure could some one please check this proof that $\mathbb Z[i]/\langle 1 - i \rangle$ is a field. Thank you. Proof: Notice that $$\langle 1 - i \rangle\\ 
\Rightarrow 1 = i\\
 \Rightarrow 2 = 0.$$
Thus all elements of the form $a+ bi + \langle 1 - i \rangle$ can be rewritten as $a+ b + \langle 1 - i \rangle$. But since $2=0$ this implies that the elements that are left can be written as $1 + \langle 1 - i \rangle$ or $0 + \langle 1 - i \rangle$. Thus 
$$
\mathbb Z[i]/ \langle 1 - i \rangle = \{ 0+ \langle 1 - i \rangle , 1 + \langle 1 - i \rangle\}.
$$ This is obviously a commutative ring with unity and no zero-divisors, thus it is a finite integral domain, and hence is a field. $\square$","['ring-theory', 'self-learning', 'abstract-algebra', 'ideals', 'field-theory']"
362899,Convergence of $\prod_{n=1}^\infty(1+a_n)$,"The question is motivated by the following exercise in complex analysis: Let $\{a_n\}\subset{\Bbb C}$ such that $a_n\neq-1$ for all $n$. Show that if $\sum_{n=1}^\infty |a_n|^2$ converges, then the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges. One can get a proof by using $|a_n|^2$ to bound $|\log(1+a_n)-a_n|$. Here is my question : is the converse of this statement also true? If ""the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges"", then $\sum_{n=1}^\infty |a_n|^2$ converges.","['sequences-and-series', 'infinite-product', 'complex-analysis']"
362911,What does it mean for elements to be algebraically independent?,"Wikipedia's definition: ""In abstract algebra, a subset S of a field L is algebraically independent over a subfield K if the elements of S do not satisfy any non-trivial polynomial equation with coefficients in K."" My textbook's definition: ""Let A be a subring of the commutative ring B. We say that the
elements $b_1, . . . , b_n$ of B are algebraically independent over A if the evaluation map $ε_{b_1,...,b_n} : A[X_1, . . . , X_n] → B$ that evaluates each $X_i$ at $b_i$ is injective."" I'm a bit confused about how these two definitions are related. I think wikipedia's definiton is clearer but I'm not sure how this relates to the definition in the textbook. In other words, why are we looking at this evaluation map in order to understand the definition of algebraic independence? Thanks in advance","['abstract-algebra', 'definition']"
362925,Prove that: $2^{n+1}|k^{2^n}-1$,Let's denote that $k$ is an odd number and $n\in \mathbb{N}$. Prove that: $$2^{n+1}|k^{2^n}-1$$ Could you give me any HINT how to start with this?,"['elementary-number-theory', 'discrete-mathematics']"
362933,"Creating a bijection from $(a,b)$ to $\mathbb R$ that is visually compelling","Given this ""proof without words"" from MO I am trying to: a) find a function that behaves like the function shown, on an open interval - say $(-1/2,1/2)$ b) find some intuition for why/how this function works. Given this related M.SE question and the use of the circle in the MO post, I am drawn to the tangent function. Sanity check: is $f(x) = -\tan (\pi x)$ from $(-1/2,1/2)$ to the reals, the/a function that fits the picture? Can you provide some visualization that would help me bridge the intuition gap?","['functions', 'real-analysis']"
362940,When L'Hôpital's Rule Fails,"I was discussing L'Hôpital's Rule with a Calculus I student earlier today. I mentioned that if the limit obtained by differentiating the numerator and denominator doesn't exist, then L'Hôpital's Rule tells us nothing about the original limit. A clear example of this is,
  $$\lim\limits_{ x \to \infty  }{ \frac { x+\sin { x }  }{ x }  } =1.$$
  However, L'Hôpital's Rule gives
  $$\lim\limits_{ x\rightarrow \infty  }{ \frac { x+\sin { x }  }{ x }  } =\lim \limits_{ x\rightarrow \infty  }{ \frac { 1+\cos { x }  }{ 1 }  } =\lim\limits_{ x\rightarrow \infty  }{ \left( 1+\cos { x }  \right)  }, $$
  which diverges by oscillation. I couldn't come up with an example that shows that if the limit from LH is infinite, then the original limit may be finite. This begs these two questions, Is it true that an infinite result from  L'Hôpital's Rule  does not imply an infinite limit? Is there a simple example where the LH is infinite, but the limit is actually finite?","['calculus', 'real-analysis', 'limits']"
362952,Turning an ellipse into a parabola,"Today I was discussing circles, ellipses, hyperbolas, and parabolas in my precalculus class.  We did the usual: completing the square, finding the center and radius (radii), etc. etc.  But I like to also go a little bit deeper on this topic: Algebraically, all these shapes are related by the fact their implicit equations are quadratic.  I like to show this relation geometrically by first drawing a circle, and then ""stretching"" it to make an ellipse, and then ""stretching"" it even further to make a parabola (point goes to infinity), and then ""stretching"" it even further to get a hyperbola.  I do this in the projective plane (I draw a big orange circle around the axes, which represents the line at infinity).  The students really like it. But one of my more clever students asked me what is happening to the equation as I'm doing this stretching. So if I start with the equation of the unit circle
$$ x^2+y^2=1,$$
and then I do some stretching in the vertical direction,
$$ x^2+\left(\frac{y}{b}\right)^2=1,$$
(so here stretching by a factor of $b$)
and I let $b$ get really really big , I should expect to get the equation
$$ x^2=1,$$
which is just two vertical lines (and that is what I get geometrically!). The students seem to intuitively understand this, and everyone is happy. If I want to do the parabola, I need to fix the bottom-most point at the origin, so my equation changes as
$$ x^2+\left(\frac{y-b}{b}\right)^2=1.$$
Here again I let $b$ get really really big , but now I have no idea how to explain that what I get is not $$ x^2+1=1.$$
Because, when you draw the picture, it is clear that as $b$ gets bigger and bigger, you get closer to a parabola.  But how can I show this algebraically, without going into a whole thing on limits, etc.? [This is a precalculus class.] To summarize, my question is How do I show the equation $x^2+\left(\dfrac{y-b}{b}\right)^2=1$ eventually becomes the equation of a parabola as $b\rightarrow\infty$, intuitively ? (No limits, no formal arguments please.)","['analytic-geometry', 'conic-sections', 'algebra-precalculus', 'intuition']"
362975,Concise proof that every common divisor divides GCD without Bezout's identity?,"In the integers, it follows almost immediately from the division theorem and the fact that $a \mid x,y \implies a \mid ux + vy$ for any $u, v \in \mathbb{Z}$ that the least common multiple of $a$ and $b$ divides any other common multiple. In contrast, proving $e\mid a,b \implies e\mid\gcd(a,b)$ seems to be more difficult. In Elementary Number Theory by Jones & Jones, they do not try to prove this fact until establishing Bezout's identity. This Wikipedia page has a proof without Bezout's identity, but it is convoluted to my eyes. I tried my hand at it, and what I got seems no cleaner: Proposition: If $e \mid a,b$ , then $e \mid \gcd(a,b)$ . Proof: Let $d = \gcd(a,b)$ . Then if $e \nmid d$ , by the division theorem there's some $q$ and $c$ such that $d = qe + c$ with $0 < c < r$ . We have $a = k_1 d$ and $b = k_2 d$ , so by substituting we obtain $a = k_1 (qe + c)$ and $b = k_2 (qe + c)$ . Since $e$ divides both $a$ and $b$ , it must divide both $k_1 c$ and $k_2 c$ as well. This implies that both $k_1 c$ and $k_2 c$ are common multiples of $c$ and $r$ . Now let $l = \operatorname{lcm}(r, c)$ . $l$ divides both $k_1 c$ and $k_2 c$ . Since $l = \phi c$ for some $\phi$ , we have $\phi | k_1, k_2$ , so $d \phi | a, b$ . But we must have $\phi > 1$ otherwise $l = c$ , implying $r \mid c$ , which could not be the case since $c < r$ . So $d \phi$ is a common divisor greater than $d$ , which is a contradiction. $\Box$ Question: Is there a cleaner proof I'm missing, or is this seemingly elementary proposition just not very easy to prove without using Bezout's identity?","['elementary-number-theory', 'divisibility', 'gcd-and-lcm', 'number-theory']"
363004,series involving $\log \left(\tanh\frac{\pi k}{2} \right)$,"I found an interesting series $$\sum_{k=1}^\infty \log \left(\tanh \frac{\pi k}{2} \right)=\log(\vartheta_4(e^{-\pi}))=\log \left(\frac{\pi^{\frac{1}{4}}}{2^{\frac{1}{4}}\Gamma \left( \frac{3}{4}\right)} \right)$$ Does anybody know how to approach this series using Jacobi Theta Function? Also, can any one suggest any good papers/books on Jacobi theta functions and Jacobi Elliptic functions? Thank you very much!","['sequences-and-series', 'reference-request', 'theta-functions']"
363007,Are coordinate projections continuous?,"Okay I have been working under the assumption that this is ""obvious"" for a while now, but it started to bug me and now I'm fumbling to prove it. Suppose $X$ is a normed linear space (possibly infinite dimensional). Let $\mathcal{B}$ be a Hamel basis of $X$.
Fix $b \in \mathcal{B}$.
Is the coordinate projection $P_b : X \to \mathbb{C}$ or $\mathbb{R}$ defined by $P_b(b) = 1$ and $P_b(x)=0$ for $x \notin \mathrm{span}(\{b\})$ continuous?","['vector-spaces', 'functional-analysis']"
363010,Finding formula for the nth partial sum,"A few days ago, I asked for some clarification about pattern recognition and the n-th partial sum for infinite series.  Although the explanation given was top-notch (thanks again), I'm still having difficulty with the homework.  The one I'm asking about tonight is the following sequence: $1 - 2 + 4 - 8 + ... + (-1)^{n-1}2^{n-1} + ...$ In my efforts to solve this problem, this is what I've gotten thus far:
$$
\begin{array}{lcc}
\textrm{Parial Sum} & \textrm{Value} & \textrm{Suggested Expression} \\
s_1 = 1 & 1 & ?? \\
s_2 = 1 - 2 & -1 & ??\\
s_3 = 1 - 2 +4 & 3 & ??\\
s_4 = 1 -2 +4 -8 & -5 & ??\\
\end{array}
$$ As you can see from the question marks where suggested expressions might be, I'm struggling to find the pattern.  What I do know is the formula to compute $a_n$, but I haven't discerned the pattern for the n-th partial sum.  Because this is a power of 2 series, I see that the magnitude between the values of each sum is exactly the power of 2 for the next n-1 .  That is, the distance between 1 and -1 is $2^1$ and the distance between -1 and 3 is $2^2$.  I think that within this is the key to figuring this out.  Nevertheless, the solution eludes me and I need a hint. One of my attempts was $(-1)^{n-1}*2(\frac{1}{2^{n-1}})$ which worked for the first two partial sums but then fell apart miserably.  While typing this up, I just made the further discovery that starting with $s_2$ each partial sum is equal to $2^n - m$ where m is the same number twice.  I know that probably doesn't make sense but $s_2, s_3$ are both equal to $2^n - 5$ and $s_4, s_5$ are both $2^n - 21$.  The next two are $2^n - 85$.  That can't be coincidence. Please, help me see what I'm missing or help me to understand how I should set this up to find the pattern for the n-th partial sum. Thanks,
Andy","['sequences-and-series', 'pattern-recognition']"
363012,Abelian group admitting a surjective homomorphism onto an infinite cyclic group,"I am working on the following problem: Let $G$ an Abelian group and $f: G \to \Bbb Z$ a surjective
  homomorphism. Prove that $G \cong \ker(f) \times \Bbb Z$ By means of the First Isomorphism Theorem, we can obtain that $G / \ker(f) \cong \Bbb Z$. Is there some natural way to proceed from this point, invoking probably some other theorem, or would one need to define a map and prove that is it an isomorphism? More generally, is it true that given an Abelian group $A$ and a subgroup $B$, $$A/B \cong C \Rightarrow A \cong C \times B$$ Thank you very much in advance!","['cyclic-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
363032,How do I get from $-4(x+\frac{1}{2})^2+4$ to $4-(2x+1)^2$?,"I'm trying to follow along with printed solutions to previous exam questions, and I'm completely stumped as to how this makes any sense. I had to complete the square for the function $3-4x-4x^2$, and I got $-4(x+\frac{1}{2})^2+4$. But that's not the final form I need it in because I""m trying to use the solution to integrate a function... so the solution says that I need it in the form $4-(2x+1)^2$, but I cannot figure out how to transform it to that. It could very well be because I'm a bit tired right now, but could somebody point out how it's happening?",['algebra-precalculus']
363036,"$G$ a group and $H, K\mathrel{\unlhd}G$. Assuming that $H \cap K = \{1_G\}$ and $G = \langle H, K \rangle$, prove that $G \cong H \times K$","I am trying to prove the following statement: Let $G$ be a group and $H, K\mathrel{\unlhd}G$. Assuming that $H \cap K =
 \{1_G\}$ and $G = \langle H, K \rangle$, prove that $G \cong H \times
K$. From this, we get that $HK \cong H \times K$. Naturally, it would be ideal if I could prove that $HK \cong G$. One issue that I am facing here is the meaning of $G = \langle H, K \rangle$. How is this defined (I mean, more explicitly)? Is my strategy correct or","['group-theory', 'abstract-algebra']"
363050,I need to prove a formula but I'm not sure how,"I'm working on a problem with the goal of finding a general formula and proof for the number of ways to arrange a string of 2n bits so that the number of 1's is strictly greater than the number of 0's I've figured out how to do it, but I don't know how to prove it. Here's what I have so far. To calculate it for a given number, in this case let's say 5, 2*5 = 10 so I need to do 10c6 + 10c7 +...+ 10c10 = 386 I've broken that down to (2^2n - 2n c(comb) n) / 2 For the case above that'd be (2^2(5) - 2(5) c(comb) n) /2 = (1024 - 252) / 2 = 386 Once again, my problem is I don't know how to prove it. I figure it's probably by induction, but I don't know how to do it.","['discrete-mathematics', 'probability']"
363056,Finding the zeroes of finite exponential sum,"I want to find the zeroes for functions that look like this (an example): $$f(t) = k_1e^\left(a_1t\right)+k_2e^\left(a_2t\right)+k_3e^\left(a_3t\right) ,$$ where all $a_i$ are negative real numbers, so this sum always converges to zero at infinity. With two factors of $k$ , I can simply compare both and solve it algebrically. However, I am stuck with how to do it with 3 or more factors.
This may probably be a stupid question, but it doesn't ring any bells and I couldn't find anything related on a web search. Thank you.","['exponential-function', 'algebra-precalculus', 'roots']"
363082,Determine if $x(t)$ is periodic. If periodic calculate its period.,"Determine if $$x(t) = \cos(8t) + 4 \sin(8t)$$ is periodic. If so, calculate its period.",['functions']
363086,Generally covariant Klein-Gordon equation,"Consider a 4-dimensional smooth manifold $M$ on which there is a Lorentzian metric $g_{ab}$ and a function $\phi$ satisfying the following two equations (in abstract index notation):
\begin{equation}
g^{ab}\nabla_{a}\nabla_{b}\phi - m^{2}\phi = 0,
\qquad
R_{abcd} = 0.
\end{equation}
I've been told that the covariance group of these equations is $\mathrm{Diff}(M)$, but I am having a hard time seeing it for myself.  From what I understand, this means that for any $\psi \in \mathrm{Diff}(M)$, $\psi^{*}\phi$ (and $\psi^{*}g_{ab}$?) is a solution of these equations just if $\phi$ (and $g_{ab}$?) is.  It's straightforward that $\psi^{*}R_{abcd} = 0$, but I am having a hard time showing that $\psi^{*}(g^{ab}\nabla_{a}\nabla_{b}\phi) = g^{ab}\nabla_{a}\nabla_{b}(\psi^{*}\phi)$.  Is this true?  If so, how would I go about showing that?","['physics', 'differential-geometry']"
363088,Order of the first cohomology group and subgroups,"Let $M$ be a $G$-module and $H$ a subgroup of $G$. Is $\# H^{1}(H, M) < \# H^{1}(G, M)$?","['homology-cohomology', 'group-cohomology', 'group-theory', 'abstract-algebra']"
363096,Dimension of the corresponding eigenspace?,"I'm studying for my linear exam and would appreciate any help for this practise question: You are given that λ = 1 is an eigenvalue of A. What is the dimension of the corresponding eigenspace? A = $\begin{bmatrix} 1 & 0 & 0 & -2 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ -1 & 0 & 0 & 1 \end{bmatrix}$ Then with my knowing that λ = 1, I got: $\begin{bmatrix} 0 & 0 & 0 & -2 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ -1 & 0 & 0 & 0 \end{bmatrix}$ Which I assume right off the bat means my dimension is 0. Is that correct? If not how should I do it? If we had a different matrix, how would I go ahead to properly find the dimension?
In layman terms I think that it would be whichever value is linearly independent? Thanks for the help.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
363099,The Starry Rebound,"An (infinitely small) ball starting out in the middle of a 5 pointed star table (outer 5 points 10m radius, inner 5 points 5m radius) has a starting angle of a random value from 0 to 360 degrees. The ball is now set loose and travels around the table.
On average, how many sides will have been hit once the ball has traveled 1000 m ?","['dynamical-systems', 'geometry', 'probability']"
363118,How we do actually compute the topological index in Atiyah-Singer?,"I am taking a lectured class in Atiyah-Singer this semester. While the class is moving on really slowly (we just covered how to use Atiyah-Singer to prove Gauss-Bonnet, and introducing pseudodifferential operators), I am wondering how practical this theorem is. The following question is general in nature: Suppose we have a PDE given by certain elliptic differential operator, how computable is the topological index of this differential operator? If we give certain boundary conditions on the domain (for example, the unit circle with a point removed, a triangle, a square, etc), can we extend the $K$-theory proof to this case? I know the $K$-theory rhetoric proof in literature, but to my knowledge this proof is highly abstract and does not seem to be directly computable. Now if we are interested in the analytical side of things, but cannot compute the analytical index directly because of analytical difficulties, how difficult is it to compute the topological index instead? It does not appear obvious to me how one may compute the Todd class or the chern character in practical cases. The question is motiviated by the following observation: 
Given additional algebraic structure (for example, if $M$ is a homogeneous space, $E$ is a bundle with fibre isomorphic to $H$) we can show that Atiyah-Singer can be reduced to direct algebraic computations. However, what if the underlying manifold is really bad? What if it has boundaries of codimension 1 or higher?How computable is the index if we encounter an analytical/geometrical singularity?(which appears quite often in PDE). On the other hand, suppose we have a manifold with corners and we know a certain operator's topological index. How much hope do we have in recovering the associated operator by recovering its principal symbol? Can we use this to put certain analytical limits on the manifolds(like how bad an operator on it could be if the index is given)?","['topological-k-theory', 'partial-differential-equations', 'algebraic-topology', 'differential-geometry']"
363119,Why do prime numbers in modulo result in more uniform distributions?,"Let us assume a sequence as follows: $S_{n} = (S_{n-1} * c_{1} + c_{2})\text{ mod } m$ This is the pseudorandom generator found in most programming languages' random function. It is known that a prime $m$ results in a more uniform distribution of random numbers, as a result of a larger period for $S_{n}$. As a result, $m$ is typically a prime number. Why do prime numbers typically result in larger periods than factorable numbers for modulo arithmetic?","['uniform-distribution', 'number-theory']"
363133,Is there a problem in studying analysis before calculus? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question Is there a problem in studying analysis before calculus? Most people say that analysis is rigorous calculus, the university I'm studying teaches calculus first because they believe it's better for the student to have a intuitive background (which is obtained with calculus) and the go to analysis but I've seen some other universities that teach analysis first, for undegraduate levels. I decided to study analysis first and I'm being able to understand it, I'm just not sure if any loss is made by not studying calculus. What could also be a nice alternative would be to study some Springer books on calculus and analysis, what do you think? EDIT: One of the doubts I also have is if I'll be able to use calculus if studying only analysis.","['self-learning', 'calculus', 'real-analysis']"
363209,"Understanding the definition of Lie bracket of vector fields as $[X,Y](f)=X(Y(f))-Y(X(f))$","The Jacobi-Lie bracket or simply Lie bracket, $[X,Y]$, of two vector
  fields  $X$ and $Y$ is the vector field such that $[X,Y](f) = X(Y(f))-Y(X(f)) \,.$ ( http://en.wikipedia.org/wiki/Lie_bracket_of_vector_fields ) So for the right-hand side, for $X(Y(f))$, do we evaluate $Y(f)$ first, then evaluate $X$ at position $Y(f)$? I can only think this way. If it is wrong, please tell me. Also, for $\left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)}$, does this mean that $(\mathrm{d}\Phi^X_{-t})$ is evaluated with vector  $Y_{\Phi^X_t(x)}$ and then differentiate with regard to $t=0$?","['differential-geometry', 'lie-algebras', 'abstract-algebra']"
363222,Expressing $\cos\theta - \sqrt{3}\sin\theta = r\sin(\theta - \alpha)$,"My book explains that $a\cos\theta + b\sin\theta$ is a sine (or cosine) graph with a particular amplitude/shift (i.e. $r\sin(\theta + \alpha)$) and shows me some steps to solve for $r$ and $\alpha$: $$r\sin(\theta + \alpha) \equiv a\cos\theta + b\sin\theta$$ $$\Rightarrow r\sin\theta\cos\alpha + r\cos\theta\sin\alpha \equiv a\cos\theta + b\sin\theta$$ I see the basic trig identity $\sin(a + b) \equiv \sin a\cos b + \sin b\cos a$ is being used, and the coefficients $a$ and $b$ are easily identified as: $$r\sin\alpha = a$$
$$r\cos\alpha = b$$ Then the book squares and adds the equations: $$r^2(\sin^2\alpha + \cos^2\alpha) = a^2 + b^2 \Rightarrow r = \sqrt{a^2 + b^2}$$ I see that the basic identity $\sin^2\alpha + \cos^2\alpha \equiv 1$ is being used here. All the examples in the book involve $r$ being a positive quantity. An exercise asks me to express $\cos\theta - \sqrt{3}\sin\theta$ in the form $r\sin(\theta - \alpha)$. I tried this and ran into problems as the squaring and square rooting process only ever produces a positive $r$, but the answer is $-2\sin(\theta - \frac{1}{6}\pi)$. My workings: $\cos\theta - \sqrt{3}\sin\theta = r\sin(\theta - \alpha) = r\sin\theta\cos\alpha - r\sin\alpha\cos\theta$ $\Rightarrow r\cos\alpha = -\sqrt{3}$, $r\sin\alpha = -1$ $\Rightarrow r^2\cos^2\alpha = 3$, $r^2\sin^2\alpha = 1 => r^2(\cos^2\alpha + \sin^2\alpha) = 4$ $\Rightarrow r^2 = 4 \Rightarrow r = \pm2$. My question is how should the process in the book be refined so one knows whether $r$ should be positive or negative? (sorry if this is a bit long winded for such a basic question but I thought showing what I do and don't know might get me an answer targeted at my simple level!).",['trigonometry']
363226,Very curious sequence of integrals $I_n=\int_0^1 \frac {(x(1-x))^{4n}} {1+x^2}\mathrm dx$,"I was studying the behaviour of very curious sequence of integrals 
$$I_n=\int_0^1 \frac {(x(1-x))^{4n}} {1+x^2} \,\mathrm dx$$ which gives a very beautiful result for $n=1$; I tried to calculate for different values of $n$ but every time what I get is a $4^{n-1}$ times $\pi$ along with a fraction that in the denominator has almost a product a consecutive primes, Can we generalize this pattern? Any help would be appreciated! Here are few calculations: $$
I_1=22/7-\pi
$$ $$
I_2=-\frac {2^2 \cdot 43\cdot 1097} {3\cdot 5\cdot 7\cdot 11 \cdot 13} +4\pi
$$ $$
I_3=\frac {13\cdot 31\cdot 13912991} {3\cdot 5\cdot 7\cdot 11\cdot 13\cdot 17\cdot 19\cdot 23}-16\pi
$$","['integration', 'number-theory']"
363231,plane cubic with a singularity must have non-constant morphism from $\mathbb{P}^1$?,"If $C$ is a plane projective curve which is defined by an irreducible homogeneous cubic polynomial and has a singularity, why must there be a nonconstant morphism $\mathbb{P}^1\rightarrow C$? (I'm not sure whether $C$ is supposed to have exactly one singularity; is the result still true if it has more than one?) I think the proof should look something like this: let $\alpha$ be the projection map from a singularity $P$ of $C$ onto $\mathbb{P}^1$. This is a rational map of degree 1 (why?), so it has an inverse rational map $\alpha^{-1}$ from $\mathbb{P}^1$ to $C$ (why?), which must be a morphism since $\mathbb{P}^1$ is smooth. But there's two points I can't prove! If we choose coordinates so that $P=[0:0:1]$, then $\alpha([x:y:z])=[x:y]$, so $\alpha$ has domain $C\backslash\{P\}$, and its degree is the sum of ramification indices and therefore at most 3; but why must it be 1? Then given a rational map of degree 1 between two projective curves, why does it need to have a well-defined inverse? Many thanks for any help with this!","['projective-space', 'algebraic-geometry', 'algebraic-curves']"
363234,Existence of limit in $\mathbb R^2$,"I want to prove for a function from $\mathbb{R}^2$ to $\mathbb{R}^2$, its limit at 0 exists. Is it enough to prove that the limit exists and same if we approach $0$ through the all the lines starting at $0$ of various slopes? Thanks.","['multivariable-calculus', 'complex-analysis', 'real-analysis', 'analysis']"
363237,How to find the eigenvalues and Jordan canonical form of this matrix,"Question: let $a_{i,j}\in R,A=(a_{i,j})_{n\times n} $,and 
$a_{i,j}=\begin{cases}
1&i+j\in\{n,n+1\}\\
0&i+j\notin\{n,n+1\}
\end{cases}$ that's meaning:
$$A=\begin{bmatrix}
0&0&0&\cdots&0&1&1\\
0&0&0&\cdots&1&1&0\\
0&0&\cdots&1&1&0&0\\
\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots\\
0&1&1&\cdots&0&0&0\\
1&1&0&\cdots&0&0&0\\
1&0&0&\cdots&0&0&0
\end{bmatrix}_{n\times n}$$ Problem (1): Find the Jordan canonical form of $A$. I know this matrix Jordan is 
$$diag(\lambda_{1},\lambda_{2},\cdots,\lambda_{n})$$ where $\lambda_{i}$ is eigenvalue But this problem key find the eigenvalue is hard, Thank you.maybe this problem is not easy,But I hope see someone can solve it.Thank you very much!","['matrices', 'linear-algebra', 'trigonometry']"
363240,Equivalence of seminorms of Schwartz space,"I have seen the definitions of the family of seminorms defined on Schwartz spaces vary slightly in literature. For example the following $$\rho_{a,b}(f) = \sup_{x\in \mathbb{R}^n}|x^aD^bf(x)|,$$ $$\hat{\rho_{a,b}}(f) = \sup_{x\in \mathbb{R}^n}|x|^{|a|}|D^bf(x)|$$ and $$\tilde{\rho_{a,b}}(f) = \sup_{x\in \mathbb{R}^n}(1+|x|)^{|a|}|D^bf(x)|,$$ where $x\in\mathbb{R}^n$, and $a$ is multiindex. How can I show the equivalence of these definitions? And another question would be whether we have $$\sup_{a,b\in\mathbb{N}}\rho_{a,b}(f)=M<\infty$$ for $f\in\mathcal{S}(\mathbb{R}^n)$. Thank you.","['fourier-analysis', 'analysis']"
363252,Trace of the matrix power,"Say I have matrix $A = \begin{bmatrix}
a & 0 & -c\\
0 & b & 0\\
-c & 0 & a 
\end{bmatrix}$. What is matrix trace tr(A^200) Thanks much!","['trace', 'matrices', 'exponentiation', 'determinant']"
363258,"If a topological space is a path-connected, it is also connected. The converse fails. Can this be remedied?","If a topological space is a path-connected, it is also connected. However, the converse of this theorem is false. Can we generalize the notion of a path so that the converse also holds? I was thinking that maybe if the domain of a path was allowed to be an arbitrary connected totally ordered set, this might fix the problem. EDIT . As Brian M. Scott explains in his answer, this doesn't fix the problem; so here's a last ditch-effort at salvaging the idea. Definition: A connected path in a topological space $X$ is a mapping $\gamma : T \rightarrow X,$ that preserves connectedness under direct images, where $T$ is a connected totally ordered set possessing both a least and a greatest element. Note in particular that $\gamma$ needn't be continuous. Can anyone see whether this fixes the problem or not? We want to be able to prove that a topological space is path connected iff it is connected. Anyway, here's the motivation. The problem, as Brian explains, is that a connected linearly ordered space with endpoints is compact, so the continuous image of such a space is also compact and connected. This is a problem, because: No compact, connected subset of the topologist’s sine curve contains the origin and at least one other point of the curve, and There exist countably infinite connected Hausdorff spaces, and there are no paths between distinct points in such a space; because if such a path existed, its image would be a compact countably infinite connected Hausdorff space with at least two points, and no such space exist. So the problem seems to be the compactness of the image of the path, which is implied by the compactness of the domain, because the path is defined as a continuous function. Thus, weakening the requirement that paths need to be continuous might fix the problem.","['general-topology', 'connectedness']"
