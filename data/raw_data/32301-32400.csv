question_id,title,body,tags
305945,$\int_0^{\infty} \frac{\sin(x)}{ \sqrt{x}}dx$ [duplicate],"This question already has answers here : Proof of $\int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}$ (8 answers) Closed 9 years ago . I want to know how to solve this using contour integration: $$\int_0^{\infty} \frac{\sin(x)}{\sqrt{x}}dx.$$ So I let the integral become: $$\oint_c \frac{\sin(z)}{\sqrt{z}}dz$$ where c is a ""half doughnut"" shape avoiding the singularity at z = 0 and extending into the upper half of the complex plane towards infinity. $$\oint_c = \int_{up} + \int_{-R}^{- \epsilon} + \int_{low} + \int_ {\epsilon}^R = 0$$ 
(Because no singularities are actually contained within the contour.) By a bound argument, the $\int_{up}$ contributes nothing to the integral. Therefore: $$\lim{R \to \infty}, {\epsilon \to 0}$$ $$- \int_{low} = \int_{- \infty}^{\infty} $$ Where $\int_{low}$ is the integral over the bump going over the point z = 0. So can I use the Cauchy Integral theorem to say $$\int_{low} = \pi i\, \text{Res} \left( \frac{\sin x}{ \sqrt{x}}, 0 \right)$$ Because there is no residue for this function, which would imply the integral is zero, which I know it is actually $\sqrt \frac{ \pi}{2}$.","['integration', 'complex-analysis']"
305948,A question on immersions,"I am facing the following problem: Let $\alpha:\mathbb{R}\rightarrow\mathbb{R}^2$ and $\beta:\mathbb{R}\rightarrow\mathbb{R}^2$ be $C^1$ curves with $\alpha(0)=(0,0)=\beta (0)$, such that $\alpha '(0)$ and $\beta '(0)$ are linearly independent. Show that there are open sets $U$ and $V$ in $\mathbb{R}^2$ and a $C^1$ diffeomorphism $\phi :U\rightarrow V$ such that $\phi(0,0)=(0,0)$, $\phi (\alpha(x))=(x,0)$ and $\phi (\beta (y))=(0,y)$ whenever $\alpha (x)$ and $\beta (y)$ are in $U$. Using the Theorem for Local Form of Immersions (I don't know the english name for this theorem, I'm using a portuguese Analysis book and haven't found it elsewhere in the internet) I can find $C^1$ homeomorphisms $h_\alpha:\mathbb{R}^2\rightarrow\mathbb{R}^2$ and $h_\beta:\mathbb{R}^2\rightarrow\mathbb{R}^2$ such that $h_\alpha\circ\alpha (t) = (t,0)$ and $h_\beta \circ \beta (t)=(0,t)$. Now, I'm trying to define a function $h:\mathbb{R}^2\rightarrow\mathbb{R}^2$ such that it solves the problem; it should involve $h_\alpha$ and $h_\beta$ though I don't know how to assemble these parts together. Any help would be appreciated.","['real-analysis', 'analysis']"
305949,Derivative of floor function,I thought the derivative of function $\text{floor}(x)$ should be $\infty$ for integer values of $x$ and 0 elsewhere. But wolframalpha plot showed something different. Is there any explanation?,"['wolfram-alpha', 'calculus']"
305953,The derivative of Multivariate function,"For Multivariate function
$$f(x,y)=x^3+y^3$$
How to express $$f''(x,y)$$","['multivariable-calculus', 'calculus', 'derivatives', 'real-analysis']"
305968,Integral of a weird trigonometric function,"I'm been trying to figure this out for hours, but no success. Can anyone take a look at it? Thanks a lot! $$\int\frac{1}{\sin2x + \cos2x}dx\qquad\text{Hint: start by evaluating }\int\frac{1}{\sin x + \cos x}dx$$","['trigonometry', 'calculus', 'integration']"
305974,What is the Nash Equilibrium of the Monty Hall Problem?,"The Monty Hall problem or paradox is famous and well-studied. But what confused me about the description was an unstated assumption. Suppose you're on a game show, and you're given the choice of three
  doors: behind one door   is a car; behind the others, goats. You pick
  a door, say No. 1, and the host, who knows what's behind the doors,
  opens another door, say No. 3, which has a goat. He then says to you,
  ""Do you want to pick door No. 2?"" Is it to your advantage to switch
  your choice? The assumption is that the host of the show does not have a choice whether to offer the switch. In fact, Monty Hall himself, in response to Steve Selvin's original formulation of the problem, pointed out that as the host he did not always offer the switch. Because the host knows what's behind the doors, it would be possible and to his advantage to offer a switch more often to contestants who guess correctly. If he only offered the switch to contestants who guess correctly, all contestants who accept the offer would lose. However, if he did this consistently, the public would learn not to accept the offer and soon all contestants who first guess correctly would win. If, for instance, he gave the offer to one third of incorrect guessers and two thirds of correct guessers, 2/9 contestants would be given the offer and should not switch and 2/9 contestants would be given the offer and should, which would bring the chances of winning back to 1/2 whether one accepts the offer or not, instead of 1/3 or 2/3. Is this a Nash equilibrium for the Monty Hall problem (or the iterated Monty Hall problem) as a two-player zero-sum game?  And if not, what is it, or aren't there any?","['game-theory', 'nash-equilibrium', 'probability', 'monty-hall']"
305988,Partition an integer $n$ into exactly $k$ distinct parts,"I know how to find the number of partition into distinct parts, which is necessarily equal to the number of ways to divide a number into odd parts. I also know how to partition n into exactly k parts. However, combining the two restrictions, if you limit the number of summands and also say that each summand is unique, then I cannot find a method to either evaluate/approximate this quantity. Please give me some hints or links for the solution.","['integer-partitions', 'combinatorics']"
305989,How do I show that the sum of two random variables is random variable?,"How do I prove the following? If $X$ and $Y$ are random variables on a probability space $(\Omega, F, \mathbb P)$, then so is $X+Y$. The definition of a random variable is a function $X: \Omega \to \mathbb R$, with the property that $\{\omega\in\Omega: X(\omega)\leq x\}\in F$, for each $x\in\mathbb R$. Furthermore, how to approach $X+Y$ and $\min\{X, Y\}$?","['probability-theory', 'proof-writing', 'probability']"
305997,Does the square of uniform distribution have density function?,"$X\sim U[0,1]$ and $Y\sim U[-1,1]$ are two uniform-distributed R.V.'s. Are $X^2$ and $Y^2$ still uniform? Do they have explicit probability density funtion?",['probability']
305998,Punctured plane algebraic over a finite field?,"I've been asked to prove, by my algebraic geometry teacher, that the punctured affine plane $\mathbb{A}_k^2 \backslash \{0,0\}$ is not an algebraic set, i.e. is not the zero set of any set of polynomials, even in the case of a non-algebraically closed field. I was going to proceed by showing that it has the same ring of regular functions as $\mathbb{A}_k^2$, then use the fact that we have a bijection between maximal ideals of the ring of regular functions and points of the algebraic set, then say that there is no maximal ideal in $\mathbb{A}_k^2 \backslash \{0,0\}$ corresponding to the maximal ideal in $\mathbb{A}_k^2$ corresponding to the origin i.e. the bijection between the sets misses the origin. However, let $k$ be finite and let $a_1,...,a_l$ be its nonzero elements. Define $p(x, y) = \prod(x-a_i)(y-a_i)$. Clearly $p(a,b) = 0$ if at most one of $a, b$ are zero, and $p(0, 0) \neq 0$ as $k$ is in specific a domain. Then we have that $V(p) = \mathbb{A}_k^2 \backslash \{0,0\}$. What am I missing here? Do any of the results I wanted to use break down in the case of finite fields? The definitions I'm using: a set is algebraic if it is the zero locus of an ideal $I$ of A = $k[x_1,...,x_n]$, in which case the ring of regular functions is $A/I$ (or equivalently a function is regular on an algebraic set if it is the restriction of a polynomial on $\mathbb{A}_k^n$ to the set). I do not think I'm assuming that the field is algebraically closed; there are other problems in the same assignment that expressly say to separate finite and infinite cases.","['commutative-algebra', 'algebraic-geometry']"
306003,Normal subsets of a Sylow p subgroup are conjugate if and only if they are $N_G(P)$ conjugate.,"The following is a question from Dummit & Foote. Prove that if $U$ and $W$ are normal subsets of a Sylow $p$-subgroup
  $P$ of a finite group $G$ then $U$ is $G$-conjugate to $W$ if and only
  if $U$ is $N_G(P)$-conjugate to $W$. Ofcourse G-conjugate means, there exists a $g 
\in G$ such that $gUg^{-1}=W$, and for $N_G(P)$ conjugate the element is restricted to $N_G(P)$. The reverse implication is obvious. But I havent been able to prove the implication. D&F gives the hint that $N_P(U)=N_P(W)=P$, but I have not idea how this can be used to get information about $N_G(P)$. Any help will be appreciated. Thanks!","['sylow-theory', 'group-theory', 'abstract-algebra']"
306011,"Integral $\int_0^{\infty} \sin(x^2)/x^2\,dx$","Does anyone have  a proof for $$\int_0^{\infty}\frac{\sin(x^2)}{x^2}\,dx=\sqrt{\frac{\pi}{2}}.$$
I tried to get it from contour integrating $$\frac{e^{iz^2}-1}{z^2},$$ but failed.
Thanks.","['integration', 'analysis']"
306027,Integral of type $\displaystyle \int\frac{1}{\sqrt[4]{x^4+1}}dx$,How can I solve integral of types (1) $\displaystyle \int\dfrac{1}{\sqrt[4]{x^4+1}}dx$ (2) $\displaystyle \int\dfrac{1}{\sqrt[4]{x^4-1}}dx$,"['calculus', 'indefinite-integrals']"
306033,"Another about limits, vertical asymptote","I am asked to find the vertical asymptotes if any of the following rational function: $$\begin{align} y= (x^2-1)/(x^2-x)\end{align}$$ so what I do is first of all is to find the domain of the function, so $$\begin{align}x^2-x=0\end{align}$$ to find the solution to that I factorize the expression and I get $$\begin{align}x(x-1)\end{align}$$ so the values I get are $0$ and $1$, now what I would do is to plug the values $0$ and $1$ into the function, I do that as the numerator can not be factorized. by putting $1$ I get $0/0$ and by putting $0$ I get $k/0$, so I would say that only $0$ is a vertical asymptote, so my question is the way I am proceeding is it the right one to find vertical asymptotes if any? i.e looking for domain of the function factorize if possible the numerator plug the results given in step 1 into the rational function and I will only get rational asymptote in those values which give me a
rational function of the form $k/0$ and I discard those ones, as
vertical asymptotes, which give me a a rational function of the form
$0/0$ Is that right? Thanks!",['functions']
306044,The possible number of zero entries in $n\times n$ matrix that would make the determinant non-zero,"While preparing an exam, I found the following question: What is the largest possible number of zero entries in any $5 \times 5$
  matrix with a non-zero determinant? 25 15 16 20 I know that the answer is 20, but why? I can find the formula or the theorem that makes that answer true. Any help please?","['matrices', 'determinant']"
306072,Optimal Yahtzee (Dice roll) decisions: Probability and weighting choices,"I'm a senior in computer science, and I have a hobby of taking on little projects that I find interesting. My current one is a Yahtzee optimal play solver. One would enter their current roll, and it would tell you if/what to hold onto and what to reroll (if any). It will then tell you what field to put your score in after the potential 2 re-rolls of varying sizes. So far, I've come up with the following: I realize calculating the probabilities for all possible configurations takes a lot of math, like ""Probability of yahtzee if you can reroll twice"" is about 1/29. But the probability with just one roll is 1/7776. Big difference. So I am going to write a simulation for ~1 billion random plays to see the (nearly accurate) odds of certain outcomes are after three rolls. So we can assume probabilities of outcomes are out of the way. I plan to create something like this: 
Consider a very concrete non-ambiguous example of just numbers. Say your value is 20. If you reroll (in this particular way), you have a 30% chance at 30, a 25% chance at 20, a 35% chance at 5, and a 10% chance at 80. Expected net = E(gain) - E(Loss) = Sum E(val_i - val). So we have E(change/net) = .3*(30 - 20) + .25*(20 - 20) + .35*(5 - 20) + .10*(80 - 20) = 5.75. So odds are if we make the roll, we will get 25.75 instead of our current 20. This is awesome and works great for this nice simple case... but when we speak of yahtzee, it isnt so simple. For instance, we have four of a kind for, say, 5's. We also have a 5's place on the scoreboard. So if we have a 30% chance at 4 of a kind, we also have a 30% chance at four 5's. The point i'm trying to make is that your percentages wont add up to 100%. You could normalize them, but then you run into the problem of reducing weight on ""something you would pick if you got it"" which lowers the expected net value. For instance, say you have 1 1 2 2 3. If you rerolled the 3 to a 1, a 1/6 chance, you could either take the 25 point full house or the 3 point 1's. If we normalized, it would have a < 1/6 chance for full house and < 1/6 for 1's, depending on how many other % are in this normalization. So we are weighting the full house less simply because a paralell case exhists, even though you would likely choose the full house and not the 3 1's (I hope i'm making sense and not just rambling...) . Anyway, i would love if one of your brilliant minds could help me think of an elegant way to do this. That is, given a roll of 5 dice and one of the 31 possible ways to hold back dice and reroll the others, which of the reroll configurations should you do, or should you not reroll (the 32nd choice). This is the ""high level' way of saying this. The lower level version is ""Given the 32 choices (31 ways to reroll, 1 way to not reroll), which will give you the optimal score?"". I got the 32 from (5 choose 0) ways to reroll no dice + (5 choose 1) ways to reroll 1 dice, etc to (5 choose 5) ways to roll 5 dice. I'm just looking for some insight on how to weight your decisions appropriately. My hunch is that you have to do a bit of tricky manipulation such that if you have overlapping cases, you take the maximal case? (Ie. Three 1's vs. a full house with 1 1 1 2 2 after rerolling the 3 in 1 1 3 2 2, you would take that chance multiplied by the full house value, and not put any weight to the 3 1's. This of course assumes we need both a FH and 1's. If you didn't need a full house, it wouldnt even be in the equation). Thanks everyone who takes the time to read this :). John [Edit:] Thanks again for your help. I'm pretty sure I know how to do this now, but I wanted to run it by you to make sure im not misunderstanding anything. I know that you cant fit the entire game tree, but im just writing this in general assuming we had infinite memory. I know i'd actually only be able to use this with some initial non-blank states. Begin algorithm We have 13 boxes, each with a certain number of states. 
When we make the tree, we start with all states initialized to ""nothing"", and simply proceed to do all possibilities of the states which gives us all possible end states when completed. Let us look at one such ""leaf"" node, which is at the end of a completed path through our tree. In order to backtrack up the tree and give nodes values (scores), we start here. This nodes value is the sum of all scores in all boxes. To give its parent a value though, we set our value(score) to val := (val - stateScore) + (stateScore*probStateScore); This, from the parents point of view, takes away the guarenteed gain from that node state and changes it to the expected value (since we havent gotten that state yet, it is no longer a given but a probability). So if this nodes value is 300, and the gained score from its last choice was 50 with a probability of 10%, you would set your value to 250 + 5 = 255. Now, you parent takes the max of all its children and sets its own value to val := (max(children) - thisNodesStateScore) + thisNodesStateScore*probOfThisStateScore; By the time we get to the top, we have a set of nodes (first tier of the tree) with the optimal expected values should you pick them. When playing the game, we may roll perhaps a 1 1 2 1 5. We can classify this as a 0 in any state, a 3 of a kind of ones = scoreState(10), 3 ones = scoreState(3), one 5 = scoreState(5), or one 2 = scoreState(2). We observe which of the values of these states is maximal, and choose that state. Continue until the end of the game. End algorithm If this is right, my question was how does the 3 rolls come into this? If you roll 1 1 2 15 and you have 2 rolls left, how do you give the optimal setup to hold and reroll based on the optimal values in the tree? Again, we can assume we know all probabilities of rolling a given setup. Thanks again, and I apologize that this question was so long and time consuming.","['optimization', 'computer-science', 'discrete-mathematics', 'probability']"
306076,Minimum number of zeroes of $g(x)=(f'(x))^2+f''(x)f(x)$?,"If $f(x)$ is a twice differentiable function such that
$f(a)=0,f(b)=2,f(c)=-1,f(d)=2,f(e)=0$
where $a<b<c<d<e,$ then how many minimum number of zeroes does $g(x)=(f'(x))^2+f''(x)f(x)$ have in the interval $[a,e]?$ What way do I attempt a solution??","['calculus', 'derivatives']"
306081,How prove $(A\triangle B)\triangle C=A\triangle(B\triangle C)$ by defining function from $(A\triangle B)\triangle C$ to $A\triangle(B\triangle C)$,How do you prove $(A \triangle{}B) \triangle{}C=A \triangle{}(B \triangle{}C)$ by defining  function from $(A \triangle{}B) \triangle{}C$ to $A \triangle{}(B \triangle{}C)$ ? $(A \triangle{}B:=A\cup B-(A\cap B)$ ) I know this proof : let $x\in(A \triangle{}B) \triangle{}C$ the show that $x \in A \triangle{}(B \triangle{}C)$ and  similarly prove $x\in A \triangle{}(B\triangle{}C)$ then $x \in (A \triangle{}B) \triangle{}C.$ Thanks in advance.,['elementary-set-theory']
306089,Evaluating $\lim_{x \to 0+} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right] $?,"For $x>0$, $$\lim_{x \rightarrow 0} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right]
$$These are two forms of $0^\infty$ and $\infty^0$. I know these are to be evaluated separately and then added. But how do I start?","['calculus', 'limits']"
306109,Green's function for the Yamabe problem,"I'm currently reading the paper on the Yamabe problem by Lee and Parker, and am looking for a reference for Theorem 2.8. Theorem 2.8 (Existence of the Green Function). Suppose $M$ is a compact Riemannian manifold of dimension $n\ge 3$ , and $h$ is a strictly positive smooth function on $M$ . For each $P\in M$ , there exists a unique smooth function $\Gamma_P$ on $M\setminus \{P\}$ , called the Green function for $\Delta + h$ at $P$ , such that $(\Delta + h)\Gamma_P = \delta_P$ in the distribution sense, where $\delta_P$ is the Dirac measure on $P$ . Does anyone know where I might find out about general existence results for Green's functions (in particular this one)? Thanks!","['differential-geometry', 'manifolds', 'partial-differential-equations', 'reference-request', 'conformal-geometry']"
306116,The free group $F_2$ contains $F_k$,"I want to prove the following: the free group $F_2$ contains the free group $F_k$ for every $k \geq 3$. I am wondering whether the following line of reasoning is correct or not: Suppose that $\lbrace a, b \rbrace$ is a free generating set of $F_2$. Define $S := \lbrace aba^{-1}, \cdots, ab^{k}a^{-1} \rbrace$ and let $F(S)$ be the free group with free generating set $S$. Then $F(S)$ is a free group on $k$ generators and since every reduced word of $F(S)$ collapses to a reduced word of $F(a, b)$ (for example $(aba^{-1})(ab^4a^{-1}) = ab^5a^{-1}$) it follows that $F(S) \subseteq F(a, b)$.","['free-groups', 'group-theory', 'abstract-algebra']"
306146,Least power. Squares again,"$a(a+1)(a+2)(a+3) + 1$ is a square for all $a\ge1$. Are there more products of $k$ consecutive positive integers plus a known $m$ number, that are always square: $a(a+1)(a+2)(a+3)\cdots(a+k-1) + m$ is a square for all $a$ given $m$ and $k$? If the answer is negative, is there a way to prove it ?",['number-theory']
306151,A problem on left skip free random walk with downward drift,"Let $X_i$, $i \geq 1$ be i.i.d random variables. Let $P_j=P(X_i = j)$ and suppose that $$\sum_{j=-1}^{\infty} P_j=1$$. That is the possible values of the $X_i$ are $-1,0,1,\dots$. If we take $$S_0=0, S_n=\sum_{i=1}^{n}X_i$$ then the sequence of random variables $S_n, n\geq 0$ is called a left skip free random walk. Also, $E[X_i] < 0$ (downward drift). We need to prove that $$P(S_n <0, \forall n \geq 1)= P(S_n \neq 0, \forall n \geq 1)$$","['random-walk', 'probability']"
306161,Limit $\lim_{x\to\infty}\left(\frac{\ln x}x\right)^{1/x}$,"I have to find the limit of the next thing: $$\lim_{x\to\infty}\left(\frac{\ln x}x\right)^{1/x}$$ I think about: $y = \ln(x)$ and then $x = e^y$, but it will be so long. please help!","['calculus', 'limits']"
306178,Given $y_n=(1+\frac{1}{n})^{n+1}$ show that $\lbrace y_n \rbrace$ is a decreasing sequence,"Given 
$$
y_n=\left(1+\frac{1}{n}\right)^{n+1}\hspace{-6mm},\qquad n \in \mathbb{N}, \quad n \geq 1.
$$
Show that $\lbrace y_n \rbrace$ is a decreasing sequence. Anyone can help ?  I consider the ratio $\frac{y_{n+1}}{y_n}$ but I got stuck.","['sequences-and-series', 'real-analysis']"
306211,Proving that $\|A\|$ is finite.,"Let $|v|$ be the Euclidean norm on $\mathbb{R^n} $. For  $A\in \mathrm{Mat}_{n\times n}(\mathbb{R})$ we define $\displaystyle \|A\|:= \sup_{\large v\in \mathbb{R^n},\,v \neq 0}\frac{|Av|}{|v|}$. How to show that $\|A\|$ is finite for every $A$?
It would be very helpful if someone could give hints. I think I should show that $\|-\|$ is bounded,but I don't know how...",['linear-algebra']
306272,How many tetrahedrons in a tetrahedron?,"Given a regular tetrahedron. All the edges were divided into N equal segments. How many non-degenerate ($|\text{volume}| > 0$) tetrahedrons with vertices at the points of division can be built inside this tetrahedron? Vertex of given tetrahedron can't be the point of division. I'm looking for a formula. Examples:
For $N=2$, answer is $12$.
For $N=37$, answer is $65561472$.","['geometry', 'combinatorics']"
306278,How did the ancients view *infinitesimals*?,"With some category/topos theory we can now put infinitesimals on a rigorous ground, as in Bell's A Primer of Infinitesimal Analysis , where the author introduces $\epsilon$ satisfying \begin{equation}
\epsilon\ne 0, \epsilon^2=0.
\end{equation} However, he also points out that this version of infinitesimal is not compatible with the law of excluded middle . Meanwhile, the author seems convinced that this $\epsilon$ is the infinitesimal in the eyes of Newton and Leibniz among many others, when they were attacking problems like instantaneous speed and area under a curve. I wonder whether this is true. I know people like Newton and Leibniz did not use limiting argument. But this does not mean they think of infinitesimals as nilsquare elements as described by Bell, because there are still other models of infinitesimals available. Thanks very much.","['calculus', 'logic', 'math-history', 'reference-request', 'intuition']"
306309,How to show $e^{2 \pi i \theta}$ is not algebraic.,"I was wondering if someone could possibly help
me figure out how to show $e^{2 \pi i \theta}$
is not algebraic when $\theta$ is irrational. Thanks!","['number-theory', 'abstract-algebra', 'analytic-number-theory', 'transcendental-numbers', 'complex-analysis']"
306324,Interior point and Minkowski functional,"I want to prove for a convex set that contains zero a point $x$ is interior iff the value of Minkowski functional in that point is strictly less than $1$.
is there anyone to help me.","['general-topology', 'convex-analysis', 'functional-analysis']"
306326,Composition of Riemann integrable functions,"I know that if $f:[a,b]\to[m,M]$ is Riemann integrable and $g:[m,M]\to\mathbb{R}$ is continuous, then $g\circ f$ is also integrable on $[a,b]$. I'm trying to think about the following 3 cases: 1) $f$ the same, $g$ is Riemann integrable but not continuous on $[m,M]$, such that the statement is false. 2) $f:[a,b]\to\mathbb{R}$ is continuous and $g:[m,M]\to\mathbb{R}$ is bounded and Riemann integrable, then what about $g\circ f$? 3) $f$ is Riemann integrable on $[a,b]$ but not continuous, $g$ same as in 2), what about $g\circ f$? Thank you. [EDIT]:
Let $f$ be continuous on $[0,1]$, vanish on cantor set C and positive otherwise. What kind of riemann integrable bounded real $g$ will make $g\circ f$ not riemann integrable?",['analysis']
306327,Where are the values of the sine function coming from?,"On high school, I was taught that I could obtain any sine value with some basic arithmetic on the values of the following image: But I never really understood where these values where coming from, some days ago I started to explore it but I couldn't discover it. After reading for a while, I remembered that the sine function is: $$\sin=\frac{\text{opposite}}{\text{hypotenuse}}$$ Then I thought that I just needed to calculate $\frac{1}{x}$ where $0 \leq x \leq 1$ but it gave me no good results, then I thought that perhaps I could express not as a proportion of the opposite and hypotenuse, I thought I could express it as the ratio between slices of the circumference, for example: circumference $=\pi$, then divided it by $4$ (to obtain the slice from $0$ to $90$ degrees) then I came with: $x/ \frac{\pi}{4}$ where $0\leq x \leq \frac{\pi}{4} $ but it also didn't work, the best guess I could make was $\sqrt{x/ \frac{\pi}{4}}$, the result is in the following plot: The last guess I made seems to be (at least visually) very similar to the original sine function, it seems it needs only to be rotated but from here, I'm out of ideas. Can you help me?",['trigonometry']
306334,An algorithm for pairing within a set,"I have $2n$ countries and I want to pair them and have $n$ groups according to Euclidean distance, for instance, I want to minimize the sum of Euclidean distances. I have a $2n \times 2n$ symmetric matrix of distances. Is there an algorithm which allows me to do that? I have tried Hungarian, however, given that my input matrix is symmetric, the resulting matrix is not always symmetric.","['algorithms', 'combinatorics']"
306343,Subgroups of order $p$ and $p^{n-1}$ in a group of order $p^n$.,"I have a group $G$ of order $p^n$ for $n \ge 1$ and $p$ a prime.  I am looking for two specific subgroups within $G$: one of order $p$ and one of order $p^{n-1}$. I don't think I would use the Sylow theorems here because those seem to apply to groups with a ""messier"" order than simply $p^n$. Would Cauchy's Theorem allow me to generate the two requisite subgroups? I could use it to find an element of order $p$ and an element of order $p^{n-1}$ and then consider the cyclic subgroups generated by these two elements?","['p-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
306370,Analytical solution to piecewise Poisson equation in 1D,"I would like help solving the following analytically $$\frac{\partial^2 u(x)}{\partial x^2} = - p(x)$$ where $ p(x) = 
     \begin{cases}
       3 & : 0 < x  < 0.4\\
       x & : 0.5 < x < 1\\
       0 & : else
     \end{cases}
   $ and $u(0) = u(1) = 0$ Im stuck on this I have googled, and looked at textbooks, but what I would like is a worked example.
(not homework per se, something I need to understand before I attempt the homework!)",['ordinary-differential-equations']
306371,Simple proof of showing the Harmonic number $H_n = \Theta (\log n)$,"Consider the partial sum of the divergent Harmonic series $H_n = \sum\limits_{k = 1}^{n}\frac{1}{k}$. I recently saw a question which required finding out the asymptotic bounds of $H_n$. Now, I could not find any bound closer than $O(n)$. So I looked up the series and found this Wikipedia article which says that $H_n - \ln n$ approaches a constant (the Euler–Mascheroni constant ). This clearly shows that $H_n = \Theta(\log n)$. However, considering the question was in an beginners undergraduate algorithms course in CS, I was wondering if there is a simpler proof of this? Is there some clever proof requiring elementary mathematics to show $H_n = \Theta(\log n)$? PS: This is not homework in the sense that it is not my homework, and the actual question does not ask for a proof, but rather asks a lot of functions to be arranged asymptotically.","['asymptotics', 'sequences-and-series', 'harmonic-numbers']"
306373,"Gamelin's Complex Analysis, Chapter 3, Section 2, Exercise 7","I am having  a very hard time with a problem from Gamelin's Complex Analysis. Problem Statement and Hint: Show that if 0 and $\infty$ lie in different connected components of the
complement $C^*\backslash D$ of $D$ in the extended complex plane, then there
is a closed path $\gamma$ in $D$ such that $\int_{\gamma}d\theta\ne 0$. Hint. The hypothesis
means that there are  $\delta>0$ and a bounded subset $E$ of $C\backslash D$ such
that $0\in E$, and every point of $E$ has distance at least $5\delta$ from every
point of $C\backslash D$ not in $E$. Lay down a grid of squares in the plane
with side length $\delta$ and let $F$ be the union of the closed squares in
the grid that meet $E$ or that border on a square meeting $E$. Show
that $\partial F$ is a finite union of a closed paths in $D$, and that
$\int_{\partial f}d\theta=2\pi$ I've found a suggested proof online that says ""Note by construction, $\partial F\subset D$. I've attached a picture which shows my grid of squares, set $D$ and set $E$ containing 0. I've outlined in green all of the squares that meet $E$ or that border on a square meeting $E$ (I think). The union of these closed squares in the grid is called F. My first question is, how is $\partial F$, the border of $F$, contained in $D$?",['complex-analysis']
306376,Differential characterization of unknots,"How can the closed simple curves in $\mathbb{R}^3$ be characterized that can be boundaries of a 2-dimensional oriented surface in $\mathbb{R}^3$? Intuitively I would tend to say that it's exactly the family of unknots . But even if so: (how) can this family of curves be characterized - maybe by means of differential geometry, by curvatures and torsions?","['knot-theory', 'differential-geometry']"
306383,Longest consecutive subsequence bound with limit,"Let $S\subseteq \{1,2,\ldots,n\}$ and let $X(S)$ be the length of maximal consecutive subsequence in $S$. For example: if $S=\{4,5,7,8,9,11,12\}$ then $X(S)=3$ because of the subsequence $\{7,8,9\}$. Let $S\subseteq \{1,2,\ldots,n\}$ chosen uniformly from $\{1,2,\ldots,n\}$'s subsequences. I need to find a function $f(n)$, such that for any $\varepsilon>0$ we have: $$\lim_{n\to \infty}(\Pr((1-\varepsilon)f(n)\le X(S) \le (1+\varepsilon)f(n))) = 1$$","['limits', 'discrete-mathematics', 'probability', 'combinatorics']"
306385,Books for combinatorial thinking,I have looked through many discrete mathematics books but they don't put much emphasis on combinatorial thinking.What books could you recommend that are more problem-oriented and emphasize combinatorial thinking?,"['reference-request', 'combinatorics']"
306410,Nontrivial trivial integrals,"Consider two propositions in geometry: Circumscribe a right circular cylinder about a sphere.  The surface area of the cylinder between any two planes orthogonal to the cylinder's axis equals the surface area of the sphere between those two planes.  (Archimedes showed this.) Let a curve running from the south pole to the north pole on a perfectly spherical earth meet every meridian of longitude at the same angle $\gamma$.  Then the length of the curve is proportional to $\sec\gamma$.  (In particular, it's infinite if $\gamma$ is a right angle, and one could even go beyond a right angle and consider it an oriented length, so that the oriented length is negative if the curve goes from the north pole to the south pole.  In that case, the infinite length would be the $\infty$ that's at both ends of the real line rather than $+\infty$ or $-\infty$, so the length depends continuously on $\gamma$.) Both propositions admit the same kind of proof: For the first, consider what happens when the distance between the two planes is infinitesimal; then show that if it works then, then it also works for larger-than-infinitesimal distances.  For the second, show that the length of an infinitesimal increment of the curve is $\sec\gamma$ times the latitude-component of the distance, just by drawing an infinitesimal right triangle. You might think that in both cases one is finding an integral, but it's an integral of a constant: just the constant itself times the length of the interval over which one integrates.  So it's as if you don't need to know about integrals and you certainly don't need to find any antiderivatives, but the method of proof doesn't work for larger-than-infinitesimal quantities. One would like to say things like ""energy is force times distance; it is only when the force is not constant that one must use integrals and multiply the force at an instant by the infinitesimal distance and then integrate"".  But if proving the force is constant itself requires an infinitesimal viewpoint, then despite the triviality of computing the integral by multiplying two numbers, it seems necessary to the logic of the argument to view it as an integral. So: What other instances besides these two are known?  (I suspect there are many in geometry.) What else of interest can be said about this phenomenon?","['geometry', 'integration', 'infinitesimals']"
306412,Smooth path definition,"I keep getting confused with the definition of a smooth path. Here is a definition from William T. Shaw's Complex Analysis with Mathematica: A path $\phi$ is a continuous mapping from a segment of the real axis into the complex numbers; i.e. $\phi:[a,b]\rightarrow C$. A path $\phi$ is smooth if it is a differentiable path, and furthermore, the derivative map $\phi':[a,b]\rightarrow C$ is continuous. OK, now here is my path: $\phi:[-2,2]\rightarrow C$ by $\phi(t) = t^2 + i t^3$. Now, I believe it is differentiable: $$\phi'(t)=2t+i 3t^2$$ And I believe that $\phi'$ is continuous on $[-2,2]$. However, here is the image of the path: See the sharp cusp at (0,0)? This is a smooth path? I am obviously missing a subtle point. D.",['complex-analysis']
306414,If $f$ = $f^{-1}$ then $f(x) = x$ for some $x$,"I would like to know if the following suffices to prove the proposition below. While I can't see anything wrong with it, it gives me a strange feeling. Proposition: If $f$ is a continuous function on $\mathbb{R}$ and $f = f^{-1}$, prove that there is at least one $x$ such that $f(x) = x$. Proof: If there did not exist such an $x$, then we would have $f(y) > y$ or $f(y) < y$ for all $y \in \mathbb{R}$. Assume the former. In such a case, it follows that
$$ f(f(y)) > f (y) > y $$
yet by definition we have $f = f^{-1}$ and so
$$ f(f(y)) = y $$
This is a contradiction and proves the assertion.","['functions', 'real-analysis']"
306425,Expected Value Function,"My text-book defines expected value as
$$E(X) = \mu_x = \sum_{x \in D} ~x  \cdot p(x)$$ 
And so, if I was to find the expected value of a random variable $X$, where $X = 1,2,3$, then it would resemble this: 
$$E(X)= \sum_{x=1}^3~ x \cdot p(x)= 1\cdot p(1) + 2\cdot p(2) + 3 \cdot p(3)$$ 
Furthermore, if I wanted to calculate $E(X^2)$, it would be $E(X^2) = 1^2 \cdot P(1) + 2^2 \cdot p(2) + 3^2 \cdot p(3)$. My question is, why don't we square the x-values in the probability function $p(x)$? Also, is computing the expected value a way of calculating the average of the random variable? It seems a little odd to calculate it that way. PS: If any use of notation, or vocabulary, is incorrect, please inform me.","['probability', 'definition']"
306431,Birational equivalence between projective varieties is an equivalence relation,"The definition for ""birational map"" I was given was as follows: Let $V$ and $W$ be irreducible projective varieties. If $\phi$ is a dominant rational map from $V$ to $W$ and $\psi $ is a dominant rational map from $W$ to $V$ and $\phi \circ \psi$ and $\psi \circ \phi$ are identity maps (on the domains they can be defined), the $\phi$ and $\psi$ are called birational maps. $\phi$ being dominant means that $\phi(\text{dom}\phi)$ is dense in $W$. Later in the lectures I think it was assumed that birational equivalence between projective varieties was an equivalence relation, but I don't immediately see why--are the composite of dominant rational maps dominant?",['algebraic-geometry']
306452,Distributional limit,"Let $u_t(x) = t^Ne^{itx}$ for $x\geqslant 0$ and $u_t(x)=0$ elsewhere. I want to calculate the distributional limit $\lim_{t\to\infty}u_t(x)$. How would one approach such problem. I just started a little in functional analysis. Do we need to analyse $$\left\langle u_t,\phi \right\rangle = \int_{\mathbb{R}}u_t(x)\phi(x)dx ?$$
for $\phi \in C_0^{\infty}(\mathbb{R})$.
My understanding on the subject is little.","['weak-convergence', 'distribution-theory', 'real-analysis', 'limits']"
306457,Biduals generated by projections,"This question is motivated by a similar question recently posed at MO: https://mathoverflow.net/questions/122091/masas-in-second-duals-of-banach-algebras In this setting, let $B$ be a Banach algebra generated by projections , meaning that the span of all idempotents in $B$ is norm dense. Is the second dual of $B$ endowed with either Arens product generated by projections?","['operator-algebras', 'banach-algebras', 'functional-analysis']"
306458,Books at similar levels as Kallenberg' Foundation of Modern Probability?,"Thanks to many people who have mentioned it to me and others on this site before. I was just able to peek into Kallenberg' Foundation of Modern Probability. It is more comprehensive, deep and thorough than the books I have seen before. It not only covers probability theory, but also stochastic processes and calculus, random measures, point processes and other topics. I don't expect myself to understand it fully and easily at all, but I admit it is the best reference I have seen. I was wondering if you could mention other books at similar (partially) topics and/or levels as Kallenberg' book? Thanks and regards!","['probability-theory', 'stochastic-processes', 'reference-request']"
306464,Sine not a Rational Function Spivak,"This is Chapter 15 Question 31 in Spivak: a) Show sin is not a rational function. By definition of a rational function, a rational function cannot be $0$ at infinite points unless it is $0$ everywhere. Obviously, sin have infinite points that are 0 and infinite points that are not zero, thus not a rational function. b) Show that there do not exist rational functions $f_0, \ldots, f_{n-1}$ such that $(\sin x)^n + f_{n-1}(x)(\sin x)^{n-1} + \ldots + f_0({x}) = 0$ for all x First choose $x = 2k\pi$, so $f_0(x) = 0$ for $x = 2k\pi$. Since $f_0$ is rational $\implies f_0(x) = 0$ for all x. 
Thus can write $\sin x[(\sin x)^{n-1} + f_{n-1}(\sin x)^{n-2} ... +f_1(x)] = 0$ Question: The second factor is $0$ for all $x \neq 2k\pi$ How does this imply that it is 0 for all x? And how does this lead to the result?",['analysis']
306467,Expected number of steps for reaching $K$ in a random walk,"Assuming steps are $+1/-1$ with a $50/50$ probability. What is the expected step count for reaching $10, 100$ or $K$?","['random-walk', 'probability']"
306468,Perpendicular line passing through the midpoint of another line,"I have several $2d$ line segments. for example, if I take a one line segment having end points $(x_1, y_1)$ and $(x_2, y_2)$. Then, I want to make a perpendicular line which passes through the midpoint of that line segment. for the simplicity if I say mid point $(x_3, y_3)$ then, how could I derive. Any idea please. Thanks.","['geometry', 'algebra-precalculus']"
306473,The Number of Topologies on a Finite Set,"I would like to know if there is like a magical formula to know how many topologies exist on a finite set For example for $X = \{ a, b, c \}$ I found $29$, but I dont know if there are more or how to know this exact number without writing all topologies first.",['general-topology']
306480,Weighted $L^2$ Estimates for Domains $\Omega\subseteq\mathbb{C}$,"EDIT: After mrf 's comment below and some discussion with my instructor for the course it was decided that the below was not really an issue. Namely, I went into reading this lecture with the notion that we were going to solve the $\bar{\partial}$ equation--that this was our main goal. In other words, in the below we were mainly $f$ focused and not $\phi$ focused. In all actuality, it is the other way around. We were supposed to know that the $\bar{\partial}$ equation always has distributional solutions and that, in fact, we were really interested in finding solutions to $\bar{\partial}u=f$ with $u$ having controlled $\|\cdot\|_\phi$ norm. This begs two questions though that I would love if someone may be able to fill in: This is the one-dimensional case of Hormander's Theorem. Can someone give me intuition about why as an algebraic/differential geometer having Hormander's theorem is such a huge deal (as it is made out to be). mrf says that the below theorems actually show that $\bar{\partial}u=f$ is always solvable for any $f$ since we can always find (given a fixed $f$) a $C^2(\Omega,\mathbb{R})$ subharmonic function $\phi$ for which $\displaystyle \int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$ is finite (we need finiteness to actually show a solution exists). Is there an easy way to see why such a function $\phi$ always exists for a given $f$? Thanks! I am currently reading the Park City lecture notes on Analytic and Algebraic Geometry ( this book) and am really confused by some implicit assumptions made in the first lecture of the first minicourse (Lecture 1 of Bo Berndtsson's ""An Introduction to Things $\overline{\partial}$""). Let me explain some of the background to the issue I am having. Let $\phi\in C^2(\Omega,\mathbb{R})$ be subharmonic and define the inner product: $$\langle f,g\rangle_\phi=\int_\Omega f\bar{g}e^{-\phi}$$ and the norm $\|\alpha\|_\phi^2=\langle \alpha,\alpha\rangle_\phi$. We then define $\bar{\partial}^\ast_\phi$ to be the adjoint of $\bar{\phi}$ with respect to $\langle,\rangle_\phi$. Explicitly one can show that $$\bar{\partial}^\ast_\phi\alpha=-e^{\phi}\frac{\partial}{\partial z}\left(e^{-\phi}\alpha\right)$$ So, now we are trying to follow the proof of Theorem 1.1.3 in the book which is stated as follows: Theorem 1.1.3 Let $\Omega\subseteq\mathbb{C}$ be a domain and suppose that $\phi\in C^2(\Omega,\mathbb{R})$ which is subharmonic. Then, for any $f\in L^2_{\text{loc}}(\Omega)$ there is a distributional solution $u$ to $\displaystyle \frac{\partial u}{\partial \bar{z}}=f$ subject to 
  $$\int_\Omega |u|^2 e^{-\phi}\leqslant \int_\Omega \frac{|f|^2}{\Delta \phi}e^{-\phi}$$ The author states that the theorem follows from the following three propositions: Proposition 1.1.1 Given $f$ there exists a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}$ satisfying 
  $$\|u\|_\phi^2\leqslant C\quad \mathbf{(1.3)}$$
  for some $C>0$ if and only if the estimate
  $$\left\langle f,\alpha\right\rangle_\phi \leqslant C\|\bar{\partial}^\ast_\phi \alpha\|_\phi\quad\mathbf{(1.4)}$$
  holds for every $\alpha\in C^2_c(\Omega)$. , Proposition 1.1.1(cont.) For any given $\mu:\Omega\to\mathbb{R}^+$ $\mathbf{(1.4)}$ holds for all $f$ satisfying
  $$\int_\Omega \frac{|f|^2}{\mu}e^{-\phi}\, dz\leqslant C\quad\mathbf{(1.5)}$$
  if and only if 
  $$\int_\Omega \mu|\alpha|^2 e^{-\phi}\, dz\leqslant \|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.6)}$$
  holds for all $\alpha\in C^2_c(\Omega)$. and, Proposition 1.1.2 Let $\Omega\subseteq\mathbb{C}$ be a domain $\phi\in C^2(\Omega,\mathbb{R})$ and $\alpha\in C_c^2(\Omega)$. Then,
  $$\int_\Omega \Delta\phi|\alpha|^2 e^{-\phi}+\int_\Omega\left|\frac{\partial \alpha}{\partial\bar{z}}\right|^2 e^{-\phi}=\|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.7)}$$ It seems by the ease to which he claims Theorem 1.1.3 follows from these three propositions that the easy answer should be the correct one. The easier answer is that Proposition 1.1.2 shows that (1.6) holds for $\mu=\Delta\phi$. Thus, Proposition 1.1.1(cont.) implies that for every $f$ satisfying (1.5) we have that $f$ satisfies (1.4) for all $\alpha$ and thus we have a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}u=f$ satisfying (1.3). Ok, so everything seems hunky-dory, all of this goes through correctly to prove Theorem 1.1.3 if, given $f\in L^2_{\text{loc}}(\Omega)$, we could take $$C=\int_\Omega \frac{|f|^2}{\Delta\phi}e^{-\phi}$$ The only issue is that the apply the proof of Proposition 1.1.1 we apply Riesz-Fischer to a certain operator $L$, the boundedness of which follows because we obtain a bound $\|L\|_\text{op}\leqslant C$. Thus, everything breaks down if $C$ is infinite. So, all of this strongly seems to suggest that the integral $$\int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$$ is finite for every $f\in L^2_\text{loc}(\Omega)$ and every subharmonic $\phi\in C^2(\Omega,\mathbb{R})$. But, I am fairly sure this is not true (just take $\Omega=\mathbb{C}$, $\phi=x^2+y^2$, and $f=\exp(2(x^2+y^2))$). Even if we require that $f\in L^2_{\text{loc}}(\Omega)$ and $fe^{\frac{-\phi}{2}}\in L^2(\Omega)$ (which may be a possible typo) there is still doubt that this integral always converges. If anyone could provide any insight into what I am missing/what the author may have meant I would be extremely grateful.","['several-complex-variables', 'partial-differential-equations', 'functional-analysis', 'complex-analysis']"
306481,No induced ordered graph yields large clique/stable set in ordered graph,"Let $H$ be the ordered graph with three vertices $v_{1}$, $v_{2}$, $v_{3}$ (in this order) and one edge $v_{1}v_{2}$. Prove that there exists $c > 0$ such that every ordered graph $G$ not containing $H$ as an ordered induced subgraph has a clique or stable set of size at least $|V(G)|^{c}$. An ordered graph $(G,<)$ simply means a simple (unoriented) graph $G$ with a linear order $<$ of its vertex set. An ordered graph $(H,<)$ is said to be an induced subgraph of another one $(H', <')$ if there is a function $f : V(H) \rightarrow V(H')$ such that for any $u,v \in V(H)$, we have that $f(u) <' f(v)$ if and only if $u < v$ and $f(u)f(v) \in E(H')$ if and only if $uv \in E(H)$. I would like help with this if possible. I was thinking an approach using probabilities might work but I don't see it... Thanks","['graph-theory', 'extremal-combinatorics', 'combinatorics']"
306494,quotient representation -- show that it actually is a linear representation,Let $U \subset V$ be a $G$-invariant subspace and $\rho : G \to \mathrm{GL}(V)$ a linear representation. Show that $\rho_{U} : G \to \mathrm{GL}(V/U)$ with $\rho_U(g)(v+U) = \rho(g)(v) + U$ is a linear representation. So I try to show that it is a homomorphism $\rho_U(gh)(v+U) = \rho(gh)(v) + U = \rho(g) \circ \rho(h)(v) + U$ and want to get there: $\rho_U(g) \circ \rho_U(h)(v+U) \overset{?}{=} \rho(g)(v)+U \circ \rho(h)(v) +U$ Is it working like this? I feel uncomfortable in handling the v+U correctly..,"['linear-algebra', 'representation-theory', 'group-theory']"
306509,Finding the ideals in a ring of fractions,"I am dealing with the ring $$R=\left\{\frac{a}{b} \mid a,b\in\mathbb{Z}\mbox{, $b$ is not divisible by 3}\right\}$$ with addition and multiplication as defined in $\mathbb{Q}$ and I'm trying to find all the ideals of the given ring. My initial thought is to find all the additive subgroups of $(R,+)$, but I am having trouble reasoning through this step. I'm not sure how to classify all such subgroups, then to prove that these are all such subgroups. A prod in the right direction would be greatly appreciated! ~Dom","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
306518,Extension of a premeasure to a measure,"Let $X$ be any set containing more than one point and $A$ a proper
nonempty subset of $X$ . Define $S= \{A, X\}$ and the set function $\mu: S \rightarrow [0, \infty]$ by $\mu(A) = 1$ and $\mu(X) = 2$ .
Show that $\mu: S \rightarrow [0, \infty]$ is a premeasure. Can $\mu$ be extended to a measure? What are the subsets of $X$ that are
measurable with respect to the outer measure $\mu^*$ induced by $\mu$ ? How would these change if instead we considered the collection $S = \{\emptyset, [0, 1], [0, 3], [2, 3]\}$ of subsets of $R$ and define $\mu(\emptyset)=0$ , $\mu([0, 1])=1$ , $\mu([0, 3])=1$ , $\mu([2, 3])=1$ ? Solution 1: Take $a \in A$ , then $\mu^*(\{a\}) = \inf \sum_{k=1}^\infty \mu(E_k)$ , $\{a\} \subset\bigcup_{k=1}^\infty E_k$ , where $E_k \in S$ , then $\mu^*(\{a\}) = 1$ , and, similarly, $\mu^*(\{b\}) = 2$ where $b \in X$ . Let $\emptyset \neq C \subset A$ . Then, $\mu^*(C) = 1$ . Suppose, $D \cap (X\sim  A) \neq \emptyset$ , then $\mu^*(D)=2$ . Show that $\mu: S \rightarrow [0, \infty]$ is a premeasure. Using the definition of premeasure: Let $S$ be a collection of subsets of a set $X$ and $\mu: S \rightarrow [0, \infty]$ a set function. Then, $\mu$ is called a premeasure provided $\mu$ is both finitely additive and countably monotone, and if $\emptyset$ belongs to $S$ , then $\mu(\emptyset)=0$ . Should I proceed the same way as in Lebesgue Measure? Finitely Additive: So, show $\mu(\bigcup_{k=1}^n E_k) \leq \sum_{k=1}^n \mu (E_k)$ (by subadditivity) and then, $\mu(\bigcup_{k=1}^n E_k) \geq \sum_{k=1}^n \mu (E_k)$ . Countably Monotone: $\mu(E) \leq \sum_{k=1}^\infty \mu(E_k)$ or should I do something else in general measure? Lastly: Since $\emptyset \notin S$ , this isn't necessary. Can $\mu$ be extended to a measure? Is $A$ measurable? If so, then $\mu^*(B) = \mu^*(B \cap A) + \mu^*(B \cap A^c)$ . Let $B = \{a, b\}$ . $\mu^*(B) = 2$ (from before). $\{a\} \in B \cap A \subset A$ , $\mu^*(A \cap B) = 1$ . $\{b\} \in B \cap A^c$ , $\mu^*(B \cap A^c) = 2$ $2 \neq 1 + 2$ Is this enough to show that A is not measurable and that $\mu$ cannot be extended to measure? Which subsets of $X$ are measurable with respect to the outer measure $\mu^*$ induced by $\mu$ ? So, we need to find the $\mu^*$ measurable sets. $E$ is measurable with respect to $\mu^*$ if and only if $\forall B \subset X$ . $$\mu^*(B) = \mu^*(B \cap E) + \mu^*(B \cap E^c)$$ Then, $\emptyset, X$ are measurable because $$\mu^*(B \cap\emptyset) + \mu^*(B \cap S) = \mu^*(\emptyset) + \mu^*(B) = \mu^*(B)$$ and $$\mu^*(B \cap X) + \mu^*(B \cap (S \sim B)) = \mu^*(B) + \mu^*(\emptyset) = \mu^*(B)$$ Solution 2: I won't go into anything because it seems like it will basically be the same thing.  Are there any major differences that I should know about?","['measure-theory', 'functional-analysis', 'real-analysis']"
306546,Specific proof that any finitely generated $R$-module over a Noetherian ring is Noetherian.,"I have seen a handful of proofs that any finitely generated module over a Noetherian ring is again Noetherian. I'm specifically trying to understand the following proof idea. It goes as this: Observe that if $T\subseteq S$ are submodules of an $R$-module $M$ with $R$ Noetherian, and if $T$ is finitely generated (f.g.) and $S/T$ is f.g., then so is $S$. I get that. Proceed by induction. If $M$ is $1$-generated, say $M=Rv$, then if $\phi\colon R\to M$ defined by $r\mapsto rv$ is an epimorphism, and so $M\cong R/\ker(\phi)$, and is Noetherian as the quotient of a Noetherian ring. Suppose it holds for all $k$-generated $R$-modules, for $k\leq n$. Let $M=\langle v_1,\dots,v_{n+1}\rangle$. Let $M'=\langle v_1,\dots, v_n\rangle$. Then let $T=S\cap M'$. On second thought, I think $S$ is supposed to be an arbitrary submodule of $M$. Let $T=S\cap M'$. So $T$ is a submodule of $M'$, hence finitely generated. Then
$$
S/T=S/(S\cap M')\cong (S+M')/M'.
$$
How is $(S+M')/M'$ finitely generated? I suppose would give the conclusion.","['modules', 'ring-theory', 'abstract-algebra']"
306553,On Conjugacy Classes of Alternating Group $A_n$,"In Dummit & Foote, page 131 Let $K$ be a conjugacy class and suppose that $K$ is subset of $A_n$ . Show that if $\sigma$ belongs to $S_n$ then , $\sigma$ does not commute with any odd permutation if and only if the cycle type of  consists of distinct odd integers. Deduce that $K$ is a union of two -conjugacy classes in $A_n$ if and only if the cycle type of  an element of $K$ consists of distinct odd integers. [Hint: Assume first that $\sigma$ belongs to $S_n$ does not commute with any odd permutation. Observe that $\sigma$ commutes with each cycle in its own cycle decomposition, so that each cycle must have odd length. If two cycles have the same odd length , find a product of  transpositions which interchanges them and commutes with $\sigma$ . Conversely, if the cycle type of $\sigma$ consists of distinct integers, prove that $\sigma$ commutes only with the subgroup generated by the cycles in its cycle decomposition.] the exercise number 21 ,
i uesed the hints to prove that the cycles of cycle decomposition of $\sigma $ must be of odd length , but i don't know how to prove that the cycle type is distinct . the text said find transposition which interchanges them and commute $\sigma$ , my question is , interchange what ?!!! what does this mean ? can anyone help ?","['group-actions', 'permutations', 'group-theory', 'abstract-algebra']"
306566,Primes of the form $\frac{n^2-n+4}{2}$ satisfy Hardy-Littlewood analogue?,"Let $n,a,b$ be positive integers with $a<b$. Consider primes of the form $f(n)=\dfrac{n^2-n+4}{2}$. Let $C(a,b)$ denote the amount of primes of the form $f(n)$ between (and including) $f(a)$ and $f(b)$. Now it appears that $C(a,b) < C(1,b-a+1)+1$. This observation is an analogue of the second Hardy-Littlewood conjecture.( http://en.wikipedia.org/wiki/Second_Hardy%E2%80%93Littlewood_conjecture ) If we assume there are an infinite amount of primes of the form $f(n)$ and/or the original second Hardy-Littlewood conjecture is true , can we prove that $C(a,b) < C(1,b-a+1)+1$? Is it possible to say anything about $C(a,b) < C(1,b-a+1)+1$ without assuming an infinite amount of primes of the form $f(n)$ and/or the original second Hardy-Littlewood conjecture is true ? Is there a counterexample known ? Notice that a finite amount of primes $f(n)$ is also potentially consistant with $C(a,b) < C(1,b-a+1)+1$. I was thinking about using a weaker form of the second Hardy-Littlewood namely $\pi(2,x+1)+1>\pi(y,y+x)$ where $\pi(x,y)$ means counting primes from $x$ till $y$. But with no success so far.","['prime-numbers', 'inequality', 'examples-counterexamples', 'number-theory']"
306567,"If $\mu$ is a signed finite measure, then $\|\mu\| = \sup \left\{ \int f d\mu : |f| \leq 1 \right\} $","If $\mu$ is a signed finite measure, then $$
\|\mu\| = \sup \left\{ \int f d\mu : |f| \leq 1 \right\}
$$ I did the inequality ""$\geq$"". Somebody help with the other inequality ""$\leq$""?","['measure-theory', 'integration']"
306578,Morphism between matrices and linear equations,"I'm currently a beginner at linear algebra. So, in some books I see authors start defining linear equations and then they define matrices and, supposedly, the definition of associative matrix is to handle linear equations easily. However they never establish the connection between both objects and never explain why it is possible to work with matrices in substitution of linear equations. For some classmates this is irrelevant because they say that I just complicate my life with such questions. But it is important and think that the treatment given in such books is either very informal so beginners like me can understand the concepts or maybe is too simple that I'm missing something. I have read that two objects are generally treated as being the same, of course under certain properties, if there is a connection between them in terms of a one-to-one correspondence (something called morphism, isomorphism, monomorphism, etc). So, how would you establish the bijection between linear equations and matrices considering elementary operations?","['linear-algebra', 'abstract-algebra']"
306582,Give a combinatorial proof of the recurrence relation,"Let $F_n$ be the number of forests on the vertex set $V = \{1,2,\ldots,n\}$(Thus we are counting labelled forests). Give a combinatorial proof of the recurrence relation 
$$F_n = \sum_{i=1} \binom{n-1}{i-1} i^{i-2} F_{n-i} $$ ! A tree is a connected graph without cycles and a forest is a disjoint union 
of trees . Please, help!","['recurrence-relations', 'recursive-algorithms', 'recursion', 'graph-theory', 'combinatorics']"
306586,"Stopping Time, Random Walk","I'm trying to solve this problem and don't know where to start. If someone could prove it or tell me how or point me to any relevant information I'd very much appreciate it. Let $(s_n)_{n\geq0}$ be a 1-dimensional, unbiased random walk. For $a\in\mathbb Z^{*}$, let $T_a=\inf\left\{n\geq0:s_n=a\right\}$. Prove that $\mathbb E(T_a)=\infty$.","['probability-theory', 'random-walk']"
306591,"If the matrix of a linear map is independent from the basis, then the map is a multiple of the identity map.","Let $V$ be a finite dimensional vector space over $F$, and let
$$T:V\to V$$
be a linear map. Suppose that given any two bases $B$ and $C$ for $V$, we have that the matrix of $T$ with respect $B$ is equal to that with respect to $C$. How can we show that this implies that there exists some $\lambda\in F$ such that $T(v)=\lambda v$, $\forall v\in V$?",['linear-algebra']
306604,Confusion on understanding a proposition on equivalence classes,"I am given to prove this proposition on equivalence classes. Each element of $A$ is an element of one and only one equivalent class. The part that is confusing is one and only one . It sounds like an existential statement, the existence of an equivalence class and that that equivalence class is unique. How should one understand this proposition in ""common"" logic terms, namely ""for every"", ""there exists"", if..then,...? So far here is my understanding, or say 'translation' of the proposition: There exists a unique equivalence class such that each element of $A$ belongs to that equivalence class. This understanding is doubtful, at least for me, because it implies that all elements of $A$ belong to one equivalence class, which is wrong. I am not looking for a proof, just an understanding of the proposition. Thanks!","['logic', 'equivalence-relations', 'elementary-set-theory']"
306622,Differential Equation $y'' - 4y' + 4y = 0$,"[1] $y'' - 4y' + 4y = 0$ Usually problem like these will have the answer in the form $C_1e^a + C_2e^b ... $
where $a $ and $b$ are the roots of the characteristic equation $e^{rt}$ $$ y = e^{rt} $$
$$ y' = re^{rt}.. y'' = r^2 e^{rt} $$ 
$$ r^2e^{rt} - 4e^{rt} + 4e^{rt} = 0$$
$$ e^{rt}(r-2)(r-2) = 0$$
$$ y= C_1e^{2t} + C_2e^{2t}$$ However, this is not correct as the answer is $ y = C_1e^{2t} + C_2te^{2t}$ ! I just don't know why. [2] For a similar problem , $y'' + 3y' - 4y = 0 $ I did the exact same thing and the answer is $$y = c_1e^t + c_2e^{-4t} $$ How are [1] and [2] different? They look the same, why does [2]'s solution have an extra factor of t.",['ordinary-differential-equations']
306638,"Evaluation of $\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x$","Evaluation of $$\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x$$ Sis.","['calculus', 'contest-math', 'definite-integrals', 'real-analysis', 'limits']"
306642,Prove $G/\ker \phi \times \ker \phi \cong G$,"If $G, H$ are groups and $\phi : G \to H$ is a homomorphism, is it true that $G/\ker \phi \times \ker \phi \cong G$? I am pretty sure this is right, but I can't remember how to prove it. We can think of $\phi$ as a surjection of $G$ into $G/\ker \phi$, so I was thinking that for $\phi$ there ought to be a surjection $\psi : G \to \ker \phi$, such that $\psi$ maps an element of $G$ into its ""position"" in its coset of $\ker \phi$. Then then isomorphism between $G$ and $G/\ker \phi \times \ker \phi$ would be $f(g) = (\phi(g), \psi(g))$. To show $f$ is an isomorphim we only need to show it is injective since $\phi, \psi$ are both surjective. $f(g) = f(g')$ implies $\phi(g) = \phi(g')$ so they are in the same coset of $\ker\phi$ and $\psi(g) = \psi(g')$ so they are in the same ""position"" in that coset. Therefore $g = g'$. If my intuitive notion of position works, I am still not sure how I define $\psi$. Can anyone point me in the right direction?","['group-theory', 'abstract-algebra']"
306659,Computing the Expectation of the Square of a Random Variable: $ \text{E}[X^{2}] $.,"What is the rule for computing $ \text{E}[X^{2}] $, where $ \text{E} $ is the expectation operator and $ X $ is a random variable? Let $ S $ be a sample space, and let $ p(x) $ denote the probability mass function of $ X $. Is
$$
\text{E}[X^{2}] = \sum_{x \in S} x^{2} \cdot p(x),
$$
or do I also need to square the $ x $ appearing in $ p(x) $?","['probability', 'random-variables']"
306665,The integral $\int_0^{\frac{\pi}{2}}\left(\frac{x}{\sin x}\right)^2\text{d}x$,"How to evaluate :
$$\int_0^{\frac{\pi}{2}}\left(\frac{x}{\sin x}\right)^2\text{d}x$$
I was wondering how would you use a series expansion?","['sequences-and-series', 'calculus', 'integration']"
306675,Legendre symbol- what is the proof that it is a homomorphism?,"I know that one property of the Legendre symbol is that it is a homomorphism. However, I have not been able to find a proof that this is the case. If someone could give me or show me to a thorough proof of this, that would be great. I am going with the definition: $\sigma(x) = 1$ when $ x=y^2$ $\sigma(x)= -1 $ otherwise where $\sigma$ is a map st $\sigma: {\mathbb{Z}_p}^{\times} \rightarrow (-1,1)$ EDIT: How would we sketch a proof that the symbol is a homomorphism using that if $(G, *)$ is a finite group and $H\subset G$ is a subgroup, and we have an equivalence relation on $G: x \sim y$ iff $\exists h \in H$ st $y= x*h$, and $P$ is an equivalence relation: then we know $\# P = \# H$ and $\# H$ divides $\# G$. Basically how would we prove, using this fact, that the set of squares in $\mathbb{Z}_p$ is a subgroup of $\mathbb{Z}_p$?","['group-theory', 'number-theory']"
306684,Evaluating $\int_0^1 \frac{1}{\sqrt{\Gamma(x)}} dx$,"What is the value of the following integral? $$\int_0^1 \frac{1}{\sqrt{\Gamma(x)}} \,dx$$ Here $\Gamma(x)$ is Euler's gamma function. EDIT: Can we improve the upper bound strictly smaller than $1$? (Thanks for the hint about $\Gamma(x)$ being $> 1$ in the domain of integration.)","['definite-integrals', 'improper-integrals', 'special-functions', 'integration']"
306691,Proving DeMorgan's Theorem,"I'm trying to prove that (without using logical equivalencies): $\overline{A\cap B} = \bar A \cup \bar B$ by proving both sides: (1) $ x \in \overline{A\cap B} \to x \in \bar A\cup\bar B$ (2) $ x \in \bar A\cup\bar B \to x \in \overline{A\cap B}$ I figured out the 2nd part, but I'm struggling with the first. The only thing I'm confident about now is: Let $x \in \overline{A\cap B}$. We prove that $x \in \bar A\cup \bar B$. By definition of complement, $x \not\in A\cap B$. I'm not sure if I should use cases, or if I should prove by contradictions. With the other variation of DeMorgan's, I could assume $x \in A$ and $x \in B$ and they would lead to contradictions with the first assumption, but I can't do that here because it's a $\cap$ instead of a $\cup$. For reference, here's the proof I was given for the other variation of DeMorgan's: Prove: $\overline{A \cup B} = \bar A \cap \bar B$ (1) if $x \in \overline{A \cup B}$ then $x \in \bar A \cap \bar B$ (2) if $x \in \bar A \cap \bar B$ then $x \in \overline{A \cup B}$ Proof: (1)Let $x \in \overline{A \cup B}$. We prove that $x \in \bar A \cap \bar B$. By definition of complement, $x \not\in A \cup B$. Suppose, for contradiction, $x \not\in \bar A$. By definition of complement, $x \in A$, and by definition of union, $x \in A\cup B$, a contradiction. Thus, $x \in \bar A$. Now, suppose for contradiction, $x \not\in \bar B$. By definition of complement, $x \in B$, and by definition of union, $x \in A \cup B$, a contradiction. So, $x \in \bar B$. Therefore, $x \in \bar A$ and $x \in \bar B$, so by definition of intersection, $x \in \bar A \cap \bar B$. (I'm leaving out the 2nd part, as I've figured out the 2nd part in my problem above) Any ideas? I'm assuming it has to be of similar complexity.","['logic', 'discrete-mathematics', 'proof-writing']"
306707,Short exact sequence of modules and elliptic curves,"Let $E/\mathbb{Q}$ be an elliptic curve with a 3-torsion point $P$. Let $E_{d}$ denote the quadratic twist of $E$ by $d$. Then the action of $\sigma \in \operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$ on $E_{d}[3]$ can be written as the matrix $$\begin{pmatrix} \chi_{d}(\sigma) & \ast\\0 &\chi_{d}(\sigma)\omega(\sigma)\end{pmatrix}$$
where $\chi_{d}$ is the quadratic character associated to the quadratic twist and $\omega$ is the mod 3 cyclotomic character. Why does this yield the short exact sequence of modules:
$$0 \rightarrow M_{1} \rightarrow E_{d}[3] \rightarrow M_{2} \rightarrow 0$$
where $M_{1}$ is the module $\mathbb{F}_{3}$ endowed with the Galois action through $\chi_{d}$ and $M_{2}$ is the module $\mathbb{F}_{3}$ endowed with the Galois action through $\chi_{d}\omega$?","['elliptic-curves', 'number-theory']"
306714,$k$-forms as modules over $C^\infty(M)$,"Let $M$ be an $n$-dimension manifold. Is $E^k(M)$ a finite dimension module over $C^\infty(M)$? Here $E^k(M)$ is the space of $k$-form on $M$, $k<n$.",['differential-geometry']
306728,Showing that $ |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$,For every nonnegative integer $n$ and every real number $ x$ prove the inequality: $$\sum_{k=0}^n|\cos(2^kx)|= |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$$,"['inequality', 'contest-math', 'trigonometry', 'real-analysis', 'analysis']"
306729,Properties of Arbitrary Cartesian Products,"Let $X_\delta$ and $Y_\delta$ be index families of sets with the index set $\Delta$. Show the following: $$\begin{align}
\prod_{\delta \in \Delta} X_\delta \cup \prod_{\delta \in \Delta} Y_\delta \subseteq \prod_{\delta \in \Delta} X_\delta \cup Y_\delta & \tag{i}\\
\prod_{\delta \in \Delta} X_\delta \cap \prod_{\delta \in \Delta} Y_\delta = \prod_{\delta \in \Delta} X_\delta \cap Y_\delta &\tag{ii}
\end{align}$$ When working on this problem I arrived at a small issue.  For finite intersections and unions the proofs are straightforward.  However, when using arbitrary indices, how would my strategy change. I'm a bit gun shy about starting proofs for these because I'm starting to think that the arbitrary index changes everything.",['elementary-set-theory']
306743,"Given a set $S$ in a group $G$, how does the smallest normal subgroup containing $S$ look like?","In the theory of rings we have clear descriptions of the smallest ideal in a ring $R$ containing a subset $S$ of $R$. I'd like to know if there is such a description in group theory, that is, if $N(S)$ is the smallest normal subgroup of $G$ containing $S$, can you describe $N(S)$ using the operations of groups and the elements of both $S$ and $G$? Is there such description if $S$ is a subgroup? Thanks.","['group-theory', 'abstract-algebra']"
306754,Nice $\epsilon$-$\delta$ proof that the derivative of $\sin(x)$ is $\cos(x)$?,"Looked around a bit and all I see are proofs using the limit definition of a derivative. This is not for an assignment, I could just use the limit definition if I wanted to, but I was wondering how you could go about proving this using the epsilon-delta definition of a derivative ($\forall \epsilon >0$, $\exists \delta >0$ such that if $0< |x-c| <\delta$, then $\left | \frac{f(x) - f(c)}{x-c} - f'(c) \right | < \epsilon$). Edit: Just to be clear I am explicitly looking for an epsilon-delta formulation of the proof. Was just trying to prove this without throwing a bunch of trig identities and limit theorems at the problem.","['derivatives', 'real-analysis']"
306771,Combinatorial Proof of Combinatorial Identity involving $(-1)^k \binom {n-1}{k}$,"Given the following identity: $$\sum_{i=0}^k (-1)^i \binom ni = (-1)^k \binom {n-1}{k}.$$ This is provable by induction. However, I wonder if there is a way to prove this in a combinatorial fashion (something like subsets, groups, choosing $n$ balls from a box with $k$ balls, et cetera.) Thank you.","['combinatorial-proofs', 'combinatorics']"
306778,About Euler's formula for Apery number,"Euler's formula. $$\zeta(3)=\frac{\pi^2}{7}\left(1-4\sum_{m\ge 1}\frac{\zeta(2m)}{(2m+1)(2m+2)2^{2m}}\right)$$ I saw this formula in Wikipedia a few months ago. I have searched about Euler's original proof for the formula, but I couldn't find any useful information. So I just tried to prove the formula on my own, and I posted my post in here . But I doubt that Euler's skills used in his proof is similar to mine. I believe that he could think more clever skills which led him to discovery of the formula. Could you provide some information about Euler's original proof? Or, Do you have other kinds of proof for the formula? Thanks :)","['alternative-proof', 'summation', 'sequences-and-series', 'riemann-zeta']"
306808,"How is $\frac{x}{(1-x)^2}$ the equation for the sequence $0, 1, 2, 3, 4,\dots$","Our prof said this for a homework question: I get that the function shown in a is $0, 0, 0, 0, 0, 0, 1, 2, 3, 4...$ But how is $\dfrac{x}{(1-x)^2}$ the sequence $0, 1, 2, 3, 4, ...$? For the $0$th term, we'd have $0/1$, which is $0$. Good. For the first we'd have $1/0$, which is infinite. Not so good. For the second we'd have $2$, okay. For the third, $3/4$, um, not quite. Our sequence is $0$, infinite, $2$, $3/4$, so far. A far cry from $0, 1, 2, 3, 4,\dots$ Could someone explain this to me?","['generating-functions', 'discrete-mathematics']"
306809,Prove $2\lfloor x\rfloor \le \lfloor2x\rfloor$,"I am trying to prove
$$2\lfloor x\rfloor \le \lfloor2x\rfloor$$
which in turn will yield a prove for a homework question. I thought it is a simple prove but I can't figure it out. Maybe it is just a simple thing I overlooked. Any help? I tried to use $x - \lfloor x\rfloor \ge 0$ to prove $2\lfloor x\rfloor-\lfloor2x\rfloor \le 0$ with no success.","['inequality', 'discrete-mathematics', 'ceiling-and-floor-functions']"
306825,Which ODE Solution Method to Use?,"It has been awhile since I've taken a course in differential equations, and I have problem, which requires I solve an ODE (after transforming a PDE) of the following structure: $$
f(x) - (x + c_1)f'(x) = c_2xf''(x)
$$ where $c_1$ and $c_2$ are nonzero constants. I'm not looking for the actual solution, I'm looking for the name of the solution method/procedure so that I can look into how to solve these types of ODEs.  Any pointers? Thanks!",['ordinary-differential-equations']
306827,How to find critical points of an absolute values function,"I am asked to find How many critical points does the function $g(x) = |x^2 − 4|$ have?
I know that the result is $3$ but I can only find $2$. What I do, is to equal the equation to $0$, so $x^2-4=0$ and then I factorize so $(x-2)(x+2)$, so I would say that the only critical points happen is $x=-2$ and $x=2$, so two critical points? Where is the third one? How do I find it?","['absolute-value', 'derivatives', 'functions']"
306831,"Find $\lim_{n\to \infty}\frac{1}{\ln n}\sum_{j,k=1}^{n}\frac{j+k}{j^3+k^3}.$","Find $$\lim_{n\to \infty}\frac{1}{\ln n}\sum_{j,k=1}^{n}\frac{j+k}{j^3+k^3}\;.$$","['sequences-and-series', 'contest-math', 'real-analysis', 'analysis', 'limits']"
306852,"The adherent values of $x_n=cos(n)$ are the interval $[-1,1]$","This question seems really hard, I'm trying to prove that the set of the adherent values of the sequence $x_n=\cos (n)$ is the closed interval $[-1,1]$, i.e., every point of this interval is a limit of a subsequence of  $x_n$, and also the limit of any subsequence of $(x_n)$ is in $[-1,1]$ It's obvious that every adherent values is in $[-1,1]$, I'm having troubles to prove the converse, i.e., a point in $[-1,1]$ is an adherent value of $(x_n)$. I need help Thanks a lot",['real-analysis']
306886,"the general solution of the equation $y^{\prime \prime} + Py^{\prime} +Qy=0$, approaches zero as $x$ approaches $\infty$","Show that the general solution of the equation $$y^{\prime \prime} + Py^{\prime} +Qy=0$$ where P and Q are constants, approaches zero as $x$ approaches $\infty$ if and only if P ,Q are both positive. I have no idea on how to prove this. Anyone has any idea?",['ordinary-differential-equations']
306896,proving if a number is prime or not using combinations,"I am really confused on this problem. I am given that $p$ = prime number, $1 \leq k \leq p-1$, and am asked to show $\binom{p}{k}$ multiple of $p.$ How do I prove that $\binom{p}{k}$ is a multple of $p$?",['discrete-mathematics']
306901,Find the expected value of $\frac{1}{X+1}$ where $X$ is binomial,"The problem: X is a binomial random variable, find $E[\frac{1}{X+1}]$
n and p are not given PDF for a binomial distribution is $\binom{n}{k}p^k(1-p)^{n-k}$ Expected value is
$\sum{x_ip(x_i)}$ But this is where I get stuck, I'm really rusty on my statistics and I'm not sure exactly how to structure it in the next step? I think I want to get the form of the following out of the summation $\sum _{k=0}^{n} \binom{n}{k}p^k(1-p)^{n-k} = (p + 1 - p)^n = 1$ But I'm not sure if it should look like $\sum \frac{1}{xp(x)+1} $ and if it should where to go from here?","['probability-distributions', 'probability', 'binomial-distribution', 'expected-value']"
306918,Are there rigorous mathematical definitions for these waves?,"My friend linked this .gif to me tonight, and asked me if I knew of any equations that might model these bottom two waves (the blue and green waves). Unfortunately, I am not far enough in my education to recognize if any such model exists. Are these waves modeled after some equation, or is this just some piece of eye candy?","['trigonometry', 'calculus', 'mathematical-modeling']"
306921,How do we calculate this sum $\sum_{n=1}^{\infty} \frac{1}{n(n+1)\cdots(n+p)}$?,"I know that this sum $$\sum_{n=1}^{\infty} \frac{1}{n(n+1)\cdots(n+p)}$$ ($p$ fixed) converges which can be easily proved using the ratio criterion, but I couldn't calculate it. I need help in this part. Thanks a lot.","['sequences-and-series', 'real-analysis']"
306936,Proof of Compactness Theorem,"I'm going through Enderton's Mathematical Logic text and have encountered a problem that I'm having trouble solving. After searching this website I've found that another user had the same problem (you can check it out here ), and even after looking at the hints listed I'm still really confused about the problem of proving the compactness theorem using its corollary. I'd appreciate it if someone could clearly explain how to approach this problem and provide a little more insight. Thanks in advance! (Corollary 17A) Suppose $\Sigma \models \tau$, then there is a finite $\Sigma_0 \subseteq \Sigma$ such that $\Sigma_0 \models \tau$.","['general-topology', 'compactness', 'model-theory']"
306992,Calculate this sum $\sum \frac{1}{(4n+1)(4n+3)}$,"I'm having troubles to calculate this sum: $\sum \frac{1}{(4n+1)(4n+3)}$. I'm trying to use telescopic series, without success: $\sum \frac{1}{(4n+1)(4n+3)}=1/2\sum \frac{1}{(4n+1)}-\frac{1}{(4n+3)}$ I need help here Thanks a lot","['sequences-and-series', 'real-analysis']"
306995,Non-induction proof of $2\sqrt{n+1}-2<\sum_{k=1}^{n}{\frac{1}{\sqrt{k}}}<2\sqrt{n}-1$,"Prove that $$2\sqrt{n+1}-2<\sum_{k=1}^{n}{\frac{1}{\sqrt{k}}}<2\sqrt{n}-1.$$ After playing around with the sum, I couldn't get anywhere so I proved inequalities by induction. I'm however interested in solutions that don't use induction, if there are some (relatively simple ones, since I'm high-school student). Also any advice for determining if a sum can be written in ""compact"" form? For example, $\displaystyle \sum_{k=1}^{n}{(-1)^{k-1}k}$ is actually $\displaystyle-\frac{n}{2}$ for even $n$ and $\displaystyle\frac{n+1}{2}$ for odd $n$.","['inequality', 'algebra-precalculus', 'radicals', 'induction', 'summation']"
306997,question of Coherent sheaf (Hartshhorne book Example II.5.2.5),"Let $X$ be an integral Noetherian scheme, and $\mathcal{K}$ be the constant sheaf with the group $K$ equal to the function field of $X$ where the function field of $X$ is the residue field of generic point. Then, $\mathcal{K}$ is not coherent unless $X$ is reduced to a point. I don't understand that meaning of""reduced to a point"" and don't know why $\mathcal{K}$ is not coherent.",['algebraic-geometry']
307019,3D Fourier transform,"I don't know how to evaluate an integral of the form $$\int d^3 r \exp(-i \vec r\cdot\vec q)\exp(-a^2 r^2)$$
where $a\in \mathbb R$. Could anyone please teach me how to do this integral? Many thanks.","['fourier-analysis', 'calculus']"
307028,Methods to find $\lim\limits_{n\to\infty}\frac1n\sum\limits_{k=1}^nn^{1/k} $,How would you suggest to find the following limit? $$\lim_{n\to\infty} \frac{1}{n} \sum_{k=1}^{n} n^{1/k} $$,"['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
307033,The Chern class of a Kähler manifold,"This question refers mainly to this mathoverflow question and its answer. Statement 1 The well known result of Aubin and Yau states that if $X$ is a compact Kähler manifold with negative first Chern class, $c_1(X)<0$ , then it will allow a Kähler-Einstein metric $g$ such that: \begin{equation}
\text{Ric} = -g
\end{equation} where by $\text{Ric}$ I mean the Ricci curvature. I won't pretend that I understand the proof of this result, but it is used frequently and is discussed in the mathoverflow thread I mentioned above. Statement 2 The answer in the above thread then goes on to say (and I have seen this statement in several papers that I am trying to understand, such as this one by Kobayashi and this one by F. Catanese and A. Di Scala) that if the canonical bundle of $X$ is ample then $c_1(X) <0$ and so by statement 1 we get the Kähler-Einstein metric $g$ . So: 1) What exactly do we mean by the first Chern class of of a complex manifold? I always thought that this referred to the first Chern class of the canonical bundle: $c_1(X) = c_1(K_X)$ where $K_X = \bigwedge ^{n}\Omega_X$ and $\Omega_X$ is the holomorphic cotangent bundle, but... 2) If $K_X$ is ample, is it not true that it has positive first Chern class? Thanks","['algebraic-geometry', 'complex-geometry', 'kahler-manifolds']"
