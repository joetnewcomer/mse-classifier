question_id,title,body,tags
2628045,Integrals inequality,"I have
$$A=\int_1^5{\frac{e^x}{e^x+x^2}dx}$$
$$B=\int_1^5{\frac{x^2}{e^x+x^2}dx}$$
I have already found that $A+B=4$ but now I want to prove that $AB\le4$. I don't know how. I am thinking of using the properties of integrals but nothing seems to work out for me. Any ideas?","['inequality', 'integration', 'definite-integrals']"
2628135,Intuitive (combinatorial) proof of $2^n=\sum_{k=0}^n {n\choose k}$,"Why should we expect that $$2^n=\sum_{k=0}^n {n\choose k}$$ It is easily seen to be true, by the binomial theorem:  just set $x=y=1$ in $(x+y)^n$ . But what is an intuitive reason why it is true (in terms of subsets)?","['intuition', 'combinatorics', 'elementary-set-theory']"
2628149,Linear homogenous second order ODE without constant coefficients,"I am having trouble finding the general solution of the following second order ODE for $y = y(x)$ without constant coefficients: $3x^2y'' = 6y$ $x>0$ I realise that it may be possible to simply guess the form of the solution and substitute it back into the the equation but i do not wish to use that approach here. I would appreciate any help, thanks.","['derivatives', 'real-analysis', 'ordinary-differential-equations', 'mathematical-modeling']"
2628164,Find number of functions [duplicate],"This question already has answers here : Determine the number of functions $f: \{1,2,3....,1999\}\to \{2000,2001,2002,2003\}$satisfying the condition that $f(1)+f(2)+...f(1999)$ is odd. (4 answers) Closed 6 years ago . Find the number of functions $f: \{1,2,3,\dots,1999\}\to\{2000,2001,2002,2003\}$ satisfying the condition that $f(1)+f(2)+f(3)+\dots+f(1999)$ is odd. Upon first thought my try was that for any function $2000p+2001q+2002r+2003s$ is odd where $p, q, r, s$ are natural numbers  which also satisfy $p+q+r+s=1999$ and hence $q, s$ must be odd. Using generating functions I found the answer but then the thought stuck me that I am asked to find the number of functions possible. So I would like to know how would one do such questions using the mapping technique or any other combinatorial method.","['combinatorics', 'contest-math', 'functions']"
2628245,Intuition of Picard Iteration,"I understand the proof of the Picard-Lindelof Theorem, but am having trouble understanding why someone would attempt to use Lipschitz continuity in the first place. The condition of Lipschitz continuity seems ad hoc. What is the motivation of this on the intuitive level? This could be answered be answering one of the following questions: Why would the failure to be Lipschitz continuous at a point allow for a break in solutions, that is, there is not uniqueness of solutions? (I am not looking for an example, but an intuitive understanding.) Why would one go about looking for a solution through a Picard iteration, as in, why would someone have the intuition that the integral equation (induced by the differential equation) should contract approximations?","['ordinary-differential-equations', 'analysis']"
2628304,Maximum Likelihood estimator for n in binomial with known p,"I have a question concerning the ML-estimation of the trials of a Binomial variable.
The setting is the following: I have a random variable $X\sim Bin(n,p)$ with $n\in\mathbb{N}$ unknown, $p\in (0,1)$ the known success probability and with density (w.r.t. to the counting measure) $p_n(x)=\binom{n}{x}p^x(1-p)^{n-x}=:L_x(n)$. The log-likehood function is therefore given by 
$$l_x(n)=\log L_x(N)=\log(n!)-\log(x!)-\log((n-x)!)+x\log(p)+(n-x)\log(1-p) .$$
Maximizing $l_x(n)$ w.r.t. to $n$ is equivalent to maximizing $\log(n!)-\log((n-x)!)+n\log(1-p)$ or $\frac{n!}{(n-x)!}(1-p)^n$. My problem is that I don't know how to proceed from here. A person in this thread Maximum likelihood estimate of $N$ (trials) in Binomial suggested that a solution is given by $\hat{n}=X/p$. However, $X/p\notin \mathbb{N}$ for most $p$, so I suspect that this can't be the answer.","['maximum-likelihood', 'statistics', 'parameter-estimation']"
2628308,On a new definition of fractional derivative,"while studying I came across the following article which is a joint work from four peoples: Roshdi R Khalil, M. Al Horani H Horani, Abdelrahman Yousef, M. Sababheh with first three authors from university of Jordan. Note that anyone with undergraduate tools in his toolkits can easily follow what is written there is no reason to be afraid Let us give there definition as provided in the article. Definition: For fixed  $0<\alpha<1$, and a function $f:(a,b)\to \Bbb R, a>b$. Then, f is said to be $\alpha-$differentiable at a point $t\in(a,b) $ if the following limit exists
  $$f^{(\alpha)}(t):=\lim_{\varepsilon \to0}\frac{f(t+\varepsilon t^{1-\alpha})-f(t)}{\varepsilon }$$ This definition is intriguing since a couple of days now. And I have the following question Question: Can one provide a function which is $\alpha-$differentiable in the above sense but not differentiable in the classical sense. Is there any convenient reason why one should call this as fractional derivative rather saying derivative in the classical sense? Here is what I did My answer to the above question is ""NO"" I may be wrong as well and I may miss something. Assume $f$ is $\alpha-$differentiable then we have, 
  $$f^{(\alpha)}(t):=\lim_{\varepsilon \to0}\frac{f(t+\varepsilon t^{1-\alpha})-f(t)}{\varepsilon } = t^{1-\alpha}\lim_{h \to0}\frac{f(t+h)-f(t)}{h } =\color{red}{t^{1-\alpha}f'(t)}$$ this shows that $f$ is differentiable in the classical sense and we have 
$$\color{blue}{f'(t)=t^{\alpha-1}f^{(\alpha)}(t)}$$
Vice versa the differentiability in the classical sense the fractional differentiability. This is really  artefact since IMHO one should hope such equivalence to holds true. If not What is special with this definition.? On the other hand it is a bitte annoying that this definition is only valid for positive value of $t>0$ Further remark One of the remarkable fact with this definition is that all Classical property for derivative such as product rule, chain rule, linearity, fundamental theorem of calculus. mean value theorem..... remain true in this context which less surprising given the identification above. see all details in the article. Does anyone has a clarification of what I probably misunderstood?","['derivatives', 'real-analysis', 'calculus', 'functions']"
2628359,What is the largest eigenvalue of the following matrix?,"Find the largest eigenvalue of the following matrix
  $$\begin{bmatrix}
 1 &  4 & 16\\
 4 & 16 &  1\\
16 &  1 &  4
\end{bmatrix}$$ This matrix is symmetric and, thus, the eigenvalues are real. I solved for the possible eigenvalues and, fortunately, I found that the answer is $21$. My approach: The determinant on simplification leads to the following third degree polynomial.
$$\begin{vmatrix}
1-\lambda & 4 &16\\
4 &16-\lambda&1\\
16&1&4-\lambda
\end{vmatrix}
= \lambda^3-21\lambda^2-189\lambda+3969.$$ At a first glance seen how many people find the roots of this polynomial  with pen and paper using elementary algebra. I managed to find the roots and they are $21$, $\sqrt{189}$, and $-\sqrt{189}$ and the largest value is $21$. Now the problem is that my professor stared at this matrix for a few seconds and said that the largest eigenvalue is $21$. Obviously, he hadn't gone through all these steps to find that answer. So what enabled him answer this in a few seconds? Please don't say that he already knew the answer. Is there any easy way to find the answer in a few seconds? What property of this matrix makes it easy to compute that answer? Thanks in advance.","['matrices', 'eigenvalues-eigenvectors', 'symmetric-matrices', 'linear-algebra']"
2628366,why is the PDF of the sum of two continuous random variables the convolution of the PDF's?,"I have taken a probability course last year but we didn't cover that notion. I do know the steps in the discrete case. finding the support of $X + Y$... calculating the the probability of each element of the support... dressing a table. however this process is very intuitive and self-explanatory. the convolution is very useful when taking inverse of product of Laplace/Fourier transforms which is why it's hard for me to think of an analogy between taking the inverse of integral and computing the PDF of the sum of two random variables. I'd like to know the intuition behind : $$f_Z(z)=\int^{\infty}_{-\infty}f(x,z-x)dx$$ or just $$f_Z(z) = \int_{- \infty}^{\infty} f_X(x)f_Y(z-x)\;dx $$ when they are independent not a proof as I already found some on this site and elsewhere.","['intuition', 'probability', 'random-variables', 'probability-distributions']"
2628370,Proving that $\cos^{-1}\frac{4}{5}+\cos^{-1}\frac{12}{13}=\cos^{-1}\frac{33}{65}$,"Prove $$
\cos^{-1}\frac{4}{5}+\cos^{-1}\frac{12}{13}=\cos^{-1}\frac{33}{65}
$$ My Attempt: Let $\alpha=\cos^{-1}\frac{4}{5}\implies0<\alpha\leq\pi$ and $\beta=\cos^{-1}\frac{12}{13}\implies0<\beta<\pi$, thus $0\leq\alpha+\beta\leq2\pi$
$$
\cos(\alpha+\beta)=\cos\alpha\cos\beta-\sin\alpha\sin\beta=\frac{4}{5}.\frac{12}{13}-\frac{3}{5}.\frac{5}{13}=\frac{33}{65}=\cos\Big[\cos^{-1}\frac{33}{65}\Big]\\
\implies \cos^{-1}\frac{33}{65}=2n\pi\pm(\alpha+\beta)
$$ case 1: If $0\leq\alpha+\beta\leq\pi$,
$$
\cos^{-1}\frac{33}{65}=\alpha+\beta=\cos^{-1}\frac{4}{5}+\cos^{-1}\frac{12}{13}
$$ case 2: If $\pi<\alpha+\beta\leq 2\pi$,
$$
\cos^{-1}\frac{33}{65}=2\pi-(\alpha+\beta)
$$ Is there any thing wrong with my approach and how do I eliminate case 2 in similar problems ?","['real-analysis', 'trigonometry', 'inverse-function', 'calculus', 'fractions']"
2628427,"Among $2n-1$ irrationals there are $x_1,\dots,x_n$ such that for rationals $a_i\ge0$ with $\sum_{i=1}^{n}a_i>0$, $\sum_{i=1}^{n}a_ix_i$ is irrational","Given a set $S=\{z_1,\cdots, z_{2n-1}\}\subset \Bbb Q^c,$ of $2n-1$ different irrational numbers, prove that there are $n$ different elements $x_1,\cdots,x_n\in S$ such that for all non-negative rational numbers $a_1,\cdots,a_n\in\Bbb Q$, with $a_1+\cdots+a_n>0 $ we have that 
$$a_1x_1+\cdots+a_nx_n$$ is an irrational number. I have checked that this is true for $n=1,2,3,4$, but could not figure out how to use induction to argue in general.
Any thoughts are greatly appreciated.","['contest-math', 'real-analysis', 'rational-numbers', 'irrational-numbers']"
2628484,Concentration of the norm (sub-gaussianity),"I'm trying to solve the following problem (exercise 3.1.4 of these notes ) Suppose $X = (X_1, \dots, X_n) \in \mathbf{R}^n$ is a random vector with independent, sub-gaussian coordinates $X_i$, each of which satisfy $\mathbf{E} X_i^2 = 1$. Show that: 
  $$
\sqrt{n} - CK^2 \leq \mathbf{E}\|X\|_2 \leq \sqrt{n} + CK^2.
$$
  Can $CK^2$ be replaced by $o(1)$, a quantity that vanishes as $n \to \infty$? Notation: $\|\cdot\|_{\psi_2}$ refers to the sub-gaussian norm. What I've tried: The first statement is equivalent to showing that $|\mathbf{E} \|X\|_2 - \sqrt{n}| \leq CK^2$. From Theorem 3.1.1 of the notes above, I know that $\|\|X\|_2 - \sqrt{n}\|_{\psi_2} \leq CK^2$. Thus, it would suffice to establish that
$$
|\mathbf{E} \|X\|_2 - \sqrt{n}| \leq \|\|X\|_2 - \sqrt{n}\|_{\psi_2}
$$
By Jensen's inequality, 
$$
|\mathbf{E} \|X\|_2 - \sqrt{n}| \leq \mathbf{E} |\|X\|_2 - \sqrt{n}| =  \|\|X\|_2 - \sqrt{n}\|_{L_1}.
$$
But by equation 2.15 (of the same notes):
$$
|\mathbf{E} \|X\|_2 - \sqrt{n}| \leq \|\|X\|_2 - \sqrt{n}\|_{L_1}
\leq C' \|\|X\|_2 - \sqrt{n}\|_{\psi_2} \leq C' \cdot CK^2.
$$ Question: I'm not sure if this the tightest way to solve the first part of the problem. As you can see, I have to incur another absolute constant. Also, any help with the statement regarding whether $CK^2$ can be $o(1)$ would be appreciated. I have no idea.","['probability-theory', 'concentration-of-measure']"
2628510,"If a $f\in\mathbb{C}[[t]]$ is integral over $\mathbb{C}[t]$, convergent for $|t| < r$, then does it extend to a continuous function on $|t|\le r$?","Let $f = \sum_n c_nt^n \in\mathbb{C}[[t]]$ be a power series, and suppose it is integral over the subring $\mathbb{C}[t]$ (ie,it satisfies a monic polynomial with coefficients in $\mathbb{C}[t]$). Suppose $f$ has a positive radius of convergence $r$. Must $f$ extend to a continuous function on the closed disk $\{t\in\mathbb{C} : |t|\le r\}$?","['complex-analysis', 'algebraic-geometry', 'commutative-algebra']"
2628533,Linear Algebra - Matrix Inverse,"Prove that if $A$ is invertible, and $B$ can be obtained from $A$ by applying elementary row operations, then $B$ is invertible. This is what i did: Let $A$ be any nxn square matrix, Given: $E_{k}E_{(k-1)}...E_{2}E_{1}A=B$ We know that each Elementary Matrix is invertible because it can be obtained by applying one elementary row operation to identity matrix. For $k=1$, $$EA=B$$
Given that $A$ and $E$ are both invertible, 
$$(EA)^{-1}=A^{-1}E^{-1}$$
then, $$(B)^{-1}=A^{-1}E^{-1}$$
For $k=2$, $$E_{2}E_{1}A=B$$
Given that $A$ and $E_{1}$ and $E_{2}$ are invertible, $$(E_{2}E_{1}A)^{-1}=(E_{2}(E_{1}A))^{-1}=(E_{1}A)^{-1}E_{2}^{-1}=A^{-1}E_{1}^{-1}E_{2}^{-1}$$
then, $$(B)^{-1}=A^{-1}E_{1}^{-1}E_{2}^{-1}$$
For $k>2$, inductively we can assume that, $$(E_{k}E_{(k-1)}...E_{2}E_{1}A)^{-1}=A^{-1}E_{1}^{-1}E_{2}^{-1}...E_{k-1}^{-1}E_{k}^{-1}$$
Then, $$B^{-1}=A^{-1}E_{1}^{-1}E_{2}^{-1}...E_{k-1}^{-1}E_{k}^{-1}$$
Therefore, $B$ is invertible. Does this proof makes sense.","['matrices', 'linear-algebra', 'proof-verification']"
2628535,"Connectedness and path connectedness, of irreducible affine algebraic set in $\mathbb C^n$, under usual Euclidean topology",Let $n\ge 2$ and $V$ be an irreducible affine algebraic set in $\mathbb C^n$ . Then is it true that $V$ is path connected (or at least connected ) in the usual Euclidean topology of $\mathbb C^n$  ?,"['complex-geometry', 'algebraic-geometry', 'affine-geometry', 'affine-varieties', 'commutative-algebra']"
2628538,Contradiction and proofs,the problem is verify this statement:  $$\lnot ( \lnot p \land q)^\land (p \lor q)=p$$ That turns into $p \lor ( \lnot q \land  q)$ - which that last part of the statement is a contradiction and is always false which means now I have $p \lor F =p$ Does that mean that the original statement is true and valid or does it mean it's false? Could someone please explain.,['discrete-mathematics']
2628576,Probability question: setting up a recurrence equation,"I'm having trouble with the following problem: Three players, $A, B, C$ are taking turns playing chess. The winner will always go on to play the third player. Suppose that $A$ beats $B$ with probability $1/2$, $B$ beats $C$ with probability $1/2$ and $C$ beats $A$ with probability $1/4$. Let $p_n$ denote the probability that $A$ is playing in the $n^{th}$ match. Find $p_n$ given that $A$ and $B$ are playing the first match. I'm trying to set up a recurrence equation for $p_n$. We are given that $p_1 = 1$. Let $A_n$ denote the event that $A$ is playing in the $n^{th}$ match. Then, $$ p_n = P(A_n | A_{n-1})P(A_{n-1}) + P(A_n | A_{n-1}^c)P(A_{n-1}^c) = P(A_n | A_{n-1})p_{n-1} + 1- p_{n-1}$$ where the second equality comes from the fact that $A$ will always play the next match if he/she didn't play in the previous one. My difficulty lies in the computation of $P(A_n | A_{n-1})$. Am I right to condition on $A_{n-1}$, or is there some other event that would make things simpler? I know that $P(A_2 | A_1) = 1/2$ and $P(A_3 | A_2) = 3/4$. But things become rather complicated from here.","['puzzle', 'recurrence-relations', 'probability', 'discrete-mathematics']"
2628626,Quasi-components in compact space,"I know that in a compact Hausdorff space the quasi-components of the points coincide with their connected components, but I'd like to know if the Hausdorff hypothesis is needed. I could not find a counterexample, i.e. a compact space in which a connected component is strictly contained in a quasi-component.
I tried with the finite-complement topology, but it is connected. So it cannot be a counterexample because such a space must have infinite connected components. So my question is: is there such a counterexample? P.S. Sorry for my bad English, but I'm Italian and don't speak English very well.","['general-topology', 'examples-counterexamples', 'compactness', 'connectedness']"
2628644,Regularity of the rational map $[X:Y:Z]\mapsto[X^2:XY:Z^2]$?,How to see that the mapping $[X:Y:Z]\mapsto[X^2:XY:Z^2]$ from the variety $V(Y^2Z-X^3-Z^3)\subset\mathbb{P}^2$ to $\mathbb{P}^2$ is regular at $[0:1:0]$?,"['elliptic-curves', 'algebraic-geometry']"
2628658,"Find the integrable function $g:[0,b]\rightarrow \mathbb R$ in order to satisfy $\int_{0}^{x} t\cdot g(t) dt=x+x^2$","I have found $g(x)=\frac{1}{x}+2$ but it doesn't satisfy for $x=0$ , that is needed. I also tried to define the function $g(x)=\frac{1}{x}+2$, with $ x>0$ and $ x\leq b$, $g(0)=0$. Is that possible and if not how do i solve this problem? Can we use Upper and Lower sums to solve it? (Riemann definition)","['integration', 'calculus']"
2628675,Simple Method of Solution of $X^p+Y^p=(X+1)^p$,"I am looking for simple prove of non existence of solution of $$X^p+Y^p=(X+1)^p$$
for $p>2$
I know it is partial case of Fermat Last Theorem. But I am looking for simple method without going into the complex part of group theory and algebra.
I have simply found from the Fermat Little Theorem that $$Y\equiv1\pmod p$$
But this the maximum I was able to get. Is there any idea how to solve this using simple methods?","['number-theory', 'diophantine-equations']"
2628694,Examples of unbounded approximate units in $C^*$-algebras,"Sometimes I see the requirement that approximate units $(u_\lambda)_\lambda$ in $C^*$-algebras must be eventually bounded, that means for some $C>0$ there is a $\lambda_0$ such that $\|u_\lambda\|<C$ for all $\lambda\ge\lambda_0$. Yet I can not come up with an example of an approximate unit that is not eventually bounded, so I'm asking for an example here. Bonus points when the approximate unit is a sequence and not just a net. For this question I define an approximate unit of a $C^*$-algebra $A$ as a net $(u_\lambda)_\lambda$ in $A$ such that $u_\lambda a\to a$ and $a u_\lambda\to a$ for all $a\in A$. I have looked at a few $C^*$-algebras I know: $C_0(\mathbb R)$: I'm quite positive that all approximate units are bounded here, but I have not worked out the details yet. $C_0(X)$ (and therefore all commutative $C^*$-algebras): I guess only something considerably larger than $X=\mathbb R$ can work, maybe $X=\ell^2(\mathbb N)$. group algebras $C^*(G)$: With the multiplication being a form of convolution my guess is that all approximate units converge to some ""dirac"" function with the weight being centered at the unit element of $G$. My gut feeling tells me again that these converge to $1$ in norm, but I could very well be wrong. compact operators on a Hilbert space $\mathcal K(H)$. The projections on finite subspaces are an approximate unit (bounded by 1). General case: Some $C^*$-subalgebra $A\subset\mathcal B(H)$.","['functional-analysis', 'c-star-algebras', 'operator-algebras']"
2628714,What modes of convergence does the Fourier transform preserve?,"Are there are modes of Convergence (i know of Uniformly, $L^1$,a.e. and in measure) that the Fourier transform of the given sequence preserve?","['fourier-analysis', 'measure-theory', 'convergence-divergence', 'fourier-transform']"
2628719,Proof verification: lower semi continuous at x implies that the lim inf of every convergent sequence is bigger than f(x),"Show that f is lower semi-continuous at x if, and only if,
$$
\liminf f(x_n) \geq f(x).
$$
for any sequence $(x_n)$ converging to $x$. Proof (only if)*: Assume that $f$ is lower semi-continuous at $x$. Let $(x_n)$ be an arbitrary sequence converging to $x$. Fix  an arbitrary $\varepsilon > 0$. Since $(x_n)$ converges to $x$, $\exists N \in \mathbb{N}$ s.t.  $\forall n\geq\mathbb{N}, \ \  |x_n - x| < \delta$ We have that by lower semi-continuity, this implies that (for every $n$ bigger than $N$) $f(x_n) - f(x) > -\varepsilon$. Then it is the case that
$$
\liminf f(x_n) - f(x) > -\varepsilon.
$$
Since we can take $\varepsilon$ to be as small as we want, we have that
$$
\liminf f(x_n) \geq f(x).
$$ Since if we assume by contradiction that $f(x) >$ lim inf $f(x_n)$, we get the existence of an $\varepsilon$ and an $\delta$ such that lim inf $f(x_n) - f(x) < -\varepsilon$. Does this proof hold? If not, which are the mistakes and the alternatives? Thank you *Proof of if comes by contradiction without much worries.","['real-analysis', 'functions', 'proof-verification', 'continuity', 'proof-writing']"
2628720,Riemann-Hurwitz's formula,"Let $k$ be an algebraically closed field with char $k \neq 2$. Let $C$ be the affine plane curve in $\mathbb{A}^{2}$ defined by: $y^{2}=f(x)$, where $f(x)=c_{d}x^{d}+c_{d-1}x^{d-1}+...+c_{0} \in k[x]$ has no repeated roots, $c_{d} \neq 0$. Let $C'$ be the unique nonsingular projective curve birational to $C$. The map 
$\phi: C \to \mathbb{A}^{1}$ by $(x,y) \mapsto x$ induces a morphism $\pi:C' \to \mathbb{P}^{1}$. Use $\pi$ to compute the genus of $C'$ in terms of $d$. I am trying to apply Hurwitz formula, we have $d$ ramification points, each of index $2$. So the degree of ramification divisor is d. Now what is the degree of $\pi$? If $\phi$ is of degree $1$, can we say $\pi$ is also degree $1$? If degree is indeed $1$, then I got $g=\frac{d}{2}$, which contradicts to the result from the Hilbert polynomial, which says if $C$ is a plane curve of degree $d$, $g=\frac{(d-1)(d-2)}{2}$. Can someone explain this? Thanks a lot!",['algebraic-geometry']
2628721,Measurable subset of Vitaly set has measure zero. Proof.,"$E_x = \{y \in [0,1]: x-y \in \Bbb{Q}\}$,
$ \varepsilon=\{A \subset [0,1]: \exists x \quad A=E_x\}  $ .We chose one element from each set of family $\varepsilon$. This is a Vitaly set $V$. Prove that if $E$ is measurable and $E \subset V$ then $E$ has measure $0$. $E_q = [0,1] \bigcap \Bbb{Q} $, $q \in \Bbb{Q} $ I don't know how $E$ looks. I know for example that every singleton is measurable and has measure zero. But I don't know how to explain that every measurable set of $V$ has measure zero.","['lebesgue-measure', 'measure-theory']"
2628733,How to find approximation of variance of $i^\text{th}$ order statistic [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Given PDF and CDF of a distribution, how does one find an approximation of $(\operatorname{Var}(X_i))$ using a normal approximation of $(X_i)$? According to ""Mathematica Laboratories for Mathematical Statistics"" by Jenny Baglivo (Theorem 9.1 on page 120), it is said that: $\operatorname{Var}(X_i) \approx p(1-p) / (n+2)f(x)^2$ where $f$ is PDF, $x$ is $p^\text{th}$ quantile of the $X$ distribution, and $p = i/(n+1)$ I have $0$ ideas on how we get to this result. I am absolutely drawing at a blank. Help is very much appreciated!","['statistics', 'variance', 'order-statistics']"
2628746,A simple proof of McDiarmid's inequality?,"$\newcommand{\Ex}{\mathrm{E}} \newcommand{\Pr}{\mathrm{Pr}} \newcommand{\Ind}{\mathbf{1}} \newcommand{\implies}{\Rightarrow}$
Let $f(x_1, \ldots, x_n)$ be a real valued function of $n$ variables, with each $x_i \in \mathcal{X}$, such that:
\begin{equation}
 \forall (x_1,\ldots,x_{n-1}) \in \mathcal{X}^{n-1}, 
| f(x_1, \ldots, x_{n-1}, x) - f(x_1, \ldots, x_{n-1}, x') | \leq 1 ,
\end{equation}
where $x, x' \in \mathcal{X}$. Note that McDiarmid's assumes that $f$ is 1-Lipschitz, i.e., the above condition holds if we change any coordinate (and not just the n-th coordinate). The constant 1 is not important, it can be any arbitrary constant. First, I use the Hoeffding's inequality to show that
for any arbitrary $(x_1,\ldots,x_{n-1})$:
\begin{equation*}
\Pr_{X_n}\{ \hat{\Ex}[f(x_1, \ldots, x_{n-1}, X_n)] - \Ex[f(x_1, \ldots, x_{n-1}, X_n)] \geq t \mid (x_1, \ldots, x_{n-1}) \} \leq e^{-2mt^2},
\end{equation*}
where $\hat{\Ex}$ is the average of $f(\cdot)$ over $m$ samples of the $X_n$ while fixing the first $n-1$ variables to $x_1, \ldots, x_{n-1}$. Next, I take expectation with respect to $X_1, \ldots, X_{n-1}$, of both sides of the equation to get: 
\begin{gather*}
\Pr_{X_n}\{ \hat{\Ex}[f(x_1, \ldots, x_{n-1}, X_n)] - \Ex[f(x_1, \ldots, x_{n-1}, X_n)] \geq t \mid (x_1, \ldots, x_{n-1}) \} \leq e^{-2mt^2} \\
\implies \Ex_{X_n}[ \Ind[\hat{\Ex}[f(x_1, \ldots, x_{n-1}, X_n)] - \Ex[f(x_1, \ldots, x_{n-1}, X_n)] \geq t] \mid (x_1, \ldots, x_{n-1}) ] \leq e^{-2mt^2} \\
\implies \Ex_{X_1, \ldots X_{n-1}}[\Ex_{X_n}\{ \Ind[\hat{\Ex}[f(x_1, \ldots, x_{n-1}, X_n)] - \Ex[f(x_1, \ldots, x_{n-1}, X_n)] \geq t]] \mid (x_1, \ldots, x_{n-1}) ] \leq e^{-2mt^2} \\
\implies \Pr_{X_1, \ldots, X_n}\{ \hat{\Ex}[f(X_1, \ldots, X_n)] - \Ex[f(X_1, \ldots, X_n)] \geq t \} \leq e^{-2mt^2}.
\end{gather*}
Essentially, I have shown concentration of $f(.)$ with respect to all variables by showing concentration with respect to only one variable and without constructing a Doob Martingale as the standard McDiarmid's proof does. The above is definitely wrong but I am not able to see where. Also, is the above proof correct if $\mathcal{X}$ is finite or countably infinite?","['probability', 'concentration-of-measure']"
2628755,Improper integral convergence: $\int_{0}^{1}{\frac{\mid{\log(x)}\mid^a}{\sqrt{1-x^2}}}dx$,"As its told on the title I want to check the convergence/divergence of the improper integral when $a\in \mathbb{R}$: \begin{equation}
\int_{0}^{1}{\frac{\mid{\log(x)}\mid^a}{\sqrt{1-x^2}}}dx
\end{equation}
So, it's improper at $x=0$ and $x=1$, so I split the integral in :
\begin{equation}
\int_{0}^{\frac{1}{2}}{\frac{\mid{\log(x)}\mid^a}{\sqrt{1-x^2}}}dx + \int_{\frac{1}{2}}^{1}{\frac{\mid{\log(x)}\mid^a}{\sqrt{1-x^2}}}dx 
\end{equation}
I see, that on the first one the integrals it's like $\int\mid{\log(x)}\mid^a dx $ by the comparison limit test, but I don't know how to prove that $\int\mid{\log(x)}\mid^a dx $ converges. Hopefully you can help me. Much thanks!","['improper-integrals', 'analysis']"
2628890,Let f be a continuous and differentiable function such that f(a)=f(b)=0,"Let $f:[a,b] \rightarrow \mathbb{R} $  be a continuous function in $[a,b]$ and differentiable in $(a,b)$   such that $f(a)=f(b)=0$ . Show that $7f(c)+cf'(c)=0$ for some $c \in (a,b)$. I tried to use rolle's theorem and the mean value theorem, but got stuck.
 Any hint will be appreciated.",['calculus']
2628911,Why are we allowed to cancel fractions in limits?,"For example: $$\lim_{x\to 1} \frac{x^4-1}{x-1}$$ We could expand and simplify like so: $$\lim_{x\to 1} \frac{(x-1)(x^3 + x^2 + x + 1)}{x-1} = \lim_{x\to 1} (x^3 + x^2 + x + 1) = (1^3 + 1^2 + 1^1 + 1) = 4$$ In this case we divided out $x-1$ on top and bottom even though technically, at $x=1$, we have $\frac{0}{0}$ that we're just tossing aside. But what allows us to do this?","['polynomials', 'fractions', 'calculus', 'limits']"
2628961,Can a linear subspace in Banach space be the union of several other subspaces?,"It's a well known exercise for students to prove that a linear subspace of $\mathbb{R}^n$ can't be expressed as the countable union of other subspaces. The proof is quite simple, including only the comparison of Lebesgue measure. However, it is not true for the linear space of polynomials. It can be the union of the subspace of degree 1 polynomials, polynomials of degree $\leq 2$, degree $\le 3$, .... By Baire's theorem, a Banach space cannot be covered by countable number of closed subspaces. So my question is whether a (Banach) vector space of uncountable dimension can be written the union of countably many proper subspaces. PS: I know it is rude to consider union of linear subspaces--it may be more appropriate to consider sums.... Just like Goldbach, one should not try to add primes, but multiply them:)","['functional-analysis', 'banach-spaces', 'topological-vector-spaces', 'linear-algebra']"
2628963,Has Number Fields by D. Marcus ever been typeset using TeX by anyone yet? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question As the title suggests, has anyone yet ""latexed"" Number Fields by Marcus yet? It's a classic book on number theory and I was thinking of slowly typesetting it in LaTeX during my free time, if no one has done it yet. Are there any copyright ramifications (no pun intended :)) due to this? I don't intend to make any money from this.","['number-theory', 'algebraic-number-theory', 'soft-question', 'reference-works']"
2628995,How to tell when a data series is a normal distribution,"I have a list of data, and I need to know if the values are normally distributed. 4 of the 20 values on the list lie outside of 3 standard deviations of the mean. Is the data normally distributed and why?","['means', 'data-analysis', 'standard-deviation', 'statistics', 'descriptive-statistics']"
2629011,"If $\sin (y)=x\sin (a+y)$, prove that:","If $\sin (y)=x\sin (a+y)$, prove that:
$$\dfrac {dy}{dx}=\dfrac {\sin^2 (a+y)}{\sin (a)}$$ My Attempt:
$$\sin (y)=x\sin (a+y)$$
$$\dfrac {d}{dy} \sin (y)=\dfrac {d}{dy} (x\sin (a+y))$$
$$\cos (y)=x\cdot \cos (a+y)+\sin (a+y)\cdot\dfrac {dx}{dy}$$
$$\cos (y)-x\cdot\cos (a+y)=\sin (a+y)\cdot\dfrac {dx}{dy}$$","['derivatives', 'calculus']"
2629014,How is Cayley's theorem useful?,"(By ""useful"" I mean, ""useful to prove other theorems"".) I understand Cayley's theorem (""every group $G$ is isomorphic to a subgroup of the symmetric group acting on $G$""), but I don't see what one can do with it. Granted, there is great merit in the unifying view that it gives of all groups, but I'd like to know of concrete deductions and lines of proof that Cayley's theorem makes possible. In other words, I'd love to see examples where Cayley's theorem ""saves the day"" (i.e. makes an otherwise difficult/intractable proof easy/tractable).","['abstract-algebra', 'group-theory']"
2629015,Finding the derivative of a function using its series expansion,"I recently came across a proof which stated that the derivative of $\sin{x}$ is $\cos{x}$ because if we differentiate the Maclaurin series expansion of $\sin x$, we get the series expansion of $\cos x$. Is this a valid proof? My doubt is that the Maclaurin series expansion itself is defined based on the derivative of the function. 
The following expansion is the Maclaurin series where $a=0$ and $f^{(n)}$ denotes the $n^{th}$ derivative of the function.
$$\sum_{n=0} ^ {\infty} \frac {f^{(n)}(a)}{n!} \, (x-a)^{n} $$
We can clearly see that we need the derivative in the first place before we can get the expansion. Is the proof valid?","['derivatives', 'taylor-expansion', 'calculus']"
2629020,Solve the initial value problem $y′=(x+y−2)^2$?,I don't usually have problems with solving ODEs but somehow I can't solve this one. I know that I have to substitute with $u$ and $u'$ but that's it...,['ordinary-differential-equations']
2629024,Odds of two names appearing together in a print ad - help with a gift to boyfriend.,"A print ad (for Loving Embrace pendants) used my name, Jennifer and my boyfriend's name, Matthew in their sample pendant.  What are the odds that those two names would be choosen?  Howmanyofme.com shows that there are 1,521,455 Jennifer's in the US and 1,075,792 Matthews. It doesn't have to be perfect; I'm just going to send him the advertisement with a note and would like to let him know what the odds are that we'd be paired together.",['statistics']
2629115,Calculate convolution (integral),"We will define the convolution (slightly unconventionally to match Rudin's proof) of $f$ and $g$ as follows:
  $$(f\star g)(x)=\int_{-1}^1f(x+t)g(t)\,dt\qquad(0\le x\le1)$$ Let $\delta_n(x)$ be defined as $\frac n2$ for $-\frac1n<x<\frac1n$ and 0 for all other $x$. Let $f(x)$ be defined as $x$ for $.4<x<.7$ and let $f(x)=0$ for all other $x$. Find a piecewise algebraic expression for $f\star\delta_{10}$ and graph $f\star\delta_{10}$. Repeat the exercise for $f\star\delta_{20}$. In what sense does $f\star\delta_n$ converge on $[0,1]$ and to what function does it converge? Hello everyone,
I just need help finding a piecewise algebraic expression for $f* \delta_{  10}$. I think I should be able to figure out everything else in the question once I know how to do this. Thoughts/things I know (how to do):
Delta 10 is defined as $5$ for $-1/10<x<1/10$ and $0$ otherwise. 
$f(x)=x$ for $0.4<x<0.7$ and $0$ otherwise.  I know how both graphs look like visually.  I guess you could say there is a jump in the graph of f(x) at 0.4 and 0.7 and a jump in the graph of $\delta_{10}$ at $-1/10$ and $1/10$. Now confusions: I believe that perhaps I will have to split up the problem into several cases/integrals as both f(x) and delta are piecewise.  The main problem in this question is I don't understand what the t represents so I don't know how to set up my bounds as my bounds are in terms of t (as we integrate with respects to $dt$).  I believe that the integral seemingly from the definition is only valid for $0\leq x<\leq1$ inclusive. Also if I'm doing $f* \delta_{10}$, lets say for x between $0.4<x<0.7$ then wouldn't $f(x+t)=x+t$ and $g(t)=0$? Overall, I think I'm confused so I could really use some guidance on this problem for the first case $f*\delta_{10}$, then I believe I could figure out the rest.
Thank you!","['real-analysis', 'convolution', 'functional-analysis', 'integration', 'ordinary-differential-equations']"
2629133,Calculating keno odds?,"In keno, the casino picks 20 balls from a set of 80 numbered 1 to 80. Before the draw is over, you are allowed to choose 10 balls. What is the probability that 5 of the balls you choose will be in the 20 balls selected by the casino? My attempt: The total number of combinations for the 20 balls is $80\choose20$. However, I get stuck at the numerator. I thought it will be $\binom{80}{10}\binom{10}5$ but that's wrong. Thanks.","['combinatorics', 'probability']"
2629139,Integration with respect to the empirical process?,"Let $X_1, X_2, \dots, X_n$ be i.i.d from distribution $F(x)$. Let $v_n (x)$ be the corresponding empirical process $$v_n (x) = \sqrt{n} \left[ F_n (x) - F(x) \right]$$ where $F_n (x)$ is the empirical distribution function. Then I would like to understand the integral of a deterministic function $g(x)$ with respect to $v_n (x)$. That is, the integral $$ \int_\mathbb{R} g(y) dv_n (y)$$ Intuitively, when I first saw this integral I interpreted it as $$ \int_\mathbb{R} g(y) dv_n (y) = \sqrt{n} \left( \int_\mathbb{R} g(y) dF_n (y) - \int_\mathbb{R} g(y) dF(y) \right)$$ Which in turn gives $$ \frac{1}{\sqrt{n}} \sum_{i=1}^n g(X_i) - \sqrt{n} \int_\mathbb{R} g(y) dF(y)$$ Is this the correct interpretation?","['stochastic-processes', 'probability-theory', 'integration', 'probability']"
2629144,Can a subsequence repeat a term finitely many times?,"Suppose $\{a_n\}$ is a sequence. Let $f(n)$ be an increasing function(not strictly) such that $f$ takes each of its values finitely many times, then wouldn't $\{a_{f(n)}\}$ have the same limit as $\{a_n\}$ (assuming $\{a_n\}$ converges)? Then shouldn't $\{a_{f(n)}\}$ be considered a subsequence of $\{a_n\}$? UPDATE: Edited to clarify what I meant.","['real-analysis', 'sequences-and-series', 'calculus']"
2629164,"Taking the derivative of a product, which is made up of two quotients","I'm working on a calculus question, where we're asked to find $g'(z)$ for
$$g(z)=\frac{z^2-2z-8}{z-3}\cdot\frac{z^2-9}{z-4}$$
So I was thinking that first you have to use the quotient rule on each side individually and then multiply them, but I seem to keep getting stuck and it's becoming pretty frustrating.","['derivatives', 'calculus']"
2629205,Why are $-1$ and $1$ generators for the Set of integers under addition?,"I'm reading my textbook and I'm confused why $-1$ and $1$ are generators for the group of integers under addition. For example for 1:
we have $1, 1+1=2, 1+1+1=3, 1+1+1+1=4,$ etc.
So shouldn't $1$ be a generator for only the group of positive integers under addition? For $-1$: we have
$-1, -1+-1=-2, -1+-1+-1=-3$.  So shouldn't $-1$ be a generator for only the group of negative integers under addition? Or is it that both $1$ and $-1$ are generators for the set of integers under addition because in the definition of cyclic subgroup $\{a^n; n\in \Bbb Z \}$, $n$ can take on negative powers? Or am I just confused? Thanks.","['abstract-algebra', 'group-theory', 'cyclic-groups']"
2629225,Solve the initial value problem: ODE with discontinuous coefficients?,"Solve the initial value problem
  $$
y'-y = \left\lbrace
\begin{aligned}
&1 & & \text{when}\quad 0<t<1 \\
&0 & & \text{when}\quad t>1
\end{aligned}
\right.
,\qquad
y(0)=0 \, .
$$ So I understand that $p(t)=-1$ and $g(t)$ is $1$ and $0$ (depending on the $t$ value), and that I'm supposed to solve it as two separate DEs. I got for the first case that $y=-1$ and for the second case that $y=0$. Is this correct? Is this the solution? Or do I have to do something with the initial value $y(0)=0$? Any help is appreciated !!","['ordinary-differential-equations', 'initial-value-problems']"
2629271,Is a random intermediate cardinality set nonmeasurable with probability one?,"Assume the continuum hypothesis fails, so that we have some intermediate cardinal $d$ with $\omega < d < c$.  Choose a random subset $S \subset [0,1]$ of cardinality $d$ by sampling $d$ i.i.d. uniform points. Intuitively, it seems like $S$ will be nonmeasurable with probability one.  That is, almost all intermediate cardinality subsets of $[0,1]$ are nonmeasurable.  This is because its outer measure is 1, and the outer measure of the complement is 1, both with probability 1. Unfortunately, I am unsure whether this claim can be formalized.  The random process that generates $S$ is just a product of random variables, so that part is easy.  However, it's not obvious that the set of measurable sets is itself measurable, without which the claim can't be stated. Can this claim be appropriately formalized into a true theorem?","['set-theory', 'measure-theory']"
2629295,Find angle inside isosceles triangle [duplicate],This question already has answers here : Angles on a point inside a triangle (3 answers) Closed 2 years ago . Please help. I have tried to find the answer but I couldn't. I have tried to draw a picture and measure the angle. It gives the answer $\theta = 25^\circ$ but I don't know how to do it. Thank you,"['angle', 'triangles', 'geometry']"
2629331,Three circles have the same radical axis?,"Given three circles $\bigcirc O_1$, $\bigcirc O_2$, $\bigcirc O_3$, let $A$, $B$, $C$ be three points on $\bigcirc O_3$. If we have 
  $$
\frac{\operatorname{power}(A, \bigcirc O_1)}{\operatorname{power}(A, \bigcirc O_2)}=
\frac{\operatorname{power}(B, \bigcirc O_1)}{\operatorname{power}(B,\bigcirc O_2)}=
\frac{\operatorname{power}(C, \bigcirc O_1)}{\operatorname{power}(C, \bigcirc O_2 )}$$ (where $\operatorname{power}(P, \bigcirc Q)$ denotes the power of point $P$ with respect to $\bigcirc Q$ ), can we conclude that these circles have the same radical axis?",['geometry']
2629341,Proper curves over some field are projective,I'm looking for a reference of the statement Let $X$ be a proper curve (scheme of dimension one) over the field $k$. Then $X$ is projective. There is a some kind of guided exercise in Liu's Algebraic Geometry and Arithmetic Curves (Ex. 7.5.4). Does someone know a reference? Thank you very much in advance!,"['algebraic-curves', 'projective-schemes', 'algebraic-geometry']"
2629361,Value of $S_{10}+I_{10}$,Let $S_n=\sum_{i=1}^n  \frac{1}{k}$ and$$I_n=\int_{1}^{n}   \frac{x-[x]}{x^2}  dx$$ then what is the value of $S_{10}+I_{10}$ ? $S_{10}=1+1/2+1/3+.....+1/10$  and $$I_{10}=\int_{1}^{10}   \frac{x-[x]}{x^2}  dx$$ $$=ln 10-\int_{1}^{10}   \frac{[x]}{x^2}  dx$$ But I am stuck here.How to proceed further?,"['real-analysis', 'sequences-and-series']"
2629371,"I've got a formula for a generating function, but I can't seem to solve it","I'm trying to solve the recurrence
$$
a_j = 0 \quad j \leq 0\\
a_1 = 1\\
\sum_{k=0}^{\frac{n}{2}}a_ka_{n-k} = 2\sum_{k=0}^{\frac{n}{2}}a_ka_{n-2k} - \sum_{k=0}^{\frac{n}{2}}a_ka_{n-4k} \qquad n \geq 2
$$ The equation I got for the generating function$$A(x) = \sum_{n=0}^{\infty}a_nx^n$$
$${A(x)}^2 = (2A(x^2) - A(x^4))(A(x)-A(-x)) + 2A(x^4)(A(x^2) - A(-x^2))$$
This level of hideousness is beyond my capabilities....and wolfram alpha's. How can I solve for A(x)?","['generating-functions', 'recurrence-relations', 'discrete-mathematics']"
2629386,Alternate method to find distribution of function of X,"Let $X_1,X_2 ,... X_n ;(n\geq1)$ be a random sample from $Exp(1)$. Then the distribution of $2n\bar X$ is ? $(A) Exp\bigg(\dfrac{1}{2}\bigg)$ $(B) Exp(2n)$ $(C)\ \ \chi^2_{(n)}$ $(D)\ \ \chi^2_{(2n)}$ I solved this problem using Mgf : Let $Y=\sum X_i$ $Y\sim G(1,n)$ $M_Y(t)=(1-t)^{-n}$ $M_{2Y}(t)=(1-2t)^\frac{-2n}{2} \sim \chi^2_{(2n)}$ Correct me in the above steps and please tell me any alternate method(s) which cab be used in this problem or any shortcut. This question came in 1 mark so i think there is some shortcut here. (Poor English sorry ). Gamma distribution :If $Y\sim G(a,\lambda)=$ $\dfrac{\alpha^{
 \lambda}}{\Gamma{(\lambda)}}e^{-ax}x^{\lambda-1} \ \ ; \ \ (a>0) ,(\lambda>0), (x>0)$ (Please try to use this notation for gamma density i just started learning these things so it can be a case i might get confused)
.","['exponential-distribution', 'statistics', 'probability', 'chi-squared']"
2629460,$K(Y)$ is isomorphic to the quotient field of $A(Y).$,"I am doing some self study on Algebraic Geometry and following Hartshornes Algebraic Geometry book. I have some difficulties in understanding Theorem 3.2 from chapter 1. I am stating it below. Let $Y \subset \mathbb{A}^n$ be an affine variety with affine coordinate ring $A(Y)=A/I(Y),$ where $A=K[X_1,\ldots,X_n].$ I stuck in (d) where it states that $K(Y)$ is isomorphic to the quotient field of $A(Y),$ where the function field $K(Y)$ is defined as the equivalence class of $<U,f>$ where $f: U \to K$ is regular map and consider the identification $<U,f>=<V,g>$ when $f=g$ on $U \cap V$( which is always non-empty since $Y$ is irreducible). I understand that quotient field of $A(Y)$ is isomorphic to the quotient field of $\mathscr{O}_p$ (where $\mathscr{O}_p$ denotes the local ring at the point $p \in Y)$ is contained in the function field $K(Y).$ Only thing troubled me  is the line where it states every rational function is in some $\mathscr{O}_p.$ I stuck here how it shows that quotient field of $\mathscr{O}_p$ is equal to $K(Y)$ ? In my thought it may happen that for different $p \in Y$ the quotient field of $\mathscr{O}_p$ has different copy in $K(Y).$Or may be I am missing something. I need your help. Many thanks.","['affine-schemes', 'algebraic-geometry', 'commutative-algebra']"
2629465,Is there a simple bijection between $\mathbb{R}^2$ and lines on a plane?,"The two sets have the same cardinality as $\mathbb{R}$, so there is a bijection, but I can't come up with a simple function or prove that one does not exist.",['elementary-set-theory']
2629491,Find maximizing region for triple integral,"Given the following triple integral: $-\iiint_D (x^2 + y^2 + z^2 -4) \,dV$ How can I find the closed surface out of which the above integral is maximal? I am using the divergence theorem to calculate flux through a surface.","['multivariable-calculus', 'integration']"
2629499,Intersection between two hyperboloids,"I have two one-sheet hyperboloids defined as locus of points with same difference of distances from two arbitrary points in space (the foci). Given $P_1 (x_1, y_1, z_1)$, $P_2 (x_2, y_2, z_2)$ and the euclidean distance between two points $d=\sqrt{(x_a-x_b)^2+(y_a-y_b)^2+(z_a-z_b)^2}$ I can define the hyperboloid with difference of distances $d_{1,2} \in \mathbb{R}$ as $\sqrt{(x-x_1)^2+(y-y_1)^2+(z-z_1)^2} - \sqrt{(x-x_2)^2+(y-y_2)^2+(z-z_2)^2} = d_{1,2}$ Same for another hyperboloid with difference of distances $d_{1,3} \in \mathbb{R}$ from $P_1$ and $P_3(x_3, y_3, z_3)$ $\sqrt{(x-x_1)^2+(y-y_1)^2+(z-z_1)^2} - \sqrt{(x-x_3)^2+(y-y_3)^2+(z-z_3)^2} = d_{1,3}$ ( By the way, is this correct or there are neater ways to describe this kind of hyperboloids? ) This is a plot for some negative values $d_{1,2}\; d_{1,3}$ and some coordinates for $P_1, P_2, P_3$ : How can I describe the intersection (in red below) between these two surfaces? Maybe this can be done through parametrization?","['surfaces', 'geometry']"
2629500,Average and standard deviation equation system,Every exam has 100 points. Student's average of 3 exams is 88 points and standard deviation is 3. How many points should he get on fourth and fifth exam so that average is 90 and standard deviation stays same (=3). I tried solving equations $(x_1+x_2+x_3)/3=88$ and $(x_1+x_2+x_3+x_4+x_5)/5=90$. Since $x_1+x_2+x_3=264$ it means that $(264+x_4+x_5)/5=90$ so $x_4+x_5=186$. Then I tried to use equations for standard deviation but I haven't managed to get anything useful.,"['statistics', 'standard-deviation', 'average']"
2629504,About a step in the proof of Doob's $L^{p}$-maximal inequality,"We had the above mentioned theorem in class recently. Assume that $(X_n)$ is a nonnegative submartingale. Then for all $n \in \mathrm{N}$ and all $p \ge 2$ 
  $$
\| \max_{k \le n}X_k \|_p \, \le \,  \frac{p}{p-1} \|X_n\|_p 
$$ In the middle of the proof there is one step I can't follow. We introduced a stopping time $\tau$ given by $$
\tau = \inf \{n :  X_n \ge K \}
$$ for $K \le \infty$ and then deduced $$
\mathrm{E} \left[  \max_{k \le n}\left( X_{\tau \land k } \right)^p  \right] \le \mathrm E \left[  \max_{k \le n-1} \left( X_{\tau \land k } \right) ^p  \right] + \mathrm E \left[ \left( X_n \right)^p \right] \le K^p + \mathrm E \left[ \left( X_n \right)^p \right] .$$ I could see that this is true for example for a Brownian motion but why does this also hold in discrete time. Any help is appreciated very much.","['stochastic-processes', 'probability-theory', 'martingales']"
2629531,Derive $\frac{1}{x}$,"I try to derive $\frac{1}{x}$. I try to do it with the $x_0$ method. I have $m=\frac {f(x_0)-f(x)}{x_0-x}$
I am using $\frac {1}{x} $ to replace $f(x_0)$ and $f(x)$. Now we have
$m=\frac {\frac {1}{x_0}-\frac {1}{x}}{x_0-x} $ However I want to derive so I need to shorten $x_0-x$ in the denominator. So I need to have anothe $x_0-x$ in the numerator. I basically need to do: $\left(\frac {1}{x_0}-\frac {1}{x}\right)÷(x_0-x)$ However here I get stuck. It would be nice if someone could help me to calculate this division.","['derivatives', 'polynomials', 'discrete-mathematics']"
2629552,Differential Geometry tools in Several Complex Variables,"I am studying some several complex variables theory. I have encountered integrals like
$$
\int_{\partial P(z_0,r)}\frac{f(\zeta_1,\dots,\zeta_n)}{(\zeta_1-z_1)\cdots(\zeta_n-z_n)}\,d\zeta_1\wedge\cdots\wedge d\zeta_n
$$
where $P(z_0,r)$ is a polydisc centered in $z_0\in\Bbb C^n$ with muluradius $r=(r_1,\cdots,r_n)$ with $r_j>0$ and $f:\Bbb C^n\to\Bbb C$ is continuous (this integral defines a function of $z=(z_1,\dots,z_n)\in P(z_0,r)$). Now, I know these kind of integrals are integrals of differential forms on manifolds, but they are new for me. I took a good book of differential geometry, in order to becoming able to handle these integrals, but learning all the structure relies under integration of differential forms on manifold seems would taking a lot of time. All this theory is really interesting, but I have to read a paper on several complex variables and I cannot ""consume"" time and energy on things which are not dealing with the work I have to study, since I have deadlines to respect. Thus my answer is: does a complete study of differential geometry is necessary or can I study somewhere simply the tools I need? For example, I think studying SCV I will work always with open subsets of $\Bbb C^n$, not with abstract and general differential complex manifold. Are, in this framework, the integration tools needed simpler? If yes, can you provide some good references? My goal is understand and work freely with the integrals one find studying SCV.","['reference-request', 'several-complex-variables', 'integration', 'differential-geometry']"
2629581,Can a compact connected set in $\mathbb{R}^n$ with empty interior have positive Lebesgue measure? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Is there a compact connected subset if $\mathbb{R}^n$, with empty interior but positive Lebesgue measure?","['connectedness', 'lebesgue-measure', 'compactness', 'measure-theory', 'outer-measure']"
2629591,What is the definition of a free abelian group generated by the set $X$?,"What is the definition of a free abelian group generated by the set $X$? If $X=\{A,B,C,D\}$ what are the elements of the free abelian group on this set?  What is the identity of this group?","['abstract-algebra', 'free-abelian-group', 'abelian-groups', 'group-theory', 'definition']"
2629592,What's the relation between the Darboux Frame and the Frenet-Serret on a oriented surface?,"I'm studying differential geometry and I'm in the part of geodesics, my professor always defines a curve that can define the tangent field but for calculating the geodesics and normal curvatures at each point $\alpha(t)$ of the curve he defines the frame $D=\{\alpha'(t),\alpha(t)\times N(\alpha(t)),N(\alpha(t))\}$ where $N$ is the Gauss application of the surface, so we get $$\alpha''=\langle\alpha'',\alpha\times N(\alpha)\rangle\,\alpha\times N(\alpha)  + \langle\alpha'',\ N(\alpha)\rangle \,N(\alpha)$$ where these coefficients are the geodesic and normal curvatures of $\alpha$ . My question is, what's the relation between $D$ and the Frenet-Serret $F=\{\alpha^{'}(t),n(t),b(t)\}$ where $n$ and $b$ are the normal and binormal of the curve, is there a relation between $n$ and $\alpha\times N(\alpha)$ , or $b$ and $N(\alpha)$ ? I'm having several dificulties about exercises involving this because I don't know how to compare results of curves, like torsion with the Darboux vectors.","['curves', 'frenet-frame', 'differential-geometry', 'surfaces', 'geodesic']"
2629600,Construct a semidirect product in GAP,"I am trying to create the following group $G=(\operatorname{SL}_2(8) \times C_2 \times C_2) \rtimes C_3$ where the $C_3$ acts simultaneously: on $\operatorname{SL_2(8)}$ as the outer automorphism of order $3$ on $C_2\times C_2$ as the automorphism that permutes the three nonidentity elements I tried the following instructions: gap> C:=CyclicGroup(2);
 gap> C:=DirectProduct(C,C);
 gap> G:=DirectProduct(SL(2,8),C);
 gap> A:=AutomorphismGroup(G);
 gap> I:=InnerAutomorphismsAutomorphismGroup(A);
 gap> B:=A/I;
 gap> S:=SylowSubgroup(B,3);
 gap> SemidirectProduct(S,G); But sadly it gives me an error. I assume it is because of the quotient, but I do not know how I could ""find"" the correct $C_3$ action in $A$ without removing the inner automorphisms first. Is there a way of doing such a thing? Edit: I get this error after the last line Error, usage: Image(<map>), Image(<map>,<elm>), Image(<map>,<coll>) called from
 Image( aut, PreImagesRepresentative( epi, i ) ) at /proc/cygdrive/C/gap4r8/lib/grppclat.gi:88 called from
 func( C[i] ) at /proc/cygdrive/C/gap4r8/lib/coll.gi:746 called from
 List( GeneratorsOfGroup( f ), function ( i )
  return Image( epi, Image( aut, PreImagesRepresentative( epi, i ) ) );
   end ) at /proc/cygdrive/C/gap4r8/lib/grppclat.gi:88 called from
 InducedAutomorphism( niso, i ) at /proc/cygdrive/C/gap4r8/lib/gprd.gi:1094      called from
 SemidirectProduct( G, IdentityMapping( G ), N ) at /proc/cygdrive/C/gap4r8/lib/gprd.gi:1071 called from
 ...  at line 15 of *stdin*
 you can 'quit;' to quit to outer loop, or
 you can 'return;' to continue","['finite-groups', 'group-theory', 'gap']"
2629605,Another version of mean value theorem,"Let $f$ be a real valued differentiable $n+1$-times on $\Bbb R. $ Show that for each $a<b$ such that, $$\ln\left(\frac{f(b)+f'(b)+\cdots+ f^{(n)}(b)}{f(a)+f'(a)+\cdots+ f^{(n)}(a)}\right)=b-a$$
there exists $c\in (a,b)$ such that $$f^{(n+1)}(c)= f(c)$$ I have the feeling one should apply the classical mean value theorem. But I don't know to what exact function I should apply it. Can someone provide me with a hint?","['derivatives', 'real-analysis', 'logarithms', 'calculus', 'analysis']"
2629606,Conditional variance of joint density.,"Joint density for X and Y is $f(x,y)=2e^{-x-2y} \ \ \ \ \ \ $for$ \ \ \ x>0,y>0 $ $0$ otherwise Calculate the variance of $Y$ given that $X>3$ and $Y>3$ Can we use this formula somehow here $V(Y)=E(V(X|Y))+V(E(X|Y))$? I thought that because joint density seems like product of two exponential distributions one can be conditional density and other can be marginal. Am i think totally wrong ? Bad way to deal this problem i guess. When i tried to solve this it was very laborious.","['statistics', 'conditional-expectation', 'probability']"
2629615,"Minimum distance from the points of the function $\frac{1}{4xy}$ to the point $(0, 0, 0)$","I am trying to find the minimum distance from the points of the function $\large{\frac{1}{4xy}}$ to the point $(0, 0, 0)$. This appears to be a problem of Lagrange in which my condition: $C(x,y,z) = z - \frac{1}{4xy} = 0$, and my function would be $f(x,y,z) = \sqrt{x^2+y^2+z^2}$ or if i'm correct, it would be the same as the minimum value I get from using thee function as $f(x,y,z) = x^2+y^2+z^2$. If I do this, I would then have: $$
f(x,y,z,\lambda) = x^2 + y^2 + z^2 + \lambda(z-\frac{1}{4xy}) \\
= x^2 + y^2 + z^2 + \lambda z-\frac{1}{4xy} \lambda
$$ Then findind the partial derivatives ($\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}, \frac{\partial f}{\partial \lambda}$) and solving for the values of $x, y, z, \lambda$ and the minimum value I get at the end would be my answer. Would that be the correct solution?","['derivatives', 'partial-derivative', 'extreme-value-theorem']"
2629649,Understanding high and low frequency eigenmodes.,"I'm studying basic iterative methods and about solving PDEs with basic iterative methods. I came across the following text in my lecture notes ""In this section we revisit the convergence of BIMs applied to the discrete Poisson equation and reveal what causes their slow convergence. To this end we consider solving the linear system $$A^hu^h = f^h$$ resulting from finite difference discretisation of a PDE. The eigenmodes can be subdivided into low and high frequency modes. The low frequency modes are slowly varying grid vectors that correspond to the small eigenvalues of $A^h\in\mathbb{R}^{n\times n}$. We more precisely have that in one and two dimensions (of the PDE) the low frequency modes are the eigenvectors $v^{h,[k]}$ for $1\leq k\leq n/2$ and $v^{h,[kl]}$ for $1\leq k,l\leq n/2,$ respectively. The remaining eigenmodes are called the high frequency modes and correspond to oscillatory grid vectors."" I have never heard about eigenmodes or slowly varying grid vectors before, and this text doesn't make a lot of sense to me. Question: What are high and low frequency eigenmodes in this example? What does it mean for a vector to be slowly varying or oscillating, and why do the slowly varying grid vectors correspond to the small eigenvector? What do the superscripts above the eigenvectors in the one or two dimensional case mean? Thanks! Thanks in advance!","['eigenvalues-eigenvectors', 'partial-differential-equations', 'algorithms', 'numerical-methods', 'ordinary-differential-equations']"
2629654,Double summation involving factorials,Find the value of $\displaystyle \sum_{m=1}^\infty \sum^{\infty}_{n=1}\frac{m\cdot n}{(m+n)!}$. My try: $$\sum^{\infty}_{m=1}\bigg(\frac{m}{(m+1)! }+\frac{2m}{(m+2)!}+\cdots\cdots +\frac{m+\infty}{(m+\infty)!}\bigg)$$ I did not understand how to start it. I could use some help. Thanks.,['sequences-and-series']
2629656,Improper Uniform Distribution on $\mathbb{R}$,"It is not possible to write a function representing the uniform distribution, say $\mathcal{U}$, on the real line, $\mathbb{R}$ (in a Bayesian context, this is an improper prior). My question is: is it possible to write a generalized function (aka, a distribution , but I avoid this term as it may cause confusion with the ""distribution"" used in probability terminology) corresponding to $\mathcal{U}(\mathbb{R}) $? Additional text to give more context to the question. Just as Dirac's Delta can be represented as a limiting process of gaussians, i.e.,
$$
\delta(t) = \lim_{\sigma^2 \rightarrow 0} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{1}{2 \sigma^2} t^2 }
$$
in principle, $\mathcal{U}(\mathbb{R})$ could be represented as
$$
\mathcal{K}(t) = \lim_{ \sigma^2 \rightarrow +\infty} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{1}{2 \sigma^2} t^2 }
$$
in some sense of the limit. Clearly, it must hold that
$$
\int^{+\infty}_{-\infty} \mathcal{K}(t) dt = 1
$$
just as with Dirac's Delta. I do not know if there are technical difficulties that arise in measure theory for this case. Related question: link . But I would like a bit more details as an answer.","['uniform-distribution', 'probability-theory', 'probability-distributions']"
2629680,What is the closed form of the sequence : $ a_{n+2} = 2a_{n+1}-a_n+2^n+2 $,"I would like to find the closed form  of the sequence given by 
  $$ a_{n+2} = 2a_{n+1}-a_n+2^n+2,~~~~n > 0~~~~and~~~a_1 = 1, ~~~~a_2 = 4$$ This task is in the topic of differential and difference equation.
I don't know how to start solving this problem and what are we looking for? ($a_n, a_{n+2}$) I do know how to solve the following form
$$ a_{n+2} = 2a_{n+1}-a_n $$ using linear algebra as well. The actual problem I encountered  the obstructionist term $\color{red}{2^n+2}$. Are there some kind of variational constant method for recursive linear sequences,? I only now this method for linear ODE with constant coefficient. But I believe that such method could be doable here as well. Can any one provide me with a  helpful hint or answer?.","['real-analysis', 'calculus', 'closed-form', 'telescopic-series', 'sequences-and-series']"
2629719,Conjugate error - What am I doing wrong?,"I have this equation and I'm multiplying a conjugate but I'm not getting the right answer. $$f(x)=x\sqrt{x}$$
$$\lim_{h \to 0}{(x+h)(\sqrt{x+h})-x\sqrt{x}\over h} \times {\sqrt{x+h}+\sqrt{x}\over\sqrt{x+h}+\sqrt{x}}$$
$$\lim_{h \to 0}{x^2+2xh+h^2-x^2\over{h(\sqrt{x+h}+\sqrt{x}})}$$
$$\lim_{h \to 0}{h(2x+h)\over{h(\sqrt{x+h}+\sqrt{x}})}$$
$$2x\over2\sqrt{x}$$
instead of $${3\sqrt{x}\over2}$$","['derivatives', 'radicals', 'limits', 'calculus', 'fractions']"
2629801,Let $A\subset B$ be an injective homomorphism of noetherian integral domains s.t. $B$ is finite as $A$-module and $A$ normal.,"Let $A\subset B$ be an injective homomorphism of noetherian integral domains s.t. $B$ is finitely generated as $A$-module and $A$ normal. Suppose that the normalization $\bar B$ of $B$ is finitely generated as $A$-module. And call $F_A\subset F_B$ the induced extension of fraction fields. (i) Prove that if $\Omega_{B/A}=0$ then $B$ is normal. (ii) Prove that if there exists $0\neq s\in A$ such that $\Omega_{[s^{-1}]B/[s^{-1}]A}=0$ iff $F_A\subseteq F_B$ is a separable field extension. (iii) Provide an example where $\Omega_{B/A}\neq 0$, but $B$ is normal. (iv) Prove that there exists $0\neq s\in A$ s.t. $B[s^{-1}]=\bar B[s^{-1}]$. I've tried in this way: (i) I've considered the conormal sequence, with $B\cong A[X_1, ..., X_n]/(f_1,..., f_m)$, then i've got that, called $I=(f_1, ..., f_m)$, 
$$I/I^2 \rightarrow \bigoplus_{i=1}^{n} Bdx_i\cong B\otimes_A \Omega_{A[X_1,..., X_n]/A}$$ then map is surjective. My idea was to obtain some information about maximal ideals. (ii) Done (iii) I've considered $R=\frac {k[X,Y]}{(Y^2-X(X-1)(X+1))}$ and $A=k[X]$. In fact $R$ is normal since $X(X-1)(X+1)$ has no multiple roots, and $A$ UFD so it's normal. 
$$\Omega_{R/A}\cong \frac{Rdx\oplus Rdy}{(2ydy+(3x^2-1)dx)R}\neq 0$$ (iv) No idea at all.","['abstract-algebra', 'modules', 'algebraic-geometry', 'commutative-algebra']"
2629830,Proof of all finite subsets on $\mathbb{R}$ together with complements is not a $\sigma$ algebra,"Reference- ""Knowing the Odds: An introduction to probability"" by John B. Walsh 2011 edition.
Ex-1.1 Show that the following class is a field, but not $\sigma$-field- All finite subsets of $\mathbb{R}$ together with their complements My arguments- Let class be $\mathcal{C}$. Since the there are finite subsets in $\mathcal{C}$, let $(-\infty, 1] \in \mathcal{C}$. Therefore, $(1, -\infty) \in \mathcal{C}$ because complements also exist. Since it's not given as a condition, I think I have the right not to include $\Phi$ and $(-\infty, \infty)$. So, I can't even see $ \mathcal{C}$ as a field too, as union will produce $(-\infty, \infty) \notin \mathcal{C}$. [I must have been wrong here with something very elementary] Even if I consider $\Phi, (-\infty, \infty) \in \mathcal{C}$, Taking the countable unions of all elements in $\mathcal{C}$ (union of all 4 elements), I will again get $\mathbb{R} \in \mathcal{C}$ which shows that countable union is in $\mathcal{C}$. More generally, for any interval $I \in \mathcal{C}, I^C \in \mathcal{C}$. Considering $\mathbb{R}, \Phi \in \mathcal{C}$, $I\cup I^C = \mathbb{R} \in \mathcal{C}$. Now no matter hom many finite intervals are there in $\mathcal{C}$, their union will be $\mathbb{R} \in \mathcal{C}$ and hence contians all countable unions. Hence, it should be a $\sigma$-field. I might have some impreciseness about the concepts and arguments. Kindly help me in correcting those.","['measure-theory', 'elementary-set-theory']"
2629838,Existence of partial derivatives & Cauchy-Riemann does not imply differentiability example,"I learned about the Cauchy-Riemann equations today, and my instructor used the following example to show that differentiability is not guaranteed if the partial derivatives are not continuous. Let
$$
f(z)=f(x+iy)=
\begin{cases}
\frac{xy(x+iy)}{x^2+y^2},&\quad\mbox{$z\neq 0$}\\
0+0i,&\quad\mbox{$z=0$}.
\end{cases}
$$
Similar to the example here , writing $f(z)=f(x+iy)=u(x,y)+iv(x,y)$, we can show that $u_x(0,0)=0$ and $v_y(0,0)=0$ since the partial derivatives are $0$ on the axes, but $f$ is not continuous and thus not differentiable at $(0,0)$ since the limits are different if we approach $(0,0)$ along the imaginary axis or along $x=y$. My instructor mentioned that reason why in the above example, differentiability fails even though the partial derivatives exist and satisfy the Cauchy-Riemann equations, is that the partial derivatives are not continuous at $(0,0)$ (there is a similar comment in this document ). I wrote out the partial derivatives
\begin{align*}
u_x &= \left(\frac{x^2y}{x^2+y^2}\right)'=\frac{2xy(x^2+y^2)-x^2y(2x)}{(x^2+y^2)^2}=\frac{2xy^3}{(x^2+y^2)^2}\\
v_y &= \left(\frac{xy^2}{x^2+y^2}\right)'=\frac{2yx^3}{(x^2+y^2)^2}.
\end{align*}
E.g., consider $u_x$ - if I approach $(0,0)$ from the real axis, the limit of $u_x$ is $0$; if I approach $(0,0)$ from the line $x=y$, the limit of $u_x$ would be $1/2$. I thought this is why $u_x$ is not continuous at $(0,0)$. But looking at the formulas alone, it seems that the partial derivatives are simply not defined at $(0,0)$ because the denominators would be $0$ (if so, then this would already imply the partial derivatives are not continuous at $(0,0)$ and we wouldn't even need the argument using unequal limits). But we have just shown before that the partial derivatives exist at $(0,0)$. I must be missing something. According to a post here , it may have something to do with the definition of $f$ at $(0,0)$. Any help is much appreciated!","['derivatives', 'complex-analysis', 'partial-derivative', 'continuity']"
2629855,Is the complement of a complex affine algebraic set in an irreducible complex affine algebraic set (path) connected in the euclidean topology?,"Let $n \ge 2$, and $V$ be an affine algebraic set in $\mathbb C^n$ and $W$ be an irreducible affine algebraic set in $\mathbb C^n$, with $V \subsetneq W$ ; then is it true that $W \setminus V$ is connected in the Euclidean topology of $\mathbb C^n $ ? Is it path connected in the Euclidean topology ? I can see that $W \setminus V$ is connected in the Zariski topology of $\mathbb C^n$, but I can't figure out in the Euclidean topology.","['algebraic-geometry', 'affine-geometry', 'affine-varieties', 'several-complex-variables', 'commutative-algebra']"
2629882,Expected number of coin tosses before obtaining at least 1 head,"We have covered conditional probabilities and law of total expectation so far but I have a very poor understanding of those concepts. I have absolutely no clue on how to proceed with this question: A fair die is thrown and a coin is tossed the number of times as the score shown on the die. If any heads are shown in the tosses of the coin, we stop, otherwise, we continue the experiment of throwing the die and coin toss until at least one head is shown. Find the expected number of coin tosses before we stop.","['expectation', 'probability']"
2629896,Use combinatorial arguments to prove the following binomial identities,"Can anyone help prove this binomial identities by using the combinatorial arguments, I have no clue to get start. Thanks.
$$\binom{2n+1}{n}=\sum_{k=0}^{n}\binom{n+k}{k}$$","['combinatorial-proofs', 'proof-explanation', 'proof-verification', 'discrete-mathematics']"
2629897,Does an irreducible real affine algebraic set/ its complement has finitely many connected components in the Euclidean topology?,"Let $n\ge 2$ and $V$ be an irreducible affine algebraic set in $\mathbb R^n$ . Then is it true that $V$ has only finitely many connected components in the Euclidean topology of $\mathbb R^n$ ?  Does $\mathbb R^n \setminus V$ has only finitely many components  in the Euclidean topology of $\mathbb R^n$ ? [$V$ is actually a hypersurface since $V$ is the simultaneous zero set of finitely many polynomials, and we know that an $n$-tuple of real numbers is zero iff sum of  their squares is zero]","['real-algebraic-geometry', 'algebraic-geometry', 'affine-geometry', 'affine-varieties', 'commutative-algebra']"
2629905,book recommendation: differential equations on networks,"I was hoping someone would recommend a good book as an introduction to differential equations on Graphs or networks. So this would include both ODEs and PDEs. After looking around I have not been able to find an comprehensive treatment. In Fan Chung's book on spectral graph theory, there is a chapter on the heat kernel on graphs--but did not find any mention of the wave equation or Schrodinger equation on graphs. Cvetkovic and the Brouwer&Haemers book don't mention PDEs at all. I have not really found any treatments of ODEs on graphs at all. I understand that this type of topic spans a number of disciplines. So for the spectral graph theory connection you need a stronger grasp of differential topology and Riemann geometry. But I was hoping that someone could point out some good starting points on this topic.","['reference-request', 'ordinary-differential-equations', 'spectral-graph-theory', 'partial-differential-equations']"
2629939,How do I count combinations whose elements are drawn from nested sets?,"I have $n$ finite sets.  Each set is a strict subset of the next, i.e., $$S_1 \subset S_2 \subset S_3 \subset \ldots \subset S_n$$ I want to count the combinations of $n$ unordered elements where one element is drawn from $S_1$, one element is drawn from $S_2$, and so on. Ideally, I'd like this both for the case where duplicate elements within a combination are allowed and for the case where they are not. In other words, I want the number of $n$-sets (for the without-duplicate-elements case) or $n$-multisets (for the with-duplicate-elements case) $\{E_1,\cdots,E_n\}$ where $E_x \in S_x$. For example, let's say I have the following sets. $$
\begin{align}
S_1 &= \{1, 2\} \\
S_2 &= \{1, 2, 3, 4\}
\end{align}
$$ I can then draw these 5 combinations: $$
\{1,2\},
\{1,3\},
\{1,4\},
\{2,3\},
\{2,4\}
$$ And, depending on whether or not duplicate elements within a combination are allowed, I could also include these two:
$$
\{1,1\},
\{2,2\}
$$ Note that the combinations $\{3,3\}, \{3,4\}, \{4,4\}$ are not counted.  Each of those is impossible to draw in such a way that one element comes from $S_1$ and one element comes from $S_2$.","['combinatorics', 'elementary-set-theory']"
2629942,Using sequences to prove a limit doesn't exist?,"I am struggling to understand this relationship between sequences/subsequences/limits. I posted a question here , read the Wiki here , saw this other MSE answer here , and even read this page here . Despite all this I am simply not even getting this concept even a little bit. It's all so dense and abstract and I simply can't make heads or tails of it. I don't understand how this concept is used, how it works, what it illustrates, what it may or may not prove, etc. Is this technique mainly to check if a limit does or does not converge to something? Do we need to know what that something is? Or is it a general check for non-convergence? How does it work? Are there any easily understood examples? I feel like I need a really dumbed-down explanation for this because I am simply not getting any of it.","['proof-explanation', 'sequences-and-series', 'calculus', 'limits']"
2629943,Alternative conditions for a function $\phi:S_g\rightarrow S_g$ to be homotopic to identity,"Let $S_g$ be a closed oriented surface of genus $g\ge 1$ and  $f:[0,1]\times S_g\rightarrow S_g$ be a function such that: $f(0,x)=x$ for every $x\in S_g$ for every fixed $t\in [0,1]$ the function $f(t,\cdot):S_g\rightarrow S_g$ which to every $x\in S_g$ associates $f(t,x)\in S_g$ is continuous for every fixed $x\in S_g$ the function $f(\cdot,x):[0,1]\rightarrow S_g$ which to every $t\in [0,1]$ associates $f(t,x)$ is continuous (every point is moved along a continuous path) Question: is $f(1,\cdot): S_g\rightarrow S_g$ homotopic to the identity? It seems to me that the answer could be ""yes"", because the continuous paths ""lock"" the homotopy class of $f(1,\cdot)$, but I can not formalize it. However, in general a separately continuous function is not necessarily continuous and so the function $f:[0,1]\times S_g\rightarrow S_g$ could be not continuous and consequently it can not be considered as an homotopy between the identity and $f(1,\cdot)$. If the answer to the previous question is ""no"", then is it at least true that there exists a $\overline t>0$ such that $f(\overline t,\cdot):S_g\rightarrow S_g$ is homotopic to identity?","['functional-analysis', 'general-topology', 'algebraic-topology', 'analysis']"
2630002,"Determining Injective, Surjective, Bijective Functions over range of Integers","I have been slightly struggling with determining injective or surjective functions.  The issue that I am having is that i'm unclear how to handle different domains.  For example, the current domain is from $\mathbb{Z}$ to $\mathbb{Z}$ and the function is $f(n) = n/2.$ I have been solving these problems (for injective) by setting both sides equal to an arbitrary value i.e. $n_1$ and $n_2$ and solving to make them equal.  My question becomes what if the value you are mapping to does not fall within the domain..in this case $\mathbb{Z}$ to $\mathbb{Z}$.  So if I were to set $n = 1$ for example, we would end up with .5, which is not an integer. Is this still injective?  I apologize if this is a stupid question.  Does the domain only strictly effect inputs and not effect outputs?  Do these rules apply to surjective as well?","['functions', 'discrete-mathematics']"
2630010,A peculiar family of sets,"This is really stumping me. I'm rewriting the problem so I'm not just asking for homework help, but I was studying for a test on logic and this problem came up: Define an indexed family of sets $\{A_i\}_{i\in\mathbb{N}}$ where $A_i\subseteq\mathbb{N}$ for all $i\in\mathbb{N}$ that satisfies the following properties: 1. Every natural number is in at least one of the sets -> $(\forall n\in\mathbb{N})(\exists i \in \mathbb{N})(n\in A_i)$ 2. None of the sets are equal to $\mathbb{N}$ -> $(\forall i\in\mathbb{N})(\exists n\in\mathbb{N})(n\not\in A_i)$ 3. None of the sets have an upper bound -> $(\forall i \in \mathbb{N})(\forall m \in \mathbb{N})(\exists n\in\mathbb{N})(n > m \wedge n\in A_i)$ 4. One of the sets is a strict subset of every other one -> $(\exists j\in\mathbb{N})(\forall i\in\mathbb{N})(i\neq j \rightarrow A_j\subsetneq A_i)$ I've been working on this for a good half hour. Does anybody know of a set that will fit those criteria?","['logic', 'elementary-set-theory']"
2630068,"Elementary proof that the limit of $\sum_{i=1}^{\infty} \frac{1}{\operatorname{lcm}(1,2,...,i)}$ is irrational","Show that the infinite sum $S$ defined by -$$S=\sum_{i=1}^\infty \frac{1}{\operatorname{lcm}(1,2,...,i)}$$ is an irrational number. I found this question while reading 'Mathematical Gems' by Ross Honsberger. After pondering over it for nearly an hour, I was able to prove it by using Bertrand's postulate which states that there is a prime between n and 2n for every natural number n>1. This question was solved by Lajos Pósa when he was just 12 years old. Is there any elementary proof that does not use Bertrand's postulate or any complicated theorem?","['real-analysis', 'analytic-number-theory', 'irrational-numbers', 'sequences-and-series', 'elementary-number-theory']"
2630094,Recover scalar field from gradient,"In one dimension, if I have a Riemann-integrable derivative $f'$ of a function $f$ which I don't know, I can (almost) recover $f$ from integrating $f'$. A simple example would be $f'(x)=2x$, then by the Fundamental Theorem of Calculus, I get that $f(x)=x^2 + const,$ where the constant does not depend on $x$. I said 'almost recover' because to determine the constant, we need a point on the graph of $f$. My question is now: Is it possible to recover a scalar field $f:\mathbb{R}^n \rightarrow \mathbb{R}$ when I only know the gradient $\left( \partial_1 f(x), \ldots, \partial_n f(x) \right)$. My thoughts: I could apply the fundamental theorem of calculus in the first component by integrating over $x_1$, but then, I would get
\begin{align}
\int \partial_1 f(x)d x_1=f(x)+C,
\end{align}
where $C$ constant only in $x_1$, but may well vary with $x_2,\ldots,x_n$. I write $C=C_{-1}$ to indicate this. I could now proceed and do the same calculation for all the partial derivatives, i.e.
\begin{align}
\int \partial_i f(x)d x_i=f(x)+C_{-i}.
\end{align}
I cannot just add them together and divide by $n$ to recover $f$ plus a constant (in all variables). In fact, adding any two distinct $C_{-i}$ and $C_{-j}$ together woud give me a function depending on all $x_i$'s. I thought about considering $f(x)+C_{-1}=f(x)+C_{-2}$ where $f$ would cancel. Because the left hand side does not depend on $x_1$ and the right hand side does not depend on $x_2$, neither side depends on either $x_1$ or $x_2$. It appears to me that this shows that the $C_{-i}$ all are constants in all $x_i$'s, but it cannot be correct, as the follwing example shows: Take $f(x_1,x_2)=x_1+x_2$. Then
\begin{align}
\left( \partial_1 f,\partial_2 f \right)=(1,1)
\end{align}
If now $C_{-1}$ would indeed be a constant, I would have 
\begin{align}
f(x)=\int \partial_1 f(x)dx_1=x_1+c
\end{align}
which is wrong. I've looked around and found the Gradient Theorem which appears to be the right statement, but I don't see how to use it to find $f$, probably because I don't know much about line integrals.","['multivariable-calculus', 'partial-derivative', 'scalar-fields', 'vector-analysis']"
2630257,"Why does computation of the determinant have anything to do with the ""volume"" of the fundamental ""parallelepiped""?","By the ""volume"" of ""parallelepiped"", I mean the Lebesgue measure of n-Parallelotope. If I have $$\vec{v_i}=\begin{bmatrix}a_{1i} \\ a_{2i} \\ \vdots \\ a_{ni}\end{bmatrix} \qquad \text{ for } i\in\{1,2,3\ldots,n\}$$
and $$\mathbf A=\begin{bmatrix}\vec{v_1} & \vec{v_2} & \cdots & \vec{v_n}\end{bmatrix}=\begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1n}\\ a_{21} & a_{22} & \cdots & a_{2n}\\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn}\end{bmatrix}$$
Now there are two ways to define the determinant. Definition 1: If $\mathbf C_{ij}$ is the cofactor, then $$\det(\mathbf A)=\sum_{k=1}^{n}a_{ik}C_{ik}=\sum_{k=1}^{n}a_{kj}C_{kj} \qquad \text{for any } i,j\in\{1,2,3,\ldots,n\}$$ Definition 2: $\det(\mathbf A)$ is the Lebesgue measure of the fundamental n-Parallelotope spanned by the the column vectors $\vec{v_i}\in\mathbb R^n$. How do I prove that the two definitions are equivalent?
I personally like definition 2 because, I can visualize it but in definition 1, first we need to show that the summations are giving same values for all i and j. I can use the second definition definition for n=2, first thing I noted was that column operations does not change the area of the parallelogram because of simple geometry properties. Thus, $$\begin{vmatrix}a & c\\ b & d\end{vmatrix}=\begin{vmatrix}a & c-a\frac{c}{a}\\ b & d-b\frac{c}{a}\end{vmatrix}=\begin{vmatrix}a & 0\\ b & \frac{ad-bc}{a}\end{vmatrix}=\begin{vmatrix}a-0\frac{ab}{ad-bc} & 0\\ b-\frac{ad-bc}{a}\frac{ab}{ad-bc} & \frac{ad-bc}{a}\end{vmatrix}=\begin{vmatrix}a & 0\\ 0 & \frac{ad-bc}{a}\end{vmatrix}$$ This turns it into a rectangle whose area can be calculated easily.
$$\begin{vmatrix}a & c\\ b & d\end{vmatrix}=ad-bc$$
But this is the same as we get from definition 1. Thus both definitions are equivalent for n=2. The argument in finding determinant for n=2 by the second definition generalizes easily, but the method of computation feels completely different as compared to definition 1. Like for n=3, I got $$\begin{vmatrix}a&d&g\\b&e&h\\c&f&i\end{vmatrix}=\begin{vmatrix}\frac{a(ei-hf)-d(bi-ch)-g(ec-bf)}{ei-hf}&0&0\\0&\frac{ei-hf}{i}&0\\0&0&i\end{vmatrix}=a(ei-hf)-d(bi-ch)+g(bf-ec)$$ I can see a little bit connection for $i=1$ in definition 1. I got to know that definition 1 is called Laplace Expansion , but the proof written on Wikipedia went above my tiny brain. I am in 11th grade and I know very little about Linear algebra(I know only the stuff Grant Sanderson told in his essence of LA playlist). After reading the answer Determinant of transpose I can make sense why row operations do not change the determinant as well. I would be really happy if someone proves definition 1 using definition 2.","['matrices', 'volume', 'linear-algebra', 'determinant']"
2630271,How to derive approximation result from Levy 0-1 law?,"Let $(\Omega, \mathcal{F}, P)$ be a probability space. Let $\mathcal{E}_1, \mathcal{E}_2,...$ be a sequence of finite, measurable partitions of $\Omega$ such that each $\mathcal{E}_{n+1}$ is a refinement of $\mathcal{E}_n$, and assume that $\sigma(\cup_n \mathcal{E}_n) = \mathcal{F}$. Let $E_n(\omega)$ be the cell of $\mathcal{E}_n$ that contains $\omega$. For all $A$ and almost all $\omega$, the Levy 0-1 law says that
$$P(A \mid E_n(\omega)) \to \mathbf{1}_A(\omega)\tag{1}$$
In contemporary probability textbooks, this result is usually presented as an immediate consequence of the martingale convergence theorem for conditional expectations. Interestingly, I have recently discovered a much more elementary proof of this result in Halmos's Measure Theory (Theorem 49.B). Besides the basic properties of conditional probability, the only result that Halmos's proof appeals to is the standard fact that measurable sets can be approximated by sets in a generating algebra. In our context, for all $A \in \mathcal{F}$ and all $\epsilon > 0$, there exists $n$ and $E_1,...,E_k \in \mathcal{E}_n$ such that
$$P(A \triangle E)< \epsilon, \tag{2}$$
where $E=E_1 \cup ... \cup E_k$. From (2), Halmos's straightforwardly derives (1), which leads to my question: Assuming (1), is there a straightforward way to derive (2)? We might start by noticing that $P(A \mid E_n) \to \mathbf{1}_A$ a.s. iff $P(A^c \mid E_n) \to \mathbf{1}_{A^c}$ a.s. and for all $E \in \sigma(\mathcal{E}_n)$
$$P(A \triangle E) = P(A \cap E^c) + P(A^c \cap E) = \int_{E^c}P(A \mid E_n)dP + \int_E P(A^c \mid E_n)dP.$$
Then I thought about trying something like, let $F_n = \{\omega: P(A^c \mid E_n(\omega)) < 1- \epsilon\} \in \sigma(\mathcal{E}_n)$ so that $F_n^c = \{\omega: P(A \mid E_n(\omega)) \leq \epsilon\}$. Then,
$$P(A \triangle F_n) \leq \epsilon P(F_n^c) + (1-\epsilon) P(F_n).$$
But I'm stuck here and not sure this is going to work. Any hints are appreciated.","['probability-limit-theorems', 'probability', 'measure-theory']"
2630341,"Define all constant $a$ values in way that function $f(x,y)$ has critical point in $(0,0)$","Problem Define all constant $a$ values in way that function $f(x,y)$ has critical point in $(0,0)$ whe:
$$ f(x,y)=(4x^2+axy+y^2)(a+x) $$ Attempt to solve I wan to find out all constant $a$ values in a way that this function has zero gradient in point $(0,0)$ $\nabla(0,0)=0$ with what constant $a$. Gradient for this function is: $$ \nabla f(x,y)=\begin{bmatrix} a^2y+2axy+8ax+12x^2+y^2 \\ a^2x+ax^2+2ay+2xy
 \end{bmatrix} $$ $$ \nabla f(0,0)=\begin{bmatrix} a^2\cdot 0 + 2\cdot 0 \cdot 0 + 8 \cdot 0 \cdot 0 + 12 \cdot 0^2 + 0^2 \\ a^2\cdot 0 + a\cdot 0 ^2 + 2 \cdot 0 \cdot 0 + 2 \cdot 0 \cdot 0 \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \end{bmatrix} $$ Since value of gradient at point $(0,0)$ is not dependent on value of constant $a$. This constant can be anything when $a \in \mathbb{R}$. I think this is correct solution to this problem but i still have some doubt that maybe there is flaw. It would be highly appreciated if someone can tell that does this seem to be correct or not ?",['multivariable-calculus']
2630351,Bijective local diffeomorphism is a diffeomorphism,"Let $X,\ Y$ be manifolds in $\mathbb R^n$ (they are locally diffeomorphic to open subsets of some euclidean space.) I have a question about this fact (an exercise in Guillemin and Pollack): An injective local diffeomorphism $f: X\rightarrow Y$ is a
diffeomorphism onto an open subset of $Y$ . This seems too trivial to me and hence I think I musunderstand something. I would prove this claim as follows. The map $f: X\rightarrow f(X)$ is bijective. It is differentiable at any point since it is locally smooth (and even locally diffeomorphic), and the inverse $f^{-1}: f(X)\rightarrow X$ is also differentiable at any point because given any point $f(x)\in f(X)$ , the map $f$ is a diffeomorphism near $x$ , so $f^{-1}$ is differentiable at $f(x)$ . Thus $f$ is a global diffeomorphism. Because of this and since $X$ is open in itself, $f(X)$ is open in $Y$ . How bad/good does this proof look?","['manifolds', 'real-analysis', 'smooth-manifolds', 'differential-topology']"
2630536,Prove $\sum_{n=1}^\infty \text{Ci}(\pi n)=\frac{\ln(2)-\gamma}{2}$,"I'm trying to prove that
$$\sum_{n=1}^\infty \text{Ci}(\pi n)=\frac{\ln(2)-\gamma}{2}$$ I've tried parametrizing the sum by replacing $\pi$ with $x$ and differentiating, but this creates to a divergent series (whose partial sum is too messy to integrate), so I had no luck with that. Any hints? Emphasis on hints - please no full solutions. Just point me in the right direction.","['trigonometric-integrals', 'summation', 'sequences-and-series']"
2630567,Does a line stay straight when both axes are logged?,"If I have a plot of a straight line with some angle. Considering just the parts of the line where $x \geq 1$ and $y \geq 1$. If I $log$ both the $x$ and $y$ axes: Will it still be a straight line? Will it have the same slope? For example, here is the line $y = 0.5 x$ When I $log$ both the $x$ and $y$ axes, I get what looks like a line with the same angle. How would I prove/disprove it is always a straight line with the same slope? Here is the R code I used to generate the example plots. library('ggplot2')
df <- data.frame(x = seq_len(100))
df$y <- 0.5 * df$x
p <- ggplot(df, aes(x, y)) + geom_line()
p2 <- p + scale_x_log10() + scale_y_log10()

p
p2","['logarithms', 'graphing-functions', 'geometry']"
2630619,Integral of Vector Equations of Motion,"I have a problem in my textbook, it states ""At time t=o, vectors $E=E_o$ and $B=B_o$, where the unit vectors $E_o$ and $B_o$ are fixed and orthogonal. The equations of motion are $\frac{dE}{dt}=E_o+B\times E_o$ $\frac{dB}{dt}=B_o+E\times B_o$ Find E and B at a general time t, showing that after a long time the directions of E and B have almost interchanged."" At first instinct I want to integrate E and B w.r.t. t. However, I'm not sure how to do this if E depends on B and B depends on E, while they both depend on t. I just need help starting the question, once I have direction I'm sure I can finish as well answer the second part.","['ordinary-differential-equations', 'vector-analysis']"
2630656,Flip a coin 5 times. What is the probability that heads never occurs twice in a row?,"Suppose I flip a coin $5$ times in a row. There are $2^5$ possible outcomes, i.e: HHHTH, HTTTT, HTHTH, etc. I want to know the probability that heads never occurs twice in a row. I drew out $32$ events that can occur, and I found out that the answer was $\cfrac{13}{32}$. But I'm not sure how to do this generally, because say if the coin was flipped $20$ times in a row, I wouldn't write out $2^{20}$ possibilities. Thanks","['combinatorics', 'probability']"
2630676,How to prove this geometry question on quadrilateral and circles?,"In quadrilateral $ABCD$, $AC$ and $BD$ crossed at point $E$. Circle $O$ passes through $A, D$, and $E$ and its center is $O$. $P, Q, R$ are the midpoint of $AB$, $BC$ and $CD$, respectively. Circle $O_2$ passes through $P, Q$, and $R$, and crosses $BC$ at $F$. Prove: $OF$ is perpendicular to $BC$.","['euclidean-geometry', 'geometry']"
2630686,Proof of the generating function of $1 -2x +3x^2 -4x^3+5x^4-6x^5+\cdots$,"The ordinary generating function for the sequence $\{a_n\}_{n\geq0}$ where $a_n = (-1)^n\,n$ is $$1 -2x +3x^2 -4x^3+5x^4-6x^5+\cdots = \frac{1}{(x+1)^2}$$ I can see from the geometric formula, and even from long division that $$1 -x +x^2 -x^3+x^4-x^5+\cdots = \frac{1}{1+x}$$ but I'm not seeing the coefficients to explain $\frac{1}{(x+1)^2}.$","['combinatorics', 'power-series', 'discrete-mathematics']"
2630722,Analysis of a combinatorial game with prime numbers,"Many years ago, a coworker showed me a programming problem involving a combinatorial game with prime numbers that he had gotten somewhere or other.  (For some reason, he refused to tell me the source.)   Actually it is an infinite family of games, depending on an integer $N \ge 2.$  The first player names some prime $p_1 \le N.$  Then the second player names some prime $p_1 <p_2 \le p_1+N.$  The game continues in this manner.  Whenever a player names a prime $p_k,$ his opponent  must name a prime $p_k <p_{k+1}\le p_k+N.$  The first player who is unable to name a prime loses.  Of course, we assume that the players have unlimited tables of the primes available. The programming problem is to write a function that will take $N$ as input and produce as output the prime that the first player should say on his first move in order to win, or $0$ if there is no such prime.  It's easy to see what the optimum strategy is.  Let $\pi_1$ be the smallest prime such that $\pi_1+k \text{ is composite } k=1,2,\cdots,N.$  Then the player who names $\pi_1$ wins.  Then then $\pi_2$ be that largest prime such that $\pi_2 <\pi_1-N.$  Then the player who names $\pi_2$ wins.  However, this is completely impractical, because even for rather small values of $N,$ $\pi_1$ is enormous. Another friend and I solved the problem by starting from $2$ and going forward, rather than trying to go backwards from $\pi_1.$  For each prime $p$, we pretend that the goal of the game is to name $p$ and we label $p$ with the first move necessary to name it.  For $p\le N,$ the label is just $p$.  Then working through the primes, we label each $p$ with the label of the largest prime less than $p-N$.  So for example, if $N=23,$ we label the primes up through $23$ with themselves, and then we label $29$ with the label of the largest prime less than $29-23,$  that is $5.$  Then we label $31$ with $7$ and $37$ with $13$.  Later on, when we come to label $61,$ it gets the same label as $37,$ namely $13.$ What we find as we fill out the table is that we rather quickly get to an interval $I$ of length $N$ in which all the primes have the same label.  Then this label will be the winning first move (or it will be $0$ if there is no such move.)  The reason is, that in working backward from $\pi_1$ there is no way to skip over the interval $I$.  $I$ must contain a winning prime, and while we don't know what it is, we know its label. I found this solution very satisfying, and have always looked back on it fondly, but it has always bothered me that we have only empirical evidence that it works well.  I recently wrote a program to compute the value up to $N=10,001$ and the the largest prime  encountered was $2,030,647,991.$  According to the Wikipedia article on prime gaps, the largest known maximal gap as of October $2017$ is $1510$, occurring after the prime $6,787,988,999,657,777,797.$  This would be the $\pi_1$ value for $N=1509,$ for which my program only needed to go up to $6,307,507.$ My question is, does anybody know how to bound the largest prime that this algorithm would require to compute the first move for $N$?  I would be interested in any kind of of result, including a heuristic ""probabilistic"" argument. By the way, if you want to program this yourself, note that it's only necessary to compute the values for the odd numbers.  A little thought shows that the winning first moves for $N=2n+1$ and $N=2n$ will be the same, except that  if the winning first move when $N=2n+1$ is $N,$ then $N=2n$ is a loss for the first player, and if $N=2n+1$ is a loss for the first player, then the winning first move in $N=2n$ is $2.$ EDIT Results for $N\le 100:$ 2 0 11
3 3 11
4 0 29
5 5 29
6 5 79
7 5 79
8 7 127
9 7 127
10 7 97
11 7 97
12 7 127
13 7 127
14 7 149
15 7 149
16 13 127
17 13 127
18 3 173
19 3 173
20 13 307
21 13 307
22 13 787
23 13 787
24 23 191
25 23 191
26 23 1009
27 23 1009
28 23 367
29 23 367
30 13 787
31 13 787
32 31 1361
33 31 1361
34 23 1361
35 23 1361
36 31 1361
37 31 1361
38 13 907
39 13 907
40 29 853
41 29 853
42 0 1361
43 43 1361
44 19 1031
45 19 1031
46 31 2437
47 31 2437
48 37 1423
49 37 1423
50 7 1151
51 7 1151
52 29 1277
53 29 1277
54 53 1361
55 53 1361
56 19 4327
57 19 4327
58 13 3433
59 13 3433
60 47 2333
61 47 2333
62 3 5381
63 3 5381
64 61 1693
65 61 1693
66 31 4127
67 31 4127
68 67 1811
69 67 1811
70 17 2999
71 17 2999
72 13 2027
73 13 2027
74 37 2609
75 37 2609
76 31 2371
77 31 2371
78 31 1361
79 31 1361
80 2 8263
81 0 8263
82 0 8263
83 83 8263
84 79 12889
85 79 12889
86 47 4547
87 47 4547
88 19 4001
89 19 4001
90 37 10007
91 37 10007
92 83 3407
93 83 3407
94 5 5623
95 5 5623
96 83 7283
97 83 7283
98 89 4441
99 89 4441
100 37 8501 The first number is $N,$ the second number is the winning move (or $0$) the third is the largest prime used in the calculation.","['number-theory', 'combinatorial-game-theory']"
2630794,Is it always a positive value?,The values of $x$ can be from $0$ to $\infty$. So for these values of $x$ is the following function always positive $$f(x)=x^2+x+\exp(\frac{1}{x})(2x+1)Ei(-\frac{1}{x})$$ where $Ei(x)$ is the exponential integral. My checking in the WA shows that it is a positive value for arbitrarily large values of $x$.,['functions']
