question_id,title,body,tags
3491384,Evaluate $\int \frac{\sqrt{\sin^4x+\cos^4x}}{\sin^3x\cos x}dx$ [duplicate],This question already has answers here : Evaluation of $\int \frac{\sqrt{\sin ^4x+\cos ^4x}}{\sin ^3x \cos x }dx$ (3 answers) Closed 4 years ago . $$\int \dfrac{\sqrt{\sin^4x+\cos^4x}}{\sin^3x\cos x}$$ My multiple attempts are as follows:- Attempt $1$ : $$\int \dfrac{\sqrt{1-2\sin^2x\cos^2x}\cdot\sin x}{\sin^4x\cos x}dx$$ $$\cos x=t$$ $$-\sin x=\dfrac{dt}{dx}$$ $$\int -\dfrac{\sqrt{1-2t^2(1-t^2)}}{t(1-t^2)^2}dt$$ $$\int -\dfrac{\sqrt{2t^4+1-2t^2}}{t(1+t^4-2t^2)}dt$$ $$\int -\dfrac{\sqrt{2t^2+\dfrac{1}{t^2}-2}}{1+t^4-2t^2}dt$$ $$\int -\dfrac{\sqrt{2t^2+\dfrac{1}{t^2}-2}}{\left(\dfrac{1}{t^2}+t^2-2\right)t^2}dt$$ $$\int -\dfrac{\sqrt{\dfrac{2}{t^2}+\dfrac{1}{t^6}-\dfrac{2}{t^4}}}{\left(\dfrac{1}{t^2}+t^2-2\right)}dt$$ Not finding the way to proceed from here. Attempt $2$ : $$\int \dfrac{\sqrt{\tan^4x+1}\cos x}{\sin^3 x}dx$$ $$\int \dfrac{\sqrt{\tan^4x+1}}{\tan^3 x\cos^2x}dx$$ $$\tan x=t$$ $$\int \dfrac{\sqrt{t^4+1}}{t^3}dt$$ $$t=\sqrt{\tan\theta}$$ $$\dfrac{dt}{d\theta}=\dfrac{1}{2\sqrt{\tan\theta}}\sec^2\theta$$ $$\int \dfrac{\sec\theta\sec^2\theta}{2\tan^2\theta}d\theta$$ $$\int \dfrac{\sec\theta}{2\sin^2\theta}d\theta$$ $$\int \dfrac{\cos\theta}{2\sin^2\theta\cos^2\theta}d\theta$$ $$y=\sin\theta$$ $$\int \dfrac{dy}{2y^2(1-y^2)}$$ $$-\dfrac{1}{2}\cdot\int\dfrac{y^2-(y^2-1)}{y^2(y^2-1)}dy$$ $$-\dfrac{1}{2}\cdot\left(\dfrac{1}{2}\cdot\ln\left|\dfrac{y-1}{y+1}\right|+\dfrac{1}{y}\right)+C$$ $$-\dfrac{1}{4}\cdot\ln\left|\dfrac{\sin\theta-1}{\sin\theta+1}\right|-\dfrac{1}{2\sin\theta}+C$$ $$-\dfrac{1}{4}\cdot\ln\left|\dfrac{t^2-\sqrt{1+t^4}}{t^2+\sqrt{1+t^4}}\right|-\dfrac{\sqrt{1+t^4}}{2t^2}+C$$ $$-\dfrac{1}{4}\cdot\ln\left|\dfrac{\tan^2x-\sqrt{1+\tan^4x}}{\tan^2x+\sqrt{1+\tan^4x}}\right|-\dfrac{\sqrt{1+\tan^4x}}{2\tan^2x}+C$$ $$-\dfrac{1}{4}\cdot\ln\left|\dfrac{1-\sqrt{\cot^4x+1}}{1+\sqrt{\cot^4x+1}}\right|-\dfrac{\sqrt{1+\cot^4x}}{2}+C$$ But real answer is $-\dfrac{\mathrm{cosec}x}{2}-\dfrac{1}{4}\cdot\ln\left|\dfrac{\mathrm{cosec}x-1}{\mathrm{cosec}x+1}\right|+C$ What am I missing here?,"['integration', 'calculus']"
3491411,Is my argumentation for proving that a monotonic sequence is convergent if and only if it is bounded enough?,"I am studying for my first exam in Analysis 1 and one I have to know how to prove that a monotonic sequence in $\mathbb{R}$ is convergent if and only if it is bounded. I start by proving the first implication, thus that monotonic and convergent => bounded. This is easy as I am allowed to use an earlier proof from my book to say that any convergent sequence in $\mathbb{R^n}$ is bounded. However the other implication gets a little bit trickier. I know that I have to prove that monotonic and bounded => convergent. I first start by assuming that the sequence $(a_k)_{k=1}^\infty$ is increasing. Thus the set $\{a_k : k \in \mathbb{N}$ } of the values of the sequence is non-empty and bounded and therefore it has a well-defined supremum. I let $a=sup\{a_k : k \in \mathbb{N}\}$ and claim that the sequence converges to a. Thus I let $\epsilon > 0 $ and use the definiton of convergence $\forall \epsilon > 0 \exists N \in \mathbb{N} : k \geq N \rightarrow ||a_k-a||< \epsilon$ which I negate for a contradiction, ie. $\exists \epsilon > 0 \forall N \in \mathbb{N} : \exists k \geq N$ and $a-a_k \geq \epsilon $ .' Then I create a new, strictly positive sequence $(k_j)_{j=1}^\infty$ with $a-a_{kj} \geq \epsilon $ and $j \in \mathbb{N}$ but why does it need to be strictly positive and not just positive. Does this make a difference? I now let $N=1$ to obtain that $k_1 \geq 1$ . By constructing $k_{j-1}$ it immediately follows that $k_j \geq k_{j-1} + 1 > k_{j-1}$ . Is this because that I have just seen that for $N=1$ that $k_1 \geq 1$ which means that $k_j \geq k_{j-1} +1$ as $j \in \mathbb{N}$ ? I am not sure how to explain it .. As I now have constructed a strictly positive sequence I know that $\forall k \in \mathbb{N}$ I can find a $j \in \mathbb{N}$ such that $k \leq k_j$ but why is this? My friend tried to explain it is because that I first pick a $k$ and then afterwards I can pick a $j$ and therefore $k \leq k_j$ . Likewise this means that, by induction, $a_k \leq a_{kj}$ . Can this also be explained by saying that the sequences are positive? Or only by induction? I dont have time for that if I have to present this subject for my professor. Now I know this means that $a-a_k \geq a-a_{kj} \geq \epsilon $ but then $a-a_k \geq \epsilon $ and solving for $a_k$ we obtain that $a-\epsilon \geq a_k$ implying that this is an upper bound for the sequence contradicting the fact that $a = \sup \{a_k \ k \in \mathbb{N}$ } which completes the proof. I hope you can clarify my questions. Thanks in advance.",['analysis']
3491425,Finding a finite presentation for the kernel of a homomorphism,"I'm trying to solve the following extra (non-homework) problem from my lecture notes: Let $G$ be the group $\langle x, y \mid x^3y^3\rangle$ Let $\varphi: G \to \mathbb{Z}/3\mathbb{Z}$ be the homomorphism that
  sends $x$ and $y$ to the generator of $\mathbb{Z}/3\mathbb{Z}$ . Find a finite presentation for the kernel of this homomorphism. I know that in theory a finite index subgroup of a finitely presented group is again finitely presented, but I have no idea how to do this for a particular example and the notes don't give a similar example. Does anyone have any suggestions?","['group-presentation', 'group-theory', 'algebraic-topology', 'covering-spaces']"
3491549,Two rectangles: The $1$st has twice the perimeter of the $2$nd and the $2$nd has twice the area of the $1$st.,"How can this be solved using just algebra, where the first rectangle has sides $a$ and $b$ , and the second rectangle has sides $c$ and $d$ ? These are the two equations that follow: $$a + b = 2(c + d)$$ and $$2ab = cd$$",['geometry']
3491595,Does the sum $\frac{1}{3} + \frac{1}{3^{1+1/2}}+\cdots$ have a closed form?,"Evaluate the sum $$\frac{1}{3} + \frac{1}{3^{1+\frac{1}{2}}}+\frac{1}{3^{1+\frac{1}{2}+\frac{1}{3}}}+\cdots$$ It seems that $1 + \dfrac{1}{2} + \dfrac{1}{3} + \cdots + \dfrac{1}{n}$ approaches $\ln n$ as $n\to \infty$ , but I'm not sure if this is useful. Also, $3^{\ln n} =e^{\ln n\cdot \ln 3}= n^{\ln 3}$ , but I'm also not sure how this is useful. edit: I know how to prove that it converges, but I was wondering if there was a closed form for this sum.","['calculus', 'summation', 'sequences-and-series']"
3491614,Hilbert spaces: Orthonormal set has a dense span iff the only vector orthogonal to it is zero.,"I am reading in Young's An introduction to Hilbert Space that: A countable orthonormal set $S$ in a Hilbert space $\mathcal{H}$ has the property $\mathcal{P}=$ {the only vector orthogonal to it is the zero vector} if and only if $S$ spans $\mathcal{H}.$ Question I am wondering if this result can be stated in this more general form: that an orthonormal system indexed by some set $I$ has property $\mathcal{P}$ if and only if its span is dense in $\mathcal{H}$ If true, can you give me a proof?","['hilbert-spaces', 'orthonormal', 'functional-analysis', 'real-analysis']"
3491616,Evaluating a Triple integral where one bound is a function of two variables,"Problem: Evaluate the following triple integral: $$ \int_1^3 \int_1^3 \int_1^{\min(8 - x - y,3)} 2 \, dz \, dy \, dx $$ Answer: The problem is the bound $\min(8 - x - y,3)$ . I would like to write it as the sum of two triple integrals with simple bounds. I could try something like: $$ \int_1^3 \int_1^3 \int_1^{\min(8 - x - y,3)} 2 \, dz \, dy \, dx = \int_1^2 \int_1^2 \int_1^{3} 2 \, dz \, dy \, dx + \int_2^3 \int_2^3 \int_1^{8 - x - y} 2 \, dz \, dy \, dx $$ but I know that is wrong. What is the right approach to evaluate this integral? Based upon comments I received, I am updating my post.
Using Wolfram, I find: $$\int_1^3 \int_1^3 \int_1^{\min(8 - x - y,3)} 2 \, dz \, dy \, dx = \frac{47}{3} $$ Using Wolfram, I find: $$ \int_2^3 \int_1^{5-x} \int_1^3 2\,dz\,dy\,dx = 2 $$ Using Wolfram, I find: $$ \int_2^3 \int_{5-x}^3 \int_1^{8-x-y} 2\,dz\,dy\,dx = 4 $$ Since $4 + 2 = 6$ not $\frac{47}{3}$ My answer is wrong.","['integration', 'multivariable-calculus']"
3491666,Why are all $3$-cycles conjugate in $A_5$?,"I am reading Dummit and Foote's proof that $A_5$ is simple, and I saw the statement $$\text{All twenty 3-cycles are conjugate in $A_5$}$$ However, I tried to conjugate $(123)$ into $(132)$ , and I couldn't find an even conjugator. I believe the way to find all conjugators is as follows: $$
\begin{bmatrix}
(123) & (123) & (123)\\
(132) & (321) & (213)
\end{bmatrix}
$$ By reading vertically, we see that the possible conjugators are $(23)$ , $(13)$ , $(12)$ , all of which are odd. I think I must be wrong, there must be other conjugators; but on the other hand I don't see how there could be any others. What is going on here? Thank you very much.","['permutations', 'group-theory', 'abstract-algebra']"
3491667,Expectation of positive part of a random variable,"Given a random variable $X$ , does the following inequality hold? \begin{equation*}
\mathbb{E}[\max\{X,0\}]=\max\{\mathbb{E}[X],0\}
\end{equation*} I know that in general for a function $f(X)$ the equality does not hold. I just wondered whether it is the same for the positive part function.","['probability-theory', 'probability']"
3491685,Show that the complex $\cos$ function has only real roots,"I am working on an exercise and at the current stage, I want to show that (perhaps this is wrong) For $z\in\mathbb{C}$ , $\cos(z)=0$ only has real solution. However, I had some short attempt but did not know how to proceed. For instance, writing $z=x+iy$ , we know that $$\cos(z)=0\implies \dfrac{e^{iz}+e^{-iz}}{2}=0\implies e^{ix}e^{-y}=-e^{-ix}e^{y},$$ but how could I argue from here to conclude that we must have $y=0$ ? A similar argument is that $$\cos(x+iy)=\cos(x)\cos(iy)-\sin(x)\sin(iy)=0,$$ gives us $$\cos(x)\cos(iy)=\sin(x)\sin(iy),$$ again how could I use this to show $y=0$ must be true? Thank you so much!","['complex-analysis', 'complex-numbers']"
3491705,A compact operator that is the limit of finite rank operators,"I'm with trouble to solve (b). (a) Let $W$ be a Banach space. Assume that there exists a sequence $\{P_n\}\subset\mathcal{B}(W,W)$ of finite rank operators such that $P_n(y)\rightarrow y$ , for all $y\in W$ . Show that, if $V$ is a Banach space and $T\in\mathcal{B}(V,W)$ is compact, then $T$ is the limit of finite rank operators. (b) Deduce that, if $V$ is any Banach space and $T\in\mathcal{B}(V,\ell^p)$ ( $1\leqslant p<\infty$ ) is compact, then $T$ is the limit of finite rank operators. In the (a) part, I just define $T_n:=P_n\circ T$ , for each $n\in\Bbb{N}$ , and get the desired, because: $R(T_n)\subset R(P_n)$ implies that $\dim R(T_n)\leqslant\dim R(P_n)<\infty$ , since $P_n$ has finite rank, for all $n$ . Since $P_n(y)\rightarrow y$ , for all $y\in W$ , given $\varepsilon>0$ , there exists $N_0\in\Bbb{N}$ such that $$\|P_n(y)-y\|<\varepsilon,\quad\forall n\geqslant N_0.$$ Now, for any $v\in B_V[0;1]$ , we have that for all $n\geqslant N_0$ $$\|(T_n-T)(v)\|=\|T_n(v)-T(v)\|=\|P_n(\underbrace{T(v)}_{\in W})-T(v)\|<\varepsilon,$$ which implies that $$\sup_{v\in B_V[0;1]}\|(T_n-T)(v)\|=\|T_n-T\|<\varepsilon.$$ Obviously, to solve (b), I just need to find the sequence $\{P_n\}$ and apply (a), but I can't see how.","['compact-operators', 'functional-analysis']"
3491718,finding intersection and union of indexed family of subsets of real number,"I'm guessing that the intersection would be empty set and union would be set of real number. How would I be able to prove it, using Archimedean Property if necessary?",['elementary-set-theory']
3491792,Solving $\int_1^2 e^{1-\frac{1}{(x-1)^2}} + 2 + \frac{1}{\sqrt{1-\log(x-1)}}\:dx$ with a clean trick,"A friend and I have been swapping difficult integrals for the holidays  to stump each other and he recently sent me this one that I haven't been able to figure out (mission accomplished, I guess :) ). I've tried a few substitutions of the form $$x-1 = f(t)$$ but if they cancel out one side, they won't simplify on the other because of the presence of both the exponential and the log. At best I could simplify the problem to $$2 + \int_0^1 e^{1-\frac{1}{x^2}} + \frac{1}{\sqrt{1-\log x}}\:dx$$ by shifting the integral over to the interval $[0,1]$ to see if I could spot any patterns. The integral on the right evaluates to $1$ , which is a surprisingly clean answer. Wolfram gives a complicated looking antiderivative but one of the rules of our little game was that we would invoke no special functions beyond the standard transcendentals and hyperbolics/trig. Even if this was the intended solution, I'm not sure how to simplify the bound at $1$ with the $\operatorname{erf}$ s I suspect he had some clean trick in mind since that was the theme of the game, but I'm stumped.","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
3491807,"Find UMVU estimator for P((0,1))","Suppose a statistical model comprises all continuous distributions on $R^1$ . Based on $n$ samples $x_i$ , find a UMVU estimtor for $P((0,1))$ , where $P$ is the true distribution. I have three questions: In textbooks, I learned that a statistical model is denoted as $P_\theta$ , indexed by $\theta\in \Omega$ . Usually, $\theta$ is a scalar or vector value. In this question should I understand $\theta$ as an index for (uncountable) continuous distributions? In this case ( $\theta$ is not a value), do we have something like MLE for inferring $\theta$ ? Intuitively, the solution to the question is $\frac{\sum_i 1(x_i\in (0,1))}{n}$ . I can compute the variance ( $\frac{p(1-p)}{n}$ , where $p=P((0,1)$ ). How can I prove it's UMVU?","['statistics', 'maximum-likelihood']"
3491859,Solve the equation $y=2xy'+y^2y'^3$,Solve the equation $y=2xy'+y^2y'^3$ . I have tried to solve it but I can't recognize what type of equation I have learnt.,['ordinary-differential-equations']
3491929,Why do even numbers which surround primes have more divisors than those which surround composites?,"Every odd number lies between two even numbers. Accordingly we have two categories of consecutive even number pairs; those pairs which surround primes and those pairs which surround odd composites. Some even numbers can belong to both categories as explained in the example below. E.g : The pair $(8,10)$ will fall in the category of composite since it contains the odd composite number $9$ . The pair $(10, 12)$ belongs to the category of primes since they contain the prime $11$ . Hence there will be some overlap on the boundaries of primes as is the case with $10$ in this example. As primes thin out, such overlaps will also thin out accordingly. Data : Experimental data shows that the even numbers which surround a prime have on a average about $28\%$ more divisors and $7\%$ more distinct prime factors than the even numbers which surround odd composites. For numbers up to $3.5 \times 10^7$ , The average number of divisors of the even pairs surrounding primes is $35.39$ while that of those which surround odd composite numbers is only $27.70$ . Moreover, difference between the average number of distinct prime factors of these two categories seems to converge to a value in the neighborhood of $0.27$ Question 1 : How or why does the act of surrounding a prime give the two surrounding even numbers a higher number of divisors and
  distinct prime factors? Note : This question was motivated by the following question on twin primes in MSE . Code n = 3
pa = pb = ca = cb = 0
ip = ic = 0
target = step = 10^6
while true:
    if is_prime(n) == True:
        ip = ip + 1
        pb = pb + len(divisors(n-1))
        pa = pa + len(divisors(n+1))
    else:
        ic = ic + 1
        cb = cb + len(divisors(n-1))
        ca = ca + len(divisors(n+1))
    if n > target:
        print n, ip, pb, pa, ir, cb, ca, pb/ip.n(), (pb/ip)/(cb/ic).n(), pb/ip.n() - cb/ic.n()
        target = target + step
    n = n + 2","['divisibility', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
3491931,Concrete Mathematics: Josephus Problem for $J(n) = n/2$,"On page 25 of the second edition I am at the section revisiting the initial guess of a closed form solution for the Josephus Problem. This initial, and incorrect, guess was that the solution is $n/2$ . To lead us into this renewed discussion the book says: Let's return briefly to our first guess, that $J(n) = n/2$ when $n$ is even. This is obviously not true in general, but we can now determine exactly when it is true To find when this is true they substitute in the closed form solution and $2^m +l$ for the $n$ it represents. Then rearrange to find $l$ i.e. $$J(n)=n/2$$ $$2l+1=(2^m+l)/2$$ $$l=\frac{(2^m-2)}{3}$$ If the number $l=\frac{(2^m-2)}{3}$ is an integer then $n=2^m+l$ will be a solution because $l$ will be less than $2^m$ This implies, by my reading, that $l$ is sometimes greater than $2^m$ . Isn't $l$ always less than $2^m$ ? If $l$ were greater than $2^m$ then we would be going to the next power of two ""block""? (As described on page 23 in the table of small values given by the recurrence)",['discrete-mathematics']
3491953,Reflection groups of division rings,"My question is: Is there a classification of finite groups representable as a $\mathbb{K}$ -reflection group for some division ring $\mathbb{K}$ of characteristic zero? I would also appreciate any references dealing with this problem or with particular cases. If the classification turns out to be intractable, I would ask if at least an example can be found of a new exceptional reflection group of rank $\ge 3$ (i.e. not part of an infinite family, see details below). Details Let $\mathbb{K}$ be a division ring of characteristic zero, and $V$ a right vector space of dimension $n$ over $\mathbb{K}$ . A finite $\mathbb{K}$ -reflection group of rank $n$ can be defined as a finite group $G$ of linear transformations in $V$ generated by  elements of finite order that leave a hyperplane pointwise fixed (we consider only the case where $G$ is essential, i.e. no nontrivial subspace is fixed by the whole of $G$ ). Fields The irreducible finite reflection groups over $\mathbb{C}$ (also called unitary or complex reflection groups ) were classified by Shephard and Todd. The classification consists essentially of: An infinite family $G(m,p,n)$ of groups of rank $n$ , where $p$ divides $m$ , with slightly different properties when $m=p=1$ or when $n=1$ (these two cases are almost always listed independently). This family includes the familiar Coxeter groups $A_n, B_n, D_n, I_2(m)$ as special cases. 34 exceptional cases of rank $\le 8$ . These include the exceptional Coxeter groups $E_6, E_7, E_8, F_4, H_3, H_4$ . If $\mathbb{K}$ is a field of characteristic $0$ , it is known (see e.g. Section 15-2 here ) that if a group has a representation as a $\mathbb{K}$ -reflection group then it also has a representation as a complex reflection group, so we get no new examples for fields. The quaternions I'm interested in the case where $\mathbb{K}$ is not a field. I have found no information on this case except when $\mathbb{K}=\mathbb{H}$ , the skew-field of quaternions. The irreducible finite quaternionic reflection groups (also known under another form as symplectic reflection groups, e.g. here ) were classified in this paper by Cohen. Essentially: There is an infinite family $G_n(M,P,\alpha)$ of groups of rank $n$ , where $M$ is a finite subgroup of $\mathbb{H}$ , $P$ is a normal subgroup of $M$ and some conditions are satisfied, with an extra datum $\alpha$ (an automorphism of $M/P$ of order $\le 2$ ) in the case $n=2$ . If $M, P$ are cyclic groups we recover the infinite family of complex reflection groups from the previous list. There is an additional family $E(H)$ of groups of rank $2$ . There are 13 new exceptional cases of rank $\le 5$ , including a double cover of the Hall-Janko group $HJ$ , a sporadic finite simple group, in rank $3$ . Other division rings? Unlike the case for fields, not all possible finite reflection groups for division rings of characteristic zero can be found in the above list. For example, the ""baby problem"" of classifying finite $\mathbb{K}$ -reflection groups of rank $1$ (equivalently the possible finite subgroups of division rings of characteristic $0$ ) was dealt with in this paper by Amitsur; there are additional groups not realised in the quaternions. Nevertheless, I'm hopeful that it is still possible to find a full list for all $\mathbb{K}$ , perhaps using a technique similar to the case of fields to restrict our analysis to division algebras of finite dimension over $\mathbb{Q}$ (which are always cyclic algebras over their center $Z(\mathbb{K})$ , a finite extension of $\mathbb{Q}$ ). In view of the previous lists, I would expect a full classification (if there is one) to follow a similar form: An infinite family $G_n(M,P,\alpha)$ of groups of rank $n$ , where $M$ is a finite subgroup of a division ring $\mathbb{K}$ , $P \trianglelefteq M$ and some conditions are satisfied, possibly with some extra data $\alpha$ in low rank. A family or families of examples in rank $2$ . I'm not very interested in these, a brute-force method to find them might be to start with the classification of finite subgroups of $GL(2,\mathbb{K})$ and perform a tedious case-by-case check. A number of exceptional cases of small rank. These are the ones I'm most interested in. In the quaternionic case these are precisely the primitive reflection groups whose complexification is also primitive; in the general case they could correspond to primitive reflection groups which remain primitive after tensoring with a splitting field (this is just a guess).","['division-ring', 'reflection', 'representation-theory', 'finite-groups', 'abstract-algebra']"
3491955,Differential equation: $y=2xy'+\frac{1}{(y')^2}$,"I've encountered the following differential equation: $y=2xy'+\frac{1}{(y')^2}$ I tried to differentiate in order to $x$ and then used $p=y'$ . After some calculation, I arrived at the formula $ x = \frac{2}{p^3} + \frac{C_{1}}{p^2}$ Does anyone has any suggestion to solve the first equation? Thanks for your attention.",['ordinary-differential-equations']
3491972,Is binomial coefficient integer? by induction.,"To prove $\binom{n}{k}=\frac{n!}{k!(n-k)!}$ is an integer, use Mathematical Induction on $k$ Base Step: $\binom{n}{0}=\binom{n}{n}=1$ Inductive Step: Assume that $\binom{n}{k}$ , $k=1,2,...,n-1$ are all integers. We need to show that $\binom{n+1}{k}$ , $k=1,2,...,n$ are all integer Given $k=1,2,...,n$ $\binom{n+1}{k}=\frac{(n+1)!}{k!(n-k+1)!}$ $=\frac{n!}{(k-1)!(n-k)!}\frac{n+1}{(n-k+1)k}$ $=\frac{n!}{(k-1)!(n-k)!}(\frac{1}{(n-k+1)}+\frac{1}{k})$ $=\frac{n!}{(k-1)!(n-k+1)!}+\frac{n!}{k!(n-k)!}$ $=\binom{n}{k-1}+\binom{n}{k}$ Is this a complete and correct proof ? If not, what is wrong with it ?","['solution-verification', 'discrete-mathematics']"
3492047,Find the remainder when $f(x) = x^{2016}+2x^{2015}-3x+4$ is divided by $g(x)=x^2+3x+2$,"Find the remainder when $f(x) = x^{2016}+2x^{2015}-3x+4$ is divided by $g(x)=x^2+3x+2$ I try to factor them, but I failed. I know that it's impossible to divide it","['functions', 'polynomials']"
3492160,Solving Cauchy problem using implicit function,"I am trying to solve the following Cauchy problem: $$ y' = \sin(y), \quad y(0) = \frac{\pi}{3} $$ After some calculation, I get to $$ \int_{\frac{\pi}{3}}^y \frac{ds}{\sin{s}} = x $$ Actually, I just want to find the maximum interval where the solution is defined, so I study the integral function: $$ F(y) = \int_{\frac{\pi}{3}}^y \frac{ds}{\sin{s}} $$ Now I know I have to calculate some limits to find the range, but I am not sure how. Can someone give me some hints?","['integration', 'cauchy-problem', 'ordinary-differential-equations']"
3492232,"Calculate $\sum_{i=2}^{∞} i\,\frac{\operatorname{fib}(i-1)}{2^i}$","Calculate: $$\sum_{i=2}^{∞} i\,\frac{\operatorname{fib}(i-1)}{2^i}$$ Where $\operatorname{fib}(i)$ is the $i$ -th Fibonacci number. I know that it's $6$ (based on a program), but how to prove it?","['limits', 'summation', 'fibonacci-numbers']"
3492263,Find how many parts are in a triangle,"Recently, I got this interesting riddle in a math test, which I still can't solve. Here are the exact words: Each side of an equilateral triangle was divided into 100 equal parts. Points received
  connected by segments. How many parts did you get? Here is an example for a triangle with just 3 points on each side: That much lines really confuses me. I tried to find a ratio between number of lines and parts, and how does each new line drawn divides the others, but it doesn't seem to work. What could be the possible solution to this?","['triangles', 'geometry']"
3492315,prove $ \sum_{n=1}^\infty \frac{1}{n^\alpha\sqrt{n |x-x_n|}} $ converges almost everywhere,"Let $ \{x_n\}_{n=1}^\infty \subset \mathbb{R} $ be a sequence. Prove for $\alpha>1$ that $\sum_{n=1}^\infty \frac{1}{n^\alpha\sqrt{n|x-x_n|}}$ converges for almost every $x$ with regard to Lebesgue measure on $\mathbb{R}$ . I tried solving by finding an integrable function such that this series is bounded below the function's integral, but I didn't find a suitable function.","['lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3492345,Norm of bounded linear operator from an inner product.,"I am given an inner product space $X$ , with a norm induced by the inner product. Given an element $b\in X$ we define $f(a)=\langle a,b\rangle$ . Now I want to prove that $f$ is a bounded linear functional as well as finding its operator norm. My take:
I can prove that $f$ is linear by calculating $f(\alpha x+\beta y)$ and showing that this is $\alpha f(x)+\beta f(y)$ . My uncertainty is when I am to trying to show that $f$ is bounded. For $f$ to be bounded there has to exist a $C$ such that $$
\langle a,b \rangle \leq C\| a \|
$$ for every $a\in X$ . An upper bound on $f(a)$ can be given by Cauchy Schwarz, \begin{equation}\label{123}
\langle a,b \rangle \leq \| a \|\| b \|.
\end{equation} My guess is that $\| b  \|$ is the operator norm and that we can show this
by calculating $f(b)$ . As the norm is induced by the inner product we know that $\langle b,b \rangle=\| b \|$ but I'm not sure on how to continue/finish this or if I'm on the right path.","['inner-products', 'operator-theory', 'functional-analysis']"
3492364,Trouble in understanding why function is constant in a given domain,"Definition The group of unitary operators $u(\theta)$ on $L^2(\mathbb R^3)$ given by $(u(\theta)\Phi)(r) =\Phi(\theta) \equiv e^{\frac{3\theta}{2}}\Phi(e^\theta r)$ is called the group of dilation operators on $\mathbb R^3.$ Let $H$ be a compact operator and $R(z) \equiv(H-z)^{-1}$ the resolvent.
Define $R(z,\theta)$ by $R(z,\theta) \equiv u(\theta)R(z)u(\theta)^{-1}$ . Let us define also $\mathcal O \equiv \{\theta \in \mathbb C: (u(\theta)\Phi)(r)$ for $\theta \in \mathbb R$ has an analytic continuation $ \}$ In this article A Class of Analytic Perturbations
for One-body Schrδdinger Hamiltonians they were able to show that the function $\Psi_z(\theta)=(\phi(\theta)
,R(z,\theta)\phi(\theta))$ is meromorphic in $z$ for $z \in \mathcal C^{++} \equiv \{z \in \mathbb C : Im \ z > 0 ,\ Re \ z > 0 \} $ and $\theta \in \mathcal O^\epsilon \equiv \{\theta \in \mathcal O: Im \ \theta > \epsilon \}$ Now since for $\theta \in \mathbb R,\ u(\theta)$ is unitary we have that $\Psi_z \equiv (\Phi,R(z)\Phi)=\Psi_z(\theta)$ from this they claim that $\Psi_z(\theta)$ that for fixed $z \in \mathcal C^{++}$ and $\theta \in \mathcal O^\epsilon$ the function $\Psi_z(\theta)$ is constant in $\theta$ . My question is why is $\Psi_z(\theta)$ constant for fixed $z \in \mathcal C^{++}$ and $\theta \in \mathcal O^\epsilon$ ?","['complex-analysis', 'operator-theory', 'functional-analysis', 'mathematical-physics']"
3492365,The closed-form of $\int_0^\infty \frac{e^{-x}\cos(x)}{x^2+1}\mathrm{d}x$,"What is  the closed-form of the following integral $$I\;=\; \int_0^\infty \frac{e^{-x}\cos(x)}{x^2+1}\mathrm{d}x$$ If we replaced $\;\;\displaystyle \frac{1}{x^2+1}\;\;$ by its integral representation, $\;\;\displaystyle \int_0^\infty e^{-xt}\sin(t)\text{d}t,\;\;$ we get that $$I\;=\; \int_0^\infty e^{-x}\cos(x)\Bigg(\int_0^\infty e^{-xt}\sin(t)\text{d}t\Bigg)\mathrm{d}x$$ $$ \{\text{ reverse the order of integration  } \} $$ $$I\;=\; \int_0^\infty \sin(t) \Bigg(\int_0^\infty e^{-x(t+1)}\cos(x)\text{d}x\Bigg)\mathrm{d}t$$ $$I\;=\; \int_0^\infty \frac{(t+1)\sin(t)}{(t+1)^2+1} \mathrm{d}t$$ $$\{\text{ make the change of variable $t+1=u$}\big\}$$ $$=\int_1^\infty \frac{u\sin(u-1)}{u^2+1} \mathrm{d}t $$ $$=\;\;\cos(1)\int_1^\infty \frac{u\sin(u)}{u^2+1} \mathrm{d}t\;-\;\sin(1)\int_1^\infty \frac{u\cos(u)}{u^2+1} \mathrm{d}t  $$ Have anyone an idea to finish the remaining integrals ?","['integration', 'complex-analysis', 'improper-integrals', 'laplace-transform']"
3492425,"Prove that $I_{m, n} = I_{m+1,n-1}$ for $n\geq 1$.","Let $I_{m,n} = \dfrac{1}{m!n!}\displaystyle\int_0^1 x^m(1-x)^ndx$ for $m,n\in\mathbb{Z},m,n \geq 0$ . Prove that $I_{m,n}=I_{m+1,n-1}$ for $n\geq 1$ . I thought of proving this by induction, with $P(n)$ being the statement that $I_{m,n} = I_{m+1,n-1}.$ I can prove the base case, but I'm having difficulty proving the inductive step. I tried using the hypothesis (i.e., $\dfrac{1}{m!k!}\displaystyle\int_0^1 x^m (1-x)^kdx=\dfrac{1}{(m+1)!(k-1)!}\displaystyle\int_0^1 x^{m+1}(1-x)^{k-1}dx$ ). But I'm not sure how to prove $I_{m,k+1} = I_{m+1,k}$ using integration by parts.","['integration', 'calculus', 'real-analysis']"
3492438,Banach Tarski paradox on a closed 1D or 2D set embedded in $\Bbb R^3$,"Suppose we have a 1D closed line segment, or a 2D closed disk embedded in $\Bbb R^3$ . Is it possible to perform a Banach-Tarski type procedure on the object to produce two such objects? The reason I ask is because Banach and Tarski showed that for a 2D disk in $R^2$ , they can produce only one disk with their method using standard Euclidean congruences. But, if we embed the 2D disk into 3D, there are now more types of ""rigid motions"" permitted, and the resulting groups of motions have different properties. So, is it then possible to perform a Banach-Tarski type procedure? I am most curious about the simple example of a line segment embedded in $\Bbb R^3$ .","['euclidean-geometry', 'group-theory', 'geometry', 'measure-theory']"
3492485,Colored areas in a triangle that don't share a line,"A friend and I came up with this puzzle and I'm looking for a proof. Given an equilateral triangle of area 1, color parts of the triangle red,
  blue, and green such that Each color makes exactly one connected region strictly inside the triangle There is no line parallel to one of the sides that contains points of multiple colors Let $X$ be the minimum area of the red, blue, and green regions. Find
  the maximum value of $X$ over all possible colorings. I suspect the maximum occurs in the following arrangement of teardrop-shaped figures, which each have an area of $\frac{4}{45}$ (new bound found by Daniel Mathias). This is an awfully strange number for what seems like a nice problem, so I'm not sure if it's correct. If you consider the triangle formed by the three points closest to the center and call $x$ the side length, $\frac{4}{45}$ can be reached when $x=\frac{4}{5\cdot 3^{3/4}}$ . If $s$ is the side length of the original triangle, each region has area $x\left(\frac{s}{3}-\frac{5x\sqrt{3}}{12}\right)$ . Maximizing this gives $\frac{4}{45}$ . Does anybody have an idea of a proof (or a counterexample) that this indeed gives the maximum? If it is valid, is there any intuition behind the value $\frac{4}{45}$ that makes it so special? Also, we can look at the discrete case of this puzzle on a triangular grid with $n$ vertices on each side where we color vertices three colors. Asymptotically, this should have the same behavior as the original problem. I couldn't see a very nice pattern with small values—does anybody have a solution to this modified problem? We tried to look for problems similar to this one; it seems like it should be well known! However, we couldn't find anything. If anybody could help us, that would be greatly appreciated.","['euclidean-geometry', 'geometry', 'extremal-combinatorics', 'combinatorial-geometry', 'combinatorics']"
3492498,"Why isn't this property preserved going from pmfs to pdfs? $\Pr(cX=x)=\Pr(X=x/c)$, but $f_X(x/c)\neq f_Y(x),\ Y=cX$","I've tried searching for this but I think the question is a bit too specific. I was working through a problem and along the way I had to write the probability density of some variable $cX$ at the point $x$ . In my case $X\sim N(0,1)$ . Then I wrote ""The event $cX=x$ is equivalent to the event $X=\frac{x}{c}$ , so $f_{Y}(x)=f_X\left(\frac{x}{c}\right)$ , where $f_Y(\cdot)$ is the density function for the variable $Y=cX$ ."" But then I thought about it for a while and realised it wasn't true. We have \begin{equation*}
    f_X\left(\frac{x}{c}\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{\left(\frac{x}{c}\right)^2}{2}}=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2c^2}}
\end{equation*} whereas we have \begin{equation*}
    f_Y(x)=\frac{1}{\sqrt{2\pi c^2}}e^{-\frac{x^2}{2c^2}}
\end{equation*} So my statement above was false. However, I gather that it would be true if $X$ was discrete. I am aware of the transformation-of-variables formula $Y=g(X)\implies f_Y(y)=f_X(g^{-1}(y))\bigg|\frac{\mathrm{d}}{\mathrm{d}y}g^{-1}(y)\bigg|$ , and I just need a bit of help understanding which step in my logic was faulty. Is it because probability mass functions for discrete variables are not trivially analogous to probability density functions for continuous variables? Thank you!","['statistics', 'probability']"
3492506,Convergence in distribution implies point-wise convergence of MGF,"Let $\mu_n, \mu$ be probability measures on $\mathbb{R}$ such that $\mu_n$ converges in distribution to $\mu$ . Let $M_n(s) = \mathbb{E}(e^{sX_n})$ and $M(s) = \mathbb{E}(e^{sX})$ be the respective moment generating functions. Assume that $M_n(s)$ is finite in a common interval $[-s_0, s_0]$ , $s_0 > 0$ . Does it follow that $M_n(s) \rightarrow M(s)$ in this interval? I want to know if this holds in order to prove a version of the continuity theorem for MGFs. The issue I am having is that the function $e^{sx}$ is continuous but not bounded, unlike the case for characteristic functions.","['moment-generating-functions', 'probability-theory', 'weak-convergence']"
3492509,"Find $\lim\limits_{n \to \infty} \int_0^1 \sqrt[n]{x^n+(1-x)^n} \,dx$. [duplicate]","This question already has answers here : Evaluate $\lim_{n \to \infty} \int_{0}^1 [x^n + (1-x)^n ]^{1/n} \ \mathrm{d}x$ (4 answers) Closed 4 years ago . I have the following limit to find: $$\lim_{n \to \infty} \int_0^1 \sqrt[n]{x^n+(1-x)^n} \, dx$$ And I have to choose between the following options: A. $0$ B. $1$ C. $\dfrac{3}{4}$ D. $\dfrac{1}{2}$ E. $\dfrac{1}{4}$ This is what I did: $$\int_0^1 \sqrt[n]{x^n+(1-x)^n}  \, dx =
\int_0^{\frac{1}{2}} \sqrt[n]{x^n+(1-x)^n} \, dx +
\int_{\frac{1}{2}}^1 \sqrt[n]{x^n+(1-x)^n} \, dx$$ If we consider the first term of this sum: $$\int_0^{\frac{1}{2}} \sqrt[n]{x^n+(1-x)^n} \, dx \ge
\int_0^\frac{1}{2} \sqrt[n]{x^n+x^n} \, dx =
\int_0^\frac{1}{2}2^{\frac{1}{n}}x \, dx$$ And that means: $$\lim_{n \to \infty} \int_0^{\frac{1}{2}} \sqrt[n]{x^n+(1-x)^n} \, dx \ge
\lim_{n \to \infty} \int_0^\frac{1}{2}2^{\frac{1}{n}}x \, dx =
\int_0^\frac{1}{2}x \, dx = 
\frac{1}{8} \tag 1$$ If we consider the second term of that sum we have: $$\int_{\frac{1}{2}}^1 \sqrt[n]{x^n+(1-x)^n} \, dx \ge
\int_\frac{1}{2}^1 \sqrt[n]{(1-x)^n+(1-x)^n} \, dx =
\int_\frac{1}{2}^1 2^{\frac{1}{n}}(1-x) \, dx$$ And that means: $$\lim_{n \to \infty} \int_{\frac{1}{2}}^1 \sqrt[n]{x^n+(1-x)^n} \, dx \ge \lim_{n \to \infty} \int_\frac{1}{2}^1 2^{\frac{1}{n}}(1-x) \, dx = \lim_{n \to \infty} \int_\frac{1}{2}^1 (1-x) \, dx = \frac{1}{8} \tag 2$$ Now we can sum $(1)$ and $(2)$ and we have: $$\lim_{n \to \infty} \int_0^1 \sqrt[n]{x^n+(1-x)^n} \, dx \ge \frac{1}{4}$$ So now we have a lower bound. We can do something similar for the upper bound. Again, let's consider the first term of that sum: $$\int_0^{\frac{1}{2}} \sqrt[n]{x^n+(1-x)^n} \, dx \le
\int_0^{\frac{1}{2}} \sqrt[n]{(1-x)^n+(1-x)^n} \, dx = 
\int_0^{\frac{1}{2}} 2^\frac{1}{n}(1-x) \, dx$$ That means: $$\lim_{n \to \infty} \int_0^{\frac{1}{2}} \sqrt[n]{x^n+(1-x)^n} \, dx \le
\lim_{n \to \infty} \int_0^{\frac{1}{2}} 2^\frac{1}{n}(1-x) \, dx = 
\int_0^{\frac{1}{2}} (1-x) \, dx = 
\frac{3}{8} \tag 3$$ And if we consider the second part of that sum: $$\int_{\frac{1}{2}}^1 \sqrt[n]{x^n+(1-x)^n} \, dx \le 
\int_{\frac{1}{2}}^1 \sqrt[n]{x^n+x^n} \, dx = 
\int_{\frac{1}{2}}^1 2^\frac{1}{n} x \, dx$$ And that means: $$\lim_{n \to \infty} \int_{\frac{1}{2}}^1 \sqrt[n]{x^n+(1-x)^n} \, dx \le
\lim\_{n \to \infty} \int_{\frac{1}{2}}^1 2^\frac{1}{n} x \, dx = 
\lim_{n \to \infty} \int_{\frac{1}{2}}^1 x \, dx = 
\frac{3}{8} \tag 4$$ And now if we sum $(3)$ and $(4)$ we get: $$\lim_{n \to \infty} \int_0^1 \sqrt[n]{x^n+(1-x)^n} \, dx \le
\frac{3}{4}$$ So after all of that, we have: $$\frac{1}{4} \le
\lim_{n \to \infty} \int_0^1 \sqrt[n]{x^n+(1-x)^n} \, dx \le \frac{3}{4}$$ But this didn't help me all that much. Choices C , D and E are still consistent with this inequality that I got. So what should I do to find the exact answer? Or did I do something wrong in my calculations?","['integration', 'limits', 'calculus']"
3492510,"Find the positive integers $a,b,$ and $c$ s.t. $\sqrt{\sqrt[3]{5} - \sqrt[3]{4}}\times 3 = \sqrt[3]{a}+\sqrt[3]{b}-\sqrt[3]{c}.$","Let $a,b,c$ be positive integers such that $\sqrt{\sqrt[3]{5} - \sqrt[3]{4}}\times 3 = \sqrt[3]{a}+\sqrt[3]{b}-\sqrt[3]{c}$ . Determine the values of $a, b,$ and $c$ . To solve this simplification problem, it seems that it will be useful to use the difference of cubes formula and/or difference of squares formula as well as some substitutions. I wasn't able to determine a useful method of solving this, however. Using a computer program, I was able to deduce that the desired values $(a,b,c)$ are $(2,20,25)$ .","['algebra-precalculus', 'radicals']"
3492514,Find a limit in order to find an asymptote,I need to draw the graph of the function $y=\sqrt[3]{(x^2)(x+9)}$ . Suppose $y=k\cdot x + b$ is the equation for the asymptote. I managed to find $$k=\lim_{x\to\infty}\frac{y(x)}{x}=\lim_{x\to\infty}\sqrt[3]{\frac{x+9}{x}}=1$$ But then I got stuck finding $$b=\lim_{x\to\infty}y(x)-k\cdot x$$ Any ideas on how to deal with it?,"['graphing-functions', 'analysis', 'real-analysis', 'calculus', 'limits']"
3492549,Proof Involving De Morgan's Law and Cartesian Product of Sets,"Please check/critique the following proof. I think it is correct, but a bit verbose/overexplained. Let $A$ and $B$ be sets. Show, in general, that $\overline{(A \times B)} \neq \overline{A} \times \overline{B}$ . Let $(x,y)\in \overline{A \times B}$ $\implies (x,y)\not\in A \times B$ $\implies \lnot ((x,y) \in A \times B)$ $\implies \lnot(x\in A \land y\in B)$ $\implies x\not\in A \lor y\not\in B$ $\implies (x \in A \land y\not\in B) \lor (x\not\in A \land y\in B) \lor (x\not\in A \land y\not\in B)$ Let $(x \in A \land y\not\in B) \neq (x\not\in A \land y\not\in B) = (x\in \overline{A} \land y\in \overline{B}) = (x,y)\in \overline{A} \times \overline{B}$ . Thus, $\overline{A \times B} \not\subseteq \overline{A} \times \overline{B}$ and $\overline{A \times B} \neq \overline{A} \times \overline{B}$ . Thanks","['elementary-set-theory', 'proof-writing']"
3492560,What is an algebraic variety?,"I'm studying abelian varieties from Milne's book, but I'm having difficulty juggling different conventions and definitions of basic concepts, like those of algebraic and projective varieties. First, let me write some terminology the way I understand it. Classically, an affine $k$ -variety is a Zariski closed (zero set of some family of polynomial), irreducible subset of $k^n$ where $k$ is any field, and an affine algebraic set is just any Zariski closed subset. A projective $k$ -variety is a Zariski closed (zero set of some family of homogeneous polynomials) subset of $\mathbb P^n$ . The definition of an algebraic ( $k$ -)variety is somewhat more delicate. According to Milne's Algebraic Geometry notes, an affine $k$ -variety is any locally ringed space isomorphic to some $(V,\mathcal{O}_V)$ where $V$ is affine algebraic and $\mathcal{O}_V(U)$ is the set of regular functions on $U$ (rational functions with a denominator that doesn't vanish on $U$ ). First question: how is this definition of an affine $k$ -variety related to the one above? Next, Milne defines an algebraic prevariety over $k$ as a locally ringed space admitting a finite open cover of affine $k$ -varieties, and then an algebraic $k$ -variety is a separated algebraic prevariety over $k$ . What confuses me with this definition is that I don't recognize a scheme structure on Milne's definition of a variety. My second question is, is it true that the affine $k$ -varieties $(V,\mathcal{O}_V)$ are affine (k-)schemes. In particular, to what ring $R$ is $(V,\mathcal{O}_V)$ isomorphic to $\operatorname{Spec} R$ ? Finally, Qing Liu's definition of an algebraic $k$ -variety is as follows. An affine $k$ -variety is ""the affine scheme associated to a finitely generated (reduced) $k$ -aglebra"". Which affine scheme is this? Is it simply $\operatorname{Spec} k[T_1,\dots,T_n]/I$ with $I$ radical? How does one make this association precise? Finally, Liu's algebraic $k$ -variety is a $k$ -scheme admitting an finite cover of affine $k$ -varieties. I suppose the ultimate question is this. What is the relationship between affine algebraic sets in $k^n$ , sheaves of reduced, finitely-generated $k$ -algebras, and the scheme $\operatorname{Spec}k[T_1,\dots,T_n]/I$ where $I$ is a radical ideal, and what does it mean for a variety to be affine or projective in these contexts?","['definition', 'algebraic-geometry', 'soft-question', 'terminology']"
3492567,vertical component of Lie bracket,"Let $f:X\to Y$ be a submersion equipped with a connection given by a vertical projection $\mathrm V$ . Let $\vec v_1,\vec v_2$ be vector fields on $Y$ with unique horizontal lifts $\vec u_1,\vec u_2$ . I have read the vertical component $\mathrm V([\vec u_1,\vec u_2](x))$ of the Lie bracket at a point $x\in X$ depends only on $\vec u_1(x),\vec u_2(x)$ , i.e $\vec v_1(fx),\vec v_2(fx)$ . Question. What is the intuition behind this fact and how can I prove it?","['connections', 'lie-derivative', 'differential-geometry']"
3492571,Distribution function of stopped Brownian motion,"Suppose $\{B(t); t \geq 0\}$ is a standard Brownian motion, and define the process $\{X(t); t \geq 0\}$ $X(t) = x+B(t)$ , where $x>0$ fixed real number. Next define $\tau_0 := \inf \{t \geq 0: X(t) = 0\}$ and using $\tau_0$ define the stochastic process $\{Y(t); t \geq 0\}$ as $Y(t) = X(t), t\leq \tau_0$ and $Y(t)=0$ otherwise. Compute for $t>0 $ the probability density function of $Y(t)$ . Hint: observe that for each $t>0, y>0$ , $$P(Y(t)>y)= P(X(t)>y, \tau_0>t).$$ I started solving this problem on my own, however, I am not sure how to continue. I would be grateful for any help! Solution: Note that $\tau_0 = inf\{B(t)=-x\} =: \tau_{-x}^{B}$ and recall that $\tau_{-x}^{B} = \tau_{x}^{B}$ . Then, $P(Y(t)> y) = P(X(t)>y, \tau_0>t) = P(B(t) > y-x, \tau_{x}^{B}>t)= P(B(t)>y-x)P(\tau_{x}^{B})$ .","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
3492573,"Evaluate $\int_0^1 \frac{\arctan x\ln^2 x}{1+x^2}\,dx$","Empirically, i have obtained the following value: \begin{align}K&=\int_0^1 \frac{\arctan x\ln^2 x}{1+x^2}\,dx\\
&=\frac{151}{11520}\pi^4-\frac{1}{24}\ln^4 2-\text{Li}_4\left(\frac{1}{2}\right)+\frac{1}{24}\pi^2\ln^2 2-\frac{7}{8}\zeta(3)\ln 2\end{align} How to prove this? My attempt: Observe: \begin{align}K&=\int_0^1 \int_0^1\frac{x\ln^2 x}{(1+x^2)(1+t^2x^2)}\,dt\,dx\\
\end{align} On the other hand, \begin{align}K&\overset{\text{IBP}}=\left[\left(\int_0^x \frac{\ln^2 t}{1+t^2}\,dt\right)\arctan x\right]_0^1-\int_0^1 \int_0^1\frac{x\ln(tx)^2}{(1+x^2)(1+t^2x^2)}\,dt\,dx\\
&=\frac{\pi^4}{64}-K-\int_0^1\int_0^1 \frac{x\ln^2 t}{(1+x^2)(1+t^2x^2)}\,dt\,dx-2\int_0^1\int_0^1 \frac{x\ln t\ln x}{(1+x^2)(1+t^2x^2)}\,dt\,dx\\
\end{align} Moreover, one can prove: \begin{align}\int_0^1 \int_0^1\frac{x\ln^2 t}{(1+x^2)(1+t^2x^2)}\,dt\,dx&=\frac{1}{64}\pi^4-\text{G}^2\end{align} Unfortunately, $\displaystyle U= \int_0^1\int_0^1 \frac{x\ln t\ln x}{(1+x^2)(1+t^2x^2)}\,dt\,dx$ seems not easier to compute than $K$ Edit: \begin{align}U&=\int_0^1\int_0^1 \frac{x\ln t\ln x}{(1-t^2)(1+x^2)}\,dt\,dx -\int_0^1\int_0^1 \frac{xt^2\ln t\ln x}{(1-t^2)(1+t^2x^2)}\,dt\,dx\\
&=\frac{1}{384}\pi^4-\int_0^1\int_0^1 \frac{xt^2\ln t\ln(tx)}{(1-t^2)(1+t^2x^2)}\,dt\,dx+\int_0^1\int_0^1 \frac{xt^2\ln^2 t}{(1-t^2)(1+t^2x^2)}\,dt\,dx\\
\end{align} The last one is doable and, \begin{align}V&=\int_0^1\int_0^1 \frac{xt^2\ln t\ln(tx)}{(1-t^2)(1+t^2x^2)}\,dt\,dx\\
&=\int_0^1 \frac{\ln t}{1-t^2}\left(\int_0^t \frac{u\ln u}{1+u^2}\,du\right)\,dt\\
&=\frac{1}{4}\int_0^1 \frac{\ln t}{1-t^2}\left(\int_0^{t^2} \frac{\ln u}{1+u}\,du\right)\,dt\\
\end{align} Edit2: Since for $t\neq 1$ , $\displaystyle \frac{1}{1-t^2}=\frac{1}{2}\times \frac{2t}{1-t^2}+\frac{1}{1+t}$ then, \begin{align}V&=\frac{1}{4}\int_0^1 \left(\frac{1}{2}\times \frac{2t}{1-t^2}+\frac{1}{1+t}\right)\ln t\left(\int_0^{t^2} \frac{\ln u}{1+u} \,du\right)\,dt\\
&=\frac{1}{4}\int_0^1 \frac{\ln t}{1+t}\left(\int_0^{t^2} \frac{\ln u}{1+u}\,du\right)\,dt+\frac{1}{16}\int_0^1 \frac{\ln t}{1-t}\left(\int_0^t \frac{\ln u}{1+u}\,du\right)\,dt
\end{align}","['integration', 'harmonic-numbers', 'definite-integrals']"
3492584,What's the probability of generating an existing account id?,"I'm working on a website that supposed to generate a unique account id for every person that registers for the site. What is the probability of having the same user id being generated twice? Each user id is $32$ characters in length. Each character is randomly chosen and replaced from a set of characters A set is a combination of [a-zA-Z] that is $52$ characters in length. import secrets
from string import ascii_letters as letters


def get_random_user_id():
    while True:
        user_id = ''.join([letters[secrets.randbelow(len(letters))]
                            for _ in range(32)])
        try:
            User.objects.get(uid=user_id)
        except User.DoesNotExist:
            return user_id That's my current function def prob_of_col(n: int, set_size: int, output_size: int) -> float:
    '''Calculates the probability of a collision.

    Args:
        n: The number of users. 
        set_size: The number of characters to choose from.
        output_size: The number of characters to return. 
    Returns:
        A float that ranges from 0 to 1.
    '''

    e = 2.7182818284590452353602875
    return 1 - 1.0 / pow(e, ((n*(n-1))/(2*pow(set_size, output_size))))


n = pow(10, 27)
set_size = 52
output_size = 32

prob = prob_of_col(n, set_size, output_size)
print(prob)","['statistics', 'probability']"
3492590,"linear combination, span, independence and bases for infinite dimensional vector spaces.","I've only recently started studying linear algebra using some lecture notes by Evan Dummit ( https://math.la.asu.edu/~dummit/docs/linalgprac_2_vector_spaces.pdf ). After defining vector spaces, the notions of linear combination, span, generating set and linear independence are introduced. All of this culminates in the definition of a basis for a vector space followed by the dimension. Def: A vector $w$ is a linear combination of a set of vectors $v_{1}, v_{2},...,v_{n}$ if $\exists$ scalars $a_{1}, a_{2},..., a_{n}$ s.t. $w=a_{1}v_{1}+a_{2}v_{2}+\cdots+a_{n}v_{n}$ . Even though it is not explicitly stated this is a finite set of vectors since otherwise the expression does not have any meaning. Def: The span of a set of vectors $S=\{v_{1}, v_{2},...,v_{n}\}$ is the set of all linear combinations of $S$ . Def: Given a vector space $V$ , we say that $S$ is a generating set for $V$ if $\operatorname{span}(S)=V$ . This means that every vector in $V$ can be written as a linear combination of the vectors in the set $S$ . Def: A finite set of vectors $v_{1}, v_{2},...,v_{n}$ is linearly independent if $a_{1}v_{1}+a_{2}v_{2}+\cdots+a_{n}v_{n}=0$ implies that $a_{i}=0$ $\forall i$ . An infinite set of vectors is linearly independent if every finite subset is linearly independent (this is again because a linear combination of infinitely many vectors does not make sense). Def: Given a vector space $V$ , we say that an independent set of vectors which spans $V$ is a basis. So far so good with the definitions, but there is one thing that I just couldn't understand so far. Given the basis we can talk about the dimension of the vector space (which is the number of basis elements) and there are also infinite-dimensional vector spaces. However, there is also a theorem that states that every vector space (finite- or infinite-dimensional) has a basis. So my question is how a basis can even exist for the infinite-dimensional case when the definition of a linear combination only makes sense for finitely many vectors and the basis in this case has an infinite number of elements by definition. Can someone please point me in the correct direction? What am I missing? Thanks very much!","['hamel-basis', 'linear-algebra', 'vector-spaces']"
3492609,Eigendecomposition and Diagonalization of a matrix.,"Is a matrix diagonalizable if and only if it has an eigendecomposition? If not, can you give an example of a diagonalizable matrix which doesn't have an eigendecomposition, or vice-versa?","['matrices', 'diagonalization', 'linear-algebra', 'eigenvalues-eigenvectors']"
3492643,How many distinct $6$ digit numbers are there in which all of the digits $1$ to $5$ appear?,"For part (i), I think it's just $6!$ . (ii), I think if we treat $\texttt{123}$ as a block, then we should have 4 slots intead of 6 slots now, so the answer should be $4!$ . (iii) $\frac{6!}{2}$ - this should also be correct. (iv) -not sure what do to- need help and explanation. I did some programming and checked one by one, and if my code is correct, the answer is 5280 ?","['permutations', 'statistics', 'combinatorics', 'combinations']"
3492680,Algebraic de Rham cohomology for projective hypersurfaces degree d,"I am trying to understand how to get hold of the algebraic de Rham cohomology for a smooth projective hypersurface (say the zero set of some polynomial $f$ ). I think I need to find a hypercohomology(?) but remain unsure what this means so I am stuck. I have been told it is easier to get hold of the algebraic de Rham cohomology than the de Rham cohomology of the corresponding smooth manifold I have a couple of ideas of how to proceed: one way may be by adjunction formula. An understandable explanation or link to an explanation of how to use this would be great. Another thought is that (I think) the Hodge to De Rham spectral sequence degenerates at the second page in our case so I think I can conclude(?) $$H_{dR}(X) = \sum_{i+j=n}H^i(X,\Omega^j)$$ which reduces my problem to finding $H^i(X,\Omega^j)$ which may be easier?","['algebraic-geometry', 'de-rham-cohomology', 'projective-space']"
3492709,Law of total expectation and recursion,"I have a problem with one exercise from Probability and Random Processes (2001) by Geoffrey R. Grimmett and David R. Stirzaker. A coin shows heads with probability $p$ . Let $X_n$ be   the number of flips required to obtain a run of n consecutive heads. Show that $E(X_n) = \sum\limits_{i=1}^n p^{-i}$ . The solution offered by authors is $E(X_n) = E\{E(X_n|X_{n-1})\} = E\{p(X_{n-1} + 1) + (1-p)(X_{n-1} + 1 + X_{n})\}$ . I am a bit confused with the last equation. From definition of $E(X|Y)$ we shoud have something like: $$
E(X_n|X_{n-1}) =
\begin{cases}
v_1, \text{with} \; \text{probability} \; P(X_{n-1} = w_1), \\
v_2, \text{with} \; \text{probability} \; P(X_{n-1} = w_2), \\
\dots
\end{cases}
$$ But on the right hand we got something like this (from answer to Rigorous proof of the recursion method to compute expectations in probability. ) $$
E(X_n) = E(X_n|X_n \; \text{ends})P(X_n \; \text{ends}) + E(X_n|X_n \; \text{starts} \; \text{again})P(X_n \; \text{starts} \; \text{again})
$$ So could someone expand the given answer in a more clear and strict form. Excuse my English, I'm not a native speaker.","['conditional-expectation', 'probability-theory']"
3492835,Guessing the third side of the triangle from the given two sides,"My solution:- We know that the length of the third side of a triangle is between the sum of the two sides and the difference between the two sides. So according to the question the third side $x$ , should follow this condition, $29>x>7$ . So a probable value of $x$ is 28. So the answer should be II only. But this option is non-existent. So is the question above or more specifically the options for the questions formulated wrongly? If there's any problem in my question please let me know. Thanks!","['triangles', 'geometry', 'triangle-inequality']"
3492855,Group with exactly $2$ elements of order $6$ has a normal subgroup of order $3$,"Let $G$ be a group with exactly $2$ elements of order $6$ . Prove that $G$ has a normal subgroup of order $3$ . Since there is an element of order $6$ , by Lagrange's Theorem, the order of $G$ must be a multiple of $6$ . That means that both $2$ and $3$ are also divisors of the order of $G$ , so, again by Cauchy's Theorem, $G$ must contain elements of order $2$ and order $3$ as well, respectively. I suppose I'm not sure where to proceed from here. How can we use the fact that $G$ has exactly $2$ elements of order $6$ ? Would Sylow Theorems be helpful here at all ? I don't see how - since we don't know the exact order of $G$ here, which is when I'm used to using the Sylow Theorems. Any help would be appreciated. Thanks!","['normal-subgroups', 'group-theory', 'abstract-algebra']"
3492904,Expected winning amounts for $2$ players with different number of sided dice,"The following is an interview question. Given $2$ fair dice. My dice consists of $20$ sides with number from $1$ to $20$ . The other player has a $30$ -sided die with numbers from $1$ to $30$ . We both flip our own die. If my number is bigger, then the other player gave me my number of dollars and vice versa. But if we got the same number, I will pay the other player the number of dollars. What is the expected value of my winning or lost? My attempt: Let $X$ and $Y$ be the score obtained by my die and my opponent respectively.
Therefore, for each $2\leq i\leq 20,$ $$P(I \text{ win } i \text{ amount}) = P(Y<i)\cdot P(X=i) = \frac{(i-1)\times 1}{30\times 20}.$$ On the other hand, for each $-30\leq j\leq -1,$ we have $$P(I \text{ lose } j \text{ amount}) = P(X=j)P(Y\geq j) = \frac{1}{20} \frac{30-j+1}{30}$$ It follows that my expected wining amounts is $$-\sum_{j=-30}^{-1} j P(I \text{ lose } j \text{ amount}) + \sum_{i=2}^{30} i P(I \text{ win } i \text{ amount}).$$ I am not sure whether I am on the right track.","['discrete-mathematics', 'combinatorics', 'probability']"
3492942,how to calculate the norm of the above fields $K^{\times}$?,"Let $K$ be the quadratic extension of p-adic field $\mathbb{Q}_2$ , then $K=\mathbb{Q}_2(\sqrt n)$ , where $n=-1, \pm 2, \pm 3, \pm 6$ . Then I have seen a table in page $34$ of  the book $\text{Arithmetic of quadratic forms}$ by Goro Shimura as follows: \begin{array}{c  | c}
K & N_{K/\mathbb{Q}_2}(K^{\times}) \\ 
\hline
\mathbb{Q}_2(\sqrt{-3}) & 4^{\mathbb{Z}} \mathbb{Z}_2^{\times} \\ \hline
\mathbb{Q}_2(\sqrt{-1}) & 2^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2 |x-1 \in 4 \mathbb{Z}_2\} \\ \hline
\mathbb{Q}_2(\sqrt{3}) & (-2)^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2|x-1 \in 4 \mathbb{Z}_2 \} \\ \hline 
\mathbb{Q}_2(\sqrt{2}) & 2^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2 |x\pm 1 \in 8 \mathbb{Z}_2\} \\ \hline
 \mathbb{Q}_2(\sqrt{-2})& 2^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2 |x- 1 \in 8 \mathbb{Z}_2 \ \text{or} \ x-3 \in 8 \mathbb{Z}_2\}\\ \hline
\mathbb{Q}_2(\sqrt{6}) &  (-2)^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2 |x- 1 \in 8 \mathbb{Z}_2 \ \text{or} \ x-3 \in 8 \mathbb{Z}_2\}\\ \hline
\mathbb{Q}_2(\sqrt{-6}) & 6^{\mathbb{Z}} \cdot \{ x \in \mathbb{Z}_2 |x\pm 1 \in 8 \mathbb{Z}_2 \}
\\ \hline 
\end{array} where $N_{K/\mathbb{Q}_2}$ denotes the field norm. My question is- I know to calculate field norm at a point of a field in few ways like by multiplication map, by using Galois group etc. (i)But how to calculate the norm of the above fields $K^{\times}$ ? (ii) Does it mean $N(K^{\times})=\{N(a)  \ | \  \forall a \in K^{\times} \}$ ? (iii) Can you please help me in case $-1, -2$ in the above cases ?","['field-theory', 'number-theory', 'p-adic-number-theory', 'commutative-algebra']"
3493008,"Do there exist such groups $G$, such that $(A \cup A^{-1})^* \setminus L(G, A)$ is recursively enumerable, but $L(G, A)$ isn't?","Suppose $G$ is a finitely generated group, $A$ is a finite set of generators of $G$ . Define $\pi: (A \cup A^{-1})^* \to G$ using the following recurrence: $$\pi(\Lambda) = e$$ $$\pi(a \alpha) = a\pi(\alpha)$$ Now define the language $L(G, A) := \{w \in (A \cup A^{-1})^*| \pi(w) = e\}$ . Note that the position of $L(G, A)$ (as well as of $(A \cup A^{-1})^* \setminus L(G, A)$ ) in Chomsky hierarchy is uniquely determined by the properties of $G$ . It is a well known fact, proved by Novikov and Boone, that there exist such groups $G$ , that $L(G, A)$ is recursively enumerable, but $(A \cup A^{-1})^* \setminus L(G, A)$ isn't. Such groups can even be finitely presented. The smallest known such group has $12$ generators. My question is: Do there exist such groups $G$ , such that $(A \cup A^{-1})^* \setminus L(G, A)$ is recursively enumerable, but $L(G, A)$ isn't? I know, that $L(G, A)$ its recursively enumerable iff $G$ is isomorphic to a subgroup of a finitely presented group. I also know that a such asymmetry holds for context-freedom: on one hand context free $L(G, A)$ implies context free $(A \cup A^{-1})^* \setminus L(G, A)$ , but on the other hand, there exist groups such that $(A \cup A^{-1})^* \setminus L(G, A)$ is context free, but $L(G, A)$ isn't.","['combinatorial-group-theory', 'discrete-mathematics', 'group-theory', 'formal-languages', 'computability']"
3493051,All norms are equivalent in finite dimensional vector spaces example.,"While researching the equivalence in finite dimensional vector spaces, I found multiple proofs of the theorem, but I still can't wrap my head around the following example:
take a finite-dimensional vector: $v = \begin{bmatrix}1\\ 1\\ 1\end{bmatrix}$ .
If I calculate the 1-norm I get: |1| + |1| + |1| = 3.
For the 2-norm I get: $\sqrt {1^2 + 1^2 + 1^2} = \sqrt{3}$ . Lastly, for the infinite norm I get 1. How are these equal? I seem to not understand what the theorem actually means. Thanks in advance.","['linear-algebra', 'functional-analysis']"
3493077,Doubts on the mathematical content of the Hitler Downfall Meme.,"This question was inspired by this ""beautiful mind"" question , where some one asks about the mathematical contents of some movie. I do not see how this other question is less opinion-based than the one I am posing. This post also did not motivate anyone to censor it... I am giving a summer course on topology starting on January 6th. I am thinking about showing the Hitler Learns Topology meme on our first class, and maybe, showing again on the last class, or after the chapter on connectedness. But I have some doubts on the mathematical contents of the video, and I would be really thankful if someone could clarify those to me. OF COURSE, since the problem is NOT fully shown, I just hope someone can recognize the theory they are talking about and explain it to me. What is the ""null set"" they are talking about? Is this ""null set"" the topological space they are talking about? Or is it just the ""clopen"" set in question? I understood that the clopen set in question is ""the zero of the points in the null set"". What is this set? And why is it clopen? What is the ""close points"" Hitler refers to? Edit: I have edited the question so as to make it absolutely mathematical.",['general-topology']
3493078,"How to evaluate: $\int_0^1 \frac{\frac{\pi^2}{6}-\operatorname{Li}_2(1-x)}{1-x}\cdot \ln^2(x) \, \mathrm dx$","$$\int_0^1 \frac{\frac{\pi^2}{6}-\operatorname{Li}_2(1-x)}{1-x}\cdot \ln^2(x)\,\mathrm dx=1.03693\ldots$$ This number looks like $\zeta(5)$ value. We expand the terms $$\int_0^1\frac{\frac{\pi^2}{6}}{1-x}\cdot \ln^2(x) \, \mathrm dx-\int_0^1 \frac{\operatorname{Li}_2(1-x)}{1-x} \cdot \ln^2(x) \, \mathrm dx$$ $$2\zeta(2)\zeta(3)-\int_0^1 \frac{\operatorname{Li}_2(1-x)}{1-x}\cdot \ln^2(x) \, \mathrm dx$$ this last integral it is very complicate to compute... Can any user please help to show that whether this value is equal to $\zeta(5)$ or not?","['integration', 'definite-integrals', 'harmonic-numbers', 'polylogarithm', 'closed-form']"
3493151,High school contest math problem,"This is a calculus problem from a high school math contest in Greece,from 2012. I wish to know some solutions for this. I attempted to solve it. Let $f:\Bbb{R} \to \Bbb{R}$ differentiable such that $\lim_{x \to +\infty}f(x)=+\infty$ and $\lim_{x \to +\infty}\frac{f'(x)}{f(x)}=2$ .Show that $$\lim_{x \to +\infty}\frac{f(x)}{x^{2012}}=+\infty$$ Here is my attempt: $\frac{f(x)}{x^{2012}}=e^{\ln{\frac{f(x)}{x^{2012}}}}$ Now $\ln{\frac{f(x)}{x^{2012}}}=\ln{f(x)}-2012\ln x=\ln{x}\left( \frac{\ln{f(x)}}{\ln{x}}-2012\right)$ Now from hypothesis we see that $\lim_{x \to +\infty}\ln{f(x)}=+\infty$ By L'Hospital's rule we have that $$\lim_{x \to +\infty}\frac{\ln{f(x)}}{\ln{x}}=\lim_{x \to +\infty}x \frac{f'(x)}{f(x)}=2(+\infty)=+\infty$$ Thus $$\lim_{x \to +\infty}\ln{x}\left( \frac{\ln{f(x)}}{\ln{x}}-2012\right)=+\infty$$ Finally $\lim_{x \to +\infty}\frac{f(x)}{x^{2012}}=+\infty$ Is this solution correct? If it is,then are there also  better and quicker ways  to solve this? Thank you in advance.","['contest-math', 'real-analysis', 'calculus', 'solution-verification', 'limits']"
3493165,Probability that an integral of brownian motion is greater than $\frac{2}{\sqrt{3}}$,"Compute the probability $\mathbb{P}\big(\int_0^1 W(t) dt > \frac{2}{\sqrt 3} \big)$ Clearly, as I am not sure about where to start I am confused about how the $W(t)$ relates to an integral and how this number could relate to a probability. 1) Should I evaluate the integral first? Not sure how to do this. 2) Should I square both sides (risky)?","['stochastic-integrals', 'probability', 'stochastic-processes', 'brownian-motion', 'stochastic-calculus']"
3493198,Cardinality of the family of factorials of natural numbers,"Fix a nonempty subset $X$ of $\mathbb N$ . A number $a\in X$ will be called irreducible if it is not a product of smaller elements of $X$ . We call $X$ factorial if any number in $X$ has a unique factorization into irreducibles (up to the order of factors). Prove that the family of all factorial sets has cardinality $2^{\aleph_0}$ . Of course it has cardinality at most $2^{\aleph_0}$ , because the family of all subsets of $\mathbb N$ has that cardinality. But I don't know how to get that it is exactly of that size. I thought about assuming it has power $\aleph_0$ , and somehow using Cantor's diagonal argument, but this would not be enough without assuming extra assumptions (the continuum hypothesis). Any hints? Thanks in advance.","['elementary-set-theory', 'elementary-number-theory']"
3493219,Algebraic number theory in first-order arithmetic,"I was inspired to think about how algebraic number theory could be developed in first-order arithmetic, since most developments of ANT do make use of complex numbers. Most of the time such uses of continuous structures can be circumvented by employing tricks like rational approximations, but it's not entirely clear how all that could be done in first-order arithmetic. At least for ""elementary"" ANT, this most prominently comes up in the proof of Dirichlet's Unit Theorem, which even in the statement counts real and complex embeddings, and the standard proof further uses Minkowski's Theorem on convex bodies. While I have little doubt that the answer to this question is positive, let me state it anyway: Can Dirichlet's Unit Theorem be stated and proven in Peano arithmetic? The application of Minkowski's Theorem can probably be replaced with a clever pigeonhole principle argument (like in the usual proof of finiteness of the class number), I am more interested in how one would deal with the question of real vs complex embeddings. If there is one, I would be interested in some reference which systematically develops (or at least describes how one could do that) algebraic number theory in first-order arithmetic. One can of course extend this last request to other areas, two coming to my mind being analytic number theory and class field theory. If anyone has any references for those I am interested, but principal focus is still on algebraic number theory.","['algebraic-number-theory', 'first-order-logic', 'number-theory', 'reference-request', 'peano-axioms']"
3493250,Example where character table and Frobenius-Schur index doesn't determine the group.,"It is well known that the complex character table does not determine the group. The classical example always given is of a pair of groups of order $8$ , the dihedral group $D_8$ and the Quaternion group $Q_8$ . However these have different real representation theory - $\mathbb{R}[Q_8] = \mathbb{R} \times \mathbb{R} \times \mathbb{R} \times \mathbb{R} \times \mathbb{H}$ and $\mathbb{R}[D_8] = \mathbb{R} \times \mathbb{R} \times \mathbb{R} \times \mathbb{R} \times M_2(\mathbb{R})$ . This can be deduced from the complex character table as the Frobenius-Schur index of the 2 dimensional representation is 1 for $D_8$ and -1 for $Q_8$ . This then gives that the groups are non isomorphic. I was wondering what the smallest (or just any) example of two non isomorphic groups with identical character tables and Frobenius Schur indicators was. Many thanks in advance!","['group-theory', 'representation-theory', 'characters']"
3493267,"How is the set of functions from ${\{a,b\}}$ to $N$ countable?","Assume a set of functions from ${\{a,b\}}$ to $N$ Where $N$ is the set of Natural numbers. Let us assume that the size of $N$ is $n$ . i.e $|N|=n$ The first element $a$ have $n$ choices for mapping. The second element $b$ have $n$ choices for mapping as well. So the number of functions = $n.n$ = $n^2$ .
which  is strictly greater than $n$ and hence the size of $N$ .
So ""Set of functions from ${\{a,b\}}$ to $N$ "", should not be countable. But it is. I am just a beginner in discrete maths, so this might be a stupid question for some. But please explain.","['elementary-set-theory', 'functions', 'combinatorics', 'discrete-mathematics']"
3493342,$\int_{0}^{\frac{\pi}{4}}{\frac{\cos(2x)}{\cos x+\sin x}dx}$,$$\int_{0}^{\frac{\pi}{4}}{\frac{\cos(2x)}{\cos x+\sin x}dx}$$ I don't know how to evaluate this integral. This is a path that I've tried: $$\int_{0}^{\frac{\pi}{4}}{\frac{\cos(2x)}{\cos x+\sin x}dx} =$$ $$= \int_{0}^{\frac{\pi}{4}}{\frac{\cos^2x - \sin^2x}{\cos x+\sin x}dx} =$$ $$= \int_{0}^{\frac{\pi}{4}}{\frac{1-2\sin^2x}{\cos x+\sin x}dx}$$ My idea was: let $t = \sin x$ . Then $dt = \cos x dx$ . But I only have $\frac{1}{\cos x}$ . Any hints as to how to proceed from there? This integral is giving me a hard time.,"['integration', 'real-analysis', 'calculus', 'trigonometry', 'riemann-integration']"
3493361,What do you get when you sum over the smaller half of the harmonic series? [duplicate],"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 4 years ago . More specifically, how would you evaluate the below formula? $$\lim_{n\to\infty}\sum_{k=n/2}^{n}\frac{1}{k}$$ I know that the harmonic series starting at any point diverges, but when we limit it in this way, does the series diverge or converge? If it diverges: How might you determine that? Is there some $d$ that we can replace with $2$ to make the sequence converge? If it converges: What does it converge to, and how might you determine that? The sequence must converge for any $d>2$ . Is there a formula for the series generalized for any $d$ ?","['harmonic-numbers', 'sequences-and-series', 'real-analysis']"
3493374,How can we show that $n < 2^n$ for all natural numbers $n$?,"I proved it using calculus or by drawing their graph but I was thinking if there is any simpler way to prove it. Please help me. Proof by induction > $P(n) : n < 2^n$ for all $n \in\mathbb{N}$ $P(1) : 1 < 2^1$ , i.e. $1 < 2,$ this is a true statement. Now lets assume $P(m)$ is true i.e. $m < 2^m$ . So $P(m + 1) : m + 1 < 2^{m + 1}.$ Now $m < 2 ^ m \Rightarrow 2m < 2^{m + 1} \\
\Rightarrow m+m < 2^{m+1}\\
\Rightarrow m+1 <= m+m < 2^{m+1}\\
\Rightarrow m+1 < 2^(m+1)$ Hence $P(m+1)$ is true. Thus $P(m)$ is true $\Rightarrow P(m+1)$ so by principle of mathematical induction $P(n)$ is true for all $n \in \mathbb{N}.$ So as I said I know the proof using induction hence I wanted to know any other way to prove it.","['alternative-proof', 'algebra-precalculus']"
3493417,Is this logic behind the derivative of $x^x$ a coincidence?,"As many of you probably know, when you take the derivative of $x^x$ , you cannot treat it as either a exponential function ( $a^x$ ) or like a function of the form $x^a$ . If you treat it like $x^a$ then you get an aswer of $xx^{x-1}$ , which is just $x^x$ . Treat it like $a^x$ , and you get $x^xln(x)$ . The correct derivative is $x^x(ln(x)+1)$ , which you get by doing implicit differentiation after taking the natural log of both side. This is the same as $x^xln(x)+x^x$ , which happens to be the combination of the ""wrong"" derivatives you get when treating $x^x$ as the 2 different types of functions I specified earlier. Is there any real logic behind this or is it coincidence. Also, could this also be applied to other function hybrids like $x^x$ ?","['calculus', 'derivatives']"
3493438,Why is the curvature of the connection $\bar{z_1}dz_1 + \bar{z_2}dz_2$ on the Hopf fibration not exact?,"Let $\pi : S^3 \to S^2$ be the Hopf fibration, where we take $S^3 \subset \mathbb{C}^2$ , $S^2 = \mathbb{C}\mathbb{P}^1$ , and $\pi(z_1, z_2) = [z_1 : z_2]$ . This is a principal $U(1)$ -bundle. The form $\omega = \bar{z_1}dz_1 + \bar{z_2}dz_2$ on $S^3$ defines a connection on this principal bundle. Its curvature is given by $K = d\bar{z_1}\wedge dz_1 + d\bar{z_2}\wedge dz_2$ . Since the Lie algebra of $U(1)$ is isomorphic to $\mathbb{R}$ and the adjoint representation is trivial, $K$ descends to a standard $2$ -form on $S^2$ . I want to show this gives a non-trivial element of $H^2_{dR}(S^2)$ . I have tried to compute the pullback along $\pi$ of the Fubini-Study area form on $\mathbb{C}\mathbb{P}^1$ to see whether this is proportional to $K$ , but I didn't succeed. Does someone know how to do this? (A solution using a different approach would also be appreciated.)","['principal-bundles', 'hopf-fibration', 'differential-geometry']"
3493472,HAPPY NEW YEAR $2020$ Remainder Problem [duplicate],This question already has answers here : Modular exponentiation by hand ($a^b\bmod c$) (12 answers) Closed 4 years ago . I framed a new question just now. What is the Remainder when the number $20^{20}$ is divided by $2020$ My try: $$\frac{20^{20}}{2020}=\frac{20^{19}}{101}$$ Now Consider: $$20^{18}=(400)^9=(404-4)^9=101k-2^{18}$$ Now i was trying to find Remainder without calculator or by manual division.,"['elementary-number-theory', 'algebra-precalculus', 'euclidean-algorithm']"
3493534,What are some techniques for embedding a finite group into $S_m$ for $m$ as small as possible?,"I know that if $|G| = n$ , then $G$ can be embedded into $S_n$ . But the group $S_n$ is very large compared to $G$ , so I was wondering if there are general ways of embedding $G$ into a smaller symmetric group. (By general I don't mean that it has to work for all groups, but hopefully for large classes of groups) Also, I was wondering embedding groups into smaller symmetric groups is common/useful, or just a curiosity? The only approach I could think of is to let $G$ act on various things, and hope that the action is faithful. One nice thing, for example, is that if $G$ has a simple subgroup $H$ (which is itself non-normal in $G$ ), then the action of $G$ on the left cosets of $H$ is faithful, since according to this question, the kernel must be trivial. Furthermore, if you let $G$ act by conjugation on a subgroup, I believe the action is sometimes faithful, sometimes not (has to do with weather the conjugates are disjoint).","['permutations', 'group-theory', 'abstract-algebra']"
3493548,Why can a vector from an infinite-dimensional vector space be written as finite linear combination?,"Suppose $V$ is a infinite-dimensional vector space over $\mathbb{R}$ or $\mathbb{C}$ and $\beta$ is a basis for $V$ . I have seen the following claim: For every $v$ $\in$ $V$ , there exist $v_1,...,v_n \in \beta $ such that $$v = \sum_{i=1}^{n} a_i v_i.$$ But when $v$ is a linear combination of infinite number of vectors in $\beta$ , there does not exist such a integer $n$ . How can we still choose vectors like this? A related question is about $\textrm{span}(\beta)$ . I know that $\textrm{span}$ is the set of all linear combinations of finite vectors in the set. But then it would not include vectors that are obtained by a linear combination of infinite number of vectors. How can this be the case?","['linear-algebra', 'vector-spaces']"
3493550,Sine Wave With Alternating Wavelength,"Please Read Everything Fully and Carefully Before Responding!! I'm trying to formulate parametric equations for a sine wave where the wavelength grows by a constant on alternate sides, in this case, 1.3, and where  the amplitude decreases in an inverse manner. (See my image. It MUST be noted that the image probably does NOT look like the actual, properly graphed wave will!) To give you an idea of the sort of equations i'm looking for: $$y(t)=(function)$$ $$x(t)=sin(t)(function)^{-1}$$ NOTE. I'm using the term 'wavelength' in a way that is, to my understanding not in conformity with the standard definition. But, the above image should clarify what I'm talking about satisfactorily. NOTE. A note to everyone: I'd rather deal with this problem in the form that is given by my example equations, unless there is some issue with doing so...","['calculus', 'functions', 'trigonometry', 'wave-equation', 'constants']"
3493593,Transformation which takes Fermat curve $x^n+y^n=1$ to a hyperelliptic curve?,Motivated by this where it is possible to take certain Fermat curves like $x^3+y^3=1$ into Elliptic curves. I was wondering if it is always possible to transform  any Fermat curve $x^n+y^n=1$ birationally into some hyperelliptic curve?,"['number-theory', 'algebraic-geometry', 'elliptic-curves']"
3493615,Why is an exponent of $2n$ necessary in Dirichlet's Function?,"For those unfamiliar, a question explaining the definition is in the question here . The definition itself is $$\lim_{m\to\infty}\lim_{n\to\infty}\cos^{2n}\left(m!\pi x\right)$$ and evaluates to 1 for rational $x$ and 0 for irrational $x$ . The part I don't totally understand is why the exponent is $2n$ as opposed to just $n$ . This is a very-not rigorous question, but my concern stems from the fact that as $n\to\infty$ , $2n$ isn't necessarily even, let alone an integer, which negates the whole point of making rational values become $1$ instead of $\pm1$ . It seems like you could, on the other hand, write it as $$\lim_{m\to\infty}\lim_{n\to\infty}\left(\cos^{2}\left(m!\pi x\right)\right)^n$$ although I'm not entirely sure if this is the same expression. My other question is that if the first equation is 'right', it seems to like it logically follows that $$\lim_{n\to\infty}(-1)^{2n}=1$$ as well. Is this true?",['limits']
3493626,Translating predicate logic to english?,"I'm super confused about translating from predicate logic to english and vice versa. I can't find any good explanation that I can generally follow. Here is an example: ""Nobody is the judge for a case that s/he prosecutes."" I would choose J(x,y) = x is a judge of case y P(x,y) = x is the prosecutor of case y Now I translated it as follows: $∃x∀y(P(x,y) → ∀z¬J(z,y)$ So there exists someone that for any case the person prosecutes, there is nobody that will be the judge for that case. Now the correct answer was: $∀x∀y(P(x,y) → ¬J(x,y))$ I just don't understand why and how you translate these with certainty. I would really appreciate some tips here.","['first-order-logic', 'predicate-logic', 'discrete-mathematics', 'logic-translation']"
3493641,Having trouble understanding the concept of multiplicative inverse of modulo,"I'm trying to solve equations like this $$27x \equiv 10 \pmod 4$$ I understand that in a regular equation you have to multiply by the inverses of each number to isolate the variable. For example: $$27x = 10 \Leftrightarrow x = 10/27$$ You can't do that with modulo so the method that is used is to find if the gcd = 1, if it does it can be solved and you work your way back and write 1 as a linear conbination of 27 and 4 in this case, skipping a lot of steps you get $$1 = 7*4 + (−1)*27$$ Then you multiply both sides by 10 $$10 = 70*4 + (−10)*27$$ And this can be rewritten as $$10 + 70*4 = -10*27 \Leftrightarrow \\
-10*27 \equiv 10 \pmod 4$$ I don't understand why the answer is $x=2$ and not $x=-10$ . -10 is 2 mod 4. Yet both -10*27 and 2*27 are 2 mod 4, not 10. I don't understand. The idea of a multiplicative inverse still puzzles me.","['modular-arithmetic', 'discrete-mathematics']"
3493644,What is the Infinite Pigeonhole Principle?,"I saw this problem on AOPS and, at the end of pi $37$ 's proof, he mentioned something about the infinite pigeonhole principle. Can someone explain what he means by this?","['pigeonhole-principle', 'combinatorics']"
3493647,Do coordinate components transform in the same or opposite way as their bases?,"Consider a vector $\vec{A} = A_x \hat{x} + A_y \hat{y} = A^i e_i$ .
Intuitively, it seems as though the coordinates ( $A_x,A_y$ ) must transform in the opposite way as the bases ( $\hat{x},\hat{y}$ ).  For example if you rotate the bases by some angle, then to get the components in the different bases, you must rotate in the opposite direction to compensate.  i.e. if you can write $e'_i = M e_i$ , where $M$ is some rotation (or other linear transformation), then $(A')^i = M^{-1} A^i$ .  And this also seems familiar from my vague memory of covariance vs contravariance in general relativity. But considering a particular example: $\vec{A} = A_x \hat{x} + A_y \hat{y} = A_r \hat{r} + A_\theta \hat{\theta}$ , and the transformation between bases is given by: $$\pmatrix{\hat{r} \\ \hat{\theta}} = \pmatrix{\cos\theta & \sin\theta \\ -\sin\theta & \cos\theta} \pmatrix{\hat{x} \\ \hat{y}}$$ This gives, $$\vec{A} = A_r(\hat{x}\cos\theta + \hat{y}\sin\theta) + A_\theta(-\hat{x}\sin\theta + \hat{y}\cos\theta) \\ = \hat{x}(A_r \cos\theta - A_\theta \sin\theta) + \hat{y}(A_r\sin\theta + A_\theta\cos\theta)$$ Doing the same for $\hat{x}$ and $\hat{y}$ shows that the components transform in the same way as the bases, i.e. $A_r = A_x \cos\theta + A_y \sin \theta, \,\,\, A_\theta = - A_x \sin \theta + A_y \cos\theta$ , instead of transforming in the inverse manner. Am I doing something wrong here?  Or are the components and bases supposed to transform in the same way?","['coordinate-systems', 'geometry', 'linear-transformations']"
3493664,"How to show $d(\exp_p(tv),\exp_p(tw))=\vert t \vert\cdot\Vert v-w \Vert+O(t^2)$?","I'm self-studying Peter Petersen's Riemannian geometry book. This is Exercise 5.(14) in the book: Exercise 5.14) $M$ is a $n$ -dimensional Riemannian manifold, $p\in M$ , and $\exp_p:B(0,\varepsilon)\subset T_pM\rightarrow B(p,\varepsilon)$ is diffeomorphism. Then, whenever $tv,tw\in B(0,\varepsilon)$ , we have the following result. $$d(\exp_p(tv),\exp_p(tw))=\vert t \vert\cdot\Vert v-w \Vert+O(t^2)$$ So far, I've been trying to use the normal coordinate. In the normal coordinate, one can express $g_{ij}(x^1,\cdots,x^n)=\delta_{ij}+\frac{1}{3}R_{ikjl}x^kx^l+O(\Vert x \Vert^3)$ where $R_{ikjl}=\langle R(\partial_i,\partial_k)\partial_j,\partial_l \rangle$ . And, choose the minimizing geodesic $\gamma(s)=(x^1(s),\cdots,x^n(s))$ between $\gamma(0)=tv$ and $\gamma(1)=tw$ . Now, since the geodesic distance $d(tv,tw)=\int _0 ^1 \Vert \dot{\gamma}(s)\Vert ds$ , I tried to directly compute $\Vert \dot{\gamma}(s)\Vert$ . It is $$\sqrt{g_{ij}\,\dot{x}^i(s)\,\dot{x}^j(s)}=\sqrt{(\dot{x}^i)^2+\frac{1}{3}R_{ikjl}x^kx^l\dot{x}^i\dot{x}^j+\cdots}$$ But I don't know how to proceed after this. It seems like some analysis trick is needed? Or do I need totally different approach?","['riemannian-geometry', 'differential-geometry']"
3493757,Expected falling time of all $500$ random ants,"The random ant question is asked in this post . 
I reproduce it below for completeness. Question: $500$ ants are randomly put on a 1-foot string (independent uniform distribution for each ant between 0 and 1). Each ant randomly moves toward on end of the string (equal probability to the left or the right) at constant speed of 1 foot/minute until it falls of a t one end of the string. Also assume that the size of the ant is infinitely small. When two ants collide head-on, they both immediately change directions and keep on moving at 1 foot/min. What is the expected time for all ants to fall off the string? The question above is equivalent to asking the expected value of the maximum of $500$ IID random variables with uniform 
distribution between $0$ and $1$ . We know that the expected value of $\max(X_1,...,X_{500})$ where $X_1,...,X_{500}$ are IID, is $\frac{500}{501}$ , as shown in another post . However, the answer given to the random ant question is $\frac{499}{500},$ which I fail to decipher.","['expected-value', 'discrete-mathematics', 'probability', 'uniform-distribution']"
3493759,"How many numbers can we select from $\{1,2,...2016\}$ such that sum of any four of them cannot be divided by $11$","How many numbers can we select from $\{1,2, \ldots, 2016\}$ such that sum of any four of them cannot be divided by $11$ It's not hard to come up with some combinations, but the question is how to prove it's the largest set. For example if we select numbers in forms of $11N+1,11N+4,11N+9$ will yield us $184 + 183 + 183$ numbers. it looks like proof will be somewhat of an inequalities problem. Let $a_{i_0}, a_{i_1}, \ldots, a_{i_k} > 0$ be the count of numbers we select from each modulo class, and we want to maximize $a_{i_0} + a_{i_1} + \cdots + a_{i_k}$ But how to express the constraint is tricky.","['contest-math', 'number-theory', 'elementary-number-theory', 'combinatorics', 'inequality']"
3493778,Attribution of Numbers [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 4 years ago . Improve this question 2020 is an “undulating” as well as “abundant” number. Hope the year 2020 throws your life on an undulating path that ultimately leads to abundance ( Happy New Year) . My question revolves more around the attribution of numbers with sometimes  fancy words that I just used above (abundant and undulating) . When I read the formal or main stream Number Theory , an average book on number theory would deal with primes, rational, irrational, composites , highly composite etc. numbers. I have never or rarely come across terms like lazy caterer number , evil number , happy number in formal literature on number theory. Now, I understand that these attributes are based on certain characteristics that maybe exhibited by such numbers. However, is it worthwhile to know these attributes or are they just trivial and cursory properties being assigned to numbers that might be lacking depth otherwise? I may be missing out something here that maybe worthwhile . Is it really the case or am I amiss?","['number-theory', 'discrete-mathematics', 'terminology']"
3493803,"Trying to find $\tan^{-1}x-\tan^{-1}y$ for $\forall~x,y$","Suppose we want to calculate $\tan^{-1}x-\tan^{-1}y$ for $\forall~x,y$ We already know $\tan^{-1}x-\tan^{-1}y=\tan^{-1}\dfrac{x-y}{1+xy}$ for $x>0$ and $y>0$ , but we will not make use of it as we have to prove for $\forall$ $x,y$ $$\tan^{-1}x-\tan^{-1}y=\theta\tag{1}$$ Let's find range of $\theta$ , assuming $x$ and $y$ to be independent variables $$\theta\in(-\pi,\pi)$$ Taking $\tan$ on both sides of equation $1$ $$\dfrac{\tan(\tan^{-1}x)-\tan(\tan^{-1}y)}{1+\tan(\tan^{-1}x)\cdot \tan(\tan^{-1}y)}=\tan\theta$$ $$\dfrac{x-y}{1+xy}=\tan\theta$$ Taking $\tan^{-1}$ on both sides $$\tan^{-1}\dfrac{x-y}{1+xy}=\tan^{-1}(\tan\theta)$$ $$\tan^{-1}(\tan\theta)=\begin{cases}
    \pi+\theta,&-\pi<\theta<\dfrac{-\pi}{2} \\
    \theta,&-\dfrac{\pi}{2}<\theta<\dfrac{\pi}{2} \\
    -\pi+\theta, & \dfrac{\pi}{2}<\theta<\pi
  \end{cases}$$ So $$\theta=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy},&-\pi<\theta<\dfrac{-\pi}{2} \\
    \tan^{-1}\dfrac{x-y}{1+xy},&-\dfrac{\pi}{2}<\theta<\dfrac{\pi}{2} \\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{\pi}{2}<\theta<\pi
  \end{cases}$$ $$\tan^{-1}x-\tan^{-1}y=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy},&-\pi<\tan^{-1}x-\tan^{-1}y<-\dfrac{\pi}{2} \\
    \tan^{-1}\dfrac{x-y}{1+xy},&-\dfrac{\pi}{2}<\tan^{-1}x-\tan^{-1}y<\dfrac{\pi }{2}\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{\pi}{2}<\tan^{-1}x-\tan^{-1}y<\pi
  \end{cases}$$ $$\tan^{-1}x-\tan^{-1}y=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \tan^{-1}x-\tan^{-1}y\in\left(-\pi,\dfrac{-\pi}{2}\right)\\
    \tan^{-1}\dfrac{x-y}{1+xy},& \tan^{-1}x-\tan^{-1}y\in\left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \tan^{-1}x-\tan^{-1}y\in\left(\dfrac{\pi}{2},\pi\right)
  \end{cases}$$ $$\tan^{-1}x-\tan^{-1}y=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{x-y}{1+xy}\in\left(0,\infty\right)\\
    \tan^{-1}\dfrac{x-y}{1+xy},&\dfrac{x-y}{1+xy}\in\left(-\infty,\infty\right)\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{x-y}{1+xy}\in\left(-\infty,0\right)
  \end{cases}$$ $$\tan^{-1}x-\tan^{-1}y=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{x-y}{1+xy}>0\\
    \tan^{-1}\dfrac{x-y}{1+xy},&\dfrac{x-y}{1+xy}\in\left(-\infty,\infty\right)\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & \dfrac{x-y}{1+xy}\in\left(-\infty,0\right)
  \end{cases}$$ Let's take a look at first branch $\dfrac{x-y}{1+xy}>0$ , only in two following cases Case $1$ : $x>y$ and $xy>-1$ In this case, L.H.S= $\tan^{-1}x-\tan^{-1}y$ will be positive as $\tan^{-1}$ is increasing function but R.H.S= $-\pi+\tan^{-1}\dfrac{x-y}{1+xy}$ is always negative because range of $\tan^{-1}$ is $\left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)$ . So we got contradiction in this case Case $2$ : $x<y$ and $xy<-1$ $\implies$ $x<0$ and $y>0$ (just determining the sign of $x$ and $y$ ) So in this case this branch looks perfectly valid. Let's take a look at third branch $\dfrac{x-y}{1+xy}<0$ , only in two following cases Case $1$ : $x<y$ and $xy>-1$ In this case, L.H.S= $\tan^{-1}x-\tan^{-1}y$ will be negative as $\tan^{-1}$ is increasing function but R.H.S= $-\pi+\tan^{-1}\dfrac{x-y}{1+xy}$ is always positive because range of $\tan^{-1}$ is $\left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)$ . So we got contradiction in this case Case $2$ : $x>y$ and $xy<-1$ $\implies$ $y<0$ and $x>0$ (just determining the sign of $x$ and $y$ ) So in this case this branch looks perfectly valid. Let's take a look at second branch This branch looks perfectly valid for all cases, but let's see if is it actually? Case $1$ : $x>0,y>0$ , $x>y$ L.H.S is positive and R.H.S is also positive, perfectly valid. Case $2$ : $x>0,y>0$ , $x<y$ L.H.S is negative and R.H.S is also negative, perfectly valid. Case $3$ : $x<0,y<0$ , $x>y$ L.H.S is positive and R.H.S is also positive, perfectly valid. Case $4$ : $x<0,y<0$ , $x<y$ L.H.S is negative and R.H.S is also negative, perfectly valid. Case $5$ : $x>0,y<0$ , $xy>-1$ and $xy<0$ L.H.S is positive and R.H.S is also positive, perfectly valid. Case $5$ : $x>0,y<0$ , $xy<-1$ L.H.S is positive and R.H.S is negative, got contradiction. Case $7$ : $x<0,y>0$ , $xy<-1$ L.H.S is negative and R.H.S is positive, got contradiction. Case $8$ : $x<0,y>0$ , $xy>-1$ and $xy<0$ L.H.S is negative and R.H.S is negative, perfectly valid. So finally we can write $$\tan^{-1}x-\tan^{-1}y=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy}, &x<0 \text{ and } y>0 \text { and } xy<-1\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & x>0 \text{ and } y<0 \text { and } xy<-1\\
   \tan^{-1}\dfrac{x-y}{1+xy},& \text{ otherwise }
  \end{cases}$$ One can also derive $\tan^{-1}x+\tan^{-1}y$ by the above formula $$\tan^{-1} x+\tan^{-1} (-y)=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x-y}{1+xy}, &x<0 \text{ and } y>0 \text { and } xy<-1\\
    \pi+\tan^{-1}\dfrac{x-y}{1+xy}, & x>0 \text{ and } y<0 \text { and } xy<-1\\
   \tan^{-1}\dfrac{x-y}{1+xy},& \text{ otherwise }
  \end{cases}$$ Replace $y$ by $-y$ $$\tan^{-1} x+\tan^{-1} (y)=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x+y}{1-xy}, &x<0 \text{ and } -y>0 \text { and } -xy<-1\\
    \pi+\tan^{-1}\dfrac{x+y}{1-xy}, & x>0 \text{ and } -y<0 \text { and } -xy<-1\\
   \tan^{-1}\dfrac{x+y}{1-xy},& \text{ otherwise }
  \end{cases}$$ $$\tan^{-1} x+\tan^{-1} (y)=\begin{cases}
    -\pi+\tan^{-1}\dfrac{x+y}{1-xy}, &x<0 \text{ and } y<0 \text { and } xy>1\\
    \pi+\tan^{-1}\dfrac{x+y}{1-xy}, & x>0 \text{ and } y>0 \text { and } xy>1\\
   \tan^{-1}\dfrac{x+y}{1-xy},& \text{ otherwise }
  \end{cases}$$",['trigonometry']
3493813,"Happy New Year! Suppose $H''(r)-aH'(r)=0$ and $H'(0)=\frac{1}{p^2}$. Find the ""special solution"" for $H'(0)=\frac{H'(0)}{a}\cdot(1+\frac{N}{Y}e^w)$. [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Suppose that $H''(r)-aH'(r)=0$ , $H'(0)=\frac{1}{p^2}$ . Find the ""special solution"" for $$H(0)=\dfrac{H'(0)}{a}\cdot(1+\frac{N}{Y}e^w)$$ Solution: Since $$\lambda^2-a\lambda=0\text{ has roots }\lambda=0 \text{ and }\lambda=a $$ We have: $$H(r)=C_0+C_1e^{ar},\text{ where $C_0,C_1$ =const.} \\H(0)=C_0+C_1,~~H'(0)=aC_1$$ We have: $$C_1=\frac{1}{ap^2},~ C_0=H(0)-C_1=\frac{1}{ap^2}\cdot\frac{N}{Y}e^w$$ Hence, $$H=\frac{1}{ap^2}\cdot\frac{N}{Y}e^w+\frac{1}{ap^2}e^{ar}$$ We deduce that: $$Hap^2Y=Ne^w+Ye^{ar}$$ $$\bf{\text{Happy New Year!!!}}$$","['recreational-mathematics', 'ordinary-differential-equations']"
3493816,Book for Group cohomology for CS student,"I am graduate student who did his B.Tech in Computer science and Engineering but I have completed my Ph.D in Algorithms for group theory. I have fair knowledge of algorithms related to groups. I have to read Group cohomology as it is needed for solving various problems of group theory efficiently. I am interested in the computational part only. Kindly suggest me a book to study Group cohomology. I have fair idea of Group theory(commutative algebra to some extent), Graph theory, Linear Algebra, Probability,Combinatorics etc.","['group-theory', 'group-cohomology', 'reference-request']"
3493836,That $(\sin x)(\arcsin x)\approx x^2$ for small $x$ is clear from the Maclaurin series. Is there an intuitive explanation?,"I know it may sound trivial, but if you look at the graph of $(\sin x)(\arcsin x)$ , it's very similar to that of $x^2$ upto a certain point. Now this is because, when multiplying the Maclaurin expansions of $\sin x$ and $\arcsin x$ , after $x^2$ , the coeffecient of $x^4$ is $0$ , and the next few terms are small, starting with $\frac{x^6}{18}$ . Is there some intuition, possibly related to circles or the nature of the sine function? Or is it just a mathematical coincidence?","['calculus', 'trigonometry']"
3493871,A collection of sets that cover all edges in Kn?,"The problem is the following: Let $\mathcal{F}$ be a family of distinct proper subsets of {1,2,...,n}. Suppose that for every $1\leq i\neq j\leq n$ there is a unique member of $\mathcal{F}$ that contains both $i$ and $j$ . Prove that $\mathcal{F}$ has at least $n$ elements. I realized that each member $A_i$ in $\mathcal{F}$ can be regarded as a collection of edges in a clique induced by the element in $A_i$ , and at the end all the members in $\mathcal{F}$ exactly cover all the edges in $K_n$ and every edge must live in exactly one member in $\mathcal{F}$ . So if we write $\mathcal{F}=\{A_1,...,A_m\}$ with sizes $a_1,...,a_m$ , respectively, then we obtain the following equation: $a_1\choose 2$ +...+ $a_m\choose 2$ = $n\choose 2$ = $\frac{n(n-1)}{2}$ . I got stuck from here. Even if I assumed $m<n$ , I cannot obtain a contradiction. Is my approach correct at all? If so, how should I continue? I appreciate any help and insights.","['graph-theory', 'algebraic-combinatorics', 'combinatorics', 'combinatorial-proofs']"
3493907,Rank-$1$ update of inverse of a matrix transpose-matrix product,"I have a problem, I have access to a matrix $G = (A^t A)^{-1}$ , but I want to compute a second matrix $\bar{G} = (\bar{A}^t \bar{A})^{-1}$ , where $\bar{A} = A + b c^t$ is a rank one update of matrix $A$ . I was wondering if there exist a formula to easily obtain the second matrix from the first? I already know the Sherman-Morrison formula, I tried to use it by developing $\bar{G}$ into $ (A^t A + c b^t A + A^t b c^t + c b^t b c^t)^{-1}$ and recursively update it, but the result is too complicated. Thank you in advance.","['matrices', 'linear-algebra', 'inverse']"
3493920,"$G$ is torsionfree group and any $x,y \in G$ satisfy $(xy)^n=x^ny^n$, show $G$ is abelian.","Let $G$ be a torsionfree group and there exists $n\in\mathbb{N}$ such that for any $x,y \in G$ satisfy $(xy)^n=x^ny^n$ . Show that $G$ is abelian. (The question does not restrict $n$ but as Brian Moehring commented: For the question to make sense we probably need to assume $n>1$ ) The question appeared in last year Israel Mathematics Olympiad for undergrads and I'm trying to solve it because I'm taking course on algebraic structures right now. Previously, at the beginning of our course in one of our exercises we had to prove a (somewhat) similar theorem: Let $G$ be a group. We say $G$ has the property $\Phi_n$ if for any $x,y \in G$ we have $(xy)^n=x^ny^n$ . Show that if $G$ has $\Phi_n,\Phi_{n+1},\Phi_{n+2}$ then $G$ is abelian. A similar question was asked and answered here previously in In a group, does $(xy)^n=x^ny^n$ for $n\geq 3$ imply $xy=yx$? . I wanted to follow in a similar way, that is- derive some identities. These are the couple I was able to come up with: $$(xy)^n=x^ny^n\Longrightarrow x^{-1}(xy)^ny^{-1}=x^{n-1}y^{n-1}\Longrightarrow (yx)^{n-1}=x^{n-1}y^{n-1}$$ And notice that $$(x^ny^n)^n=x^{n^{n}}y^{n^{n}}=x^{n^{2}}y^{n^{2}}$$ So in a similar fashion  we can get $$x^{n^{2}-1}y^{n^{2}-1}=(xy)^{n^{2}-1}$$ (and I also tried to decompose it back to $n^2-1=(n-1)(n+1)$ and then use the power of $n-1$ but didn't get far) I figured since we know the group is torsionfree I need to find something to the power of $n$ that equals $e$ so that something must be $e$ but couldn't find the right thing to define. I also thought I'll end up getting something along the lines of $e=xyx^{-1}y^{-1}$ and that made me think maybe I need to use the commutator somehow. Since we know that the quotient group $G/N$ is abelian if and only if $N$ contains the commutator subgroup of $G$ . If I could show the commutator is trivial and $N$ is trivial I'd get and abelian group I think? [ I might be wrong about this! feel free to correct me! ]. Anyhow. I didn't get far with this approach either! Thank you very much for any help!","['contest-math', 'group-theory', 'abstract-algebra', 'abelian-groups']"
3493937,Generalization of alternative coin flipping problem,"Two players $A$ and $B$ are flipping a fair coin alternatively, with $A$ starting first. 
  The first player to obtain head wins the game. Then the probability that $A$ wins this game is $\frac{2}{3}.$ The answer above can be obtained easily by using recursion: Let $p$ be the probability that $A$ wins. Then $$p = \frac{1}{2} +\frac{1}{2}(1-p).$$ Solving the equation above leads to $p = \frac{2}{3}.$ Another extended question: The same setting as above. The game ends if there is a head followed by a tail and the player who obtains tail wins the game. Then the probability that $A$ wins the game is $\frac{4}{9}.$ The answer above can be obtained in this post . I notice that the answer to the second question is just a square of the first question. 
I wonder whether there is a generalization. 
More precisely, Fixed a natural number $n.$ Two players $A$ and $B$ flip a fair coin alternatively, with $A$ starting first. The game ends if there exists a subsequence $HTHT...HT$ with length $n$ and the player who obtains the last toss in the subsequence wins the game. What is the probability that $A$ wins? Note that if $n$ is odd, then the last toss is $H$ and $n$ is even, the last toss is $T$ .","['discrete-mathematics', 'markov-chains', 'combinatorics', 'probability']"
3493952,"Given a natural number $n$ and define $B_n$ as the set of all sequence $b_1, b_2, \dots, b_n$ of length $n$...","Given a natural number $n$ and define $B_n$ as the set of all sequences $b_1, b_2, \dots, b_n$ of length $n$ such that $b_1 = 1$ and for every $i = 1, 2, \dots, n-1$ , then we have $$ b_{i+1} - b_i \in \{ 1 , -1, -3, -5, -7, \dots \} $$ Where $b_i > 0$ for all $i$ .
  Find a closed form of $|B_n|$ . We can easly see (say by induction) that $b_n\leq n$ for all $n$ . So if we say $[e_2,e_4,...,e_{2n}]$ are all possible outcomes for $b_{2n}$ to be $2,4,...2n$ and $(o_1,o_3,...,o_{2n-1})$ are all possible outcomes for $b_{2n-1}$ to be $1,3,...,2n-1$ then we have a following chain: $$(1)\to [1]\to (1,1)\to [2,1]\to (3,3,1)\to [7,4,1]\to$$ $$\to (12,12,5,1)\to [30,18,6,1]\to (55,55,25,7,1) \to...$$ so $|B_n|\in \{1,1,2,3,7,12,30,55,143,...\}$ , but no closed form. Any idea how to find it? Edit: So, writen number at a vertex $V$ is a number of paths (only going up or right) from red vertex to the vertex $V$ .","['contest-math', 'combinatorics', 'discrete-mathematics', 'generating-functions', 'sequences-and-series']"
3493970,"Show: $e^{y^2}-e^{x^2} \le e(y-x)(y+x)$ for $x,y \in [0,1], 0 \lt x \lt y$.","Let $x,y \in [0,1], 0 \lt x \lt y$ . Show: $e^{y^2}-e^{x^2} \le e(y-x)(y+x)$ . I tried to solve it with the mean value theorem: Let $f: [0,1] \rightarrow \mathbb{R}, \ f(x):=e^{x^2}$ , thus $f'(x)=2xe^{x^2}$ . By the mean value theorem, it holds that: $\exists \lambda \in (0,1): f(y)-f(x) = f'(\lambda)(y-x)$ . It follows: $$\begin{align} f(y)-f(x) &= e^{y^2}-e^{y^2} \\ &= f'(\lambda)(y-x) = (2\lambda e^{\lambda^2})(y-x) \\ &\le (2e)(y-x) \\ &= e(2y-2x) \\ &= e(\sqrt{2y}-\sqrt{2x})(\sqrt{2y}+\sqrt{2x}). \end{align}$$ I don't know how to go on from there on. I had the idea to split up $e(2y-2x)$ to $e(\sqrt{2y}-\sqrt{2x})(\sqrt{2y}+\sqrt{2x})$ so that I would maybe get to $e(y-x)(y+x)$ , but that didn't work out for me. Any help is appreciated.","['analysis', 'real-analysis', 'inequality', 'derivatives', 'exponential-function']"
3494024,"$\tan x>x+\frac {x^3}3$ for $x\in(0,\frac\pi2)$","$$\tan x>x+\frac {x^3}3~\text{ for }~x\in\left(0,\frac\pi2\right)$$ My solution: Both functions are monotone, increasing, equal at $x=0$ . If i could show that the derivative of the first is greater than then derivative of second function that would be it. Taking the derivatives: $$\frac1{\cos^2 x}>1+x^2$$ Applying the same reasoning on the derivatives  and taking their derivatives we get $$\frac{\tan x}{\cos^2 x}>x$$ Doing the same thing (it is possible to stop here if we use $\tan x>x$ ) $$\frac{1+\tan x\sin 2x}{\cos^4 x}>1$$ It is easy to see that last inequality is true therefore all previous are also true. Is my solution correct, i would be very disappointed if it weren't. Are there different ways to solve this ?","['inequality', 'derivatives', 'real-analysis']"
3494028,Are all balls the same weight?,"A few days ago this question was asked on puzzling.SE: There are 10 balls which come in two possible weights. Using a balance scale at most 3 times, determine whether all the balls are the same weight or not. The solution is not terribly satisfying, because there's no obvious way to generalize it.  Can it be generalized? Given N balls, how many weighings are required to determine if all balls are the same weight ?  Equivalently, for a given number of weighings, what's the maximum number of balls we can weigh?","['puzzle', 'combinatorics']"
3494036,How to understand quasi-inverse of a function f∘g∘f = f?,"Recently I was studying the quasi-inverse. Before I studied the quasi-inverse, I revisited the inverse and the left-right inverse. inverse function: Let $f : X → Y$ , $g : Y → X$ is inverse of $f$ , if only if, $f∘g = id_{Y}$ and $g∘f = id_{X}$ . It is easy to understand. right-inverse function: Let $f : X → Y$ , $g : Y → X$ is right-inverse of $f$ (or section of $f$ ), if only if , $f∘g = id_{Y}$ . It means that $f$ must be surjective and $g$ must be injective.
It is also very intuitive. Now I start to study quasi-inverse: One thing I have to explain here is that the ""quasi-inverse"" does not seem to be a precise terminology and I can't find any information about quasi-inverse in wikipedia or nlab. (I study it because the form of ""quasi-inverse"" appears in many branches of mathematics, e.g. in category theory, adjoint functors needs to satisfy triangular identity. Although they are completely different, they are similar in form) Here, I use the definition of quasi-inverse from https://planetmath.org/QuasiinverseOfAFunction Let f:X→Y be a function from sets X to Y. A quasi-inverse g of f is a
function g such that g:Z→X where ran⁡(f)⊆Z⊆Y, and f∘g∘f=f, where ∘ denotes functional composition operation. Note that ran⁡(f) is the range of f. In order to understand this formula intuitively, I drew the following diagram This formula seems to tell us that A function $g$ is a quasi-inverse of a function $f$ , if the restriction of $g$ to $ran(f)$ is the right-inverse of $f$ , i.e. $f ∘ g ∘ j_{ran(f)} = j_{ran(f)}$ Note: $j_{S}$ denote identity function on $S$ . My first question is, is this conclusion correct? i.e. $f ∘ g ∘ j_{ran(f)} = j_{ran(f)} \Leftrightarrow f∘g∘f=f $ If this conclusion is correct, how to prove it? It is easy to prove $\Rightarrow$ , but how to prove the opposite? If this conclusion is wrong, anyone can give me an example which satisfies $f∘g∘f=f$ but not satisfies $f ∘ g ∘ j_{ran(f)} = j_{ran(f)}$ ? I may have missed some key things... The second question is, if I have $f∘g∘f=f$ and $g∘f∘g=g$ , is there any interesting conclusion? e.g. it can be concluded that f and g are bijection? Very thanks. PS: The reference of https://planetmath.org/QuasiinverseOfAFunction mentioned a book ""Probabilistic Metric Spaces"". In this book, the author mentioned another definition of quasi-inverse, which is stronger than the two quasi-inverses here, but it is another topic.","['functional-equations', 'category-theory', 'functions', 'inverse', 'generalized-inverse']"
3494041,Proof verification (sets & logic),"Question: Let $f$ : $\mathbb{N} \rightarrow \mathbb{Z}$ be a function that is eventually zero. i.e: There exists some $N \in \mathbb{N}$ s.t $f(n)=0$ for all $n \geq \mathbb{N}$ . Prove that the set of such functions is countable. Proof: Define $g$ : $\mathbb{N} \rightarrow \mathbb{Z}$ s.t $$
g(i) = \left\{
        \begin{array}{ll}
            f(i) & \quad i \in \{0,1…N-1\} \\
            0 & \quad  , otherwise
        \end{array}
    \right.
$$ Let $B_n=\{h|h: \{0,1…N-1\}\rightarrow \mathbb{Z}$ }. Clearly, $B_n$ is equal to $N$ copies of $\mathbb{Z}$ . Hence, it's countable. Let $G=\{f|f: \mathbb{N}\rightarrow \mathbb{Z}\}$ is eventually zero}.
So, $G = \cup_{N=1}^{\infty} B_n$ . Countable union of countable sets is countable. So is $G$ . Is my approach correct?","['elementary-set-theory', 'solution-verification']"
3494116,"Express $\sin (2x)$ in the form $\dfrac{a\pi^2+b\pi + c}{d},$ where $a,b,c,d$ are integers","Let $0<x<\dfrac{\pi}{2}.$ If $x$ is such that $\cos\left(\dfrac{3}{2}\cos x\right) = \sin\left(\dfrac{3}{2}\sin x\right),$ then express $\sin\, (2x)$ in the form $\dfrac{a\pi^2+b\pi + c}{d},$ where $a,b,c,d$ are integers. Here are my proofs that $\sin \left(\dfrac{\pi}{2}-x\right)=\cos\left(x\right).$ First, angle addition says that $\sin\left( \dfrac{\pi}{2}-x\right)=\sin\dfrac{\pi}{2}\cos x-\sin x\cos\dfrac{\pi}{2}=(1)\cos x - \sin x (0) = \cos x.$ Second, a geometric proof. Consider a right triangle. We may assume WLOG that the hypotenuse is $1$ . If not, then multiply all sides by the multiplicative inverse of the hypotenuse so that it is (the triangle obtained is similar, so the angles are preserved). Let one of the acute angles be $\alpha$ . Then the side adjacent to that angle has length $\cos \alpha$ . Now consider the angle $\dfrac{\pi}{2} - \alpha$ . The side opposite to this angle has length $\cos \alpha$ . But since $\sin x = \dfrac{\text{opposite}}{\text{hypotenuse}}, \sin\left(\dfrac{\pi}{2} - \alpha\right)=\cos \alpha.$ Now, if $\alpha$ is not acute, we may add an integer multiple of $2\pi$ to $\alpha$ so that it is, without changing the value of $\sin \alpha$ since $\sin x$ is $2\pi$ periodic. Now, since $0<x < \dfrac{\pi}{2}, \sin x,\cos x \in (0, 1)\Rightarrow \dfrac{3}{2}\sin x, \dfrac{3}{2}\cos x \in (0,\dfrac{3}{2})\subseteq (0,\dfrac{\pi}{2})$ . So, using this fact, we have that $\cos \left(\dfrac{3}{2}\cos x\right)=\sin \left(\dfrac{3}{2}\sin x\right)\Leftrightarrow\dfrac{3}{2}\cos x+\dfrac{3}{2}\sin x = \dfrac{\pi}{2}.$ Using the fact that $\sin x = \sqrt{1-\cos ^2 x},$ I get that $\sin x = \dfrac{\frac{2\pi}{3}\pm \frac{2}{3}\sqrt{18-\pi^2}}{4},$ but I'm not sure how to use this to get $\sin \,(2x)$ into the desired form.","['calculus', 'trigonometry']"
3494153,Artin conjecture for soluble extensions,"Towards the end of ch. VII §10 of Neukirch's Algebraische Zahlentheorie , he proves that the Artin $L$ -series of Abelian extensions coincide with Hecke $L$ -series, thereby proving Artin's conjecture for Abelian extensions. He then mentions in passing that this also settles the Artin conjecture for all soluble extensions. I have been trying to convince myself why this is the case. Let $E/K$ be a soluble extension of algebraic number fields, and let $G':=\textrm{Gal}(E/K)$ . Then there exists a subgroup $N \vartriangleleft G'$ such that $G:=G'/N$ is Abelian. Let $M$ be the subfield fixed by $N$ . Then we have $G \cong \textrm{Gal}(M/K)$ , and for any non-trivial simple character $\chi$ of $G$ , we have, by inflation: $$L(E/K,\chi',s) = L(M/K,\chi,s)$$ $\chi ' = \chi \circ \pi$ , where $\pi:G' \to G \cong G'/N$ is the canonical projection. As $M/K$ is an Abelian extension, this proves that $L(E/K,\chi',s)$ is holomorphic on $\mathbb{C}$ . The problem is that not every simple character of $\textrm{Gal}(E/K)$ can be expressed as $\chi \circ \pi$ , where $\chi$ is a simple character of $\textrm{Gal}(M/K)$ . So why does this prove the Artin conjecture for soluble groups? Thank you for your attention. $\textbf{Addendum:}$ I thought I had a solution. I include it here, as it might contain some useful idea. I begin by listing three properties, the third of which is not true: 1) The ""converse of inflation"" (deflation?) mentioned here : If $G:=\textrm{Gal}(E/K)$ and $\chi$ is a simple character of $G$ , then $L(E/K,\chi,s) = L(E_{\chi}/K,\chi',s)$ , where $\chi': G/\textrm{Ker}(\chi) \cong \textrm{Gal}(E_{\chi}/K) \to \mathbb{C}^{\times}$ is a faithful simple character given by $\chi'(g\ \textrm{Ker}(\chi)):=\chi(g)$ . 2) That every normal subgroup $N \vartriangleleft G$ can be expressed as the kernel of some simple character of $G$ . 3) The quotient of a soluble group by a normal subgroup is always Abelian (NB: This is not true. Take $\textit{e.g.}$ $S_4/(C_2 \times C_2) \cong S_3$ ). We then have that as $G$ is soluble, there exists a simple character $\chi$ of $G$ , so that $G/\textrm{Ker}(\chi)$ is Abelian, and by the above $$
L(E/K,\chi,s) = L(E_{\chi}/K,\chi',s)
$$ is entire. My next idea was to replace the erroneous property 3) with the fact that the quotient of a soluble group by a normal subgroup is a soluble group, and then apply the process iteratively, but this does not seem to work. $\textbf{Addendum II:}$ I have still not found a solution and hence add a bounty. $\textbf{Addendum III:}$ I think I have a solution. Correct me if I am wrong. I think the answer is just to keep ""quotienting"". By 1) above, for any character $\chi$ of $\textrm{Gal}(E/K)$ ,  we get a simple character $\chi'$ of $\textrm{Gal}(E'/K)$ and $L(E/K,\chi,s) = L(E'/K,\chi',s)$ , where $E'$ is the subfield fixed by $\textrm{Ker}(\chi)$ . Applying this again w.r.t. the group $\textrm{Gal}(E'/K)/\textrm{Ker}(\chi') = \textrm{Gal}(E''/K)$ , we get a simple character $\chi''$ , and $L(E/K,\chi,s) = L(E'/K,\chi',s) = L(E''/K,\chi'',s)$ , where $E''$ is the subfield of $E'$ fixed by $\textrm{Ker}(\chi')$ . Applying this iteratively, we find that $L(E/K,\chi,s) = L(E^{(n)}/K,\chi^{(n)},s)$ , where $E^{(n)}/K$ is an Abelian extension for some $n \in \mathbb{N}$ . Note that this process must terminate after a finite number of iterations, as the groups in question are finite - by ""terminate"", I mean that eventually the resulting quotient group is Abelian. $\textbf{Addendum IV:}$ The above is not a solution. See the comment by Lukas Heger below. $\textbf{Addendum V:}$ Would the Artin conjecture for all soluble extensions not trivially imply the proofs of Langlands and Tunnell of the Artin conjecture for tetra- and octahedral representations? What I mean is the following: What they proved is that if $(V,\rho)$ is a degree 2 representation of a finite group $G$ and $\rho(G)/Z(\rho(G))$ is isomorphic to either $A_4$ or $S_4$ , then the corresponding Artin $L$ -series is entire. But we know that if $G/Z(G)$ is soluble, then so is $G$ . And $A_4$ and $S_4$ are soluble groups! On the other hand, $\rho(G)$ soluble does not necessarily imply that $G$ is soluble, so I suppose the work of Langlands and Tunnell is only non-trivial for degree 2 representations of insoluble extensions whose images in the projective general linear group are isomorphic to either $A_4$ or $S_4$ . In particular, these representations must be unfaithful. This is of course assuming that we have a proof of the Artin conjecture for all soluble extensions. I should also add that when I wrote $\textrm{Ker}(\chi)$ above, I meant $\textrm{Ker}(\rho)$ , where $(V,\rho)$ is the representations corresponding to the character $\chi$ . I realise this is poor notation, but hopefully unambiguous. $\textbf{Addendum VI:}$ The same is true for unfaithful representations! We assume the Artin conjecture for soluble extensions. Let $G$ be insoluble and $(V,\rho)$ an unfaithful representation of $G$ so that $\rho(G)$ is soluble. Let $E_{\rho}$ be the subfield fixed by the kernel of $\rho$ . We then have $\rho(G) \cong G/\textrm{Ker}(\rho) \cong \textrm{Gal}(E_{\rho}/K)$ , and: $$ L(E/K,\rho,s) = L(E_{\rho}/K,\rho',s) $$ where $\rho' = \rho \circ \pi$ . As the RHS is an $L$ -series of a soluble extension, it is entire by our assumption. Thus the Artin conjecture for all soluble extensions does indeed imply the proofs of Langlands and Tunnell. My conclusion: Neukirch was mistaken, and proving the Artin conjecture for all soluble extensions is not as simple as he seems to have imagined. It seems that the Artin conjecture for soluble extensions is in fact an open problem. Addendum VII: I should add that the credit for discovering the falseness of the above claim goes entirely to my friend and colleague O. Justinussen. If anyone is able to prove him wrong by providing an elementary proof of the Artin conjecture for all soluble extensions, please let me know.","['algebraic-number-theory', 'representation-theory', 'galois-theory', 'abstract-algebra', 'group-theory']"
3494169,"Integral $\int_0^e \left(\operatorname{W}(x)^{2}x-\frac{6x}{8}-\frac{3\operatorname{W}(x)}{8}+\frac{3}{8}\right)\,dx=0$","Hi I was playing with the Lambert function when I wondering myself about that : Prove that  : $$\int_0^e \left(\operatorname{W}(x)^2 x-\frac{6x}{8}-\frac{3\operatorname{W}(x)}{8}+\frac{3}{8} \right) \, dx=0$$ My try It's straightforward if we have : \begin{align}
& \int \left(\operatorname{W}(x)^2 x-\frac{6x}{8}-\frac{3\operatorname{W}(x)}{8}+\frac{3}{8} \right) \, dx \\[8pt]
= {} & \frac{(x (\operatorname{W}(x) - 1) (4 x \operatorname{W}(x)^3 - 3 \operatorname{W}(x)^2 + 3 (x + 1) \operatorname{W}(x) - 3 x))}{(8 \operatorname{W}(x)^2)} \\
& {} + \text{constant}
\end{align} And after using the fundamental theorem of calculus. My question How to prove it using others method? Thanks in advance for your time.","['integration', 'alternative-proof', 'lambert-w', 'real-analysis']"
3494172,The squares of skew-symmetric matrices span all symmetric matrices,"This is a self-answered question. I post this here, since it wasn't obvious for me at first, and I think it might be helpful for someone at some future time (maybe even future me...). Claim: Let $n \ge 3$ , and let $X$ be the set of all squares of real $n \times n$ skew-symmetric matrices. Then $\text{span}(X)$ is the space of all symmetric matrices. How to prove this claim?","['matrices', 'skew-symmetric-matrices', 'linear-algebra', 'symmetric-matrices']"
3494232,Curious convergence domain for $x_n$ defined by $(a_1 n+ b_1) x_{n+2} = (a_2 n + b_2) x_{n+1} - (a_3 n + b_3) x_n$,"What are the conditions on $a_1, b_1, a_2, b_2, a_3, b_3$ and on the initial values $x_1, x_2$ for $x_n$ to converge to a value different from zero? We can assume that $a_1=1$ . Also we need $a_1 = a_2 - a_3$ and $b_1 = b_2 - b_3$ , but this is not enough to guarantee convergence. We can even assume that $x_1=0, x_2 = 1$ , see detailed discussion on these recurrences in my previous question, here . In short, there is only 3 free parameters, characterizing all the recurrences that do converge. As a starting point, see the chart below for $$2(n+2)x_{n+2}=(r (n+2) + s)x_{n+1} + ((2-r)(n+2)-s)x_n$$ with $x_0=0, x_1=1$ . This 2-dimensional plot represents one slice of all the possible 3-dimensional parameter representations leading to divergence. The X-axis represents $r$ , the Y-axis represents $s$ . I tried with 400,000 values of $(r, s)$ to check which ones result in actual convergence. The blue dots represent the points $(r,s)$ such that $|x_{40} - x_{39}|<0.000001$ . The blue area is full of holes because I only used 400,000 values of $(r, s)$ in this experiment. If you use 10,000,000 values, the boundaries will be smoother, and the holes in the blue area will vanish. These recurrences can be represented by generalized hypergeometric functions , and according to Wikipedia, the convergence status is typically studied separately for each recurrence. Yet my chart suggests that there is a general law governing the convergence (or lack of) for these recurrences. It is an interesting math problem, and also of interest to statisticians who are interested in estimating the boundaries (in the parameter space) of the convergence region, and test whether the boundaries are parallel lines. More cases Here we look at the general case, which can be written as: $$2(n+q)x_{n+2}=(r (n+q) + s)x_{n+1} + ((2-r)(n+q)-s)x_n$$ The charts below give some insights about the shape of the convergence regions / boundaries in the full 3-dimensional parameter space. Case $q=1$ : Case $q=5$ : Time permitting, I will try to create a 3-D picture of the boundary, maybe a rotating one so that it can be viewed under different angles.","['recurrence-relations', 'calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
3494247,Find $\lim\limits_{t \to 0} \int\limits_{2^t}^{3^t} \frac{x}{\ln x} dx$.,"I have the following limit to find: $$\lim_{t \to 0} \int _{2^t} ^ {3^t} \dfrac{x}{\ln x} dx$$ This wouldn't be a problem if instead of the given fraction, we would have $\dfrac{\ln x}{x}$ since then I could a substitution like $t = \ln x$ , but it looks like that doesn't work here. Most of the limit-integrals that I worked with were solved with the Squeeze Theorem, but I don't see any boundaries that I could use here.","['integration', 'limits', 'calculus']"
