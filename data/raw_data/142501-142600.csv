question_id,title,body,tags
2311541,Why can bases of number systems not be rational numbers?,"This is a question that keeps bothering me: much of mathematics was created by extending rules to new domains e.g. negative numbers were created by consistently extending arithmetic beyond positive integers. However, with number bases it seems impossible to do this. Number bases are integers, but could they be rational numbers? I've had previous discussions about this, see here . One problem can be seen with this example: in base 2.5, 0.22 is greater than one. That's not what we want! What, if anything, can be done about this? EDIT: To put it another way - if every positional number is less than any digit to its left, why doesn't this apply to fractional base positional numbers?","['number-theory', 'decimal-expansion', 'elementary-number-theory']"
2311583,"Evaluating $\int_0^1 \sqrt{1 + x ^4 } \, d x $","$$
\int_{0}^{1}\sqrt{\,1 + x^{4}\,}\,\,\mathrm{d}x
$$ I used substitution of tanx=z but it was not fruitful. Then i used $ (x-1/x)= z$ and
$(x)^2-1/(x)^2=z $ but no helpful expression was derived.
I also used property $\int_0^a f(a-x)=\int_0^a f(x) $
Please help me out",['calculus']
2311652,I'm trying to find the longest consecutive set of composite numbers,"Hello and I'm quite new to Math SE. I am trying to find the largest consecutive sequence of composite numbers. The largest I know is: $$90, 91, 92, 93, 94, 95, 96$$ I can't make this series any longer because $97$ is prime unfortunately. I can however, see a certain relation, if suppose we take the numbers like (let $a_1, a_2, a_3,...,a_n$denote digits and not multiplication): $$a_1a_2a_3...a_n1,\ a_1a_2a_3...a_n2,\ a_1a_2a_3...a_n3,\ a_1a_2a_3...a_n4,\ a_1a_2a_3...a_n5,\ a_1a_2a_3...a_n6,\ a_1a_2a_3...a_n7,\ a_1a_2a_3...a_n8,\ a_1a_2a_3...a_n9,\ a_1a_2a_3...(a_n+1)0$$ The entire list of consecutive natural numbers I showed above can be made composite if: The number formed by digits $a_1a_2a_3...a_n$ should be a multiple of 3 The numbers $a_1a_2a_3...a_n1$ and $a_1a_2a_3...a_n7$ should be composite numbers If I didn't clearly convey what I'm trying to say, I mean like, say I want the two numbers (eg: ($121$, $127$) or ($151$, $157$) or ($181$, $187$)) to be both composite . I'm still quite not equipped with enough knowledge to identify if a random large number is prime or not, so I believe you guys at Math SE can help me out.","['prime-numbers', 'sequences-and-series', 'elementary-number-theory']"
2311659,Function of exponential order whose derivative is not,"I am looking for a function of exponential order(i.e. bounded in absolute value by $Me^{ct}$ for some $M, c$) whose derivative is not of exponential order. My thought was to look for functions which oscillate wildly between + and - in continually decreasing ""periods,"" but I'm having trouble finding specific functions. Any help is appreciated.","['exponential-function', 'functions']"
2311673,Two properties of surface integrals.,"Let $\Omega$ be a bounded open set in $\mathbb{R}^n$ with $C^1$ boundary. I know the following (possible) definition for $$\int_{\partial\Omega}u\,d\sigma.$$
For each $x_0\in\partial\Omega$, there exist an open subset $U$ in $\mathbb{R}^n$ containing $x_0$, an open subset $A$ in $\mathbb{R}^{n-1}$ and a $C^1$ function $g:A\rightarrow\mathbb{R}$ such that its graph is $G_g=\partial\Omega\cap U$. By compactness of $\partial\Omega$, we can write $\partial\Omega=\cup_{j=1}^N U_j$, where each $U_j$ is open in $\mathbb{R}^n$, and $\partial\Omega\cap U_j=G_{g_j}$, where $g_j:A_j\rightarrow\mathbb{R}$ is $C^1$. Take a partition of unity $\{\eta_j\}_{j=1}^N$ corresponding to $\{U_j\}_{j=1}^N$: $\eta_j\in C_c^{\infty}(U_j)$, $0\leq\eta_j\leq 1$ and $\sum_{j=1}^N\eta_j=1$ on $\partial \Omega$. Let $u:\partial\Omega\rightarrow\mathbb{R}$ measurable. Define $u_j=u\,\eta_j$, which has support in $U_j$. Then:
$$\int_{\partial\Omega}u\,d\sigma=\sum_{j=1}^N\int_{A_j}u_j(x',g_j(x'))\sqrt{1+|\nabla g_j(x')|^2}\,dx'$$(whenever the right-hand side exists). My two doubts are the following: Given a subset $\Gamma$ of $\partial\Omega$, in what sense it is understood $\int_\Gamma u\,d\sigma$? Is it true that $$\int_{\partial\Omega}u\,1_\Gamma\,d\sigma=\int_\Gamma u\,d\sigma\,?$$
($1_\Gamma$ is the characteristic function on $\Gamma$). If $u_m\rightarrow u$ in $L^p(\partial\Omega)$, is it true that there exists a subsequence $u_{m_k}$ that converges pointwise almost everywhere on $\partial\Omega$?","['surface-integrals', 'lebesgue-integral', 'differential-geometry', 'vector-analysis']"
2311680,Show that a normed space is not separable,"Question: Let $B[0,1]$ be the normed space of bounded real-valued functions on $[0,1]$ with the norm $\|f\| =\sup\left\{\left|f(x)\right| : x\in [0,1]\right\}$. Is this metric space separable? My problem is that I have no real intuition about this metric space. I have a solution for the problem that uses the ""characteristic equation"" but do not know how I would come up with this solution. Any insight as well as different solutions would be appreciated. The characteristic equation is $\mathcal{X}_x(s) = 1$ if $s=x$ , $0$ otherwise Sorry, I'm not sure how to do a piecewise function.","['general-topology', 'metric-spaces', 'separable-spaces']"
2311687,"Is this series diverging? If not, what's the sum?","The series in question: $$\frac{5}{7^2+11^2} + \frac{9}{11^2+15^2} + \frac{13}{15^2+19^2} + \dots$$ Or in a concise form: $$\sum_{i=1}^\infty {\frac{4i+1}{(4i+3)^2+(4i+7)^2}}$$ I tried to solve, and find a closed form of the above summation but got no luck. The denominator could not be factorised and decomposed and I couldn't transform the series into a telescopic one to solve it either. I asked this to my maths professor and he looked at the series in question for a while, and declared it as a diverging one, so it can't be solved. He looked unsure. Was he right? Is it a divergent series? If not, how can I solve it, if I can? Thanks!","['summation', 'divergent-series', 'sequences-and-series']"
2311692,How many infinite subsets does $\mathbb N$ have?,"I attempted to write a derivation of the answer, but was told my mathematics was wrong; please correct me. The cardinality of $\mathbb N$ is $\aleph_0$. From this set, we can generate another infinite subset by excluding $1$ element. There are $\aleph_0$ such possible subsets that can be generated like this. We can generate an infinite subset by excluding $2$ elements from $\mathbb N$. There are $\aleph_0 \choose 2$ possible subsets that can be generated like this. In general, for any $i$ from $0$ to $\aleph_0$ we can generate $\aleph_0 \choose i$ such possible subsets by excluding $i$. To find the total number of possible subsets, we simply sum all the combinations. $$\sum_{i = 0}^{n} {n \choose i} = 2^n$$ Based on the above:
$$\sum_{i = 0}^{\aleph_0} {\aleph_0 \choose i} = 2^{\aleph_0}$$ $2^{\aleph_0} = \aleph_1$ $\therefore$  the number of infinite subsets of $\mathbb N$ is $\aleph_1$. I realise that I excluded the number of infinite subsets who have infinite complements. To account for this, merely combine any $k$ $i$ used in the selection above, and exclude all multiples of the products of $i_1*i_2*i_3*...*i_k$. We have $\aleph_0$ such sets of $i$ with numbers increasing from $0$ to $\aleph_o$. I didn't consider this when I first wrote it out, and only realised it after. I haven't yet updated my proof to include it. However, this wasn't the problem with my proof; I was told I did ""bad mathematics"".",['elementary-set-theory']
2311725,Why the denseness of norm attaining operator is important?,"I plan for studying norm attaining operators, Lindenstrauss property A and B, property $\alpha$, $\beta$, and so on... Before do it, I wanna understand why these properties are important. I know it starts from Bishop-Phelps theorem, but I don't know why the denseness of the set of norm attaining operators in the set of linear operator is important. What I want is something like: if we know the denseness, then we can characterize the original space by only considering norm attaining operators or something else. Any useful links or comments should be appreciated","['functional-analysis', 'banach-spaces', 'operator-theory']"
2311735,A closed form of $\sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)$?,"I'm curious about a possible closed form of the following series. $$
\sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right) \tag1
$$ One may observe that $(1)$ is absolutely convergent. One may notice that apparently one can't apply the same route that proved
$$
\sum_{n=1}^{\infty}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)=\frac12\ln^2 2. \tag2
$$","['integration', 'sequences-and-series', 'calculus', 'closed-form']"
2311736,Automorphisms of matrix rings,"I am trying to classify automorphisms of matrix rings.  I was surprised to be able to find little on the subject by searching (here or elsewhere) though this could be an indication of my poor searching skills rather than the lack of material. For the moment, I am looking at matrices over a field but I am trying to be as general as possible about the field: not necessarily $\mathbb{R}$ or $\mathbb{C}$ or even necessarily of characteristic $0$ . I am not sure whether it is standard but I am only interested in automorphisms which in a sense preserve the field.  More exactly, they should have this property: $$\phi(\lambda M) = \lambda\phi(M)$$ I am most interested in automorphisms due to the matrix structure rather than ones which are in a sense inherited from the field. One obvious class of automorphisms is those of the form: $$A \rightarrow P^{-1}AP$$ where $P$ is invertible. Now, I need to either find others or prove that all must have this form. After trying and failing for a while to prove that all must have this form, I started to look for counterexamples.  I found a partial one.  For $M_2(\mathbb{R})$ , the automorphism: $$
\left(\begin{matrix}
        x_{11} & x_{12} \\
        x_{21} & x_{22} \\
        \end{matrix}\right) 
\rightarrow
\left(\begin{matrix}
        x_{11} & -x_{12} \\
        -x_{21} & x_{22} \\
        \end{matrix}\right) 
$$ [This was originally mistyped giving the appearance that it was only defined for symmetric matrices.] cannot be expressed in this form but if I extend to $M_2(\mathbb{C})$ it can with $$ P = 
\left(\begin{matrix}
        i & 0 \\
        0 & -i \\
        \end{matrix}\right) 
$$ So, I may need to consider whether allowing extensions of the field would cover all automorphisms.  The question now becomes: are all automorphisms of this form if field extensions are allowed or can I find a counterexample to that. My attempts mostly involve considering possible images of simple matrices e.g. ones with a single entry of $1$ and otherwise $0$ . This is not homework, I am long past that.  It is an old man doing self-imposed brain exercise. Some hints rather than a complete answer would be appreciated since the purpose is to exercise my brain.","['matrices', 'ring-theory', 'field-theory']"
2311754,Tangent space of circle at a point,"I am trying to compute tangent space of $S^1=\{(x,y)\in \mathbb{R}^2: x^2+y^2=1\}$ at a point say $(1,0)=p$. As $S^1\subseteq \mathbb{R}^2$  we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ are elements of $T_pS^1$. As $S^1$ is one dimensional, we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ is a linearly dependent set when seen as elements of $T_pS^1$ i.e., for some $a,b\in \mathbb{R}$ we have $$a\frac{\partial}{\partial x}\bigg|_p+b\frac{\partial}{\partial y}\bigg|_p=0$$ as functions $C_p^{\infty}(S^1)\rightarrow \mathbb{R}$. For all $f\in C_p^{\infty}(S^1)$ we have $$a\frac{\partial f}{\partial x}\bigg|_p+b\frac{\partial f}{\partial y}\bigg|_p=0.$$ I have no idea how to proceed from here. Any reference which discuss this kind of examples are also welcome.","['tangent-bundle', 'differential-geometry']"
2311778,Matrix exponential using the Schur decomposition,"I have a Hermitian $m\times m$ matrix, say $A$. I can use Schur decomposition and transform the matrix in to $A=QTQ^{\dagger}$. Is it then possible to calculate straightforward the matrix exponential using $\exp[A]=Q\cdot\exp[-a T]\cdot Q^{\dagger}$, where $a>1$ is a scalar and $\dagger$ denotes the conjugate transpose of $Q$. Thanks for any suggestion.","['matrices', 'matrix-exponential', 'linear-algebra', 'schur-decomposition']"
2311795,Solving the limit: $\lim_{x\to0}\left[100\frac{\sin^{-1}(x)}{x}\right]+\left[100\frac{\tan^{-1}(x)}{x}\right]$,Find the value of the limit $$\lim_{x\to0}\left[100\frac{\sin^{-1}(x)}{x}\right]+\left[100\frac{\tan^{-1}(x)}{x}\right]$$ where $[\cdot]$ denotes the greatest integer function or the box function. My attempt: I am aware of the standard limits $$\lim_{x\to0}\left(\frac{\sin^{-1}(x)}{x} \right) = 1 $$ and $$\lim_{x\to0}\left(\frac{\tan^{-1}(x)}{x} \right) = 1 $$ but am not sure how will I apply the box function on this limit. Any detailed explanation to help me understand this concept will be appreciated.,"['limits-without-lhopital', 'limits']"
2311822,Equation $x = \tau(2^x - 1)$,"I want to find all integer solutions of the equation $x = \tau(2^x – 1)$, where $\tau(n)$ is the number of divisors of n. I know that 1, 2, 4, 6, 8, 16 and 32 are solutions, but I have no idea how to solve this equation in general. Any help will be appreciated.","['number-theory', 'divisor-counting-function', 'perfect-powers', 'diophantine-equations']"
2311831,Does $\mathrm{adj}(A)=\mathrm{adj}(B)$ imply $A=B$?,"If $A$ and $B$ are any two square matrices of same order and if $\mathrm{adj}(A)=\mathrm{adj}(B)$, does it imply $A=B$? I am pretty sure if $A$ and $B$ are invertible and if $A^{-1}=B^{-1}$, then $A=B$. So is it true for Adjoint?","['matrices', 'linear-algebra', 'determinant']"
2311848,"CDF of max($X$, $Y$) - where is the mistake?","$X$ and $Y$ are independent r.v.'s and we know $F_X(x)$ and $F_Y(y)$. Let $Z=max(X,Y)$. Find $F_Z(z)$. Here's my reasoning: $F_Z(z)=P(Z\leq z)=P(max(X,Y)\leq z)$. I claim that we have 2 cases here: 1) $max(X,Y)=X$. If $X<z$, we are guaranteed that $Y<z$, so $F_Z(z)=P(Z\leq z)=P(X<z)=F_X(z)$ 2) $max(X,Y)=Y$. Similarly, $F_Z(z)=P(Z\leq z)=P(Y<z)=F_Y(z)$ Since we're interested in either case #1 or #2, $F_Z(z)=F_X(z)+F_Y(z)-F_X(z)*F_Y(z)$ However, it's wrong and I know it. But I would like to know where the flaw in my reasoning is. I know the answer to this problem, I just want to know at what moment my reasoning fails.","['probability-theory', 'probability']"
2311872,Spanning Tree of a Simple Graph,"I've been studying this topic, but there are a few questions I cannot find the answers to. When must an edge of a connected simple graph be in every spanning tree for this graph? For which graphs do depth-first search and breadth-first search produce identical spanning trees no matter which vertex is selected as the root of the tree?","['graph-theory', 'trees', 'discrete-mathematics']"
2311917,Is a unary function a binary relation,"$f: X \rightarrow Y$ is a unary function, however writing it in relation notation, we would write it $xRy$, which would be binary relation. Is my assumption that a $n$-ary function, corresponds to a $(n+1)$-ary relation correct?","['relations', 'functions']"
2311936,Is $e$ a coincidence?,"$e$ has many definitions and properties. The one I'm most used to is $$\lim_{n\to \infty}\left(1+\frac{1}{n}\right)^n $$ If someone asked me (and I didn't know about $e$): Is there a constant $c$ such that the equation $\frac{d}{dx}c^x=c^x $ is true for all $x$? Then I'd likely answer that: I doubt it! That would be a crazy coincidence. I'm curious, is it a coincidence that there is a constant that makes this true?","['derivatives', 'exponential-function', 'limits']"
2311939,What’s the relation between local diagonalisation of Riemannian metrics and the eigenprojections for the representation matrix functions?,"Recently, the topic of smooth diagonalisation of Riemannian metrics came to my interest. Namely, I've read through this paper from Duke Math. J.
Volume 51, Number 2 (1984), 243-260 (unfortunately the document doesn't seem to be publicly available). In Theorem 4.2, they state and prove the following: Let $(M^3, g)$ be a three-dimensional $C^\infty$ Riemannian manifold. Then there is an atlas of $C^\infty$ coordinate charts for $M$ such that, in each chart, the metric is diagonal, i.e. $$d s^2 = \lambda_1(x, y, z) d x^2 + \lambda_2 (x, y, z) d y^2 + \lambda_3 (x, y, z) d z^2$$ They furthermore make a similar statement for the case $n = 2$ , namely that for two-manifolds, one has always coordinates in which the metric locally takes the form $$d s^2 = \lambda(x, y) (d x^2 + d y^2)$$ As someone for who Riemannian manifolds are a relatively fresh topic, I'm still confused by how one can understand and interpret this property of diagonalisation and how one can actually diagonalize in practice. First and foremost, I've been trying to wrap my head around the following: let's take a fixed point $p \in M$ and consider the metric $g_p$ at this point $p$ , and let $T(x)$ be it's representation as a matrix, where $x \in T_pM$ . From my understanding, the diagonalisation of $g_p$ would then be equipvalent to finding smooth eigenprojections for the representation matrix $T(x)$ . However, even for a smooth matrix function $T(x)$ , the eigenspaces and eigenprojections do not need to behave smoothly or even exist everywhere. I found the following example in this book by Kato, §5.3: Let $n = 2$ , and: $$T(x) = e^{- \frac 1{x^2}} \pmatrix{\cos \frac 2x & \sin \frac 2x \\ \sin \frac 2x & - \cos \frac 2x}, T(0) = 0$$ Then $T(x)$ is continuous and indefinitely differentiable for all real values of $x$ , and the eigenvalues of $T(x)$ which turn out to be $\pm e^{- \frac 1 {x^2}}$ (for $x \neq 0$ ) and $0$ (for $x = 0$ ) are continuous and indefinitely differentiable aswell. However, the eigenprojections for $x \neq 0$ in this case are: $$ \pmatrix{\cos^2 \frac 1x & \cos \frac 1x \sin \frac 1x \\ \cos \frac 1x \sin \frac 1x & \sin^2 \frac 1x}, \pmatrix{ \sin^2 \frac 1x & - \cos \frac 1x \sin \frac 1x \\ - \cos \frac 1x \sin \frac 1x & \cos^2 \frac 1x}$$ These matrix functions are continuous and indefinitely differentiable on any interval that doesn't contain $0$ , but they cannot be continued to $x = 0$ as continuous functions. Also, one can show that there doesn't exist any eigenvector of $T(x)$ that is continuous in the neighborhood of $x = 0$ and doesn't vanish in $x = 0$ . Sorry for this rather tedious example, but now my question is: Why is this not a contradiction to the diagonalisation? If according to Deturck and Yang all Riemannian metrics are locally diagonalizable for $n = 2, 3$ , then why are there matrix functions like these that are not smoothly diagonalizable? Do these metric diagonalisations not correspond to finding the respective eigenprojection functions of the local metrix representation, and if so, why not? Or if there something else that I'm missing? Any help would be much appreciated – maybe I'm just missing something very simple. I've been trying to wrap my head around this now for some days but without success.","['manifolds', 'riemannian-geometry', 'differential-geometry']"
2311941,Multiple integral related to zeta function,"I am trying to calculate the following integral
$$\int_V \frac{d^d\vec{r}}{e^{x_1+...+x_d}-1},$$
where $V=[0,\infty)^d$ and $\vec{r}=(x_1,...,x_d)$. I know that the result should be related to the Riemann zeta function, but I do not see how to do it quickly and elementary (i.e. without the knowledge of all possible relations for zeta function). Any sugestion or hint ?","['multivariable-calculus', 'special-functions', 'integration', 'riemann-zeta']"
2311957,Graph Coloring calculating Chromatic Polynomial,"Trying to figure out the required steps in order to calculate the Chromatic Polynomial for this graph. I'm not too good at this topic having just started it a few days ago, but for this graph is it possible to separate the graph into 2? So the top 3 triangles as one half, and the bottom 3 as the other half? Doing the first half I get: $T(G,k) = k(k-1)(k-2)^3$ But I'm not sure if it would work to get the answer, would I have to use the deletion formula to get the answer, and if so which line would I have to remove?","['graph-theory', 'coloring', 'discrete-mathematics']"
2311958,How to start reading topology?,I've recently completed my high school. I want to read topology. How should I begin and from where should I begin?,"['self-learning', 'general-topology', 'differential-topology']"
2311967,Show that if y satisfies $y''+y=\sin^{2017}{x}\cos x$ then $y$ is a periodic function.,"Show that if y satisfies $y''+y=\sin^{2017} x \cdot \cos x$ then $y$ is a periodic function. To deal with this problem, the first thing I do is solving $y''+y=0$. Then I get $y=c_1 \cos x +c_2 \sin x$, and I get stuck here. Any suggestion? Thanks in advance!","['periodic-functions', 'ordinary-differential-equations']"
2311988,Complex Analysis Book to follow Ahlfors.,"I have worked through Ahfors for an introduction to Complex Analysis. I am seeking advice on the books to read to learn more Complex Analysis. At this point, one name suggested to me has been Conway. My background includes Analysis at the US undergrad level -- analysis in euclidean spaces, point set topology, measure theory, basic functional analysis and differentiable manifolds.","['complex-analysis', 'reference-request', 'analysis']"
2312010,Calculate Integral using residue theorem,"I want to verify the following result using the residue theorem: $$\int_0^\infty \frac{\log(x)}{x^2+a^2}dx = \frac{\pi}{2a}\log a, \, a > 0.$$ Here are my ideas: At first I might want to show that this function is in fact a well defined improper Riemann integral, but I didn't come up with any nice solution yet. I want to integrate the function $f(z) := \frac{\log(z)}{z^2+a^2}$ along the contour $C:= \gamma_1 \cup \gamma_2 \cup \gamma_3 \cup \gamma_4$ constisting of to semicircles with center at 0 around the upper half plane and radius $R$ and $\epsilon$ (resp.) as well as the intervals $[-R, -\epsilon]$ and $[\epsilon, R]$. For the complex logarithm, use the branch $\log z = \log|z| + i\theta, \theta \in [-\pi/2, 3\pi/2)$ so we don't get any problems on the real line (is this choice correct?). Note that I have one pole in my contour, namely $z = ia$. The Residue theorem yields $$\int_C f(z) dz= 2\pi i \text{ Res}(f, ia) = 2\pi i\lim_{z\to ia}(z-ia) \frac{\log z}{(z-ia)(z+ia)} = 2\pi i\frac{\log(ia)}{2ia} = \pi \frac{\log(a)+ i\pi/2}{a}$$
Proceeding, we choose the following parametrizations: $$\gamma_1 : [-R,0]  \to \mathbb C, \quad t\mapsto -\frac{\epsilon t}{R} + (t-\epsilon) \\ \gamma_2 : [0, R] \to \mathbb C, \quad t\mapsto -\frac{\epsilon t}{R} + (\epsilon+t) \\ \gamma_3: [0, \pi]\to \mathbb C, \quad t\mapsto \epsilon e^{it} \\ \gamma_4:[0,\pi] \to \mathbb C, \quad t \mapsto Re^{it}$$
Now here's what I am unsure about. To show that the big and the small circle vanish as $R\to \infty$ and $\epsilon \to 0$ is not too hard, but how to deal with the other integrals?
Can I just say 
$$\int_{\gamma_1} f(z)dz = \int_0^R \frac{\log(-\frac{\epsilon}{R}t+\epsilon+t)}{(-\frac{\epsilon}{R}t + \epsilon + t)^2 + a^2}(\frac{\epsilon}{R}+1)dt \xrightarrow{\epsilon \to 0} \int_0^R \frac{\log t}{t^2 + a^2}dt$$ 
or what kind of reasoning should be used to interchange limit and integral?Also, I then finally I get $$\int_0^\infty \frac{\log(x)}{x^2+a^2}dx = \pi \frac{\log a + i\frac{\pi}{2}}{2a}$$
almost what I want, but where does $i\pi /2$ come from? Thanks in advance!","['complex-analysis', 'integration', 'residue-calculus', 'analysis']"
2312036,Determinant of the Jacobian of a short map,"Let $U\subset \mathbb{R}^2$ and $f:U\rightarrow \mathbb{R}^2$ be an everywhere differentiable short map (i.e. a Lipschitz function with upper Lipschitz constant =1, the upper Lipschitz constant is defined as $\sup\limits_{x\in U}\sup\limits_{v\in\mathbb{R}^2,||v||=1}||df_xv||$). Suppose that $f$ is also bi-Lipschitz and that its lower Lipschitz constant is equal to $c$, $0<c<1$ (the lower Lipschitz constant is defined as $\inf\limits_{x\in U}\inf\limits_{v\in\mathbb{R}^2,||v||=1}||df_xv||$). Let $|J_f(p)|$ be the determinant of the Jacobian of $f$ in $p\in U$. In this case I've read that it should be $|J_f(p)|\ge c$ for every $p\in U$, but I can't understand why. Can you explain it to me?","['jacobian', 'real-analysis', 'lipschitz-functions', 'analysis']"
2312038,How does one prove that $e$ exists?,"In my calculus class, $e$ was defined to be the number such that $\frac{d}{dx}e^x = e^x$. From the definition of the derivative, we have \begin{align*}
\frac{d}{dx}a^x &= \lim_{h \to 0} \frac{a^{x+h} - a^x}{h}\\
&= a^x \lim_{h \to 0} \frac{a^h - 1}{h}
\end{align*} Thus $e$ is the number such that $$
\lim_{h \to 0} \frac{e^h - 1}{h} = 1
$$ But how is it proven that there exists such number?","['real-analysis', 'calculus']"
2312079,$x^2+y^3 = z^4$ for positive integers,"How can I solve this diophatine equation : $$x^2+y^3=z^4$$
for $(x, y, z) \in \mathbb{Z}_{>0}$ I tried to look on wolfram alpha yet it seems like there aren't any solutions...","['number-theory', 'diophantine-equations']"
2312083,Is it true that $\Delta\cos(k\|x\|)=-k\left(k\cos(k\|x\|)+2\frac{\sin(k\|x\|)}{\|x\|}\right)$?,"As per the title: is it true that for $x\in\mathbb{R}^3$ and $k\in\mathbb{R}_{\ge 0}$, $$\Delta\cos(k\|x\|)=-k\left(k\cos(k\|x\|)+2\frac{\sin(k\|x\|)}{\|x\|}\right)\qquad(\star)$$ My own calculations yield that $$\begin{aligned}
\Delta\cos(k\|x\|)&=-k\nabla\left\{\sin(k\|x\|)\frac{x}{\|x\|}\right\}
\\
&=-k\left(k\cos(k\|x\|)\frac{x^2}{\|x\|^2}+\sin(k\|x\|)\frac{\|x\|+\frac{x^2}{\|x\|^3}}{\|x\|^2}\right)
\end{aligned}$$ which is not the same as $(\star)$. Note that $(\star)$ is the value that I am supposed to verify, as per a textbook I am following.","['derivatives', 'trigonometry', 'chain-rule', 'calculus']"
2312130,Proving an infinite series is differentiable,"I'm trying to prove that the following series is differentiable with respect to $x$ on any interval $[a,b]$ with $0<a<b$: $$f(x)=\sum_{n=1}^\infty \frac{e^{-nx}}{n}$$ What I've tried is applying the Term-wise Differentiability Theorem, where I need to show that the following three conditions hold: Each $f_n$ is differentiable on $[a,b]$ $\sum_{i=1}^n f_i'$ converges to $g$ uniformly on $[a,b]$ (This is where I really get stuck) $\sum_{i=1}^n f_i(x_0)$ converges for some $x_0$ on [a,b] I already get stuck on choosing $f_n$ and going on with step 1 and 2, and I don't know of any other way to show that the infinite series is differentiable with my current knowledge, so I hope someone could help me out.","['derivatives', 'real-analysis', 'sequences-and-series']"
2312138,Reciprocal of Expectation,"Let $X$ be a random variable. Is it ever true that $$E\left({\frac 1 X}\right) \stackrel{?}{=} \frac 1 {E(X)} \text{ ?}$$ I'll assume $X$ never takes on the value of $0$. I'll use the notation for discrete RV's, otherwise replace $\sum$ with $\int$. Let $f$ be the mass/density function. $$E\left({\frac 1 X}\right) = \sum \frac 1 x f(x)$$ $$\frac 1 {E(X)} = \frac 1 {\sum x f(x)}$$ Assume they're equal. Then: $$\sum \frac 1 x f(x) = \frac 1 {\sum x f(x)}$$ $$\implies \left(\sum \frac 1 x f(x)\right)\left(\sum xf(x)\right) = 1$$ This is a type of convolution, which would mean that $$\dfrac {f(x)}{x} = (x f(x))^{-1}$$ in regards to this convolution. Is that possible? Do functions have inverses under convolution?","['expectation', 'probability', 'convolution']"
2312163,"If $\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty$, then $\frac{1}{n} \sum_{k = 1}^n a_k \to 0$ [duplicate]","This question already has an answer here : Slick proofs that if $\sum\limits_{k=1}^\infty \frac{a_k}{k}$ converges then $\lim\limits_{n\to\infty} \frac{1}{n}\sum\limits_{k=1}^n a_k=0$ (1 answer) Closed 7 years ago . I'm currently reading a paper, where they assert that for a nonnegative sequence $a_k$ of real numbers with $\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty$, we have $\lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n a_k = 0$. My attempt to prove this was using the following idea: If $a_k > \varepsilon > 0$ for all $k \geq k_0$, then $$ \sum_{k = 1}^\infty \frac{a_k}{k} > \varepsilon \sum_{k = k_0}^\infty \frac{1}{k} = + \infty.$$ So we should have some decay condition on the $a_k$. However, we could have $a_k$ to be the characteristic function of $\{ n^2 : n \geq 1 \}$ for instance; then we can't compare the series $\sum_{k = 1}^\infty \frac{a_k}{k}$ to the harmonic numbers; but then we can equally deduce the fact since square numbers have density zero. I know that this is very vague. The reason for this is, that I couldn't get the idea to work. How can I prove the fact? Thanks!","['real-analysis', 'sequences-and-series', 'calculus']"
2312207,Tiling the unit square with right triangles,"What's the minimal number of distinct right angled triangles needed to tile a unit square? I suspect it cannot be done in less than four, thus here are the solutions for $4$ triangles so far: Define a unit square $ABCD$; then the three distinct constructions so far are: Connect two opposite corners ($\overline{AC}$), and place a fifth point ($E$) anywhere on some side ($\overline{BC}$) of the square. Connect the fifth point with the remaining available point ($A$) and draw a perpendicular line  ($\overline{EF}$) from it to the diagonal line. You now have $4$ distinct triangles tiling the square. Place a fifth point ($E$) anywhere on some side ($\overline{BC}$)  of the square except on the middle point ($P$) of that side. Connect it with the two points of the opposing side ($\overline{DA}$) and draw a perpendicular line ($\overline{DF}$ or $\overline{AF}$) from any of those two points to the opposing line segment. You now have $4$ distinct triangles tiling the square. Oscar Lanzi's construction ; From $A$ draw a line segment to a point $E$ anywhere on side $\overline{BC}$. Construct the perpendicular to $\overline{AE}$ through $E$ which intersects side $\overline{CD}$ at $F$. Finish the division by drawing $AF$. You now have $4$ distinct triangles tiling the square. Do these constructions contain all valid solutions to tile the
  unit square with $4$ distinct right angle triangles? Or are there some other ways missing? The goal is to find all valid solutions for this simple problem, and prove no more exist. But I'm not sure how can one tell whether we have all the solutions contained in these constructions so far or not? Follow up question; is it possible that there exists a solution among the solutions such that all four triangles have all side lengths rational? Since I stumbled upon a tweet showing $5$ Pythagorean triples packed in a square; If that square were scaled down to a unit square, we would have a solution with $5$ triangles that have all sides rational. Is it possible to do it in $4$? Pack four rational distinct triangles in a unit square? I suppose this can be shown false if all constructions were found and
  shown to not contain such a solution. So far, these three
  constructions seem to not contain such a solution, if I'm not
  mistaken.","['packing-problem', 'discrete-geometry', 'euclidean-geometry', 'geometry', 'recreational-mathematics']"
2312208,$PGL(n)$ is a closed subgroup of $GL(n^2)$,"Assume the base field is complex numbers. Let $PGL(n)$ be the projective linear group. I heard it is a closed algebraic subgroup of $GL(n^2)$, but I am having trouble proving it. What I tried is embedding a matrix in $PGL(n)$ using the ratios of its entries, but this works bad when there is $0$ in the matrix. Similar question has been asked here. How to realise $\mathrm{PGL}_2$ as a closed subgroup of some $\mathrm{GL}_n$ explicitly? Thanks for the help.","['matrices', 'algebraic-groups', 'group-theory']"
2312215,Relationship between tensor product and wedge product,"In Gravitation (Misner, Thorne & Wheeler), the wedge product over a vector space $V$ is introduced as just the antisymmetrised tensor product: for $u, v \in V$, they define
$$u \wedge v = u \otimes v - v \otimes u$$
I'm trying to work out how to fit this together with the characterisation of the exterior algebra $\Lambda V$ as the quotient of the tensor algebra $T(V)$ by the two-sided ideal $I$ generated by tensor products of the form $v \otimes v$. In that characterisation (at least in Wikipedia), the wedge product is defined by
$$[u] \wedge [v] = [u \otimes v]$$
where square brackets indicate equivalence classes, for the equivalence relation $\sim$ induced by the ideal (i.e., $u \sim v$ iff $v = u + i$, for some $i \in I$). At first, I took it that the way they fit together was that we would be able to show that $$u \otimes v \sim u \otimes v - v \otimes u$$ But so far as I'm able to tell, this isn't the case: what we can show instead is that $u \otimes v \sim -v \otimes u$, and hence that
$$u \otimes v \sim \frac{1}{2} (u \otimes v - v \otimes u)$$
Having browsed a bit, this answer suggests to me that what's going on is just that there are two ways of relating the exterior algebra to the tensor algebra: the MTW characterisation amounts to treating $\Lambda V$ as a subalgebra of $T(V)$ (specifically, the subalgebra generated by antisymmetric tensor products), rather than as a quotient algebra of $T(V)$. Is that correct? If so, what are the advantages of a subalgebra vs a quotient algebra construction, and vice versa? (Apologies if this is overly duplicative of the linked discussion - it was a bit too abstract for me to be sure I'd followed it correctly.)","['tensor-products', 'linear-algebra', 'exterior-algebra']"
2312234,Zero joint subsums of integers,"Fix integers $x_1,y_1,\ldots,x_{10},y_{10}\in [-2,2]$ such that 
$$
\sum x_i=\sum y_i=0\,.
$$ Then, does it necessarily exist a nonempty proper subset $J$ of $\{1,\ldots,10\}$ such that
$$
\sum_{j \in J} x_j=\sum_{j \in J} y_j=0\,?
$$","['number-theory', 'integers']"
2312255,Cutting a $D$-dimensional space with $n$ hyperplanes,"I'm wondering the following: What's the maximum number of parts you can get when cutting a $D$-dimensional space with $n$ hyperplanes? The root of this questioning is that I first dicovered while studying simple neural nets for classification, that in 2D with 3 binary output neurons, where the network is just a linear classificator (no hidden layer), you can get maximum 7 classes, and not 8 (number of possible combinations of 3 binary digits) as expected. As shown on the image, the class 010 is missing. There can also be the case where all three points intersect at the same place and we only get 6 domains but this is of fewer interest for me. I've tried to understand what's going on in two dimensions and I figured out that you can get maximum $n+1$ new domains by adding a straight line, where $n$ designs the number of existing straight lines. It seems to work pretty fine, although I did not prove it (my bad): For all integer $n$, let $f(n)$ be the maximum number of domains that you can get with $n$ straight lines on a plane. $$
\text{Conjecture:}~~~~~~~~~~~\begin{cases}
f(0)=1\\
\forall n>0, ~~ f(n)=n+f(n-1)
\end{cases}
$$ Then I tried to see how the problem looked like in higher dimensions, starting with planes in 3D but it quickly became hard to sketch on a sheet of paper. I defined another function $f_D$ that describes the maximum number of domains you get when cutting a $D$-dimensional space with hyperplanes. From hand drawings, I got the following formula (which does not hold for $n=0$ anymore): $$
\text{Conjecture:}~~~~~~~~~~~\forall D\in \mathbb N^*, ~~ \begin{cases}
f_D(1)=2\\
\forall n>1, ~~ f_D(n)=n\cdot(D-1)+f(n-1)
\end{cases}
$$ Which can be de-recursified (easy proof by induction) into: $$
\forall D, n\in \mathbb N^*, f_D(n)=\frac{n^2+n-2}{2}(D-1)+2 = \frac{n\cdot(n+1)}{2}(D-1)+3-D
$$ Can anyone prove or disprove my intuition? Or give me hints about how I should take the problem, or point me to existing solutions? Thanks in advance.",['geometry']
2312281,Geometric visualization of nested radicals,"There are a number of extremely useful geometric techniques for visualizing results from number theory, such as various infinite sums, results from combinatorics, and so on.  (One of my favorites is the grid representation of the Euclidean algorithm for computing the greatest common factor of two integers, shown in an animation here .)  Are there any analogous visualization techniques for nested radicals--to visualize, for instance, equations of the form: $$\sqrt{n + \sqrt{n + \sqrt{n + ...}}} = \frac{1 + \sqrt{1 + 4n}}{2},$$ such as studied by Ramanujan and others? The algebraic solution of that equation (in particular) is simple indeed, by denoting the left-hand side $x$, squaring and solving a quadratic equation.  But can one represent it (and others like it) graphically/geometrically? For example, Viète's expression for $\pi$ is: $${2 \over \pi} = {\sqrt{2} \over 2} \cdot {\sqrt{2 + \sqrt{2}} \over 2} \cdot {\sqrt{2 + \sqrt{2 + \sqrt{2}}} \over 2} \cdot \cdots$$ and its form strongly suggests there is some graphic involving linked hypotenuses of scaled squares and a circle that illustrates this result.  Is there one?","['nested-radicals', 'geometry']"
2312284,Is it possible to convert a linear system in an ODE of higher order,The opposite direction is quit simple. But under which circumstances is it possible to convert a system of first order ODE of dimension n into a single ODE of order n?,['ordinary-differential-equations']
2312326,Variance of the Euclidean norm of a vector of Gaussians,"Given a vector of correlated Gaussian random variables $\vec{X}=\left(X_1, ..., X_k\right)$ that are normally distributed $\vec{X} \sim \mathcal{N}\left(\vec{\mu}, \Sigma\right)$ with arbitrary $\Sigma$ and $\vec{\mu}$ values what's the variance (i.e. the second central moment) of the random variable $\lVert X \lVert_2$? From length of Gaussian Random Vector we know that the general probability density function of $\sqrt{Q(\vec{X})} = \sqrt{X^TAX}$ does not follow any known laws. However I'm only looking for the variance. From the post we know that when analyzing the quadratic form (see linked post)
$$
Q(\vec{X})=\sum_{i=1}^k\lambda_i\left(U_i+b_i\right)^2=\sum_{i=1}^k\lambda_i\left(U_i^2 + 2b_iU_i + b_i^2\right)
$$
we obtain a superposition of Chi-Squared-Distributions and zero-mean Gaussian distributions since $\vec{U}$ is multivariate normal with identity covariance matrix and expectation zero.
Using these rules we obtain: $var\left(U_i^2\right) = 2$ (Chi-Squared) $var\left(U_i\right) = 1$ (uniform Gaussian) $var\left(2b_iU_i\right) = 4b_i^2$ $var\left(b_i^2\right) = 0$ (constant) $cov\left(U_i^2, 2b_iU_i\right) = E\left[2b_iU_i^3\right] = 2b_iE\left[U_i^3\right] = 0$ $cov\left(U_i^2, b_i^2\right) = 0$ $var\left(U_i^2 + 2b_iU_i + b_i^2\right) = 2 + 4b_i^2$, and hence $$var\left(Q(\vec{X})\right) = \sum_{i=1}^k\lambda_i^2(2 + 4b_i^2)$$ So the only step missing would to find $var\left(\sqrt{Q(\vec{X})}\right)$ given $var\left(Q(\vec{X})\right)$. Unfortunately it doesn't appear that simple according to Mean and variance of $\sqrt{X}$ given mean and variance of X . So how to move on with this?
Will the definition of the central moment be helpful? Assuming we are able to come up with the pdf of $\sqrt{Q(\vec{X})}$ I'm afraid this might only yield ugly integral terms that are impossible to solve or even approximate in the general case... edit: fixed the variance of Chi-Squared to 2","['normal-distribution', 'normed-spaces', 'statistics', 'chi-squared', 'random-variables']"
2312362,Probability from randomized dice,"Suppose you have a pair of dice that have removable stickers for numbers on each of their 6 sides. Suppose that you unstick all 12 of the stickers from the dice and reapply them randomly to the 2 dice. You will still have 2 occurrences of each number 1 through 6. However, they may both occur on the same die. (For instance: after rearranging the stickers, you may have dice $d_1$ and $d_2$ with sides  $d_1 = [1,2,2,4,4,6]$ and $d_2 = [1,3,3,5,5,6]$.) Suppose now that you roll this randomized pair of dice. Is there a concise way to calculate the probability of each outcome? What is the probability of each possible outcome? Just by working out some of the possible arrangements, it seems like $p(2)$ should be $\frac{1}{72}$ (which might not be correct), but the other probabilities are more difficult to compute this way.","['probability', 'dice']"
2312379,Prove the existence of Laplace transform of $2te^{t^2}\cos(e^{t^2})$,"I tried to directly compute the integral, but I was unable to and wolfram alpha says it cannot find the answer in terms of elementary integrals. How can I prove the existence of the Laplace transform without directly computing it? Helpful hints leading me to the answer will be accepted as the answer(and I actually prefer this to outright stating it. Any help is appreciated! I messed up and put the wrong function in the title initially- it should be the derivative of the function I gave. I am sorry for wasting people's time.","['laplace-transform', 'calculus']"
2312417,Computing expectation of conditional probability when the conditioning variable is continuous,"I have a question about the computation of an expectation. Consider 3 random variables $Y,X,Z$. $Y\equiv f(Z)$. $Z$ is continuous, $Y$ is discrete. In what follows the notation $1(...)$ denotes the indicator function taking values $1$ if the condition inside is satisfied and $0$ otherwise. Moreover, small case letters denote realisations of random variables. CASE 1 : $X$ is discrete . Let $$
m^{y,x}(Y,X)\equiv 1(Y=y) 1(X=x) - P(Z \text{ takes a value s.t. } Y=y| X)*1(X=x)
$$ Then 
$$
E\Big[m^{y,x}(Y,X)\Big]=E\Big[1(Y=y) 1(X=x)\Big] - E\Big[P(Z \text{ takes a value s.t. } Y=y| X)*1(X=x)\Big]=P(Y=y, X=x)-P(Z \text{ takes a value s.t. } Y=y| X=x)*P(X=x)
$$
$$= P(Y=y, X=x)-P(Z \text{ takes a value s.t. } Y=y, X=x)
$$ CASE 2 : $X$ is continuous with pdf $g$. Let $K$ be a subset of the support of $X$ such that $P(X\in K)>0$. Let $$
m^{y,K}(Y,X)\equiv 1(Y=y) 1(X\in K) - P(Z \text{ takes a value s.t. } Y=y| X)*1(X\in K)
$$ Then 
$$
E\Big[m^{y,K}(Y,X)\Big]=E\Big[1(Y=y) 1(X\in K)\Big] - E\Big[P(Z \text{ takes a value s.t. } Y=y| X)*1(X\in K)\Big]=P(Y=y, X\in K)-\int_{K}P(Z \text{ takes a value s.t. } Y=y| X=x)*g(x)dx
$$
Question: is it true that
$$
\int_{K}P(Z \text{ takes a value s.t. } Y=y| X=x)*g(x)dx= P(Z \text{ takes a value s.t. } Y=y, X\in K)
$$ ?","['probability-theory', 'conditional-expectation', 'probability', 'expectation']"
2312452,Integration of power series,"I am trying to find an approximate solution of:
\begin{equation}
\int_{0}^{+\infty} e^{-x}dx \ (=1)
\end{equation}
from the power series expansion of :
\begin{equation}
e^{-x}= 1-x+(1/2)\cdot x^2-(1/6)\cdot x^3+(1/24)\cdot x^4-(1/120)\cdot x^5+O(x^6)
\end{equation}
My Problem is that when I integrate the series term by term, the polynomials wont behave well with the $\infty$ term..
Can you help me please","['integration', 'power-series', 'calculus']"
2312474,Why do we need a Borel function in the definition of exponential family?,"See the following definition. I was expecting $h$ to be a $\cal F$-measurable function, but the definition says it is a Borel function. Anyone can help explain why we need a Borel function here ? What difference does it make?","['probability-theory', 'probability', 'statistics']"
2312505,Computing isogenous curves,"Let $E_1$ and $E_2$ be elliptic curves defined over a field $\mathbb{K}$. An isogeny is a finite morphism
$$\varphi:E_1\to E_2$$
such that $\varphi(\mathcal{O})=\mathcal{O}$. It is possible to show that an isogeny induces a morphisms of the groups of $E_1$ and $E_2$. It is clear that isogeny is an equivalence relation. Furthermore, following Hartshorne's Algebraic Geometry exercise 4.9.b, for a fixed elliptic curve $E$, the set elliptic curves of isogenous to $E$ is countable. We are looking for a way to compute explicitly this set of isogenous curves for a fixed curve $E$. Our ultimate goal would be to give a set of curves $\lbrace E_i\rbrace_{i\in I}$ such that if $\varphi: E\to E'$ is an isogeny, then there exists $i\in I$ with $E_i\simeq E'$, each $E_i$ being expressed explicitely in the Weirstrass form (assuming $\mathrm{car}(\mathbb{K})\neq 2,3$). Many theorems & propositions in Silverman's The Arithmetic of Elliptic Curves suggest a classification using subgroups of the fixed curve $E$. For example, proposition 4.12 tells us: "" For an elliptic curve $E$ and $\Phi$ a finite subgroup of $E$, there is a unique elliptic curve $E'$ and a separable isogeny $\varphi:E\to E'$ such that $\ker \varphi=\Phi$. "" This approach did not show much progress yet unfortunatly. I hope you find this question as interesting as I do. Any progress on the question, as tiny as it may seem, is more than welcome. If anything is unclear, please let me know. Edit : Thanks to @Jyrki Lahtonen for pointing out this trivial case. Using Silverman's proposition cited above, if we have $\Phi=E[n]$, then the curve and the isogeny is $[n]:E\to E$.","['field-theory', 'elliptic-curves', 'group-theory', 'algebraic-geometry']"
2312516,Polynomials $f$ and $f'$ with all roots distinct integers,"Edit 2. Since the question below appears to be open for degree seven and above, I have re-tagged appropriately, and also suggested this on MathOverflow ( link ) as a potential polymath project . Edit 1. A re-phrasing thanks to a comment below: Is it true that, for all $n \in \mathbb{N}$, there exists a degree $n$ polynomial $f \in \mathbb{Z}[x]$ such that both $f$ and $f'$ have all of their roots being distinct integers? (If not, what is the minimal $n$ to serve as a counterexample?) The worked example below for $n = 3$ uses $f$ with roots $\{-9, 0, 24\}$ and $f'$ with roots $\{-18, -4\}$. (See also the note at the end, and the linked arXiv paper.) Question. For all $n \in \mathbb{N}$: Is it possible to find a polynomial in $\mathbb{Z}[x]$ with $n$ distinct $x$-intercepts, and all of its turning points, at lattice points? This is clearly true when $n = 1$ and $n = 2$. A bit of investigation around $n = 3$ leads to, e.g., the polynomial defined by: $$f(x) = x^3 + 33x^2 + 216x = x(x+9)(x+24)$$ which has $x$-intercepts at $(0,0)$, $(-9, 0)$, and $(-24, 0)$. Taking the derivative, we find that: $$f'(x) = 3x^2 + 66x + 216 = 3(x+4)(x+18)$$ so that the turning points of $f$ occur at $(-4, -400)$ and $(-18, 972)$. I am not even sure if this is true in the quartic ${^1}$ case; nevertheless, this question concerns the more general setting. In particular, is the statement true for all $n \in \mathbb{N}$ and if not , then what is the minimal $n$ for which this is not possible? $1$. Will Jagy kindly resolves $n=4$ since the monic quartic $f$ with integer roots $\{-7, -1, 1, 7\}$ leads to an $f'$ with roots $\{-5, 0, 5\}$. This example is also found as B5 in the paper here (PDF 22/24). The same paper has the cubic example above as B1 , and includes a quintic example as B7 : $$f(x) = x(x-180)(x-285)(x-460)(x-780)$$ $$\text{ and }$$ $$f'(x) = 5(x-60)(x-230)(x-390)(x-684)$$ The linked arXiv (unpublished) manuscript seems to suggest that this problem is open.","['derivatives', 'real-analysis', 'polynomials', 'calculus', 'open-problem']"
2312585,Derivatives involving inner product and Hadamard product,"Let $x,y,z\in\mathbb{R}^n$. I am trying to compute $$
\frac{\partial}{\partial x} (x\circ y)^Tz\\
\frac{\partial}{\partial x} (x\circ y)^T(x \circ y)
$$ where $x\circ y$ is the Hadamard product of $x$ and $y$, but it is throwing me for a loop. Can someone show me how to proceed with these derivatives? Based on this answer , it appears that I can write $f(x,y)=(x\circ y)^T(x\circ y) = (x\circ y)^TI(x\circ y)$ and thus $$
\frac{\partial f}{\partial x} = y\circ (I^T+I)(x\circ y)
$$
but I am confused about the first part, $y\circ(I^T+I)$. The dimensions do not seem to match up properly since $y\in\mathbb{R}^n$ and $I\in\mathbb{R}^{n\times n}$. Context: I would like to compute the gradient of the following: $$
\begin{split}
||x-\alpha\circ y||_2^2 &= (x-\alpha\circ y)^T(x-\alpha\circ y)\\
& = x^Tx - x^T(\alpha\circ y) - (\alpha\circ y)^Tx + (\alpha\circ y)^T(\alpha\circ y)
\end{split}
$$ with respect to $\alpha$ as part of the derivation of a gradient descent update. If there is  a simpler way to compute the derivative of this 2-norm, please share; however, I'd still like to know how to compute the individual derivatives as well!","['derivatives', 'gradient-descent', 'hadamard-product', 'vector-analysis']"
2312648,What does a binomial coefficient with commas mean?,"I'm reading through this paper (on Dyck Paths). Near the middle of the second page, the author states the following: Remark For the set $h_n$ there are ${k\choose t_1, t_2, ... , t_m }$ $n + k \choose{k}$ $=$ $ n + k\choose {n, t_1, t_2, ..., t_m}$ different Dyck paths. What does ${k\choose t_1, t_2, ... , t_m }$ mean? I know what the binomial coefficient is, but I'm not sure how to interpret it when one of the parameters is a set.","['combinatorics', 'binomial-coefficients', 'notation']"
2312688,Defining Jacobian of differential map on Riemannian manifold,"I'm reading Rufus Bowen's notes on ergodic properties of Anosov diffeomorphisms, and I've come across an important-seeming function but I'm confused about how it's defined. Let $M$ be a Riemannian manifold, and let $f : M \to M$ be a $\mathcal{C}^2$ Axiom A diffeomorphism. (For our purposes, this means there is a closed invariant $\Omega_s \subseteq M$ for which there is a $Df$-invariant splitting of the tangent bundle $T\Omega_s = E^s \oplus E^u$.) Bowen writes the following (first paragraph of Section 4B): For $x \in \Omega_s$, let $\phi^{(u)}(x) = -\log \lambda(x)$, where $\lambda(x)$ is the Jacobian of the linear map $$Df : E^u_x \to E^u_{fx}$$ using inner products derived from the Riemannian metric. My question is, how exactly is $\lambda(x)$ defined? My first thought was it's the determinant of the Jacobian matrix of partial derivatives, but (a) this requires writing $Df$ in coordinates and I'm not sure the determinant is coordinate-idnependent, and (b) this determinant has seemingly nothing to do with the Riemannian structure on $M$, but the dependence of $\phi^{(u)}(x)$ on the Riemannian metric plays a key role in subsequent arguments of his lecture notes. So how do we typically define the Jacobian of the differential of a diffeomorphism? Any help is appreciated!","['dynamical-systems', 'riemannian-geometry', 'differential-geometry']"
2312690,Distribution of elements of inverse matrix,"Suppose $M$ is an $n \times n$ matrix whose elements are independent random values that follow a normal distribution whose mean is $0$ and whose standard deviation is $1$. What distribution will the elements of $M^{-1}$ follow? If the distribution of $M$ follows a uniform distribution, how does this change the distribution of the elements of $M^{-1}$? To clarify, $M$ is almost surely an invertible matrix simply because of the way it's generated. When you have a matrix filled with independent random real values, it's almost surely invertible even if it's really large.","['statistics', 'linear-algebra']"
2312747,Why is Matrix Addition defined as element by element addition?,"Matrix multiplication is defined as row by column multiplication. It represents linear transformation. Why isn't matrix addition defined in a similar way: row by column addition. Given to matrices A and B (of the same size). What transformation, if any, does (element by element) addition  A+B represent? What would row by column addition represent? How about the Hadamard product (element by element matrix multiplication) represent?",['matrices']
2312764,Prove that a function $f : X \mapsto X$ is injective if and only if it has a left inverse.,"Prove that a function $f : X \mapsto X$ is injective if and only if it has a left
inverse. Can someone help me with this? What I've done is form predicates of the form $LI(f) \Rightarrow INJ(f)$ to begin step-by-step. I understand the left hand side will be quantified to $\exists f,g: X \mapsto X: g \circ f = id_X$. Am I in the right direction here? Or am I missing something more that should be quantified? I know the following: the identity function, $id_X: X \mapsto X$, is defined by $\forall x \in X, id_X(x)=x$. A function $g \in \mathcal{F}$ is called a left inverse of a function $f \in \mathcal{F}$ if $g \circ f =id_X$.","['proof-writing', 'elementary-set-theory']"
2312766,"Why some functions $f(x,y)$ can be discontinuous but its partial derivatives still could exist?","Why some functions  $f(x,y)$ can be discontinuous but its partial
  derivatives still could exist? I am slightly confused,... the relationship between continuity, limits, partial derivatives and differentation. I don't understand that from the definition very well.","['continuity', 'partial-derivative', 'ordinary-differential-equations', 'analysis']"
2312772,Does $\nabla_X Y-\nabla_Y X$ satisfy the Jacobi identity?,"Assume that $\nabla$ is an arbitrary connection on a manifold.
Under what conditions, other than LC connections, the binary operator $\nabla_XY -\nabla_YX$ defines a Lie braket on $\chi^{\infty}(M)$? If it is  not true  for  a  general  connection, is there  a name  for  this property  of  connection? What  is  an  example or  non example  of    a  connection $\nabla $, with non trivial torsion,  for  which $\nabla_XY -\nabla_YX$  satisfy or dissatisfy the  Jacobi  identity?","['riemannian-geometry', 'differential-geometry']"
2312774,Prove that the product is never a perfect square,"Prove that for nonnegative integers $x_1,\ldots,x_{2011}$ and $y_1,\ldots,y_{2011}$ the product $$(2x_1^2+3y_1^2)(2x_2^2+3y_2^2) \cdots (2x_{2011}^2+3y_{2011}^2)$$ is never a positive perfect square. I thought about generalizing this question to any odd subscript $n$ instead of $2011$. Thus, $$(2x_1^2+3y_1^2)(2x_2^2+3y_2^2) \cdots (2x_n^2+3y_n^2)$$ is never a perfect square. For $n = 1$ we have $2x^2+3y^2 = z^2$ and I want to show the only solution is $x = y = z = 0$. If $x$ is even, then $y$ must be even by taking modulo $4$. If $x$ is odd, then $y$ must be odd. I didn't see how to continue from here.",['number-theory']
2312805,Prove that $\frac{(\sin 20^\circ + \cos 20^\circ)^2}{\cos 40^\circ} = \cot 25^\circ$,So I'm trying to come up with an answer to this question for hours now. I don't know what I'm doing wrong and none of the calculators on the internet couldn't help so I figured I should ask people. What have I done so far: $\frac{(\sin 20^\circ + \cos 20^\circ)^2}{\cos 40^\circ} = \frac{(\frac{2\sin(45^\circ+20^\circ)}{\sqrt{2}})^2}{\cos 40^\circ} = \frac{\sin^2 65^\circ}{\cos 40^\circ} = \frac{1 - \cos 130^\circ}{\cos 40^\circ} = \frac{1 + \cos 50^\circ}{\cos 40^\circ} = \frac{2\cos^2 25^\circ}{\cos 40^\circ}$ ... etc. I can't seem to figure out where to go from here so I'm just stuck. I also tried the classic approach: $\frac{(\sin 20^\circ + \cos 20^\circ)^2}{\cos 40^\circ} = \frac{1 + \sin 40^\circ}{\cos 40^\circ} = \frac{1}{\cos 40^\circ} + {\tan 40^\circ} = \sec 40^\circ + \tan 40^\circ$ But how can I prove that $\sec 40^\circ + \tan 40^\circ = \cot 25^\circ$ ? What am I doing wrong? Any hints or solutions would be great. Thanks in advance.,['trigonometry']
2312821,"How to solve $\bigcap_{k=1}^{5}[\bigcup_{n=1}^{k}X_{n}]$ and $\bigcap_{k=5}^{\infty}[\bigcup_{n=3}^{k}X_{n}]$? When $X_{n}=\{n+1,n+2,...,2n\}$","Let $X_{n}=\{n+1,n+2,...,2n\}$ for each $n \in \mathbb{N^{+}}$ What are (i) $\bigcap_{k=1}^{5}[\bigcup_{n=1}^{k}X_{n}]$ I solve the inside through the loop outside $\bigcup_{n=1}^{k}X_{n}$ $
k=1 \\
n=1:\{2\} \\
\ \\ 
k=2 \\
n=1:\{2\}\\n=2:\{3,4\} \\
k=3 \\
n=1:\{2\}\\n=2:\{3,4\} \\ n=3:\{4,5,6\} \\
... \\k=5\\
n=k:\{2,3,...,k+1,k+2,...2k\}$ $\bigcap_{k=1}^{5}[k+1,k+2,...2k]=\{2\}$ Is this correct? (ii)$\bigcap_{k=5}^{\infty}[\bigcup_{n=3}^{k}X_{n}]$ $
k=5 \\
n=3:\{4,5,6\} \\ n=4:\{5,6,7,8\} \\ n=5:\{6,7,8,9,10\}
\ \\ 
k=6 \\
n=3:\{4,5,6\} \\ n=4:\{5,6,7,8\} \\ n=5:\{6,7,8,9,10\} \\ n=6:\{7,8,9,10,11,12\} \\
... \\ k=\infty \\ n=k:
\{4,5,6,...k+1,k+2,....2k\}$ $\bigcap_{k=5}^{\infty}[\bigcup_{n=3}^{k}X_{n}]=\{4,5,6\}$ Is this correct?","['sequences-and-series', 'elementary-set-theory']"
2312826,Calculate the curve that is orthogonal to the given curve?,Given the equation $y = Cy^{2} - 3x^{4}$ find a curve orthogonal to the given curve The steps I did so far are: Isolating C: $C = (y + 3x^{4})/y^{2}$ Using symbolab's implicit differentiation calculator: $y' = -(12x^{3}y)/(-6x^{4}-y)$ Taking the negative reciprocal: $y' = (-6x^{4} -y)/(12x^{3}y)$ Simplifying the right hand side: $y'= -x/(2y) - 1/(12x^{3})$ At this point I'm completely confused as the y is in the denominator and y' is already isolated so separation of variables and Bernoulli's does not seem to work. Is there another way to do this equation or did I just make a simple mistake? Thanks in advance,"['ordinary-differential-equations', 'calculus']"
2312842,What are some meaningful connections between the minimal polynomial and other concepts in linear algebra?,"I’ve found that the most effective way for me to deeply grasp mathematical concepts is to connect them to as many other concepts as I can. Unfortunately, I’m seeing neither the importance nor the relevance of the minimal polynomial at all. Are there any significant connections between the minimal polynomial and linear algebra? Particularly regarding the relationship between the minimal polynomial of a linear operator on a vector space and other properties of that operator? I think the problem is partially due to my textbook's emphasis on crunching out as many theorems about a concept as possible, rather than explaining it on a deep level and demonstrating its importance. But part of it is definitely also that this concept is not clicking well for me. Thanks for any help.","['polynomials', 'operator-theory', 'minimal-polynomials', 'linear-transformations', 'linear-algebra']"
2312888,Find $S = \frac{a}{b+c}+\frac{b}{c+a} + \frac{c}{a+b}$ if values of $a+b+c$ and $\frac1{a+b}+\frac1{b+c}+\frac1{a+c}$ are given,"I just stumbled upon a contest question from last year's city olympiad math contest: Question : For the real numbers $a,b,c$ such that: $a+b+c = 6, \dfrac{1}{a+b}+\dfrac{1}{b+c} + \dfrac{1}{c+a} = \dfrac{47}{60}$, find the value of $S = \dfrac{a}{b+c}+\dfrac{b}{c+a} + \dfrac{c}{a+b}$. Since I just saw it from an online forum ""elsewhere"", I thought I'd want to hear from other more skilled and experienced MSE members about your tactics and approaches to the solution of this interesting question.","['algebra-precalculus', 'contest-math', 'symmetric-polynomials']"
2312889,Exterior multiplication with parallel form commutes with Laplacian,"Let $(M,g)$ be a Riemannian manifold, let $\nabla$ be the Levi-Civita connection, and let $\Delta=dd^*+d^*d$ be the Laplacian. Suppose $\omega \in \Omega^*(M)$ is a parallel differential form (i.e. $\nabla \omega=0$), is it true that $\Delta (\alpha \wedge \omega)=\Delta(\alpha) \wedge \omega$? I have seen this fact being used a few times in literature, but I cannot find or work out a full proof myself. The sources I have consulted simply say 'use Weitzenbock's formula ', but I cannot see how the formula can prove this. Any help is appreciated!","['laplacian', 'riemannian-geometry', 'differential-geometry']"
2312890,Name for when the addition of two elements of a set also belongs to the set,"Considering the set of integers $\mathbb{Z}$, $$\forall a, b \in \mathbb{Z}, a + b \in \mathbb{Z}$$ This is not true for all sets. If $$A = \{ 1, 2, 3 \}$$
then $$2 + 3 = 5 \notin A$$ So is there a name for the property that the sum of two elements in a set is also contained in the set?","['terminology', 'elementary-set-theory']"
2312915,"What does it mean for a function to be ""Locally Bijective""?","In my calculus text, it states that a function $f$ can be integrated iff it is Locally Bijective . I'm wondering what this means, since given my (very elementary) understanding of what a bijective function is, I feel like this is somewhat inaccurate. For instance,  $f(x)=-x^2+1$ isn't bijective around x=0, but I can still integrate it in an interval containing $0$. Sorry if this is a really stupid question, just need some help!","['calculus', 'functions']"
2312928,"Discrete Mathematics, Equivalnces""","The ""≡ mod 3"" relation is an equivalence relation on the set {1,2,3,4,5,6,7}. List the equivalence classes. I understand ""≡ mod n"" relation on Z is transitive. I just cant see how to start this problem, Thanks for any tips.",['discrete-mathematics']
2312970,Sufficient Conditions for Existence of a lift given a quotient,"Let $Y$ be a topological space with some equivalence relation $\sim$ and let $q: Y\to Y/\sim$ be the quotient map. Question : Given a topological space $X$, and a map $f: X\to Y/\sim$, are there any nice sufficient conditions to guarantee the existence of a lift $g: X\to Y$ such that $q \circ g = f$?  What does one generally need to ask for to get such existence? Does it simplify matters if $Y/\sim$ is finite?  Unfortunately this isn't a topic I'm familiar with, any references welcome! Edit : I've realized if $q$ admits a continuous right-inverse then this problem would be easy, so any conditions to guarantee this would suffice as an answer.","['algebraic-topology', 'general-topology']"
2312988,First Hardy Littlewood Conjecture,"The first Hardy Littlewood conjecture, also known as the k-Tuple conjecture is concisely presented here . However, I cannot find a paper explaining how Hardy and Littlewood came to such a conjecture. How is their statement justified? Where can the intuition behind the statement be understood? What paper presents a clear introduction to the conjecture and how it arose?","['number-theory', 'reference-request', 'prime-numbers']"
2312997,How to represent this limit:$\lim\limits_{n\to\infty}\left(\frac{n^n}{n!}\prod_{k=1}^n\frac{x+\frac{n}{k}}{x^2+\frac{n^2}{k^2}}\right)^{\frac{x}{n}}$?,"$$f(x)= \lim_{n\rightarrow\infty} \left(\dfrac{n^n(x+n)(x+\dfrac{n}{2})\cdots(x+\dfrac{n}{n})}{n!(x^2+n^2)(x^2+\dfrac{n^2}{2^2})\cdots(x^2+\dfrac{n^2}{n^2})}\right)^{x/n}
 , \quad x>0$$ How can I represent this limit in a simple form? I tried that
above fomula $\left(\dfrac{\prod\limits_{k=1}^n \left(\dfrac{kx}{n}+1\right)} {\prod\limits_{k=1}^n \left(\dfrac{k^2 x^2}{n^2}+1\right)}\right)^{x/n}$ help me.","['real-analysis', 'calculus', 'limits']"
2313011,About Hadamard products,"in the following problem I have some questions. Show that if $f$ is an entire function of finite order thar omits two values, then $f$ is constant. I know that by Hadamard products, if $f$ omits the values $a$ and $b$, I can write $f(z)-a=e^{p(z)}$ and $f(z)-b=e^{q(z)}$, where $p(z)$, $q(z)$ are polynomials of degree $n,m$ respectively. Then $$e^{p(z)}-e^{q(z)}=b-a.$$ Now, if $z\to\infty$ the leading terms of $p$ and $q$ must be the same, why? And then, how can I conclude that $f$ is constant? Thanks in advance !","['complex-analysis', 'infinite-product']"
2313023,Chebyshev’s inequality is and is not sharp,"(i) Show that Chebyshev’s inequality is sharp by showing that if $0<b\leq a$ are fixed there is an $X$ with $E(X^2)=b^2$ for which $P(|X|\geq a)=b^2/a^2$ . (ii) Show that Chebyshev’s inequality is not sharp by showing $X$ has $0<E(X^2)<\infty$ then $\lim_{a\to\infty} a^2P(|X|\geq a)/E(X^2)=0$ In (i) it looks like problem is to find a $X$ for which the equality holds. But I could not find any such $X$ . In (ii) if $\lim_{a\to\infty} P(|X|\geq a)/E(X^2)=0$ it would be one line proof. But given is $\lim_{a\to\infty} a^2P(|X|\geq a)/E(X^2)=0$ . If we can take $b=a-\varepsilon$ , where $\varepsilon >0$ is a fixed quantity, the equality holds too. But I don't think it would be the case. It should hold for any $b\leq a$ . Need help in both part. Note: Chebyshev’s inequality :- Suppose $\varphi : \mathbb{R}\rightarrow \mathbb{R}$ has $\varphi \geq 0$ let $A\in \mathcal{B}$ (Borel set) and let $i_A = \inf \{ \varphi (y) :y\in A \}$ . $i_A P(X\in A) \leq E(\varphi (X), X\in A)\leq E\varphi (X)$ Clearly here $\varphi (X)=X^2$","['inequality', 'probability-theory', 'integral-inequality', 'expected-value', 'measure-theory']"
2313045,Characterisation of uniformly continuous function,"I have the following exercise:
Let $(X,d)$, $(Y,e)$ be metric spaces. This is the definition of distance of sets used in the exercise: $d(A,B)=inf\{d(a,b)\colon a \in A, b \in B\}$ $d(f(A),f(B))=inf\{e(f(a),f(b))\colon f(a) \in A, f(b) \in B\}$ The exercise is: Prove that $f\colon X \rightarrow Y$ is uniformly continuous if and only if, for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$. If we suppose that $f$ is uniformly continuous, the implication is easy. But the converse is very hard for me. Let me show you what I have tried: Suppose that for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$, and for the sake of a contradiction suppose also that $f$ is not uniformly continuous. Then there exist $\epsilon_0>0$ such that for all $\delta>0$, exist $x_\delta$, $y_\delta$ in $X$ such that $d(x_\delta, y_\delta)<\delta$ but $e(f(x),f(y)) \geq \epsilon_0$. In particular, for all $\delta=\frac{1}{n}>0$ there exist $x_n,y_n$ in $X$ such that $d(x_n,y_n)<\frac{1}{n}$ but $e(f(x_n),f(y_n)) \geq \epsilon_0$ Then $A=\{x_n \colon n \in \mathbb{N}\}$ and $B=\{y_n \colon n \in \mathbb{N}\}$ are such that $d(A,B)=0$. Then by hypotheses, we have that $d(f(A),f(B))=0$. Then, in particular for $\epsilon_0>0$, there exist $x_n,y_m$ in $X$ such that $e(f(x_n),f(y_m))<\epsilon_0$. But I get a contradiction if $n=m$ but I don't know how to proceed in case that $n\neq m$. Any help would be appreciated.","['uniform-continuity', 'general-topology', 'metric-spaces']"
2313049,If $E(X_n) = 1/n$ and $\mathrm{Var}(X_n) = 1/n^2$ then $X_n\to0$ almost surely,I would like to show that If $E(X_n) = 1/n$ and $\mathrm{Var}(X_n) = 1/n^2$ then $X_n\to0$ almost surely. I can not find some relation between the almost sure convergence and $E(X_n)$ and $Var(X_n)$.,"['borel-cantelli-lemmas', 'probability-theory', 'limsup-and-liminf', 'convergence-divergence']"
2313060,How to prove $f(\bigcap_{\alpha \in A}U_{\alpha}) \subseteq \bigcap_{\alpha \in A}f(U_{\alpha})$?,"$f(\bigcap_{\alpha \in A} U_{\alpha}) \subseteq \bigcap_{\alpha \in A}f(U_{\alpha})$ Suppose $y \in f(\bigcap_{\alpha \in A} U_{\alpha})$
$\implies f^{-1}(y) \in \bigcap_{\alpha \in A} U_{\alpha} \implies f^{-1}(y) \in  U_{\alpha}$ for all $\alpha \in A$ $\implies y \in f (U_{\alpha})$ for all $\alpha \in A \implies  y \in \bigcap_{\alpha \in A}f (U_{\alpha})$ $\bigcap_{\alpha \in A}f(U_{\alpha}) \subseteq f(\bigcap_{\alpha \in A} U_{\alpha})$ Suppose $y \in \bigcap_{\alpha \in A}f(U_{\alpha})\implies y \in f(U_{a}) $ for all $\alpha \in A$
$\implies f^{-1}(y)\in U_{a}$ for all $a\in A$ $ \implies  f^{-1}(y)\in \bigcap_{a \in A}U_{a} \implies y \in f(\bigcap_{a \in A}(U_{a})$ Therefore $f(\bigcap_{\alpha \in A} U_{\alpha}) \subseteq \bigcap_{\alpha \in A}f(U_{\alpha})$ Please let me know if my proof works, also I don't fully know how to do the following. Please give me some help. Give an example of proper containment. Find a condition on f that would ensure equality.",['elementary-set-theory']
2313091,Show this infinite series converges,"I want to show that the series $$\sum_{k=1}^{\infty} \binom{\frac{1}{2}}{k} (-1)^k$$ converges. I'm fairly sure it converges to zero, but haven't been successful. Will the ratio test work?","['power-series', 'sequences-and-series']"
2313122,Intersection of a line and a curve.,"Given that the line $y = 2x + 3$ intersects the curve $y = x^2 + 3x + 1$ at two separate points, I have to find these two points. Here is what I did: $$2x + 3 = x^2 + 3x + 1$$ $$0 = x^2 + 1x - 2$$ Using factorisation:
$$x = -2 \text{ or } 1$$ Substituting each values of $x$ obtained into the equation of the  straight line gives two points of intersections at $(-2, -1)$ and $(1, 5)$ Here is my issue: Why does this work? Equating the curve and the straight line means they share a single similar value of $y$ while they clearly share two.","['algebra-precalculus', 'linear-algebra', 'quadratics']"
2313142,"If $H$ and $K$ are normal subgroups of $G$ and $H \cong K$, prove that $G/H \cong G/K$.","It is natural.
But I want to prove exactly. My idea is to use isomorphism theorem. Let $f: G \to G/H$ be the quotient map, 
 then $f$ is a homomorphism and obviously surjective. Hence, I just need to show $\ker(f) = K$. However, I couldn't find the way.
Definitely, $\ker(f) = H $ and $H  \cong K$ But I can say $\ker (f) = K$. How to prove it?","['abstract-algebra', 'normal-subgroups', 'group-theory', 'group-isomorphism']"
2313148,Dimension of $U(n)$,"I've found the dimension of $O(n)$ by the following argument and tried to apply it to $U(n)$, but it didn't go well. my attempt on $O(n)$: define the map $f:M(n,\mathbb{R})\to Sym(n,\mathbb{R})$ by $A\mapsto A^TA$. then since $O(n)$ is the kernel of $f$, by the rank-nullity theorem, $\dim O(n) = \dim M(n,\mathbb{R})-\dim Sym(n,\mathbb{R})=n^2-\frac{n(n+1)}{2}=\frac{n(n-1)}{2}$. for $U(n)$, define the map $g:M(n,\mathbb{C})\to Sym(n,\mathbb{C})$ by $A\mapsto A^*A$. then since $U(n)$ is the kernel of $g$, by the rank-nullity theorem, $\dim U(n) = \dim M(n,\mathbb{C})-\dim Sym(n,\mathbb{C})=2n^2-n(n+1)=n(n-1)$. but in fact $\dim U(n) = n^2$ according to the wiki. where did I miss $n$?","['matrices', 'lie-groups']"
2313195,"Recursion, code-words and sets","""A code-word from the alphabet $\{0,1,2\}$ is considered legitimate if and only if no two $0$'s appear consecutively. Find a recurrence for the number $b_n$ of legitimate code-words"". My dumb solution for this is just observing that, given the code-words of length one (there are three of them), we can append either $\{0,1,2\}$ to find $b_2$, from the resulting $9$ two letters code-word only $8$ are valid (no consecutive 00) or $ 3 \times 3 - 1 = 8$. To find $b_3$ we work in a similar way, appending 1,2 or 3 give us 24 code-words, but only 22 of them are valid: $3\times8 - 2 = 22$. The next iteration is: $3\times22-6=3\times22-2\times3=60$, then $3\times60-16=3\times60-2\times8=164$. Putting all this together (on paper) and you'll notice that in general it seems that $b_n=3\times b_{n-1}-2\times b_{n-3}$. Which looks the correct solution. This problem can be solved also by using some set theory methodologies, does anybody have any idea on how this can be done? This should be something similar to the proof that given a set $A_n$ where $a_i=\{0,1\}$ then the number of subsets of $A$ which do not have consecutive 0 is: $b_n=F_{n+1}$ for $n\ge1$ where $F_n$ is the n-th Fibonacci number.","['combinatorics', 'recursion']"
2313203,Is prime factorization better?,"From the point of view of a grade $4$ student - why and how is prime factorization of a number better in some sense (if at all)? Visually, why is representing $30$ in the form of $2 \times 3 \times 5$, like this (Source: mathlesstraveled.com) might be better than say in the form $5 \times 6$ like this? If it is not, then why would we need it? I know the fact that they are the building blocks of every number, but how could we make the kids appreciate this fact? I'm also familiar with some 'contrived' problems which force prime-factorization, and with the application of primes to the field of cryptography. But the latter might not make much sense at the middle school level. Edit: middle school = grade 4-7 = ages 8-12 = generally when prime factorization would be introduced.","['number-theory', 'prime-factorization', 'prime-numbers', 'elementary-number-theory']"
2313229,Good video lectures on complex analysis?,"I would like to find a complete series of video lectures on complex analysis, preferably with the following conditions: The videos are in English and clearly recorded. (Using English as a second language, I find it hard to understand spoken English when the sound is not clear.) The videos constitute a complete course and they are intended for students in mathematics who already have some familiarity with ""serious"" mathematics, i.e., they are decently fast paced and rigorous, and the content is deep enough. There are already several posts here about video lectures on complex analysis, but I don't know which one will be approapriate for me. For the background, I have studied mathematical analysis from the first seven chapters of Rudin's text. I hope the videos will be at the level of, say, Conway's book (or anything like that). I will clarify any vague points in the above description, just leave a comment. Thanks in advance!","['complex-analysis', 'online-resources', 'reference-request', 'soft-question']"
2313245,Bound on the sum of squared distances between points inside a semi-circle,"There are $n$ points $(a_0, ..., a_{n-1})$ inside a half-disk of diameter $D$.
I would like to prove that there exists a permutation of the $n$ points $(b_0, b_1, .., b_{n-1})=(a_{j_0},a_{j_1} \cdots a_{j_{n-1}})$ such that $$\sum_{i=1}^{n-1} \operatorname {d}(b_{i-1},b_i)^2 \leq D ^2.$$ Here, $\operatorname {d}(\cdot,\cdot)$ denotes the euclidean distance between two points. I tried to use analytic geometry, yet it doesn't help. And I think there is a nice combinatoric way to solve this...","['combinatorics', 'geometry']"
2313259,How many monotonic functions from $\mathbb{R}$ to $\mathbb{R}$ are there,"from $\mathbb{N}$ to $\mathbb{N}$ there are $2^{\aleph_0}$ as you can define $2^{\aleph_0}$ functions as following:
For every subset of $\mathbb{N}$ keep the numbers in the subset the same, and add 1 to the rest. What about the cardinality of all montonic functions from $\mathbb{R}$ to $\mathbb{R}$? Is it ${\mathfrak c}$ or $2^{\mathfrak c}$, ${\aleph_1}$ or ${\aleph_2}$ My intuition is to say that its cardinality is the same as the cardinality of the set of real continuous functions which is ${\mathfrak c}$, as monotonic functions are continuous except possibly at a countable number of points, but I couldn't come up with a concrete proof.",['real-analysis']
2313276,Convergence of series of expectations of indicator functions.,"Let $\{X_n\}_{n\in\mathbb{N}}$ be a sequence of stationary ergodic random variables. Let $A$ be an event such that $p = P(X_1\in A)>0$. Question: Does the following series converge:
\begin{align}
\sum_{k=1}^{\infty}E\left(\prod_{n=1}^{k}1_{\{X_n\in A\}}\right).
\end{align} Notes: The potential difficulty lies in the stationary ergodicness instead of independence. If $\{X_n\}_{n\in\mathbb{N}}$ is an iid sequence, then
\begin{align}
\sum_{k=1}^{\infty}E\left(\prod_{n=1}^{k}1_{\{X_n\in A\}}\right) = \sum_{k=1}^{\infty}\prod_{n=1}^{k}E\left(1_{\{X_n\in A\}}\right) = \sum_{k=1}^{\infty}\prod_{n=1}^{k}p = \sum_{k=1}^{\infty}p^k<\infty.
\end{align}","['probability-theory', 'ergodic-theory', 'sequences-and-series', 'convergence-divergence']"
2313301,Keeping the change in angle constant,"Say I have a ball under a plane that has been secured to the ground on the left, as shown in the diagram (the red part). When I push the ball to the left, the angle increases. If I wanted the change in angle to be constant, what velocity function would the ball have to follow? I know the change in angle change starts off as being large and then continues to diminish because of the sin curve. So, I'm thinking the velocity might just be the cos function. Is this right?",['trigonometry']
2313306,Is there some general way to characterize real symmetrical functions?,"I am looking for a way to rewrite a function $f: \mathbb{R}^2 \mapsto \mathbb{R}$ that is symmetric in its two arguments. That is:
$$
f(x,y) = f(y,x)
$$
At first I was thinking that since $x$ and $y$ are interchangeable, their influence on the value of $f$ must be the same, hence somewhere within $f$ they must be mapped by some auxiliary function $a$ and then aggregated somehow. For example by summation or multiplication:
$$
f(x,y) = a(x) + a(y) \\
 \text{  or}\\
f(x,y) = a(x)a(y)
$$
We can see that if we compose $f$ with any $g : \mathbb{R} \mapsto \mathbb{R}$, the symmetry remains. Hence if we take the logarithm of the lower equation, we can transform multiplication into addition. This would suggest a general form:
$$
f(x,y) = g(a(x) + a(y))
$$
But the problem is that if we add two symmetric functions, we also get a symmetric function, but the given general form does not stand up to this task:
$$
f_1(x,y) + f_2(x,y) = g_1(a_1(x) + a_1(y)) + g_2(a_2(x) + a_2(y))
$$
Is there some general way to characterize $f$? We can assume any number of finite derivatives of $f$.","['functional-analysis', 'functions', 'symmetric-functions']"
2313325,"In a metric space $(X,d)$ if two sequences {$x_n$} and {$y_n$} are Cauchy then d($x_n$,$y_n$) is convergent","Let (X,d) be a metric space and{ ${x_n}$} , {$y_n$} be two arbitrary Cauchy sequences in X then   {$d(x_n,y_n)$} is convergent. I think it is sufficient to show that {$d(x_n,y_n)$} is Cauchy in $\mathbb R$. But I can't use the triangle inequality properly so that I can't bring the result. Need someone's help please..","['real-analysis', 'sequences-and-series', 'calculus']"
2313378,Evaluate $\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy$,"Evaluate the following double integral $$\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy$$ I tried transforming to \begin{align}
x+y &=u\\
x-y &=v
\end{align} but I think it is getting complicated.  Thanks in advance.","['multivariable-calculus', 'multiple-integral', 'integration']"
2313436,How to prove $\tan3°\tan63°\tan69°=\tan15°$?,"Prove $\tan3°\tan63°\tan69°=\tan15°$ And assuming we don't know that $\tan15^{\circ}$ part, how to just evaluate $\tan3^{\circ} tan63^{\circ} tan69^{\circ}$?",['trigonometry']
2313448,What is the difference between orthogonal subspaces and orthogonal complements?,"I am learning linear algebra through professor Giblert Strang's lectures on MIT OCW. The professor says that the row space and the null space of a matrix are orthogonal subspaces . This I can follow, since any vector in the nullspace takes any linear combination of the rows to zero. He then says that the row space and null space are more than just orthogonal subspaces, they are orthogonal complements , Because The ""nullspace contains all the vectors that are perpendicular to the row space"" , and vice versa. Consider:
$$A= \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}=0 $$ A is rank 2, Dimension of nullspace of A=1 Null space:
$$X=c \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}$$ Graphically, the row space of A is the x-y plane, and the null space is the z-axis. It's easy to see that the nullspace does not contain all the vectors that are perpendicular to a vector in the row space. If we look at $[1 ~0~ 0]$, it has the entire y-z plane perpendicular to it, not just the z-axis. All I can see is two orthogonal subspaces. I do not understand what additional property has earned these subspaces the term orthogonal complements . Refer: Lecture Video (from 31:16 to 33:00) Lecture Notes Page 2 paragraph 1",['linear-algebra']
2313450,Calculate: $\sin9°$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I found this question in the olympiad book. But I could not find the solution. The question is to calculate the following real number: $$\sin{9°}$$","['algebra-precalculus', 'radicals', 'trigonometry']"
2313458,Can a continuous function take finite and infinite values?,"Let $X$ be a convex subspace of $\mathbb R^n$. Can a function $f:X\mapsto \mathbb{R}\cup\{\infty\}$ be continuous when there are $x_1,x_2\in X$ such that $f(x_1)=\infty$ and  $f(x_2)<\infty$? My intuition is that that's not possible, here is my reasoning: We take a continuous path $(x_t)_{1\leq t\leq 2}$ from $x_1$ to $x_2$. Then there has to be an $x_s$ such that $f(x_s)=\infty$, but $f(x_{s+\epsilon})<\infty, \forall\epsilon>0$. Is my intuition right or am I missing something?","['continuity', 'real-analysis', 'functions']"
2313472,"given the inverse of a matrix, is there an efficient way to find the determinant?","Suppose one has the inverse $A^{-1}$ of an $N\times N$ non-singular matrix $A$ .   Is there an ''efficient'' way to obtain $\det{A}$ ? With ''efficient'' I mean anything that has a better scaling than the standard $\mathcal{O}(N^3)$ .  Naively, one can argue that $\det{A}$ is already implicitly incorporated in the inverse via the adjugate $A^{-1}=\displaystyle\frac{1}{\det{A}}\operatorname{adj}A$ , so all the work has ""already been done"", and one only needs an efficient trick to distill the determinant. E.g.: for $N=2$ , we have $A=\left(\begin{array}{cc} a & b \\ c & d\end{array}\right)$ and $A^{-1}=\displaystyle\frac{1}{\det{A}}\left(\begin{array}{cc} d & -b \\ -c & a\end{array}\right)$ .  The determinant can efficiently be obtained from $\displaystyle\frac{A_{11}}{[A^{-1}]_{22}}=\det{A}$ in $\mathcal{O}(1)$ .","['inverse', 'linear-algebra', 'determinant']"
2313486,Integration in terms of x,"Evaluating the integral 
$$\int\frac{1}{\sqrt{x^{2} +9}}dx$$
so I use tan substitution $$ x=3\tan t ~\mbox{and}~ dx = 3\sec^{2} t ~dt  $$
after substituting everything in and smplifying im left with 
$$\int \sec t ~dt$$ but I need to have this answer in terms of x, I know 
$$ \sec t = \sqrt{1 + \tan^{2}t}$$ and $$\tan t = \frac{x}{3} $$ so do I just plug in $$\sqrt{1 + (\frac{x}{3})^{2}}$$ just not sure of the final steps I need to get the integral.","['integration', 'trigonometric-integrals', 'calculus']"
2313495,Can the input variable of any polynomial function be a non-polynomial function?,"Since the domain of a polynomial function is $\mathbb{R}$, can we replace the input variable $x$ of any polynomial function by a one-to-one non-polynomial function (with range $\mathbb{R}$) and get another polynomial function? For example, if $p(x)$ is a polynomial function, then can we always define $x$ to be a function such as $ $ $\sinh u$, so that $p(\sinh u)$ is a polynomial function? Or in other words, is the following conjecture true: For all polynomial functions $f(x)$ and for some function $g(x)$ with range and domain $R$, we can conclude that $f(g(x))$ is a polynomial function of $x$.","['hyperbolic-functions', 'polynomials', 'functions']"
2313507,How to find the pointwise limit,"I'm having doubts about the pointwise limit of the following function: $f_n(x)=(\tan(x))^n$ with $x\in [0,\frac{\pi}4]$ I know that $f_n$ converges to $0$ when $x∈ [0,\frac{\pi}4[$. However, when $x=\frac{\pi}4$, $f_n$ converges to 1. So it seems that $f_n$ converges pointwise to $$f(x)=\begin{cases}
0\mbox{ if $0\leq x<\pi/4$,}\\
1\mbox{ if $x=\pi/4$.}
\end{cases}$$
So because my $f(x)$ isn't continuous i'm not sure what the pointwise limit is. I'm then going to need to calculate my $M_n$, which is the supremum of $|f_n(x)-f(x)|$, but because I'm not understanding the pointwise limit i don't know what to substitute $f(x)$ for or what the interval of $x$ related to the supremum is.
Can anyone help me?","['pointwise-convergence', 'functions', 'limits']"
2313540,What's the value of $\theta$ in Lagrange's form of remainder $R_{n}$ for the expansion of $\frac{1}{1-x}$,"The n-th remainder in the expression of $\frac{1}{1-x}$ , $R_{n}$ = $\frac{x^n}{n!}f^n(\theta x)$ . 
And, $f^n(\theta x)$ = $\frac{(-1)^n n!}{(1-\theta x)^{n+1}}$
I have to evaluate the value of $\theta$ here. But I'm clueless about what steps to take. I've tried expanding $\frac{1}{1-x}$ into its polynomial form but i cannot derive anything from it. any help would be appreciated.","['derivatives', 'calculus']"
2313580,Is the product of two Zariski closed subgroups of $GL_n$ still Zariski closed?,"Let $H, H' \subset GL_n {k}$ be two Zariski closed subgroups. Is the set $H H' = \{ h h' : h \in H, h' \in H' \}$ Zariski closed? Here $k$ is a field. Same question for any (reductive?) algebraic group. The counter examples I know to this claim in topological groups setting (where Zariski closed is replaced by closed) are distinctly non-algebraic, since these involve infinite discrete subgroups, or similar. I guess a proof might be found by studying the action of $H$ and $H'$ on the ideals $I(H)$ and $I(H')$ through the regular representation. Maybe if $\rho_H$ is the (left) Reynolds operator for $H$, then $\rho_H(I(H'))$ should vanish on $HH'$, and similarly for a right reynolds operator for $H'$. Though for this we would need $H$ and $H'$ to be reductive to get these projectors, and I'm not sure how to argue further. These are the only ways I could think of right now to produce functions vanishing on $H H'$. I guess that if true this is a standard fact -- a reference or hint would be great.","['algebraic-groups', 'algebraic-geometry']"
2313588,"Proving there exists a prime $q$ such that for every integer $n$, the number $n^p-p$ is not divisible by $q$.","The problem I found was from the 2003 IMO Problem 6. Let p be a prime number. Prove that there exists a prime q such that for every integer n, the number $n^p-p$ is not divisible by q. I studied one version of the solution which started with the expanded form of the equation, $${\frac{p^p-1}{p-1}}$$ Then, it is quite obvious that we would find atleast one prime divisor of ${\frac{p^p-1}{p-1}}$ which is not congruent to $1$ $mod$ $p^2$ . Denoting this prime divisor as $q$ . And in the  solution it stated that this $q$ is what we wanted. I don't understand why this is the q we  sought for in the first place. I also don't understand how this $q$ is related to the $q$ we wanted in forming the proof. Also, from the method of reasoning in the solution, it deduced by stating Fermat's Little Theorem that $n^{q-1}=1$ mod $q$ . I don't understand how $n$ is coprime to $q$ , because this version of FLT is true only for $(q,n)=1$ So, please help me clear my doubts and also if it wouldn't be too much of a trouble, please tell​ your versions of the solution. FYI, I have also tried reading the discussions on Art of problem solving site, that didn't help.","['number-theory', 'prime-numbers', 'elementary-number-theory']"
