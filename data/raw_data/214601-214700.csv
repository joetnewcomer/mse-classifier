question_id,title,body,tags
4348973,proving a result in (elementary) planar projective geometry about cross ratios,"I'm stuck on the following problem in the projective space $P(\mathbb{R}^3) = \mathbb{R}P^2$ . Say we have three distinct and non-concurrent lines $\mathcal{A}, \mathcal{B}$ and $\mathcal{C}$ . Let $P$ be a point outside of these three lines. Show that there exists a unique line $\mathcal{P}$ through the point $P$ , such that the cross ratio $(CPAB) = -1$ , where $A, B$ and $C$ are respectively the intersections $\mathcal{A} \cap \mathcal{P}$ , $\mathcal{B} \cap \mathcal{P}$ and $\mathcal{C} \cap \mathcal{P}$ . My attempt so far: intuitively, I believe this can be proved analytically. ""Choosing"" $A$ on $\mathcal{A}$ randomly (only one ""degree of freedom""), we've also fixed the line $\mathcal{P} = A + P,$ since $A$ and $P$ are necessarily distinct. Then $B$ and $C$ naturally follow. There's only one degree of freedom left, and so filling this in to the definition of cross ratio and setting it equal to $-1$ would uniquely determine the coordinates of $A,$ very loosely speaking. (I am in no way asserting that this is a proof, it's as far as I've got.) Is this how you would do it? Or is there a way to prove it synthetically? I've also tried to look at the dual version of the statement, but I wasn't able to get anything useful from it.","['projective-geometry', 'geometry', 'projective-space']"
4349011,Exotic Definitions of Groups,"Inspired by this question I was wondering, whether there are alternative definitions of groups, namely ones different from the usual 4 axioms. I already suspected that the category theorists have one and indeed, a group can also be defined as a groupoid with only one object. Do you know of any other? And if you happen to know any weird ones, I also welcome exotic definitions of algebraic objects other than groups :)","['group-theory', 'abstract-algebra', 'definition', 'big-list']"
4349052,Diffeomorphisms of Spheres and Real Projective Spaces,In the comments to Mapping torus of orientation reversing isometry of the sphere it was stated that there are only two $ S^n $ bundles over $ S^1 $ up to diffeomorphism. The conversation related to this led me to wonder several things: Is every $ \mathbb{RP}^n $ bundle over $ S^1 $ trivial? Every diffeomorphism of the sphere is either homotopic to the identity or to an orientation reversing isometry. Is every diffeomorphism of even dimensional real projective space homotopic to the identity and every diffeomorphism of odd dimensional projective space is homotopic to either the identity or to an orientation reversing isometry? I expect the answer to my first question is yes for even $ n $ and no for odd $ n $ . Basically because there are exactly 2 sphere bundles over the circle one the mapping torus of orientation preserving maps (the trivial bundle) and one for orientation reversing maps (the non trivial bundle). So importing that intuition to the case of $ RP^n $ then the orientable $ RP^n $ should have two bundles over the circle and the non orientable should have just one. For $ n=1 $ this checks out since that projective space is orientable and thus we have exactly two bundles over the circle (the trivial one/ the 2 torus and the nontrivial one/ the Klein bottle).,"['mapping-class-group', 'fiber-bundles', 'geometric-topology', 'algebraic-topology', 'differential-geometry']"
4349056,"$\int_0^1f(t)\phi'(t)dt=-\int_0^1g(t)\phi(t)dt$, for all smooth $\phi\in[0,1]$ implies $f$ is absolutely continuous and $f'=g$ a.e.","I'm trying to solve the following problem. Let $f,g\in L^1[0,1]$ such that for all $\phi\in C^\infty[0,1]$ with $\phi(0)=\phi(1)$ , $$\int_0^1f(t)\phi'(t)dt=-\int_0^1g(t)\phi(t)dt.$$ Show that $f$ is absolutely continuous and $f'=g$ . My idea is to show that $$f(x)=f(0)+\int_0^x g(t)dt.$$ If I can do this, then by the fundamental theorem of (Lebesgue) calculus, the result will follow. So I integrate by parts and get $$-\int_0^1g(t)\phi(t)dt=\int_0^1f(t)\phi'(t)dt=f(1)\phi(1)-f(0)\phi(0)-\int_0^1\phi(t)f'(t)dt$$ Now there's a couple of questions I have on how to proceed: I'm using the symbol $f'$ here even though I do not know at this point if $f$ is differentiable  (even if almost everywhere). So is the above step even legal? If $\phi$ was compactly supported, I could conclude that $f'=g$ a.e., but it isn't, so I'm not sure how to proceed. Suppose I could show that $f'=g$ a.e. Then I would proceed to get $$\int_0^xf'(t)dt=\int_0^xg(t)dt.$$ And if I knew that $f$ was absolutely continuous (the very thing I want to show), I'd get $f(x)-f(0)=\int_0^1g(t)dt$ , as desired. But this seems circular. How do I get around this? Any help with this is greatly appreciated. Thanks a lot.","['lebesgue-integral', 'real-analysis', 'absolute-continuity', 'almost-everywhere', 'derivatives']"
4349069,An operator on the space of compactly supported sequence does not satisfy a given property.,"Let $\ell_0(\mathbb{N})$ denote the space of compactly sequences: $$\ell_0(\mathbb{N})=\left\{\sum_{k=1}^\infty a_k \,e_k:\#\{j:a_j\neq0<\infty\}\right\}$$ Show that the map $\lambda:\ell_0(\mathbb{N})\to\mathbb{C}$ : $\sum_{j=1}^N a_j \,e_j\mapsto\sum_{j=1}^N a_j$ does not satisfy the following property: There exists $f\in\ell_2(\mathbb{N})$ such that for all $\tau\in \ell_0(\mathbb{N})$ , $\lambda(\tau)=\sum_{j=1}^\infty\tau(j)\overline{f(j)}$ . I don't quite understand the notation $\sum_{k=1}^\infty a_k \,e_k$ to represent a sequence. In particular, could you clarify the difference between $\sum_{j=1}^N a_j e_j$ and $\sum_{j=1}^N a_j$ ? Also can I please get a hint on how to solve this problem.","['lp-spaces', 'sequences-and-series', 'functional-analysis', 'real-analysis']"
4349079,Kunen exercise IV.4.13 (4): Topological version of effective AC,"I am dealing with Kunen's The Foundations of mathematics exercise IV.4.13 (4): Let $X$ denote the Cantor set. Prove if $S\subset X\times X$ is open, then there is an $F\subset S$ such that $F$ is the graph of a function and $\text{dom} (F)=\text{dom} (S)$ and $F$ is continuous on $\text{dom} (F)$ . Kunen called this a topological version of the 'effective AC', with open sets analogous to $\Sigma_1$ sets, closed analogous to $\Pi_1$ , and clopen analogous to $\Delta_1$ , continuous analogous to computable in a zero-dimensional space. Thus, one natural approach is to imitate the proof of its recursion theory counterpart: If $S\subset HF^2$ is $\Sigma_1$ , then there is a partial computable function $F$ of 1 variables such that $F\subset S$ and $\text{dom} (F)=\text{dom} (S)$ . However, the proof makes use of a computable well-ordering on $HF$ , for which I am unable to make connection to the topology version. The exercises proceeding it establish an analog of $\Sigma_1$ reduction (i.e. If $U,V\subset X$ open, then there are $U'\subset U$ and $V'\subset V$ such that $U'\cup V'=U\cup V$ and $U'\cap V' = \emptyset$ .), though I am not sure if this will be of help.","['general-topology', 'cantor-set', 'descriptive-set-theory', 'computability']"
4349098,Linear dependence of functionals (Intuition),"I'm trying to understand why the linear dependence theorem of functionals is true at an intuitive level. I know the proof given in Brezis's functional analysis book (lemma 3.2), where the Hahn-Banach theorem is used; despite all formal details of the proof are clear to me, I feel I don't understand the intuition underground. Could you help me? Linear Dependence Theorem: Let $X$ be a vector space and let $\varphi, \varphi_1,..., \varphi_k$ be $(k+1)$ linear functionals on $X$ such that $ \bigcap_{i=1}^{k}ker(\varphi_i) \subseteq
 ker(\varphi)$ . Then there exist constants $\lambda,\lambda_1,...,\lambda_k$ in $\mathbb{R}$ such that $\varphi=
 \sum_{i=1}^{k}\lambda_i\varphi_i$ .",['functional-analysis']
4349123,"When $p\in X\times Y$, is there a rule that allows us to infer $p=(p_x,p_y)$?","For $p\in X \times Y$ , is there a inference rule that allows us to say that $p=(p_x,p_y)$ for some $p_x\in X, p_y\in Y$ ? For context, I am reading Pinter's ""A Book of Set Theory"" and couldn't find a clear inference rule. I have tried using proof by contradiction to get the desired result, but I get a bit stuck as shown. Edit: Some definitions used in the text $X\times Y  = \{ (x,y) \mid x\in X\wedge y\in Y\}$ $(x,y)= \{\{x\},\{x,y\}\}$","['elementary-set-theory', 'definition']"
4349163,How do we handle the integral $I_{4}=\int\left(\frac{\cos \theta}{1+\sin ^{2} \theta}\right)^{4} d \theta$?,"After struggling with $I_2,I_3$ in the post , I dare to tackle $I_4$ now. We first rewrite the integral $$I_{4}=\int\left(\frac{\cos \theta}{1+\sin ^{2} \theta}\right)^{4} d \theta =\int \frac{\sec ^{2} \theta}{\left(\sec ^{2} \theta+\tan ^{2} \theta\right)^{4}} d(\tan \theta) $$ Letting $x=\tan \theta$ converts $$
\begin{aligned}I_4 &=\int \frac{1+x^{2}}{\left(2 x^{2}+1\right)^{4}} d t \\
&=\frac{1}{2}\left[\int \frac{d t}{\left(2 x^{2}+1\right)^{3}}+\int \frac{d t}{\left(2 x^{2}+1\right)^{4}}\right]
\end{aligned}
$$ By my post , we have an elegant reduction formula: $$
\begin{aligned}
J_{n} &=\int \frac{d x}{\left(a x^{2}+b\right)^{n}}, \text { where } n \geqslant 2 \\
&=\frac{x}{2 b(n-1)\left(a x^{2}+b\right)^{n-1}}+\frac{2 n-3}{2 b(n-1)} J_{n-1}
\end{aligned}
$$ When $a=2$ and $b=1,$ $$
J_{n}=\frac{x}{2(n-1)\left(2 x^{2}+1\right)^{n-1}}+\frac{2 n-3}{2(n-1)} J_{n-1}
$$ Hence $$
I_{4}=\frac{1}{2}\left(J_{3}+J_{4}\right)
$$ Letâ€™s start with $$J_1= \int \frac{d x}{2 x^{2}+1}=\frac{1}{\sqrt{2}} \tan ^{-1}(\sqrt{2} x)+C_1 $$ $$
J_{2}=\frac{x}{2\left(2 x^{2}+1\right)}+\frac{1}{2} J_{1}=\frac{x}{2\left(2 x^{2}+1\right)}+\frac{1}{2 \sqrt{2}} \tan ^{-1}(\sqrt{2} x)+C_2
$$ $$
\begin{aligned}
J_{3} &=\frac{x}{4\left(2 x^{2}+1\right)^{2}}+\frac{3}{4} J_{2} \\
&=\frac{x}{4\left(2 x^{2}+1\right)^{2}}+\frac{3 x}{8\left(2 x^{2}+1\right)}+\frac{3}{8 \sqrt{2}} \tan ^{-1}(\sqrt{2} x)+C_3
\end{aligned}
$$ $$
J_{4}=\frac{x}{6\left(2 x^{2}+1\right)^{3}}+\frac{5 x}{24\left(2 x^{2}+1\right)^{2}}+\frac{5 x}{16\left(2 x^{2}+1\right)}+\frac{5}{16 \sqrt{2}} \tan ^{-1}(\sqrt2 x)+C_4
$$ Now we can conclude that $$
\begin{array}{c}
\displaystyle I_{4}=\frac{\tan \theta}{96}\left[\frac{8}{\left(2 \tan ^{2} \theta+1\right)^{3}}+\frac{22}{\left(2 \tan ^{2} \theta+1\right)^{2}}+\frac{33}{2 \tan ^{2} \theta+1}\right] +\frac{11}{32 \sqrt{2}} \tan ^{-1}(\sqrt{2} \tan \theta)+C
\end{array}
$$ Please let me know if there is any mistake.
Can we go further? Wish you all a happy and healthy New Year 2022 !","['integration', 'trigonometry', 'rational-functions', 'reduction-formula']"
4349307,How to show a statement of the form $p\Leftrightarrow(q\wedge r)$?,"I am trying to prove a statement of the form: \begin{gather}
p\Leftrightarrow(q\wedge r)
\end{gather} Therefore, I need to show the following two statements: \begin{gather}
\text{(a) }\;p\Rightarrow(q\wedge r)\\
\text{(b) }\;(q\wedge r)\Rightarrow p
\end{gather} Given the nature of the statement, my approach is to show the equivalent statements: \begin{gather}
\text{(a’) }\;\neg(q\wedge r)\Rightarrow\neg p\\
\text{(b’) }\;\neg p\Rightarrow\neg(q\wedge r)
\end{gather} What I am currently doing is this: To show (a’), I just show that $\neg q\Rightarrow\neg p$ and $\neg r\Rightarrow\neg p$ ; To show (b’), I just show that $\neg p\Rightarrow(\neg q\vee\neg r)$ . Unfortunately, I have two doubts regarding my approach: When showing (a’), is it enough with what I am doing or do I need to also show $(\neg q\wedge\neg r)\Rightarrow\neg p$ ? When showing (b’), is it enough with what I am doing or do I need to also show $\neg p\Rightarrow(\neg q\wedge\neg r)$ ? Thank you all very much for your time.","['elementary-set-theory', 'propositional-calculus', 'logic']"
4349310,Understanding of algebraic maps via number of inequalities in a semi-algebraic set,"Let $P_{(d,0,e)}(x) = dx^2 + e$ , and $Q_{(a,b,c)}(x) = ax^2 + bx+c$ be two polynomials in $\mathbb{R}[x]$ . Define an algebraic map $\phi:\mathbb{A}_{\mathbb{R}}^2 \times \mathbb{A}_{\mathbb{R}}^3 \to \mathbb{A}_{\mathbb{R}}^5$ that sends $((d,e),(a,b,c)) \in \mathbb{A}_{\mathbb{R}}^2 \times \mathbb{A}_{\mathbb{R}}^3$ to coefficents of multiplication of these two polynomials i.e. $(ad,bd,ae+cd,be,ce)\in \mathbb{A}_\mathbb{R}^5$ . The image of this map is described by $$\mathcal{M}_{P,Q} = \{(A,B,C,D,E) \in \mathbb{A}_{\mathbb{R}}^5: AD^2+B^2E=BCD \textit{ and  } C^2 \ge 4AE\}.$$ In general, we might have $P_v$ , and $Q_w$ , of degree at most $m$ and $n$ respectively, where $v$ and $w$ are vectors that can represent the polynomials (Note that just like the above example, we might have some forced zeros in $v$ and $w$ , but others are arbitrary numbers in $\mathbb{R}$ .). By Tarski-Seidenberg Theorem, we have that the image of the algebraic map $\phi$ is semi-algebraic i.e. it can be described by zeros of some polynomials and some inequalities. I'm wondering about the number of nonredundant inequalities that appear in $\mathcal{M}_{P,Q}$ . Based on a few examples that I checked, this number was one, like the example above or zero if the image of $\phi$ is closed. Is this true for an arbitrary $P_v$ and $Q_w$ ? $\textbf{Edit}$ : I would like to add two more examples to this post that shows if there is no fixed zero in $v$ , and $w$ then the problem is easier to handle. Example: Let $P_{(d,e)}(x) = dx+e$ , and $Q_{(a,b,c)}(x) = ax^2+bx+c$ then the map $\phi$ sends $$((d,e),(a,b,c)) \in \mathbb{A}_{\mathbb{R}}^2 \times \mathbb{A}_{\mathbb{R}}^3 \to (ad, bd+ae,cd+be,ce) \in \mathbb{A}_{\mathbb{R}}^4.$$ One can check that this map is surjective as every cubic polynomial in $\mathbb{R}$ has a real root corresponds to $dx+e$ and a degree 2 polynomial corresponds to $ax^2+bx+c$ . Example: Let $P_{(c,d)}(x) = cx+d$ and $Q_{(a,b)}(x)= ax+b$ then $\phi$ sends $$((c,d),(a,b)) \in \mathbb{A}_{\mathbb{R}}^2 \times \mathbb{A}_{\mathbb{R}}^2 \to (ac, ad+bc,bd) \in \mathbb{A}_{\mathbb{R}}^3.$$ Since not all degree 2 polynomials have real roots, we expect that this map is not surjective, so one can check that $$\mathcal{M} = \{(A,B,C)\in \mathbb{A}_{\mathbb{R}}^3: B^2-4AC \ge 0\}.$$ These two examples illustrate that if we don't have $\textbf{forced}$ zeros in $v$ and $w$ , then we are able to describe $\mathcal{M}$ . To be more precise, if $v$ and $w$ don't have forced zero then the image of $\phi$ is $m+n+1$ dimensional (it is not hard to justify this via roots of the target polynomial) and two cases happen: If $m$ and $n$ are odd simultaneously then the decomposition $P_vQ_w$ implies having at least two real roots, so $\phi$ is not surjective. In this case, we expect that the discriminant to appear as an inequality. If $m$ and $n$ are not odd simultaneously then this decomposition exists in $\mathbb{R}[x]$ . So, $\phi$ is surjective and we don't have any inequalities.","['algebraic-geometry', 'abstract-algebra', 'polynomials']"
4349317,"Reflection principle, brownian motion","Let $(B_t)_{t \ge 0}$ be a Brownian motion and define its maximal function on a interval $M_a^b = \sup_{a \le s \le b} B_s$ . By the reflection principle, I have shown that for $t \in (0,1)$ , we have $$\mathbb{P}(B_1 \le -1, M_{t}^1 \ge 1 \ |\   \mathcal{F}_t) = \mathbb{P}(B_1 \ge 3 \  | \ \mathcal{F}_t) = 1-\phi\left(\frac{3-B_t}{\sqrt{1-t}}\right), $$ which I hope is correct. Now, is it possible to calculate in a similar manner the following probability: $$\mathbb{P}(B_1 > -1, M_{t}^1 < 1, M_{1}^2 \ge 1 \ |\   \mathcal{F}_t) = \ ?$$ I started by conditioning on $\mathcal{F}_1$ and got to the point $2\mathbb{E}\left((1 - \phi(1-B_1))1_{\lbrace B_1 > -1, M_{t}^1 < 1\rbrace} \ | \ \mathcal{F}_t\right)$ , but I don't know how to proceed further. Edit. I've decided to check the case $t=0$ first. So using the joint distribution of $(B_1, M_0^1)$ , omitting the constant $2$ and taking $\phi(1-B_1)$ instead of $1-\phi(1-B_1)$ just for simplicity, I have the following integral to calculate $$\int_{0}^1 \int_{-1}^b \int_{-\infty}^{1-a} \frac{1}{\pi}(2b-a)e^{-\frac{(2b-a)^2}{2}}e^{-\frac{x^2}{2}} \mbox{d}x\mbox{d}a\mbox{d}b.$$ Is it correct? And is it possible to simplify this expression?","['stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
4349363,The definition of a free monoidal category,"I want to understand what a free monoidal category is, over a signature $\Sigma,$ as described just before Theorem 2.3 of Selinger . In particular, I am hoping to get a more explicit description of the free monoidal category (ideally something akin to Definition 4.4.4 of the statebox book ), and I would like to understand how Selinger's definition relates to some free/forgetful adjoint functors (so I guess knowing what type of category Selinger's monoidal signatures live in would be useful, i.e., what the arrows are between them). I heard that free monoidal categories can somehow be obtained from Petri nets, as described by Meseguer and Montanari . I would like to emphasize that I am interested in free monoidal categories over signatures which may involve morphism variables like $f: A \otimes B \rightarrow C,$ and I don't just want to focus on strict cases. I am similarly seeking understanding of the meaning of free symmetric monoidal categories and also free Markov categories over a signature. I would really appreciate any literature or insights people have on these topics.","['abstract-algebra', 'monoidal-categories', 'category-theory']"
4349365,What are irreducible $n$-times antisymmetrized representations?,"I came across the following statement while reading a string theory textbook: if $\boldsymbol{16}_s$ and $\boldsymbol{16}_c$ are the are respectively spinor and conjugate spinor representationsof $Spin(10)$ , we have the Clebsch-Gordan decomposition $$\boldsymbol{16}_s\otimes\boldsymbol{16}_c = [0]\oplus[2]\oplus[4]$$ where $[n]$ denotes the irreducible $n$ -times antisymmetrized representation of $Spin(10)$ , which from a field theoretic point of view correspond to $n$ -forms. I don't understand what exactly are those antisymmetrized representations. What is the general definition ? In what way does it corresponds to forms ?","['spin-geometry', 'representation-theory', 'differential-forms', 'differential-geometry']"
4349375,"Oksendal chapter 7, what does $E^x[f_1(X_{t_1})\ldots f_k(X_{t_k})]=E[f_1(X^x_{t_1})\ldots f_k(X^x_{t_k})]$ mean?","I am trying to read Oksendal's book ""Stochastic Differential Equations"" . In chapter 7, he consider processes like $$dX_t=b(X_t)dt+\sigma(X_t)dB_t$$ with the usual conditions ensuring unicity. Denote by $X^x_t$ the unique solution of the above equation such that $X_0=x$ . Let $Q^x$ denote the probability law of $X^x_t$ when $X_0=x$ and $E^x(\cdot)$ be the expectation with respect to $Q^x$ . Now this is claimed [...]Hence we have $$E^x[f_1(X_{t_1})\ldots f_k(X_{t_k})]=E[f_1(X^x_{t_1})\ldots f_k(X^x_{t_k})]$$ for all Borel functions $f_1,\ldots,f_k$ and all times $t_1,\ldots,t_k$ where $E=E_P$ denotes the expectation with respect to the probability law $P=P^0$ for $\{B_t\}_{t\ge0}$ when $B_0=0$ . First I don't understand what are the processes on the left hand side : Is $X_{t_1}=X^0_{t_1}$ ? Or $X_{t_1}=X^x_{t_1}$ ? Or something else? This is not clear to me. Second, how do you show the identity properly?","['stochastic-differential-equations', 'probability-theory']"
4349406,Can mode lie between mean and median?,The distribution is left-skewed if mean<median<mode. The distribution is right-skewed if mean>median>mode. Can mode lie between mean and median?,['statistics']
4349430,Is $A-\left(A-B\right)=B$ true?,"I am trying to prove that $A-\left(A-B\right)=B$ but I've arrived to this instead: $A-\left(A-B\right)=A\cap \overline{\left(A\cap \overline{B}\right)}=A\cap \left(\overline{A}\cup B\right)=\left(A \cap \overline{A} \right)\cup \left( A \cap B\right)=\emptyset \cup \left( A \cap B\right)=\left( A \cap B\right) \neq B$ Is this correct? The first step is to use a logical equivalence, then de Morgan's law, distributive laws and other logical equivalences, I think I am following the rules. If this happens to be correct should the equal sign have to change to a subset sign so the statement holds? Kind Regards","['elementary-set-theory', 'solution-verification']"
4349431,Vector fields and group actions,"In section 4 page 12 of the article Cohomologie équivariante et théorème de Stokes, there is a statement which says that if we consider  the action of the $S^1$ (parametrized by the angle $\phi$ ) on itself is by rotations. Then this action is generated by the vector field $\frac{\partial}{\partial \phi}$ . what does it mean in for a group action to be generated by a vector field ?","['vector-fields', 'group-actions', 'differential-geometry']"
4349492,ind the largest natural number $n$ for which $50\lfloor x\rfloor-\lfloor x\lfloor x\rfloor \rfloor=100n-27\lceil x\rceil$has a real solution for $x$.,"Find the largest natural number $n$ for which $$50\lfloor x\rfloor-\lfloor x\lfloor x\rfloor \rfloor=100n-27\lceil x\rceil$$ has a real solution for $x$ . I tried taking $x=a+r, 0\le r<1.$ We get $$50a-\lfloor (a+r)a\rfloor= 100n-27(a+1)$$ $$\implies 50a-a^2-\lfloor ra\rfloor= 100n-27(a+1)$$ $$\implies 100n+a^2+\lfloor ra\rfloor-27=77a$$ This is a quadratic in $a,$ so we get $$a^2-77a-27+100n+\lfloor ra\rfloor=0\implies 77^2-4\cdot (27+100n+\cdot\lfloor ra\rfloor )\text{ is square } $$ Hence $$ 4\cdot (27+100n+\lfloor ra\rfloor) \le 77^2$$ So $4\cdot (27+100n+\lfloor ra\rfloor) \le 77^2\implies n\le 58.$ I can't progress after this.","['elementary-number-theory', 'algebra-precalculus']"
4349525,Can we construct this figure in more elementary steps?,"The problem is given in image below. We're given a semicircle whose diameter is $AB$ and center $O$ and we want to construct the rectangle triangle $\triangle PCD$ with $CD \parallel AB$ , $C$ and $D$ on the circle. I've managed to find one solution with the help of some calculation. Let $$AB := 2R \text{ and } \angle BOD := d $$ then, my (long) calculations led to $$\cos (2d) = \frac{OP^2}{R^2}$$ which allowed me to find the following solution ( $PQ \perp OP, PX \perp OQ, OX=OY, YZ \perp OP$ and $DZ=DB$ ) I want to know if there is a simpler construction of the triangle and if there is an easy way to see that $\cos (2d) = \frac{OP^2}{R^2}$ without too many calculations","['geometric-construction', 'euclidean-geometry', 'geometry', 'plane-geometry']"
4349534,Building a particular function with directional derivatives but not differentiable,"I am interested in building a function $f:]0,1[^2 \rightarrow \mathbb{R}$ such that $f$ is continuous $f$ has directional derivatives everywhere and in every directions $\forall t\in ]0,1[$ , $$\frac{\partial f}{\partial x}(t,t)=0$$ $$\frac{\partial f}{\partial y}(t,t)=0$$ the function $g(t)=f(t,t)$ is non constant. It is clear that this function cannot be differentiable. Is it possible to build an $f$ like this? If yes, can we build an example? If no, is there a simple argument proving it? Thank you.",['multivariable-calculus']
4349625,Starting digits of $2^n$.,"Prove that for any finite sequence of decimal digits, there exists an $n$ such that the decimal expansion of $2^n$ begins with these digits.","['exponentiation', 'decimal-expansion', 'dynamical-systems']"
4349664,Is this operator between $\ell^{25}$ and $\ell^{12}$ continuous?,"Problem: Let us define $\ell^p$ as the space of sequences $(x_n)_{n \in \mathbb{N}}$ such that $\sum\limits_{n \in \mathbb{N}}|x_n|^p < +\infty$ with the usual norm $$\|x\|_p = \big( \sum\limits_{n \in \mathbb{N}}|x_n|^p \big)^{\frac 1 p}$$ Define $T:\ell^{25} \to \ell^{12}$ in the following way: $$T(x_1,\dots,x_n, \dots) = (x_1^{2018},\dots,x_n^{2018}, \dots)$$ I am asking if the map $T$ is continuous. Attempt: Let us fix $x \in \ell^{25}$ and let us study what happens for $y \in \ell^{25}$ with $\|y-x\|_p \leq 1$ . We have that $|y_n-x_n| \leq 1$ for all $n \in \mathbb{N}$ and thus $|x_n^{2018}-y_n^{2018}| \leq |x_n - y_n| K$ for $K > 0$ depending only on $\|x\|_p$ which has been fixed. This is because $a^n-b^n = (a-b)p(a, b)$ where $p$ is a polynomial on $a$ and $b$ . Thus $\|Tx-Ty\|_{12}^{12} \leq K^{12} \|x-y\|_{12}^{12}$ but this does not help me to conclude because we cannot control the $\mathcal{l}^{12}$ with the $\mathcal{l}^{25}$ norm. Trivial remark: the operator is not linear and thus we have no hope to prove that $T$ is Lipschitz continuous.","['lp-spaces', 'functional-analysis', 'real-analysis']"
4349716,How to solve coupled second order differential equations,"I have the following coupled differential equations: $$ 2y''- 3y' + 2z' + 3y + z = e^{2x}$$ $$y''- 3y' + z' + 2y - z = 0 $$ I'm not sure how to solve them as if I try $y = Ae^{\lambda x} $ and $z = Be^{\lambda x}$ , I only get one value for $\lambda$ ( $\lambda = 1$ ) so am not sure how to form a complementary function. Any suggestions? Thanks.","['calculus', 'systems-of-equations', 'ordinary-differential-equations']"
4349742,Binet's formula of Fibonacci Sequence,"In an attempt to find the $n^{th}$ Fibonacci number by Binet's formula , the derivation of this formula starts by using the quadratic equation $$x^2-x-1 = 0$$ If we try to find roots of this equation using quadratic roots formula, we find that we have 2 roots: $$ \sigma = \frac{1+\sqrt 5}{2}, \gamma= \frac{1-\sqrt 5}{2}$$ Then, we notice that: \begin{align}
x^2 = x+1 \\
x^3 = 2x+1 \\
\vdots\\
x^6 = 8x+5 \\
\vdots\\
\end{align} Question : why do we start with $x^2-x-1 = 0$ specifically and not with others? Is it because it just fulfill the need?","['elementary-number-theory', 'fibonacci-numbers', 'discrete-mathematics']"
4349744,"Theorem 9.41 Rudin, Principles of Mathematical Analysis","Rudin pp. 235-6 I am having trouble following Rudin’s proof of theorem 9.41.  The first inequality is clear to me: for any $(x,y)$ sufficiently close to $(a,b)$ , the difference in $D_{21}$ at these points can be made arbitrarily small.  However I do not understand how Rudin gets the next inequality.  The identity $\frac{\Delta(f,Q)}{hk}=hk(D_{21}f)(x,y)$ can only be said to apply for a point in the rectangle, $Q$ , not for every $(x,y)$ in $Q$ . Along the same line of reasoning it seems to me to be erroneous for Rudin to use the variable $b$ in (97), again, because the identity applies only to a specific $(x,y)$ . Can anyone lend clarification to these issues? EDIT: I believe that I have answered my own question and there is only one other problem that remains for me. Final question: Why, in equation (97), is there an $\leq$ sign instead of $<$ ? My answer: Rudin uses theorem 9.40, which guarantees the existence of an $(x,y)$ in the interior of $Q$ that satisfies (95), to rewrite $D_{21}f(x,y)$ in terms of $a,b,h,k,$ and the function, $f$ . He then applies limits twice in one inequality to get the desired derivatives.  Specifically, $$|D_{21}f(x,y)-A|<\epsilon$$ for all $(x,y)$ in $Q$ .  Now apply theorem 9.40 and hence write $$\bigg | \frac{\Delta(f,Q)}{hk}-A \bigg |=\bigg | \frac{1}{h} \cdot\frac{f(a+h,b+k)-f(a+h,b)-[f(a,b+k)-f(a,b)]}{k}-A \bigg |< \epsilon$$ for some $(x,y)$ in $Q$ . Now take the limit of the first two and last two terms in the large numerator with $k$ approaching zero.  This gives equation (97).  This time it seems that we cannot take a limit because we are not told explicitly that $D_{12}$ exists. So instead Rudin says that equation (97) holds for all small $h$ , and this is, incidentally, the derivative we want, $D_{12}$ . Theorem 9.41, Rudin, PMA and Theorem 9.40, Rudin, PMA","['partial-derivative', 'multivariable-calculus', 'real-analysis']"
4349761,Is this formula for the area of a triangle worth being published? $\frac{(a^2+b^2-c^2)^2\sec C\tan C}{8ab}$,"I created this trigonometric formula for finding the area of oblique triangles: $$R=\frac{(a^2+b^2-c^2)^2\sec C\tan C}{8ab}$$ where $a, b$ and $c$ are sides of the triangle, angle $C$ is the angle opposite to side $c$ , and $R$ is the area. Does this formula deserve being in textbooks or contests? And where can I publish this or find out if someone already discovered the formula? Also see this post Have I found a formula for the area of a triangle?","['area', 'geometry', 'publishing', 'triangles', 'trigonometry']"
4349793,Equilateral triangle and very peculiar inscribed tangent circles,"The problem is to find the length of the size of the equilateral triangle below I found one equation: Let $R$ be the radius of the big circle whose red arc touches the two purple circles. Let $A$ be the triangle vertex on which the red circle touches the green side. Let's call $B$ the other vertex of the green side. So in side $AB$ I've found this equation: $x = \sqrt 3 + 2\sqrt R$ and that's it. I know we can think about a couple homotheties between the circles but they didn't seem much productive to me in order to find a new equation for $x$ and $R$ . How to find a new equation or how to draw this figure? EDIT: I can't prove it, but apparently one of the inner tangents of the purple circles is parallel to the green side. EDIT2: It is quite similar to this question here in which we need to prove the internal tangent of the circles are parallel to one side of the triangle. Apparently it is not so trivial the application of the theorem mentioned in the answer to that question though.","['euclidean-geometry', 'homothety', 'geometric-construction', 'geometry', 'sangaku']"
4349796,"If $M$ is a $m$-dimensional smooth manifold, what is the rank of $\Omega^{m}(M)$ as a $\mathcal{C}^{\infty}(M)$-module?","It is clear to me that if $(U,\mathtt{x})$ is a chart of $M$ , then $\Omega^{m}(U)$ is a free $\mathcal{C}^{\infty}(U)$ -module of rank one. Is $\Omega^{m}(M)$ a free $\mathcal{C}^{\infty}(M)$ -module of rank one? More generally, is ${m}\choose{k}$ the rank of $\Omega^{k}(M)$ as a $\mathcal{C}^{\infty}(M)$ - module for $0\leq k \leq m$ ? I would also appreciate it if you could give me some reference text where I can look this up.","['differential-forms', 'smooth-manifolds', 'differential-geometry']"
4349809,Do there exist methods for determining the orbits of a group action on the cartesian product of sets?,"Suppose that we have some group $G$ acting on some set $\Omega$ . Then $G$ acts on $\Omega^n = \Omega \times \cdots \times \Omega$ ( $n$ times) naturally. I wonder, is there an iterative algorithm to determine orbit representatives for the action of $G$ on $\Omega^n$ using information from the action of $G$ on $\Omega$ ? Of course, there are algorithms to determine orbit representatives from any group action, but since the action of $G$ on $\Omega^n$ relates naturally to the action $G$ on $\Omega$ , I hoped that these orbits could be computed more efficiently than on some arbitrary set. Please note that I am not asking about computing the number of said orbits; I know there are questions here that already address that. I am looking for representatives.","['group-theory', 'group-actions', 'algorithms']"
4349836,Solving the ODE $\;\;y'^2-yy'+e^x=0$,"Solve, $$y'^2-yy'+e^x=0$$ By seeing it as a quadratic equation in $y'$ , we have $y'=\dfrac{y\pm\sqrt{y^2-4e^x}}{2}$ . But from here I don't know how to continue since both $y^2$ and $e^x$ are under square root. Another approach I've tried is using $y'=\frac1{x'}$ , $$\frac1{x'^2}-\frac{y}{x'}+e^x=0\;\Rightarrow\; e^x x'^2-y\;x'+1=0$$ I'm not sure if it helps.",['ordinary-differential-equations']
4349886,Toeplitz tridiagonal matrix with $0$s on main diagonal and $1$s on sub/superdiagonal has distinct eigenvalues [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question $$\begin{pmatrix}0&1&&&\\ 1&\ddots&\ddots&&\\ &\ddots&\ddots&\ddots&\\ &&\ddots&\ddots&1\\ &&&1&0\end{pmatrix}$$ has distinct eigenvalues. Why? Clearly, the eigenvalues should be reals. How to show they are distinct? It seems hard to factor the eigenpolynomial.","['eigenvalues-eigenvectors', 'toeplitz-matrices', 'matrices', 'linear-algebra', 'tridiagonal-matrices']"
4349932,Counting the Number of Closed Binary Operations That Are Commutative,"I'm working my way through the Section 5.4 exercises for the Grimaldi textbook, and the book's answer to one of the exercises doesn't make any sense to me.  I was hoping someone could help me understand how it reaches its given answer. Here's the problem: Let $|A| = 5$ .  How many closed binary operations on $A$ are commutative? The book gives the answer $5^{10}$ , but that makes little sense to me.  When I do the problem, I get $5^{15}$ . Here's how I reach $5^{15}$ . There are $5$ functions that have double pairs (i.e., $f(a,a),f(b,b),f(c,c),f(d,d),f(e,e)$ ), and each of those has $5$ possible answers.  Thus, there are $5^5$ potential arrangements for those $5$ inputs.  For the rest of the inputs (which should be only $20$ , since $25-5=20$ ), each combination of inputs corresponds with another combination if the function is commutative (i.e., $f(a,b) = f(b,a)$ ).  So we only have to match half (i.e., $10$ ) of the remaining possible combinations with answers.  That leaves us with $5^{10}$ potential arrangements for the remaining $10$ possible inputs.  The total number of commutative operations should therefore be $5^{5} \times 5^{10} = 5^{15}$ , not $5^{10}$ . Given this discrepancy, I thought I'd share my thoughts for scrutiny and see if I'm missing something. Any help or insight on this would be greatly appreciated.  Thank you!","['functions', 'combinatorics']"
4350017,Is this operator between $\ell^{25}$ and $\ell^{12}$ continuous?,"Problem: Let us define $\ell^p$ as the space of sequences $(x_n)_{n \in \mathbb{N}}$ such that $\sum\limits_{n \in \mathbb{N}}|x_n|^p < +\infty$ with the usual norm $$\|x\|_p = \big( \sum\limits_{n \in \mathbb{N}}|x_n|^p \big)^{\frac 1 p}$$ Define $T:\ell^{25} \to \ell^{12}$ in the following way: $$T(x_1,\dots,x_n, \dots) = (x_1^{2018},\dots,x_n^{2018}, \dots)$$ I am asking if the map $T$ is continuous. Attempt: Let us fix $x \in \ell^{25}$ and let us study what happens for $y \in \ell^{25}$ with $\|y-x\|_p \leq 1$ . We have that $|y_n-x_n| \leq 1$ for all $n \in \mathbb{N}$ and thus $|x_n^{2018}-y_n^{2018}| \leq |x_n - y_n| K$ for $K > 0$ depending only on $\|x\|_p$ which has been fixed. This is because $a^n-b^n = (a-b)p(a, b)$ where $p$ is a polynomial on $a$ and $b$ . Thus $\|Tx-Ty\|_{12}^{12} \leq K^{12} \|x-y\|_{12}^{12}$ but this does not help me to conclude because we cannot control the $\mathcal{l}^{12}$ with the $\mathcal{l}^{25}$ norm. Trivial remark: the operator is not linear and thus we have no hope to prove that $T$ is Lipschitz continuous.","['lp-spaces', 'functional-analysis', 'real-analysis']"
4350031,Integral form of a conditional expectation,"I have seen this line in a computation and I wonder if that makes sense : $\mathbb{E} (X | Y) = \int \mathbb{E} (X | Y = y) dP(Y = y)$ where P is a probability measure, $X,Y$ are random variables, so is $\mathbb{E} (X | Y)$ . But I'm not familiar with this notation. If this is right, how can I understand it ?","['conditional-expectation', 'measure-theory', 'probability-theory']"
4350045,Arriving at a particular solution of the ODE $y''-2y'-2y=\sin x$,"If we have an ODE: $(D^2-2D-2)y=\sin x$ then it may be observed that $y=\frac 1{13}(2\cos x -3\sin x)$ is a particular solution of the ODE. It can be found using undetermined coefficients method. I'm trying to find the particular solution using operator's method. I did the following: Let $a:=1+\sqrt 3, b:=1-\sqrt 3$ so that $D^2-2D-2=(D-a)(D-b)$ . \begin{align*}
y&=\frac 1{D-a}.\frac 1{D-b}\sin x\\&=\frac 1{2(D-a)}\Re\left[\frac 1{iD-ib}.(e^{ix}-e^{-ix})\right]\\&=\frac 1{2(D-a)}.\Re\left[\frac 1{-1-ib}e^{ix}+\frac 1{-1+ib}e^{-ix}\right]\\&=\frac 1{2(D-a)}\Re\left[ -2 \Re\left(\frac{e^{ix}}{1+ib}\right) \right]\\&=\frac {-2}{1+b^2}.\frac 1{2(D-a)}(\cos x+b\sin x).
\end{align*} etc.
Continuation is possible but this is getting tedious. I saw the following solution then and in the solution, I didn't understand the red highlighted parts: \begin{align*}
y&=\frac 1{\color{red}{D^2}-2D-2} \sin x\\&=\frac 1{\color {red}{-1}-2D-2}\sin x\\& =\frac 1{-2D-3}\sin x=-\frac 1{2D+3}\sin x\\&=-\frac {2D-3}{4\color{red}{D^2}-9}\sin x=-\frac {2D-3}{4(\color{red}{-1})-9}\sin x=\frac 1{13} (2D-3)\sin x.
\end{align*} I tried to prove the red highlighted part as follows: Suppose that in general we have $p(D)y=\sin x$ , where $p(D)$ is a polynomial operator in $D$ . If $p$ has only even degree terms then: $D^2\sin x=(-1)\sin x,..., (D^2)^k\sin x=(-1)^k\sin x$ . So $p(D)\sin x=p(-1)\sin x\implies \frac {\sin x}{p(D)}=\frac {\sin x}{p(-1)}$ , assuming $p(-1)\ne 0$ . It follows that $y=\color{blue}{\frac{\sin x}{p(-1)}}$ . Can anyone please help me to establish the result similar to the one highlighted in blue, in case $p$ happens to contain odd powered terms along with the even powered ones? Thanks.","['calculus', 'ordinary-differential-equations', 'real-analysis']"
4350118,When an ordinary partial derivative is a Frechet derivative on a Banach space?,"We have a function $p(x, \theta)\in \mathbb{R},\ x\in\mathbb{R},\ \theta\in\mathbb{R}^n$ . We can also consider $p(\cdot, \theta)$ to be a map from $\mathbb{R}^n$ to a Banach space of functions. For example, assuming $p(\cdot, \theta)\in \mathbb{L}^1(\mathbb{R})$ for each $\theta$ we have that $\hat p:\theta\to p(\cdot, \theta)$ is a map from $\mathbb{R}^n$ to $\mathbb{L}^1(\mathbb{R})$ . My question is about relation of the ordinary partial derivative $\frac{\partial p(x, \theta)}{\partial\theta}$ (assuming it is $\in\mathbb{L}^1(\mathbb{R})$ )  to the Frechet derivative of $\hat p:\theta\to p(\cdot, \theta)$ . When are they the same? Addition after the comments of Zerox: For the ordinary partial derivative for each $x$ $$
\lim_{d\theta\to0}\frac{\left|p(x,\theta+d\theta)-p(x, \theta)-\frac{\partial p(x, \theta)}{\partial\theta}\cdot d\theta\right|}{\Vert d\theta \Vert}=0
$$ For the Frechet derivative we have different convergence $$\lim_{d\theta\to0}\frac{\Vert p(\cdot,\theta+d\theta)-p(\cdot, \theta)-L(d\theta)\Vert_{\mathbb{L}^1}}{\Vert d\theta\Vert}=0$$ where $L(d\theta)$ is a continuous linear map from $\mathbb{R}^n$ to $\mathbb{L}^1(\mathbb{R})$ . The linear map $d\theta\to\frac{\partial p(\cdot, \theta)}{\partial\theta}\cdot d\theta$ from $\mathbb{R}^n$ to $\mathbb{L}^1(\mathbb{R})$ is continuous in the Banach norm. $$\left\|\frac{\partial p(\cdot, \theta)}{\partial\theta}\cdot d\theta\right\|_{\mathbb{L}^1}=\left\|\sum_i\frac{\partial p(\cdot, \theta)}{\partial\theta_i}d\theta_i\right\|_{\mathbb{L}^1}\leq\sum_i\left\Vert\frac{\partial p(\cdot, \theta)}{\partial\theta_i}\right\Vert_{\mathbb{L}^1}|d\theta_i|\leq\operatorname{max}_i\left\Vert\frac{\partial p(\cdot, \theta)}{\partial\theta_i}\right\|_{\mathbb{L}^1}\Vert d\theta\Vert_{\mathbb{L}^1}$$ So this map seems to be a candidate for $L(d\theta)$ , but i don't see why (or when) they have to coincide. Pointwise convergence (in $x$ ) doesn't imply $\mathbb{L}^1$ convergence and vice versa. Of course in the topology of pointwise convergence on the Banach space they would coincide, but i am interested in the $\mathbb{L}^1$ convergence. A special case of parametrized probability density functions: If there are no convenient conditions for the general case, then maybe there are some for this case? $$\int p(x,\theta)dx=1,\ p(x,\theta)\geq0\ \forall\theta$$ Upd: deleted the incorrect Scheffe's Lemma application. The case of dominated partial derivatives: Assume $\left|\frac{\partial p(x, \theta)}{\partial\theta_i}\right|\leq g(x)$ for some $g(x)\in \mathbb{L}^1(\mathbb{R})$ . Then by the multivariate MVT $$
\begin{split}
\frac{\left|p(x,\theta+d\theta)-p(x, \theta)-\frac{\partial p(x, \theta)}{\partial\theta}\cdot d\theta\right|}{\Vert d\theta\Vert}\leq&\frac{\left|\frac{\partial p(x, c)}{\partial\theta}\cdot d\theta\right|+\left|\frac{\partial p(x, \theta)}{\partial\theta}\cdot d\theta\right|}{\Vert d\theta\Vert}\\
\leq&\left\Vert\frac{\partial p(x, c)}{\partial\theta}\right\Vert+\left\Vert\frac{\partial p(x, \theta)}{\partial\theta}\right\Vert\leq2\sqrt n g(x)
\end{split}
$$ So the whole expression is also dominated by the $\mathbb{L}^1(\mathbb{R})$ function. By the dominated convergence theorem we have the convergence of the expression above in $\mathbb{L}^1$ , so $L(d\theta)=\frac{\partial p(x, \theta)}{\partial\theta}\cdot d\theta$ . If both derivatives exist, they have to be equal: One more observation. For any $\mathbb R \ni h_m\to0$ the existence of the Frechet derivative implies the $\mathbb L^1$ convergence to $0$ of the corresponding expression for each $i=1,\cdots,n$ . $$
\left\Vert\frac{p(\cdot,\theta+e_ih_m)-p(\cdot, \theta)}{h_m}-L(e_i)\right\Vert_{\mathbb{L}^1}\to0$$ Where $e_i$ is $i$ th vector of the standard basis. Then there exists a subsequence of $h_m$ , call it $\mathbb R \ni g_l\to0$ , for which the expression above converges pointwise a.e. to $0$ . $$\left|\frac{p(x,\theta+e_ig_l)-p(x, \theta)}{g_l}-L(e_i)(x)\right|\to0\ \textbf{a.e.}$$ But we also have for the ordinary partial derivative $$\left|\frac{p(x,\theta+e_ig_l)-p(x, \theta)}{g_l}-\frac{\partial p(x, \theta)}{\partial\theta_i}\right|\to0$$ So $L(e_i)=\frac{\partial p(\cdot, \theta)}{\partial\theta_i}$ and thus $L(d\theta)=\frac{\partial p(\cdot, \theta)}{\partial\theta}\cdot d\theta$ . Additions, corrections, indications of errors are still welcome.","['banach-spaces', 'analysis', 'real-analysis', 'frechet-derivative', 'functional-analysis']"
4350137,A problem about the area element in the Stokes' Theorem,"Given a vector field $F(x,y,z) = x^2 \hat i + 2x  \hat{j} + z^2 \hat{k}  $ and a curve $C: \text{the ellipse } 4x^2 + y^2 = 4 \text{ in the } xy- \text{plane}$ , I want to find $$\oint_{C} \vec F \cdot dr = \int\int_{S} \nabla \times \vec F \cdot \hat n d\sigma $$ via Stokes' Theorem. Here, $S$ is the surface on the $xy$ -plane bounded by the curve $C$ above. I found $$\nabla \times \vec F = 2 \hat{k}$$ and I take $\hat n = \hat k$ as the surface is lying on the $xy$ -plane. Thus, I end up with $$\oint_{C} \vec F \cdot dr = \int\int_{S} \nabla \times \vec F \cdot \hat n d\sigma 
 =\int\int_{S} 2 d\sigma = 2(\text{area of the ellipse}) = 4 \pi.
  $$ However, for the surface area element, we should have $$d \sigma = \frac{\mid \nabla f|}{|\nabla f \cdot \hat k |} $$ where $f$ is the level surface that comes from the the surface $4x^2 + y^2 = 4 $ in the $xy$ -plane. So, if I let $f(x,y,z)=4x^2 +y^2 -4$ for example, I end up with $\nabla f \cdot \hat k = 0$ such that I cannot write $d\sigma$ . What do I do wrong?","['multivariable-calculus', 'calculus', 'surface-integrals', 'stokes-theorem']"
4350170,Diagonalization of the Ricci curvature tensor in dimension 3,"It seems to be well-known that in dimension 3, we can simultaneously diagonalize the metric and the Ricci tensor at any given point (see https://mathoverflow.net/questions/80452/diagonalizability-of-the-curvature-operator ). I am unable to prove this myself, and so I am hoping for a proof of this fact or a source which provides the proof. I think the link above has a proof by counting dimensions, but I am looking for a more straightforward proof if there is one.",['differential-geometry']
4350195,What's wrong with using rectangles rather than triangles in Goursat's proof?,"I am reading the article On Goursat's Proof of Cauchy's Integral Theorem written by Harald Hanche-Olsen. In a historical remark, the author wrote that Goursat presented a proof in 1884 for the case of a simple closed curve, by dividing up the interior into small squares... Moore cleaned up the proof a bit, paying more careful attention to the treatment of the boundary curve. He also introduced the current idea of proof by contradiction, by subdividing and always selecting a part where the desired conclusion is maximally violated, and then applying the definition of the derivative at the resulting limit point. Pringsheim presented a more severe criticism of Goursat's treatment of the boundary curve in 1901. He pointed out that these problems disapper if the proof technique is applied to a simple geometric figure such as a triangle. Since some modern textbooks (such as Bak and Newman, Cartan, or Beardon) do use rectangles to present Goursat's proof, I don't understand what is the issue with rectangles. What is Pringsheim's criticism all about? Is his criticism justified? Is it OK to use rectangles?","['complex-analysis', 'math-history']"
4350260,How many ways to deal with the integral $\int_{0}^{\frac{\pi}{4}} \ln (\tan x) d x$ and $\int_{0}^{\frac{\pi}{4}} \ln (\sin x) d x$?,"After finding that $\displaystyle \int_{0}^{\frac{\pi}{2}} \ln (\tan x) d x =0$ in my post , I was curious about the value of the integral with different upper limit $\dfrac{\pi}{4} $ . The answer is surprisingly simple and elegant i.e. $$
\int_{0}^{\frac{\pi}{4}} \ln (\tan x) d x=-G \text {, }
$$ where $G$ is the Catalan’s constant. We first let $y=\tan x$ , then $d y=\sec ^{2} x d x=\left(1+y^{2}\right) d x$ and $I$ is converted to $$
I=\int_{0}^{1} \frac{\ln y}{1+y^{2}} d y.
$$ Applying a power series yields $$
\begin{aligned}
I &=\sum_{n=0}^{\infty}(-1)^{n} \int_{0}^{1} y^{2 n} \ln y d y \\
&=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{2 n+1} \int_{0}^{1} \ln y d\left(y^{2 n+1}\right) \\
&\left.=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{2 n+1}\left(\left[y^{2 n+1} \ln y\right]_{0}^{1}-\int_{0}^{1} y^{2 n+1} \cdot \frac{1}{y} d y\right)\right) \\
&=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{2 n+1}\left(-\int_{0}^{1} y^{2 n} d y\right) \\
&=-\sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n+1)^{2}} \\
&=-G.
\end{aligned}
$$ where $G$ is the Catalan’s constant. For the second integral in the question, we use the identity $$
\ln (\sin x)=\ln (\tan x)+\ln (\cos x), $$ we have $$\int_{0}^{\frac{\pi}{4}} \ln (\sin x) d x=\int_{0}^{\frac{\pi}{4}} \ln (\tan x) d x+ +\int_{0}^{\frac{\pi}{4}} \ln (\cos x) d x$$ By my post in Quora , $$\int_{0}^{\frac{\pi}{4}} \ln (\cos x) d x=\frac{G}{2}-\frac{\pi}{4} \ln 2.$$ Now we conclude that $$
\int_{0}^{\frac{\pi}{4}} \ln (\sin x) d x=-G+\left(\frac{G}{2}-\frac{\pi}{4} \ln 2\right)=-\frac{G}{2}-\frac{\pi}{4} \ln 2
$$ :|D Wish you enjoy the solution! Is there any other simpler method to deal with the integral?","['integration', 'trigonometry', 'catalans-constant', 'sequences-and-series']"
4350277,"If the linear system $|2P_0|$ had base points, an elliptic curve would be rational?","Hartshorne writes the beginning chapter IV.4 Elliptic curves Let $X$ be an elliptic curve over the algebraically closed field $k$ . Let $P_0 \in X$ be a point and consider the linear system $|2P_0|$ on $X$ . The divisor $2P_0$ is nonspecial, so by Riemann-Roch, this linear system has dimension $1$ . It has no base points, because otherwise the curve would be rational. I don't understand the last sentence here. How does the existence of base points imply that $X$ is rational? I can use Corollary 3.2 to see that $|2P_0|$ has no base points, because $\deg(2 P_0) = 2 \geq 2 \cdot g(X)$ . But what argument might Hartshorne have in mind regarding the rationality of $X$ ?","['algebraic-curves', 'algebraic-geometry', 'elliptic-curves']"
4350281,Lower bound for the size of a product-set,"I recently realised (rather late in life) that I don't have a good grasp of the following: Let $G$ be a finite non-abelian group and let $A, B$ be subsets of $G$ . (Neither $A$ nor $B$ is required to be a subgroup.) How small
can $|AB|$ be? By $AB$ here I mean the set $AB = \{ab : a \in A, \, b \in B\}$ . I impose the condition that $G$ be non-abelian because if $G$ is abelian then we have an answer to the question. This is known as Kneser's theorem and states that (in multiplicative notation): Let $G$ be a finite abelian group and let $A, B$ be subsets of $G$ .
Then $$|AB| \geqslant |A|+|B| - |H(AB)|,$$ where $H(AB) := \{g \in G : g(AB) = AB\}$ is the so-called stabiliser of the subset $AB$ . Is there anything known about this question? For example, does Kneser's theorem fail for non-abelian groups? Kneser's theorem, as I have stated it (and restricted to the setting
of finite groups), is (I think) equivalent to the statement that
appears on Wikipedia. There exist easy (and silly) answers to the question. For instance,
one could say that $|AB| \geq |A|, |B|$ and thus $|AB| \geq
    \max\{|A|, |B|\}$ . I am not interested in something like that.","['finite-groups', 'group-theory', 'combinatorics', 'additive-combinatorics']"
4350290,Evaluating line integral using The Stokes' Theorem,"I want to evaluate $$\oint_C (x-z) dx + (x + y) dy + (y+z) dz$$ where $C$ is the ellipse, in which the plane $z=y$ intersects the cylinder $x^2 + y^2 = 1$ , oriented counterclockwise as viewed from above. However, solution is somehow wrong. First, I say that the integral equals to $$\oint_{C} \vec F \cdot dr =\int\int_{S} \nabla \times \vec F \cdot \hat n d\sigma $$ where $F= (x-z)\hat i + (x+y)\hat j + (y+z)\hat k$ . Then, I found $\nabla \times \vec F = \hat i - \hat j + \hat k$ . Next, I wrote $$\hat n = \frac{\nabla f}{ |\nabla f|} = \frac{-\hat j + \hat k}{\sqrt{2}}$$ and $$d \sigma = \frac{|\nabla f|}{|\nabla f \cdot \hat n|}dxdy$$ where $f(x,y,z) = z-y$ . Finally, I got $$\int\int_{S} \nabla \times \vec F \cdot \hat n d\sigma  = \int\int_{x^2 +y^2 \le 1} (\hat i - \hat j + \hat k) \cdot (\frac{-\hat j + \hat k}{\sqrt{2}})dxdy = \int\int_{x^2 +y^2 \le 1} \frac{2}{\sqrt{2}} dxdy = \frac{2}{\sqrt{2}}\pi $$ but the solution must be just $2 \pi.$ Where is my mistake?","['multivariable-calculus', 'calculus', 'surface-integrals', 'stokes-theorem']"
4350305,I need help with this exercise on limits at infinity.,"The exercise I propose is the following. Let $a_0, a_1, ...., a_p$ be real numbers whose sum is equal to zero. Justify that $\lim \limits_{n \to \infty} (a_0\sqrt{n}+a_1\sqrt{n+1}+a_2\sqrt{n+2}+...+a_p\sqrt{n+p}) = 0$ I tried to get a common factor $\sqrt{n}$ and then try to group the terms together $a_0, a_1, a_p$ to add them.
However, I can't come up with anything concrete to give me an idea of the limit.
Any help?","['limits', 'calculus', 'sequences-and-series']"
4350306,$V[\sqrt{X}]\le\frac{V[X]}{E[X]}$ for non-negative $X$,"Let $X$ be a non-negative random variable with $0<E[X]<\infty$ . Then the following inequality holds: $$V[\sqrt{X}]\le\frac{V[X]}{E[X]}$$ where $V$ stands for the variance. This inequality is stated in a paper with no proof or reference. Here are my thoughts: the inequality is homogeneous so we may suppose WLOG that $V[X]=1$ or that $V[\sqrt{X}]=1$ . However I can't prove the inequality in either of these cases. Another line of thought is proving the equivalent inequality $$2E[X]^2 \leq E[X^2] + E[X]E[\sqrt X]^2.$$ By Jensen's inequality we already have $E[X]^2\leq E[X^2]$ and so it would suffice to show $E[X]^2 \leq E[X]E[\sqrt X]^2$ , i.e. $E[X]^{1/2}\leq E[\sqrt X]$ . Unfortunately this does not hold in general (by Jensen's inequality and strict concavity of the square root it implies that $X$ is degenerate).","['inequality', 'probability-theory']"
4350386,Prove or disprove that this paramater-dependent integral is continously differentiable,"How to prove (or perhaps disprove) that the following statement is correct: If $f: (-1,1) \to \mathbb{R}$ is continously differentiable, then $F(x) = \int_0^{\sqrt[3]{x}}t^3f(xt)dt$ is also continously differentiable on $(-1,1)$ . I know that if the upper bound of the integral was contionously differentiable, then $F$ would also be. But this is not the case here. I've tried proving this statement by definition of derivatives and finding a simple counterexample but without any luck.","['integration', 'real-analysis', 'continuity', 'multivariable-calculus', 'derivatives']"
4350394,Formulas for $\pi$ of the form $2\sum_{k=0}^\infty\binom{2k}{k}\frac{a^{2k+1}+b^{2k+1}+c^{2k+1}}{4^k(2k+1)}$,"Fourth edit :
I decided to start an infinite formulas challenge based on the formulas below to be interpreted as music: #InfinitePiChallenge: Rules: https://www.reddit.com/r/algorithmicmusic/comments/10cifzg/a_little_challenge/ Here is my interpretation of this challenge: https://www.youtube.com/watch?v=RdCDsSfe2_E Third edit : For those interested in the Sagemath-code to produce your own formula, given three natural numbers $x<y<z$ , it can be found here. I am sharing those formulas in public domain, for the benefit of all, if there is any: https://github.com/githubuser1983/generate_formulas_for_pi/blob/main/formulas_for_pi.ipynb First edit: I have found a method which allows one to plug in some numbers $a,b,c$ in this formula and get formulas for $\pi$ : $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( a \right )^{2k+1}+\left ( b \right )^{2k+1}+\left ( c \right )^{2k+1}}{4^k(2k+1)}$$ Some formulas generated this way are: $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{4}{65} \, \sqrt{13} \sqrt{5} \right )^{2k+1}+\left ( \frac{17}{26} \, \sqrt{2} \right )^{2k+1}+\left ( \frac{9}{130} \, \sqrt{13} \sqrt{5} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{261}{47965} \, \sqrt{181} \sqrt{53} \sqrt{2} \right )^{2k+1}+\left ( \frac{2071}{47965} \, \sqrt{53} \sqrt{5} \sqrt{2} \right )^{2k+1}+\left ( \frac{1309}{47965} \, \sqrt{181} \sqrt{5} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{931}{96050} \, \sqrt{113} \sqrt{85} \right )^{2k+1}+\left ( \frac{2061}{19210} \, \sqrt{85} \right )^{2k+1}+\left ( \frac{1781}{19210} \, \sqrt{113} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{19}{2210} \, \sqrt{85} \sqrt{65} \sqrt{2} \right )^{2k+1}+\left ( \frac{32}{1105} \, \sqrt{85} \sqrt{13} \right )^{2k+1}+\left ( \frac{53}{2210} \, \sqrt{65} \sqrt{13} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{96}{12665} \, \sqrt{149} \sqrt{85} \right )^{2k+1}+\left ( \frac{437}{25330} \, \sqrt{85} \sqrt{17} \sqrt{2} \right )^{2k+1}+\left ( \frac{351}{25330} \, \sqrt{149} \sqrt{17} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{283}{3770} \, \sqrt{145} \right )^{2k+1}+\left ( \frac{1037}{3770} \, \sqrt{13} \right )^{2k+1}+\left ( \frac{413}{18850} \, \sqrt{145} \sqrt{13} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{464}{3485} \, \sqrt{41} \right )^{2k+1}+\left ( \frac{1161}{6970} \, \sqrt{17} \sqrt{2} \right )^{2k+1}+\left ( \frac{889}{34850} \, \sqrt{41} \sqrt{17} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{704}{40001} \, \sqrt{181} \sqrt{13} \right )^{2k+1}+\left ( \frac{3781}{80002} \, \sqrt{17} \sqrt{13} \sqrt{2} \right )^{2k+1}+\left ( \frac{925}{80002} \, \sqrt{181} \sqrt{17} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{320}{42601} \, \sqrt{145} \sqrt{113} \right )^{2k+1}+\left ( \frac{697}{85202} \, \sqrt{113} \sqrt{65} \sqrt{2} \right )^{2k+1}+\left ( \frac{3069}{426010} \, \sqrt{145} \sqrt{65} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{18751}{1380634} \, \sqrt{113} \sqrt{41} \right )^{2k+1}+\left ( \frac{10323}{1380634} \, \sqrt{149} \sqrt{113} \right )^{2k+1}+\left ( \frac{17475}{1380634} \, \sqrt{149} \sqrt{41} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{21131}{3505970} \, \sqrt{181} \sqrt{65} \sqrt{2} \right )^{2k+1}+\left ( \frac{25023}{3505970} \, \sqrt{149} \sqrt{65} \sqrt{2} \right )^{2k+1}+\left ( \frac{10272}{1752985} \, \sqrt{181} \sqrt{149} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{12879}{2152090} \, \sqrt{181} \sqrt{145} \right )^{2k+1}+\left ( \frac{27721}{2152090} \, \sqrt{145} \sqrt{41} \right )^{2k+1}+\left ( \frac{24769}{2152090} \, \sqrt{181} \sqrt{41} \right )^{2k+1}}{4^k(2k+1)}$$ Other formulas are: $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{1}{21} \, \sqrt{7} \sqrt{3} \right )^{2k+1}+\left ( \frac{4}{21} \, \sqrt{7} \sqrt{3} \right )^{2k+1}+\left ( \frac{2}{3} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{1}{26} \right )^{2k+1}+\left ( \frac{3}{26} \, \sqrt{13} \sqrt{3} \right )^{2k+1}+\left ( \frac{3}{26} \, \sqrt{13} \sqrt{3} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{133} \, \sqrt{19} \sqrt{3} \right )^{2k+1}+\left ( \frac{31}{399} \, \sqrt{21} \sqrt{3} \right )^{2k+1}+\left ( \frac{5}{133} \, \sqrt{21} \sqrt{19} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{1}{91} \, \sqrt{13} \sqrt{7} \right )^{2k+1}+\left ( \frac{9}{91} \, \sqrt{13} \sqrt{7} \right )^{2k+1}+\left ( \frac{3}{7} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{399} \, \sqrt{19} \sqrt{7} \right )^{2k+1}+\left ( \frac{4}{57} \, \sqrt{21} \sqrt{7} \right )^{2k+1}+\left ( \frac{10}{399} \, \sqrt{21} \sqrt{19} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{1}{273} \, \sqrt{21} \sqrt{13} \right )^{2k+1}+\left ( \frac{16}{273} \, \sqrt{21} \sqrt{13} \right )^{2k+1}+\left ( \frac{4}{13} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{31}{546} \, \sqrt{13} \sqrt{7} \right )^{2k+1}+\left ( \frac{109}{546} \, \sqrt{7} \sqrt{3} \right )^{2k+1}+\left ( \frac{73}{546} \, \sqrt{13} \sqrt{3} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{4}{133} \, \sqrt{19} \sqrt{7} \right )^{2k+1}+\left ( \frac{9}{133} \, \sqrt{19} \sqrt{7} \right )^{2k+1}+\left ( \frac{6}{7} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{37}{798} \, \sqrt{21} \sqrt{3} \right )^{2k+1}+\left ( \frac{101}{798} \, \sqrt{19} \sqrt{3} \right )^{2k+1}+\left ( \frac{25}{798} \, \sqrt{21} \sqrt{19} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( -\frac{223}{5187} \, \sqrt{21} \sqrt{13} \right )^{2k+1}+\left ( \frac{311}{5187} \, \sqrt{19} \sqrt{13} \right )^{2k+1}+\left ( \frac{235}{5187} \, \sqrt{21} \sqrt{19} \right )^{2k+1}}{4^k(2k+1)}$$ My questions are: Q1) Are these formulas known or the method to generate them known? Q2) Is any of this formula of some usage to someone? :-) Whatever that means. Q3) Also if anyone knows of a way to further ""simplify"" the $a^{2k+1}+b^{2k+1}+c^{2k+1}$ to get some ""nicer"" formulas, that would also be nice to share. Thanks for your help. If there is interest, I can share the code and the method. Edit :
Here are the ""top ten"" formulas sorted by ""velocity of convergence"" to $\pi$ : $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{4} \right )^{2k+1}+\left ( \frac{1}{4} \, \sqrt{3} \sqrt{2} \right )^{2k+1}+\left ( \frac{1}{4} \, \sqrt{3} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{2}{15} \, \sqrt{5} \sqrt{3} \right )^{2k+1}+\left ( \frac{1}{6} \, \sqrt{3} \right )^{2k+1}+\left ( \frac{3}{10} \, \sqrt{5} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{6} \, \sqrt{3} \right )^{2k+1}+\left ( \frac{2}{15} \, \sqrt{5} \sqrt{3} \right )^{2k+1}+\left ( \frac{3}{10} \, \sqrt{5} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{8} \, \sqrt{3} \sqrt{2} \right )^{2k+1}+\left ( \frac{5}{28} \, \sqrt{7} \right )^{2k+1}+\left ( \frac{3}{28} \, \sqrt{7} \sqrt{3} \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{5} \, \sqrt{5} \right )^{2k+1}+\left ( \frac{1}{10} \, \sqrt{5} \sqrt{2} \right )^{2k+1}+\left ( \frac{1}{2} \, \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{10} \, \sqrt{5} \sqrt{2} \right )^{2k+1}+\left ( \frac{1}{5} \, \sqrt{5} \right )^{2k+1}+\left ( \frac{1}{2} \, \sqrt{2} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{1}{12} \, \sqrt{5} \sqrt{3} \right )^{2k+1}+\left ( \frac{7}{132} \, \sqrt{11} \sqrt{6} \right )^{2k+1}+\left ( \frac{1}{44} \, \sqrt{11} \sqrt{6} \sqrt{5} \sqrt{3} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{4}{91} \, \sqrt{13} \sqrt{7} \right )^{2k+1}+\left ( \frac{1}{14} \, \sqrt{7} \sqrt{3} \right )^{2k+1}+\left ( \frac{3}{26} \, \sqrt{13} \sqrt{3} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{5}{51} \, \sqrt{17} \right )^{2k+1}+\left ( \frac{1}{3} \right )^{2k+1}+\left ( \frac{3}{17} \, \sqrt{17} \right )^{2k+1}}{4^k(2k+1)}$$ $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( \frac{2}{77} \, \sqrt{21} \sqrt{11} \right )^{2k+1}+\left ( \frac{1}{22} \, \sqrt{11} \sqrt{5} \right )^{2k+1}+\left ( \frac{1}{14} \, \sqrt{21} \sqrt{5} \right )^{2k+1}}{4^k(2k+1)}$$ Second edit :
Since requested, here are a few formulas where $a,b,c,L$ are integers, sorted by ""error"" with $N=10$ and the top ten I could find:
where we have $\epsilon, x,y,z$ and $x,y,z$ are the numbers to generate the formula, $\epsilon$ is the error to $\pi$ for $N=10$ : 4.91689293680153e-6 1 2 4 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 17 \right )^{2k+1}+\left ( 63 \right )^{2k+1}+\left ( 63 \right )^{2k+1}}{\left ( 98 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000153102607067801 1 2 3 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 39 \right )^{2k+1}+\left ( 11 \right )^{2k+1}+\left ( 46 \right )^{2k+1}}{\left ( 66 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000209005609743684 1 2 6 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 1353 \right )^{2k+1}+\left ( 2987 \right )^{2k+1}+\left ( 4062 \right )^{2k+1}}{\left ( 5742 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000342678923108686 1 2 8 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 609 \right )^{2k+1}+\left ( 1159 \right )^{2k+1}+\left ( 1731 \right )^{2k+1}}{\left ( 2394 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000369975262812794 1 2 5 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 78 \right )^{2k+1}+\left ( 34 \right )^{2k+1}+\left ( 111 \right )^{2k+1}}{\left ( 153 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000467633890810504 1 2 10 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 5763 \right )^{2k+1}+\left ( 9917 \right )^{2k+1}+\left ( 15813 \right )^{2k+1}}{\left ( 21573 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000565682056867800 1 2 7 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 43 \right )^{2k+1}+\left ( 23 \right )^{2k+1}+\left ( 68 \right )^{2k+1}}{\left ( 92 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000787760002207705 1 2 12 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 8451 \right )^{2k+1}+\left ( 12089 \right )^{2k+1}+\left ( 21826 \right )^{2k+1}}{\left ( 29106 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000850493982005318 1 2 11 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 267 \right )^{2k+1}+\left ( 175 \right )^{2k+1}+\left ( 474 \right )^{2k+1}}{\left ( 630 \right )^{2k+1} 4^k(2k+1)}$$ 0.0000904264442818103 1 2 9 $$\pi = 2 \cdot \sum_{k=0}^{\infty}\binom{2k}{k} \frac{\left ( 309 \right )^{2k+1}+\left ( 209 \right )^{2k+1}+\left ( 559 \right )^{2k+1}}{\left ( 741 \right )^{2k+1} 4^k(2k+1)}$$ ​","['power-series', 'trigonometry', 'pi', 'sagemath']"
4350450,"Is $\pi\left(\bigcap_{n}A_n\right)=\bigcap_{n}\pi\left( A_n\right)$, when $\pi$ is a projection?","For me, $\Bbb N$ includes $0$ . I am referencing, yet again, this text, exercise $19$ , page $30$ . Let $K$ be a compact Hausdorff space, and $\phi:K\to K$ continuous and surjective - i.e. $(K;\phi)$ is a surjective topological dynamic system. Let $K^\omega=\prod_{n\in\Bbb N}K$ , and let $\psi:K^\omega\to K^\omega,\,(x_1,x_2,\cdots)\mapsto(\phi(x_1),x_1,x_2,\cdots)$ . By Tychonoff's theorem, $(K^\omega;\psi)$ is a topological system. Let $L=\bigcap_{n\in\Bbb N}\psi^n(K^\omega)\subseteq K^\omega$ . It is ""shown"" earlier in the book (Corollary $2.27$ , page $20$ ), that $L$ is the maximal (by set inclusion) surjective subsystem of $K^\omega$ . Show that $\pi(L)=K$ , where $\pi:K^\omega\to K$ is the projection onto the first component. I can do this fine, but I fear it is a bit unrigorous in equality $1$ : $$\pi(L)=\pi\left(\bigcap_{n\in\Bbb N}\psi^n(K^\omega)\right)\color{red}{\overset{1}=}\bigcap_{n\in\Bbb N}(\pi\circ\psi^n)(K^\omega)$$ Note that $\psi^n(x_1,x_2,\cdots)=(\phi^n(x_1),\phi^{n-1}(x_1),\cdots)$ , and $\pi\circ\psi^n$ therefore maps $(x_1,x_2,\cdots)\mapsto\phi^n(x_1)$ . As $\phi$ is a surjection on $K$ , $(\pi\circ\psi^n)(K^\omega)=K$ regardless of $n$ , from which it follows that $\pi(L)=K$ . However, they leave a hint suggesting more rigour is required: Hint: For $y\in K$ apply Lemma $2.26$ to the $\psi$ -invariant set $\pi^{-1}\{y\}$ . Lemma $2.2$ 6: Suppose that $(K;\phi)$ is a topological system and then $\varnothing\neq A\subseteq K$ is closed and invariant ( $\phi(A)\subseteq A$ ). Then there is a closed set $B$ , $\varnothing\neq B\subseteq A$ , with $\phi(B)=B$ . Explicitly, $B=\bigcap_{n\in\Bbb N_1}\phi^n(A)$ . Assuming for the moment that $\pi^{-1}\{y\}$ is indeed $\psi$ -invariant, then this lemma can ""solve"" the problem similarly (I am unsure why it is needed, but I tried to indulge them nonetheless): $$\begin{align}\pi(L)&=\pi\left(\bigcap_{n\in\Bbb N}\psi^n(K^\omega)\right)\\&=\pi\left(\bigcap_{n\in\Bbb N}\bigcup_{\mathbf{x}\in K^\omega}\psi^n(\mathbf{x})\right)\\&=\pi\left(\bigcap_{n\in\Bbb N}\bigcup_{y\in K}\psi^n(\pi^{-1}\{y\})\right)\\&\color{red}{\overset{2}{=}}\pi\left(\bigcup_{y\in K}\bigcap_{n\in\Bbb N}\psi^n(\pi^{-1}\{y\})\right)\\&=\pi\left(\bigcup_{y\in K}B_y\right)\\&=\bigcup_{y\in K}\pi(B_y)\\&=\bigcup_{y\in K}y\\&=K\end{align}$$ Why we need to go down that route, I am very unsure. It seems like a strange detour to take, so I feel like I'm missing their intended solution. Moreover, this approach introduces a second dubious equality, $2$ , that I don't know how to justify. My proof seems much shorter and more elegant, but also uses a potentially dubious equality in $1$ . Returning to the invariance of $\pi^{-1}\{y\}$ - I do not believe it is invariant: $$\pi^{-1}\{y\}=\{(y,x_1,x_2,\cdots):x_1,x_2,\cdots\in K\}=\{y\}\times K^\omega\\\psi(\pi^{-1}\{y\})=\{(\phi(y),y,x_1,x_2,\cdots):x_1,x_2,\cdots\in K\}=\{(\phi(y),y)\}\times K^\omega\not\subset\pi^{-1}(y)$$ Whenever $\phi(y)\neq y$ . What am I missing with regards to the alleged $\psi$ -invariance, and are the equalities $1,2$ correct? That is, is my proposed proof of $\pi(L)=K$ correct?","['solution-verification', 'set-invariance', 'elementary-set-theory', 'general-topology', 'dynamical-systems']"
4350461,Determine the stability of equilibrium point with Lyapunov function,"I want to determine the stability of $(0,0)$ (stable, asymptotically stable or unstable) in the nonlinear system: $$ \begin{aligned} 
   \dot{x} &=  y +       xy \\
   \dot{y} &= -y + \sin^2(x) \end{aligned} $$ My attempt I tried using the eigenvalues of Jacobian evaluated at (0,0), but since $$\det\left(J_{(0,0)}\right) = \det \begin{pmatrix} 0 & 1 \\ 0 & -1 \end{pmatrix} = 0$$ that criterion for evaluating stability does not work, so I then proposed the following Lyapunov function: $$V(x,y) = \dfrac{1}{2}x^2 + \dfrac{1}{4}y^4$$ then $$\dot{V}(x,y) = xy + x^2y - y^4 + y^3\sin^2(x)$$ Doing a simple analysis of regions, it is easy to see that $$\dot{V}(x,y) < 0, \ \mbox{ for } x > 0, \ y < 0$$ I understand that the Lyapunov stability criterion allows us to conclude that $(0,0)$ is stable if $\dot{V}(x,y) \leq 0$ and asymptotically stable if $\dot{V}(x,y) < 0$ for $(x,y) \neq (0,0)$ . My first question is about the previous result, since it is not clear to me whether to conclude the type of stability it is necessary to prove the results for every point $(x,y) \neq (0,0)$ in $\mathbb{R}^2$ or only for any $(x,y) \neq (0,0)$ within a neighborhood $U$ . The second question has to do with my analysis of the behavior of the derivative in a region: in the mentioned region $\{x>0,\ y <0\}$ , I could conclude that the derivative is strictly negative, however, for the region $\{x < 0 ,\  y < 0\}$ , the derivative can take positive values, can I state, just for the first region, that the (0,0) is asymptotically stable or due to the behavior not necessarily less than or equal to zero of the derivative at $\{x < 0, y < 0\}$ , should it be stated that the point is unstable? The problem is that I have done other Lyapunov stability exercises where it is very simple to verify that, for any point other than the equilibrium point, the derivative $\dot{V} \leq 0$ or $\dot{V} < 0$ and therefore, to conclude the stability of the equilibrium point is simple, however, this exercise has made me realize that maybe I am not understanding well the stability criterion or, I have problem finding a Lyapunov function that is useful for the analysis. I would appreciate any help you can give me to better understand and conclude my result.","['ordinary-differential-equations', 'lyapunov-functions', 'stability-in-odes', 'nonlinear-system', 'dynamical-systems']"
4350469,"Equivalent characterizations of Henselian Rings (Theorem 4.2 in James Milne's ""Étale Cohomology"")","I am stuck on a step in the proof of Theorem 4.2 in Chapter I of James Milne's ""Étale Cohomology"". The particular implication is (c) $\Rightarrow$ (d) . Let $X=\text{Spec} (A)$ , where $A$ is a local ring with the maximal ideal $m$ , and let $x$ be the unique closed point of $X$ . (c) If $f:Y\to X$ is a quasi-finite separated morphism, then $Y=Y_0\coprod Y_1\coprod\ldots\coprod Y_n$ , where $f(Y_0)$ does not contain $x$ and $Y_i$ are spectrums of local rings and are finite over $X$ for $i\geqslant 1.$ (d) For any étale morphism $g:Y\to X$ such that there is a point $y\in Y$ such that $f(y)=x,\ k(y)=k(x)$ there is a section $s: X\to Y.$ The proof states: Using (c) , we may reduce the question to the case of a finite
étale local homomorphism $A\to B$ such that $k(m)=k(n)$ , where $n$ is
the maximal ideal of $B$ . According to (2.9b), $B$ is a free $A$ -module, and since $k(n)=B\otimes_A k(m)=k(m)$ it must have rank 1,
that is, $A\approx B.$ I think everything makes sense if we add the separated hypothesis to (d) . As I understand the proof in this case, we are applying (c) , restricting to the $Y_i$ , and then we find at least one of them such that there is a $y\in Y_i$ with $f(y)=x,\ k(y)=k(x)$ , and finally use flatness to argue that some $Y_i$ is isomorphic to $X$ . But without this additional hypothesis, I don't see how (c) can be applied.","['etale-cohomology', 'hensels-lemma', 'algebraic-geometry']"
4350478,End space of non-compact 2-manifolds in terms of proper rays,"I am wondering if the classification of noncompact surfaces given by Ian Richards can be stated with proper rays instead of nested sequences of connected open subsets with compact boundary. Below I deliver some definitions needed to explain my question. Given a surface $\Sigma$ (i.e. a connected second-countable Hausdorff space locally homeomorphic to $\mathbb{R}^2$ ), a pre-end of $\Sigma$ is a nested sequence $\{U_{n}\}_{n\in \mathbb{N}}$ of connected open subsets of $\Sigma$ with compact boundary such that for all $n\in \mathbb{N}$ , $U_{n+1}\subset U_{n}$ and for every compact $K\subset \Sigma$ there exists $l\in \mathbb{N}$ with the property that $U_{l}\cap K=\emptyset$ . Two pre-ends $\{U_{n}\}$ and $\{V_{n}\}_{n\in \mathbb{N}}$ are equivalent if for any $i\in \mathbb{N}$ there exists $j\in \mathbb{N}$ such that $V_{j}\subset U_{i}$ and vice versa. The set of equivalence classes of pre-ends is denoted by $E(\Sigma)$ and its elements are the ends of $\Sigma$ . A topology is given to $E(\Sigma)$ by specifying a basis as follows: for any open subset $W\subset \Sigma$ whose boundary is compact, a basic open subset of $E(\Sigma)$ is given by $$W^*:=\{[U_{n}]\in E(\Sigma)\hspace{0.1cm}|\hspace{0.1cm}U_{l}\subset W \mbox{ for }l \mbox{ sufficiently large}\}.$$ The corresponfing topological space $E(\Sigma)$ is known as the end space of $\Sigma$ . A surface is said to be planar if all of its compact subsurfaces (possibly with non-empty manifold boundary) are of genus zero. An end $[U_{n}]$ is called planar if there exists $l\in \mathbb{N}$ such that $U_{l}$ is planar (equivalently, if there exists an open subset $W\subset \Sigma$ with compact boundary that is embeddable in $\mathbb{R}^2$ such that $[U_{n}]\in W^*$ ).
Analogously, an orientable end can be defined. Equivalently, the end space of $\Sigma$ can be described using proper rays (i.e. continuous maps $\gamma:[0,+\infty)\rightarrow \Sigma$ such that for every compact set $K\subset \Sigma$ , the set $\gamma^{-1}(K)$ is compact as well) as follows: two proper rays $\gamma_{1}$ and $\gamma_{2}$ are equivalent ( $\gamma_{1}\sim \gamma_{2} $ ) if for every compact $K\subset \Sigma$ there exist an $T>0$ such that $\gamma_{1}\big([T,+\infty)\big)$ and $\gamma_{2}\big([T,+\infty)\big)$ lie in the same path component of $\Sigma\setminus K$ . In this setting, the end space of $\Sigma$ is the quotient $$e(\Sigma):=\frac{\{\gamma:[0,+\infty)\rightarrow \Sigma\hspace{0.1cm}|\hspace{0.1cm}\gamma \mbox{ is a proper ray}\}}{\sim},$$ equipped with the topology determined by the following convergence notion (see User's answer below for a description of a basis of such topology): If $end(\gamma)$ is the equivalence class of a proper ray $\gamma:[0,+\infty)\rightarrow \Sigma$ , then a sequence of equivalence classes $\{end(\gamma_{n})\}$ converges to $end(\gamma)$ if for every compact set $K\subset \Sigma$ there exists a sequence of positive numbers $N_{n}$ such that, for $n$ sufficiently large, $\gamma_{n}\big([N_{n},+\infty)\big)$ and $\gamma\big([N_{n},+\infty)\big)$ lie in the same path component of $\Sigma\setminus K$ . The two previous definitions give rise to homeomorphic end spaces. Indeed, on one hand, given a pre-end $\{U_{n}\}$ , we can create a proper ray by picking points $x_n\in U_{n}$ and connecting $x_{n}$ with $x_{n+1}$ using a path entirely contained in $U_n$ . On the other hand, if $\gamma: [0,+\infty)\rightarrow \Sigma$ is a proper ray, we can construct a pre-end $\{U_{n}\}$ for which $\gamma\big([n,n+1]\big)\subset U_{n}$ . My question is whether or not the space of ends seen as a quotient of proper rays can distinguish the planar ends and the orientable ends.","['surfaces', 'geometric-topology', 'compactification', 'general-topology', 'algebraic-topology']"
4350481,$\left\{\begin{matrix} x^2 x'=\sin^2(x^3-3t) \\ x(0)=1 \end{matrix}\right.$,"I have to solve the following Cauchy's problem: $$
\left\{
  \begin{align}
    & x^2 x'=\sin^2(x^3-3t) \\
    & x(0)=1
  \end{align}
\right.
$$ First of all I've tried to identify if it is homogeneous, linear, exact, euler's ... but I can't recognise it. So I don't know which procedure to follow to solve it... I think that my problem is that inside the $\sin$ there are both $x$ and $t$ . Could anyone help me?","['cauchy-problem', 'ordinary-differential-equations', 'partial-differential-equations']"
4350492,Is the cyclic group $\langle x\rangle$ always a subgroup of $G$ for any $x\in G$?,"I have been thinking about the following: If $G$ is a finite group and $x\in G$ an element of order $n$ is then $\langle x\rangle$ always a subgroup of $G$ ? I have the definition that $\langle x\rangle=\{1,x,x^2,...,x^{{\rm ord}(x)-1}\}$ Do check this I know that I should check the following three points: $1_G\in \langle x\rangle$ . This is clear since $x^0=1$ . Stable under inverses: Let $u\in \langle x\rangle$ . Then $u=x^i$ for some $1\leq i \leq n$ . I claim that $u^{-1}=(x^{n-1})^i$ is the inverse of $u$ . Indeed $$x^i(x^{n-1})^i=x^i(x^{ni-i})=x^{ni}=(x^n)^i=1_G^i=1_G$$ And since $\langle x\rangle$ is abelian $u^{-1}$ is indeed the inverse of $u$ . Furthermore  it is clear that $u^{-1}\in \langle x\rangle$ . Stable under composition: let $u,v\in \langle x\rangle$ , then $u=x^i, v=x^j$ for some $1\leq i,j\leq n$ . Then $uv=x^ix^j=x^{i+j}\in \langle x\rangle$ According to this proof I think my claim should be correct but I'm not 100% sure, thats why I wanted to ask if someone could take a look. Thanks a lot.","['finitely-generated', 'group-theory', 'solution-verification', 'cyclic-groups']"
4350508,Is it possible to find the angles of an irregular quadrilateral when the area and side lengths are given? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question This was a question that I was asked by my math teacher at the end of last semester as a fun thought question and I have spent a while on it but I still cannot find an equation that would solve this. I have tried finding a system of equations with law of cosines and law of sines and Heron's formula but still can't find something. Please let me know if it is even possible. If it is, what would the process be?","['trigonometry', 'geometry']"
4350556,Likelihood the wordle of the day is sampled as a uniform distribution from the entire wordle word list,"I have been playing the wordle a lot recently. I noticed early on that misspellings on my part were 'accepted' as valid words, but that the answer was always a well known word. Recently I saw the list of all the 5 letter strings considered 'valid' by the wordle. Indeed, the majority of these are unknown to me. However, over the last 20 days only one wordle word was unknown to me. I am wondering what the likelihood is that the 'wordle of the day' set is equal to the 'accepted words' list? Is the wordle of the day generated from a uniform sampling of the accepted words list or a subset? For example, these are the first 10 wordle words in the wordle dictionary:
""aahed"",""aalii"",""aargh"",""aarti"",""abaca"",""abaci"",""abacs"",""abaft"",""abaka"",""abamp"" There are two sets, A and W . A contains all valid 5 letter words accepted by wordle. W contains the set of words chosen to be wordle of the day. We know W is a subset of A . I either know a word or I don't know it. K + U = 1 For the sake of argument, let's say that I recognize 10% of the words from set A . Thus Pr(K | A) = 0.1 . Of the last 20 wordles of the day, I was familiar with all but one. Thus Pr(K | W) = 0.95 with an N of 20. My question is - what is the likelihood W = A ?","['statistics', 'probability']"
4350594,Complex eigenvalues of a polynomial-valued matrix,"I'm working on the following problem: Let $A(z)$ be an $n \times n$ matrix whose entries $A_{ij}(z)$ are polynomials in $z$ . Let $\lambda_j(z), j = 1,\dots,n$ be the eigenvalues of $A(z)$ . If $\lambda_j(z_0)$ is a simple eigenvalue, show that $\lambda_j(z)$ is holomorphic in a neighborhood of $z_0$ . If $\lambda_j(z_0)$ has multiplicity $p$ , show that there is a representation $\lambda_j(z) = \sum_{k=0}^{\infty} c_k (z - z_0)^{\frac{k}{l}}$ for some $1 \leqslant l \leqslant p$ . Let $P(z,w) = \det (A(z) - wI)$ , then $P$ is a polynomial in $z,w$ . If $\lambda_j(z_0)$ is simple, then $P(z,\lambda_j(z_0)) = 0$ and $\frac{\partial P}{\partial w}(z_0, \lambda_j(z_0)) \neq 0$ . By the implicit function theorem, $\lambda_j(z)$ is holomorphic in a neighborhood of $z_0$ . For the second part, I'm trying to apply the IFT to the $(p-1)$ -th derivative of $P$ , but can't argue why $\lambda_j(z)$ admits the desired power series representation. Any insight would be appreciated.",['complex-analysis']
4350611,Intuition behind a hypergeometric distribution with standard deviation greater than the mean,"Say I've bought 100 tickets in a raffle of 10,000 tickets total. Assuming three tickets are randomly drawn without replacement from this raffle, we can represent the probability of different outcomes as a hypergeometric distribution with parameters $n = 3$ , $s = 100$ and $N = 10,000$ . In this case, the number of my tickets that I can expect to be drawn are: $$E(X) = n\left(\frac{s}{N}\right) = 0.03$$ With standard deviation of: $$\sigma(X) = \sqrt{n \left(\frac{s}{N}\right) \left(1 - \frac{s}{N}\right) \left(\frac{N - n}{N - 1}\right)} = 0.17$$ I'm trying to intuitively understand how this makes sense - our expected number of successes in this instance is $0.03 \pm 0.17$ . This means that negative successes lie in the range of probable outcomes, but by definition we can't have negative successes. Hence, are the expected outcomes positively skewed in some way? E.g. say each prize was worth €20, we'd have an expected return of $ € 0.60 \pm €3.40$ . But, since we can't have negative prizes, this actually lies in the range €0 - €4.00. This doesn't seem right but I'm trying to figure out where I'm going wrong with my assumptions and interpretations above. Many thanks.","['statistics', 'probability-distributions', 'probability']"
4350629,"""Absolute"" version of determinant","It is well known that for a matrix $A = (A_{i,j})$ , the determinant of $A$ is $$\det(A) = \sum_{\sigma \in S_n} \mbox{sgn} (\sigma)\prod_{i \in [n]} A_{i,\sigma(i)}.$$ Is there any way to manipulate the matrix to obtain, or any existing interpretation for, the ""absolute"" version of the determinant, which is $$\det^+(A) = \sum_{\sigma \in S_n} \prod_{i \in [n]} A_{i,\sigma(i)}?$$","['permutations', 'determinant', 'permanent', 'matrices', 'linear-algebra']"
4350643,Is the number of 3-dimensional slices slices of a 5-dimensional space less than the number of 3-dimensional slices of a 4-dimensional space?,"I’m only in high school, so I’m not certain whether I could have used better terminology to describe this. I’m initially thinking of it using dimensional analogy. I think, tentatively, that the question is similar to asking if the number of points on a line is greater than the number of points on a plane. I‘m not certain whether this question would have an equivalent answer to that of the question “Is the number of 3-d slices of a 5-d hypercube greater than the number of 3-d slices of a 4-d hypercube?”, so if you could tell me whether they’re the same (and if not, what the answer to that one is), I would also greatly appreciate it. I’m guessing that the solution may have something to do with the infinite number of real number coordinate possibilities (Aleph-1?) that can be chosen for each given new dimension. If that’s the case, maybe this question is really asking “Is Aleph-1 to the power of 5 greater than Aleph-1 to the power of 4?”
I’m not sure whether “Infinity” or “Aleph-1” is the right term to use in this context.","['elementary-set-theory', 'cardinals', 'geometry', 'infinity']"
4350747,A composite function problem,"The question is:
Suppose $$f(x) = x^2+1,$$ $$g(x) = 3-x.$$ Find the values for $x$ for such that $$(g\circ f)(x) = (f \circ g)(x).$$ I tried banging my head for one hour but my answer doesn't match the one given by the book which is $1/\sqrt{2}$ and $-1/\sqrt{2}$ .
I think the answer given in the book is wrong because I even tried putting the given answer in $(g\circ f)(x)$ and $(f \circ g)(x)$ and the two don't match up.
My answer: $$ x =\frac{3\pm\sqrt{-7}}{2} $$",['functions']
4350774,Help me understand easy (not for me) concepts in volume integral,"Keep looking at the page for an hour.
Still not sure how I can get the sloping surface of $x+y+z=1$ and integration ranges for $x, y, z$ . and why their range is different too. The book keeps throwing things at me without much explanation. Help me.","['integration', 'multivariable-calculus', 'bounds-of-integration']"
4350813,"Elliptic curves, $j$-invariant and example of $j(\Lambda)=0$","First, consider $\Lambda=\mathbb{Z}\bigoplus\omega\mathbb{Z}$ with $\omega$ the third root of unity in the upper half plane. I know that the lattice is such that $g_2(\Lambda)=0$ , where $g_2$ is the coefficient of the differential equation $$(\wp')^2=4\wp^3+g_2(\Lambda)\wp+g_3(\Lambda).$$ We know that for any $\tau\in\mathbb{C}$ $$g_3(\tau\Lambda)=\frac{1}{\tau^6}g_3(\Lambda).$$ We also know that $g_2(\tau\Lambda)=0$ for all $\tau$ . Does this mean that given a curve of the kind $y^2=4x^3+b $ we can map $\mathbb{C}/\Lambda$ to it by just taking the $\wp$ function of the lattice $\tau\mathbb{Z}\bigoplus\tau\omega\mathbb{Z}$ , $\tau=\sqrt[6]{\frac{g_3(\Lambda)}{b}}$ ? More in general, by the lifting properties we know that the only way two complex tori are isomorphic is if their lattices satisfy $\Lambda'=\tau\Lambda$ , in particular all the elliptic curves given before are isomorphic (obviously). We can also see that $$j(\Lambda)=1728\frac{g_2(\Lambda)^3}{g_2(\Lambda)^3-27g_3(\Lambda)^2}=j(\tau\Lambda),$$ so essentially it is invariant under isomorphisms of tori. Is this the motivation behind the definition of modular form(function), which is an equivalent condition for the above homogeneity condition? Another question is:
Is it possible to show, in a not too sophisticated way, that the converse also holds, hence that the $j$ -invariant is essentially injective up to isomorphism of lattices, without using similar results about the corresponding elliptic curves, and that $g_2$ and $g_3$ are surjective once we know the surjectivity of $j$ (which I have shown)?","['complex-analysis', 'modular-forms', 'algebraic-geometry']"
4350820,Covariant derivative of horizontal lift,"Suppose $\pi\colon (\tilde{M},\tilde{g})\to(M,g)$ is a Riemannian submersion.
If $Z$ is a vector field on $M$ , denote its horizontal lift by $\tilde{Z}$ .
Now, consider a curve $\gamma$ on $M$ starting at $p$ . We can lift this curve to a horizontal curve $\tilde\gamma$ starting at some $\tilde{p}\in\pi^{-1}(p)$ - essentially by lifting the velocity vector field of $\gamma$ pointwise via the isomorphism $\mathrm{d}\pi_{\tilde{p}}|_{H_{\tilde{p}}}\colon H_{\tilde{p}}\to T_{\pi(\tilde{p})}M$ and then solving the flow equation by Picard-Lindelöff. If V is a vector (tensor) field along $\gamma$ then we can also lift it to a vector (tensor) field $\tilde{V}$ along $\tilde{\gamma}$ by attaching to each $\tilde{\gamma}(t)$ the vector (tensor) $\mathrm{d}\pi_{\tilde{\gamma}(t)}|_{H_{\tilde{\gamma}(t)}}^{-1}(V_{\gamma(t)})$ . Exercise 5.6 (b) in Lee's Riemannian manifolds shows that for lifts of vector fields $$
\tilde{\nabla}_{\tilde{X}}{\tilde{Y}} = \widetilde{\nabla_{X}{Y}} + \tfrac12[\tilde{X},\tilde{Y}]^{V}
$$ where the superscript $V$ denotes the projection onto the vertical tangent bundle. Question 1: Is there a corresponding statement for the covariant derivative along $\gamma$ and its lift? If I can locally extend the vector field $\gamma^{\prime}$ and $V$ downstairs then I can use Lee's formula for the lifts. Of course, that's not always possible. So my guess would be $$
\tilde{D_t}{\tilde{V}} = \widetilde{D_t{V}} + \tfrac12[\tilde{\gamma}^{\prime},\tilde{V}]^{V}
$$ but I don't know if a commutator of vector fields along a curve makes sense or how it acts on functions. Question 2: Is the following true at least for geodesics $\gamma$ downstairs? For those I would guess that the 'commutator' disappears and it should simply be: $$
\tilde{D_t}{\tilde{\gamma}^{\prime}} = \widetilde{D_t{\gamma^{\prime}}} = 0.
$$ Is this true?
That is, the lifted curve only has vertical curvature. Or in other words: Horizontal geodesics upstairs are horizontal lifts of geodesics downstairs. Edit: For what it's worth I can show that the horizontal part of $\tilde{D}_{t}\tilde{V}$ is the lift of $D_{t}V$ by showing that $\mathrm{d}\pi\circ\tilde{D}_{t}\tilde{V}$ fulfils the three defining properties of the covariant derivative along the curve $\gamma$ downstairs. Uniqueness of the covariant derivative operator then tells me that $$
\mathrm{d}\pi\circ\tilde{D}_{t}\tilde{V} = D_{t}V
$$ for all vector fields $V\in\mathfrak{X}(\gamma)$ . Or in other words: $$
(\tilde{D_t}{\tilde{V}})^{H} = \widetilde{D_t{V}}.
$$ This also shows that horizontal geodesics upstairs descend to geodesics downstairs.
Question 1 about the vertical part of $\tilde{D_t}{\tilde{V}}$ still remains open though.","['connections', 'vector-bundles', 'riemannian-geometry', 'differential-geometry']"
4350835,$\int_{-\infty}^{\infty} {\rm exp}\left(\frac{i b t - a}{t^2 + 1}\right) - {\rm exp}\left(\frac{i b}{t} - \frac{1}{t^2}\right) {\rm d}t$,"How to solve this integral? $$\int_{-\infty}^{\infty} {\rm exp}\left(\frac{i b t - a}{t^2 + 1}\right) - 
  {\rm exp}\left(\frac{i b}{t} - \frac{1}{t^2}\right) {\rm d}t\\ {\rm with}\, a>0,b\in \mathbb{R},i^2=-1$$ The integral converges only if both summands are considered together. The integral originates from the comments in this post .","['integration', 'residue-calculus', 'definite-integrals']"
4350861,Prove that $\mathbb R\mathrm{P}^n$ is orientable if and only if $n$ is odd,"I am trying to prove that: The real projective space $\mathbb R\mathrm{P}^n$ is orientable if and only if $n$ is odd. For do so, consider first the antipode map $\sigma:\mathbb R^{n+1}\to \mathbb R^{n+1}$ , $p\mapsto -p$ and denote $\sigma^\star$ its pullback. The $(n-1)$ -form in $\mathbb R^{n+1}$ : $$\Omega=\sum_{\alpha=1}^{n+1}(-1)^{\alpha+1}\, dx^1\wedge\ldots\wedge dx^{\alpha-1}\wedge dx^{\alpha+1}\wedge \ldots \wedge dx^{n+1}\qquad\qquad\qquad (\star)$$ induces a volume form in $S^n\subset\mathbb R^{n+1}$ and satisfies $$\sigma^\star_p\Omega_p=(-1)^{n+1}\Omega_p$$ for each $p\in S^n$ Now, suppose that $\mathbb R\mathrm P^n$ is orientable, then there exists a volume form $\Lambda$ in $\mathbb R\mathrm P^n$ . If $\pi$ is the quotient map $S^n\to\mathbb R\mathrm P^n$ then $\pi^\star \Lambda$ is a $n$ -form in $S^n$ and there must exists a smooth map $f:S^n\to\mathbb R$ such that $$\pi^\star \Lambda=f\Omega$$ in $S^n$ . Composing both sides of the last equation by $\sigma^\star$ and using $(\star)$ we obtain: $$\sigma^\star (\pi^\star \Lambda)=\sigma^\star (f\Omega)\Longleftrightarrow f\Omega=(-1)^{n+1}f\Omega$$ Since $f\ne 0$ in $S^2$ (why?) then $n$ must be odd. I am not able to prove the converse. Any help?","['differential-geometry', 'tensors', 'smooth-manifolds', 'orientation', 'projective-space']"
4350881,Is the set of the upper Riemann sums convex for an arbitrary bounded function $f(x)$?,"If $f$ is bounded on $[a,b]$ and $P= (x_0,x_1.\cdots,x_n)$ is a partition of $[a,b]$ , let $M_j = \sup_{x_{j-1}\le x \le x_j}\text{$f(x)$}$ . The upper Riemann sums of $f$ over $P$ is $S(P)= \sum_{j=1}^{n} M_j(x_j-x_{j-1}) $ . Now, let's consider the set of all $S(P)$ : $X_f$ = { $S(P)$ | for all possible $P$ }. Is $X_f$ convex for arbitrary bounded functions? If not, what conditions $f$ should have so that $X_f$ can be convex? By convex I mean: if $S(P_1) \in X_f$ and $S(P_2) \in X_f$ , then $\lambda S(P_1)+(1-\lambda)S(P_2) \in X_f$ for all $\lambda \in [0,1]$ .","['riemann-sum', 'riemann-integration', 'real-analysis']"
4350922,A Question about the Definition of Ordered Pair [duplicate],"This question already has answers here : Why do we accept Kuratowski's definition of ordered pairs? (8 answers) slightly different definition of an ordered pair (2 answers) The Hausdorff ordered pair definition (1 answer) Closed 2 years ago . I am self-studying set theory, following the book "" The Joy of Sets "". It says that an ordered pair $(a,b)$ is defined as the set $$\left\{\left\{a\right\},\left\{a,b\right\}\right\}.$$ Is this definition unique? Why cannot it be defined as $\left\{a,\left\{a,b\right\}\right\}$ or $\left\{a,\left\{b\right\}\right\}$ ?",['elementary-set-theory']
4350930,Special version of Tonelli’s theorem,"I am trying to prove this theorem. I have not find anything similar to it in the internet Special version of Tonelli’s theorem Assume that the function $f(x,u): [a,b] \times \mathbb{R} \to \mathbb{R},\,\, g(x, \xi): [a,b] \times \mathbb{R} \to \mathbb{R}$ are continuous, $f$ is bounded below, $g$ is convex in $\xi$ and satisfies $$\exists r>1,\, \exists C>0\,\, \text{such that}\,\, g(x,\xi) \ge C| \xi|^r,\,\, \forall (x, \xi) \in [a,b] \times \mathbb{R}.$$ Then there exists a minimizer of the functional $J[u] = \displaystyle\int_a^b (f(x,u(x)) + g(x,u'(x))) dx$ in the space $X= \{ u \in AC([a,b]); u(a)=\alpha, u(b)= \beta \}.$ Proof Since $f$ is bounded then there is a real number $m \in \mathbb{R}$ such that $m (b-a)\le f(x,u(x)), \quad \forall (x,u(x)) \in [a,b] \times \mathbb{R}$ . From the properties of $g$ we get $$m+ C \int_a^b |u'(x)|^r dx \leq J[u] \Rightarrow m+ C \| u'\|_{L^r[a,b]}^r \leq J[u]\,\,\, \forall u \in X.$$ We can see that $J[u]$ is bounded below and from the definition of the infimum there is a minimizing sequence $\{u_n\}_{n\in \mathbb{N}} \subset X$ such that $$\underset{n \to \infty}{\lim} J[u_n] = \inf \{ J[u] | u \in X \}> -\infty \,\, \text{ in } \mathbb{R}.$$ and hence, $\{ u_n'\}_{n \in \mathbb{N}}$ is uniformly bounded, i.e. there is $N>0$ such that $\forall n >N$ we have $$\| u'_n\|_{L^r[a,b]} \leq \left(\frac{J[u_N] -m}{c} \right)^\frac{1}{r}.$$ Now, since $\{u_n\}$ is equicontinuous, and uniformly bounded in $L^r[a,b]$ then according to Arzela-Ascoli theorem there is a subsequence $\{ u_{n_k} \}_{k \in \mathbb{N}}$ and $\overline{u} \in AC[a,b]$ such that $u_{n_k} \to \overline{u}$ uniformly, and $u'_{n_k} \to \overline{u}'$ in the sense of $L^r[a,b]$ . I am not sure of my last argument is right? I want to make it more rigorous. Although I found the general idea of the proof on page (140) in the book of Hansjörg Kielhöfer named ( Calculus of Variations
An Introduction to the One-Dimensional Theory with Examples and Exercises ) I have no idea about completing the proof of the theorem. Could you please help.","['calculus-of-variations', 'nonlinear-optimization', 'lp-spaces', 'real-analysis']"
4350932,"For Dirichlet's test, is it true that if $\ a_1=1\ $ then $\ \left\vert \sum_{n=1}^{\infty} a_n b_n \right\vert \leq M\ ?$","I think I might be gaining more understanding of Dirichlet's test visually. For Dirichlet's test, is it true that if $\ a_1=1\ $ then $\ \displaystyle\left\vert \sum_{n=1}^{\infty}  a_n b_n \right\vert \leq M\ ?$ I think this because $\ \displaystyle\left\vert \sum_{n=1}^{k}\ b_n \right\vert\ \leq M\implies\ \sum_{n=1}^{k}\ b_n\in\ B(0+0i,M)=\{\ \vert z\vert\leq M:z\in\mathbb{C}\ \}\ $ for every $\ k.\ $ Therefore it seems to me that if $\ a_1=1\ $ and $\ \{a_n\}\ $ is decreasing with $\ a_n\to 0,\ $ then the terms of $\ \displaystyle\sum_{n=1}^{k}  a_n b_n\ $ ought to also be ""bouncing around"" inside $\ B(0+0i,M).\ $ Is this picture correct? And if so is there a proof of this? Or is the proof of this covered in the proof of Dirichlet's test?","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4350941,Need some clarification for the proof that a martingale is a Brownian motion with change of time.,"Theorem 7.37 : Let $M (t)$ be a continuous martingale, null at zero, such that $[M, M ](t)$ is non-decreasing to $∞$ , and $τ_t:=\inf\{s : [M, M ](s) > t\}$ . Then the process $B(t) = M (τ_t )$ is a Brownian motion with respect to the ﬁltration $\mathcal{F}_{τ_t}$ . Moreover, $[M, M ](t)$ is a stopping time with respect to this ﬁltration, and
the martingale $M$ can be obtained from the Brownian motion $B$ by the
change of time $M (t) = B([M, M ](t))$ Proof. Let $M (t)$ be a local martingale. $τ_t$ deﬁned as in the statement are ﬁnite stopping times since $[M, M ](t) → ∞$ . Thus $\mathcal{F}_{τ_t}$ are well deﬁned. Note that $\{[M, M ](s) ≤ t\} = \{τ_t ≥ s\}$ . This implies that $[M, M ](s)$ are stopping times for $\mathcal{F}_{τ_t}$ . Since $[M, M ](s)$ is continuous $[M, M ](τ_t ) = t. Let X(t) = M(τ_t )$ . Then it is a continuous local martingale since $M$ and $[M, M]$ have the same intervals of constancy (see the comment following
Theorem 7.28). Since $M^2(t)-[M,M](t)$ is a martingale, we obtain $EX^2 (t) = E[X, X](t) = E[M, M ](τ_t ) = t$ . Thus $X$ is a Brownian
motion by Levy’s characterization. The second part is proven as
follows. Recall that $M$ and $[M, M ]$ have the same intervals of
constancy. Thus $X([M, M ](t)) = M (τ_{[M,M ](t)} ) = M (t)$ . There are two things I don't understand in this proof. First isn't $M(τ_{[M,M ](t)} ) = M (t)$ a consequence of the fact that $[M,M]$ is non-decreasing rather than the fact that "" $M$ and $[M, M ]$ have the same intervals of constancy"". Second I am not sure why $[X, X](t) = [M, M ](τ_t)$ . Indeed, if $\delta_n$ denotes the size of a partition, $$[X, X](t)=\lim\limits_{\delta_n\to0}\sum_{i=1}^n (X(t_{i+1})-X(t_i))^2=\lim\limits_{\delta_n\to0}\sum_{i=1}^n (M(\tau_{t_{i+1}})-X(\tau_{t_i}))^2$$ however it is not clear to me that this is the same thing as $[M,M](\tau_t)$ which I understand as the quadratic variation on a partition of the random interval $[0,\tau_t]$ .","['stochastic-processes', 'brownian-motion', 'probability-theory', 'martingales']"
4350964,Solve system of 2 equations with 3 unknowns,"We are given a triangle $ABC$ with sides $a, b, c$ respectively and for which the following relationships hold: $a^2+bc\sqrt 3  = b^2+c^2$ , $c^2+ba = a^2+b^2$ We want to prove that angle $B$ is right. I am trying to express sides $b$ and $c$ in relation to $a$ and then prove that they satisfy the Pythagorean theorem. By combining the two equations, I am getting: $b = \frac {c\sqrt 3+1}{2}$ Then I am plugging this expression into the second equation, in order to eliminate $b$ : $4a^2-2a(c\sqrt 3+1)-c^2+2c \sqrt 3 +1=0$ and I must now solve for $a$ in relation to $c$ but I am getting a complex expression, which, by no means, satisfies Pythagorean. I input the two initial equations in Wolfram and it gives as a solution (apart from the ones which are rejected): $b=2a$ and $c=a\sqrt 3$ which clearly satisfy Pythagorean, because $b^2 = 4a^2 = c^2+a^2$ . Any ideas?
Thank you!!","['calculus', 'systems-of-equations', 'linear-algebra', 'geometry']"
4350978,"Proving that $f=\{(x^n,x): x \in \mathbb{R}\}$ is a function for positive odd integers $n$","Question: Prove or disprove that, for any positive odd integer n, $f=\{(x^n,x): x \in \mathbb{R}\}$ is a function. I believe the set defines a function. My attempt: Let $n$ be a positive odd integer. Claim: $f$ defines a function from $\mathbb{R}$ to $\mathbb{R}$ . Note that if $x \in \mathbb{R}$ then, $x^n \in \mathbb{R}$ . Thus $f \subset \mathbb{R^2}$ . Let $y \in \mathbb{R}$ . Then, $(y,y^{1/n}) \in f$ . Thus, we have shown the existence of an element $x$ , such that $(y,x) \in f$ . Suppose that for some $y_1,y_2 \in \mathbb{R}$ , $(y,y_1^{1/n}),(y,y_2^{1/n}) \in f$ . Thus, $y_1^{1/n}=y_2^{1/n}$ . Thus $y_1=y_2.$ From 2 and 3, we conclude that $\forall y \in \mathbb{R}, \exists ! x \in \mathbb{R}, (y,x) \in f$ . Hence $f$ is a function. Since $n$ was arbitrary, $f$ is a function for any odd integer $n$ . Could someone tell me if it is correct? Please let me know if there are any points to improve on and if anything is incorrect. Thank you.","['elementary-set-theory', 'functions', 'solution-verification']"
4350993,Which special orthogonal groups are ambivalent?,"A group is ambivalent if every element is conjugate to its inverse. $SO(1)$ , the trivial group, is obviously ambivalent. $SO(2)\cong \mathbb{R}/\mathbb{Z}$ is not. $SO(3)$ is, however; any three-dimensional rotation is a rotation about some axis $A$ , and viewing the rotation from the other side of $A$ will present the rotation as occurring in the opposite direction (so any element of $SO(3)$ which exchanges the two ends of $A$ suffices for the conjugation). Similar reasoning shows that $A_5$ , the symmetry group of the icosahedron, must be ambivalent. What about other $SO(n)$ ?","['group-theory', 'geometry', 'rotations']"
4351046,"Find two graphs with the same score, but one is a tree and the other is not a tree","The question is pretty self-explanatory:
Find a tree and a non-tree which have the same graph score. (The score of the graph is a sequence of the degrees of the graph from smallest to the largest) I am thinking about one thing: A graph is a tree when it is cyclic and connected. So if I want to make a graph which is not a tree, I think I should use the acyclic property of the tree","['graph-theory', 'trees', 'discrete-mathematics']"
4351202,Calculate leftover volume of a drilled out cube,"Say you have a cube with sidelengths $2r$ , now you use a cylindrical drill with radius $r$ to hollow out the cube along the $x$ , $y$ and $z$ axes through the middle of the cube so that you're left with something like this , meaning we're left with the 8 corners of the cube which each resemble some kind of spike-like structure. I want to calculate the total volume $V$ of the leftover spikes. Since this is a symmetric problem we can calculate the volume $V_{spike}$ of 1 spike and multiply with 8 to get the full volume. Now, I can set up an integral and calculate the volume of 1 spike if we only use 1 drill (the area under a circle), just to simplify things at the start (using the result from here ): $$V_{spike\_1\_drill}=r^3 - r\int_0^r \sqrt{r^2-x^2} dx$$ $$V_{spike\_1\_drill}=r^3\left(1-\frac{\pi}{4}\right)$$ And then I get stuck when trying to add another drill, I just can't visualize how to set up the remaining integration functions and limits such that it interacts properly with what I already have up above. I don't know if it would be a better approach to calculate the volume of the drilled out volume instead, but then you still have the problem of layering things correctly so you don't include any overlaps. Any help/hints is appreciated.","['integration', 'geometry']"
4351221,Showing ${\rm Aut}(Q_{2^n})\cong{\rm Hol}(\Bbb Z_{2^{n-1}})$ for $n>3$,"This is part of Exercise 5.3.4 of Robinson's, ""A Course in the Theory of Groups (Second Edition)"" . According to this search , it is new to MSE. The second part is here: Automorphism group of the quaternion group For previous questions of mine on generalised quaternion groups, see here: Find the upper central series of $Q_{2^n}$. Showing ${\rm Aut}(D_{2^n})\cong{\rm Aut}(Q_{2^n})$ for $n\ge 4$. The Details: On page 37 of the book, Let $\lambda:G\to {\rm Sym}\, G$ and $\rho:G\to{\rm Sym}\, G$ be the left and right regular representations of a group $G$ . Then $G^\lambda$ and $G^\rho$ are subgroups of ${\rm Sym}\, G$ , as is ${\rm Aut}(G)$ . Now $g^\lambda g^\rho$ maps $x$ to $g^{-1}xg$ , so $g^\lambda g^\rho$ is just $g^\tau$ , the inner automorphism induced by $g$ . Consequently $$\langle G^\lambda, {\rm Aut}(G)\rangle =\langle G^\rho, {\rm Aut}(G)\rangle;$$ this subgroup of ${\rm Sym}\, G$ is known as the holomorph of the group $G$ , $${\rm Hol}\, G.$$ Elsewhere in the book, we have: $$D_{2^n}\cong \langle r,s\mid r^{2^{n-1}}, s^2, srs=r^{-1}\rangle$$ is the dihedral group of order $2^n$ and $$Q_{2^n}\cong\langle x,y\mid x^{2^{n-1}}, y^2=x^{2^{n-2}}, y^{-1}xy=x^{-1}\rangle$$ is the generalised quaternion group of order $2^n$ (defined for $n\ge 3$ ). The Question: Prove that ${\rm Aut}(Q_{2^n})\cong {\rm Hol}(\Bbb Z_{2^{n-1}})$ if $n>3$ . Thoughts: The answers to my previous question (linked to above) establish that $${\rm Aut}(D_{2^n})\cong{\rm Aut}(Q_{2^n})$$ for $n>3$ . It might help. By definition, we have $${\rm Hol}(\Bbb Z_{2^{n-1}})=\langle \Bbb Z_{2^{n-1}}^\lambda, {\rm Aut}(\Bbb Z_{2^{n-1}})\rangle.$$ Here $\Bbb Z_{2^{n-1}}^\lambda$ is the image of $\Bbb Z_{2^{n-1}}$ under $\lambda$ , i.e. , $$\Bbb Z_{2^{n-1}}^\lambda=\{ g^\lambda: x\mapsto g^{-1}x\mid g\in \Bbb Z_{2^{n-1}}\}$$ and it is well-known that $${\rm Aut}(\Bbb Z_{2^{n-1}})\cong U(2^{n-1}),$$ where $U(m)$ is the group of units modulo $m$ . (See Theorem 6.5 of Gallian's ""Contemporary Abstract Algebra (Eighth Edition)"" .) That's all I have there. In GroupNames , we have ${\rm Aut}(Q_{2^4})\cong \langle a,b,c\mid a^8=b^2=c^2=1, bab=a^3, cac=a^5, bc=cb\rangle\cong \Bbb Z_8\rtimes\Bbb Z_2^2$ . ${\rm Aut}(Q_{2^5})\cong\langle a,b,c\mid a^{16}=b^2=c^4=1, bab=a^{-1}, cac^{-1}=a^5, bc=cb\rangle\cong D_{32}\rtimes \Bbb Z_4$ . $\lvert{\rm Aut}(Q_{2^6})\rvert=512$ . $\lvert{\rm Aut}(Q_{2^7})\rvert=2,048$ . Please help :)","['automorphism-group', 'group-isomorphism', 'holomorph', 'group-theory', 'quaternions']"
4351237,Roots of $1+x+x^{2}/2!+...+x^{n}/n!$ are larger than $\frac{n}{2e}$,"I wish to prove that the absolute values of the roots of the polynomial $p(x)=1+x+x^{2}/2!+...+x^{n}/n!$ are between $n/2e$ and $2n$ . I was able to prove the upper bound using the following: Claim: If $a_{n}x^{n}+\dots+a_{1}x+a_0$ is a polynomial, then its roots are bounded from above by $2\max\left\{\left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}:\;0\leq i<n\right\}$ . It works perfectly, because $\frac{n!}{i!}<n^{n-i}$ , as one can see immediately by expanding the left hand side. To achieve the lower bound, I tried the following idea - if $x$ is a root of $p(x)$ , then $1/x$ is a root of $x^{n}p(1/x)$ . Thus I need to bound the roots of $q(x)=x^{n}+x^{n-1}+\dots+x/(n-1)!+1/n!$ from above by $2e/n$ . I tried to use the same claim, but now things are different, because now $\left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}=\left(\frac{1}{(n-i)!}\right)^{\frac{1}{n-i}}$ , which equals $1$ when $i=n-1$ , which is certainly not smaller than $e/n$ . Am I missing something? I really can't think of any other idea, or in other words, I'm not sure how I would use Rouche's theorem here, so any hints or references towards this lower bound would be very useful, thank you very much!","['complex-analysis', 'rouches-theorem', 'polynomials']"
4351241,"Coloring triangles of triangulations in $\mathbb{R}^2$ with permutations, s. t. opposing vertices get the same number","I wonder if it is always possible and if there is a known algorithm for the following problem: Given : A triangulation $\mathcal{K}$ of a domain $\Omega \subseteq \mathbb{R}^2$ with Lipschitz boundary
consisting of triangles $T_k$ with $\{\bar{T}_k\}_{k=0}^{k=N} = \Omega$ . We define the set of vertices $\mathcal{V}$ of the triangulation as the points $v_{k,l}$ in $\mathbb{R}^2$ being vertices of the triangles $T_k$ . Because my motivation comes from a numerical analysis setting, we ignore all weird corner cases. Every edge is straight and not curved. Every vertex belongs to at least one triangle. Every intersection of the interiors of two triangles is always empty. Every intersection of the closures of two triangles is either empty, consists of a vertex or the common edge of the two triangles. There are no hanging nodes (numerical analysis speak). Problem : Is it always possible to color with the numbers $0, 1, 2$ the vertices of the triangles in such a way, that opposing vertices of two triangles get the same number?
(Here opposing vertices of two neighbour triangles mean the two vertices not belonging to the common edge.) By coloring the vertices of the triangles, its meant to put the three different numbers $0, 1, 2$ into the three different corners of each of the triangles. The following picture shows the situation for an example triangulation, where pairs of opposing vertices get one of the three numbers $0, 1, 2$ . I have marked pairs of opposing vertices with different ""RGB colors"" here red, dark red, blue and dark blue.
These ""RGB colors"" are NOT part of the problem. On the left it can be seen that one can't simultaneously
color the vertices such that all triangles are equally oriented (pluses and minuses). The bottom triangle would get two times the same number to satisfy
the opposing vertex criterion, but three different numbers per triangle are required.
On the right the two criteria are satisfied. Questions : Is this a well known problem? What is the situation in dimension 3 or higher dimensions where one uses d-simplices? Are there known algorithms for this problem? What I've done : I haven't found a counter example yet. I haven't tried some random triangulation generator yet. I have written a small C++ program for finding possible orientation patterns for a triangulated $n$ -sided convex polygon. Looks like this is related to https://oeis.org/A001045","['euclidean-geometry', 'coloring', 'reference-request', 'combinatorics', 'algorithms']"
4351253,Changing the basis in diagonalization: why doesn't it work?,"I read the theorem  on Apostol Calculus II : Theorem $4.10$ Let $T : V \to V$ be a linear transformation, where $V$ has scalars in $F$ , and $\dim V = n$ . Assume that the characteristic polynomial of $T$ has $n$ distinct roots $\lambda_1,\dots, \lambda_n$ in $F$ . Then
we have: The corresponding eigenvectors $u_1,\dots,u_n$ form a basis for $V$ . The matrix of $T$ relative to the ordered basis $U = [u_1,\dots,u_n]$ is the diagonal   matrix $\Lambda$ having the
eigenvalues as diagonal entries: $$\Lambda = \text{diag}(\lambda_1,\dots,\lambda_n) $$ If $A$ is the matrix of $T$ relative to another basis $E = [e_1,\dots, e_n]$ then $$\Lambda = C^{-1}AC$$ where $C$ is the
nonsingular matrix relating the two bases by the equation $U = EC$ . But something went wrong when I applied it: I took the matrix $A= \begin{bmatrix}1 & 2 \\5 & 4\end{bmatrix}$ and I tried to find the matrix $C$ in $\Lambda =C^{-1}AC$ : First, I found the eigenvalues which are $6$ and $-1$ , then I chose the eigenvectors $\begin{pmatrix}2  \\5 \end{pmatrix}$ and $\begin{pmatrix}1  \\-1 \end{pmatrix}$ which then give me the matrix $C = U =\begin{bmatrix}2 & 1 \\5 & -1\end{bmatrix}$ if I choose for the $E$ mentioned in the theorem above the basis composed by the unit coordinate vectors. Then $C^{-1} = \frac{1}{7} \begin{bmatrix}1 & 1 \\ 5 & -2\end{bmatrix}$ which indeed gives me $$\Lambda  = C^{-1} A C =  \begin{bmatrix}
                              6 & 0 \\
                              0 & -1
                             \end{bmatrix}$$ which is the correct result. But then I tried to use a different basis instead of the one composed by the unit coordinate vectors, I chose $E = \begin{bmatrix}1 & 0 \\1 & 1\end{bmatrix}$ and I used for $U$ the same matrix as before as I think it should be done, so $U = \begin{bmatrix}2 & 1 \\5 & -1\end{bmatrix}$ , then, since $C = E^{-1}U$ and $C^{-1} = U^{-1}E$ , we have that $\Lambda = U^{-1}EAE^{-1}U$ . However, calculating it on Wolfram unfortunately doesn't return a diagonal matrix . Where did I make a mistake? Am I misapplying the theorem?","['matrices', 'change-of-basis', 'linear-algebra', 'linear-transformations', 'diagonalization']"
4351272,Limit of quotient of two Lebesgue-integrals,"Let $(\Omega,\mathcal{A},\mu)$ be a measure space with $0<\mu(\Omega)<+\infty$ and $f \in \mathcal{L}^\infty(\Omega,\mathcal{A},\mu,\mathbb{C})$ with $\|f\|_\infty>0$ , where $\|f\|_\infty$ denotes the essential supremum of $f$ . Show that $$ \lim_{n\to\infty} \frac{\int_\Omega |f|^{n+1}\,\mathrm{d}\mu}{\int_\Omega |f|^n\,\mathrm{d}\mu} = \|f\|_\infty.\\$$ Hint: Factor out a suitable power of $\|f\|_\infty$ in the numerator and in the denominator. My proof is nearly complete but I don't know what to do in the case of $\mu([|f|=\|f\|_\infty])=0$ . Just for notation purposes, for $y\in\mathbb{R}$ , the set $[|f|=y]$ is defined to be $\{x\in\Omega:\,|f(x)|=y\}$ . Analogously, we define $[|f|\le y],\;[|f|<y],\;[|f|\ge y]$ and $[|f|>y]$ . Here would be my (incomplete) proof : We start by using the given hint and write $$ \lim_{n\to\infty} \frac{\int_\Omega |f|^{n+1}\,\mathrm{d}\mu}{\int_\Omega |f|^n\,\mathrm{d}\mu} = \lim_{n\to\infty} \frac{\|f\|_\infty \int_\Omega {\left(\frac{|f|}{\|f\|_\infty}\right)}^{n+1}\,\mathrm{d}\mu}{\int_\Omega {\left(\frac{|f|}{\|f\|_\infty}\right)}^n\,\mathrm{d}\mu} = \|f\|_\infty \lim_{n\to\infty} \frac{\int_\Omega {\left(\frac{|f|}{\|f\|_\infty}\right)}^{n+1}\,\mathrm{d}\mu}{\int_\Omega {\left(\frac{|f|}{\|f\|_\infty}\right)}^n\,\mathrm{d}\mu} =: \star\\$$ Now, we want to use the dominated convergence theorem. For this, we define for $n\in\mathbb{N}$ the function $f_n:\Omega\to [-\infty,+\infty]$ by $$ f_n(x) = \left(\frac{|f(x)|}{\|f\|_\infty}\right)^n.$$ We know that $[|f|>\|f\|_\infty]$ is a $\mu$ -null set. For $x\in\Omega\setminus[|f|>\|f\|_\infty]$ we have $$ \lim_{n\to\infty} f_n(x) = \lim_{n\to\infty} \left(\frac{|f(x)|}{\|f\|_\infty}\right)^n =
\begin{cases}
   0 &\mbox{if}\;\; |f(x)|<\|f\|_\infty, \\
   1 &\mbox{if}\;\; |f(x)|=\|f\|_\infty.
\end{cases}
$$ Thus, $f_n \xrightarrow{n\to\infty} \mathbf{1}_{[|f|=\|f\|_\infty]}$ pointwise $\mu$ -almost everywhere. Since $f$ is measurable, we have for all $n\in\mathbb{N}$ that $f_n$ is measurable, too. Indicator functions are measurable and therefore $\mathbf{1}_{[|f|=\|f\|_\infty]}$ is measurable. For $n\in\mathbb{N}$ and $x\in\Omega\setminus[|f|>\|f\|_\infty]$ , we see that $$ |f_n(x)| = f_n(x) = \left(\frac{|f(x)|}{\|f\|_\infty}\right)^n \le \frac{|f(x)|}{\|f\|_\infty} \le 1 = |\mathbf{1}_\Omega(x)|.$$ And since $\mu(\Omega)<+\infty$ , we get $\int_\Omega |\mathbf{1}_\Omega|\,\mathrm{d}\mu = \mu(\Omega) < +\infty$ and hence, $\mathbf{1}_\Omega$ is an integrable function which dominates all $f_n$ on the complement of a $\mu$ -null set. One can simply show that $\lim_{n\to\infty} f_{n+1}(x) = \lim_{n\to\infty} f_n(x)\quad\forall x\in\Omega\setminus[|f|>\|f\|_\infty]$ . Now, we are ready to use the dominated convergence theorem (applied on the sequences $(f_{n+1})_{n\in\mathbb{N}}$ and $(f_n)_{n\in\mathbb{N}}$ ) and we get $$ \lim_{n\to\infty} \int_\Omega f_{n+1}\,\mathrm{d}\mu = \lim_{n\to\infty} \int_\Omega f_n\,\mathrm{d}\mu = \int_\Omega \mathbf{1}_{[|f|=\|f\|_\infty]}\,\mathrm{d}\mu = \mu([|f|=\|f\|_\infty]) \le \mu(\Omega) < +\infty.\\
$$ Thus, the sequences $(\int_\Omega f_{n+1}\,\mathrm{d}\mu)_{n\in\mathbb{N}}$ and $(\int_\Omega f_n\,\mathrm{d}\mu)_{n\in\mathbb{N}}$ converge both to $\mu([|f|=\|f\|_\infty])\in\mathbb{R}$ , so we are allowed to use the quotient rule for limits and therefore $$
   \star = \|f\|_\infty \lim_{n\to\infty} \frac{\int_\Omega f_{n+1}\,\mathrm{d}\mu}{\int_\Omega f_n\,\mathrm{d}\mu} = \|f\|_\infty \frac{\lim_{n\to\infty}\int_\Omega f_{n+1}\,\mathrm{d}\mu}{\lim_{n\to\infty}\int_\Omega f_n\,\mathrm{d}\mu} = \|f\|_\infty \frac{\mu([|f|=\|f\|_\infty])}{\mu([|f|=\|f\|_\infty])} = \|f\|_\infty.\\
$$ My question would be: What if $\mu([|f|=\|f\|_\infty])=0$ ? Then both sequences would converge to $0$ , so how would I solve this problem? Thank you in advance! :)",['measure-theory']
4351274,Does this summation $ \sum_{x=a}^b \frac{p(1-p)^x}{(1-p)^a-(1-p)^b} $ equal 1?,"I believe that I have found the PMF of a truncated geometric distribution, however I want to verify that this is a valid PMF by showing its sum is equal to 1. In the following PMF, the random variable x is bounded between a and b: $ P(X = x) = \frac{p(1-p)^x}{(1-p)^a-(1-p)^b}$ Given a, b, and p are all constants (a and b are both positive integers, and 0 < p < 1), is it possible to show that the summation is equal to 1: $\sum_{x=a}^b P(X=x) = 1$ ?","['statistics', 'summation', 'probability', 'random-variables']"
4351285,Is circle the only shape that can remain convex after folding?,"Here ""fold"" means ""fold a piece of paper (along a straight crease)"". The sketch below shows that one can always find a fold by which an ellipse or rectangle loses convexity. But it seems a circle remains convex no matter how the crease is chosen? I am not sure how to deal with a problem like this, where the shape is generic and a convenient coordinate system cannot be defined. Update : to be precise, the circle means ""disk"", which includes both the border and the interior. Same for all other shapes. Update Jan. 13 I am thrilled by the number of upvotes. Here is an interesting experiment. Starting simple, let's use an upright rectangle centered at the origin, and reflect it w.r.t. all creases passing the origin (the experiment can only use a finite subset of such creases). The area union of all reflected shapes appears to be a disk. This observation seems to allow the following general statement: a 2d shape, convex or not, transforms into a new shape by folding. The union of all new shapes is a disk . To be honest, this statement itself sounds like a question in need of a proof. But I feel it is highly related with the original question. So I update it here along with the Mathematica code for plotting the figure (). Enjoy! foldAlongMiddleAxis[mya_, mytheta_] := 
 Block[{a = mya, cs = Cos[mytheta], 
   ss = Sin[mytheta]},
  polPrime1 = 
   Polygon[{{cs, ss}, {cs, ss} + a {-ss, cs}, {-cs, -ss} + 
      a {-ss, cs}, {-cs, -ss}}];
  polPrime2 = Polygon[{{1, 0}, {1, a}, {-1, a}, {-1, 0}}]; 
  Graphics[{{Opacity[0], EdgeForm[Gray], polPrime2}, {Opacity[0], 
     EdgeForm[Gray], polPrime1}}, AspectRatio -> Automatic]]

plotAllFoldsAndTrajO[a_, n_] := Show[{
   Graphics[{LightPink, Opacity[0.9], EdgeForm[Gray], 
     Polygon[{{1, -a}, {1, a}, {-1, a}, {-1, -a}}]}],
   Table[foldAlongMiddleAxis[a, mytheta], {mytheta, 
     Range[0, 2 \[Pi], \[Pi]/n]}],
   ParametricPlot[{{Cos[\[Theta]], Sin[\[Theta]]} + 
      a {-Sin[\[Theta]], Cos[\[Theta]]}}, {\[Theta], 0, 2 \[Pi]}, 
    PlotStyle -> {Black, Thick}]
   }]

plotAllFoldsAndTrajO[5, 50]","['convex-geometry', 'geometry']"
4351316,Proving the scaling property of the Lebesgue measure using Dynkin's lemma,"Let $\lambda_1$ be the Lebesgue measure on $(\mathbb{R},\mathcal{B})$ where $\mathcal{B}$ is the Borel $\sigma$ -algebra on $\mathbb{R}$ . I would like to show that $\lambda_1$ has the scaling property, i.e. $\lambda_1(cB) = |c|\lambda_1(B)$ , for any $B \in \mathcal{B}$ and non-zero $c \in \mathbb{R}$ . I know this can be shown using the uniqueness theorems for measures; I am curious if and how it can be done using the following theorem: Let $X$ be a non empty set. If $\mathcal{D}$ is a $\pi$ -system in $X$ , $\mathcal{L}$ is a $\lambda$ -system in X and $\mathcal{D} \subset \mathcal{L}$ , then $\sigma(\mathcal{D}) \subset \mathcal{L}$ . My idea: Define $\mathcal{L} := \{A \in \mathcal{B} : \lambda_1(cB) = |c|\lambda_1(B)$ for non-zero $c \in \mathbb{R}\}$ $\mathcal{I} := \{(a,b]: -\infty<a<b\leq\infty \}$ I know that $\mathcal{I}$ is a $\pi$ -system and that $\mathcal{I} \subset \mathcal{L}$ . So I just need to show that my $\mathcal{L}$ is a $\lambda$ -system, whence $\mathcal{B} = \sigma(\mathcal{I}) \subset \mathcal{L}$ and the scaling property holds true for all Borel sets. $\mathcal{L}$ is a called a $\lambda$ -system if: (i) $\emptyset \in \mathcal{L}$ (ii) $a \in \mathcal{L} \implies A^{c} \in \mathcal{L}$ (iii) If $A_1,A_2,... \in \mathcal{L}$ are pairwise disjoint then $\cup_{n=1}^{\infty}A_n \in \mathcal{L}$ I believe (i) and (iii) are true but I am not sure if (ii) is true. Question: Is (ii) above true for my $\mathcal{L}$ ? If so, how would one show that? If not, what is a counter example?","['measure-theory', 'lebesgue-measure']"
4351351,Why does gimbal lock occur “in two circles”?,"Let $S^1=ℝ/2\pi ℤ$ . Consider the Euler angle parametrization $$
T^3 \to SO(3),\\\ (ξ, υ, ζ)\mapsto R^Z_{ζ}R^Y_{υ}R^X_{ξ},
$$ where $T^3\cong S^1\times S^1\times S^1$ is the 3-torus and $$
R^X_ξ=\begin{pmatrix}1&0&0\\\ 0& \cos ξ&-\sin ξ\\\ 0& \sinξ &\cos ξ\end{pmatrix}
$$ represents the rotation around the $x$ -axis etc.
This map has singular values whenever $υ=\pm \pi/2$ , a phenomenon which is known as gimbal lock . It is well known that we cannot circumvent the existence of singular values with such a three-angle parametrization: If a continuous map $T^3\to SO(3) $ would have only regular values, it would have to be a covering map, because it's proper. But the only cover of $SO(3)\cong \mathbb RP^3$ is $S^3$ , contradiction. However, couldn't it be possible that there exists a different map $T^3\to SO(3)$ which posesses „less“ singular values? Calculating the image of the singular values $S^1\times \{\pm \pi/2\}\times S^1$ , we get (unless I miscalculated) $$
\begin{pmatrix}0 & \sin(ξ-ζ) & \cos(ξ-ζ) \\\ 0 & \cos(ξ-ζ) & -\sin(ξ-ζ) \\\ -1 & 0 & 0\end{pmatrix},\qquad
\begin{pmatrix}0 & -\sin(ξ+ζ) & -\cos(ξ+ζ) \\\ 0 & \cos(ξ+ζ) & -\sin(ξ+ζ) \\\ 1 & 0 & 0\end{pmatrix},
$$ where $ξ, ζ$ range over $S^1$ .
This is homeomorphic to $S^1\sqcup S^1$ . Question Is there a continuous surjection $T^3 \to SO(3)$ whose (image of the) set of singular values is „topologically simpler“ than $S^1\sqcup S^1$ , e.g. by being of the form $S^1\times D$ or $D$ where $D$ is discrete? If not, is there a theorem putting qualitative restrictions on what
this subspace of $SO(3)$ can look like?","['orthogonal-matrices', 'differential-topology', 'differential-geometry']"
4351360,"$\zeta(1 + 2/x)$ has a strange, nearly linear behaviour","I was messing around with some infinite sums in $\ell^p$ spaces and I encountered a strange result: $\zeta\left(1 + \frac{2}{x}\right)$ looks like it is linear in $x$ for $x > 1$ ! A simple linear regression gives me $\zeta\left(1 + \frac{2}{x}\right)\approx 0.593413 + 0.499801 x$ . The greatest difference appears to be relatively small. Is this true? If so, how could I show this? And if not, why does it appear to be nearly linear?","['riemann-zeta', 'linear-approximation', 'analysis']"
4351364,"Prove or disprove: $a_n >0$, $\sum _{n=1}^\infty \ln(1+a_n)$ is convergent $\Rightarrow$ $\sum _{n=1}^\infty a_n$ is convergent.","We know that $\sum _{n=1}^\infty \ln(1+a_n)$ is convergent if $\sum _{n=1}^\infty a_n$ is convergent where $a_n >0$ for all $n\geq 1$ . This follows by using the inequality $\ln(1+x) \leq x$ for all $x\geq 0$ and the comparison test. I am trying to see if the converse is true, i.e., whether the convergence of $\sum _{n=1}^\infty \ln(1+a_n)$ implies the convergence of $\sum _{n=1}^\infty a_n$ .","['calculus', 'analysis', 'real-analysis']"
4351440,Is one of the roots of a linear equation $\infty$?,"Consider the quadratic $ax^{2}+bx+c=0$ . This equation is linear if $a=0$ . Suppose we write $x=\frac{1}{y}$ , we get $a+by+cy^{2}=0$ . Since $a=0$ , we get $y=-\frac{b}{c},0$ . Thus, we get two roots of the equation $ax^{2}+bx+c=0$ which are $x=\frac{-c}{b},\infty$ . Does this argument mean anything or have any significance in any branch of math or is it just one of the discrepancies of dividing by $0$ ?","['algebra-precalculus', 'quadratics', 'infinity']"
4351479,"If the number of triplet $(l,m,n)$ satisfying $1\leq l\leq m\leq n \leq 20$ is $p \choose q$ then least value of $p+q$ is?","If the number of triplet $(l,m,n)$ satisfying $1\leq l\leq m\leq n \leq 20$ is $p
\choose q$ then least value of $p+q$ is? My Approach: Case $1:$ $1\leq l=m=n \leq 20$ so there are such $20$ nuumber using $20 \choose 1$ Case $2:$ $1 \leq l=m<n\leq20$ so there are $20 \choose 2$ = $190$ ways Case $3:$ $1 \leq l<m =n\leq20$ so there are $20 \choose 2$ = $190$ ways Case $4:$ $1 \leq l<m<n\leq20$ so there are $20 \choose 3$ = $1140$ ways So total Number of such order Triplets is $1540$ That is $22 \choose 3$ please let me know if i made any mistake in calculating triplets","['permutations', 'combinations', 'combinatorics']"
4351509,Prove that cardinality of union of $2$ finite sets is less than or equal to the sum of their cardinality.,"So, here's what I thought of doing: $X$ and $Y$ are the 2 finite sets, with # $X=n$ and # $Y=m$ where # is cardinality. To prove: # $(X\cup Y) \leq$ # $X+$ # $Y$ I defined a function $h:X\cup(Y\setminus X)\rightarrow\{1,2...,n+m-k\}$ as \begin{equation*}
h(x)=\begin{cases}
          f(x) \quad &\text{if} \, x \in X \\
          g(x)+n \quad &\text{if} \, x \in Y\setminus X \\
     \end{cases}
\end{equation*} Where $f:X\rightarrow\{1,2...,n\}$ is a bijection and $g:(Y\setminus X)\rightarrow\{1,2...,m-k\}$ is another bijection, and $k=$ # $(Y\cap X)$ . $f$ is a bijection because of the finite set $X$ with cardinality $n$ . But I want to prove that $h$ is a bijection, for which I will need to prove that $g$ is a bijection as well. I am having a hard time figuring out how to prove that $g$ is a bijection.
Any help is appreciated.",['elementary-set-theory']
4351550,Intersection of perpendicular bisector and circle in a triangle.,"In $\triangle ABC$ , $\measuredangle C=2\measuredangle B$ . $P$ is a point in the interior of $\triangle ABC$ , that lies on the perpendicular bisector of $BC$ and the circle centred at $A$ that passes through $C$ . Show that $\angle ABP=30^{\circ}$ . Using the definition of point $P$ , $$PB=PC ~~\text{and}~~ AP=AC.$$ Let $\angle CBP=\alpha$ and $\angle ABP=\beta$ . Simple angle chasing leads to $\angle CAP=180^{\circ}-2\alpha-4\beta\;$ and $\;\angle BAP=\beta-\alpha.$ I am trying to prove, $~2\angle BAP=\angle CAP~$ since this would imply $\beta=30^{\circ}$ . There is probably a smart construction that I am unable to find. Also, dropping perpendiculars from $A$ to $CP$ and $P$ to $AB$ looks like a good attempt to reach the desired result.","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'plane-geometry']"
4351587,Tiling a square with 3:1 rectangles,"It is known that a square can be tiled with $n$ rectangles whose length is double their width for any $n > 4$ . In particular, no two rectangles can overlap and no part of any rectangle is outside the square. The rectangles can be of different size. I am now investigating the same problem for rectangles whose length is triple their width. Clearly if we can tile a square with $m$ rectangles then we can also tile it with $m+4$ rectangles using the ""building up"" method from the video. Also by placing the square into a $2 \times 2$ square grid (adding 3 additional squares), we can also tile it with $m+9$ rectangles. Using these two facts I was able to show that we can tile a square for any $n > 26$ . However I still don't know which $n \leq 26$ do not have a tiling (other than the trivial ones). How can I find them? I am also interested in the general version of this problem, ie., when the length of the rectangles is $k$ times their width.","['rectangles', 'geometry', 'tiling']"
4351636,What is the correct standard deviation when splitting a sample?,"I roll a four-faced die 1000 times, but I have 100 dies, so I seperate into 10 rolls of 100 each and tally the result. I want to calculate the standard deviation of the 0 count. As an example, here's a result: {0: 251, 1: 254, 2: 271, 3: 224} , $\mu = \frac{251}{1000} = 0.251$ {0: 30, 1: 24, 2: 26, 3: 20}
{0: 25, 1: 25, 2: 26, 3: 24}
{0: 22, 1: 22, 2: 27, 3: 29}
{0: 23, 1: 26, 2: 30, 3: 21}
{0: 24, 1: 20, 2: 30, 3: 26}
{0: 26, 1: 31, 2: 26, 3: 17}
{0: 22, 1: 23, 2: 32, 3: 23}
{0: 23, 1: 32, 2: 23, 3: 22}
{0: 27, 1: 28, 2: 22, 3: 23}
{0: 29, 1: 23, 2: 29, 3: 19} The first way I do it is by using the normal approximation: $$\sigma_1 = \sqrt{\frac{0.251*(1-0.251)}{1000}} = 0.0137$$ . The second way is to calculate the deviation of the 10 rolls, which gives: $$\sigma_2 = \sqrt{\frac{(0.3-0.251)^2+(0.25-0.251)^2+\cdots+(0.29-0.251)^2}{10}}=0.027$$ I tried changing and increasing both the total size and the size of the tally, but the results never approach each other. I think they are both consequences of the central limit theorem, and the discrepancy is due to sampling technique? Which is more correct, or are they both wrong? What's the right way to find $\sigma$ of 0 , or 1 , etc.? Thank you! Here's the Python code I used to generate the problem: import numpy as np
import collections

small = 100
big = 1000

die = np.random.randint(0,4,big)
diedict = collections.Counter(die)
print(dict(sorted(diedict.items()))) #the total tally
std1 = np.sqrt(diedict[0]/big*(1-diedict[0]/big)/big)

sumsquare=0
for i in range(0,big,small):
    print(dict(sorted(collections.Counter(die[i:i+small]).items()))) #the seperate rolls
    sumsquare += (collections.Counter(die[i:i+small])[0]/small-diedict[0]/big)**2

std2 = np.sqrt(sumsquare/(big/small))
print(std1,std2)

plot_histogram(diedict)","['statistics', 'central-limit-theorem', 'probability', 'sampling']"
4351640,Are integration and differentiation really mutually opposite?,"Scenario 1: Suppose, I have a function $f(x)$ . Now, let me add 5 to it: $$F(x):=f(x)+5$$ Now, let me subtract 5 from $F(x)$ : $$F(x)-5$$ $$f(x)+5-5$$ $$f(x)$$ If I add 5 to $f(x)$ , I get $F(x)$ . Again, if I subtract 5 from $F(x)$ , I get $f(x)$ . So, we can understand that addition and subtraction are mutually opposite processes. Scenario 2: Suppose, I have a function $f(x)$ . Now, let me differentiate it with respect to $x$ : $$\frac{d}{dx}f(x)=f'(x)$$ Now, let me find the indefinite integral of $f'(x)$ , $$\int{f'(x)dx}$$ $$f(x)+c$$ If I differentiate $f(x)$ , I get $f'(x)$ . Now, if I find the indefinite integral of $f'(x)$ , I get $f(x)+c$ . Comments: Integration and differentiation are not quite opposite processes, are they? If I had gotten $f(x)$ instead of $f(x)+c$ after finding the indefinite integral of $f'(x)$ , I think we could've said that they are opposite processes. Am I correct?","['integration', 'convention', 'calculus', 'derivatives']"
4351651,Stuck solving this differential equation,"I'm trying to solve this differential equation: $y' = 9x^2+y+4+3x(2y+1)$ My approach to the problem: First, I multiplied $3x$ by $(2y+1)$ , which brought me to this equation: \begin{align*}
    y' &= 9x^2+y^2+y+4+6xy+3x \\
    y' &= (3x+y)^2+(3x+y)+4
\end{align*} Then I tried replacing $(3x+y)$ with $u$ , so $y = u - 3x$ and $y' = u' - 3$ With this kind of replacement the equation then looked like this: \begin{align*}
    u' - 3 &= u^2 + u + 4 \\
    u' &= u^2 + u + 7 \\
    du &/ (u^2+u+7)=dx 
\end{align*} Problem: This led to some confusion because $u^2 + u + 7$ does not seem to have any rational solutions and there is no mention of complex numbers in the answer. What exactly I might be doing wrong here? Maybe I've picked the wrong path from the start? Would really appreciate any help. Answer to the differential equation:","['derivatives', 'ordinary-differential-equations']"
4351662,"If $f,g$ are measurable and $\Phi$ is continuous, then $\Phi(f(x),g(x))$ is measurable.","Let $E\subseteq\mathbb{R}^d$ be a (Lebesgue) measurable set and let $f,g$ be two measurable functions defined on E. I would like to show that if $\Phi$ is a continuous function on $\mathbb{R}^2$ , then the function $h:x\mapsto\Phi(f(x),g(x))$ is measurable. The proof remains unknown to me, but I can address the problem if it is only one-dimensional. Specifically, if $\Phi$ is a continuous function on $\mathbb{R}$ , then I can show that $\Phi\circ f$ is measurable. Indeed, since $\{\Phi<a\}$ is an open set $G$ , we can conclude that $\{\Phi\circ f<a\}=f^{-1}(G)$ is measurable. How about the two-dimensional problem? Does anyone have an idea? Thank you.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4351668,Finding the Bass-Serre tree of a given splitting over $\mathbb Z$ or $\{1\}$.,"Consider an amalgam $G \ast _A H$ , or an HNN extension $G \ast_A$ . For simplicity, suppose that $A = \{1\}$ or $A = \mathbb Z$ . I'd like to use find the Bass-Serre tree associated with such splittings. I am aware of the construction of the universal cover of a graph of groups given in Serre [1], though I am struggling to put this construction into practice and examples seem to be lacking in the literature. As a concrete example, consider the fundamental group of a torus $G = \pi_1(S^1 \times S^1) \cong \mathbb Z^2$ , split along a simple closed curve $\{z\} \times S^1$ via the Seifert-van Kampen Theorem. This represents $G$ as an HNN extension $G \cong \mathbb Z \ast_{\mathbb Z}$ . My question is, how can we explicitly construct the Bass-Serre tree for this splitting? I am working on a problem where being able to construct explicit examples of such trees will prove very helpful, so any guidance on this would be appreciated. Thanks! References [1] Serre, J. P. (1980). Trees . Springer, Berlin, Heidelberg.","['trees', 'group-theory', 'algebraic-topology']"
4351683,Distance between point and convex hull in high dimensions,"I am trying to develop an intuition for the properties of the convex hull of a set of points in high ( $d>20$ ) dimensions. Consider a set of $n$ data points which are iid distributed according to some simple distribution (e.g. uniform hypercube, multivariate normal with mean $\mathbf{0}$ and identity covariance matrix $\mathbf{I}_d$ , or similar). Now suppose we draw an $n+1$ 'th data point $\mathbf{x}$ from that same distribution. What can we say about the relationship between $\mathbf{x}$ and the convex hull of the first $n$ points? My expectation $^1$ is that as dimensionality increases, the distance between $\mathbf{x}$ and the convex hull should grow for fixed $n$ . I also expect the volume of the convex hull to, in some sense, shrink relative to the volume of the domain or something similar. To make this more concrete, I would like some expression (or bound) on the expected distance between $\mathbf{x}$ and the convex hull for some simple data distribution as a function of $n$ and $d$ . Does such an example exist (either analytic or numeric) which could aid with my intuition? Disclaimer: this is not my area of expertise, so even simple examples or half-answers would be very helpful. $^1$ Inspired by section 2.5 of The Elements of Statistical Learning where the authors demonstrate the curse of dimensionality (e.g. points tend to be further apart as dimensions increase, side-length of the subcube needed to capture a fraction r of the volume of the data increases with dimension).","['convex-hulls', 'geometry', 'machine-learning', 'linear-algebra', 'convex-analysis']"
4351709,Simplifying $10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 2\binom{37}{8} + 1\binom{38}{9}$,"In trying to solve a probability problem from an old math contest: https://artofproblemsolving.com/wiki/index.php/1987_AIME_Problems/Problem_13 I had reduced the crux of the problem to calculating/simplifying $$10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 
2\binom{37}{8} + 1\binom{38}{9},$$ which I'm not sure how to simplify further. Could anyone give me a hint? Thanks in advance. EDIT: Calvin Lin asks me to explain how I got my expression. The total number of ways to order $40$ distinct numbers is $40!$ , so that will be our denominator. So let's calculate the numerator. Without loss of generality let our numbers in some order be $1$ , $2$ , $\ldots$ , $39$ , $40$ . We are counting the total number of configurations where: $r_{20}$ is greater than the other first $29$ numbers i.e. $r_1$ , $r_2$ , $\ldots$ , $r_{18}$ , $r_{19}$ , $r_{21}$ , $r_{22}$ , $\ldots$ , $r_{29}$ , $r_{30}$ . $r_{20}$ is less than $r_{31}$ . So $r_{20}$ has to be at least $30$ and is at most $39$ . Let's go case by case: $r_{20} = 30$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $28$ , $29$ , hence $29!$ ways to select and order. Then there's $10$ choices for $r_{31}$ , and then $9!$ choices for the last $9$ numbers. $r_{20} = 31$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $28$ , $29$ , $30$ , hence $30 \cdot 29 \cdots 3 \cdot 2$ ways to select and order. Then there's $9$ choices for $r_{31}$ , and then $9!$ choices for the last $9$ numbers. And so forth $\ldots$ $r_{20} = 39$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $37$ , $38$ , hence $38 \cdot 37 \cdots 11 \cdot 10$ ways to select and order. There's only $1$ choice for $r_{31}$ and that's $r_{31} = 40$ , and again there's $9!$ choices for the last $9$ numbers. So our numerator is $$(29!)(10)(9!) + (30 \cdot 29 \cdots 3 \cdot 2)(9)(9!) + \ldots + (37 \cdot 36 \cdots 10 \cdot 9)(2)(9!) + (38 \cdot 37 \cdots 11 \cdot 10)(1)(9!) = (29!)(9!)\left(10 + 9{{30}\over{1}} + 8{{31 \cdot 20}\over{2 \cdot 1}} + 7{{32 \cdot 31 \cdot 30}\over{3 \cdot 2 \cdot 1}}  + \ldots + 1{{38 \cdots 30}\over{9 \cdots 1}}\right) = (29!)(9!)\left(10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}\right).$$ So the expression we want to calculate/simplify is $$10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}.$$ Again, any help would be well-appreciated.","['contest-math', 'summation', 'binomial-coefficients', 'combinatorics', 'probability']"
4351714,Recurrence Relations using Maple,"I wanted to know how can one find arbitrary number of terms of the non-linear recurrence (using software, like maple)such as $$a_{2n-1}=-\sum_{j=1}^{n}{n+j-1\choose 2j-2}a_{n+j-2}, \ a_{0}=-1$$ $$a_{2n}=-\sum_{j=1}^{n}{n+j\choose 2j-1}a_{n+j-1}.$$ I have tried something like the following code into maple, yet it doesn't yield anything useful, a := n -> rsolve({a(0) = -1, a(2*n) = -sum(binomial(n + j, 2*j - 1)*a(n + j - 1), j = 1 .. n), a(2*n - 1) = -sum(binomial(n + j - 1, 2*j - 2)*a(n + j - 2), j = 1 .. n)}, a(n), makeproc); . Edit :I know that there is the Mathematica recurrence table, but don't know how to get it working for this particular example. I have also tried the Rsolve as shown above, it works for some examples like the second-order linear recurrences but not for this one. The link for recurrence table:- https://reference.wolfram.com/language/ref/RecurrenceTable.html .","['recurrence-relations', 'discrete-mathematics']"
