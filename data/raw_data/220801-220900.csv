question_id,title,body,tags
4519048,Is there any method to compute $\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)$ other than complex numbers?,"In this couple of days, I need to know the high derivatives of $cos^kx$ whose power $k$ make the differentiation much harder.  Then I attempt to
use the identity $$
\cos x=\frac{1}{2}\left(e^{x i}+e^{-x i}\right),
$$ to expand it with Binomial expansion $$
\begin{aligned}
\cos ^{k} x &=\frac{1}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}e^{x(k-j) i} e^{-x i j} 
=\frac{1}{2^{k}} \sum_{j=0}^{k}\binom{k}{j} e^{x(k-2 j) i}
\end{aligned}
$$ Differentiating it by $n$ times yields $$
\begin{aligned}
\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) &=\frac{1}{2^k} \sum_{j=0}^{k}\binom{k}{j}[(k-2 j) i]^{n} e^{x(k-2 j) i} \\
&=\frac{i^{n}}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n} e^{x(k-2 j) i} \\
&=\frac{i^{n}}{2^{k}} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n}[\cos ((k-2 j) x)+i \sin ((k-2 j) x)]
\end{aligned}
$$ If $x$ is real , then comparing the imaginary and real parts on both sides yields \begin{equation}
\displaystyle \frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)=\left\{\begin{array}{ll}
\displaystyle \frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n}\cos((k-2j)x) \quad \textrm{ if n is even.}\\\displaystyle 
\frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin((k-2j)x)  \quad \textrm{ if n is odd.}
\end{array}\right.
\end{equation} For examples, When $n$ is even, $$
\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=\frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n}
$$ In particular, $$
\begin{aligned}
\left.\frac{d^{6}}{d x^{6}}\left(\cos ^{5} x\right)\right|_{x=0}&=\frac{(-1)^{3}}{2^{4}} \sum_{j=0}^{2}\binom{5}{j}(5-2 j)^{6} \\
&=\frac{1}{16}\left[5^{6}+5 \cdot 3^{6}+10 \cdot 1^{6}\right] \\
&=1205
\end{aligned}
$$ When $n$ is odd, $$
\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=0;
$$ $$\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) \right|_{x=\frac{\pi}{4} }= 
\frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin \frac{(k-2 j) \pi}{4} $$ Can we find its closed form without using the complex numbers?","['calculus', 'binomial-theorem', 'derivatives', 'complex-numbers']"
4519061,The sum of $n$ terms in $1 \cdot 2+2 \cdot 3+3 \cdot 4+\ldots$,"I am just confused, considering we can take $1 \cdot 2$ as the first term then we get the $n$ th term as $n(n+1)$ so the sum of $n$ terms would be $\frac{n(n+1)(2n+1)}{6}$ + $\frac{n(n+1)}{2}$ but let's assume $0 \cdot 1$ as the first term then the $n$ th term becomes $(n-1) \cdot n$ and so it's summation becomes $\frac{n(n+1) (2n+1)}{6} - \frac{n(n+1)}{2}$ but it's the same summation as above but the results are different what am I doing wrong?","['summation', 'recreational-mathematics', 'sequences-and-series']"
4519068,"Is $\sin^{-1}(\sin x) = x - \pi$ or $\pi - x$ for $x \in[\pi/2,3\pi/2]$?","Consider $\sin^{-1}(\sin(x))$ for $x\in[\pi/2 , 3\pi/2]$ .
Clearly, $$\pi/2 \le x \le 3\pi/2\tag{1}$$ Subtracting $\pi$ , we get: $$-\pi/2 \le x - \pi \le \pi/2$$ Now, the term $(x-\pi)$ had come in the range of $\sin^{-1}(x)$ . Hence, $\sin^{-1}(\sin(x))=x-\pi$ for all $x\in[\pi/2,3\pi/2]\tag{2}$ Once more consider the inequation (1): $$\pi/2 \le x \le 3\pi/2$$ Multiplying this by $(-1)$ , we get; $$-\pi/2 \ge -x \ge -3\pi/2$$ Adding $\pi$ in this gives: $$\pi/2 \ge \pi-x \ge -\pi/2;$$ which can be re-written as; $$-\pi/2 \le \pi-x \le œÄ/2$$ Now, the term $(\pi -x)$ has come within range of $\sin^{-1}(\sin(x))$ .  Hence, $\sin^{-1}(\sin(x)) = \pi -x$ for all $x\in[\pi/2,3\pi/2]\tag{3}$ But (2) and (3) are contradictory. Can anyone tell whether $\sin^{-1}(\sin(x)) =  x-\pi$ or $\pi-x$ and also explain why.","['trigonometry', 'inverse-function']"
4519079,"Showing that a map $\operatorname{Div}(X) \to \bigoplus_{x\in C^{1}}\operatorname{Div}(\mathcal{O}_{X,x})$ is surjecitve (Gortz, Algebraic Geometry)","I'm reading the Gortz's Algebraic Geometry, proof of the Proposition 15.26 and stuck at understanding that some map appearing in the proposition is surjective.
Let $X$ be an absolute curve ; i.e., a non-empty noetherian scheme with irreducible components $X_i$ ( $1\le i \le n$ ) satisfying following equivalent condtions (Gortz, Prop.15.1) (i) For every closed point $x \in X$ , $\operatorname{dim}\mathcal{O}_{X,x} =1$ (ii) The closed irreducible subsets of $X$ are the $X_i$ and the closed points of $X$ .
(iii) $\operatorname{dim}X_i = 1$ for all $i$ . Let $C^{1}$ be the set of points $x\in X$ such that $\operatorname{dim}\mathcal{O}_{X,x}=1$ and let $j_x : \operatorname{Spec}\mathcal{O}_{X,x} \to X $ be the canonical morphism of $x\in C^{1}$ .
Note that $C^{1}$ is precisely the set of closed point of $X$ (If needed, I will upload detail). Then Gortz claims that next homomorphism of abelian groups : $$ \Psi : \operatorname{Div}(X) \to \bigoplus_{x\in C^{1}}\operatorname{Div}(\mathcal{O}_{X,x})$$ $$ D \mapsto \Sigma_{x\in C^{1}}  j_{x}^{*}(D)$$ is isomorphism, where $\operatorname{Div}(X)$ is the Cartier divisors and $j_x^{*} : \operatorname{Div}(X) \to \operatorname{Div}(\operatorname{Spec} \mathcal{O}_{X,x})$ is the inverse image of cartier divisor (c.f. Gortz's book p.312) Note that $\operatorname{Div}(\mathcal{O}_{X,x}) \cong (\operatorname{Frac}\mathcal{O}_{X,x})^{\times}/\mathcal{O}_{X,x}^{\times}$ since for $x \in C^{1}$ , $\mathcal{O}_{X,x}$ is a local noetherian ring of dimension $1$ . (His book Exercise 11.18) I don't know explicit isomorphism. I want to get explicit map, for later usage. Now, let $\mathcal{K}_X$ be the sheaf of total fractions( or called sheaf of meromorphic functions) of $\mathcal{O}_{X}$ . For the surjectivity, he argues that To show that surjectivity we first recall that $\operatorname{Frac}\mathcal{O}_{X,x}=\mathcal{K}_{X,x}$ and that $\Gamma(U, \mathcal{K}_X) = \operatorname{Frac}(\Gamma(U, \mathcal{O}_{X}))$ for every open affine subset $U$ of $X$ (Remark 11.23, $X$ is noetherian). Thus it suffices to show that for $f\in (\operatorname{Frac}\mathcal{O}_{X,x})^{\times}$ there exists an open affine neighborhood $U$ of $x$ and $g \in (\operatorname{Frac}\Gamma(U,\mathcal{O}_X))^{\times}$ such that $g_x = f$ and such that $g_y \in \mathcal{O}_{X,y}^{\times}$ for all $y\in U$ , $y\neq x$ . My question is, why the condition is sufficient for the surjectivity of the $\Psi$ ? My first attempt is, let $(\overline{f}_x)_{x\in C^{1}} \in \bigoplus_{x\in C^{1}}\operatorname{Div}(\mathcal{O}_{X,x})= \bigoplus_{x\in C^{1}}(\operatorname{Frac}\mathcal{O}_{X,x})^{\times}/\mathcal{O}_{X,x}^{\times}= \bigoplus_{x\in C^{1}}(\mathcal{K}_{X,x})^{\times}/\mathcal{O}_{X,x}^{\times} 
$ ( $f_x \in (\operatorname{Frac}\mathcal{O}_{X,x})^{\times}$ ). Then by the above condition, for each $x\in C^{1}$ , there exists an open affine neighborhood $U_x$ of $x$ and $g_x \in (\operatorname{Frac}\Gamma(U_x,\mathcal{O}_X))^{\times} = \Gamma(U_x, \mathcal{K}_X)^{\times}$ such that $(g_x)_{,x} = f_x$ and such that $(g_x)_{,y} \in \mathcal{O}_{X,y}^{\times}$ for all $y \in U_x$ with $y\neq x$ . I could show that $\{ U_x\}_{x\in C^{1}}$ forms an open cover of $X$ (If needed, I will upload proof). Now consider $D := (U_x , g_x)_{x\in C^{1}}$ . Then my question is, Q.1) $D \in \operatorname{Div}(X)$ ; i.e., $D$ forms a Cartier divisor on $X$ ? Q.2) $\Psi(D) = (j_x^{*}(D))_{x\in C^{1}} = (\overline{f}_x)_{x\in C^{1}} $ ? To show Q.2), fix $x_0 \in C^{1}$ . We need to show that $j_{x_0}^{*}(D) = \overline{f_{x_0}}$ . Note that $j_{x_0}^{*}(D) = j_{x_0}^{*}((U_x, g_x)_{x\in C^{1}})
                          := (j_{x_0}^{-1}(U_x), \overline{j_{x_0}^{\flat}}_{,U_x}(g_x))_{x\in C^{1}} 
                           = (j_{x_0}^{-1}(U_{x_0}), \overline{j_{x_0}^{\flat}}_{,U_{x_0}}(g_{x_0})) \in \operatorname{Div}(\mathcal{O}_{X,x_0})  $ , where $\overline{j_{x_0}^{\flat}} : \mathcal{K}_X \to j_{x_0,*}\mathcal{K}_{\operatorname{Spec}\mathcal{O}_{X,x_0}}$ is an extension of $j_{x_0}^{\flat} : \mathcal{O}_X \to j_{x_0,*}\mathcal{O}_{\operatorname{Spec}\mathcal{O}_{X,x_0}}$ and the final equality is true since $j_{x_0}$ is a homeomorphism onto the subspace which is the intersection of all open subsets of $X$ which contains $x_0$ (c.f.Gortz, p.69), so $j_{x_0}^{-1}(U_{x_0})$ forms an open cover of $\operatorname{Spec}\mathcal{O}_{X,x}$ . I asked that what is an explicit isomorphism $\operatorname{Div}(\mathcal{O}_{X,x_0}) \cong (\operatorname{Frac}\mathcal{O}_{X,x_0})^{\times}/\mathcal{O}_{X,x_0}^{\times}$ . My question about Q.2) is, upto this explicit isomorphism, $(j_{x_0}^{-1}(U_{x_0}), \overline{j_{x_0}^{\flat}}_{,U_{x_0}}(g_{x_0}))$ sends to $\overline{(g_{x_0})_{,x_0}}$ ? If so, then since $(g_{x_0})_{,x_0} = f_{x_0}$ as above, maybe we are done. Furthur progress : Let $Y_0 : =\operatorname{Spec}\mathcal{O}_{X,x_0}$ . Note that $\operatorname{DivCl}(Y_0) =0$ ( c.f. Gortz, p.318, Exercise 11.18-(a) ) ; i.e., every Cartier divisor on $Y_0$ is principal. So, there exists a homomorphism $ \eta : \operatorname{Div}(Y_0) \cong \Gamma(Y_0,\mathcal{K}_{Y_0}^{\times})/ \Gamma(Y_0,\mathcal{O}_{Y_0}^{\times})$ (c.f. Gortz, p.301, (11.11.2)) defined as follows : For every divisor $(Y_0, f) \in \operatorname{Div}(Y_0)$ , $\eta ( (Y_0, f)) : = f + \Gamma(Y_0,\mathcal{O}_{Y_0}^{\times}) 
=f + \mathcal{O}_{X,x_0}^{\times} $ . Now let's go back to the above question. Note that $(j_{x_0}^{-1}(U_{x_0}), \overline{j_{x_0}^{\flat}}_{,U_{x_0}}(g_{x_0}))$ is a principal divisor on $Y_0$ . So it sends via $\eta$ to $\overline{j_{x_0}^{\flat}}_{,U_{x_0}}(g_{x_0}) + \mathcal{O}_{X,x_0}^{\times} \in \Gamma(Y_0,\mathcal{K}_{Y_0}^{\times})/ \Gamma(Y_0,\mathcal{O}_{Y_0}^{\times})$ . So, it suffices to show that upto isomorphism ( since $X$ is noetherian ; c.f. Gortz, p.301, Remark 11.23) $$\operatorname{Div}(Y_0) \cong \Gamma(Y_0,\mathcal{K}_{Y_0}^{\times})/ \Gamma(Y_0,\mathcal{O}_{Y_0}^{\times}) \cong (\operatorname{Frac}(\mathcal{O}_{X,x_0}))^{\times}/ \mathcal{O}_{X,x_0}^{\times} \cong (\mathcal{K}_{X,x_0})^{\times}/\mathcal{O}_{X,x_0}^{\times}
 $$ , $\overline{j_{x_0}^{\flat}}_{,U_{x_0}}(g_{x_0}) + \mathcal{O}_{X,x_0}^{\times}$ sends to $(g_{x_0})_{,x_0} + \mathcal{O}_{X,x_0}^{\times}$ . To sum it up, next question is true? Q. For the canonical map $j_x : Y:= \operatorname{Spec}(\mathcal{O}_{X,x}) \to X$ and an open (affine) neighborhood $U \ni x$ and $g \in \mathcal{K}_{X}(U)^{\times}$ , upto isomorphism : $$ \Gamma(j_x^{-1}(U),\mathcal{K}_{Y}^{\times})/ \Gamma(Y,\mathcal{O}_{Y}^{\times}) 
=\Gamma(Y,\mathcal{K}_{Y}^{\times})/ \Gamma(Y,\mathcal{O}_{Y}^{\times}) \cong (\operatorname{Frac}(\mathcal{O}_{X,x}))^{\times}/ \mathcal{O}_{X,x}^{\times} \cong (\mathcal{K}_{X,x})^{\times}/\mathcal{O}_{X,x}^{\times}
 $$ , $\overline{j_{x}^{\flat}}_{,U}(g) + \mathcal{O}_{X,x}^{\times}$ sends to $g_{x} + \mathcal{O}_{X,x}^{\times}$ , where $g_x$ is the germ in $\mathcal{K}_{X,x}^{\times}$ at $x$ ? C.f. Next is full proof of the Proposition 15.26 of the Gortz's book : Why the underlined statement is sufficient for the surjectivity of the $\Psi$ ? Can anyone help?",['algebraic-geometry']
4519137,Logarithm and absolute value,"$$y' - y \tan x = 2x \sec x,\quad y(0)=0\tag1$$ integrating factor $= e^{-\int \tan x\ dx} = e^{\ln|\cos x|} = \cos x$ Can we write $|\cos x|$ as $\cos x$ above? $$I.F. y = \int I.F.\ 2x\ \sec x\ dx\\(\cos x) y = \int \cos x \ 2x\ \sec x\ dx = \int 2x\ dx$$ If we had taken the integrating factor to be $ |\cos x|$ , then in the above line $|\cos x|$ and $\sec x$ wouldn't have cancelled.","['calculus', 'absolute-value', 'ordinary-differential-equations']"
4519177,Quantile estimation with apriori known expectation,"I have the following problem: If we have a typical random sample $\{X_1, X_2, ...\}$ from some unknown distribution and we want to estimate a quantile we just need to sort our observations and take a specific observation from this sorted sequence. Let us know assume that we know additionally that $\mathbb{E}[X_i] = 0$ (or any other number). My question is: If we have our observations $\{x_1, x_2, ..., x_n\}$ , can we substract from them its sample mean (that should be close to $0$ as $\mathbb{E}[X_i] = 0$ ) and then sort them and take a specific quantile. Is it mathematically correct? Can I say sth about my new quantile estimator? Does it have better or worse properties than the standard one?","['statistics', 'quantile', 'estimation']"
4519181,Papa Rudin theorem 1.7 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question There is the theorem:
Let $Y$ and $Z$ be topological spaces, and let $g:Y\to Z$ be continuous. $(a)$ If $X$ is a topological space, if $f:X\to Y$ is continuous, and if $h$ $=$ $g$ $\circ$ $f$ , then $h:X\to Z$ is continuous. $(b)$ If $X$ is a measurable space, if $f:X\to Y$ is measurable , and if $h$ $=$ $g$ $\circ$ $f$ , then $h:X\to Z$ is measurable. There is the proof: If $V$ is open in $Z$ , then $g^{-1}(V)$ is open in $Y$ , and $h^{-1}(V)$ $=$$f^{-1}(g^{-1}(V))$ If f is continuous, it follows that $h^{-1}(V)$ is open, proving $(a)$ . If f is measurable , it follows that $h^{-1}(V)$ is measurable, proving $(b)$ . I don't understand that why is $h^{-1}(V)$ equal of $f^{-1}(g^{-1}(V))$ Any help would be appreciated.","['measure-theory', 'topological-vector-spaces', 'real-analysis', 'measurable-sets', 'set-theory']"
4519185,Hypothesis of Gr√∂nwall's inequality (Evans version),"I hope this question has not alredy been asked: unfortunately there are many versions of this inequality and is difficult to find exactly the version I'm looking for. In Partial Differential Equations, Evans (Appendix B2), there is the proof of the following inequality: Gr√∂nwall's inequality: Let $\eta$ be a nonnegative, absolutely continuous function on $[0,T]$ , which satisfies: $$\eta'(t)\leq\phi(t)\eta(t)+\psi(t) \qquad a.e. \ t$$ where $\phi,\psi$ are nonnegative summable functions on $[0,T]$ , then: $$\eta(t)\leq e^{\int_0^t\phi(s)\ ds}\Big[\eta(0)+\int_0^t\psi(s) \ ds\Big] \qquad \forall t\in[0,T]$$ Proof: $$\frac{d}{ds}\Big[\eta(s)e^{-\int_0^s\phi(r)\ dr}\Big]=e^{-\int_0^s\phi(r)\ dr}[\eta'(s)-\phi(s)\eta(s)]\leq e^{-\int_0^s\phi(r)\ dr}\psi(s)$$ By integration on $[0,t]$ , with $t\in[0,T]$ , we have: $$\eta(t) e^{-\int_0^t\phi(r)\ dr}\leq \eta(0)+\int_0^t e^{-\int_0^s\phi(r)\ dr}\psi(s) \ ds\leq \eta(0)+\int_0^t\psi(s) \ ds$$ where the last inequality follows by the nonnegativeness of $\phi,\psi$ . I can't understand how the nonnegativeness of $\eta$ is used in the proof. Is this hypothesis not necessary? I need to use it for a positive $\eta$ so this hypothesis is not a problem. It is just to be sure that I am not missing something important in the proof of the inequality.
Thank you","['inequality', 'partial-differential-equations', 'ordinary-differential-equations', 'real-analysis']"
4519201,Smooth family of diffeomorphisms gives a complete vector field?,"Let $M$ be a manifold and $U\subseteq \mathbb R$ an open interval containing $0$ . Consider a smooth map $\Phi:U \times M\rightarrow M$ such that $\Phi(t,-):M\rightarrow M$ is a diffeomorphism, for every $t\in U$ $\Phi(0,-)$ is the identity morphism. Then, for every $x\in M$ , we have a path $\Phi(-,x):(U,0)\rightarrow (M,x)$ representing a tangent vector $v_x=\Phi(-,x)_*(\frac{d}{dt})\in T_xM$ and so we get a vector field $v:M\rightarrow TM$ . This vector field has itself a maximal flow $\Psi:V\rightarrow M$ (defined on some open $V\subseteq \mathbb R\times M$ containing $\{0\}\times M$ ) and so I define the following $$\mathcal D=\{t\in\mathbb R|(t,x)\in V\forall x\in M\}$$ so $\mathcal D$ is the maximal domain on which every maximal integral curve is defined. My question is In the context of this question, is $\mathcal D$ an open neighborhood of $0$ ? For those interested, here is where this question comes from: I'm reading about the internal tangent space to a diffeological space . I'm particularly interested in the tangent space at the identity of the diffeological space $\text{Diff}(M)$ . The construction of the internal tangent space (ITS, for short) is here and here . In general, the ITS at some point $x$ of the diffeological space $X$ is linearly generated by pairs $(p,u)$ , with $p: (W,0)\rightarrow(X,x)$ a plot for $X$ (with $W$ open neighborhood of $0\in\mathbb R$ ) and $u\in T_0W$ . For every smooth $f:(W',0)\rightarrow (W,0)$ we identify $(pf,u)$ with $(p,f_*(u))$ . In here , the author proves that if $G$ is a diffeological group, then every tangent vector $v\in T_gG$ ( $g$ any point $\in G$ ) can be represented by a single pair $(p,u)$ like above. In particular, this applies to $\text{Diff}(M)$ , so every $v\in T_\text{id}\text{Diff}(M)$ is represented by some plot $p:U\rightarrow \text{Diff}(M)$ sending $0$ to $\text{id}$ and a tangent vector $u\in T_0U$ . Now, a plot $p$ is like above a smooth family $U\times M\rightarrow M$ of diffeomorphisms, in particular given the pair $(p,u)$ we can associate a vector field as $$x\mapsto p(-,x)_*(u)\in T_xM$$ so that we have a map $$\gamma:T_\text{id}\text{Diff}(M)\rightarrow \mathfrak X(M)$$ If $M$ is compact, then $\gamma$ is an isomorphism (proved in the articles above). In general, I want to understand the image of $\gamma$ for a non-necessarily compact manifold. For now, my guess is that the image of $\gamma$ are those vector fields for which $\mathcal D$ (defined as above) is an open neighborhood of $0$ .","['vector-fields', 'differential-geometry']"
4519205,Solving definite integral $\int_{0}^{1} \tan^{-1}(1-1/x)dx$,"$$\int_{0}^{1} \tan^{-1}\left(1-\frac1x\right)dx$$ Here's what I have done so far. (the answer is given as $-\pi/4$ ) Let $$
I = \int_{0}^{1}\tan^{-1}\left(1-\frac1x\right)dx = \int_{0}^{1}\tan^{-1}\left(\frac{x-1}x\right)dx.
$$ Since, $\int_{0}^{1} f(x)dx = \int_{0}^{1} f(1-x)dx$ one has \begin{align}
I &= \int_{0}^{1}\tan^{-1}\left(1-\frac1{1-x}\right)dx\\
& = \int_{0}^{1}\tan^{-1}\left(\frac x{x-1}\right)dx\\
& = \int_{0}^{1}\frac\pi2-\cot^{-1}\left(\frac x{x-1}\right)dx\\
& = \int_{0}^{1}\frac\pi2-\tan^{-1}\left(\frac{x-1}x\right)dx\\
& = \frac\pi2 - I,
\end{align} Hence, $I = \dfrac\pi4$ . The given answer is $-\dfrac\pi4$ . Where have I gone wrong?","['integration', 'improper-integrals', 'trigonometric-integrals', 'definite-integrals']"
4519209,"Let $a^2, b^2$ and $c^2$ be three distinct numbers in AP. If $ab + bc + ca = 1$ then $(b + c), (c + a)$ and $(a + b)$ are in which series","Let $a^2, b^2$ and $c^2$ be three distinct numbers in AP. If $ab + bc + ca = 1$ then $(b + c), (c + a)$ and $(a + b)$ are in (1)AP (2) GP (3) HP (4) none of these My approach is as follow $2{b^2} = {a^2} + {c^2} \Rightarrow 2{b^2} + {b^2} = {a^2} + {c^2} + {b^2} \Rightarrow 3{b^2} = {a^2} + {c^2} + {b^2}$ ${\left( {a + b + c} \right)^2} = {a^2} + {b^2} + {c^2} + 2\left( {ab + bc + ac} \right)$ ${\left( {a + b + c} \right)^2} = 3{b^2} + 2 \Rightarrow {\left( {a + b + c} \right)^2} - {b^2} = 2{b^2} + 2$ $\Rightarrow \left( {a + b + c - b} \right)\left( {a + b + c + b} \right) = 2{b^2} + 2$ $\Rightarrow \left( {a + c} \right)\left( {a + c + 2b} \right) = 2{b^2} + 2 \Rightarrow {\left( {a + c} \right)^2} + 2b\left( {a + c} \right) = 2{b^2} + 2$ $ \Rightarrow {\left( {a + c} \right)^2} + 2\left( {ab + bc} \right) = 2{b^2} + 2 \Rightarrow {\left( {a + c} \right)^2} + 2\left( {1 - ac} \right) = 2{b^2} + 2$ $\Rightarrow {\left( {a + c} \right)^2} - 2ac = 2{b^2} \Rightarrow {\left( {a + c} \right)^2} = 2\left( {{b^2} + ac} \right)$ $ \Rightarrow \frac{{a + c}}{{{b^2} + ac}} = \frac{2}{{\left( {a + c} \right)}}$ Not able to proceed further.","['algebra-precalculus', 'arithmetic-progressions']"
4519252,Can Sum Of Exponentially Increasing sinusoids be square integrable?,"Apologies if this is a trivial question.... im still learning Suppose we have an exponentially increasing sinusoidal signal $$f(x)=e^{\alpha x}\cos(\beta x)+e^{\alpha x}\sin(\beta x)$$ with $0<\alpha<1$ and $\beta\in\mathbb{R}$ Is it ever possible to dampen the signal with countably (perhaps infinitely) many other potentially exponentially increasing sinusoids such that the sum is square integrable? $$\int_\mathbb{R} [f(x)+\sum[\omega_i e^{\alpha_i x}\cos(\beta_i x)+\omega_i e^{\alpha_i x}\sin(\beta_i x)]]^2<\infty$$ where, for the elements in the summation, $\omega_i$ is the amplitude of the i'th element, $0\leq\alpha_i<1$ and $\beta_i\neq \beta$ . my instinct says it is not possible, but im not sure. edit: to make the question a bit more general, i'll add the possibility of both sin and cos.","['real-analysis', 'calculus', 'functional-analysis', 'trigonometry', 'exponential-function']"
4519253,Genus of quotient space of $\mathbb{H}^2$ given by triangle group,"I am an undergraduate student looking into the quotients of hyperbolic space by triangle groups.
For clarity, a triangle group is a group generated by reflections in the sides of a triangle. For example, $$\Delta (2,3,7) = \; \langle a,b,c \mid a^2, b^2, c^2, (ab)^2, (bc)^7, (ca)^3 \rangle,$$ where $(2,3,7)$ refers to angles $\frac{\pi}{2}, \frac{\pi}{3}, \frac{\pi}{7}$ in a hyperbolic triangle. My question is how can we determine which quotients of $\mathbb{H}^2$ by subgroups of $\Delta (p,q,r)$ (where $\frac{1}{p} + \frac{1}{q} + \frac{1}{r} < 1$ ) form surfaces of certain genus $g$ ? In particular, as a result of the Riemann-Hurwitz formula, we have that any finite quotient $G$ of $\Delta (p,q,r)$ satisfies $$
g = 1 + \frac{1}{2}|G|(1-(\frac{1}{p} + \frac{1}{q} + \frac{1}{r})).
$$ Would this imply, for example, that there are no hyperbolic triangle groups which give rise to a genus 1 surface as a quotient of $\mathbb{H}^2$ by a subgroup of the triangle group? Any help would be much appreciated.","['group-theory', 'geometry', 'quotient-spaces']"
4519254,Showing that the infinite series $\sum_1^\infty \left(\frac {1}{n} - \frac{1}{n+2}\right)$ is convergent,"If we consider an infinite series witht the $n^{th}$ term $$a_n= \frac {1}{n} - \frac{1}{n+2}$$ for $n\ge1$ I am used to calculate the value to which a geometric series converges by looking at the coefficient. However, here I do not have the coefficient but the series itself. How could I show that this infinite series converges and calculate its sum?","['calculus', 'convergence-divergence', 'telescopic-series', 'sequences-and-series']"
4519271,"When the mean of a non-negative, integer-valued random variable goes to zero, does this imply anything about the other raw moments?","When the mean of a non-negative, integer-valued random variable $X_n$ , for example counting paths in a random graph on $n$ vertices between two fixed vertices, goes to zero, $$\lim_{n \to \infty}\mathbb{E}[X_n] =0$$ can we have $\lim_{n \to \infty}\mathbb{E}[X_n^3] = \infty$ , or under what conditions does this occur? This seems reasonable given we just need two different sequences to have different limits, but a bit counter-intuitive, since we're counting objects, and the raw moments give the typical number of ordered pairs, triples, etc.","['random-graphs', 'probability']"
4519272,Is a family a one-to-one function?,"I haven't seen this being explicitly stated anywhere. I'm reading Halmos' book on Naive Set Theory, and it defines a family as a function from an indexing set to an indexed set. It never really said that the function is one-to-one. Since, by intuition it seems that it is not practical for one element in the indexed set to be assigned two different indices. So as the title suggests, is it obviously implied that a family is a one-to-one function? Thanks in advance.","['predicate-logic', 'logic', 'discrete-mathematics', 'elementary-set-theory', 'set-theory']"
4519274,A question about consistency,"These Definitions come from Analysis I textbook of Tao, My question is: what is mean of ' Definition 6.1.2 is consistent with Definition 4.3.4 ',and why is it so clear that they are consistent. How do we verify this 'consistency'? Thank you!",['analysis']
4519347,Why is this integral not finite?,"This question is related to a previous one, I asked here , though I'm not going to explicitly state their relationship. Let $f:\mathbb{R} \to \mathbb{R}$ be a smooth compactly supported function and let $a_1$ and $a_2$ be two non-zero real numbers with non-zero solutions to the equation $a_1x + a_2y = 0 $ for $(x,y) \in [0,\infty)^2$ . I want to prove that the following integral below is not necessarily finite: $$\int_{ [0,\infty)^2 } f(a_1x+ a_2y) \ dx \ dy $$ The thing is that I ""sort of"" understand the intuition of why this is so, but I'm struggling to express it rigorously (as are the texts I've read claiming this fact ...) Let $K$ the set of $(x,y) \in [0,\infty)^2$ such that $a_1x + a_2y = 0$ . Because $K$ contains a non-zero vector, we can scale that non-zero vector by positive scalars and get a new non-zero solution for each scale. Therefore, $K$ is a ray. Now let $(x_t,y_t) \in [0,\infty)^2$ such that $a_1x_t +a_2y_t = t $ where $t$ lies in the support of $f$ . Then we should have something like \begin{align*}
\int_{ [0,\infty)^2 } f(a_1x+ a_2y) \ dx \ dy & \geq \int_{K + (x_t,y_t)} f(a_1x+ a_2y) \ dx \ dy \newline
&  = \int_{K+(x_t,y_t)} f(t) \ dx \  dy
\end{align*} and we should have that the last integral is not finite. Of course, the last two integrals don't make sense so the inequality doesn't make sense. But it feels like it's capturing the idea. I would appreciate some help in completing my idea into a rigorous proof or by being given a totally different (and rigorous) argument.","['distribution-theory', 'multivariable-calculus', 'improper-integrals', 'real-analysis']"
4519350,"Evaluating $\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt$, $k\in\Bbb N_0$","Let $$
I_k=\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt,
$$ with $k\in\Bbb N_0$ and $a>0$ . Since $k$ is an integer we can expand the binomial to obtain $$
I_k=\sum_{\ell=0}^k\binom{k}{\ell}a^{k-\ell}\int_0^\infty t^\ell e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt.
$$ Expanding the quadratic in the Gaussian and combining all the exponential terms subsequently allows us to write a closed-form for $I_k$ that is a finite sum of parabolic cylinder function $D_\nu(z)$ with $$
D_\nu(z)=\frac{e^{-z^2/4}}{\Gamma(-\nu)}\int_0^\infty t^{-\nu-1} e^{-t^2/2-zt}\,\mathrm dt.
$$ Can we write a closed-form for $I_k$ that does not involve a sum like this? Is there a special function, related to $D_\nu$ , that admits an integral expression in the form of $I_k$ ? I would think that Meijer-G functions would be a potential candidate. Edit: I was asked for additional details/context. The origins of this problem are rooted in studying how photon noise passes through electro-optical image sensors.  Without getting into too much detail, the model of the problem being studied leads to a random variable of the form $$
Y=\mathcal P(W)+R,
$$ where $R\sim\mathcal N(0,\sigma_R^2)$ and $\mathcal P(W)$ is a compound Poisson random variable with random mean $W$ , i.e. $\mathcal P(W)|W=w\sim\operatorname{Poisson}(w)$ . In this problem, $W$ is truncated normal with lower bound $(a)$ and infinite upper bound.  The density of $Y$ has the form $$
f_Y(y)=\sum_{k=0}^\infty \mathsf P(\mathcal P(W)=k)\phi(y-k,0,\sigma_R)
$$ and the integral in question is needed to deduce $\mathsf P(\mathcal P(W)=k)$ .","['integration', 'special-functions', 'hermite-polynomials', 'normal-distribution']"
4519381,absolute value of sum vs sum of absolute values,"I know that if $w$ satisfies $\lvert f_1(w)+f_2(w)\rvert>b$ then $\lvert f_1(w)\rvert>b/2$ or $\lvert f_2(w)\rvert>b/2$ , given $b>0$ and $f_1,f_2$ two functions. This can be viewed geometrically. If $f_1, f_2$ are measurable functions, this implies the well known result that $$P(\lvert f_1+f_2\rvert>b)\leq P(\lvert f_1\rvert>b/2)+P(\lvert f_2\rvert>b/2). \quad (1)$$ Question . Is it true that $$P(\lvert \sum_{k=1}^n f_k\rvert>b)\leq \sum_{k=1}^n P(\lvert f_k\rvert>b/n)? \quad (2)$$ How to prove it? Comment . For $n=3$ , I could use $(1)$ repeatedly, as \begin{align}
P(\lvert f_1+f_2+f_3\rvert>b)&\leq P(\lvert f_1+f_2\rvert>b/2)+P(\lvert f_3\rvert>b/2)\\
&\leq P(\lvert f_1>b/4)+P(\lvert f_2\rvert>b/4)+P(\lvert f_3\rvert>b/2).
\end{align} Clearly, this inequality is different from $(2)$ . This example suggests me something like $$P(\lvert \sum_{k=1}^n f_k\rvert>b)\leq \sum_{k=1}^n P(\lvert f_k\rvert>b/2^{\lfloor (n-1)/2\rfloor +1}). \quad (4)$$ But $(2)$ is a better bound than $(4)$ .","['measure-theory', 'statistics', 'probability']"
4519395,Prove solution of a ODE is bounded,"I am trying to prove the following statement: ""Let $f:\mathbb{R} \rightarrow \mathbb{R}$ of class $C^1(\mathbb{R})$ verifying that $f(m)=0 \, \, \forall m \in \mathbb{Z}$ . Prove that all solutions of the ODE $y'=f(y)$ are bounded and defined in all $\mathbb{R}$ .""
I know I need to show that $|y|\leq M$ with $M$ a constant but I don't know how to work with the ODE to achieve this. I also looked for inspiration and found this question Proving all solutions of $y'+y=f(x)$ are bounded . Thanks for your attention.",['ordinary-differential-equations']
4519400,Integration on Hypersurfaces,"Consider a pseudo-Riemannian manifold $(M,g)$ of dimension $d$ . The natural volume form induced by the metric is $$\boldsymbol{\omega} = \sqrt{(-1)^s \mathrm{det}(g_{ij})} dx^1 \wedge ...\wedge dx^d$$ where $s$ is the number of negatives in the signature. Such a $d$ -form enables integration of functions $f : M \to \mathbb{R}$ over a chart domain $\mathcal{U}$ as we define $$\int_{\mathcal{U}} f := \int_{x(\mathcal{U})} d\alpha_1... d\alpha_d \omega(x^{-1}(\alpha))f_{(x)}(\alpha)$$ which is invariant under the choice of chart $x$ (non-boldface $\omega$ being the components of the volume form). Now, given an embedded submanifold of dimension $(d-1)$ , can someone show explicitly how to go from the data above to a similar notion of integration on hypersurfaces? For example, in the sort of flux integrals given by the generalized divergence theorem $$\int_{M} \mathrm{div}(X) = \int_{\partial M} \langle X,\vec{n} \rangle $$ what is the volume form on the rhs? I know both the interior product and hodge star operations can be used to get a $(d-1)$ form from a $d$ -form and and a $(d-1)$ form from a vector field respectively, and that somehow the pullback of $g$ to the hypersuface must show up, but not well enough to implement them myself. i.e. the goal is to understand what really is the volume form in flux-integral resembling expressions like $$E = \int T_{\mu \nu} \xi^\mu n^\nu \sqrt{h} d^3 x$$ and how to derive it from the definition of integration given above. Thank you.","['integration', 'riemannian-geometry', 'smooth-manifolds', 'general-relativity', 'differential-geometry']"
4519429,Hard? problem with the largest square [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 1 year ago . Improve this question Let me start by saying that this post is not likely to be a question. I am writing it because I found a mathematical problem that I found interesting enough to share with others. It seems to me that it is rather difficult and thus I rather not expect an answer. What is it about? Take any two irrational numbers (e.g., the canonical $e$ and $\pi$ ) and on both positive semi-diagonals of the coordinate system, instead of the natural numbers, start writing out their consecutive digits. This is how we label the axes. Then let's put a black square on the lattice points when its ""digital coordinates"" have a sum modulo $2$ equal to $1$ , and let's not give it when it is equal to $0$ . As you can see, the squares begin to cluster into larger groupings, and within these groupings into larger squares (as the picture below). The question is: What is the largest area of a square that can be obtained in this way in a ""grid of digits modulo"" for two specific irrational numbers? Of course, I can choose two artificial irrational numbers in such a way as to elevate the area of such squares to infinity (again, picture below), but putting two specific irrational numbers in it makes the whole problem quite interesting, because we have a predetermined ""grid of digits modulo"" that we can't change, and which doesn't seem to have such simple patterns of distribution of small squares (by the fact that we have irrational numbers). My intuition pushes me, in the direction of saying that such a maximum field will exist, although I could be wrong (due to the fact that the digits seem to behave randomly in this case, and over time you will come across larger and larger groupings of squares if you just wait long enough. Such a hypothesis. Then one could ask about the expected value of the area of a random square spanning maximally the local group, etc.). I am simply curious about your impressions and whether problems of this type appeal to you. Regards.",['discrete-mathematics']
4519438,Does SVD(SINGULAR VALUE DECOMPOSITION) tell if a matrix is singular or not?,"We know that the singular value decomposition of a matrix A is the factorization of A into the product of three matrices A = UDV T where the columns of U and V are orthonormal and the matrix D is diagonal with positive real entries. Now, if we use SVD, does it tell if a matrix is singular or not? If this is not the case, then how should I know if a matrix is singular or not? Example: Find all values of ùëé for which the matrix is singular: matrix: (just a verification of terms question) Should I use gaussian for this?","['matrices', 'linear-algebra', 'matrix-equations', 'soft-question', 'matrix-decomposition']"
4519447,What is the resolvent and spectrum of the projection operator?,"What is the resolvent and spectrum of the projection operator? Well, i am reading about this subject and for one projection operator $P:X\to X$ ( $P^2=P$ ) the excercise ask me to find the resolvent and spectrum. (The excersice do not say who is $X$ . I suppose that $X$ is a Banach space) My attempt. I note that If $\lambda x=Px$ implies that $P(\lambda x)=P^2(x)=P(x)$ then $\lambda=1$ . Therefore, for me the spectrum is $\{1\}$ and the resolvent is $\mathbb C-\{1\}.$ Am i fine or there is other elements? Please somebody can to help me?  Thank you. Best",['functional-analysis']
4519488,Find the minimum of $\\ f(x)=\frac{5\cos(x)-2\sin¬≤(x)+4\sin(x)-3}{6|\cos(x)|+1}$,"Question : Find the minimum of $\\ f(x)=\frac{5\cos(x)-2\sin¬≤(x)+4\sin(x)-3}{6|\cos(x)|+1}$ Attempt. So of course I tried calculus by differentiating but the derivative was overly complicated and couldn't manage to solve it, also I'm wondering if there is a non-calculus method. Which is what I tried right after, by considering the inequalities of the range of $\cos$ and $\sin$ , of $-1‚â§\sin(x)‚â§1$ but only could manage to do it with trial and error: Edit for those who asked for the trial and error method : You want the denominator to be smaller so that the outcome is bigger, and the numerator to be negative to find the minimum. So you start with the denominator which you want to be small as possible, hence by $|\cos(x)|=0$ which gives $x=-\frac{œÄ}{2}$ which then you find out that in the numerator it outputs a negative number which pretty much concludes that is the least number you could get, which was $-9.$ And I checked on desmos and it was right. But it isn't elegant. So I was wondering on how to do it.",['functions']
4519511,Are these normed vector spaces homeomorphic?,"Let $X = \{(x_n) \mid \sum_{n = 1}^\infty |x_n| < \infty\}$ , and let $\|\cdot\|_1$ and $\|\cdot\|_\infty$ be the $L^1$ and $L^\infty$ norms on $X$ , respectively. Are the normed vector spaces $(X, \|\cdot\|_1)$ and $(X, \|\cdot\|_\infty)$ homeomorphic? If so, is there a linear homeomorphism between these spaces? One thing I do know is that $\|\cdot\|_1$ and $\|\cdot\|_\infty$ do not induce the same topology on $X$ . This is easily seen from this criterion ‚Äîin our case, we do not have the bound $\|x\|_1 \leq C\|x\|_\infty$ . For instance, the vector $x = (1, 1 / 2, 1 / 3, \dots, 1 / n, 0, 0, \dots)$ always satisfies $\|x\|_\infty = 1$ , but $\|x\|_1$ can be made arbitrarily large.","['general-topology', 'normed-spaces', 'functional-analysis']"
4519544,Mutually Exclusive question,"If we have $P(a)=0.6, P(b)=0.7$ , can we say they are not mutually exclusive?
without any further infotmation? For example, is there a possible that $b$ depends on $c$ , like this $p(b \mid c)$ , right now we only have $P(b)=0.7$ and $P(a)=0.6$ , can we say $p(a)$ and $p(b)$ are not mutually exclusive, cause $p(a)+p(b)>1$ ? If event a and b are totally not related, can we still add them? For example,the p(b) is probability that we go to jail if we rob a bank, p(a) is the probability of jack eat an apple today, can we still say they are not mutually exclusive? I understand the math here, but do not understand the jail probability p(b) is dependent on the rob probability, is it right that we add p(b) to p(a) to say they are not mutually exclusive? or the example i made is totally wrong?",['probability']
4519557,What can we say about $f(x)=\prod_{n=2}^\infty(1-n^{-1/x})$?,"Main Question: What can we say about $f(x)=\prod_{n=2}^\infty(1-n^{-1/x})$ ? Is $f(x)$ integrable from $0$ to $1$ ? Is it continuous? If we have an affirmative answer to the question on integrability... $$I=\int_{0}^{1}f(x)\,dx=\int_{1}^{\infty}\frac{1}{x^2}\prod_{n=2}^{\infty}\left(1-\frac{1}{n^{x}}\right)dx$$ Can we get bounds on $I$ ? Can we get a closed form for I? Can we get a decent approximation for $I$ ? Motivations I saw this post wherein I found $$ \prod_{n=2}^{\infty} \left(1 - \frac{1}{n^p}\right) = \prod_{\omega : \omega^p = 1} \frac{1}{\Gamma(2-\omega)}. $$ After plotting $f(x)$ , I found myself unsatisfied when I couldn't get a handle on $I$ using desmos. Maybe the issue is that $f_m(x)=\prod_{n=2}^{m}(1-n^{-1/x})$ don't converge fast enough? As I run $m\to \infty$ I observe $I_m= \int_0^1 f_m(x)\,dx$ wiggling.  I'm not quite sure how to proceed in my curiosities. Thanks for any insights.","['integration', 'weierstrass-factorization', 'number-theory', 'real-analysis', 'infinite-product']"
4519578,Conjugacy of p-subgroups in $GL_{5}(\mathbb{F}_{p})$?.,"Let $U_{5}$ denote the unitriangular group of $5\times 5$ upper triangular matrices with ones on the diagonal, over the finite field $\mathbb{F}_{p}$ . Let $H=\left. \left\{
A=\begin{pmatrix}
1 & 0 & 0 & a &d \\
0 & 1 & 0 & b &e \\
0 & 0 & 1 & c &f \\
0 & 0 & 0 & 1 &0 \\
0 & 0 & 0 & 0 &1%
\end{pmatrix}%
\right| a,b,c,d,e,f \in \mathbb{F}_{p}\right\}$ .
and $K=\left. \left\{B=
\begin{pmatrix}
1 & 0 & a' & b' &c' \\
0 & 1 & d' & e' &f' \\
0 & 0 & 1 & 0 &0 \\
0 & 0 & 0 & 1 &0 \\
0 & 0 & 0 & 0 &1%
\end{pmatrix}%
\right| a',b',c',d',e',f' \in \mathbb{F}_{p}\right\}$ be two subgroups of $GL_{5}(\mathbb{F}_{p})$ . The subgroups $H$ and $K$ are maximal abelian normal in $U_{5}$ (See for example Exercise $3$ p. $94$ of the Book {M. Suzuki, Group theory I}). Does the subgroups $H$ and $K$ conjugate in $GL_{5}(\mathbb{F}_{p})$ ?.
I think the answer is No but I don't sure what to do about it. My try to this question: Let $V$ be a vector of $\mathbb{F}_{p}^{5}$ . H and K are not conjugate since $I(\mathbb{F}_{p}[H])V$ is a 3-dimensional vector space but $I(\mathbb{F}_{p}[K])V$ is just a 2-dimensional. Here, $I$ denotes the augmentation ideal. Could anyone please tell me if my try is correct or provide a defferent approche? Thank you in advance.","['matrices', 'group-theory', 'similar-matrices', 'finite-groups']"
4519617,$\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)} = \sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2}$,"I am supposed to prove: $$\underbrace{\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)}}_\text{:=f(z)}=\underbrace{\sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2}}_\text{:=g(z)}$$ I was able to show that both sides have the same poles and the same singular parts. Therefore, $h=f-g$ is an entire function. Clearly, both $f$ and $g$ have period $2$ , so $h$ also has period $2$ . So, if I can show that $h(z)$ is bounded in the vertical strip $0 \leq \Re(z) \leq 2$ , I can invoke Liouville's to get $h$ is consant. To evaluate that constant, one can use the fact that $\lim_{z \to 0}\Big(f(z)-\frac{1}{z^2}\Big)=-\frac{\pi^2}{6}=\sum_{n\neq 0} \frac{(-1)^n}{(z-n)^2}$ implying $h \equiv 0$ and we are done. So, how should I show that $h$ is bounded in that strip?","['complex-analysis', 'power-series', 'laurent-series']"
4519622,Munkres Lemma 2.1,"I'm trying to make sure that I have correctly proved Munkres' Lemma 2.1, which is left to the reader. The lemma states: Let $f: A \to B$ . If there are functions $g: B \to A$ and $h: B \to A$ such that $g(f(a)) = a$ for every $a$ in $A$ and $f(h(b)) = b$ for every $b$ in $B$ , then $f$ is bijective and $g = h = f^{-1}$ . Here is my attempted proof. We will show that $f$ is bijective by showing that it is both surjective and injective. Fix $b \in B$ . Then $h(b) = a$ for some $a \in A$ . Applying $f$ , we obtain $f(a) = f(h(b)) = b$ , so $f$ is surjective. Now, suppose $f(a) = f(a')$ for some $a,a' \in A$ . Applying $g$ , we obtain $g(f(a)) = g(f(a'))$ and hence $a = a'$ , so $f$ is injective and hence bijective. Now, it suffices to demonstrate that $g = h$ . We have $$g \circ \mathrm{id}_B = g \circ (f \circ h) = (g \circ f) \circ h = \mathrm{id}_A \circ h = h.$$ Therefore, we have $f \circ g =  f \circ h = \mathrm{id}_B$ and $g \circ f = h \circ f = \mathrm{id}_B$ , so $g = h = f^{-1}$ , as required. The thing I'm most concerned about is whether I've shown that $g = h = f^{-1}$ . This requires showing two things, I believe: (1) that $g$ and $h$ are equal and (2) that they both operate as both left and right inverses. By showing that $g$ is also a right inverse, I've shown it is a two-sided inverse, and similarly by showing that $h$ is also a left inverse. I haven't shown that any two-sided inverse is necessarily equal to both $g$ and $h$ , so the equality to $f^{-1}$ is not immediately clear to me, which suggests I should also prove (3) any other inverse is necessarily equal to $g$ and $h$ .",['solution-verification']
4519626,What is the Prime at Infinity?,"I've been watching Alex Kontorovich's lectures on Analytic number theory, and he often references a ""prime at infinity"" or a similar sounding concept. For example, in lecture 15 at 45:21 he says: So there are local obstructions that are not just the prime at infinity. For an example that doesn't require the context of multiple lectures to understand, he explains $\xi(s)$ (Symmetric zeta function) in terms of the prime at infinity. I can't find the specific quote where he says this (as it would involve re-watching multiple hours of lectures,) however here's roughly what he said. Suppose we wrote $\xi(s)$ as follows: $$\xi(s)=\pi^{-\tfrac{s}{2}}\Gamma(\frac{s}{2})\prod_{p\text{ prime}}(1-p^{-s})^{-1}$$ He refers to the factors in the infinite product coming from each prime (which makes sense) and the $\pi^{-\tfrac{s}{2}}\Gamma(\frac{s}{2})$ factor coming from the prime at infinity. Can someone explain what this object is, or perhaps point me to a place where I can learn about it?","['analytic-number-theory', 'number-theory', 'prime-numbers']"
4519664,Implicit function theorem for overdetermined system of nonlinear equations,"Consider a sufficiently regular ( $C^1$ ?) function $$F:\mathbb{R}^{m}\times\mathbb{R}^{n}\to\mathbb{R}^{n+k}$$ with $k>0$ . And assume an implicit function $y(x)$ is locally well defined by the condition $$F(x,y(x))=0$$ I am interested in implicit differentiation techniques which apply in this contest, extending the implicit function theorem. EDIT My situation of interest is the following. There is a $C^1$ function $$G:\mathbb{R}^{m}\times\mathbb{R}^{n}\to\mathbb{R}^{n}$$ where I think of $x\in\mathbb{R}^{m}$ as parameters and $y\in\mathbb{R}^{n}$ as variables. Of course, for each $\bar{x},\bar{y}$ such that $$G(\bar{x},\bar{y})=0$$ The IFT ensures there exists a local function $$f:U\ni \bar{x}\to V\ni \bar{y}$$ such that $$G(x,f(x))=0\quad\forall x\in U$$ Moreover, it tells that $$D_x f(\bar{x})=-[D_y G(\bar{x},f(\bar{x}))]^{-1}[D_x G(\bar{x},f(\bar{x}))]$$ Now, I am interested in the value of $D_x f(\bar{x})$ at points which not only satisfy $G(\bar{x},\bar{y})=0$ , but also an additional feasibility condition $$s(\bar{x},\bar{y})=0\quad\text{where}\quad s:\mathbb{R}^{m}\times\mathbb{R}^{n}\to\mathbb{R}$$ My doubt : Is it enough to consider $D_x f(\bar{x})=-[D_y G(\bar{x},f(\bar{x}))]^{-1}[D_x G(\bar{x},f(\bar{x}))]$ at points where $s(\bar{x},\bar{y})=0$ or does the additional constraint changes the shape of the implicit function $f$ , so that we need a different approach? To get this other with, I thought of considering the function $$F\equiv\binom{G}{s}:\mathbb{R}^{m}\times\mathbb{R}^{n}\to\mathbb{R}^{n+1}$$ which already ""selects"" the zeros I am interested in. Observe that it still makes sense to consider $(\bar{x},\bar{y})\in \mathbb{R}^{m}\times\mathbb{R}^{n}$ such that $$F(\bar{x},\bar{y})=0$$ and, assuming there exists $f:U\ni \bar{x}\to V\ni \bar{y}$ such that $F(x,f(x))=0\quad\forall x\in U$ , to ask for implicit differentiation methods to compute the jacobian $D_xf$ . Of course, in this case, the IFT cannot be applied off-the-shelf to ensure $f$ exists, nor to compute such a Jacobian. Hence my question.","['multivariable-calculus', 'reference-request', 'implicit-function-theorem', 'real-analysis']"
4519665,What is the intuitive way to graph a given equation?,"I just recently started to learn some math on my own. It's been fun to be honest. But I am a little bit confused regarding graphing a given equation. In most of the videos and articles I have read, they first identify what the graph would be like, from their previous knowledge base. Like if its a ""linear equation"", then the graph would be a straight line. Or if it's a quadratic, maybe it's a ellipse or something. But if I were to approach an equation and assume I don't know what the outcome might be, how should I graph that equation? Will I have to find the possible domain of the equation and figure out the range by using the possible domain values? For example, here's an equation: x 2 + y 2 = 100 And as for the method of identifying equations by just looking at the equation structure, do we use this method because that's the result we get most of the time and because of it's fast usage? I would be really grateful for some answer on this. I am just a bit confused and don't know who to turn to other than online communities right now.","['self-learning', 'algebra-precalculus', 'graphing-functions']"
4519733,Coincidence of Subspace and Metric Topologies,"How to show that a subspace of a metrizable space is also metrizable? Let $X$ be a topological space, and let $Y$ be a (non-empty) subset of $X$ ; let $d$ be a metric on $X$ that induces the topology of $X$ . Then the restriction $d | Y \times Y$ of $d$ to the subset $Y \times Y$ of $X \times X$ , which is defined by $$
\big( d | Y \times Y \big) ( p, q) := d(p, q) \ \mbox{ for all } p, q \in Y, 
$$ is also a metric on $Y$ . Now let $\mathscr{T}$ be the subspace topology that $Y$ inherits as a subspace of $X$ , and let $\mathscr{T}^\prime$ be the topology induced by the metric $d | Y \times Y$ on $Y$ . How to show that these two topologies on $Y$ are the same? My Attempt: Let $V$ be a $\mathscr{T}$ -open set of $Y$ , and let $y \in Y$ . Then there exists an open set $U$ of $X$ such that $V = Y \cap U$ , and our $y \in U$ of course, which implies the existence a real number $\epsilon_y > 0$ such that $B_d \left( y, \epsilon_y \right) \subset U$ , that is, for any point $x \in X$ such that $d(x, y) < \epsilon_y$ , we also have $x \in U$ ; therefore for any point $x \in Y \subset X$ in particular such that $\big( d | Y \times Y \big) (x, y) < \epsilon_y$ , we  have $x \in U$ and hence $x \in Y \cap U = V$ , which implies that $$
B_{d | Y \times Y} \left( y, \epsilon_y \right) \subset V,
$$ and so $$
V = \bigcup_{y \in V} B_{d | Y \times Y} \left( y, \epsilon_y \right),
$$ from which it follows that $V$ is also a $\mathscr{T}^\prime$ -open set and hence that $$
\mathscr{T} \subset \mathscr{T}^\prime. 
$$ Am I right? Conversely, let $V^\prime$ be a $\mathscr{T}^\prime$ -open set of $Y$ , and let $y^\prime \in V^\prime$ . Then there exists a real number $\epsilon_{y^\prime} > 0$ such that $$
B_{d | Y \times Y } \left( y^\prime, \epsilon_{y^\prime} \right) \subset V^\prime,
$$ that is, for any point $y \in Y$ such that $\big( d | Y \times Y\big) \left( y, y^\prime \right) < \epsilon_{y^\prime}$ , we also have $y \in V^\prime$ .
Let us put $$
U^\prime := \bigcup_{ y^\prime \in V^\prime} B_d \left( y^\prime, \epsilon_{y^\prime} \right). 
$$ This set $U^\prime$ is an open set of $X$ of course and $V^\prime = Y \cap U^\prime$ , thus showing that $V^\prime$ is $\mathscr{T}$ -open, which implies that $$
\mathscr{T}^\prime \subset \mathscr{T}.
$$ Am I right? Is the above proof correct, clear, and complete enough in each and every detail? Or, are there any gaps therein?","['metric-spaces', 'analysis', 'metrizability', 'solution-verification', 'general-topology']"
4519737,(Egorov type) Convergence of solutions of heat equation to their initial condition as $t\to 0^+$ when the initial condition is in $L^2$,"I am trying to understand the behaviour of solutions of parabolic equations as $t\to 0^+$ . More specifically: $\mathbb T^d$ being the $d$ -dimensional flat torus, let $u_0\in L^\infty(\mathbb T^d)$ and consider the solution $u$ of the heat equation \begin{cases}
\partial_t u-\Delta u=0&
\\ u(0,\cdot)=u_0.\end{cases} We know that there exists a unique weak solution $u\in L^2(0,T;H^1(\mathbb T^d))$ that further satisfies: for any $p\in [1;\infty)$ , $u\in C([0,T];L^p(\mathbb T^d))$ . In particular $$ \Vert u(t,\cdot)-u_0\Vert_{L^p}\underset{t\to 0^+}\rightarrow 0.$$ Of course if $u_0$ is not continuous, one can not take $p=\infty$ . My question is the following: is there an ""Egorov type theorem"", in the sense that, for any $\epsilon>0$ , there exists a measurable subset $E_\epsilon$ such that $|\mathbb T^d\backslash E_\epsilon|\leq \epsilon$ , and such that $u(t,\cdot)$ converges as $t\to 0^+$ uniformly to $u_0$ in $E_\epsilon$ ? So far I have only tried but without success the following: 1-Trying to extend the proof of the Egorov theorem to this uncountable case, using the continuity in $L^p$ , but without success. 2-Trying to approximate $u_0$ by a sequence $(u_{0,k})$ of smooth initial data, and using the Egorov theorem on this sequence, but I have also failed there.","['measure-theory', 'measurable-functions', 'heat-equation', 'partial-differential-equations']"
4519760,Find the number of words that can be made by all of the letters in the word 'GEOMETRY' so that no vowels are adjacent.,"The given question is: Find the number of words that can be made by all of the letters in the word GEOMETRY so that no vowels are adjacent. My approach:
5! √ó (6ùëÉ 3/2!) = 7200, using the logic of filling the blanks in  _G_M_T_R_Y _ However, the given answer is 18,000. Where am I incorrect in my method (without using other methods such as the inclusive-exclusive principle)? EDIT : Just for context, the working out provided by the answer key is 8!/2! - (6! √ó 3!/2!) = 18,000. All help is appreciated.","['permutations', 'combinatorics-on-words', 'combinatorics']"
4519765,What are the singular values of Jordan blocks?,"As per the title: consider an $n\times n$ matrix of the form $$J_n = a I_n + E_n,$$ where $E_n$ is defined componentwise as $(E_n)_{i,i+1}=1$ for all $i$ , and with zero components everywhere else. This is a single Jordan block of size $n$ . Is there a general expression for its singular values? This is simple enough to work out in the $n=2$ case, where we get $$s_\pm(J_2) = \frac{1}{\sqrt2}\sqrt{1 + 2|a|^2 \pm \sqrt{1 + 4 |a|^2}}.$$ Already for $n=3$ I get nontrivial cubic polynomial equations to solve, however. While of course it is natural that working this out for generic $n$ involves solving polynomial equations of degree $n$ , is there any way to simplify the problem, or get some understanding about the structure of the solutions more in general? Looking at it numerically, there seems to be a relatively straightforward structure to the solutions. For example, for $n=4$ and $a\in\mathbb{R}$ , we have where I'm plotting the singular values of $J_4$ as a function of $a\in[-3,3]$ . It also seems like the only thing that ever matters is $|a|$ , so the right half-plane in this plot is sufficient to cover the general case with $n=4$ , also when $a\in\mathbb{C}$ . There is clearly a lot of structure here, so how can we see it analytically by computing or somehow estimating the singular values?","['jordan-normal-form', 'linear-algebra', 'svd', 'eigenvalues-eigenvectors']"
4519805,"How do we prove that the simple continued fraction for $e^{2/n}=[1;\frac{n-1}{2},6n,\frac{5n-1}{2},1,1,...]$?","Motivation: remarkably, the simple continued fraction - which is unique - for $e^{1/n},e^{2/n}$ is known for every $n\in\Bbb N$ . The expansions for $e^{3/n}$ , or even $e^{p/q}$ , are not known in general, and it is a strange miracle that we can figure out any of them at all... Euler first derived the continued fraction for $e$ and $e^{1/n}$ . The expansion for $e^{2/n}$ is viewable on the web, but I have not been able to find a proof of this beautiful fact. This original text from Euler proves that, for real $s$ : $$\begin{align}\tag{1}e^{2/s}&=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s+}\cdots\\e^{1/s}&=1+\frac{1}{s-1+}\frac{1}{1+}\frac{1}{1+}\frac{1}{3s-1+}\cdots\end{align}$$ It derives the expansion for $e^{1/s}$ from that for $e^{2/s}$ by means of his ""interpolation"" formulae: $$\begin{align}a+\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\frac{1}{m+}\frac{1}{n+}\frac{1}{c+}\cdots&=\frac{1}{mn+1}\left((mn+1)a+n+\frac{1}{(mn+1)b+m+n+}\frac{1}{(mn+1)c+m+n+}\cdots\right)\\A+\frac{1}{a+}\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\cdots&=A+\frac{mn+1}{(mn+1)a+n+}\frac{1}{(mn+1)b+m+n+}\cdots\\a+\frac{1}{b+}\frac{1}{c+}\cdots&=a-n+\frac{mn+1}{m+}\frac{1}{n+}\frac{1}{\frac{b-m-n}{mn+1}+}\frac{1}{m+}\frac{1}{n+}\frac{1}{\frac{c-m-n}{mn+1}+}\cdots\end{align}$$ Which all have nice special cases for $m=n=1$ . Wikipedia claims that in fact: $$\tag{$\ast$}e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{6s+}\frac{1}{\frac{5s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{7s-1}{2}+}\frac{1}{18s+}\frac{1}{\frac{11s-1}{2}+}\frac{1}{1+}\cdots$$ Which I'd like to understand. First note that, by equivalence transformation (multiply by $2,1/2,2,1/2,\cdots$ ) the a first try might be to convert $(\ast)$ into: $$e^{2/s}=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s-1+}\frac{1}{\frac{1}{2}+}\frac{1}{2+}\frac{1}{\frac{7s-1}{4}+}\cdots$$ Which unfortunately doesn't work out. Also, although two $1s$ have clearly been interpolated somehow to get $(\ast)$ , we can't directly employ any of the standard results shown above, since, instead of $a,1,1,b,1,1,...$ it is of the form $a,b,c,1,1,d,e,f,1,1,...$ . If we try to realise $(1)$ as an interpolation, using the middle formula, we need to solve $2a+1=s-1\implies a=\frac{s-1}{2}$ , $2b+2=3s\implies b=\frac{3s-2}{2}$ , etc., to get: $$e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{3s-2}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{5s-2}{2}+}\cdots$$ Which seems better, but is still not quite right. I'm convinced the answer is going to be a simple transformation: the denominators of $(\ast)$ are of the form $\frac{x-1}{2},2x$ for $x$ the denominator in $(1)$ . The presence of a $2$ -multiplier and a $1/2$ -multiplier suggests some simple cancellation. However, the two interpolating $1s$ are causing me a headache. Does anyone know how we get $(\ast)$ ?","['number-theory', 'reference-request', 'real-analysis', 'sequences-and-series', 'continued-fractions']"
4519825,"If every denumerable subset of a relation is bijective, then is the relation bijective?","Suppose that $X$ and $Y$ are uncountable sets. Also suppose that $R \subseteq X \times Y$ and $ 
 \begin{vmatrix}    R \end{vmatrix}   \neq \begin{vmatrix}   \mathbb {N} \end{vmatrix} $ If there exists a countable subset of $R$ and for every countable subset of $R$ there exists $ X^{\prime }
\subseteq X$ and exists $ Y^{\prime } 
\subseteq Y$ such that $R$ is a one-to-one correspondence from $ X^{\prime }$ to $ Y^{\prime }$ then does that necessarily imply that $R$ is a one-to-one correspondence from $X$ to $Y$ ? Clarifications: $R$ is a $\text{relation}$ from set $X$ to set $Y$ . When I wrote that "" $R$ was a one-to-one correspondence from $X^{\prime }$ to $Y^{\prime }$ "" I probably should have said that the following subset of $R$ represents a one-to-one correspondence from $X^{\prime}$ to $Y^{\prime }$ : $\begin{Bmatrix}(x, y): (x, y) \in R \text{ and } x \in X^{\prime} \text{ and }  y \in Y^{\prime} \end{Bmatrix}$","['elementary-set-theory', 'functions', 'relations']"
4519854,Does a morphism that is constant on fibers factor?,"Given a morphism $\varphi:Z\to Y$ over $X$ , where $X,Y,Z$ are all varieties over an algebraically closed field of characteristic zero. Let $q:Z\to X$ be the structure morphism. Suppose that $q$ is smooth and $\varphi$ is constant on the fibers of $q$ . Then is there a morphism $\rho:X\to Y$ such that $\varphi=\rho\circ q$ ?",['algebraic-geometry']
4519873,probability of number of comparisons of randomized quicksort,"Let's assume we have an array of length $5$ which contains pairwise different integers. The subcript denotes the order of the respective integer, so $i_1<i_2<i_3<i_4<i_5$ . We apply the randomized quicksort algorithm to the unordered array and would like to know the probability $P(A_{24})$ that two integers $s_2$ and $s_4$ are being compared. (Note that every item in the array is chosen as pivot with equal probability) In our lecture the professor simply says that if we think about it for a while it becomes trivial that $P(A_{24})=\frac{2}{4-2+1}=\frac{2}{3}$ . However it didn't.... I would like to have a mathematical frame to argue that $P(A_{24})=\frac{2}{3}$ . My attempt: So far I have only assumed that we already have a discrete probability space $(\Omega,P)$ where $\Omega=\{i_1,i_2,i_3,i_4,i_5\}$ and $B_i$ denotes the event that $s_i$ has been chosen as pivot element. So I simply collect all the events where $s_2$ or $s_4$ are the pivot at some stage during the algorithm and get \begin{align*}
&P(A_{24})=\\
&P(B_2)+P(B_4)+P(B_1)P(B_2\mid B_1)+P(B_5)P(B_2\mid B_5)+P(B_5)P(B_4\mid B_5)+P(B_1)P(B_4\mid B_1)\\
&+P(B_1)P(B_5\mid B_1)P(B_2\mid B_1\cap B_5)+P(B_5)P(B_1\mid B_5)P(B_2\mid B_5\cap B_1)\\
&+P(B_1)P(B_5\mid B_1)P(B_4\mid B_1\cap B_5)+P(B_5)P(B_1\mid B_5)P(B_4\mid B_5\cap B_1)\dots
\end{align*} If we use some intuition and the fact that every element has the same probability to be chosen as pivot we get (conditional) probabilities \begin{align*}
&\dots=\frac{1}{5}+\frac{1}{5}+\frac{1}{5}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4}\\
&+\frac{1}{5}\cdot\frac{1}{4}\cdot\frac{1}{3}+\frac{1}{5}\cdot\frac{1}{4}\cdot\frac{1}{3}+\frac{1}{5}\cdot\frac{1}{4}\cdot\frac{1}{3}+\frac{1}{5}\cdot\frac{1}{4}\cdot\frac{1}{3}\\
&=\frac{1}{5}+\frac{1}{5}+\frac{1}{5}+\frac{1}{15}=\frac{2}{3}.
\end{align*} Though this seems much clearer to me why we get $\frac{2}{3}$ I am not sure about the actual definition of the probability space. How would you set up an appropriate probability space in order to derive $P(A_{24})$ ? Or is there a simpler approach to show why $P(A_{24})=\frac{2}{3}$ ?","['sorting', 'combinatorics', 'probability-theory', 'probability', 'computer-science']"
4519897,Find $\frac{m}{n}$ given $\lim_{x\to 0}\frac{e^{\cos(x^n)}-e}{x^m}=-\frac{e}{2}$,"Question. Find $\frac{m}{n}$ given $$\lim_{x\to 0}\frac{e^{\cos(x^n)}-e}{x^m}=-\frac{e}{2}$$ Attempt. So this is what I tried, using L'Hopital's rule: $$\lim_{x\to 0}\frac{-\sin(x^n)x^{n-1}ne^{\cos(x^n)}}{mx^{m-1}}=-\frac{e}{2}$$ $$\frac{n}{m}\lim_{x\to 0}\frac{-\sin(x^n)x^{n-1}e^{\cos(x^n)}}{x^{m-1}}=-\frac{e}{2}$$ and since the limit of $e^{\cos(x^n)}$ is 1, we can just take the $e$ outside and remove the minus and that $e$ from both sides: $$\frac{n}{m}\lim_{x\to 0}\frac{\sin(x^n)x^{n-1}}{x^{m-1}}=\frac{1}{2}$$ multiplying on the numerator and denominator by $x^n$ : $$\frac{n}{m}\lim_{x\to 0}\frac{\sin(x^n)}{x^n}\frac{x^{n-1}x^n}{x^{m-1}}=\frac{1}{2}$$ but I'm unsure whether you can use the common limit here of $\frac{\sin(x)}{x}$ or how to continue. Can someone shed some light?","['limits', 'calculus']"
4519906,Hecke regularization of weight-2 Eisenstein series and differentiating under the infinite sum,"I have a ""proof"" of the false fact that the Hecke regularized Eisenstein series $$ E_2(\tau) = \lim_{s\to 0} \sum_{(m,n)\ne (0,0)} \frac{1}{(m+\tau n)^2 |m+\tau n|^s}$$ is holomorphic; could someone help me figure out where I'm being too naive? If we write $$ E_2(\tau, s) = \sum_{(m,n)\ne (0,0)} \frac{1}{(m+\tau n)^2 |m+\tau n|^s},$$ it converges absolutely and uniformly on compact subsets of the upper half-plane for $\text{Re }s>0$ . Thus, for $\text{Re }s>0$ , $$ \frac{\partial}{\partial \overline{\tau}}E_2(\tau, s) = \sum_{(m,n)\ne (0,0)} \frac{\partial}{\partial \overline{\tau}}\frac{1}{(m+\tau n)^2 |m+\tau n|^s} $$ and the RHS is still an absolutely convergent sum which approaches $0$ as $s\to 0$ since we pick up a factor of $s$ from the antiholomorphic derivative. Thus, by continuity, $ \frac{\partial}{\partial \overline{\tau}}E_2(\tau, 0)=0$ , i.e. it's holomorphic.","['number-theory', 'analysis', 'complex-analysis', 'sequences-and-series', 'modular-forms']"
4519950,What do the Fibers tell us about torsion? (Geometric Intuition),"Edit: I provided a full answer to the question based on my current understanding of the topic. Any form of proof-reading would be highly appreciated. Alternative answers are also welcome. Inspired by this wonderful post: I am trying to gain a geometric intuition on what torsion does to the Fibers of the Tangent Bundle along a suitable (closed) curve and how that relates to the ""non-closing parallelograms"", if at all. Let's again work on the sphere $S^2$ with its poles removed - call it $S_0^2$ - and its tangent bundle $\pi: \mathcal{T}(S_0^2) \rightarrow S_0^2$ . We define the trivial connection on the Fibers $T_p S_0^2 \cong \mathbb{R}^2$ to be the one where a vector is to be parallel transported if the angle between the vector and the latitude is kept fixed during the navigation. This leads to torsion but no curvature (see post above). Main Question: What exactly does the connection do to the Fibers (tangent planes) which allow us to see this geometrically? More specifically: if $\gamma$ is a closed curve on $S^2_0$ and $\phi_{\gamma} : T_p S_0^2 \rightarrow T_p S_0^2$ is the automorphism produced by the connection (i.e. by the parallel transport of $T_p S_0^2$ along $\gamma$ ), how does $\phi_{\gamma}$ look like? One may be tempted to say that $\phi_{\gamma} = id$ since all $\underline{angles}$ are preserved ( no curvature !) but then again, where exactly is the torsion ? Related Questions (Optional): Is the torsion of a connection related to the torsion of a curve (see picture below), or is the choice of words, a misnomer ? For some context, if we instead had the Levi-Civita Connection on $\mathcal{T}(S^2)$ , my understanding is that we would simply get that $\phi_{\gamma}$ is a rotation, correct? (I.e. the holonomy group is $SO(2)$ since $S^2$ is orientable) Is looking at the Fibers (vector spaces) even the right approach? For example, Roger Penrose defines torsion (in abstract index notion) as the ""commutator"" of the covariant derivative acting on a scalar function $\Phi$ (which is precise and clear but not very visual). In symbols: $$(\nabla_a \nabla_b - \nabla_b \nabla_a)\Phi = \tau_{ab}^c \nabla_c \Phi $$","['riemannian-geometry', 'connections', 'curvature', 'tangent-bundle', 'differential-geometry']"
4519958,Difficult limit question involving Euler's number and L'Hospital,"The limit I'm trying to evaluate is $$
\lim_{x\to+\infty} e^x \left[e - \left(1 + \frac{1}{x}\right)^x\right]
$$ After some hours trying, I've made almost no progress. I always end up in some indeterminate form and L'Hospital isn't getting me anywhere (though I think that, if used properly, it might solve the problem). Maybe it's not even that difficult and I'm just stuck for some stupid reason. Any ideas?","['indeterminate-forms', 'limits', 'eulers-number-e']"
4519975,Is this epsilon-delta proof sufficient?,"I am currently reading ""Calculus a Rigorous First Course"" by Daniel J. Velleman. I am on the exercise set of section 2.4 problem 29, and it states the following. ""Suppose that $f$ and $g$ are functions that agree on all values except one. In other words, there is some number $c$ such that for all $x \neq c$ , $f(x) = g(x)$ , but $f(c) \neq g(c) $ . Show that for every number a, $\lim_{x \rightarrow a}f(x)=\lim_{x \rightarrow a}g(x)$ , where we interpret this equation to mean that either both limtis are defined and they are equal, or both limits are undefined."" My attempt: (Let $\lim_{x \rightarrow a}f(x)=\lim_{x \rightarrow a}g(x)=L$ ) Proof. Supppose $\epsilon > 0$ . Let $\delta=\min(\delta_1, \delta_2)$ , such that if $0<|x-a|<\delta_1$ then $|f(x) - L| < \epsilon/2$ . Similarly, if $0<|x-a|<\delta_2$ then $|g(x)-L|<\epsilon/2$ . Now, suppose $0<|x-a|<\delta$ . Because $\delta \leq \delta_1$ then $0<|x-a|<\delta_1$ which means that $|f(x)-L|< \epsilon /2$ . Similarly, because $\delta \leq \delta_2$ then $0<|x-a|<\delta_2$ , so $|g(x)-L|< \epsilon/2$ . Therefore, $$|f(x) - L+g(x)-L)| \leq |f(x)-L| + |g(x)-L| < \epsilon/2 + \epsilon/2 = \epsilon. $$ My doubt I do not see how my proof has anything to do with the condition $f(c) \neq g(c)$ . Also, I would like to add an additional note left on the problem, which states ""(Note: We could state this result more informally by saying the value of the limit $\lim_{x \rightarrow a}f(x)$ will not be affected if we change the value of $f(c)$ , for any number $c$ . This may seem paradoxical: it suggests that none of the values of the function $f$ are relevant to the value of $\lim_{x \rightarrow a}f(x)!)$ "" How is the factorial of $f(x)$ relevant? Or this some sort of typo?","['limits', 'solution-verification', 'epsilon-delta']"
4519983,Homogeneous linear differential equation $y'+a(x)y=0$ where $a$ is continuous and periodic.,"$y'+a(x)y=0$ is an homogeneous linear differential equation, where $a$ is continuous in $-\infty<x<\infty$ with periodicity $\xi>0$ , i.e. $a(x+\xi)=a(x)~\forall x$ .
I have to show three things: If $\phi$ is a non-trivial solution and $\psi(x)=\phi(x+\xi)$ , show that $\psi$ is also a solution. Show that there exists a constante $c$ such that $\phi(x+\xi)=c\phi(x)~\forall x$ . Also prove that $$c=e^{-\int\limits_0^\xi a(t)dt}$$ . Which condition needs $a$ so that there exists a non-trivial solution, with periodicity $\xi$ . I could manage to prove item 1, we know $$\phi'(x+\xi)+a(x+\xi)\phi(x+\xi)=0$$ $$\phi'(x+\xi)+a(x)\phi(x+\xi)=0$$ $$\psi'(x)+a(x)\psi(x)=0$$ Hence $\psi$ is a solution. I'm struggling with item 2. Not sure where to start, the only thing I tried is the following: $$y'+a(x)y=0$$ $$\dfrac{1}{y}\dfrac{dy}{dx}=-a(x)$$ $$|y|=e^{-\int^x a(t)dt}e^c$$ which leads me to nowhere, but it has a similar form of the $c$ given. I also thought about using Mean Value Theorem but not sure how to apply it here because there is a $c$ multiplying $\phi(x)$ . Tried working with $\dfrac{\phi(x+\xi)}{\phi(x)}$ but still failed.","['homogeneous-equation', 'ordinary-differential-equations']"
4519994,Find the limit of the sequence $a_{n+1}=a_n + \frac{1}{2^n a_n}$ with $a_1=1$,"Find the limit of the sequence $a_{n+1}=a_n + \frac{1}{2^n a_n}$ with $a_1=1$ .
I could only estimate the upper and lower bound for $a_n$ . My result is $$\sqrt{3} \leq \lim_{n\to \infty} a_n \leq \sqrt{\frac{79}{24}}$$ . Is there any way to compute $\lim_{n\to \infty} a_n$ , or find the non-linear equality it satisfies. B.T.W., I find the limit value depends on the initial value $a_1=1$ .","['recurrence-relations', 'sequences-and-series']"
4519997,Herstein's proof of transcendence of $e$,"This question concerns Herstein's proof (in Topics in Algebra ) that $e$ is transcendental. If you have the book, it's Theorem 5.2.1, page 218, or there's a transcription here: https://sites.math.washington.edu/~palmieri/Courses/2005/Math403/transcendental.pdf . In the final step, he goes from $$\epsilon_i = \frac{-ie^{i\left(1-\theta_i\right)}\left(i\theta_i\right)^{p-1}\left(1-i\theta_i\right)^p \dotsm \left(n-i\theta_i\right)^p}{(p-1)!}$$ to $$\lvert\epsilon_i\rvert \leq \frac{e^n n^p \left(n!\right)^p}{(p-1)!}$$ I can see where most of this estimate comes from, but am having difficulty with the $\left(n!\right)^p$ part. This seems to assume that $$\left\lvert\left(1-i\theta_i\right) \dotsm \left(n-i\theta_i\right)\right\rvert \leq n! \qquad (*)$$ but some of the terms inside the absolute value will be negative (the $\theta_i$ are between 0 and 1, but $i$ can range from $1$ to $n$ ), so we can't just multiply the inequalities $1-i\theta_i < 1$ , $2-i\theta_i < 2$ , etc. So can anyone clarify how the inequality $(*)$ arises? Thanks very much in advance for assistance.","['number-theory', 'analysis', 'real-analysis', 'transcendental-numbers', 'inequality']"
4520010,What is $\left(\bigcup\limits_{n=1}^\infty E_n\right)^c$?,"In an experiment, die is rolled continually until a 6 appears, at which point the experiment stops. What is the sample space of this experiment? The sample space consists of sequence where the last entry must be equal to six and no other entry can be six. Mathematically, we can describe the space as $$ S = \{(6), (x_1,6), (x_1,x_2,6), \dots, (x_1,x_2,\dots,x_i,6) | \text{ where } x_i=\{1,2,3,4,5\} \text{ and } i\geq 1\}$$ Let $E_n$ denote the event that $n$ rolls are necessary to complete the experiment. What points of the sample space are contained in $E_n$ ? $E_n$ contains all sequences in the sample space of length $n$ . Mathematically, we can $E_n$ as $$ E_n=\{(x_1,\dots,x_{n-1},6) | \text{ where } x_i=\{1,2,3,4,5\} \} $$ What is $\left(\bigcup\limits_{n=1}^\infty E_n\right)^c$ ? By De Morgan's Law, $$
\left(\bigcup\limits_{n=1}^\infty E_n\right)^c = \bigcap\limits_{n=1}^\infty E_n^c
$$ So here is my question: Is $E_n^c$ is the set of $n$ length sequences where the last entry is anything but 6? I am having a hard time believing that because then those sequences would not belong in the sample space $S$ ?",['statistics']
4520014,Find the derivative of $y=\ln^3(3-x+x^2)$,"Find the derivative of $$y=\ln^3(3-x+x^2)$$ We have to use the chain rule, but I am not sure how to think about it when we have more complex functions as in this problem. We can rewrite the function as $$y=\left[\ln(3-x+x^2)\right]^3,$$ so the outermost function is $g(x)=x^3$ , right? And its derivative is $g'(x)=3x^2$ . Then we have $t(x)=\ln(3-x+x^2)$ and $t'(x)=\dfrac{1}{3-x+x^2}(3-x+x^2)^{'}$ and finally $v(x)=(3-x+x^2)$ with $v'(x)=2x-1$ . How do we use that in order to find $y'$ ? I would be grateful if you explained it in detail.","['calculus', 'derivatives']"
4520024,Relationship between the conductor of an extension $L/K$ and that of the Dirichlet's character on $Gal(L/K)$,"Let $d$ be an odd prime and $d \equiv 1 \pmod{4}$ . For quadratic extensions $\mathbb{Q}(\sqrt{d})/\mathbb{Q}$ , the only prime that is ramified is $d$ , and it is also the conductor of the extension. So the conductor of the extension is same as the conductor defined on the Dirichlet characters. How do I prove this? Also, if I have $\mathbb{Q}(d^{1/p})/\mathbb{Q}$ where $p$ is some odd prime, how do I find the conductors? I am trying to use the discriminant-conductor formula for cubic extensions to try and estimate what conductors are using the discriminant but I am unable to make any progress. So how do I show this? Since the extension $(L=\mathbb{Q}(d^{1/p}))/{K}$ , (where $K$ contains the $p$ -th roots of unity) is abelian so $\chi(1)=1$ but what are the values of the conductors? My understanding says that for $p=3$ there will be three Artin conductors defined at $1, \omega, \omega^2$ but what is their value? I know that only primes ramified in the extension $L/K$ in this case of $p=3$ are $(1-omega), d$ but then how is the conductor $3d$ ? So how are these conductors related to the conductor of the extension and the ramified primes? I would really appreciate the help.","['algebraic-number-theory', 'number-theory', 'maximal-and-prime-ideals', 'galois-theory', 'galois-extensions']"
4520035,Intersection numbers on blow-up,"Let $p:X\to\mathbb A^3$ be the blow-up of $\mathbb A^3$ along a line $L$ . Denote the exceptional divisor as $E$ . Let $H$ be a plane containing $L$ and $\tilde{H}$ be the strict transform. I found contradiction when computing some intersection numbers. Let $C=\tilde{H}\cap E$ . Then projection formula implies that $$p^*H\cdot C=p_*(p^*H\cdot C)=H\cdot p_*C=H\cdot L=1.$$ The intersections are interpreted as intersections in the Chow ring of $X$ and $\mathbb A^3$ . On the other hand, however, $E\cdot C=0$ since $C$ deforms in $\tilde{H}$ in a ruling and a small perturbation of $C$ is disjoint from the exceptional divisor $E$ . Similarly, $\tilde{H}\cdot C=0$ since $C$ can be deformed in $E$ (consider a family of planes $H_t$ containing $L$ , their strict transforms on $E$ are disjoint) and a small deformation will be disjoint from $\tilde{H}$ . So $0=E\cdot C+\tilde{H}\cdot C=p^*H\cdot C=1$ . Contradiction. Where is the mistake?","['algebraic-geometry', 'intersection-theory', 'birational-geometry']"
4520056,Find the derivative of $y=\sqrt{\ln\left(4x-x^2\right)}$,"Find the derivative of $$y=\sqrt{\ln{\left(4x-x^2\right)}}$$ So we can rewrite the function as $$y=\left[\ln\left(4x-x^2\right)\right]^\frac12$$ Let's try to break it down a bit. So let's set $$a(x)=x^\frac12$$ and $$b(x)=\ln(4x-x^2)$$ then $$y=a(b(x))$$ The chain rule then tells us that $$y'=a'(b(x))b'(x)$$ Now $a'$ we can easily find, as it is just $$a'(x)=\dfrac{1}{2\sqrt{x}},$$ but how do we find $b'$ ? Well, let's do the same thing again, namely notice that it's a composition and break it down. So now let $\alpha(x)=\ln x$ and $\beta(x)=4x-x^2$ . These two functions we know how to differentiate! Indeed $\alpha'(x)=\dfrac{1}{x}$ and $\beta'(x)=4-2x$ . Furthermore, the chain rule also tells us now that, as $b(x)=\alpha(\beta(x))$ , $b'(x)=\alpha'(\beta(x))\beta'(x)$ . Putting this all together we get that $$y'(x)=a'(b(x))\alpha'(\beta(x))\beta'(x)\\=\dfrac{1}{2\sqrt{\ln(4x-x^2)}}\cdot\dfrac{1}{4x-x^2}\cdot(4-2x)=\dfrac{1}{2x\sqrt{\ln(4x-x^2)}}.$$ The answer seems to differ...","['calculus', 'derivatives']"
4520057,"Bernoulli numbers identity:$\sum_{k=0}^n\sum_{l=0}^m\binom{n}{k}\binom{m}{l}\frac{(n-k)!(m-l)!}{(n+m-k-l+1)!}(-1)^l B_{k+l}=0$,for all $n\ge1$,$m\ge0$","For all $n\geq 1$ and $m\geq0$ , I'm trying to prove that $\sum_{k=0}^n\sum_{l=0}^m\binom{n}{k}\binom{m}{l}\frac{(n-k)!(m-l)!}{(n+m-k-l+1)!}(-1)^l B_{k+l}=0$ where $B_n$ are the Bernoulli numbers with $B_{1}=-\frac{1}{2}$ . I made a couple of attempts using the recursive relationship of Bernoulli numbers and induction, but unsuccessful. Now I'm wondering if this is a viable proof strategy. Any comments are appreciated! Edit: This is a conjecture, I evaluated it numerically for $n,m\leq 20$ .","['binomial-coefficients', 'combinatorics', 'bernoulli-numbers', 'generating-functions', 'sequences-and-series']"
4520070,asymptotic bound on Galton-Watson extinction probability,"Consider a Galton-Watson process with offspring distribution $$Z \sim \text{Binomial}(d,1-e^{-\lambda/d})$$ with $d$ a large integer and $\lambda >0$ . Let $\zeta= \zeta(\lambda)$ be the probability of extinction. We would like to prove that $\zeta \leq e^{-\lambda + \epsilon}$ for any $\epsilon >0$ so long as $\lambda$ is large enough. This seems true since, classically, we know that $\zeta$ is the unique solution to $$\zeta = \mathbf E[\zeta^Z] = (e^{-\lambda/d} + (1-e^{-\lambda/d})\zeta)^d.$$ So we can write $$\zeta^{1/d} - (1- e^{-\lambda/d})\zeta = e^{-\lambda/d}.$$ Plugging in $e^{-\lambda}$ for $\zeta$ is almost a root, since the left side is $$e^{-\lambda/d} - (1- e^{-\lambda/d} )e^{-\lambda}$$ which is $O(e^{-\lambda})$ away from $e^{-\lambda/d}$ . Is there a rigorous way to reason that $\zeta \leq e^{-\lambda + \epsilon}$ for $\lambda$ large enough?","['analysis', 'probability']"
4520176,Find a bounded operator $T$ with spectrum $\sigma(T) = \mathbb{C}$,"I have been stuck at question 10B.5 from Axler's Measure, Integration and Real Analysis (MIRA) for a long time. Could anyone please give me some hints or post a solution? The exercise reads Give an example of a bounded operator $T$ on a normed vector space such that for every $\alpha \in F$ , the operator $T‚àí \alpha I$ is not invertible. Here, $F$ is either $\mathbb{R}$ or $\mathbb{C}$ . If the vector space is a Banach space, then $T ‚àí \alpha I$ is invertible for $\alpha > \|T\|$ (this is result 10.35b in the book), so I have been considering non-complete spaces. But I haven't had any luck so far. Thank you in advance!","['operator-theory', 'spectral-theory', 'functional-analysis']"
4520184,"If two metric spaces are homeomorphic, what more conditions are required so that their balls are homeomorphic?","I was talking to a friend about topological homeomorphisms, and the conversation turned to about ""sphere"" to ""cube"" homeomorphism in the standard topology. We found this paper which seemed to be quite complicated for showing it. My friend then tried to find an easier solution, and, mistakenly concluded that if two metric spaces are homeomorphic then their balls are also homeomorphic , so the sphere is homeomorphic to a cube trivially because the $d_1$ metric is same as $d_2$ metric on $\mathbb{R^3}$ (topological sense). We both concluded that this statement should not be generally true because even in a single metric space the balls around different point need not be homeomorphic, so one would have to specify which balls they are talking about in the framing of the above claim. I tried to account for that problem and frame the following question: If we have a homeomorphism $f,g$ between two metric spaces $X$ and $Y$ , when is that the ball centered at a point $x \in X$ is homeomorphic to a ball centered at the point point $f(x) \in Y$ ? I would also appreciate discussion on other ways of turning my friends statement into a rigorous true statement other than the above.","['general-topology', 'metric-spaces', 'real-analysis']"
4520229,"Understanding the definition of ""Indefinite integral"".","Everywhere I have looked up, see here , the indefinite integral is defined as: $$F'(x)= f(x) \iff \int f(x) \, dx= F(x) + C $$ From what I understand if $f$ has an antiderivative $F$ then the set $$\{F(x) + C : C \in \mathbb{R}\}$$ is called ""indefinite integral"" of $f$ . But I don't understand the definition, $F'(x) =f(x)$ ... okay, where? What values of $x$ ? For every $x$ in the domain of $f$ ? Oh then I think we have a problem. Let $f(x)= 0$ for $x \in (0,1)\cup(1,2)= \text{Domain}(f)$ , we then go on to say $\displaystyle\int f(x)\, dx =\int 0 \ dx = C = \{ F(x) = C, \forall x \in \text{Domain}(f): C \in \mathbb{R}\}$ , a set of constant functions ... Sure but what if $F:(0,1)\cup(1,2)\to \mathbb{R}$ given by, $$ F(x)= \begin{cases}1, \ x \in (0,1) \\ \\ 2, \ x \in (1,2) \end{cases}$$ then $$F'(x)= 0 = f(x)\, , \ \forall x \in \text{Domain}(f)$$ but $F(x)$ is not a constant function on $\text{Domain}(f)$ and so $F(x)\notin \displaystyle\int f(x) \, dx$ and yet $F'(x)=f(x), \forall x $ . What gives? Surely, that definition is incomplete? NOTE: I have not mentioned $f$ is Riemann integrable or not so writing $F(x)=\int_a^x f(t) \, dt$ is already a no-go.","['integration', 'calculus', 'definition', 'indefinite-integrals', 'derivatives']"
4520248,Colimit of Grothendieck topoi,"Let me preface this by saying that I am a simple man, with simple needs, and I would appreciate a) no modifications to the question unless strictly necessary (but please let me know if I need to change something to make it sensible/have a reasonable answer), b) as simple of an answer as is possible. Suppose that I have an indexed collection of sites $\{\mathcal{C}_i\}_{i\in I}$ (by a site I mean a category with a Grothendieck pre-topology) where $I$ is some index category. Suppose that for every morphism $f\colon i\to j$ in $I$ I have a morphism of topoi $$(f_\ast,f^\ast)\colon \mathbf{Sh}(\mathcal{C}_i)\to\mathbf{Sh}(\mathcal{C}_j),$$ which is something like a lax $2$ -functor (for $i\xrightarrow{f}j\xrightarrow{g}k$ I have chosen equivalences $(g\circ f)^\ast=f^\ast\circ g^\ast$ and $(g\circ f)_\ast= g_\ast\circ f_\ast$ satisfying 'reasonable compatibility conditions'). I can then form the $2$ -limit $$2\text{-lim}\, \mathbf{Sh}(\mathcal{C}_i),$$ with respect to the pullback functors $f^\ast$ . My question is whether or not this is naturally $\mathbf{Sh}(\mathcal{C})$ for some reasonable site $\mathcal{C}$ . I strongly suspect this is related to the existence of colimits in $\mathbf{ShTopos}$ , as in a paper of Moerdijk, but I find that to be too jargony for me. It could, be related to the colimit of sites , but this seems slightly wrong to me. Any suggestions would be helpful!","['topos-theory', 'algebraic-geometry', 'category-theory']"
4520284,Mapping a graph to a line,"What does it exactly mean when a graph is mapped to a line in the plane? We have a graph where there is a vertex $v$ of degree 3 or more, and it is stated that if this vertex is mapped to a line in the plane with all of its neighboring vertices, then at least one of the faces adjacent to $v$ is not a triangle (geometrically speaking). We define a triangle in a geometric manner i.e. a face of a drawing of a graph is a triangle if the edges connecting the vertices form a triangle.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
4520300,"Find a function such that $f(x)>0$, $f'(x)>0$ and $f''(x)>0$ for all $x$, except exponential functions.","How do I find a function that the function itself and its first and second derivative are all positive for all x? I don't have a clue, I tried $f(x)=x^2$ , but $f'(x)$ have negative value.","['calculus', 'derivatives']"
4520308,Integrating from $\int_0^\infty \frac{\sin(x)}x dx$ with year $10$ mathematics?,"I am currently a year $10$ student self studying a level further maths. One day, my friend sent me this funny photo , from the photo we can easily know that glass beer = $10$ , burger = $5$ , and cup beer = $2$ , and the next part is the challenging part. From the integral question provided, we know that we need to do $$\int_{0}^{\infty}\frac{10\sin x}{2x}dx$$ where it means $5\int_{0}^{\infty}\frac{\sin x}{x}dx$ after simplifying, but the problem is how to integrate it. After searching online, I realized that $\int_{0}^{\infty}\frac{\sin x}{x}dx$ is simply $\frac{\pi}{2}$ , so the answer is $\frac{5\pi}{2}$ . But why?! I am a person with a lot of curiosity haha and after searching online, I found out that lot of people use Laplace transforms or Feynman's Technique (by blackpenredpen which is a yt channel I like so much), but I don‚Äôt really understand those with my current knowledge. Then, I suddenly thought of a thing; can I do a Taylor series expansion, integrate it, and then find out where it converges? For example, $\sin x = \sum\limits_{n=0}^{\infty}(-1)^{n}\frac{x^{2n+1}}{(2n+1)!}$ , when you divide it by $x$ , it is $\sum\limits_{n=0}^{\infty}(-1)^{n}\frac{x^{2n}}{(2n+1)!}$ , and after you integrate it, it is $\sum\limits_{n=0}^{\infty}(-1)^{n}\frac{x^{2n+1}}{(2n+1)(2n+1)!}$ . But what's next, here is where I am currently stucking at. I found out that this formula is actually a bit like the taylor series of $\arctan $ , just need to remove the $(2n+1)!$ and they are the same. When you $\lim_{x\to \infty}$ , their answers are both $\frac{\pi}{2}$ . Does anyone here know how to evaluate and where does $$\lim_{x\to \infty}\sum_{n=0}^{\infty}(-1)^{n}\frac{x^{2n+1}}{(2n+1)(2n+1)!}$$ or $$\lim_{x\to \infty}x-\frac{x^{3}}{18}+\frac{x^{5}}{600}-\frac{x^{7}}{35280} \cdot\cdot\cdot $$ converge? If anybody here could help me out, I would really be so thankful because I have spent days on it and still can't find the answer. Also, at the end sorry for my bad English as I am not a native speaker so the language maybe a bit odd!","['integration', 'trigonometric-series', 'trigonometry', 'taylor-expansion']"
4520315,Constructing functions involving existential quantifiers: issues of one input being mapped to many outputs,"I was wondering if someone could help me formalize the below construction. Suppose I know that some set $T$ is dense on the $\mathbb R$ eal closed interval $[a,b]$ . The definition that I would like to work with is: $T \subseteq [a,b]$ is dense in $[a,b]$ if for any $c \lt d \in [a,b]$ , there is a $t\in T$ such that $t \in (c,d)$ . Next, suppose I have the following set: $R=\{(c_n,d_n)\ |\  \exists n \in \mathbb N: c_n=b-\frac{b-a}{n} \text{ and } d_n=b-\frac{b-a}{n+1}\}$ . I want to use the following function: $G:R \to T$ , where the mapping rule is $(c_n,d_n) \mapsto x_n$ such that $x_n \in T \text{ and } x_n \in (c_n,d_n)$ . However, I am unsure whether or not the function $G$ exists. The main problem I see here is that, for a given input $(c_n,d_n)$ , how do I know that $G$ only maps to a single element (a requirement for a function )? By assumption, there is at least one such element $x_n \in T \text { and } x_n\in (c_n,d_n)$ , but there may be many (infinitely) more. As far as I know, the implied existential statement, ""... $\exists t \in T$ ..."" has no upper bound on the number of objects satisfying the given property...it simply asserts that there is at least one. Is the only way around this issue to invoke the Axiom of Choice, which will allow me to posit the existence of a choice function? In particular, this choice function $K_n$ would allow me to choose precisely one of the possibly many $t \in T$ that lay within $(c_n,d_n)$ . If this is true, would it be appropriate to recast my function $G$ in the following way? $G:R \to T$ , where the mapping rule is $(c_n,d_n) \mapsto K_n\left((c_n,d_n) \right)$ Are there other ways to go about this construction that do not require the Axiom of Choice? 1st Edit For completeness, with this updated version of $G$ , we can show that the set $T$ is, at a minimum, countably infinite. To see this, we will show that there is a bijection from a subset of $T$ to $\mathbb N$ . Firstly, because $\forall n \in \mathbb N: (c_n,d_n) \cap (c_{n+1},d_{n+1}) = \emptyset$ , we must have that $G$ is injective. Also, $\forall n \in \mathbb N: [c_n,d_n] \subset [a,b]$ , which means that $R \subseteq [a,b]$ (so $G$ is well-defined). Next, by construction, it is straightforward to see that $R$ , the domain of $G$ , can be put in a bijection with $\mathbb N$ in the obvious way, which, together with the injectivity claim, shows that $G[R]$ can be put in a bijection with $\mathbb N$ (once again, in the obvious way). But $G[R] \subseteq T$ , so we see that we have a subset of $T$ which can be put in a bijection with $\mathbb N$ . Therefore, $T$ is, at a minimum, countably infinite. More generally, we show that any set that is dense in a non-empty subset of $\mathbb R$ is at least countably infinite. 2nd Edit In the comments, Asaf Karagila stated that to prove a set is simply 'infinite' does not require the Axiom of Choice. Here is how. In this context 'infinite' (rather than 'Dedekind Infinite') simply means 'not infinite' where we define 'finite' as: A set $A$ is finite if there exists a bijection $f: A \rightarrow \{1,...,n\},$ for some positive integer $n$ Returning to our initial problem, to show that $T$ is infinite, we will proceed by contradiction. Suppose, instead, that $T$ is finite. Therefore, there exists some $N$ such that $T$ can be put in a bijection with the set $\{1,2,\cdots,N\}$ . Now, consider the following length $\ell  = \frac{b-a}{N+1}$ . Consider the following list of subintervals: \begin{align}s_1=\left(a,a+1\cdot \frac{b-a}{N+1}\right),s_2=\left(a+1\cdot \frac{b-a}{N+1},a+2\cdot \frac{b-a}{N+1}\right),\cdots, \\s_N=\left(a+(N-1)\cdot \frac{b-a}{N+1},a+N\cdot \frac{b-a}{N+1}\right), s_{N+1}=\left(a+N\cdot \frac{b-a}{N+1},b\right)\end{align} . In each of these intervals, there is a $t_j \in s_j$ . All of these subintervals are disjoint. Therefore, there are a total of $N+1$ elements in $T$ , which is a contradiction. $T$ must be infinite...no Axiom of Choice required.","['first-order-logic', 'axiom-of-choice', 'functions', 'set-theory']"
4520317,"$\int_W x^2y^2 = \int_V x^2y^2$. Is my proof of this equation right? (""Analysis on Manifolds"" by James R. Munkres)","I am reading ""Analysis on Manifolds"" by James R. Munkres. The following example is EXAMPLE 4 on p.149: EXAMPLE 4. Suppose we wish to integrate the same function $x^2y^2$ over the open set $$W=\{(x,y)\mid x^2+y^2<a^2\}.$$ Here the use of polar coordinates is a bit more tricky. The polar coordinate transformation $g$ does not in this case define a diffeomorphism of an open set in the $(r,\theta)$ plane with $W$ .  However, $g$ does define a diffeomorphism of the open set $U=(0,a)\times (0,2\pi)$ with the open set $$V=\{(x,y)\mid x^2+y^2<a^2\text{ and }x<0\text{   if   }y=0\}$$ of $\mathbb{R}^2$ . See Figure 17.5; the set $V$ consists of $W$ with the non-negative $x$ -axis deleted. Because the non-negative $x$ -axis has measure zero, $$\int_W x^2y^2=\int_V x^2y^2.$$ The latter can be expressed as an integral over $U$ , by use of the polar coordinate transformation. Is my proof of the following equality right? $\int_W x^2y^2=\int_V x^2y^2.$ Theorem 11.3. Let $Q$ be a rectangle in $\mathbb{R}^n$ ; let $f:Q\to\mathbb{R}$ ; assume $f$ is integrable over $Q$ . (a) If $f$ vanishes except on a set of measure zero, then $\int_Q f=0$ . Theorem 13.3 (Properties of the integral). (d) (Additivity). If $S=S_1\cup S_2$ and $f$ is integrable over $S_1$ and $S_2$ , then $f$ is integrable over $S$ and $S_1\cap S_2$ ; furthermore $$\int_S f=\int_{S_1} f+\int_{S_2} f-\int_{S_1\cap S_2} f.$$ My proof is here: Let $T:=\{(x,y)\mid 0\leq x<a\text{ and }y=0\}$ . Then, $W=V\cup T$ and $V\cap T=\emptyset.$ So, by Theorem 13.3(d), $\int_W x^2y^2 = \int_V x^2y^2 + \int_T x^2y^2 - \int_{V\cap T} x^2y^2$ . Since $T$ and $V\cap T$ have measure zero, $\int_T x^2y^2=0$ and $\int_{V\cap T} x^2y^2=0$ by Theorem 11.3. So, $\int_W x^2y^2 = \int_V x^2y^2$ .","['integration', 'multivariable-calculus', 'measure-theory', 'solution-verification']"
4520334,"An exercise on derived category in Weibel's book: commuting $\mathbf{R}\mathrm{Hom}_R$ with $\otimes^{\mathbf{L}}_R$ in a ""weird"" way","My question is on the following exercise in Weibel's book: Exercise 10.8.3. Exercise 10.8.3 : Let $R$ be a commutative ring and $C$ a bounded complex of finite $\mathrm{Tor}$ -dimension over $R$ . Show that there is a natural isomorphism in the derived category $\mathsf{D}(R-\mathrm{Mod})$ : $$
\mathbf{R}\mathrm{Hom}_R(A,B) \otimes^{\mathbf{L}}_R C \cong \mathbf{R}\mathrm{Hom}_R(A,B \otimes^{\mathbf{L}}_R C ).
$$ How I got stuck : I feel that the general way to prove such problems is in two steps: Degenerate the desired isomorphism to the zeroth degree and prove the zeroth degree version. Use the composition theorem for derived functors (i.e. $\mathbf{R}(GF) \cong \mathbf{R}G \circ \mathbf{R}F$ ) to upgrade to the derived version. At least for most exercises and theorem I have met, the thing works smoothly: Example 1 : To show $$
\mathbf{R}\mathrm{Hom}_R(A,\mathbf{R}\mathrm{Hom}_R(B,C)) \cong \mathbf{R}\mathrm{Hom}_R(A \otimes^{\mathbf{L}}_R B, C )  \quad\quad (\star),
$$ we first degenerate it to the zeroth degree as $$
\mathrm{Hom}_R(A, \mathrm{Hom}_R(B,C)) \cong \mathrm{Hom}_R(A \otimes_R B, C).
$$ This is the clear adjoint isomorphism. Then we view both sides as composed functors in $B$ . Then if $A$ is a projective complex and $C$ is an injective complex , we check the conditions of the composition theorem of derived functors hold. So we upgrade both sides to the derived version. Then we take projective resolution of $A$ and injective resolution of $C$ in general, we have the final isomorphism $(\star)$ . Example 2 : We can also prove the Shapiro's lemma in group cohomology by this method, by first degenerate to the canonical isomorphism $$
\mathrm{Hom}_G(\mathbb{Z}, \mathrm{Ind}^G_H(-)) \cong \mathrm{Hom}_H(\mathbb{Z}, -)
$$ and upgrade it to $$
\mathbf{R}\mathrm{Hom}_G(\mathbb{Z}, \mathrm{Ind}^G_H(-)) \cong \mathbf{R}\mathrm{Hom}_H(\mathbb{Z}, -),
$$ by further noticing $\mathrm{Ind}^G_H(-)$ is an exact functor. Then taking the $n$ -th cohomology, we get the Shapiro's lemma. But my experience fails when facing the exercise above, since the isomorphism on the zeroth degree level, i.e. commuting tensor product with Hom in such a weird (for me) way is quite out of reach for me. Yet I have no idea how to tackle in another approach. Similar questions arises when I'm trying to solve the following exercise in Weibel's book: Exercise 10.8.4 : Let $f: R \rightarrow S$ is a flat ring homomorphism, and $f^{\ast}$ is the functor sending an $R$ -module $A$ to the $S$ -module $A \otimes_{R} S$ . Now suppose $A$ is quasi-isomorphic to a bounded above complex of finitely generated projective modules. Show that we have a natural isomorphism for every $B$ in $\mathsf{D}^{+}(R-\mathrm{Mod})$ : $$
\mathbf{L}f^{\ast} \mathbf{R}\mathrm{Hom}_R(A,B) \rightarrow \mathbf{R}\mathrm{Hom}_S(\mathbf{L}f^{\ast}A, \mathbf{L}f^{\ast} B).
$$ And similar to the previous exercise, I also got stuck at the very first beginning, feeling confused on the degenerated version. Or maybe my two-step approach has some hidden troubles that I haven't realized? Or is it quite limited in the application of derived category? Quite frustrated! :( Thank you all for helping, commenting or answering, or even reading such a long post! :)","['homological-algebra', 'abstract-algebra', 'derived-categories']"
4520375,The catch in proving that a singleton is a Borel set?,"Let $\Omega= (0,1]$ . Let $\mathcal{C}$ be the collection of all open interval in $(0,1]$ .
By open interval in $(0,1]$ I mean any interval of the form $(a,b)$ , where $a\geq 0$ and $b\leq 1$ .
Let $\sigma(\mathcal{C})$ be the smallest sigma-algebra that contains $\mathcal{C}$ . We call this sigma-algebra a Borel-sigma algebra. Now, let us we have to prove that the singleton $\{0.7\}$ is in $\sigma(\mathcal{C})$ . In order to prove it, we use the following result: \begin{equation}
\{0.7\}=\bigcap_{n=1}^{\infty}\Big[(0.7-1/n, 0.7+1/n)\cap(0,1]\Big].
\end{equation} The above result is based on the fact that \begin{equation}
(0.7-1/n, 0.7+1/n)\cap(0,1]\in\mathcal{C}\in\sigma(\mathcal{C}), \mbox{for}\ n=2,3,4...
\end{equation} Therefore the intersection of $\bigcap_{n=1}^{\infty}\Big[(0.7-1/n, 0.7+1/n)\cap(0,1]\Big]$ would be contained in $\sigma(\mathcal{C})$ . However, here is the catch, for $n=2$ , we have \begin{equation}
(0.7-1/n, 0.7+1/n)\cap(0,1]= (0.2, 1.2)\cap(0,1]=(0.2, 1]\notin \mathcal{C}
\end{equation} Therefore the quantity $\bigcap_{n=1}^{\infty}\Big[(0.7-1/n, 0.7+1/n)\cap(0,1]\Big]$ does not have to be contained in $\sigma(\mathcal{C})$ . Now, can anybody help me to figure out how my argument is not valid?","['measure-theory', 'lebesgue-measure', 'borel-measures', 'borel-sets', 'probability']"
4520385,"Solving $\frac{dx}{dt}=\frac{xt}{x^2+t^2},\ x(0)=1$","I have started self-studying differential equations and I have come across the following initial value problem $$\frac{dx}{dt}=\frac{xt}{x^2+t^2}, \quad x(0)=1$$ Now, since $f(t,x)=\frac{xt}{x^2+t^2}$ is such that $f(rt,rx)=f(t,x)$ for every $r\in\mathbb{R}\setminus\{0\}$ , we can use the change of variables $y=\frac{x}{t}$ to rewrite it in the form \begin{align}
y+t\frac{dy}{dt} &=\frac{t^2 y}{t^2(1+y^2)} \\
&=\frac{y}{1+y^2} \\
\implies t\frac{dy}{dt} &=\frac{y}{1+y^2}-y \\
&=-\frac{y^3}{1+y^2} \\
\implies \frac{dy}{dt} &= \left(-\frac{y^3}{1+y^2}\right)\cdot\frac{1}{t}
\end{align} which is separable, and becomes: \begin{align}
\left(\frac{1+y^2}{y^3}\right)dy &= -\frac{dt}{t} \\
\implies \int_{y_1}^{y_2} \left(\frac{1+y^2}{y^3}\right) dy &= -\int_{t_1}^{t_2} \frac{dt}{t} \\
\implies -\frac{1}{2y_2^2}+\ln \left\lvert \frac{y_2}{y_1} \right\rvert + \frac{1}{2y_1^2} &= -\ln \left\lvert \frac{t_2}{t_1} \right\rvert
\end{align} but now I don't see how to go forward and find $y(t)$ . Also, I integrated from a generic time $t_1$ to a generic time $t_2$ because the right hand side wouldn't have converged otherwise. So, I would appreciate any hint about how to go forward in solving this IVP. Thanks","['initial-value-problems', 'ordinary-differential-equations']"
4520388,Fundamental Theorem of Calculus with multiple variables,"I'm stuck on this multivariable equation: $$
\frac{d}{dx}\left(\int^x_af(g(b,t),t)dt\right)
$$ where a and b are just constants. If this involved a single variable, it looks like one would just apply the fundamental theorem of calculus. Is there an equivalent for multiple variables. I know that the answer should just be $$
f(g(b,x),x)
$$ but I'm hoping someone can explain / walk me through. Is there maybe some rule that lets me pass the $\frac{d}{dx}$ into the integral? Thanks","['multivariable-calculus', 'calculus']"
4520434,Integration $\int_{0}^{\infty} \frac{2x-1}{x^{2/3}\sqrt{(x+1)((x+1)^3-x)}}\text{d}x=0.$,"Here is the integral: $$\int_{0}^{\infty} \frac{2x-1}{x^{2/3}\sqrt{(x+1)((x+1)^3-x)}}\text{d}x=0.$$ This is an elliptic integral, with such an easy result, maybe some clever substitutions or integrating methods can solve it, but so far I don't know exactly how to attack it. Thought 1 :
To separate the integration interval into two parts: $(0,\frac12]$ and $[\frac12,+\infty)$ , for the second one, doing a substitution $x\mapsto \frac1x$ is my first thought(possibly not valid). Thought 2 :
It looks 100%, even 90%, like pseudo elliptic integral (its anti-derivative is elementary). I think this one is elementary as well. THOUGHT 3 : Maybe this is a very STUPID question. Perhaps some mathematical softwares can done it(especially for Mathematica). For some good reasons, I can't use them. Waiting for your replies.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'complex-integration']"
4520465,Dividing Factorial formula from book,"I'm reading a book Discrete Mathmatics with Cryptographic Applications and it claims that $\frac{n!}{k!} = (k+1)(k+2)...n$ for $k<n$ . But a very simple example where $n = 3$ and $k = 2, \frac{(1)(2)(3)}{(1)(2)} = 3 \neq (2+1)(2+2)(2+3)$ What am i misunderstanding here?","['cryptography', 'factorial', 'discrete-mathematics']"
4520506,Find the domain of the following function $ f(x)={(\ln x)}^{\ln^{2}x} $.,"I know that $ x \gt 0 $ because of logarithm precondition, and I can see that $ x \neq 1 $ because otherwise it would lead to $ 0^0$ which is problematic, but when I checked the graph of the function I have discovered that it started from $ 1 $ on $ x $ axis and $ (0,1) $ interval is not considered. In sum, I thought that the domain should have been $ (0, \infty) - \{1\}$ but it seems to be $(1,\infty)$ and I can't figure out where I am wrong.","['functions', 'real-analysis']"
4520520,Verify stokes theorem in spherical coordinates,"I got the vector field $F= r \sin^2 (\theta) \hat{r} + r\sin(\theta)\cos(\phi) \hat{\theta}+ r\cos^2(\theta)\sin(\phi) \hat{\phi}$ .
I‚Äôm trying to solve the integral $ \int_C F \cdot dl$ over a close path.
The idea is to use the volume stored in the upper hemisphere of radius $R$ $(x^2 + y^2 + z^2 =R^2, z>0)$ but I cannot use the stokes theorem, since the idea is to verify both integrals have the same result.
I don‚Äôt know how to parametrize the surface.  I know $dl= dr \hat{r} + rd\theta \hat{\theta} + r\sin(\theta) d\phi \hat{\phi}$ but I cannot integrate over a closed path with this.
Thank you!","['integration', 'multivariable-calculus', 'spherical-coordinates', 'stokes-theorem']"
4520552,Compute the limit $\lim_{x\to 0}\left(\frac{(1+x)^\frac{1}{x}}{e}\right)^\frac{1}{x}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question $\lim_{x\to 0}\left(\frac{(1+x)^\frac{1}{x}}{e}\right)^\frac{1}{x}$.
I tried adding $1$ and subtracting $1$ so I can use $1^\infty$ case.","['limits', 'calculus']"
4520568,Which One of the Integral Expression is Always Larger?,"I am a little bit stuck on solving the following problem: Let $f_n \in L_1$ for all $n \in \mathbb{N}$ . Which is always larger? $$
\left(\sum_{n = 1} ^\infty \left\lvert\int f_n \,d\mu\right\rvert^2\right)^\frac{1}{2}
$$ or $$
\int\left(\sum_{n = 1} ^\infty \lvert f_n\rvert^2\right)^\frac{1}{2} \,d\mu?
$$ My guess is that the second expression is always greater. The reason for the guess is if we consider this sum to be just one term, then we simply just have the triangle inequality for integrals. However, when I try to show this result to the finite case, I run into problems: \begin{align}
\left(\sum_{n = 1} ^k \left\lvert\int f_n \,d\mu\right\rvert^2\right)^{\frac{1}{2}} \leq \left(\sum_{n = 1} ^k \left(\int \lvert f_n\rvert \,d\mu\right)^2\right)^{\frac{1}{2}} \leq \left(\int \sum_{n = 1} ^k \lvert f_n\rvert \,d\mu\right).
\end{align} How do I incorporate the square and square root into the expression? If I could show this, the result should then be true through Monotone Convergence.","['alternative-proof', 'measure-theory', 'solution-verification']"
4520608,What does this math notation mean? $\min_{i} \|x_{i}\|$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $\qquad\min_{i} \|x_{i}\|$ I'm doing some machine learning problems and I ran into this notation. I don't understand what "" min i "" means in this case. Is it the smallest element in the norm of $x$ ? Any help would be appreciated.","['notation', 'statistics', 'machine-learning']"
4520637,evaluation of $\int\sqrt{\frac{e^{nx}}{e^{nx}+1}}dx:n\in \mathbb{Z^*}$,Compute the indefinite integral $$\displaystyle \int\sqrt{\frac{e^{nx}}{e^{nx}+1}}dx:n\in \mathbb{Z^*}$$ My Attempt:(The steps are shortened) $$\displaystyle e^{nx}=\sinh^{2}(y)\Rightarrow dx=\frac{2}{n}\frac{\ \cosh(y)dy}{\sinh(y)}$$ $$\displaystyle \sqrt{\frac{e^{nx}}{e^{nx}+1}}dx=\frac{2}{n}dy$$ $$\displaystyle \int\sqrt{\frac{e^{nx}}{e^{nx}+1}}dx=\frac{2}{n}y+c=\frac{2}{n}\text{arcsinh}(\sqrt{e^{nx}})+c=\frac{2}{n}\ln(\sqrt{e^{nx}}+\sqrt{e^{nx}+1})+c$$ I am a new beginner so you should encourage me and not demoralize me. Thank you,"['integration', 'indefinite-integrals', 'calculus', 'trigonometry']"
4520695,No perfect non-empty set in $\mathscr{P}(\Bbb{R})$ can be strong measure zero.,"Here is what to be proven: No perfect non-empty set in $\mathscr{P}(\Bbb{R})$ has strong measure zero. The textbook (Teor√≠a de la Medida, Jaime San Martin Aristegui, section 1.6) suggests the following approach: Suppose that $f\colon [0,1]\to \Bbb{R}$ is a continuous function and $A\subset [0,1]$ a strong measure $0$ set. Prove that $f(A)$ is also a strong measure $0$ set. Show that every perfect set $A\subset [0,1]$ (not empty) contains a set $F$ homeomorphic to the Cantor set and therefore $A$ can't be a strong measure $0$ set. I have already proven 1 but have no idea how to prove 2; in fact, I don't think it's true (intuitively, I'm not saying that the text book is wrong). Any hints or solutions are more than welcomed. The solution to the first point is available at this post, If $A\subset [0,1]$ is strong measure zero, then $f(A)$ is strong measure zero where $f\colon [0,1]\to \Bbb{R}$ is continuous.","['general-topology', 'cantor-set', 'measure-theory', 'real-analysis']"
4520713,Why should the rows of $AB^\top$ sum to one if the rows of $A$ and column of $B$ sum to one,"For $A \in \mathbb{R}^{a \times n}$ and $B \in \mathbb{R}^{b\times n}$ $$
\sum_j AB^\top = \mathbb{1}^a \quad \textit{iff} \quad \sum_jA = \mathbb{1}^a \quad \text{and} \quad \sum_i B = (\mathbb{1}^n)^\top
$$ I saw this immediately before section 3.4 of this paper (they are using different notation). I tested this with random matrices and it is true, but I cannot see why this should always be true. Is there some theorem or some easy reason to see why this is true?","['matrices', 'linear-algebra']"
4520757,Show a specific set has Hausdorff dimension 3/4,"Let $S$ be the set of points in $[0,1]$ such that every fourth digit is zero, i.e., the set of $x=0.a_1a_2a_3a_4...$ with $a_{4i}=0$ . How do I show that this set has Hausdorff dimension $\frac{3}{4}$ ? Can I use an argument similar to that used for the Cantor set on page 14 of Falconer's book The Geometry of Fractal Sets ? I am trying to find an argument that does not make reference to the idea of self-similarity dimension.","['measure-theory', 'hausdorff-measure', 'geometric-measure-theory', 'real-analysis', 'fractals']"
4520791,"Discussion of Example 2, section 7 on page 45 of Munkres‚Äô Topology.","In Example 2, section 7 on page 45 of Munkres‚Äô Topology, the problem is stated as follows. $$\mathbb{Z}_+\times\mathbb{Z}_+ \text{ is countably infinite.}$$ First, he defines a function $f:\mathbb{Z}_+\times\mathbb{Z}_+\rightarrow A$ , where $A$ the subset of $\mathbb{Z}_+\times\mathbb{Z}_+$ consisting of pairs $(x,y)$ for which $y\le x$ by the equation $$f\left(x,y\right)=(x+y-1,y),$$ and he defines a function $g:A\rightarrow\mathbb{Z}_+$ by the formula $g\left(x,y\right)=\frac{1}{2}\left(x-1\right)x+y$ . Then he leaves it to the reader to show that $f$ and $g$ are bijections. Though there is a similar question, unfortunately, it isn‚Äôt in detail. So I have attempted a detail one. The following is my attempt to proof of bijections. Let $f\left(x,y\right)=\left(x^\prime,y^\prime\right)$ . If $x=1$ , then $f\left(1,y\right)=(y,y)$ ; hence $y^\prime=x^\prime$ .
If $x>1$ , then $x-1>0$ and $x+y-1>y$ . So $y^\prime<x^\prime$ . Thus, $\forall\left(x,y\right),\ f\left(x,y\right)\in A$ . Let $f\left(x_1,\ y_1\right)=f(x_2,y_2)$ .
Then $\left(x_1+y_1-1,y_1\right)=(x_2+y_2-1,y_2)$ implying that $y_1=y_2$ ; and hence $x_1=x_2$ .
Thus, $f\left(x_1,\ y_1\right)=f\left(x_2,y_2\right)\Longrightarrow\left(x_1,y_1\right)=(x_2,y_2)$ . So, $f$ is injective. Let $x^\prime,y^\prime$ be given point in $A$ . Since $y^\prime\le x^\prime$ , there exists a positive integer $x \in \mathbb{Z}_+$ such that $$ x^\prime+1=x+y^\prime, \text{ i.e.}, x^\prime=x+y^\prime-1.$$ Therefore, for every $(x^\prime,y^\prime)\in\ A$ , there exists $(x,y) \in \mathbb{Z}_+\times\mathbb{Z}_+$ such that $f(x,y)=(x^\prime,y^\prime).$ Hence $f$ is surjective; and hence bijective. Next consider the function $g:A\rightarrow\mathbb{Z}_+$ .
Since $A\subset\mathbb{Z}_+\times\mathbb{Z}_+$ , it is clear that $\forall\left(x,y\right)\in A,\ g\left(x,y\right)=\frac{1}{2}\left(x-1\right)x+y\in\mathbb{Z}_+$ for $2\ |\ (x-1)x$ . Suppose $\left(x_1,y_1\right)\neq\left(x_2,y_2\right)$ . Clearly we have $y_1\le x_1,\ \ y_2\le x_2$ . If $x_1=x_2$ , then $y_1\neq y_2$ and vice-versa. In these cases, $\frac{1}{2}\left(x_1-1\right)x_1+y_1\neq\frac{1}{2}\left(x_2-1\right)x_2+y_2$ .
If $x_1=y_2$ , then $x_2>y_2=x_1>y_1$ and vice-versa. In these cases, $\frac{1}{2}\left(x_1-1\right)x_1+y_1=\frac{1}{2}\left(y_2-1\right)y_2+y_1<\frac{1}{2}\left(x_2-1\right)x_2+y_2$ and vice-versa. Hence, in either case, it is clear that $\left(x_1,y_1\right)\neq\left(x_2,y_2\right)\Longrightarrow g\left(x_1,y_1\right)\neq g(x_2,y_2)$ . That is, $g\left(x_1,\ y_1\right)=g\left(x_2,y_2\right)\Longrightarrow\left(x_1,y_1\right)=\left(x_2,y_2\right)$ .
Thus, g is injective. Let $z$ be given point in $\mathbb{Z}_+$ .
We can choose $x$ in $\mathbb{Z}_+$ such that $2z \le (x+1)x$ . Then, $2z \le (x+1)x \implies \left(x-1\right)x+2y \le (x+1)x \implies y\le x$ . Thus, we can choose $(x,y)\in A$ for which $y\le x$ such that $2z=\left(x-1\right)x+2y$ .
Therefore, for every $z\in\mathbb{Z}_+$ , there exists $\left(x,y\right)\in A$ for which $y\le x$ such that $g\left(x,y\right)=z.$ Hence $g$ is surjective; and hence bijective.
It follows that $g\circ f:\mathbb{Z}_+\times\mathbb{Z}_+\rightarrow\mathbb{Z}_+$ is bijective. Hence $\mathbb{Z}_+\times\mathbb{Z}_+$ is countably infinite.‚àé I wonder if my attempt is valid or not, if not, please suggest me.","['elementary-set-theory', 'functions']"
4520811,How is this an equation of a line?,"First let me start that I have read some related questions on MathStackExchange, yet none really answers my question. I am trying to understand the proof that M√∂bius transformations map lines and circles into lines and circles. But I am stuck already at the beginning, as I can not, no matter what I do, understand the complex equation of a line. We wrote than a general equation of a line in $\mathbb{C}$ is: $\text{Re}(\overline{\alpha}z) = b$ . How is that a line? How to see it geometrically and understand that this is a line? Some of the things I have written that the professor said are: This is actually a scalar product. When we multiply by $i$ , we rotate by $90 ^{\circ}$ , so the points that are perpendicular on $\alpha$ , are exactly of the form $i \alpha$ , so they are in the kernel, then we also have a translation for $b$ . These comments make no sense (to me), as I cannot see in any way, how this is even an equation of a line. I would appreciate if someone thoroughly explains how this represents a line and the direct geometric intrepretation of it.","['complex-analysis', 'complex-numbers', 'mobius-transformation']"
4520846,"How many methods are there to find the closed form of $ \int_{0}^{\frac{\pi}{2}} \frac{d x}{(\sin x+\cos x)^{ n}}, \textrm{ where } n\in N $","Latest Edit Great thanks to @Quanto for his closed form for $$\int_{0}^{\frac{\pi}{4}} \sec^{2n+1} x \ dx=
 \frac1{2^{2n}}
 \binom {2n}n \ln(\sqrt2+1) +\sum_{k=0}^{n-1} \binom {2n}k \frac{(\sqrt2+1)^{2(n-k)} - (\sqrt2-1)^{2(n-k)}}{2^{2n+1}(n-k)}, $$ by which the closed form for integrals with odd powers can be found as $$\boxed{\quad  \int_{0}^{\frac{\pi}{2}} \frac{d x}{(\sin x+\cos x)^{2 n+1}}\\=
 \frac1{2^{3n-\frac{1}{2} }}
 \binom {2n}n \ln(\sqrt2+1) +\sum_{k=0}^{n-1} \binom {2n}k \frac{(\sqrt2+1)^{2(n-k)} - (\sqrt2-1)^{2(n-k)}}{2^{3n+\frac{1}{2} }(n-k)} } $$ Inspired by the post , I firstly try to generalise it to even powers as $$
I_{n}=\int_{0}^{\frac{\pi}{2}} \frac{d x}{(\sin x+\cos x)^{2 n}},
$$ where $n\in N.$ For simplicity, we express the denominator as cosine using compound angle formula. $$
\begin{aligned}
I_{n} &=\int_{0}^{\frac{\pi}{2}} \frac{d x}{(\sin x+\cos x)^{2 n}} \\
&=\int_{0}^{\frac{\pi}{2}} \frac{d x}{\left[\sqrt{2} \cos \left(\frac{\pi}{4}-x\right)\right]^{2 n}} \\
& \stackrel{x\mapsto\frac{\pi}{2}-x}{=}  \frac{1}{2^{n}}\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d x}{\cos ^{2 n} x}\\ & \stackrel{Symm}{=} \frac{1}{2^{n-1}} \int_{0}^{\frac{\pi}{4}} \sec ^{2 n} x d x 
\end{aligned}
$$ Letting $t= \tan x$ yields $$
\begin{aligned}
I_{n} &= \frac{1}{2^{n-1}}\int_{0}^{1}\left(1+t^{2}\right)^{n-1} d t \\
&= \frac{1}{2^{n-1}} \sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \int_{0}^{1} t^{2 k} d t \\
&=\boxed{\frac{1}{2^{n-1}}  \sum_{k=0}^{n-1}\left(\begin{array}{l}
n-1 \\
\quad  k
\end{array}\right) \frac{1}{2 k+1}}
\end{aligned}
$$ Examples: $$
I_{2} =\frac{1}{2}\left(1+\frac{1}{3}\right)=\frac{2}{3},I_{5}=\frac{83}{315}; I_{10}=\frac{26206}{230945};
$$ However, it is harder to find the integral of odd powers. $$
J_{n}=\int_{0}^{\frac{\pi}{2}} \frac{d x}{(\sin x+\cos x)^{2 n+1}}= \frac{1}{2^{n-\frac{1}{2} }} \int_{0}^{\frac{\pi}{4}} \sec ^{2 n+1} x d x 
$$ where $n=0, 1, 2,‚Ä¶$ I had found a reduction formula for it as $$
\boxed{J_{n+1}=\frac{1}{2 n}+\frac{2 n-1}{4 n} J_{n}}
$$ via the reduction formula for $$
\int_{0}^{\frac{\pi}{4}} \sec ^{2 n+1} x d x=\frac{1}{2 n}\left[2^{n-\frac{1}{2}}+(2 n-1) \int_{0}^{\frac{\pi}{4}} \sec ^{2 n-1} x d x\right]
$$ Examples $$
\begin{aligned}
J_{0} &=\sqrt{2} \int_{0}^{\frac{\pi}{4}} \sec x d x \\
&=\sqrt{2}\left|\ln \left|\sec x+\tan x\right|\right]_{0} ^{\frac{\pi}{4}}\\
&=\sqrt{2} \ln (\sqrt{2}+1)
\end{aligned}
$$ \begin{align}
\begin{aligned}
J_{1} &=\frac{1}{2}+\frac{1}{4} \cdot \sqrt{2} \ln (\sqrt{2}+1) \\
&=\frac{1}{2}+\frac{1}{2 \sqrt{2}} \ln (\sqrt{2}+1)
\end{aligned}
\end{align} $$
\begin{aligned}
J_{2} &=\frac{1}{4}+\frac{3}{8}\left[\frac{1}{2}+\frac{1}{2 \sqrt{2}} \ln (\sqrt{2}+1)\right] \\
&=\frac{7}{16}+\frac{3}{16 \sqrt{2}} \ln (\sqrt{2}+1)
\end{aligned}
$$ Although I can find the integral with odd powers one by one, I still can‚Äôt find its closed form. Your help will be highly appreciated .","['integration', 'calculus', 'reduction-formula', 'trigonometric-integrals']"
4520876,"If $f(x) =\frac{3 + 7^{2x}}4$, which of the following is the inverse?","If $f(x) = \frac{3 + 7^{2x}}  4$ , what is the inverse function $f^{-1}(x)$ ? Initially, I thought it would simplify down to $\frac 12 \log_7(4x-3)$ But apparently that is not correct.","['algebra-precalculus', 'inverse-function']"
4520959,A presentation for $(\Bbb Z/2)^3$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question I‚Äôm reading the book ‚ÄúGeometric group theory: an introduction‚Äù, written by Clara Loh.
In the introduction part there‚Äôs the following exercise about presentations of groups (exercise 2.E.24): Prove that $$\langle s_1,s_2,s_3 \mid (s_1s_2)^2,(s_1s_3)^2, (s_2s_3)^2\rangle\cong (\Bbb Z/2)^3$$ I tried to prove that the generators need to have order two, but I wasn‚Äôt able to.
I thought that maybe it could be useful two prove that the $s_is_j$ ‚Äôs commute with the each other and then show that these products generate the entire group.","['group-presentation', 'group-theory', 'finite-groups']"
4520974,Solve $\sin(z) = \frac{3+i}{4}$,"What i did so far was this: $$\sin(z)=\frac{3+i}{4}\Rightarrow\frac{e^{iz}-e^{-iz}}{2i}=\frac{3+i}{4}\Rightarrow e^{2iz}-1=\left(\frac{-1+3i}{2}\right)e^{iz}$$ setting $u=e^{iz}$ we'll have $$u^2+\left(\frac{1-3i}{2}\right)u-1=0$$ completing squares $$\left(u+\frac{1-3i}{4}\right)^2=\frac{3}{8}(1+i)$$ seting $w=u + \frac{1-3i}{4}$ $$w^2=\frac{3}{8}(1+i)$$ solving $$w=\pm2^{\frac{-5}{4}}\sqrt{3}\left(\cos\left(\frac{\sqrt{2}}{4}\right)+i\sin\left(\frac{\sqrt{2}}{4}\right)\right)$$ now i just have to substitute this in $w=u + \frac{1-3i}{4}$ and then in $u=e^{iz}$ , but the solution looks really big and really different from the answer i got from here . So what did i do wrong? Or, if i didn't do anything wrong, can i simplify somewhere?","['complex-analysis', 'trigonometry', 'complex-numbers']"
4520988,Self contained exposition of second order Fuchsian ODEs,"I am teaching a graduate course in Complex Analysis.  I would like students to give an oral presentation at the end of the term on a topic which we did not cover in the lecture.  So I am putting together a list of textbook chapters and expository papers on various topics. One topic which I think is very nice, and uses many of the tools we will cover in the course, is the theory of second order Fuchsian ODEs.  However, I have been unable to find an exposition of this topic which is ""self contained"" in the sense that it is relatively short (10 to 15 pages) and assumes only the background of a one semester complex analysis course (basically they will know all the machinery leading up to the Residue theorem). Can anyone recommend such a resource?","['complex-analysis', 'monodromy', 'ordinary-differential-equations', 'reference-request']"
4521021,Radius and interval of convergence for $\sum_{n=2}^\infty \frac{x^{2n}}{n\ln^2(n)}$,"I was requested to show radius and interval of convergence for the series $$\sum_{n=2}^\infty \frac{x^{2n}}{n\ln^2(n)}$$ and was wondering if my result is correct. This was my approach. $i)$ $a_n := \frac{x^{2n}}{n\ln^2(n)} = \frac{(x^2)^n}{n\ln^2(n)}$ . We have $$|\frac{a_{n+1}}{a_n}| = \frac{|(x^2)^{n+1}|}{(n+1)\ln^2(n+1)}\times\frac{n \ln^2(n)}{|(x^2)^n|}$$ $$= \frac{n\ln^2(n)}{(n+1) \ln^2(n+1)}|x^2|$$ Because $\lim_{n\to\infty} (\frac{\ln x}{\ln (x+1)})^2 = 1$ (through L'Hopital) we have $$\lim_{n\to\infty} \frac{n\ln^2(n)}{(n+1) \ln^2(n+1)}= \lim_{n\to\infty} \Big((\frac{\ln(n)}{ln(n+1)})^2\Big) \times \lim_{n\to\infty}\frac{n}{n+1} =1 \times 1=1$$ and therefore $|\frac{a_{n+1}}{a_n}| \to |x^2|$ when $n \to \infty$ . $ii)$ $|x^2|=x^2 <1 \iff x \in(-1, 1) \equiv |x| <1$ . This already implies a radius of convergence of $1$ . $iii)$ $x=1 \implies a_n = \frac{1}{n\ln^2(n)}$ . Since $$\int_{2}^\infty \frac{1}{x \ln^2x} dx= \lim_{t\to\infty}\int_2^t \frac{1}{u^2}du \tag{$u=\ln x$}$$ $$= \lim_{t\to\infty} (-\frac{1}{t} + \frac{1}{2}) = \frac{1}{2}$$ we know the series will converge when $x=1$ via the integral test. For $x=-1$ , $a_n=\frac{((-1)^2)^n}{n \ln^2 n} = \frac{1}{n \ln^2 n}$ , the same case we already examined. Therefore,the interval of convergence is $[-1, 1]$ . Final answer . $R= 1, I=[-1, 1]$ . Is this answer correct?","['calculus', 'sequences-and-series', 'power-series', 'limits', 'convergence-divergence']"
4521036,Derivative of AX'B with respect to X,"Since $\frac{\partial \left( AXB \right)}{\partial X}={{B}^{T}}\otimes A$ ,
What is $\frac{\partial \left( A{{X}^{T}}B \right)}{\partial X}$ ? Thank you for your help.","['matrices', 'derivatives', 'linear-algebra']"
4521068,How many digit number I have to write if I write $2^n$ exponential sequence from 1 to $2^{1000}$?,"If I write sequence $2^n$ exponential sequence, ""1,2,4,8,16,..."" until I reach $2^{1000}$ , how many digit number I have to write ? I try using the method that work for linear sequence by writing some first sequence and find the pattern. 1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262144,524288,1048576,2097152,4194304,8388608,16777216,33554432,67108864,134217728,268435456,536870912,1073741824,... The total digit number seem to be repeat (1+1+1+1)+(2+2+2)+(3+3+3)+(4+4+4+4)+(5+5+5)+(6+6+6)+(7+7+7+7)+(8+8+8)+(9+9+9)+... The total digit number from I have to write from 1 to 536870912 or $2^{29}$ is 4(1)+3(2)+3(3)+4(4)+3(5)+3(6)+4(7)+3(8)+3(9) = 147. From this, I get Total digit number from I have to write for number $2^{(10n-10)}$ , $2^{(10n-9)}$ , $2^{(10n-8)}$ , $2^{(10n-7)}$ is $3n-2$ if n>0 Total digit number from I have to write for number $2^{(10n-6)}$ , $2^{(10n-5)}$ , $2^{(10n-4)}$ is $3n-1$ if n>0 Total digit number from I have to write for number $2^{(10n-3)}$ , $2^{(10n-2)}$ , $2^{(10n-1)}$ is $3n$ if n>0 Total digit number from I have to write from 1 to $2^{(10n-1)}$ is $\sum_{k=1}^{n} \biggl(4(3k-2)+3(3k-1)+3(3k)\biggl)$ if n>0 So, the total digit number from I have to write from 1 to $2^{1000}$ is $(3(101)-2)+\sum_{k=0}^{100} \biggl(4(3k-2)+3(3k-1)+3(3k)\biggl) = 301+150400 = 150701$ . Am I get the correct answer ? I am not sure since it is a method for linear sequence not exponential sequence. If my answer isn't correct answer, what is the correct answer ?","['algebra-precalculus', 'combinatorics', 'problem-solving', 'discrete-mathematics']"
4521075,How to generate exponential distributions from finite random variables?,"Let $ {\textstyle \{X_{1},\ldots ,X_{n},\ldots \}}$ be a sequence random variables For the summation of those random variable: $ {\displaystyle {\bar {X}}_{n}\equiv {\frac {X_{1}+\cdots +X_{n}}{n}}}$ We know if each $X_i$ is a random variable for an independent simple binominal random walk, then ${\bar {X}}_{n}$ follow a normal distribution. Question: What kind of simple sequences of random variables (which takes finite values) can naturally lead to an exponential distribution in the limit (like binormal random walks do for normal distributions) ?","['stochastic-processes', 'probability-distributions', 'combinatorics', 'random-variables']"
4521096,Any two sets of continuum cardinality are equinumerous?,Is it true that any two uncountable subsets of $\mathbb{R}$ is equinumerous? If yes how to prove that? More generally can I say two sets of same Cardinality are equinumerous? equinumerous means there is a bijective map between them,"['elementary-set-theory', 'real-numbers', 'cardinals', 'real-analysis']"
4521192,Does a Lower Bounded Differentiable Function Always Have Arbitrarily Small Gradient?,"I am studying optimization and the following question occurred to me: Suppose $f:\mathbb{R}^n\to\mathbb{R}$ is differentiable and bounded below. Is it true that for every $\epsilon>0$ , there exists $x\in\mathbb{R}^n$ such that $\|\nabla f(x)\|<\epsilon$ ? I am able to show that this is true for $n=1$ . Let $f^*=\inf_{x\in\mathbb{R}}f(x)$ , then there exists a sequence $\{x_n\}$ such that $f(x_n)\to f^*$ . There are two cases. Case 1. If $\{x_n\}$ has a limit point $x^*$ , then $f(x^*)=f^*$ , so $x^*$ is a global minimizer and $f'(x^*)=0$ . Case 2. If $\{x_n\}$ does not have a limit point, then $|x_n|\to\infty$ . By Mean Value Theorem, there exists $\xi_n$ such that $f(x_n)-f(0)=f'(\xi_n)x_n$ . Thus $|f'(\xi_n)|=|f(x_n)-f(0)|/|x_n|\to0$ . In $\mathbb{R}^n$ , the analysis of case 1 is the same, but case 2 does not generalize naturally, because MVT becomes $f(x_n)-f(0)=\nabla f(\xi_n)^\top x_n$ . Is there a way to get around this?","['optimization', 'multivariable-calculus', 'real-analysis']"
4521201,Are initial submanifolds cofibrations?,"In Natural Operations in Differential Geometry by Kolar, Michor, & Slovak, they define an initial submanifold as follows: They can be shown to satisfy the following universal property: I am aware that the inclusion of an embedded submanifold is a cofibration, and I am wondering if the same holds for the more general class of initial submanifolds?","['general-topology', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
4521206,Show that a countable and dense set $A$ of $\mathbb{R}$ is not closed.,"Show that a countable and dense set $A$ of $\mathbb{R}$ is not closed.
Deduce that $\mathbb{R}$ is not countable. Hint: Let $(a_n)$ be a sequence obtained by ranking the points of $A$ in a certain order, define a sequence of intervals $[b_n , c_n ]$ such that $b_{n-1} < b_n < c_n < c_{n-1}$ , whatever $n$ is, and that $[b_n,c_n]$ contains no point $a_k$ such that $k < n$ . It's hard for me to see how I can define such a sequence of intervals with only the sequence $a_n$ . Then I think that I have to apply the Borel-Lebesgue theorem, saying that any compact set A is closed and bounded.","['general-topology', 'compactness', 'real-analysis']"
4521207,Are all principal curvatures equal at an isotropy point?,"Suppose $M$ is a hypersurface embedded in a Riemannian manifold $(N, g)$ and there exists $p\in M$ s.t. for any two tangent vectors $u,v\in T_pM$ we can find an isometry $\phi$ of $M$ fixing $p$ s.t. $d\phi_p u=v$ . Because there is no preferred direction, it seems intuitive that all principal curvatures of $M$ at $p$ are equal. An identity that would immediately prove this hypothesis would be $$ s \phi_* v=\phi_* sv,$$ Where $s$ is the shape operator of $M$ . This equation is equivalent to $$h(\phi_* v, \phi_* w) = g(s \phi_* v, \phi_*w) = g(\phi_* sv,\phi_*w) = g(sv,w)=h(v,w),$$ Where $h$ is the scalar second fundamental form of $M$ . Since $h$ is related to the Levi-Civita connection, which is invariant under isometries, I would expect $h$ to also be preserved under $\phi$ , but the fact that we also need to consider the connection in the ambient manifold $N$ confounds me. Is the claim even true?","['curvature', 'differential-geometry']"
4521210,How to best characterize a monotonic real valued function defined on a power set?,"The question is pretty vague because it arises from an application scenario and is open-ended. $\mathcal{S}$ is a countable infinite set, $f$ is a function defined on the power set of $\mathcal{S}$ , mapping any subset of $\mathcal{S}$ to a real number in $[0, 1]$ . $f$ is known to satisfy the following properties: For any $S_0 \subseteq S_1$ , $f(S_0) \leq f(S_1)$ . For any $S$ with $|S| \leq 1$ ( $|S|$ being the carnality of $S$ ) we have $f(S) \in \{0, 1\}$ . There exists infinitely many $S$ (not depending on $f$ ) such that $|S| = 2$ and $f(S) = 1$ . There exists a set $S_T$ (not depending on $f$ ) such that $|S_T| = \infty$ and $f(S_T) = 0$ . What's the best way to ""characterize"" $f$ ? i.e., what extra information (as minimal as possible) is needed to determine or construct $f$ ? For example, it would be great if we can say $f$ is uniquely determined by (or can be constructed from) $f(S)$ for any $S$ with $|S| = 3$ (this is not necessarily true, just an example of a helpful result).",['discrete-mathematics']
4521216,Can the tape of a Turing machine be represented as a discrete function?,"I'm just thinking aloud here, and to expand on this, each square of the tape could lie between integers, and discrete y values of the function could map to symbols. That way a given discrete/step function could describe a given program, and vice versa. I'm playing with ideas of somehow using integration on some analytic analogue of such a function to give some indication on whether the program halts.","['discrete-mathematics', 'turing-machines']"
