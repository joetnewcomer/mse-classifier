question_id,title,body,tags
2062991,Dimension of extension of scalars,"The context is this: Let's say $X$ is an affine scheme of finite type over a field $k$. Then if $K$ is a field extension of $k$, you can consider the affine scheme $X_K$. Are the dimensions of $X$ and $X_K$ equal?",['algebraic-geometry']
2063015,"If $\Sigma$ is a covariance matrix, how to obtain the decomposition $\Sigma = \Sigma^{1/2}(\Sigma^{1/2})^T$ from Cholesky Decompositon?","I read somewhere that if $\Sigma$ is a covariance matrix, one can obtain the decomposition $\Sigma = \Sigma^{1/2}(\Sigma^{1/2})^T$ from Cholesky Decompositon. However, I am confused how because Cholesky decomposition requires an upper and lower triangular matrix. How can the square root here for upper and lower triangular, or can it?","['matrices', 'matrix-decomposition', 'statistics', 'linear-algebra']"
2063017,"If one egg is found to be good, then what is the probability that other is also good?","A basket contains 10 eggs out of which 3 are rotten. Two eggs are taken out together at random. If one egg is found to be good, then what is the Probability that other is also good? I applied conditional probability. It says that one of them is good, so the probability of the other one being good can be found in the 9 eggs left out of which 6 are good, so Probability = $6/9$ Am I right with my understanding?","['permutations', 'combinatorics', 'combinations']"
2063036,Proof of Probability of Set Difference,I've been trying to figure out a rigorous proof for the following identity but I'm getting nowhere: $P[A\setminus B]=P[A]-P[A \cap B]$ It seems obvious with Venn diagrams but I'm interested in a formal proof for this. Any help and/or hints appreciated!,"['probability-theory', 'probability', 'elementary-set-theory']"
2063060,What is the relationship between the asymptotic series outside the radius of convergence and the analytic continuation?,"In his post about computing the zeta function by smooth cutoff regularization of the series $\sum\frac{1}{n^2}$, Terry Tao shows how $-{1\over 12}$ is the finite part of the asymptotic series for the smooth cutoff regularization of the sum $\sum\frac{1}{n}$. In the last section of his post, he justifies why that value should match the analytic continuation of the function from its convergent domain. While all the steps of that argument make sense, I am somehow missing the larger picture. Can someone attempt another explanation? Let's make my question more concrete. If $f(z)=\sum a_nz^n$ is absolutely convergent for $\lvert z\rvert < R$ with a pole at some $z_0$, $\lvert z_0\rvert = R$, and has analytic continuation $\tilde f(z)$ defined on $\mathbb{C}\setminus z_0$, is there some standard way to break $f$ into an asymptotic series, with a demarcated finite part and infinite part? Like $f(z)\sim\sum_{n=1}^N b_n\epsilon^{-n} +\sum_{n=0}^\infty c_n\epsilon^n$ as $\epsilon\to 0$, and with $\sum_{n=0}^\infty c_n\epsilon^n\to \tilde f(z)$. If we discard the divergent part, the finite part matches the analytic continuation. Why? This is what Tao does, and seems to also match the approach of some shady QFT maneuvers.","['real-analysis', 'asymptotics', 'complex-analysis', 'analytic-continuation', 'convergence-divergence']"
2063070,Which quantity is bigger (practice GRE question),"Given, x is a real number Quantity A: $$(x-2)(x-4)(x+5)$$ Quantity B: $$(x-5)(x^2+5x+5)+68$$ The first thing I did was to expand Quantity B and after combining like terms I get $$x^3-20x+43$$ Since $43$ is prime I can't (I don't think) factor that so I decide to subtract that from Quantity A, but first I expand quantity A and, after combining like terms, I get $$x^3-x^2-22x+40$$ so after subtracting quantity B from quantity A I get $$x^3-x^2-22x+40-x^3+20x-43$$
$$-x^2-2x-3$$ Immediately I can see that the discriminate of that is less than zero so the roots will be imaginary which violates the real number constraint that was given so I select ""can not be determined"".  However, the answer key acknowledges the negative discriminate but then says that because the roots are imaginary that quantity B is bigger.  Could someone help me understand how they came up with that?",['algebra-precalculus']
2063078,Does the limit $\lim _{x\to 0} \frac 1x \int_0^x \left|\cos \frac 1t \right| dt$ exists?,Does the limit $\lim _{x\to 0} \frac 1x \int_0^x \left|\cos \frac 1t \right| dt$ exists ? If it does then what is the value ? I don't think even L'Hospital's rule can be applied . Please help . Thanks in advance,"['derivatives', 'real-analysis', 'riemann-integration', 'limits']"
2063105,Translation of eigenvalue and its bound,"Picture below is from AN UPPER BOUND TO THE SPECTRUM OF $\Delta$ ON A MANIFOLD OF NEGATIVE CURVATURE . First, how to get (6) from (5)  ?  The (6) implies $f^{old}=f^{new}\sqrt{g}$ . But I can't get it from $f'^{~new}=\sqrt{g}f'^{~old}$ . Because $\sqrt{g}$ and $f$ are functions of $r$ . Then integrate them , there will be not $f^{old}=f^{new}\sqrt{g}$ . Second, How to get (7) from (4) ? Thanks for any help.","['eigenvalues-eigenvectors', 'riemannian-geometry', 'partial-differential-equations', 'laplacian', 'differential-geometry']"
2063137,Series related to the Mandelbrot set,"Apologies if this question has been asked here before. The Mandelbrot set is the set of complex numbers $c$ for which the iteration $z_{n+1}(c)=z_n (c)^2+c$ with $z_0(c)=0$ does not diverge (we write $z_\infty(c)=\lim\limits_{n\rightarrow\infty}z_n(c)$ where it converges). Thus every $z_n(c)$ can be written as a polynomial in $c$ of order $2^{n-1}$, so we define: $$z_n(c)=\sum_{j=0}^\infty \beta_{n,j}c^j$$ where $\beta_{n.j}$ is only nonzero for $j\le2^{n-1}$. Using the Mandelbrot iteration formula and the Cauchy product , we get: $$\beta_{n+1,j}=\begin{cases}\sum\limits_{k=0}^j\beta_{n,k}\beta_{n,j-k}&j\ne1\\2\beta_{n,0}\beta_{n,1}+1&j=1\end{cases}\tag{1}$$ Now $\beta_{n,0}=0\;\;\forall n\ge0$ and $\beta_{n,1}=1\;\;\forall n\ge1$ and using $(1)$ we can show that $\beta_{n+1,2}=\beta_{n,1}^2=1\;\;\forall n\ge1$, that $\beta_{n+1,3}=2\;\;\forall n\ge2$ and in general that $\beta_{n,j}=\beta_j\;\;\forall n\ge j$ where: $$\beta_j=\begin{cases}0&j=0\\1&j=1\\\sum\limits_{k=0}^j \beta_k\beta_{j-k}&j\ge2\end{cases}$$ (I calculated the first few terms $0,1,1,2,5,14,42,132,429,...$ by hand, but the OEIS would not give me a general formula). Thus the first $n+1$ terms of $z_n(c)$ are $\beta_i c^i$ as seen here in red: $$z_0(c)=\color{#ff0000}{0}$$
$$z_1(c)=\color{#ff0000}{0+c}$$
$$z_2(c)=\color{#ff0000}{0+c+c^2}$$
$$z_3(c)=\color{#ff0000}{0+c+c^2+2c^3}+\color{#0000ff}{c^4}$$
$$z_4(c)=\color{#ff0000}{0+c+c^2+2c^3+5c^4}+\color{#0000ff}{6c^5+6c^6+4c^7+c^8}$$ and so on. Thus as $n\rightarrow\infty$ the first $n+1$ terms of $z_n(c)$ will tend to the following series: $$z(c)=\sum_{j=0}^\infty\beta_j c^j\tag{2}$$ However, because of the extra $2^{n-1}-n$ terms in $z_n(c)$ (shown in blue), I assume that $\{z_n(c)\}$ will not always converge to $z(c)$, especially since the Mandelbrot set is not a disc (and power series converge within discs), but I do not know of any way of describing the extra terms which will enable a connection to be made between the convergence of the Mandelbrot iteration and the convergence of $(2)$. My questions are the following: For what $c$ are $\color{blue}{the\ blue\ terms}$ small enough that $z(c)=z_\infty(c)$, How if at all is the convergence of $(2)$ connected with the convergence of the iteration $z_{n+1}=z_n^2+c$? I would also to like to know whether there is a closed form for $z(c)$ [see comment] What is the radius of convergence of $(2)$?","['polynomials', 'complex-numbers', 'fractals', 'convergence-divergence', 'sequences-and-series']"
2063138,Partial derivative isn't continuous,"I would like verification on a calculation that shows $f$ below is differentiable at $(0,0)$ but $f_x$ is not continuous at $(0,0)$. $$f(x,y)=(x^2+y^2)\sin(\frac{1}{x^2+y^2})$$ when $(x,y)\neq (0,0)$ and $f(0,0)=0$. So assuming for the moment that the function is differentiable at $(0,0)$ (it is), this shows that $f_x(0,0)$ exists.  In fact, it is easy to see $f_x(0,0)=0$ by applying the definition of the derivative and using the squeeze theorem.  Then by standard computation we get that away from the origin 
$$f_x(x,y)=2x\left(\sin\left(\frac{1}{x^2+y^2}\right)-\frac{\cos\left(\frac{1}{x^2+y^2}\right)}{x^2+y^2}\right)$$ Here is where I'm a little fuzzy....   I found that $\lim_{(x,0)\to (0,0)} f_x=0$ and so this isn't helpful.   I need to find a path that makes the limit not equal to zero, right?  What if I find a path where the limit doesn't exist? Is this enough?  I have a result that says $$\lim_{(x,y)\to(0,0)}g(x,y)=\lim_{r\to 0^+} g(r\cos\theta,r\sin\theta)$$ I guess I prefer working in these coordinates because then I don't have to worry about the path.  I computed the following $$\lim_{r\to 0^+} f_x(r,\theta)=2r\cos\theta\left(\sin(r^{-2})-r^{-2}\cos(r^{-2})\right)$$ Where $2r\cos\theta\sin(\frac{1}{r^2})\to0$ by the squeeze theorem and the second term's limit does not exist (right?)  So I have two questions: 1) Does this prove that $f_x$ is not continuous since this limit does not exist? Or should I work in Cartesian coordinates and find a path that shows the limit depends on the path. 2) Can I always do this switch to polar coordinates (where the above centred equation holds true)?  Does there need to be polar symmetry?  I don't believe this function has polar symmetry.","['multivariable-calculus', 'real-analysis']"
2063147,Proof of Fubini's theorem for infinite sums.,"In his book Analysis 1, the author Tao states Fubini's theorem as follows Let $f:N \times N \rightarrow \mathbb{R}$ be a function such that $\sum_{(n,m)\in N\times N}f(n,m)  $ is absolutely convergent. Then we have $$\begin{align*}
\sum_{n=0}^{\infty}\Bigg(\sum^{\infty}_{m=0}f(n,m)\Bigg) &=\sum_{(n,m)\in N \times N}f(n,m) \\
&=\sum_{(m,n)\in N \times N}f(n,m)\\
&=\sum_{m=0}^{\infty}\Bigg(\sum^{\infty}_{n=0}f(n,m)\Bigg)
\end{align*}$$ He says that the second inequality follows from the rearrangement of absolutely convergent series. But that theorem is for bijective functions $f:N\rightarrow N$. How can we use it to obtain the second equality in the theorem stated above ?","['real-analysis', 'sequences-and-series', 'analysis']"
2063151,Periodic sequences given by recurrence relations,"Question: Is there any sort of theory on periodic sequences given by recurrence relations? I cannot describe what makes the examples at the bottom interesting, or what I could possibly want to know about a general theory (if one exists). I hope they are more than just curiosities, but I cannot really tell where, in the mathematical world, they fit, or where I could go to learn anything about them. What I know: (possibly a red herring, or running before crawling) To exclude sequences like $x \mapsto x + k \pmod p$ that are obviously periodic, the interesting examples I've seen so far have terms that are Laurent polynomials in the first two terms $a_1 = x$ and $a_2 = y$. This is even called the Laurent Phenomenon (I personally know very little about Laurent polynomials). Based on my research (primarily Fomin and Reading's notes Root Systems and Generalized Associahedra and web searches), there are certain structures called cluster algebras (or, evidently, Laurent phenomenon algebras ) that seem to have been created with these recurrence relations in mind, or as a motivation, or create them as a natural byproduct (I don't know). Although I've taken some courses in combinatorics in which recurrence relations were covered, I really don't remember anything periodic happening, just the basic stuff (and I've forgotten most of that!). Motivation: In this question , a sequence $a_i$ is given by the recurrence relation $a_i = a_{i - 1}a_{i + 1}$, or equivalently, $a_{i + 1} = \frac{a_i}{a_{i - 1}}$. It is shown in several answers that if $a_1 = x$ and $a_2 = y$, the terms of the sequence are $$\underbrace{x,\, y,\, \frac{y}{x},\, \frac{1}{x},\, \frac{1}{y},\, \frac{x}{y}}_{\text{period}},\, x,\, y,\, \ldots$$ and so is periodic with period of $6$. This reminded me of Fomin and Reading's notes Root Systems and Generalized Associahedra . The first topic there is a sequence defined recursively by
\begin{align}
f_1 &= x,\\
f_2 &= y, \\
f_{i+1} &= \frac{f_i + 1}{f_{i - 1}}, 
\end{align} 
whose terms are $$\underbrace{x,\, y,\, \frac{y+1}{x},\, \frac{x+y+1}{xy},\, \frac{x+1}{y}}_{\text{period}},\, x,\, y,\, \ldots$$ that turns out to have period $5$.","['recurrence-relations', 'periodic-functions', 'sequences-and-series', 'dynamical-systems']"
2063154,Help on proving $I=\int_{-\infty}^{\infty}xe^{-\pi{x^2}\left(a+x\over b+x\right)^2}dx=b-a$,$0<b<a$ $$I=\int_{-\infty}^{\infty}xe^{-\pi{x^2}\left(a+x\over b+x\right)^2}dx=b-a.$$ Applying integration by parts here is doesn't work. $u=x$ then $du=dx$ $dv=e^{-\pi{x^2}\left(a+x\over b+x\right)}dx$ Then $v=\int_{-\infty}^{-\infty}e^{-\pi{x^2}\left(a+x\over b+x\right)}dx=1$ See the solution of @Olivier $$I=x-\int_{-\infty}^{-\infty}dx$$ It doesn't make any sense here. Can anyone provide a prove of this integral?,"['integration', 'definite-integrals']"
2063201,Closure of an open set in the Zariski topology,"For a commutative ring $R$  with 1, if $\mathrm{Spec} (R)$ is the set of all prime ideals of $R$, we can define the Zariski Topology on $\mathrm{Spec} (R)$ as follows: 1) The sets of the form $$V(E)=\{P \in \mathrm{Spec}(R)|E \subseteq P\}$$ are closed subsets. 2)  The sets of the form $$D(E)=\{P \in \mathrm{Spec}(R) | E \not\subseteq P \},$$ are open subsets. Is there any description for the closure of an open set $D(E)$ in the Zariski topology?","['zariski-topology', 'general-topology', 'algebraic-geometry']"
2063215,(first) cohomology $H^1$ of sheaves on curves,"Say we have a reduced, irreducible, complete curve $X$ over a field $k$ and a sheaf $\mathcal F$ on $X$. I am interested in understanding the cohomology groups of $\mathcal F$. By flat base change, we can assume $k$ is algebraically closed and by Grothendieck's vanishing theorem, $H^i(X,\mathcal F)$ is zero for $i\ge 2$. So the interesting information (if any) is reflected in $H^0$ and $H^1$, in particular $\chi(\mathcal F)=h^0-h^1$. $H^0$ is just the global sections. If anything up to here is incorrect please correct me. I am not fully comfortable with the topic. This leaves $H^1$. How should I think of $H^1$ (or $h^1$)? I know it is the ''obstruction'' to exactness of $\Gamma(X,\cdot)$, but  that doesn't quite help me visualize it. In the particular instance of what I am reading, $\mathcal F$ is a torsion-free coherent $\mathcal O_X$-Module and it is assumed that $h^0=h^1=0$. If the above is correct, all cohomology groups thus vanish (since we are on a curve). Does this ''mean'' anything? (or should I just take it as a given and continue reading until hopefully it becomes clear) Thank you.","['sheaf-theory', 'algebraic-geometry', 'sheaf-cohomology', 'curves', 'algebraic-curves']"
2063230,Reference for Hyperbolic Geometry related with Complex Analysis?,"I'm a first year Graduate student.In my first semester complex analysis course there was a topic hyperbolic geometry but due to time limit unfortunately this topic was not touched during the course.Now i am trying to read this topic on my own from the point of view of complex analysis.I tried to find out some books but could not find much,the only book which i found was Gamelin's complex analysis.This book also does not contain,it discuss some hyperbolic geometry on disc only. What are the interesting result in complex analysis related with hyperbolic geometry? Are there any good notes/book which contains the same material? Thank you","['mobius-transformation', 'reference-request', 'complex-analysis', 'book-recommendation', 'hyperbolic-geometry']"
2063241,Matrix multiplication notation,"This is from my textbook: If $A=(a_{ij})\in M_{mn}(\Bbb F), B=(b_{ij})\in M_{np}(\Bbb F)$ then $C=A\times B=(c_{ij})\in M_{mp}(\Bbb F)$.
  $c_{ij}=\sum_{k=1}^{n} a_{ik}b_{kj}$ where $i=1,...m, j=1,...p$ I know how to multiply matrices but I don't understand this notation : $c_{ij}=\sum_{k=1}^{n} a_{ik}b_{kj}$ Can someone explain what that represents by giving me an example? And how did we get that formula?","['matrices', 'notation', 'linear-algebra']"
2063255,"An unclear sentence in the book ""Griffiths, Harris-Principles of algebraic geometry""","Let $X$ be a complex manifold and consider a holomorphic vector bundle $\pi:E\to X$ of rank $r$. By the usual correspondence between vector bundles and locally free sheaves, we consider $E$ as a sheaf by abuse of notation. We denote with $\mathscr A_X^{p,q}$ the sheaf of $C^\infty$ $(p,q)$-differential forms on $X$ and we define:
$$A^{p,q}(E):=\Gamma(X,\mathscr A^{p,q}\otimes_{\mathscr O_X} E)$$
$$A^k(E):=\bigoplus_{p+q=k}A^{p,q}(E)$$ Now suppose that $\nabla:A^\bullet(E)\to A^\bullet(E)$ is a linear connection on $E$, then the curvature operator is defined as:
$$\nabla^2:A^0(E)\to A^2(E)$$
where $\nabla^2$ is the composition of the maps $\nabla: A^0(E)\to A^2(E)$   and $\nabla: A^1(E)\to A^2(E)$. One can show that $\nabla^2$ is $C^\infty(X)$-linear. I don't understand the following sentence from the Griffiths-Harris book at page 75 (I rephrase it by using my notation): Since $\nabla^2$ is $C^\infty(X)$-linear, then it is induced by a bundle map $E\to\bigwedge^2T^*X\otimes E$, or in other words, $\nabla^2$ corresponds to a global section $\Theta$ of the bundle $\bigwedge^2T^*X\otimes\operatorname{Hom}(E,E)$. I absolutely don't understand how I can see the operator $\nabla^2$ as the section $\Theta$.","['complex-manifolds', 'curvature', 'differential-geometry', 'vector-bundles', 'connections']"
2063264,Different notions of upper / lower indices,"In differential geometry and tensor analysis, lower and upper indices appear naturally through covariant and contravariant transformations. One uses the metric tensor and its inverse to lower and raise indices: $V_\mu=g_{\mu\nu}V^\nu$, and $R^{\mu\nu}=g^{\mu\lambda}R_\lambda^\nu$. In Anthony Zee's Group Theory in a Nutshell for Physicists on page 232, when talking about representations of $SU(N)$, Zee defines the lower index as simply a notation for the complex conjugate representation: $\psi_i={(\psi^i)}^*$ He calls these indices covariant and contravariant too, because if $\psi^i$ transforms like $\psi^i\mapsto {U^i}_j\psi^j$, then $\psi_i\mapsto{\psi_i}^{'} = \psi_j {(U^\dagger)^j}_i$. Then he says that these indices can be lowered or raised with the total antisymmetric symbol $\varepsilon^{ij\dots k}$ (the Levi-Civita symbol). For a tensor $\phi_k^{ij}$ in $SU(4)$ with two upper and two lower indices, the tensor $\phi_{kpq}:=\varepsilon_{ijpq}\phi^{ij}_k$ will have three lower indices (page 235). My question is: Applying the totally antisymmetric symbol $\varepsilon$ to a tensor representation looks like the Hodge star operator to me. Is it the same, or is there a difference? Zee does not write about the Hodge star operator, but it seems he avoids certain names to avoid confusion (which is the cause of much confusion for me - why not just say that it's known as the Hodge star?). Is there a connection between the index raising/lowering in differential geometry (using the metric) and the one of Zee (using $\varepsilon$)? The definition $\psi_i={(\psi^i)}^*$ is useful for complex representations, but for real (or pseudoreal) representations, it does not make much sense. However, the Hodge star operation is defined for all representations, complex and noncomplex. If Zee really talks about the Hodge star operation, why does he define it for complex reps only?","['representation-theory', 'differential-geometry', 'lie-groups']"
2063266,Every intermediate field of an infinite Galois extension is the union of finite extensions,"I was stumbling upon this statement in my study of infinite Galois extensions but it had no further explanation. It seems true to me but I don't know how to construct these finite extensions.
Thanks for the help in advance!","['abstract-algebra', 'galois-theory', 'extension-field']"
2063275,Is there an equation for the maximum of n random draws from a Gamma distribution,"Suppose a random variable $X$ follows a Gamma distribution with parameters $\alpha$ and $\beta$ with the probability density function for $x>0$ as $$f(x;\alpha,\beta)= \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} \exp(-\beta x)$$ where $\Gamma(\alpha)$ represents the Gamma function. Suppose we take n samples from this distribution and only record the maximum value. For a given n, is there a general way to describe the expectation of this maximum value that we record? Below is a plot of the expectation (circles) and also the standard deviation (lines) for 1000 trials for each n draws, which produces a log-like curve with $\alpha=0.02$ and $\beta=0.0025$.","['statistics', 'probability', 'stochastic-calculus', 'probability-distributions']"
2063302,Generating Coprime Integers,Is there a formula for generating a set of Coprime integers that every element of this set is coprime to the other elements in this set? I want to create a collection of this formulas!,"['number-theory', 'elementary-number-theory']"
2063303,Grandi's series with 3 numbers,"So it appears that given any number X, where S = X-X+X-X..., the sum (S) is always X/2. However, what about if we have a series like the following: 3-2-1 + 3-2-1 + 3-2-1 ... How would one go about calculating this?","['divergent-series', 'sequences-and-series']"
2063307,Why do we omit the negative sign when finding basic angle when solving trigonometric equations?,"Suppose I'm asked to solve for $\cos \theta = -0.5$, for $\theta$ between $0^\circ$ and $360^\circ$ inclusive. I am told that the first step would be to buy the basic angle, $\alpha$. The way I am told to do this is by omitting the negative sign from -0.5 and hence finding sine inverse of 0.5 to get $60^\circ$. I understand the next steps of identifying the quadrant $\theta$ lies in etc: what I don't understand is why I need to omit the negative sign when finding the basic angle. I know the basic angle itself is acute and positive but why must the trigonometric function of the angle be positive for me to find the basic angle too?",['trigonometry']
2063316,Shorter method to find the orthocentre of this triangle?,"The given vertices are (0,0) (5,-1) (-2,3). My approach:: I assumed the orthocentre of the triangle as (a,b).
Now,
I used the fact that the line through each vertex and orthocentre is perpendicular to the opposite side. So, m (AH).m (BC) = -1 m (BH).m (AC) = -1 From this, I got two equations and I solved them to get the orthocentre. However,
THIS METHOD IS VERY LENGTHY.
Can someone please suggests me easier or shorter method to find it? Thanks.","['coordinate-systems', 'linear-algebra', 'geometry']"
2063357,Find UMVU estimator for $\frac{\mu }{\sigma}$,"Let $X_{1},\cdots,X_{n}$ be random samples which has normal
  distribution $N(\mu,\sigma^{2})$. When $\mu$ and $\sigma^{2}$ are unknown, I want to find UMVU estimator
  for $\frac{\mu}{\sigma}$. I know that $(\sum_{i=1}^{n}X_{i},\sum_{i=1}^{n}X_{i}^{2})$
is complete sufficient statistic for $\left(\mu,\sigma^{2}\right)$. Let $\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$, $S^{2}=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}$.
Then $E(\bar{X})=\mu$ and $E(S^{2})=\sigma^{2}+\mu^{2}$. So for $\frac{\mu}{\sigma}$, I guess as a estimator
$$
Y^{2}=\frac{\bar{X}^{2}}{\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}-\bar{X}}.
$$
But how can I compute $E(Y^{2})?$","['parameter-estimation', 'statistics', 'statistical-inference', 'normal-distribution']"
2063390,Logarithm of Brownian Motion - local martingale but not martingale.,"I have just started studying stochastic analysis and I am stuck on trying to show that for $B$ a two-dimensional Brownian motion, $\ X_t=\log\left(\left|B_t\right|\right)_t$ is a local martingale but not a martingale. I saw people trying to tackle such questions using Ito integrals, but being one of the first things in my course, I imagine there is an elementary way to think about this, and I would be very curious about it? In particular, what sequence of stopping times should I use? 
Intuitively I imagine it has to do with the fact that the stopped process is uniformly integrable, so we can apply Doob's stopping theorem. I would be extremely grateful if someone could please explain these details to me? Thank you very much for your time and help!!","['stochastic-analysis', 'brownian-motion', 'probability', 'martingales']"
2063396,Cubic spline between circles,"I would like to define a spline between some circles as shown in the figure below: I want to write the spline mathematically, so I have four coordinates that I can define, but I can't manage to find a good approximation. Can anyone help me to find the coordinates for such a spline, by using the radius (R) and the angle ($\alpha$=60$^\circ$). If I use the point of intersection between the circles I get a weird curve (please see figure below). Can anyone please help me with this? Thank you! EDIT: The coordinates that I have now are: 1.(0,R)
2.(0,2*R-(-(2*R)*sin(60)+2*R)/2)
3.(R-cos(60)),2*R-(-(2*R)*sin(60)+2*R)/2)
4.(R,3*R-(-(2*R)*sin(60)+2*R)) They give a good approximation, but still not good enough!","['algebraic-geometry', 'geometry']"
2063425,"Is relation $\{(1,2),(2,3),(1,3),(3,1)\}$ symmetric and transitive?","$\{(1,2),(2,3),(1,3),(3,1)\}$ is our set. According to this set, I know that it isn't reflexive. Because; $\{(1,1),(2,2),(3,3),(4,4)\}$ are missing. However, I also think that it's symmetric and transitive. Transitive because; $\{(1,2),(2,3),(1,3)\}$ Symmetric because; $\{(1,3),(3,1)\}$ Is it correct or to be symmetric, should each one of the subsets be symmetric? Like; $\{(1,2),(2,1),(2,3),(3,2),(1,3),(3,1)\}$ Thanks!","['relations', 'elementary-set-theory']"
2063463,Solving a system of equations involving smooth functions,"This is a follow-up question of my previous question . Suppose $h_{i\overline{j}}$, where $1\leq i, j\leq n$, are functions defined on $\mathbb{C}^n$ such that $h_{i\overline{j}}$ are smooth when viewed as functions defined on $\mathbb{R}^{2n}$
and $H=(h_{i\overline{j}})$ is a Hermitian positive definite matrix. I wonder if it is always possible to find smooth functions $p_1,..., p_n$ defined on $\mathbb{R}^{2n}$ such that 
$$\frac{\partial p_i}{\partial z_j}+\overline{\frac{\partial p_j}{\partial z_i}}=h_{i\overline{j}}\mbox{ and }
\frac{\partial p_i}{\partial \overline{z}_j}
-\frac{\partial p_j}{\partial \overline{z}_i}=0.$$
In the previous question, I require $p_i$ to be holomorphic, which seems to be too strong.","['systems-of-equations', 'partial-differential-equations', 'partial-derivative', 'holomorphic-functions', 'ordinary-differential-equations']"
2063473,"Prove that if $f$ is differentiable on $[a,b]$ and $f'$ is monotonic on $[a,b]$ , $f'$ is continuous on $[a,b]$","Assume that $f:[a,b] \to \mathbb R$ is a function. Prove the following statement : If $f$ is differentiable on $[a,b]$ and $f'$ is monotonic on $[a,b]$,
  then $f'$ is continuous on $[a,b]$. Note 1 : We've learned a theorem in the class which says : If $I$ is an open interval and $f:I\to\mathbb R$ is monotonic, then
  $f$ is continuous on $I$. So, here i can say that $f'$ is continuous on $(a,b)$. But my problem is how to prove that $f'$ is also continuous at the end points $a$,$b$. Note 2 : There's a similar question here but please pay attention that my question is asking about when $f$ is defined on a closed interval.","['derivatives', 'continuity']"
2063496,Proof that a group is abelian if every square is the identity.,"I need to prove that for $(\mathbf G, \circ)$ a group, if for every $a\in\mathbf G$ $$a\circ a=e$$ where $e$ is identity element of that group, then the group is abelian group.$$\\$$My proof:
$$\text{We know that:}\\a\circ e=a=e\circ a\\b\circ e=b=e\circ b\\b\circ b=e=a\circ a\text{, so if}\\a\circ a=b\circ b\text{, then}\\a\circ (e\circ a)=(e\circ b)\circ b\\a\circ(b\circ b\circ a)=(a\circ a\circ b)\circ b\\(a\circ b)\circ (b\circ a)=(a\circ a)\circ(b\circ b)=e\circ e=e\\(a\circ b)\circ (b\circ a)=e\Rightarrow a\circ b=b\circ a$$
And I'm not really sure of the last step. Is this proof proper?","['abelian-groups', 'group-theory', 'proof-verification']"
2063527,Condition on two irrational numbers,"Consider two irrational numbers $a$ and $b$. Are there well known sufficent conditions on the relation between $a$ and $b$ that would allow me to conclude that there is $c \in \mathbb{R}$, $c \neq 0$, such that both $ca$ and $cb$ are rational?","['irrational-numbers', 'analysis']"
2063573,Math question - specifying the range of ln,"The original problem is this:
$$\lim_{x\to 0}\frac{1}{2x}\ln \frac{1}{n}\sum_1^n {e^{kx}} = 20$$ Find out the value of $n$, which is a natural number. But I'm having a bit of trouble solving this problem. My problem is that I think that this question can be interpreted in two ways.
Since there is no brackets limiting the range of the $\ln$, I believe it can be interpreted as both : 1)
$$
\lim_{x\to 0}\frac{1}{2x}\ln \left(\frac{1}{n}\right)\sum_1^n {e^{kx}} = 20
$$ 2)
$$
\lim_{x\to 0}\frac{1}{2x}\ln \left(\frac{1}{n}\sum_1^n {e^{kx}}\right) = 20
$$ If I interpret the problem as 2), the value of $n$ becomes $79$.
If I interpret the problem as 1), I can't get the value of $n$. Am I right in assuming that all two of my interpretations are correct? What I mean is, just like $\cos x \cos x$ is different from $\cos(x \cos x)$, shouldn't the range of the ln be specified using brackets?
Without these brackets, can this equation be interpreted in two ways, just like I did? And if my first interpretation is correct, could anyone please explain in detail why ln and sigma can be diverged?
I certainly learned it at some point at school, but I don't exactly remember the specific details.","['exponential-function', 'ordinary-differential-equations']"
2063576,Is $\ln(\ln(n))$ irrational for any integer $n>1$?,"Is there $n\in \mathbb{N}$ such that $\ln(\ln(n)) \in \mathbb{Q}$?
If such $n$ exists, we will get $$\ln(\ln(n))  = \frac{p}{q}, \quad p, q \in \mathbb{Z}.$$ 
Hence we will get $n = e^{e^{p/q}},$ where the question about the nature of  $e^{e^{p/q}}$ haven't been answered yet. Is there any other direction ? 
Thank you in advance.","['real-analysis', 'algebraic-number-theory', 'irrational-numbers', 'rationality-testing', 'elementary-number-theory']"
2063642,Partition of Unity for a commutative ring,The Partition of Unity is an important theorem in geometry. Has this theorem any interpretation for a commutative ring with respect to the Zariski topology?,"['zariski-topology', 'algebraic-geometry']"
2063656,"If $\alpha\in (0,1]$ and $x_n=\alpha x_{n-1}+(1-\alpha)x_{n-2}$, show that the sequence $\{x_n\}$ is convergent.","If $x_1$, $x_2$ are arbitary real numbers, $\alpha\in (0,1]$ and  $x_n=\alpha x_{n-1}+(1-\alpha)x_{n-2}$ for every positive integer $n$ (>2), show that the sequence $\{x_n\}$ is convergent. (Given $x_1<x_2$) I cannot rearrange to test convergency. Please help me by solving the problem. Edit I want to prove by using the property below: If $\{x_{2n}\}$ and $\{x_{2n-1}\}$ converges to same limit $l$ then $\{x_{n}\}$ converges to $l$.","['real-analysis', 'sequences-and-series']"
2063704,Almost surely convergence for a martingale,"Let $X_1, \dots$ be a sequence of independent random variables with $P(X_i = \frac{1}{2})=\frac{1}{2}$ and $P(X_i = \frac{3}{2})=\frac{1}{2}$. Let $S_n := \prod_{i=1}^n X_i$. I've proven that $S_n$ is a martingale and using the convergence theorem for martingales there exists an $S_\infty$ such that $S_n \to S_\infty$ a.s. Now I'd like to compute $S_\infty$ and this is my attempt so far: Using the strong law of large numbers it is clear that: $\frac{1}{n}\log(S_n) = \frac{1}{n}\sum_{i=1}^n \log(X_i) \to E(\log(X_1)) = \frac{1}{2}\log(\frac{3}{2})-\frac{\log(2)}{2} < 0 $ a.s. Therefore $\log(S_n) \to -\infty$ a.s. and so $S_n \to 0$ a.s which means $S_\infty = 0$. Is the proof correct or is there something lacking?","['probability-theory', 'probability', 'martingales', 'proof-verification']"
2063711,interpreting eigenvectors/values of linear systems,"I have two related questions: If I have a system of linear equations, written in matrix form: $Ax = b$ then this system has a non-trivial solution only if $det(A) \neq 0$. but what is the significance of the eigenvalues/eigenvectors of A for finding the solutions? Related, if I have a system of homogeneous ordinary differential equations: $x' = Ax$ then what is the interpretation of eigenvalues/eigenvectors of A in finding the solutions of this system of equations? pointers to explanations or concise explanations to this would help.","['eigenvalues-eigenvectors', 'intuition', 'ordinary-differential-equations', 'linear-algebra']"
2063733,Learning roadmap for Knot theory,"I want to study Knot theory in the summer break. What are some good resources on this topic? My background is a a first course in Analysis and Linear Algebra, and Hatcher's notes on point-set topology. Also, what should I study next, and from where, to be sufficiently prepared for learning Knot theory? I am interested in learning some Algebraic Topology as well.","['reference-request', 'knot-theory', 'book-recommendation', 'algebraic-topology', 'general-topology']"
2063781,Laplace transform of an integral?,"I have the following integral: $$ I = \int_{0}^{t} e^{-\tau}\theta(t-\tau )d\tau $$ where $\theta(t) \left\{\begin{matrix}
 0&  0 \leq t < 1\\ 
 5 & t\geq 1
\end{matrix}\right.$ is the Heaviside step function. $$$$
I need to get the Laplace transform of it. I know there is a rule for it: $ \mathcal{L} \left \{ I \right \} = F(s)G(s), $ but I don't know if its correct the do the transformation as follows: $$ \mathcal{L} \left \{  e^{-\tau} \right \}= e^{-\tau}\mathcal{L}\left \{  1\right \}$$ Because the transformation should be in respect of $ t $ Thanks in advance","['ordinary-differential-equations', 'laplace-transform']"
2063785,Necessary conditions for a measure space to support an i.i.d. sequence of discrete random variables,"Assume $(\Omega,\mathcal{A},\mu)$ is given. We are interested in the space, $\mathcal{M}$ of measurable functions from $\Omega$ to a set $S=\{1,2,\ldots,n\}$ with the standard discrete topology. Also let $(p_1,p_2,\ldots,p_n)$ be given, where $\sum_{j=1}^n p_j=1$ and $0<p_j<1$. What are the necessary conditions on $(\Omega,\mathcal{A},\mu)$ to conclude that there exists a sequence, $X_1, X_2, X_3, \ldots$, of $\mu$-independent (def. below) random variables in $\mathcal{M}$, with identical distributions $\mu(X_i^{-1}(\{j\}))=p_j$? $X$ and $Y$ are $\mu$-independent if for all $A\in\sigma(X)$ and $B\in\sigma(Y)$, $\mu(A\cap B)=\mu(A)\mu(B)$, where $\sigma(X)$ and $\sigma(Y)$ are the sub-sigma algebras of $\mathcal{A}$ generated by the preimages of measurable sets in $S$ (which means preimages of all subsets of $S$ since $S$ is discrete) Examples: Any discrete $\Omega$ does not allow for an i.i.d sequence as described above. Proof: The set $\{\sigma(X_i), i=1,\ldots,\infty\}$ is finite because $\mathcal{A}$ is finite. Thus, for some $i_1\ne i_2$, $\sigma(X_{i_1})=\sigma(X_{i_2})$. By independence, if $A=X_{i_1}^{-1}(\{j\})=X_{i_2}^{-1}(\{j\})$, then $\mu(A)=\mu(A\cap A)=\mu(A)\mu(A)$. This implies $\mu(A)\in\{0,1\}$, violating the assumption that $0<p_j<1$. If $n=2$, $p_1=2/3, p_2=1/3$, and $\Omega=\mathbb{R}$ with Lebesgue measure then there does exist an i.i.d. sequence with the given law. Construction  See image below. Basically, construct $X_1$ to have $X_1([0, 2/3))=1$ and $X_1([2/3, 1])=2$. Then for subsequent $X_j$ divide each of the intervals on the previous step in a self-similar fashion. There needs to be some rule for assigning endpoints like all intervals are of the form $[a,b)$ unless $b=1$.","['probability-theory', 'measure-theory']"
2063798,Evaluate $P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx $ where $0 < \alpha <1$ [duplicate],"This question already has answers here : Closed form for $ \int_0^\infty {\frac{{{x^n}}}{{1 + {x^m}}}dx }$ (11 answers) Closed 7 years ago . Evaluate $$P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx   $$
where $0 < \alpha <1$ Thm Let $P$ and $Q$ be polynomials of degree $m$ and $n$,respectively, where $n \geq m+2$. If $Q(x)\neq 0$. for $Q$ has a zero of order at most 1 at the origin and $f(z)= \frac{z^\alpha P(z)}{Q(z)}$, where $0 < \alpha <1$ then 
$$P.V, \int^{\infty}_0 \frac{x^ \alpha  P(x)}{Q(x)} dx= \frac{2 \pi i}{1- e^{i \alpha 2 \pi }}  \sum^{k}_{j=1} Res [f,z_j] $$
where $z_1,z_2 ,\dots , z_k$ are the nonzero poles of $\frac{P}{Q}$ Attempt Got that $P(x)=1$ where its degree $m=1$ and $q(x)=x(x+1)$ its degree is $n=1$ so it is not the case that $n \geq  m+2$ because $2 \geq 1+2$",['complex-analysis']
2063800,"The number of families of subsets of $\{1,2,...,n\}$ whose union is not the whole set.","I wrote a code in Mathematica that returns the number of families (collections) of subsets of $\{1,2,...,n\}$ whose union is not the whole set.  The code can only return values for $n = 1,2,3,4$.  The respective values are $2,6,40, 1376$.  These are the first four terms of Sloane's A051185 which counts the number of intersecting families.  Is this a coincidence or is there some reason why these two counts are equal?","['combinatorics', 'general-topology', 'elementary-set-theory']"
2063805,Calculus (solve for $d_1$) [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I am learning Calculus on my own and came through this example and I solved the first two. However I couldn't find a solution for the last one.
Can you help ?
My solution is The first x =1 The second x=2 & y=1",['algebra-precalculus']
2063815,$W_n = \frac{1}{n}\sum\log(X_i) - \log(X_{(1)})$ with Delta method,"Note: $\log = \ln$. Suppose $X_1, \dots, X_n \sim \text{Pareto}(\alpha, \beta)$ with $n > \dfrac{2}{\beta}$ are independent. The Pareto$(\alpha, \beta)$ pdf is $$f(x) = \beta\alpha^{\beta}x^{-(\beta +1)}I(x > \alpha)\text{, } \alpha, \beta > 0\text{.}$$
Define $W_n = \dfrac{1}{n}\sum\log(X_i) - \log(X_{(1)})$, with $X_{(1)}$ being the first order statistic. I wish to show
  $$\sqrt{n}(W_{n}^{-1}-\beta)\overset{d}{\to}\mathcal{N}(0, v^2)$$ as
  $n \to \infty$ (convergence in distribution) for some $v^2$. Here's what I've already shown: $W_n \overset{p}{\to}\beta^{-1}$. $X_{(1)} \overset{p}{\to} \alpha$. The expected values and variances of $\log(X_i)$ for each $i$ and the same for $X_{(1)}$. It is very obvious that I need to use the Delta method here, but this would require showing that 
$$\sqrt{n}(W_n - \beta) \overset{d}{\to}\mathcal{N}(0, \text{something})\text{.}$$
I suppose I could approach using the Central Limit Theorem, but it isn't clear to me how this could be done. I can see that by the CLT, we have
$$\sqrt{n}\left[\dfrac{1}{n}\sum\log(X_i) - \underbrace{\left(\beta^{-1}+\log(\alpha) \right)}_{\mathbb{E}[\log(X_i)]} \right]\overset{d}{\to}\mathcal{N}\left(0, \underbrace{\beta^{-2}}_{\text{Var}(\log(X_i))}\right)$$
but I'm stuck as to how to proceed from here. By the continuous mapping theorem, I know that 
$$\log(X_{(1)}) \overset{p}{\to} \log(\alpha)$$
but I'm stuck from here.","['probability-theory', 'probability', 'central-limit-theorem']"
2063848,Kolmogorov–Smirnov test,"We measured time of reaction of 8 drivers right before and 15 minutes after drinking certain amount of alcohol. Times of reaction before were: 0.22, 0.18, 0.16, 0.19, 0.20, 0.23, 0.17, 0.25 and after: 0.28, 0.25, 0.20, 0.30, 0.19, 0.26, 0.28, 0.24. The problem is to test the hypothesis whether drinking alcohol prolongs time of reaction (with a significance level $\alpha=0.05$). My attempt to the problem: The classical approach to the problem like that would be to use Kolmogorov–Smirnov test to verify if the distribution of the random variable ""times before"" (X) is equal to distribution of the random variable ""times after"" (Y). The value of D=0.625 and p-value=0.08787. It would mean that with significance level $\alpha=0.05$ we operate only on one distribution. However the alternative hypothesis in such case would be in a from $F \neq G$ and it does denote hypothesis ""drinking alcohol prolongs time of reaction"". So my second step was to define alternative hypothesis as ""CDF of Y lies below CDF of X"". I found somewhere that in such situation I should focus only on $D^{-}$. Therefore $D^{-}=0$ and $p=1$. Is that a right solution?",['statistics']
2063855,Invariant forms on a Lie group - are these equal?,"Motivation: This is a follow-up question to this question that I asked a few minutes ago. (my question there actually doesn't even make sense (apparently I did not pay close enough attention) - see levap's answer. I've tried to modify that question so that it actually does make sense and here is what I've come up with: Background: Let $L$ be a Lie group, and $g$ a left-invariant riemannian metric on $L$. With respect to $g$, choose an orthonormal basis $v_e = v_e^1, \cdots v_e^n$ for the tangent space at the identity $T_e L$, and let $w_e = w_e^1, \cdots, w_e^n$ denote the dual basis to $v_e$ in $T^*_eL$. As $g$ is left-invariant this orthonormal basis at the identity induces a global an orthonormal frame field $v$ on all of $L$ by using Lie group structure. See here for details. Now, we can construct global 1- forms from this basis in two obvious ways, and I'm wondering if the result is the same. Take $w_e$, the dual basis to $v_e$, and using the Lie group structure define a global basis of invariant 1-forms. Again, see here for details. Call this $\phi =\phi^1, \cdots, \phi^n$. Take the global frame field $v$ and at each point $p \in L$ take the dual coframe to produce a global coframe field. Call this $w= w^1, \cdots, w^n$. Question: Does $$\phi = w?$$  i.e  does $\phi^1 = w^1, \cdots, \phi^n = w^n$? Attempt: I think I may have figured this out. We have by construction that at any point $g\in L$  $$w_g^i (v_g^j) = \delta_{ij}.$$ So for equality of $\phi$ and $w$ we would need
$$
\phi_g^i (v_g^j) = \delta_{ij}.
$$
However, 
$$ \phi_g^i (v_g^j)= (w_e^i \circ dg^{-1}) \circ (dg \circ v_e^j) = w_e^i(v_e^j) = \delta_{ij}.   $$
So by uniqueness of the dual basis $\phi$ and $w$ are equal.","['differential-geometry', 'linear-algebra', 'lie-groups']"
2063862,Inverse Laplace transform involving an Laplace transform and an absolute sine function,"I want to compute this inverse Laplace transform that involve in itself a Laplace transform, is there a general approach for this? And how can I find what the inverse looks like? $$\mathcal{L}_\text{s}^{-1}\left[\frac{1}{1+\text{L}\cdot\text{C}_2\cdot\text{s}^2}\cdot\mathcal{L}_t\left[\left|\sin\left(\omega t+\theta\right)\right|\right]_{\left(\text{s}\right)}\right]_{\left(t\right)}=$$
$$\mathcal{L}_\text{s}^{-1}\left[\frac{1}{1+\text{L}\cdot\text{C}_2\cdot\text{s}^2}\cdot\left\{\int_0^\infty e^{-\text{s}t}\cdot\left|\sin\left(\omega t+\theta\right)\right|\space\text{d}t\right\}\right]_{\left(t\right)}=$$
$$\mathcal{L}_\text{s}^{-1}\left[\frac{1}{1+\text{L}\cdot\text{C}_2\cdot\text{s}^2}\cdot\left\{\int_0^\infty e^{-\text{s}t}\cdot\left(\frac{2}{\pi}-\frac{4}{\pi}\sum_{\text{n}\ge1}\frac{\cos\left(2\text{n}\left(\omega t+\theta\right)\right)}{4\text{n}^2-1}\right)\space\text{d}t\right\}\right]_{\left(t\right)}$$ Thanks in advance","['laplace-transform', 'trigonometry', 'integration', 'absolute-value', 'sequences-and-series']"
2063901,Is something wrong with this precalculus question?,"If $x^{2}-4x+6=0$, then what can be the value of $1-\frac{4}{3x}+\frac{2}{x^{2}}$? My answer is $1-\frac{4}{3x}+\frac{2}{x^{2}}=\frac{3x^{2}-4x+6}{3x^{2}}=\frac{3x^{2}-x^{2}}{3x^{2}}=\frac{2}{3}$ for $x\neq 0$. But according to the book answer is 2. What is the point i miss?",['algebra-precalculus']
2063904,Proving $\sin(x)\cos(2kx) = [\sin((2k+1)x)-\sin((2k-1)x)]/2$?,"I am trying to calculate the following integral related to fourier series
$$4/\pi\int_0^{\pi/2} \sin(x)\cos(2kx) \, dx .$$ I plugged it into an online integral calculator and wanted to see the step by step solution. The first step was using the equation
$$\sin(x)\cos(2kx) = \frac{\sin((2k+1)x)-\sin((2k-1)x)}2.$$
Why does it hold?","['fourier-series', 'trigonometry', 'calculus']"
2063914,Proving inequality using Lagrange multipliers.,"I started learing about Lagrange Multipliers and I got the following question: Prove that $\frac{a}{b+c}+\frac{b}{c+a}+\frac{c}{a+b}≥\frac{3}{2}$, for each $a,b,c>0$. I'm not sure how to use Lagrange multipliers for it... any ideas?","['inequality', 'calculus', 'multivariable-calculus', 'fractions', 'lagrange-multiplier']"
2063934,"GRE algebra question, evaluate the expression","Given x,y<0, What is the value of $$\frac{\sqrt{x^2}}{x} - \sqrt{\frac{-y}{\left\lvert y \right\rvert}}$$ Since $x$ and $y$ are negative that means the first term should reduce to $$\frac{\left\lvert x \right\rvert}{x}$$ and the second term reduces to $$\sqrt{\frac{\left\lvert y \right\rvert}{\left\lvert y \right\rvert}}$$ So the answer is $-1-1=-2$ ..... or so I thought. The answer key says the answer is $y-1$ which I don't follow at all.  The site has goofed some answers already so is the goof on their part or mine?",['algebra-precalculus']
2063945,Need help finding the kernel of a linear transformation $P^2 \to \mathbb{R}$,The question asks to find the kernel of $S: P^2 \to \mathbb{R}$ defined by $S(a+bx+cx^2) = a+b+c$. I know how to find the kernel of a matrix transformation (it's just the null space of the matrix) but I can't conceptualize a transformation from two different types of vector spaces. How would I go about finding a basis ker(S)?,"['linear-algebra', 'linear-transformations']"
2063959,Construct a set with different upper and lower Lebesgue density at zero.,"For $\delta >0,$let $I(\delta)$ be the segment $(- \delta, \delta) \subset \mathbb{R}.$ Given $\alpha,\beta,$ and $0 \leq \alpha < \beta \leq 1,$ construct a measurable set $E \subset \mathbb{R}$ so that the upper and lower limits of 
$$m(E \cap I(\delta))/2 \delta$$ are $\beta$ and $\alpha$ repsectively as $\delta \rightarrow 0.$ This is a question from Rudin's book on Real and Complex Analysis and it has been taken up before here: Lebesgue measurable subset of $\mathbb{R}$ with given metric density at zero . 
Yuval Filmus has posted an answer which I'm trying to verify, but I can't make it to work. In his answer, he sets $E$ to be the duplication around zero of
$$\bigcup_{n \geq 1} \left[\frac{1}{(2n)!}-\alpha\left(\frac{1}{(2n)!} - \frac{1}{(2n+1)!}\right),\frac{1}{(2n)!}\right] \cup \left[\frac{1}{(2n+1)!}-\beta\left(\frac{1}{(2n+1)!} - \frac{1}{(2n+2)!}\right),\frac{1}{(2n+1)!}\right].$$ I have no problem with showing that $\beta$ and $\alpha$ can occur as limits, but I can't show that any limit must lie between $\beta$ and $\alpha.$ My questions are thus: 1. Is the construction of Yuval correct? Does this work? 2. If not, what is an example that does work? My attempt with Yuval's example Let us try to show that any limit must lie between $\alpha$ and $\beta.$ Say that $0< r <1$ and that $ \dfrac{1}{(2n+1)!} < r \leq \dfrac{1}{(2n)!}.$ Then we have that $$m(E \cap I(1/(2n+1)!)) \leq m(E \cap I(r) ) \leq m(E \cap I(1/(2n)!)).$$
We have that $$m(E \cap I(1/(2n+1)!)) = 2\sum_{k=n+1}^\infty  \beta \frac{2k}{(2k+1)!} + 2 \sum_{k=n+2}^\infty \alpha \frac{2k}{(2k+1)!}$$ while
$$m(E \cap I(1/(2n)!)) = 2\sum_{k=n}^\infty  \alpha \frac{2k}{(2k+1)!} + 2 \sum_{k=n+1}^\infty \beta \frac{2k}{(2k+1)!}.$$ We have  $$m(E \cap I(1/(2n+1)!))/(2r) \leq m(E \cap I(r) )/(2r) \leq m(E \cap I(1/(2n)!))/(2r).$$
We now want an upper and a lower bound on $m(E \cap I(r))/(2r).$For the upper bound, the obvious thing would be, since $(2n)!/2 \leq 1/(2r) < (2n+1)!/2$ would be to calculate  $$(2n+1)!/2m(E \cap I(1/(2n)!)).$$ This is $$(2n+1)!\sum_{k=n}^\infty  \alpha \frac{2k}{(2k+1)!} + (2n+1)! \sum_{k=n+1}^\infty \beta \frac{2k}{(2k+1)!}.$$ But this upper bound is much too crude to give us anything valuable. I also tried by taking the midpoint of the interval $[1/(2n+1)!,1/(2n)!]$ but that similarily seemed to give me nothing.",['real-analysis']
2063979,Classifying homeomorphisms of the torus,"I'm reading Automorphisms of Surfaces after Nielsen and Thurston by Casson and Bleiler, and I'm confused by something in the introductory section where the authors classify the homeomorphisms of a torus. They say that, ""The homeomorphisms of $T^2$ correspond to the elements of the general linear group $GL_2(\mathbb{Z})$ as any element $\alpha$ in $GL_2(\mathbb{Z})$ maps $\mathbb{Z}^2$ to itself and so induces a continuous map $h_\alpha:T^2\to T^2$."" I understand why the map $h_\alpha$ is induced by $\alpha$, but it's not clear to me why every homeomorphism of the torus is induced by some element of $GL_2(\mathbb{Z})$. Any homeomorphism $f:T^2\to T^2$ certainly lifts to an invertible map $\tilde f:\mathbb{R}^2\to\mathbb{R}^2$, but why is $\tilde f$ linear?","['algebraic-topology', 'general-topology']"
2064009,Why is $f|X_f$ a unit in $\mathcal O_X(X_f)$?,"I am on the last part of this problem in Hartshorne.  I think what I am stuck on comes down to showing that $f|X_f$ is a unit in $\mathcal O_X(X_f)$: I don't see why this is.  In general, if $Y$ is a scheme, and $s \in \mathcal O_Y(Y)$ has the property that for each $y \in Y$, the stalk $s_y$ does not lie in the maximal ideal $\mathfrak m_y$, I don't think that $y$ needs to be a unit.",['algebraic-geometry']
2064025,"Prove that $\int_0^{\infty} \frac{\sin x}{x^p}\, dx$ converges for $0<p<2$","I would really appreciate feedback/guidance. This is from a past year exam and my professor didn't cover much on improper integrals. I'm trying to prove that $\int_0^{\infty} \frac{\sin x}{x^p}\, dx$ converges for $0<p<2$ using the comparison test for improper integrals. I know that from the test, if $|f(x)| \leq g(x) \forall x\geq a$ then $\int_a^{\infty} g(x)\, dx$ converges. EDIT: Here's my second attempt at the proof after much discussion in the comments below. We know that $\frac{\sin x}{x^p}$ will be continuous on 1 because $\lim_{x\rightarrow 1} \frac{\sin x}{x^p} = lim_{x\rightarrow 1} x^{-p} \sin(x) = 1^{-p}\sin(1) = \sin(1)$. However, for 0 we have that: $\lim_{x \rightarrow 0} \frac{\sin x}{x^p} = \frac{\sin 0} {0^{p}} = \frac{0}{0^{-p}} = \frac{1}{0^{p-1}}$. Since we can't have 0 in the denominator, we only have continuity on 0 if p-1 < 1, which implies p<2. And so, by a theorem, we know that $\frac{\sin(x)}{x^p}$ is Riemann integrable on [0,1] for p<2. Furthermore, by the improper limit comparison test, if we prove that $\int_1^{\infty} f(x)\, dx$, then we can show that $\int_0^{\infty} f(x)\, dx$ converges. Hence we have that $\lim_{b \rightarrow \infty} \int_1^{b} \frac{\sin(x)}{x^p}\,dx = \lim_{b \rightarrow \infty} \int_1^{b} \frac{\sin(x)}{x^p}\,dx =\lim_{b\rightarrow \infty} -\frac{cos x}{{p}} |_p^{b} - \int_1^{b} \frac{\cos x}{(p-1)x^{p+1}}\,dx$ And so I know that since $\int \frac{cos x}{x^{p+1}} < \int \frac{1}{x^{p+1}}$, and since the RHS will converge if and only if p+1 > 1, we have that p>0. And so, we conclude that the integral converges for $0<p<2$.","['improper-integrals', 'convergence-divergence', 'proof-verification', 'limits']"
2064035,Understanding the P-value,"I'm having difficulty understanding the p-value.
It is said to reject the null hypothesis when the p-value is small. Smaller than the significance level. So does that mean in a hypothesis test, the p-value represents the area of the null hypothesis? Therefore because the p-value is small, it would imply the probability of the null hypothesis being unlikely?","['statistics', 'hypothesis-testing']"
2064050,"Cardinality of a $\mathbb Q$ basis for $\mathbb C$, assuming the continuum hypothesis","Prove that $\operatorname{tr.deg}(\mathbb{C/Q})=\mathfrak{c}$ (where $\mathfrak{c}$ is the cardinality of $\mathbb{R}$ ) using the continuum hypothesis. $Proposition$ If $E/F$ is an algebraic extension then $|E|=\aleph_0 |F|$ Proof: Let $S$ be a trancendental basis of the extension $\mathbb{C/Q}$ .Then $|S| \leqslant \mathfrak{c}$ .Suppose that $|S|< \mathfrak{c}$ . Then, by the continuum hypothesis, $S$ is finite or countable. Let $S=\{s_1,s_2, \ldots \}$ a countably infinite set. Then let $A_n=\mathbb{Q}(s_1,,,s_n)$ $(\dagger)$ We have that every $A_n$ is a countable set and $\bigcup_{n=1}^{\infty}A_n=\mathbb{Q}(S)$ which is countable as a countable union of countable sets. Also by definition of the trancendental basis we have that $\mathbb{C}/\mathbb{Q}(S)$ is an algebraic extension thus by the above proposition $|\mathbb{C}|=\aleph_0 |\mathbb{Q}(S)|=\aleph_0 \aleph_0=\aleph_0$ - deriving a contradiction. Is this proof correct? I'm not sure about if the equation of the sets in $(\dagger)$ is correct.","['abstract-algebra', 'field-theory', 'elementary-set-theory', 'proof-verification']"
2064057,Find the smallest positive integer $m$ and $n$ for which $13<2^\frac{m}{n}<14$,Q: Find the smallest positive integers $m$ and $n$ for which $13<2^\frac{m}{n}<14$ No idea where to start Question from year 11 Cambridge book,['algebra-precalculus']
2064093,How to build a square with a star,"I have a problem that I can't solve. It says: ""If you rotate a square 45º you get a 8-pointed star. Prove that you can divide that star in 8 parts with which you can build a new square"" I have calculated that if the original side of the square was 1, the new side is $\sqrt{4-2\sqrt2}$, and I don't know how I can do a division to obtain this side.
Any suggestion? 
Thanks! Thanks you very much. 
I haven't solved the problem yet, but I have done more steps:
In Moti's picture, the segment IJ has lenght $\sqrt{4-2\sqrt{2}}$ as we want. This triangle is rectangle in F so the angles FIJ, IJF are supplementary. With 4 triangles like that we can build a square with side IJ, but in the middle we obtain a new empty square with side $\sqrt 2 /2 $ (and diagonal 1). But I don't know how to do the partition. Thanks!",['geometry']
2064101,Height of all skyscraper,"There is a bunch of skyscapers, each have a height, which is a positive integer. You are given at the start the total sum of their height. Now everyday you can make one measurement, which will tell you how many skyscapers there are which have height at least $k$, for some $k$ of your choice. You are allowed to choose that $k$ whatever knowledge you have obtained so far, such that measurement results from previous days. You can stop once you know with perfect certainty the height of each skyscrapers. (also, you are not given the number of skyscrapers at the start, but asymptotically, that does not matter since you can always pick $k=1$ on the first day) So my question is, what is the algorithm for choosing the measurement each day such that the number of days in take in worst case is asymptotically optimal, and what is that number of days asymptotically. Example: Let's say that the final result would be $3,1$ (there are $2$ skyscrapers, and the height of the skyscapers are $3$ and $1$). First you know the total height is $4$. You pick $k=1$ on the first day, you now know there is $2$ skyscrapers of height at least $1$ (which means there are $2$ skyscapers). The next day you pick $k=2$, and you learn there is only $1$ skyscapers of height at least $2$. So exactly one of them have height $1$, and the other one must have the remaining height, which is $3$. Hence you are done after $2$ days. EDIT: I made some edits to the question to clarify certain points.","['information-theory', 'combinatorics', 'algorithms']"
2064163,"Does $\int_0^\infty \sin^2 (x^2)\, dx$ converge or diverge?","I'm trying to show determine if $\int_0^\infty \sin^2(x^2)\,dx$ converges. By continuity, we have that $\sin^2(x^2)$ is continuous on $[0,1]$, and therefore (by a theorem) it is Riemann integrable on $[0,1]$. And so, we will have that if $\int_1^\infty \sin^2(x^2) \,dx$ converges then so will $\int_0^\infty \sin^2(x^2) \, dx$. And so I'm left with $\int_0^\infty \sin^2(x^2) \,dx$ and I have no idea how to integrate this. Hints or help would be very much welcomed!","['real-analysis', 'improper-integrals']"
2064164,Prove that $\sum_{k=0}^n (-1)^k\frac{{ {n}\choose{k}}{ {x}\choose{k}}}{{ {y}\choose{k}}} = \frac{{ {y-x}\choose{n}}}{{ {y}\choose{n}}}$,"I need to prove this equation
$$\sum_{k=0}^n (-1)^k\frac{{ {n}\choose{k}}{ {x}\choose{k}}}{{ {y}\choose{k}}} = \frac{{ {y-x}\choose{n}}}{{ {y}\choose{n}}}$$ where $x$, $y$ and $n$ are nonnegative integers satisfying $y \geq n$. The sign $(-1)^k$ suggests using binomial expansion, I've tried this, but without success. Is there a better way?","['combinatorics', 'summation', 'binomial-coefficients', 'sequences-and-series']"
2064180,Limit cycle for a system of ODEs,"Consider the system
  $$\frac{dx}{dt}=x (\lambda-x^2 + (1+\epsilon^2)y^2))+\omega y,~\frac{dy}{dt}=-\omega x + y (\lambda-x^2 + (1+\epsilon^2)y^2)).$$
  Show that the system has a stable limit cycle for $\lambda, \epsilon >0.$ My approach: Setting the RHS of each equal to zero and adding the two terms yields:
$$(x^2+y^2)\lambda - x^2 (x^2+y^2)-(1+\epsilon^2)(x^2+y^2)y^2=0.$$
Using polar coordinates $x=r \cos \theta,~y=r \sin \theta,$ we get
$$r^2 \cdot (\lambda - r^2 \cos^2 \theta - (1+\epsilon^2) r^2 \sin^2 \theta)=0,$$
which gives 
$$r=0,~r=\pm \frac{ \sqrt{\lambda}}{\sqrt{(1+\epsilon^2 \sin^2 \theta)}}.$$
............................................................................................ As one of the comments suggested, I tried setting the right hand sides of each equal to zero. $$x (\lambda-x^2 + (1+\epsilon^2)y^2))+\omega y=0,~-\omega x + x (\lambda-x^2 + (1+\epsilon^2)y^2))=0.$$ I tried method of elimination to solve for $x$ and $y,$ but wasn't successful. 
I still don't know how can this be any simpler than what I did before. 
I'm still stuck in this problem. Can someone please explain me from this how can I proved the desired conclusion. Thank you for your time.","['stability-in-odes', 'ordinary-differential-equations']"
2064290,Evaluating $\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx$ by method of residues.,"Im trying to solve $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx$$ using the method of residues. This function has two simple poles at $x=\pm i$ and so $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=2\pi i\text{Res}_{z=i }\frac{z^2 \cos(z)}{(z^2+1)^2}=2\pi i \lim_{z\to i} \frac d{dz}\Big[ (x-i)\frac{z^2 \cos(z)}{(z^2+1)^2}\Big]=2\pi i\lim_{z\to i}\frac d{dz}\Big[\frac{z^2\cos(z)}{(z+i)^2} \Big]=2\pi i \lim_{z\to i} \Big[ \frac{(z+i)^2(2z\cos z-z^2 \sin z)-2z^2(z+i)\cos z}{(z+i)^4} \Big]=2\pi i(-\frac{ei}{4})=\frac{\pi e}{4}$$
However wolfram alpha says that $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=0$$
I'm almost certain that the residue calculated above is correct, so why am I not able to apply the method here?","['complex-analysis', 'integration', 'residue-calculus']"
2064292,How to show this estimator of variance is biased?,"It is known that the sample variance is an unbiased estimator: $$s^2 = \frac 1{n-1} \sum_{i=1}^n (X_i - \bar X)^2$$ I would like show that $\sigma '^2 = (X_1 - X_2)^2 $ is a biased estimator. My work: $$E((X_1 - X_2)^2)= E(X_1^2) - 2E(X_1 X_2) + E(X_2^2)$$ I wasn't taught of how to specifically simplify these kinds of expression, but I suspect that $E(X_1^2)=E(X_2^2)$ since it's symmetrical. I don't have any further ideas about how to show that the expected value is not the population variance. Please give me some hints to work on it. Thanks.","['statistics', 'probability', 'expectation']"
2064293,"Maximum determinant of a non-negative matrix, given the sum of all entries","Let $M$ be an $n\times n$ matrix such that all of its entries are non-negative and sum to $A$. Can we prove $\det(M)\leq \frac{A^n}{n^n}$? I am looking for cool solutions, please go for it. My boring solution: We proceed via induction, Let $A_j$ be the matrix obtained by removing the $n$th row and $j$th column.Let $b_1,b_2,\dots b_n$ be the determinants of these matrices, then the determinant of $M$ is $\sum\limits_{j=1}^n(-1)^{n+j}a_ib_i$, if $a_1+a_2+\dots+a_n=s$ and the maximum of the absolute values of $b_1,b_2,\dots b_n$ is $m$ then clearly this sum is less than or equal to $sm$. Notice that the sum of the terms inside the matrix corresponding to $m$ is at most $A-s$, so by the induction hypothesis this product is at most $\frac{(A-s)^{n-1}}{(n-1)^{n-1}}s$. It is easy to show with calculus that this is maximized when $s=\frac{A}{n}$.","['optimization', 'linear-algebra', 'calculus', 'determinant']"
2064297,How do I actually choose poles?,"I have a control theory problem much akin to controlling the angle of an electric motor to a reference angle $\gamma_{ref}$ . (The ""electric motor"" exists in software only, and so has very little noise) Both the angle $x_1=\gamma$ and the speed $x_2=\dot{\gamma}$ are measureable, but only the angle acceleration $\ddot{\gamma}$ is controllable. The motor experiences a friction force $-b\dot{\gamma}$ and has inertia $1/c$ . Because I want to eliminate steady-state errors, I've introduced a dummy variable $x_3$ such that $\dot{x_3}=\gamma_{ref}-\gamma$ . My open loop system is: $$
\dot{x}=
\begin{bmatrix}
    0  & 1  & 0 \\
    0  & -b & 0 \\
    -1 & 0  & 0
\end{bmatrix}
x + 
\begin{bmatrix}
    0   \\
    c \\
    0
\end{bmatrix}
u +
\begin{bmatrix}
    0 \\
    0 \\
    1
\end{bmatrix}
\gamma_{ref}
$$ To put the control in canonical form, I've set: $$u=-l_1\gamma-l_2\dot{\gamma}-l_3x_3$$ and so $$
\begin{bmatrix}
    0 \\
    c \\
    0
\end{bmatrix}
u =
\begin{bmatrix}
    0 & 0 & 0 \\
    -cl_1 & -cl_2 & -cl_3 \\
    0 & 0 & 0
\end{bmatrix}
x
$$ which makes my closed loop system $$
\dot{x}=
\begin{bmatrix}
    0  & 1  & 0 \\
    -cl_1  & -b-cl_2 & -cl_3 \\
    -1 & 0  & 0
\end{bmatrix}
x + 
\begin{bmatrix}
    0 \\
    0 \\
    1
\end{bmatrix}
\gamma_{ref}
=
Ax+R\gamma_{ref}
$$ To get the characteristic equation, I have to take $$\det{(A-\lambda I)}=0$$ which I've worked out to be $$\boxed{\lambda^3+(b+cl_2)\lambda^2+cl_1\lambda-cl_3=0}$$ PROBLEM. How do I actually choose the poles? Using my test environment in Java, I've concluded that for $b=0.1,c=1.0$ the poles $$
\lambda=-0.63\quad
\lambda=-0.085-0.074i\quad
\lambda=-0.085+0.074i
$$ work fairly nicely... but this is a completely arbitrary trial-and-error method. I've seen some textbooks give answers like ""choose one pole -42b"" or whatever. But this is still not ideal. What general methods are available to me, where I can pick the poles based on some properties I want, like rise time and overshoot, and so on? I've tried reading about Bode plots but they sidetrack into theoretical stuff. Thanks a lot!!","['control-theory', 'ordinary-differential-equations', 'laplace-transform', 'linear-control']"
2064307,Expected value of distance between two points chosen at random on the edges of a unit cube,"Consider the probability space formed by the set $A$ of the edges of the unit cube $[0,1]^3$ in $\mathbb{R}^3$, the corresponding Borel $\sigma$- algebra, and the normalized length measure. Compute the expected value of the distance of $2$ distinct points chosen independently and uniformly in $A$. My attempt: I know that the expected value can be calculated as 
$$\int \int \int \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+(x_3-y_3)^2}\,dx\,dy\,dz. $$ But since the points are all chosen on the edges, then depending on the edge some of coordinates are fixed value, for example $0$ or $1$. But there are many scenarios for example two points are on the same edge, or two points are chosen on two jointed edges and etc. How do I calculate the total expected value? Help please.","['expectation', 'probability']"
2064309,How to prove $\sum_{k=0}^\infty \frac{2^k}{2^{2^k}+1}=1$?,"How can I prove this result?
$$\sum_{k=0}^\infty \frac{2^k}{2^{2^k}+1}=1$$ The sum converges very quickly: The term at $k=4$ is already smaller than $2^{-12}$ and each further term is much smaller than its predecessor. I've tried replacing the $2$'s by $x$'s and looking for power series, as well as seeing if the sum telescopes, but nothing so far has worked.","['power-series', 'sequences-and-series']"
2064327,Closeness the eigenvalues of a Matrix to a list of numbers,"Let $A,B\in M_n(\mathbb R)$, and $\ell$ a list of $n$ numbers sorted in some order (say, decreasing). Let $\lambda_i(A)$ be the $i$th eigenvalue of $A$ with respect to the chosen order. Finally, let $d(A,\ell) = ||\lambda(A)-\ell||_1 = \sum_{i = 1}^n |\lambda_i(A)-\ell_i|$ be the taxicab metric . My question is as follows: Given, $A,B,\ell$, is it possible to determine which of $d(A,\ell)$ or $d(B,\ell)$ is smaller without computing the eigenvalues of $A$ and $B$? Note : The $d(A,\ell)$ can also be any other meaningful metric that determines the matrix which its eigenvalues are closer to the list $\ell$ Update: My solution (Not working!) Let $\lambda$ and $\beta$ be the eigenvalues of $A$ and $B$ respectively. Clearly $det(A-\lambda I) = 0$ and $det(B-\beta I) = 0$ and $P_n(\lambda), P_n(\beta)$ are characteristic polynomial of $A,B$. Let sort the eigenvalues $\beta = \{\beta_1,\beta_2,...\beta_n \}$ and $\lambda = \{\lambda_1,\lambda_2,...\lambda_n \}$ in chosen order (say, decreasing). Let $\forall \ell_i \in \ell, i\in\{1,2,...,n\},$ if $\sum_{i=1}^{n} (det(A-\ell_i I)-det(B-\ell_i I)) > 0$ then eigenvalues of $B$ are closer to $\ell$ and if   $\sum_{i=1}^{n} (det(A-\ell_i I)-det(B-\ell_i I)) < 0$ then eigenvalues of $A$ are closer to $\ell$. Notice, since we don't actually need to calculate the eigenvalues of $A, B$, we don't need to solve the characteristic polynomial of $A, B$, It is enough to form the $det(A-\ell_i I)-det(B-\ell_i I)$, where $\ell_i$ is known then continue as described. Is this solution right? and is it easier to find determinant of $n$ matrices than finding the eigenvalues of a $n \times n$ matrix?","['matrices', 'eigenvalues-eigenvectors']"
2064344,Prove function increasing,"Assume $f(x)$ is continuous on $[0,1]$ and differentiable on $(0,1)$. Also we know $f(0)=0$ and $f'(x)$ is increasing. How to prove $\frac{f(x)}{x}$ is also increasing on $(0,1)$?","['derivatives', 'continuity', 'functions']"
2064345,Show that ${(F_n^2+F_{n+1}^2+F_{n+2}^2)^2\over F_{n}^4+F_{n+1}^4+F_{n+2}^4}=2$,"If $F_n$ is the $n$ -th Fibonacci number ( $1,1,2,3,5,8,\dots$ ), show that $${(F_n^2+F_{n+1}^2+F_{n+2}^2)^2\over F_{n}^4+F_{n+1}^4+F_{n+2}^4}=2$$ I have tested with a lot of Fibonacci numbers and it seem to obey the ruse, but I don't know how simplify it to 2. I try: Let $a=F_n$ , $b=F_{n+1}$ and $c=F_{n+2}$ $a^4+b^4+c^4+2(ab)^2+2(ac)^2+2(bc)^2=2a^4+2b^4+2c^4$ $2(ab)^2+2(ac)^2+2(bc)^2=a^4+b^4+c^4$ I am not sure, what to do next. Can anyone help by completing the prove?","['number-theory', 'recurrence-relations', 'fibonacci-numbers', 'elementary-number-theory']"
2064403,Why do we define change of basis matrix to be the transpose of the transformation?,"Example. Let $V$ be a finite dim vector space with two different bases $S = \{ u_1,u_2 \} =   \{ (1,2),(3,5) \}$ and $S' = \{ v_1, v_2 \}  = \{ (1,-1), (1,-2) \} $ You can check that $v_1 = -8u_1 + 3u_2$ and $v_2 = -11u_1+4u_2$ and $P = \begin{bmatrix}
-8 &-11 \\ 
 3& 4
\end{bmatrix}$ is the change of basis where the columns are the coords. But why can't we define change of basis by their rows? Since it works nicely that $\begin{bmatrix}
 v_1 \\
v_2 
\end{bmatrix} = \begin{bmatrix}
-8 &3 \\ 
 -11& 4
\end{bmatrix}\begin{bmatrix}
u_1 \\
u_2 
\end{bmatrix}$ So to move from the old basis $S$, you apply the matrix $\begin{bmatrix}
-8 &3 \\ 
 -11& 4
\end{bmatrix}$ to get a new basis. Why do we have to transpose? If you transpose, how do you even use this change of basis? Why can't I use this definition of change of basis.",['linear-algebra']
2064425,In how many ways can we put $31$ people in $3$ rooms?,"In how many ways can we put $31$ people in $3$ rooms such that each room has an odd number of people ? Can I apply generating functions here or Sterling's formula of $2$nd kind or any other method ? www.math.toronto.edu/szegedy/solutions.pdf The above link gives an approach, but I am not familiar with it .","['permutations', 'combinatorics', 'combinations']"
2064427,"Asymptotics of a double integral: $ \int_0^{\infty}du\int_0^{\infty}dv\, \frac{1}{(u+v)^2}\exp\left(-\frac{x}{u+v}\right)$","I want to calculate the asymptotic form as $x \to 0$ of the following integral.
\begin{alignat}{2}
I_2(x) &=&& \int_0^{\infty}du\int_0^{\infty}dv\, \frac{1}{(u+v)^2}\exp\left(-\frac{x}{u+v}\right) \\
&=&& \frac{\partial^2}{\partial x^2} \int_0^{\infty}du\int_0^{\infty}dv\, \exp\left(-\frac{x}{u+v}\right)
\end{alignat}
How can we solve? This question is related with this post . Thanks.","['limits', 'multiple-integral', 'asymptotics', 'integration', 'definite-integrals']"
2064457,An elementary algebra problem ($10$th grade standard),"Find out positive values of $x,y,z$ such that $$xyz=12167$$ and $$\frac{12167+xy}{1+z} + \frac{12167+yz}{1+x} + \frac{12167+xz}{1+y}=1587 $$
At first I made the following substitution: I replaced $$12167=xyz$$ in the equation and I got a simpler form: $$xy+yz+xz=1587$$ How to go further?",['algebra-precalculus']
2064460,Number of path-connected components of the set of all $m$-th roots of the identity matrix,"Let $m$ be a fixed natural number Let $X$ be the subset of $M_n( \Bbb C)$ defined by :
$X=\{A:A^m=I_n\}$ count the number of arc connected components of $X$ Except to note that the eigenvalues of the matrices of $X$ are the $n$-th roots of the unit, I do not advance in the enumeration","['combinatorics', 'general-topology', 'linear-algebra']"
2064469,Invertible ideal sheaf.,"I am a little bit confused with the idea of an invertible ideal sheaf. I cannot convince myself that there are invertible ideal sheaves on a scheme $X$ non isomorphic to the structure sheaf of $X$. I would like to know where my reasoning fails. Given an invertible ideal sheaf $\mathcal{I} \subset \mathcal{O}_X$ it comes equipped with the inclusion morphism into the structure sheaf. If the localization $\mathcal{I}_x \cong \mathcal{O}_{X,x}$ how is possible that the inclusion morphism does not induce an isomorphism between stalks?","['sheaf-theory', 'algebraic-geometry']"
2064484,How to show that $\sum\limits_{k=0}^n (-1)^k\tfrac{{ {n}\choose{k}}}{{ {x+k}\choose{k}}} = \frac{x}{x+n}$,"I'm trying to show that $$\sum_{k=0}^n (-1)^k\frac{{ {n}\choose{k}}}{{ {x+k}\choose{k}}} = \frac{x}{x+n}$$ I've tried expanding this using definition of binomial coefficient, then binomial expansion, now I'm using induction to simplify $\sum_{k=0}^m (-1)^k\frac{{ {n}\choose{k}}}{{ {x+k}\choose{k}}}$, but it looks very inelegant, is there a better way?","['combinatorics', 'summation', 'binomial-coefficients', 'sequences-and-series']"
2064500,What is the graph of cubic equation..,"I know that a parabola is the locus of the points found at equal distance from the focus and the directrix. Is there any similar geometric description of cubic curves, that would also allow me to draw their graphs?","['curves', 'geometry', 'algebraic-curves', 'cubics', 'conic-sections']"
2064516,"If $H,K$ be subgroup of $G$ such that $|H|=12$ and $|K|=5$ prove that $H\cap K ={e}$","Please check my proof: Consider the order of subgroup that can exist in H and K are 
For H are $1,2,3,6,12$
For K are $1,5$ Because the set of subgroup order n for H and K has no common member that has the same order except $1$ then only subgroup that in $H\cap K$ is $1$ or ${e}$","['abstract-algebra', 'group-theory', 'proof-verification']"
2064518,Showing that a complex number $z$ satisfies $|z|\leq 1$ given a certain condition,"If $z$ is a complex number such that $$|z-\varepsilon|\leq1\quad\mbox{ and}\quad |z-\varepsilon^{2}|\leq1$$ 
  where $\varepsilon \neq 1$ is the 3th root of unity. 
  Prove that $|z| \leq 1$. I don't know how to start. Any ideas?","['algebra-precalculus', 'complex-numbers']"
2064523,Cardinality the set of strictly decreasing functions $\Bbb N\to \Bbb N$,I'd like some help/clues with finding the cardinality of the set of the strictly decreasing functions from $\Bbb N$ to $\Bbb N$. I'm not quite sure if it's countable. Hints or clues will be helpful! Thank you so much!,"['elementary-set-theory', 'discrete-mathematics']"
2064539,"On a manifold, is the $L^p$ space of vector fields complete?","If $(M,g)$ is a Riemannian manifold, let $\mathcal L^p(M)$ denote the set of vector fields $X$ whose norm $|X|$ is an $L^p(M)$ function. Is this complete? The usual proof fails miserably because of off-diagonal terms in the metric.","['riemannian-geometry', 'differential-topology', 'partial-differential-equations', 'functional-analysis', 'lp-spaces']"
2064572,prove strictly convexity,"I wanna show $f(x)=-x^{\top}p+c\cdot\sqrt{x^\top\Sigma x}$ is strictly convex, where $p$ is a constant vector, $\Sigma$ is positive definite. I tried to show it by using $f''(x)$ is positive definite and I could obtain $$H(x)=c\cdot \frac{\Sigma -\frac{(\Sigma x)(\Sigma x)^{\top}}{x^\top\Sigma x}}{\sqrt{x^\top \Sigma x}}$$ yet I am stuck here. Could someone help me clarify it? Thanks in advance!","['derivatives', 'positive-definite', 'convex-analysis', 'calculus']"
2064588,Continuous partial derivatives implies continuous differential,"We have the well-known statement (Analysis I by Zorich, p.457): Let $f: U(x) \to \mathbb{R}$ be a function defined in a neighbourhood
  $U(x) \subseteq \mathbb{R}^m$ of the point $x = (x^1,\dots,x^m)$. If
  the function $f$ has all partial derivatives $\frac{\partial
 f}{\partial x^1},\dots,\frac{\partial f}{\partial x^m}$ at each point
  of $U(x)$ and they are continuous at $x$, then $f$ is differentiable
  at $x$. Now my question is, that somehow my lecture notes suggest, that when the partial derivatives are continuous at all points of $U(x)$, $f$ is then continuously differentiable, i.e. the map $U(x) \to \text{Hom}(\mathbb{R}^m,\mathbb{R})$ is continuous. How can this be seen?",['multivariable-calculus']
2064651,"Given $U$ with known PDF, find $W$ independent of $U$ such that $U+W$ is distributed like $2U$","Let $U$ denote a random variable with PDF $$f_U(u)=ce^{-u\sqrt{u}}\,\mathbf 1_{u>0}$$ Does there exist a random variable $W$ independent of $U$ such that $U+W$ is distributed like $2U$? This question is related to something I asked here . In other words, can we find a random variable $W$ such that 
\begin{align}
2 U' =U+W
\end{align}
where $W$ and $U$ are independent and $U'$ has the same distribution as $U$.","['independence', 'probability-theory', 'convolution', 'random-variables']"
2064658,Give the general formula for the integer $n$,"For the following equation:- $$a_1+a_2+a_3.....+a_n=a_1a_2a_3.....a_n = n$$ For $a_1,a_2...a_n \in \mathbb Z$, find the general form of the integer n. Note that we need $n$ summands/factors Note:- Regarding the explanation of the term ""general form"": For instance, even numbers are of the general form $2m.$ and rational numbers are of the general form $p/q,etc $. I mean it in that way. PS: My guess is that we have to use some general formula for multivariable diophantine equation but I don't even know what to do if it is a multivariable diophantine equation.","['number-theory', 'diophantine-equations', 'linear-algebra']"
2064678,Proving the *Caratheodory Criterion* for *Lebesgue Measurability*,"I'm following Terry Tao 's An introduction to measure theory . Here he has defined lebesgue measurability as: Definition 1 (Lebesgue measurability): A set $E$ is said to be lebesgue measurable if for every $\epsilon > 0$, $\exists$ an open set $U$, containing $E$, such that $m^*(U \setminus E) \leq \epsilon$. where $m^*$ denotes the outer lebesgue measure . Then he has stated the Caratheodory Criterion : Definition 2 (Lebesgue measurability): A set $E$ is said to be lebesgue measurable if for every elementary set $A$, we have 
  $$m(A)=m^*(A \cap E)+m^*(A \setminus E)$$ where an elementary set is a finite union of boxes . The problem is to show the equivalence of the two definitions. I have shown that Def $(1)$ $\implies$ Def $(2)$, but having difficulty in showing the reverse, i.e. Def $(2)$ $\implies$ Def $(1)$. Any help (full/brief solution or even some hints) would be greatly appreciated! Thanks in advance.","['real-analysis', 'measurable-sets', 'lebesgue-measure', 'measure-theory']"
2064723,Find acceleration given velocity with respect to distance,"A particle moves with the velocity given by: $$v(s(t)) = \frac{3s(t) + 4}{2s(t)+1}$$
where s(t) is the distance traveled. Find the acceleration when s(t) = 2. My attempt:
$$a(s(t)) = \frac{\mathrm d}{\mathrm dV(s(t))}\left(\frac{3s(t) + 4}{2s(t)+1}\right) = \frac{(3s(t)+4)2 - 3(2s(t)+1)}{(2s(t)+1)^2}$$
$$a(2) = \frac{10\times 2-3\times 5}{25} = \frac{5}{25} = \frac{1}{5}.$$ The answer is however supposed to be $-\frac{2}{5}$. Why?",['derivatives']
2064741,Finding the functions $f : \Bbb N \to \Bbb N$ which satisfy $f\circ f(x) + f(x) = 2x+15$,"I'm stuck on finding the functions that satisfy $f\circ f(x) + f(x) = 2x+15$ . The answer given is $f(x) = x + 5$ , which I can easily verify, but I do not know how to go about forming this aside from just trial and error. How would I go about doing this systematically? It is also given that $f : \Bbb N \to \Bbb N$ is injective.","['relations', 'functional-equations', 'functions', 'discrete-mathematics']"
2064776,"""homogenization"" of an ideal","Hello all of this originated from Gathmann's notes on Algebraic Geometry. I'm currently trying to wrap my head around projective $n$-space $\mathbb P^n$, its algebraic subsets and their connection to algebraic subsets of affine $n+1$-space $\mathbb A^{n+1}$, via the projection map $\pi : \mathbb A^{n+1} \rightarrow \mathbb P^n$. For all that I'm missing the link between the respective ideal operations, which should be something like ""homogenization"" of an ideal. Also I'm wondering about the connection to the usual homogenization of an ideal $I$ in $k[x_1, ..., x_n]$ to an homogeneous ideal in $k[x_0, ..., x_n]$ via homogenization with respect to $x_0$. Then there's another operation that, in my head, sounds like it should be connected to all that, but maybe its purpose is entirely different. This operation is taking the saturation of an homogeneous ideal $I$ in $k[x_0, ..., x_n]$. We have the following diagram (sorry for the formatting): {alg. sets in $\mathbb P^n$} $\hspace 1.5cm$ $\longleftrightarrow$ $\hspace 1.5cm$ {cones in $\mathbb A^{n+1}$ with $0$ removed} $\subset$ {alg. sets in $\mathbb A^{n+1}$} $\hspace 1.5cm$ $\downarrow$ $\hspace 7cm$ $\downarrow$ {homog ideals in $k[x_0, ..., x_n]$} $\hspace 0.5cm$ $\longleftarrow$ $\hspace 0.5cm$ {ideals in $k[x_0, ..., x_n]$} Here the left-down map is taking the ideal generated by the homogeneous polynomials vanishing on the algebraic set. The right-down map is taking the ideal of polynomials vanishing on the algebraic set. I do know that the ideal associated to a cone is homogeneous. The top maps are given by taking the preimage and image of the algebraic sets in $\mathbb P^n$ and $\mathbb A^{n+1}$ respectively. The cones in $\mathbb A^{n+1}$ are by definition the saturated sets in $\mathbb A^{n+1}$ with respect to the projection $\pi$, i.e. algebraic sets, that for any point in them contain the whole line through this point and the origin. Now my main question is, is there a nice map for the lower arrow, so that the diagram commutes? One could go the whole way around, by taking the zero locus of the ideal, then applying $\pi$ to the zero locus and finally taking the homogeneous ideal associated to the obtained algebraic set. But I'm wondering whether there is a simpler way to describe this. This is what i mean by something like ""homogenization"". 
I.e. what do I do when I only have some not necessarily homogeneous polynomials in $k[x_0, ..., x_n]$. Is there a nice way to get an algebraic set in $\mathbb P^n$? At first I was very happy, because I thought, this was exactly just what is actually called homogenization of an ideal, but ""of course"" it is not, since that is about taking an ideal from $k[x_1, ..., x_n]$ and giving an homogeneous ideal in $k[x_0, ..., x_n]$. This sits in the following diagram: {alg. sets in $\mathbb P^n = \mathbb A^n \cup \mathbb P^{n-1}$} $\hspace 0.8cm$ $\longleftrightarrow$ $\hspace 1cm$ {alg. sets in $\mathbb A^n$} $\hspace 1.5cm$ $\uparrow$ $\hspace 7cm$ $\uparrow$ {homog ideals in $k[x_0, ..., x_n]$} $\hspace 0.5cm$ $\longleftrightarrow$ $\hspace 0.8cm$ {ideals in $k[x_1, ..., x_n]$} Here the top arrow from the left to the right is taking intersection with $\mathbb A^n$ and the other direction is taking the topological closure in $\mathbb P^n$. Both the maps upwards are taking the zero locus of the respective ideals. The maps at the bottom are homogenization of an ideal with respect to $x_0$ (see http://mathworld.wolfram.com/HomogeneousIdeal.html ), and in the other direction dehomogenization, by setting $x_0=1$. My question is, is there any connection between this homogenization and the previous diagram? Now, as I said, there's another operation called saturation that takes an homogeneous ideal in $k[x_0, ..., x_n]$ and gives an homogeneous ideal in $k[x_0, ..., x_n]$. This is defined by $\bar I = \{f \in k[x_0, ..., x_n], \exists\ m\ s.t. \forall\ i\ x_i^m s \in I \}$ To be honest I haven't really understood what is happening here and I haven't found much on it, so I don't know whether it is at all connected to the previous stuff. If anyone had some insight on this I would be very thankful. For example I don't know whether the fact that it is called saturation means, that it comes from the saturation with respect to some equivalence relation. I know, that it is needed to get a 1 to 1 correspondence between projective subschemes of $\mathbb P^n$ and homogeneous ideals in $k[x_0, ..., x_n]$, modulo having the same saturation. I'm very thankful to anyone, who read through this whole text and even more if they can help me. Btw. this whole problem started, when I tried to write down an equation for a line through two points in $\mathbb P^2$ and realized that I have no clue about what I'm doing.","['algebraic-geometry', 'commutative-algebra']"
2064860,Isomorphic plane curves and projective equivalence,"1) If $C\subset\mathbb{P}^2$ is a smooth degree $d$ plane curve, does there exist another degree $d$ curve $C'\subset\mathbb{P}^2$ such that $C\cong C'$, but $C$ and $C'$ are not related by a $PGL_3$ action? 2) If so, does there exist a 1-dimensional family of such $C'$? (i.e. is the space of plane curves of degree $d$ isomorphic to $C$ of dimension at least 8+1=9?) (My guess is that the answer to 1) is no for $C$ general, but yes for specific $C$ and the answer to 2) is no for all $C$. However, I feel like there should be a reference, and there's no need to guess.)","['algebraic-curves', 'algebraic-geometry']"
2064929,Gauss-Bonnet theorem proof considering membrane Force and hydrostatic fluid Pressure equilibrium,"Is it possible to prove Gauss-Bonnet Theorem by using physics (Mechanics of materials) models? For example in mechanics  could one consider static equilibrium by action of hydrostatic pressure normal to  a patch, tension in the curved patch boundary line or using strain energy, or by considering tension forces and/or moments in all three directions? Surface Tension property $N$ or force per unit arc length of a closed boundary (or membrane energy in creating a new unit area), $N$ can balance pressure on a spherical soap-film as $ p = 2 N \kappa_n , $ where $\kappa_n$ is normal curvature of the bubble or by mean curvature  $  2 H = p /N $ for a doubly curved patch. EDIT1: My attempt ... Gauss Bonnet theorem for a singly connected patch. Proposing here an elementary physics model : $$ \int K dA  + \int k_g ds = 2 \pi\tag{1} $$ Defining elemental force $dF$ linking the above solid and tangential membrane "" rotations"" as applicable for pressure and surface tension by means of their force component  $ dF$: $$ dF = p \,dA  \cos \phi  = N \,ds \sin \phi ;\ \tag{2}$$ we have $$    \int  \left( \frac{K}{p \cos \phi} +  \frac{k_g}{ N\sin \phi } \right) dF = 2 \pi\tag{3}$$ as a topological constant.. However getting a full physical sense is elusive, at time of posting but was soon changed  as following. EDIT2: Answering own question at least partially .. We can derive Gauss Bonnet by considering mechanical Force Equilibrium of a spherical segment of the soap bubble in the following manner taken after equilibrium considerations of spherical or cylindrical pressure vessels... the attempt appears to me this way now, but may still need revision : Considering static force and pressure equilibria, net force in horizontal direction is zero. $$ 2 \pi R \cdot  p  \Delta z + N\cdot 2 \pi r  = 0 $$ $$ \frac{1}{2 \pi R \cdot  p  \Delta z} +\frac{1}{ N\cdot 2 \pi r } = 0  \tag{4}$$ Divide numerator and denominator of each term by $R$ and let $$ 1/R^2 = K ;\, \Delta z/R = \cos \phi ;\,  r/R = \sin \phi \,; 1/R = k_g\, ;\tag{5} $$ $$ \frac{ 1/R^2}{2 \pi p (\Delta z/R) } + \frac {1/R}{2 \pi N ( r/R) } \tag{6}$$ $$ \frac{ K } { 2 \pi p\cos \phi} + \frac { k_g}{ 2 \pi N \sin \phi} = 0  \tag {7} $$ which relation when multiplied by $dF$ and integrated we get the same form of of Gauss Bonnet theorem Equn (3) with $2 \pi$ now appearing as an integration constant which can be  identified as a topological constant. EDIT 3: Essentially it is seen that physical model geometrization is made  possible by looking at area as reciprocal of pressure $p$ and boundary length as reciprocal of surface tension $T.$ The insight applied so far is that in a soap film application of pressure increases its area and boundary line dilations occur by linear (uni-axial) tension. The correct model should include all doubly curved surfaces, not spherical the surfaces only .","['physics', 'differential-geometry', 'geometric-interpretation']"
2064939,Laplace-Beltrami Operator of p-forms,"I'm trying to compute the Laplace-Beltrami Operator in local coordinates of some Riemannian manifold $M$ . By definition, Laplace-Beltrami Operator $$\Delta=d\delta+\delta d$$ acts in p-form on $M$ , where is defined by $$\delta=(-1)^{n(p+1)+1}\star d\star$$ and $\star$ is the Hodge operator. So, I started with the $M=\mathbb{R}^n$ and by direct calculation is simple to verifie that, in coordinates $(x_1,\dots,x_n)$ if $\omega=fdx_{i_1}\wedge\dots\wedge dx_{i_p}$ is a p-form on $\mathbb{R}^n$ then $$\Delta\omega=-\sum_{s=1}^n \frac{\partial^2f}{\partial x_s ^2}dx_{i_1}\wedge\dots\wedge dx_{i_p}.$$ The question is if I have a local coordinates of $\mathbb{S}^n$ , for example, $F:\mathbb{S}^n \setminus{(0,\dots,0,1)}\subset\mathbb{R}^{n+1}\to \mathbb{R}^n$ defined by $$F(x_1,\dots,x_{n+1})=\frac{1}{x_{n+1}-1}(x_1,\dots,x_n)$$ how can I write the Laplace-Beltrami operator of the p-form $\omega=fdx_{i_1}\wedge\dots\wedge dx_{i_p}$ ? Any idea? Thanks so much.","['riemannian-geometry', 'differential-geometry', 'analysis']"
2064953,Example of the good set principle,"Can anyone help me with the following? For $A \subset \mathbb{R}^d$ and $\mathbb{a}> 1$ , let $aA:=\{ax|x\in A\}$ . If $A$ is a Borel set in $\mathbb{R}^d$ , then $\mathbb{a}A$ is also a Borel set. Our lecturer gave us this as an example, but without a proof. He only gave us the hint to use the good set principle. Can someone show me how to proof this?
Or at least explain to me how to use the principle in general?
I saw a question similar to this one, but it didn't help me.
It'd be great, if anyone could help me.",['measure-theory']
2064954,"Path connectedness of the set $\{(x,y):(x+1)^{2}+y^{2}\leq 1\}\cup\{(x,y):y=x\sin(\frac{1}{x}),x>0\}$","Let $A$ be the following subset of $\mathbb{R}^{2}$:$$A=\{(x,y):(x+1)^{2}+y^{2}\leq 1\}\cup\{(x,y):y=x\sin(\frac{1}{x}),x>0\}$$ Then $1.$ $A$ is connected. $2.$ $A$ is compact. $3.$ $A$ is path connected. $4.$ $A$ is bounded. It is clear that $A$ is unbounded as the graph of $x\sin(\frac{1}{x})$, so option $2$nd and $4$th are not correct. Again $A$ is connected by using the fact that closure of connected set is connected. But i am confused about path connectedness of $A$. Please help me about path connectedness of $A.$ Thanking you.","['general-topology', 'connectedness']"
