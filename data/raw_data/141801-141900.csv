question_id,title,body,tags
2295691,Expected value: Poisson random variable,"I have proved that $$E[X^n]=\lambda E[(X+1)^{n-1}]$$ for a Poisson random variable with parameter $\lambda$ where $n$ is a positive integer. Now $E[X+2]=E[X]+2=\lambda+2$ But using the formula that I proved, $E[X+2]=\lambda E[(X+3)^0]=\lambda E[1]=\lambda$ Which of these is correct and where have I gone wrong? Proof of $E[X^n]=\lambda E[(X+1)^{n-1}]$: \begin{align}
E[X^n]&=\sum_{i=0}^\infty i^np(i) \\
&=\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^i}{i!} \\
&=\lambda\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\
&=\lambda\sum_{i=1}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\
&=\lambda\sum_{i=1}^\infty i^{n-1}e^{-\lambda}\frac{\lambda^{i-1}}{(i-1)!} \\
&=\lambda\sum_{i=0}^\infty(i+1)^{n-1}e^{-\lambda}\frac{\lambda^i}{i!} \\
&=\lambda\sum_{i=0}^\infty(i+1)^{n-1}p(i) \\
&=\lambda E[(X+1)^{n-1}]
\end{align}","['statistics', 'probability']"
2295786,"If $G'/G''$ and $G''/G'''$ are cyclic, then $G''=1$","Here, $G'=[G,G]$, $G''=[G',G']$ and $G'''=[G'',G'']$. I had no idea where to start so I read the hint given by the book, which started with ""You may assume $G'''=1$"". I am uncomfortable with this assumption, since I have been unable to prove that $G''$ is abelian. I tried arguing that $G'$ consisted of elements of the form $x^k[y,k]$ where $x\in G''^c$ and $y,z \in G'$ but after computing the commutator of two such elements, I found no reason for which two such commutators should commute. If I blindly assumed that was true, then $G''$ would be cyclic, but other than that I do not see how exactly it is necessarily the trivial group. Why is $G''$ abelian? And why is it necessarily equal to $1$?","['group-theory', 'quotient-group']"
2295823,An inequality problem of product of matrices,"Let $A,B \in \mathbb{R^{n\times n}_{\geq 0}}$ be random matrices where A is symmetric and B is both symmetric and PSD. Suppose $\|A-\mathbb{E}A\|_{\text{op}}\leq \epsilon_1$ and 
$\|B-\mathbb{E}B\|_{\text{op}}\leq \epsilon_2$ both with high probability. Is this possible to prove a concentration as follows: $\| (B+\lambda I)^{1/2} A (B+\lambda I)^{1/2} - \mathbb{E}[(B+\lambda I)^{1/2}] \mathbb{E}[A] \mathbb{E}[(B+\lambda I)^{1/2}]\|_{\text{op}}\leq \epsilon_3$  with high probability? ,where $\lambda \geq 0$ is a scalar and $I$ is the identity matrix. (I tried to add and subtract $(B+\lambda I)^{1/2} \mathbb{E}[A] (B+\lambda I)^{1/2}$ and use triangle inequality but got stuck to prove the concentration of the second term.)","['inequality', 'random-matrices', 'concentration-of-measure', 'probability-theory', 'linear-algebra']"
2295826,An interesting trigonometric identity,"I found the following interesting fact:- $$\dfrac {(\dfrac {\sin 30^0}{\sin 40^0})}{\sin 50^0} = \dfrac {1}{\sin 80^0} \text {(exactly)}$$ It can easily be verified by applying double angle formula. My questions are:- 1) What is corresponding geometrical figure that can reflect the above; and 2) How can this be applied to give further results [For example, constructing a $50^0$ angle from an $80^0$ one.]?","['trigonometry', 'geometry']"
2295907,Find $\tan x$ if $x=\arctan(2 \tan^2x)-\frac{1}{2}\arcsin\left(\frac{3\sin2x}{5+4\cos 2x}\right)$,Find $\tan x$   if $$x=\arctan(2 \tan^2x)-\frac{1}{2}\arcsin\left(\frac{3\sin2x}{5+4\cos 2x}\right) \tag{1}$$ First i converted $$\frac{3 \sin 2x}{5+4 \cos 2x}=\frac{6 \tan x}{9+\tan^2 x}$$ So $$\arcsin\left( \frac{6 \tan x}{9+\tan^2x}\right)=\arctan \left( \frac{6 \tan x}{9-\tan^2x}\right)$$ Now using above result $(1)$ can be written as $$2x=2 \arctan(2 \tan^2 x)-\arctan \left( \frac{6 \tan x}{9-\tan^2x}\right) \tag{2}$$ But $$2\arctan (\theta)=\arctan \left(\frac{2 \theta}{1-\theta^2}\right)$$ So $(2)$ becomes $$2x=\arctan \left(\frac{4 \tan^2x}{1-4 \tan^4x}\right)-\arctan \left( \frac{6 \tan x}{9-\tan^2x}\right)$$ Now using $$\arctan(a)-\arctan(b)=\arctan\left(\frac{a-b}{1+ab}\right)$$ i am getting a sixth degree polynomial in $\tan x$. is there any better approach?,"['algebra-precalculus', 'trigonometry', 'inverse-function']"
2295935,hint on solving $1+y'^2-y\cdot y''=0$?,"I have the following ODE: $$1+y'^2-y\cdot y''=0$$ I've never solved an ODE where two ""versions"" (don't know the term) of $y$ are multiplied with eachother, in this case $y$ and $y''$. Can I have a hint how to approach this, without too much of an answer?","['ordinary-differential-equations', 'nonlinear-system']"
2295974,Lie derivative characterisation of the Levi-Civita connection,"In this note , equation (6) the author claimed that $(M,g)$ is a Riemannian manifold. Let $X,Y,K$ be vector fields defined in the vicinity of a point $p\in M$. Then the condition that $\nabla$ is Levi-Civita connection means that
  $$L_K|_p(M\ni x\mapsto g_x(X_x,Y_x)\in\Bbb R)=g_p((\nabla_KX)_p,Y_p)+g_p(X_p,(\nabla_KY)_p)$$ I have rearranged the notations to make them look rigorous. In the original notations the equation looks like $$L_K\langle X,Y\rangle=\partial_K\langle X,Y\rangle=\langle \nabla_KX,Y\rangle+\langle X,\nabla_KY\rangle$$ Could anybody provide any references for a proof? The reference the author gave seems inaccessible (I couldn't find it online). Many thanks! EDIT In effect I'm looking for a proof for the characterisation of Killing fields found on Wikipedia , i.e., $X$ preserves metric (which I think is equivalent to $L_K|_p(M\ni x\mapsto g_x(X_x,Y_x)\in\Bbb R)=0$) means $$g(\nabla _{{Y}}X,Z)+g(Y,\nabla _{{Z}}X)=0\,$$ EDIT AGAIN Sorry I was so dumb, the equation I asked about in the main text is just the compatibility of the Levi-Civita connection. And in fact, this expression doesn't quite match the one characterising the Killing form (in the previous EDIT): for the one in the main text it's $\nabla_KX$ and for the one in the EDIT it's $\nabla_XK$. I have to give it quite a lot of thoughts how to make use of the relation $\nabla_KX-\nabla_XK=[K,X]$ etc.","['connections', 'lie-derivative', 'riemannian-geometry', 'differential-geometry']"
2295985,"Find all functions $\Phi$ on $[0,\infty)$ where $\Phi(\lim\limits_{p\to 0}||f||_p)=\int\limits_{0}^{1}(\Phi \circ f)d\mu$.","Where I am in the Problem I am now trying to solve the smaller problem: Find all functions $f$ on $[0,\infty)$ satisfying the relation $cf(x)+(1-c)f(1)=f(x^c)$ where $0\leq c\leq 1$ I know constant functions work, and logrithmic functions would work if $0$ was omitted from the domain, but I am having a hard time approaching this problem when I can't assume that the function $\Phi$ is at least continuous. For some context this problem came out of a bigger problem from rudin real and complex analysis Let $m$ be Lebesgue measure on $[0,1]$, and define $||f||_p$ with respect to $m$. Find all functions $\Phi$ on $[0,\infty)$ such that the relation $$\Phi(\lim\limits_{p\to 0}||f||_p)=\int\limits_{0}^{1}(\Phi \circ f)d\mu$$
  holds for every bounded, measurable, positive $f$. Show first thtat $$c\Phi(x)+(1-c)\Phi(1)=\Phi(x^c)\quad (x>0,0\leq c\leq 1)$$ My Work In total: Let $f=a\chi_A+b\chi_B$ be measurable, where $a,b>0$, $A\cup B=[0,1]$, and $A\cap B=\emptyset$. Then $$||f||_p=\bigg\{\int\limits_{X}|f|^pd\mu\bigg\}^{1/p}$$
so $$||a\chi_A+b\chi_B||_p=\bigg\{\int\limits_{X}|a\chi_A+b\chi_B|^pd\mu\bigg\}^{1/p}=\bigg\{\int\limits_{X}|a|^o\chi_A+|b|^p\chi_Bd\mu\bigg\}^{1/p} \quad (*)$$ $$=\big\{a^p\mu(A)+b^{p}\mu(B)\big\}^{1/p}$$ Let $a=x$, $b=1$, and $\mu(A)=c$. $$||f||_p=\big\{cx^p+(1-c)\big\}^{1/p}$$ Thus $$\Phi(\lim\limits_{p\to 0} ||f||_p)=\Phi(\lim\limits_{p\to 0}\big\{cx^p+(1-c)\big\}^{1/p})=\Phi(x^c)\quad (**)$$ $$\int\limits_{0}^{1}(\Phi \circ f)d\mu= c\Phi(x)+(1-c)\Phi(1)$$ Thus $$c\Phi(x)+(1-c)\Phi(1)=\Phi(x^c)\quad (x>0,0\leq c\leq 1)$$ Footnotes (*) While it is normally true that $(a+b)^p\neq a^p+b^p$, since $a$ and $b$ are being multiplied by characteristic functions it means that $$|a\chi_A(x)+b\chi_B(x)|^p=\begin{cases}|a|^p & x\in A\\ |b|^p & x\in B\end{cases}$$. Given that the proceding equality holds. (**) The limit on the inside is achived by letting $\big\{cx^p+(1-c)\big\}^{1/p}=e^{\frac{\ln(cx^p+(1-c))}{p}}$, applying l'hopital's rule to the exponent once gives the desired equality.","['real-analysis', 'measure-theory']"
2295996,Product of upper triangular matrix and lower triangular matrix,"I need to show the following: Let $A,B \in GL(n)$ so that both of them are upper triangular matrices and  $A*B^t$ or $A^t*B$ is a diagonal matrix. Show that $A$ and $B$ are diagonal matrices as well. I tried it for small $n$ and it is kinda clear but i don't know how to prove it. I tried contraposition but it did not work well. Some help would be appreciated!","['matrices', 'matrix-calculus', 'linear-algebra']"
2296020,What does it mean to multiply differentials?,"Often times in multi-variable calculus you would have expressions for the differentials of area and volume like this $dA =dxdy$ or $dV = dxdydz$  which we are supposed to just accept because it makes sense in that if you take a tiny piece of area/volume it looks like a square blah blah....But  cannot get my head around it especially when doing integral substitutions. In single variable calculus it made sense, for example consider the integral
$$\int f'(g) \frac{dg}{dx} dx = \int f'(g)dg = f(x) + c$$
this makes sense as $f'(x) = g'(x)f'(g)$ by the chain rule but when preforming a substitution in a double integral 
$$\int \int f(x,y) dx dy = \int \int f(u,v) \det(J)du dv$$ where $$J = \frac{\partial(x,y)}{\partial(u,v)} = \begin{pmatrix} \frac{\partial x}{\partial u} &  \frac{\partial x}{\partial v} \\ \frac{\partial y}{\partial u}  
 & \frac{\partial y}{\partial v}\end{pmatrix}$$
How on earth have they magically jumped and concluded that $dxdy$ (which itself is not explained) equal to $\det(J)dudv$ ? This has caused me so many problems conceptually and i was not able to find any clear explanation to why this is the case and even what is meant by the term $dxdy$","['multivariable-calculus', 'differential-forms']"
2296087,Is there a Banach space version of Riesz representation theorem?,"Let $X,Y$ be Banach spaces over $\mathbb{R}$ and $B:X\times Y\rightarrow \mathbb{R}$ be a continuous bilinear function such that $X\rightarrow L(Y,\mathbb{R}):x\mapsto B(x,-)$ and $Y\rightarrow L(X,\mathbb{R}):y\mapsto B(-,y)$ are injective. Let $T:X\rightarrow X$ be a continuous linear transformation. Then, does there exist a continuous linear transformation $T^*:Y\rightarrow Y$ such that $B(Tx,y)=B(x,T^*y)$ for all $(x,y)\in X\times Y$?","['functional-analysis', 'riesz-representation-theorem']"
2296089,Why does the antiderivative of $\frac{1}{x}$ have to be $0$ at precisely $x=1$? (when $C = 0$),"Why does $\log{x}$ represent the area below the graph of $f(x)=\frac{1}{x}$ from $1$ to $x$? What's so special about $1$ in this case? Of course I understand that $\log{1}=0$ and I also understand that you cannot start at $x=0$ because $f(0)$ is not defined. Still I can't get my head around of why it has to be $1$. Also, this further implies that part of the antiderivative of $f(x)=\frac{1}{x}$ has to be negative (as part of the function of $\log{x}$ is negative). But why is this necessary? The background of this question is that my calculus-book (Calculus, a complete course) starts with noticing that $f(x)=\frac{1}{x}$ is not an antiderivative of a polynomial function and then attempts to define a antiderivative which ends up being $\log{x}$. It does this all before even addressing the fundamental theorem of calculus or techniques of integration. They then simply define $log(1)$ to be $0$ without even knowing what that function really is yet. So I am stuck with kind of a circular reasoning where log(1)=0 because we defined it that way, but I don't understand why we define it that way. When calculating areas under graphs by taking the limit of a sum (instead of by integration), you would start at $x=0$ right? So in short: Why does the antiderivative of $\frac{1}{x}$ have to be $0$ at precisely $x=1$? (when $C = 0$). Why do we define it that way? I am looking for some kind of deeper understanding; something still didn't ""click"". So some real background on what's going on here would be much appreciated. Thanks!","['integration', 'calculus']"
2296108,Surface integral - spherical,"I'm trying to calculate the following surface integral $$\int \int_{s_r} \frac{z-R}{(x^2+y^2+(z-R)^2)^{3/2}} dS $$, where $s_r=\{(x,y,z)\in \mathbb{R}^3 : x^2+y^2+z^2=r^2 \}. $ I've switched to spherical coordinates but don't really know how to do it.","['multivariable-calculus', 'surface-integrals', 'integration']"
2296118,"""A proof"" that Riemann tensor is zero","Riemann tensor is zero in flat space, and well, it is tensor. Thus we have the tensor equation R=0 which means that Riemann tensor is zero in all the coordiantes systems, which is completely a lie. Where is my mistake here?","['differential-geometry', 'general-relativity']"
2296177,Determine exact values using angle sum and difference identity (trig),"Ok so we have just learnt the basic angle sum and difference identities: $$\begin{array}{l}\cos \left( {A \pm B} \right) = \cos A\cos B \mp \sin A\sin B\\\sin \left( {A \pm B} \right) = \sin A\cos B \pm \cos A\sin B\\\tan \left( {A \pm B} \right) = \frac{{\tan A \pm \tan B}}{{1 \mp \tan A\tan B}}\end{array}
$$ The question i have been given is determine the exact value of $\tan {15^0}$ degrees. 
So i assume you use the tan identity, sub in $$\tan \left( {{{45}^0} - {{30}^0}} \right) = \frac{{\tan {{45}^0} - \tan {{30}^0}}}{{1 + \tan {{45}^0}\tan 30}}
$$ After simplifying it down as far as possible i end up with: $$\frac{{\left( {3\left( {3 - \sqrt 3 } \right)} \right)}}{{\left( {3\left( {3 + \sqrt 3 } \right)} \right)}}
$$ However the correct answer is: ${2 - \sqrt 3 }$ I'm not sure if iv'e done something wrong or are completely off track, but could someone please explain (as simply as possible) how to achieve this answer.",['trigonometry']
2296198,Let $k$ be a postive integer number . Then $2k^2+1$ and $3k^2+1$ cannot both be square numbers.,Let $k$ be a postive integer number . Then $2k^2+1$ and $3k^2+1$ cannot both be square numbers. I tried to prove this by supposing one of them is a square number and by substituting the corresponding $k$ value. But I failed to prove it.,"['number-theory', 'pell-type-equations', 'diophantine-equations']"
2296219,Terms like ds dx dy in metrics?,"How is one meant to make sense of the terms ds, dx and dy in a metric? For example the metric for hyperbolic space is $$ds^{2} = \frac{dx^{2} +dy^{2}}{y^2}$$ Given two points in the upper half plane model of hyperbolic space, how am I to use this formula to find the distance between them?",['geometry']
2296278,A $\frac{1}{3}$ Conjecture?,"Question: Let $A(n)$ be a finite square $n \times n$ matrix with entries $a_{ij}=1$ if $i+j$ is a perfect power; otherwise equals to
  $0$. Is it true that $${1 \above 1.5 pt n^2}\sum_{i=1}^n \sum_{j=1}^n
a_{ij} \leq {1 \above 1.5pt 3}$$ with equality holding if and only if
  $n=3$ or $n=6$ ? Let $A(n)$ be a finite square $n \times n$ matrix with entries $a_{ij}=1$ if $i+j$ is a perfect power; otherwise equals to $0$. For an example consider $A(5)$ $$A(5)= \text{ }\begin{pmatrix}
0&0&1&0&0\\
0&1&0&0&0\\
1&0&0&0&1\\
0&0&0&1&1\\
0&0&1&1&0\\
\end{pmatrix}$$ Can we show that ${1 \above 1.5 pt n^2}\sum_{i=1}^n \sum_{j=1}^n a_{ij} \leq {1 \above 1.5pt 3}$ with equality holding if and only if $n=3$ or $n=6$. The graph below plots the values of ${1 \above 1.5 pt n^2}\sum_{i=1}^n \sum_{j=1}^n a_{ij}$ for small $n$. The graph is what motivated me to ask the question. It appears that the maximums are achieved if $n=3$ or $n=6$. UPDATE: I have corrected several terms and added several new terms check out: A293462 . Here was my approach: Let $^t$ be the transpose map that sends the entry $a_{ij} \to a_{ji}$. The commutativity of addition shows us that if $i+j$ is a perfect power then so is $j+i$. Equivalently we see that $a_{ij}=a_{ji}$. In particular $A(n)^t=A(n)$ and so $A(n)$ is symmetric. Now observe that $(a_{ij})^2=a_{ij}$. Since $A(n)$ is symmetric $A(n)^tA(n)=A(n)^2$. The following result is easy to show $$\sum_{i=1}^n \sum_{j=1}^n a_{ij}=tr(A(n)^2)$$ Similarly it easy to show that if ${1 \above 1.5 pt n^2}\sum_{i=1}^n \sum_{j=1}^n a_{ij}={1 \above 1.5 pt x}$ then $x$ is a divisor of $n$. Assume ${tr(A(n)^2) \above 1.5pt n^2}={1 \above 1.5pt 3}$ then $3$ divides $n$. We start by showing via inspection the base case of $n=3$ and $n=6$. Suppose $n=3$ then $$A(3)^2= \text{ }
\begin{pmatrix}
1&0&0\\
0&1&0\\
0&0&1\\
\end{pmatrix}$$ And so $tr(A(3)^2)=3$. Surely ${3 \above 1.5pt 3^2}={1 \above 1.5 pt 3}$. Similarly it is easy to compute and show that if $n=6$ $$A(6)^2= \text{ }\begin{pmatrix}
1&0&0&0&1&1\\
0&2&1&0&0&1\\
0&1&3&1&0&0\\
0&0&1&2&1&0\\
1&0&0&1&2&1\\
1&1&0&0&1&2\\
\end{pmatrix}
$$ And from this we can see that $tr(A(6)^2)=12$. And again we have that ${12 \above 1.5pt 6^2}={1 \above 1.5 pt 3}$. Assume $n\neq 3$ and $n\neq 6$. Now since ${tr(A(n)^2) \above 1.5pt n^2}={1 \above 1.5pt 3}$ we know that $3\times tr(A(n)^2)=n^2$. If $a_{ii}$ is any entry on the diagonal of $A(n)^2$ then explictly $3(a_{11}+ \ldots +a_{nn})=n^2$ so $\sqrt{3}\sqrt{a_{11}+\ldots + a_{nn}}=n$ and consequently $\sqrt{3} \mid \sqrt{a_{11}+\ldots + a_{nn}}$ otherwise $n$ is not an integer which is a contradiction. ^Update 1: The argument scratched out above is wrong thanks to commentator @SEWillB. 
^Update 2: The argument previously scratched out above is correct. See edits. That is all I can come up with - and it might not be the best approach and possibly the problem is trivial and I am just missing it. It could also be wrong. The picture below provides some data for small values of $n$.","['matrices', 'analytic-number-theory', 'perfect-powers', 'conjectures']"
2296281,Why is $\sqrt{2}$ not in the ring of integers of $\mathbb{Q}$?,"Sorry if this is too obvious but I can't see what I'm missing. If an element $b\in B$ is the root of a polynomial $f\in A[X]$, then $b$ is integral over $B$. $\sqrt{2}$ is a root of $f(X) = X^2 -2$, so why is the integral closure of $\mathbb{Z}$ in $\mathbb{Q}$ equal to $\mathbb{Z}$? I know I must be misreading a definition but I can't see where, if anyone could point out what I'm missing that would be great.","['number-theory', 'ring-theory', 'algebraic-number-theory']"
2296312,Proving derivative of a function is a linear isomorphism on some subset of the domain,"Suppose $f:U\subseteq\mathbb{R^n}\to\mathbb{R^n}$ is of class $C^1$ and for some $a\in U$ , $Df(a)$ is a linear isomorphism. Prove there exists a $V\subseteq U$ such that it contains $a$ and also for all $p\in V$ , $Df(p)$ is a linear isomorphism. I know it has something to do with the inverse function theorem, but I can not figure out a way to prove it.","['multivariable-calculus', 'partial-derivative', 'inverse-function', 'vector-space-isomorphism']"
2296336,Can every curve be subdivided equichordally?,"This question build on top of this other question: Dividing a curve into chords of equal length , for which I wrote an (incomplete) answer . I got the feeling we might need some help from a real topologist . Let me repeat the crucial definitions. We are dealing with curves $c:[0,1]\to\Bbb R^m$ which are assumed to be continuous maps. Definition. Given a curve $c:[a,b]\to\Bbb R^m$ and $n\in\Bbb N$, an equichordal subdivision of $c$ into $n$ segments is a sequence $t_i,i=0,...,n$ with
  $$a=t_0\leq t_1\leq\cdots\leq t_{n-1}\leq t_n=b, \qquad \|c(t_{i-1})-c(t_i)\|=\Delta,\quad \text{for all $i=1,...,n$}$$
  and some chord length $\Delta$. Essentially this means we are looking for $n+1$ points on a curve (including the end points) so that neighboring points all have the same Euclidean distance $\Delta$ from each other. Now the big question is: Question: Is it always possible for arbitrary curves $c$ and $n\in\Bbb N$ to equichordally subdivide $c$ into $n$ segments? It seems not so strange to assume that this might be. However, look at the following examples for $n=3$. The subdivision might not at all follow the shape of the curve or will look similar to a subdivision with equal arc lengths (for small $n$). Most of the time, for a given $n$ the final chord length $\Delta$ is pretty unpredictable. Further information for the interested reader: In one of my answers I gave a proof that felt good at first, but I cited a result incompletely. I used this statement despite some answer below gave a nice counter-example. Currently I have no idea how to justify that this is no problem. I also think that my proof might be too complicated, even though it proves a more general statement (the existence of a continuous transition from a trivial subdivision to a subdivision of the whole curve). In this answer Rahul gave a proof for the cases $n=2$ and $n=3$. He (and now me too) got the feeling that this might be generalizable by someone with enough experience in topology (homotopy maybe?). I really prefer Rahul's approach for its simplicity. He even posted a follow up question on it over here . As far as I know, there is no easy way to find such a subdivision. For sufficiently well behaved curves it might be possible to just choose some reasonable subdivision and wiggling the points a bit to bring them into the right spot for equichordality. However, this will fail in general. Also, given an equichordal subdivision of some subcurve of $c$, it is highly non-trivial to ""stretch"" it out to cover the whole curve while still keeping the desired property. I found counterexamples for most easy approaches. For example, test your procedure on the examples given above. I have not studied any possible counter-examples in higher dimensions. I only looked at plane curves so far. I have no clue what might hide over there.","['geometric-topology', 'general-topology', 'curves', 'geometry']"
2296340,Didactic examples in linear ordinary differential equations,"I believe it is very common among beginners in differential equations to feel like this field is absolutely chaotic and that there is little to no theory and only techniques which may be applicable only in some rare cases. Recently however I have come to believe that for the case of linear ordinary differential equations one can do much better than just a a bag of tools. What are the most simple instructive examples in the theory of linear
  ordinary differential equations? I use ""instructive"" in the sense that they contain an instance of a general qualitative phenomenon which occurs in many different equations. For instance here is a very partial list I made for myself. All will be of the form $Ly=0$ and so i will only specify $L$. The fractional monomial $L=x \partial + c$  - regular singularities at 0 and infinity. If $c \ne 0,1$ solutions have branch points. If $c \notin \mathbb{Q}$ solution is transcendental. The exponentiated monomial $L = x^{n}\partial + c, n \in \mathbb{Z} \text{\\}\{1\} $  - Irregular singularity at zero/infinity. The Legendre equation $L=(1-x^2)\partial^2 -2x\partial+c$ - Regualr singularities at $-1,1, \infty$. One solution will be entire, the other will have singularities at $-1,+1,\infty$, non trivial monodromy representation. The Airy equation $L=\partial^2 - x$ - Irregular singularity at $\infty$, stokes phenomenon, trivial monodromy. The Bessel equation $L=\partial^2+x^{-1}\partial +(1-n^2x^{-2})$ - regular singularity at $0$ and irregular singularity at $\infty$. Stokes phenomenon and non-trivial monodromy. I'm sure the above partial list is very naive and elementary i think a a list like this written by a specialist could be of a lot of help to anyone willing to put some effort in studying said examples.",['ordinary-differential-equations']
2296374,How to express complex multiplication with a linear operator on $\mathbb R^n$?,"I've recently been trying to find analogues between linear algebra ideas on $\mathbb R^2$ and $\mathbb C$, such as how the function $\textrm{Re}$ on $\mathbb C$ is equivalent to the linear operator given by the projection matrix $\begin{bmatrix}1 & 0 \\ 0 & 0\end{bmatrix}$ on $\mathbb R^2$. I now want to do the same thing with complex multiplication. One constraint is that I really want to find a matrix that gives complex multiplication that is not a function of one of the arguments. With the cross-product, for example, we can write $u \times v = Av$ but $A$ depends on $u$. I want to find a linear operator $A$ that encodes complex multiplication independent of the arguments, just like the projection matrix for $\textrm{Re}$. At first I was seeking a linear operator $A : \mathbb R^2 \times \mathbb R^2 \to \mathbb R^2$, but I don't know to do this with a matrix. The only things I can think of are $Av$ or $u^T A v$ but the first has the wrong domain and the second has the wrong codomain. My next idea was to consider $A: \mathbb R^4 \to \mathbb R^2$ so essentially I'd just stack the two, but this would require having $ac-bd = r_1a + r_2b + r_3c + r_4d$ which is impossible with my goal of fixed $r_i$ independent of the arguments. Am I wrong about this being linear? I know it's at least bilinear, but did I make a mistake here? To summarize all of this, I want to see if there's a way to represent complex multiplication using a fixed matrix $A$ between real-valued vector spaces.","['matrices', 'vectors', 'linear-algebra', 'complex-numbers']"
2296377,Solution by radicals of $(1+x)^n=x^m$,"Given the equation $$(1+x)^n=x^m$$ where $m$ and $n$ are two different natural numbers, I was trying to find as many solution as possible expressing them without transcendent functions. WLOG we can suppose $n<m$ and coprime, in this case by the Abel–Ruffini theorem we know we can find a closed form solution for $m<4$. So I found solutions for $(n,m) \in \{(1,2),(1,3),(1,4),(3,4)\}$ Indeed, by playing with the numbers, I noticed that also $(1+x)^4=x^5$ has closed form solutions as the equation is divisible by $x^2+x+1$. How can I find other solutions violating Abel-Ruffini?",['algebra-precalculus']
2296393,limit $\lim_{n\to\infty}\frac{1}{\sqrt n}\left(\frac{1}{\sqrt 2+\sqrt4}+\frac{1}{\sqrt4+\sqrt6}+\cdots+\frac{1}{\sqrt{2n}+\sqrt{2n+2}}\right)$,"$$\lim_{n\to\infty}\frac{1}{\sqrt n}\left(\frac{1}{\sqrt 2+\sqrt4}+\frac{1}{\sqrt4+\sqrt6}+\cdots+\frac{1}{\sqrt{2n} +\sqrt{2n+2}}\right)$$ To find the limit I think I can use the sandwich theorem: if $f,g$ and $h$ are real functions such that $f(x)\le g(x) \le h(x)$ for all $x$ and if $\lim_{x\to 0} f(x)=L= \lim_{x\to 0} h(x)$, then $\lim_{x\to 0} g(x)= L$. I don't know that which series I can take for $f(x)$ and $h(x)$ to compare with $g(x)$.","['sequences-and-series', 'calculus', 'limits']"
2296544,Special Fibonacci sequence,"Let $\{F_n\}, n\in \mathbb{N}$ be the sequence of Fibonacci numbers such that $F_1=1$, $F_2=1$ and $F_n=F_{n-1}+F_{n-2}$ $\forall n\geq2$. Define a new sequence $\{S_n\}$ such that $S_n=F_n+1$ $\forall n\in \mathbb{N}$. Now the question is: For every prime $p$, does there exist an $N\in  \mathbb{N}$, such that $p|S_N$ ?","['number-theory', 'fibonacci-numbers', 'prime-numbers']"
2296587,"For primes sufficiently large, must digit products be zero?","Let $\{P_n\}, n\in \mathbb{N}$ be the sequence prime numbers such that $P_1=2, P_2=3\dots$. Define a new sequence $\{M_n\}$,  $n\in \mathbb{N}$, such that $M_n=$Product of the digits of the $nth$ prime in its decimal representation. Now the question is: Does there exist an $N\in  \mathbb{N}$, such that $M_n=0$ $  \forall n\geq N$ ?","['number-theory', 'analytic-number-theory', 'prime-numbers']"
2296619,Is it always true that operator norm assume supremum in definition?,"Suppose that $X, Y$ are  normed vector spaces. 
Let $T: X \longrightarrow Y$ be linear operator.
We define $\Vert T \Vert := \sup\{\Vert Tx \Vert : x \in X, \ \Vert x \Vert = 1\}$. Is it always true for $\Vert T \Vert$ to assume (reach) supremum? If not are there any examples?","['functional-analysis', 'operator-theory']"
2296622,Does every positive ray intersect a deformed simplex? A topological conjecture.,"This question is motivated by my partial answer to a different question . I will use $\mathbb R_+$ to denote the set of nonnegative reals. Consider the standard simplex $\Delta^n=\{(x_0,\dots,x_n)\in\mathbb R_+^{n+1}:x_0+\dots+x_n=1\}.$ We are given a continuous function $f:\Delta^n\to\mathbb R_+^{n+1}$ with the property that it preserves zero coordinates, that is, if $x_i=0$ then $f(x)_i=0.$ Thus vertices of the simplex map to points on the coordinate axes, $1$-faces (edges) map to curves on the coordinate $2$-planes, and so on. I believe the following conjecture is true, but I don't know how to prove it for arbitrary $n$: Conjecture: For any $y\in\mathbb R_+^{n+1}$, there exists a point $x\in\Delta^n$ such that $f(x)=ay$ for some scalar $a\in\mathbb R_+$. Geometrically, every ray from the origin lying in $\mathbb R_+^{n+1}$ must intersect the surface $S = f(\Delta^n)$. Here are some examples with $n=1,y=(1,1)$ and $n=2,y=(1,1,1)$ respectively: These examples suggest that when $y\in\operatorname{int}\mathbb R_+^{n+1}$, the boundary $\partial S=f(\partial\Delta^n)$ ""surrounds"" the line $\{ay:a\in\mathbb R\}$, so the surface $S$ must intersect the line. Thus I feel the conjecture is essentially topological in nature and should have a natural proof based on something like homotopy theory. Unfortunately, I don't know any homotopy theory.","['geometric-topology', 'general-topology', 'simplex']"
2296639,Is the empty set (or any analogy) ever non-unique?,"I seems SO obvious that the empty set is unique, and yet every lecture on set theory and topology feels the need to state the proof. Why is that? Usually if something seems completely obvious, but the lecturer still presents the proof, it is a tell-tail sign, that one is studying the special case without knowing, and the property isn't true in the general case.",['elementary-set-theory']
2296646,Why is $\lim_{x \to 0}\frac{\sin^{-1}x}{x} = \lim_{x \to 0}\frac{1/\sqrt{1-x^2}}{1}$?,"I'm a beginner in Calculus and I'm studying L'Hospital's Rule. I have to calculate the following limit: $$\lim_{x \to 0}\frac{\sin^{-1}x}{x}$$. My solutions manual presents the following equation: $$\lim_{x \to 0}\frac{\sin^{-1}x}{x} = \lim_{x \to 0}\frac{1/\sqrt{1-x^2}}{1}$$ While applying L'Hospital's Rule, I understand that the derivative of $x$ is $1$, but I can't figure out why the derivative of $1/\sin x$ would be $1/\sqrt{1-x^2}$. I would rather think this should be the result. Any explanations for this?","['derivatives', 'calculus', 'limits']"
2296656,Calculate $\lim_{n \to \infty} n(1+\sin(n))$,I think it doesn't exists but I can't find out how to prove it; note that $n$ is integer. I know that there are infinite many integers $a_n$ s.t. $\sin(a_n)>0$ and then limsup is $+ \infty$. I want to prove that liminf $\ne +\infty$ but I don't know how.,"['real-analysis', 'calculus']"
2296662,Is the definition of fpqc topology in SGA 4.5 different from usual?,"I am confused about Theorem 1.4.5, Example 1.6.4(b) in SGA 4.5, because here a covering of $U$ is a finite family $\{U_i\to U\}$ of flat morphisms such that $\coprod
U_i\to U$ is surjective $\qquad$ (1) . But in the definition of fpqc topology everywhere else, a covering of $U$ is a (not necessary finite) family $\{U_i\to U\}$ of flat morphisms such
  that $\coprod U_i\to U$ is fpqc $\quad$(2) where fpqc means faithfully flat and every affine open of $U$ is the image of a quasicompact open of $\coprod U_i$. I believe that definition (1) allows too many coverings, and I don't see a way to prove Theorem 1.4.5 using definition (1) (in the proof Deligne says we can formally reduce to affine case, but definition (1) is not good enough to do so).","['etale-cohomology', 'algebraic-geometry', 'descent']"
2296714,Prove that $g^{-1}hg$ is contained in set of injections with finite non-identities of a set onto itself,"I'm struggling with a proof for a problem from Herstein's Abstract Algebra text. I'm very new to proof writing, so please bear with me. The problem is the following: Let $S$ be an infinite set and let $M \subset A(S)$ (where $A(S)$ is the set of all 1-1 mappings of $S$ onto itself) be the set of all elements
$f \in A(S)$ such that $f(s) \not= s$ for at most a finite number of $s \in S$. If $g \in A(S)$, prove that $g^{-1}Mg =  \{ g^{-1}hg \mid h \in M \}$ must equal $M$. In order to prove this, I need to show both that $g^{-1}Mg \subseteq M$ (that is, if $h \in M$, $g^{-1}hg \in M$) and that $M \subseteq g^{-1}Mg$. My attempt at showing that $g^{-1}Mg \subseteq M$ is the following: Suppose that $h \in M$ moves only elements $s_1,s_2,...,s_m$, leaving the other elements of $S$ fixed. This means that for some element $s \not\in s_1,s_2,...s_m$, $h(s) = s$. Since $g \in A(S)$, we know that if $g(s_1) = s_2$, there exists some $g^{-1}$ such that $g^{-1}(s_2) = s_1$. Therefore, for all $g(s) \not\in s_1,s_2,...,s_m$, then $(g^{-1}hg)(s) = s$, meaning there is a finite number of $(g^{-1}hg)(s) \not = s$, so $g^{-1}hg \in M$. The part I've really been struggling with is showing that  $M \subseteq g^{-1}Mg$. I assume that I need to show that for some $h \in M$, $h \subseteq g^{-1}hg$, but I don't know how to go about doing this. I thought I could possibly show this by proving any $(s_1, s_2) \in h$ is also in $g^{-1}hg$, but it seems like my approach isn't working. It seems to me that $(g^{-1}hg)(s)$ could first transform $s$ to one of two places: either to an element such that $g(s) \in s_1,s_2,...s_m$, or to an element such that $g(s) \not\in s_1,s_2,...s_m$. If $g(s) \not\in s_1,s_2,...s_m$, then $h(g(s)) = g(s)$ and $g^{-1}(h(g(s))) = g^{-1}(g(s)) = s$. However, since we only know that $g(s) \not\in s_1,s_2,...,s_m$, we can't say that $s \not\in s_1,s_2,...,s_m$, so it's possible that $h(s) \not= s$, which doesn't seem to help me. How can I prove this set equivalence?","['elementary-set-theory', 'proof-writing', 'functions']"
2296719,"Redefining $f(x,y) = x \cdot y \cdot \sin(1/x)\cdot \sin(1/y)$","I'm analysing this function from my calculus class: $$f(x,y) = x \cdot y \cdot \sin(1/x)\cdot \sin(1/y)$$ I want to know if it's possible to redefine this function to all of $\Bbb R^2$ so it's continuous. Will it suffice to make it equal to 0 along both axis?","['multivariable-calculus', 'analytic-continuation', 'continuity', 'limits']"
2296734,Probability that the density is equal to 0,"Let $X$ be a continuous random variable taking values in $\mathbb{R}$, with density $f$ . Prove that $P(f(X)=0)=0$ . Can anyone give me a hint?","['probability', 'measure-theory']"
2296744,Natural conditions implying the union of closed sets is closed,"There is the nice theorem that the union of a locally finite collection of closed sets is closed. Are there known any other natural conditions on a collection of closed sets which imply this? There are collections of closed sets with closed unions which are not themselves locally finite. For example, take the singleton subsets of $\mathbb{R}$. Therefore ""locally finite"" cannot be the best possible condition in the sense that any other condition implying the closed union condition implies it.",['general-topology']
2296757,Conjectures on Twin Euler Bricks,"After this answer euler bricks: way to calculate them? and this question Cuboid nearest to a cube I had some three hundred primitive Euler Brick solutions, complete with their Twin solutions (see below), and wanted to sort them into some logical order. The equations, with $x,y,z$ as the edges and $u,v,w$ as the face diagonals, are:
$$x^2+y^2=u^2$$
$$y^2+z^2=v^2$$
$$x^2+z^2=w^2$$ I used the (IMHO) well known method: “If $(x,y,z)$ is a solution, then (xy,xz,yz) is also a solution, but applying this to the new solution returns to the original shape.” I don’t know when or where this method of producing Twins originated, or if it has been proven, but it works for every example I’ve tried. However, the calculations soon increase in magnitude. Conjecture 1 If $(x_0,y_0,z_0)$ is a primitive Euler Brick solution then the following is also a solution, $$(X_1,Y_1,Z_1)=(\frac{x_0y_0}{12},\frac{x_0z_0}{12},\frac{y_0z_0}{12})$$ Put $G_1=gcd(X_1,Y_1,Z_1)$ then a new primitive Euler Brick solution is given by, $$(x_1,y_1,z_1)=(\frac{X_1}{G_1},\frac{Y_1}{G_1},\frac{Z_1}{G_1})$$ Now repeat using $(x_1,y_1,z_1)$ as the generator, $$(X_2,Y_2,Z_2)=(\frac{x_1y_1}{12},\frac{x_1z_1}{12},\frac{y_1z_1}{12})$$ Put $G_2=gcd(X_2,Y_2,Z_2)$ to produce, $$(x_2,y_2,z_2)=(\frac{X_2}{G_2},\frac{Y_2}{G_2},\frac{Z_2}{G_2})$$ If all went well, $x_2=x_0$, $y_2=y_0$ and $y_2=y_0$ Definition If $\frac{G_1}{G_2}<1$ then $(x_1,y_1,z_1)$ is the Good twin and $(x_2,y_2,z_2)$ is the Evil Twin. If $\frac{G_1}{G_2}>1$ then $(x_1,y_1,z_1)$ is the Evil Twin and $(x_2,y_2,z_2)$ is the Good Twin. Example $$(x_0,y_0,z_0)=(117,44,240)$$
$$(X_1,Y_1,Z_1)=(429,2340,880)$$
$$G_1=gcd(429,2340,880)=1$$
$$(x_1,y_1,z_1)=(429,2340,880)$$
$$(X_2,Y_2,Z_2)=(83655,31460,171600)$$
$$G_2=gcd(83655,31460,171600)=715$$
$$(x_2,y_2,z_2)=(117,44,240)$$ Hence, as $\frac{G_1}{G_2}=\frac{1}{715}$, we find $(117,44,240)$ is the Good Twin and $(429,2340,880)$ is the Evil Twin. The product $G_1G_2=715$, whichever Twin we start from, and is the lowest I’ve found. Conjecture 2 The value of $G_1G_2$ is equal for each of a pair of twins. Conjecture 3 Except for twins, the value of $G_1G_2$ is unique for primitive solutions. Conjecture 4 There are no Identical Twins, where the original solution is returned as $(x_1,y_1,z_1)$ in any order.
The nearest I’ve found is $(72611,9180,206448)$ and its Evil Twin $(12915,290444,36720)$ My questions I would welcome any help proving or disproving any of these conjectures.
Also, if there is an easier way to identify Twins, I’d love to know about it. Please let me know if I’ve failed to make anything clear. Update 26 May 2017 I generated $82$ solutions using Saunderson’s  parametric formula, http://mathworld.wolfram.com/EulerBrick.html and found they were all Good Twins . I would appreciate any other Euler Brick parametric formula.","['diophantine-equations', 'elementary-number-theory', 'pythagorean-triples', 'geometry']"
2296793,Can the product of 4 distinct numbers be equal to a fourth power?,"The set $M$ consists of 2001 distinct positive integers, none of which is divisible by any prime $p > 23$. Prove that there are distinct $x, y, z, t \in M$ such that $xyzt = u^4$ for some integer $u$. I guess some kinda Pigeonhole Principle argument should be useful, but I can't figure it out.","['number-theory', 'combinatorics', 'pigeonhole-principle']"
2296794,Examples of proper loops in $\mathbb{R}$,"A loop $(L, \cdot)$ is a binary structure that satisfies every group axiom except for the associative property. A loop which is not a group is called a proper loop . A topological loop $(L,\cdot)$ is a topological space which is also a loop such that   ""$\cdot$"" and the inverse operations are continuous. In the literature there are many examples of finite proper loops, but I couldn't find any example on $\mathbb{R}$. So my question is What are some examples of proper topological loop structures on $\mathbb{R}$? The operations here need to be continuous with respect to the usual topology of $\mathbb{R}$.  If the loop  happens to be commutative, even better. I am just trying to picture them, because a continuous group structure  in $\mathbb{R}$ is, basically, just the addition and there is nothing counterintuitive about it. However, for continuous loops defined on $\mathbb{R}$ there is a very deep theory behind their classification, so examples of them could be very enlightening. Edit No2: As Eric noticed some of the efforts made towards the classification of continuous loops may provide us with examples. Here is a collection of the most relevant results, which were found in Chapter 18 of the book ""Loops in Group and Lie Theory"" , by Nagy and Strambach. (Thm. 18.18) A topological loop   on $\mathbb{R}$ is a proper loop if and only if the group $G$ generated by its translations is not locally compact ($G$ is equipped with the Arens topology). (by Hoffman, pg. 243) A monassociative (a special type of loop) loop on $\mathbb{R}$ is either a Lie group, or the union
of two one-parameter semigroups meeting in the unit $e$, each being isomorphic to the semigroup of positive real numbers with respect to the addition. The first one is impressive, but difficult for me to work with. The second one is very promising to provide an example. So $L=A\cup B$, $A\cap B=\{e\}$ and each component is just the $[0,\infty)$. What boggles me here is that is that we don't seem to know enough to be able to reconstruct the operation ""$\cdot$"" on $L=A\cup B$ from the available data. For $x, y\in A$, we know what $x\cdot y$ is equal to, it's just $f(x)+f(y)$ where $f:(A, \cdot) \rightarrow [0,\infty)$ is our isomorphism. Similarly, for $x, y\in B$.   But for pairs $(a,b)$ such that $a\in A$ and $b\in B$, what can we tell for their product $a\cdot b$?","['quasigroups', 'abstract-algebra', 'grouplike-elements', 'examples-counterexamples']"
2296804,$L^p$ implies polynomial decay?,"Suppose $f$ is uniformly continuous on $\mathbb{R}^n$. Question: If $f \in L^p(\mathbb{R}^n)$, must there exist a $q > 0$ such that $|f(x)| \leq C|x|^{-q}$ for all large x (or perhaps a.e. large x)? I know $f \in L^p(\mathbb{R}^n)$ implies $f(x) \to 0$ as $|x| \to \infty$. And I know $|f(x)| \leq C|x|^{-q}$ implies $f \in L^p(\mathbb{R}^n)$ when $pq > n$. Remark: One could ask a similar question about infinite series.","['real-analysis', 'measure-theory', 'analysis']"
2296854,Two individuals are walking around a cylindrical tower. What is the probability that they can see each other?,"It'd be of the greatest interest to have not only a rigorous solution, but also an intuitive insight onto this simple yet very difficult problem: Let there exist some tower which has the shape of a cylinder and whose
  radius is A. Further, let this tower be surrounded by a walking lane
  whose width is B. Now, there are two individuals who are on the walk;
  what is the probability that they're able to see each other?","['plane-geometry', 'geometric-probability', 'calculus', 'solid-geometry', 'probability']"
2296865,"If $f:A \rightarrow B$ and $f^{-1}$ is a function, then f is 1-1.","Just verifying if this proof is valid. Claim: If $f:A \rightarrow B$ and $f^{-1}$ is  a function, then $f$ is $1-1$. Proof: Suppose $f(a)=f(z)$ where $a,z\in A$. This implies that $(a,b)\in f$ and $(z,b)\in f$, where $b\in B$ Which then implies that $(b,a)\in f^{-1}$ and $(b,z)\in f^{-1}$ Since $f^{-1}$ is a function, $a=z$ So, $f(a)=f(b) \implies a=z$ Therefore $f$ is $1-1$","['multivalued-functions', 'functions']"
2296878,Axiom of choice proof,"For the theorem, ""Let A and B be sets and let $f : A \rightarrow B$ be a function. Then $f : A \rightarrow B$ is $surjective$ $iff$ there exists a function $g : B \rightarrow A$ such that $f \circ g = I_B$.
"" The theorem implies Axiom of choice. I proved the statement, but I want to know whether my proof is right or not. Proof) Suppose the theorem.
Let A be a set and $Q_R$=$\text{{(R,r)|$r\in R$}}$ for all $R\in \mathscr P'(A)$ . Let $Q = \cup_{R\in\mathscr P'(A)} Q_R$. Let $f: Q \rightarrow \mathscr P'(A)$ where $(R,r) \mapsto R$.
Then, $\exists (R,r)\in Q$ for $\forall R \in \mathscr P'(A)$. So $f$ is surjective. By theorem, $\exists g: \mathscr P'(A) \rightarrow Q $ such that $f \circ g = I_B$. Then, $g(R) = (R,r)$ for some $ r\in R$. So, let $\gamma : \mathscr P'(A) \rightarrow A$ such that $\gamma(R) = r$ where $\gamma(R) \in R$ for all $R \in \mathscr P'(A).$
Hence, Axiom of choice holds.","['axiom-of-choice', 'elementary-set-theory', 'proof-verification']"
2296892,$f(n+1)=f(n)/2+1$; $f(1)=4$; general formula for $f(n)$,"As the question says, but note, as this is a sequence question (I am trying to find general formula for the sequence $4,3,2.25,...$) we assume that $n$ is greater than or equal to $1$. At first, I thought I could solve this as a geometric series but then saw the 'plus $1$' which sort of turned things on their head for me. Do you know of any ways to find the general formula? Thank you for any comments or answers.","['sequences-and-series', 'functions']"
2296929,Double integral; limits and variable exchange,"I am struggling to figure out the correct way of calculating certain integrals of this nature, i.e. more complicated limits and functions: $$\int_{x=0}^1 \left( \int_{y=\sqrt[3]{x}}^1 \frac{dy}{\sqrt{1+y^8}}\right) dx $$ Typically I'd try to re-write the limits and/or a variable change so it is easier to perform the integration. However, I am struggling and I can't seem to find any help in my textbook and class material. The idea I had would be to rewrite the limits to $ \; 0 \le x \le y^3 \; , \; 0 \le y \le 1 \;$ and first integrate $\; \int_{x=0}^{y^3}dx \;$ and then $ \int dy \;$, but I seem to get stuck on the next step. I.e when. $$ \int_{y=0}^1 \frac{([x]_0^{y^3})}{\sqrt{1+y^8}}dy = \int_{y=0}^1 \frac{y^3}{\sqrt{1+y^8}}dy $$ What would my next steps be and how? I would like to say that a variable exchange would be in order, e.g. $ u=y^4 \Rightarrow \frac{du}{dy}= 4y^3 \; $ but I can't figure it out. The answer in my book does not give any advice or guidance. This is my first post, so I do ask for your forgiveness if there is something wrong! Thank you,","['multivariable-calculus', 'integration']"
2296933,Fixed points of difference equations – stability/limits,"Suppose I have the difference equation $x_{n+1} = f(x_n)$. The point $x^{\ast}$ is called a fixed point of the equation if $x^{\ast}=f(x^{\ast})$. The fixed point is stable if $\,\left\lvert\, f'(x^{\ast})\right\rvert < 1$ and unstable if $\,\left\lvert\, f'(x^{\ast})\right\rvert > 1$. This is all from my differential equations notes. But could someone give a proof of these or explain why they are true? Thanks.","['stability-in-odes', 'real-analysis', 'ordinary-differential-equations']"
2296949,"How to prove that $\lim_{(x,y)\to(0,0)} \frac{\sin(xy)}{|x-y|}$ does not exist?","I want to prove this $\lim_{(x,y)\to(0,0)} \frac{\sin(xy)}{|x-y|}$ does not exist. For my calculus class. I know that I have to show that there at least two paths that lead me to different limits but I can't come up with them... Thanks","['multivariable-calculus', 'limits', 'calculus', 'analysis']"
2296953,"Construct a continuous function $f: (0, 1) \rightarrow \mathbb R$ but is not differentiable at any point of $\{\frac{1}{1+n}: n \in\mathbb N\}$","I can construct many function continuous in this interval . I have to choose one function that is not differentiable in $(0,1)$ because all point of $\{\frac{1}{1+n}: n \in\mathbb N\}$ is in the interval $(0,1)$,but i don't know that function choose that  is not differentiable,moreover I don't know like prove that one function is not differentiable, with the definition or have to use other theorem?","['derivatives', 'real-analysis', 'continuity']"
2296956,"If $H$ is a subgroup of $G$ having finite index, then $H$ contains a normal subgroup of $G$ of finite index [duplicate]","This question already has answers here : For $G$ group and $H$ subgroup of finite index, prove that $N \subset H$ normal subgroup of $G$ of finite index exists (3 answers) Closed 7 years ago . I'm trying to show that any subgroup $H$ of a group $G$ having finite index must contain a normal subgroup of $G$ of finite index. I tried to define a homomorphism $\psi:G/H \to G/H$ given by $\psi(xH) =gxH$ and prove that $\ker(\psi)\subset H$. Is there another way to solve this problem?","['abstract-algebra', 'group-theory']"
2297021,Understanding the proof of convergence criterion for infinite products via the relation of series?,"In the text ""Functions of one Complex Variable"" I'm having trouble understanding the proof for convergence criteria of an infinite product via it's relation to infinite series as seen in Corollary $(8.1.4)$ $Corollary \, (8.1.3)$: If $a_{j} \in \mathbb{C}$, $|a_{j}| < 1$ then the partial product $P_{n}$ for 
$$\prod_{j=1}^{\infty} (1+|a_{j}|)$$ satisfies:
 $$\exp(\frac{1}{2}\sum_{}^{}|a_{j}|) \leq P_{n}\leq \exp(\sum_{}^{}|a_{j}|). $$ $Corollary \, (8.1.4)$ If: $$\sum_{}^{}|a_{j}| < \infty$$ then: $$\prod_{j=1}^{\infty} (1+|a_{j}|)$$ converges. I observed that the author directly applied the previous result in Corollary $(8.1.3)$ directly to $(8.1.4)$. This initially begins by allowing the series in $(9.1)$ to exist $(9.1)$
$$\sum_{}^{}|a_{j}| = M$$
Initially from $(9.1)$ applying the following observations can be made: $$\sum_{}^{}|a_{j}| = a_{1}+a_{2}+a_{3}+a_{4}+a_{5}+a_{6}+ \cdot \cdot \cdot + a_{n}=M$$. Now the partial product for $a_{j}$ can be defined as follows:
$$\prod_{j=1}^{\infty} (1+|M|)$$ Our product satisfies the following inequality sated below: $$\exp(\frac{1}{2}\sum_{}^{}|M|) \leq P_{n}\leq \exp(\sum_{}^{}|M|)$$. The final result which the concludes the proof is the following: $$P_{n} \leq \exp M$$ In summary my question is how did the inequality in Corollary $(8.1.4)$ was used to show that our infinite product converges, I'm missing any small but fundamental observations.","['complex-analysis', 'infinite-product', 'proof-explanation']"
2297035,Determinant inequality about Toeplitz matrix,"Given, Toeplitz matrix $T \in R^{n \times n}$ : $$
        T=
        \begin{bmatrix}
        \tau_0 & \tau_1 & \cdots & \tau_{n-1} \\
        \tau_1 & \tau_0 & \ddots & \vdots \\
        \vdots & \ddots & \ddots & \tau_1 \\
        \tau_{n-1} & \cdots & \tau_1 & \tau_0 \\
        \end{bmatrix}
$$ and denoted the $k$ -th order leading principal submatrix of $T$ by $T_k$ . If $T$ is a positive definite matrix, how to prove the following inequality: $$
        \det T_{k+1} \le \frac{(\det T_k)^2}{\det T_{k-1}}
$$ ,where $\forall k \in \{1, \cdots, n\}$ . And, when the equality is attained?","['inequality', 'matrices', 'toeplitz-matrices', 'determinant', 'linear-algebra']"
2297047,Compute $\sum\limits_{n=1}^\infty\frac{b_{n-1}}{n 2^n}$ where $b_n=\sum\limits_{k=0}^n\frac{2^k}{k+1}$,"Define the sequence $a_n := \frac{2^n}{n+1}$. Then, define the sequence $b_n$, the partial sums of $a_n$; i.e.:
$$b_n=\sum_{k=0}^{n} {a_k}$$
The problem is to compute:
$$\sum_{n=1}^{\infty} {\left(\frac{b_{n-1}}{n 2^n}\right)}$$ This is very difficult to estimate using a computer algebra system. On Maple, I cannot complete an estimate of $100000$ terms under a minute. (However, the sum of the first $1000$ terms is approximately $1.23270055$.) I am wondering whether the double sum can be converted into a series convolution of some sort; the possibility of getting a $2^{n-m}$ term seems to help that prospect. Thanks!","['summation', 'sequences-and-series']"
2297050,Finding rotation of 3 given lines in 3D until intersection with 3 other given lines,"I already posted a similar question. but since the problem is still unanswered and the details are a bit changed, I'm posting it again. I'm trying to solve the following mathematical problem: Given 2 sets of 3 lines each in 3D space (where each line is given by a $3D$ point and a $3D$ vector):
$$
set1=\{ [(px1,py1,pz1), (vx1,vy1,vz1)], [(px2,py2,pz2),(vx2,vy2,vz2)],
[(px3,py3,pz3), (vx3,vy3,vz3)] \}
$$
$$
set2=\{ [(qx1,qy1,qz1), (ux1,uy1,uz1)], [(qx2,qy2,qz2),(ux2,uy2,uz2)],
 [(qx3,qy3,qz3), (ux3,uy3,uz3)] \}
$$ find the angles of rotation $x,y,z$ (in radians) such that: $$R=rotate\_x*rotate\_y*rotate\_z$$
$$
{rotate\_x} = \left( {\matrix{
   {1} & {0} & {0}  \cr 
   {0} & {cos(x)} & {-sin(x)}  \cr 
   {0} & {sin(x)} & {cos(x)}  \cr 
 } } \right)
$$
$$
{rotate\_y} = \left( {\matrix{
   {cos(y)} & {0} & {sin(y)}  \cr 
   {0} & {1} & {0}  \cr 
   {-sin(y)} & {0} & {cos(y)}  \cr 
 } } \right)
$$
$$
{rotate\_z} = \left( {\matrix{
   {cos(z)} & {-sin(z)} & {0}  \cr 
   {sin(z)} & {cos(z)} & {0}  \cr 
   {0} & {0} & {1}  \cr 
 } } \right)
$$ and if we rotate $set1$ by $R$ then all the lines in $set1$ will intersect their corresponding lines in $set2$. Meaning, let's define $set1\_r$ as $set1$ after the above rotation. Then line $i$ $(i=1,2,3)$ in $set1\_r$ will intersect line $i$  in $set2$. I already built the 3 equations with 3 variables that needed to be solved. but they seem to be unsolvable. Here are the equations (only the angles $x,y,z$ are unknown and the rest are known): eq1 = qx1*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + qy1*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + ((ux1*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + uy1*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + uz1*cos(x)*cos(y))*(px1 - qz1*sin(y) - qx1*cos(y)*cos(z) + qy1*cos(y)*sin(z) + (vx1*(qx1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py1 + qy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz1*cos(y)*sin(x) + ((ux1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz1*cos(y)*sin(x))*(px1 - qz1*sin(y) - qx1*cos(y)*cos(z) + qy1*cos(y)*sin(z)))/(uz1*sin(y) + ux1*cos(y)*cos(z) - uy1*cos(y)*sin(z))))/(vy1 - (vx1*(ux1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz1*cos(y)*sin(x)))/(uz1*sin(y) + ux1*cos(y)*cos(z) - uy1*cos(y)*sin(z)))))/(uz1*sin(y) + ux1*cos(y)*cos(z) - uy1*cos(y)*sin(z)) + qz1*cos(x)*cos(y) == pz1 + (vz1*(qx1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py1 + qy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz1*cos(y)*sin(x) + ((ux1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz1*cos(y)*sin(x))*(px1 - qz1*sin(y) - qx1*cos(y)*cos(z) + qy1*cos(y)*sin(z)))/(uz1*sin(y) + ux1*cos(y)*cos(z) - uy1*cos(y)*sin(z))))/(vy1 - (vx1*(ux1*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy1*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz1*cos(y)*sin(x)))/(uz1*sin(y) + ux1*cos(y)*cos(z) - uy1*cos(y)*sin(z)))
eq2 = qx2*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + qy2*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + ((ux2*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + uy2*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + uz2*cos(x)*cos(y))*(px2 - qz2*sin(y) - qx2*cos(y)*cos(z) + qy2*cos(y)*sin(z) + (vx2*(qx2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py2 + qy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz2*cos(y)*sin(x) + ((ux2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz2*cos(y)*sin(x))*(px2 - qz2*sin(y) - qx2*cos(y)*cos(z) + qy2*cos(y)*sin(z)))/(uz2*sin(y) + ux2*cos(y)*cos(z) - uy2*cos(y)*sin(z))))/(vy2 - (vx2*(ux2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz2*cos(y)*sin(x)))/(uz2*sin(y) + ux2*cos(y)*cos(z) - uy2*cos(y)*sin(z)))))/(uz2*sin(y) + ux2*cos(y)*cos(z) - uy2*cos(y)*sin(z)) + qz2*cos(x)*cos(y) == pz2 + (vz2*(qx2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py2 + qy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz2*cos(y)*sin(x) + ((ux2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz2*cos(y)*sin(x))*(px2 - qz2*sin(y) - qx2*cos(y)*cos(z) + qy2*cos(y)*sin(z)))/(uz2*sin(y) + ux2*cos(y)*cos(z) - uy2*cos(y)*sin(z))))/(vy2 - (vx2*(ux2*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy2*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz2*cos(y)*sin(x)))/(uz2*sin(y) + ux2*cos(y)*cos(z) - uy2*cos(y)*sin(z)))
eq3 = qx3*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + qy3*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + ((ux3*(sin(x)*sin(z) - cos(x)*cos(z)*sin(y)) + uy3*(cos(z)*sin(x) + cos(x)*sin(y)*sin(z)) + uz3*cos(x)*cos(y))*(px3 - qz3*sin(y) - qx3*cos(y)*cos(z) + qy3*cos(y)*sin(z) + (vx3*(qx3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py3 + qy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz3*cos(y)*sin(x) + ((ux3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz3*cos(y)*sin(x))*(px3 - qz3*sin(y) - qx3*cos(y)*cos(z) + qy3*cos(y)*sin(z)))/(uz3*sin(y) + ux3*cos(y)*cos(z) - uy3*cos(y)*sin(z))))/(vy3 - (vx3*(ux3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz3*cos(y)*sin(x)))/(uz3*sin(y) + ux3*cos(y)*cos(z) - uy3*cos(y)*sin(z)))))/(uz3*sin(y) + ux3*cos(y)*cos(z) - uy3*cos(y)*sin(z)) + qz3*cos(x)*cos(y) == pz3 + (vz3*(qx3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) - py3 + qy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - qz3*cos(y)*sin(x) + ((ux3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz3*cos(y)*sin(x))*(px3 - qz3*sin(y) - qx3*cos(y)*cos(z) + qy3*cos(y)*sin(z)))/(uz3*sin(y) + ux3*cos(y)*cos(z) - uy3*cos(y)*sin(z))))/(vy3 - (vx3*(ux3*(cos(x)*sin(z) + cos(z)*sin(x)*sin(y)) + uy3*(cos(x)*cos(z) - sin(x)*sin(y)*sin(z)) - uz3*cos(y)*sin(x)))/(uz3*sin(y) + ux3*cos(y)*cos(z) - uy3*cos(y)*sin(z))) It can be seen that it's almost impossible (hopefully not impossible) to extract $x,y,z$ from the equations since there are many multiplications between $sin$ and $cos$ of the different angles. I couldn't solve it. and I also tried it in matlab using the 'solve' function but it didn't work. Can anyone suggest a solution for finding the angles $x,y,z$? or any other way of finding the matrix $R$? If it helps, here's a specific example of the 2 sets of lines in which I know the desired angles $x,y,z$ (there are probably many more triplets of angles that also solve the problem). %set1
px1=0;
py1=0;
pz1=-30;

px2=0;
py2=0;
pz2=-30;

px3=0; 
py3=0;
pz3=-30;

vx1 = -0.083717247687439; 
vy1 = -0.107930827800543; 
vz1 = 0.990627255252918;

vx2 = 0.076364294519742;
vy2 = 0.060269029165473; 
vz2 = 0.995256820446840;

vx3 = -0.081460429387834; 
vy3 = 0.105021268850622; 
vz3 = 0.991128009660183; 

%set2
qx1=0; 
qy1=0;
qz1=-30;

qx2=0; 
qy2=0;
qz2=-30;

qx3=0; 
qy3=0; 
qz3=-30;

ux1 = -0.079382581863774;
uy1 = -0.095259098236529; 
uz1 = 0.992282273297173;

ux2 = 0.079382581863774; 
uy2 = 0.095259098236529; 
uz2 = 0.992282273297173;

ux3 = -0.086165283952334; 
uy3 = 0.103398340742801; 
uz3 = 0.990900765451843; For the above example, for $x=0.5236$ ($x$ is 30 degrees), $y=0, z=0$, 
meaning, $$
{R} = \left( {\matrix{
   {1} & {0} & {0}  \cr 
   {0} & {0.866} & {-0.5}  \cr 
   {0} & {0.5} & {0.866}  \cr 
 } } \right)
$$ $line$ $i$ ($i=1,2,3$) in $set1$ will intersect $line$ $i$ in $set2$. Also, $x=0, y=0, z=0$ ($R$ is the identity matrix) is also a solution since all the $6$ lines already intersect at the point $(0,0,-30)$. And I'm sure there are many more solutions. But, of course I need the general solution. Hope anyone can solve it since I've been trying to solve it for weeks :(. Thanks","['rotations', 'matrices', 'calculus', 'geometry', 'linear-algebra']"
2297078,Two smooth bounded connected domains in $\Bbb R^d$ with the same boundary are identical,"Let $\Omega_1,\Omega_2\subset\Bbb R^d$ be two connected opens such that $\overline{\Omega_1}$ and $\overline{\Omega_2}$ are smooth bounded connected manifolds with boundary. Then I suspect that if $\partial\Omega_1=\partial\Omega_2$, then $\Omega_1=\Omega_2$, however, I don't see how to prove this. Is the correct to solution to put some normal vector field on the boundaries and use that?","['manifolds', 'real-analysis', 'differential-geometry']"
2297103,How to simplify the expression $m+n \cdot 2m - mn + 3n \cdot 4m -2$,"$$m+n \cdot 2m - mn + 3n \cdot 4m -2$$ I'm in grade nine and my exams are coming up and I'm struggling to learn all the things i need to, I have more of a grasp on the more advance concepts but the simple ones I keep forgetting, help?",['algebra-precalculus']
2297127,Minimize $\left(a+\frac1a\right)\left(a+\frac1b\right)$+$\left(b+\frac1b\right)\left(b+\frac1c\right)$+$\left(c+\frac1c\right)\left(c+\frac1a\right)$,"Question: Minimize $\left(a+\frac1a\right)\left(a+\frac1b\right)+\left(b+\frac1b\right)\left(b+\frac1c\right)+\left(c+\frac1c\right)\left(c+\frac1a\right)$
when $a+b=c+2$ and $a,b,c>0$. I tried to replace $c$ with $a+b-2$ but it didn't bring me anywhere..","['algebra-precalculus', 'contest-math', 'optimization']"
2297159,Minimisation of Energy Functional,"Suppose I have the energy functional given by $$\Pi(u) : = \frac{1}{2} \int_{\Omega} k\nabla u \cdot \nabla u dx - \int_{\Omega} fu dx + \int_{\partial \Omega} \sigma_0 u^2 ds,$$ where $f \in L^2(\Omega)$ and $\sigma_0 \in C^{\infty}(\partial \Omega)$ and $\partial \Omega$ denotes the boundary of $\Omega$. Also note that $\sigma_0 > 0$. How do I show this energy functional attains a minimum in $H^1(U)$? According to Evan's, we need to show that $\Pi(u)$ is coercive and convex, but I haven't had any luck.","['calculus-of-variations', 'analysis', 'partial-differential-equations']"
2297169,Is there a way to see this geometrically?,"In my answer to this question - Finding the no. of possible right angled triangle. - I derived this result: If a right triangle
has integer sides
$a, b, c$
and integer inradius $r$,
then all possible values
of $a$ and $b$
can be gotten in terms of $r$
as follows: For every possible divisor $d$
of $2r^2$,
$a = 2r+d$
and
$b = 2r+\dfrac{2r^2}{d}$.
These are exactly the solutions. From this, of course,
the number of solutions
depends only on
the prime factorization of $r$. My answer involved
some annoyingly complicated algebra. My question is
""is there a geometrical way
to show that the expressions
for $a$ and $b$ are true?"" (Added later) Another way to phrase this,
without mentioning divisibility: Take a rectangle of area $2r^2$.
Extend the sides by $2r$.
Then the inradius of the
resulting right triangle
is $r$.","['divisibility', 'pythagorean-triples', 'geometry']"
2297237,Is there an explicit description of $\mathbb{RP}^n$ in some $\mathbb{R}^m$?,"We can realize $\mathbb{RP}^1$ as $S^1 \subset \mathbb{R}^2$ defined by the set
$$
\{(x,y) \in \mathbb{R}^2 : x^2 + y^2 = 1 \}
$$
Does there exist a nice description of $\mathbb{RP}^n$ as a subset of $\mathbb{R}^m$ similar to the one for the $n=1$ case?","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2297246,Prove or disprove that a graph made by $n$ straight lines is Hamiltonian.,"Given $n$ lines, no two of which are parallel and no more than two intersect at the same point. Construct a graph with the intersection of lines as vertices and the line segments as edges. Prove or disprove that this graph is Hamiltonian. I checked this for many graphs of different sizes and in every case, I could find a Hamiltonian cycle. I know that for n lines, the number of vertices will be n(n-1)/2 and edges n(n-2). I have no clue how to use this information and how to proceed further.","['graph-theory', 'hamiltonian-path', 'discrete-mathematics']"
2297267,Examples of other Mills' constants,"Mills' constant is the well-known constant A such that the function $\lfloor A^{{3}^{n}} \rfloor$ gives primes for all natural numbers $n$, whose value is ~$1.306377883...$ It is also well-known that there is an infinity of functions $\lfloor A^{{r}^{n}} \rfloor$ that gives primes for all $n$, depending on the value of $r$. Are there any examples of such $\lfloor A^{{r}^{n}} \rfloor$ where $r \neq 3$? There seems to be very little information available on this subject.","['number-theory', 'constants', 'prime-numbers']"
2297275,$C^\infty_c (K)$ is separable for $K$ compact,"$C^\infty_c (K)$ is the space of smooth functions supported on $K$ a compact subset of $\mathbb{R}^d$. For simplicity assume $K$ is just a ball centered at the origin. This has the smooth topology in which convergence is uniform convergence of the functon and all derivatives. Note that convergence in the smooth topology of $C^\infty_c(K)$ is the same as uniform convergence of all derivatives. I'm trying to show this space is separable. I initially wanted to use polynomials with rational coefficients, as these are countable and dense in $C_c(K)$ with uniform topology. Then using the fundamental theorem of calculus, we can easily show that this set is also dense in the smooth topology. But the polynomials are not supported on $K$ so this fails. I was thinking about multiplying by a smooth function supported on $K$ that equals $1$ on most of $K$, but then I'm not sure if the fundamental theorem of calculus argument will still work. So what can I do?","['general-topology', 'real-analysis']"
2297300,How to calculate $\sum_{j=0}^\infty (-1)^j/(3j + 1)$,How do you calculate the value of $$\sum_{j=0}^\infty \frac{(-1)^j}{3j + 1} =  1-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+ \cdots $$ I know this series will converge .. but I don't know how to compute the limit.,"['summation', 'sequences-and-series']"
2297309,Laurent series and region of convergence of $\frac{z}{(z+2)(z+1)}$ at $z=-2$,"I am trying to find the Laurent series and region of convergence $\frac{z}{(z+2)(z+1)}$ at $z=-2$. I found that $$
\frac{z}{(z+2)(z+1)}=\frac{2}{z+2}+\sum^\infty_{n=0}(z+2)^n
$$ But I am confused because usually when I am asked to find the radius of convergence of Laurent series I just calculate the radius for the series but for the function above we have a series plus the term $\frac{2}{z+2}$ so do I just find the radius of convergence of the series and ignore the term $\frac{2}{z+2}$?","['laurent-series', 'ordinary-differential-equations', 'sequences-and-series']"
2297322,"Take the function $f(x)=8x+120$. Find a function $g(x)$ which contains the point $(0,0)$ and is asymptotic to $f(x)$.","Take the function $f(x)=8x+120$. Find a function $g(x)$ which contains the point $(0,0)$ and is asymptotic to $f(x)$ in the first quadrant. I'm not even sure what kind of function $g(x)$ would be. My thoughts are that: as $x$ approaches infinity $f(x)=g(x)$. Also at infinity: $g'(x)=8$. It's not quadratic as quadratics do not have asymptotes. Is it some kind of rotated logarithmic function?","['logarithms', 'functions', 'graphing-functions']"
2297331,"Different methods, different answers.","If $\int_{\pi/2}^\theta\sin x\,dx=\sin2\theta$, then the value of $\theta$ satisfying $0<\theta<\pi$, is (a) $3\pi/2$ (b) $\pi/6$ (c) $5\pi/6$ (d) $\pi/2$ Method 1: I apply Leibniz rule and differentiate both the sides with respect to $\theta$. No option seems to be correct. Method 2: I integrate the left hand side and get to a conclusion of option d). Now which method to follow?",['calculus']
2297424,Extending a distribution over samples to a distribution over functions,"A gaussian process is a distribution over a function space, which can be parametrized as \begin{align}
		x(\cdot) &\sim \mathrm{GP}(m(\cdot), K(\cdot,\cdot))\,.
	\end{align} For simplicity, let's choose $x\colon \mathbb{R}\to\mathbb{R}$.
We can write the probability density of a finite set of samples of $x$ as \begin{align}
		p(\{x(l) : l \in L\}; m, K)
			&\propto \exp{\left[
				-\frac{1}{2}
				\sum_{i\in L}
				\sum_{j\in L}
					\left(x(i) - m(i)\right)
					{K(i,j)}^{-1}
					\left(x(j) - m(j)\right)
			\right]}\,.
	\end{align} (Apologies for any notational misuse here). Can this be extended to the probability density for the infinite set $x(\cdot)$? Is it valid to write \begin{align}
		p(x(\cdot); m, K)
			&\propto \exp{\left[
				-\frac{1}{2}
				\sum_{i\in \mathbb{R}}
				\sum_{j\in \mathbb{R}}
					\left(x(i) - m(i)\right)
					{K(i,j)}^{-1}
					\left(x(j) - m(j)\right)
			\right]}\,.
	\end{align} It feels incorrect to me to sum over the reals rather than integrate, but I have little intuition in this area.","['functional-analysis', 'probability', 'notation']"
2297465,Find $\lim_{n\to\infty}\sin^4x+\frac{1}{4}\sin^42x+.....+\frac{1}{4^n}\sin^42^nx$,"$\lim_{n\to\infty}\sin^4x+\frac{1}{4}\sin^42x+.....+\frac{1}{4^n}\sin^42^nx$ I feel that this question will be solved by telescoping series but i cannot express it as telescoping series. $\sin^4x=(\frac{1-\cos2x}{2})^2=\frac{1+\cos^22x-2\cos2x}{4}$ I am not able to solve it further. The options are $(A)\sin^4x,(B)\sin^2x,(C)\cos^2x$(D)does not exist","['trigonometry', 'limits']"
2297470,Do all graphs have interval representations?,The interval representation of a graph is the idea of depicting graph as layers of sequences of intervals. Two intervals intersect iff there exist an edge in the initial graph between corresponding vertices. Example can be seen here. Do all graphs have interval representation?,"['graph-theory', 'discrete-mathematics']"
2297474,Representation of $e$ as a descending series,"I saw on Wikipedia: List of representations of e that $$e=3+\sum_{k=2}^{\infty}\frac{-1}{k!(k-1)k}$$ 
It was also mentioned that this identity come from consideration on ways to put upper bound of $e$. Can anyone give me a hint how we can derive this identity? I have tried to look at its Taylor expansion but that approach seems to fail miserably. Thanks in advance.","['exponential-function', 'sequences-and-series', 'approximation']"
2297482,Is there an unbiased estimator of the reciprocal of the slope in linear regression?,"I have a situation which can be handled well through a simple linear regression model. That is, I have data points with known x values, y values with a given amount of error, and an ideal fit of the form $y = \alpha + \beta x$. It's easily possible to get unbiased (but correlated) estimators for $\alpha$ and $\beta$ through linear regression, but I have a case where it would be useful to have an unbiased estimator of $\beta^{-1}$, and I haven't been able to figure out if this is possible. Some things I've tried which don't work: Using the inverse of the estimator, $\hat{\beta}^{-1}$. This can be shown through Taylor expansion to be biased. Eg. if $\beta > 0$, then this will be biased high proportional to $\sigma^2 (\hat{\beta})$ to lowest order. Performing the inverse linear regression, instead trying to fit $x = -\alpha/\beta + y/\beta$ for $-\alpha/\beta$ and $\beta^{-1}$. The problem here is that this breaks the assumption going into the linear regression model, that error is on the dependent variable only. Instead of getting an unbiased estimator of $\beta^{-1}$, you end up getting an unbiased estimator of $\beta\sigma^2(x)/\sigma^2(y)$. So, is there any known way to do this?","['regression', 'statistics', 'linear-regression']"
2297492,Symmetric Part of the inverse of a matrix,"I've this question that i hope it has an elegant solution. Consider the symmetric part of a matrix $\mathcal{H}\{A\} = \dfrac{A+A^{T}}{2}$ where $A\in\mathbb{R}^{n\times n}$. Furthermore, consider that $\mathcal{H}\{A\}<0$, i.e. is negative-definite. Provided that $A$ is invertible: Is it possible to say that $\mathcal{H}\{A^{-1}\}$ will be also negative-definite? Thanks in advance!","['matrices', 'matrix-decomposition', 'symmetric-matrices', 'linear-transformations', 'linear-algebra']"
2297493,How many elements of order 3 in this set of 2×2 matrices?,"Let $M$ be a group, $M=\bigg  \{ \bigg(
  {\begin{array}{cc}
   a & b \\
   0 & c \\
  \end{array} } \bigg)\bigg| a,c \in \mathbb{Z}_3\setminus \{0\},
b\in \mathbb{Z}_3
\bigg \}$ The elements of $M$ of order 3 are
${\bigg(\begin{array}{cc}
   1 & b \\
   0 & 1 \\
  \end{array}\bigg) }$. I thought those were ${\bigg(\begin{array}{cc}
   1 & 0 \\
   0 & 1 \\
  \end{array}\bigg) }, {\bigg(\begin{array}{cc}
   1 & 1 \\
   0 & 1 \\
  \end{array}\bigg) },{\bigg(\begin{array}{cc}
   1 & 2 \\
   0 & 1 \\
  \end{array}\bigg) }$, since $b \in \mathbb{Z}_3$. But my answer sheet doesn't mention ${\bigg(\begin{array}{cc}
   1 & 0 \\
   0 & 1 \\
\end{array}} \bigg )
$, but that's just a mistake in the sheet, right? Or have I misunderstood something?","['matrices', 'group-theory']"
2297500,"Let $K = \mathbb{Q}(\alpha)$, where $\alpha ^n = a$. If $p\mid a, p^2\nmid a$, then $p\nmid [\mathcal{O}_K : \mathbb{Z}[\alpha]]$","I've been given the following question for some revision of algebraic number theory: Let $K = \mathbb{Q}(\alpha)$, where $\alpha ^n = a$. If $p\mid a, p^2\nmid a$, then $p\nmid [\mathcal{O}_K : \mathbb{Z}[\alpha]]$ I have already proved that if $\alpha \in K$ is algebraic with $\mathbb{Q}(\alpha) = K$ and $\mathbb{Z}[\alpha]≠\mathcal{O}_K$, the ring of integers of $K$, then for all prime divisors $p$ of $[\mathcal{O}_K : \mathbb{Z}[\alpha]]$ there is an algebraic integer of the form $$\beta = \sum_{I=0}^{n-1} \frac{c_i}{p} \alpha^I$$ where the $c_i \in \mathbb{Z}$ are not all divisible by $p$. What I have attempted so far is to go by contradiction: if it is the case that $p\mid[\mathcal{O}_K : \mathbb{Z}[\alpha]]$, then there is such a $\beta$. I then tried to compute an expression for the norm of $\beta$, and show that $\text{Norm}_{K/\mathbb{Q}}(\beta) \notin \mathbb{Z}$, but couldn't manage this. Perhaps I am supposed to extract some other algebraic integer from the expression for $\beta$, then show that its norm is not an integer, but I can't see how I could do that. Thanks for your help, any hints would be appreciated.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'group-theory']"
2297504,Find $\lim_{x\to 1}\frac{p}{1-x^p}-\frac{q}{1-x^q}$ [duplicate],This question already has answers here : Showing that $\lim_{x \to 1} \left(\frac{23}{1-x^{23}}-\frac{11}{1-x^{11}} \right)=6$ (11 answers) Closed 7 years ago . Find $\lim_{x\to 1}(\frac{p}{1-x^p}-\frac{q}{1-x^q})$ My attempt: I took LCM and applied lhospital but not getting the answer.Please help,['limits']
2297523,$S_n=\sum_{k=1}^n\frac{1}{k}$. then $S_{2^n}$=? [duplicate],"This question already has answers here : $ S_n=\sum_{k=1}^n\frac{1}{k}$ then is $S_n$ bounded? (3 answers) Closed 3 years ago . Let $S_n$=$\sum_{k=1}^n\frac{1}{k}$. which of the following is true? $S_{2^n}\ge\frac{n}{2}$ for every n$\ge1$. $S_n$ is a bounded sequence. $|S_{2^n}-S_{2^{n-1}}|\to0$ as n$\to\infty$. $\frac{S_n}{n}\to1$ as n$\to\infty$. I have a confusion that whether $S_{2^n}$=$\frac{1}{2}+\frac{1}{2^2}+\dots+\frac{1}{2^n}$? 
or
$S_{2^n}$=$1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{2^n}$?",['sequences-and-series']
2297543,Did the directional derivative get developed before the gradient?,"In learning multivariable calculus, I've often seen the gradient introduced before the directional derivative. To me this is backwards. Once we have partials, we treat then as rates of change in the direction of the axes. We should then naturally ask ""what if the direction were not aligned with the axes?"". From there, a natural question of ""in which direction is the rate of change maximal?"" Seems to arise.  In the development of calculus, which came first? I find that by introducing the gradient before directional derivatives it seems like some arbitrary vector that was pulled out of no where. It only seems to make sense once we understand directional derivatives.","['math-history', 'calculus']"
2297569,Converting an $\prod_{n=2}(1+(-1)^{n}\frac{1}{n})$ into an Infinite Series to determine Convergence?,"I'm having trouble determining whether the infinite product in $(1.)$ converges or diverges, my attack was to use the convergence cretina stated in $(0.)$ $(0.)$ An Infinite Product is said to be convergent if there exists a non-zero limit of the sequence of partial products: $$P_{n}=\prod_{k=1}^n(1 + u_{k})$$. as $n \rightarrow \infty$ The value of the infinite product is the limit:
$$P = \lim_{n \rightarrow \infty}P_{n}$$ and one writes $$\prod_{k=1}(1 + u_{k}) = P$$ $(1.)$ $$\prod_{k=2}\left(1 + (-1)^{k}\frac{1}{k}\right)$$ Attacking $(1.)$ via our convergence criteria stated in $(0.)$ one can make the following observations: $$P_{n} = \prod_{k=2}^n\left(1 + (-1)^{k}\frac{1}{k}\right)$$ Now taking the limit of $P_{n}$ we may now see:
$$\lim_{n \rightarrow \infty} \left(\prod_{k=2}^n\left(1 + (-1)^{k}\frac{1}{k}\right)\right)$$ Further observations reveal that we have the following:
$$\lim_{n \rightarrow \infty}P_{n}=\lim_{n \rightarrow \infty} \left(\prod_{k=2}^n\left(1 + (-1)^{k}\frac{1}{k}\right)\right)= \lim_{n \rightarrow \infty}\left(P_{2}\times P_{3}\times P_{4}\times P_{5} \times \cdots \times P_{n}\right)$$. Finally in conclusion the limit on the RHS side of our result becomes the following:
$$\lim_{n \rightarrow \infty}\left(1 +(-1)^{2}\frac{1}{2}\right) \times \cdots  + \left(1 +(-1)^{n})\frac{1}{n}\right)$$ My question is how to convert our sequence of partial products as seen in our previous result into an infinite series of any form ?","['complex-analysis', 'infinite-product']"
2297574,Express $\frac {a^2+(a+b)^2}{a(a+b)}$ in terms of $x$ and $y$.,"Given that ${ab}=x$ and ${a+b}=y$.  Express $\dfrac{a^2+(a+b)^2}{a(a+b)}$ in terms of $x$ and $y$. I try many way still cannot succeed.  Please use some elementary way to help me to solve this.  As I am not familiar with MathJax, so if exists any mistake please forgive me.  Thanks.",['algebra-precalculus']
2297578,System differential equations,Solve the system differential equation $$\frac{dx}{\cos y}=\frac{dy}{\cos x}=\frac{dz}{\cos x \cos y}$$ I think: $$\frac{dx}{\cos y}=\frac{dy}{\cos x}$$ $$\cos x~dx = \cos y~dy$$ $$\sin x = \sin y + C_1$$ $$C_1 = \sin x - \sin y$$ And then I do not know how to solve it. Maybe: $$\frac{dxdy}{\cos y \cos x}=\frac{dz}{\cos x \cos y}$$ $$dx dy=dz$$ But what next?,['ordinary-differential-equations']
2297613,Reordering sequences,"I am trying to study the reordering of sequences. I am having difficulties finding any learned articles, probably because I don't know the key words to search for. I hope if I can describe what I want to do someone can can expand my knowledge or name what I am doing so I can research it myself. I want to define a reordering of a sequence in a form that can be coded easily. Here I will use $S(...)$. I start with the most simple integer sequence. $1,2,3,4,5,...$ Perhaps I want to swap pairs of them to become: $2,1,4,3,6,5,... = S(3,-1)$ meaning skip forward 3, then skip back 1 and repeat. or reverse triplets $3,2,1,6,5,4,9,... = S(5,-1,-1)$ meaning skip forward 4, then skip back 1, and once more back 1 and repeat. or something more complicated like $5,4,2,3,1,10,9,7,8,6,15... = S(9,-1,-2,1,-2)$ so I define a function $S(...)$ that can do that which takes as parameters as the sequence of steps in the original sequence to make the new one (I haven't explained that very well but bear with me). Now clearly I can code S without difficulty, I just need to retain enough history of the incoming sequence to jump back and forward as directed. Is there a name for this function $S$ or something similar? Is there a way of examining the parameters of S to determine whether the resulting sequence: emits all of the original sequence does not emit duplicates For example, $S(2,-1)$ would produce the sequence $2,1,3,2,4,3,...$ which is not acceptable because 2 gets repeated. And $S(2)$ would generate $2,4,6,8,...$ which skips some and is also not acceptable. Is there a way of generating these orderings? There is clearly a null form $S(1)$ which could be considered the first. Added This process is manipulating an infinite sequence by applying $S$ repeatedly. The two requirements apply to the whole infinite sequence generated. So, for example $S(24,-23)$ is invalid because eventually a duplicate will arise even though the first iteration does not.",['sequences-and-series']
2297630,Numerical Integration Problems,"I want to analyze the following integral changing $\sigma$ over the interval $[0,\infty)$ $$\frac{1}{\sigma}\int_{0}^{1}\frac{(y-1/2)^2}{y(1-y)}\exp\bigg\{-\frac{\big[\log\big(\frac{y}{1-y}\big)\big]^2}{2\sigma^2}\bigg\}dy$$ For large $\sigma$, the adaptive quadrature method has numerical problems (probably due to the singularity of the integrand at $y=1$). Is there a way to evaluate it? I've tried also to study its equivalent form with the same method, namely $$\frac{1}{\sigma}\int_{0}^{\infty}\frac{(t-1)^2}{4t(t+1)^2}\exp\bigg\{-\frac{(\log t)^2}{2\sigma^2}\bigg\}dt$$ where $t=\frac{y}{1-y}$ but I still get numerical problems and find huge differences between the two integrals even for small values of $\sigma$.","['numerical-methods', 'integration', 'definite-integrals']"
2297633,What is the smallest positive integer $n$ such that there are $m$ nonisomorphic groups of order $n$? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question This following  question given in Gallian's algebra text: What is the smallest positive integer $n$ such that there are two nonisomorphic groups of order $n$? The answer for this question given in text book is $n=4$ as $\mathbb Z_4$ and $\mathbb Z_2 \times \mathbb Z_2$ served our purpose.I did this by inspection. Now i wanted to generalise this question i.e; i wanted to know What is the smallest positive integer $n$ such that there are EXACTLY $m$ nonisomorphic groups of order $n$? Here inspection does'nt work.So please guide me to get to the result. Thank you!,"['finite-groups', 'abstract-algebra', 'groups-enumeration', 'abelian-groups', 'group-theory']"
2297660,Derivative of vector consisting of euclidean distances,"I have $g: \Bbb R^2 \to \Bbb R^4$ given by $g(x) = (\|c_1 - x\|, \dots, \|c_4 - x\|)$, where $c_1, \dots, c_4 \in \Bbb R^2$. I want to find $\left( \dfrac {\partial g} {\partial x_1}, \dfrac {\partial g} {\partial x_2} \right)$. Any hints?","['multivariable-calculus', 'calculus', 'derivatives']"
2297705,real Lie algebra with positive Killing form is zero,"Let $L$ be a finite-dimensional Lie algebra over the real numbers with positive definite Killing form. Why is $L=\{0\}$? As a hint we should have a look at Gram-Schmidt orthonormalisation. Everything I tried failed so far, so the usual 'What do I have so far' field is left empty. Sorry for that.","['abstract-algebra', 'lie-algebras']"
2297731,"Studying continuity of $f(x,y) = \left( \frac{\sin(x^2+y^2)}{x^2 + y^2},\frac{e^{x^2+y^2}-1}{x^2 + y^2} \right)$","I need to study the continuity of this function: $$f(x,y) = \left( \frac{\sin(x^2+y^2)}{x^2 + y^2},\frac{e^{x^2+y^2}-1}{x^2 + y^2} \right)$$ It's from an exercise of a calculus textbook. As they are continuous functions I know that the only problematic point is the origin... I know from previous exercises that the limit of $\frac{\sin(x)}{x}$ when $x$ approaches $0$ is $1$. But I don't know how to prove that the $y$ coordinate is algo going to $1$. Could you help me with this? Thank you.","['multivariable-calculus', 'continuity', 'limits']"
2297734,Intersection of $n+k$ subspaces of $\mathbb{R}^n$,"In $\mathbb{R}^n$, $n\ge 3$ consider $n+k$ vectors $v_1,\dots, v_{n+k}$, $k\ge 1$ such that subset of cardinality $n$ of $\{v_1,\dots, v_{n+k}\}$ is composed of linearly independent vectors of $\mathbb{R}^n$. Define the subsets $W_i$ of $\mathbb{R}^n$ as $W_i:=\{w\in \mathbb{R}^n|w\cdot v_i\le 0\}$, $i=1,\dots, n+k$. What is a sufficient condition on $v_1,\dots,v_{n+k}$ to guarantee $\cap_{i=1}^{n+k}W_i=\{0\}$? In the meantime I had an idea: A sufficient condition for $\cap_{i=1}^{n+k}W_i=\{0\}$ could be, up to renumbering the indexes, $v_{n+1}=\alpha_1v_1+\dots \alpha_nv_n$ with $\alpha_i<0$ for all $i=1,\dots,n$. In this way, if $w\in \cap_{i=1}^{n}W_i,w\neq 0$ it's clear that $w\notin W_{n+1}$. But this is a rather unpleasant condition: for $n$ big it will be very complicated to compute the $\alpha_i$ (as one should compute the inverse of the Gram matrix associated to the basis). Do you know a better condition?","['inequality', 'euclidean-geometry', 'linear-algebra', 'convex-analysis']"
2297740,Solve $\cos 2x - \sin 2x = \sqrt 3\cos 4x$,"How do I solve this trig equation? $$\cos 2x - \sin2x = \sqrt{3} \cos 4x$$ I have tried in different ways. But I can't get to a final answer.Please help. My work is, $$\cos 2x - \sin 2x = √3(\cos 2x - \sin 2x)(\cos 2x + \sin 2x)$$
$$⇔(\cos 2x - \sin 2x)((1-√3(\cos 2x + \sin 2x))= 0$$
 Then,
$$\tan 2x = 1  \ \ \  \text{or}  \ \ \   (\cos 2x + \sin 2x)= \dfrac1{\sqrt3}$$ I don't know whether this way is correct. Please someone help for a better solution.",['trigonometry']
2297749,Approximation of the first derivative by writing Taylor expansions,"What is the most accurate approximation you can write for $f'(x)$ using the values $f(x-2h)$, $f(x)$ and $f(x+4h)$? What is the order of this approximation? Note: I know how to approximate $f'(x)$ with these given values by using Taylor expansion but I couldn't understand how to find the most accurate one.","['derivatives', 'numerical-methods', 'taylor-expansion', 'approximation']"
2297750,Definition of a bounded subset in a normed vector space,"I'm having a hard time trying to understand what is exactly a bounded set (or subset) in a normed vector space. This is where I am so far in my ""understanding"": Let $(V, \|\cdot\|)$ be a normed vector space. We can define $\|y-x\| =: d(x,y) =: d$ such that $(V,d)$ is a metric space. In a metric space (such as in $(V,d)$), a set $A$ is bounded if it is contained in a ball of finite radius, that is: $A \subset V$ is bounded if there exists $x \in V$ and $0 < R < \infty$ such that $A \subset B(x,R)$, i.e. such that $d(x,y) \le R$ for all $y \in A$. A set in a topological vector space (such as a normed vector space) is called bounded if every neighborhood of the zero vector can be inflated to include the set. (Source: Wikipedia ) Apparently, a subset $A$ of a normed vector space $(V, \|\cdot\|)$ is said to be bounded if there exists $C > 0$ such that $\|v\| \le C$ for all $v \in A$. What I don't understand is that, to me, it would be ""logical"" to say that a subset $A$ of a normed vector space $(V, \|\cdot\|)$ is bounded if there exists $x \in V$ and $C>0$ such that $d(x,y) = \|y-x\| \le C$ for all $y \in A$. But it seems like the ""real"" definition of a bounded (sub)set of a normed vector space is considering only $x=0$, that is, $x$ being the zero vector. Why is that? Furthermore, I'm not sure to understand the definition given by Wikipedia. Since a neighborhood is a set containing an open set containing a particular point, and considering that this point could be the zero vector, how can we use that information to get the actual definition of a bounded subset of a normed vector space (i.e. the last definition I mentioned in my list above)? As you can see, I'm quite confused about all this... And I'm a little bit exhausted since I've tried to get it for hours now. Any help would be greatly appreciated...!","['normed-spaces', 'real-analysis', 'definition']"
2297825,To find domain of $f(x)=\frac{1}{\sqrt{\left\{x\right\}-x^2}}$,Find domain of $$f(x)=\frac{1}{\sqrt{\left\{x\right\}-x^2}}$$ where $\left\{x\right\}$ is Fractional part function.  I tried as follows: $$\left\{x\right\} \gt x^2$$ so $$x-\left[x \right] \gt x^2$$  Or $$x^2-x+\left[x\right] \lt 0$$ How to proceed further?,"['algebra-precalculus', 'real-analysis', 'functions']"
2297845,Proof for sum of product of four consecutive integers,"I had to prove that
$(1)(2)(3)(4)+\cdots(n)(n+1)(n+2)(n+3)=\frac{n(n+1)(n+2)(n+3)(n+4)}{5}$ This is how I attempted to do the problem:
First I expanded the $n^{th}$ term:$n(n+1)(n+2)(n+3)=n^4+6n^3+11n^2+6n$. So the series $(1)(2)(3)(4)+\cdots+(n)(n+1)(n+2)(n+3)$ will be equal to $(1^4+2^4+\cdots+n^4)+6(1^3+2^3+\cdots+n^3)+11(1^2+2^2+\cdots+n^2)+6(1+\cdots+n)$ $=\frac{n(n+1)(2n+1)(3n^2-3n-1)}{30}+6*\frac{n^2(n+1)^2}{4}+11*\frac{(n+1)(2n+1)(n)}{6}+6*\frac{n(n+1)}{2}$ I tried to factor out $\frac{n(n+1)}{5}$ and tried to manipulate the expressions in ways which further complicated things. How should I proceed? Can anyone please give me some clues? Any help is appreciated.",['sequences-and-series']
2297863,Are all additionlike operations on $\mathbb{R}$ of this form?,"Suppose we're given real numbers $x,x',y,y' \in \mathbb{R}$ such that $$|x-x'| \leq a, \qquad |y-y'| \leq b.$$ Then $$|(x+y)-(x'+y')| = |(x-x')+(y-y')| \leq |x-x'| + |y-y'| \leq a+b$$ This tells us that if we know a real number $x$ to a precision of $a$, and if we know $y$ to a precision of $b$, then we know $x+y$ to a precision of $a+b$. Interestingly, the above argument only needs the following two properties of addition: Axiom 0. $(x\star y) - (x' \star y') = (x-x') \star (y-y')$ Axiom 1. $|x \star y| \leq |x| \star |y|$. Call a binary operation on $\mathbb{R}$ additionlike iff it satisfies these two axioms. It's easy to see that the operation defined by $x \star y = k(x+y)$ is additionlike, for all $k \geq 0$. Question. Are all additionlike operations on $\mathbb{R}$ of this form?","['magma', 'abstract-algebra', 'real-analysis', 'binary-operations']"
2297875,Show that $(1+u) \log (1+u) - u \ge \frac{u^2}{2(1+u/3)} $,"This is used to go from Bennett's inequality to Bernstein's inequality.
Yet I don't understand how to prove the inequality. Assume that $u > 0$, define
$$
h(u) = (1+u) \log (1+u) - u
$$
show that
$$
h(u) \ge \frac{u^2}{2(1+u/3)}
$$ My research : Decomposing the function $h$ as a power series show that it is equivalent to
$$
\sum_{n=1}^\infty (-1)^n \frac{u^n}{n+1} \frac{n-1}{n (n+2)} \ge 0
$$
Sadly, I see no reason for this series to be positive. SOLUTION The twice differenciation technique given below works. However, I don't agree with the calculus, only on small things that don't change the result. Define
$$
g(u) = (1+u)\log (1+u) - u - \frac{3u^2}{2(3+u)}
$$
$$
g'(u) = \log (1+u) + 1 - 1 - \frac{3}{2} \frac{2u (3+u) - u^2}{(3+u)^2}\\
$$
Simplifying,
$$
g'(u) = \log (1+u) - \frac{3}{2} \frac{u(u+6 )}{(3+u)^2}  
$$
$$
g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{(2u +6)(3+u)^2 - 
2 (u+3)(u^2 + 6u) }{(3+u)^4}  
$$
Simplifying, $$
g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{2u^2 +6u + 6u + 18 - 
2u^2 - 12u }{(3+u)^3}   =
 \frac{1}{1+u} - \frac{ 27  }{(3+u)^3} 
$$ Simplifying again, $$
g''(u)= \frac{ u^3 + 3\times 3u^2 + 3 \times 9u + 27 - 27(1+u)}{(1+u)(3+u)^3} 
= \frac{ u^2(u+9)}{(1+u)(3+u)^3} > 0
$$
And the result is given by the reasoning of Clement.","['real-analysis', 'probability', 'analysis']"
2297885,Is every compact subset contained in a regular subset?,"Let $A$ be an open set in $\mathbb{R}^n$, $C \subset A$ a compact set. Does there always exist an open set $B \subset A$ such that $C \subset B$ and $\partial B \subset A$ is a $C^1$ regular surface? As possible partial results, first notice that by compactness there is a finite collection of balls contained in $A$ whose union contains $C$ (the border of course is not regular in the intersections). One can also try to regularize the characteristic function $\mathbb{1}_B$ of an open set $B$ that satisfies the inclusions, and consider a level set of the regularized function. However, it seems non trivial to show that one can choose the regularization and the level set in such a way that the gradient never vanish in the level set.","['geometric-topology', 'differential-geometry']"
2297901,A Conjectured Mathematical Constant For Base-10 Normal Numbers.,"Question 1: Let $a$ be a real number with a base-10 decimal
  representation $a_1a_2\ldots a_n \ldots$ Denote the number of ways to
  write $a_n$ as the sum of positive integers as $p(a_n)$ - also called
  the partition of $a_n$. I write $A(n)=\sum_{k=1}^n p(a_k)$ and $B(n)= \sum_{k=1}^n a_k$ and set $$\beta(a)=\lim_{n\to \infty}{A(n)\above 1.5 pt B(n)}$$ 
  If $a$ is a base-10 simply normal number is it true that  $\beta(a)={97 \above 1.5 pt 45}$ ? Attempted Solution : Let $a$ be a base-10 simply normal number with decimal representation $a_1a_2\ldots a_n \ldots$. Explicitly we can write \begin{equation}\lim_{n\to \infty}{A(n)\above 1.5 pt B(n)} =\lim_{n\to \infty}{p(a_1)+p(a_2)+\ldots +p(a_n)\above 1.5pt a_1+a_2\ldots +a_n }\end{equation} Surely $a_k \in [0,9]$ for every $1\leq k \leq n$.  Now let $\nu_n(a_k)$ count occurrences of the digit $a_k$ up to and including the n-th decimal place of $a$. Observe the following: the numerator in the above equation can be written explicitly as: $$ \underbrace{(p(0)+\ldots +p(0))}_{\nu_n(0)\text{ times}}+\ldots+\underbrace{(p(9)+\ldots + p(9))}_{\nu_n(9)\text{ times}}$$ and similarly the denominator may be written as $$\underbrace{(0+\ldots  +0)}_{\nu_n(0)\text{ times}}+\ldots+\underbrace{(9+\ldots + 9)}_{\nu_n(9)\text{ times}}$$ Combining those two observation together we can rewrite the RHS of our first equation as $$ \lim_{n \to \infty}{\nu_n(0)\times p(0)+\nu_n(1)\times p(1)+\ldots + \nu_n(9)\times p(9)\above 1.5pt \nu_n(0)\times 0+ \nu_n(1)\times1+\ldots + \nu_n(9)\times9} $$ Recall that every digit of $a$ occurs with equal frequency. In particular since $a$ is simply normal we have that $\lim_{n \to \infty}\nu_n(a_j)=\lim_{n \to \infty}\nu_n(a_k)$ for every $j$ and $k$. With out loss to generality we can substitute $\nu_n(j)$ with $\nu_n(1)$ in the numerators and denominators of the equation above and evaluate the limit, $$\lim_{n \to \infty}{\nu_n(1)\times p(1)+\ldots + \nu_n(1)\times p(9) \above 1.5pt \nu_n(1)\times1+\ldots + \nu_n(1)\times9}$$ We can then pull out the term $ \nu_n(1)$, noticing those terms cancel out in the limit, and make a final simplification to show that $$\lim_{n \to \infty}{\nu_n(1) \above 1.5pt \nu_n(1)}{p(1) +\ldots +p(9)\above 1.5 pt 1+ \ldots +9}={1+1+1+2+3+5+7+11+15+22+30 \above 1.5pt 0+1+2+3+4+5+6+7+8+9}={ 97 \above 1.5pt 45}.$$ I believe the above solution to Question 1 is correct? Now my understanding is that we have the following implication: base-10 normal $\implies$ base-10 simply normal. So the follow up question seems natural. Question 2: If $a$ is a base-10 normal is it true that $\beta(a)={97 \above 1.5 pt 45}$ ? The answer to Question 2 should be yes by implication alone. Moreover it should be true for both algebraic and transcendental base-10 normal numbers. Since I believe I have shown every base-10 simply normal number converges to ${97 \above 1.5 pt 45}$ under $\beta$ and every base-10 normal number is simply normal then so to will every base-10 normal number converge to ${97 \above 1.5 pt 45}$ under $\beta$. It should be clear that the converse two Question 2 is false ! If we believe Questions 1 and 2 are true then we would expect several well known provably base-10 normal constants to converge to ${97 \above 1.5pt 45}$ under $\beta$. So I ran an experiment using data from Sloan's Database on the Erdos-Copeland constants which is proven to be normal in base-10. Using the first $2\text{ }000$ digits I plotted the values of $\beta(\text{Erdos-Copeland})$. The graph below illustrates the convergence. The blue line is the value of ${97 \above 1.5 pt 45}$ and the green graph are the values of the Erdos-Copeland constant under $\beta$. Up to the $2\text{ }000$-th digit $\beta(\text{Erdos-Copeland})=2.12999037999\ldots$ I believe given enough terms one can plot a similar graph for the Champernowne constant and one should expect the convergence to be significantly slower. Finally it is not known if $\pi$ is normal in base-10. Out of curiosity I computed $\beta(\pi)$ up to the first $500\text{ }000$ digits of $\pi$. See the graph below. Again the blue line is the value of ${97 \above 1.5 pt 45}$ and the orange graph are the values of the $\pi$ under $\beta$. Up to the $500\text{ }000$-th digit $\beta(\pi)=2.153781\ldots$. $\pi$ appears to converge faster under $\beta$ than any other mathematical constant I have looked into. I have numerous plots for zeta values and square roots and they all appear to approach ${97 \above 1.5 pt 45}$ which can be written numerically as $2.15555\ldots$. I have not attempted to plot numbers that are known to be abnormal in base-10.","['conjectures', 'integer-partitions', 'number-theory', 'combinatorics', 'elementary-number-theory']"
2297929,Geometry Construction Problems,"Recently I've been trying my hand at a few geometrical construction problems using just a straight edge and a compass. So far I have constructed the following: an equilateral triangle a square a regular pentagon a circle circumscribed about a triangle a circle inscribed in a triangle a parallel line through a point a perpendicular line through a point a bisected angle a segment cut into $n$ congruent segments I can't think of anything else to do other than just regular polygons, and I can't find a good list online. Can anyone think of any other constructions that I could try? I'm new to this, so if you give me something incredibly difficult, I may need a hint. Thank you!","['euclidean-geometry', 'geometric-construction', 'geometry']"
2297983,How many bases can a vector space have? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Hello guys I am currently taking a linear Algebra class; I stumbled upon this question: How many bases can a vector space have? Are they unique? Thanks in advance.","['linear-algebra', 'vector-spaces']"
2298011,Lower bound of $1-x$ involving exponential when $x$ is very small?,It is well know that $1-x\le e^{-x}$ for all real $x$. I wonder is there any inequality having the form $1-x\ge e^{-(1+o(1))x}$ when $x=x(n)=o(1)$ and what requirements should be satisfied? Here $x=o(1)$ means $x\to 0$ as $n\to \infty.$ http://mathworld.wolfram.com/Little-ONotation.html So we may assume $x$ is very small.,"['real-analysis', 'inequality', 'calculus', 'limits']"
