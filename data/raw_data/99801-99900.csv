question_id,title,body,tags
1382332,Is $K := \mathbb{Q}(\cos (2\pi / 11))$ a Galois extension over $\mathbb{Q}$?,"I believe that it is because $\cos(2\pi / 11) = (\zeta + \zeta^{-1})/2$ where $\zeta = e^{2\pi i/11}$ is a primitive $11$-th root of unity, and so $K$ is a subfield of $\mathbb{Q}(\zeta)$ with corresponding subgroup $H$ of $\mbox{Gal}(\mathbb{Q}(\zeta)/\mathbb{Q})$. Since the latter is isomorphic to $\mathbb{Z}/10$, $H$ is in particular normal and so $K$ is Galois over $\mathbb{Q}$. Is this argument sufficient? It seems that this argument would also work in the case that $11$ is replaced with a composite number - is that true?","['extension-field', 'abstract-algebra', 'field-theory', 'galois-theory']"
1382344,Expected value using indicator variables,"Randomly, $k$ distinguishable balls are placed into $n$ distinguishable boxes, with
all possibilities equally likely. Find the expected number of empty boxes. PROPOSED SOLUTION: Let $I_j$ be the indicator random variable for the $j^{th}$ box being empty, so $I_1 + ··· + I_n$ is the number of empty boxes. Now $E(I_j) = P(I_j = 1) $ Given both boxes AND balls are distinguishable total number of ways to place balls in boxes is $(n + k)!$ Now lets assume $j^{th}$ box is left empty, remaining $(n-1)$ boxes can be filled as $(k + n - 1)!$ ways Therefore,  $I_j = \dfrac{(k + n -1)!}{(k + n)! }= E(I_j)$ By linearity of Expectation, $E(\sum_{k=1}^n[I_j]) = \sum_{k=1}^n(E(I_j))$ = $\sum_{k=1}^n(\dfrac{(k + n -1)!}{(k + n)!})$ = $\dfrac{n(k + n - 1)!}{(k + n)!}$ solution guide gives answer as $n(1 - 1/n)^k$ which is arrived at by saying $I_j = (1 - 1/n)^k$ Any insights in what is wrong above.","['probability', 'expectation']"
1382366,$\zeta(2n)$ proof [duplicate],"This question already has answers here : Ways to prove Euler's formula for $\zeta(2n)$ (2 answers) Closed 8 years ago . Can anybody pass me on a good source to see the steps in proving, \begin{equation}
\zeta(2n) = \frac{(-1)^{k-1}B_{2k}(2\pi)^{2k}}{2(2k)!}
\end{equation} I know how we start by looking at the product of sine and use the generatinf function for the Bernoulli numbers to connect them. I am finding it hard to find a source that doesn't just assume the result or say that it is fairly trivial. Any help would be appreciated,
Thanks","['riemann-zeta', 'number-theory', 'analytic-number-theory', 'reference-request', 'complex-analysis']"
1382375,Find the sum of the series below,"Find the sum $$(1\cdot2)+(1\cdot3)+(1\cdot4)+\cdots+(1\cdot2015)+(2\cdot3)+(2\cdot4)+\cdots+(2\cdot2015)+\cdots+(2014\cdot2015)$$ What I have tried... We are looking for $$S(n)=\sum_{i=1}^{n-1}\sum_{j=i+1}^nij$$ when $n=2015$
$$S(n)=\sum_{1\le i<j\le n}ij$$ $$=\frac 12\left((\sum_{i=1}^n i)^2-\sum_{i=1}^ni^2\right)$$ $$S(n)=\frac 12\left(\frac{n^2(n+1)^2}4-\frac{n(n+1)(2n+1)}6\right)$$
 $$=\frac{(n-1)n(n+1)(3n+2)}{24}$$ And so $$\boxed{S(2015)=\frac{2014\times 2015\times 2016\times 6047}{24}}$$ Is the solution wrong or not?","['summation', 'sequences-and-series', 'algebra-precalculus']"
1382382,To what fractional Sobolev spaces does the step function belong? (Sobolev-Slobodeckij norm of step function),"I'm new to fractional Sobolev spaces and I'm curious about the regularity of some simple functions like e.$\,$g. step functions in order to understand these spaces better. In more detail, for $\Omega = [-1,1]^n \subseteq \mathbb{R^n}$ and $A = [-\frac{1}{2},\frac{1}{2}]^n\subseteq \Omega$ consider the function
$$
\begin{align}
f \colon \ \Omega & \longrightarrow \mathbb{R} \\
x & \longmapsto \begin{cases} 1 & \text{ for } x \in A \\ 0 & \text{ for } x \notin A\text{.}\end{cases}
\end{align}
$$
For which $s \in [0,1]$ does $f$ have a finite Sobolev-Slobodeckij norm? The norm that is meant here is defined by
$$
\Vert f\Vert_{s}^2 := \int_\Omega \int_\Omega \frac{\vert f(x) - f(y)\vert^2}{\Vert x-y\Vert^{2s+n}} \, \mathrm{d}x \, \mathrm{d}y\text{.}
$$ Is there a way to determine the value of the integral analytically in dependence of $n$ and $s$? Or can one at least easily determine those $s$ for which this integral would be finite? Can it at least be done for $n=2$? So far I tried the simple case $n=1$ for which I get that $s\in [0,\frac{1}{2})$ has to be fulfilled. I expect that to be the case for any $n$ but at the moment I'm not quite sure since I did not prove it. For $n=2$ I would try to integrate by hand but with my approach it's about to become a rather long calculation. Is there maybe an elegant way to do it? I don't mind if $A$ is replaced by another set like for example a scaled $n$-Sphere or some simplex.","['sobolev-spaces', 'integration']"
1382392,"Over ZF does ""every non-seperable Hilbert space has an orthonormal basis"" imply ""there exists a non-Lebesgue measurable set""?","I know from this question that it's an open problem whether or not the existence of a dense orthonomral basis for every real or complex Hilbert space $(\text{B}_\text{orth})$ implies the axiom of choice. This tells me that the axiom of dependent choice, $(\text{DC})$, isn't strong enough to imply that every non-seperable Hilbert space has an orthonormal basis (otherwise it wouldn't be an open problem because if $(\text{B}_\text{orth})\Rightarrow(\text{AC})$ then $(\text{DC})\Rightarrow(\text{AC})$ and the Solovay model would be unsatisfiable) so it's not immediately impossible that you can prove the existence of a non-Lebesgue measurable set, $(\text{not-LM})$, from $(\text{B}_\text{orth})$. I know from the paper The Hahn-Banach theorem implies the existence of a non-Lebesgue measurable set by Foreman and Wehrung that the full Hahn-Banach theorem is enough to prove $(\text{not-LM})$ and I know that a weakened version of the Hahn-Banach theorem for Hilbert spaces is somewhat immediate, but the proof of $(\text{not-LM})$ in that paper relies on the equivalence of Hahn-Banach and the existence of a finitely additive measure on every Boolean algebra and I'm not sure how that statement is weakened for weakened versions of Hahn-Banach.","['lebesgue-measure', 'measure-theory', 'axiom-of-choice', 'hilbert-spaces', 'set-theory']"
1382393,Prove that the Mandelbrot Set Is A Closed Set,"The Problem: Suppose we define the Mandelbrot Set as the following For  $c \in \mathbb{C}$  , $\mathbb{M}$ = $({c:|c| \leq 2}) \cap ({c: |c^2 + c| \leq 2}) \cap ({c: |(c^2+c)^2 + c| \leq 2})       \cap ...$ Carefully argue that each set in this intersection of sets is a closed subset of the Complex Plane. By this, show that the Mandelbrot Set is closed. The attempt - So for each $i \in \mathbb{N} $, we can write this set as the following: $\mathbb{M}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| \leq 2)$, for $i \geq 1$,  which $Q_{c} (z) = z^2+c$. Now if we are going to show the set is closed, we can show that the complement of each set is open, which it is for each $i$, $\mathbb{M}^{c}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| > 2)$, for $i \geq 1$. To show each set is open, we can find an ε-neighborhood of any point, $z_{0} \in \mathbb{M^c}$ for which $N(z_{0}, ε) \subseteq \mathbb{M} ^{c}$. I can define $ε = max ({2, |z_{0}|})$ and that is all I got so far. I am not sure if I am on the right track. However, there was a hint to this problem which I do not know what it means (Hint: If $F : \mathbb{C} \mapsto \mathbb{R}$, is a continuous function, then for every $b \in \mathbb{R}$, 
the set $(c \in \mathbb{C} : F(c) \leq b)$. Is this the neighborhood I was supposed to be defining? Thank you very much for your help!","['chaos-theory', 'complex-dynamics', 'complex-analysis']"
1382437,Line segment equation in polar coordinates,"I have a line segment given by two points $A$ and $B$. $$A+u(B-A), u\in[0,1]$$ when doing calculations with this segment, it would be advantageous to have it written in polar coordinates around some point $S$. More specifically, in the form $$r=f(\phi)$$ I could brute force this expression but the result starts getting ugly, fast. Is there some insight I can use that would give me a simpler definition of $f$ using $A$, $B$ and $S$?","['geometry', 'polar-coordinates']"
1382443,The number $\sum\limits_{n=-\infty}^{\infty} \frac{1}{2^{n^2}}$ is transcendental,"Prove that the number:
  $$\sum_{n=-\infty}^{\infty} \frac{1}{2^{n^2}}$$
  is transcendental. I don't have a direct proof but a round one. The series can be expressed in terms of $\vartheta_3$ which is one of the theta Jacobi functions. More specifically, $$\sum_{n=-\infty}^{\infty} \frac{1}{2^{n^2}}=\vartheta_{3} \left (\frac{1}{2} \right)$$ From the theory of the Jacobi function we know that for $|q|<1$ the series converges and the number is transcedental. Any other direct proof?","['transcendental-numbers', 'number-theory', 'special-functions']"
1382445,Is an open subset of a compact surface with connected boundary completely determined by its fundamental group?,"Is an open, connected subset of a compact surface with connected boundary  determined (up to homeomorphism) by its fundamental group? If we weaken the hypotheses, I can see how this can fail: A cylinder and circle are both subsets of the torus with $F_1$ as their fundamental group, so the requirement that the subset be open is necessary. A torus with a point removed and a twice-puntured disk both have $F_2$ as their fundamental group, so the result can fail if we allow subsets with disconnected boundaries. Since a disconnected spaces does not generally have a single uniquely defined fundamental group (we have to specify where the base point lies), requiring connectedness seems reasonable. It seems like open subsets of a compact surface with a connected boundary are sufficiently 'nice' that this result could hold. This question came to me when I was answering this question : if it were true, then we could enumerate the possible faces of a graph embedding in any surface $S$ by simply enumerating the subgroups of $S \setminus \{p\}$.","['surfaces', 'general-topology', 'fundamental-groups']"
1382459,Determine $P(S_n\leq1)$ where $S_n=\sum_{k=1}^nX_k$,"Suppose that $X_n$ are i.i.d. $Uniform(0,1)$ random variables. Let $S_n=\sum_{k=1}^nX_k$ with $S_0:=0$ . Then, determine $P(S_n\leq1)$ . I know that maybe by using Characteristic function of $S_n$ I will be able to get the d.f. of $S_n$ using Inversion Theorem but I do not want to use that. I tried the following method: I want to find $P(S_n>1)$ instead. Let $A=\{S_n>1\}$ . Then define $A_k=\{S_{k-1}\leq1,S_k>1\}$ . Notice that $A_k$ are disjoint, and $\cup_kA_k=A$ . Hence $P(A)=\sum_{k=1}^nP(A_k)=\sum_{k=1}^nP(S_{k-1}\leq1,S_k>1)=\sum_{k=2}^nP(S_{k-1}\leq1,S_k>1)$ because $P(S_0\leq1,S_1>1)=0$ . Now $P(S_{k-1}\leq1,S_k>1)=P(S_{k-1}\leq1, S_{k-1}>1-X_k)=P(1-X_k< S_{k-1}\leq 1)$ It seems I can't proceed from here, because I would need knowledge of $P(S_{k-1}\leq1)$ . Will induction work here, then? In general is there any formula for $P(S_n\leq a)$ where $a>0$ ?","['probability-theory', 'independence', 'uniform-distribution', 'random-variables']"
1382460,vercongent sequences,"Definition- We say a sequence $(x_n)$ verconges to $x$ if there exist an $\epsilon>0$ such that for all $N\in \Bbb{N}$ , $n\ge N \implies |x_n-x|<\epsilon$ . Loosely speaking, by convergent sequence we mean that a sequence is convergent to some point $x$ if we can confine its infinite ""tail"" in some neighbourhood of $x$ . In similar wordings, vercongent sequence should mean, that a sequence $(x_n)$ is vercongent to $x$ if  we are given a point in its infinite ""tail"", say $\mathfrak{n}\in \Bbb{N}$ , then we can put a wall around $x$ , in which whole tail after $\frak{n}$ must lie. Question- Give an example of convergent sequence and one that is not vercongent or verdigent According to me $(x_n)=\{1,\frac12,\frac13, \frac14, \dots \}$ verconges to $0$ , also to $1$ as for any given $n\in \Bbb{N}$ , all terms after $n$ lies in $\epsilon=\frac{1}{n}$ neighbourhood of $0$ , clearly, and for $1$ we $\epsilon=\frac{n-1}{n}$ works. I guess  a convergent sequence is also vercongent , with the same limit, any many more limits, almost any number works as a limit, am I correct? But sequence $\{1,-1,1,-1,1,-1,\dots\}$ is not convergent as it is oscillatory but it is vercongent as for any natural number $\frak{n}$ , we can always choose $\epsilon=10$ around $0$ or $1$ or $-1$ , so it verconges to many numbers, a big enough epsilon will work. Thus vercongent does not imply convergent . But on the other hand, sequence $\{1,2,3,\dots \}$ neither converges nor verconges . Please correct me if I am wrong in this understanding of this exercise from Abbott's book "" Understanding Analysis .""","['convergence-divergence', 'real-analysis']"
1382503,Covariance of 1-D random process is $n\times n$!!!!,"I'm reading a tutorial on stochastic processes. There is an example in the tutorial as follows: General Moving Average random process given as $X[n]=\frac{(U[n]+U[n-1])}{2}$ where $E[U[n]]=\mu$ and $var(U[n]) = {σ^2}_U$ and the
  $U[n]$'s are uncorrelated. As you see $X[n]$ is a 1-D random variable Then the example is solved in the following way: $[C_X]_{ij}=E[(X[i]-E[X[i]])(X[j]-E[X[j]])]\qquad i=0,1,\dots,N-1;j=0,1,\dots,N-1.$ $\begin{align}
X[n]-E[X[n]]&=\frac{1}{2}(U[n]+U[n-1])-\frac{1}{2}(\mu+\mu)\\
&=\frac{1}{2}[(U[n]-\mu)+(U[n-1]-\mu)]\\
&=\frac{1}{2}[\overline U[n]+\overline U[n-1]]
\end{align}$ $\begin{align}
[C_X]_{ij}&=\frac{1}{4}E[(\overline U[i]+\overline U[i-1])(\overline U[j]+\overline U[j-1])]\\
&=\frac{1}{4}(E[\overline U[i]\overline U[j]]+E[\overline U[i]\overline U[j-1]]+E[\overline U[i-1]\overline U[j]]+E[\overline U[i-1]\overline U[j-1]])  
\end{align}$ $[C_X]_{ij}=\frac{1}{4}(\sigma^2_U\delta[j-i]+\sigma^2_U\delta[j-i-1]+\sigma^2_U\delta[j-i+1]+\sigma^2_U\delta[j-i]).$ $C_X=\begin{bmatrix}\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{2}&0&0&\dots & 0&0&0\\
\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}&0&\dots &0&0&0\\
\vdots &\vdots &\vdots& \vdots&\vdots &\vdots &\vdots& \vdots\\
0&0&0&0&\cdots &\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}\\
0&0&0&0&\cdots &0&\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}\end{bmatrix}$ So why $C_X$ is $n\times n$ inspite of $X[n]$ being 1-dimensional?","['random-variables', 'stochastic-processes', 'covariance', 'statistics', 'correlation']"
1382520,How to find unkown height of triangle without hyptenuse,"I been trying to solve this question and have tried to solve it for many days, but do not know how, any help would be much oblidged. A cable company owns the roads marked with the dotted lines in the figure, and it costs the cable company 25 dollars per foot to run the line on poles along the county roads. The area bounded by the house and roads is a privately owned field, ant the cable company must pay for an easement to run lines underground in the field. It is also more costly for the company to run the line underground than to run them on the poles. The total cost to run lines underground across the field is $52 per foot. Whilst to run the cable via pole 46% less than to run it underground. Image: https://i.sstatic.net/2A5ib.jpg The cable company has the choice of running the lines line along the road or cutting across the field. I. Advise the company on the costings to the company to run lines both along the road to H and directly across the field. II. What would the critical distance that the piped must be laid which will contribute to a minimum costings to the company. For part I, I had used pythagor's theorem to find the distance of PH and multiply it by the respective costs of the material. However for II, I am a bit stumped. The critical distance is defined as the distance from p to the second point on the line, let us call it G. So critical distance is equal to PG, however, I do not know how to find it since the value of that hypotenuse is not given, and the height is ewual to (100-x). Plugging in this value in the theorem gives an unimaginably large expression without any real roots. Any help would be much oblidged.","['calculus', 'algebra-precalculus', 'economics', 'trigonometry', 'derivatives']"
1382521,How can I try myself to solve exponential equations easily?,"I spent hours trying to solve: $$4^x + 1 = 2^{x+1}$$ Can you guide me on how to solve this? How can I train myself to always find the right ""trick"" to solve such equations? Rather than just practicing... Is there a better way to always know how to approach such equations? Are there steps that will always lead me to the right way to approach? For example - ""first always simplify"" then ""multiply"" then... ? Thanks!",['algebra-precalculus']
1382530,Some questions about an exercise about $C^\infty \subset L^\infty$,"Let 
$$ L^\infty (\mathbb R) = \{f : \mathbb R \to \mathbb C\mid \text{essential sup of } f < \infty \text{ and } f \text{ Borel measurable} \}$$ and $$ C^\infty (\mathbb R ) = \{ f: \mathbb R \to \mathbb C \mid f \text{ continuous }, \lim_{|x|\to \infty}f(x) = 0 \}$$ I was going to solve the following exercise but then realised there were a few things that were not clear to me. Here is the exercise: Prove that there exists an element $\lambda \in (L^\infty (\mathbb R))^\ast$ such that $\lambda (f) = f(0) $ for all $f \in C^\infty(\mathbb R)$. Hint: Use consequences of the Hahn-Banach theorem. Here are my thoughts and questions: (1) It's clear to me that $C^\infty$ is a subspace of the space of bounded functions $B(\mathbb R)$ but here in this exercise $L^\infty$ is a space consisting of elements that are equivalence classes. Is this not a problem? Does $C^\infty$ embed into $L^\infty$? (I'm not
  sure embed is the correct word...) (2) Say we use representatives of $L^\infty$ so that (1) is not a problem. Then to me it seems that the evaluation map $f \mapsto f(0)$ is an element of $(L^\infty)^\ast$. And this would answer the question but the hint suggests I am missing something. What am I missing?","['solution-verification', 'functional-analysis']"
1382555,"If a $n$-manifold exists, then is it the boundary of an existing $(n+1)$-manifold?","I am reading some basic context books about topology (i.e. The Poincaré Conjecture , by Donal O'Shea between others) and following this open Topology and Geometry video lectures of the brilliant professor Tadashi Tokieda in the African Institute for Mathematical Sciences (for beginners in the matter, if you have time I would suggest you to have a look to them!). I would like to ask the following question: Is every $n$-manifold the boundary of an $(n+1)$-manifold? Is every compact $n$-manifold the boundary of a compact $(n+1)$-manifold? Thank you! p.s. This question was rewritten according to the suggestions in the comments and Meta ( here ), I hope now will be more accurate. Thanks to everybody for the suggestions!","['reference-request', 'manifolds', 'general-topology']"
1382570,Name of $|x|^p+|y|^p\le (|x|+|y|)^p$ ($p\ge 1$)?,"I checked these What is the difference between square of sum and sum of square? Prove $(|x| + |y|)^p \le |x|^p + |y|^p$ for $x,y \in \mathbb R$ and $p \in (0,1]$. It is easy to see $p$-th power ($p\ge 1$) version, i.e., $|x|^p+|y|^p\le (|x|+|y|)^p$ ($p\ge 1$), holds as well using the argument by Quang Hoang in Prove $(|x| + |y|)^p \le |x|^p + |y|^p$ for $x,y \in \mathbb R$ and $p \in (0,1]$. Is there a name for this inequality so that I can just quote? (It might be an elementary result but people around me bother to put ""from Cauchy--Schwarz,..."" when it is clearly Cauchy--Schwarz, so.)","['analysis', 'calculus', 'inequality']"
1382606,When $\cos(\theta) = 1/8$ it's easy to show $\theta$ is an irrational angle. Is it algebraic?,"Along the lines of my lines of my previous question about irrational angles "" $45^\circ$ Rubik's Cube: proving $\arccos ( \frac{\sqrt{2}}{2} - \frac{1}{4} )$ is an irrational angle? "", I was working on a puzzle and I ran into an interesting question about an irrational angle. Take a puzzle made out of a triangular bipyramid that turns on its vertices: The piece in the center must be a circle because it gets rotated by an irrational amount after some combination of moves.  Here is the path a point takes after repeatedly turning the purple axis followed by the green axis 90 degrees: The rotation matrix for this operation is
$$\left( \begin{array}{ccc}
\frac{1}{8} & \frac{3}{4} & \frac{3}{8}\sqrt{3} \\
\frac{-3}{4} & \frac{1}{2} & \frac{-1}{4}\sqrt{3} \\
\frac{-3}{8}\sqrt{3} & \frac{-1}{4}\sqrt{3} & \frac{5}{8} \end{array} \right)$$ From there you can find the axis that points are rotating around is $[0, \sqrt{3}/2, -1]$
And the angle $\theta$ they're rotating through is $\arccos{\frac{1}{8}}$. $\arccos{\frac{1}{8}}$ is approximately $82.819244218541^{\circ}$ and it's an irrational angle because the only rational values that correspond to rational angles for $\cos{\theta}$ are $\{-1, \frac{-1}{2}, 0, \frac{1}{2}, 1\}$. So what do we know about $\theta = \arccos{\frac{1}{8}}$?  It's irrational angle but is it an algebraic angle?  In general if $\cos \theta$ is rational does that tell us anything (beyond rationality) about $\theta$?","['transcendental-numbers', 'rationality-testing', 'trigonometry']"
1382653,"Existence of a solution for a nonlinear ODE on $[0,\infty)$","I'd like to prove that the solution to the following IVP exists on $[0,\infty)$. The IVP is given by $$ \begin{cases} 
      y'(t) = y^2 \cos(t)-ye^t  \\
      y(0)= y_0
   \end{cases}
$$
where $y_0 \in \mathbb{R}$. I've already established unique solvability in an interval around the origin, say $[0,\epsilon)$ for some $\epsilon>0$ because $f(y,t)=y^2 \cos(t)-ye^t$ is lipschitz in $y$ in a neighborhood of the origin. My usual strategy for showing a solution exists on such an interval is to try to find a upper/lower solution to make a bound for the solutions and thus use the bound to generate some information about what happens to the solution as $t \rightarrow \infty$. This, however, is difficult in this case because of the $e^t$ term. How might I show existence on $[0,\infty)$ given any initial condition, for $y_0$?","['real-analysis', 'ordinary-differential-equations']"
1382661,Looking for an alternative proof of the angle difference expansion,"I have thought about this for a while and have no progress.
Does there exist a purely Euclidean Geometric proof of the Angle Difference expansion for Sine and Cosine, for Obtuse angles?","['euclidean-geometry', 'trigonometry']"
1382663,Prove that every integer $n\geq 7$ can be expressed as a sum of distinct primes.,"My teacher said to use Bertrand's postulate and I have tried this for so long and I seem to go nowhere. Help would be appreciated. EDIT: Here's what I've done in my proof so far (I need help finalizing case 2) First note that for $p_0=13$, we can express all integers $7 \leq n \leq 2p_0=26$ as a sum of distinct primes less than or equal to $13$. 
Now, we will prove that we can construct these sums indefinitely. Assume we know some prime $p'$ exists such that every integer $7\leq n \leq 2p'$ can be expressed as a sum of distinct primes less than or equal to $p'$. Then, by Bertrand's postulate, there exists a prime $p$ such that $p'<p<2p'$. We claim now that every integer $7\leq n \leq 2p$ can be written as a sum of distinct primes less than or equal to $p$. Consider the two following cases Case 1: $2p'-p\geq 7$, hence $2p'\geq p+7$ so the terms $p,p+1,\dots,p+7$ are less than or equal to $2p'$ which means they can be written as a sum of distinct primes $\leq p'$ by hypothesis. It is left to check whether the terms $p+8,p+9,\dots, 2p$ satisfy our claim. Note if we subtract $p$ from every term in the arithmetic progression above, it becomes $8,9,\dots, p<2p'$ which shows that each term can be written as the sum of $p$ plus some other distinct primes less than or equal to $p'<p$ by hypothesis. Case 2: $2p'-p\leq 6$, hence $2p'\leq p+6$. Here we can see all terms $p+7,\dots, 2p$ satisfy our claim along with $p+2,p+3$ and $p+5$ by a similar argument as in Case 1. I'm not sure how to deal with $p+1,p+4,$ and $p+6$ though. EDIT: Oh, since any prime $p \geq 13$ is odd, then the only possible values for $2p'$ in Case 2 are $p+1,p+3$ and $p+5$, so I don't have to worry about the other cases. I think I'm done! EDIT: Nope, I still need to deal with $p+4$ and $p+6$.","['number-theory', 'elementary-number-theory']"
1382701,People sitting in a circle chewing gum,"Ten people are sitting in a circle of ten chairs, chewing gum. Each person spits out his or her gum and places it either under his or her own chair or under an immediately adjacent chair. How many ways can this happen such that every chair ends up with exactly one piece of gum under it? I tried creating a chart of small values, obtaining for n people, when n = {1, 2, 3, 4, 5}, $f_n$ = {1, 2, 6, 9, 13} At first I thought tribonacci, as soon as I saw $f_4$ but that notion vanished as I calculated $f_5$ Can someone provide a clear answer and or solution for $f_{10}$? Thanks.","['induction', 'combinatorics', 'fibonacci-numbers']"
1382714,Prove that if $\mathcal{F} \subseteq \mathcal{G}$ then $\cup\mathcal{F} \subseteq \cup\mathcal{G}$,"Suppose $\mathcal{F}$ and $\mathcal{G}$ are families of sets. Prove that if $\mathcal{F} \subseteq \mathcal{G}$ then $\cup\mathcal{F} \subseteq \cup\mathcal{G}$ My attempt : Given $\mathcal{F} \subseteq \mathcal{G}$, writing out logical form of Goal we have $$\exists A \in F(x \in A) \rightarrow \exists A \in G(x \in A)$$ Now assuming $\exists A \in F(x \in A)$ (putting it to list of givens), our Goal is now to obtain $$\exists A \in G(x \in A)$$ Now, applying Existensial Instantiation, let us assume there exists $A_{0}$, such that $A_{0}$ $\in F$. So now $x \in A_{0}$
I am feeling stuck here.Thanks EDIT","['elementary-set-theory', 'logic']"
1382737,What's the time complexity of $T(n) =\sqrt{99nT(\sqrt {n})+100n}$?,"What's the time complexity of  $T(n) =\sqrt{99nT(\sqrt {n})+100n}$ , I don't have an idea for solve the question. My attempt : $\frac{T(n)}{\sqrt {n}}^2 =99T(\sqrt {n})+100 $ and $\ s(k)= \frac{T(n)}{\sqrt {n}}$  but it's not useful .","['recurrence-relations', 'discrete-mathematics']"
1382755,"$n$-vertex $3$-edge-colored graphs with exactly $6$ automorphisms which preserve edge color classes, but permute the edge colors distinctly?","In each of these $3$-edge-colored graphs, there are exactly $6$ automorphisms which preserve the set of edge color classes: (These automorphisms don't necessarily map e.g. green edges to green edges, but if one green edge is mapped to e.g. a blue edge, then every green edge is mapped to some blue edge.) Moreover, in each example, each of these $6$ automorphisms permutes the colors differently. Question : For all $n \geq 3$, does there exist an $n$-vertex graph such that (a) we have exactly $6$ automorphisms which preserve the set of edge color classes, and (b) each of these $6$ automorphisms gives rise to a different permutation of the edge colors? These come from partial Latin rectangles with a certain symmetry.  E.g. the one on the right comes from
$$
\begin{bmatrix}
1 & 2 & 3 \\
2 & 3 & \cdot \\
3 & \cdot & \cdot \\
\end{bmatrix}
$$
by making the entries the vertex set and adding a green edge when two entries share a row, an orange edge when they share a column, and a blue edge when they share a symbol.  This partial Latin rectangle has a trivial autotopism group and an automorphism group isomorphic to $S_3$ (which gives rise to the symmetry property of the graph). It's possible that I might be able to reverse this construction, and construct interesting partial Latin rectangles this way.","['graph-theory', 'combinatorics']"
1382765,"Consider the function f(x)=sin(x) in the interval x=[π/4,7π/4]. The number and location(s) of the local minima of this function are?","This is MCQ of a competitive exam(GATE), Answer is (d) given by GATE , and from other sources ,explanation is (b) somewhere and (d) somewhere , I am going with (b) as minimum at $270$, I have drawn graph . but it produces two pictures , I confused , it asked Local minima of a trivial $\sin(x)$ function and explanation here , but didn't get obviously , finally I want to explanation . Problem is : Consider the function $f(x)=\sin(x)$ in the interval $x=[\pi /4,7 \pi /4]$. The
  number and location(s) of the local minima of this function are (A) One, at $\pi /2$ (B) One, at $3 \pi /2$ (C) Two, at $ \pi /2$ and $3 \pi /2$ (D) Two, at $\pi /4$ and $3 \pi /2$","['graphing-functions', 'calculus', 'functions']"
1382773,Free lattice in three generators,"By general results for every set $X$ there is a free bounded lattice $L(X)$ on $X$. I would like to understand the element structure of this lattice. The cases $X=\emptyset$, $X=\{x\}$ and $X=\{x,y\}$ are quite easy. But for $X=\{x,y,z\}$ we get an infinite lattice. But what are the elements explicitly? Is there any normal form available? Or, is there any natural representation of $L(X)$? Compare this to the free group on two generators, which might be quite abstract, but it can be explicitly realized as a certain subgroup of $\mathrm{SL}(2,\mathbb{Z})$, generated by two matrices (see Ping-pong lemma ). So is there a natural and non-abstract example of a bounded lattice which contains the free bounded lattice on three generators? Notice that the recursive description at Wikipedia doesn't answer these questions.","['abstract-algebra', 'lattice-orders', 'category-theory']"
1382799,$\lim x_n^{x_n}=4$ prove that $\lim x_n=2$ [duplicate],"This question already has answers here : Prove $\lim_{n\to\infty}x_n=2$ Given $\lim_{n \to \infty} x_n^{x_n} = 4$ (4 answers) Closed 8 years ago . Let $(x_n)$ be a sequence of real numbers, such that: $\lim x_n^{x_n}=4$, prove that $\lim x_n=2$ I'm not sure if my proof is right. I assumed that $\lim x_n $ isn't 2 and using Cauchy's criterion: $|x_n-2|>\epsilon$  so $ x_n>\epsilon+2$  or $x_n<-\epsilon+2$ $|x_n^{x_n}-4|<\epsilon $ so $x_n<\sqrt[x_n]{\epsilon+4}$ and then we combine what we've found and get:
$\epsilon+2<\sqrt[x_n]{\epsilon+4}$ $\epsilon+4<(\epsilon+2)^2<(\epsilon+2)^{\epsilon+2}<(\epsilon+2)^{x_n}<\epsilon+4$  and it's not true so  $\lim x_n=2$. Is that okay? Edit: I just wanted to know if my solution was right but the other post helped as well, thanks.","['sequences-and-series', 'calculus', 'proof-verification']"
1382806,Why this process is nonergodic?,"I am studying a tutorial on stochastic processes and there's an example in it which I don't understand anything of it. First of all there is this criterion for a mean-ergodic random process: For a WSS random process to be ergodic in the mean, the variance of
  the sample mean
  $$\operatorname{var} (\hat\mu_N)=\frac{1}{N}\sum_{k=-(N-1)}^{N-1}\left(1-\frac{|k|}{N}\right)(r_X[k]-\mu^2)$$
  must converge to zero as $N\to\infty$. 1- What is $r_X[k]$ in the formula and how is it computed? Then there is the following example: Define a random process as $X[n]=A$ where $A=N(0,1)$. The random
  process is WSS since $$\mu_X[n]=E[X[n]]=E[A]=0=\mu$$
  $$r_X[k]=E[X[n]X[n+k]]=E[A^2]=1$$ However, it should be clear that sample mean will not converge to $\mu$ In addition, it can be shown that var(sample mean)=1 Each realization is not representative of the ensemble of realizations. Assuminig that $A=N(0,1)$ is the standard normal distribution 2- How is it clear that sample mean does not converge to $\mu$? 3- Why var(sample mean)=1?","['average', 'random-variables', 'stochastic-processes', 'statistics', 'intuition']"
1382811,Div$f$ is invariant under an orthogonal change of coordinates,"Let $f: \mathbb{R^n} \to \mathbb{R^n}$ and $Df$ exists. I need to show that div$f$ is invariant under an orthogonal change of coordinates. Let $T:\mathbb{R^n} \to \mathbb{R^n}$ be an orthogonal transformation. Then Suppose that $$f(x_1,x_2,..,x_n)=(f_1(x_1,x_2,..,x_n),f_2(x_1,x_2,..,x_n),..,f_n(x_1,x_2,..,x_n))$$
Also suppose that $T(x_1,x_2,..,x_n)=(x'_1,x'_2,..,x'_n),T^{t}T=TT^{t}=I$ Let $X=(x_1,x_2,..x_n)$ and $X'=(x'_1,x'_2,..,x'_n)$ Now I want to use the fact that $divf=trace(Df)$. So I let $$g(X')=f(T(X))$$(considering them as a function of $X$ and $X'$ respectively) This is where I am stuck. Somehow on differentiating two sides I should have $DT$ and $(DT)^{-1}$ and that should do it for me. Thanks for the help!!","['vectors', 'calculus', 'multivariable-calculus']"
1382842,Basic Ordinary Differential Equation Help,"I have the following $3$rd order, non-linear, homogeneous differential equation: $$y''' + ey'' + y' + (d + e)y - dy^2 = 0,$$
where $d,e$ are constants. My questions: Have I classified this differential equation correctly? (3rd order, non-linear, homogeneous with constant coefficients) What is the independent variable? I haven't done calculus/linear algebra etc.. for approximately $2$ years, and hence, my skills are rusty. I'm panicking a little, and if you could direct me to some helpful resources I would appreciate that very much. Thanks",['ordinary-differential-equations']
1382856,Problem Solving Positive Integers,"This is a very interesting word problem that I came across in an old textbook of mine. So I know the maximum value of the HCF has to be a factor of $540$ and mayhaps the Euclidean Algorithm, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: Let $a_1, a_2, ... , a_{49}$ be positive integers such that $$a_1 + a_2 \ + \ ... \ + a_{49} = 540.$$
  What can be the maximum value of the highest common factor of the numbers $a_1, a_2, ... , a_{49}$?","['gcd-and-lcm', 'number-theory', 'integers', 'problem-solving', 'elementary-number-theory']"
1382857,Is reading old calculus books still beneficial for undergraduate students today?,"this is really a question about math and not books. I am mainly wondering if reading really old calculus books is still beneficial for undrgraduate students today. I was told that the material covered won't be of much benefit, things like curves, various mechanical integration methods, etc., and that I would be better off studying a 'calculus with an intro to analysis' type book like Apostol or Spivak's calculus. Is this true? Some specific examples of old books I have in mind are: Edwards: https://archive.org/details/anelementarytre01edwagoog Todhunter: https://archive.org/details/atreatiseondiff06todhgoog Williamson: https://archive.org/details/anelementarytre20willgoog One thing's for sure: The problems in these books are much harder than in modern books, which is very appealing to me coming from an olympiad background. So they aren't as far back as say Cauchy, but still are fairly old. I would still be interested however in knowing if something like Cauchy's Calcul Differentiel et Integral (I can read french!) is worth studying today; I know that Clerk Maxwell studied it at Edinburgh University for instance (before ""going up"" to Cambridge): https://archive.org/details/leonsdecalculdi02goog Thanks","['reference-request', 'calculus']"
1382863,Does $A\cap B =\varnothing \Rightarrow B\subseteq \overline{A}$?,"How to prove $A\cap  B =\varnothing \Rightarrow B\subseteq \overline{A}$?
If I going by definitions, there is no $x$ s.t  $x\in A$ and $x\in B$.
But, what do we can tell about $\overline{A}$? What i'm missing?",['elementary-set-theory']
1382920,Derivations of important algebras?,"After knowing the importance of studying derivations of an algebras( Why we wonder to know all derivations of an algebra? ), this problem naturally raised ""what is the space of all derivations of important algebras like algebra of matrices, cliford algebra, exterior algebra and C* algebras?""
has anybody studied on this problem? In graded cases we have the notion of super and graded derivations.
does this kinds of derivations for famous algebras obtained?
If so, I want to be familiar with references with geometrical looking. any hint is appreciated.","['differential-geometry', 'linear-algebra']"
1382940,"Why is the largest element of symmetric, positive semidefinite matrix on the diagonal?","I know the very well know equivalence of the properties of a positive, semidefinite matrix: $A$ is positive semidefinite, $A = U^T U$ for some matrix $U$, $\mathbf{x}^T A \mathbf{x}\geq 0$ for every $\mathbf{x} \in \mathbb{R}^n$, All principal minors $A$ are nonnegative. But how can you derive from this that the largest entry of the matrix $A$ appears on the diagonal and why - when a diagonal entry is equal to zero - are all the entries of the corresponding row and column also equal to zero?","['semidefinite-programming', 'matrix-decomposition', 'matrices']"
1382947,How to recognise intuitively which functions grow faster asymptotically?,"There are some cases where it is not so simple to decide which function grows faster asymptotically. For example, in the following cases, why (intuitively) $g(n)$ should grow faster than $f(n)$, or vice-versa? $$
\begin{array}{c|c}
f(n) & g(n)\\
\hline
10 \log(n) & \log(n^2)\\
\frac{n^2}{\log(n)} & n(\log(n))^2\\
n^{0.1} & \log(n)^{10}\\
\log(n)^{\log(n)} & \frac{n}{\log(n)}\\
\sqrt n & \log(n)^3\\
n\,2^n & 3^n\\
\log(n)^{\log(n)} & 2^{(\log_2 n)^2}
\end{array}
$$ It is easy to type some values on a calculator or to plot the functions to see which one grows faster, but during an exam I cannot do this of course.","['calculus', 'limits', 'logarithms', 'functions', 'asymptotics']"
1382966,Proving that the coordinate basis is a basis of a tangent space,"Given a differentiable manifold $M$ and some chart $(U, \psi)$ near $p$, we can consider the curve $\tilde{\beta}_i: t \mapsto \psi(p)+t e_i$, where $e_i$ denoted the standard basis in $\mathbb{R}^n$, $i \in \{1, \dots, n\}$. Now we can set $\beta_i := \psi^{-1} \circ \tilde{\beta}_i$ to get the corresponding curve on $M$ and we can define the corresponding tangent vector by $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} u := \left.\frac{d}{dt}\right|_{t=0} u(\beta_i(t))$$ for all $u \in C^{\infty}(M)$. We can quickly verify that this is indeed well-defined. A quick computation also shows that any linear combination of these vectors still lies in $T_pM$ and that they span $T_pM$. To show that they form a basis, it is left to show that they are linearly independent. We have done a proof in class where at some point I must have made a typo or I simply fail to understand what is happening. There exists a cutoff function $\rho: \mathbb{R}\to\mathbb{R}$ that is smooth and satisfies
  $$\rho(x) = \begin{cases}1 & x \in (-\frac{1}{2},\frac{1}{2})\\ 0 & x \in (-\infty, -\frac{3}{4}] \cup [\frac{3}{4},\infty)\end{cases}.$$
  For $j \in \{1,\dots,n\}$ define $\varphi_j: M \to \mathbb{R}$ by
  $$\varphi_j(q) := \begin{cases} 0 & q \notin U\\ \left(\prod_{i=1}^n \rho \left(\frac{\psi^i(q)-\psi^i(p)}{\varepsilon}\right)\right)\psi^j(q) & q \in U \end{cases}.$$
  Then, $\varphi_j \in C^{\infty}(M)$ and $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij},$$
  which implies that they are linearly independent. Question 1: What is $\varepsilon$? In an earlier class we defined tangent vectors as linear maps arising as a directional derivative along some smooth curve $\gamma: (-\varepsilon,\varepsilon)\to M$ with $\gamma(0)=p$. This doesn't make any sense in the proof because we can choose $\varepsilon$ rather freely. I am pretty sure this must be a typo, so the real question is: What should the definition of $\varphi_j$ actually be? Question 2: What does the function $\varphi_j$ do? Question 3: Why does $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij}$$ imply that the coordinate basis vectors are linearly independent?",['differential-geometry']
1382996,the unit group of an infinite field cannot be cyclic [duplicate],"This question already has answers here : Why must a field whose a group of units is cyclic be finite? (4 answers) Closed 8 years ago . It is well-known that the unit group of a finite field is a finite cyclic group. But for infinite fields, e.g., $\mathbb{Q}$ or $\mathbb{R}$, the unit groups are not cyclic. I heard this fact in my class and I'm trying to prove it. Assuming the unit group is infinite cyclic with the generator $a$, I tried to show some element, $\frac{1}{a+1}$ or $\frac{1}{a^2+1}$ cannot be a power of $a$, but it doesn't seem hopeful. Could someone help me?",['abstract-algebra']
1383010,compute temporal average of $\sin(\omega_0t+\Phi)\sin(\omega_0t+\omega_0\tau+\Phi)$,"assuming that $\Phi$ is uniformly distributed over $(0,2\pi)$ compute:
$$E[\sin(\omega_0t+\Phi)\sin(\omega_0t+\omega_0\tau+\Phi)]$$
I have solved the problem as continues: $$\begin{align}
E[\sin(\omega_0t+\Phi)\sin(\omega_0t+\omega_0\tau+\Phi)]&=\frac{1}{2\pi}\int_0^{2\pi}\sin(\omega_0t+\Phi)\sin(\omega_0t+\omega_0\tau+\Phi)\,dt\\
&=\frac{1}{4\pi}\int_0^{2\pi}(\cos(\omega_0\tau)-\cos(2\omega_0t+2\Phi+\omega_0\tau))\,dt\\
&=\frac{1}{4\pi}[t\,cos(\omega_0\tau)-\frac{1}{2\omega_0}\sin(2\omega_0t+2\Phi+\omega_0\tau)]_0^{2\pi}\\
&=\frac{1}{4\pi}[(2\pi)\cos(\omega_0\tau)-\frac{1}{2\omega_0}(\sin(4\pi\omega_0+2\Phi+\omega_0\tau)-\sin(2\Phi+\omega_0\tau))]\\
&=\frac{1}{2}\cos(\omega_0\tau)-\frac{1}{8\pi\omega_0}(\sin(4\pi\omega_0+2\Phi+\omega_0\tau)-\sin(2\Phi+\omega_0\tau))
\end{align}$$ but the book that I am studying has written $\frac{1}{2}\cos(\omega_0\tau)$ as the answer could you tell me what am I doing wrong? P.S. $\sin(\omega_0t+\Phi)\sin(\omega_0t+\omega_0\tau+\Phi)$ is a stochastic. if I integrate with respect to $\Phi$ I'll get ensemble average but if I integrate with respect to time I'll get temporal average. here I'm trying to compute the temporal average but I'm totally not sure about the interval of integration","['expectation', 'stochastic-processes', 'statistics', 'trigonometry', 'integration']"
1383012,How to change a $9\times 16$ rectangle to $12\times 12$ square?,"Given a $9\times 16$ sq. unit rectangle. You have one change, you can cut the $9\times 16$ sq. unit rectangle only once and join the two parts to get a square of dimension $12\times 12$ sq. unit. Note : $9\times 16=12\times12$ I don't have any proof but I think that answer is not possible because (case i) you cut the $9\times 16$ rectangle into two rectangles, with this you cannot make the $12\times 12$ rectangle, (case ii) you cut the $9\times 16$ rectangle into two hexagons. I'm defending my case (i) with the reason that $9$ and $16$ are co-primes. I don't have any mathematical reason to defend my case (ii). My questions 1. Is it possible to transform $9\times 16$ sq. unit rectangle to a $12\times 12$ sq. unit square with only one chance to cut and rejoin the original rectangle( note that rotation of parts are allowed). 2. If not possible then what is the smallest number of chance(cutting and rejoining) required to accomplish the job.",['geometry']
1383018,Largest jumps of a spectrally positive $\alpha$-stable process,"Let $X(.)$ be a (strictly) $\alpha$-stable process (with $\alpha \in (1,2)$). Assume also that $X(.)$ is spectrally positive (its Lévy measure is concentrated in $[0,+\infty)$). I am looking for a result that qualitatively says that the set of jumps heights of $X(.)$ is unbounded. More formally, define $J_t(x(.)) := \sup_{0\leq s \leq t} \{\vert x(s) - x(s^-)\vert\}$. Is it true that \begin{equation}
J_t(X(.)) \stackrel{t\rightarrow\infty}{\longrightarrow}  + \infty\qquad \mathrm {a.s.}
\end{equation}
or any other suitable convergence?","['levy-processes', 'probability', 'stochastic-processes']"
1383028,Existence of a function,"I need some help:
I am thinking about this problem. Any advice would be appreciated. Let's fix $\epsilon>0$. Does there exists some $f\in C^0([0,\pi])$ such that: $f\mid_{[\epsilon,\pi-\epsilon]}>0$ $f=\sum_{k=3}^\infty{a_k\cos(kx)+b_k\sin(kx)}$? Thanks :)","['approximation', 'fourier-analysis', 'functional-analysis']"
1383046,"Difficult to read about different subjects simultaneously, should I leave one for now? [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I learn math by reading books. Usually I read 3 books (about 3 different subjects) simultaneously and switch focus every couple of days. The books i'm studying right now are Rudin's functional analysis, Aluffi's algebra, and Jefferey Lee's Manifolds and differential geometry. Recently I find it very hard to switch to Rudin's book. It feels like a totally different realm and whenever I pick it up (again) I spend a lot of time building up my motivation and interest in the topic. Apart from being frustrating, it feels like an inefficient use of my time. Don't get me wrong, I Love functional analysis and think it's beautiful (and Rudin's book fits me quite well). It's just hard for me to routinely switch between these subjects since I'm still in the level where they don't interact that much. Whereas differential geometry and algebra are pretty much fused in my brain to a big blob that can grow in either direction. I'm not asking for examples where functional analysis touches algebra or differential geometry. I am very much aware of a lot of connections. (geometric analysis/operator algebras for example). What i'm asking is what of the 2 should i do: Leave Rudin's book for when you'll have a more concrete motivation to read it and pick up the next book on the list and read on some other topic you're passionate about (algebraic topology, algebraic curves). Something closer to your current mindset (but not too close since you do want to have experience with different types of math). Flow is important! Grind through this phase and continue to switch between the topics. Eventually you'll develop flexibility and it would be easier. You'll gain a lot from this. Flexibility is important! So, what should i do? I realize this is highly opinion based but i think a detailed answer about the pros and cons of learning about different subjects simultaneously will help many self learners like myself.","['education', 'learning', 'functional-analysis', 'abstract-algebra', 'differential-geometry']"
1383051,Show that $f$ is continuous at $0$ and it satisfies the Cauchy-Riemann conditions but it is not differentiable.,"Let $f:\Bbb{C}\to \Bbb{C}$ be defined as $$f(x+iy)= \frac{x^{3}-y^{3}+i(x^{3}+y^{3})}{x^2+y^2} \text{ if} x+iy \neq 0$$ and $f(x+iy)=0$ if $x+iy=0$ Show that $f$ is continuous at $0$ and it satisfies the Cauchy-Riemann conditions but it is not differentiable Ok, so I'm getting messed up when trying to check the continuity. Of course I have to check that $$\lim_{x+iy \to 0}f(x+iy) = 0$$ However, my doubt is the following: I am aware of a result (I have already proved) that says that $$\lim_{z\to z_0} f(z) = a + ib \text{ iff } \lim_{z\to z_0}\operatorname{Re}(f(z)) = a  \text{ and } \lim_{z\to z_0} \operatorname{Im}(f(z)) = b$$ However, with the use of this result (or not), I'm getting mixed up with the $x+iy \to 0$ . Does this imply taking $|x+iy|=x^2+y^2 < \epsilon$ for every $\epsilon >0$ ? And so, how can I proceed? Should I encounter this limit by definition or is there another way?",['complex-analysis']
1383052,"If $|f| \le |g|$, does analytic continuation of $g$ imply analytic continuation of $f$?","Let $f,g$ be two holomorphic functions on a domain $D$ such that $|f(z)| \le |g(z)|$ for all $z \in D$. Further suppose that there is an analytic continuation of $g$ to a bigger domain $D'$. Does that imply that there will be an analytic continuation of $f$ on $D'$? If so, will it be necessarily true that $|f(z)| \le |g(z)|$ for all $z \in D'$?","['maximum-principle', 'analytic-continuation', 'complex-analysis']"
1383071,structure theorem for Banach spaces,"The following is a theorem in the Banach Algebra Techniques in Operator Theory by Douglas: Here are my questions : Could one come up with some reference (or proof) regarding the remark right after the proof: if $\mathscr{X}$ is separable, then $X$ can be taken into the closed unit interval $[0,1]$? Why does the remark say that the canonical $X$ associated with $\mathscr{X}$ is absent? Isn't it $(\mathscr{X}^*)_1$ (the closed unit ball in $\mathscr{X}^*$)?",['functional-analysis']
1383079,Weak convergence of a sequence of stationary distributions to another stationary distribution,"Let $\{X_n(t) \in \mathbb{R}^+\}$ for each $t \in (0,1)$ denote a discrete time Markov chain (with time index $n$ and parameterized by $t$). For each $t$, the Markov chain $\{X_n(t)\}$ has a unique stationary distribution, $X_{\infty}(t) \in \mathbb{R}^+$, i.e.,
$$X_n(t) \rightarrow^w X_{\infty}(t). $$ Suppose for each $n$, $X_n(t)$ converges weakly to $\overline{X}_n$ as $t \rightarrow 0$, i.e., 
$$X_n(t) \rightarrow^w  \overline{X}_n$$ The sequence $\{\overline{X}_n \in \mathbb{R}^+\}$ is also a Markov chain. Suppose it has a unique stationary distribution $\overline{X}_{\infty} \in \mathbb{R}^+$, i.e.,
$$\overline{X}_n \rightarrow^w  \overline{X}_\infty.$$ Are there general conditions under which $X_{\infty}(t)$ converge to $\overline{X}_{\infty}$ as $t \rightarrow \infty$, i.e., 
$$ X_{\infty}(t) \rightarrow^w \overline{X}_{\infty}.$$ I believe that the above problem would require some justification for an exchange of limits. I want to know if under Markovian conditions there are some results which justify these results.","['probability-theory', 'weak-convergence', 'markov-chains', 'stochastic-processes']"
1383087,How to solve this exponential equation?,"I'm given this equation and i have to solve for the x. $$ e^{2x} -(e^5 + e^2)e^x + e^7 = 0      $$ The results should be $x =2$ and $x = 5$. At first i thought it would be an easy task, substituting $e^x$ with $y$, but I can't get rid of the coefficients. I'm sorry if this question is too simple for this site but I'd be really grateful if you could explain me. Thanks for your kindness.",['algebra-precalculus']
1383094,On finding special kinds of power series,"Let $\sum a_n x^n$ be a real power series with finite positive radius of convergence $R$, then is it true that for every real number $s>0$ , we can find a real sequence $\{b_n\}$ (depending on $s$, of course) such  that $\sum b_n x^n$ has radius of convergence $s$ and $\sum a_nb_nx^n$ has radius of convergence $R$ ? Moreover, can we find a sequence $\{b_n\}$ such that $\sum b_nx^n$ converges everywhere and $\sum a_nb_n x^n$ has radius of convergence $R$ ?","['power-series', 'analysis', 'convergence-divergence', 'real-analysis']"
1383105,Theorem 12.13 of Apostol's Mathematical Analysis (2nd Ed),"I had a little difficulty understanding Theorem 12.13 of Apostol's Mathematical Analysis, and was wondering if someone who had read this book could give me some pointers.  Specifically, on page 360, the author writes "" As a consequence of Theorem 12.11 and 12.12 we have Theorem 12.13 If both partial derivatives $D_{r}f$ and $D_{k}f$ exist in an n-ball $B(c)$ and if both $D_{k,r}f$ and $D_{r,k}f$ are continuous at c, then $D_{k,r}f(c) = D_{r,k}f(c)$. "" My understanding is that we're using Theorem 12.11 to establish the differentiability of $D_{r}f$ and $D_{k}f$ so that we can use Theorem 12.12 to assert the equality of $D_{k,r}f(c) = D_{r,k}f(c)$.  If so, my question is: why shouldn't we require $D_{r,r}f$ and $D_{k,k}f$ also exist at c? For convenience, I typed Theorem 12.11 & 12.12 below: "" Theorem 12.11 Assume that one of the partial derivatives $D_{1}f,...,D_{n}f$ exists at c and that the remaining n-1 partial derivatives exist in some n-ball $B(c)$ and are continuous at c.  Then $f$ is differentiable at c. Theorem 12.12 If both partial derivatives $D_{r}f$ and $D_{k}f$ exist in an n-ball $B(c)$ and if both are differentiable at c, then $D_{k,r}f(c) = D_{r,k}f(c)$. """,['real-analysis']
1383107,Does given point satisfy FONC?,"minimize $4x_1^2+2x_2^2-4x_1x_2-8x_2$ subject to $x_1+x_2\leq 4$ Does the point $(2,2)$ satisfy the FONC for a local minimizer? The gradient of the objective function is $\nabla f = \begin{bmatrix} 8x_1^2-4x_2-4x_2 \\ 4x_2^2-4x_1-8\end{bmatrix}$ = $\begin{bmatrix} 0\\0 \end{bmatrix} $ Filling in the point should give $0$ but it doesn't so the answer is no. Is this correct or do I have to use Lagrange?","['optimization', 'multivariable-calculus']"
1383113,Poisson Process Derivation.,"I was looking at a derivation for the poisson process , which tells the number of events occurring in time $t$ , I came across the following differential equation : $\frac{d}{dt}(P_n(t))$ = $\lambda[P_{n-1}(t) - P_n(t)]$ , but i have no idea how to tackle this differential equation , Here , $P_n(t)$ = Probability that $n$ events occur in time interval $t$. Probability that $0$ events occur in time interval $t$ is given as : $P_0(t)$ = $e^{-\lambda t}$ , Also , how can we take $P_n(t+dt)$ = $P_n(t)$ + $dt*\frac{d}{dt}(P_n(t))$ , where , $P_n(t+dt)$ is the probability that $n$ events occur in the time interval $t+dt$. Kindly help me with this...","['probability', 'ordinary-differential-equations']"
1383126,"Can a bidegree $(3,4)$ curve be embedded in plane?","Suppose $C$ is a curve on $\mathbf{P}^1\times\mathbf{P}^1$ of bidegree $(3,4)$, why such a curve cannot be embedded as a curve in $\mathbf{P}^2$?","['algebraic-geometry', 'algebraic-curves']"
1383148,Is an infinite system of (linear) equations solvable if all finite subsystems are?,"I was wondering about the following. Let $A$ be an abelian group, $a_i$ variables indexed with some arbitrary set $I$ and assume we have an infinite set $E$ of linear equations in finitely many variables of the form
$$n_1a_1 + \ldots + n_ka_k = b$$
with $n_i \in \mathbb Z, b \in A$. If this system has no solution, then is there already a finite subset of equations in $E$ which are inconsistent? So if any finite subset of equations is solvable, is $E$ solvable? This is reminiscent of the compactness theorem in 1st order logic, but of course you can't apply this for a concrete group. Am I missing something? I assume that this has an easy proof or a counterexample. What happens if we presume particularly nice groups (divisible, free) or vector spaces? Then this question is just about linear systems of equations. Thanks for giving some insight","['logic', 'group-theory', 'linear-algebra']"
1383149,Schwarz Reflection Principle on a unit disk,"Suppose $f$ is a analytic function defined on $\bar{D}(0;1)$ and has real value on the boundary. I'm trying to show $f$ can be extended to entire plane by $$g(z) = \begin{cases}f(z) &, \lvert z\rvert \leqslant 1\\ \frac{1}{\overline{f(\overline{z}^{-1})}},  &, \lvert z\rvert > 1\end{cases}
$$
I tried to use $\gamma(z)=e^{iz}$, which sends real axis to unit circle, for Schwarz Reflection Principle. But I did not get the result. May I get a help?",['complex-analysis']
1383157,Does a choice of measure on $\mathfrak{g}$ induce a measure on $G$?,"Let $G$ be a Lie group with Lie algebra $\mathfrak{g}$. One can put a (left) Haar measure $\mu$ on $G$ and a Lebesgue measure $\lambda$ on $\mathfrak{g}$ which are both unique up to constants. My question is whether fixing $\mu$ on $G$ picks out $\lambda$ uniquely on $\mathfrak{g}$ and conversely. I think a natural first step in answering this question is to consider the exponential map $\exp:\mathfrak{g}\to G$ and try to use the change of variables formula. However there are two issues that one faces: The exponential map is in general a local diffeomorphism only. The Lebesgue measure transferred from $\mathfrak{g}$ to $G$ via the change of variables formula need not be a Haar measure:
$$\int_G f(g)\, d\mu(g):=\int_{\mathfrak{g}}f(\exp X) |\mathrm{Jac}\exp|\, d\lambda(X) $$ Can someone please shed some light on the relation between the measures on the Lie group and the Lie algebra and resolving the above two issues? (I think the first issue is not severe, as $\exp$ is a local diffeomorphism and that should be enough for transferring the measure from one side to the other, if at all possible for a group $G$.) Thanks in advance for any comments/answers.","['lie-groups', 'lie-algebras', 'measure-theory']"
1383192,Closed form of series involving Fibonacci numbers,"Let $F_n$ denote the $n$-th Fibonacci number and $\phi$ be the golden ratio, that $\phi = \frac{1+\sqrt{5}}{2}$. Find a closed form for the sum: $$\sum_{n=0}^{\infty} \frac{1}{(5\phi)^n(n+2)} \sum_{k=0}^{n} \frac{F_{k+1} F_{n-k+1}}{k+1}$$ I don't know how to tackle the sum. A closed form exists as the book suggests but there is no hind nor answer on how to tackle it. And I have not come up with some idea to kill this sum. Can anyone help me find a closed form?","['sequences-and-series', 'real-analysis', 'fibonacci-numbers']"
1383200,Solving functional equation $e^xf(y)+e^yf(x)=2e^{x+y}-e^{x-y}$ gives incorrect function,"Let $f:\mathbb{R} \to \mathbb{R}$ be a function which satisfies $e^xf(y)+e^yf(x)=2e^{x+y}-e^{x-y}$ for all real $x$ and $y$ . If I place $x=y$ , I get $f(x)=e^x-\frac{1}{2}e^{-x}$ which does not satisfy the original equation. Now instead, if I set $x=y=0$ , I get $f(0)=\frac{1}{2}$ . Now setting $y=0$ in the original equation, I get $f(x)=\frac{e^x}{2}$ . My question is that why do we get incorrect and different solutions if we proceed in the ways mentioned above? Also, what is the correct solution of this functional equation and how can I find it?","['functional-equations', 'functions']"
1383201,"Two disjoint number fields $K$, $L$ such that $(\mathrm{disc}({\cal O}_K), \mathrm{disc}({\cal O}_L))\neq 1$ but ${\cal O}_L{\cal O}_K={\cal O}_{KL}$","I know that if two disjoint number field $K$, $L$ are such that $(\operatorname{disc}(\mathcal{O}_K), \operatorname{disc}(\mathcal{O}_L))= 1$ then $\mathcal{O}_L\mathcal{O}_K=\mathcal{O}_{KL}$. It is true the converse or there are some counterexamples? EDIT. Is pretty standard notation but with $\mathcal{O}_K$ I denote the integer closure of $\mathbb{Z}$ in $K$, if $K$ is a finite extension of $\mathbb{Q}$. Then $\operatorname{disc}(\mathcal{O}_K)$ is just the discriminant of $\mathcal{O}_K$.","['number-theory', 'algebraic-number-theory']"
1383207,"On extended real line, is $(-\infty,+\infty)$ still a closed set?","On real line $(-\infty,+\infty)$ is open as well as closed. On extended real line $[-\infty,+\infty]$, is $(-\infty,+\infty)$ still a closed set? Thank you.","['real-analysis', 'general-topology']"
1383220,Integrating the Hopf invariant for $\pi:S^3\to S^2$,"I've been working on the last part of problem 9., chapter 9 in Nakahara's Geometry, Topology and Physics all day, with no success, and am in need of some assistance. We are asked to compute the Hopf invariant of $\pi:S^3\to S^2$, where given $S^3 = \{\mathbf x = (x^1,x^2,x^3,x^3)\in\mathbb R \,|\, \|\mathbf x\|=1\}$, and similarly given $S^2$ (where we write the points as $(\xi^1,\xi^2,\xi^3)$), the map $\pi$ is defined by 
$$\xi^1=2(x^1x^3+x^2x^4)\\
\xi^2=2(x^2x^3-x^1x^4)\\
\xi^3=(x^1)^2+(x^2)^2-(x^3)^2-(x^4)^2.$$ But consider for now just some general $f:S^{2n-1}\to S^n$. Let $\Omega_n$ be a volume form on $S^n$ normalized to 1, and consider its pullback $f^*\Omega_n$. We verify it is closed and can be written as $f^*\Omega_n=d\omega_{n-1}$, $\omega_{n-1}\in \Omega^{n-1}(S^{2n-1})$.
The Hopf invariant is defined as $$H(f)\equiv \int_{S^{2n-1}}\omega_{n-1}\wedge\mathrm d \omega_{n-1}.$$ After a few more questions, we are asked to compute $H(\pi)$, with $n=2$. My approach was to take the god given volume element $vol_{\mathbb R^3}=\mathrm d\xi^1\wedge\mathrm d\xi^2\wedge\mathrm d\xi^3$ and take the interior product with a vector field everywhere normal to the 2-sphere, $N=\sum_i \xi^i\partial_{\xi^i}$, to obtain the volume form on $S^2$, $$vol_{S^2}=\xi^1 \mathrm d\xi^2\wedge\mathrm d\xi^3-\xi^2 \mathrm d\xi^1\wedge\mathrm d\xi^3+\xi^3 \mathrm d\xi^1\wedge\mathrm d\xi^2.$$ I don't care about the normalization yet so I take this to be $\Omega_2$. However, when I pull it back with $\pi$ the result is horribly long, and I won't even post it here. After that, I have, modulo my own errors in arithmetic, the result $\mathrm d \omega_1$, but I also need $\omega_1$. Everything just seems hopeless. I could get it by solving a system of PDEs but that seems also inaccessible. I found a similar calculation in Topology for physicists by Schwarz and Levy, p.165: The (7.4.1) they mention is just the integral definition of the invariant, whereas (6.3.1) is a volume form for the n-sphere $$\omega = \frac{1}{(1+\sum (x^i)^2)^n} \mathrm dx^1\wedge\dots\wedge\mathrm dx^n.$$ They haven't specified $f:S^3\rightarrow S^2$ anywhere, and their entire calculation is unclear to me. How did they get the one-form $\sigma$? In one of the questions, we are asked to prove that the invariant does not depend on the choice of $\omega_{n-1}$ - so did the authors simply take $d\omega_{n-1}$ to be the volume form (6.3.1) on the 2-sphere in spherical coordinates? Still, how did they get $\omega_1=\sigma$? Can anyone explain? And, again, is the direct approach that Nakahara asks even doable? Or does it need to be a bit more indirect :)","['differential-geometry', 'differential-forms', 'general-topology']"
1383229,Vector Field Conceptual Question,"Given that:
$$F = \langle yz-2xy^2, axz-2x^2y+z, xy+y \rangle$$
in which $a$ is some constant. Now, for what $a$ would make the vector field of $F$ conservative? Why is there only one, or are there many? How can we find an $f$ with $\nabla f=F$? Also for what $a$ would $F$ be the curl of another vector field? For to find for which $a$ the vector field is conservative, do we have to go through the process of finding partial derivative, or is there a much shorter approach. I don't know how to approach my other questions either.",['multivariable-calculus']
1383232,$|f(x)-f(y)| \geq \frac{|x-y|}{2}$,"Let $f:\mathbb{R} \to \mathbb{R}$ be a continuous function such that $|f(x)-f(y)| \geq \frac{|x-y|}{2}$ then prove $f$ is onto. I can prove it just using IVT, but looking for some short solution which is using some good argument.","['analysis', 'continuity']"
1383251,"In how many ways can the group $\mathbb Z_5$ act on the set $\{1,2,3,4,5\}$ $?$","$\mathbb Z_{5}$ is the group to act on the set $\{ 1,2,3,4,5\}$ . In how many ways is that possible?
Now $0$ will give the identity map. $1$ will give a  bijection in $5!$ ways so will the others and the number of possible bijections being $5!$ the bijections given by $1$ will coincide with those given by others. All get mixed up here.","['abstract-algebra', 'group-theory', 'group-actions', 'cyclic-groups', 'combinatorics']"
1383270,Solution to Diophantine equation $\frac{1}{x^2}+\frac{1}{y^2}=\frac{1}{z^2} $,"I have to prove the following, but I don't know how to start. The only solutions in positive integers of the equation
  $$
  \frac{1}{x^2}+\frac{1}{y^2}=\frac{1}{z^2} \qquad \gcd(x,y,z)=1
  $$
  are given by
  $$
  x=2st(s^2+t^2) \qquad y=s^4-t^4 \qquad z=2st(s^2-t^2)
  $$
  where $s,t$ are relatively prime positive integers, one of which is even, with $s>t$. I tried the following. After multiplying the equation by $x^2y^2z^2$, you get:
$$
(yz)^2+(xz)^2=(xy)^2,
$$
which is a Pythagorean equation of the form $x^2+y^2=z^2$, which has solutions $x=2st$, $y=s^2-t^2$ and $z=s^2+t^2$ with some conditions. But I don't think this is a good approach. Any hints on how to start/continue with this problem are very much appreciated!","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1383271,Can it be proved without the axiom of choice that every cardinal is comparable with every finite cardinal?,"Can it be proven in ZF, without using the axiom of choice, that every finite set is a universal size comparator, meaning, is comparable with every set in terms of size? And what is the proof?","['elementary-set-theory', 'axiom-of-choice', 'cardinals']"
1383284,"$f$ is an analytic function in the disk $D=\{z\in\mathbb{C}\,:\,|z|\leq 2\}$ such that $\iint_D=|f(z)|^2\,dx\,dy\leq 3\pi$. Maximize $|f''(0)|$","Determine the largest possible value of $|f''(0)|$ when $f$ is an analytic function in the disk $D=\{z\in\mathbb{C}\,:\,|z|<2\}$ with the property that $\iint_{D}|f(z)|^2\,dx\,dy\leq 3\pi$. I don't really know what to do with the assumption that $\iint_D|f(z)|^2\,dx\,dy\leq 3\pi$. I believe you could use Stokes' theorem to rewrite this as a line integral on $\partial D$, but I'm really rusty with my usage, so I'm kind of stuck. If I could get a bound on $\int_{\partial D}|f(z)|^2\,dz$, I could probably use harnack's inequality for subharmonic functions to get a bound on $|f|$ then Cauchy's inequality, however I'm not very sure about my usage of green's theorem (if that's even the right way to go) any help is greatly appreciated. Thanks","['greens-theorem', 'complex-analysis']"
1383292,Is there a polynomial $p$ such that it is bijective and $ p: \mathbb{Q}^n \rightarrow \mathbb{Q}$ for $ n>1$ ??,"Let us define a polynomial $p$   defined as follow $$p: \mathbb{Q}^n \rightarrow \mathbb{Q}.$$ I acrossed this question in mind. Is there a polynomial $p$ such that it is bijective and  $p: \mathbb{Q}^n \rightarrow \mathbb{Q}$ for $n>1$   ? Note : $p$  is polynomial with $n$  variables $p(x_1,\dots x_n)$. Thank you for any help","['abstract-algebra', 'polynomials', 'applications', 'inverse']"
1383295,Finding a basis of a complex vector space over $\Bbb R$ given a basis over $\Bbb C$,"Suppose $X$ is a vector space over $\mathbb C$ and  has as basis $\{e_1,e_2,\ldots,e_n\}$. Now regard $X$ as a vector space over $\mathbb R$. What will be the basis? My thoughts: I considered $\mathbb C$ over $\mathbb C$ and $\mathbb C$ over $\mathbb R$.In the first case we have $(1,0)$ as basis and in the latter case we have $\{(1,0),(0,1)\}$ as basis i.e. $\{(1,0),(0,1)(1,0)=(0,1)\}$ as basis. So may be the answer is $\{e_1,e_2,\ldots,e_n,ie_1,\ldots,ie_n\}$. How to justify the result if its true?","['vector-spaces', 'linear-algebra']"
1383330,On the definition of a filter: Isn't $\emptyset$ a subset of any set?,"Beginning my study of nonstandard analysis, I have found this definition of a filter U on a set J, where A, B are subsets of J: Proper filter: $\emptyset \not\in U$, Finite intersection property: If $A, B\in U$, then $A\cap B\in U$, Superset property: If $A\in U$ and $A\subseteq B$, then $B\in U$. It seems to me that (3) contradicts (1), since any set in the filter has ∅ as a subset. Is this untrue? If so, could someone please explain how ∅ isn't a subset of any set?","['elementary-set-theory', 'filters']"
1383345,How to prove there are no solutions to $a^2 - 223 b^2 = -3$.,"As the title suggests, I'm trying to prove that there are no solutions to $a^2 - 223b^2 = -3$ (with $a,b\in \mathbb{Z}$).  Ordinarily, taking both sides $\mod n$ for some clever choice of $n$ proves that no solutions exist, but I've tried this method for $n = 2$ through $18$, and all have solutions.  Moreover, we have that \begin{align}
\left(\frac{-3}{223} \right) &= \left(\frac{220}{223} \right)=\left(\frac{55}{223} \right) = \left(\frac{11}{223}\right)\left(\frac{5}{223}\right) \\
&= -\left(\frac{223}{11}\right)\left(\frac{223}{5}\right) = -\left(\frac{3}{11}\right)\left(\frac{3}{5}\right) \\
&= -(1)(-1) = 1, \end{align}
so $-3$ is a square $\mod 233$, so Legendre symbols aren't much of a help. I suppose if I keeping taking both sides $\mod n$ for increasingly large $n$, then I'll eventually get the answer, but there must be a more intelligent way to do this.  Any help is appreciated. As a bit of background, this came up in a proof that the ideal class group of $\mathbb{Z}[\sqrt{223}]$ is $\mathbb{Z}/3\mathbb{Z}$.  In this post , the OP casually states that there is no element of norm $-3$, and this is not an obvious fact to me.","['algebraic-number-theory', 'number-theory', 'elementary-number-theory']"
1383362,On any continuous map $f:S^1 \to \mathbb R$,"Let $f:S^1 \to \mathbb R$ be any continuous map , where $S^1$ is the unit circle in the plane . Let $A:=\{(x,y) \in S^1 \times S^1 : x \ne y , f(x)=f(y)\}$ ; then how to prove $A$ is uncountable , or to atleast prove $A$ is infinite ?","['analysis', 'metric-spaces', 'continuity', 'general-topology']"
1383373,Math Subject GRE 1268 Question 55,"If $a$ and $b$ are positive numbers, what is the value of $\displaystyle \int_0^\infty \frac{e^{ax}-e^{bx}}{(1+e^{ax})(1+e^{bx})}dx$. A: $0$ B: $1$ C: $a-b$ D: $(a-b)\log 2$ E: $\frac{a-b}{ab}\log 2$ I really don't see how to start this one, I'm not so great with integrals.","['gre-exam', 'calculus', 'integration']"
1383380,In which sense does Cauchy-Riemann equations link complex- and real analysis?,"On page 12 of Stein, Shakarchi textbook 'Complex analysis', the authors state that the Cauchy-Riemann equations link complex and real analysis . I have completed courses on real and complex analysis, but I feel that this is somewhat of an over-statement. But perhaps it is just me which doesnt have a good enough overview. $$
\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \qquad \frac{\partial u}{\partial y} = - \frac{\partial v}{\partial x}
$$ If anyone with a clear insight is able to concisely explain how one could justify writing something like this -- then that insight would be most valuable.","['complex-analysis', 'real-analysis']"
1383384,what is wrong with this natural log conversion,"why can't we convert this: $$4e^{1+3x}-9e^{5-2x}$$
to this: $$(1+3x)\ln(4)-(5-2x)\ln(9)$$
or this: $$(1+3x)\ln(4)+(5-2x)\ln(-9)$$ this comes from the q, solve: $$4e^{1+3x}-9e^{5-2x}=0$$
do the above conversions not work because of the ln of $0$? (that's why I posed it first without the $= 0$) or independently of that issue?",['algebra-precalculus']
1383397,Cutting a Banach-Tarski Cake,"I was reading a cake-cutting problem here (not really related, so I won't link to it), and for some reason, this variation occurred to me.  I have no idea whether this problem is even well-formed: Alice and Bob have bought a cube-shaped cake, $10$ cm on a side.  Alice makes one ordinary linear cut dividing the cake into two ordinary parts (she does not separate the parts, however), and Bob selects a piece* that is a subset (not necessarily proper) of one of the two parts.  Continuing with Alice, they then take turns selecting pieces from the whole cake until the cake is entirely divvied up. Each person's objective is to obtain pieces sufficient to be reassembled into a cube-shaped cake, $10$ cm on a side.  Can either person ""win""?  Can both?  Note that I do not require the actual algorithm either person would follow (though I would be happy with one); I merely want to know if such an algorithm must exist. *Assume that by ""piece,"" we mean the usual definition of piece with respect to the Banach-Tarski paradox.","['set-theory', 'game-theory', 'measure-theory']"
1383406,Minimum Cake Cutting for a Party,"You are organizing a party.  However, the number of guests to attend your party can be anything from $a_1$, $a_2$, $\ldots$, $a_n$, where the $a_i$'s are positive integers.  You want to be prepared, so you want to cut a cake into smaller pieces.  The pieces are not necessarily of equal size.  The requirement is that, no matter how many guests come (which you will have known before distributing the cake), you will be able to give each of them some pieces of the cake without having to cut the cake any further so that everybody will get the same amount of cake.  What is the minimum number of pieces of your cake you will have to cut it into? Trivially, if $n=1$, then the answer is $a_1$.  The answer is also known for $n=2$, which is $a_1+a_2-\gcd\left(a_1,a_2\right)$ (if you wonder why graph theory is in the tag, it is because the only proof known to me for the $n=2$ case is done via a graph-theorical argument).  I conjecture that the answer, in general, is
$$m:=\sum_{j=1}^n\,(-1)^{j-1}\,g_j\,,$$
where
$$g_j:=\sum_{1\leq k_1<k_2<\ldots<k_j\leq n}\,\gcd\left(a_{k_1},a_{k_2},\ldots,a_{k_j}\right)$$
for $j=1,2,\ldots,n$ (here, $g_1$ is simply $a_1+a_2+\ldots+a_n$).  It is easy to cut the cake into $m$ pieces to satisfy the required condition. Apparently, the conjecture is false for $n>2$ (see Dividing the whole into a minimal amount of parts to equally distribute it between different groups. ).  However, I expect that my guess is not far away from the correct answer. EDIT: The $n=2$ case with $\gcd\left(a_1,a_2\right)=1$ appeared as a problem for the Spring Contest, A Level, of the Tournament of the Towns of 1990.  See https://keoserey.files.wordpress.com/2012/12/imtot-book-3.pdf (page 35 of the PDF). Related Topics: Dividing the whole into a minimal amount of parts to equally distribute it between different groups. https://puzzling.stackexchange.com/questions/19870/nine-gangsters-and-a-gold-bar/19881#19881 https://mathoverflow.net/questions/214477/minimal-possible-cardinality-of-a-a-1-a-k-distributable-multiset","['extremal-combinatorics', 'graph-theory', 'number-theory', 'hypergraphs', 'combinatorics']"
1383413,"Condition to guarantee $f=0$ on $[a,b]$","I have been stuck for several days on this old Analysis problem (I am doing some study on my own).  I have tried several things (which I'll indicate below), but I cannot seem to figure it out.  Here is how the problem is presented: Problem: ""Let $f$ be a continuous real-valued function on $[a,b]$ .  Suppose there exists a constant $M \geq 0 $ such that $$|f(x)| \leq M \int_a^x |f(t)| dt$$ for all $x \in [a,b]$ .  Show that $f(x)=0$ for all $x \in [a,b]$ ."" My Thoughts: I have tried using the mean value theorem iteratively, but that seems to always lead me down a dead end road.  I deduced that $f(a)=0$ .  If only $f$ were assumed to be differentiable, then maybe I could play with trying to get the derivative to be $0$ , but unfortunately it's only continuous.  My other thought was to (somehow) use the condition to show that $\int_a^b |f(x)| dx = 0$ .  I also played around a bit with contradiction, but to no avail.  Even if one of these hair-brained thoughts is correct, I am not really sure what to do next. If you have any ideas, suggestions, or solutions, I would really appreciate it if you are willing to share them.  Thank you for your time.",['real-analysis']
1383423,A Quotient of the Euclidean Group,"$\newcommand{\euc}{\mathscr I}\newcommand{\R}{\mathbf R}$
Let $\euc(n)$ denote the the Euclidean group $\R^n\rtimes O_n(\R)$. Recall that $\euc(n)$ acts on $\R^n$ as $(\mathbf x, T)\cdot \mathbf y=\mathbf x+T\mathbf y$ for all $(\mathbf x, T)\in \euc(n)$ and $\mathbf y\in \R^n$. Consider the action of $\euc(n)$ on $(\R^n)^v$ defined as follows:
$$
A\cdot(\mathbf y_1, \ldots, \mathbf y_v)=(A\cdot\mathbf y_1,\ldots, A\cdot\mathbf y_v)
$$
for all $A\in \euc(n)$ and $(\mathbf y_1,\ldots, \mathbf y_v)\in (\R^n)^v$. Fix a point $\mathbf p=(\mathbf p_1, \ldots, \mathbf p_v)\in (\R^n)^v$ and define a map $F:\euc(n)\to (\R^n)^v$ as
$$
F(A)=(A\cdot\mathbf p_1,\ldots,A\cdot\mathbf p_v)
$$
for all $A\in \euc(n)$. Since $F^{-1}(\mathbf p)$ is an isotropy subgroup of a Lie group action, we know that $F^{-1}(\mathbf p)$ is a Lie subgroup of $\euc(n)$. Now for some reason unknown to me, we can give a manifold structure to $\euc(n)/F^{-1}(\mathbf p)$ such that the natural projection map $\pi:\euc(n)\to \euc(n)/F^{-1}(\mathbf p)$ is a smooth submersion. For set theoretical reasons, we can get a map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to (\R^{n})^v$ such that $F=\bar F\circ \pi$.
Since $\pi$ is a smooth submersion, we infer that $\bar F$ is a smooth map. My Question: Now on pg. 283 of this paper (titled ' The Rigidity of Graphs ' and written by B. Roth and L. Asimow ), it is said that the map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to \text{im}(\bar F)$ is a diffeomorphism. It is not clear to me why is this map a diffeomorphism. In fact, it is not even clear why is $\text{im}(\bar F)$ a smooth manifold.","['lie-groups', 'differential-geometry']"
1383433,"Absolute Min and Max of $f(x, y)=x^2+4y^2-2x^2y+4$ Using Partial Derivatives","Consider this problem: Find the absolute minimum and absolute maximum of $f(x, y)=x^2+4y^2-2x^2y+4$ on the rectangle given by $-1\leq x\leq1$ and $-1\leq y\leq1$ I solved this problem using partial derivatives: I got $f_x=2x-4xy=0$ And $f_y=8y-2x^2=0$ Solving simultaneously gives the following critical points: $(0,0), (0,\frac{1}{2}), (\sqrt2,\frac{1}{2}) $ And with the restriction: $-1\leq x\leq1$ and $-1\leq y\leq1$ The critical points becomes: $(0,0), (0,\frac{1}{2}) $ $f(0,0)=4 $ and $f(0,\frac{1}{2}) =5$ Now the quagmire is how to use partial derivatives (probably of second order) to determine which is the absolute minimum and maximum. Plotting a graph of $z=x^2+4y^2-2x^2y+4$ suggests that: $(0,0,4) $ is the absolute minimum and $(0,\frac{1}{2},5) $ the maximum But I need to be sure I'm on the right path. I also need to know how to use partial derivatives to differentiate a minimum critical point from a maximum critical point.","['partial-derivative', 'multivariable-calculus']"
1383434,Calculating probability for forming a triangle,"I am having trouble coming up with a solution for this problem: There is a stick of unit length. We break it into two parts.
  Now, we pick the bigger one and break it into two parts.
  I want to calculate the probability that the three pieces form a triangle. The problem is from ""Introduction to Probability, Charles M. Grinstead"", Chapter 2.2, Exercise 13",['probability']
1383436,Commutative binary operations on $\Bbb C$ that distribute over both multiplication and addition,"Does there exist a non-trivial commutative binary operation on $\Bbb C$ that distributes over both multiplication and addition? In other words, if our operation is denoted by $\odot$, then I want the following to hold: $a \odot (b \cdot c) = a \odot b \cdot a \odot c$ $a \odot (b + c) = a \odot b + a \odot c$ $a \odot b = b \odot a$ All of the things I can find so far distribute over either multiplication or addition, but not both. Alternatively, is there a proof that no such operation can exist? I wasn't sure if this question was too elementary for MO, so I'm trying here first. This question is obliquely related to the following other questions I've asked on MO and here: A particularly “natural” algebraic structure with three commutative, pairwise-distributive operations Translations AND dilations of infinite series Discrete “difference” equations that involve changes in both shift and scale","['abstract-algebra', 'binary-operations', 'complex-numbers', 'ring-theory']"
1383437,Simplify multinomial trig expansion to fewer linear terms like Wolfram?,"I'm mystified as to how Wolfram Alpha's TrigReduce[expr] does its magic, particularly on sums of long products that look like
$$A \cos^a(B_1 x) \sin^b(B_2 x) \cos^c (B_3 x) \sin^d (B_4 x) \dots$$ I can get to a linear combination of sines & cosines by using power-reduction and product-to-sum formulas, but this yields wayyy more terms than the original expansion, while Wolfram's method yields way fewer . E.g. $\approx 2500$ vs $59$ (!?). What is the trick? Here's what I'm able to do on my own, taking one term of a multinomial expansion: $$\begin{align}
& A \cos^2 (B x) \sin(C x) \sin^2 (D x) \cos(E x) \\
= & \frac{A}{4}\big[1 + \cos(2 B x)\big] \sin(C x) \big[1 - \cos(2 D x)\big] \cos(E x) \\
= & \frac{A}{4} \big[ -\cos(2 B x) \sin(C x) \cos(2 D x) \cos (E x) - \sin(C x) \cos(2 D x) \cos(E x) + \cos(2 B x) \sin(C x) \cos(E x) + \sin(C x) \cos(E x) \big]
\end{align}$$ Then I can perform splits like the following:
$$\begin{align}
& \cos(2 B x) \sin(C x) \cos(E x) \\
& = \frac{1}{2}\big[\sin((2B+C)x) - \sin((2B-C)x)\big] \cos(E x) \\
& = \frac{1}{2}\sin((2B+C)x)\cos(Ex) - \frac{1}{2}\sin((2B-C)x)\cos(Ex) \\
& = \frac{1}{4}\big[\sin((2B+C+E)x) + \sin((2B+C-E)x) - \sin((2B-C+E)x) - \sin((2B-C-E)x)\big]
\end{align}$$ This small example fails to demonstrate how the # of terms blows up when recursively applying product-to-sum formulas, suggesting there's more to the story of $\text{TrigReduce}$. Informally, I'll let $s_n$ denote a sum of $n$ trig functions and $p_n$ denote a product of $n$ trig functions. So the splitting example shown above would be expressed as:
$$p_3 = (s_2)p_1 = p_2 + p_2 = s_2 + s_2 = s_4$$ Splitting a term of $6$ trig factors would then be expressed as:
$$\begin{align}
p_6 & = (s_2)p_4 = p_5 + p_5 = (s_2)p_3 + (s_2)p_3 = p_4 + p_4 + p_4 + p_4 \\
& = (s_2)p_2 + (s_2)p_2 + (s_2)p_2 + (s_2)p_2 = p_3 \times 8 = s_4 \times 8
\end{align}$$ In general, it appears that splitting a product of $n$ trig factors using product-to-sum formulas yields $2^{n-1}$ linear terms. Suppose I want to simplify the following expression:
$$(\cos(3x) + \sin(5x) + \cos(7x) + \sin(11x))^6$$ The number of terms in the multinomial expansion is $\binom{6+4-1}{4-1} = 84$. Each term is a product of $6$ trig functions (since the exponents in each term must sum to $6$ according to multinomial theorem). As per the earlier formula, a product of $6$ trig functions splits into $32$ linear terms. Not counting the effect of power reduction (PR) formulae, $84 \cdot 32 = 2688$ linear terms. If my intuition is correct, the effect of PR is no better than product-to-sum conversions, because for each exponent that is cut in half, the entire enclosing term gets duplicated (since there are two terms in a PR formula). So roughly $\approx 2688$ terms is the best I know how to do. However, TrigReduce applied to same expression spits out a mere 59 linear sin/cos terms (!?!). How is this possible? Is Wolfram doing something tricky across the sums of the product strings? Would appreciate any clues. I know I've posted a few lame tumbleweeds lately; maybe my allowance of dumb questions is reaching a limit. I wouldn't ask this except it's the missing puzzle-piece in an algorithm.","['wolfram-alpha', 'trigonometry']"
1383441,Finding fundamental solution to the biharmonic operator $\Delta^2=\Delta(\Delta)$?,"Show that when $n=2$, the function $u(x)=-\dfrac{1}{8\pi}\left\lvert x\right\rvert^2\log\left\lvert x\right\rvert$ is a fundamental solution to the biharmonic operator $\Delta^2=\Delta\left(\Delta\right)$. That is, show that $$\varphi(0)=\int_{\Bbb R^2}u(x)\,\Delta^2\varphi(x)\,dx$$ for all functions $\varphi$ smooth with compact support. My attempt: My first confusion: the question says it is equivalent to show $\varphi(0)=\int_{\Bbb R^2}u(x)\,\Delta^2\varphi(x)\,dx$. Why is that true? Considering the definition, I think it is $\;0=\int_{\Bbb R^2}u(x)\,\Delta^2\varphi(x)\,dx\;$ instead of $\varphi(0)$. Where am I wrong? My second confusion is it seems I can directly compute $\Delta u=-\dfrac{1}{2\pi}\Big(1+
\log\left\lvert x\right\rvert\Big)$, then it is obvious $\,\Delta\left(\Delta u\right)=0$. Is that enough for proving this question? The calculation of $\Delta u(x)$ is as follows:
$$u_{11}=-\dfrac{1}{8\pi}\left[2\ln\left(\sqrt{x_1^2+x_2^2}+\dfrac{2x_1^2}{x1^2+x_2^2}+1\right)\right]$$
and 
$$u_{22}=-\frac{1}{8\pi}\left[2\ln\left(\sqrt{x_1^2+x_2^2}+\dfrac{2x_2^2}{x1^2+x_2^2}+1\right)\right],$$
so 
$$\Delta u=u_{11}+u_{22}=-\frac{1}{2\pi}\Big(1+\log\left\lvert x\right\rvert\Big).$$ Could someone kindly help? Thanks!","['harmonic-analysis', 'integration', 'harmonic-functions', 'analysis', 'partial-differential-equations']"
1383443,"matrix with fractional exponent, not getting expected output in Matlab/Octave","I have a matrix exponential function that is called a number of times in an integration routine from the heat conduction model I'm trying to implement . It works, and my results match the samples in the paper, but want to speed things up by breaking apart the exponential function so that I can precalculate the constant part and just pass that to the calling function. Unfortunately, the separation only works for integer values of the exponent, and I'm not sure why the manipulation doesn't hold for fractional values. the matrix exponential is equation (20) in the paper defined as: $e^{[F(s)]x}=\pmatrix{ \mathrm{cosh}{(\sqrt{s/\alpha_j}x)} & \frac{1}{\lambda_j\sqrt{s/\alpha_j}}\mathrm{sinh}{(\sqrt{s/\alpha_j}x)} \\ \lambda_j\sqrt{s/\alpha_j}\mathrm{sinh}{(\sqrt{s/\alpha_j}x)} & \mathrm{cosh}{(\sqrt{s/\alpha_j}x})}$ this is most often called in the model as $e^{[F(-\beta^2)](x_j-x)}$ where $\beta$ is a real eigenvalue, and $x_j$ is a nodal location. Because $\beta$ and $x_j$ are known prior to the call for $e^{[F(-\beta^2)](x_j-x)}$, I wanted to do the manipulation below to separate out $x$: $$
e^{[F(-\beta^2)](x-x_j)}
= e^{[F(-\beta^2)]x_j}*e^{[F(-\beta^2)](-x)}
= e^{[F(-\beta^2)]x_j}*[e^{[F(-\beta^2)](-1)}]^x
$$ In that form, I can precalculate both exponential functions, and just do a scalar power operation with x inside the integration and other calling loops. Implemented it in Octave (and tried it in Matlab), led to a great speedup, but non integer values of x produce ""wrong"" answers.  I realize a fractional matrix exponent involves solving an eigenvalue equation where $A^m=P(D^m)P^{-1}$ as per This Answer . It seems what I've done is consistent with rules for matrix exponentials . But here's an example to belabor the point ($\alpha_j=1, \lambda_j=2$): $e^{[F(-\beta^2)]x}, \beta=1,x=1 = \pmatrix{\mathrm{cos}{(1)}&\mathrm{sin}{(1)}/2\\-2\cdot \mathrm{sin}{(1)}&\mathrm{cos}{(1)}}=\pmatrix{0.54030&  0.42074\\-1.68294& 0.54030}$ $e^{[F(-\beta^2)]x}, \beta=1,x=3 = \pmatrix{\mathrm{cos}\left( 3\right)  & \frac{\mathrm{sin}\left( 3\right) }{2}\cr -2\cdot \mathrm{sin}\left( 3\right)  & \mathrm{cos}\left( 3\right) }=\pmatrix{0.45360 &  0.44560\\-1.78241 & 0.45360}$ $e^{[F(-\beta^2)]x}, \beta=1,x=1.1 =\pmatrix{-0.989992 &  0.070560\\-0.282240 & -0.989992}$ These work fine in Octave, Matlab, and the integer ones checked out in Maxima whether x is input as a multiplication in the matrix function, or as an exponent to the matrix function. Now, the problem seems to creep in when $\beta > \pi$. Integer values of x are ok:
$e^{[F(-\beta^2)]x}, \beta=1.1\cdot\pi,x=3 = \pmatrix{-0.58779 & -0.11705\\   5.59152  &-0.58779}$ $[e^{[F(-\beta^2)](1)}]^{x}, \beta=1.1\cdot\pi,x=3 = \pmatrix{-0.58779 & -0.11705\\   5.59152  &-0.58779}$ But fractional values are not: $e^{[F(-\beta^2)]x}, \beta=1.1\cdot\pi,x=1.1 = \pmatrix{ -0.790155 & -0.088679\\   4.236109 & -0.790155}$ $[e^{[F(-\beta^2)](1)}]^{x}, \beta=1.1\cdot\pi,x=1.1 = \pmatrix{-0.9995066 & -0.0045447\\   0.2170956 & -0.9995066}$ As I'm summing over a large number of Beta's of increasing size, this is a problem, and I can't seem to identify the cause. I just realized the issue occurs at $\beta > \pi$ when typing this up, so maybe there's something obvious there that I'm missing. for reference, here's my implementation of the calling function: function answer=expfxs(x,s,alphaj,lamj)
   answer = [cosh(sqrt(s/alphaj)*x),...
         sinh(sqrt(s/alphaj)*x)/(lamj*sqrt(s/alphaj));...
         sinh(sqrt(s/alphaj)*x)*lamj*sqrt(s/alphaj),...
         cosh(sqrt(s/alphaj)*x)];
endfunction","['octave', 'linear-algebra', 'matlab', 'matrices']"
1383454,$R$ is a unique factorization domain $\iff$ every prime minimal over a principal ideal is also principal,"I'm trying to show that a ring $R$ is a unique factorization domain $\iff$ every prime minimal over a principal ideal is also principal. I think the idea is to use the principal ideal theorem of Krull, but I don't know how to connect principal ideal properties with unique factorization domain properties. I know that ""principal ideal domain $\implies$ unique factorization domain"", which helps me if I prove $R$ is principal from the second statement, but that is as far as I can go right now. PS: assume $R$ is a commutative ring with unity. Thanks.","['abstract-algebra', 'unique-factorization-domains', 'commutative-algebra']"
1383458,"Use class algebra to prove the following: If $A\cap B = \emptyset$ and $A\cup B = C$, then $A = C-B$","I'm having a bit of trouble proving the following. If $A\cap B = \emptyset$ and $A\cup B = C$ , then $A = C-B$ My initial attempt is to prove it directly, however, I believe I'm assuming the consequent, namely, $A = C-B$ , and I'm unsure how to close the proof. Attempted proof Suppose that $A = C-B$ . We know that $C = A\cup B$ from our premises, therefore: $A = (A\cup B)-B$ , which is $A = (A\cup B) \cap B'$ Now distribute: $A =(A\cap B') \cup (B\cap B')$ , but $B \cap B'= \emptyset$ , so we have $A = (A\cap B') \cup \emptyset$ Thus, $A = A\cap B'$ Here is where I am at a loss. I see that if some element x was an element of both $A$ and $B$ , we would have a disjoint set according to our premises. Any tips are appreciated and I apologize in advance for the formatting.",['elementary-set-theory']
1383460,Is this set of random variables a Hilbert space?,"Consider a sequence of i.i.d. random variables $\left\{ {{\varepsilon _t}} \right\}_{t = 1}^\infty $ with $E\left( {{\varepsilon _t}} \right) = 0$
 and $E\left( {\varepsilon _t^2} \right) = {\sigma ^2} < \infty $ and denote by ${\varepsilon ^t} = ({\varepsilon _{1,}}{\varepsilon _{2,}} \ldots {\varepsilon _t})$ the history of the process up to and including period $t$. Let $0 < \beta  < 1$. Define P as the set of all ${R^\infty }{\rm{ - valued}}$ functions $x(\varepsilon ) = \left\{{{x_t}({\varepsilon ^t})} \right\}_{t = 1}^\infty$ such that $\sum\limits_{t = 1}^\infty  {{\beta ^t}x_t^2} \mathop  < \limits^{a.s.} \infty $ and ${E_{t = 0}}\sum\limits_{t = 0}^\infty  {{\beta ^t}x_t^2}  < \infty $ exist. For meaning/intuition: ${x_t} = {x_t}({\varepsilon ^t})$ are decision rules that can depend only on information ${\varepsilon ^t}$ available at time $t$. I have the following question: Is P a Hilbert space with the product $\langle x,y\rangle  = {E_{t = 0}}\left( {\sum\limits_{t = 1}^\infty  {{\beta ^t}{x_t}{y_t}} } \right)$ and associated norm $$\left\| x \right\| = {\langle x,x\rangle ^{1/2}} = {\left( {{E_{t = 0}}\left( {\sum\limits_{t = 0}^\infty  {{\beta ^t}x_t^2} } \right)} \right)^{1/2}}$$? (By ${E_{t = 0}}$ I mean the expectation at t=0, before any information on the ${\varepsilon _t}$ is available. By a.s. I mean almost surely.) I guess the tricky part is to prove that P is complete (with the norm (is it a norm?) just described), and perhaps, that if $\left\| x \right\| = 0$ then $x\mathop= \limits^{a.s.} 0$ ? I will be very grateful for any suggestions or references. I am not a mathematician, so even steps that may seem elementary to you would help me.","['probability-theory', 'random-variables', 'functional-analysis', 'stochastic-processes', 'discrete-optimization']"
1383470,Problem with finding Maximum value,"My problem states: Show that y:
\begin{equation}
y = e^{-t}sin(2t)
\end{equation}
is a maximum when
\begin{equation}
t =
\frac{1}{2}\tan^{-1}(2)
\end{equation}
and determine this maximum value. So basically i have to calculate first and second derivatives of function f(t) = y and find some relation with what i must prove. Well, i've almost done it i think. But not quite. Can someone help me by checking out my answer a bit and tell me where i'm wrong, what i should improve, anything that could help me really? So first i calculate first derivative:
\begin{equation}
\frac{dy}{dt} = -e^{-t}\sin(2t) + 2e^{-t}\cos(2t)
\end{equation}
and i convert the result to a more simplified form
\begin{equation}
\sqrt{5}e^{-t}\cos(2t-0.464)
\end{equation}
which i equate to 0 to find t(which i can't find it here).
And then i calculate the second derivative:
\begin{equation}
\frac{d^{2}y}{dt^{2}} = -\sqrt{5}e^{-t}\cos(2t-0.464)-2\sqrt{5}e^{-t}\sin(2t-0.464)
\end{equation}
which ""simplifies"" to:
\begin{equation}
5e^{-t}\cos(2(t-\frac{tan^{-1}(2)}{2})-0.4636)
\end{equation}
I doubt i'm right so far but if i am then i'm close. However i don't see exactly how i can prove what is needed from here. If someone could help me a bit i would be most grateful. Thank you in advance.",['derivatives']
1383480,Estimating the Average and Standard Deviation of a Population based on a Sample with Missing Data with Known Ranks,"I need a way to shows me how the parameters of PDF, log-normal in this case, can be estimated based on a set with missing data points at the tail end of a sample. For example, Consider we had 20 numbers with specified μ and σ , and then missed two largest number of them. How do we can estimate the mean ( μ ) and standard deviation ( σ ) of these 20 numbers with only 18 available numbers, if we know that all of them obey a log-normal distribution?! (this is obvious that these 2 missing numbers are in the tail end of log-normal distribution) *I am a structural engineering student. So please don't present complex solutions :) I want to code a program in Matlab to do this for me.","['estimation', 'probability', 'statistics', 'parameter-estimation']"
1383498,Weird thing about $\sum_{k=2}^{\infty}(-1)^k\zeta{(k)}$,"Consider the sum $S=\sum_{k=2}^{\infty}(-1)^k\zeta{(k)}$. By a simple manipulation, we can show:
$$
S=\sum_{k=2}^{\infty}{(-1)^k\sum_{r=1}^{\infty}\frac{1}{r^k}}=\sum_{r=1}^{\infty}{\sum_{k=2}^{\infty}\frac{(-1)^k}{r^k}}=\sum_{r=1}^{\infty}{\frac{1}{1+\frac{1}{r}}-1+\frac{1}{r}}=\sum_{r=1}^{\infty}{\frac{1}{r}-\frac{1}{r+1}}=1
$$
But looking at the partial sums $S_n$ we can see that:
$$
\begin{array}{c|lcr}
n & S_n\\
\hline
2 & 1.644934... \\
3 & 0.442877... \\
4 & 1.525200... \\
100 & 1.500…026… \\
101 & 0.499…987...
\end{array}
$$
Which disagrees with the result. How can one be trapped so easily? Edit: And how to show 
$$
\lim_{n\to\infty}{S_n-\frac{(-1)^n+1}{2}}=\frac{1}{2}
$$
?","['sequences-and-series', 'riemann-zeta', 'limits']"
1383511,Normal curvature of geodesic spheres,"I would like to ask the community for a reference on the following property of geodesic spheres. Let $(M,g)$ be a compact Riemannian manifold without conjugate points and $\tilde{M}$ its universal covering with the natural metric $\tilde{g}$. Given a point $\tilde{p}\in\tilde{M}$ and $R>1$, Is there some result like The inner normal field of the geodesic sphere centered at $\tilde{p}$ and with radius $R$ is a Lipschitz vector field ? I am aware that the normal curvature satisfies a Riccati equation along a geodesi radius starting at the center of the sphere, namely $\tilde{p}$. Perhaps I could get some control of the normal vector field of a geodesic sphere using this equation, but I don't know if there is this control. If someone could give me any reference on the subject, it would be really appreciated.","['reference-request', 'lipschitz-functions', 'differential-geometry', 'spheres', 'geodesic']"
1383521,Incomplete measure space that is not sigma-finite,"I am looking for an example of an incomplete measure space with a measure that is not sigma-finite. All the measures which are not sigma-finite which I have come across so far are the following: counting measure on a set that is not countable (e.g. on the measurable space $(\mathbb{R},\mathcal{P}(\mathbb{R}))$ or the measure $\mu$ on the trivial
sigma algebra $\Sigma = \{\emptyset,X \}$ with $\mu(X) = \infty$ were complete. Suppose $(\Omega, \Sigma, \mu)$ would be such a measure space. Let $\eta$ denote the induced outer measure and $\Sigma_\eta$ the $\sigma$-algebra of the $\eta$-measurable sets. Furthermore let $(\Omega,\tilde{\Sigma},\tilde{\mu})$ denote the completion of $(\Omega,\Sigma,\mu)$. Will in this case the inclusion $\tilde{\Sigma} \subset \Sigma_\eta$ be strict?",['measure-theory']
1383532,Etale fundamental group action on set-theoretic fiber,"Let $f: Y \to X$ be a finite etale cover of schemes. Fix a geometric point $x \in X$. I would like $\pi_1(X,x)^{et}$, the etale fundamental group, to act on the set-theoretic fiber of $x$. This set is the same as sets as the scheme-theoretic fiber of $x$. But we have an action only on the geometric fiber of $x$. Is there a way I can induce an action on the set-theoretic fiber of x? (Maybe it injects to the geometric fiber of $x$ through a set map?) I'd appreciate any inputs on this. Thanks!","['etale-cohomology', 'algebraic-geometry']"
1383536,Help with a proof regarding simple functions.,"The question is If $f>g≥0$, then there exists non-negative measurable simple functions $f_k↗f$ s.t. $f_k≥g$ for all $k$. My attempt. Using a theorem in my text book For every non-negative function $f$, there exists a sequence $f_k$ of non-negative simple functions s.t. $f_k↗f$. Suppose $g_k$ is a sequence of non-negative simple function s.t. $g_k↗g$. For any $k$, $f-g_k>0$, then there exists non-negative simple functions $h_j↗f-g_k$, thus $h_j+g_k↗f$ with respect to $j$. But I got stuck here. Sine $g_k\le g$, I cannot conclude $h_j+g_k \ge g$. Hope someone can help. Thank you!","['real-analysis', 'measure-theory']"
1383546,"$f: \Omega \rightarrow \Omega$ bounded, $f(z_0) = z_0$, show $|f'(z_0)| \leq 1$","I'm stuck on the following problem: Let $\Omega$ be a bounded domain, and $f: \Omega \rightarrow \Omega$ analytic such that $f(z_0) = z_0$.  Show that $|f'(z_0)| \leq 1$. What I did so far was suppose that $|f'(z_0)| > 1$, and define $g_n := f \circ \cdots \circ f$ ($n$ times).  Then $g: \Omega \rightarrow \Omega$ is analytic with $g_n(z_0) = z_0$ and $g_n'(z_0) = f'(z_0)^n$.  It follows that $|g_n'(z_0)|$ is large for $n$ large. So now we are reduced to the case where $g: \Omega \rightarrow \Omega$ is analytic, fixes a point $z_0$, and $g'(z_0)$ is very large.  Somehow I want to show that as a result of $g'(z_0)$ being so large, it must map some point in $\Omega$ outside of $\Omega$, contradiction.  Can anyone give a hint?",['complex-analysis']
1383547,Derivative of sum of powers,"For fixed $n \geq 1$ and $p \in [0,1]$, is there a nice expression for the derivative of $\sum_{k=0}^n p^k (1-p)^{n-k}$ with respect to p?","['power-series', 'binomial-coefficients', 'combinatorics']"
1383550,Uniform limit of injective analytic functions is injective,"I'm stuck on the following problem: Let $f_n$ be a sequence of injective analytic functions on the unit disc $D$ such that $f_n$ converges uniformly to $f$ on compact subsets of $D$.  Show that $f$ is either injective or constant. Already $f$ is analytic as an almost uniform limit.  If $f'$ is identically zero, then $f$ is constant.  Otherwise $f'$ has isolated zeroes.  If $c$ is such an isolated zero, then $f_n'$ converges uniformly to $f'$ on a small disc near $c$.  By Hurwitz's theorem, for almost all $n$ the functions $f_n'$ should also have a zero in that small disc. But an analytic function is locally injective at a point if and only if its derivative at the point is nonzero.  And injective implies locally injective.  So the $f_n'$ shouldn't have any zeros in $D$. So, we can at least conclude that $f'$ is never zero on $D$.  This shows that $f$ is locally injective.  Is there an easy way to conclude injectivity from local injectivity here?",['complex-analysis']
