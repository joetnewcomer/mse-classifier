question_id,title,body,tags
1996559,"Closed form for $\int_0^e\mathrm{Li}_2(\ln{x})\,dx$?","Inspired by this question and this answer , I decided to investigate the family of integrals 
$$I(k)=\int_0^e\mathrm{Li}_k(\ln{x})\,dx,\tag{1}$$
where $\mathrm{Li}_k(z)$ represents the polylogarithm of order $k$ and argument $z$. $I(1)$ evaluates to $e\gamma$, but $I(2)$ has resisted my efforts (which can be seen here ). Neither ISC nor WolframAlpha could provide a closed form for its numerical value--however, I've conjectured a possible analytic form. $$\eqalign{\int_0^e\mathrm{Li}_2(\ln{x})\,dx&\stackrel?=\,_3F_3(1,1,1;2,2,2;1)+\frac{\pi^2(2e-5)}{12}+\frac{\gamma^2}{2}-\gamma\,\mathrm{Ei}(1)\\&=0.578255559804073275225659054377625577...\tag{2}}$$ Brevan Ellefsen has computed that my conjecture is accurate to at least 150 digits. Brevan also gave the alternate form 
$$\frac{\pi^2e}{6}+\gamma G_{1,2}^{2,0}\left(-1\left|\begin{array}{c}1\\0,0\\\end{array}\right.\right)+G_{2,3}^{3,0}\left(-1\left|\begin{array}{c}1,1\\0,0,0\\\end{array}\right.\right).\tag{2.1}$$ Is there a closed form for $I(2)$ that doesn't involve Meijer G or hypergeometrics? The simplicity of the following two equations seems to suggest that there might be. $(3.1)$ follows directly from $(3)$, which I've proven here . 
  $$\begin{align}
\sum_{k=1}^\infty I(k)&=e\tag{3}\\\sum_{k=2}^\infty I(k)&=e(1-\gamma)\tag{3.1}\end{align}$$ PROGRESS UPDATE : Using this equation , I've turned $_3F_3(1,1,1;2,2,2;1)$ into
$$\lim_{c\to 1}\left(\frac{\mathrm{Ei}(1)-\gamma}{c-1}+\frac{1-e}{(c-1)^2}+\frac{(-1)^{-c}\,\Gamma(c-1)}{c-1}+\frac{(-1)^{1-c}\,\Gamma(c,-1)}{(c-1)^2}\right),\tag{4}\label{4}$$ but I don't know how to proceed from there. EDIT: This limit leads nowhere. See below. SECOND PROGRESS UPDATE : After some studying of the properties of the Meijer G function, I've finally cracked the limit; however, the result is an underwhelming $_3F_3(1,1,1;2,2,2;1)$. Before I evaluate the limit, I'd first like to state the following intermediate result: Lemma $(4.1)$ : For $z\in\mathbb{C}$, 
  $$G_{2,3}^{3,0}\left(z\left|\begin{array}{c}1,1\\0,0,0\\\end{array}\right.\right)=\gamma\ln{z}+\frac12\ln^2(z)-z\,_3F_3(1,1,1;2,2,2;-z)+\frac{\gamma^2}2+\frac{\pi^2}{12}.\tag{4.1}\label{4.1}$$ My proof for this can be found here . Now I return to the limit $\eqref{4}$.
Consider the following: $\frac{1}{c-1}=\frac{c-1}{(c-1)^2}$, $(c-1)\Gamma(c-1)=\Gamma(c)$, and $(-1)^{1-c}=-(-1)^{-c}$. Based on these algebraic identities, the limit can be written as 
$$\lim_{c\to 1}\frac{(c-1)(\mathrm{Ei}(1)-\gamma)+1-e+(-1)^{-c}(\Gamma(c)-\Gamma(c,-1))}{(c-1)^2}.\tag{4.2}$$ 
In this form, the limit is $\frac{0}0$. Using l'Hospital twice, we obtain 
$$\lim_{c\to 1}{(-1)^{-c}\left(-G_{3,4}^{4,0}\left(-1\left|\begin{array}{c}1,1,1\\0,0,0,c\\\end{array}\right.\right)+\Gamma{(c)}\left(\frac{\psi_0{(c)}^2}2-i\pi\psi_0(c)+\frac{\psi_1(c)}2-\frac{\pi^2}2\right)\right)}$$ $$\begin{align}&=G_{3,4}^{4,0}\left(-1\left|\begin{array}{c}1,1,1\\0,0,0,1\\\end{array}\right.\right)-\frac{\psi_0(1)^2}2+i\pi\psi_0(1)-\frac{\psi_1(1)}2+\frac{\pi^2}2\\&=G_{2,3}^{3,0}\left(-1\left|\begin{array}{c}1,1\\0,0,0\\\end{array} \right.\right)-\frac{\gamma^2}{2}-i\gamma\pi+\frac{5\pi^2}{12}.\tag{4.2a}\end{align}$$ 
Using Lemma $\eqref{4.1}$, we know that 
$$G_{2,3}^{3,0}\left(-1\left|\begin{array}{c}1,1\\0,0,0\\\end{array}\right.\right)={}_3F_3(1,1,1;2,2,2;1)+\frac{\gamma^2}2+i\gamma\pi-\frac{5\pi^2}{12},\tag{4.3}$$ which can be rewritten as 
$$G_{2,3}^{3,0}\left(-1\left|\begin{array}{c}1,1\\0,0,0\\\end{array}\right.\right)-\frac{\gamma^2}{2}-i\gamma\pi+\frac{5\pi^2}{12}={}_3F_3(1,1,1;2,2,2;1).\tag{4.3a}$$ Thus, 
  $$\eqalign{&\lim_{c\to 1}\left(\frac{\mathrm{Ei}(1)-\gamma}{c-1}+\frac{1-e}{(c-1)^2}+\frac{(-1)^{-c}\,\Gamma(c-1)}{c-1}+\frac{(-1)^{1-c}\,\Gamma(c,-1)}{(c-1)^2}\right)\\=&{}_3F_3(1,1,1;2,2,2;1).\tag{4.4}}$$","['closed-form', 'integration', 'definite-integrals', 'special-functions', 'polylogarithm']"
1996569,How to determine if a function is increasing.,"How would I determine whether a function is increasing, decreasing or neither without using calculus? Like whether x^0.5 is increasing in interval [0, infinity)
Just curious 
Thanks",['functions']
1996572,A calculus limit problem,"The problem is: $\lim_{x\to0}$ $\frac{sin(\frac{1}{x})}{sin(\frac{1}{sin(x)})}$ my intuition tells that the answer equal to $1$ by the limit equality : $\lim_{x\to0}$ $\frac{sinx}{x}=1$. But we can easily see that the limit of numerator and denominator both don't exist, and they are both between -1 and 1. I cannot seem to find a rigorous argument for this problem. If any one can help or give some hint would be very much appreciated!",['calculus']
1996574,Boundedness of integral,"I am currently working on a research project and have kind of stuck in proving the boundedness of a certain integral of a continuously differentiable signal $f(t)$. I have managed to prove the following properties: $f(t)$ is uniformly bounded. $\frac{1}{t}\int_0^t{sf^2(s)}ds$ is uniformly bounded. From 2. it is easy to prove that
$$\inf_{\tau\in[0,t]}|f(\tau)|\leq \sqrt{\frac{2\sigma}{t}}\qquad\qquad \qquad\qquad(1)$$
for some $\sigma>0$. From the simulations I run it seems that the whole function has a behavior of the form
$$|f(t)|\leq \sqrt{\frac{\eta}{t}}\qquad\qquad \qquad\qquad\qquad\quad(2)$$
for some $\eta>0$ but I could not prove that. So my question is this: Do these properties 1., 2. suffice to prove that $\int_0^t{f^4(\tau)d\tau}$ is uniformly bounded or do I need to impose some extra assumption? Note that from (2) the boundeness of $\int_0^t{f^4(\tau)d\tau}$ follows directly. Note also that I cannot use boundedness of $f'(t)$ since, in my current setting, this property follows as a consequence of the boundedness of the integral $\int_0^t{f^4(\tau)d\tau}$.","['functional-analysis', 'real-analysis', 'integral-inequality', 'functions']"
1996604,Dini function measurable for continuous functions,"Suppose $F$ is continuous on $[a, b]$. Show that,
$$D^+(F)(x) = \limsup_{\substack{h \to 0 \\ h > 0}} \frac{F(x+h)-F(x)}{h}$$
is measurable. I wonder whether the following ""proof"" of this statement is correct. I'm very much in doubt due to the continuity being only supposed on $[a, b]$. I sort of ignored it, not knowing what to do with it. Is the statement even through without supposing continuity everywhere (that is taking $a = -\infty, b = +\infty$)? Proof:
We must show that Dini function $D^+(F)(x) = \lim_{\delta \to 0} \sup_{0<h<\delta} \frac{F(x+h) - F(x)}{h} = \lim_{n\to\infty} \sup_{0<h<\frac{1}{n}} \frac{F(x+h) - F(x)}{h}$ is a measurable. In particular then, we are done if we show that $\forall \delta > 0$, $\sup_{0<h<\delta} \frac{F(x+h) - F(x)}{h}$ is measurable. Suppose therefore for arbitrary $\delta > 0$ and $\alpha$ that $x_0 \in F_{\delta, \alpha} = \{x : \sup_{0<h<\delta} \frac{F(x+h) - F(x)}{h} > \alpha\}$, we show that there exists some ball containing $x_0$ that is entirely contained in $F_{\delta, \alpha}$, then $F_{\delta, \alpha}$ is open and hence measurable, and we are done. For $x_0$ we have some $h_0 < \delta$ such that $\frac{F(x_0+h_0) - F(x_0)}{h_0} > \alpha$. Now consider the open interval $O = \{x : |x| < \delta_O\}$, by continuity taking $\delta_O$ small enough we have for any $\epsilon > 0$, however small, $\forall o \in O$ simultaneously that $F(x_0+o+h_0)-F(x_0+h_0) > -\epsilon/2$ and $F(x_0+o)-F(x_0) < \epsilon/2$, and therefore
\begin{equation*}
\begin{split}
    &\frac{F(x_0+o+h_0) - F(x_0+o)}{h_0} \\
    =& \frac{(F(x_0+o+h_0) - F(x_0+h_0)) + F(x_0+h_0) - (F(x_0+o) - F(x_0) + F(x_0))}{h_0} \\
    >& -\epsilon/h_0 + \frac{F(x_0+h_0) - F(x_0)}{h_0} > \alpha \text{ when taking $\epsilon$ small enough}
\end{split}
\end{equation*}
so that $x_0 + O$ is an open ball containing $x_0$ and being contained in $F_{\delta, \alpha}$. Thank-you so much for all the help!","['real-analysis', 'measure-theory', 'proof-verification']"
1996623,Telescopic series multiplied by n,"If I have a convergent monotonic series $\sum_{n \in \mathbb{N}}a_n = S < \infty$ then I now that the corresponding telescoping series $\sum_{n=0}^{\infty}(a_n-a_{n+1})$ converges too. How can I demonstrate that another series \begin{equation}
  \sum_{n=0}^{\infty}n(a_n-a_{n+1})
\end{equation} converges and has the same limit as $\sum_{n=0}^{\infty} a_n$? I tried with the method of differences but I end up with \begin{align}
  \lim_{N\to \infty} \sum_{n=0}^{N}n(a_n-a_{n+1})
  &= -\lim_{N\to \infty}Na_{N+1} + \lim_{N\to \infty} \sum_{n=0}^{N}a_n\\
  &= S -\lim_{N\to \infty}Na_{N+1}
\end{align} $\lim_{N\to \infty}Na_{N+1}$ is now an indeterminate form $\infty \times 0$ and I have to show that it is equal to $0$.","['telescopic-series', 'sequences-and-series', 'proof-verification', 'limits']"
1996628,Analytic Geometry proof of orthogonality in triangle geometry,"In triangle $ABC$, $AB = AC$, $D$ is the midpoint of $\overline{BC}$, $E$ is the foot of the perpendicular from $D$ to $\overline{AC}$, and $F$ is the midpoint of $\overline{DE}$. Prove that $\overline{AF}$ is perpendicular to $\overline{BE}$. My first approach was to align the triangle in the first quadrant, on the x-coordinates and started calculating slopes and positions of points.  But then things got messy real fast, i'm afraid I'm approaching this problem the wrong way.  Is there a better way?  No trigonometry just yet!  Solutions are greatly appreciated.  Thanks in advance!","['analytic-geometry', 'coordinate-systems', 'triangles', 'geometry']"
1996649,Show that $f(x)=\pi-2\arctan(\sqrt{x-1})$,"Given, for every $x>1$,
  $$f(x)=4\arctan\frac{1}{\sqrt{x-1}+\sqrt{x}}$$
  Show that $f(x)=\pi-2\arctan(\sqrt{x-1})$ I have tried to use the fact that $\arctan(x)+\arctan(1/x)=\frac{\pi}{2
}$ So I obtain: $f(x)=4(\frac{\pi}{2}-\arctan(\sqrt{x-1}+\sqrt{x})$ I am stuck here !","['trigonometry', 'inverse-function', 'calculus']"
1996653,"When is $F(x)=x^a\sin(x^{-b})$ with $F(0)=0$ of bounded variation on $[0,1]$?",I'm trying to show that $F(x)=x^a\sin\left(x^{-b}\right)$ for $0<x \leq 1$ and $F(0)=0$ has bounded variation only if $a>b$. I know I have to show there exist an $M< \infty$ such that for any partition $0=t_0<t_1<...<t_n=1$ we have $$\sum_{j=1}^N |F(t_j)-F(t_{j-1})|<M \iff |F(t_1)| + \sum_{j=2}^N |F(t_j)-F(t_{j-1})|<M .$$ I'm stuck here.,"['real-analysis', 'measure-theory', 'bounded-variation']"
1996682,"Show, that $\sigma$-finite measure on $\sigma$($\mathcal{A}$) may not be $\sigma$-finite on $\mathcal{A}$","Let  $(E,M,\mu)$ be a measurable space, $\mu$ a $\sigma$-finite measure, $\mathcal{A}$ an  algebra, such that $\sigma$ ($\mathcal{A}$) = $M$. Show that $\mu$ may not be $\sigma$-finite on $\mathcal{A}$. Here are my thoughts: I think we can consider the σ-algebra generated by cylinder sets. But I don't know how to construct a measure in this setting. Moreover, let $E = \mathbb Q$, $\mathcal M = 2^E$, $\mu$ the counting measure, $\mathcal A = \{\emptyset, \mathbb Q\}$. Then, $μ$ is't $σ$-finite on $\mathcal A$. But I need $σ (\mathcal A) = \mathcal M$. $\mathcal A=\{\emptyset, \mathbb Q\}$ is a $σ$-algebra and wider than what is needed.",['measure-theory']
1996700,Every basis of a topological space contains a basis of minimal cardinality - about finite topological space cases,"I know same question has an answer already . But I'm rather doubtful if the proof given there actually proves the claim for finite cardinalities. For infinite cardinals $\kappa (=w(X) \;\;\text{in the proof})$ we do have that, say, union of $\kappa$ copies of sets of cardinality $\kappa$ is $\kappa$, but of course this isn't necessarily true if $\kappa$ is finite. So I'm wondering how should one account for cases when $\kappa$ is finite? Any helps are appreciated","['general-topology', 'proof-explanation']"
1996756,Prove the countability of $\mathbb Q \times \mathbb Q$ and $M_{2 \times 2}(\mathbb Z)$,"Using the fact that $\mathbb N \times \mathbb N$ is countable, or otherwise, prove that the following sets are countable. a) the set of all points in the $(x,y)$ plane with rational coordinates b) the set of all $2\times 2$ matrices with integer entries. I really don't know where to start... and I've never done matrices either! I know that I need to prove there exists a bijection, but from there I'm lost.","['proof-writing', 'elementary-set-theory']"
1996768,"If $f$ is differentiable on $[1,2]$, then $\exists \alpha\in(1,2): f(2)-f(1) = \frac{\alpha^2}{2}f'(\alpha)$","If $f$ is differentiable on $[1,2]$, then $\exists \alpha\in(1,2) : f(2)-f(1) = \frac{\alpha^2}{2}f'(\alpha)$ I really would like some hint. I noticed that the equation can be written $$\int_1^2f(x)'\mathbb{d}x = f'(\alpha)\int_0^{\alpha} x\mathbb{d}x$$ EDIT:
I confused the theorems. I guess I have to apply the Mean Value Theorem, but I don't know how.","['real-analysis', 'calculus']"
1996790,Elements of a specific set,"I have got the set: $M_2 = \{l \in \mathbb{N} \mid \forall y(y \in \mathbb{N} \rightarrow y \leq l)\}.$ Does this mean that M2 includes all elements $l \in {N}$ that are bigger than every number in $\mathbb{N}$ because there is for every number a bigger one? So M2 would have an infinite amount of elements whose exact value is undefined. Or is M2 an empty set because there is no element $l \in \mathbb{N}$ that is bigger than all numbers in $\mathbb{N}$, because $l$ is also only an element of $\mathbb{N}$? Thank you that you took the time to read my question. I am really locking forward to your answers. Kindest regards =)","['quantifiers', 'logic', 'elementary-set-theory', 'elementary-number-theory']"
1996795,Are these valid Dedekind cuts for $e$ and $\pi$?,"I took the liberty to attempt to construct Dedekind cuts for $e$ and $\pi.$ That is, come up with a set $\alpha$ of rational numbers (that would correspond to the reals $e$ and $\pi$ ) such that, If $x \in \alpha$ and $y \in \mathbb Q : y < x$ , then $y \in \alpha$ $\alpha \neq \varnothing$ $\alpha \neq \mathbb Q$ $\alpha$ has no greatest element I came up with the following (hopefully valid) rational Dedekind cuts, $e = \left\{a\in\mathbb Q \, | \, a <0 \lor \left( \exists n \in \mathbb N : a <  \left(1 + \frac{1}{n}\right)^n \right) \right\}$ $\pi = \left\{a\in\mathbb Q \, | \, a <0 \lor \left( \exists n \in \mathbb N : a^2 < \displaystyle\sum_{i=1}^n \frac{6}{i^2} \right) \right\}$ The justification for these seemly arbitrary cuts is the simple fact that $$e := \displaystyle\lim_{n \to \infty}\left(1 + \frac{1}{n}\right)^n$$ and $$\pi^2 = \displaystyle\lim_{n \to \infty} \displaystyle\sum_{i=1}^n \frac{6}{i^2}$$ Are these cuts valid, and how would one attempt to show that they indeed satisfy the requirements for $\alpha$ ?","['real-analysis', 'real-numbers', 'analysis']"
1996806,"Show that for any $x,y \in X$, $\sum_{k=1}^\infty|\left<x,e_k\right>\left<y,e_k\right>|\le \|x\|\|y\|.$ [duplicate]","This question already has an answer here : Proving $\sum\limits_{i=1}^k | \langle x,v_i \rangle \langle y,v_i\rangle| \leq \|x\|\cdot \|y\|$ (1 answer) Closed 5 years ago . Let $(e_k)$ be any orthonormal sequence in an inner product space $X$. Show that for any $x,y \in X$ $$\sum_{k=1}^\infty|\left<x,e_k\right>\left<y,e_k\right>|\le \|x\|\|y\|.$$ If $x=y$, then the proof becomes trivial, as then the result follows directly from Bessel's inequality $$\sum_{k=1}^\infty|\left<x,e_k\right>|^2\le \|x\|^2.$$ Now suppose that $x \neq y$, then \begin{align}\sum_{k=1}^\infty |\left<x,e_k\right>\left<y,e_k\right>| &= \sum_{k=1}^\infty \left|\left<\left<x,e_k\right>y,e_k\right>\right|\end{align}
But I have no idea where to continue from here. Can anyone please help point me in the right direction?","['functional-analysis', 'orthonormal', 'inner-products']"
1996824,How to change the order of integration when angles and trigonometric functions are involved in limits?,"Problem: Change the order of integration of $$\int_0^{\pi/2}\int_0^{\cos(\theta)}\ \cos{(\theta)}\ dr\,d\theta$$ Solution: First, I've made a plot of the given region: $$0\leqslant\ r \leqslant \cos(\theta)$$ $$0\leqslant\ \theta \leqslant \pi/2$$ I have tried to define the new limits, $$\int_0^1\int_0^{\cos(\theta)}\ \cos(\theta)\ d\theta\, dr$$ Some suggestions, tips,... to understand how to define limits when angles and trigonometric functions are involved in the original limits?",['multivariable-calculus']
1996884,"Investigate the stability of the origin for $\dot x=-y^2$, $ \dot y = -y + x^2 + xy$","I need to determine the stability of the origin of the following system of differential equations $$\pmatrix{\dot x \\ \dot y} = \pmatrix{-y^2 \\ -y + x^2 + xy},$$ using the Local Center Manifold Theorem as defined below. Local Center Manifold Theorem : Let ${\bf f} \in C^r(E)$, where $E$ is an open subset of $\mathbb R^n$ containing the origin and $r \ge 1$. Suppose that ${\bf f}({\bf 0}) = {\bf 0}$ and that $D{\bf f}({\bf 0})$ has $c$ eigenvalues with zero real parts and $s$ eigenvalues with negative real parts, where $c+s = n$. The system $\dot {\bf x} = {\bf f}({\bf x})$ then can be written in the diagonal form $$\begin{cases}\dot{\bf x} &= C{\bf x} + {\bf F}({\bf x}, {\bf y}) \\ \dot{\bf y} & = P{\bf y} + {\bf G}({\bf x}, {\bf y}),\end{cases}$$ where $({\bf x}, {\bf y}) \in \mathbb R^c \times \mathbb R^s$, $C$ is a square matrix with $c$ eigenvalues having zero real parts, $P$ is a square matrix with $s$ eigenvalues with negative real parts, and ${\bf F}({\bf 0}) = {\bf G}({\bf 0}) = {\bf 0}, D{\bf F}({\bf 0}) = D{\bf G}({\bf 0}) = O$; furthermore, there exists $\delta > 0$ and a function ${\bf h} \in C^r(N_\delta({\bf 0}))$ that defines the local center manifold $$W^c_{\text{loc}}({\bf 0}) = \{({\bf x}, {\bf y}) \in \mathbb R^c \times \mathbb R^s : {\bf y} = {\bf h}({\bf x}) \text{ for } |{\bf x}| < \delta\}$$ and satisfies $$D{\bf h}({\bf x})[C{\bf x} + {\bf F}({\bf x}, {\bf h}({\bf x}))] - P{\bf h}({\bf x}) - {\bf G}({\bf x}, {\bf h}({\bf x})) = 0$$ for $|{\bf x}| < \delta$; and the flow on the center manifold $W^c({\bf 0})$ is defined by the system of differential equations $$\dot {\bf x} = C{\bf x} + {\bf F}({\bf x}, {\bf h}({\bf x}))$$ for all ${\bf x} \in \mathbb R^c$ with $|{\bf x}| < \delta$. I have begun to attempt to solve the problem, namely by letting $f({\bf x}) = \pmatrix{-y^2 \\ -y + x^2 + xy}.$ Then, $$D{\bf f}({\bf x}) = \pmatrix{0 & -2y\\2x + y & x - 1} \implies D{\bf f}({\bf 0}) = \pmatrix{0 & -2\\0 & -1},$$ which has eigenvalues of $0$ and $-1$. Thus, following the above theorem, $C = O$ and $P = [-1]$, as well as $F(x,y) = -y^2$ and $G(x,y) = x^2 + xy$ (just take the nonlinear part of the original systems). Then the system is now in diagonal form. Here's where I am unfortunately stuck . I'm trying to follow examples in my textbook like the one found here on the first page . Almost magically, they come up with the next part which is the function $h$ with no explanation of how they come up with the terms that they do. I understand that we omit the linear terms $1$ and $x$ because this would mean $(x,h(x))$ is tangent to the origin, as I have discovered here . But how do I know what terms to include or even when to stop? I've been looking at some examples and sometimes they have an $xy$ term in there in addition to the powers of $x$, especially when the dimension of the system gets higher. The reason being is that the next step is to plug $h(x) = ax^2 + bx^3 + \cdots$ into the equation we have above, i.e., $D{\bf h}({\bf x})[C{\bf x} + {\bf F}({\bf x}, {\bf h}({\bf x}))] - P{\bf h}({\bf x}) - {\bf G}({\bf x}, {\bf h}({\bf x})) = 0$ to find the unknown coefficients. Short of just guessing can anyone provide some insight on how we come up with the form of $h$? (short of just guessing).","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems']"
1996918,Show that the closure of a set A is the smallest closed set containing A.,"I need to prove that $\bar A$ (the closure of set A) is the smallest closed set containing A. We have already proved that it is a closed set, so now I just need to show that it is the smallest one. I have written a preliminary proof that I don't think is particularly rigorous, and would be grateful if someone could give me some pointers. We haven't covered anything regarding metric spaces or anything else in topology, so I had trouble understanding other solutions posted on the site. Let $A$ be a non-empty set, and $\bar A$ the closure of $A$ (the union of $A$ and all of its limit points). Let $B$ be a closed set with $A \subset B \subset \bar A$ and $B \neq \bar A$ . Since $A \subset B$ and $B \subset \bar A$ , $B$ consists of all the elements of $A$ and some (but not all) of its limit points. However, this means that there are sequences contained entirely within $B$ whose limit points are not elements of $B$ . Thus, $B$ is not closed, posing a contradiction to the original statement.","['general-topology', 'proof-writing', 'proof-verification']"
1996964,Entire function and injectivity [duplicate],"This question already has answers here : Proving that all entire and injective functions take the form $f = ax + b$? (3 answers) Closed 7 years ago . So if $f(z)=az+b$, is an entire injective map from $\Bbb C$ to $\Bbb C$, for both a and b are complex numbers and a is not equal to 0. I've proved that if f is an injective entire function, it cannot have an essential singularity at infinity, but then how to show that $f(z)$ has to be a polynomial? And why $f(z)$ has to satisfy that $f(z)=az+b$?","['laurent-series', 'complex-analysis', 'polynomials', 'entire-functions']"
1997004,A normal subgroup with an additional property,"Let $G$ be a Lie group and let $H$ be a closed subgroup such that $g_1g_2\in H$ for all $g_1,g_2\in H^c$. Now since $H^c$ is open then it's a manifold and actually we have transitive action of $H$ on $H^c$ by the group multiplication. The isotropy group is $\{e\}$.   Thus, $H$ is diffeomorphic to $H^c$. An example of this is the orthogonal group $O(n)$, since the special orthogonal group $SO(n)$ is a closed subgroup and satisfies the property above then   $SO(n)\cong SO(n)^c$. My question: could this be interesting somewhere in geometry? In general what are those Lie groups have such normal subgroups? And what Tits fibration would be?","['group-actions', 'topological-groups', 'differential-geometry', 'lie-groups']"
1997052,Real function such that restriction to any uncountable set is surjective,"This is a problem posed by my professor, which I don't know how to prove (or find an example) Does there exist a function $f:\mathbb{R} \to \mathbb{R}$ such that the restriction of $f$ to any $A \subset \mathbb{R}$ with $|A| = \mathfrak{c}$  is surjective? As I've said, I haven't made significant progress. An observation is that such a function is everywhere discontinuous but Darboux. I considered the Conway Base $13$ as a possible candidate, but I'm not sure if it takes on all real values when restricted to (for example) the Cantor set.","['real-analysis', 'elementary-set-theory']"
1997057,Evaluating contour integral along the boundary of the fundamental domain of $SL_2(\mathbb{Z})$ near poles,"Background: I'm working through Serre's introduction to modular forms in A Course in Arithmetic , Ch. 6, $\S 3$, where we prove the weighted sum of the count of poles and zeros on the fundamental domain is k/12 (k/6 by Serre's notation). The contour integral is broken into pieces, some of which are arcs of circles. I don't understand why the contour integrals along these arcs are proportional to the portion of the circumference the path takes. Question: Let $f$ be a modular function of weight $2k$. Let $C$ be a negatively-oriented circlular path centered at $\rho=e^{2\pi/3}$ with radius $r>0$. For sufficiently small $r$ (we in fact take the limit as $r\to\infty$), the closed contour integral $\frac{1}{2i\pi}\int_C \frac{df}{f}=-v_\rho(f)$, but I don't see why evaluating only along 1/6 of the circumference produces 1/6 the result - for instance, if $a=\rho+ir$ and we integrate clockwise along the arc of a circle of radius $r$ centered at $\rho$ to $b$ on the unit circle, $$\frac{1}{2i\pi}\lim_{r\to 0}\int_{a}^{b}\frac{df}{f}=-\frac{1}{6}v_\rho(f).$$
I'm not sure if this is a general property of complex analysis - because the radius is going to zero, the value of the function becomes constant along the contour, so the integral becomes linear in arc length? - or a property of modular functions in particular.","['complex-analysis', 'modular-forms']"
1997169,Compare big exponent numbers using logarithms and without logarithms,"It's from an exam problem mostly, however, I believe will help many others out here. Problem #1 Which one is bigger: $31^{11}$ OR $17^{14}$ Problem #2 Which one is bigger: $31^{11}$ OR $14^{14}$ My logarithmic way for first one: $31^{11}$ ? $17^{14} \rightarrow 31 ? \;17^{14/11} \rightarrow 31 ?\; (17\cdot17^{0.3}$).
So $31^{11}$ < $17^{14}$. However, the problem with this way is the $17^{0.3}$, which I can't calculate without a calculator. So Problem #3 How $17^{0.3}$ can be calculated without a calculator (while assuming I've memorized the values of $\log 2,\log 3,\log 5$ and $\log 7$.) Please mention if there's any general way to solve these problems, fast! Thank you!","['algebra-precalculus', 'inequality', 'exponentiation', 'logarithms']"
1997284,Number of Bit Operation in fast multiplication Algorithm,Determine  a  Value  for  the  constant $C$ and  use  it  to  estimate  the      number  of  bit  operations  needed  to  multiply  two 64-bit integers using the Fast Multiplication Algorithm Attempt/Analysis-: Let me write the recursive equation for Fast Multiplication ( Karatsuba_algorithm ) $f \left(2n\right)$ = $3*f \left(n\right)+C*n$ As The bit operations involves 3 operation -: $1 .\text{Shift operation} $ $2 .\text{Add operation} $ $3 .\text{Subtract operation} $ $\Rightarrow \text{I know that shifting $n$ places would require n bit operation.} $ $\Rightarrow \text{I know that Addition of 2$n$ bit number  would require atmost $3n$ bit operation.} $ $\Rightarrow \text{I know that Subtraction of 2$n$ bit number  would require atmost $3n$ bit operation.} $ I am unable to move forward ....please help me out...answer is $50$ n,"['recurrence-relations', 'discrete-mathematics']"
1997330,Using moment generating function to calculate expectation of a random variable,"I'm having difficulties with a statistics problem on the book Rice - Mathematical statistics regarding moment generating function. I was given a random variable $X$ and i derived that the first order derivative of mgf of $X$ is 
$$M'(t) =  2(e^t/t - 2e^t/t^2 + 2e^t/t^3 -2/t^3)$$ To calculate the $E(X)$, I have to plug in $t=0$ into $M'(t)$. However since the terms have t as denominator, I cannot simply plug in $t=0$. I have seen solution online that takes the limit of $t$ approaching $0$ of the function $M'(t)$ instead to calculate $M'(0)$. But I don't understand why so. Can someone please help me?","['statistics', 'calculus']"
1997407,What is the relationship between the characteristic polynomial of a product vs. the product of characteristic polynomials,"What is the relationship between the characteristic polynomial of two square matrices and the characteristic polynomial of the product of these two square matrices? If I know the characteristic polynomials of each one of these matrices, what can I say about the characteristic polynomial of their product?
I can't seem to find this information anywhere. Thank you!","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1997424,"Rigorous definition of ""differential""","When it comes to definitions, I will be very strict. Most textbooks tend to define differential of a function/variable like this: Let $f(x)$ be a differentiable function. By assuming that changes in $x$ are small enough, we can say:
$$\Delta f(x)\approx  {f}'(x)\Delta x$$
Where $\Delta f(x)$ is the changes in the value of function. Now we define differential of $f(x)$ as follows:
$$\mathrm{d}f(x):= {f}'(x)\mathrm{d} x$$
Where $\mathrm{d} f(x)$ is the differential of $f(x)$ and $\mathrm{d} x$ is the differential of $x$. What bothers me is this definition is completely circular. I mean we are defining differential by differential itself. Can we define differential more precisely and rigorously? P.S.
Is it possible to define differential simply as the limit of a difference as the difference approaches zero?:
$$\mathrm{d}x= \lim_{\Delta x \to 0}\Delta x$$
Thank you in advance. EDIT: I still think I didn't catch the best answer. I prefer the answer to be in the context of ""Calculus"" or ""Analysis"" rather than the ""Theory of Differential forms"". And again I don't want a circular definition. I think it is possible to define ""Differential"" with the use of ""Limits"" in some way. Thank you in advance. EDIT 2 (Answer to ""Mikhail Katz""'s comment): the account I gave in terms of the hyperreal number system which contains infinitesimals seems to respond to your concerns. I would be happy to elaborate if anything seems unclear. – Mikhail Katz Thank you for your help. I have two issues: First of all we define differential as $\mathrm{d} f(x)=f'(x)\mathrm{d} x$ then we deceive ourselves that $\mathrm{d} x$ is nothing but another representation of $\Delta x$ and then without clarifying the reason, we indeed treat $\mathrm{d} x$ as the differential of the variable $x$ and then we write the derivative of $f(x)$ as the ratio of $\mathrm{d} f(x)$ to $\mathrm{d} x$. So we literally (and also by stealthily screwing ourselves) defined ""Differential"" by another differential and it is circular. Secondly (at least I think) it could be possible to define differential without having any knowledge of the notion of derivative. So we can define ""Derivative"" and ""Differential"" independently and then deduce that the relation $f'{(x)}=\frac{\mathrm{d} f(x)}{\mathrm{d} x}$ is just a natural result of their definitions (using possibly the notion of limits) and is not related to the definition itself. I know the relation $\mathrm{d} f(x)=f'(x)\mathrm{d} x$ always works and it will always give us a way to calculate differentials. But I (as an strictly axiomaticist person) couldn't accept it as a definition of Differential. EDIT 3: Answer to comments: I am not aware of any textbook defining differentials like this. What kind of textbooks have you been reading? – Najib Idrissi which textbooks? – m_t_ Check ""Calculus and Analytic Geometry"", ""Thomas-Finney"", 9th edition, page 251 and ""Calculus: Early Transcendentals"", ""Stewart"", 8th edition, page 254 They literally defined differential by another differential.","['real-analysis', 'differential', 'calculus', 'infinitesimals', 'definition']"
1997439,"If $A,B,$ and $C$ are sets, then $A\times(B-C)$ = $(A \times B)$ $-$ $(A \times C)$.","If $A,B,$ and $C$ are sets, then $A\times(B-C)$ = $(A \times B)$ $-$ $(A \times C)$. Proof. Observe the following sequence of equalities. $$\begin{align}
A\times(B-C) &= \{(x,y)\} : (x \in A) \wedge (y \in (B-C))\} \, (\text{Definition of Cartesian Product}) \\
&=\{(x,y) : (x \in A) \wedge \big((y \in B) \wedge (y\notin C)\big)\} \,
 (\text{Definition of } -) \\ 
&=\{(x,y) : (x \in A) \wedge (x \in A) \wedge \big((y \in B) \wedge (y\notin C)\big)\} \, (P=P \wedge P) \\
&=\{(x,y) : \big((x \in A) \wedge (y \in B)\big) \wedge \big((x \in A) \wedge (y\notin C)\big)\} \, (\text{Rearrange}) \\
&=\{(x,y) : \big((x \in A) \wedge (y \in B)\big) \wedge \big((x \in A) \wedge (y\notin C)\big)\} \, (\text{Definition of }\cap) \\
\end{align}$$ I'm stuck on the last part -- $(x \in A) \wedge (y\notin C)$ translates to $(A-C)$ but I need it to be $(A \times C)$. I can't quite figure out how to reach that.",['elementary-set-theory']
1997454,Why does this particular ratio of prime numbers seems to converge to 3?,"I noticed this interesting property of prime numbers, and I'd like to know if it has an explanation/proof/disproof. Define $p(n)$ to be the $n$'th prime number. Define the following sequence: 
 $$\Sigma(n) =
\begin{cases}
p(1),  & \text{if $n=1$} \\
\Sigma(n-1)+p(n), & \text{if $n>1$ and  $\Sigma(n-1)-p(n)<0$} \\
\Sigma(n-1)-p(n), & \text{otherwise}
\end{cases}$$ The first few elements of the sequence are:  $2,5,0,7,18,5,22,3,26,55$. Now, in $\Sigma(n)$ lets look at all indexes $n$'s such that $\Sigma(n-1)<\Sigma(n)<\Sigma(n+1)$. These indexes also form a sequence, which I'll denote by $a(k)$. Here are its first elements: $4,9,22,57,146,367,946,2507$. So, what I noticed is that these two limits seem to hold: 
$$\lim_{k\to \infty}\frac{p(a(k+1))}{p(a(k))} = 3$$
$$\lim_{k\to \infty}\frac{\Sigma(a(k+1))}{\Sigma(a(k))} = 3$$ Here is a graph of the former of these ratios: Of course, these are only empirical findings. Do you have other reasons to believe that they are true?","['number-theory', 'experimental-mathematics', 'elementary-number-theory']"
1997482,dividing n with 2 until you get odd number (Function),"So I'm not really sure how to phrase this question so i apologize in advance. I am trying to find a function that matches the image below. I generated this image by iterating through hole numbers between 1 and 100. Then I counted how many divisions of 2 it could do until it would reach an odd number (The y axis number of divisions). So my question is, is there any function that matches this graph at the points not necessarily the lines? (I am thinking some kind of trick with modular)","['modular-arithmetic', 'functions', 'graphing-functions']"
1997608,Solving the equation $(x+1)xy''+(x+2)y'-y=0$,Find the general solution to the equation $(x+1)xy''+(x+2)y'-y=0$ given that one of the solutions is a polynomial. Here's what I did: plugging in $y=Ax^2+Bx+C$ we find that $y_1=x+2$ solves the equation. Then we can try to find a solution of the form $y_2=y_1 z = (x+2) z$. From the original differential equation we obtain $z''+\left ( \frac{2}{x+2}+\frac{x+2}{x(x+1)} \right)z'=0$. Then we must do fraction decomposition and the substitution $w=z'$ so we obtain $w=\frac{x+1}{x^2 (x+1)^2}$. Then we need to integrate the function $\frac{x+1}{x^2 (x+1)^2}$ which requires fraction decomposition once again and we arrive at the result $z=-\frac{1}{2x(x+2)}$ which in turn gives us $y_2=-1/(2x)$. Although I got the correct result I wonder whether there is a simpler way of arriving at this solution (avoiding so many fraction decompositions and integrations which I omitted here). Maybe there's some better substitution that will work?,['ordinary-differential-equations']
1997613,Prove that $\frac{p^p-1}{p-1}$ is not prime if $p \equiv 1 \pmod 4$,"Let $p$ be a prime number such that $p \equiv 1 \pmod 4$. Prove that  $\frac{p^p-1}{p-1}$ is not prime. We can rewrite $\frac{p^p-1}{p-1}$ as $$\dfrac{p^p-1}{p-1} = 1+p+p^2+\cdots+p^{p-1},$$but how do we show this is not prime?",['number-theory']
1997703,Elementary problem of geometry involving equilateral triangles,"I have the following exercise of elementary geometry: Given a triangle $ABC$, and draw (to the outside of this triangle) two equilateral triangles $ABE$ and $ACF$. Let $M,P$ be the midpoints of $BC,EF$ respectively and $H$ the projection of $A$ on $EF$. Prove that $MP=MH$. Sorry if this problem bothers you, but I do not have any idea to do it, except using coordinates. Does someone have any idea?","['geometric-transformation', 'euclidean-geometry', 'geometry']"
1997709,Calculate this limit : $\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right]$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Calculate the limit $$\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right]$$ Neither L'Hospital's rule nor Taylor expansions are allowed,","['limits-without-lhopital', 'limits']"
1997722,What is the probability that a quadrilateral inside a square is convex?,"Need probability that ABCD is convex if the points have coordinates $(x_1,y_1)(x_2,y_2)(x_3,y_3)(x_4,y_4)$ where $x_i,y_i\in[0,1]$ are uniformly equiprobable. It would be same as the expected value of the green area but I can't get it... I guess Monte Carlo would do the job","['probability', 'geometric-probability']"
1997725,The set of points of boundedness of a function is open,"I was reading (self study) the book by Thomson Bruckner and Bruckner and ran into one of the exercises that I think I have the proof for by not sure it is right. The statement of the problem goes as follows. A function $f:\mathbb{R} \mapsto \mathbb{R}$ is said to be bounded at a point $x_o$ provided there are positive number $\epsilon$ and $M$ so that $|f(x)| < M$. for all $x \in (x_o - \epsilon, x_o + \epsilon)$. Show that the set of points at which a function is bounded is open. Let $E$ be an arbitrary closed set. Is it possible to construct a function $f:\mathbb{R} \mapsto \mathbb{R}$ so that the set of points at which f is not bounded is precisely the set E? My Proof of the first section of the problem was as follows. Let $B_f = \{x : |f(x)| < M, M > 0 \}$ the set of all points where $f$ is bounded (note $M = sup(\{M_x : x \in \mathbb{R}, |f(x)| < M_x\})$ over each $x$, This $sup(\{M_x : x \in \mathbb{R}, |f(x)| < M_x\})$ is bounded and exists, since each $M_x$ is bounded). Then if for every $x \in B_f$ we have by our definition of bounded function at a point, $\forall x \in B_f \ \exists \epsilon > 0 \text{ and } \forall x \in (x - \epsilon, x + \epsilon)$ we have $|f(x)| < M_x$, but this would mean $(x - \epsilon, x + \epsilon) \subset B_f$ which means that $x$ is a interior point of $B_f$. The conclusion follows that $B_f$ is open. I have no clue how to construct the function for the second half of the question. I was wondering if my proof is right? If someone can provide an example for the second part of the question I would be extremely thankful.",['analysis']
1997735,"If $A$ is open and $A\subset B$, is $B$ open?","Is it true that, if $A \subset B$ and $A$ is open, then $B$ is open?","['general-topology', 'elementary-set-theory']"
1997808,Closed sets and subtraction of elements.,"Let $X$ be a normed vector space, $A,B\subset X$ closed and $M=A-B:=\{x\in X:x=a-b ,\quad a\in A, b \in B\}$. I am looking for an example where $A,B\quad$ closed $\Longrightarrow\quad M\quad$ closed is wrong.","['functional-analysis', 'normed-spaces', 'general-topology']"
1997948,"Let $G = (V, E)$ be a graph. What is a mutual neighbor of a set $R$ where $R \subset V(G)$?","Let $G = (V,E)$ be a graph with $V$ set of vertices, $E$ edges. What is the set of mutual neigbors of a set $R \subset V(G)$? In particular, what is a mutual neighbor of a set $R \subset V(G)$? This notation is at the end of page 2 of the following paper and I could not find any definition on the Internet: https://www.ethz.ch/content/dam/ethz/special-interest/eth-its/Documents/lecture5.pdf Thank you in advance!","['graph-theory', 'random-graphs', 'discrete-mathematics']"
1997959,"On rearrangement of level set: $\{f>t\}^* = \{f^*>t\}\,\,\text{?}$","Let $A$ be a subset of $\mathbb{R}^n$ then the rearrangement of $A$ denoted by $A^*$ is the ball $B(0,r)$ having the same volume as $A$ i.e if  $|A| =|B(0,r)|$  with respect to Lebesgue measure then $$A^*= B(0,r)$$ Let $f$ be a function from $\mathbb{R}^n$ to $\mathbb{R}$. Then its symmetric decreasing rearrangement $f^*$ is the function defined for $x \in  \mathbb{R}^n$ by $$f^*(x) = \int_0^{\infty} 1_{\{f>t\}^*}(x) dt.$$ Where $1_{\{f>t\}^*}$ is the characteristic function of the set $\{f>t\}^*= B(0,r_t )$ on $\mathbb{R}^n$ for suitable $r_t >0$. The set $\{f>t\} := \{x \in \mathbb{R}^n: f(x)>t\}$ is called the $t$-level set of the function $f$. Question. How can I show that
  $$\{f>t\}^* = \{f^*>t\}\,\,\text{?}$$ This is mentioned to be easy in the book of Elliott Lieb and Loss (Analysis second edition, Graduate Studies in Mathematical,
vol 14, American mathematical Society, providence, RI 2001).","['harmonic-analysis', 'decreasing-rearrangements', 'measure-theory']"
1997975,Proof that field trace in $GF(2^k)$ maps half of the elements to 0 and the other half to 1.,"I'm reading a proof on the solutions of equation $a = z^z + z$ in $GF(2^k)$, that is, the finite field with $2^k$. At some point it uses that the trace function defined as $Tr(a) = a + a^2 +  \cdots + a^{2^{k-1}}$ maps half of the elements of $GF(2^k)$ to 0 and half of the elements to 1. I'm trying to proof it. My approach The solutions of the equations are proved to be of the form $\theta$ and $\theta + 1$. As the trace is linear we have $Tr(\theta + 1) = Tr(\theta) + Tr(1)$. If k is odd then $Tr(1) = 1 + 1^2 + \cdots + 1^{2^{k-1}} = 1$ so it is natural to define from the set $$A = \{ a \in GF(2^k):Tr(a) = 0\}$$ to $$B = \{ a \in GF(2^k):Tr(a) = 1\}$$ the mapping $f(a) = a+1$. This mapping appears to me to a bijection. What happens if k is even?","['finite-groups', 'abstract-algebra', 'finite-fields', 'group-theory']"
1998010,Brezis' exercise 4.19,"I'm having trouble with problem 4.19 of Brezis' book in functional analysis (Functional Analysis, Sobolev Spaces and Partial Differential Equations). It asks for a sequence $f_n\geq 0$ in $L^1(0,1)$ and a function $f\in L^1(0,1)$ such that $f_n \to f$ weakly $\sigma(L^1,L^\infty)$; $||f_n||_1 \to ||f||_1$; $||f_n-f||_1 \not \to 0$. What sequence $f_n$ work? I know that i cannot choose $f=0$ because statement 2 would contradicts 3.","['functional-analysis', 'lp-spaces', 'weak-convergence']"
1998076,Find the following partial derivatives for a nested function? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question For $g(t,x) = f(t , h(t,x))$ find the following partial derivatives: 
$\frac{\partial g}{\partial t}$, $\frac{\partial g}{\partial x}$, $\frac{\partial^2 g}{\partial x^2}$","['multivariable-calculus', 'partial-derivative', 'chain-rule']"
1998097,Largest domain where $\text{Log}(z-z_0)$ is analytic,"I need to find the largest domain where $\text{Log}(z-z_0)$ with the definition that $\text{Log} z = \ln |z| +\text{Arg} \ z$ is analytic. I know that $\text{Log} \ z$ is analytic in $\mathbb{C}-D^* $, where $D^* = \{x+iy; x\le 0, y=0\}$ But how to apply that for $\text{Log}(z-z_0)$? Wouldn't it be just the set $S = \{z; \text{Re}(z-z_0)\le 0, \text{Im}(z-z_0)=0\}$?","['complex-analysis', 'functions']"
1998105,Group of units of localization,"Let $R$ be a commutative ring with $1$. Let $S \subset R$ be a multiplicatively closed set.
  What are the units of $S^{-1}R$ ? This question is probably too broad, so let's focus on integral domains $R$, and $0 \not \in S$ (so that the localization is not the zero ring and the natural morphism $i : R \to S^{-1}R$ is injective). I think I proved that
$$A:= \left\{
\dfrac{a}{s}    \;\Big\vert\;   s \in S, a \in R^{\times} \cup S
\right\}$$
is a subgroup of $R^{\times}$.
Notice that if $R$ is a domain and $0 \not \in S$, then $a/s$ is a unit iff there is $(a',s') \in R \times S$ such that $aa'=ss'$. I'm not sure that $(S^{-1}R)^{\times} = A$ holds. Anyway, it would be nice to have some explicit description of $(S^{-1}R)^{\times}$. I found quite nothing on that topic (except maybe this or this ). Thank you very much for your comments!","['localization', 'abstract-algebra', 'ring-theory', 'commutative-algebra']"
1998115,"""Algebrization"" of Analytic Concepts","Please excuse my inventing new words in the title. I've been studying algebraic geometry, and one of my favourite parts of the subject (at least, before schemes) is the way that one can describe, or even define, the tangent space at a point $P$ of a variety $V$ purely algebraically, as the (dual space of) $\mathfrak{m}/\mathfrak{m}^2$, where $\mathfrak{m}$ is the unique maximal ideal of the local ring $\mathcal{O}_{V,P}$. Are there other instances of concepts which are traditionally analytic in nature, but have been given alternative algebraic descriptions? My search yielded little beyond differential algebra, which seems to be an underdeveloped subject of study, but I would think that if one wanted to ""re-imagine"" analysis using abstract algebra, this would be a good place to start - taking the interesting algebraic properties of derivative (such as the product rule) and building them into the definition of some new algebraic object. Algebraic analysis is apparently also a subject of study, but information is scarce. Conversely, are there instances of algebraic concepts being re-cast only in terms of analysis?","['abstract-algebra', 'algebraic-geometry', 'analysis']"
1998127,Where do we need compactness in this proof?,"Let $X$ be a metric space and $f:X\to X$ continuous. A dynamical system is called positively expansive if $$\exists c > 0 \ \ \forall x, y \in X \ \left( x \neq y \implies  \exists n \geq 1: d(f^n(x), f^n(y)) > c   \right).$$ According to my lecture notes, if $X$ is compact, positive expansiveness can be characterized topologically: Let $X$ be compact. Then $f$ is positively expansive iff there is a neighborhood $U$ of the diagonal $\Delta_X$ such that for all $(x,y)\in U \setminus \Delta_X$ holds $\mathcal O_{f \times f}(x,y)\not\subseteq U$. Where $\Delta_X := \{(x,y)\in X\times X \mid x=y \}$ $(f \times f)^n (x,y) := (f^n(x), f^n(y))$ $\mathcal O_{f \times f}(x,y):= \{(f \times f)^n (x,y) \mid n\geq1  \}$ The proof appears to be trivial with $U := \{ (x,y)\in X\times X \mid d(x,y) < c \}$ in one direction and a slight variation in another direction. But where do we need compactness here? Added : ""A slight variation in another direction"": $U\subseteq X\times X$ is a neighborhood of the diagonal $\Delta_X$ iff there exists $a > 0$ such that $V_a:= \{ (x,y)\in X\times X \mid d(x,y) < a \} \subset U$. Now with $c:=a$ we get the definition of positive expansiveness.","['general-topology', 'metric-spaces', 'dynamical-systems', 'compactness']"
1998142,Calculate the exact value of $f(1)$,"Having a function $f:\mathbb{N}\rightarrow\mathbb{N}$: $$f(n)=\left\{
			\begin{array}{lcc}
				n-3 & if & n \geq 1000
				\\f(f(n+6)) & if & n < 1000
			\end{array}
		\right\}$$
Calculate the exact value of $f(1)$ by hand. Is there an easy way to solve it?","['recursion', 'functions']"
1998143,Random walk that is not bounded in $L^1(P)$,"Let $T$ be a r.v. in $\mathbb{N}$ and $(Y_k)_{k\in\mathbb{N}}$ be an independent
  family of i.i.d. r.v. with $\operatorname{Var}(Y_1)=1$ and $\mathbb{E}(Y_1)=0$. Set $\mathcal{F}_n=\sigma(T,Y_1\dots,Y_n)$ and
  $$X_n:=\sum\limits_{k=1}^nY_n,\qquad n\geq 0$$
  1. Show that $(X_n)_{n\geq 0 } $ is a martingale but it is not bounded in $L^1(P)$ Name a distribution of $T$ s.t. the stopped martingale $(X_{n\wedge T})_{n\in \mathbb{N}}$ is still not bounded in $L^1(P)$ I can show that $(X_n)$ is a martingale and I know that by the CLT
$$P\left(\frac{X_n}{\sqrt{n}}\right)\xrightarrow{n\to \infty} \mathcal{N}(0,1)$$
But I have absolutely no idea how to prove that $(X_n)$ is not bounded in $L^1(P)$. I find it strange since $\mathbb{E}(X_n)=\sum\limits_{k=1}^n\mathbb{E}(Y_n)=0$. Do I have to show somehow that it is not uniform integrable? Or is there someway to change the CLT that we can influence the expected value in the limit? For 2.) I also have no idea.","['random-walk', 'probability-theory', 'filtrations', 'martingales', 'convergence-divergence']"
1998149,Set theory and injectivity,"So right now I'm working through Topology by Munkres and reviewing some basic set theory. I came across the following problem: Show $f(A-B) \supset f(A)-f(B)$ with equality iff $f$ is injective. The problem I'm having here is that I feel I can show equality without $f$ being injective. My proof  to show the reverse inclusion goes as follows: take $y \in f(A-B)$. This means that $y = f(a)$ for some $a \in A-B$. So, as $a \in A$ and $a \notin B$,  $f(a) \in f(A)$ and $f(a) \notin f(B)$. Since $y=f(a)$ then $y \in f(A)-f(B)$. I feel like this shows equality without injectivity but I know from looking up other answers I am wrong.",['functions']
1998177,Is there a way to calculate $ \sum_{k=0}^{n}\sin({2^kx})$?,"The context for this question is basic curiosity.  I know that there are formulas for calculating $\displaystyle \sum_{k=0}^{n}\sin({kx})$ and $\displaystyle \sum_{k=0}^{n}\sin({2kx})$.  Is there a formula/method/identity that could be used to find
$\displaystyle \sum_{k=0}^{n}\sin({2^kx})$ ?","['trigonometry', 'trigonometric-integrals']"
1998220,Integral bounds when finding surface are of hyperbolic paraboloid $z=y^2-x^2$ between cylinders by switching to cylindrical coords,"I came to this problem, and had to look up cylindrical coords since we didn't cover them in any of my classes. But from everything I've read so far I'm still unsure about how they got the 4 and 2 fro the upper and lower bounds of the inner integral. Can someone please explain this?","['cylindrical-coordinates', 'partial-derivative', 'multivariable-calculus', 'integration', 'surfaces']"
1998292,Pythagorean triples and Pell numbers.,"This problem is mentioned in this one , but I think it deserves some attention on its own. So here it is: For any integers $n,m > 0$: If $2mn(n+m)(n-m)$ divides  $(n^2 + m^2 + 1)(n^2 + m^2 - 1)$, then is it true that $n,m$ are a pair of consecutive Pell-numbers, where the Pell-numbers are given recursively by: $P_0 = 0$ $P_1 = 1$ $P_{n+2} = 2P_{n-1} + P_{n-2}$. The converse is definitely true. See Wikipedia article on Pell numbers , and the OEIS page . Remark: Notice that this implies the quotient of $(n^2 + m^2 + 1)(n^2 + m^2 - 1)$ by 
$2mn(n+m)(n-m)$ is then 2 if $m < n$ and $-2$ if $n < m$. So that in the case when $n,m$ are coprime we have following, if the above is true: Let $(a,b,c)$ be a primitive Pythagorean triple. If $ab \mid c^2 - 1$, then $2ab = c^2 - 1$. -","['number-theory', 'contest-math', 'elementary-number-theory']"
1998301,Abelianization of the direct product is the direct product of the abelianizations?,"I'm trying to prove that $(H \times K)^{ab} \cong H^{ab} \times K^{ab}$, by invoking the universal property of abelianization. As $(H^{ab} \times K^{ab})$ is an abelian group, we know that, for the abelianization map $ \phi : (H \times K) \rightarrow (H \times K) ^{ab}$, we can define a group homomorphism $f : (H \times K) \rightarrow (H^{ab} \times K^{ab})$, with the existence of a unique $F: (H \times K) ^{ab} \rightarrow (H^{ab} \times K^{ab})$ such that $f = F \circ \phi$ ensured by the universal property. So F ensures that $(H \times K)^{ab}$ is homomorphic to $H^{ab} \times K^{ab}$ pretty straight-forwardly. I'm not exactly sure how to go further, though, and show that $f$ is actually an isomorphism. Theoretically, I could show that $\phi$ and $f$ are both isomorphic, and then the condition about F would follow (as $F = f \circ \phi^{-1}$, when $\phi^{-1}$ is defined). But I don't have much intuition about doing that. Some guidance would be appreciated. EDIT: $\phi$ has a trivial kernel iff the commutator subgroup is trivial ... which would seem to mean that $\phi$ can only be an isomorphism, logically, when $(H \times K)$ is abelian. We're working with arbitrary $H, K$ here, so I'm guessing my strategy isn't on point.","['abstract-algebra', 'group-theory']"
1998326,What elements are in this set?,"Given the set $M = \{n\in\mathbb{N}\ |\ \forall z(z\in\mathbb{N}\rightarrow z\leq n\}$ I think this set is empty. Here's why: Let $k$ be in the set. Hence, $k\in\mathbb{N}$. Let $z=k+1$. So $k+1\leq k$ must hold. But $1\leq 0$ is always false. So there are no elements in $M$. But I'm not really sure because a logical implication is also true if the assumption ($z\in\mathbb{N}$) is false. So what if $z$ is not in $\mathbb{N}$? Would that make $M$ an infinitely large set? And if so, what elements would be in $M$?","['logic', 'elementary-set-theory']"
1998338,"X ~ N(0,1) What is the CDF of random vector $ \begin{pmatrix} X\\ X\\ \end{pmatrix}$ [duplicate]","This question already exists : What is the distribution function of $\left( \begin{smallmatrix} X \\ (-1)^nX \\ \end{smallmatrix}\right)$ where $X\sim N(0,1)$ [closed] Closed 7 years ago . Is this the degenerate case? Would the CDF just be that of the standard normal?
Thanks for the help.",['probability-theory']
1998373,"Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function. If $f(0)=f(1)$ then exists $x\in [0,1]$ s.t. $f(x) = f(x+\frac{1}{2})$","Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function. If $f(0)=f(1)$ then exists $x\in [0,1]$ s.t. $f(x) = f(x+\frac{1}{2})$ We have that $f\left(\frac{1}{2}\right)=f(0)$ or $f\left(\frac{1}{2}\right)>f(0)$ or $f\left(\frac{1}{2}\right)<f(0)$. If $f\left(\frac{1}{2}\right)=f(0)$ then $x = 0$ Solves the problem. if $f\left(\frac{1}{2}\right)<f(0)$ then by the intermediate value theorem 
$$\exists k \in \left[0,\frac{1}{2}\right], f(0)>f(k)>f\left(\frac{1}{2}\right) \implies$$ $$\implies f(1)>f(k)>f\left(\frac{1}{2}\right)\implies \exists t \in \left[\frac{1}{2},1\right] s.t. f(t)=f(k).$$ Now how can I show that exists at least one value of k such that $t = k+\frac{1}{2}$? (The solution is similar if $f(\frac{1}{2})>f(0)$)","['continuity', 'real-analysis', 'functions']"
1998391,Conditions on exponential function with natural exponent in the case of series of functions,"To define a real exponential function
$$f(x)=a^x=e^{x \,\mathrm{lg} a}$$ It is strictly necessary that $a>0$. But is the same true if the exponent is a natural number? In function series and moreover in power series I see things like
$$\sum_{n\geq0} f(n)  x^n, \,\,\,\, x\in \mathbb{R}$$
So there is not the resctriction $x>0$. It makes sense because natural number in the exponent do not create problems like even roots of negative numbers, so I think I'm ok with this. Nevertheless if I rewrite $x^n$ using the definition of logaritm (for example this passage is useful while evaluating limits of such expressions), I get $$\sum_{n\geq0} f(n) \,\, e^{n \, \mathrm{lg}x}$$ So suddenly I get a $\mathrm{lg}x$ and I need the condition $x>0$. On the one hand this passage should be valid because it is just the definition of logaritm, but on the other hand it looks like I cannot perform it without meet a restriction on $x$ that was not present in the form $x^n$. So what is the point here? Is the use of the definition of logaritm not allowed in these cases, or is it wrong to avoid setting the condition $x>0$ in $x^n$?","['power-series', 'real-analysis', 'sequences-and-series', 'functions']"
1998396,How to find Gaussian curvature here?,"$\textbf{Problem}$ Let $M=\mathbb{R}^{2}$ with the standard coordinates $(x,y)$. Consider the following Riemannian metric on $M$:
  $$dx^{2}+2\cos(\alpha(x,y))dxdy+dy^{2},$$
  where $\alpha$ is a smooth function on $M$ such that $\alpha(x,y)\neq\pi k,k\in\mathbb{Z}$ for all $(x,y)\in\mathbb{R}.$ (a) Prove that the vector fields
  $$e_{1}=\frac{\partial}{\partial x},\quad e_{2}=\frac{1}{\sin(\alpha(x,y))}\bigg(\frac{\partial}{\partial y}-\cos(\alpha(x,y))\frac{\partial}{\partial x}\bigg)$$
  constitute an orthonormal frame with respect to this Riemannian metric. (b) Find the dual coframe to the frame $(e_{1},e_{2})$. (c) Prove that the Gaussian curvature of this Riemannian metric is equal to $-\frac{\alpha_{xy}}{\sin\alpha}$. I am having trouble with (c). I think the dual coframes are given by
$$e_{1}^{*}=dx+\cos(\alpha(x,y))dy,\quad e_{2}^{*}=\sin(\alpha(x,y))dy.$$
I tried to use the equation
$$d\omega_{12}=-Ke_{1}^{*}\wedge e_{2}^{*}$$
where 
$$0=de_{1}=\omega_{11}e_{1}+\omega_{12}e_{2}$$
and so, $\omega_{11}=\omega_{12}=0$. But since $$e_{1}^{*}\wedge e_{2}^{*}=\sin(\alpha(x,y))dx\wedge dy,$$
it looks like $K=0$. What did I do wrong? $\large\textbf{The following was added to the original question following levap's answer.}$ We have $$\omega_{12}=\langle\nabla_{e_{1}}e_{1},e_{2}\rangle e^{1}+\langle\nabla_{e_{2}}e_{1},e_{2}\rangle e^{2}$$
and
$$\nabla_{e_{1}}e_{1}=\Gamma_{11}^{1}e_{1}+\Gamma_{11}^{2}e_{2},\quad\nabla_{e_{2}}e_{1}=\Gamma_{12}^{1}e_{1}+\Gamma_{12}^{2}e_{2}.$$
We have
$$\begin{gather*}\Gamma_{11}^{1}=\frac{1}{2}g^{11}\bigg(\frac{\partial g_{11}}{\partial x^{1}}+\frac{\partial g_{11}}{\partial x^{1}}-\frac{\partial g_{11}}{\partial x^{1}}\bigg)+\frac{1}{2}g^{12}\bigg(\frac{\partial g_{12}}{\partial x^{1}}+\frac{\partial g_{21}}{\partial x^{1}}-\frac{\partial g_{11}}{\partial x^{2}}\bigg)\\
\Gamma_{11}^{2}=\frac{1}{2}g^{21}\bigg(\frac{\partial g_{11}}{\partial x^{1}}+\frac{\partial g_{11}}{\partial x^{1}}-\frac{\partial g_{11}}{\partial x^{1}}\bigg)+\frac{1}{2}g^{22}\bigg(\frac{\partial g_{12}}{\partial x^{1}}+\frac{\partial g_{21}}{\partial x^{1}}-\frac{\partial g_{11}}{\partial x^{2}}\bigg)\\
\Gamma_{12}^{1}=\frac{1}{2}g^{11}\bigg(\frac{\partial g_{11}}{\partial x^{2}}+\frac{\partial g_{12}}{\partial x^{1}}-\frac{\partial g_{12}}{\partial x^{1}}\bigg)+\frac{1}{2}g^{12}\bigg(\frac{\partial g_{12}}{\partial x^{2}}+\frac{\partial g_{22}}{\partial x^{1}}-\frac{\partial g_{12}}{\partial x^{2}}\bigg)\\
\Gamma_{12}^{2}=\frac{1}{2}g^{21}\bigg(\frac{\partial g_{11}}{\partial x^{2}}+\frac{\partial g_{12}}{\partial x^{1}}-\frac{\partial g_{12}}{\partial x^{1}}\bigg)+\frac{1}{2}g^{22}\bigg(\frac{\partial g_{12}}{\partial x^{2}}+\frac{\partial g_{22}}{\partial x^{1}}-\frac{\partial g_{12}}{\partial x^{2}}\bigg)\end{gather*}$$
and
$$g=\begin{pmatrix}1&\cos(\alpha(x,y))\\
\cos(\alpha(x,y))&1\end{pmatrix},\quad g^{-1}=\begin{pmatrix}\frac{1}{1-\cos^{2}(\alpha(x,y))}&\frac{-\cos(\alpha(x,y))}{1-\cos^{2}(\alpha(x,y))}\\\frac{-\cos(\alpha(x,y))}{1-\cos^{2}(\alpha(x,y))}&\frac{1}{1-\cos^{2}(\alpha(x,y))}
\end{pmatrix}.$$
The Christoffel symbols turn out to be
$$\Gamma_{11}^{1}=\frac{\cos(\alpha(x,y))\alpha_{x}}{\sin(\alpha(x,y))},\quad\Gamma_{11}^{2}=\frac{-\alpha_{x}}{\sin(\alpha(x,y))},\quad\Gamma_{12}^{1}=0,\quad\Gamma_{12}^{2}=0.$$
So I got $$\nabla_{e_{1}}e_{1}=\begin{pmatrix}\bigg(\frac{\cos(\alpha(x,y))}{\sin(\alpha(x,y))}+\frac{\cos(\alpha(x,y))}{\sin^{2}(\alpha(x,y))}\bigg)\alpha_{x}\\\frac{-\alpha_{x}}{\sin^{2}(\alpha(x,y))}\end{pmatrix},\quad\nabla_{e_{2}}e_{1}=0$$
and
$\displaystyle\omega_{12}=\bigg\langle\begin{pmatrix}\bigg(\frac{\cos(\alpha(x,y))}{\sin(\alpha(x,y))}+\frac{\cos(\alpha(x,y))}{\sin^{2}(\alpha(x,y))}\bigg)\alpha_{x}\\\frac{-\alpha_{x}}{\sin^{2}(\alpha(x,y))}\end{pmatrix},\begin{pmatrix}\frac{-\cos(\alpha(x,y))}{\sin(\alpha(x,y))}\\\frac{1}{\sin(\alpha(x,y))}\end{pmatrix}\bigg\rangle(dx+\cos(\alpha(x,y))dy)=\frac{-\alpha_{x}}{\sin(\alpha)}dx-\frac{\alpha_{x}\cos(\alpha)}{\sin(\alpha)}dy.$ By taking exterior derivative, I got
$$d\omega_{12}=\frac{1}{\sin^{2}(\alpha)}\bigg(\alpha_{xy}\sin(\alpha)-\alpha_{x}\alpha_{y}\cos(\alpha)-\alpha_{xx}\cos(\alpha)\sin(\alpha)+\alpha_{x}^{2}\sin^{2}(\alpha)-\alpha_{x}^{2}\cos^{2}(\alpha)\bigg)dx\wedge dy$$
but $Ke^{1}\wedge e^{2}=K\sin(\alpha)dx\wedge dy$, so I don't get $\displaystyle K=\frac{-\alpha_{xy}}{\sin\alpha}$. Where did I make a mistake?","['riemannian-geometry', 'differential-geometry']"
1998419,How to prove partition into $A_k=\{2^kn | n \in \mathbb N \text{ and }n\text{ is odd}\}$,I am having trouble showing that this is a partition: $\{A_k|k\in \mathbb N \cup \{0\}\}$ where each $A_k=\{2^kn | n \in \mathbb N \text{ and n - odd}\}$ is a partition of the natural numbers. I understand I need to use the definition of partition but I am not to sure how to apply this. For the first part of the definition I think I need to say something like X in Ak. I want to solve it using the three part of the definition of partitions as this is how I will understand it I asked my professor for help and she said to start with X=Ak for some vale of k and to go from there.,"['set-partition', 'proof-writing', 'elementary-set-theory', 'proof-explanation', 'relations']"
1998477,Can any infinite set be written as the union of finite sets?,"While working on a problem, I was wondering about the following: Is it  possible to write any infinite set as union of finite sets or not ?",['elementary-set-theory']
1998527,Is the truth value of $(F \iff T) \iff (T \iff F)$ True?,"I think $(F \iff T) \iff (T \iff F)$ is true, but would like some confirmation.","['logic', 'discrete-mathematics']"
1998580,An invitation to differential geometry?,"For the sake of context: I've just finished a master degree in Mathematics and my goal is to get a Ph.D. in Complex Analysis . In the years I spent studying my undergraduate mathematics degree I had always avoided the Geometry courses because the subject (or maybe the way it was taught to me) seemed... tedious. I remember to think ""Euclidean Geometry, manifolds, Riemann metrics, curvature, geodesics... Ok, so what?"" . That thought, that inability to appreciate the beauty of Geometry ---which I can tell it exists by the many people in the mathematical community who know way more than me about it and claim so--- in the same way I distinctly see it (specially) in Complex Analysis has always bothered me. A few days ago I was reading Rudin's Real and Complex Analysis and reached the following theorem: Theorem: If $\varphi$ is convex on $(a,b)$ , then $\varphi$ is continuous on $(a,b)$ . PROOF The idea of the proof is most easily conveyed in geometric language. Those who may worry that this is not ""rigorous"" are invited to transcribe it in terms of epsilons and deltas. Suppose $a<s<x<y<t<b$ . Write $S$ for the point $(s,\varphi(s))$ in the plane, and deal similarly with $x,y,$ and $t$ . Then $X$ is on or below the line $SY$ , hence $Y$ is on or above the line through $S$ and $X$ ; also, $Y$ is on or below $XT$ . As $y\to x$ , it follows that $Y\to X$ , i.e., $\varphi(y)\to\varphi(x)$ . Left-hand limits are handled in the same manner, and the continuity of $\varphi$ follows. The instant I read ""in geometric language"" I started frowning, but I continued reading. After drawing a picture and give it some thought I was thinking, much to my surprise, that it couldn't exist a more beautiful proof of this theorem. I couldn't like more that ""three-lines-Lipschitz"" clean argument; (!!) Today I had a similar ""incident"" working out the proof that the (angle preserving) set of isometries of the Poincaré disk model coincides exactly with the Mobius transformations of the unit disk, so I have decided to give a hard try to Geometry . I want to begin with Differential Geometry which, being closer to my comfort zone, I expect to be a good choice. I have already chosen from which books I will study (Spivak's A Comprehensive Introduction to Differential Geometry ), so my question is Question: Could you please share some example of a geometric argument , geometric result , geometric idea , or even a geometric calculation in the realm of Differential Geometry which ---in the same spirit as the two examples I gave--- you find exceptionally beautiful or enlightening and explain why? It would be a good source of motivation to keep studying and learning Geometry to me (and maybe others with a similar problem), so I would be sincerely grateful to hear from you. =) [Sorry for the extension, I couldn't find a shorter way to accurately explain what I am looking for.]","['self-learning', 'differential-geometry', 'soft-question', 'geometry']"
1998618,Factorize $x^{2n}+1$ to evaluate $\int\tan^{1/n}(x)dx$,"I've been attempting to find a formula for $\int\tan(x)^{1/n}dx, n\in\Bbb N$. I started out by performing the substitution $$u=\tan(x)^{1/n}$$ $$dx=\frac {nu^{n-1}}{1+u^{2n}}du$$ to transform the integral into $$n\int \frac{u^n}{1+u^{2n}}du$$
This is a relatively simple rational function, so it should be possible to solve via a partial fraction expansion. For the simple case where $n=2$, I was able to rewrite the integral as $$\frac{\sqrt2}{2}\left(\int\frac{u}{u^2-\sqrt2u+1}du - \int\frac{u}{u^2+\sqrt2u+1}du\right)$$ Which can then be solved by completing the square to yield $$\frac{\sqrt2}{4}\ln\left(\left(\sqrt{\tan{x}}-\frac{\sqrt2}{2}\right)^2+\frac{1}{2}\over\left(\sqrt{\tan{x}}+\frac{\sqrt2}{2}\right)^2+\frac{1}{2}\right)+\frac{\sqrt2}{2}\left(\arctan\left({\sqrt{2\tan{x}}-1}\right)+\arctan\left({\sqrt{2\tan{x}}+1}\right)\right)+C$$ However, I can't figure out how to factor the denominator for the partial fraction expansion of the general case. It will always be a product of $n$ irreducible quadratic factors, clearly, but I don't know how to locate them. I have managed to find the complex linear factors, using Euler's identity to find that they're of the form $$x\pm e^{im\pi\over{2n}}$$ where m is allowed to vary from 1 to $2n$. How can I combine these linear factors into real, irreducible quadratics for use in my partial fraction expansion? Alternatively, is there a simpler method of evaluating this integral? Any help would be vastly appreciated.","['algebra-precalculus', 'integration', 'trigonometric-integrals', 'calculus']"
1998711,Why does choosing $\varepsilon$ to be arbitrarily small mean equality?,"Suppose that $\int_a^bf(x)dx$ exists and there is a number A such that, for every $\varepsilon> 0$ and $\delta > 0$ , there is a partition $P$ of $[a,b]$ with $||P||<\delta$ and the Riemann sum of $f$ over $P$ that satisfies the inequality $|\sigma -A|$ . Show that $\int_a^bf(x)dx=A$ . In the last part of this proof it follows that, $|A-\int_a^bf(x)dx| \leq |A-\sigma|+|\sigma-\int_a^bf(x)dx| \leq 2\varepsilon$ Then it says we can choose $\varepsilon$ to be arbitrarily small so that $A=\int_a^bf(x)dx$ . If we choose $\varepsilon$ to be very small how does $A=\int_a^bf(x)dx$ follow?","['real-analysis', 'limits', 'calculus', 'integration', 'riemann-sum']"
1998756,Galois group acting transitively on roots,"Let $F$ be a field of characteristic $0$ and let $f(x)\in F[x]$, and let $G$ be the Galois group of $f(x)$ over $F$. Now, if $f(x)$ is irreducible, I know that $G$ acts transitively on the roots of $f(x)$. $(*)$ Suppose that $f(x)$ is not irreducible, and let $g(x)$ be an irreducible factor of $f(x)$. Does $G$ act transitively on the roots of $g(x)$? I think we can show this by a restriction homomorphism but I'm not sure. My idea is this: If $K$ is the splitting field of $f(x)$ and $L$ is the splitting field of $g(x)$ then $G = \text{Gal}(K/F)$ and $L$ is an intermediate field of $K/F$. Let $H = \text{Gal}(L/F)$. Define a map $$\phi : G\rightarrow H$$ $$\sigma \mapsto \sigma|_L$$ Now this map is surjective and so the image of $\phi$ is $H$ and so $\text{im}\phi$ acts transitively on the roots of $g(x)$ by $(*)$. But since $\phi$ is just a restriction, $G$ must also act transitively on the roots of $g(x)$. It's quite a wordy proof but is the idea correct?","['abstract-algebra', 'galois-theory', 'splitting-field']"
1998758,Integrating $\int_0^\infty \frac{\ln x}{x^{3/4}(1+x)} dx$ via branch cut,"How can I solve the following integral? $$\int_0^\infty \frac{\ln x}{x^{3/4}(1+x)} dx$$ Supposedly, it involves a branch cut, but I am unsure what branch to use, much less the particular contour of integration. WolframAlpha evaluates $-\sqrt{2}\pi^2$, which hints at a circular path of integration.","['logarithms', 'complex-analysis', 'branch-cuts']"
1998813,Calculating limit of $\lim_{x\to\infty}\dfrac{\sqrt{x+1}-2\sqrt{x+2}+\sqrt{x}}{\sqrt{x+2}-2\sqrt{x}+\sqrt{x-4}}$,"As the title says we want to calculate:
$$\lim_{x\to\infty}\dfrac{\sqrt{x+1}-2\sqrt{x+2}+\sqrt{x}}{\sqrt{x+2}-2\sqrt{x}+\sqrt{x-4}}$$ By multiplying nominator and denominator in their conjugates $=\lim_{x\to\infty}\dfrac{(\sqrt{x+2}+2\sqrt{x}+\sqrt{x-4})(x+1+x+2\sqrt{x(x+1)}-4(x+2))}{(\sqrt{x+1}+2\sqrt{x+2}+\sqrt{x})(x+2+x-4+2\sqrt{(x+2)(x-4)})-4x)}$ $=\lim_{x\to\infty}\dfrac{(\sqrt{x+2}+2\sqrt{x}+\sqrt{x-4})(-2x-7+2\sqrt{x^2+x})}{(\sqrt{x+1}+2\sqrt{x+2}+\sqrt{x})(-2x-2+2\sqrt{x^2-2x-8})}$ I think now we can take $$2x\approx2\sqrt{x^2+x}\approx2\sqrt{x^2-2x-8}\\[2ex]
\sqrt{x}\approx\sqrt{x+1}\approx\sqrt{x+2}\approx\sqrt{x-4}$$ as $x$ goes to infinity. Hence the limit of above fraction would be $\dfrac{7}{2}$, but wolframalpha gives me $\dfrac{3}{2}$ as the limit of the above fraction. What am I doing wrong?","['proof-verification', 'limits']"
1998842,Is $f(z)=\frac{z^{2}-1}{z-1}$ continous at $z=1$?,"My teacher said no, but doesn't $f(z)=z+1$ which is continuous?","['algebra-precalculus', 'continuity', 'limits']"
1998843,Showing that the group of invertible $ (3 \times 3) $-matrices over $ \mathbb{F}_{2} $ is isomorphic to a subgroup of $ S_{7} $.,"Show that the group of 3x3 invertible matrices over $\mathbb{Z}_2$ acts on the set of 3-tuples over $\mathbb{Z}_2$ by matrix multiplication. There are 8 such 3-tuples. Show that one of these are fixed by all matrices and that the group acts transitively on the others. Use these facts to prove that $GL_3(\mathbb{F}_2)$ is isomorphic to a subgroup of $S_7$. If we treat the rows and the columns as tuples, it is clear to see that they are elements of $(\mathbb{Z}_2)^3$. I am not sure what ""fixed"" means in this context. I am also confused to how I could use these results to prove that there exists as isomorphism between $GL_3(\mathbb{F}_2)$ and a subgroup of $S_7$. Any hints as to how to continue would be much appreciated.","['abstract-algebra', 'group-theory']"
1998884,Any way to solve this right angle triangle problem without trig? [duplicate],"This question already has answers here : Why does $\tan^{-1}(1)+\tan^{-1}(2)+\tan^{-1}(3)=\pi$? (7 answers) Show that the angles satisfy $x+y=z$ (5 answers) Closed 7 years ago . I know that the answer is 180 from using the arctangent (arctan(1)+arctan(2)+arctan(3)), but thats boring. Is there any way to solve this problem without the help of trig at all?","['recreational-mathematics', 'triangles', 'geometry']"
1998893,Maximum number of regions of a sphere partitioned by $\binom{n}{3}$ planes from $n$ points,"We can place $n\in\mathbb{N}$ points on the surface of a sphere in a configuration so as to maximize the answer. A plane is defined by $3$ points. We create all $\binom{n}{3}$ planes from the $n$ points on the surface of the sphere. What is a formula or way to compute $f(n)$: the maximum number of regions the sphere can be cut into by the planes? For example, I hand-counted for the first few $n$. $f(1)=1$, $f(2)=1$, $f(3)=2$, and $f(4)=11$. For $f(5)$, I have explicitly counted $26$ regions for a configuration but according to my lower bound conjecture, I should have $f(5)\geq 41$. I have conjectures for both the lower and upper bound on $f(n)$. My conjecture for a lower bound on $f(n)$: $f(n)\geq 1+\binom{n}{3}+6\binom{n}{4}$. This is my conjecture because, first, there is the original region ($1$). Then, as each plane enters the sphere, it adds another region (splitting a previous region) ($\binom{n}{3}$). Note that, for each subset of $4$ points, the $\binom{4}{3}=4$ planes formed using them have $\binom{4}{2}=6$ intersections. Each time a plane intersects withe another plane, it adds $1$ region (by splitting a region into $2$). There are $\binom{n}{4}$ such subsets of $4$ points from the $n$. I am certain that the maximal number of regions cannot be LESS than shown via this count. But I'm not sure whether I should be incorporating the counts from planes formed from larger subsets of the $n$ points. My conjecture for an upper bound on $f(n)$: $f(n)\leq 1+\binom{n}{3}+\binom{\binom{n}{3}}{2}$. This is my conjecture because, first, there is the original region ($1$). Then, as each plane enters the sphere, it adds another region (splitting a previous region) ($\binom{n}{3}$). Then, as each plane intersects with another plane, it adds another region (splitting a previous region) ($\binom{\binom{n}{3}}{2}$). I am certain that we cannot have MORE regions than shown via this count. But given the additional constraints on the $\binom{n}{3}$ planes (that they all come from just $n$ points on the sphere's surface), $f(n)$ may be less than this count for $n>4$.","['combinatorics', 'combinatorial-geometry', 'geometry']"
1998912,How do I explain Euler method?,"The explicit Euler method for numerically solving the begining values of differential equation $x′=f(t,x),x(t_0)=x_0$ on the interval $I = [t_0, T]$ is given by $x_{k+1}=x_k+hf(t_k,x_k),k=0,…,N−1$  with $h = (T - t_0) / N, N ∈ N. $ $X_k$ is an approximation of the exact solution $x(t)$ of the begining values at time $t_k: = t_0 + kh, k = 0, ..., N.$ By linear interpolation between the points $(t_k, x_k)$ and $(t_{k + 1}, x_{k + 1}), k = 0, ..., N -1,$ we obtain a approximation solution $x_h(t)$. Can someone tell if this sketch is good?",['ordinary-differential-equations']
1998920,"Partitioning the set of pairs of $\{1,\ldots,n\}$ into classes of size at most $m$?","Let $m,n$ be integers, and let $A = \{\{a,b\} \mid 1 \leq a < b\leq n\}$, the set of unordered pairs. Suppose we try to partition $A$ into subsets $A_1,\ldots,A_k$ such that each $A_i$ consists only of disjoint pairs (in other words, if $\{a,b\} \in A_i$ and $\{a,c\} \in A_i$ then $b = c$). Furthermore suppose we have the restriction that $|A_i| \leq m$ for each $i$. Clearly a lower bound for $k$ is given by
$$
k \geq \left\lceil \frac{n(n-1)}{2m} \right\rceil.
$$
Is this lower bound tight in all cases? That is, can we always give a partition which allows this lower bound? If not, which tight lower bound does work? For example, this trivially holds if $m = 1$, and it somewhat less trivially holds if $n$ is even and $m = \frac n2$.","['combinatorics', 'discrete-optimization', 'discrete-mathematics']"
1998930,"Evaluate $\int_0^\infty\left\{ \frac{1}{t} \right\}^{kn}t^{s-1}dt$ for positive integers $n,k$ and $0<\Re s<1$","Denoting  $\{x\}$ the fractional part function, and $k\geq 1$ and $n\geq 1$ integers, I've interested in a closed-form for the integral in this Question. What's about closed-form for the integral 
  $$\int_0^\infty\left\{ \frac{1}{t} \right\}^{kn}t^{s-1}dt,$$ for $0<\Re s<1$? Many thanks. I don't know if this integral is well known. See below what is my motivation (do calculations, perhaps artificious from an integral representation of the Riemann Zeta function), and this attempt : First, the integral is convergence for integers $k\geq 1$ and $n\geq 1$, because using absolute convergence one gets from the inequality (and the appendix) that our integral is convergent for $$ \left|  \int_0^\infty\left\{ \frac{1}{t} \right\}^{kn}t^{s-1}dt\right|\leq  \int_0^\infty\left\{ \frac{1}{t} \right\}t^{\Re s-1}dt,$$ when $0<\Re s<1$. Secondly, following the hints of solutions in [2] for some integrals that likes to the integrand in the Question (see [2] if you want in the section References in the appendix), I believe that I obtain $$\int_0^\infty\left\{ \frac{1}{t} \right\}^{kn}t^{s-1}dt=\sum_{j=0}^\infty\int_0^1\frac{u^{nk}}{(u+j)^{s+1}}du,$$ when $0<\Re s<1$. As, I've said I'm interested in compute closed-forms for such integral and after try more calculations from the approach in the appendix (that interchange some summation index to get an identity, if it is feasible). I understand that if you answer previous Question you satisfy an answer for this post, but feel free if you want add some remarks with the purpose to get such identities that I evoke. We know the formula (11) here in MathWorld with reference to [1] , that is the Mellin transform of this fractional part function $$ \left\{ \frac{1}{t} \right\} =\operatorname{frac}\left(\frac{1}{t}\right).$$ 
Then since $0\leq \left\{ \frac{1}{t} \right\}<1$ I've computed with Möbius inversion formula to get $$ \left\{ \frac{1}{t} \right\}= \sum_{n=1}^\infty\sum_{k=1}^\infty\frac{\mu(n)}{kn}\left\{ \frac{1}{t} \right\}^{kn},$$ and after combining with the cited Mellin transform by absolute convergence, for $0<\Re s<1$ $$-\frac{\zeta(s)}{s}=\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{\mu(n)}{kn}\int_0^\infty\left\{ \frac{1}{t} \right\}^{kn}t^{s-1}dt.$$ References: [1] Balazard, M. and Saias, E. The Nyman-Beurling Equivalent Form for the Riemann Hypothesis. Expos. Math. 18, 131-138 (2000). [2] Furdui, Limits, Series, and Fractional Part Integrals , Problems in Mathematical Analysis. Springer (2013). (I say hints to Problems likes 2.14 and 2.21.)","['mobius-inversion', 'fractional-part', 'improper-integrals', 'integration', 'sequences-and-series']"
1998967,How do I calculate an approximation of the solution of the begining values at the point t = 1 with Euler method?,"I have already posted question where I was asking about sketching Euler method. The explicit Euler method for numerically solving the begining values of differential equation $x′=f(t,x),x(t_0)=x_0$ on the interval $I = [t_0, T]$ is given by $x_{k+1}=x_k+hf(t_k,x_k),k=0,…,N−1$  with $h = (T - t_0) / N, N ∈ N. $ $X_k$ is an approximation of the exact solution $x(t)$ of the begining values at time $t_k: = t_0 + kh, k = 0, ..., N.$ By linear interpolation between the points $(t_k, x_k)$ and $(t_{k + 1}, x_{k + 1}), k = 0, ..., N -1,$ we obtain a approximation solution $x_h(t)$. I need to calculate an approximation of the solution of the begining values at the point $t = 1$ $x'=-t/x, x(0)=1$ I need to use h = 0.5. Specify $x_h (1)$ and calculate the error, that is difference $x_h (1) -x (1)$, where $x (1)$ is the value of the exact solution. I really don't know how to start. How can I calulate $x$ or $x_h$ at all?","['numerical-methods', 'eulers-method', 'ordinary-differential-equations']"
1998977,"Prove that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3","How can I show that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3? I tried to think about it using the pigeonhole principle but I don't quite get it.","['pigeonhole-principle', 'integers', 'elementary-set-theory']"
1999011,Geodesic convexity and the 2nd fundamental form,"Let $(M,g)$ be a Riemannian manifold, $\Omega\subset M$ be a closed set with smooth boundary $\partial\Omega$ and $\nu$ be the unit normal of $\partial\Omega$ pointing into $\Omega$. $\Omega$ is said to be geodesically convex iff
$\forall x_0, x_1\in\Omega$ $\exists c:[0,1]\stackrel{\text{geodesic}}\to(M,g)$ s.t. $c(0)=x_0, c(1)=x_1$, $c([0,1])\subset\Omega$, $\mathrm{Length}[c]=d_g(x_0,x_1)$. Suppose $\Omega$ is geodesically convex. Then... [Q.1] Does it hold that the 2nd fundamental form of $\partial\Omega$ toward $\nu$ is nonnegative definite at each point on $\partial\Omega$? [Q.2] Let $\psi_r(x):=\mathrm{exp}^g_x [r\nu(x)]\in N$ $(x\in\partial\Omega)$. Then for small $|r|$, $\psi_r$ is an embedding. Here, does it hold that the inner 2nd fundamental form of $\psi_r$ is nonnegative definite at each point on $\partial\Omega$ when $r>0$ and is sufficinetly small? Thank you.","['manifolds', 'riemannian-geometry', 'differential-geometry', 'geometry']"
1999036,The closure of a connected set is connected.,"This is a proof by contradiction, unsing the definition of connectedness from Rudin, Principles of Mathematical Anaylsis. Can someone please check if it is any good? Suppose S is a connected set, where its closure $ \bar{S} $ is not connected. Therefore there exist two nonempty sets A and B, such that $ \bar{A} \cap B = \bar{B}  \cap A = \emptyset $ and $ A \cup B = \bar{S}$. Define $ G:= A \cap S $ and $ H:= B \cap S $. Because G is a subset of A and H is a subset of B, it is clear that $ \bar{G} \cap H = \bar{H}  \cap G = \emptyset $. and $A\cup B = S$. So that S is not connected, contrary to our first assumption. q.e.d. Thank you","['general-topology', 'real-analysis', 'analysis']"
1999039,Locus of tangent lines to a smooth curve of degree $d$ and genus $g$,"Suppose $C\subseteq\mathbb{P}^3$ is a smooth curve of degree $d$ and genus $g$ (let's say we are working over $\mathbb{C}$). Let $T(C)$ be the locus of tangent lines to $C$. In other words,
$$
T(C) = \{ L \in\mathbb{G}(1, 3) \ | \ L \text{ is tangent to C}\}
$$ 
Here $\mathbb{G}(1, 3)$ is the Grassmannian of lines in $\mathbb{P}^3$. How can I compute the class of this locus $[T(C)]$ in the Chow ring? More precisely, what does $[T(C)]$ look like in $A^{3}(\mathbb{G}(1,3))$? Attempt: We know that $[T(C)]=c \sigma_{1, 2}$ where $\sigma_{1, 2}$ is the Schubert cycle corresponding to lines in $\mathbb{P}^3$ that pass through a point $p$ and contained in a plane $H$ (where $p$ and $H$ are general but fixed). So we just need to figure out the constant $c$. To do this, can fix a general line $L_{0}$, and intersect this class $[T(C)]$ with the Schubert cycle $\sigma_{1}$ (which consists of all lines incident to $L_0$). Thus, $c$ is equal to the number of lines $L$ that is tangent to $C$ (at some point) such that $L\cap L_{0}\neq\emptyset$. How can we determine this number in terms of the degree $d$ and genus $g$ of the smooth curve $C$?","['tangent-line', 'algebraic-geometry', 'intersection-theory', 'algebraic-curves', 'schubert-calculus']"
1999048,Borel-Cantelli Lemma and almost sure convergence,"Almost sure convergence is usually proved by Borel-Cantelli lemma. If the condition of Borel-Cantelli lemma doesn't hold, does the almost sure convergence still hold? If so, how to construct a sequence of identically distributed random variables $\{X_n,n\geq1\}$ and a sequence of real numbers $0\leq a_n\rightarrow\infty$ such that $$\sum_{n=1}P[|X_n|>a_n]=\infty,\mbox{  and }  \ X_n/a_n\rightarrow 0\mbox{  a.s.} $$","['borel-cantelli-lemmas', 'probability-theory', 'examples-counterexamples', 'convergence-divergence']"
1999158,"Is it possible to cut the unit disk in $5$ ""small"" parts?","Let $D = \{(x,y) \in \Bbb R^2 \mid x^2+y^2 \leq 1\}$ be the unit disk. Is it possible to find five subsets $A_1, \dots, A_5 \subset D$ such that they cover $D$ and they all have diameter at most $1$? My conditions just mean $$D = \bigcup\limits_{i=1}^5 A_i \qquad\text{and}\qquad
\mathrm{diam}(A_i) := \sup\limits_{x,y \in A_i} \|x-y\|_2 \leq 1,
\;\;\forall i \in \{1,\dots,5\}.$$ Of course, this is possible with $6$ pieces, namely $$A_i = \{re^{ia}    \;\mid\;    0≤r≤1,\; 2\pi (i-1) /6 ≤ a ≤ 2\pi i/6\}$$ But I don't think that this is possible with only $5$ pieces (even with non-measurable subsets), but I don't see any simple argument. Thank you for your help!","['circles', 'dissection', 'geometry']"
1999285,Intersection of Maximal subgroups,"Let G be a group. Show that the intersection of all maximal subgroups of G is a normal subgroup.
I proved that the normalizer of a Maximal subgroup is either the subgroup itself of the Maximal subgroup is normal. 
Also I showed that every subgroup is present in a Maximal subgroup","['finite-groups', 'abstract-algebra', 'maximal-subgroup', 'group-theory']"
1999288,How do I verify the energy conservation rate for the total energy?,"It's given differential equation $\dot{x}=p$ $\dot{p}=-x^3+x$ How do I verify the energy conservation rate for the total energy? $H(x,p)=\frac{x^4}{4}-\frac{x^2}{2}+\frac{p^2}{2}+\frac{1}{2}$? What follows for the solution curves of the differential equation? I have found on internet that if I want to check  energy conservation, I need to verify that $0=\frac{dH}{dt}=\frac{dH}{dx}\frac{dx}{dt}+\frac{dH}{dp}\frac{dp}{dt}$ I'm not sure if this equation  is good, but if it is, what is my $t$ here?",['ordinary-differential-equations']
1999312,Group presentation of $A_5$ with two generators,"In [Huppert, Endliche Gruppen, p140] the author shows that the alternating group $A_5$ is isomorphic to $G := \langle x,y \mid x^5=y^2=(xy)^3=1 \rangle$ . The proof is elementary but long and complicated. Is there a simple way to prove the assertion by using some theory? Of course essentially we have to show that $|G| \leq 60$ . Here is a possible attempt: $A_5$ is generated by $(1,2,3,4,5)$ and $(12)(34)$ , and these elements satisfy the above relations. We can try to give a proof of $|A_5| \leq 60$ by using these generators (and the well known subgroup structure of $A_5$ ), and then to adapt the same proof for $G$ . This could be done as follows: Set $a := xy$ and $b := (xy)^{x^2} = x^{-1}y{x^2}$ . Both elements are of order three. The corresponding permutations are $(2,4,5)$ and $(1,2,4)$ so in principle we should be able to show that $U := \langle a,b \rangle$ (which is in fact isomorphic to $A_4$ ) has at most $12$ elements. For doing so we define $V := \langle ab, (ab)^b \rangle$ . $V$ has to be isomorphic to the Klein four group, so we have to show that $(ab)$ and $(ab)^b$ are commuting involutions (should be possible somehow...), and that $b$ normalizes $V$ (easy). Then it is clear that $U = V \langle b \rangle$ has at most $12$ elements. Finally, we have to show that the index $|G:U|$ is at most $5$ . This is the only part, where I have no idea how to proceed. Any ideas?","['alternative-proof', 'abstract-algebra', 'group-presentation', 'group-theory', 'symmetric-groups']"
1999314,"How to find $f_1\circ f_2\circ\cdots f_{13}(2),$ where $f_n(x) = \frac{nx+9}{x+3}$","How to find $f_1\circ f_2\circ\cdots f_{13}(2),$ where $f_n(x) = \frac{nx+9}{x+3}$ in a reasonable amount of time? I solved this problem through brute forcing, but that took about an hour, and got the final answer $23/11.$ Is there a much quicker way to do this? (The recommended time is 5-10 minutes)","['contest-math', 'function-and-relation-composition', 'functions']"
1999329,Complex number (cube roots of unity),"If $w$ and $w^2$ are non real cube roots of unity, then what would be the value of $\frac{2015+2016w+2017w^2}{2017+2015w+2016w^2}$+$\frac{2015+2016w+2017w^2}{2016+2017w+2015w^2}$ All I know is --> $1+w+w^2=0$ and $w^3=1$ Any tips and suggestions regarding how to solve these kinds of problems would be great.","['complex-analysis', 'complex-numbers']"
1999393,What would you see if you would look out of the window of a car that drives on the real line into an open set?,"Open sets are defined as those sets which contain an open ball around each of their points . Since I started learning topology, I have not understood this definition.
The reason is the following. If I take an open set, for example the set defined by
$U:=\{x|0<x<1, x\in\mathbb{R}\}=(0,1)$ on $\mathbb{R}$, and then choose a point that is rather near to the boundary of its closure $1$, e.g. $0.9$, then by definition, I can draw an epsilon-ball around this point which is still fully contained in the open set. I choose to take the ball with radius infinitesimally bigger than $0.1*0.9=0.09$ such that the ball extends over $0.99$. Now all the points in that ball must again fulfill the definition that I can draw a ball around them which is contained in the set $U$. So let's take a point of the ball we just drew which is nearer to $1$ than the point we chose first, choose $0.99$. We can draw the epsilon-ball with radius infinitesimally bigger than $0.1^2*0.9$ around this point such that the ball extends over $0.999$.
Now we can repeat this process an arbitrary number of times without ever violating the definition of the open set. But if we really do it an infinite amount of times we eventually reach the point $0.9*(1+0.1+0.01+...)=0.\bar 9=1$ which is not in the open set.
I know that someone could counter-argue that as we increase the number of repetitions to an infinite amount, we must choose epsilon balls that have a smaller radius to not violate the definition of the open set. But then again: What would be the biggest radius that we are still allowed to choose? So I just can't imagine how an open set can ""work out"", to say it colloquially. More precisely, the only way how I can imagine how every point can have a surrounding that is again made of points which all again must have a surrounding of points, is to have an infinitely extended Set such as $\mathbb{R}$ itself. In that case I can understand that there is just no limit point (or the limit point is infinity) and therefore the above procedure will not lead to a difficulty in my imagination. But for every Set with a finite extend (even though it may has uncountably many points and even though there is an isomorphism from $\mathbb{R}$ to $(0,1)$), it just does not fit into my intuition. (I know intuition is not everything but without intuition, topics for me loose a certain sense of beauty.) Or, from another perspective: Imagine you would drive with a car on the real line. The car shall have a constant velocity, such that its position is given by the function 
$x(t):= 2-t$, such that at $t=1$, we reach the boundary of the closure of $(0,1)$, then for $t=1+\epsilon$ with $\epsilon>0$, no matter how small $\epsilon$ is, our car will have entered the open set. Now my intuitive problem with this is that we somehow entered the open set, without passing its first point because there is NO first point in an open set. Or, put differently, us driving the car (or varying $t$ of $x(t)$) is actually a continuous process because $x(t)$ is continuous. And as we pass all the points of the real line in a continuous manner, we could stop anywhere we want (because $t\in\mathbb{R}$). Now when undergoing the transition of the outside of the open set to the inside of the open set, then, because the open set is ultimately just a collection of uncountably many points, we must somehow reach the first point (in my imagination) of that Set but this is impossible for if there was a first point there would not be a surrounding of points around it that is also contained in the set thus contradicting the definition of the open set. So again I cannot imagine this properly. If there would be a first point of the open set, then it would have to be an uncountable number of points away from the boundary of the closure (e.g. $1$) but if there are uncountably many points between the boundary of the closure and the first point, then it can't be the first point. If there is no first point of the open set, I can not imagine how the open set can have a finite extend. So, put into a different question: What would you see if you would look out of the window of a car that drives on the real line into an open set? Maybe my unability to understand is also connected to a difficulty of imagining the concept of infinity. Creative and honest thoughts are very much appreciated! PS: This is my first question on stackexchange. Please excuse the probably outrageous number of things that could have been done better.","['general-topology', 'infinity']"
1999415,There must exist a random variable with certain given law?,"Let $(\Omega,\mathcal F,\mathbb P)$ and $(E,\mathcal G,\mu)$ be two probability spaces . My question is the following: Measure-theoretically, is there exist a measurable mapping $X:(\Omega,\mathcal F)\to(E,\mathcal G)$ , such that $\mu$ is just the push-forward measure of $\mathbb P$ w.r.t $X$ , i.e., $\mu(A)=\mathbb P(X^{-1}(A))$ for $\forall A\in\mathcal G$ . Or equivalently in probability, is there exist a random variable $X:(\Omega,\mathcal F)\to(E,\mathcal G)$ , such that $\mu$ is just the law of $X$ . For stochastic processes, there is the well-known Kolmogorov extension theorem to guarantee the existence of stochastic processes for given finite-dimensional distributions. But for random variables, is there some theorem to guarantee the existence for given law? Any comments or references will be appreciated.","['stochastic-processes', 'probability-theory', 'probability', 'measure-theory']"
1999427,Density of order statistics,"I need help with order statistics: Given a sample $X_1, \ldots, X_n$, $X_i \sim U_{0,1}$, i.e. the $X_i$ are uniformly distributed on $[0,1]$, determine the following for the corresponding order statistics: a) the density of $X_{(k)}$ b) the joint density of $X_{(1)}, X_{(n)}$ c) the density of the range $R:=X_{(n)} - X_{(1)}$ d) the limit distribution for $2n(1-R)$ with $n \rightarrow \infty$. Here is my idea for the first one: a) For  the density of an order statistic we've shown: $$f_{X_{(k)}}(t) = \binom{n}{k} k F_X(t)^{k-1}(1-F_X(t))^{n-k}f_X(t)$$
Given the fact that $X_i \sim U_{0,1}$, the density is pretty easy to determine, i.e. $$f_{X_{(k)}}(t) = \binom{n}{k} k t^{k-1}(1-t)^{n-k} \mathbb{1}_{[0,1]}$$ b) For b), I think I can use the following formula: $$f_{(i),(j)} = \dfrac{n!f(x_i)f(x_j)(F(X_i))^{i-1}(F(x_j)-F(x_i))^{j-1-i}(1-F(x_j))^{n-j}}{(i-1)!(j-1-i)!(n-j)!}$$ to get $$f_{(1),(n)} (x_1,x_n) = (n-1)n(x_n-x_1)^{n-2}$$
Is that correct? c) My idea was to use the transformation rule for densities, so $$ \begin{pmatrix}
x \\
y 
\end{pmatrix} = \phi ( z,u) =  \begin{pmatrix}
z-u \\
u 
\end{pmatrix} $$ $$ \begin{pmatrix}
z \\
u 
\end{pmatrix} = \phi^{-1}(x,y) =  \begin{pmatrix}
x+u \\
y 
\end{pmatrix} $$ with $J_{\phi^{-1}}(x,y) = \begin{vmatrix}
1 & 0 \\
0 & 1 
\end{vmatrix} = 1$ Then $f_R = f_{(n)}(\phi^{-1}(x,y))f_{(1)}(\phi^{-1}(x,y))\cdot1 = \cdots$ - how do I proceed now? d) Here I don't know how to start... Thank you for the help!","['density-function', 'probability-theory', 'statistics', 'probability', 'order-statistics']"
1999437,Prove that two sets are equal,I need to show that the relation $A-B=((A\cup B)-(A\cap B))-(B-A)$ is true for any sets A and B. I know that I can prove this through double inclusion. So here is how I did it. (left to right) Let x $\in A-B$ $\Leftrightarrow (x\in A) \wedge !(x \in B)$ $\Leftrightarrow x \in(A\cup B) \wedge \ !\ x\in(A \cap B) \wedge\ !\ x\in(B-A)$ $\Leftrightarrow  x\in((A\cup B)-(A\cap B))-(B-A)$ (right to left) Let $x\in((A\cup B)-(A\cap B))-(B-A)$ $\Leftrightarrow x \in ((A\cup B)-(A\cap B))  \wedge\ !\ x\in(B-A)$ $\Leftrightarrow x\in (A \cup B) \wedge \ !\ x \in (A \cap B) \wedge\ !\ x \in(B-A)$ $\Leftrightarrow (x\in A \vee x \in B) \wedge \ ! \ (x \in A \wedge x \in B) \wedge \ ! \ (x\in B \wedge\  ! \ (x \in A))$ $\Leftrightarrow x\in A \wedge \ !\ (x\in B)$ $x \in (A-B)$ Is this the right way to do it? Am I correct?,"['predicate-logic', 'logic', 'elementary-set-theory']"
1999533,Why are the domains for $\ln x^2$ and $2\ln x$ different?,"If I have a function like this $f(x)=2 \ln(x)$ and I want to find the domain, I put $x>0$. But if I use the properties of logarithmic functions, I can write that function like $f(x)=\ln(x^2)$ and so the domain is all $\mathbb{R}$ and the graphic of function is different. Where is the mistake?","['algebra-precalculus', 'logarithms']"
1999534,Differential of a function definition,"Consider $f: U \rightarrow \mathbb R$, $U \subset \mathbb R^n $ is an open set. a. Show that if $f$ is differenciable on $a \in U$ then there is a unique vector $w$ such that $\lim\limits_{h\mapsto 0}\dfrac{f(a + hv) - f(a)}{h} = \langle w,v \rangle$. b. Is the reciprocal statement true ? c. Find the parcials derivatives of $f$ on $a$ with respect to $w$. I think part $a$ comes from the definition of a differentiable function, $w$ is unique because of the uniqueness of the limit. However, I'm not so sure about  $b$ and $c$. Any help will be appreciated !","['derivatives', 'real-analysis', 'definition']"
1999572,"If $f(x)= \lim_ {n \to \infty} \sum_{r=1}^{n} \frac{n}{n^2+x^2r^2}$, find the required value","We have $$f(x)= \lim_ {n \to \infty} \sum_{r=1}^{n} \frac{n}{n^2+x^2r^2}$$, then find the value of $\sum_{k=1}^{3} k f(k)$. Could someone give me slight hint as how to find $f(x)$ here.","['riemann-sum', 'trigonometry', 'calculus', 'limits']"
1999614,Proof that a set is a group,"Let $G$ be a nonempty set with an associative operation and for each $a\in G$ exists only one $a'\in G$  such that $aa'a=a$. Prove that $G$ is a group. I tried playing with the fact that $aa'a=a$ and the only thing I found is that $(a')'=a$. Then I tried proving that for each $a,b\in G$, $aa'=bb'$ (which means we can write $e=aa'$ and then $G$ has an identity) but I couldn't get anything meaningful. Proof that $(a')'=a$ (by request): $aa'a=a$ $a'aa'a=a'a$ (multiply by $a'$ from left side) $a(a'aa')a=a(a')a$ (multiply by $a$ from right side) We know that $a'$ is the only one that satisfy $aa'a=a$ and therfore $a'aa'=a'$ (whice means that $(a')'=a$.","['abstract-algebra', 'group-theory']"
1999626,"Let $I$ be an interval, $f:I \rightarrow \mathbb{R}$ is a monotone function. Prove that if $f(I)$ is an interval, then $f$ is continuous","Let $I$ be an interval, $f:I \rightarrow \mathbb{R}$ is a monotone function. Prove that if $f(I)$ is an interval, then $f$ is continuous. What I did was: supose f is monotone non decreasing (argument is similar if f is increasing, non increasing and decreasing) Let $a \in I \implies f(a) \in f(I)$. Let $\epsilon>0$. As $f(I)$ is an interval $\forall y \in [f(a)-\epsilon, f(a)+\epsilon]\cap f(I)\, \exists x \in I$ s.t. $f(x)=y $. Let $W:=[f(a)-\epsilon, f(a)+\epsilon]\cap f(I)$ Since $W\subseteq [f(a)-\epsilon, f(a)+\epsilon]$ then it is limited and $f(a)$ belongs to it, therefore there is an inf and a sup. Let $\alpha = \inf W$ and $\beta = \sup W$. Then $f(y)\in [\alpha,\beta]$. $a \in I$ then $a$ is an interior point or a is a border($I = [a,*$ or $I=*,a]$). If $a$ is an interior point let $\delta>0$ such that $[a-\delta, a+\delta] \subseteq I$ and $f(a-\delta)\leq\alpha$ and $f(a+\delta)\geq \beta$. Then $y\leq a-\delta$ or $y\geq a+\delta$ or $y\in [a-\delta, a+\delta]$. if  $y\leq a-\delta \implies f(y)\leq f(a-\delta)<\alpha$ which is a contradiction. if  $y\geq a-\delta \implies f(y)\geq f(a-\delta)>\beta$ which is a contradiction. therefore exists $\delta$ such that $y\in [a-\delta, a+\delta] \implies |f(x)-f(a)|\leq \epsilon$ if $a$ is a border point supose $I=[a,*$ (argument similar for the other case): then exists $\delta>0$ such that $[a, a+\delta]\subseteq I$ and $f(a+\delta)>\beta$. Then $y\in [a,a+\delta]$ or $y\geq a+\delta$, ($y<a-\delta$ is not possible since $a-\delta \not \in I$). if $y>a+\delta\implies f(y)>f(a+\delta)>f(a)+\epsilon$ which is a contradiction, therefore exists $\delta>0$ such that $y \in [a-\delta, a+\delta] \implies |f(x)-f(a)|\leq \epsilon$. therefore f is continuous. Is this correct? I'm not sure if I can choose $\delta$ that obeys those restrictions. Is there a simpler way to prove this?","['continuity', 'real-analysis', 'functions']"
1999629,"Prove that $G$ is an abelian group if $\{(g, g):g\in G\}$ is a normal subgroup.","Let $G$ be a group and let $D=\{(g, g):g\in G\}$. If $D$ is a normal subgroup of $G\times G$, prove that $G$ is an abelian group. My attempt: $D$ is a normal subgroup of $G\times G$. $\implies(a, b)D=D(a, b)\ \forall(a, b)\in G\times G$ So for a given $(a, b)\in G$ and $(g, g)\in D$, $\exists(g', g')\in D$ such that $(a, b)(g, g)=(g', g')(a, b)$ $(ag, bg)=(g'a, g'b)$ $ag=g'a$ and $bg=g'b$ I feel like I've used all of the information given but don't know how to conclude that $G$ is abelian. Any suggestions?","['normal-subgroups', 'group-theory']"
1999683,"How to prove $f$ is in the span of $f_{1,\cdots, n}$? [duplicate]","This question already has answers here : Intersection of kernels and linear dependence of functionals (3 answers) Closed 7 years ago . Suppose $f, f_{1,\cdots,n}\in X^*$ where $X$ is a normed vector space. How to show that, if $\cap Ker f_i \subset Ker f$, then $f$ is a linear combination of $f_{1,\cdots,n}$? I'm at a loss even for the classical linear algebra cases (where $X$ is a finite dimensional Euclidean spade with $\ell^2$ norm, so really don't know how to proceed for the more general cases. EDIT It seems I might want to relax the conditions a little here. So let's now assume $X$ is a Banach space. EDIT The Banach space assumption can be dropped. Any normed vector space is okay.","['functional-analysis', 'linear-algebra']"
1999686,lower bound on norm of matrix vector product,"I'm wondering if the following inequality holds $ \sigma_{min}\|v\|_2 \leq \|Av\|_2$ , where $ \sigma_{min}$ is the smallest singular value of A. Furthermore, assuming that A is positive definite and $v \in \mathbb{R^n}$. Thank you :)","['matrices', 'normed-spaces', 'linear-algebra', 'vectors']"
